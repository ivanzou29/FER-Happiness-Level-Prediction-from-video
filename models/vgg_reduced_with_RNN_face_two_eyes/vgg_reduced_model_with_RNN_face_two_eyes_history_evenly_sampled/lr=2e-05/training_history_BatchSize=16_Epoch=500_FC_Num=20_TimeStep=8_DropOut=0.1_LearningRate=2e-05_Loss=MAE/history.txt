Epoch: 1| Step: 0
Training loss: 4.9205732345581055
Validation loss: 5.226443988020702

Epoch: 6| Step: 1
Training loss: 4.0638227462768555
Validation loss: 5.207821912662958

Epoch: 6| Step: 2
Training loss: 4.068097114562988
Validation loss: 5.192255189341884

Epoch: 6| Step: 3
Training loss: 4.818743705749512
Validation loss: 5.1789543449237785

Epoch: 6| Step: 4
Training loss: 4.997770309448242
Validation loss: 5.165057674531014

Epoch: 6| Step: 5
Training loss: 5.325100421905518
Validation loss: 5.148962502838463

Epoch: 6| Step: 6
Training loss: 5.190642356872559
Validation loss: 5.130324053507979

Epoch: 6| Step: 7
Training loss: 4.859947204589844
Validation loss: 5.108394176729264

Epoch: 6| Step: 8
Training loss: 4.941600799560547
Validation loss: 5.083261259140507

Epoch: 6| Step: 9
Training loss: 5.593074798583984
Validation loss: 5.05401264211183

Epoch: 6| Step: 10
Training loss: 5.359489440917969
Validation loss: 5.020512191198206

Epoch: 6| Step: 11
Training loss: 4.266818046569824
Validation loss: 4.982650874763407

Epoch: 6| Step: 12
Training loss: 4.143584728240967
Validation loss: 4.940333858613045

Epoch: 6| Step: 13
Training loss: 6.869411945343018
Validation loss: 4.894022346824728

Epoch: 2| Step: 0
Training loss: 4.731366157531738
Validation loss: 4.843440476284232

Epoch: 6| Step: 1
Training loss: 5.059927463531494
Validation loss: 4.789132933462819

Epoch: 6| Step: 2
Training loss: 4.4360575675964355
Validation loss: 4.732962134063885

Epoch: 6| Step: 3
Training loss: 4.188446521759033
Validation loss: 4.673966925631287

Epoch: 6| Step: 4
Training loss: 4.530850410461426
Validation loss: 4.613476489179877

Epoch: 6| Step: 5
Training loss: 4.448770046234131
Validation loss: 4.548421347013083

Epoch: 6| Step: 6
Training loss: 4.340908050537109
Validation loss: 4.483889795118762

Epoch: 6| Step: 7
Training loss: 4.267563819885254
Validation loss: 4.420249431363998

Epoch: 6| Step: 8
Training loss: 4.246635437011719
Validation loss: 4.360439961956393

Epoch: 6| Step: 9
Training loss: 3.9926016330718994
Validation loss: 4.3025488084362395

Epoch: 6| Step: 10
Training loss: 3.1772067546844482
Validation loss: 4.249217664041827

Epoch: 6| Step: 11
Training loss: 3.6321895122528076
Validation loss: 4.197653934519778

Epoch: 6| Step: 12
Training loss: 4.770098686218262
Validation loss: 4.1489610415633

Epoch: 6| Step: 13
Training loss: 3.822403907775879
Validation loss: 4.109704894404257

Epoch: 3| Step: 0
Training loss: 4.050021648406982
Validation loss: 4.071251571819347

Epoch: 6| Step: 1
Training loss: 3.7405405044555664
Validation loss: 4.036061984236523

Epoch: 6| Step: 2
Training loss: 3.5061118602752686
Validation loss: 4.001041899445236

Epoch: 6| Step: 3
Training loss: 4.193400859832764
Validation loss: 3.964809725361486

Epoch: 6| Step: 4
Training loss: 4.332849025726318
Validation loss: 3.9282114557040635

Epoch: 6| Step: 5
Training loss: 2.610212802886963
Validation loss: 3.8934041582128054

Epoch: 6| Step: 6
Training loss: 4.313693046569824
Validation loss: 3.8614567095233547

Epoch: 6| Step: 7
Training loss: 4.361911296844482
Validation loss: 3.8342113443600234

Epoch: 6| Step: 8
Training loss: 3.296262264251709
Validation loss: 3.803249938513643

Epoch: 6| Step: 9
Training loss: 3.2360081672668457
Validation loss: 3.7750434157668904

Epoch: 6| Step: 10
Training loss: 3.7301318645477295
Validation loss: 3.7534410415157193

Epoch: 6| Step: 11
Training loss: 3.4133286476135254
Validation loss: 3.7360479600967897

Epoch: 6| Step: 12
Training loss: 4.262020111083984
Validation loss: 3.7188842578600814

Epoch: 6| Step: 13
Training loss: 3.389758586883545
Validation loss: 3.703720651647096

Epoch: 4| Step: 0
Training loss: 3.29597806930542
Validation loss: 3.690578983676049

Epoch: 6| Step: 1
Training loss: 3.9027023315429688
Validation loss: 3.6768097723684003

Epoch: 6| Step: 2
Training loss: 4.677191734313965
Validation loss: 3.659959982800227

Epoch: 6| Step: 3
Training loss: 3.403595447540283
Validation loss: 3.636699281713014

Epoch: 6| Step: 4
Training loss: 3.7170839309692383
Validation loss: 3.589610012628699

Epoch: 6| Step: 5
Training loss: 3.8296656608581543
Validation loss: 3.577829243034445

Epoch: 6| Step: 6
Training loss: 3.1169986724853516
Validation loss: 3.5761190024755334

Epoch: 6| Step: 7
Training loss: 3.0189788341522217
Validation loss: 3.5606431832877536

Epoch: 6| Step: 8
Training loss: 3.5306715965270996
Validation loss: 3.5566983428052676

Epoch: 6| Step: 9
Training loss: 3.42218279838562
Validation loss: 3.5521946055914766

Epoch: 6| Step: 10
Training loss: 3.174501895904541
Validation loss: 3.5469874592237574

Epoch: 6| Step: 11
Training loss: 3.515747547149658
Validation loss: 3.5344624724439395

Epoch: 6| Step: 12
Training loss: 3.047241687774658
Validation loss: 3.50996987024943

Epoch: 6| Step: 13
Training loss: 3.364241361618042
Validation loss: 3.5107181610599643

Epoch: 5| Step: 0
Training loss: 3.404442310333252
Validation loss: 3.488584728651149

Epoch: 6| Step: 1
Training loss: 2.6541030406951904
Validation loss: 3.4733779225298154

Epoch: 6| Step: 2
Training loss: 4.393013954162598
Validation loss: 3.468229470714446

Epoch: 6| Step: 3
Training loss: 3.0207583904266357
Validation loss: 3.4552254497364

Epoch: 6| Step: 4
Training loss: 3.1752614974975586
Validation loss: 3.4443483762843634

Epoch: 6| Step: 5
Training loss: 4.033456802368164
Validation loss: 3.434160860635901

Epoch: 6| Step: 6
Training loss: 2.2982654571533203
Validation loss: 3.429816581869638

Epoch: 6| Step: 7
Training loss: 2.328084707260132
Validation loss: 3.4242762698922107

Epoch: 6| Step: 8
Training loss: 3.897930383682251
Validation loss: 3.417675607947893

Epoch: 6| Step: 9
Training loss: 4.3883771896362305
Validation loss: 3.408380477659164

Epoch: 6| Step: 10
Training loss: 2.799109935760498
Validation loss: 3.40123353978639

Epoch: 6| Step: 11
Training loss: 3.053529739379883
Validation loss: 3.3925099090863298

Epoch: 6| Step: 12
Training loss: 4.114962100982666
Validation loss: 3.381067378546602

Epoch: 6| Step: 13
Training loss: 3.859001636505127
Validation loss: 3.37723970413208

Epoch: 6| Step: 0
Training loss: 3.9538466930389404
Validation loss: 3.372707889926049

Epoch: 6| Step: 1
Training loss: 3.8936567306518555
Validation loss: 3.358088570256387

Epoch: 6| Step: 2
Training loss: 2.980266571044922
Validation loss: 3.3518831447888444

Epoch: 6| Step: 3
Training loss: 3.2712252140045166
Validation loss: 3.3424934802516812

Epoch: 6| Step: 4
Training loss: 3.192260265350342
Validation loss: 3.338699430547735

Epoch: 6| Step: 5
Training loss: 4.487539291381836
Validation loss: 3.331588855353735

Epoch: 6| Step: 6
Training loss: 2.384916305541992
Validation loss: 3.3255860241510535

Epoch: 6| Step: 7
Training loss: 2.938692808151245
Validation loss: 3.3161561976196947

Epoch: 6| Step: 8
Training loss: 3.4445369243621826
Validation loss: 3.3083257905898558

Epoch: 6| Step: 9
Training loss: 3.476985454559326
Validation loss: 3.3095038706256497

Epoch: 6| Step: 10
Training loss: 2.312852621078491
Validation loss: 3.3048714745429253

Epoch: 6| Step: 11
Training loss: 2.9270522594451904
Validation loss: 3.2973467150042133

Epoch: 6| Step: 12
Training loss: 3.114330291748047
Validation loss: 3.2870186631397535

Epoch: 6| Step: 13
Training loss: 3.866072416305542
Validation loss: 3.275438403570524

Epoch: 7| Step: 0
Training loss: 2.8747637271881104
Validation loss: 3.269869404454385

Epoch: 6| Step: 1
Training loss: 3.120388984680176
Validation loss: 3.264382682820802

Epoch: 6| Step: 2
Training loss: 2.6565866470336914
Validation loss: 3.2578267307691675

Epoch: 6| Step: 3
Training loss: 4.005338668823242
Validation loss: 3.2505925393873647

Epoch: 6| Step: 4
Training loss: 2.015634298324585
Validation loss: 3.2436205084605882

Epoch: 6| Step: 5
Training loss: 2.668087959289551
Validation loss: 3.239146381296137

Epoch: 6| Step: 6
Training loss: 3.652125358581543
Validation loss: 3.230132520839732

Epoch: 6| Step: 7
Training loss: 4.616074562072754
Validation loss: 3.221911884123279

Epoch: 6| Step: 8
Training loss: 2.620241403579712
Validation loss: 3.2113812097939114

Epoch: 6| Step: 9
Training loss: 3.5221285820007324
Validation loss: 3.2054131595037316

Epoch: 6| Step: 10
Training loss: 3.373701572418213
Validation loss: 3.20066418955403

Epoch: 6| Step: 11
Training loss: 3.3308193683624268
Validation loss: 3.191925020628078

Epoch: 6| Step: 12
Training loss: 3.1474575996398926
Validation loss: 3.181216711639076

Epoch: 6| Step: 13
Training loss: 3.6481738090515137
Validation loss: 3.1821692964082122

Epoch: 8| Step: 0
Training loss: 3.2067859172821045
Validation loss: 3.181058129956645

Epoch: 6| Step: 1
Training loss: 3.0810494422912598
Validation loss: 3.174054350904239

Epoch: 6| Step: 2
Training loss: 2.7643604278564453
Validation loss: 3.1633031342619207

Epoch: 6| Step: 3
Training loss: 2.600215196609497
Validation loss: 3.1586868429696686

Epoch: 6| Step: 4
Training loss: 3.3840630054473877
Validation loss: 3.150193296453004

Epoch: 6| Step: 5
Training loss: 3.1907243728637695
Validation loss: 3.142696431888047

Epoch: 6| Step: 6
Training loss: 3.36417293548584
Validation loss: 3.137650469298004

Epoch: 6| Step: 7
Training loss: 2.498263120651245
Validation loss: 3.135250042843562

Epoch: 6| Step: 8
Training loss: 3.171766996383667
Validation loss: 3.128171561866678

Epoch: 6| Step: 9
Training loss: 3.453187942504883
Validation loss: 3.1182692076570246

Epoch: 6| Step: 10
Training loss: 3.7210752964019775
Validation loss: 3.112213765421221

Epoch: 6| Step: 11
Training loss: 3.3748106956481934
Validation loss: 3.1084986809761292

Epoch: 6| Step: 12
Training loss: 2.893451690673828
Validation loss: 3.1010585484966153

Epoch: 6| Step: 13
Training loss: 3.699212074279785
Validation loss: 3.095684956478816

Epoch: 9| Step: 0
Training loss: 2.8290863037109375
Validation loss: 3.091832176331551

Epoch: 6| Step: 1
Training loss: 3.171252727508545
Validation loss: 3.0811044580192974

Epoch: 6| Step: 2
Training loss: 2.7859139442443848
Validation loss: 3.076889599523237

Epoch: 6| Step: 3
Training loss: 3.054985523223877
Validation loss: 3.087278086652038

Epoch: 6| Step: 4
Training loss: 3.5395593643188477
Validation loss: 3.1860053026547996

Epoch: 6| Step: 5
Training loss: 3.326082229614258
Validation loss: 3.1909814137284473

Epoch: 6| Step: 6
Training loss: 2.9570960998535156
Validation loss: 3.155760021619899

Epoch: 6| Step: 7
Training loss: 3.506453514099121
Validation loss: 3.127262676915815

Epoch: 6| Step: 8
Training loss: 3.393625259399414
Validation loss: 3.048626520300424

Epoch: 6| Step: 9
Training loss: 3.5298914909362793
Validation loss: 3.0452160271265174

Epoch: 6| Step: 10
Training loss: 3.3491601943969727
Validation loss: 3.118370335589173

Epoch: 6| Step: 11
Training loss: 2.929276943206787
Validation loss: 3.0527590372229136

Epoch: 6| Step: 12
Training loss: 1.939115047454834
Validation loss: 3.046193192082067

Epoch: 6| Step: 13
Training loss: 3.8456661701202393
Validation loss: 3.04562965003393

Epoch: 10| Step: 0
Training loss: 4.228367805480957
Validation loss: 3.050458561989569

Epoch: 6| Step: 1
Training loss: 2.750581741333008
Validation loss: 3.046824998753045

Epoch: 6| Step: 2
Training loss: 3.2683706283569336
Validation loss: 3.0429575443267822

Epoch: 6| Step: 3
Training loss: 2.9438018798828125
Validation loss: 3.0439722973813295

Epoch: 6| Step: 4
Training loss: 3.5364632606506348
Validation loss: 3.0502120397424184

Epoch: 6| Step: 5
Training loss: 3.9242641925811768
Validation loss: 3.035877286746938

Epoch: 6| Step: 6
Training loss: 2.7476117610931396
Validation loss: 3.0124103253887546

Epoch: 6| Step: 7
Training loss: 2.776829242706299
Validation loss: 3.0088331571189304

Epoch: 6| Step: 8
Training loss: 2.4281978607177734
Validation loss: 2.9919516014796432

Epoch: 6| Step: 9
Training loss: 3.5387203693389893
Validation loss: 2.990996109542026

Epoch: 6| Step: 10
Training loss: 2.7114453315734863
Validation loss: 2.976139486476939

Epoch: 6| Step: 11
Training loss: 3.682936191558838
Validation loss: 2.966031923088976

Epoch: 6| Step: 12
Training loss: 1.8496683835983276
Validation loss: 2.965020674531178

Epoch: 6| Step: 13
Training loss: 2.31143856048584
Validation loss: 2.9620132061742965

Epoch: 11| Step: 0
Training loss: 2.362081289291382
Validation loss: 2.958228667577108

Epoch: 6| Step: 1
Training loss: 2.5080134868621826
Validation loss: 2.9409802395810365

Epoch: 6| Step: 2
Training loss: 2.662226676940918
Validation loss: 2.938446452540736

Epoch: 6| Step: 3
Training loss: 2.6341967582702637
Validation loss: 2.959801950762349

Epoch: 6| Step: 4
Training loss: 3.363872766494751
Validation loss: 2.976139304458454

Epoch: 6| Step: 5
Training loss: 2.517183303833008
Validation loss: 2.944406368399179

Epoch: 6| Step: 6
Training loss: 3.4274420738220215
Validation loss: 2.997501427127469

Epoch: 6| Step: 7
Training loss: 2.9773850440979004
Validation loss: 3.0286442490034204

Epoch: 6| Step: 8
Training loss: 3.0300705432891846
Validation loss: 3.0348326493335027

Epoch: 6| Step: 9
Training loss: 3.775418758392334
Validation loss: 3.0337516928231842

Epoch: 6| Step: 10
Training loss: 2.8547844886779785
Validation loss: 3.017365809409849

Epoch: 6| Step: 11
Training loss: 3.6274144649505615
Validation loss: 2.9918111549910678

Epoch: 6| Step: 12
Training loss: 3.3496146202087402
Validation loss: 2.979775285208097

Epoch: 6| Step: 13
Training loss: 4.104828834533691
Validation loss: 2.972859856902912

Epoch: 12| Step: 0
Training loss: 3.567213535308838
Validation loss: 2.919687896646479

Epoch: 6| Step: 1
Training loss: 2.9558846950531006
Validation loss: 2.929062630540581

Epoch: 6| Step: 2
Training loss: 3.6058993339538574
Validation loss: 2.96748532531082

Epoch: 6| Step: 3
Training loss: 3.8301830291748047
Validation loss: 2.940871789891233

Epoch: 6| Step: 4
Training loss: 2.6191625595092773
Validation loss: 2.9120053552812144

Epoch: 6| Step: 5
Training loss: 3.566844940185547
Validation loss: 2.9045925268562893

Epoch: 6| Step: 6
Training loss: 2.546360492706299
Validation loss: 2.8990313263349634

Epoch: 6| Step: 7
Training loss: 3.6714651584625244
Validation loss: 2.8952048183769308

Epoch: 6| Step: 8
Training loss: 2.1162726879119873
Validation loss: 2.9034979727960404

Epoch: 6| Step: 9
Training loss: 2.5231852531433105
Validation loss: 2.8952582959205873

Epoch: 6| Step: 10
Training loss: 2.728156566619873
Validation loss: 2.8809028235814904

Epoch: 6| Step: 11
Training loss: 2.7280149459838867
Validation loss: 2.875402578743555

Epoch: 6| Step: 12
Training loss: 2.7996158599853516
Validation loss: 2.874315172113398

Epoch: 6| Step: 13
Training loss: 2.66753888130188
Validation loss: 2.8714850897430093

Epoch: 13| Step: 0
Training loss: 3.525847911834717
Validation loss: 2.866148151377196

Epoch: 6| Step: 1
Training loss: 3.2829179763793945
Validation loss: 2.8625601081437964

Epoch: 6| Step: 2
Training loss: 2.8274221420288086
Validation loss: 2.856981844030401

Epoch: 6| Step: 3
Training loss: 2.6777071952819824
Validation loss: 2.8516912691054808

Epoch: 6| Step: 4
Training loss: 2.537651538848877
Validation loss: 2.8472129555158716

Epoch: 6| Step: 5
Training loss: 2.713008403778076
Validation loss: 2.842095254569925

Epoch: 6| Step: 6
Training loss: 2.8988587856292725
Validation loss: 2.8415693108753493

Epoch: 6| Step: 7
Training loss: 3.123147487640381
Validation loss: 2.844186546981976

Epoch: 6| Step: 8
Training loss: 3.6087236404418945
Validation loss: 2.8497560178079913

Epoch: 6| Step: 9
Training loss: 3.041114568710327
Validation loss: 2.848812175053422

Epoch: 6| Step: 10
Training loss: 3.1660192012786865
Validation loss: 2.8253592752641246

Epoch: 6| Step: 11
Training loss: 2.3898537158966064
Validation loss: 2.822585149477887

Epoch: 6| Step: 12
Training loss: 3.439663887023926
Validation loss: 2.8210494415734404

Epoch: 6| Step: 13
Training loss: 1.6320297718048096
Validation loss: 2.8232995874138287

Epoch: 14| Step: 0
Training loss: 2.8568358421325684
Validation loss: 2.820831383428266

Epoch: 6| Step: 1
Training loss: 2.501323938369751
Validation loss: 2.817345065455283

Epoch: 6| Step: 2
Training loss: 3.0612874031066895
Validation loss: 2.8171608730029036

Epoch: 6| Step: 3
Training loss: 2.424739122390747
Validation loss: 2.8125922500446277

Epoch: 6| Step: 4
Training loss: 3.3461921215057373
Validation loss: 2.8120777094235985

Epoch: 6| Step: 5
Training loss: 3.0724735260009766
Validation loss: 2.8130273742060505

Epoch: 6| Step: 6
Training loss: 3.394207000732422
Validation loss: 2.8139243433552403

Epoch: 6| Step: 7
Training loss: 2.290902614593506
Validation loss: 2.8124826877347884

Epoch: 6| Step: 8
Training loss: 2.874837875366211
Validation loss: 2.802719498193392

Epoch: 6| Step: 9
Training loss: 3.1060750484466553
Validation loss: 2.8011986465864283

Epoch: 6| Step: 10
Training loss: 2.7134528160095215
Validation loss: 2.7982242645755893

Epoch: 6| Step: 11
Training loss: 2.873830795288086
Validation loss: 2.7927717419080835

Epoch: 6| Step: 12
Training loss: 3.067479133605957
Validation loss: 2.7902591818122455

Epoch: 6| Step: 13
Training loss: 3.940746784210205
Validation loss: 2.7909536361694336

Epoch: 15| Step: 0
Training loss: 2.2959911823272705
Validation loss: 2.7889653739108833

Epoch: 6| Step: 1
Training loss: 2.802419424057007
Validation loss: 2.788559357325236

Epoch: 6| Step: 2
Training loss: 2.675853729248047
Validation loss: 2.7811320827853296

Epoch: 6| Step: 3
Training loss: 2.826371192932129
Validation loss: 2.7817398296889437

Epoch: 6| Step: 4
Training loss: 3.2829718589782715
Validation loss: 2.7781778279171196

Epoch: 6| Step: 5
Training loss: 3.2207815647125244
Validation loss: 2.7754684827661

Epoch: 6| Step: 6
Training loss: 2.824789524078369
Validation loss: 2.7759153817289617

Epoch: 6| Step: 7
Training loss: 3.337416648864746
Validation loss: 2.772964464720859

Epoch: 6| Step: 8
Training loss: 3.1515235900878906
Validation loss: 2.782733676254108

Epoch: 6| Step: 9
Training loss: 2.679703712463379
Validation loss: 2.7830178596640147

Epoch: 6| Step: 10
Training loss: 2.2003140449523926
Validation loss: 2.774532523206485

Epoch: 6| Step: 11
Training loss: 2.9867730140686035
Validation loss: 2.76847227158085

Epoch: 6| Step: 12
Training loss: 2.942732572555542
Validation loss: 2.7646269952097247

Epoch: 6| Step: 13
Training loss: 4.241686820983887
Validation loss: 2.7647655958770425

Epoch: 16| Step: 0
Training loss: 2.5429582595825195
Validation loss: 2.763768293524301

Epoch: 6| Step: 1
Training loss: 2.8064980506896973
Validation loss: 2.7628887699496363

Epoch: 6| Step: 2
Training loss: 2.5599355697631836
Validation loss: 2.761609080017254

Epoch: 6| Step: 3
Training loss: 2.650930404663086
Validation loss: 2.763207843226771

Epoch: 6| Step: 4
Training loss: 3.138773202896118
Validation loss: 2.7640623661779586

Epoch: 6| Step: 5
Training loss: 2.986846446990967
Validation loss: 2.7636458540475495

Epoch: 6| Step: 6
Training loss: 2.504711627960205
Validation loss: 2.7628197721255723

Epoch: 6| Step: 7
Training loss: 2.3789548873901367
Validation loss: 2.7667296778771187

Epoch: 6| Step: 8
Training loss: 2.733865261077881
Validation loss: 2.790825838683754

Epoch: 6| Step: 9
Training loss: 3.411311149597168
Validation loss: 2.7611327735326623

Epoch: 6| Step: 10
Training loss: 3.264280319213867
Validation loss: 2.7593799765392015

Epoch: 6| Step: 11
Training loss: 2.6950550079345703
Validation loss: 2.759486444534794

Epoch: 6| Step: 12
Training loss: 3.9891185760498047
Validation loss: 2.7634222020385084

Epoch: 6| Step: 13
Training loss: 3.026726484298706
Validation loss: 2.7593821376882572

Epoch: 17| Step: 0
Training loss: 2.940305709838867
Validation loss: 2.755819151478429

Epoch: 6| Step: 1
Training loss: 2.5995450019836426
Validation loss: 2.752348424285971

Epoch: 6| Step: 2
Training loss: 2.359044075012207
Validation loss: 2.751612742741903

Epoch: 6| Step: 3
Training loss: 3.1110546588897705
Validation loss: 2.75250304642544

Epoch: 6| Step: 4
Training loss: 3.1229918003082275
Validation loss: 2.751749748824745

Epoch: 6| Step: 5
Training loss: 2.984149932861328
Validation loss: 2.7508850148929063

Epoch: 6| Step: 6
Training loss: 3.1964523792266846
Validation loss: 2.747031299016809

Epoch: 6| Step: 7
Training loss: 2.813746452331543
Validation loss: 2.7448203922599874

Epoch: 6| Step: 8
Training loss: 2.1465554237365723
Validation loss: 2.7428968798729683

Epoch: 6| Step: 9
Training loss: 3.2438759803771973
Validation loss: 2.7432104131226898

Epoch: 6| Step: 10
Training loss: 2.9883835315704346
Validation loss: 2.7435697970851773

Epoch: 6| Step: 11
Training loss: 3.3315157890319824
Validation loss: 2.748328229432465

Epoch: 6| Step: 12
Training loss: 2.8944644927978516
Validation loss: 2.749860732786117

Epoch: 6| Step: 13
Training loss: 2.7481369972229004
Validation loss: 2.745176505017024

Epoch: 18| Step: 0
Training loss: 3.8220887184143066
Validation loss: 2.7395925265486523

Epoch: 6| Step: 1
Training loss: 3.146529197692871
Validation loss: 2.740691948962468

Epoch: 6| Step: 2
Training loss: 2.4081664085388184
Validation loss: 2.7413186514249412

Epoch: 6| Step: 3
Training loss: 2.9738707542419434
Validation loss: 2.7464684978608163

Epoch: 6| Step: 4
Training loss: 3.2220218181610107
Validation loss: 2.740840568337389

Epoch: 6| Step: 5
Training loss: 2.2559099197387695
Validation loss: 2.737400572787049

Epoch: 6| Step: 6
Training loss: 3.495433807373047
Validation loss: 2.735645824863065

Epoch: 6| Step: 7
Training loss: 2.1329379081726074
Validation loss: 2.73619677687204

Epoch: 6| Step: 8
Training loss: 2.656604766845703
Validation loss: 2.7339006572641353

Epoch: 6| Step: 9
Training loss: 2.812356472015381
Validation loss: 2.740165202848373

Epoch: 6| Step: 10
Training loss: 2.7683982849121094
Validation loss: 2.7517185954637426

Epoch: 6| Step: 11
Training loss: 2.6296653747558594
Validation loss: 2.7510733373703493

Epoch: 6| Step: 12
Training loss: 3.623678207397461
Validation loss: 2.734975989146899

Epoch: 6| Step: 13
Training loss: 2.235712766647339
Validation loss: 2.730806489144602

Epoch: 19| Step: 0
Training loss: 2.5568010807037354
Validation loss: 2.727721566795021

Epoch: 6| Step: 1
Training loss: 3.055980682373047
Validation loss: 2.727774658510762

Epoch: 6| Step: 2
Training loss: 2.974743366241455
Validation loss: 2.727318840642129

Epoch: 6| Step: 3
Training loss: 2.783130645751953
Validation loss: 2.7266894873752388

Epoch: 6| Step: 4
Training loss: 2.243574857711792
Validation loss: 2.7279492988381335

Epoch: 6| Step: 5
Training loss: 2.8332529067993164
Validation loss: 2.7271660040783625

Epoch: 6| Step: 6
Training loss: 2.9620487689971924
Validation loss: 2.7264924792833227

Epoch: 6| Step: 7
Training loss: 3.504443645477295
Validation loss: 2.7235469664296796

Epoch: 6| Step: 8
Training loss: 3.675841808319092
Validation loss: 2.722802864607944

Epoch: 6| Step: 9
Training loss: 2.9145326614379883
Validation loss: 2.7230921445354337

Epoch: 6| Step: 10
Training loss: 2.415626049041748
Validation loss: 2.7258322136376494

Epoch: 6| Step: 11
Training loss: 2.8902668952941895
Validation loss: 2.7276321739278813

Epoch: 6| Step: 12
Training loss: 2.9542617797851562
Validation loss: 2.7303088377880793

Epoch: 6| Step: 13
Training loss: 2.312272071838379
Validation loss: 2.7207877764137844

Epoch: 20| Step: 0
Training loss: 3.273667812347412
Validation loss: 2.715926875350296

Epoch: 6| Step: 1
Training loss: 2.536001205444336
Validation loss: 2.7141994609627673

Epoch: 6| Step: 2
Training loss: 2.5148167610168457
Validation loss: 2.713766872241933

Epoch: 6| Step: 3
Training loss: 2.441793441772461
Validation loss: 2.712922711526194

Epoch: 6| Step: 4
Training loss: 3.1814305782318115
Validation loss: 2.7146244638709613

Epoch: 6| Step: 5
Training loss: 3.505643367767334
Validation loss: 2.717200945782405

Epoch: 6| Step: 6
Training loss: 3.3763489723205566
Validation loss: 2.7146373897470455

Epoch: 6| Step: 7
Training loss: 2.5998449325561523
Validation loss: 2.712870764475997

Epoch: 6| Step: 8
Training loss: 2.854189872741699
Validation loss: 2.7083496842333066

Epoch: 6| Step: 9
Training loss: 3.0183842182159424
Validation loss: 2.7120637483494257

Epoch: 6| Step: 10
Training loss: 2.6861765384674072
Validation loss: 2.7122356763450046

Epoch: 6| Step: 11
Training loss: 2.4920365810394287
Validation loss: 2.7330021114759546

Epoch: 6| Step: 12
Training loss: 3.158536434173584
Validation loss: 2.7807226950122463

Epoch: 6| Step: 13
Training loss: 2.298591136932373
Validation loss: 2.7191882082211074

Epoch: 21| Step: 0
Training loss: 3.5180304050445557
Validation loss: 2.708016680132958

Epoch: 6| Step: 1
Training loss: 3.266167163848877
Validation loss: 2.7081258758421867

Epoch: 6| Step: 2
Training loss: 2.193274974822998
Validation loss: 2.71554055265201

Epoch: 6| Step: 3
Training loss: 2.807802677154541
Validation loss: 2.7338233942626626

Epoch: 6| Step: 4
Training loss: 3.310232400894165
Validation loss: 2.7222201516551356

Epoch: 6| Step: 5
Training loss: 2.7521555423736572
Validation loss: 2.7199316486235587

Epoch: 6| Step: 6
Training loss: 3.126661777496338
Validation loss: 2.7157249937775316

Epoch: 6| Step: 7
Training loss: 2.6380057334899902
Validation loss: 2.707083022722634

Epoch: 6| Step: 8
Training loss: 2.6833181381225586
Validation loss: 2.709745304558867

Epoch: 6| Step: 9
Training loss: 2.5001449584960938
Validation loss: 2.712326103641141

Epoch: 6| Step: 10
Training loss: 2.4873528480529785
Validation loss: 2.7109236383950837

Epoch: 6| Step: 11
Training loss: 2.968592882156372
Validation loss: 2.716056380220639

Epoch: 6| Step: 12
Training loss: 3.346066951751709
Validation loss: 2.7173153123547955

Epoch: 6| Step: 13
Training loss: 2.193166494369507
Validation loss: 2.714437618050524

Epoch: 22| Step: 0
Training loss: 2.854060173034668
Validation loss: 2.7102771394996235

Epoch: 6| Step: 1
Training loss: 3.927999496459961
Validation loss: 2.7064045013919955

Epoch: 6| Step: 2
Training loss: 3.0435190200805664
Validation loss: 2.699411151229694

Epoch: 6| Step: 3
Training loss: 3.316962718963623
Validation loss: 2.7004879520785425

Epoch: 6| Step: 4
Training loss: 2.5566916465759277
Validation loss: 2.697586731244159

Epoch: 6| Step: 5
Training loss: 2.333507537841797
Validation loss: 2.702748547318161

Epoch: 6| Step: 6
Training loss: 2.688784599304199
Validation loss: 2.7067674898332164

Epoch: 6| Step: 7
Training loss: 3.0916309356689453
Validation loss: 2.711879796879266

Epoch: 6| Step: 8
Training loss: 3.154029369354248
Validation loss: 2.701597975146386

Epoch: 6| Step: 9
Training loss: 2.480380058288574
Validation loss: 2.6961618136334162

Epoch: 6| Step: 10
Training loss: 2.435145378112793
Validation loss: 2.6926194801125476

Epoch: 6| Step: 11
Training loss: 2.565843105316162
Validation loss: 2.6941622200832573

Epoch: 6| Step: 12
Training loss: 2.9070796966552734
Validation loss: 2.692040986912225

Epoch: 6| Step: 13
Training loss: 2.4054765701293945
Validation loss: 2.6993774162825717

Epoch: 23| Step: 0
Training loss: 2.6528055667877197
Validation loss: 2.6978436567450084

Epoch: 6| Step: 1
Training loss: 2.0607059001922607
Validation loss: 2.6940091040826615

Epoch: 6| Step: 2
Training loss: 2.7064290046691895
Validation loss: 2.6906588872273765

Epoch: 6| Step: 3
Training loss: 2.6973159313201904
Validation loss: 2.6897549013937674

Epoch: 6| Step: 4
Training loss: 2.6789050102233887
Validation loss: 2.682144857222034

Epoch: 6| Step: 5
Training loss: 2.928034782409668
Validation loss: 2.6830776147944952

Epoch: 6| Step: 6
Training loss: 3.13301420211792
Validation loss: 2.683393745012181

Epoch: 6| Step: 7
Training loss: 3.0703558921813965
Validation loss: 2.6868322818509993

Epoch: 6| Step: 8
Training loss: 3.28700590133667
Validation loss: 2.685644567653697

Epoch: 6| Step: 9
Training loss: 3.1033763885498047
Validation loss: 2.690137550395022

Epoch: 6| Step: 10
Training loss: 3.643362522125244
Validation loss: 2.6821200309261197

Epoch: 6| Step: 11
Training loss: 2.809056282043457
Validation loss: 2.6819033776560137

Epoch: 6| Step: 12
Training loss: 2.381028652191162
Validation loss: 2.6853682456477994

Epoch: 6| Step: 13
Training loss: 2.391162395477295
Validation loss: 2.6852065363237934

Epoch: 24| Step: 0
Training loss: 3.273716449737549
Validation loss: 2.6972087173051733

Epoch: 6| Step: 1
Training loss: 2.2624197006225586
Validation loss: 2.7125149875558834

Epoch: 6| Step: 2
Training loss: 3.876671552658081
Validation loss: 2.6803686900805404

Epoch: 6| Step: 3
Training loss: 1.720154047012329
Validation loss: 2.6751825424932663

Epoch: 6| Step: 4
Training loss: 3.2314376831054688
Validation loss: 2.673059614755774

Epoch: 6| Step: 5
Training loss: 3.262941360473633
Validation loss: 2.67916049111274

Epoch: 6| Step: 6
Training loss: 2.868119716644287
Validation loss: 2.697444538916311

Epoch: 6| Step: 7
Training loss: 3.1546132564544678
Validation loss: 2.775384282553068

Epoch: 6| Step: 8
Training loss: 3.115311861038208
Validation loss: 2.9990768432617188

Epoch: 6| Step: 9
Training loss: 3.049834966659546
Validation loss: 2.9531571865081787

Epoch: 6| Step: 10
Training loss: 2.2146124839782715
Validation loss: 2.832333705758536

Epoch: 6| Step: 11
Training loss: 2.4106056690216064
Validation loss: 2.7837976460815756

Epoch: 6| Step: 12
Training loss: 3.1068925857543945
Validation loss: 2.7657385718437935

Epoch: 6| Step: 13
Training loss: 2.415217161178589
Validation loss: 2.7699774413980465

Epoch: 25| Step: 0
Training loss: 2.711622476577759
Validation loss: 2.8364802919408327

Epoch: 6| Step: 1
Training loss: 2.8992919921875
Validation loss: 2.851134248959121

Epoch: 6| Step: 2
Training loss: 3.188450813293457
Validation loss: 2.76449175547528

Epoch: 6| Step: 3
Training loss: 3.2044119834899902
Validation loss: 2.7416603001215125

Epoch: 6| Step: 4
Training loss: 3.114306926727295
Validation loss: 2.761166149570096

Epoch: 6| Step: 5
Training loss: 2.8274435997009277
Validation loss: 2.794151217706742

Epoch: 6| Step: 6
Training loss: 2.5473690032958984
Validation loss: 2.8947028216495307

Epoch: 6| Step: 7
Training loss: 2.775106191635132
Validation loss: 2.923717939725486

Epoch: 6| Step: 8
Training loss: 2.978515386581421
Validation loss: 2.913165997433406

Epoch: 6| Step: 9
Training loss: 3.6958792209625244
Validation loss: 2.8604035018592753

Epoch: 6| Step: 10
Training loss: 2.790010690689087
Validation loss: 2.791346570496918

Epoch: 6| Step: 11
Training loss: 3.144547939300537
Validation loss: 2.7636056664169475

Epoch: 6| Step: 12
Training loss: 2.0335946083068848
Validation loss: 2.7354787472755677

Epoch: 6| Step: 13
Training loss: 3.0148866176605225
Validation loss: 2.7765131740159887

Epoch: 26| Step: 0
Training loss: 3.0280978679656982
Validation loss: 2.790407939623761

Epoch: 6| Step: 1
Training loss: 2.2803118228912354
Validation loss: 2.7962554603494625

Epoch: 6| Step: 2
Training loss: 4.11752462387085
Validation loss: 2.7846373819535777

Epoch: 6| Step: 3
Training loss: 3.690176010131836
Validation loss: 2.777906599865165

Epoch: 6| Step: 4
Training loss: 3.1374013423919678
Validation loss: 2.7684333785887687

Epoch: 6| Step: 5
Training loss: 2.7083582878112793
Validation loss: 2.7598869159657466

Epoch: 6| Step: 6
Training loss: 2.353193998336792
Validation loss: 2.732998771052207

Epoch: 6| Step: 7
Training loss: 2.305762767791748
Validation loss: 2.7155058922306186

Epoch: 6| Step: 8
Training loss: 3.3702425956726074
Validation loss: 2.7086185665540796

Epoch: 6| Step: 9
Training loss: 2.79559326171875
Validation loss: 2.7031942670063307

Epoch: 6| Step: 10
Training loss: 2.038200616836548
Validation loss: 2.709735006414434

Epoch: 6| Step: 11
Training loss: 2.951862335205078
Validation loss: 2.7143135352801253

Epoch: 6| Step: 12
Training loss: 2.960463523864746
Validation loss: 2.723452245035479

Epoch: 6| Step: 13
Training loss: 2.24078106880188
Validation loss: 2.717253433760776

Epoch: 27| Step: 0
Training loss: 2.258209228515625
Validation loss: 2.7013879642691663

Epoch: 6| Step: 1
Training loss: 2.103583812713623
Validation loss: 2.691542717718309

Epoch: 6| Step: 2
Training loss: 3.5663228034973145
Validation loss: 2.6869269212086997

Epoch: 6| Step: 3
Training loss: 3.5481815338134766
Validation loss: 2.6920848584944204

Epoch: 6| Step: 4
Training loss: 2.7406606674194336
Validation loss: 2.6967322928931123

Epoch: 6| Step: 5
Training loss: 2.8140108585357666
Validation loss: 2.7099660750358336

Epoch: 6| Step: 6
Training loss: 3.281209707260132
Validation loss: 2.719354521843695

Epoch: 6| Step: 7
Training loss: 1.7156952619552612
Validation loss: 2.7177139251462874

Epoch: 6| Step: 8
Training loss: 3.7153518199920654
Validation loss: 2.716544125669746

Epoch: 6| Step: 9
Training loss: 2.9889543056488037
Validation loss: 2.7004607544150403

Epoch: 6| Step: 10
Training loss: 2.9868245124816895
Validation loss: 2.690418158808062

Epoch: 6| Step: 11
Training loss: 2.7184064388275146
Validation loss: 2.6829918430697535

Epoch: 6| Step: 12
Training loss: 2.4607319831848145
Validation loss: 2.682696070722354

Epoch: 6| Step: 13
Training loss: 3.0226149559020996
Validation loss: 2.6785062692498647

Epoch: 28| Step: 0
Training loss: 3.0125248432159424
Validation loss: 2.6758571491446546

Epoch: 6| Step: 1
Training loss: 3.8687257766723633
Validation loss: 2.671647543548256

Epoch: 6| Step: 2
Training loss: 2.816039562225342
Validation loss: 2.670518744376398

Epoch: 6| Step: 3
Training loss: 3.1724703311920166
Validation loss: 2.6668551378352667

Epoch: 6| Step: 4
Training loss: 2.669590473175049
Validation loss: 2.668697816069408

Epoch: 6| Step: 5
Training loss: 2.916862964630127
Validation loss: 2.668459535926901

Epoch: 6| Step: 6
Training loss: 3.4827353954315186
Validation loss: 2.6725384189236547

Epoch: 6| Step: 7
Training loss: 2.823451042175293
Validation loss: 2.679852221601753

Epoch: 6| Step: 8
Training loss: 1.792327642440796
Validation loss: 2.6782073564426874

Epoch: 6| Step: 9
Training loss: 2.938803195953369
Validation loss: 2.6672118504842124

Epoch: 6| Step: 10
Training loss: 2.0535526275634766
Validation loss: 2.6618789601069626

Epoch: 6| Step: 11
Training loss: 2.3862056732177734
Validation loss: 2.6509586175282798

Epoch: 6| Step: 12
Training loss: 2.3604323863983154
Validation loss: 2.6468933500269407

Epoch: 6| Step: 13
Training loss: 3.506986379623413
Validation loss: 2.6461032385467202

Epoch: 29| Step: 0
Training loss: 2.64166259765625
Validation loss: 2.6452542274228987

Epoch: 6| Step: 1
Training loss: 2.4598023891448975
Validation loss: 2.6489801022314254

Epoch: 6| Step: 2
Training loss: 3.4754183292388916
Validation loss: 2.6492149265863563

Epoch: 6| Step: 3
Training loss: 2.080409526824951
Validation loss: 2.648964984442598

Epoch: 6| Step: 4
Training loss: 3.2269115447998047
Validation loss: 2.6312202151103685

Epoch: 6| Step: 5
Training loss: 3.406101942062378
Validation loss: 2.6253707831905735

Epoch: 6| Step: 6
Training loss: 3.0895228385925293
Validation loss: 2.617732278762325

Epoch: 6| Step: 7
Training loss: 2.3199715614318848
Validation loss: 2.616865914355042

Epoch: 6| Step: 8
Training loss: 2.3754429817199707
Validation loss: 2.613239683130736

Epoch: 6| Step: 9
Training loss: 1.813543438911438
Validation loss: 2.6084085202986196

Epoch: 6| Step: 10
Training loss: 3.7824931144714355
Validation loss: 2.6039237078799995

Epoch: 6| Step: 11
Training loss: 2.8938446044921875
Validation loss: 2.602148499540103

Epoch: 6| Step: 12
Training loss: 3.084516763687134
Validation loss: 2.6024370603663947

Epoch: 6| Step: 13
Training loss: 2.2379720211029053
Validation loss: 2.6012495307512182

Epoch: 30| Step: 0
Training loss: 2.6229279041290283
Validation loss: 2.601598713987617

Epoch: 6| Step: 1
Training loss: 3.1737871170043945
Validation loss: 2.603312741043747

Epoch: 6| Step: 2
Training loss: 2.5932509899139404
Validation loss: 2.604041555876373

Epoch: 6| Step: 3
Training loss: 3.310530185699463
Validation loss: 2.604785721789124

Epoch: 6| Step: 4
Training loss: 3.1936161518096924
Validation loss: 2.602792888559321

Epoch: 6| Step: 5
Training loss: 1.6458796262741089
Validation loss: 2.600598176320394

Epoch: 6| Step: 6
Training loss: 2.851132392883301
Validation loss: 2.6038514773050943

Epoch: 6| Step: 7
Training loss: 3.1191177368164062
Validation loss: 2.5989076706670944

Epoch: 6| Step: 8
Training loss: 2.764051914215088
Validation loss: 2.5982163029332317

Epoch: 6| Step: 9
Training loss: 3.006490707397461
Validation loss: 2.598520276367023

Epoch: 6| Step: 10
Training loss: 2.6067190170288086
Validation loss: 2.597167812367921

Epoch: 6| Step: 11
Training loss: 2.9627578258514404
Validation loss: 2.595312682531213

Epoch: 6| Step: 12
Training loss: 2.212130069732666
Validation loss: 2.594417219520897

Epoch: 6| Step: 13
Training loss: 2.870220184326172
Validation loss: 2.596296771880119

Epoch: 31| Step: 0
Training loss: 2.0515494346618652
Validation loss: 2.607723564229986

Epoch: 6| Step: 1
Training loss: 3.5203986167907715
Validation loss: 2.6180831360560592

Epoch: 6| Step: 2
Training loss: 2.7070953845977783
Validation loss: 2.620526962382819

Epoch: 6| Step: 3
Training loss: 2.997455358505249
Validation loss: 2.6090990163946666

Epoch: 6| Step: 4
Training loss: 3.820735454559326
Validation loss: 2.5959242082411245

Epoch: 6| Step: 5
Training loss: 2.4420831203460693
Validation loss: 2.583570098364225

Epoch: 6| Step: 6
Training loss: 2.270782947540283
Validation loss: 2.585937697400329

Epoch: 6| Step: 7
Training loss: 2.210690498352051
Validation loss: 2.5854143942556074

Epoch: 6| Step: 8
Training loss: 2.407438278198242
Validation loss: 2.5835091221717095

Epoch: 6| Step: 9
Training loss: 2.3052964210510254
Validation loss: 2.581802814237533

Epoch: 6| Step: 10
Training loss: 2.93561053276062
Validation loss: 2.584644430427141

Epoch: 6| Step: 11
Training loss: 3.1515560150146484
Validation loss: 2.5955223191169

Epoch: 6| Step: 12
Training loss: 3.165658712387085
Validation loss: 2.5954820263770317

Epoch: 6| Step: 13
Training loss: 2.7254648208618164
Validation loss: 2.6041301065875637

Epoch: 32| Step: 0
Training loss: 2.794454336166382
Validation loss: 2.609771118369154

Epoch: 6| Step: 1
Training loss: 1.7512860298156738
Validation loss: 2.6321543621760544

Epoch: 6| Step: 2
Training loss: 3.0588271617889404
Validation loss: 2.6498955398477535

Epoch: 6| Step: 3
Training loss: 3.4452221393585205
Validation loss: 2.6502355426870365

Epoch: 6| Step: 4
Training loss: 2.3360304832458496
Validation loss: 2.622840853147609

Epoch: 6| Step: 5
Training loss: 2.5333049297332764
Validation loss: 2.6041358619607906

Epoch: 6| Step: 6
Training loss: 3.1475751399993896
Validation loss: 2.5845058810326362

Epoch: 6| Step: 7
Training loss: 2.5727720260620117
Validation loss: 2.5978637613276

Epoch: 6| Step: 8
Training loss: 2.455301284790039
Validation loss: 2.6589214340333016

Epoch: 6| Step: 9
Training loss: 3.1372814178466797
Validation loss: 2.7444956123187976

Epoch: 6| Step: 10
Training loss: 3.144620895385742
Validation loss: 2.7368626030542518

Epoch: 6| Step: 11
Training loss: 3.3656787872314453
Validation loss: 2.5939840834627867

Epoch: 6| Step: 12
Training loss: 2.6923768520355225
Validation loss: 2.5763202251926547

Epoch: 6| Step: 13
Training loss: 3.0381805896759033
Validation loss: 2.612666599212154

Epoch: 33| Step: 0
Training loss: 3.539825916290283
Validation loss: 2.7081328617629183

Epoch: 6| Step: 1
Training loss: 2.556687116622925
Validation loss: 2.7541890785258305

Epoch: 6| Step: 2
Training loss: 2.756026268005371
Validation loss: 2.755570291191019

Epoch: 6| Step: 3
Training loss: 3.2875096797943115
Validation loss: 2.755545372604042

Epoch: 6| Step: 4
Training loss: 3.004581928253174
Validation loss: 2.7049486867843138

Epoch: 6| Step: 5
Training loss: 2.2570300102233887
Validation loss: 2.653060215775685

Epoch: 6| Step: 6
Training loss: 2.2597339153289795
Validation loss: 2.611033049962854

Epoch: 6| Step: 7
Training loss: 3.165097236633301
Validation loss: 2.601593017578125

Epoch: 6| Step: 8
Training loss: 3.068617105484009
Validation loss: 2.5917590177187355

Epoch: 6| Step: 9
Training loss: 2.5775208473205566
Validation loss: 2.5920976105556695

Epoch: 6| Step: 10
Training loss: 2.01023530960083
Validation loss: 2.58535522542974

Epoch: 6| Step: 11
Training loss: 2.7336435317993164
Validation loss: 2.5728974649983067

Epoch: 6| Step: 12
Training loss: 2.568107843399048
Validation loss: 2.5706366415946715

Epoch: 6| Step: 13
Training loss: 3.8960330486297607
Validation loss: 2.5672834919344996

Epoch: 34| Step: 0
Training loss: 2.601855754852295
Validation loss: 2.5650343920594905

Epoch: 6| Step: 1
Training loss: 3.0258383750915527
Validation loss: 2.557880324702109

Epoch: 6| Step: 2
Training loss: 2.21217942237854
Validation loss: 2.5564514385756625

Epoch: 6| Step: 3
Training loss: 2.755857467651367
Validation loss: 2.5593521774456067

Epoch: 6| Step: 4
Training loss: 2.543689727783203
Validation loss: 2.5736156330313733

Epoch: 6| Step: 5
Training loss: 2.875706672668457
Validation loss: 2.583058208547613

Epoch: 6| Step: 6
Training loss: 2.949768304824829
Validation loss: 2.5821827585979173

Epoch: 6| Step: 7
Training loss: 3.0987560749053955
Validation loss: 2.5787560657788346

Epoch: 6| Step: 8
Training loss: 3.5363008975982666
Validation loss: 2.577718222013084

Epoch: 6| Step: 9
Training loss: 2.9079647064208984
Validation loss: 2.56668617135735

Epoch: 6| Step: 10
Training loss: 2.2837252616882324
Validation loss: 2.565653949655512

Epoch: 6| Step: 11
Training loss: 3.198049306869507
Validation loss: 2.5669718506515666

Epoch: 6| Step: 12
Training loss: 2.464160680770874
Validation loss: 2.557000372999458

Epoch: 6| Step: 13
Training loss: 1.5404359102249146
Validation loss: 2.5505393576878372

Epoch: 35| Step: 0
Training loss: 3.033945083618164
Validation loss: 2.5483477884723293

Epoch: 6| Step: 1
Training loss: 2.2244315147399902
Validation loss: 2.5488109024622108

Epoch: 6| Step: 2
Training loss: 2.795029401779175
Validation loss: 2.5484192525186846

Epoch: 6| Step: 3
Training loss: 3.257833480834961
Validation loss: 2.549118644447737

Epoch: 6| Step: 4
Training loss: 2.721226930618286
Validation loss: 2.5493196928372948

Epoch: 6| Step: 5
Training loss: 2.6004862785339355
Validation loss: 2.5457834505265757

Epoch: 6| Step: 6
Training loss: 2.8156890869140625
Validation loss: 2.543529959135158

Epoch: 6| Step: 7
Training loss: 2.4903616905212402
Validation loss: 2.5444865201109197

Epoch: 6| Step: 8
Training loss: 2.155604600906372
Validation loss: 2.5429676937800583

Epoch: 6| Step: 9
Training loss: 2.775017261505127
Validation loss: 2.5409965463863906

Epoch: 6| Step: 10
Training loss: 3.032712459564209
Validation loss: 2.5466468231652373

Epoch: 6| Step: 11
Training loss: 2.4371557235717773
Validation loss: 2.5552341527836298

Epoch: 6| Step: 12
Training loss: 3.319464683532715
Validation loss: 2.5426505791243685

Epoch: 6| Step: 13
Training loss: 2.675001859664917
Validation loss: 2.5406245031664447

Epoch: 36| Step: 0
Training loss: 2.6739702224731445
Validation loss: 2.5435191815899265

Epoch: 6| Step: 1
Training loss: 3.156738042831421
Validation loss: 2.546968639537852

Epoch: 6| Step: 2
Training loss: 2.968168258666992
Validation loss: 2.5506834060915056

Epoch: 6| Step: 3
Training loss: 2.3830134868621826
Validation loss: 2.556232529301797

Epoch: 6| Step: 4
Training loss: 2.9714114665985107
Validation loss: 2.5542009081891788

Epoch: 6| Step: 5
Training loss: 2.795987844467163
Validation loss: 2.5528920927355365

Epoch: 6| Step: 6
Training loss: 2.7708256244659424
Validation loss: 2.5465305133532454

Epoch: 6| Step: 7
Training loss: 1.9764783382415771
Validation loss: 2.539132877062726

Epoch: 6| Step: 8
Training loss: 3.1645755767822266
Validation loss: 2.5383615929593324

Epoch: 6| Step: 9
Training loss: 2.6804370880126953
Validation loss: 2.544462732089463

Epoch: 6| Step: 10
Training loss: 3.2501602172851562
Validation loss: 2.549611276195895

Epoch: 6| Step: 11
Training loss: 1.7596951723098755
Validation loss: 2.5550361935810377

Epoch: 6| Step: 12
Training loss: 3.630807876586914
Validation loss: 2.557481073564099

Epoch: 6| Step: 13
Training loss: 1.5490140914916992
Validation loss: 2.5584924682494132

Epoch: 37| Step: 0
Training loss: 2.79788875579834
Validation loss: 2.566784679248769

Epoch: 6| Step: 1
Training loss: 3.5726218223571777
Validation loss: 2.582013209660848

Epoch: 6| Step: 2
Training loss: 2.062021255493164
Validation loss: 2.5833789020456295

Epoch: 6| Step: 3
Training loss: 2.5942606925964355
Validation loss: 2.582856209047379

Epoch: 6| Step: 4
Training loss: 2.3965961933135986
Validation loss: 2.576615092574909

Epoch: 6| Step: 5
Training loss: 2.5752923488616943
Validation loss: 2.541406495596773

Epoch: 6| Step: 6
Training loss: 3.1844749450683594
Validation loss: 2.5291441922546714

Epoch: 6| Step: 7
Training loss: 3.2829785346984863
Validation loss: 2.524443849440544

Epoch: 6| Step: 8
Training loss: 2.144573450088501
Validation loss: 2.5335684053359495

Epoch: 6| Step: 9
Training loss: 3.765091896057129
Validation loss: 2.5393528656292985

Epoch: 6| Step: 10
Training loss: 1.8867688179016113
Validation loss: 2.5455833763204594

Epoch: 6| Step: 11
Training loss: 2.6227869987487793
Validation loss: 2.5492616109950568

Epoch: 6| Step: 12
Training loss: 2.7372970581054688
Validation loss: 2.5407397952131046

Epoch: 6| Step: 13
Training loss: 2.632098436355591
Validation loss: 2.5410545795194563

Epoch: 38| Step: 0
Training loss: 2.560884475708008
Validation loss: 2.537013587131295

Epoch: 6| Step: 1
Training loss: 2.428619623184204
Validation loss: 2.5327685007485012

Epoch: 6| Step: 2
Training loss: 2.64190936088562
Validation loss: 2.5303165117899575

Epoch: 6| Step: 3
Training loss: 1.9878286123275757
Validation loss: 2.5285101500890588

Epoch: 6| Step: 4
Training loss: 3.0455241203308105
Validation loss: 2.519702216630341

Epoch: 6| Step: 5
Training loss: 2.793576955795288
Validation loss: 2.52158284700045

Epoch: 6| Step: 6
Training loss: 2.4916913509368896
Validation loss: 2.521079642798311

Epoch: 6| Step: 7
Training loss: 2.924889087677002
Validation loss: 2.5285587259518203

Epoch: 6| Step: 8
Training loss: 2.748687744140625
Validation loss: 2.538292146498157

Epoch: 6| Step: 9
Training loss: 3.3226890563964844
Validation loss: 2.586275500635947

Epoch: 6| Step: 10
Training loss: 3.4905927181243896
Validation loss: 2.59587098193425

Epoch: 6| Step: 11
Training loss: 2.601301431655884
Validation loss: 2.601155791231381

Epoch: 6| Step: 12
Training loss: 2.634526252746582
Validation loss: 2.59468481104861

Epoch: 6| Step: 13
Training loss: 2.5609800815582275
Validation loss: 2.557253081311462

Epoch: 39| Step: 0
Training loss: 3.3511390686035156
Validation loss: 2.527975913017027

Epoch: 6| Step: 1
Training loss: 2.793020009994507
Validation loss: 2.5149238007042998

Epoch: 6| Step: 2
Training loss: 2.6738877296447754
Validation loss: 2.5123259764845653

Epoch: 6| Step: 3
Training loss: 2.388667345046997
Validation loss: 2.521339072976061

Epoch: 6| Step: 4
Training loss: 2.602351188659668
Validation loss: 2.5251111932980117

Epoch: 6| Step: 5
Training loss: 2.9008374214172363
Validation loss: 2.529456592375232

Epoch: 6| Step: 6
Training loss: 2.016423225402832
Validation loss: 2.5284498840249996

Epoch: 6| Step: 7
Training loss: 2.681428909301758
Validation loss: 2.5300968206056984

Epoch: 6| Step: 8
Training loss: 3.1319005489349365
Validation loss: 2.5262592146473546

Epoch: 6| Step: 9
Training loss: 2.7862389087677
Validation loss: 2.524046903015465

Epoch: 6| Step: 10
Training loss: 2.3947086334228516
Validation loss: 2.5222925422012166

Epoch: 6| Step: 11
Training loss: 2.76175594329834
Validation loss: 2.517385446897117

Epoch: 6| Step: 12
Training loss: 2.400120735168457
Validation loss: 2.5128712525931736

Epoch: 6| Step: 13
Training loss: 3.8622026443481445
Validation loss: 2.5107046391374324

Epoch: 40| Step: 0
Training loss: 3.2719438076019287
Validation loss: 2.508463095593196

Epoch: 6| Step: 1
Training loss: 3.685800075531006
Validation loss: 2.510451868016233

Epoch: 6| Step: 2
Training loss: 2.571056604385376
Validation loss: 2.5123225770970827

Epoch: 6| Step: 3
Training loss: 1.9431495666503906
Validation loss: 2.51563121170126

Epoch: 6| Step: 4
Training loss: 2.612248659133911
Validation loss: 2.512096066628733

Epoch: 6| Step: 5
Training loss: 2.184995651245117
Validation loss: 2.5080781828972603

Epoch: 6| Step: 6
Training loss: 3.41379976272583
Validation loss: 2.5060560036731023

Epoch: 6| Step: 7
Training loss: 2.308866024017334
Validation loss: 2.5053898954904206

Epoch: 6| Step: 8
Training loss: 2.9675753116607666
Validation loss: 2.5073499833383868

Epoch: 6| Step: 9
Training loss: 2.5071592330932617
Validation loss: 2.5050258585201797

Epoch: 6| Step: 10
Training loss: 2.3423004150390625
Validation loss: 2.502603195046866

Epoch: 6| Step: 11
Training loss: 3.210055351257324
Validation loss: 2.504223841492848

Epoch: 6| Step: 12
Training loss: 2.500516414642334
Validation loss: 2.50246597361821

Epoch: 6| Step: 13
Training loss: 2.2821121215820312
Validation loss: 2.502751114547894

Epoch: 41| Step: 0
Training loss: 2.826216697692871
Validation loss: 2.5015632619139967

Epoch: 6| Step: 1
Training loss: 2.2234268188476562
Validation loss: 2.499365045178321

Epoch: 6| Step: 2
Training loss: 2.3896923065185547
Validation loss: 2.5040832001675843

Epoch: 6| Step: 3
Training loss: 2.6148481369018555
Validation loss: 2.5059705806034867

Epoch: 6| Step: 4
Training loss: 2.3128879070281982
Validation loss: 2.5167563910125406

Epoch: 6| Step: 5
Training loss: 2.4593706130981445
Validation loss: 2.5193944156810804

Epoch: 6| Step: 6
Training loss: 3.0786819458007812
Validation loss: 2.521182357624013

Epoch: 6| Step: 7
Training loss: 2.4881591796875
Validation loss: 2.5115151097697597

Epoch: 6| Step: 8
Training loss: 3.4437196254730225
Validation loss: 2.50582730385565

Epoch: 6| Step: 9
Training loss: 2.3385720252990723
Validation loss: 2.502070721759591

Epoch: 6| Step: 10
Training loss: 2.385864496231079
Validation loss: 2.49544100094867

Epoch: 6| Step: 11
Training loss: 3.523176431655884
Validation loss: 2.501264577270836

Epoch: 6| Step: 12
Training loss: 3.3570613861083984
Validation loss: 2.5055845142692648

Epoch: 6| Step: 13
Training loss: 2.2222981452941895
Validation loss: 2.50415204417321

Epoch: 42| Step: 0
Training loss: 2.4617602825164795
Validation loss: 2.5123446551702355

Epoch: 6| Step: 1
Training loss: 2.831730604171753
Validation loss: 2.516169709544028

Epoch: 6| Step: 2
Training loss: 1.859804630279541
Validation loss: 2.526432987182371

Epoch: 6| Step: 3
Training loss: 2.6575331687927246
Validation loss: 2.5657443051697104

Epoch: 6| Step: 4
Training loss: 2.843043565750122
Validation loss: 2.587346358965802

Epoch: 6| Step: 5
Training loss: 2.8945181369781494
Validation loss: 2.5622436667001374

Epoch: 6| Step: 6
Training loss: 2.794614791870117
Validation loss: 2.5127575628219114

Epoch: 6| Step: 7
Training loss: 2.3916563987731934
Validation loss: 2.5034521472069526

Epoch: 6| Step: 8
Training loss: 3.1813859939575195
Validation loss: 2.499124914087275

Epoch: 6| Step: 9
Training loss: 3.557727098464966
Validation loss: 2.4925742508262716

Epoch: 6| Step: 10
Training loss: 2.549138069152832
Validation loss: 2.4883773839601906

Epoch: 6| Step: 11
Training loss: 2.7782907485961914
Validation loss: 2.4897886963300806

Epoch: 6| Step: 12
Training loss: 2.898885726928711
Validation loss: 2.521502697339622

Epoch: 6| Step: 13
Training loss: 2.1619904041290283
Validation loss: 2.5738909039446103

Epoch: 43| Step: 0
Training loss: 2.245551109313965
Validation loss: 2.6333769418859996

Epoch: 6| Step: 1
Training loss: 2.986294746398926
Validation loss: 2.689118331478488

Epoch: 6| Step: 2
Training loss: 3.3224267959594727
Validation loss: 2.6499835034852386

Epoch: 6| Step: 3
Training loss: 2.528989315032959
Validation loss: 2.5710938566474506

Epoch: 6| Step: 4
Training loss: 2.416325092315674
Validation loss: 2.5143260468718824

Epoch: 6| Step: 5
Training loss: 2.3641109466552734
Validation loss: 2.490598181242584

Epoch: 6| Step: 6
Training loss: 2.944455623626709
Validation loss: 2.4899621343099945

Epoch: 6| Step: 7
Training loss: 2.436048984527588
Validation loss: 2.485229871606314

Epoch: 6| Step: 8
Training loss: 2.5199034214019775
Validation loss: 2.4972705200154293

Epoch: 6| Step: 9
Training loss: 2.5509893894195557
Validation loss: 2.5132975527035293

Epoch: 6| Step: 10
Training loss: 2.990135669708252
Validation loss: 2.5208636214656215

Epoch: 6| Step: 11
Training loss: 3.259995460510254
Validation loss: 2.5246333486290387

Epoch: 6| Step: 12
Training loss: 2.6752824783325195
Validation loss: 2.5114941007347515

Epoch: 6| Step: 13
Training loss: 3.040205717086792
Validation loss: 2.5141686137004564

Epoch: 44| Step: 0
Training loss: 2.6307332515716553
Validation loss: 2.5850113438021753

Epoch: 6| Step: 1
Training loss: 3.7445168495178223
Validation loss: 2.6001769881094656

Epoch: 6| Step: 2
Training loss: 3.4230971336364746
Validation loss: 2.5171735055984987

Epoch: 6| Step: 3
Training loss: 2.974031686782837
Validation loss: 2.490541535039102

Epoch: 6| Step: 4
Training loss: 2.8125531673431396
Validation loss: 2.4822560792328208

Epoch: 6| Step: 5
Training loss: 3.234463691711426
Validation loss: 2.487130436846005

Epoch: 6| Step: 6
Training loss: 2.1543405055999756
Validation loss: 2.5022224610851658

Epoch: 6| Step: 7
Training loss: 2.1126272678375244
Validation loss: 2.547716545802291

Epoch: 6| Step: 8
Training loss: 2.4312596321105957
Validation loss: 2.609574717860068

Epoch: 6| Step: 9
Training loss: 2.937567710876465
Validation loss: 2.6551416843168196

Epoch: 6| Step: 10
Training loss: 3.028632164001465
Validation loss: 2.594354917926173

Epoch: 6| Step: 11
Training loss: 2.3266098499298096
Validation loss: 2.550589353807511

Epoch: 6| Step: 12
Training loss: 1.8543381690979004
Validation loss: 2.5105499708524315

Epoch: 6| Step: 13
Training loss: 2.7856836318969727
Validation loss: 2.489030716239765

Epoch: 45| Step: 0
Training loss: 2.9056997299194336
Validation loss: 2.485876685829573

Epoch: 6| Step: 1
Training loss: 2.420290946960449
Validation loss: 2.4870857654079312

Epoch: 6| Step: 2
Training loss: 2.719470977783203
Validation loss: 2.5107767607576106

Epoch: 6| Step: 3
Training loss: 2.857100486755371
Validation loss: 2.4918896203399985

Epoch: 6| Step: 4
Training loss: 1.6806564331054688
Validation loss: 2.491089936225645

Epoch: 6| Step: 5
Training loss: 3.486814498901367
Validation loss: 2.4901120521688975

Epoch: 6| Step: 6
Training loss: 2.953902006149292
Validation loss: 2.4942409940945205

Epoch: 6| Step: 7
Training loss: 2.833967447280884
Validation loss: 2.49409976056827

Epoch: 6| Step: 8
Training loss: 2.716176748275757
Validation loss: 2.495560110256236

Epoch: 6| Step: 9
Training loss: 2.984750747680664
Validation loss: 2.494700353632691

Epoch: 6| Step: 10
Training loss: 2.8368005752563477
Validation loss: 2.4937909367263957

Epoch: 6| Step: 11
Training loss: 2.494509220123291
Validation loss: 2.4930826284552134

Epoch: 6| Step: 12
Training loss: 2.7304134368896484
Validation loss: 2.4899231208268033

Epoch: 6| Step: 13
Training loss: 1.8817729949951172
Validation loss: 2.495524201341855

Epoch: 46| Step: 0
Training loss: 1.7845265865325928
Validation loss: 2.4954831061824674

Epoch: 6| Step: 1
Training loss: 2.103891372680664
Validation loss: 2.497713306898712

Epoch: 6| Step: 2
Training loss: 2.6603782176971436
Validation loss: 2.4971947362346034

Epoch: 6| Step: 3
Training loss: 3.2225377559661865
Validation loss: 2.4941224898061445

Epoch: 6| Step: 4
Training loss: 2.7629151344299316
Validation loss: 2.4935603859604045

Epoch: 6| Step: 5
Training loss: 2.3649849891662598
Validation loss: 2.4872459519294

Epoch: 6| Step: 6
Training loss: 2.942577362060547
Validation loss: 2.4810911737462527

Epoch: 6| Step: 7
Training loss: 2.5848402976989746
Validation loss: 2.473904735298567

Epoch: 6| Step: 8
Training loss: 2.6483795642852783
Validation loss: 2.4708708024794057

Epoch: 6| Step: 9
Training loss: 3.666748046875
Validation loss: 2.4701779939795054

Epoch: 6| Step: 10
Training loss: 2.383134603500366
Validation loss: 2.468185055640436

Epoch: 6| Step: 11
Training loss: 2.3220596313476562
Validation loss: 2.4683434553043817

Epoch: 6| Step: 12
Training loss: 2.7288289070129395
Validation loss: 2.4682016372680664

Epoch: 6| Step: 13
Training loss: 3.928290367126465
Validation loss: 2.466679632022817

Epoch: 47| Step: 0
Training loss: 2.9597127437591553
Validation loss: 2.46973983446757

Epoch: 6| Step: 1
Training loss: 3.084615468978882
Validation loss: 2.4765191308913694

Epoch: 6| Step: 2
Training loss: 3.0301198959350586
Validation loss: 2.492142100487986

Epoch: 6| Step: 3
Training loss: 3.185556650161743
Validation loss: 2.497208672185098

Epoch: 6| Step: 4
Training loss: 2.6470539569854736
Validation loss: 2.499223724488289

Epoch: 6| Step: 5
Training loss: 2.3408737182617188
Validation loss: 2.4969242747111986

Epoch: 6| Step: 6
Training loss: 2.5329771041870117
Validation loss: 2.4886706465034076

Epoch: 6| Step: 7
Training loss: 2.469440221786499
Validation loss: 2.474191588740195

Epoch: 6| Step: 8
Training loss: 2.7148842811584473
Validation loss: 2.4633411656143847

Epoch: 6| Step: 9
Training loss: 1.8229873180389404
Validation loss: 2.461134515782838

Epoch: 6| Step: 10
Training loss: 2.5477561950683594
Validation loss: 2.460004145099271

Epoch: 6| Step: 11
Training loss: 2.992467164993286
Validation loss: 2.4601892091894664

Epoch: 6| Step: 12
Training loss: 2.502139091491699
Validation loss: 2.4574883163616223

Epoch: 6| Step: 13
Training loss: 2.6872591972351074
Validation loss: 2.4545185207038798

Epoch: 48| Step: 0
Training loss: 1.6271405220031738
Validation loss: 2.4601591248666086

Epoch: 6| Step: 1
Training loss: 2.7614083290100098
Validation loss: 2.4598904732734925

Epoch: 6| Step: 2
Training loss: 2.0778145790100098
Validation loss: 2.457279805214174

Epoch: 6| Step: 3
Training loss: 2.218855857849121
Validation loss: 2.4616113106409707

Epoch: 6| Step: 4
Training loss: 3.12716007232666
Validation loss: 2.465404518188969

Epoch: 6| Step: 5
Training loss: 3.7280054092407227
Validation loss: 2.460822284862559

Epoch: 6| Step: 6
Training loss: 2.0159223079681396
Validation loss: 2.4590235474289104

Epoch: 6| Step: 7
Training loss: 3.731700897216797
Validation loss: 2.4586199124654136

Epoch: 6| Step: 8
Training loss: 2.1997525691986084
Validation loss: 2.4600184399594545

Epoch: 6| Step: 9
Training loss: 3.030768871307373
Validation loss: 2.46233642742198

Epoch: 6| Step: 10
Training loss: 3.3107643127441406
Validation loss: 2.4586136033458095

Epoch: 6| Step: 11
Training loss: 2.243483066558838
Validation loss: 2.4684592934064966

Epoch: 6| Step: 12
Training loss: 2.916325569152832
Validation loss: 2.459232653340986

Epoch: 6| Step: 13
Training loss: 2.1859004497528076
Validation loss: 2.459755318139189

Epoch: 49| Step: 0
Training loss: 2.719012498855591
Validation loss: 2.4437503122514292

Epoch: 6| Step: 1
Training loss: 2.7039644718170166
Validation loss: 2.436895760156775

Epoch: 6| Step: 2
Training loss: 3.198651075363159
Validation loss: 2.445704916472076

Epoch: 6| Step: 3
Training loss: 2.410114288330078
Validation loss: 2.451996403355752

Epoch: 6| Step: 4
Training loss: 2.7694122791290283
Validation loss: 2.4542810942537043

Epoch: 6| Step: 5
Training loss: 2.357835531234741
Validation loss: 2.445539674451274

Epoch: 6| Step: 6
Training loss: 2.7554731369018555
Validation loss: 2.43652146093307

Epoch: 6| Step: 7
Training loss: 2.8196451663970947
Validation loss: 2.43547131681955

Epoch: 6| Step: 8
Training loss: 2.665379524230957
Validation loss: 2.4352552275503836

Epoch: 6| Step: 9
Training loss: 2.496244430541992
Validation loss: 2.446060085809359

Epoch: 6| Step: 10
Training loss: 2.8106305599212646
Validation loss: 2.46296646518092

Epoch: 6| Step: 11
Training loss: 2.6165013313293457
Validation loss: 2.5103660911642094

Epoch: 6| Step: 12
Training loss: 2.8737268447875977
Validation loss: 2.5606674968555407

Epoch: 6| Step: 13
Training loss: 1.9729260206222534
Validation loss: 2.602166252751504

Epoch: 50| Step: 0
Training loss: 2.9132044315338135
Validation loss: 2.617148548044184

Epoch: 6| Step: 1
Training loss: 2.039950370788574
Validation loss: 2.6123716395388366

Epoch: 6| Step: 2
Training loss: 3.0234360694885254
Validation loss: 2.6003883218252533

Epoch: 6| Step: 3
Training loss: 2.999089002609253
Validation loss: 2.5548536636496104

Epoch: 6| Step: 4
Training loss: 2.4249775409698486
Validation loss: 2.516264566811182

Epoch: 6| Step: 5
Training loss: 2.8256683349609375
Validation loss: 2.4476238425059984

Epoch: 6| Step: 6
Training loss: 3.6099750995635986
Validation loss: 2.4271583095673592

Epoch: 6| Step: 7
Training loss: 2.482135057449341
Validation loss: 2.424575203208513

Epoch: 6| Step: 8
Training loss: 2.3039751052856445
Validation loss: 2.4296843800493466

Epoch: 6| Step: 9
Training loss: 2.5535106658935547
Validation loss: 2.4640409895168838

Epoch: 6| Step: 10
Training loss: 2.914626121520996
Validation loss: 2.5084862221953688

Epoch: 6| Step: 11
Training loss: 2.0152416229248047
Validation loss: 2.527681686544931

Epoch: 6| Step: 12
Training loss: 1.9514797925949097
Validation loss: 2.51364698461307

Epoch: 6| Step: 13
Training loss: 4.444184303283691
Validation loss: 2.5276081100586922

Epoch: 51| Step: 0
Training loss: 2.9095358848571777
Validation loss: 2.4537873319400254

Epoch: 6| Step: 1
Training loss: 2.303079128265381
Validation loss: 2.4333528113621536

Epoch: 6| Step: 2
Training loss: 3.184953212738037
Validation loss: 2.429719325034849

Epoch: 6| Step: 3
Training loss: 2.5812625885009766
Validation loss: 2.426437190783921

Epoch: 6| Step: 4
Training loss: 2.508175849914551
Validation loss: 2.420137966832807

Epoch: 6| Step: 5
Training loss: 2.61030650138855
Validation loss: 2.4226637194233556

Epoch: 6| Step: 6
Training loss: 2.8610823154449463
Validation loss: 2.429506781280682

Epoch: 6| Step: 7
Training loss: 3.0545849800109863
Validation loss: 2.434636426228349

Epoch: 6| Step: 8
Training loss: 2.5091304779052734
Validation loss: 2.4533465472600793

Epoch: 6| Step: 9
Training loss: 3.6341545581817627
Validation loss: 2.4839748195422593

Epoch: 6| Step: 10
Training loss: 2.213688373565674
Validation loss: 2.482019691057103

Epoch: 6| Step: 11
Training loss: 2.345828056335449
Validation loss: 2.4954237143198648

Epoch: 6| Step: 12
Training loss: 2.6122827529907227
Validation loss: 2.4878697113324235

Epoch: 6| Step: 13
Training loss: 1.3339940309524536
Validation loss: 2.4853081728822444

Epoch: 52| Step: 0
Training loss: 2.346850872039795
Validation loss: 2.449125213007773

Epoch: 6| Step: 1
Training loss: 2.449429512023926
Validation loss: 2.434843212045649

Epoch: 6| Step: 2
Training loss: 2.7823643684387207
Validation loss: 2.4230797957348567

Epoch: 6| Step: 3
Training loss: 2.9148592948913574
Validation loss: 2.4156996191188855

Epoch: 6| Step: 4
Training loss: 2.215378999710083
Validation loss: 2.413311363548361

Epoch: 6| Step: 5
Training loss: 2.0930981636047363
Validation loss: 2.4134239560814312

Epoch: 6| Step: 6
Training loss: 2.956348419189453
Validation loss: 2.412901157973915

Epoch: 6| Step: 7
Training loss: 2.454071044921875
Validation loss: 2.412862003490489

Epoch: 6| Step: 8
Training loss: 2.556161880493164
Validation loss: 2.4101291882094515

Epoch: 6| Step: 9
Training loss: 2.9781956672668457
Validation loss: 2.410284685832198

Epoch: 6| Step: 10
Training loss: 1.9853276014328003
Validation loss: 2.410053413401368

Epoch: 6| Step: 11
Training loss: 3.0316195487976074
Validation loss: 2.4088841022983676

Epoch: 6| Step: 12
Training loss: 3.50875186920166
Validation loss: 2.4129389921824136

Epoch: 6| Step: 13
Training loss: 3.0074307918548584
Validation loss: 2.412632203871204

Epoch: 53| Step: 0
Training loss: 2.708003520965576
Validation loss: 2.4125851482473393

Epoch: 6| Step: 1
Training loss: 3.0218300819396973
Validation loss: 2.417687077676096

Epoch: 6| Step: 2
Training loss: 3.262705087661743
Validation loss: 2.418175128198439

Epoch: 6| Step: 3
Training loss: 2.6862683296203613
Validation loss: 2.420554766090967

Epoch: 6| Step: 4
Training loss: 3.0391931533813477
Validation loss: 2.4133601368114515

Epoch: 6| Step: 5
Training loss: 2.288771629333496
Validation loss: 2.4115830826502975

Epoch: 6| Step: 6
Training loss: 1.86866295337677
Validation loss: 2.4054635237622004

Epoch: 6| Step: 7
Training loss: 2.4955289363861084
Validation loss: 2.413418833927442

Epoch: 6| Step: 8
Training loss: 2.956378221511841
Validation loss: 2.4280324238602833

Epoch: 6| Step: 9
Training loss: 2.8712456226348877
Validation loss: 2.447463486784248

Epoch: 6| Step: 10
Training loss: 2.7497310638427734
Validation loss: 2.4511560060644664

Epoch: 6| Step: 11
Training loss: 2.557786464691162
Validation loss: 2.4318858013358167

Epoch: 6| Step: 12
Training loss: 2.057669162750244
Validation loss: 2.430413717864662

Epoch: 6| Step: 13
Training loss: 2.5227725505828857
Validation loss: 2.4243178085614274

Epoch: 54| Step: 0
Training loss: 3.019317388534546
Validation loss: 2.4141823117451002

Epoch: 6| Step: 1
Training loss: 2.234314441680908
Validation loss: 2.39989504378329

Epoch: 6| Step: 2
Training loss: 1.8773343563079834
Validation loss: 2.3970396082888366

Epoch: 6| Step: 3
Training loss: 1.9027180671691895
Validation loss: 2.398688836764264

Epoch: 6| Step: 4
Training loss: 2.908918857574463
Validation loss: 2.399186900866929

Epoch: 6| Step: 5
Training loss: 2.64677357673645
Validation loss: 2.395560449169528

Epoch: 6| Step: 6
Training loss: 2.68859601020813
Validation loss: 2.392623462984639

Epoch: 6| Step: 7
Training loss: 2.1450884342193604
Validation loss: 2.39461011527687

Epoch: 6| Step: 8
Training loss: 2.9149973392486572
Validation loss: 2.3949243932641964

Epoch: 6| Step: 9
Training loss: 2.7310643196105957
Validation loss: 2.3971643204330118

Epoch: 6| Step: 10
Training loss: 2.3156630992889404
Validation loss: 2.3977508698740313

Epoch: 6| Step: 11
Training loss: 2.6252353191375732
Validation loss: 2.4030132344973985

Epoch: 6| Step: 12
Training loss: 3.4216837882995605
Validation loss: 2.3988594239757908

Epoch: 6| Step: 13
Training loss: 4.34359073638916
Validation loss: 2.393396585218368

Epoch: 55| Step: 0
Training loss: 3.2270407676696777
Validation loss: 2.390517860330561

Epoch: 6| Step: 1
Training loss: 2.5019261837005615
Validation loss: 2.390393576314372

Epoch: 6| Step: 2
Training loss: 3.0892062187194824
Validation loss: 2.3897190222176175

Epoch: 6| Step: 3
Training loss: 3.0656657218933105
Validation loss: 2.386533596182382

Epoch: 6| Step: 4
Training loss: 2.415133476257324
Validation loss: 2.39024882419135

Epoch: 6| Step: 5
Training loss: 4.134232044219971
Validation loss: 2.385122458140055

Epoch: 6| Step: 6
Training loss: 2.525256395339966
Validation loss: 2.3866435609838015

Epoch: 6| Step: 7
Training loss: 2.3584628105163574
Validation loss: 2.3881849550431773

Epoch: 6| Step: 8
Training loss: 1.8739123344421387
Validation loss: 2.3888995544884795

Epoch: 6| Step: 9
Training loss: 1.6965603828430176
Validation loss: 2.3867902191736365

Epoch: 6| Step: 10
Training loss: 1.9914579391479492
Validation loss: 2.3892944679465344

Epoch: 6| Step: 11
Training loss: 2.7037880420684814
Validation loss: 2.3854674754604215

Epoch: 6| Step: 12
Training loss: 2.3629322052001953
Validation loss: 2.3887019183046077

Epoch: 6| Step: 13
Training loss: 3.2088804244995117
Validation loss: 2.389486635884931

Epoch: 56| Step: 0
Training loss: 2.6543288230895996
Validation loss: 2.3941807746887207

Epoch: 6| Step: 1
Training loss: 2.3920156955718994
Validation loss: 2.3899871944099345

Epoch: 6| Step: 2
Training loss: 2.9890947341918945
Validation loss: 2.392778309442664

Epoch: 6| Step: 3
Training loss: 3.4324300289154053
Validation loss: 2.400175271495696

Epoch: 6| Step: 4
Training loss: 3.0614352226257324
Validation loss: 2.3968865640701784

Epoch: 6| Step: 5
Training loss: 2.504940986633301
Validation loss: 2.402061470093266

Epoch: 6| Step: 6
Training loss: 2.2774510383605957
Validation loss: 2.4016256063215193

Epoch: 6| Step: 7
Training loss: 2.5938429832458496
Validation loss: 2.4193288869755243

Epoch: 6| Step: 8
Training loss: 3.214913845062256
Validation loss: 2.4400681090611283

Epoch: 6| Step: 9
Training loss: 2.1737937927246094
Validation loss: 2.468944864888345

Epoch: 6| Step: 10
Training loss: 2.919787883758545
Validation loss: 2.4614212794970443

Epoch: 6| Step: 11
Training loss: 1.844158411026001
Validation loss: 2.447031233900337

Epoch: 6| Step: 12
Training loss: 2.1063289642333984
Validation loss: 2.428451161230764

Epoch: 6| Step: 13
Training loss: 2.6586122512817383
Validation loss: 2.4195376083415043

Epoch: 57| Step: 0
Training loss: 2.9531383514404297
Validation loss: 2.416886742397021

Epoch: 6| Step: 1
Training loss: 2.892185688018799
Validation loss: 2.4067774024060977

Epoch: 6| Step: 2
Training loss: 2.1710448265075684
Validation loss: 2.390519634369881

Epoch: 6| Step: 3
Training loss: 2.5414395332336426
Validation loss: 2.381083955046951

Epoch: 6| Step: 4
Training loss: 2.0673775672912598
Validation loss: 2.3793748604354037

Epoch: 6| Step: 5
Training loss: 2.32395076751709
Validation loss: 2.381065942907846

Epoch: 6| Step: 6
Training loss: 2.5713977813720703
Validation loss: 2.375617678447436

Epoch: 6| Step: 7
Training loss: 2.2853376865386963
Validation loss: 2.3757220814304967

Epoch: 6| Step: 8
Training loss: 3.0459096431732178
Validation loss: 2.3749834978452293

Epoch: 6| Step: 9
Training loss: 3.401477336883545
Validation loss: 2.3810825014627106

Epoch: 6| Step: 10
Training loss: 2.4478092193603516
Validation loss: 2.3782223116966987

Epoch: 6| Step: 11
Training loss: 2.6065967082977295
Validation loss: 2.389667667368407

Epoch: 6| Step: 12
Training loss: 2.774298667907715
Validation loss: 2.3996497943837154

Epoch: 6| Step: 13
Training loss: 2.6918067932128906
Validation loss: 2.390836864389399

Epoch: 58| Step: 0
Training loss: 3.086442470550537
Validation loss: 2.3787615273588445

Epoch: 6| Step: 1
Training loss: 1.947421908378601
Validation loss: 2.3715141152822845

Epoch: 6| Step: 2
Training loss: 2.237044095993042
Validation loss: 2.3670737974105345

Epoch: 6| Step: 3
Training loss: 2.7481820583343506
Validation loss: 2.365525786594678

Epoch: 6| Step: 4
Training loss: 3.047051191329956
Validation loss: 2.3629136059873845

Epoch: 6| Step: 5
Training loss: 2.1604034900665283
Validation loss: 2.3639933422047603

Epoch: 6| Step: 6
Training loss: 2.248535633087158
Validation loss: 2.3656218000637588

Epoch: 6| Step: 7
Training loss: 3.56681489944458
Validation loss: 2.3688989377790883

Epoch: 6| Step: 8
Training loss: 2.659878730773926
Validation loss: 2.368295946428853

Epoch: 6| Step: 9
Training loss: 2.8667585849761963
Validation loss: 2.3717442981658445

Epoch: 6| Step: 10
Training loss: 2.391948699951172
Validation loss: 2.39177793072116

Epoch: 6| Step: 11
Training loss: 2.53749942779541
Validation loss: 2.421034792418121

Epoch: 6| Step: 12
Training loss: 2.732138156890869
Validation loss: 2.486170978956325

Epoch: 6| Step: 13
Training loss: 2.1022403240203857
Validation loss: 2.5453867450837167

Epoch: 59| Step: 0
Training loss: 2.4367854595184326
Validation loss: 2.628940592529953

Epoch: 6| Step: 1
Training loss: 2.3087267875671387
Validation loss: 2.639789735117266

Epoch: 6| Step: 2
Training loss: 2.4790284633636475
Validation loss: 2.634570301219981

Epoch: 6| Step: 3
Training loss: 3.265634298324585
Validation loss: 2.5441651216117283

Epoch: 6| Step: 4
Training loss: 2.870955228805542
Validation loss: 2.426592009041899

Epoch: 6| Step: 5
Training loss: 2.955573558807373
Validation loss: 2.365243363124068

Epoch: 6| Step: 6
Training loss: 3.3402440547943115
Validation loss: 2.356012331542148

Epoch: 6| Step: 7
Training loss: 2.787830352783203
Validation loss: 2.378403394452987

Epoch: 6| Step: 8
Training loss: 2.6892764568328857
Validation loss: 2.4116276874337146

Epoch: 6| Step: 9
Training loss: 2.432448387145996
Validation loss: 2.428242588555941

Epoch: 6| Step: 10
Training loss: 2.4439620971679688
Validation loss: 2.415688442927535

Epoch: 6| Step: 11
Training loss: 2.3020637035369873
Validation loss: 2.3873629134188414

Epoch: 6| Step: 12
Training loss: 2.660017967224121
Validation loss: 2.385230500210998

Epoch: 6| Step: 13
Training loss: 2.7240092754364014
Validation loss: 2.3708301308334514

Epoch: 60| Step: 0
Training loss: 2.9263081550598145
Validation loss: 2.364095587884226

Epoch: 6| Step: 1
Training loss: 2.6837282180786133
Validation loss: 2.357105944746284

Epoch: 6| Step: 2
Training loss: 2.3686113357543945
Validation loss: 2.3550551091471026

Epoch: 6| Step: 3
Training loss: 2.9942328929901123
Validation loss: 2.352674207379741

Epoch: 6| Step: 4
Training loss: 2.13339900970459
Validation loss: 2.3531147638956704

Epoch: 6| Step: 5
Training loss: 3.0517313480377197
Validation loss: 2.3525198698043823

Epoch: 6| Step: 6
Training loss: 1.9485318660736084
Validation loss: 2.3561687956574144

Epoch: 6| Step: 7
Training loss: 3.1452901363372803
Validation loss: 2.355425778255668

Epoch: 6| Step: 8
Training loss: 2.181990146636963
Validation loss: 2.3584604147941834

Epoch: 6| Step: 9
Training loss: 2.7534072399139404
Validation loss: 2.3664242400917956

Epoch: 6| Step: 10
Training loss: 2.98362135887146
Validation loss: 2.3684657235299387

Epoch: 6| Step: 11
Training loss: 2.120842933654785
Validation loss: 2.372152877110307

Epoch: 6| Step: 12
Training loss: 2.5620834827423096
Validation loss: 2.370302705354588

Epoch: 6| Step: 13
Training loss: 3.0295827388763428
Validation loss: 2.3716575099575903

Epoch: 61| Step: 0
Training loss: 2.598256826400757
Validation loss: 2.3718089160098823

Epoch: 6| Step: 1
Training loss: 2.8439278602600098
Validation loss: 2.372643824546568

Epoch: 6| Step: 2
Training loss: 2.093031644821167
Validation loss: 2.3715574766999934

Epoch: 6| Step: 3
Training loss: 1.8563045263290405
Validation loss: 2.3720071187583347

Epoch: 6| Step: 4
Training loss: 2.7182047367095947
Validation loss: 2.3806025751175417

Epoch: 6| Step: 5
Training loss: 2.2032878398895264
Validation loss: 2.4054959768890054

Epoch: 6| Step: 6
Training loss: 2.923785448074341
Validation loss: 2.427980702410462

Epoch: 6| Step: 7
Training loss: 2.8230690956115723
Validation loss: 2.4544527171760477

Epoch: 6| Step: 8
Training loss: 3.5678839683532715
Validation loss: 2.5022859470818632

Epoch: 6| Step: 9
Training loss: 3.263681411743164
Validation loss: 2.49221791759614

Epoch: 6| Step: 10
Training loss: 2.5344104766845703
Validation loss: 2.437749029487692

Epoch: 6| Step: 11
Training loss: 2.52237606048584
Validation loss: 2.396409297502169

Epoch: 6| Step: 12
Training loss: 2.5611066818237305
Validation loss: 2.3721091388374247

Epoch: 6| Step: 13
Training loss: 2.0732364654541016
Validation loss: 2.3544291732131795

Epoch: 62| Step: 0
Training loss: 2.6101348400115967
Validation loss: 2.3427789647092103

Epoch: 6| Step: 1
Training loss: 2.641164541244507
Validation loss: 2.3489223552006546

Epoch: 6| Step: 2
Training loss: 2.51265025138855
Validation loss: 2.361553986867269

Epoch: 6| Step: 3
Training loss: 2.8488125801086426
Validation loss: 2.388138335238221

Epoch: 6| Step: 4
Training loss: 2.567920684814453
Validation loss: 2.4157484039183585

Epoch: 6| Step: 5
Training loss: 3.1485612392425537
Validation loss: 2.388137312345607

Epoch: 6| Step: 6
Training loss: 2.689578056335449
Validation loss: 2.355003147996882

Epoch: 6| Step: 7
Training loss: 2.209567070007324
Validation loss: 2.3440451160553963

Epoch: 6| Step: 8
Training loss: 2.6404542922973633
Validation loss: 2.352341341715987

Epoch: 6| Step: 9
Training loss: 2.3644797801971436
Validation loss: 2.3760237591240996

Epoch: 6| Step: 10
Training loss: 3.521514415740967
Validation loss: 2.421893140321137

Epoch: 6| Step: 11
Training loss: 2.4733381271362305
Validation loss: 2.4805991880355345

Epoch: 6| Step: 12
Training loss: 2.151125907897949
Validation loss: 2.5565066670858734

Epoch: 6| Step: 13
Training loss: 2.633578062057495
Validation loss: 2.595933393765521

Epoch: 63| Step: 0
Training loss: 2.0424933433532715
Validation loss: 2.5946455027467463

Epoch: 6| Step: 1
Training loss: 2.901304006576538
Validation loss: 2.5782907957671792

Epoch: 6| Step: 2
Training loss: 2.4575035572052
Validation loss: 2.5537262373073126

Epoch: 6| Step: 3
Training loss: 2.690504550933838
Validation loss: 2.4936412790770173

Epoch: 6| Step: 4
Training loss: 3.2381231784820557
Validation loss: 2.4478783504937285

Epoch: 6| Step: 5
Training loss: 2.920525074005127
Validation loss: 2.410359562084239

Epoch: 6| Step: 6
Training loss: 2.2831554412841797
Validation loss: 2.388173416096677

Epoch: 6| Step: 7
Training loss: 2.5833382606506348
Validation loss: 2.384849791885704

Epoch: 6| Step: 8
Training loss: 2.641066789627075
Validation loss: 2.3798423941417406

Epoch: 6| Step: 9
Training loss: 2.081156015396118
Validation loss: 2.3809008598327637

Epoch: 6| Step: 10
Training loss: 3.6356680393218994
Validation loss: 2.381011550144483

Epoch: 6| Step: 11
Training loss: 2.8257718086242676
Validation loss: 2.390119773085399

Epoch: 6| Step: 12
Training loss: 2.501526355743408
Validation loss: 2.393370025901384

Epoch: 6| Step: 13
Training loss: 2.362990379333496
Validation loss: 2.392222653153122

Epoch: 64| Step: 0
Training loss: 2.1654303073883057
Validation loss: 2.3936161328387517

Epoch: 6| Step: 1
Training loss: 2.8177809715270996
Validation loss: 2.3856607175642446

Epoch: 6| Step: 2
Training loss: 3.1613197326660156
Validation loss: 2.3847038976607786

Epoch: 6| Step: 3
Training loss: 2.2817680835723877
Validation loss: 2.3911805563075568

Epoch: 6| Step: 4
Training loss: 2.1209185123443604
Validation loss: 2.3934927217421995

Epoch: 6| Step: 5
Training loss: 2.651841640472412
Validation loss: 2.4106506686056814

Epoch: 6| Step: 6
Training loss: 2.7584991455078125
Validation loss: 2.4250812838154454

Epoch: 6| Step: 7
Training loss: 3.090773582458496
Validation loss: 2.443472680225167

Epoch: 6| Step: 8
Training loss: 2.988762855529785
Validation loss: 2.4203809794559272

Epoch: 6| Step: 9
Training loss: 2.3709497451782227
Validation loss: 2.4046281460792787

Epoch: 6| Step: 10
Training loss: 3.528517007827759
Validation loss: 2.3953993269192275

Epoch: 6| Step: 11
Training loss: 1.6777613162994385
Validation loss: 2.3840627106287147

Epoch: 6| Step: 12
Training loss: 2.7170519828796387
Validation loss: 2.3788149459387666

Epoch: 6| Step: 13
Training loss: 2.695016384124756
Validation loss: 2.3739535859836045

Epoch: 65| Step: 0
Training loss: 2.4913523197174072
Validation loss: 2.376134469944944

Epoch: 6| Step: 1
Training loss: 2.549015522003174
Validation loss: 2.3726416531429497

Epoch: 6| Step: 2
Training loss: 2.497319221496582
Validation loss: 2.3756941082657024

Epoch: 6| Step: 3
Training loss: 2.3010993003845215
Validation loss: 2.373048590075585

Epoch: 6| Step: 4
Training loss: 2.4133715629577637
Validation loss: 2.3713704603974537

Epoch: 6| Step: 5
Training loss: 2.918215751647949
Validation loss: 2.373464330550163

Epoch: 6| Step: 6
Training loss: 2.301377296447754
Validation loss: 2.373065002502934

Epoch: 6| Step: 7
Training loss: 2.7034456729888916
Validation loss: 2.3717919088179067

Epoch: 6| Step: 8
Training loss: 2.839003324508667
Validation loss: 2.37326741474931

Epoch: 6| Step: 9
Training loss: 2.8177382946014404
Validation loss: 2.394244304267309

Epoch: 6| Step: 10
Training loss: 2.9996695518493652
Validation loss: 2.4092998273911013

Epoch: 6| Step: 11
Training loss: 2.5404062271118164
Validation loss: 2.410155665489935

Epoch: 6| Step: 12
Training loss: 3.1807408332824707
Validation loss: 2.420030117034912

Epoch: 6| Step: 13
Training loss: 1.7884869575500488
Validation loss: 2.42511914109671

Epoch: 66| Step: 0
Training loss: 2.419492721557617
Validation loss: 2.4226415041954286

Epoch: 6| Step: 1
Training loss: 3.0139148235321045
Validation loss: 2.4250550667444863

Epoch: 6| Step: 2
Training loss: 2.8055343627929688
Validation loss: 2.43915468646634

Epoch: 6| Step: 3
Training loss: 2.484013795852661
Validation loss: 2.440468990674583

Epoch: 6| Step: 4
Training loss: 2.7463464736938477
Validation loss: 2.4348064084206857

Epoch: 6| Step: 5
Training loss: 2.2714099884033203
Validation loss: 2.4169766902923584

Epoch: 6| Step: 6
Training loss: 2.7879395484924316
Validation loss: 2.4148314716995403

Epoch: 6| Step: 7
Training loss: 3.1365323066711426
Validation loss: 2.414426002451169

Epoch: 6| Step: 8
Training loss: 2.7089011669158936
Validation loss: 2.4142490766381703

Epoch: 6| Step: 9
Training loss: 2.575551986694336
Validation loss: 2.3951782564963064

Epoch: 6| Step: 10
Training loss: 2.5100936889648438
Validation loss: 2.3884650507280902

Epoch: 6| Step: 11
Training loss: 2.599834442138672
Validation loss: 2.3879261093754924

Epoch: 6| Step: 12
Training loss: 2.501568555831909
Validation loss: 2.3802962290343417

Epoch: 6| Step: 13
Training loss: 1.8698315620422363
Validation loss: 2.37258606572305

Epoch: 67| Step: 0
Training loss: 3.1119470596313477
Validation loss: 2.3689313037421114

Epoch: 6| Step: 1
Training loss: 2.9419212341308594
Validation loss: 2.362393912448678

Epoch: 6| Step: 2
Training loss: 2.5913848876953125
Validation loss: 2.3657043031466904

Epoch: 6| Step: 3
Training loss: 1.908223271369934
Validation loss: 2.364020034831057

Epoch: 6| Step: 4
Training loss: 1.9742436408996582
Validation loss: 2.3604871739623365

Epoch: 6| Step: 5
Training loss: 2.4492087364196777
Validation loss: 2.363098052240187

Epoch: 6| Step: 6
Training loss: 2.7216506004333496
Validation loss: 2.361703439425397

Epoch: 6| Step: 7
Training loss: 2.4609603881835938
Validation loss: 2.363855759302775

Epoch: 6| Step: 8
Training loss: 2.0092835426330566
Validation loss: 2.365272178444811

Epoch: 6| Step: 9
Training loss: 2.315542459487915
Validation loss: 2.361613760712326

Epoch: 6| Step: 10
Training loss: 3.763216495513916
Validation loss: 2.373642998356973

Epoch: 6| Step: 11
Training loss: 2.1882572174072266
Validation loss: 2.3680043605066117

Epoch: 6| Step: 12
Training loss: 3.1120495796203613
Validation loss: 2.369643013964417

Epoch: 6| Step: 13
Training loss: 3.542419910430908
Validation loss: 2.363949155294767

Epoch: 68| Step: 0
Training loss: 1.921257734298706
Validation loss: 2.3595820255176996

Epoch: 6| Step: 1
Training loss: 2.1283376216888428
Validation loss: 2.36195388660636

Epoch: 6| Step: 2
Training loss: 3.0530471801757812
Validation loss: 2.3588840294909734

Epoch: 6| Step: 3
Training loss: 1.874563217163086
Validation loss: 2.367448547834991

Epoch: 6| Step: 4
Training loss: 2.6574277877807617
Validation loss: 2.3684607962126374

Epoch: 6| Step: 5
Training loss: 2.5217320919036865
Validation loss: 2.365451746089484

Epoch: 6| Step: 6
Training loss: 2.3792831897735596
Validation loss: 2.3539941464701006

Epoch: 6| Step: 7
Training loss: 3.5121989250183105
Validation loss: 2.354111748356973

Epoch: 6| Step: 8
Training loss: 2.447843074798584
Validation loss: 2.349140920946675

Epoch: 6| Step: 9
Training loss: 2.3622944355010986
Validation loss: 2.3542251279277187

Epoch: 6| Step: 10
Training loss: 2.92509388923645
Validation loss: 2.35494880137905

Epoch: 6| Step: 11
Training loss: 2.903496742248535
Validation loss: 2.3499927982207267

Epoch: 6| Step: 12
Training loss: 3.1981101036071777
Validation loss: 2.3570637984942366

Epoch: 6| Step: 13
Training loss: 2.6481356620788574
Validation loss: 2.3568166814824587

Epoch: 69| Step: 0
Training loss: 2.537533760070801
Validation loss: 2.367257841171757

Epoch: 6| Step: 1
Training loss: 2.978729724884033
Validation loss: 2.3630764792042394

Epoch: 6| Step: 2
Training loss: 2.4397594928741455
Validation loss: 2.3713573986484158

Epoch: 6| Step: 3
Training loss: 3.2484383583068848
Validation loss: 2.375599935490598

Epoch: 6| Step: 4
Training loss: 2.350283622741699
Validation loss: 2.3638643039170133

Epoch: 6| Step: 5
Training loss: 2.0504138469696045
Validation loss: 2.3568924524450816

Epoch: 6| Step: 6
Training loss: 2.3211865425109863
Validation loss: 2.3557561289879585

Epoch: 6| Step: 7
Training loss: 2.973086357116699
Validation loss: 2.350692569568593

Epoch: 6| Step: 8
Training loss: 2.240480661392212
Validation loss: 2.3431469676315144

Epoch: 6| Step: 9
Training loss: 2.8214454650878906
Validation loss: 2.33745946550882

Epoch: 6| Step: 10
Training loss: 2.898409366607666
Validation loss: 2.3335717826761226

Epoch: 6| Step: 11
Training loss: 2.377870798110962
Validation loss: 2.330893506285965

Epoch: 6| Step: 12
Training loss: 2.5753369331359863
Validation loss: 2.3314393925410446

Epoch: 6| Step: 13
Training loss: 2.6147217750549316
Validation loss: 2.3331282959189465

Epoch: 70| Step: 0
Training loss: 2.576965808868408
Validation loss: 2.3312951031551568

Epoch: 6| Step: 1
Training loss: 2.165813446044922
Validation loss: 2.330093183825093

Epoch: 6| Step: 2
Training loss: 2.799309730529785
Validation loss: 2.325998716456916

Epoch: 6| Step: 3
Training loss: 2.2257673740386963
Validation loss: 2.327909618295649

Epoch: 6| Step: 4
Training loss: 2.7308621406555176
Validation loss: 2.327038113788892

Epoch: 6| Step: 5
Training loss: 3.1358635425567627
Validation loss: 2.331424920789657

Epoch: 6| Step: 6
Training loss: 2.6238903999328613
Validation loss: 2.3337193689038678

Epoch: 6| Step: 7
Training loss: 3.1676971912384033
Validation loss: 2.330054170341902

Epoch: 6| Step: 8
Training loss: 2.4960858821868896
Validation loss: 2.3368714240289505

Epoch: 6| Step: 9
Training loss: 1.5045679807662964
Validation loss: 2.346653402492564

Epoch: 6| Step: 10
Training loss: 2.046325445175171
Validation loss: 2.350468186921971

Epoch: 6| Step: 11
Training loss: 2.614778518676758
Validation loss: 2.3504715017093125

Epoch: 6| Step: 12
Training loss: 3.5784730911254883
Validation loss: 2.3370376761241625

Epoch: 6| Step: 13
Training loss: 2.6685197353363037
Validation loss: 2.326802868996897

Epoch: 71| Step: 0
Training loss: 2.2668192386627197
Validation loss: 2.3257082303365073

Epoch: 6| Step: 1
Training loss: 3.405734062194824
Validation loss: 2.3250866731007895

Epoch: 6| Step: 2
Training loss: 2.6156132221221924
Validation loss: 2.320917639681088

Epoch: 6| Step: 3
Training loss: 2.879429340362549
Validation loss: 2.3203364726035827

Epoch: 6| Step: 4
Training loss: 2.5305380821228027
Validation loss: 2.3201914628346763

Epoch: 6| Step: 5
Training loss: 2.3871593475341797
Validation loss: 2.32902592484669

Epoch: 6| Step: 6
Training loss: 2.3324224948883057
Validation loss: 2.334024747212728

Epoch: 6| Step: 7
Training loss: 2.589815139770508
Validation loss: 2.3424455145353913

Epoch: 6| Step: 8
Training loss: 2.1163806915283203
Validation loss: 2.350899445113315

Epoch: 6| Step: 9
Training loss: 2.3868656158447266
Validation loss: 2.3636598561399724

Epoch: 6| Step: 10
Training loss: 2.4795758724212646
Validation loss: 2.358357165449409

Epoch: 6| Step: 11
Training loss: 3.075207471847534
Validation loss: 2.358896865639635

Epoch: 6| Step: 12
Training loss: 2.3829352855682373
Validation loss: 2.344637199114728

Epoch: 6| Step: 13
Training loss: 2.960747480392456
Validation loss: 2.353005299004175

Epoch: 72| Step: 0
Training loss: 1.9652982950210571
Validation loss: 2.370846449687917

Epoch: 6| Step: 1
Training loss: 2.055809736251831
Validation loss: 2.3818504797515048

Epoch: 6| Step: 2
Training loss: 2.6195483207702637
Validation loss: 2.3959081813853276

Epoch: 6| Step: 3
Training loss: 2.172144889831543
Validation loss: 2.389838103325136

Epoch: 6| Step: 4
Training loss: 2.593137741088867
Validation loss: 2.394959106240221

Epoch: 6| Step: 5
Training loss: 2.474351644515991
Validation loss: 2.4019650772053707

Epoch: 6| Step: 6
Training loss: 3.398743152618408
Validation loss: 2.396762970955141

Epoch: 6| Step: 7
Training loss: 2.4573585987091064
Validation loss: 2.4056024320663942

Epoch: 6| Step: 8
Training loss: 2.9897284507751465
Validation loss: 2.3924704508114885

Epoch: 6| Step: 9
Training loss: 2.055032253265381
Validation loss: 2.3827474014733427

Epoch: 6| Step: 10
Training loss: 2.554797887802124
Validation loss: 2.3812915035473403

Epoch: 6| Step: 11
Training loss: 3.3110618591308594
Validation loss: 2.3713752736327467

Epoch: 6| Step: 12
Training loss: 2.938929557800293
Validation loss: 2.3678492756300074

Epoch: 6| Step: 13
Training loss: 3.0029547214508057
Validation loss: 2.362844128762522

Epoch: 73| Step: 0
Training loss: 2.591968059539795
Validation loss: 2.363368772691296

Epoch: 6| Step: 1
Training loss: 2.472727060317993
Validation loss: 2.3619234331192507

Epoch: 6| Step: 2
Training loss: 2.6302781105041504
Validation loss: 2.3528022496931014

Epoch: 6| Step: 3
Training loss: 2.8399953842163086
Validation loss: 2.347159916354764

Epoch: 6| Step: 4
Training loss: 1.627585768699646
Validation loss: 2.344081255697435

Epoch: 6| Step: 5
Training loss: 2.775723457336426
Validation loss: 2.3398877138732583

Epoch: 6| Step: 6
Training loss: 3.1807968616485596
Validation loss: 2.3444045538543374

Epoch: 6| Step: 7
Training loss: 2.6396031379699707
Validation loss: 2.3425401090293803

Epoch: 6| Step: 8
Training loss: 2.1581473350524902
Validation loss: 2.3483827344832884

Epoch: 6| Step: 9
Training loss: 2.571743965148926
Validation loss: 2.3494841488458778

Epoch: 6| Step: 10
Training loss: 3.4403939247131348
Validation loss: 2.3461682693932646

Epoch: 6| Step: 11
Training loss: 2.6648552417755127
Validation loss: 2.3358616572554394

Epoch: 6| Step: 12
Training loss: 2.040111541748047
Validation loss: 2.3256419756079234

Epoch: 6| Step: 13
Training loss: 2.702315330505371
Validation loss: 2.3296929713218444

Epoch: 74| Step: 0
Training loss: 2.886329174041748
Validation loss: 2.3242269946682836

Epoch: 6| Step: 1
Training loss: 2.7466306686401367
Validation loss: 2.3094854252312773

Epoch: 6| Step: 2
Training loss: 3.086331605911255
Validation loss: 2.3057022863818752

Epoch: 6| Step: 3
Training loss: 2.163874864578247
Validation loss: 2.2989073235501527

Epoch: 6| Step: 4
Training loss: 2.837491035461426
Validation loss: 2.3044129520334224

Epoch: 6| Step: 5
Training loss: 2.148928642272949
Validation loss: 2.296863753308532

Epoch: 6| Step: 6
Training loss: 2.6013166904449463
Validation loss: 2.300168729597522

Epoch: 6| Step: 7
Training loss: 2.084308624267578
Validation loss: 2.301638859574513

Epoch: 6| Step: 8
Training loss: 2.624904155731201
Validation loss: 2.2999547604591615

Epoch: 6| Step: 9
Training loss: 2.131995677947998
Validation loss: 2.306512212240568

Epoch: 6| Step: 10
Training loss: 2.722041606903076
Validation loss: 2.325416364977437

Epoch: 6| Step: 11
Training loss: 3.1122286319732666
Validation loss: 2.350922892170568

Epoch: 6| Step: 12
Training loss: 2.540971517562866
Validation loss: 2.357352074756417

Epoch: 6| Step: 13
Training loss: 2.447901487350464
Validation loss: 2.3574530898883777

Epoch: 75| Step: 0
Training loss: 2.725584030151367
Validation loss: 2.3293983961946223

Epoch: 6| Step: 1
Training loss: 3.177067756652832
Validation loss: 2.311399946930588

Epoch: 6| Step: 2
Training loss: 2.573641061782837
Validation loss: 2.301887865989439

Epoch: 6| Step: 3
Training loss: 3.0984790325164795
Validation loss: 2.2999821709048365

Epoch: 6| Step: 4
Training loss: 2.663576602935791
Validation loss: 2.2926390017232587

Epoch: 6| Step: 5
Training loss: 2.5748074054718018
Validation loss: 2.2956385381760134

Epoch: 6| Step: 6
Training loss: 1.9574065208435059
Validation loss: 2.295743512850936

Epoch: 6| Step: 7
Training loss: 2.1564438343048096
Validation loss: 2.294429379124795

Epoch: 6| Step: 8
Training loss: 2.485220432281494
Validation loss: 2.2973564568386284

Epoch: 6| Step: 9
Training loss: 2.5929274559020996
Validation loss: 2.2968587849729802

Epoch: 6| Step: 10
Training loss: 3.200526714324951
Validation loss: 2.2925702576996176

Epoch: 6| Step: 11
Training loss: 2.1233959197998047
Validation loss: 2.2963154341584895

Epoch: 6| Step: 12
Training loss: 2.3477988243103027
Validation loss: 2.2943031839145127

Epoch: 6| Step: 13
Training loss: 2.7528810501098633
Validation loss: 2.300353668069327

Epoch: 76| Step: 0
Training loss: 2.752246379852295
Validation loss: 2.2961458518940914

Epoch: 6| Step: 1
Training loss: 2.114518165588379
Validation loss: 2.291606646712108

Epoch: 6| Step: 2
Training loss: 1.9892138242721558
Validation loss: 2.296398916552144

Epoch: 6| Step: 3
Training loss: 2.8753864765167236
Validation loss: 2.292363397536739

Epoch: 6| Step: 4
Training loss: 2.685499668121338
Validation loss: 2.2877668821683494

Epoch: 6| Step: 5
Training loss: 2.6814303398132324
Validation loss: 2.2970684805224018

Epoch: 6| Step: 6
Training loss: 2.968454360961914
Validation loss: 2.2948602732791694

Epoch: 6| Step: 7
Training loss: 3.1309938430786133
Validation loss: 2.296953534567228

Epoch: 6| Step: 8
Training loss: 2.4510648250579834
Validation loss: 2.3018630191844

Epoch: 6| Step: 9
Training loss: 2.3784642219543457
Validation loss: 2.2997719575000066

Epoch: 6| Step: 10
Training loss: 2.461773633956909
Validation loss: 2.312873778804656

Epoch: 6| Step: 11
Training loss: 3.1082773208618164
Validation loss: 2.3288205003225677

Epoch: 6| Step: 12
Training loss: 2.342074394226074
Validation loss: 2.3459708177915184

Epoch: 6| Step: 13
Training loss: 1.855436086654663
Validation loss: 2.327435306323472

Epoch: 77| Step: 0
Training loss: 3.3216209411621094
Validation loss: 2.322892014698316

Epoch: 6| Step: 1
Training loss: 2.301039695739746
Validation loss: 2.3341509039684007

Epoch: 6| Step: 2
Training loss: 2.9062132835388184
Validation loss: 2.3240758501073366

Epoch: 6| Step: 3
Training loss: 1.5695159435272217
Validation loss: 2.2930626279564312

Epoch: 6| Step: 4
Training loss: 2.626734495162964
Validation loss: 2.292300811377905

Epoch: 6| Step: 5
Training loss: 2.607400417327881
Validation loss: 2.2891086968042518

Epoch: 6| Step: 6
Training loss: 2.5392985343933105
Validation loss: 2.2889619899052445

Epoch: 6| Step: 7
Training loss: 1.9743201732635498
Validation loss: 2.284088606475502

Epoch: 6| Step: 8
Training loss: 3.135615825653076
Validation loss: 2.283670481815133

Epoch: 6| Step: 9
Training loss: 2.203561782836914
Validation loss: 2.286232538120721

Epoch: 6| Step: 10
Training loss: 3.3285653591156006
Validation loss: 2.2912525874312206

Epoch: 6| Step: 11
Training loss: 2.6444976329803467
Validation loss: 2.3062078055515083

Epoch: 6| Step: 12
Training loss: 1.9012367725372314
Validation loss: 2.3066970789304344

Epoch: 6| Step: 13
Training loss: 3.0777721405029297
Validation loss: 2.3227262753312305

Epoch: 78| Step: 0
Training loss: 2.6811513900756836
Validation loss: 2.333644579815608

Epoch: 6| Step: 1
Training loss: 2.7878875732421875
Validation loss: 2.3446632380126626

Epoch: 6| Step: 2
Training loss: 2.8416595458984375
Validation loss: 2.3297735670561432

Epoch: 6| Step: 3
Training loss: 2.423053741455078
Validation loss: 2.3157099523851947

Epoch: 6| Step: 4
Training loss: 2.4801292419433594
Validation loss: 2.304140370379212

Epoch: 6| Step: 5
Training loss: 2.5529332160949707
Validation loss: 2.2951500261983564

Epoch: 6| Step: 6
Training loss: 2.5694825649261475
Validation loss: 2.29349466933999

Epoch: 6| Step: 7
Training loss: 2.3164196014404297
Validation loss: 2.296752796378187

Epoch: 6| Step: 8
Training loss: 2.145380735397339
Validation loss: 2.298594072300901

Epoch: 6| Step: 9
Training loss: 2.925379753112793
Validation loss: 2.2968746308357484

Epoch: 6| Step: 10
Training loss: 2.6136717796325684
Validation loss: 2.2978138590371735

Epoch: 6| Step: 11
Training loss: 2.932535171508789
Validation loss: 2.304005443408925

Epoch: 6| Step: 12
Training loss: 2.59564208984375
Validation loss: 2.3009110548162974

Epoch: 6| Step: 13
Training loss: 1.4904314279556274
Validation loss: 2.2969703110315467

Epoch: 79| Step: 0
Training loss: 2.4983415603637695
Validation loss: 2.298894315637568

Epoch: 6| Step: 1
Training loss: 2.0143961906433105
Validation loss: 2.3083527908530286

Epoch: 6| Step: 2
Training loss: 2.585390329360962
Validation loss: 2.3050530469545754

Epoch: 6| Step: 3
Training loss: 3.1794328689575195
Validation loss: 2.3008408751539005

Epoch: 6| Step: 4
Training loss: 2.1143639087677
Validation loss: 2.2919749239439606

Epoch: 6| Step: 5
Training loss: 3.1145071983337402
Validation loss: 2.2862864950651764

Epoch: 6| Step: 6
Training loss: 2.8042235374450684
Validation loss: 2.2746717237657115

Epoch: 6| Step: 7
Training loss: 2.487732172012329
Validation loss: 2.26737396178707

Epoch: 6| Step: 8
Training loss: 2.0717813968658447
Validation loss: 2.265403027175575

Epoch: 6| Step: 9
Training loss: 2.6841955184936523
Validation loss: 2.256744343747375

Epoch: 6| Step: 10
Training loss: 1.900712251663208
Validation loss: 2.258614522154613

Epoch: 6| Step: 11
Training loss: 2.559760332107544
Validation loss: 2.2504965284819245

Epoch: 6| Step: 12
Training loss: 2.7070260047912598
Validation loss: 2.238162591893186

Epoch: 6| Step: 13
Training loss: 3.345614433288574
Validation loss: 2.2459475353199947

Epoch: 80| Step: 0
Training loss: 2.696601390838623
Validation loss: 2.2664074987493534

Epoch: 6| Step: 1
Training loss: 2.453179121017456
Validation loss: 2.26909460559968

Epoch: 6| Step: 2
Training loss: 3.1018447875976562
Validation loss: 2.2615312658330446

Epoch: 6| Step: 3
Training loss: 2.1064038276672363
Validation loss: 2.2588666087837628

Epoch: 6| Step: 4
Training loss: 2.0517311096191406
Validation loss: 2.244341686207761

Epoch: 6| Step: 5
Training loss: 2.9549601078033447
Validation loss: 2.2390642396865355

Epoch: 6| Step: 6
Training loss: 2.030109405517578
Validation loss: 2.2399457782827397

Epoch: 6| Step: 7
Training loss: 2.2078704833984375
Validation loss: 2.235810543901177

Epoch: 6| Step: 8
Training loss: 1.8850733041763306
Validation loss: 2.2402132480375228

Epoch: 6| Step: 9
Training loss: 3.1158478260040283
Validation loss: 2.2482169289742746

Epoch: 6| Step: 10
Training loss: 3.1675469875335693
Validation loss: 2.2617743194744153

Epoch: 6| Step: 11
Training loss: 2.906205177307129
Validation loss: 2.2595124988145727

Epoch: 6| Step: 12
Training loss: 1.7492846250534058
Validation loss: 2.267808086128645

Epoch: 6| Step: 13
Training loss: 3.3490965366363525
Validation loss: 2.2696804308122203

Epoch: 81| Step: 0
Training loss: 2.851128101348877
Validation loss: 2.266657349883869

Epoch: 6| Step: 1
Training loss: 2.971557140350342
Validation loss: 2.2709553318638958

Epoch: 6| Step: 2
Training loss: 2.757467746734619
Validation loss: 2.278495051527536

Epoch: 6| Step: 3
Training loss: 2.2351605892181396
Validation loss: 2.266854702785451

Epoch: 6| Step: 4
Training loss: 2.3234200477600098
Validation loss: 2.2695784671332246

Epoch: 6| Step: 5
Training loss: 2.326718807220459
Validation loss: 2.269750682256555

Epoch: 6| Step: 6
Training loss: 2.1438992023468018
Validation loss: 2.2600151723431003

Epoch: 6| Step: 7
Training loss: 2.356637954711914
Validation loss: 2.2464314173626643

Epoch: 6| Step: 8
Training loss: 2.709611177444458
Validation loss: 2.2489140674632084

Epoch: 6| Step: 9
Training loss: 2.6773252487182617
Validation loss: 2.2515237382663194

Epoch: 6| Step: 10
Training loss: 2.4288101196289062
Validation loss: 2.2503060294735815

Epoch: 6| Step: 11
Training loss: 2.4036154747009277
Validation loss: 2.2603438028725247

Epoch: 6| Step: 12
Training loss: 2.116990566253662
Validation loss: 2.2656704815485145

Epoch: 6| Step: 13
Training loss: 3.4101438522338867
Validation loss: 2.2738577601730183

Epoch: 82| Step: 0
Training loss: 1.757080078125
Validation loss: 2.2756852937001053

Epoch: 6| Step: 1
Training loss: 2.9251089096069336
Validation loss: 2.2758765054005448

Epoch: 6| Step: 2
Training loss: 1.9217725992202759
Validation loss: 2.2937825367014897

Epoch: 6| Step: 3
Training loss: 3.161007881164551
Validation loss: 2.309024131426247

Epoch: 6| Step: 4
Training loss: 2.061551570892334
Validation loss: 2.340799008646319

Epoch: 6| Step: 5
Training loss: 2.662611961364746
Validation loss: 2.3601835504654916

Epoch: 6| Step: 6
Training loss: 2.3789286613464355
Validation loss: 2.345302911214931

Epoch: 6| Step: 7
Training loss: 2.266360282897949
Validation loss: 2.266120772207937

Epoch: 6| Step: 8
Training loss: 2.2479913234710693
Validation loss: 2.249081047632361

Epoch: 6| Step: 9
Training loss: 2.8729045391082764
Validation loss: 2.229865233103434

Epoch: 6| Step: 10
Training loss: 2.4915883541107178
Validation loss: 2.2183595985494633

Epoch: 6| Step: 11
Training loss: 3.208211898803711
Validation loss: 2.211414598649548

Epoch: 6| Step: 12
Training loss: 2.836426019668579
Validation loss: 2.2063035811147382

Epoch: 6| Step: 13
Training loss: 2.6271684169769287
Validation loss: 2.208798752036146

Epoch: 83| Step: 0
Training loss: 2.229635715484619
Validation loss: 2.2076035622627503

Epoch: 6| Step: 1
Training loss: 2.2922616004943848
Validation loss: 2.204247377252066

Epoch: 6| Step: 2
Training loss: 2.5207505226135254
Validation loss: 2.2052749331279466

Epoch: 6| Step: 3
Training loss: 2.5998306274414062
Validation loss: 2.2124141903333765

Epoch: 6| Step: 4
Training loss: 2.474118232727051
Validation loss: 2.2239023588036977

Epoch: 6| Step: 5
Training loss: 2.6791296005249023
Validation loss: 2.2362044190847747

Epoch: 6| Step: 6
Training loss: 2.5024538040161133
Validation loss: 2.2879776044558455

Epoch: 6| Step: 7
Training loss: 2.2560315132141113
Validation loss: 2.32964385837637

Epoch: 6| Step: 8
Training loss: 2.602789878845215
Validation loss: 2.3589432111350437

Epoch: 6| Step: 9
Training loss: 2.218663215637207
Validation loss: 2.3422359266588764

Epoch: 6| Step: 10
Training loss: 2.8122124671936035
Validation loss: 2.294704585947016

Epoch: 6| Step: 11
Training loss: 3.1264591217041016
Validation loss: 2.260374476832728

Epoch: 6| Step: 12
Training loss: 2.7151458263397217
Validation loss: 2.2343489175201743

Epoch: 6| Step: 13
Training loss: 2.6823182106018066
Validation loss: 2.2147459830007246

Epoch: 84| Step: 0
Training loss: 3.0115790367126465
Validation loss: 2.203504413686773

Epoch: 6| Step: 1
Training loss: 2.099900960922241
Validation loss: 2.1940133161442255

Epoch: 6| Step: 2
Training loss: 2.6453185081481934
Validation loss: 2.193226304105533

Epoch: 6| Step: 3
Training loss: 2.299283266067505
Validation loss: 2.2062857791941655

Epoch: 6| Step: 4
Training loss: 2.9120540618896484
Validation loss: 2.209344272972435

Epoch: 6| Step: 5
Training loss: 2.7375102043151855
Validation loss: 2.203435277426115

Epoch: 6| Step: 6
Training loss: 2.5419554710388184
Validation loss: 2.1985692183176675

Epoch: 6| Step: 7
Training loss: 1.8243759870529175
Validation loss: 2.192181646182973

Epoch: 6| Step: 8
Training loss: 3.436166286468506
Validation loss: 2.1921311257987894

Epoch: 6| Step: 9
Training loss: 2.415895462036133
Validation loss: 2.1882510492878575

Epoch: 6| Step: 10
Training loss: 2.4568138122558594
Validation loss: 2.18892172075087

Epoch: 6| Step: 11
Training loss: 1.8831299543380737
Validation loss: 2.1899395809378674

Epoch: 6| Step: 12
Training loss: 2.402045726776123
Validation loss: 2.1912141948617916

Epoch: 6| Step: 13
Training loss: 2.8064467906951904
Validation loss: 2.1944823623985372

Epoch: 85| Step: 0
Training loss: 1.9657611846923828
Validation loss: 2.193376660346985

Epoch: 6| Step: 1
Training loss: 2.654799699783325
Validation loss: 2.1943446179871917

Epoch: 6| Step: 2
Training loss: 2.1615686416625977
Validation loss: 2.2070504811502274

Epoch: 6| Step: 3
Training loss: 2.538668155670166
Validation loss: 2.2220280221713486

Epoch: 6| Step: 4
Training loss: 3.2412147521972656
Validation loss: 2.244842726697204

Epoch: 6| Step: 5
Training loss: 2.6406004428863525
Validation loss: 2.2514851900839035

Epoch: 6| Step: 6
Training loss: 2.2179503440856934
Validation loss: 2.2856387117857575

Epoch: 6| Step: 7
Training loss: 2.164161443710327
Validation loss: 2.2572991847991943

Epoch: 6| Step: 8
Training loss: 2.480769634246826
Validation loss: 2.2380119664694673

Epoch: 6| Step: 9
Training loss: 3.2293996810913086
Validation loss: 2.218993527914888

Epoch: 6| Step: 10
Training loss: 2.024541139602661
Validation loss: 2.2103387642932195

Epoch: 6| Step: 11
Training loss: 2.3991875648498535
Validation loss: 2.2171310199204313

Epoch: 6| Step: 12
Training loss: 2.2010910511016846
Validation loss: 2.208180664688028

Epoch: 6| Step: 13
Training loss: 3.4063332080841064
Validation loss: 2.1991544205655336

Epoch: 86| Step: 0
Training loss: 2.6189982891082764
Validation loss: 2.19852190889338

Epoch: 6| Step: 1
Training loss: 2.4680593013763428
Validation loss: 2.1935125422734085

Epoch: 6| Step: 2
Training loss: 2.482523202896118
Validation loss: 2.1918263537909395

Epoch: 6| Step: 3
Training loss: 3.026559829711914
Validation loss: 2.183692609110186

Epoch: 6| Step: 4
Training loss: 2.0522871017456055
Validation loss: 2.183661855677123

Epoch: 6| Step: 5
Training loss: 2.433415412902832
Validation loss: 2.190914756508284

Epoch: 6| Step: 6
Training loss: 2.3959946632385254
Validation loss: 2.1958140121993197

Epoch: 6| Step: 7
Training loss: 2.6267647743225098
Validation loss: 2.2025996279972855

Epoch: 6| Step: 8
Training loss: 2.807553291320801
Validation loss: 2.1991531566907

Epoch: 6| Step: 9
Training loss: 2.3342881202697754
Validation loss: 2.1887052674447336

Epoch: 6| Step: 10
Training loss: 2.97800874710083
Validation loss: 2.188768612441196

Epoch: 6| Step: 11
Training loss: 1.5887646675109863
Validation loss: 2.1870057082945302

Epoch: 6| Step: 12
Training loss: 2.223965883255005
Validation loss: 2.188072983936597

Epoch: 6| Step: 13
Training loss: 3.2351808547973633
Validation loss: 2.20446111822641

Epoch: 87| Step: 0
Training loss: 2.333242893218994
Validation loss: 2.2200575131241993

Epoch: 6| Step: 1
Training loss: 2.0989599227905273
Validation loss: 2.2497513601856847

Epoch: 6| Step: 2
Training loss: 1.8478116989135742
Validation loss: 2.258347829182943

Epoch: 6| Step: 3
Training loss: 3.1665828227996826
Validation loss: 2.2511977226503435

Epoch: 6| Step: 4
Training loss: 3.165053367614746
Validation loss: 2.2378905050216185

Epoch: 6| Step: 5
Training loss: 2.146104335784912
Validation loss: 2.201088014469352

Epoch: 6| Step: 6
Training loss: 2.3778233528137207
Validation loss: 2.186068270796089

Epoch: 6| Step: 7
Training loss: 2.6303868293762207
Validation loss: 2.1816791129368607

Epoch: 6| Step: 8
Training loss: 2.3218398094177246
Validation loss: 2.1907293104356333

Epoch: 6| Step: 9
Training loss: 2.453141689300537
Validation loss: 2.1992987804515387

Epoch: 6| Step: 10
Training loss: 2.3312625885009766
Validation loss: 2.199213389427431

Epoch: 6| Step: 11
Training loss: 2.6524980068206787
Validation loss: 2.219327254961896

Epoch: 6| Step: 12
Training loss: 2.118354320526123
Validation loss: 2.263282986097438

Epoch: 6| Step: 13
Training loss: 4.205156326293945
Validation loss: 2.2722440406840336

Epoch: 88| Step: 0
Training loss: 3.0591039657592773
Validation loss: 2.2552230229941745

Epoch: 6| Step: 1
Training loss: 2.635946750640869
Validation loss: 2.220015448908652

Epoch: 6| Step: 2
Training loss: 1.7778403759002686
Validation loss: 2.1962178907086773

Epoch: 6| Step: 3
Training loss: 2.4691519737243652
Validation loss: 2.1885624008793987

Epoch: 6| Step: 4
Training loss: 2.6074061393737793
Validation loss: 2.1721055276932253

Epoch: 6| Step: 5
Training loss: 2.059563159942627
Validation loss: 2.1693539106717674

Epoch: 6| Step: 6
Training loss: 2.813894271850586
Validation loss: 2.1754793261968963

Epoch: 6| Step: 7
Training loss: 2.2673845291137695
Validation loss: 2.17398581453549

Epoch: 6| Step: 8
Training loss: 2.9030256271362305
Validation loss: 2.174279278324496

Epoch: 6| Step: 9
Training loss: 2.359457015991211
Validation loss: 2.177476450961123

Epoch: 6| Step: 10
Training loss: 2.1616079807281494
Validation loss: 2.1758976982485865

Epoch: 6| Step: 11
Training loss: 1.825073480606079
Validation loss: 2.1783745160666843

Epoch: 6| Step: 12
Training loss: 2.9539074897766113
Validation loss: 2.175339011735814

Epoch: 6| Step: 13
Training loss: 3.1137590408325195
Validation loss: 2.1728680646547707

Epoch: 89| Step: 0
Training loss: 2.511335611343384
Validation loss: 2.187043410475536

Epoch: 6| Step: 1
Training loss: 1.7519551515579224
Validation loss: 2.193543900725662

Epoch: 6| Step: 2
Training loss: 2.0145201683044434
Validation loss: 2.201484198211342

Epoch: 6| Step: 3
Training loss: 2.3233578205108643
Validation loss: 2.197894584748053

Epoch: 6| Step: 4
Training loss: 1.9905617237091064
Validation loss: 2.1997641747997654

Epoch: 6| Step: 5
Training loss: 2.3306031227111816
Validation loss: 2.196096948398057

Epoch: 6| Step: 6
Training loss: 2.565845012664795
Validation loss: 2.1849969356290755

Epoch: 6| Step: 7
Training loss: 2.768892765045166
Validation loss: 2.18941157351258

Epoch: 6| Step: 8
Training loss: 2.4746909141540527
Validation loss: 2.18164272333986

Epoch: 6| Step: 9
Training loss: 2.913968086242676
Validation loss: 2.169568415611021

Epoch: 6| Step: 10
Training loss: 2.712614059448242
Validation loss: 2.1718787121516403

Epoch: 6| Step: 11
Training loss: 3.066699504852295
Validation loss: 2.1617497705644175

Epoch: 6| Step: 12
Training loss: 2.6837406158447266
Validation loss: 2.162728927468741

Epoch: 6| Step: 13
Training loss: 2.3270750045776367
Validation loss: 2.1581441779290476

Epoch: 90| Step: 0
Training loss: 2.911342144012451
Validation loss: 2.1532237657936673

Epoch: 6| Step: 1
Training loss: 2.7990126609802246
Validation loss: 2.1552808810305852

Epoch: 6| Step: 2
Training loss: 2.23463773727417
Validation loss: 2.1577015615278676

Epoch: 6| Step: 3
Training loss: 2.956305503845215
Validation loss: 2.1691811674384662

Epoch: 6| Step: 4
Training loss: 2.0357847213745117
Validation loss: 2.1733405077329246

Epoch: 6| Step: 5
Training loss: 2.4805984497070312
Validation loss: 2.177728626035875

Epoch: 6| Step: 6
Training loss: 2.380201578140259
Validation loss: 2.1882630061077815

Epoch: 6| Step: 7
Training loss: 2.374251127243042
Validation loss: 2.1720883795010146

Epoch: 6| Step: 8
Training loss: 2.6576991081237793
Validation loss: 2.178550748414891

Epoch: 6| Step: 9
Training loss: 2.0739104747772217
Validation loss: 2.1684445155564176

Epoch: 6| Step: 10
Training loss: 1.760511875152588
Validation loss: 2.181776882499777

Epoch: 6| Step: 11
Training loss: 3.155137062072754
Validation loss: 2.1814159218982985

Epoch: 6| Step: 12
Training loss: 2.552290439605713
Validation loss: 2.1805449070469027

Epoch: 6| Step: 13
Training loss: 1.8806512355804443
Validation loss: 2.1816369077210784

Epoch: 91| Step: 0
Training loss: 2.5432419776916504
Validation loss: 2.188319365183512

Epoch: 6| Step: 1
Training loss: 2.7349157333374023
Validation loss: 2.196699662875104

Epoch: 6| Step: 2
Training loss: 3.174311876296997
Validation loss: 2.1940219299767607

Epoch: 6| Step: 3
Training loss: 2.3996121883392334
Validation loss: 2.2098713023688203

Epoch: 6| Step: 4
Training loss: 2.5862183570861816
Validation loss: 2.206684071530578

Epoch: 6| Step: 5
Training loss: 2.1860766410827637
Validation loss: 2.2039074513220016

Epoch: 6| Step: 6
Training loss: 2.718681812286377
Validation loss: 2.1785962709816555

Epoch: 6| Step: 7
Training loss: 2.166736125946045
Validation loss: 2.1696630498414398

Epoch: 6| Step: 8
Training loss: 2.0495645999908447
Validation loss: 2.152869619348998

Epoch: 6| Step: 9
Training loss: 2.7020554542541504
Validation loss: 2.15244532656926

Epoch: 6| Step: 10
Training loss: 2.2692956924438477
Validation loss: 2.151969535376436

Epoch: 6| Step: 11
Training loss: 1.9804158210754395
Validation loss: 2.15238324416581

Epoch: 6| Step: 12
Training loss: 2.929861545562744
Validation loss: 2.165387212589223

Epoch: 6| Step: 13
Training loss: 1.6565017700195312
Validation loss: 2.1738580811408257

Epoch: 92| Step: 0
Training loss: 2.8173155784606934
Validation loss: 2.178105934973686

Epoch: 6| Step: 1
Training loss: 2.223437547683716
Validation loss: 2.1682471101002028

Epoch: 6| Step: 2
Training loss: 2.7569289207458496
Validation loss: 2.1666165500558834

Epoch: 6| Step: 3
Training loss: 2.0384743213653564
Validation loss: 2.1684291849854174

Epoch: 6| Step: 4
Training loss: 2.447239398956299
Validation loss: 2.170711504515781

Epoch: 6| Step: 5
Training loss: 2.443999767303467
Validation loss: 2.190680919154998

Epoch: 6| Step: 6
Training loss: 2.173750638961792
Validation loss: 2.187670338538385

Epoch: 6| Step: 7
Training loss: 1.8080867528915405
Validation loss: 2.191470253852106

Epoch: 6| Step: 8
Training loss: 2.1778833866119385
Validation loss: 2.2127227629384687

Epoch: 6| Step: 9
Training loss: 1.901280403137207
Validation loss: 2.2339164108358402

Epoch: 6| Step: 10
Training loss: 2.6681947708129883
Validation loss: 2.2227474899702173

Epoch: 6| Step: 11
Training loss: 2.868497848510742
Validation loss: 2.2045556294020785

Epoch: 6| Step: 12
Training loss: 3.636842727661133
Validation loss: 2.2033961793427825

Epoch: 6| Step: 13
Training loss: 2.837325096130371
Validation loss: 2.188826068755119

Epoch: 93| Step: 0
Training loss: 2.298694610595703
Validation loss: 2.1723873589628484

Epoch: 6| Step: 1
Training loss: 2.4070212841033936
Validation loss: 2.161642200203352

Epoch: 6| Step: 2
Training loss: 1.7436367273330688
Validation loss: 2.15894829329624

Epoch: 6| Step: 3
Training loss: 3.1474971771240234
Validation loss: 2.157960904541836

Epoch: 6| Step: 4
Training loss: 3.224468231201172
Validation loss: 2.152580350957891

Epoch: 6| Step: 5
Training loss: 2.7366018295288086
Validation loss: 2.14126129047845

Epoch: 6| Step: 6
Training loss: 2.519428014755249
Validation loss: 2.144878110577983

Epoch: 6| Step: 7
Training loss: 2.4977145195007324
Validation loss: 2.141461697957849

Epoch: 6| Step: 8
Training loss: 2.1117703914642334
Validation loss: 2.1446073849995932

Epoch: 6| Step: 9
Training loss: 2.638760805130005
Validation loss: 2.1484680560327347

Epoch: 6| Step: 10
Training loss: 2.2885923385620117
Validation loss: 2.158763949589063

Epoch: 6| Step: 11
Training loss: 2.0320615768432617
Validation loss: 2.1691075319884927

Epoch: 6| Step: 12
Training loss: 2.178884983062744
Validation loss: 2.18851347507969

Epoch: 6| Step: 13
Training loss: 2.849776029586792
Validation loss: 2.1958779224785427

Epoch: 94| Step: 0
Training loss: 2.6543679237365723
Validation loss: 2.2046204279827815

Epoch: 6| Step: 1
Training loss: 2.37500262260437
Validation loss: 2.1968349205550326

Epoch: 6| Step: 2
Training loss: 2.369025468826294
Validation loss: 2.179689766258322

Epoch: 6| Step: 3
Training loss: 2.1257829666137695
Validation loss: 2.184902832072268

Epoch: 6| Step: 4
Training loss: 2.7288882732391357
Validation loss: 2.184353341338455

Epoch: 6| Step: 5
Training loss: 2.873483657836914
Validation loss: 2.1603214792025986

Epoch: 6| Step: 6
Training loss: 2.4382975101470947
Validation loss: 2.1631776543073755

Epoch: 6| Step: 7
Training loss: 1.712715983390808
Validation loss: 2.1646574184458744

Epoch: 6| Step: 8
Training loss: 2.3192005157470703
Validation loss: 2.1666239538500385

Epoch: 6| Step: 9
Training loss: 2.364764451980591
Validation loss: 2.154207921797229

Epoch: 6| Step: 10
Training loss: 1.851518988609314
Validation loss: 2.142726516210905

Epoch: 6| Step: 11
Training loss: 2.650622844696045
Validation loss: 2.1436961427811654

Epoch: 6| Step: 12
Training loss: 2.9878509044647217
Validation loss: 2.1353156002618934

Epoch: 6| Step: 13
Training loss: 2.9402966499328613
Validation loss: 2.1297097013842676

Epoch: 95| Step: 0
Training loss: 2.6295690536499023
Validation loss: 2.1334643992044593

Epoch: 6| Step: 1
Training loss: 2.7590785026550293
Validation loss: 2.1464463228820474

Epoch: 6| Step: 2
Training loss: 3.044610023498535
Validation loss: 2.153240943467745

Epoch: 6| Step: 3
Training loss: 2.2692503929138184
Validation loss: 2.1634897083364506

Epoch: 6| Step: 4
Training loss: 2.3500027656555176
Validation loss: 2.157308506709273

Epoch: 6| Step: 5
Training loss: 2.1635005474090576
Validation loss: 2.1701705724962297

Epoch: 6| Step: 6
Training loss: 2.0513312816619873
Validation loss: 2.1699455886758785

Epoch: 6| Step: 7
Training loss: 2.535228967666626
Validation loss: 2.1672816250913884

Epoch: 6| Step: 8
Training loss: 2.5593037605285645
Validation loss: 2.1735944953016055

Epoch: 6| Step: 9
Training loss: 2.17930269241333
Validation loss: 2.177244287665172

Epoch: 6| Step: 10
Training loss: 2.4366745948791504
Validation loss: 2.189617577419486

Epoch: 6| Step: 11
Training loss: 2.361937999725342
Validation loss: 2.2262536351398756

Epoch: 6| Step: 12
Training loss: 2.212369203567505
Validation loss: 2.2553238355985252

Epoch: 6| Step: 13
Training loss: 2.7085981369018555
Validation loss: 2.2150426833860335

Epoch: 96| Step: 0
Training loss: 2.5023603439331055
Validation loss: 2.2053032998115785

Epoch: 6| Step: 1
Training loss: 1.673896074295044
Validation loss: 2.1749598313403387

Epoch: 6| Step: 2
Training loss: 2.2051944732666016
Validation loss: 2.151992695305937

Epoch: 6| Step: 3
Training loss: 2.822861909866333
Validation loss: 2.1493146124706475

Epoch: 6| Step: 4
Training loss: 2.630990505218506
Validation loss: 2.140701199090609

Epoch: 6| Step: 5
Training loss: 2.687519073486328
Validation loss: 2.137620020938176

Epoch: 6| Step: 6
Training loss: 2.537705421447754
Validation loss: 2.142835212010209

Epoch: 6| Step: 7
Training loss: 2.8573763370513916
Validation loss: 2.150889790186318

Epoch: 6| Step: 8
Training loss: 2.3235557079315186
Validation loss: 2.1519410571744366

Epoch: 6| Step: 9
Training loss: 2.154512405395508
Validation loss: 2.1618115030309206

Epoch: 6| Step: 10
Training loss: 2.4236316680908203
Validation loss: 2.171153376179357

Epoch: 6| Step: 11
Training loss: 2.605419635772705
Validation loss: 2.1709213000471874

Epoch: 6| Step: 12
Training loss: 1.8289124965667725
Validation loss: 2.176365151200243

Epoch: 6| Step: 13
Training loss: 3.376452922821045
Validation loss: 2.1635164650537635

Epoch: 97| Step: 0
Training loss: 2.6475517749786377
Validation loss: 2.1362142819230274

Epoch: 6| Step: 1
Training loss: 2.5441017150878906
Validation loss: 2.1318202839102796

Epoch: 6| Step: 2
Training loss: 2.17098069190979
Validation loss: 2.122105267740065

Epoch: 6| Step: 3
Training loss: 1.9500231742858887
Validation loss: 2.1179575766286542

Epoch: 6| Step: 4
Training loss: 2.2768051624298096
Validation loss: 2.118161165586082

Epoch: 6| Step: 5
Training loss: 3.3240573406219482
Validation loss: 2.1264574271376415

Epoch: 6| Step: 6
Training loss: 2.4023942947387695
Validation loss: 2.151335664974746

Epoch: 6| Step: 7
Training loss: 2.3485493659973145
Validation loss: 2.1497115627411874

Epoch: 6| Step: 8
Training loss: 2.357337474822998
Validation loss: 2.130930157117946

Epoch: 6| Step: 9
Training loss: 2.9279894828796387
Validation loss: 2.1063360680815992

Epoch: 6| Step: 10
Training loss: 2.8604352474212646
Validation loss: 2.1097489377503753

Epoch: 6| Step: 11
Training loss: 2.276331663131714
Validation loss: 2.113323119378859

Epoch: 6| Step: 12
Training loss: 1.8316172361373901
Validation loss: 2.1179247799740044

Epoch: 6| Step: 13
Training loss: 2.3588707447052
Validation loss: 2.1300276530686246

Epoch: 98| Step: 0
Training loss: 1.7658751010894775
Validation loss: 2.1842745093889135

Epoch: 6| Step: 1
Training loss: 2.158700942993164
Validation loss: 2.256868149644585

Epoch: 6| Step: 2
Training loss: 2.6166775226593018
Validation loss: 2.2825215016641924

Epoch: 6| Step: 3
Training loss: 2.5110459327697754
Validation loss: 2.2132975824417604

Epoch: 6| Step: 4
Training loss: 1.907996654510498
Validation loss: 2.199214317465341

Epoch: 6| Step: 5
Training loss: 2.0529558658599854
Validation loss: 2.1465854696048203

Epoch: 6| Step: 6
Training loss: 2.5713024139404297
Validation loss: 2.131540431771227

Epoch: 6| Step: 7
Training loss: 2.9229273796081543
Validation loss: 2.1310762551523026

Epoch: 6| Step: 8
Training loss: 2.349052906036377
Validation loss: 2.119768797710378

Epoch: 6| Step: 9
Training loss: 2.6932544708251953
Validation loss: 2.1349641251307663

Epoch: 6| Step: 10
Training loss: 2.424720525741577
Validation loss: 2.1528838629363687

Epoch: 6| Step: 11
Training loss: 2.6993308067321777
Validation loss: 2.168208368362919

Epoch: 6| Step: 12
Training loss: 2.7874321937561035
Validation loss: 2.173943522155926

Epoch: 6| Step: 13
Training loss: 3.062753438949585
Validation loss: 2.1711819069359892

Epoch: 99| Step: 0
Training loss: 2.30954647064209
Validation loss: 2.1618522059532905

Epoch: 6| Step: 1
Training loss: 2.6040589809417725
Validation loss: 2.16121321083397

Epoch: 6| Step: 2
Training loss: 2.039372682571411
Validation loss: 2.135706432404057

Epoch: 6| Step: 3
Training loss: 1.9949816465377808
Validation loss: 2.1173636169843775

Epoch: 6| Step: 4
Training loss: 2.567014217376709
Validation loss: 2.1088014776988695

Epoch: 6| Step: 5
Training loss: 2.3204991817474365
Validation loss: 2.125129329260959

Epoch: 6| Step: 6
Training loss: 2.4236574172973633
Validation loss: 2.1387398986406225

Epoch: 6| Step: 7
Training loss: 2.031740665435791
Validation loss: 2.1642549089206162

Epoch: 6| Step: 8
Training loss: 2.8977437019348145
Validation loss: 2.2204572616084928

Epoch: 6| Step: 9
Training loss: 2.606433153152466
Validation loss: 2.2651368084774224

Epoch: 6| Step: 10
Training loss: 2.579740524291992
Validation loss: 2.2844029549629457

Epoch: 6| Step: 11
Training loss: 3.0595593452453613
Validation loss: 2.292863817625148

Epoch: 6| Step: 12
Training loss: 2.5904226303100586
Validation loss: 2.279047396875197

Epoch: 6| Step: 13
Training loss: 2.708994150161743
Validation loss: 2.2413342768146145

Epoch: 100| Step: 0
Training loss: 2.358010768890381
Validation loss: 2.18298626202409

Epoch: 6| Step: 1
Training loss: 2.3442740440368652
Validation loss: 2.1484223988748368

Epoch: 6| Step: 2
Training loss: 1.5257468223571777
Validation loss: 2.1334447347989647

Epoch: 6| Step: 3
Training loss: 2.5361504554748535
Validation loss: 2.123315918830133

Epoch: 6| Step: 4
Training loss: 2.463966131210327
Validation loss: 2.117021127413678

Epoch: 6| Step: 5
Training loss: 2.6488335132598877
Validation loss: 2.1164110757971324

Epoch: 6| Step: 6
Training loss: 2.2194056510925293
Validation loss: 2.110534733341586

Epoch: 6| Step: 7
Training loss: 2.5455482006073
Validation loss: 2.1187830048222698

Epoch: 6| Step: 8
Training loss: 2.9271576404571533
Validation loss: 2.12924515047381

Epoch: 6| Step: 9
Training loss: 2.123288631439209
Validation loss: 2.1270135077097083

Epoch: 6| Step: 10
Training loss: 2.642120838165283
Validation loss: 2.131022760944982

Epoch: 6| Step: 11
Training loss: 3.0554699897766113
Validation loss: 2.124297498374857

Epoch: 6| Step: 12
Training loss: 2.386247158050537
Validation loss: 2.129480097883491

Epoch: 6| Step: 13
Training loss: 1.7729634046554565
Validation loss: 2.1153140606418734

Epoch: 101| Step: 0
Training loss: 2.1547892093658447
Validation loss: 2.130553037889542

Epoch: 6| Step: 1
Training loss: 2.206799030303955
Validation loss: 2.1495772471991916

Epoch: 6| Step: 2
Training loss: 2.335520029067993
Validation loss: 2.1730638729628695

Epoch: 6| Step: 3
Training loss: 2.8368701934814453
Validation loss: 2.1598285821176346

Epoch: 6| Step: 4
Training loss: 2.075108528137207
Validation loss: 2.137397227748748

Epoch: 6| Step: 5
Training loss: 2.1392059326171875
Validation loss: 2.114351728911041

Epoch: 6| Step: 6
Training loss: 2.2286171913146973
Validation loss: 2.1089142343049407

Epoch: 6| Step: 7
Training loss: 2.3354909420013428
Validation loss: 2.096703957485896

Epoch: 6| Step: 8
Training loss: 2.3913140296936035
Validation loss: 2.0933197903376755

Epoch: 6| Step: 9
Training loss: 2.905425786972046
Validation loss: 2.102175863840247

Epoch: 6| Step: 10
Training loss: 2.519707202911377
Validation loss: 2.1031404413202757

Epoch: 6| Step: 11
Training loss: 1.9619030952453613
Validation loss: 2.1034362008494716

Epoch: 6| Step: 12
Training loss: 3.429905891418457
Validation loss: 2.1013485129161547

Epoch: 6| Step: 13
Training loss: 2.392977237701416
Validation loss: 2.0981201882003457

Epoch: 102| Step: 0
Training loss: 3.486083984375
Validation loss: 2.1008974813645884

Epoch: 6| Step: 1
Training loss: 2.6855852603912354
Validation loss: 2.1079737806832917

Epoch: 6| Step: 2
Training loss: 2.0395240783691406
Validation loss: 2.158987973325996

Epoch: 6| Step: 3
Training loss: 2.274266242980957
Validation loss: 2.2001958470190726

Epoch: 6| Step: 4
Training loss: 2.1840004920959473
Validation loss: 2.2214887295999834

Epoch: 6| Step: 5
Training loss: 2.7677435874938965
Validation loss: 2.2674729516429286

Epoch: 6| Step: 6
Training loss: 2.7593331336975098
Validation loss: 2.211897309108447

Epoch: 6| Step: 7
Training loss: 2.2072830200195312
Validation loss: 2.164967357471425

Epoch: 6| Step: 8
Training loss: 1.615739345550537
Validation loss: 2.124061099944576

Epoch: 6| Step: 9
Training loss: 2.563560962677002
Validation loss: 2.1125559473550446

Epoch: 6| Step: 10
Training loss: 2.719095230102539
Validation loss: 2.104161734222084

Epoch: 6| Step: 11
Training loss: 1.755889654159546
Validation loss: 2.097103721352034

Epoch: 6| Step: 12
Training loss: 2.7885401248931885
Validation loss: 2.1051647637480047

Epoch: 6| Step: 13
Training loss: 1.7626783847808838
Validation loss: 2.0962113270195584

Epoch: 103| Step: 0
Training loss: 2.674823760986328
Validation loss: 2.1007718527188866

Epoch: 6| Step: 1
Training loss: 2.448591709136963
Validation loss: 2.106404382695434

Epoch: 6| Step: 2
Training loss: 2.3458895683288574
Validation loss: 2.114803412909149

Epoch: 6| Step: 3
Training loss: 2.2414276599884033
Validation loss: 2.1214362677707466

Epoch: 6| Step: 4
Training loss: 2.657808542251587
Validation loss: 2.1204071121831096

Epoch: 6| Step: 5
Training loss: 2.758488178253174
Validation loss: 2.145913726540022

Epoch: 6| Step: 6
Training loss: 2.0836734771728516
Validation loss: 2.1626611832649476

Epoch: 6| Step: 7
Training loss: 2.875967025756836
Validation loss: 2.184016230285809

Epoch: 6| Step: 8
Training loss: 2.879176616668701
Validation loss: 2.1857702988450245

Epoch: 6| Step: 9
Training loss: 1.3495161533355713
Validation loss: 2.176714866392074

Epoch: 6| Step: 10
Training loss: 2.0233049392700195
Validation loss: 2.169579731520786

Epoch: 6| Step: 11
Training loss: 2.575474500656128
Validation loss: 2.160562325549382

Epoch: 6| Step: 12
Training loss: 2.5951766967773438
Validation loss: 2.1374564581019904

Epoch: 6| Step: 13
Training loss: 1.9618772268295288
Validation loss: 2.120188646419074

Epoch: 104| Step: 0
Training loss: 2.216886520385742
Validation loss: 2.110971132914225

Epoch: 6| Step: 1
Training loss: 2.4402403831481934
Validation loss: 2.1129741079063824

Epoch: 6| Step: 2
Training loss: 2.8636274337768555
Validation loss: 2.125838612997404

Epoch: 6| Step: 3
Training loss: 2.485013246536255
Validation loss: 2.180067221323649

Epoch: 6| Step: 4
Training loss: 2.9771106243133545
Validation loss: 2.236730275615569

Epoch: 6| Step: 5
Training loss: 2.252943992614746
Validation loss: 2.247327599474179

Epoch: 6| Step: 6
Training loss: 3.1037492752075195
Validation loss: 2.1947618094823693

Epoch: 6| Step: 7
Training loss: 2.360459327697754
Validation loss: 2.123462874402282

Epoch: 6| Step: 8
Training loss: 2.120605945587158
Validation loss: 2.0817326448296987

Epoch: 6| Step: 9
Training loss: 2.360816478729248
Validation loss: 2.083249597139256

Epoch: 6| Step: 10
Training loss: 2.3221054077148438
Validation loss: 2.1326635358154133

Epoch: 6| Step: 11
Training loss: 1.7353559732437134
Validation loss: 2.194773374065276

Epoch: 6| Step: 12
Training loss: 3.1204724311828613
Validation loss: 2.2275507706467823

Epoch: 6| Step: 13
Training loss: 2.4406933784484863
Validation loss: 2.2478372704598213

Epoch: 105| Step: 0
Training loss: 2.2072031497955322
Validation loss: 2.2241949060911774

Epoch: 6| Step: 1
Training loss: 2.972937822341919
Validation loss: 2.171897634383171

Epoch: 6| Step: 2
Training loss: 2.027782440185547
Validation loss: 2.113861962031293

Epoch: 6| Step: 3
Training loss: 2.8341689109802246
Validation loss: 2.090388621053388

Epoch: 6| Step: 4
Training loss: 2.1117804050445557
Validation loss: 2.0744043293819634

Epoch: 6| Step: 5
Training loss: 2.5952186584472656
Validation loss: 2.06495270165064

Epoch: 6| Step: 6
Training loss: 2.8457674980163574
Validation loss: 2.0629853022995817

Epoch: 6| Step: 7
Training loss: 1.8136545419692993
Validation loss: 2.057611737200009

Epoch: 6| Step: 8
Training loss: 2.720459461212158
Validation loss: 2.064676277099117

Epoch: 6| Step: 9
Training loss: 2.357454299926758
Validation loss: 2.056263323753111

Epoch: 6| Step: 10
Training loss: 2.131723403930664
Validation loss: 2.061141303790513

Epoch: 6| Step: 11
Training loss: 2.8621292114257812
Validation loss: 2.0718433831327703

Epoch: 6| Step: 12
Training loss: 2.0518784523010254
Validation loss: 2.1036802325197446

Epoch: 6| Step: 13
Training loss: 2.056605100631714
Validation loss: 2.129410811649856

Epoch: 106| Step: 0
Training loss: 2.64918851852417
Validation loss: 2.1271367278150333

Epoch: 6| Step: 1
Training loss: 2.393758773803711
Validation loss: 2.1024440257780013

Epoch: 6| Step: 2
Training loss: 2.7851343154907227
Validation loss: 2.1133929068042385

Epoch: 6| Step: 3
Training loss: 1.5629090070724487
Validation loss: 2.0967812820147445

Epoch: 6| Step: 4
Training loss: 2.737409830093384
Validation loss: 2.0745851737196728

Epoch: 6| Step: 5
Training loss: 2.3881993293762207
Validation loss: 2.0768425567175752

Epoch: 6| Step: 6
Training loss: 2.421643018722534
Validation loss: 2.073941938338741

Epoch: 6| Step: 7
Training loss: 1.6211357116699219
Validation loss: 2.0625501909563617

Epoch: 6| Step: 8
Training loss: 2.8023393154144287
Validation loss: 2.0679951995931645

Epoch: 6| Step: 9
Training loss: 2.922321319580078
Validation loss: 2.067442782463566

Epoch: 6| Step: 10
Training loss: 2.6697309017181396
Validation loss: 2.065144549133957

Epoch: 6| Step: 11
Training loss: 2.461073637008667
Validation loss: 2.068055014456472

Epoch: 6| Step: 12
Training loss: 1.8368234634399414
Validation loss: 2.074331332278508

Epoch: 6| Step: 13
Training loss: 2.4847748279571533
Validation loss: 2.077249305222624

Epoch: 107| Step: 0
Training loss: 1.6909606456756592
Validation loss: 2.0885781165092223

Epoch: 6| Step: 1
Training loss: 2.375995635986328
Validation loss: 2.094952191075971

Epoch: 6| Step: 2
Training loss: 2.626626968383789
Validation loss: 2.1115007041603007

Epoch: 6| Step: 3
Training loss: 2.5803539752960205
Validation loss: 2.1282069580529326

Epoch: 6| Step: 4
Training loss: 1.932921290397644
Validation loss: 2.154382590324648

Epoch: 6| Step: 5
Training loss: 2.2619733810424805
Validation loss: 2.1798347888454312

Epoch: 6| Step: 6
Training loss: 1.7053239345550537
Validation loss: 2.1918882554577244

Epoch: 6| Step: 7
Training loss: 2.7480993270874023
Validation loss: 2.203083577976432

Epoch: 6| Step: 8
Training loss: 2.796658515930176
Validation loss: 2.1758809499843146

Epoch: 6| Step: 9
Training loss: 2.3571715354919434
Validation loss: 2.1483265174332487

Epoch: 6| Step: 10
Training loss: 2.6375274658203125
Validation loss: 2.122207236546342

Epoch: 6| Step: 11
Training loss: 2.9710254669189453
Validation loss: 2.1069499664409186

Epoch: 6| Step: 12
Training loss: 2.6879167556762695
Validation loss: 2.1069512008338847

Epoch: 6| Step: 13
Training loss: 1.9748213291168213
Validation loss: 2.0938851141160533

Epoch: 108| Step: 0
Training loss: 2.2159998416900635
Validation loss: 2.067620228695613

Epoch: 6| Step: 1
Training loss: 2.642226219177246
Validation loss: 2.0708152683832313

Epoch: 6| Step: 2
Training loss: 2.306344509124756
Validation loss: 2.062932788684804

Epoch: 6| Step: 3
Training loss: 1.9779995679855347
Validation loss: 2.0591619194194837

Epoch: 6| Step: 4
Training loss: 3.0178287029266357
Validation loss: 2.067295753827659

Epoch: 6| Step: 5
Training loss: 2.090149402618408
Validation loss: 2.0646137217039704

Epoch: 6| Step: 6
Training loss: 1.7854747772216797
Validation loss: 2.070788456547645

Epoch: 6| Step: 7
Training loss: 2.2954697608947754
Validation loss: 2.0677880241024877

Epoch: 6| Step: 8
Training loss: 2.792738199234009
Validation loss: 2.066442715224399

Epoch: 6| Step: 9
Training loss: 2.435941219329834
Validation loss: 2.086907458561723

Epoch: 6| Step: 10
Training loss: 2.055713653564453
Validation loss: 2.0860388009778914

Epoch: 6| Step: 11
Training loss: 2.5225768089294434
Validation loss: 2.0840703415614303

Epoch: 6| Step: 12
Training loss: 2.514514684677124
Validation loss: 2.099927007511098

Epoch: 6| Step: 13
Training loss: 2.8053529262542725
Validation loss: 2.0972806817741803

Epoch: 109| Step: 0
Training loss: 2.5342352390289307
Validation loss: 2.08673184405091

Epoch: 6| Step: 1
Training loss: 2.652463674545288
Validation loss: 2.090384775592435

Epoch: 6| Step: 2
Training loss: 1.8317807912826538
Validation loss: 2.092648417718949

Epoch: 6| Step: 3
Training loss: 2.078449010848999
Validation loss: 2.1003644979128273

Epoch: 6| Step: 4
Training loss: 2.2011754512786865
Validation loss: 2.116062541161814

Epoch: 6| Step: 5
Training loss: 2.289799928665161
Validation loss: 2.1224540138757355

Epoch: 6| Step: 6
Training loss: 2.08962345123291
Validation loss: 2.118964707979592

Epoch: 6| Step: 7
Training loss: 2.737168312072754
Validation loss: 2.106068641908707

Epoch: 6| Step: 8
Training loss: 2.344762086868286
Validation loss: 2.1022340456644693

Epoch: 6| Step: 9
Training loss: 2.8595714569091797
Validation loss: 2.096603952428346

Epoch: 6| Step: 10
Training loss: 2.0464789867401123
Validation loss: 2.067353544696685

Epoch: 6| Step: 11
Training loss: 2.7943429946899414
Validation loss: 2.0648758719044347

Epoch: 6| Step: 12
Training loss: 2.1451077461242676
Validation loss: 2.0569770771970033

Epoch: 6| Step: 13
Training loss: 2.497861623764038
Validation loss: 2.0664431202796196

Epoch: 110| Step: 0
Training loss: 2.467775344848633
Validation loss: 2.085270263815439

Epoch: 6| Step: 1
Training loss: 1.0934996604919434
Validation loss: 2.084353434142246

Epoch: 6| Step: 2
Training loss: 2.5493557453155518
Validation loss: 2.0861164767255067

Epoch: 6| Step: 3
Training loss: 2.677337646484375
Validation loss: 2.0821544483143795

Epoch: 6| Step: 4
Training loss: 2.548891544342041
Validation loss: 2.1110939172006424

Epoch: 6| Step: 5
Training loss: 2.1595687866210938
Validation loss: 2.1087960991808163

Epoch: 6| Step: 6
Training loss: 1.5660104751586914
Validation loss: 2.1192673893385034

Epoch: 6| Step: 7
Training loss: 2.662306547164917
Validation loss: 2.109854736635762

Epoch: 6| Step: 8
Training loss: 3.1501636505126953
Validation loss: 2.09771591360851

Epoch: 6| Step: 9
Training loss: 2.4041757583618164
Validation loss: 2.0975341527692732

Epoch: 6| Step: 10
Training loss: 2.5129733085632324
Validation loss: 2.0878455561976277

Epoch: 6| Step: 11
Training loss: 2.175095558166504
Validation loss: 2.095429184616253

Epoch: 6| Step: 12
Training loss: 2.718085289001465
Validation loss: 2.0969471393092984

Epoch: 6| Step: 13
Training loss: 2.276228666305542
Validation loss: 2.0866846397358882

Epoch: 111| Step: 0
Training loss: 1.9982874393463135
Validation loss: 2.090329780373522

Epoch: 6| Step: 1
Training loss: 2.6415529251098633
Validation loss: 2.0882201322945217

Epoch: 6| Step: 2
Training loss: 2.012981653213501
Validation loss: 2.0960509905251126

Epoch: 6| Step: 3
Training loss: 2.61846661567688
Validation loss: 2.093048918631769

Epoch: 6| Step: 4
Training loss: 2.470855712890625
Validation loss: 2.09829802666941

Epoch: 6| Step: 5
Training loss: 2.0051803588867188
Validation loss: 2.124836262836251

Epoch: 6| Step: 6
Training loss: 2.1635918617248535
Validation loss: 2.1227589832839144

Epoch: 6| Step: 7
Training loss: 2.3642959594726562
Validation loss: 2.1497565674525436

Epoch: 6| Step: 8
Training loss: 2.83998441696167
Validation loss: 2.1750237172649753

Epoch: 6| Step: 9
Training loss: 2.032283306121826
Validation loss: 2.1564145459923694

Epoch: 6| Step: 10
Training loss: 1.878949522972107
Validation loss: 2.1202568366963375

Epoch: 6| Step: 11
Training loss: 2.3511338233947754
Validation loss: 2.0841028844156573

Epoch: 6| Step: 12
Training loss: 3.13281512260437
Validation loss: 2.069448027559506

Epoch: 6| Step: 13
Training loss: 2.5638394355773926
Validation loss: 2.057245123770929

Epoch: 112| Step: 0
Training loss: 2.603048086166382
Validation loss: 2.048920944172849

Epoch: 6| Step: 1
Training loss: 2.205732822418213
Validation loss: 2.0614593657114173

Epoch: 6| Step: 2
Training loss: 2.6108925342559814
Validation loss: 2.0637984762909594

Epoch: 6| Step: 3
Training loss: 1.6592189073562622
Validation loss: 2.0667137381851033

Epoch: 6| Step: 4
Training loss: 2.3972225189208984
Validation loss: 2.064147241653935

Epoch: 6| Step: 5
Training loss: 2.18477725982666
Validation loss: 2.0575013186341975

Epoch: 6| Step: 6
Training loss: 2.0169832706451416
Validation loss: 2.0492051263009348

Epoch: 6| Step: 7
Training loss: 2.9628939628601074
Validation loss: 2.0421698298505557

Epoch: 6| Step: 8
Training loss: 1.7320252656936646
Validation loss: 2.0347071642516763

Epoch: 6| Step: 9
Training loss: 3.010538101196289
Validation loss: 2.063132602681396

Epoch: 6| Step: 10
Training loss: 2.218653917312622
Validation loss: 2.0717028494804137

Epoch: 6| Step: 11
Training loss: 2.172431468963623
Validation loss: 2.094391199850267

Epoch: 6| Step: 12
Training loss: 2.7515578269958496
Validation loss: 2.1136224026321084

Epoch: 6| Step: 13
Training loss: 2.7339959144592285
Validation loss: 2.134729472539758

Epoch: 113| Step: 0
Training loss: 1.9257099628448486
Validation loss: 2.1590866593904394

Epoch: 6| Step: 1
Training loss: 2.6841368675231934
Validation loss: 2.1929889776373424

Epoch: 6| Step: 2
Training loss: 2.864042043685913
Validation loss: 2.2245464991497736

Epoch: 6| Step: 3
Training loss: 1.8395317792892456
Validation loss: 2.231875809290076

Epoch: 6| Step: 4
Training loss: 1.8973357677459717
Validation loss: 2.273742104089388

Epoch: 6| Step: 5
Training loss: 1.8854330778121948
Validation loss: 2.2387118954812326

Epoch: 6| Step: 6
Training loss: 2.0152649879455566
Validation loss: 2.22007365252382

Epoch: 6| Step: 7
Training loss: 2.8851089477539062
Validation loss: 2.1569200613165416

Epoch: 6| Step: 8
Training loss: 2.292924404144287
Validation loss: 2.110145370165507

Epoch: 6| Step: 9
Training loss: 1.793052315711975
Validation loss: 2.080070585332891

Epoch: 6| Step: 10
Training loss: 2.6916165351867676
Validation loss: 2.0752217115894442

Epoch: 6| Step: 11
Training loss: 2.9329168796539307
Validation loss: 2.063698817324895

Epoch: 6| Step: 12
Training loss: 2.8866467475891113
Validation loss: 2.071789236478908

Epoch: 6| Step: 13
Training loss: 2.462881326675415
Validation loss: 2.0748232795346166

Epoch: 114| Step: 0
Training loss: 2.3449764251708984
Validation loss: 2.0982093349579842

Epoch: 6| Step: 1
Training loss: 2.9043526649475098
Validation loss: 2.1122977605430027

Epoch: 6| Step: 2
Training loss: 2.6701083183288574
Validation loss: 2.102502406284373

Epoch: 6| Step: 3
Training loss: 2.8432700634002686
Validation loss: 2.0852254283043647

Epoch: 6| Step: 4
Training loss: 2.692875623703003
Validation loss: 2.064633651446271

Epoch: 6| Step: 5
Training loss: 2.48867130279541
Validation loss: 2.058038309056272

Epoch: 6| Step: 6
Training loss: 2.0505757331848145
Validation loss: 2.0487124368708622

Epoch: 6| Step: 7
Training loss: 2.1207642555236816
Validation loss: 2.064009435715214

Epoch: 6| Step: 8
Training loss: 1.736363410949707
Validation loss: 2.073546196824761

Epoch: 6| Step: 9
Training loss: 1.7086737155914307
Validation loss: 2.0918317392308223

Epoch: 6| Step: 10
Training loss: 3.2105212211608887
Validation loss: 2.150187785907458

Epoch: 6| Step: 11
Training loss: 1.9407068490982056
Validation loss: 2.128315823052519

Epoch: 6| Step: 12
Training loss: 2.3676419258117676
Validation loss: 2.1321761479941745

Epoch: 6| Step: 13
Training loss: 1.7881131172180176
Validation loss: 2.1123758951822915

Epoch: 115| Step: 0
Training loss: 2.5357584953308105
Validation loss: 2.084501894571448

Epoch: 6| Step: 1
Training loss: 1.4460387229919434
Validation loss: 2.0611976449207594

Epoch: 6| Step: 2
Training loss: 2.6189146041870117
Validation loss: 2.0408748272926576

Epoch: 6| Step: 3
Training loss: 1.3511887788772583
Validation loss: 2.0409472821861185

Epoch: 6| Step: 4
Training loss: 2.6839587688446045
Validation loss: 2.0342757368600495

Epoch: 6| Step: 5
Training loss: 2.24539852142334
Validation loss: 2.0464681322856615

Epoch: 6| Step: 6
Training loss: 2.8044722080230713
Validation loss: 2.0559086620166735

Epoch: 6| Step: 7
Training loss: 2.6024954319000244
Validation loss: 2.0730002439150246

Epoch: 6| Step: 8
Training loss: 2.462477684020996
Validation loss: 2.11211036866711

Epoch: 6| Step: 9
Training loss: 1.9211761951446533
Validation loss: 2.1543978542409916

Epoch: 6| Step: 10
Training loss: 3.0156524181365967
Validation loss: 2.2258016114593833

Epoch: 6| Step: 11
Training loss: 2.8709864616394043
Validation loss: 2.147025659520139

Epoch: 6| Step: 12
Training loss: 2.086000919342041
Validation loss: 2.0748118123700543

Epoch: 6| Step: 13
Training loss: 2.686262369155884
Validation loss: 2.071021338944794

Epoch: 116| Step: 0
Training loss: 2.6351938247680664
Validation loss: 2.1061459356738674

Epoch: 6| Step: 1
Training loss: 1.9956789016723633
Validation loss: 2.1685238525431645

Epoch: 6| Step: 2
Training loss: 2.541548728942871
Validation loss: 2.222766322474326

Epoch: 6| Step: 3
Training loss: 2.8489692211151123
Validation loss: 2.267007149675841

Epoch: 6| Step: 4
Training loss: 2.35459041595459
Validation loss: 2.259960077142203

Epoch: 6| Step: 5
Training loss: 2.2044525146484375
Validation loss: 2.2111536674602057

Epoch: 6| Step: 6
Training loss: 3.071913242340088
Validation loss: 2.159095800051125

Epoch: 6| Step: 7
Training loss: 2.192610025405884
Validation loss: 2.1175877458305767

Epoch: 6| Step: 8
Training loss: 1.4779162406921387
Validation loss: 2.0904189873767156

Epoch: 6| Step: 9
Training loss: 1.7356104850769043
Validation loss: 2.075650143366988

Epoch: 6| Step: 10
Training loss: 2.6239631175994873
Validation loss: 2.0710836661759244

Epoch: 6| Step: 11
Training loss: 2.620102643966675
Validation loss: 2.0642723216805408

Epoch: 6| Step: 12
Training loss: 2.2292280197143555
Validation loss: 2.0444573240895427

Epoch: 6| Step: 13
Training loss: 3.618715524673462
Validation loss: 2.0444291099425285

Epoch: 117| Step: 0
Training loss: 2.6939351558685303
Validation loss: 2.041926481390512

Epoch: 6| Step: 1
Training loss: 2.712529420852661
Validation loss: 2.0541755819833405

Epoch: 6| Step: 2
Training loss: 2.1465060710906982
Validation loss: 2.0442819890155586

Epoch: 6| Step: 3
Training loss: 1.7044520378112793
Validation loss: 2.053407258884881

Epoch: 6| Step: 4
Training loss: 1.7054904699325562
Validation loss: 2.047770571965043

Epoch: 6| Step: 5
Training loss: 2.7338624000549316
Validation loss: 2.053847010417651

Epoch: 6| Step: 6
Training loss: 2.0229835510253906
Validation loss: 2.0559473550447853

Epoch: 6| Step: 7
Training loss: 2.2881646156311035
Validation loss: 2.04852456174871

Epoch: 6| Step: 8
Training loss: 2.06923246383667
Validation loss: 2.0471252831079627

Epoch: 6| Step: 9
Training loss: 2.704500198364258
Validation loss: 2.045163349438739

Epoch: 6| Step: 10
Training loss: 2.557562828063965
Validation loss: 2.051956061393984

Epoch: 6| Step: 11
Training loss: 2.4392738342285156
Validation loss: 2.050626734251617

Epoch: 6| Step: 12
Training loss: 2.6462409496307373
Validation loss: 2.0485137098579

Epoch: 6| Step: 13
Training loss: 1.786896824836731
Validation loss: 2.0451212313867386

Epoch: 118| Step: 0
Training loss: 2.432995557785034
Validation loss: 2.065206628973766

Epoch: 6| Step: 1
Training loss: 3.0455479621887207
Validation loss: 2.0565275889570995

Epoch: 6| Step: 2
Training loss: 2.9460597038269043
Validation loss: 2.070786263353081

Epoch: 6| Step: 3
Training loss: 2.20211124420166
Validation loss: 2.0731984235907115

Epoch: 6| Step: 4
Training loss: 1.6665750741958618
Validation loss: 2.0671484444731023

Epoch: 6| Step: 5
Training loss: 2.2085204124450684
Validation loss: 2.079440265573481

Epoch: 6| Step: 6
Training loss: 2.0638413429260254
Validation loss: 2.075211860800302

Epoch: 6| Step: 7
Training loss: 2.487185001373291
Validation loss: 2.0675433002492434

Epoch: 6| Step: 8
Training loss: 2.4699182510375977
Validation loss: 2.0517478642925138

Epoch: 6| Step: 9
Training loss: 2.407778263092041
Validation loss: 2.049600819105743

Epoch: 6| Step: 10
Training loss: 1.8292471170425415
Validation loss: 2.0479595276617233

Epoch: 6| Step: 11
Training loss: 2.6816487312316895
Validation loss: 2.0389796303164576

Epoch: 6| Step: 12
Training loss: 1.5246844291687012
Validation loss: 2.0395353853061633

Epoch: 6| Step: 13
Training loss: 2.159109115600586
Validation loss: 2.047721588483421

Epoch: 119| Step: 0
Training loss: 2.42030668258667
Validation loss: 2.0519687232150825

Epoch: 6| Step: 1
Training loss: 1.740147352218628
Validation loss: 2.0504607333931872

Epoch: 6| Step: 2
Training loss: 2.2301149368286133
Validation loss: 2.0747069710044452

Epoch: 6| Step: 3
Training loss: 2.0537662506103516
Validation loss: 2.1225926260794363

Epoch: 6| Step: 4
Training loss: 1.9700950384140015
Validation loss: 2.128407742387505

Epoch: 6| Step: 5
Training loss: 1.9276673793792725
Validation loss: 2.111328660800893

Epoch: 6| Step: 6
Training loss: 2.6062731742858887
Validation loss: 2.074072645556542

Epoch: 6| Step: 7
Training loss: 2.531963348388672
Validation loss: 2.0429654147035334

Epoch: 6| Step: 8
Training loss: 2.18393874168396
Validation loss: 2.0305209967397873

Epoch: 6| Step: 9
Training loss: 2.7444472312927246
Validation loss: 2.019426333006992

Epoch: 6| Step: 10
Training loss: 2.619798183441162
Validation loss: 2.025874512169951

Epoch: 6| Step: 11
Training loss: 2.3940985202789307
Validation loss: 2.035425745030885

Epoch: 6| Step: 12
Training loss: 2.3565011024475098
Validation loss: 2.0391155468520297

Epoch: 6| Step: 13
Training loss: 2.729688882827759
Validation loss: 2.0435177946603424

Epoch: 120| Step: 0
Training loss: 2.9516243934631348
Validation loss: 2.039904546994035

Epoch: 6| Step: 1
Training loss: 1.9877104759216309
Validation loss: 2.042929562189246

Epoch: 6| Step: 2
Training loss: 2.4725069999694824
Validation loss: 2.057851775999992

Epoch: 6| Step: 3
Training loss: 1.6874258518218994
Validation loss: 2.0620744433454288

Epoch: 6| Step: 4
Training loss: 1.8963885307312012
Validation loss: 2.0578477049386628

Epoch: 6| Step: 5
Training loss: 2.321411371231079
Validation loss: 2.062113449137698

Epoch: 6| Step: 6
Training loss: 1.8392869234085083
Validation loss: 2.0828011638374737

Epoch: 6| Step: 7
Training loss: 1.790748953819275
Validation loss: 2.09308692332237

Epoch: 6| Step: 8
Training loss: 2.729511260986328
Validation loss: 2.0765297643599974

Epoch: 6| Step: 9
Training loss: 2.5344643592834473
Validation loss: 2.0622646513805596

Epoch: 6| Step: 10
Training loss: 2.4228363037109375
Validation loss: 2.0546328739453386

Epoch: 6| Step: 11
Training loss: 1.9663598537445068
Validation loss: 2.0700385262889247

Epoch: 6| Step: 12
Training loss: 2.4086904525756836
Validation loss: 2.073161002128355

Epoch: 6| Step: 13
Training loss: 3.5645382404327393
Validation loss: 2.0812608054889146

Epoch: 121| Step: 0
Training loss: 2.924896478652954
Validation loss: 2.0818592040769515

Epoch: 6| Step: 1
Training loss: 2.701765298843384
Validation loss: 2.0826434217473513

Epoch: 6| Step: 2
Training loss: 2.18749737739563
Validation loss: 2.0726340611775718

Epoch: 6| Step: 3
Training loss: 1.358835220336914
Validation loss: 2.084645608420013

Epoch: 6| Step: 4
Training loss: 2.2432355880737305
Validation loss: 2.0983750025431314

Epoch: 6| Step: 5
Training loss: 1.6683580875396729
Validation loss: 2.122032409073204

Epoch: 6| Step: 6
Training loss: 2.4386191368103027
Validation loss: 2.115603518742387

Epoch: 6| Step: 7
Training loss: 2.393629789352417
Validation loss: 2.114401460975729

Epoch: 6| Step: 8
Training loss: 2.6988131999969482
Validation loss: 2.101020469460436

Epoch: 6| Step: 9
Training loss: 2.203327178955078
Validation loss: 2.0752462520394275

Epoch: 6| Step: 10
Training loss: 1.9147474765777588
Validation loss: 2.0582877538537465

Epoch: 6| Step: 11
Training loss: 2.4698219299316406
Validation loss: 2.0385135322488765

Epoch: 6| Step: 12
Training loss: 1.974830150604248
Validation loss: 2.0289706081472416

Epoch: 6| Step: 13
Training loss: 3.2194671630859375
Validation loss: 2.0374881362402313

Epoch: 122| Step: 0
Training loss: 2.4136605262756348
Validation loss: 2.045322525885797

Epoch: 6| Step: 1
Training loss: 1.6429632902145386
Validation loss: 2.0485381798077653

Epoch: 6| Step: 2
Training loss: 2.106812000274658
Validation loss: 2.0443905348418863

Epoch: 6| Step: 3
Training loss: 1.9919713735580444
Validation loss: 2.045344459113254

Epoch: 6| Step: 4
Training loss: 2.567488670349121
Validation loss: 2.072605707312143

Epoch: 6| Step: 5
Training loss: 1.3113476037979126
Validation loss: 2.0906526927025086

Epoch: 6| Step: 6
Training loss: 2.9768896102905273
Validation loss: 2.1012564833446215

Epoch: 6| Step: 7
Training loss: 2.9478721618652344
Validation loss: 2.1652095907477924

Epoch: 6| Step: 8
Training loss: 2.7132415771484375
Validation loss: 2.2185390277575423

Epoch: 6| Step: 9
Training loss: 2.616989850997925
Validation loss: 2.2054818266181537

Epoch: 6| Step: 10
Training loss: 1.5798324346542358
Validation loss: 2.1681667809845298

Epoch: 6| Step: 11
Training loss: 2.6604068279266357
Validation loss: 2.113832471191242

Epoch: 6| Step: 12
Training loss: 2.4367308616638184
Validation loss: 2.0820747959998345

Epoch: 6| Step: 13
Training loss: 2.5913586616516113
Validation loss: 2.0930070172074022

Epoch: 123| Step: 0
Training loss: 2.2768325805664062
Validation loss: 2.107162871668416

Epoch: 6| Step: 1
Training loss: 1.8084704875946045
Validation loss: 2.0934183982110794

Epoch: 6| Step: 2
Training loss: 2.4248173236846924
Validation loss: 2.065739457325269

Epoch: 6| Step: 3
Training loss: 2.6145715713500977
Validation loss: 2.0398471163165186

Epoch: 6| Step: 4
Training loss: 2.1852970123291016
Validation loss: 2.021306691631194

Epoch: 6| Step: 5
Training loss: 2.9175469875335693
Validation loss: 2.007296323776245

Epoch: 6| Step: 6
Training loss: 2.6249241828918457
Validation loss: 2.0124619724929973

Epoch: 6| Step: 7
Training loss: 1.5931978225708008
Validation loss: 2.021880486960052

Epoch: 6| Step: 8
Training loss: 2.260711431503296
Validation loss: 2.0403656498078377

Epoch: 6| Step: 9
Training loss: 2.0028769969940186
Validation loss: 2.083390930647491

Epoch: 6| Step: 10
Training loss: 2.298283100128174
Validation loss: 2.1580259915321105

Epoch: 6| Step: 11
Training loss: 2.7307729721069336
Validation loss: 2.195727432927778

Epoch: 6| Step: 12
Training loss: 2.326190233230591
Validation loss: 2.1760551262927312

Epoch: 6| Step: 13
Training loss: 1.5531977415084839
Validation loss: 2.130173155056533

Epoch: 124| Step: 0
Training loss: 2.524488925933838
Validation loss: 2.1024680381180136

Epoch: 6| Step: 1
Training loss: 1.9923220872879028
Validation loss: 2.0629213868930774

Epoch: 6| Step: 2
Training loss: 2.8941333293914795
Validation loss: 2.0317144957921838

Epoch: 6| Step: 3
Training loss: 2.0580267906188965
Validation loss: 2.0137388424206804

Epoch: 6| Step: 4
Training loss: 1.5494389533996582
Validation loss: 2.0018943817384782

Epoch: 6| Step: 5
Training loss: 2.527283191680908
Validation loss: 2.0048479162236696

Epoch: 6| Step: 6
Training loss: 2.0166690349578857
Validation loss: 1.9946706410377257

Epoch: 6| Step: 7
Training loss: 1.8860793113708496
Validation loss: 2.0073697361894833

Epoch: 6| Step: 8
Training loss: 1.3037606477737427
Validation loss: 2.0030443796547512

Epoch: 6| Step: 9
Training loss: 2.8300323486328125
Validation loss: 2.0231374822637087

Epoch: 6| Step: 10
Training loss: 2.962069511413574
Validation loss: 2.0540044358981553

Epoch: 6| Step: 11
Training loss: 2.241253137588501
Validation loss: 2.067646534212174

Epoch: 6| Step: 12
Training loss: 2.753443479537964
Validation loss: 2.05088665921201

Epoch: 6| Step: 13
Training loss: 1.7717633247375488
Validation loss: 2.0378984366693804

Epoch: 125| Step: 0
Training loss: 1.6919043064117432
Validation loss: 2.0412805413687103

Epoch: 6| Step: 1
Training loss: 2.4005846977233887
Validation loss: 2.034994504785025

Epoch: 6| Step: 2
Training loss: 2.4419987201690674
Validation loss: 2.03379132927105

Epoch: 6| Step: 3
Training loss: 2.053659439086914
Validation loss: 2.030449410920502

Epoch: 6| Step: 4
Training loss: 2.7681217193603516
Validation loss: 2.029960996361189

Epoch: 6| Step: 5
Training loss: 2.79695200920105
Validation loss: 2.0330647960785897

Epoch: 6| Step: 6
Training loss: 2.07735013961792
Validation loss: 2.022954361413115

Epoch: 6| Step: 7
Training loss: 1.9120643138885498
Validation loss: 2.039747649623502

Epoch: 6| Step: 8
Training loss: 2.268237590789795
Validation loss: 2.0481111593143915

Epoch: 6| Step: 9
Training loss: 2.187824010848999
Validation loss: 2.0319542423371346

Epoch: 6| Step: 10
Training loss: 2.0925657749176025
Validation loss: 2.0480349730419856

Epoch: 6| Step: 11
Training loss: 2.7375049591064453
Validation loss: 2.0799762959121377

Epoch: 6| Step: 12
Training loss: 2.224726676940918
Validation loss: 2.1027497194146596

Epoch: 6| Step: 13
Training loss: 2.20686674118042
Validation loss: 2.1735515530391405

Epoch: 126| Step: 0
Training loss: 2.8660576343536377
Validation loss: 2.1744824993994927

Epoch: 6| Step: 1
Training loss: 2.107588291168213
Validation loss: 2.2036012295753724

Epoch: 6| Step: 2
Training loss: 2.3462743759155273
Validation loss: 2.189295969983583

Epoch: 6| Step: 3
Training loss: 2.748835563659668
Validation loss: 2.24833083152771

Epoch: 6| Step: 4
Training loss: 3.5618414878845215
Validation loss: 2.3185354227660806

Epoch: 6| Step: 5
Training loss: 2.3882627487182617
Validation loss: 2.381786049053233

Epoch: 6| Step: 6
Training loss: 3.0634047985076904
Validation loss: 2.339217899948038

Epoch: 6| Step: 7
Training loss: 1.5780869722366333
Validation loss: 2.209239632852616

Epoch: 6| Step: 8
Training loss: 2.558403968811035
Validation loss: 2.0719399529118694

Epoch: 6| Step: 9
Training loss: 2.3781235218048096
Validation loss: 2.017207181581887

Epoch: 6| Step: 10
Training loss: 1.650475263595581
Validation loss: 2.016378107891288

Epoch: 6| Step: 11
Training loss: 1.3473576307296753
Validation loss: 2.008769937740859

Epoch: 6| Step: 12
Training loss: 1.5791540145874023
Validation loss: 2.0292906350986932

Epoch: 6| Step: 13
Training loss: 1.6846421957015991
Validation loss: 2.03455065911816

Epoch: 127| Step: 0
Training loss: 1.7797791957855225
Validation loss: 2.0541012415321926

Epoch: 6| Step: 1
Training loss: 1.6775275468826294
Validation loss: 2.0531574154412873

Epoch: 6| Step: 2
Training loss: 1.6300745010375977
Validation loss: 2.0506126367917625

Epoch: 6| Step: 3
Training loss: 2.250640392303467
Validation loss: 2.046282204248572

Epoch: 6| Step: 4
Training loss: 1.9149999618530273
Validation loss: 2.0531007500105005

Epoch: 6| Step: 5
Training loss: 2.137239933013916
Validation loss: 2.068222471462783

Epoch: 6| Step: 6
Training loss: 2.5213122367858887
Validation loss: 2.0945560778340986

Epoch: 6| Step: 7
Training loss: 2.6724853515625
Validation loss: 2.093830188115438

Epoch: 6| Step: 8
Training loss: 2.259755849838257
Validation loss: 2.128594526680567

Epoch: 6| Step: 9
Training loss: 2.891885995864868
Validation loss: 2.178663747285002

Epoch: 6| Step: 10
Training loss: 2.0639281272888184
Validation loss: 2.165920688259986

Epoch: 6| Step: 11
Training loss: 2.410278797149658
Validation loss: 2.1599194490781395

Epoch: 6| Step: 12
Training loss: 2.3411331176757812
Validation loss: 2.1366884887859388

Epoch: 6| Step: 13
Training loss: 2.962463617324829
Validation loss: 2.1300217874588503

Epoch: 128| Step: 0
Training loss: 2.1078829765319824
Validation loss: 2.1048110890132126

Epoch: 6| Step: 1
Training loss: 1.8968467712402344
Validation loss: 2.088345258466659

Epoch: 6| Step: 2
Training loss: 1.756453275680542
Validation loss: 2.094600107080193

Epoch: 6| Step: 3
Training loss: 2.6371512413024902
Validation loss: 2.0835386924846198

Epoch: 6| Step: 4
Training loss: 2.3982396125793457
Validation loss: 2.0733418874843146

Epoch: 6| Step: 5
Training loss: 1.9277632236480713
Validation loss: 2.089182804989558

Epoch: 6| Step: 6
Training loss: 1.8480851650238037
Validation loss: 2.08474443035741

Epoch: 6| Step: 7
Training loss: 1.834777593612671
Validation loss: 2.0802939835415093

Epoch: 6| Step: 8
Training loss: 2.390906810760498
Validation loss: 2.0809110838879823

Epoch: 6| Step: 9
Training loss: 1.7658405303955078
Validation loss: 2.0923977436557895

Epoch: 6| Step: 10
Training loss: 2.9656801223754883
Validation loss: 2.0887474590732205

Epoch: 6| Step: 11
Training loss: 2.4330661296844482
Validation loss: 2.078059369517911

Epoch: 6| Step: 12
Training loss: 2.1266746520996094
Validation loss: 2.0648258886029645

Epoch: 6| Step: 13
Training loss: 3.1978893280029297
Validation loss: 2.071973701959015

Epoch: 129| Step: 0
Training loss: 2.2748026847839355
Validation loss: 2.0585714975992837

Epoch: 6| Step: 1
Training loss: 2.587228536605835
Validation loss: 2.052427973798526

Epoch: 6| Step: 2
Training loss: 1.788040041923523
Validation loss: 2.0500418268224245

Epoch: 6| Step: 3
Training loss: 1.5105352401733398
Validation loss: 2.03130950209915

Epoch: 6| Step: 4
Training loss: 1.9936580657958984
Validation loss: 1.9925179404597129

Epoch: 6| Step: 5
Training loss: 1.7548956871032715
Validation loss: 1.9742270861902544

Epoch: 6| Step: 6
Training loss: 2.2563905715942383
Validation loss: 1.9740149103185183

Epoch: 6| Step: 7
Training loss: 2.6008081436157227
Validation loss: 1.9813871870758712

Epoch: 6| Step: 8
Training loss: 2.4550821781158447
Validation loss: 1.996818309189171

Epoch: 6| Step: 9
Training loss: 2.396160125732422
Validation loss: 2.0087177958539737

Epoch: 6| Step: 10
Training loss: 2.1346442699432373
Validation loss: 2.0306698865787958

Epoch: 6| Step: 11
Training loss: 2.0661673545837402
Validation loss: 2.051428678215191

Epoch: 6| Step: 12
Training loss: 2.556422710418701
Validation loss: 2.0549648718167375

Epoch: 6| Step: 13
Training loss: 2.6482722759246826
Validation loss: 2.0570665431279007

Epoch: 130| Step: 0
Training loss: 2.9525034427642822
Validation loss: 2.074788301221786

Epoch: 6| Step: 1
Training loss: 1.539553165435791
Validation loss: 2.058242177450529

Epoch: 6| Step: 2
Training loss: 2.3422703742980957
Validation loss: 2.0396145236107612

Epoch: 6| Step: 3
Training loss: 2.091825008392334
Validation loss: 2.0321777841096282

Epoch: 6| Step: 4
Training loss: 1.3999813795089722
Validation loss: 2.036206160822222

Epoch: 6| Step: 5
Training loss: 2.354848861694336
Validation loss: 2.04414507906924

Epoch: 6| Step: 6
Training loss: 2.034670114517212
Validation loss: 2.0457427655496905

Epoch: 6| Step: 7
Training loss: 2.1142163276672363
Validation loss: 2.0474656346023723

Epoch: 6| Step: 8
Training loss: 2.999122142791748
Validation loss: 2.049454253206971

Epoch: 6| Step: 9
Training loss: 2.6355690956115723
Validation loss: 2.0479687336952455

Epoch: 6| Step: 10
Training loss: 1.8286256790161133
Validation loss: 2.0513992591570784

Epoch: 6| Step: 11
Training loss: 1.9053410291671753
Validation loss: 2.039591940500403

Epoch: 6| Step: 12
Training loss: 1.9971325397491455
Validation loss: 2.051476240158081

Epoch: 6| Step: 13
Training loss: 1.9316054582595825
Validation loss: 2.080595277970837

Epoch: 131| Step: 0
Training loss: 2.218695640563965
Validation loss: 2.1601786408373105

Epoch: 6| Step: 1
Training loss: 1.906485915184021
Validation loss: 2.2295887777882237

Epoch: 6| Step: 2
Training loss: 1.7630573511123657
Validation loss: 2.2705997907987205

Epoch: 6| Step: 3
Training loss: 2.5069212913513184
Validation loss: 2.287845462881109

Epoch: 6| Step: 4
Training loss: 2.298062324523926
Validation loss: 2.271538358862682

Epoch: 6| Step: 5
Training loss: 2.9690184593200684
Validation loss: 2.219796778053366

Epoch: 6| Step: 6
Training loss: 2.4599204063415527
Validation loss: 2.18321519641466

Epoch: 6| Step: 7
Training loss: 2.1583364009857178
Validation loss: 2.1432361730965237

Epoch: 6| Step: 8
Training loss: 1.6154546737670898
Validation loss: 2.1099012603041944

Epoch: 6| Step: 9
Training loss: 1.8107929229736328
Validation loss: 2.069092445476081

Epoch: 6| Step: 10
Training loss: 2.4127016067504883
Validation loss: 2.0585262262693016

Epoch: 6| Step: 11
Training loss: 1.925184965133667
Validation loss: 2.0291212656164683

Epoch: 6| Step: 12
Training loss: 2.372365951538086
Validation loss: 2.018394954742924

Epoch: 6| Step: 13
Training loss: 2.278216600418091
Validation loss: 1.9990368876405942

Epoch: 132| Step: 0
Training loss: 1.6798205375671387
Validation loss: 2.001342059463583

Epoch: 6| Step: 1
Training loss: 1.94999098777771
Validation loss: 2.011056588542077

Epoch: 6| Step: 2
Training loss: 2.3786802291870117
Validation loss: 2.022551646796606

Epoch: 6| Step: 3
Training loss: 1.5501899719238281
Validation loss: 2.042267120012673

Epoch: 6| Step: 4
Training loss: 1.9993956089019775
Validation loss: 2.026776029217628

Epoch: 6| Step: 5
Training loss: 2.0758936405181885
Validation loss: 2.043871694995511

Epoch: 6| Step: 6
Training loss: 2.4832515716552734
Validation loss: 2.0289735358248473

Epoch: 6| Step: 7
Training loss: 2.227815628051758
Validation loss: 2.0435943808606876

Epoch: 6| Step: 8
Training loss: 2.457598924636841
Validation loss: 2.054161597323674

Epoch: 6| Step: 9
Training loss: 2.731180191040039
Validation loss: 2.0702699102381223

Epoch: 6| Step: 10
Training loss: 2.2720494270324707
Validation loss: 2.0715922745325233

Epoch: 6| Step: 11
Training loss: 2.8038289546966553
Validation loss: 2.0774294637864634

Epoch: 6| Step: 12
Training loss: 1.4509096145629883
Validation loss: 2.1127799326373684

Epoch: 6| Step: 13
Training loss: 1.7552852630615234
Validation loss: 2.1372310756355204

Epoch: 133| Step: 0
Training loss: 2.5333709716796875
Validation loss: 2.142497662575014

Epoch: 6| Step: 1
Training loss: 1.9856550693511963
Validation loss: 2.178884413934523

Epoch: 6| Step: 2
Training loss: 1.7808005809783936
Validation loss: 2.1992765421508462

Epoch: 6| Step: 3
Training loss: 2.864351272583008
Validation loss: 2.2392246441174577

Epoch: 6| Step: 4
Training loss: 2.58713960647583
Validation loss: 2.1934483948574273

Epoch: 6| Step: 5
Training loss: 2.650435447692871
Validation loss: 2.154945276116812

Epoch: 6| Step: 6
Training loss: 1.6391092538833618
Validation loss: 2.136748242121871

Epoch: 6| Step: 7
Training loss: 2.562070846557617
Validation loss: 2.0820395510683776

Epoch: 6| Step: 8
Training loss: 2.198070526123047
Validation loss: 2.0546770813644573

Epoch: 6| Step: 9
Training loss: 1.3484299182891846
Validation loss: 2.0107011820680354

Epoch: 6| Step: 10
Training loss: 1.4784799814224243
Validation loss: 2.0116266537738103

Epoch: 6| Step: 11
Training loss: 1.8456189632415771
Validation loss: 2.005364380856996

Epoch: 6| Step: 12
Training loss: 2.1323771476745605
Validation loss: 1.9997364218517015

Epoch: 6| Step: 13
Training loss: 2.2756197452545166
Validation loss: 1.9942574257491736

Epoch: 134| Step: 0
Training loss: 2.3063015937805176
Validation loss: 1.987995239996141

Epoch: 6| Step: 1
Training loss: 2.377000093460083
Validation loss: 2.0039794060491745

Epoch: 6| Step: 2
Training loss: 2.1305665969848633
Validation loss: 2.0293037788842314

Epoch: 6| Step: 3
Training loss: 2.8420801162719727
Validation loss: 2.0473482467794932

Epoch: 6| Step: 4
Training loss: 2.440998077392578
Validation loss: 2.049451945930399

Epoch: 6| Step: 5
Training loss: 1.6614131927490234
Validation loss: 2.0393164298867665

Epoch: 6| Step: 6
Training loss: 1.8294181823730469
Validation loss: 2.0642129644270866

Epoch: 6| Step: 7
Training loss: 1.9037501811981201
Validation loss: 2.0542127598998365

Epoch: 6| Step: 8
Training loss: 2.204139232635498
Validation loss: 2.0712209452864943

Epoch: 6| Step: 9
Training loss: 2.8505141735076904
Validation loss: 2.0819741705412507

Epoch: 6| Step: 10
Training loss: 1.9606823921203613
Validation loss: 2.082553231587974

Epoch: 6| Step: 11
Training loss: 1.5428872108459473
Validation loss: 2.1051867546573764

Epoch: 6| Step: 12
Training loss: 1.8417234420776367
Validation loss: 2.1137457457921838

Epoch: 6| Step: 13
Training loss: 2.4763920307159424
Validation loss: 2.1251348628792712

Epoch: 135| Step: 0
Training loss: 2.0661706924438477
Validation loss: 2.1144237877220236

Epoch: 6| Step: 1
Training loss: 2.101015329360962
Validation loss: 2.139022006783434

Epoch: 6| Step: 2
Training loss: 2.093918800354004
Validation loss: 2.1469268439918436

Epoch: 6| Step: 3
Training loss: 1.3854053020477295
Validation loss: 2.1156561118300243

Epoch: 6| Step: 4
Training loss: 2.0431065559387207
Validation loss: 2.121147733862682

Epoch: 6| Step: 5
Training loss: 2.69342041015625
Validation loss: 2.113539836739981

Epoch: 6| Step: 6
Training loss: 2.0320487022399902
Validation loss: 2.1243086912298716

Epoch: 6| Step: 7
Training loss: 2.179248809814453
Validation loss: 2.12947670362329

Epoch: 6| Step: 8
Training loss: 2.0374755859375
Validation loss: 2.132543181860319

Epoch: 6| Step: 9
Training loss: 2.243558883666992
Validation loss: 2.1391545995589225

Epoch: 6| Step: 10
Training loss: 1.8580429553985596
Validation loss: 2.142073195467713

Epoch: 6| Step: 11
Training loss: 2.4093592166900635
Validation loss: 2.1196355717156523

Epoch: 6| Step: 12
Training loss: 2.0116419792175293
Validation loss: 2.1086249146410214

Epoch: 6| Step: 13
Training loss: 2.2529234886169434
Validation loss: 2.088299443644862

Epoch: 136| Step: 0
Training loss: 1.5304744243621826
Validation loss: 2.0784382909856816

Epoch: 6| Step: 1
Training loss: 1.9736924171447754
Validation loss: 2.0662064052397207

Epoch: 6| Step: 2
Training loss: 2.051954507827759
Validation loss: 2.0633687626930977

Epoch: 6| Step: 3
Training loss: 2.4146976470947266
Validation loss: 2.0758918075151342

Epoch: 6| Step: 4
Training loss: 2.2207510471343994
Validation loss: 2.0675671536435365

Epoch: 6| Step: 5
Training loss: 1.8090811967849731
Validation loss: 2.0571912821903022

Epoch: 6| Step: 6
Training loss: 2.390542507171631
Validation loss: 2.0499855369649906

Epoch: 6| Step: 7
Training loss: 2.527230739593506
Validation loss: 2.062855210355533

Epoch: 6| Step: 8
Training loss: 1.4556100368499756
Validation loss: 2.0540437595818632

Epoch: 6| Step: 9
Training loss: 1.512944221496582
Validation loss: 2.0754903901007866

Epoch: 6| Step: 10
Training loss: 2.2810659408569336
Validation loss: 2.075904320645076

Epoch: 6| Step: 11
Training loss: 2.1079466342926025
Validation loss: 2.0779627766660465

Epoch: 6| Step: 12
Training loss: 1.883581280708313
Validation loss: 2.0722018493119108

Epoch: 6| Step: 13
Training loss: 2.9968724250793457
Validation loss: 2.0740414921955397

Epoch: 137| Step: 0
Training loss: 1.8404756784439087
Validation loss: 2.0865125784309964

Epoch: 6| Step: 1
Training loss: 2.292748212814331
Validation loss: 2.106157536147743

Epoch: 6| Step: 2
Training loss: 1.6112444400787354
Validation loss: 2.1027361449374946

Epoch: 6| Step: 3
Training loss: 2.7974085807800293
Validation loss: 2.107271586695025

Epoch: 6| Step: 4
Training loss: 1.7468795776367188
Validation loss: 2.1005228937313123

Epoch: 6| Step: 5
Training loss: 1.711397647857666
Validation loss: 2.099896510442098

Epoch: 6| Step: 6
Training loss: 2.2105698585510254
Validation loss: 2.0895457780489357

Epoch: 6| Step: 7
Training loss: 3.2323360443115234
Validation loss: 2.0730671446810485

Epoch: 6| Step: 8
Training loss: 2.044013500213623
Validation loss: 2.0913135056854575

Epoch: 6| Step: 9
Training loss: 1.7692184448242188
Validation loss: 2.081770880247957

Epoch: 6| Step: 10
Training loss: 1.4190142154693604
Validation loss: 2.0841475302173245

Epoch: 6| Step: 11
Training loss: 2.3814635276794434
Validation loss: 2.079010509675549

Epoch: 6| Step: 12
Training loss: 1.8005576133728027
Validation loss: 2.0906242555187595

Epoch: 6| Step: 13
Training loss: 1.8379020690917969
Validation loss: 2.126270371098672

Epoch: 138| Step: 0
Training loss: 2.721709728240967
Validation loss: 2.1446253791932137

Epoch: 6| Step: 1
Training loss: 2.605851173400879
Validation loss: 2.2092483492307764

Epoch: 6| Step: 2
Training loss: 2.0329835414886475
Validation loss: 2.1581161406732376

Epoch: 6| Step: 3
Training loss: 2.064028024673462
Validation loss: 2.1177762862174743

Epoch: 6| Step: 4
Training loss: 2.455702543258667
Validation loss: 2.085864290114372

Epoch: 6| Step: 5
Training loss: 1.6563482284545898
Validation loss: 2.0789789179319977

Epoch: 6| Step: 6
Training loss: 2.5315346717834473
Validation loss: 2.0796734876530145

Epoch: 6| Step: 7
Training loss: 2.2273948192596436
Validation loss: 2.0616126188667874

Epoch: 6| Step: 8
Training loss: 1.2145342826843262
Validation loss: 2.0666334462422196

Epoch: 6| Step: 9
Training loss: 1.604144811630249
Validation loss: 2.092761024352043

Epoch: 6| Step: 10
Training loss: 2.1363656520843506
Validation loss: 2.092078839578936

Epoch: 6| Step: 11
Training loss: 1.3675504922866821
Validation loss: 2.1031369752781366

Epoch: 6| Step: 12
Training loss: 2.4585297107696533
Validation loss: 2.096328289278092

Epoch: 6| Step: 13
Training loss: 1.4515340328216553
Validation loss: 2.0628416102419616

Epoch: 139| Step: 0
Training loss: 1.5740993022918701
Validation loss: 2.0351542144693355

Epoch: 6| Step: 1
Training loss: 1.6756653785705566
Validation loss: 2.016619914321489

Epoch: 6| Step: 2
Training loss: 1.9451887607574463
Validation loss: 2.0060885337091263

Epoch: 6| Step: 3
Training loss: 2.4103450775146484
Validation loss: 2.00173335049742

Epoch: 6| Step: 4
Training loss: 1.938719630241394
Validation loss: 2.0175547343428417

Epoch: 6| Step: 5
Training loss: 2.363766670227051
Validation loss: 2.034599401617563

Epoch: 6| Step: 6
Training loss: 1.9175477027893066
Validation loss: 2.0376917482704244

Epoch: 6| Step: 7
Training loss: 2.6417508125305176
Validation loss: 2.0520158608754477

Epoch: 6| Step: 8
Training loss: 2.3514890670776367
Validation loss: 2.059040270825868

Epoch: 6| Step: 9
Training loss: 2.5403780937194824
Validation loss: 2.0569153447305

Epoch: 6| Step: 10
Training loss: 2.1205735206604004
Validation loss: 2.0708730092612644

Epoch: 6| Step: 11
Training loss: 1.2348062992095947
Validation loss: 2.072105012914186

Epoch: 6| Step: 12
Training loss: 1.3166502714157104
Validation loss: 2.071731536619125

Epoch: 6| Step: 13
Training loss: 2.535175323486328
Validation loss: 2.051311562138219

Epoch: 140| Step: 0
Training loss: 1.3353221416473389
Validation loss: 2.0358599232089136

Epoch: 6| Step: 1
Training loss: 2.5031440258026123
Validation loss: 2.0190661132976575

Epoch: 6| Step: 2
Training loss: 2.4236247539520264
Validation loss: 2.00981225762316

Epoch: 6| Step: 3
Training loss: 1.587585687637329
Validation loss: 2.0123341775709584

Epoch: 6| Step: 4
Training loss: 1.6821318864822388
Validation loss: 2.0318686398126746

Epoch: 6| Step: 5
Training loss: 2.125502347946167
Validation loss: 2.07054030254323

Epoch: 6| Step: 6
Training loss: 1.9154982566833496
Validation loss: 2.0766873334043767

Epoch: 6| Step: 7
Training loss: 2.807765483856201
Validation loss: 2.114006527008549

Epoch: 6| Step: 8
Training loss: 2.194690227508545
Validation loss: 2.1191951510726765

Epoch: 6| Step: 9
Training loss: 2.260435104370117
Validation loss: 2.1154586768919423

Epoch: 6| Step: 10
Training loss: 1.606014609336853
Validation loss: 2.105686169798656

Epoch: 6| Step: 11
Training loss: 2.5756497383117676
Validation loss: 2.089840296776064

Epoch: 6| Step: 12
Training loss: 1.3799803256988525
Validation loss: 2.084736060070735

Epoch: 6| Step: 13
Training loss: 1.395692229270935
Validation loss: 2.1258060137430825

Epoch: 141| Step: 0
Training loss: 2.224965810775757
Validation loss: 2.1403963001825477

Epoch: 6| Step: 1
Training loss: 2.0798816680908203
Validation loss: 2.1195665944007134

Epoch: 6| Step: 2
Training loss: 2.0965044498443604
Validation loss: 2.098071982783656

Epoch: 6| Step: 3
Training loss: 2.1397976875305176
Validation loss: 2.0955504012364212

Epoch: 6| Step: 4
Training loss: 2.273491621017456
Validation loss: 2.097556480797388

Epoch: 6| Step: 5
Training loss: 2.1032042503356934
Validation loss: 2.0705303120356735

Epoch: 6| Step: 6
Training loss: 1.6582614183425903
Validation loss: 2.0798479228891353

Epoch: 6| Step: 7
Training loss: 1.927172064781189
Validation loss: 2.0367146422786098

Epoch: 6| Step: 8
Training loss: 2.059025764465332
Validation loss: 2.0235086666640414

Epoch: 6| Step: 9
Training loss: 1.8377635478973389
Validation loss: 1.9840398539779007

Epoch: 6| Step: 10
Training loss: 2.1803817749023438
Validation loss: 1.9895774254234888

Epoch: 6| Step: 11
Training loss: 1.988013505935669
Validation loss: 2.0107731255151893

Epoch: 6| Step: 12
Training loss: 1.7820091247558594
Validation loss: 2.031082932667066

Epoch: 6| Step: 13
Training loss: 2.0659258365631104
Validation loss: 2.072476307551066

Epoch: 142| Step: 0
Training loss: 1.3745442628860474
Validation loss: 2.1484484672546387

Epoch: 6| Step: 1
Training loss: 2.1179709434509277
Validation loss: 2.182884377817954

Epoch: 6| Step: 2
Training loss: 2.1473898887634277
Validation loss: 2.162254346314297

Epoch: 6| Step: 3
Training loss: 1.2070062160491943
Validation loss: 2.1829681345211562

Epoch: 6| Step: 4
Training loss: 2.6612000465393066
Validation loss: 2.1961746587548205

Epoch: 6| Step: 5
Training loss: 1.963681936264038
Validation loss: 2.2266671862653507

Epoch: 6| Step: 6
Training loss: 2.3584299087524414
Validation loss: 2.247037115917411

Epoch: 6| Step: 7
Training loss: 1.9601266384124756
Validation loss: 2.23238084905891

Epoch: 6| Step: 8
Training loss: 2.2016782760620117
Validation loss: 2.2198180396069764

Epoch: 6| Step: 9
Training loss: 2.2051000595092773
Validation loss: 2.147891177926012

Epoch: 6| Step: 10
Training loss: 2.17197322845459
Validation loss: 2.135063438005345

Epoch: 6| Step: 11
Training loss: 2.64971923828125
Validation loss: 2.16835376011428

Epoch: 6| Step: 12
Training loss: 1.9766558408737183
Validation loss: 2.222461336402483

Epoch: 6| Step: 13
Training loss: 2.11612606048584
Validation loss: 2.215505870439673

Epoch: 143| Step: 0
Training loss: 2.1331357955932617
Validation loss: 2.204707968619562

Epoch: 6| Step: 1
Training loss: 1.8879997730255127
Validation loss: 2.1557032344161824

Epoch: 6| Step: 2
Training loss: 2.1545348167419434
Validation loss: 2.1500228810054

Epoch: 6| Step: 3
Training loss: 2.4869441986083984
Validation loss: 2.1410319856418076

Epoch: 6| Step: 4
Training loss: 1.9674084186553955
Validation loss: 2.1191336083155807

Epoch: 6| Step: 5
Training loss: 2.0685179233551025
Validation loss: 2.0525154939261814

Epoch: 6| Step: 6
Training loss: 1.415356159210205
Validation loss: 2.0222350166689966

Epoch: 6| Step: 7
Training loss: 1.847059726715088
Validation loss: 2.019571796540291

Epoch: 6| Step: 8
Training loss: 1.7331438064575195
Validation loss: 2.0256972697473343

Epoch: 6| Step: 9
Training loss: 2.0804319381713867
Validation loss: 2.02813696476721

Epoch: 6| Step: 10
Training loss: 1.7950797080993652
Validation loss: 2.052884817123413

Epoch: 6| Step: 11
Training loss: 1.7608262300491333
Validation loss: 2.047148367410065

Epoch: 6| Step: 12
Training loss: 2.214231252670288
Validation loss: 2.0624011101261264

Epoch: 6| Step: 13
Training loss: 3.0080251693725586
Validation loss: 2.0480424768181256

Epoch: 144| Step: 0
Training loss: 2.286367893218994
Validation loss: 2.038121020922097

Epoch: 6| Step: 1
Training loss: 2.5492167472839355
Validation loss: 2.027623394484161

Epoch: 6| Step: 2
Training loss: 2.2883248329162598
Validation loss: 1.995547240780246

Epoch: 6| Step: 3
Training loss: 1.8291164636611938
Validation loss: 1.9788382899376653

Epoch: 6| Step: 4
Training loss: 1.1067490577697754
Validation loss: 1.9715007940928142

Epoch: 6| Step: 5
Training loss: 1.6404856443405151
Validation loss: 1.9766081917670466

Epoch: 6| Step: 6
Training loss: 1.7777388095855713
Validation loss: 1.980192066520773

Epoch: 6| Step: 7
Training loss: 1.1322489976882935
Validation loss: 1.9902826996259793

Epoch: 6| Step: 8
Training loss: 2.460367441177368
Validation loss: 2.0056265361847414

Epoch: 6| Step: 9
Training loss: 2.2739739418029785
Validation loss: 2.0103947565119755

Epoch: 6| Step: 10
Training loss: 2.0963387489318848
Validation loss: 2.0368017599146855

Epoch: 6| Step: 11
Training loss: 2.453573226928711
Validation loss: 2.070789440985649

Epoch: 6| Step: 12
Training loss: 1.7041709423065186
Validation loss: 2.0906395284078454

Epoch: 6| Step: 13
Training loss: 2.0322210788726807
Validation loss: 2.1157194927174556

Epoch: 145| Step: 0
Training loss: 2.4571056365966797
Validation loss: 2.141976369324551

Epoch: 6| Step: 1
Training loss: 2.1008472442626953
Validation loss: 2.108915877598588

Epoch: 6| Step: 2
Training loss: 2.128765106201172
Validation loss: 2.070639225744432

Epoch: 6| Step: 3
Training loss: 1.7877545356750488
Validation loss: 2.05320143699646

Epoch: 6| Step: 4
Training loss: 2.2619247436523438
Validation loss: 2.0558561522473573

Epoch: 6| Step: 5
Training loss: 1.466296911239624
Validation loss: 2.07183938641702

Epoch: 6| Step: 6
Training loss: 1.8036904335021973
Validation loss: 2.0356980318664224

Epoch: 6| Step: 7
Training loss: 1.6957601308822632
Validation loss: 2.0113638216449368

Epoch: 6| Step: 8
Training loss: 2.2108864784240723
Validation loss: 1.981338224103374

Epoch: 6| Step: 9
Training loss: 1.3269902467727661
Validation loss: 1.990237578268974

Epoch: 6| Step: 10
Training loss: 2.1895220279693604
Validation loss: 2.0118401281295286

Epoch: 6| Step: 11
Training loss: 1.622926950454712
Validation loss: 2.0231937080301265

Epoch: 6| Step: 12
Training loss: 2.351884365081787
Validation loss: 2.051593880499563

Epoch: 6| Step: 13
Training loss: 2.1231534481048584
Validation loss: 2.1152150092586393

Epoch: 146| Step: 0
Training loss: 2.201810836791992
Validation loss: 2.1836981478557793

Epoch: 6| Step: 1
Training loss: 1.764944314956665
Validation loss: 2.2736535559418383

Epoch: 6| Step: 2
Training loss: 1.96024751663208
Validation loss: 2.3275999612705682

Epoch: 6| Step: 3
Training loss: 2.230656862258911
Validation loss: 2.3304393009472917

Epoch: 6| Step: 4
Training loss: 2.1710197925567627
Validation loss: 2.3171396614402853

Epoch: 6| Step: 5
Training loss: 1.7122204303741455
Validation loss: 2.2524968731787895

Epoch: 6| Step: 6
Training loss: 2.1369967460632324
Validation loss: 2.2473192830239572

Epoch: 6| Step: 7
Training loss: 1.8822191953659058
Validation loss: 2.2379934403204147

Epoch: 6| Step: 8
Training loss: 1.6665560007095337
Validation loss: 2.218364525866765

Epoch: 6| Step: 9
Training loss: 2.0151710510253906
Validation loss: 2.1696803672339326

Epoch: 6| Step: 10
Training loss: 1.8768852949142456
Validation loss: 2.1479432787946475

Epoch: 6| Step: 11
Training loss: 2.0081114768981934
Validation loss: 2.1070727648273593

Epoch: 6| Step: 12
Training loss: 2.6500322818756104
Validation loss: 2.0838556571673323

Epoch: 6| Step: 13
Training loss: 2.0755603313446045
Validation loss: 2.0492978224190335

Epoch: 147| Step: 0
Training loss: 1.7956428527832031
Validation loss: 2.039394090252538

Epoch: 6| Step: 1
Training loss: 2.1558175086975098
Validation loss: 2.078749134976377

Epoch: 6| Step: 2
Training loss: 2.476551055908203
Validation loss: 2.109466419425062

Epoch: 6| Step: 3
Training loss: 2.3218653202056885
Validation loss: 2.1453757004071305

Epoch: 6| Step: 4
Training loss: 1.4637956619262695
Validation loss: 2.186275832114681

Epoch: 6| Step: 5
Training loss: 1.637475609779358
Validation loss: 2.21274406679215

Epoch: 6| Step: 6
Training loss: 1.8566207885742188
Validation loss: 2.2244034838932816

Epoch: 6| Step: 7
Training loss: 1.3848388195037842
Validation loss: 2.2347856721570416

Epoch: 6| Step: 8
Training loss: 2.2362208366394043
Validation loss: 2.2347828316432174

Epoch: 6| Step: 9
Training loss: 1.7361690998077393
Validation loss: 2.2321385747642926

Epoch: 6| Step: 10
Training loss: 2.4362521171569824
Validation loss: 2.2062101774318243

Epoch: 6| Step: 11
Training loss: 1.6939857006072998
Validation loss: 2.1355005271973146

Epoch: 6| Step: 12
Training loss: 1.570760726928711
Validation loss: 2.088368818324099

Epoch: 6| Step: 13
Training loss: 2.5010180473327637
Validation loss: 2.065414078773991

Epoch: 148| Step: 0
Training loss: 2.4282288551330566
Validation loss: 2.0470883538646083

Epoch: 6| Step: 1
Training loss: 1.0094246864318848
Validation loss: 2.0509996478275587

Epoch: 6| Step: 2
Training loss: 2.2025694847106934
Validation loss: 2.063912755699568

Epoch: 6| Step: 3
Training loss: 1.966861367225647
Validation loss: 2.0680735957237983

Epoch: 6| Step: 4
Training loss: 2.059682607650757
Validation loss: 2.065200690300234

Epoch: 6| Step: 5
Training loss: 1.5169697999954224
Validation loss: 2.081098897482759

Epoch: 6| Step: 6
Training loss: 1.524656057357788
Validation loss: 2.0969324624666603

Epoch: 6| Step: 7
Training loss: 2.117197036743164
Validation loss: 2.104762810532765

Epoch: 6| Step: 8
Training loss: 1.699958324432373
Validation loss: 2.1443070480900426

Epoch: 6| Step: 9
Training loss: 1.9969018697738647
Validation loss: 2.183424413845103

Epoch: 6| Step: 10
Training loss: 1.795445203781128
Validation loss: 2.231218781522525

Epoch: 6| Step: 11
Training loss: 1.9996824264526367
Validation loss: 2.2181358619402816

Epoch: 6| Step: 12
Training loss: 2.8200693130493164
Validation loss: 2.264465690940939

Epoch: 6| Step: 13
Training loss: 1.64832603931427
Validation loss: 2.23732820633919

Epoch: 149| Step: 0
Training loss: 1.9788445234298706
Validation loss: 2.2474269610579296

Epoch: 6| Step: 1
Training loss: 1.5826728343963623
Validation loss: 2.212853253528636

Epoch: 6| Step: 2
Training loss: 2.508021831512451
Validation loss: 2.138664710906244

Epoch: 6| Step: 3
Training loss: 1.6021003723144531
Validation loss: 2.1043026575478176

Epoch: 6| Step: 4
Training loss: 2.1463358402252197
Validation loss: 2.1033691180649625

Epoch: 6| Step: 5
Training loss: 1.8040704727172852
Validation loss: 2.1031815236614597

Epoch: 6| Step: 6
Training loss: 1.9868247509002686
Validation loss: 2.1127231992701048

Epoch: 6| Step: 7
Training loss: 1.6810212135314941
Validation loss: 2.117003643384544

Epoch: 6| Step: 8
Training loss: 1.4129247665405273
Validation loss: 2.139676925956562

Epoch: 6| Step: 9
Training loss: 1.7195658683776855
Validation loss: 2.154505479720331

Epoch: 6| Step: 10
Training loss: 2.4358532428741455
Validation loss: 2.1365869596440303

Epoch: 6| Step: 11
Training loss: 1.3406445980072021
Validation loss: 2.1448014449047785

Epoch: 6| Step: 12
Training loss: 2.456460952758789
Validation loss: 2.1568783457561205

Epoch: 6| Step: 13
Training loss: 1.661257266998291
Validation loss: 2.140137131496142

Epoch: 150| Step: 0
Training loss: 1.8656280040740967
Validation loss: 2.0754227740790254

Epoch: 6| Step: 1
Training loss: 1.6429636478424072
Validation loss: 2.0662385776478756

Epoch: 6| Step: 2
Training loss: 2.6982569694519043
Validation loss: 2.0483133715967976

Epoch: 6| Step: 3
Training loss: 1.8491826057434082
Validation loss: 2.0553202782907793

Epoch: 6| Step: 4
Training loss: 2.3790268898010254
Validation loss: 2.106666426504812

Epoch: 6| Step: 5
Training loss: 2.2339251041412354
Validation loss: 2.1146762178790186

Epoch: 6| Step: 6
Training loss: 1.6946574449539185
Validation loss: 2.1287753671728153

Epoch: 6| Step: 7
Training loss: 1.3429436683654785
Validation loss: 2.1412452113243843

Epoch: 6| Step: 8
Training loss: 1.8768560886383057
Validation loss: 2.114862170270694

Epoch: 6| Step: 9
Training loss: 2.0652623176574707
Validation loss: 2.0962564278674383

Epoch: 6| Step: 10
Training loss: 1.6335105895996094
Validation loss: 2.072055034739997

Epoch: 6| Step: 11
Training loss: 2.010972023010254
Validation loss: 2.0762821679474204

Epoch: 6| Step: 12
Training loss: 1.2710331678390503
Validation loss: 2.12341708008961

Epoch: 6| Step: 13
Training loss: 2.1585171222686768
Validation loss: 2.119701011206514

Epoch: 151| Step: 0
Training loss: 1.6397688388824463
Validation loss: 2.114579416090442

Epoch: 6| Step: 1
Training loss: 1.5392258167266846
Validation loss: 2.1330780598425094

Epoch: 6| Step: 2
Training loss: 1.6885366439819336
Validation loss: 2.1484400559497137

Epoch: 6| Step: 3
Training loss: 2.9389758110046387
Validation loss: 2.2077710910509993

Epoch: 6| Step: 4
Training loss: 1.335723876953125
Validation loss: 2.2565640813560894

Epoch: 6| Step: 5
Training loss: 2.684858798980713
Validation loss: 2.2843848736055437

Epoch: 6| Step: 6
Training loss: 1.5101326704025269
Validation loss: 2.2545849687309674

Epoch: 6| Step: 7
Training loss: 1.9195947647094727
Validation loss: 2.2633023338933147

Epoch: 6| Step: 8
Training loss: 1.0168920755386353
Validation loss: 2.2296363307583715

Epoch: 6| Step: 9
Training loss: 2.2613492012023926
Validation loss: 2.2058426590376

Epoch: 6| Step: 10
Training loss: 2.002486228942871
Validation loss: 2.1910028714005665

Epoch: 6| Step: 11
Training loss: 1.4199700355529785
Validation loss: 2.150281148572122

Epoch: 6| Step: 12
Training loss: 2.3732080459594727
Validation loss: 2.113094275997531

Epoch: 6| Step: 13
Training loss: 1.891753077507019
Validation loss: 2.107418032102687

Epoch: 152| Step: 0
Training loss: 1.9663841724395752
Validation loss: 2.1105752324545257

Epoch: 6| Step: 1
Training loss: 2.0511646270751953
Validation loss: 2.11355733999642

Epoch: 6| Step: 2
Training loss: 2.425900459289551
Validation loss: 2.1092024375033636

Epoch: 6| Step: 3
Training loss: 1.6587672233581543
Validation loss: 2.0917073783054145

Epoch: 6| Step: 4
Training loss: 1.8530778884887695
Validation loss: 2.080887084366173

Epoch: 6| Step: 5
Training loss: 1.8102129697799683
Validation loss: 2.0719130833943686

Epoch: 6| Step: 6
Training loss: 1.2773103713989258
Validation loss: 2.0609843013107136

Epoch: 6| Step: 7
Training loss: 1.576887607574463
Validation loss: 2.0403485836521273

Epoch: 6| Step: 8
Training loss: 2.5234053134918213
Validation loss: 2.0326345953890073

Epoch: 6| Step: 9
Training loss: 2.2217211723327637
Validation loss: 2.0229053728042112

Epoch: 6| Step: 10
Training loss: 1.5360383987426758
Validation loss: 2.036281918966642

Epoch: 6| Step: 11
Training loss: 2.2021327018737793
Validation loss: 2.03259269396464

Epoch: 6| Step: 12
Training loss: 1.3700156211853027
Validation loss: 2.0634099539890083

Epoch: 6| Step: 13
Training loss: 1.9297995567321777
Validation loss: 2.104768837651899

Epoch: 153| Step: 0
Training loss: 2.4369993209838867
Validation loss: 2.1425404164098922

Epoch: 6| Step: 1
Training loss: 1.665724754333496
Validation loss: 2.186260756625924

Epoch: 6| Step: 2
Training loss: 2.308471202850342
Validation loss: 2.203722673077737

Epoch: 6| Step: 3
Training loss: 1.1355394124984741
Validation loss: 2.192789764814479

Epoch: 6| Step: 4
Training loss: 2.3130359649658203
Validation loss: 2.1861049795663483

Epoch: 6| Step: 5
Training loss: 1.0103830099105835
Validation loss: 2.1588561611790813

Epoch: 6| Step: 6
Training loss: 1.762657880783081
Validation loss: 2.1508834015938545

Epoch: 6| Step: 7
Training loss: 2.0801963806152344
Validation loss: 2.16479048421306

Epoch: 6| Step: 8
Training loss: 1.6108427047729492
Validation loss: 2.169021575681625

Epoch: 6| Step: 9
Training loss: 2.093310832977295
Validation loss: 2.165543935632193

Epoch: 6| Step: 10
Training loss: 1.5093580484390259
Validation loss: 2.1503330687040925

Epoch: 6| Step: 11
Training loss: 1.6659060716629028
Validation loss: 2.161074547357457

Epoch: 6| Step: 12
Training loss: 1.4794259071350098
Validation loss: 2.1646314564571587

Epoch: 6| Step: 13
Training loss: 2.6292853355407715
Validation loss: 2.1500823536226825

Epoch: 154| Step: 0
Training loss: 2.263015031814575
Validation loss: 2.158075624896634

Epoch: 6| Step: 1
Training loss: 2.2745471000671387
Validation loss: 2.1524001475303405

Epoch: 6| Step: 2
Training loss: 1.69148588180542
Validation loss: 2.170504090606525

Epoch: 6| Step: 3
Training loss: 1.5255963802337646
Validation loss: 2.1687838198036276

Epoch: 6| Step: 4
Training loss: 2.735088586807251
Validation loss: 2.2033651900547806

Epoch: 6| Step: 5
Training loss: 1.6494909524917603
Validation loss: 2.2209091750524377

Epoch: 6| Step: 6
Training loss: 1.4806333780288696
Validation loss: 2.253433189084453

Epoch: 6| Step: 7
Training loss: 1.436877727508545
Validation loss: 2.2525891501416444

Epoch: 6| Step: 8
Training loss: 1.4744764566421509
Validation loss: 2.2643210400817213

Epoch: 6| Step: 9
Training loss: 1.9320142269134521
Validation loss: 2.257835683002267

Epoch: 6| Step: 10
Training loss: 1.7625726461410522
Validation loss: 2.233111983986311

Epoch: 6| Step: 11
Training loss: 1.7274198532104492
Validation loss: 2.208623565653319

Epoch: 6| Step: 12
Training loss: 1.2742013931274414
Validation loss: 2.1893313828335015

Epoch: 6| Step: 13
Training loss: 1.4320261478424072
Validation loss: 2.1311608335023284

Epoch: 155| Step: 0
Training loss: 1.789347529411316
Validation loss: 2.13767010037617

Epoch: 6| Step: 1
Training loss: 1.5687669515609741
Validation loss: 2.1271333643185195

Epoch: 6| Step: 2
Training loss: 2.011586904525757
Validation loss: 2.1224013400334183

Epoch: 6| Step: 3
Training loss: 1.2733421325683594
Validation loss: 2.1164531515490626

Epoch: 6| Step: 4
Training loss: 1.9825763702392578
Validation loss: 2.1076497698342926

Epoch: 6| Step: 5
Training loss: 2.38474178314209
Validation loss: 2.0988345325634046

Epoch: 6| Step: 6
Training loss: 1.7849514484405518
Validation loss: 2.1038876387380783

Epoch: 6| Step: 7
Training loss: 1.7784976959228516
Validation loss: 2.1134630146846978

Epoch: 6| Step: 8
Training loss: 1.2365450859069824
Validation loss: 2.119640591324017

Epoch: 6| Step: 9
Training loss: 1.4682141542434692
Validation loss: 2.14467998602057

Epoch: 6| Step: 10
Training loss: 2.0787746906280518
Validation loss: 2.1624257743999524

Epoch: 6| Step: 11
Training loss: 1.498513102531433
Validation loss: 2.211526878418461

Epoch: 6| Step: 12
Training loss: 2.1082406044006348
Validation loss: 2.2265451031346477

Epoch: 6| Step: 13
Training loss: 1.7320280075073242
Validation loss: 2.2192958644641343

Epoch: 156| Step: 0
Training loss: 2.3504042625427246
Validation loss: 2.2265477770118305

Epoch: 6| Step: 1
Training loss: 1.5900498628616333
Validation loss: 2.202977021535238

Epoch: 6| Step: 2
Training loss: 1.7800438404083252
Validation loss: 2.2072549071363223

Epoch: 6| Step: 3
Training loss: 2.4034810066223145
Validation loss: 2.2102531566414783

Epoch: 6| Step: 4
Training loss: 1.7954283952713013
Validation loss: 2.2023001973347

Epoch: 6| Step: 5
Training loss: 1.5397422313690186
Validation loss: 2.1400776268333517

Epoch: 6| Step: 6
Training loss: 1.889603614807129
Validation loss: 2.0876012771360335

Epoch: 6| Step: 7
Training loss: 1.617750644683838
Validation loss: 2.056848436273554

Epoch: 6| Step: 8
Training loss: 1.528620958328247
Validation loss: 2.0497321005790465

Epoch: 6| Step: 9
Training loss: 1.266465425491333
Validation loss: 2.0942430803852696

Epoch: 6| Step: 10
Training loss: 1.8185551166534424
Validation loss: 2.098525147284231

Epoch: 6| Step: 11
Training loss: 1.54534912109375
Validation loss: 2.093682046859495

Epoch: 6| Step: 12
Training loss: 1.730033040046692
Validation loss: 2.107424182276572

Epoch: 6| Step: 13
Training loss: 1.8121323585510254
Validation loss: 2.106671740931849

Epoch: 157| Step: 0
Training loss: 1.5652477741241455
Validation loss: 2.15939788920905

Epoch: 6| Step: 1
Training loss: 1.5621740818023682
Validation loss: 2.214654158520442

Epoch: 6| Step: 2
Training loss: 2.1567978858947754
Validation loss: 2.250216478942543

Epoch: 6| Step: 3
Training loss: 1.8785035610198975
Validation loss: 2.25101879847947

Epoch: 6| Step: 4
Training loss: 2.133946418762207
Validation loss: 2.2225609107684066

Epoch: 6| Step: 5
Training loss: 0.9541553258895874
Validation loss: 2.1872159281084613

Epoch: 6| Step: 6
Training loss: 1.7093932628631592
Validation loss: 2.1482812179032194

Epoch: 6| Step: 7
Training loss: 1.8100172281265259
Validation loss: 2.1126411268788

Epoch: 6| Step: 8
Training loss: 1.6668472290039062
Validation loss: 2.095840979647893

Epoch: 6| Step: 9
Training loss: 1.808156967163086
Validation loss: 2.1277886308649534

Epoch: 6| Step: 10
Training loss: 2.353024482727051
Validation loss: 2.1306410425452778

Epoch: 6| Step: 11
Training loss: 2.0584630966186523
Validation loss: 2.136850200673585

Epoch: 6| Step: 12
Training loss: 2.2925543785095215
Validation loss: 2.1091955438736947

Epoch: 6| Step: 13
Training loss: 1.905509114265442
Validation loss: 2.0813453428206907

Epoch: 158| Step: 0
Training loss: 1.593868613243103
Validation loss: 2.0815615346354823

Epoch: 6| Step: 1
Training loss: 1.7131590843200684
Validation loss: 2.0265926238029235

Epoch: 6| Step: 2
Training loss: 1.826486349105835
Validation loss: 2.0323332125140774

Epoch: 6| Step: 3
Training loss: 1.1192703247070312
Validation loss: 2.0870723480819375

Epoch: 6| Step: 4
Training loss: 1.9266917705535889
Validation loss: 2.16064445177714

Epoch: 6| Step: 5
Training loss: 1.8353192806243896
Validation loss: 2.228485917532316

Epoch: 6| Step: 6
Training loss: 1.9649064540863037
Validation loss: 2.30156792876541

Epoch: 6| Step: 7
Training loss: 2.078997850418091
Validation loss: 2.3051343784537366

Epoch: 6| Step: 8
Training loss: 2.543017864227295
Validation loss: 2.3038007136314147

Epoch: 6| Step: 9
Training loss: 2.096238613128662
Validation loss: 2.2524305441046275

Epoch: 6| Step: 10
Training loss: 1.3864959478378296
Validation loss: 2.2209971412535636

Epoch: 6| Step: 11
Training loss: 1.4683778285980225
Validation loss: 2.1942281902477307

Epoch: 6| Step: 12
Training loss: 1.9253939390182495
Validation loss: 2.1307273218708653

Epoch: 6| Step: 13
Training loss: 1.534301519393921
Validation loss: 2.136371689458047

Epoch: 159| Step: 0
Training loss: 1.8996208906173706
Validation loss: 2.104133411120343

Epoch: 6| Step: 1
Training loss: 1.6072795391082764
Validation loss: 2.087910857251895

Epoch: 6| Step: 2
Training loss: 1.9030311107635498
Validation loss: 2.097777658893216

Epoch: 6| Step: 3
Training loss: 1.8184316158294678
Validation loss: 2.064380448351624

Epoch: 6| Step: 4
Training loss: 2.059861183166504
Validation loss: 2.058022633675606

Epoch: 6| Step: 5
Training loss: 2.2195277214050293
Validation loss: 2.0560698047760995

Epoch: 6| Step: 6
Training loss: 1.3611643314361572
Validation loss: 2.0947415764613817

Epoch: 6| Step: 7
Training loss: 1.5724034309387207
Validation loss: 2.125072649730149

Epoch: 6| Step: 8
Training loss: 1.3065203428268433
Validation loss: 2.1872689031785533

Epoch: 6| Step: 9
Training loss: 2.040065288543701
Validation loss: 2.2504326323027253

Epoch: 6| Step: 10
Training loss: 1.2785882949829102
Validation loss: 2.280520221238495

Epoch: 6| Step: 11
Training loss: 2.0942208766937256
Validation loss: 2.3296313593464513

Epoch: 6| Step: 12
Training loss: 2.0706818103790283
Validation loss: 2.3415215605048725

Epoch: 6| Step: 13
Training loss: 1.2134244441986084
Validation loss: 2.3453198222703833

Epoch: 160| Step: 0
Training loss: 2.305558681488037
Validation loss: 2.2890463541912776

Epoch: 6| Step: 1
Training loss: 2.0874123573303223
Validation loss: 2.2026088314671672

Epoch: 6| Step: 2
Training loss: 1.626952052116394
Validation loss: 2.1798445640071744

Epoch: 6| Step: 3
Training loss: 2.1709518432617188
Validation loss: 2.1108041796632993

Epoch: 6| Step: 4
Training loss: 1.3999325037002563
Validation loss: 2.0796604643585863

Epoch: 6| Step: 5
Training loss: 2.1897592544555664
Validation loss: 2.0772829107058945

Epoch: 6| Step: 6
Training loss: 1.1003518104553223
Validation loss: 2.054150619814473

Epoch: 6| Step: 7
Training loss: 1.5095809698104858
Validation loss: 2.03865151123334

Epoch: 6| Step: 8
Training loss: 1.6992391347885132
Validation loss: 2.0273305036688365

Epoch: 6| Step: 9
Training loss: 2.055415153503418
Validation loss: 2.0298029530432915

Epoch: 6| Step: 10
Training loss: 1.2576115131378174
Validation loss: 2.0139879283084663

Epoch: 6| Step: 11
Training loss: 1.6727776527404785
Validation loss: 2.029432730008197

Epoch: 6| Step: 12
Training loss: 1.3837471008300781
Validation loss: 2.0440438485914663

Epoch: 6| Step: 13
Training loss: 1.9227674007415771
Validation loss: 2.0574519275337138

Epoch: 161| Step: 0
Training loss: 1.108891487121582
Validation loss: 2.063950938563193

Epoch: 6| Step: 1
Training loss: 1.8971277475357056
Validation loss: 2.08646696870045

Epoch: 6| Step: 2
Training loss: 1.8664144277572632
Validation loss: 2.1097106536229453

Epoch: 6| Step: 3
Training loss: 1.7903327941894531
Validation loss: 2.144170800844828

Epoch: 6| Step: 4
Training loss: 1.7194818258285522
Validation loss: 2.1273152994853195

Epoch: 6| Step: 5
Training loss: 1.7055187225341797
Validation loss: 2.1719974907495643

Epoch: 6| Step: 6
Training loss: 1.0416699647903442
Validation loss: 2.2128528728280017

Epoch: 6| Step: 7
Training loss: 2.050877571105957
Validation loss: 2.2223695606313725

Epoch: 6| Step: 8
Training loss: 1.805518388748169
Validation loss: 2.2564254704342095

Epoch: 6| Step: 9
Training loss: 1.868624210357666
Validation loss: 2.281863640713435

Epoch: 6| Step: 10
Training loss: 1.6556376218795776
Validation loss: 2.2702763875325522

Epoch: 6| Step: 11
Training loss: 2.013688802719116
Validation loss: 2.2365377064674132

Epoch: 6| Step: 12
Training loss: 1.1221967935562134
Validation loss: 2.2143536101105394

Epoch: 6| Step: 13
Training loss: 2.160447359085083
Validation loss: 2.207467084289879

Epoch: 162| Step: 0
Training loss: 1.814882755279541
Validation loss: 2.1700821204852034

Epoch: 6| Step: 1
Training loss: 1.4449992179870605
Validation loss: 2.1584048296815608

Epoch: 6| Step: 2
Training loss: 2.164724588394165
Validation loss: 2.1106854869473364

Epoch: 6| Step: 3
Training loss: 1.7149314880371094
Validation loss: 2.1190824124120895

Epoch: 6| Step: 4
Training loss: 2.029468297958374
Validation loss: 2.1008910107356247

Epoch: 6| Step: 5
Training loss: 1.7036092281341553
Validation loss: 2.074815359166873

Epoch: 6| Step: 6
Training loss: 1.391740083694458
Validation loss: 2.0460310456573323

Epoch: 6| Step: 7
Training loss: 2.0466365814208984
Validation loss: 2.033047583795363

Epoch: 6| Step: 8
Training loss: 2.1228084564208984
Validation loss: 2.0097279856281896

Epoch: 6| Step: 9
Training loss: 1.1214604377746582
Validation loss: 2.0202483643767652

Epoch: 6| Step: 10
Training loss: 1.6420097351074219
Validation loss: 2.0609268885786816

Epoch: 6| Step: 11
Training loss: 1.5793952941894531
Validation loss: 2.1422292006913053

Epoch: 6| Step: 12
Training loss: 1.4157536029815674
Validation loss: 2.1555237488080095

Epoch: 6| Step: 13
Training loss: 1.8864506483078003
Validation loss: 2.205821257765575

Epoch: 163| Step: 0
Training loss: 1.606884241104126
Validation loss: 2.238270886482731

Epoch: 6| Step: 1
Training loss: 1.5222991704940796
Validation loss: 2.22924627283568

Epoch: 6| Step: 2
Training loss: 1.8050825595855713
Validation loss: 2.2314382291609243

Epoch: 6| Step: 3
Training loss: 1.2492512464523315
Validation loss: 2.2472488367429344

Epoch: 6| Step: 4
Training loss: 2.1338398456573486
Validation loss: 2.248458949468469

Epoch: 6| Step: 5
Training loss: 1.5177645683288574
Validation loss: 2.281326619527673

Epoch: 6| Step: 6
Training loss: 2.08152437210083
Validation loss: 2.2841745615005493

Epoch: 6| Step: 7
Training loss: 1.2508034706115723
Validation loss: 2.262050526116484

Epoch: 6| Step: 8
Training loss: 1.6887693405151367
Validation loss: 2.2160375515619912

Epoch: 6| Step: 9
Training loss: 1.7188974618911743
Validation loss: 2.188959190922399

Epoch: 6| Step: 10
Training loss: 2.0916049480438232
Validation loss: 2.208773292520995

Epoch: 6| Step: 11
Training loss: 1.7040181159973145
Validation loss: 2.2711956885553177

Epoch: 6| Step: 12
Training loss: 2.402560234069824
Validation loss: 2.290074489449942

Epoch: 6| Step: 13
Training loss: 1.9705901145935059
Validation loss: 2.279360484051448

Epoch: 164| Step: 0
Training loss: 1.592372179031372
Validation loss: 2.20926058676935

Epoch: 6| Step: 1
Training loss: 2.19315242767334
Validation loss: 2.154741674341181

Epoch: 6| Step: 2
Training loss: 1.6189634799957275
Validation loss: 2.121761450203516

Epoch: 6| Step: 3
Training loss: 1.585153579711914
Validation loss: 2.025043995149674

Epoch: 6| Step: 4
Training loss: 1.1031956672668457
Validation loss: 1.9859430277219383

Epoch: 6| Step: 5
Training loss: 1.458341121673584
Validation loss: 1.9604902036728398

Epoch: 6| Step: 6
Training loss: 1.5958086252212524
Validation loss: 1.9912324566994943

Epoch: 6| Step: 7
Training loss: 1.5680029392242432
Validation loss: 2.033666318462741

Epoch: 6| Step: 8
Training loss: 1.640632152557373
Validation loss: 2.055157971638505

Epoch: 6| Step: 9
Training loss: 1.9221115112304688
Validation loss: 2.0905872480843657

Epoch: 6| Step: 10
Training loss: 2.083768844604492
Validation loss: 2.110239000730617

Epoch: 6| Step: 11
Training loss: 2.030596971511841
Validation loss: 2.1388244231541953

Epoch: 6| Step: 12
Training loss: 2.3970160484313965
Validation loss: 2.148649856608401

Epoch: 6| Step: 13
Training loss: 1.065470814704895
Validation loss: 2.1472710486381286

Epoch: 165| Step: 0
Training loss: 1.8058669567108154
Validation loss: 2.1933658225561983

Epoch: 6| Step: 1
Training loss: 2.268615245819092
Validation loss: 2.208522688957953

Epoch: 6| Step: 2
Training loss: 1.4078919887542725
Validation loss: 2.2195826845784343

Epoch: 6| Step: 3
Training loss: 1.2677628993988037
Validation loss: 2.19624710723918

Epoch: 6| Step: 4
Training loss: 1.7232064008712769
Validation loss: 2.2003002756385395

Epoch: 6| Step: 5
Training loss: 1.9327641725540161
Validation loss: 2.1883836433451664

Epoch: 6| Step: 6
Training loss: 1.776772379875183
Validation loss: 2.1624600964207805

Epoch: 6| Step: 7
Training loss: 1.085612416267395
Validation loss: 2.161800616530962

Epoch: 6| Step: 8
Training loss: 1.8436579704284668
Validation loss: 2.151618398645873

Epoch: 6| Step: 9
Training loss: 1.3338701725006104
Validation loss: 2.1570813937853743

Epoch: 6| Step: 10
Training loss: 1.615849256515503
Validation loss: 2.1448387843306347

Epoch: 6| Step: 11
Training loss: 1.2665801048278809
Validation loss: 2.164491420151085

Epoch: 6| Step: 12
Training loss: 1.6379514932632446
Validation loss: 2.185472837058447

Epoch: 6| Step: 13
Training loss: 2.0279085636138916
Validation loss: 2.1515413676538775

Epoch: 166| Step: 0
Training loss: 2.1635313034057617
Validation loss: 2.132122601232221

Epoch: 6| Step: 1
Training loss: 1.7393944263458252
Validation loss: 2.1183442005547146

Epoch: 6| Step: 2
Training loss: 1.7615909576416016
Validation loss: 2.133376289439458

Epoch: 6| Step: 3
Training loss: 1.14472234249115
Validation loss: 2.172915442015535

Epoch: 6| Step: 4
Training loss: 1.411729335784912
Validation loss: 2.211786518814743

Epoch: 6| Step: 5
Training loss: 1.7650532722473145
Validation loss: 2.2132796010663434

Epoch: 6| Step: 6
Training loss: 2.14457106590271
Validation loss: 2.1738614087463706

Epoch: 6| Step: 7
Training loss: 1.518803358078003
Validation loss: 2.1760224244927846

Epoch: 6| Step: 8
Training loss: 1.1633777618408203
Validation loss: 2.184638293840552

Epoch: 6| Step: 9
Training loss: 1.567694902420044
Validation loss: 2.205556247823982

Epoch: 6| Step: 10
Training loss: 1.6851584911346436
Validation loss: 2.1947419797220538

Epoch: 6| Step: 11
Training loss: 1.5595436096191406
Validation loss: 2.184576713910667

Epoch: 6| Step: 12
Training loss: 1.7050671577453613
Validation loss: 2.1885683997984855

Epoch: 6| Step: 13
Training loss: 1.6235905885696411
Validation loss: 2.18100070440641

Epoch: 167| Step: 0
Training loss: 1.9049016237258911
Validation loss: 2.171341585856612

Epoch: 6| Step: 1
Training loss: 1.3376543521881104
Validation loss: 2.1462887512740267

Epoch: 6| Step: 2
Training loss: 1.5699421167373657
Validation loss: 2.1730701128641763

Epoch: 6| Step: 3
Training loss: 1.4242525100708008
Validation loss: 2.1771921726965133

Epoch: 6| Step: 4
Training loss: 1.9589636325836182
Validation loss: 2.172640932503567

Epoch: 6| Step: 5
Training loss: 1.715355634689331
Validation loss: 2.1364242030728247

Epoch: 6| Step: 6
Training loss: 1.6762769222259521
Validation loss: 2.109523768066078

Epoch: 6| Step: 7
Training loss: 1.454254388809204
Validation loss: 2.1341979477995183

Epoch: 6| Step: 8
Training loss: 1.6591838598251343
Validation loss: 2.12895958141614

Epoch: 6| Step: 9
Training loss: 1.8140759468078613
Validation loss: 2.145295412309708

Epoch: 6| Step: 10
Training loss: 1.1652487516403198
Validation loss: 2.1544379854714997

Epoch: 6| Step: 11
Training loss: 1.9184331893920898
Validation loss: 2.1382510405714794

Epoch: 6| Step: 12
Training loss: 1.4297728538513184
Validation loss: 2.144968266128212

Epoch: 6| Step: 13
Training loss: 1.4466629028320312
Validation loss: 2.1764476042921825

Epoch: 168| Step: 0
Training loss: 1.2383594512939453
Validation loss: 2.20097456952577

Epoch: 6| Step: 1
Training loss: 1.370718240737915
Validation loss: 2.23178441550142

Epoch: 6| Step: 2
Training loss: 1.6122157573699951
Validation loss: 2.266505979722546

Epoch: 6| Step: 3
Training loss: 1.8139064311981201
Validation loss: 2.256587246412872

Epoch: 6| Step: 4
Training loss: 1.6049827337265015
Validation loss: 2.2718921656249673

Epoch: 6| Step: 5
Training loss: 2.126415729522705
Validation loss: 2.1941256010404198

Epoch: 6| Step: 6
Training loss: 1.956191897392273
Validation loss: 2.123086613993491

Epoch: 6| Step: 7
Training loss: 0.9896304607391357
Validation loss: 2.107654310041858

Epoch: 6| Step: 8
Training loss: 1.720409631729126
Validation loss: 2.071989784958542

Epoch: 6| Step: 9
Training loss: 2.094302177429199
Validation loss: 2.044444863514234

Epoch: 6| Step: 10
Training loss: 1.1520795822143555
Validation loss: 2.056724025357154

Epoch: 6| Step: 11
Training loss: 1.5148873329162598
Validation loss: 2.0504179334127777

Epoch: 6| Step: 12
Training loss: 1.093040943145752
Validation loss: 2.0604950151135846

Epoch: 6| Step: 13
Training loss: 2.6403095722198486
Validation loss: 2.095495175289851

Epoch: 169| Step: 0
Training loss: 1.4429020881652832
Validation loss: 2.1132061378930205

Epoch: 6| Step: 1
Training loss: 1.0745755434036255
Validation loss: 2.1548641881635113

Epoch: 6| Step: 2
Training loss: 1.7299376726150513
Validation loss: 2.205281824193975

Epoch: 6| Step: 3
Training loss: 1.9027330875396729
Validation loss: 2.215919840720392

Epoch: 6| Step: 4
Training loss: 1.8930072784423828
Validation loss: 2.199477744358842

Epoch: 6| Step: 5
Training loss: 1.7615225315093994
Validation loss: 2.1977960576293287

Epoch: 6| Step: 6
Training loss: 1.0249214172363281
Validation loss: 2.2126890395277288

Epoch: 6| Step: 7
Training loss: 1.237051010131836
Validation loss: 2.211194310137021

Epoch: 6| Step: 8
Training loss: 1.5570569038391113
Validation loss: 2.180159273967948

Epoch: 6| Step: 9
Training loss: 1.8765869140625
Validation loss: 2.1655812801853305

Epoch: 6| Step: 10
Training loss: 1.2812751531600952
Validation loss: 2.1586879094441733

Epoch: 6| Step: 11
Training loss: 1.2883540391921997
Validation loss: 2.121612855183181

Epoch: 6| Step: 12
Training loss: 1.610661268234253
Validation loss: 2.138133848867109

Epoch: 6| Step: 13
Training loss: 2.1487655639648438
Validation loss: 2.172538738096914

Epoch: 170| Step: 0
Training loss: 1.3269009590148926
Validation loss: 2.1391713209049676

Epoch: 6| Step: 1
Training loss: 1.7211339473724365
Validation loss: 2.126923762341981

Epoch: 6| Step: 2
Training loss: 1.5030665397644043
Validation loss: 2.1411476494163595

Epoch: 6| Step: 3
Training loss: 1.833486795425415
Validation loss: 2.158735030440874

Epoch: 6| Step: 4
Training loss: 1.2178945541381836
Validation loss: 2.1447862476430912

Epoch: 6| Step: 5
Training loss: 1.1546703577041626
Validation loss: 2.1664714454322733

Epoch: 6| Step: 6
Training loss: 2.087912082672119
Validation loss: 2.1861974731568368

Epoch: 6| Step: 7
Training loss: 0.6087208986282349
Validation loss: 2.182711426929761

Epoch: 6| Step: 8
Training loss: 2.0318961143493652
Validation loss: 2.1976479907189646

Epoch: 6| Step: 9
Training loss: 1.7903755903244019
Validation loss: 2.1817003860268542

Epoch: 6| Step: 10
Training loss: 1.7351361513137817
Validation loss: 2.1688379318483415

Epoch: 6| Step: 11
Training loss: 1.4538853168487549
Validation loss: 2.1578788706051406

Epoch: 6| Step: 12
Training loss: 1.5508127212524414
Validation loss: 2.1615091677634948

Epoch: 6| Step: 13
Training loss: 1.3310859203338623
Validation loss: 2.1665966433863484

Epoch: 171| Step: 0
Training loss: 1.136231541633606
Validation loss: 2.179140406270181

Epoch: 6| Step: 1
Training loss: 1.2459800243377686
Validation loss: 2.182250561252717

Epoch: 6| Step: 2
Training loss: 1.7790744304656982
Validation loss: 2.197094694260628

Epoch: 6| Step: 3
Training loss: 1.232969880104065
Validation loss: 2.20110418463266

Epoch: 6| Step: 4
Training loss: 1.6236510276794434
Validation loss: 2.2228084943627797

Epoch: 6| Step: 5
Training loss: 2.2810401916503906
Validation loss: 2.2486191872627503

Epoch: 6| Step: 6
Training loss: 0.9826959371566772
Validation loss: 2.2047162286696897

Epoch: 6| Step: 7
Training loss: 1.5502475500106812
Validation loss: 2.1795899227101314

Epoch: 6| Step: 8
Training loss: 1.674390435218811
Validation loss: 2.1710460365459485

Epoch: 6| Step: 9
Training loss: 1.796858549118042
Validation loss: 2.163364887237549

Epoch: 6| Step: 10
Training loss: 1.4241122007369995
Validation loss: 2.1651008180392686

Epoch: 6| Step: 11
Training loss: 1.694230318069458
Validation loss: 2.1362451763563257

Epoch: 6| Step: 12
Training loss: 1.289550542831421
Validation loss: 2.1275491855477773

Epoch: 6| Step: 13
Training loss: 1.3324508666992188
Validation loss: 2.1455043567124235

Epoch: 172| Step: 0
Training loss: 1.5685570240020752
Validation loss: 2.105864747878044

Epoch: 6| Step: 1
Training loss: 1.245858907699585
Validation loss: 2.094523263233964

Epoch: 6| Step: 2
Training loss: 1.5456254482269287
Validation loss: 2.1156746008062877

Epoch: 6| Step: 3
Training loss: 1.4186060428619385
Validation loss: 2.1137138823027253

Epoch: 6| Step: 4
Training loss: 1.6358006000518799
Validation loss: 2.10130415936952

Epoch: 6| Step: 5
Training loss: 1.3863449096679688
Validation loss: 2.1241888205210366

Epoch: 6| Step: 6
Training loss: 1.1337798833847046
Validation loss: 2.134398506533715

Epoch: 6| Step: 7
Training loss: 1.7208141088485718
Validation loss: 2.1497232426879225

Epoch: 6| Step: 8
Training loss: 1.4203389883041382
Validation loss: 2.1455108196504655

Epoch: 6| Step: 9
Training loss: 1.1914961338043213
Validation loss: 2.1472127001772643

Epoch: 6| Step: 10
Training loss: 1.2095921039581299
Validation loss: 2.132894731337024

Epoch: 6| Step: 11
Training loss: 1.9434932470321655
Validation loss: 2.1761901686268468

Epoch: 6| Step: 12
Training loss: 1.8107528686523438
Validation loss: 2.2217798027940976

Epoch: 6| Step: 13
Training loss: 1.778921365737915
Validation loss: 2.2431171760764173

Epoch: 173| Step: 0
Training loss: 1.4344398975372314
Validation loss: 2.2903228549547094

Epoch: 6| Step: 1
Training loss: 1.8717734813690186
Validation loss: 2.3355571531480357

Epoch: 6| Step: 2
Training loss: 1.305527925491333
Validation loss: 2.317958208822435

Epoch: 6| Step: 3
Training loss: 1.5773775577545166
Validation loss: 2.303763484442106

Epoch: 6| Step: 4
Training loss: 1.5130362510681152
Validation loss: 2.267307309694188

Epoch: 6| Step: 5
Training loss: 0.8715584874153137
Validation loss: 2.1496107039913053

Epoch: 6| Step: 6
Training loss: 1.9078307151794434
Validation loss: 2.108819071964551

Epoch: 6| Step: 7
Training loss: 1.6513856649398804
Validation loss: 2.105000762529271

Epoch: 6| Step: 8
Training loss: 2.3725814819335938
Validation loss: 2.1091646020130446

Epoch: 6| Step: 9
Training loss: 1.5607753992080688
Validation loss: 2.115993115209764

Epoch: 6| Step: 10
Training loss: 1.757176160812378
Validation loss: 2.108882619488624

Epoch: 6| Step: 11
Training loss: 1.6674373149871826
Validation loss: 2.1261533767946306

Epoch: 6| Step: 12
Training loss: 0.9937881231307983
Validation loss: 2.120466516863915

Epoch: 6| Step: 13
Training loss: 1.6244417428970337
Validation loss: 2.118826186785134

Epoch: 174| Step: 0
Training loss: 1.136034369468689
Validation loss: 2.1595048930055354

Epoch: 6| Step: 1
Training loss: 1.066075086593628
Validation loss: 2.21111644980728

Epoch: 6| Step: 2
Training loss: 1.1871380805969238
Validation loss: 2.2616565150599324

Epoch: 6| Step: 3
Training loss: 1.8866199254989624
Validation loss: 2.3194544751157045

Epoch: 6| Step: 4
Training loss: 1.5174620151519775
Validation loss: 2.3380393264114216

Epoch: 6| Step: 5
Training loss: 1.8753697872161865
Validation loss: 2.3466680742079213

Epoch: 6| Step: 6
Training loss: 2.1311068534851074
Validation loss: 2.3268388266204507

Epoch: 6| Step: 7
Training loss: 1.354947805404663
Validation loss: 2.325374226416311

Epoch: 6| Step: 8
Training loss: 1.5018945932388306
Validation loss: 2.344877246887453

Epoch: 6| Step: 9
Training loss: 1.4699474573135376
Validation loss: 2.336949784268615

Epoch: 6| Step: 10
Training loss: 1.674156904220581
Validation loss: 2.3010220758376585

Epoch: 6| Step: 11
Training loss: 2.053554058074951
Validation loss: 2.247765164221487

Epoch: 6| Step: 12
Training loss: 1.7070212364196777
Validation loss: 2.206266357052711

Epoch: 6| Step: 13
Training loss: 1.481781005859375
Validation loss: 2.15713140015961

Epoch: 175| Step: 0
Training loss: 1.9385368824005127
Validation loss: 2.1518994210868754

Epoch: 6| Step: 1
Training loss: 1.416632890701294
Validation loss: 2.1134396291548208

Epoch: 6| Step: 2
Training loss: 1.4874122142791748
Validation loss: 2.011116753342331

Epoch: 6| Step: 3
Training loss: 1.3918418884277344
Validation loss: 2.015049393459033

Epoch: 6| Step: 4
Training loss: 1.458008885383606
Validation loss: 2.0481826874517624

Epoch: 6| Step: 5
Training loss: 1.4416847229003906
Validation loss: 2.0549415952415875

Epoch: 6| Step: 6
Training loss: 1.850024700164795
Validation loss: 2.1064273952155985

Epoch: 6| Step: 7
Training loss: 1.4552795886993408
Validation loss: 2.112254435016263

Epoch: 6| Step: 8
Training loss: 1.3732848167419434
Validation loss: 2.107355874071839

Epoch: 6| Step: 9
Training loss: 1.6417288780212402
Validation loss: 2.1118820303229877

Epoch: 6| Step: 10
Training loss: 1.654983639717102
Validation loss: 2.114209795510897

Epoch: 6| Step: 11
Training loss: 1.4460303783416748
Validation loss: 2.133190139647453

Epoch: 6| Step: 12
Training loss: 1.2384495735168457
Validation loss: 2.20948508093434

Epoch: 6| Step: 13
Training loss: 1.447747826576233
Validation loss: 2.2478845657840854

Epoch: 176| Step: 0
Training loss: 1.6852742433547974
Validation loss: 2.3082188560116674

Epoch: 6| Step: 1
Training loss: 1.3775571584701538
Validation loss: 2.3205292917067006

Epoch: 6| Step: 2
Training loss: 1.8744717836380005
Validation loss: 2.305113620655511

Epoch: 6| Step: 3
Training loss: 1.7720904350280762
Validation loss: 2.281329547205279

Epoch: 6| Step: 4
Training loss: 1.8854469060897827
Validation loss: 2.280512950753653

Epoch: 6| Step: 5
Training loss: 1.4176541566848755
Validation loss: 2.195454264199862

Epoch: 6| Step: 6
Training loss: 1.2435364723205566
Validation loss: 2.1540578488380677

Epoch: 6| Step: 7
Training loss: 1.0454761981964111
Validation loss: 2.0966145518005534

Epoch: 6| Step: 8
Training loss: 1.5495156049728394
Validation loss: 2.1036693562743483

Epoch: 6| Step: 9
Training loss: 1.0154260396957397
Validation loss: 2.118018965567312

Epoch: 6| Step: 10
Training loss: 1.276800513267517
Validation loss: 2.161189909904234

Epoch: 6| Step: 11
Training loss: 1.925537109375
Validation loss: 2.234758307856898

Epoch: 6| Step: 12
Training loss: 1.7259635925292969
Validation loss: 2.224417166043353

Epoch: 6| Step: 13
Training loss: 1.501977801322937
Validation loss: 2.2070834405960573

Epoch: 177| Step: 0
Training loss: 1.7850828170776367
Validation loss: 2.2411657020609868

Epoch: 6| Step: 1
Training loss: 1.603230357170105
Validation loss: 2.2046069355421167

Epoch: 6| Step: 2
Training loss: 0.9881290197372437
Validation loss: 2.1313941581274873

Epoch: 6| Step: 3
Training loss: 1.3081722259521484
Validation loss: 2.0925962104592273

Epoch: 6| Step: 4
Training loss: 1.5958037376403809
Validation loss: 2.0882924346513647

Epoch: 6| Step: 5
Training loss: 2.152329206466675
Validation loss: 2.0983472165241035

Epoch: 6| Step: 6
Training loss: 1.7079105377197266
Validation loss: 2.0896689571360105

Epoch: 6| Step: 7
Training loss: 1.1948249340057373
Validation loss: 2.1154521383265013

Epoch: 6| Step: 8
Training loss: 1.0347543954849243
Validation loss: 2.1412056274311517

Epoch: 6| Step: 9
Training loss: 1.5622303485870361
Validation loss: 2.1959274917520504

Epoch: 6| Step: 10
Training loss: 1.0034806728363037
Validation loss: 2.2140445414409844

Epoch: 6| Step: 11
Training loss: 1.1949880123138428
Validation loss: 2.2058335914406726

Epoch: 6| Step: 12
Training loss: 1.3554415702819824
Validation loss: 2.1780842222193235

Epoch: 6| Step: 13
Training loss: 1.6466336250305176
Validation loss: 2.1678214252636

Epoch: 178| Step: 0
Training loss: 1.425681233406067
Validation loss: 2.2037745368096138

Epoch: 6| Step: 1
Training loss: 1.0037329196929932
Validation loss: 2.2350043442941483

Epoch: 6| Step: 2
Training loss: 1.8321871757507324
Validation loss: 2.260240218972647

Epoch: 6| Step: 3
Training loss: 1.8282268047332764
Validation loss: 2.2616891707143476

Epoch: 6| Step: 4
Training loss: 1.4135243892669678
Validation loss: 2.2732966433289232

Epoch: 6| Step: 5
Training loss: 1.5682260990142822
Validation loss: 2.25058687374156

Epoch: 6| Step: 6
Training loss: 1.1054280996322632
Validation loss: 2.251373093615296

Epoch: 6| Step: 7
Training loss: 1.7460336685180664
Validation loss: 2.2250579992930093

Epoch: 6| Step: 8
Training loss: 0.958419919013977
Validation loss: 2.174288275421307

Epoch: 6| Step: 9
Training loss: 1.1062008142471313
Validation loss: 2.1758595846032582

Epoch: 6| Step: 10
Training loss: 1.105734944343567
Validation loss: 2.1433718050679853

Epoch: 6| Step: 11
Training loss: 1.662414312362671
Validation loss: 2.1302111071925007

Epoch: 6| Step: 12
Training loss: 1.7299220561981201
Validation loss: 2.1207977571795062

Epoch: 6| Step: 13
Training loss: 1.6241695880889893
Validation loss: 2.0634499275556175

Epoch: 179| Step: 0
Training loss: 0.9591065645217896
Validation loss: 2.0667205972056233

Epoch: 6| Step: 1
Training loss: 0.9321001172065735
Validation loss: 2.044750810951315

Epoch: 6| Step: 2
Training loss: 1.3765308856964111
Validation loss: 2.048509427296218

Epoch: 6| Step: 3
Training loss: 1.5760667324066162
Validation loss: 2.0758145650227866

Epoch: 6| Step: 4
Training loss: 1.8006598949432373
Validation loss: 2.0872742129910375

Epoch: 6| Step: 5
Training loss: 2.479511260986328
Validation loss: 2.0834296698211343

Epoch: 6| Step: 6
Training loss: 0.9605767130851746
Validation loss: 2.0836879668697232

Epoch: 6| Step: 7
Training loss: 1.1919095516204834
Validation loss: 2.0917576256618706

Epoch: 6| Step: 8
Training loss: 0.8640695810317993
Validation loss: 2.122925235379127

Epoch: 6| Step: 9
Training loss: 1.2362383604049683
Validation loss: 2.1540589255671345

Epoch: 6| Step: 10
Training loss: 1.2066335678100586
Validation loss: 2.2262091047020367

Epoch: 6| Step: 11
Training loss: 1.6298801898956299
Validation loss: 2.301073346086728

Epoch: 6| Step: 12
Training loss: 1.9849250316619873
Validation loss: 2.3288621197464647

Epoch: 6| Step: 13
Training loss: 1.902569055557251
Validation loss: 2.359005679366409

Epoch: 180| Step: 0
Training loss: 1.5995844602584839
Validation loss: 2.3680335629370903

Epoch: 6| Step: 1
Training loss: 1.525757074356079
Validation loss: 2.346495125883369

Epoch: 6| Step: 2
Training loss: 1.1375532150268555
Validation loss: 2.2914428377664215

Epoch: 6| Step: 3
Training loss: 1.1672180891036987
Validation loss: 2.304152855309107

Epoch: 6| Step: 4
Training loss: 2.0982489585876465
Validation loss: 2.28844702628351

Epoch: 6| Step: 5
Training loss: 0.8663785457611084
Validation loss: 2.261004627391856

Epoch: 6| Step: 6
Training loss: 1.3637768030166626
Validation loss: 2.219900305553149

Epoch: 6| Step: 7
Training loss: 1.8843295574188232
Validation loss: 2.1444995851926905

Epoch: 6| Step: 8
Training loss: 1.5838755369186401
Validation loss: 2.0894002119700112

Epoch: 6| Step: 9
Training loss: 1.3837491273880005
Validation loss: 2.041580048940515

Epoch: 6| Step: 10
Training loss: 1.3047112226486206
Validation loss: 1.9903066440295147

Epoch: 6| Step: 11
Training loss: 1.8863427639007568
Validation loss: 2.0026797325380388

Epoch: 6| Step: 12
Training loss: 0.846415638923645
Validation loss: 2.0090748622853267

Epoch: 6| Step: 13
Training loss: 1.519356608390808
Validation loss: 2.020424199360673

Epoch: 181| Step: 0
Training loss: 0.8400640487670898
Validation loss: 2.0955991014357536

Epoch: 6| Step: 1
Training loss: 1.2986083030700684
Validation loss: 2.1808802209874636

Epoch: 6| Step: 2
Training loss: 1.7612993717193604
Validation loss: 2.1851571593233334

Epoch: 6| Step: 3
Training loss: 1.7249855995178223
Validation loss: 2.151416959301118

Epoch: 6| Step: 4
Training loss: 1.8745336532592773
Validation loss: 2.1132090912070325

Epoch: 6| Step: 5
Training loss: 1.1539788246154785
Validation loss: 2.0961221725709978

Epoch: 6| Step: 6
Training loss: 1.304182529449463
Validation loss: 2.0576430828340593

Epoch: 6| Step: 7
Training loss: 1.7918729782104492
Validation loss: 2.055002021533187

Epoch: 6| Step: 8
Training loss: 1.314281940460205
Validation loss: 2.0935185609325284

Epoch: 6| Step: 9
Training loss: 1.2180004119873047
Validation loss: 2.0952442897263395

Epoch: 6| Step: 10
Training loss: 1.434805154800415
Validation loss: 2.107083006571698

Epoch: 6| Step: 11
Training loss: 1.2049535512924194
Validation loss: 2.0611319324021697

Epoch: 6| Step: 12
Training loss: 1.453235387802124
Validation loss: 2.0564710811902116

Epoch: 6| Step: 13
Training loss: 1.560309886932373
Validation loss: 2.0874491532643638

Epoch: 182| Step: 0
Training loss: 1.903290867805481
Validation loss: 2.054841137701465

Epoch: 6| Step: 1
Training loss: 1.2207697629928589
Validation loss: 2.075797155339231

Epoch: 6| Step: 2
Training loss: 1.6921577453613281
Validation loss: 2.0623777707417807

Epoch: 6| Step: 3
Training loss: 1.553051471710205
Validation loss: 2.0976929664611816

Epoch: 6| Step: 4
Training loss: 1.6761047840118408
Validation loss: 2.1096048175647693

Epoch: 6| Step: 5
Training loss: 1.4662377834320068
Validation loss: 2.161761817111764

Epoch: 6| Step: 6
Training loss: 1.700748324394226
Validation loss: 2.1613488710054787

Epoch: 6| Step: 7
Training loss: 0.9741998910903931
Validation loss: 2.2153441675247683

Epoch: 6| Step: 8
Training loss: 1.433075189590454
Validation loss: 2.245272604368066

Epoch: 6| Step: 9
Training loss: 1.4057799577713013
Validation loss: 2.294675105361528

Epoch: 6| Step: 10
Training loss: 1.324765682220459
Validation loss: 2.281512801365186

Epoch: 6| Step: 11
Training loss: 0.9494569301605225
Validation loss: 2.270194735578311

Epoch: 6| Step: 12
Training loss: 1.4526087045669556
Validation loss: 2.196261485417684

Epoch: 6| Step: 13
Training loss: 0.8714179992675781
Validation loss: 2.141023387191116

Epoch: 183| Step: 0
Training loss: 1.8569350242614746
Validation loss: 2.1152629813840313

Epoch: 6| Step: 1
Training loss: 1.6533278226852417
Validation loss: 2.0933186648994364

Epoch: 6| Step: 2
Training loss: 1.2355064153671265
Validation loss: 2.0971722474662204

Epoch: 6| Step: 3
Training loss: 1.2632217407226562
Validation loss: 2.0611909845823884

Epoch: 6| Step: 4
Training loss: 1.556931495666504
Validation loss: 2.069708287075002

Epoch: 6| Step: 5
Training loss: 0.8868736028671265
Validation loss: 2.0937935536907566

Epoch: 6| Step: 6
Training loss: 1.0681936740875244
Validation loss: 2.1244215875543575

Epoch: 6| Step: 7
Training loss: 1.697801113128662
Validation loss: 2.1409968278741323

Epoch: 6| Step: 8
Training loss: 1.1652824878692627
Validation loss: 2.205739446865615

Epoch: 6| Step: 9
Training loss: 1.3723130226135254
Validation loss: 2.2489476075736423

Epoch: 6| Step: 10
Training loss: 1.7205653190612793
Validation loss: 2.2872803236848567

Epoch: 6| Step: 11
Training loss: 1.0957425832748413
Validation loss: 2.270525065801477

Epoch: 6| Step: 12
Training loss: 1.413489580154419
Validation loss: 2.261364536900674

Epoch: 6| Step: 13
Training loss: 1.6995229721069336
Validation loss: 2.240807928064818

Epoch: 184| Step: 0
Training loss: 1.2633535861968994
Validation loss: 2.1583936060628583

Epoch: 6| Step: 1
Training loss: 0.7442431449890137
Validation loss: 2.145937401761291

Epoch: 6| Step: 2
Training loss: 1.1410794258117676
Validation loss: 2.1217249247335617

Epoch: 6| Step: 3
Training loss: 2.07529878616333
Validation loss: 2.0956012792484735

Epoch: 6| Step: 4
Training loss: 1.9244885444641113
Validation loss: 2.059357991782568

Epoch: 6| Step: 5
Training loss: 1.219207525253296
Validation loss: 2.064533802770799

Epoch: 6| Step: 6
Training loss: 1.44181489944458
Validation loss: 2.095257156638689

Epoch: 6| Step: 7
Training loss: 1.3519855737686157
Validation loss: 2.087225447418869

Epoch: 6| Step: 8
Training loss: 1.2364307641983032
Validation loss: 2.1163057101670133

Epoch: 6| Step: 9
Training loss: 1.7796623706817627
Validation loss: 2.1489128387102516

Epoch: 6| Step: 10
Training loss: 1.0235599279403687
Validation loss: 2.189828183061333

Epoch: 6| Step: 11
Training loss: 1.6800265312194824
Validation loss: 2.167951137788834

Epoch: 6| Step: 12
Training loss: 1.2642568349838257
Validation loss: 2.1507070654182026

Epoch: 6| Step: 13
Training loss: 1.0078333616256714
Validation loss: 2.118050003564486

Epoch: 185| Step: 0
Training loss: 1.6658295392990112
Validation loss: 2.088860023406244

Epoch: 6| Step: 1
Training loss: 0.7920105457305908
Validation loss: 2.061311806401899

Epoch: 6| Step: 2
Training loss: 1.7706058025360107
Validation loss: 2.0737197629867063

Epoch: 6| Step: 3
Training loss: 1.054776668548584
Validation loss: 2.0468746782631

Epoch: 6| Step: 4
Training loss: 2.1417136192321777
Validation loss: 2.0644521546620194

Epoch: 6| Step: 5
Training loss: 1.584388017654419
Validation loss: 2.0423036775281354

Epoch: 6| Step: 6
Training loss: 0.9104542136192322
Validation loss: 2.0542122548626316

Epoch: 6| Step: 7
Training loss: 1.0080771446228027
Validation loss: 2.079793503207545

Epoch: 6| Step: 8
Training loss: 1.4634838104248047
Validation loss: 2.1316123688092796

Epoch: 6| Step: 9
Training loss: 1.6568212509155273
Validation loss: 2.1062294475493895

Epoch: 6| Step: 10
Training loss: 0.6529918909072876
Validation loss: 2.0657670882440384

Epoch: 6| Step: 11
Training loss: 0.949748158454895
Validation loss: 2.0341476958285094

Epoch: 6| Step: 12
Training loss: 1.6259384155273438
Validation loss: 2.0418544700068813

Epoch: 6| Step: 13
Training loss: 1.2898619174957275
Validation loss: 2.0471664013401156

Epoch: 186| Step: 0
Training loss: 0.7620012164115906
Validation loss: 2.032788215144988

Epoch: 6| Step: 1
Training loss: 1.6390103101730347
Validation loss: 2.059250439366987

Epoch: 6| Step: 2
Training loss: 1.7891349792480469
Validation loss: 2.0827118927432644

Epoch: 6| Step: 3
Training loss: 0.9306989908218384
Validation loss: 2.0574092095898044

Epoch: 6| Step: 4
Training loss: 1.597523808479309
Validation loss: 2.0568947689507597

Epoch: 6| Step: 5
Training loss: 1.3998807668685913
Validation loss: 2.0306531972782587

Epoch: 6| Step: 6
Training loss: 1.1563823223114014
Validation loss: 2.0642459956548547

Epoch: 6| Step: 7
Training loss: 0.8793193697929382
Validation loss: 2.0600686073303223

Epoch: 6| Step: 8
Training loss: 1.3858909606933594
Validation loss: 2.096405049806

Epoch: 6| Step: 9
Training loss: 1.2838670015335083
Validation loss: 2.124112365066364

Epoch: 6| Step: 10
Training loss: 1.4456545114517212
Validation loss: 2.101305642435628

Epoch: 6| Step: 11
Training loss: 1.447155237197876
Validation loss: 2.1159606684920607

Epoch: 6| Step: 12
Training loss: 0.9943238496780396
Validation loss: 2.1203091093288955

Epoch: 6| Step: 13
Training loss: 1.797111988067627
Validation loss: 2.114077642399778

Epoch: 187| Step: 0
Training loss: 1.6856176853179932
Validation loss: 2.12016144106465

Epoch: 6| Step: 1
Training loss: 0.7992902994155884
Validation loss: 2.1082962892388784

Epoch: 6| Step: 2
Training loss: 1.3164434432983398
Validation loss: 2.1226051187002533

Epoch: 6| Step: 3
Training loss: 1.3358261585235596
Validation loss: 2.1535394319923977

Epoch: 6| Step: 4
Training loss: 1.4569724798202515
Validation loss: 2.1686915402771323

Epoch: 6| Step: 5
Training loss: 0.8060724139213562
Validation loss: 2.1676929637949955

Epoch: 6| Step: 6
Training loss: 1.3949594497680664
Validation loss: 2.138896257646622

Epoch: 6| Step: 7
Training loss: 1.061708688735962
Validation loss: 2.09999503115172

Epoch: 6| Step: 8
Training loss: 1.641916036605835
Validation loss: 2.071782690222545

Epoch: 6| Step: 9
Training loss: 1.4022889137268066
Validation loss: 2.0348592086504866

Epoch: 6| Step: 10
Training loss: 1.604760766029358
Validation loss: 2.086216201064407

Epoch: 6| Step: 11
Training loss: 1.2117938995361328
Validation loss: 2.0607471607064687

Epoch: 6| Step: 12
Training loss: 1.1741254329681396
Validation loss: 2.065288887229017

Epoch: 6| Step: 13
Training loss: 0.9236228466033936
Validation loss: 2.0728519834497923

Epoch: 188| Step: 0
Training loss: 1.8979902267456055
Validation loss: 2.1130219544133833

Epoch: 6| Step: 1
Training loss: 1.0225303173065186
Validation loss: 2.1128238554923766

Epoch: 6| Step: 2
Training loss: 0.879982054233551
Validation loss: 2.107167249084801

Epoch: 6| Step: 3
Training loss: 1.6478278636932373
Validation loss: 2.1746175930064213

Epoch: 6| Step: 4
Training loss: 1.0317981243133545
Validation loss: 2.16773283866144

Epoch: 6| Step: 5
Training loss: 1.4243885278701782
Validation loss: 2.174261377703759

Epoch: 6| Step: 6
Training loss: 0.8324881792068481
Validation loss: 2.226238250732422

Epoch: 6| Step: 7
Training loss: 1.4250364303588867
Validation loss: 2.2116036325372677

Epoch: 6| Step: 8
Training loss: 0.8229274749755859
Validation loss: 2.1677516147654545

Epoch: 6| Step: 9
Training loss: 1.5807206630706787
Validation loss: 2.11287937882126

Epoch: 6| Step: 10
Training loss: 1.1561312675476074
Validation loss: 2.0352172672107653

Epoch: 6| Step: 11
Training loss: 1.2996985912322998
Validation loss: 2.0068753214292627

Epoch: 6| Step: 12
Training loss: 1.8626830577850342
Validation loss: 1.9684601791443364

Epoch: 6| Step: 13
Training loss: 0.833794116973877
Validation loss: 1.9591426362273514

Epoch: 189| Step: 0
Training loss: 1.2574999332427979
Validation loss: 1.9929412590560092

Epoch: 6| Step: 1
Training loss: 1.0894030332565308
Validation loss: 1.9943092343627766

Epoch: 6| Step: 2
Training loss: 1.5485951900482178
Validation loss: 2.019825789236253

Epoch: 6| Step: 3
Training loss: 1.1355894804000854
Validation loss: 2.0656461690061834

Epoch: 6| Step: 4
Training loss: 1.0394338369369507
Validation loss: 2.096989244543096

Epoch: 6| Step: 5
Training loss: 0.6536033749580383
Validation loss: 2.1690748788977183

Epoch: 6| Step: 6
Training loss: 1.5838289260864258
Validation loss: 2.2175571508305048

Epoch: 6| Step: 7
Training loss: 1.8060917854309082
Validation loss: 2.252448119143004

Epoch: 6| Step: 8
Training loss: 1.7398595809936523
Validation loss: 2.224372870178633

Epoch: 6| Step: 9
Training loss: 1.745652198791504
Validation loss: 2.202441620570357

Epoch: 6| Step: 10
Training loss: 1.0403817892074585
Validation loss: 2.1995398126622683

Epoch: 6| Step: 11
Training loss: 0.811683177947998
Validation loss: 2.128073646176246

Epoch: 6| Step: 12
Training loss: 1.1445329189300537
Validation loss: 2.1052870993973105

Epoch: 6| Step: 13
Training loss: 1.4812942743301392
Validation loss: 2.100240539478999

Epoch: 190| Step: 0
Training loss: 1.8783910274505615
Validation loss: 2.121956056164157

Epoch: 6| Step: 1
Training loss: 1.1528509855270386
Validation loss: 2.1457829552312053

Epoch: 6| Step: 2
Training loss: 1.0245352983474731
Validation loss: 2.2033212595088507

Epoch: 6| Step: 3
Training loss: 0.9968029260635376
Validation loss: 2.2014715543357273

Epoch: 6| Step: 4
Training loss: 1.0731850862503052
Validation loss: 2.1621363214267197

Epoch: 6| Step: 5
Training loss: 0.7926210165023804
Validation loss: 2.1131260984687397

Epoch: 6| Step: 6
Training loss: 1.2195504903793335
Validation loss: 2.0633094336396907

Epoch: 6| Step: 7
Training loss: 1.3609501123428345
Validation loss: 2.087346475611451

Epoch: 6| Step: 8
Training loss: 1.2982170581817627
Validation loss: 2.1144597479092178

Epoch: 6| Step: 9
Training loss: 1.0856026411056519
Validation loss: 2.1420686424419446

Epoch: 6| Step: 10
Training loss: 1.5042130947113037
Validation loss: 2.179465136220378

Epoch: 6| Step: 11
Training loss: 1.8699140548706055
Validation loss: 2.2280898811996623

Epoch: 6| Step: 12
Training loss: 1.8940850496292114
Validation loss: 2.2194642866811445

Epoch: 6| Step: 13
Training loss: 0.6073817014694214
Validation loss: 2.2015226451299523

Epoch: 191| Step: 0
Training loss: 1.904089093208313
Validation loss: 2.2187558015187583

Epoch: 6| Step: 1
Training loss: 1.335273265838623
Validation loss: 2.1967336567499305

Epoch: 6| Step: 2
Training loss: 1.2889248132705688
Validation loss: 2.184669984284268

Epoch: 6| Step: 3
Training loss: 1.193192720413208
Validation loss: 2.1128178206823205

Epoch: 6| Step: 4
Training loss: 1.2084811925888062
Validation loss: 2.067207295407531

Epoch: 6| Step: 5
Training loss: 1.3558270931243896
Validation loss: 2.082728385925293

Epoch: 6| Step: 6
Training loss: 1.1830165386199951
Validation loss: 2.106898292418449

Epoch: 6| Step: 7
Training loss: 1.4665311574935913
Validation loss: 2.1167848161471787

Epoch: 6| Step: 8
Training loss: 1.322536587715149
Validation loss: 2.1244049892630628

Epoch: 6| Step: 9
Training loss: 1.4043629169464111
Validation loss: 2.1167316667495237

Epoch: 6| Step: 10
Training loss: 0.9290892481803894
Validation loss: 2.101857534018896

Epoch: 6| Step: 11
Training loss: 0.6168705224990845
Validation loss: 2.0602810690479894

Epoch: 6| Step: 12
Training loss: 0.9942301511764526
Validation loss: 2.002816234865496

Epoch: 6| Step: 13
Training loss: 0.9230606555938721
Validation loss: 2.000233422043503

Epoch: 192| Step: 0
Training loss: 1.559651255607605
Validation loss: 1.96550246977037

Epoch: 6| Step: 1
Training loss: 0.9531499147415161
Validation loss: 1.9610901801816878

Epoch: 6| Step: 2
Training loss: 1.0840327739715576
Validation loss: 1.9675798416137695

Epoch: 6| Step: 3
Training loss: 1.3561619520187378
Validation loss: 1.9628548083766815

Epoch: 6| Step: 4
Training loss: 0.9726935625076294
Validation loss: 1.9795535354204075

Epoch: 6| Step: 5
Training loss: 1.4663527011871338
Validation loss: 2.02574630706541

Epoch: 6| Step: 6
Training loss: 0.687471866607666
Validation loss: 2.0501439597017024

Epoch: 6| Step: 7
Training loss: 1.9097765684127808
Validation loss: 2.0583772492665116

Epoch: 6| Step: 8
Training loss: 1.5957450866699219
Validation loss: 2.064875010521181

Epoch: 6| Step: 9
Training loss: 1.5860992670059204
Validation loss: 2.0672921083306752

Epoch: 6| Step: 10
Training loss: 1.166822910308838
Validation loss: 2.0545788785462737

Epoch: 6| Step: 11
Training loss: 0.924228310585022
Validation loss: 2.0393473153473227

Epoch: 6| Step: 12
Training loss: 0.8353932499885559
Validation loss: 2.040941058948476

Epoch: 6| Step: 13
Training loss: 0.7029598951339722
Validation loss: 2.05244174567602

Epoch: 193| Step: 0
Training loss: 1.1824350357055664
Validation loss: 2.077456771686513

Epoch: 6| Step: 1
Training loss: 0.8858089447021484
Validation loss: 2.0842070887165685

Epoch: 6| Step: 2
Training loss: 1.6969727277755737
Validation loss: 2.1168264829984276

Epoch: 6| Step: 3
Training loss: 0.8860196471214294
Validation loss: 2.0883692874703357

Epoch: 6| Step: 4
Training loss: 0.6984552145004272
Validation loss: 2.0823427977100497

Epoch: 6| Step: 5
Training loss: 1.3109307289123535
Validation loss: 2.063686342649562

Epoch: 6| Step: 6
Training loss: 1.2756614685058594
Validation loss: 2.0846065193094234

Epoch: 6| Step: 7
Training loss: 1.271862268447876
Validation loss: 2.0554402182179112

Epoch: 6| Step: 8
Training loss: 1.1562190055847168
Validation loss: 2.0662656932748775

Epoch: 6| Step: 9
Training loss: 1.7697612047195435
Validation loss: 2.0787390765323432

Epoch: 6| Step: 10
Training loss: 0.9269158244132996
Validation loss: 2.1164415754297727

Epoch: 6| Step: 11
Training loss: 1.304774284362793
Validation loss: 2.157553231844338

Epoch: 6| Step: 12
Training loss: 1.5423142910003662
Validation loss: 2.1664519489452405

Epoch: 6| Step: 13
Training loss: 1.2024247646331787
Validation loss: 2.1714155109979774

Epoch: 194| Step: 0
Training loss: 1.055982232093811
Validation loss: 2.1559532816692064

Epoch: 6| Step: 1
Training loss: 0.7403867244720459
Validation loss: 2.165297192911948

Epoch: 6| Step: 2
Training loss: 1.4772948026657104
Validation loss: 2.1349473691755727

Epoch: 6| Step: 3
Training loss: 0.9623849391937256
Validation loss: 2.1047369241714478

Epoch: 6| Step: 4
Training loss: 1.1630693674087524
Validation loss: 2.0990883432408816

Epoch: 6| Step: 5
Training loss: 1.0313153266906738
Validation loss: 2.0513683749783422

Epoch: 6| Step: 6
Training loss: 1.4960328340530396
Validation loss: 2.016014657994752

Epoch: 6| Step: 7
Training loss: 1.7294718027114868
Validation loss: 1.9972120741362214

Epoch: 6| Step: 8
Training loss: 1.260163426399231
Validation loss: 2.001539562338142

Epoch: 6| Step: 9
Training loss: 0.5649589896202087
Validation loss: 1.9739123570021762

Epoch: 6| Step: 10
Training loss: 1.5801446437835693
Validation loss: 1.9771047138398694

Epoch: 6| Step: 11
Training loss: 1.4251888990402222
Validation loss: 1.9852198170077415

Epoch: 6| Step: 12
Training loss: 1.0248531103134155
Validation loss: 1.9772867015613023

Epoch: 6| Step: 13
Training loss: 1.423154592514038
Validation loss: 2.0118952464031916

Epoch: 195| Step: 0
Training loss: 1.2415578365325928
Validation loss: 2.0410270408917497

Epoch: 6| Step: 1
Training loss: 1.2316367626190186
Validation loss: 2.109510047461397

Epoch: 6| Step: 2
Training loss: 1.4345511198043823
Validation loss: 2.1681788967501734

Epoch: 6| Step: 3
Training loss: 1.386518955230713
Validation loss: 2.174791430914274

Epoch: 6| Step: 4
Training loss: 0.7619180083274841
Validation loss: 2.1768345781551894

Epoch: 6| Step: 5
Training loss: 1.0243617296218872
Validation loss: 2.181976220941031

Epoch: 6| Step: 6
Training loss: 1.1443393230438232
Validation loss: 2.156569670605403

Epoch: 6| Step: 7
Training loss: 0.9014023542404175
Validation loss: 2.105520271485852

Epoch: 6| Step: 8
Training loss: 1.2909917831420898
Validation loss: 2.0896625672617266

Epoch: 6| Step: 9
Training loss: 1.711024284362793
Validation loss: 2.016302740702065

Epoch: 6| Step: 10
Training loss: 1.3756710290908813
Validation loss: 1.981384551653298

Epoch: 6| Step: 11
Training loss: 1.1424936056137085
Validation loss: 1.972626527150472

Epoch: 6| Step: 12
Training loss: 1.1141549348831177
Validation loss: 2.0056966838016304

Epoch: 6| Step: 13
Training loss: 1.360876441001892
Validation loss: 2.024852713590027

Epoch: 196| Step: 0
Training loss: 0.9831746816635132
Validation loss: 2.0603384048708024

Epoch: 6| Step: 1
Training loss: 1.2622593641281128
Validation loss: 2.1190115046757523

Epoch: 6| Step: 2
Training loss: 0.8687701225280762
Validation loss: 2.094676638162264

Epoch: 6| Step: 3
Training loss: 1.4369404315948486
Validation loss: 2.099140139036281

Epoch: 6| Step: 4
Training loss: 1.7546865940093994
Validation loss: 2.1322967031950593

Epoch: 6| Step: 5
Training loss: 1.0300984382629395
Validation loss: 2.1061252342757357

Epoch: 6| Step: 6
Training loss: 1.524940848350525
Validation loss: 2.069410870152135

Epoch: 6| Step: 7
Training loss: 1.2242013216018677
Validation loss: 2.0822224642640803

Epoch: 6| Step: 8
Training loss: 0.9324100613594055
Validation loss: 2.113609452401438

Epoch: 6| Step: 9
Training loss: 1.1802942752838135
Validation loss: 2.118749980003603

Epoch: 6| Step: 10
Training loss: 1.3197048902511597
Validation loss: 2.1503741728362216

Epoch: 6| Step: 11
Training loss: 0.6139023303985596
Validation loss: 2.1139828133326706

Epoch: 6| Step: 12
Training loss: 1.6521635055541992
Validation loss: 2.0795558793570406

Epoch: 6| Step: 13
Training loss: 1.486882209777832
Validation loss: 2.067949389898649

Epoch: 197| Step: 0
Training loss: 1.5843660831451416
Validation loss: 2.047264793867706

Epoch: 6| Step: 1
Training loss: 1.1708232164382935
Validation loss: 2.047824239218107

Epoch: 6| Step: 2
Training loss: 1.18338942527771
Validation loss: 2.037311900046564

Epoch: 6| Step: 3
Training loss: 1.74127995967865
Validation loss: 2.01028267029793

Epoch: 6| Step: 4
Training loss: 1.350758671760559
Validation loss: 2.0118516978397163

Epoch: 6| Step: 5
Training loss: 1.3116635084152222
Validation loss: 1.9923308587843371

Epoch: 6| Step: 6
Training loss: 0.8522509932518005
Validation loss: 2.0191664644466933

Epoch: 6| Step: 7
Training loss: 0.6595450043678284
Validation loss: 2.0213044253728722

Epoch: 6| Step: 8
Training loss: 1.1787687540054321
Validation loss: 2.030655566082206

Epoch: 6| Step: 9
Training loss: 1.3678746223449707
Validation loss: 2.0539966014123734

Epoch: 6| Step: 10
Training loss: 1.3738945722579956
Validation loss: 2.050709327061971

Epoch: 6| Step: 11
Training loss: 1.0931220054626465
Validation loss: 2.1097491479689077

Epoch: 6| Step: 12
Training loss: 1.0480631589889526
Validation loss: 2.098657223486131

Epoch: 6| Step: 13
Training loss: 0.6975737810134888
Validation loss: 2.1318757995482414

Epoch: 198| Step: 0
Training loss: 1.5137858390808105
Validation loss: 2.127437107024654

Epoch: 6| Step: 1
Training loss: 1.4158775806427002
Validation loss: 2.063942769522308

Epoch: 6| Step: 2
Training loss: 0.9111098647117615
Validation loss: 2.085556874993027

Epoch: 6| Step: 3
Training loss: 1.5802887678146362
Validation loss: 2.0739995869257117

Epoch: 6| Step: 4
Training loss: 0.7560920119285583
Validation loss: 2.06545784524692

Epoch: 6| Step: 5
Training loss: 0.9562243819236755
Validation loss: 2.063327755979312

Epoch: 6| Step: 6
Training loss: 1.1755207777023315
Validation loss: 2.06124351614265

Epoch: 6| Step: 7
Training loss: 1.4009172916412354
Validation loss: 2.042230785533946

Epoch: 6| Step: 8
Training loss: 1.1821579933166504
Validation loss: 2.062952992736652

Epoch: 6| Step: 9
Training loss: 1.1182583570480347
Validation loss: 2.0517465401721258

Epoch: 6| Step: 10
Training loss: 1.3510046005249023
Validation loss: 2.0811557821048203

Epoch: 6| Step: 11
Training loss: 1.1846884489059448
Validation loss: 2.083803715244416

Epoch: 6| Step: 12
Training loss: 1.0656882524490356
Validation loss: 2.058407240016486

Epoch: 6| Step: 13
Training loss: 0.8343909382820129
Validation loss: 2.0477312687904603

Epoch: 199| Step: 0
Training loss: 1.1229496002197266
Validation loss: 2.0396308591288905

Epoch: 6| Step: 1
Training loss: 0.8942815065383911
Validation loss: 2.0319093260713803

Epoch: 6| Step: 2
Training loss: 0.9764259457588196
Validation loss: 2.0006502059198197

Epoch: 6| Step: 3
Training loss: 1.6766297817230225
Validation loss: 1.9612453445311515

Epoch: 6| Step: 4
Training loss: 1.4137378931045532
Validation loss: 1.9566692690695486

Epoch: 6| Step: 5
Training loss: 1.4339561462402344
Validation loss: 1.9478564185480918

Epoch: 6| Step: 6
Training loss: 1.3003435134887695
Validation loss: 1.9114200556150047

Epoch: 6| Step: 7
Training loss: 1.3965928554534912
Validation loss: 1.9307379402140135

Epoch: 6| Step: 8
Training loss: 1.134696364402771
Validation loss: 1.9223609867916311

Epoch: 6| Step: 9
Training loss: 1.4816710948944092
Validation loss: 2.0035685070099367

Epoch: 6| Step: 10
Training loss: 1.0958975553512573
Validation loss: 2.0831157174161685

Epoch: 6| Step: 11
Training loss: 0.8276797533035278
Validation loss: 2.1384907717345865

Epoch: 6| Step: 12
Training loss: 1.097273826599121
Validation loss: 2.1545635628443893

Epoch: 6| Step: 13
Training loss: 0.7825325131416321
Validation loss: 2.155363130313094

Epoch: 200| Step: 0
Training loss: 0.8388048410415649
Validation loss: 2.0856691201527915

Epoch: 6| Step: 1
Training loss: 1.0124937295913696
Validation loss: 2.0262566330612346

Epoch: 6| Step: 2
Training loss: 1.298480749130249
Validation loss: 1.96802738020497

Epoch: 6| Step: 3
Training loss: 1.3824191093444824
Validation loss: 1.9416163864956106

Epoch: 6| Step: 4
Training loss: 1.3571187257766724
Validation loss: 1.9214935456552813

Epoch: 6| Step: 5
Training loss: 1.28081476688385
Validation loss: 1.8725735372112644

Epoch: 6| Step: 6
Training loss: 1.9275730848312378
Validation loss: 1.875921715972244

Epoch: 6| Step: 7
Training loss: 1.3210546970367432
Validation loss: 1.88753846896592

Epoch: 6| Step: 8
Training loss: 1.1652171611785889
Validation loss: 1.8951265658101728

Epoch: 6| Step: 9
Training loss: 1.0426054000854492
Validation loss: 1.883985621954805

Epoch: 6| Step: 10
Training loss: 1.7290445566177368
Validation loss: 1.9616580573461389

Epoch: 6| Step: 11
Training loss: 0.8315331935882568
Validation loss: 2.017862537855743

Epoch: 6| Step: 12
Training loss: 0.5722700953483582
Validation loss: 2.0781302785360687

Epoch: 6| Step: 13
Training loss: 0.9157311916351318
Validation loss: 2.1086263938616683

Epoch: 201| Step: 0
Training loss: 1.2192115783691406
Validation loss: 2.175810965158606

Epoch: 6| Step: 1
Training loss: 1.3844560384750366
Validation loss: 2.227345597359442

Epoch: 6| Step: 2
Training loss: 1.6454051733016968
Validation loss: 2.22426115569248

Epoch: 6| Step: 3
Training loss: 0.9384816288948059
Validation loss: 2.214312614933137

Epoch: 6| Step: 4
Training loss: 1.0521857738494873
Validation loss: 2.198884963989258

Epoch: 6| Step: 5
Training loss: 1.0272815227508545
Validation loss: 2.172458533317812

Epoch: 6| Step: 6
Training loss: 1.8796868324279785
Validation loss: 2.0961904769302695

Epoch: 6| Step: 7
Training loss: 1.2734644412994385
Validation loss: 2.0821837148358746

Epoch: 6| Step: 8
Training loss: 1.1899762153625488
Validation loss: 2.0341296785621235

Epoch: 6| Step: 9
Training loss: 0.9870713949203491
Validation loss: 2.0389078124876945

Epoch: 6| Step: 10
Training loss: 0.3921920955181122
Validation loss: 2.001027509730349

Epoch: 6| Step: 11
Training loss: 1.1385672092437744
Validation loss: 1.9898504211056618

Epoch: 6| Step: 12
Training loss: 1.307076096534729
Validation loss: 1.9601786905719387

Epoch: 6| Step: 13
Training loss: 0.9921644926071167
Validation loss: 1.956283204017147

Epoch: 202| Step: 0
Training loss: 1.0423349142074585
Validation loss: 1.9068223430264382

Epoch: 6| Step: 1
Training loss: 0.778546929359436
Validation loss: 1.929546401064883

Epoch: 6| Step: 2
Training loss: 1.3708415031433105
Validation loss: 1.9472975013076619

Epoch: 6| Step: 3
Training loss: 1.1998319625854492
Validation loss: 1.9585066687676214

Epoch: 6| Step: 4
Training loss: 1.8857131004333496
Validation loss: 1.9950785457447011

Epoch: 6| Step: 5
Training loss: 0.8818545341491699
Validation loss: 2.026973029618622

Epoch: 6| Step: 6
Training loss: 0.975152850151062
Validation loss: 2.0969943859243907

Epoch: 6| Step: 7
Training loss: 0.868379533290863
Validation loss: 2.1266957662438832

Epoch: 6| Step: 8
Training loss: 1.3447277545928955
Validation loss: 2.171916320759763

Epoch: 6| Step: 9
Training loss: 1.2110551595687866
Validation loss: 2.1931548221136934

Epoch: 6| Step: 10
Training loss: 1.3631768226623535
Validation loss: 2.087637424468994

Epoch: 6| Step: 11
Training loss: 0.8323224782943726
Validation loss: 1.9830583090423255

Epoch: 6| Step: 12
Training loss: 1.2420599460601807
Validation loss: 1.987513228129315

Epoch: 6| Step: 13
Training loss: 1.30830717086792
Validation loss: 1.9760582498324815

Epoch: 203| Step: 0
Training loss: 1.405447006225586
Validation loss: 1.958977077596931

Epoch: 6| Step: 1
Training loss: 1.338728427886963
Validation loss: 1.9696107718252367

Epoch: 6| Step: 2
Training loss: 0.6655322909355164
Validation loss: 1.9734050612295828

Epoch: 6| Step: 3
Training loss: 0.9843642115592957
Validation loss: 1.9780617324254846

Epoch: 6| Step: 4
Training loss: 1.7144749164581299
Validation loss: 1.9660677499668573

Epoch: 6| Step: 5
Training loss: 0.9887620210647583
Validation loss: 2.0011457409909976

Epoch: 6| Step: 6
Training loss: 1.0859284400939941
Validation loss: 2.0653257690450197

Epoch: 6| Step: 7
Training loss: 1.361668348312378
Validation loss: 2.071280315358152

Epoch: 6| Step: 8
Training loss: 0.8627513647079468
Validation loss: 2.0788698529684417

Epoch: 6| Step: 9
Training loss: 1.1080398559570312
Validation loss: 2.071013722368466

Epoch: 6| Step: 10
Training loss: 1.2881507873535156
Validation loss: 2.027966196819018

Epoch: 6| Step: 11
Training loss: 0.933192789554596
Validation loss: 2.018619183571108

Epoch: 6| Step: 12
Training loss: 1.0244146585464478
Validation loss: 2.052530329714539

Epoch: 6| Step: 13
Training loss: 1.143941879272461
Validation loss: 2.041895071665446

Epoch: 204| Step: 0
Training loss: 1.3159722089767456
Validation loss: 1.9807384283311906

Epoch: 6| Step: 1
Training loss: 0.9955443143844604
Validation loss: 2.0083404740979596

Epoch: 6| Step: 2
Training loss: 0.9580864906311035
Validation loss: 2.0272710169515302

Epoch: 6| Step: 3
Training loss: 0.7395225763320923
Validation loss: 2.063656732600222

Epoch: 6| Step: 4
Training loss: 1.1544055938720703
Validation loss: 2.0916997373745008

Epoch: 6| Step: 5
Training loss: 1.6336919069290161
Validation loss: 2.1175840285516556

Epoch: 6| Step: 6
Training loss: 1.3802828788757324
Validation loss: 2.125355617974394

Epoch: 6| Step: 7
Training loss: 1.7001906633377075
Validation loss: 2.0884464940717145

Epoch: 6| Step: 8
Training loss: 1.2321498394012451
Validation loss: 2.032194346509954

Epoch: 6| Step: 9
Training loss: 1.0582358837127686
Validation loss: 2.011269905233896

Epoch: 6| Step: 10
Training loss: 1.1886532306671143
Validation loss: 1.933812964347101

Epoch: 6| Step: 11
Training loss: 1.0823923349380493
Validation loss: 1.925580709211288

Epoch: 6| Step: 12
Training loss: 0.6910017728805542
Validation loss: 1.9235416304680608

Epoch: 6| Step: 13
Training loss: 0.9373511075973511
Validation loss: 1.917967645070886

Epoch: 205| Step: 0
Training loss: 0.8951512575149536
Validation loss: 1.9621929904466033

Epoch: 6| Step: 1
Training loss: 1.0165300369262695
Validation loss: 2.0271594498747136

Epoch: 6| Step: 2
Training loss: 1.2363193035125732
Validation loss: 2.056211056247834

Epoch: 6| Step: 3
Training loss: 1.4344102144241333
Validation loss: 2.074555257315277

Epoch: 6| Step: 4
Training loss: 1.3289272785186768
Validation loss: 2.118112302595569

Epoch: 6| Step: 5
Training loss: 1.068447470664978
Validation loss: 2.069442947705587

Epoch: 6| Step: 6
Training loss: 1.5916507244110107
Validation loss: 2.057328962510632

Epoch: 6| Step: 7
Training loss: 1.0596046447753906
Validation loss: 2.0527804846404702

Epoch: 6| Step: 8
Training loss: 0.7839536666870117
Validation loss: 2.016777102665235

Epoch: 6| Step: 9
Training loss: 1.4207792282104492
Validation loss: 2.05633415842569

Epoch: 6| Step: 10
Training loss: 0.828394889831543
Validation loss: 2.0574944647409583

Epoch: 6| Step: 11
Training loss: 0.8826459646224976
Validation loss: 2.0463914922488633

Epoch: 6| Step: 12
Training loss: 1.1953407526016235
Validation loss: 2.090793207127561

Epoch: 6| Step: 13
Training loss: 1.2064505815505981
Validation loss: 2.1399675979409167

Epoch: 206| Step: 0
Training loss: 1.18314528465271
Validation loss: 2.108736512481525

Epoch: 6| Step: 1
Training loss: 0.9416192770004272
Validation loss: 2.139425805819932

Epoch: 6| Step: 2
Training loss: 1.0605124235153198
Validation loss: 2.1377656126535065

Epoch: 6| Step: 3
Training loss: 1.8806800842285156
Validation loss: 2.090779504468364

Epoch: 6| Step: 4
Training loss: 1.0100475549697876
Validation loss: 2.0768873730013446

Epoch: 6| Step: 5
Training loss: 1.1379165649414062
Validation loss: 2.0145288334097913

Epoch: 6| Step: 6
Training loss: 1.055591344833374
Validation loss: 1.9794976480545536

Epoch: 6| Step: 7
Training loss: 0.8701070547103882
Validation loss: 1.9785948466229182

Epoch: 6| Step: 8
Training loss: 0.9169242978096008
Validation loss: 1.9381285611019339

Epoch: 6| Step: 9
Training loss: 1.8525818586349487
Validation loss: 1.95394943862833

Epoch: 6| Step: 10
Training loss: 0.7158650159835815
Validation loss: 1.9401866825678016

Epoch: 6| Step: 11
Training loss: 0.8940783143043518
Validation loss: 1.9545104144721903

Epoch: 6| Step: 12
Training loss: 0.9372718334197998
Validation loss: 1.9602436288710563

Epoch: 6| Step: 13
Training loss: 1.3992202281951904
Validation loss: 1.9623770226714432

Epoch: 207| Step: 0
Training loss: 1.2604601383209229
Validation loss: 1.9724767733645696

Epoch: 6| Step: 1
Training loss: 1.1953904628753662
Validation loss: 1.9887358527029715

Epoch: 6| Step: 2
Training loss: 0.8070369362831116
Validation loss: 2.021579768068047

Epoch: 6| Step: 3
Training loss: 1.2355618476867676
Validation loss: 2.081466600459109

Epoch: 6| Step: 4
Training loss: 1.2061502933502197
Validation loss: 2.1313342573822185

Epoch: 6| Step: 5
Training loss: 1.4793779850006104
Validation loss: 2.1312626395174252

Epoch: 6| Step: 6
Training loss: 0.739952027797699
Validation loss: 2.1012909463656846

Epoch: 6| Step: 7
Training loss: 0.9753669500350952
Validation loss: 2.0308055672594296

Epoch: 6| Step: 8
Training loss: 0.8254560828208923
Validation loss: 2.033667546446605

Epoch: 6| Step: 9
Training loss: 0.8681148290634155
Validation loss: 2.009002529164796

Epoch: 6| Step: 10
Training loss: 1.4003888368606567
Validation loss: 1.982622415788712

Epoch: 6| Step: 11
Training loss: 0.6529974341392517
Validation loss: 1.9608194828033447

Epoch: 6| Step: 12
Training loss: 1.1103466749191284
Validation loss: 1.997562321283484

Epoch: 6| Step: 13
Training loss: 1.7034791707992554
Validation loss: 2.015139974573607

Epoch: 208| Step: 0
Training loss: 0.9397968053817749
Validation loss: 2.0275664842256935

Epoch: 6| Step: 1
Training loss: 0.9986323714256287
Validation loss: 2.028232266826014

Epoch: 6| Step: 2
Training loss: 0.7601523399353027
Validation loss: 2.037009440442567

Epoch: 6| Step: 3
Training loss: 0.8652970790863037
Validation loss: 2.0783212415633665

Epoch: 6| Step: 4
Training loss: 0.41677308082580566
Validation loss: 2.06345957838079

Epoch: 6| Step: 5
Training loss: 1.4962809085845947
Validation loss: 2.0162252610729587

Epoch: 6| Step: 6
Training loss: 1.301687240600586
Validation loss: 2.002626253712562

Epoch: 6| Step: 7
Training loss: 1.1431505680084229
Validation loss: 1.9784482717514038

Epoch: 6| Step: 8
Training loss: 0.9813448786735535
Validation loss: 1.9888915220896404

Epoch: 6| Step: 9
Training loss: 0.9141961336135864
Validation loss: 1.9587355608581214

Epoch: 6| Step: 10
Training loss: 1.4521453380584717
Validation loss: 1.99702634093582

Epoch: 6| Step: 11
Training loss: 1.5157334804534912
Validation loss: 1.969994943629029

Epoch: 6| Step: 12
Training loss: 1.125439167022705
Validation loss: 1.9637863802653488

Epoch: 6| Step: 13
Training loss: 1.3049572706222534
Validation loss: 2.017988133174117

Epoch: 209| Step: 0
Training loss: 0.8303157091140747
Validation loss: 2.0410724506583264

Epoch: 6| Step: 1
Training loss: 1.268119215965271
Validation loss: 2.070525506491302

Epoch: 6| Step: 2
Training loss: 0.9957190752029419
Validation loss: 2.0942035900649203

Epoch: 6| Step: 3
Training loss: 1.045381784439087
Validation loss: 2.0926978985468545

Epoch: 6| Step: 4
Training loss: 1.8594019412994385
Validation loss: 2.1147513363950994

Epoch: 6| Step: 5
Training loss: 0.6019012928009033
Validation loss: 2.0695375562995992

Epoch: 6| Step: 6
Training loss: 1.0307526588439941
Validation loss: 2.0551658804698656

Epoch: 6| Step: 7
Training loss: 1.310243010520935
Validation loss: 2.0341309347460346

Epoch: 6| Step: 8
Training loss: 0.7981008291244507
Validation loss: 2.008614581118348

Epoch: 6| Step: 9
Training loss: 0.8231974840164185
Validation loss: 2.001233567473709

Epoch: 6| Step: 10
Training loss: 1.043264627456665
Validation loss: 2.0005921240775817

Epoch: 6| Step: 11
Training loss: 0.7786998152732849
Validation loss: 2.0069536650052635

Epoch: 6| Step: 12
Training loss: 1.2808018922805786
Validation loss: 1.9976106100184943

Epoch: 6| Step: 13
Training loss: 0.7659644484519958
Validation loss: 2.011963262352892

Epoch: 210| Step: 0
Training loss: 1.6988250017166138
Validation loss: 2.029069936403664

Epoch: 6| Step: 1
Training loss: 0.9404760003089905
Validation loss: 2.0360497428524877

Epoch: 6| Step: 2
Training loss: 0.8792508840560913
Validation loss: 2.0593344908888622

Epoch: 6| Step: 3
Training loss: 1.3550580739974976
Validation loss: 2.048884919894639

Epoch: 6| Step: 4
Training loss: 1.2603355646133423
Validation loss: 2.111048900952903

Epoch: 6| Step: 5
Training loss: 0.45820438861846924
Validation loss: 2.0981422931917253

Epoch: 6| Step: 6
Training loss: 1.0296828746795654
Validation loss: 2.0557373108402377

Epoch: 6| Step: 7
Training loss: 0.9252851605415344
Validation loss: 2.027777983296302

Epoch: 6| Step: 8
Training loss: 1.061539888381958
Validation loss: 2.0159700096294446

Epoch: 6| Step: 9
Training loss: 1.45669686794281
Validation loss: 2.0429131241254908

Epoch: 6| Step: 10
Training loss: 1.1322314739227295
Validation loss: 2.064611686173306

Epoch: 6| Step: 11
Training loss: 0.901938796043396
Validation loss: 1.9485537672555575

Epoch: 6| Step: 12
Training loss: 1.1368366479873657
Validation loss: 1.9302591239252398

Epoch: 6| Step: 13
Training loss: 0.7215120792388916
Validation loss: 1.9357436985097907

Epoch: 211| Step: 0
Training loss: 0.8481051921844482
Validation loss: 1.892004479644119

Epoch: 6| Step: 1
Training loss: 1.0125274658203125
Validation loss: 1.9529511979831162

Epoch: 6| Step: 2
Training loss: 1.157902717590332
Validation loss: 1.9465245495560348

Epoch: 6| Step: 3
Training loss: 1.071415662765503
Validation loss: 2.0163745854490545

Epoch: 6| Step: 4
Training loss: 0.8401937484741211
Validation loss: 2.0427135293201735

Epoch: 6| Step: 5
Training loss: 1.1314367055892944
Validation loss: 2.042873663287009

Epoch: 6| Step: 6
Training loss: 0.5604909658432007
Validation loss: 2.0580492199108167

Epoch: 6| Step: 7
Training loss: 1.3307427167892456
Validation loss: 2.034296638222151

Epoch: 6| Step: 8
Training loss: 1.5231928825378418
Validation loss: 2.047680908633817

Epoch: 6| Step: 9
Training loss: 1.2821781635284424
Validation loss: 2.060694812446512

Epoch: 6| Step: 10
Training loss: 0.7960383296012878
Validation loss: 2.0663531800752044

Epoch: 6| Step: 11
Training loss: 1.0778968334197998
Validation loss: 2.1277217711171796

Epoch: 6| Step: 12
Training loss: 1.4122118949890137
Validation loss: 2.14637436661669

Epoch: 6| Step: 13
Training loss: 0.9157791137695312
Validation loss: 2.125037339425856

Epoch: 212| Step: 0
Training loss: 0.8481338024139404
Validation loss: 2.1201170567543275

Epoch: 6| Step: 1
Training loss: 0.9282464385032654
Validation loss: 2.1183739528861096

Epoch: 6| Step: 2
Training loss: 0.7326204180717468
Validation loss: 2.0540526272148214

Epoch: 6| Step: 3
Training loss: 1.1818346977233887
Validation loss: 2.0515018227279826

Epoch: 6| Step: 4
Training loss: 1.3517239093780518
Validation loss: 2.0016833338686215

Epoch: 6| Step: 5
Training loss: 1.185125708580017
Validation loss: 1.9493866594888831

Epoch: 6| Step: 6
Training loss: 1.1512162685394287
Validation loss: 1.9753135327369935

Epoch: 6| Step: 7
Training loss: 1.2179780006408691
Validation loss: 1.9004057120251399

Epoch: 6| Step: 8
Training loss: 1.093338966369629
Validation loss: 1.9187884228203886

Epoch: 6| Step: 9
Training loss: 0.8572923541069031
Validation loss: 1.964948873366079

Epoch: 6| Step: 10
Training loss: 1.1748712062835693
Validation loss: 1.9791953076598465

Epoch: 6| Step: 11
Training loss: 1.2404910326004028
Validation loss: 2.0225944852316253

Epoch: 6| Step: 12
Training loss: 0.8344943523406982
Validation loss: 2.064578442163365

Epoch: 6| Step: 13
Training loss: 0.964608907699585
Validation loss: 2.0498817633557063

Epoch: 213| Step: 0
Training loss: 0.5819419026374817
Validation loss: 2.0633860313764183

Epoch: 6| Step: 1
Training loss: 1.1738274097442627
Validation loss: 2.0719965081061087

Epoch: 6| Step: 2
Training loss: 0.7115857601165771
Validation loss: 2.0804215900359617

Epoch: 6| Step: 3
Training loss: 1.0791645050048828
Validation loss: 2.0295177441771313

Epoch: 6| Step: 4
Training loss: 0.9283548593521118
Validation loss: 1.9827455448847946

Epoch: 6| Step: 5
Training loss: 1.3375025987625122
Validation loss: 1.9283417065938313

Epoch: 6| Step: 6
Training loss: 1.3313078880310059
Validation loss: 1.902342451516018

Epoch: 6| Step: 7
Training loss: 1.4329020977020264
Validation loss: 1.8803196299460627

Epoch: 6| Step: 8
Training loss: 1.0534181594848633
Validation loss: 1.9209280654948244

Epoch: 6| Step: 9
Training loss: 0.6440368890762329
Validation loss: 1.9127131098060197

Epoch: 6| Step: 10
Training loss: 1.2121130228042603
Validation loss: 1.9794304473425752

Epoch: 6| Step: 11
Training loss: 0.9250083565711975
Validation loss: 2.083245272277504

Epoch: 6| Step: 12
Training loss: 0.7783717513084412
Validation loss: 2.1180199166779876

Epoch: 6| Step: 13
Training loss: 1.4956340789794922
Validation loss: 2.196064676007917

Epoch: 214| Step: 0
Training loss: 1.2057234048843384
Validation loss: 2.2254661206276185

Epoch: 6| Step: 1
Training loss: 1.0082204341888428
Validation loss: 2.2664309163247385

Epoch: 6| Step: 2
Training loss: 1.0942003726959229
Validation loss: 2.2014262727511826

Epoch: 6| Step: 3
Training loss: 1.135995626449585
Validation loss: 2.144270021428344

Epoch: 6| Step: 4
Training loss: 1.2073696851730347
Validation loss: 2.111095231066468

Epoch: 6| Step: 5
Training loss: 0.687178373336792
Validation loss: 2.0121597346439155

Epoch: 6| Step: 6
Training loss: 0.8926423192024231
Validation loss: 1.98998386116438

Epoch: 6| Step: 7
Training loss: 1.6984717845916748
Validation loss: 1.9528886874516804

Epoch: 6| Step: 8
Training loss: 1.0438095331192017
Validation loss: 1.9189046262412943

Epoch: 6| Step: 9
Training loss: 1.2246437072753906
Validation loss: 1.8849275099333895

Epoch: 6| Step: 10
Training loss: 0.8495806455612183
Validation loss: 1.8437868805341824

Epoch: 6| Step: 11
Training loss: 0.8566123247146606
Validation loss: 1.8254274296504196

Epoch: 6| Step: 12
Training loss: 0.7190041542053223
Validation loss: 1.8340089526227725

Epoch: 6| Step: 13
Training loss: 1.1164989471435547
Validation loss: 1.8472509230336835

Epoch: 215| Step: 0
Training loss: 0.9197809100151062
Validation loss: 1.8548443830141457

Epoch: 6| Step: 1
Training loss: 0.5711908340454102
Validation loss: 1.9428028880908925

Epoch: 6| Step: 2
Training loss: 0.8147987723350525
Validation loss: 2.0074845616535475

Epoch: 6| Step: 3
Training loss: 1.0016393661499023
Validation loss: 2.072308796708302

Epoch: 6| Step: 4
Training loss: 0.737165093421936
Validation loss: 2.039947404656359

Epoch: 6| Step: 5
Training loss: 0.6491239666938782
Validation loss: 2.056982191660071

Epoch: 6| Step: 6
Training loss: 1.7295007705688477
Validation loss: 2.022071752496945

Epoch: 6| Step: 7
Training loss: 1.494012713432312
Validation loss: 1.9951040411508212

Epoch: 6| Step: 8
Training loss: 1.2399797439575195
Validation loss: 1.9581004393998014

Epoch: 6| Step: 9
Training loss: 1.1597576141357422
Validation loss: 1.95249802835526

Epoch: 6| Step: 10
Training loss: 0.961898148059845
Validation loss: 1.911292620884475

Epoch: 6| Step: 11
Training loss: 0.6682939529418945
Validation loss: 1.935475589126669

Epoch: 6| Step: 12
Training loss: 0.8415106534957886
Validation loss: 1.940383586832272

Epoch: 6| Step: 13
Training loss: 1.946839451789856
Validation loss: 2.000874719312114

Epoch: 216| Step: 0
Training loss: 1.0676443576812744
Validation loss: 1.961646023616996

Epoch: 6| Step: 1
Training loss: 1.4405434131622314
Validation loss: 1.9694857866533342

Epoch: 6| Step: 2
Training loss: 0.5063101053237915
Validation loss: 1.9771100808215398

Epoch: 6| Step: 3
Training loss: 0.8529530763626099
Validation loss: 1.9685615416496032

Epoch: 6| Step: 4
Training loss: 1.0194693803787231
Validation loss: 2.0205000600507184

Epoch: 6| Step: 5
Training loss: 1.3127777576446533
Validation loss: 2.018652585244948

Epoch: 6| Step: 6
Training loss: 0.4750083088874817
Validation loss: 2.037778659533429

Epoch: 6| Step: 7
Training loss: 1.001395583152771
Validation loss: 1.9952912048626972

Epoch: 6| Step: 8
Training loss: 1.0221277475357056
Validation loss: 2.0184595943779073

Epoch: 6| Step: 9
Training loss: 1.2477788925170898
Validation loss: 2.002670931559737

Epoch: 6| Step: 10
Training loss: 0.8042683005332947
Validation loss: 1.9372441819919053

Epoch: 6| Step: 11
Training loss: 0.7124878168106079
Validation loss: 1.9105414036781556

Epoch: 6| Step: 12
Training loss: 1.3377691507339478
Validation loss: 1.8855607125066942

Epoch: 6| Step: 13
Training loss: 1.1019179821014404
Validation loss: 1.8653115905741209

Epoch: 217| Step: 0
Training loss: 0.9997800588607788
Validation loss: 1.8849661850160169

Epoch: 6| Step: 1
Training loss: 1.198848009109497
Validation loss: 1.8688756291584303

Epoch: 6| Step: 2
Training loss: 0.720217227935791
Validation loss: 1.9346046870754612

Epoch: 6| Step: 3
Training loss: 1.3846149444580078
Validation loss: 1.9243906762010308

Epoch: 6| Step: 4
Training loss: 0.7822670936584473
Validation loss: 1.9693837678560646

Epoch: 6| Step: 5
Training loss: 0.5115143656730652
Validation loss: 2.0081993187627485

Epoch: 6| Step: 6
Training loss: 0.9178351163864136
Validation loss: 2.026311716725749

Epoch: 6| Step: 7
Training loss: 0.9091054201126099
Validation loss: 2.013426960155528

Epoch: 6| Step: 8
Training loss: 1.0936574935913086
Validation loss: 2.0247578826001895

Epoch: 6| Step: 9
Training loss: 0.7705363035202026
Validation loss: 1.9888356449783489

Epoch: 6| Step: 10
Training loss: 0.7778127193450928
Validation loss: 1.9818014137206539

Epoch: 6| Step: 11
Training loss: 1.2461224794387817
Validation loss: 1.9561703833200599

Epoch: 6| Step: 12
Training loss: 1.1478960514068604
Validation loss: 1.8903864711843512

Epoch: 6| Step: 13
Training loss: 1.2286275625228882
Validation loss: 1.8763758290198542

Epoch: 218| Step: 0
Training loss: 0.8963454961776733
Validation loss: 1.8802151872265724

Epoch: 6| Step: 1
Training loss: 0.5531822443008423
Validation loss: 1.8453149052076443

Epoch: 6| Step: 2
Training loss: 0.4443158805370331
Validation loss: 1.8510202925692323

Epoch: 6| Step: 3
Training loss: 1.1546425819396973
Validation loss: 1.8489348311578073

Epoch: 6| Step: 4
Training loss: 1.0677443742752075
Validation loss: 1.8528026496210406

Epoch: 6| Step: 5
Training loss: 0.7851919531822205
Validation loss: 1.892007658558507

Epoch: 6| Step: 6
Training loss: 1.4809681177139282
Validation loss: 1.8934348091002433

Epoch: 6| Step: 7
Training loss: 0.8082065582275391
Validation loss: 1.8909451282152565

Epoch: 6| Step: 8
Training loss: 1.0607985258102417
Validation loss: 1.8926314769252655

Epoch: 6| Step: 9
Training loss: 1.2257704734802246
Validation loss: 1.9828802898365965

Epoch: 6| Step: 10
Training loss: 1.135859489440918
Validation loss: 1.9765023621179725

Epoch: 6| Step: 11
Training loss: 1.2619154453277588
Validation loss: 2.02634189462149

Epoch: 6| Step: 12
Training loss: 0.904703676700592
Validation loss: 2.024605348546018

Epoch: 6| Step: 13
Training loss: 0.5036755204200745
Validation loss: 2.0588863870149017

Epoch: 219| Step: 0
Training loss: 1.0212745666503906
Validation loss: 2.0397923018342707

Epoch: 6| Step: 1
Training loss: 0.5333165526390076
Validation loss: 2.042258720244131

Epoch: 6| Step: 2
Training loss: 0.9053653478622437
Validation loss: 2.0384413465376823

Epoch: 6| Step: 3
Training loss: 0.8003859519958496
Validation loss: 2.0240842321867585

Epoch: 6| Step: 4
Training loss: 1.0905508995056152
Validation loss: 2.00493057568868

Epoch: 6| Step: 5
Training loss: 0.6559425592422485
Validation loss: 1.9916782225331953

Epoch: 6| Step: 6
Training loss: 0.2926206588745117
Validation loss: 1.9906023138312883

Epoch: 6| Step: 7
Training loss: 1.0881266593933105
Validation loss: 1.9446278566955237

Epoch: 6| Step: 8
Training loss: 1.254776954650879
Validation loss: 1.9738601176969466

Epoch: 6| Step: 9
Training loss: 1.0652501583099365
Validation loss: 1.9648985426913026

Epoch: 6| Step: 10
Training loss: 1.6389005184173584
Validation loss: 1.9635106081603675

Epoch: 6| Step: 11
Training loss: 0.7431572675704956
Validation loss: 1.9511792595668505

Epoch: 6| Step: 12
Training loss: 1.092541217803955
Validation loss: 2.0128598828469553

Epoch: 6| Step: 13
Training loss: 1.0001057386398315
Validation loss: 1.9881956385027977

Epoch: 220| Step: 0
Training loss: 0.4665015935897827
Validation loss: 1.9250377288428686

Epoch: 6| Step: 1
Training loss: 0.751598060131073
Validation loss: 1.920797537731868

Epoch: 6| Step: 2
Training loss: 0.8084292411804199
Validation loss: 1.8874180137470205

Epoch: 6| Step: 3
Training loss: 0.8418043255805969
Validation loss: 1.90368999204328

Epoch: 6| Step: 4
Training loss: 1.2144849300384521
Validation loss: 1.9240045791031213

Epoch: 6| Step: 5
Training loss: 0.6850690841674805
Validation loss: 1.8870194996556928

Epoch: 6| Step: 6
Training loss: 1.2948778867721558
Validation loss: 1.8874432681709208

Epoch: 6| Step: 7
Training loss: 1.1149533987045288
Validation loss: 1.896535458103303

Epoch: 6| Step: 8
Training loss: 0.9746978282928467
Validation loss: 1.8776512985588403

Epoch: 6| Step: 9
Training loss: 1.0925109386444092
Validation loss: 1.921403161941036

Epoch: 6| Step: 10
Training loss: 1.0856060981750488
Validation loss: 1.9547893014005435

Epoch: 6| Step: 11
Training loss: 0.8478904366493225
Validation loss: 1.9915297133948213

Epoch: 6| Step: 12
Training loss: 1.006795883178711
Validation loss: 2.02481415963942

Epoch: 6| Step: 13
Training loss: 0.5711589455604553
Validation loss: 2.036373153809578

Epoch: 221| Step: 0
Training loss: 1.2316787242889404
Validation loss: 2.0525219799369894

Epoch: 6| Step: 1
Training loss: 1.244985580444336
Validation loss: 2.035142247394849

Epoch: 6| Step: 2
Training loss: 0.8844324350357056
Validation loss: 2.0439894442917197

Epoch: 6| Step: 3
Training loss: 0.4982560873031616
Validation loss: 2.02017351119749

Epoch: 6| Step: 4
Training loss: 0.6562674641609192
Validation loss: 1.985062317181659

Epoch: 6| Step: 5
Training loss: 0.39752769470214844
Validation loss: 1.980496960301553

Epoch: 6| Step: 6
Training loss: 0.7921416759490967
Validation loss: 1.9612191671966224

Epoch: 6| Step: 7
Training loss: 0.566977858543396
Validation loss: 1.9662438002965783

Epoch: 6| Step: 8
Training loss: 1.2169065475463867
Validation loss: 1.984694492432379

Epoch: 6| Step: 9
Training loss: 1.0816431045532227
Validation loss: 1.9883530652651222

Epoch: 6| Step: 10
Training loss: 0.7212545871734619
Validation loss: 1.9753351134638633

Epoch: 6| Step: 11
Training loss: 1.3146905899047852
Validation loss: 2.034083377930426

Epoch: 6| Step: 12
Training loss: 0.9796367883682251
Validation loss: 2.001799638553332

Epoch: 6| Step: 13
Training loss: 1.0179451704025269
Validation loss: 2.001514870633361

Epoch: 222| Step: 0
Training loss: 1.0781762599945068
Validation loss: 2.0089429988655993

Epoch: 6| Step: 1
Training loss: 0.785201370716095
Validation loss: 1.9788716121386456

Epoch: 6| Step: 2
Training loss: 0.9624577164649963
Validation loss: 1.9508247990762033

Epoch: 6| Step: 3
Training loss: 0.8768243193626404
Validation loss: 1.9041050454621673

Epoch: 6| Step: 4
Training loss: 0.9028497934341431
Validation loss: 1.8564847400111537

Epoch: 6| Step: 5
Training loss: 0.8645035028457642
Validation loss: 1.8324087960745699

Epoch: 6| Step: 6
Training loss: 1.04818594455719
Validation loss: 1.8320760188564178

Epoch: 6| Step: 7
Training loss: 1.0322997570037842
Validation loss: 1.8332785714057185

Epoch: 6| Step: 8
Training loss: 1.236124038696289
Validation loss: 1.8480085121688021

Epoch: 6| Step: 9
Training loss: 0.5523906946182251
Validation loss: 1.8568421358703284

Epoch: 6| Step: 10
Training loss: 0.5327101945877075
Validation loss: 1.8918502869144562

Epoch: 6| Step: 11
Training loss: 1.1182973384857178
Validation loss: 1.9561336860861829

Epoch: 6| Step: 12
Training loss: 0.724178671836853
Validation loss: 1.9890520649571573

Epoch: 6| Step: 13
Training loss: 1.5140206813812256
Validation loss: 2.0413630905971734

Epoch: 223| Step: 0
Training loss: 1.0837788581848145
Validation loss: 2.0255424412347938

Epoch: 6| Step: 1
Training loss: 0.773385763168335
Validation loss: 2.0476589420790314

Epoch: 6| Step: 2
Training loss: 1.1390066146850586
Validation loss: 2.0493705580311437

Epoch: 6| Step: 3
Training loss: 0.4368002414703369
Validation loss: 2.0438927783760974

Epoch: 6| Step: 4
Training loss: 0.8713438510894775
Validation loss: 2.008638035866522

Epoch: 6| Step: 5
Training loss: 0.8181977272033691
Validation loss: 1.9978269761608494

Epoch: 6| Step: 6
Training loss: 1.1357489824295044
Validation loss: 1.9920174114165767

Epoch: 6| Step: 7
Training loss: 1.0367250442504883
Validation loss: 1.940815471833752

Epoch: 6| Step: 8
Training loss: 0.5820352435112
Validation loss: 1.9239697174359394

Epoch: 6| Step: 9
Training loss: 1.162070870399475
Validation loss: 1.9288948223155031

Epoch: 6| Step: 10
Training loss: 0.5291194319725037
Validation loss: 1.944565173118345

Epoch: 6| Step: 11
Training loss: 1.2510321140289307
Validation loss: 1.9417471052497945

Epoch: 6| Step: 12
Training loss: 0.9998912811279297
Validation loss: 1.950880044250078

Epoch: 6| Step: 13
Training loss: 1.1036221981048584
Validation loss: 1.9425348953534198

Epoch: 224| Step: 0
Training loss: 0.9964796900749207
Validation loss: 1.9217066252103416

Epoch: 6| Step: 1
Training loss: 0.6729456186294556
Validation loss: 1.910613718853202

Epoch: 6| Step: 2
Training loss: 0.6043591499328613
Validation loss: 1.9140617078350437

Epoch: 6| Step: 3
Training loss: 0.9208990335464478
Validation loss: 1.907566855030675

Epoch: 6| Step: 4
Training loss: 0.8539578914642334
Validation loss: 1.8856300500131422

Epoch: 6| Step: 5
Training loss: 0.9687367677688599
Validation loss: 1.8888200713742165

Epoch: 6| Step: 6
Training loss: 0.9090631604194641
Validation loss: 1.8772598440929125

Epoch: 6| Step: 7
Training loss: 0.8500990271568298
Validation loss: 1.9471203460488269

Epoch: 6| Step: 8
Training loss: 1.0838203430175781
Validation loss: 1.9341244595025175

Epoch: 6| Step: 9
Training loss: 0.6954474449157715
Validation loss: 1.939139239249691

Epoch: 6| Step: 10
Training loss: 0.7793154716491699
Validation loss: 1.9664270262564383

Epoch: 6| Step: 11
Training loss: 1.465335488319397
Validation loss: 1.9465108943241898

Epoch: 6| Step: 12
Training loss: 0.9532267451286316
Validation loss: 1.9879356789332565

Epoch: 6| Step: 13
Training loss: 0.5931851267814636
Validation loss: 1.9568307809932257

Epoch: 225| Step: 0
Training loss: 0.3069678246974945
Validation loss: 1.9225585672163195

Epoch: 6| Step: 1
Training loss: 1.1828025579452515
Validation loss: 1.9644531306400095

Epoch: 6| Step: 2
Training loss: 1.1763890981674194
Validation loss: 1.9418195050249818

Epoch: 6| Step: 3
Training loss: 1.2074520587921143
Validation loss: 1.9346228222693167

Epoch: 6| Step: 4
Training loss: 0.8239544630050659
Validation loss: 1.91312042872111

Epoch: 6| Step: 5
Training loss: 0.9610052108764648
Validation loss: 1.916327312428464

Epoch: 6| Step: 6
Training loss: 1.3963022232055664
Validation loss: 1.9702523857034662

Epoch: 6| Step: 7
Training loss: 0.735969066619873
Validation loss: 1.9760479696335331

Epoch: 6| Step: 8
Training loss: 0.5902022123336792
Validation loss: 2.006232311648707

Epoch: 6| Step: 9
Training loss: 0.633919358253479
Validation loss: 2.0114161224775415

Epoch: 6| Step: 10
Training loss: 0.9333938360214233
Validation loss: 2.0193972305584977

Epoch: 6| Step: 11
Training loss: 0.6518839597702026
Validation loss: 1.9997038149064588

Epoch: 6| Step: 12
Training loss: 0.7591281533241272
Validation loss: 2.0026146545205066

Epoch: 6| Step: 13
Training loss: 0.5714966654777527
Validation loss: 1.985201169085759

Epoch: 226| Step: 0
Training loss: 1.3015536069869995
Validation loss: 1.9573638182814403

Epoch: 6| Step: 1
Training loss: 1.083160400390625
Validation loss: 1.9178534220623713

Epoch: 6| Step: 2
Training loss: 0.7397531270980835
Validation loss: 1.8773395322984265

Epoch: 6| Step: 3
Training loss: 0.6989836096763611
Validation loss: 1.838064528280689

Epoch: 6| Step: 4
Training loss: 0.6515637636184692
Validation loss: 1.8861551630881526

Epoch: 6| Step: 5
Training loss: 0.6062443256378174
Validation loss: 1.8484054047574279

Epoch: 6| Step: 6
Training loss: 1.1382477283477783
Validation loss: 1.9032313836518155

Epoch: 6| Step: 7
Training loss: 0.9443582892417908
Validation loss: 1.8902145765161003

Epoch: 6| Step: 8
Training loss: 0.789826512336731
Validation loss: 1.8818094730377197

Epoch: 6| Step: 9
Training loss: 0.6646628975868225
Validation loss: 1.9082982796494679

Epoch: 6| Step: 10
Training loss: 1.167534589767456
Validation loss: 1.9543476771282893

Epoch: 6| Step: 11
Training loss: 0.8022205233573914
Validation loss: 1.9677733195725309

Epoch: 6| Step: 12
Training loss: 0.694080114364624
Validation loss: 2.0201910823904057

Epoch: 6| Step: 13
Training loss: 1.0280778408050537
Validation loss: 2.009840811452558

Epoch: 227| Step: 0
Training loss: 0.8519525527954102
Validation loss: 2.0211536051124654

Epoch: 6| Step: 1
Training loss: 0.7640172839164734
Validation loss: 2.0685480871508197

Epoch: 6| Step: 2
Training loss: 0.7609129548072815
Validation loss: 2.10315796636766

Epoch: 6| Step: 3
Training loss: 0.6397112607955933
Validation loss: 2.0821942847262145

Epoch: 6| Step: 4
Training loss: 0.9115340113639832
Validation loss: 2.059106174335685

Epoch: 6| Step: 5
Training loss: 1.0892343521118164
Validation loss: 1.9975128866011096

Epoch: 6| Step: 6
Training loss: 0.9431008100509644
Validation loss: 1.9272370440985567

Epoch: 6| Step: 7
Training loss: 1.1954530477523804
Validation loss: 1.8761946655088855

Epoch: 6| Step: 8
Training loss: 0.8143491744995117
Validation loss: 1.8123522599538167

Epoch: 6| Step: 9
Training loss: 0.789490282535553
Validation loss: 1.8407388297460412

Epoch: 6| Step: 10
Training loss: 0.9522998332977295
Validation loss: 1.8346752274420954

Epoch: 6| Step: 11
Training loss: 1.0432026386260986
Validation loss: 1.8538704405548752

Epoch: 6| Step: 12
Training loss: 1.0637093782424927
Validation loss: 1.8848144495359032

Epoch: 6| Step: 13
Training loss: 1.0671755075454712
Validation loss: 1.9088731658074163

Epoch: 228| Step: 0
Training loss: 0.9290030002593994
Validation loss: 1.9060556324579383

Epoch: 6| Step: 1
Training loss: 0.8710827827453613
Validation loss: 1.9163239322682863

Epoch: 6| Step: 2
Training loss: 0.9114673733711243
Validation loss: 1.919076483736756

Epoch: 6| Step: 3
Training loss: 0.7408161163330078
Validation loss: 1.9876820105378346

Epoch: 6| Step: 4
Training loss: 0.7161116003990173
Validation loss: 2.018758379003053

Epoch: 6| Step: 5
Training loss: 0.7312781810760498
Validation loss: 2.023591936275523

Epoch: 6| Step: 6
Training loss: 1.1829416751861572
Validation loss: 2.048457614837154

Epoch: 6| Step: 7
Training loss: 1.2662200927734375
Validation loss: 2.0354851522753314

Epoch: 6| Step: 8
Training loss: 0.9873603582382202
Validation loss: 1.964437625741446

Epoch: 6| Step: 9
Training loss: 1.0353929996490479
Validation loss: 1.8971947059836438

Epoch: 6| Step: 10
Training loss: 0.43162453174591064
Validation loss: 1.8328691451780257

Epoch: 6| Step: 11
Training loss: 0.6671929359436035
Validation loss: 1.8300878424798288

Epoch: 6| Step: 12
Training loss: 0.9963836669921875
Validation loss: 1.841149172475261

Epoch: 6| Step: 13
Training loss: 0.8860037326812744
Validation loss: 1.8234438396269275

Epoch: 229| Step: 0
Training loss: 0.7022714614868164
Validation loss: 1.8384370637196366

Epoch: 6| Step: 1
Training loss: 0.4228455722332001
Validation loss: 1.8559518898687055

Epoch: 6| Step: 2
Training loss: 0.9217055439949036
Validation loss: 1.872452284700127

Epoch: 6| Step: 3
Training loss: 0.9687963128089905
Validation loss: 1.9607066903063046

Epoch: 6| Step: 4
Training loss: 0.7320224642753601
Validation loss: 2.006675890696946

Epoch: 6| Step: 5
Training loss: 1.1971951723098755
Validation loss: 2.050955250699033

Epoch: 6| Step: 6
Training loss: 1.3874582052230835
Validation loss: 2.024364158671389

Epoch: 6| Step: 7
Training loss: 0.7222285270690918
Validation loss: 2.0172721044991606

Epoch: 6| Step: 8
Training loss: 0.6010563373565674
Validation loss: 1.957198917224843

Epoch: 6| Step: 9
Training loss: 1.153294324874878
Validation loss: 1.9189035020848757

Epoch: 6| Step: 10
Training loss: 0.9573562145233154
Validation loss: 1.8452544571250997

Epoch: 6| Step: 11
Training loss: 0.7829878330230713
Validation loss: 1.7780736479707944

Epoch: 6| Step: 12
Training loss: 0.6520814299583435
Validation loss: 1.8023318834202264

Epoch: 6| Step: 13
Training loss: 0.8617193698883057
Validation loss: 1.7637864723000476

Epoch: 230| Step: 0
Training loss: 0.767869234085083
Validation loss: 1.7915442041171494

Epoch: 6| Step: 1
Training loss: 0.9504160284996033
Validation loss: 1.8120897303345382

Epoch: 6| Step: 2
Training loss: 0.7630230188369751
Validation loss: 1.821691487425117

Epoch: 6| Step: 3
Training loss: 0.7302817106246948
Validation loss: 1.8501674359844578

Epoch: 6| Step: 4
Training loss: 0.7633261680603027
Validation loss: 1.8813099143325642

Epoch: 6| Step: 5
Training loss: 0.8406857848167419
Validation loss: 1.9054256049535607

Epoch: 6| Step: 6
Training loss: 0.7736340761184692
Validation loss: 1.8855983134238952

Epoch: 6| Step: 7
Training loss: 0.7965271472930908
Validation loss: 1.9346197843551636

Epoch: 6| Step: 8
Training loss: 0.8594768643379211
Validation loss: 1.9515933106022496

Epoch: 6| Step: 9
Training loss: 1.2764949798583984
Validation loss: 1.9649336555952668

Epoch: 6| Step: 10
Training loss: 0.6849843859672546
Validation loss: 1.9745553206372004

Epoch: 6| Step: 11
Training loss: 0.8378980755805969
Validation loss: 1.9848443872185164

Epoch: 6| Step: 12
Training loss: 0.8967926502227783
Validation loss: 2.000833366506843

Epoch: 6| Step: 13
Training loss: 1.2942370176315308
Validation loss: 2.054933668464743

Epoch: 231| Step: 0
Training loss: 0.803977906703949
Validation loss: 2.032932094348374

Epoch: 6| Step: 1
Training loss: 0.6703999638557434
Validation loss: 2.0574624717876477

Epoch: 6| Step: 2
Training loss: 0.8775106072425842
Validation loss: 2.0709437042154293

Epoch: 6| Step: 3
Training loss: 0.8098276257514954
Validation loss: 2.0589049426458215

Epoch: 6| Step: 4
Training loss: 0.8794289827346802
Validation loss: 2.0293728625902565

Epoch: 6| Step: 5
Training loss: 0.9226168394088745
Validation loss: 2.0084830381536998

Epoch: 6| Step: 6
Training loss: 0.8202853202819824
Validation loss: 1.951110525797772

Epoch: 6| Step: 7
Training loss: 0.9423595070838928
Validation loss: 1.954666022331484

Epoch: 6| Step: 8
Training loss: 0.7984826564788818
Validation loss: 1.901733022864147

Epoch: 6| Step: 9
Training loss: 0.7323230504989624
Validation loss: 1.8484277827765352

Epoch: 6| Step: 10
Training loss: 0.8908032774925232
Validation loss: 1.8876502180612216

Epoch: 6| Step: 11
Training loss: 0.8255805969238281
Validation loss: 1.8738224352559736

Epoch: 6| Step: 12
Training loss: 0.8428549766540527
Validation loss: 1.9010052796333068

Epoch: 6| Step: 13
Training loss: 0.747675359249115
Validation loss: 1.8717213805003832

Epoch: 232| Step: 0
Training loss: 1.2490601539611816
Validation loss: 1.9147306052587365

Epoch: 6| Step: 1
Training loss: 0.7736095190048218
Validation loss: 1.8895059759898851

Epoch: 6| Step: 2
Training loss: 0.3611881732940674
Validation loss: 1.96639814940832

Epoch: 6| Step: 3
Training loss: 0.9965574145317078
Validation loss: 1.9559799419936312

Epoch: 6| Step: 4
Training loss: 0.6620121598243713
Validation loss: 1.8935916423797607

Epoch: 6| Step: 5
Training loss: 0.511689305305481
Validation loss: 1.8908828432841966

Epoch: 6| Step: 6
Training loss: 0.8606962561607361
Validation loss: 1.8250943191589848

Epoch: 6| Step: 7
Training loss: 0.6513335704803467
Validation loss: 1.828874232307557

Epoch: 6| Step: 8
Training loss: 0.8215975165367126
Validation loss: 1.804683139247279

Epoch: 6| Step: 9
Training loss: 0.7615563273429871
Validation loss: 1.7576140742148123

Epoch: 6| Step: 10
Training loss: 0.8960689306259155
Validation loss: 1.810679740803216

Epoch: 6| Step: 11
Training loss: 1.4146385192871094
Validation loss: 1.79814431359691

Epoch: 6| Step: 12
Training loss: 1.031132698059082
Validation loss: 1.8175558031246226

Epoch: 6| Step: 13
Training loss: 0.3742193579673767
Validation loss: 1.8192429542541504

Epoch: 233| Step: 0
Training loss: 0.6841412782669067
Validation loss: 1.8559290824397918

Epoch: 6| Step: 1
Training loss: 0.4626796841621399
Validation loss: 1.8700045052395071

Epoch: 6| Step: 2
Training loss: 0.8139742612838745
Validation loss: 1.9777886970068819

Epoch: 6| Step: 3
Training loss: 0.8762927651405334
Validation loss: 1.9859594401492868

Epoch: 6| Step: 4
Training loss: 0.7408405542373657
Validation loss: 1.9808519783840384

Epoch: 6| Step: 5
Training loss: 1.3715457916259766
Validation loss: 1.984096541199633

Epoch: 6| Step: 6
Training loss: 1.1943423748016357
Validation loss: 1.9767283906218827

Epoch: 6| Step: 7
Training loss: 0.33518949151039124
Validation loss: 1.982901862872544

Epoch: 6| Step: 8
Training loss: 0.6588214635848999
Validation loss: 1.9340710921954083

Epoch: 6| Step: 9
Training loss: 1.2015111446380615
Validation loss: 1.916704770057432

Epoch: 6| Step: 10
Training loss: 0.6334180235862732
Validation loss: 1.9243067618339293

Epoch: 6| Step: 11
Training loss: 0.4613420367240906
Validation loss: 1.8806369304656982

Epoch: 6| Step: 12
Training loss: 1.1936519145965576
Validation loss: 1.8667486726596791

Epoch: 6| Step: 13
Training loss: 0.6742338538169861
Validation loss: 1.8467694213313441

Epoch: 234| Step: 0
Training loss: 0.5342185497283936
Validation loss: 1.834768323488133

Epoch: 6| Step: 1
Training loss: 0.37770533561706543
Validation loss: 1.8400910951757943

Epoch: 6| Step: 2
Training loss: 0.5744199752807617
Validation loss: 1.8637935025717622

Epoch: 6| Step: 3
Training loss: 0.8154791593551636
Validation loss: 1.8747574578049362

Epoch: 6| Step: 4
Training loss: 0.771542489528656
Validation loss: 1.9092405919105775

Epoch: 6| Step: 5
Training loss: 1.001960277557373
Validation loss: 1.9158272076678533

Epoch: 6| Step: 6
Training loss: 0.9231805801391602
Validation loss: 1.9565024683552403

Epoch: 6| Step: 7
Training loss: 1.068040370941162
Validation loss: 1.8888540780672463

Epoch: 6| Step: 8
Training loss: 0.6460243463516235
Validation loss: 1.9185088751136616

Epoch: 6| Step: 9
Training loss: 0.6299617886543274
Validation loss: 1.9139480975366407

Epoch: 6| Step: 10
Training loss: 0.7824435234069824
Validation loss: 1.9148841519509592

Epoch: 6| Step: 11
Training loss: 1.0875046253204346
Validation loss: 1.8684828307038994

Epoch: 6| Step: 12
Training loss: 0.7592872381210327
Validation loss: 1.917301167723953

Epoch: 6| Step: 13
Training loss: 1.3102575540542603
Validation loss: 1.9122847767286404

Epoch: 235| Step: 0
Training loss: 0.5760233402252197
Validation loss: 1.872576541798089

Epoch: 6| Step: 1
Training loss: 0.9788841605186462
Validation loss: 1.8694641000481063

Epoch: 6| Step: 2
Training loss: 0.5397232174873352
Validation loss: 1.8453568835412302

Epoch: 6| Step: 3
Training loss: 1.1036750078201294
Validation loss: 1.874004945960096

Epoch: 6| Step: 4
Training loss: 0.9792993068695068
Validation loss: 1.863664657838883

Epoch: 6| Step: 5
Training loss: 0.7676582336425781
Validation loss: 1.8933390417406637

Epoch: 6| Step: 6
Training loss: 0.88665771484375
Validation loss: 1.8727237588615828

Epoch: 6| Step: 7
Training loss: 0.9031249284744263
Validation loss: 1.8732676083041775

Epoch: 6| Step: 8
Training loss: 0.6755807399749756
Validation loss: 1.8901459299108034

Epoch: 6| Step: 9
Training loss: 1.086808681488037
Validation loss: 1.8927632249811643

Epoch: 6| Step: 10
Training loss: 0.9402572512626648
Validation loss: 1.8805178762764059

Epoch: 6| Step: 11
Training loss: 0.4213104248046875
Validation loss: 1.8938368161519368

Epoch: 6| Step: 12
Training loss: 0.4207708537578583
Validation loss: 1.9085286842879428

Epoch: 6| Step: 13
Training loss: 0.7927519679069519
Validation loss: 1.9264971876657138

Epoch: 236| Step: 0
Training loss: 0.8048553466796875
Validation loss: 1.942336020931121

Epoch: 6| Step: 1
Training loss: 0.9235697984695435
Validation loss: 1.965348925641788

Epoch: 6| Step: 2
Training loss: 0.4845028519630432
Validation loss: 1.9690746825228456

Epoch: 6| Step: 3
Training loss: 1.085365891456604
Validation loss: 2.0038513291266655

Epoch: 6| Step: 4
Training loss: 1.0907819271087646
Validation loss: 1.9631353450077835

Epoch: 6| Step: 5
Training loss: 0.6427931785583496
Validation loss: 1.9533583348797214

Epoch: 6| Step: 6
Training loss: 0.9768715500831604
Validation loss: 1.9707409707448815

Epoch: 6| Step: 7
Training loss: 0.8671436309814453
Validation loss: 1.8840456624184885

Epoch: 6| Step: 8
Training loss: 0.7092049717903137
Validation loss: 1.8799496978841803

Epoch: 6| Step: 9
Training loss: 0.9360588192939758
Validation loss: 1.8765185584304154

Epoch: 6| Step: 10
Training loss: 0.7875713109970093
Validation loss: 1.8565700259259952

Epoch: 6| Step: 11
Training loss: 0.48930227756500244
Validation loss: 1.8723870272277503

Epoch: 6| Step: 12
Training loss: 0.7768007516860962
Validation loss: 1.8192866309996574

Epoch: 6| Step: 13
Training loss: 0.5576563477516174
Validation loss: 1.8742161386756486

Epoch: 237| Step: 0
Training loss: 0.7131264209747314
Validation loss: 1.8823295985498736

Epoch: 6| Step: 1
Training loss: 1.0334715843200684
Validation loss: 1.9347613062909854

Epoch: 6| Step: 2
Training loss: 0.9420720338821411
Validation loss: 1.9542153317441222

Epoch: 6| Step: 3
Training loss: 0.8370330929756165
Validation loss: 1.9364790326805525

Epoch: 6| Step: 4
Training loss: 0.6969460248947144
Validation loss: 1.933742602666219

Epoch: 6| Step: 5
Training loss: 0.927399754524231
Validation loss: 1.8936828682499547

Epoch: 6| Step: 6
Training loss: 0.3632475733757019
Validation loss: 1.9186129800734981

Epoch: 6| Step: 7
Training loss: 0.6512262225151062
Validation loss: 1.8828835654002365

Epoch: 6| Step: 8
Training loss: 0.8321595191955566
Validation loss: 1.8958773292520994

Epoch: 6| Step: 9
Training loss: 0.8552671670913696
Validation loss: 1.901850732423926

Epoch: 6| Step: 10
Training loss: 0.9039758443832397
Validation loss: 1.9082632654456682

Epoch: 6| Step: 11
Training loss: 0.7355847358703613
Validation loss: 1.8867479191031507

Epoch: 6| Step: 12
Training loss: 0.7623082399368286
Validation loss: 1.8899290843676495

Epoch: 6| Step: 13
Training loss: 1.1324392557144165
Validation loss: 1.8962160605256275

Epoch: 238| Step: 0
Training loss: 0.3824795186519623
Validation loss: 1.8665368018611785

Epoch: 6| Step: 1
Training loss: 1.2798311710357666
Validation loss: 1.893376470893942

Epoch: 6| Step: 2
Training loss: 0.7171924114227295
Validation loss: 1.8990554053296325

Epoch: 6| Step: 3
Training loss: 0.8382115364074707
Validation loss: 1.9506318300001082

Epoch: 6| Step: 4
Training loss: 0.8684258460998535
Validation loss: 1.9690002151714858

Epoch: 6| Step: 5
Training loss: 0.5654460191726685
Validation loss: 1.9964440740564817

Epoch: 6| Step: 6
Training loss: 1.4377071857452393
Validation loss: 1.9814656216611144

Epoch: 6| Step: 7
Training loss: 0.8476493954658508
Validation loss: 1.9667587254637031

Epoch: 6| Step: 8
Training loss: 0.7675127983093262
Validation loss: 1.9486564846449002

Epoch: 6| Step: 9
Training loss: 0.8748188018798828
Validation loss: 1.9338444086813158

Epoch: 6| Step: 10
Training loss: 0.7787364721298218
Validation loss: 1.941405906472155

Epoch: 6| Step: 11
Training loss: 0.540292501449585
Validation loss: 1.900819375950803

Epoch: 6| Step: 12
Training loss: 0.8069347739219666
Validation loss: 1.9120765116906935

Epoch: 6| Step: 13
Training loss: 0.6522486209869385
Validation loss: 1.8857299948251376

Epoch: 239| Step: 0
Training loss: 0.574353039264679
Validation loss: 1.8896198759796798

Epoch: 6| Step: 1
Training loss: 0.8490959405899048
Validation loss: 1.897822057047198

Epoch: 6| Step: 2
Training loss: 0.9128667116165161
Validation loss: 1.8908974444994362

Epoch: 6| Step: 3
Training loss: 0.6343358755111694
Validation loss: 1.8921650891662927

Epoch: 6| Step: 4
Training loss: 1.1886487007141113
Validation loss: 1.8655277567525064

Epoch: 6| Step: 5
Training loss: 1.008933663368225
Validation loss: 1.836904775711798

Epoch: 6| Step: 6
Training loss: 0.8746477961540222
Validation loss: 1.8325324186714746

Epoch: 6| Step: 7
Training loss: 0.5114469528198242
Validation loss: 1.8769908540992326

Epoch: 6| Step: 8
Training loss: 1.3318583965301514
Validation loss: 1.8553468668332664

Epoch: 6| Step: 9
Training loss: 0.5069303512573242
Validation loss: 1.896590809668264

Epoch: 6| Step: 10
Training loss: 0.8251448273658752
Validation loss: 1.8596002901754072

Epoch: 6| Step: 11
Training loss: 0.5197145938873291
Validation loss: 1.8897424180020568

Epoch: 6| Step: 12
Training loss: 0.5225815176963806
Validation loss: 1.8831955361109909

Epoch: 6| Step: 13
Training loss: 0.42619583010673523
Validation loss: 1.8878417617531233

Epoch: 240| Step: 0
Training loss: 1.0867972373962402
Validation loss: 1.8616804563870994

Epoch: 6| Step: 1
Training loss: 0.6188740730285645
Validation loss: 1.9035092015420236

Epoch: 6| Step: 2
Training loss: 0.5398566722869873
Validation loss: 1.8990145498706448

Epoch: 6| Step: 3
Training loss: 0.7595003247261047
Validation loss: 1.8624393337516374

Epoch: 6| Step: 4
Training loss: 1.009704828262329
Validation loss: 1.8903158736485306

Epoch: 6| Step: 5
Training loss: 0.568196713924408
Validation loss: 1.8881666801309074

Epoch: 6| Step: 6
Training loss: 0.849797248840332
Validation loss: 1.889654556910197

Epoch: 6| Step: 7
Training loss: 1.3061227798461914
Validation loss: 1.8935820030909714

Epoch: 6| Step: 8
Training loss: 0.7091835141181946
Validation loss: 1.8760235207055205

Epoch: 6| Step: 9
Training loss: 1.0595632791519165
Validation loss: 1.843291687709029

Epoch: 6| Step: 10
Training loss: 0.7817005515098572
Validation loss: 1.7749393998935659

Epoch: 6| Step: 11
Training loss: 0.6511213183403015
Validation loss: 1.810674282812303

Epoch: 6| Step: 12
Training loss: 0.6230682730674744
Validation loss: 1.7969241001272713

Epoch: 6| Step: 13
Training loss: 0.41630131006240845
Validation loss: 1.8145912821574877

Epoch: 241| Step: 0
Training loss: 0.7961474061012268
Validation loss: 1.8736167671859905

Epoch: 6| Step: 1
Training loss: 0.6826606392860413
Validation loss: 1.8974570074389059

Epoch: 6| Step: 2
Training loss: 0.562328577041626
Validation loss: 1.942711543011409

Epoch: 6| Step: 3
Training loss: 0.8529109954833984
Validation loss: 1.940632595810839

Epoch: 6| Step: 4
Training loss: 0.33348554372787476
Validation loss: 1.8966144002893919

Epoch: 6| Step: 5
Training loss: 0.8833334445953369
Validation loss: 1.983354405690265

Epoch: 6| Step: 6
Training loss: 0.7452011108398438
Validation loss: 1.9868598343223653

Epoch: 6| Step: 7
Training loss: 0.7770859003067017
Validation loss: 1.9716725400699082

Epoch: 6| Step: 8
Training loss: 0.6311163902282715
Validation loss: 1.958261578313766

Epoch: 6| Step: 9
Training loss: 0.7522724866867065
Validation loss: 1.9115010307681175

Epoch: 6| Step: 10
Training loss: 0.7195818424224854
Validation loss: 1.868490788244432

Epoch: 6| Step: 11
Training loss: 1.0952781438827515
Validation loss: 1.807994222128263

Epoch: 6| Step: 12
Training loss: 0.7423812747001648
Validation loss: 1.7713638531264437

Epoch: 6| Step: 13
Training loss: 0.7301792502403259
Validation loss: 1.7349855822901572

Epoch: 242| Step: 0
Training loss: 1.0415267944335938
Validation loss: 1.733079953860211

Epoch: 6| Step: 1
Training loss: 0.8285676836967468
Validation loss: 1.7170261926548456

Epoch: 6| Step: 2
Training loss: 0.7059403657913208
Validation loss: 1.7083359764468284

Epoch: 6| Step: 3
Training loss: 0.741278886795044
Validation loss: 1.691542470967898

Epoch: 6| Step: 4
Training loss: 0.9203009009361267
Validation loss: 1.763710368064142

Epoch: 6| Step: 5
Training loss: 0.7344495058059692
Validation loss: 1.772290422070411

Epoch: 6| Step: 6
Training loss: 0.7609648704528809
Validation loss: 1.8545567297166394

Epoch: 6| Step: 7
Training loss: 1.0646047592163086
Validation loss: 1.9537620749524844

Epoch: 6| Step: 8
Training loss: 0.7687860131263733
Validation loss: 1.961267743059384

Epoch: 6| Step: 9
Training loss: 0.6640304327011108
Validation loss: 1.9626407982200704

Epoch: 6| Step: 10
Training loss: 0.7873520851135254
Validation loss: 2.025098745540906

Epoch: 6| Step: 11
Training loss: 0.6730434894561768
Validation loss: 1.9730959617963402

Epoch: 6| Step: 12
Training loss: 1.006462574005127
Validation loss: 1.9387895791761336

Epoch: 6| Step: 13
Training loss: 0.5590658187866211
Validation loss: 1.9069016325858332

Epoch: 243| Step: 0
Training loss: 0.8131990432739258
Validation loss: 1.894770847853794

Epoch: 6| Step: 1
Training loss: 0.3699888586997986
Validation loss: 1.8491081947921424

Epoch: 6| Step: 2
Training loss: 1.0244903564453125
Validation loss: 1.8225834138931767

Epoch: 6| Step: 3
Training loss: 0.820418119430542
Validation loss: 1.7999602671592467

Epoch: 6| Step: 4
Training loss: 0.8272379040718079
Validation loss: 1.791514583813247

Epoch: 6| Step: 5
Training loss: 0.776185929775238
Validation loss: 1.7634386247204197

Epoch: 6| Step: 6
Training loss: 1.0319955348968506
Validation loss: 1.7478000989524267

Epoch: 6| Step: 7
Training loss: 0.5692524909973145
Validation loss: 1.7199575939486105

Epoch: 6| Step: 8
Training loss: 1.1200134754180908
Validation loss: 1.7494771660015147

Epoch: 6| Step: 9
Training loss: 0.6727272272109985
Validation loss: 1.7295525189368957

Epoch: 6| Step: 10
Training loss: 0.48358190059661865
Validation loss: 1.7830300023478847

Epoch: 6| Step: 11
Training loss: 0.24515694379806519
Validation loss: 1.803418868331499

Epoch: 6| Step: 12
Training loss: 0.8220181465148926
Validation loss: 1.8075665107337378

Epoch: 6| Step: 13
Training loss: 1.4042636156082153
Validation loss: 1.8429350955511934

Epoch: 244| Step: 0
Training loss: 0.6067875623703003
Validation loss: 1.905024197793776

Epoch: 6| Step: 1
Training loss: 0.604396402835846
Validation loss: 1.902726205446387

Epoch: 6| Step: 2
Training loss: 0.33999377489089966
Validation loss: 1.9028732699732627

Epoch: 6| Step: 3
Training loss: 0.9929897785186768
Validation loss: 1.9119094494850404

Epoch: 6| Step: 4
Training loss: 0.6929477453231812
Validation loss: 1.8824595866664764

Epoch: 6| Step: 5
Training loss: 0.6015356779098511
Validation loss: 1.844417397693921

Epoch: 6| Step: 6
Training loss: 1.3264944553375244
Validation loss: 1.8450218939012097

Epoch: 6| Step: 7
Training loss: 0.8188364505767822
Validation loss: 1.8133093118667603

Epoch: 6| Step: 8
Training loss: 0.8172786235809326
Validation loss: 1.76901291519083

Epoch: 6| Step: 9
Training loss: 0.7958297729492188
Validation loss: 1.7628506909134567

Epoch: 6| Step: 10
Training loss: 0.9201598763465881
Validation loss: 1.7935159257663194

Epoch: 6| Step: 11
Training loss: 0.8114553689956665
Validation loss: 1.7518197490322975

Epoch: 6| Step: 12
Training loss: 0.8634178042411804
Validation loss: 1.7487390797625306

Epoch: 6| Step: 13
Training loss: 0.4503445029258728
Validation loss: 1.7826513731351463

Epoch: 245| Step: 0
Training loss: 0.7286896705627441
Validation loss: 1.7541885837431876

Epoch: 6| Step: 1
Training loss: 0.8594216108322144
Validation loss: 1.7497949702765352

Epoch: 6| Step: 2
Training loss: 1.164322853088379
Validation loss: 1.7562874901679255

Epoch: 6| Step: 3
Training loss: 0.5352613925933838
Validation loss: 1.8011978492941907

Epoch: 6| Step: 4
Training loss: 0.5068721175193787
Validation loss: 1.8070680857986532

Epoch: 6| Step: 5
Training loss: 0.5826178789138794
Validation loss: 1.7947999200513285

Epoch: 6| Step: 6
Training loss: 0.6187451481819153
Validation loss: 1.8306046839683288

Epoch: 6| Step: 7
Training loss: 1.1708368062973022
Validation loss: 1.8231158243712557

Epoch: 6| Step: 8
Training loss: 0.9243834018707275
Validation loss: 1.8270638732499973

Epoch: 6| Step: 9
Training loss: 0.8480347394943237
Validation loss: 1.792020683647484

Epoch: 6| Step: 10
Training loss: 0.7229030132293701
Validation loss: 1.7861201314515964

Epoch: 6| Step: 11
Training loss: 0.3713238835334778
Validation loss: 1.8190563494159329

Epoch: 6| Step: 12
Training loss: 0.6201646327972412
Validation loss: 1.8199805726287186

Epoch: 6| Step: 13
Training loss: 0.3221014440059662
Validation loss: 1.8304510206304572

Epoch: 246| Step: 0
Training loss: 0.861503005027771
Validation loss: 1.8703189485816545

Epoch: 6| Step: 1
Training loss: 0.7229396104812622
Validation loss: 1.8917350499860701

Epoch: 6| Step: 2
Training loss: 0.5378928780555725
Validation loss: 1.879412252415893

Epoch: 6| Step: 3
Training loss: 0.9028920531272888
Validation loss: 1.912403388689923

Epoch: 6| Step: 4
Training loss: 0.37575608491897583
Validation loss: 1.9211261503158077

Epoch: 6| Step: 5
Training loss: 0.7718072533607483
Validation loss: 1.8597354632551952

Epoch: 6| Step: 6
Training loss: 0.8637347221374512
Validation loss: 1.8660174146775277

Epoch: 6| Step: 7
Training loss: 0.5703177452087402
Validation loss: 1.8220875891306068

Epoch: 6| Step: 8
Training loss: 1.0648655891418457
Validation loss: 1.8366269693579724

Epoch: 6| Step: 9
Training loss: 0.6015854477882385
Validation loss: 1.8038807831784731

Epoch: 6| Step: 10
Training loss: 0.7045354843139648
Validation loss: 1.816752374813121

Epoch: 6| Step: 11
Training loss: 0.7469071745872498
Validation loss: 1.779031712521789

Epoch: 6| Step: 12
Training loss: 0.7934140563011169
Validation loss: 1.8065936924308859

Epoch: 6| Step: 13
Training loss: 0.2626985013484955
Validation loss: 1.7900447358367264

Epoch: 247| Step: 0
Training loss: 1.2403640747070312
Validation loss: 1.8109709549975652

Epoch: 6| Step: 1
Training loss: 0.8133361339569092
Validation loss: 1.8328354230491064

Epoch: 6| Step: 2
Training loss: 0.640557050704956
Validation loss: 1.8166336282607047

Epoch: 6| Step: 3
Training loss: 0.59344482421875
Validation loss: 1.8644822861558648

Epoch: 6| Step: 4
Training loss: 0.6118318438529968
Validation loss: 1.9034952835370136

Epoch: 6| Step: 5
Training loss: 0.7370606660842896
Validation loss: 1.9211806328065935

Epoch: 6| Step: 6
Training loss: 0.51845383644104
Validation loss: 1.9468144037390267

Epoch: 6| Step: 7
Training loss: 0.5323910713195801
Validation loss: 1.920320818501134

Epoch: 6| Step: 8
Training loss: 0.8085780143737793
Validation loss: 1.8737839396281908

Epoch: 6| Step: 9
Training loss: 0.9686930179595947
Validation loss: 1.8560170383863552

Epoch: 6| Step: 10
Training loss: 0.5920581221580505
Validation loss: 1.8674737586770007

Epoch: 6| Step: 11
Training loss: 0.6132926940917969
Validation loss: 1.8252027496214835

Epoch: 6| Step: 12
Training loss: 1.0109186172485352
Validation loss: 1.8442749028564782

Epoch: 6| Step: 13
Training loss: 0.3476259112358093
Validation loss: 1.8624634332554315

Epoch: 248| Step: 0
Training loss: 0.9893751740455627
Validation loss: 1.7913479061536892

Epoch: 6| Step: 1
Training loss: 0.5176562070846558
Validation loss: 1.818872469727711

Epoch: 6| Step: 2
Training loss: 0.7462562322616577
Validation loss: 1.7862114996038458

Epoch: 6| Step: 3
Training loss: 0.74570631980896
Validation loss: 1.8242399923263057

Epoch: 6| Step: 4
Training loss: 0.87278151512146
Validation loss: 1.8335090683352562

Epoch: 6| Step: 5
Training loss: 0.3569418787956238
Validation loss: 1.8876659254873953

Epoch: 6| Step: 6
Training loss: 0.5966275930404663
Validation loss: 1.9026344142934328

Epoch: 6| Step: 7
Training loss: 0.4170492887496948
Validation loss: 1.9332284107003161

Epoch: 6| Step: 8
Training loss: 1.088080644607544
Validation loss: 1.9814410748020295

Epoch: 6| Step: 9
Training loss: 0.3500221371650696
Validation loss: 1.955216787194693

Epoch: 6| Step: 10
Training loss: 0.6906516551971436
Validation loss: 1.94528204266743

Epoch: 6| Step: 11
Training loss: 0.8811489939689636
Validation loss: 1.91917372006242

Epoch: 6| Step: 12
Training loss: 1.046284556388855
Validation loss: 1.9464219411214192

Epoch: 6| Step: 13
Training loss: 0.9288588762283325
Validation loss: 1.9335819559712564

Epoch: 249| Step: 0
Training loss: 0.9134529829025269
Validation loss: 1.925690193330088

Epoch: 6| Step: 1
Training loss: 0.6013827323913574
Validation loss: 1.899550622509372

Epoch: 6| Step: 2
Training loss: 0.7159718871116638
Validation loss: 1.882129971699048

Epoch: 6| Step: 3
Training loss: 0.8517215251922607
Validation loss: 1.8587034889446792

Epoch: 6| Step: 4
Training loss: 0.5608896017074585
Validation loss: 1.846828822166689

Epoch: 6| Step: 5
Training loss: 1.1576792001724243
Validation loss: 1.8702978857101933

Epoch: 6| Step: 6
Training loss: 0.7050381898880005
Validation loss: 1.8738753564896122

Epoch: 6| Step: 7
Training loss: 1.0475022792816162
Validation loss: 1.8374207205669855

Epoch: 6| Step: 8
Training loss: 0.47736814618110657
Validation loss: 1.821587053678369

Epoch: 6| Step: 9
Training loss: 0.6467357873916626
Validation loss: 1.8502647863921298

Epoch: 6| Step: 10
Training loss: 0.6875975131988525
Validation loss: 1.8626909666163947

Epoch: 6| Step: 11
Training loss: 0.24490195512771606
Validation loss: 1.8542299168084257

Epoch: 6| Step: 12
Training loss: 0.4859272241592407
Validation loss: 1.8450192097694642

Epoch: 6| Step: 13
Training loss: 0.6878743767738342
Validation loss: 1.8345388571421306

Epoch: 250| Step: 0
Training loss: 0.8368510007858276
Validation loss: 1.8470086333572224

Epoch: 6| Step: 1
Training loss: 0.8737337589263916
Validation loss: 1.8588960747564993

Epoch: 6| Step: 2
Training loss: 0.5523048639297485
Validation loss: 1.856785612721597

Epoch: 6| Step: 3
Training loss: 0.4981343746185303
Validation loss: 1.806944836852371

Epoch: 6| Step: 4
Training loss: 0.7429299354553223
Validation loss: 1.8696469901710429

Epoch: 6| Step: 5
Training loss: 0.5659087896347046
Validation loss: 1.8310368676339426

Epoch: 6| Step: 6
Training loss: 0.5688211917877197
Validation loss: 1.8466661360956007

Epoch: 6| Step: 7
Training loss: 0.7167050242424011
Validation loss: 1.891701949540005

Epoch: 6| Step: 8
Training loss: 0.9512330293655396
Validation loss: 1.8797948937262259

Epoch: 6| Step: 9
Training loss: 0.6625853776931763
Validation loss: 1.880727901253649

Epoch: 6| Step: 10
Training loss: 0.6710222959518433
Validation loss: 1.8662863700620589

Epoch: 6| Step: 11
Training loss: 0.5431859493255615
Validation loss: 1.8461298006837086

Epoch: 6| Step: 12
Training loss: 1.118600606918335
Validation loss: 1.8537801311862083

Epoch: 6| Step: 13
Training loss: 0.39334237575531006
Validation loss: 1.8316248898865075

Epoch: 251| Step: 0
Training loss: 0.7166244983673096
Validation loss: 1.8361827814450828

Epoch: 6| Step: 1
Training loss: 0.4942188262939453
Validation loss: 1.8254720472520398

Epoch: 6| Step: 2
Training loss: 0.9067846536636353
Validation loss: 1.8542983493497294

Epoch: 6| Step: 3
Training loss: 0.33453813195228577
Validation loss: 1.8511116658487627

Epoch: 6| Step: 4
Training loss: 0.7534822225570679
Validation loss: 1.8444633945342033

Epoch: 6| Step: 5
Training loss: 0.7713803052902222
Validation loss: 1.8436587587479623

Epoch: 6| Step: 6
Training loss: 0.31589317321777344
Validation loss: 1.8275431433031637

Epoch: 6| Step: 7
Training loss: 0.6138245463371277
Validation loss: 1.8732158304542623

Epoch: 6| Step: 8
Training loss: 0.7411895394325256
Validation loss: 1.9078902736786874

Epoch: 6| Step: 9
Training loss: 0.8363009691238403
Validation loss: 1.9131486492772256

Epoch: 6| Step: 10
Training loss: 0.7517894506454468
Validation loss: 1.8965762725440405

Epoch: 6| Step: 11
Training loss: 0.8234843015670776
Validation loss: 1.909362458413647

Epoch: 6| Step: 12
Training loss: 0.6507832407951355
Validation loss: 1.8863131782060027

Epoch: 6| Step: 13
Training loss: 0.9916958212852478
Validation loss: 1.8523904815796883

Epoch: 252| Step: 0
Training loss: 0.5180078744888306
Validation loss: 1.8575388359767135

Epoch: 6| Step: 1
Training loss: 0.43262824416160583
Validation loss: 1.8127322530233732

Epoch: 6| Step: 2
Training loss: 0.8099069595336914
Validation loss: 1.82848709629428

Epoch: 6| Step: 3
Training loss: 1.0919699668884277
Validation loss: 1.7914882347147951

Epoch: 6| Step: 4
Training loss: 0.8013975024223328
Validation loss: 1.7952899266314764

Epoch: 6| Step: 5
Training loss: 0.6707439422607422
Validation loss: 1.8022788698955248

Epoch: 6| Step: 6
Training loss: 0.4889485836029053
Validation loss: 1.7922378586184593

Epoch: 6| Step: 7
Training loss: 0.6507053971290588
Validation loss: 1.8132070213235834

Epoch: 6| Step: 8
Training loss: 0.47628486156463623
Validation loss: 1.826598826275077

Epoch: 6| Step: 9
Training loss: 0.9312668442726135
Validation loss: 1.8505315678094023

Epoch: 6| Step: 10
Training loss: 0.7074166536331177
Validation loss: 1.9036912482271913

Epoch: 6| Step: 11
Training loss: 0.6456356048583984
Validation loss: 1.9441212313149565

Epoch: 6| Step: 12
Training loss: 0.6376410722732544
Validation loss: 1.9254378208550074

Epoch: 6| Step: 13
Training loss: 0.6114112734794617
Validation loss: 1.951487470698613

Epoch: 253| Step: 0
Training loss: 0.4448641538619995
Validation loss: 1.9296079758674867

Epoch: 6| Step: 1
Training loss: 0.7550989985466003
Validation loss: 1.861599829889113

Epoch: 6| Step: 2
Training loss: 0.2842884659767151
Validation loss: 1.782562509659798

Epoch: 6| Step: 3
Training loss: 0.5908332467079163
Validation loss: 1.7746299133505872

Epoch: 6| Step: 4
Training loss: 0.7992330193519592
Validation loss: 1.7836647725874377

Epoch: 6| Step: 5
Training loss: 0.7556021213531494
Validation loss: 1.7501979130570606

Epoch: 6| Step: 6
Training loss: 0.9661768078804016
Validation loss: 1.7506490356178694

Epoch: 6| Step: 7
Training loss: 0.7418531179428101
Validation loss: 1.7246863316464167

Epoch: 6| Step: 8
Training loss: 0.6194356679916382
Validation loss: 1.7366549097081667

Epoch: 6| Step: 9
Training loss: 0.6916240453720093
Validation loss: 1.7284765704985587

Epoch: 6| Step: 10
Training loss: 1.0021207332611084
Validation loss: 1.7440959574073873

Epoch: 6| Step: 11
Training loss: 0.6050564050674438
Validation loss: 1.8093770268142864

Epoch: 6| Step: 12
Training loss: 0.6215046644210815
Validation loss: 1.8659946226304578

Epoch: 6| Step: 13
Training loss: 0.6194345355033875
Validation loss: 1.887682358423869

Epoch: 254| Step: 0
Training loss: 0.6159603595733643
Validation loss: 1.887019807292569

Epoch: 6| Step: 1
Training loss: 0.8147152662277222
Validation loss: 1.8123467942719818

Epoch: 6| Step: 2
Training loss: 0.8829606771469116
Validation loss: 1.8319073941117974

Epoch: 6| Step: 3
Training loss: 0.43392497301101685
Validation loss: 1.8046653757813156

Epoch: 6| Step: 4
Training loss: 0.4267108738422394
Validation loss: 1.850806910504577

Epoch: 6| Step: 5
Training loss: 0.7063802480697632
Validation loss: 1.8658189107013006

Epoch: 6| Step: 6
Training loss: 1.0201327800750732
Validation loss: 1.8495225996099494

Epoch: 6| Step: 7
Training loss: 0.4903150200843811
Validation loss: 1.8397401891728884

Epoch: 6| Step: 8
Training loss: 0.9048768281936646
Validation loss: 1.8151086030467865

Epoch: 6| Step: 9
Training loss: 0.8704370856285095
Validation loss: 1.8566936382683374

Epoch: 6| Step: 10
Training loss: 0.6419240236282349
Validation loss: 1.803038183078971

Epoch: 6| Step: 11
Training loss: 0.8731058835983276
Validation loss: 1.8365434677370134

Epoch: 6| Step: 12
Training loss: 0.5027413368225098
Validation loss: 1.8654180803606588

Epoch: 6| Step: 13
Training loss: 0.531973659992218
Validation loss: 1.9005239958404212

Epoch: 255| Step: 0
Training loss: 0.4896431565284729
Validation loss: 1.856569528579712

Epoch: 6| Step: 1
Training loss: 0.806106448173523
Validation loss: 1.9056256201959425

Epoch: 6| Step: 2
Training loss: 0.6582545638084412
Validation loss: 1.8889873181619952

Epoch: 6| Step: 3
Training loss: 0.6481067538261414
Validation loss: 1.876531821425243

Epoch: 6| Step: 4
Training loss: 0.6593397855758667
Validation loss: 1.8298914304343603

Epoch: 6| Step: 5
Training loss: 0.5960400104522705
Validation loss: 1.8017725162608649

Epoch: 6| Step: 6
Training loss: 0.509464681148529
Validation loss: 1.823386489704091

Epoch: 6| Step: 7
Training loss: 1.0031540393829346
Validation loss: 1.806296811308912

Epoch: 6| Step: 8
Training loss: 0.7424889802932739
Validation loss: 1.8001431944549724

Epoch: 6| Step: 9
Training loss: 0.8551304340362549
Validation loss: 1.8382119670990975

Epoch: 6| Step: 10
Training loss: 0.8427019119262695
Validation loss: 1.811468703772432

Epoch: 6| Step: 11
Training loss: 0.8541051745414734
Validation loss: 1.7888444880003571

Epoch: 6| Step: 12
Training loss: 0.614524245262146
Validation loss: 1.8079013234825545

Epoch: 6| Step: 13
Training loss: 0.33345896005630493
Validation loss: 1.840409545488255

Epoch: 256| Step: 0
Training loss: 0.6906633377075195
Validation loss: 1.8480941275114655

Epoch: 6| Step: 1
Training loss: 0.6251765489578247
Validation loss: 1.9094913287829327

Epoch: 6| Step: 2
Training loss: 0.6459656953811646
Validation loss: 1.89271116769442

Epoch: 6| Step: 3
Training loss: 0.37959739565849304
Validation loss: 1.9477573658830376

Epoch: 6| Step: 4
Training loss: 0.5548858642578125
Validation loss: 1.9688426615089498

Epoch: 6| Step: 5
Training loss: 1.0052845478057861
Validation loss: 1.9667161869746383

Epoch: 6| Step: 6
Training loss: 0.8268246650695801
Validation loss: 1.975706059445617

Epoch: 6| Step: 7
Training loss: 1.0645313262939453
Validation loss: 1.9147720862460393

Epoch: 6| Step: 8
Training loss: 0.5388875007629395
Validation loss: 1.9109180870876517

Epoch: 6| Step: 9
Training loss: 0.7337814569473267
Validation loss: 1.8508077885514946

Epoch: 6| Step: 10
Training loss: 0.5848370790481567
Validation loss: 1.8417643142002884

Epoch: 6| Step: 11
Training loss: 0.9521326422691345
Validation loss: 1.786506433640757

Epoch: 6| Step: 12
Training loss: 0.6647881269454956
Validation loss: 1.8226754998648038

Epoch: 6| Step: 13
Training loss: 0.6249043941497803
Validation loss: 1.8379971160683581

Epoch: 257| Step: 0
Training loss: 0.9775160551071167
Validation loss: 1.8375783902342602

Epoch: 6| Step: 1
Training loss: 0.955518364906311
Validation loss: 1.8420331670391945

Epoch: 6| Step: 2
Training loss: 0.7022550106048584
Validation loss: 1.8228629904408609

Epoch: 6| Step: 3
Training loss: 0.6537535190582275
Validation loss: 1.8289032610513831

Epoch: 6| Step: 4
Training loss: 0.5985136032104492
Validation loss: 1.8615593192397908

Epoch: 6| Step: 5
Training loss: 0.36796683073043823
Validation loss: 1.8863248248254099

Epoch: 6| Step: 6
Training loss: 0.5255851149559021
Validation loss: 1.950613910152066

Epoch: 6| Step: 7
Training loss: 0.7620368003845215
Validation loss: 1.94365874157157

Epoch: 6| Step: 8
Training loss: 0.5716452598571777
Validation loss: 1.98563802114097

Epoch: 6| Step: 9
Training loss: 0.5888901948928833
Validation loss: 1.9426011577729256

Epoch: 6| Step: 10
Training loss: 1.1532096862792969
Validation loss: 1.9830182354937318

Epoch: 6| Step: 11
Training loss: 0.9405351877212524
Validation loss: 1.9865938373791274

Epoch: 6| Step: 12
Training loss: 0.6499768495559692
Validation loss: 1.9741839670365857

Epoch: 6| Step: 13
Training loss: 0.9729633331298828
Validation loss: 1.9489561793624715

Epoch: 258| Step: 0
Training loss: 0.5654202103614807
Validation loss: 1.8894651820582729

Epoch: 6| Step: 1
Training loss: 0.7893110513687134
Validation loss: 1.842718538417611

Epoch: 6| Step: 2
Training loss: 0.8077856302261353
Validation loss: 1.8002681603995703

Epoch: 6| Step: 3
Training loss: 0.6778425574302673
Validation loss: 1.7624841966936666

Epoch: 6| Step: 4
Training loss: 0.7267402410507202
Validation loss: 1.7759058834404073

Epoch: 6| Step: 5
Training loss: 0.36350980401039124
Validation loss: 1.7368076514172297

Epoch: 6| Step: 6
Training loss: 0.6749351024627686
Validation loss: 1.7699849528651084

Epoch: 6| Step: 7
Training loss: 0.7635035514831543
Validation loss: 1.7776662970101962

Epoch: 6| Step: 8
Training loss: 0.723530650138855
Validation loss: 1.7886387096938265

Epoch: 6| Step: 9
Training loss: 0.7488576173782349
Validation loss: 1.7697904263773272

Epoch: 6| Step: 10
Training loss: 0.49241089820861816
Validation loss: 1.8342344914713213

Epoch: 6| Step: 11
Training loss: 0.7691464424133301
Validation loss: 1.8643347165917838

Epoch: 6| Step: 12
Training loss: 0.8064206838607788
Validation loss: 1.8921184565431328

Epoch: 6| Step: 13
Training loss: 0.4641476273536682
Validation loss: 1.9245404402414958

Epoch: 259| Step: 0
Training loss: 0.8341156244277954
Validation loss: 1.8685131354998517

Epoch: 6| Step: 1
Training loss: 0.5851298570632935
Validation loss: 1.884134715603244

Epoch: 6| Step: 2
Training loss: 0.43376362323760986
Validation loss: 1.8594000236962431

Epoch: 6| Step: 3
Training loss: 0.7840145230293274
Validation loss: 1.8629796351155927

Epoch: 6| Step: 4
Training loss: 0.778359055519104
Validation loss: 1.8710237946561588

Epoch: 6| Step: 5
Training loss: 0.8489217162132263
Validation loss: 1.864132672227839

Epoch: 6| Step: 6
Training loss: 0.9234217405319214
Validation loss: 1.8780411930494412

Epoch: 6| Step: 7
Training loss: 0.5403755307197571
Validation loss: 1.869063033852526

Epoch: 6| Step: 8
Training loss: 0.39875760674476624
Validation loss: 1.8795228171092209

Epoch: 6| Step: 9
Training loss: 0.6016173362731934
Validation loss: 1.845921706127864

Epoch: 6| Step: 10
Training loss: 0.3863520324230194
Validation loss: 1.8698170902908489

Epoch: 6| Step: 11
Training loss: 0.580578625202179
Validation loss: 1.8678320274558118

Epoch: 6| Step: 12
Training loss: 0.6648317575454712
Validation loss: 1.889199767061459

Epoch: 6| Step: 13
Training loss: 0.918929934501648
Validation loss: 1.8915525021091584

Epoch: 260| Step: 0
Training loss: 0.5698756575584412
Validation loss: 1.9395596647775302

Epoch: 6| Step: 1
Training loss: 0.5216911435127258
Validation loss: 1.949203106664842

Epoch: 6| Step: 2
Training loss: 0.8533555269241333
Validation loss: 1.9869903377307359

Epoch: 6| Step: 3
Training loss: 0.7422159314155579
Validation loss: 1.9874757489850443

Epoch: 6| Step: 4
Training loss: 0.6310962438583374
Validation loss: 1.9573374486738635

Epoch: 6| Step: 5
Training loss: 0.6457594037055969
Validation loss: 1.9486065013434297

Epoch: 6| Step: 6
Training loss: 0.6197279095649719
Validation loss: 1.9077281708358436

Epoch: 6| Step: 7
Training loss: 0.974959135055542
Validation loss: 1.860760586236113

Epoch: 6| Step: 8
Training loss: 0.2831180691719055
Validation loss: 1.8654004707131335

Epoch: 6| Step: 9
Training loss: 0.6254822015762329
Validation loss: 1.7964424343519314

Epoch: 6| Step: 10
Training loss: 0.7473177909851074
Validation loss: 1.7996363562922324

Epoch: 6| Step: 11
Training loss: 0.5457003712654114
Validation loss: 1.7836747528404318

Epoch: 6| Step: 12
Training loss: 0.49363598227500916
Validation loss: 1.805550177892049

Epoch: 6| Step: 13
Training loss: 0.884315013885498
Validation loss: 1.800670734015844

Epoch: 261| Step: 0
Training loss: 0.5947148203849792
Validation loss: 1.8505125327776837

Epoch: 6| Step: 1
Training loss: 0.5642824172973633
Validation loss: 1.887892020645962

Epoch: 6| Step: 2
Training loss: 0.7469619512557983
Validation loss: 1.889061830377066

Epoch: 6| Step: 3
Training loss: 0.4787008464336395
Validation loss: 1.9319557220705095

Epoch: 6| Step: 4
Training loss: 0.729697585105896
Validation loss: 1.8871056008082565

Epoch: 6| Step: 5
Training loss: 0.758011519908905
Validation loss: 1.9451677671042822

Epoch: 6| Step: 6
Training loss: 0.7701807022094727
Validation loss: 1.9231697385029127

Epoch: 6| Step: 7
Training loss: 0.6868672370910645
Validation loss: 1.904995233781876

Epoch: 6| Step: 8
Training loss: 1.0028492212295532
Validation loss: 1.8713151844598914

Epoch: 6| Step: 9
Training loss: 0.6873225569725037
Validation loss: 1.8120990030227169

Epoch: 6| Step: 10
Training loss: 0.4733240008354187
Validation loss: 1.8032352296254968

Epoch: 6| Step: 11
Training loss: 0.5174142718315125
Validation loss: 1.774315982736567

Epoch: 6| Step: 12
Training loss: 0.5538835525512695
Validation loss: 1.7760527287760088

Epoch: 6| Step: 13
Training loss: 0.5841629505157471
Validation loss: 1.7425308253175469

Epoch: 262| Step: 0
Training loss: 0.3736076056957245
Validation loss: 1.749130448987407

Epoch: 6| Step: 1
Training loss: 0.5264513492584229
Validation loss: 1.7556961800462456

Epoch: 6| Step: 2
Training loss: 0.5213906168937683
Validation loss: 1.774065899592574

Epoch: 6| Step: 3
Training loss: 0.7355173826217651
Validation loss: 1.833803911362925

Epoch: 6| Step: 4
Training loss: 0.8221548795700073
Validation loss: 1.8821490349308136

Epoch: 6| Step: 5
Training loss: 0.8606696724891663
Validation loss: 1.8597410673736243

Epoch: 6| Step: 6
Training loss: 0.6179895401000977
Validation loss: 1.8472716180227136

Epoch: 6| Step: 7
Training loss: 0.5130165815353394
Validation loss: 1.8805245225147535

Epoch: 6| Step: 8
Training loss: 0.83150714635849
Validation loss: 1.9115804779914118

Epoch: 6| Step: 9
Training loss: 0.6688354015350342
Validation loss: 1.8797263817120624

Epoch: 6| Step: 10
Training loss: 0.46681416034698486
Validation loss: 1.8684061393942883

Epoch: 6| Step: 11
Training loss: 0.8945989012718201
Validation loss: 1.8443787533749816

Epoch: 6| Step: 12
Training loss: 0.4505409002304077
Validation loss: 1.870183212782747

Epoch: 6| Step: 13
Training loss: 0.36668965220451355
Validation loss: 1.8579694430033367

Epoch: 263| Step: 0
Training loss: 0.8399686813354492
Validation loss: 1.790533866933597

Epoch: 6| Step: 1
Training loss: 0.5117122530937195
Validation loss: 1.8042454052996892

Epoch: 6| Step: 2
Training loss: 0.5593233108520508
Validation loss: 1.8054109798964633

Epoch: 6| Step: 3
Training loss: 0.45693379640579224
Validation loss: 1.8165571138422976

Epoch: 6| Step: 4
Training loss: 0.7392896413803101
Validation loss: 1.7986706661921676

Epoch: 6| Step: 5
Training loss: 0.7592005133628845
Validation loss: 1.8541365426073793

Epoch: 6| Step: 6
Training loss: 0.29446911811828613
Validation loss: 1.8789442162359915

Epoch: 6| Step: 7
Training loss: 0.7858725190162659
Validation loss: 1.8791699665848927

Epoch: 6| Step: 8
Training loss: 0.7220112085342407
Validation loss: 1.905185971208798

Epoch: 6| Step: 9
Training loss: 0.7477306127548218
Validation loss: 1.9036707070565992

Epoch: 6| Step: 10
Training loss: 0.34421175718307495
Validation loss: 1.8513096558150424

Epoch: 6| Step: 11
Training loss: 0.35252848267555237
Validation loss: 1.8456642717443488

Epoch: 6| Step: 12
Training loss: 0.6968122720718384
Validation loss: 1.8407765216724847

Epoch: 6| Step: 13
Training loss: 0.7917045950889587
Validation loss: 1.8077245758425804

Epoch: 264| Step: 0
Training loss: 0.4066561758518219
Validation loss: 1.8000448288456086

Epoch: 6| Step: 1
Training loss: 0.41187676787376404
Validation loss: 1.7557095084139096

Epoch: 6| Step: 2
Training loss: 0.5977000594139099
Validation loss: 1.7630703961977394

Epoch: 6| Step: 3
Training loss: 0.5802526473999023
Validation loss: 1.7752408289140271

Epoch: 6| Step: 4
Training loss: 0.952713131904602
Validation loss: 1.8322398495930496

Epoch: 6| Step: 5
Training loss: 0.5112679600715637
Validation loss: 1.7828152820628176

Epoch: 6| Step: 6
Training loss: 0.3950080871582031
Validation loss: 1.8337869323709959

Epoch: 6| Step: 7
Training loss: 0.4662123918533325
Validation loss: 1.8509281194338234

Epoch: 6| Step: 8
Training loss: 0.8007181286811829
Validation loss: 1.87921606468898

Epoch: 6| Step: 9
Training loss: 0.9087944030761719
Validation loss: 1.8762088744871077

Epoch: 6| Step: 10
Training loss: 0.7804570198059082
Validation loss: 1.8895619466740599

Epoch: 6| Step: 11
Training loss: 0.42135509848594666
Validation loss: 1.8935327863180509

Epoch: 6| Step: 12
Training loss: 0.7557114362716675
Validation loss: 1.8829017749396704

Epoch: 6| Step: 13
Training loss: 0.5901567339897156
Validation loss: 1.8743663769896313

Epoch: 265| Step: 0
Training loss: 0.5230213403701782
Validation loss: 1.870062735772902

Epoch: 6| Step: 1
Training loss: 0.5165578722953796
Validation loss: 1.8493549580215125

Epoch: 6| Step: 2
Training loss: 0.6619845628738403
Validation loss: 1.78696483437733

Epoch: 6| Step: 3
Training loss: 0.6887975931167603
Validation loss: 1.7968672129415697

Epoch: 6| Step: 4
Training loss: 0.7021386027336121
Validation loss: 1.7476293451042586

Epoch: 6| Step: 5
Training loss: 0.5892837643623352
Validation loss: 1.777961919384618

Epoch: 6| Step: 6
Training loss: 0.3832200765609741
Validation loss: 1.741126783432499

Epoch: 6| Step: 7
Training loss: 0.4179667830467224
Validation loss: 1.7689792815075125

Epoch: 6| Step: 8
Training loss: 0.6267054080963135
Validation loss: 1.7570534444624377

Epoch: 6| Step: 9
Training loss: 0.830828070640564
Validation loss: 1.7923531724560646

Epoch: 6| Step: 10
Training loss: 0.7364505529403687
Validation loss: 1.7919025523688203

Epoch: 6| Step: 11
Training loss: 0.4365716576576233
Validation loss: 1.8155986467997234

Epoch: 6| Step: 12
Training loss: 0.84760582447052
Validation loss: 1.7790341620804162

Epoch: 6| Step: 13
Training loss: 0.5812503695487976
Validation loss: 1.8482657478701683

Epoch: 266| Step: 0
Training loss: 0.6233927011489868
Validation loss: 1.8206757448052848

Epoch: 6| Step: 1
Training loss: 0.6832810640335083
Validation loss: 1.897924546272524

Epoch: 6| Step: 2
Training loss: 0.6424317955970764
Validation loss: 1.8985159166397587

Epoch: 6| Step: 3
Training loss: 0.7198363542556763
Validation loss: 1.9264973120022846

Epoch: 6| Step: 4
Training loss: 0.5943077802658081
Validation loss: 1.8886319078424925

Epoch: 6| Step: 5
Training loss: 0.4166695177555084
Validation loss: 1.8540314474413473

Epoch: 6| Step: 6
Training loss: 0.5485066175460815
Validation loss: 1.8174762802739297

Epoch: 6| Step: 7
Training loss: 0.38463544845581055
Validation loss: 1.8178840324442873

Epoch: 6| Step: 8
Training loss: 0.8485487699508667
Validation loss: 1.8162107980379494

Epoch: 6| Step: 9
Training loss: 0.5942131280899048
Validation loss: 1.7967279841822963

Epoch: 6| Step: 10
Training loss: 0.4896411895751953
Validation loss: 1.7997263035466593

Epoch: 6| Step: 11
Training loss: 0.8644770979881287
Validation loss: 1.7830520650391937

Epoch: 6| Step: 12
Training loss: 0.8509868383407593
Validation loss: 1.7844940103510374

Epoch: 6| Step: 13
Training loss: 0.4197246730327606
Validation loss: 1.7731555264483216

Epoch: 267| Step: 0
Training loss: 0.599846363067627
Validation loss: 1.778223153083555

Epoch: 6| Step: 1
Training loss: 0.8414269089698792
Validation loss: 1.7357615232467651

Epoch: 6| Step: 2
Training loss: 0.1848028004169464
Validation loss: 1.7510603602214525

Epoch: 6| Step: 3
Training loss: 0.6730008125305176
Validation loss: 1.7619048677464968

Epoch: 6| Step: 4
Training loss: 0.5064612627029419
Validation loss: 1.7535755608671455

Epoch: 6| Step: 5
Training loss: 0.44016891717910767
Validation loss: 1.7655133073047926

Epoch: 6| Step: 6
Training loss: 0.5853316187858582
Validation loss: 1.8085062016722977

Epoch: 6| Step: 7
Training loss: 1.2021712064743042
Validation loss: 1.8013917579445788

Epoch: 6| Step: 8
Training loss: 0.7407060861587524
Validation loss: 1.8122627555683095

Epoch: 6| Step: 9
Training loss: 0.6168023347854614
Validation loss: 1.812403622493949

Epoch: 6| Step: 10
Training loss: 0.4844871163368225
Validation loss: 1.816405718044568

Epoch: 6| Step: 11
Training loss: 0.4391371011734009
Validation loss: 1.8108605697590818

Epoch: 6| Step: 12
Training loss: 0.4958800673484802
Validation loss: 1.8035076971976989

Epoch: 6| Step: 13
Training loss: 0.6320458650588989
Validation loss: 1.8234021112483034

Epoch: 268| Step: 0
Training loss: 0.5332943797111511
Validation loss: 1.7690893270636117

Epoch: 6| Step: 1
Training loss: 0.4986388683319092
Validation loss: 1.802686636165906

Epoch: 6| Step: 2
Training loss: 0.8674033284187317
Validation loss: 1.7459850900916642

Epoch: 6| Step: 3
Training loss: 0.8192771673202515
Validation loss: 1.745359201585093

Epoch: 6| Step: 4
Training loss: 0.6088436245918274
Validation loss: 1.7374869328673168

Epoch: 6| Step: 5
Training loss: 0.3987374007701874
Validation loss: 1.7514623698367868

Epoch: 6| Step: 6
Training loss: 0.788036584854126
Validation loss: 1.7493149811221707

Epoch: 6| Step: 7
Training loss: 0.6506495475769043
Validation loss: 1.7522423613455989

Epoch: 6| Step: 8
Training loss: 0.8256679773330688
Validation loss: 1.7717563311258953

Epoch: 6| Step: 9
Training loss: 0.5236719250679016
Validation loss: 1.7749133597138107

Epoch: 6| Step: 10
Training loss: 0.5712704062461853
Validation loss: 1.8080389115118212

Epoch: 6| Step: 11
Training loss: 0.36397337913513184
Validation loss: 1.8192227694296068

Epoch: 6| Step: 12
Training loss: 0.5884016752243042
Validation loss: 1.9322929971961564

Epoch: 6| Step: 13
Training loss: 0.3122473955154419
Validation loss: 1.9411263824791036

Epoch: 269| Step: 0
Training loss: 0.7079900503158569
Validation loss: 1.9955714030932354

Epoch: 6| Step: 1
Training loss: 0.5239819884300232
Validation loss: 2.0179536650257726

Epoch: 6| Step: 2
Training loss: 0.7545521259307861
Validation loss: 1.9881284518908429

Epoch: 6| Step: 3
Training loss: 0.6262722611427307
Validation loss: 2.002919049673183

Epoch: 6| Step: 4
Training loss: 0.42942726612091064
Validation loss: 2.006562013779917

Epoch: 6| Step: 5
Training loss: 0.5972681641578674
Validation loss: 1.9397280434126496

Epoch: 6| Step: 6
Training loss: 0.4089263379573822
Validation loss: 1.8777438363721293

Epoch: 6| Step: 7
Training loss: 0.7248439788818359
Validation loss: 1.853203644034683

Epoch: 6| Step: 8
Training loss: 0.7845092415809631
Validation loss: 1.7557814467337824

Epoch: 6| Step: 9
Training loss: 0.5209935307502747
Validation loss: 1.7759543452211606

Epoch: 6| Step: 10
Training loss: 0.677062451839447
Validation loss: 1.7474709242902777

Epoch: 6| Step: 11
Training loss: 0.5329228639602661
Validation loss: 1.7762424433103172

Epoch: 6| Step: 12
Training loss: 0.8003661036491394
Validation loss: 1.7781820361332228

Epoch: 6| Step: 13
Training loss: 0.6783627271652222
Validation loss: 1.7993132222083308

Epoch: 270| Step: 0
Training loss: 0.48648685216903687
Validation loss: 1.811884997993387

Epoch: 6| Step: 1
Training loss: 0.4244675636291504
Validation loss: 1.8786518112305672

Epoch: 6| Step: 2
Training loss: 0.819015622138977
Validation loss: 1.864766916921062

Epoch: 6| Step: 3
Training loss: 0.7752498388290405
Validation loss: 1.884043219268963

Epoch: 6| Step: 4
Training loss: 0.6629288196563721
Validation loss: 1.898515162929412

Epoch: 6| Step: 5
Training loss: 0.5859863758087158
Validation loss: 1.866318501451964

Epoch: 6| Step: 6
Training loss: 0.6641483902931213
Validation loss: 1.8747486452902518

Epoch: 6| Step: 7
Training loss: 0.7454978227615356
Validation loss: 1.873141497694036

Epoch: 6| Step: 8
Training loss: 0.5057426691055298
Validation loss: 1.8865766973905667

Epoch: 6| Step: 9
Training loss: 0.37653225660324097
Validation loss: 1.87256371718581

Epoch: 6| Step: 10
Training loss: 0.6068766117095947
Validation loss: 1.872872890964631

Epoch: 6| Step: 11
Training loss: 0.4774149954319
Validation loss: 1.8537154620693577

Epoch: 6| Step: 12
Training loss: 0.6592274904251099
Validation loss: 1.8116909201427172

Epoch: 6| Step: 13
Training loss: 0.37283268570899963
Validation loss: 1.8052710230632494

Epoch: 271| Step: 0
Training loss: 0.46555188298225403
Validation loss: 1.7855699998076244

Epoch: 6| Step: 1
Training loss: 0.5431607961654663
Validation loss: 1.8378825213319512

Epoch: 6| Step: 2
Training loss: 0.4822807312011719
Validation loss: 1.8496870648476385

Epoch: 6| Step: 3
Training loss: 0.4373779892921448
Validation loss: 1.8304576540506015

Epoch: 6| Step: 4
Training loss: 0.6351698637008667
Validation loss: 1.8573752974951139

Epoch: 6| Step: 5
Training loss: 0.4021613597869873
Validation loss: 1.8431031139948035

Epoch: 6| Step: 6
Training loss: 0.7444173097610474
Validation loss: 1.8240777087467972

Epoch: 6| Step: 7
Training loss: 0.541196346282959
Validation loss: 1.8160295255722538

Epoch: 6| Step: 8
Training loss: 0.5026190280914307
Validation loss: 1.798467182344006

Epoch: 6| Step: 9
Training loss: 0.8710764646530151
Validation loss: 1.771754785250592

Epoch: 6| Step: 10
Training loss: 0.6710598468780518
Validation loss: 1.7624528049140848

Epoch: 6| Step: 11
Training loss: 0.5538289546966553
Validation loss: 1.7647348834622292

Epoch: 6| Step: 12
Training loss: 0.41313493251800537
Validation loss: 1.7516740034985285

Epoch: 6| Step: 13
Training loss: 0.9378982186317444
Validation loss: 1.7826170844416465

Epoch: 272| Step: 0
Training loss: 0.6732394099235535
Validation loss: 1.7850854653184132

Epoch: 6| Step: 1
Training loss: 0.8468177318572998
Validation loss: 1.824465263274408

Epoch: 6| Step: 2
Training loss: 0.5128342509269714
Validation loss: 1.832978972824671

Epoch: 6| Step: 3
Training loss: 0.6495071053504944
Validation loss: 1.851758833854429

Epoch: 6| Step: 4
Training loss: 0.534643292427063
Validation loss: 1.8953483322615265

Epoch: 6| Step: 5
Training loss: 0.35219210386276245
Validation loss: 1.9086545500704037

Epoch: 6| Step: 6
Training loss: 0.7414828538894653
Validation loss: 1.9594574820610784

Epoch: 6| Step: 7
Training loss: 0.48264768719673157
Validation loss: 1.9785796442339498

Epoch: 6| Step: 8
Training loss: 0.4581370949745178
Validation loss: 1.980128385687387

Epoch: 6| Step: 9
Training loss: 0.5227829217910767
Validation loss: 1.9694045756452827

Epoch: 6| Step: 10
Training loss: 0.5671323537826538
Validation loss: 1.9790456730832335

Epoch: 6| Step: 11
Training loss: 0.8400885462760925
Validation loss: 1.946157427244289

Epoch: 6| Step: 12
Training loss: 0.4932590126991272
Validation loss: 1.9274640724223147

Epoch: 6| Step: 13
Training loss: 0.37505772709846497
Validation loss: 1.868670912199123

Epoch: 273| Step: 0
Training loss: 0.5073355436325073
Validation loss: 1.8440795893310218

Epoch: 6| Step: 1
Training loss: 0.4670792818069458
Validation loss: 1.775899109020028

Epoch: 6| Step: 2
Training loss: 0.6754458546638489
Validation loss: 1.7428240109515447

Epoch: 6| Step: 3
Training loss: 0.6482959389686584
Validation loss: 1.7039267478450653

Epoch: 6| Step: 4
Training loss: 0.6488314867019653
Validation loss: 1.7711622330450243

Epoch: 6| Step: 5
Training loss: 0.5821806192398071
Validation loss: 1.80420349490258

Epoch: 6| Step: 6
Training loss: 0.9476813077926636
Validation loss: 1.7976320674342494

Epoch: 6| Step: 7
Training loss: 0.5887546539306641
Validation loss: 1.8447583734348256

Epoch: 6| Step: 8
Training loss: 0.4954022169113159
Validation loss: 1.8416565272115892

Epoch: 6| Step: 9
Training loss: 0.7367843389511108
Validation loss: 1.920828862856793

Epoch: 6| Step: 10
Training loss: 0.7515255212783813
Validation loss: 1.9505613401371946

Epoch: 6| Step: 11
Training loss: 0.5995237827301025
Validation loss: 1.9659347457270469

Epoch: 6| Step: 12
Training loss: 0.5404178500175476
Validation loss: 1.9980409837538196

Epoch: 6| Step: 13
Training loss: 0.49178969860076904
Validation loss: 2.017414991573621

Epoch: 274| Step: 0
Training loss: 0.3418242931365967
Validation loss: 2.0218435295166506

Epoch: 6| Step: 1
Training loss: 0.4745209217071533
Validation loss: 2.008482663862167

Epoch: 6| Step: 2
Training loss: 0.7834285497665405
Validation loss: 2.0186183555151826

Epoch: 6| Step: 3
Training loss: 0.24156218767166138
Validation loss: 2.016137812727241

Epoch: 6| Step: 4
Training loss: 0.5929436683654785
Validation loss: 1.9911066101443382

Epoch: 6| Step: 5
Training loss: 0.9039289951324463
Validation loss: 1.96691640346281

Epoch: 6| Step: 6
Training loss: 0.876081645488739
Validation loss: 1.923154402804631

Epoch: 6| Step: 7
Training loss: 0.5443581342697144
Validation loss: 1.848465996403848

Epoch: 6| Step: 8
Training loss: 0.43521052598953247
Validation loss: 1.7793615210440852

Epoch: 6| Step: 9
Training loss: 0.572428286075592
Validation loss: 1.7774758826019943

Epoch: 6| Step: 10
Training loss: 0.25575727224349976
Validation loss: 1.7475306833944013

Epoch: 6| Step: 11
Training loss: 0.593106746673584
Validation loss: 1.7398104590754355

Epoch: 6| Step: 12
Training loss: 0.923004150390625
Validation loss: 1.7176231543223064

Epoch: 6| Step: 13
Training loss: 0.49921172857284546
Validation loss: 1.7405755981322257

Epoch: 275| Step: 0
Training loss: 0.5050459504127502
Validation loss: 1.751895325158232

Epoch: 6| Step: 1
Training loss: 0.4093867540359497
Validation loss: 1.7694243833582888

Epoch: 6| Step: 2
Training loss: 0.6624340415000916
Validation loss: 1.8205611154597292

Epoch: 6| Step: 3
Training loss: 0.7988022565841675
Validation loss: 1.840045157299247

Epoch: 6| Step: 4
Training loss: 0.45415937900543213
Validation loss: 1.8650568749314995

Epoch: 6| Step: 5
Training loss: 0.6375664472579956
Validation loss: 1.8610144712591683

Epoch: 6| Step: 6
Training loss: 0.6815148591995239
Validation loss: 1.9327448337308821

Epoch: 6| Step: 7
Training loss: 0.5194159746170044
Validation loss: 1.8820264621447491

Epoch: 6| Step: 8
Training loss: 0.4283696413040161
Validation loss: 1.8634603420893352

Epoch: 6| Step: 9
Training loss: 0.4655495882034302
Validation loss: 1.8682047244041198

Epoch: 6| Step: 10
Training loss: 0.661460280418396
Validation loss: 1.8612911566611259

Epoch: 6| Step: 11
Training loss: 0.37828147411346436
Validation loss: 1.8646890142912507

Epoch: 6| Step: 12
Training loss: 0.624790608882904
Validation loss: 1.8644695769074142

Epoch: 6| Step: 13
Training loss: 0.39955055713653564
Validation loss: 1.859786751449749

Epoch: 276| Step: 0
Training loss: 0.5909024477005005
Validation loss: 1.8374684895238569

Epoch: 6| Step: 1
Training loss: 0.549311637878418
Validation loss: 1.8352917804512927

Epoch: 6| Step: 2
Training loss: 0.29512321949005127
Validation loss: 1.7959995397957422

Epoch: 6| Step: 3
Training loss: 0.3189198970794678
Validation loss: 1.789939990607641

Epoch: 6| Step: 4
Training loss: 0.43393757939338684
Validation loss: 1.7608331531606696

Epoch: 6| Step: 5
Training loss: 0.3886905610561371
Validation loss: 1.7687405424733316

Epoch: 6| Step: 6
Training loss: 0.3309708833694458
Validation loss: 1.7377374326029131

Epoch: 6| Step: 7
Training loss: 0.933169960975647
Validation loss: 1.7400353454774427

Epoch: 6| Step: 8
Training loss: 0.6241231560707092
Validation loss: 1.7619631828800324

Epoch: 6| Step: 9
Training loss: 0.5835068225860596
Validation loss: 1.7883710822751444

Epoch: 6| Step: 10
Training loss: 0.4013829231262207
Validation loss: 1.829312515515153

Epoch: 6| Step: 11
Training loss: 0.7391284704208374
Validation loss: 1.8314393156318254

Epoch: 6| Step: 12
Training loss: 0.7647429704666138
Validation loss: 1.8308818007028231

Epoch: 6| Step: 13
Training loss: 0.45502132177352905
Validation loss: 1.9037626122915616

Epoch: 277| Step: 0
Training loss: 0.6236993670463562
Validation loss: 1.8787751697724866

Epoch: 6| Step: 1
Training loss: 0.5425233840942383
Validation loss: 1.8746433027328984

Epoch: 6| Step: 2
Training loss: 0.33145153522491455
Validation loss: 1.9118722702867241

Epoch: 6| Step: 3
Training loss: 0.5952227115631104
Validation loss: 1.9037852761565999

Epoch: 6| Step: 4
Training loss: 0.2819429337978363
Validation loss: 1.9056576477584017

Epoch: 6| Step: 5
Training loss: 0.8395710587501526
Validation loss: 1.9156951224932106

Epoch: 6| Step: 6
Training loss: 0.6747097373008728
Validation loss: 1.880744940491133

Epoch: 6| Step: 7
Training loss: 0.40129491686820984
Validation loss: 1.8661992460168817

Epoch: 6| Step: 8
Training loss: 0.6327680349349976
Validation loss: 1.8542122046152751

Epoch: 6| Step: 9
Training loss: 0.4400632679462433
Validation loss: 1.8325003923908356

Epoch: 6| Step: 10
Training loss: 0.4557328224182129
Validation loss: 1.8064507297290269

Epoch: 6| Step: 11
Training loss: 0.3148711025714874
Validation loss: 1.8469406263802641

Epoch: 6| Step: 12
Training loss: 0.7065255045890808
Validation loss: 1.825668599015923

Epoch: 6| Step: 13
Training loss: 0.5506406426429749
Validation loss: 1.8677358140227616

Epoch: 278| Step: 0
Training loss: 0.4191865921020508
Validation loss: 1.8727642823291082

Epoch: 6| Step: 1
Training loss: 0.4701785445213318
Validation loss: 1.8772756515010711

Epoch: 6| Step: 2
Training loss: 0.7567598223686218
Validation loss: 1.8957474975175754

Epoch: 6| Step: 3
Training loss: 0.531503438949585
Validation loss: 1.8753219881365377

Epoch: 6| Step: 4
Training loss: 0.5500628352165222
Validation loss: 1.8828253771669121

Epoch: 6| Step: 5
Training loss: 0.4799284338951111
Validation loss: 1.805898989400556

Epoch: 6| Step: 6
Training loss: 0.39455339312553406
Validation loss: 1.8124836644818705

Epoch: 6| Step: 7
Training loss: 0.5657716989517212
Validation loss: 1.8510750468059252

Epoch: 6| Step: 8
Training loss: 0.4706501364707947
Validation loss: 1.822720996795162

Epoch: 6| Step: 9
Training loss: 0.6973075270652771
Validation loss: 1.8639992744691911

Epoch: 6| Step: 10
Training loss: 0.87845778465271
Validation loss: 1.8705053893468713

Epoch: 6| Step: 11
Training loss: 0.5289208292961121
Validation loss: 1.8668530756427395

Epoch: 6| Step: 12
Training loss: 0.4464486241340637
Validation loss: 1.872168456354449

Epoch: 6| Step: 13
Training loss: 0.26458510756492615
Validation loss: 1.8757542038476596

Epoch: 279| Step: 0
Training loss: 0.22267204523086548
Validation loss: 1.864287689167966

Epoch: 6| Step: 1
Training loss: 0.4710213541984558
Validation loss: 1.8815554829053982

Epoch: 6| Step: 2
Training loss: 0.619204580783844
Validation loss: 1.9159137715575516

Epoch: 6| Step: 3
Training loss: 0.8316559791564941
Validation loss: 1.9227256621083906

Epoch: 6| Step: 4
Training loss: 0.5994492769241333
Validation loss: 1.8956881800005514

Epoch: 6| Step: 5
Training loss: 0.31396758556365967
Validation loss: 1.8657638052458405

Epoch: 6| Step: 6
Training loss: 0.34774288535118103
Validation loss: 1.8304063453469226

Epoch: 6| Step: 7
Training loss: 0.43713632225990295
Validation loss: 1.8522702545248053

Epoch: 6| Step: 8
Training loss: 0.5782663822174072
Validation loss: 1.9073466741910545

Epoch: 6| Step: 9
Training loss: 0.38618314266204834
Validation loss: 1.8726922799182195

Epoch: 6| Step: 10
Training loss: 0.43183523416519165
Validation loss: 1.8691486773952362

Epoch: 6| Step: 11
Training loss: 0.7592194080352783
Validation loss: 1.878990069512398

Epoch: 6| Step: 12
Training loss: 0.6101077795028687
Validation loss: 1.85337463501961

Epoch: 6| Step: 13
Training loss: 0.6529572606086731
Validation loss: 1.8650553239289152

Epoch: 280| Step: 0
Training loss: 0.49904364347457886
Validation loss: 1.817407952841892

Epoch: 6| Step: 1
Training loss: 0.46455854177474976
Validation loss: 1.8564168689071492

Epoch: 6| Step: 2
Training loss: 0.4776994585990906
Validation loss: 1.8656427193713445

Epoch: 6| Step: 3
Training loss: 0.4768368899822235
Validation loss: 1.8680860329699773

Epoch: 6| Step: 4
Training loss: 0.449316143989563
Validation loss: 1.8688124661804528

Epoch: 6| Step: 5
Training loss: 0.6695547699928284
Validation loss: 1.8726995055393507

Epoch: 6| Step: 6
Training loss: 0.8570243120193481
Validation loss: 1.9053318833792081

Epoch: 6| Step: 7
Training loss: 0.3119809925556183
Validation loss: 1.8879909669199297

Epoch: 6| Step: 8
Training loss: 0.45347166061401367
Validation loss: 1.9300693042816655

Epoch: 6| Step: 9
Training loss: 0.8374074101448059
Validation loss: 1.9212781883055163

Epoch: 6| Step: 10
Training loss: 0.5374869704246521
Validation loss: 1.9242115482207267

Epoch: 6| Step: 11
Training loss: 0.5775773525238037
Validation loss: 1.8631648453333045

Epoch: 6| Step: 12
Training loss: 0.4207569360733032
Validation loss: 1.857659407841262

Epoch: 6| Step: 13
Training loss: 0.6444776058197021
Validation loss: 1.8754690539452337

Epoch: 281| Step: 0
Training loss: 0.631001889705658
Validation loss: 1.8615606818147885

Epoch: 6| Step: 1
Training loss: 0.7065296173095703
Validation loss: 1.8251438525415236

Epoch: 6| Step: 2
Training loss: 0.5294876098632812
Validation loss: 1.8480373479986703

Epoch: 6| Step: 3
Training loss: 0.9094141721725464
Validation loss: 1.8726429708542363

Epoch: 6| Step: 4
Training loss: 0.6094789505004883
Validation loss: 1.879282429013201

Epoch: 6| Step: 5
Training loss: 0.3795158863067627
Validation loss: 1.8628601617710565

Epoch: 6| Step: 6
Training loss: 0.3563742935657501
Validation loss: 1.8443795929672897

Epoch: 6| Step: 7
Training loss: 0.20498064160346985
Validation loss: 1.8630088913825251

Epoch: 6| Step: 8
Training loss: 0.6903051137924194
Validation loss: 1.811736863146546

Epoch: 6| Step: 9
Training loss: 0.4492167830467224
Validation loss: 1.811165976267989

Epoch: 6| Step: 10
Training loss: 0.4699151813983917
Validation loss: 1.8493601045300883

Epoch: 6| Step: 11
Training loss: 0.625153660774231
Validation loss: 1.8797050829856627

Epoch: 6| Step: 12
Training loss: 0.6029848456382751
Validation loss: 1.8915574858265538

Epoch: 6| Step: 13
Training loss: 0.42697885632514954
Validation loss: 1.8915884007689774

Epoch: 282| Step: 0
Training loss: 0.47847068309783936
Validation loss: 1.859504715088875

Epoch: 6| Step: 1
Training loss: 0.4360712468624115
Validation loss: 1.8630142955369846

Epoch: 6| Step: 2
Training loss: 0.7182823419570923
Validation loss: 1.8686253345140846

Epoch: 6| Step: 3
Training loss: 0.5501495599746704
Validation loss: 1.8473265017232587

Epoch: 6| Step: 4
Training loss: 0.2536180913448334
Validation loss: 1.8430314346026349

Epoch: 6| Step: 5
Training loss: 0.43780645728111267
Validation loss: 1.8644799981065976

Epoch: 6| Step: 6
Training loss: 0.7420041561126709
Validation loss: 1.810178586231765

Epoch: 6| Step: 7
Training loss: 0.45983201265335083
Validation loss: 1.7779583866878221

Epoch: 6| Step: 8
Training loss: 0.5365493297576904
Validation loss: 1.755803878589343

Epoch: 6| Step: 9
Training loss: 0.3410213589668274
Validation loss: 1.7230721930021882

Epoch: 6| Step: 10
Training loss: 0.608288049697876
Validation loss: 1.7510276109941545

Epoch: 6| Step: 11
Training loss: 0.40953946113586426
Validation loss: 1.7142508440120245

Epoch: 6| Step: 12
Training loss: 0.6464036107063293
Validation loss: 1.7512820869363763

Epoch: 6| Step: 13
Training loss: 0.4675314128398895
Validation loss: 1.7974019665871896

Epoch: 283| Step: 0
Training loss: 0.6914186477661133
Validation loss: 1.7953967855822655

Epoch: 6| Step: 1
Training loss: 0.6645156145095825
Validation loss: 1.7757737816021006

Epoch: 6| Step: 2
Training loss: 0.4166415333747864
Validation loss: 1.788242809234127

Epoch: 6| Step: 3
Training loss: 0.4582939147949219
Validation loss: 1.7984005148692797

Epoch: 6| Step: 4
Training loss: 0.4488723576068878
Validation loss: 1.776845509006131

Epoch: 6| Step: 5
Training loss: 0.3740595579147339
Validation loss: 1.819152101393669

Epoch: 6| Step: 6
Training loss: 0.7326759099960327
Validation loss: 1.8455467403575938

Epoch: 6| Step: 7
Training loss: 0.6379818916320801
Validation loss: 1.8984366898895593

Epoch: 6| Step: 8
Training loss: 0.590116024017334
Validation loss: 1.8756057472639187

Epoch: 6| Step: 9
Training loss: 0.46823084354400635
Validation loss: 1.8766606751308645

Epoch: 6| Step: 10
Training loss: 0.8229377269744873
Validation loss: 1.850369535466676

Epoch: 6| Step: 11
Training loss: 0.3214166760444641
Validation loss: 1.8440201718320128

Epoch: 6| Step: 12
Training loss: 0.44751131534576416
Validation loss: 1.8583140014320292

Epoch: 6| Step: 13
Training loss: 0.2530844509601593
Validation loss: 1.8157303538373721

Epoch: 284| Step: 0
Training loss: 0.49357905983924866
Validation loss: 1.7793628118371452

Epoch: 6| Step: 1
Training loss: 0.22175848484039307
Validation loss: 1.8002620204802482

Epoch: 6| Step: 2
Training loss: 0.34867143630981445
Validation loss: 1.8003906767855409

Epoch: 6| Step: 3
Training loss: 0.6100373864173889
Validation loss: 1.773946149374849

Epoch: 6| Step: 4
Training loss: 0.474941611289978
Validation loss: 1.769867129223321

Epoch: 6| Step: 5
Training loss: 0.4482925534248352
Validation loss: 1.7337527980086624

Epoch: 6| Step: 6
Training loss: 0.4551677703857422
Validation loss: 1.735359102167109

Epoch: 6| Step: 7
Training loss: 0.5887298583984375
Validation loss: 1.7628996269677275

Epoch: 6| Step: 8
Training loss: 0.7679005861282349
Validation loss: 1.761615642937281

Epoch: 6| Step: 9
Training loss: 0.42006656527519226
Validation loss: 1.7690360917839953

Epoch: 6| Step: 10
Training loss: 0.5833832025527954
Validation loss: 1.7472615677823302

Epoch: 6| Step: 11
Training loss: 0.76851487159729
Validation loss: 1.7225811212293562

Epoch: 6| Step: 12
Training loss: 0.4894210994243622
Validation loss: 1.751387603821293

Epoch: 6| Step: 13
Training loss: 0.3180249035358429
Validation loss: 1.8198921449722782

Epoch: 285| Step: 0
Training loss: 0.5771589279174805
Validation loss: 1.8310635807693645

Epoch: 6| Step: 1
Training loss: 0.5216322541236877
Validation loss: 1.8557563956065843

Epoch: 6| Step: 2
Training loss: 0.6986669898033142
Validation loss: 1.8395790412861814

Epoch: 6| Step: 3
Training loss: 0.44038572907447815
Validation loss: 1.8633162180582683

Epoch: 6| Step: 4
Training loss: 0.6374408006668091
Validation loss: 1.898053002613847

Epoch: 6| Step: 5
Training loss: 0.49928057193756104
Validation loss: 1.8880623873843942

Epoch: 6| Step: 6
Training loss: 0.3679826855659485
Validation loss: 1.8412243576459988

Epoch: 6| Step: 7
Training loss: 0.5276429653167725
Validation loss: 1.8496969323004446

Epoch: 6| Step: 8
Training loss: 0.24119099974632263
Validation loss: 1.7998184542502127

Epoch: 6| Step: 9
Training loss: 0.6616325378417969
Validation loss: 1.7920530585832493

Epoch: 6| Step: 10
Training loss: 0.19394637644290924
Validation loss: 1.7875721787893644

Epoch: 6| Step: 11
Training loss: 0.4281156361103058
Validation loss: 1.7954846800014537

Epoch: 6| Step: 12
Training loss: 0.5934205055236816
Validation loss: 1.766411958202239

Epoch: 6| Step: 13
Training loss: 0.4993739724159241
Validation loss: 1.7403062005196848

Epoch: 286| Step: 0
Training loss: 0.43669676780700684
Validation loss: 1.7148717449557396

Epoch: 6| Step: 1
Training loss: 0.6078838109970093
Validation loss: 1.7210870276215255

Epoch: 6| Step: 2
Training loss: 0.4484859108924866
Validation loss: 1.769699788862659

Epoch: 6| Step: 3
Training loss: 0.31210970878601074
Validation loss: 1.8067165497810609

Epoch: 6| Step: 4
Training loss: 0.46203723549842834
Validation loss: 1.8318363722934519

Epoch: 6| Step: 5
Training loss: 0.4746895432472229
Validation loss: 1.8125982540909962

Epoch: 6| Step: 6
Training loss: 0.6668714284896851
Validation loss: 1.8567339271627448

Epoch: 6| Step: 7
Training loss: 0.40658271312713623
Validation loss: 1.8500645314493487

Epoch: 6| Step: 8
Training loss: 0.32216310501098633
Validation loss: 1.8548732701168265

Epoch: 6| Step: 9
Training loss: 0.32103821635246277
Validation loss: 1.8526220206291444

Epoch: 6| Step: 10
Training loss: 0.5421329140663147
Validation loss: 1.8684879451669671

Epoch: 6| Step: 11
Training loss: 0.4383251368999481
Validation loss: 1.8597605959061654

Epoch: 6| Step: 12
Training loss: 0.6135626435279846
Validation loss: 1.8483004191870331

Epoch: 6| Step: 13
Training loss: 0.571279764175415
Validation loss: 1.8496462119522916

Epoch: 287| Step: 0
Training loss: 0.28500789403915405
Validation loss: 1.8516606310362458

Epoch: 6| Step: 1
Training loss: 0.6570245027542114
Validation loss: 1.8367281139537852

Epoch: 6| Step: 2
Training loss: 0.4780464172363281
Validation loss: 1.8577901855591805

Epoch: 6| Step: 3
Training loss: 0.3358156681060791
Validation loss: 1.8453798063339726

Epoch: 6| Step: 4
Training loss: 0.44570016860961914
Validation loss: 1.853781730897965

Epoch: 6| Step: 5
Training loss: 0.32751911878585815
Validation loss: 1.8194108381066272

Epoch: 6| Step: 6
Training loss: 0.26748886704444885
Validation loss: 1.8231754059432654

Epoch: 6| Step: 7
Training loss: 0.4906148314476013
Validation loss: 1.8190941220970565

Epoch: 6| Step: 8
Training loss: 0.4626936912536621
Validation loss: 1.8199325325668498

Epoch: 6| Step: 9
Training loss: 0.5532824397087097
Validation loss: 1.848933789037889

Epoch: 6| Step: 10
Training loss: 0.3640480041503906
Validation loss: 1.8232722295227872

Epoch: 6| Step: 11
Training loss: 0.5778617858886719
Validation loss: 1.8195215809729792

Epoch: 6| Step: 12
Training loss: 0.8952170610427856
Validation loss: 1.8365913975623347

Epoch: 6| Step: 13
Training loss: 0.48711860179901123
Validation loss: 1.8069760748135146

Epoch: 288| Step: 0
Training loss: 0.7002698183059692
Validation loss: 1.811617748711699

Epoch: 6| Step: 1
Training loss: 0.47236162424087524
Validation loss: 1.8106140757119784

Epoch: 6| Step: 2
Training loss: 0.31288161873817444
Validation loss: 1.8738597695545485

Epoch: 6| Step: 3
Training loss: 0.34686413407325745
Validation loss: 1.8739317053107805

Epoch: 6| Step: 4
Training loss: 0.6156046390533447
Validation loss: 1.900554305763655

Epoch: 6| Step: 5
Training loss: 0.5722000002861023
Validation loss: 1.952868987155217

Epoch: 6| Step: 6
Training loss: 0.5779610276222229
Validation loss: 1.983311330118487

Epoch: 6| Step: 7
Training loss: 0.5881602764129639
Validation loss: 1.9848394663103166

Epoch: 6| Step: 8
Training loss: 0.6084089279174805
Validation loss: 1.973049186891125

Epoch: 6| Step: 9
Training loss: 0.43683767318725586
Validation loss: 1.8964027794458533

Epoch: 6| Step: 10
Training loss: 0.3178040385246277
Validation loss: 1.8756548204729635

Epoch: 6| Step: 11
Training loss: 0.28972333669662476
Validation loss: 1.8909871296216083

Epoch: 6| Step: 12
Training loss: 0.30420511960983276
Validation loss: 1.881621829925045

Epoch: 6| Step: 13
Training loss: 0.550094723701477
Validation loss: 1.8732052528730003

Epoch: 289| Step: 0
Training loss: 0.47399789094924927
Validation loss: 1.8684382791160254

Epoch: 6| Step: 1
Training loss: 0.2681068778038025
Validation loss: 1.864036959986533

Epoch: 6| Step: 2
Training loss: 0.7312361001968384
Validation loss: 1.8432001670201619

Epoch: 6| Step: 3
Training loss: 0.42995598912239075
Validation loss: 1.8396710708577146

Epoch: 6| Step: 4
Training loss: 0.6496180295944214
Validation loss: 1.8222895822217386

Epoch: 6| Step: 5
Training loss: 0.4612268805503845
Validation loss: 1.8181450482337707

Epoch: 6| Step: 6
Training loss: 0.39984220266342163
Validation loss: 1.8372478882471721

Epoch: 6| Step: 7
Training loss: 0.41273120045661926
Validation loss: 1.8332527273444719

Epoch: 6| Step: 8
Training loss: 0.5666690468788147
Validation loss: 1.8315605194337907

Epoch: 6| Step: 9
Training loss: 0.42701566219329834
Validation loss: 1.846946471480913

Epoch: 6| Step: 10
Training loss: 0.3678246736526489
Validation loss: 1.865704600529004

Epoch: 6| Step: 11
Training loss: 0.4173295497894287
Validation loss: 1.8270287013822986

Epoch: 6| Step: 12
Training loss: 0.3452627658843994
Validation loss: 1.8606332002147552

Epoch: 6| Step: 13
Training loss: 0.9628628492355347
Validation loss: 1.8738851162695116

Epoch: 290| Step: 0
Training loss: 0.3492737412452698
Validation loss: 1.8427484150855773

Epoch: 6| Step: 1
Training loss: 0.5262939929962158
Validation loss: 1.8335495341208674

Epoch: 6| Step: 2
Training loss: 0.41336914896965027
Validation loss: 1.8043526808420818

Epoch: 6| Step: 3
Training loss: 0.4031471014022827
Validation loss: 1.7546256139714231

Epoch: 6| Step: 4
Training loss: 0.26344186067581177
Validation loss: 1.812333829941288

Epoch: 6| Step: 5
Training loss: 0.45767638087272644
Validation loss: 1.791004079644398

Epoch: 6| Step: 6
Training loss: 0.4557800590991974
Validation loss: 1.7848003192614483

Epoch: 6| Step: 7
Training loss: 0.5892889499664307
Validation loss: 1.8218097225312264

Epoch: 6| Step: 8
Training loss: 0.7998090386390686
Validation loss: 1.8368819426464778

Epoch: 6| Step: 9
Training loss: 0.6750519275665283
Validation loss: 1.8293037760642268

Epoch: 6| Step: 10
Training loss: 0.3557943105697632
Validation loss: 1.8734685067207582

Epoch: 6| Step: 11
Training loss: 0.34022027254104614
Validation loss: 1.8775504532680716

Epoch: 6| Step: 12
Training loss: 0.22958141565322876
Validation loss: 1.8510799638686641

Epoch: 6| Step: 13
Training loss: 0.4117884635925293
Validation loss: 1.8556468230421825

Epoch: 291| Step: 0
Training loss: 0.6463537216186523
Validation loss: 1.878639631373908

Epoch: 6| Step: 1
Training loss: 0.30167245864868164
Validation loss: 1.8342686673646331

Epoch: 6| Step: 2
Training loss: 0.5018312931060791
Validation loss: 1.8497703075408936

Epoch: 6| Step: 3
Training loss: 0.6210916042327881
Validation loss: 1.8516338409916047

Epoch: 6| Step: 4
Training loss: 0.7412772178649902
Validation loss: 1.839495703738223

Epoch: 6| Step: 5
Training loss: 0.2703014016151428
Validation loss: 1.8405622641245525

Epoch: 6| Step: 6
Training loss: 0.7807053327560425
Validation loss: 1.8722537422692904

Epoch: 6| Step: 7
Training loss: 0.6061885356903076
Validation loss: 1.8838594113626788

Epoch: 6| Step: 8
Training loss: 0.43537837266921997
Validation loss: 1.882209280485748

Epoch: 6| Step: 9
Training loss: 0.43509092926979065
Validation loss: 1.8642459133619904

Epoch: 6| Step: 10
Training loss: 0.2594444155693054
Validation loss: 1.8903997559701242

Epoch: 6| Step: 11
Training loss: 0.5233259797096252
Validation loss: 1.8879478029025498

Epoch: 6| Step: 12
Training loss: 0.4565184712409973
Validation loss: 1.9014218520092707

Epoch: 6| Step: 13
Training loss: 0.339566707611084
Validation loss: 1.8635511295769804

Epoch: 292| Step: 0
Training loss: 0.372622013092041
Validation loss: 1.8732575793420114

Epoch: 6| Step: 1
Training loss: 0.5464689135551453
Validation loss: 1.8413740396499634

Epoch: 6| Step: 2
Training loss: 0.6983988881111145
Validation loss: 1.8399698119009695

Epoch: 6| Step: 3
Training loss: 0.40609264373779297
Validation loss: 1.8183205935262865

Epoch: 6| Step: 4
Training loss: 0.48190760612487793
Validation loss: 1.767730091207771

Epoch: 6| Step: 5
Training loss: 0.6594181060791016
Validation loss: 1.737643995592671

Epoch: 6| Step: 6
Training loss: 0.5396345257759094
Validation loss: 1.7591577332506898

Epoch: 6| Step: 7
Training loss: 0.4696830213069916
Validation loss: 1.776302577346884

Epoch: 6| Step: 8
Training loss: 0.6664148569107056
Validation loss: 1.763123612250051

Epoch: 6| Step: 9
Training loss: 0.5145177841186523
Validation loss: 1.7921814175062283

Epoch: 6| Step: 10
Training loss: 0.3454641103744507
Validation loss: 1.835012646131618

Epoch: 6| Step: 11
Training loss: 0.5967563390731812
Validation loss: 1.8290532558195052

Epoch: 6| Step: 12
Training loss: 0.46685075759887695
Validation loss: 1.8077121729491858

Epoch: 6| Step: 13
Training loss: 0.7613397240638733
Validation loss: 1.8065741587710638

Epoch: 293| Step: 0
Training loss: 0.5016605854034424
Validation loss: 1.8044840494791667

Epoch: 6| Step: 1
Training loss: 0.45843347907066345
Validation loss: 1.817246331963488

Epoch: 6| Step: 2
Training loss: 0.5914531946182251
Validation loss: 1.8688600832416165

Epoch: 6| Step: 3
Training loss: 0.22017717361450195
Validation loss: 1.9166093898075882

Epoch: 6| Step: 4
Training loss: 0.3236082196235657
Validation loss: 1.9775324765072073

Epoch: 6| Step: 5
Training loss: 0.6614865660667419
Validation loss: 1.938444519555697

Epoch: 6| Step: 6
Training loss: 0.31625670194625854
Validation loss: 1.9271912087676346

Epoch: 6| Step: 7
Training loss: 0.6683948040008545
Validation loss: 1.882141408099923

Epoch: 6| Step: 8
Training loss: 0.43847987055778503
Validation loss: 1.8570734557285105

Epoch: 6| Step: 9
Training loss: 0.30351436138153076
Validation loss: 1.8283961575518373

Epoch: 6| Step: 10
Training loss: 0.6783256530761719
Validation loss: 1.7940043031528432

Epoch: 6| Step: 11
Training loss: 0.7370088696479797
Validation loss: 1.7579850407056912

Epoch: 6| Step: 12
Training loss: 0.4177071452140808
Validation loss: 1.7886508305867512

Epoch: 6| Step: 13
Training loss: 0.5068054795265198
Validation loss: 1.813360115533234

Epoch: 294| Step: 0
Training loss: 0.18034040927886963
Validation loss: 1.7863797859479023

Epoch: 6| Step: 1
Training loss: 0.6380876302719116
Validation loss: 1.8239417986203266

Epoch: 6| Step: 2
Training loss: 0.48089906573295593
Validation loss: 1.8449041869050713

Epoch: 6| Step: 3
Training loss: 0.6268543004989624
Validation loss: 1.881885575991805

Epoch: 6| Step: 4
Training loss: 0.48266705870628357
Validation loss: 1.8991758079938992

Epoch: 6| Step: 5
Training loss: 0.4338397979736328
Validation loss: 1.9482832980412308

Epoch: 6| Step: 6
Training loss: 0.532340407371521
Validation loss: 1.9339123015762658

Epoch: 6| Step: 7
Training loss: 0.6160956621170044
Validation loss: 1.9467443637950446

Epoch: 6| Step: 8
Training loss: 0.2527896761894226
Validation loss: 1.9113866770139305

Epoch: 6| Step: 9
Training loss: 0.4601309597492218
Validation loss: 1.860383302934708

Epoch: 6| Step: 10
Training loss: 0.45201051235198975
Validation loss: 1.8858149641303605

Epoch: 6| Step: 11
Training loss: 0.5257360935211182
Validation loss: 1.834368968522677

Epoch: 6| Step: 12
Training loss: 0.4670048654079437
Validation loss: 1.8358622110018166

Epoch: 6| Step: 13
Training loss: 0.47874170541763306
Validation loss: 1.8122160409086494

Epoch: 295| Step: 0
Training loss: 0.4903741478919983
Validation loss: 1.8181271219766268

Epoch: 6| Step: 1
Training loss: 0.6876192092895508
Validation loss: 1.8225446388285647

Epoch: 6| Step: 2
Training loss: 0.376997172832489
Validation loss: 1.8234574948587725

Epoch: 6| Step: 3
Training loss: 0.39496177434921265
Validation loss: 1.8473789691925049

Epoch: 6| Step: 4
Training loss: 0.3108574151992798
Validation loss: 1.844338373471332

Epoch: 6| Step: 5
Training loss: 0.40190911293029785
Validation loss: 1.850326766249954

Epoch: 6| Step: 6
Training loss: 0.29304996132850647
Validation loss: 1.865530889521363

Epoch: 6| Step: 7
Training loss: 0.5738893747329712
Validation loss: 1.8640224882351455

Epoch: 6| Step: 8
Training loss: 0.6545530557632446
Validation loss: 1.8994047975027433

Epoch: 6| Step: 9
Training loss: 0.0977112203836441
Validation loss: 1.8885353329361125

Epoch: 6| Step: 10
Training loss: 0.6718099117279053
Validation loss: 1.9243264941759006

Epoch: 6| Step: 11
Training loss: 0.4401794373989105
Validation loss: 1.9350693302769815

Epoch: 6| Step: 12
Training loss: 0.42099106311798096
Validation loss: 1.9585021747055875

Epoch: 6| Step: 13
Training loss: 0.5611793994903564
Validation loss: 1.9352392047964118

Epoch: 296| Step: 0
Training loss: 0.5094180703163147
Validation loss: 1.9374378496600735

Epoch: 6| Step: 1
Training loss: 0.37492626905441284
Validation loss: 1.8800677766082108

Epoch: 6| Step: 2
Training loss: 0.38616567850112915
Validation loss: 1.8608062190394248

Epoch: 6| Step: 3
Training loss: 0.6832221746444702
Validation loss: 1.8386646560443345

Epoch: 6| Step: 4
Training loss: 0.5602558851242065
Validation loss: 1.8167877145992812

Epoch: 6| Step: 5
Training loss: 0.38117945194244385
Validation loss: 1.8601875484630626

Epoch: 6| Step: 6
Training loss: 0.5133745670318604
Validation loss: 1.8435638694353

Epoch: 6| Step: 7
Training loss: 0.2574326694011688
Validation loss: 1.831436554590861

Epoch: 6| Step: 8
Training loss: 0.593679666519165
Validation loss: 1.8386704896086006

Epoch: 6| Step: 9
Training loss: 0.22559300065040588
Validation loss: 1.8316836152025449

Epoch: 6| Step: 10
Training loss: 0.42689967155456543
Validation loss: 1.8505959626167052

Epoch: 6| Step: 11
Training loss: 0.3034132122993469
Validation loss: 1.8129820721123808

Epoch: 6| Step: 12
Training loss: 0.5205422639846802
Validation loss: 1.8739358443085865

Epoch: 6| Step: 13
Training loss: 0.5273312330245972
Validation loss: 1.9008901708869523

Epoch: 297| Step: 0
Training loss: 0.38477879762649536
Validation loss: 1.8868597656167962

Epoch: 6| Step: 1
Training loss: 0.384742796421051
Validation loss: 1.8393057469398744

Epoch: 6| Step: 2
Training loss: 0.46574801206588745
Validation loss: 1.833125255441153

Epoch: 6| Step: 3
Training loss: 0.6821649074554443
Validation loss: 1.8005921045939128

Epoch: 6| Step: 4
Training loss: 0.44046199321746826
Validation loss: 1.7841611639145882

Epoch: 6| Step: 5
Training loss: 0.4558262825012207
Validation loss: 1.8030050211055304

Epoch: 6| Step: 6
Training loss: 0.2842302918434143
Validation loss: 1.7514198005840342

Epoch: 6| Step: 7
Training loss: 0.4090465307235718
Validation loss: 1.781211583845077

Epoch: 6| Step: 8
Training loss: 0.3047720789909363
Validation loss: 1.781240258165585

Epoch: 6| Step: 9
Training loss: 0.35367995500564575
Validation loss: 1.805657479070848

Epoch: 6| Step: 10
Training loss: 0.38942041993141174
Validation loss: 1.82114956584028

Epoch: 6| Step: 11
Training loss: 0.6239556074142456
Validation loss: 1.8132668669505785

Epoch: 6| Step: 12
Training loss: 0.6417363286018372
Validation loss: 1.854932230005982

Epoch: 6| Step: 13
Training loss: 0.4994901418685913
Validation loss: 1.824361660147226

Epoch: 298| Step: 0
Training loss: 0.41406095027923584
Validation loss: 1.8374804360892183

Epoch: 6| Step: 1
Training loss: 0.5989622473716736
Validation loss: 1.838565029123778

Epoch: 6| Step: 2
Training loss: 0.44223955273628235
Validation loss: 1.8581125095326414

Epoch: 6| Step: 3
Training loss: 0.2564149498939514
Validation loss: 1.8492283539105487

Epoch: 6| Step: 4
Training loss: 0.5414307117462158
Validation loss: 1.8647994392661638

Epoch: 6| Step: 5
Training loss: 0.42229852080345154
Validation loss: 1.8326779245048441

Epoch: 6| Step: 6
Training loss: 0.4097190499305725
Validation loss: 1.8117010747232745

Epoch: 6| Step: 7
Training loss: 0.41139131784439087
Validation loss: 1.8416153929566825

Epoch: 6| Step: 8
Training loss: 0.45078933238983154
Validation loss: 1.8111562690427225

Epoch: 6| Step: 9
Training loss: 0.3579643666744232
Validation loss: 1.8218324043417489

Epoch: 6| Step: 10
Training loss: 0.5250388383865356
Validation loss: 1.8327218178779847

Epoch: 6| Step: 11
Training loss: 0.49099594354629517
Validation loss: 1.8031813201083933

Epoch: 6| Step: 12
Training loss: 0.5659430623054504
Validation loss: 1.8390318514198385

Epoch: 6| Step: 13
Training loss: 0.17566436529159546
Validation loss: 1.8384808173743628

Epoch: 299| Step: 0
Training loss: 0.4878009259700775
Validation loss: 1.851691363960184

Epoch: 6| Step: 1
Training loss: 0.32379448413848877
Validation loss: 1.865755788100663

Epoch: 6| Step: 2
Training loss: 0.4700874388217926
Validation loss: 1.8718090339373517

Epoch: 6| Step: 3
Training loss: 0.4267023801803589
Validation loss: 1.8417342324410715

Epoch: 6| Step: 4
Training loss: 0.6113737225532532
Validation loss: 1.8632411751695859

Epoch: 6| Step: 5
Training loss: 0.4302339553833008
Validation loss: 1.8898455686466669

Epoch: 6| Step: 6
Training loss: 0.41587817668914795
Validation loss: 1.9303319364465692

Epoch: 6| Step: 7
Training loss: 0.5020895004272461
Validation loss: 1.9038300232220722

Epoch: 6| Step: 8
Training loss: 0.41201505064964294
Validation loss: 1.8634717772083897

Epoch: 6| Step: 9
Training loss: 0.44301873445510864
Validation loss: 1.8921439660492765

Epoch: 6| Step: 10
Training loss: 0.3063631057739258
Validation loss: 1.8908839097587011

Epoch: 6| Step: 11
Training loss: 0.3562658727169037
Validation loss: 1.8903376492120887

Epoch: 6| Step: 12
Training loss: 0.32417386770248413
Validation loss: 1.88973791240364

Epoch: 6| Step: 13
Training loss: 0.43536174297332764
Validation loss: 1.899276037370005

Epoch: 300| Step: 0
Training loss: 0.5974457263946533
Validation loss: 1.8483494071550266

Epoch: 6| Step: 1
Training loss: 0.3931155800819397
Validation loss: 1.8198370215713338

Epoch: 6| Step: 2
Training loss: 0.40951573848724365
Validation loss: 1.8567008715803905

Epoch: 6| Step: 3
Training loss: 0.47095638513565063
Validation loss: 1.8315660453611804

Epoch: 6| Step: 4
Training loss: 0.6460061073303223
Validation loss: 1.8066943371167747

Epoch: 6| Step: 5
Training loss: 0.21538618206977844
Validation loss: 1.8279574340389622

Epoch: 6| Step: 6
Training loss: 0.44183439016342163
Validation loss: 1.8075489074953142

Epoch: 6| Step: 7
Training loss: 0.12821684777736664
Validation loss: 1.8143698688476317

Epoch: 6| Step: 8
Training loss: 0.2951752543449402
Validation loss: 1.7817391836515037

Epoch: 6| Step: 9
Training loss: 0.24215692281723022
Validation loss: 1.7744755116842126

Epoch: 6| Step: 10
Training loss: 0.6019229888916016
Validation loss: 1.7934431440086775

Epoch: 6| Step: 11
Training loss: 0.4495643079280853
Validation loss: 1.8007677011592413

Epoch: 6| Step: 12
Training loss: 0.40382468700408936
Validation loss: 1.8028001240504685

Epoch: 6| Step: 13
Training loss: 0.49040815234184265
Validation loss: 1.8461348292648152

Epoch: 301| Step: 0
Training loss: 0.3887515664100647
Validation loss: 1.867219071234426

Epoch: 6| Step: 1
Training loss: 0.2803693115711212
Validation loss: 1.8242269382681897

Epoch: 6| Step: 2
Training loss: 0.44240492582321167
Validation loss: 1.8697886877162482

Epoch: 6| Step: 3
Training loss: 0.3263803720474243
Validation loss: 1.8897402837712278

Epoch: 6| Step: 4
Training loss: 0.4936066269874573
Validation loss: 1.8716590801874797

Epoch: 6| Step: 5
Training loss: 0.46587809920310974
Validation loss: 1.8625070971827353

Epoch: 6| Step: 6
Training loss: 0.7915797233581543
Validation loss: 1.890571814711376

Epoch: 6| Step: 7
Training loss: 0.3495998978614807
Validation loss: 1.8797309321741904

Epoch: 6| Step: 8
Training loss: 0.379923939704895
Validation loss: 1.8548288345336914

Epoch: 6| Step: 9
Training loss: 0.22245433926582336
Validation loss: 1.8646951183196037

Epoch: 6| Step: 10
Training loss: 0.3134865164756775
Validation loss: 1.8474261517165809

Epoch: 6| Step: 11
Training loss: 0.4147641658782959
Validation loss: 1.8292830887661184

Epoch: 6| Step: 12
Training loss: 0.5247548818588257
Validation loss: 1.7821447067363287

Epoch: 6| Step: 13
Training loss: 0.6378813982009888
Validation loss: 1.7819842779508202

Epoch: 302| Step: 0
Training loss: 0.6814574003219604
Validation loss: 1.7189133795358802

Epoch: 6| Step: 1
Training loss: 0.44511517882347107
Validation loss: 1.7387515985837547

Epoch: 6| Step: 2
Training loss: 0.4430520832538605
Validation loss: 1.7610053798203826

Epoch: 6| Step: 3
Training loss: 0.2523331642150879
Validation loss: 1.7661878165378366

Epoch: 6| Step: 4
Training loss: 0.25984901189804077
Validation loss: 1.7476773005659862

Epoch: 6| Step: 5
Training loss: 0.3998273015022278
Validation loss: 1.7814949020262687

Epoch: 6| Step: 6
Training loss: 0.17813605070114136
Validation loss: 1.792508316296403

Epoch: 6| Step: 7
Training loss: 0.5660597681999207
Validation loss: 1.781604113117341

Epoch: 6| Step: 8
Training loss: 0.7135862708091736
Validation loss: 1.7777754158102057

Epoch: 6| Step: 9
Training loss: 0.558273434638977
Validation loss: 1.7612064653827297

Epoch: 6| Step: 10
Training loss: 0.33931970596313477
Validation loss: 1.7871407488340973

Epoch: 6| Step: 11
Training loss: 0.39809656143188477
Validation loss: 1.7782558125834311

Epoch: 6| Step: 12
Training loss: 0.4792608618736267
Validation loss: 1.810068288157063

Epoch: 6| Step: 13
Training loss: 0.2345844954252243
Validation loss: 1.8006025104112522

Epoch: 303| Step: 0
Training loss: 0.42973604798316956
Validation loss: 1.808854236397692

Epoch: 6| Step: 1
Training loss: 0.2693118155002594
Validation loss: 1.8210235872576315

Epoch: 6| Step: 2
Training loss: 0.2704665958881378
Validation loss: 1.8105644667020409

Epoch: 6| Step: 3
Training loss: 0.4316040873527527
Validation loss: 1.8116257318886377

Epoch: 6| Step: 4
Training loss: 0.25697261095046997
Validation loss: 1.817309739769146

Epoch: 6| Step: 5
Training loss: 0.5300570130348206
Validation loss: 1.8422739755722783

Epoch: 6| Step: 6
Training loss: 0.6790810227394104
Validation loss: 1.8072004087509648

Epoch: 6| Step: 7
Training loss: 0.5250250697135925
Validation loss: 1.8267793193940194

Epoch: 6| Step: 8
Training loss: 0.29567989706993103
Validation loss: 1.876190867475284

Epoch: 6| Step: 9
Training loss: 0.493386447429657
Validation loss: 1.834605404125747

Epoch: 6| Step: 10
Training loss: 0.2261296808719635
Validation loss: 1.8698190809578024

Epoch: 6| Step: 11
Training loss: 0.5165858268737793
Validation loss: 1.8594831651256931

Epoch: 6| Step: 12
Training loss: 0.3553619980812073
Validation loss: 1.8434235395923737

Epoch: 6| Step: 13
Training loss: 0.4385443925857544
Validation loss: 1.85260401105368

Epoch: 304| Step: 0
Training loss: 0.4723352789878845
Validation loss: 1.8470782644005233

Epoch: 6| Step: 1
Training loss: 0.5547734498977661
Validation loss: 1.8187181167705084

Epoch: 6| Step: 2
Training loss: 0.24931985139846802
Validation loss: 1.8414544187566286

Epoch: 6| Step: 3
Training loss: 0.4487108588218689
Validation loss: 1.8064633697591803

Epoch: 6| Step: 4
Training loss: 0.5190777778625488
Validation loss: 1.7907568254778463

Epoch: 6| Step: 5
Training loss: 0.4270426630973816
Validation loss: 1.836948779321486

Epoch: 6| Step: 6
Training loss: 0.5052157640457153
Validation loss: 1.829433633435157

Epoch: 6| Step: 7
Training loss: 0.3249419927597046
Validation loss: 1.8226112031167554

Epoch: 6| Step: 8
Training loss: 0.4136715531349182
Validation loss: 1.799488490627658

Epoch: 6| Step: 9
Training loss: 0.34357568621635437
Validation loss: 1.8237726534566572

Epoch: 6| Step: 10
Training loss: 0.15629523992538452
Validation loss: 1.8290864075383833

Epoch: 6| Step: 11
Training loss: 0.2863961160182953
Validation loss: 1.7759560564512848

Epoch: 6| Step: 12
Training loss: 0.6121662259101868
Validation loss: 1.7531472688080163

Epoch: 6| Step: 13
Training loss: 0.27360212802886963
Validation loss: 1.7571911773374003

Epoch: 305| Step: 0
Training loss: 0.3509657382965088
Validation loss: 1.7698059543486564

Epoch: 6| Step: 1
Training loss: 0.44801098108291626
Validation loss: 1.7725531734446043

Epoch: 6| Step: 2
Training loss: 0.4779545068740845
Validation loss: 1.7887005382968533

Epoch: 6| Step: 3
Training loss: 0.40137574076652527
Validation loss: 1.7710057112478441

Epoch: 6| Step: 4
Training loss: 0.43164485692977905
Validation loss: 1.7719541416373303

Epoch: 6| Step: 5
Training loss: 0.4441015124320984
Validation loss: 1.7648481662555406

Epoch: 6| Step: 6
Training loss: 0.47206026315689087
Validation loss: 1.7954401175181072

Epoch: 6| Step: 7
Training loss: 0.5295743346214294
Validation loss: 1.7477624877806632

Epoch: 6| Step: 8
Training loss: 0.3908405900001526
Validation loss: 1.7620030513373754

Epoch: 6| Step: 9
Training loss: 0.28268057107925415
Validation loss: 1.7672055921246927

Epoch: 6| Step: 10
Training loss: 0.3859408497810364
Validation loss: 1.7924468466030654

Epoch: 6| Step: 11
Training loss: 0.27900996804237366
Validation loss: 1.7805359389192315

Epoch: 6| Step: 12
Training loss: 0.35766345262527466
Validation loss: 1.8207309271699639

Epoch: 6| Step: 13
Training loss: 0.6348341703414917
Validation loss: 1.8086846233696066

Epoch: 306| Step: 0
Training loss: 0.17696526646614075
Validation loss: 1.7723032966736825

Epoch: 6| Step: 1
Training loss: 0.37852656841278076
Validation loss: 1.786531622691821

Epoch: 6| Step: 2
Training loss: 0.26034632325172424
Validation loss: 1.7976956444401895

Epoch: 6| Step: 3
Training loss: 0.38163864612579346
Validation loss: 1.7633760757343744

Epoch: 6| Step: 4
Training loss: 0.49840423464775085
Validation loss: 1.7851269181056688

Epoch: 6| Step: 5
Training loss: 0.29485076665878296
Validation loss: 1.7808689430195799

Epoch: 6| Step: 6
Training loss: 0.508811354637146
Validation loss: 1.7981277524784047

Epoch: 6| Step: 7
Training loss: 0.535190761089325
Validation loss: 1.8271668027806025

Epoch: 6| Step: 8
Training loss: 0.4556913673877716
Validation loss: 1.7968515772973337

Epoch: 6| Step: 9
Training loss: 0.40920260548591614
Validation loss: 1.8542738345361525

Epoch: 6| Step: 10
Training loss: 0.2934761941432953
Validation loss: 1.8574628496682772

Epoch: 6| Step: 11
Training loss: 0.4139089584350586
Validation loss: 1.8511450944408294

Epoch: 6| Step: 12
Training loss: 0.37287473678588867
Validation loss: 1.8741694791342622

Epoch: 6| Step: 13
Training loss: 0.49412664771080017
Validation loss: 1.8366843949082077

Epoch: 307| Step: 0
Training loss: 0.2653082609176636
Validation loss: 1.868933077781431

Epoch: 6| Step: 1
Training loss: 0.39280256628990173
Validation loss: 1.8619171393814908

Epoch: 6| Step: 2
Training loss: 0.3126818835735321
Validation loss: 1.8331329386721376

Epoch: 6| Step: 3
Training loss: 0.28644612431526184
Validation loss: 1.8394265764503068

Epoch: 6| Step: 4
Training loss: 0.6268868446350098
Validation loss: 1.7930157735783567

Epoch: 6| Step: 5
Training loss: 0.2938236892223358
Validation loss: 1.7837503904937415

Epoch: 6| Step: 6
Training loss: 0.5831204652786255
Validation loss: 1.785506304874215

Epoch: 6| Step: 7
Training loss: 0.3253777325153351
Validation loss: 1.7824970163324827

Epoch: 6| Step: 8
Training loss: 0.32127633690834045
Validation loss: 1.7786547394209011

Epoch: 6| Step: 9
Training loss: 0.3920097351074219
Validation loss: 1.7778007817524735

Epoch: 6| Step: 10
Training loss: 0.5347325205802917
Validation loss: 1.7787765931057673

Epoch: 6| Step: 11
Training loss: 0.422247976064682
Validation loss: 1.7808098331574471

Epoch: 6| Step: 12
Training loss: 0.28505927324295044
Validation loss: 1.7956335890677668

Epoch: 6| Step: 13
Training loss: 0.5775802731513977
Validation loss: 1.826609629456715

Epoch: 308| Step: 0
Training loss: 0.21803367137908936
Validation loss: 1.822770501977654

Epoch: 6| Step: 1
Training loss: 0.47486621141433716
Validation loss: 1.8328775744284354

Epoch: 6| Step: 2
Training loss: 0.17623718082904816
Validation loss: 1.7914008273873279

Epoch: 6| Step: 3
Training loss: 0.35136842727661133
Validation loss: 1.7830849091211955

Epoch: 6| Step: 4
Training loss: 0.3959217071533203
Validation loss: 1.7570172176566174

Epoch: 6| Step: 5
Training loss: 0.407937616109848
Validation loss: 1.7813209692637126

Epoch: 6| Step: 6
Training loss: 0.2716010808944702
Validation loss: 1.772231468590357

Epoch: 6| Step: 7
Training loss: 0.500537633895874
Validation loss: 1.747388833312578

Epoch: 6| Step: 8
Training loss: 0.34987953305244446
Validation loss: 1.7593126668724963

Epoch: 6| Step: 9
Training loss: 0.4748814105987549
Validation loss: 1.8088524149310203

Epoch: 6| Step: 10
Training loss: 0.4902558922767639
Validation loss: 1.8224760678506666

Epoch: 6| Step: 11
Training loss: 0.4440232515335083
Validation loss: 1.840980605412555

Epoch: 6| Step: 12
Training loss: 0.40376943349838257
Validation loss: 1.825950321330819

Epoch: 6| Step: 13
Training loss: 0.5946077704429626
Validation loss: 1.832144078388009

Epoch: 309| Step: 0
Training loss: 0.3160412311553955
Validation loss: 1.8183921332000403

Epoch: 6| Step: 1
Training loss: 0.20893070101737976
Validation loss: 1.878892901123211

Epoch: 6| Step: 2
Training loss: 0.6515531539916992
Validation loss: 1.8520596693920832

Epoch: 6| Step: 3
Training loss: 0.38636183738708496
Validation loss: 1.8215511973186205

Epoch: 6| Step: 4
Training loss: 0.2218865156173706
Validation loss: 1.84980789051261

Epoch: 6| Step: 5
Training loss: 0.39739862084388733
Validation loss: 1.7964756104253954

Epoch: 6| Step: 6
Training loss: 0.21268051862716675
Validation loss: 1.7938069758876678

Epoch: 6| Step: 7
Training loss: 0.2778394818305969
Validation loss: 1.762634959272159

Epoch: 6| Step: 8
Training loss: 0.3538541793823242
Validation loss: 1.7877362440991145

Epoch: 6| Step: 9
Training loss: 0.5693598985671997
Validation loss: 1.7792889533504364

Epoch: 6| Step: 10
Training loss: 0.34807339310646057
Validation loss: 1.7893224967423307

Epoch: 6| Step: 11
Training loss: 0.318665087223053
Validation loss: 1.7856234555603356

Epoch: 6| Step: 12
Training loss: 0.5265755653381348
Validation loss: 1.7562957963635843

Epoch: 6| Step: 13
Training loss: 0.8348709940910339
Validation loss: 1.7710018337413829

Epoch: 310| Step: 0
Training loss: 0.3073047697544098
Validation loss: 1.7242923244353263

Epoch: 6| Step: 1
Training loss: 0.3658369183540344
Validation loss: 1.7769299450741018

Epoch: 6| Step: 2
Training loss: 0.6418124437332153
Validation loss: 1.7271477765934442

Epoch: 6| Step: 3
Training loss: 0.4366964101791382
Validation loss: 1.723006599692888

Epoch: 6| Step: 4
Training loss: 0.4088019132614136
Validation loss: 1.741258301401651

Epoch: 6| Step: 5
Training loss: 0.29939815402030945
Validation loss: 1.7379733336869108

Epoch: 6| Step: 6
Training loss: 0.5961723327636719
Validation loss: 1.7439222669088712

Epoch: 6| Step: 7
Training loss: 0.4842297434806824
Validation loss: 1.790530445755169

Epoch: 6| Step: 8
Training loss: 0.5701028108596802
Validation loss: 1.7855076405309862

Epoch: 6| Step: 9
Training loss: 0.28523093461990356
Validation loss: 1.8142891353176487

Epoch: 6| Step: 10
Training loss: 0.18694037199020386
Validation loss: 1.8243635854413431

Epoch: 6| Step: 11
Training loss: 0.30643951892852783
Validation loss: 1.799182612408874

Epoch: 6| Step: 12
Training loss: 0.4384003281593323
Validation loss: 1.8055356753769742

Epoch: 6| Step: 13
Training loss: 0.3649129867553711
Validation loss: 1.7868207090644426

Epoch: 311| Step: 0
Training loss: 0.6025980710983276
Validation loss: 1.7790798935838925

Epoch: 6| Step: 1
Training loss: 0.37104958295822144
Validation loss: 1.7826959138275476

Epoch: 6| Step: 2
Training loss: 0.34042564034461975
Validation loss: 1.781088872622418

Epoch: 6| Step: 3
Training loss: 0.49566084146499634
Validation loss: 1.7719708873379616

Epoch: 6| Step: 4
Training loss: 0.3120522201061249
Validation loss: 1.765587814392582

Epoch: 6| Step: 5
Training loss: 0.4322774410247803
Validation loss: 1.7257278978183705

Epoch: 6| Step: 6
Training loss: 0.33494770526885986
Validation loss: 1.7678243242284304

Epoch: 6| Step: 7
Training loss: 0.27333909273147583
Validation loss: 1.7595283831319501

Epoch: 6| Step: 8
Training loss: 0.31307223439216614
Validation loss: 1.778227215172142

Epoch: 6| Step: 9
Training loss: 0.23360897600650787
Validation loss: 1.8378031125632666

Epoch: 6| Step: 10
Training loss: 0.5037745237350464
Validation loss: 1.8377294437859648

Epoch: 6| Step: 11
Training loss: 0.14704079926013947
Validation loss: 1.8120292284155404

Epoch: 6| Step: 12
Training loss: 0.5495595335960388
Validation loss: 1.805423467389999

Epoch: 6| Step: 13
Training loss: 0.25830063223838806
Validation loss: 1.7993175060518327

Epoch: 312| Step: 0
Training loss: 0.4918135404586792
Validation loss: 1.7726501764789704

Epoch: 6| Step: 1
Training loss: 0.49279293417930603
Validation loss: 1.7912332306626022

Epoch: 6| Step: 2
Training loss: 0.28796979784965515
Validation loss: 1.7598321296835457

Epoch: 6| Step: 3
Training loss: 0.2690099775791168
Validation loss: 1.7615423766515588

Epoch: 6| Step: 4
Training loss: 0.3159385323524475
Validation loss: 1.7334755979558474

Epoch: 6| Step: 5
Training loss: 0.41118520498275757
Validation loss: 1.7597389208373202

Epoch: 6| Step: 6
Training loss: 0.2784242033958435
Validation loss: 1.755136518068211

Epoch: 6| Step: 7
Training loss: 0.2764545679092407
Validation loss: 1.7174960137695394

Epoch: 6| Step: 8
Training loss: 0.40365320444107056
Validation loss: 1.734738496042067

Epoch: 6| Step: 9
Training loss: 0.360431969165802
Validation loss: 1.7429166968150804

Epoch: 6| Step: 10
Training loss: 0.490936815738678
Validation loss: 1.749581697166607

Epoch: 6| Step: 11
Training loss: 0.29812872409820557
Validation loss: 1.766356316945886

Epoch: 6| Step: 12
Training loss: 0.5469624996185303
Validation loss: 1.8245904445648193

Epoch: 6| Step: 13
Training loss: 0.3526564836502075
Validation loss: 1.8154163283686484

Epoch: 313| Step: 0
Training loss: 0.37903767824172974
Validation loss: 1.7750331945316766

Epoch: 6| Step: 1
Training loss: 0.41572022438049316
Validation loss: 1.820345401763916

Epoch: 6| Step: 2
Training loss: 0.5551412105560303
Validation loss: 1.8224944094175934

Epoch: 6| Step: 3
Training loss: 0.24018123745918274
Validation loss: 1.7807389087574457

Epoch: 6| Step: 4
Training loss: 0.3479505181312561
Validation loss: 1.7806258945054905

Epoch: 6| Step: 5
Training loss: 0.4011811912059784
Validation loss: 1.7939402640506785

Epoch: 6| Step: 6
Training loss: 0.30468493700027466
Validation loss: 1.7136485230538152

Epoch: 6| Step: 7
Training loss: 0.47104108333587646
Validation loss: 1.6985525559353571

Epoch: 6| Step: 8
Training loss: 0.32649946212768555
Validation loss: 1.7104222441232333

Epoch: 6| Step: 9
Training loss: 0.2822468876838684
Validation loss: 1.7180591860125143

Epoch: 6| Step: 10
Training loss: 0.5248122811317444
Validation loss: 1.740167849807329

Epoch: 6| Step: 11
Training loss: 0.4803888499736786
Validation loss: 1.7479421810437274

Epoch: 6| Step: 12
Training loss: 0.26201677322387695
Validation loss: 1.7443308394442323

Epoch: 6| Step: 13
Training loss: 0.44842249155044556
Validation loss: 1.8387957798537387

Epoch: 314| Step: 0
Training loss: 0.3806149661540985
Validation loss: 1.8191422159953783

Epoch: 6| Step: 1
Training loss: 0.4332617223262787
Validation loss: 1.8778671526139783

Epoch: 6| Step: 2
Training loss: 0.4489399492740631
Validation loss: 1.9037956063465407

Epoch: 6| Step: 3
Training loss: 0.4667337238788605
Validation loss: 1.9390070861385715

Epoch: 6| Step: 4
Training loss: 0.4748839735984802
Validation loss: 1.9222760969592678

Epoch: 6| Step: 5
Training loss: 0.20544099807739258
Validation loss: 1.9557426180890811

Epoch: 6| Step: 6
Training loss: 0.34173908829689026
Validation loss: 1.9339372316996257

Epoch: 6| Step: 7
Training loss: 0.382102906703949
Validation loss: 1.8958642944212882

Epoch: 6| Step: 8
Training loss: 0.5582932233810425
Validation loss: 1.871764527854099

Epoch: 6| Step: 9
Training loss: 0.41967564821243286
Validation loss: 1.8565310585883357

Epoch: 6| Step: 10
Training loss: 0.4262295961380005
Validation loss: 1.8246709210898286

Epoch: 6| Step: 11
Training loss: 0.7188826203346252
Validation loss: 1.790938364562168

Epoch: 6| Step: 12
Training loss: 0.3765517771244049
Validation loss: 1.7707265692372476

Epoch: 6| Step: 13
Training loss: 0.22660166025161743
Validation loss: 1.7713350557511853

Epoch: 315| Step: 0
Training loss: 0.36972570419311523
Validation loss: 1.76337985069521

Epoch: 6| Step: 1
Training loss: 0.3304580748081207
Validation loss: 1.7965202690452657

Epoch: 6| Step: 2
Training loss: 0.44734883308410645
Validation loss: 1.7468280176962576

Epoch: 6| Step: 3
Training loss: 0.28966665267944336
Validation loss: 1.7852859868798205

Epoch: 6| Step: 4
Training loss: 0.24747009575366974
Validation loss: 1.8082859131597704

Epoch: 6| Step: 5
Training loss: 0.46638941764831543
Validation loss: 1.8048041494943763

Epoch: 6| Step: 6
Training loss: 0.3648817837238312
Validation loss: 1.8044615676326137

Epoch: 6| Step: 7
Training loss: 0.4679437577724457
Validation loss: 1.8099374091753395

Epoch: 6| Step: 8
Training loss: 0.33803802728652954
Validation loss: 1.8080729156412103

Epoch: 6| Step: 9
Training loss: 0.27881303429603577
Validation loss: 1.7566063404083252

Epoch: 6| Step: 10
Training loss: 0.44154155254364014
Validation loss: 1.8138737665709628

Epoch: 6| Step: 11
Training loss: 0.6110195517539978
Validation loss: 1.851722905712743

Epoch: 6| Step: 12
Training loss: 0.3174029588699341
Validation loss: 1.9028954198283534

Epoch: 6| Step: 13
Training loss: 0.6799494624137878
Validation loss: 1.8771308955325876

Epoch: 316| Step: 0
Training loss: 0.3704065680503845
Validation loss: 1.8642745633279123

Epoch: 6| Step: 1
Training loss: 0.3909149765968323
Validation loss: 1.8696925178650887

Epoch: 6| Step: 2
Training loss: 0.5086236000061035
Validation loss: 1.8182566460742746

Epoch: 6| Step: 3
Training loss: 0.6027345657348633
Validation loss: 1.8562425759530836

Epoch: 6| Step: 4
Training loss: 0.29259178042411804
Validation loss: 1.8521900215456564

Epoch: 6| Step: 5
Training loss: 0.41164323687553406
Validation loss: 1.8350190206240582

Epoch: 6| Step: 6
Training loss: 0.19890427589416504
Validation loss: 1.8487810037469352

Epoch: 6| Step: 7
Training loss: 0.6079365611076355
Validation loss: 1.851801400543541

Epoch: 6| Step: 8
Training loss: 0.3797602653503418
Validation loss: 1.8560056545401131

Epoch: 6| Step: 9
Training loss: 0.39124953746795654
Validation loss: 1.8202637228914487

Epoch: 6| Step: 10
Training loss: 0.4324491024017334
Validation loss: 1.7792351117698095

Epoch: 6| Step: 11
Training loss: 0.29616814851760864
Validation loss: 1.762153935688798

Epoch: 6| Step: 12
Training loss: 0.3230486810207367
Validation loss: 1.7759704154024842

Epoch: 6| Step: 13
Training loss: 0.20047982037067413
Validation loss: 1.7942267464053245

Epoch: 317| Step: 0
Training loss: 0.5170597434043884
Validation loss: 1.790336944723642

Epoch: 6| Step: 1
Training loss: 0.6348055601119995
Validation loss: 1.816911724305922

Epoch: 6| Step: 2
Training loss: 0.29939958453178406
Validation loss: 1.8302743550269835

Epoch: 6| Step: 3
Training loss: 0.38420653343200684
Validation loss: 1.7886736687793527

Epoch: 6| Step: 4
Training loss: 0.28222206234931946
Validation loss: 1.8302669935328986

Epoch: 6| Step: 5
Training loss: 0.3731434941291809
Validation loss: 1.901681657760374

Epoch: 6| Step: 6
Training loss: 0.4624277353286743
Validation loss: 1.8763332956580705

Epoch: 6| Step: 7
Training loss: 0.30989545583724976
Validation loss: 1.8514330002569384

Epoch: 6| Step: 8
Training loss: 0.38326793909072876
Validation loss: 1.823370138804118

Epoch: 6| Step: 9
Training loss: 0.5994569659233093
Validation loss: 1.7658314256257908

Epoch: 6| Step: 10
Training loss: 0.404551237821579
Validation loss: 1.7710889641956618

Epoch: 6| Step: 11
Training loss: 0.40122002363204956
Validation loss: 1.7186510383441884

Epoch: 6| Step: 12
Training loss: 0.3498994708061218
Validation loss: 1.6949002306948426

Epoch: 6| Step: 13
Training loss: 0.33636268973350525
Validation loss: 1.683161361243135

Epoch: 318| Step: 0
Training loss: 0.5261639356613159
Validation loss: 1.679617287010275

Epoch: 6| Step: 1
Training loss: 0.38450077176094055
Validation loss: 1.6734954913457234

Epoch: 6| Step: 2
Training loss: 0.2948019504547119
Validation loss: 1.7105067801731888

Epoch: 6| Step: 3
Training loss: 0.3830257058143616
Validation loss: 1.70458601110725

Epoch: 6| Step: 4
Training loss: 0.40474823117256165
Validation loss: 1.7050461000011814

Epoch: 6| Step: 5
Training loss: 0.33505237102508545
Validation loss: 1.7311965727037

Epoch: 6| Step: 6
Training loss: 0.3233238458633423
Validation loss: 1.7424175021468953

Epoch: 6| Step: 7
Training loss: 0.33855247497558594
Validation loss: 1.7622482648459814

Epoch: 6| Step: 8
Training loss: 0.5377012491226196
Validation loss: 1.817446070332681

Epoch: 6| Step: 9
Training loss: 0.5597103834152222
Validation loss: 1.860341533537834

Epoch: 6| Step: 10
Training loss: 0.2018083781003952
Validation loss: 1.900799261626377

Epoch: 6| Step: 11
Training loss: 0.42610377073287964
Validation loss: 1.852464343911858

Epoch: 6| Step: 12
Training loss: 0.35487666726112366
Validation loss: 1.8464621843830231

Epoch: 6| Step: 13
Training loss: 0.424698144197464
Validation loss: 1.8281108115309028

Epoch: 319| Step: 0
Training loss: 0.3010687530040741
Validation loss: 1.8130734095009424

Epoch: 6| Step: 1
Training loss: 0.1325201392173767
Validation loss: 1.7712775353462464

Epoch: 6| Step: 2
Training loss: 0.39217519760131836
Validation loss: 1.7652371032263643

Epoch: 6| Step: 3
Training loss: 0.5088475942611694
Validation loss: 1.75887131690979

Epoch: 6| Step: 4
Training loss: 0.3608393371105194
Validation loss: 1.780017129836544

Epoch: 6| Step: 5
Training loss: 0.33252036571502686
Validation loss: 1.7757043056590582

Epoch: 6| Step: 6
Training loss: 0.48098868131637573
Validation loss: 1.782207973541752

Epoch: 6| Step: 7
Training loss: 0.27049922943115234
Validation loss: 1.752052955729987

Epoch: 6| Step: 8
Training loss: 0.21203406155109406
Validation loss: 1.7947105694842596

Epoch: 6| Step: 9
Training loss: 0.36472776532173157
Validation loss: 1.8154373066399687

Epoch: 6| Step: 10
Training loss: 0.39591312408447266
Validation loss: 1.822285000995923

Epoch: 6| Step: 11
Training loss: 0.4960747957229614
Validation loss: 1.8667698983223207

Epoch: 6| Step: 12
Training loss: 0.6179262399673462
Validation loss: 1.8243957065766858

Epoch: 6| Step: 13
Training loss: 0.24475611746311188
Validation loss: 1.8202143971638014

Epoch: 320| Step: 0
Training loss: 0.2489655315876007
Validation loss: 1.7734759174367434

Epoch: 6| Step: 1
Training loss: 0.3803443908691406
Validation loss: 1.73105570449624

Epoch: 6| Step: 2
Training loss: 0.3290637135505676
Validation loss: 1.7288377067094207

Epoch: 6| Step: 3
Training loss: 0.34430158138275146
Validation loss: 1.7361826986394904

Epoch: 6| Step: 4
Training loss: 0.45230138301849365
Validation loss: 1.7406365563792567

Epoch: 6| Step: 5
Training loss: 0.2047584354877472
Validation loss: 1.7538107531045073

Epoch: 6| Step: 6
Training loss: 0.5658878087997437
Validation loss: 1.764378668159567

Epoch: 6| Step: 7
Training loss: 0.2714793086051941
Validation loss: 1.7651980384703605

Epoch: 6| Step: 8
Training loss: 0.2070564329624176
Validation loss: 1.7891499368093347

Epoch: 6| Step: 9
Training loss: 0.4805108904838562
Validation loss: 1.7666171827623922

Epoch: 6| Step: 10
Training loss: 0.41011473536491394
Validation loss: 1.7939275938977477

Epoch: 6| Step: 11
Training loss: 0.43932586908340454
Validation loss: 1.8071415757620206

Epoch: 6| Step: 12
Training loss: 0.3577336072921753
Validation loss: 1.8514687092073503

Epoch: 6| Step: 13
Training loss: 0.20860609412193298
Validation loss: 1.8170137969396447

Epoch: 321| Step: 0
Training loss: 0.33372506499290466
Validation loss: 1.8353081710876957

Epoch: 6| Step: 1
Training loss: 0.38569822907447815
Validation loss: 1.8476008317803825

Epoch: 6| Step: 2
Training loss: 0.28813567757606506
Validation loss: 1.8525387305085377

Epoch: 6| Step: 3
Training loss: 0.4500681459903717
Validation loss: 1.8173999196739608

Epoch: 6| Step: 4
Training loss: 0.49831295013427734
Validation loss: 1.791227444525688

Epoch: 6| Step: 5
Training loss: 0.45163050293922424
Validation loss: 1.745816767856639

Epoch: 6| Step: 6
Training loss: 0.2835780084133148
Validation loss: 1.7644404518988825

Epoch: 6| Step: 7
Training loss: 0.4162697196006775
Validation loss: 1.7511877257336852

Epoch: 6| Step: 8
Training loss: 0.2545395493507385
Validation loss: 1.7608372447311238

Epoch: 6| Step: 9
Training loss: 0.4428856372833252
Validation loss: 1.7676646965806202

Epoch: 6| Step: 10
Training loss: 0.3053802251815796
Validation loss: 1.783403040260397

Epoch: 6| Step: 11
Training loss: 0.2852184772491455
Validation loss: 1.7872519928921935

Epoch: 6| Step: 12
Training loss: 0.2921994924545288
Validation loss: 1.7917790105265956

Epoch: 6| Step: 13
Training loss: 0.3448530435562134
Validation loss: 1.8391488021419895

Epoch: 322| Step: 0
Training loss: 0.5746711492538452
Validation loss: 1.819887497091806

Epoch: 6| Step: 1
Training loss: 0.2563583254814148
Validation loss: 1.8036556372078516

Epoch: 6| Step: 2
Training loss: 0.48841410875320435
Validation loss: 1.8722328832072597

Epoch: 6| Step: 3
Training loss: 0.370604932308197
Validation loss: 1.8280675488133584

Epoch: 6| Step: 4
Training loss: 0.41639119386672974
Validation loss: 1.8306289206268966

Epoch: 6| Step: 5
Training loss: 0.3646058440208435
Validation loss: 1.8572216469754455

Epoch: 6| Step: 6
Training loss: 0.2586421072483063
Validation loss: 1.8284695840650989

Epoch: 6| Step: 7
Training loss: 0.19030119478702545
Validation loss: 1.8300436363425305

Epoch: 6| Step: 8
Training loss: 0.27977851033210754
Validation loss: 1.8169367159566572

Epoch: 6| Step: 9
Training loss: 0.3131791055202484
Validation loss: 1.8047132363883398

Epoch: 6| Step: 10
Training loss: 0.31563475728034973
Validation loss: 1.8440443956723778

Epoch: 6| Step: 11
Training loss: 0.2876906394958496
Validation loss: 1.854400057946482

Epoch: 6| Step: 12
Training loss: 0.3522735834121704
Validation loss: 1.819160597298735

Epoch: 6| Step: 13
Training loss: 0.3026866614818573
Validation loss: 1.7527310091962096

Epoch: 323| Step: 0
Training loss: 0.40920281410217285
Validation loss: 1.7731318422543105

Epoch: 6| Step: 1
Training loss: 0.45103779435157776
Validation loss: 1.7415664695924329

Epoch: 6| Step: 2
Training loss: 0.40155673027038574
Validation loss: 1.7362783839625697

Epoch: 6| Step: 3
Training loss: 0.28513121604919434
Validation loss: 1.7339386632365565

Epoch: 6| Step: 4
Training loss: 0.35292601585388184
Validation loss: 1.7950101014106505

Epoch: 6| Step: 5
Training loss: 0.33368930220603943
Validation loss: 1.7923557040511922

Epoch: 6| Step: 6
Training loss: 0.5889012217521667
Validation loss: 1.8129627345710673

Epoch: 6| Step: 7
Training loss: 0.1499277651309967
Validation loss: 1.8073806249967186

Epoch: 6| Step: 8
Training loss: 0.24193479120731354
Validation loss: 1.7839502173085366

Epoch: 6| Step: 9
Training loss: 0.29052072763442993
Validation loss: 1.781284680930517

Epoch: 6| Step: 10
Training loss: 0.14272044599056244
Validation loss: 1.7675217313151206

Epoch: 6| Step: 11
Training loss: 0.2948973774909973
Validation loss: 1.786799825647826

Epoch: 6| Step: 12
Training loss: 0.40496891736984253
Validation loss: 1.7858016644754717

Epoch: 6| Step: 13
Training loss: 0.25214433670043945
Validation loss: 1.7512969355429373

Epoch: 324| Step: 0
Training loss: 0.32717448472976685
Validation loss: 1.7553734343539003

Epoch: 6| Step: 1
Training loss: 0.468688040971756
Validation loss: 1.7424383791544105

Epoch: 6| Step: 2
Training loss: 0.5713452100753784
Validation loss: 1.723831017812093

Epoch: 6| Step: 3
Training loss: 0.27400270104408264
Validation loss: 1.686043659845988

Epoch: 6| Step: 4
Training loss: 0.3083952069282532
Validation loss: 1.7051409098409838

Epoch: 6| Step: 5
Training loss: 0.5117806792259216
Validation loss: 1.702713128059141

Epoch: 6| Step: 6
Training loss: 0.2230008840560913
Validation loss: 1.7038321418146933

Epoch: 6| Step: 7
Training loss: 0.36560308933258057
Validation loss: 1.7095266413945023

Epoch: 6| Step: 8
Training loss: 0.3279982805252075
Validation loss: 1.7443232805498186

Epoch: 6| Step: 9
Training loss: 0.34284451603889465
Validation loss: 1.7213875068131315

Epoch: 6| Step: 10
Training loss: 0.29492002725601196
Validation loss: 1.753573731709552

Epoch: 6| Step: 11
Training loss: 0.19214263558387756
Validation loss: 1.7662706426394883

Epoch: 6| Step: 12
Training loss: 0.4136626720428467
Validation loss: 1.8001841691232496

Epoch: 6| Step: 13
Training loss: 0.12955480813980103
Validation loss: 1.8622276077988327

Epoch: 325| Step: 0
Training loss: 0.48924916982650757
Validation loss: 1.823161066219371

Epoch: 6| Step: 1
Training loss: 0.3869425654411316
Validation loss: 1.8642374264296664

Epoch: 6| Step: 2
Training loss: 0.24837912619113922
Validation loss: 1.8643905962667158

Epoch: 6| Step: 3
Training loss: 0.48962318897247314
Validation loss: 1.848786747583779

Epoch: 6| Step: 4
Training loss: 0.4304273724555969
Validation loss: 1.8093486626942952

Epoch: 6| Step: 5
Training loss: 0.13826864957809448
Validation loss: 1.8127871944058327

Epoch: 6| Step: 6
Training loss: 0.12307438254356384
Validation loss: 1.8307227485923356

Epoch: 6| Step: 7
Training loss: 0.30077502131462097
Validation loss: 1.8080505401857438

Epoch: 6| Step: 8
Training loss: 0.38326388597488403
Validation loss: 1.772100208907999

Epoch: 6| Step: 9
Training loss: 0.2619670629501343
Validation loss: 1.837387889944097

Epoch: 6| Step: 10
Training loss: 0.4208926558494568
Validation loss: 1.79338038352228

Epoch: 6| Step: 11
Training loss: 0.5069497227668762
Validation loss: 1.8156890382048905

Epoch: 6| Step: 12
Training loss: 0.40565332770347595
Validation loss: 1.7725147278078142

Epoch: 6| Step: 13
Training loss: 0.34021472930908203
Validation loss: 1.8002365622469174

Epoch: 326| Step: 0
Training loss: 0.4423728585243225
Validation loss: 1.8169904806280648

Epoch: 6| Step: 1
Training loss: 0.2979052662849426
Validation loss: 1.8659543016905427

Epoch: 6| Step: 2
Training loss: 0.22578108310699463
Validation loss: 1.8748326506665958

Epoch: 6| Step: 3
Training loss: 0.2686361074447632
Validation loss: 1.8795425712421376

Epoch: 6| Step: 4
Training loss: 0.5699125528335571
Validation loss: 1.8961253268744356

Epoch: 6| Step: 5
Training loss: 0.32757264375686646
Validation loss: 1.905071928936948

Epoch: 6| Step: 6
Training loss: 0.22078385949134827
Validation loss: 1.9297400366875432

Epoch: 6| Step: 7
Training loss: 0.5451092720031738
Validation loss: 1.895370860253611

Epoch: 6| Step: 8
Training loss: 0.39525479078292847
Validation loss: 1.8502081337795462

Epoch: 6| Step: 9
Training loss: 0.32511383295059204
Validation loss: 1.8121687007206742

Epoch: 6| Step: 10
Training loss: 0.34087029099464417
Validation loss: 1.8332197435440556

Epoch: 6| Step: 11
Training loss: 0.2621360421180725
Validation loss: 1.7807197750255626

Epoch: 6| Step: 12
Training loss: 0.14760461449623108
Validation loss: 1.7733603523623558

Epoch: 6| Step: 13
Training loss: 0.3455144166946411
Validation loss: 1.746279731873543

Epoch: 327| Step: 0
Training loss: 0.4414616525173187
Validation loss: 1.7182162141287198

Epoch: 6| Step: 1
Training loss: 0.4366625249385834
Validation loss: 1.7177152941303868

Epoch: 6| Step: 2
Training loss: 0.21787716448307037
Validation loss: 1.7302446621720509

Epoch: 6| Step: 3
Training loss: 0.46407318115234375
Validation loss: 1.735884435715214

Epoch: 6| Step: 4
Training loss: 0.3333621025085449
Validation loss: 1.725024833474108

Epoch: 6| Step: 5
Training loss: 0.2011822760105133
Validation loss: 1.6788689205723424

Epoch: 6| Step: 6
Training loss: 0.39765509963035583
Validation loss: 1.7081860957607147

Epoch: 6| Step: 7
Training loss: 0.24554935097694397
Validation loss: 1.739150002438535

Epoch: 6| Step: 8
Training loss: 0.23047012090682983
Validation loss: 1.7774076077245897

Epoch: 6| Step: 9
Training loss: 0.6282695531845093
Validation loss: 1.8104196197243148

Epoch: 6| Step: 10
Training loss: 0.5070173144340515
Validation loss: 1.8104866191905031

Epoch: 6| Step: 11
Training loss: 0.3291749060153961
Validation loss: 1.7943907860786683

Epoch: 6| Step: 12
Training loss: 0.13946527242660522
Validation loss: 1.7702102648314608

Epoch: 6| Step: 13
Training loss: 0.663252592086792
Validation loss: 1.7831959480880408

Epoch: 328| Step: 0
Training loss: 0.24879176914691925
Validation loss: 1.788488390625164

Epoch: 6| Step: 1
Training loss: 0.35870373249053955
Validation loss: 1.783082753099421

Epoch: 6| Step: 2
Training loss: 0.4372815787792206
Validation loss: 1.7923002909588557

Epoch: 6| Step: 3
Training loss: 0.37682268023490906
Validation loss: 1.8102633312184324

Epoch: 6| Step: 4
Training loss: 0.36634987592697144
Validation loss: 1.777964856034966

Epoch: 6| Step: 5
Training loss: 0.2994617819786072
Validation loss: 1.7616884477676884

Epoch: 6| Step: 6
Training loss: 0.43712007999420166
Validation loss: 1.7300277474105998

Epoch: 6| Step: 7
Training loss: 0.22988004982471466
Validation loss: 1.7649835591675134

Epoch: 6| Step: 8
Training loss: 0.2857527732849121
Validation loss: 1.7640320767638504

Epoch: 6| Step: 9
Training loss: 0.21584421396255493
Validation loss: 1.745949004286079

Epoch: 6| Step: 10
Training loss: 0.40248602628707886
Validation loss: 1.7734082360421457

Epoch: 6| Step: 11
Training loss: 0.32284417748451233
Validation loss: 1.7601249602533156

Epoch: 6| Step: 12
Training loss: 0.2871518135070801
Validation loss: 1.762207442714322

Epoch: 6| Step: 13
Training loss: 0.38580119609832764
Validation loss: 1.7722196681525118

Epoch: 329| Step: 0
Training loss: 0.4268384575843811
Validation loss: 1.751534262011128

Epoch: 6| Step: 1
Training loss: 0.13367848098278046
Validation loss: 1.7867286641110656

Epoch: 6| Step: 2
Training loss: 0.46346938610076904
Validation loss: 1.7993177893341228

Epoch: 6| Step: 3
Training loss: 0.36413756012916565
Validation loss: 1.8336661015787432

Epoch: 6| Step: 4
Training loss: 0.202760249376297
Validation loss: 1.7982708715623426

Epoch: 6| Step: 5
Training loss: 0.22577016055583954
Validation loss: 1.8610326884895243

Epoch: 6| Step: 6
Training loss: 0.21553203463554382
Validation loss: 1.8593033782897457

Epoch: 6| Step: 7
Training loss: 0.31562647223472595
Validation loss: 1.8675795831987936

Epoch: 6| Step: 8
Training loss: 0.44087669253349304
Validation loss: 1.8826849281146962

Epoch: 6| Step: 9
Training loss: 0.43735960125923157
Validation loss: 1.8216986124233534

Epoch: 6| Step: 10
Training loss: 0.3942372798919678
Validation loss: 1.8216865165259248

Epoch: 6| Step: 11
Training loss: 0.34555768966674805
Validation loss: 1.7850222254312167

Epoch: 6| Step: 12
Training loss: 0.2763502597808838
Validation loss: 1.783993754335629

Epoch: 6| Step: 13
Training loss: 0.1103147566318512
Validation loss: 1.743967471584197

Epoch: 330| Step: 0
Training loss: 0.40609389543533325
Validation loss: 1.7234853544542867

Epoch: 6| Step: 1
Training loss: 0.3208833932876587
Validation loss: 1.731387520349154

Epoch: 6| Step: 2
Training loss: 0.29554057121276855
Validation loss: 1.7304047948570662

Epoch: 6| Step: 3
Training loss: 0.4118419289588928
Validation loss: 1.7107819613590036

Epoch: 6| Step: 4
Training loss: 0.3424418568611145
Validation loss: 1.7291825599567865

Epoch: 6| Step: 5
Training loss: 0.22581905126571655
Validation loss: 1.697589139784536

Epoch: 6| Step: 6
Training loss: 0.3352462351322174
Validation loss: 1.7538076395629554

Epoch: 6| Step: 7
Training loss: 0.18945980072021484
Validation loss: 1.7556112825229604

Epoch: 6| Step: 8
Training loss: 0.41458484530448914
Validation loss: 1.77111578372217

Epoch: 6| Step: 9
Training loss: 0.22492560744285583
Validation loss: 1.8097258383227932

Epoch: 6| Step: 10
Training loss: 0.43618690967559814
Validation loss: 1.7338364752390052

Epoch: 6| Step: 11
Training loss: 0.2811729907989502
Validation loss: 1.7919640348803612

Epoch: 6| Step: 12
Training loss: 0.2808741331100464
Validation loss: 1.7954000247422086

Epoch: 6| Step: 13
Training loss: 0.49165767431259155
Validation loss: 1.8062191406885784

Epoch: 331| Step: 0
Training loss: 0.3038080632686615
Validation loss: 1.8281637648100495

Epoch: 6| Step: 1
Training loss: 0.2837950587272644
Validation loss: 1.8392785826037008

Epoch: 6| Step: 2
Training loss: 0.3336627781391144
Validation loss: 1.8080896536509197

Epoch: 6| Step: 3
Training loss: 0.26608937978744507
Validation loss: 1.8256940367401286

Epoch: 6| Step: 4
Training loss: 0.33918505907058716
Validation loss: 1.8129446506500244

Epoch: 6| Step: 5
Training loss: 0.18614448606967926
Validation loss: 1.8179660561264201

Epoch: 6| Step: 6
Training loss: 0.3808172345161438
Validation loss: 1.8032167778220227

Epoch: 6| Step: 7
Training loss: 0.36583560705184937
Validation loss: 1.7855284265292588

Epoch: 6| Step: 8
Training loss: 0.31331539154052734
Validation loss: 1.7552168702566495

Epoch: 6| Step: 9
Training loss: 0.2785656452178955
Validation loss: 1.756835840081656

Epoch: 6| Step: 10
Training loss: 0.5274026989936829
Validation loss: 1.7512567530396164

Epoch: 6| Step: 11
Training loss: 0.23418626189231873
Validation loss: 1.8084548583594702

Epoch: 6| Step: 12
Training loss: 0.46997272968292236
Validation loss: 1.8146316159156062

Epoch: 6| Step: 13
Training loss: 0.5539526343345642
Validation loss: 1.7911641302929129

Epoch: 332| Step: 0
Training loss: 0.5924538373947144
Validation loss: 1.828805802970804

Epoch: 6| Step: 1
Training loss: 0.3253520727157593
Validation loss: 1.8371185512952908

Epoch: 6| Step: 2
Training loss: 0.39005234837532043
Validation loss: 1.8516845062214842

Epoch: 6| Step: 3
Training loss: 0.3738047778606415
Validation loss: 1.8311197155265397

Epoch: 6| Step: 4
Training loss: 0.1958586573600769
Validation loss: 1.846736102975825

Epoch: 6| Step: 5
Training loss: 0.4171370267868042
Validation loss: 1.8180698040992982

Epoch: 6| Step: 6
Training loss: 0.24738222360610962
Validation loss: 1.8240234236563406

Epoch: 6| Step: 7
Training loss: 0.2829342782497406
Validation loss: 1.8372485304391513

Epoch: 6| Step: 8
Training loss: 0.22825664281845093
Validation loss: 1.7830164483798447

Epoch: 6| Step: 9
Training loss: 0.2859850525856018
Validation loss: 1.7917394676516134

Epoch: 6| Step: 10
Training loss: 0.3096643090248108
Validation loss: 1.7486982627581524

Epoch: 6| Step: 11
Training loss: 0.4239239990711212
Validation loss: 1.7614632678288284

Epoch: 6| Step: 12
Training loss: 0.2832159101963043
Validation loss: 1.7596167556701168

Epoch: 6| Step: 13
Training loss: 0.5136218070983887
Validation loss: 1.7643748701259654

Epoch: 333| Step: 0
Training loss: 0.14715126156806946
Validation loss: 1.7145789720678841

Epoch: 6| Step: 1
Training loss: 0.2478364109992981
Validation loss: 1.739824979535995

Epoch: 6| Step: 2
Training loss: 0.5176792144775391
Validation loss: 1.7696280120521464

Epoch: 6| Step: 3
Training loss: 0.4234844446182251
Validation loss: 1.8055026505583076

Epoch: 6| Step: 4
Training loss: 0.28822243213653564
Validation loss: 1.847410822427401

Epoch: 6| Step: 5
Training loss: 0.4047483503818512
Validation loss: 1.895494249559218

Epoch: 6| Step: 6
Training loss: 0.3067042827606201
Validation loss: 1.8344830774491834

Epoch: 6| Step: 7
Training loss: 0.40233856439590454
Validation loss: 1.8093040245835499

Epoch: 6| Step: 8
Training loss: 0.40194493532180786
Validation loss: 1.774151740535613

Epoch: 6| Step: 9
Training loss: 0.20986714959144592
Validation loss: 1.7505476833671652

Epoch: 6| Step: 10
Training loss: 0.5009056329727173
Validation loss: 1.768466108588762

Epoch: 6| Step: 11
Training loss: 0.36088261008262634
Validation loss: 1.780597670103914

Epoch: 6| Step: 12
Training loss: 0.2947884798049927
Validation loss: 1.7415865454622494

Epoch: 6| Step: 13
Training loss: 0.43000563979148865
Validation loss: 1.7721542619889783

Epoch: 334| Step: 0
Training loss: 0.25198811292648315
Validation loss: 1.7888261989880634

Epoch: 6| Step: 1
Training loss: 0.3152107894420624
Validation loss: 1.7925139729694655

Epoch: 6| Step: 2
Training loss: 0.4259583353996277
Validation loss: 1.813955053206413

Epoch: 6| Step: 3
Training loss: 0.2738017737865448
Validation loss: 1.768678903579712

Epoch: 6| Step: 4
Training loss: 0.4502594470977783
Validation loss: 1.8001338922849266

Epoch: 6| Step: 5
Training loss: 0.32538771629333496
Validation loss: 1.8035433856389855

Epoch: 6| Step: 6
Training loss: 0.28701236844062805
Validation loss: 1.8186768754836051

Epoch: 6| Step: 7
Training loss: 0.2951236367225647
Validation loss: 1.799253430417789

Epoch: 6| Step: 8
Training loss: 0.4002552628517151
Validation loss: 1.7700635976688837

Epoch: 6| Step: 9
Training loss: 0.29688799381256104
Validation loss: 1.7640300322604436

Epoch: 6| Step: 10
Training loss: 0.306315153837204
Validation loss: 1.7814722625158166

Epoch: 6| Step: 11
Training loss: 0.41651293635368347
Validation loss: 1.7801909100624822

Epoch: 6| Step: 12
Training loss: 0.3912985622882843
Validation loss: 1.7722680568695068

Epoch: 6| Step: 13
Training loss: 0.26247867941856384
Validation loss: 1.7920538597209479

Epoch: 335| Step: 0
Training loss: 0.32772523164749146
Validation loss: 1.7876747333875267

Epoch: 6| Step: 1
Training loss: 0.33933502435684204
Validation loss: 1.8020135817989227

Epoch: 6| Step: 2
Training loss: 0.42051732540130615
Validation loss: 1.8069996365936853

Epoch: 6| Step: 3
Training loss: 0.37791720032691956
Validation loss: 1.8037980576997161

Epoch: 6| Step: 4
Training loss: 0.3246210217475891
Validation loss: 1.7763134638468425

Epoch: 6| Step: 5
Training loss: 0.24417518079280853
Validation loss: 1.738054742095291

Epoch: 6| Step: 6
Training loss: 0.2065773755311966
Validation loss: 1.7488680847229496

Epoch: 6| Step: 7
Training loss: 0.26587650179862976
Validation loss: 1.7826848722273303

Epoch: 6| Step: 8
Training loss: 0.1902616173028946
Validation loss: 1.7689490907935685

Epoch: 6| Step: 9
Training loss: 0.42052534222602844
Validation loss: 1.758490772657497

Epoch: 6| Step: 10
Training loss: 0.3419075310230255
Validation loss: 1.776080495567732

Epoch: 6| Step: 11
Training loss: 0.5331391096115112
Validation loss: 1.7976811419251144

Epoch: 6| Step: 12
Training loss: 0.2593359053134918
Validation loss: 1.7943094468885852

Epoch: 6| Step: 13
Training loss: 0.22883054614067078
Validation loss: 1.8167662492362402

Epoch: 336| Step: 0
Training loss: 0.3753485679626465
Validation loss: 1.7878874014782649

Epoch: 6| Step: 1
Training loss: 0.36203014850616455
Validation loss: 1.780621749098583

Epoch: 6| Step: 2
Training loss: 0.42646822333335876
Validation loss: 1.7973238704025105

Epoch: 6| Step: 3
Training loss: 0.4500328004360199
Validation loss: 1.794089062239534

Epoch: 6| Step: 4
Training loss: 0.3194706439971924
Validation loss: 1.7613393081131803

Epoch: 6| Step: 5
Training loss: 0.2472580373287201
Validation loss: 1.7445217114622875

Epoch: 6| Step: 6
Training loss: 0.20950838923454285
Validation loss: 1.7919974506542247

Epoch: 6| Step: 7
Training loss: 0.341713011264801
Validation loss: 1.765853713917476

Epoch: 6| Step: 8
Training loss: 0.4701199531555176
Validation loss: 1.7673327666456982

Epoch: 6| Step: 9
Training loss: 0.2039889693260193
Validation loss: 1.7546369824358212

Epoch: 6| Step: 10
Training loss: 0.2687089741230011
Validation loss: 1.787647581869556

Epoch: 6| Step: 11
Training loss: 0.3466825485229492
Validation loss: 1.7949057497004026

Epoch: 6| Step: 12
Training loss: 0.4764731824398041
Validation loss: 1.763658695323493

Epoch: 6| Step: 13
Training loss: 0.2334948182106018
Validation loss: 1.7876286814289708

Epoch: 337| Step: 0
Training loss: 0.26073157787323
Validation loss: 1.8355164079255955

Epoch: 6| Step: 1
Training loss: 0.3388015925884247
Validation loss: 1.8134208667662837

Epoch: 6| Step: 2
Training loss: 0.33603790402412415
Validation loss: 1.8125990898378435

Epoch: 6| Step: 3
Training loss: 0.5586297512054443
Validation loss: 1.8333664658249065

Epoch: 6| Step: 4
Training loss: 0.4425334930419922
Validation loss: 1.8441555448757705

Epoch: 6| Step: 5
Training loss: 0.4159088432788849
Validation loss: 1.7946486114173807

Epoch: 6| Step: 6
Training loss: 0.2979038953781128
Validation loss: 1.7870253824418592

Epoch: 6| Step: 7
Training loss: 0.3490363657474518
Validation loss: 1.7473483290723575

Epoch: 6| Step: 8
Training loss: 0.267566442489624
Validation loss: 1.7446694861176193

Epoch: 6| Step: 9
Training loss: 0.22278490662574768
Validation loss: 1.731216549873352

Epoch: 6| Step: 10
Training loss: 0.3749261796474457
Validation loss: 1.712535217244138

Epoch: 6| Step: 11
Training loss: 0.301467627286911
Validation loss: 1.6942563595310334

Epoch: 6| Step: 12
Training loss: 0.37358835339546204
Validation loss: 1.663458196065759

Epoch: 6| Step: 13
Training loss: 0.31560018658638
Validation loss: 1.6666416378431423

Epoch: 338| Step: 0
Training loss: 0.38902634382247925
Validation loss: 1.6979370553006408

Epoch: 6| Step: 1
Training loss: 0.2979952096939087
Validation loss: 1.6866313680525749

Epoch: 6| Step: 2
Training loss: 0.2664839029312134
Validation loss: 1.7254236975023824

Epoch: 6| Step: 3
Training loss: 0.5157500505447388
Validation loss: 1.728610174630278

Epoch: 6| Step: 4
Training loss: 0.2796262502670288
Validation loss: 1.7872051859414706

Epoch: 6| Step: 5
Training loss: 0.3251505494117737
Validation loss: 1.7679048417716898

Epoch: 6| Step: 6
Training loss: 0.17609599232673645
Validation loss: 1.8226434889660086

Epoch: 6| Step: 7
Training loss: 0.35096031427383423
Validation loss: 1.81785108453484

Epoch: 6| Step: 8
Training loss: 0.3642255365848541
Validation loss: 1.8315635483752015

Epoch: 6| Step: 9
Training loss: 0.2720816731452942
Validation loss: 1.8053539094104563

Epoch: 6| Step: 10
Training loss: 0.3609951138496399
Validation loss: 1.8106259043498705

Epoch: 6| Step: 11
Training loss: 0.20624500513076782
Validation loss: 1.7637608807574037

Epoch: 6| Step: 12
Training loss: 0.34432971477508545
Validation loss: 1.7933781070093955

Epoch: 6| Step: 13
Training loss: 0.44445767998695374
Validation loss: 1.7978297638636764

Epoch: 339| Step: 0
Training loss: 0.3294510841369629
Validation loss: 1.8261401781471827

Epoch: 6| Step: 1
Training loss: 0.2707712650299072
Validation loss: 1.8361689672675183

Epoch: 6| Step: 2
Training loss: 0.30355578660964966
Validation loss: 1.7777331618852512

Epoch: 6| Step: 3
Training loss: 0.3993352949619293
Validation loss: 1.7611515214366298

Epoch: 6| Step: 4
Training loss: 0.36062270402908325
Validation loss: 1.7323670823086974

Epoch: 6| Step: 5
Training loss: 0.2141568511724472
Validation loss: 1.7383997042973836

Epoch: 6| Step: 6
Training loss: 0.3321937322616577
Validation loss: 1.7163905084774058

Epoch: 6| Step: 7
Training loss: 0.23050269484519958
Validation loss: 1.7160932915185088

Epoch: 6| Step: 8
Training loss: 0.33371055126190186
Validation loss: 1.7143733309161278

Epoch: 6| Step: 9
Training loss: 0.35167521238327026
Validation loss: 1.7661256162069177

Epoch: 6| Step: 10
Training loss: 0.2827470898628235
Validation loss: 1.7671629805718698

Epoch: 6| Step: 11
Training loss: 0.606898307800293
Validation loss: 1.746065560207572

Epoch: 6| Step: 12
Training loss: 0.3151407837867737
Validation loss: 1.7765068520781815

Epoch: 6| Step: 13
Training loss: 0.19833704829216003
Validation loss: 1.7747535577384375

Epoch: 340| Step: 0
Training loss: 0.30454593896865845
Validation loss: 1.7624964996050763

Epoch: 6| Step: 1
Training loss: 0.44040772318840027
Validation loss: 1.7852045143804243

Epoch: 6| Step: 2
Training loss: 0.3038850426673889
Validation loss: 1.7818471424041256

Epoch: 6| Step: 3
Training loss: 0.23456570506095886
Validation loss: 1.7624158718252694

Epoch: 6| Step: 4
Training loss: 0.2635132670402527
Validation loss: 1.77242785884488

Epoch: 6| Step: 5
Training loss: 0.4119323194026947
Validation loss: 1.7366223066083846

Epoch: 6| Step: 6
Training loss: 0.21734942495822906
Validation loss: 1.757152836809876

Epoch: 6| Step: 7
Training loss: 0.2198413908481598
Validation loss: 1.7736212361243464

Epoch: 6| Step: 8
Training loss: 0.30287861824035645
Validation loss: 1.7172511149478216

Epoch: 6| Step: 9
Training loss: 0.30698803067207336
Validation loss: 1.7182578361162575

Epoch: 6| Step: 10
Training loss: 0.2102060317993164
Validation loss: 1.759163264305361

Epoch: 6| Step: 11
Training loss: 0.29574495553970337
Validation loss: 1.701423692446883

Epoch: 6| Step: 12
Training loss: 0.2822292149066925
Validation loss: 1.712548344366012

Epoch: 6| Step: 13
Training loss: 0.3485634922981262
Validation loss: 1.7443359692891438

Epoch: 341| Step: 0
Training loss: 0.3787840008735657
Validation loss: 1.7410377584477907

Epoch: 6| Step: 1
Training loss: 0.24314525723457336
Validation loss: 1.7114237944285076

Epoch: 6| Step: 2
Training loss: 0.23371034860610962
Validation loss: 1.7337978193836827

Epoch: 6| Step: 3
Training loss: 0.3320739269256592
Validation loss: 1.7310174101142473

Epoch: 6| Step: 4
Training loss: 0.20476830005645752
Validation loss: 1.6791004673127206

Epoch: 6| Step: 5
Training loss: 0.17199349403381348
Validation loss: 1.695190127177905

Epoch: 6| Step: 6
Training loss: 0.2435046136379242
Validation loss: 1.7165061504610124

Epoch: 6| Step: 7
Training loss: 0.42998892068862915
Validation loss: 1.6686003688843019

Epoch: 6| Step: 8
Training loss: 0.1746346801519394
Validation loss: 1.7016288695796844

Epoch: 6| Step: 9
Training loss: 0.3968379497528076
Validation loss: 1.7405560939542708

Epoch: 6| Step: 10
Training loss: 0.12794695794582367
Validation loss: 1.7276842953056417

Epoch: 6| Step: 11
Training loss: 0.2563949227333069
Validation loss: 1.742906625552844

Epoch: 6| Step: 12
Training loss: 0.48521488904953003
Validation loss: 1.7321873659728675

Epoch: 6| Step: 13
Training loss: 0.5191311240196228
Validation loss: 1.734490841947576

Epoch: 342| Step: 0
Training loss: 0.18823112547397614
Validation loss: 1.7607943409232683

Epoch: 6| Step: 1
Training loss: 0.2275463342666626
Validation loss: 1.7999960453279558

Epoch: 6| Step: 2
Training loss: 0.2546788156032562
Validation loss: 1.8411729335784912

Epoch: 6| Step: 3
Training loss: 0.1943097710609436
Validation loss: 1.8138391292223366

Epoch: 6| Step: 4
Training loss: 0.2284289002418518
Validation loss: 1.8317792889892415

Epoch: 6| Step: 5
Training loss: 0.29275184869766235
Validation loss: 1.8501922238257624

Epoch: 6| Step: 6
Training loss: 0.32263270020484924
Validation loss: 1.8100365015768236

Epoch: 6| Step: 7
Training loss: 0.3297285735607147
Validation loss: 1.8006630905212895

Epoch: 6| Step: 8
Training loss: 0.5189940929412842
Validation loss: 1.7568035792278986

Epoch: 6| Step: 9
Training loss: 0.32450252771377563
Validation loss: 1.7677816332027476

Epoch: 6| Step: 10
Training loss: 0.19015657901763916
Validation loss: 1.7631483180548555

Epoch: 6| Step: 11
Training loss: 0.41925185918807983
Validation loss: 1.7397774291294876

Epoch: 6| Step: 12
Training loss: 0.38396307826042175
Validation loss: 1.7295857911468835

Epoch: 6| Step: 13
Training loss: 0.27198469638824463
Validation loss: 1.717776765105545

Epoch: 343| Step: 0
Training loss: 0.19944271445274353
Validation loss: 1.7205035865947764

Epoch: 6| Step: 1
Training loss: 0.15291708707809448
Validation loss: 1.7070243781612766

Epoch: 6| Step: 2
Training loss: 0.23385202884674072
Validation loss: 1.760085254587153

Epoch: 6| Step: 3
Training loss: 0.3247544765472412
Validation loss: 1.761981620583483

Epoch: 6| Step: 4
Training loss: 0.2937719225883484
Validation loss: 1.771592410661841

Epoch: 6| Step: 5
Training loss: 0.4648002088069916
Validation loss: 1.7661450665484193

Epoch: 6| Step: 6
Training loss: 0.32935744524002075
Validation loss: 1.75434281492746

Epoch: 6| Step: 7
Training loss: 0.4418441653251648
Validation loss: 1.7820213430671281

Epoch: 6| Step: 8
Training loss: 0.3635250926017761
Validation loss: 1.7947883836684688

Epoch: 6| Step: 9
Training loss: 0.42082324624061584
Validation loss: 1.8139070221172866

Epoch: 6| Step: 10
Training loss: 0.32887470722198486
Validation loss: 1.8058537026887298

Epoch: 6| Step: 11
Training loss: 0.27879083156585693
Validation loss: 1.7738253493462839

Epoch: 6| Step: 12
Training loss: 0.23229028284549713
Validation loss: 1.7836297596654584

Epoch: 6| Step: 13
Training loss: 0.20365804433822632
Validation loss: 1.754498299732003

Epoch: 344| Step: 0
Training loss: 0.1556047797203064
Validation loss: 1.7505370186221214

Epoch: 6| Step: 1
Training loss: 0.26655301451683044
Validation loss: 1.7469948017469017

Epoch: 6| Step: 2
Training loss: 0.44831740856170654
Validation loss: 1.751544189709489

Epoch: 6| Step: 3
Training loss: 0.35931164026260376
Validation loss: 1.7594594711898475

Epoch: 6| Step: 4
Training loss: 0.6356470584869385
Validation loss: 1.7778350076367777

Epoch: 6| Step: 5
Training loss: 0.32476669549942017
Validation loss: 1.7306078210953744

Epoch: 6| Step: 6
Training loss: 0.30630695819854736
Validation loss: 1.7487162774608982

Epoch: 6| Step: 7
Training loss: 0.10310885310173035
Validation loss: 1.768163743839469

Epoch: 6| Step: 8
Training loss: 0.3255777060985565
Validation loss: 1.8065303602526266

Epoch: 6| Step: 9
Training loss: 0.13002242147922516
Validation loss: 1.7835494459316295

Epoch: 6| Step: 10
Training loss: 0.31703317165374756
Validation loss: 1.8167308722772906

Epoch: 6| Step: 11
Training loss: 0.2331422120332718
Validation loss: 1.8202105619574105

Epoch: 6| Step: 12
Training loss: 0.314281165599823
Validation loss: 1.82929612487875

Epoch: 6| Step: 13
Training loss: 0.14155536890029907
Validation loss: 1.7817920292577436

Epoch: 345| Step: 0
Training loss: 0.3071010112762451
Validation loss: 1.7690399398085892

Epoch: 6| Step: 1
Training loss: 0.38475996255874634
Validation loss: 1.7442390668776728

Epoch: 6| Step: 2
Training loss: 0.2662505507469177
Validation loss: 1.757258120403495

Epoch: 6| Step: 3
Training loss: 0.23814372718334198
Validation loss: 1.7521777627288655

Epoch: 6| Step: 4
Training loss: 0.2917868494987488
Validation loss: 1.750759317028907

Epoch: 6| Step: 5
Training loss: 0.28281351923942566
Validation loss: 1.743412289568173

Epoch: 6| Step: 6
Training loss: 0.1914573609828949
Validation loss: 1.744712548871194

Epoch: 6| Step: 7
Training loss: 0.280805379152298
Validation loss: 1.762377687679824

Epoch: 6| Step: 8
Training loss: 0.214231938123703
Validation loss: 1.7386438359496414

Epoch: 6| Step: 9
Training loss: 0.14756959676742554
Validation loss: 1.7777872662390433

Epoch: 6| Step: 10
Training loss: 0.4848758578300476
Validation loss: 1.733885249783916

Epoch: 6| Step: 11
Training loss: 0.30078476667404175
Validation loss: 1.7743151482715402

Epoch: 6| Step: 12
Training loss: 0.24203673005104065
Validation loss: 1.7649559743942753

Epoch: 6| Step: 13
Training loss: 0.622807502746582
Validation loss: 1.7645033495400542

Epoch: 346| Step: 0
Training loss: 0.18915125727653503
Validation loss: 1.766323169072469

Epoch: 6| Step: 1
Training loss: 0.3065840005874634
Validation loss: 1.7545518900758477

Epoch: 6| Step: 2
Training loss: 0.38886359333992004
Validation loss: 1.7680680303163425

Epoch: 6| Step: 3
Training loss: 0.30338582396507263
Validation loss: 1.736835902737033

Epoch: 6| Step: 4
Training loss: 0.1975453943014145
Validation loss: 1.7531054032746183

Epoch: 6| Step: 5
Training loss: 0.27526557445526123
Validation loss: 1.7672995444267028

Epoch: 6| Step: 6
Training loss: 0.28992897272109985
Validation loss: 1.7589735818165604

Epoch: 6| Step: 7
Training loss: 0.1811690628528595
Validation loss: 1.7762522146265993

Epoch: 6| Step: 8
Training loss: 0.24671606719493866
Validation loss: 1.7911911395288282

Epoch: 6| Step: 9
Training loss: 0.18487432599067688
Validation loss: 1.8229439796939972

Epoch: 6| Step: 10
Training loss: 0.40571296215057373
Validation loss: 1.8115916546954904

Epoch: 6| Step: 11
Training loss: 0.33983203768730164
Validation loss: 1.8186127114039596

Epoch: 6| Step: 12
Training loss: 0.3993529677391052
Validation loss: 1.8034153010255547

Epoch: 6| Step: 13
Training loss: 0.2912576496601105
Validation loss: 1.7832740929818922

Epoch: 347| Step: 0
Training loss: 0.32863670587539673
Validation loss: 1.762921134630839

Epoch: 6| Step: 1
Training loss: 0.3681116998195648
Validation loss: 1.7421685739230084

Epoch: 6| Step: 2
Training loss: 0.339656800031662
Validation loss: 1.723536611885153

Epoch: 6| Step: 3
Training loss: 0.19805967807769775
Validation loss: 1.7183198544286913

Epoch: 6| Step: 4
Training loss: 0.22249501943588257
Validation loss: 1.7026417216947

Epoch: 6| Step: 5
Training loss: 0.368630051612854
Validation loss: 1.7033455884584816

Epoch: 6| Step: 6
Training loss: 0.230620339512825
Validation loss: 1.6992019607174782

Epoch: 6| Step: 7
Training loss: 0.2404513955116272
Validation loss: 1.696355991466071

Epoch: 6| Step: 8
Training loss: 0.17616170644760132
Validation loss: 1.7068261433673162

Epoch: 6| Step: 9
Training loss: 0.21153932809829712
Validation loss: 1.737558768641564

Epoch: 6| Step: 10
Training loss: 0.2174564152956009
Validation loss: 1.7789390125582296

Epoch: 6| Step: 11
Training loss: 0.39646467566490173
Validation loss: 1.7815067268187

Epoch: 6| Step: 12
Training loss: 0.19529056549072266
Validation loss: 1.7685929370182816

Epoch: 6| Step: 13
Training loss: 0.25031810998916626
Validation loss: 1.757615876454179

Epoch: 348| Step: 0
Training loss: 0.39151591062545776
Validation loss: 1.7773709284361972

Epoch: 6| Step: 1
Training loss: 0.1615951955318451
Validation loss: 1.7569911774768625

Epoch: 6| Step: 2
Training loss: 0.23961801826953888
Validation loss: 1.6960158630083966

Epoch: 6| Step: 3
Training loss: 0.24137908220291138
Validation loss: 1.7149848399623748

Epoch: 6| Step: 4
Training loss: 0.20663154125213623
Validation loss: 1.6502249574148526

Epoch: 6| Step: 5
Training loss: 0.3211965560913086
Validation loss: 1.6507966108219598

Epoch: 6| Step: 6
Training loss: 0.1554301232099533
Validation loss: 1.658185774921089

Epoch: 6| Step: 7
Training loss: 0.36578717827796936
Validation loss: 1.6497448887876285

Epoch: 6| Step: 8
Training loss: 0.3827425241470337
Validation loss: 1.6560068771403322

Epoch: 6| Step: 9
Training loss: 0.182687908411026
Validation loss: 1.6819142026285971

Epoch: 6| Step: 10
Training loss: 0.2657662034034729
Validation loss: 1.6744112763353574

Epoch: 6| Step: 11
Training loss: 0.4503049850463867
Validation loss: 1.7177654838049283

Epoch: 6| Step: 12
Training loss: 0.3190953731536865
Validation loss: 1.7080143779836676

Epoch: 6| Step: 13
Training loss: 0.3811641037464142
Validation loss: 1.7444300292640604

Epoch: 349| Step: 0
Training loss: 0.18183094263076782
Validation loss: 1.772070623213245

Epoch: 6| Step: 1
Training loss: 0.16753652691841125
Validation loss: 1.7448389196908602

Epoch: 6| Step: 2
Training loss: 0.2572830319404602
Validation loss: 1.7820855545741257

Epoch: 6| Step: 3
Training loss: 0.1492253988981247
Validation loss: 1.7693155606587727

Epoch: 6| Step: 4
Training loss: 0.258090615272522
Validation loss: 1.7332276221244567

Epoch: 6| Step: 5
Training loss: 0.23944753408432007
Validation loss: 1.7529580131653817

Epoch: 6| Step: 6
Training loss: 0.4195348918437958
Validation loss: 1.7121927943280948

Epoch: 6| Step: 7
Training loss: 0.2439286708831787
Validation loss: 1.6981934001368861

Epoch: 6| Step: 8
Training loss: 0.29859644174575806
Validation loss: 1.729636957568507

Epoch: 6| Step: 9
Training loss: 0.30893784761428833
Validation loss: 1.714750418099024

Epoch: 6| Step: 10
Training loss: 0.27627289295196533
Validation loss: 1.7432747951117895

Epoch: 6| Step: 11
Training loss: 0.3716961145401001
Validation loss: 1.728886253090315

Epoch: 6| Step: 12
Training loss: 0.24383500218391418
Validation loss: 1.7447164443231398

Epoch: 6| Step: 13
Training loss: 0.3385186195373535
Validation loss: 1.7494144926788986

Epoch: 350| Step: 0
Training loss: 0.3142927289009094
Validation loss: 1.7720394621613205

Epoch: 6| Step: 1
Training loss: 0.34969362616539
Validation loss: 1.7428688490262596

Epoch: 6| Step: 2
Training loss: 0.36321568489074707
Validation loss: 1.7637162157284316

Epoch: 6| Step: 3
Training loss: 0.3223777413368225
Validation loss: 1.7462203887201124

Epoch: 6| Step: 4
Training loss: 0.309905081987381
Validation loss: 1.7335564321087253

Epoch: 6| Step: 5
Training loss: 0.30379682779312134
Validation loss: 1.7180982943504088

Epoch: 6| Step: 6
Training loss: 0.18118375539779663
Validation loss: 1.7257852926049182

Epoch: 6| Step: 7
Training loss: 0.22263756394386292
Validation loss: 1.7182228565216064

Epoch: 6| Step: 8
Training loss: 0.2598777413368225
Validation loss: 1.6874096906313332

Epoch: 6| Step: 9
Training loss: 0.3032539486885071
Validation loss: 1.7183841454085482

Epoch: 6| Step: 10
Training loss: 0.18146511912345886
Validation loss: 1.6765944521914247

Epoch: 6| Step: 11
Training loss: 0.381754606962204
Validation loss: 1.661609076684521

Epoch: 6| Step: 12
Training loss: 0.20886719226837158
Validation loss: 1.686132610485118

Epoch: 6| Step: 13
Training loss: 0.2294512838125229
Validation loss: 1.7149707912116923

Epoch: 351| Step: 0
Training loss: 0.29132235050201416
Validation loss: 1.7166888842018702

Epoch: 6| Step: 1
Training loss: 0.15474098920822144
Validation loss: 1.7180768148873442

Epoch: 6| Step: 2
Training loss: 0.20841854810714722
Validation loss: 1.7048331217099262

Epoch: 6| Step: 3
Training loss: 0.2784874141216278
Validation loss: 1.7288006044203235

Epoch: 6| Step: 4
Training loss: 0.26118701696395874
Validation loss: 1.746164350099461

Epoch: 6| Step: 5
Training loss: 0.21699735522270203
Validation loss: 1.742944203397279

Epoch: 6| Step: 6
Training loss: 0.3395354449748993
Validation loss: 1.8077862288362236

Epoch: 6| Step: 7
Training loss: 0.3025946617126465
Validation loss: 1.7343666553497314

Epoch: 6| Step: 8
Training loss: 0.25442570447921753
Validation loss: 1.7479709092006888

Epoch: 6| Step: 9
Training loss: 0.17133605480194092
Validation loss: 1.7577806865015337

Epoch: 6| Step: 10
Training loss: 0.21190427243709564
Validation loss: 1.79635783549278

Epoch: 6| Step: 11
Training loss: 0.23301436007022858
Validation loss: 1.7433430712710145

Epoch: 6| Step: 12
Training loss: 0.3212825059890747
Validation loss: 1.742998461569509

Epoch: 6| Step: 13
Training loss: 0.3640207052230835
Validation loss: 1.7636964859501008

Epoch: 352| Step: 0
Training loss: 0.16482272744178772
Validation loss: 1.7240029868259226

Epoch: 6| Step: 1
Training loss: 0.31128546595573425
Validation loss: 1.7099478962600871

Epoch: 6| Step: 2
Training loss: 0.35544508695602417
Validation loss: 1.747786627020887

Epoch: 6| Step: 3
Training loss: 0.1694517880678177
Validation loss: 1.715119751550818

Epoch: 6| Step: 4
Training loss: 0.20264294743537903
Validation loss: 1.7434060509486864

Epoch: 6| Step: 5
Training loss: 0.4739714562892914
Validation loss: 1.7534608366668865

Epoch: 6| Step: 6
Training loss: 0.26887503266334534
Validation loss: 1.7896216684772122

Epoch: 6| Step: 7
Training loss: 0.28618937730789185
Validation loss: 1.7539463940487112

Epoch: 6| Step: 8
Training loss: 0.28014805912971497
Validation loss: 1.7748800746856197

Epoch: 6| Step: 9
Training loss: 0.296578049659729
Validation loss: 1.7934969984075075

Epoch: 6| Step: 10
Training loss: 0.22879257798194885
Validation loss: 1.7654593965058685

Epoch: 6| Step: 11
Training loss: 0.2437417060136795
Validation loss: 1.7555534339720202

Epoch: 6| Step: 12
Training loss: 0.17128536105155945
Validation loss: 1.7271364312018118

Epoch: 6| Step: 13
Training loss: 0.2712249755859375
Validation loss: 1.728352298018753

Epoch: 353| Step: 0
Training loss: 0.30320119857788086
Validation loss: 1.7485491357823855

Epoch: 6| Step: 1
Training loss: 0.20082736015319824
Validation loss: 1.7324043563617173

Epoch: 6| Step: 2
Training loss: 0.1572585254907608
Validation loss: 1.7018690698890275

Epoch: 6| Step: 3
Training loss: 0.17798063158988953
Validation loss: 1.7146176349732183

Epoch: 6| Step: 4
Training loss: 0.19228820502758026
Validation loss: 1.7142772392560077

Epoch: 6| Step: 5
Training loss: 0.23814016580581665
Validation loss: 1.7322410088713451

Epoch: 6| Step: 6
Training loss: 0.31430450081825256
Validation loss: 1.7524599234263103

Epoch: 6| Step: 7
Training loss: 0.3226434588432312
Validation loss: 1.803168014813495

Epoch: 6| Step: 8
Training loss: 0.36290568113327026
Validation loss: 1.7771009065771615

Epoch: 6| Step: 9
Training loss: 0.38026222586631775
Validation loss: 1.786021774814975

Epoch: 6| Step: 10
Training loss: 0.3151576817035675
Validation loss: 1.7713176742676766

Epoch: 6| Step: 11
Training loss: 0.2958400249481201
Validation loss: 1.7460462457390242

Epoch: 6| Step: 12
Training loss: 0.23844531178474426
Validation loss: 1.745240674223951

Epoch: 6| Step: 13
Training loss: 0.4228977560997009
Validation loss: 1.7470598784826135

Epoch: 354| Step: 0
Training loss: 0.23376911878585815
Validation loss: 1.712826516038628

Epoch: 6| Step: 1
Training loss: 0.2716250419616699
Validation loss: 1.7022690657646424

Epoch: 6| Step: 2
Training loss: 0.14533163607120514
Validation loss: 1.6721456275191358

Epoch: 6| Step: 3
Training loss: 0.22901394963264465
Validation loss: 1.6605898154679166

Epoch: 6| Step: 4
Training loss: 0.4454416036605835
Validation loss: 1.6534651812686716

Epoch: 6| Step: 5
Training loss: 0.2647398114204407
Validation loss: 1.655042750861055

Epoch: 6| Step: 6
Training loss: 0.33309805393218994
Validation loss: 1.6682019778477248

Epoch: 6| Step: 7
Training loss: 0.17294970154762268
Validation loss: 1.6577548788439842

Epoch: 6| Step: 8
Training loss: 0.2474212348461151
Validation loss: 1.6693031454599032

Epoch: 6| Step: 9
Training loss: 0.22859808802604675
Validation loss: 1.6620910616331204

Epoch: 6| Step: 10
Training loss: 0.24189919233322144
Validation loss: 1.6720403163663802

Epoch: 6| Step: 11
Training loss: 0.36083054542541504
Validation loss: 1.6759468483668503

Epoch: 6| Step: 12
Training loss: 0.23884697258472443
Validation loss: 1.701869474944248

Epoch: 6| Step: 13
Training loss: 0.4394286870956421
Validation loss: 1.7173039887541084

Epoch: 355| Step: 0
Training loss: 0.24513569474220276
Validation loss: 1.7417333946433118

Epoch: 6| Step: 1
Training loss: 0.3039575219154358
Validation loss: 1.757952013323384

Epoch: 6| Step: 2
Training loss: 0.25326085090637207
Validation loss: 1.7406723653116534

Epoch: 6| Step: 3
Training loss: 0.19626262784004211
Validation loss: 1.7329255611665788

Epoch: 6| Step: 4
Training loss: 0.33440911769866943
Validation loss: 1.727371383738774

Epoch: 6| Step: 5
Training loss: 0.22510233521461487
Validation loss: 1.7025730622712003

Epoch: 6| Step: 6
Training loss: 0.5770182013511658
Validation loss: 1.7259404018361082

Epoch: 6| Step: 7
Training loss: 0.26784688234329224
Validation loss: 1.7127418479611796

Epoch: 6| Step: 8
Training loss: 0.19328804314136505
Validation loss: 1.718267394650367

Epoch: 6| Step: 9
Training loss: 0.1785009801387787
Validation loss: 1.7162352377368557

Epoch: 6| Step: 10
Training loss: 0.1211714893579483
Validation loss: 1.6999137555399249

Epoch: 6| Step: 11
Training loss: 0.32476186752319336
Validation loss: 1.7478510308009323

Epoch: 6| Step: 12
Training loss: 0.15461166203022003
Validation loss: 1.697249230518136

Epoch: 6| Step: 13
Training loss: 0.35681530833244324
Validation loss: 1.7218656911644885

Epoch: 356| Step: 0
Training loss: 0.3775767683982849
Validation loss: 1.7042411040234309

Epoch: 6| Step: 1
Training loss: 0.26536452770233154
Validation loss: 1.7321295110128259

Epoch: 6| Step: 2
Training loss: 0.29454588890075684
Validation loss: 1.7417187049824705

Epoch: 6| Step: 3
Training loss: 0.1910955160856247
Validation loss: 1.7630632244130617

Epoch: 6| Step: 4
Training loss: 0.21472646296024323
Validation loss: 1.80768879254659

Epoch: 6| Step: 5
Training loss: 0.38267165422439575
Validation loss: 1.7748691343492078

Epoch: 6| Step: 6
Training loss: 0.22083815932273865
Validation loss: 1.792639619560652

Epoch: 6| Step: 7
Training loss: 0.20746663212776184
Validation loss: 1.7746390911840624

Epoch: 6| Step: 8
Training loss: 0.2651968002319336
Validation loss: 1.8162849526251517

Epoch: 6| Step: 9
Training loss: 0.2241891324520111
Validation loss: 1.7809803652507004

Epoch: 6| Step: 10
Training loss: 0.2514634132385254
Validation loss: 1.7881689174200899

Epoch: 6| Step: 11
Training loss: 0.13986079394817352
Validation loss: 1.772600067559109

Epoch: 6| Step: 12
Training loss: 0.23334315419197083
Validation loss: 1.75371426920737

Epoch: 6| Step: 13
Training loss: 0.34751996397972107
Validation loss: 1.7703662405731857

Epoch: 357| Step: 0
Training loss: 0.5094442963600159
Validation loss: 1.7582741065691876

Epoch: 6| Step: 1
Training loss: 0.17031538486480713
Validation loss: 1.7498511024700698

Epoch: 6| Step: 2
Training loss: 0.29121047258377075
Validation loss: 1.7550009194240774

Epoch: 6| Step: 3
Training loss: 0.25997376441955566
Validation loss: 1.7469977422427105

Epoch: 6| Step: 4
Training loss: 0.191205233335495
Validation loss: 1.7739799663584719

Epoch: 6| Step: 5
Training loss: 0.16486307978630066
Validation loss: 1.7543782854592929

Epoch: 6| Step: 6
Training loss: 0.1496935784816742
Validation loss: 1.7327159937991892

Epoch: 6| Step: 7
Training loss: 0.24138440191745758
Validation loss: 1.7133634564697102

Epoch: 6| Step: 8
Training loss: 0.3881787061691284
Validation loss: 1.7209175876391831

Epoch: 6| Step: 9
Training loss: 0.18206100165843964
Validation loss: 1.7295827147781209

Epoch: 6| Step: 10
Training loss: 0.20977705717086792
Validation loss: 1.741777728962642

Epoch: 6| Step: 11
Training loss: 0.14552192389965057
Validation loss: 1.7270839022051903

Epoch: 6| Step: 12
Training loss: 0.19069305062294006
Validation loss: 1.745648976295225

Epoch: 6| Step: 13
Training loss: 0.20496171712875366
Validation loss: 1.7214345406460505

Epoch: 358| Step: 0
Training loss: 0.1987529844045639
Validation loss: 1.7206098905173681

Epoch: 6| Step: 1
Training loss: 0.19997695088386536
Validation loss: 1.7474526769371443

Epoch: 6| Step: 2
Training loss: 0.30920860171318054
Validation loss: 1.7727915381872525

Epoch: 6| Step: 3
Training loss: 0.3280881941318512
Validation loss: 1.7456817114224998

Epoch: 6| Step: 4
Training loss: 0.1851654350757599
Validation loss: 1.7240838901970976

Epoch: 6| Step: 5
Training loss: 0.196549192070961
Validation loss: 1.7582534718257126

Epoch: 6| Step: 6
Training loss: 0.2513085901737213
Validation loss: 1.718087952624085

Epoch: 6| Step: 7
Training loss: 0.20932158827781677
Validation loss: 1.7313467200084398

Epoch: 6| Step: 8
Training loss: 0.1729564368724823
Validation loss: 1.723656415939331

Epoch: 6| Step: 9
Training loss: 0.1761820912361145
Validation loss: 1.7442473801233436

Epoch: 6| Step: 10
Training loss: 0.15708905458450317
Validation loss: 1.7729243373358121

Epoch: 6| Step: 11
Training loss: 0.40939784049987793
Validation loss: 1.775075263874505

Epoch: 6| Step: 12
Training loss: 0.3749157786369324
Validation loss: 1.807057201221425

Epoch: 6| Step: 13
Training loss: 0.18834945559501648
Validation loss: 1.8326867459922709

Epoch: 359| Step: 0
Training loss: 0.26464253664016724
Validation loss: 1.8099644517385831

Epoch: 6| Step: 1
Training loss: 0.2707194685935974
Validation loss: 1.7893247283915037

Epoch: 6| Step: 2
Training loss: 0.23731233179569244
Validation loss: 1.8163759964768604

Epoch: 6| Step: 3
Training loss: 0.3049778640270233
Validation loss: 1.7725414588887205

Epoch: 6| Step: 4
Training loss: 0.21461576223373413
Validation loss: 1.7884519741099367

Epoch: 6| Step: 5
Training loss: 0.28554028272628784
Validation loss: 1.7343440068665372

Epoch: 6| Step: 6
Training loss: 0.19644851982593536
Validation loss: 1.6927037367256739

Epoch: 6| Step: 7
Training loss: 0.28178322315216064
Validation loss: 1.7457488736798685

Epoch: 6| Step: 8
Training loss: 0.33842170238494873
Validation loss: 1.7160705789442985

Epoch: 6| Step: 9
Training loss: 0.19885653257369995
Validation loss: 1.7229709445789296

Epoch: 6| Step: 10
Training loss: 0.1836247593164444
Validation loss: 1.7407538993384248

Epoch: 6| Step: 11
Training loss: 0.2694282829761505
Validation loss: 1.731861013238148

Epoch: 6| Step: 12
Training loss: 0.2641119658946991
Validation loss: 1.748238863483552

Epoch: 6| Step: 13
Training loss: 0.11892468482255936
Validation loss: 1.7669106837241881

Epoch: 360| Step: 0
Training loss: 0.22752316296100616
Validation loss: 1.743687787363606

Epoch: 6| Step: 1
Training loss: 0.22900977730751038
Validation loss: 1.7574136116171395

Epoch: 6| Step: 2
Training loss: 0.1330503523349762
Validation loss: 1.796794665757046

Epoch: 6| Step: 3
Training loss: 0.18946155905723572
Validation loss: 1.822326954974923

Epoch: 6| Step: 4
Training loss: 0.30945974588394165
Validation loss: 1.794191837310791

Epoch: 6| Step: 5
Training loss: 0.22765690088272095
Validation loss: 1.7830549209348616

Epoch: 6| Step: 6
Training loss: 0.3143143653869629
Validation loss: 1.7471388334869056

Epoch: 6| Step: 7
Training loss: 0.5049570798873901
Validation loss: 1.736016422189692

Epoch: 6| Step: 8
Training loss: 0.2058698832988739
Validation loss: 1.7248318708071144

Epoch: 6| Step: 9
Training loss: 0.3416867256164551
Validation loss: 1.6395898813842444

Epoch: 6| Step: 10
Training loss: 0.33598560094833374
Validation loss: 1.6433527213270946

Epoch: 6| Step: 11
Training loss: 0.1935061812400818
Validation loss: 1.6632181970022057

Epoch: 6| Step: 12
Training loss: 0.20047765970230103
Validation loss: 1.723115195510208

Epoch: 6| Step: 13
Training loss: 0.0751148983836174
Validation loss: 1.6614066080380512

Epoch: 361| Step: 0
Training loss: 0.26603350043296814
Validation loss: 1.7038516383017264

Epoch: 6| Step: 1
Training loss: 0.20001351833343506
Validation loss: 1.686785864573653

Epoch: 6| Step: 2
Training loss: 0.2103343904018402
Validation loss: 1.6919368620841735

Epoch: 6| Step: 3
Training loss: 0.25391700863838196
Validation loss: 1.7554048479244273

Epoch: 6| Step: 4
Training loss: 0.23821699619293213
Validation loss: 1.7446407887243456

Epoch: 6| Step: 5
Training loss: 0.31989288330078125
Validation loss: 1.7184996297282558

Epoch: 6| Step: 6
Training loss: 0.12508970499038696
Validation loss: 1.714484425001247

Epoch: 6| Step: 7
Training loss: 0.2797635495662689
Validation loss: 1.7340107733203518

Epoch: 6| Step: 8
Training loss: 0.1591869294643402
Validation loss: 1.761392875384259

Epoch: 6| Step: 9
Training loss: 0.49558162689208984
Validation loss: 1.8174608010117725

Epoch: 6| Step: 10
Training loss: 0.23445439338684082
Validation loss: 1.7831127182129891

Epoch: 6| Step: 11
Training loss: 0.19654670357704163
Validation loss: 1.7976910170688425

Epoch: 6| Step: 12
Training loss: 0.3373245894908905
Validation loss: 1.7913187524323821

Epoch: 6| Step: 13
Training loss: 0.20703496038913727
Validation loss: 1.7623118136518745

Epoch: 362| Step: 0
Training loss: 0.13804039359092712
Validation loss: 1.7310526524820635

Epoch: 6| Step: 1
Training loss: 0.2867288589477539
Validation loss: 1.741632152629155

Epoch: 6| Step: 2
Training loss: 0.32670679688453674
Validation loss: 1.716115044009301

Epoch: 6| Step: 3
Training loss: 0.15815715491771698
Validation loss: 1.7040547324765114

Epoch: 6| Step: 4
Training loss: 0.31196242570877075
Validation loss: 1.6850924056063417

Epoch: 6| Step: 5
Training loss: 0.26342839002609253
Validation loss: 1.6783124631451023

Epoch: 6| Step: 6
Training loss: 0.3037600517272949
Validation loss: 1.6586222238438104

Epoch: 6| Step: 7
Training loss: 0.4001510441303253
Validation loss: 1.6893975709074287

Epoch: 6| Step: 8
Training loss: 0.14382021129131317
Validation loss: 1.721124525993101

Epoch: 6| Step: 9
Training loss: 0.4843459129333496
Validation loss: 1.740045105257342

Epoch: 6| Step: 10
Training loss: 0.17021745443344116
Validation loss: 1.808931876254338

Epoch: 6| Step: 11
Training loss: 0.23645247519016266
Validation loss: 1.7835730000208783

Epoch: 6| Step: 12
Training loss: 0.2810758352279663
Validation loss: 1.7559944737342097

Epoch: 6| Step: 13
Training loss: 0.09712089598178864
Validation loss: 1.72751199430035

Epoch: 363| Step: 0
Training loss: 0.2524505853652954
Validation loss: 1.7064256821909258

Epoch: 6| Step: 1
Training loss: 0.30118659138679504
Validation loss: 1.7477939532649132

Epoch: 6| Step: 2
Training loss: 0.48401251435279846
Validation loss: 1.7369837568652244

Epoch: 6| Step: 3
Training loss: 0.3828062117099762
Validation loss: 1.7814843372632099

Epoch: 6| Step: 4
Training loss: 0.27494025230407715
Validation loss: 1.7156459631458405

Epoch: 6| Step: 5
Training loss: 0.18574318289756775
Validation loss: 1.7150614364172823

Epoch: 6| Step: 6
Training loss: 0.22631126642227173
Validation loss: 1.7070083105435936

Epoch: 6| Step: 7
Training loss: 0.2084764689207077
Validation loss: 1.7225258529827159

Epoch: 6| Step: 8
Training loss: 0.15702712535858154
Validation loss: 1.7369018870015298

Epoch: 6| Step: 9
Training loss: 0.29075849056243896
Validation loss: 1.7454847969034666

Epoch: 6| Step: 10
Training loss: 0.2590632140636444
Validation loss: 1.7484415397849133

Epoch: 6| Step: 11
Training loss: 0.15623730421066284
Validation loss: 1.716652944523801

Epoch: 6| Step: 12
Training loss: 0.16896072030067444
Validation loss: 1.721591841789984

Epoch: 6| Step: 13
Training loss: 0.16494889557361603
Validation loss: 1.7346083143705964

Epoch: 364| Step: 0
Training loss: 0.18459516763687134
Validation loss: 1.7619561713228944

Epoch: 6| Step: 1
Training loss: 0.26776498556137085
Validation loss: 1.7647221831865207

Epoch: 6| Step: 2
Training loss: 0.5143368244171143
Validation loss: 1.7548041664144045

Epoch: 6| Step: 3
Training loss: 0.35164350271224976
Validation loss: 1.7512678869308964

Epoch: 6| Step: 4
Training loss: 0.3021409809589386
Validation loss: 1.7553210053392636

Epoch: 6| Step: 5
Training loss: 0.1896428018808365
Validation loss: 1.7856425469921482

Epoch: 6| Step: 6
Training loss: 0.25994572043418884
Validation loss: 1.6953243363288142

Epoch: 6| Step: 7
Training loss: 0.23334501683712006
Validation loss: 1.7210290688340382

Epoch: 6| Step: 8
Training loss: 0.2092999368906021
Validation loss: 1.7186771118512718

Epoch: 6| Step: 9
Training loss: 0.22442099452018738
Validation loss: 1.7411441572250859

Epoch: 6| Step: 10
Training loss: 0.16571678221225739
Validation loss: 1.7346460344970867

Epoch: 6| Step: 11
Training loss: 0.08433505892753601
Validation loss: 1.7310675908160467

Epoch: 6| Step: 12
Training loss: 0.33350443840026855
Validation loss: 1.7936379550605692

Epoch: 6| Step: 13
Training loss: 0.31441810727119446
Validation loss: 1.786318241908986

Epoch: 365| Step: 0
Training loss: 0.3284129798412323
Validation loss: 1.8056327591660202

Epoch: 6| Step: 1
Training loss: 0.22569631040096283
Validation loss: 1.7900184021201184

Epoch: 6| Step: 2
Training loss: 0.31558796763420105
Validation loss: 1.768705879488299

Epoch: 6| Step: 3
Training loss: 0.39383625984191895
Validation loss: 1.7240678264248757

Epoch: 6| Step: 4
Training loss: 0.12402232736349106
Validation loss: 1.6888910903725574

Epoch: 6| Step: 5
Training loss: 0.2935430109500885
Validation loss: 1.699269825412381

Epoch: 6| Step: 6
Training loss: 0.2023237645626068
Validation loss: 1.688021432968878

Epoch: 6| Step: 7
Training loss: 0.3718363642692566
Validation loss: 1.673018132486651

Epoch: 6| Step: 8
Training loss: 0.23851853609085083
Validation loss: 1.6833726872680008

Epoch: 6| Step: 9
Training loss: 0.20320439338684082
Validation loss: 1.6905124482288156

Epoch: 6| Step: 10
Training loss: 0.2706443965435028
Validation loss: 1.7236968573703562

Epoch: 6| Step: 11
Training loss: 0.3076131343841553
Validation loss: 1.7231051524480183

Epoch: 6| Step: 12
Training loss: 0.23112305998802185
Validation loss: 1.6894292901921015

Epoch: 6| Step: 13
Training loss: 0.2413480579853058
Validation loss: 1.6620853998327767

Epoch: 366| Step: 0
Training loss: 0.19855034351348877
Validation loss: 1.6889868936231058

Epoch: 6| Step: 1
Training loss: 0.22646993398666382
Validation loss: 1.7111009807996853

Epoch: 6| Step: 2
Training loss: 0.28265511989593506
Validation loss: 1.7277834389799385

Epoch: 6| Step: 3
Training loss: 0.31704646348953247
Validation loss: 1.7511404265639603

Epoch: 6| Step: 4
Training loss: 0.2923690676689148
Validation loss: 1.743520321384553

Epoch: 6| Step: 5
Training loss: 0.14601503312587738
Validation loss: 1.7743476129347278

Epoch: 6| Step: 6
Training loss: 0.18261659145355225
Validation loss: 1.7533432206799906

Epoch: 6| Step: 7
Training loss: 0.10604582726955414
Validation loss: 1.809526881863994

Epoch: 6| Step: 8
Training loss: 0.23307354748249054
Validation loss: 1.7770251663782264

Epoch: 6| Step: 9
Training loss: 0.23047369718551636
Validation loss: 1.7591680108859975

Epoch: 6| Step: 10
Training loss: 0.24480722844600677
Validation loss: 1.7247567663910568

Epoch: 6| Step: 11
Training loss: 0.24421674013137817
Validation loss: 1.7107345058071999

Epoch: 6| Step: 12
Training loss: 0.3576478958129883
Validation loss: 1.6870076348704677

Epoch: 6| Step: 13
Training loss: 0.1861143410205841
Validation loss: 1.7011551241720877

Epoch: 367| Step: 0
Training loss: 0.38541504740715027
Validation loss: 1.7644109520860898

Epoch: 6| Step: 1
Training loss: 0.27952122688293457
Validation loss: 1.7486806172196583

Epoch: 6| Step: 2
Training loss: 0.3944510519504547
Validation loss: 1.768544472673888

Epoch: 6| Step: 3
Training loss: 0.14641405642032623
Validation loss: 1.8106043543866885

Epoch: 6| Step: 4
Training loss: 0.291197806596756
Validation loss: 1.819995762199484

Epoch: 6| Step: 5
Training loss: 0.17817287147045135
Validation loss: 1.809498853580926

Epoch: 6| Step: 6
Training loss: 0.1325126588344574
Validation loss: 1.7827904557669034

Epoch: 6| Step: 7
Training loss: 0.21536913514137268
Validation loss: 1.7939123697178339

Epoch: 6| Step: 8
Training loss: 0.18906550109386444
Validation loss: 1.7602614177170621

Epoch: 6| Step: 9
Training loss: 0.23795729875564575
Validation loss: 1.7262621656540902

Epoch: 6| Step: 10
Training loss: 0.25759264826774597
Validation loss: 1.69629535623776

Epoch: 6| Step: 11
Training loss: 0.23898082971572876
Validation loss: 1.6839674544590775

Epoch: 6| Step: 12
Training loss: 0.24343803524971008
Validation loss: 1.650000162022088

Epoch: 6| Step: 13
Training loss: 0.27215784788131714
Validation loss: 1.6064790916699234

Epoch: 368| Step: 0
Training loss: 0.3686980605125427
Validation loss: 1.6193578563710695

Epoch: 6| Step: 1
Training loss: 0.30011019110679626
Validation loss: 1.5956400748222106

Epoch: 6| Step: 2
Training loss: 0.2736057937145233
Validation loss: 1.6009850271286503

Epoch: 6| Step: 3
Training loss: 0.33207058906555176
Validation loss: 1.6068055783548663

Epoch: 6| Step: 4
Training loss: 0.36113056540489197
Validation loss: 1.6306892761620142

Epoch: 6| Step: 5
Training loss: 0.30569738149642944
Validation loss: 1.6949312276737665

Epoch: 6| Step: 6
Training loss: 0.11800523102283478
Validation loss: 1.7119702780118553

Epoch: 6| Step: 7
Training loss: 0.19988828897476196
Validation loss: 1.6983198606839744

Epoch: 6| Step: 8
Training loss: 0.2676420509815216
Validation loss: 1.759930504265652

Epoch: 6| Step: 9
Training loss: 0.27657318115234375
Validation loss: 1.734297239652244

Epoch: 6| Step: 10
Training loss: 0.18560098111629486
Validation loss: 1.749523196169125

Epoch: 6| Step: 11
Training loss: 0.08725515007972717
Validation loss: 1.7262926165775587

Epoch: 6| Step: 12
Training loss: 0.2064249962568283
Validation loss: 1.7261769726712217

Epoch: 6| Step: 13
Training loss: 0.14150184392929077
Validation loss: 1.6846021830394704

Epoch: 369| Step: 0
Training loss: 0.1258167028427124
Validation loss: 1.6850539920150593

Epoch: 6| Step: 1
Training loss: 0.32176780700683594
Validation loss: 1.6974100323133572

Epoch: 6| Step: 2
Training loss: 0.3330814242362976
Validation loss: 1.691415197105818

Epoch: 6| Step: 3
Training loss: 0.3349624276161194
Validation loss: 1.6883643814312514

Epoch: 6| Step: 4
Training loss: 0.25225478410720825
Validation loss: 1.706067580048756

Epoch: 6| Step: 5
Training loss: 0.21616888046264648
Validation loss: 1.7187275091807048

Epoch: 6| Step: 6
Training loss: 0.22731846570968628
Validation loss: 1.7042609773656374

Epoch: 6| Step: 7
Training loss: 0.2159285694360733
Validation loss: 1.6973681321708105

Epoch: 6| Step: 8
Training loss: 0.15367491543293
Validation loss: 1.7719883739307363

Epoch: 6| Step: 9
Training loss: 0.18267276883125305
Validation loss: 1.6932056437256515

Epoch: 6| Step: 10
Training loss: 0.19101303815841675
Validation loss: 1.7008471873498732

Epoch: 6| Step: 11
Training loss: 0.23234900832176208
Validation loss: 1.7373380302101054

Epoch: 6| Step: 12
Training loss: 0.23310191929340363
Validation loss: 1.716493848831423

Epoch: 6| Step: 13
Training loss: 0.2469908893108368
Validation loss: 1.7634690359074583

Epoch: 370| Step: 0
Training loss: 0.13794752955436707
Validation loss: 1.7288499615525688

Epoch: 6| Step: 1
Training loss: 0.24627220630645752
Validation loss: 1.7663292590007986

Epoch: 6| Step: 2
Training loss: 0.20980925858020782
Validation loss: 1.7604702518832298

Epoch: 6| Step: 3
Training loss: 0.18752026557922363
Validation loss: 1.787533220424447

Epoch: 6| Step: 4
Training loss: 0.146738201379776
Validation loss: 1.7780739607349518

Epoch: 6| Step: 5
Training loss: 0.12598437070846558
Validation loss: 1.7623200262746503

Epoch: 6| Step: 6
Training loss: 0.17635348439216614
Validation loss: 1.7457320779882453

Epoch: 6| Step: 7
Training loss: 0.3945314884185791
Validation loss: 1.7617500930704095

Epoch: 6| Step: 8
Training loss: 0.22891981899738312
Validation loss: 1.747392435227671

Epoch: 6| Step: 9
Training loss: 0.27391317486763
Validation loss: 1.7503567895581644

Epoch: 6| Step: 10
Training loss: 0.24701853096485138
Validation loss: 1.7797764129536127

Epoch: 6| Step: 11
Training loss: 0.28268885612487793
Validation loss: 1.7665027149261967

Epoch: 6| Step: 12
Training loss: 0.29584115743637085
Validation loss: 1.7321637958608649

Epoch: 6| Step: 13
Training loss: 0.18776601552963257
Validation loss: 1.7208146523403864

Epoch: 371| Step: 0
Training loss: 0.42712080478668213
Validation loss: 1.7119030503816501

Epoch: 6| Step: 1
Training loss: 0.1863224357366562
Validation loss: 1.6968893517730057

Epoch: 6| Step: 2
Training loss: 0.15722867846488953
Validation loss: 1.69634735456077

Epoch: 6| Step: 3
Training loss: 0.15929773449897766
Validation loss: 1.706155595599964

Epoch: 6| Step: 4
Training loss: 0.26704633235931396
Validation loss: 1.711535192305042

Epoch: 6| Step: 5
Training loss: 0.11670994013547897
Validation loss: 1.7132244558744534

Epoch: 6| Step: 6
Training loss: 0.19807319343090057
Validation loss: 1.72235704493779

Epoch: 6| Step: 7
Training loss: 0.2237706184387207
Validation loss: 1.7157247374134679

Epoch: 6| Step: 8
Training loss: 0.33539605140686035
Validation loss: 1.7079673620962328

Epoch: 6| Step: 9
Training loss: 0.28311485052108765
Validation loss: 1.6936960553610196

Epoch: 6| Step: 10
Training loss: 0.2312130182981491
Validation loss: 1.6575589333811114

Epoch: 6| Step: 11
Training loss: 0.23331287503242493
Validation loss: 1.7053062595346922

Epoch: 6| Step: 12
Training loss: 0.16775071620941162
Validation loss: 1.6741627313757454

Epoch: 6| Step: 13
Training loss: 0.3282844126224518
Validation loss: 1.6453198258594801

Epoch: 372| Step: 0
Training loss: 0.18475961685180664
Validation loss: 1.6606161440572431

Epoch: 6| Step: 1
Training loss: 0.20587864518165588
Validation loss: 1.67255828713858

Epoch: 6| Step: 2
Training loss: 0.19388848543167114
Validation loss: 1.6628782223629694

Epoch: 6| Step: 3
Training loss: 0.28270894289016724
Validation loss: 1.691284171996578

Epoch: 6| Step: 4
Training loss: 0.3689267635345459
Validation loss: 1.6884213019442815

Epoch: 6| Step: 5
Training loss: 0.45438703894615173
Validation loss: 1.7191964272529847

Epoch: 6| Step: 6
Training loss: 0.35010915994644165
Validation loss: 1.705697992796539

Epoch: 6| Step: 7
Training loss: 0.2387162148952484
Validation loss: 1.7164887125774095

Epoch: 6| Step: 8
Training loss: 0.2873237133026123
Validation loss: 1.7107096423384964

Epoch: 6| Step: 9
Training loss: 0.17384499311447144
Validation loss: 1.7601354968163274

Epoch: 6| Step: 10
Training loss: 0.26178818941116333
Validation loss: 1.7513262917918544

Epoch: 6| Step: 11
Training loss: 0.24456629157066345
Validation loss: 1.7235200482030069

Epoch: 6| Step: 12
Training loss: 0.11690184473991394
Validation loss: 1.7052380077300533

Epoch: 6| Step: 13
Training loss: 0.19705359637737274
Validation loss: 1.7324499468649588

Epoch: 373| Step: 0
Training loss: 0.20856031775474548
Validation loss: 1.7419857863456971

Epoch: 6| Step: 1
Training loss: 0.2641022503376007
Validation loss: 1.7591979542086202

Epoch: 6| Step: 2
Training loss: 0.40185272693634033
Validation loss: 1.770685798378401

Epoch: 6| Step: 3
Training loss: 0.28378698229789734
Validation loss: 1.7550012321882351

Epoch: 6| Step: 4
Training loss: 0.23963141441345215
Validation loss: 1.7063597043355305

Epoch: 6| Step: 5
Training loss: 0.2516483664512634
Validation loss: 1.7040129271886681

Epoch: 6| Step: 6
Training loss: 0.2775232195854187
Validation loss: 1.7599151775401125

Epoch: 6| Step: 7
Training loss: 0.1686507761478424
Validation loss: 1.7271629866733347

Epoch: 6| Step: 8
Training loss: 0.2797660529613495
Validation loss: 1.7574746506188506

Epoch: 6| Step: 9
Training loss: 0.17642371356487274
Validation loss: 1.7447014085708126

Epoch: 6| Step: 10
Training loss: 0.302188515663147
Validation loss: 1.738688035677838

Epoch: 6| Step: 11
Training loss: 0.13929501175880432
Validation loss: 1.758286831199482

Epoch: 6| Step: 12
Training loss: 0.2065712809562683
Validation loss: 1.707820212969216

Epoch: 6| Step: 13
Training loss: 0.26808813214302063
Validation loss: 1.725919641474242

Epoch: 374| Step: 0
Training loss: 0.35966745018959045
Validation loss: 1.7235627661469162

Epoch: 6| Step: 1
Training loss: 0.17954449355602264
Validation loss: 1.7074659050151866

Epoch: 6| Step: 2
Training loss: 0.2180401086807251
Validation loss: 1.6929362025312198

Epoch: 6| Step: 3
Training loss: 0.36169305443763733
Validation loss: 1.706564393094791

Epoch: 6| Step: 4
Training loss: 0.22914279997348785
Validation loss: 1.6751351343688143

Epoch: 6| Step: 5
Training loss: 0.23382902145385742
Validation loss: 1.7097980476194812

Epoch: 6| Step: 6
Training loss: 0.27473485469818115
Validation loss: 1.6944675471193047

Epoch: 6| Step: 7
Training loss: 0.2894066572189331
Validation loss: 1.6810029604101693

Epoch: 6| Step: 8
Training loss: 0.2169170081615448
Validation loss: 1.6870938308777348

Epoch: 6| Step: 9
Training loss: 0.19558501243591309
Validation loss: 1.6976693304636146

Epoch: 6| Step: 10
Training loss: 0.17327041923999786
Validation loss: 1.679458386154585

Epoch: 6| Step: 11
Training loss: 0.12640005350112915
Validation loss: 1.6609306925086564

Epoch: 6| Step: 12
Training loss: 0.25057482719421387
Validation loss: 1.680695438897738

Epoch: 6| Step: 13
Training loss: 0.23713988065719604
Validation loss: 1.6592121790814143

Epoch: 375| Step: 0
Training loss: 0.32143378257751465
Validation loss: 1.6852801974101732

Epoch: 6| Step: 1
Training loss: 0.1092260405421257
Validation loss: 1.6964407037663203

Epoch: 6| Step: 2
Training loss: 0.2756193280220032
Validation loss: 1.6649560466889413

Epoch: 6| Step: 3
Training loss: 0.19284602999687195
Validation loss: 1.703293223534861

Epoch: 6| Step: 4
Training loss: 0.3440214991569519
Validation loss: 1.6537190227098362

Epoch: 6| Step: 5
Training loss: 0.23952877521514893
Validation loss: 1.6900486356468611

Epoch: 6| Step: 6
Training loss: 0.23571613430976868
Validation loss: 1.672641779786797

Epoch: 6| Step: 7
Training loss: 0.2244410216808319
Validation loss: 1.7220231871451102

Epoch: 6| Step: 8
Training loss: 0.2383483499288559
Validation loss: 1.6885150171095324

Epoch: 6| Step: 9
Training loss: 0.21682485938072205
Validation loss: 1.7145598396178214

Epoch: 6| Step: 10
Training loss: 0.2990787625312805
Validation loss: 1.708094145662041

Epoch: 6| Step: 11
Training loss: 0.21194341778755188
Validation loss: 1.7017056121621081

Epoch: 6| Step: 12
Training loss: 0.19431030750274658
Validation loss: 1.7475598345520675

Epoch: 6| Step: 13
Training loss: 0.4617515206336975
Validation loss: 1.738755162044238

Epoch: 376| Step: 0
Training loss: 0.15393006801605225
Validation loss: 1.7437709762204079

Epoch: 6| Step: 1
Training loss: 0.13355237245559692
Validation loss: 1.7453569622449978

Epoch: 6| Step: 2
Training loss: 0.451578289270401
Validation loss: 1.7622505272588422

Epoch: 6| Step: 3
Training loss: 0.21830309927463531
Validation loss: 1.7878725015988914

Epoch: 6| Step: 4
Training loss: 0.20042046904563904
Validation loss: 1.7355107671471053

Epoch: 6| Step: 5
Training loss: 0.17385759949684143
Validation loss: 1.7803001839627501

Epoch: 6| Step: 6
Training loss: 0.24663551151752472
Validation loss: 1.768308606199039

Epoch: 6| Step: 7
Training loss: 0.31156671047210693
Validation loss: 1.7652006764565744

Epoch: 6| Step: 8
Training loss: 0.22052426636219025
Validation loss: 1.7591017484664917

Epoch: 6| Step: 9
Training loss: 0.17626771330833435
Validation loss: 1.7550709350134737

Epoch: 6| Step: 10
Training loss: 0.28956112265586853
Validation loss: 1.7422549186214324

Epoch: 6| Step: 11
Training loss: 0.31722718477249146
Validation loss: 1.7350554517520371

Epoch: 6| Step: 12
Training loss: 0.16705243289470673
Validation loss: 1.7216658925497403

Epoch: 6| Step: 13
Training loss: 0.22122585773468018
Validation loss: 1.6751518794285354

Epoch: 377| Step: 0
Training loss: 0.19208556413650513
Validation loss: 1.664792263379661

Epoch: 6| Step: 1
Training loss: 0.2554183006286621
Validation loss: 1.6346332629521687

Epoch: 6| Step: 2
Training loss: 0.23705410957336426
Validation loss: 1.6219596939702188

Epoch: 6| Step: 3
Training loss: 0.28800052404403687
Validation loss: 1.6221079518718104

Epoch: 6| Step: 4
Training loss: 0.3259073495864868
Validation loss: 1.601111663285122

Epoch: 6| Step: 5
Training loss: 0.3674769997596741
Validation loss: 1.6333599052121561

Epoch: 6| Step: 6
Training loss: 0.236773282289505
Validation loss: 1.668063235539262

Epoch: 6| Step: 7
Training loss: 0.4262743294239044
Validation loss: 1.6804125424354308

Epoch: 6| Step: 8
Training loss: 0.18621109426021576
Validation loss: 1.6952003830222673

Epoch: 6| Step: 9
Training loss: 0.19920872151851654
Validation loss: 1.7085565578552984

Epoch: 6| Step: 10
Training loss: 0.2616499066352844
Validation loss: 1.7860995249081684

Epoch: 6| Step: 11
Training loss: 0.190392404794693
Validation loss: 1.7741839244801512

Epoch: 6| Step: 12
Training loss: 0.24610862135887146
Validation loss: 1.768280303606423

Epoch: 6| Step: 13
Training loss: 0.18308843672275543
Validation loss: 1.7649731918047833

Epoch: 378| Step: 0
Training loss: 0.33352696895599365
Validation loss: 1.7236940322383758

Epoch: 6| Step: 1
Training loss: 0.4188845753669739
Validation loss: 1.740940995113824

Epoch: 6| Step: 2
Training loss: 0.19768567383289337
Validation loss: 1.698586046054799

Epoch: 6| Step: 3
Training loss: 0.39799579977989197
Validation loss: 1.6993899999126312

Epoch: 6| Step: 4
Training loss: 0.10862010717391968
Validation loss: 1.6622282933163386

Epoch: 6| Step: 5
Training loss: 0.2446097433567047
Validation loss: 1.729025076794368

Epoch: 6| Step: 6
Training loss: 0.24333861470222473
Validation loss: 1.6806864853828185

Epoch: 6| Step: 7
Training loss: 0.2199411392211914
Validation loss: 1.6838709346709713

Epoch: 6| Step: 8
Training loss: 0.21272876858711243
Validation loss: 1.7135507855364072

Epoch: 6| Step: 9
Training loss: 0.2116745412349701
Validation loss: 1.7437283172402331

Epoch: 6| Step: 10
Training loss: 0.32007235288619995
Validation loss: 1.780108977389592

Epoch: 6| Step: 11
Training loss: 0.22340744733810425
Validation loss: 1.799671111568328

Epoch: 6| Step: 12
Training loss: 0.1817757934331894
Validation loss: 1.7979955929581837

Epoch: 6| Step: 13
Training loss: 0.34061601758003235
Validation loss: 1.7871867085015902

Epoch: 379| Step: 0
Training loss: 0.1740780621767044
Validation loss: 1.7893984381870558

Epoch: 6| Step: 1
Training loss: 0.32944393157958984
Validation loss: 1.7762589954560803

Epoch: 6| Step: 2
Training loss: 0.3002190589904785
Validation loss: 1.8060469114652244

Epoch: 6| Step: 3
Training loss: 0.1799534410238266
Validation loss: 1.8422284305736583

Epoch: 6| Step: 4
Training loss: 0.209199920296669
Validation loss: 1.826581302509513

Epoch: 6| Step: 5
Training loss: 0.3372223973274231
Validation loss: 1.8462078058591453

Epoch: 6| Step: 6
Training loss: 0.26457679271698
Validation loss: 1.8105004987409037

Epoch: 6| Step: 7
Training loss: 0.3116971552371979
Validation loss: 1.8051588855763918

Epoch: 6| Step: 8
Training loss: 0.18119990825653076
Validation loss: 1.7427853973962928

Epoch: 6| Step: 9
Training loss: 0.430134117603302
Validation loss: 1.720554292842906

Epoch: 6| Step: 10
Training loss: 0.10850366950035095
Validation loss: 1.7418096642340384

Epoch: 6| Step: 11
Training loss: 0.19095948338508606
Validation loss: 1.6840107158948017

Epoch: 6| Step: 12
Training loss: 0.2655410170555115
Validation loss: 1.702615854560688

Epoch: 6| Step: 13
Training loss: 0.18871261179447174
Validation loss: 1.6841945032919607

Epoch: 380| Step: 0
Training loss: 0.28845536708831787
Validation loss: 1.6868807526044949

Epoch: 6| Step: 1
Training loss: 0.23882026970386505
Validation loss: 1.6566283869486984

Epoch: 6| Step: 2
Training loss: 0.23820486664772034
Validation loss: 1.657128103317753

Epoch: 6| Step: 3
Training loss: 0.12544435262680054
Validation loss: 1.6697846753622896

Epoch: 6| Step: 4
Training loss: 0.15277454257011414
Validation loss: 1.6939719236025246

Epoch: 6| Step: 5
Training loss: 0.2634621560573578
Validation loss: 1.6664345584889895

Epoch: 6| Step: 6
Training loss: 0.15242928266525269
Validation loss: 1.6802000358540525

Epoch: 6| Step: 7
Training loss: 0.26356837153434753
Validation loss: 1.7049141292290022

Epoch: 6| Step: 8
Training loss: 0.3545542359352112
Validation loss: 1.7121742572835696

Epoch: 6| Step: 9
Training loss: 0.21995344758033752
Validation loss: 1.7495180304332445

Epoch: 6| Step: 10
Training loss: 0.3620586395263672
Validation loss: 1.735037531903995

Epoch: 6| Step: 11
Training loss: 0.4063642621040344
Validation loss: 1.7330840710670716

Epoch: 6| Step: 12
Training loss: 0.20341135561466217
Validation loss: 1.724117980208448

Epoch: 6| Step: 13
Training loss: 0.3142040967941284
Validation loss: 1.72858077479947

Epoch: 381| Step: 0
Training loss: 0.292288213968277
Validation loss: 1.7189458826536774

Epoch: 6| Step: 1
Training loss: 0.18922168016433716
Validation loss: 1.6956822461979364

Epoch: 6| Step: 2
Training loss: 0.21706044673919678
Validation loss: 1.7147468110566497

Epoch: 6| Step: 3
Training loss: 0.1387663036584854
Validation loss: 1.7015141043611752

Epoch: 6| Step: 4
Training loss: 0.3906446099281311
Validation loss: 1.676880790341285

Epoch: 6| Step: 5
Training loss: 0.2043062448501587
Validation loss: 1.7324236221210931

Epoch: 6| Step: 6
Training loss: 0.2297665774822235
Validation loss: 1.6968558936990716

Epoch: 6| Step: 7
Training loss: 0.24419206380844116
Validation loss: 1.7138095107129825

Epoch: 6| Step: 8
Training loss: 0.28566646575927734
Validation loss: 1.6794498402585265

Epoch: 6| Step: 9
Training loss: 0.15409912168979645
Validation loss: 1.7306213801906956

Epoch: 6| Step: 10
Training loss: 0.35289466381073
Validation loss: 1.7453644121846845

Epoch: 6| Step: 11
Training loss: 0.3069872558116913
Validation loss: 1.742345106217169

Epoch: 6| Step: 12
Training loss: 0.25133851170539856
Validation loss: 1.744409409902429

Epoch: 6| Step: 13
Training loss: 0.3275000751018524
Validation loss: 1.7168005858698199

Epoch: 382| Step: 0
Training loss: 0.16712254285812378
Validation loss: 1.7321649853901198

Epoch: 6| Step: 1
Training loss: 0.20862053334712982
Validation loss: 1.7637880873936478

Epoch: 6| Step: 2
Training loss: 0.24628815054893494
Validation loss: 1.7416704188111007

Epoch: 6| Step: 3
Training loss: 0.1766248345375061
Validation loss: 1.7481453059822

Epoch: 6| Step: 4
Training loss: 0.2231045961380005
Validation loss: 1.7454937273456204

Epoch: 6| Step: 5
Training loss: 0.46565866470336914
Validation loss: 1.738362298216871

Epoch: 6| Step: 6
Training loss: 0.24429436028003693
Validation loss: 1.7235331048247635

Epoch: 6| Step: 7
Training loss: 0.12528428435325623
Validation loss: 1.732340326873205

Epoch: 6| Step: 8
Training loss: 0.19340956211090088
Validation loss: 1.7491914405617663

Epoch: 6| Step: 9
Training loss: 0.17562848329544067
Validation loss: 1.7194833909311602

Epoch: 6| Step: 10
Training loss: 0.20454317331314087
Validation loss: 1.7569629492298249

Epoch: 6| Step: 11
Training loss: 0.20998205244541168
Validation loss: 1.7234651324569539

Epoch: 6| Step: 12
Training loss: 0.25499463081359863
Validation loss: 1.7071587449760848

Epoch: 6| Step: 13
Training loss: 0.17718006670475006
Validation loss: 1.7238543148963683

Epoch: 383| Step: 0
Training loss: 0.2774713337421417
Validation loss: 1.6950635205033004

Epoch: 6| Step: 1
Training loss: 0.22510939836502075
Validation loss: 1.7122971511656238

Epoch: 6| Step: 2
Training loss: 0.29465585947036743
Validation loss: 1.692768281505954

Epoch: 6| Step: 3
Training loss: 0.23450030386447906
Validation loss: 1.7166643488791682

Epoch: 6| Step: 4
Training loss: 0.33646291494369507
Validation loss: 1.7084931532541912

Epoch: 6| Step: 5
Training loss: 0.08857664465904236
Validation loss: 1.7519178441775742

Epoch: 6| Step: 6
Training loss: 0.2163783609867096
Validation loss: 1.7588610546563261

Epoch: 6| Step: 7
Training loss: 0.225853830575943
Validation loss: 1.7543815451283609

Epoch: 6| Step: 8
Training loss: 0.1778404265642166
Validation loss: 1.7684614171263993

Epoch: 6| Step: 9
Training loss: 0.1943904310464859
Validation loss: 1.7249234773779427

Epoch: 6| Step: 10
Training loss: 0.15875928103923798
Validation loss: 1.7376945287950578

Epoch: 6| Step: 11
Training loss: 0.28592610359191895
Validation loss: 1.7570058786740868

Epoch: 6| Step: 12
Training loss: 0.2944108843803406
Validation loss: 1.7621938464462117

Epoch: 6| Step: 13
Training loss: 0.315922349691391
Validation loss: 1.7508400691452848

Epoch: 384| Step: 0
Training loss: 0.17649759352207184
Validation loss: 1.7057650819901498

Epoch: 6| Step: 1
Training loss: 0.2025158405303955
Validation loss: 1.7285181681315105

Epoch: 6| Step: 2
Training loss: 0.19812992215156555
Validation loss: 1.7214941363180838

Epoch: 6| Step: 3
Training loss: 0.1988193690776825
Validation loss: 1.735365706105386

Epoch: 6| Step: 4
Training loss: 0.21053723990917206
Validation loss: 1.7299367650862663

Epoch: 6| Step: 5
Training loss: 0.191987082362175
Validation loss: 1.7383629891180223

Epoch: 6| Step: 6
Training loss: 0.23839934170246124
Validation loss: 1.7377129370166409

Epoch: 6| Step: 7
Training loss: 0.16905450820922852
Validation loss: 1.6906058993390811

Epoch: 6| Step: 8
Training loss: 0.24784837663173676
Validation loss: 1.7278078615024526

Epoch: 6| Step: 9
Training loss: 0.26745277643203735
Validation loss: 1.767418437106635

Epoch: 6| Step: 10
Training loss: 0.12294179201126099
Validation loss: 1.7646075781955515

Epoch: 6| Step: 11
Training loss: 0.10607525706291199
Validation loss: 1.7751268930332635

Epoch: 6| Step: 12
Training loss: 0.3568287491798401
Validation loss: 1.7230103054354269

Epoch: 6| Step: 13
Training loss: 0.3370341658592224
Validation loss: 1.6997621879782727

Epoch: 385| Step: 0
Training loss: 0.16347821056842804
Validation loss: 1.7137022941343245

Epoch: 6| Step: 1
Training loss: 0.2556566596031189
Validation loss: 1.7405461765104724

Epoch: 6| Step: 2
Training loss: 0.2303583323955536
Validation loss: 1.7436727221294115

Epoch: 6| Step: 3
Training loss: 0.3992847204208374
Validation loss: 1.7611126784355409

Epoch: 6| Step: 4
Training loss: 0.22972747683525085
Validation loss: 1.747921730882378

Epoch: 6| Step: 5
Training loss: 0.1383138746023178
Validation loss: 1.7373896619325042

Epoch: 6| Step: 6
Training loss: 0.2287559062242508
Validation loss: 1.7462550081232542

Epoch: 6| Step: 7
Training loss: 0.22785836458206177
Validation loss: 1.7531753714366625

Epoch: 6| Step: 8
Training loss: 0.2260848581790924
Validation loss: 1.790322449899489

Epoch: 6| Step: 9
Training loss: 0.21354617178440094
Validation loss: 1.7784241104638705

Epoch: 6| Step: 10
Training loss: 0.14653363823890686
Validation loss: 1.8212567875462193

Epoch: 6| Step: 11
Training loss: 0.17757433652877808
Validation loss: 1.800437250444966

Epoch: 6| Step: 12
Training loss: 0.1856638491153717
Validation loss: 1.7929566957617318

Epoch: 6| Step: 13
Training loss: 0.25158262252807617
Validation loss: 1.7891198294137114

Epoch: 386| Step: 0
Training loss: 0.3462567925453186
Validation loss: 1.7573928692007577

Epoch: 6| Step: 1
Training loss: 0.11155477166175842
Validation loss: 1.7162935836340791

Epoch: 6| Step: 2
Training loss: 0.2127971649169922
Validation loss: 1.7093900262668569

Epoch: 6| Step: 3
Training loss: 0.21386215090751648
Validation loss: 1.6727720229856429

Epoch: 6| Step: 4
Training loss: 0.28039419651031494
Validation loss: 1.653448785504987

Epoch: 6| Step: 5
Training loss: 0.2944619059562683
Validation loss: 1.662569276748165

Epoch: 6| Step: 6
Training loss: 0.23677702248096466
Validation loss: 1.7106422685807752

Epoch: 6| Step: 7
Training loss: 0.23954781889915466
Validation loss: 1.677757534929501

Epoch: 6| Step: 8
Training loss: 0.17006778717041016
Validation loss: 1.6623640393698087

Epoch: 6| Step: 9
Training loss: 0.1789732575416565
Validation loss: 1.6683908508669945

Epoch: 6| Step: 10
Training loss: 0.119748555123806
Validation loss: 1.6549997175893476

Epoch: 6| Step: 11
Training loss: 0.23026451468467712
Validation loss: 1.7138822655523978

Epoch: 6| Step: 12
Training loss: 0.13731414079666138
Validation loss: 1.6762669881184895

Epoch: 6| Step: 13
Training loss: 0.20126715302467346
Validation loss: 1.7309953653684227

Epoch: 387| Step: 0
Training loss: 0.21758362650871277
Validation loss: 1.772118604311379

Epoch: 6| Step: 1
Training loss: 0.3693367540836334
Validation loss: 1.7790181623992098

Epoch: 6| Step: 2
Training loss: 0.1325204223394394
Validation loss: 1.7965585467635945

Epoch: 6| Step: 3
Training loss: 0.16354042291641235
Validation loss: 1.7275019012471682

Epoch: 6| Step: 4
Training loss: 0.17325469851493835
Validation loss: 1.6950083214749572

Epoch: 6| Step: 5
Training loss: 0.22981345653533936
Validation loss: 1.7211848458936136

Epoch: 6| Step: 6
Training loss: 0.09690865129232407
Validation loss: 1.6780853835485314

Epoch: 6| Step: 7
Training loss: 0.24561363458633423
Validation loss: 1.6738399536378923

Epoch: 6| Step: 8
Training loss: 0.23373588919639587
Validation loss: 1.6808625716035084

Epoch: 6| Step: 9
Training loss: 0.11256315559148788
Validation loss: 1.6582730021528018

Epoch: 6| Step: 10
Training loss: 0.19734707474708557
Validation loss: 1.664149744536287

Epoch: 6| Step: 11
Training loss: 0.2338595688343048
Validation loss: 1.6607684230291715

Epoch: 6| Step: 12
Training loss: 0.20246826112270355
Validation loss: 1.7007835706075032

Epoch: 6| Step: 13
Training loss: 0.2007150948047638
Validation loss: 1.6666546970285394

Epoch: 388| Step: 0
Training loss: 0.25928038358688354
Validation loss: 1.692826412057364

Epoch: 6| Step: 1
Training loss: 0.1757049262523651
Validation loss: 1.7018885189487087

Epoch: 6| Step: 2
Training loss: 0.27858951687812805
Validation loss: 1.706803060347034

Epoch: 6| Step: 3
Training loss: 0.3177887201309204
Validation loss: 1.697043966221553

Epoch: 6| Step: 4
Training loss: 0.1914319097995758
Validation loss: 1.6544836900567497

Epoch: 6| Step: 5
Training loss: 0.28938597440719604
Validation loss: 1.6835675175471971

Epoch: 6| Step: 6
Training loss: 0.17424243688583374
Validation loss: 1.6361769642881168

Epoch: 6| Step: 7
Training loss: 0.21014338731765747
Validation loss: 1.6229314291349022

Epoch: 6| Step: 8
Training loss: 0.18061256408691406
Validation loss: 1.667143496774858

Epoch: 6| Step: 9
Training loss: 0.19896462559700012
Validation loss: 1.6606388656041955

Epoch: 6| Step: 10
Training loss: 0.18103469908237457
Validation loss: 1.670121213441254

Epoch: 6| Step: 11
Training loss: 0.3818766474723816
Validation loss: 1.6812326036473757

Epoch: 6| Step: 12
Training loss: 0.15367528796195984
Validation loss: 1.6832065966821486

Epoch: 6| Step: 13
Training loss: 0.2874186933040619
Validation loss: 1.7214445926809823

Epoch: 389| Step: 0
Training loss: 0.20598554611206055
Validation loss: 1.7200294040864514

Epoch: 6| Step: 1
Training loss: 0.137248694896698
Validation loss: 1.7824352005476594

Epoch: 6| Step: 2
Training loss: 0.2543153166770935
Validation loss: 1.7314087780573035

Epoch: 6| Step: 3
Training loss: 0.1354852169752121
Validation loss: 1.8000052641796809

Epoch: 6| Step: 4
Training loss: 0.1904139667749405
Validation loss: 1.78055336013917

Epoch: 6| Step: 5
Training loss: 0.21188053488731384
Validation loss: 1.8055947467844973

Epoch: 6| Step: 6
Training loss: 0.17294788360595703
Validation loss: 1.7809468315493675

Epoch: 6| Step: 7
Training loss: 0.13681530952453613
Validation loss: 1.7819423547355078

Epoch: 6| Step: 8
Training loss: 0.2521980106830597
Validation loss: 1.7440574656250656

Epoch: 6| Step: 9
Training loss: 0.18379473686218262
Validation loss: 1.742529410187916

Epoch: 6| Step: 10
Training loss: 0.19393572211265564
Validation loss: 1.6753426854328444

Epoch: 6| Step: 11
Training loss: 0.35914236307144165
Validation loss: 1.6704274685152116

Epoch: 6| Step: 12
Training loss: 0.3152031898498535
Validation loss: 1.6488651114125406

Epoch: 6| Step: 13
Training loss: 0.17157384753227234
Validation loss: 1.6523687865144463

Epoch: 390| Step: 0
Training loss: 0.13191211223602295
Validation loss: 1.6306543183583084

Epoch: 6| Step: 1
Training loss: 0.215060755610466
Validation loss: 1.610446762013179

Epoch: 6| Step: 2
Training loss: 0.18986816704273224
Validation loss: 1.5859659410292102

Epoch: 6| Step: 3
Training loss: 0.1577949821949005
Validation loss: 1.5959711177374727

Epoch: 6| Step: 4
Training loss: 0.2307436168193817
Validation loss: 1.6285220679416452

Epoch: 6| Step: 5
Training loss: 0.19415205717086792
Validation loss: 1.6332760549360705

Epoch: 6| Step: 6
Training loss: 0.15167953073978424
Validation loss: 1.6489410592663674

Epoch: 6| Step: 7
Training loss: 0.24742412567138672
Validation loss: 1.6590550509832238

Epoch: 6| Step: 8
Training loss: 0.30632418394088745
Validation loss: 1.6620358523502146

Epoch: 6| Step: 9
Training loss: 0.24401380121707916
Validation loss: 1.679313773749977

Epoch: 6| Step: 10
Training loss: 0.3653290569782257
Validation loss: 1.6410846774296095

Epoch: 6| Step: 11
Training loss: 0.28508326411247253
Validation loss: 1.6366489497564172

Epoch: 6| Step: 12
Training loss: 0.1906450390815735
Validation loss: 1.6217350479095214

Epoch: 6| Step: 13
Training loss: 0.35508835315704346
Validation loss: 1.6574647183059363

Epoch: 391| Step: 0
Training loss: 0.23467451333999634
Validation loss: 1.6500962908549974

Epoch: 6| Step: 1
Training loss: 0.3125731945037842
Validation loss: 1.6630675356875184

Epoch: 6| Step: 2
Training loss: 0.2933589220046997
Validation loss: 1.6870049661205662

Epoch: 6| Step: 3
Training loss: 0.4684269428253174
Validation loss: 1.6913550310237433

Epoch: 6| Step: 4
Training loss: 0.31159067153930664
Validation loss: 1.651072855918638

Epoch: 6| Step: 5
Training loss: 0.14268943667411804
Validation loss: 1.6569306670978505

Epoch: 6| Step: 6
Training loss: 0.321117639541626
Validation loss: 1.6289488910346903

Epoch: 6| Step: 7
Training loss: 0.22181710600852966
Validation loss: 1.6585365200555453

Epoch: 6| Step: 8
Training loss: 0.22179533541202545
Validation loss: 1.6361692977207962

Epoch: 6| Step: 9
Training loss: 0.206510990858078
Validation loss: 1.652302848395481

Epoch: 6| Step: 10
Training loss: 0.23245662450790405
Validation loss: 1.6546989897246003

Epoch: 6| Step: 11
Training loss: 0.14108848571777344
Validation loss: 1.6595737639293875

Epoch: 6| Step: 12
Training loss: 0.2105642706155777
Validation loss: 1.6562824197994765

Epoch: 6| Step: 13
Training loss: 0.2464057356119156
Validation loss: 1.6505201952431792

Epoch: 392| Step: 0
Training loss: 0.18920278549194336
Validation loss: 1.6421255629549745

Epoch: 6| Step: 1
Training loss: 0.18236231803894043
Validation loss: 1.6172362553176058

Epoch: 6| Step: 2
Training loss: 0.14628693461418152
Validation loss: 1.6239200266458655

Epoch: 6| Step: 3
Training loss: 0.2688993215560913
Validation loss: 1.6255262436405304

Epoch: 6| Step: 4
Training loss: 0.4434465169906616
Validation loss: 1.6076124483539211

Epoch: 6| Step: 5
Training loss: 0.21661439538002014
Validation loss: 1.6607703060232184

Epoch: 6| Step: 6
Training loss: 0.27686697244644165
Validation loss: 1.6655593995125062

Epoch: 6| Step: 7
Training loss: 0.35046201944351196
Validation loss: 1.6700913675369755

Epoch: 6| Step: 8
Training loss: 0.27696213126182556
Validation loss: 1.6895915603124967

Epoch: 6| Step: 9
Training loss: 0.17078112065792084
Validation loss: 1.7011456874109083

Epoch: 6| Step: 10
Training loss: 0.17936289310455322
Validation loss: 1.700656957523797

Epoch: 6| Step: 11
Training loss: 0.3713729977607727
Validation loss: 1.7287685691669423

Epoch: 6| Step: 12
Training loss: 0.2821671664714813
Validation loss: 1.6894553297309465

Epoch: 6| Step: 13
Training loss: 0.1839095950126648
Validation loss: 1.7189741455098635

Epoch: 393| Step: 0
Training loss: 0.2023678719997406
Validation loss: 1.7210767499862178

Epoch: 6| Step: 1
Training loss: 0.20118379592895508
Validation loss: 1.7449074509323284

Epoch: 6| Step: 2
Training loss: 0.3108474016189575
Validation loss: 1.740563113202331

Epoch: 6| Step: 3
Training loss: 0.17692053318023682
Validation loss: 1.7302848908209032

Epoch: 6| Step: 4
Training loss: 0.2554221749305725
Validation loss: 1.7165114315607215

Epoch: 6| Step: 5
Training loss: 0.21168142557144165
Validation loss: 1.7535762850956251

Epoch: 6| Step: 6
Training loss: 0.27537673711776733
Validation loss: 1.7498760325934297

Epoch: 6| Step: 7
Training loss: 0.13106562197208405
Validation loss: 1.7626768158328148

Epoch: 6| Step: 8
Training loss: 0.2535155713558197
Validation loss: 1.7578461529106222

Epoch: 6| Step: 9
Training loss: 0.6039129495620728
Validation loss: 1.7535930968100024

Epoch: 6| Step: 10
Training loss: 0.31748998165130615
Validation loss: 1.7520303213468162

Epoch: 6| Step: 11
Training loss: 0.37967103719711304
Validation loss: 1.750582069479009

Epoch: 6| Step: 12
Training loss: 0.2945427894592285
Validation loss: 1.7164253291263376

Epoch: 6| Step: 13
Training loss: 0.19003282487392426
Validation loss: 1.6854624991775842

Epoch: 394| Step: 0
Training loss: 0.1305018663406372
Validation loss: 1.661841880890631

Epoch: 6| Step: 1
Training loss: 0.4376605451107025
Validation loss: 1.6869550110191427

Epoch: 6| Step: 2
Training loss: 0.21203482151031494
Validation loss: 1.684911927869243

Epoch: 6| Step: 3
Training loss: 0.16101884841918945
Validation loss: 1.6742227872212727

Epoch: 6| Step: 4
Training loss: 0.16608183085918427
Validation loss: 1.689228193734282

Epoch: 6| Step: 5
Training loss: 0.16980379819869995
Validation loss: 1.680600259893684

Epoch: 6| Step: 6
Training loss: 0.236883744597435
Validation loss: 1.73342796679466

Epoch: 6| Step: 7
Training loss: 0.3514215350151062
Validation loss: 1.71809850072348

Epoch: 6| Step: 8
Training loss: 0.23384824395179749
Validation loss: 1.702104373644757

Epoch: 6| Step: 9
Training loss: 0.2537994682788849
Validation loss: 1.6627576517802414

Epoch: 6| Step: 10
Training loss: 0.27281278371810913
Validation loss: 1.6518293382019125

Epoch: 6| Step: 11
Training loss: 0.18704518675804138
Validation loss: 1.6571486508974465

Epoch: 6| Step: 12
Training loss: 0.3476181626319885
Validation loss: 1.6528695757671068

Epoch: 6| Step: 13
Training loss: 0.2450082004070282
Validation loss: 1.6568595465793405

Epoch: 395| Step: 0
Training loss: 0.3525925874710083
Validation loss: 1.6625395487713557

Epoch: 6| Step: 1
Training loss: 0.3287947177886963
Validation loss: 1.651185106205684

Epoch: 6| Step: 2
Training loss: 0.4773824214935303
Validation loss: 1.6700132354613273

Epoch: 6| Step: 3
Training loss: 0.2288457453250885
Validation loss: 1.6586460951835877

Epoch: 6| Step: 4
Training loss: 0.159554585814476
Validation loss: 1.6761469879458029

Epoch: 6| Step: 5
Training loss: 0.1312764585018158
Validation loss: 1.6511945243804687

Epoch: 6| Step: 6
Training loss: 0.178927481174469
Validation loss: 1.6897972001824328

Epoch: 6| Step: 7
Training loss: 0.17738205194473267
Validation loss: 1.7007928663684475

Epoch: 6| Step: 8
Training loss: 0.17012304067611694
Validation loss: 1.7197281993845457

Epoch: 6| Step: 9
Training loss: 0.31379061937332153
Validation loss: 1.7358203972539594

Epoch: 6| Step: 10
Training loss: 0.1376628875732422
Validation loss: 1.726399105082276

Epoch: 6| Step: 11
Training loss: 0.2546085715293884
Validation loss: 1.7141669014448762

Epoch: 6| Step: 12
Training loss: 0.13811203837394714
Validation loss: 1.7472666719908356

Epoch: 6| Step: 13
Training loss: 0.13876019418239594
Validation loss: 1.6982600740207139

Epoch: 396| Step: 0
Training loss: 0.20312169194221497
Validation loss: 1.697870312198516

Epoch: 6| Step: 1
Training loss: 0.31676188111305237
Validation loss: 1.7000707016196301

Epoch: 6| Step: 2
Training loss: 0.29156172275543213
Validation loss: 1.7322820219942319

Epoch: 6| Step: 3
Training loss: 0.3717654049396515
Validation loss: 1.7333153857979724

Epoch: 6| Step: 4
Training loss: 0.15905754268169403
Validation loss: 1.7148631888051187

Epoch: 6| Step: 5
Training loss: 0.14389920234680176
Validation loss: 1.732429027557373

Epoch: 6| Step: 6
Training loss: 0.19551533460617065
Validation loss: 1.7197020258954776

Epoch: 6| Step: 7
Training loss: 0.1984107494354248
Validation loss: 1.725537048873081

Epoch: 6| Step: 8
Training loss: 0.22111117839813232
Validation loss: 1.7040225575047154

Epoch: 6| Step: 9
Training loss: 0.16639751195907593
Validation loss: 1.7146108509391866

Epoch: 6| Step: 10
Training loss: 0.2712097764015198
Validation loss: 1.711393835724041

Epoch: 6| Step: 11
Training loss: 0.2095533162355423
Validation loss: 1.7169353308216218

Epoch: 6| Step: 12
Training loss: 0.16933581233024597
Validation loss: 1.7482085048511464

Epoch: 6| Step: 13
Training loss: 0.21814554929733276
Validation loss: 1.7128227346686906

Epoch: 397| Step: 0
Training loss: 0.1675189733505249
Validation loss: 1.7160767586000505

Epoch: 6| Step: 1
Training loss: 0.29329127073287964
Validation loss: 1.7132948162735149

Epoch: 6| Step: 2
Training loss: 0.21087199449539185
Validation loss: 1.6870887740965812

Epoch: 6| Step: 3
Training loss: 0.3172364830970764
Validation loss: 1.7020916938781738

Epoch: 6| Step: 4
Training loss: 0.21105359494686127
Validation loss: 1.6614220655092629

Epoch: 6| Step: 5
Training loss: 0.2453261911869049
Validation loss: 1.6722462087549188

Epoch: 6| Step: 6
Training loss: 0.17467570304870605
Validation loss: 1.6449195736198015

Epoch: 6| Step: 7
Training loss: 0.22331343591213226
Validation loss: 1.6567076765080935

Epoch: 6| Step: 8
Training loss: 0.18301117420196533
Validation loss: 1.6417788420954058

Epoch: 6| Step: 9
Training loss: 0.19193926453590393
Validation loss: 1.6076546048605314

Epoch: 6| Step: 10
Training loss: 0.3350217938423157
Validation loss: 1.664697270239553

Epoch: 6| Step: 11
Training loss: 0.18863871693611145
Validation loss: 1.6246632555479645

Epoch: 6| Step: 12
Training loss: 0.12348340451717377
Validation loss: 1.6162925394632484

Epoch: 6| Step: 13
Training loss: 0.23743152618408203
Validation loss: 1.6434995282080866

Epoch: 398| Step: 0
Training loss: 0.20065662264823914
Validation loss: 1.5968629852417977

Epoch: 6| Step: 1
Training loss: 0.21281017363071442
Validation loss: 1.673095731325047

Epoch: 6| Step: 2
Training loss: 0.10146433115005493
Validation loss: 1.641483877294807

Epoch: 6| Step: 3
Training loss: 0.1478249430656433
Validation loss: 1.63695691990596

Epoch: 6| Step: 4
Training loss: 0.11136205494403839
Validation loss: 1.6287097712998748

Epoch: 6| Step: 5
Training loss: 0.11843380331993103
Validation loss: 1.6392057198350147

Epoch: 6| Step: 6
Training loss: 0.13436239957809448
Validation loss: 1.6131828523451281

Epoch: 6| Step: 7
Training loss: 0.3269529342651367
Validation loss: 1.669082663392508

Epoch: 6| Step: 8
Training loss: 0.18228036165237427
Validation loss: 1.6735752705604798

Epoch: 6| Step: 9
Training loss: 0.17408159375190735
Validation loss: 1.6936683603512344

Epoch: 6| Step: 10
Training loss: 0.3207983672618866
Validation loss: 1.7000186481783468

Epoch: 6| Step: 11
Training loss: 0.3376193642616272
Validation loss: 1.7038655357976114

Epoch: 6| Step: 12
Training loss: 0.24388813972473145
Validation loss: 1.6861899719443372

Epoch: 6| Step: 13
Training loss: 0.25737664103507996
Validation loss: 1.6846896012624104

Epoch: 399| Step: 0
Training loss: 0.203415647149086
Validation loss: 1.707767758318173

Epoch: 6| Step: 1
Training loss: 0.21507689356803894
Validation loss: 1.7110556133331791

Epoch: 6| Step: 2
Training loss: 0.21216055750846863
Validation loss: 1.711184122229135

Epoch: 6| Step: 3
Training loss: 0.3967418968677521
Validation loss: 1.7672763204061857

Epoch: 6| Step: 4
Training loss: 0.21273106336593628
Validation loss: 1.7050454103818504

Epoch: 6| Step: 5
Training loss: 0.12537872791290283
Validation loss: 1.6987149407786708

Epoch: 6| Step: 6
Training loss: 0.22328217327594757
Validation loss: 1.7052306346995856

Epoch: 6| Step: 7
Training loss: 0.15750350058078766
Validation loss: 1.6797228038951915

Epoch: 6| Step: 8
Training loss: 0.3465491533279419
Validation loss: 1.6960648772537068

Epoch: 6| Step: 9
Training loss: 0.25679445266723633
Validation loss: 1.6741643938966977

Epoch: 6| Step: 10
Training loss: 0.2429616004228592
Validation loss: 1.655280875903304

Epoch: 6| Step: 11
Training loss: 0.175912007689476
Validation loss: 1.6401693513316493

Epoch: 6| Step: 12
Training loss: 0.17484436929225922
Validation loss: 1.6530028889256139

Epoch: 6| Step: 13
Training loss: 0.10551966726779938
Validation loss: 1.6447368027061544

Epoch: 400| Step: 0
Training loss: 0.13638919591903687
Validation loss: 1.6465217656986688

Epoch: 6| Step: 1
Training loss: 0.14069384336471558
Validation loss: 1.6246832122084915

Epoch: 6| Step: 2
Training loss: 0.17312085628509521
Validation loss: 1.644151230012217

Epoch: 6| Step: 3
Training loss: 0.20841050148010254
Validation loss: 1.6370630623191915

Epoch: 6| Step: 4
Training loss: 0.21587024629116058
Validation loss: 1.6669644040446128

Epoch: 6| Step: 5
Training loss: 0.19711345434188843
Validation loss: 1.6476990920241161

Epoch: 6| Step: 6
Training loss: 0.16383130848407745
Validation loss: 1.6432322609809138

Epoch: 6| Step: 7
Training loss: 0.2384418547153473
Validation loss: 1.655196580835568

Epoch: 6| Step: 8
Training loss: 0.2574726343154907
Validation loss: 1.6111595963919034

Epoch: 6| Step: 9
Training loss: 0.22141872346401215
Validation loss: 1.6092952015579387

Epoch: 6| Step: 10
Training loss: 0.3164851665496826
Validation loss: 1.6222339176362561

Epoch: 6| Step: 11
Training loss: 0.3659215569496155
Validation loss: 1.6302090267981253

Epoch: 6| Step: 12
Training loss: 0.15947167575359344
Validation loss: 1.6332747833703154

Epoch: 6| Step: 13
Training loss: 0.09428289532661438
Validation loss: 1.6578364372253418

Epoch: 401| Step: 0
Training loss: 0.18018028140068054
Validation loss: 1.659315764263112

Epoch: 6| Step: 1
Training loss: 0.1716814637184143
Validation loss: 1.6546415936562322

Epoch: 6| Step: 2
Training loss: 0.2844240665435791
Validation loss: 1.6948450752483901

Epoch: 6| Step: 3
Training loss: 0.36760368943214417
Validation loss: 1.6804423460396387

Epoch: 6| Step: 4
Training loss: 0.1372987926006317
Validation loss: 1.6787601440183577

Epoch: 6| Step: 5
Training loss: 0.20386192202568054
Validation loss: 1.6879503521867978

Epoch: 6| Step: 6
Training loss: 0.1328093409538269
Validation loss: 1.7071901957194011

Epoch: 6| Step: 7
Training loss: 0.24573549628257751
Validation loss: 1.7328958992035157

Epoch: 6| Step: 8
Training loss: 0.13542480766773224
Validation loss: 1.7226618489911478

Epoch: 6| Step: 9
Training loss: 0.22395657002925873
Validation loss: 1.6904578055104902

Epoch: 6| Step: 10
Training loss: 0.21633219718933105
Validation loss: 1.7092919054851736

Epoch: 6| Step: 11
Training loss: 0.18853512406349182
Validation loss: 1.6626468012409825

Epoch: 6| Step: 12
Training loss: 0.16016584634780884
Validation loss: 1.7023106595521331

Epoch: 6| Step: 13
Training loss: 0.23244057595729828
Validation loss: 1.6734642482572986

Epoch: 402| Step: 0
Training loss: 0.2633166015148163
Validation loss: 1.6464658591055101

Epoch: 6| Step: 1
Training loss: 0.2260555624961853
Validation loss: 1.6820349283115839

Epoch: 6| Step: 2
Training loss: 0.18809041380882263
Validation loss: 1.6636119299037482

Epoch: 6| Step: 3
Training loss: 0.19374863803386688
Validation loss: 1.6736155838094733

Epoch: 6| Step: 4
Training loss: 0.17295780777931213
Validation loss: 1.669041851515411

Epoch: 6| Step: 5
Training loss: 0.29639220237731934
Validation loss: 1.6937409613722114

Epoch: 6| Step: 6
Training loss: 0.28854358196258545
Validation loss: 1.6913775628612888

Epoch: 6| Step: 7
Training loss: 0.17723307013511658
Validation loss: 1.6945600189188474

Epoch: 6| Step: 8
Training loss: 0.1050352156162262
Validation loss: 1.684827661001554

Epoch: 6| Step: 9
Training loss: 0.21070697903633118
Validation loss: 1.7109378460914857

Epoch: 6| Step: 10
Training loss: 0.10472986102104187
Validation loss: 1.6813451013257426

Epoch: 6| Step: 11
Training loss: 0.19893935322761536
Validation loss: 1.6523110520455144

Epoch: 6| Step: 12
Training loss: 0.1526196449995041
Validation loss: 1.6856632053211171

Epoch: 6| Step: 13
Training loss: 0.16454198956489563
Validation loss: 1.6816223180422218

Epoch: 403| Step: 0
Training loss: 0.10564986616373062
Validation loss: 1.7021659740837671

Epoch: 6| Step: 1
Training loss: 0.16774818301200867
Validation loss: 1.7016919518029818

Epoch: 6| Step: 2
Training loss: 0.20424020290374756
Validation loss: 1.718637699721962

Epoch: 6| Step: 3
Training loss: 0.1960642784833908
Validation loss: 1.749836180799751

Epoch: 6| Step: 4
Training loss: 0.24241401255130768
Validation loss: 1.6981213836259739

Epoch: 6| Step: 5
Training loss: 0.21657207608222961
Validation loss: 1.706605226762833

Epoch: 6| Step: 6
Training loss: 0.1793559342622757
Validation loss: 1.7502371796997644

Epoch: 6| Step: 7
Training loss: 0.0940898209810257
Validation loss: 1.7039291897127706

Epoch: 6| Step: 8
Training loss: 0.2855129539966583
Validation loss: 1.6759928503344137

Epoch: 6| Step: 9
Training loss: 0.21505855023860931
Validation loss: 1.67551290476194

Epoch: 6| Step: 10
Training loss: 0.24108028411865234
Validation loss: 1.6663745321253294

Epoch: 6| Step: 11
Training loss: 0.21359382569789886
Validation loss: 1.6532725185476325

Epoch: 6| Step: 12
Training loss: 0.1718333661556244
Validation loss: 1.6420779138483026

Epoch: 6| Step: 13
Training loss: 0.22418369352817535
Validation loss: 1.6304762722343527

Epoch: 404| Step: 0
Training loss: 0.21265292167663574
Validation loss: 1.6482470420099073

Epoch: 6| Step: 1
Training loss: 0.08001615107059479
Validation loss: 1.617912072007374

Epoch: 6| Step: 2
Training loss: 0.18167456984519958
Validation loss: 1.6239796671816098

Epoch: 6| Step: 3
Training loss: 0.2120838165283203
Validation loss: 1.645852973384242

Epoch: 6| Step: 4
Training loss: 0.4020853340625763
Validation loss: 1.6418324773029616

Epoch: 6| Step: 5
Training loss: 0.13470883667469025
Validation loss: 1.631328477654406

Epoch: 6| Step: 6
Training loss: 0.09502760320901871
Validation loss: 1.6681790762050177

Epoch: 6| Step: 7
Training loss: 0.17945632338523865
Validation loss: 1.6675183465403896

Epoch: 6| Step: 8
Training loss: 0.16000798344612122
Validation loss: 1.6654581587801698

Epoch: 6| Step: 9
Training loss: 0.22187922894954681
Validation loss: 1.6771341075179398

Epoch: 6| Step: 10
Training loss: 0.17767292261123657
Validation loss: 1.6782753403468798

Epoch: 6| Step: 11
Training loss: 0.15013492107391357
Validation loss: 1.6655732803447272

Epoch: 6| Step: 12
Training loss: 0.11903577297925949
Validation loss: 1.6584349319499025

Epoch: 6| Step: 13
Training loss: 0.2780984342098236
Validation loss: 1.6615608135859172

Epoch: 405| Step: 0
Training loss: 0.1072947233915329
Validation loss: 1.6703952589342672

Epoch: 6| Step: 1
Training loss: 0.20090743899345398
Validation loss: 1.6940017374612952

Epoch: 6| Step: 2
Training loss: 0.20201478898525238
Validation loss: 1.7096855819866221

Epoch: 6| Step: 3
Training loss: 0.1421920210123062
Validation loss: 1.6859326465155489

Epoch: 6| Step: 4
Training loss: 0.184745192527771
Validation loss: 1.7158907895447106

Epoch: 6| Step: 5
Training loss: 0.27441975474357605
Validation loss: 1.669729394297446

Epoch: 6| Step: 6
Training loss: 0.1545623540878296
Validation loss: 1.6837554413785216

Epoch: 6| Step: 7
Training loss: 0.1882430911064148
Validation loss: 1.6502786003133303

Epoch: 6| Step: 8
Training loss: 0.13723833858966827
Validation loss: 1.6342861729283487

Epoch: 6| Step: 9
Training loss: 0.1671164333820343
Validation loss: 1.631211450663946

Epoch: 6| Step: 10
Training loss: 0.3089088797569275
Validation loss: 1.5965986482558712

Epoch: 6| Step: 11
Training loss: 0.21347743272781372
Validation loss: 1.6027667342975576

Epoch: 6| Step: 12
Training loss: 0.23364832997322083
Validation loss: 1.6093962807809152

Epoch: 6| Step: 13
Training loss: 0.28868594765663147
Validation loss: 1.5887111681763844

Epoch: 406| Step: 0
Training loss: 0.15925782918930054
Validation loss: 1.5878517807170909

Epoch: 6| Step: 1
Training loss: 0.2349308878183365
Validation loss: 1.6443586586624064

Epoch: 6| Step: 2
Training loss: 0.20073804259300232
Validation loss: 1.6121538351940852

Epoch: 6| Step: 3
Training loss: 0.17488572001457214
Validation loss: 1.6536141698078444

Epoch: 6| Step: 4
Training loss: 0.27149999141693115
Validation loss: 1.6433716294586018

Epoch: 6| Step: 5
Training loss: 0.14708375930786133
Validation loss: 1.647699197133382

Epoch: 6| Step: 6
Training loss: 0.273628294467926
Validation loss: 1.6473281921878937

Epoch: 6| Step: 7
Training loss: 0.10360102355480194
Validation loss: 1.6688896712436472

Epoch: 6| Step: 8
Training loss: 0.15246567130088806
Validation loss: 1.682904783115592

Epoch: 6| Step: 9
Training loss: 0.36436018347740173
Validation loss: 1.6862711265522947

Epoch: 6| Step: 10
Training loss: 0.17050643265247345
Validation loss: 1.697766101488503

Epoch: 6| Step: 11
Training loss: 0.18534217774868011
Validation loss: 1.689485267926288

Epoch: 6| Step: 12
Training loss: 0.1722302883863449
Validation loss: 1.6665356069482782

Epoch: 6| Step: 13
Training loss: 0.3891722559928894
Validation loss: 1.6885588271643526

Epoch: 407| Step: 0
Training loss: 0.07382874190807343
Validation loss: 1.675620541136752

Epoch: 6| Step: 1
Training loss: 0.26661866903305054
Validation loss: 1.653549289190641

Epoch: 6| Step: 2
Training loss: 0.28887566924095154
Validation loss: 1.6227065196601294

Epoch: 6| Step: 3
Training loss: 0.1027994230389595
Validation loss: 1.6212581703739781

Epoch: 6| Step: 4
Training loss: 0.2058427482843399
Validation loss: 1.6127736363359677

Epoch: 6| Step: 5
Training loss: 0.13100238144397736
Validation loss: 1.6348148520274828

Epoch: 6| Step: 6
Training loss: 0.13699184358119965
Validation loss: 1.626635338670464

Epoch: 6| Step: 7
Training loss: 0.141132652759552
Validation loss: 1.6505194376873713

Epoch: 6| Step: 8
Training loss: 0.1481422781944275
Validation loss: 1.6480288403008574

Epoch: 6| Step: 9
Training loss: 0.17474083602428436
Validation loss: 1.6618487681111982

Epoch: 6| Step: 10
Training loss: 0.22936254739761353
Validation loss: 1.6884905740778933

Epoch: 6| Step: 11
Training loss: 0.09802437573671341
Validation loss: 1.7244528121845697

Epoch: 6| Step: 12
Training loss: 0.3730373978614807
Validation loss: 1.7291130532500565

Epoch: 6| Step: 13
Training loss: 0.24471288919448853
Validation loss: 1.7464307533797396

Epoch: 408| Step: 0
Training loss: 0.234445720911026
Validation loss: 1.7300197911518875

Epoch: 6| Step: 1
Training loss: 0.3059828281402588
Validation loss: 1.7029222185893724

Epoch: 6| Step: 2
Training loss: 0.08762163668870926
Validation loss: 1.6970152701100996

Epoch: 6| Step: 3
Training loss: 0.22919684648513794
Validation loss: 1.6906765199476672

Epoch: 6| Step: 4
Training loss: 0.25716638565063477
Validation loss: 1.717825674241589

Epoch: 6| Step: 5
Training loss: 0.35018014907836914
Validation loss: 1.6633820995207755

Epoch: 6| Step: 6
Training loss: 0.10593433678150177
Validation loss: 1.6711725881022792

Epoch: 6| Step: 7
Training loss: 0.20836098492145538
Validation loss: 1.6484272710738643

Epoch: 6| Step: 8
Training loss: 0.15891015529632568
Validation loss: 1.6281677702421784

Epoch: 6| Step: 9
Training loss: 0.13504602015018463
Validation loss: 1.6267320007406256

Epoch: 6| Step: 10
Training loss: 0.18825939297676086
Validation loss: 1.6256678258219073

Epoch: 6| Step: 11
Training loss: 0.2127644568681717
Validation loss: 1.630849943366102

Epoch: 6| Step: 12
Training loss: 0.1950426697731018
Validation loss: 1.6186778494106826

Epoch: 6| Step: 13
Training loss: 0.2160218060016632
Validation loss: 1.6318768596136441

Epoch: 409| Step: 0
Training loss: 0.10701228678226471
Validation loss: 1.6408948347132692

Epoch: 6| Step: 1
Training loss: 0.14323537051677704
Validation loss: 1.6686108958336614

Epoch: 6| Step: 2
Training loss: 0.12887290120124817
Validation loss: 1.6516298260740054

Epoch: 6| Step: 3
Training loss: 0.19081047177314758
Validation loss: 1.6884047151893697

Epoch: 6| Step: 4
Training loss: 0.12834104895591736
Validation loss: 1.7027708202280023

Epoch: 6| Step: 5
Training loss: 0.35591012239456177
Validation loss: 1.7053966368398359

Epoch: 6| Step: 6
Training loss: 0.24742481112480164
Validation loss: 1.717412143625239

Epoch: 6| Step: 7
Training loss: 0.19420763850212097
Validation loss: 1.714751539691802

Epoch: 6| Step: 8
Training loss: 0.2353738397359848
Validation loss: 1.6638499357367074

Epoch: 6| Step: 9
Training loss: 0.13675850629806519
Validation loss: 1.6580440498167468

Epoch: 6| Step: 10
Training loss: 0.23055869340896606
Validation loss: 1.6807238658269246

Epoch: 6| Step: 11
Training loss: 0.20408132672309875
Validation loss: 1.6277277367089384

Epoch: 6| Step: 12
Training loss: 0.1478586345911026
Validation loss: 1.6477273510348411

Epoch: 6| Step: 13
Training loss: 0.1573099046945572
Validation loss: 1.6180020481027582

Epoch: 410| Step: 0
Training loss: 0.24527350068092346
Validation loss: 1.6276566238813504

Epoch: 6| Step: 1
Training loss: 0.2720144987106323
Validation loss: 1.6188349473860957

Epoch: 6| Step: 2
Training loss: 0.1885140836238861
Validation loss: 1.6162053436361334

Epoch: 6| Step: 3
Training loss: 0.14386354386806488
Validation loss: 1.5951790514812674

Epoch: 6| Step: 4
Training loss: 0.1833384782075882
Validation loss: 1.5907553947100075

Epoch: 6| Step: 5
Training loss: 0.17586474120616913
Validation loss: 1.5776977987699612

Epoch: 6| Step: 6
Training loss: 0.41456449031829834
Validation loss: 1.6178025968613163

Epoch: 6| Step: 7
Training loss: 0.15360979735851288
Validation loss: 1.6087950596245386

Epoch: 6| Step: 8
Training loss: 0.16798031330108643
Validation loss: 1.6167693048395135

Epoch: 6| Step: 9
Training loss: 0.1775967925786972
Validation loss: 1.618202510700431

Epoch: 6| Step: 10
Training loss: 0.24998171627521515
Validation loss: 1.6617997154112785

Epoch: 6| Step: 11
Training loss: 0.19579961895942688
Validation loss: 1.660783939464118

Epoch: 6| Step: 12
Training loss: 0.25646623969078064
Validation loss: 1.6503746676188644

Epoch: 6| Step: 13
Training loss: 0.10671591758728027
Validation loss: 1.6217239441410187

Epoch: 411| Step: 0
Training loss: 0.1951673924922943
Validation loss: 1.679421164656198

Epoch: 6| Step: 1
Training loss: 0.13426172733306885
Validation loss: 1.6713699371584

Epoch: 6| Step: 2
Training loss: 0.1254473775625229
Validation loss: 1.6467738279732325

Epoch: 6| Step: 3
Training loss: 0.27399399876594543
Validation loss: 1.6410423812045847

Epoch: 6| Step: 4
Training loss: 0.19000598788261414
Validation loss: 1.6441754653889646

Epoch: 6| Step: 5
Training loss: 0.15289846062660217
Validation loss: 1.6423510889853201

Epoch: 6| Step: 6
Training loss: 0.1718365103006363
Validation loss: 1.6589667104905652

Epoch: 6| Step: 7
Training loss: 0.26460427045822144
Validation loss: 1.690955251775762

Epoch: 6| Step: 8
Training loss: 0.2434273064136505
Validation loss: 1.6651006911390571

Epoch: 6| Step: 9
Training loss: 0.14968733489513397
Validation loss: 1.680530144322303

Epoch: 6| Step: 10
Training loss: 0.1407204270362854
Validation loss: 1.6978356299861785

Epoch: 6| Step: 11
Training loss: 0.16106046736240387
Validation loss: 1.6817222769542406

Epoch: 6| Step: 12
Training loss: 0.15706972777843475
Validation loss: 1.6921921776187034

Epoch: 6| Step: 13
Training loss: 0.22034433484077454
Validation loss: 1.6421497688498548

Epoch: 412| Step: 0
Training loss: 0.1744135171175003
Validation loss: 1.664402792530675

Epoch: 6| Step: 1
Training loss: 0.17680241167545319
Validation loss: 1.653009060890444

Epoch: 6| Step: 2
Training loss: 0.2284533679485321
Validation loss: 1.6462907560410038

Epoch: 6| Step: 3
Training loss: 0.16535420715808868
Validation loss: 1.665895636363696

Epoch: 6| Step: 4
Training loss: 0.220950186252594
Validation loss: 1.6658125205706524

Epoch: 6| Step: 5
Training loss: 0.16874773800373077
Validation loss: 1.6254983678940804

Epoch: 6| Step: 6
Training loss: 0.11513651907444
Validation loss: 1.6144535067260906

Epoch: 6| Step: 7
Training loss: 0.12794175744056702
Validation loss: 1.6292850778948875

Epoch: 6| Step: 8
Training loss: 0.2083316147327423
Validation loss: 1.645706763831518

Epoch: 6| Step: 9
Training loss: 0.10586228221654892
Validation loss: 1.6612262213101952

Epoch: 6| Step: 10
Training loss: 0.2569299340248108
Validation loss: 1.6044769774201095

Epoch: 6| Step: 11
Training loss: 0.38349196314811707
Validation loss: 1.65964800055309

Epoch: 6| Step: 12
Training loss: 0.21512269973754883
Validation loss: 1.6467038969839773

Epoch: 6| Step: 13
Training loss: 0.10405686497688293
Validation loss: 1.6486117929540656

Epoch: 413| Step: 0
Training loss: 0.17734727263450623
Validation loss: 1.6233806033288278

Epoch: 6| Step: 1
Training loss: 0.2218775600194931
Validation loss: 1.6437399259177587

Epoch: 6| Step: 2
Training loss: 0.1630772352218628
Validation loss: 1.637789580129808

Epoch: 6| Step: 3
Training loss: 0.0776953250169754
Validation loss: 1.6134119790087464

Epoch: 6| Step: 4
Training loss: 0.15823403000831604
Validation loss: 1.6463466100795294

Epoch: 6| Step: 5
Training loss: 0.15994034707546234
Validation loss: 1.6308138370513916

Epoch: 6| Step: 6
Training loss: 0.40714573860168457
Validation loss: 1.685927584607114

Epoch: 6| Step: 7
Training loss: 0.15568596124649048
Validation loss: 1.695729927350116

Epoch: 6| Step: 8
Training loss: 0.15218932926654816
Validation loss: 1.6683664770536526

Epoch: 6| Step: 9
Training loss: 0.0961267277598381
Validation loss: 1.6491928062131327

Epoch: 6| Step: 10
Training loss: 0.2103494107723236
Validation loss: 1.684269215471001

Epoch: 6| Step: 11
Training loss: 0.12713809311389923
Validation loss: 1.660712266481051

Epoch: 6| Step: 12
Training loss: 0.22543717920780182
Validation loss: 1.7160155978254092

Epoch: 6| Step: 13
Training loss: 0.2155698984861374
Validation loss: 1.7010603117686447

Epoch: 414| Step: 0
Training loss: 0.1632855087518692
Validation loss: 1.686421827603412

Epoch: 6| Step: 1
Training loss: 0.3544054925441742
Validation loss: 1.6485308742010465

Epoch: 6| Step: 2
Training loss: 0.2523718476295471
Validation loss: 1.6397543261128087

Epoch: 6| Step: 3
Training loss: 0.12494873255491257
Validation loss: 1.6457864020460395

Epoch: 6| Step: 4
Training loss: 0.21338610351085663
Validation loss: 1.647128217963762

Epoch: 6| Step: 5
Training loss: 0.15698903799057007
Validation loss: 1.666055392193538

Epoch: 6| Step: 6
Training loss: 0.1757892668247223
Validation loss: 1.6799048839076873

Epoch: 6| Step: 7
Training loss: 0.23227329552173615
Validation loss: 1.6659260372961722

Epoch: 6| Step: 8
Training loss: 0.13103219866752625
Validation loss: 1.7177167733510335

Epoch: 6| Step: 9
Training loss: 0.3032824695110321
Validation loss: 1.7279412182428504

Epoch: 6| Step: 10
Training loss: 0.18385955691337585
Validation loss: 1.7317314609404533

Epoch: 6| Step: 11
Training loss: 0.20335263013839722
Validation loss: 1.7276361116798975

Epoch: 6| Step: 12
Training loss: 0.15756410360336304
Validation loss: 1.758623844192874

Epoch: 6| Step: 13
Training loss: 0.06901707500219345
Validation loss: 1.7308534652956071

Epoch: 415| Step: 0
Training loss: 0.30168092250823975
Validation loss: 1.734314331444361

Epoch: 6| Step: 1
Training loss: 0.1583998203277588
Validation loss: 1.7322284124230827

Epoch: 6| Step: 2
Training loss: 0.2840621769428253
Validation loss: 1.7306477472346316

Epoch: 6| Step: 3
Training loss: 0.33421725034713745
Validation loss: 1.7192547577683643

Epoch: 6| Step: 4
Training loss: 0.28389865159988403
Validation loss: 1.7302236903098323

Epoch: 6| Step: 5
Training loss: 0.23146921396255493
Validation loss: 1.66685490838943

Epoch: 6| Step: 6
Training loss: 0.13506658375263214
Validation loss: 1.676623370057793

Epoch: 6| Step: 7
Training loss: 0.13360001146793365
Validation loss: 1.6660774907758158

Epoch: 6| Step: 8
Training loss: 0.20320218801498413
Validation loss: 1.662754766402706

Epoch: 6| Step: 9
Training loss: 0.39412540197372437
Validation loss: 1.6560258506446757

Epoch: 6| Step: 10
Training loss: 0.22735188901424408
Validation loss: 1.645590418128557

Epoch: 6| Step: 11
Training loss: 0.26207196712493896
Validation loss: 1.6205064250576882

Epoch: 6| Step: 12
Training loss: 0.1888812929391861
Validation loss: 1.6174677700124762

Epoch: 6| Step: 13
Training loss: 0.11370012164115906
Validation loss: 1.6273133216365692

Epoch: 416| Step: 0
Training loss: 0.24184668064117432
Validation loss: 1.6089313645516672

Epoch: 6| Step: 1
Training loss: 0.27100610733032227
Validation loss: 1.6271617976568078

Epoch: 6| Step: 2
Training loss: 0.1819435954093933
Validation loss: 1.5974307598606232

Epoch: 6| Step: 3
Training loss: 0.2167368233203888
Validation loss: 1.6188469920107114

Epoch: 6| Step: 4
Training loss: 0.18713146448135376
Validation loss: 1.613125934395739

Epoch: 6| Step: 5
Training loss: 0.20553618669509888
Validation loss: 1.6215892555893108

Epoch: 6| Step: 6
Training loss: 0.18119248747825623
Validation loss: 1.691151652925758

Epoch: 6| Step: 7
Training loss: 0.29654860496520996
Validation loss: 1.661159989654377

Epoch: 6| Step: 8
Training loss: 0.17352983355522156
Validation loss: 1.7151053079994776

Epoch: 6| Step: 9
Training loss: 0.14897894859313965
Validation loss: 1.7229607323164582

Epoch: 6| Step: 10
Training loss: 0.19209922850131989
Validation loss: 1.7574348988071564

Epoch: 6| Step: 11
Training loss: 0.18306468427181244
Validation loss: 1.7088714030481154

Epoch: 6| Step: 12
Training loss: 0.22556422650814056
Validation loss: 1.7209812184815765

Epoch: 6| Step: 13
Training loss: 0.1576363444328308
Validation loss: 1.724357324261819

Epoch: 417| Step: 0
Training loss: 0.16941125690937042
Validation loss: 1.6690362858515915

Epoch: 6| Step: 1
Training loss: 0.10406996309757233
Validation loss: 1.6758606972232941

Epoch: 6| Step: 2
Training loss: 0.1990203559398651
Validation loss: 1.6835314650689401

Epoch: 6| Step: 3
Training loss: 0.2019018828868866
Validation loss: 1.6783733393556328

Epoch: 6| Step: 4
Training loss: 0.09772311896085739
Validation loss: 1.6886260958128079

Epoch: 6| Step: 5
Training loss: 0.3010404407978058
Validation loss: 1.6679384208494616

Epoch: 6| Step: 6
Training loss: 0.2659265995025635
Validation loss: 1.6616784244455316

Epoch: 6| Step: 7
Training loss: 0.21001678705215454
Validation loss: 1.6530116642675092

Epoch: 6| Step: 8
Training loss: 0.16676698625087738
Validation loss: 1.7086491918051114

Epoch: 6| Step: 9
Training loss: 0.14900466799736023
Validation loss: 1.6924542803918161

Epoch: 6| Step: 10
Training loss: 0.17837034165859222
Validation loss: 1.7006860907359789

Epoch: 6| Step: 11
Training loss: 0.18694047629833221
Validation loss: 1.6859381762883996

Epoch: 6| Step: 12
Training loss: 0.27060553431510925
Validation loss: 1.7139007609377626

Epoch: 6| Step: 13
Training loss: 0.08923682570457458
Validation loss: 1.6856541454151113

Epoch: 418| Step: 0
Training loss: 0.15459167957305908
Validation loss: 1.706306174237241

Epoch: 6| Step: 1
Training loss: 0.22637386620044708
Validation loss: 1.726446182497086

Epoch: 6| Step: 2
Training loss: 0.24028676748275757
Validation loss: 1.7384499760084255

Epoch: 6| Step: 3
Training loss: 0.20793159306049347
Validation loss: 1.7124461435502576

Epoch: 6| Step: 4
Training loss: 0.16834089159965515
Validation loss: 1.706461275777509

Epoch: 6| Step: 5
Training loss: 0.14133456349372864
Validation loss: 1.6893919911435855

Epoch: 6| Step: 6
Training loss: 0.14491960406303406
Validation loss: 1.6758428953027213

Epoch: 6| Step: 7
Training loss: 0.09471890330314636
Validation loss: 1.7051714235736477

Epoch: 6| Step: 8
Training loss: 0.12145648151636124
Validation loss: 1.687422337070588

Epoch: 6| Step: 9
Training loss: 0.08419264107942581
Validation loss: 1.7279171866755332

Epoch: 6| Step: 10
Training loss: 0.21148890256881714
Validation loss: 1.6753672989465858

Epoch: 6| Step: 11
Training loss: 0.2616213858127594
Validation loss: 1.6903887371863089

Epoch: 6| Step: 12
Training loss: 0.21917298436164856
Validation loss: 1.7219598062576786

Epoch: 6| Step: 13
Training loss: 0.20610465109348297
Validation loss: 1.7117978161381138

Epoch: 419| Step: 0
Training loss: 0.13950373232364655
Validation loss: 1.688737033515848

Epoch: 6| Step: 1
Training loss: 0.08493133634328842
Validation loss: 1.7083159095497542

Epoch: 6| Step: 2
Training loss: 0.258431613445282
Validation loss: 1.7228677247160225

Epoch: 6| Step: 3
Training loss: 0.17787811160087585
Validation loss: 1.691814197007046

Epoch: 6| Step: 4
Training loss: 0.3344663679599762
Validation loss: 1.7203806087534914

Epoch: 6| Step: 5
Training loss: 0.13376334309577942
Validation loss: 1.7180577196100706

Epoch: 6| Step: 6
Training loss: 0.22273069620132446
Validation loss: 1.743175786028626

Epoch: 6| Step: 7
Training loss: 0.12114492058753967
Validation loss: 1.7091293411870156

Epoch: 6| Step: 8
Training loss: 0.23963649570941925
Validation loss: 1.6892309509297854

Epoch: 6| Step: 9
Training loss: 0.19447284936904907
Validation loss: 1.6589372952779133

Epoch: 6| Step: 10
Training loss: 0.14118686318397522
Validation loss: 1.6824082943700975

Epoch: 6| Step: 11
Training loss: 0.12127582728862762
Validation loss: 1.672577513161526

Epoch: 6| Step: 12
Training loss: 0.12588199973106384
Validation loss: 1.6716116179702103

Epoch: 6| Step: 13
Training loss: 0.1872914582490921
Validation loss: 1.6570728632711595

Epoch: 420| Step: 0
Training loss: 0.2366465926170349
Validation loss: 1.6525723113808581

Epoch: 6| Step: 1
Training loss: 0.17987772822380066
Validation loss: 1.6657100787726782

Epoch: 6| Step: 2
Training loss: 0.1595260053873062
Validation loss: 1.6342451136599305

Epoch: 6| Step: 3
Training loss: 0.18989522755146027
Validation loss: 1.6567569009719356

Epoch: 6| Step: 4
Training loss: 0.2092263251543045
Validation loss: 1.6710780641084075

Epoch: 6| Step: 5
Training loss: 0.18437975645065308
Validation loss: 1.7006716715392245

Epoch: 6| Step: 6
Training loss: 0.2895374000072479
Validation loss: 1.6577697659051547

Epoch: 6| Step: 7
Training loss: 0.15627014636993408
Validation loss: 1.69104399219636

Epoch: 6| Step: 8
Training loss: 0.1359497606754303
Validation loss: 1.6621745504358763

Epoch: 6| Step: 9
Training loss: 0.1615455448627472
Validation loss: 1.7044529299582205

Epoch: 6| Step: 10
Training loss: 0.1959860622882843
Validation loss: 1.6832936438181068

Epoch: 6| Step: 11
Training loss: 0.24154068529605865
Validation loss: 1.6805596031168455

Epoch: 6| Step: 12
Training loss: 0.1467316746711731
Validation loss: 1.6475086340340235

Epoch: 6| Step: 13
Training loss: 0.22978536784648895
Validation loss: 1.6247870409360496

Epoch: 421| Step: 0
Training loss: 0.15846958756446838
Validation loss: 1.604535993709359

Epoch: 6| Step: 1
Training loss: 0.3319796919822693
Validation loss: 1.5979758103688557

Epoch: 6| Step: 2
Training loss: 0.17080846428871155
Validation loss: 1.5885731853464597

Epoch: 6| Step: 3
Training loss: 0.20732146501541138
Validation loss: 1.5905343422325708

Epoch: 6| Step: 4
Training loss: 0.20356442034244537
Validation loss: 1.6049038838314753

Epoch: 6| Step: 5
Training loss: 0.16080603003501892
Validation loss: 1.603611489777924

Epoch: 6| Step: 6
Training loss: 0.3485628068447113
Validation loss: 1.6079397047719648

Epoch: 6| Step: 7
Training loss: 0.18223357200622559
Validation loss: 1.6511667364387101

Epoch: 6| Step: 8
Training loss: 0.1935533881187439
Validation loss: 1.6402775382482877

Epoch: 6| Step: 9
Training loss: 0.127937912940979
Validation loss: 1.6521660679130143

Epoch: 6| Step: 10
Training loss: 0.1777726709842682
Validation loss: 1.6848631058969805

Epoch: 6| Step: 11
Training loss: 0.13174474239349365
Validation loss: 1.6980767301333848

Epoch: 6| Step: 12
Training loss: 0.15930435061454773
Validation loss: 1.7015206531811786

Epoch: 6| Step: 13
Training loss: 0.2237110733985901
Validation loss: 1.6856511010918567

Epoch: 422| Step: 0
Training loss: 0.1701682060956955
Validation loss: 1.665104071299235

Epoch: 6| Step: 1
Training loss: 0.26120150089263916
Validation loss: 1.672503553411012

Epoch: 6| Step: 2
Training loss: 0.22604526579380035
Validation loss: 1.6719341316530782

Epoch: 6| Step: 3
Training loss: 0.19812017679214478
Validation loss: 1.6800278861035582

Epoch: 6| Step: 4
Training loss: 0.2566920816898346
Validation loss: 1.6550460284756077

Epoch: 6| Step: 5
Training loss: 0.21952396631240845
Validation loss: 1.6641332641724618

Epoch: 6| Step: 6
Training loss: 0.18942034244537354
Validation loss: 1.6718913791000203

Epoch: 6| Step: 7
Training loss: 0.1997760534286499
Validation loss: 1.6422684038839033

Epoch: 6| Step: 8
Training loss: 0.14647220075130463
Validation loss: 1.6619055771058606

Epoch: 6| Step: 9
Training loss: 0.13827265799045563
Validation loss: 1.658691014653893

Epoch: 6| Step: 10
Training loss: 0.19415318965911865
Validation loss: 1.6627970767277542

Epoch: 6| Step: 11
Training loss: 0.16647706925868988
Validation loss: 1.6815831815042803

Epoch: 6| Step: 12
Training loss: 0.226516455411911
Validation loss: 1.6521970648919382

Epoch: 6| Step: 13
Training loss: 0.13133233785629272
Validation loss: 1.6734057382870746

Epoch: 423| Step: 0
Training loss: 0.21255511045455933
Validation loss: 1.7171706089409449

Epoch: 6| Step: 1
Training loss: 0.20671789348125458
Validation loss: 1.6735267626341952

Epoch: 6| Step: 2
Training loss: 0.24254104495048523
Validation loss: 1.6889524536748086

Epoch: 6| Step: 3
Training loss: 0.21022668480873108
Validation loss: 1.6929632002307522

Epoch: 6| Step: 4
Training loss: 0.20905403792858124
Validation loss: 1.6867116241044895

Epoch: 6| Step: 5
Training loss: 0.25936275720596313
Validation loss: 1.6564188798268635

Epoch: 6| Step: 6
Training loss: 0.12915661931037903
Validation loss: 1.6138020958951724

Epoch: 6| Step: 7
Training loss: 0.23266386985778809
Validation loss: 1.6509573536534463

Epoch: 6| Step: 8
Training loss: 0.1285809874534607
Validation loss: 1.658390365621095

Epoch: 6| Step: 9
Training loss: 0.17226070165634155
Validation loss: 1.6464393408067766

Epoch: 6| Step: 10
Training loss: 0.23046156764030457
Validation loss: 1.6200605464237992

Epoch: 6| Step: 11
Training loss: 0.1906672865152359
Validation loss: 1.6761533611564225

Epoch: 6| Step: 12
Training loss: 0.07985285669565201
Validation loss: 1.7003886981676983

Epoch: 6| Step: 13
Training loss: 0.11210955679416656
Validation loss: 1.689410509601716

Epoch: 424| Step: 0
Training loss: 0.19797110557556152
Validation loss: 1.686709698169462

Epoch: 6| Step: 1
Training loss: 0.16390755772590637
Validation loss: 1.7654123601093088

Epoch: 6| Step: 2
Training loss: 0.1490316241979599
Validation loss: 1.7219888458969772

Epoch: 6| Step: 3
Training loss: 0.17333129048347473
Validation loss: 1.7636024477661296

Epoch: 6| Step: 4
Training loss: 0.19801244139671326
Validation loss: 1.7341223967972623

Epoch: 6| Step: 5
Training loss: 0.1626647412776947
Validation loss: 1.738889386576991

Epoch: 6| Step: 6
Training loss: 0.3259095549583435
Validation loss: 1.7325902984988304

Epoch: 6| Step: 7
Training loss: 0.1699363887310028
Validation loss: 1.7628352744604951

Epoch: 6| Step: 8
Training loss: 0.2627885937690735
Validation loss: 1.727234910893184

Epoch: 6| Step: 9
Training loss: 0.2519753575325012
Validation loss: 1.7220869923150668

Epoch: 6| Step: 10
Training loss: 0.1470111608505249
Validation loss: 1.7277849733188588

Epoch: 6| Step: 11
Training loss: 0.10315494239330292
Validation loss: 1.7002516933666763

Epoch: 6| Step: 12
Training loss: 0.12667614221572876
Validation loss: 1.7242583549150856

Epoch: 6| Step: 13
Training loss: 0.13630343973636627
Validation loss: 1.7515063401191466

Epoch: 425| Step: 0
Training loss: 0.1765124499797821
Validation loss: 1.7308068788179787

Epoch: 6| Step: 1
Training loss: 0.2105606496334076
Validation loss: 1.7261302137887606

Epoch: 6| Step: 2
Training loss: 0.156581848859787
Validation loss: 1.6887669768384708

Epoch: 6| Step: 3
Training loss: 0.1901969611644745
Validation loss: 1.7095789781180761

Epoch: 6| Step: 4
Training loss: 0.1831401288509369
Validation loss: 1.678838227384834

Epoch: 6| Step: 5
Training loss: 0.1491466462612152
Validation loss: 1.676614672906937

Epoch: 6| Step: 6
Training loss: 0.23963479697704315
Validation loss: 1.67567955165781

Epoch: 6| Step: 7
Training loss: 0.13107433915138245
Validation loss: 1.6529573471315446

Epoch: 6| Step: 8
Training loss: 0.11365018039941788
Validation loss: 1.6441073289481543

Epoch: 6| Step: 9
Training loss: 0.17621320486068726
Validation loss: 1.6474337988002326

Epoch: 6| Step: 10
Training loss: 0.0990128144621849
Validation loss: 1.6200295930267663

Epoch: 6| Step: 11
Training loss: 0.23672734200954437
Validation loss: 1.5996072548691944

Epoch: 6| Step: 12
Training loss: 0.19393619894981384
Validation loss: 1.6273638631707878

Epoch: 6| Step: 13
Training loss: 0.18810635805130005
Validation loss: 1.629726343257453

Epoch: 426| Step: 0
Training loss: 0.39199304580688477
Validation loss: 1.672284624909842

Epoch: 6| Step: 1
Training loss: 0.10813623666763306
Validation loss: 1.650123942282892

Epoch: 6| Step: 2
Training loss: 0.17845454812049866
Validation loss: 1.6698765882881739

Epoch: 6| Step: 3
Training loss: 0.24314388632774353
Validation loss: 1.662839865171781

Epoch: 6| Step: 4
Training loss: 0.1585940718650818
Validation loss: 1.6713298642507164

Epoch: 6| Step: 5
Training loss: 0.12709441781044006
Validation loss: 1.6727234778865692

Epoch: 6| Step: 6
Training loss: 0.14360202848911285
Validation loss: 1.6913443137240667

Epoch: 6| Step: 7
Training loss: 0.13394758105278015
Validation loss: 1.707896077504722

Epoch: 6| Step: 8
Training loss: 0.13713283836841583
Validation loss: 1.711473520084094

Epoch: 6| Step: 9
Training loss: 0.10617178678512573
Validation loss: 1.7079074664782452

Epoch: 6| Step: 10
Training loss: 0.24889683723449707
Validation loss: 1.6943617789976058

Epoch: 6| Step: 11
Training loss: 0.2282514125108719
Validation loss: 1.6885164694119525

Epoch: 6| Step: 12
Training loss: 0.20424768328666687
Validation loss: 1.7049086862994778

Epoch: 6| Step: 13
Training loss: 0.13156527280807495
Validation loss: 1.7010415959101852

Epoch: 427| Step: 0
Training loss: 0.0920037180185318
Validation loss: 1.6861760750893624

Epoch: 6| Step: 1
Training loss: 0.12424339354038239
Validation loss: 1.6800255031995877

Epoch: 6| Step: 2
Training loss: 0.09379502385854721
Validation loss: 1.671507438023885

Epoch: 6| Step: 3
Training loss: 0.17279194295406342
Validation loss: 1.663866590428096

Epoch: 6| Step: 4
Training loss: 0.23330789804458618
Validation loss: 1.636072499777681

Epoch: 6| Step: 5
Training loss: 0.16780884563922882
Validation loss: 1.6927637746257167

Epoch: 6| Step: 6
Training loss: 0.09054457396268845
Validation loss: 1.675701331066829

Epoch: 6| Step: 7
Training loss: 0.2779490351676941
Validation loss: 1.692701344848961

Epoch: 6| Step: 8
Training loss: 0.2042824774980545
Validation loss: 1.6523668714748916

Epoch: 6| Step: 9
Training loss: 0.12223025411367416
Validation loss: 1.6682653811670118

Epoch: 6| Step: 10
Training loss: 0.1021193265914917
Validation loss: 1.6500154913112681

Epoch: 6| Step: 11
Training loss: 0.21149113774299622
Validation loss: 1.626706237434059

Epoch: 6| Step: 12
Training loss: 0.17653051018714905
Validation loss: 1.6193302587796283

Epoch: 6| Step: 13
Training loss: 0.14961162209510803
Validation loss: 1.6421562907516316

Epoch: 428| Step: 0
Training loss: 0.34044283628463745
Validation loss: 1.6456256117872012

Epoch: 6| Step: 1
Training loss: 0.21700656414031982
Validation loss: 1.6745098008904407

Epoch: 6| Step: 2
Training loss: 0.21329577267169952
Validation loss: 1.6499972535717873

Epoch: 6| Step: 3
Training loss: 0.20353223383426666
Validation loss: 1.6512747182640979

Epoch: 6| Step: 4
Training loss: 0.1581864058971405
Validation loss: 1.6446428427132227

Epoch: 6| Step: 5
Training loss: 0.11175259947776794
Validation loss: 1.6582506882247103

Epoch: 6| Step: 6
Training loss: 0.2803995609283447
Validation loss: 1.6523366807609476

Epoch: 6| Step: 7
Training loss: 0.22064433991909027
Validation loss: 1.6035800505709905

Epoch: 6| Step: 8
Training loss: 0.20950795710086823
Validation loss: 1.59731549345037

Epoch: 6| Step: 9
Training loss: 0.1886044442653656
Validation loss: 1.6145774536235358

Epoch: 6| Step: 10
Training loss: 0.19357110559940338
Validation loss: 1.6321554555687854

Epoch: 6| Step: 11
Training loss: 0.16875812411308289
Validation loss: 1.6074834267298381

Epoch: 6| Step: 12
Training loss: 0.31899380683898926
Validation loss: 1.6404916650505477

Epoch: 6| Step: 13
Training loss: 0.2193351835012436
Validation loss: 1.6641745349412322

Epoch: 429| Step: 0
Training loss: 0.24637633562088013
Validation loss: 1.6608531654521983

Epoch: 6| Step: 1
Training loss: 0.16828244924545288
Validation loss: 1.6597418836368028

Epoch: 6| Step: 2
Training loss: 0.12201325595378876
Validation loss: 1.6230632105181295

Epoch: 6| Step: 3
Training loss: 0.30997130274772644
Validation loss: 1.601948659907105

Epoch: 6| Step: 4
Training loss: 0.12467551231384277
Validation loss: 1.5927557381250526

Epoch: 6| Step: 5
Training loss: 0.14134705066680908
Validation loss: 1.6346252772115892

Epoch: 6| Step: 6
Training loss: 0.12194178998470306
Validation loss: 1.64290577109142

Epoch: 6| Step: 7
Training loss: 0.21757610142230988
Validation loss: 1.6588752513290734

Epoch: 6| Step: 8
Training loss: 0.18125119805335999
Validation loss: 1.7098557833702333

Epoch: 6| Step: 9
Training loss: 0.2850435972213745
Validation loss: 1.6965419983351102

Epoch: 6| Step: 10
Training loss: 0.1750502586364746
Validation loss: 1.7163713452636555

Epoch: 6| Step: 11
Training loss: 0.22647860646247864
Validation loss: 1.707443582114353

Epoch: 6| Step: 12
Training loss: 0.3494065999984741
Validation loss: 1.6790582979879072

Epoch: 6| Step: 13
Training loss: 0.1461218297481537
Validation loss: 1.646641024979212

Epoch: 430| Step: 0
Training loss: 0.13431748747825623
Validation loss: 1.6215764784043836

Epoch: 6| Step: 1
Training loss: 0.2507816553115845
Validation loss: 1.628644242081591

Epoch: 6| Step: 2
Training loss: 0.23739653825759888
Validation loss: 1.6251147511184856

Epoch: 6| Step: 3
Training loss: 0.20542040467262268
Validation loss: 1.6181315414367183

Epoch: 6| Step: 4
Training loss: 0.1336982548236847
Validation loss: 1.571596102047992

Epoch: 6| Step: 5
Training loss: 0.24844703078269958
Validation loss: 1.5894122354445919

Epoch: 6| Step: 6
Training loss: 0.17502906918525696
Validation loss: 1.5988014410900813

Epoch: 6| Step: 7
Training loss: 0.17959383130073547
Validation loss: 1.5963879721139067

Epoch: 6| Step: 8
Training loss: 0.27807047963142395
Validation loss: 1.6135140452333676

Epoch: 6| Step: 9
Training loss: 0.17182548344135284
Validation loss: 1.61192028240491

Epoch: 6| Step: 10
Training loss: 0.1318458616733551
Validation loss: 1.6485890688434723

Epoch: 6| Step: 11
Training loss: 0.20285531878471375
Validation loss: 1.6687561132574593

Epoch: 6| Step: 12
Training loss: 0.11174017190933228
Validation loss: 1.7152828234498219

Epoch: 6| Step: 13
Training loss: 0.21319815516471863
Validation loss: 1.7254197757731202

Epoch: 431| Step: 0
Training loss: 0.09926791489124298
Validation loss: 1.726753250245125

Epoch: 6| Step: 1
Training loss: 0.20780590176582336
Validation loss: 1.769388505207595

Epoch: 6| Step: 2
Training loss: 0.21190783381462097
Validation loss: 1.7542734876755746

Epoch: 6| Step: 3
Training loss: 0.16316011548042297
Validation loss: 1.748420206449365

Epoch: 6| Step: 4
Training loss: 0.2827082574367523
Validation loss: 1.7194757000092538

Epoch: 6| Step: 5
Training loss: 0.11998899281024933
Validation loss: 1.7297449637484807

Epoch: 6| Step: 6
Training loss: 0.17074793577194214
Validation loss: 1.710616998775031

Epoch: 6| Step: 7
Training loss: 0.18768340349197388
Validation loss: 1.6604717444348078

Epoch: 6| Step: 8
Training loss: 0.24895019829273224
Validation loss: 1.6922860632660568

Epoch: 6| Step: 9
Training loss: 0.13803911209106445
Validation loss: 1.6177713101910007

Epoch: 6| Step: 10
Training loss: 0.19773362576961517
Validation loss: 1.5964039743587535

Epoch: 6| Step: 11
Training loss: 0.31337520480155945
Validation loss: 1.6305753274630475

Epoch: 6| Step: 12
Training loss: 0.17810586094856262
Validation loss: 1.6070278645843588

Epoch: 6| Step: 13
Training loss: 0.1836530566215515
Validation loss: 1.5929406432695286

Epoch: 432| Step: 0
Training loss: 0.2795068919658661
Validation loss: 1.6322420745767572

Epoch: 6| Step: 1
Training loss: 0.12951751053333282
Validation loss: 1.598556633918516

Epoch: 6| Step: 2
Training loss: 0.17644184827804565
Validation loss: 1.5815967846942205

Epoch: 6| Step: 3
Training loss: 0.13478529453277588
Validation loss: 1.6283386740633237

Epoch: 6| Step: 4
Training loss: 0.17320609092712402
Validation loss: 1.6555934067695373

Epoch: 6| Step: 5
Training loss: 0.3245227336883545
Validation loss: 1.6209927066679923

Epoch: 6| Step: 6
Training loss: 0.2445378452539444
Validation loss: 1.6198684938492314

Epoch: 6| Step: 7
Training loss: 0.30527836084365845
Validation loss: 1.6263152553189186

Epoch: 6| Step: 8
Training loss: 0.18782135844230652
Validation loss: 1.6467163178228563

Epoch: 6| Step: 9
Training loss: 0.1761247217655182
Validation loss: 1.5966149735194382

Epoch: 6| Step: 10
Training loss: 0.18860143423080444
Validation loss: 1.5912556199617283

Epoch: 6| Step: 11
Training loss: 0.1227373257279396
Validation loss: 1.6235297802955873

Epoch: 6| Step: 12
Training loss: 0.05861402302980423
Validation loss: 1.6134721348362584

Epoch: 6| Step: 13
Training loss: 0.14299258589744568
Validation loss: 1.6351766253030429

Epoch: 433| Step: 0
Training loss: 0.1659812033176422
Validation loss: 1.6189268135255384

Epoch: 6| Step: 1
Training loss: 0.15799149870872498
Validation loss: 1.6179054046189913

Epoch: 6| Step: 2
Training loss: 0.16677284240722656
Validation loss: 1.6072314605917981

Epoch: 6| Step: 3
Training loss: 0.2614787817001343
Validation loss: 1.6286617812289987

Epoch: 6| Step: 4
Training loss: 0.11779216676950455
Validation loss: 1.6423565636398971

Epoch: 6| Step: 5
Training loss: 0.1558775007724762
Validation loss: 1.6397220088589577

Epoch: 6| Step: 6
Training loss: 0.17626050114631653
Validation loss: 1.6384279933027042

Epoch: 6| Step: 7
Training loss: 0.21582886576652527
Validation loss: 1.6722379833139398

Epoch: 6| Step: 8
Training loss: 0.14184676110744476
Validation loss: 1.6504549775072324

Epoch: 6| Step: 9
Training loss: 0.2536191940307617
Validation loss: 1.6781551543102469

Epoch: 6| Step: 10
Training loss: 0.11441846191883087
Validation loss: 1.6702137377954298

Epoch: 6| Step: 11
Training loss: 0.1932743787765503
Validation loss: 1.6467896123086252

Epoch: 6| Step: 12
Training loss: 0.10257945209741592
Validation loss: 1.6462934619636946

Epoch: 6| Step: 13
Training loss: 0.2454811930656433
Validation loss: 1.6632149680968253

Epoch: 434| Step: 0
Training loss: 0.1596750020980835
Validation loss: 1.6398597481430217

Epoch: 6| Step: 1
Training loss: 0.22034984827041626
Validation loss: 1.636071382030364

Epoch: 6| Step: 2
Training loss: 0.12861940264701843
Validation loss: 1.62994187108932

Epoch: 6| Step: 3
Training loss: 0.17126873135566711
Validation loss: 1.6190845376701766

Epoch: 6| Step: 4
Training loss: 0.14536958932876587
Validation loss: 1.6511536887896958

Epoch: 6| Step: 5
Training loss: 0.3034103512763977
Validation loss: 1.650452180575299

Epoch: 6| Step: 6
Training loss: 0.16077569127082825
Validation loss: 1.6620220138180641

Epoch: 6| Step: 7
Training loss: 0.10821641236543655
Validation loss: 1.6266029445073937

Epoch: 6| Step: 8
Training loss: 0.20772439241409302
Validation loss: 1.644748782598844

Epoch: 6| Step: 9
Training loss: 0.2532136142253876
Validation loss: 1.6329580276243147

Epoch: 6| Step: 10
Training loss: 0.3612181842327118
Validation loss: 1.5880453560941963

Epoch: 6| Step: 11
Training loss: 0.22311869263648987
Validation loss: 1.5960788867806877

Epoch: 6| Step: 12
Training loss: 0.17666320502758026
Validation loss: 1.6015186296996249

Epoch: 6| Step: 13
Training loss: 0.17698335647583008
Validation loss: 1.5862954431964504

Epoch: 435| Step: 0
Training loss: 0.11757118999958038
Validation loss: 1.6103290050260481

Epoch: 6| Step: 1
Training loss: 0.32763543725013733
Validation loss: 1.6225341212364934

Epoch: 6| Step: 2
Training loss: 0.19523483514785767
Validation loss: 1.6361600532326648

Epoch: 6| Step: 3
Training loss: 0.19593030214309692
Validation loss: 1.651414518715233

Epoch: 6| Step: 4
Training loss: 0.1527710258960724
Validation loss: 1.6637858549753826

Epoch: 6| Step: 5
Training loss: 0.14529748260974884
Validation loss: 1.6514394590931554

Epoch: 6| Step: 6
Training loss: 0.1740221083164215
Validation loss: 1.6412309472278883

Epoch: 6| Step: 7
Training loss: 0.15193693339824677
Validation loss: 1.6125225969540176

Epoch: 6| Step: 8
Training loss: 0.09148035943508148
Validation loss: 1.6468547569808138

Epoch: 6| Step: 9
Training loss: 0.1301170289516449
Validation loss: 1.6228884009904758

Epoch: 6| Step: 10
Training loss: 0.2681352496147156
Validation loss: 1.5931065082550049

Epoch: 6| Step: 11
Training loss: 0.19677306711673737
Validation loss: 1.5999775650680705

Epoch: 6| Step: 12
Training loss: 0.22411870956420898
Validation loss: 1.6033214484491656

Epoch: 6| Step: 13
Training loss: 0.13590388000011444
Validation loss: 1.595735587099547

Epoch: 436| Step: 0
Training loss: 0.12087338417768478
Validation loss: 1.610937339003368

Epoch: 6| Step: 1
Training loss: 0.26069176197052
Validation loss: 1.6300716092509608

Epoch: 6| Step: 2
Training loss: 0.24428106844425201
Validation loss: 1.6095842776759979

Epoch: 6| Step: 3
Training loss: 0.1717115193605423
Validation loss: 1.657976617095291

Epoch: 6| Step: 4
Training loss: 0.224495068192482
Validation loss: 1.6323406850138018

Epoch: 6| Step: 5
Training loss: 0.19119901955127716
Validation loss: 1.6339743573178527

Epoch: 6| Step: 6
Training loss: 0.14301402866840363
Validation loss: 1.6689188762377667

Epoch: 6| Step: 7
Training loss: 0.13102155923843384
Validation loss: 1.6224938195238832

Epoch: 6| Step: 8
Training loss: 0.19950181245803833
Validation loss: 1.6288640858024679

Epoch: 6| Step: 9
Training loss: 0.12419566512107849
Validation loss: 1.635967029038296

Epoch: 6| Step: 10
Training loss: 0.2081640362739563
Validation loss: 1.6354562659417429

Epoch: 6| Step: 11
Training loss: 0.23921780288219452
Validation loss: 1.6332461372498543

Epoch: 6| Step: 12
Training loss: 0.15668852627277374
Validation loss: 1.6750172767587888

Epoch: 6| Step: 13
Training loss: 0.15806640684604645
Validation loss: 1.674430863831633

Epoch: 437| Step: 0
Training loss: 0.17342370748519897
Validation loss: 1.6759501041904572

Epoch: 6| Step: 1
Training loss: 0.27266019582748413
Validation loss: 1.6992116358972364

Epoch: 6| Step: 2
Training loss: 0.4046868085861206
Validation loss: 1.712312594536812

Epoch: 6| Step: 3
Training loss: 0.1357927769422531
Validation loss: 1.7217369899954846

Epoch: 6| Step: 4
Training loss: 0.2574537396430969
Validation loss: 1.700474460919698

Epoch: 6| Step: 5
Training loss: 0.14620733261108398
Validation loss: 1.6811980714080155

Epoch: 6| Step: 6
Training loss: 0.19621433317661285
Validation loss: 1.6462298849577546

Epoch: 6| Step: 7
Training loss: 0.1336161494255066
Validation loss: 1.639221356761071

Epoch: 6| Step: 8
Training loss: 0.18212181329727173
Validation loss: 1.6651189384921905

Epoch: 6| Step: 9
Training loss: 0.09329092502593994
Validation loss: 1.6458936019610333

Epoch: 6| Step: 10
Training loss: 0.1588846743106842
Validation loss: 1.6272106939746487

Epoch: 6| Step: 11
Training loss: 0.14929264783859253
Validation loss: 1.6511931188644902

Epoch: 6| Step: 12
Training loss: 0.110878124833107
Validation loss: 1.6333370900923205

Epoch: 6| Step: 13
Training loss: 0.17119669914245605
Validation loss: 1.6319619096735472

Epoch: 438| Step: 0
Training loss: 0.2382379025220871
Validation loss: 1.6251061859951224

Epoch: 6| Step: 1
Training loss: 0.2142154425382614
Validation loss: 1.6327128717976231

Epoch: 6| Step: 2
Training loss: 0.2008693814277649
Validation loss: 1.6410529177675965

Epoch: 6| Step: 3
Training loss: 0.13628244400024414
Validation loss: 1.6526373368437572

Epoch: 6| Step: 4
Training loss: 0.11667568236589432
Validation loss: 1.6645219851565618

Epoch: 6| Step: 5
Training loss: 0.13684743642807007
Validation loss: 1.670849613605007

Epoch: 6| Step: 6
Training loss: 0.09291763603687286
Validation loss: 1.6623962015234015

Epoch: 6| Step: 7
Training loss: 0.17247673869132996
Validation loss: 1.6936213534365419

Epoch: 6| Step: 8
Training loss: 0.2628764808177948
Validation loss: 1.749590157180704

Epoch: 6| Step: 9
Training loss: 0.15016134083271027
Validation loss: 1.7585177190842167

Epoch: 6| Step: 10
Training loss: 0.3158884048461914
Validation loss: 1.780672448937611

Epoch: 6| Step: 11
Training loss: 0.12375421077013016
Validation loss: 1.732140471858363

Epoch: 6| Step: 12
Training loss: 0.19980956614017487
Validation loss: 1.7260215308076592

Epoch: 6| Step: 13
Training loss: 0.19251319766044617
Validation loss: 1.6709053708660988

Epoch: 439| Step: 0
Training loss: 0.14524534344673157
Validation loss: 1.6342534595920193

Epoch: 6| Step: 1
Training loss: 0.25232404470443726
Validation loss: 1.6412754635657034

Epoch: 6| Step: 2
Training loss: 0.09138859063386917
Validation loss: 1.630724795403019

Epoch: 6| Step: 3
Training loss: 0.11316873133182526
Validation loss: 1.6704619469181183

Epoch: 6| Step: 4
Training loss: 0.145645409822464
Validation loss: 1.6215909360557474

Epoch: 6| Step: 5
Training loss: 0.19872801005840302
Validation loss: 1.633698424985332

Epoch: 6| Step: 6
Training loss: 0.21970483660697937
Validation loss: 1.6289755862246278

Epoch: 6| Step: 7
Training loss: 0.16922980546951294
Validation loss: 1.6487619094951178

Epoch: 6| Step: 8
Training loss: 0.1388164460659027
Validation loss: 1.6264664037253267

Epoch: 6| Step: 9
Training loss: 0.07135683298110962
Validation loss: 1.6349808631404754

Epoch: 6| Step: 10
Training loss: 0.1837010681629181
Validation loss: 1.6592922890058128

Epoch: 6| Step: 11
Training loss: 0.11396046727895737
Validation loss: 1.6425525706301454

Epoch: 6| Step: 12
Training loss: 0.2090853899717331
Validation loss: 1.6791585824822868

Epoch: 6| Step: 13
Training loss: 0.10155773162841797
Validation loss: 1.6674727803917342

Epoch: 440| Step: 0
Training loss: 0.17643550038337708
Validation loss: 1.682126199045489

Epoch: 6| Step: 1
Training loss: 0.17754045128822327
Validation loss: 1.6466354759790565

Epoch: 6| Step: 2
Training loss: 0.20048007369041443
Validation loss: 1.676358151179488

Epoch: 6| Step: 3
Training loss: 0.2369031310081482
Validation loss: 1.6683185126191826

Epoch: 6| Step: 4
Training loss: 0.14512988924980164
Validation loss: 1.6250499999651344

Epoch: 6| Step: 5
Training loss: 0.11727800965309143
Validation loss: 1.62661571656504

Epoch: 6| Step: 6
Training loss: 0.20313891768455505
Validation loss: 1.649402379989624

Epoch: 6| Step: 7
Training loss: 0.15431705117225647
Validation loss: 1.6387180128405172

Epoch: 6| Step: 8
Training loss: 0.13185814023017883
Validation loss: 1.642012889667224

Epoch: 6| Step: 9
Training loss: 0.17075979709625244
Validation loss: 1.6083652460446922

Epoch: 6| Step: 10
Training loss: 0.12480233609676361
Validation loss: 1.5794035824396278

Epoch: 6| Step: 11
Training loss: 0.170270636677742
Validation loss: 1.6079626769147894

Epoch: 6| Step: 12
Training loss: 0.14476943016052246
Validation loss: 1.6151110869581982

Epoch: 6| Step: 13
Training loss: 0.1327165961265564
Validation loss: 1.6065356795505812

Epoch: 441| Step: 0
Training loss: 0.2274838089942932
Validation loss: 1.6159383943003993

Epoch: 6| Step: 1
Training loss: 0.14203815162181854
Validation loss: 1.581361695002484

Epoch: 6| Step: 2
Training loss: 0.13492296636104584
Validation loss: 1.5698313174709198

Epoch: 6| Step: 3
Training loss: 0.1787499338388443
Validation loss: 1.5800705558510237

Epoch: 6| Step: 4
Training loss: 0.2194451242685318
Validation loss: 1.578266841109081

Epoch: 6| Step: 5
Training loss: 0.10155966132879257
Validation loss: 1.6018272689593736

Epoch: 6| Step: 6
Training loss: 0.19765278697013855
Validation loss: 1.6041720041664698

Epoch: 6| Step: 7
Training loss: 0.1838199496269226
Validation loss: 1.6155518575381207

Epoch: 6| Step: 8
Training loss: 0.24716374278068542
Validation loss: 1.616532701317982

Epoch: 6| Step: 9
Training loss: 0.12057767808437347
Validation loss: 1.6501292028734762

Epoch: 6| Step: 10
Training loss: 0.22476813197135925
Validation loss: 1.6416261144863662

Epoch: 6| Step: 11
Training loss: 0.1524827778339386
Validation loss: 1.6843770960325837

Epoch: 6| Step: 12
Training loss: 0.2901908755302429
Validation loss: 1.6701842969463718

Epoch: 6| Step: 13
Training loss: 0.13603466749191284
Validation loss: 1.6582764899858864

Epoch: 442| Step: 0
Training loss: 0.1870451122522354
Validation loss: 1.6639217612563924

Epoch: 6| Step: 1
Training loss: 0.186265766620636
Validation loss: 1.6803860177275955

Epoch: 6| Step: 2
Training loss: 0.20516395568847656
Validation loss: 1.7102531566414783

Epoch: 6| Step: 3
Training loss: 0.21348470449447632
Validation loss: 1.674706789755052

Epoch: 6| Step: 4
Training loss: 0.2281990647315979
Validation loss: 1.6941147773496565

Epoch: 6| Step: 5
Training loss: 0.1423376053571701
Validation loss: 1.6889361822476952

Epoch: 6| Step: 6
Training loss: 0.16383934020996094
Validation loss: 1.6577367013500584

Epoch: 6| Step: 7
Training loss: 0.18159639835357666
Validation loss: 1.6130054612313547

Epoch: 6| Step: 8
Training loss: 0.25365281105041504
Validation loss: 1.6403289584703342

Epoch: 6| Step: 9
Training loss: 0.11022596061229706
Validation loss: 1.612819871594829

Epoch: 6| Step: 10
Training loss: 0.186336487531662
Validation loss: 1.6462426736790647

Epoch: 6| Step: 11
Training loss: 0.12995870411396027
Validation loss: 1.6341280988467637

Epoch: 6| Step: 12
Training loss: 0.13804709911346436
Validation loss: 1.622599236426815

Epoch: 6| Step: 13
Training loss: 0.12568147480487823
Validation loss: 1.5980582570516935

Epoch: 443| Step: 0
Training loss: 0.16275814175605774
Validation loss: 1.6434592726410076

Epoch: 6| Step: 1
Training loss: 0.17259818315505981
Validation loss: 1.6021701494852703

Epoch: 6| Step: 2
Training loss: 0.2298862636089325
Validation loss: 1.626352180716812

Epoch: 6| Step: 3
Training loss: 0.1777035892009735
Validation loss: 1.670111826671067

Epoch: 6| Step: 4
Training loss: 0.24601954221725464
Validation loss: 1.6290513982055008

Epoch: 6| Step: 5
Training loss: 0.1432686150074005
Validation loss: 1.6287521841705486

Epoch: 6| Step: 6
Training loss: 0.20043954253196716
Validation loss: 1.6517011991111181

Epoch: 6| Step: 7
Training loss: 0.14783133566379547
Validation loss: 1.634687138501034

Epoch: 6| Step: 8
Training loss: 0.10488627851009369
Validation loss: 1.646546309994113

Epoch: 6| Step: 9
Training loss: 0.13134542107582092
Validation loss: 1.6111782981503395

Epoch: 6| Step: 10
Training loss: 0.12011981755495071
Validation loss: 1.6251768501855994

Epoch: 6| Step: 11
Training loss: 0.1040845587849617
Validation loss: 1.60895755598622

Epoch: 6| Step: 12
Training loss: 0.14335888624191284
Validation loss: 1.6045678853988647

Epoch: 6| Step: 13
Training loss: 0.25964438915252686
Validation loss: 1.6267866062861618

Epoch: 444| Step: 0
Training loss: 0.2502567768096924
Validation loss: 1.613276825156263

Epoch: 6| Step: 1
Training loss: 0.17376787960529327
Validation loss: 1.642869153330403

Epoch: 6| Step: 2
Training loss: 0.23871050775051117
Validation loss: 1.6509652201847365

Epoch: 6| Step: 3
Training loss: 0.19387270510196686
Validation loss: 1.642002724832104

Epoch: 6| Step: 4
Training loss: 0.15187813341617584
Validation loss: 1.6203357743960556

Epoch: 6| Step: 5
Training loss: 0.2205270528793335
Validation loss: 1.6276978395318473

Epoch: 6| Step: 6
Training loss: 0.21282649040222168
Validation loss: 1.641119868524613

Epoch: 6| Step: 7
Training loss: 0.17226392030715942
Validation loss: 1.6304246379483132

Epoch: 6| Step: 8
Training loss: 0.147009938955307
Validation loss: 1.6178039145726029

Epoch: 6| Step: 9
Training loss: 0.11626951396465302
Validation loss: 1.6437908731481081

Epoch: 6| Step: 10
Training loss: 0.16945421695709229
Validation loss: 1.6590040114618116

Epoch: 6| Step: 11
Training loss: 0.16291749477386475
Validation loss: 1.6431115211979035

Epoch: 6| Step: 12
Training loss: 0.2254483699798584
Validation loss: 1.6202924815557336

Epoch: 6| Step: 13
Training loss: 0.07621000707149506
Validation loss: 1.5666627396819413

Epoch: 445| Step: 0
Training loss: 0.11699284613132477
Validation loss: 1.5704988882105837

Epoch: 6| Step: 1
Training loss: 0.1963057816028595
Validation loss: 1.5731694108696395

Epoch: 6| Step: 2
Training loss: 0.30356496572494507
Validation loss: 1.575735116517672

Epoch: 6| Step: 3
Training loss: 0.19331613183021545
Validation loss: 1.5660747212748374

Epoch: 6| Step: 4
Training loss: 0.18515799939632416
Validation loss: 1.5872147108918877

Epoch: 6| Step: 5
Training loss: 0.20738941431045532
Validation loss: 1.6178964953268729

Epoch: 6| Step: 6
Training loss: 0.2308180183172226
Validation loss: 1.6284612917130994

Epoch: 6| Step: 7
Training loss: 0.15385258197784424
Validation loss: 1.6196011625310427

Epoch: 6| Step: 8
Training loss: 0.10355815291404724
Validation loss: 1.5982391834259033

Epoch: 6| Step: 9
Training loss: 0.10482034832239151
Validation loss: 1.609030540271472

Epoch: 6| Step: 10
Training loss: 0.14467927813529968
Validation loss: 1.6064852501756401

Epoch: 6| Step: 11
Training loss: 0.1876038908958435
Validation loss: 1.5927803888115832

Epoch: 6| Step: 12
Training loss: 0.227566659450531
Validation loss: 1.6731206601665867

Epoch: 6| Step: 13
Training loss: 0.1258009523153305
Validation loss: 1.6453977887348463

Epoch: 446| Step: 0
Training loss: 0.12535685300827026
Validation loss: 1.6216095698777067

Epoch: 6| Step: 1
Training loss: 0.1973589062690735
Validation loss: 1.599753265739769

Epoch: 6| Step: 2
Training loss: 0.32407379150390625
Validation loss: 1.5511269300214705

Epoch: 6| Step: 3
Training loss: 0.1907098889350891
Validation loss: 1.6327479206105715

Epoch: 6| Step: 4
Training loss: 0.20433950424194336
Validation loss: 1.578293074843704

Epoch: 6| Step: 5
Training loss: 0.18975120782852173
Validation loss: 1.6254097530918736

Epoch: 6| Step: 6
Training loss: 0.10529057681560516
Validation loss: 1.5740059909000192

Epoch: 6| Step: 7
Training loss: 0.14984115958213806
Validation loss: 1.5991069206627466

Epoch: 6| Step: 8
Training loss: 0.17679795622825623
Validation loss: 1.6371059366451797

Epoch: 6| Step: 9
Training loss: 0.1709195375442505
Validation loss: 1.6085102878591067

Epoch: 6| Step: 10
Training loss: 0.2126786857843399
Validation loss: 1.6395251981673702

Epoch: 6| Step: 11
Training loss: 0.22385618090629578
Validation loss: 1.598164382801261

Epoch: 6| Step: 12
Training loss: 0.1279338300228119
Validation loss: 1.6138145936432706

Epoch: 6| Step: 13
Training loss: 0.1494917869567871
Validation loss: 1.6077839251487487

Epoch: 447| Step: 0
Training loss: 0.17426082491874695
Validation loss: 1.6024672267257527

Epoch: 6| Step: 1
Training loss: 0.16833312809467316
Validation loss: 1.6572615850356318

Epoch: 6| Step: 2
Training loss: 0.20656993985176086
Validation loss: 1.635778123332608

Epoch: 6| Step: 3
Training loss: 0.2577393352985382
Validation loss: 1.7227189451135614

Epoch: 6| Step: 4
Training loss: 0.17147010564804077
Validation loss: 1.6553651376437115

Epoch: 6| Step: 5
Training loss: 0.13188916444778442
Validation loss: 1.615038582073745

Epoch: 6| Step: 6
Training loss: 0.09232041984796524
Validation loss: 1.6379920257035123

Epoch: 6| Step: 7
Training loss: 0.135190948843956
Validation loss: 1.641677571881202

Epoch: 6| Step: 8
Training loss: 0.08601483702659607
Validation loss: 1.598835006836922

Epoch: 6| Step: 9
Training loss: 0.13502033054828644
Validation loss: 1.6279973932491836

Epoch: 6| Step: 10
Training loss: 0.1393319070339203
Validation loss: 1.6314159747092956

Epoch: 6| Step: 11
Training loss: 0.18573975563049316
Validation loss: 1.6537456486814766

Epoch: 6| Step: 12
Training loss: 0.23353980481624603
Validation loss: 1.6008917042004165

Epoch: 6| Step: 13
Training loss: 0.10823759436607361
Validation loss: 1.6289418692229896

Epoch: 448| Step: 0
Training loss: 0.10415806621313095
Validation loss: 1.6226108356188702

Epoch: 6| Step: 1
Training loss: 0.1595073938369751
Validation loss: 1.6273714021969867

Epoch: 6| Step: 2
Training loss: 0.15141727030277252
Validation loss: 1.6177610646012008

Epoch: 6| Step: 3
Training loss: 0.1319115161895752
Validation loss: 1.6308298790326683

Epoch: 6| Step: 4
Training loss: 0.13632738590240479
Validation loss: 1.6203673129440637

Epoch: 6| Step: 5
Training loss: 0.09480088949203491
Validation loss: 1.637366606343177

Epoch: 6| Step: 6
Training loss: 0.08394226431846619
Validation loss: 1.6163073380788167

Epoch: 6| Step: 7
Training loss: 0.09527677297592163
Validation loss: 1.6184285891953336

Epoch: 6| Step: 8
Training loss: 0.2427709996700287
Validation loss: 1.6115342186343284

Epoch: 6| Step: 9
Training loss: 0.18059350550174713
Validation loss: 1.6389343533464658

Epoch: 6| Step: 10
Training loss: 0.07404258847236633
Validation loss: 1.6454706717562932

Epoch: 6| Step: 11
Training loss: 0.18941497802734375
Validation loss: 1.6463609305761193

Epoch: 6| Step: 12
Training loss: 0.1216016635298729
Validation loss: 1.6520292457713877

Epoch: 6| Step: 13
Training loss: 0.04651649296283722
Validation loss: 1.6374774043278029

Epoch: 449| Step: 0
Training loss: 0.08910788595676422
Validation loss: 1.61703416608995

Epoch: 6| Step: 1
Training loss: 0.13531921803951263
Validation loss: 1.6354087950080953

Epoch: 6| Step: 2
Training loss: 0.11994201689958572
Validation loss: 1.6110917304151802

Epoch: 6| Step: 3
Training loss: 0.21251429617404938
Validation loss: 1.6085527468753118

Epoch: 6| Step: 4
Training loss: 0.23519650101661682
Validation loss: 1.601062665703476

Epoch: 6| Step: 5
Training loss: 0.08562594652175903
Validation loss: 1.6140889897141406

Epoch: 6| Step: 6
Training loss: 0.14617778360843658
Validation loss: 1.6003549778333275

Epoch: 6| Step: 7
Training loss: 0.14277499914169312
Validation loss: 1.6012773629157775

Epoch: 6| Step: 8
Training loss: 0.09281972050666809
Validation loss: 1.6279084272282098

Epoch: 6| Step: 9
Training loss: 0.11679382622241974
Validation loss: 1.630734980747264

Epoch: 6| Step: 10
Training loss: 0.09353974461555481
Validation loss: 1.5872592554297498

Epoch: 6| Step: 11
Training loss: 0.11745838075876236
Validation loss: 1.6136364052372594

Epoch: 6| Step: 12
Training loss: 0.12260708212852478
Validation loss: 1.6068159341812134

Epoch: 6| Step: 13
Training loss: 0.19667233526706696
Validation loss: 1.604488811185283

Epoch: 450| Step: 0
Training loss: 0.09416443109512329
Validation loss: 1.6066579652088944

Epoch: 6| Step: 1
Training loss: 0.15522702038288116
Validation loss: 1.6380618887562906

Epoch: 6| Step: 2
Training loss: 0.16438892483711243
Validation loss: 1.6387785737232496

Epoch: 6| Step: 3
Training loss: 0.22231683135032654
Validation loss: 1.652558377994004

Epoch: 6| Step: 4
Training loss: 0.17529377341270447
Validation loss: 1.6207027448120939

Epoch: 6| Step: 5
Training loss: 0.14201021194458008
Validation loss: 1.6219013006456438

Epoch: 6| Step: 6
Training loss: 0.11835116893053055
Validation loss: 1.6148790108260287

Epoch: 6| Step: 7
Training loss: 0.07967983186244965
Validation loss: 1.6278485982648787

Epoch: 6| Step: 8
Training loss: 0.15284068882465363
Validation loss: 1.6327388132772138

Epoch: 6| Step: 9
Training loss: 0.17870736122131348
Validation loss: 1.6106407450091453

Epoch: 6| Step: 10
Training loss: 0.09063097834587097
Validation loss: 1.6255624640372492

Epoch: 6| Step: 11
Training loss: 0.1522543877363205
Validation loss: 1.6197476822842833

Epoch: 6| Step: 12
Training loss: 0.09791982173919678
Validation loss: 1.6219623191382295

Epoch: 6| Step: 13
Training loss: 0.22555753588676453
Validation loss: 1.647640125725859

Epoch: 451| Step: 0
Training loss: 0.11278314888477325
Validation loss: 1.6411351478228005

Epoch: 6| Step: 1
Training loss: 0.17094942927360535
Validation loss: 1.631968512330004

Epoch: 6| Step: 2
Training loss: 0.18067055940628052
Validation loss: 1.6668164614708192

Epoch: 6| Step: 3
Training loss: 0.1053198054432869
Validation loss: 1.65072625811382

Epoch: 6| Step: 4
Training loss: 0.21875981986522675
Validation loss: 1.6651840697052658

Epoch: 6| Step: 5
Training loss: 0.14182624220848083
Validation loss: 1.650801609921199

Epoch: 6| Step: 6
Training loss: 0.12794002890586853
Validation loss: 1.6137144450218446

Epoch: 6| Step: 7
Training loss: 0.08673349767923355
Validation loss: 1.603963812192281

Epoch: 6| Step: 8
Training loss: 0.2089196741580963
Validation loss: 1.596311605104836

Epoch: 6| Step: 9
Training loss: 0.09172128140926361
Validation loss: 1.6016775600371822

Epoch: 6| Step: 10
Training loss: 0.09808097779750824
Validation loss: 1.6012503389389283

Epoch: 6| Step: 11
Training loss: 0.18375146389007568
Validation loss: 1.5845425282755206

Epoch: 6| Step: 12
Training loss: 0.17806664109230042
Validation loss: 1.6030806956752655

Epoch: 6| Step: 13
Training loss: 0.17219074070453644
Validation loss: 1.617108565504833

Epoch: 452| Step: 0
Training loss: 0.10310953855514526
Validation loss: 1.5852553485542216

Epoch: 6| Step: 1
Training loss: 0.16288787126541138
Validation loss: 1.6052300942841398

Epoch: 6| Step: 2
Training loss: 0.1118829995393753
Validation loss: 1.5873399396096506

Epoch: 6| Step: 3
Training loss: 0.06806528568267822
Validation loss: 1.6047768695380098

Epoch: 6| Step: 4
Training loss: 0.0911245197057724
Validation loss: 1.5906078533459735

Epoch: 6| Step: 5
Training loss: 0.1597571074962616
Validation loss: 1.6425653029513616

Epoch: 6| Step: 6
Training loss: 0.1728202998638153
Validation loss: 1.6003567582817488

Epoch: 6| Step: 7
Training loss: 0.1306755393743515
Validation loss: 1.6373313985845095

Epoch: 6| Step: 8
Training loss: 0.17828872799873352
Validation loss: 1.6501229322084816

Epoch: 6| Step: 9
Training loss: 0.17385950684547424
Validation loss: 1.65916000130356

Epoch: 6| Step: 10
Training loss: 0.19511820375919342
Validation loss: 1.6530124025960122

Epoch: 6| Step: 11
Training loss: 0.13564036786556244
Validation loss: 1.6447526613871257

Epoch: 6| Step: 12
Training loss: 0.16794277727603912
Validation loss: 1.6644968345601072

Epoch: 6| Step: 13
Training loss: 0.12104091048240662
Validation loss: 1.6259582081148702

Epoch: 453| Step: 0
Training loss: 0.16543149948120117
Validation loss: 1.6561241406266407

Epoch: 6| Step: 1
Training loss: 0.15494795143604279
Validation loss: 1.6296683857517857

Epoch: 6| Step: 2
Training loss: 0.1164063960313797
Validation loss: 1.6041471483886882

Epoch: 6| Step: 3
Training loss: 0.17775674164295197
Validation loss: 1.6140639833224717

Epoch: 6| Step: 4
Training loss: 0.1718468815088272
Validation loss: 1.5945251693007767

Epoch: 6| Step: 5
Training loss: 0.10876769572496414
Validation loss: 1.5899371306101482

Epoch: 6| Step: 6
Training loss: 0.14252036809921265
Validation loss: 1.605813152046614

Epoch: 6| Step: 7
Training loss: 0.18309694528579712
Validation loss: 1.6113614959101523

Epoch: 6| Step: 8
Training loss: 0.08691663295030594
Validation loss: 1.5931972726698844

Epoch: 6| Step: 9
Training loss: 0.1484394669532776
Validation loss: 1.5731926195083126

Epoch: 6| Step: 10
Training loss: 0.11718377470970154
Validation loss: 1.574387522153957

Epoch: 6| Step: 11
Training loss: 0.13158169388771057
Validation loss: 1.6017874927930935

Epoch: 6| Step: 12
Training loss: 0.15804964303970337
Validation loss: 1.5745164527687976

Epoch: 6| Step: 13
Training loss: 0.16126488149166107
Validation loss: 1.6041900316874187

Epoch: 454| Step: 0
Training loss: 0.08575348556041718
Validation loss: 1.5938637064349266

Epoch: 6| Step: 1
Training loss: 0.16798394918441772
Validation loss: 1.596608418290333

Epoch: 6| Step: 2
Training loss: 0.13257494568824768
Validation loss: 1.6300013001247118

Epoch: 6| Step: 3
Training loss: 0.1254308521747589
Validation loss: 1.6401037182859195

Epoch: 6| Step: 4
Training loss: 0.14920251071453094
Validation loss: 1.6392184880471998

Epoch: 6| Step: 5
Training loss: 0.13559472560882568
Validation loss: 1.675064532987533

Epoch: 6| Step: 6
Training loss: 0.1359167844057083
Validation loss: 1.6492830117543538

Epoch: 6| Step: 7
Training loss: 0.21405097842216492
Validation loss: 1.6793447297106507

Epoch: 6| Step: 8
Training loss: 0.17248423397541046
Validation loss: 1.6731365175657376

Epoch: 6| Step: 9
Training loss: 0.1286877691745758
Validation loss: 1.6868514989012031

Epoch: 6| Step: 10
Training loss: 0.10476133227348328
Validation loss: 1.6448881087764617

Epoch: 6| Step: 11
Training loss: 0.13770300149917603
Validation loss: 1.6310861251687492

Epoch: 6| Step: 12
Training loss: 0.07814568281173706
Validation loss: 1.5932768737116167

Epoch: 6| Step: 13
Training loss: 0.26309335231781006
Validation loss: 1.560213924736105

Epoch: 455| Step: 0
Training loss: 0.2327561378479004
Validation loss: 1.5869077354349115

Epoch: 6| Step: 1
Training loss: 0.08636056631803513
Validation loss: 1.6095183049478838

Epoch: 6| Step: 2
Training loss: 0.15261709690093994
Validation loss: 1.606699764087636

Epoch: 6| Step: 3
Training loss: 0.19091370701789856
Validation loss: 1.619534909084279

Epoch: 6| Step: 4
Training loss: 0.1545426845550537
Validation loss: 1.5995932253458167

Epoch: 6| Step: 5
Training loss: 0.1020350307226181
Validation loss: 1.6118958803915209

Epoch: 6| Step: 6
Training loss: 0.16367900371551514
Validation loss: 1.633730706348214

Epoch: 6| Step: 7
Training loss: 0.08593592047691345
Validation loss: 1.6172497849310599

Epoch: 6| Step: 8
Training loss: 0.2161789983510971
Validation loss: 1.612614836744083

Epoch: 6| Step: 9
Training loss: 0.20271438360214233
Validation loss: 1.655889029143959

Epoch: 6| Step: 10
Training loss: 0.10386316478252411
Validation loss: 1.6637511894267092

Epoch: 6| Step: 11
Training loss: 0.09742359817028046
Validation loss: 1.6438083482044998

Epoch: 6| Step: 12
Training loss: 0.14103606343269348
Validation loss: 1.667502591686864

Epoch: 6| Step: 13
Training loss: 0.06495246291160583
Validation loss: 1.6619120772166918

Epoch: 456| Step: 0
Training loss: 0.17923903465270996
Validation loss: 1.6681785198949999

Epoch: 6| Step: 1
Training loss: 0.18458117544651031
Validation loss: 1.6461141494012648

Epoch: 6| Step: 2
Training loss: 0.08202861249446869
Validation loss: 1.6581325748915314

Epoch: 6| Step: 3
Training loss: 0.14720959961414337
Validation loss: 1.6563642640267648

Epoch: 6| Step: 4
Training loss: 0.10096296668052673
Validation loss: 1.6315292241752788

Epoch: 6| Step: 5
Training loss: 0.08594461530447006
Validation loss: 1.5996813799745293

Epoch: 6| Step: 6
Training loss: 0.11719118803739548
Validation loss: 1.6391629378000896

Epoch: 6| Step: 7
Training loss: 0.11669417470693588
Validation loss: 1.5841707875651698

Epoch: 6| Step: 8
Training loss: 0.10440059751272202
Validation loss: 1.5925766498811784

Epoch: 6| Step: 9
Training loss: 0.09413442015647888
Validation loss: 1.5931063390547229

Epoch: 6| Step: 10
Training loss: 0.1671004444360733
Validation loss: 1.634998122851054

Epoch: 6| Step: 11
Training loss: 0.12033508718013763
Validation loss: 1.6022777967555548

Epoch: 6| Step: 12
Training loss: 0.17914097011089325
Validation loss: 1.5994730470001057

Epoch: 6| Step: 13
Training loss: 0.2599017918109894
Validation loss: 1.6221181833615868

Epoch: 457| Step: 0
Training loss: 0.11813586950302124
Validation loss: 1.5862914400715982

Epoch: 6| Step: 1
Training loss: 0.21630841493606567
Validation loss: 1.6163791014302162

Epoch: 6| Step: 2
Training loss: 0.1275579035282135
Validation loss: 1.5920765579387706

Epoch: 6| Step: 3
Training loss: 0.08768928050994873
Validation loss: 1.584995719694322

Epoch: 6| Step: 4
Training loss: 0.14822593331336975
Validation loss: 1.5752769118996077

Epoch: 6| Step: 5
Training loss: 0.19406133890151978
Validation loss: 1.5924732313361218

Epoch: 6| Step: 6
Training loss: 0.16408300399780273
Validation loss: 1.6139835567884548

Epoch: 6| Step: 7
Training loss: 0.1789238005876541
Validation loss: 1.614571375872499

Epoch: 6| Step: 8
Training loss: 0.14549648761749268
Validation loss: 1.598265886947673

Epoch: 6| Step: 9
Training loss: 0.1503705084323883
Validation loss: 1.5787041815378333

Epoch: 6| Step: 10
Training loss: 0.2059505134820938
Validation loss: 1.6118638515472412

Epoch: 6| Step: 11
Training loss: 0.163438618183136
Validation loss: 1.616374243972122

Epoch: 6| Step: 12
Training loss: 0.15224871039390564
Validation loss: 1.6085343540355723

Epoch: 6| Step: 13
Training loss: 0.170277938246727
Validation loss: 1.5818561776991813

Epoch: 458| Step: 0
Training loss: 0.16203120350837708
Validation loss: 1.604719740088268

Epoch: 6| Step: 1
Training loss: 0.09125915914773941
Validation loss: 1.6133120008694228

Epoch: 6| Step: 2
Training loss: 0.16873827576637268
Validation loss: 1.5763476651201966

Epoch: 6| Step: 3
Training loss: 0.13835200667381287
Validation loss: 1.5670094438778457

Epoch: 6| Step: 4
Training loss: 0.08041438460350037
Validation loss: 1.5908163670570619

Epoch: 6| Step: 5
Training loss: 0.16256111860275269
Validation loss: 1.5658302589129376

Epoch: 6| Step: 6
Training loss: 0.10841282457113266
Validation loss: 1.5941092147622058

Epoch: 6| Step: 7
Training loss: 0.11709249019622803
Validation loss: 1.633008026307629

Epoch: 6| Step: 8
Training loss: 0.14838287234306335
Validation loss: 1.6351162695115613

Epoch: 6| Step: 9
Training loss: 0.3114910423755646
Validation loss: 1.6314379938187138

Epoch: 6| Step: 10
Training loss: 0.15269112586975098
Validation loss: 1.5871392667934459

Epoch: 6| Step: 11
Training loss: 0.11004574596881866
Validation loss: 1.6027094394929948

Epoch: 6| Step: 12
Training loss: 0.2799692153930664
Validation loss: 1.6115528460471862

Epoch: 6| Step: 13
Training loss: 0.14395499229431152
Validation loss: 1.6265583807422268

Epoch: 459| Step: 0
Training loss: 0.16401362419128418
Validation loss: 1.6149575377023349

Epoch: 6| Step: 1
Training loss: 0.21696648001670837
Validation loss: 1.6302387278567079

Epoch: 6| Step: 2
Training loss: 0.18245084583759308
Validation loss: 1.635196082053646

Epoch: 6| Step: 3
Training loss: 0.24871736764907837
Validation loss: 1.647278247341033

Epoch: 6| Step: 4
Training loss: 0.15286098420619965
Validation loss: 1.631807695152939

Epoch: 6| Step: 5
Training loss: 0.22327740490436554
Validation loss: 1.6214325761282316

Epoch: 6| Step: 6
Training loss: 0.21097341179847717
Validation loss: 1.6495573751388057

Epoch: 6| Step: 7
Training loss: 0.17231518030166626
Validation loss: 1.6388702315668906

Epoch: 6| Step: 8
Training loss: 0.14970405399799347
Validation loss: 1.6237338832629624

Epoch: 6| Step: 9
Training loss: 0.13494311273097992
Validation loss: 1.6391412506821335

Epoch: 6| Step: 10
Training loss: 0.13655853271484375
Validation loss: 1.6224668987335698

Epoch: 6| Step: 11
Training loss: 0.19692887365818024
Validation loss: 1.6525797933660529

Epoch: 6| Step: 12
Training loss: 0.15471209585666656
Validation loss: 1.6546220651236914

Epoch: 6| Step: 13
Training loss: 0.26103144884109497
Validation loss: 1.6434974503773514

Epoch: 460| Step: 0
Training loss: 0.17112398147583008
Validation loss: 1.6567113117505146

Epoch: 6| Step: 1
Training loss: 0.17528343200683594
Validation loss: 1.6469915656633274

Epoch: 6| Step: 2
Training loss: 0.10264500230550766
Validation loss: 1.6601749261220295

Epoch: 6| Step: 3
Training loss: 0.23192408680915833
Validation loss: 1.646600713012039

Epoch: 6| Step: 4
Training loss: 0.11687834560871124
Validation loss: 1.645542803631034

Epoch: 6| Step: 5
Training loss: 0.1701829433441162
Validation loss: 1.639741861692039

Epoch: 6| Step: 6
Training loss: 0.1532226949930191
Validation loss: 1.6355018410631406

Epoch: 6| Step: 7
Training loss: 0.1972236931324005
Validation loss: 1.6565710331804009

Epoch: 6| Step: 8
Training loss: 0.15226168930530548
Validation loss: 1.6158456443458475

Epoch: 6| Step: 9
Training loss: 0.11500696837902069
Validation loss: 1.6047432166273876

Epoch: 6| Step: 10
Training loss: 0.11170507967472076
Validation loss: 1.6676466170177664

Epoch: 6| Step: 11
Training loss: 0.13927613198757172
Validation loss: 1.6476975871670632

Epoch: 6| Step: 12
Training loss: 0.15726038813591003
Validation loss: 1.6647649029249787

Epoch: 6| Step: 13
Training loss: 0.19816763699054718
Validation loss: 1.6482359619550808

Epoch: 461| Step: 0
Training loss: 0.16362828016281128
Validation loss: 1.6776973496201217

Epoch: 6| Step: 1
Training loss: 0.17815472185611725
Validation loss: 1.6519814832236177

Epoch: 6| Step: 2
Training loss: 0.22755300998687744
Validation loss: 1.641800126721782

Epoch: 6| Step: 3
Training loss: 0.16630813479423523
Validation loss: 1.6134302859665246

Epoch: 6| Step: 4
Training loss: 0.15013974905014038
Validation loss: 1.60725716557554

Epoch: 6| Step: 5
Training loss: 0.0682874470949173
Validation loss: 1.5984413777628252

Epoch: 6| Step: 6
Training loss: 0.08493742346763611
Validation loss: 1.6186791684037896

Epoch: 6| Step: 7
Training loss: 0.12717275321483612
Validation loss: 1.6106875814417356

Epoch: 6| Step: 8
Training loss: 0.19272567331790924
Validation loss: 1.586805123154835

Epoch: 6| Step: 9
Training loss: 0.14923930168151855
Validation loss: 1.5471609228400773

Epoch: 6| Step: 10
Training loss: 0.1868310272693634
Validation loss: 1.5961535476869153

Epoch: 6| Step: 11
Training loss: 0.1198810487985611
Validation loss: 1.5776738941028554

Epoch: 6| Step: 12
Training loss: 0.10357987880706787
Validation loss: 1.562783298953887

Epoch: 6| Step: 13
Training loss: 0.10761414468288422
Validation loss: 1.5325928003557268

Epoch: 462| Step: 0
Training loss: 0.15220853686332703
Validation loss: 1.5651986547695693

Epoch: 6| Step: 1
Training loss: 0.13988882303237915
Validation loss: 1.5832624409788398

Epoch: 6| Step: 2
Training loss: 0.1654229760169983
Validation loss: 1.589507831040249

Epoch: 6| Step: 3
Training loss: 0.1843603551387787
Validation loss: 1.5753794780341528

Epoch: 6| Step: 4
Training loss: 0.171510249376297
Validation loss: 1.5394233324194466

Epoch: 6| Step: 5
Training loss: 0.1495935320854187
Validation loss: 1.5382324482804985

Epoch: 6| Step: 6
Training loss: 0.16454827785491943
Validation loss: 1.5667622896932787

Epoch: 6| Step: 7
Training loss: 0.17233990132808685
Validation loss: 1.574198543384511

Epoch: 6| Step: 8
Training loss: 0.08906638622283936
Validation loss: 1.5459823916035313

Epoch: 6| Step: 9
Training loss: 0.1875174343585968
Validation loss: 1.6213459968566895

Epoch: 6| Step: 10
Training loss: 0.12786993384361267
Validation loss: 1.6414125580941477

Epoch: 6| Step: 11
Training loss: 0.18540437519550323
Validation loss: 1.623680644137885

Epoch: 6| Step: 12
Training loss: 0.21590973436832428
Validation loss: 1.5974176327387493

Epoch: 6| Step: 13
Training loss: 0.087087482213974
Validation loss: 1.623133715762887

Epoch: 463| Step: 0
Training loss: 0.14383438229560852
Validation loss: 1.628733988731138

Epoch: 6| Step: 1
Training loss: 0.1271657943725586
Validation loss: 1.6123733289780156

Epoch: 6| Step: 2
Training loss: 0.12227746099233627
Validation loss: 1.606833174664487

Epoch: 6| Step: 3
Training loss: 0.15114489197731018
Validation loss: 1.614852455354506

Epoch: 6| Step: 4
Training loss: 0.12123298645019531
Validation loss: 1.6223054547463693

Epoch: 6| Step: 5
Training loss: 0.15898397564888
Validation loss: 1.6389212454518964

Epoch: 6| Step: 6
Training loss: 0.12830649316310883
Validation loss: 1.6313713032712218

Epoch: 6| Step: 7
Training loss: 0.1757282018661499
Validation loss: 1.5972936320048507

Epoch: 6| Step: 8
Training loss: 0.14245733618736267
Validation loss: 1.6098862642882972

Epoch: 6| Step: 9
Training loss: 0.07830406725406647
Validation loss: 1.607545885988461

Epoch: 6| Step: 10
Training loss: 0.17032063007354736
Validation loss: 1.5810196848325833

Epoch: 6| Step: 11
Training loss: 0.1417573094367981
Validation loss: 1.5952874896346882

Epoch: 6| Step: 12
Training loss: 0.14585909247398376
Validation loss: 1.5654273981689124

Epoch: 6| Step: 13
Training loss: 0.12370896339416504
Validation loss: 1.5874716261381745

Epoch: 464| Step: 0
Training loss: 0.13580322265625
Validation loss: 1.6044433604004562

Epoch: 6| Step: 1
Training loss: 0.08466881513595581
Validation loss: 1.5771574384422713

Epoch: 6| Step: 2
Training loss: 0.16114971041679382
Validation loss: 1.5818799118841849

Epoch: 6| Step: 3
Training loss: 0.15439967811107635
Validation loss: 1.5757132345630276

Epoch: 6| Step: 4
Training loss: 0.1206129938364029
Validation loss: 1.5332424589382705

Epoch: 6| Step: 5
Training loss: 0.13837695121765137
Validation loss: 1.559878787686748

Epoch: 6| Step: 6
Training loss: 0.10293948650360107
Validation loss: 1.5531378676814418

Epoch: 6| Step: 7
Training loss: 0.19116994738578796
Validation loss: 1.5875017822429698

Epoch: 6| Step: 8
Training loss: 0.1125355213880539
Validation loss: 1.5754011113156554

Epoch: 6| Step: 9
Training loss: 0.1487654447555542
Validation loss: 1.6004858145149805

Epoch: 6| Step: 10
Training loss: 0.14842036366462708
Validation loss: 1.5670751948510446

Epoch: 6| Step: 11
Training loss: 0.13781604170799255
Validation loss: 1.5525984751280917

Epoch: 6| Step: 12
Training loss: 0.22217467427253723
Validation loss: 1.5742843792002688

Epoch: 6| Step: 13
Training loss: 0.08744924515485764
Validation loss: 1.5737293369026595

Epoch: 465| Step: 0
Training loss: 0.16875331103801727
Validation loss: 1.5821660833974038

Epoch: 6| Step: 1
Training loss: 0.0881207138299942
Validation loss: 1.5770342401278916

Epoch: 6| Step: 2
Training loss: 0.1652071475982666
Validation loss: 1.5877004490103772

Epoch: 6| Step: 3
Training loss: 0.06959424912929535
Validation loss: 1.5695361116881013

Epoch: 6| Step: 4
Training loss: 0.14093324542045593
Validation loss: 1.609540247148083

Epoch: 6| Step: 5
Training loss: 0.12401437759399414
Validation loss: 1.583387836333244

Epoch: 6| Step: 6
Training loss: 0.09860093891620636
Validation loss: 1.5718009125801824

Epoch: 6| Step: 7
Training loss: 0.10918760299682617
Validation loss: 1.5963659453135666

Epoch: 6| Step: 8
Training loss: 0.14679250121116638
Validation loss: 1.57564801298162

Epoch: 6| Step: 9
Training loss: 0.12109541147947311
Validation loss: 1.594792935156053

Epoch: 6| Step: 10
Training loss: 0.11922277510166168
Validation loss: 1.5800295247826526

Epoch: 6| Step: 11
Training loss: 0.13450315594673157
Validation loss: 1.597828952215051

Epoch: 6| Step: 12
Training loss: 0.19358375668525696
Validation loss: 1.5983930877459946

Epoch: 6| Step: 13
Training loss: 0.1565486490726471
Validation loss: 1.5923581020806425

Epoch: 466| Step: 0
Training loss: 0.17848598957061768
Validation loss: 1.58967686084009

Epoch: 6| Step: 1
Training loss: 0.15770673751831055
Validation loss: 1.6026768005022438

Epoch: 6| Step: 2
Training loss: 0.06288430094718933
Validation loss: 1.6365228955463698

Epoch: 6| Step: 3
Training loss: 0.15903571248054504
Validation loss: 1.6194199797927693

Epoch: 6| Step: 4
Training loss: 0.08967413008213043
Validation loss: 1.584418385900477

Epoch: 6| Step: 5
Training loss: 0.08038181066513062
Validation loss: 1.607647201066376

Epoch: 6| Step: 6
Training loss: 0.10096640139818192
Validation loss: 1.5743729427296629

Epoch: 6| Step: 7
Training loss: 0.08982890844345093
Validation loss: 1.5873543293245378

Epoch: 6| Step: 8
Training loss: 0.10633695125579834
Validation loss: 1.5727937195890693

Epoch: 6| Step: 9
Training loss: 0.126581072807312
Validation loss: 1.5808397903237292

Epoch: 6| Step: 10
Training loss: 0.13256096839904785
Validation loss: 1.532129741484119

Epoch: 6| Step: 11
Training loss: 0.09205958247184753
Validation loss: 1.5440214000722414

Epoch: 6| Step: 12
Training loss: 0.14916905760765076
Validation loss: 1.5386366921086465

Epoch: 6| Step: 13
Training loss: 0.14134293794631958
Validation loss: 1.5427348395829559

Epoch: 467| Step: 0
Training loss: 0.1127188503742218
Validation loss: 1.5462560935686993

Epoch: 6| Step: 1
Training loss: 0.11393967270851135
Validation loss: 1.5633286429989723

Epoch: 6| Step: 2
Training loss: 0.14980998635292053
Validation loss: 1.5454258534216112

Epoch: 6| Step: 3
Training loss: 0.17806749045848846
Validation loss: 1.5375118806797972

Epoch: 6| Step: 4
Training loss: 0.08166740089654922
Validation loss: 1.54613923001033

Epoch: 6| Step: 5
Training loss: 0.25004205107688904
Validation loss: 1.553253855756534

Epoch: 6| Step: 6
Training loss: 0.11220785230398178
Validation loss: 1.5660580858107536

Epoch: 6| Step: 7
Training loss: 0.0762595534324646
Validation loss: 1.5792842103588967

Epoch: 6| Step: 8
Training loss: 0.10822921991348267
Validation loss: 1.5650663824491604

Epoch: 6| Step: 9
Training loss: 0.07132841646671295
Validation loss: 1.5918902120282572

Epoch: 6| Step: 10
Training loss: 0.0848577618598938
Validation loss: 1.5852344753921672

Epoch: 6| Step: 11
Training loss: 0.1415036916732788
Validation loss: 1.5538895181430283

Epoch: 6| Step: 12
Training loss: 0.11500965058803558
Validation loss: 1.576001440325091

Epoch: 6| Step: 13
Training loss: 0.08766469359397888
Validation loss: 1.5820363311357395

Epoch: 468| Step: 0
Training loss: 0.14927613735198975
Validation loss: 1.5821251843565254

Epoch: 6| Step: 1
Training loss: 0.12086525559425354
Validation loss: 1.5877733320318244

Epoch: 6| Step: 2
Training loss: 0.16663655638694763
Validation loss: 1.606860996574484

Epoch: 6| Step: 3
Training loss: 0.18795594573020935
Validation loss: 1.6060190079032735

Epoch: 6| Step: 4
Training loss: 0.20013409852981567
Validation loss: 1.5901790511223577

Epoch: 6| Step: 5
Training loss: 0.09571758657693863
Validation loss: 1.578022264665173

Epoch: 6| Step: 6
Training loss: 0.14571425318717957
Validation loss: 1.532558286061851

Epoch: 6| Step: 7
Training loss: 0.15419945120811462
Validation loss: 1.5378160656139415

Epoch: 6| Step: 8
Training loss: 0.05685289949178696
Validation loss: 1.537744955349994

Epoch: 6| Step: 9
Training loss: 0.1091187447309494
Validation loss: 1.5445300327834262

Epoch: 6| Step: 10
Training loss: 0.15141284465789795
Validation loss: 1.550143866128819

Epoch: 6| Step: 11
Training loss: 0.11288106441497803
Validation loss: 1.574501440089236

Epoch: 6| Step: 12
Training loss: 0.10214909166097641
Validation loss: 1.556673441522865

Epoch: 6| Step: 13
Training loss: 0.10209855437278748
Validation loss: 1.552030372363265

Epoch: 469| Step: 0
Training loss: 0.08703930675983429
Validation loss: 1.5625115299737582

Epoch: 6| Step: 1
Training loss: 0.1440276801586151
Validation loss: 1.5981738169987996

Epoch: 6| Step: 2
Training loss: 0.08371518552303314
Validation loss: 1.55401328943109

Epoch: 6| Step: 3
Training loss: 0.11602983623743057
Validation loss: 1.5660086447192776

Epoch: 6| Step: 4
Training loss: 0.1511143445968628
Validation loss: 1.5550132092609201

Epoch: 6| Step: 5
Training loss: 0.09753450751304626
Validation loss: 1.577772089230117

Epoch: 6| Step: 6
Training loss: 0.0764450654387474
Validation loss: 1.61091786174364

Epoch: 6| Step: 7
Training loss: 0.19780300557613373
Validation loss: 1.593604673621475

Epoch: 6| Step: 8
Training loss: 0.20612913370132446
Validation loss: 1.6199725007498136

Epoch: 6| Step: 9
Training loss: 0.16993241012096405
Validation loss: 1.5945909689831477

Epoch: 6| Step: 10
Training loss: 0.17377141118049622
Validation loss: 1.5961453581369052

Epoch: 6| Step: 11
Training loss: 0.13473661243915558
Validation loss: 1.559620640611136

Epoch: 6| Step: 12
Training loss: 0.13940198719501495
Validation loss: 1.556992849996013

Epoch: 6| Step: 13
Training loss: 0.0904124528169632
Validation loss: 1.5321619036377117

Epoch: 470| Step: 0
Training loss: 0.07881186157464981
Validation loss: 1.5571844718789543

Epoch: 6| Step: 1
Training loss: 0.07732775807380676
Validation loss: 1.5304680408970002

Epoch: 6| Step: 2
Training loss: 0.10951913148164749
Validation loss: 1.5537443609647854

Epoch: 6| Step: 3
Training loss: 0.14350563287734985
Validation loss: 1.5170962015787761

Epoch: 6| Step: 4
Training loss: 0.20312504470348358
Validation loss: 1.5242603081528858

Epoch: 6| Step: 5
Training loss: 0.09732875972986221
Validation loss: 1.5141208466663156

Epoch: 6| Step: 6
Training loss: 0.16430726647377014
Validation loss: 1.507245054808996

Epoch: 6| Step: 7
Training loss: 0.13099363446235657
Validation loss: 1.5159951973986883

Epoch: 6| Step: 8
Training loss: 0.13401196897029877
Validation loss: 1.513906491700039

Epoch: 6| Step: 9
Training loss: 0.0782339870929718
Validation loss: 1.5284537820405857

Epoch: 6| Step: 10
Training loss: 0.17287510633468628
Validation loss: 1.5609071363684952

Epoch: 6| Step: 11
Training loss: 0.1394709050655365
Validation loss: 1.5587143417327636

Epoch: 6| Step: 12
Training loss: 0.21328118443489075
Validation loss: 1.5797911331217775

Epoch: 6| Step: 13
Training loss: 0.16461071372032166
Validation loss: 1.5711682881078413

Epoch: 471| Step: 0
Training loss: 0.14106297492980957
Validation loss: 1.5864285038363548

Epoch: 6| Step: 1
Training loss: 0.15633118152618408
Validation loss: 1.5937658202263616

Epoch: 6| Step: 2
Training loss: 0.0736360251903534
Validation loss: 1.5750700773731354

Epoch: 6| Step: 3
Training loss: 0.07763922214508057
Validation loss: 1.5564148938784035

Epoch: 6| Step: 4
Training loss: 0.16008852422237396
Validation loss: 1.595269851787116

Epoch: 6| Step: 5
Training loss: 0.14532500505447388
Validation loss: 1.6209127928621025

Epoch: 6| Step: 6
Training loss: 0.07331977784633636
Validation loss: 1.5800687754026024

Epoch: 6| Step: 7
Training loss: 0.1786346733570099
Validation loss: 1.5869409409902429

Epoch: 6| Step: 8
Training loss: 0.1160966232419014
Validation loss: 1.5708884680142967

Epoch: 6| Step: 9
Training loss: 0.1468256115913391
Validation loss: 1.5653910944538731

Epoch: 6| Step: 10
Training loss: 0.06941483914852142
Validation loss: 1.582865321508018

Epoch: 6| Step: 11
Training loss: 0.14306333661079407
Validation loss: 1.5641363333630305

Epoch: 6| Step: 12
Training loss: 0.10142733156681061
Validation loss: 1.5452423614840354

Epoch: 6| Step: 13
Training loss: 0.24555166065692902
Validation loss: 1.5326661307324645

Epoch: 472| Step: 0
Training loss: 0.07264108955860138
Validation loss: 1.5313276808748963

Epoch: 6| Step: 1
Training loss: 0.09547843039035797
Validation loss: 1.5732573001615462

Epoch: 6| Step: 2
Training loss: 0.12339994311332703
Validation loss: 1.5399121135793707

Epoch: 6| Step: 3
Training loss: 0.08204001933336258
Validation loss: 1.558072805404663

Epoch: 6| Step: 4
Training loss: 0.07812006771564484
Validation loss: 1.5866301598087433

Epoch: 6| Step: 5
Training loss: 0.11981898546218872
Validation loss: 1.5983409266318045

Epoch: 6| Step: 6
Training loss: 0.14964808523654938
Validation loss: 1.5857451718340638

Epoch: 6| Step: 7
Training loss: 0.09803690016269684
Validation loss: 1.5982571481376566

Epoch: 6| Step: 8
Training loss: 0.15013441443443298
Validation loss: 1.6029244853604225

Epoch: 6| Step: 9
Training loss: 0.10744098573923111
Validation loss: 1.6006791476280458

Epoch: 6| Step: 10
Training loss: 0.1785372793674469
Validation loss: 1.590010896805794

Epoch: 6| Step: 11
Training loss: 0.0800299346446991
Validation loss: 1.5937674058380948

Epoch: 6| Step: 12
Training loss: 0.11061576008796692
Validation loss: 1.5747169089573685

Epoch: 6| Step: 13
Training loss: 0.1328727751970291
Validation loss: 1.5717717729588991

Epoch: 473| Step: 0
Training loss: 0.131070077419281
Validation loss: 1.5481223265329997

Epoch: 6| Step: 1
Training loss: 0.10957559943199158
Validation loss: 1.5457725422356718

Epoch: 6| Step: 2
Training loss: 0.14971238374710083
Validation loss: 1.5365547364757908

Epoch: 6| Step: 3
Training loss: 0.11808769404888153
Validation loss: 1.5467888591110066

Epoch: 6| Step: 4
Training loss: 0.0887569785118103
Validation loss: 1.5241903861363728

Epoch: 6| Step: 5
Training loss: 0.15173760056495667
Validation loss: 1.552238323996144

Epoch: 6| Step: 6
Training loss: 0.15762820839881897
Validation loss: 1.5458304036048152

Epoch: 6| Step: 7
Training loss: 0.15092939138412476
Validation loss: 1.5968302731872888

Epoch: 6| Step: 8
Training loss: 0.13471807539463043
Validation loss: 1.5777014276032806

Epoch: 6| Step: 9
Training loss: 0.1499747335910797
Validation loss: 1.5989730383760186

Epoch: 6| Step: 10
Training loss: 0.15888172388076782
Validation loss: 1.5712987979253132

Epoch: 6| Step: 11
Training loss: 0.10568005591630936
Validation loss: 1.5635967190547655

Epoch: 6| Step: 12
Training loss: 0.19841980934143066
Validation loss: 1.5710610907564881

Epoch: 6| Step: 13
Training loss: 0.10462934523820877
Validation loss: 1.551615309971635

Epoch: 474| Step: 0
Training loss: 0.12036488950252533
Validation loss: 1.5822215990353656

Epoch: 6| Step: 1
Training loss: 0.10265088081359863
Validation loss: 1.5651669322803456

Epoch: 6| Step: 2
Training loss: 0.09048472344875336
Validation loss: 1.5616960756240352

Epoch: 6| Step: 3
Training loss: 0.17052893340587616
Validation loss: 1.576714728468208

Epoch: 6| Step: 4
Training loss: 0.08751386404037476
Validation loss: 1.5491078425479192

Epoch: 6| Step: 5
Training loss: 0.15471407771110535
Validation loss: 1.5576741330085262

Epoch: 6| Step: 6
Training loss: 0.16883039474487305
Validation loss: 1.5216205286723312

Epoch: 6| Step: 7
Training loss: 0.17698179185390472
Validation loss: 1.5426949313891831

Epoch: 6| Step: 8
Training loss: 0.09931840747594833
Validation loss: 1.5464584442877

Epoch: 6| Step: 9
Training loss: 0.14679861068725586
Validation loss: 1.5386541787014212

Epoch: 6| Step: 10
Training loss: 0.14033514261245728
Validation loss: 1.5643485451257357

Epoch: 6| Step: 11
Training loss: 0.12430842965841293
Validation loss: 1.5440058708190918

Epoch: 6| Step: 12
Training loss: 0.12346123158931732
Validation loss: 1.5633791390285696

Epoch: 6| Step: 13
Training loss: 0.10974136739969254
Validation loss: 1.5635887627960534

Epoch: 475| Step: 0
Training loss: 0.17436102032661438
Validation loss: 1.5755044452605709

Epoch: 6| Step: 1
Training loss: 0.1113058477640152
Validation loss: 1.5835699689003728

Epoch: 6| Step: 2
Training loss: 0.1194383054971695
Validation loss: 1.5648907730656285

Epoch: 6| Step: 3
Training loss: 0.2084011435508728
Validation loss: 1.617197008543117

Epoch: 6| Step: 4
Training loss: 0.1314842402935028
Validation loss: 1.576507863178048

Epoch: 6| Step: 5
Training loss: 0.07584298402070999
Validation loss: 1.5981561022420083

Epoch: 6| Step: 6
Training loss: 0.0789601132273674
Validation loss: 1.5483460759603849

Epoch: 6| Step: 7
Training loss: 0.06765291094779968
Validation loss: 1.544931407897703

Epoch: 6| Step: 8
Training loss: 0.07537384331226349
Validation loss: 1.596083382124542

Epoch: 6| Step: 9
Training loss: 0.10616137832403183
Validation loss: 1.5691725554004792

Epoch: 6| Step: 10
Training loss: 0.17437809705734253
Validation loss: 1.5586113756702793

Epoch: 6| Step: 11
Training loss: 0.12670691311359406
Validation loss: 1.574154943548223

Epoch: 6| Step: 12
Training loss: 0.09110798686742783
Validation loss: 1.5667057806445706

Epoch: 6| Step: 13
Training loss: 0.04999028146266937
Validation loss: 1.545987085629535

Epoch: 476| Step: 0
Training loss: 0.14055176079273224
Validation loss: 1.5239325031157462

Epoch: 6| Step: 1
Training loss: 0.09824509918689728
Validation loss: 1.538942761318658

Epoch: 6| Step: 2
Training loss: 0.121769018471241
Validation loss: 1.5731104304713588

Epoch: 6| Step: 3
Training loss: 0.1520502269268036
Validation loss: 1.5371442443581038

Epoch: 6| Step: 4
Training loss: 0.10196755826473236
Validation loss: 1.5323579670280538

Epoch: 6| Step: 5
Training loss: 0.11906536668539047
Validation loss: 1.5499148420108262

Epoch: 6| Step: 6
Training loss: 0.16691255569458008
Validation loss: 1.5566825321925584

Epoch: 6| Step: 7
Training loss: 0.09905493259429932
Validation loss: 1.5700994409540647

Epoch: 6| Step: 8
Training loss: 0.12456806749105453
Validation loss: 1.5473141336953768

Epoch: 6| Step: 9
Training loss: 0.09279345721006393
Validation loss: 1.5487961153830252

Epoch: 6| Step: 10
Training loss: 0.13477879762649536
Validation loss: 1.5641842888247581

Epoch: 6| Step: 11
Training loss: 0.10617145895957947
Validation loss: 1.567210042348472

Epoch: 6| Step: 12
Training loss: 0.10104222595691681
Validation loss: 1.5568209335368166

Epoch: 6| Step: 13
Training loss: 0.14532653987407684
Validation loss: 1.553482969601949

Epoch: 477| Step: 0
Training loss: 0.08138154447078705
Validation loss: 1.5592649617502767

Epoch: 6| Step: 1
Training loss: 0.16238564252853394
Validation loss: 1.5384505871803529

Epoch: 6| Step: 2
Training loss: 0.11473492532968521
Validation loss: 1.5354557280899377

Epoch: 6| Step: 3
Training loss: 0.146418035030365
Validation loss: 1.5462803238181657

Epoch: 6| Step: 4
Training loss: 0.10170069336891174
Validation loss: 1.5301875106749996

Epoch: 6| Step: 5
Training loss: 0.09714137017726898
Validation loss: 1.5481742633286344

Epoch: 6| Step: 6
Training loss: 0.09504608064889908
Validation loss: 1.561198926741077

Epoch: 6| Step: 7
Training loss: 0.17992544174194336
Validation loss: 1.5498617567041868

Epoch: 6| Step: 8
Training loss: 0.09193339943885803
Validation loss: 1.5379208185339486

Epoch: 6| Step: 9
Training loss: 0.1113671287894249
Validation loss: 1.563177934256933

Epoch: 6| Step: 10
Training loss: 0.04723888635635376
Validation loss: 1.5484416087468464

Epoch: 6| Step: 11
Training loss: 0.12043271958827972
Validation loss: 1.514987567419647

Epoch: 6| Step: 12
Training loss: 0.13266701996326447
Validation loss: 1.5486521451703963

Epoch: 6| Step: 13
Training loss: 0.06730403006076813
Validation loss: 1.566681485022268

Epoch: 478| Step: 0
Training loss: 0.13572615385055542
Validation loss: 1.5592219573195263

Epoch: 6| Step: 1
Training loss: 0.10621900111436844
Validation loss: 1.5838097122407728

Epoch: 6| Step: 2
Training loss: 0.08420898020267487
Validation loss: 1.5574886029766453

Epoch: 6| Step: 3
Training loss: 0.15512385964393616
Validation loss: 1.5748979981227587

Epoch: 6| Step: 4
Training loss: 0.10288666188716888
Validation loss: 1.5992671148751372

Epoch: 6| Step: 5
Training loss: 0.0857701227068901
Validation loss: 1.5878601817674534

Epoch: 6| Step: 6
Training loss: 0.09919539093971252
Validation loss: 1.5695923707818473

Epoch: 6| Step: 7
Training loss: 0.10080388188362122
Validation loss: 1.5771246238421368

Epoch: 6| Step: 8
Training loss: 0.09962217509746552
Validation loss: 1.5804572143862325

Epoch: 6| Step: 9
Training loss: 0.10373611748218536
Validation loss: 1.5675349389353106

Epoch: 6| Step: 10
Training loss: 0.09604258835315704
Validation loss: 1.6042831661880657

Epoch: 6| Step: 11
Training loss: 0.11129767447710037
Validation loss: 1.603242886963711

Epoch: 6| Step: 12
Training loss: 0.1491115540266037
Validation loss: 1.605668229441489

Epoch: 6| Step: 13
Training loss: 0.08866015076637268
Validation loss: 1.584113154360043

Epoch: 479| Step: 0
Training loss: 0.10337618738412857
Validation loss: 1.5942209843666322

Epoch: 6| Step: 1
Training loss: 0.11059390008449554
Validation loss: 1.583886605437084

Epoch: 6| Step: 2
Training loss: 0.20055678486824036
Validation loss: 1.5932678676420642

Epoch: 6| Step: 3
Training loss: 0.07548171281814575
Validation loss: 1.5796254296456613

Epoch: 6| Step: 4
Training loss: 0.15406611561775208
Validation loss: 1.5687446517329062

Epoch: 6| Step: 5
Training loss: 0.09222055226564407
Validation loss: 1.5289908352718558

Epoch: 6| Step: 6
Training loss: 0.10022765398025513
Validation loss: 1.5231651721462127

Epoch: 6| Step: 7
Training loss: 0.06624314934015274
Validation loss: 1.5401536239090787

Epoch: 6| Step: 8
Training loss: 0.0786886215209961
Validation loss: 1.5376982881176857

Epoch: 6| Step: 9
Training loss: 0.17257365584373474
Validation loss: 1.5573667710827244

Epoch: 6| Step: 10
Training loss: 0.16437815129756927
Validation loss: 1.514412268515556

Epoch: 6| Step: 11
Training loss: 0.14899592101573944
Validation loss: 1.5069040470225836

Epoch: 6| Step: 12
Training loss: 0.1183985024690628
Validation loss: 1.512166154000067

Epoch: 6| Step: 13
Training loss: 0.07936014235019684
Validation loss: 1.5189200498724496

Epoch: 480| Step: 0
Training loss: 0.11794413626194
Validation loss: 1.5248155722054102

Epoch: 6| Step: 1
Training loss: 0.08234246075153351
Validation loss: 1.540802078862344

Epoch: 6| Step: 2
Training loss: 0.07406727969646454
Validation loss: 1.5483496317299463

Epoch: 6| Step: 3
Training loss: 0.1048000231385231
Validation loss: 1.5635226638086381

Epoch: 6| Step: 4
Training loss: 0.1085752323269844
Validation loss: 1.5253552954684022

Epoch: 6| Step: 5
Training loss: 0.1406431794166565
Validation loss: 1.5405490424043389

Epoch: 6| Step: 6
Training loss: 0.11809760332107544
Validation loss: 1.589675981511352

Epoch: 6| Step: 7
Training loss: 0.14091283082962036
Validation loss: 1.5989456753576956

Epoch: 6| Step: 8
Training loss: 0.1385963410139084
Validation loss: 1.610213045151003

Epoch: 6| Step: 9
Training loss: 0.10374243557453156
Validation loss: 1.6084733355429865

Epoch: 6| Step: 10
Training loss: 0.10423391312360764
Validation loss: 1.596583576612575

Epoch: 6| Step: 11
Training loss: 0.13551583886146545
Validation loss: 1.597679534266072

Epoch: 6| Step: 12
Training loss: 0.09390957653522491
Validation loss: 1.5620844171893211

Epoch: 6| Step: 13
Training loss: 0.13153666257858276
Validation loss: 1.5727469780111825

Epoch: 481| Step: 0
Training loss: 0.11537568271160126
Validation loss: 1.576634495489059

Epoch: 6| Step: 1
Training loss: 0.11964395642280579
Validation loss: 1.5491199852317892

Epoch: 6| Step: 2
Training loss: 0.2072315663099289
Validation loss: 1.5306607279726254

Epoch: 6| Step: 3
Training loss: 0.09417034685611725
Validation loss: 1.517871097851825

Epoch: 6| Step: 4
Training loss: 0.2258967161178589
Validation loss: 1.5094747427971131

Epoch: 6| Step: 5
Training loss: 0.12108536064624786
Validation loss: 1.5276376598624772

Epoch: 6| Step: 6
Training loss: 0.13255169987678528
Validation loss: 1.5392563189229658

Epoch: 6| Step: 7
Training loss: 0.155227929353714
Validation loss: 1.5244968834743704

Epoch: 6| Step: 8
Training loss: 0.10725422203540802
Validation loss: 1.5385023342665805

Epoch: 6| Step: 9
Training loss: 0.08296163380146027
Validation loss: 1.5325145131798201

Epoch: 6| Step: 10
Training loss: 0.12903523445129395
Validation loss: 1.5559264806009108

Epoch: 6| Step: 11
Training loss: 0.14212562143802643
Validation loss: 1.569437196177821

Epoch: 6| Step: 12
Training loss: 0.1379469335079193
Validation loss: 1.5674596678826116

Epoch: 6| Step: 13
Training loss: 0.08228487521409988
Validation loss: 1.5563419877841909

Epoch: 482| Step: 0
Training loss: 0.12896330654621124
Validation loss: 1.580077446917052

Epoch: 6| Step: 1
Training loss: 0.1711781769990921
Validation loss: 1.5728410713134273

Epoch: 6| Step: 2
Training loss: 0.10549641400575638
Validation loss: 1.6093972588098178

Epoch: 6| Step: 3
Training loss: 0.13938234746456146
Validation loss: 1.5741689179533271

Epoch: 6| Step: 4
Training loss: 0.1533622443675995
Validation loss: 1.5723854252087173

Epoch: 6| Step: 5
Training loss: 0.09117379039525986
Validation loss: 1.5750862090818343

Epoch: 6| Step: 6
Training loss: 0.08971881866455078
Validation loss: 1.5997079777461227

Epoch: 6| Step: 7
Training loss: 0.10174314677715302
Validation loss: 1.5780179026306316

Epoch: 6| Step: 8
Training loss: 0.1376963108778
Validation loss: 1.6002629982527865

Epoch: 6| Step: 9
Training loss: 0.16819889843463898
Validation loss: 1.5665078534874866

Epoch: 6| Step: 10
Training loss: 0.13176143169403076
Validation loss: 1.600309145066046

Epoch: 6| Step: 11
Training loss: 0.13379135727882385
Validation loss: 1.5942809812484249

Epoch: 6| Step: 12
Training loss: 0.05043689161539078
Validation loss: 1.6197534479120725

Epoch: 6| Step: 13
Training loss: 0.11133521050214767
Validation loss: 1.5850769114750687

Epoch: 483| Step: 0
Training loss: 0.15608695149421692
Validation loss: 1.6224289542885237

Epoch: 6| Step: 1
Training loss: 0.0816158652305603
Validation loss: 1.6066134091346496

Epoch: 6| Step: 2
Training loss: 0.09517782926559448
Validation loss: 1.5826817379202893

Epoch: 6| Step: 3
Training loss: 0.10707858949899673
Validation loss: 1.5759302082882132

Epoch: 6| Step: 4
Training loss: 0.09768655896186829
Validation loss: 1.6025863180878341

Epoch: 6| Step: 5
Training loss: 0.13213452696800232
Validation loss: 1.590201134322792

Epoch: 6| Step: 6
Training loss: 0.12906648218631744
Validation loss: 1.6223691765980055

Epoch: 6| Step: 7
Training loss: 0.18757596611976624
Validation loss: 1.6400646278935094

Epoch: 6| Step: 8
Training loss: 0.10605640709400177
Validation loss: 1.6311497675475253

Epoch: 6| Step: 9
Training loss: 0.07843264937400818
Validation loss: 1.649856767346782

Epoch: 6| Step: 10
Training loss: 0.11790745705366135
Validation loss: 1.5907748860697593

Epoch: 6| Step: 11
Training loss: 0.1391315758228302
Validation loss: 1.6202604065659225

Epoch: 6| Step: 12
Training loss: 0.09278595447540283
Validation loss: 1.574314005913273

Epoch: 6| Step: 13
Training loss: 0.09508543461561203
Validation loss: 1.6291589877938712

Epoch: 484| Step: 0
Training loss: 0.13539688289165497
Validation loss: 1.579399311414329

Epoch: 6| Step: 1
Training loss: 0.2292613685131073
Validation loss: 1.6000995994896017

Epoch: 6| Step: 2
Training loss: 0.14514660835266113
Validation loss: 1.605069584743951

Epoch: 6| Step: 3
Training loss: 0.09766341000795364
Validation loss: 1.5785071721640966

Epoch: 6| Step: 4
Training loss: 0.10609561204910278
Validation loss: 1.5622665407837077

Epoch: 6| Step: 5
Training loss: 0.12425685673952103
Validation loss: 1.5209305542771534

Epoch: 6| Step: 6
Training loss: 0.09414061158895493
Validation loss: 1.524170344875705

Epoch: 6| Step: 7
Training loss: 0.04193821921944618
Validation loss: 1.5113732020060222

Epoch: 6| Step: 8
Training loss: 0.08478203415870667
Validation loss: 1.5023360111380135

Epoch: 6| Step: 9
Training loss: 0.21320971846580505
Validation loss: 1.5395809142820296

Epoch: 6| Step: 10
Training loss: 0.13384859263896942
Validation loss: 1.5468592977011075

Epoch: 6| Step: 11
Training loss: 0.1690363585948944
Validation loss: 1.541214313558353

Epoch: 6| Step: 12
Training loss: 0.11907602846622467
Validation loss: 1.5909276123969787

Epoch: 6| Step: 13
Training loss: 0.12472948431968689
Validation loss: 1.5895898643360342

Epoch: 485| Step: 0
Training loss: 0.11664661765098572
Validation loss: 1.5955543748794063

Epoch: 6| Step: 1
Training loss: 0.22590303421020508
Validation loss: 1.6353100140889485

Epoch: 6| Step: 2
Training loss: 0.17916221916675568
Validation loss: 1.6556657988538024

Epoch: 6| Step: 3
Training loss: 0.1401645541191101
Validation loss: 1.7026982768889396

Epoch: 6| Step: 4
Training loss: 0.2155005931854248
Validation loss: 1.6501833200454712

Epoch: 6| Step: 5
Training loss: 0.24741551280021667
Validation loss: 1.6640733852181384

Epoch: 6| Step: 6
Training loss: 0.10690614581108093
Validation loss: 1.5809181646634174

Epoch: 6| Step: 7
Training loss: 0.0876895934343338
Validation loss: 1.5515174993904688

Epoch: 6| Step: 8
Training loss: 0.0970858633518219
Validation loss: 1.5327495073759427

Epoch: 6| Step: 9
Training loss: 0.13770580291748047
Validation loss: 1.545978170569225

Epoch: 6| Step: 10
Training loss: 0.1640920341014862
Validation loss: 1.5342822690163889

Epoch: 6| Step: 11
Training loss: 0.1667560189962387
Validation loss: 1.537266024979212

Epoch: 6| Step: 12
Training loss: 0.23219034075737
Validation loss: 1.5332803194240858

Epoch: 6| Step: 13
Training loss: 0.16236577928066254
Validation loss: 1.5418557774636052

Epoch: 486| Step: 0
Training loss: 0.14788216352462769
Validation loss: 1.519072986418201

Epoch: 6| Step: 1
Training loss: 0.13707086443901062
Validation loss: 1.550403287333827

Epoch: 6| Step: 2
Training loss: 0.12792912125587463
Validation loss: 1.5686142008791688

Epoch: 6| Step: 3
Training loss: 0.10674695670604706
Validation loss: 1.5611884683691046

Epoch: 6| Step: 4
Training loss: 0.12393555045127869
Validation loss: 1.5867658699712446

Epoch: 6| Step: 5
Training loss: 0.1248714029788971
Validation loss: 1.5911886794592744

Epoch: 6| Step: 6
Training loss: 0.2228856384754181
Validation loss: 1.6043332443442395

Epoch: 6| Step: 7
Training loss: 0.1432153582572937
Validation loss: 1.5665304532615087

Epoch: 6| Step: 8
Training loss: 0.10147012770175934
Validation loss: 1.5982161311693088

Epoch: 6| Step: 9
Training loss: 0.13586577773094177
Validation loss: 1.6109149353478545

Epoch: 6| Step: 10
Training loss: 0.1966625154018402
Validation loss: 1.5838876757570493

Epoch: 6| Step: 11
Training loss: 0.11725357919931412
Validation loss: 1.593811378684095

Epoch: 6| Step: 12
Training loss: 0.15349671244621277
Validation loss: 1.555712999836091

Epoch: 6| Step: 13
Training loss: 0.16214916110038757
Validation loss: 1.5363462150737803

Epoch: 487| Step: 0
Training loss: 0.12009397149085999
Validation loss: 1.5397246832488685

Epoch: 6| Step: 1
Training loss: 0.15358182787895203
Validation loss: 1.556070485422688

Epoch: 6| Step: 2
Training loss: 0.15400588512420654
Validation loss: 1.5444679683254612

Epoch: 6| Step: 3
Training loss: 0.14336714148521423
Validation loss: 1.5035515177634455

Epoch: 6| Step: 4
Training loss: 0.09972298890352249
Validation loss: 1.5530130491461804

Epoch: 6| Step: 5
Training loss: 0.07810453325510025
Validation loss: 1.5429893616707093

Epoch: 6| Step: 6
Training loss: 0.13813601434230804
Validation loss: 1.5590740865276707

Epoch: 6| Step: 7
Training loss: 0.10320376604795456
Validation loss: 1.5517636319642425

Epoch: 6| Step: 8
Training loss: 0.19639790058135986
Validation loss: 1.5995792470952517

Epoch: 6| Step: 9
Training loss: 0.11376771330833435
Validation loss: 1.5717657061033352

Epoch: 6| Step: 10
Training loss: 0.06723274290561676
Validation loss: 1.6103891928990681

Epoch: 6| Step: 11
Training loss: 0.0593167282640934
Validation loss: 1.604745517494858

Epoch: 6| Step: 12
Training loss: 0.14561113715171814
Validation loss: 1.60714965738276

Epoch: 6| Step: 13
Training loss: 0.08124974370002747
Validation loss: 1.6561650704312068

Epoch: 488| Step: 0
Training loss: 0.08710427582263947
Validation loss: 1.6194336760428645

Epoch: 6| Step: 1
Training loss: 0.18584562838077545
Validation loss: 1.61159251646329

Epoch: 6| Step: 2
Training loss: 0.09188219904899597
Validation loss: 1.615063021259923

Epoch: 6| Step: 3
Training loss: 0.125820130109787
Validation loss: 1.622707066997405

Epoch: 6| Step: 4
Training loss: 0.12646611034870148
Validation loss: 1.6156269747723815

Epoch: 6| Step: 5
Training loss: 0.1166786178946495
Validation loss: 1.591374248586675

Epoch: 6| Step: 6
Training loss: 0.09170806407928467
Validation loss: 1.606146663747808

Epoch: 6| Step: 7
Training loss: 0.11687443405389786
Validation loss: 1.6028252570859847

Epoch: 6| Step: 8
Training loss: 0.1186920702457428
Validation loss: 1.566717614409744

Epoch: 6| Step: 9
Training loss: 0.10871169716119766
Validation loss: 1.5798367659250896

Epoch: 6| Step: 10
Training loss: 0.1291808933019638
Validation loss: 1.5635024783431843

Epoch: 6| Step: 11
Training loss: 0.08036155253648758
Validation loss: 1.5515272104611961

Epoch: 6| Step: 12
Training loss: 0.08633163571357727
Validation loss: 1.5535972605469406

Epoch: 6| Step: 13
Training loss: 0.10181070864200592
Validation loss: 1.5786756533448414

Epoch: 489| Step: 0
Training loss: 0.09787461906671524
Validation loss: 1.5381846415099276

Epoch: 6| Step: 1
Training loss: 0.18367961049079895
Validation loss: 1.5721773062982867

Epoch: 6| Step: 2
Training loss: 0.08271943032741547
Validation loss: 1.5391748938509213

Epoch: 6| Step: 3
Training loss: 0.10449879616498947
Validation loss: 1.5558054267719228

Epoch: 6| Step: 4
Training loss: 0.11865758150815964
Validation loss: 1.5647231468590357

Epoch: 6| Step: 5
Training loss: 0.09646096080541611
Validation loss: 1.5851178117977676

Epoch: 6| Step: 6
Training loss: 0.08665542304515839
Validation loss: 1.5891001852609778

Epoch: 6| Step: 7
Training loss: 0.08003970980644226
Validation loss: 1.5756457159596104

Epoch: 6| Step: 8
Training loss: 0.1719677746295929
Validation loss: 1.606671997295913

Epoch: 6| Step: 9
Training loss: 0.08939329534769058
Validation loss: 1.5837873566535212

Epoch: 6| Step: 10
Training loss: 0.1410495638847351
Validation loss: 1.5731558402379353

Epoch: 6| Step: 11
Training loss: 0.07797077298164368
Validation loss: 1.5756999805409422

Epoch: 6| Step: 12
Training loss: 0.09581346809864044
Validation loss: 1.5402986477780085

Epoch: 6| Step: 13
Training loss: 0.10325472056865692
Validation loss: 1.5428108675505525

Epoch: 490| Step: 0
Training loss: 0.12310807406902313
Validation loss: 1.5631678553037747

Epoch: 6| Step: 1
Training loss: 0.14754386246204376
Validation loss: 1.546295541588978

Epoch: 6| Step: 2
Training loss: 0.1163623109459877
Validation loss: 1.5349949431675736

Epoch: 6| Step: 3
Training loss: 0.1411631554365158
Validation loss: 1.5711440245310466

Epoch: 6| Step: 4
Training loss: 0.1442466676235199
Validation loss: 1.5702204806830293

Epoch: 6| Step: 5
Training loss: 0.1001872569322586
Validation loss: 1.5262734313164987

Epoch: 6| Step: 6
Training loss: 0.061771102249622345
Validation loss: 1.57262413091557

Epoch: 6| Step: 7
Training loss: 0.08040206134319305
Validation loss: 1.5378909213568575

Epoch: 6| Step: 8
Training loss: 0.10268525034189224
Validation loss: 1.5562408854884486

Epoch: 6| Step: 9
Training loss: 0.10650073736906052
Validation loss: 1.547719681134788

Epoch: 6| Step: 10
Training loss: 0.10374060273170471
Validation loss: 1.5474383959206202

Epoch: 6| Step: 11
Training loss: 0.11858620494604111
Validation loss: 1.5715634322935534

Epoch: 6| Step: 12
Training loss: 0.07260903716087341
Validation loss: 1.5467007506278254

Epoch: 6| Step: 13
Training loss: 0.07329601794481277
Validation loss: 1.5818000980602798

Epoch: 491| Step: 0
Training loss: 0.08585390448570251
Validation loss: 1.581623182501844

Epoch: 6| Step: 1
Training loss: 0.07705989480018616
Validation loss: 1.5883387891195153

Epoch: 6| Step: 2
Training loss: 0.14159372448921204
Validation loss: 1.5974769925558439

Epoch: 6| Step: 3
Training loss: 0.07083943486213684
Validation loss: 1.5939759567219725

Epoch: 6| Step: 4
Training loss: 0.1300138235092163
Validation loss: 1.5835901203975882

Epoch: 6| Step: 5
Training loss: 0.07988885045051575
Validation loss: 1.5952296795383576

Epoch: 6| Step: 6
Training loss: 0.09870950132608414
Validation loss: 1.5727935426978654

Epoch: 6| Step: 7
Training loss: 0.12778067588806152
Validation loss: 1.5680494180289648

Epoch: 6| Step: 8
Training loss: 0.1504228711128235
Validation loss: 1.5607828632477792

Epoch: 6| Step: 9
Training loss: 0.2006324827671051
Validation loss: 1.5785946166643532

Epoch: 6| Step: 10
Training loss: 0.06366023421287537
Validation loss: 1.5556754078916324

Epoch: 6| Step: 11
Training loss: 0.11487527191638947
Validation loss: 1.5508261419111682

Epoch: 6| Step: 12
Training loss: 0.13774842023849487
Validation loss: 1.5603482928327335

Epoch: 6| Step: 13
Training loss: 0.13150180876255035
Validation loss: 1.5651458142906107

Epoch: 492| Step: 0
Training loss: 0.10193654894828796
Validation loss: 1.5569677891269806

Epoch: 6| Step: 1
Training loss: 0.138205885887146
Validation loss: 1.5407470169887747

Epoch: 6| Step: 2
Training loss: 0.12959173321723938
Validation loss: 1.5540311503153976

Epoch: 6| Step: 3
Training loss: 0.13317832350730896
Validation loss: 1.5304291466230988

Epoch: 6| Step: 4
Training loss: 0.12432803213596344
Validation loss: 1.5305405861587935

Epoch: 6| Step: 5
Training loss: 0.1606467068195343
Validation loss: 1.5350631026811496

Epoch: 6| Step: 6
Training loss: 0.09755375981330872
Validation loss: 1.5176408797182062

Epoch: 6| Step: 7
Training loss: 0.13618850708007812
Validation loss: 1.5124452517878624

Epoch: 6| Step: 8
Training loss: 0.06219513714313507
Validation loss: 1.5375131343000679

Epoch: 6| Step: 9
Training loss: 0.13575327396392822
Validation loss: 1.5454752996403684

Epoch: 6| Step: 10
Training loss: 0.16397812962532043
Validation loss: 1.5460255376754268

Epoch: 6| Step: 11
Training loss: 0.13309094309806824
Validation loss: 1.5415224843127753

Epoch: 6| Step: 12
Training loss: 0.10434797406196594
Validation loss: 1.5598357390331965

Epoch: 6| Step: 13
Training loss: 0.20670540630817413
Validation loss: 1.5586321507730792

Epoch: 493| Step: 0
Training loss: 0.12063295394182205
Validation loss: 1.5647133178608392

Epoch: 6| Step: 1
Training loss: 0.11313679814338684
Validation loss: 1.56265458496668

Epoch: 6| Step: 2
Training loss: 0.11410646140575409
Validation loss: 1.5543206609705442

Epoch: 6| Step: 3
Training loss: 0.15083083510398865
Validation loss: 1.545117038552479

Epoch: 6| Step: 4
Training loss: 0.11304602771997452
Validation loss: 1.585785073618735

Epoch: 6| Step: 5
Training loss: 0.12054764479398727
Validation loss: 1.53602768528846

Epoch: 6| Step: 6
Training loss: 0.11141673475503922
Validation loss: 1.5459053452296923

Epoch: 6| Step: 7
Training loss: 0.18758165836334229
Validation loss: 1.577913030501335

Epoch: 6| Step: 8
Training loss: 0.0844849944114685
Validation loss: 1.5496119760697888

Epoch: 6| Step: 9
Training loss: 0.10152867436408997
Validation loss: 1.531657632961068

Epoch: 6| Step: 10
Training loss: 0.06618453562259674
Validation loss: 1.5772867715486916

Epoch: 6| Step: 11
Training loss: 0.12761744856834412
Validation loss: 1.5315012367822791

Epoch: 6| Step: 12
Training loss: 0.12214892357587814
Validation loss: 1.5473957254040627

Epoch: 6| Step: 13
Training loss: 0.09743627160787582
Validation loss: 1.5607479592805267

Epoch: 494| Step: 0
Training loss: 0.0790194720029831
Validation loss: 1.5833141931923487

Epoch: 6| Step: 1
Training loss: 0.09325569868087769
Validation loss: 1.571994391820764

Epoch: 6| Step: 2
Training loss: 0.17997312545776367
Validation loss: 1.567409191080319

Epoch: 6| Step: 3
Training loss: 0.10397614538669586
Validation loss: 1.572661804896529

Epoch: 6| Step: 4
Training loss: 0.14246726036071777
Validation loss: 1.584938701762948

Epoch: 6| Step: 5
Training loss: 0.11033391952514648
Validation loss: 1.5987382153029084

Epoch: 6| Step: 6
Training loss: 0.14780232310295105
Validation loss: 1.5583295873416367

Epoch: 6| Step: 7
Training loss: 0.1776706576347351
Validation loss: 1.5236247713847826

Epoch: 6| Step: 8
Training loss: 0.07324020564556122
Validation loss: 1.5315165647896387

Epoch: 6| Step: 9
Training loss: 0.11384283006191254
Validation loss: 1.5007881836224628

Epoch: 6| Step: 10
Training loss: 0.16204601526260376
Validation loss: 1.5069309639674362

Epoch: 6| Step: 11
Training loss: 0.07982871681451797
Validation loss: 1.513748372754743

Epoch: 6| Step: 12
Training loss: 0.08946910500526428
Validation loss: 1.5104130359106167

Epoch: 6| Step: 13
Training loss: 0.12632344663143158
Validation loss: 1.4740310304908342

Epoch: 495| Step: 0
Training loss: 0.07794447988271713
Validation loss: 1.5087810203593264

Epoch: 6| Step: 1
Training loss: 0.11944107711315155
Validation loss: 1.5247696695789215

Epoch: 6| Step: 2
Training loss: 0.09434019029140472
Validation loss: 1.5096674350000197

Epoch: 6| Step: 3
Training loss: 0.07588742673397064
Validation loss: 1.5379459793849657

Epoch: 6| Step: 4
Training loss: 0.11516495794057846
Validation loss: 1.538719795083487

Epoch: 6| Step: 5
Training loss: 0.06683375686407089
Validation loss: 1.5880812432176323

Epoch: 6| Step: 6
Training loss: 0.1446402370929718
Validation loss: 1.5649905256045762

Epoch: 6| Step: 7
Training loss: 0.15702953934669495
Validation loss: 1.5864502614544285

Epoch: 6| Step: 8
Training loss: 0.1985090970993042
Validation loss: 1.5888439583522018

Epoch: 6| Step: 9
Training loss: 0.1928059458732605
Validation loss: 1.5991199503662765

Epoch: 6| Step: 10
Training loss: 0.07573800534009933
Validation loss: 1.582003047389369

Epoch: 6| Step: 11
Training loss: 0.12303350120782852
Validation loss: 1.5907494188636861

Epoch: 6| Step: 12
Training loss: 0.10705593228340149
Validation loss: 1.5874900984507736

Epoch: 6| Step: 13
Training loss: 0.07230623811483383
Validation loss: 1.549575618518296

Epoch: 496| Step: 0
Training loss: 0.11045312136411667
Validation loss: 1.5758634421133226

Epoch: 6| Step: 1
Training loss: 0.09351939707994461
Validation loss: 1.5978939366597

Epoch: 6| Step: 2
Training loss: 0.06801499426364899
Validation loss: 1.5484131882267613

Epoch: 6| Step: 3
Training loss: 0.055652812123298645
Validation loss: 1.5737580137868081

Epoch: 6| Step: 4
Training loss: 0.10541980713605881
Validation loss: 1.5813793046500093

Epoch: 6| Step: 5
Training loss: 0.16407787799835205
Validation loss: 1.5459295267699866

Epoch: 6| Step: 6
Training loss: 0.0859910249710083
Validation loss: 1.57308546445703

Epoch: 6| Step: 7
Training loss: 0.06705846637487411
Validation loss: 1.5410981152647285

Epoch: 6| Step: 8
Training loss: 0.10685302317142487
Validation loss: 1.5260023045283493

Epoch: 6| Step: 9
Training loss: 0.11708512902259827
Validation loss: 1.5272030497110018

Epoch: 6| Step: 10
Training loss: 0.08951591700315475
Validation loss: 1.527731414764158

Epoch: 6| Step: 11
Training loss: 0.08629605174064636
Validation loss: 1.5186579253083916

Epoch: 6| Step: 12
Training loss: 0.16494232416152954
Validation loss: 1.4868950331082909

Epoch: 6| Step: 13
Training loss: 0.11975906789302826
Validation loss: 1.4800264976357902

Epoch: 497| Step: 0
Training loss: 0.07440350949764252
Validation loss: 1.5213314025632796

Epoch: 6| Step: 1
Training loss: 0.09298259019851685
Validation loss: 1.5032180842532907

Epoch: 6| Step: 2
Training loss: 0.10077502578496933
Validation loss: 1.5289252291443527

Epoch: 6| Step: 3
Training loss: 0.1405215859413147
Validation loss: 1.5242881159628592

Epoch: 6| Step: 4
Training loss: 0.18482457101345062
Validation loss: 1.5682101108694588

Epoch: 6| Step: 5
Training loss: 0.15357577800750732
Validation loss: 1.57118324951459

Epoch: 6| Step: 6
Training loss: 0.08572740107774734
Validation loss: 1.5432732617983254

Epoch: 6| Step: 7
Training loss: 0.06401588022708893
Validation loss: 1.5396523244919316

Epoch: 6| Step: 8
Training loss: 0.07948353886604309
Validation loss: 1.5420128119889127

Epoch: 6| Step: 9
Training loss: 0.1087159812450409
Validation loss: 1.54526698717507

Epoch: 6| Step: 10
Training loss: 0.07465000450611115
Validation loss: 1.5529247688990768

Epoch: 6| Step: 11
Training loss: 0.11686823517084122
Validation loss: 1.5451836515498418

Epoch: 6| Step: 12
Training loss: 0.09356656670570374
Validation loss: 1.5295492590114634

Epoch: 6| Step: 13
Training loss: 0.18574555218219757
Validation loss: 1.5810176967292704

Epoch: 498| Step: 0
Training loss: 0.1714450716972351
Validation loss: 1.5519699806808143

Epoch: 6| Step: 1
Training loss: 0.11147581040859222
Validation loss: 1.526441297223491

Epoch: 6| Step: 2
Training loss: 0.13465020060539246
Validation loss: 1.5200732625940794

Epoch: 6| Step: 3
Training loss: 0.09116721153259277
Validation loss: 1.5477065450401717

Epoch: 6| Step: 4
Training loss: 0.13382932543754578
Validation loss: 1.5429715597501366

Epoch: 6| Step: 5
Training loss: 0.0921354815363884
Validation loss: 1.5530884470990909

Epoch: 6| Step: 6
Training loss: 0.1095363199710846
Validation loss: 1.5209622588208926

Epoch: 6| Step: 7
Training loss: 0.11286735534667969
Validation loss: 1.5502174926060501

Epoch: 6| Step: 8
Training loss: 0.1339406967163086
Validation loss: 1.5222019251956735

Epoch: 6| Step: 9
Training loss: 0.10311658680438995
Validation loss: 1.5792977117723035

Epoch: 6| Step: 10
Training loss: 0.07780162990093231
Validation loss: 1.5556281035946262

Epoch: 6| Step: 11
Training loss: 0.08185893297195435
Validation loss: 1.5365482209831156

Epoch: 6| Step: 12
Training loss: 0.08413203060626984
Validation loss: 1.5473220361176359

Epoch: 6| Step: 13
Training loss: 0.04875019192695618
Validation loss: 1.5508261188384025

Epoch: 499| Step: 0
Training loss: 0.12879446148872375
Validation loss: 1.5648461759731334

Epoch: 6| Step: 1
Training loss: 0.09856793284416199
Validation loss: 1.5747227796944239

Epoch: 6| Step: 2
Training loss: 0.13619360327720642
Validation loss: 1.5174306874634118

Epoch: 6| Step: 3
Training loss: 0.10117177665233612
Validation loss: 1.5651630099101732

Epoch: 6| Step: 4
Training loss: 0.07465122640132904
Validation loss: 1.589911707626876

Epoch: 6| Step: 5
Training loss: 0.08689749240875244
Validation loss: 1.5566698376850416

Epoch: 6| Step: 6
Training loss: 0.16866055130958557
Validation loss: 1.5707948489855694

Epoch: 6| Step: 7
Training loss: 0.08103563636541367
Validation loss: 1.5592486730185888

Epoch: 6| Step: 8
Training loss: 0.09585954993963242
Validation loss: 1.554633702001264

Epoch: 6| Step: 9
Training loss: 0.09339316189289093
Validation loss: 1.513466695303558

Epoch: 6| Step: 10
Training loss: 0.0960702896118164
Validation loss: 1.5073355808052966

Epoch: 6| Step: 11
Training loss: 0.09836746007204056
Validation loss: 1.5067306192972327

Epoch: 6| Step: 12
Training loss: 0.10866227746009827
Validation loss: 1.5092321083109865

Epoch: 6| Step: 13
Training loss: 0.1757695972919464
Validation loss: 1.549385856556636

Epoch: 500| Step: 0
Training loss: 0.0897630900144577
Validation loss: 1.5123001785688504

Epoch: 6| Step: 1
Training loss: 0.13231533765792847
Validation loss: 1.545477782526324

Epoch: 6| Step: 2
Training loss: 0.05603701248764992
Validation loss: 1.5299504136526456

Epoch: 6| Step: 3
Training loss: 0.09035471081733704
Validation loss: 1.551028165765988

Epoch: 6| Step: 4
Training loss: 0.1111033707857132
Validation loss: 1.5393751872483121

Epoch: 6| Step: 5
Training loss: 0.0909324586391449
Validation loss: 1.5362929003213042

Epoch: 6| Step: 6
Training loss: 0.10511735081672668
Validation loss: 1.532286613218246

Epoch: 6| Step: 7
Training loss: 0.15270376205444336
Validation loss: 1.551315954615993

Epoch: 6| Step: 8
Training loss: 0.09303849935531616
Validation loss: 1.5102981745555837

Epoch: 6| Step: 9
Training loss: 0.08717978000640869
Validation loss: 1.5326319971392233

Epoch: 6| Step: 10
Training loss: 0.1755615770816803
Validation loss: 1.5480198462804158

Epoch: 6| Step: 11
Training loss: 0.08358096331357956
Validation loss: 1.5531259223979006

Epoch: 6| Step: 12
Training loss: 0.07910314202308655
Validation loss: 1.5668934083754016

Epoch: 6| Step: 13
Training loss: 0.11713731288909912
Validation loss: 1.5694799115580897

Testing loss: 2.0877385510338677
