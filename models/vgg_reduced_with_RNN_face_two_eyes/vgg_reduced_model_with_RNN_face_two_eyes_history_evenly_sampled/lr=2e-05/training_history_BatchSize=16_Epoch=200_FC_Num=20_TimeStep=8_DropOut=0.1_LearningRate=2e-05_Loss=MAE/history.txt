Epoch: 1| Step: 0
Training loss: 5.726787567138672
Validation loss: 5.220736698437762

Epoch: 6| Step: 1
Training loss: 3.9042813777923584
Validation loss: 5.201438847408499

Epoch: 6| Step: 2
Training loss: 5.112959861755371
Validation loss: 5.1799900403586765

Epoch: 6| Step: 3
Training loss: 5.167452812194824
Validation loss: 5.157711731490268

Epoch: 6| Step: 4
Training loss: 5.384744167327881
Validation loss: 5.13245306732834

Epoch: 6| Step: 5
Training loss: 5.488133430480957
Validation loss: 5.104375849487961

Epoch: 6| Step: 6
Training loss: 4.77874755859375
Validation loss: 5.072167493963755

Epoch: 6| Step: 7
Training loss: 5.853032112121582
Validation loss: 5.036536601281935

Epoch: 6| Step: 8
Training loss: 4.04606819152832
Validation loss: 4.995919348091207

Epoch: 6| Step: 9
Training loss: 4.78629207611084
Validation loss: 4.953673665241529

Epoch: 6| Step: 10
Training loss: 4.151238441467285
Validation loss: 4.906269545196205

Epoch: 6| Step: 11
Training loss: 5.045350074768066
Validation loss: 4.853935800572877

Epoch: 6| Step: 12
Training loss: 3.668466329574585
Validation loss: 4.7995880137207685

Epoch: 6| Step: 13
Training loss: 4.184545516967773
Validation loss: 4.741257308631815

Epoch: 2| Step: 0
Training loss: 5.0603179931640625
Validation loss: 4.6800708514387885

Epoch: 6| Step: 1
Training loss: 3.2904272079467773
Validation loss: 4.616964278682586

Epoch: 6| Step: 2
Training loss: 4.349659442901611
Validation loss: 4.5503409754845405

Epoch: 6| Step: 3
Training loss: 5.755352973937988
Validation loss: 4.484334112495504

Epoch: 6| Step: 4
Training loss: 3.3637592792510986
Validation loss: 4.420104411340529

Epoch: 6| Step: 5
Training loss: 5.126317977905273
Validation loss: 4.355700354422292

Epoch: 6| Step: 6
Training loss: 3.7496654987335205
Validation loss: 4.292459595587946

Epoch: 6| Step: 7
Training loss: 3.7818171977996826
Validation loss: 4.231100020870086

Epoch: 6| Step: 8
Training loss: 5.134158611297607
Validation loss: 4.172472164195071

Epoch: 6| Step: 9
Training loss: 3.232839584350586
Validation loss: 4.105121981713079

Epoch: 6| Step: 10
Training loss: 3.7778875827789307
Validation loss: 4.036481154862271

Epoch: 6| Step: 11
Training loss: 2.8890719413757324
Validation loss: 3.977285703023275

Epoch: 6| Step: 12
Training loss: 3.5275774002075195
Validation loss: 3.9324639484446537

Epoch: 6| Step: 13
Training loss: 4.572912216186523
Validation loss: 3.897409539068899

Epoch: 3| Step: 0
Training loss: 3.420022964477539
Validation loss: 3.870320709802771

Epoch: 6| Step: 1
Training loss: 3.772510528564453
Validation loss: 3.8434370692058275

Epoch: 6| Step: 2
Training loss: 2.949985980987549
Validation loss: 3.808226436697027

Epoch: 6| Step: 3
Training loss: 4.398652076721191
Validation loss: 3.770949125289917

Epoch: 6| Step: 4
Training loss: 3.435102939605713
Validation loss: 3.731540080039732

Epoch: 6| Step: 5
Training loss: 3.1591544151306152
Validation loss: 3.704288718520954

Epoch: 6| Step: 6
Training loss: 4.755396842956543
Validation loss: 3.6778561043482956

Epoch: 6| Step: 7
Training loss: 2.880361318588257
Validation loss: 3.6494795942819245

Epoch: 6| Step: 8
Training loss: 3.965855121612549
Validation loss: 3.628920232096026

Epoch: 6| Step: 9
Training loss: 3.787076711654663
Validation loss: 3.6095155285250757

Epoch: 6| Step: 10
Training loss: 4.1523942947387695
Validation loss: 3.5866886133788736

Epoch: 6| Step: 11
Training loss: 2.846540927886963
Validation loss: 3.5656026896610054

Epoch: 6| Step: 12
Training loss: 2.9957995414733887
Validation loss: 3.5540951016128703

Epoch: 6| Step: 13
Training loss: 3.954813241958618
Validation loss: 3.5503040359866236

Epoch: 4| Step: 0
Training loss: 3.623382091522217
Validation loss: 3.5310537430547897

Epoch: 6| Step: 1
Training loss: 3.1050150394439697
Validation loss: 3.5148103288424912

Epoch: 6| Step: 2
Training loss: 3.645015239715576
Validation loss: 3.5048314294507428

Epoch: 6| Step: 3
Training loss: 4.309576988220215
Validation loss: 3.4960097497509373

Epoch: 6| Step: 4
Training loss: 4.543215751647949
Validation loss: 3.485747742396529

Epoch: 6| Step: 5
Training loss: 4.255891799926758
Validation loss: 3.4790228566815777

Epoch: 6| Step: 6
Training loss: 3.449916124343872
Validation loss: 3.4687615363828597

Epoch: 6| Step: 7
Training loss: 3.3115830421447754
Validation loss: 3.454981411657026

Epoch: 6| Step: 8
Training loss: 3.2193191051483154
Validation loss: 3.44608828841999

Epoch: 6| Step: 9
Training loss: 2.1923770904541016
Validation loss: 3.433178388944236

Epoch: 6| Step: 10
Training loss: 3.153489112854004
Validation loss: 3.4251226327752553

Epoch: 6| Step: 11
Training loss: 3.778062582015991
Validation loss: 3.4151369884449947

Epoch: 6| Step: 12
Training loss: 2.6991333961486816
Validation loss: 3.4057699275273148

Epoch: 6| Step: 13
Training loss: 1.709375023841858
Validation loss: 3.3980078005021617

Epoch: 5| Step: 0
Training loss: 3.5890610218048096
Validation loss: 3.388768639615787

Epoch: 6| Step: 1
Training loss: 3.1765356063842773
Validation loss: 3.378623854729437

Epoch: 6| Step: 2
Training loss: 3.005427360534668
Validation loss: 3.361650025972756

Epoch: 6| Step: 3
Training loss: 3.110947608947754
Validation loss: 3.3444575981427263

Epoch: 6| Step: 4
Training loss: 3.7712366580963135
Validation loss: 3.331753489791706

Epoch: 6| Step: 5
Training loss: 2.832615375518799
Validation loss: 3.3196423028105047

Epoch: 6| Step: 6
Training loss: 3.9482970237731934
Validation loss: 3.2986229876036286

Epoch: 6| Step: 7
Training loss: 3.0231659412384033
Validation loss: 3.2838723069878033

Epoch: 6| Step: 8
Training loss: 2.7889206409454346
Validation loss: 3.2760255413670696

Epoch: 6| Step: 9
Training loss: 2.8283236026763916
Validation loss: 3.2688660544733845

Epoch: 6| Step: 10
Training loss: 3.827765941619873
Validation loss: 3.268695964608141

Epoch: 6| Step: 11
Training loss: 3.133857250213623
Validation loss: 3.264978588268321

Epoch: 6| Step: 12
Training loss: 3.239067554473877
Validation loss: 3.2570566028677006

Epoch: 6| Step: 13
Training loss: 3.893280029296875
Validation loss: 3.240158801437706

Epoch: 6| Step: 0
Training loss: 2.9206790924072266
Validation loss: 3.2284806313053256

Epoch: 6| Step: 1
Training loss: 3.1770801544189453
Validation loss: 3.2222397917060444

Epoch: 6| Step: 2
Training loss: 3.246889114379883
Validation loss: 3.212121981446461

Epoch: 6| Step: 3
Training loss: 3.7467026710510254
Validation loss: 3.205830430471769

Epoch: 6| Step: 4
Training loss: 3.003516674041748
Validation loss: 3.2038891161641767

Epoch: 6| Step: 5
Training loss: 2.5135223865509033
Validation loss: 3.187827956291937

Epoch: 6| Step: 6
Training loss: 3.7936811447143555
Validation loss: 3.1875063168105258

Epoch: 6| Step: 7
Training loss: 2.776752471923828
Validation loss: 3.1829173718729327

Epoch: 6| Step: 8
Training loss: 2.834805488586426
Validation loss: 3.180712543508058

Epoch: 6| Step: 9
Training loss: 3.350231170654297
Validation loss: 3.1817802177962435

Epoch: 6| Step: 10
Training loss: 2.873295307159424
Validation loss: 3.178096520003452

Epoch: 6| Step: 11
Training loss: 4.310522079467773
Validation loss: 3.1620419666331303

Epoch: 6| Step: 12
Training loss: 3.0704662799835205
Validation loss: 3.1470938933792936

Epoch: 6| Step: 13
Training loss: 3.015566110610962
Validation loss: 3.135649060690275

Epoch: 7| Step: 0
Training loss: 2.9506428241729736
Validation loss: 3.13073464362852

Epoch: 6| Step: 1
Training loss: 2.660386323928833
Validation loss: 3.126148687895908

Epoch: 6| Step: 2
Training loss: 2.8776440620422363
Validation loss: 3.1199002471021426

Epoch: 6| Step: 3
Training loss: 3.019202947616577
Validation loss: 3.106932819530528

Epoch: 6| Step: 4
Training loss: 3.083509922027588
Validation loss: 3.097368860757479

Epoch: 6| Step: 5
Training loss: 3.3126096725463867
Validation loss: 3.0912930016876548

Epoch: 6| Step: 6
Training loss: 2.55485463142395
Validation loss: 3.0841170690392934

Epoch: 6| Step: 7
Training loss: 3.2998039722442627
Validation loss: 3.081513040809221

Epoch: 6| Step: 8
Training loss: 2.9633078575134277
Validation loss: 3.0742648852768766

Epoch: 6| Step: 9
Training loss: 3.18412709236145
Validation loss: 3.0680339387668076

Epoch: 6| Step: 10
Training loss: 3.728572368621826
Validation loss: 3.0707077800586657

Epoch: 6| Step: 11
Training loss: 3.003211736679077
Validation loss: 3.052794164226901

Epoch: 6| Step: 12
Training loss: 4.292342185974121
Validation loss: 3.0516103570179274

Epoch: 6| Step: 13
Training loss: 2.5516252517700195
Validation loss: 3.0408076624716482

Epoch: 8| Step: 0
Training loss: 2.2862677574157715
Validation loss: 3.043093204498291

Epoch: 6| Step: 1
Training loss: 2.715095043182373
Validation loss: 3.030927481189851

Epoch: 6| Step: 2
Training loss: 3.670830249786377
Validation loss: 3.028063820254418

Epoch: 6| Step: 3
Training loss: 2.1259448528289795
Validation loss: 3.0213899638063166

Epoch: 6| Step: 4
Training loss: 3.4751784801483154
Validation loss: 3.0163720192447787

Epoch: 6| Step: 5
Training loss: 2.5092625617980957
Validation loss: 3.0136969858600247

Epoch: 6| Step: 6
Training loss: 3.8470566272735596
Validation loss: 3.011648675446869

Epoch: 6| Step: 7
Training loss: 3.4669735431671143
Validation loss: 3.008950638514693

Epoch: 6| Step: 8
Training loss: 3.9305710792541504
Validation loss: 3.001873234266876

Epoch: 6| Step: 9
Training loss: 3.1475772857666016
Validation loss: 2.9947396580890944

Epoch: 6| Step: 10
Training loss: 2.973365068435669
Validation loss: 2.985856117740754

Epoch: 6| Step: 11
Training loss: 2.4901304244995117
Validation loss: 2.988078345534622

Epoch: 6| Step: 12
Training loss: 3.100431442260742
Validation loss: 2.9865851197191464

Epoch: 6| Step: 13
Training loss: 3.4006357192993164
Validation loss: 2.9771010952611126

Epoch: 9| Step: 0
Training loss: 3.4067273139953613
Validation loss: 2.974636170171922

Epoch: 6| Step: 1
Training loss: 3.733895778656006
Validation loss: 2.9710058448135213

Epoch: 6| Step: 2
Training loss: 2.4699134826660156
Validation loss: 2.9694778739765124

Epoch: 6| Step: 3
Training loss: 3.1915106773376465
Validation loss: 2.967896492250504

Epoch: 6| Step: 4
Training loss: 2.65090012550354
Validation loss: 2.9701064760966966

Epoch: 6| Step: 5
Training loss: 2.784943103790283
Validation loss: 2.9649893340244087

Epoch: 6| Step: 6
Training loss: 2.66290545463562
Validation loss: 2.953346129386656

Epoch: 6| Step: 7
Training loss: 3.506943702697754
Validation loss: 2.9480744331113753

Epoch: 6| Step: 8
Training loss: 3.5378987789154053
Validation loss: 2.9455072982336885

Epoch: 6| Step: 9
Training loss: 2.731783151626587
Validation loss: 2.9418447684216242

Epoch: 6| Step: 10
Training loss: 3.6364521980285645
Validation loss: 2.9395296983821417

Epoch: 6| Step: 11
Training loss: 2.8014721870422363
Validation loss: 2.9331799912196335

Epoch: 6| Step: 12
Training loss: 1.5866787433624268
Validation loss: 2.9295294054092897

Epoch: 6| Step: 13
Training loss: 4.375784873962402
Validation loss: 2.932468124615249

Epoch: 10| Step: 0
Training loss: 2.7295689582824707
Validation loss: 2.9357691528976604

Epoch: 6| Step: 1
Training loss: 3.1900558471679688
Validation loss: 2.9278825431741695

Epoch: 6| Step: 2
Training loss: 2.9285237789154053
Validation loss: 2.91482223233869

Epoch: 6| Step: 3
Training loss: 2.567051410675049
Validation loss: 2.914095204363587

Epoch: 6| Step: 4
Training loss: 2.449605703353882
Validation loss: 2.9151715847753708

Epoch: 6| Step: 5
Training loss: 4.222633361816406
Validation loss: 2.917484127065187

Epoch: 6| Step: 6
Training loss: 3.75046443939209
Validation loss: 2.909878728210285

Epoch: 6| Step: 7
Training loss: 2.5850741863250732
Validation loss: 2.902535520574098

Epoch: 6| Step: 8
Training loss: 2.6740052700042725
Validation loss: 2.8985202389378704

Epoch: 6| Step: 9
Training loss: 2.5853066444396973
Validation loss: 2.900770018177648

Epoch: 6| Step: 10
Training loss: 2.6463189125061035
Validation loss: 2.901060083860992

Epoch: 6| Step: 11
Training loss: 3.579853057861328
Validation loss: 2.9004034790941464

Epoch: 6| Step: 12
Training loss: 2.6052536964416504
Validation loss: 2.8998944631186863

Epoch: 6| Step: 13
Training loss: 4.09105110168457
Validation loss: 2.892807227309032

Epoch: 11| Step: 0
Training loss: 3.107482671737671
Validation loss: 2.883632221529561

Epoch: 6| Step: 1
Training loss: 3.428093433380127
Validation loss: 2.8740581491942048

Epoch: 6| Step: 2
Training loss: 1.6481316089630127
Validation loss: 2.8714099699451077

Epoch: 6| Step: 3
Training loss: 2.427255630493164
Validation loss: 2.868117050458026

Epoch: 6| Step: 4
Training loss: 3.639789581298828
Validation loss: 2.8708984518563874

Epoch: 6| Step: 5
Training loss: 2.3446531295776367
Validation loss: 2.8643659058437554

Epoch: 6| Step: 6
Training loss: 3.123281955718994
Validation loss: 2.8827798007636942

Epoch: 6| Step: 7
Training loss: 2.5932202339172363
Validation loss: 2.8581553351494575

Epoch: 6| Step: 8
Training loss: 3.4963600635528564
Validation loss: 2.8649991481534895

Epoch: 6| Step: 9
Training loss: 2.957550048828125
Validation loss: 2.8756847971229145

Epoch: 6| Step: 10
Training loss: 3.7053236961364746
Validation loss: 2.8645980178668933

Epoch: 6| Step: 11
Training loss: 3.380093812942505
Validation loss: 2.851802013253653

Epoch: 6| Step: 12
Training loss: 3.1843180656433105
Validation loss: 2.8552956837479786

Epoch: 6| Step: 13
Training loss: 2.4978749752044678
Validation loss: 2.858583927154541

Epoch: 12| Step: 0
Training loss: 2.801185131072998
Validation loss: 2.8596642760820288

Epoch: 6| Step: 1
Training loss: 2.9065701961517334
Validation loss: 2.8520367632630053

Epoch: 6| Step: 2
Training loss: 2.254122257232666
Validation loss: 2.8428592630611953

Epoch: 6| Step: 3
Training loss: 2.852471351623535
Validation loss: 2.83566104724843

Epoch: 6| Step: 4
Training loss: 3.169739246368408
Validation loss: 2.827922095534622

Epoch: 6| Step: 5
Training loss: 3.0260019302368164
Validation loss: 2.8238209088643393

Epoch: 6| Step: 6
Training loss: 2.3945889472961426
Validation loss: 2.82062768167065

Epoch: 6| Step: 7
Training loss: 2.3411972522735596
Validation loss: 2.8191977162514963

Epoch: 6| Step: 8
Training loss: 3.110105514526367
Validation loss: 2.815737585867605

Epoch: 6| Step: 9
Training loss: 3.2302064895629883
Validation loss: 2.8144156548284713

Epoch: 6| Step: 10
Training loss: 3.2379822731018066
Validation loss: 2.808154434286138

Epoch: 6| Step: 11
Training loss: 3.105088233947754
Validation loss: 2.7944933009404007

Epoch: 6| Step: 12
Training loss: 3.260272979736328
Validation loss: 2.7942002332338722

Epoch: 6| Step: 13
Training loss: 4.109156608581543
Validation loss: 2.792545062239452

Epoch: 13| Step: 0
Training loss: 3.0831351280212402
Validation loss: 2.788738489151001

Epoch: 6| Step: 1
Training loss: 2.8684403896331787
Validation loss: 2.785809099033315

Epoch: 6| Step: 2
Training loss: 2.801596164703369
Validation loss: 2.7817376403398413

Epoch: 6| Step: 3
Training loss: 2.723633289337158
Validation loss: 2.777837884041571

Epoch: 6| Step: 4
Training loss: 2.8899078369140625
Validation loss: 2.7728218570832284

Epoch: 6| Step: 5
Training loss: 2.2476272583007812
Validation loss: 2.7715208043334303

Epoch: 6| Step: 6
Training loss: 3.0147647857666016
Validation loss: 2.7668128398156937

Epoch: 6| Step: 7
Training loss: 2.8048107624053955
Validation loss: 2.774199003814369

Epoch: 6| Step: 8
Training loss: 2.779006242752075
Validation loss: 2.7808362463469147

Epoch: 6| Step: 9
Training loss: 3.491518259048462
Validation loss: 2.7718536981972317

Epoch: 6| Step: 10
Training loss: 2.872183322906494
Validation loss: 2.7555718909027758

Epoch: 6| Step: 11
Training loss: 3.149102210998535
Validation loss: 2.7585815562996814

Epoch: 6| Step: 12
Training loss: 3.6545257568359375
Validation loss: 2.751937994392969

Epoch: 6| Step: 13
Training loss: 1.920472264289856
Validation loss: 2.7476199698704544

Epoch: 14| Step: 0
Training loss: 3.3611841201782227
Validation loss: 2.7392290997248825

Epoch: 6| Step: 1
Training loss: 2.7592883110046387
Validation loss: 2.73701221968538

Epoch: 6| Step: 2
Training loss: 3.050140857696533
Validation loss: 2.7318292074306036

Epoch: 6| Step: 3
Training loss: 3.0754168033599854
Validation loss: 2.729181651146181

Epoch: 6| Step: 4
Training loss: 3.3524744510650635
Validation loss: 2.7231444235770934

Epoch: 6| Step: 5
Training loss: 1.8553831577301025
Validation loss: 2.7219332982135076

Epoch: 6| Step: 6
Training loss: 2.4748518466949463
Validation loss: 2.7201881126690934

Epoch: 6| Step: 7
Training loss: 2.5080008506774902
Validation loss: 2.730694434976065

Epoch: 6| Step: 8
Training loss: 2.523175001144409
Validation loss: 2.723071123964043

Epoch: 6| Step: 9
Training loss: 3.234853744506836
Validation loss: 2.723518156236218

Epoch: 6| Step: 10
Training loss: 2.3854432106018066
Validation loss: 2.723600233754804

Epoch: 6| Step: 11
Training loss: 3.562190055847168
Validation loss: 2.7112755647269626

Epoch: 6| Step: 12
Training loss: 3.235898494720459
Validation loss: 2.7039377766270793

Epoch: 6| Step: 13
Training loss: 2.9708778858184814
Validation loss: 2.7035443141896236

Epoch: 15| Step: 0
Training loss: 2.937718391418457
Validation loss: 2.6978684984227663

Epoch: 6| Step: 1
Training loss: 3.499457359313965
Validation loss: 2.694206145501906

Epoch: 6| Step: 2
Training loss: 2.255309820175171
Validation loss: 2.688281656593405

Epoch: 6| Step: 3
Training loss: 2.1715619564056396
Validation loss: 2.706382841192266

Epoch: 6| Step: 4
Training loss: 2.0799450874328613
Validation loss: 2.69024831761596

Epoch: 6| Step: 5
Training loss: 2.3813395500183105
Validation loss: 2.6877484501049085

Epoch: 6| Step: 6
Training loss: 3.227961778640747
Validation loss: 2.6968084048199397

Epoch: 6| Step: 7
Training loss: 4.023764610290527
Validation loss: 2.6940750178470405

Epoch: 6| Step: 8
Training loss: 3.0063509941101074
Validation loss: 2.6797717925040954

Epoch: 6| Step: 9
Training loss: 2.5430335998535156
Validation loss: 2.6764521932089202

Epoch: 6| Step: 10
Training loss: 2.825023889541626
Validation loss: 2.673759468140141

Epoch: 6| Step: 11
Training loss: 2.9598026275634766
Validation loss: 2.684205952511039

Epoch: 6| Step: 12
Training loss: 3.092705249786377
Validation loss: 2.684500919875278

Epoch: 6| Step: 13
Training loss: 3.0680859088897705
Validation loss: 2.6723659525635424

Epoch: 16| Step: 0
Training loss: 2.861292839050293
Validation loss: 2.663039720186623

Epoch: 6| Step: 1
Training loss: 3.1315746307373047
Validation loss: 2.6722261546760477

Epoch: 6| Step: 2
Training loss: 1.8543875217437744
Validation loss: 2.654321091149443

Epoch: 6| Step: 3
Training loss: 3.128019094467163
Validation loss: 2.6608978061265844

Epoch: 6| Step: 4
Training loss: 2.9750282764434814
Validation loss: 2.665654420852661

Epoch: 6| Step: 5
Training loss: 3.0766677856445312
Validation loss: 2.670763764330136

Epoch: 6| Step: 6
Training loss: 2.9379448890686035
Validation loss: 2.6680043205138175

Epoch: 6| Step: 7
Training loss: 3.3339860439300537
Validation loss: 2.6653825493269068

Epoch: 6| Step: 8
Training loss: 2.0386815071105957
Validation loss: 2.674844067583802

Epoch: 6| Step: 9
Training loss: 2.875391721725464
Validation loss: 2.6821816249560286

Epoch: 6| Step: 10
Training loss: 2.8504700660705566
Validation loss: 2.6764733252986783

Epoch: 6| Step: 11
Training loss: 3.4108951091766357
Validation loss: 2.664270850919908

Epoch: 6| Step: 12
Training loss: 2.289858818054199
Validation loss: 2.647969968857304

Epoch: 6| Step: 13
Training loss: 2.968186378479004
Validation loss: 2.6472116311391196

Epoch: 17| Step: 0
Training loss: 3.9825844764709473
Validation loss: 2.6423367787432928

Epoch: 6| Step: 1
Training loss: 3.292893886566162
Validation loss: 2.648699245145244

Epoch: 6| Step: 2
Training loss: 1.95009183883667
Validation loss: 2.6471137692851405

Epoch: 6| Step: 3
Training loss: 2.3672122955322266
Validation loss: 2.642531964086717

Epoch: 6| Step: 4
Training loss: 1.9633854627609253
Validation loss: 2.640286450744957

Epoch: 6| Step: 5
Training loss: 3.1061253547668457
Validation loss: 2.627356506163074

Epoch: 6| Step: 6
Training loss: 2.07287335395813
Validation loss: 2.6230334274230467

Epoch: 6| Step: 7
Training loss: 2.994138717651367
Validation loss: 2.6332271688727924

Epoch: 6| Step: 8
Training loss: 3.404892921447754
Validation loss: 2.6243254676941903

Epoch: 6| Step: 9
Training loss: 2.4170851707458496
Validation loss: 2.6169873975938365

Epoch: 6| Step: 10
Training loss: 2.3636152744293213
Validation loss: 2.6171608048100627

Epoch: 6| Step: 11
Training loss: 3.601651906967163
Validation loss: 2.638576271713421

Epoch: 6| Step: 12
Training loss: 2.9226696491241455
Validation loss: 2.6199993882127988

Epoch: 6| Step: 13
Training loss: 2.8757729530334473
Validation loss: 2.6103671109804543

Epoch: 18| Step: 0
Training loss: 3.1789703369140625
Validation loss: 2.6120795665248746

Epoch: 6| Step: 1
Training loss: 2.816107749938965
Validation loss: 2.627197955244331

Epoch: 6| Step: 2
Training loss: 2.8033502101898193
Validation loss: 2.6158760850147535

Epoch: 6| Step: 3
Training loss: 2.5727734565734863
Validation loss: 2.616034548769715

Epoch: 6| Step: 4
Training loss: 3.1352996826171875
Validation loss: 2.598581087204718

Epoch: 6| Step: 5
Training loss: 2.6509785652160645
Validation loss: 2.5970644848321074

Epoch: 6| Step: 6
Training loss: 2.9464802742004395
Validation loss: 2.6012337669249503

Epoch: 6| Step: 7
Training loss: 2.8686280250549316
Validation loss: 2.604660144416235

Epoch: 6| Step: 8
Training loss: 2.5775465965270996
Validation loss: 2.604650115454069

Epoch: 6| Step: 9
Training loss: 2.01605224609375
Validation loss: 2.593541004324472

Epoch: 6| Step: 10
Training loss: 3.199371337890625
Validation loss: 2.589275684407962

Epoch: 6| Step: 11
Training loss: 2.465219736099243
Validation loss: 2.615557614193168

Epoch: 6| Step: 12
Training loss: 3.128328323364258
Validation loss: 2.641262751753612

Epoch: 6| Step: 13
Training loss: 2.6040120124816895
Validation loss: 2.6022151875239548

Epoch: 19| Step: 0
Training loss: 2.2131643295288086
Validation loss: 2.5728096679974626

Epoch: 6| Step: 1
Training loss: 2.245800018310547
Validation loss: 2.5777692794799805

Epoch: 6| Step: 2
Training loss: 2.3984150886535645
Validation loss: 2.5946452104917137

Epoch: 6| Step: 3
Training loss: 3.212843656539917
Validation loss: 2.6166473742454284

Epoch: 6| Step: 4
Training loss: 3.3296337127685547
Validation loss: 2.621732937392368

Epoch: 6| Step: 5
Training loss: 3.290350914001465
Validation loss: 2.609612344413675

Epoch: 6| Step: 6
Training loss: 2.53074049949646
Validation loss: 2.6452100353856243

Epoch: 6| Step: 7
Training loss: 3.184098243713379
Validation loss: 2.6549776292616323

Epoch: 6| Step: 8
Training loss: 2.22851824760437
Validation loss: 2.6452862601126395

Epoch: 6| Step: 9
Training loss: 3.100459575653076
Validation loss: 2.6098588025698097

Epoch: 6| Step: 10
Training loss: 3.0450668334960938
Validation loss: 2.583901893708014

Epoch: 6| Step: 11
Training loss: 3.0845136642456055
Validation loss: 2.5818646210496143

Epoch: 6| Step: 12
Training loss: 2.327702045440674
Validation loss: 2.5838453692774617

Epoch: 6| Step: 13
Training loss: 2.9254560470581055
Validation loss: 2.5847760656828522

Epoch: 20| Step: 0
Training loss: 3.051673173904419
Validation loss: 2.579445985055739

Epoch: 6| Step: 1
Training loss: 2.6280617713928223
Validation loss: 2.572910834384221

Epoch: 6| Step: 2
Training loss: 2.8294434547424316
Validation loss: 2.574710633165093

Epoch: 6| Step: 3
Training loss: 2.9393458366394043
Validation loss: 2.57992507309042

Epoch: 6| Step: 4
Training loss: 2.8300600051879883
Validation loss: 2.5861579474582466

Epoch: 6| Step: 5
Training loss: 3.4507744312286377
Validation loss: 2.581122613722278

Epoch: 6| Step: 6
Training loss: 2.280594825744629
Validation loss: 2.5796637048003492

Epoch: 6| Step: 7
Training loss: 1.7176952362060547
Validation loss: 2.5760571008087485

Epoch: 6| Step: 8
Training loss: 2.069800853729248
Validation loss: 2.5722400347391763

Epoch: 6| Step: 9
Training loss: 2.403562307357788
Validation loss: 2.5620837416700137

Epoch: 6| Step: 10
Training loss: 3.388559103012085
Validation loss: 2.5557511339905443

Epoch: 6| Step: 11
Training loss: 2.7249884605407715
Validation loss: 2.5510170382838093

Epoch: 6| Step: 12
Training loss: 3.424268960952759
Validation loss: 2.5458670021385275

Epoch: 6| Step: 13
Training loss: 2.734823703765869
Validation loss: 2.5465987138850714

Epoch: 21| Step: 0
Training loss: 2.3394107818603516
Validation loss: 2.547043626026441

Epoch: 6| Step: 1
Training loss: 2.407911777496338
Validation loss: 2.5479203116509224

Epoch: 6| Step: 2
Training loss: 2.044680595397949
Validation loss: 2.5496479260024203

Epoch: 6| Step: 3
Training loss: 2.9615318775177
Validation loss: 2.537491608691472

Epoch: 6| Step: 4
Training loss: 2.6457161903381348
Validation loss: 2.5369820620424006

Epoch: 6| Step: 5
Training loss: 3.3991165161132812
Validation loss: 2.5345499746261106

Epoch: 6| Step: 6
Training loss: 2.8054795265197754
Validation loss: 2.5322766509107364

Epoch: 6| Step: 7
Training loss: 3.8045616149902344
Validation loss: 2.5356639072459233

Epoch: 6| Step: 8
Training loss: 2.1456570625305176
Validation loss: 2.5334924241547943

Epoch: 6| Step: 9
Training loss: 2.424243450164795
Validation loss: 2.53059967102543

Epoch: 6| Step: 10
Training loss: 2.7493014335632324
Validation loss: 2.5290400571720575

Epoch: 6| Step: 11
Training loss: 3.2454633712768555
Validation loss: 2.5245239427012782

Epoch: 6| Step: 12
Training loss: 2.452712059020996
Validation loss: 2.5293107750595256

Epoch: 6| Step: 13
Training loss: 2.9407382011413574
Validation loss: 2.5244193923088813

Epoch: 22| Step: 0
Training loss: 2.6071529388427734
Validation loss: 2.5483040194357596

Epoch: 6| Step: 1
Training loss: 2.1348414421081543
Validation loss: 2.5897041341309905

Epoch: 6| Step: 2
Training loss: 2.561649799346924
Validation loss: 2.6086143139869935

Epoch: 6| Step: 3
Training loss: 3.00557279586792
Validation loss: 2.625323495557231

Epoch: 6| Step: 4
Training loss: 2.419938802719116
Validation loss: 2.5615799965397006

Epoch: 6| Step: 5
Training loss: 2.721461296081543
Validation loss: 2.532571969493743

Epoch: 6| Step: 6
Training loss: 2.2947347164154053
Validation loss: 2.5263852047663864

Epoch: 6| Step: 7
Training loss: 2.98561692237854
Validation loss: 2.5355647763898297

Epoch: 6| Step: 8
Training loss: 3.2628417015075684
Validation loss: 2.5352849293780584

Epoch: 6| Step: 9
Training loss: 3.068657398223877
Validation loss: 2.537411907667755

Epoch: 6| Step: 10
Training loss: 2.673701763153076
Validation loss: 2.547060722945839

Epoch: 6| Step: 11
Training loss: 2.572467803955078
Validation loss: 2.548522674909202

Epoch: 6| Step: 12
Training loss: 2.8463759422302246
Validation loss: 2.540592065421484

Epoch: 6| Step: 13
Training loss: 3.608828544616699
Validation loss: 2.5331868817729335

Epoch: 23| Step: 0
Training loss: 3.194464921951294
Validation loss: 2.5161961534971833

Epoch: 6| Step: 1
Training loss: 2.509023666381836
Validation loss: 2.5079904884420414

Epoch: 6| Step: 2
Training loss: 1.784977674484253
Validation loss: 2.5075450276815765

Epoch: 6| Step: 3
Training loss: 2.2130613327026367
Validation loss: 2.5401108264923096

Epoch: 6| Step: 4
Training loss: 2.6427087783813477
Validation loss: 2.5607621874860538

Epoch: 6| Step: 5
Training loss: 2.391479969024658
Validation loss: 2.580454041880946

Epoch: 6| Step: 6
Training loss: 3.767728567123413
Validation loss: 2.5557408050824235

Epoch: 6| Step: 7
Training loss: 2.844151496887207
Validation loss: 2.5112245775038198

Epoch: 6| Step: 8
Training loss: 3.488954544067383
Validation loss: 2.50068845031082

Epoch: 6| Step: 9
Training loss: 3.051455497741699
Validation loss: 2.5026323000590005

Epoch: 6| Step: 10
Training loss: 2.4002280235290527
Validation loss: 2.508172112126504

Epoch: 6| Step: 11
Training loss: 3.070657253265381
Validation loss: 2.533086235805224

Epoch: 6| Step: 12
Training loss: 2.010618209838867
Validation loss: 2.509847184663178

Epoch: 6| Step: 13
Training loss: 2.9431707859039307
Validation loss: 2.508856455485026

Epoch: 24| Step: 0
Training loss: 3.085488796234131
Validation loss: 2.5017301369738836

Epoch: 6| Step: 1
Training loss: 2.5406551361083984
Validation loss: 2.502235125469905

Epoch: 6| Step: 2
Training loss: 3.3133747577667236
Validation loss: 2.5193532564306773

Epoch: 6| Step: 3
Training loss: 2.5114994049072266
Validation loss: 2.540650208791097

Epoch: 6| Step: 4
Training loss: 2.511974811553955
Validation loss: 2.583164143305953

Epoch: 6| Step: 5
Training loss: 3.0059564113616943
Validation loss: 2.5966399664519937

Epoch: 6| Step: 6
Training loss: 2.06485652923584
Validation loss: 2.5637884806561213

Epoch: 6| Step: 7
Training loss: 2.906101942062378
Validation loss: 2.5183955674530356

Epoch: 6| Step: 8
Training loss: 2.12626576423645
Validation loss: 2.4893429830510128

Epoch: 6| Step: 9
Training loss: 2.4469470977783203
Validation loss: 2.484787371850783

Epoch: 6| Step: 10
Training loss: 2.721952438354492
Validation loss: 2.4940624262696955

Epoch: 6| Step: 11
Training loss: 2.8928773403167725
Validation loss: 2.500456271633025

Epoch: 6| Step: 12
Training loss: 2.86483097076416
Validation loss: 2.5052780925586657

Epoch: 6| Step: 13
Training loss: 3.2355754375457764
Validation loss: 2.5074576100995465

Epoch: 25| Step: 0
Training loss: 2.485015392303467
Validation loss: 2.5116711637025237

Epoch: 6| Step: 1
Training loss: 2.220957040786743
Validation loss: 2.5157886153908184

Epoch: 6| Step: 2
Training loss: 2.4442248344421387
Validation loss: 2.5120609344974643

Epoch: 6| Step: 3
Training loss: 2.572789192199707
Validation loss: 2.505688600642707

Epoch: 6| Step: 4
Training loss: 2.3571362495422363
Validation loss: 2.4934511761511526

Epoch: 6| Step: 5
Training loss: 2.888019561767578
Validation loss: 2.4874481283208376

Epoch: 6| Step: 6
Training loss: 3.6198530197143555
Validation loss: 2.484879950041412

Epoch: 6| Step: 7
Training loss: 2.920279026031494
Validation loss: 2.4845325639170985

Epoch: 6| Step: 8
Training loss: 2.826141834259033
Validation loss: 2.4876558806306575

Epoch: 6| Step: 9
Training loss: 2.3731040954589844
Validation loss: 2.502257823944092

Epoch: 6| Step: 10
Training loss: 2.6591367721557617
Validation loss: 2.525506575902303

Epoch: 6| Step: 11
Training loss: 2.958144426345825
Validation loss: 2.504775165229715

Epoch: 6| Step: 12
Training loss: 2.9408295154571533
Validation loss: 2.4921521525229178

Epoch: 6| Step: 13
Training loss: 2.9675114154815674
Validation loss: 2.5026096656758297

Epoch: 26| Step: 0
Training loss: 3.167240619659424
Validation loss: 2.50204538529919

Epoch: 6| Step: 1
Training loss: 1.6687425374984741
Validation loss: 2.4979021241587978

Epoch: 6| Step: 2
Training loss: 2.8658180236816406
Validation loss: 2.48383593046537

Epoch: 6| Step: 3
Training loss: 2.84922194480896
Validation loss: 2.481472123053766

Epoch: 6| Step: 4
Training loss: 2.832825183868408
Validation loss: 2.4802011853905133

Epoch: 6| Step: 5
Training loss: 2.854208469390869
Validation loss: 2.4757820560086157

Epoch: 6| Step: 6
Training loss: 3.0167386531829834
Validation loss: 2.4739312766700663

Epoch: 6| Step: 7
Training loss: 2.8265700340270996
Validation loss: 2.4730587646525395

Epoch: 6| Step: 8
Training loss: 2.299044609069824
Validation loss: 2.48553216585549

Epoch: 6| Step: 9
Training loss: 2.236915111541748
Validation loss: 2.5006871402904554

Epoch: 6| Step: 10
Training loss: 2.9337730407714844
Validation loss: 2.5215490159168037

Epoch: 6| Step: 11
Training loss: 3.05035138130188
Validation loss: 2.4849558081678165

Epoch: 6| Step: 12
Training loss: 2.6177773475646973
Validation loss: 2.4741763299511326

Epoch: 6| Step: 13
Training loss: 2.5646655559539795
Validation loss: 2.4685896852964997

Epoch: 27| Step: 0
Training loss: 2.3833603858947754
Validation loss: 2.4653571010917745

Epoch: 6| Step: 1
Training loss: 3.1341006755828857
Validation loss: 2.464644496158887

Epoch: 6| Step: 2
Training loss: 2.614717960357666
Validation loss: 2.4606086438702

Epoch: 6| Step: 3
Training loss: 2.6542181968688965
Validation loss: 2.461508253569244

Epoch: 6| Step: 4
Training loss: 3.2570738792419434
Validation loss: 2.4701508040069253

Epoch: 6| Step: 5
Training loss: 1.8746120929718018
Validation loss: 2.4808049612147833

Epoch: 6| Step: 6
Training loss: 2.846933364868164
Validation loss: 2.500246699138354

Epoch: 6| Step: 7
Training loss: 4.02730655670166
Validation loss: 2.522584392178443

Epoch: 6| Step: 8
Training loss: 1.8297628164291382
Validation loss: 2.5401005565479235

Epoch: 6| Step: 9
Training loss: 2.6814470291137695
Validation loss: 2.5617645094471593

Epoch: 6| Step: 10
Training loss: 1.9637539386749268
Validation loss: 2.542440520819797

Epoch: 6| Step: 11
Training loss: 2.5494813919067383
Validation loss: 2.524553645041681

Epoch: 6| Step: 12
Training loss: 3.2405896186828613
Validation loss: 2.527162290388538

Epoch: 6| Step: 13
Training loss: 2.6229987144470215
Validation loss: 2.4892513649438017

Epoch: 28| Step: 0
Training loss: 3.4538488388061523
Validation loss: 2.4767570034150155

Epoch: 6| Step: 1
Training loss: 3.3014910221099854
Validation loss: 2.4782122924763668

Epoch: 6| Step: 2
Training loss: 2.070406436920166
Validation loss: 2.4794162934826267

Epoch: 6| Step: 3
Training loss: 2.9703245162963867
Validation loss: 2.492177014709801

Epoch: 6| Step: 4
Training loss: 2.4657559394836426
Validation loss: 2.4950347895263345

Epoch: 6| Step: 5
Training loss: 2.443474292755127
Validation loss: 2.4811438501522107

Epoch: 6| Step: 6
Training loss: 3.0204339027404785
Validation loss: 2.4623158721513647

Epoch: 6| Step: 7
Training loss: 2.928779363632202
Validation loss: 2.4588519142520044

Epoch: 6| Step: 8
Training loss: 2.7922117710113525
Validation loss: 2.4573724962049917

Epoch: 6| Step: 9
Training loss: 2.380922794342041
Validation loss: 2.4551285877022693

Epoch: 6| Step: 10
Training loss: 2.898756504058838
Validation loss: 2.4737662320495932

Epoch: 6| Step: 11
Training loss: 2.5406131744384766
Validation loss: 2.5001434690208844

Epoch: 6| Step: 12
Training loss: 2.0635650157928467
Validation loss: 2.5430730773556616

Epoch: 6| Step: 13
Training loss: 2.4062254428863525
Validation loss: 2.587420137979651

Epoch: 29| Step: 0
Training loss: 2.834144115447998
Validation loss: 2.5791523969301613

Epoch: 6| Step: 1
Training loss: 2.4151558876037598
Validation loss: 2.5132082329001477

Epoch: 6| Step: 2
Training loss: 2.7228739261627197
Validation loss: 2.496659460888114

Epoch: 6| Step: 3
Training loss: 3.286259174346924
Validation loss: 2.477119456055344

Epoch: 6| Step: 4
Training loss: 2.0019545555114746
Validation loss: 2.480791420064947

Epoch: 6| Step: 5
Training loss: 2.5229554176330566
Validation loss: 2.4703833300580262

Epoch: 6| Step: 6
Training loss: 2.6385610103607178
Validation loss: 2.458817961395428

Epoch: 6| Step: 7
Training loss: 2.718751907348633
Validation loss: 2.454527690846433

Epoch: 6| Step: 8
Training loss: 2.2260847091674805
Validation loss: 2.4558800394817064

Epoch: 6| Step: 9
Training loss: 2.929769515991211
Validation loss: 2.4633122490298365

Epoch: 6| Step: 10
Training loss: 2.496828556060791
Validation loss: 2.4558395057596187

Epoch: 6| Step: 11
Training loss: 2.7873997688293457
Validation loss: 2.4515270392100015

Epoch: 6| Step: 12
Training loss: 2.897479295730591
Validation loss: 2.4522319673210062

Epoch: 6| Step: 13
Training loss: 3.3759407997131348
Validation loss: 2.4536046263992146

Epoch: 30| Step: 0
Training loss: 2.3518199920654297
Validation loss: 2.4465296858100483

Epoch: 6| Step: 1
Training loss: 1.969985842704773
Validation loss: 2.4531273662403064

Epoch: 6| Step: 2
Training loss: 1.9081053733825684
Validation loss: 2.46254712535489

Epoch: 6| Step: 3
Training loss: 2.5847649574279785
Validation loss: 2.499682728962232

Epoch: 6| Step: 4
Training loss: 3.2354183197021484
Validation loss: 2.513066840428178

Epoch: 6| Step: 5
Training loss: 2.7235968112945557
Validation loss: 2.486763172252204

Epoch: 6| Step: 6
Training loss: 2.427807331085205
Validation loss: 2.4604899498724166

Epoch: 6| Step: 7
Training loss: 3.107849597930908
Validation loss: 2.4444881972446235

Epoch: 6| Step: 8
Training loss: 3.217122793197632
Validation loss: 2.4431296702354186

Epoch: 6| Step: 9
Training loss: 2.048762321472168
Validation loss: 2.4417200652501916

Epoch: 6| Step: 10
Training loss: 2.2615089416503906
Validation loss: 2.453612786467357

Epoch: 6| Step: 11
Training loss: 3.5052571296691895
Validation loss: 2.471899086429227

Epoch: 6| Step: 12
Training loss: 3.2072291374206543
Validation loss: 2.4708393978816208

Epoch: 6| Step: 13
Training loss: 3.0503573417663574
Validation loss: 2.4722991169139905

Epoch: 31| Step: 0
Training loss: 3.4581360816955566
Validation loss: 2.455628684771958

Epoch: 6| Step: 1
Training loss: 2.2223379611968994
Validation loss: 2.441291819336594

Epoch: 6| Step: 2
Training loss: 2.9283151626586914
Validation loss: 2.432778960915022

Epoch: 6| Step: 3
Training loss: 2.8253653049468994
Validation loss: 2.4330955961699128

Epoch: 6| Step: 4
Training loss: 3.297224998474121
Validation loss: 2.447078245942311

Epoch: 6| Step: 5
Training loss: 2.9048619270324707
Validation loss: 2.4606321665548507

Epoch: 6| Step: 6
Training loss: 2.001753330230713
Validation loss: 2.4823481805862917

Epoch: 6| Step: 7
Training loss: 2.8587489128112793
Validation loss: 2.5072083909024476

Epoch: 6| Step: 8
Training loss: 2.1568140983581543
Validation loss: 2.5373644623705136

Epoch: 6| Step: 9
Training loss: 2.8140597343444824
Validation loss: 2.543456974849906

Epoch: 6| Step: 10
Training loss: 1.9569964408874512
Validation loss: 2.511899161082442

Epoch: 6| Step: 11
Training loss: 2.9131088256835938
Validation loss: 2.5118383848538963

Epoch: 6| Step: 12
Training loss: 2.268737316131592
Validation loss: 2.4845298849126345

Epoch: 6| Step: 13
Training loss: 2.9048900604248047
Validation loss: 2.455245972961508

Epoch: 32| Step: 0
Training loss: 2.6050493717193604
Validation loss: 2.436951978232271

Epoch: 6| Step: 1
Training loss: 2.961909770965576
Validation loss: 2.41649269288586

Epoch: 6| Step: 2
Training loss: 2.34525728225708
Validation loss: 2.4250180259827645

Epoch: 6| Step: 3
Training loss: 2.0067360401153564
Validation loss: 2.429381042398432

Epoch: 6| Step: 4
Training loss: 3.250058650970459
Validation loss: 2.4591113598115983

Epoch: 6| Step: 5
Training loss: 2.733365058898926
Validation loss: 2.4579992089220273

Epoch: 6| Step: 6
Training loss: 3.028163433074951
Validation loss: 2.4325395758434007

Epoch: 6| Step: 7
Training loss: 1.9210560321807861
Validation loss: 2.4132972071247716

Epoch: 6| Step: 8
Training loss: 3.1415915489196777
Validation loss: 2.40487765753141

Epoch: 6| Step: 9
Training loss: 2.8016357421875
Validation loss: 2.4011266436628116

Epoch: 6| Step: 10
Training loss: 2.708611488342285
Validation loss: 2.4054301554156887

Epoch: 6| Step: 11
Training loss: 3.430389881134033
Validation loss: 2.417975776938982

Epoch: 6| Step: 12
Training loss: 2.066646099090576
Validation loss: 2.4391179187323457

Epoch: 6| Step: 13
Training loss: 2.3496551513671875
Validation loss: 2.4645469137417373

Epoch: 33| Step: 0
Training loss: 1.9417529106140137
Validation loss: 2.481198477488692

Epoch: 6| Step: 1
Training loss: 2.681403636932373
Validation loss: 2.4846100858462754

Epoch: 6| Step: 2
Training loss: 2.451991558074951
Validation loss: 2.4525347807074107

Epoch: 6| Step: 3
Training loss: 2.1772680282592773
Validation loss: 2.432768198751634

Epoch: 6| Step: 4
Training loss: 2.174304962158203
Validation loss: 2.4180455951280493

Epoch: 6| Step: 5
Training loss: 3.0615854263305664
Validation loss: 2.411922795798189

Epoch: 6| Step: 6
Training loss: 2.6318206787109375
Validation loss: 2.4100672301425727

Epoch: 6| Step: 7
Training loss: 2.8667354583740234
Validation loss: 2.406872605764738

Epoch: 6| Step: 8
Training loss: 3.116182804107666
Validation loss: 2.4109070454874346

Epoch: 6| Step: 9
Training loss: 3.479320764541626
Validation loss: 2.410024796762774

Epoch: 6| Step: 10
Training loss: 2.470417022705078
Validation loss: 2.415496018625075

Epoch: 6| Step: 11
Training loss: 2.9445900917053223
Validation loss: 2.4126801029328377

Epoch: 6| Step: 12
Training loss: 2.3235206604003906
Validation loss: 2.412445390096275

Epoch: 6| Step: 13
Training loss: 3.052074432373047
Validation loss: 2.411054080532443

Epoch: 34| Step: 0
Training loss: 2.7029051780700684
Validation loss: 2.4192413283932592

Epoch: 6| Step: 1
Training loss: 2.5106818675994873
Validation loss: 2.4259254701675905

Epoch: 6| Step: 2
Training loss: 2.690624952316284
Validation loss: 2.438374980803459

Epoch: 6| Step: 3
Training loss: 2.0152335166931152
Validation loss: 2.450191622139305

Epoch: 6| Step: 4
Training loss: 2.208977222442627
Validation loss: 2.4883942245155253

Epoch: 6| Step: 5
Training loss: 1.9534391164779663
Validation loss: 2.519919564647059

Epoch: 6| Step: 6
Training loss: 3.38588285446167
Validation loss: 2.633299663502683

Epoch: 6| Step: 7
Training loss: 3.3609814643859863
Validation loss: 2.7903066142912833

Epoch: 6| Step: 8
Training loss: 2.764988422393799
Validation loss: 2.7811733394540767

Epoch: 6| Step: 9
Training loss: 3.5283594131469727
Validation loss: 2.6839584919714157

Epoch: 6| Step: 10
Training loss: 2.252349853515625
Validation loss: 2.6106791419367634

Epoch: 6| Step: 11
Training loss: 3.2920780181884766
Validation loss: 2.6494098248020297

Epoch: 6| Step: 12
Training loss: 3.5646021366119385
Validation loss: 2.6010079409486506

Epoch: 6| Step: 13
Training loss: 1.8941200971603394
Validation loss: 2.5251107087699314

Epoch: 35| Step: 0
Training loss: 2.879518985748291
Validation loss: 2.5185064628560054

Epoch: 6| Step: 1
Training loss: 2.6964478492736816
Validation loss: 2.5068065761238016

Epoch: 6| Step: 2
Training loss: 2.3282878398895264
Validation loss: 2.419509464694608

Epoch: 6| Step: 3
Training loss: 2.9861903190612793
Validation loss: 2.3999535909263034

Epoch: 6| Step: 4
Training loss: 2.374330520629883
Validation loss: 2.405230863119966

Epoch: 6| Step: 5
Training loss: 2.5661916732788086
Validation loss: 2.406999736703852

Epoch: 6| Step: 6
Training loss: 2.489137649536133
Validation loss: 2.4321532018723024

Epoch: 6| Step: 7
Training loss: 3.1344687938690186
Validation loss: 2.4749207676097913

Epoch: 6| Step: 8
Training loss: 2.6169192790985107
Validation loss: 2.5009773354376517

Epoch: 6| Step: 9
Training loss: 2.437605857849121
Validation loss: 2.491028654959894

Epoch: 6| Step: 10
Training loss: 2.8694450855255127
Validation loss: 2.4808483482688986

Epoch: 6| Step: 11
Training loss: 2.880882978439331
Validation loss: 2.4824621959399154

Epoch: 6| Step: 12
Training loss: 2.1943554878234863
Validation loss: 2.474698697367022

Epoch: 6| Step: 13
Training loss: 3.290041446685791
Validation loss: 2.464965446020967

Epoch: 36| Step: 0
Training loss: 3.4789466857910156
Validation loss: 2.448151916585943

Epoch: 6| Step: 1
Training loss: 2.7634787559509277
Validation loss: 2.4204004041610228

Epoch: 6| Step: 2
Training loss: 2.593557596206665
Validation loss: 2.419017909675516

Epoch: 6| Step: 3
Training loss: 3.1673946380615234
Validation loss: 2.426666457165954

Epoch: 6| Step: 4
Training loss: 3.0780510902404785
Validation loss: 2.412229414909117

Epoch: 6| Step: 5
Training loss: 2.3360962867736816
Validation loss: 2.400262709586851

Epoch: 6| Step: 6
Training loss: 2.5464839935302734
Validation loss: 2.3962717287002073

Epoch: 6| Step: 7
Training loss: 2.2780086994171143
Validation loss: 2.394246642307569

Epoch: 6| Step: 8
Training loss: 2.3525679111480713
Validation loss: 2.3989094611137145

Epoch: 6| Step: 9
Training loss: 2.3899874687194824
Validation loss: 2.4439645326265724

Epoch: 6| Step: 10
Training loss: 2.4152626991271973
Validation loss: 2.4685912337354434

Epoch: 6| Step: 11
Training loss: 2.111920118331909
Validation loss: 2.448482387809343

Epoch: 6| Step: 12
Training loss: 2.8895795345306396
Validation loss: 2.4343939417151996

Epoch: 6| Step: 13
Training loss: 3.004185676574707
Validation loss: 2.3977151942509476

Epoch: 37| Step: 0
Training loss: 2.6701643466949463
Validation loss: 2.413854734871977

Epoch: 6| Step: 1
Training loss: 2.825601577758789
Validation loss: 2.428921450850784

Epoch: 6| Step: 2
Training loss: 2.1566600799560547
Validation loss: 2.4498108689503004

Epoch: 6| Step: 3
Training loss: 2.8049168586730957
Validation loss: 2.473464342855638

Epoch: 6| Step: 4
Training loss: 2.8797848224639893
Validation loss: 2.456680759306877

Epoch: 6| Step: 5
Training loss: 2.8769772052764893
Validation loss: 2.437503601915093

Epoch: 6| Step: 6
Training loss: 3.114530324935913
Validation loss: 2.4278527203426568

Epoch: 6| Step: 7
Training loss: 2.846099376678467
Validation loss: 2.426865775098083

Epoch: 6| Step: 8
Training loss: 2.1080875396728516
Validation loss: 2.412337157034105

Epoch: 6| Step: 9
Training loss: 2.41919207572937
Validation loss: 2.407498444280317

Epoch: 6| Step: 10
Training loss: 2.1744775772094727
Validation loss: 2.4138270629349576

Epoch: 6| Step: 11
Training loss: 2.3618109226226807
Validation loss: 2.416306052156674

Epoch: 6| Step: 12
Training loss: 2.655755043029785
Validation loss: 2.4276507041787587

Epoch: 6| Step: 13
Training loss: 3.00213623046875
Validation loss: 2.4528763037855907

Epoch: 38| Step: 0
Training loss: 2.61155366897583
Validation loss: 2.4578560834289878

Epoch: 6| Step: 1
Training loss: 2.5508360862731934
Validation loss: 2.4578651458986345

Epoch: 6| Step: 2
Training loss: 2.3716301918029785
Validation loss: 2.4555054787666566

Epoch: 6| Step: 3
Training loss: 3.141388416290283
Validation loss: 2.4516453460980485

Epoch: 6| Step: 4
Training loss: 2.8490052223205566
Validation loss: 2.4252897231809554

Epoch: 6| Step: 5
Training loss: 3.2212653160095215
Validation loss: 2.4108083119956394

Epoch: 6| Step: 6
Training loss: 2.499650239944458
Validation loss: 2.3939544590570594

Epoch: 6| Step: 7
Training loss: 1.6017621755599976
Validation loss: 2.3821325507215274

Epoch: 6| Step: 8
Training loss: 2.7788643836975098
Validation loss: 2.3701655210987216

Epoch: 6| Step: 9
Training loss: 2.7603187561035156
Validation loss: 2.36777497876075

Epoch: 6| Step: 10
Training loss: 2.9412612915039062
Validation loss: 2.36742522639613

Epoch: 6| Step: 11
Training loss: 2.34112548828125
Validation loss: 2.3722333549171366

Epoch: 6| Step: 12
Training loss: 2.393728017807007
Validation loss: 2.368059112179664

Epoch: 6| Step: 13
Training loss: 2.625460624694824
Validation loss: 2.3747793846232916

Epoch: 39| Step: 0
Training loss: 2.6630799770355225
Validation loss: 2.384994129980764

Epoch: 6| Step: 1
Training loss: 3.148397207260132
Validation loss: 2.3905881681749896

Epoch: 6| Step: 2
Training loss: 1.9306859970092773
Validation loss: 2.3830356726082425

Epoch: 6| Step: 3
Training loss: 2.0782032012939453
Validation loss: 2.38997394551513

Epoch: 6| Step: 4
Training loss: 2.2821035385131836
Validation loss: 2.4014154121439946

Epoch: 6| Step: 5
Training loss: 2.4132256507873535
Validation loss: 2.3957387119211178

Epoch: 6| Step: 6
Training loss: 3.0806493759155273
Validation loss: 2.3875045494366716

Epoch: 6| Step: 7
Training loss: 2.489607572555542
Validation loss: 2.3796484598549466

Epoch: 6| Step: 8
Training loss: 2.450866460800171
Validation loss: 2.3758382412695114

Epoch: 6| Step: 9
Training loss: 2.4706664085388184
Validation loss: 2.366951137460688

Epoch: 6| Step: 10
Training loss: 2.5936388969421387
Validation loss: 2.3618065695608816

Epoch: 6| Step: 11
Training loss: 3.1606836318969727
Validation loss: 2.3576705558325655

Epoch: 6| Step: 12
Training loss: 2.967081069946289
Validation loss: 2.3480683090866252

Epoch: 6| Step: 13
Training loss: 2.9982595443725586
Validation loss: 2.3510138347584713

Epoch: 40| Step: 0
Training loss: 3.1971147060394287
Validation loss: 2.3505642132092546

Epoch: 6| Step: 1
Training loss: 2.9998974800109863
Validation loss: 2.351912666392583

Epoch: 6| Step: 2
Training loss: 2.9488844871520996
Validation loss: 2.3448563288616877

Epoch: 6| Step: 3
Training loss: 2.466033458709717
Validation loss: 2.3458010688904793

Epoch: 6| Step: 4
Training loss: 2.2629141807556152
Validation loss: 2.3442640560929493

Epoch: 6| Step: 5
Training loss: 2.5221166610717773
Validation loss: 2.341587389669111

Epoch: 6| Step: 6
Training loss: 2.1921918392181396
Validation loss: 2.340459512126061

Epoch: 6| Step: 7
Training loss: 2.695756196975708
Validation loss: 2.3395241050310034

Epoch: 6| Step: 8
Training loss: 3.071091651916504
Validation loss: 2.3450114534747217

Epoch: 6| Step: 9
Training loss: 1.4882011413574219
Validation loss: 2.3423058140662407

Epoch: 6| Step: 10
Training loss: 3.02693772315979
Validation loss: 2.3439594058580298

Epoch: 6| Step: 11
Training loss: 2.5708532333374023
Validation loss: 2.342512199955602

Epoch: 6| Step: 12
Training loss: 2.5799412727355957
Validation loss: 2.3541776877577587

Epoch: 6| Step: 13
Training loss: 2.495819091796875
Validation loss: 2.3824442099499445

Epoch: 41| Step: 0
Training loss: 1.8268097639083862
Validation loss: 2.42422087987264

Epoch: 6| Step: 1
Training loss: 3.034585475921631
Validation loss: 2.5198578770442674

Epoch: 6| Step: 2
Training loss: 2.144040107727051
Validation loss: 2.5538468873629006

Epoch: 6| Step: 3
Training loss: 3.846313714981079
Validation loss: 2.6435744557329404

Epoch: 6| Step: 4
Training loss: 2.900979995727539
Validation loss: 2.6518615830329155

Epoch: 6| Step: 5
Training loss: 2.8380982875823975
Validation loss: 2.623637563438826

Epoch: 6| Step: 6
Training loss: 2.1938064098358154
Validation loss: 2.556532024055399

Epoch: 6| Step: 7
Training loss: 2.9200944900512695
Validation loss: 2.458834361004573

Epoch: 6| Step: 8
Training loss: 2.147055149078369
Validation loss: 2.3784653832835536

Epoch: 6| Step: 9
Training loss: 3.084787130355835
Validation loss: 2.361094146646479

Epoch: 6| Step: 10
Training loss: 2.4876370429992676
Validation loss: 2.350694546135523

Epoch: 6| Step: 11
Training loss: 2.906647205352783
Validation loss: 2.388350212445823

Epoch: 6| Step: 12
Training loss: 2.516622543334961
Validation loss: 2.51526710038544

Epoch: 6| Step: 13
Training loss: 2.3026177883148193
Validation loss: 2.5402521805096696

Epoch: 42| Step: 0
Training loss: 3.0051040649414062
Validation loss: 2.67692893807606

Epoch: 6| Step: 1
Training loss: 3.121870517730713
Validation loss: 2.8792169145358506

Epoch: 6| Step: 2
Training loss: 2.9281954765319824
Validation loss: 2.7899579796739804

Epoch: 6| Step: 3
Training loss: 2.9057352542877197
Validation loss: 2.6144583661069154

Epoch: 6| Step: 4
Training loss: 3.19022274017334
Validation loss: 2.4892223599136516

Epoch: 6| Step: 5
Training loss: 2.4122352600097656
Validation loss: 2.3869819512931247

Epoch: 6| Step: 6
Training loss: 2.0962259769439697
Validation loss: 2.3399505205051874

Epoch: 6| Step: 7
Training loss: 2.8119773864746094
Validation loss: 2.3388763371334282

Epoch: 6| Step: 8
Training loss: 2.6696770191192627
Validation loss: 2.351142144972278

Epoch: 6| Step: 9
Training loss: 2.721250295639038
Validation loss: 2.3922908331758235

Epoch: 6| Step: 10
Training loss: 2.699528217315674
Validation loss: 2.408066629081644

Epoch: 6| Step: 11
Training loss: 2.503864288330078
Validation loss: 2.434775739587763

Epoch: 6| Step: 12
Training loss: 2.2982804775238037
Validation loss: 2.513989322928972

Epoch: 6| Step: 13
Training loss: 2.5860049724578857
Validation loss: 2.515873432159424

Epoch: 43| Step: 0
Training loss: 2.858368158340454
Validation loss: 2.4108473203515493

Epoch: 6| Step: 1
Training loss: 2.7869510650634766
Validation loss: 2.3925106525421143

Epoch: 6| Step: 2
Training loss: 2.8388938903808594
Validation loss: 2.3910160987607894

Epoch: 6| Step: 3
Training loss: 1.9896807670593262
Validation loss: 2.3844417372057514

Epoch: 6| Step: 4
Training loss: 2.7045936584472656
Validation loss: 2.363693780796502

Epoch: 6| Step: 5
Training loss: 2.5815014839172363
Validation loss: 2.352117118015084

Epoch: 6| Step: 6
Training loss: 3.3218963146209717
Validation loss: 2.3384291920610654

Epoch: 6| Step: 7
Training loss: 3.1235227584838867
Validation loss: 2.3370297724200833

Epoch: 6| Step: 8
Training loss: 2.133760452270508
Validation loss: 2.3329619105144213

Epoch: 6| Step: 9
Training loss: 2.291116237640381
Validation loss: 2.3301678575495237

Epoch: 6| Step: 10
Training loss: 2.3673295974731445
Validation loss: 2.3242943363804973

Epoch: 6| Step: 11
Training loss: 2.287930965423584
Validation loss: 2.3232650679926716

Epoch: 6| Step: 12
Training loss: 2.282273292541504
Validation loss: 2.3200629885478685

Epoch: 6| Step: 13
Training loss: 3.3397154808044434
Validation loss: 2.320397869233162

Epoch: 44| Step: 0
Training loss: 2.6759486198425293
Validation loss: 2.319484720947922

Epoch: 6| Step: 1
Training loss: 2.170464038848877
Validation loss: 2.314048973462915

Epoch: 6| Step: 2
Training loss: 1.9365891218185425
Validation loss: 2.31301470469403

Epoch: 6| Step: 3
Training loss: 3.0283498764038086
Validation loss: 2.312873666004468

Epoch: 6| Step: 4
Training loss: 2.623128890991211
Validation loss: 2.3148995073892737

Epoch: 6| Step: 5
Training loss: 2.4068007469177246
Validation loss: 2.3167672259833223

Epoch: 6| Step: 6
Training loss: 2.761679172515869
Validation loss: 2.320233973123694

Epoch: 6| Step: 7
Training loss: 3.8611388206481934
Validation loss: 2.327359366160567

Epoch: 6| Step: 8
Training loss: 2.7121496200561523
Validation loss: 2.3243818308717463

Epoch: 6| Step: 9
Training loss: 2.8425793647766113
Validation loss: 2.3179235548101444

Epoch: 6| Step: 10
Training loss: 2.3592422008514404
Validation loss: 2.3149106810169835

Epoch: 6| Step: 11
Training loss: 1.9155099391937256
Validation loss: 2.3157417158926688

Epoch: 6| Step: 12
Training loss: 3.186781644821167
Validation loss: 2.315079189115955

Epoch: 6| Step: 13
Training loss: 1.6049870252609253
Validation loss: 2.3154800322748

Epoch: 45| Step: 0
Training loss: 2.348374843597412
Validation loss: 2.320780961744247

Epoch: 6| Step: 1
Training loss: 2.8809585571289062
Validation loss: 2.3271528725982993

Epoch: 6| Step: 2
Training loss: 2.9945030212402344
Validation loss: 2.3409206098125828

Epoch: 6| Step: 3
Training loss: 2.328878164291382
Validation loss: 2.3406677297366563

Epoch: 6| Step: 4
Training loss: 2.6826870441436768
Validation loss: 2.362256496183334

Epoch: 6| Step: 5
Training loss: 2.3477354049682617
Validation loss: 2.3616298039754233

Epoch: 6| Step: 6
Training loss: 1.9919545650482178
Validation loss: 2.3493799855632167

Epoch: 6| Step: 7
Training loss: 2.542024612426758
Validation loss: 2.3515455030625865

Epoch: 6| Step: 8
Training loss: 2.941009521484375
Validation loss: 2.353342251111102

Epoch: 6| Step: 9
Training loss: 2.4726858139038086
Validation loss: 2.3428180551016204

Epoch: 6| Step: 10
Training loss: 2.26071834564209
Validation loss: 2.334492516774003

Epoch: 6| Step: 11
Training loss: 2.7800278663635254
Validation loss: 2.3239004201786493

Epoch: 6| Step: 12
Training loss: 2.939167022705078
Validation loss: 2.3210655258547876

Epoch: 6| Step: 13
Training loss: 2.7712159156799316
Validation loss: 2.320798045845442

Epoch: 46| Step: 0
Training loss: 2.175896406173706
Validation loss: 2.3262394679489957

Epoch: 6| Step: 1
Training loss: 2.534437656402588
Validation loss: 2.3260386477234545

Epoch: 6| Step: 2
Training loss: 2.0530498027801514
Validation loss: 2.323596926145656

Epoch: 6| Step: 3
Training loss: 2.2337303161621094
Validation loss: 2.3051331991790445

Epoch: 6| Step: 4
Training loss: 2.781268358230591
Validation loss: 2.302832334272323

Epoch: 6| Step: 5
Training loss: 2.579576015472412
Validation loss: 2.300657400520899

Epoch: 6| Step: 6
Training loss: 2.814192295074463
Validation loss: 2.291817457445206

Epoch: 6| Step: 7
Training loss: 3.144038200378418
Validation loss: 2.289968475218742

Epoch: 6| Step: 8
Training loss: 2.7603254318237305
Validation loss: 2.2944498318497852

Epoch: 6| Step: 9
Training loss: 2.692262649536133
Validation loss: 2.2923585830196256

Epoch: 6| Step: 10
Training loss: 2.7372372150421143
Validation loss: 2.294768069380073

Epoch: 6| Step: 11
Training loss: 2.3580381870269775
Validation loss: 2.295969081181352

Epoch: 6| Step: 12
Training loss: 2.6457557678222656
Validation loss: 2.313873262815578

Epoch: 6| Step: 13
Training loss: 2.554734230041504
Validation loss: 2.3304600100363455

Epoch: 47| Step: 0
Training loss: 2.692709445953369
Validation loss: 2.342710884668494

Epoch: 6| Step: 1
Training loss: 2.92614483833313
Validation loss: 2.3721406613626788

Epoch: 6| Step: 2
Training loss: 1.997434139251709
Validation loss: 2.394134844503095

Epoch: 6| Step: 3
Training loss: 2.588252544403076
Validation loss: 2.419238036678683

Epoch: 6| Step: 4
Training loss: 2.296966314315796
Validation loss: 2.441949446996053

Epoch: 6| Step: 5
Training loss: 2.234588861465454
Validation loss: 2.4474171887161913

Epoch: 6| Step: 6
Training loss: 3.0504801273345947
Validation loss: 2.4296437412179928

Epoch: 6| Step: 7
Training loss: 3.251359462738037
Validation loss: 2.3937877275610484

Epoch: 6| Step: 8
Training loss: 2.2620396614074707
Validation loss: 2.3487740742262972

Epoch: 6| Step: 9
Training loss: 2.9583373069763184
Validation loss: 2.31186496057818

Epoch: 6| Step: 10
Training loss: 2.5022809505462646
Validation loss: 2.2926325541670605

Epoch: 6| Step: 11
Training loss: 2.5462818145751953
Validation loss: 2.292195632893552

Epoch: 6| Step: 12
Training loss: 2.5507733821868896
Validation loss: 2.296793286518384

Epoch: 6| Step: 13
Training loss: 2.3749477863311768
Validation loss: 2.3168886297492572

Epoch: 48| Step: 0
Training loss: 2.616175413131714
Validation loss: 2.323408447286134

Epoch: 6| Step: 1
Training loss: 2.6121153831481934
Validation loss: 2.329317528714416

Epoch: 6| Step: 2
Training loss: 2.6904754638671875
Validation loss: 2.327315089523151

Epoch: 6| Step: 3
Training loss: 3.1451363563537598
Validation loss: 2.320546252753145

Epoch: 6| Step: 4
Training loss: 2.2317519187927246
Validation loss: 2.3109658200253724

Epoch: 6| Step: 5
Training loss: 2.764268398284912
Validation loss: 2.3035724534783313

Epoch: 6| Step: 6
Training loss: 2.5453248023986816
Validation loss: 2.3007601538012104

Epoch: 6| Step: 7
Training loss: 2.863020896911621
Validation loss: 2.294362086121754

Epoch: 6| Step: 8
Training loss: 2.2489867210388184
Validation loss: 2.2922410375328472

Epoch: 6| Step: 9
Training loss: 2.8174726963043213
Validation loss: 2.2837910729069866

Epoch: 6| Step: 10
Training loss: 2.597811460494995
Validation loss: 2.28304519191865

Epoch: 6| Step: 11
Training loss: 2.424689769744873
Validation loss: 2.279373791909987

Epoch: 6| Step: 12
Training loss: 2.5066537857055664
Validation loss: 2.27828287821944

Epoch: 6| Step: 13
Training loss: 2.3515846729278564
Validation loss: 2.2810067489583004

Epoch: 49| Step: 0
Training loss: 2.3143744468688965
Validation loss: 2.2897236065198014

Epoch: 6| Step: 1
Training loss: 2.7522530555725098
Validation loss: 2.3131819181544806

Epoch: 6| Step: 2
Training loss: 1.7990187406539917
Validation loss: 2.343379941037906

Epoch: 6| Step: 3
Training loss: 2.3785879611968994
Validation loss: 2.404821716329103

Epoch: 6| Step: 4
Training loss: 2.9816412925720215
Validation loss: 2.411365629524313

Epoch: 6| Step: 5
Training loss: 2.3884472846984863
Validation loss: 2.3895738406847884

Epoch: 6| Step: 6
Training loss: 2.502115249633789
Validation loss: 2.3709461381358485

Epoch: 6| Step: 7
Training loss: 2.9943857192993164
Validation loss: 2.351719879334973

Epoch: 6| Step: 8
Training loss: 2.745661735534668
Validation loss: 2.325337358700332

Epoch: 6| Step: 9
Training loss: 2.020364761352539
Validation loss: 2.313464492879888

Epoch: 6| Step: 10
Training loss: 2.868309497833252
Validation loss: 2.3233196222653953

Epoch: 6| Step: 11
Training loss: 2.8124396800994873
Validation loss: 2.3072834399438675

Epoch: 6| Step: 12
Training loss: 2.673201560974121
Validation loss: 2.299341001818257

Epoch: 6| Step: 13
Training loss: 2.7563695907592773
Validation loss: 2.295340318833628

Epoch: 50| Step: 0
Training loss: 3.0010085105895996
Validation loss: 2.2941420232096026

Epoch: 6| Step: 1
Training loss: 2.122528076171875
Validation loss: 2.284624504786666

Epoch: 6| Step: 2
Training loss: 2.238852024078369
Validation loss: 2.280294103007163

Epoch: 6| Step: 3
Training loss: 2.714413642883301
Validation loss: 2.2749610613751154

Epoch: 6| Step: 4
Training loss: 2.2951769828796387
Validation loss: 2.2750769097317933

Epoch: 6| Step: 5
Training loss: 3.330319881439209
Validation loss: 2.271034389413813

Epoch: 6| Step: 6
Training loss: 2.491929054260254
Validation loss: 2.2680385856218237

Epoch: 6| Step: 7
Training loss: 2.6323745250701904
Validation loss: 2.266753840190108

Epoch: 6| Step: 8
Training loss: 3.2634992599487305
Validation loss: 2.2712374810249574

Epoch: 6| Step: 9
Training loss: 2.4830713272094727
Validation loss: 2.270122766494751

Epoch: 6| Step: 10
Training loss: 2.4717297554016113
Validation loss: 2.2758141243329613

Epoch: 6| Step: 11
Training loss: 2.783970594406128
Validation loss: 2.2754244009653726

Epoch: 6| Step: 12
Training loss: 1.8607752323150635
Validation loss: 2.286296747064078

Epoch: 6| Step: 13
Training loss: 1.973427414894104
Validation loss: 2.2891628639672392

Epoch: 51| Step: 0
Training loss: 2.569025993347168
Validation loss: 2.2925058975014636

Epoch: 6| Step: 1
Training loss: 2.6274847984313965
Validation loss: 2.3186165440467095

Epoch: 6| Step: 2
Training loss: 2.8032054901123047
Validation loss: 2.3379558645268923

Epoch: 6| Step: 3
Training loss: 1.9352881908416748
Validation loss: 2.3707802141866376

Epoch: 6| Step: 4
Training loss: 2.240579605102539
Validation loss: 2.3376554532717635

Epoch: 6| Step: 5
Training loss: 2.3992550373077393
Validation loss: 2.3021691460763254

Epoch: 6| Step: 6
Training loss: 2.172031879425049
Validation loss: 2.274015509954063

Epoch: 6| Step: 7
Training loss: 2.6685657501220703
Validation loss: 2.258018814107423

Epoch: 6| Step: 8
Training loss: 2.396746873855591
Validation loss: 2.2500696054068943

Epoch: 6| Step: 9
Training loss: 3.488685131072998
Validation loss: 2.249927650215805

Epoch: 6| Step: 10
Training loss: 2.131101608276367
Validation loss: 2.252310845159715

Epoch: 6| Step: 11
Training loss: 3.3881633281707764
Validation loss: 2.2531062274850826

Epoch: 6| Step: 12
Training loss: 2.301154136657715
Validation loss: 2.257289286582701

Epoch: 6| Step: 13
Training loss: 2.685969591140747
Validation loss: 2.251871424336587

Epoch: 52| Step: 0
Training loss: 2.2195229530334473
Validation loss: 2.2533272517624723

Epoch: 6| Step: 1
Training loss: 2.822598457336426
Validation loss: 2.2558182080586753

Epoch: 6| Step: 2
Training loss: 2.507256269454956
Validation loss: 2.257777237123059

Epoch: 6| Step: 3
Training loss: 2.6404480934143066
Validation loss: 2.255163808022776

Epoch: 6| Step: 4
Training loss: 3.0197112560272217
Validation loss: 2.2519129809512886

Epoch: 6| Step: 5
Training loss: 2.373199939727783
Validation loss: 2.2528705776378675

Epoch: 6| Step: 6
Training loss: 2.50750470161438
Validation loss: 2.25533022931827

Epoch: 6| Step: 7
Training loss: 2.9497036933898926
Validation loss: 2.260439888123543

Epoch: 6| Step: 8
Training loss: 2.9048819541931152
Validation loss: 2.2602049586593465

Epoch: 6| Step: 9
Training loss: 2.315791130065918
Validation loss: 2.25221505472737

Epoch: 6| Step: 10
Training loss: 2.19075345993042
Validation loss: 2.257821444542177

Epoch: 6| Step: 11
Training loss: 3.127377986907959
Validation loss: 2.2564977369000836

Epoch: 6| Step: 12
Training loss: 2.407489776611328
Validation loss: 2.2632036798743793

Epoch: 6| Step: 13
Training loss: 1.6078826189041138
Validation loss: 2.3039751129765667

Epoch: 53| Step: 0
Training loss: 3.041027545928955
Validation loss: 2.3245038550387145

Epoch: 6| Step: 1
Training loss: 2.3126025199890137
Validation loss: 2.28759781775936

Epoch: 6| Step: 2
Training loss: 2.8325979709625244
Validation loss: 2.2850526737910446

Epoch: 6| Step: 3
Training loss: 2.4663147926330566
Validation loss: 2.28538836971406

Epoch: 6| Step: 4
Training loss: 2.179896354675293
Validation loss: 2.294222108779415

Epoch: 6| Step: 5
Training loss: 1.773053526878357
Validation loss: 2.290675167114504

Epoch: 6| Step: 6
Training loss: 2.0950613021850586
Validation loss: 2.2921175341452322

Epoch: 6| Step: 7
Training loss: 2.9990577697753906
Validation loss: 2.2918264430056334

Epoch: 6| Step: 8
Training loss: 2.6256346702575684
Validation loss: 2.2929274523130028

Epoch: 6| Step: 9
Training loss: 2.9332315921783447
Validation loss: 2.2899441270418066

Epoch: 6| Step: 10
Training loss: 2.4300920963287354
Validation loss: 2.2851393248445246

Epoch: 6| Step: 11
Training loss: 2.9494800567626953
Validation loss: 2.278001344332131

Epoch: 6| Step: 12
Training loss: 2.585848331451416
Validation loss: 2.272157751103883

Epoch: 6| Step: 13
Training loss: 2.252657413482666
Validation loss: 2.2628057054294053

Epoch: 54| Step: 0
Training loss: 2.8340277671813965
Validation loss: 2.2638101885395665

Epoch: 6| Step: 1
Training loss: 2.0939528942108154
Validation loss: 2.2718688031678558

Epoch: 6| Step: 2
Training loss: 2.199202537536621
Validation loss: 2.2783033873445246

Epoch: 6| Step: 3
Training loss: 3.0016984939575195
Validation loss: 2.296098424542335

Epoch: 6| Step: 4
Training loss: 2.931483745574951
Validation loss: 2.303838647821898

Epoch: 6| Step: 5
Training loss: 2.6541738510131836
Validation loss: 2.331619652368689

Epoch: 6| Step: 6
Training loss: 2.4920196533203125
Validation loss: 2.344607740320185

Epoch: 6| Step: 7
Training loss: 1.9495395421981812
Validation loss: 2.3795494315444783

Epoch: 6| Step: 8
Training loss: 2.091395854949951
Validation loss: 2.414749489035658

Epoch: 6| Step: 9
Training loss: 2.5732340812683105
Validation loss: 2.3795021657020814

Epoch: 6| Step: 10
Training loss: 2.140658378601074
Validation loss: 2.300399277799873

Epoch: 6| Step: 11
Training loss: 2.7030832767486572
Validation loss: 2.2687015507810857

Epoch: 6| Step: 12
Training loss: 3.262397527694702
Validation loss: 2.251319641708046

Epoch: 6| Step: 13
Training loss: 2.7478885650634766
Validation loss: 2.2493969471223894

Epoch: 55| Step: 0
Training loss: 1.9175167083740234
Validation loss: 2.2403113508737214

Epoch: 6| Step: 1
Training loss: 2.00095534324646
Validation loss: 2.242568285234513

Epoch: 6| Step: 2
Training loss: 2.345841407775879
Validation loss: 2.2506611757380988

Epoch: 6| Step: 3
Training loss: 3.4014267921447754
Validation loss: 2.2772702709321053

Epoch: 6| Step: 4
Training loss: 2.386867046356201
Validation loss: 2.2849408503501647

Epoch: 6| Step: 5
Training loss: 2.539933681488037
Validation loss: 2.2637591336363103

Epoch: 6| Step: 6
Training loss: 2.1041018962860107
Validation loss: 2.260086019833883

Epoch: 6| Step: 7
Training loss: 2.5949482917785645
Validation loss: 2.276553056573355

Epoch: 6| Step: 8
Training loss: 2.5193161964416504
Validation loss: 2.288777946144022

Epoch: 6| Step: 9
Training loss: 2.03031587600708
Validation loss: 2.2935144106547036

Epoch: 6| Step: 10
Training loss: 2.510707378387451
Validation loss: 2.2593709550878054

Epoch: 6| Step: 11
Training loss: 3.027625560760498
Validation loss: 2.2395235543609946

Epoch: 6| Step: 12
Training loss: 2.6250243186950684
Validation loss: 2.2462047582031577

Epoch: 6| Step: 13
Training loss: 4.417112350463867
Validation loss: 2.2525146622811594

Epoch: 56| Step: 0
Training loss: 2.0835747718811035
Validation loss: 2.2540940418038318

Epoch: 6| Step: 1
Training loss: 2.4229326248168945
Validation loss: 2.24287320721534

Epoch: 6| Step: 2
Training loss: 2.409554958343506
Validation loss: 2.2376173773119525

Epoch: 6| Step: 3
Training loss: 1.9134137630462646
Validation loss: 2.235417345518707

Epoch: 6| Step: 4
Training loss: 1.861234426498413
Validation loss: 2.2445315302059217

Epoch: 6| Step: 5
Training loss: 2.9547677040100098
Validation loss: 2.2383045432388142

Epoch: 6| Step: 6
Training loss: 2.819366931915283
Validation loss: 2.24152615762526

Epoch: 6| Step: 7
Training loss: 2.271251916885376
Validation loss: 2.222251307579779

Epoch: 6| Step: 8
Training loss: 2.3916375637054443
Validation loss: 2.2264378378468175

Epoch: 6| Step: 9
Training loss: 2.938915967941284
Validation loss: 2.228329748235723

Epoch: 6| Step: 10
Training loss: 2.0228378772735596
Validation loss: 2.241332036192699

Epoch: 6| Step: 11
Training loss: 3.39534854888916
Validation loss: 2.252539760322981

Epoch: 6| Step: 12
Training loss: 2.904827356338501
Validation loss: 2.2498424155737764

Epoch: 6| Step: 13
Training loss: 3.1096768379211426
Validation loss: 2.2360952259391866

Epoch: 57| Step: 0
Training loss: 2.7976577281951904
Validation loss: 2.2242207463069628

Epoch: 6| Step: 1
Training loss: 1.9545190334320068
Validation loss: 2.2181683227580082

Epoch: 6| Step: 2
Training loss: 3.4151558876037598
Validation loss: 2.217702149063028

Epoch: 6| Step: 3
Training loss: 2.674560070037842
Validation loss: 2.2161564762874315

Epoch: 6| Step: 4
Training loss: 2.757864475250244
Validation loss: 2.215624624683011

Epoch: 6| Step: 5
Training loss: 2.8320741653442383
Validation loss: 2.216773501006506

Epoch: 6| Step: 6
Training loss: 2.094202995300293
Validation loss: 2.222630867394068

Epoch: 6| Step: 7
Training loss: 2.364058017730713
Validation loss: 2.2279787640417776

Epoch: 6| Step: 8
Training loss: 2.0907156467437744
Validation loss: 2.2423030445652623

Epoch: 6| Step: 9
Training loss: 2.482691764831543
Validation loss: 2.243370181770735

Epoch: 6| Step: 10
Training loss: 3.0197534561157227
Validation loss: 2.2449316260635213

Epoch: 6| Step: 11
Training loss: 2.424255132675171
Validation loss: 2.2475616214095906

Epoch: 6| Step: 12
Training loss: 1.8507719039916992
Validation loss: 2.2448979552074144

Epoch: 6| Step: 13
Training loss: 2.1780128479003906
Validation loss: 2.2470888604399977

Epoch: 58| Step: 0
Training loss: 2.8812551498413086
Validation loss: 2.2576228175111996

Epoch: 6| Step: 1
Training loss: 2.854477882385254
Validation loss: 2.262853008444591

Epoch: 6| Step: 2
Training loss: 2.535890579223633
Validation loss: 2.2609718922645814

Epoch: 6| Step: 3
Training loss: 3.1096596717834473
Validation loss: 2.260309301396852

Epoch: 6| Step: 4
Training loss: 2.721421718597412
Validation loss: 2.258813278649443

Epoch: 6| Step: 5
Training loss: 1.587172508239746
Validation loss: 2.252800387720908

Epoch: 6| Step: 6
Training loss: 2.788848876953125
Validation loss: 2.273227942887173

Epoch: 6| Step: 7
Training loss: 1.9898231029510498
Validation loss: 2.3023430737116004

Epoch: 6| Step: 8
Training loss: 2.8642587661743164
Validation loss: 2.3458112798711306

Epoch: 6| Step: 9
Training loss: 2.1104354858398438
Validation loss: 2.3209348827280025

Epoch: 6| Step: 10
Training loss: 1.9138963222503662
Validation loss: 2.3213976890810075

Epoch: 6| Step: 11
Training loss: 2.2575502395629883
Validation loss: 2.2738482375298776

Epoch: 6| Step: 12
Training loss: 2.5836124420166016
Validation loss: 2.2511110357058945

Epoch: 6| Step: 13
Training loss: 3.192582845687866
Validation loss: 2.2137107438938592

Epoch: 59| Step: 0
Training loss: 2.508456230163574
Validation loss: 2.1957625471135622

Epoch: 6| Step: 1
Training loss: 2.283480644226074
Validation loss: 2.196705866885442

Epoch: 6| Step: 2
Training loss: 2.547037124633789
Validation loss: 2.200463548783333

Epoch: 6| Step: 3
Training loss: 2.12678599357605
Validation loss: 2.2004965056655226

Epoch: 6| Step: 4
Training loss: 2.1056113243103027
Validation loss: 2.2073819893662647

Epoch: 6| Step: 5
Training loss: 2.2795515060424805
Validation loss: 2.1997943591046076

Epoch: 6| Step: 6
Training loss: 2.6626200675964355
Validation loss: 2.194588327920565

Epoch: 6| Step: 7
Training loss: 2.5666682720184326
Validation loss: 2.1981064119646625

Epoch: 6| Step: 8
Training loss: 2.5128607749938965
Validation loss: 2.1925848222547963

Epoch: 6| Step: 9
Training loss: 2.4005913734436035
Validation loss: 2.1891391687495734

Epoch: 6| Step: 10
Training loss: 2.4432506561279297
Validation loss: 2.195282874568816

Epoch: 6| Step: 11
Training loss: 3.434197425842285
Validation loss: 2.1938919841602282

Epoch: 6| Step: 12
Training loss: 2.7320170402526855
Validation loss: 2.1937776714242916

Epoch: 6| Step: 13
Training loss: 2.6151864528656006
Validation loss: 2.1934562780523814

Epoch: 60| Step: 0
Training loss: 2.364893913269043
Validation loss: 2.1978406726673083

Epoch: 6| Step: 1
Training loss: 2.461333751678467
Validation loss: 2.220353208562379

Epoch: 6| Step: 2
Training loss: 2.7433948516845703
Validation loss: 2.229218189434339

Epoch: 6| Step: 3
Training loss: 2.196071147918701
Validation loss: 2.2488235888942594

Epoch: 6| Step: 4
Training loss: 2.5979127883911133
Validation loss: 2.280452787235219

Epoch: 6| Step: 5
Training loss: 2.6758720874786377
Validation loss: 2.272301848216723

Epoch: 6| Step: 6
Training loss: 2.5992276668548584
Validation loss: 2.2412959580780356

Epoch: 6| Step: 7
Training loss: 2.3424854278564453
Validation loss: 2.2176568943967103

Epoch: 6| Step: 8
Training loss: 3.0291242599487305
Validation loss: 2.2161278699034

Epoch: 6| Step: 9
Training loss: 2.042367935180664
Validation loss: 2.2080273858962522

Epoch: 6| Step: 10
Training loss: 3.6507680416107178
Validation loss: 2.1960672563122166

Epoch: 6| Step: 11
Training loss: 2.3855695724487305
Validation loss: 2.1843437558861187

Epoch: 6| Step: 12
Training loss: 1.2949318885803223
Validation loss: 2.179061870421133

Epoch: 6| Step: 13
Training loss: 2.6231303215026855
Validation loss: 2.179960948164745

Epoch: 61| Step: 0
Training loss: 2.6693623065948486
Validation loss: 2.174824527514878

Epoch: 6| Step: 1
Training loss: 3.0916552543640137
Validation loss: 2.1766650958727767

Epoch: 6| Step: 2
Training loss: 2.2052395343780518
Validation loss: 2.180426191258174

Epoch: 6| Step: 3
Training loss: 3.1417958736419678
Validation loss: 2.1796394714745144

Epoch: 6| Step: 4
Training loss: 1.9763514995574951
Validation loss: 2.178530749454293

Epoch: 6| Step: 5
Training loss: 2.852084159851074
Validation loss: 2.1717489252808275

Epoch: 6| Step: 6
Training loss: 2.473748207092285
Validation loss: 2.172075645897978

Epoch: 6| Step: 7
Training loss: 2.438762664794922
Validation loss: 2.174595304714736

Epoch: 6| Step: 8
Training loss: 2.476142168045044
Validation loss: 2.1863686884603193

Epoch: 6| Step: 9
Training loss: 2.842592239379883
Validation loss: 2.1976689766812068

Epoch: 6| Step: 10
Training loss: 1.9127377271652222
Validation loss: 2.2041098917684248

Epoch: 6| Step: 11
Training loss: 2.346008777618408
Validation loss: 2.214293167155276

Epoch: 6| Step: 12
Training loss: 1.6653296947479248
Validation loss: 2.2300953403595956

Epoch: 6| Step: 13
Training loss: 3.0115184783935547
Validation loss: 2.2491563571396695

Epoch: 62| Step: 0
Training loss: 2.296241283416748
Validation loss: 2.2264275961024786

Epoch: 6| Step: 1
Training loss: 2.95221209526062
Validation loss: 2.2307245859535794

Epoch: 6| Step: 2
Training loss: 2.966826915740967
Validation loss: 2.2339436572085143

Epoch: 6| Step: 3
Training loss: 2.570070743560791
Validation loss: 2.2300972118172595

Epoch: 6| Step: 4
Training loss: 2.3835246562957764
Validation loss: 2.2221150962255334

Epoch: 6| Step: 5
Training loss: 2.07420015335083
Validation loss: 2.2204819520314536

Epoch: 6| Step: 6
Training loss: 2.480461597442627
Validation loss: 2.2265459260632916

Epoch: 6| Step: 7
Training loss: 2.2849738597869873
Validation loss: 2.2269393103097075

Epoch: 6| Step: 8
Training loss: 1.65687894821167
Validation loss: 2.2141030757657942

Epoch: 6| Step: 9
Training loss: 2.745379686355591
Validation loss: 2.1987618041294876

Epoch: 6| Step: 10
Training loss: 2.1135036945343018
Validation loss: 2.1928424425022577

Epoch: 6| Step: 11
Training loss: 2.5901026725769043
Validation loss: 2.175556400770782

Epoch: 6| Step: 12
Training loss: 2.5970005989074707
Validation loss: 2.1689597880968483

Epoch: 6| Step: 13
Training loss: 3.264735460281372
Validation loss: 2.155795640842889

Epoch: 63| Step: 0
Training loss: 3.173372507095337
Validation loss: 2.152454799221408

Epoch: 6| Step: 1
Training loss: 3.130131721496582
Validation loss: 2.1562498730997883

Epoch: 6| Step: 2
Training loss: 2.369596481323242
Validation loss: 2.148271245341147

Epoch: 6| Step: 3
Training loss: 2.3601629734039307
Validation loss: 2.1518193944807975

Epoch: 6| Step: 4
Training loss: 2.497866630554199
Validation loss: 2.153710945960014

Epoch: 6| Step: 5
Training loss: 2.3385510444641113
Validation loss: 2.1489280757083686

Epoch: 6| Step: 6
Training loss: 1.3497169017791748
Validation loss: 2.180264631907145

Epoch: 6| Step: 7
Training loss: 2.6445648670196533
Validation loss: 2.2008537835972284

Epoch: 6| Step: 8
Training loss: 3.1209025382995605
Validation loss: 2.206227881934053

Epoch: 6| Step: 9
Training loss: 2.334228038787842
Validation loss: 2.2036574322690248

Epoch: 6| Step: 10
Training loss: 2.326146125793457
Validation loss: 2.1822849371099986

Epoch: 6| Step: 11
Training loss: 2.569359064102173
Validation loss: 2.1882049319564656

Epoch: 6| Step: 12
Training loss: 2.2030909061431885
Validation loss: 2.19759028445008

Epoch: 6| Step: 13
Training loss: 2.127007484436035
Validation loss: 2.192428683721891

Epoch: 64| Step: 0
Training loss: 2.863772392272949
Validation loss: 2.1796452050567954

Epoch: 6| Step: 1
Training loss: 2.4239583015441895
Validation loss: 2.1687295308677097

Epoch: 6| Step: 2
Training loss: 2.1042752265930176
Validation loss: 2.1646197329285326

Epoch: 6| Step: 3
Training loss: 2.2266948223114014
Validation loss: 2.156249310380669

Epoch: 6| Step: 4
Training loss: 2.3647661209106445
Validation loss: 2.1628462306914793

Epoch: 6| Step: 5
Training loss: 2.9546737670898438
Validation loss: 2.1704097922130297

Epoch: 6| Step: 6
Training loss: 2.207516670227051
Validation loss: 2.178629513709776

Epoch: 6| Step: 7
Training loss: 3.0518736839294434
Validation loss: 2.184727458543675

Epoch: 6| Step: 8
Training loss: 2.7611100673675537
Validation loss: 2.2004994935886835

Epoch: 6| Step: 9
Training loss: 1.836369514465332
Validation loss: 2.2228071048695552

Epoch: 6| Step: 10
Training loss: 2.004117965698242
Validation loss: 2.2262192849190003

Epoch: 6| Step: 11
Training loss: 3.2479519844055176
Validation loss: 2.2189526173376266

Epoch: 6| Step: 12
Training loss: 1.757239818572998
Validation loss: 2.223833309706821

Epoch: 6| Step: 13
Training loss: 2.604224681854248
Validation loss: 2.227952226515739

Epoch: 65| Step: 0
Training loss: 2.6457109451293945
Validation loss: 2.197883311138358

Epoch: 6| Step: 1
Training loss: 2.4165003299713135
Validation loss: 2.1805004330091577

Epoch: 6| Step: 2
Training loss: 2.3752574920654297
Validation loss: 2.1607623433554046

Epoch: 6| Step: 3
Training loss: 2.654500961303711
Validation loss: 2.1510247876567226

Epoch: 6| Step: 4
Training loss: 2.456815242767334
Validation loss: 2.1442984663030153

Epoch: 6| Step: 5
Training loss: 1.7371513843536377
Validation loss: 2.141982527189357

Epoch: 6| Step: 6
Training loss: 2.6290106773376465
Validation loss: 2.1417482386353197

Epoch: 6| Step: 7
Training loss: 2.476936101913452
Validation loss: 2.1403264717389177

Epoch: 6| Step: 8
Training loss: 2.6522936820983887
Validation loss: 2.1442437171936035

Epoch: 6| Step: 9
Training loss: 2.1572072505950928
Validation loss: 2.142954026499102

Epoch: 6| Step: 10
Training loss: 2.6498889923095703
Validation loss: 2.1523219308545514

Epoch: 6| Step: 11
Training loss: 2.6431121826171875
Validation loss: 2.158415820008965

Epoch: 6| Step: 12
Training loss: 2.3686325550079346
Validation loss: 2.1790940582111316

Epoch: 6| Step: 13
Training loss: 2.2900571823120117
Validation loss: 2.2165712771877164

Epoch: 66| Step: 0
Training loss: 2.66831374168396
Validation loss: 2.226549433123681

Epoch: 6| Step: 1
Training loss: 2.1686997413635254
Validation loss: 2.2343461180246003

Epoch: 6| Step: 2
Training loss: 2.5862159729003906
Validation loss: 2.1960928286275556

Epoch: 6| Step: 3
Training loss: 2.4455912113189697
Validation loss: 2.1730296714331514

Epoch: 6| Step: 4
Training loss: 2.1150927543640137
Validation loss: 2.176807040809303

Epoch: 6| Step: 5
Training loss: 1.8075557947158813
Validation loss: 2.16644190460123

Epoch: 6| Step: 6
Training loss: 2.79687237739563
Validation loss: 2.15580976393915

Epoch: 6| Step: 7
Training loss: 2.252638578414917
Validation loss: 2.147970063712007

Epoch: 6| Step: 8
Training loss: 1.8980515003204346
Validation loss: 2.138827341859059

Epoch: 6| Step: 9
Training loss: 2.2769436836242676
Validation loss: 2.1312121780969764

Epoch: 6| Step: 10
Training loss: 2.751920700073242
Validation loss: 2.1355965240027315

Epoch: 6| Step: 11
Training loss: 2.5188825130462646
Validation loss: 2.132964082943496

Epoch: 6| Step: 12
Training loss: 3.203073501586914
Validation loss: 2.1321753276291715

Epoch: 6| Step: 13
Training loss: 2.665109872817993
Validation loss: 2.122168210244948

Epoch: 67| Step: 0
Training loss: 2.4568445682525635
Validation loss: 2.1245664909321773

Epoch: 6| Step: 1
Training loss: 2.4741363525390625
Validation loss: 2.1273577008196103

Epoch: 6| Step: 2
Training loss: 2.3839807510375977
Validation loss: 2.1390184151229037

Epoch: 6| Step: 3
Training loss: 2.4303274154663086
Validation loss: 2.1441726056478356

Epoch: 6| Step: 4
Training loss: 1.7101051807403564
Validation loss: 2.17543061061572

Epoch: 6| Step: 5
Training loss: 2.432244300842285
Validation loss: 2.1852419107191023

Epoch: 6| Step: 6
Training loss: 2.108975887298584
Validation loss: 2.182537965877082

Epoch: 6| Step: 7
Training loss: 2.094080924987793
Validation loss: 2.191382638869747

Epoch: 6| Step: 8
Training loss: 2.6595675945281982
Validation loss: 2.160916038738784

Epoch: 6| Step: 9
Training loss: 2.368412971496582
Validation loss: 2.1453552784458285

Epoch: 6| Step: 10
Training loss: 2.6574108600616455
Validation loss: 2.150551135822009

Epoch: 6| Step: 11
Training loss: 3.1168174743652344
Validation loss: 2.1405870299185477

Epoch: 6| Step: 12
Training loss: 2.774826765060425
Validation loss: 2.1421209817291587

Epoch: 6| Step: 13
Training loss: 2.1233103275299072
Validation loss: 2.143908275071011

Epoch: 68| Step: 0
Training loss: 2.471219062805176
Validation loss: 2.1411416633154756

Epoch: 6| Step: 1
Training loss: 2.1823840141296387
Validation loss: 2.1450057901361936

Epoch: 6| Step: 2
Training loss: 1.9291751384735107
Validation loss: 2.153798077696113

Epoch: 6| Step: 3
Training loss: 2.4985857009887695
Validation loss: 2.1606419599184425

Epoch: 6| Step: 4
Training loss: 2.345015287399292
Validation loss: 2.1531095761124805

Epoch: 6| Step: 5
Training loss: 2.692643165588379
Validation loss: 2.1480751268325315

Epoch: 6| Step: 6
Training loss: 2.5605573654174805
Validation loss: 2.133893738510788

Epoch: 6| Step: 7
Training loss: 2.6508991718292236
Validation loss: 2.1268087407594085

Epoch: 6| Step: 8
Training loss: 2.6587698459625244
Validation loss: 2.11929347438197

Epoch: 6| Step: 9
Training loss: 2.151334047317505
Validation loss: 2.119923973596224

Epoch: 6| Step: 10
Training loss: 2.088015556335449
Validation loss: 2.117891574418673

Epoch: 6| Step: 11
Training loss: 2.36804461479187
Validation loss: 2.1145781868247577

Epoch: 6| Step: 12
Training loss: 2.241142511367798
Validation loss: 2.1206811986943728

Epoch: 6| Step: 13
Training loss: 3.5999739170074463
Validation loss: 2.150438888098604

Epoch: 69| Step: 0
Training loss: 2.4778542518615723
Validation loss: 2.160664607119817

Epoch: 6| Step: 1
Training loss: 2.6812875270843506
Validation loss: 2.177211259001045

Epoch: 6| Step: 2
Training loss: 2.4949426651000977
Validation loss: 2.1992254154656523

Epoch: 6| Step: 3
Training loss: 2.4751758575439453
Validation loss: 2.1975093477515766

Epoch: 6| Step: 4
Training loss: 3.1905295848846436
Validation loss: 2.1900579647351335

Epoch: 6| Step: 5
Training loss: 2.361332893371582
Validation loss: 2.1636537249370287

Epoch: 6| Step: 6
Training loss: 2.3852877616882324
Validation loss: 2.1389440003261773

Epoch: 6| Step: 7
Training loss: 2.5250515937805176
Validation loss: 2.135083693330006

Epoch: 6| Step: 8
Training loss: 2.3364133834838867
Validation loss: 2.124252880773237

Epoch: 6| Step: 9
Training loss: 2.419260263442993
Validation loss: 2.1324906528636975

Epoch: 6| Step: 10
Training loss: 2.3864057064056396
Validation loss: 2.1238634611970637

Epoch: 6| Step: 11
Training loss: 1.7969436645507812
Validation loss: 2.1172975032560286

Epoch: 6| Step: 12
Training loss: 1.8916343450546265
Validation loss: 2.109904678918982

Epoch: 6| Step: 13
Training loss: 2.316868782043457
Validation loss: 2.1077016861208024

Epoch: 70| Step: 0
Training loss: 1.9981727600097656
Validation loss: 2.1084476350456156

Epoch: 6| Step: 1
Training loss: 2.2509326934814453
Validation loss: 2.1058992493537163

Epoch: 6| Step: 2
Training loss: 2.5684690475463867
Validation loss: 2.109866455037107

Epoch: 6| Step: 3
Training loss: 1.784477949142456
Validation loss: 2.120739758655589

Epoch: 6| Step: 4
Training loss: 2.6879689693450928
Validation loss: 2.137775082742014

Epoch: 6| Step: 5
Training loss: 2.681776523590088
Validation loss: 2.1468046326791086

Epoch: 6| Step: 6
Training loss: 2.4873573780059814
Validation loss: 2.1839226240752847

Epoch: 6| Step: 7
Training loss: 2.3325653076171875
Validation loss: 2.218346712409809

Epoch: 6| Step: 8
Training loss: 2.329631805419922
Validation loss: 2.2013494968414307

Epoch: 6| Step: 9
Training loss: 3.5277838706970215
Validation loss: 2.167673360916876

Epoch: 6| Step: 10
Training loss: 2.111461877822876
Validation loss: 2.1327471989457325

Epoch: 6| Step: 11
Training loss: 2.007796287536621
Validation loss: 2.1247800614244197

Epoch: 6| Step: 12
Training loss: 2.7322373390197754
Validation loss: 2.109277904674571

Epoch: 6| Step: 13
Training loss: 2.3450565338134766
Validation loss: 2.10620573002805

Epoch: 71| Step: 0
Training loss: 2.1679868698120117
Validation loss: 2.1042918492388982

Epoch: 6| Step: 1
Training loss: 2.6447277069091797
Validation loss: 2.0962714251651557

Epoch: 6| Step: 2
Training loss: 2.4764654636383057
Validation loss: 2.090677046006726

Epoch: 6| Step: 3
Training loss: 2.6138882637023926
Validation loss: 2.093067246098672

Epoch: 6| Step: 4
Training loss: 1.865578532218933
Validation loss: 2.1042900444358907

Epoch: 6| Step: 5
Training loss: 2.680114507675171
Validation loss: 2.1221851366822437

Epoch: 6| Step: 6
Training loss: 2.36865234375
Validation loss: 2.124165282454542

Epoch: 6| Step: 7
Training loss: 2.346111297607422
Validation loss: 2.1380179543648996

Epoch: 6| Step: 8
Training loss: 2.736454486846924
Validation loss: 2.153188605462351

Epoch: 6| Step: 9
Training loss: 2.5106725692749023
Validation loss: 2.1652201183380617

Epoch: 6| Step: 10
Training loss: 2.3782434463500977
Validation loss: 2.1992249565739788

Epoch: 6| Step: 11
Training loss: 2.277254343032837
Validation loss: 2.234865878217964

Epoch: 6| Step: 12
Training loss: 2.320974588394165
Validation loss: 2.214992869284845

Epoch: 6| Step: 13
Training loss: 2.570011854171753
Validation loss: 2.18409998314355

Epoch: 72| Step: 0
Training loss: 1.978365182876587
Validation loss: 2.1460133162877892

Epoch: 6| Step: 1
Training loss: 2.1277456283569336
Validation loss: 2.113222465720228

Epoch: 6| Step: 2
Training loss: 2.456505298614502
Validation loss: 2.1056299645413636

Epoch: 6| Step: 3
Training loss: 2.482647657394409
Validation loss: 2.093209974227413

Epoch: 6| Step: 4
Training loss: 2.0653533935546875
Validation loss: 2.0942580751193467

Epoch: 6| Step: 5
Training loss: 2.6248323917388916
Validation loss: 2.092039797895698

Epoch: 6| Step: 6
Training loss: 2.3340940475463867
Validation loss: 2.0958340680727394

Epoch: 6| Step: 7
Training loss: 2.6704206466674805
Validation loss: 2.093109194950391

Epoch: 6| Step: 8
Training loss: 2.108316421508789
Validation loss: 2.096731576868283

Epoch: 6| Step: 9
Training loss: 2.073306083679199
Validation loss: 2.0946792325665875

Epoch: 6| Step: 10
Training loss: 2.638681173324585
Validation loss: 2.0894275224337013

Epoch: 6| Step: 11
Training loss: 2.3158421516418457
Validation loss: 2.0961688385214856

Epoch: 6| Step: 12
Training loss: 3.2798542976379395
Validation loss: 2.09619806402473

Epoch: 6| Step: 13
Training loss: 2.3229475021362305
Validation loss: 2.1145140945270495

Epoch: 73| Step: 0
Training loss: 2.5485012531280518
Validation loss: 2.1263633133262716

Epoch: 6| Step: 1
Training loss: 2.2815909385681152
Validation loss: 2.124148004798479

Epoch: 6| Step: 2
Training loss: 1.8786202669143677
Validation loss: 2.1084998346144155

Epoch: 6| Step: 3
Training loss: 2.063464641571045
Validation loss: 2.1077916647798274

Epoch: 6| Step: 4
Training loss: 2.388597249984741
Validation loss: 2.110809410772016

Epoch: 6| Step: 5
Training loss: 2.7530226707458496
Validation loss: 2.1175047633468465

Epoch: 6| Step: 6
Training loss: 2.2445285320281982
Validation loss: 2.1223465486239363

Epoch: 6| Step: 7
Training loss: 2.7899208068847656
Validation loss: 2.1390776813671155

Epoch: 6| Step: 8
Training loss: 2.2312917709350586
Validation loss: 2.153108457083343

Epoch: 6| Step: 9
Training loss: 2.4455535411834717
Validation loss: 2.1537016130262807

Epoch: 6| Step: 10
Training loss: 2.661630392074585
Validation loss: 2.1592578323938514

Epoch: 6| Step: 11
Training loss: 2.396048069000244
Validation loss: 2.131673510356616

Epoch: 6| Step: 12
Training loss: 1.9534060955047607
Validation loss: 2.127428831592683

Epoch: 6| Step: 13
Training loss: 3.1702980995178223
Validation loss: 2.110899980350207

Epoch: 74| Step: 0
Training loss: 3.1303534507751465
Validation loss: 2.0875333893683647

Epoch: 6| Step: 1
Training loss: 2.206820487976074
Validation loss: 2.083240509033203

Epoch: 6| Step: 2
Training loss: 2.4508209228515625
Validation loss: 2.1002766932210615

Epoch: 6| Step: 3
Training loss: 2.5097086429595947
Validation loss: 2.0919405414212133

Epoch: 6| Step: 4
Training loss: 2.2431716918945312
Validation loss: 2.084130694789271

Epoch: 6| Step: 5
Training loss: 2.4076998233795166
Validation loss: 2.08179840477564

Epoch: 6| Step: 6
Training loss: 1.9461928606033325
Validation loss: 2.0873234528367237

Epoch: 6| Step: 7
Training loss: 2.4224672317504883
Validation loss: 2.071358193633377

Epoch: 6| Step: 8
Training loss: 2.2545957565307617
Validation loss: 2.070775132025442

Epoch: 6| Step: 9
Training loss: 2.879697561264038
Validation loss: 2.0815369403490456

Epoch: 6| Step: 10
Training loss: 2.334946632385254
Validation loss: 2.109150214861798

Epoch: 6| Step: 11
Training loss: 2.7923922538757324
Validation loss: 2.1473115951784196

Epoch: 6| Step: 12
Training loss: 2.0137510299682617
Validation loss: 2.1546571575185305

Epoch: 6| Step: 13
Training loss: 2.2838034629821777
Validation loss: 2.1329882375655638

Epoch: 75| Step: 0
Training loss: 2.393605947494507
Validation loss: 2.086565822683355

Epoch: 6| Step: 1
Training loss: 1.7233824729919434
Validation loss: 2.075699876713496

Epoch: 6| Step: 2
Training loss: 2.5219078063964844
Validation loss: 2.082999389658692

Epoch: 6| Step: 3
Training loss: 2.9954309463500977
Validation loss: 2.0898714296279417

Epoch: 6| Step: 4
Training loss: 2.030733823776245
Validation loss: 2.096977626123736

Epoch: 6| Step: 5
Training loss: 2.275175094604492
Validation loss: 2.106389891716742

Epoch: 6| Step: 6
Training loss: 2.0886240005493164
Validation loss: 2.1168922044897593

Epoch: 6| Step: 7
Training loss: 2.7072389125823975
Validation loss: 2.125933212618674

Epoch: 6| Step: 8
Training loss: 2.8712315559387207
Validation loss: 2.157746150929441

Epoch: 6| Step: 9
Training loss: 2.5878968238830566
Validation loss: 2.1651113033294678

Epoch: 6| Step: 10
Training loss: 2.512998342514038
Validation loss: 2.15642669123988

Epoch: 6| Step: 11
Training loss: 1.4714157581329346
Validation loss: 2.154882266957273

Epoch: 6| Step: 12
Training loss: 2.954603672027588
Validation loss: 2.1369689279986965

Epoch: 6| Step: 13
Training loss: 2.5952892303466797
Validation loss: 2.1144874685554096

Epoch: 76| Step: 0
Training loss: 1.8167099952697754
Validation loss: 2.084018768802766

Epoch: 6| Step: 1
Training loss: 2.3460922241210938
Validation loss: 2.073009539675969

Epoch: 6| Step: 2
Training loss: 2.222132921218872
Validation loss: 2.0680064667937574

Epoch: 6| Step: 3
Training loss: 1.6030505895614624
Validation loss: 2.077677049944478

Epoch: 6| Step: 4
Training loss: 3.0484728813171387
Validation loss: 2.07240863256557

Epoch: 6| Step: 5
Training loss: 2.8718514442443848
Validation loss: 2.077979891530929

Epoch: 6| Step: 6
Training loss: 1.462090015411377
Validation loss: 2.074967799648162

Epoch: 6| Step: 7
Training loss: 2.6498498916625977
Validation loss: 2.0960915780836538

Epoch: 6| Step: 8
Training loss: 2.9052529335021973
Validation loss: 2.11557073490594

Epoch: 6| Step: 9
Training loss: 2.9027767181396484
Validation loss: 2.114355912772558

Epoch: 6| Step: 10
Training loss: 2.318359375
Validation loss: 2.1122068551278885

Epoch: 6| Step: 11
Training loss: 2.292179822921753
Validation loss: 2.1197193258552143

Epoch: 6| Step: 12
Training loss: 2.4556844234466553
Validation loss: 2.125270815305812

Epoch: 6| Step: 13
Training loss: 2.5386362075805664
Validation loss: 2.1264221258060907

Epoch: 77| Step: 0
Training loss: 1.874121069908142
Validation loss: 2.133330306699199

Epoch: 6| Step: 1
Training loss: 3.4397566318511963
Validation loss: 2.1246650936783

Epoch: 6| Step: 2
Training loss: 2.667086124420166
Validation loss: 2.108165246184154

Epoch: 6| Step: 3
Training loss: 2.0568878650665283
Validation loss: 2.0952030792031238

Epoch: 6| Step: 4
Training loss: 2.4832875728607178
Validation loss: 2.0884085291175434

Epoch: 6| Step: 5
Training loss: 2.1479592323303223
Validation loss: 2.0797933763073337

Epoch: 6| Step: 6
Training loss: 2.154759407043457
Validation loss: 2.068471083077051

Epoch: 6| Step: 7
Training loss: 2.4195497035980225
Validation loss: 2.074320339387463

Epoch: 6| Step: 8
Training loss: 2.2037787437438965
Validation loss: 2.074706139103059

Epoch: 6| Step: 9
Training loss: 2.454677104949951
Validation loss: 2.096117486235916

Epoch: 6| Step: 10
Training loss: 2.788707733154297
Validation loss: 2.124945955891763

Epoch: 6| Step: 11
Training loss: 1.5481854677200317
Validation loss: 2.1651159255735335

Epoch: 6| Step: 12
Training loss: 2.329127788543701
Validation loss: 2.1800826082947435

Epoch: 6| Step: 13
Training loss: 2.8827357292175293
Validation loss: 2.189319351667999

Epoch: 78| Step: 0
Training loss: 1.6116973161697388
Validation loss: 2.1754331101653395

Epoch: 6| Step: 1
Training loss: 2.452219247817993
Validation loss: 2.157568834161246

Epoch: 6| Step: 2
Training loss: 2.408012628555298
Validation loss: 2.110764834188646

Epoch: 6| Step: 3
Training loss: 2.110762119293213
Validation loss: 2.1029948085866947

Epoch: 6| Step: 4
Training loss: 2.5253958702087402
Validation loss: 2.096211055273651

Epoch: 6| Step: 5
Training loss: 2.7356085777282715
Validation loss: 2.1020090349258913

Epoch: 6| Step: 6
Training loss: 2.7777862548828125
Validation loss: 2.1129453310402493

Epoch: 6| Step: 7
Training loss: 2.0958333015441895
Validation loss: 2.1035258385442916

Epoch: 6| Step: 8
Training loss: 2.7245540618896484
Validation loss: 2.1062623557224067

Epoch: 6| Step: 9
Training loss: 2.6347856521606445
Validation loss: 2.099005368448073

Epoch: 6| Step: 10
Training loss: 2.109039783477783
Validation loss: 2.086954509058306

Epoch: 6| Step: 11
Training loss: 2.5256190299987793
Validation loss: 2.08726897803686

Epoch: 6| Step: 12
Training loss: 2.2773735523223877
Validation loss: 2.078696995653132

Epoch: 6| Step: 13
Training loss: 2.5292298793792725
Validation loss: 2.079488624808609

Epoch: 79| Step: 0
Training loss: 2.2518107891082764
Validation loss: 2.0947153645177043

Epoch: 6| Step: 1
Training loss: 2.3497323989868164
Validation loss: 2.1164870236509588

Epoch: 6| Step: 2
Training loss: 2.7866225242614746
Validation loss: 2.159131351337638

Epoch: 6| Step: 3
Training loss: 2.435904026031494
Validation loss: 2.180956143204884

Epoch: 6| Step: 4
Training loss: 2.0569043159484863
Validation loss: 2.185595655954012

Epoch: 6| Step: 5
Training loss: 2.8984622955322266
Validation loss: 2.1963706003722323

Epoch: 6| Step: 6
Training loss: 2.7760684490203857
Validation loss: 2.208823078422136

Epoch: 6| Step: 7
Training loss: 2.477468490600586
Validation loss: 2.203258724622829

Epoch: 6| Step: 8
Training loss: 1.9901297092437744
Validation loss: 2.191182674900178

Epoch: 6| Step: 9
Training loss: 2.014232873916626
Validation loss: 2.1787225213102115

Epoch: 6| Step: 10
Training loss: 2.3617680072784424
Validation loss: 2.1566878339295745

Epoch: 6| Step: 11
Training loss: 2.0378851890563965
Validation loss: 2.1149581145214778

Epoch: 6| Step: 12
Training loss: 2.6254422664642334
Validation loss: 2.0954329570134482

Epoch: 6| Step: 13
Training loss: 2.1992528438568115
Validation loss: 2.096467419337201

Epoch: 80| Step: 0
Training loss: 1.9587451219558716
Validation loss: 2.090795245221866

Epoch: 6| Step: 1
Training loss: 1.9754045009613037
Validation loss: 2.0929240949692263

Epoch: 6| Step: 2
Training loss: 2.7033181190490723
Validation loss: 2.0906285162894958

Epoch: 6| Step: 3
Training loss: 2.728529691696167
Validation loss: 2.1024887741252942

Epoch: 6| Step: 4
Training loss: 2.436805248260498
Validation loss: 2.1176593560044483

Epoch: 6| Step: 5
Training loss: 1.5738493204116821
Validation loss: 2.1460388732212845

Epoch: 6| Step: 6
Training loss: 2.3148741722106934
Validation loss: 2.1755006467142413

Epoch: 6| Step: 7
Training loss: 2.1041221618652344
Validation loss: 2.2039023394225747

Epoch: 6| Step: 8
Training loss: 2.6794638633728027
Validation loss: 2.2267037950536257

Epoch: 6| Step: 9
Training loss: 2.634303331375122
Validation loss: 2.207475613522273

Epoch: 6| Step: 10
Training loss: 2.627105712890625
Validation loss: 2.182960897363642

Epoch: 6| Step: 11
Training loss: 2.2579867839813232
Validation loss: 2.1497095374650854

Epoch: 6| Step: 12
Training loss: 2.5948171615600586
Validation loss: 2.120608469491364

Epoch: 6| Step: 13
Training loss: 2.935211181640625
Validation loss: 2.1203570006996073

Epoch: 81| Step: 0
Training loss: 1.4128484725952148
Validation loss: 2.1064068271267797

Epoch: 6| Step: 1
Training loss: 2.905330181121826
Validation loss: 2.10948585566654

Epoch: 6| Step: 2
Training loss: 2.8012025356292725
Validation loss: 2.1038406254142843

Epoch: 6| Step: 3
Training loss: 2.0217957496643066
Validation loss: 2.1029059489568076

Epoch: 6| Step: 4
Training loss: 2.379708766937256
Validation loss: 2.1041747446983092

Epoch: 6| Step: 5
Training loss: 3.155681610107422
Validation loss: 2.1081381023571057

Epoch: 6| Step: 6
Training loss: 2.4012436866760254
Validation loss: 2.103930029817807

Epoch: 6| Step: 7
Training loss: 2.4606337547302246
Validation loss: 2.1110024003572363

Epoch: 6| Step: 8
Training loss: 2.6271300315856934
Validation loss: 2.123165125487953

Epoch: 6| Step: 9
Training loss: 2.3266170024871826
Validation loss: 2.0971202568341325

Epoch: 6| Step: 10
Training loss: 1.9041473865509033
Validation loss: 2.0940071408466627

Epoch: 6| Step: 11
Training loss: 2.0057730674743652
Validation loss: 2.066541616634656

Epoch: 6| Step: 12
Training loss: 2.2594103813171387
Validation loss: 2.0575458836811844

Epoch: 6| Step: 13
Training loss: 1.8927472829818726
Validation loss: 2.046155887265359

Epoch: 82| Step: 0
Training loss: 2.860983371734619
Validation loss: 2.0524617933457896

Epoch: 6| Step: 1
Training loss: 2.6995723247528076
Validation loss: 2.0510124032215407

Epoch: 6| Step: 2
Training loss: 2.6524410247802734
Validation loss: 2.059125646468132

Epoch: 6| Step: 3
Training loss: 2.5537056922912598
Validation loss: 2.079596934779998

Epoch: 6| Step: 4
Training loss: 2.632042169570923
Validation loss: 2.0781425365837674

Epoch: 6| Step: 5
Training loss: 2.025186538696289
Validation loss: 2.10021996754472

Epoch: 6| Step: 6
Training loss: 2.258458137512207
Validation loss: 2.1210767722898916

Epoch: 6| Step: 7
Training loss: 2.323206901550293
Validation loss: 2.1189054750627085

Epoch: 6| Step: 8
Training loss: 2.4253416061401367
Validation loss: 2.1383478128781883

Epoch: 6| Step: 9
Training loss: 1.809409260749817
Validation loss: 2.12898229142671

Epoch: 6| Step: 10
Training loss: 1.8165104389190674
Validation loss: 2.089848182534659

Epoch: 6| Step: 11
Training loss: 2.7349114418029785
Validation loss: 2.066266558503592

Epoch: 6| Step: 12
Training loss: 2.037907123565674
Validation loss: 2.05462553680584

Epoch: 6| Step: 13
Training loss: 1.7890205383300781
Validation loss: 2.037674237323064

Epoch: 83| Step: 0
Training loss: 2.0242483615875244
Validation loss: 2.0333063422992663

Epoch: 6| Step: 1
Training loss: 2.849518060684204
Validation loss: 2.03267244626117

Epoch: 6| Step: 2
Training loss: 2.258408546447754
Validation loss: 2.0312281090726136

Epoch: 6| Step: 3
Training loss: 2.653876304626465
Validation loss: 2.0317875390411704

Epoch: 6| Step: 4
Training loss: 2.5155560970306396
Validation loss: 2.0270926439633934

Epoch: 6| Step: 5
Training loss: 2.1033706665039062
Validation loss: 2.0359905458265737

Epoch: 6| Step: 6
Training loss: 0.8796688914299011
Validation loss: 2.0400233730193107

Epoch: 6| Step: 7
Training loss: 2.1365294456481934
Validation loss: 2.0756185670052805

Epoch: 6| Step: 8
Training loss: 2.1357195377349854
Validation loss: 2.1030722625793947

Epoch: 6| Step: 9
Training loss: 2.3538618087768555
Validation loss: 2.117508138379743

Epoch: 6| Step: 10
Training loss: 2.6186323165893555
Validation loss: 2.109493583761236

Epoch: 6| Step: 11
Training loss: 3.005319118499756
Validation loss: 2.105760633304555

Epoch: 6| Step: 12
Training loss: 2.485708475112915
Validation loss: 2.091880249720748

Epoch: 6| Step: 13
Training loss: 2.942519187927246
Validation loss: 2.0819464883496686

Epoch: 84| Step: 0
Training loss: 1.9800136089324951
Validation loss: 2.074332211607246

Epoch: 6| Step: 1
Training loss: 2.262488603591919
Validation loss: 2.064472354868407

Epoch: 6| Step: 2
Training loss: 3.526179790496826
Validation loss: 2.048852987186883

Epoch: 6| Step: 3
Training loss: 2.5071380138397217
Validation loss: 2.0335291303614134

Epoch: 6| Step: 4
Training loss: 2.1794753074645996
Validation loss: 2.0408957901821343

Epoch: 6| Step: 5
Training loss: 2.7229723930358887
Validation loss: 2.0356950144613943

Epoch: 6| Step: 6
Training loss: 2.9357199668884277
Validation loss: 2.0400492222078386

Epoch: 6| Step: 7
Training loss: 2.074068307876587
Validation loss: 2.0322545523284585

Epoch: 6| Step: 8
Training loss: 2.0930614471435547
Validation loss: 2.0366411362924883

Epoch: 6| Step: 9
Training loss: 2.9835822582244873
Validation loss: 2.0381717066611014

Epoch: 6| Step: 10
Training loss: 1.913361668586731
Validation loss: 2.061528467362927

Epoch: 6| Step: 11
Training loss: 2.583956241607666
Validation loss: 2.0851496086325696

Epoch: 6| Step: 12
Training loss: 1.1751505136489868
Validation loss: 2.1002028167888684

Epoch: 6| Step: 13
Training loss: 1.5476014614105225
Validation loss: 2.1007819790993967

Epoch: 85| Step: 0
Training loss: 2.891035556793213
Validation loss: 2.0830529069387786

Epoch: 6| Step: 1
Training loss: 2.114118814468384
Validation loss: 2.0757832527160645

Epoch: 6| Step: 2
Training loss: 2.4955410957336426
Validation loss: 2.0678445946785713

Epoch: 6| Step: 3
Training loss: 1.6696135997772217
Validation loss: 2.073852362171296

Epoch: 6| Step: 4
Training loss: 2.270843029022217
Validation loss: 2.083647948439403

Epoch: 6| Step: 5
Training loss: 2.3629026412963867
Validation loss: 2.0706321603508404

Epoch: 6| Step: 6
Training loss: 2.316941499710083
Validation loss: 2.0648511045722553

Epoch: 6| Step: 7
Training loss: 2.604599714279175
Validation loss: 2.0616764150640017

Epoch: 6| Step: 8
Training loss: 1.8746637105941772
Validation loss: 2.0615012158629713

Epoch: 6| Step: 9
Training loss: 2.441585063934326
Validation loss: 2.071591123457878

Epoch: 6| Step: 10
Training loss: 1.9123988151550293
Validation loss: 2.0898979902267456

Epoch: 6| Step: 11
Training loss: 2.0436806678771973
Validation loss: 2.0834908793049474

Epoch: 6| Step: 12
Training loss: 2.8180832862854004
Validation loss: 2.071642852598621

Epoch: 6| Step: 13
Training loss: 2.5014290809631348
Validation loss: 2.061231096585592

Epoch: 86| Step: 0
Training loss: 2.5616908073425293
Validation loss: 2.0501404475140315

Epoch: 6| Step: 1
Training loss: 2.5745301246643066
Validation loss: 2.051127879850326

Epoch: 6| Step: 2
Training loss: 2.3219807147979736
Validation loss: 2.0406899067663375

Epoch: 6| Step: 3
Training loss: 2.0391581058502197
Validation loss: 2.0464943480748

Epoch: 6| Step: 4
Training loss: 2.2377867698669434
Validation loss: 2.0465973743828396

Epoch: 6| Step: 5
Training loss: 2.7403457164764404
Validation loss: 2.0529340890146073

Epoch: 6| Step: 6
Training loss: 2.5696349143981934
Validation loss: 2.060755470747589

Epoch: 6| Step: 7
Training loss: 1.822463035583496
Validation loss: 2.0630605207976473

Epoch: 6| Step: 8
Training loss: 2.086233377456665
Validation loss: 2.066943432695122

Epoch: 6| Step: 9
Training loss: 2.132434368133545
Validation loss: 2.0697697362592145

Epoch: 6| Step: 10
Training loss: 2.6776843070983887
Validation loss: 2.068008230578515

Epoch: 6| Step: 11
Training loss: 2.3966715335845947
Validation loss: 2.0654187663908927

Epoch: 6| Step: 12
Training loss: 2.4604268074035645
Validation loss: 2.0672269841676116

Epoch: 6| Step: 13
Training loss: 0.7764865159988403
Validation loss: 2.064023669048022

Epoch: 87| Step: 0
Training loss: 1.8598155975341797
Validation loss: 2.05470024642124

Epoch: 6| Step: 1
Training loss: 2.3586416244506836
Validation loss: 2.050566218232596

Epoch: 6| Step: 2
Training loss: 1.991519808769226
Validation loss: 2.054206138016075

Epoch: 6| Step: 3
Training loss: 2.975867748260498
Validation loss: 2.0638913826275895

Epoch: 6| Step: 4
Training loss: 2.1034255027770996
Validation loss: 2.087153219407605

Epoch: 6| Step: 5
Training loss: 2.534210681915283
Validation loss: 2.104247216255434

Epoch: 6| Step: 6
Training loss: 2.553762912750244
Validation loss: 2.0903009881255445

Epoch: 6| Step: 7
Training loss: 2.3205807209014893
Validation loss: 2.078156876307662

Epoch: 6| Step: 8
Training loss: 2.4212214946746826
Validation loss: 2.0725219031815887

Epoch: 6| Step: 9
Training loss: 2.7924962043762207
Validation loss: 2.0717611799957933

Epoch: 6| Step: 10
Training loss: 2.32900333404541
Validation loss: 2.059810571773078

Epoch: 6| Step: 11
Training loss: 2.0475363731384277
Validation loss: 2.0539925482965287

Epoch: 6| Step: 12
Training loss: 1.9729313850402832
Validation loss: 2.0500851472218833

Epoch: 6| Step: 13
Training loss: 1.6758997440338135
Validation loss: 2.048101238025132

Epoch: 88| Step: 0
Training loss: 2.9487826824188232
Validation loss: 2.0496313302747664

Epoch: 6| Step: 1
Training loss: 2.562077045440674
Validation loss: 2.056521331110308

Epoch: 6| Step: 2
Training loss: 1.958295464515686
Validation loss: 2.0619767083916614

Epoch: 6| Step: 3
Training loss: 2.4213573932647705
Validation loss: 2.076557062005484

Epoch: 6| Step: 4
Training loss: 1.8066627979278564
Validation loss: 2.0950492197467434

Epoch: 6| Step: 5
Training loss: 1.9738717079162598
Validation loss: 2.1035030811063704

Epoch: 6| Step: 6
Training loss: 2.261672019958496
Validation loss: 2.112647161688856

Epoch: 6| Step: 7
Training loss: 3.1527462005615234
Validation loss: 2.104002965393887

Epoch: 6| Step: 8
Training loss: 2.301417350769043
Validation loss: 2.0786947511857554

Epoch: 6| Step: 9
Training loss: 2.085616111755371
Validation loss: 2.063925676448371

Epoch: 6| Step: 10
Training loss: 2.0189647674560547
Validation loss: 2.0603040392680834

Epoch: 6| Step: 11
Training loss: 2.6158976554870605
Validation loss: 2.062212940185301

Epoch: 6| Step: 12
Training loss: 1.7340149879455566
Validation loss: 2.061932344590464

Epoch: 6| Step: 13
Training loss: 2.1543502807617188
Validation loss: 2.0634166553456295

Epoch: 89| Step: 0
Training loss: 2.625946521759033
Validation loss: 2.060751889341621

Epoch: 6| Step: 1
Training loss: 2.4733238220214844
Validation loss: 2.0682461248931063

Epoch: 6| Step: 2
Training loss: 1.6258169412612915
Validation loss: 2.077575869457696

Epoch: 6| Step: 3
Training loss: 2.0780301094055176
Validation loss: 2.057911454990346

Epoch: 6| Step: 4
Training loss: 2.150601387023926
Validation loss: 2.0474126851686867

Epoch: 6| Step: 5
Training loss: 1.8451887369155884
Validation loss: 2.0392828500399025

Epoch: 6| Step: 6
Training loss: 0.9938679337501526
Validation loss: 2.031238635381063

Epoch: 6| Step: 7
Training loss: 2.914844036102295
Validation loss: 2.0200608135551534

Epoch: 6| Step: 8
Training loss: 2.7016611099243164
Validation loss: 2.0146085549426336

Epoch: 6| Step: 9
Training loss: 2.8487539291381836
Validation loss: 2.0212720260825208

Epoch: 6| Step: 10
Training loss: 2.652554512023926
Validation loss: 2.016825052999681

Epoch: 6| Step: 11
Training loss: 2.2134928703308105
Validation loss: 2.0217751943936912

Epoch: 6| Step: 12
Training loss: 2.3963751792907715
Validation loss: 2.0163496130256244

Epoch: 6| Step: 13
Training loss: 2.556406021118164
Validation loss: 2.0300452132378854

Epoch: 90| Step: 0
Training loss: 2.2220041751861572
Validation loss: 2.0573766231536865

Epoch: 6| Step: 1
Training loss: 2.7255024909973145
Validation loss: 2.093182445854269

Epoch: 6| Step: 2
Training loss: 1.9521945714950562
Validation loss: 2.0954967083469516

Epoch: 6| Step: 3
Training loss: 2.365546464920044
Validation loss: 2.086026830057944

Epoch: 6| Step: 4
Training loss: 2.230982780456543
Validation loss: 2.079016213775963

Epoch: 6| Step: 5
Training loss: 2.1885595321655273
Validation loss: 2.079627429285357

Epoch: 6| Step: 6
Training loss: 1.9406733512878418
Validation loss: 2.0585024023568756

Epoch: 6| Step: 7
Training loss: 1.4884767532348633
Validation loss: 2.050848825003511

Epoch: 6| Step: 8
Training loss: 2.2546191215515137
Validation loss: 2.0518586686862412

Epoch: 6| Step: 9
Training loss: 2.8084933757781982
Validation loss: 2.0492371307906283

Epoch: 6| Step: 10
Training loss: 3.034724712371826
Validation loss: 2.0542032757113056

Epoch: 6| Step: 11
Training loss: 1.6903481483459473
Validation loss: 2.068556659965105

Epoch: 6| Step: 12
Training loss: 2.1788973808288574
Validation loss: 2.08800942667069

Epoch: 6| Step: 13
Training loss: 3.008870840072632
Validation loss: 2.1125030440668904

Epoch: 91| Step: 0
Training loss: 2.22377872467041
Validation loss: 2.1301461253114926

Epoch: 6| Step: 1
Training loss: 2.2172505855560303
Validation loss: 2.1396696746990247

Epoch: 6| Step: 2
Training loss: 1.9128940105438232
Validation loss: 2.1547701384431575

Epoch: 6| Step: 3
Training loss: 2.216782331466675
Validation loss: 2.1953818541701122

Epoch: 6| Step: 4
Training loss: 2.803370714187622
Validation loss: 2.214463444166286

Epoch: 6| Step: 5
Training loss: 2.1197519302368164
Validation loss: 2.1917231416189544

Epoch: 6| Step: 6
Training loss: 2.1172966957092285
Validation loss: 2.142244459480368

Epoch: 6| Step: 7
Training loss: 2.5941638946533203
Validation loss: 2.0870159249151907

Epoch: 6| Step: 8
Training loss: 2.241779327392578
Validation loss: 2.0797499046530774

Epoch: 6| Step: 9
Training loss: 2.119462490081787
Validation loss: 2.1022991800820954

Epoch: 6| Step: 10
Training loss: 2.401721954345703
Validation loss: 2.145852409383302

Epoch: 6| Step: 11
Training loss: 2.778032064437866
Validation loss: 2.140877003310829

Epoch: 6| Step: 12
Training loss: 1.8676239252090454
Validation loss: 2.0948514015443864

Epoch: 6| Step: 13
Training loss: 2.8324577808380127
Validation loss: 2.0750203696630334

Epoch: 92| Step: 0
Training loss: 2.7339348793029785
Validation loss: 2.0605477697105816

Epoch: 6| Step: 1
Training loss: 2.510164737701416
Validation loss: 2.0439180481818413

Epoch: 6| Step: 2
Training loss: 1.961157202720642
Validation loss: 2.055684340897427

Epoch: 6| Step: 3
Training loss: 2.907658815383911
Validation loss: 2.0546314562520673

Epoch: 6| Step: 4
Training loss: 1.717287302017212
Validation loss: 2.059319947355537

Epoch: 6| Step: 5
Training loss: 2.248352289199829
Validation loss: 2.0709235219545263

Epoch: 6| Step: 6
Training loss: 2.1424593925476074
Validation loss: 2.0854909984014367

Epoch: 6| Step: 7
Training loss: 2.1812283992767334
Validation loss: 2.099825243796072

Epoch: 6| Step: 8
Training loss: 1.8672080039978027
Validation loss: 2.0985573696833786

Epoch: 6| Step: 9
Training loss: 2.490182638168335
Validation loss: 2.082073570579611

Epoch: 6| Step: 10
Training loss: 1.9116971492767334
Validation loss: 2.0651150698302896

Epoch: 6| Step: 11
Training loss: 1.7645745277404785
Validation loss: 2.0629790290709464

Epoch: 6| Step: 12
Training loss: 2.59689998626709
Validation loss: 2.076158933742072

Epoch: 6| Step: 13
Training loss: 2.6312549114227295
Validation loss: 2.0829166827663297

Epoch: 93| Step: 0
Training loss: 2.9652161598205566
Validation loss: 2.0978373532654135

Epoch: 6| Step: 1
Training loss: 2.369675636291504
Validation loss: 2.084422803694202

Epoch: 6| Step: 2
Training loss: 1.948035717010498
Validation loss: 2.0808621004063594

Epoch: 6| Step: 3
Training loss: 2.0558342933654785
Validation loss: 2.065716289704846

Epoch: 6| Step: 4
Training loss: 2.2034640312194824
Validation loss: 2.073743548444522

Epoch: 6| Step: 5
Training loss: 2.2730369567871094
Validation loss: 2.0745543690137964

Epoch: 6| Step: 6
Training loss: 2.730929136276245
Validation loss: 2.0772580433917303

Epoch: 6| Step: 7
Training loss: 2.2729716300964355
Validation loss: 2.0712472623394382

Epoch: 6| Step: 8
Training loss: 1.4077823162078857
Validation loss: 2.059873584778078

Epoch: 6| Step: 9
Training loss: 1.5899567604064941
Validation loss: 2.068371049819454

Epoch: 6| Step: 10
Training loss: 2.331324815750122
Validation loss: 2.069208509178572

Epoch: 6| Step: 11
Training loss: 2.554192066192627
Validation loss: 2.060647464567615

Epoch: 6| Step: 12
Training loss: 2.415316581726074
Validation loss: 2.0745722106707993

Epoch: 6| Step: 13
Training loss: 2.256756067276001
Validation loss: 2.0690551252775293

Epoch: 94| Step: 0
Training loss: 2.1987576484680176
Validation loss: 2.0738447994314213

Epoch: 6| Step: 1
Training loss: 2.0034046173095703
Validation loss: 2.0723670400598997

Epoch: 6| Step: 2
Training loss: 1.6286555528640747
Validation loss: 2.0800535909591185

Epoch: 6| Step: 3
Training loss: 2.583007335662842
Validation loss: 2.0882480221409954

Epoch: 6| Step: 4
Training loss: 2.128319263458252
Validation loss: 2.116390246216969

Epoch: 6| Step: 5
Training loss: 1.5342655181884766
Validation loss: 2.153292932818013

Epoch: 6| Step: 6
Training loss: 2.2349355220794678
Validation loss: 2.1690566514127996

Epoch: 6| Step: 7
Training loss: 1.6136759519577026
Validation loss: 2.1640467489919355

Epoch: 6| Step: 8
Training loss: 2.149754524230957
Validation loss: 2.1399917064174527

Epoch: 6| Step: 9
Training loss: 3.2660577297210693
Validation loss: 2.122642465817031

Epoch: 6| Step: 10
Training loss: 2.435570240020752
Validation loss: 2.112699798358384

Epoch: 6| Step: 11
Training loss: 2.429483652114868
Validation loss: 2.095695977569908

Epoch: 6| Step: 12
Training loss: 2.237492084503174
Validation loss: 2.0772539287485103

Epoch: 6| Step: 13
Training loss: 2.9979398250579834
Validation loss: 2.053845008214315

Epoch: 95| Step: 0
Training loss: 2.145771026611328
Validation loss: 2.039372468507418

Epoch: 6| Step: 1
Training loss: 2.826533317565918
Validation loss: 2.023985114148868

Epoch: 6| Step: 2
Training loss: 2.3486618995666504
Validation loss: 2.030041444686151

Epoch: 6| Step: 3
Training loss: 2.497309923171997
Validation loss: 2.044102208588713

Epoch: 6| Step: 4
Training loss: 2.2376468181610107
Validation loss: 2.045811698000918

Epoch: 6| Step: 5
Training loss: 2.361097574234009
Validation loss: 2.046265800793966

Epoch: 6| Step: 6
Training loss: 1.880766749382019
Validation loss: 2.0440632092055453

Epoch: 6| Step: 7
Training loss: 2.146009922027588
Validation loss: 2.047596710984425

Epoch: 6| Step: 8
Training loss: 1.6693289279937744
Validation loss: 2.0695644040261545

Epoch: 6| Step: 9
Training loss: 2.0557241439819336
Validation loss: 2.1180403847848215

Epoch: 6| Step: 10
Training loss: 1.8938748836517334
Validation loss: 2.1705033343325377

Epoch: 6| Step: 11
Training loss: 2.2359232902526855
Validation loss: 2.176304078871204

Epoch: 6| Step: 12
Training loss: 2.708268642425537
Validation loss: 2.1748591584544026

Epoch: 6| Step: 13
Training loss: 2.754685163497925
Validation loss: 2.1546452942714898

Epoch: 96| Step: 0
Training loss: 2.3603110313415527
Validation loss: 2.1267337799072266

Epoch: 6| Step: 1
Training loss: 2.062251567840576
Validation loss: 2.098820765813192

Epoch: 6| Step: 2
Training loss: 2.4361181259155273
Validation loss: 2.059347810283784

Epoch: 6| Step: 3
Training loss: 2.402535915374756
Validation loss: 2.0501574431696246

Epoch: 6| Step: 4
Training loss: 2.276226043701172
Validation loss: 2.064599516571209

Epoch: 6| Step: 5
Training loss: 2.0139143466949463
Validation loss: 2.0666966553657287

Epoch: 6| Step: 6
Training loss: 2.293416976928711
Validation loss: 2.063085748303321

Epoch: 6| Step: 7
Training loss: 2.47584867477417
Validation loss: 2.0665005099388862

Epoch: 6| Step: 8
Training loss: 2.5508670806884766
Validation loss: 2.0647858599180817

Epoch: 6| Step: 9
Training loss: 2.341209650039673
Validation loss: 2.0490041535387755

Epoch: 6| Step: 10
Training loss: 1.6640479564666748
Validation loss: 2.036993174142735

Epoch: 6| Step: 11
Training loss: 2.2596421241760254
Validation loss: 2.053952101738222

Epoch: 6| Step: 12
Training loss: 2.5062198638916016
Validation loss: 2.0651315002031225

Epoch: 6| Step: 13
Training loss: 1.8546862602233887
Validation loss: 2.075989500168831

Epoch: 97| Step: 0
Training loss: 1.9671752452850342
Validation loss: 2.1020938965582077

Epoch: 6| Step: 1
Training loss: 2.3946900367736816
Validation loss: 2.1123018803135043

Epoch: 6| Step: 2
Training loss: 1.630424976348877
Validation loss: 2.1566856907260035

Epoch: 6| Step: 3
Training loss: 1.9194234609603882
Validation loss: 2.2023706461793635

Epoch: 6| Step: 4
Training loss: 3.0239386558532715
Validation loss: 2.1648528498987996

Epoch: 6| Step: 5
Training loss: 2.0132741928100586
Validation loss: 2.134243667766612

Epoch: 6| Step: 6
Training loss: 2.610913038253784
Validation loss: 2.086326606812016

Epoch: 6| Step: 7
Training loss: 2.2332043647766113
Validation loss: 2.091246181918729

Epoch: 6| Step: 8
Training loss: 2.2249786853790283
Validation loss: 2.0757655635956795

Epoch: 6| Step: 9
Training loss: 2.2254085540771484
Validation loss: 2.074461919005199

Epoch: 6| Step: 10
Training loss: 2.1796836853027344
Validation loss: 2.0819030807864283

Epoch: 6| Step: 11
Training loss: 2.234945774078369
Validation loss: 2.0819983700270295

Epoch: 6| Step: 12
Training loss: 2.1573948860168457
Validation loss: 2.086081539430926

Epoch: 6| Step: 13
Training loss: 2.082573890686035
Validation loss: 2.0847563256499586

Epoch: 98| Step: 0
Training loss: 1.9938149452209473
Validation loss: 2.0874065006932905

Epoch: 6| Step: 1
Training loss: 1.9697718620300293
Validation loss: 2.098240331936908

Epoch: 6| Step: 2
Training loss: 2.5977625846862793
Validation loss: 2.1733265487096642

Epoch: 6| Step: 3
Training loss: 2.7625927925109863
Validation loss: 2.198791329578687

Epoch: 6| Step: 4
Training loss: 2.532522439956665
Validation loss: 2.112405987196071

Epoch: 6| Step: 5
Training loss: 2.787766218185425
Validation loss: 2.065437550185829

Epoch: 6| Step: 6
Training loss: 2.2770707607269287
Validation loss: 2.051391086270732

Epoch: 6| Step: 7
Training loss: 1.899822473526001
Validation loss: 2.0558213597984722

Epoch: 6| Step: 8
Training loss: 1.7491081953048706
Validation loss: 2.0538843139525382

Epoch: 6| Step: 9
Training loss: 2.169604778289795
Validation loss: 2.0566235332078833

Epoch: 6| Step: 10
Training loss: 2.0656819343566895
Validation loss: 2.067610366370088

Epoch: 6| Step: 11
Training loss: 1.8642568588256836
Validation loss: 2.0837531499965216

Epoch: 6| Step: 12
Training loss: 2.5984795093536377
Validation loss: 2.1081201632817588

Epoch: 6| Step: 13
Training loss: 1.8744746446609497
Validation loss: 2.1274370480609197

Epoch: 99| Step: 0
Training loss: 1.3983354568481445
Validation loss: 2.110367977490989

Epoch: 6| Step: 1
Training loss: 2.2525556087493896
Validation loss: 2.1008119660039104

Epoch: 6| Step: 2
Training loss: 2.885327100753784
Validation loss: 2.0896356515986945

Epoch: 6| Step: 3
Training loss: 2.5548784732818604
Validation loss: 2.0790207232198408

Epoch: 6| Step: 4
Training loss: 2.553314208984375
Validation loss: 2.056921059085477

Epoch: 6| Step: 5
Training loss: 2.3509581089019775
Validation loss: 2.055630212189049

Epoch: 6| Step: 6
Training loss: 2.2778892517089844
Validation loss: 2.0516636884340675

Epoch: 6| Step: 7
Training loss: 1.9394855499267578
Validation loss: 2.0604018742038357

Epoch: 6| Step: 8
Training loss: 1.6997008323669434
Validation loss: 2.06758947782619

Epoch: 6| Step: 9
Training loss: 2.5730714797973633
Validation loss: 2.0699896081801383

Epoch: 6| Step: 10
Training loss: 2.078336715698242
Validation loss: 2.079431403067804

Epoch: 6| Step: 11
Training loss: 2.1811628341674805
Validation loss: 2.0918528982388076

Epoch: 6| Step: 12
Training loss: 2.1048851013183594
Validation loss: 2.098536083775182

Epoch: 6| Step: 13
Training loss: 1.7234349250793457
Validation loss: 2.1182891553448093

Epoch: 100| Step: 0
Training loss: 1.790712594985962
Validation loss: 2.130918202861663

Epoch: 6| Step: 1
Training loss: 2.0456783771514893
Validation loss: 2.123556608794838

Epoch: 6| Step: 2
Training loss: 2.1749610900878906
Validation loss: 2.1183277099363265

Epoch: 6| Step: 3
Training loss: 1.876039981842041
Validation loss: 2.104802546962615

Epoch: 6| Step: 4
Training loss: 2.0945000648498535
Validation loss: 2.092207318993025

Epoch: 6| Step: 5
Training loss: 3.3316457271575928
Validation loss: 2.094273103180752

Epoch: 6| Step: 6
Training loss: 2.2517032623291016
Validation loss: 2.099776598715013

Epoch: 6| Step: 7
Training loss: 2.4599573612213135
Validation loss: 2.1177364344237954

Epoch: 6| Step: 8
Training loss: 2.174748182296753
Validation loss: 2.1186876425179104

Epoch: 6| Step: 9
Training loss: 2.1758413314819336
Validation loss: 2.1174080243674656

Epoch: 6| Step: 10
Training loss: 1.9106683731079102
Validation loss: 2.1116717066816104

Epoch: 6| Step: 11
Training loss: 2.1832334995269775
Validation loss: 2.1299267789368987

Epoch: 6| Step: 12
Training loss: 1.7192503213882446
Validation loss: 2.134853281000609

Epoch: 6| Step: 13
Training loss: 1.9624733924865723
Validation loss: 2.1475348959686937

Epoch: 101| Step: 0
Training loss: 2.0345139503479004
Validation loss: 2.1535998262384886

Epoch: 6| Step: 1
Training loss: 2.3150382041931152
Validation loss: 2.1699374439895793

Epoch: 6| Step: 2
Training loss: 2.25711727142334
Validation loss: 2.17079262323277

Epoch: 6| Step: 3
Training loss: 1.8841986656188965
Validation loss: 2.142812841682024

Epoch: 6| Step: 4
Training loss: 2.2813618183135986
Validation loss: 2.136678687987789

Epoch: 6| Step: 5
Training loss: 2.2577273845672607
Validation loss: 2.1301764852257183

Epoch: 6| Step: 6
Training loss: 1.6644729375839233
Validation loss: 2.1223689202339417

Epoch: 6| Step: 7
Training loss: 2.9363741874694824
Validation loss: 2.1140544106883388

Epoch: 6| Step: 8
Training loss: 2.2941949367523193
Validation loss: 2.123347900247061

Epoch: 6| Step: 9
Training loss: 2.322600841522217
Validation loss: 2.122184818790805

Epoch: 6| Step: 10
Training loss: 1.897283673286438
Validation loss: 2.1190645848551104

Epoch: 6| Step: 11
Training loss: 2.2193808555603027
Validation loss: 2.1262833367111864

Epoch: 6| Step: 12
Training loss: 1.6376030445098877
Validation loss: 2.1185785954998386

Epoch: 6| Step: 13
Training loss: 2.3860552310943604
Validation loss: 2.0970365411491803

Epoch: 102| Step: 0
Training loss: 2.289914608001709
Validation loss: 2.084206017114783

Epoch: 6| Step: 1
Training loss: 1.5305696725845337
Validation loss: 2.076567283240698

Epoch: 6| Step: 2
Training loss: 2.1136834621429443
Validation loss: 2.0676355105574413

Epoch: 6| Step: 3
Training loss: 2.1520988941192627
Validation loss: 2.085257517394199

Epoch: 6| Step: 4
Training loss: 2.275836944580078
Validation loss: 2.084059041033509

Epoch: 6| Step: 5
Training loss: 1.260867953300476
Validation loss: 2.0729724412323325

Epoch: 6| Step: 6
Training loss: 2.0544726848602295
Validation loss: 2.0574536695275256

Epoch: 6| Step: 7
Training loss: 2.8207597732543945
Validation loss: 2.059900724759666

Epoch: 6| Step: 8
Training loss: 2.7739105224609375
Validation loss: 2.0548671676266577

Epoch: 6| Step: 9
Training loss: 3.0354347229003906
Validation loss: 2.067561258551895

Epoch: 6| Step: 10
Training loss: 2.037247896194458
Validation loss: 2.068379448306176

Epoch: 6| Step: 11
Training loss: 1.8655824661254883
Validation loss: 2.0723521171077603

Epoch: 6| Step: 12
Training loss: 2.0460755825042725
Validation loss: 2.081182097875944

Epoch: 6| Step: 13
Training loss: 1.0151640176773071
Validation loss: 2.082900107547801

Epoch: 103| Step: 0
Training loss: 2.6562185287475586
Validation loss: 2.093680145919964

Epoch: 6| Step: 1
Training loss: 2.567261219024658
Validation loss: 2.0975833272421234

Epoch: 6| Step: 2
Training loss: 1.548196792602539
Validation loss: 2.1148456604250017

Epoch: 6| Step: 3
Training loss: 2.5015408992767334
Validation loss: 2.1203926519681047

Epoch: 6| Step: 4
Training loss: 1.7811317443847656
Validation loss: 2.139777521933279

Epoch: 6| Step: 5
Training loss: 1.4233812093734741
Validation loss: 2.136227438526769

Epoch: 6| Step: 6
Training loss: 1.871421456336975
Validation loss: 2.142939018946822

Epoch: 6| Step: 7
Training loss: 2.431117057800293
Validation loss: 2.1330752077923028

Epoch: 6| Step: 8
Training loss: 2.3149547576904297
Validation loss: 2.1201345946199153

Epoch: 6| Step: 9
Training loss: 2.199735403060913
Validation loss: 2.098690084231797

Epoch: 6| Step: 10
Training loss: 1.8050169944763184
Validation loss: 2.087778009394164

Epoch: 6| Step: 11
Training loss: 2.2583160400390625
Validation loss: 2.0789841144315657

Epoch: 6| Step: 12
Training loss: 1.8177483081817627
Validation loss: 2.0694934091260357

Epoch: 6| Step: 13
Training loss: 2.4343485832214355
Validation loss: 2.065200600572812

Epoch: 104| Step: 0
Training loss: 1.879813551902771
Validation loss: 2.0567314329967705

Epoch: 6| Step: 1
Training loss: 2.1650302410125732
Validation loss: 2.056733981255562

Epoch: 6| Step: 2
Training loss: 1.8770534992218018
Validation loss: 2.049907866344657

Epoch: 6| Step: 3
Training loss: 1.9003665447235107
Validation loss: 2.045764983341258

Epoch: 6| Step: 4
Training loss: 2.4118638038635254
Validation loss: 2.040662634757257

Epoch: 6| Step: 5
Training loss: 2.0875649452209473
Validation loss: 2.051225441758351

Epoch: 6| Step: 6
Training loss: 2.719036102294922
Validation loss: 2.0625915860617035

Epoch: 6| Step: 7
Training loss: 2.2191805839538574
Validation loss: 2.0871111269920104

Epoch: 6| Step: 8
Training loss: 1.676520586013794
Validation loss: 2.094388492645756

Epoch: 6| Step: 9
Training loss: 1.8630549907684326
Validation loss: 2.119354433910821

Epoch: 6| Step: 10
Training loss: 2.5889933109283447
Validation loss: 2.1242297644256265

Epoch: 6| Step: 11
Training loss: 1.813337802886963
Validation loss: 2.139706277078198

Epoch: 6| Step: 12
Training loss: 2.1661205291748047
Validation loss: 2.15480024327514

Epoch: 6| Step: 13
Training loss: 2.528045177459717
Validation loss: 2.1255174593258928

Epoch: 105| Step: 0
Training loss: 2.352334499359131
Validation loss: 2.1174837543118383

Epoch: 6| Step: 1
Training loss: 1.5528075695037842
Validation loss: 2.1100185814724175

Epoch: 6| Step: 2
Training loss: 2.164109230041504
Validation loss: 2.1031687900584233

Epoch: 6| Step: 3
Training loss: 1.6085302829742432
Validation loss: 2.100319788020144

Epoch: 6| Step: 4
Training loss: 1.676198959350586
Validation loss: 2.0999445069220757

Epoch: 6| Step: 5
Training loss: 2.6065776348114014
Validation loss: 2.083148928098781

Epoch: 6| Step: 6
Training loss: 2.129706382751465
Validation loss: 2.077747442389047

Epoch: 6| Step: 7
Training loss: 2.4453439712524414
Validation loss: 2.074162324269613

Epoch: 6| Step: 8
Training loss: 2.2866766452789307
Validation loss: 2.0648716931701987

Epoch: 6| Step: 9
Training loss: 2.4663949012756348
Validation loss: 2.0793853818729358

Epoch: 6| Step: 10
Training loss: 2.197948455810547
Validation loss: 2.091073256666942

Epoch: 6| Step: 11
Training loss: 1.628442645072937
Validation loss: 2.0985858901854484

Epoch: 6| Step: 12
Training loss: 2.051112174987793
Validation loss: 2.0995232494928504

Epoch: 6| Step: 13
Training loss: 1.9414666891098022
Validation loss: 2.0896045802741923

Epoch: 106| Step: 0
Training loss: 1.6288673877716064
Validation loss: 2.087757054195609

Epoch: 6| Step: 1
Training loss: 2.283052444458008
Validation loss: 2.1063604893222934

Epoch: 6| Step: 2
Training loss: 2.3103654384613037
Validation loss: 2.093815085708454

Epoch: 6| Step: 3
Training loss: 2.4302754402160645
Validation loss: 2.0839222041509484

Epoch: 6| Step: 4
Training loss: 1.4656355381011963
Validation loss: 2.0749895418843916

Epoch: 6| Step: 5
Training loss: 2.7588491439819336
Validation loss: 2.0890891475062214

Epoch: 6| Step: 6
Training loss: 2.168161153793335
Validation loss: 2.0807279438100834

Epoch: 6| Step: 7
Training loss: 1.7510647773742676
Validation loss: 2.089577362101565

Epoch: 6| Step: 8
Training loss: 1.7095410823822021
Validation loss: 2.109189118108442

Epoch: 6| Step: 9
Training loss: 1.8085472583770752
Validation loss: 2.140034947344052

Epoch: 6| Step: 10
Training loss: 2.217320442199707
Validation loss: 2.134736817370179

Epoch: 6| Step: 11
Training loss: 1.89410400390625
Validation loss: 2.1083498295917305

Epoch: 6| Step: 12
Training loss: 2.844733476638794
Validation loss: 2.1043938282997376

Epoch: 6| Step: 13
Training loss: 1.9253896474838257
Validation loss: 2.0875518347627375

Epoch: 107| Step: 0
Training loss: 2.3960983753204346
Validation loss: 2.0922933111908617

Epoch: 6| Step: 1
Training loss: 2.02866268157959
Validation loss: 2.090966393870692

Epoch: 6| Step: 2
Training loss: 2.0365467071533203
Validation loss: 2.1116172959727626

Epoch: 6| Step: 3
Training loss: 2.119586944580078
Validation loss: 2.1485996823157034

Epoch: 6| Step: 4
Training loss: 1.9491748809814453
Validation loss: 2.1797062209857407

Epoch: 6| Step: 5
Training loss: 1.7395848035812378
Validation loss: 2.150637262610979

Epoch: 6| Step: 6
Training loss: 2.478764057159424
Validation loss: 2.164114062504102

Epoch: 6| Step: 7
Training loss: 2.1960716247558594
Validation loss: 2.14554492632548

Epoch: 6| Step: 8
Training loss: 2.5796310901641846
Validation loss: 2.1367344240988455

Epoch: 6| Step: 9
Training loss: 1.7913742065429688
Validation loss: 2.130294669059015

Epoch: 6| Step: 10
Training loss: 2.404050827026367
Validation loss: 2.1236909576641616

Epoch: 6| Step: 11
Training loss: 2.0764284133911133
Validation loss: 2.136408717401566

Epoch: 6| Step: 12
Training loss: 1.9263113737106323
Validation loss: 2.179173172161143

Epoch: 6| Step: 13
Training loss: 1.520054817199707
Validation loss: 2.1904035178563928

Epoch: 108| Step: 0
Training loss: 2.8820409774780273
Validation loss: 2.187159833087716

Epoch: 6| Step: 1
Training loss: 2.0692691802978516
Validation loss: 2.1923972227240123

Epoch: 6| Step: 2
Training loss: 2.4285507202148438
Validation loss: 2.1770106156667075

Epoch: 6| Step: 3
Training loss: 1.647669792175293
Validation loss: 2.156808381439537

Epoch: 6| Step: 4
Training loss: 2.126923084259033
Validation loss: 2.1301839684927337

Epoch: 6| Step: 5
Training loss: 2.216948986053467
Validation loss: 2.1172637913816716

Epoch: 6| Step: 6
Training loss: 1.3517255783081055
Validation loss: 2.108391677179644

Epoch: 6| Step: 7
Training loss: 2.4051103591918945
Validation loss: 2.082814049977128

Epoch: 6| Step: 8
Training loss: 1.734637975692749
Validation loss: 2.0570242225482898

Epoch: 6| Step: 9
Training loss: 2.2464277744293213
Validation loss: 2.065044351803359

Epoch: 6| Step: 10
Training loss: 2.0330865383148193
Validation loss: 2.089695235734345

Epoch: 6| Step: 11
Training loss: 2.3091683387756348
Validation loss: 2.1795123674536265

Epoch: 6| Step: 12
Training loss: 2.515230178833008
Validation loss: 2.2346987237212477

Epoch: 6| Step: 13
Training loss: 1.9367209672927856
Validation loss: 2.2321735453862015

Epoch: 109| Step: 0
Training loss: 1.804694414138794
Validation loss: 2.1671597573064987

Epoch: 6| Step: 1
Training loss: 2.1988792419433594
Validation loss: 2.11699330165822

Epoch: 6| Step: 2
Training loss: 1.9270544052124023
Validation loss: 2.07164518807524

Epoch: 6| Step: 3
Training loss: 1.4952917098999023
Validation loss: 2.0502421984108548

Epoch: 6| Step: 4
Training loss: 1.9220197200775146
Validation loss: 2.0514724049516904

Epoch: 6| Step: 5
Training loss: 1.6736059188842773
Validation loss: 2.0504081787601596

Epoch: 6| Step: 6
Training loss: 1.8345510959625244
Validation loss: 2.050465855547177

Epoch: 6| Step: 7
Training loss: 1.5261896848678589
Validation loss: 2.0510835006672847

Epoch: 6| Step: 8
Training loss: 2.2292184829711914
Validation loss: 2.0559214366379606

Epoch: 6| Step: 9
Training loss: 3.0082430839538574
Validation loss: 2.0574287342768844

Epoch: 6| Step: 10
Training loss: 1.4765889644622803
Validation loss: 2.0464625332945134

Epoch: 6| Step: 11
Training loss: 2.6428334712982178
Validation loss: 2.065978063050137

Epoch: 6| Step: 12
Training loss: 2.301464557647705
Validation loss: 2.0788987041801534

Epoch: 6| Step: 13
Training loss: 3.089050769805908
Validation loss: 2.082809866115611

Epoch: 110| Step: 0
Training loss: 1.82371187210083
Validation loss: 2.0677906595250612

Epoch: 6| Step: 1
Training loss: 1.3187617063522339
Validation loss: 2.0478831721890356

Epoch: 6| Step: 2
Training loss: 1.7738009691238403
Validation loss: 2.0525986199737876

Epoch: 6| Step: 3
Training loss: 2.2750244140625
Validation loss: 2.063217601468486

Epoch: 6| Step: 4
Training loss: 1.6014125347137451
Validation loss: 2.073496997997325

Epoch: 6| Step: 5
Training loss: 2.3816590309143066
Validation loss: 2.1061919363596107

Epoch: 6| Step: 6
Training loss: 2.055276870727539
Validation loss: 2.11382548270687

Epoch: 6| Step: 7
Training loss: 2.7462270259857178
Validation loss: 2.11253894400853

Epoch: 6| Step: 8
Training loss: 2.7674214839935303
Validation loss: 2.122370312290807

Epoch: 6| Step: 9
Training loss: 2.274705410003662
Validation loss: 2.1123808814633276

Epoch: 6| Step: 10
Training loss: 1.5023362636566162
Validation loss: 2.1283486376526537

Epoch: 6| Step: 11
Training loss: 1.6935687065124512
Validation loss: 2.1256072854483

Epoch: 6| Step: 12
Training loss: 1.9157660007476807
Validation loss: 2.116722663243612

Epoch: 6| Step: 13
Training loss: 2.339038848876953
Validation loss: 2.1052659147529194

Epoch: 111| Step: 0
Training loss: 1.826369047164917
Validation loss: 2.0881151717196227

Epoch: 6| Step: 1
Training loss: 2.2147347927093506
Validation loss: 2.0958217754158923

Epoch: 6| Step: 2
Training loss: 1.9575552940368652
Validation loss: 2.082008223379812

Epoch: 6| Step: 3
Training loss: 2.138869285583496
Validation loss: 2.077192711573775

Epoch: 6| Step: 4
Training loss: 1.551473617553711
Validation loss: 2.0743476113965436

Epoch: 6| Step: 5
Training loss: 1.9596333503723145
Validation loss: 2.0634760715628184

Epoch: 6| Step: 6
Training loss: 1.993379831314087
Validation loss: 2.0621146694306405

Epoch: 6| Step: 7
Training loss: 2.06996488571167
Validation loss: 2.07093144488591

Epoch: 6| Step: 8
Training loss: 1.5517159700393677
Validation loss: 2.0866562525431314

Epoch: 6| Step: 9
Training loss: 2.2997756004333496
Validation loss: 2.0942226353512017

Epoch: 6| Step: 10
Training loss: 1.6797161102294922
Validation loss: 2.1087623360336467

Epoch: 6| Step: 11
Training loss: 2.5720150470733643
Validation loss: 2.117186887289888

Epoch: 6| Step: 12
Training loss: 2.4794442653656006
Validation loss: 2.142743936149023

Epoch: 6| Step: 13
Training loss: 1.9358956813812256
Validation loss: 2.1444527282509753

Epoch: 112| Step: 0
Training loss: 1.4710124731063843
Validation loss: 2.1335440963827152

Epoch: 6| Step: 1
Training loss: 2.0176587104797363
Validation loss: 2.125296467094011

Epoch: 6| Step: 2
Training loss: 2.3888487815856934
Validation loss: 2.1353732309033795

Epoch: 6| Step: 3
Training loss: 2.264878749847412
Validation loss: 2.1340532277220037

Epoch: 6| Step: 4
Training loss: 1.8457022905349731
Validation loss: 2.122299542991064

Epoch: 6| Step: 5
Training loss: 1.3149985074996948
Validation loss: 2.1000091516843407

Epoch: 6| Step: 6
Training loss: 1.9722051620483398
Validation loss: 2.07065349753185

Epoch: 6| Step: 7
Training loss: 1.6095085144042969
Validation loss: 2.0560236643719416

Epoch: 6| Step: 8
Training loss: 1.909507155418396
Validation loss: 2.0566511948903403

Epoch: 6| Step: 9
Training loss: 2.538226842880249
Validation loss: 2.060920238494873

Epoch: 6| Step: 10
Training loss: 3.503603458404541
Validation loss: 2.0798801311882595

Epoch: 6| Step: 11
Training loss: 1.6123037338256836
Validation loss: 2.0707931826191563

Epoch: 6| Step: 12
Training loss: 1.5942978858947754
Validation loss: 2.083167870839437

Epoch: 6| Step: 13
Training loss: 1.6914024353027344
Validation loss: 2.071909596843104

Epoch: 113| Step: 0
Training loss: 3.0064969062805176
Validation loss: 2.0802786055431572

Epoch: 6| Step: 1
Training loss: 1.8277626037597656
Validation loss: 2.0835269317832044

Epoch: 6| Step: 2
Training loss: 2.0404088497161865
Validation loss: 2.0970269967150945

Epoch: 6| Step: 3
Training loss: 1.3374428749084473
Validation loss: 2.111960240589675

Epoch: 6| Step: 4
Training loss: 2.1085708141326904
Validation loss: 2.1219488971976825

Epoch: 6| Step: 5
Training loss: 2.272287368774414
Validation loss: 2.1675259220984673

Epoch: 6| Step: 6
Training loss: 2.1663403511047363
Validation loss: 2.177396066727177

Epoch: 6| Step: 7
Training loss: 1.4292348623275757
Validation loss: 2.168100792874572

Epoch: 6| Step: 8
Training loss: 2.8800830841064453
Validation loss: 2.170458045057071

Epoch: 6| Step: 9
Training loss: 1.7473664283752441
Validation loss: 2.1670915875383603

Epoch: 6| Step: 10
Training loss: 1.3707644939422607
Validation loss: 2.195515622374832

Epoch: 6| Step: 11
Training loss: 1.9862990379333496
Validation loss: 2.219564699357556

Epoch: 6| Step: 12
Training loss: 2.3147079944610596
Validation loss: 2.2092912991841636

Epoch: 6| Step: 13
Training loss: 2.277693748474121
Validation loss: 2.1890097074611212

Epoch: 114| Step: 0
Training loss: 2.3392817974090576
Validation loss: 2.2061593647926085

Epoch: 6| Step: 1
Training loss: 1.5369443893432617
Validation loss: 2.2107360004096903

Epoch: 6| Step: 2
Training loss: 1.7242071628570557
Validation loss: 2.186243934016074

Epoch: 6| Step: 3
Training loss: 1.750322699546814
Validation loss: 2.16196209128185

Epoch: 6| Step: 4
Training loss: 1.7779372930526733
Validation loss: 2.1382125628891813

Epoch: 6| Step: 5
Training loss: 1.635948896408081
Validation loss: 2.133737849932845

Epoch: 6| Step: 6
Training loss: 3.1809463500976562
Validation loss: 2.132471194831274

Epoch: 6| Step: 7
Training loss: 2.250753879547119
Validation loss: 2.1007486568984164

Epoch: 6| Step: 8
Training loss: 2.5222725868225098
Validation loss: 2.0942435162041777

Epoch: 6| Step: 9
Training loss: 1.916067123413086
Validation loss: 2.093632457076862

Epoch: 6| Step: 10
Training loss: 2.932866334915161
Validation loss: 2.0830431484406993

Epoch: 6| Step: 11
Training loss: 1.426961898803711
Validation loss: 2.0630179938449653

Epoch: 6| Step: 12
Training loss: 1.4837340116500854
Validation loss: 2.0540087120507353

Epoch: 6| Step: 13
Training loss: 1.7737382650375366
Validation loss: 2.0502309888921757

Epoch: 115| Step: 0
Training loss: 2.7866811752319336
Validation loss: 2.066895684888286

Epoch: 6| Step: 1
Training loss: 1.8268128633499146
Validation loss: 2.081255538489229

Epoch: 6| Step: 2
Training loss: 2.1480557918548584
Validation loss: 2.1000079442096014

Epoch: 6| Step: 3
Training loss: 1.9431488513946533
Validation loss: 2.096151433965211

Epoch: 6| Step: 4
Training loss: 2.01863694190979
Validation loss: 2.0822159064713346

Epoch: 6| Step: 5
Training loss: 2.389335870742798
Validation loss: 2.047288292197771

Epoch: 6| Step: 6
Training loss: 2.214308977127075
Validation loss: 2.0356193447625763

Epoch: 6| Step: 7
Training loss: 2.2787351608276367
Validation loss: 2.0410215162461802

Epoch: 6| Step: 8
Training loss: 1.7833021879196167
Validation loss: 2.0570528584141887

Epoch: 6| Step: 9
Training loss: 2.2162671089172363
Validation loss: 2.062130653730003

Epoch: 6| Step: 10
Training loss: 1.5125126838684082
Validation loss: 2.084504060847785

Epoch: 6| Step: 11
Training loss: 1.4725948572158813
Validation loss: 2.111369599578201

Epoch: 6| Step: 12
Training loss: 1.8198678493499756
Validation loss: 2.1391121161881315

Epoch: 6| Step: 13
Training loss: 1.7591445446014404
Validation loss: 2.1558166370596936

Epoch: 116| Step: 0
Training loss: 1.7671703100204468
Validation loss: 2.179242628876881

Epoch: 6| Step: 1
Training loss: 1.4409780502319336
Validation loss: 2.211872072630031

Epoch: 6| Step: 2
Training loss: 1.8832056522369385
Validation loss: 2.2510620778606785

Epoch: 6| Step: 3
Training loss: 2.2280616760253906
Validation loss: 2.301027282591789

Epoch: 6| Step: 4
Training loss: 2.106414794921875
Validation loss: 2.298928899149741

Epoch: 6| Step: 5
Training loss: 2.3719043731689453
Validation loss: 2.299292701546864

Epoch: 6| Step: 6
Training loss: 1.8444929122924805
Validation loss: 2.2538529980567192

Epoch: 6| Step: 7
Training loss: 2.433204174041748
Validation loss: 2.214306867250832

Epoch: 6| Step: 8
Training loss: 1.7364262342453003
Validation loss: 2.1549605220876713

Epoch: 6| Step: 9
Training loss: 1.7544710636138916
Validation loss: 2.1093670552776707

Epoch: 6| Step: 10
Training loss: 1.6227426528930664
Validation loss: 2.067108110714984

Epoch: 6| Step: 11
Training loss: 2.2196993827819824
Validation loss: 2.0534114235190937

Epoch: 6| Step: 12
Training loss: 1.8471612930297852
Validation loss: 2.046908091473323

Epoch: 6| Step: 13
Training loss: 3.0496842861175537
Validation loss: 2.0420466007724887

Epoch: 117| Step: 0
Training loss: 1.7032872438430786
Validation loss: 2.0350955160715247

Epoch: 6| Step: 1
Training loss: 2.4160919189453125
Validation loss: 2.0202649818953646

Epoch: 6| Step: 2
Training loss: 2.455054759979248
Validation loss: 2.014118468889626

Epoch: 6| Step: 3
Training loss: 1.822946310043335
Validation loss: 2.017925799533885

Epoch: 6| Step: 4
Training loss: 1.9232720136642456
Validation loss: 2.0227864224423646

Epoch: 6| Step: 5
Training loss: 2.117293357849121
Validation loss: 2.0225649815733715

Epoch: 6| Step: 6
Training loss: 2.389808177947998
Validation loss: 2.018972360959617

Epoch: 6| Step: 7
Training loss: 1.8196732997894287
Validation loss: 2.0323772212510467

Epoch: 6| Step: 8
Training loss: 1.473264455795288
Validation loss: 2.0418078578928465

Epoch: 6| Step: 9
Training loss: 1.9467735290527344
Validation loss: 2.0448413459203576

Epoch: 6| Step: 10
Training loss: 2.620871067047119
Validation loss: 2.0728241846125615

Epoch: 6| Step: 11
Training loss: 1.7493257522583008
Validation loss: 2.0705283072686966

Epoch: 6| Step: 12
Training loss: 1.8493313789367676
Validation loss: 2.063445959039914

Epoch: 6| Step: 13
Training loss: 1.746946930885315
Validation loss: 2.0468771765308995

Epoch: 118| Step: 0
Training loss: 2.090873956680298
Validation loss: 2.04032487510353

Epoch: 6| Step: 1
Training loss: 2.1397297382354736
Validation loss: 2.0288005875002955

Epoch: 6| Step: 2
Training loss: 1.6975480318069458
Validation loss: 2.0368690567631877

Epoch: 6| Step: 3
Training loss: 1.8474979400634766
Validation loss: 2.035646609080735

Epoch: 6| Step: 4
Training loss: 1.7563059329986572
Validation loss: 2.0598902112694195

Epoch: 6| Step: 5
Training loss: 1.8412361145019531
Validation loss: 2.08667274572516

Epoch: 6| Step: 6
Training loss: 1.8443336486816406
Validation loss: 2.1418438649946645

Epoch: 6| Step: 7
Training loss: 1.9239314794540405
Validation loss: 2.150084972381592

Epoch: 6| Step: 8
Training loss: 2.1961510181427
Validation loss: 2.1415908093093545

Epoch: 6| Step: 9
Training loss: 2.278463363647461
Validation loss: 2.129558773450954

Epoch: 6| Step: 10
Training loss: 1.830669641494751
Validation loss: 2.0975261708741546

Epoch: 6| Step: 11
Training loss: 2.3585317134857178
Validation loss: 2.0979024992194226

Epoch: 6| Step: 12
Training loss: 2.2119672298431396
Validation loss: 2.105495076025686

Epoch: 6| Step: 13
Training loss: 0.931645929813385
Validation loss: 2.1149207622774187

Epoch: 119| Step: 0
Training loss: 2.1792688369750977
Validation loss: 2.108680268769623

Epoch: 6| Step: 1
Training loss: 2.125504493713379
Validation loss: 2.129648562400572

Epoch: 6| Step: 2
Training loss: 1.646674394607544
Validation loss: 2.150178711901429

Epoch: 6| Step: 3
Training loss: 1.7360317707061768
Validation loss: 2.136988898759247

Epoch: 6| Step: 4
Training loss: 2.116217851638794
Validation loss: 2.1073509352181548

Epoch: 6| Step: 5
Training loss: 1.7834386825561523
Validation loss: 2.0937409272757908

Epoch: 6| Step: 6
Training loss: 2.0139946937561035
Validation loss: 2.068566499217864

Epoch: 6| Step: 7
Training loss: 2.2677671909332275
Validation loss: 2.061672320929907

Epoch: 6| Step: 8
Training loss: 1.3000397682189941
Validation loss: 2.0466992316707486

Epoch: 6| Step: 9
Training loss: 2.1155459880828857
Validation loss: 2.0388539503979426

Epoch: 6| Step: 10
Training loss: 2.1616196632385254
Validation loss: 2.021433996897872

Epoch: 6| Step: 11
Training loss: 1.9013150930404663
Validation loss: 2.0111455250811834

Epoch: 6| Step: 12
Training loss: 2.1647539138793945
Validation loss: 2.0286093988726215

Epoch: 6| Step: 13
Training loss: 1.5435518026351929
Validation loss: 2.0262994535507692

Epoch: 120| Step: 0
Training loss: 1.7927796840667725
Validation loss: 2.0322400498133835

Epoch: 6| Step: 1
Training loss: 1.2267855405807495
Validation loss: 2.0470858209876606

Epoch: 6| Step: 2
Training loss: 2.2940573692321777
Validation loss: 2.052288827075753

Epoch: 6| Step: 3
Training loss: 1.5908598899841309
Validation loss: 2.0612641765225317

Epoch: 6| Step: 4
Training loss: 1.8656178712844849
Validation loss: 2.0638678304610716

Epoch: 6| Step: 5
Training loss: 2.3088834285736084
Validation loss: 2.050981924098025

Epoch: 6| Step: 6
Training loss: 2.031184196472168
Validation loss: 2.063978669463947

Epoch: 6| Step: 7
Training loss: 2.1565866470336914
Validation loss: 2.0497937458817677

Epoch: 6| Step: 8
Training loss: 2.5535385608673096
Validation loss: 2.035780850277152

Epoch: 6| Step: 9
Training loss: 2.161349296569824
Validation loss: 2.0436027960110734

Epoch: 6| Step: 10
Training loss: 1.5899052619934082
Validation loss: 2.049014127382668

Epoch: 6| Step: 11
Training loss: 1.5986573696136475
Validation loss: 2.0685723981549664

Epoch: 6| Step: 12
Training loss: 1.9287996292114258
Validation loss: 2.102170939086586

Epoch: 6| Step: 13
Training loss: 1.6166926622390747
Validation loss: 2.118371496918381

Epoch: 121| Step: 0
Training loss: 1.8492822647094727
Validation loss: 2.137281422973961

Epoch: 6| Step: 1
Training loss: 1.5085334777832031
Validation loss: 2.150664550001903

Epoch: 6| Step: 2
Training loss: 1.9781941175460815
Validation loss: 2.1578001796558337

Epoch: 6| Step: 3
Training loss: 2.2072086334228516
Validation loss: 2.160961271614157

Epoch: 6| Step: 4
Training loss: 2.2342071533203125
Validation loss: 2.1403359866911367

Epoch: 6| Step: 5
Training loss: 1.5754249095916748
Validation loss: 2.1305174084119898

Epoch: 6| Step: 6
Training loss: 2.447727680206299
Validation loss: 2.136136016538066

Epoch: 6| Step: 7
Training loss: 1.7716574668884277
Validation loss: 2.1179562435355237

Epoch: 6| Step: 8
Training loss: 1.5803982019424438
Validation loss: 2.1065485221083446

Epoch: 6| Step: 9
Training loss: 1.848314642906189
Validation loss: 2.07287758909246

Epoch: 6| Step: 10
Training loss: 1.652811050415039
Validation loss: 2.060622476762341

Epoch: 6| Step: 11
Training loss: 2.3446059226989746
Validation loss: 2.0308589217483357

Epoch: 6| Step: 12
Training loss: 2.1694297790527344
Validation loss: 2.030345114328528

Epoch: 6| Step: 13
Training loss: 1.4992663860321045
Validation loss: 2.0127152601877847

Epoch: 122| Step: 0
Training loss: 1.5744445323944092
Validation loss: 2.0282626126402166

Epoch: 6| Step: 1
Training loss: 1.8241949081420898
Validation loss: 2.020902128629787

Epoch: 6| Step: 2
Training loss: 2.1210947036743164
Validation loss: 2.0507431748092815

Epoch: 6| Step: 3
Training loss: 2.4574320316314697
Validation loss: 2.0451515823282223

Epoch: 6| Step: 4
Training loss: 1.6811667680740356
Validation loss: 2.0502105938491

Epoch: 6| Step: 5
Training loss: 1.8326212167739868
Validation loss: 2.052161516681794

Epoch: 6| Step: 6
Training loss: 1.6628236770629883
Validation loss: 2.056661452016523

Epoch: 6| Step: 7
Training loss: 2.320995330810547
Validation loss: 2.0404731124959965

Epoch: 6| Step: 8
Training loss: 1.5405704975128174
Validation loss: 2.0469042485760105

Epoch: 6| Step: 9
Training loss: 1.616100549697876
Validation loss: 2.05231100128543

Epoch: 6| Step: 10
Training loss: 2.3219923973083496
Validation loss: 2.067426350808913

Epoch: 6| Step: 11
Training loss: 1.801493525505066
Validation loss: 2.0799165502671273

Epoch: 6| Step: 12
Training loss: 1.433584451675415
Validation loss: 2.075878186892438

Epoch: 6| Step: 13
Training loss: 1.9575743675231934
Validation loss: 2.0893059084492345

Epoch: 123| Step: 0
Training loss: 1.1179789304733276
Validation loss: 2.0632969038460844

Epoch: 6| Step: 1
Training loss: 2.0096185207366943
Validation loss: 2.081003504414712

Epoch: 6| Step: 2
Training loss: 2.523660182952881
Validation loss: 2.0938960108705746

Epoch: 6| Step: 3
Training loss: 2.3331236839294434
Validation loss: 2.0967161424698366

Epoch: 6| Step: 4
Training loss: 1.6822506189346313
Validation loss: 2.1120628387697282

Epoch: 6| Step: 5
Training loss: 2.037198543548584
Validation loss: 2.1087152214460474

Epoch: 6| Step: 6
Training loss: 1.6958746910095215
Validation loss: 2.11607349816189

Epoch: 6| Step: 7
Training loss: 1.953385591506958
Validation loss: 2.1187499287307903

Epoch: 6| Step: 8
Training loss: 1.3289427757263184
Validation loss: 2.11260558712867

Epoch: 6| Step: 9
Training loss: 1.6073391437530518
Validation loss: 2.122491031564692

Epoch: 6| Step: 10
Training loss: 2.5682873725891113
Validation loss: 2.1101802677236576

Epoch: 6| Step: 11
Training loss: 1.5679748058319092
Validation loss: 2.1164130267276557

Epoch: 6| Step: 12
Training loss: 1.809617519378662
Validation loss: 2.105220781859531

Epoch: 6| Step: 13
Training loss: 1.4924472570419312
Validation loss: 2.0908366198180826

Epoch: 124| Step: 0
Training loss: 2.079690456390381
Validation loss: 2.0660776502342633

Epoch: 6| Step: 1
Training loss: 1.901875615119934
Validation loss: 2.0693086603636384

Epoch: 6| Step: 2
Training loss: 2.3351798057556152
Validation loss: 2.0582618918470157

Epoch: 6| Step: 3
Training loss: 1.863783359527588
Validation loss: 2.063890726335587

Epoch: 6| Step: 4
Training loss: 1.775327444076538
Validation loss: 2.059713613602423

Epoch: 6| Step: 5
Training loss: 2.081538677215576
Validation loss: 2.0562085566982145

Epoch: 6| Step: 6
Training loss: 1.786037564277649
Validation loss: 2.043408473332723

Epoch: 6| Step: 7
Training loss: 2.387892246246338
Validation loss: 2.035781145095825

Epoch: 6| Step: 8
Training loss: 2.1080880165100098
Validation loss: 2.040291276029361

Epoch: 6| Step: 9
Training loss: 1.705071210861206
Validation loss: 2.0459927000025266

Epoch: 6| Step: 10
Training loss: 1.2352311611175537
Validation loss: 2.045325202326621

Epoch: 6| Step: 11
Training loss: 1.577955961227417
Validation loss: 2.0599022488440237

Epoch: 6| Step: 12
Training loss: 1.0032057762145996
Validation loss: 2.0708840329159974

Epoch: 6| Step: 13
Training loss: 1.56636381149292
Validation loss: 2.079956736615909

Epoch: 125| Step: 0
Training loss: 2.3187336921691895
Validation loss: 2.0549795948049074

Epoch: 6| Step: 1
Training loss: 1.2307791709899902
Validation loss: 2.0534772898561213

Epoch: 6| Step: 2
Training loss: 2.000779628753662
Validation loss: 2.0467453925840315

Epoch: 6| Step: 3
Training loss: 1.4164865016937256
Validation loss: 2.0559751064546647

Epoch: 6| Step: 4
Training loss: 1.9955800771713257
Validation loss: 2.0546617892480667

Epoch: 6| Step: 5
Training loss: 2.046147346496582
Validation loss: 2.0747339161493445

Epoch: 6| Step: 6
Training loss: 1.6240191459655762
Validation loss: 2.100957783319617

Epoch: 6| Step: 7
Training loss: 1.3683624267578125
Validation loss: 2.0822578976231236

Epoch: 6| Step: 8
Training loss: 2.2080490589141846
Validation loss: 2.076030082600091

Epoch: 6| Step: 9
Training loss: 1.7378661632537842
Validation loss: 2.0849615040645806

Epoch: 6| Step: 10
Training loss: 1.594975471496582
Validation loss: 2.078734185106011

Epoch: 6| Step: 11
Training loss: 1.9767932891845703
Validation loss: 2.0432137917446833

Epoch: 6| Step: 12
Training loss: 2.2162885665893555
Validation loss: 2.0395671988046296

Epoch: 6| Step: 13
Training loss: 1.6071934700012207
Validation loss: 2.026782134527801

Epoch: 126| Step: 0
Training loss: 2.1172046661376953
Validation loss: 2.02438784158358

Epoch: 6| Step: 1
Training loss: 1.7009549140930176
Validation loss: 2.0257764477883615

Epoch: 6| Step: 2
Training loss: 1.7741001844406128
Validation loss: 2.027144375667777

Epoch: 6| Step: 3
Training loss: 1.13864004611969
Validation loss: 2.057480663381597

Epoch: 6| Step: 4
Training loss: 1.6466615200042725
Validation loss: 2.0661026457304597

Epoch: 6| Step: 5
Training loss: 2.0030598640441895
Validation loss: 2.08647749757254

Epoch: 6| Step: 6
Training loss: 2.1728596687316895
Validation loss: 2.0519725507305515

Epoch: 6| Step: 7
Training loss: 1.9227639436721802
Validation loss: 2.0560696996668333

Epoch: 6| Step: 8
Training loss: 1.5387697219848633
Validation loss: 2.0500006957720687

Epoch: 6| Step: 9
Training loss: 2.2421655654907227
Validation loss: 2.072235425313314

Epoch: 6| Step: 10
Training loss: 1.47205650806427
Validation loss: 2.07955495003731

Epoch: 6| Step: 11
Training loss: 1.6024260520935059
Validation loss: 2.0796658787676083

Epoch: 6| Step: 12
Training loss: 1.8357555866241455
Validation loss: 2.069556279848981

Epoch: 6| Step: 13
Training loss: 1.9334166049957275
Validation loss: 2.0701054450004333

Epoch: 127| Step: 0
Training loss: 1.4177802801132202
Validation loss: 2.0616962140606296

Epoch: 6| Step: 1
Training loss: 2.2312726974487305
Validation loss: 2.058195919118902

Epoch: 6| Step: 2
Training loss: 1.4315650463104248
Validation loss: 2.0582288695919897

Epoch: 6| Step: 3
Training loss: 1.8284988403320312
Validation loss: 2.0699091893370434

Epoch: 6| Step: 4
Training loss: 2.4455487728118896
Validation loss: 2.0684886247881

Epoch: 6| Step: 5
Training loss: 1.743424892425537
Validation loss: 2.0874280186109644

Epoch: 6| Step: 6
Training loss: 1.2831348180770874
Validation loss: 2.094646139811444

Epoch: 6| Step: 7
Training loss: 1.461430311203003
Validation loss: 2.0944169234204035

Epoch: 6| Step: 8
Training loss: 1.7912652492523193
Validation loss: 2.105785701864509

Epoch: 6| Step: 9
Training loss: 1.6812498569488525
Validation loss: 2.116888851247808

Epoch: 6| Step: 10
Training loss: 1.3001121282577515
Validation loss: 2.0889825795286443

Epoch: 6| Step: 11
Training loss: 2.5331344604492188
Validation loss: 2.069062363716864

Epoch: 6| Step: 12
Training loss: 1.6786887645721436
Validation loss: 2.0493143514920305

Epoch: 6| Step: 13
Training loss: 2.2518539428710938
Validation loss: 2.0304928069473593

Epoch: 128| Step: 0
Training loss: 1.7164084911346436
Validation loss: 2.019734642838919

Epoch: 6| Step: 1
Training loss: 1.0798799991607666
Validation loss: 2.04287431316991

Epoch: 6| Step: 2
Training loss: 2.4435067176818848
Validation loss: 2.0463617129992415

Epoch: 6| Step: 3
Training loss: 1.8330096006393433
Validation loss: 2.0340063879566808

Epoch: 6| Step: 4
Training loss: 1.7671494483947754
Validation loss: 2.045831173978826

Epoch: 6| Step: 5
Training loss: 1.9835021495819092
Validation loss: 2.0719386864733953

Epoch: 6| Step: 6
Training loss: 1.8396152257919312
Validation loss: 2.0521376235510713

Epoch: 6| Step: 7
Training loss: 1.76837956905365
Validation loss: 2.044626666653541

Epoch: 6| Step: 8
Training loss: 1.7707884311676025
Validation loss: 2.045334085341423

Epoch: 6| Step: 9
Training loss: 1.742324948310852
Validation loss: 2.0415145351040747

Epoch: 6| Step: 10
Training loss: 2.1096720695495605
Validation loss: 2.052671904204994

Epoch: 6| Step: 11
Training loss: 1.7706539630889893
Validation loss: 2.0568906466166177

Epoch: 6| Step: 12
Training loss: 1.6068694591522217
Validation loss: 2.0774004344017274

Epoch: 6| Step: 13
Training loss: 1.1458100080490112
Validation loss: 2.0785430092965402

Epoch: 129| Step: 0
Training loss: 1.183109998703003
Validation loss: 2.077915117304812

Epoch: 6| Step: 1
Training loss: 2.0240297317504883
Validation loss: 2.0729844236886628

Epoch: 6| Step: 2
Training loss: 2.491591453552246
Validation loss: 2.0348366704038394

Epoch: 6| Step: 3
Training loss: 1.891424298286438
Validation loss: 2.027327160681448

Epoch: 6| Step: 4
Training loss: 1.801722526550293
Validation loss: 2.0455325162538918

Epoch: 6| Step: 5
Training loss: 1.1782541275024414
Validation loss: 2.075489213389735

Epoch: 6| Step: 6
Training loss: 1.6014955043792725
Validation loss: 2.072533046045611

Epoch: 6| Step: 7
Training loss: 1.4257755279541016
Validation loss: 2.075386196054438

Epoch: 6| Step: 8
Training loss: 1.6598970890045166
Validation loss: 2.0731248522317536

Epoch: 6| Step: 9
Training loss: 2.1584949493408203
Validation loss: 2.0347051543574177

Epoch: 6| Step: 10
Training loss: 2.2492823600769043
Validation loss: 2.0413452425310687

Epoch: 6| Step: 11
Training loss: 1.749354362487793
Validation loss: 2.0144993848698114

Epoch: 6| Step: 12
Training loss: 1.7528674602508545
Validation loss: 1.9981380739519674

Epoch: 6| Step: 13
Training loss: 1.3482611179351807
Validation loss: 2.0034876818298013

Epoch: 130| Step: 0
Training loss: 2.002317190170288
Validation loss: 1.9948550860087078

Epoch: 6| Step: 1
Training loss: 1.6267940998077393
Validation loss: 2.010210091067899

Epoch: 6| Step: 2
Training loss: 1.7794345617294312
Validation loss: 1.9972648838514924

Epoch: 6| Step: 3
Training loss: 0.9923766851425171
Validation loss: 2.009520055145346

Epoch: 6| Step: 4
Training loss: 1.3775086402893066
Validation loss: 2.0350848500446608

Epoch: 6| Step: 5
Training loss: 2.4741337299346924
Validation loss: 2.0459530174091296

Epoch: 6| Step: 6
Training loss: 1.4704829454421997
Validation loss: 2.074648611007198

Epoch: 6| Step: 7
Training loss: 1.9039722681045532
Validation loss: 2.0906128473179315

Epoch: 6| Step: 8
Training loss: 1.5498515367507935
Validation loss: 2.101556724117648

Epoch: 6| Step: 9
Training loss: 2.063046932220459
Validation loss: 2.1052615027273855

Epoch: 6| Step: 10
Training loss: 1.7476593255996704
Validation loss: 2.098268278183476

Epoch: 6| Step: 11
Training loss: 1.95628821849823
Validation loss: 2.083323569707973

Epoch: 6| Step: 12
Training loss: 1.974129557609558
Validation loss: 2.0708905778905398

Epoch: 6| Step: 13
Training loss: 1.3976396322250366
Validation loss: 2.0384124991714314

Epoch: 131| Step: 0
Training loss: 1.6515634059906006
Validation loss: 2.032012144724528

Epoch: 6| Step: 1
Training loss: 1.5919747352600098
Validation loss: 2.048994243785899

Epoch: 6| Step: 2
Training loss: 1.4613227844238281
Validation loss: 2.040923532619271

Epoch: 6| Step: 3
Training loss: 1.7843830585479736
Validation loss: 2.0418190930479314

Epoch: 6| Step: 4
Training loss: 1.7669670581817627
Validation loss: 2.039106366454914

Epoch: 6| Step: 5
Training loss: 1.7883418798446655
Validation loss: 2.037180951846543

Epoch: 6| Step: 6
Training loss: 1.4541082382202148
Validation loss: 2.0584307575738556

Epoch: 6| Step: 7
Training loss: 1.4775818586349487
Validation loss: 2.063971186196932

Epoch: 6| Step: 8
Training loss: 2.0163931846618652
Validation loss: 2.0462330028574955

Epoch: 6| Step: 9
Training loss: 2.2170510292053223
Validation loss: 2.0412726479191936

Epoch: 6| Step: 10
Training loss: 1.3110473155975342
Validation loss: 2.0351291343729985

Epoch: 6| Step: 11
Training loss: 2.3183326721191406
Validation loss: 2.0003659584188975

Epoch: 6| Step: 12
Training loss: 1.4966344833374023
Validation loss: 2.002056634554299

Epoch: 6| Step: 13
Training loss: 1.4970883131027222
Validation loss: 2.0013935437766452

Epoch: 132| Step: 0
Training loss: 1.4682927131652832
Validation loss: 1.996651823802661

Epoch: 6| Step: 1
Training loss: 1.981542944908142
Validation loss: 1.9853895377087336

Epoch: 6| Step: 2
Training loss: 1.568955898284912
Validation loss: 2.008738253706245

Epoch: 6| Step: 3
Training loss: 1.9000087976455688
Validation loss: 2.0053050825672765

Epoch: 6| Step: 4
Training loss: 1.595262050628662
Validation loss: 2.0156862876748525

Epoch: 6| Step: 5
Training loss: 1.0450077056884766
Validation loss: 2.0298631280981083

Epoch: 6| Step: 6
Training loss: 1.6478335857391357
Validation loss: 2.031911874330172

Epoch: 6| Step: 7
Training loss: 1.4871883392333984
Validation loss: 2.0556357496528217

Epoch: 6| Step: 8
Training loss: 1.4137835502624512
Validation loss: 2.082959823710944

Epoch: 6| Step: 9
Training loss: 1.5659407377243042
Validation loss: 2.108260284187973

Epoch: 6| Step: 10
Training loss: 1.8255349397659302
Validation loss: 2.1356101843618576

Epoch: 6| Step: 11
Training loss: 2.053967237472534
Validation loss: 2.1308320670999508

Epoch: 6| Step: 12
Training loss: 2.4115240573883057
Validation loss: 2.128499702740741

Epoch: 6| Step: 13
Training loss: 1.7104151248931885
Validation loss: 2.106087315467096

Epoch: 133| Step: 0
Training loss: 1.6622353792190552
Validation loss: 2.095376665874194

Epoch: 6| Step: 1
Training loss: 2.1136837005615234
Validation loss: 2.0565293629964194

Epoch: 6| Step: 2
Training loss: 1.5424975156784058
Validation loss: 2.0227651314068864

Epoch: 6| Step: 3
Training loss: 1.2927888631820679
Validation loss: 2.0066821523891982

Epoch: 6| Step: 4
Training loss: 1.769195556640625
Validation loss: 2.0006892104302683

Epoch: 6| Step: 5
Training loss: 1.6641188859939575
Validation loss: 2.00739352421094

Epoch: 6| Step: 6
Training loss: 1.5690891742706299
Validation loss: 1.9991002928826116

Epoch: 6| Step: 7
Training loss: 1.9394209384918213
Validation loss: 2.006978475919334

Epoch: 6| Step: 8
Training loss: 1.3268117904663086
Validation loss: 2.0123304961830057

Epoch: 6| Step: 9
Training loss: 1.9931387901306152
Validation loss: 2.01400593532029

Epoch: 6| Step: 10
Training loss: 1.7638201713562012
Validation loss: 2.072601181204601

Epoch: 6| Step: 11
Training loss: 1.731433629989624
Validation loss: 2.1223473215615876

Epoch: 6| Step: 12
Training loss: 1.293559193611145
Validation loss: 2.1417659444193684

Epoch: 6| Step: 13
Training loss: 1.9858050346374512
Validation loss: 2.1425595462963147

Epoch: 134| Step: 0
Training loss: 1.3444623947143555
Validation loss: 2.1152312178765573

Epoch: 6| Step: 1
Training loss: 1.72804856300354
Validation loss: 2.0984732925250964

Epoch: 6| Step: 2
Training loss: 1.4574317932128906
Validation loss: 2.06029039172716

Epoch: 6| Step: 3
Training loss: 1.7254085540771484
Validation loss: 2.019221149465089

Epoch: 6| Step: 4
Training loss: 2.2289671897888184
Validation loss: 2.023310658752277

Epoch: 6| Step: 5
Training loss: 1.7243967056274414
Validation loss: 2.0220864062668173

Epoch: 6| Step: 6
Training loss: 1.9298840761184692
Validation loss: 2.0429595208937124

Epoch: 6| Step: 7
Training loss: 2.0100674629211426
Validation loss: 2.031525311931487

Epoch: 6| Step: 8
Training loss: 1.8837554454803467
Validation loss: 2.027386483325753

Epoch: 6| Step: 9
Training loss: 1.4898533821105957
Validation loss: 2.02681545031968

Epoch: 6| Step: 10
Training loss: 1.0981460809707642
Validation loss: 2.0361580553875176

Epoch: 6| Step: 11
Training loss: 1.5449893474578857
Validation loss: 2.0599297682444253

Epoch: 6| Step: 12
Training loss: 1.7329158782958984
Validation loss: 2.0783238410949707

Epoch: 6| Step: 13
Training loss: 1.1293137073516846
Validation loss: 2.102548953025572

Epoch: 135| Step: 0
Training loss: 2.6015055179595947
Validation loss: 2.098672338711318

Epoch: 6| Step: 1
Training loss: 1.5188833475112915
Validation loss: 2.0699746660006944

Epoch: 6| Step: 2
Training loss: 1.3023428916931152
Validation loss: 2.0513375728361067

Epoch: 6| Step: 3
Training loss: 1.8418365716934204
Validation loss: 2.055743848123858

Epoch: 6| Step: 4
Training loss: 1.4841928482055664
Validation loss: 2.0392303671888126

Epoch: 6| Step: 5
Training loss: 2.0955848693847656
Validation loss: 2.0707887500844975

Epoch: 6| Step: 6
Training loss: 1.6276756525039673
Validation loss: 2.0992130118031658

Epoch: 6| Step: 7
Training loss: 1.8590750694274902
Validation loss: 2.1187404240331342

Epoch: 6| Step: 8
Training loss: 1.780620813369751
Validation loss: 2.124239044804727

Epoch: 6| Step: 9
Training loss: 1.269298791885376
Validation loss: 2.0992391186375774

Epoch: 6| Step: 10
Training loss: 1.1704645156860352
Validation loss: 2.0900558092260875

Epoch: 6| Step: 11
Training loss: 1.3306636810302734
Validation loss: 2.0636663616344495

Epoch: 6| Step: 12
Training loss: 1.6768248081207275
Validation loss: 2.0736769322426087

Epoch: 6| Step: 13
Training loss: 1.7133278846740723
Validation loss: 2.077744981294037

Epoch: 136| Step: 0
Training loss: 1.8440237045288086
Validation loss: 2.0978049027022494

Epoch: 6| Step: 1
Training loss: 1.9495127201080322
Validation loss: 2.083777686601044

Epoch: 6| Step: 2
Training loss: 1.7296708822250366
Validation loss: 2.0700526852761545

Epoch: 6| Step: 3
Training loss: 1.6836529970169067
Validation loss: 2.048924825524771

Epoch: 6| Step: 4
Training loss: 1.460797667503357
Validation loss: 2.010605888981973

Epoch: 6| Step: 5
Training loss: 1.9661883115768433
Validation loss: 2.0131627000788206

Epoch: 6| Step: 6
Training loss: 1.4134225845336914
Validation loss: 2.0439637130306614

Epoch: 6| Step: 7
Training loss: 1.8089097738265991
Validation loss: 2.0479070858288835

Epoch: 6| Step: 8
Training loss: 0.8740907907485962
Validation loss: 2.045930608626335

Epoch: 6| Step: 9
Training loss: 1.81443452835083
Validation loss: 2.0503113372351534

Epoch: 6| Step: 10
Training loss: 1.8138954639434814
Validation loss: 2.0574669786678847

Epoch: 6| Step: 11
Training loss: 1.4215505123138428
Validation loss: 2.0721121782897622

Epoch: 6| Step: 12
Training loss: 1.8812333345413208
Validation loss: 2.0910881232189875

Epoch: 6| Step: 13
Training loss: 1.1985093355178833
Validation loss: 2.0768093652622674

Epoch: 137| Step: 0
Training loss: 1.30003023147583
Validation loss: 2.0465771793037333

Epoch: 6| Step: 1
Training loss: 1.8321927785873413
Validation loss: 2.0477186069693616

Epoch: 6| Step: 2
Training loss: 1.5445940494537354
Validation loss: 2.078289315264712

Epoch: 6| Step: 3
Training loss: 2.0436770915985107
Validation loss: 2.108615718862062

Epoch: 6| Step: 4
Training loss: 1.9351375102996826
Validation loss: 2.095256382419217

Epoch: 6| Step: 5
Training loss: 1.8966704607009888
Validation loss: 2.0607585560890938

Epoch: 6| Step: 6
Training loss: 1.3911164999008179
Validation loss: 2.0576700190062165

Epoch: 6| Step: 7
Training loss: 0.8717418313026428
Validation loss: 2.0455735242494972

Epoch: 6| Step: 8
Training loss: 1.4690009355545044
Validation loss: 2.037502234981906

Epoch: 6| Step: 9
Training loss: 1.000298023223877
Validation loss: 2.0535445392772718

Epoch: 6| Step: 10
Training loss: 1.8812540769577026
Validation loss: 2.0606891416734263

Epoch: 6| Step: 11
Training loss: 2.4829423427581787
Validation loss: 2.048905764856646

Epoch: 6| Step: 12
Training loss: 1.4250919818878174
Validation loss: 2.023563050454663

Epoch: 6| Step: 13
Training loss: 1.4638200998306274
Validation loss: 2.004455690742821

Epoch: 138| Step: 0
Training loss: 1.3768320083618164
Validation loss: 2.022363137173396

Epoch: 6| Step: 1
Training loss: 2.051042079925537
Validation loss: 2.0361852197236914

Epoch: 6| Step: 2
Training loss: 1.9803320169448853
Validation loss: 2.028342416209559

Epoch: 6| Step: 3
Training loss: 2.0067529678344727
Validation loss: 2.045182237061121

Epoch: 6| Step: 4
Training loss: 1.250333547592163
Validation loss: 2.035212411675402

Epoch: 6| Step: 5
Training loss: 1.9253082275390625
Validation loss: 2.0055752672174925

Epoch: 6| Step: 6
Training loss: 1.3648215532302856
Validation loss: 1.9960096959144837

Epoch: 6| Step: 7
Training loss: 1.285697340965271
Validation loss: 2.0025494226845364

Epoch: 6| Step: 8
Training loss: 1.9566035270690918
Validation loss: 2.0305210698035454

Epoch: 6| Step: 9
Training loss: 1.6329001188278198
Validation loss: 2.019979807638353

Epoch: 6| Step: 10
Training loss: 1.2475485801696777
Validation loss: 2.0279343692205285

Epoch: 6| Step: 11
Training loss: 1.1944358348846436
Validation loss: 2.047983971975183

Epoch: 6| Step: 12
Training loss: 1.5194028615951538
Validation loss: 2.0772224523687877

Epoch: 6| Step: 13
Training loss: 1.99757981300354
Validation loss: 2.068024819897067

Epoch: 139| Step: 0
Training loss: 1.312920093536377
Validation loss: 2.0331071499855287

Epoch: 6| Step: 1
Training loss: 1.39998459815979
Validation loss: 2.030378867221135

Epoch: 6| Step: 2
Training loss: 1.6293141841888428
Validation loss: 2.032179481239729

Epoch: 6| Step: 3
Training loss: 1.5445135831832886
Validation loss: 2.0531645872259654

Epoch: 6| Step: 4
Training loss: 1.3127694129943848
Validation loss: 2.0716584831155758

Epoch: 6| Step: 5
Training loss: 1.6447029113769531
Validation loss: 2.0908892129057195

Epoch: 6| Step: 6
Training loss: 1.5781663656234741
Validation loss: 2.1142458787528415

Epoch: 6| Step: 7
Training loss: 2.2593231201171875
Validation loss: 2.052668677863254

Epoch: 6| Step: 8
Training loss: 1.5433812141418457
Validation loss: 2.0255181481761317

Epoch: 6| Step: 9
Training loss: 1.4926785230636597
Validation loss: 1.9760191325218446

Epoch: 6| Step: 10
Training loss: 1.488053321838379
Validation loss: 1.9796814880063456

Epoch: 6| Step: 11
Training loss: 1.3474606275558472
Validation loss: 1.9887066348906486

Epoch: 6| Step: 12
Training loss: 1.9207183122634888
Validation loss: 1.9920373629498225

Epoch: 6| Step: 13
Training loss: 2.3175511360168457
Validation loss: 1.9780957839822257

Epoch: 140| Step: 0
Training loss: 1.6793715953826904
Validation loss: 1.957634368250447

Epoch: 6| Step: 1
Training loss: 1.3618066310882568
Validation loss: 1.9422321896399222

Epoch: 6| Step: 2
Training loss: 2.086920738220215
Validation loss: 1.9037205121850456

Epoch: 6| Step: 3
Training loss: 1.606711506843567
Validation loss: 1.9155904554551648

Epoch: 6| Step: 4
Training loss: 1.5853277444839478
Validation loss: 1.921265593139074

Epoch: 6| Step: 5
Training loss: 1.6398473978042603
Validation loss: 1.9465588933678084

Epoch: 6| Step: 6
Training loss: 1.566572904586792
Validation loss: 2.0070527048521143

Epoch: 6| Step: 7
Training loss: 1.4515867233276367
Validation loss: 2.046909106675015

Epoch: 6| Step: 8
Training loss: 1.5273202657699585
Validation loss: 2.0732852617899575

Epoch: 6| Step: 9
Training loss: 1.364317774772644
Validation loss: 2.105429450670878

Epoch: 6| Step: 10
Training loss: 2.083400011062622
Validation loss: 2.1323469633697183

Epoch: 6| Step: 11
Training loss: 1.168156623840332
Validation loss: 2.1253655546454975

Epoch: 6| Step: 12
Training loss: 1.6033613681793213
Validation loss: 2.060833643841487

Epoch: 6| Step: 13
Training loss: 1.8265963792800903
Validation loss: 1.998427329524871

Epoch: 141| Step: 0
Training loss: 1.606468915939331
Validation loss: 1.9489862739398915

Epoch: 6| Step: 1
Training loss: 1.4133665561676025
Validation loss: 1.9189347015914096

Epoch: 6| Step: 2
Training loss: 1.243147611618042
Validation loss: 1.8959248668404036

Epoch: 6| Step: 3
Training loss: 1.303478717803955
Validation loss: 1.9143016569076046

Epoch: 6| Step: 4
Training loss: 1.1936208009719849
Validation loss: 1.9288110643304803

Epoch: 6| Step: 5
Training loss: 2.4275622367858887
Validation loss: 1.9285547220578758

Epoch: 6| Step: 6
Training loss: 1.6186344623565674
Validation loss: 1.936842820977652

Epoch: 6| Step: 7
Training loss: 1.6340947151184082
Validation loss: 1.9190995385569911

Epoch: 6| Step: 8
Training loss: 1.7089552879333496
Validation loss: 1.9574060965609807

Epoch: 6| Step: 9
Training loss: 1.9608452320098877
Validation loss: 2.015469558777348

Epoch: 6| Step: 10
Training loss: 1.9029195308685303
Validation loss: 2.08666580723178

Epoch: 6| Step: 11
Training loss: 1.6017029285430908
Validation loss: 2.1216992819181053

Epoch: 6| Step: 12
Training loss: 1.5736050605773926
Validation loss: 2.124883541496851

Epoch: 6| Step: 13
Training loss: 1.545866847038269
Validation loss: 2.074615373406359

Epoch: 142| Step: 0
Training loss: 1.5683053731918335
Validation loss: 2.05081078057648

Epoch: 6| Step: 1
Training loss: 1.9356547594070435
Validation loss: 1.993054057962151

Epoch: 6| Step: 2
Training loss: 2.076246738433838
Validation loss: 2.0032969456846996

Epoch: 6| Step: 3
Training loss: 1.4985003471374512
Validation loss: 1.9974760868216073

Epoch: 6| Step: 4
Training loss: 1.8862261772155762
Validation loss: 2.008868363595778

Epoch: 6| Step: 5
Training loss: 1.8924410343170166
Validation loss: 2.03756461604949

Epoch: 6| Step: 6
Training loss: 1.0776050090789795
Validation loss: 2.0385965685690604

Epoch: 6| Step: 7
Training loss: 1.3880510330200195
Validation loss: 2.047568316100746

Epoch: 6| Step: 8
Training loss: 1.0068714618682861
Validation loss: 2.006814936155914

Epoch: 6| Step: 9
Training loss: 1.387280821800232
Validation loss: 2.0210015094408424

Epoch: 6| Step: 10
Training loss: 1.6947054862976074
Validation loss: 2.035156742219002

Epoch: 6| Step: 11
Training loss: 1.35597825050354
Validation loss: 2.035883906067059

Epoch: 6| Step: 12
Training loss: 1.657997488975525
Validation loss: 2.0635633084081833

Epoch: 6| Step: 13
Training loss: 0.9332813620567322
Validation loss: 2.0651537884948072

Epoch: 143| Step: 0
Training loss: 2.0711164474487305
Validation loss: 2.0532678224707164

Epoch: 6| Step: 1
Training loss: 1.4854700565338135
Validation loss: 1.996856302343389

Epoch: 6| Step: 2
Training loss: 1.7052416801452637
Validation loss: 1.9798883699601697

Epoch: 6| Step: 3
Training loss: 1.712813377380371
Validation loss: 1.985406155227333

Epoch: 6| Step: 4
Training loss: 1.9815561771392822
Validation loss: 1.9805132894105808

Epoch: 6| Step: 5
Training loss: 1.432293176651001
Validation loss: 1.9657521273500176

Epoch: 6| Step: 6
Training loss: 1.0582733154296875
Validation loss: 1.944026436856998

Epoch: 6| Step: 7
Training loss: 1.8218857049942017
Validation loss: 1.930420160293579

Epoch: 6| Step: 8
Training loss: 1.8669753074645996
Validation loss: 1.909147890665198

Epoch: 6| Step: 9
Training loss: 1.0273034572601318
Validation loss: 1.9206292360059676

Epoch: 6| Step: 10
Training loss: 1.612778902053833
Validation loss: 1.9265280923535746

Epoch: 6| Step: 11
Training loss: 1.2074050903320312
Validation loss: 1.9350328791526057

Epoch: 6| Step: 12
Training loss: 1.095510721206665
Validation loss: 1.9622339984422088

Epoch: 6| Step: 13
Training loss: 1.3583712577819824
Validation loss: 1.9880159772852415

Epoch: 144| Step: 0
Training loss: 1.2093138694763184
Validation loss: 2.0225650110552387

Epoch: 6| Step: 1
Training loss: 1.849541187286377
Validation loss: 2.0560278136243104

Epoch: 6| Step: 2
Training loss: 1.766351580619812
Validation loss: 2.0725406651855796

Epoch: 6| Step: 3
Training loss: 1.6075260639190674
Validation loss: 2.0935526073619886

Epoch: 6| Step: 4
Training loss: 1.4598286151885986
Validation loss: 2.0949861208597818

Epoch: 6| Step: 5
Training loss: 0.9868109226226807
Validation loss: 2.080295255107264

Epoch: 6| Step: 6
Training loss: 0.9638066291809082
Validation loss: 2.080583394214671

Epoch: 6| Step: 7
Training loss: 1.9156203269958496
Validation loss: 2.045734187608124

Epoch: 6| Step: 8
Training loss: 2.572831630706787
Validation loss: 2.035574456696869

Epoch: 6| Step: 9
Training loss: 1.1374969482421875
Validation loss: 2.056477080109299

Epoch: 6| Step: 10
Training loss: 1.5374844074249268
Validation loss: 2.039632487040694

Epoch: 6| Step: 11
Training loss: 1.3646858930587769
Validation loss: 2.0295097930457002

Epoch: 6| Step: 12
Training loss: 1.0997954607009888
Validation loss: 2.022601435261388

Epoch: 6| Step: 13
Training loss: 1.7830557823181152
Validation loss: 2.0276563705936557

Epoch: 145| Step: 0
Training loss: 1.3446930646896362
Validation loss: 2.0195398407597698

Epoch: 6| Step: 1
Training loss: 1.4037295579910278
Validation loss: 2.0375208547038417

Epoch: 6| Step: 2
Training loss: 1.4612854719161987
Validation loss: 2.0364407095857846

Epoch: 6| Step: 3
Training loss: 1.3316129446029663
Validation loss: 2.0120695611482025

Epoch: 6| Step: 4
Training loss: 1.1997227668762207
Validation loss: 1.9853319198854509

Epoch: 6| Step: 5
Training loss: 1.865966796875
Validation loss: 1.9580085559557843

Epoch: 6| Step: 6
Training loss: 1.9566487073898315
Validation loss: 1.9359095096588135

Epoch: 6| Step: 7
Training loss: 1.442954182624817
Validation loss: 1.9262127863463534

Epoch: 6| Step: 8
Training loss: 1.2956904172897339
Validation loss: 1.9185862964199436

Epoch: 6| Step: 9
Training loss: 1.5045843124389648
Validation loss: 1.9152271478406844

Epoch: 6| Step: 10
Training loss: 1.5211642980575562
Validation loss: 1.9116209514679448

Epoch: 6| Step: 11
Training loss: 1.3083617687225342
Validation loss: 1.9119834335901404

Epoch: 6| Step: 12
Training loss: 1.5914291143417358
Validation loss: 1.9205478493885328

Epoch: 6| Step: 13
Training loss: 2.003934144973755
Validation loss: 1.9192238623096096

Epoch: 146| Step: 0
Training loss: 1.605914831161499
Validation loss: 1.9649630054350822

Epoch: 6| Step: 1
Training loss: 1.736027479171753
Validation loss: 2.0181791192741803

Epoch: 6| Step: 2
Training loss: 1.030227780342102
Validation loss: 2.0426888850427445

Epoch: 6| Step: 3
Training loss: 1.259019136428833
Validation loss: 2.065143791578149

Epoch: 6| Step: 4
Training loss: 1.235901951789856
Validation loss: 2.0819303733046337

Epoch: 6| Step: 5
Training loss: 1.865065336227417
Validation loss: 2.0979627768198648

Epoch: 6| Step: 6
Training loss: 1.4906394481658936
Validation loss: 2.107356030453918

Epoch: 6| Step: 7
Training loss: 1.5927238464355469
Validation loss: 2.1194338619068103

Epoch: 6| Step: 8
Training loss: 1.1842241287231445
Validation loss: 2.080734860512518

Epoch: 6| Step: 9
Training loss: 1.639393925666809
Validation loss: 2.0735195708531204

Epoch: 6| Step: 10
Training loss: 1.096677541732788
Validation loss: 2.030834849162768

Epoch: 6| Step: 11
Training loss: 1.3896998167037964
Validation loss: 2.006274543782716

Epoch: 6| Step: 12
Training loss: 2.043705701828003
Validation loss: 1.9185349710526005

Epoch: 6| Step: 13
Training loss: 1.5354570150375366
Validation loss: 1.9010697564771097

Epoch: 147| Step: 0
Training loss: 1.9621596336364746
Validation loss: 1.8842058117671678

Epoch: 6| Step: 1
Training loss: 1.3925888538360596
Validation loss: 1.8883785816930956

Epoch: 6| Step: 2
Training loss: 1.7527098655700684
Validation loss: 1.8891355593999226

Epoch: 6| Step: 3
Training loss: 1.3448243141174316
Validation loss: 1.8814231221393873

Epoch: 6| Step: 4
Training loss: 2.158236503601074
Validation loss: 1.8944282275374218

Epoch: 6| Step: 5
Training loss: 1.2403899431228638
Validation loss: 1.9115499219586771

Epoch: 6| Step: 6
Training loss: 1.5181422233581543
Validation loss: 1.9201429172228741

Epoch: 6| Step: 7
Training loss: 1.5447381734848022
Validation loss: 1.9344736094115882

Epoch: 6| Step: 8
Training loss: 1.369878888130188
Validation loss: 1.9470955633348035

Epoch: 6| Step: 9
Training loss: 1.098299264907837
Validation loss: 1.93338704493738

Epoch: 6| Step: 10
Training loss: 1.6867804527282715
Validation loss: 1.953013409850418

Epoch: 6| Step: 11
Training loss: 1.0342732667922974
Validation loss: 1.9573434399020286

Epoch: 6| Step: 12
Training loss: 0.984613835811615
Validation loss: 2.0048185676656742

Epoch: 6| Step: 13
Training loss: 1.1508129835128784
Validation loss: 1.9999058605522237

Epoch: 148| Step: 0
Training loss: 1.6563068628311157
Validation loss: 1.996661352854903

Epoch: 6| Step: 1
Training loss: 1.3593018054962158
Validation loss: 2.0014126608448644

Epoch: 6| Step: 2
Training loss: 1.1817618608474731
Validation loss: 1.993301942784299

Epoch: 6| Step: 3
Training loss: 1.330754280090332
Validation loss: 1.986247270337997

Epoch: 6| Step: 4
Training loss: 1.9054608345031738
Validation loss: 1.9664618404962684

Epoch: 6| Step: 5
Training loss: 1.921828269958496
Validation loss: 1.982994189826391

Epoch: 6| Step: 6
Training loss: 1.373081922531128
Validation loss: 1.975686454003857

Epoch: 6| Step: 7
Training loss: 1.412077784538269
Validation loss: 1.9228447201431438

Epoch: 6| Step: 8
Training loss: 1.1749932765960693
Validation loss: 1.9198227159438594

Epoch: 6| Step: 9
Training loss: 1.5934028625488281
Validation loss: 1.914759861525669

Epoch: 6| Step: 10
Training loss: 1.520919680595398
Validation loss: 1.932707586596089

Epoch: 6| Step: 11
Training loss: 1.1152437925338745
Validation loss: 1.9623869990789762

Epoch: 6| Step: 12
Training loss: 1.2360059022903442
Validation loss: 2.0122269776559647

Epoch: 6| Step: 13
Training loss: 1.0963058471679688
Validation loss: 2.058021367237132

Epoch: 149| Step: 0
Training loss: 1.6911675930023193
Validation loss: 2.1117699402634815

Epoch: 6| Step: 1
Training loss: 1.7548840045928955
Validation loss: 2.1690368511343516

Epoch: 6| Step: 2
Training loss: 1.8208727836608887
Validation loss: 2.157218981814641

Epoch: 6| Step: 3
Training loss: 1.6921206712722778
Validation loss: 2.1355883998255574

Epoch: 6| Step: 4
Training loss: 1.1632599830627441
Validation loss: 2.085569953405729

Epoch: 6| Step: 5
Training loss: 1.580625057220459
Validation loss: 2.0134948620232205

Epoch: 6| Step: 6
Training loss: 1.0194251537322998
Validation loss: 1.9463686917417793

Epoch: 6| Step: 7
Training loss: 0.9436924457550049
Validation loss: 1.901324149101011

Epoch: 6| Step: 8
Training loss: 0.9554022550582886
Validation loss: 1.8930452177601476

Epoch: 6| Step: 9
Training loss: 1.2854316234588623
Validation loss: 1.881874394673173

Epoch: 6| Step: 10
Training loss: 1.7785491943359375
Validation loss: 1.8911991170657578

Epoch: 6| Step: 11
Training loss: 1.6974321603775024
Validation loss: 1.9074223259443879

Epoch: 6| Step: 12
Training loss: 1.7872263193130493
Validation loss: 1.9279347876066804

Epoch: 6| Step: 13
Training loss: 0.8676176071166992
Validation loss: 1.9341837911195652

Epoch: 150| Step: 0
Training loss: 1.9748419523239136
Validation loss: 1.9482481223280712

Epoch: 6| Step: 1
Training loss: 1.5118027925491333
Validation loss: 1.9738245087285196

Epoch: 6| Step: 2
Training loss: 1.6930513381958008
Validation loss: 1.9831529125090568

Epoch: 6| Step: 3
Training loss: 1.5853114128112793
Validation loss: 1.998079861364057

Epoch: 6| Step: 4
Training loss: 1.8590376377105713
Validation loss: 2.0162545006762267

Epoch: 6| Step: 5
Training loss: 1.1429128646850586
Validation loss: 2.0404453610861175

Epoch: 6| Step: 6
Training loss: 0.8705364465713501
Validation loss: 2.0438193557082966

Epoch: 6| Step: 7
Training loss: 1.1209925413131714
Validation loss: 2.031489531199137

Epoch: 6| Step: 8
Training loss: 1.1803654432296753
Validation loss: 2.035550290538419

Epoch: 6| Step: 9
Training loss: 1.1326065063476562
Validation loss: 2.0213814845649143

Epoch: 6| Step: 10
Training loss: 1.4122939109802246
Validation loss: 1.9846726553414458

Epoch: 6| Step: 11
Training loss: 1.171997308731079
Validation loss: 1.9451653290820379

Epoch: 6| Step: 12
Training loss: 1.3749079704284668
Validation loss: 1.9130180587050736

Epoch: 6| Step: 13
Training loss: 1.5697855949401855
Validation loss: 1.9077737741572882

Epoch: 151| Step: 0
Training loss: 1.4801702499389648
Validation loss: 1.9007625861834454

Epoch: 6| Step: 1
Training loss: 1.8155139684677124
Validation loss: 1.9056617790652859

Epoch: 6| Step: 2
Training loss: 1.3604698181152344
Validation loss: 1.8925412957386305

Epoch: 6| Step: 3
Training loss: 1.379094123840332
Validation loss: 1.8999259907712218

Epoch: 6| Step: 4
Training loss: 1.6505012512207031
Validation loss: 1.8869521425616356

Epoch: 6| Step: 5
Training loss: 1.3670952320098877
Validation loss: 1.895482288893833

Epoch: 6| Step: 6
Training loss: 1.0425786972045898
Validation loss: 1.9178439596647858

Epoch: 6| Step: 7
Training loss: 1.6475915908813477
Validation loss: 1.966002461730793

Epoch: 6| Step: 8
Training loss: 1.3867790699005127
Validation loss: 1.9974950013622161

Epoch: 6| Step: 9
Training loss: 1.6104315519332886
Validation loss: 2.0415713710169636

Epoch: 6| Step: 10
Training loss: 1.2918916940689087
Validation loss: 2.0519574765236146

Epoch: 6| Step: 11
Training loss: 1.4917516708374023
Validation loss: 2.063716642318233

Epoch: 6| Step: 12
Training loss: 1.1981803178787231
Validation loss: 2.0354121961901264

Epoch: 6| Step: 13
Training loss: 1.2315707206726074
Validation loss: 2.0406531518505466

Epoch: 152| Step: 0
Training loss: 0.7983046770095825
Validation loss: 2.037140464269987

Epoch: 6| Step: 1
Training loss: 1.4126570224761963
Validation loss: 2.0301061035484396

Epoch: 6| Step: 2
Training loss: 1.2636070251464844
Validation loss: 2.004654634383417

Epoch: 6| Step: 3
Training loss: 1.0381535291671753
Validation loss: 1.9723443626075663

Epoch: 6| Step: 4
Training loss: 1.4225244522094727
Validation loss: 1.9487195553318146

Epoch: 6| Step: 5
Training loss: 1.1071698665618896
Validation loss: 1.9437909433918614

Epoch: 6| Step: 6
Training loss: 1.5927678346633911
Validation loss: 1.9139252042257657

Epoch: 6| Step: 7
Training loss: 1.7227975130081177
Validation loss: 1.9271631266481133

Epoch: 6| Step: 8
Training loss: 1.8887227773666382
Validation loss: 1.924778769093175

Epoch: 6| Step: 9
Training loss: 1.11110258102417
Validation loss: 1.916612409776257

Epoch: 6| Step: 10
Training loss: 1.4273242950439453
Validation loss: 1.9099160804543445

Epoch: 6| Step: 11
Training loss: 1.6340365409851074
Validation loss: 1.9203093116001417

Epoch: 6| Step: 12
Training loss: 1.7547712326049805
Validation loss: 1.9285937752774966

Epoch: 6| Step: 13
Training loss: 1.4662173986434937
Validation loss: 1.9456301107201526

Epoch: 153| Step: 0
Training loss: 1.4511101245880127
Validation loss: 1.9388400790511922

Epoch: 6| Step: 1
Training loss: 0.7889586091041565
Validation loss: 1.9749901833072785

Epoch: 6| Step: 2
Training loss: 1.015114426612854
Validation loss: 1.9893629435570008

Epoch: 6| Step: 3
Training loss: 1.2522674798965454
Validation loss: 1.9969290379554994

Epoch: 6| Step: 4
Training loss: 0.8552829027175903
Validation loss: 2.0252734384229107

Epoch: 6| Step: 5
Training loss: 1.3013529777526855
Validation loss: 2.0104251574444514

Epoch: 6| Step: 6
Training loss: 1.7389585971832275
Validation loss: 2.038705489968741

Epoch: 6| Step: 7
Training loss: 1.781074047088623
Validation loss: 2.007916033908885

Epoch: 6| Step: 8
Training loss: 1.8409576416015625
Validation loss: 1.9988938095749065

Epoch: 6| Step: 9
Training loss: 1.5840308666229248
Validation loss: 1.9907665150139922

Epoch: 6| Step: 10
Training loss: 0.8905335664749146
Validation loss: 1.992080952531548

Epoch: 6| Step: 11
Training loss: 1.0970993041992188
Validation loss: 1.9871517022450764

Epoch: 6| Step: 12
Training loss: 1.7133582830429077
Validation loss: 1.9603729401865313

Epoch: 6| Step: 13
Training loss: 1.5314992666244507
Validation loss: 1.9443422004740725

Epoch: 154| Step: 0
Training loss: 1.1283968687057495
Validation loss: 1.9333264962319405

Epoch: 6| Step: 1
Training loss: 1.7547411918640137
Validation loss: 1.9238828843639744

Epoch: 6| Step: 2
Training loss: 1.517376184463501
Validation loss: 1.9096711925280991

Epoch: 6| Step: 3
Training loss: 1.462059497833252
Validation loss: 1.9246306598827403

Epoch: 6| Step: 4
Training loss: 0.9889664649963379
Validation loss: 1.9148215119556715

Epoch: 6| Step: 5
Training loss: 1.3773671388626099
Validation loss: 1.8995141726668163

Epoch: 6| Step: 6
Training loss: 0.991662859916687
Validation loss: 1.88248396688892

Epoch: 6| Step: 7
Training loss: 1.4151926040649414
Validation loss: 1.8923229312384

Epoch: 6| Step: 8
Training loss: 1.311201572418213
Validation loss: 1.9215746566813479

Epoch: 6| Step: 9
Training loss: 1.6061792373657227
Validation loss: 1.9415488140557402

Epoch: 6| Step: 10
Training loss: 1.1495420932769775
Validation loss: 2.002670726468486

Epoch: 6| Step: 11
Training loss: 1.361340045928955
Validation loss: 2.0379041497425368

Epoch: 6| Step: 12
Training loss: 1.712543249130249
Validation loss: 2.038660808276105

Epoch: 6| Step: 13
Training loss: 1.101121187210083
Validation loss: 2.049222553929975

Epoch: 155| Step: 0
Training loss: 1.1128849983215332
Validation loss: 2.023795759806069

Epoch: 6| Step: 1
Training loss: 1.7106934785842896
Validation loss: 2.010778598887946

Epoch: 6| Step: 2
Training loss: 1.1137914657592773
Validation loss: 1.9849234806594027

Epoch: 6| Step: 3
Training loss: 1.0796546936035156
Validation loss: 1.914182255345006

Epoch: 6| Step: 4
Training loss: 1.3468290567398071
Validation loss: 1.9105334358830606

Epoch: 6| Step: 5
Training loss: 1.2762327194213867
Validation loss: 1.9180258909861247

Epoch: 6| Step: 6
Training loss: 1.592125654220581
Validation loss: 1.927996249609096

Epoch: 6| Step: 7
Training loss: 1.6461782455444336
Validation loss: 1.9100570909438594

Epoch: 6| Step: 8
Training loss: 1.1114786863327026
Validation loss: 1.914752338522224

Epoch: 6| Step: 9
Training loss: 1.5947036743164062
Validation loss: 1.9166330675924979

Epoch: 6| Step: 10
Training loss: 1.0537627935409546
Validation loss: 1.93022951515772

Epoch: 6| Step: 11
Training loss: 1.3443143367767334
Validation loss: 1.9126629419224237

Epoch: 6| Step: 12
Training loss: 1.1378155946731567
Validation loss: 1.930463444802069

Epoch: 6| Step: 13
Training loss: 1.138777494430542
Validation loss: 1.9205093306879844

Epoch: 156| Step: 0
Training loss: 1.2983958721160889
Validation loss: 1.8956702832252748

Epoch: 6| Step: 1
Training loss: 1.2842750549316406
Validation loss: 1.8919641894678916

Epoch: 6| Step: 2
Training loss: 0.8500096797943115
Validation loss: 1.9128692432116436

Epoch: 6| Step: 3
Training loss: 1.6839715242385864
Validation loss: 1.9295804590307257

Epoch: 6| Step: 4
Training loss: 1.2511825561523438
Validation loss: 1.9116834748175837

Epoch: 6| Step: 5
Training loss: 1.475280523300171
Validation loss: 1.9506345128500333

Epoch: 6| Step: 6
Training loss: 1.0853532552719116
Validation loss: 1.9743149639457784

Epoch: 6| Step: 7
Training loss: 1.248950719833374
Validation loss: 1.9935266689587665

Epoch: 6| Step: 8
Training loss: 0.9692977070808411
Validation loss: 1.9997515960406231

Epoch: 6| Step: 9
Training loss: 1.576181173324585
Validation loss: 2.0232944539798203

Epoch: 6| Step: 10
Training loss: 1.3219597339630127
Validation loss: 2.0301402666235484

Epoch: 6| Step: 11
Training loss: 1.1719446182250977
Validation loss: 2.003778039768178

Epoch: 6| Step: 12
Training loss: 1.3793400526046753
Validation loss: 2.00956827978934

Epoch: 6| Step: 13
Training loss: 1.328188419342041
Validation loss: 1.9724874599005586

Epoch: 157| Step: 0
Training loss: 1.473379373550415
Validation loss: 1.9788223325565297

Epoch: 6| Step: 1
Training loss: 0.8298476934432983
Validation loss: 1.9397158404832244

Epoch: 6| Step: 2
Training loss: 1.2308393716812134
Validation loss: 1.9170431321667087

Epoch: 6| Step: 3
Training loss: 0.8764053583145142
Validation loss: 1.8961823576240129

Epoch: 6| Step: 4
Training loss: 1.7915349006652832
Validation loss: 1.8834655169517762

Epoch: 6| Step: 5
Training loss: 1.3125615119934082
Validation loss: 1.8636522831455353

Epoch: 6| Step: 6
Training loss: 1.2029650211334229
Validation loss: 1.8635036496705906

Epoch: 6| Step: 7
Training loss: 0.6563112139701843
Validation loss: 1.8813553189718595

Epoch: 6| Step: 8
Training loss: 1.323056936264038
Validation loss: 1.8996114141197615

Epoch: 6| Step: 9
Training loss: 1.666227102279663
Validation loss: 1.9003532932650657

Epoch: 6| Step: 10
Training loss: 1.4671329259872437
Validation loss: 1.916227432989305

Epoch: 6| Step: 11
Training loss: 1.8443310260772705
Validation loss: 1.922608781886357

Epoch: 6| Step: 12
Training loss: 0.7502095699310303
Validation loss: 1.9303236315327306

Epoch: 6| Step: 13
Training loss: 1.8277620077133179
Validation loss: 1.94580195155195

Epoch: 158| Step: 0
Training loss: 1.153156042098999
Validation loss: 1.9621246655782063

Epoch: 6| Step: 1
Training loss: 0.9107260704040527
Validation loss: 1.9466526687786143

Epoch: 6| Step: 2
Training loss: 1.7375822067260742
Validation loss: 1.967224544094455

Epoch: 6| Step: 3
Training loss: 1.3668642044067383
Validation loss: 1.930068862053656

Epoch: 6| Step: 4
Training loss: 1.65462064743042
Validation loss: 1.9056882730094336

Epoch: 6| Step: 5
Training loss: 1.3029258251190186
Validation loss: 1.8951482798463555

Epoch: 6| Step: 6
Training loss: 1.6591010093688965
Validation loss: 1.902704442701032

Epoch: 6| Step: 7
Training loss: 0.6700806617736816
Validation loss: 1.918860318840191

Epoch: 6| Step: 8
Training loss: 1.0168101787567139
Validation loss: 1.9332894202201598

Epoch: 6| Step: 9
Training loss: 1.1851381063461304
Validation loss: 1.9518767069744807

Epoch: 6| Step: 10
Training loss: 1.1049916744232178
Validation loss: 1.9346338830968386

Epoch: 6| Step: 11
Training loss: 1.2355167865753174
Validation loss: 1.9249644048752323

Epoch: 6| Step: 12
Training loss: 1.423837661743164
Validation loss: 1.9425686110732376

Epoch: 6| Step: 13
Training loss: 1.2204104661941528
Validation loss: 1.9706099238446964

Epoch: 159| Step: 0
Training loss: 0.8777875304222107
Validation loss: 1.9888599072733233

Epoch: 6| Step: 1
Training loss: 1.6920428276062012
Validation loss: 1.9938759496135097

Epoch: 6| Step: 2
Training loss: 1.1402297019958496
Validation loss: 2.0032079937637493

Epoch: 6| Step: 3
Training loss: 1.6293901205062866
Validation loss: 1.995758016904195

Epoch: 6| Step: 4
Training loss: 0.8749141693115234
Validation loss: 1.9775379511617845

Epoch: 6| Step: 5
Training loss: 1.8982017040252686
Validation loss: 1.9283840092279578

Epoch: 6| Step: 6
Training loss: 0.7845859527587891
Validation loss: 1.9043777988803001

Epoch: 6| Step: 7
Training loss: 1.1508430242538452
Validation loss: 1.8938517109040292

Epoch: 6| Step: 8
Training loss: 1.3878653049468994
Validation loss: 1.8948842428063835

Epoch: 6| Step: 9
Training loss: 1.2279587984085083
Validation loss: 1.8964101704218055

Epoch: 6| Step: 10
Training loss: 1.906449794769287
Validation loss: 1.8888785813444404

Epoch: 6| Step: 11
Training loss: 1.2003214359283447
Validation loss: 1.876318226578415

Epoch: 6| Step: 12
Training loss: 1.0970253944396973
Validation loss: 1.8825565615007955

Epoch: 6| Step: 13
Training loss: 0.9096254706382751
Validation loss: 1.8866544487655803

Epoch: 160| Step: 0
Training loss: 1.2945702075958252
Validation loss: 1.8991337924875238

Epoch: 6| Step: 1
Training loss: 0.9944943189620972
Validation loss: 1.9255949271622526

Epoch: 6| Step: 2
Training loss: 0.7790167927742004
Validation loss: 1.9440144210733392

Epoch: 6| Step: 3
Training loss: 0.6530816555023193
Validation loss: 1.937697365719785

Epoch: 6| Step: 4
Training loss: 1.3246487379074097
Validation loss: 1.9666008314778727

Epoch: 6| Step: 5
Training loss: 0.9047989845275879
Validation loss: 1.9872193131395566

Epoch: 6| Step: 6
Training loss: 1.0153226852416992
Validation loss: 1.9706948982772006

Epoch: 6| Step: 7
Training loss: 1.784625768661499
Validation loss: 1.9779606314115628

Epoch: 6| Step: 8
Training loss: 2.1499340534210205
Validation loss: 1.9729676797825804

Epoch: 6| Step: 9
Training loss: 1.496551513671875
Validation loss: 1.958265584002259

Epoch: 6| Step: 10
Training loss: 1.2246307134628296
Validation loss: 1.9754758304165256

Epoch: 6| Step: 11
Training loss: 1.6012463569641113
Validation loss: 1.9587216069621425

Epoch: 6| Step: 12
Training loss: 1.0159674882888794
Validation loss: 1.9502982670261013

Epoch: 6| Step: 13
Training loss: 1.5687496662139893
Validation loss: 1.9253493585894186

Epoch: 161| Step: 0
Training loss: 1.5990161895751953
Validation loss: 1.9196487203721078

Epoch: 6| Step: 1
Training loss: 1.5747520923614502
Validation loss: 1.9061465289003106

Epoch: 6| Step: 2
Training loss: 1.1261248588562012
Validation loss: 1.922289192035634

Epoch: 6| Step: 3
Training loss: 1.01353120803833
Validation loss: 1.9132276401724866

Epoch: 6| Step: 4
Training loss: 1.2536193132400513
Validation loss: 1.9237291812896729

Epoch: 6| Step: 5
Training loss: 1.1032605171203613
Validation loss: 1.9185299578533377

Epoch: 6| Step: 6
Training loss: 0.8110547065734863
Validation loss: 1.9254589644811486

Epoch: 6| Step: 7
Training loss: 0.8860893249511719
Validation loss: 1.9405491377717705

Epoch: 6| Step: 8
Training loss: 1.2258062362670898
Validation loss: 1.9569031166773971

Epoch: 6| Step: 9
Training loss: 1.7296271324157715
Validation loss: 1.9883436015857163

Epoch: 6| Step: 10
Training loss: 0.9746273756027222
Validation loss: 1.9529310605859245

Epoch: 6| Step: 11
Training loss: 1.510359764099121
Validation loss: 1.9644375437049455

Epoch: 6| Step: 12
Training loss: 1.2611680030822754
Validation loss: 1.9883926632583782

Epoch: 6| Step: 13
Training loss: 0.7346282005310059
Validation loss: 1.9677987585785568

Epoch: 162| Step: 0
Training loss: 1.247260332107544
Validation loss: 1.9692159673219085

Epoch: 6| Step: 1
Training loss: 0.9285686016082764
Validation loss: 1.9531416508459276

Epoch: 6| Step: 2
Training loss: 1.6050117015838623
Validation loss: 1.9430924320733676

Epoch: 6| Step: 3
Training loss: 0.7423002123832703
Validation loss: 1.9674609784157044

Epoch: 6| Step: 4
Training loss: 0.8641918301582336
Validation loss: 1.9575852488958707

Epoch: 6| Step: 5
Training loss: 1.7029521465301514
Validation loss: 1.9681071850561327

Epoch: 6| Step: 6
Training loss: 0.9891455173492432
Validation loss: 1.9921497888462518

Epoch: 6| Step: 7
Training loss: 1.1927781105041504
Validation loss: 1.9698332484050463

Epoch: 6| Step: 8
Training loss: 1.43479585647583
Validation loss: 1.980222277743842

Epoch: 6| Step: 9
Training loss: 0.9801767468452454
Validation loss: 1.9691064921758508

Epoch: 6| Step: 10
Training loss: 1.4483929872512817
Validation loss: 1.9549147326459166

Epoch: 6| Step: 11
Training loss: 1.6999887228012085
Validation loss: 1.9372107444270965

Epoch: 6| Step: 12
Training loss: 1.2440319061279297
Validation loss: 1.9134574039008028

Epoch: 6| Step: 13
Training loss: 0.4022197127342224
Validation loss: 1.9066915281357304

Epoch: 163| Step: 0
Training loss: 1.4201433658599854
Validation loss: 1.9024784206062235

Epoch: 6| Step: 1
Training loss: 1.2953062057495117
Validation loss: 1.9148867950644544

Epoch: 6| Step: 2
Training loss: 1.0749900341033936
Validation loss: 1.9150942871647496

Epoch: 6| Step: 3
Training loss: 0.853030264377594
Validation loss: 1.9449667789602791

Epoch: 6| Step: 4
Training loss: 1.552571415901184
Validation loss: 1.9450377161784838

Epoch: 6| Step: 5
Training loss: 0.8303879499435425
Validation loss: 1.9516867309488275

Epoch: 6| Step: 6
Training loss: 1.469222068786621
Validation loss: 1.9508606849178192

Epoch: 6| Step: 7
Training loss: 1.105349063873291
Validation loss: 1.9721375370538363

Epoch: 6| Step: 8
Training loss: 1.238014817237854
Validation loss: 1.977254859862789

Epoch: 6| Step: 9
Training loss: 1.505887746810913
Validation loss: 1.9510076943264212

Epoch: 6| Step: 10
Training loss: 1.243671178817749
Validation loss: 1.9919728066331597

Epoch: 6| Step: 11
Training loss: 0.9628728032112122
Validation loss: 1.956503754021019

Epoch: 6| Step: 12
Training loss: 1.3338639736175537
Validation loss: 1.9720202786948091

Epoch: 6| Step: 13
Training loss: 0.8194373250007629
Validation loss: 1.936800556798135

Epoch: 164| Step: 0
Training loss: 1.091914176940918
Validation loss: 1.9352148989195466

Epoch: 6| Step: 1
Training loss: 1.1032025814056396
Validation loss: 1.9168527446767336

Epoch: 6| Step: 2
Training loss: 0.6337465047836304
Validation loss: 1.9186430772145588

Epoch: 6| Step: 3
Training loss: 1.7728421688079834
Validation loss: 1.903153980931928

Epoch: 6| Step: 4
Training loss: 0.8836459517478943
Validation loss: 1.8641506010486233

Epoch: 6| Step: 5
Training loss: 0.9796775579452515
Validation loss: 1.8543038765589397

Epoch: 6| Step: 6
Training loss: 1.2574946880340576
Validation loss: 1.8809181490252096

Epoch: 6| Step: 7
Training loss: 1.3608455657958984
Validation loss: 1.905195588706642

Epoch: 6| Step: 8
Training loss: 1.2374508380889893
Validation loss: 1.9384997813932356

Epoch: 6| Step: 9
Training loss: 1.1477506160736084
Validation loss: 1.9364630227447839

Epoch: 6| Step: 10
Training loss: 0.9236209988594055
Validation loss: 1.9119687618747834

Epoch: 6| Step: 11
Training loss: 1.4453473091125488
Validation loss: 1.9267044067382812

Epoch: 6| Step: 12
Training loss: 1.2919337749481201
Validation loss: 1.9155247237092705

Epoch: 6| Step: 13
Training loss: 1.4668447971343994
Validation loss: 1.9119609966072986

Epoch: 165| Step: 0
Training loss: 0.8099365234375
Validation loss: 1.9164629546544885

Epoch: 6| Step: 1
Training loss: 1.0810096263885498
Validation loss: 1.908238003330846

Epoch: 6| Step: 2
Training loss: 0.8815516233444214
Validation loss: 1.89565735478555

Epoch: 6| Step: 3
Training loss: 1.012693166732788
Validation loss: 1.8887680294693157

Epoch: 6| Step: 4
Training loss: 1.031630039215088
Validation loss: 1.9042869844744283

Epoch: 6| Step: 5
Training loss: 1.4759763479232788
Validation loss: 1.941246066042172

Epoch: 6| Step: 6
Training loss: 0.8140740394592285
Validation loss: 1.9442318331810735

Epoch: 6| Step: 7
Training loss: 1.4794801473617554
Validation loss: 1.9546423291647306

Epoch: 6| Step: 8
Training loss: 1.1444706916809082
Validation loss: 1.9546433251391175

Epoch: 6| Step: 9
Training loss: 1.1986135244369507
Validation loss: 1.9783943801797845

Epoch: 6| Step: 10
Training loss: 1.6143698692321777
Validation loss: 1.9682400867503176

Epoch: 6| Step: 11
Training loss: 1.5256578922271729
Validation loss: 1.9570149708819646

Epoch: 6| Step: 12
Training loss: 1.3140681982040405
Validation loss: 1.9249506112067931

Epoch: 6| Step: 13
Training loss: 0.9214990139007568
Validation loss: 1.8902840793773692

Epoch: 166| Step: 0
Training loss: 1.03594970703125
Validation loss: 1.8419631578588997

Epoch: 6| Step: 1
Training loss: 1.6406147480010986
Validation loss: 1.8506073656902517

Epoch: 6| Step: 2
Training loss: 1.4414317607879639
Validation loss: 1.8548020316708473

Epoch: 6| Step: 3
Training loss: 1.0184104442596436
Validation loss: 1.8430466869825959

Epoch: 6| Step: 4
Training loss: 1.0512807369232178
Validation loss: 1.8568736904410905

Epoch: 6| Step: 5
Training loss: 1.7708914279937744
Validation loss: 1.869050770677546

Epoch: 6| Step: 6
Training loss: 1.0803577899932861
Validation loss: 1.8742464588534447

Epoch: 6| Step: 7
Training loss: 1.4170804023742676
Validation loss: 1.8596502760405182

Epoch: 6| Step: 8
Training loss: 1.1131680011749268
Validation loss: 1.8773528375933248

Epoch: 6| Step: 9
Training loss: 0.9760968089103699
Validation loss: 1.8694524111286286

Epoch: 6| Step: 10
Training loss: 0.9600770473480225
Validation loss: 1.8634411699028426

Epoch: 6| Step: 11
Training loss: 0.6655415296554565
Validation loss: 1.8915500769051172

Epoch: 6| Step: 12
Training loss: 0.9498320817947388
Validation loss: 1.9026442958462624

Epoch: 6| Step: 13
Training loss: 1.088888168334961
Validation loss: 1.9133544891111312

Epoch: 167| Step: 0
Training loss: 1.1945443153381348
Validation loss: 1.926057384860131

Epoch: 6| Step: 1
Training loss: 1.6633391380310059
Validation loss: 1.931880876582156

Epoch: 6| Step: 2
Training loss: 0.7874342203140259
Validation loss: 1.95589631090882

Epoch: 6| Step: 3
Training loss: 1.0066050291061401
Validation loss: 1.9696369773598128

Epoch: 6| Step: 4
Training loss: 0.861305832862854
Validation loss: 1.9566287071474138

Epoch: 6| Step: 5
Training loss: 1.1902711391448975
Validation loss: 1.9271438583250968

Epoch: 6| Step: 6
Training loss: 1.3827816247940063
Validation loss: 1.9213998753537413

Epoch: 6| Step: 7
Training loss: 1.491971731185913
Validation loss: 1.928969725485771

Epoch: 6| Step: 8
Training loss: 0.8672899007797241
Validation loss: 1.9309241746061592

Epoch: 6| Step: 9
Training loss: 1.0416836738586426
Validation loss: 1.9233580045802618

Epoch: 6| Step: 10
Training loss: 1.2351162433624268
Validation loss: 1.896272946429509

Epoch: 6| Step: 11
Training loss: 1.1395843029022217
Validation loss: 1.8495659212912283

Epoch: 6| Step: 12
Training loss: 0.8203389048576355
Validation loss: 1.8188050100880284

Epoch: 6| Step: 13
Training loss: 2.095954418182373
Validation loss: 1.80837038511871

Epoch: 168| Step: 0
Training loss: 0.5807204246520996
Validation loss: 1.7984595388494513

Epoch: 6| Step: 1
Training loss: 1.673595666885376
Validation loss: 1.8050124337596278

Epoch: 6| Step: 2
Training loss: 1.012377142906189
Validation loss: 1.7978857845388434

Epoch: 6| Step: 3
Training loss: 1.2646815776824951
Validation loss: 1.7966599900235412

Epoch: 6| Step: 4
Training loss: 1.1942598819732666
Validation loss: 1.8331853599958523

Epoch: 6| Step: 5
Training loss: 0.61093670129776
Validation loss: 1.8589559242289553

Epoch: 6| Step: 6
Training loss: 1.704642653465271
Validation loss: 1.9320519867763724

Epoch: 6| Step: 7
Training loss: 1.0679395198822021
Validation loss: 1.9194022993887625

Epoch: 6| Step: 8
Training loss: 1.4914824962615967
Validation loss: 1.9638162864151822

Epoch: 6| Step: 9
Training loss: 0.9513935446739197
Validation loss: 1.983367221329802

Epoch: 6| Step: 10
Training loss: 1.433396816253662
Validation loss: 1.9771908098651516

Epoch: 6| Step: 11
Training loss: 0.9079517126083374
Validation loss: 1.9480359169744677

Epoch: 6| Step: 12
Training loss: 1.1524165868759155
Validation loss: 1.960684957042817

Epoch: 6| Step: 13
Training loss: 1.0057637691497803
Validation loss: 1.9072463743148311

Epoch: 169| Step: 0
Training loss: 1.2663066387176514
Validation loss: 1.8762339340743197

Epoch: 6| Step: 1
Training loss: 1.0790339708328247
Validation loss: 1.8746308024211595

Epoch: 6| Step: 2
Training loss: 0.7224973440170288
Validation loss: 1.866583138383845

Epoch: 6| Step: 3
Training loss: 1.1480095386505127
Validation loss: 1.8574179231479604

Epoch: 6| Step: 4
Training loss: 1.3688876628875732
Validation loss: 1.8639699207839144

Epoch: 6| Step: 5
Training loss: 1.391115427017212
Validation loss: 1.8447881360207834

Epoch: 6| Step: 6
Training loss: 0.8122138977050781
Validation loss: 1.8145069870897519

Epoch: 6| Step: 7
Training loss: 1.2823683023452759
Validation loss: 1.819756947537904

Epoch: 6| Step: 8
Training loss: 0.6352661848068237
Validation loss: 1.829527311427619

Epoch: 6| Step: 9
Training loss: 1.3362467288970947
Validation loss: 1.8269916657478578

Epoch: 6| Step: 10
Training loss: 1.3354737758636475
Validation loss: 1.86729859793058

Epoch: 6| Step: 11
Training loss: 1.2763911485671997
Validation loss: 1.8702740566704863

Epoch: 6| Step: 12
Training loss: 0.9328405857086182
Validation loss: 1.872997965863956

Epoch: 6| Step: 13
Training loss: 0.7581565976142883
Validation loss: 1.8984802051257061

Epoch: 170| Step: 0
Training loss: 0.8969442844390869
Validation loss: 1.9136778795590965

Epoch: 6| Step: 1
Training loss: 1.5999330282211304
Validation loss: 1.919132004501999

Epoch: 6| Step: 2
Training loss: 1.427074670791626
Validation loss: 1.9074236757011824

Epoch: 6| Step: 3
Training loss: 1.2556519508361816
Validation loss: 1.917385785810409

Epoch: 6| Step: 4
Training loss: 0.7942814826965332
Validation loss: 1.897541525543377

Epoch: 6| Step: 5
Training loss: 1.2354985475540161
Validation loss: 1.9048885709495955

Epoch: 6| Step: 6
Training loss: 0.6387805938720703
Validation loss: 1.9064162546588528

Epoch: 6| Step: 7
Training loss: 1.5120184421539307
Validation loss: 1.9035100065251833

Epoch: 6| Step: 8
Training loss: 0.8914777040481567
Validation loss: 1.9188804985374532

Epoch: 6| Step: 9
Training loss: 1.5012540817260742
Validation loss: 1.9438963705493557

Epoch: 6| Step: 10
Training loss: 1.085566520690918
Validation loss: 1.9378586199975782

Epoch: 6| Step: 11
Training loss: 1.0715105533599854
Validation loss: 1.9539755121354134

Epoch: 6| Step: 12
Training loss: 1.0368444919586182
Validation loss: 1.9355464955811859

Epoch: 6| Step: 13
Training loss: 0.7596445679664612
Validation loss: 1.9195748811127038

Epoch: 171| Step: 0
Training loss: 0.9439760446548462
Validation loss: 1.903774312747422

Epoch: 6| Step: 1
Training loss: 1.1301321983337402
Validation loss: 1.8726037522797943

Epoch: 6| Step: 2
Training loss: 1.1184064149856567
Validation loss: 1.887174681950641

Epoch: 6| Step: 3
Training loss: 1.3049392700195312
Validation loss: 1.8801812048881286

Epoch: 6| Step: 4
Training loss: 1.653853416442871
Validation loss: 1.8666105924114105

Epoch: 6| Step: 5
Training loss: 0.7873243093490601
Validation loss: 1.8514263732458955

Epoch: 6| Step: 6
Training loss: 1.3489573001861572
Validation loss: 1.8650593757629395

Epoch: 6| Step: 7
Training loss: 1.0387300252914429
Validation loss: 1.874847815882775

Epoch: 6| Step: 8
Training loss: 1.3538845777511597
Validation loss: 1.8696896119784283

Epoch: 6| Step: 9
Training loss: 1.123049020767212
Validation loss: 1.8519343048013666

Epoch: 6| Step: 10
Training loss: 0.6033159494400024
Validation loss: 1.8341233832861787

Epoch: 6| Step: 11
Training loss: 1.2088024616241455
Validation loss: 1.842513015193324

Epoch: 6| Step: 12
Training loss: 0.7989617586135864
Validation loss: 1.8728587896593156

Epoch: 6| Step: 13
Training loss: 1.0699539184570312
Validation loss: 1.8888008620149346

Epoch: 172| Step: 0
Training loss: 1.1435528993606567
Validation loss: 1.911731671261531

Epoch: 6| Step: 1
Training loss: 1.134331464767456
Validation loss: 1.8925307014937043

Epoch: 6| Step: 2
Training loss: 1.2246158123016357
Validation loss: 1.8842482695015528

Epoch: 6| Step: 3
Training loss: 1.150147795677185
Validation loss: 1.8524088039193103

Epoch: 6| Step: 4
Training loss: 0.9827014207839966
Validation loss: 1.830041067574614

Epoch: 6| Step: 5
Training loss: 1.073298454284668
Validation loss: 1.8313329142908896

Epoch: 6| Step: 6
Training loss: 1.1574277877807617
Validation loss: 1.8112718353989303

Epoch: 6| Step: 7
Training loss: 1.0433177947998047
Validation loss: 1.819520963135586

Epoch: 6| Step: 8
Training loss: 0.7434460520744324
Validation loss: 1.804474203817306

Epoch: 6| Step: 9
Training loss: 0.9834892749786377
Validation loss: 1.8198712051555674

Epoch: 6| Step: 10
Training loss: 1.4198243618011475
Validation loss: 1.8289331082374818

Epoch: 6| Step: 11
Training loss: 0.8601637482643127
Validation loss: 1.827587454549728

Epoch: 6| Step: 12
Training loss: 0.6884444355964661
Validation loss: 1.8756251937599593

Epoch: 6| Step: 13
Training loss: 1.0110416412353516
Validation loss: 1.8964587565391295

Epoch: 173| Step: 0
Training loss: 1.3152204751968384
Validation loss: 1.9374329954065301

Epoch: 6| Step: 1
Training loss: 1.2399523258209229
Validation loss: 1.9349505721881826

Epoch: 6| Step: 2
Training loss: 0.6679040193557739
Validation loss: 1.9358249043905607

Epoch: 6| Step: 3
Training loss: 0.9431056976318359
Validation loss: 1.89016354468561

Epoch: 6| Step: 4
Training loss: 1.4442317485809326
Validation loss: 1.8953250364590717

Epoch: 6| Step: 5
Training loss: 1.4956413507461548
Validation loss: 1.853315984049151

Epoch: 6| Step: 6
Training loss: 0.3858039379119873
Validation loss: 1.8440930843353271

Epoch: 6| Step: 7
Training loss: 1.0804221630096436
Validation loss: 1.8670863387405232

Epoch: 6| Step: 8
Training loss: 1.0596890449523926
Validation loss: 1.86371265175522

Epoch: 6| Step: 9
Training loss: 1.215331792831421
Validation loss: 1.8609111719234015

Epoch: 6| Step: 10
Training loss: 0.7081477642059326
Validation loss: 1.8649665360809655

Epoch: 6| Step: 11
Training loss: 0.89090496301651
Validation loss: 1.8527889059435936

Epoch: 6| Step: 12
Training loss: 1.459080457687378
Validation loss: 1.8573390591529109

Epoch: 6| Step: 13
Training loss: 1.0980764627456665
Validation loss: 1.8408909510540705

Epoch: 174| Step: 0
Training loss: 0.7353720664978027
Validation loss: 1.8442083917638308

Epoch: 6| Step: 1
Training loss: 1.1565085649490356
Validation loss: 1.8669640928186395

Epoch: 6| Step: 2
Training loss: 0.8444450497627258
Validation loss: 1.9057597729467577

Epoch: 6| Step: 3
Training loss: 1.3334581851959229
Validation loss: 1.9420864825607629

Epoch: 6| Step: 4
Training loss: 1.0396769046783447
Validation loss: 1.9426024780478528

Epoch: 6| Step: 5
Training loss: 0.7840195894241333
Validation loss: 1.9648053851178897

Epoch: 6| Step: 6
Training loss: 1.1824287176132202
Validation loss: 1.9426139170123684

Epoch: 6| Step: 7
Training loss: 0.8821669816970825
Validation loss: 1.916283675419387

Epoch: 6| Step: 8
Training loss: 0.8637136220932007
Validation loss: 1.9052096810392154

Epoch: 6| Step: 9
Training loss: 1.5997833013534546
Validation loss: 1.8767842567095192

Epoch: 6| Step: 10
Training loss: 1.2283732891082764
Validation loss: 1.8771488999807706

Epoch: 6| Step: 11
Training loss: 1.0095582008361816
Validation loss: 1.8434562785651094

Epoch: 6| Step: 12
Training loss: 1.3799703121185303
Validation loss: 1.8489199940876295

Epoch: 6| Step: 13
Training loss: 0.6191936731338501
Validation loss: 1.8348431817946895

Epoch: 175| Step: 0
Training loss: 0.5340576767921448
Validation loss: 1.8317460013974098

Epoch: 6| Step: 1
Training loss: 2.0529026985168457
Validation loss: 1.8200919730688936

Epoch: 6| Step: 2
Training loss: 1.2194958925247192
Validation loss: 1.821437769038703

Epoch: 6| Step: 3
Training loss: 1.4062267541885376
Validation loss: 1.8263978086492068

Epoch: 6| Step: 4
Training loss: 0.8776262998580933
Validation loss: 1.8425576020312566

Epoch: 6| Step: 5
Training loss: 0.8033428192138672
Validation loss: 1.828905600373463

Epoch: 6| Step: 6
Training loss: 0.7838448286056519
Validation loss: 1.835949558083729

Epoch: 6| Step: 7
Training loss: 1.0641047954559326
Validation loss: 1.8488985261609476

Epoch: 6| Step: 8
Training loss: 0.4466049373149872
Validation loss: 1.8534075470380886

Epoch: 6| Step: 9
Training loss: 0.6863923072814941
Validation loss: 1.8715223048322944

Epoch: 6| Step: 10
Training loss: 0.8971095681190491
Validation loss: 1.9170281246144285

Epoch: 6| Step: 11
Training loss: 0.9621626138687134
Validation loss: 1.9171731779652257

Epoch: 6| Step: 12
Training loss: 1.3922845125198364
Validation loss: 1.9293690330238753

Epoch: 6| Step: 13
Training loss: 1.4008725881576538
Validation loss: 1.9364051741938437

Epoch: 176| Step: 0
Training loss: 0.8419938087463379
Validation loss: 1.91027916759573

Epoch: 6| Step: 1
Training loss: 0.5582448244094849
Validation loss: 1.8821739740269159

Epoch: 6| Step: 2
Training loss: 0.8724672794342041
Validation loss: 1.8337570544212096

Epoch: 6| Step: 3
Training loss: 1.3461284637451172
Validation loss: 1.8452856950862433

Epoch: 6| Step: 4
Training loss: 1.1281230449676514
Validation loss: 1.8489405442309637

Epoch: 6| Step: 5
Training loss: 1.077417254447937
Validation loss: 1.8617708016467351

Epoch: 6| Step: 6
Training loss: 1.2398029565811157
Validation loss: 1.8525408096210931

Epoch: 6| Step: 7
Training loss: 0.8777531385421753
Validation loss: 1.849117204707156

Epoch: 6| Step: 8
Training loss: 0.937156617641449
Validation loss: 1.8222039899518412

Epoch: 6| Step: 9
Training loss: 0.8562793135643005
Validation loss: 1.7828304088243874

Epoch: 6| Step: 10
Training loss: 1.2242841720581055
Validation loss: 1.7773129440123034

Epoch: 6| Step: 11
Training loss: 1.0348281860351562
Validation loss: 1.7783181936510148

Epoch: 6| Step: 12
Training loss: 0.9880713224411011
Validation loss: 1.7888370175515451

Epoch: 6| Step: 13
Training loss: 1.4343981742858887
Validation loss: 1.7829101777845813

Epoch: 177| Step: 0
Training loss: 0.9342314004898071
Validation loss: 1.8168379158102057

Epoch: 6| Step: 1
Training loss: 1.1164714097976685
Validation loss: 1.8108473695734495

Epoch: 6| Step: 2
Training loss: 1.20082688331604
Validation loss: 1.814702646706694

Epoch: 6| Step: 3
Training loss: 1.0815831422805786
Validation loss: 1.8442286201702651

Epoch: 6| Step: 4
Training loss: 0.9777716398239136
Validation loss: 1.8221927996604674

Epoch: 6| Step: 5
Training loss: 0.5460185408592224
Validation loss: 1.8392922237355223

Epoch: 6| Step: 6
Training loss: 0.6005060076713562
Validation loss: 1.8185840165743263

Epoch: 6| Step: 7
Training loss: 0.7440720796585083
Validation loss: 1.8304031331052062

Epoch: 6| Step: 8
Training loss: 1.3258004188537598
Validation loss: 1.840912990672614

Epoch: 6| Step: 9
Training loss: 1.1229091882705688
Validation loss: 1.8473676853282477

Epoch: 6| Step: 10
Training loss: 0.7928858399391174
Validation loss: 1.8632079119323401

Epoch: 6| Step: 11
Training loss: 1.5668959617614746
Validation loss: 1.866819081767913

Epoch: 6| Step: 12
Training loss: 1.204563856124878
Validation loss: 1.866325404054375

Epoch: 6| Step: 13
Training loss: 0.4944874346256256
Validation loss: 1.863762790156949

Epoch: 178| Step: 0
Training loss: 0.9882347583770752
Validation loss: 1.8670384973608039

Epoch: 6| Step: 1
Training loss: 0.9641613960266113
Validation loss: 1.8475099943017448

Epoch: 6| Step: 2
Training loss: 1.199341893196106
Validation loss: 1.8459572381870721

Epoch: 6| Step: 3
Training loss: 1.2475252151489258
Validation loss: 1.8760774430408274

Epoch: 6| Step: 4
Training loss: 1.0501494407653809
Validation loss: 1.8395666935110604

Epoch: 6| Step: 5
Training loss: 0.7796040773391724
Validation loss: 1.822794868100074

Epoch: 6| Step: 6
Training loss: 1.0089900493621826
Validation loss: 1.8155329073629072

Epoch: 6| Step: 7
Training loss: 1.267446756362915
Validation loss: 1.8053817467022968

Epoch: 6| Step: 8
Training loss: 0.901812732219696
Validation loss: 1.8122886957660798

Epoch: 6| Step: 9
Training loss: 0.7667532563209534
Validation loss: 1.8344323699192335

Epoch: 6| Step: 10
Training loss: 1.0290030241012573
Validation loss: 1.8641832925940072

Epoch: 6| Step: 11
Training loss: 1.0387146472930908
Validation loss: 1.8586237968937043

Epoch: 6| Step: 12
Training loss: 0.8698092103004456
Validation loss: 1.8632857889257453

Epoch: 6| Step: 13
Training loss: 0.9534814357757568
Validation loss: 1.8743778800451627

Epoch: 179| Step: 0
Training loss: 1.100908875465393
Validation loss: 1.9021887061416463

Epoch: 6| Step: 1
Training loss: 0.8877524733543396
Validation loss: 1.9039873269296461

Epoch: 6| Step: 2
Training loss: 0.6577351689338684
Validation loss: 1.8833990199591524

Epoch: 6| Step: 3
Training loss: 1.0169484615325928
Validation loss: 1.8570443378981722

Epoch: 6| Step: 4
Training loss: 0.8307957649230957
Validation loss: 1.8299205457010577

Epoch: 6| Step: 5
Training loss: 0.9241654276847839
Validation loss: 1.8201761104727303

Epoch: 6| Step: 6
Training loss: 0.9802807569503784
Validation loss: 1.7992686943341327

Epoch: 6| Step: 7
Training loss: 1.328880786895752
Validation loss: 1.7936292361187678

Epoch: 6| Step: 8
Training loss: 0.9953727126121521
Validation loss: 1.7992963431983866

Epoch: 6| Step: 9
Training loss: 0.9757895469665527
Validation loss: 1.7945310492669382

Epoch: 6| Step: 10
Training loss: 1.293131947517395
Validation loss: 1.7852859573979531

Epoch: 6| Step: 11
Training loss: 1.0610990524291992
Validation loss: 1.7877368311728201

Epoch: 6| Step: 12
Training loss: 1.1332595348358154
Validation loss: 1.8387741029903453

Epoch: 6| Step: 13
Training loss: 0.4727713167667389
Validation loss: 1.84445144027792

Epoch: 180| Step: 0
Training loss: 1.0578746795654297
Validation loss: 1.8553438904464885

Epoch: 6| Step: 1
Training loss: 0.9505208134651184
Validation loss: 1.8529907631617721

Epoch: 6| Step: 2
Training loss: 1.1971135139465332
Validation loss: 1.862932405164165

Epoch: 6| Step: 3
Training loss: 0.911364734172821
Validation loss: 1.8538065315574728

Epoch: 6| Step: 4
Training loss: 1.2528190612792969
Validation loss: 1.8682684206193494

Epoch: 6| Step: 5
Training loss: 0.6323006749153137
Validation loss: 1.8639548734952045

Epoch: 6| Step: 6
Training loss: 0.9621140956878662
Validation loss: 1.8426633060619395

Epoch: 6| Step: 7
Training loss: 1.248517632484436
Validation loss: 1.8495223470913467

Epoch: 6| Step: 8
Training loss: 0.9313710331916809
Validation loss: 1.836798156461408

Epoch: 6| Step: 9
Training loss: 0.964867115020752
Validation loss: 1.8422455967113536

Epoch: 6| Step: 10
Training loss: 0.7142184972763062
Validation loss: 1.826184324038926

Epoch: 6| Step: 11
Training loss: 0.7402635812759399
Validation loss: 1.8390915829648253

Epoch: 6| Step: 12
Training loss: 1.1432251930236816
Validation loss: 1.798247334777668

Epoch: 6| Step: 13
Training loss: 1.1657655239105225
Validation loss: 1.8155099256064302

Epoch: 181| Step: 0
Training loss: 1.262199878692627
Validation loss: 1.8333697536940217

Epoch: 6| Step: 1
Training loss: 0.6859718561172485
Validation loss: 1.8211542803754088

Epoch: 6| Step: 2
Training loss: 0.5733869075775146
Validation loss: 1.8324213258681759

Epoch: 6| Step: 3
Training loss: 1.0359551906585693
Validation loss: 1.858729531688075

Epoch: 6| Step: 4
Training loss: 0.9709526300430298
Validation loss: 1.8529973619727678

Epoch: 6| Step: 5
Training loss: 0.8916069269180298
Validation loss: 1.8514688117529756

Epoch: 6| Step: 6
Training loss: 0.8737408518791199
Validation loss: 1.8662257604701544

Epoch: 6| Step: 7
Training loss: 1.0181374549865723
Validation loss: 1.8743551559345697

Epoch: 6| Step: 8
Training loss: 1.0378378629684448
Validation loss: 1.9230264361186693

Epoch: 6| Step: 9
Training loss: 1.0789463520050049
Validation loss: 1.90819582375147

Epoch: 6| Step: 10
Training loss: 1.1779905557632446
Validation loss: 1.8746388753255208

Epoch: 6| Step: 11
Training loss: 1.2145655155181885
Validation loss: 1.8411345430599746

Epoch: 6| Step: 12
Training loss: 1.170442819595337
Validation loss: 1.7930578403575446

Epoch: 6| Step: 13
Training loss: 0.8194441795349121
Validation loss: 1.759172845912236

Epoch: 182| Step: 0
Training loss: 0.8247252106666565
Validation loss: 1.7342097438791746

Epoch: 6| Step: 1
Training loss: 1.2336905002593994
Validation loss: 1.7293424606323242

Epoch: 6| Step: 2
Training loss: 1.4566422700881958
Validation loss: 1.7236332906189786

Epoch: 6| Step: 3
Training loss: 0.816818118095398
Validation loss: 1.7324814104264783

Epoch: 6| Step: 4
Training loss: 0.5523202419281006
Validation loss: 1.7454625163027035

Epoch: 6| Step: 5
Training loss: 1.0467286109924316
Validation loss: 1.7472010222814416

Epoch: 6| Step: 6
Training loss: 0.8602293729782104
Validation loss: 1.795282620255665

Epoch: 6| Step: 7
Training loss: 0.9783639311790466
Validation loss: 1.7842682010384017

Epoch: 6| Step: 8
Training loss: 0.4055725634098053
Validation loss: 1.8151380400503836

Epoch: 6| Step: 9
Training loss: 0.7880942821502686
Validation loss: 1.8582073693634362

Epoch: 6| Step: 10
Training loss: 1.5775442123413086
Validation loss: 1.8754635600633518

Epoch: 6| Step: 11
Training loss: 1.0624096393585205
Validation loss: 1.8687474368720927

Epoch: 6| Step: 12
Training loss: 0.9239670038223267
Validation loss: 1.8522505606374433

Epoch: 6| Step: 13
Training loss: 1.0591387748718262
Validation loss: 1.8486541906992595

Epoch: 183| Step: 0
Training loss: 0.8856498599052429
Validation loss: 1.820123957049462

Epoch: 6| Step: 1
Training loss: 0.724768877029419
Validation loss: 1.8272017202069681

Epoch: 6| Step: 2
Training loss: 0.9266442060470581
Validation loss: 1.8359738754969772

Epoch: 6| Step: 3
Training loss: 1.0988798141479492
Validation loss: 1.8333703587132115

Epoch: 6| Step: 4
Training loss: 0.719082772731781
Validation loss: 1.8366766821953557

Epoch: 6| Step: 5
Training loss: 0.8240503668785095
Validation loss: 1.837284053525617

Epoch: 6| Step: 6
Training loss: 0.8348677158355713
Validation loss: 1.8421522648103776

Epoch: 6| Step: 7
Training loss: 0.9822284579277039
Validation loss: 1.8441692513804282

Epoch: 6| Step: 8
Training loss: 0.7237023711204529
Validation loss: 1.8585442419975036

Epoch: 6| Step: 9
Training loss: 1.249332070350647
Validation loss: 1.8737767255434425

Epoch: 6| Step: 10
Training loss: 0.9846444129943848
Validation loss: 1.8652800308760775

Epoch: 6| Step: 11
Training loss: 1.1450821161270142
Validation loss: 1.884675718122913

Epoch: 6| Step: 12
Training loss: 0.8377965688705444
Validation loss: 1.861035523235157

Epoch: 6| Step: 13
Training loss: 0.9507375359535217
Validation loss: 1.8763631466896302

Epoch: 184| Step: 0
Training loss: 0.6161324977874756
Validation loss: 1.8536031861459055

Epoch: 6| Step: 1
Training loss: 0.9025707244873047
Validation loss: 1.8462969218530962

Epoch: 6| Step: 2
Training loss: 0.8825277090072632
Validation loss: 1.8611766869022

Epoch: 6| Step: 3
Training loss: 1.072662353515625
Validation loss: 1.8487527806271788

Epoch: 6| Step: 4
Training loss: 1.194305181503296
Validation loss: 1.8293307032636417

Epoch: 6| Step: 5
Training loss: 1.3774656057357788
Validation loss: 1.8469432489846342

Epoch: 6| Step: 6
Training loss: 0.9728477001190186
Validation loss: 1.845607865241266

Epoch: 6| Step: 7
Training loss: 0.9054509401321411
Validation loss: 1.8426904421980663

Epoch: 6| Step: 8
Training loss: 0.7097516059875488
Validation loss: 1.8555971512230494

Epoch: 6| Step: 9
Training loss: 0.8401607871055603
Validation loss: 1.8452997502460275

Epoch: 6| Step: 10
Training loss: 0.9626911878585815
Validation loss: 1.850355097042617

Epoch: 6| Step: 11
Training loss: 0.4296776056289673
Validation loss: 1.8691924925773375

Epoch: 6| Step: 12
Training loss: 0.8680402040481567
Validation loss: 1.8632025116233415

Epoch: 6| Step: 13
Training loss: 1.0793838500976562
Validation loss: 1.8568017559666787

Epoch: 185| Step: 0
Training loss: 0.9379664063453674
Validation loss: 1.8200973374869234

Epoch: 6| Step: 1
Training loss: 0.7555453181266785
Validation loss: 1.8211052802301222

Epoch: 6| Step: 2
Training loss: 0.6647567749023438
Validation loss: 1.8273421833592076

Epoch: 6| Step: 3
Training loss: 0.9027780294418335
Validation loss: 1.8119697916892268

Epoch: 6| Step: 4
Training loss: 1.4132053852081299
Validation loss: 1.8343307382317

Epoch: 6| Step: 5
Training loss: 1.0749396085739136
Validation loss: 1.8226552881220335

Epoch: 6| Step: 6
Training loss: 0.8637673854827881
Validation loss: 1.824175650073636

Epoch: 6| Step: 7
Training loss: 1.0781397819519043
Validation loss: 1.8126521777081233

Epoch: 6| Step: 8
Training loss: 0.39783015847206116
Validation loss: 1.8280276842014764

Epoch: 6| Step: 9
Training loss: 1.1133383512496948
Validation loss: 1.8489087384234193

Epoch: 6| Step: 10
Training loss: 0.9365864396095276
Validation loss: 1.8402195720262424

Epoch: 6| Step: 11
Training loss: 0.5543527603149414
Validation loss: 1.8702581749167493

Epoch: 6| Step: 12
Training loss: 0.8696349859237671
Validation loss: 1.8595239154754146

Epoch: 6| Step: 13
Training loss: 0.8714783191680908
Validation loss: 1.8744212888902234

Epoch: 186| Step: 0
Training loss: 0.5592583417892456
Validation loss: 1.876374590781427

Epoch: 6| Step: 1
Training loss: 0.9355804324150085
Validation loss: 1.8510857576965003

Epoch: 6| Step: 2
Training loss: 0.5441316962242126
Validation loss: 1.8197739675480833

Epoch: 6| Step: 3
Training loss: 1.0344293117523193
Validation loss: 1.8123925078299739

Epoch: 6| Step: 4
Training loss: 1.038581371307373
Validation loss: 1.7945467784840574

Epoch: 6| Step: 5
Training loss: 0.873880922794342
Validation loss: 1.7799444993336995

Epoch: 6| Step: 6
Training loss: 0.4856981337070465
Validation loss: 1.7742659584168465

Epoch: 6| Step: 7
Training loss: 1.0202250480651855
Validation loss: 1.7819815322916994

Epoch: 6| Step: 8
Training loss: 1.058786392211914
Validation loss: 1.7880941039772444

Epoch: 6| Step: 9
Training loss: 0.6792452931404114
Validation loss: 1.789476921481471

Epoch: 6| Step: 10
Training loss: 1.277871012687683
Validation loss: 1.8022056914144946

Epoch: 6| Step: 11
Training loss: 1.4840614795684814
Validation loss: 1.805861561529098

Epoch: 6| Step: 12
Training loss: 0.7405402660369873
Validation loss: 1.8172695675203878

Epoch: 6| Step: 13
Training loss: 0.9093632102012634
Validation loss: 1.8209259727949738

Epoch: 187| Step: 0
Training loss: 0.35690993070602417
Validation loss: 1.846313416316945

Epoch: 6| Step: 1
Training loss: 0.7493352293968201
Validation loss: 1.875378301066737

Epoch: 6| Step: 2
Training loss: 0.8098520040512085
Validation loss: 1.9021257790186072

Epoch: 6| Step: 3
Training loss: 0.6013159155845642
Validation loss: 1.9175032390061246

Epoch: 6| Step: 4
Training loss: 0.8669002056121826
Validation loss: 1.9366025514500116

Epoch: 6| Step: 5
Training loss: 0.6598113179206848
Validation loss: 1.8926553316013788

Epoch: 6| Step: 6
Training loss: 0.8799859285354614
Validation loss: 1.8586060757278113

Epoch: 6| Step: 7
Training loss: 1.248620629310608
Validation loss: 1.832874039167999

Epoch: 6| Step: 8
Training loss: 1.5180716514587402
Validation loss: 1.8149071842111566

Epoch: 6| Step: 9
Training loss: 1.2254530191421509
Validation loss: 1.7911046089664582

Epoch: 6| Step: 10
Training loss: 0.7869040369987488
Validation loss: 1.760498785203503

Epoch: 6| Step: 11
Training loss: 1.0679905414581299
Validation loss: 1.7352345938323646

Epoch: 6| Step: 12
Training loss: 0.9642863869667053
Validation loss: 1.7441983428052676

Epoch: 6| Step: 13
Training loss: 0.8290615677833557
Validation loss: 1.7322443454496321

Epoch: 188| Step: 0
Training loss: 1.0738294124603271
Validation loss: 1.7300944328308105

Epoch: 6| Step: 1
Training loss: 0.593866229057312
Validation loss: 1.7311886664359801

Epoch: 6| Step: 2
Training loss: 0.7418135404586792
Validation loss: 1.7614211600313905

Epoch: 6| Step: 3
Training loss: 0.6740861535072327
Validation loss: 1.7472243501294045

Epoch: 6| Step: 4
Training loss: 0.7809020280838013
Validation loss: 1.759061417272014

Epoch: 6| Step: 5
Training loss: 0.4875214993953705
Validation loss: 1.793843093738761

Epoch: 6| Step: 6
Training loss: 1.2216284275054932
Validation loss: 1.7957701734317246

Epoch: 6| Step: 7
Training loss: 0.8976665735244751
Validation loss: 1.8332835217957855

Epoch: 6| Step: 8
Training loss: 1.018094539642334
Validation loss: 1.912313017793881

Epoch: 6| Step: 9
Training loss: 0.7468140125274658
Validation loss: 1.93400070487812

Epoch: 6| Step: 10
Training loss: 1.08232581615448
Validation loss: 1.9273192574900966

Epoch: 6| Step: 11
Training loss: 0.9980466961860657
Validation loss: 1.8980136315027873

Epoch: 6| Step: 12
Training loss: 1.2093443870544434
Validation loss: 1.8610201317776915

Epoch: 6| Step: 13
Training loss: 1.2292168140411377
Validation loss: 1.8389203907341085

Epoch: 189| Step: 0
Training loss: 0.6392635107040405
Validation loss: 1.8231905903867496

Epoch: 6| Step: 1
Training loss: 0.9710524082183838
Validation loss: 1.8027224566346856

Epoch: 6| Step: 2
Training loss: 0.8015138506889343
Validation loss: 1.7977406132605769

Epoch: 6| Step: 3
Training loss: 0.8848347663879395
Validation loss: 1.7973665960373417

Epoch: 6| Step: 4
Training loss: 0.6863874793052673
Validation loss: 1.7876551484548917

Epoch: 6| Step: 5
Training loss: 0.6632633209228516
Validation loss: 1.7924910719676683

Epoch: 6| Step: 6
Training loss: 0.9595763087272644
Validation loss: 1.8085854450861614

Epoch: 6| Step: 7
Training loss: 0.7695757150650024
Validation loss: 1.834808603409798

Epoch: 6| Step: 8
Training loss: 0.7101520299911499
Validation loss: 1.846932352230113

Epoch: 6| Step: 9
Training loss: 1.1358522176742554
Validation loss: 1.8567866048505228

Epoch: 6| Step: 10
Training loss: 1.091610312461853
Validation loss: 1.8425773766732985

Epoch: 6| Step: 11
Training loss: 0.9577242136001587
Validation loss: 1.8315617884359052

Epoch: 6| Step: 12
Training loss: 1.0621843338012695
Validation loss: 1.8271349963321482

Epoch: 6| Step: 13
Training loss: 0.9309870600700378
Validation loss: 1.8341789066150624

Epoch: 190| Step: 0
Training loss: 0.7201869487762451
Validation loss: 1.8263337842879757

Epoch: 6| Step: 1
Training loss: 1.0019822120666504
Validation loss: 1.8185546731436124

Epoch: 6| Step: 2
Training loss: 0.7188632488250732
Validation loss: 1.8270436679163287

Epoch: 6| Step: 3
Training loss: 0.6355035305023193
Validation loss: 1.8254880366786834

Epoch: 6| Step: 4
Training loss: 0.83008873462677
Validation loss: 1.8020554601505239

Epoch: 6| Step: 5
Training loss: 0.8030271530151367
Validation loss: 1.8094782585738807

Epoch: 6| Step: 6
Training loss: 0.942727267742157
Validation loss: 1.8089814788551741

Epoch: 6| Step: 7
Training loss: 1.3648022413253784
Validation loss: 1.806995407227547

Epoch: 6| Step: 8
Training loss: 0.5353257656097412
Validation loss: 1.8001953478782409

Epoch: 6| Step: 9
Training loss: 0.6362497806549072
Validation loss: 1.801843612424789

Epoch: 6| Step: 10
Training loss: 0.6252442598342896
Validation loss: 1.8220940943687194

Epoch: 6| Step: 11
Training loss: 1.5484859943389893
Validation loss: 1.8182728418739893

Epoch: 6| Step: 12
Training loss: 0.44620102643966675
Validation loss: 1.78247848890161

Epoch: 6| Step: 13
Training loss: 0.8816335797309875
Validation loss: 1.8188217788614252

Epoch: 191| Step: 0
Training loss: 0.6808472871780396
Validation loss: 1.8343794820129231

Epoch: 6| Step: 1
Training loss: 1.0448050498962402
Validation loss: 1.8225692574695875

Epoch: 6| Step: 2
Training loss: 0.45920273661613464
Validation loss: 1.8351150815204909

Epoch: 6| Step: 3
Training loss: 1.264357566833496
Validation loss: 1.8061340355104016

Epoch: 6| Step: 4
Training loss: 0.6471372842788696
Validation loss: 1.807583644825925

Epoch: 6| Step: 5
Training loss: 0.8941890001296997
Validation loss: 1.8026130865978938

Epoch: 6| Step: 6
Training loss: 0.8027182817459106
Validation loss: 1.7875936236432803

Epoch: 6| Step: 7
Training loss: 0.6195526123046875
Validation loss: 1.8048329532787364

Epoch: 6| Step: 8
Training loss: 0.9374032020568848
Validation loss: 1.7992151283448743

Epoch: 6| Step: 9
Training loss: 0.9055906534194946
Validation loss: 1.8130768473430345

Epoch: 6| Step: 10
Training loss: 0.9137654304504395
Validation loss: 1.7904188248418993

Epoch: 6| Step: 11
Training loss: 0.9406178593635559
Validation loss: 1.8043648722351238

Epoch: 6| Step: 12
Training loss: 0.5109527111053467
Validation loss: 1.8176481621239775

Epoch: 6| Step: 13
Training loss: 0.839414656162262
Validation loss: 1.8095760268549765

Epoch: 192| Step: 0
Training loss: 0.649631142616272
Validation loss: 1.835357863415954

Epoch: 6| Step: 1
Training loss: 0.9674010276794434
Validation loss: 1.8750381597908594

Epoch: 6| Step: 2
Training loss: 1.0479180812835693
Validation loss: 1.930474091601628

Epoch: 6| Step: 3
Training loss: 0.8607863783836365
Validation loss: 1.9530920572178339

Epoch: 6| Step: 4
Training loss: 0.8941371440887451
Validation loss: 1.9504236482804822

Epoch: 6| Step: 5
Training loss: 1.2602133750915527
Validation loss: 1.9352953921082199

Epoch: 6| Step: 6
Training loss: 0.950870156288147
Validation loss: 1.900122166961752

Epoch: 6| Step: 7
Training loss: 0.8150970935821533
Validation loss: 1.8746161127603183

Epoch: 6| Step: 8
Training loss: 0.9767090678215027
Validation loss: 1.8653344185121599

Epoch: 6| Step: 9
Training loss: 0.568193256855011
Validation loss: 1.8448380808676443

Epoch: 6| Step: 10
Training loss: 0.47841063141822815
Validation loss: 1.8440529146502096

Epoch: 6| Step: 11
Training loss: 0.8335096836090088
Validation loss: 1.8242170003152662

Epoch: 6| Step: 12
Training loss: 0.5854526162147522
Validation loss: 1.7900479262874973

Epoch: 6| Step: 13
Training loss: 0.7869786620140076
Validation loss: 1.794674168350876

Epoch: 193| Step: 0
Training loss: 0.9437954425811768
Validation loss: 1.786350437389907

Epoch: 6| Step: 1
Training loss: 1.0714561939239502
Validation loss: 1.781247805523616

Epoch: 6| Step: 2
Training loss: 0.8864853382110596
Validation loss: 1.8038566279154953

Epoch: 6| Step: 3
Training loss: 0.8216477632522583
Validation loss: 1.800896365155456

Epoch: 6| Step: 4
Training loss: 0.8800135850906372
Validation loss: 1.8062340726134598

Epoch: 6| Step: 5
Training loss: 1.1070653200149536
Validation loss: 1.812727548742807

Epoch: 6| Step: 6
Training loss: 0.48815205693244934
Validation loss: 1.8291329978614725

Epoch: 6| Step: 7
Training loss: 0.6753324866294861
Validation loss: 1.8468160270362772

Epoch: 6| Step: 8
Training loss: 0.5054370164871216
Validation loss: 1.8555109231702742

Epoch: 6| Step: 9
Training loss: 0.7328399419784546
Validation loss: 1.8760483687923801

Epoch: 6| Step: 10
Training loss: 0.9364426732063293
Validation loss: 1.9165639313318397

Epoch: 6| Step: 11
Training loss: 0.8470561504364014
Validation loss: 1.9138814428801179

Epoch: 6| Step: 12
Training loss: 0.8182544708251953
Validation loss: 1.8611533411087529

Epoch: 6| Step: 13
Training loss: 0.9313748478889465
Validation loss: 1.8606811697765062

Epoch: 194| Step: 0
Training loss: 0.5762370824813843
Validation loss: 1.8380985413828204

Epoch: 6| Step: 1
Training loss: 1.0162439346313477
Validation loss: 1.8175169742235573

Epoch: 6| Step: 2
Training loss: 0.42821088433265686
Validation loss: 1.8180382149193877

Epoch: 6| Step: 3
Training loss: 0.9227336049079895
Validation loss: 1.8295804608252741

Epoch: 6| Step: 4
Training loss: 0.7405575513839722
Validation loss: 1.842129961777759

Epoch: 6| Step: 5
Training loss: 0.8598015904426575
Validation loss: 1.8435128491411927

Epoch: 6| Step: 6
Training loss: 0.6852030754089355
Validation loss: 1.8681905590077883

Epoch: 6| Step: 7
Training loss: 0.8187534809112549
Validation loss: 1.8693191569338563

Epoch: 6| Step: 8
Training loss: 1.188849687576294
Validation loss: 1.900054536839967

Epoch: 6| Step: 9
Training loss: 0.7263676524162292
Validation loss: 1.8816331919803415

Epoch: 6| Step: 10
Training loss: 1.150716781616211
Validation loss: 1.8987453253038469

Epoch: 6| Step: 11
Training loss: 0.8740866184234619
Validation loss: 1.8867792775554042

Epoch: 6| Step: 12
Training loss: 0.615989089012146
Validation loss: 1.89587325690895

Epoch: 6| Step: 13
Training loss: 0.9668896794319153
Validation loss: 1.8726900546781478

Epoch: 195| Step: 0
Training loss: 0.7197989225387573
Validation loss: 1.8837676048278809

Epoch: 6| Step: 1
Training loss: 0.4438738226890564
Validation loss: 1.8616175779732325

Epoch: 6| Step: 2
Training loss: 1.0151355266571045
Validation loss: 1.891601248454022

Epoch: 6| Step: 3
Training loss: 0.3735559582710266
Validation loss: 1.8498074444391395

Epoch: 6| Step: 4
Training loss: 0.8296369314193726
Validation loss: 1.8523034152164255

Epoch: 6| Step: 5
Training loss: 1.0502969026565552
Validation loss: 1.8295522300145959

Epoch: 6| Step: 6
Training loss: 0.8524032831192017
Validation loss: 1.8630264779572845

Epoch: 6| Step: 7
Training loss: 0.7215691804885864
Validation loss: 1.8597509104718444

Epoch: 6| Step: 8
Training loss: 0.5970652103424072
Validation loss: 1.8527517523816837

Epoch: 6| Step: 9
Training loss: 1.1879336833953857
Validation loss: 1.8520070019588675

Epoch: 6| Step: 10
Training loss: 0.8944923281669617
Validation loss: 1.8620863601725588

Epoch: 6| Step: 11
Training loss: 0.9374096393585205
Validation loss: 1.8729538584268222

Epoch: 6| Step: 12
Training loss: 0.5024563074111938
Validation loss: 1.8660323812115578

Epoch: 6| Step: 13
Training loss: 1.120951771736145
Validation loss: 1.8755092479849373

Epoch: 196| Step: 0
Training loss: 0.6357361078262329
Validation loss: 1.8857245099159978

Epoch: 6| Step: 1
Training loss: 0.8775103688240051
Validation loss: 1.8698973348063808

Epoch: 6| Step: 2
Training loss: 0.7255427837371826
Validation loss: 1.8764009937163322

Epoch: 6| Step: 3
Training loss: 0.7082416415214539
Validation loss: 1.8448454064707602

Epoch: 6| Step: 4
Training loss: 0.8652868270874023
Validation loss: 1.857835321016209

Epoch: 6| Step: 5
Training loss: 0.9637221097946167
Validation loss: 1.861905926017351

Epoch: 6| Step: 6
Training loss: 0.6511809229850769
Validation loss: 1.850612009725263

Epoch: 6| Step: 7
Training loss: 0.667791485786438
Validation loss: 1.8540262009507866

Epoch: 6| Step: 8
Training loss: 0.6318416595458984
Validation loss: 1.8442624948358024

Epoch: 6| Step: 9
Training loss: 0.8612523078918457
Validation loss: 1.8476563397274222

Epoch: 6| Step: 10
Training loss: 0.7171409130096436
Validation loss: 1.8279584607770365

Epoch: 6| Step: 11
Training loss: 0.7735780477523804
Validation loss: 1.8271800369344733

Epoch: 6| Step: 12
Training loss: 1.1022343635559082
Validation loss: 1.789348683049602

Epoch: 6| Step: 13
Training loss: 0.8310267329216003
Validation loss: 1.7824711543257519

Epoch: 197| Step: 0
Training loss: 0.4079194664955139
Validation loss: 1.7745789276656283

Epoch: 6| Step: 1
Training loss: 0.6711419820785522
Validation loss: 1.7806645119062035

Epoch: 6| Step: 2
Training loss: 1.1804382801055908
Validation loss: 1.7890187296816098

Epoch: 6| Step: 3
Training loss: 0.6341243982315063
Validation loss: 1.80090348182186

Epoch: 6| Step: 4
Training loss: 0.40448814630508423
Validation loss: 1.794744986359791

Epoch: 6| Step: 5
Training loss: 1.0238125324249268
Validation loss: 1.8013437076281476

Epoch: 6| Step: 6
Training loss: 0.5669917464256287
Validation loss: 1.802177821436236

Epoch: 6| Step: 7
Training loss: 1.1605781316757202
Validation loss: 1.7856988124949957

Epoch: 6| Step: 8
Training loss: 0.780032217502594
Validation loss: 1.7791786398938907

Epoch: 6| Step: 9
Training loss: 0.7930059432983398
Validation loss: 1.8109102813146447

Epoch: 6| Step: 10
Training loss: 0.6185017824172974
Validation loss: 1.8182975105060044

Epoch: 6| Step: 11
Training loss: 0.9317917823791504
Validation loss: 1.8042274034151466

Epoch: 6| Step: 12
Training loss: 1.014538049697876
Validation loss: 1.8416044173702117

Epoch: 6| Step: 13
Training loss: 0.491375595331192
Validation loss: 1.8280758626999394

Epoch: 198| Step: 0
Training loss: 1.011102318763733
Validation loss: 1.8417815341744372

Epoch: 6| Step: 1
Training loss: 0.8561339974403381
Validation loss: 1.7936363348396875

Epoch: 6| Step: 2
Training loss: 0.7729870080947876
Validation loss: 1.7963114169336134

Epoch: 6| Step: 3
Training loss: 0.4418450891971588
Validation loss: 1.8189022669228174

Epoch: 6| Step: 4
Training loss: 0.9563854932785034
Validation loss: 1.7956032727354316

Epoch: 6| Step: 5
Training loss: 0.584004282951355
Validation loss: 1.793449414673672

Epoch: 6| Step: 6
Training loss: 0.6372075080871582
Validation loss: 1.7804336906761251

Epoch: 6| Step: 7
Training loss: 0.3967669904232025
Validation loss: 1.78450684906334

Epoch: 6| Step: 8
Training loss: 0.6464921832084656
Validation loss: 1.7976470634501467

Epoch: 6| Step: 9
Training loss: 1.2097737789154053
Validation loss: 1.8125814648084744

Epoch: 6| Step: 10
Training loss: 0.7982320785522461
Validation loss: 1.8199563077701035

Epoch: 6| Step: 11
Training loss: 0.6203664541244507
Validation loss: 1.7901400263591478

Epoch: 6| Step: 12
Training loss: 0.8917734622955322
Validation loss: 1.782351024689213

Epoch: 6| Step: 13
Training loss: 0.8955402374267578
Validation loss: 1.754963389006994

Epoch: 199| Step: 0
Training loss: 1.1502549648284912
Validation loss: 1.7547020450715096

Epoch: 6| Step: 1
Training loss: 0.9003746509552002
Validation loss: 1.7589060465494792

Epoch: 6| Step: 2
Training loss: 0.6993796825408936
Validation loss: 1.7620873540960333

Epoch: 6| Step: 3
Training loss: 0.8261086940765381
Validation loss: 1.7898644247362692

Epoch: 6| Step: 4
Training loss: 0.7155377864837646
Validation loss: 1.7895977907283331

Epoch: 6| Step: 5
Training loss: 1.0946139097213745
Validation loss: 1.79219497916519

Epoch: 6| Step: 6
Training loss: 0.5855152606964111
Validation loss: 1.8100290388189337

Epoch: 6| Step: 7
Training loss: 0.3977224826812744
Validation loss: 1.8278370723929456

Epoch: 6| Step: 8
Training loss: 0.3401051461696625
Validation loss: 1.812967026105491

Epoch: 6| Step: 9
Training loss: 0.9643574953079224
Validation loss: 1.8151224582426009

Epoch: 6| Step: 10
Training loss: 0.5474529266357422
Validation loss: 1.8223596952294792

Epoch: 6| Step: 11
Training loss: 0.9242503643035889
Validation loss: 1.8502170937035674

Epoch: 6| Step: 12
Training loss: 0.8654389381408691
Validation loss: 1.8208711736945695

Epoch: 6| Step: 13
Training loss: 0.3922180235385895
Validation loss: 1.821765608684991

Epoch: 200| Step: 0
Training loss: 0.4988734722137451
Validation loss: 1.8431955960489088

Epoch: 6| Step: 1
Training loss: 0.7229763269424438
Validation loss: 1.8309747634395477

Epoch: 6| Step: 2
Training loss: 1.3425719738006592
Validation loss: 1.823989760491156

Epoch: 6| Step: 3
Training loss: 0.5887864232063293
Validation loss: 1.835397534472968

Epoch: 6| Step: 4
Training loss: 0.667579174041748
Validation loss: 1.8124263235317764

Epoch: 6| Step: 5
Training loss: 0.7126548290252686
Validation loss: 1.845058205307171

Epoch: 6| Step: 6
Training loss: 1.082256555557251
Validation loss: 1.846151485238024

Epoch: 6| Step: 7
Training loss: 0.5915656089782715
Validation loss: 1.7973902866404543

Epoch: 6| Step: 8
Training loss: 0.9471803903579712
Validation loss: 1.801558417658652

Epoch: 6| Step: 9
Training loss: 0.5476677417755127
Validation loss: 1.8171994993763585

Epoch: 6| Step: 10
Training loss: 0.5628261566162109
Validation loss: 1.8106734291199715

Epoch: 6| Step: 11
Training loss: 1.018660068511963
Validation loss: 1.8055957235315794

Epoch: 6| Step: 12
Training loss: 0.5872290134429932
Validation loss: 1.8166266615672777

Epoch: 6| Step: 13
Training loss: 0.5321521162986755
Validation loss: 1.8211719041229577

Testing loss: 2.226291529337565
