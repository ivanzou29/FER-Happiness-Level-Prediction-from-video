Epoch: 1| Step: 0
Training loss: 5.902945426604642
Validation loss: 5.852626206215376

Epoch: 5| Step: 1
Training loss: 5.557578320485468
Validation loss: 5.829302562726381

Epoch: 5| Step: 2
Training loss: 6.757751817375667
Validation loss: 5.809831666389137

Epoch: 5| Step: 3
Training loss: 4.753720683454563
Validation loss: 5.791002786896004

Epoch: 5| Step: 4
Training loss: 5.849051778516213
Validation loss: 5.769002662337255

Epoch: 5| Step: 5
Training loss: 6.539339595196796
Validation loss: 5.7435596167469445

Epoch: 5| Step: 6
Training loss: 5.626837197261213
Validation loss: 5.714850227683628

Epoch: 5| Step: 7
Training loss: 5.269034620315009
Validation loss: 5.680450188287984

Epoch: 5| Step: 8
Training loss: 5.423075166609376
Validation loss: 5.6413478675027795

Epoch: 5| Step: 9
Training loss: 5.821103527412605
Validation loss: 5.5974320492006004

Epoch: 5| Step: 10
Training loss: 5.601170907904059
Validation loss: 5.546544000807008

Epoch: 2| Step: 0
Training loss: 5.704589321322892
Validation loss: 5.490278185526632

Epoch: 5| Step: 1
Training loss: 4.45171304369874
Validation loss: 5.427039678402479

Epoch: 5| Step: 2
Training loss: 6.145123491404332
Validation loss: 5.3585296521917645

Epoch: 5| Step: 3
Training loss: 5.030738188495939
Validation loss: 5.285132198516847

Epoch: 5| Step: 4
Training loss: 5.708850400946816
Validation loss: 5.2093870308775605

Epoch: 5| Step: 5
Training loss: 4.822964277368885
Validation loss: 5.130383085259606

Epoch: 5| Step: 6
Training loss: 5.139332153631594
Validation loss: 5.051156708160911

Epoch: 5| Step: 7
Training loss: 5.185758735078915
Validation loss: 4.97731000681412

Epoch: 5| Step: 8
Training loss: 4.8716340793942665
Validation loss: 4.9019415891417495

Epoch: 5| Step: 9
Training loss: 4.361833651568464
Validation loss: 4.831576242606799

Epoch: 5| Step: 10
Training loss: 5.445774316017969
Validation loss: 4.767785122693408

Epoch: 3| Step: 0
Training loss: 4.338160369469454
Validation loss: 4.705688092123726

Epoch: 5| Step: 1
Training loss: 4.850197518642785
Validation loss: 4.651579624494075

Epoch: 5| Step: 2
Training loss: 5.068949041444945
Validation loss: 4.601021220027391

Epoch: 5| Step: 3
Training loss: 4.575078060964207
Validation loss: 4.553718759514371

Epoch: 5| Step: 4
Training loss: 5.306501165585599
Validation loss: 4.513941001791101

Epoch: 5| Step: 5
Training loss: 4.2372478578883825
Validation loss: 4.478331293884099

Epoch: 5| Step: 6
Training loss: 4.226065389622854
Validation loss: 4.450780264260131

Epoch: 5| Step: 7
Training loss: 4.548720991184187
Validation loss: 4.421655498503352

Epoch: 5| Step: 8
Training loss: 4.37571013000698
Validation loss: 4.391547346053743

Epoch: 5| Step: 9
Training loss: 4.5023036994059575
Validation loss: 4.362467520100706

Epoch: 5| Step: 10
Training loss: 4.488586787223295
Validation loss: 4.340088103494415

Epoch: 4| Step: 0
Training loss: 3.983063844851484
Validation loss: 4.314183251902559

Epoch: 5| Step: 1
Training loss: 4.824268170926008
Validation loss: 4.288412085631671

Epoch: 5| Step: 2
Training loss: 4.478411706982324
Validation loss: 4.265317683204428

Epoch: 5| Step: 3
Training loss: 3.8488435568965214
Validation loss: 4.24402625166603

Epoch: 5| Step: 4
Training loss: 3.8572564739064426
Validation loss: 4.2240057301359695

Epoch: 5| Step: 5
Training loss: 3.8851909145739527
Validation loss: 4.2059977867356215

Epoch: 5| Step: 6
Training loss: 4.976449626798359
Validation loss: 4.191084685165556

Epoch: 5| Step: 7
Training loss: 4.685947008368146
Validation loss: 4.1676367994172345

Epoch: 5| Step: 8
Training loss: 3.7357482938825766
Validation loss: 4.154533229665886

Epoch: 5| Step: 9
Training loss: 4.364845917419365
Validation loss: 4.151183587180315

Epoch: 5| Step: 10
Training loss: 4.951740637018836
Validation loss: 4.143598562159138

Epoch: 5| Step: 0
Training loss: 4.445066850843942
Validation loss: 4.104702181827923

Epoch: 5| Step: 1
Training loss: 4.433513301169897
Validation loss: 4.093387107041638

Epoch: 5| Step: 2
Training loss: 4.494901099554404
Validation loss: 4.089931535478498

Epoch: 5| Step: 3
Training loss: 3.914734194563778
Validation loss: 4.087506539733839

Epoch: 5| Step: 4
Training loss: 3.9735047701092614
Validation loss: 4.063700693049974

Epoch: 5| Step: 5
Training loss: 4.296504334154477
Validation loss: 4.045063152458339

Epoch: 5| Step: 6
Training loss: 3.755237990150677
Validation loss: 4.027774420031849

Epoch: 5| Step: 7
Training loss: 4.372407199404834
Validation loss: 4.0131660556474

Epoch: 5| Step: 8
Training loss: 4.088533761893566
Validation loss: 4.023753629172849

Epoch: 5| Step: 9
Training loss: 4.3131945506846385
Validation loss: 4.026310839271943

Epoch: 5| Step: 10
Training loss: 4.02452887390069
Validation loss: 3.985913787386775

Epoch: 6| Step: 0
Training loss: 3.220230798920386
Validation loss: 3.9798251840215078

Epoch: 5| Step: 1
Training loss: 4.688609894642614
Validation loss: 3.9795306661569843

Epoch: 5| Step: 2
Training loss: 5.027483175696283
Validation loss: 3.9776578333048502

Epoch: 5| Step: 3
Training loss: 4.069780604192291
Validation loss: 3.973738232016662

Epoch: 5| Step: 4
Training loss: 3.956761673898336
Validation loss: 3.9626955064278286

Epoch: 5| Step: 5
Training loss: 4.15962598403106
Validation loss: 3.9467332268453745

Epoch: 5| Step: 6
Training loss: 3.4143071905305464
Validation loss: 3.929268006553685

Epoch: 5| Step: 7
Training loss: 3.9369799558145266
Validation loss: 3.9117000396954835

Epoch: 5| Step: 8
Training loss: 3.826421989456213
Validation loss: 3.900763035350421

Epoch: 5| Step: 9
Training loss: 4.610974050627116
Validation loss: 3.886336019916293

Epoch: 5| Step: 10
Training loss: 3.774329291375018
Validation loss: 3.8888061689455764

Epoch: 7| Step: 0
Training loss: 3.8152788384804124
Validation loss: 3.8723545524787375

Epoch: 5| Step: 1
Training loss: 4.295849043000015
Validation loss: 3.850774898355755

Epoch: 5| Step: 2
Training loss: 4.7165095587311745
Validation loss: 3.843768070664352

Epoch: 5| Step: 3
Training loss: 4.591777559707887
Validation loss: 3.8423623588999662

Epoch: 5| Step: 4
Training loss: 3.5150481026235365
Validation loss: 3.832593738602974

Epoch: 5| Step: 5
Training loss: 3.860827338740103
Validation loss: 3.8187241095686724

Epoch: 5| Step: 6
Training loss: 4.029477698317765
Validation loss: 3.8072508138414713

Epoch: 5| Step: 7
Training loss: 3.68312226693314
Validation loss: 3.7933927679849293

Epoch: 5| Step: 8
Training loss: 3.9400522346713216
Validation loss: 3.7840887532973797

Epoch: 5| Step: 9
Training loss: 3.6098746081948123
Validation loss: 3.7764886139941694

Epoch: 5| Step: 10
Training loss: 3.6243401288550317
Validation loss: 3.7691094598363817

Epoch: 8| Step: 0
Training loss: 3.2471280246281014
Validation loss: 3.757855033211682

Epoch: 5| Step: 1
Training loss: 4.1130308417368
Validation loss: 3.7439732965850694

Epoch: 5| Step: 2
Training loss: 4.020856366396274
Validation loss: 3.731435262510632

Epoch: 5| Step: 3
Training loss: 3.747479672672652
Validation loss: 3.72082611725613

Epoch: 5| Step: 4
Training loss: 3.3777114431521063
Validation loss: 3.714073108722811

Epoch: 5| Step: 5
Training loss: 4.600711659653162
Validation loss: 3.707454060509891

Epoch: 5| Step: 6
Training loss: 3.5276086988672963
Validation loss: 3.6970033651585235

Epoch: 5| Step: 7
Training loss: 3.9081677421405554
Validation loss: 3.6867693077523755

Epoch: 5| Step: 8
Training loss: 4.575447210748336
Validation loss: 3.6788691368833146

Epoch: 5| Step: 9
Training loss: 4.081883594817548
Validation loss: 3.671119936613942

Epoch: 5| Step: 10
Training loss: 3.221662962454692
Validation loss: 3.6610051069476706

Epoch: 9| Step: 0
Training loss: 3.309062685831843
Validation loss: 3.649380430409335

Epoch: 5| Step: 1
Training loss: 4.093243516646947
Validation loss: 3.6391028265389878

Epoch: 5| Step: 2
Training loss: 3.7146712302211635
Validation loss: 3.6274499785848398

Epoch: 5| Step: 3
Training loss: 3.790865439693204
Validation loss: 3.6202797615595927

Epoch: 5| Step: 4
Training loss: 4.040495450450034
Validation loss: 3.619997019803077

Epoch: 5| Step: 5
Training loss: 3.4578124117431077
Validation loss: 3.611289496915601

Epoch: 5| Step: 6
Training loss: 4.0910062258199105
Validation loss: 3.6183266803869625

Epoch: 5| Step: 7
Training loss: 3.884289220843328
Validation loss: 3.607217869372659

Epoch: 5| Step: 8
Training loss: 4.186241985779247
Validation loss: 3.6012991991212675

Epoch: 5| Step: 9
Training loss: 3.4596417414681944
Validation loss: 3.5844153516034236

Epoch: 5| Step: 10
Training loss: 3.7668956338163198
Validation loss: 3.580012795959417

Epoch: 10| Step: 0
Training loss: 2.8645676121135835
Validation loss: 3.572112129032883

Epoch: 5| Step: 1
Training loss: 3.5030188484000617
Validation loss: 3.5634145478517167

Epoch: 5| Step: 2
Training loss: 4.114346937639873
Validation loss: 3.552217273077228

Epoch: 5| Step: 3
Training loss: 3.540187362195431
Validation loss: 3.5429956846423893

Epoch: 5| Step: 4
Training loss: 4.50388719301584
Validation loss: 3.5349293904952144

Epoch: 5| Step: 5
Training loss: 3.7717010736069025
Validation loss: 3.529218480830485

Epoch: 5| Step: 6
Training loss: 3.138749506808675
Validation loss: 3.5292227811432593

Epoch: 5| Step: 7
Training loss: 3.931476527057016
Validation loss: 3.529646503330043

Epoch: 5| Step: 8
Training loss: 4.558940178032061
Validation loss: 3.5058895928204348

Epoch: 5| Step: 9
Training loss: 3.2269103668597725
Validation loss: 3.503109832186657

Epoch: 5| Step: 10
Training loss: 3.530880799024366
Validation loss: 3.497279536750096

Epoch: 11| Step: 0
Training loss: 3.4340253435020616
Validation loss: 3.4968083899501083

Epoch: 5| Step: 1
Training loss: 2.809439541050947
Validation loss: 3.4916381389151403

Epoch: 5| Step: 2
Training loss: 3.677732430172415
Validation loss: 3.487961917354702

Epoch: 5| Step: 3
Training loss: 3.2893404084361353
Validation loss: 3.4841199270442433

Epoch: 5| Step: 4
Training loss: 4.113185261967613
Validation loss: 3.476390029557677

Epoch: 5| Step: 5
Training loss: 3.9239495250554772
Validation loss: 3.47068860898716

Epoch: 5| Step: 6
Training loss: 3.876859403385447
Validation loss: 3.4611980410811802

Epoch: 5| Step: 7
Training loss: 3.4838464447238544
Validation loss: 3.452190873618468

Epoch: 5| Step: 8
Training loss: 3.6089572417024454
Validation loss: 3.444631045248109

Epoch: 5| Step: 9
Training loss: 4.12150911524953
Validation loss: 3.4376525576570303

Epoch: 5| Step: 10
Training loss: 3.979813541472783
Validation loss: 3.433185192507846

Epoch: 12| Step: 0
Training loss: 3.3989122782579972
Validation loss: 3.4306368407522916

Epoch: 5| Step: 1
Training loss: 3.4963969349595354
Validation loss: 3.423564061551388

Epoch: 5| Step: 2
Training loss: 3.2305230686183
Validation loss: 3.4174095374670537

Epoch: 5| Step: 3
Training loss: 3.0810040791703375
Validation loss: 3.4136562415915415

Epoch: 5| Step: 4
Training loss: 3.7240155551311003
Validation loss: 3.467086897346478

Epoch: 5| Step: 5
Training loss: 3.58295085255556
Validation loss: 3.4114071597078275

Epoch: 5| Step: 6
Training loss: 3.6038474821785518
Validation loss: 3.419603046901637

Epoch: 5| Step: 7
Training loss: 4.07467891621704
Validation loss: 3.4238328976210037

Epoch: 5| Step: 8
Training loss: 3.556084863351673
Validation loss: 3.4142820684196304

Epoch: 5| Step: 9
Training loss: 4.496324733763142
Validation loss: 3.400307959852009

Epoch: 5| Step: 10
Training loss: 3.6349631885621823
Validation loss: 3.3878221612098836

Epoch: 13| Step: 0
Training loss: 3.603818505436892
Validation loss: 3.4080882129148478

Epoch: 5| Step: 1
Training loss: 4.028354048154193
Validation loss: 3.41122876769241

Epoch: 5| Step: 2
Training loss: 3.48946211115629
Validation loss: 3.3847556188990615

Epoch: 5| Step: 3
Training loss: 3.8230335241988707
Validation loss: 3.370254773618896

Epoch: 5| Step: 4
Training loss: 3.825091222535454
Validation loss: 3.3680669991486605

Epoch: 5| Step: 5
Training loss: 3.606606350486646
Validation loss: 3.369715105835284

Epoch: 5| Step: 6
Training loss: 3.399206596252836
Validation loss: 3.366010392146814

Epoch: 5| Step: 7
Training loss: 2.8143555348278255
Validation loss: 3.3641514248364386

Epoch: 5| Step: 8
Training loss: 3.385983854855814
Validation loss: 3.3570183033208734

Epoch: 5| Step: 9
Training loss: 3.383015474568787
Validation loss: 3.351112262623395

Epoch: 5| Step: 10
Training loss: 4.214557740527728
Validation loss: 3.3430226389458655

Epoch: 14| Step: 0
Training loss: 3.656537558178184
Validation loss: 3.3385216793925925

Epoch: 5| Step: 1
Training loss: 3.086507778348875
Validation loss: 3.345449050274677

Epoch: 5| Step: 2
Training loss: 3.1098330366449107
Validation loss: 3.3365358616841814

Epoch: 5| Step: 3
Training loss: 3.7292973301904118
Validation loss: 3.3301602771183654

Epoch: 5| Step: 4
Training loss: 3.7532286414479668
Validation loss: 3.326608075946029

Epoch: 5| Step: 5
Training loss: 3.2605949247500314
Validation loss: 3.3239924703994275

Epoch: 5| Step: 6
Training loss: 3.615437226295082
Validation loss: 3.3215987823775928

Epoch: 5| Step: 7
Training loss: 3.849424561932317
Validation loss: 3.320133095031832

Epoch: 5| Step: 8
Training loss: 3.259327341903493
Validation loss: 3.3159749267912995

Epoch: 5| Step: 9
Training loss: 3.860577971122739
Validation loss: 3.311658152096021

Epoch: 5| Step: 10
Training loss: 3.9350322680380256
Validation loss: 3.308194040151757

Epoch: 15| Step: 0
Training loss: 3.569141287655898
Validation loss: 3.3033163984471465

Epoch: 5| Step: 1
Training loss: 3.749374083099024
Validation loss: 3.3019180207301098

Epoch: 5| Step: 2
Training loss: 4.242391844828042
Validation loss: 3.29971883663017

Epoch: 5| Step: 3
Training loss: 3.1593396766868844
Validation loss: 3.2945247271015696

Epoch: 5| Step: 4
Training loss: 3.1002245114151328
Validation loss: 3.289392171220041

Epoch: 5| Step: 5
Training loss: 3.1877635772035395
Validation loss: 3.2873018380115435

Epoch: 5| Step: 6
Training loss: 3.7727091779410724
Validation loss: 3.280090606920147

Epoch: 5| Step: 7
Training loss: 3.665223805878732
Validation loss: 3.278994983981606

Epoch: 5| Step: 8
Training loss: 3.764485800232075
Validation loss: 3.274155061777379

Epoch: 5| Step: 9
Training loss: 3.201032597116933
Validation loss: 3.2678904626988534

Epoch: 5| Step: 10
Training loss: 3.200783520381868
Validation loss: 3.267335293427919

Epoch: 16| Step: 0
Training loss: 4.225627577179573
Validation loss: 3.262459043538751

Epoch: 5| Step: 1
Training loss: 2.906892930973894
Validation loss: 3.2590971326841585

Epoch: 5| Step: 2
Training loss: 3.895640254548524
Validation loss: 3.2554665760930455

Epoch: 5| Step: 3
Training loss: 3.9595758328464945
Validation loss: 3.250186654497905

Epoch: 5| Step: 4
Training loss: 3.3092494346420476
Validation loss: 3.2456659457858663

Epoch: 5| Step: 5
Training loss: 2.5686068455515256
Validation loss: 3.241305206473959

Epoch: 5| Step: 6
Training loss: 3.45645781680368
Validation loss: 3.237589708805992

Epoch: 5| Step: 7
Training loss: 3.300459517650372
Validation loss: 3.234701598163852

Epoch: 5| Step: 8
Training loss: 3.5386788873995676
Validation loss: 3.226900248643085

Epoch: 5| Step: 9
Training loss: 3.3399471155422717
Validation loss: 3.231155018870232

Epoch: 5| Step: 10
Training loss: 3.6656730056832303
Validation loss: 3.2267899805869105

Epoch: 17| Step: 0
Training loss: 4.032958622280105
Validation loss: 3.213739227355872

Epoch: 5| Step: 1
Training loss: 3.5472843421296885
Validation loss: 3.2095868847708102

Epoch: 5| Step: 2
Training loss: 3.7648921269215614
Validation loss: 3.2078763052695223

Epoch: 5| Step: 3
Training loss: 3.277593700893942
Validation loss: 3.204824391908341

Epoch: 5| Step: 4
Training loss: 3.6233499652114682
Validation loss: 3.204277843163457

Epoch: 5| Step: 5
Training loss: 3.3704438715812333
Validation loss: 3.196258728150689

Epoch: 5| Step: 6
Training loss: 2.832243728559367
Validation loss: 3.1932665037150283

Epoch: 5| Step: 7
Training loss: 3.5701554345238464
Validation loss: 3.1849620880854794

Epoch: 5| Step: 8
Training loss: 2.86479498803777
Validation loss: 3.181244441691844

Epoch: 5| Step: 9
Training loss: 3.321426312494169
Validation loss: 3.1750081520922238

Epoch: 5| Step: 10
Training loss: 3.6759393801915805
Validation loss: 3.1693538254126152

Epoch: 18| Step: 0
Training loss: 3.39583191354796
Validation loss: 3.1622811947937746

Epoch: 5| Step: 1
Training loss: 3.274430226855792
Validation loss: 3.1567499785546826

Epoch: 5| Step: 2
Training loss: 3.3984483039070366
Validation loss: 3.15364654490336

Epoch: 5| Step: 3
Training loss: 3.256974293116313
Validation loss: 3.1521503989825055

Epoch: 5| Step: 4
Training loss: 2.627055952477509
Validation loss: 3.1474799595255853

Epoch: 5| Step: 5
Training loss: 2.47530123486175
Validation loss: 3.1443742039624443

Epoch: 5| Step: 6
Training loss: 3.198922876037104
Validation loss: 3.1423033603590413

Epoch: 5| Step: 7
Training loss: 4.132530274877405
Validation loss: 3.1361750021337844

Epoch: 5| Step: 8
Training loss: 3.7565348588576932
Validation loss: 3.1341471578236115

Epoch: 5| Step: 9
Training loss: 3.928310752245924
Validation loss: 3.1328376861272607

Epoch: 5| Step: 10
Training loss: 3.7887166602802016
Validation loss: 3.133876823198286

Epoch: 19| Step: 0
Training loss: 3.5487698102494187
Validation loss: 3.128209512320115

Epoch: 5| Step: 1
Training loss: 2.937659401322541
Validation loss: 3.1252910306218906

Epoch: 5| Step: 2
Training loss: 3.1346183766039784
Validation loss: 3.1221045010820583

Epoch: 5| Step: 3
Training loss: 3.625440241948143
Validation loss: 3.1197401199274633

Epoch: 5| Step: 4
Training loss: 4.087183220863508
Validation loss: 3.115030569710262

Epoch: 5| Step: 5
Training loss: 3.6706959231432754
Validation loss: 3.1158707494794906

Epoch: 5| Step: 6
Training loss: 3.3043297828797114
Validation loss: 3.1142225548699063

Epoch: 5| Step: 7
Training loss: 2.837819213388763
Validation loss: 3.113619245914119

Epoch: 5| Step: 8
Training loss: 3.3835070736127477
Validation loss: 3.107303783095877

Epoch: 5| Step: 9
Training loss: 2.9952160520751083
Validation loss: 3.1056819806191602

Epoch: 5| Step: 10
Training loss: 3.636271612130015
Validation loss: 3.1217017030277003

Epoch: 20| Step: 0
Training loss: 3.7577909282612385
Validation loss: 3.107555154281206

Epoch: 5| Step: 1
Training loss: 2.9872668570361243
Validation loss: 3.1043438177824987

Epoch: 5| Step: 2
Training loss: 3.5575733585259974
Validation loss: 3.103699919869522

Epoch: 5| Step: 3
Training loss: 3.243187439928166
Validation loss: 3.1048551100090127

Epoch: 5| Step: 4
Training loss: 3.292617724840464
Validation loss: 3.1025123116169113

Epoch: 5| Step: 5
Training loss: 3.8499265837171763
Validation loss: 3.1017711806115593

Epoch: 5| Step: 6
Training loss: 3.0448523434572374
Validation loss: 3.1012317062310353

Epoch: 5| Step: 7
Training loss: 4.015217682482449
Validation loss: 3.102624143383953

Epoch: 5| Step: 8
Training loss: 2.9640623326922397
Validation loss: 3.0961896670394795

Epoch: 5| Step: 9
Training loss: 3.145315586624867
Validation loss: 3.1001292602339534

Epoch: 5| Step: 10
Training loss: 3.1045794287246467
Validation loss: 3.1098400429236914

Epoch: 21| Step: 0
Training loss: 3.83134157155363
Validation loss: 3.098432512242957

Epoch: 5| Step: 1
Training loss: 3.071991982856859
Validation loss: 3.09114448425765

Epoch: 5| Step: 2
Training loss: 2.8359026946146715
Validation loss: 3.09319808543183

Epoch: 5| Step: 3
Training loss: 3.858683288610476
Validation loss: 3.102229176389698

Epoch: 5| Step: 4
Training loss: 3.226668607800533
Validation loss: 3.104266273622099

Epoch: 5| Step: 5
Training loss: 2.9867748577526427
Validation loss: 3.0970492238709912

Epoch: 5| Step: 6
Training loss: 3.5637279870280985
Validation loss: 3.093180915976356

Epoch: 5| Step: 7
Training loss: 3.1937141431374494
Validation loss: 3.0913646588855492

Epoch: 5| Step: 8
Training loss: 3.5736742615921653
Validation loss: 3.0889347356624817

Epoch: 5| Step: 9
Training loss: 3.6952323662938658
Validation loss: 3.081857072334255

Epoch: 5| Step: 10
Training loss: 3.0028926890505305
Validation loss: 3.0800742804665155

Epoch: 22| Step: 0
Training loss: 2.946411575334418
Validation loss: 3.08304798221495

Epoch: 5| Step: 1
Training loss: 2.667121898020896
Validation loss: 3.0819609785418747

Epoch: 5| Step: 2
Training loss: 3.708441543429028
Validation loss: 3.079952658723716

Epoch: 5| Step: 3
Training loss: 3.7368068039473026
Validation loss: 3.0782766988246313

Epoch: 5| Step: 4
Training loss: 3.753668834153021
Validation loss: 3.076208317116452

Epoch: 5| Step: 5
Training loss: 3.6724978953460004
Validation loss: 3.078709833873375

Epoch: 5| Step: 6
Training loss: 2.804337928685079
Validation loss: 3.0760284141401537

Epoch: 5| Step: 7
Training loss: 2.978589266507668
Validation loss: 3.0745495434002432

Epoch: 5| Step: 8
Training loss: 3.1870227531240913
Validation loss: 3.0714111600178002

Epoch: 5| Step: 9
Training loss: 3.538082298637033
Validation loss: 3.0727137734138688

Epoch: 5| Step: 10
Training loss: 3.733320143085975
Validation loss: 3.0728993182616384

Epoch: 23| Step: 0
Training loss: 3.777144165446935
Validation loss: 3.0706986317550045

Epoch: 5| Step: 1
Training loss: 3.4989389446085144
Validation loss: 3.0673955530215053

Epoch: 5| Step: 2
Training loss: 3.5110111053995214
Validation loss: 3.067851830062091

Epoch: 5| Step: 3
Training loss: 3.5982613815692677
Validation loss: 3.067827211807907

Epoch: 5| Step: 4
Training loss: 3.4260745124174155
Validation loss: 3.0661498657082547

Epoch: 5| Step: 5
Training loss: 2.9714935475099162
Validation loss: 3.065101894456894

Epoch: 5| Step: 6
Training loss: 3.3380794750738305
Validation loss: 3.0620594038376785

Epoch: 5| Step: 7
Training loss: 2.9508640575631846
Validation loss: 3.0596212837384997

Epoch: 5| Step: 8
Training loss: 3.3487238033077382
Validation loss: 3.0603509310120756

Epoch: 5| Step: 9
Training loss: 3.151043062236046
Validation loss: 3.0588004305744176

Epoch: 5| Step: 10
Training loss: 3.0987723842364803
Validation loss: 3.0581968327048834

Epoch: 24| Step: 0
Training loss: 3.226813133425435
Validation loss: 3.0576757958473646

Epoch: 5| Step: 1
Training loss: 3.222710404374533
Validation loss: 3.057958480539042

Epoch: 5| Step: 2
Training loss: 3.048262842474632
Validation loss: 3.054281105686853

Epoch: 5| Step: 3
Training loss: 2.967882210237255
Validation loss: 3.0540102885251383

Epoch: 5| Step: 4
Training loss: 3.101875039599678
Validation loss: 3.056177389486606

Epoch: 5| Step: 5
Training loss: 3.50708272092715
Validation loss: 3.057228924731022

Epoch: 5| Step: 6
Training loss: 4.060002894658903
Validation loss: 3.074336716849552

Epoch: 5| Step: 7
Training loss: 3.4815631006546948
Validation loss: 3.0520632995622177

Epoch: 5| Step: 8
Training loss: 3.438845423182533
Validation loss: 3.05299825932276

Epoch: 5| Step: 9
Training loss: 2.8998875037110814
Validation loss: 3.060566626519448

Epoch: 5| Step: 10
Training loss: 3.6605529244511024
Validation loss: 3.0614194656833043

Epoch: 25| Step: 0
Training loss: 3.351181755580492
Validation loss: 3.0561715780048284

Epoch: 5| Step: 1
Training loss: 2.133276361459713
Validation loss: 3.0512428026460237

Epoch: 5| Step: 2
Training loss: 3.5610206611031776
Validation loss: 3.0538601008228787

Epoch: 5| Step: 3
Training loss: 3.5255026168153494
Validation loss: 3.0680912352070018

Epoch: 5| Step: 4
Training loss: 2.9328056323174785
Validation loss: 3.0724363346159325

Epoch: 5| Step: 5
Training loss: 3.4032602050377165
Validation loss: 3.1007519974607627

Epoch: 5| Step: 6
Training loss: 3.9141114740106016
Validation loss: 3.087305808049781

Epoch: 5| Step: 7
Training loss: 2.8028629924757014
Validation loss: 3.0481908337551804

Epoch: 5| Step: 8
Training loss: 3.9779589885824302
Validation loss: 3.0471807511031312

Epoch: 5| Step: 9
Training loss: 3.196673338972281
Validation loss: 3.0503376668770894

Epoch: 5| Step: 10
Training loss: 3.589185519470437
Validation loss: 3.0539462549748264

Epoch: 26| Step: 0
Training loss: 2.6247607530830868
Validation loss: 3.0479624248363586

Epoch: 5| Step: 1
Training loss: 3.3840620098700183
Validation loss: 3.0439737740056163

Epoch: 5| Step: 2
Training loss: 3.1440565805367133
Validation loss: 3.042936538445133

Epoch: 5| Step: 3
Training loss: 3.572326759745468
Validation loss: 3.0418078984943784

Epoch: 5| Step: 4
Training loss: 3.3819759470999635
Validation loss: 3.0431487489757916

Epoch: 5| Step: 5
Training loss: 3.271338761917978
Validation loss: 3.054847935682578

Epoch: 5| Step: 6
Training loss: 3.8610907690547607
Validation loss: 3.0505777506759233

Epoch: 5| Step: 7
Training loss: 3.235089209386348
Validation loss: 3.0408929359640746

Epoch: 5| Step: 8
Training loss: 2.8808777475579403
Validation loss: 3.0400415291281133

Epoch: 5| Step: 9
Training loss: 3.5198004447117825
Validation loss: 3.0353893277587582

Epoch: 5| Step: 10
Training loss: 3.6077019583254075
Validation loss: 3.0338766357119376

Epoch: 27| Step: 0
Training loss: 3.0939455837502248
Validation loss: 3.035641990532205

Epoch: 5| Step: 1
Training loss: 3.535100137676221
Validation loss: 3.0338478352730918

Epoch: 5| Step: 2
Training loss: 3.01140556240831
Validation loss: 3.0317091159116876

Epoch: 5| Step: 3
Training loss: 3.6084900138497975
Validation loss: 3.0315431419909573

Epoch: 5| Step: 4
Training loss: 2.951272534838173
Validation loss: 3.027960015751751

Epoch: 5| Step: 5
Training loss: 3.1450772587394322
Validation loss: 3.0243046002524454

Epoch: 5| Step: 6
Training loss: 3.542033112959734
Validation loss: 3.0227181217745165

Epoch: 5| Step: 7
Training loss: 3.4710033074409643
Validation loss: 3.0241976297002346

Epoch: 5| Step: 8
Training loss: 3.404602492287927
Validation loss: 3.0238993365830447

Epoch: 5| Step: 9
Training loss: 3.047561333456106
Validation loss: 3.0265073262109063

Epoch: 5| Step: 10
Training loss: 3.5976172827185273
Validation loss: 3.0305208293937316

Epoch: 28| Step: 0
Training loss: 2.780978928975508
Validation loss: 3.022440870801788

Epoch: 5| Step: 1
Training loss: 3.2879948638820213
Validation loss: 3.0205009707595214

Epoch: 5| Step: 2
Training loss: 3.0316507920039544
Validation loss: 3.016619044589566

Epoch: 5| Step: 3
Training loss: 3.28869815357827
Validation loss: 3.017762682260431

Epoch: 5| Step: 4
Training loss: 3.9367958529144502
Validation loss: 3.0177408895226954

Epoch: 5| Step: 5
Training loss: 3.42448694883364
Validation loss: 3.014620515515666

Epoch: 5| Step: 6
Training loss: 3.4211735812131088
Validation loss: 3.0171363813873198

Epoch: 5| Step: 7
Training loss: 3.1573134037797863
Validation loss: 3.0133231140944967

Epoch: 5| Step: 8
Training loss: 3.452138216038616
Validation loss: 3.011840611851405

Epoch: 5| Step: 9
Training loss: 2.9905668406476633
Validation loss: 3.012595068557749

Epoch: 5| Step: 10
Training loss: 3.453968066007701
Validation loss: 3.0102414361438474

Epoch: 29| Step: 0
Training loss: 2.8977745922665292
Validation loss: 3.0117194633237783

Epoch: 5| Step: 1
Training loss: 3.9637192207231307
Validation loss: 3.0097068639330775

Epoch: 5| Step: 2
Training loss: 3.4042215169334296
Validation loss: 3.010135493727215

Epoch: 5| Step: 3
Training loss: 3.5594894002292294
Validation loss: 3.0084391697149213

Epoch: 5| Step: 4
Training loss: 2.80206916172079
Validation loss: 3.00956107299839

Epoch: 5| Step: 5
Training loss: 3.708185271546943
Validation loss: 3.0090005885637665

Epoch: 5| Step: 6
Training loss: 3.1850825099348326
Validation loss: 3.0062681501712727

Epoch: 5| Step: 7
Training loss: 3.34320891093326
Validation loss: 3.006551708490944

Epoch: 5| Step: 8
Training loss: 2.9035605835766543
Validation loss: 3.003555725240606

Epoch: 5| Step: 9
Training loss: 3.1288221255076816
Validation loss: 3.005390891844642

Epoch: 5| Step: 10
Training loss: 3.1184148451649936
Validation loss: 3.01077811538782

Epoch: 30| Step: 0
Training loss: 3.211216972421784
Validation loss: 3.0023672239515564

Epoch: 5| Step: 1
Training loss: 3.4059394904880813
Validation loss: 2.9963850182552934

Epoch: 5| Step: 2
Training loss: 3.4299281563755746
Validation loss: 2.99664264391415

Epoch: 5| Step: 3
Training loss: 3.2884404914927177
Validation loss: 2.9945294379965803

Epoch: 5| Step: 4
Training loss: 3.33879406590376
Validation loss: 2.9935749189182683

Epoch: 5| Step: 5
Training loss: 2.566852130216783
Validation loss: 2.9941156755253187

Epoch: 5| Step: 6
Training loss: 3.90033414338486
Validation loss: 2.991851189709544

Epoch: 5| Step: 7
Training loss: 3.2282342528534675
Validation loss: 2.993734710206968

Epoch: 5| Step: 8
Training loss: 3.340128140304252
Validation loss: 2.9951279397991057

Epoch: 5| Step: 9
Training loss: 3.081367450201157
Validation loss: 2.9894158792835213

Epoch: 5| Step: 10
Training loss: 3.1215836733654565
Validation loss: 2.987166766450512

Epoch: 31| Step: 0
Training loss: 3.0515571809049424
Validation loss: 2.9861039213981284

Epoch: 5| Step: 1
Training loss: 3.597255025850725
Validation loss: 2.9871110006332176

Epoch: 5| Step: 2
Training loss: 3.2197086425134467
Validation loss: 2.9828251007110786

Epoch: 5| Step: 3
Training loss: 3.520940805333581
Validation loss: 2.9830009872272467

Epoch: 5| Step: 4
Training loss: 3.263220380855133
Validation loss: 2.9885225137903273

Epoch: 5| Step: 5
Training loss: 3.243578803041185
Validation loss: 2.993777504400124

Epoch: 5| Step: 6
Training loss: 2.722999671501731
Validation loss: 2.991987859765427

Epoch: 5| Step: 7
Training loss: 3.783993695026008
Validation loss: 2.997258492389842

Epoch: 5| Step: 8
Training loss: 3.128546114232519
Validation loss: 2.995650318778565

Epoch: 5| Step: 9
Training loss: 3.241872013782709
Validation loss: 2.9872350420707114

Epoch: 5| Step: 10
Training loss: 3.033837855654025
Validation loss: 2.9816968244578335

Epoch: 32| Step: 0
Training loss: 3.499785007958162
Validation loss: 2.9806913958421206

Epoch: 5| Step: 1
Training loss: 3.1492092048199427
Validation loss: 2.981141431021753

Epoch: 5| Step: 2
Training loss: 2.833436141299339
Validation loss: 2.9757418521977357

Epoch: 5| Step: 3
Training loss: 2.6810881843733663
Validation loss: 2.9842682269405176

Epoch: 5| Step: 4
Training loss: 3.1666430087627955
Validation loss: 2.989946140465857

Epoch: 5| Step: 5
Training loss: 3.1394707375839634
Validation loss: 2.977005343580796

Epoch: 5| Step: 6
Training loss: 2.735079690863642
Validation loss: 2.977447764834259

Epoch: 5| Step: 7
Training loss: 3.452620387426462
Validation loss: 2.974915345606625

Epoch: 5| Step: 8
Training loss: 3.5447584382520456
Validation loss: 2.9751206269199786

Epoch: 5| Step: 9
Training loss: 4.093869738975248
Validation loss: 2.9752447201885235

Epoch: 5| Step: 10
Training loss: 3.35265782382315
Validation loss: 2.9726973279036604

Epoch: 33| Step: 0
Training loss: 2.8461236793521367
Validation loss: 2.9737870804407667

Epoch: 5| Step: 1
Training loss: 3.3638264815567496
Validation loss: 2.9705656310167776

Epoch: 5| Step: 2
Training loss: 3.0434073253326086
Validation loss: 2.967979190328024

Epoch: 5| Step: 3
Training loss: 4.0031844814387005
Validation loss: 2.9704518956361716

Epoch: 5| Step: 4
Training loss: 3.5413713818290913
Validation loss: 2.9689543657496396

Epoch: 5| Step: 5
Training loss: 3.103164989140781
Validation loss: 2.9660394510439523

Epoch: 5| Step: 6
Training loss: 3.4307867908324456
Validation loss: 2.96851168562731

Epoch: 5| Step: 7
Training loss: 2.8919687807711685
Validation loss: 2.9722228371445087

Epoch: 5| Step: 8
Training loss: 3.521982370413697
Validation loss: 2.974754209043021

Epoch: 5| Step: 9
Training loss: 3.3383220217496152
Validation loss: 2.980319730143524

Epoch: 5| Step: 10
Training loss: 2.372921485884821
Validation loss: 2.963575015686091

Epoch: 34| Step: 0
Training loss: 3.2345563312507295
Validation loss: 2.961660494864575

Epoch: 5| Step: 1
Training loss: 2.7540922927240548
Validation loss: 2.9643287728634484

Epoch: 5| Step: 2
Training loss: 3.855729207340281
Validation loss: 2.9643359509442697

Epoch: 5| Step: 3
Training loss: 2.819812508430771
Validation loss: 2.9651806118602297

Epoch: 5| Step: 4
Training loss: 3.5821348152456136
Validation loss: 2.9663406793953944

Epoch: 5| Step: 5
Training loss: 2.731366928006956
Validation loss: 2.9666526842726846

Epoch: 5| Step: 6
Training loss: 3.3252333136136207
Validation loss: 2.96217963225523

Epoch: 5| Step: 7
Training loss: 3.9094670590570337
Validation loss: 2.962018151655298

Epoch: 5| Step: 8
Training loss: 2.9863950274042095
Validation loss: 2.959249356084939

Epoch: 5| Step: 9
Training loss: 3.1829428914346356
Validation loss: 2.959872097917636

Epoch: 5| Step: 10
Training loss: 3.1412096380880854
Validation loss: 2.958155157976607

Epoch: 35| Step: 0
Training loss: 3.2895007351214782
Validation loss: 2.959168306055358

Epoch: 5| Step: 1
Training loss: 3.143690748016579
Validation loss: 2.9599422035627634

Epoch: 5| Step: 2
Training loss: 3.82765126313771
Validation loss: 2.9667724274821023

Epoch: 5| Step: 3
Training loss: 2.768119075352798
Validation loss: 2.96282693673587

Epoch: 5| Step: 4
Training loss: 2.993811423163353
Validation loss: 2.9572226400549617

Epoch: 5| Step: 5
Training loss: 3.004398935538885
Validation loss: 2.957788756695359

Epoch: 5| Step: 6
Training loss: 2.7939705712551
Validation loss: 2.9525121732385142

Epoch: 5| Step: 7
Training loss: 3.052268551011709
Validation loss: 2.9521353949973705

Epoch: 5| Step: 8
Training loss: 3.7011002425455994
Validation loss: 2.951737687799279

Epoch: 5| Step: 9
Training loss: 3.576167874878293
Validation loss: 2.9523642526368548

Epoch: 5| Step: 10
Training loss: 3.3817544388100713
Validation loss: 2.9512780916254617

Epoch: 36| Step: 0
Training loss: 2.9945202690657653
Validation loss: 2.949851540580079

Epoch: 5| Step: 1
Training loss: 2.691507412320042
Validation loss: 2.949701631855465

Epoch: 5| Step: 2
Training loss: 3.73854489727134
Validation loss: 2.9495339575931774

Epoch: 5| Step: 3
Training loss: 3.108884993238586
Validation loss: 2.9490366863710196

Epoch: 5| Step: 4
Training loss: 3.793233624529503
Validation loss: 2.950638973375906

Epoch: 5| Step: 5
Training loss: 3.263350867619489
Validation loss: 2.9450577832781213

Epoch: 5| Step: 6
Training loss: 3.477103407710239
Validation loss: 2.9421998213598877

Epoch: 5| Step: 7
Training loss: 2.613739292847108
Validation loss: 2.9424154513560965

Epoch: 5| Step: 8
Training loss: 3.3677432847306137
Validation loss: 2.941701468970337

Epoch: 5| Step: 9
Training loss: 3.170350859566478
Validation loss: 2.940896661792821

Epoch: 5| Step: 10
Training loss: 3.136760250591355
Validation loss: 2.938451095904357

Epoch: 37| Step: 0
Training loss: 2.7671695857273217
Validation loss: 2.943216278090168

Epoch: 5| Step: 1
Training loss: 2.9110923541615796
Validation loss: 2.959504237359421

Epoch: 5| Step: 2
Training loss: 3.9420581652773943
Validation loss: 2.9743869134260104

Epoch: 5| Step: 3
Training loss: 3.213846119081657
Validation loss: 2.94398005988467

Epoch: 5| Step: 4
Training loss: 2.883731685161925
Validation loss: 2.9346221899040676

Epoch: 5| Step: 5
Training loss: 2.5162895699055543
Validation loss: 2.9347620789070716

Epoch: 5| Step: 6
Training loss: 2.681649337943329
Validation loss: 2.934153103896965

Epoch: 5| Step: 7
Training loss: 3.5516244959255747
Validation loss: 2.93399465846864

Epoch: 5| Step: 8
Training loss: 3.752435529080059
Validation loss: 2.9326381354441784

Epoch: 5| Step: 9
Training loss: 3.531079718611152
Validation loss: 2.93421369604607

Epoch: 5| Step: 10
Training loss: 3.500441250915496
Validation loss: 2.935068866869123

Epoch: 38| Step: 0
Training loss: 3.304550420564901
Validation loss: 2.933723886933796

Epoch: 5| Step: 1
Training loss: 2.8366982356584898
Validation loss: 2.935726753755953

Epoch: 5| Step: 2
Training loss: 3.163470780415087
Validation loss: 2.935323281816036

Epoch: 5| Step: 3
Training loss: 2.813461478450106
Validation loss: 2.942952470219812

Epoch: 5| Step: 4
Training loss: 3.135546169373597
Validation loss: 2.9466857755101086

Epoch: 5| Step: 5
Training loss: 3.143203208497998
Validation loss: 2.9472701150950793

Epoch: 5| Step: 6
Training loss: 3.2282651237512257
Validation loss: 2.9328034767228286

Epoch: 5| Step: 7
Training loss: 3.063465666819961
Validation loss: 2.928714104506578

Epoch: 5| Step: 8
Training loss: 3.8372672392495
Validation loss: 2.926256088238798

Epoch: 5| Step: 9
Training loss: 3.3154163118747126
Validation loss: 2.9285778947448464

Epoch: 5| Step: 10
Training loss: 3.544262970358119
Validation loss: 2.9363145760006355

Epoch: 39| Step: 0
Training loss: 2.8508930413324305
Validation loss: 2.9260528862010955

Epoch: 5| Step: 1
Training loss: 2.8137633982830423
Validation loss: 2.9247899128944064

Epoch: 5| Step: 2
Training loss: 2.7339238257801655
Validation loss: 2.922443600637624

Epoch: 5| Step: 3
Training loss: 2.7725971506913827
Validation loss: 2.921549218843588

Epoch: 5| Step: 4
Training loss: 3.0621076059999357
Validation loss: 2.925245964675596

Epoch: 5| Step: 5
Training loss: 3.01168296782813
Validation loss: 2.926876034645631

Epoch: 5| Step: 6
Training loss: 2.6709348574984917
Validation loss: 2.9281102367547303

Epoch: 5| Step: 7
Training loss: 3.8743440626631953
Validation loss: 2.944637589115557

Epoch: 5| Step: 8
Training loss: 3.5631976866589126
Validation loss: 2.9235437618111395

Epoch: 5| Step: 9
Training loss: 4.278430762276942
Validation loss: 2.919823802695215

Epoch: 5| Step: 10
Training loss: 3.361656088735959
Validation loss: 2.9203803891246585

Epoch: 40| Step: 0
Training loss: 3.7341494951035674
Validation loss: 2.924181364997974

Epoch: 5| Step: 1
Training loss: 3.2139093239223504
Validation loss: 2.926118468271239

Epoch: 5| Step: 2
Training loss: 2.556951703525148
Validation loss: 2.9241095883847716

Epoch: 5| Step: 3
Training loss: 3.122105134991131
Validation loss: 2.9219151818157503

Epoch: 5| Step: 4
Training loss: 3.250860980503932
Validation loss: 2.918713162533081

Epoch: 5| Step: 5
Training loss: 3.501671936694511
Validation loss: 2.9177598114773033

Epoch: 5| Step: 6
Training loss: 3.703941544913965
Validation loss: 2.9160513819252216

Epoch: 5| Step: 7
Training loss: 3.302152342130388
Validation loss: 2.913631912482078

Epoch: 5| Step: 8
Training loss: 2.4821204746095775
Validation loss: 2.9113789672940906

Epoch: 5| Step: 9
Training loss: 3.0100276568083184
Validation loss: 2.9118701562031934

Epoch: 5| Step: 10
Training loss: 3.2733556332058438
Validation loss: 2.9219842740846804

Epoch: 41| Step: 0
Training loss: 3.3631681097585755
Validation loss: 2.909358286852281

Epoch: 5| Step: 1
Training loss: 3.1751579245392128
Validation loss: 2.9096704494203753

Epoch: 5| Step: 2
Training loss: 3.79798263908223
Validation loss: 2.9092156949945482

Epoch: 5| Step: 3
Training loss: 3.067438930907775
Validation loss: 2.907732763166567

Epoch: 5| Step: 4
Training loss: 2.9041789889701333
Validation loss: 2.908231404039737

Epoch: 5| Step: 5
Training loss: 2.8808878441389925
Validation loss: 2.906723154192618

Epoch: 5| Step: 6
Training loss: 2.9006437968208294
Validation loss: 2.904473913971219

Epoch: 5| Step: 7
Training loss: 3.010459785196629
Validation loss: 2.9022886615807733

Epoch: 5| Step: 8
Training loss: 3.4692253268253035
Validation loss: 2.9014377701726

Epoch: 5| Step: 9
Training loss: 3.274744323767485
Validation loss: 2.901062980761049

Epoch: 5| Step: 10
Training loss: 3.336998228150956
Validation loss: 2.9033313041009214

Epoch: 42| Step: 0
Training loss: 2.6760423964433477
Validation loss: 2.9039477119621075

Epoch: 5| Step: 1
Training loss: 3.534010626698672
Validation loss: 2.9043293707614284

Epoch: 5| Step: 2
Training loss: 2.9253224317416495
Validation loss: 2.9070812055091513

Epoch: 5| Step: 3
Training loss: 3.3435279558558135
Validation loss: 2.902754118132232

Epoch: 5| Step: 4
Training loss: 3.389508604145398
Validation loss: 2.9020287374758107

Epoch: 5| Step: 5
Training loss: 3.7173082137260236
Validation loss: 2.9040533102787616

Epoch: 5| Step: 6
Training loss: 3.17921927938927
Validation loss: 2.9021556239393247

Epoch: 5| Step: 7
Training loss: 2.6523421319835823
Validation loss: 2.8958048175414928

Epoch: 5| Step: 8
Training loss: 2.696246264600576
Validation loss: 2.898251107077952

Epoch: 5| Step: 9
Training loss: 3.686712277862048
Validation loss: 2.893654927666875

Epoch: 5| Step: 10
Training loss: 3.1477917939081377
Validation loss: 2.8928115640964003

Epoch: 43| Step: 0
Training loss: 3.055928244162758
Validation loss: 2.8940592773443936

Epoch: 5| Step: 1
Training loss: 3.3027532882645185
Validation loss: 2.8909999694005273

Epoch: 5| Step: 2
Training loss: 2.96023817032083
Validation loss: 2.8935556922046937

Epoch: 5| Step: 3
Training loss: 2.839107202777363
Validation loss: 2.8890849979146043

Epoch: 5| Step: 4
Training loss: 3.537574977551961
Validation loss: 2.887482919097782

Epoch: 5| Step: 5
Training loss: 3.604598546842481
Validation loss: 2.889166541031325

Epoch: 5| Step: 6
Training loss: 2.7472289602696103
Validation loss: 2.8855334564404593

Epoch: 5| Step: 7
Training loss: 3.6210550349366466
Validation loss: 2.8884186399097764

Epoch: 5| Step: 8
Training loss: 3.3813721583611356
Validation loss: 2.8880741392568265

Epoch: 5| Step: 9
Training loss: 2.9485124361171517
Validation loss: 2.886246756648009

Epoch: 5| Step: 10
Training loss: 2.930033996436881
Validation loss: 2.885930128307035

Epoch: 44| Step: 0
Training loss: 3.1483613187220265
Validation loss: 2.8884166153880333

Epoch: 5| Step: 1
Training loss: 3.572479992457451
Validation loss: 2.8865038476656726

Epoch: 5| Step: 2
Training loss: 2.4179940907963817
Validation loss: 2.8888199384910216

Epoch: 5| Step: 3
Training loss: 2.9610499056211634
Validation loss: 2.8894011607568704

Epoch: 5| Step: 4
Training loss: 3.574697927237502
Validation loss: 2.8896713745815754

Epoch: 5| Step: 5
Training loss: 3.0572087256614884
Validation loss: 2.8855976530568683

Epoch: 5| Step: 6
Training loss: 2.719054983286699
Validation loss: 2.884174002184373

Epoch: 5| Step: 7
Training loss: 3.5033094563443323
Validation loss: 2.88161247375216

Epoch: 5| Step: 8
Training loss: 3.2944960847623794
Validation loss: 2.882492923216847

Epoch: 5| Step: 9
Training loss: 3.1070276342365655
Validation loss: 2.8799886113258384

Epoch: 5| Step: 10
Training loss: 3.478483685063568
Validation loss: 2.8766024235946195

Epoch: 45| Step: 0
Training loss: 3.136685609939349
Validation loss: 2.8794436468921147

Epoch: 5| Step: 1
Training loss: 3.5951788673947798
Validation loss: 2.8774916635456713

Epoch: 5| Step: 2
Training loss: 3.149491883728451
Validation loss: 2.8784861140985907

Epoch: 5| Step: 3
Training loss: 3.430849056756088
Validation loss: 2.875963075612009

Epoch: 5| Step: 4
Training loss: 2.9757729431821573
Validation loss: 2.875711585712419

Epoch: 5| Step: 5
Training loss: 3.3385662647279433
Validation loss: 2.875653112915755

Epoch: 5| Step: 6
Training loss: 3.3038223613156616
Validation loss: 2.8824218463967326

Epoch: 5| Step: 7
Training loss: 3.3674721298820316
Validation loss: 2.883559733887926

Epoch: 5| Step: 8
Training loss: 3.319840700625085
Validation loss: 2.8736444106769095

Epoch: 5| Step: 9
Training loss: 2.8077965295981713
Validation loss: 2.872040454517543

Epoch: 5| Step: 10
Training loss: 2.217451870986241
Validation loss: 2.868898495305267

Epoch: 46| Step: 0
Training loss: 3.1899838213375795
Validation loss: 2.8697655184924873

Epoch: 5| Step: 1
Training loss: 3.4623532811557913
Validation loss: 2.871910693207839

Epoch: 5| Step: 2
Training loss: 2.9361418161157102
Validation loss: 2.870498705615717

Epoch: 5| Step: 3
Training loss: 2.973402052571322
Validation loss: 2.878309516318214

Epoch: 5| Step: 4
Training loss: 3.14598150514864
Validation loss: 2.8755587319794107

Epoch: 5| Step: 5
Training loss: 3.3548657338412293
Validation loss: 2.867676252823646

Epoch: 5| Step: 6
Training loss: 3.2690475999430415
Validation loss: 2.8648789334783062

Epoch: 5| Step: 7
Training loss: 2.549279885431401
Validation loss: 2.863862348793683

Epoch: 5| Step: 8
Training loss: 3.4492309155363037
Validation loss: 2.866203821362821

Epoch: 5| Step: 9
Training loss: 3.2978906016344935
Validation loss: 2.864766988973086

Epoch: 5| Step: 10
Training loss: 3.1433045452764308
Validation loss: 2.8639302778834055

Epoch: 47| Step: 0
Training loss: 3.2277947905969917
Validation loss: 2.863929578772957

Epoch: 5| Step: 1
Training loss: 3.0215089941223905
Validation loss: 2.86331595357963

Epoch: 5| Step: 2
Training loss: 3.6719398005834583
Validation loss: 2.86133678893728

Epoch: 5| Step: 3
Training loss: 2.8441666517938553
Validation loss: 2.8605920694035336

Epoch: 5| Step: 4
Training loss: 2.499114928931647
Validation loss: 2.8593320251029115

Epoch: 5| Step: 5
Training loss: 3.4733472722286978
Validation loss: 2.858279846864359

Epoch: 5| Step: 6
Training loss: 3.3996131003656482
Validation loss: 2.8577372473984157

Epoch: 5| Step: 7
Training loss: 3.5528688578347047
Validation loss: 2.8572990331580654

Epoch: 5| Step: 8
Training loss: 2.8655686966784275
Validation loss: 2.8619145346109787

Epoch: 5| Step: 9
Training loss: 2.5251244731475944
Validation loss: 2.8672624119816756

Epoch: 5| Step: 10
Training loss: 3.4672378130679418
Validation loss: 2.8585232069406574

Epoch: 48| Step: 0
Training loss: 3.4169313436816493
Validation loss: 2.8552007081247224

Epoch: 5| Step: 1
Training loss: 2.559892956462704
Validation loss: 2.8534307468989577

Epoch: 5| Step: 2
Training loss: 2.80997022660525
Validation loss: 2.854233360963399

Epoch: 5| Step: 3
Training loss: 3.251440169284755
Validation loss: 2.8628033507490263

Epoch: 5| Step: 4
Training loss: 3.762069226315011
Validation loss: 2.8498759763192636

Epoch: 5| Step: 5
Training loss: 3.1255957989166747
Validation loss: 2.847133723405183

Epoch: 5| Step: 6
Training loss: 2.7441413200621896
Validation loss: 2.8450412210041374

Epoch: 5| Step: 7
Training loss: 3.228642197543466
Validation loss: 2.842638738209688

Epoch: 5| Step: 8
Training loss: 3.5186290876032857
Validation loss: 2.8425927812423923

Epoch: 5| Step: 9
Training loss: 3.1884174896422888
Validation loss: 2.8398380988417817

Epoch: 5| Step: 10
Training loss: 2.7852595712723103
Validation loss: 2.8409581787551987

Epoch: 49| Step: 0
Training loss: 2.9153519710093607
Validation loss: 2.8430243477590853

Epoch: 5| Step: 1
Training loss: 2.9450547487516308
Validation loss: 2.8385334636068826

Epoch: 5| Step: 2
Training loss: 3.489080835098628
Validation loss: 2.8425733297082956

Epoch: 5| Step: 3
Training loss: 3.2224237901481843
Validation loss: 2.847558245642203

Epoch: 5| Step: 4
Training loss: 3.759612542541018
Validation loss: 2.8517461731346576

Epoch: 5| Step: 5
Training loss: 2.902835932569393
Validation loss: 2.8515639402459216

Epoch: 5| Step: 6
Training loss: 3.219375401450391
Validation loss: 2.8451676015965486

Epoch: 5| Step: 7
Training loss: 3.549625355468457
Validation loss: 2.840078669349148

Epoch: 5| Step: 8
Training loss: 2.50793323642141
Validation loss: 2.8332738206562094

Epoch: 5| Step: 9
Training loss: 3.281492533121793
Validation loss: 2.8339327920597386

Epoch: 5| Step: 10
Training loss: 2.4669028989549457
Validation loss: 2.831760049917358

Epoch: 50| Step: 0
Training loss: 3.246042776797815
Validation loss: 2.8311228396271932

Epoch: 5| Step: 1
Training loss: 2.7729269068123092
Validation loss: 2.830869837581071

Epoch: 5| Step: 2
Training loss: 2.7718300042698867
Validation loss: 2.8295692305567135

Epoch: 5| Step: 3
Training loss: 3.44999836354977
Validation loss: 2.8298298291959583

Epoch: 5| Step: 4
Training loss: 3.20976157827077
Validation loss: 2.830437023764676

Epoch: 5| Step: 5
Training loss: 2.3931485488701343
Validation loss: 2.8352478747317797

Epoch: 5| Step: 6
Training loss: 3.364867364726602
Validation loss: 2.8393427383495378

Epoch: 5| Step: 7
Training loss: 2.971332591204443
Validation loss: 2.8434426944984916

Epoch: 5| Step: 8
Training loss: 3.8402550167599547
Validation loss: 2.8361296424103486

Epoch: 5| Step: 9
Training loss: 3.222124127469683
Validation loss: 2.8262713357315534

Epoch: 5| Step: 10
Training loss: 3.0545712031790204
Validation loss: 2.8251007295524553

Epoch: 51| Step: 0
Training loss: 3.477718546819675
Validation loss: 2.824197514380591

Epoch: 5| Step: 1
Training loss: 2.6994231349559934
Validation loss: 2.825505883748304

Epoch: 5| Step: 2
Training loss: 3.0586631250613174
Validation loss: 2.8243395732241017

Epoch: 5| Step: 3
Training loss: 3.7724954444043743
Validation loss: 2.8234123361198007

Epoch: 5| Step: 4
Training loss: 2.85651091671458
Validation loss: 2.8228870601136036

Epoch: 5| Step: 5
Training loss: 2.9044640088300056
Validation loss: 2.8230623518613394

Epoch: 5| Step: 6
Training loss: 3.1357304784603097
Validation loss: 2.8196323958583194

Epoch: 5| Step: 7
Training loss: 3.4460844182917465
Validation loss: 2.8194155007004937

Epoch: 5| Step: 8
Training loss: 2.617728379569137
Validation loss: 2.818641943888943

Epoch: 5| Step: 9
Training loss: 2.8003919429299713
Validation loss: 2.8206386619014094

Epoch: 5| Step: 10
Training loss: 3.5736136836298718
Validation loss: 2.819934166825133

Epoch: 52| Step: 0
Training loss: 3.2118530453215337
Validation loss: 2.8221005143612907

Epoch: 5| Step: 1
Training loss: 2.9768982545215477
Validation loss: 2.828340039859077

Epoch: 5| Step: 2
Training loss: 3.3573029981408715
Validation loss: 2.8457304503993837

Epoch: 5| Step: 3
Training loss: 3.6407661901772936
Validation loss: 2.838557852346774

Epoch: 5| Step: 4
Training loss: 2.990678451522803
Validation loss: 2.8150798291169568

Epoch: 5| Step: 5
Training loss: 3.0386523286225366
Validation loss: 2.817568717398291

Epoch: 5| Step: 6
Training loss: 2.574235328539891
Validation loss: 2.8195507129822834

Epoch: 5| Step: 7
Training loss: 3.1368099593681804
Validation loss: 2.8173934423630325

Epoch: 5| Step: 8
Training loss: 3.1420577847164997
Validation loss: 2.823478912157501

Epoch: 5| Step: 9
Training loss: 2.8990132461776836
Validation loss: 2.8164407083052287

Epoch: 5| Step: 10
Training loss: 3.423003546242377
Validation loss: 2.8173711216062114

Epoch: 53| Step: 0
Training loss: 3.1141685456299277
Validation loss: 2.8291147381486

Epoch: 5| Step: 1
Training loss: 3.0991035149596966
Validation loss: 2.8699337896720674

Epoch: 5| Step: 2
Training loss: 3.1254830559268343
Validation loss: 2.8874961799376484

Epoch: 5| Step: 3
Training loss: 2.9710945909786313
Validation loss: 2.8433372768708525

Epoch: 5| Step: 4
Training loss: 2.6853501348389726
Validation loss: 2.814265712552084

Epoch: 5| Step: 5
Training loss: 3.2914360706020633
Validation loss: 2.8136343488058206

Epoch: 5| Step: 6
Training loss: 3.158492849409818
Validation loss: 2.8142763478121915

Epoch: 5| Step: 7
Training loss: 3.1636451728542694
Validation loss: 2.8202259317564766

Epoch: 5| Step: 8
Training loss: 3.1008679743773424
Validation loss: 2.8176094650298666

Epoch: 5| Step: 9
Training loss: 3.3836623747478383
Validation loss: 2.8152071540579993

Epoch: 5| Step: 10
Training loss: 3.3875083838777855
Validation loss: 2.8111832684585054

Epoch: 54| Step: 0
Training loss: 2.949771490783541
Validation loss: 2.806760123319147

Epoch: 5| Step: 1
Training loss: 2.8529184958190834
Validation loss: 2.8052058236123725

Epoch: 5| Step: 2
Training loss: 3.3811733159590784
Validation loss: 2.8053526233517703

Epoch: 5| Step: 3
Training loss: 3.4311692636576736
Validation loss: 2.807514300030124

Epoch: 5| Step: 4
Training loss: 2.756001253213584
Validation loss: 2.80455713251608

Epoch: 5| Step: 5
Training loss: 2.874529426873963
Validation loss: 2.8066940951622628

Epoch: 5| Step: 6
Training loss: 3.469317827916761
Validation loss: 2.823399782170888

Epoch: 5| Step: 7
Training loss: 2.6853529759546975
Validation loss: 2.834515199932609

Epoch: 5| Step: 8
Training loss: 3.0687683726458035
Validation loss: 2.842065892371323

Epoch: 5| Step: 9
Training loss: 3.388652174834667
Validation loss: 2.807934978289367

Epoch: 5| Step: 10
Training loss: 3.3392654721409345
Validation loss: 2.7979474120188335

Epoch: 55| Step: 0
Training loss: 3.236760683223118
Validation loss: 2.7978212936451436

Epoch: 5| Step: 1
Training loss: 3.1597036973645425
Validation loss: 2.8005519997433304

Epoch: 5| Step: 2
Training loss: 2.765856285984588
Validation loss: 2.8023062588078345

Epoch: 5| Step: 3
Training loss: 2.7747626778787016
Validation loss: 2.801926900609005

Epoch: 5| Step: 4
Training loss: 3.5138196590742363
Validation loss: 2.803371635720045

Epoch: 5| Step: 5
Training loss: 3.0704946682300873
Validation loss: 2.804027433884735

Epoch: 5| Step: 6
Training loss: 3.4604108767123227
Validation loss: 2.7988316972779863

Epoch: 5| Step: 7
Training loss: 3.1278801424912395
Validation loss: 2.7949924216016457

Epoch: 5| Step: 8
Training loss: 3.3744164421531084
Validation loss: 2.79424519501266

Epoch: 5| Step: 9
Training loss: 2.8945317442117493
Validation loss: 2.793381206870593

Epoch: 5| Step: 10
Training loss: 2.7894097120076986
Validation loss: 2.793383675631479

Epoch: 56| Step: 0
Training loss: 3.2535384062978085
Validation loss: 2.7926120210414895

Epoch: 5| Step: 1
Training loss: 2.661472885380706
Validation loss: 2.7922542126990497

Epoch: 5| Step: 2
Training loss: 2.605153672413754
Validation loss: 2.7936638116738552

Epoch: 5| Step: 3
Training loss: 3.2987919879422396
Validation loss: 2.7925091847914727

Epoch: 5| Step: 4
Training loss: 3.132289776274493
Validation loss: 2.7937253476108856

Epoch: 5| Step: 5
Training loss: 3.58441036509567
Validation loss: 2.7948378536847343

Epoch: 5| Step: 6
Training loss: 3.0517749999516
Validation loss: 2.7920830816593933

Epoch: 5| Step: 7
Training loss: 2.9330173134356174
Validation loss: 2.7877780448409597

Epoch: 5| Step: 8
Training loss: 2.9976067533723914
Validation loss: 2.7887878071286587

Epoch: 5| Step: 9
Training loss: 2.936069870868385
Validation loss: 2.786684643066819

Epoch: 5| Step: 10
Training loss: 3.6605088950566116
Validation loss: 2.7871193256015574

Epoch: 57| Step: 0
Training loss: 2.944072755909718
Validation loss: 2.785172705115671

Epoch: 5| Step: 1
Training loss: 3.088839554640468
Validation loss: 2.7872622293563176

Epoch: 5| Step: 2
Training loss: 2.3319098921848966
Validation loss: 2.7938746146656896

Epoch: 5| Step: 3
Training loss: 3.154874898664082
Validation loss: 2.8019499345388708

Epoch: 5| Step: 4
Training loss: 3.4417700862047633
Validation loss: 2.79794396184864

Epoch: 5| Step: 5
Training loss: 3.5366377787319556
Validation loss: 2.790584701359008

Epoch: 5| Step: 6
Training loss: 3.5268743631489765
Validation loss: 2.783105588627665

Epoch: 5| Step: 7
Training loss: 3.1895849851225684
Validation loss: 2.7821696577848005

Epoch: 5| Step: 8
Training loss: 2.7844650031377176
Validation loss: 2.785708069714575

Epoch: 5| Step: 9
Training loss: 2.6502821358253725
Validation loss: 2.7878734369932667

Epoch: 5| Step: 10
Training loss: 3.3746874629233607
Validation loss: 2.7898706276653367

Epoch: 58| Step: 0
Training loss: 3.088521527401052
Validation loss: 2.7913427120555814

Epoch: 5| Step: 1
Training loss: 3.3739226705737817
Validation loss: 2.7907899304195745

Epoch: 5| Step: 2
Training loss: 2.8347400838125245
Validation loss: 2.790045126934736

Epoch: 5| Step: 3
Training loss: 3.1170660392024137
Validation loss: 2.786533603489198

Epoch: 5| Step: 4
Training loss: 3.1019411408419018
Validation loss: 2.7878767455988194

Epoch: 5| Step: 5
Training loss: 2.9783105398144474
Validation loss: 2.784478191129472

Epoch: 5| Step: 6
Training loss: 3.0667184852976654
Validation loss: 2.7830361897048457

Epoch: 5| Step: 7
Training loss: 2.993848693112833
Validation loss: 2.7831393253172023

Epoch: 5| Step: 8
Training loss: 3.087617441021016
Validation loss: 2.7804972584113283

Epoch: 5| Step: 9
Training loss: 2.949782321463493
Validation loss: 2.776539438608385

Epoch: 5| Step: 10
Training loss: 3.6202994816018768
Validation loss: 2.777247285400081

Epoch: 59| Step: 0
Training loss: 3.3864975519333376
Validation loss: 2.7730660767118067

Epoch: 5| Step: 1
Training loss: 3.3643249947936456
Validation loss: 2.772972068573084

Epoch: 5| Step: 2
Training loss: 2.7692816746956117
Validation loss: 2.774986973755681

Epoch: 5| Step: 3
Training loss: 2.58273559751216
Validation loss: 2.7874558903537925

Epoch: 5| Step: 4
Training loss: 3.163234574116537
Validation loss: 2.7906485641640835

Epoch: 5| Step: 5
Training loss: 3.1934426953006287
Validation loss: 2.786635470728188

Epoch: 5| Step: 6
Training loss: 2.9388315956798396
Validation loss: 2.788255399588177

Epoch: 5| Step: 7
Training loss: 3.243066287153424
Validation loss: 2.7834177965132136

Epoch: 5| Step: 8
Training loss: 3.229624627566701
Validation loss: 2.7732201553030817

Epoch: 5| Step: 9
Training loss: 2.5288060010214313
Validation loss: 2.7683425324605175

Epoch: 5| Step: 10
Training loss: 3.571319504843591
Validation loss: 2.770764060353058

Epoch: 60| Step: 0
Training loss: 2.8972899435030026
Validation loss: 2.764884787102153

Epoch: 5| Step: 1
Training loss: 3.017681310179577
Validation loss: 2.7658083589409768

Epoch: 5| Step: 2
Training loss: 2.8738716233158024
Validation loss: 2.7663925122785726

Epoch: 5| Step: 3
Training loss: 3.3420648339201886
Validation loss: 2.7669273782786648

Epoch: 5| Step: 4
Training loss: 3.057008763773357
Validation loss: 2.76714073596475

Epoch: 5| Step: 5
Training loss: 3.231603494636279
Validation loss: 2.7667633933979356

Epoch: 5| Step: 6
Training loss: 3.859642853496029
Validation loss: 2.7632953167677794

Epoch: 5| Step: 7
Training loss: 3.116663379633457
Validation loss: 2.76078057950268

Epoch: 5| Step: 8
Training loss: 2.808793147069339
Validation loss: 2.7613809998115837

Epoch: 5| Step: 9
Training loss: 2.9139595729455876
Validation loss: 2.7619219108519744

Epoch: 5| Step: 10
Training loss: 2.627005945972209
Validation loss: 2.7621087520654926

Epoch: 61| Step: 0
Training loss: 2.5345778077208663
Validation loss: 2.7607071769899476

Epoch: 5| Step: 1
Training loss: 3.2264872766182107
Validation loss: 2.7657297192322945

Epoch: 5| Step: 2
Training loss: 2.8564862109785762
Validation loss: 2.7641577063703417

Epoch: 5| Step: 3
Training loss: 3.438695664969748
Validation loss: 2.7676840004284795

Epoch: 5| Step: 4
Training loss: 2.8240374959396166
Validation loss: 2.7590433621882537

Epoch: 5| Step: 5
Training loss: 3.347871183708764
Validation loss: 2.7613406349426217

Epoch: 5| Step: 6
Training loss: 2.9760668084018693
Validation loss: 2.76225504537372

Epoch: 5| Step: 7
Training loss: 3.525154727218378
Validation loss: 2.773509835376358

Epoch: 5| Step: 8
Training loss: 3.2615558880560496
Validation loss: 2.7749557219607808

Epoch: 5| Step: 9
Training loss: 2.369334037666166
Validation loss: 2.7557482645241134

Epoch: 5| Step: 10
Training loss: 3.398668724174171
Validation loss: 2.753332492343868

Epoch: 62| Step: 0
Training loss: 3.103967459685055
Validation loss: 2.7518480995071903

Epoch: 5| Step: 1
Training loss: 3.5076022010753682
Validation loss: 2.7557841008607307

Epoch: 5| Step: 2
Training loss: 3.0966578217849916
Validation loss: 2.7535937842182

Epoch: 5| Step: 3
Training loss: 2.9591722686837736
Validation loss: 2.755044892547228

Epoch: 5| Step: 4
Training loss: 3.0805012007805246
Validation loss: 2.75759598950757

Epoch: 5| Step: 5
Training loss: 3.8831225756863734
Validation loss: 2.758479674909512

Epoch: 5| Step: 6
Training loss: 3.138402959368981
Validation loss: 2.7597054182607796

Epoch: 5| Step: 7
Training loss: 3.133552749201974
Validation loss: 2.756612821737751

Epoch: 5| Step: 8
Training loss: 2.5707781987226332
Validation loss: 2.754875453458399

Epoch: 5| Step: 9
Training loss: 2.698945800406654
Validation loss: 2.753837688508663

Epoch: 5| Step: 10
Training loss: 2.46207956123246
Validation loss: 2.7528821612119874

Epoch: 63| Step: 0
Training loss: 3.828442245105558
Validation loss: 2.7498930642749086

Epoch: 5| Step: 1
Training loss: 3.0166812292207656
Validation loss: 2.745345740372374

Epoch: 5| Step: 2
Training loss: 3.1480306736422348
Validation loss: 2.747487059206503

Epoch: 5| Step: 3
Training loss: 2.545511360432337
Validation loss: 2.750279944630818

Epoch: 5| Step: 4
Training loss: 3.6128639433852316
Validation loss: 2.7784588902330487

Epoch: 5| Step: 5
Training loss: 3.1995771903616452
Validation loss: 2.755604179551006

Epoch: 5| Step: 6
Training loss: 2.4642534471061834
Validation loss: 2.7458583271270203

Epoch: 5| Step: 7
Training loss: 2.9109601644963585
Validation loss: 2.7475029262814643

Epoch: 5| Step: 8
Training loss: 2.5399454782296313
Validation loss: 2.746811495884312

Epoch: 5| Step: 9
Training loss: 3.322011858327004
Validation loss: 2.747811148311317

Epoch: 5| Step: 10
Training loss: 3.029544153702969
Validation loss: 2.749482683240824

Epoch: 64| Step: 0
Training loss: 3.4292014088189826
Validation loss: 2.746816671111645

Epoch: 5| Step: 1
Training loss: 2.7792647916827926
Validation loss: 2.748677227379805

Epoch: 5| Step: 2
Training loss: 3.1660766219158822
Validation loss: 2.749949701842982

Epoch: 5| Step: 3
Training loss: 2.7366182553295286
Validation loss: 2.74639886495351

Epoch: 5| Step: 4
Training loss: 3.1038926449527215
Validation loss: 2.7495855688485653

Epoch: 5| Step: 5
Training loss: 2.9202917368698245
Validation loss: 2.7479057037570946

Epoch: 5| Step: 6
Training loss: 3.8234675510287164
Validation loss: 2.751125827721528

Epoch: 5| Step: 7
Training loss: 3.356143550498872
Validation loss: 2.742821352463803

Epoch: 5| Step: 8
Training loss: 3.023309749299592
Validation loss: 2.7415546034769673

Epoch: 5| Step: 9
Training loss: 2.564746895064343
Validation loss: 2.741167581202796

Epoch: 5| Step: 10
Training loss: 2.7010109633527244
Validation loss: 2.737027160486629

Epoch: 65| Step: 0
Training loss: 3.241883633633162
Validation loss: 2.737439685051629

Epoch: 5| Step: 1
Training loss: 2.921965898538044
Validation loss: 2.7388176061771223

Epoch: 5| Step: 2
Training loss: 3.4595984630551753
Validation loss: 2.742511621782013

Epoch: 5| Step: 3
Training loss: 3.464890403390463
Validation loss: 2.741001422942692

Epoch: 5| Step: 4
Training loss: 2.698234058302991
Validation loss: 2.743741619968037

Epoch: 5| Step: 5
Training loss: 3.0050524445843116
Validation loss: 2.77314854268723

Epoch: 5| Step: 6
Training loss: 3.1082685025760637
Validation loss: 2.7936525097191236

Epoch: 5| Step: 7
Training loss: 2.99952026346099
Validation loss: 2.782260974194713

Epoch: 5| Step: 8
Training loss: 3.0047749031038506
Validation loss: 2.7661152558019686

Epoch: 5| Step: 9
Training loss: 2.86106180767882
Validation loss: 2.7349844004735138

Epoch: 5| Step: 10
Training loss: 2.857136334684284
Validation loss: 2.7336635131560065

Epoch: 66| Step: 0
Training loss: 3.582289358842481
Validation loss: 2.7357737002423774

Epoch: 5| Step: 1
Training loss: 2.44999952510907
Validation loss: 2.7322225275937084

Epoch: 5| Step: 2
Training loss: 2.9917874778503353
Validation loss: 2.7320938744405336

Epoch: 5| Step: 3
Training loss: 3.4954103622413015
Validation loss: 2.7313781873399154

Epoch: 5| Step: 4
Training loss: 2.9662899063840373
Validation loss: 2.731291787008617

Epoch: 5| Step: 5
Training loss: 2.963524325051323
Validation loss: 2.728453288292328

Epoch: 5| Step: 6
Training loss: 3.15316364729668
Validation loss: 2.726713225797594

Epoch: 5| Step: 7
Training loss: 2.9489235029159038
Validation loss: 2.728005934943948

Epoch: 5| Step: 8
Training loss: 3.41175495440345
Validation loss: 2.7277905998953105

Epoch: 5| Step: 9
Training loss: 2.5121423533189002
Validation loss: 2.7347343731355656

Epoch: 5| Step: 10
Training loss: 3.075147553912254
Validation loss: 2.730498602203373

Epoch: 67| Step: 0
Training loss: 3.357489194078589
Validation loss: 2.7255731699922827

Epoch: 5| Step: 1
Training loss: 2.628926564743203
Validation loss: 2.724518439168055

Epoch: 5| Step: 2
Training loss: 2.632163129012321
Validation loss: 2.7379210137447836

Epoch: 5| Step: 3
Training loss: 3.3310201884115727
Validation loss: 2.7434016621572885

Epoch: 5| Step: 4
Training loss: 3.1261219299513656
Validation loss: 2.7235914495530507

Epoch: 5| Step: 5
Training loss: 3.2216946363608168
Validation loss: 2.7231846437288856

Epoch: 5| Step: 6
Training loss: 2.7484634615055294
Validation loss: 2.725414949140623

Epoch: 5| Step: 7
Training loss: 2.577949101776468
Validation loss: 2.724718237319401

Epoch: 5| Step: 8
Training loss: 3.0669022663117906
Validation loss: 2.7303503557359474

Epoch: 5| Step: 9
Training loss: 3.1884005901171015
Validation loss: 2.733724576645043

Epoch: 5| Step: 10
Training loss: 3.7138024765102533
Validation loss: 2.75043185377298

Epoch: 68| Step: 0
Training loss: 3.1410617809322536
Validation loss: 2.7371747690384485

Epoch: 5| Step: 1
Training loss: 2.4399063752144285
Validation loss: 2.7225579174153363

Epoch: 5| Step: 2
Training loss: 3.339926556904744
Validation loss: 2.7218117245023885

Epoch: 5| Step: 3
Training loss: 2.688219018607746
Validation loss: 2.7221769687057393

Epoch: 5| Step: 4
Training loss: 2.673706319415599
Validation loss: 2.720593529095204

Epoch: 5| Step: 5
Training loss: 2.8829683091151566
Validation loss: 2.72188386648298

Epoch: 5| Step: 6
Training loss: 2.969771681207324
Validation loss: 2.732628480483743

Epoch: 5| Step: 7
Training loss: 3.4447225813873206
Validation loss: 2.7259865739699545

Epoch: 5| Step: 8
Training loss: 2.729005435131639
Validation loss: 2.7392252199795517

Epoch: 5| Step: 9
Training loss: 3.46975446024705
Validation loss: 2.7314147836058003

Epoch: 5| Step: 10
Training loss: 3.6469065948399084
Validation loss: 2.7208802954575995

Epoch: 69| Step: 0
Training loss: 3.4893351604217346
Validation loss: 2.721943542243606

Epoch: 5| Step: 1
Training loss: 2.8073262417185156
Validation loss: 2.716794142257231

Epoch: 5| Step: 2
Training loss: 3.2110369961584437
Validation loss: 2.7154354304997588

Epoch: 5| Step: 3
Training loss: 2.9161060521080358
Validation loss: 2.7160358018312194

Epoch: 5| Step: 4
Training loss: 2.559199929683168
Validation loss: 2.713392099139834

Epoch: 5| Step: 5
Training loss: 2.976138587862642
Validation loss: 2.7150033989589315

Epoch: 5| Step: 6
Training loss: 3.4921581429222566
Validation loss: 2.713063693461264

Epoch: 5| Step: 7
Training loss: 2.919201612148117
Validation loss: 2.715093288135969

Epoch: 5| Step: 8
Training loss: 2.558292563379675
Validation loss: 2.7158538362832885

Epoch: 5| Step: 9
Training loss: 3.0885942442837573
Validation loss: 2.718214021570477

Epoch: 5| Step: 10
Training loss: 3.3984495666991235
Validation loss: 2.711506270552479

Epoch: 70| Step: 0
Training loss: 3.1166973445694857
Validation loss: 2.7146403589059815

Epoch: 5| Step: 1
Training loss: 2.7503962664769137
Validation loss: 2.7120931323717965

Epoch: 5| Step: 2
Training loss: 3.67997400419756
Validation loss: 2.707587675398463

Epoch: 5| Step: 3
Training loss: 2.5019333039808154
Validation loss: 2.7094579086224795

Epoch: 5| Step: 4
Training loss: 2.883671826318712
Validation loss: 2.70511418717592

Epoch: 5| Step: 5
Training loss: 3.2266558986936023
Validation loss: 2.7067383858702883

Epoch: 5| Step: 6
Training loss: 3.019145432630164
Validation loss: 2.7065093196932746

Epoch: 5| Step: 7
Training loss: 2.947348136581087
Validation loss: 2.70659553743018

Epoch: 5| Step: 8
Training loss: 3.491188947701726
Validation loss: 2.7073946560637516

Epoch: 5| Step: 9
Training loss: 2.890523877823714
Validation loss: 2.7075789001110997

Epoch: 5| Step: 10
Training loss: 2.7337458295402235
Validation loss: 2.71752916893019

Epoch: 71| Step: 0
Training loss: 2.9658712785277617
Validation loss: 2.7289138294199486

Epoch: 5| Step: 1
Training loss: 3.1620246258524096
Validation loss: 2.709741622562895

Epoch: 5| Step: 2
Training loss: 3.178879693821093
Validation loss: 2.7037471899491576

Epoch: 5| Step: 3
Training loss: 2.5860934023234297
Validation loss: 2.7070411445545637

Epoch: 5| Step: 4
Training loss: 2.905474979879127
Validation loss: 2.7124456574949

Epoch: 5| Step: 5
Training loss: 3.141544795687005
Validation loss: 2.7187425422118268

Epoch: 5| Step: 6
Training loss: 3.351498334221509
Validation loss: 2.7214038651023214

Epoch: 5| Step: 7
Training loss: 2.25064649830651
Validation loss: 2.708297508387746

Epoch: 5| Step: 8
Training loss: 3.706041177717471
Validation loss: 2.7054083433985796

Epoch: 5| Step: 9
Training loss: 3.146080327390196
Validation loss: 2.704183966301667

Epoch: 5| Step: 10
Training loss: 2.9658961985064383
Validation loss: 2.700807070647918

Epoch: 72| Step: 0
Training loss: 2.875997950631421
Validation loss: 2.7007003248132615

Epoch: 5| Step: 1
Training loss: 3.2781156556148097
Validation loss: 2.7019967142785273

Epoch: 5| Step: 2
Training loss: 2.8532047924904766
Validation loss: 2.7087361026011063

Epoch: 5| Step: 3
Training loss: 3.0348038438130334
Validation loss: 2.723181178386495

Epoch: 5| Step: 4
Training loss: 2.6989273377708134
Validation loss: 2.715154113050157

Epoch: 5| Step: 5
Training loss: 3.8340322576050343
Validation loss: 2.698718232978979

Epoch: 5| Step: 6
Training loss: 2.621528600786654
Validation loss: 2.6989449103807517

Epoch: 5| Step: 7
Training loss: 3.1785492230369883
Validation loss: 2.7028969791769106

Epoch: 5| Step: 8
Training loss: 2.9538103549649466
Validation loss: 2.703818228602905

Epoch: 5| Step: 9
Training loss: 2.9487501567923005
Validation loss: 2.7078313856170024

Epoch: 5| Step: 10
Training loss: 3.1279830427856528
Validation loss: 2.7166243727720003

Epoch: 73| Step: 0
Training loss: 2.845099160556348
Validation loss: 2.729725916065684

Epoch: 5| Step: 1
Training loss: 2.990551055344821
Validation loss: 2.734565297432633

Epoch: 5| Step: 2
Training loss: 2.863621294716825
Validation loss: 2.7350804866468836

Epoch: 5| Step: 3
Training loss: 3.0910654461934914
Validation loss: 2.7304547284121123

Epoch: 5| Step: 4
Training loss: 3.294028983706064
Validation loss: 2.7264815435811807

Epoch: 5| Step: 5
Training loss: 3.106993103176844
Validation loss: 2.727932865667471

Epoch: 5| Step: 6
Training loss: 3.3243395271280543
Validation loss: 2.7060776573857632

Epoch: 5| Step: 7
Training loss: 2.8477644199920156
Validation loss: 2.6980702776993084

Epoch: 5| Step: 8
Training loss: 2.872701970396124
Validation loss: 2.7012378744860444

Epoch: 5| Step: 9
Training loss: 2.8869727904329467
Validation loss: 2.696343004836877

Epoch: 5| Step: 10
Training loss: 3.419358813317764
Validation loss: 2.698289010665904

Epoch: 74| Step: 0
Training loss: 2.3768706734492775
Validation loss: 2.6964462808544023

Epoch: 5| Step: 1
Training loss: 2.7709032112048733
Validation loss: 2.698043525371716

Epoch: 5| Step: 2
Training loss: 3.2637791139435675
Validation loss: 2.6983011481483343

Epoch: 5| Step: 3
Training loss: 2.7489186675195043
Validation loss: 2.6979434528763977

Epoch: 5| Step: 4
Training loss: 3.054087079838319
Validation loss: 2.6998769211375335

Epoch: 5| Step: 5
Training loss: 3.528035008488176
Validation loss: 2.6993317875196214

Epoch: 5| Step: 6
Training loss: 3.2154270537520344
Validation loss: 2.704768060671958

Epoch: 5| Step: 7
Training loss: 3.763248437600232
Validation loss: 2.708085691680024

Epoch: 5| Step: 8
Training loss: 2.696208417958235
Validation loss: 2.7080518445309556

Epoch: 5| Step: 9
Training loss: 3.107282231404252
Validation loss: 2.705621396825643

Epoch: 5| Step: 10
Training loss: 2.470921201467644
Validation loss: 2.695393243632162

Epoch: 75| Step: 0
Training loss: 2.635264084410931
Validation loss: 2.698663927733879

Epoch: 5| Step: 1
Training loss: 2.8588676627914227
Validation loss: 2.696563303021708

Epoch: 5| Step: 2
Training loss: 2.997870484173786
Validation loss: 2.694238444855558

Epoch: 5| Step: 3
Training loss: 3.4359995948693567
Validation loss: 2.7031029572241048

Epoch: 5| Step: 4
Training loss: 2.8208817095155885
Validation loss: 2.705827306755019

Epoch: 5| Step: 5
Training loss: 3.167873319982976
Validation loss: 2.70286678608084

Epoch: 5| Step: 6
Training loss: 3.1035374423989266
Validation loss: 2.687145370968024

Epoch: 5| Step: 7
Training loss: 3.16615312996624
Validation loss: 2.68467552151896

Epoch: 5| Step: 8
Training loss: 3.323367878445141
Validation loss: 2.6871850491439813

Epoch: 5| Step: 9
Training loss: 2.753925123217687
Validation loss: 2.6839364138102444

Epoch: 5| Step: 10
Training loss: 2.9976045263548925
Validation loss: 2.6883100265242192

Epoch: 76| Step: 0
Training loss: 3.570889682985426
Validation loss: 2.6910881296089517

Epoch: 5| Step: 1
Training loss: 2.7504843372037007
Validation loss: 2.6818311618350696

Epoch: 5| Step: 2
Training loss: 3.0830088951633354
Validation loss: 2.681972196872228

Epoch: 5| Step: 3
Training loss: 2.8886753414976667
Validation loss: 2.6805916298366115

Epoch: 5| Step: 4
Training loss: 2.7705709768200593
Validation loss: 2.683094753552387

Epoch: 5| Step: 5
Training loss: 2.8614011162831754
Validation loss: 2.68372039130703

Epoch: 5| Step: 6
Training loss: 3.1107288269533986
Validation loss: 2.6835785014371045

Epoch: 5| Step: 7
Training loss: 2.9822814948338983
Validation loss: 2.706220571054843

Epoch: 5| Step: 8
Training loss: 3.1071221706409573
Validation loss: 2.712731968738317

Epoch: 5| Step: 9
Training loss: 3.389166311641237
Validation loss: 2.7109141864030066

Epoch: 5| Step: 10
Training loss: 2.5009585450285687
Validation loss: 2.6918485316088323

Epoch: 77| Step: 0
Training loss: 3.2359743448662144
Validation loss: 2.6873813096413577

Epoch: 5| Step: 1
Training loss: 3.193537062621462
Validation loss: 2.6768866088019703

Epoch: 5| Step: 2
Training loss: 2.994705614705726
Validation loss: 2.6775995172403833

Epoch: 5| Step: 3
Training loss: 2.7374576304044007
Validation loss: 2.678232228882917

Epoch: 5| Step: 4
Training loss: 3.0006752843602404
Validation loss: 2.675111721566716

Epoch: 5| Step: 5
Training loss: 3.4803529799330986
Validation loss: 2.6727716533780885

Epoch: 5| Step: 6
Training loss: 3.289727875374885
Validation loss: 2.675021690669426

Epoch: 5| Step: 7
Training loss: 3.004343861624264
Validation loss: 2.675467321850269

Epoch: 5| Step: 8
Training loss: 2.9554829543939816
Validation loss: 2.678642019014583

Epoch: 5| Step: 9
Training loss: 2.937819118616062
Validation loss: 2.6794915523619656

Epoch: 5| Step: 10
Training loss: 2.0700823961896204
Validation loss: 2.6835520870756864

Epoch: 78| Step: 0
Training loss: 3.084236081598043
Validation loss: 2.6847944460809567

Epoch: 5| Step: 1
Training loss: 2.7267024050782247
Validation loss: 2.6778234846635245

Epoch: 5| Step: 2
Training loss: 3.001781411555683
Validation loss: 2.6738584935534626

Epoch: 5| Step: 3
Training loss: 3.3916427561474025
Validation loss: 2.6708447798706554

Epoch: 5| Step: 4
Training loss: 3.1224537966801598
Validation loss: 2.67033198423618

Epoch: 5| Step: 5
Training loss: 2.9480815791898625
Validation loss: 2.669928625149154

Epoch: 5| Step: 6
Training loss: 3.160041118547454
Validation loss: 2.666981087947419

Epoch: 5| Step: 7
Training loss: 3.2744493036054663
Validation loss: 2.6692544611987246

Epoch: 5| Step: 8
Training loss: 2.939212218896826
Validation loss: 2.6731680083947085

Epoch: 5| Step: 9
Training loss: 2.648303273268258
Validation loss: 2.6747822215647727

Epoch: 5| Step: 10
Training loss: 2.7231630485771032
Validation loss: 2.680506689339032

Epoch: 79| Step: 0
Training loss: 3.7554075035717895
Validation loss: 2.6900951335830645

Epoch: 5| Step: 1
Training loss: 2.767900123789852
Validation loss: 2.66666681984419

Epoch: 5| Step: 2
Training loss: 3.132205285946007
Validation loss: 2.663858547047377

Epoch: 5| Step: 3
Training loss: 3.174930697908765
Validation loss: 2.6647402546857313

Epoch: 5| Step: 4
Training loss: 2.978004726931354
Validation loss: 2.6632198562076757

Epoch: 5| Step: 5
Training loss: 2.4492371480880455
Validation loss: 2.663933628848054

Epoch: 5| Step: 6
Training loss: 3.0202187450084135
Validation loss: 2.6632442543953654

Epoch: 5| Step: 7
Training loss: 2.7877330015504262
Validation loss: 2.6636318086830553

Epoch: 5| Step: 8
Training loss: 3.2482324341914333
Validation loss: 2.6632132007175326

Epoch: 5| Step: 9
Training loss: 2.4114376476436004
Validation loss: 2.664019890718936

Epoch: 5| Step: 10
Training loss: 3.278954275023565
Validation loss: 2.661719572088919

Epoch: 80| Step: 0
Training loss: 3.304714626624776
Validation loss: 2.66759637775495

Epoch: 5| Step: 1
Training loss: 3.0483753129568902
Validation loss: 2.672003816268585

Epoch: 5| Step: 2
Training loss: 3.2703983155285403
Validation loss: 2.695378846500304

Epoch: 5| Step: 3
Training loss: 2.6558883420787103
Validation loss: 2.6761439335789565

Epoch: 5| Step: 4
Training loss: 3.5615503484296576
Validation loss: 2.6738501828400816

Epoch: 5| Step: 5
Training loss: 3.0951254513263664
Validation loss: 2.6712689309920585

Epoch: 5| Step: 6
Training loss: 2.2367975933263926
Validation loss: 2.6634231814056486

Epoch: 5| Step: 7
Training loss: 2.9083195362656444
Validation loss: 2.663487158478619

Epoch: 5| Step: 8
Training loss: 2.9482290868477565
Validation loss: 2.660022022852533

Epoch: 5| Step: 9
Training loss: 2.866002973716029
Validation loss: 2.6614315523750296

Epoch: 5| Step: 10
Training loss: 2.9738170547910663
Validation loss: 2.6598290683160646

Epoch: 81| Step: 0
Training loss: 4.071634440368046
Validation loss: 2.6572839142285876

Epoch: 5| Step: 1
Training loss: 2.5512786427020315
Validation loss: 2.6511810454343903

Epoch: 5| Step: 2
Training loss: 3.137487257973379
Validation loss: 2.6555483639967936

Epoch: 5| Step: 3
Training loss: 2.97791569905959
Validation loss: 2.6541434981699945

Epoch: 5| Step: 4
Training loss: 2.3297192536204223
Validation loss: 2.6562233003629268

Epoch: 5| Step: 5
Training loss: 2.8517720184693425
Validation loss: 2.6542228607461222

Epoch: 5| Step: 6
Training loss: 3.156060241433708
Validation loss: 2.6528029860929667

Epoch: 5| Step: 7
Training loss: 3.231848868207422
Validation loss: 2.6535643655710928

Epoch: 5| Step: 8
Training loss: 2.9483476375436264
Validation loss: 2.6533871882229234

Epoch: 5| Step: 9
Training loss: 2.532956901825198
Validation loss: 2.6606122374887877

Epoch: 5| Step: 10
Training loss: 2.8579920358299944
Validation loss: 2.6643026429719883

Epoch: 82| Step: 0
Training loss: 2.91092658376157
Validation loss: 2.67875385860526

Epoch: 5| Step: 1
Training loss: 3.342065975339282
Validation loss: 2.6751277467180987

Epoch: 5| Step: 2
Training loss: 2.944890404363697
Validation loss: 2.6700078339458146

Epoch: 5| Step: 3
Training loss: 3.3770064994516766
Validation loss: 2.6630690350994843

Epoch: 5| Step: 4
Training loss: 2.843771630508824
Validation loss: 2.658728274538532

Epoch: 5| Step: 5
Training loss: 2.2896162281213015
Validation loss: 2.65373169477511

Epoch: 5| Step: 6
Training loss: 2.8733338213372166
Validation loss: 2.6514756023050134

Epoch: 5| Step: 7
Training loss: 2.810627631961743
Validation loss: 2.6491890219537697

Epoch: 5| Step: 8
Training loss: 3.195160878508433
Validation loss: 2.655262957082569

Epoch: 5| Step: 9
Training loss: 3.1400094259327136
Validation loss: 2.6584780031053485

Epoch: 5| Step: 10
Training loss: 3.111533484473532
Validation loss: 2.6566773661357623

Epoch: 83| Step: 0
Training loss: 2.9014672743907264
Validation loss: 2.6492386890862822

Epoch: 5| Step: 1
Training loss: 2.4876236697945235
Validation loss: 2.6546080985278757

Epoch: 5| Step: 2
Training loss: 3.6681580256010307
Validation loss: 2.6477027459726408

Epoch: 5| Step: 3
Training loss: 3.160993580643611
Validation loss: 2.6439005489437433

Epoch: 5| Step: 4
Training loss: 2.978937918321867
Validation loss: 2.6457285005592692

Epoch: 5| Step: 5
Training loss: 2.904173078123994
Validation loss: 2.64614266649608

Epoch: 5| Step: 6
Training loss: 2.982033495043938
Validation loss: 2.6473370065277515

Epoch: 5| Step: 7
Training loss: 2.9650166376943314
Validation loss: 2.6422870403121412

Epoch: 5| Step: 8
Training loss: 2.645376140912744
Validation loss: 2.6428182277133736

Epoch: 5| Step: 9
Training loss: 3.228812922308765
Validation loss: 2.6436371719595506

Epoch: 5| Step: 10
Training loss: 2.802137145101227
Validation loss: 2.6489364159415323

Epoch: 84| Step: 0
Training loss: 3.646872599387666
Validation loss: 2.6629669175972865

Epoch: 5| Step: 1
Training loss: 2.7856706783528566
Validation loss: 2.649023308922314

Epoch: 5| Step: 2
Training loss: 2.4803621524523622
Validation loss: 2.6450280115419287

Epoch: 5| Step: 3
Training loss: 3.0965303200337284
Validation loss: 2.6407671057243207

Epoch: 5| Step: 4
Training loss: 2.894939934300117
Validation loss: 2.64129995569367

Epoch: 5| Step: 5
Training loss: 3.072201368626355
Validation loss: 2.6394323743192674

Epoch: 5| Step: 6
Training loss: 2.5633255163833355
Validation loss: 2.6395983480809955

Epoch: 5| Step: 7
Training loss: 3.009993755549547
Validation loss: 2.639489691157556

Epoch: 5| Step: 8
Training loss: 3.4484989715614462
Validation loss: 2.637454674405223

Epoch: 5| Step: 9
Training loss: 2.6803209095596476
Validation loss: 2.6363985222831725

Epoch: 5| Step: 10
Training loss: 2.998737705423356
Validation loss: 2.642215575681174

Epoch: 85| Step: 0
Training loss: 3.371995789748128
Validation loss: 2.640003412489365

Epoch: 5| Step: 1
Training loss: 2.5903515900386704
Validation loss: 2.6394017029085717

Epoch: 5| Step: 2
Training loss: 2.6554130582028237
Validation loss: 2.6408663937469763

Epoch: 5| Step: 3
Training loss: 2.8154555156474412
Validation loss: 2.6494824272631803

Epoch: 5| Step: 4
Training loss: 3.401990975136423
Validation loss: 2.6602794912663073

Epoch: 5| Step: 5
Training loss: 2.6815296658580814
Validation loss: 2.6504185915004594

Epoch: 5| Step: 6
Training loss: 2.898509063248533
Validation loss: 2.6364651329608972

Epoch: 5| Step: 7
Training loss: 3.0933846922699604
Validation loss: 2.635353254607307

Epoch: 5| Step: 8
Training loss: 3.0776152987538947
Validation loss: 2.6331371877504615

Epoch: 5| Step: 9
Training loss: 3.157084137630037
Validation loss: 2.6339454028214444

Epoch: 5| Step: 10
Training loss: 2.964611180045798
Validation loss: 2.6353827386809243

Epoch: 86| Step: 0
Training loss: 2.5962649183069693
Validation loss: 2.632573715729932

Epoch: 5| Step: 1
Training loss: 2.4673396077537104
Validation loss: 2.632204991738965

Epoch: 5| Step: 2
Training loss: 2.886013827633793
Validation loss: 2.632522397109601

Epoch: 5| Step: 3
Training loss: 3.140051490458705
Validation loss: 2.6337158234796774

Epoch: 5| Step: 4
Training loss: 3.030396646151756
Validation loss: 2.635801405333905

Epoch: 5| Step: 5
Training loss: 2.418694752301243
Validation loss: 2.6415148713334227

Epoch: 5| Step: 6
Training loss: 2.748955007890543
Validation loss: 2.654514429539238

Epoch: 5| Step: 7
Training loss: 3.3445340957397813
Validation loss: 2.6740762666484095

Epoch: 5| Step: 8
Training loss: 3.3697833965657953
Validation loss: 2.655504089863105

Epoch: 5| Step: 9
Training loss: 3.4433599289208288
Validation loss: 2.6470039609876035

Epoch: 5| Step: 10
Training loss: 3.187101152187119
Validation loss: 2.634804239401129

Epoch: 87| Step: 0
Training loss: 2.775437614370647
Validation loss: 2.6263347597689535

Epoch: 5| Step: 1
Training loss: 3.126879317718886
Validation loss: 2.6318375213671246

Epoch: 5| Step: 2
Training loss: 3.2103376361906677
Validation loss: 2.630758948226189

Epoch: 5| Step: 3
Training loss: 3.0526946999381175
Validation loss: 2.63637374437746

Epoch: 5| Step: 4
Training loss: 3.090907168260272
Validation loss: 2.640131678636234

Epoch: 5| Step: 5
Training loss: 2.5959524891683374
Validation loss: 2.6337610060499554

Epoch: 5| Step: 6
Training loss: 3.0460518532019476
Validation loss: 2.626864373304019

Epoch: 5| Step: 7
Training loss: 2.7249791485749864
Validation loss: 2.624219491244492

Epoch: 5| Step: 8
Training loss: 2.9003600456089997
Validation loss: 2.624753683129107

Epoch: 5| Step: 9
Training loss: 3.4735529185006686
Validation loss: 2.628123861789646

Epoch: 5| Step: 10
Training loss: 2.6318466271234673
Validation loss: 2.6407416620640447

Epoch: 88| Step: 0
Training loss: 2.7960501365532386
Validation loss: 2.6534664328450432

Epoch: 5| Step: 1
Training loss: 2.4472682554043623
Validation loss: 2.671104880028854

Epoch: 5| Step: 2
Training loss: 3.3939072152775607
Validation loss: 2.6727607389678294

Epoch: 5| Step: 3
Training loss: 3.525534536536346
Validation loss: 2.6670088843237307

Epoch: 5| Step: 4
Training loss: 2.8436971806242544
Validation loss: 2.6269394496932765

Epoch: 5| Step: 5
Training loss: 2.743926798136031
Validation loss: 2.6273265310505316

Epoch: 5| Step: 6
Training loss: 2.8796791478086115
Validation loss: 2.626765839423498

Epoch: 5| Step: 7
Training loss: 3.187514809966743
Validation loss: 2.620767543773066

Epoch: 5| Step: 8
Training loss: 3.1821864100820276
Validation loss: 2.6247835475359858

Epoch: 5| Step: 9
Training loss: 2.646118409025288
Validation loss: 2.62454028872531

Epoch: 5| Step: 10
Training loss: 2.8932839201591274
Validation loss: 2.6258924903683063

Epoch: 89| Step: 0
Training loss: 3.388857191663692
Validation loss: 2.62218779029207

Epoch: 5| Step: 1
Training loss: 3.117997219688835
Validation loss: 2.6231365093708856

Epoch: 5| Step: 2
Training loss: 3.355065709023481
Validation loss: 2.622602779388512

Epoch: 5| Step: 3
Training loss: 3.1298445724555544
Validation loss: 2.6222378603284295

Epoch: 5| Step: 4
Training loss: 3.265788097050454
Validation loss: 2.6261321818317076

Epoch: 5| Step: 5
Training loss: 2.423887929862518
Validation loss: 2.6322301215218395

Epoch: 5| Step: 6
Training loss: 2.080904371184356
Validation loss: 2.645474865418797

Epoch: 5| Step: 7
Training loss: 2.8942711181713707
Validation loss: 2.678638081636893

Epoch: 5| Step: 8
Training loss: 3.3073785885579774
Validation loss: 2.7607154342432447

Epoch: 5| Step: 9
Training loss: 2.682461739984508
Validation loss: 2.6279187107433493

Epoch: 5| Step: 10
Training loss: 2.8990418660041333
Validation loss: 2.6254544174871826

Epoch: 90| Step: 0
Training loss: 3.248525138138863
Validation loss: 2.6447693443470235

Epoch: 5| Step: 1
Training loss: 3.305125683170789
Validation loss: 2.6758987620117205

Epoch: 5| Step: 2
Training loss: 3.341076218595127
Validation loss: 2.6387243380045153

Epoch: 5| Step: 3
Training loss: 2.7888276671807217
Validation loss: 2.627758793358797

Epoch: 5| Step: 4
Training loss: 3.19353975025748
Validation loss: 2.625568136992241

Epoch: 5| Step: 5
Training loss: 2.611589052093411
Validation loss: 2.6259294359669685

Epoch: 5| Step: 6
Training loss: 2.8950728554526752
Validation loss: 2.6325578502828066

Epoch: 5| Step: 7
Training loss: 2.5186623191243998
Validation loss: 2.6500532220382156

Epoch: 5| Step: 8
Training loss: 2.6487044028317546
Validation loss: 2.702061876724819

Epoch: 5| Step: 9
Training loss: 3.3144564339166602
Validation loss: 2.8772177736049875

Epoch: 5| Step: 10
Training loss: 3.3420586987858805
Validation loss: 2.690186505910479

Epoch: 91| Step: 0
Training loss: 2.869615571330362
Validation loss: 2.634977318100514

Epoch: 5| Step: 1
Training loss: 3.18400696489157
Validation loss: 2.6334005751721

Epoch: 5| Step: 2
Training loss: 3.3436637225562285
Validation loss: 2.6727022959020363

Epoch: 5| Step: 3
Training loss: 2.9281190462978093
Validation loss: 2.7005688324077353

Epoch: 5| Step: 4
Training loss: 2.730567766612644
Validation loss: 2.7635127870949256

Epoch: 5| Step: 5
Training loss: 3.4423594026243016
Validation loss: 2.77632537840673

Epoch: 5| Step: 6
Training loss: 3.4063943254884945
Validation loss: 2.736427288409496

Epoch: 5| Step: 7
Training loss: 2.4234794962310584
Validation loss: 2.653605706151836

Epoch: 5| Step: 8
Training loss: 2.792732025998353
Validation loss: 2.625631433222222

Epoch: 5| Step: 9
Training loss: 2.706312207923201
Validation loss: 2.6263776788194138

Epoch: 5| Step: 10
Training loss: 3.336913348011703
Validation loss: 2.652183277401366

Epoch: 92| Step: 0
Training loss: 3.1269151541163507
Validation loss: 2.698384753254418

Epoch: 5| Step: 1
Training loss: 2.8046118425881055
Validation loss: 2.6756302449254017

Epoch: 5| Step: 2
Training loss: 2.801477662231127
Validation loss: 2.6896133898775796

Epoch: 5| Step: 3
Training loss: 3.096736352859819
Validation loss: 2.6427565527906896

Epoch: 5| Step: 4
Training loss: 3.1790158923898733
Validation loss: 2.626014077532784

Epoch: 5| Step: 5
Training loss: 3.0564735440058235
Validation loss: 2.6150306587333305

Epoch: 5| Step: 6
Training loss: 2.764292250379437
Validation loss: 2.617581796981051

Epoch: 5| Step: 7
Training loss: 2.9108903816574543
Validation loss: 2.613976536651931

Epoch: 5| Step: 8
Training loss: 3.2133956373144628
Validation loss: 2.61434995456755

Epoch: 5| Step: 9
Training loss: 2.351493758404004
Validation loss: 2.6098182826828444

Epoch: 5| Step: 10
Training loss: 3.27498355308072
Validation loss: 2.6132851995210857

Epoch: 93| Step: 0
Training loss: 3.429914671167383
Validation loss: 2.6070699460030613

Epoch: 5| Step: 1
Training loss: 3.107415583500466
Validation loss: 2.6088423548513315

Epoch: 5| Step: 2
Training loss: 2.829120945362062
Validation loss: 2.60916601961214

Epoch: 5| Step: 3
Training loss: 2.517873576534793
Validation loss: 2.610291903819453

Epoch: 5| Step: 4
Training loss: 3.0356528171759405
Validation loss: 2.6092398612613787

Epoch: 5| Step: 5
Training loss: 3.1040720743876364
Validation loss: 2.6139019441559923

Epoch: 5| Step: 6
Training loss: 3.0831589176919123
Validation loss: 2.6099728547886696

Epoch: 5| Step: 7
Training loss: 2.9071996634420683
Validation loss: 2.613521235842714

Epoch: 5| Step: 8
Training loss: 3.137908671842555
Validation loss: 2.608868061467327

Epoch: 5| Step: 9
Training loss: 2.9741325973165518
Validation loss: 2.6089689319386924

Epoch: 5| Step: 10
Training loss: 2.19659820592745
Validation loss: 2.61278794555413

Epoch: 94| Step: 0
Training loss: 3.055764713257237
Validation loss: 2.6266269300622156

Epoch: 5| Step: 1
Training loss: 2.9979829365128263
Validation loss: 2.643479042400284

Epoch: 5| Step: 2
Training loss: 2.9253423180744984
Validation loss: 2.6380295342090103

Epoch: 5| Step: 3
Training loss: 2.718927662624094
Validation loss: 2.659737129726197

Epoch: 5| Step: 4
Training loss: 3.210660973589255
Validation loss: 2.658550668931322

Epoch: 5| Step: 5
Training loss: 3.215818681435587
Validation loss: 2.6329871681726082

Epoch: 5| Step: 6
Training loss: 2.6042104997124835
Validation loss: 2.607591833849767

Epoch: 5| Step: 7
Training loss: 3.191323922448287
Validation loss: 2.6046985734374877

Epoch: 5| Step: 8
Training loss: 2.687369143826663
Validation loss: 2.60319098786694

Epoch: 5| Step: 9
Training loss: 3.064826859878103
Validation loss: 2.596753117120338

Epoch: 5| Step: 10
Training loss: 2.770940984102319
Validation loss: 2.597129055858098

Epoch: 95| Step: 0
Training loss: 3.2928301690423942
Validation loss: 2.599469557868623

Epoch: 5| Step: 1
Training loss: 3.2716209451438005
Validation loss: 2.5985437150787964

Epoch: 5| Step: 2
Training loss: 2.9387933034882603
Validation loss: 2.5969314663235394

Epoch: 5| Step: 3
Training loss: 2.648293280261612
Validation loss: 2.592454854036334

Epoch: 5| Step: 4
Training loss: 2.865461864424681
Validation loss: 2.585744368456699

Epoch: 5| Step: 5
Training loss: 2.8084312678465646
Validation loss: 2.590775637751709

Epoch: 5| Step: 6
Training loss: 3.0965087612477196
Validation loss: 2.5949312439243744

Epoch: 5| Step: 7
Training loss: 2.5305659935860767
Validation loss: 2.5948873616554238

Epoch: 5| Step: 8
Training loss: 2.552269774393322
Validation loss: 2.594223518899574

Epoch: 5| Step: 9
Training loss: 3.3515158341011113
Validation loss: 2.5928097268567116

Epoch: 5| Step: 10
Training loss: 2.909165427488968
Validation loss: 2.6044233347424357

Epoch: 96| Step: 0
Training loss: 3.068684619587785
Validation loss: 2.6015096058743943

Epoch: 5| Step: 1
Training loss: 3.33497080319734
Validation loss: 2.6093132940675203

Epoch: 5| Step: 2
Training loss: 2.7028986665202694
Validation loss: 2.605814989409878

Epoch: 5| Step: 3
Training loss: 3.462369807580964
Validation loss: 2.6078043196750214

Epoch: 5| Step: 4
Training loss: 2.8435952280706123
Validation loss: 2.592189481969443

Epoch: 5| Step: 5
Training loss: 3.192896743533709
Validation loss: 2.591386594247082

Epoch: 5| Step: 6
Training loss: 2.5609255349960254
Validation loss: 2.5851791960800017

Epoch: 5| Step: 7
Training loss: 2.4599853611332216
Validation loss: 2.586988385696445

Epoch: 5| Step: 8
Training loss: 2.933180534833606
Validation loss: 2.5873657551192597

Epoch: 5| Step: 9
Training loss: 3.150142993406212
Validation loss: 2.587948061057444

Epoch: 5| Step: 10
Training loss: 2.500483752177479
Validation loss: 2.5840912427250107

Epoch: 97| Step: 0
Training loss: 2.8968863642365754
Validation loss: 2.583941946341014

Epoch: 5| Step: 1
Training loss: 2.39977592375891
Validation loss: 2.5912672718810996

Epoch: 5| Step: 2
Training loss: 3.2047522900530994
Validation loss: 2.6144387251313144

Epoch: 5| Step: 3
Training loss: 2.9877723410103627
Validation loss: 2.6333244358887007

Epoch: 5| Step: 4
Training loss: 3.033026577735916
Validation loss: 2.658024555498395

Epoch: 5| Step: 5
Training loss: 3.4761636226584818
Validation loss: 2.680583451894

Epoch: 5| Step: 6
Training loss: 3.328395205708863
Validation loss: 2.694533809290225

Epoch: 5| Step: 7
Training loss: 2.673196566151958
Validation loss: 2.6539236209511263

Epoch: 5| Step: 8
Training loss: 2.7587059238025784
Validation loss: 2.629102650478922

Epoch: 5| Step: 9
Training loss: 3.000232210709076
Validation loss: 2.606331746182299

Epoch: 5| Step: 10
Training loss: 2.5064742180658586
Validation loss: 2.5921733386910724

Epoch: 98| Step: 0
Training loss: 2.957011254266938
Validation loss: 2.582935492823277

Epoch: 5| Step: 1
Training loss: 2.810935708639646
Validation loss: 2.5836072628324342

Epoch: 5| Step: 2
Training loss: 2.9732031901777263
Validation loss: 2.586288263294836

Epoch: 5| Step: 3
Training loss: 3.107865930618661
Validation loss: 2.585825399029767

Epoch: 5| Step: 4
Training loss: 2.8846340472277903
Validation loss: 2.5806558884056754

Epoch: 5| Step: 5
Training loss: 2.79710327580779
Validation loss: 2.5788493451774523

Epoch: 5| Step: 6
Training loss: 3.0583502232832713
Validation loss: 2.577747539831892

Epoch: 5| Step: 7
Training loss: 3.3062314874891543
Validation loss: 2.5826613881772023

Epoch: 5| Step: 8
Training loss: 2.901454291228686
Validation loss: 2.5761343800037464

Epoch: 5| Step: 9
Training loss: 2.5632814285850287
Validation loss: 2.5843456258457396

Epoch: 5| Step: 10
Training loss: 2.954418403721458
Validation loss: 2.5996497235783695

Epoch: 99| Step: 0
Training loss: 2.958459305207913
Validation loss: 2.6092370099753395

Epoch: 5| Step: 1
Training loss: 3.2270059719544655
Validation loss: 2.644521630990783

Epoch: 5| Step: 2
Training loss: 2.9855639900296915
Validation loss: 2.6353742930144426

Epoch: 5| Step: 3
Training loss: 2.3263163870020094
Validation loss: 2.6243748816579986

Epoch: 5| Step: 4
Training loss: 2.9919790489156823
Validation loss: 2.614211057221824

Epoch: 5| Step: 5
Training loss: 2.8804069758661974
Validation loss: 2.606356626737297

Epoch: 5| Step: 6
Training loss: 2.978252421772367
Validation loss: 2.604686110999141

Epoch: 5| Step: 7
Training loss: 2.657136208295927
Validation loss: 2.6057829424134855

Epoch: 5| Step: 8
Training loss: 3.1863154285847175
Validation loss: 2.6067438799829685

Epoch: 5| Step: 9
Training loss: 3.162894327661628
Validation loss: 2.606999723642019

Epoch: 5| Step: 10
Training loss: 2.868652634640943
Validation loss: 2.6027211275403332

Epoch: 100| Step: 0
Training loss: 2.9968251276888456
Validation loss: 2.6038648848053665

Epoch: 5| Step: 1
Training loss: 2.4550782221124186
Validation loss: 2.6162241622771285

Epoch: 5| Step: 2
Training loss: 2.6622055607279465
Validation loss: 2.612374164714277

Epoch: 5| Step: 3
Training loss: 3.097430881224768
Validation loss: 2.5924729031089813

Epoch: 5| Step: 4
Training loss: 3.2792411831278256
Validation loss: 2.600838875860588

Epoch: 5| Step: 5
Training loss: 2.6505637846725048
Validation loss: 2.5953278924317975

Epoch: 5| Step: 6
Training loss: 3.083018020453484
Validation loss: 2.5956422703637827

Epoch: 5| Step: 7
Training loss: 3.1492635622955163
Validation loss: 2.58402948761248

Epoch: 5| Step: 8
Training loss: 3.011930901047623
Validation loss: 2.5749959741949815

Epoch: 5| Step: 9
Training loss: 3.050923323406404
Validation loss: 2.5727558747515835

Epoch: 5| Step: 10
Training loss: 2.7278262819258186
Validation loss: 2.577862165520373

Epoch: 101| Step: 0
Training loss: 2.7537724022770074
Validation loss: 2.5774501937892396

Epoch: 5| Step: 1
Training loss: 3.0263975966022256
Validation loss: 2.5757581101189357

Epoch: 5| Step: 2
Training loss: 2.8169998622700607
Validation loss: 2.578315711402243

Epoch: 5| Step: 3
Training loss: 2.9492560984286618
Validation loss: 2.575078256415297

Epoch: 5| Step: 4
Training loss: 2.993274461412246
Validation loss: 2.5743040267122295

Epoch: 5| Step: 5
Training loss: 3.4002126683312577
Validation loss: 2.579459948080681

Epoch: 5| Step: 6
Training loss: 2.924921905257552
Validation loss: 2.5727152548572207

Epoch: 5| Step: 7
Training loss: 2.822701665331865
Validation loss: 2.570015858845112

Epoch: 5| Step: 8
Training loss: 2.9520531379341755
Validation loss: 2.56817180937928

Epoch: 5| Step: 9
Training loss: 2.535080072466335
Validation loss: 2.5763737841043226

Epoch: 5| Step: 10
Training loss: 3.185865095138045
Validation loss: 2.5922297482456984

Epoch: 102| Step: 0
Training loss: 2.793345008528292
Validation loss: 2.606764271060683

Epoch: 5| Step: 1
Training loss: 3.2441823682218067
Validation loss: 2.6101527178462307

Epoch: 5| Step: 2
Training loss: 3.4258488960503404
Validation loss: 2.621528011101889

Epoch: 5| Step: 3
Training loss: 2.3371874676829494
Validation loss: 2.602850839905592

Epoch: 5| Step: 4
Training loss: 2.831875500835778
Validation loss: 2.581437564141225

Epoch: 5| Step: 5
Training loss: 2.7804635468295213
Validation loss: 2.577626514936962

Epoch: 5| Step: 6
Training loss: 2.8614384444389986
Validation loss: 2.575892752175132

Epoch: 5| Step: 7
Training loss: 3.2777017936592
Validation loss: 2.567552639975715

Epoch: 5| Step: 8
Training loss: 2.7932649468705124
Validation loss: 2.5662048363697236

Epoch: 5| Step: 9
Training loss: 2.8004343411213704
Validation loss: 2.5712149844360073

Epoch: 5| Step: 10
Training loss: 3.005695341020481
Validation loss: 2.5686603792885845

Epoch: 103| Step: 0
Training loss: 2.884453696585643
Validation loss: 2.57532343184726

Epoch: 5| Step: 1
Training loss: 2.5296092425959884
Validation loss: 2.5791278617582747

Epoch: 5| Step: 2
Training loss: 2.901044387861764
Validation loss: 2.582826771790482

Epoch: 5| Step: 3
Training loss: 2.6920275144148693
Validation loss: 2.58264204859295

Epoch: 5| Step: 4
Training loss: 3.1900684256076066
Validation loss: 2.5859497077955367

Epoch: 5| Step: 5
Training loss: 3.13854395303644
Validation loss: 2.579695314911395

Epoch: 5| Step: 6
Training loss: 2.483419174485776
Validation loss: 2.567163870742805

Epoch: 5| Step: 7
Training loss: 3.0332246621196908
Validation loss: 2.561965928746463

Epoch: 5| Step: 8
Training loss: 2.8771765389745867
Validation loss: 2.5621648049490227

Epoch: 5| Step: 9
Training loss: 3.255897013739026
Validation loss: 2.5677468063333335

Epoch: 5| Step: 10
Training loss: 3.162446237943934
Validation loss: 2.5625549418564355

Epoch: 104| Step: 0
Training loss: 3.011417121477662
Validation loss: 2.5603207361253633

Epoch: 5| Step: 1
Training loss: 2.816108677311296
Validation loss: 2.559677238037108

Epoch: 5| Step: 2
Training loss: 3.1222074619938343
Validation loss: 2.55677059809629

Epoch: 5| Step: 3
Training loss: 2.951664639225814
Validation loss: 2.558472795029823

Epoch: 5| Step: 4
Training loss: 2.6603152413826288
Validation loss: 2.560145299933775

Epoch: 5| Step: 5
Training loss: 3.0441010196380196
Validation loss: 2.5596502697021197

Epoch: 5| Step: 6
Training loss: 2.871748370843855
Validation loss: 2.562129354295765

Epoch: 5| Step: 7
Training loss: 2.9649872072918453
Validation loss: 2.561232720926359

Epoch: 5| Step: 8
Training loss: 3.1143118613509113
Validation loss: 2.560488108407861

Epoch: 5| Step: 9
Training loss: 2.7127065905113317
Validation loss: 2.5609005348970224

Epoch: 5| Step: 10
Training loss: 2.7695046492188236
Validation loss: 2.5762705099684924

Epoch: 105| Step: 0
Training loss: 3.0195146686054266
Validation loss: 2.5780808510578423

Epoch: 5| Step: 1
Training loss: 2.6005081927216835
Validation loss: 2.5712371927247952

Epoch: 5| Step: 2
Training loss: 2.7374593723017044
Validation loss: 2.5692511305017764

Epoch: 5| Step: 3
Training loss: 2.8746478652917244
Validation loss: 2.572397928470618

Epoch: 5| Step: 4
Training loss: 2.7498254720619157
Validation loss: 2.5626501804206208

Epoch: 5| Step: 5
Training loss: 3.4508901415228888
Validation loss: 2.56833236157966

Epoch: 5| Step: 6
Training loss: 2.657507206215333
Validation loss: 2.5608415156359996

Epoch: 5| Step: 7
Training loss: 2.7649823320317535
Validation loss: 2.559171398102357

Epoch: 5| Step: 8
Training loss: 3.0349362955210597
Validation loss: 2.5599678698809565

Epoch: 5| Step: 9
Training loss: 2.969671969553285
Validation loss: 2.5549620651753133

Epoch: 5| Step: 10
Training loss: 3.1627655762145714
Validation loss: 2.5532295467419353

Epoch: 106| Step: 0
Training loss: 2.504942871325559
Validation loss: 2.556570354162678

Epoch: 5| Step: 1
Training loss: 3.2345023752092645
Validation loss: 2.5570712436366296

Epoch: 5| Step: 2
Training loss: 2.4381027454572144
Validation loss: 2.555843700135128

Epoch: 5| Step: 3
Training loss: 3.280211511398202
Validation loss: 2.5570317661707005

Epoch: 5| Step: 4
Training loss: 3.308264994135648
Validation loss: 2.5572507202674433

Epoch: 5| Step: 5
Training loss: 3.0687724126242073
Validation loss: 2.5565769182574347

Epoch: 5| Step: 6
Training loss: 3.2054131499565015
Validation loss: 2.5517068437462296

Epoch: 5| Step: 7
Training loss: 3.0194906649014905
Validation loss: 2.553837093031671

Epoch: 5| Step: 8
Training loss: 2.451394412208893
Validation loss: 2.5508899690363624

Epoch: 5| Step: 9
Training loss: 2.3634430632878214
Validation loss: 2.5516438075365926

Epoch: 5| Step: 10
Training loss: 3.0110491095990914
Validation loss: 2.5510862437256505

Epoch: 107| Step: 0
Training loss: 3.075793007422918
Validation loss: 2.55210033827125

Epoch: 5| Step: 1
Training loss: 2.925357151234747
Validation loss: 2.556872903713289

Epoch: 5| Step: 2
Training loss: 3.0832492370134377
Validation loss: 2.555993101163033

Epoch: 5| Step: 3
Training loss: 2.9111110273107204
Validation loss: 2.561102672479038

Epoch: 5| Step: 4
Training loss: 3.228364085883206
Validation loss: 2.557861932863212

Epoch: 5| Step: 5
Training loss: 2.929478996486736
Validation loss: 2.574835369543314

Epoch: 5| Step: 6
Training loss: 2.709393240087373
Validation loss: 2.568753703855499

Epoch: 5| Step: 7
Training loss: 1.8782937048675308
Validation loss: 2.5631623531352643

Epoch: 5| Step: 8
Training loss: 3.0690949721968948
Validation loss: 2.5573703286029272

Epoch: 5| Step: 9
Training loss: 2.736163094204799
Validation loss: 2.5574584466128654

Epoch: 5| Step: 10
Training loss: 3.264362730075857
Validation loss: 2.5556740325015155

Epoch: 108| Step: 0
Training loss: 2.997994388282415
Validation loss: 2.557135981712136

Epoch: 5| Step: 1
Training loss: 3.3000850146353504
Validation loss: 2.5560211667311252

Epoch: 5| Step: 2
Training loss: 2.706557988003497
Validation loss: 2.552336625033369

Epoch: 5| Step: 3
Training loss: 3.1703111523530896
Validation loss: 2.557484720838208

Epoch: 5| Step: 4
Training loss: 2.5696977152592946
Validation loss: 2.560746352966085

Epoch: 5| Step: 5
Training loss: 2.9600057217826183
Validation loss: 2.568099461232047

Epoch: 5| Step: 6
Training loss: 2.793333571289101
Validation loss: 2.55085424711896

Epoch: 5| Step: 7
Training loss: 2.9072824920615234
Validation loss: 2.5473223364517295

Epoch: 5| Step: 8
Training loss: 2.453244248911656
Validation loss: 2.5559734885821968

Epoch: 5| Step: 9
Training loss: 2.6417946115631015
Validation loss: 2.5487674708275234

Epoch: 5| Step: 10
Training loss: 3.419144747468025
Validation loss: 2.5536479678274775

Epoch: 109| Step: 0
Training loss: 2.114967449109091
Validation loss: 2.552783383021886

Epoch: 5| Step: 1
Training loss: 2.798125600126712
Validation loss: 2.5538984619763094

Epoch: 5| Step: 2
Training loss: 3.0481538094087357
Validation loss: 2.5497280396865545

Epoch: 5| Step: 3
Training loss: 3.2245818702453564
Validation loss: 2.5535624099084884

Epoch: 5| Step: 4
Training loss: 3.4457435943714465
Validation loss: 2.554129225020472

Epoch: 5| Step: 5
Training loss: 3.1612830493145188
Validation loss: 2.5505851207005232

Epoch: 5| Step: 6
Training loss: 3.0586807413994057
Validation loss: 2.555245910349231

Epoch: 5| Step: 7
Training loss: 2.633241884438353
Validation loss: 2.5617967076172135

Epoch: 5| Step: 8
Training loss: 2.7350396792586285
Validation loss: 2.577145141862569

Epoch: 5| Step: 9
Training loss: 2.8430795403194415
Validation loss: 2.594909519490688

Epoch: 5| Step: 10
Training loss: 2.691352123939824
Validation loss: 2.5868929728706456

Epoch: 110| Step: 0
Training loss: 2.737133618227426
Validation loss: 2.573497258000383

Epoch: 5| Step: 1
Training loss: 3.4065908558939757
Validation loss: 2.5654102350012415

Epoch: 5| Step: 2
Training loss: 2.272523991423514
Validation loss: 2.5539068036622483

Epoch: 5| Step: 3
Training loss: 2.8232818780178754
Validation loss: 2.5483268904067486

Epoch: 5| Step: 4
Training loss: 2.9991038891439588
Validation loss: 2.5470612965688604

Epoch: 5| Step: 5
Training loss: 2.813236818224918
Validation loss: 2.5547099743899686

Epoch: 5| Step: 6
Training loss: 3.312739813418967
Validation loss: 2.5646174906388453

Epoch: 5| Step: 7
Training loss: 2.913032411038159
Validation loss: 2.5714339262172

Epoch: 5| Step: 8
Training loss: 2.809394817685507
Validation loss: 2.5593587628916947

Epoch: 5| Step: 9
Training loss: 2.8570276850239242
Validation loss: 2.5466390631691134

Epoch: 5| Step: 10
Training loss: 2.862048457483877
Validation loss: 2.5487266205056733

Epoch: 111| Step: 0
Training loss: 3.0521093547523326
Validation loss: 2.546649726363192

Epoch: 5| Step: 1
Training loss: 2.6351682724326437
Validation loss: 2.542185200112984

Epoch: 5| Step: 2
Training loss: 3.399459650073168
Validation loss: 2.5418662640574508

Epoch: 5| Step: 3
Training loss: 2.9622170293040195
Validation loss: 2.5429620499655976

Epoch: 5| Step: 4
Training loss: 3.325945789943673
Validation loss: 2.540083598120196

Epoch: 5| Step: 5
Training loss: 3.0838912940156735
Validation loss: 2.5492355708111107

Epoch: 5| Step: 6
Training loss: 2.3904576461158094
Validation loss: 2.54369234357008

Epoch: 5| Step: 7
Training loss: 2.5253738202142926
Validation loss: 2.5463196338749583

Epoch: 5| Step: 8
Training loss: 2.618886458817886
Validation loss: 2.553782266785984

Epoch: 5| Step: 9
Training loss: 3.042439366961278
Validation loss: 2.554392816926496

Epoch: 5| Step: 10
Training loss: 2.5908025517377937
Validation loss: 2.558755441212781

Epoch: 112| Step: 0
Training loss: 3.3087266267038125
Validation loss: 2.5843827457815083

Epoch: 5| Step: 1
Training loss: 2.59738529484423
Validation loss: 2.6440538199069734

Epoch: 5| Step: 2
Training loss: 3.249422168715846
Validation loss: 2.681575840118601

Epoch: 5| Step: 3
Training loss: 2.673085702460543
Validation loss: 2.6900179419845696

Epoch: 5| Step: 4
Training loss: 2.961598989228293
Validation loss: 2.71916824271334

Epoch: 5| Step: 5
Training loss: 2.847769443266423
Validation loss: 2.6610444396887867

Epoch: 5| Step: 6
Training loss: 2.816044079142986
Validation loss: 2.630793482847547

Epoch: 5| Step: 7
Training loss: 3.091638326043734
Validation loss: 2.5815382184179656

Epoch: 5| Step: 8
Training loss: 2.6985954304718005
Validation loss: 2.5327490628141343

Epoch: 5| Step: 9
Training loss: 2.3784338571342385
Validation loss: 2.5402837757168433

Epoch: 5| Step: 10
Training loss: 3.5071691929946884
Validation loss: 2.5505290284331785

Epoch: 113| Step: 0
Training loss: 3.1556608953340235
Validation loss: 2.553386152945197

Epoch: 5| Step: 1
Training loss: 2.3730744034540114
Validation loss: 2.5396834620833246

Epoch: 5| Step: 2
Training loss: 3.276345793288942
Validation loss: 2.5352547990759446

Epoch: 5| Step: 3
Training loss: 2.810567403775357
Validation loss: 2.5409981598041465

Epoch: 5| Step: 4
Training loss: 2.701066396423265
Validation loss: 2.546173110717536

Epoch: 5| Step: 5
Training loss: 2.9843440029272124
Validation loss: 2.5943504910443766

Epoch: 5| Step: 6
Training loss: 3.453817997089459
Validation loss: 2.6643238376691523

Epoch: 5| Step: 7
Training loss: 2.4820312384730583
Validation loss: 2.744417239305303

Epoch: 5| Step: 8
Training loss: 3.190213861979861
Validation loss: 2.849775564520639

Epoch: 5| Step: 9
Training loss: 2.9889934812993486
Validation loss: 2.7149508981784334

Epoch: 5| Step: 10
Training loss: 2.81366400473311
Validation loss: 2.633890660479986

Epoch: 114| Step: 0
Training loss: 2.746700040867578
Validation loss: 2.541138058595019

Epoch: 5| Step: 1
Training loss: 3.7506166586888843
Validation loss: 2.539877330449165

Epoch: 5| Step: 2
Training loss: 3.075392076261089
Validation loss: 2.5397524922394585

Epoch: 5| Step: 3
Training loss: 2.7701051276188604
Validation loss: 2.559310756260035

Epoch: 5| Step: 4
Training loss: 2.8370379370007455
Validation loss: 2.5678577003165364

Epoch: 5| Step: 5
Training loss: 2.5414213989819494
Validation loss: 2.565673503757232

Epoch: 5| Step: 6
Training loss: 2.751135331658213
Validation loss: 2.5670457403688065

Epoch: 5| Step: 7
Training loss: 2.700340821689679
Validation loss: 2.5695399621268757

Epoch: 5| Step: 8
Training loss: 2.9770428928185018
Validation loss: 2.5705816853139085

Epoch: 5| Step: 9
Training loss: 3.0691756067932108
Validation loss: 2.553380038480236

Epoch: 5| Step: 10
Training loss: 2.8348960120019826
Validation loss: 2.547915449172266

Epoch: 115| Step: 0
Training loss: 2.8133737690296177
Validation loss: 2.545483359263798

Epoch: 5| Step: 1
Training loss: 3.2693889044581024
Validation loss: 2.538966493771408

Epoch: 5| Step: 2
Training loss: 2.8707114036441723
Validation loss: 2.543752880910634

Epoch: 5| Step: 3
Training loss: 2.879019870871008
Validation loss: 2.5515549481697763

Epoch: 5| Step: 4
Training loss: 2.950831577315226
Validation loss: 2.56732269055574

Epoch: 5| Step: 5
Training loss: 2.656144712268785
Validation loss: 2.5690032270492336

Epoch: 5| Step: 6
Training loss: 2.484985564437477
Validation loss: 2.5621283006744324

Epoch: 5| Step: 7
Training loss: 3.0195296708234873
Validation loss: 2.56502779446178

Epoch: 5| Step: 8
Training loss: 3.176156297522832
Validation loss: 2.5510325512261147

Epoch: 5| Step: 9
Training loss: 3.0955099629208096
Validation loss: 2.540108312095318

Epoch: 5| Step: 10
Training loss: 2.587536366525039
Validation loss: 2.532661436428787

Epoch: 116| Step: 0
Training loss: 3.235789114268203
Validation loss: 2.5260921828852783

Epoch: 5| Step: 1
Training loss: 2.5630239555796197
Validation loss: 2.527245175453302

Epoch: 5| Step: 2
Training loss: 2.2721796390343427
Validation loss: 2.5275024743592063

Epoch: 5| Step: 3
Training loss: 3.3503895376532133
Validation loss: 2.5257014537818763

Epoch: 5| Step: 4
Training loss: 2.8294401535713036
Validation loss: 2.5270812642001648

Epoch: 5| Step: 5
Training loss: 2.8633894958435584
Validation loss: 2.5290292791921303

Epoch: 5| Step: 6
Training loss: 2.965399206346918
Validation loss: 2.5235775595953536

Epoch: 5| Step: 7
Training loss: 2.846092684439565
Validation loss: 2.527395790275514

Epoch: 5| Step: 8
Training loss: 2.775583903423539
Validation loss: 2.528448751843814

Epoch: 5| Step: 9
Training loss: 3.226032647693128
Validation loss: 2.5302847193142157

Epoch: 5| Step: 10
Training loss: 2.653668843707098
Validation loss: 2.547787452856849

Epoch: 117| Step: 0
Training loss: 2.8261451324484144
Validation loss: 2.565943775695281

Epoch: 5| Step: 1
Training loss: 3.568456789387683
Validation loss: 2.5953810330493465

Epoch: 5| Step: 2
Training loss: 2.85710579303134
Validation loss: 2.585920377859964

Epoch: 5| Step: 3
Training loss: 3.0236291159301736
Validation loss: 2.5467529005895706

Epoch: 5| Step: 4
Training loss: 2.956538735094512
Validation loss: 2.5285396125059303

Epoch: 5| Step: 5
Training loss: 2.3656029764457918
Validation loss: 2.5218783024396774

Epoch: 5| Step: 6
Training loss: 3.136191811962543
Validation loss: 2.5236568667342207

Epoch: 5| Step: 7
Training loss: 2.906876527256422
Validation loss: 2.5207046364747097

Epoch: 5| Step: 8
Training loss: 2.5140412836501347
Validation loss: 2.5219665220406577

Epoch: 5| Step: 9
Training loss: 2.530781737919446
Validation loss: 2.521785480669943

Epoch: 5| Step: 10
Training loss: 3.0748205117045804
Validation loss: 2.5197262863292984

Epoch: 118| Step: 0
Training loss: 2.7294761152254887
Validation loss: 2.5195301795824285

Epoch: 5| Step: 1
Training loss: 3.252011483616747
Validation loss: 2.518515468467115

Epoch: 5| Step: 2
Training loss: 2.773362107662558
Validation loss: 2.5236874155054956

Epoch: 5| Step: 3
Training loss: 3.0692711537169637
Validation loss: 2.52781391666378

Epoch: 5| Step: 4
Training loss: 2.9766414762017006
Validation loss: 2.5291274050984347

Epoch: 5| Step: 5
Training loss: 2.8996064741224714
Validation loss: 2.532546924096859

Epoch: 5| Step: 6
Training loss: 2.938676801294804
Validation loss: 2.535697263062695

Epoch: 5| Step: 7
Training loss: 2.8305198687981563
Validation loss: 2.53262315859116

Epoch: 5| Step: 8
Training loss: 2.748478295054376
Validation loss: 2.5587003075589436

Epoch: 5| Step: 9
Training loss: 3.0240867371103786
Validation loss: 2.547658276796342

Epoch: 5| Step: 10
Training loss: 2.3452744675919326
Validation loss: 2.537228307075974

Epoch: 119| Step: 0
Training loss: 2.719900742711288
Validation loss: 2.5562606307650424

Epoch: 5| Step: 1
Training loss: 2.9301734622996363
Validation loss: 2.555083434167018

Epoch: 5| Step: 2
Training loss: 2.3252770330623105
Validation loss: 2.5541493932677266

Epoch: 5| Step: 3
Training loss: 2.8210403475359116
Validation loss: 2.548429719085101

Epoch: 5| Step: 4
Training loss: 3.551199406844517
Validation loss: 2.5421078425303825

Epoch: 5| Step: 5
Training loss: 2.8620656179480632
Validation loss: 2.545080647380921

Epoch: 5| Step: 6
Training loss: 3.068763555741524
Validation loss: 2.5377526758439024

Epoch: 5| Step: 7
Training loss: 2.4894139273451805
Validation loss: 2.5300316592211214

Epoch: 5| Step: 8
Training loss: 3.3515216673740067
Validation loss: 2.5264061070664248

Epoch: 5| Step: 9
Training loss: 2.7951837466308365
Validation loss: 2.517130698773241

Epoch: 5| Step: 10
Training loss: 2.416451762498767
Validation loss: 2.515596202475835

Epoch: 120| Step: 0
Training loss: 2.593722056042996
Validation loss: 2.5169904077548315

Epoch: 5| Step: 1
Training loss: 2.87874889590747
Validation loss: 2.517721387075046

Epoch: 5| Step: 2
Training loss: 2.868512837365788
Validation loss: 2.521440095489581

Epoch: 5| Step: 3
Training loss: 3.35159863717042
Validation loss: 2.5184986839717136

Epoch: 5| Step: 4
Training loss: 2.531172574589879
Validation loss: 2.520243497824395

Epoch: 5| Step: 5
Training loss: 3.1608771219865304
Validation loss: 2.516483126638618

Epoch: 5| Step: 6
Training loss: 3.0457226261279304
Validation loss: 2.527228142584711

Epoch: 5| Step: 7
Training loss: 2.6862646412971856
Validation loss: 2.538684745561442

Epoch: 5| Step: 8
Training loss: 2.6899223943243777
Validation loss: 2.5679982407820097

Epoch: 5| Step: 9
Training loss: 3.0733197653657824
Validation loss: 2.570840987141277

Epoch: 5| Step: 10
Training loss: 2.830046954355171
Validation loss: 2.5779351138094495

Epoch: 121| Step: 0
Training loss: 2.973220190224825
Validation loss: 2.5688814079745574

Epoch: 5| Step: 1
Training loss: 3.2689309064647167
Validation loss: 2.545579550746287

Epoch: 5| Step: 2
Training loss: 2.3570857784246644
Validation loss: 2.5715589810091615

Epoch: 5| Step: 3
Training loss: 2.4882225137482346
Validation loss: 2.542206375242895

Epoch: 5| Step: 4
Training loss: 2.9472410328662546
Validation loss: 2.5308347630084396

Epoch: 5| Step: 5
Training loss: 2.650637902550213
Validation loss: 2.5258147083282623

Epoch: 5| Step: 6
Training loss: 2.333136777319257
Validation loss: 2.5204788693733753

Epoch: 5| Step: 7
Training loss: 2.512320391559845
Validation loss: 2.518182892904504

Epoch: 5| Step: 8
Training loss: 3.5885675629602773
Validation loss: 2.52008132748646

Epoch: 5| Step: 9
Training loss: 3.308546478041873
Validation loss: 2.5171672282357425

Epoch: 5| Step: 10
Training loss: 2.815016913083697
Validation loss: 2.519317239860222

Epoch: 122| Step: 0
Training loss: 2.9214296052473228
Validation loss: 2.5124334493137117

Epoch: 5| Step: 1
Training loss: 2.8609696407794027
Validation loss: 2.51479494717199

Epoch: 5| Step: 2
Training loss: 2.813012648590975
Validation loss: 2.5171273153891685

Epoch: 5| Step: 3
Training loss: 2.767773154957734
Validation loss: 2.5159726751974096

Epoch: 5| Step: 4
Training loss: 2.7681071893631937
Validation loss: 2.5216532178759987

Epoch: 5| Step: 5
Training loss: 2.9407836741528715
Validation loss: 2.539004273105879

Epoch: 5| Step: 6
Training loss: 2.8410089717993214
Validation loss: 2.570543684918236

Epoch: 5| Step: 7
Training loss: 3.183202052446822
Validation loss: 2.621601316800566

Epoch: 5| Step: 8
Training loss: 3.1095081089991776
Validation loss: 2.604282901918097

Epoch: 5| Step: 9
Training loss: 2.376164201193839
Validation loss: 2.5476590526329788

Epoch: 5| Step: 10
Training loss: 3.080307085408447
Validation loss: 2.518395088718128

Epoch: 123| Step: 0
Training loss: 2.510504018020985
Validation loss: 2.5141006138385564

Epoch: 5| Step: 1
Training loss: 2.6125255455702865
Validation loss: 2.5220796312294977

Epoch: 5| Step: 2
Training loss: 2.7318217536730964
Validation loss: 2.525133233752034

Epoch: 5| Step: 3
Training loss: 3.5860902840971254
Validation loss: 2.527405528942649

Epoch: 5| Step: 4
Training loss: 3.326129153700248
Validation loss: 2.531931335883774

Epoch: 5| Step: 5
Training loss: 2.92231167880767
Validation loss: 2.532717059983987

Epoch: 5| Step: 6
Training loss: 3.021030779118907
Validation loss: 2.530783388069347

Epoch: 5| Step: 7
Training loss: 2.4919089039031026
Validation loss: 2.525291827011293

Epoch: 5| Step: 8
Training loss: 2.871506434254559
Validation loss: 2.5224693790830477

Epoch: 5| Step: 9
Training loss: 2.6365808521521394
Validation loss: 2.518743070613598

Epoch: 5| Step: 10
Training loss: 3.0378250701647365
Validation loss: 2.5201883151010267

Epoch: 124| Step: 0
Training loss: 3.177463662984967
Validation loss: 2.5162606409168804

Epoch: 5| Step: 1
Training loss: 3.1306947318589455
Validation loss: 2.5267656437960553

Epoch: 5| Step: 2
Training loss: 2.4862422044266457
Validation loss: 2.5357776550652997

Epoch: 5| Step: 3
Training loss: 3.179906589167757
Validation loss: 2.569378414781924

Epoch: 5| Step: 4
Training loss: 2.7940780037468045
Validation loss: 2.559504390988071

Epoch: 5| Step: 5
Training loss: 2.5709703525360585
Validation loss: 2.549103124676634

Epoch: 5| Step: 6
Training loss: 2.6742907751504754
Validation loss: 2.5382782007956326

Epoch: 5| Step: 7
Training loss: 2.600364248730208
Validation loss: 2.5424030077201256

Epoch: 5| Step: 8
Training loss: 2.9771705466955245
Validation loss: 2.5273610965394475

Epoch: 5| Step: 9
Training loss: 2.9367824246139658
Validation loss: 2.5292422638207603

Epoch: 5| Step: 10
Training loss: 2.982633072345723
Validation loss: 2.5139132279280467

Epoch: 125| Step: 0
Training loss: 3.0048161630364376
Validation loss: 2.507620227695845

Epoch: 5| Step: 1
Training loss: 3.150170996732524
Validation loss: 2.5144534548894306

Epoch: 5| Step: 2
Training loss: 2.906188307896966
Validation loss: 2.5173925967870634

Epoch: 5| Step: 3
Training loss: 3.0334442691289274
Validation loss: 2.5127499272362757

Epoch: 5| Step: 4
Training loss: 2.5952421744944925
Validation loss: 2.516062572152113

Epoch: 5| Step: 5
Training loss: 2.9638107168734815
Validation loss: 2.5122086879881382

Epoch: 5| Step: 6
Training loss: 2.7425629013762602
Validation loss: 2.515555012210314

Epoch: 5| Step: 7
Training loss: 3.2582745487409657
Validation loss: 2.515787679744167

Epoch: 5| Step: 8
Training loss: 2.181777444372469
Validation loss: 2.519816281335539

Epoch: 5| Step: 9
Training loss: 2.6747840081119203
Validation loss: 2.524353070528998

Epoch: 5| Step: 10
Training loss: 2.825724979649296
Validation loss: 2.5321519192577404

Epoch: 126| Step: 0
Training loss: 2.4524072459623887
Validation loss: 2.54592021210311

Epoch: 5| Step: 1
Training loss: 3.1065897519764274
Validation loss: 2.5421573861837814

Epoch: 5| Step: 2
Training loss: 3.1679678468902845
Validation loss: 2.562466320793952

Epoch: 5| Step: 3
Training loss: 3.1466271281048215
Validation loss: 2.5349505785525146

Epoch: 5| Step: 4
Training loss: 2.9257760347083024
Validation loss: 2.5250009452877347

Epoch: 5| Step: 5
Training loss: 2.9327692125201823
Validation loss: 2.5120109666636945

Epoch: 5| Step: 6
Training loss: 2.901890592251785
Validation loss: 2.5217994100494416

Epoch: 5| Step: 7
Training loss: 2.4884130901100905
Validation loss: 2.514791005058889

Epoch: 5| Step: 8
Training loss: 2.73146076218481
Validation loss: 2.5141979091353255

Epoch: 5| Step: 9
Training loss: 2.936305026224498
Validation loss: 2.5150751455495595

Epoch: 5| Step: 10
Training loss: 2.6196094750415173
Validation loss: 2.5162440497327703

Epoch: 127| Step: 0
Training loss: 3.2354224531453974
Validation loss: 2.5235617535388237

Epoch: 5| Step: 1
Training loss: 2.518652474382412
Validation loss: 2.5304898885928484

Epoch: 5| Step: 2
Training loss: 2.7341450621791847
Validation loss: 2.537635405955928

Epoch: 5| Step: 3
Training loss: 2.7766239397746477
Validation loss: 2.560937156277552

Epoch: 5| Step: 4
Training loss: 2.98045627096421
Validation loss: 2.5449135683343265

Epoch: 5| Step: 5
Training loss: 2.577545470790321
Validation loss: 2.5503562459234543

Epoch: 5| Step: 6
Training loss: 3.133648159227139
Validation loss: 2.525674003398141

Epoch: 5| Step: 7
Training loss: 2.568918331227579
Validation loss: 2.51912549048849

Epoch: 5| Step: 8
Training loss: 3.3352664746111427
Validation loss: 2.5176938069182655

Epoch: 5| Step: 9
Training loss: 2.8216823305107197
Validation loss: 2.50930941105276

Epoch: 5| Step: 10
Training loss: 2.6130879192371865
Validation loss: 2.504677756480827

Epoch: 128| Step: 0
Training loss: 2.5021792450329534
Validation loss: 2.509367754869097

Epoch: 5| Step: 1
Training loss: 2.8272535129976957
Validation loss: 2.5054795224565045

Epoch: 5| Step: 2
Training loss: 3.4368643433051336
Validation loss: 2.514831806191159

Epoch: 5| Step: 3
Training loss: 3.2584865979558084
Validation loss: 2.5091922820628785

Epoch: 5| Step: 4
Training loss: 2.539916472976477
Validation loss: 2.5063426692952486

Epoch: 5| Step: 5
Training loss: 2.6122561327263276
Validation loss: 2.513825127514364

Epoch: 5| Step: 6
Training loss: 2.543807915255552
Validation loss: 2.5119478303719047

Epoch: 5| Step: 7
Training loss: 3.032310693528921
Validation loss: 2.513117332248593

Epoch: 5| Step: 8
Training loss: 2.876524811124297
Validation loss: 2.5081897720541155

Epoch: 5| Step: 9
Training loss: 2.8228456739294163
Validation loss: 2.532337271706507

Epoch: 5| Step: 10
Training loss: 2.8184048866409355
Validation loss: 2.5340176270043884

Epoch: 129| Step: 0
Training loss: 2.1131462011709443
Validation loss: 2.5611183079101836

Epoch: 5| Step: 1
Training loss: 3.398094843986198
Validation loss: 2.560706764966619

Epoch: 5| Step: 2
Training loss: 2.9333270036744694
Validation loss: 2.5275817090605637

Epoch: 5| Step: 3
Training loss: 3.1375138544635437
Validation loss: 2.5011034806688848

Epoch: 5| Step: 4
Training loss: 2.853749228438525
Validation loss: 2.5051468249872695

Epoch: 5| Step: 5
Training loss: 3.0848834978112802
Validation loss: 2.5163755862044734

Epoch: 5| Step: 6
Training loss: 3.2622223425330135
Validation loss: 2.518323936977757

Epoch: 5| Step: 7
Training loss: 2.7077648935684118
Validation loss: 2.5283462770933105

Epoch: 5| Step: 8
Training loss: 2.6277286334972394
Validation loss: 2.5411475529146483

Epoch: 5| Step: 9
Training loss: 3.103201714035155
Validation loss: 2.5299860052979573

Epoch: 5| Step: 10
Training loss: 2.304383131715908
Validation loss: 2.5389123753291676

Epoch: 130| Step: 0
Training loss: 3.1107965794771473
Validation loss: 2.5205261184288195

Epoch: 5| Step: 1
Training loss: 2.7609497899039392
Validation loss: 2.5277653961332156

Epoch: 5| Step: 2
Training loss: 2.6392859500403367
Validation loss: 2.5193077843644587

Epoch: 5| Step: 3
Training loss: 2.925405399235793
Validation loss: 2.5299825357485064

Epoch: 5| Step: 4
Training loss: 3.071826978678727
Validation loss: 2.540538523015739

Epoch: 5| Step: 5
Training loss: 2.8327413576327727
Validation loss: 2.546807755353154

Epoch: 5| Step: 6
Training loss: 3.1819177252816306
Validation loss: 2.565564538846487

Epoch: 5| Step: 7
Training loss: 2.3145905401585196
Validation loss: 2.5580307899229493

Epoch: 5| Step: 8
Training loss: 2.6971782032074145
Validation loss: 2.5870695408109206

Epoch: 5| Step: 9
Training loss: 2.935585859272081
Validation loss: 2.58909356987312

Epoch: 5| Step: 10
Training loss: 2.996670623906811
Validation loss: 2.5619675137814024

Epoch: 131| Step: 0
Training loss: 2.3374028027567704
Validation loss: 2.5471886258589795

Epoch: 5| Step: 1
Training loss: 3.179248676433859
Validation loss: 2.5143312604998784

Epoch: 5| Step: 2
Training loss: 2.3889271809468573
Validation loss: 2.4988528398681664

Epoch: 5| Step: 3
Training loss: 3.1753348286612053
Validation loss: 2.501618057555036

Epoch: 5| Step: 4
Training loss: 3.0120345963090784
Validation loss: 2.5003854069963714

Epoch: 5| Step: 5
Training loss: 3.4904734524825356
Validation loss: 2.5099229330077732

Epoch: 5| Step: 6
Training loss: 2.0889913656696346
Validation loss: 2.5095760551735924

Epoch: 5| Step: 7
Training loss: 2.8338967118484213
Validation loss: 2.53093702659455

Epoch: 5| Step: 8
Training loss: 3.2629950487600223
Validation loss: 2.5140336693226617

Epoch: 5| Step: 9
Training loss: 2.678580987095808
Validation loss: 2.5084398274914546

Epoch: 5| Step: 10
Training loss: 2.763371902199728
Validation loss: 2.506171888618893

Epoch: 132| Step: 0
Training loss: 2.7388971047045
Validation loss: 2.5198885069851116

Epoch: 5| Step: 1
Training loss: 2.9871284604974995
Validation loss: 2.5377068446249234

Epoch: 5| Step: 2
Training loss: 3.1404011964528697
Validation loss: 2.5550430691143333

Epoch: 5| Step: 3
Training loss: 1.93160989117834
Validation loss: 2.542360235027166

Epoch: 5| Step: 4
Training loss: 3.090469624901919
Validation loss: 2.5460291588510024

Epoch: 5| Step: 5
Training loss: 2.8523138859151143
Validation loss: 2.504641420508075

Epoch: 5| Step: 6
Training loss: 2.7758195989844077
Validation loss: 2.4978659155530587

Epoch: 5| Step: 7
Training loss: 2.8401585631364537
Validation loss: 2.5015121132376943

Epoch: 5| Step: 8
Training loss: 3.232758491253028
Validation loss: 2.4986248787466265

Epoch: 5| Step: 9
Training loss: 3.1775720105839125
Validation loss: 2.5053063385983436

Epoch: 5| Step: 10
Training loss: 2.502212308491743
Validation loss: 2.5026885947159965

Epoch: 133| Step: 0
Training loss: 3.0442123907835663
Validation loss: 2.5030090435448216

Epoch: 5| Step: 1
Training loss: 2.757163427983481
Validation loss: 2.5017516234573987

Epoch: 5| Step: 2
Training loss: 3.0398465986196817
Validation loss: 2.5044070945590984

Epoch: 5| Step: 3
Training loss: 2.905523558035844
Validation loss: 2.5097154725537707

Epoch: 5| Step: 4
Training loss: 2.7103335012763408
Validation loss: 2.5188027582404287

Epoch: 5| Step: 5
Training loss: 2.9497596901466836
Validation loss: 2.5191520016928846

Epoch: 5| Step: 6
Training loss: 3.5550354504326687
Validation loss: 2.5398057711415394

Epoch: 5| Step: 7
Training loss: 2.4230536761350625
Validation loss: 2.532447156096158

Epoch: 5| Step: 8
Training loss: 2.568616313193603
Validation loss: 2.524300157089168

Epoch: 5| Step: 9
Training loss: 2.890447827657365
Validation loss: 2.520774027703836

Epoch: 5| Step: 10
Training loss: 2.279249699095388
Validation loss: 2.507952030749515

Epoch: 134| Step: 0
Training loss: 3.278528738114935
Validation loss: 2.5340986206105374

Epoch: 5| Step: 1
Training loss: 2.454913805285602
Validation loss: 2.521408339552832

Epoch: 5| Step: 2
Training loss: 2.3477612565560504
Validation loss: 2.542604094671629

Epoch: 5| Step: 3
Training loss: 2.257755054416264
Validation loss: 2.565606620920291

Epoch: 5| Step: 4
Training loss: 2.879415852592439
Validation loss: 2.593137403610788

Epoch: 5| Step: 5
Training loss: 3.1485959148072986
Validation loss: 2.553730595565824

Epoch: 5| Step: 6
Training loss: 3.1805910518466396
Validation loss: 2.5356530881812422

Epoch: 5| Step: 7
Training loss: 3.028168517942666
Validation loss: 2.512084467865356

Epoch: 5| Step: 8
Training loss: 2.86685320077263
Validation loss: 2.506899331386782

Epoch: 5| Step: 9
Training loss: 2.9675944438454
Validation loss: 2.5031026092200124

Epoch: 5| Step: 10
Training loss: 2.8234397056414755
Validation loss: 2.4966869582375386

Epoch: 135| Step: 0
Training loss: 2.994082973495032
Validation loss: 2.500847199157213

Epoch: 5| Step: 1
Training loss: 2.7806063989628895
Validation loss: 2.501786915194558

Epoch: 5| Step: 2
Training loss: 2.7183388585498944
Validation loss: 2.509328413705466

Epoch: 5| Step: 3
Training loss: 3.2380446104825515
Validation loss: 2.551116864495599

Epoch: 5| Step: 4
Training loss: 2.511046988682234
Validation loss: 2.535619432537959

Epoch: 5| Step: 5
Training loss: 2.4994014977254606
Validation loss: 2.533141360945693

Epoch: 5| Step: 6
Training loss: 2.8706815047364174
Validation loss: 2.5398591014128757

Epoch: 5| Step: 7
Training loss: 3.033118547094317
Validation loss: 2.5087209175675143

Epoch: 5| Step: 8
Training loss: 2.713378335109374
Validation loss: 2.5141055379885437

Epoch: 5| Step: 9
Training loss: 2.9752747160430904
Validation loss: 2.514424826451287

Epoch: 5| Step: 10
Training loss: 2.8987288418582042
Validation loss: 2.551864046708897

Epoch: 136| Step: 0
Training loss: 2.4127909944383945
Validation loss: 2.5477885164336334

Epoch: 5| Step: 1
Training loss: 2.6933885867365293
Validation loss: 2.5601537624578374

Epoch: 5| Step: 2
Training loss: 3.1181499936066888
Validation loss: 2.607040554736826

Epoch: 5| Step: 3
Training loss: 3.347540587449111
Validation loss: 2.5751913692696426

Epoch: 5| Step: 4
Training loss: 2.354099160185813
Validation loss: 2.5074141021758796

Epoch: 5| Step: 5
Training loss: 2.5355314614840205
Validation loss: 2.5099752742142853

Epoch: 5| Step: 6
Training loss: 2.7545364416360116
Validation loss: 2.50389823319094

Epoch: 5| Step: 7
Training loss: 3.294886273981498
Validation loss: 2.5168335608342227

Epoch: 5| Step: 8
Training loss: 2.9820904200947034
Validation loss: 2.5239744522793264

Epoch: 5| Step: 9
Training loss: 2.974403539537906
Validation loss: 2.5305823951371478

Epoch: 5| Step: 10
Training loss: 2.8127041212820365
Validation loss: 2.547360263084952

Epoch: 137| Step: 0
Training loss: 2.9992067559875117
Validation loss: 2.570033901912387

Epoch: 5| Step: 1
Training loss: 3.007464817313807
Validation loss: 2.595712453811094

Epoch: 5| Step: 2
Training loss: 2.5899605703114137
Validation loss: 2.614350137450091

Epoch: 5| Step: 3
Training loss: 3.0510849258171002
Validation loss: 2.652112352030259

Epoch: 5| Step: 4
Training loss: 3.303714978843966
Validation loss: 2.649655729496216

Epoch: 5| Step: 5
Training loss: 3.3327086499108245
Validation loss: 2.6496558746268004

Epoch: 5| Step: 6
Training loss: 2.582256820913453
Validation loss: 2.590287383215116

Epoch: 5| Step: 7
Training loss: 2.918396700075442
Validation loss: 2.567062499054638

Epoch: 5| Step: 8
Training loss: 2.427421666304584
Validation loss: 2.572181778717273

Epoch: 5| Step: 9
Training loss: 2.6407246768354433
Validation loss: 2.55816569056784

Epoch: 5| Step: 10
Training loss: 2.5150341027073098
Validation loss: 2.5543685271910856

Epoch: 138| Step: 0
Training loss: 2.731156727749838
Validation loss: 2.5501328083675703

Epoch: 5| Step: 1
Training loss: 2.7727364527156673
Validation loss: 2.552229313612878

Epoch: 5| Step: 2
Training loss: 2.8061127932847736
Validation loss: 2.5453044941918894

Epoch: 5| Step: 3
Training loss: 2.49360754997278
Validation loss: 2.5462262089557957

Epoch: 5| Step: 4
Training loss: 2.9293930516094746
Validation loss: 2.548709955502621

Epoch: 5| Step: 5
Training loss: 3.0105768356921163
Validation loss: 2.536653838151155

Epoch: 5| Step: 6
Training loss: 2.8578218504772024
Validation loss: 2.540399146240544

Epoch: 5| Step: 7
Training loss: 2.8121839557671575
Validation loss: 2.5517582143626565

Epoch: 5| Step: 8
Training loss: 3.0007707877201435
Validation loss: 2.5961242258650263

Epoch: 5| Step: 9
Training loss: 3.187445546601358
Validation loss: 2.6046794722805444

Epoch: 5| Step: 10
Training loss: 3.068513221696076
Validation loss: 2.5979425847822046

Epoch: 139| Step: 0
Training loss: 3.057196247923157
Validation loss: 2.5722769030319235

Epoch: 5| Step: 1
Training loss: 2.8546859565818385
Validation loss: 2.57203597134941

Epoch: 5| Step: 2
Training loss: 2.5064319839426354
Validation loss: 2.56493106897421

Epoch: 5| Step: 3
Training loss: 2.8816605414050964
Validation loss: 2.5467588668850225

Epoch: 5| Step: 4
Training loss: 2.982085303280656
Validation loss: 2.55540522207064

Epoch: 5| Step: 5
Training loss: 2.713919019667407
Validation loss: 2.5607302637512994

Epoch: 5| Step: 6
Training loss: 2.727313880898905
Validation loss: 2.577171903749122

Epoch: 5| Step: 7
Training loss: 3.1368260727475703
Validation loss: 2.5872476226501564

Epoch: 5| Step: 8
Training loss: 2.507136744071392
Validation loss: 2.5558899122660073

Epoch: 5| Step: 9
Training loss: 2.828666340142467
Validation loss: 2.543895997157597

Epoch: 5| Step: 10
Training loss: 3.2947544310873056
Validation loss: 2.5239821615501907

Epoch: 140| Step: 0
Training loss: 3.33275500684778
Validation loss: 2.5311984147203916

Epoch: 5| Step: 1
Training loss: 2.7028636475274226
Validation loss: 2.532422479723961

Epoch: 5| Step: 2
Training loss: 2.5065509796163186
Validation loss: 2.5306933717830655

Epoch: 5| Step: 3
Training loss: 3.030449043715333
Validation loss: 2.5265271969257963

Epoch: 5| Step: 4
Training loss: 2.9037031273542135
Validation loss: 2.5318830653784468

Epoch: 5| Step: 5
Training loss: 3.1115909520482687
Validation loss: 2.5230713214182767

Epoch: 5| Step: 6
Training loss: 3.065077961712712
Validation loss: 2.5271074403574807

Epoch: 5| Step: 7
Training loss: 2.700017300303099
Validation loss: 2.5331333880812403

Epoch: 5| Step: 8
Training loss: 2.7974993472401093
Validation loss: 2.528422518597755

Epoch: 5| Step: 9
Training loss: 2.094545810966148
Validation loss: 2.5317473586951085

Epoch: 5| Step: 10
Training loss: 3.1164216365133135
Validation loss: 2.5666057749912397

Epoch: 141| Step: 0
Training loss: 2.9856213269002487
Validation loss: 2.5821348219209836

Epoch: 5| Step: 1
Training loss: 2.767352238322709
Validation loss: 2.605809416090287

Epoch: 5| Step: 2
Training loss: 3.549893342685918
Validation loss: 2.646509840944574

Epoch: 5| Step: 3
Training loss: 2.766055057515536
Validation loss: 2.571705525188099

Epoch: 5| Step: 4
Training loss: 2.7845905259072934
Validation loss: 2.5606263196415675

Epoch: 5| Step: 5
Training loss: 2.936553153168987
Validation loss: 2.5334442140582465

Epoch: 5| Step: 6
Training loss: 2.534896860827229
Validation loss: 2.52280114873075

Epoch: 5| Step: 7
Training loss: 3.008938506766132
Validation loss: 2.519900067251227

Epoch: 5| Step: 8
Training loss: 2.9685453645549864
Validation loss: 2.510515731785597

Epoch: 5| Step: 9
Training loss: 2.391680216557026
Validation loss: 2.5118403570456382

Epoch: 5| Step: 10
Training loss: 2.7909132856609165
Validation loss: 2.5052165632351735

Epoch: 142| Step: 0
Training loss: 2.9081450815858134
Validation loss: 2.5054481249515175

Epoch: 5| Step: 1
Training loss: 2.86502900326946
Validation loss: 2.4953923469595454

Epoch: 5| Step: 2
Training loss: 2.6557212752166186
Validation loss: 2.4799389665587825

Epoch: 5| Step: 3
Training loss: 2.9606862628405355
Validation loss: 2.484231485638325

Epoch: 5| Step: 4
Training loss: 2.5372134004547235
Validation loss: 2.47568320453627

Epoch: 5| Step: 5
Training loss: 2.562147628003095
Validation loss: 2.49671559702649

Epoch: 5| Step: 6
Training loss: 3.0183924492857575
Validation loss: 2.5018162907797405

Epoch: 5| Step: 7
Training loss: 2.5210368071687026
Validation loss: 2.5297914610029153

Epoch: 5| Step: 8
Training loss: 3.2295187645376036
Validation loss: 2.5121844149048393

Epoch: 5| Step: 9
Training loss: 2.9316196428192343
Validation loss: 2.521094079305219

Epoch: 5| Step: 10
Training loss: 2.832824343421447
Validation loss: 2.54944153786354

Epoch: 143| Step: 0
Training loss: 3.378931934060621
Validation loss: 2.550241312781333

Epoch: 5| Step: 1
Training loss: 2.358941853154702
Validation loss: 2.5304975911844196

Epoch: 5| Step: 2
Training loss: 3.4952627547658723
Validation loss: 2.525274712949537

Epoch: 5| Step: 3
Training loss: 2.373862546288617
Validation loss: 2.509282801478065

Epoch: 5| Step: 4
Training loss: 2.5280522056633496
Validation loss: 2.5134961570007777

Epoch: 5| Step: 5
Training loss: 2.7662537285753332
Validation loss: 2.5088877225283768

Epoch: 5| Step: 6
Training loss: 2.5445256543237043
Validation loss: 2.5091174169329076

Epoch: 5| Step: 7
Training loss: 2.8877724258916655
Validation loss: 2.5024311867702096

Epoch: 5| Step: 8
Training loss: 3.1703313068341568
Validation loss: 2.4814475569608123

Epoch: 5| Step: 9
Training loss: 3.109071036198736
Validation loss: 2.485674495980697

Epoch: 5| Step: 10
Training loss: 2.2042263876234465
Validation loss: 2.479489130144114

Epoch: 144| Step: 0
Training loss: 3.1074534857560936
Validation loss: 2.4781666154740583

Epoch: 5| Step: 1
Training loss: 2.6605768305383535
Validation loss: 2.481206317720744

Epoch: 5| Step: 2
Training loss: 2.9336904619024353
Validation loss: 2.484136692659172

Epoch: 5| Step: 3
Training loss: 2.8170242372281966
Validation loss: 2.4756929094908053

Epoch: 5| Step: 4
Training loss: 2.8266994192217214
Validation loss: 2.4877064531464463

Epoch: 5| Step: 5
Training loss: 2.2887060519321563
Validation loss: 2.4959325876228204

Epoch: 5| Step: 6
Training loss: 2.844658004505578
Validation loss: 2.5103847103529886

Epoch: 5| Step: 7
Training loss: 2.7938383869296186
Validation loss: 2.529306435053237

Epoch: 5| Step: 8
Training loss: 2.494145022203935
Validation loss: 2.523432381729934

Epoch: 5| Step: 9
Training loss: 3.0161217789285546
Validation loss: 2.5159805964722004

Epoch: 5| Step: 10
Training loss: 3.2261902084042133
Validation loss: 2.50705884904354

Epoch: 145| Step: 0
Training loss: 2.2557917332932447
Validation loss: 2.482204972635229

Epoch: 5| Step: 1
Training loss: 3.1284468905352085
Validation loss: 2.4750457795070027

Epoch: 5| Step: 2
Training loss: 3.10309368936007
Validation loss: 2.4798097065202405

Epoch: 5| Step: 3
Training loss: 2.621107758031216
Validation loss: 2.4909647255308998

Epoch: 5| Step: 4
Training loss: 1.7640397373619636
Validation loss: 2.4866639835921953

Epoch: 5| Step: 5
Training loss: 2.6475575653532317
Validation loss: 2.4883302643300285

Epoch: 5| Step: 6
Training loss: 2.6336425921568507
Validation loss: 2.497797562934921

Epoch: 5| Step: 7
Training loss: 3.3832071615912302
Validation loss: 2.4979639427391738

Epoch: 5| Step: 8
Training loss: 3.2225785679557837
Validation loss: 2.497473479887706

Epoch: 5| Step: 9
Training loss: 2.439404941446432
Validation loss: 2.508382090640203

Epoch: 5| Step: 10
Training loss: 3.420934539177546
Validation loss: 2.5247261386193864

Epoch: 146| Step: 0
Training loss: 2.496039878013137
Validation loss: 2.5113589649610284

Epoch: 5| Step: 1
Training loss: 2.7872718170240085
Validation loss: 2.4989026542837944

Epoch: 5| Step: 2
Training loss: 3.2680653484165516
Validation loss: 2.5057498634063338

Epoch: 5| Step: 3
Training loss: 3.077571916026566
Validation loss: 2.501202887664413

Epoch: 5| Step: 4
Training loss: 2.8238423836680924
Validation loss: 2.5039420929110556

Epoch: 5| Step: 5
Training loss: 2.653846730622364
Validation loss: 2.4866191706330105

Epoch: 5| Step: 6
Training loss: 2.4228751793740138
Validation loss: 2.480962002066007

Epoch: 5| Step: 7
Training loss: 2.581887476347728
Validation loss: 2.4701064446091316

Epoch: 5| Step: 8
Training loss: 3.145004938118701
Validation loss: 2.476440998115826

Epoch: 5| Step: 9
Training loss: 2.857688531538406
Validation loss: 2.484871119600365

Epoch: 5| Step: 10
Training loss: 2.534876827129287
Validation loss: 2.515608236982733

Epoch: 147| Step: 0
Training loss: 2.805802062717348
Validation loss: 2.5588776131086775

Epoch: 5| Step: 1
Training loss: 2.8657021481977254
Validation loss: 2.583351594329133

Epoch: 5| Step: 2
Training loss: 2.716588180281943
Validation loss: 2.674275501342829

Epoch: 5| Step: 3
Training loss: 3.4962407768490644
Validation loss: 2.610106570678069

Epoch: 5| Step: 4
Training loss: 2.6894784786273176
Validation loss: 2.494250456157698

Epoch: 5| Step: 5
Training loss: 2.8325460873631223
Validation loss: 2.472313761087002

Epoch: 5| Step: 6
Training loss: 2.778882765865109
Validation loss: 2.475765821767459

Epoch: 5| Step: 7
Training loss: 3.2273936829020466
Validation loss: 2.501193677329146

Epoch: 5| Step: 8
Training loss: 2.604951684251114
Validation loss: 2.4924189432806174

Epoch: 5| Step: 9
Training loss: 2.8728677887017118
Validation loss: 2.4753559579575426

Epoch: 5| Step: 10
Training loss: 2.852306028653186
Validation loss: 2.4694646151780963

Epoch: 148| Step: 0
Training loss: 3.0617399245627674
Validation loss: 2.4826681225479645

Epoch: 5| Step: 1
Training loss: 2.5604738738640225
Validation loss: 2.4899156530302164

Epoch: 5| Step: 2
Training loss: 2.5953121766349136
Validation loss: 2.5368167842652722

Epoch: 5| Step: 3
Training loss: 2.60364336986747
Validation loss: 2.5117703138128245

Epoch: 5| Step: 4
Training loss: 2.5751037465648854
Validation loss: 2.526283613026404

Epoch: 5| Step: 5
Training loss: 2.9154998261790714
Validation loss: 2.5248628415413767

Epoch: 5| Step: 6
Training loss: 2.46656451486302
Validation loss: 2.5587040708082456

Epoch: 5| Step: 7
Training loss: 3.5467804883556813
Validation loss: 2.6529133531955313

Epoch: 5| Step: 8
Training loss: 3.0897314000591893
Validation loss: 2.5896549101872557

Epoch: 5| Step: 9
Training loss: 2.996065261486543
Validation loss: 2.5448963505024467

Epoch: 5| Step: 10
Training loss: 2.5301453805700707
Validation loss: 2.5097062418734573

Epoch: 149| Step: 0
Training loss: 2.606375426423514
Validation loss: 2.485336263241934

Epoch: 5| Step: 1
Training loss: 2.6034682799696927
Validation loss: 2.482656396142995

Epoch: 5| Step: 2
Training loss: 3.1429498522572246
Validation loss: 2.4807766165931486

Epoch: 5| Step: 3
Training loss: 2.8095739614537916
Validation loss: 2.473774424497645

Epoch: 5| Step: 4
Training loss: 2.441940761800553
Validation loss: 2.4696694195400686

Epoch: 5| Step: 5
Training loss: 2.7640964572819615
Validation loss: 2.4656234794233645

Epoch: 5| Step: 6
Training loss: 2.444121146737952
Validation loss: 2.471817076117563

Epoch: 5| Step: 7
Training loss: 3.1485601737306115
Validation loss: 2.470592593615794

Epoch: 5| Step: 8
Training loss: 2.590914543730186
Validation loss: 2.4810439186047084

Epoch: 5| Step: 9
Training loss: 3.2089857123494627
Validation loss: 2.4741449273837723

Epoch: 5| Step: 10
Training loss: 3.068071396764112
Validation loss: 2.487386721874521

Epoch: 150| Step: 0
Training loss: 3.061985206154654
Validation loss: 2.4975368527478263

Epoch: 5| Step: 1
Training loss: 2.874103738153593
Validation loss: 2.508099052202761

Epoch: 5| Step: 2
Training loss: 2.4835886160529568
Validation loss: 2.5326098464935867

Epoch: 5| Step: 3
Training loss: 1.9230827940337722
Validation loss: 2.536242609266333

Epoch: 5| Step: 4
Training loss: 2.9518486372953543
Validation loss: 2.554212227124446

Epoch: 5| Step: 5
Training loss: 3.18263546615647
Validation loss: 2.56181235082104

Epoch: 5| Step: 6
Training loss: 2.7513152358533137
Validation loss: 2.5689593813900937

Epoch: 5| Step: 7
Training loss: 2.4548701985029275
Validation loss: 2.496534694601368

Epoch: 5| Step: 8
Training loss: 2.952630541545651
Validation loss: 2.484332835976747

Epoch: 5| Step: 9
Training loss: 3.324359608410359
Validation loss: 2.48473309395763

Epoch: 5| Step: 10
Training loss: 2.774848342737908
Validation loss: 2.4969644986366815

Epoch: 151| Step: 0
Training loss: 2.8223809347388933
Validation loss: 2.503740558943235

Epoch: 5| Step: 1
Training loss: 3.183561097896204
Validation loss: 2.512606608211037

Epoch: 5| Step: 2
Training loss: 2.832734287737181
Validation loss: 2.510765851680125

Epoch: 5| Step: 3
Training loss: 3.0646773402777994
Validation loss: 2.498536058667373

Epoch: 5| Step: 4
Training loss: 2.8537039462904574
Validation loss: 2.4871326758441823

Epoch: 5| Step: 5
Training loss: 3.036453657108499
Validation loss: 2.490692842582441

Epoch: 5| Step: 6
Training loss: 2.815926562554621
Validation loss: 2.490976163764574

Epoch: 5| Step: 7
Training loss: 2.580926840737406
Validation loss: 2.485206262165907

Epoch: 5| Step: 8
Training loss: 2.9069327916215886
Validation loss: 2.4731199965620387

Epoch: 5| Step: 9
Training loss: 2.8864977265479026
Validation loss: 2.482724407694772

Epoch: 5| Step: 10
Training loss: 2.6997850544459943
Validation loss: 2.4935463103068813

Epoch: 152| Step: 0
Training loss: 3.327962378885296
Validation loss: 2.517156863320702

Epoch: 5| Step: 1
Training loss: 2.3028095417518784
Validation loss: 2.4793966167217163

Epoch: 5| Step: 2
Training loss: 3.3768448202792176
Validation loss: 2.4942591679452515

Epoch: 5| Step: 3
Training loss: 2.6728870638969497
Validation loss: 2.487922904217525

Epoch: 5| Step: 4
Training loss: 2.2348554401456013
Validation loss: 2.4810202995239914

Epoch: 5| Step: 5
Training loss: 2.9153048651324682
Validation loss: 2.4887555370101415

Epoch: 5| Step: 6
Training loss: 2.72836253037751
Validation loss: 2.502098781721782

Epoch: 5| Step: 7
Training loss: 2.869947056564443
Validation loss: 2.552306158514534

Epoch: 5| Step: 8
Training loss: 3.017585077864158
Validation loss: 2.6038158625103853

Epoch: 5| Step: 9
Training loss: 2.647895149805829
Validation loss: 2.622632398985062

Epoch: 5| Step: 10
Training loss: 2.7682895217206083
Validation loss: 2.6243160458400894

Epoch: 153| Step: 0
Training loss: 2.1211985075707807
Validation loss: 2.517894414456373

Epoch: 5| Step: 1
Training loss: 3.017871553543007
Validation loss: 2.4891233743145107

Epoch: 5| Step: 2
Training loss: 2.276547955405666
Validation loss: 2.4823435772514797

Epoch: 5| Step: 3
Training loss: 2.474272815726731
Validation loss: 2.466879586151615

Epoch: 5| Step: 4
Training loss: 2.6567090703658556
Validation loss: 2.4748564537552147

Epoch: 5| Step: 5
Training loss: 2.973159727351234
Validation loss: 2.480610517423698

Epoch: 5| Step: 6
Training loss: 2.9967729378068477
Validation loss: 2.4836386684976284

Epoch: 5| Step: 7
Training loss: 3.1086457130478036
Validation loss: 2.482785952495493

Epoch: 5| Step: 8
Training loss: 2.8790970510042837
Validation loss: 2.4897348810293

Epoch: 5| Step: 9
Training loss: 3.0741549997857165
Validation loss: 2.497939027321848

Epoch: 5| Step: 10
Training loss: 3.2183290965603706
Validation loss: 2.5034353085211722

Epoch: 154| Step: 0
Training loss: 3.086553970762331
Validation loss: 2.505345893340592

Epoch: 5| Step: 1
Training loss: 2.488447102958472
Validation loss: 2.5006188324042324

Epoch: 5| Step: 2
Training loss: 2.888563421043432
Validation loss: 2.4975899944625577

Epoch: 5| Step: 3
Training loss: 2.9627874629267748
Validation loss: 2.5051620288439707

Epoch: 5| Step: 4
Training loss: 3.152157538112676
Validation loss: 2.5072199250717944

Epoch: 5| Step: 5
Training loss: 2.8725373045090117
Validation loss: 2.5105426167671947

Epoch: 5| Step: 6
Training loss: 2.7786459572722606
Validation loss: 2.5269368922870052

Epoch: 5| Step: 7
Training loss: 2.853589317419848
Validation loss: 2.5215748186513216

Epoch: 5| Step: 8
Training loss: 2.2046480798475168
Validation loss: 2.516528879848852

Epoch: 5| Step: 9
Training loss: 2.68027652239106
Validation loss: 2.508208370260909

Epoch: 5| Step: 10
Training loss: 2.5413895023332373
Validation loss: 2.482620915582742

Epoch: 155| Step: 0
Training loss: 2.8823294713048235
Validation loss: 2.500950048777584

Epoch: 5| Step: 1
Training loss: 3.043081259453277
Validation loss: 2.518673176592473

Epoch: 5| Step: 2
Training loss: 2.5134502037492794
Validation loss: 2.5347205175855834

Epoch: 5| Step: 3
Training loss: 2.8153132461883916
Validation loss: 2.5627894144323022

Epoch: 5| Step: 4
Training loss: 3.0491086939488805
Validation loss: 2.573955379194273

Epoch: 5| Step: 5
Training loss: 3.1843051232634716
Validation loss: 2.5290846430541314

Epoch: 5| Step: 6
Training loss: 2.2736572998343094
Validation loss: 2.498403616838367

Epoch: 5| Step: 7
Training loss: 2.931075029498946
Validation loss: 2.4857490110710536

Epoch: 5| Step: 8
Training loss: 2.796102065366844
Validation loss: 2.4761121340444596

Epoch: 5| Step: 9
Training loss: 2.5600127267521176
Validation loss: 2.475166775041969

Epoch: 5| Step: 10
Training loss: 2.431188481589594
Validation loss: 2.468207179567956

Epoch: 156| Step: 0
Training loss: 2.10920194693059
Validation loss: 2.4768368159000143

Epoch: 5| Step: 1
Training loss: 2.478955000702476
Validation loss: 2.471403223488303

Epoch: 5| Step: 2
Training loss: 2.50474213024776
Validation loss: 2.4737549611530047

Epoch: 5| Step: 3
Training loss: 2.2054517647348955
Validation loss: 2.4711071852131523

Epoch: 5| Step: 4
Training loss: 3.061284193702345
Validation loss: 2.4681341790284654

Epoch: 5| Step: 5
Training loss: 3.1570510603092727
Validation loss: 2.468305344969615

Epoch: 5| Step: 6
Training loss: 2.9642727469129455
Validation loss: 2.493204325033741

Epoch: 5| Step: 7
Training loss: 2.9094322584112833
Validation loss: 2.494788254356958

Epoch: 5| Step: 8
Training loss: 2.6159835551442048
Validation loss: 2.5034360509566485

Epoch: 5| Step: 9
Training loss: 3.369842120131419
Validation loss: 2.529622615075897

Epoch: 5| Step: 10
Training loss: 3.174090734327879
Validation loss: 2.525859799237703

Epoch: 157| Step: 0
Training loss: 2.4390838563461843
Validation loss: 2.4938504849165275

Epoch: 5| Step: 1
Training loss: 2.796147683479606
Validation loss: 2.476104073838075

Epoch: 5| Step: 2
Training loss: 2.6592617239400025
Validation loss: 2.485895098513733

Epoch: 5| Step: 3
Training loss: 2.5492978419556063
Validation loss: 2.480067652877136

Epoch: 5| Step: 4
Training loss: 2.9918475642718425
Validation loss: 2.488730568033484

Epoch: 5| Step: 5
Training loss: 2.118510378450456
Validation loss: 2.490279598513106

Epoch: 5| Step: 6
Training loss: 3.197954125863204
Validation loss: 2.511680939947222

Epoch: 5| Step: 7
Training loss: 3.078187273818829
Validation loss: 2.5042527973409894

Epoch: 5| Step: 8
Training loss: 2.9870721103583135
Validation loss: 2.5017954255113786

Epoch: 5| Step: 9
Training loss: 2.6486362618999917
Validation loss: 2.4988125165074155

Epoch: 5| Step: 10
Training loss: 2.9760092874505113
Validation loss: 2.47082174550523

Epoch: 158| Step: 0
Training loss: 2.863179162093355
Validation loss: 2.4684464696542063

Epoch: 5| Step: 1
Training loss: 2.3865809923739025
Validation loss: 2.4727617085882714

Epoch: 5| Step: 2
Training loss: 3.128053317930251
Validation loss: 2.472536024335541

Epoch: 5| Step: 3
Training loss: 2.7579139064051335
Validation loss: 2.467887985455271

Epoch: 5| Step: 4
Training loss: 3.2337998325679806
Validation loss: 2.473750537031848

Epoch: 5| Step: 5
Training loss: 2.79191524670458
Validation loss: 2.469980506682217

Epoch: 5| Step: 6
Training loss: 2.8927861563233153
Validation loss: 2.4774127314760066

Epoch: 5| Step: 7
Training loss: 2.6740651217215183
Validation loss: 2.488856187067905

Epoch: 5| Step: 8
Training loss: 2.4017884147576187
Validation loss: 2.485419235212349

Epoch: 5| Step: 9
Training loss: 2.621298223442099
Validation loss: 2.4943800742600986

Epoch: 5| Step: 10
Training loss: 2.8617595464541026
Validation loss: 2.509945756134651

Epoch: 159| Step: 0
Training loss: 2.8966206822697935
Validation loss: 2.5237245941488315

Epoch: 5| Step: 1
Training loss: 3.329522211204969
Validation loss: 2.532366074238359

Epoch: 5| Step: 2
Training loss: 2.8847170278785783
Validation loss: 2.5157708311934943

Epoch: 5| Step: 3
Training loss: 2.7993785372841815
Validation loss: 2.4920116908644694

Epoch: 5| Step: 4
Training loss: 2.505050707092569
Validation loss: 2.4688823119834993

Epoch: 5| Step: 5
Training loss: 2.109468359117452
Validation loss: 2.470268107777605

Epoch: 5| Step: 6
Training loss: 3.245720907344626
Validation loss: 2.473157307725711

Epoch: 5| Step: 7
Training loss: 2.7324661131325536
Validation loss: 2.4783057650667395

Epoch: 5| Step: 8
Training loss: 3.0044021097971414
Validation loss: 2.478713865871014

Epoch: 5| Step: 9
Training loss: 2.5237821455821767
Validation loss: 2.491606731176144

Epoch: 5| Step: 10
Training loss: 2.331841798176371
Validation loss: 2.498879899572607

Epoch: 160| Step: 0
Training loss: 2.123936106322465
Validation loss: 2.531779352518441

Epoch: 5| Step: 1
Training loss: 2.695839385350631
Validation loss: 2.565444339233331

Epoch: 5| Step: 2
Training loss: 2.882872045878928
Validation loss: 2.588119815793558

Epoch: 5| Step: 3
Training loss: 2.868146273512676
Validation loss: 2.564869883042588

Epoch: 5| Step: 4
Training loss: 2.8887907239749695
Validation loss: 2.544747820207353

Epoch: 5| Step: 5
Training loss: 2.997869211704513
Validation loss: 2.5145347707633166

Epoch: 5| Step: 6
Training loss: 2.5522510914583028
Validation loss: 2.4862586880271857

Epoch: 5| Step: 7
Training loss: 2.3907047831866572
Validation loss: 2.47069320433528

Epoch: 5| Step: 8
Training loss: 2.685491210360606
Validation loss: 2.4680250221491495

Epoch: 5| Step: 9
Training loss: 2.907451258322148
Validation loss: 2.4665667063458887

Epoch: 5| Step: 10
Training loss: 3.477467759817314
Validation loss: 2.461490855497868

Epoch: 161| Step: 0
Training loss: 2.7955276397937965
Validation loss: 2.475056177833567

Epoch: 5| Step: 1
Training loss: 2.974381255872496
Validation loss: 2.46541160390883

Epoch: 5| Step: 2
Training loss: 2.3051018811132864
Validation loss: 2.465639105829156

Epoch: 5| Step: 3
Training loss: 2.8376790733799577
Validation loss: 2.4715784997746733

Epoch: 5| Step: 4
Training loss: 2.4917441425164695
Validation loss: 2.4745768305760976

Epoch: 5| Step: 5
Training loss: 2.394019316420868
Validation loss: 2.49726940666807

Epoch: 5| Step: 6
Training loss: 2.648117181092514
Validation loss: 2.5251360500529967

Epoch: 5| Step: 7
Training loss: 2.593694571396872
Validation loss: 2.607873551586206

Epoch: 5| Step: 8
Training loss: 3.043424403264959
Validation loss: 2.6065256970720503

Epoch: 5| Step: 9
Training loss: 3.6847426887024013
Validation loss: 2.619489752991519

Epoch: 5| Step: 10
Training loss: 2.8591708751422535
Validation loss: 2.5347690121886273

Epoch: 162| Step: 0
Training loss: 2.661560494589109
Validation loss: 2.517334310643314

Epoch: 5| Step: 1
Training loss: 2.7589867877153016
Validation loss: 2.4757932373546128

Epoch: 5| Step: 2
Training loss: 2.7967380937708355
Validation loss: 2.4713643775532854

Epoch: 5| Step: 3
Training loss: 2.642748999868537
Validation loss: 2.474625385986722

Epoch: 5| Step: 4
Training loss: 2.6299589636904606
Validation loss: 2.467640031311989

Epoch: 5| Step: 5
Training loss: 2.872527344576012
Validation loss: 2.4679862134134263

Epoch: 5| Step: 6
Training loss: 2.246861600239023
Validation loss: 2.4756718716858956

Epoch: 5| Step: 7
Training loss: 2.9488850183692312
Validation loss: 2.4694966430296756

Epoch: 5| Step: 8
Training loss: 2.9139960641932565
Validation loss: 2.4789209806815387

Epoch: 5| Step: 9
Training loss: 2.849392668946866
Validation loss: 2.471243342119461

Epoch: 5| Step: 10
Training loss: 3.108954933200603
Validation loss: 2.4899046001484564

Epoch: 163| Step: 0
Training loss: 2.7409753973440214
Validation loss: 2.4791609278966042

Epoch: 5| Step: 1
Training loss: 2.8606576179510044
Validation loss: 2.5142105244040978

Epoch: 5| Step: 2
Training loss: 2.097765132983581
Validation loss: 2.5239228066672763

Epoch: 5| Step: 3
Training loss: 2.9814697824392975
Validation loss: 2.573879009328993

Epoch: 5| Step: 4
Training loss: 2.848541247832052
Validation loss: 2.570670122345503

Epoch: 5| Step: 5
Training loss: 2.326271804469603
Validation loss: 2.53899986271865

Epoch: 5| Step: 6
Training loss: 2.5487595589137184
Validation loss: 2.5216419503105616

Epoch: 5| Step: 7
Training loss: 2.462823345042827
Validation loss: 2.51358518686752

Epoch: 5| Step: 8
Training loss: 3.2480677215769678
Validation loss: 2.524035972417594

Epoch: 5| Step: 9
Training loss: 3.065624122736161
Validation loss: 2.5283577256836964

Epoch: 5| Step: 10
Training loss: 3.0355764758461365
Validation loss: 2.515682226686911

Epoch: 164| Step: 0
Training loss: 3.0335995721478706
Validation loss: 2.4894299357980563

Epoch: 5| Step: 1
Training loss: 2.701608662517013
Validation loss: 2.47910126823629

Epoch: 5| Step: 2
Training loss: 2.662162214889662
Validation loss: 2.4682746565619187

Epoch: 5| Step: 3
Training loss: 3.1110646626623035
Validation loss: 2.453333125610441

Epoch: 5| Step: 4
Training loss: 2.9454352153439203
Validation loss: 2.4628495442130136

Epoch: 5| Step: 5
Training loss: 2.3735440459454744
Validation loss: 2.4644225409579463

Epoch: 5| Step: 6
Training loss: 2.886879468684383
Validation loss: 2.452740393187146

Epoch: 5| Step: 7
Training loss: 2.8780478203083155
Validation loss: 2.439390764902697

Epoch: 5| Step: 8
Training loss: 2.1702377405329005
Validation loss: 2.445709060593687

Epoch: 5| Step: 9
Training loss: 2.91326075101941
Validation loss: 2.4466555933810583

Epoch: 5| Step: 10
Training loss: 2.6234583187583618
Validation loss: 2.4701204578423472

Epoch: 165| Step: 0
Training loss: 2.7328567213403265
Validation loss: 2.495401559701177

Epoch: 5| Step: 1
Training loss: 2.8381913741834355
Validation loss: 2.504152589013489

Epoch: 5| Step: 2
Training loss: 2.739081990792301
Validation loss: 2.4523354288974235

Epoch: 5| Step: 3
Training loss: 2.1547202613337193
Validation loss: 2.459594423610875

Epoch: 5| Step: 4
Training loss: 2.961294832031143
Validation loss: 2.4566137157743437

Epoch: 5| Step: 5
Training loss: 2.6810286032585475
Validation loss: 2.4509152247206143

Epoch: 5| Step: 6
Training loss: 2.8525037910242323
Validation loss: 2.474975218575799

Epoch: 5| Step: 7
Training loss: 2.950988642661339
Validation loss: 2.4695511506200662

Epoch: 5| Step: 8
Training loss: 2.5429063077371135
Validation loss: 2.4828930840809926

Epoch: 5| Step: 9
Training loss: 2.7745736387417326
Validation loss: 2.4820604698402

Epoch: 5| Step: 10
Training loss: 2.869248317413887
Validation loss: 2.4845905185966535

Epoch: 166| Step: 0
Training loss: 2.656904611146575
Validation loss: 2.4810159234906037

Epoch: 5| Step: 1
Training loss: 3.2040375688900538
Validation loss: 2.4838530382405004

Epoch: 5| Step: 2
Training loss: 2.467450826168442
Validation loss: 2.486171008988905

Epoch: 5| Step: 3
Training loss: 2.697187396330042
Validation loss: 2.475854120907572

Epoch: 5| Step: 4
Training loss: 2.9252798875755968
Validation loss: 2.4742280125071026

Epoch: 5| Step: 5
Training loss: 2.3692982142430146
Validation loss: 2.4902023250955154

Epoch: 5| Step: 6
Training loss: 2.5687427307174553
Validation loss: 2.4814800655139058

Epoch: 5| Step: 7
Training loss: 2.9952854622907568
Validation loss: 2.4785167193369357

Epoch: 5| Step: 8
Training loss: 3.0028126565101685
Validation loss: 2.4671498288423943

Epoch: 5| Step: 9
Training loss: 2.5548194594526534
Validation loss: 2.4845941010597605

Epoch: 5| Step: 10
Training loss: 2.434012534661722
Validation loss: 2.478474391521638

Epoch: 167| Step: 0
Training loss: 2.1601196065212545
Validation loss: 2.4879676514469877

Epoch: 5| Step: 1
Training loss: 2.777740493100332
Validation loss: 2.4679397638697402

Epoch: 5| Step: 2
Training loss: 2.880312116982351
Validation loss: 2.473836059311984

Epoch: 5| Step: 3
Training loss: 2.6272667679864594
Validation loss: 2.4718030092364764

Epoch: 5| Step: 4
Training loss: 2.636319142895917
Validation loss: 2.4966905212900183

Epoch: 5| Step: 5
Training loss: 2.8792860176607293
Validation loss: 2.485417493055336

Epoch: 5| Step: 6
Training loss: 2.864833104197308
Validation loss: 2.4758885516864098

Epoch: 5| Step: 7
Training loss: 2.2903158772928114
Validation loss: 2.44551863409748

Epoch: 5| Step: 8
Training loss: 2.862765277414363
Validation loss: 2.4626412432723686

Epoch: 5| Step: 9
Training loss: 2.7744255777326146
Validation loss: 2.4434690609129928

Epoch: 5| Step: 10
Training loss: 3.2816724232832555
Validation loss: 2.440116493998652

Epoch: 168| Step: 0
Training loss: 2.632609192557088
Validation loss: 2.4438471542947466

Epoch: 5| Step: 1
Training loss: 2.8332829938418365
Validation loss: 2.4510611374732956

Epoch: 5| Step: 2
Training loss: 2.726774453393191
Validation loss: 2.449519722511335

Epoch: 5| Step: 3
Training loss: 2.794378093119671
Validation loss: 2.4826490418124973

Epoch: 5| Step: 4
Training loss: 2.345187750744634
Validation loss: 2.5021957865502453

Epoch: 5| Step: 5
Training loss: 2.82732013187626
Validation loss: 2.4937767670299715

Epoch: 5| Step: 6
Training loss: 2.5170831659859285
Validation loss: 2.482596385739321

Epoch: 5| Step: 7
Training loss: 2.541004647092687
Validation loss: 2.473804300604722

Epoch: 5| Step: 8
Training loss: 2.656000282666754
Validation loss: 2.4774182614711067

Epoch: 5| Step: 9
Training loss: 3.369305928915769
Validation loss: 2.46449465489955

Epoch: 5| Step: 10
Training loss: 2.641190507817258
Validation loss: 2.461437134385452

Epoch: 169| Step: 0
Training loss: 2.5540746484540127
Validation loss: 2.453496759160275

Epoch: 5| Step: 1
Training loss: 2.4436970697705007
Validation loss: 2.471178401752791

Epoch: 5| Step: 2
Training loss: 2.324225622856172
Validation loss: 2.457019154999014

Epoch: 5| Step: 3
Training loss: 2.5495656784285057
Validation loss: 2.4549092030975963

Epoch: 5| Step: 4
Training loss: 3.260220669023798
Validation loss: 2.4850985112718007

Epoch: 5| Step: 5
Training loss: 2.6603156894847095
Validation loss: 2.4686582856427717

Epoch: 5| Step: 6
Training loss: 3.288524592760769
Validation loss: 2.500981759527718

Epoch: 5| Step: 7
Training loss: 2.794657248839072
Validation loss: 2.5014783866696844

Epoch: 5| Step: 8
Training loss: 2.7355115000044314
Validation loss: 2.4810780412591744

Epoch: 5| Step: 9
Training loss: 2.4510646842224864
Validation loss: 2.4734118397616833

Epoch: 5| Step: 10
Training loss: 2.454501597979195
Validation loss: 2.4684219360446646

Epoch: 170| Step: 0
Training loss: 2.207207326701421
Validation loss: 2.4860103665670157

Epoch: 5| Step: 1
Training loss: 2.942865220110386
Validation loss: 2.473550186211028

Epoch: 5| Step: 2
Training loss: 2.7476062760351803
Validation loss: 2.4708385965571753

Epoch: 5| Step: 3
Training loss: 2.5510993046529817
Validation loss: 2.496279992354485

Epoch: 5| Step: 4
Training loss: 2.6531451760323557
Validation loss: 2.4859962902806836

Epoch: 5| Step: 5
Training loss: 2.872291616080724
Validation loss: 2.452395968627105

Epoch: 5| Step: 6
Training loss: 2.9029210210944276
Validation loss: 2.4373850872928258

Epoch: 5| Step: 7
Training loss: 2.4549775144708796
Validation loss: 2.4357531093195677

Epoch: 5| Step: 8
Training loss: 2.539246725588249
Validation loss: 2.439024094044597

Epoch: 5| Step: 9
Training loss: 2.75847498903592
Validation loss: 2.440860702235784

Epoch: 5| Step: 10
Training loss: 3.2041210579736825
Validation loss: 2.4558017283146127

Epoch: 171| Step: 0
Training loss: 2.648231790931405
Validation loss: 2.458054942522797

Epoch: 5| Step: 1
Training loss: 2.962342585634809
Validation loss: 2.464721754154587

Epoch: 5| Step: 2
Training loss: 2.9898994801443055
Validation loss: 2.497987629448307

Epoch: 5| Step: 3
Training loss: 2.9892000668221836
Validation loss: 2.5001302818478806

Epoch: 5| Step: 4
Training loss: 3.257975549071037
Validation loss: 2.5024961725460413

Epoch: 5| Step: 5
Training loss: 2.661215774222875
Validation loss: 2.499025312765855

Epoch: 5| Step: 6
Training loss: 2.025198152054319
Validation loss: 2.5221076594619203

Epoch: 5| Step: 7
Training loss: 1.9015715674855709
Validation loss: 2.5433214084006623

Epoch: 5| Step: 8
Training loss: 2.792643921643001
Validation loss: 2.4955753538694854

Epoch: 5| Step: 9
Training loss: 2.655701344991387
Validation loss: 2.474540862760782

Epoch: 5| Step: 10
Training loss: 2.506842404792982
Validation loss: 2.4567586994562602

Epoch: 172| Step: 0
Training loss: 2.455611214311429
Validation loss: 2.460240785960204

Epoch: 5| Step: 1
Training loss: 2.567972619703979
Validation loss: 2.4540034823619568

Epoch: 5| Step: 2
Training loss: 2.7582263149771755
Validation loss: 2.4730459323277376

Epoch: 5| Step: 3
Training loss: 2.338775339891504
Validation loss: 2.4763319351289983

Epoch: 5| Step: 4
Training loss: 2.769639544394104
Validation loss: 2.5184694632715106

Epoch: 5| Step: 5
Training loss: 3.0474782493259482
Validation loss: 2.5097117461680174

Epoch: 5| Step: 6
Training loss: 2.960930092029816
Validation loss: 2.540103125480789

Epoch: 5| Step: 7
Training loss: 2.659987748196717
Validation loss: 2.548315466642161

Epoch: 5| Step: 8
Training loss: 2.528258074262927
Validation loss: 2.5114727019359266

Epoch: 5| Step: 9
Training loss: 2.3951733772102957
Validation loss: 2.530989315090254

Epoch: 5| Step: 10
Training loss: 2.9958349561266866
Validation loss: 2.526579655321358

Epoch: 173| Step: 0
Training loss: 2.538619440009441
Validation loss: 2.5282725733335356

Epoch: 5| Step: 1
Training loss: 2.654859919615259
Validation loss: 2.5070534519186007

Epoch: 5| Step: 2
Training loss: 2.8373470113909782
Validation loss: 2.469543715737875

Epoch: 5| Step: 3
Training loss: 3.4462222327662366
Validation loss: 2.4503903560803355

Epoch: 5| Step: 4
Training loss: 2.620555748564691
Validation loss: 2.4569649792648485

Epoch: 5| Step: 5
Training loss: 2.8393178082868915
Validation loss: 2.4680348372004475

Epoch: 5| Step: 6
Training loss: 2.2397492339912857
Validation loss: 2.4807903804422087

Epoch: 5| Step: 7
Training loss: 2.148282354128312
Validation loss: 2.4941501368474737

Epoch: 5| Step: 8
Training loss: 2.137059827846237
Validation loss: 2.4907621384433662

Epoch: 5| Step: 9
Training loss: 2.8768168803660723
Validation loss: 2.4721933497374855

Epoch: 5| Step: 10
Training loss: 2.776378866379763
Validation loss: 2.4943057090961105

Epoch: 174| Step: 0
Training loss: 3.1889118732801123
Validation loss: 2.4848315288430483

Epoch: 5| Step: 1
Training loss: 2.880002852014613
Validation loss: 2.4827040294137905

Epoch: 5| Step: 2
Training loss: 2.4351547892287386
Validation loss: 2.469619445225606

Epoch: 5| Step: 3
Training loss: 2.943645298871596
Validation loss: 2.486469069636942

Epoch: 5| Step: 4
Training loss: 2.614241305367898
Validation loss: 2.478446741827005

Epoch: 5| Step: 5
Training loss: 2.9846718525668585
Validation loss: 2.456207688799103

Epoch: 5| Step: 6
Training loss: 2.187192513789472
Validation loss: 2.467290374889379

Epoch: 5| Step: 7
Training loss: 2.9188714731167433
Validation loss: 2.4528329420787176

Epoch: 5| Step: 8
Training loss: 2.049995431662331
Validation loss: 2.4420922979716986

Epoch: 5| Step: 9
Training loss: 2.8207773264100817
Validation loss: 2.458397976202856

Epoch: 5| Step: 10
Training loss: 2.149319443446415
Validation loss: 2.452314122763625

Epoch: 175| Step: 0
Training loss: 2.5623025585496912
Validation loss: 2.4538073777119487

Epoch: 5| Step: 1
Training loss: 2.2076691642392685
Validation loss: 2.4870935756604315

Epoch: 5| Step: 2
Training loss: 2.687494056162804
Validation loss: 2.5007238816709183

Epoch: 5| Step: 3
Training loss: 2.3593402379992967
Validation loss: 2.4855315290447457

Epoch: 5| Step: 4
Training loss: 2.585598188652688
Validation loss: 2.4748858827741422

Epoch: 5| Step: 5
Training loss: 2.3586602549418147
Validation loss: 2.4770763833623857

Epoch: 5| Step: 6
Training loss: 3.1972964966343262
Validation loss: 2.4956293088187205

Epoch: 5| Step: 7
Training loss: 2.6297893429650983
Validation loss: 2.483303865647578

Epoch: 5| Step: 8
Training loss: 2.8050615066611897
Validation loss: 2.5173952689922117

Epoch: 5| Step: 9
Training loss: 2.652265544744045
Validation loss: 2.5018816829323662

Epoch: 5| Step: 10
Training loss: 2.9777104124195715
Validation loss: 2.4655431852316414

Epoch: 176| Step: 0
Training loss: 1.7099073261111404
Validation loss: 2.452970055851429

Epoch: 5| Step: 1
Training loss: 2.858412450320111
Validation loss: 2.4445566828712497

Epoch: 5| Step: 2
Training loss: 2.5059977111927734
Validation loss: 2.447011242845822

Epoch: 5| Step: 3
Training loss: 2.4767104625124046
Validation loss: 2.4481461538921043

Epoch: 5| Step: 4
Training loss: 2.6993325150139116
Validation loss: 2.4870895958244854

Epoch: 5| Step: 5
Training loss: 2.8915944716119575
Validation loss: 2.500999027522932

Epoch: 5| Step: 6
Training loss: 2.3753418927305687
Validation loss: 2.5236957153413786

Epoch: 5| Step: 7
Training loss: 2.8947786747953295
Validation loss: 2.5205921460100207

Epoch: 5| Step: 8
Training loss: 2.9836830815009425
Validation loss: 2.4854750351644523

Epoch: 5| Step: 9
Training loss: 2.716662954160186
Validation loss: 2.4544315384552666

Epoch: 5| Step: 10
Training loss: 2.953678462727729
Validation loss: 2.442041627040846

Epoch: 177| Step: 0
Training loss: 2.788463624401982
Validation loss: 2.448305479723462

Epoch: 5| Step: 1
Training loss: 2.9892952987379218
Validation loss: 2.4359187215569453

Epoch: 5| Step: 2
Training loss: 2.5645114168629584
Validation loss: 2.4271369141955246

Epoch: 5| Step: 3
Training loss: 2.839345854253391
Validation loss: 2.4441122845589933

Epoch: 5| Step: 4
Training loss: 2.717051271310756
Validation loss: 2.4461035582653636

Epoch: 5| Step: 5
Training loss: 2.846448686757373
Validation loss: 2.4679984868290745

Epoch: 5| Step: 6
Training loss: 2.112397127073184
Validation loss: 2.5686413215338386

Epoch: 5| Step: 7
Training loss: 2.9563240606535546
Validation loss: 2.6301712147227607

Epoch: 5| Step: 8
Training loss: 2.632515004722965
Validation loss: 2.5878722814496844

Epoch: 5| Step: 9
Training loss: 2.4264677737894584
Validation loss: 2.5279714949679017

Epoch: 5| Step: 10
Training loss: 2.4357376574548426
Validation loss: 2.487302881730065

Epoch: 178| Step: 0
Training loss: 2.792235207430291
Validation loss: 2.4754313532538994

Epoch: 5| Step: 1
Training loss: 2.744978568405119
Validation loss: 2.4608015146234004

Epoch: 5| Step: 2
Training loss: 2.7896850062201364
Validation loss: 2.455800892141043

Epoch: 5| Step: 3
Training loss: 2.6016941896392414
Validation loss: 2.4707337344769185

Epoch: 5| Step: 4
Training loss: 3.0231682709283887
Validation loss: 2.499022562443843

Epoch: 5| Step: 5
Training loss: 2.419560957403846
Validation loss: 2.5117130546445927

Epoch: 5| Step: 6
Training loss: 2.815546716751293
Validation loss: 2.5269687420839477

Epoch: 5| Step: 7
Training loss: 2.4422743573793357
Validation loss: 2.5277094070177344

Epoch: 5| Step: 8
Training loss: 2.0465372986347865
Validation loss: 2.501132993429907

Epoch: 5| Step: 9
Training loss: 2.637804500123461
Validation loss: 2.4862785937934633

Epoch: 5| Step: 10
Training loss: 2.4682114412071465
Validation loss: 2.4723732703482093

Epoch: 179| Step: 0
Training loss: 3.2107520131092433
Validation loss: 2.4565374569867706

Epoch: 5| Step: 1
Training loss: 2.945232521812827
Validation loss: 2.4484178904860294

Epoch: 5| Step: 2
Training loss: 2.030614313277716
Validation loss: 2.4553701309480656

Epoch: 5| Step: 3
Training loss: 2.4287494185481844
Validation loss: 2.4783659993534948

Epoch: 5| Step: 4
Training loss: 2.7100302637528872
Validation loss: 2.473082964722149

Epoch: 5| Step: 5
Training loss: 2.473984203537983
Validation loss: 2.4725670828811652

Epoch: 5| Step: 6
Training loss: 2.1898692787906127
Validation loss: 2.4583272831339884

Epoch: 5| Step: 7
Training loss: 2.5291616042797154
Validation loss: 2.4509038861282018

Epoch: 5| Step: 8
Training loss: 3.1822467973525015
Validation loss: 2.450887422063918

Epoch: 5| Step: 9
Training loss: 2.3278134540786866
Validation loss: 2.472081595947043

Epoch: 5| Step: 10
Training loss: 2.588060320202816
Validation loss: 2.490782559897726

Epoch: 180| Step: 0
Training loss: 2.9394594515608827
Validation loss: 2.5197363161167496

Epoch: 5| Step: 1
Training loss: 2.559427792257343
Validation loss: 2.4571294372514956

Epoch: 5| Step: 2
Training loss: 3.253531957670765
Validation loss: 2.4410538587666104

Epoch: 5| Step: 3
Training loss: 2.6845704013107023
Validation loss: 2.4336561864815653

Epoch: 5| Step: 4
Training loss: 2.3488474028135804
Validation loss: 2.4279783734778895

Epoch: 5| Step: 5
Training loss: 2.383258014991606
Validation loss: 2.4293628036866686

Epoch: 5| Step: 6
Training loss: 2.9275982133530762
Validation loss: 2.4394654710351276

Epoch: 5| Step: 7
Training loss: 2.5307942674837505
Validation loss: 2.4494525436524435

Epoch: 5| Step: 8
Training loss: 2.635965332897338
Validation loss: 2.4409682066703167

Epoch: 5| Step: 9
Training loss: 2.129759675200206
Validation loss: 2.4606740846695154

Epoch: 5| Step: 10
Training loss: 2.1357372756573603
Validation loss: 2.4676883803828438

Epoch: 181| Step: 0
Training loss: 2.7346035235142683
Validation loss: 2.5290810475873595

Epoch: 5| Step: 1
Training loss: 2.573284436915967
Validation loss: 2.6191836511698643

Epoch: 5| Step: 2
Training loss: 3.145992721326087
Validation loss: 2.7449861762560213

Epoch: 5| Step: 3
Training loss: 2.930832783953243
Validation loss: 2.7159118321874787

Epoch: 5| Step: 4
Training loss: 2.249686961120295
Validation loss: 2.5427147321454218

Epoch: 5| Step: 5
Training loss: 2.6202917108410553
Validation loss: 2.468284310151817

Epoch: 5| Step: 6
Training loss: 2.503763132275153
Validation loss: 2.4519065211961246

Epoch: 5| Step: 7
Training loss: 2.4819506446302215
Validation loss: 2.46013870987199

Epoch: 5| Step: 8
Training loss: 2.968953818301578
Validation loss: 2.454351006595816

Epoch: 5| Step: 9
Training loss: 2.4725663830183846
Validation loss: 2.4488501394619973

Epoch: 5| Step: 10
Training loss: 2.593080365248954
Validation loss: 2.4390932749396943

Epoch: 182| Step: 0
Training loss: 2.7101005559473155
Validation loss: 2.4416835758987685

Epoch: 5| Step: 1
Training loss: 2.2444749388915564
Validation loss: 2.4717102890320133

Epoch: 5| Step: 2
Training loss: 2.4048162375053597
Validation loss: 2.5330298600098673

Epoch: 5| Step: 3
Training loss: 2.6079878175017983
Validation loss: 2.5755474103679505

Epoch: 5| Step: 4
Training loss: 2.8110374886677185
Validation loss: 2.6070713610314074

Epoch: 5| Step: 5
Training loss: 2.8135911308458996
Validation loss: 2.6299343346949193

Epoch: 5| Step: 6
Training loss: 2.194232824506294
Validation loss: 2.55527751464372

Epoch: 5| Step: 7
Training loss: 2.322623389736911
Validation loss: 2.496545575907705

Epoch: 5| Step: 8
Training loss: 2.9028738777602974
Validation loss: 2.4780743775207283

Epoch: 5| Step: 9
Training loss: 3.0010167624117607
Validation loss: 2.4593467007261687

Epoch: 5| Step: 10
Training loss: 2.8144766748993044
Validation loss: 2.451450509765784

Epoch: 183| Step: 0
Training loss: 2.4550398624081815
Validation loss: 2.4410559003910888

Epoch: 5| Step: 1
Training loss: 2.6799916798192016
Validation loss: 2.4388500121511476

Epoch: 5| Step: 2
Training loss: 2.8435439150407253
Validation loss: 2.448074078827817

Epoch: 5| Step: 3
Training loss: 2.308367568036468
Validation loss: 2.4646807231312797

Epoch: 5| Step: 4
Training loss: 2.2183556004683727
Validation loss: 2.497582261208304

Epoch: 5| Step: 5
Training loss: 2.6075552802658537
Validation loss: 2.5646830858051395

Epoch: 5| Step: 6
Training loss: 2.8294172338017893
Validation loss: 2.678534084534387

Epoch: 5| Step: 7
Training loss: 2.53062977668611
Validation loss: 2.6343499419047824

Epoch: 5| Step: 8
Training loss: 3.3038409796956345
Validation loss: 2.591922242039491

Epoch: 5| Step: 9
Training loss: 2.806467070818074
Validation loss: 2.524125949864338

Epoch: 5| Step: 10
Training loss: 2.2401954228441183
Validation loss: 2.4822584461990465

Epoch: 184| Step: 0
Training loss: 2.6775403554174333
Validation loss: 2.4546869813997594

Epoch: 5| Step: 1
Training loss: 2.6000270952133375
Validation loss: 2.4457890976783796

Epoch: 5| Step: 2
Training loss: 2.830494093880205
Validation loss: 2.442065775332716

Epoch: 5| Step: 3
Training loss: 2.728190026485999
Validation loss: 2.4639959724004745

Epoch: 5| Step: 4
Training loss: 2.928938055183741
Validation loss: 2.463071303211711

Epoch: 5| Step: 5
Training loss: 2.465755723163979
Validation loss: 2.483501059525273

Epoch: 5| Step: 6
Training loss: 2.3378222972601863
Validation loss: 2.4814836679641257

Epoch: 5| Step: 7
Training loss: 3.0068164315602286
Validation loss: 2.4887173461535395

Epoch: 5| Step: 8
Training loss: 2.537624292195329
Validation loss: 2.511754532459006

Epoch: 5| Step: 9
Training loss: 2.315571678052206
Validation loss: 2.5004839541532706

Epoch: 5| Step: 10
Training loss: 2.547763786397651
Validation loss: 2.5168207712902078

Epoch: 185| Step: 0
Training loss: 2.352983014001263
Validation loss: 2.5142106793924572

Epoch: 5| Step: 1
Training loss: 2.839602789435526
Validation loss: 2.5267543614883423

Epoch: 5| Step: 2
Training loss: 2.8891234750951202
Validation loss: 2.5007579474863015

Epoch: 5| Step: 3
Training loss: 2.378392055920865
Validation loss: 2.479417901059855

Epoch: 5| Step: 4
Training loss: 2.4608139733692878
Validation loss: 2.4595512427370196

Epoch: 5| Step: 5
Training loss: 2.4980382852056184
Validation loss: 2.446882315214184

Epoch: 5| Step: 6
Training loss: 2.3051046737437506
Validation loss: 2.422542254370671

Epoch: 5| Step: 7
Training loss: 2.692098985170005
Validation loss: 2.422038498519031

Epoch: 5| Step: 8
Training loss: 2.639932394896048
Validation loss: 2.421086362161115

Epoch: 5| Step: 9
Training loss: 2.2892186238553967
Validation loss: 2.439637682673024

Epoch: 5| Step: 10
Training loss: 2.892978514289912
Validation loss: 2.46186650286831

Epoch: 186| Step: 0
Training loss: 2.8656901677666196
Validation loss: 2.479890425248116

Epoch: 5| Step: 1
Training loss: 2.55245398081096
Validation loss: 2.5357256897525686

Epoch: 5| Step: 2
Training loss: 2.7144969252103266
Validation loss: 2.58365164875343

Epoch: 5| Step: 3
Training loss: 2.64394021578676
Validation loss: 2.6006487515013137

Epoch: 5| Step: 4
Training loss: 2.255988100020495
Validation loss: 2.593995317070614

Epoch: 5| Step: 5
Training loss: 2.596698601672841
Validation loss: 2.578940339740452

Epoch: 5| Step: 6
Training loss: 2.3193751024653775
Validation loss: 2.597139350362

Epoch: 5| Step: 7
Training loss: 2.86366608701971
Validation loss: 2.5757317953649497

Epoch: 5| Step: 8
Training loss: 2.480740173388041
Validation loss: 2.5724169424491237

Epoch: 5| Step: 9
Training loss: 2.9070789426537424
Validation loss: 2.5252035591161053

Epoch: 5| Step: 10
Training loss: 1.8651780045065063
Validation loss: 2.4723071091089803

Epoch: 187| Step: 0
Training loss: 3.287329282788167
Validation loss: 2.461849898642315

Epoch: 5| Step: 1
Training loss: 2.631208253651632
Validation loss: 2.4413900117067504

Epoch: 5| Step: 2
Training loss: 2.4640167831988773
Validation loss: 2.4397298417381204

Epoch: 5| Step: 3
Training loss: 2.3986211948689626
Validation loss: 2.449262913762063

Epoch: 5| Step: 4
Training loss: 2.7764428417244678
Validation loss: 2.4436092096022737

Epoch: 5| Step: 5
Training loss: 2.7301839044131264
Validation loss: 2.457789868001952

Epoch: 5| Step: 6
Training loss: 2.2118623234842887
Validation loss: 2.4977318380523084

Epoch: 5| Step: 7
Training loss: 2.0841246310142054
Validation loss: 2.5242493560153565

Epoch: 5| Step: 8
Training loss: 2.1025360008178473
Validation loss: 2.5228957418799824

Epoch: 5| Step: 9
Training loss: 2.166999228948677
Validation loss: 2.5259165367610112

Epoch: 5| Step: 10
Training loss: 2.882363881505969
Validation loss: 2.5080264890871784

Epoch: 188| Step: 0
Training loss: 2.6358661996981527
Validation loss: 2.5045399963422676

Epoch: 5| Step: 1
Training loss: 2.3805762631932526
Validation loss: 2.5155797317499085

Epoch: 5| Step: 2
Training loss: 2.4703836950747373
Validation loss: 2.5205863008518348

Epoch: 5| Step: 3
Training loss: 2.689237698173561
Validation loss: 2.507350023993191

Epoch: 5| Step: 4
Training loss: 2.9403623879192238
Validation loss: 2.4931932754205826

Epoch: 5| Step: 5
Training loss: 2.1889689281867146
Validation loss: 2.4860447164960258

Epoch: 5| Step: 6
Training loss: 1.9557503107776026
Validation loss: 2.4833974970640935

Epoch: 5| Step: 7
Training loss: 2.5282724080533194
Validation loss: 2.4774111006218016

Epoch: 5| Step: 8
Training loss: 2.72735566677789
Validation loss: 2.474853454896786

Epoch: 5| Step: 9
Training loss: 2.2826097172484077
Validation loss: 2.4639103999045147

Epoch: 5| Step: 10
Training loss: 2.6453192704593476
Validation loss: 2.4757077837198853

Epoch: 189| Step: 0
Training loss: 2.8331941308626023
Validation loss: 2.487838156781223

Epoch: 5| Step: 1
Training loss: 2.180049196265632
Validation loss: 2.508897254080629

Epoch: 5| Step: 2
Training loss: 2.2541988189529008
Validation loss: 2.5345339794854516

Epoch: 5| Step: 3
Training loss: 2.8145380900765837
Validation loss: 2.556873641661285

Epoch: 5| Step: 4
Training loss: 2.1199780756338527
Validation loss: 2.5362371954018044

Epoch: 5| Step: 5
Training loss: 2.4768634216207386
Validation loss: 2.5847550435318976

Epoch: 5| Step: 6
Training loss: 2.6079088306405778
Validation loss: 2.623352133197574

Epoch: 5| Step: 7
Training loss: 2.7582322792680976
Validation loss: 2.5600032523269785

Epoch: 5| Step: 8
Training loss: 2.614995875747375
Validation loss: 2.5025156387535916

Epoch: 5| Step: 9
Training loss: 2.3346170118676963
Validation loss: 2.457913314543391

Epoch: 5| Step: 10
Training loss: 2.3937902501957797
Validation loss: 2.445655882253318

Epoch: 190| Step: 0
Training loss: 2.384135494977298
Validation loss: 2.4465582400685277

Epoch: 5| Step: 1
Training loss: 2.821351934982205
Validation loss: 2.441863594386018

Epoch: 5| Step: 2
Training loss: 2.2509581327201067
Validation loss: 2.44301149868627

Epoch: 5| Step: 3
Training loss: 2.5502856300302463
Validation loss: 2.437556981045715

Epoch: 5| Step: 4
Training loss: 2.5247691511626558
Validation loss: 2.4453595229747096

Epoch: 5| Step: 5
Training loss: 1.9963838549353023
Validation loss: 2.473616920492268

Epoch: 5| Step: 6
Training loss: 2.3320964759382266
Validation loss: 2.5402900387707286

Epoch: 5| Step: 7
Training loss: 2.748794811763019
Validation loss: 2.5627850369750917

Epoch: 5| Step: 8
Training loss: 2.586117187895318
Validation loss: 2.604809593986081

Epoch: 5| Step: 9
Training loss: 2.7363494719735226
Validation loss: 2.61851220458642

Epoch: 5| Step: 10
Training loss: 2.5561477267597987
Validation loss: 2.6235360860273755

Epoch: 191| Step: 0
Training loss: 2.3716525530132686
Validation loss: 2.605276107892192

Epoch: 5| Step: 1
Training loss: 2.455176303693985
Validation loss: 2.5706008024829483

Epoch: 5| Step: 2
Training loss: 2.6899081242126694
Validation loss: 2.4976851821482042

Epoch: 5| Step: 3
Training loss: 2.619630863014763
Validation loss: 2.465425386987316

Epoch: 5| Step: 4
Training loss: 2.7024373850242687
Validation loss: 2.455836820206148

Epoch: 5| Step: 5
Training loss: 2.4564392638149073
Validation loss: 2.4654778295708075

Epoch: 5| Step: 6
Training loss: 2.561233765907651
Validation loss: 2.4849333638392106

Epoch: 5| Step: 7
Training loss: 2.6436751767655915
Validation loss: 2.479848215988831

Epoch: 5| Step: 8
Training loss: 2.060837856194695
Validation loss: 2.5023363752996226

Epoch: 5| Step: 9
Training loss: 2.3216380433533783
Validation loss: 2.5007855914057595

Epoch: 5| Step: 10
Training loss: 2.4530461778551373
Validation loss: 2.509915443054762

Epoch: 192| Step: 0
Training loss: 2.292371213866883
Validation loss: 2.5189290652284364

Epoch: 5| Step: 1
Training loss: 2.22540338695711
Validation loss: 2.5461167531019533

Epoch: 5| Step: 2
Training loss: 2.5902159180355366
Validation loss: 2.5440621051058225

Epoch: 5| Step: 3
Training loss: 2.4823969998077544
Validation loss: 2.5244203486778547

Epoch: 5| Step: 4
Training loss: 1.7321472982537889
Validation loss: 2.506828769666384

Epoch: 5| Step: 5
Training loss: 2.2919294611210526
Validation loss: 2.487378874445563

Epoch: 5| Step: 6
Training loss: 2.3797998613467306
Validation loss: 2.48270968599115

Epoch: 5| Step: 7
Training loss: 2.8044984376562607
Validation loss: 2.471440958895529

Epoch: 5| Step: 8
Training loss: 2.4789926056438065
Validation loss: 2.4722428074603005

Epoch: 5| Step: 9
Training loss: 2.8526191321460943
Validation loss: 2.4852461914893014

Epoch: 5| Step: 10
Training loss: 2.69822257135242
Validation loss: 2.491668171302055

Epoch: 193| Step: 0
Training loss: 2.1068072478955346
Validation loss: 2.4878049970913265

Epoch: 5| Step: 1
Training loss: 2.234689436975578
Validation loss: 2.5146324672524374

Epoch: 5| Step: 2
Training loss: 3.0377374815235156
Validation loss: 2.5415604725693157

Epoch: 5| Step: 3
Training loss: 2.368306716869603
Validation loss: 2.5550782448402614

Epoch: 5| Step: 4
Training loss: 2.524845450930893
Validation loss: 2.557345189994149

Epoch: 5| Step: 5
Training loss: 2.5483436328620757
Validation loss: 2.526679791472609

Epoch: 5| Step: 6
Training loss: 2.8403455875906722
Validation loss: 2.5119105136524524

Epoch: 5| Step: 7
Training loss: 2.045637732307957
Validation loss: 2.47824737168479

Epoch: 5| Step: 8
Training loss: 1.9139860799675876
Validation loss: 2.46083168782838

Epoch: 5| Step: 9
Training loss: 2.4929307170227353
Validation loss: 2.471945170972884

Epoch: 5| Step: 10
Training loss: 2.3680047868474055
Validation loss: 2.4556854421276557

Epoch: 194| Step: 0
Training loss: 2.6187119328684116
Validation loss: 2.461266230334361

Epoch: 5| Step: 1
Training loss: 2.4555037318476876
Validation loss: 2.465112756797127

Epoch: 5| Step: 2
Training loss: 2.455204950545296
Validation loss: 2.4946585413382176

Epoch: 5| Step: 3
Training loss: 2.286326156190422
Validation loss: 2.5211287352257177

Epoch: 5| Step: 4
Training loss: 1.5226581634149325
Validation loss: 2.5907735993267256

Epoch: 5| Step: 5
Training loss: 2.674246555354323
Validation loss: 2.6636079193416844

Epoch: 5| Step: 6
Training loss: 2.783109493353765
Validation loss: 2.7235310559244335

Epoch: 5| Step: 7
Training loss: 2.5087339425630355
Validation loss: 2.738925692234689

Epoch: 5| Step: 8
Training loss: 2.8415517170348132
Validation loss: 2.662753508101254

Epoch: 5| Step: 9
Training loss: 2.380104402127532
Validation loss: 2.5624214008241317

Epoch: 5| Step: 10
Training loss: 2.317683621964179
Validation loss: 2.467379329562689

Epoch: 195| Step: 0
Training loss: 2.784072900689082
Validation loss: 2.457794896625034

Epoch: 5| Step: 1
Training loss: 2.3548213644775378
Validation loss: 2.4716154058314426

Epoch: 5| Step: 2
Training loss: 2.1161285792767845
Validation loss: 2.481361066008786

Epoch: 5| Step: 3
Training loss: 2.5269880796271353
Validation loss: 2.4741012564772693

Epoch: 5| Step: 4
Training loss: 2.694020898920571
Validation loss: 2.4799236246052616

Epoch: 5| Step: 5
Training loss: 2.8901356875763704
Validation loss: 2.481905995504292

Epoch: 5| Step: 6
Training loss: 2.144910101440552
Validation loss: 2.516852780679032

Epoch: 5| Step: 7
Training loss: 2.595347176997083
Validation loss: 2.580109443998292

Epoch: 5| Step: 8
Training loss: 1.9880800876143487
Validation loss: 2.6878087666962593

Epoch: 5| Step: 9
Training loss: 2.9252973291284685
Validation loss: 2.7108547454219654

Epoch: 5| Step: 10
Training loss: 2.1855665108869924
Validation loss: 2.6508544469598725

Epoch: 196| Step: 0
Training loss: 2.9623261670324648
Validation loss: 2.5767797615411197

Epoch: 5| Step: 1
Training loss: 2.043295839576591
Validation loss: 2.512320625237715

Epoch: 5| Step: 2
Training loss: 2.421470362177655
Validation loss: 2.4753244528141436

Epoch: 5| Step: 3
Training loss: 1.8920616807379829
Validation loss: 2.4556620395350515

Epoch: 5| Step: 4
Training loss: 2.4240048795153664
Validation loss: 2.4534868389297677

Epoch: 5| Step: 5
Training loss: 2.55538231036693
Validation loss: 2.451036704405178

Epoch: 5| Step: 6
Training loss: 2.128784848172678
Validation loss: 2.4499313951370953

Epoch: 5| Step: 7
Training loss: 2.490521104050407
Validation loss: 2.4547220923604596

Epoch: 5| Step: 8
Training loss: 2.4751131166753035
Validation loss: 2.467654760846276

Epoch: 5| Step: 9
Training loss: 2.391532675770106
Validation loss: 2.474201535941753

Epoch: 5| Step: 10
Training loss: 2.7080646870717904
Validation loss: 2.497300411169878

Epoch: 197| Step: 0
Training loss: 2.6388954050976348
Validation loss: 2.5238417252108034

Epoch: 5| Step: 1
Training loss: 1.9315514461964478
Validation loss: 2.578313169949051

Epoch: 5| Step: 2
Training loss: 2.424210142513119
Validation loss: 2.5818820569150835

Epoch: 5| Step: 3
Training loss: 2.3154737580158535
Validation loss: 2.6600686783891145

Epoch: 5| Step: 4
Training loss: 2.554776904673637
Validation loss: 2.6660221321392856

Epoch: 5| Step: 5
Training loss: 2.5644547984690846
Validation loss: 2.607144490106177

Epoch: 5| Step: 6
Training loss: 2.504723378362952
Validation loss: 2.55370016675928

Epoch: 5| Step: 7
Training loss: 2.3352704068431547
Validation loss: 2.515804090005843

Epoch: 5| Step: 8
Training loss: 1.883739512312462
Validation loss: 2.4733149259944955

Epoch: 5| Step: 9
Training loss: 2.7538208860329085
Validation loss: 2.458257288840326

Epoch: 5| Step: 10
Training loss: 2.2801895812338033
Validation loss: 2.4331368330627012

Epoch: 198| Step: 0
Training loss: 2.5970660234650977
Validation loss: 2.4432538162039985

Epoch: 5| Step: 1
Training loss: 2.446538745678565
Validation loss: 2.4345489814685677

Epoch: 5| Step: 2
Training loss: 3.098421211603839
Validation loss: 2.446835942812446

Epoch: 5| Step: 3
Training loss: 2.4809295947084324
Validation loss: 2.447162143424119

Epoch: 5| Step: 4
Training loss: 1.749785410122004
Validation loss: 2.4717045554224013

Epoch: 5| Step: 5
Training loss: 2.6041814778224643
Validation loss: 2.5059814280172605

Epoch: 5| Step: 6
Training loss: 2.7291740436793983
Validation loss: 2.552545066653316

Epoch: 5| Step: 7
Training loss: 1.8988459897216217
Validation loss: 2.5773509514568196

Epoch: 5| Step: 8
Training loss: 1.97315933308835
Validation loss: 2.5923315588562827

Epoch: 5| Step: 9
Training loss: 2.2317988343116224
Validation loss: 2.6072666374102065

Epoch: 5| Step: 10
Training loss: 2.2136330499672314
Validation loss: 2.579793537912797

Epoch: 199| Step: 0
Training loss: 2.0406040488506805
Validation loss: 2.5640630519491134

Epoch: 5| Step: 1
Training loss: 2.5677286164035245
Validation loss: 2.569197386556377

Epoch: 5| Step: 2
Training loss: 2.155346667381328
Validation loss: 2.5879503919557294

Epoch: 5| Step: 3
Training loss: 2.334325329764089
Validation loss: 2.552395701843514

Epoch: 5| Step: 4
Training loss: 2.567102253683222
Validation loss: 2.5378506119440583

Epoch: 5| Step: 5
Training loss: 2.0680337132596427
Validation loss: 2.540666506134254

Epoch: 5| Step: 6
Training loss: 2.5227371991998706
Validation loss: 2.523945601723917

Epoch: 5| Step: 7
Training loss: 2.3311306797612756
Validation loss: 2.512660224991943

Epoch: 5| Step: 8
Training loss: 2.143251019563814
Validation loss: 2.501004365960106

Epoch: 5| Step: 9
Training loss: 2.699992222244928
Validation loss: 2.4974079173918042

Epoch: 5| Step: 10
Training loss: 2.5197859761012333
Validation loss: 2.469658304074377

Epoch: 200| Step: 0
Training loss: 1.9569531575533825
Validation loss: 2.4767955487801347

Epoch: 5| Step: 1
Training loss: 2.393625109728771
Validation loss: 2.464467591093789

Epoch: 5| Step: 2
Training loss: 2.5877852278065707
Validation loss: 2.4741392905996094

Epoch: 5| Step: 3
Training loss: 2.4012383127399732
Validation loss: 2.4855254436267624

Epoch: 5| Step: 4
Training loss: 2.4309181947992218
Validation loss: 2.4913627665812696

Epoch: 5| Step: 5
Training loss: 2.38332984186019
Validation loss: 2.5181622314583905

Epoch: 5| Step: 6
Training loss: 1.8041513810894143
Validation loss: 2.552376418186809

Epoch: 5| Step: 7
Training loss: 2.2012175831961223
Validation loss: 2.6013900639085574

Epoch: 5| Step: 8
Training loss: 2.6564189183996825
Validation loss: 2.6251973196658582

Epoch: 5| Step: 9
Training loss: 2.3416416094469934
Validation loss: 2.5698559295663737

Epoch: 5| Step: 10
Training loss: 2.6202262886982863
Validation loss: 2.511782728979709

Testing loss: 2.6724257468556294
