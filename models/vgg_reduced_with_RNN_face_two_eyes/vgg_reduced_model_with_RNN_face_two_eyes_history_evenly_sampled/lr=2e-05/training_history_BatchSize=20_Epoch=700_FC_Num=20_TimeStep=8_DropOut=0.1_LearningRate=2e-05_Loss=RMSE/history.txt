Epoch: 1| Step: 0
Training loss: 4.9158041677058675
Validation loss: 5.788490248859293

Epoch: 5| Step: 1
Training loss: 6.125005293863305
Validation loss: 5.76712109830086

Epoch: 5| Step: 2
Training loss: 6.432734531081108
Validation loss: 5.745375926050773

Epoch: 5| Step: 3
Training loss: 6.070127113683002
Validation loss: 5.7229900075328155

Epoch: 5| Step: 4
Training loss: 4.667512317512495
Validation loss: 5.698026129602175

Epoch: 5| Step: 5
Training loss: 5.881542053430336
Validation loss: 5.670183456151941

Epoch: 5| Step: 6
Training loss: 6.119241927325371
Validation loss: 5.638522393933437

Epoch: 5| Step: 7
Training loss: 5.545724668902296
Validation loss: 5.602551848339438

Epoch: 5| Step: 8
Training loss: 5.8592910150231035
Validation loss: 5.561342055023476

Epoch: 5| Step: 9
Training loss: 5.146239765296971
Validation loss: 5.517376437786591

Epoch: 5| Step: 10
Training loss: 5.580487603106715
Validation loss: 5.469371060734641

Epoch: 2| Step: 0
Training loss: 5.175553687509196
Validation loss: 5.41717174942335

Epoch: 5| Step: 1
Training loss: 5.25738986216942
Validation loss: 5.3647655149882985

Epoch: 5| Step: 2
Training loss: 5.152367997419726
Validation loss: 5.310910589758557

Epoch: 5| Step: 3
Training loss: 5.817139117592748
Validation loss: 5.25725764751045

Epoch: 5| Step: 4
Training loss: 4.498114720775779
Validation loss: 5.202372706874773

Epoch: 5| Step: 5
Training loss: 4.845110695974861
Validation loss: 5.146554701126665

Epoch: 5| Step: 6
Training loss: 4.964282444544124
Validation loss: 5.090275000697854

Epoch: 5| Step: 7
Training loss: 5.318085370971347
Validation loss: 5.034830547558738

Epoch: 5| Step: 8
Training loss: 5.877204643691432
Validation loss: 4.977923727200114

Epoch: 5| Step: 9
Training loss: 5.400920026605566
Validation loss: 4.921764177076413

Epoch: 5| Step: 10
Training loss: 4.667648802450499
Validation loss: 4.868326801238472

Epoch: 3| Step: 0
Training loss: 5.398476011191326
Validation loss: 4.820229932015017

Epoch: 5| Step: 1
Training loss: 5.289499915558129
Validation loss: 4.775273716086866

Epoch: 5| Step: 2
Training loss: 5.094522242135208
Validation loss: 4.7376558733666

Epoch: 5| Step: 3
Training loss: 4.081178888282657
Validation loss: 4.703788819768148

Epoch: 5| Step: 4
Training loss: 5.2444026718164265
Validation loss: 4.672258118343492

Epoch: 5| Step: 5
Training loss: 4.445111047239432
Validation loss: 4.640448847441261

Epoch: 5| Step: 6
Training loss: 4.2029532358461905
Validation loss: 4.607216651063961

Epoch: 5| Step: 7
Training loss: 5.03653169701474
Validation loss: 4.579444046500156

Epoch: 5| Step: 8
Training loss: 4.7170791194023
Validation loss: 4.549044154628194

Epoch: 5| Step: 9
Training loss: 4.032121667585431
Validation loss: 4.519501633379154

Epoch: 5| Step: 10
Training loss: 4.326482247613645
Validation loss: 4.492663787517257

Epoch: 4| Step: 0
Training loss: 4.228034759032142
Validation loss: 4.464882716234575

Epoch: 5| Step: 1
Training loss: 4.059769637238828
Validation loss: 4.4407913160813015

Epoch: 5| Step: 2
Training loss: 5.227428050994132
Validation loss: 4.417137265262611

Epoch: 5| Step: 3
Training loss: 4.798295298499921
Validation loss: 4.392591341866459

Epoch: 5| Step: 4
Training loss: 3.8045367263904306
Validation loss: 4.370058393900403

Epoch: 5| Step: 5
Training loss: 4.588790811738056
Validation loss: 4.353638712900814

Epoch: 5| Step: 6
Training loss: 4.331361957991136
Validation loss: 4.332867253388177

Epoch: 5| Step: 7
Training loss: 4.674416963664593
Validation loss: 4.318928176184096

Epoch: 5| Step: 8
Training loss: 4.809478802270294
Validation loss: 4.305815552689979

Epoch: 5| Step: 9
Training loss: 4.480945724734087
Validation loss: 4.29198941957452

Epoch: 5| Step: 10
Training loss: 4.01833290795211
Validation loss: 4.271328547370032

Epoch: 5| Step: 0
Training loss: 4.32727306808925
Validation loss: 4.2525908012771145

Epoch: 5| Step: 1
Training loss: 4.277258801596528
Validation loss: 4.231874658666111

Epoch: 5| Step: 2
Training loss: 4.059066965163983
Validation loss: 4.219199237125678

Epoch: 5| Step: 3
Training loss: 5.1380096554010235
Validation loss: 4.209209823994423

Epoch: 5| Step: 4
Training loss: 4.056728077415566
Validation loss: 4.186172546770166

Epoch: 5| Step: 5
Training loss: 4.512032634170689
Validation loss: 4.1739491463161755

Epoch: 5| Step: 6
Training loss: 3.928609468845639
Validation loss: 4.162138082979513

Epoch: 5| Step: 7
Training loss: 3.943350184950906
Validation loss: 4.151878334477742

Epoch: 5| Step: 8
Training loss: 3.834065464151393
Validation loss: 4.133679560597281

Epoch: 5| Step: 9
Training loss: 4.428267424560406
Validation loss: 4.114696944217994

Epoch: 5| Step: 10
Training loss: 4.823926958533838
Validation loss: 4.103379298922726

Epoch: 6| Step: 0
Training loss: 3.9781975223376476
Validation loss: 4.090007557704897

Epoch: 5| Step: 1
Training loss: 4.128146272152564
Validation loss: 4.071880099884308

Epoch: 5| Step: 2
Training loss: 3.870363230059005
Validation loss: 4.051239105827678

Epoch: 5| Step: 3
Training loss: 3.8036101458886056
Validation loss: 4.034775478479468

Epoch: 5| Step: 4
Training loss: 4.271581271048905
Validation loss: 4.027695346753034

Epoch: 5| Step: 5
Training loss: 4.1056346043151954
Validation loss: 4.0049114735221725

Epoch: 5| Step: 6
Training loss: 4.697515951294992
Validation loss: 3.994187343731456

Epoch: 5| Step: 7
Training loss: 4.228926077076881
Validation loss: 3.976114976506973

Epoch: 5| Step: 8
Training loss: 4.433809491928783
Validation loss: 3.9606187260174743

Epoch: 5| Step: 9
Training loss: 4.598159438400028
Validation loss: 3.9492999060663982

Epoch: 5| Step: 10
Training loss: 3.3429664335445644
Validation loss: 3.9416462647432686

Epoch: 7| Step: 0
Training loss: 3.919631620341964
Validation loss: 3.9233073650434704

Epoch: 5| Step: 1
Training loss: 4.653726393122077
Validation loss: 3.911414462894465

Epoch: 5| Step: 2
Training loss: 3.935604789818905
Validation loss: 3.903994085126693

Epoch: 5| Step: 3
Training loss: 4.680587758382062
Validation loss: 3.889744420050974

Epoch: 5| Step: 4
Training loss: 4.392436566749703
Validation loss: 3.8743748062927477

Epoch: 5| Step: 5
Training loss: 3.8940799187608217
Validation loss: 3.8765621615638755

Epoch: 5| Step: 6
Training loss: 3.605791699461746
Validation loss: 3.858234533437939

Epoch: 5| Step: 7
Training loss: 3.5525408288916798
Validation loss: 3.833964724303309

Epoch: 5| Step: 8
Training loss: 3.7698320496079103
Validation loss: 3.8236367778331983

Epoch: 5| Step: 9
Training loss: 4.0641391675054095
Validation loss: 3.8202538761664013

Epoch: 5| Step: 10
Training loss: 3.6830107954759357
Validation loss: 3.8111121470589673

Epoch: 8| Step: 0
Training loss: 4.548559761566404
Validation loss: 3.8111114017347703

Epoch: 5| Step: 1
Training loss: 3.2570578892698814
Validation loss: 3.7938834377652273

Epoch: 5| Step: 2
Training loss: 3.7929731500602055
Validation loss: 3.7838396807884096

Epoch: 5| Step: 3
Training loss: 3.7717400122936513
Validation loss: 3.7773125736258044

Epoch: 5| Step: 4
Training loss: 4.750177681259938
Validation loss: 3.7712454159639868

Epoch: 5| Step: 5
Training loss: 4.072950566273499
Validation loss: 3.762635566117827

Epoch: 5| Step: 6
Training loss: 2.6440575314840187
Validation loss: 3.7584470439524003

Epoch: 5| Step: 7
Training loss: 4.513831604162081
Validation loss: 3.7605493421171987

Epoch: 5| Step: 8
Training loss: 4.290192335392226
Validation loss: 3.7488036103312186

Epoch: 5| Step: 9
Training loss: 3.888003281768544
Validation loss: 3.736068862481185

Epoch: 5| Step: 10
Training loss: 3.2525017719425238
Validation loss: 3.7362525213175686

Epoch: 9| Step: 0
Training loss: 3.2961840154056214
Validation loss: 3.7298063269364867

Epoch: 5| Step: 1
Training loss: 3.8837518611101762
Validation loss: 3.7173695575640604

Epoch: 5| Step: 2
Training loss: 3.08332656309742
Validation loss: 3.7138022625170146

Epoch: 5| Step: 3
Training loss: 3.936418051646896
Validation loss: 3.7094321278161293

Epoch: 5| Step: 4
Training loss: 3.9337770330314186
Validation loss: 3.7085389959019723

Epoch: 5| Step: 5
Training loss: 3.622896439135904
Validation loss: 3.699054188916546

Epoch: 5| Step: 6
Training loss: 4.283866806552718
Validation loss: 3.6927786660612116

Epoch: 5| Step: 7
Training loss: 4.142800964951741
Validation loss: 3.687476957404555

Epoch: 5| Step: 8
Training loss: 3.8859517783227453
Validation loss: 3.6823581799144227

Epoch: 5| Step: 9
Training loss: 4.012892450172368
Validation loss: 3.674500416326296

Epoch: 5| Step: 10
Training loss: 4.532763839928621
Validation loss: 3.6680815536079807

Epoch: 10| Step: 0
Training loss: 3.320012911576132
Validation loss: 3.66399640632132

Epoch: 5| Step: 1
Training loss: 4.076568423376901
Validation loss: 3.658790090986113

Epoch: 5| Step: 2
Training loss: 3.631452802290184
Validation loss: 3.65487285404703

Epoch: 5| Step: 3
Training loss: 3.977322908555565
Validation loss: 3.650859883299813

Epoch: 5| Step: 4
Training loss: 3.7349561933325646
Validation loss: 3.643782295333417

Epoch: 5| Step: 5
Training loss: 4.121125453447366
Validation loss: 3.640181657616317

Epoch: 5| Step: 6
Training loss: 3.942795598396816
Validation loss: 3.6347935481602196

Epoch: 5| Step: 7
Training loss: 4.033040676586219
Validation loss: 3.6336444644377375

Epoch: 5| Step: 8
Training loss: 4.094279247754573
Validation loss: 3.626837579011839

Epoch: 5| Step: 9
Training loss: 3.1793211179906424
Validation loss: 3.6221059364704917

Epoch: 5| Step: 10
Training loss: 3.946037241021901
Validation loss: 3.6167165635305074

Epoch: 11| Step: 0
Training loss: 3.261225022278447
Validation loss: 3.6110046824339377

Epoch: 5| Step: 1
Training loss: 4.168495666889667
Validation loss: 3.608056454618308

Epoch: 5| Step: 2
Training loss: 4.286824405036233
Validation loss: 3.60005953538995

Epoch: 5| Step: 3
Training loss: 3.584580241465843
Validation loss: 3.6000728717729795

Epoch: 5| Step: 4
Training loss: 3.424724629045383
Validation loss: 3.590040662193994

Epoch: 5| Step: 5
Training loss: 3.958335126909887
Validation loss: 3.590964244785865

Epoch: 5| Step: 6
Training loss: 4.205218733134563
Validation loss: 3.5834008062887444

Epoch: 5| Step: 7
Training loss: 2.924133081019517
Validation loss: 3.574889358700413

Epoch: 5| Step: 8
Training loss: 4.157673756815851
Validation loss: 3.572152532866539

Epoch: 5| Step: 9
Training loss: 3.8368808806070294
Validation loss: 3.5808191534315337

Epoch: 5| Step: 10
Training loss: 3.5755975450629585
Validation loss: 3.562255449434238

Epoch: 12| Step: 0
Training loss: 3.9816527397984167
Validation loss: 3.5626237218472743

Epoch: 5| Step: 1
Training loss: 4.0764245474514125
Validation loss: 3.5642766374180312

Epoch: 5| Step: 2
Training loss: 3.6058895572245926
Validation loss: 3.556228079202844

Epoch: 5| Step: 3
Training loss: 3.820082207039854
Validation loss: 3.5538985840856383

Epoch: 5| Step: 4
Training loss: 3.4267134230079486
Validation loss: 3.550275243857294

Epoch: 5| Step: 5
Training loss: 3.064958792031401
Validation loss: 3.548721091081797

Epoch: 5| Step: 6
Training loss: 4.013144116382134
Validation loss: 3.5434676125749043

Epoch: 5| Step: 7
Training loss: 4.174915363116307
Validation loss: 3.5416959458551776

Epoch: 5| Step: 8
Training loss: 4.055192214041433
Validation loss: 3.5391664026825866

Epoch: 5| Step: 9
Training loss: 3.6848583781177626
Validation loss: 3.5366109681910185

Epoch: 5| Step: 10
Training loss: 3.1188724715471157
Validation loss: 3.535429158313983

Epoch: 13| Step: 0
Training loss: 3.5618973607092523
Validation loss: 3.5315721230430355

Epoch: 5| Step: 1
Training loss: 4.194198034148865
Validation loss: 3.5274186537078944

Epoch: 5| Step: 2
Training loss: 3.6338117640298
Validation loss: 3.5253741285801508

Epoch: 5| Step: 3
Training loss: 3.992514281513084
Validation loss: 3.521865572297441

Epoch: 5| Step: 4
Training loss: 3.749107127387068
Validation loss: 3.5208904428953955

Epoch: 5| Step: 5
Training loss: 2.4148842607331757
Validation loss: 3.5162342516210323

Epoch: 5| Step: 6
Training loss: 4.13528132117086
Validation loss: 3.51686093717615

Epoch: 5| Step: 7
Training loss: 4.103870723272125
Validation loss: 3.5125517463747995

Epoch: 5| Step: 8
Training loss: 3.4782499525686688
Validation loss: 3.5114798282226487

Epoch: 5| Step: 9
Training loss: 3.379321969097528
Validation loss: 3.5084895029185397

Epoch: 5| Step: 10
Training loss: 4.090169724204943
Validation loss: 3.5071991583112925

Epoch: 14| Step: 0
Training loss: 4.210377162249086
Validation loss: 3.506405500496379

Epoch: 5| Step: 1
Training loss: 3.236529383735335
Validation loss: 3.504040523161375

Epoch: 5| Step: 2
Training loss: 3.825376933355846
Validation loss: 3.50175609569329

Epoch: 5| Step: 3
Training loss: 3.6019625824250907
Validation loss: 3.4989559136880217

Epoch: 5| Step: 4
Training loss: 4.286175866474638
Validation loss: 3.496499348661144

Epoch: 5| Step: 5
Training loss: 4.708949946084219
Validation loss: 3.4954477039232756

Epoch: 5| Step: 6
Training loss: 3.1823014895489936
Validation loss: 3.493513335494871

Epoch: 5| Step: 7
Training loss: 3.5846790773407338
Validation loss: 3.4924013947231023

Epoch: 5| Step: 8
Training loss: 3.6982864123395465
Validation loss: 3.4895697519806097

Epoch: 5| Step: 9
Training loss: 3.5226888939788887
Validation loss: 3.4862964140027572

Epoch: 5| Step: 10
Training loss: 2.1891514674969486
Validation loss: 3.4859923020400587

Epoch: 15| Step: 0
Training loss: 3.609957561296303
Validation loss: 3.4841208350302475

Epoch: 5| Step: 1
Training loss: 3.781762458817565
Validation loss: 3.484406234061912

Epoch: 5| Step: 2
Training loss: 3.9480227386530937
Validation loss: 3.4816593016669257

Epoch: 5| Step: 3
Training loss: 3.42394705966772
Validation loss: 3.4826660696373946

Epoch: 5| Step: 4
Training loss: 4.51879243738447
Validation loss: 3.475793411782028

Epoch: 5| Step: 5
Training loss: 3.7631544184045667
Validation loss: 3.4760745074852815

Epoch: 5| Step: 6
Training loss: 3.873871300500862
Validation loss: 3.4763394848244773

Epoch: 5| Step: 7
Training loss: 4.148002989691574
Validation loss: 3.4762498712029872

Epoch: 5| Step: 8
Training loss: 2.7928483843709624
Validation loss: 3.4745933111185914

Epoch: 5| Step: 9
Training loss: 3.4496453476106774
Validation loss: 3.4722501579446123

Epoch: 5| Step: 10
Training loss: 2.879755482360194
Validation loss: 3.4708529483922557

Epoch: 16| Step: 0
Training loss: 4.263542812908636
Validation loss: 3.469144988433818

Epoch: 5| Step: 1
Training loss: 3.489973693573626
Validation loss: 3.466834529318076

Epoch: 5| Step: 2
Training loss: 2.7960843295258146
Validation loss: 3.464171931899057

Epoch: 5| Step: 3
Training loss: 3.57750246720992
Validation loss: 3.4629639023916576

Epoch: 5| Step: 4
Training loss: 3.556171752927004
Validation loss: 3.46250642893098

Epoch: 5| Step: 5
Training loss: 3.877152122175658
Validation loss: 3.4608029738211314

Epoch: 5| Step: 6
Training loss: 4.170359132519579
Validation loss: 3.4587772651298985

Epoch: 5| Step: 7
Training loss: 3.720680440998765
Validation loss: 3.4581591451943687

Epoch: 5| Step: 8
Training loss: 3.8858502975269182
Validation loss: 3.456890315649991

Epoch: 5| Step: 9
Training loss: 3.2470081937197213
Validation loss: 3.456196280479947

Epoch: 5| Step: 10
Training loss: 3.69262094040058
Validation loss: 3.45485857888939

Epoch: 17| Step: 0
Training loss: 4.728240719303811
Validation loss: 3.4539923517060895

Epoch: 5| Step: 1
Training loss: 3.1155466144461887
Validation loss: 3.452505813162112

Epoch: 5| Step: 2
Training loss: 3.7456646336355925
Validation loss: 3.4503039435561025

Epoch: 5| Step: 3
Training loss: 2.7784757171772445
Validation loss: 3.448423853857238

Epoch: 5| Step: 4
Training loss: 2.8183408486754655
Validation loss: 3.4470825380950276

Epoch: 5| Step: 5
Training loss: 3.9955550769479835
Validation loss: 3.4444765831961552

Epoch: 5| Step: 6
Training loss: 3.4580974421807
Validation loss: 3.4435822330867336

Epoch: 5| Step: 7
Training loss: 3.672171333205334
Validation loss: 3.4411328745268315

Epoch: 5| Step: 8
Training loss: 3.873759040243427
Validation loss: 3.4399447416463764

Epoch: 5| Step: 9
Training loss: 4.001775347594763
Validation loss: 3.486953819195212

Epoch: 5| Step: 10
Training loss: 3.777935372288025
Validation loss: 3.432108969630198

Epoch: 18| Step: 0
Training loss: 4.002440661646341
Validation loss: 3.432365053071316

Epoch: 5| Step: 1
Training loss: 3.8004379823149166
Validation loss: 3.4292550854436814

Epoch: 5| Step: 2
Training loss: 3.7417301543583643
Validation loss: 3.442906989971003

Epoch: 5| Step: 3
Training loss: 3.737655411873234
Validation loss: 3.429469855304371

Epoch: 5| Step: 4
Training loss: 3.709244448285423
Validation loss: 3.426648032484609

Epoch: 5| Step: 5
Training loss: 3.119560695922885
Validation loss: 3.446722214037107

Epoch: 5| Step: 6
Training loss: 2.9811135890629856
Validation loss: 3.4472455531895516

Epoch: 5| Step: 7
Training loss: 3.573222704237673
Validation loss: 3.4397352794836955

Epoch: 5| Step: 8
Training loss: 3.7384473231625885
Validation loss: 3.4316674219291095

Epoch: 5| Step: 9
Training loss: 3.903657342725417
Validation loss: 3.432566226747878

Epoch: 5| Step: 10
Training loss: 3.8235214267837208
Validation loss: 3.4289040385539264

Epoch: 19| Step: 0
Training loss: 3.6473390939321075
Validation loss: 3.421678882941878

Epoch: 5| Step: 1
Training loss: 3.4404025221571577
Validation loss: 3.4085162720961213

Epoch: 5| Step: 2
Training loss: 3.5374477315215658
Validation loss: 3.409084607115707

Epoch: 5| Step: 3
Training loss: 4.083768600827846
Validation loss: 3.412641492781016

Epoch: 5| Step: 4
Training loss: 3.9438112329725925
Validation loss: 3.4034479520273537

Epoch: 5| Step: 5
Training loss: 3.307726893986291
Validation loss: 3.4024486239964076

Epoch: 5| Step: 6
Training loss: 3.316050516017552
Validation loss: 3.402488742987051

Epoch: 5| Step: 7
Training loss: 3.0302893305960117
Validation loss: 3.4047238981394092

Epoch: 5| Step: 8
Training loss: 4.0777569016405275
Validation loss: 3.4057099357411693

Epoch: 5| Step: 9
Training loss: 3.849474482154327
Validation loss: 3.4020259270719233

Epoch: 5| Step: 10
Training loss: 3.5822792424974392
Validation loss: 3.4024060316163562

Epoch: 20| Step: 0
Training loss: 2.556506055025316
Validation loss: 3.401223358716743

Epoch: 5| Step: 1
Training loss: 3.8563538127756227
Validation loss: 3.397085073238413

Epoch: 5| Step: 2
Training loss: 3.4633502343224047
Validation loss: 3.3975702375057746

Epoch: 5| Step: 3
Training loss: 3.6624825330714836
Validation loss: 3.393551366566411

Epoch: 5| Step: 4
Training loss: 3.503043077992963
Validation loss: 3.3945176679758475

Epoch: 5| Step: 5
Training loss: 4.069580246558447
Validation loss: 3.3915015431066315

Epoch: 5| Step: 6
Training loss: 3.381154277243349
Validation loss: 3.391706544919264

Epoch: 5| Step: 7
Training loss: 3.1026223627470153
Validation loss: 3.3896449418120707

Epoch: 5| Step: 8
Training loss: 4.01521483230177
Validation loss: 3.387434691928847

Epoch: 5| Step: 9
Training loss: 4.369316551135136
Validation loss: 3.387226229321348

Epoch: 5| Step: 10
Training loss: 3.501844737412184
Validation loss: 3.3839848269422035

Epoch: 21| Step: 0
Training loss: 2.8339160619135635
Validation loss: 3.3818925581779204

Epoch: 5| Step: 1
Training loss: 3.7278656350508617
Validation loss: 3.37970308876513

Epoch: 5| Step: 2
Training loss: 4.468133630460087
Validation loss: 3.3769309802915117

Epoch: 5| Step: 3
Training loss: 3.082551049322572
Validation loss: 3.371842134877348

Epoch: 5| Step: 4
Training loss: 4.169109442226213
Validation loss: 3.3675170612296594

Epoch: 5| Step: 5
Training loss: 3.9043081110706255
Validation loss: 3.3607901589411346

Epoch: 5| Step: 6
Training loss: 2.7695012057333264
Validation loss: 3.3579028342487622

Epoch: 5| Step: 7
Training loss: 3.6900870090140474
Validation loss: 3.3514699355424753

Epoch: 5| Step: 8
Training loss: 3.6580019934780723
Validation loss: 3.345279868426189

Epoch: 5| Step: 9
Training loss: 3.2701782898900875
Validation loss: 3.344020468769662

Epoch: 5| Step: 10
Training loss: 3.6043106814738413
Validation loss: 3.345777162194203

Epoch: 22| Step: 0
Training loss: 4.142927803414121
Validation loss: 3.3456310554695214

Epoch: 5| Step: 1
Training loss: 3.117911577381584
Validation loss: 3.3441026463520878

Epoch: 5| Step: 2
Training loss: 3.773956705391884
Validation loss: 3.3386287824062517

Epoch: 5| Step: 3
Training loss: 3.212628812470988
Validation loss: 3.3383532814862265

Epoch: 5| Step: 4
Training loss: 4.400678859706708
Validation loss: 3.3363643053420686

Epoch: 5| Step: 5
Training loss: 3.8387868208564857
Validation loss: 3.3352098210455905

Epoch: 5| Step: 6
Training loss: 2.711315733278528
Validation loss: 3.331832277559199

Epoch: 5| Step: 7
Training loss: 2.942493172040486
Validation loss: 3.3314590619679985

Epoch: 5| Step: 8
Training loss: 3.2952121681361013
Validation loss: 3.333751648116883

Epoch: 5| Step: 9
Training loss: 3.8535614088290084
Validation loss: 3.3324666485997945

Epoch: 5| Step: 10
Training loss: 3.6647417622307157
Validation loss: 3.3281940640028425

Epoch: 23| Step: 0
Training loss: 4.047475173808083
Validation loss: 3.321986157088826

Epoch: 5| Step: 1
Training loss: 3.897019367251139
Validation loss: 3.3221252087251987

Epoch: 5| Step: 2
Training loss: 3.3153698563268508
Validation loss: 3.3148045385559963

Epoch: 5| Step: 3
Training loss: 3.976305400578768
Validation loss: 3.310020884288204

Epoch: 5| Step: 4
Training loss: 3.249144808420207
Validation loss: 3.308885806422058

Epoch: 5| Step: 5
Training loss: 4.215348292177675
Validation loss: 3.303781486488046

Epoch: 5| Step: 6
Training loss: 3.308253030899402
Validation loss: 3.300821612099729

Epoch: 5| Step: 7
Training loss: 3.463259501424423
Validation loss: 3.299404940086826

Epoch: 5| Step: 8
Training loss: 3.0611183007954534
Validation loss: 3.2981367474268364

Epoch: 5| Step: 9
Training loss: 3.4286291622795955
Validation loss: 3.299199761955323

Epoch: 5| Step: 10
Training loss: 2.649803327063943
Validation loss: 3.2942374971625803

Epoch: 24| Step: 0
Training loss: 3.748615899557402
Validation loss: 3.2913108161884623

Epoch: 5| Step: 1
Training loss: 3.6173857599554027
Validation loss: 3.293153344273907

Epoch: 5| Step: 2
Training loss: 3.812534394656265
Validation loss: 3.2896648678966116

Epoch: 5| Step: 3
Training loss: 2.720792419764686
Validation loss: 3.2908628506974273

Epoch: 5| Step: 4
Training loss: 3.6253329157050977
Validation loss: 3.287515226188743

Epoch: 5| Step: 5
Training loss: 3.5921875584068474
Validation loss: 3.285964958168997

Epoch: 5| Step: 6
Training loss: 3.2198411888149026
Validation loss: 3.2911933993805054

Epoch: 5| Step: 7
Training loss: 3.8013209305793616
Validation loss: 3.295509645465138

Epoch: 5| Step: 8
Training loss: 3.713768066239045
Validation loss: 3.299543013367205

Epoch: 5| Step: 9
Training loss: 3.7152959345832413
Validation loss: 3.297402230925011

Epoch: 5| Step: 10
Training loss: 2.9968219454049883
Validation loss: 3.2908093605656474

Epoch: 25| Step: 0
Training loss: 4.064276204252502
Validation loss: 3.3152741378136246

Epoch: 5| Step: 1
Training loss: 3.728246664154846
Validation loss: 3.2862518556669857

Epoch: 5| Step: 2
Training loss: 3.2682960209588168
Validation loss: 3.34457186486152

Epoch: 5| Step: 3
Training loss: 3.8711453616245977
Validation loss: 3.38351924508105

Epoch: 5| Step: 4
Training loss: 3.1594641909664087
Validation loss: 3.3313866581242815

Epoch: 5| Step: 5
Training loss: 2.8295109340404556
Validation loss: 3.4177881171667615

Epoch: 5| Step: 6
Training loss: 3.96004113281928
Validation loss: 3.5853732246397025

Epoch: 5| Step: 7
Training loss: 3.3544060441995978
Validation loss: 3.4437295737739353

Epoch: 5| Step: 8
Training loss: 4.004103701305158
Validation loss: 3.355720529005309

Epoch: 5| Step: 9
Training loss: 4.234979002268866
Validation loss: 3.3301828698658293

Epoch: 5| Step: 10
Training loss: 2.710661332632591
Validation loss: 3.4377469299464445

Epoch: 26| Step: 0
Training loss: 3.8670471782464952
Validation loss: 3.5202047057818038

Epoch: 5| Step: 1
Training loss: 3.610659284120203
Validation loss: 3.530376747787036

Epoch: 5| Step: 2
Training loss: 3.653174647507013
Validation loss: 3.465013436172408

Epoch: 5| Step: 3
Training loss: 3.864964071405373
Validation loss: 3.418485706993692

Epoch: 5| Step: 4
Training loss: 3.1826544938266856
Validation loss: 3.3750526351196943

Epoch: 5| Step: 5
Training loss: 3.687571767334923
Validation loss: 3.3756918287341167

Epoch: 5| Step: 6
Training loss: 3.9916982332280893
Validation loss: 3.3928562166772642

Epoch: 5| Step: 7
Training loss: 3.5759313263923596
Validation loss: 3.3637756355507995

Epoch: 5| Step: 8
Training loss: 2.841543494395606
Validation loss: 3.358488372918273

Epoch: 5| Step: 9
Training loss: 4.293207108160468
Validation loss: 3.343520854235879

Epoch: 5| Step: 10
Training loss: 3.1263423325525403
Validation loss: 3.3299095964969263

Epoch: 27| Step: 0
Training loss: 3.142236400586049
Validation loss: 3.3183916339707618

Epoch: 5| Step: 1
Training loss: 3.8320049942159264
Validation loss: 3.3069582860828555

Epoch: 5| Step: 2
Training loss: 4.073462148108205
Validation loss: 3.2951075066516364

Epoch: 5| Step: 3
Training loss: 3.2753348667082434
Validation loss: 3.2955895725947473

Epoch: 5| Step: 4
Training loss: 3.342846472051262
Validation loss: 3.280817467249102

Epoch: 5| Step: 5
Training loss: 3.5415488429198754
Validation loss: 3.271578459668614

Epoch: 5| Step: 6
Training loss: 3.573269010173651
Validation loss: 3.2647724847366577

Epoch: 5| Step: 7
Training loss: 3.374220440160421
Validation loss: 3.2621236232403703

Epoch: 5| Step: 8
Training loss: 4.082041996845901
Validation loss: 3.257545929093414

Epoch: 5| Step: 9
Training loss: 3.6714108437517807
Validation loss: 3.257047427077555

Epoch: 5| Step: 10
Training loss: 2.3634648527595017
Validation loss: 3.2508416470408625

Epoch: 28| Step: 0
Training loss: 3.163088500259459
Validation loss: 3.2465404100874062

Epoch: 5| Step: 1
Training loss: 2.7120838215176435
Validation loss: 3.2428575760552683

Epoch: 5| Step: 2
Training loss: 2.9510629710837684
Validation loss: 3.241592182172887

Epoch: 5| Step: 3
Training loss: 2.950952447273479
Validation loss: 3.239865308210585

Epoch: 5| Step: 4
Training loss: 3.1508195446741447
Validation loss: 3.2416647821674984

Epoch: 5| Step: 5
Training loss: 3.6072464648829645
Validation loss: 3.237008517781043

Epoch: 5| Step: 6
Training loss: 3.2979280498514623
Validation loss: 3.236252339615503

Epoch: 5| Step: 7
Training loss: 3.8810252445523385
Validation loss: 3.2354733321884073

Epoch: 5| Step: 8
Training loss: 3.742791941333806
Validation loss: 3.234576786058606

Epoch: 5| Step: 9
Training loss: 4.28263131015509
Validation loss: 3.23205087146906

Epoch: 5| Step: 10
Training loss: 4.367048612784815
Validation loss: 3.230230303252454

Epoch: 29| Step: 0
Training loss: 3.4380412282552135
Validation loss: 3.2295448928546455

Epoch: 5| Step: 1
Training loss: 3.298381298603757
Validation loss: 3.228310939577253

Epoch: 5| Step: 2
Training loss: 3.6644578407288972
Validation loss: 3.227658502654397

Epoch: 5| Step: 3
Training loss: 3.033612932866129
Validation loss: 3.2249856059325603

Epoch: 5| Step: 4
Training loss: 4.150200363286081
Validation loss: 3.223750678082658

Epoch: 5| Step: 5
Training loss: 3.467375611904947
Validation loss: 3.222760152474893

Epoch: 5| Step: 6
Training loss: 3.81807051636773
Validation loss: 3.2210224419942346

Epoch: 5| Step: 7
Training loss: 2.9308776879300926
Validation loss: 3.2220728259895792

Epoch: 5| Step: 8
Training loss: 2.975063958001444
Validation loss: 3.2235246404026046

Epoch: 5| Step: 9
Training loss: 3.5765971957449096
Validation loss: 3.217984130809233

Epoch: 5| Step: 10
Training loss: 3.7452614409555443
Validation loss: 3.2173981894808925

Epoch: 30| Step: 0
Training loss: 4.147624997674921
Validation loss: 3.217437331517132

Epoch: 5| Step: 1
Training loss: 3.775227818972524
Validation loss: 3.216634808632889

Epoch: 5| Step: 2
Training loss: 2.962128009860775
Validation loss: 3.2181770682159616

Epoch: 5| Step: 3
Training loss: 3.3861597429190238
Validation loss: 3.222973225835171

Epoch: 5| Step: 4
Training loss: 3.4402306548126957
Validation loss: 3.2378549290107426

Epoch: 5| Step: 5
Training loss: 3.3132611245999244
Validation loss: 3.2128582451049583

Epoch: 5| Step: 6
Training loss: 3.843788332864307
Validation loss: 3.2113161868977533

Epoch: 5| Step: 7
Training loss: 3.2971101649874357
Validation loss: 3.210537317381144

Epoch: 5| Step: 8
Training loss: 2.9272271570097446
Validation loss: 3.210981415375256

Epoch: 5| Step: 9
Training loss: 3.595232981001802
Validation loss: 3.2095657642929556

Epoch: 5| Step: 10
Training loss: 3.2499254658295267
Validation loss: 3.207475847821148

Epoch: 31| Step: 0
Training loss: 4.622565376145402
Validation loss: 3.2080650174775975

Epoch: 5| Step: 1
Training loss: 3.4359581003443243
Validation loss: 3.207988930414063

Epoch: 5| Step: 2
Training loss: 3.619520320830548
Validation loss: 3.207193172574303

Epoch: 5| Step: 3
Training loss: 2.803226866301163
Validation loss: 3.205937557928212

Epoch: 5| Step: 4
Training loss: 3.1977215105746613
Validation loss: 3.2050396463009148

Epoch: 5| Step: 5
Training loss: 3.3804036433256135
Validation loss: 3.203241875469845

Epoch: 5| Step: 6
Training loss: 2.5257976820529513
Validation loss: 3.202540774806483

Epoch: 5| Step: 7
Training loss: 3.321546186248629
Validation loss: 3.203140329984071

Epoch: 5| Step: 8
Training loss: 4.127128976450438
Validation loss: 3.2015099640507536

Epoch: 5| Step: 9
Training loss: 3.2595207437790568
Validation loss: 3.199511204068635

Epoch: 5| Step: 10
Training loss: 3.2309566991862644
Validation loss: 3.201190223894778

Epoch: 32| Step: 0
Training loss: 3.5042912198374974
Validation loss: 3.1986825778093215

Epoch: 5| Step: 1
Training loss: 2.8727132576314136
Validation loss: 3.199431334267219

Epoch: 5| Step: 2
Training loss: 3.4262096524289727
Validation loss: 3.1976415327342216

Epoch: 5| Step: 3
Training loss: 3.92589202269091
Validation loss: 3.198575745195219

Epoch: 5| Step: 4
Training loss: 3.087794109961857
Validation loss: 3.1969219797372257

Epoch: 5| Step: 5
Training loss: 3.560456610125028
Validation loss: 3.2005939479129375

Epoch: 5| Step: 6
Training loss: 3.9000200564528975
Validation loss: 3.1981020701961933

Epoch: 5| Step: 7
Training loss: 3.6040747893572176
Validation loss: 3.200429390098643

Epoch: 5| Step: 8
Training loss: 3.1666660476148567
Validation loss: 3.1986770997731857

Epoch: 5| Step: 9
Training loss: 3.5184518257497954
Validation loss: 3.1958524591395814

Epoch: 5| Step: 10
Training loss: 3.1617141109024374
Validation loss: 3.196446600780995

Epoch: 33| Step: 0
Training loss: 2.5332270307155555
Validation loss: 3.1950430960198153

Epoch: 5| Step: 1
Training loss: 3.9704294330862595
Validation loss: 3.192608358582455

Epoch: 5| Step: 2
Training loss: 3.1600430801931734
Validation loss: 3.1924371158347844

Epoch: 5| Step: 3
Training loss: 3.367958635506588
Validation loss: 3.1915388583942392

Epoch: 5| Step: 4
Training loss: 3.2943090785926343
Validation loss: 3.189555950192864

Epoch: 5| Step: 5
Training loss: 3.7229972114808705
Validation loss: 3.188188026997687

Epoch: 5| Step: 6
Training loss: 3.830752595907207
Validation loss: 3.188181097205962

Epoch: 5| Step: 7
Training loss: 3.7910476989804316
Validation loss: 3.1876575415757085

Epoch: 5| Step: 8
Training loss: 3.2099829227076437
Validation loss: 3.187445491909423

Epoch: 5| Step: 9
Training loss: 3.2268060402942855
Validation loss: 3.1861704796807024

Epoch: 5| Step: 10
Training loss: 3.519344820256632
Validation loss: 3.1856402739217144

Epoch: 34| Step: 0
Training loss: 3.3331550232561367
Validation loss: 3.185368043084755

Epoch: 5| Step: 1
Training loss: 3.0193976487463328
Validation loss: 3.186196594963495

Epoch: 5| Step: 2
Training loss: 2.8723233243494803
Validation loss: 3.1819123513219765

Epoch: 5| Step: 3
Training loss: 3.9215177700073474
Validation loss: 3.182111568492725

Epoch: 5| Step: 4
Training loss: 2.91413367954078
Validation loss: 3.1815031882818667

Epoch: 5| Step: 5
Training loss: 3.5536427733741602
Validation loss: 3.180236783475141

Epoch: 5| Step: 6
Training loss: 3.2339630601763156
Validation loss: 3.1795857118349415

Epoch: 5| Step: 7
Training loss: 3.5653880944146805
Validation loss: 3.1788376979240667

Epoch: 5| Step: 8
Training loss: 3.585158053522577
Validation loss: 3.1776732162256787

Epoch: 5| Step: 9
Training loss: 3.780002608929092
Validation loss: 3.1779442346825277

Epoch: 5| Step: 10
Training loss: 3.8253281944943316
Validation loss: 3.177247389187646

Epoch: 35| Step: 0
Training loss: 2.9246504550319603
Validation loss: 3.1759011683490366

Epoch: 5| Step: 1
Training loss: 3.46465836881645
Validation loss: 3.177475194032798

Epoch: 5| Step: 2
Training loss: 3.942929354494099
Validation loss: 3.1747078495425987

Epoch: 5| Step: 3
Training loss: 3.861589421956914
Validation loss: 3.173413776975041

Epoch: 5| Step: 4
Training loss: 3.589743595158224
Validation loss: 3.175698799926036

Epoch: 5| Step: 5
Training loss: 3.874440429647009
Validation loss: 3.1797933757137047

Epoch: 5| Step: 6
Training loss: 3.233924723808935
Validation loss: 3.1811023120463466

Epoch: 5| Step: 7
Training loss: 3.414166411819678
Validation loss: 3.1990531485773017

Epoch: 5| Step: 8
Training loss: 3.162985988261484
Validation loss: 3.19852942569538

Epoch: 5| Step: 9
Training loss: 2.7216880970672017
Validation loss: 3.168485501795343

Epoch: 5| Step: 10
Training loss: 3.2750720766013064
Validation loss: 3.1693027277777817

Epoch: 36| Step: 0
Training loss: 3.830184195847648
Validation loss: 3.1641652477317534

Epoch: 5| Step: 1
Training loss: 3.4262024154058683
Validation loss: 3.1674163580747643

Epoch: 5| Step: 2
Training loss: 3.9453504503898764
Validation loss: 3.1666925204721506

Epoch: 5| Step: 3
Training loss: 3.6292985882671394
Validation loss: 3.1727000069372795

Epoch: 5| Step: 4
Training loss: 3.6087813776843545
Validation loss: 3.17607454973925

Epoch: 5| Step: 5
Training loss: 2.523195804323471
Validation loss: 3.166480431858011

Epoch: 5| Step: 6
Training loss: 3.102653253967557
Validation loss: 3.1619153474034563

Epoch: 5| Step: 7
Training loss: 3.553701813243989
Validation loss: 3.159238480978485

Epoch: 5| Step: 8
Training loss: 2.7767597770268075
Validation loss: 3.1564942075283065

Epoch: 5| Step: 9
Training loss: 3.7415629524747467
Validation loss: 3.156252285649786

Epoch: 5| Step: 10
Training loss: 3.182016480446941
Validation loss: 3.1601762339877335

Epoch: 37| Step: 0
Training loss: 3.0624448810210434
Validation loss: 3.169645102598271

Epoch: 5| Step: 1
Training loss: 3.9497222126690095
Validation loss: 3.165337839658707

Epoch: 5| Step: 2
Training loss: 3.5418754665683423
Validation loss: 3.1611552175848363

Epoch: 5| Step: 3
Training loss: 2.775891746685891
Validation loss: 3.1512743282367057

Epoch: 5| Step: 4
Training loss: 3.9536364077550887
Validation loss: 3.1508426943450076

Epoch: 5| Step: 5
Training loss: 3.3152178285126728
Validation loss: 3.151167482925218

Epoch: 5| Step: 6
Training loss: 2.9598357634473627
Validation loss: 3.151492880673444

Epoch: 5| Step: 7
Training loss: 3.188318484069522
Validation loss: 3.149274908427113

Epoch: 5| Step: 8
Training loss: 3.8914227874165515
Validation loss: 3.14925804306907

Epoch: 5| Step: 9
Training loss: 3.1973782230001393
Validation loss: 3.1483266140121686

Epoch: 5| Step: 10
Training loss: 3.4901764474767583
Validation loss: 3.1463244735992673

Epoch: 38| Step: 0
Training loss: 2.6476077239946725
Validation loss: 3.1456176666500735

Epoch: 5| Step: 1
Training loss: 3.2142630107017274
Validation loss: 3.144615741772423

Epoch: 5| Step: 2
Training loss: 3.809001380429427
Validation loss: 3.145038000298147

Epoch: 5| Step: 3
Training loss: 3.449745837814725
Validation loss: 3.1428133061277292

Epoch: 5| Step: 4
Training loss: 2.4921918049837917
Validation loss: 3.1423577712115356

Epoch: 5| Step: 5
Training loss: 3.5041830406456556
Validation loss: 3.1407442902339606

Epoch: 5| Step: 6
Training loss: 3.3247672322190467
Validation loss: 3.1405771115420738

Epoch: 5| Step: 7
Training loss: 3.2995980393639637
Validation loss: 3.1403931636396916

Epoch: 5| Step: 8
Training loss: 4.347029292030534
Validation loss: 3.142749926047778

Epoch: 5| Step: 9
Training loss: 3.4053055039983597
Validation loss: 3.137076814085385

Epoch: 5| Step: 10
Training loss: 3.5542600940679874
Validation loss: 3.1396782246461115

Epoch: 39| Step: 0
Training loss: 3.1492888480438066
Validation loss: 3.138635320098532

Epoch: 5| Step: 1
Training loss: 3.5688621864122223
Validation loss: 3.1389112454193335

Epoch: 5| Step: 2
Training loss: 3.3659233676485156
Validation loss: 3.138021205322886

Epoch: 5| Step: 3
Training loss: 2.9202494459861175
Validation loss: 3.136098604724637

Epoch: 5| Step: 4
Training loss: 3.9000924368443086
Validation loss: 3.1345970797758143

Epoch: 5| Step: 5
Training loss: 3.3710711181163826
Validation loss: 3.133436378450634

Epoch: 5| Step: 6
Training loss: 2.915344283643922
Validation loss: 3.132844396283612

Epoch: 5| Step: 7
Training loss: 3.7410690770627943
Validation loss: 3.132200754030895

Epoch: 5| Step: 8
Training loss: 3.750989910440648
Validation loss: 3.1318277632056546

Epoch: 5| Step: 9
Training loss: 2.9390699371292466
Validation loss: 3.1289774613783097

Epoch: 5| Step: 10
Training loss: 3.5288554487103982
Validation loss: 3.132336152908824

Epoch: 40| Step: 0
Training loss: 3.2243837107780853
Validation loss: 3.126712985872972

Epoch: 5| Step: 1
Training loss: 3.1689427544770106
Validation loss: 3.125723146014712

Epoch: 5| Step: 2
Training loss: 3.3956420626142294
Validation loss: 3.1263473739869845

Epoch: 5| Step: 3
Training loss: 3.134077088031752
Validation loss: 3.1245402049134983

Epoch: 5| Step: 4
Training loss: 3.8692580719885985
Validation loss: 3.125494508071778

Epoch: 5| Step: 5
Training loss: 2.920786445738354
Validation loss: 3.127209731612866

Epoch: 5| Step: 6
Training loss: 3.674869306666775
Validation loss: 3.122303192429167

Epoch: 5| Step: 7
Training loss: 2.6254613561741245
Validation loss: 3.1221169493247554

Epoch: 5| Step: 8
Training loss: 3.4337319269249726
Validation loss: 3.1201384500559652

Epoch: 5| Step: 9
Training loss: 3.5805123040390465
Validation loss: 3.120152948738723

Epoch: 5| Step: 10
Training loss: 4.029970424344793
Validation loss: 3.1198610246752256

Epoch: 41| Step: 0
Training loss: 3.35409599529869
Validation loss: 3.1176992308810747

Epoch: 5| Step: 1
Training loss: 2.9559883889059306
Validation loss: 3.1190710975462093

Epoch: 5| Step: 2
Training loss: 3.3099345223211323
Validation loss: 3.1177753325276782

Epoch: 5| Step: 3
Training loss: 3.712330382097575
Validation loss: 3.117403137921651

Epoch: 5| Step: 4
Training loss: 2.567980604199518
Validation loss: 3.115487098478718

Epoch: 5| Step: 5
Training loss: 3.466526040257128
Validation loss: 3.114238835333948

Epoch: 5| Step: 6
Training loss: 3.893438953203738
Validation loss: 3.1142244070784795

Epoch: 5| Step: 7
Training loss: 3.720794500395361
Validation loss: 3.1126917171526807

Epoch: 5| Step: 8
Training loss: 3.5679267909232926
Validation loss: 3.112495378244639

Epoch: 5| Step: 9
Training loss: 3.3323111556304963
Validation loss: 3.111208103233546

Epoch: 5| Step: 10
Training loss: 2.972410815980853
Validation loss: 3.1086702406093267

Epoch: 42| Step: 0
Training loss: 3.6089074298489896
Validation loss: 3.1088229434590775

Epoch: 5| Step: 1
Training loss: 2.469381903404834
Validation loss: 3.107500195925332

Epoch: 5| Step: 2
Training loss: 3.296618410945934
Validation loss: 3.1070010952741662

Epoch: 5| Step: 3
Training loss: 3.676732522945895
Validation loss: 3.107707364994285

Epoch: 5| Step: 4
Training loss: 2.711836695984114
Validation loss: 3.1055324831419506

Epoch: 5| Step: 5
Training loss: 3.572734787355312
Validation loss: 3.107057331466089

Epoch: 5| Step: 6
Training loss: 3.6883719754913336
Validation loss: 3.105324129594034

Epoch: 5| Step: 7
Training loss: 2.7793980122311175
Validation loss: 3.1044457615644503

Epoch: 5| Step: 8
Training loss: 3.5343803102165015
Validation loss: 3.1019416102730433

Epoch: 5| Step: 9
Training loss: 3.228576918041515
Validation loss: 3.101974619038216

Epoch: 5| Step: 10
Training loss: 4.224607569058791
Validation loss: 3.101368254628381

Epoch: 43| Step: 0
Training loss: 3.1010977062884932
Validation loss: 3.102975669025164

Epoch: 5| Step: 1
Training loss: 3.7079233235781937
Validation loss: 3.1053309520389885

Epoch: 5| Step: 2
Training loss: 3.4242424287179674
Validation loss: 3.104653893307708

Epoch: 5| Step: 3
Training loss: 3.0836253328641345
Validation loss: 3.103583762974124

Epoch: 5| Step: 4
Training loss: 3.9770750903281784
Validation loss: 3.104983505092393

Epoch: 5| Step: 5
Training loss: 3.1394760535393593
Validation loss: 3.0974462824098716

Epoch: 5| Step: 6
Training loss: 3.0729635116541036
Validation loss: 3.0978853726787166

Epoch: 5| Step: 7
Training loss: 3.143804051444586
Validation loss: 3.098530559153706

Epoch: 5| Step: 8
Training loss: 3.226549347118697
Validation loss: 3.098259447761965

Epoch: 5| Step: 9
Training loss: 3.648988473854668
Validation loss: 3.0970095089261656

Epoch: 5| Step: 10
Training loss: 3.3109590797027106
Validation loss: 3.091150946545988

Epoch: 44| Step: 0
Training loss: 3.6302098949689894
Validation loss: 3.08989793717428

Epoch: 5| Step: 1
Training loss: 3.382999969996611
Validation loss: 3.088463094344398

Epoch: 5| Step: 2
Training loss: 2.65630331546907
Validation loss: 3.0875332809327807

Epoch: 5| Step: 3
Training loss: 3.5709581855541344
Validation loss: 3.0851744022288816

Epoch: 5| Step: 4
Training loss: 3.597508198594221
Validation loss: 3.084904449749419

Epoch: 5| Step: 5
Training loss: 3.0049258164882633
Validation loss: 3.08417500717981

Epoch: 5| Step: 6
Training loss: 3.645803411451804
Validation loss: 3.082887923061555

Epoch: 5| Step: 7
Training loss: 3.3404698905941093
Validation loss: 3.0864291149333165

Epoch: 5| Step: 8
Training loss: 2.6917104341552665
Validation loss: 3.083048747220589

Epoch: 5| Step: 9
Training loss: 3.473072692136708
Validation loss: 3.0826342983984

Epoch: 5| Step: 10
Training loss: 3.718634467373866
Validation loss: 3.082058784196238

Epoch: 45| Step: 0
Training loss: 3.624331708670256
Validation loss: 3.0821045517046577

Epoch: 5| Step: 1
Training loss: 3.1722798206588085
Validation loss: 3.081083004237623

Epoch: 5| Step: 2
Training loss: 3.984562409425217
Validation loss: 3.08160246768551

Epoch: 5| Step: 3
Training loss: 3.4783191828918936
Validation loss: 3.0797977203215905

Epoch: 5| Step: 4
Training loss: 2.328151011481683
Validation loss: 3.078756939332841

Epoch: 5| Step: 5
Training loss: 2.9214103451665587
Validation loss: 3.0780834501060808

Epoch: 5| Step: 6
Training loss: 3.202578763209128
Validation loss: 3.077999815584927

Epoch: 5| Step: 7
Training loss: 3.7584953718645377
Validation loss: 3.076375772959082

Epoch: 5| Step: 8
Training loss: 3.198570027328863
Validation loss: 3.074515726550023

Epoch: 5| Step: 9
Training loss: 2.7779512881024075
Validation loss: 3.0744722750703715

Epoch: 5| Step: 10
Training loss: 4.061125067811412
Validation loss: 3.076554249875164

Epoch: 46| Step: 0
Training loss: 3.3089783860414608
Validation loss: 3.077029120425861

Epoch: 5| Step: 1
Training loss: 3.6588219619727416
Validation loss: 3.0795692797958862

Epoch: 5| Step: 2
Training loss: 2.528865680245423
Validation loss: 3.0792209924231067

Epoch: 5| Step: 3
Training loss: 3.5857981403339836
Validation loss: 3.076158447444666

Epoch: 5| Step: 4
Training loss: 3.908814953787982
Validation loss: 3.068755627799011

Epoch: 5| Step: 5
Training loss: 4.113798248462452
Validation loss: 3.06751674412686

Epoch: 5| Step: 6
Training loss: 2.916875468454922
Validation loss: 3.064867289629883

Epoch: 5| Step: 7
Training loss: 3.1330949841470654
Validation loss: 3.064552197138862

Epoch: 5| Step: 8
Training loss: 3.262067545441159
Validation loss: 3.064583124109577

Epoch: 5| Step: 9
Training loss: 2.8472074513452816
Validation loss: 3.065040114239851

Epoch: 5| Step: 10
Training loss: 3.0712677923051226
Validation loss: 3.064995200183803

Epoch: 47| Step: 0
Training loss: 3.136174783059366
Validation loss: 3.0618422243206376

Epoch: 5| Step: 1
Training loss: 3.3329362791730404
Validation loss: 3.0638956602743033

Epoch: 5| Step: 2
Training loss: 2.885354345500164
Validation loss: 3.065202300544821

Epoch: 5| Step: 3
Training loss: 3.5486807238840066
Validation loss: 3.063738411190768

Epoch: 5| Step: 4
Training loss: 3.824413508910064
Validation loss: 3.0641292685667976

Epoch: 5| Step: 5
Training loss: 3.3524494553638005
Validation loss: 3.063945930349697

Epoch: 5| Step: 6
Training loss: 3.472983037035613
Validation loss: 3.063537662948105

Epoch: 5| Step: 7
Training loss: 3.4514845321642458
Validation loss: 3.0609236597452636

Epoch: 5| Step: 8
Training loss: 3.197779665983148
Validation loss: 3.059815731147762

Epoch: 5| Step: 9
Training loss: 3.225480237586571
Validation loss: 3.0588920608193417

Epoch: 5| Step: 10
Training loss: 3.1213467415455516
Validation loss: 3.058037187212656

Epoch: 48| Step: 0
Training loss: 3.4082582485692643
Validation loss: 3.056446294325092

Epoch: 5| Step: 1
Training loss: 4.119689760101168
Validation loss: 3.056000146065019

Epoch: 5| Step: 2
Training loss: 3.0439266709707495
Validation loss: 3.055928390132632

Epoch: 5| Step: 3
Training loss: 3.8611268303152477
Validation loss: 3.0544372293256186

Epoch: 5| Step: 4
Training loss: 2.5578872287578913
Validation loss: 3.0605424949702136

Epoch: 5| Step: 5
Training loss: 3.0925304436630707
Validation loss: 3.0620283190936903

Epoch: 5| Step: 6
Training loss: 3.858360744129032
Validation loss: 3.057815404317098

Epoch: 5| Step: 7
Training loss: 4.134212033382285
Validation loss: 3.0620131910373027

Epoch: 5| Step: 8
Training loss: 2.2420068329120815
Validation loss: 3.0574036828703153

Epoch: 5| Step: 9
Training loss: 2.8248343528862603
Validation loss: 3.0572799282970515

Epoch: 5| Step: 10
Training loss: 2.746392658402064
Validation loss: 3.0566607271789086

Epoch: 49| Step: 0
Training loss: 3.0128985319425774
Validation loss: 3.0532749572262627

Epoch: 5| Step: 1
Training loss: 3.1067991082225674
Validation loss: 3.0541381795213534

Epoch: 5| Step: 2
Training loss: 4.078545910390622
Validation loss: 3.047316920034876

Epoch: 5| Step: 3
Training loss: 3.2320327017423316
Validation loss: 3.047239908475093

Epoch: 5| Step: 4
Training loss: 3.042483407369488
Validation loss: 3.0448071467661797

Epoch: 5| Step: 5
Training loss: 3.2740508531408974
Validation loss: 3.0432489577767434

Epoch: 5| Step: 6
Training loss: 3.255470367057734
Validation loss: 3.0429214123595942

Epoch: 5| Step: 7
Training loss: 3.331043092410558
Validation loss: 3.042516706469695

Epoch: 5| Step: 8
Training loss: 3.323893691418332
Validation loss: 3.042880778640663

Epoch: 5| Step: 9
Training loss: 3.494182520317238
Validation loss: 3.0407049271539344

Epoch: 5| Step: 10
Training loss: 3.2563407372775686
Validation loss: 3.0405507172252833

Epoch: 50| Step: 0
Training loss: 3.6170111133256
Validation loss: 3.0403436898472767

Epoch: 5| Step: 1
Training loss: 2.9252161516709467
Validation loss: 3.0387590316228095

Epoch: 5| Step: 2
Training loss: 3.3240534991240835
Validation loss: 3.038585147579399

Epoch: 5| Step: 3
Training loss: 3.053184197905179
Validation loss: 3.0366706600126707

Epoch: 5| Step: 4
Training loss: 3.1067404776169623
Validation loss: 3.036883641835223

Epoch: 5| Step: 5
Training loss: 3.1717257159200902
Validation loss: 3.03457471619629

Epoch: 5| Step: 6
Training loss: 3.6333962904582298
Validation loss: 3.03474740406942

Epoch: 5| Step: 7
Training loss: 3.296232621946734
Validation loss: 3.0348364677565494

Epoch: 5| Step: 8
Training loss: 2.8295766571764567
Validation loss: 3.0340066039773808

Epoch: 5| Step: 9
Training loss: 4.154721315955721
Validation loss: 3.0338302234625747

Epoch: 5| Step: 10
Training loss: 3.055182297382475
Validation loss: 3.031112889380643

Epoch: 51| Step: 0
Training loss: 2.780598596304755
Validation loss: 3.031544616813505

Epoch: 5| Step: 1
Training loss: 2.746879020401548
Validation loss: 3.0307029845403464

Epoch: 5| Step: 2
Training loss: 3.11416456454353
Validation loss: 3.0293848650885606

Epoch: 5| Step: 3
Training loss: 3.531487515994154
Validation loss: 3.027705478234627

Epoch: 5| Step: 4
Training loss: 3.1940031843366614
Validation loss: 3.026298662977613

Epoch: 5| Step: 5
Training loss: 3.2480035665426734
Validation loss: 3.026864065009039

Epoch: 5| Step: 6
Training loss: 3.458146668570848
Validation loss: 3.0263727072093123

Epoch: 5| Step: 7
Training loss: 3.818385849492619
Validation loss: 3.027505024171244

Epoch: 5| Step: 8
Training loss: 3.488412749918499
Validation loss: 3.0278517214277683

Epoch: 5| Step: 9
Training loss: 3.4014734497469616
Validation loss: 3.025780351762674

Epoch: 5| Step: 10
Training loss: 3.432730678022515
Validation loss: 3.023611927886044

Epoch: 52| Step: 0
Training loss: 3.0409375366298748
Validation loss: 3.0215538503671806

Epoch: 5| Step: 1
Training loss: 3.144114666941935
Validation loss: 3.0209902557474853

Epoch: 5| Step: 2
Training loss: 2.8521246369080733
Validation loss: 3.0183777369870555

Epoch: 5| Step: 3
Training loss: 3.655949246027134
Validation loss: 3.0201949098761998

Epoch: 5| Step: 4
Training loss: 3.215727043942408
Validation loss: 3.019197731663103

Epoch: 5| Step: 5
Training loss: 3.3456964264472493
Validation loss: 3.0195310581216077

Epoch: 5| Step: 6
Training loss: 4.130101141995827
Validation loss: 3.016368371599819

Epoch: 5| Step: 7
Training loss: 3.161384409878673
Validation loss: 3.0154838837162212

Epoch: 5| Step: 8
Training loss: 2.483720897241042
Validation loss: 3.0148056951637985

Epoch: 5| Step: 9
Training loss: 3.6703540005536093
Validation loss: 3.015320629223493

Epoch: 5| Step: 10
Training loss: 3.272976717690405
Validation loss: 3.01377161612316

Epoch: 53| Step: 0
Training loss: 3.9347479754813013
Validation loss: 3.014172815121227

Epoch: 5| Step: 1
Training loss: 3.2948447389737305
Validation loss: 3.015716802972298

Epoch: 5| Step: 2
Training loss: 2.9670980575604022
Validation loss: 3.016752057613904

Epoch: 5| Step: 3
Training loss: 3.533972306925067
Validation loss: 3.011711557167257

Epoch: 5| Step: 4
Training loss: 2.769556473158458
Validation loss: 3.0095521585625864

Epoch: 5| Step: 5
Training loss: 3.581919428121015
Validation loss: 3.00741451950824

Epoch: 5| Step: 6
Training loss: 3.4648573745064004
Validation loss: 3.008692215161897

Epoch: 5| Step: 7
Training loss: 3.005011029215295
Validation loss: 3.0102371558004704

Epoch: 5| Step: 8
Training loss: 3.125300736261654
Validation loss: 3.007895847929536

Epoch: 5| Step: 9
Training loss: 3.310470535163328
Validation loss: 3.0080331406879686

Epoch: 5| Step: 10
Training loss: 2.980482028916602
Validation loss: 3.007805046388734

Epoch: 54| Step: 0
Training loss: 3.7455751380294084
Validation loss: 3.0069127817252133

Epoch: 5| Step: 1
Training loss: 3.5605527675828914
Validation loss: 3.0111851552082176

Epoch: 5| Step: 2
Training loss: 3.378991909815577
Validation loss: 3.0037790836919283

Epoch: 5| Step: 3
Training loss: 2.8957126692919903
Validation loss: 2.999774189452612

Epoch: 5| Step: 4
Training loss: 3.1024955672018026
Validation loss: 2.99992266080151

Epoch: 5| Step: 5
Training loss: 3.5437308336173574
Validation loss: 2.9996557901342733

Epoch: 5| Step: 6
Training loss: 3.262062283087973
Validation loss: 2.9992073739882494

Epoch: 5| Step: 7
Training loss: 3.8515938221739194
Validation loss: 2.996467551290997

Epoch: 5| Step: 8
Training loss: 2.856569007738423
Validation loss: 2.996185891295801

Epoch: 5| Step: 9
Training loss: 3.104836223171407
Validation loss: 2.9964036569606676

Epoch: 5| Step: 10
Training loss: 2.408770145634895
Validation loss: 2.996732838374016

Epoch: 55| Step: 0
Training loss: 3.4797881859959485
Validation loss: 2.9973961492201715

Epoch: 5| Step: 1
Training loss: 2.9737614145015767
Validation loss: 2.9971547939889356

Epoch: 5| Step: 2
Training loss: 3.3603099852575333
Validation loss: 3.0002158268506585

Epoch: 5| Step: 3
Training loss: 3.6827044581611035
Validation loss: 2.9965261202534363

Epoch: 5| Step: 4
Training loss: 3.481670476151411
Validation loss: 2.998786388539036

Epoch: 5| Step: 5
Training loss: 2.923464256176414
Validation loss: 3.003308701986161

Epoch: 5| Step: 6
Training loss: 3.4301437734827815
Validation loss: 3.0019432135653124

Epoch: 5| Step: 7
Training loss: 3.308930831366098
Validation loss: 3.0001925232341935

Epoch: 5| Step: 8
Training loss: 3.1476537898080794
Validation loss: 2.9914144380928143

Epoch: 5| Step: 9
Training loss: 2.95121049129889
Validation loss: 2.987986092759787

Epoch: 5| Step: 10
Training loss: 3.1822635797154972
Validation loss: 2.9888042312149725

Epoch: 56| Step: 0
Training loss: 3.510576072869426
Validation loss: 2.9890791799594933

Epoch: 5| Step: 1
Training loss: 3.364169226201252
Validation loss: 2.9914598150144296

Epoch: 5| Step: 2
Training loss: 3.327656027835119
Validation loss: 2.992055416177233

Epoch: 5| Step: 3
Training loss: 3.013556368796681
Validation loss: 2.992990647356963

Epoch: 5| Step: 4
Training loss: 3.2580203349097663
Validation loss: 2.9931815290236683

Epoch: 5| Step: 5
Training loss: 3.400489345565817
Validation loss: 2.99311892297382

Epoch: 5| Step: 6
Training loss: 3.7959352437034077
Validation loss: 2.991953213431906

Epoch: 5| Step: 7
Training loss: 2.551455445154949
Validation loss: 2.988480618854495

Epoch: 5| Step: 8
Training loss: 3.1234946630684814
Validation loss: 2.989008607545735

Epoch: 5| Step: 9
Training loss: 3.706690878160108
Validation loss: 2.9873516191967795

Epoch: 5| Step: 10
Training loss: 2.669265275654783
Validation loss: 2.9863062685506416

Epoch: 57| Step: 0
Training loss: 2.938684103099974
Validation loss: 2.9852265050174704

Epoch: 5| Step: 1
Training loss: 3.2349367989877056
Validation loss: 2.985037977139501

Epoch: 5| Step: 2
Training loss: 3.1494219355521746
Validation loss: 2.9831583903854653

Epoch: 5| Step: 3
Training loss: 3.2257952574566455
Validation loss: 2.981587725108221

Epoch: 5| Step: 4
Training loss: 3.2167512187485547
Validation loss: 2.981713961793153

Epoch: 5| Step: 5
Training loss: 3.181887753456766
Validation loss: 2.9831737765291306

Epoch: 5| Step: 6
Training loss: 3.5982881502604385
Validation loss: 2.982860309440689

Epoch: 5| Step: 7
Training loss: 3.023187829090905
Validation loss: 2.981380490868217

Epoch: 5| Step: 8
Training loss: 3.361471825852261
Validation loss: 2.9821980207404355

Epoch: 5| Step: 9
Training loss: 3.38095076782884
Validation loss: 2.987927029069961

Epoch: 5| Step: 10
Training loss: 3.660428259969961
Validation loss: 2.990899512768514

Epoch: 58| Step: 0
Training loss: 3.4708219646314986
Validation loss: 2.9913951504002045

Epoch: 5| Step: 1
Training loss: 3.1124850108080655
Validation loss: 2.98069097612181

Epoch: 5| Step: 2
Training loss: 3.2778811645007613
Validation loss: 2.974114620684615

Epoch: 5| Step: 3
Training loss: 2.470521026052447
Validation loss: 2.973115878452905

Epoch: 5| Step: 4
Training loss: 3.185753586995269
Validation loss: 2.972974207764401

Epoch: 5| Step: 5
Training loss: 3.4849636795143475
Validation loss: 2.9735577377820634

Epoch: 5| Step: 6
Training loss: 3.748597963817397
Validation loss: 2.9741335799727535

Epoch: 5| Step: 7
Training loss: 3.1592281379109304
Validation loss: 2.9745533022272634

Epoch: 5| Step: 8
Training loss: 3.652245961884423
Validation loss: 2.9729722347867327

Epoch: 5| Step: 9
Training loss: 3.131595517890345
Validation loss: 2.973386070955084

Epoch: 5| Step: 10
Training loss: 3.0279554573522023
Validation loss: 2.9734338310391975

Epoch: 59| Step: 0
Training loss: 3.447660100482214
Validation loss: 2.973004745635516

Epoch: 5| Step: 1
Training loss: 3.112609407884292
Validation loss: 2.971578042672524

Epoch: 5| Step: 2
Training loss: 2.9997167453558284
Validation loss: 2.97051835644297

Epoch: 5| Step: 3
Training loss: 3.486127609342229
Validation loss: 2.96818663989548

Epoch: 5| Step: 4
Training loss: 3.6337708224397764
Validation loss: 2.968130107207733

Epoch: 5| Step: 5
Training loss: 2.938031899203081
Validation loss: 2.964991611754592

Epoch: 5| Step: 6
Training loss: 3.24112354883699
Validation loss: 2.96566417096863

Epoch: 5| Step: 7
Training loss: 3.434678046451498
Validation loss: 2.9642750508628795

Epoch: 5| Step: 8
Training loss: 2.9545760853386693
Validation loss: 2.961816985952546

Epoch: 5| Step: 9
Training loss: 3.1254946507927013
Validation loss: 2.9606613457683406

Epoch: 5| Step: 10
Training loss: 3.3556014757473935
Validation loss: 2.958876077473403

Epoch: 60| Step: 0
Training loss: 4.109912213504074
Validation loss: 2.9638102549734695

Epoch: 5| Step: 1
Training loss: 3.3902991353616403
Validation loss: 2.9619791794532246

Epoch: 5| Step: 2
Training loss: 3.1108217180472764
Validation loss: 2.973313757723781

Epoch: 5| Step: 3
Training loss: 2.9380734472371284
Validation loss: 2.956843803768459

Epoch: 5| Step: 4
Training loss: 3.0865949099489165
Validation loss: 2.954873540466305

Epoch: 5| Step: 5
Training loss: 2.8458529231978296
Validation loss: 2.955334397432918

Epoch: 5| Step: 6
Training loss: 2.963189308033515
Validation loss: 2.956964734014068

Epoch: 5| Step: 7
Training loss: 3.110712578391216
Validation loss: 2.957981626571523

Epoch: 5| Step: 8
Training loss: 3.318498901523341
Validation loss: 2.9603749177259275

Epoch: 5| Step: 9
Training loss: 3.626135023596141
Validation loss: 3.0062469784969585

Epoch: 5| Step: 10
Training loss: 3.1045654518623795
Validation loss: 3.006024421724068

Epoch: 61| Step: 0
Training loss: 3.6156643323811357
Validation loss: 2.957749764302406

Epoch: 5| Step: 1
Training loss: 2.678823081411213
Validation loss: 2.952363710795887

Epoch: 5| Step: 2
Training loss: 3.0883404224998547
Validation loss: 2.9502894103682857

Epoch: 5| Step: 3
Training loss: 2.9003034893266246
Validation loss: 2.9491997513719044

Epoch: 5| Step: 4
Training loss: 3.93929153133655
Validation loss: 2.950836668395747

Epoch: 5| Step: 5
Training loss: 3.217522396314993
Validation loss: 2.963819740343923

Epoch: 5| Step: 6
Training loss: 3.829076282872112
Validation loss: 2.9624667070472985

Epoch: 5| Step: 7
Training loss: 3.1136112971521377
Validation loss: 2.945598161177638

Epoch: 5| Step: 8
Training loss: 3.5296359804403266
Validation loss: 2.9468672162134566

Epoch: 5| Step: 9
Training loss: 2.336403892677642
Validation loss: 2.948550087369326

Epoch: 5| Step: 10
Training loss: 3.0963101053698936
Validation loss: 2.9492304450133737

Epoch: 62| Step: 0
Training loss: 3.616614541470676
Validation loss: 2.952576509449784

Epoch: 5| Step: 1
Training loss: 3.119891301486842
Validation loss: 2.9600949626740025

Epoch: 5| Step: 2
Training loss: 3.4078110783647024
Validation loss: 2.952818766607505

Epoch: 5| Step: 3
Training loss: 2.962074886676119
Validation loss: 2.947149582982846

Epoch: 5| Step: 4
Training loss: 3.355054481166325
Validation loss: 2.9432148269476257

Epoch: 5| Step: 5
Training loss: 2.908682184875533
Validation loss: 2.942585740660742

Epoch: 5| Step: 6
Training loss: 3.046571217578354
Validation loss: 2.9433823481789103

Epoch: 5| Step: 7
Training loss: 3.20069905036552
Validation loss: 2.942607634347173

Epoch: 5| Step: 8
Training loss: 3.118599096404775
Validation loss: 2.9428665390124635

Epoch: 5| Step: 9
Training loss: 3.5924951103883305
Validation loss: 2.9419285127098957

Epoch: 5| Step: 10
Training loss: 3.18025806003698
Validation loss: 2.941296986246776

Epoch: 63| Step: 0
Training loss: 3.2144828584551894
Validation loss: 2.943084337912568

Epoch: 5| Step: 1
Training loss: 3.268632443941788
Validation loss: 2.9422493049095646

Epoch: 5| Step: 2
Training loss: 3.2624025644536436
Validation loss: 2.9380451046588134

Epoch: 5| Step: 3
Training loss: 3.3801648216013676
Validation loss: 2.937451268169123

Epoch: 5| Step: 4
Training loss: 2.477926654743159
Validation loss: 2.938968074288091

Epoch: 5| Step: 5
Training loss: 3.661997003484278
Validation loss: 2.939637316192156

Epoch: 5| Step: 6
Training loss: 2.778242134911746
Validation loss: 2.9497540601016525

Epoch: 5| Step: 7
Training loss: 3.096090337080979
Validation loss: 2.9494330715339427

Epoch: 5| Step: 8
Training loss: 3.3449989909582514
Validation loss: 2.956926776351008

Epoch: 5| Step: 9
Training loss: 3.1805769592483015
Validation loss: 2.9498387686341614

Epoch: 5| Step: 10
Training loss: 3.817904284740701
Validation loss: 2.951496549247653

Epoch: 64| Step: 0
Training loss: 3.2675047214651984
Validation loss: 2.9349602913316026

Epoch: 5| Step: 1
Training loss: 3.453480007513071
Validation loss: 2.933751545968528

Epoch: 5| Step: 2
Training loss: 2.8037068557310936
Validation loss: 2.93128879114855

Epoch: 5| Step: 3
Training loss: 2.8062185714762915
Validation loss: 2.9317157342746105

Epoch: 5| Step: 4
Training loss: 3.145902081342569
Validation loss: 2.9301769846887127

Epoch: 5| Step: 5
Training loss: 3.1372652064766604
Validation loss: 2.9317275279663733

Epoch: 5| Step: 6
Training loss: 3.324186331639076
Validation loss: 2.936258403174247

Epoch: 5| Step: 7
Training loss: 3.249088599718512
Validation loss: 2.9309741500804085

Epoch: 5| Step: 8
Training loss: 3.27524838852426
Validation loss: 2.932627058744518

Epoch: 5| Step: 9
Training loss: 3.555961095676504
Validation loss: 2.9273826741799396

Epoch: 5| Step: 10
Training loss: 3.4389663343143333
Validation loss: 2.9269913415280913

Epoch: 65| Step: 0
Training loss: 2.6188037038317478
Validation loss: 2.9266400787483233

Epoch: 5| Step: 1
Training loss: 3.9094681567856386
Validation loss: 2.9259102878313037

Epoch: 5| Step: 2
Training loss: 2.8011710136475023
Validation loss: 2.930217606470354

Epoch: 5| Step: 3
Training loss: 3.376667034855854
Validation loss: 2.929244938501314

Epoch: 5| Step: 4
Training loss: 3.048018177468872
Validation loss: 2.932266736790231

Epoch: 5| Step: 5
Training loss: 2.6881859369739263
Validation loss: 2.9303267094313954

Epoch: 5| Step: 6
Training loss: 3.0548943256887773
Validation loss: 2.9313306227895213

Epoch: 5| Step: 7
Training loss: 3.5271293431341926
Validation loss: 2.933083797377034

Epoch: 5| Step: 8
Training loss: 2.9817893126246884
Validation loss: 2.927483251761292

Epoch: 5| Step: 9
Training loss: 3.3949883156576766
Validation loss: 2.9154996766956396

Epoch: 5| Step: 10
Training loss: 3.8267504657205036
Validation loss: 2.916958038144356

Epoch: 66| Step: 0
Training loss: 3.394935785734071
Validation loss: 2.915831998122985

Epoch: 5| Step: 1
Training loss: 3.0278384487439047
Validation loss: 2.913700323953607

Epoch: 5| Step: 2
Training loss: 3.1246624573563317
Validation loss: 2.9122580074802245

Epoch: 5| Step: 3
Training loss: 3.0057989341206506
Validation loss: 2.913002865544756

Epoch: 5| Step: 4
Training loss: 3.1058522881278408
Validation loss: 2.9130497974335383

Epoch: 5| Step: 5
Training loss: 3.0424713394206835
Validation loss: 2.912198081791045

Epoch: 5| Step: 6
Training loss: 3.325269593516873
Validation loss: 2.9217093517654775

Epoch: 5| Step: 7
Training loss: 2.5681946908347384
Validation loss: 2.912901784459761

Epoch: 5| Step: 8
Training loss: 3.5968351970097605
Validation loss: 2.911014100704225

Epoch: 5| Step: 9
Training loss: 3.1758492663092333
Validation loss: 2.9105606554611256

Epoch: 5| Step: 10
Training loss: 3.875563057630707
Validation loss: 2.9185792222034004

Epoch: 67| Step: 0
Training loss: 2.8618953416030193
Validation loss: 2.905992031391456

Epoch: 5| Step: 1
Training loss: 3.3032624619391138
Validation loss: 2.9035458862873105

Epoch: 5| Step: 2
Training loss: 3.0439351301662385
Validation loss: 2.9042227655791795

Epoch: 5| Step: 3
Training loss: 3.8000813826830933
Validation loss: 2.90238172459111

Epoch: 5| Step: 4
Training loss: 2.7736842086023947
Validation loss: 2.9057764520324927

Epoch: 5| Step: 5
Training loss: 2.980003150579848
Validation loss: 2.9060572431164315

Epoch: 5| Step: 6
Training loss: 3.210386354244309
Validation loss: 2.904169770481277

Epoch: 5| Step: 7
Training loss: 3.139089939876646
Validation loss: 2.905896490276891

Epoch: 5| Step: 8
Training loss: 3.6276006906259517
Validation loss: 2.9049699010418064

Epoch: 5| Step: 9
Training loss: 3.227427664492081
Validation loss: 2.9027276563143483

Epoch: 5| Step: 10
Training loss: 3.1558876962733096
Validation loss: 2.902770177746813

Epoch: 68| Step: 0
Training loss: 2.614684681745551
Validation loss: 2.901498301562395

Epoch: 5| Step: 1
Training loss: 2.9993773450005645
Validation loss: 2.901859761866107

Epoch: 5| Step: 2
Training loss: 3.7797632999081463
Validation loss: 2.9004291148342376

Epoch: 5| Step: 3
Training loss: 3.3414982138878253
Validation loss: 2.8990687249112894

Epoch: 5| Step: 4
Training loss: 3.8064489654002047
Validation loss: 2.8996401063843247

Epoch: 5| Step: 5
Training loss: 3.293598010847053
Validation loss: 2.8983587713096526

Epoch: 5| Step: 6
Training loss: 2.9012947086306355
Validation loss: 2.8962642614337017

Epoch: 5| Step: 7
Training loss: 2.536951684199253
Validation loss: 2.896661353357802

Epoch: 5| Step: 8
Training loss: 3.0217965179950474
Validation loss: 2.8954741375520303

Epoch: 5| Step: 9
Training loss: 2.9166240325718173
Validation loss: 2.8946437970191354

Epoch: 5| Step: 10
Training loss: 3.75911697935533
Validation loss: 2.897205273609962

Epoch: 69| Step: 0
Training loss: 3.3092051980292148
Validation loss: 2.8951166032791873

Epoch: 5| Step: 1
Training loss: 2.789120628114501
Validation loss: 2.8971163767619563

Epoch: 5| Step: 2
Training loss: 3.61580966224023
Validation loss: 2.901479677877278

Epoch: 5| Step: 3
Training loss: 2.791468418730503
Validation loss: 2.9105242840926056

Epoch: 5| Step: 4
Training loss: 3.105788880168172
Validation loss: 2.8937901961530743

Epoch: 5| Step: 5
Training loss: 3.675730397828373
Validation loss: 2.89073294205519

Epoch: 5| Step: 6
Training loss: 3.535193747642981
Validation loss: 2.8900066997116736

Epoch: 5| Step: 7
Training loss: 3.6067070947333257
Validation loss: 2.889312420411962

Epoch: 5| Step: 8
Training loss: 2.8471798177729988
Validation loss: 2.893258857672541

Epoch: 5| Step: 9
Training loss: 2.7491393910103636
Validation loss: 2.8916688718755155

Epoch: 5| Step: 10
Training loss: 2.8136139253227803
Validation loss: 2.892671047542035

Epoch: 70| Step: 0
Training loss: 3.607404426900143
Validation loss: 2.8923785964866746

Epoch: 5| Step: 1
Training loss: 3.0836460539173176
Validation loss: 2.8932074179776657

Epoch: 5| Step: 2
Training loss: 3.1813242305946208
Validation loss: 2.892953269265547

Epoch: 5| Step: 3
Training loss: 3.7030549505505417
Validation loss: 2.8899195525596033

Epoch: 5| Step: 4
Training loss: 2.6201652326241645
Validation loss: 2.8907332542256583

Epoch: 5| Step: 5
Training loss: 3.150742664285335
Validation loss: 2.8889306652144797

Epoch: 5| Step: 6
Training loss: 3.1331677318667035
Validation loss: 2.8881017117572054

Epoch: 5| Step: 7
Training loss: 3.3225634316387676
Validation loss: 2.8885999224908683

Epoch: 5| Step: 8
Training loss: 2.8994688271078406
Validation loss: 2.886069080135781

Epoch: 5| Step: 9
Training loss: 3.1124695374250533
Validation loss: 2.884794405726842

Epoch: 5| Step: 10
Training loss: 3.1685427746551467
Validation loss: 2.884693896768892

Epoch: 71| Step: 0
Training loss: 3.2017131392048284
Validation loss: 2.8868705430634347

Epoch: 5| Step: 1
Training loss: 3.2527341345828993
Validation loss: 2.882961175651165

Epoch: 5| Step: 2
Training loss: 3.6009852014951016
Validation loss: 2.8849610574284634

Epoch: 5| Step: 3
Training loss: 2.6780743873469643
Validation loss: 2.8891070982645424

Epoch: 5| Step: 4
Training loss: 3.1326064044389357
Validation loss: 2.885148195208425

Epoch: 5| Step: 5
Training loss: 3.3101909434859533
Validation loss: 2.8817438105109345

Epoch: 5| Step: 6
Training loss: 3.1288772943611813
Validation loss: 2.877332366385098

Epoch: 5| Step: 7
Training loss: 3.28097910898168
Validation loss: 2.8748201935528206

Epoch: 5| Step: 8
Training loss: 3.248362055090933
Validation loss: 2.874450233330996

Epoch: 5| Step: 9
Training loss: 2.8321544962406575
Validation loss: 2.877037968537468

Epoch: 5| Step: 10
Training loss: 3.2975448723343543
Validation loss: 2.877923280907076

Epoch: 72| Step: 0
Training loss: 3.1742863250982976
Validation loss: 2.8802947074238237

Epoch: 5| Step: 1
Training loss: 3.0607090598480027
Validation loss: 2.8808444248518588

Epoch: 5| Step: 2
Training loss: 2.9942696202031773
Validation loss: 2.8856216564568347

Epoch: 5| Step: 3
Training loss: 3.267654299489418
Validation loss: 2.878670696540344

Epoch: 5| Step: 4
Training loss: 3.0780481629051977
Validation loss: 2.883778556474919

Epoch: 5| Step: 5
Training loss: 3.4705600998860957
Validation loss: 2.8834813031347926

Epoch: 5| Step: 6
Training loss: 3.0865789978012823
Validation loss: 2.883145841493736

Epoch: 5| Step: 7
Training loss: 2.718073355122055
Validation loss: 2.879195789334533

Epoch: 5| Step: 8
Training loss: 3.700011284269704
Validation loss: 2.8813248090566344

Epoch: 5| Step: 9
Training loss: 2.8925253729997364
Validation loss: 2.887031178706875

Epoch: 5| Step: 10
Training loss: 3.5018098783795226
Validation loss: 2.886628764658535

Epoch: 73| Step: 0
Training loss: 2.3173547253552313
Validation loss: 2.8736115598905156

Epoch: 5| Step: 1
Training loss: 3.347340447609802
Validation loss: 2.877653673524089

Epoch: 5| Step: 2
Training loss: 3.154677197466461
Validation loss: 2.8782201676790766

Epoch: 5| Step: 3
Training loss: 3.4682851943916364
Validation loss: 2.877395288365015

Epoch: 5| Step: 4
Training loss: 2.4472238304180047
Validation loss: 2.8809301682372697

Epoch: 5| Step: 5
Training loss: 3.2950059555532443
Validation loss: 2.9522414223870017

Epoch: 5| Step: 6
Training loss: 3.0087392989231017
Validation loss: 3.0231329405814344

Epoch: 5| Step: 7
Training loss: 3.2690137592631747
Validation loss: 3.2197056184163038

Epoch: 5| Step: 8
Training loss: 3.9989489128052838
Validation loss: 3.125258107344823

Epoch: 5| Step: 9
Training loss: 3.876376615078348
Validation loss: 2.967950368031572

Epoch: 5| Step: 10
Training loss: 3.1611693164790666
Validation loss: 2.960083898647092

Epoch: 74| Step: 0
Training loss: 3.305407290156661
Validation loss: 2.943683383378523

Epoch: 5| Step: 1
Training loss: 3.3551104779537293
Validation loss: 3.0745451758143587

Epoch: 5| Step: 2
Training loss: 3.5976382243712375
Validation loss: 3.2773878159179124

Epoch: 5| Step: 3
Training loss: 3.514913258031671
Validation loss: 3.2471736011519936

Epoch: 5| Step: 4
Training loss: 3.007415190378498
Validation loss: 3.1858763173550146

Epoch: 5| Step: 5
Training loss: 3.3366714134779585
Validation loss: 3.154822448367544

Epoch: 5| Step: 6
Training loss: 3.2726697362793558
Validation loss: 3.110582092337743

Epoch: 5| Step: 7
Training loss: 3.6990571032033
Validation loss: 3.0316900313011916

Epoch: 5| Step: 8
Training loss: 2.975247630864668
Validation loss: 2.907315434145594

Epoch: 5| Step: 9
Training loss: 3.644190797921436
Validation loss: 2.9424550773560822

Epoch: 5| Step: 10
Training loss: 2.865568197471551
Validation loss: 3.063447350776489

Epoch: 75| Step: 0
Training loss: 3.369963243097269
Validation loss: 3.1152915504700016

Epoch: 5| Step: 1
Training loss: 3.18340996521856
Validation loss: 3.145572977280902

Epoch: 5| Step: 2
Training loss: 3.5161373867060974
Validation loss: 2.9896624074703455

Epoch: 5| Step: 3
Training loss: 2.891195374998226
Validation loss: 2.9325207444272294

Epoch: 5| Step: 4
Training loss: 3.026123115813457
Validation loss: 2.9116122602641643

Epoch: 5| Step: 5
Training loss: 3.194144410864364
Validation loss: 2.897127378627037

Epoch: 5| Step: 6
Training loss: 3.071410160072882
Validation loss: 2.9159625523411052

Epoch: 5| Step: 7
Training loss: 3.3760096134844395
Validation loss: 3.0185946465221236

Epoch: 5| Step: 8
Training loss: 3.5822689930134595
Validation loss: 3.0111653198632724

Epoch: 5| Step: 9
Training loss: 3.5482636140777073
Validation loss: 2.9637334938032724

Epoch: 5| Step: 10
Training loss: 3.026975941618178
Validation loss: 2.908217775833593

Epoch: 76| Step: 0
Training loss: 2.781988495924287
Validation loss: 2.8706280484997397

Epoch: 5| Step: 1
Training loss: 3.62469586379057
Validation loss: 2.856502114288534

Epoch: 5| Step: 2
Training loss: 3.4866766063580115
Validation loss: 2.854671623724256

Epoch: 5| Step: 3
Training loss: 3.451116884200401
Validation loss: 2.857579516207366

Epoch: 5| Step: 4
Training loss: 3.1607175123492284
Validation loss: 2.8573156838144156

Epoch: 5| Step: 5
Training loss: 3.269455848471574
Validation loss: 2.857708112536064

Epoch: 5| Step: 6
Training loss: 3.0939821098417015
Validation loss: 2.8657129978161304

Epoch: 5| Step: 7
Training loss: 3.2817173216323132
Validation loss: 2.8595617842862633

Epoch: 5| Step: 8
Training loss: 3.366343098063808
Validation loss: 2.865692910602714

Epoch: 5| Step: 9
Training loss: 2.4386623252230724
Validation loss: 2.859223826492858

Epoch: 5| Step: 10
Training loss: 2.716873837004124
Validation loss: 2.8667072686279322

Epoch: 77| Step: 0
Training loss: 3.3630342647588924
Validation loss: 2.9328918687899486

Epoch: 5| Step: 1
Training loss: 2.7879742548231397
Validation loss: 2.9345617739211427

Epoch: 5| Step: 2
Training loss: 2.9936014923022665
Validation loss: 2.945714394854998

Epoch: 5| Step: 3
Training loss: 2.8167243597980245
Validation loss: 2.9622878609335648

Epoch: 5| Step: 4
Training loss: 3.3956670583882835
Validation loss: 3.017722845597824

Epoch: 5| Step: 5
Training loss: 3.198652317453277
Validation loss: 3.0220681987240905

Epoch: 5| Step: 6
Training loss: 3.959824625813586
Validation loss: 2.9673268307695086

Epoch: 5| Step: 7
Training loss: 3.766818795184392
Validation loss: 2.9292520345187287

Epoch: 5| Step: 8
Training loss: 3.4378137618701383
Validation loss: 2.927059644833076

Epoch: 5| Step: 9
Training loss: 2.9740088214140576
Validation loss: 2.9240356146349855

Epoch: 5| Step: 10
Training loss: 2.6028188243747454
Validation loss: 2.8983751657413084

Epoch: 78| Step: 0
Training loss: 3.5993499910784403
Validation loss: 2.897889756646975

Epoch: 5| Step: 1
Training loss: 3.3510684914187725
Validation loss: 2.8786194922142996

Epoch: 5| Step: 2
Training loss: 2.6871117599749557
Validation loss: 2.8505992962373283

Epoch: 5| Step: 3
Training loss: 3.6490223189194344
Validation loss: 2.8583537402345813

Epoch: 5| Step: 4
Training loss: 3.119741975434208
Validation loss: 2.867867383506569

Epoch: 5| Step: 5
Training loss: 2.800725406957237
Validation loss: 2.8829255969914134

Epoch: 5| Step: 6
Training loss: 3.2794382088736347
Validation loss: 2.896895209439946

Epoch: 5| Step: 7
Training loss: 2.9415398272292324
Validation loss: 2.9031596809750386

Epoch: 5| Step: 8
Training loss: 2.9188794779189173
Validation loss: 2.9075703077968194

Epoch: 5| Step: 9
Training loss: 3.0498311105463602
Validation loss: 2.9074211270580412

Epoch: 5| Step: 10
Training loss: 3.301434442119115
Validation loss: 2.9129097158970914

Epoch: 79| Step: 0
Training loss: 3.5571227063797206
Validation loss: 2.8904536335309685

Epoch: 5| Step: 1
Training loss: 2.4361598903692863
Validation loss: 2.8712569084850266

Epoch: 5| Step: 2
Training loss: 3.006501781681966
Validation loss: 2.8607224875061186

Epoch: 5| Step: 3
Training loss: 3.4174964796493246
Validation loss: 2.8543157677043642

Epoch: 5| Step: 4
Training loss: 2.6453297253412336
Validation loss: 2.8444357280422468

Epoch: 5| Step: 5
Training loss: 3.083906137683188
Validation loss: 2.8394835411048227

Epoch: 5| Step: 6
Training loss: 3.425233351283119
Validation loss: 2.842020399716382

Epoch: 5| Step: 7
Training loss: 3.326575406516693
Validation loss: 2.835515049713235

Epoch: 5| Step: 8
Training loss: 2.8358875617052024
Validation loss: 2.8377982403469826

Epoch: 5| Step: 9
Training loss: 3.3252495177299966
Validation loss: 2.832712037180014

Epoch: 5| Step: 10
Training loss: 3.307794936128529
Validation loss: 2.829185436144896

Epoch: 80| Step: 0
Training loss: 3.299047974329302
Validation loss: 2.831156253147756

Epoch: 5| Step: 1
Training loss: 3.2067853157262065
Validation loss: 2.834080312321198

Epoch: 5| Step: 2
Training loss: 3.7898091947088584
Validation loss: 2.834417218761971

Epoch: 5| Step: 3
Training loss: 2.7141483870880325
Validation loss: 2.835552555902728

Epoch: 5| Step: 4
Training loss: 3.1632987902101535
Validation loss: 2.8340603609258053

Epoch: 5| Step: 5
Training loss: 3.1878265512779573
Validation loss: 2.8344573614960233

Epoch: 5| Step: 6
Training loss: 2.6043067182392354
Validation loss: 2.833022253149551

Epoch: 5| Step: 7
Training loss: 2.774593144739504
Validation loss: 2.832125399633109

Epoch: 5| Step: 8
Training loss: 2.26930001897972
Validation loss: 2.8326947957288042

Epoch: 5| Step: 9
Training loss: 3.3889430220680503
Validation loss: 2.8298579918434243

Epoch: 5| Step: 10
Training loss: 3.932179080117694
Validation loss: 2.8328210845977013

Epoch: 81| Step: 0
Training loss: 3.119649655650298
Validation loss: 2.8288711092145995

Epoch: 5| Step: 1
Training loss: 3.6439830044665165
Validation loss: 2.8281940929253846

Epoch: 5| Step: 2
Training loss: 2.9640293535743023
Validation loss: 2.8297943009373707

Epoch: 5| Step: 3
Training loss: 3.1677715649367886
Validation loss: 2.829265628477975

Epoch: 5| Step: 4
Training loss: 2.8049755745434575
Validation loss: 2.8276007771564005

Epoch: 5| Step: 5
Training loss: 2.9958300219549803
Validation loss: 2.8268651318584013

Epoch: 5| Step: 6
Training loss: 2.8279295795850867
Validation loss: 2.827738924380953

Epoch: 5| Step: 7
Training loss: 3.1548161035013784
Validation loss: 2.8344231403100046

Epoch: 5| Step: 8
Training loss: 3.2915516764840325
Validation loss: 2.834985579428141

Epoch: 5| Step: 9
Training loss: 3.009461582479241
Validation loss: 2.832478470899106

Epoch: 5| Step: 10
Training loss: 3.474928842817718
Validation loss: 2.8199106243198497

Epoch: 82| Step: 0
Training loss: 2.752373104929678
Validation loss: 2.821304311877118

Epoch: 5| Step: 1
Training loss: 3.353992212785792
Validation loss: 2.821415387590694

Epoch: 5| Step: 2
Training loss: 3.1895371453454002
Validation loss: 2.8234233418900816

Epoch: 5| Step: 3
Training loss: 3.5611909837207802
Validation loss: 2.8148812908544176

Epoch: 5| Step: 4
Training loss: 2.5747142077613097
Validation loss: 2.810159751900422

Epoch: 5| Step: 5
Training loss: 2.7171126071815612
Validation loss: 2.815922922743121

Epoch: 5| Step: 6
Training loss: 3.2981310435968587
Validation loss: 2.814138821461409

Epoch: 5| Step: 7
Training loss: 3.1418864435549443
Validation loss: 2.8147784339254645

Epoch: 5| Step: 8
Training loss: 2.81077200469731
Validation loss: 2.8137924169038864

Epoch: 5| Step: 9
Training loss: 3.4122306745396815
Validation loss: 2.812218614400534

Epoch: 5| Step: 10
Training loss: 3.4676527057623234
Validation loss: 2.81015530181572

Epoch: 83| Step: 0
Training loss: 3.240266308848441
Validation loss: 2.8139400209300502

Epoch: 5| Step: 1
Training loss: 2.794670984082248
Validation loss: 2.8058979238819997

Epoch: 5| Step: 2
Training loss: 3.235146840461141
Validation loss: 2.8056472953656666

Epoch: 5| Step: 3
Training loss: 3.3626032022854715
Validation loss: 2.80614952033402

Epoch: 5| Step: 4
Training loss: 2.5097119514871133
Validation loss: 2.8053802284644576

Epoch: 5| Step: 5
Training loss: 3.3371624093640047
Validation loss: 2.8072445496194356

Epoch: 5| Step: 6
Training loss: 2.7952883178279047
Validation loss: 2.8026694383845285

Epoch: 5| Step: 7
Training loss: 2.8002825390090207
Validation loss: 2.801459999772292

Epoch: 5| Step: 8
Training loss: 3.6999758436084598
Validation loss: 2.804984876831634

Epoch: 5| Step: 9
Training loss: 3.2207451719890265
Validation loss: 2.802074556938895

Epoch: 5| Step: 10
Training loss: 3.1924047693971893
Validation loss: 2.8072672486016184

Epoch: 84| Step: 0
Training loss: 3.3010047250070764
Validation loss: 2.8062957015775276

Epoch: 5| Step: 1
Training loss: 3.7258804304888535
Validation loss: 2.8044145985888527

Epoch: 5| Step: 2
Training loss: 3.443865898383647
Validation loss: 2.807133519582861

Epoch: 5| Step: 3
Training loss: 3.0780985100085565
Validation loss: 2.806797830162911

Epoch: 5| Step: 4
Training loss: 3.117766744769801
Validation loss: 2.807228488718422

Epoch: 5| Step: 5
Training loss: 3.109476059081258
Validation loss: 2.808482698451182

Epoch: 5| Step: 6
Training loss: 2.893476080237108
Validation loss: 2.808896369198947

Epoch: 5| Step: 7
Training loss: 2.789086435252688
Validation loss: 2.8079044218867795

Epoch: 5| Step: 8
Training loss: 3.317705490773818
Validation loss: 2.8043643828017677

Epoch: 5| Step: 9
Training loss: 2.295473151041436
Validation loss: 2.8036544030088133

Epoch: 5| Step: 10
Training loss: 3.0778397945975837
Validation loss: 2.807972249382859

Epoch: 85| Step: 0
Training loss: 3.253954022664766
Validation loss: 2.802905565484482

Epoch: 5| Step: 1
Training loss: 3.6080384525271554
Validation loss: 2.804189556853459

Epoch: 5| Step: 2
Training loss: 2.341305487892231
Validation loss: 2.8047069848579733

Epoch: 5| Step: 3
Training loss: 3.7780538875680643
Validation loss: 2.8016110444703135

Epoch: 5| Step: 4
Training loss: 3.399568356434505
Validation loss: 2.800770537866115

Epoch: 5| Step: 5
Training loss: 3.1554795637368094
Validation loss: 2.800834649875089

Epoch: 5| Step: 6
Training loss: 2.7768470116062747
Validation loss: 2.8017091298048844

Epoch: 5| Step: 7
Training loss: 2.827054658958466
Validation loss: 2.8020507838666595

Epoch: 5| Step: 8
Training loss: 2.8921898807328295
Validation loss: 2.8018673079573064

Epoch: 5| Step: 9
Training loss: 2.9326911685744164
Validation loss: 2.798584244876481

Epoch: 5| Step: 10
Training loss: 3.048235936542495
Validation loss: 2.7972572254762134

Epoch: 86| Step: 0
Training loss: 3.0925896520425096
Validation loss: 2.797970818638078

Epoch: 5| Step: 1
Training loss: 2.8034524987831255
Validation loss: 2.7955400016101732

Epoch: 5| Step: 2
Training loss: 3.3398967181015418
Validation loss: 2.7976535426887983

Epoch: 5| Step: 3
Training loss: 2.964219983893746
Validation loss: 2.7937507615996036

Epoch: 5| Step: 4
Training loss: 3.5600840089293913
Validation loss: 2.796270830789001

Epoch: 5| Step: 5
Training loss: 3.3614220348408317
Validation loss: 2.800169837652671

Epoch: 5| Step: 6
Training loss: 2.6135809345926635
Validation loss: 2.7947049701023987

Epoch: 5| Step: 7
Training loss: 3.7155576194512063
Validation loss: 2.7935940225658116

Epoch: 5| Step: 8
Training loss: 3.059153226737857
Validation loss: 2.7991249749075062

Epoch: 5| Step: 9
Training loss: 3.091832346902487
Validation loss: 2.7970285919431683

Epoch: 5| Step: 10
Training loss: 2.1891855557888555
Validation loss: 2.801603229851791

Epoch: 87| Step: 0
Training loss: 3.1875565467755393
Validation loss: 2.7980010116599243

Epoch: 5| Step: 1
Training loss: 2.7550892122089667
Validation loss: 2.802084854210345

Epoch: 5| Step: 2
Training loss: 2.5882952219099193
Validation loss: 2.7992060705489994

Epoch: 5| Step: 3
Training loss: 3.454194882733577
Validation loss: 2.7990942600502473

Epoch: 5| Step: 4
Training loss: 3.4346698554579027
Validation loss: 2.7966123384153265

Epoch: 5| Step: 5
Training loss: 3.130656806356227
Validation loss: 2.7970977124400487

Epoch: 5| Step: 6
Training loss: 3.2266378694095215
Validation loss: 2.7946473525971784

Epoch: 5| Step: 7
Training loss: 3.1611715791085238
Validation loss: 2.7922101101779107

Epoch: 5| Step: 8
Training loss: 2.425860073510515
Validation loss: 2.79004924614857

Epoch: 5| Step: 9
Training loss: 3.456083385459404
Validation loss: 2.7905272018117784

Epoch: 5| Step: 10
Training loss: 3.175151767257305
Validation loss: 2.7880451225050495

Epoch: 88| Step: 0
Training loss: 3.509173089025076
Validation loss: 2.788907584128919

Epoch: 5| Step: 1
Training loss: 2.992875540488527
Validation loss: 2.7888458159508924

Epoch: 5| Step: 2
Training loss: 2.968384248388598
Validation loss: 2.787858937199221

Epoch: 5| Step: 3
Training loss: 3.259630167291168
Validation loss: 2.7884893088319176

Epoch: 5| Step: 4
Training loss: 2.623838894498099
Validation loss: 2.7838741881052327

Epoch: 5| Step: 5
Training loss: 3.3340673274317147
Validation loss: 2.785881894764676

Epoch: 5| Step: 6
Training loss: 2.9004161075795545
Validation loss: 2.785921834122297

Epoch: 5| Step: 7
Training loss: 2.695904033820624
Validation loss: 2.786545429281201

Epoch: 5| Step: 8
Training loss: 3.1477525595490286
Validation loss: 2.7834055512522737

Epoch: 5| Step: 9
Training loss: 3.502012355492896
Validation loss: 2.7844274238317603

Epoch: 5| Step: 10
Training loss: 3.0370030816910085
Validation loss: 2.7866578610392922

Epoch: 89| Step: 0
Training loss: 2.637260776898066
Validation loss: 2.782632663584306

Epoch: 5| Step: 1
Training loss: 3.8275765162318915
Validation loss: 2.7843470901035663

Epoch: 5| Step: 2
Training loss: 2.719468295917421
Validation loss: 2.7849990429181326

Epoch: 5| Step: 3
Training loss: 3.0326833580543364
Validation loss: 2.7839764675863865

Epoch: 5| Step: 4
Training loss: 3.5038847481398516
Validation loss: 2.780035172316173

Epoch: 5| Step: 5
Training loss: 2.7941934528047225
Validation loss: 2.7824552274435885

Epoch: 5| Step: 6
Training loss: 2.6792836232461776
Validation loss: 2.781161795537106

Epoch: 5| Step: 7
Training loss: 2.6846864743875174
Validation loss: 2.779876458306122

Epoch: 5| Step: 8
Training loss: 3.0322878918918574
Validation loss: 2.7805076143855727

Epoch: 5| Step: 9
Training loss: 3.711280822934272
Validation loss: 2.7797146530174914

Epoch: 5| Step: 10
Training loss: 3.182440088851386
Validation loss: 2.78144295237323

Epoch: 90| Step: 0
Training loss: 3.1714735857642258
Validation loss: 2.784750714860095

Epoch: 5| Step: 1
Training loss: 3.297850550368145
Validation loss: 2.7817918692740853

Epoch: 5| Step: 2
Training loss: 2.6514723052654348
Validation loss: 2.78059258318142

Epoch: 5| Step: 3
Training loss: 3.280574038678962
Validation loss: 2.7776056950771624

Epoch: 5| Step: 4
Training loss: 3.4699311865763556
Validation loss: 2.78003106500705

Epoch: 5| Step: 5
Training loss: 2.8461116165073648
Validation loss: 2.7771598159987128

Epoch: 5| Step: 6
Training loss: 2.7090810966139434
Validation loss: 2.77623540149214

Epoch: 5| Step: 7
Training loss: 2.68418591225266
Validation loss: 2.774547324692304

Epoch: 5| Step: 8
Training loss: 3.3563423129835592
Validation loss: 2.7734336722435793

Epoch: 5| Step: 9
Training loss: 3.3634057282242007
Validation loss: 2.774401000387238

Epoch: 5| Step: 10
Training loss: 3.0083414776833592
Validation loss: 2.7721865934069125

Epoch: 91| Step: 0
Training loss: 2.778763849289977
Validation loss: 2.7721758567828028

Epoch: 5| Step: 1
Training loss: 3.4416749050482056
Validation loss: 2.7716305591476673

Epoch: 5| Step: 2
Training loss: 3.138935906462241
Validation loss: 2.771136941189291

Epoch: 5| Step: 3
Training loss: 2.953618084144818
Validation loss: 2.769447348877881

Epoch: 5| Step: 4
Training loss: 2.6824978252306084
Validation loss: 2.7710914627279877

Epoch: 5| Step: 5
Training loss: 2.6743265248947017
Validation loss: 2.7668341335292896

Epoch: 5| Step: 6
Training loss: 3.7295966442150337
Validation loss: 2.7753226506054607

Epoch: 5| Step: 7
Training loss: 2.7747072563752635
Validation loss: 2.778532799960079

Epoch: 5| Step: 8
Training loss: 2.899307655034222
Validation loss: 2.771006500497813

Epoch: 5| Step: 9
Training loss: 3.2247877065883697
Validation loss: 2.772205195133973

Epoch: 5| Step: 10
Training loss: 3.5167040715932645
Validation loss: 2.771277646871691

Epoch: 92| Step: 0
Training loss: 3.2407685265535697
Validation loss: 2.7674775460756087

Epoch: 5| Step: 1
Training loss: 2.9779767058558595
Validation loss: 2.766857590248445

Epoch: 5| Step: 2
Training loss: 3.0419213349493472
Validation loss: 2.765918460045566

Epoch: 5| Step: 3
Training loss: 2.9830522252062743
Validation loss: 2.7665703285695233

Epoch: 5| Step: 4
Training loss: 2.891381242134237
Validation loss: 2.7673466420099144

Epoch: 5| Step: 5
Training loss: 2.960572877038143
Validation loss: 2.7639605337889663

Epoch: 5| Step: 6
Training loss: 3.3892065500376867
Validation loss: 2.7648294763631522

Epoch: 5| Step: 7
Training loss: 3.363573582225011
Validation loss: 2.7684259188570026

Epoch: 5| Step: 8
Training loss: 2.4033140626505998
Validation loss: 2.767902232755943

Epoch: 5| Step: 9
Training loss: 3.2703049996367946
Validation loss: 2.76932820302847

Epoch: 5| Step: 10
Training loss: 3.3299609927163853
Validation loss: 2.772231348313018

Epoch: 93| Step: 0
Training loss: 3.096898798076447
Validation loss: 2.7780900448116745

Epoch: 5| Step: 1
Training loss: 3.628488506339411
Validation loss: 2.8022357243400435

Epoch: 5| Step: 2
Training loss: 3.040108860977955
Validation loss: 2.7933351113084686

Epoch: 5| Step: 3
Training loss: 3.2961694043707115
Validation loss: 2.7748331410932225

Epoch: 5| Step: 4
Training loss: 3.239605346474061
Validation loss: 2.772184071552428

Epoch: 5| Step: 5
Training loss: 3.3381670395989977
Validation loss: 2.765755487794263

Epoch: 5| Step: 6
Training loss: 2.4202180177829176
Validation loss: 2.7664926561928165

Epoch: 5| Step: 7
Training loss: 2.6377334563722004
Validation loss: 2.7618885795956833

Epoch: 5| Step: 8
Training loss: 2.9715542047529047
Validation loss: 2.7602913005932104

Epoch: 5| Step: 9
Training loss: 2.9575862388903613
Validation loss: 2.7620495106451495

Epoch: 5| Step: 10
Training loss: 3.100032246329656
Validation loss: 2.762741652033643

Epoch: 94| Step: 0
Training loss: 3.3071503536441895
Validation loss: 2.7635847310348303

Epoch: 5| Step: 1
Training loss: 2.993063218376655
Validation loss: 2.762146874477843

Epoch: 5| Step: 2
Training loss: 3.269871629067578
Validation loss: 2.7650388496605594

Epoch: 5| Step: 3
Training loss: 3.2315860831758876
Validation loss: 2.7621731841486525

Epoch: 5| Step: 4
Training loss: 2.830975018551747
Validation loss: 2.765245754017461

Epoch: 5| Step: 5
Training loss: 2.641649758398134
Validation loss: 2.7662097944590176

Epoch: 5| Step: 6
Training loss: 3.149371214582557
Validation loss: 2.765808958648222

Epoch: 5| Step: 7
Training loss: 2.939777870869449
Validation loss: 2.763198660475458

Epoch: 5| Step: 8
Training loss: 3.101401682799455
Validation loss: 2.7645990215856364

Epoch: 5| Step: 9
Training loss: 3.2887000384825664
Validation loss: 2.757673324470345

Epoch: 5| Step: 10
Training loss: 3.175969079575774
Validation loss: 2.759900378476821

Epoch: 95| Step: 0
Training loss: 2.9658416958296474
Validation loss: 2.7584136323536557

Epoch: 5| Step: 1
Training loss: 3.1831686473275496
Validation loss: 2.7587679950978

Epoch: 5| Step: 2
Training loss: 2.694170635333345
Validation loss: 2.7587724212077784

Epoch: 5| Step: 3
Training loss: 3.474206979404392
Validation loss: 2.7545962317972257

Epoch: 5| Step: 4
Training loss: 2.6751045206631026
Validation loss: 2.755600464712702

Epoch: 5| Step: 5
Training loss: 3.0882897791610815
Validation loss: 2.7554422468402255

Epoch: 5| Step: 6
Training loss: 2.9232779821754513
Validation loss: 2.752901118744372

Epoch: 5| Step: 7
Training loss: 3.2935731091131473
Validation loss: 2.754878302902484

Epoch: 5| Step: 8
Training loss: 2.9936290485581365
Validation loss: 2.756434841606972

Epoch: 5| Step: 9
Training loss: 3.2791507363487846
Validation loss: 2.7519945348972485

Epoch: 5| Step: 10
Training loss: 3.2574357288311644
Validation loss: 2.7569222533095923

Epoch: 96| Step: 0
Training loss: 3.7952603647130605
Validation loss: 2.7544225572540424

Epoch: 5| Step: 1
Training loss: 3.095276581172131
Validation loss: 2.757845738293818

Epoch: 5| Step: 2
Training loss: 3.254198297077432
Validation loss: 2.7582132273239846

Epoch: 5| Step: 3
Training loss: 3.0204915522012215
Validation loss: 2.7574658203118956

Epoch: 5| Step: 4
Training loss: 2.5224943022195756
Validation loss: 2.759055121831898

Epoch: 5| Step: 5
Training loss: 2.9338980160120385
Validation loss: 2.7565168313942614

Epoch: 5| Step: 6
Training loss: 3.280797582045108
Validation loss: 2.7607822556119572

Epoch: 5| Step: 7
Training loss: 2.2915787651080937
Validation loss: 2.7624085817628283

Epoch: 5| Step: 8
Training loss: 3.1677945955810456
Validation loss: 2.7693216840544514

Epoch: 5| Step: 9
Training loss: 3.4030584379610254
Validation loss: 2.7622283160506425

Epoch: 5| Step: 10
Training loss: 2.6736389048619316
Validation loss: 2.76086170759588

Epoch: 97| Step: 0
Training loss: 3.4603323310498073
Validation loss: 2.7610445109984925

Epoch: 5| Step: 1
Training loss: 2.8116462259354207
Validation loss: 2.756253211364371

Epoch: 5| Step: 2
Training loss: 2.989099088964342
Validation loss: 2.75389868447882

Epoch: 5| Step: 3
Training loss: 2.987047526678433
Validation loss: 2.752808914084916

Epoch: 5| Step: 4
Training loss: 2.7970996105853767
Validation loss: 2.7462732311285976

Epoch: 5| Step: 5
Training loss: 3.102668315247132
Validation loss: 2.7451559876012284

Epoch: 5| Step: 6
Training loss: 3.1417413501986204
Validation loss: 2.744719151046473

Epoch: 5| Step: 7
Training loss: 2.737821749935106
Validation loss: 2.7440731685636988

Epoch: 5| Step: 8
Training loss: 3.0197321145189404
Validation loss: 2.7435568469881084

Epoch: 5| Step: 9
Training loss: 3.2887919625041406
Validation loss: 2.740754453196773

Epoch: 5| Step: 10
Training loss: 3.346472229216972
Validation loss: 2.7438544667665767

Epoch: 98| Step: 0
Training loss: 2.7432276826015207
Validation loss: 2.7420258940835827

Epoch: 5| Step: 1
Training loss: 2.882018768291791
Validation loss: 2.7415576500464356

Epoch: 5| Step: 2
Training loss: 3.781653768876936
Validation loss: 2.7415990308770937

Epoch: 5| Step: 3
Training loss: 3.621401348855466
Validation loss: 2.7380498809104763

Epoch: 5| Step: 4
Training loss: 2.5950328917430925
Validation loss: 2.739575924148438

Epoch: 5| Step: 5
Training loss: 2.8505626859170756
Validation loss: 2.739910054938275

Epoch: 5| Step: 6
Training loss: 3.4842670235774635
Validation loss: 2.7375003683775754

Epoch: 5| Step: 7
Training loss: 2.868340782615421
Validation loss: 2.739554050201247

Epoch: 5| Step: 8
Training loss: 2.3564716184296293
Validation loss: 2.7377932042519535

Epoch: 5| Step: 9
Training loss: 2.9925528918239306
Validation loss: 2.7383132208769845

Epoch: 5| Step: 10
Training loss: 3.182675469079355
Validation loss: 2.735905254770857

Epoch: 99| Step: 0
Training loss: 3.229808144791366
Validation loss: 2.7394474469499848

Epoch: 5| Step: 1
Training loss: 3.290390507674304
Validation loss: 2.741250079999989

Epoch: 5| Step: 2
Training loss: 3.889034329071333
Validation loss: 2.7439440853658827

Epoch: 5| Step: 3
Training loss: 2.8231330779244868
Validation loss: 2.7409376333175874

Epoch: 5| Step: 4
Training loss: 3.2074115634539218
Validation loss: 2.7371040135377296

Epoch: 5| Step: 5
Training loss: 2.816243710635731
Validation loss: 2.7311290445077763

Epoch: 5| Step: 6
Training loss: 3.1091607561534964
Validation loss: 2.7336995827363118

Epoch: 5| Step: 7
Training loss: 2.7435409813863965
Validation loss: 2.731533931365875

Epoch: 5| Step: 8
Training loss: 3.0580177982827794
Validation loss: 2.7332166711635297

Epoch: 5| Step: 9
Training loss: 2.372256049104356
Validation loss: 2.7315189889067213

Epoch: 5| Step: 10
Training loss: 2.905722785628627
Validation loss: 2.733782870494928

Epoch: 100| Step: 0
Training loss: 2.811361124667376
Validation loss: 2.732008453882752

Epoch: 5| Step: 1
Training loss: 3.1779033332272575
Validation loss: 2.730564535029676

Epoch: 5| Step: 2
Training loss: 2.635667650738409
Validation loss: 2.73095430281995

Epoch: 5| Step: 3
Training loss: 3.3405808020327346
Validation loss: 2.730463555993116

Epoch: 5| Step: 4
Training loss: 3.026745940219182
Validation loss: 2.7308083970733894

Epoch: 5| Step: 5
Training loss: 3.4146959777710033
Validation loss: 2.7324675720564557

Epoch: 5| Step: 6
Training loss: 2.6816024833128274
Validation loss: 2.7280036391363667

Epoch: 5| Step: 7
Training loss: 2.8902770786711263
Validation loss: 2.7344976432239223

Epoch: 5| Step: 8
Training loss: 3.1404286792942595
Validation loss: 2.7265314303202026

Epoch: 5| Step: 9
Training loss: 3.106399415872437
Validation loss: 2.7285758716588404

Epoch: 5| Step: 10
Training loss: 3.280297277283868
Validation loss: 2.7292862970590623

Epoch: 101| Step: 0
Training loss: 3.5134672197555616
Validation loss: 2.7298069537632563

Epoch: 5| Step: 1
Training loss: 2.728938949830251
Validation loss: 2.73335008671106

Epoch: 5| Step: 2
Training loss: 2.9513479870723307
Validation loss: 2.73242482104114

Epoch: 5| Step: 3
Training loss: 3.068350983140179
Validation loss: 2.732988156443969

Epoch: 5| Step: 4
Training loss: 3.364193888861132
Validation loss: 2.731341004896447

Epoch: 5| Step: 5
Training loss: 3.0630710614337007
Validation loss: 2.729830427189498

Epoch: 5| Step: 6
Training loss: 3.0685853249675894
Validation loss: 2.727306449348536

Epoch: 5| Step: 7
Training loss: 2.617054312434298
Validation loss: 2.7302423151755684

Epoch: 5| Step: 8
Training loss: 3.034976516959578
Validation loss: 2.7243505757163926

Epoch: 5| Step: 9
Training loss: 2.7095192489151465
Validation loss: 2.7260537566570266

Epoch: 5| Step: 10
Training loss: 3.486446295266197
Validation loss: 2.72628377038665

Epoch: 102| Step: 0
Training loss: 3.233940058410422
Validation loss: 2.7257286653986794

Epoch: 5| Step: 1
Training loss: 3.402587881866278
Validation loss: 2.723309619046874

Epoch: 5| Step: 2
Training loss: 2.6479739343276516
Validation loss: 2.7213940679858615

Epoch: 5| Step: 3
Training loss: 3.2363282723389375
Validation loss: 2.720973567938295

Epoch: 5| Step: 4
Training loss: 2.427063828636896
Validation loss: 2.721883606528888

Epoch: 5| Step: 5
Training loss: 2.7765385014361454
Validation loss: 2.722044053761605

Epoch: 5| Step: 6
Training loss: 2.729575342539228
Validation loss: 2.723597951852936

Epoch: 5| Step: 7
Training loss: 2.935105504441806
Validation loss: 2.735069741210279

Epoch: 5| Step: 8
Training loss: 3.6563382912433315
Validation loss: 2.757892141650783

Epoch: 5| Step: 9
Training loss: 3.111381151953179
Validation loss: 2.7237856920079273

Epoch: 5| Step: 10
Training loss: 3.2455734037855857
Validation loss: 2.7187928830636663

Epoch: 103| Step: 0
Training loss: 2.9562066363325785
Validation loss: 2.717218882804134

Epoch: 5| Step: 1
Training loss: 3.104361321066051
Validation loss: 2.721635020658028

Epoch: 5| Step: 2
Training loss: 2.789061816132619
Validation loss: 2.718708459039124

Epoch: 5| Step: 3
Training loss: 2.809941208655415
Validation loss: 2.7359913669877676

Epoch: 5| Step: 4
Training loss: 3.1493695491040317
Validation loss: 2.738229993208485

Epoch: 5| Step: 5
Training loss: 3.721802940920231
Validation loss: 2.7234634344806086

Epoch: 5| Step: 6
Training loss: 3.0846094291669037
Validation loss: 2.7178568265738443

Epoch: 5| Step: 7
Training loss: 2.4759784575404913
Validation loss: 2.716660279790468

Epoch: 5| Step: 8
Training loss: 2.8776857850710695
Validation loss: 2.725353844330644

Epoch: 5| Step: 9
Training loss: 3.0192550394670485
Validation loss: 2.730994360198716

Epoch: 5| Step: 10
Training loss: 3.399316292627713
Validation loss: 2.732225117296681

Epoch: 104| Step: 0
Training loss: 2.2026796364244605
Validation loss: 2.749435937482799

Epoch: 5| Step: 1
Training loss: 3.2583926482464456
Validation loss: 2.7569848343476937

Epoch: 5| Step: 2
Training loss: 3.0305467556706107
Validation loss: 2.750348070029949

Epoch: 5| Step: 3
Training loss: 3.301964758700522
Validation loss: 2.754967330260391

Epoch: 5| Step: 4
Training loss: 2.89052618734193
Validation loss: 2.7414711169919626

Epoch: 5| Step: 5
Training loss: 3.2518069306008632
Validation loss: 2.735214927574369

Epoch: 5| Step: 6
Training loss: 2.9762962402443045
Validation loss: 2.7230045897713606

Epoch: 5| Step: 7
Training loss: 3.5184019523035786
Validation loss: 2.713306074693622

Epoch: 5| Step: 8
Training loss: 2.8194059568721204
Validation loss: 2.710773739796857

Epoch: 5| Step: 9
Training loss: 3.153544408845706
Validation loss: 2.7114194771520137

Epoch: 5| Step: 10
Training loss: 2.893666085330357
Validation loss: 2.705758981361707

Epoch: 105| Step: 0
Training loss: 3.019547989220258
Validation loss: 2.704928895719654

Epoch: 5| Step: 1
Training loss: 3.449710452327125
Validation loss: 2.7062113082026933

Epoch: 5| Step: 2
Training loss: 3.4229926805342736
Validation loss: 2.6991956191694384

Epoch: 5| Step: 3
Training loss: 2.872263559781404
Validation loss: 2.7060446472321575

Epoch: 5| Step: 4
Training loss: 3.3222825612259377
Validation loss: 2.699938854161699

Epoch: 5| Step: 5
Training loss: 3.368413361270807
Validation loss: 2.7006439302124647

Epoch: 5| Step: 6
Training loss: 2.2652657059530332
Validation loss: 2.701619017233961

Epoch: 5| Step: 7
Training loss: 2.554710831375207
Validation loss: 2.7039006344025402

Epoch: 5| Step: 8
Training loss: 2.9255995241982062
Validation loss: 2.7015948726142365

Epoch: 5| Step: 9
Training loss: 3.35190706771542
Validation loss: 2.703775492991958

Epoch: 5| Step: 10
Training loss: 2.5166133100230277
Validation loss: 2.701384709277102

Epoch: 106| Step: 0
Training loss: 2.5015310367699986
Validation loss: 2.7050784358502016

Epoch: 5| Step: 1
Training loss: 2.9691483079840735
Validation loss: 2.707300846633341

Epoch: 5| Step: 2
Training loss: 3.035306595425718
Validation loss: 2.703777235729098

Epoch: 5| Step: 3
Training loss: 2.602824686777359
Validation loss: 2.708227771440349

Epoch: 5| Step: 4
Training loss: 3.0336222067418523
Validation loss: 2.7107687865689654

Epoch: 5| Step: 5
Training loss: 3.1916288674077546
Validation loss: 2.7153317484814834

Epoch: 5| Step: 6
Training loss: 3.41142146355116
Validation loss: 2.7014966474120325

Epoch: 5| Step: 7
Training loss: 2.9960907260924277
Validation loss: 2.703677355546027

Epoch: 5| Step: 8
Training loss: 2.886677619114538
Validation loss: 2.698878486263908

Epoch: 5| Step: 9
Training loss: 3.2509162784944605
Validation loss: 2.6937859005702403

Epoch: 5| Step: 10
Training loss: 3.335791412656805
Validation loss: 2.6915315740889483

Epoch: 107| Step: 0
Training loss: 3.200450543634595
Validation loss: 2.693122600708686

Epoch: 5| Step: 1
Training loss: 3.105039554902998
Validation loss: 2.6961409023519

Epoch: 5| Step: 2
Training loss: 3.541715524373862
Validation loss: 2.6948464286548393

Epoch: 5| Step: 3
Training loss: 3.098727605014769
Validation loss: 2.6951665595351018

Epoch: 5| Step: 4
Training loss: 2.781306919844167
Validation loss: 2.694620576692148

Epoch: 5| Step: 5
Training loss: 2.8739539192131702
Validation loss: 2.695336703750155

Epoch: 5| Step: 6
Training loss: 2.400035114826173
Validation loss: 2.6946239236873546

Epoch: 5| Step: 7
Training loss: 3.2575083345905282
Validation loss: 2.692882613524277

Epoch: 5| Step: 8
Training loss: 2.8958396271195843
Validation loss: 2.6930400583520675

Epoch: 5| Step: 9
Training loss: 3.533077341079144
Validation loss: 2.687897649194186

Epoch: 5| Step: 10
Training loss: 2.339451522941251
Validation loss: 2.6900223163423633

Epoch: 108| Step: 0
Training loss: 2.764054364267369
Validation loss: 2.6942304111010857

Epoch: 5| Step: 1
Training loss: 2.7528632603561163
Validation loss: 2.695698878014226

Epoch: 5| Step: 2
Training loss: 3.521799455321586
Validation loss: 2.7180068608489822

Epoch: 5| Step: 3
Training loss: 3.1157728154386928
Validation loss: 2.742215277278094

Epoch: 5| Step: 4
Training loss: 2.883451230793788
Validation loss: 2.769019625441013

Epoch: 5| Step: 5
Training loss: 2.7221793984485383
Validation loss: 2.824083900105822

Epoch: 5| Step: 6
Training loss: 3.1162352673074825
Validation loss: 2.7894000214005072

Epoch: 5| Step: 7
Training loss: 3.093899964059902
Validation loss: 2.70489714156887

Epoch: 5| Step: 8
Training loss: 3.308000207331327
Validation loss: 2.6947575565428306

Epoch: 5| Step: 9
Training loss: 3.149423752407574
Validation loss: 2.7026752138257284

Epoch: 5| Step: 10
Training loss: 2.988731838986411
Validation loss: 2.701707061564832

Epoch: 109| Step: 0
Training loss: 2.700234162808215
Validation loss: 2.7282350295332525

Epoch: 5| Step: 1
Training loss: 3.0789474705238344
Validation loss: 2.7551262807236654

Epoch: 5| Step: 2
Training loss: 3.330121941152356
Validation loss: 2.7803612552213997

Epoch: 5| Step: 3
Training loss: 3.412794353379927
Validation loss: 2.696997441535789

Epoch: 5| Step: 4
Training loss: 3.0858773913746425
Validation loss: 2.693709061705091

Epoch: 5| Step: 5
Training loss: 2.9527879956621774
Validation loss: 2.7053778987856707

Epoch: 5| Step: 6
Training loss: 2.78864342883
Validation loss: 2.7337097465032936

Epoch: 5| Step: 7
Training loss: 2.5378765446943277
Validation loss: 2.78970204573513

Epoch: 5| Step: 8
Training loss: 2.9761972278336737
Validation loss: 2.819258480340073

Epoch: 5| Step: 9
Training loss: 3.139825671756863
Validation loss: 2.853527070781445

Epoch: 5| Step: 10
Training loss: 3.5092084184414096
Validation loss: 2.856187986877086

Epoch: 110| Step: 0
Training loss: 2.6999055068823705
Validation loss: 2.793932186629114

Epoch: 5| Step: 1
Training loss: 3.1041697730405144
Validation loss: 2.7621488820295523

Epoch: 5| Step: 2
Training loss: 2.698223101520446
Validation loss: 2.723813383058644

Epoch: 5| Step: 3
Training loss: 2.9727743077739586
Validation loss: 2.685244823365267

Epoch: 5| Step: 4
Training loss: 3.5885611848711005
Validation loss: 2.6759773754378253

Epoch: 5| Step: 5
Training loss: 3.2032442396346306
Validation loss: 2.682942421036358

Epoch: 5| Step: 6
Training loss: 3.039959380480789
Validation loss: 2.691157435247747

Epoch: 5| Step: 7
Training loss: 3.273762033621748
Validation loss: 2.6972698345800312

Epoch: 5| Step: 8
Training loss: 2.738903372233873
Validation loss: 2.696359008390966

Epoch: 5| Step: 9
Training loss: 3.1739317891724355
Validation loss: 2.7109592284739388

Epoch: 5| Step: 10
Training loss: 2.69928102104025
Validation loss: 2.713423222900199

Epoch: 111| Step: 0
Training loss: 2.6391042811065986
Validation loss: 2.7003609113751197

Epoch: 5| Step: 1
Training loss: 3.1039353525567446
Validation loss: 2.689416891908704

Epoch: 5| Step: 2
Training loss: 3.169230142967954
Validation loss: 2.682013231483642

Epoch: 5| Step: 3
Training loss: 3.281482797266334
Validation loss: 2.678847657125075

Epoch: 5| Step: 4
Training loss: 3.087347630744942
Validation loss: 2.6770116094882463

Epoch: 5| Step: 5
Training loss: 3.3060488951587175
Validation loss: 2.6810469491429916

Epoch: 5| Step: 6
Training loss: 2.7694527382207266
Validation loss: 2.679815268205329

Epoch: 5| Step: 7
Training loss: 2.8116247722652945
Validation loss: 2.6829802904620386

Epoch: 5| Step: 8
Training loss: 3.058045397793869
Validation loss: 2.6842427949337186

Epoch: 5| Step: 9
Training loss: 3.0208001672086024
Validation loss: 2.6830633200208096

Epoch: 5| Step: 10
Training loss: 2.842258439481568
Validation loss: 2.688607493499774

Epoch: 112| Step: 0
Training loss: 2.934034210338476
Validation loss: 2.6917841524099346

Epoch: 5| Step: 1
Training loss: 3.210258764847512
Validation loss: 2.6917150467245836

Epoch: 5| Step: 2
Training loss: 2.883846769391719
Validation loss: 2.6820684435476476

Epoch: 5| Step: 3
Training loss: 2.9992121615664153
Validation loss: 2.684280982193914

Epoch: 5| Step: 4
Training loss: 2.7942880782240804
Validation loss: 2.6857196608638376

Epoch: 5| Step: 5
Training loss: 3.168817860254787
Validation loss: 2.6801106821275025

Epoch: 5| Step: 6
Training loss: 2.72688479554443
Validation loss: 2.6765420515794824

Epoch: 5| Step: 7
Training loss: 3.0280238021459316
Validation loss: 2.6882165867796353

Epoch: 5| Step: 8
Training loss: 2.6587869534168527
Validation loss: 2.6976370778045515

Epoch: 5| Step: 9
Training loss: 3.39451172431273
Validation loss: 2.6953339273731416

Epoch: 5| Step: 10
Training loss: 3.313812859398409
Validation loss: 2.6776153685685804

Epoch: 113| Step: 0
Training loss: 3.438794672518796
Validation loss: 2.675186424287712

Epoch: 5| Step: 1
Training loss: 3.370251600115857
Validation loss: 2.6702398614657032

Epoch: 5| Step: 2
Training loss: 3.043828918561888
Validation loss: 2.6712474977266387

Epoch: 5| Step: 3
Training loss: 2.595348463090639
Validation loss: 2.672991587615002

Epoch: 5| Step: 4
Training loss: 2.6509749148695425
Validation loss: 2.6723980691763787

Epoch: 5| Step: 5
Training loss: 2.862402975112196
Validation loss: 2.6747125913019523

Epoch: 5| Step: 6
Training loss: 3.0690657629957645
Validation loss: 2.673360158877094

Epoch: 5| Step: 7
Training loss: 3.1530103014225097
Validation loss: 2.675015647228296

Epoch: 5| Step: 8
Training loss: 3.256191811069126
Validation loss: 2.6764931564304404

Epoch: 5| Step: 9
Training loss: 2.681793364129344
Validation loss: 2.6737779030891926

Epoch: 5| Step: 10
Training loss: 2.82893621286086
Validation loss: 2.6735648186141265

Epoch: 114| Step: 0
Training loss: 2.3369688481159114
Validation loss: 2.668731800860808

Epoch: 5| Step: 1
Training loss: 2.819067598369366
Validation loss: 2.6716900056051625

Epoch: 5| Step: 2
Training loss: 3.5149595181778
Validation loss: 2.6709944142216684

Epoch: 5| Step: 3
Training loss: 3.226167890234705
Validation loss: 2.6736519616024026

Epoch: 5| Step: 4
Training loss: 2.9823505665386487
Validation loss: 2.6732844077780427

Epoch: 5| Step: 5
Training loss: 2.7231734672542562
Validation loss: 2.674238214211689

Epoch: 5| Step: 6
Training loss: 2.766734014020791
Validation loss: 2.6719606226661243

Epoch: 5| Step: 7
Training loss: 2.548598659899582
Validation loss: 2.6719630951946507

Epoch: 5| Step: 8
Training loss: 3.574053717800303
Validation loss: 2.6746717600272114

Epoch: 5| Step: 9
Training loss: 3.056360747470226
Validation loss: 2.6764239902224767

Epoch: 5| Step: 10
Training loss: 3.2546570496730265
Validation loss: 2.6786996615996714

Epoch: 115| Step: 0
Training loss: 3.120460875779491
Validation loss: 2.678977250092696

Epoch: 5| Step: 1
Training loss: 3.2145988584297225
Validation loss: 2.693129254630011

Epoch: 5| Step: 2
Training loss: 2.9551910762038722
Validation loss: 2.6918828243942254

Epoch: 5| Step: 3
Training loss: 3.3822342376172516
Validation loss: 2.685460449259992

Epoch: 5| Step: 4
Training loss: 2.769394455559225
Validation loss: 2.691262694440629

Epoch: 5| Step: 5
Training loss: 3.1048353016982055
Validation loss: 2.682482170000845

Epoch: 5| Step: 6
Training loss: 2.6922029553466245
Validation loss: 2.687983840158287

Epoch: 5| Step: 7
Training loss: 2.96023301573479
Validation loss: 2.694724227912741

Epoch: 5| Step: 8
Training loss: 2.6476631945634064
Validation loss: 2.6821795065671252

Epoch: 5| Step: 9
Training loss: 3.4308440532861226
Validation loss: 2.674314143437617

Epoch: 5| Step: 10
Training loss: 2.507060666147977
Validation loss: 2.6688168750097816

Epoch: 116| Step: 0
Training loss: 2.606448331097212
Validation loss: 2.6697560819468102

Epoch: 5| Step: 1
Training loss: 3.4819002814565674
Validation loss: 2.668191299617669

Epoch: 5| Step: 2
Training loss: 2.6969832839532653
Validation loss: 2.6664232901164766

Epoch: 5| Step: 3
Training loss: 2.785773638208277
Validation loss: 2.6664430834756443

Epoch: 5| Step: 4
Training loss: 3.7390987893434597
Validation loss: 2.667433753036491

Epoch: 5| Step: 5
Training loss: 2.841326508807265
Validation loss: 2.6621441009504956

Epoch: 5| Step: 6
Training loss: 2.948965220890785
Validation loss: 2.664995451070635

Epoch: 5| Step: 7
Training loss: 2.212260467149318
Validation loss: 2.6653909503032103

Epoch: 5| Step: 8
Training loss: 3.268899544382208
Validation loss: 2.6639168155512056

Epoch: 5| Step: 9
Training loss: 3.004981197101586
Validation loss: 2.6693841895227925

Epoch: 5| Step: 10
Training loss: 3.1056255181047847
Validation loss: 2.680805230659457

Epoch: 117| Step: 0
Training loss: 2.853988994627961
Validation loss: 2.7277632255303312

Epoch: 5| Step: 1
Training loss: 2.902723243927151
Validation loss: 2.7263541108634155

Epoch: 5| Step: 2
Training loss: 2.920446689353607
Validation loss: 2.7214425586574595

Epoch: 5| Step: 3
Training loss: 3.3383970105298366
Validation loss: 2.7113163299102823

Epoch: 5| Step: 4
Training loss: 2.9714401103413985
Validation loss: 2.6858747814230806

Epoch: 5| Step: 5
Training loss: 3.13737843798525
Validation loss: 2.6697294338395854

Epoch: 5| Step: 6
Training loss: 3.330793144003339
Validation loss: 2.659947092791657

Epoch: 5| Step: 7
Training loss: 2.7767216539681687
Validation loss: 2.653845473843961

Epoch: 5| Step: 8
Training loss: 2.574046845550006
Validation loss: 2.656544823785731

Epoch: 5| Step: 9
Training loss: 3.354457076553877
Validation loss: 2.655792219079014

Epoch: 5| Step: 10
Training loss: 2.712308421599017
Validation loss: 2.654798503194437

Epoch: 118| Step: 0
Training loss: 3.139892037108873
Validation loss: 2.654925324547165

Epoch: 5| Step: 1
Training loss: 2.8874988043976657
Validation loss: 2.6572344148376956

Epoch: 5| Step: 2
Training loss: 3.514904168723184
Validation loss: 2.65573201446274

Epoch: 5| Step: 3
Training loss: 2.4761718056746913
Validation loss: 2.6550023864129133

Epoch: 5| Step: 4
Training loss: 2.8232013141282035
Validation loss: 2.650995622354257

Epoch: 5| Step: 5
Training loss: 2.9959840916108114
Validation loss: 2.6537898533170132

Epoch: 5| Step: 6
Training loss: 3.1476689387425743
Validation loss: 2.651407241556512

Epoch: 5| Step: 7
Training loss: 2.9709064883034695
Validation loss: 2.6526008624025392

Epoch: 5| Step: 8
Training loss: 2.783528369839162
Validation loss: 2.651797162890651

Epoch: 5| Step: 9
Training loss: 2.789379796377234
Validation loss: 2.6489698938672173

Epoch: 5| Step: 10
Training loss: 3.316513077775535
Validation loss: 2.6520561886246576

Epoch: 119| Step: 0
Training loss: 2.8587567437496464
Validation loss: 2.6552529883375984

Epoch: 5| Step: 1
Training loss: 3.115347948066863
Validation loss: 2.6535998989361342

Epoch: 5| Step: 2
Training loss: 2.6520951931296946
Validation loss: 2.659421060888484

Epoch: 5| Step: 3
Training loss: 3.574748482559579
Validation loss: 2.6734259531482527

Epoch: 5| Step: 4
Training loss: 2.923760932552909
Validation loss: 2.6726068294315644

Epoch: 5| Step: 5
Training loss: 2.730839127072787
Validation loss: 2.670851176378931

Epoch: 5| Step: 6
Training loss: 3.0879591874504064
Validation loss: 2.6606261752449702

Epoch: 5| Step: 7
Training loss: 2.5967852745668116
Validation loss: 2.652497013435168

Epoch: 5| Step: 8
Training loss: 3.2214082278025256
Validation loss: 2.6463964255667642

Epoch: 5| Step: 9
Training loss: 3.035410591770465
Validation loss: 2.6440020124182557

Epoch: 5| Step: 10
Training loss: 2.9069851181441946
Validation loss: 2.642268989019371

Epoch: 120| Step: 0
Training loss: 3.0242899794432314
Validation loss: 2.641280881431554

Epoch: 5| Step: 1
Training loss: 3.2604445841186136
Validation loss: 2.6416822058480496

Epoch: 5| Step: 2
Training loss: 3.0034084031534594
Validation loss: 2.6413770190855033

Epoch: 5| Step: 3
Training loss: 3.260325827668682
Validation loss: 2.6435782392348766

Epoch: 5| Step: 4
Training loss: 3.2008395345426353
Validation loss: 2.669943338110711

Epoch: 5| Step: 5
Training loss: 2.856846759984543
Validation loss: 2.700296327835085

Epoch: 5| Step: 6
Training loss: 3.2722397390550517
Validation loss: 2.7060503068479944

Epoch: 5| Step: 7
Training loss: 2.317244122482815
Validation loss: 2.7110099143302406

Epoch: 5| Step: 8
Training loss: 2.2249353720890737
Validation loss: 2.7048077836306987

Epoch: 5| Step: 9
Training loss: 3.1558407055453315
Validation loss: 2.7020705342553972

Epoch: 5| Step: 10
Training loss: 3.3265711062612517
Validation loss: 2.7045406665457388

Epoch: 121| Step: 0
Training loss: 2.801097474275804
Validation loss: 2.698138030072356

Epoch: 5| Step: 1
Training loss: 2.8794339031589407
Validation loss: 2.687966574527898

Epoch: 5| Step: 2
Training loss: 3.09260229535166
Validation loss: 2.6905604377001744

Epoch: 5| Step: 3
Training loss: 3.2841432440644516
Validation loss: 2.6758154392416

Epoch: 5| Step: 4
Training loss: 2.953303901864415
Validation loss: 2.6569720247854502

Epoch: 5| Step: 5
Training loss: 3.364650115461502
Validation loss: 2.6896977253927448

Epoch: 5| Step: 6
Training loss: 2.8244402575651493
Validation loss: 2.7099039551459754

Epoch: 5| Step: 7
Training loss: 3.0130376438912707
Validation loss: 2.7451416516034444

Epoch: 5| Step: 8
Training loss: 3.2066134181792885
Validation loss: 2.732848685727703

Epoch: 5| Step: 9
Training loss: 3.0718648543631732
Validation loss: 2.720895669454809

Epoch: 5| Step: 10
Training loss: 2.5208331862100186
Validation loss: 2.7101905736841196

Epoch: 122| Step: 0
Training loss: 2.7706217481859547
Validation loss: 2.6757753663596793

Epoch: 5| Step: 1
Training loss: 3.1003689331049467
Validation loss: 2.663477856738123

Epoch: 5| Step: 2
Training loss: 3.217358038200237
Validation loss: 2.6509276080124033

Epoch: 5| Step: 3
Training loss: 3.1943004096541543
Validation loss: 2.6403111747481156

Epoch: 5| Step: 4
Training loss: 2.9540484563924885
Validation loss: 2.641764971000391

Epoch: 5| Step: 5
Training loss: 3.025858065385809
Validation loss: 2.64001396805072

Epoch: 5| Step: 6
Training loss: 2.757769187176474
Validation loss: 2.637122018861404

Epoch: 5| Step: 7
Training loss: 3.1566545585982855
Validation loss: 2.6413098916874094

Epoch: 5| Step: 8
Training loss: 2.9927042621957076
Validation loss: 2.63834393305132

Epoch: 5| Step: 9
Training loss: 2.7860082149891117
Validation loss: 2.637606190379513

Epoch: 5| Step: 10
Training loss: 2.6913340521486973
Validation loss: 2.6338881522114526

Epoch: 123| Step: 0
Training loss: 3.20693044004544
Validation loss: 2.633498927493079

Epoch: 5| Step: 1
Training loss: 2.798155933487766
Validation loss: 2.635213393131758

Epoch: 5| Step: 2
Training loss: 2.8875328227237747
Validation loss: 2.6309928225283046

Epoch: 5| Step: 3
Training loss: 2.562745338418584
Validation loss: 2.631261456869225

Epoch: 5| Step: 4
Training loss: 2.51653316051055
Validation loss: 2.6333995831656716

Epoch: 5| Step: 5
Training loss: 3.257016896678091
Validation loss: 2.6286542100870287

Epoch: 5| Step: 6
Training loss: 2.9631614686998415
Validation loss: 2.6301681356283417

Epoch: 5| Step: 7
Training loss: 3.1479740227641724
Validation loss: 2.6300327186759276

Epoch: 5| Step: 8
Training loss: 3.219519810145973
Validation loss: 2.625889928574046

Epoch: 5| Step: 9
Training loss: 3.1056545369936774
Validation loss: 2.6281965260367883

Epoch: 5| Step: 10
Training loss: 2.881404708713781
Validation loss: 2.6281196019342064

Epoch: 124| Step: 0
Training loss: 2.395712830097638
Validation loss: 2.628717779195033

Epoch: 5| Step: 1
Training loss: 3.034170729639577
Validation loss: 2.634635822909893

Epoch: 5| Step: 2
Training loss: 3.321276571894699
Validation loss: 2.6441778630698476

Epoch: 5| Step: 3
Training loss: 2.357614631009922
Validation loss: 2.663094675531148

Epoch: 5| Step: 4
Training loss: 3.1142458695678807
Validation loss: 2.6731179908259803

Epoch: 5| Step: 5
Training loss: 2.8132447846053372
Validation loss: 2.685475742505532

Epoch: 5| Step: 6
Training loss: 2.876339807546487
Validation loss: 2.6558465302562317

Epoch: 5| Step: 7
Training loss: 3.1245463232695596
Validation loss: 2.636522912971971

Epoch: 5| Step: 8
Training loss: 3.398888428686529
Validation loss: 2.624322351101466

Epoch: 5| Step: 9
Training loss: 2.9449519333859446
Validation loss: 2.6201883067685525

Epoch: 5| Step: 10
Training loss: 3.1078533494047385
Validation loss: 2.618184713218017

Epoch: 125| Step: 0
Training loss: 3.15561888777469
Validation loss: 2.6189856865640877

Epoch: 5| Step: 1
Training loss: 3.1471277735844474
Validation loss: 2.6172975637317717

Epoch: 5| Step: 2
Training loss: 2.9679034180465744
Validation loss: 2.6178129739004445

Epoch: 5| Step: 3
Training loss: 2.2740728270545345
Validation loss: 2.6194916379273474

Epoch: 5| Step: 4
Training loss: 2.7919487217618286
Validation loss: 2.6193430311402723

Epoch: 5| Step: 5
Training loss: 2.8860151494210817
Validation loss: 2.6170758878184923

Epoch: 5| Step: 6
Training loss: 3.0726989324123584
Validation loss: 2.6170314340062624

Epoch: 5| Step: 7
Training loss: 3.4523858707687345
Validation loss: 2.616675372671277

Epoch: 5| Step: 8
Training loss: 2.6717940647292617
Validation loss: 2.614199725722149

Epoch: 5| Step: 9
Training loss: 2.871982815683113
Validation loss: 2.6140732940393505

Epoch: 5| Step: 10
Training loss: 3.1437135000366205
Validation loss: 2.6126509031187033

Epoch: 126| Step: 0
Training loss: 2.625835285805481
Validation loss: 2.6128278139312693

Epoch: 5| Step: 1
Training loss: 3.225477280895836
Validation loss: 2.614391557319323

Epoch: 5| Step: 2
Training loss: 2.8197270258547533
Validation loss: 2.6120602694890205

Epoch: 5| Step: 3
Training loss: 2.7264740937774024
Validation loss: 2.6127232146862096

Epoch: 5| Step: 4
Training loss: 2.8307691826868213
Validation loss: 2.612525162867839

Epoch: 5| Step: 5
Training loss: 3.0347392656171173
Validation loss: 2.6130529004376553

Epoch: 5| Step: 6
Training loss: 3.164805835957252
Validation loss: 2.624003141463095

Epoch: 5| Step: 7
Training loss: 2.8504449195913297
Validation loss: 2.636268681953156

Epoch: 5| Step: 8
Training loss: 3.1983930665746803
Validation loss: 2.6310789318116656

Epoch: 5| Step: 9
Training loss: 2.874202451791926
Validation loss: 2.6512460924543397

Epoch: 5| Step: 10
Training loss: 3.0895080769882894
Validation loss: 2.6312908893631417

Epoch: 127| Step: 0
Training loss: 2.8204944160945797
Validation loss: 2.628621623276951

Epoch: 5| Step: 1
Training loss: 2.783168002793741
Validation loss: 2.6434398603319145

Epoch: 5| Step: 2
Training loss: 3.024500933376628
Validation loss: 2.6383084847531877

Epoch: 5| Step: 3
Training loss: 3.259643771829381
Validation loss: 2.6388149631798

Epoch: 5| Step: 4
Training loss: 2.9789460818561246
Validation loss: 2.620310053442457

Epoch: 5| Step: 5
Training loss: 3.0172235076826013
Validation loss: 2.6111059030245114

Epoch: 5| Step: 6
Training loss: 2.718980099817416
Validation loss: 2.6089902646613523

Epoch: 5| Step: 7
Training loss: 3.480034558135576
Validation loss: 2.611045722547046

Epoch: 5| Step: 8
Training loss: 3.1722841797534875
Validation loss: 2.618756598976446

Epoch: 5| Step: 9
Training loss: 2.347421136085901
Validation loss: 2.620305931553722

Epoch: 5| Step: 10
Training loss: 2.8491121816618326
Validation loss: 2.6204773058626736

Epoch: 128| Step: 0
Training loss: 2.9102398137121672
Validation loss: 2.622943028295685

Epoch: 5| Step: 1
Training loss: 2.347289197920511
Validation loss: 2.6100630255625936

Epoch: 5| Step: 2
Training loss: 3.092295911834386
Validation loss: 2.6174747657736783

Epoch: 5| Step: 3
Training loss: 2.9835462767686574
Validation loss: 2.6053435447789286

Epoch: 5| Step: 4
Training loss: 3.429836817382435
Validation loss: 2.6063000301385815

Epoch: 5| Step: 5
Training loss: 2.8499811673796978
Validation loss: 2.6087141805960234

Epoch: 5| Step: 6
Training loss: 3.44710101634259
Validation loss: 2.615681709287079

Epoch: 5| Step: 7
Training loss: 3.099897038380399
Validation loss: 2.6235438027271507

Epoch: 5| Step: 8
Training loss: 2.568668570237189
Validation loss: 2.6275830741765946

Epoch: 5| Step: 9
Training loss: 2.6608592713482926
Validation loss: 2.6435920621804354

Epoch: 5| Step: 10
Training loss: 2.9685207880778752
Validation loss: 2.653526901411702

Epoch: 129| Step: 0
Training loss: 2.9107093643828903
Validation loss: 2.638159327718363

Epoch: 5| Step: 1
Training loss: 2.8590689740288524
Validation loss: 2.6462691373435967

Epoch: 5| Step: 2
Training loss: 2.8868684020114643
Validation loss: 2.6320441094736955

Epoch: 5| Step: 3
Training loss: 3.2619704828944136
Validation loss: 2.629007291672132

Epoch: 5| Step: 4
Training loss: 2.4841300795645274
Validation loss: 2.6260000219665383

Epoch: 5| Step: 5
Training loss: 3.103450632825227
Validation loss: 2.6217698782962233

Epoch: 5| Step: 6
Training loss: 2.8298819969566256
Validation loss: 2.620231526580405

Epoch: 5| Step: 7
Training loss: 3.222939736584334
Validation loss: 2.6113713466493524

Epoch: 5| Step: 8
Training loss: 2.665764049914792
Validation loss: 2.628784235366417

Epoch: 5| Step: 9
Training loss: 2.5339905773008726
Validation loss: 2.6340639714764897

Epoch: 5| Step: 10
Training loss: 3.5319278032780286
Validation loss: 2.6406807250106312

Epoch: 130| Step: 0
Training loss: 3.1508009301064495
Validation loss: 2.6139241183256896

Epoch: 5| Step: 1
Training loss: 2.6972424660143535
Validation loss: 2.5986805731505043

Epoch: 5| Step: 2
Training loss: 3.3436323483883457
Validation loss: 2.595210076954188

Epoch: 5| Step: 3
Training loss: 2.824313804535838
Validation loss: 2.5947234413442857

Epoch: 5| Step: 4
Training loss: 3.1006900511555426
Validation loss: 2.5931329854416063

Epoch: 5| Step: 5
Training loss: 2.8829972536177824
Validation loss: 2.5910212582015295

Epoch: 5| Step: 6
Training loss: 3.059103503079572
Validation loss: 2.593044561157486

Epoch: 5| Step: 7
Training loss: 2.293405208607214
Validation loss: 2.5944429596946192

Epoch: 5| Step: 8
Training loss: 2.982445217758192
Validation loss: 2.5930949348960866

Epoch: 5| Step: 9
Training loss: 2.6779067459108656
Validation loss: 2.5920897555883453

Epoch: 5| Step: 10
Training loss: 3.269085378564058
Validation loss: 2.591692875606709

Epoch: 131| Step: 0
Training loss: 3.0726385648069585
Validation loss: 2.590170226279501

Epoch: 5| Step: 1
Training loss: 2.327246480998326
Validation loss: 2.5928780663790696

Epoch: 5| Step: 2
Training loss: 3.127291945162511
Validation loss: 2.594822422340516

Epoch: 5| Step: 3
Training loss: 3.204440409686752
Validation loss: 2.5968457914456424

Epoch: 5| Step: 4
Training loss: 2.683244041078704
Validation loss: 2.597328170128335

Epoch: 5| Step: 5
Training loss: 2.691708396926698
Validation loss: 2.598939343211542

Epoch: 5| Step: 6
Training loss: 2.768771778994082
Validation loss: 2.6019704431690336

Epoch: 5| Step: 7
Training loss: 3.1358893831265107
Validation loss: 2.597195437861358

Epoch: 5| Step: 8
Training loss: 3.45438041133053
Validation loss: 2.602152414006806

Epoch: 5| Step: 9
Training loss: 2.9621521564479463
Validation loss: 2.5936556088642884

Epoch: 5| Step: 10
Training loss: 2.568386388136222
Validation loss: 2.603748519961866

Epoch: 132| Step: 0
Training loss: 2.465173665983939
Validation loss: 2.6155606253914354

Epoch: 5| Step: 1
Training loss: 3.3662656154900734
Validation loss: 2.6080813311488096

Epoch: 5| Step: 2
Training loss: 2.6014202640359207
Validation loss: 2.611084984245953

Epoch: 5| Step: 3
Training loss: 3.0897338693325644
Validation loss: 2.6040139801220086

Epoch: 5| Step: 4
Training loss: 2.5758317400375006
Validation loss: 2.601957316397962

Epoch: 5| Step: 5
Training loss: 2.861192469587193
Validation loss: 2.6017269127036213

Epoch: 5| Step: 6
Training loss: 2.9521111256635653
Validation loss: 2.5965411363412856

Epoch: 5| Step: 7
Training loss: 3.439710703816841
Validation loss: 2.5894888795889823

Epoch: 5| Step: 8
Training loss: 3.0843589898247568
Validation loss: 2.5924305728316472

Epoch: 5| Step: 9
Training loss: 2.6462953619657106
Validation loss: 2.5890847910183603

Epoch: 5| Step: 10
Training loss: 3.021778213229139
Validation loss: 2.5876170640719627

Epoch: 133| Step: 0
Training loss: 2.5071005122482872
Validation loss: 2.5901714812918186

Epoch: 5| Step: 1
Training loss: 2.979469941892946
Validation loss: 2.594321390474983

Epoch: 5| Step: 2
Training loss: 3.3126494176022354
Validation loss: 2.5999136912784713

Epoch: 5| Step: 3
Training loss: 3.0981943593929384
Validation loss: 2.605370094751317

Epoch: 5| Step: 4
Training loss: 2.557786840497726
Validation loss: 2.608949545638843

Epoch: 5| Step: 5
Training loss: 2.925843995749496
Validation loss: 2.610468376425382

Epoch: 5| Step: 6
Training loss: 2.993332765688202
Validation loss: 2.6007729072121437

Epoch: 5| Step: 7
Training loss: 3.2626602367352833
Validation loss: 2.598177607367019

Epoch: 5| Step: 8
Training loss: 2.693969568920377
Validation loss: 2.5938023575382085

Epoch: 5| Step: 9
Training loss: 3.2627146040098634
Validation loss: 2.591076814240675

Epoch: 5| Step: 10
Training loss: 2.4383881735832795
Validation loss: 2.591863581500516

Epoch: 134| Step: 0
Training loss: 2.7263386369417226
Validation loss: 2.5867258804610573

Epoch: 5| Step: 1
Training loss: 2.9656082394028815
Validation loss: 2.5842549813247664

Epoch: 5| Step: 2
Training loss: 3.35348747121627
Validation loss: 2.5858871018347953

Epoch: 5| Step: 3
Training loss: 2.9446654886570545
Validation loss: 2.583739929143078

Epoch: 5| Step: 4
Training loss: 3.2552478675984715
Validation loss: 2.5804172938890857

Epoch: 5| Step: 5
Training loss: 2.7243076389821335
Validation loss: 2.5812585913326886

Epoch: 5| Step: 6
Training loss: 2.63734973280539
Validation loss: 2.5786914669233942

Epoch: 5| Step: 7
Training loss: 2.8854416021010962
Validation loss: 2.579542624580327

Epoch: 5| Step: 8
Training loss: 2.605198607387841
Validation loss: 2.580304482652269

Epoch: 5| Step: 9
Training loss: 2.9872212044460302
Validation loss: 2.581478743938165

Epoch: 5| Step: 10
Training loss: 3.0553809742230253
Validation loss: 2.5821731104205865

Epoch: 135| Step: 0
Training loss: 3.137967024008093
Validation loss: 2.585044926635597

Epoch: 5| Step: 1
Training loss: 3.12571540273097
Validation loss: 2.5927361499584864

Epoch: 5| Step: 2
Training loss: 2.5620878865148864
Validation loss: 2.6296957063279094

Epoch: 5| Step: 3
Training loss: 2.7943435379813373
Validation loss: 2.633659179183122

Epoch: 5| Step: 4
Training loss: 2.97950259006501
Validation loss: 2.6327545002857033

Epoch: 5| Step: 5
Training loss: 2.7963600750242184
Validation loss: 2.6207694268116675

Epoch: 5| Step: 6
Training loss: 2.65501159521757
Validation loss: 2.6069764708137715

Epoch: 5| Step: 7
Training loss: 3.0691032066554924
Validation loss: 2.614274751986478

Epoch: 5| Step: 8
Training loss: 2.5071431154927115
Validation loss: 2.5914200786311494

Epoch: 5| Step: 9
Training loss: 2.6832260035340405
Validation loss: 2.585072294986288

Epoch: 5| Step: 10
Training loss: 3.703264837401265
Validation loss: 2.58528713396198

Epoch: 136| Step: 0
Training loss: 3.309729659228272
Validation loss: 2.5789065531547974

Epoch: 5| Step: 1
Training loss: 2.7734947521049347
Validation loss: 2.583469048572889

Epoch: 5| Step: 2
Training loss: 3.0807483937987463
Validation loss: 2.5805267452943594

Epoch: 5| Step: 3
Training loss: 2.614345727182576
Validation loss: 2.5821258694884897

Epoch: 5| Step: 4
Training loss: 2.4120695412006956
Validation loss: 2.58328489032568

Epoch: 5| Step: 5
Training loss: 2.7994968336863804
Validation loss: 2.583948041069989

Epoch: 5| Step: 6
Training loss: 3.234651268111285
Validation loss: 2.5826873623321913

Epoch: 5| Step: 7
Training loss: 3.13187232619373
Validation loss: 2.5840423274638953

Epoch: 5| Step: 8
Training loss: 2.5241894620225214
Validation loss: 2.5895692262243917

Epoch: 5| Step: 9
Training loss: 3.1105488617270436
Validation loss: 2.5894771250784343

Epoch: 5| Step: 10
Training loss: 3.1100312887010024
Validation loss: 2.6083310835272084

Epoch: 137| Step: 0
Training loss: 2.8135577438066512
Validation loss: 2.613590581647699

Epoch: 5| Step: 1
Training loss: 2.543549033434551
Validation loss: 2.6384612410663295

Epoch: 5| Step: 2
Training loss: 3.1384269652037418
Validation loss: 2.6561041794960625

Epoch: 5| Step: 3
Training loss: 3.0647439326344426
Validation loss: 2.6823078074190145

Epoch: 5| Step: 4
Training loss: 3.246570538371239
Validation loss: 2.660691300647218

Epoch: 5| Step: 5
Training loss: 2.5436116473839947
Validation loss: 2.646506741143201

Epoch: 5| Step: 6
Training loss: 2.842442641673463
Validation loss: 2.635832159488532

Epoch: 5| Step: 7
Training loss: 2.8081511041245966
Validation loss: 2.613902816061746

Epoch: 5| Step: 8
Training loss: 2.9862086869101
Validation loss: 2.6044343888682593

Epoch: 5| Step: 9
Training loss: 3.0134778853434616
Validation loss: 2.5848887597441825

Epoch: 5| Step: 10
Training loss: 3.1512763994708264
Validation loss: 2.5883455395106827

Epoch: 138| Step: 0
Training loss: 3.0031929508583777
Validation loss: 2.584431720068611

Epoch: 5| Step: 1
Training loss: 2.8544038177498914
Validation loss: 2.5777308436513295

Epoch: 5| Step: 2
Training loss: 2.6972722544440164
Validation loss: 2.5801672996809772

Epoch: 5| Step: 3
Training loss: 2.5646082881288725
Validation loss: 2.5764097332989926

Epoch: 5| Step: 4
Training loss: 2.290448390923038
Validation loss: 2.5841394755099665

Epoch: 5| Step: 5
Training loss: 3.2865604116765614
Validation loss: 2.5767317680671917

Epoch: 5| Step: 6
Training loss: 3.0721974883675265
Validation loss: 2.5814337516052164

Epoch: 5| Step: 7
Training loss: 3.178582226656824
Validation loss: 2.581751140102564

Epoch: 5| Step: 8
Training loss: 3.3558593806836368
Validation loss: 2.572157080882748

Epoch: 5| Step: 9
Training loss: 2.9305958878170886
Validation loss: 2.5773659392584447

Epoch: 5| Step: 10
Training loss: 2.7109703039993374
Validation loss: 2.5747162180770204

Epoch: 139| Step: 0
Training loss: 3.4861549655001633
Validation loss: 2.5721220759306394

Epoch: 5| Step: 1
Training loss: 2.7803064524569905
Validation loss: 2.574709464246398

Epoch: 5| Step: 2
Training loss: 2.9829225850560555
Validation loss: 2.5750773255680808

Epoch: 5| Step: 3
Training loss: 3.1451362359600616
Validation loss: 2.5771178584384575

Epoch: 5| Step: 4
Training loss: 2.424784727471463
Validation loss: 2.578194837472627

Epoch: 5| Step: 5
Training loss: 2.146491261576191
Validation loss: 2.5780252237859953

Epoch: 5| Step: 6
Training loss: 2.073634178417712
Validation loss: 2.5735619519503925

Epoch: 5| Step: 7
Training loss: 3.0017748986415116
Validation loss: 2.582430429356485

Epoch: 5| Step: 8
Training loss: 2.8682925721869945
Validation loss: 2.584309184898455

Epoch: 5| Step: 9
Training loss: 3.501526499694664
Validation loss: 2.578380236230051

Epoch: 5| Step: 10
Training loss: 3.2375493344116046
Validation loss: 2.588208319677627

Epoch: 140| Step: 0
Training loss: 3.2960785541062076
Validation loss: 2.5963267230494718

Epoch: 5| Step: 1
Training loss: 2.6930727290925747
Validation loss: 2.5948448652669884

Epoch: 5| Step: 2
Training loss: 3.10417929695854
Validation loss: 2.597202277332241

Epoch: 5| Step: 3
Training loss: 2.76360078861757
Validation loss: 2.600329047242444

Epoch: 5| Step: 4
Training loss: 3.2097626181796493
Validation loss: 2.588530545992677

Epoch: 5| Step: 5
Training loss: 2.672890899446788
Validation loss: 2.583026490329179

Epoch: 5| Step: 6
Training loss: 2.681393983616271
Validation loss: 2.580659455726371

Epoch: 5| Step: 7
Training loss: 3.0505331917898264
Validation loss: 2.58777011509487

Epoch: 5| Step: 8
Training loss: 3.186907395270957
Validation loss: 2.5805035360631545

Epoch: 5| Step: 9
Training loss: 2.6112219390164877
Validation loss: 2.56710903152232

Epoch: 5| Step: 10
Training loss: 2.530514928261547
Validation loss: 2.578201530466682

Epoch: 141| Step: 0
Training loss: 3.166783347406194
Validation loss: 2.5749848434730156

Epoch: 5| Step: 1
Training loss: 2.7024124176485413
Validation loss: 2.592406417979229

Epoch: 5| Step: 2
Training loss: 2.8808064084113916
Validation loss: 2.589265075355633

Epoch: 5| Step: 3
Training loss: 3.4134043183495484
Validation loss: 2.5954013267134632

Epoch: 5| Step: 4
Training loss: 2.512852058606878
Validation loss: 2.5933481293790357

Epoch: 5| Step: 5
Training loss: 2.282703198081925
Validation loss: 2.5986066475031944

Epoch: 5| Step: 6
Training loss: 3.1507717216606794
Validation loss: 2.5910631108581668

Epoch: 5| Step: 7
Training loss: 3.1687585713949655
Validation loss: 2.5942752808837892

Epoch: 5| Step: 8
Training loss: 2.7855785846844525
Validation loss: 2.58551930705908

Epoch: 5| Step: 9
Training loss: 3.140382368290107
Validation loss: 2.5761351223856863

Epoch: 5| Step: 10
Training loss: 2.5264292835792492
Validation loss: 2.5649886373502375

Epoch: 142| Step: 0
Training loss: 2.764436283143819
Validation loss: 2.5607807455637217

Epoch: 5| Step: 1
Training loss: 2.8592327478596604
Validation loss: 2.5670679567640566

Epoch: 5| Step: 2
Training loss: 3.187788856732042
Validation loss: 2.566163164711804

Epoch: 5| Step: 3
Training loss: 2.962114004750025
Validation loss: 2.5698971193748457

Epoch: 5| Step: 4
Training loss: 2.8411078282980746
Validation loss: 2.56898040468718

Epoch: 5| Step: 5
Training loss: 2.4775299204415977
Validation loss: 2.571367292911897

Epoch: 5| Step: 6
Training loss: 3.1065882170544903
Validation loss: 2.5706913580294364

Epoch: 5| Step: 7
Training loss: 3.2425592783830686
Validation loss: 2.5719474551914296

Epoch: 5| Step: 8
Training loss: 2.7713754644628823
Validation loss: 2.57291502095416

Epoch: 5| Step: 9
Training loss: 3.0150430542764437
Validation loss: 2.5762590663205245

Epoch: 5| Step: 10
Training loss: 2.725650930091067
Validation loss: 2.5808551233130084

Epoch: 143| Step: 0
Training loss: 2.2242648935572906
Validation loss: 2.5744897674004195

Epoch: 5| Step: 1
Training loss: 2.5674760467095394
Validation loss: 2.5765114377076492

Epoch: 5| Step: 2
Training loss: 3.0775914383295415
Validation loss: 2.5761885972062473

Epoch: 5| Step: 3
Training loss: 3.1144458310874237
Validation loss: 2.5840215814784453

Epoch: 5| Step: 4
Training loss: 2.6152669208031365
Validation loss: 2.594079504866153

Epoch: 5| Step: 5
Training loss: 3.2036733762677243
Validation loss: 2.6088813725994493

Epoch: 5| Step: 6
Training loss: 2.7428528068286817
Validation loss: 2.634029958586637

Epoch: 5| Step: 7
Training loss: 3.1340598954914425
Validation loss: 2.6533723312836153

Epoch: 5| Step: 8
Training loss: 3.2056059370777508
Validation loss: 2.660514826288755

Epoch: 5| Step: 9
Training loss: 3.0302372449901167
Validation loss: 2.626608245067278

Epoch: 5| Step: 10
Training loss: 3.0527390609968834
Validation loss: 2.596069890762941

Epoch: 144| Step: 0
Training loss: 2.720985633439253
Validation loss: 2.573014145438923

Epoch: 5| Step: 1
Training loss: 2.8141208640511146
Validation loss: 2.5677391096495215

Epoch: 5| Step: 2
Training loss: 2.8961819409180602
Validation loss: 2.5538523904845682

Epoch: 5| Step: 3
Training loss: 2.79721842953592
Validation loss: 2.55889301567905

Epoch: 5| Step: 4
Training loss: 2.7190732215711177
Validation loss: 2.5673881397182607

Epoch: 5| Step: 5
Training loss: 2.825280038912746
Validation loss: 2.5680512526258483

Epoch: 5| Step: 6
Training loss: 2.959793876481902
Validation loss: 2.5745744496330483

Epoch: 5| Step: 7
Training loss: 3.228098653739369
Validation loss: 2.578127992093167

Epoch: 5| Step: 8
Training loss: 3.0613617630756065
Validation loss: 2.5666658917545617

Epoch: 5| Step: 9
Training loss: 2.9754820937943354
Validation loss: 2.5658295013109553

Epoch: 5| Step: 10
Training loss: 3.150503233418321
Validation loss: 2.558858699899807

Epoch: 145| Step: 0
Training loss: 2.7018842550768216
Validation loss: 2.554673998813553

Epoch: 5| Step: 1
Training loss: 3.2565237739265664
Validation loss: 2.5532254762080364

Epoch: 5| Step: 2
Training loss: 2.918443919435265
Validation loss: 2.5513029136226337

Epoch: 5| Step: 3
Training loss: 2.961284687552418
Validation loss: 2.556958329805567

Epoch: 5| Step: 4
Training loss: 2.5153619853832145
Validation loss: 2.5656722177766422

Epoch: 5| Step: 5
Training loss: 2.823692431021361
Validation loss: 2.5822682846425717

Epoch: 5| Step: 6
Training loss: 2.7680602478184935
Validation loss: 2.6218323509984005

Epoch: 5| Step: 7
Training loss: 2.8554265010019977
Validation loss: 2.6472946567896014

Epoch: 5| Step: 8
Training loss: 3.662408581526915
Validation loss: 2.690559147571098

Epoch: 5| Step: 9
Training loss: 2.8430761859466025
Validation loss: 2.6988307153431106

Epoch: 5| Step: 10
Training loss: 2.48468313165683
Validation loss: 2.6861197133893358

Epoch: 146| Step: 0
Training loss: 2.511997616772827
Validation loss: 2.675843528991055

Epoch: 5| Step: 1
Training loss: 2.9051866124105845
Validation loss: 2.6802981302257973

Epoch: 5| Step: 2
Training loss: 2.732150759004338
Validation loss: 2.7139423235104787

Epoch: 5| Step: 3
Training loss: 3.3737960363401074
Validation loss: 2.707921660556452

Epoch: 5| Step: 4
Training loss: 2.6499695974081474
Validation loss: 2.6291428750378487

Epoch: 5| Step: 5
Training loss: 3.0481617875701947
Validation loss: 2.5960430787858897

Epoch: 5| Step: 6
Training loss: 3.1921656252596535
Validation loss: 2.5661283866962106

Epoch: 5| Step: 7
Training loss: 2.6905168854971007
Validation loss: 2.5616057401490218

Epoch: 5| Step: 8
Training loss: 3.066549776447972
Validation loss: 2.5606175302920273

Epoch: 5| Step: 9
Training loss: 3.035750832858596
Validation loss: 2.5806887937966687

Epoch: 5| Step: 10
Training loss: 2.809574725187706
Validation loss: 2.5874568177659762

Epoch: 147| Step: 0
Training loss: 3.1801634486196653
Validation loss: 2.6064817518198264

Epoch: 5| Step: 1
Training loss: 3.0595386745790805
Validation loss: 2.6119770950601815

Epoch: 5| Step: 2
Training loss: 2.7701184681922584
Validation loss: 2.6102582215241075

Epoch: 5| Step: 3
Training loss: 3.3597065606728402
Validation loss: 2.606647703227002

Epoch: 5| Step: 4
Training loss: 2.985502020251744
Validation loss: 2.5999829336305154

Epoch: 5| Step: 5
Training loss: 3.060209079156896
Validation loss: 2.607899321818496

Epoch: 5| Step: 6
Training loss: 3.0097843196815575
Validation loss: 2.6047950701796516

Epoch: 5| Step: 7
Training loss: 2.3833144362796435
Validation loss: 2.601160781818193

Epoch: 5| Step: 8
Training loss: 2.7817279533581534
Validation loss: 2.589661361712957

Epoch: 5| Step: 9
Training loss: 2.6911251546957238
Validation loss: 2.5819164211681156

Epoch: 5| Step: 10
Training loss: 3.096256820307748
Validation loss: 2.5829878482434387

Epoch: 148| Step: 0
Training loss: 2.724084553368369
Validation loss: 2.5819110057679215

Epoch: 5| Step: 1
Training loss: 2.950092029752426
Validation loss: 2.591576473179584

Epoch: 5| Step: 2
Training loss: 3.027550711171626
Validation loss: 2.6007226191017345

Epoch: 5| Step: 3
Training loss: 2.9245430092142843
Validation loss: 2.6069981187846163

Epoch: 5| Step: 4
Training loss: 3.337407022959869
Validation loss: 2.627398713870547

Epoch: 5| Step: 5
Training loss: 2.5284191361287185
Validation loss: 2.621783886626219

Epoch: 5| Step: 6
Training loss: 2.780655872450536
Validation loss: 2.616215848783957

Epoch: 5| Step: 7
Training loss: 3.1359632824577743
Validation loss: 2.6142672246468845

Epoch: 5| Step: 8
Training loss: 3.3017139087771668
Validation loss: 2.6217953672211505

Epoch: 5| Step: 9
Training loss: 2.473547511205647
Validation loss: 2.6235422373050223

Epoch: 5| Step: 10
Training loss: 2.983477232746285
Validation loss: 2.627257680509382

Epoch: 149| Step: 0
Training loss: 3.292044332221992
Validation loss: 2.6380732474146997

Epoch: 5| Step: 1
Training loss: 2.8231557953586166
Validation loss: 2.6343467032305488

Epoch: 5| Step: 2
Training loss: 3.0849974154024102
Validation loss: 2.6316522940154408

Epoch: 5| Step: 3
Training loss: 2.756476924490354
Validation loss: 2.6314948539596204

Epoch: 5| Step: 4
Training loss: 3.0223438739446253
Validation loss: 2.632711349242902

Epoch: 5| Step: 5
Training loss: 2.8877813425107726
Validation loss: 2.6343274550301077

Epoch: 5| Step: 6
Training loss: 3.0143800053089276
Validation loss: 2.6245339444271774

Epoch: 5| Step: 7
Training loss: 2.453459601452751
Validation loss: 2.597710114731017

Epoch: 5| Step: 8
Training loss: 3.2721798467851717
Validation loss: 2.600447747271371

Epoch: 5| Step: 9
Training loss: 2.471846172101969
Validation loss: 2.6023390810426905

Epoch: 5| Step: 10
Training loss: 3.0133278749917256
Validation loss: 2.6010732287061598

Epoch: 150| Step: 0
Training loss: 3.2662640544064883
Validation loss: 2.6008079661716033

Epoch: 5| Step: 1
Training loss: 3.0304172591151968
Validation loss: 2.6090981538802387

Epoch: 5| Step: 2
Training loss: 2.6602972276164776
Validation loss: 2.612431169448942

Epoch: 5| Step: 3
Training loss: 2.9203049628505933
Validation loss: 2.6191611672017103

Epoch: 5| Step: 4
Training loss: 2.974155684479624
Validation loss: 2.6338058442491583

Epoch: 5| Step: 5
Training loss: 3.3594912486699733
Validation loss: 2.6057487817348757

Epoch: 5| Step: 6
Training loss: 2.7117450841417945
Validation loss: 2.60260230119177

Epoch: 5| Step: 7
Training loss: 2.7092362488238115
Validation loss: 2.604282355579333

Epoch: 5| Step: 8
Training loss: 2.614563768371897
Validation loss: 2.605423693245734

Epoch: 5| Step: 9
Training loss: 3.0845579516290513
Validation loss: 2.618922113226245

Epoch: 5| Step: 10
Training loss: 2.964032088441938
Validation loss: 2.614976058649901

Epoch: 151| Step: 0
Training loss: 3.3503485484070143
Validation loss: 2.618342313271381

Epoch: 5| Step: 1
Training loss: 2.9960471178228083
Validation loss: 2.6202090070863635

Epoch: 5| Step: 2
Training loss: 3.2586838542632717
Validation loss: 2.605776638039933

Epoch: 5| Step: 3
Training loss: 3.143006897120444
Validation loss: 2.5996573247997765

Epoch: 5| Step: 4
Training loss: 2.2611597717739387
Validation loss: 2.5924621895775104

Epoch: 5| Step: 5
Training loss: 2.70619433127713
Validation loss: 2.581083183774864

Epoch: 5| Step: 6
Training loss: 2.881640188148096
Validation loss: 2.576406484478805

Epoch: 5| Step: 7
Training loss: 2.524806829182922
Validation loss: 2.5713877332245474

Epoch: 5| Step: 8
Training loss: 3.221646681353736
Validation loss: 2.569232078126861

Epoch: 5| Step: 9
Training loss: 2.95309868048994
Validation loss: 2.5784076902367845

Epoch: 5| Step: 10
Training loss: 2.5576452462724437
Validation loss: 2.579687191769322

Epoch: 152| Step: 0
Training loss: 2.7879605721048724
Validation loss: 2.59391651194821

Epoch: 5| Step: 1
Training loss: 3.0051711337444362
Validation loss: 2.6008647424083557

Epoch: 5| Step: 2
Training loss: 3.4459980738850864
Validation loss: 2.610044138499845

Epoch: 5| Step: 3
Training loss: 2.23398122452075
Validation loss: 2.592314413678798

Epoch: 5| Step: 4
Training loss: 3.146357225327041
Validation loss: 2.5965938265990087

Epoch: 5| Step: 5
Training loss: 2.9824151599261337
Validation loss: 2.608924928593907

Epoch: 5| Step: 6
Training loss: 3.3185665791143393
Validation loss: 2.6105641266531214

Epoch: 5| Step: 7
Training loss: 2.6259354332440563
Validation loss: 2.5963659377669566

Epoch: 5| Step: 8
Training loss: 3.061306779365259
Validation loss: 2.5997466118476336

Epoch: 5| Step: 9
Training loss: 2.793768494820021
Validation loss: 2.603109395330583

Epoch: 5| Step: 10
Training loss: 2.4145504356515173
Validation loss: 2.60108798125668

Epoch: 153| Step: 0
Training loss: 2.5514980553304327
Validation loss: 2.584711599969449

Epoch: 5| Step: 1
Training loss: 3.158086261462607
Validation loss: 2.573250281174148

Epoch: 5| Step: 2
Training loss: 3.0853147240453658
Validation loss: 2.584387227516409

Epoch: 5| Step: 3
Training loss: 2.679914726210202
Validation loss: 2.5842284227458845

Epoch: 5| Step: 4
Training loss: 3.2154504845421705
Validation loss: 2.563135321949716

Epoch: 5| Step: 5
Training loss: 2.9535646464549536
Validation loss: 2.5606709357126856

Epoch: 5| Step: 6
Training loss: 2.9130823363621725
Validation loss: 2.5513456951551534

Epoch: 5| Step: 7
Training loss: 2.7880565207511183
Validation loss: 2.5282129510899836

Epoch: 5| Step: 8
Training loss: 2.9749982433153623
Validation loss: 2.5316978518209234

Epoch: 5| Step: 9
Training loss: 2.91636129324695
Validation loss: 2.5319268858379393

Epoch: 5| Step: 10
Training loss: 2.5283783058419864
Validation loss: 2.536240381961816

Epoch: 154| Step: 0
Training loss: 2.054747141853607
Validation loss: 2.541222507461316

Epoch: 5| Step: 1
Training loss: 2.2523052274470814
Validation loss: 2.5407914174873505

Epoch: 5| Step: 2
Training loss: 3.1507363079487565
Validation loss: 2.547699245880207

Epoch: 5| Step: 3
Training loss: 3.447830491079114
Validation loss: 2.5587848761340752

Epoch: 5| Step: 4
Training loss: 3.045447695037301
Validation loss: 2.5483502432973992

Epoch: 5| Step: 5
Training loss: 3.048857840882571
Validation loss: 2.5493201184892857

Epoch: 5| Step: 6
Training loss: 3.4570202153778693
Validation loss: 2.5428297756148277

Epoch: 5| Step: 7
Training loss: 2.8838434624377114
Validation loss: 2.542608020886075

Epoch: 5| Step: 8
Training loss: 3.1443234961455677
Validation loss: 2.5513894265129755

Epoch: 5| Step: 9
Training loss: 2.3286613512186927
Validation loss: 2.560519403700888

Epoch: 5| Step: 10
Training loss: 2.8154037744319975
Validation loss: 2.5736479950188795

Epoch: 155| Step: 0
Training loss: 2.6334432418034557
Validation loss: 2.5616444756027352

Epoch: 5| Step: 1
Training loss: 2.727065687557179
Validation loss: 2.5575348697672906

Epoch: 5| Step: 2
Training loss: 3.2938111156606134
Validation loss: 2.5528018752715593

Epoch: 5| Step: 3
Training loss: 3.314190846880043
Validation loss: 2.54855242520394

Epoch: 5| Step: 4
Training loss: 3.184564323150608
Validation loss: 2.545330955315434

Epoch: 5| Step: 5
Training loss: 2.581692718151134
Validation loss: 2.548053767877782

Epoch: 5| Step: 6
Training loss: 2.1340227989830827
Validation loss: 2.5617736409224565

Epoch: 5| Step: 7
Training loss: 2.7343191958591357
Validation loss: 2.553418455952703

Epoch: 5| Step: 8
Training loss: 2.7130900255474115
Validation loss: 2.5640135426288033

Epoch: 5| Step: 9
Training loss: 2.812846522706622
Validation loss: 2.5529789287180105

Epoch: 5| Step: 10
Training loss: 3.368607719403392
Validation loss: 2.5525471727678233

Epoch: 156| Step: 0
Training loss: 2.7771915442371937
Validation loss: 2.565624490154591

Epoch: 5| Step: 1
Training loss: 2.9485570708481847
Validation loss: 2.5683377716729243

Epoch: 5| Step: 2
Training loss: 2.6786782724778777
Validation loss: 2.5720429773966367

Epoch: 5| Step: 3
Training loss: 2.2014926788326172
Validation loss: 2.578872831736665

Epoch: 5| Step: 4
Training loss: 3.2286783813142215
Validation loss: 2.577084728391166

Epoch: 5| Step: 5
Training loss: 3.1823362523195358
Validation loss: 2.57233564347702

Epoch: 5| Step: 6
Training loss: 2.987877513065262
Validation loss: 2.5644760716248767

Epoch: 5| Step: 7
Training loss: 3.073191605676847
Validation loss: 2.565474019179569

Epoch: 5| Step: 8
Training loss: 2.695259690803987
Validation loss: 2.572760398662447

Epoch: 5| Step: 9
Training loss: 3.0102703406511035
Validation loss: 2.5659689044967484

Epoch: 5| Step: 10
Training loss: 2.6975302597484054
Validation loss: 2.5606577203700818

Epoch: 157| Step: 0
Training loss: 2.963675569124988
Validation loss: 2.5428013436551096

Epoch: 5| Step: 1
Training loss: 2.47614330510563
Validation loss: 2.535233845987859

Epoch: 5| Step: 2
Training loss: 2.691944793724592
Validation loss: 2.5348201521144524

Epoch: 5| Step: 3
Training loss: 2.5949875051091023
Validation loss: 2.5368195461620267

Epoch: 5| Step: 4
Training loss: 2.9558664343240335
Validation loss: 2.536256471375371

Epoch: 5| Step: 5
Training loss: 3.143005228269466
Validation loss: 2.5372444119484805

Epoch: 5| Step: 6
Training loss: 2.5471239026848815
Validation loss: 2.534119364568822

Epoch: 5| Step: 7
Training loss: 3.136957864922841
Validation loss: 2.5344077441467503

Epoch: 5| Step: 8
Training loss: 2.599246440404003
Validation loss: 2.534546145586126

Epoch: 5| Step: 9
Training loss: 3.4300153223701986
Validation loss: 2.5275619074644378

Epoch: 5| Step: 10
Training loss: 2.8899228454639365
Validation loss: 2.535143761207708

Epoch: 158| Step: 0
Training loss: 3.1742676979251168
Validation loss: 2.5346065311848007

Epoch: 5| Step: 1
Training loss: 3.130888769210503
Validation loss: 2.5373728855425495

Epoch: 5| Step: 2
Training loss: 2.3744154762941005
Validation loss: 2.5417936674275463

Epoch: 5| Step: 3
Training loss: 2.798113159945354
Validation loss: 2.5579447121194825

Epoch: 5| Step: 4
Training loss: 2.9094697897903385
Validation loss: 2.5521062076858585

Epoch: 5| Step: 5
Training loss: 2.9881835921542574
Validation loss: 2.5539249053281656

Epoch: 5| Step: 6
Training loss: 2.9351470938999955
Validation loss: 2.548923816109681

Epoch: 5| Step: 7
Training loss: 2.565208957035589
Validation loss: 2.545549118165316

Epoch: 5| Step: 8
Training loss: 2.8474703755566715
Validation loss: 2.541488024564357

Epoch: 5| Step: 9
Training loss: 2.6441730386260693
Validation loss: 2.538404551688017

Epoch: 5| Step: 10
Training loss: 3.090992324646794
Validation loss: 2.5387417054071757

Epoch: 159| Step: 0
Training loss: 2.8355877453057463
Validation loss: 2.5400850353261353

Epoch: 5| Step: 1
Training loss: 2.5288567237376487
Validation loss: 2.539366730668535

Epoch: 5| Step: 2
Training loss: 2.59507625636843
Validation loss: 2.538949015489495

Epoch: 5| Step: 3
Training loss: 3.5491350006627935
Validation loss: 2.538617402118768

Epoch: 5| Step: 4
Training loss: 2.8732088563277256
Validation loss: 2.532441102430127

Epoch: 5| Step: 5
Training loss: 2.647669407915123
Validation loss: 2.5219796534693355

Epoch: 5| Step: 6
Training loss: 2.306576436415049
Validation loss: 2.5212774703301064

Epoch: 5| Step: 7
Training loss: 2.7338892914040627
Validation loss: 2.525568148538828

Epoch: 5| Step: 8
Training loss: 2.529763244286618
Validation loss: 2.524515802212751

Epoch: 5| Step: 9
Training loss: 3.555144898886007
Validation loss: 2.5277930540248055

Epoch: 5| Step: 10
Training loss: 3.0850204457203674
Validation loss: 2.522717676638888

Epoch: 160| Step: 0
Training loss: 3.2711819181547512
Validation loss: 2.520965015087713

Epoch: 5| Step: 1
Training loss: 2.6079080078481836
Validation loss: 2.5199134831162078

Epoch: 5| Step: 2
Training loss: 2.7451832809824017
Validation loss: 2.5245414434059072

Epoch: 5| Step: 3
Training loss: 2.7321524170210534
Validation loss: 2.528531103994415

Epoch: 5| Step: 4
Training loss: 2.5451162619724834
Validation loss: 2.5211912430069874

Epoch: 5| Step: 5
Training loss: 3.212652857368503
Validation loss: 2.52478606455809

Epoch: 5| Step: 6
Training loss: 3.220469487716578
Validation loss: 2.5304525687335984

Epoch: 5| Step: 7
Training loss: 2.316777474568652
Validation loss: 2.5259562620122638

Epoch: 5| Step: 8
Training loss: 2.962593521380347
Validation loss: 2.5240106257212767

Epoch: 5| Step: 9
Training loss: 3.1724663544923124
Validation loss: 2.5311320713028644

Epoch: 5| Step: 10
Training loss: 2.398522092837146
Validation loss: 2.535936956486645

Epoch: 161| Step: 0
Training loss: 3.162839299874183
Validation loss: 2.5197963983674923

Epoch: 5| Step: 1
Training loss: 3.389783060339849
Validation loss: 2.5259218519690503

Epoch: 5| Step: 2
Training loss: 3.290830449630879
Validation loss: 2.52878825888062

Epoch: 5| Step: 3
Training loss: 2.447154366048855
Validation loss: 2.527572827116052

Epoch: 5| Step: 4
Training loss: 2.664182777710057
Validation loss: 2.522845531374044

Epoch: 5| Step: 5
Training loss: 2.6667092339773983
Validation loss: 2.5206750070685096

Epoch: 5| Step: 6
Training loss: 2.4538101891604187
Validation loss: 2.523774115724489

Epoch: 5| Step: 7
Training loss: 2.7251229844644707
Validation loss: 2.5202486530871555

Epoch: 5| Step: 8
Training loss: 2.9418602905813382
Validation loss: 2.5222390395553647

Epoch: 5| Step: 9
Training loss: 2.6595722739433816
Validation loss: 2.5199288674758735

Epoch: 5| Step: 10
Training loss: 2.975436580904534
Validation loss: 2.5310780172944214

Epoch: 162| Step: 0
Training loss: 3.1374747955404145
Validation loss: 2.5457114395223117

Epoch: 5| Step: 1
Training loss: 2.7638837429831526
Validation loss: 2.56225958175798

Epoch: 5| Step: 2
Training loss: 2.6505077451439134
Validation loss: 2.5636333407399574

Epoch: 5| Step: 3
Training loss: 3.111179154272616
Validation loss: 2.5710514483918585

Epoch: 5| Step: 4
Training loss: 2.777575004382107
Validation loss: 2.571084526558152

Epoch: 5| Step: 5
Training loss: 3.0144250884018375
Validation loss: 2.575581735714805

Epoch: 5| Step: 6
Training loss: 2.7813606668807336
Validation loss: 2.5453210203399736

Epoch: 5| Step: 7
Training loss: 2.611228604299818
Validation loss: 2.544043997755996

Epoch: 5| Step: 8
Training loss: 3.117908518684246
Validation loss: 2.5238400715380394

Epoch: 5| Step: 9
Training loss: 2.602320197029457
Validation loss: 2.525797590704518

Epoch: 5| Step: 10
Training loss: 2.751441491069377
Validation loss: 2.516951830479021

Epoch: 163| Step: 0
Training loss: 2.6003739674925583
Validation loss: 2.5267304777318933

Epoch: 5| Step: 1
Training loss: 3.39932611182369
Validation loss: 2.5241306472634144

Epoch: 5| Step: 2
Training loss: 2.7073680233336455
Validation loss: 2.5221199759693524

Epoch: 5| Step: 3
Training loss: 2.8034765663099668
Validation loss: 2.5207908346779795

Epoch: 5| Step: 4
Training loss: 2.3401776363732507
Validation loss: 2.517737609597216

Epoch: 5| Step: 5
Training loss: 2.913978391359074
Validation loss: 2.53574987700843

Epoch: 5| Step: 6
Training loss: 2.692989686376042
Validation loss: 2.542112864708254

Epoch: 5| Step: 7
Training loss: 2.547639041808594
Validation loss: 2.5413725360178665

Epoch: 5| Step: 8
Training loss: 3.107851661677045
Validation loss: 2.5408896471064617

Epoch: 5| Step: 9
Training loss: 3.1190381973828725
Validation loss: 2.542055539689469

Epoch: 5| Step: 10
Training loss: 3.0297037487174676
Validation loss: 2.543368130289165

Epoch: 164| Step: 0
Training loss: 2.9428226054912208
Validation loss: 2.5281858078460258

Epoch: 5| Step: 1
Training loss: 3.0987863872279795
Validation loss: 2.5248502982805165

Epoch: 5| Step: 2
Training loss: 2.9697758558573413
Validation loss: 2.5232220898782036

Epoch: 5| Step: 3
Training loss: 2.804331637362459
Validation loss: 2.5259339194897934

Epoch: 5| Step: 4
Training loss: 2.1882219485630556
Validation loss: 2.5233815520104477

Epoch: 5| Step: 5
Training loss: 2.3004045420928674
Validation loss: 2.5343783386709395

Epoch: 5| Step: 6
Training loss: 3.1886581112173085
Validation loss: 2.526730968802056

Epoch: 5| Step: 7
Training loss: 3.1870927737533377
Validation loss: 2.51966961392258

Epoch: 5| Step: 8
Training loss: 2.8988421792544363
Validation loss: 2.527346440085726

Epoch: 5| Step: 9
Training loss: 2.7120357344644646
Validation loss: 2.526990056895522

Epoch: 5| Step: 10
Training loss: 2.8761610920745513
Validation loss: 2.52216874232419

Epoch: 165| Step: 0
Training loss: 2.5675686275295497
Validation loss: 2.5237845306633844

Epoch: 5| Step: 1
Training loss: 3.127571268832411
Validation loss: 2.5268914340567146

Epoch: 5| Step: 2
Training loss: 3.3273103818454075
Validation loss: 2.542516384444838

Epoch: 5| Step: 3
Training loss: 2.743226639660932
Validation loss: 2.5329444163585877

Epoch: 5| Step: 4
Training loss: 3.2156520119469514
Validation loss: 2.5403803815547175

Epoch: 5| Step: 5
Training loss: 2.9083631483005314
Validation loss: 2.5333480040212333

Epoch: 5| Step: 6
Training loss: 2.9338001732259986
Validation loss: 2.528459566274014

Epoch: 5| Step: 7
Training loss: 2.4125017472493067
Validation loss: 2.523428972253283

Epoch: 5| Step: 8
Training loss: 2.828135284910943
Validation loss: 2.5153145037665596

Epoch: 5| Step: 9
Training loss: 2.478408943447528
Validation loss: 2.518002993670672

Epoch: 5| Step: 10
Training loss: 2.647100150340485
Validation loss: 2.5148088051745345

Epoch: 166| Step: 0
Training loss: 2.715308806840192
Validation loss: 2.523393369564563

Epoch: 5| Step: 1
Training loss: 3.1804856556888415
Validation loss: 2.5142393989784186

Epoch: 5| Step: 2
Training loss: 2.0757370616386024
Validation loss: 2.5199824006937033

Epoch: 5| Step: 3
Training loss: 3.0112172858399813
Validation loss: 2.5231032057864087

Epoch: 5| Step: 4
Training loss: 3.05883195711934
Validation loss: 2.5237956769265586

Epoch: 5| Step: 5
Training loss: 3.288709317995661
Validation loss: 2.523305000715817

Epoch: 5| Step: 6
Training loss: 2.563362720686477
Validation loss: 2.525960861620324

Epoch: 5| Step: 7
Training loss: 3.037969946907874
Validation loss: 2.5158537980569955

Epoch: 5| Step: 8
Training loss: 2.71096256475377
Validation loss: 2.520550042667653

Epoch: 5| Step: 9
Training loss: 2.2730364363804823
Validation loss: 2.5197391496414756

Epoch: 5| Step: 10
Training loss: 3.100662677446007
Validation loss: 2.5134959173124947

Epoch: 167| Step: 0
Training loss: 3.0627596998066573
Validation loss: 2.52100019445943

Epoch: 5| Step: 1
Training loss: 2.770686803017006
Validation loss: 2.5170982274685234

Epoch: 5| Step: 2
Training loss: 2.936012703184664
Validation loss: 2.5086835855486833

Epoch: 5| Step: 3
Training loss: 2.5919989684597367
Validation loss: 2.5135479995093393

Epoch: 5| Step: 4
Training loss: 2.5152449231875225
Validation loss: 2.5214632912135415

Epoch: 5| Step: 5
Training loss: 2.7015452095921355
Validation loss: 2.523856942402989

Epoch: 5| Step: 6
Training loss: 2.937283122396151
Validation loss: 2.5276158033881346

Epoch: 5| Step: 7
Training loss: 3.070474790210285
Validation loss: 2.529842873312741

Epoch: 5| Step: 8
Training loss: 2.8683928157203082
Validation loss: 2.548879705509155

Epoch: 5| Step: 9
Training loss: 2.856967600488192
Validation loss: 2.562390655017452

Epoch: 5| Step: 10
Training loss: 2.973376233286062
Validation loss: 2.5584318521694067

Epoch: 168| Step: 0
Training loss: 3.008556561276098
Validation loss: 2.544865584368529

Epoch: 5| Step: 1
Training loss: 2.585769140750073
Validation loss: 2.5375417785017915

Epoch: 5| Step: 2
Training loss: 2.796870055806995
Validation loss: 2.531304591157506

Epoch: 5| Step: 3
Training loss: 2.9653987239459014
Validation loss: 2.5260091539545946

Epoch: 5| Step: 4
Training loss: 2.152790002548893
Validation loss: 2.520094730179138

Epoch: 5| Step: 5
Training loss: 2.4935318241907307
Validation loss: 2.50771868120108

Epoch: 5| Step: 6
Training loss: 3.166099062460843
Validation loss: 2.510941684174538

Epoch: 5| Step: 7
Training loss: 3.2942853402080945
Validation loss: 2.5125217393336543

Epoch: 5| Step: 8
Training loss: 3.099602298452067
Validation loss: 2.511654746935212

Epoch: 5| Step: 9
Training loss: 2.8849600052995075
Validation loss: 2.510953067140872

Epoch: 5| Step: 10
Training loss: 2.5797764892756003
Validation loss: 2.5090179178671908

Epoch: 169| Step: 0
Training loss: 2.5966165168369115
Validation loss: 2.5115399872526187

Epoch: 5| Step: 1
Training loss: 2.6995739847986857
Validation loss: 2.5178732955179615

Epoch: 5| Step: 2
Training loss: 2.4407595823256742
Validation loss: 2.526699135285699

Epoch: 5| Step: 3
Training loss: 2.6354566025755077
Validation loss: 2.5271723190918

Epoch: 5| Step: 4
Training loss: 3.1764116588229165
Validation loss: 2.5290321043324

Epoch: 5| Step: 5
Training loss: 3.1792372776121
Validation loss: 2.5379483341593594

Epoch: 5| Step: 6
Training loss: 2.8309362780838585
Validation loss: 2.54230501001774

Epoch: 5| Step: 7
Training loss: 2.8056198738036016
Validation loss: 2.5421712049474583

Epoch: 5| Step: 8
Training loss: 2.897258673056915
Validation loss: 2.538545115523233

Epoch: 5| Step: 9
Training loss: 2.945390533303989
Validation loss: 2.5333297168703717

Epoch: 5| Step: 10
Training loss: 2.932041534722919
Validation loss: 2.531182304802862

Epoch: 170| Step: 0
Training loss: 2.437963783940237
Validation loss: 2.5462585303061362

Epoch: 5| Step: 1
Training loss: 2.8355808506690745
Validation loss: 2.5287095445607735

Epoch: 5| Step: 2
Training loss: 3.1301737871765596
Validation loss: 2.524572560801921

Epoch: 5| Step: 3
Training loss: 3.1289833621310876
Validation loss: 2.5173801665150064

Epoch: 5| Step: 4
Training loss: 2.4785489079350196
Validation loss: 2.5157140238235094

Epoch: 5| Step: 5
Training loss: 2.5268591957249082
Validation loss: 2.5167805565311525

Epoch: 5| Step: 6
Training loss: 2.7558754664329115
Validation loss: 2.5070864848407504

Epoch: 5| Step: 7
Training loss: 2.879749852549147
Validation loss: 2.5193346660871976

Epoch: 5| Step: 8
Training loss: 3.497936594218839
Validation loss: 2.5165698015358076

Epoch: 5| Step: 9
Training loss: 2.763484579149223
Validation loss: 2.514039379815496

Epoch: 5| Step: 10
Training loss: 2.430209971488818
Validation loss: 2.507882477947413

Epoch: 171| Step: 0
Training loss: 2.8461268625943146
Validation loss: 2.506516513867654

Epoch: 5| Step: 1
Training loss: 2.6282595424255715
Validation loss: 2.5052886746025376

Epoch: 5| Step: 2
Training loss: 2.9949211999273726
Validation loss: 2.5063259301160397

Epoch: 5| Step: 3
Training loss: 2.365313200263203
Validation loss: 2.5091729023908993

Epoch: 5| Step: 4
Training loss: 2.7194709260469665
Validation loss: 2.5114661189696403

Epoch: 5| Step: 5
Training loss: 3.3575890340241057
Validation loss: 2.5088427342982476

Epoch: 5| Step: 6
Training loss: 2.897210120906003
Validation loss: 2.511672784643096

Epoch: 5| Step: 7
Training loss: 3.0211968214210487
Validation loss: 2.514527426067063

Epoch: 5| Step: 8
Training loss: 2.600250096396932
Validation loss: 2.5278503738920564

Epoch: 5| Step: 9
Training loss: 3.3340781969077606
Validation loss: 2.5416377842750024

Epoch: 5| Step: 10
Training loss: 1.917464864078183
Validation loss: 2.5666949043537137

Epoch: 172| Step: 0
Training loss: 2.9313722369443838
Validation loss: 2.56359750538753

Epoch: 5| Step: 1
Training loss: 1.9994538276685139
Validation loss: 2.5468592449168734

Epoch: 5| Step: 2
Training loss: 2.659388046142996
Validation loss: 2.5301580237281165

Epoch: 5| Step: 3
Training loss: 3.4526133438719597
Validation loss: 2.5255471171160497

Epoch: 5| Step: 4
Training loss: 2.5870368211246975
Validation loss: 2.52325101373061

Epoch: 5| Step: 5
Training loss: 2.7403148549579077
Validation loss: 2.508072967951617

Epoch: 5| Step: 6
Training loss: 2.704454304621343
Validation loss: 2.500810981798739

Epoch: 5| Step: 7
Training loss: 2.686677851342079
Validation loss: 2.49708325248118

Epoch: 5| Step: 8
Training loss: 2.752247672091877
Validation loss: 2.4964027016516823

Epoch: 5| Step: 9
Training loss: 3.389314178365648
Validation loss: 2.4985873763856765

Epoch: 5| Step: 10
Training loss: 3.0669650789554526
Validation loss: 2.507443562131163

Epoch: 173| Step: 0
Training loss: 2.7233799939805996
Validation loss: 2.504918716916307

Epoch: 5| Step: 1
Training loss: 2.7408586635174945
Validation loss: 2.517565615198162

Epoch: 5| Step: 2
Training loss: 2.587334569535439
Validation loss: 2.5418404184062244

Epoch: 5| Step: 3
Training loss: 3.4668301604916176
Validation loss: 2.536872363195543

Epoch: 5| Step: 4
Training loss: 2.815108890629468
Validation loss: 2.5171117601154362

Epoch: 5| Step: 5
Training loss: 3.0013068849383138
Validation loss: 2.501838726743658

Epoch: 5| Step: 6
Training loss: 2.539156867987924
Validation loss: 2.5000910403994894

Epoch: 5| Step: 7
Training loss: 2.3507129237094913
Validation loss: 2.49838124853406

Epoch: 5| Step: 8
Training loss: 2.8819103948785236
Validation loss: 2.5011244408842837

Epoch: 5| Step: 9
Training loss: 2.6591370096189655
Validation loss: 2.4951378722997366

Epoch: 5| Step: 10
Training loss: 3.1035288383725956
Validation loss: 2.4977928036969717

Epoch: 174| Step: 0
Training loss: 2.4356523015286173
Validation loss: 2.5029666546729064

Epoch: 5| Step: 1
Training loss: 2.1641342206287115
Validation loss: 2.5036508646454454

Epoch: 5| Step: 2
Training loss: 2.7103818824250356
Validation loss: 2.5183156586305566

Epoch: 5| Step: 3
Training loss: 2.992373786884274
Validation loss: 2.5533390139573315

Epoch: 5| Step: 4
Training loss: 3.181126674217711
Validation loss: 2.5466649768929828

Epoch: 5| Step: 5
Training loss: 3.446874839526784
Validation loss: 2.5381365545576124

Epoch: 5| Step: 6
Training loss: 2.4043922684289596
Validation loss: 2.530329773120211

Epoch: 5| Step: 7
Training loss: 3.3068880731024666
Validation loss: 2.5160353671152498

Epoch: 5| Step: 8
Training loss: 2.778566587558078
Validation loss: 2.5223876553227527

Epoch: 5| Step: 9
Training loss: 2.6820100111749627
Validation loss: 2.5160658846254638

Epoch: 5| Step: 10
Training loss: 2.8533358141926946
Validation loss: 2.523985917652813

Epoch: 175| Step: 0
Training loss: 2.82247740271065
Validation loss: 2.5052416140071934

Epoch: 5| Step: 1
Training loss: 3.0195342504330984
Validation loss: 2.4991625644542244

Epoch: 5| Step: 2
Training loss: 2.9570767236637248
Validation loss: 2.495252231529632

Epoch: 5| Step: 3
Training loss: 2.6269956904369796
Validation loss: 2.4926461842976275

Epoch: 5| Step: 4
Training loss: 2.936417238061357
Validation loss: 2.4982007699645012

Epoch: 5| Step: 5
Training loss: 2.7832291665448357
Validation loss: 2.4945595466923955

Epoch: 5| Step: 6
Training loss: 2.5406698450538907
Validation loss: 2.492504419510532

Epoch: 5| Step: 7
Training loss: 3.041675689544533
Validation loss: 2.495242433125913

Epoch: 5| Step: 8
Training loss: 2.504089253562486
Validation loss: 2.495264521346819

Epoch: 5| Step: 9
Training loss: 2.8985720703472375
Validation loss: 2.493333211976889

Epoch: 5| Step: 10
Training loss: 2.808930229648679
Validation loss: 2.5071879481223234

Epoch: 176| Step: 0
Training loss: 2.725483065843504
Validation loss: 2.5054788051836927

Epoch: 5| Step: 1
Training loss: 2.595080666289736
Validation loss: 2.509565885689315

Epoch: 5| Step: 2
Training loss: 2.851406981525435
Validation loss: 2.5038856048728575

Epoch: 5| Step: 3
Training loss: 2.7981745082487763
Validation loss: 2.4908902059126414

Epoch: 5| Step: 4
Training loss: 3.1540726809354815
Validation loss: 2.4889939305075215

Epoch: 5| Step: 5
Training loss: 2.9400115943212968
Validation loss: 2.49476616500209

Epoch: 5| Step: 6
Training loss: 2.272646736972237
Validation loss: 2.484644463423247

Epoch: 5| Step: 7
Training loss: 3.280613283415134
Validation loss: 2.4904902745536655

Epoch: 5| Step: 8
Training loss: 2.9583625971103418
Validation loss: 2.49435514668338

Epoch: 5| Step: 9
Training loss: 2.8579932037336775
Validation loss: 2.492208176198328

Epoch: 5| Step: 10
Training loss: 2.387986366303341
Validation loss: 2.4987098728488037

Epoch: 177| Step: 0
Training loss: 2.4663766003078074
Validation loss: 2.501653783632959

Epoch: 5| Step: 1
Training loss: 3.08212485128977
Validation loss: 2.5290748986887253

Epoch: 5| Step: 2
Training loss: 2.775144411745537
Validation loss: 2.533861909956162

Epoch: 5| Step: 3
Training loss: 2.7309030343004608
Validation loss: 2.545668788884047

Epoch: 5| Step: 4
Training loss: 2.5632896137188297
Validation loss: 2.5725962692739355

Epoch: 5| Step: 5
Training loss: 2.8451779312245393
Validation loss: 2.566074329083661

Epoch: 5| Step: 6
Training loss: 3.3559390927449604
Validation loss: 2.5486967767153

Epoch: 5| Step: 7
Training loss: 2.7632372187459744
Validation loss: 2.534203377633769

Epoch: 5| Step: 8
Training loss: 3.012674578281568
Validation loss: 2.5007308137892847

Epoch: 5| Step: 9
Training loss: 2.5619935256256796
Validation loss: 2.5035631065849167

Epoch: 5| Step: 10
Training loss: 2.8331540742901704
Validation loss: 2.4949349998396406

Epoch: 178| Step: 0
Training loss: 2.8271531600780935
Validation loss: 2.4963804925662694

Epoch: 5| Step: 1
Training loss: 2.875007131816477
Validation loss: 2.4931786103921487

Epoch: 5| Step: 2
Training loss: 2.7257231811390854
Validation loss: 2.498238715281385

Epoch: 5| Step: 3
Training loss: 2.2857000763485518
Validation loss: 2.4962545343081266

Epoch: 5| Step: 4
Training loss: 2.4361048887437464
Validation loss: 2.5045035539624045

Epoch: 5| Step: 5
Training loss: 2.8525612950070784
Validation loss: 2.515088338441143

Epoch: 5| Step: 6
Training loss: 3.1925837050108767
Validation loss: 2.5146573192177946

Epoch: 5| Step: 7
Training loss: 2.981866551269127
Validation loss: 2.5249307340894527

Epoch: 5| Step: 8
Training loss: 2.948677387192474
Validation loss: 2.5278239245031804

Epoch: 5| Step: 9
Training loss: 2.8714235700226194
Validation loss: 2.5145921705995513

Epoch: 5| Step: 10
Training loss: 2.973477584721025
Validation loss: 2.5187291294207177

Epoch: 179| Step: 0
Training loss: 2.1122115666237025
Validation loss: 2.530136072944361

Epoch: 5| Step: 1
Training loss: 2.7910147707639528
Validation loss: 2.56354985014286

Epoch: 5| Step: 2
Training loss: 2.9936773112159174
Validation loss: 2.568295665474672

Epoch: 5| Step: 3
Training loss: 2.8198255292881154
Validation loss: 2.5391210062434557

Epoch: 5| Step: 4
Training loss: 3.0524416421346525
Validation loss: 2.5060700077462723

Epoch: 5| Step: 5
Training loss: 2.9425968835481666
Validation loss: 2.5085733173454776

Epoch: 5| Step: 6
Training loss: 3.037318182633112
Validation loss: 2.519802654351789

Epoch: 5| Step: 7
Training loss: 3.104068848436278
Validation loss: 2.5380590382234463

Epoch: 5| Step: 8
Training loss: 2.3523148762005555
Validation loss: 2.574742765249003

Epoch: 5| Step: 9
Training loss: 2.8089020497514072
Validation loss: 2.600927135697449

Epoch: 5| Step: 10
Training loss: 3.2356614949741873
Validation loss: 2.5634489105811475

Epoch: 180| Step: 0
Training loss: 2.691415019913823
Validation loss: 2.552214513692494

Epoch: 5| Step: 1
Training loss: 2.1492828370678905
Validation loss: 2.5576573906447884

Epoch: 5| Step: 2
Training loss: 2.9468169480690936
Validation loss: 2.6145151320039157

Epoch: 5| Step: 3
Training loss: 2.4173673951192938
Validation loss: 2.709629071346842

Epoch: 5| Step: 4
Training loss: 3.336442609867646
Validation loss: 2.8467058742184617

Epoch: 5| Step: 5
Training loss: 3.000658122036604
Validation loss: 2.841648829710327

Epoch: 5| Step: 6
Training loss: 3.2909866467566924
Validation loss: 2.642938358675015

Epoch: 5| Step: 7
Training loss: 2.6479897809883077
Validation loss: 2.488566271492627

Epoch: 5| Step: 8
Training loss: 3.0845210047585
Validation loss: 2.4886301863977085

Epoch: 5| Step: 9
Training loss: 2.985222341668911
Validation loss: 2.495956723971819

Epoch: 5| Step: 10
Training loss: 3.148833673508013
Validation loss: 2.493135385999208

Epoch: 181| Step: 0
Training loss: 2.9372977329174104
Validation loss: 2.4980070312409453

Epoch: 5| Step: 1
Training loss: 2.8753724893506662
Validation loss: 2.533866481048966

Epoch: 5| Step: 2
Training loss: 2.94511465526244
Validation loss: 2.5532066335879327

Epoch: 5| Step: 3
Training loss: 3.0205220204564
Validation loss: 2.5669132409344977

Epoch: 5| Step: 4
Training loss: 2.581893293934164
Validation loss: 2.5744610686905394

Epoch: 5| Step: 5
Training loss: 2.8855759522762487
Validation loss: 2.597614446330322

Epoch: 5| Step: 6
Training loss: 2.630943925684087
Validation loss: 2.5782559249413914

Epoch: 5| Step: 7
Training loss: 3.250384528080224
Validation loss: 2.5668547888848683

Epoch: 5| Step: 8
Training loss: 3.208409560317741
Validation loss: 2.5457506947590107

Epoch: 5| Step: 9
Training loss: 2.465483907281532
Validation loss: 2.5324677657847716

Epoch: 5| Step: 10
Training loss: 2.9895013848923764
Validation loss: 2.489838312716755

Epoch: 182| Step: 0
Training loss: 3.0020600239689093
Validation loss: 2.48250124323848

Epoch: 5| Step: 1
Training loss: 3.12237514884573
Validation loss: 2.4765788337497807

Epoch: 5| Step: 2
Training loss: 2.5275492046634085
Validation loss: 2.477175254968429

Epoch: 5| Step: 3
Training loss: 2.7346791125528442
Validation loss: 2.4835537377075165

Epoch: 5| Step: 4
Training loss: 2.923326264492117
Validation loss: 2.4738040280538476

Epoch: 5| Step: 5
Training loss: 2.7172267636779606
Validation loss: 2.5193998558974395

Epoch: 5| Step: 6
Training loss: 2.5194642523795716
Validation loss: 2.561141538661317

Epoch: 5| Step: 7
Training loss: 2.881194366116558
Validation loss: 2.6004018715156474

Epoch: 5| Step: 8
Training loss: 3.1213360478735517
Validation loss: 2.6476216788910625

Epoch: 5| Step: 9
Training loss: 2.7549191607403576
Validation loss: 2.6958831387541533

Epoch: 5| Step: 10
Training loss: 3.055257992753266
Validation loss: 2.6881004010057343

Epoch: 183| Step: 0
Training loss: 2.5677944475839034
Validation loss: 2.676973936222938

Epoch: 5| Step: 1
Training loss: 2.9169740424088304
Validation loss: 2.7077622762112035

Epoch: 5| Step: 2
Training loss: 2.603405731926796
Validation loss: 2.6542685398399533

Epoch: 5| Step: 3
Training loss: 3.118341753275636
Validation loss: 2.6128683145480487

Epoch: 5| Step: 4
Training loss: 2.0688781375903855
Validation loss: 2.5826639849096122

Epoch: 5| Step: 5
Training loss: 3.0893651540986355
Validation loss: 2.5805587781015182

Epoch: 5| Step: 6
Training loss: 3.289330405879435
Validation loss: 2.5832108982326543

Epoch: 5| Step: 7
Training loss: 2.9249879298816968
Validation loss: 2.5768918725006245

Epoch: 5| Step: 8
Training loss: 2.768378315039009
Validation loss: 2.5872124106539145

Epoch: 5| Step: 9
Training loss: 3.111838433609568
Validation loss: 2.5812937901959825

Epoch: 5| Step: 10
Training loss: 3.113381569656827
Validation loss: 2.5931145979074928

Epoch: 184| Step: 0
Training loss: 3.149703989804228
Validation loss: 2.591009741181658

Epoch: 5| Step: 1
Training loss: 2.5113007715313582
Validation loss: 2.5700251188008685

Epoch: 5| Step: 2
Training loss: 2.88149870421794
Validation loss: 2.562708554308618

Epoch: 5| Step: 3
Training loss: 2.5867863209896145
Validation loss: 2.5607510993202

Epoch: 5| Step: 4
Training loss: 3.091292513050992
Validation loss: 2.5540217665848126

Epoch: 5| Step: 5
Training loss: 2.7093807444792044
Validation loss: 2.567468878423846

Epoch: 5| Step: 6
Training loss: 2.7161504660713476
Validation loss: 2.5658285371339993

Epoch: 5| Step: 7
Training loss: 3.450695166832245
Validation loss: 2.566321898609225

Epoch: 5| Step: 8
Training loss: 2.8101719864040646
Validation loss: 2.5611188013956694

Epoch: 5| Step: 9
Training loss: 3.080651345429594
Validation loss: 2.555724211944798

Epoch: 5| Step: 10
Training loss: 2.6996413699144495
Validation loss: 2.5584112141541917

Epoch: 185| Step: 0
Training loss: 2.778498799736858
Validation loss: 2.552245313783185

Epoch: 5| Step: 1
Training loss: 2.6538263371215716
Validation loss: 2.5471062851198996

Epoch: 5| Step: 2
Training loss: 2.651680370401697
Validation loss: 2.547093733134406

Epoch: 5| Step: 3
Training loss: 2.9085066043279726
Validation loss: 2.5431374910883977

Epoch: 5| Step: 4
Training loss: 2.9990267764451457
Validation loss: 2.531323997867279

Epoch: 5| Step: 5
Training loss: 2.5343952182852303
Validation loss: 2.5384061989024125

Epoch: 5| Step: 6
Training loss: 2.776070733601099
Validation loss: 2.5421221436095824

Epoch: 5| Step: 7
Training loss: 2.660994477482412
Validation loss: 2.522421038289453

Epoch: 5| Step: 8
Training loss: 2.657505142766762
Validation loss: 2.521510769899311

Epoch: 5| Step: 9
Training loss: 3.166775366941964
Validation loss: 2.5141313271615884

Epoch: 5| Step: 10
Training loss: 3.6128207846379015
Validation loss: 2.4993017236677293

Epoch: 186| Step: 0
Training loss: 2.9147778162353264
Validation loss: 2.506258581535151

Epoch: 5| Step: 1
Training loss: 2.8399285431052395
Validation loss: 2.4988399429063763

Epoch: 5| Step: 2
Training loss: 2.6875729218281768
Validation loss: 2.512508753360966

Epoch: 5| Step: 3
Training loss: 3.0659375263774398
Validation loss: 2.514473339324166

Epoch: 5| Step: 4
Training loss: 2.962119638997943
Validation loss: 2.512722410862376

Epoch: 5| Step: 5
Training loss: 2.714598105315512
Validation loss: 2.5163109497065244

Epoch: 5| Step: 6
Training loss: 2.9416127733979813
Validation loss: 2.5148891258521267

Epoch: 5| Step: 7
Training loss: 2.557553052007048
Validation loss: 2.536332739922298

Epoch: 5| Step: 8
Training loss: 2.727374024388421
Validation loss: 2.517855079247664

Epoch: 5| Step: 9
Training loss: 2.4628471594536387
Validation loss: 2.5195996967648777

Epoch: 5| Step: 10
Training loss: 3.040087843177937
Validation loss: 2.5342600598665044

Epoch: 187| Step: 0
Training loss: 2.963842894000521
Validation loss: 2.543363482531874

Epoch: 5| Step: 1
Training loss: 2.681452667472978
Validation loss: 2.5586013840172654

Epoch: 5| Step: 2
Training loss: 3.151748014785772
Validation loss: 2.547805989417241

Epoch: 5| Step: 3
Training loss: 2.7055577262679975
Validation loss: 2.519180290451249

Epoch: 5| Step: 4
Training loss: 2.853018610998209
Validation loss: 2.505828480490149

Epoch: 5| Step: 5
Training loss: 2.681045054892727
Validation loss: 2.488406875748141

Epoch: 5| Step: 6
Training loss: 3.031745791445139
Validation loss: 2.489583894888561

Epoch: 5| Step: 7
Training loss: 2.156586772769389
Validation loss: 2.4847747703982987

Epoch: 5| Step: 8
Training loss: 2.955393409424162
Validation loss: 2.472337401128449

Epoch: 5| Step: 9
Training loss: 3.000625068395988
Validation loss: 2.4771998659179295

Epoch: 5| Step: 10
Training loss: 2.6905544577465994
Validation loss: 2.4772003844000436

Epoch: 188| Step: 0
Training loss: 2.6143792871945744
Validation loss: 2.47547805990232

Epoch: 5| Step: 1
Training loss: 2.4925559796902554
Validation loss: 2.469749621104176

Epoch: 5| Step: 2
Training loss: 2.706276087822395
Validation loss: 2.4849095624949196

Epoch: 5| Step: 3
Training loss: 3.015292767027147
Validation loss: 2.4773432691744786

Epoch: 5| Step: 4
Training loss: 2.883736645783787
Validation loss: 2.4708048943383587

Epoch: 5| Step: 5
Training loss: 3.0561593258752526
Validation loss: 2.4726805990391707

Epoch: 5| Step: 6
Training loss: 2.6658844297217867
Validation loss: 2.4696236919709267

Epoch: 5| Step: 7
Training loss: 2.7712988115897743
Validation loss: 2.4745137254554206

Epoch: 5| Step: 8
Training loss: 2.8593596577884166
Validation loss: 2.475769665518176

Epoch: 5| Step: 9
Training loss: 3.053014116411407
Validation loss: 2.4713020617882444

Epoch: 5| Step: 10
Training loss: 2.8178060706222743
Validation loss: 2.4757764345226425

Epoch: 189| Step: 0
Training loss: 2.9100680958753933
Validation loss: 2.4816939843442114

Epoch: 5| Step: 1
Training loss: 2.3094105058348653
Validation loss: 2.4866258173158973

Epoch: 5| Step: 2
Training loss: 2.745391017809253
Validation loss: 2.492389101045933

Epoch: 5| Step: 3
Training loss: 2.944755035989388
Validation loss: 2.4855166176813577

Epoch: 5| Step: 4
Training loss: 2.8814955600516994
Validation loss: 2.492196998728533

Epoch: 5| Step: 5
Training loss: 2.9239952839762466
Validation loss: 2.4966391050258627

Epoch: 5| Step: 6
Training loss: 2.868220753770253
Validation loss: 2.499309649569429

Epoch: 5| Step: 7
Training loss: 3.216611577749831
Validation loss: 2.508664696553604

Epoch: 5| Step: 8
Training loss: 2.423692968444156
Validation loss: 2.5073585195178487

Epoch: 5| Step: 9
Training loss: 2.7001051599721904
Validation loss: 2.5265303505788155

Epoch: 5| Step: 10
Training loss: 2.7076374822848113
Validation loss: 2.531298153954866

Epoch: 190| Step: 0
Training loss: 2.888234402619971
Validation loss: 2.5369202992722713

Epoch: 5| Step: 1
Training loss: 2.9314265671768074
Validation loss: 2.5316285103937988

Epoch: 5| Step: 2
Training loss: 2.838692496022614
Validation loss: 2.4994880577664174

Epoch: 5| Step: 3
Training loss: 2.8340488166238993
Validation loss: 2.492869844319036

Epoch: 5| Step: 4
Training loss: 2.9673468235143172
Validation loss: 2.481268978834132

Epoch: 5| Step: 5
Training loss: 2.9586725353935157
Validation loss: 2.470254567064044

Epoch: 5| Step: 6
Training loss: 2.2984939371178
Validation loss: 2.4739504218932993

Epoch: 5| Step: 7
Training loss: 2.612512586645442
Validation loss: 2.476398837726239

Epoch: 5| Step: 8
Training loss: 3.4776047419468097
Validation loss: 2.47776353679053

Epoch: 5| Step: 9
Training loss: 2.678550545747279
Validation loss: 2.4688015422682086

Epoch: 5| Step: 10
Training loss: 2.253554186108371
Validation loss: 2.4635928031461547

Epoch: 191| Step: 0
Training loss: 2.8848651308371625
Validation loss: 2.465341392719656

Epoch: 5| Step: 1
Training loss: 3.011161861562869
Validation loss: 2.4668504534113316

Epoch: 5| Step: 2
Training loss: 2.711043473956455
Validation loss: 2.4768547614667273

Epoch: 5| Step: 3
Training loss: 2.2405917241007756
Validation loss: 2.4786767076460388

Epoch: 5| Step: 4
Training loss: 3.1832959743790785
Validation loss: 2.486205807309194

Epoch: 5| Step: 5
Training loss: 2.601771898978222
Validation loss: 2.4915473366024776

Epoch: 5| Step: 6
Training loss: 2.6895753698332063
Validation loss: 2.494388081577162

Epoch: 5| Step: 7
Training loss: 3.1047803199688886
Validation loss: 2.512066541289773

Epoch: 5| Step: 8
Training loss: 2.7153989814142196
Validation loss: 2.4968682762424166

Epoch: 5| Step: 9
Training loss: 2.8589608981756576
Validation loss: 2.4995665471851565

Epoch: 5| Step: 10
Training loss: 2.7739525545074133
Validation loss: 2.4910798969039485

Epoch: 192| Step: 0
Training loss: 2.858475507160525
Validation loss: 2.481537908640781

Epoch: 5| Step: 1
Training loss: 2.7061357434405005
Validation loss: 2.4686955894703835

Epoch: 5| Step: 2
Training loss: 2.8200979388930327
Validation loss: 2.4711641590240236

Epoch: 5| Step: 3
Training loss: 2.592066758685419
Validation loss: 2.470969063034707

Epoch: 5| Step: 4
Training loss: 2.5727607175281113
Validation loss: 2.472730011766365

Epoch: 5| Step: 5
Training loss: 3.032418094796288
Validation loss: 2.4669040857373288

Epoch: 5| Step: 6
Training loss: 2.47653775849604
Validation loss: 2.4722861980354724

Epoch: 5| Step: 7
Training loss: 2.98779851467505
Validation loss: 2.4671457409793476

Epoch: 5| Step: 8
Training loss: 2.980859413391921
Validation loss: 2.4659087691984833

Epoch: 5| Step: 9
Training loss: 2.7525453925136096
Validation loss: 2.468750184841728

Epoch: 5| Step: 10
Training loss: 2.912087760860432
Validation loss: 2.464321292435318

Epoch: 193| Step: 0
Training loss: 2.709960585585563
Validation loss: 2.477149158670784

Epoch: 5| Step: 1
Training loss: 2.6710746414112494
Validation loss: 2.4804073079052085

Epoch: 5| Step: 2
Training loss: 2.75051207543132
Validation loss: 2.486640044683487

Epoch: 5| Step: 3
Training loss: 2.8033336038698966
Validation loss: 2.510454474656206

Epoch: 5| Step: 4
Training loss: 2.3776961632959734
Validation loss: 2.5309884379181686

Epoch: 5| Step: 5
Training loss: 3.0714388812326154
Validation loss: 2.5342917447954862

Epoch: 5| Step: 6
Training loss: 3.191201398384513
Validation loss: 2.501820444957865

Epoch: 5| Step: 7
Training loss: 2.674759139153305
Validation loss: 2.5039654732537553

Epoch: 5| Step: 8
Training loss: 3.0511046175954384
Validation loss: 2.4932965276528587

Epoch: 5| Step: 9
Training loss: 2.5652307056385073
Validation loss: 2.474054062723148

Epoch: 5| Step: 10
Training loss: 2.8343538428613617
Validation loss: 2.4692313598708933

Epoch: 194| Step: 0
Training loss: 2.8076192255427386
Validation loss: 2.4733445448972766

Epoch: 5| Step: 1
Training loss: 2.5045981083634405
Validation loss: 2.461997789461463

Epoch: 5| Step: 2
Training loss: 2.6573912917517486
Validation loss: 2.474250361893853

Epoch: 5| Step: 3
Training loss: 3.1149946640728214
Validation loss: 2.4746542396884244

Epoch: 5| Step: 4
Training loss: 2.541886950676511
Validation loss: 2.46615998792419

Epoch: 5| Step: 5
Training loss: 2.563698837089669
Validation loss: 2.470414055301657

Epoch: 5| Step: 6
Training loss: 3.293613067618079
Validation loss: 2.4694846137530617

Epoch: 5| Step: 7
Training loss: 2.210518517576053
Validation loss: 2.46341215902095

Epoch: 5| Step: 8
Training loss: 2.991109230437057
Validation loss: 2.480343306171833

Epoch: 5| Step: 9
Training loss: 2.821738181277274
Validation loss: 2.4832158871572747

Epoch: 5| Step: 10
Training loss: 2.991157214921175
Validation loss: 2.4964932283439065

Epoch: 195| Step: 0
Training loss: 2.2976648957661525
Validation loss: 2.510974605707881

Epoch: 5| Step: 1
Training loss: 2.6986338620730117
Validation loss: 2.5314136544893535

Epoch: 5| Step: 2
Training loss: 2.936890234460181
Validation loss: 2.5315922807388818

Epoch: 5| Step: 3
Training loss: 2.9289317058963964
Validation loss: 2.538281824644284

Epoch: 5| Step: 4
Training loss: 2.970372128276916
Validation loss: 2.524764504706033

Epoch: 5| Step: 5
Training loss: 2.9686359584387154
Validation loss: 2.512798709139393

Epoch: 5| Step: 6
Training loss: 3.1428824894366043
Validation loss: 2.511067174723808

Epoch: 5| Step: 7
Training loss: 2.713891434535439
Validation loss: 2.491036979828967

Epoch: 5| Step: 8
Training loss: 2.858773590377531
Validation loss: 2.4812435584319057

Epoch: 5| Step: 9
Training loss: 2.557475304209334
Validation loss: 2.473955401088011

Epoch: 5| Step: 10
Training loss: 2.4563302645782104
Validation loss: 2.475904124695087

Epoch: 196| Step: 0
Training loss: 2.666585046790666
Validation loss: 2.4726569944195687

Epoch: 5| Step: 1
Training loss: 3.3864094066028723
Validation loss: 2.4648949496051937

Epoch: 5| Step: 2
Training loss: 2.807466877769957
Validation loss: 2.473818864933607

Epoch: 5| Step: 3
Training loss: 2.6724334490120034
Validation loss: 2.4693013789551284

Epoch: 5| Step: 4
Training loss: 2.3881466054850047
Validation loss: 2.4667525356593067

Epoch: 5| Step: 5
Training loss: 2.4810323240180217
Validation loss: 2.470555082878856

Epoch: 5| Step: 6
Training loss: 2.971908816236448
Validation loss: 2.469226927644787

Epoch: 5| Step: 7
Training loss: 2.5999999523162836
Validation loss: 2.477039434474756

Epoch: 5| Step: 8
Training loss: 2.700746228269913
Validation loss: 2.4658466014681077

Epoch: 5| Step: 9
Training loss: 2.8867567418634943
Validation loss: 2.484850132677695

Epoch: 5| Step: 10
Training loss: 2.9599271071969717
Validation loss: 2.4900486503059236

Epoch: 197| Step: 0
Training loss: 2.1267794843822454
Validation loss: 2.499212647605279

Epoch: 5| Step: 1
Training loss: 3.2877261239960744
Validation loss: 2.51818194204394

Epoch: 5| Step: 2
Training loss: 2.352099183138708
Validation loss: 2.517369911443434

Epoch: 5| Step: 3
Training loss: 2.5464999619024615
Validation loss: 2.512557806252939

Epoch: 5| Step: 4
Training loss: 3.0586302305654898
Validation loss: 2.5096068299987193

Epoch: 5| Step: 5
Training loss: 2.7862775987616235
Validation loss: 2.4998363482327495

Epoch: 5| Step: 6
Training loss: 2.2272963000661976
Validation loss: 2.494539543601486

Epoch: 5| Step: 7
Training loss: 3.17274230224118
Validation loss: 2.473288645405985

Epoch: 5| Step: 8
Training loss: 2.4669674582559846
Validation loss: 2.4726618725394696

Epoch: 5| Step: 9
Training loss: 3.2627647321726654
Validation loss: 2.4740768001842315

Epoch: 5| Step: 10
Training loss: 3.049038788716079
Validation loss: 2.4684383548179007

Epoch: 198| Step: 0
Training loss: 3.1784436091506003
Validation loss: 2.474153117276701

Epoch: 5| Step: 1
Training loss: 3.0515442112747206
Validation loss: 2.48115990850411

Epoch: 5| Step: 2
Training loss: 2.9387045480579306
Validation loss: 2.479753387781503

Epoch: 5| Step: 3
Training loss: 2.724736517670793
Validation loss: 2.4736236570412067

Epoch: 5| Step: 4
Training loss: 2.5429360289453506
Validation loss: 2.475916150221333

Epoch: 5| Step: 5
Training loss: 2.594207079954826
Validation loss: 2.47684918570675

Epoch: 5| Step: 6
Training loss: 3.1944107238169175
Validation loss: 2.4746754767593164

Epoch: 5| Step: 7
Training loss: 2.3539727617825386
Validation loss: 2.468398651089486

Epoch: 5| Step: 8
Training loss: 2.1993946933325375
Validation loss: 2.4762541674523666

Epoch: 5| Step: 9
Training loss: 2.848163407824147
Validation loss: 2.4832701901374215

Epoch: 5| Step: 10
Training loss: 2.695655513443022
Validation loss: 2.4852607506577526

Epoch: 199| Step: 0
Training loss: 2.7084017720500766
Validation loss: 2.4923331329066016

Epoch: 5| Step: 1
Training loss: 2.859628301355199
Validation loss: 2.5097814924050468

Epoch: 5| Step: 2
Training loss: 2.9455553354386095
Validation loss: 2.5369103636964105

Epoch: 5| Step: 3
Training loss: 3.090058561591107
Validation loss: 2.5275530700785596

Epoch: 5| Step: 4
Training loss: 2.5151216939374805
Validation loss: 2.5057146817105487

Epoch: 5| Step: 5
Training loss: 2.766140992041802
Validation loss: 2.501734369879618

Epoch: 5| Step: 6
Training loss: 2.1228794288052217
Validation loss: 2.4946271772045083

Epoch: 5| Step: 7
Training loss: 2.6427985280580897
Validation loss: 2.487852253560163

Epoch: 5| Step: 8
Training loss: 3.0485456532542834
Validation loss: 2.4807382264284583

Epoch: 5| Step: 9
Training loss: 2.827637351129376
Validation loss: 2.4692373826605887

Epoch: 5| Step: 10
Training loss: 2.801220294159953
Validation loss: 2.464675182239558

Epoch: 200| Step: 0
Training loss: 2.958728942925093
Validation loss: 2.4670782611652347

Epoch: 5| Step: 1
Training loss: 2.2200875347510034
Validation loss: 2.4534656347466437

Epoch: 5| Step: 2
Training loss: 2.479334870944769
Validation loss: 2.4644692742034175

Epoch: 5| Step: 3
Training loss: 2.4466944680293152
Validation loss: 2.4697340009838418

Epoch: 5| Step: 4
Training loss: 2.6057147091552086
Validation loss: 2.4671040213207034

Epoch: 5| Step: 5
Training loss: 3.1790878892756735
Validation loss: 2.477505824980372

Epoch: 5| Step: 6
Training loss: 3.2704047308982775
Validation loss: 2.503584840822874

Epoch: 5| Step: 7
Training loss: 2.2694863923936643
Validation loss: 2.4997468881760443

Epoch: 5| Step: 8
Training loss: 2.9896348866837017
Validation loss: 2.469313113237417

Epoch: 5| Step: 9
Training loss: 3.2122912743590426
Validation loss: 2.4696905769869724

Epoch: 5| Step: 10
Training loss: 2.4523975241247102
Validation loss: 2.460182933950335

Epoch: 201| Step: 0
Training loss: 2.103231115058935
Validation loss: 2.4744230432147565

Epoch: 5| Step: 1
Training loss: 2.1757173648680403
Validation loss: 2.4561415054385036

Epoch: 5| Step: 2
Training loss: 3.0088717886631184
Validation loss: 2.454795125184396

Epoch: 5| Step: 3
Training loss: 2.8785903736668885
Validation loss: 2.4598122915983236

Epoch: 5| Step: 4
Training loss: 2.5842118974024304
Validation loss: 2.4580581073676364

Epoch: 5| Step: 5
Training loss: 3.2535600970404266
Validation loss: 2.4574322930683747

Epoch: 5| Step: 6
Training loss: 2.81676380358654
Validation loss: 2.4651640184118264

Epoch: 5| Step: 7
Training loss: 2.7412003264512297
Validation loss: 2.4686323838561397

Epoch: 5| Step: 8
Training loss: 3.0653010423687066
Validation loss: 2.4636588269189406

Epoch: 5| Step: 9
Training loss: 2.5635311564127092
Validation loss: 2.481289747047975

Epoch: 5| Step: 10
Training loss: 2.9101960659503594
Validation loss: 2.4715522759236412

Epoch: 202| Step: 0
Training loss: 2.8258231052613687
Validation loss: 2.464693479512703

Epoch: 5| Step: 1
Training loss: 2.587616620223018
Validation loss: 2.46526118709149

Epoch: 5| Step: 2
Training loss: 2.2814310080425417
Validation loss: 2.471988384765552

Epoch: 5| Step: 3
Training loss: 2.4529200182758406
Validation loss: 2.466405834272139

Epoch: 5| Step: 4
Training loss: 3.088169034679833
Validation loss: 2.472577412832767

Epoch: 5| Step: 5
Training loss: 2.3475493090958652
Validation loss: 2.467796961054063

Epoch: 5| Step: 6
Training loss: 2.8612871290791806
Validation loss: 2.4640206744095505

Epoch: 5| Step: 7
Training loss: 2.8752970334733563
Validation loss: 2.4669739417354704

Epoch: 5| Step: 8
Training loss: 2.7443512207891456
Validation loss: 2.4670814908114136

Epoch: 5| Step: 9
Training loss: 2.916582996439853
Validation loss: 2.463752063441461

Epoch: 5| Step: 10
Training loss: 3.2319269175906458
Validation loss: 2.4611386036125684

Epoch: 203| Step: 0
Training loss: 2.285767354519444
Validation loss: 2.4753956857652994

Epoch: 5| Step: 1
Training loss: 3.2586191765820507
Validation loss: 2.482071149671519

Epoch: 5| Step: 2
Training loss: 2.3699232351369304
Validation loss: 2.471249426398399

Epoch: 5| Step: 3
Training loss: 3.0644674404143006
Validation loss: 2.4807527996525365

Epoch: 5| Step: 4
Training loss: 2.6123179212573673
Validation loss: 2.488522430258901

Epoch: 5| Step: 5
Training loss: 1.9069505873721093
Validation loss: 2.4961132990032273

Epoch: 5| Step: 6
Training loss: 3.064251768500238
Validation loss: 2.4830944929898666

Epoch: 5| Step: 7
Training loss: 2.9849408796580397
Validation loss: 2.4862444481660106

Epoch: 5| Step: 8
Training loss: 2.8895611429130224
Validation loss: 2.4819304810414575

Epoch: 5| Step: 9
Training loss: 2.8928306618744988
Validation loss: 2.4837024057136707

Epoch: 5| Step: 10
Training loss: 2.4342597552187577
Validation loss: 2.4810335949717066

Epoch: 204| Step: 0
Training loss: 2.5854648492356844
Validation loss: 2.479479982868467

Epoch: 5| Step: 1
Training loss: 3.0756987483379032
Validation loss: 2.4835754602161866

Epoch: 5| Step: 2
Training loss: 2.33169640161052
Validation loss: 2.4790360218210363

Epoch: 5| Step: 3
Training loss: 2.4819457455160663
Validation loss: 2.478701371949327

Epoch: 5| Step: 4
Training loss: 2.3401526755059665
Validation loss: 2.4806065251195157

Epoch: 5| Step: 5
Training loss: 3.1866938749718656
Validation loss: 2.484219375496271

Epoch: 5| Step: 6
Training loss: 2.873330668236484
Validation loss: 2.4736522374233454

Epoch: 5| Step: 7
Training loss: 2.7224077196131153
Validation loss: 2.4855357620114518

Epoch: 5| Step: 8
Training loss: 2.8154575480162007
Validation loss: 2.482102455566051

Epoch: 5| Step: 9
Training loss: 2.7895450121237166
Validation loss: 2.4853469578788387

Epoch: 5| Step: 10
Training loss: 2.799228636894258
Validation loss: 2.4769832488784944

Epoch: 205| Step: 0
Training loss: 2.8635421987907512
Validation loss: 2.485445048699453

Epoch: 5| Step: 1
Training loss: 2.497104493863139
Validation loss: 2.483727871654098

Epoch: 5| Step: 2
Training loss: 2.5918723974313727
Validation loss: 2.483146327021445

Epoch: 5| Step: 3
Training loss: 2.903183662799143
Validation loss: 2.4953234529634662

Epoch: 5| Step: 4
Training loss: 2.7741603715190544
Validation loss: 2.4828332198244194

Epoch: 5| Step: 5
Training loss: 2.8870218450805267
Validation loss: 2.472497445045287

Epoch: 5| Step: 6
Training loss: 2.1363968127199935
Validation loss: 2.4842699931242227

Epoch: 5| Step: 7
Training loss: 2.988986780989289
Validation loss: 2.4857445624023717

Epoch: 5| Step: 8
Training loss: 3.2674389049652732
Validation loss: 2.4830105027537046

Epoch: 5| Step: 9
Training loss: 2.1242685742162717
Validation loss: 2.4843818631950954

Epoch: 5| Step: 10
Training loss: 2.8694502297960938
Validation loss: 2.4969671454752964

Epoch: 206| Step: 0
Training loss: 2.4636026150433907
Validation loss: 2.481432742448805

Epoch: 5| Step: 1
Training loss: 2.6198080579322016
Validation loss: 2.4718541528505553

Epoch: 5| Step: 2
Training loss: 3.1007417222182942
Validation loss: 2.474945682374165

Epoch: 5| Step: 3
Training loss: 2.295682117261535
Validation loss: 2.4690899420833303

Epoch: 5| Step: 4
Training loss: 2.960567239846586
Validation loss: 2.466075884573362

Epoch: 5| Step: 5
Training loss: 3.1116453537077415
Validation loss: 2.4772636456478625

Epoch: 5| Step: 6
Training loss: 2.8142498083223844
Validation loss: 2.4646150387874424

Epoch: 5| Step: 7
Training loss: 2.434729835985311
Validation loss: 2.4698424553950753

Epoch: 5| Step: 8
Training loss: 2.4127041349865004
Validation loss: 2.461857124540317

Epoch: 5| Step: 9
Training loss: 3.2884609369988693
Validation loss: 2.465384649994902

Epoch: 5| Step: 10
Training loss: 2.412837337963381
Validation loss: 2.473485900294662

Epoch: 207| Step: 0
Training loss: 3.1340113602890622
Validation loss: 2.4657415655593047

Epoch: 5| Step: 1
Training loss: 2.735842240274807
Validation loss: 2.4892006575386545

Epoch: 5| Step: 2
Training loss: 2.2533132741625908
Validation loss: 2.4874883589933634

Epoch: 5| Step: 3
Training loss: 2.6457873563200955
Validation loss: 2.4891647218279394

Epoch: 5| Step: 4
Training loss: 2.3882848717759075
Validation loss: 2.4872920120392785

Epoch: 5| Step: 5
Training loss: 2.3298962914630748
Validation loss: 2.480700462964283

Epoch: 5| Step: 6
Training loss: 2.893160805751559
Validation loss: 2.4804722474654666

Epoch: 5| Step: 7
Training loss: 3.1615966230351256
Validation loss: 2.4633076791305664

Epoch: 5| Step: 8
Training loss: 3.2563957957834897
Validation loss: 2.4593787117996366

Epoch: 5| Step: 9
Training loss: 2.836053178598021
Validation loss: 2.45317616202632

Epoch: 5| Step: 10
Training loss: 2.2228866484550855
Validation loss: 2.450169920747353

Epoch: 208| Step: 0
Training loss: 2.7305974534335435
Validation loss: 2.4583610104156395

Epoch: 5| Step: 1
Training loss: 2.3797734125450165
Validation loss: 2.459926458870734

Epoch: 5| Step: 2
Training loss: 2.469745097424518
Validation loss: 2.4678805289416896

Epoch: 5| Step: 3
Training loss: 2.293476418958797
Validation loss: 2.4734212084820255

Epoch: 5| Step: 4
Training loss: 2.603573225433011
Validation loss: 2.4776690095650546

Epoch: 5| Step: 5
Training loss: 3.008064398187815
Validation loss: 2.484562911170232

Epoch: 5| Step: 6
Training loss: 2.8731542550357405
Validation loss: 2.508001448754299

Epoch: 5| Step: 7
Training loss: 2.9824025291509915
Validation loss: 2.5128889757100086

Epoch: 5| Step: 8
Training loss: 3.1378662746666612
Validation loss: 2.5273491727716886

Epoch: 5| Step: 9
Training loss: 2.781592015871708
Validation loss: 2.5225321686953968

Epoch: 5| Step: 10
Training loss: 3.032453946788325
Validation loss: 2.537674978064719

Epoch: 209| Step: 0
Training loss: 2.6353931853161754
Validation loss: 2.5075508302917187

Epoch: 5| Step: 1
Training loss: 2.5414117362159314
Validation loss: 2.4997572237492314

Epoch: 5| Step: 2
Training loss: 2.46882725848257
Validation loss: 2.4689800289762487

Epoch: 5| Step: 3
Training loss: 3.0160191727997687
Validation loss: 2.4809761120819207

Epoch: 5| Step: 4
Training loss: 2.472170910201563
Validation loss: 2.482629743561548

Epoch: 5| Step: 5
Training loss: 3.0723075306066074
Validation loss: 2.4694088645580523

Epoch: 5| Step: 6
Training loss: 2.8033551209911325
Validation loss: 2.4629692663668132

Epoch: 5| Step: 7
Training loss: 2.4431191256909464
Validation loss: 2.4649776356527937

Epoch: 5| Step: 8
Training loss: 3.3905210698807307
Validation loss: 2.4620029948381874

Epoch: 5| Step: 9
Training loss: 2.530266276282803
Validation loss: 2.459095061706709

Epoch: 5| Step: 10
Training loss: 3.011470324293288
Validation loss: 2.4538873402761405

Epoch: 210| Step: 0
Training loss: 3.3044678815728683
Validation loss: 2.459774644605502

Epoch: 5| Step: 1
Training loss: 2.7267323088575233
Validation loss: 2.466625821602153

Epoch: 5| Step: 2
Training loss: 1.9940541815632817
Validation loss: 2.474479149150812

Epoch: 5| Step: 3
Training loss: 2.427885411444691
Validation loss: 2.4965269170028987

Epoch: 5| Step: 4
Training loss: 2.70570435694658
Validation loss: 2.5009140425377114

Epoch: 5| Step: 5
Training loss: 2.897260977206566
Validation loss: 2.495101511447492

Epoch: 5| Step: 6
Training loss: 2.2195323585579994
Validation loss: 2.478310669307531

Epoch: 5| Step: 7
Training loss: 2.7815992157538654
Validation loss: 2.483300211123195

Epoch: 5| Step: 8
Training loss: 2.459735298181815
Validation loss: 2.470907292378568

Epoch: 5| Step: 9
Training loss: 3.358908545468496
Validation loss: 2.4522036218625036

Epoch: 5| Step: 10
Training loss: 3.0410463580254996
Validation loss: 2.4610461451802177

Epoch: 211| Step: 0
Training loss: 3.0214703293851786
Validation loss: 2.453879667271852

Epoch: 5| Step: 1
Training loss: 2.5417361223913746
Validation loss: 2.450337345771817

Epoch: 5| Step: 2
Training loss: 2.8766756564899008
Validation loss: 2.457975611479714

Epoch: 5| Step: 3
Training loss: 2.573555057622245
Validation loss: 2.450692951548607

Epoch: 5| Step: 4
Training loss: 2.344665246914081
Validation loss: 2.459568404483873

Epoch: 5| Step: 5
Training loss: 2.291152989008584
Validation loss: 2.459583632632709

Epoch: 5| Step: 6
Training loss: 3.212804692287362
Validation loss: 2.4663915556676774

Epoch: 5| Step: 7
Training loss: 2.64674165608262
Validation loss: 2.4537589045323385

Epoch: 5| Step: 8
Training loss: 2.5997727111358504
Validation loss: 2.457034570063182

Epoch: 5| Step: 9
Training loss: 3.2256217120707635
Validation loss: 2.4698416571903303

Epoch: 5| Step: 10
Training loss: 2.5538711410074324
Validation loss: 2.483938262230556

Epoch: 212| Step: 0
Training loss: 2.867025843748309
Validation loss: 2.4708156643234194

Epoch: 5| Step: 1
Training loss: 1.8610807656744845
Validation loss: 2.492129341357513

Epoch: 5| Step: 2
Training loss: 2.5700604625372945
Validation loss: 2.4789005204587085

Epoch: 5| Step: 3
Training loss: 2.715830144826682
Validation loss: 2.4731822965820145

Epoch: 5| Step: 4
Training loss: 2.735186298448286
Validation loss: 2.459689919567571

Epoch: 5| Step: 5
Training loss: 2.858267647866165
Validation loss: 2.465052922499492

Epoch: 5| Step: 6
Training loss: 3.043937949892844
Validation loss: 2.458114175915532

Epoch: 5| Step: 7
Training loss: 2.7218119599742714
Validation loss: 2.4623944026430045

Epoch: 5| Step: 8
Training loss: 2.3272744487626036
Validation loss: 2.466419869570193

Epoch: 5| Step: 9
Training loss: 3.1518764598569984
Validation loss: 2.4671293021734444

Epoch: 5| Step: 10
Training loss: 2.996081654351399
Validation loss: 2.4664015903015906

Epoch: 213| Step: 0
Training loss: 2.600019484226873
Validation loss: 2.479006241857311

Epoch: 5| Step: 1
Training loss: 2.828434711168748
Validation loss: 2.4982442197006125

Epoch: 5| Step: 2
Training loss: 2.5181314054262334
Validation loss: 2.472445865767064

Epoch: 5| Step: 3
Training loss: 2.7506654974503033
Validation loss: 2.494269793489212

Epoch: 5| Step: 4
Training loss: 2.2445640596089005
Validation loss: 2.4823639822445513

Epoch: 5| Step: 5
Training loss: 2.480552371560455
Validation loss: 2.486515785466802

Epoch: 5| Step: 6
Training loss: 3.246004729995525
Validation loss: 2.4688078745149604

Epoch: 5| Step: 7
Training loss: 3.037760085285603
Validation loss: 2.4752794998107492

Epoch: 5| Step: 8
Training loss: 2.7140871599182845
Validation loss: 2.467929401002279

Epoch: 5| Step: 9
Training loss: 2.375495055954497
Validation loss: 2.471483752585739

Epoch: 5| Step: 10
Training loss: 3.1824469811996825
Validation loss: 2.4757362354563193

Epoch: 214| Step: 0
Training loss: 1.9735803837822263
Validation loss: 2.475167967183723

Epoch: 5| Step: 1
Training loss: 3.110010743444598
Validation loss: 2.466253456289723

Epoch: 5| Step: 2
Training loss: 2.7622056070600225
Validation loss: 2.4617560558457945

Epoch: 5| Step: 3
Training loss: 2.7233821826072675
Validation loss: 2.4693265558131756

Epoch: 5| Step: 4
Training loss: 3.104514919604569
Validation loss: 2.4584758754414175

Epoch: 5| Step: 5
Training loss: 2.52149383046736
Validation loss: 2.469364275198639

Epoch: 5| Step: 6
Training loss: 2.5256992278393042
Validation loss: 2.4691028677682927

Epoch: 5| Step: 7
Training loss: 2.7665674360320214
Validation loss: 2.4686320411556735

Epoch: 5| Step: 8
Training loss: 2.6944251327434343
Validation loss: 2.4666327923851945

Epoch: 5| Step: 9
Training loss: 2.5630553969499905
Validation loss: 2.468780716766881

Epoch: 5| Step: 10
Training loss: 2.9939686227503572
Validation loss: 2.4696664631715595

Epoch: 215| Step: 0
Training loss: 2.7473508906492667
Validation loss: 2.462286617607044

Epoch: 5| Step: 1
Training loss: 2.43433879389545
Validation loss: 2.46392497485489

Epoch: 5| Step: 2
Training loss: 2.1977883492809
Validation loss: 2.474100396438865

Epoch: 5| Step: 3
Training loss: 3.41845057987759
Validation loss: 2.4530999803073845

Epoch: 5| Step: 4
Training loss: 2.9217214288999664
Validation loss: 2.4511576153805708

Epoch: 5| Step: 5
Training loss: 2.2417409631643337
Validation loss: 2.4437550351056627

Epoch: 5| Step: 6
Training loss: 3.023243663794135
Validation loss: 2.4489231369861466

Epoch: 5| Step: 7
Training loss: 3.0545379524014975
Validation loss: 2.448934584199171

Epoch: 5| Step: 8
Training loss: 2.3387922621414843
Validation loss: 2.4429840426261813

Epoch: 5| Step: 9
Training loss: 2.5248118339904275
Validation loss: 2.4453402003978897

Epoch: 5| Step: 10
Training loss: 2.899117032823498
Validation loss: 2.463613354077979

Epoch: 216| Step: 0
Training loss: 3.055982232406654
Validation loss: 2.4588690254563947

Epoch: 5| Step: 1
Training loss: 1.916784165415851
Validation loss: 2.470434026473898

Epoch: 5| Step: 2
Training loss: 2.6185285633941042
Validation loss: 2.4552630075564936

Epoch: 5| Step: 3
Training loss: 2.3040886569714654
Validation loss: 2.4578142933913

Epoch: 5| Step: 4
Training loss: 2.5540194790006967
Validation loss: 2.46642050777262

Epoch: 5| Step: 5
Training loss: 2.800511728936105
Validation loss: 2.4644697267079736

Epoch: 5| Step: 6
Training loss: 2.8354922278709225
Validation loss: 2.4746207759105796

Epoch: 5| Step: 7
Training loss: 2.8238659396946293
Validation loss: 2.4605232563346524

Epoch: 5| Step: 8
Training loss: 2.6846418929730387
Validation loss: 2.4637584731796833

Epoch: 5| Step: 9
Training loss: 2.910714606670392
Validation loss: 2.47580900977421

Epoch: 5| Step: 10
Training loss: 3.186711082814002
Validation loss: 2.452884762372508

Epoch: 217| Step: 0
Training loss: 2.597561253696498
Validation loss: 2.4564629355651415

Epoch: 5| Step: 1
Training loss: 3.1451714095086185
Validation loss: 2.4436285783890876

Epoch: 5| Step: 2
Training loss: 2.78488521674973
Validation loss: 2.446595046780144

Epoch: 5| Step: 3
Training loss: 2.830670807396832
Validation loss: 2.436109364394059

Epoch: 5| Step: 4
Training loss: 2.7469752756678782
Validation loss: 2.44085670898469

Epoch: 5| Step: 5
Training loss: 2.9413816088775304
Validation loss: 2.4449496127897974

Epoch: 5| Step: 6
Training loss: 2.404111035351798
Validation loss: 2.451157124858227

Epoch: 5| Step: 7
Training loss: 2.7483540724539957
Validation loss: 2.4454694724603536

Epoch: 5| Step: 8
Training loss: 2.348275862947839
Validation loss: 2.4392871883504297

Epoch: 5| Step: 9
Training loss: 2.675916682247792
Validation loss: 2.4458714061069338

Epoch: 5| Step: 10
Training loss: 2.5050373825360035
Validation loss: 2.440543395909978

Epoch: 218| Step: 0
Training loss: 2.614504039114194
Validation loss: 2.4448767598195116

Epoch: 5| Step: 1
Training loss: 2.6686016354203406
Validation loss: 2.458188524738301

Epoch: 5| Step: 2
Training loss: 2.8581046529179526
Validation loss: 2.4666599883321982

Epoch: 5| Step: 3
Training loss: 2.2176990437764745
Validation loss: 2.469088246549067

Epoch: 5| Step: 4
Training loss: 2.7264550305366893
Validation loss: 2.4781747920760786

Epoch: 5| Step: 5
Training loss: 2.8326031548082047
Validation loss: 2.5077676989814166

Epoch: 5| Step: 6
Training loss: 2.547021218063586
Validation loss: 2.51249429494673

Epoch: 5| Step: 7
Training loss: 3.2418121488298457
Validation loss: 2.5097554327900395

Epoch: 5| Step: 8
Training loss: 2.974701387180822
Validation loss: 2.4965761827610824

Epoch: 5| Step: 9
Training loss: 2.616764592405643
Validation loss: 2.47824761167883

Epoch: 5| Step: 10
Training loss: 2.483076896057514
Validation loss: 2.4592994260642134

Epoch: 219| Step: 0
Training loss: 2.487259539766198
Validation loss: 2.4560061689056654

Epoch: 5| Step: 1
Training loss: 3.4382430227243956
Validation loss: 2.453715664845676

Epoch: 5| Step: 2
Training loss: 2.862645514508536
Validation loss: 2.4455699866995477

Epoch: 5| Step: 3
Training loss: 2.3046947414478396
Validation loss: 2.442613285289233

Epoch: 5| Step: 4
Training loss: 2.566031372003412
Validation loss: 2.443483996479526

Epoch: 5| Step: 5
Training loss: 2.6121280788723493
Validation loss: 2.443124527640963

Epoch: 5| Step: 6
Training loss: 2.9250141762936046
Validation loss: 2.450363967200794

Epoch: 5| Step: 7
Training loss: 2.710491924330857
Validation loss: 2.4486093243263216

Epoch: 5| Step: 8
Training loss: 2.310170314669891
Validation loss: 2.4517426779926885

Epoch: 5| Step: 9
Training loss: 2.7117609977453436
Validation loss: 2.452396883841037

Epoch: 5| Step: 10
Training loss: 2.6525496794769943
Validation loss: 2.4501241086222385

Epoch: 220| Step: 0
Training loss: 2.3243135320747377
Validation loss: 2.470825393584593

Epoch: 5| Step: 1
Training loss: 2.5683814682391017
Validation loss: 2.473920689519332

Epoch: 5| Step: 2
Training loss: 2.7715987866734157
Validation loss: 2.496474053028352

Epoch: 5| Step: 3
Training loss: 3.2083456526350504
Validation loss: 2.51552607936017

Epoch: 5| Step: 4
Training loss: 2.8298526776792046
Validation loss: 2.495869644464883

Epoch: 5| Step: 5
Training loss: 2.5623441509211853
Validation loss: 2.470508685784845

Epoch: 5| Step: 6
Training loss: 2.9247909927684397
Validation loss: 2.466126360026267

Epoch: 5| Step: 7
Training loss: 2.901826342623159
Validation loss: 2.4597147184966888

Epoch: 5| Step: 8
Training loss: 2.4635331286120437
Validation loss: 2.4558688634587433

Epoch: 5| Step: 9
Training loss: 2.273921744564406
Validation loss: 2.444044305154939

Epoch: 5| Step: 10
Training loss: 2.805958069567574
Validation loss: 2.4488720112057707

Epoch: 221| Step: 0
Training loss: 2.921054990214901
Validation loss: 2.454746580650181

Epoch: 5| Step: 1
Training loss: 2.169345837624839
Validation loss: 2.4447671779600793

Epoch: 5| Step: 2
Training loss: 2.97704049024638
Validation loss: 2.4447169620045313

Epoch: 5| Step: 3
Training loss: 2.6424815857389126
Validation loss: 2.4528561908499915

Epoch: 5| Step: 4
Training loss: 2.808429400180959
Validation loss: 2.471098929202899

Epoch: 5| Step: 5
Training loss: 2.3756268326597465
Validation loss: 2.4643911363432816

Epoch: 5| Step: 6
Training loss: 2.9440471653062645
Validation loss: 2.478068902785445

Epoch: 5| Step: 7
Training loss: 2.772576770734307
Validation loss: 2.471197072062549

Epoch: 5| Step: 8
Training loss: 2.8715804952517785
Validation loss: 2.4621843223018747

Epoch: 5| Step: 9
Training loss: 2.7930179191476174
Validation loss: 2.4659642943431646

Epoch: 5| Step: 10
Training loss: 2.3428627878047976
Validation loss: 2.4654731919918964

Epoch: 222| Step: 0
Training loss: 2.8728560041330646
Validation loss: 2.459540610002805

Epoch: 5| Step: 1
Training loss: 2.6317679033704118
Validation loss: 2.4593264904529057

Epoch: 5| Step: 2
Training loss: 2.3193110607218514
Validation loss: 2.4561656142614887

Epoch: 5| Step: 3
Training loss: 2.4444626376409415
Validation loss: 2.4528628077837653

Epoch: 5| Step: 4
Training loss: 2.728619081342145
Validation loss: 2.4416720694922054

Epoch: 5| Step: 5
Training loss: 2.7745332514381915
Validation loss: 2.4511896696001636

Epoch: 5| Step: 6
Training loss: 2.5876589113540467
Validation loss: 2.4569183985723693

Epoch: 5| Step: 7
Training loss: 3.103208628715601
Validation loss: 2.4433236800087603

Epoch: 5| Step: 8
Training loss: 2.596798954663915
Validation loss: 2.434280749673263

Epoch: 5| Step: 9
Training loss: 2.759506872186192
Validation loss: 2.4415070123695792

Epoch: 5| Step: 10
Training loss: 2.527923470328637
Validation loss: 2.443029203714712

Epoch: 223| Step: 0
Training loss: 3.0157489652305385
Validation loss: 2.4504277266751844

Epoch: 5| Step: 1
Training loss: 2.8492663192020604
Validation loss: 2.464570522887903

Epoch: 5| Step: 2
Training loss: 2.5507477879337515
Validation loss: 2.4710239619564747

Epoch: 5| Step: 3
Training loss: 2.554546573963247
Validation loss: 2.4643251425934163

Epoch: 5| Step: 4
Training loss: 2.427204298243932
Validation loss: 2.4759474852750674

Epoch: 5| Step: 5
Training loss: 2.8961368282830158
Validation loss: 2.4610988362873485

Epoch: 5| Step: 6
Training loss: 2.5392970519668316
Validation loss: 2.461904867626211

Epoch: 5| Step: 7
Training loss: 2.5453480080504085
Validation loss: 2.4446609584677357

Epoch: 5| Step: 8
Training loss: 2.973162774581182
Validation loss: 2.4501072207828383

Epoch: 5| Step: 9
Training loss: 2.577379708503231
Validation loss: 2.4550175480309107

Epoch: 5| Step: 10
Training loss: 2.497282458540558
Validation loss: 2.4894633436504394

Epoch: 224| Step: 0
Training loss: 2.4004726659723845
Validation loss: 2.472186999200454

Epoch: 5| Step: 1
Training loss: 3.2035581714533827
Validation loss: 2.4918187168453456

Epoch: 5| Step: 2
Training loss: 2.843428541186757
Validation loss: 2.4768824485983174

Epoch: 5| Step: 3
Training loss: 2.9388311089178236
Validation loss: 2.4705261128148446

Epoch: 5| Step: 4
Training loss: 2.5473187767910086
Validation loss: 2.468998892426323

Epoch: 5| Step: 5
Training loss: 2.6904266745105634
Validation loss: 2.4573523905649886

Epoch: 5| Step: 6
Training loss: 2.3450254911489092
Validation loss: 2.4742757645191418

Epoch: 5| Step: 7
Training loss: 1.922951125652113
Validation loss: 2.468960360662302

Epoch: 5| Step: 8
Training loss: 2.8921247561020595
Validation loss: 2.471302478808674

Epoch: 5| Step: 9
Training loss: 2.75186770044624
Validation loss: 2.476861709672054

Epoch: 5| Step: 10
Training loss: 2.880351517735753
Validation loss: 2.457600240410046

Epoch: 225| Step: 0
Training loss: 2.5567932782742466
Validation loss: 2.458049475868207

Epoch: 5| Step: 1
Training loss: 2.7928810799450607
Validation loss: 2.4465411421430687

Epoch: 5| Step: 2
Training loss: 2.7272726189006438
Validation loss: 2.4626839629371036

Epoch: 5| Step: 3
Training loss: 2.774844218512405
Validation loss: 2.4604227340537435

Epoch: 5| Step: 4
Training loss: 2.6454472497912755
Validation loss: 2.4584343918818665

Epoch: 5| Step: 5
Training loss: 2.7880411281425452
Validation loss: 2.4643505226933993

Epoch: 5| Step: 6
Training loss: 2.662023933366108
Validation loss: 2.4663877809758326

Epoch: 5| Step: 7
Training loss: 2.501436011829376
Validation loss: 2.4745774065873207

Epoch: 5| Step: 8
Training loss: 2.751038095302688
Validation loss: 2.4870462181889494

Epoch: 5| Step: 9
Training loss: 2.9274454311428824
Validation loss: 2.4914490415174786

Epoch: 5| Step: 10
Training loss: 2.2102733463728046
Validation loss: 2.4954265888045417

Epoch: 226| Step: 0
Training loss: 2.61589113838984
Validation loss: 2.4817315829047

Epoch: 5| Step: 1
Training loss: 2.6183236004870896
Validation loss: 2.4947522758193

Epoch: 5| Step: 2
Training loss: 2.4087561895016787
Validation loss: 2.4661790018447505

Epoch: 5| Step: 3
Training loss: 2.7932270490809166
Validation loss: 2.461621829905029

Epoch: 5| Step: 4
Training loss: 2.88820352942454
Validation loss: 2.45958966549681

Epoch: 5| Step: 5
Training loss: 2.5787737405842632
Validation loss: 2.442316337428982

Epoch: 5| Step: 6
Training loss: 2.8522104023690686
Validation loss: 2.441550067168614

Epoch: 5| Step: 7
Training loss: 3.004278311239942
Validation loss: 2.4411440456896

Epoch: 5| Step: 8
Training loss: 2.499659515083047
Validation loss: 2.4437654354439995

Epoch: 5| Step: 9
Training loss: 2.7937551818389967
Validation loss: 2.438218575894725

Epoch: 5| Step: 10
Training loss: 2.425598530790795
Validation loss: 2.436465666284126

Epoch: 227| Step: 0
Training loss: 2.682420232463182
Validation loss: 2.4380310969279044

Epoch: 5| Step: 1
Training loss: 2.6705104622806464
Validation loss: 2.445423834363415

Epoch: 5| Step: 2
Training loss: 2.693777603751449
Validation loss: 2.467170131933712

Epoch: 5| Step: 3
Training loss: 2.488089609476547
Validation loss: 2.4778544578616737

Epoch: 5| Step: 4
Training loss: 2.9710661837442256
Validation loss: 2.5120076314938764

Epoch: 5| Step: 5
Training loss: 2.626629006056113
Validation loss: 2.5025322643546204

Epoch: 5| Step: 6
Training loss: 2.392295503078132
Validation loss: 2.505669763378677

Epoch: 5| Step: 7
Training loss: 2.811517840661762
Validation loss: 2.495572628509055

Epoch: 5| Step: 8
Training loss: 3.25599542893035
Validation loss: 2.487669660084163

Epoch: 5| Step: 9
Training loss: 2.2273335510469976
Validation loss: 2.451121073811965

Epoch: 5| Step: 10
Training loss: 2.6121086375031672
Validation loss: 2.4542748070273577

Epoch: 228| Step: 0
Training loss: 2.7070143397740227
Validation loss: 2.451233173475406

Epoch: 5| Step: 1
Training loss: 3.2318404582370026
Validation loss: 2.4505267444875947

Epoch: 5| Step: 2
Training loss: 2.1013648638626896
Validation loss: 2.4414649333505025

Epoch: 5| Step: 3
Training loss: 2.7882709822568548
Validation loss: 2.4334014246144564

Epoch: 5| Step: 4
Training loss: 2.336241839431871
Validation loss: 2.4341995543146564

Epoch: 5| Step: 5
Training loss: 3.2814982002482376
Validation loss: 2.4243128230119826

Epoch: 5| Step: 6
Training loss: 2.694668900316015
Validation loss: 2.4378208110200785

Epoch: 5| Step: 7
Training loss: 2.6230647810085497
Validation loss: 2.4334503844249986

Epoch: 5| Step: 8
Training loss: 1.7626786080622963
Validation loss: 2.456235026268228

Epoch: 5| Step: 9
Training loss: 2.6697977479490116
Validation loss: 2.472208739663298

Epoch: 5| Step: 10
Training loss: 2.902741149557681
Validation loss: 2.4779587868623514

Epoch: 229| Step: 0
Training loss: 2.4615173625500297
Validation loss: 2.4685304896423825

Epoch: 5| Step: 1
Training loss: 2.4812647706175897
Validation loss: 2.446617674784555

Epoch: 5| Step: 2
Training loss: 2.9263970779942463
Validation loss: 2.4343481265897404

Epoch: 5| Step: 3
Training loss: 2.532495074705134
Validation loss: 2.4215775904275785

Epoch: 5| Step: 4
Training loss: 2.63648997126697
Validation loss: 2.435906679591671

Epoch: 5| Step: 5
Training loss: 2.8592232418957897
Validation loss: 2.4340405858926166

Epoch: 5| Step: 6
Training loss: 2.5810513620863937
Validation loss: 2.4205575514770534

Epoch: 5| Step: 7
Training loss: 2.2859334031731273
Validation loss: 2.431817583350686

Epoch: 5| Step: 8
Training loss: 2.7871761835293887
Validation loss: 2.4295752514271625

Epoch: 5| Step: 9
Training loss: 3.337763195161193
Validation loss: 2.43136912951706

Epoch: 5| Step: 10
Training loss: 2.3756089684623642
Validation loss: 2.4580199026361704

Epoch: 230| Step: 0
Training loss: 3.008950233785766
Validation loss: 2.4894367273878433

Epoch: 5| Step: 1
Training loss: 2.507928768326711
Validation loss: 2.5858145702153066

Epoch: 5| Step: 2
Training loss: 3.1432114005146383
Validation loss: 2.6836376447810877

Epoch: 5| Step: 3
Training loss: 2.759806142024986
Validation loss: 2.593435927470426

Epoch: 5| Step: 4
Training loss: 2.7603597575145455
Validation loss: 2.52561897789898

Epoch: 5| Step: 5
Training loss: 2.8213725541470827
Validation loss: 2.496519775536016

Epoch: 5| Step: 6
Training loss: 2.77688547637701
Validation loss: 2.502941017793721

Epoch: 5| Step: 7
Training loss: 3.1568583289359324
Validation loss: 2.5038857369514287

Epoch: 5| Step: 8
Training loss: 2.6265651033423763
Validation loss: 2.5088647436544687

Epoch: 5| Step: 9
Training loss: 1.7064905073973187
Validation loss: 2.5019342774112925

Epoch: 5| Step: 10
Training loss: 2.250098650147208
Validation loss: 2.526751005194995

Epoch: 231| Step: 0
Training loss: 1.9080871734218416
Validation loss: 2.5208997986330766

Epoch: 5| Step: 1
Training loss: 2.4108566181611253
Validation loss: 2.5145618278927597

Epoch: 5| Step: 2
Training loss: 2.3890768785461893
Validation loss: 2.457997046888738

Epoch: 5| Step: 3
Training loss: 2.5045035805763245
Validation loss: 2.43848397856207

Epoch: 5| Step: 4
Training loss: 2.771144639121422
Validation loss: 2.4245341426586737

Epoch: 5| Step: 5
Training loss: 3.1553724220874964
Validation loss: 2.4106100358595093

Epoch: 5| Step: 6
Training loss: 2.6143552115774638
Validation loss: 2.416123774408175

Epoch: 5| Step: 7
Training loss: 2.878246464687626
Validation loss: 2.4123929567183864

Epoch: 5| Step: 8
Training loss: 2.6161176174332508
Validation loss: 2.413746834236141

Epoch: 5| Step: 9
Training loss: 2.6024826301339505
Validation loss: 2.418365484666939

Epoch: 5| Step: 10
Training loss: 3.6769284800197264
Validation loss: 2.42235373569486

Epoch: 232| Step: 0
Training loss: 2.4761823007340364
Validation loss: 2.4270153822178577

Epoch: 5| Step: 1
Training loss: 2.534185332363655
Validation loss: 2.4321629446538453

Epoch: 5| Step: 2
Training loss: 2.9829229047674253
Validation loss: 2.433763638370276

Epoch: 5| Step: 3
Training loss: 2.2848177667317042
Validation loss: 2.437801327734171

Epoch: 5| Step: 4
Training loss: 2.3548327041133033
Validation loss: 2.439005281513322

Epoch: 5| Step: 5
Training loss: 2.649814394083027
Validation loss: 2.451560868931876

Epoch: 5| Step: 6
Training loss: 2.6253237751692637
Validation loss: 2.456188432776212

Epoch: 5| Step: 7
Training loss: 3.1278203825442064
Validation loss: 2.442469424714268

Epoch: 5| Step: 8
Training loss: 2.7631268614266786
Validation loss: 2.469953096117223

Epoch: 5| Step: 9
Training loss: 3.220376798014699
Validation loss: 2.4788812183629965

Epoch: 5| Step: 10
Training loss: 2.266134270618293
Validation loss: 2.498666938055718

Epoch: 233| Step: 0
Training loss: 2.784844465312899
Validation loss: 2.4597068859663938

Epoch: 5| Step: 1
Training loss: 2.758447849474237
Validation loss: 2.4373642878671875

Epoch: 5| Step: 2
Training loss: 2.8839259698072373
Validation loss: 2.4391541380840622

Epoch: 5| Step: 3
Training loss: 2.5000304220255933
Validation loss: 2.434778274208428

Epoch: 5| Step: 4
Training loss: 2.4541347879391315
Validation loss: 2.4335802196020615

Epoch: 5| Step: 5
Training loss: 3.303818175773936
Validation loss: 2.431295686140659

Epoch: 5| Step: 6
Training loss: 2.139745155561641
Validation loss: 2.432966366693244

Epoch: 5| Step: 7
Training loss: 2.8207475744046153
Validation loss: 2.4516263571749453

Epoch: 5| Step: 8
Training loss: 2.3309528151179193
Validation loss: 2.4466671559841653

Epoch: 5| Step: 9
Training loss: 2.634200910108121
Validation loss: 2.4472889978926395

Epoch: 5| Step: 10
Training loss: 2.4062935961452436
Validation loss: 2.452388534003957

Epoch: 234| Step: 0
Training loss: 2.5699048864078815
Validation loss: 2.4514680775055986

Epoch: 5| Step: 1
Training loss: 2.0911311382254008
Validation loss: 2.457635745780106

Epoch: 5| Step: 2
Training loss: 2.031395540158581
Validation loss: 2.4531508471092183

Epoch: 5| Step: 3
Training loss: 2.7387760167037447
Validation loss: 2.46402607527493

Epoch: 5| Step: 4
Training loss: 3.0498300161051977
Validation loss: 2.476376578125786

Epoch: 5| Step: 5
Training loss: 2.418438251129006
Validation loss: 2.4602294778426113

Epoch: 5| Step: 6
Training loss: 3.14541397499545
Validation loss: 2.4595983551715648

Epoch: 5| Step: 7
Training loss: 2.7483816586840284
Validation loss: 2.447643950977368

Epoch: 5| Step: 8
Training loss: 2.929547197161279
Validation loss: 2.4588037426275764

Epoch: 5| Step: 9
Training loss: 2.7103644653109953
Validation loss: 2.455837153209262

Epoch: 5| Step: 10
Training loss: 2.60744144275195
Validation loss: 2.462064305829708

Epoch: 235| Step: 0
Training loss: 2.618138109339615
Validation loss: 2.469051677547552

Epoch: 5| Step: 1
Training loss: 2.4666104280229564
Validation loss: 2.477658439061691

Epoch: 5| Step: 2
Training loss: 3.0234884410578533
Validation loss: 2.485049588975159

Epoch: 5| Step: 3
Training loss: 3.0306126819249335
Validation loss: 2.5240059006748456

Epoch: 5| Step: 4
Training loss: 2.878459838873273
Validation loss: 2.5301284614575215

Epoch: 5| Step: 5
Training loss: 2.7076665399815836
Validation loss: 2.517752994015304

Epoch: 5| Step: 6
Training loss: 2.7818570278241106
Validation loss: 2.4976909577316446

Epoch: 5| Step: 7
Training loss: 2.0790382615715886
Validation loss: 2.501049986172159

Epoch: 5| Step: 8
Training loss: 2.4697084135849567
Validation loss: 2.4985736951839925

Epoch: 5| Step: 9
Training loss: 2.4660037253878406
Validation loss: 2.537387230484541

Epoch: 5| Step: 10
Training loss: 3.0557938935545463
Validation loss: 2.5626077876918076

Epoch: 236| Step: 0
Training loss: 2.7166229345940165
Validation loss: 2.6383404136039657

Epoch: 5| Step: 1
Training loss: 3.1390679138653383
Validation loss: 2.7211922517866673

Epoch: 5| Step: 2
Training loss: 2.6964255867962303
Validation loss: 2.7532687407338994

Epoch: 5| Step: 3
Training loss: 2.6815443362003277
Validation loss: 2.802676112129049

Epoch: 5| Step: 4
Training loss: 2.6584264477851725
Validation loss: 2.662605766673275

Epoch: 5| Step: 5
Training loss: 3.3015157570804488
Validation loss: 2.5062325077931193

Epoch: 5| Step: 6
Training loss: 2.1102464924243005
Validation loss: 2.449744888946461

Epoch: 5| Step: 7
Training loss: 2.750608376918872
Validation loss: 2.430445747668647

Epoch: 5| Step: 8
Training loss: 2.5215439438524183
Validation loss: 2.4265989608671372

Epoch: 5| Step: 9
Training loss: 3.000040371941079
Validation loss: 2.4546536046861283

Epoch: 5| Step: 10
Training loss: 2.8899703650621573
Validation loss: 2.5243222246328094

Epoch: 237| Step: 0
Training loss: 2.348307945957133
Validation loss: 2.617606196478923

Epoch: 5| Step: 1
Training loss: 3.050685280280693
Validation loss: 2.727070262888299

Epoch: 5| Step: 2
Training loss: 3.1934250757767293
Validation loss: 2.6369763684865184

Epoch: 5| Step: 3
Training loss: 2.8825840639824007
Validation loss: 2.464887996788879

Epoch: 5| Step: 4
Training loss: 2.595924844450368
Validation loss: 2.411326108131862

Epoch: 5| Step: 5
Training loss: 2.4729946682290596
Validation loss: 2.406912650746543

Epoch: 5| Step: 6
Training loss: 2.7204316298831426
Validation loss: 2.405312353195907

Epoch: 5| Step: 7
Training loss: 2.6626837510293266
Validation loss: 2.394539933808779

Epoch: 5| Step: 8
Training loss: 3.045576709072475
Validation loss: 2.396138951166422

Epoch: 5| Step: 9
Training loss: 2.6386566952283577
Validation loss: 2.398615097370764

Epoch: 5| Step: 10
Training loss: 2.705010346482774
Validation loss: 2.4169873253657514

Epoch: 238| Step: 0
Training loss: 2.604541527788875
Validation loss: 2.4326450577511105

Epoch: 5| Step: 1
Training loss: 2.9724576585479485
Validation loss: 2.465783639929774

Epoch: 5| Step: 2
Training loss: 2.741653259924794
Validation loss: 2.5247470215240533

Epoch: 5| Step: 3
Training loss: 2.912135246259157
Validation loss: 2.5547084601144134

Epoch: 5| Step: 4
Training loss: 2.623927851115363
Validation loss: 2.561376621046755

Epoch: 5| Step: 5
Training loss: 2.9767390321462392
Validation loss: 2.567557495561703

Epoch: 5| Step: 6
Training loss: 2.880653130858894
Validation loss: 2.5400901866531

Epoch: 5| Step: 7
Training loss: 2.93558683387225
Validation loss: 2.5027364357171153

Epoch: 5| Step: 8
Training loss: 2.4154420139346473
Validation loss: 2.4724535345524545

Epoch: 5| Step: 9
Training loss: 2.263063548174773
Validation loss: 2.4771367882921482

Epoch: 5| Step: 10
Training loss: 2.715905115147144
Validation loss: 2.4819880915982595

Epoch: 239| Step: 0
Training loss: 2.740704692521412
Validation loss: 2.487404855174235

Epoch: 5| Step: 1
Training loss: 2.7731935205735767
Validation loss: 2.502115238730103

Epoch: 5| Step: 2
Training loss: 2.966975434626194
Validation loss: 2.55185467162546

Epoch: 5| Step: 3
Training loss: 2.599769317957229
Validation loss: 2.5813328385130254

Epoch: 5| Step: 4
Training loss: 2.766403950623206
Validation loss: 2.5600167524458746

Epoch: 5| Step: 5
Training loss: 2.4186689259743925
Validation loss: 2.539748532337821

Epoch: 5| Step: 6
Training loss: 3.2146697617237323
Validation loss: 2.54245466211337

Epoch: 5| Step: 7
Training loss: 3.2907481461221026
Validation loss: 2.5352636551189267

Epoch: 5| Step: 8
Training loss: 2.469659758388712
Validation loss: 2.5274675224236995

Epoch: 5| Step: 9
Training loss: 3.138498525811506
Validation loss: 2.5355196054606064

Epoch: 5| Step: 10
Training loss: 2.2131669628664894
Validation loss: 2.5259027549235467

Epoch: 240| Step: 0
Training loss: 2.4580598021667073
Validation loss: 2.5269042791560925

Epoch: 5| Step: 1
Training loss: 2.6501345978149193
Validation loss: 2.518802013209792

Epoch: 5| Step: 2
Training loss: 2.1892610273389503
Validation loss: 2.5262907652374738

Epoch: 5| Step: 3
Training loss: 2.8291479126014165
Validation loss: 2.538006015582305

Epoch: 5| Step: 4
Training loss: 3.2269261780987377
Validation loss: 2.5527636694573426

Epoch: 5| Step: 5
Training loss: 2.55283524212541
Validation loss: 2.557765028599836

Epoch: 5| Step: 6
Training loss: 2.4312417312128427
Validation loss: 2.5482482408924145

Epoch: 5| Step: 7
Training loss: 2.7430250839493864
Validation loss: 2.530002279893836

Epoch: 5| Step: 8
Training loss: 2.9444039559929434
Validation loss: 2.528765173939774

Epoch: 5| Step: 9
Training loss: 3.3110449132197526
Validation loss: 2.533809795070597

Epoch: 5| Step: 10
Training loss: 2.318498409636781
Validation loss: 2.529837457913088

Epoch: 241| Step: 0
Training loss: 2.842404225261628
Validation loss: 2.549427667000215

Epoch: 5| Step: 1
Training loss: 2.4107353714116657
Validation loss: 2.5438064146461663

Epoch: 5| Step: 2
Training loss: 2.6001109979851362
Validation loss: 2.5453773381650264

Epoch: 5| Step: 3
Training loss: 2.8241755269859845
Validation loss: 2.538656312621875

Epoch: 5| Step: 4
Training loss: 3.023661602694631
Validation loss: 2.538251363146759

Epoch: 5| Step: 5
Training loss: 2.6575953050033374
Validation loss: 2.52001917773481

Epoch: 5| Step: 6
Training loss: 2.779046889835751
Validation loss: 2.4903167956757546

Epoch: 5| Step: 7
Training loss: 2.5724322729213087
Validation loss: 2.4753594408979915

Epoch: 5| Step: 8
Training loss: 2.4852863295712253
Validation loss: 2.456493299818644

Epoch: 5| Step: 9
Training loss: 2.48953555605279
Validation loss: 2.4499598103236937

Epoch: 5| Step: 10
Training loss: 2.9568612819588056
Validation loss: 2.4495296609012427

Epoch: 242| Step: 0
Training loss: 2.57724594388534
Validation loss: 2.43720058414356

Epoch: 5| Step: 1
Training loss: 3.3073716682109633
Validation loss: 2.4157457449895037

Epoch: 5| Step: 2
Training loss: 2.250009536722953
Validation loss: 2.4068392652810746

Epoch: 5| Step: 3
Training loss: 2.484872636198371
Validation loss: 2.413060320993706

Epoch: 5| Step: 4
Training loss: 2.4579202229440194
Validation loss: 2.40111038664525

Epoch: 5| Step: 5
Training loss: 2.9209767965291706
Validation loss: 2.41902531256284

Epoch: 5| Step: 6
Training loss: 3.012330939269971
Validation loss: 2.4186363898792695

Epoch: 5| Step: 7
Training loss: 2.036303645224105
Validation loss: 2.4304588561933334

Epoch: 5| Step: 8
Training loss: 2.766814240192841
Validation loss: 2.4447171371282685

Epoch: 5| Step: 9
Training loss: 2.770777498605282
Validation loss: 2.4399835477916825

Epoch: 5| Step: 10
Training loss: 2.4412639606973188
Validation loss: 2.4668075242630807

Epoch: 243| Step: 0
Training loss: 2.760064002967336
Validation loss: 2.4735009489622013

Epoch: 5| Step: 1
Training loss: 2.3071179005193847
Validation loss: 2.4497172142853745

Epoch: 5| Step: 2
Training loss: 2.385325922898875
Validation loss: 2.461189346982296

Epoch: 5| Step: 3
Training loss: 3.2187545924478007
Validation loss: 2.4597286497080026

Epoch: 5| Step: 4
Training loss: 2.89069527205546
Validation loss: 2.4619964784836736

Epoch: 5| Step: 5
Training loss: 2.7051707558316513
Validation loss: 2.4710940002748574

Epoch: 5| Step: 6
Training loss: 2.731664916761985
Validation loss: 2.4713308298087155

Epoch: 5| Step: 7
Training loss: 2.776949955188135
Validation loss: 2.486433198583565

Epoch: 5| Step: 8
Training loss: 2.883667527016953
Validation loss: 2.4828213527396703

Epoch: 5| Step: 9
Training loss: 2.421164328379445
Validation loss: 2.4720700329549543

Epoch: 5| Step: 10
Training loss: 2.5717361357085187
Validation loss: 2.4822622757648833

Epoch: 244| Step: 0
Training loss: 2.6386866029092584
Validation loss: 2.484033062781996

Epoch: 5| Step: 1
Training loss: 2.8103731378719563
Validation loss: 2.4932673673533206

Epoch: 5| Step: 2
Training loss: 2.621930734908153
Validation loss: 2.4983225465593786

Epoch: 5| Step: 3
Training loss: 2.145757828158735
Validation loss: 2.5285676796437673

Epoch: 5| Step: 4
Training loss: 2.6965904854889335
Validation loss: 2.5367846346765277

Epoch: 5| Step: 5
Training loss: 3.2624161574307373
Validation loss: 2.5589049727946116

Epoch: 5| Step: 6
Training loss: 2.675803169105022
Validation loss: 2.5615899235457675

Epoch: 5| Step: 7
Training loss: 2.5593780480297976
Validation loss: 2.5272569029188077

Epoch: 5| Step: 8
Training loss: 2.7527891233458264
Validation loss: 2.474379789574283

Epoch: 5| Step: 9
Training loss: 2.858303181866433
Validation loss: 2.4608200990611677

Epoch: 5| Step: 10
Training loss: 2.3537382788221954
Validation loss: 2.4312885423403707

Epoch: 245| Step: 0
Training loss: 2.5838032469409487
Validation loss: 2.4312292189901097

Epoch: 5| Step: 1
Training loss: 2.294329315952765
Validation loss: 2.4111793059143443

Epoch: 5| Step: 2
Training loss: 3.0876873994241225
Validation loss: 2.4204810898240434

Epoch: 5| Step: 3
Training loss: 2.4861254013853715
Validation loss: 2.4186908623648673

Epoch: 5| Step: 4
Training loss: 2.7642519716109333
Validation loss: 2.43349732689073

Epoch: 5| Step: 5
Training loss: 2.9700038470619026
Validation loss: 2.4550577145993517

Epoch: 5| Step: 6
Training loss: 2.5821503627617512
Validation loss: 2.504061347678584

Epoch: 5| Step: 7
Training loss: 2.883461814472746
Validation loss: 2.4670601468036732

Epoch: 5| Step: 8
Training loss: 2.3567371906949317
Validation loss: 2.4334418542183665

Epoch: 5| Step: 9
Training loss: 2.541161711097793
Validation loss: 2.4391710597170233

Epoch: 5| Step: 10
Training loss: 2.811749421737013
Validation loss: 2.452876748646391

Epoch: 246| Step: 0
Training loss: 2.4733124113954537
Validation loss: 2.4689602267153754

Epoch: 5| Step: 1
Training loss: 2.285681405001243
Validation loss: 2.495445345827898

Epoch: 5| Step: 2
Training loss: 2.1372600755390447
Validation loss: 2.5383247811985234

Epoch: 5| Step: 3
Training loss: 2.6217371325795025
Validation loss: 2.5575611933263787

Epoch: 5| Step: 4
Training loss: 2.463346144247575
Validation loss: 2.565917012099633

Epoch: 5| Step: 5
Training loss: 2.5769883858149227
Validation loss: 2.5581636812759827

Epoch: 5| Step: 6
Training loss: 2.7574307012626127
Validation loss: 2.525700889430001

Epoch: 5| Step: 7
Training loss: 3.070970925742836
Validation loss: 2.497894165191693

Epoch: 5| Step: 8
Training loss: 3.0327165339840927
Validation loss: 2.4675384576735837

Epoch: 5| Step: 9
Training loss: 2.572862652869326
Validation loss: 2.455007498193183

Epoch: 5| Step: 10
Training loss: 2.7768849612273505
Validation loss: 2.4527948963541553

Epoch: 247| Step: 0
Training loss: 2.4035537277765084
Validation loss: 2.437074916049588

Epoch: 5| Step: 1
Training loss: 2.6912018763398424
Validation loss: 2.435445924987712

Epoch: 5| Step: 2
Training loss: 2.898603655635903
Validation loss: 2.4294638207468453

Epoch: 5| Step: 3
Training loss: 2.0832135992611236
Validation loss: 2.427577914802375

Epoch: 5| Step: 4
Training loss: 2.4581656210205676
Validation loss: 2.4246246025338043

Epoch: 5| Step: 5
Training loss: 2.7839682507787322
Validation loss: 2.431973758141027

Epoch: 5| Step: 6
Training loss: 2.6925739030958487
Validation loss: 2.4381343372693376

Epoch: 5| Step: 7
Training loss: 2.2081737700582336
Validation loss: 2.4482766107814062

Epoch: 5| Step: 8
Training loss: 2.609016073976467
Validation loss: 2.4525116811569907

Epoch: 5| Step: 9
Training loss: 2.9371883145812254
Validation loss: 2.4685154246939485

Epoch: 5| Step: 10
Training loss: 2.8999779404426014
Validation loss: 2.4606243881680787

Epoch: 248| Step: 0
Training loss: 2.664891625754068
Validation loss: 2.4690158815565697

Epoch: 5| Step: 1
Training loss: 2.7199463240151784
Validation loss: 2.4596489843980596

Epoch: 5| Step: 2
Training loss: 2.40652285923772
Validation loss: 2.466080424339726

Epoch: 5| Step: 3
Training loss: 2.2684488522247777
Validation loss: 2.4565403310574103

Epoch: 5| Step: 4
Training loss: 2.674748175345423
Validation loss: 2.4521526214559604

Epoch: 5| Step: 5
Training loss: 2.073055422434447
Validation loss: 2.4486762263676884

Epoch: 5| Step: 6
Training loss: 2.808055587375936
Validation loss: 2.450247273848722

Epoch: 5| Step: 7
Training loss: 2.9026591770050376
Validation loss: 2.4437840739061096

Epoch: 5| Step: 8
Training loss: 2.8274290798747175
Validation loss: 2.4471547054714593

Epoch: 5| Step: 9
Training loss: 2.362667186815938
Validation loss: 2.4585559578008667

Epoch: 5| Step: 10
Training loss: 2.689325821356179
Validation loss: 2.4876892660116203

Epoch: 249| Step: 0
Training loss: 2.6516422473287387
Validation loss: 2.542376088576104

Epoch: 5| Step: 1
Training loss: 2.913520496679286
Validation loss: 2.5337615866582595

Epoch: 5| Step: 2
Training loss: 1.9877641226451872
Validation loss: 2.541474586409029

Epoch: 5| Step: 3
Training loss: 2.732810482942634
Validation loss: 2.5392257872675215

Epoch: 5| Step: 4
Training loss: 2.907278063660392
Validation loss: 2.514700274603711

Epoch: 5| Step: 5
Training loss: 2.732004849592962
Validation loss: 2.492958153627894

Epoch: 5| Step: 6
Training loss: 3.139948681940475
Validation loss: 2.509243601506669

Epoch: 5| Step: 7
Training loss: 2.2906532358716536
Validation loss: 2.507796826634846

Epoch: 5| Step: 8
Training loss: 2.152474124234544
Validation loss: 2.4740664236465433

Epoch: 5| Step: 9
Training loss: 2.2416831057299094
Validation loss: 2.4821107751624742

Epoch: 5| Step: 10
Training loss: 2.7984983538768806
Validation loss: 2.4654875601396395

Epoch: 250| Step: 0
Training loss: 2.683910456685926
Validation loss: 2.442064354975073

Epoch: 5| Step: 1
Training loss: 2.4135038352858387
Validation loss: 2.4287776751727956

Epoch: 5| Step: 2
Training loss: 2.700312126626712
Validation loss: 2.4298801140680255

Epoch: 5| Step: 3
Training loss: 2.6640097872981
Validation loss: 2.415759151359918

Epoch: 5| Step: 4
Training loss: 2.76005977026863
Validation loss: 2.4199903720585203

Epoch: 5| Step: 5
Training loss: 2.9128009427826322
Validation loss: 2.424211232811709

Epoch: 5| Step: 6
Training loss: 2.6911165610266194
Validation loss: 2.420728188468026

Epoch: 5| Step: 7
Training loss: 2.5223140518717195
Validation loss: 2.4199408199942587

Epoch: 5| Step: 8
Training loss: 2.46035013606869
Validation loss: 2.4276754912183067

Epoch: 5| Step: 9
Training loss: 2.6038369440514657
Validation loss: 2.43709789963526

Epoch: 5| Step: 10
Training loss: 2.132748781027919
Validation loss: 2.4577050036113213

Epoch: 251| Step: 0
Training loss: 2.9813156024744543
Validation loss: 2.4652818187461163

Epoch: 5| Step: 1
Training loss: 2.486309713698525
Validation loss: 2.502649585963534

Epoch: 5| Step: 2
Training loss: 2.666479630666257
Validation loss: 2.489739635591491

Epoch: 5| Step: 3
Training loss: 2.777926913602461
Validation loss: 2.48752181971707

Epoch: 5| Step: 4
Training loss: 2.372584469801911
Validation loss: 2.4681953294094825

Epoch: 5| Step: 5
Training loss: 2.487292226423929
Validation loss: 2.4470553951138374

Epoch: 5| Step: 6
Training loss: 2.8307171318034667
Validation loss: 2.4395064895210274

Epoch: 5| Step: 7
Training loss: 2.601505863157429
Validation loss: 2.437266738033284

Epoch: 5| Step: 8
Training loss: 2.4445828942865844
Validation loss: 2.4325088070635594

Epoch: 5| Step: 9
Training loss: 2.526087169958367
Validation loss: 2.4243968175401824

Epoch: 5| Step: 10
Training loss: 2.8330961763946787
Validation loss: 2.4241610193469323

Epoch: 252| Step: 0
Training loss: 2.6476247434973015
Validation loss: 2.4251763058454854

Epoch: 5| Step: 1
Training loss: 2.4505090067973674
Validation loss: 2.4117752078207073

Epoch: 5| Step: 2
Training loss: 3.01140698750145
Validation loss: 2.4048681596983688

Epoch: 5| Step: 3
Training loss: 2.445203979814193
Validation loss: 2.4139212252957494

Epoch: 5| Step: 4
Training loss: 2.5983615921503325
Validation loss: 2.3955729314063046

Epoch: 5| Step: 5
Training loss: 2.999794953014595
Validation loss: 2.392137829882394

Epoch: 5| Step: 6
Training loss: 2.5402330722655915
Validation loss: 2.4018042003099738

Epoch: 5| Step: 7
Training loss: 2.5549131521256814
Validation loss: 2.403446768455057

Epoch: 5| Step: 8
Training loss: 2.5142342650425715
Validation loss: 2.398956032206614

Epoch: 5| Step: 9
Training loss: 2.247320911371254
Validation loss: 2.3930405856201973

Epoch: 5| Step: 10
Training loss: 2.692041419035104
Validation loss: 2.4029997774181338

Epoch: 253| Step: 0
Training loss: 2.972817134639031
Validation loss: 2.4046844239117866

Epoch: 5| Step: 1
Training loss: 3.108114015616194
Validation loss: 2.3934298682707014

Epoch: 5| Step: 2
Training loss: 2.948157598312428
Validation loss: 2.406320764496974

Epoch: 5| Step: 3
Training loss: 2.816730369509624
Validation loss: 2.419091006526719

Epoch: 5| Step: 4
Training loss: 2.1672352142692093
Validation loss: 2.424313748298978

Epoch: 5| Step: 5
Training loss: 2.167101327383418
Validation loss: 2.444232216515966

Epoch: 5| Step: 6
Training loss: 2.5135788266759844
Validation loss: 2.445331492555509

Epoch: 5| Step: 7
Training loss: 2.18431229617341
Validation loss: 2.446402780458331

Epoch: 5| Step: 8
Training loss: 1.9380072883256325
Validation loss: 2.4354704018342423

Epoch: 5| Step: 9
Training loss: 2.8206704036778354
Validation loss: 2.447418734758385

Epoch: 5| Step: 10
Training loss: 2.5981727488160655
Validation loss: 2.4500873727142416

Epoch: 254| Step: 0
Training loss: 2.084540424331024
Validation loss: 2.468523500331951

Epoch: 5| Step: 1
Training loss: 2.0997035089726457
Validation loss: 2.458696385128369

Epoch: 5| Step: 2
Training loss: 2.714936047638569
Validation loss: 2.456782597697583

Epoch: 5| Step: 3
Training loss: 2.4997279972878657
Validation loss: 2.4978594404137677

Epoch: 5| Step: 4
Training loss: 3.1639768989192274
Validation loss: 2.5030934524755226

Epoch: 5| Step: 5
Training loss: 2.7640925757808064
Validation loss: 2.509022926581462

Epoch: 5| Step: 6
Training loss: 2.9482960451254123
Validation loss: 2.5117631325028142

Epoch: 5| Step: 7
Training loss: 2.2179495213700657
Validation loss: 2.4832153379271507

Epoch: 5| Step: 8
Training loss: 1.9296072506917041
Validation loss: 2.486932101150904

Epoch: 5| Step: 9
Training loss: 2.7868156037692233
Validation loss: 2.4993513250179347

Epoch: 5| Step: 10
Training loss: 2.6494883925138133
Validation loss: 2.4823219761559154

Epoch: 255| Step: 0
Training loss: 2.600159137697406
Validation loss: 2.4897249126367353

Epoch: 5| Step: 1
Training loss: 2.3733935695497754
Validation loss: 2.4866539008241126

Epoch: 5| Step: 2
Training loss: 2.6784485380047434
Validation loss: 2.4873385031858235

Epoch: 5| Step: 3
Training loss: 2.2609622724608776
Validation loss: 2.473318343917165

Epoch: 5| Step: 4
Training loss: 2.4172675821641545
Validation loss: 2.4626825513480606

Epoch: 5| Step: 5
Training loss: 2.503510775704999
Validation loss: 2.4679645842977807

Epoch: 5| Step: 6
Training loss: 2.345409263734242
Validation loss: 2.452561275497799

Epoch: 5| Step: 7
Training loss: 2.588134846229865
Validation loss: 2.4396454125547087

Epoch: 5| Step: 8
Training loss: 2.342532846389475
Validation loss: 2.425276245732605

Epoch: 5| Step: 9
Training loss: 2.833189081746011
Validation loss: 2.4125954284955875

Epoch: 5| Step: 10
Training loss: 3.06511529851862
Validation loss: 2.42901565320727

Epoch: 256| Step: 0
Training loss: 2.0730397812466954
Validation loss: 2.4248213614357033

Epoch: 5| Step: 1
Training loss: 2.6067310575384353
Validation loss: 2.4291206117690125

Epoch: 5| Step: 2
Training loss: 2.024892512164913
Validation loss: 2.4407726769468323

Epoch: 5| Step: 3
Training loss: 2.2681134468513884
Validation loss: 2.432118019235953

Epoch: 5| Step: 4
Training loss: 2.265126982575675
Validation loss: 2.4651785578719836

Epoch: 5| Step: 5
Training loss: 3.0266343990011886
Validation loss: 2.486378659486199

Epoch: 5| Step: 6
Training loss: 2.8161078306869567
Validation loss: 2.5230482674888743

Epoch: 5| Step: 7
Training loss: 2.4331591173627083
Validation loss: 2.5426223110858714

Epoch: 5| Step: 8
Training loss: 3.0218751009888813
Validation loss: 2.559211340423313

Epoch: 5| Step: 9
Training loss: 2.459075610927816
Validation loss: 2.5871272542230646

Epoch: 5| Step: 10
Training loss: 2.6916342584727735
Validation loss: 2.591143669877386

Epoch: 257| Step: 0
Training loss: 2.480517962110245
Validation loss: 2.573183608226512

Epoch: 5| Step: 1
Training loss: 2.3722839887421125
Validation loss: 2.500770374268591

Epoch: 5| Step: 2
Training loss: 2.1954030734346235
Validation loss: 2.453259854894425

Epoch: 5| Step: 3
Training loss: 2.8047054364579234
Validation loss: 2.434555924051666

Epoch: 5| Step: 4
Training loss: 2.592383794727598
Validation loss: 2.4166585443322726

Epoch: 5| Step: 5
Training loss: 2.600476929130818
Validation loss: 2.407690092723169

Epoch: 5| Step: 6
Training loss: 2.6518631557296293
Validation loss: 2.401791082159273

Epoch: 5| Step: 7
Training loss: 2.7997163799238516
Validation loss: 2.408858872098354

Epoch: 5| Step: 8
Training loss: 2.324261217771156
Validation loss: 2.4019006437362136

Epoch: 5| Step: 9
Training loss: 2.7871198112650615
Validation loss: 2.3959055646696767

Epoch: 5| Step: 10
Training loss: 2.9495020041956077
Validation loss: 2.3891993596176526

Epoch: 258| Step: 0
Training loss: 2.69827355536757
Validation loss: 2.3932582500807618

Epoch: 5| Step: 1
Training loss: 2.32287394622613
Validation loss: 2.382325111920338

Epoch: 5| Step: 2
Training loss: 2.6165127467991813
Validation loss: 2.3986195852592

Epoch: 5| Step: 3
Training loss: 2.731262440947736
Validation loss: 2.4065875394779686

Epoch: 5| Step: 4
Training loss: 2.4081980758576935
Validation loss: 2.4134089661220326

Epoch: 5| Step: 5
Training loss: 2.9349748837177807
Validation loss: 2.43820684600143

Epoch: 5| Step: 6
Training loss: 2.7295886191597063
Validation loss: 2.464675277933682

Epoch: 5| Step: 7
Training loss: 2.3437373860337645
Validation loss: 2.4799900436945794

Epoch: 5| Step: 8
Training loss: 2.5945405789339397
Validation loss: 2.4484836994218493

Epoch: 5| Step: 9
Training loss: 2.6539881332293143
Validation loss: 2.467161001330331

Epoch: 5| Step: 10
Training loss: 2.060099389539615
Validation loss: 2.485625248788619

Epoch: 259| Step: 0
Training loss: 3.0207624405182707
Validation loss: 2.5178705281114007

Epoch: 5| Step: 1
Training loss: 2.499223493146435
Validation loss: 2.5239527544659417

Epoch: 5| Step: 2
Training loss: 2.6071565071539933
Validation loss: 2.522932490678915

Epoch: 5| Step: 3
Training loss: 2.5188503084489344
Validation loss: 2.5021659891998764

Epoch: 5| Step: 4
Training loss: 2.167831059112885
Validation loss: 2.4539401965891785

Epoch: 5| Step: 5
Training loss: 2.6374904831267134
Validation loss: 2.409194410529433

Epoch: 5| Step: 6
Training loss: 2.2326413344598417
Validation loss: 2.432029286435939

Epoch: 5| Step: 7
Training loss: 2.2838134993988937
Validation loss: 2.4257262149054197

Epoch: 5| Step: 8
Training loss: 2.5451699382651127
Validation loss: 2.4431234762133993

Epoch: 5| Step: 9
Training loss: 2.648709263544579
Validation loss: 2.449676526890349

Epoch: 5| Step: 10
Training loss: 3.0383018973588896
Validation loss: 2.4548297615190564

Epoch: 260| Step: 0
Training loss: 2.548055270010268
Validation loss: 2.436017466163048

Epoch: 5| Step: 1
Training loss: 2.6802864851061035
Validation loss: 2.4028215001475277

Epoch: 5| Step: 2
Training loss: 2.510900859648513
Validation loss: 2.414684002860554

Epoch: 5| Step: 3
Training loss: 1.939865145371338
Validation loss: 2.4029204099253905

Epoch: 5| Step: 4
Training loss: 2.2776475445286017
Validation loss: 2.3970522040983826

Epoch: 5| Step: 5
Training loss: 3.009945279254499
Validation loss: 2.4024010142629453

Epoch: 5| Step: 6
Training loss: 2.7744750755016847
Validation loss: 2.429796262665705

Epoch: 5| Step: 7
Training loss: 2.2261814795288735
Validation loss: 2.4270154392577075

Epoch: 5| Step: 8
Training loss: 1.6573522246985573
Validation loss: 2.432760406169704

Epoch: 5| Step: 9
Training loss: 2.462540361877245
Validation loss: 2.421557256554068

Epoch: 5| Step: 10
Training loss: 3.0807273436944276
Validation loss: 2.432749860779629

Epoch: 261| Step: 0
Training loss: 2.6389085055062727
Validation loss: 2.435762411334861

Epoch: 5| Step: 1
Training loss: 2.2177072143074055
Validation loss: 2.439495728435488

Epoch: 5| Step: 2
Training loss: 2.0929802006105325
Validation loss: 2.4380971415348633

Epoch: 5| Step: 3
Training loss: 2.5190646900261653
Validation loss: 2.4265999381061243

Epoch: 5| Step: 4
Training loss: 2.773929863866143
Validation loss: 2.420800739885256

Epoch: 5| Step: 5
Training loss: 2.4270840646199665
Validation loss: 2.442422334551727

Epoch: 5| Step: 6
Training loss: 2.7708000429682387
Validation loss: 2.4224126318950816

Epoch: 5| Step: 7
Training loss: 2.5839009635535812
Validation loss: 2.399238487147483

Epoch: 5| Step: 8
Training loss: 2.0537109375
Validation loss: 2.389558828225568

Epoch: 5| Step: 9
Training loss: 2.3202526971065405
Validation loss: 2.38913167947238

Epoch: 5| Step: 10
Training loss: 2.6347544042802213
Validation loss: 2.408074629923889

Epoch: 262| Step: 0
Training loss: 2.68439703722469
Validation loss: 2.384796468912152

Epoch: 5| Step: 1
Training loss: 3.217437772941989
Validation loss: 2.376262616301636

Epoch: 5| Step: 2
Training loss: 2.498645510909996
Validation loss: 2.3777167493487736

Epoch: 5| Step: 3
Training loss: 2.4766222829251725
Validation loss: 2.3859335162139614

Epoch: 5| Step: 4
Training loss: 2.622635821233644
Validation loss: 2.392706111911017

Epoch: 5| Step: 5
Training loss: 2.110542708835306
Validation loss: 2.3867257307454794

Epoch: 5| Step: 6
Training loss: 2.1305044352358364
Validation loss: 2.4188792075982226

Epoch: 5| Step: 7
Training loss: 2.2179673654754177
Validation loss: 2.4005014209803726

Epoch: 5| Step: 8
Training loss: 2.425321919418385
Validation loss: 2.3941303365808166

Epoch: 5| Step: 9
Training loss: 2.465964955534906
Validation loss: 2.3937978818059618

Epoch: 5| Step: 10
Training loss: 2.4673445358695454
Validation loss: 2.393134645183094

Epoch: 263| Step: 0
Training loss: 3.0597334841682904
Validation loss: 2.4032038849186423

Epoch: 5| Step: 1
Training loss: 2.139556618151955
Validation loss: 2.3981737394844083

Epoch: 5| Step: 2
Training loss: 2.391983344437908
Validation loss: 2.4009756564506275

Epoch: 5| Step: 3
Training loss: 2.6925900185500957
Validation loss: 2.3916523041332676

Epoch: 5| Step: 4
Training loss: 2.1921805307572533
Validation loss: 2.439581566738659

Epoch: 5| Step: 5
Training loss: 2.918731140467877
Validation loss: 2.4279033154734946

Epoch: 5| Step: 6
Training loss: 1.8685177330173948
Validation loss: 2.468672811792427

Epoch: 5| Step: 7
Training loss: 2.2672990599302607
Validation loss: 2.480855729523104

Epoch: 5| Step: 8
Training loss: 2.578154592633193
Validation loss: 2.499328077424518

Epoch: 5| Step: 9
Training loss: 2.385102119418821
Validation loss: 2.5059702598071256

Epoch: 5| Step: 10
Training loss: 2.494856215712412
Validation loss: 2.477747274999809

Epoch: 264| Step: 0
Training loss: 2.46082278998528
Validation loss: 2.4787157461594056

Epoch: 5| Step: 1
Training loss: 1.8725179774767213
Validation loss: 2.4409094031987792

Epoch: 5| Step: 2
Training loss: 2.3734453031651475
Validation loss: 2.4283869087188044

Epoch: 5| Step: 3
Training loss: 2.2472765652572435
Validation loss: 2.4152526247526063

Epoch: 5| Step: 4
Training loss: 2.7137969928680654
Validation loss: 2.4080191188159286

Epoch: 5| Step: 5
Training loss: 2.5054777215999824
Validation loss: 2.383591673096262

Epoch: 5| Step: 6
Training loss: 2.2231973482188208
Validation loss: 2.3840645042507584

Epoch: 5| Step: 7
Training loss: 2.4132482643133053
Validation loss: 2.393536380872816

Epoch: 5| Step: 8
Training loss: 2.5684697464699666
Validation loss: 2.4048199430724813

Epoch: 5| Step: 9
Training loss: 2.607800951201304
Validation loss: 2.4148967498916654

Epoch: 5| Step: 10
Training loss: 2.7820474574348872
Validation loss: 2.403147781246807

Epoch: 265| Step: 0
Training loss: 2.2439017836892394
Validation loss: 2.422923730796135

Epoch: 5| Step: 1
Training loss: 2.75467994589373
Validation loss: 2.443864497654439

Epoch: 5| Step: 2
Training loss: 2.764901190401184
Validation loss: 2.4490019944794277

Epoch: 5| Step: 3
Training loss: 2.173580679986853
Validation loss: 2.4324443323296725

Epoch: 5| Step: 4
Training loss: 1.9938853489964328
Validation loss: 2.414247167984106

Epoch: 5| Step: 5
Training loss: 2.7712114023592935
Validation loss: 2.3948662186719765

Epoch: 5| Step: 6
Training loss: 2.645732567337654
Validation loss: 2.393038611231769

Epoch: 5| Step: 7
Training loss: 2.5852623372172285
Validation loss: 2.3971809916312394

Epoch: 5| Step: 8
Training loss: 2.6991496760450038
Validation loss: 2.390859830548914

Epoch: 5| Step: 9
Training loss: 2.5362403561863265
Validation loss: 2.3766492353663407

Epoch: 5| Step: 10
Training loss: 2.039259627010494
Validation loss: 2.3608571556786715

Epoch: 266| Step: 0
Training loss: 2.220150250513955
Validation loss: 2.3731584744257948

Epoch: 5| Step: 1
Training loss: 2.4257447858886287
Validation loss: 2.370389441915105

Epoch: 5| Step: 2
Training loss: 2.3371044293414576
Validation loss: 2.37925788013916

Epoch: 5| Step: 3
Training loss: 2.3387474077170607
Validation loss: 2.3932949263647108

Epoch: 5| Step: 4
Training loss: 2.576129487840733
Validation loss: 2.421072906931849

Epoch: 5| Step: 5
Training loss: 2.574965234169937
Validation loss: 2.4129234212726423

Epoch: 5| Step: 6
Training loss: 1.7434906469279647
Validation loss: 2.42575504150838

Epoch: 5| Step: 7
Training loss: 2.8966689150691405
Validation loss: 2.4446478689438207

Epoch: 5| Step: 8
Training loss: 2.1486525549327067
Validation loss: 2.4526047749039153

Epoch: 5| Step: 9
Training loss: 2.1006458651667788
Validation loss: 2.459350581605002

Epoch: 5| Step: 10
Training loss: 3.1270970746847553
Validation loss: 2.465318658922969

Epoch: 267| Step: 0
Training loss: 2.8122624614858966
Validation loss: 2.4223762509528206

Epoch: 5| Step: 1
Training loss: 2.700154695671009
Validation loss: 2.4171954252962635

Epoch: 5| Step: 2
Training loss: 2.498967338907272
Validation loss: 2.4054733928084926

Epoch: 5| Step: 3
Training loss: 2.2920323398032805
Validation loss: 2.4049305946882917

Epoch: 5| Step: 4
Training loss: 2.8843758331991958
Validation loss: 2.3764072646550956

Epoch: 5| Step: 5
Training loss: 2.552569429983297
Validation loss: 2.3841788288309806

Epoch: 5| Step: 6
Training loss: 2.859865073642622
Validation loss: 2.363740745871601

Epoch: 5| Step: 7
Training loss: 1.8341077411666076
Validation loss: 2.3646178646655263

Epoch: 5| Step: 8
Training loss: 1.6292948087881738
Validation loss: 2.3542576931158115

Epoch: 5| Step: 9
Training loss: 2.063523818710247
Validation loss: 2.3502069993445565

Epoch: 5| Step: 10
Training loss: 2.0818739038955245
Validation loss: 2.353683978301332

Epoch: 268| Step: 0
Training loss: 2.0375209549838478
Validation loss: 2.3595417286779217

Epoch: 5| Step: 1
Training loss: 2.3364608331520382
Validation loss: 2.3625335066377353

Epoch: 5| Step: 2
Training loss: 2.7233398980287626
Validation loss: 2.3831910923113186

Epoch: 5| Step: 3
Training loss: 2.6042520636225994
Validation loss: 2.410111002655968

Epoch: 5| Step: 4
Training loss: 2.233078053341547
Validation loss: 2.4202088646981714

Epoch: 5| Step: 5
Training loss: 2.59708888232367
Validation loss: 2.427645254929364

Epoch: 5| Step: 6
Training loss: 2.156004629133701
Validation loss: 2.4187124562023987

Epoch: 5| Step: 7
Training loss: 1.9971092313597727
Validation loss: 2.443274863483521

Epoch: 5| Step: 8
Training loss: 2.5322742979917825
Validation loss: 2.4331738723018117

Epoch: 5| Step: 9
Training loss: 2.5149267898127126
Validation loss: 2.434372890386776

Epoch: 5| Step: 10
Training loss: 2.4869345669300693
Validation loss: 2.410361652666626

Epoch: 269| Step: 0
Training loss: 2.2171840245634318
Validation loss: 2.419169616718897

Epoch: 5| Step: 1
Training loss: 2.280811110827178
Validation loss: 2.4118800296319707

Epoch: 5| Step: 2
Training loss: 2.60249124164555
Validation loss: 2.423181417113671

Epoch: 5| Step: 3
Training loss: 2.548888177273884
Validation loss: 2.4027986464134674

Epoch: 5| Step: 4
Training loss: 2.633224228719347
Validation loss: 2.408112722140355

Epoch: 5| Step: 5
Training loss: 1.9563492064259695
Validation loss: 2.4099462135793113

Epoch: 5| Step: 6
Training loss: 1.881780317718849
Validation loss: 2.440480320467389

Epoch: 5| Step: 7
Training loss: 2.319863324085655
Validation loss: 2.454838927544417

Epoch: 5| Step: 8
Training loss: 2.5865115539835464
Validation loss: 2.4776269921683585

Epoch: 5| Step: 9
Training loss: 2.4879636936175893
Validation loss: 2.537267748120412

Epoch: 5| Step: 10
Training loss: 2.3060860221480532
Validation loss: 2.5220771845636882

Epoch: 270| Step: 0
Training loss: 2.3242454206715553
Validation loss: 2.491276568922955

Epoch: 5| Step: 1
Training loss: 2.973779213093591
Validation loss: 2.460300390301571

Epoch: 5| Step: 2
Training loss: 2.1268266792648647
Validation loss: 2.389728819715171

Epoch: 5| Step: 3
Training loss: 2.708424571530093
Validation loss: 2.380497727947914

Epoch: 5| Step: 4
Training loss: 2.4698108373632945
Validation loss: 2.3842098706550305

Epoch: 5| Step: 5
Training loss: 2.5260799968734657
Validation loss: 2.3942293334331866

Epoch: 5| Step: 6
Training loss: 2.102263039606441
Validation loss: 2.403443725295766

Epoch: 5| Step: 7
Training loss: 2.606574194341901
Validation loss: 2.408995920858828

Epoch: 5| Step: 8
Training loss: 2.64208799385735
Validation loss: 2.392815853762065

Epoch: 5| Step: 9
Training loss: 2.3725352296936912
Validation loss: 2.4016668254889844

Epoch: 5| Step: 10
Training loss: 2.2949263422496413
Validation loss: 2.3752003225267306

Epoch: 271| Step: 0
Training loss: 2.3879576119665678
Validation loss: 2.3674277513285986

Epoch: 5| Step: 1
Training loss: 2.5029214954874717
Validation loss: 2.36028911591076

Epoch: 5| Step: 2
Training loss: 2.307271252635837
Validation loss: 2.3478113176153648

Epoch: 5| Step: 3
Training loss: 2.515198570739544
Validation loss: 2.346009723930655

Epoch: 5| Step: 4
Training loss: 2.516749539389757
Validation loss: 2.3501585088529255

Epoch: 5| Step: 5
Training loss: 2.1899699843975617
Validation loss: 2.3547157353678805

Epoch: 5| Step: 6
Training loss: 2.231716254749117
Validation loss: 2.3459218469271605

Epoch: 5| Step: 7
Training loss: 2.6628295193063263
Validation loss: 2.392985591383427

Epoch: 5| Step: 8
Training loss: 2.3186982059092274
Validation loss: 2.4068961616327353

Epoch: 5| Step: 9
Training loss: 2.8763152721281675
Validation loss: 2.470500446453121

Epoch: 5| Step: 10
Training loss: 1.8894558909492365
Validation loss: 2.4667797957599213

Epoch: 272| Step: 0
Training loss: 2.385467950749952
Validation loss: 2.4826687472800324

Epoch: 5| Step: 1
Training loss: 2.388861011618468
Validation loss: 2.4852255584618663

Epoch: 5| Step: 2
Training loss: 2.211322009616058
Validation loss: 2.461948627837259

Epoch: 5| Step: 3
Training loss: 2.0422428511785022
Validation loss: 2.4368534245514932

Epoch: 5| Step: 4
Training loss: 2.379070808719831
Validation loss: 2.4099331110264957

Epoch: 5| Step: 5
Training loss: 2.4342189126663842
Validation loss: 2.419562560499228

Epoch: 5| Step: 6
Training loss: 2.068833539030929
Validation loss: 2.392011502716739

Epoch: 5| Step: 7
Training loss: 2.38009448513041
Validation loss: 2.383555989743708

Epoch: 5| Step: 8
Training loss: 2.9827771128278378
Validation loss: 2.376159274936946

Epoch: 5| Step: 9
Training loss: 2.492379782024449
Validation loss: 2.379630666674688

Epoch: 5| Step: 10
Training loss: 2.72253838041801
Validation loss: 2.390466558138996

Epoch: 273| Step: 0
Training loss: 2.2128021680453056
Validation loss: 2.4050429872297814

Epoch: 5| Step: 1
Training loss: 2.30005824803111
Validation loss: 2.4383252715925576

Epoch: 5| Step: 2
Training loss: 2.018340890724824
Validation loss: 2.4841430900478034

Epoch: 5| Step: 3
Training loss: 2.6788109772150683
Validation loss: 2.4974780796014575

Epoch: 5| Step: 4
Training loss: 2.554284860221303
Validation loss: 2.517054036814743

Epoch: 5| Step: 5
Training loss: 2.734081317934083
Validation loss: 2.5114741315264952

Epoch: 5| Step: 6
Training loss: 1.9723459736260662
Validation loss: 2.484952410011999

Epoch: 5| Step: 7
Training loss: 2.443020364858384
Validation loss: 2.465174995031014

Epoch: 5| Step: 8
Training loss: 2.1387220402935037
Validation loss: 2.449047748038818

Epoch: 5| Step: 9
Training loss: 2.4374315301130527
Validation loss: 2.412843030833806

Epoch: 5| Step: 10
Training loss: 2.7749471504746257
Validation loss: 2.3982919473331137

Epoch: 274| Step: 0
Training loss: 2.1588590013720617
Validation loss: 2.3948249317619257

Epoch: 5| Step: 1
Training loss: 2.9130198068046886
Validation loss: 2.396183496774878

Epoch: 5| Step: 2
Training loss: 2.4675127623130413
Validation loss: 2.4029348421739196

Epoch: 5| Step: 3
Training loss: 2.118634057037496
Validation loss: 2.390459722373518

Epoch: 5| Step: 4
Training loss: 2.4686902195899494
Validation loss: 2.392822176030192

Epoch: 5| Step: 5
Training loss: 2.136771639042074
Validation loss: 2.397791493404568

Epoch: 5| Step: 6
Training loss: 2.4917334259513835
Validation loss: 2.436311075827317

Epoch: 5| Step: 7
Training loss: 2.75063056652266
Validation loss: 2.4450639497964994

Epoch: 5| Step: 8
Training loss: 2.1770551640149836
Validation loss: 2.4250641878067376

Epoch: 5| Step: 9
Training loss: 2.1315572209580163
Validation loss: 2.436330431080841

Epoch: 5| Step: 10
Training loss: 2.301679400280592
Validation loss: 2.4339114925713243

Epoch: 275| Step: 0
Training loss: 2.5426062634672615
Validation loss: 2.4438742513388534

Epoch: 5| Step: 1
Training loss: 1.9635888523196448
Validation loss: 2.4205124286649133

Epoch: 5| Step: 2
Training loss: 2.3109805295908905
Validation loss: 2.415778979025701

Epoch: 5| Step: 3
Training loss: 2.272779336679768
Validation loss: 2.3831125356621157

Epoch: 5| Step: 4
Training loss: 2.1838083997668134
Validation loss: 2.38115036645924

Epoch: 5| Step: 5
Training loss: 2.0881986899276903
Validation loss: 2.382464788341299

Epoch: 5| Step: 6
Training loss: 2.4604736859860807
Validation loss: 2.367761499635852

Epoch: 5| Step: 7
Training loss: 2.522298738977979
Validation loss: 2.36304041002174

Epoch: 5| Step: 8
Training loss: 2.1388585954092445
Validation loss: 2.3631274904263573

Epoch: 5| Step: 9
Training loss: 2.3441314386875285
Validation loss: 2.3680700687944496

Epoch: 5| Step: 10
Training loss: 2.952943342162027
Validation loss: 2.3877499400645497

Epoch: 276| Step: 0
Training loss: 2.516808841386169
Validation loss: 2.4512182574101438

Epoch: 5| Step: 1
Training loss: 2.7770532383662907
Validation loss: 2.471298304451744

Epoch: 5| Step: 2
Training loss: 2.7875823894008502
Validation loss: 2.538177415734646

Epoch: 5| Step: 3
Training loss: 2.6507658049844305
Validation loss: 2.5014951244672226

Epoch: 5| Step: 4
Training loss: 1.7919291222724316
Validation loss: 2.4443111131223865

Epoch: 5| Step: 5
Training loss: 2.4289077537927057
Validation loss: 2.4082713943687817

Epoch: 5| Step: 6
Training loss: 2.527055349506899
Validation loss: 2.417330556456847

Epoch: 5| Step: 7
Training loss: 2.0814011069306484
Validation loss: 2.420755107978979

Epoch: 5| Step: 8
Training loss: 2.3704585775325944
Validation loss: 2.4293091741279365

Epoch: 5| Step: 9
Training loss: 2.26992116917258
Validation loss: 2.4197622821933504

Epoch: 5| Step: 10
Training loss: 2.106918939603587
Validation loss: 2.4199651008973695

Epoch: 277| Step: 0
Training loss: 2.2524113978700977
Validation loss: 2.419398703399667

Epoch: 5| Step: 1
Training loss: 2.5865781053968973
Validation loss: 2.4255454923265654

Epoch: 5| Step: 2
Training loss: 2.807139820151314
Validation loss: 2.403403110003529

Epoch: 5| Step: 3
Training loss: 2.064157917782915
Validation loss: 2.426485984105154

Epoch: 5| Step: 4
Training loss: 2.051381166903179
Validation loss: 2.4003487575839446

Epoch: 5| Step: 5
Training loss: 2.640215147817298
Validation loss: 2.4034611202111336

Epoch: 5| Step: 6
Training loss: 2.034581899596217
Validation loss: 2.3903054877657817

Epoch: 5| Step: 7
Training loss: 2.3795966789162155
Validation loss: 2.3990250081975844

Epoch: 5| Step: 8
Training loss: 2.2280593926613723
Validation loss: 2.440307824767619

Epoch: 5| Step: 9
Training loss: 2.093432729795072
Validation loss: 2.42697918805031

Epoch: 5| Step: 10
Training loss: 2.3004035056724095
Validation loss: 2.4429757115125295

Epoch: 278| Step: 0
Training loss: 2.411533944995382
Validation loss: 2.41033371248266

Epoch: 5| Step: 1
Training loss: 2.2783289981550574
Validation loss: 2.414808486797414

Epoch: 5| Step: 2
Training loss: 2.976964087441681
Validation loss: 2.3975139481987147

Epoch: 5| Step: 3
Training loss: 2.3558078097982746
Validation loss: 2.3593102076603008

Epoch: 5| Step: 4
Training loss: 2.689224931597774
Validation loss: 2.3549055493019795

Epoch: 5| Step: 5
Training loss: 2.052791170011456
Validation loss: 2.343531186954275

Epoch: 5| Step: 6
Training loss: 1.9671509924933206
Validation loss: 2.3527933184582754

Epoch: 5| Step: 7
Training loss: 1.9711438112558148
Validation loss: 2.3427688809305014

Epoch: 5| Step: 8
Training loss: 2.260961217960156
Validation loss: 2.3469148811541385

Epoch: 5| Step: 9
Training loss: 2.0924056562624003
Validation loss: 2.3669350112176937

Epoch: 5| Step: 10
Training loss: 2.6352196621043764
Validation loss: 2.371865041201909

Epoch: 279| Step: 0
Training loss: 2.395867477394833
Validation loss: 2.413300655216607

Epoch: 5| Step: 1
Training loss: 2.046615118170744
Validation loss: 2.447699998331388

Epoch: 5| Step: 2
Training loss: 2.4377782613919354
Validation loss: 2.478331491275581

Epoch: 5| Step: 3
Training loss: 2.3370910654015464
Validation loss: 2.504921125331552

Epoch: 5| Step: 4
Training loss: 2.4999734877134236
Validation loss: 2.528307662180171

Epoch: 5| Step: 5
Training loss: 2.250761962723246
Validation loss: 2.5083078390939533

Epoch: 5| Step: 6
Training loss: 2.2698054189091788
Validation loss: 2.5125437399303077

Epoch: 5| Step: 7
Training loss: 2.4888534965818114
Validation loss: 2.508379361819803

Epoch: 5| Step: 8
Training loss: 2.127244885543286
Validation loss: 2.466746771299407

Epoch: 5| Step: 9
Training loss: 2.22855456733613
Validation loss: 2.4568865495250654

Epoch: 5| Step: 10
Training loss: 2.429716545495601
Validation loss: 2.450019666874504

Epoch: 280| Step: 0
Training loss: 2.469036809944287
Validation loss: 2.416510162830441

Epoch: 5| Step: 1
Training loss: 1.8767071899230803
Validation loss: 2.4042326865461283

Epoch: 5| Step: 2
Training loss: 2.2272908408183936
Validation loss: 2.3986882235754443

Epoch: 5| Step: 3
Training loss: 1.9235427567341083
Validation loss: 2.382657012896185

Epoch: 5| Step: 4
Training loss: 2.1069037761324325
Validation loss: 2.3932158658260603

Epoch: 5| Step: 5
Training loss: 2.2674563668457473
Validation loss: 2.3856929417197006

Epoch: 5| Step: 6
Training loss: 2.5324101556203455
Validation loss: 2.3960482996251713

Epoch: 5| Step: 7
Training loss: 2.10836360844322
Validation loss: 2.40075511546875

Epoch: 5| Step: 8
Training loss: 2.6241122061476108
Validation loss: 2.4203514597048907

Epoch: 5| Step: 9
Training loss: 1.8340246096616601
Validation loss: 2.4718677962928473

Epoch: 5| Step: 10
Training loss: 2.8835081176114374
Validation loss: 2.480698477736439

Epoch: 281| Step: 0
Training loss: 2.318683707634002
Validation loss: 2.456621861321882

Epoch: 5| Step: 1
Training loss: 1.9446492117585663
Validation loss: 2.4481811937311653

Epoch: 5| Step: 2
Training loss: 2.3880001443003445
Validation loss: 2.4276453679234433

Epoch: 5| Step: 3
Training loss: 2.2778375263699795
Validation loss: 2.41996953859805

Epoch: 5| Step: 4
Training loss: 1.8930812674729414
Validation loss: 2.431156755230381

Epoch: 5| Step: 5
Training loss: 2.8459197768956663
Validation loss: 2.440209418715003

Epoch: 5| Step: 6
Training loss: 2.1961470677197825
Validation loss: 2.436837935478309

Epoch: 5| Step: 7
Training loss: 2.215677847722935
Validation loss: 2.4225419210238104

Epoch: 5| Step: 8
Training loss: 2.3527528911877225
Validation loss: 2.41530159900005

Epoch: 5| Step: 9
Training loss: 2.3520027838385578
Validation loss: 2.402748291679094

Epoch: 5| Step: 10
Training loss: 1.689779790266621
Validation loss: 2.395482111828183

Epoch: 282| Step: 0
Training loss: 2.6417231336108142
Validation loss: 2.3978544515729543

Epoch: 5| Step: 1
Training loss: 2.3297120899563155
Validation loss: 2.4278861959894127

Epoch: 5| Step: 2
Training loss: 2.2652948599376015
Validation loss: 2.4425506474432024

Epoch: 5| Step: 3
Training loss: 2.2194197812365823
Validation loss: 2.4370728500514076

Epoch: 5| Step: 4
Training loss: 1.905107687462057
Validation loss: 2.4550135318600455

Epoch: 5| Step: 5
Training loss: 2.103554387917566
Validation loss: 2.45719179214261

Epoch: 5| Step: 6
Training loss: 1.9153978321985279
Validation loss: 2.456655381914593

Epoch: 5| Step: 7
Training loss: 2.7727556276932415
Validation loss: 2.4382431305760432

Epoch: 5| Step: 8
Training loss: 1.767517021345438
Validation loss: 2.4023992183059932

Epoch: 5| Step: 9
Training loss: 2.363633008267615
Validation loss: 2.414608649452275

Epoch: 5| Step: 10
Training loss: 1.9885971328036376
Validation loss: 2.394424178330175

Epoch: 283| Step: 0
Training loss: 2.3091028365425834
Validation loss: 2.3772153080933522

Epoch: 5| Step: 1
Training loss: 2.3183013728791093
Validation loss: 2.3731597070081265

Epoch: 5| Step: 2
Training loss: 1.989851116380959
Validation loss: 2.3730505037788503

Epoch: 5| Step: 3
Training loss: 1.829773119218927
Validation loss: 2.3890760211651423

Epoch: 5| Step: 4
Training loss: 2.6538858102410563
Validation loss: 2.3761759341890025

Epoch: 5| Step: 5
Training loss: 1.4834560561400723
Validation loss: 2.368423217896462

Epoch: 5| Step: 6
Training loss: 2.386253498888123
Validation loss: 2.371398189397286

Epoch: 5| Step: 7
Training loss: 2.3663431304644287
Validation loss: 2.3598157664799655

Epoch: 5| Step: 8
Training loss: 2.0496182295570007
Validation loss: 2.3400472771295058

Epoch: 5| Step: 9
Training loss: 2.713914802850102
Validation loss: 2.331837935960239

Epoch: 5| Step: 10
Training loss: 1.8908532375309692
Validation loss: 2.3500239523978452

Epoch: 284| Step: 0
Training loss: 2.352901445081394
Validation loss: 2.3568513908934

Epoch: 5| Step: 1
Training loss: 2.3280445059359693
Validation loss: 2.3698873503059783

Epoch: 5| Step: 2
Training loss: 2.1318646794686953
Validation loss: 2.3833935192470674

Epoch: 5| Step: 3
Training loss: 2.4589263933419265
Validation loss: 2.3998752950200726

Epoch: 5| Step: 4
Training loss: 1.6940062100365316
Validation loss: 2.402296782510596

Epoch: 5| Step: 5
Training loss: 2.0376220526150033
Validation loss: 2.4354935816116443

Epoch: 5| Step: 6
Training loss: 2.316717683335582
Validation loss: 2.4354471386779384

Epoch: 5| Step: 7
Training loss: 2.1445074583863555
Validation loss: 2.435382223823016

Epoch: 5| Step: 8
Training loss: 2.1011892221205977
Validation loss: 2.4278369782521683

Epoch: 5| Step: 9
Training loss: 2.3846003594646903
Validation loss: 2.4225932061635875

Epoch: 5| Step: 10
Training loss: 1.9090519933119514
Validation loss: 2.402502246226622

Epoch: 285| Step: 0
Training loss: 1.8293004617731226
Validation loss: 2.3769765464739754

Epoch: 5| Step: 1
Training loss: 1.3539683367916333
Validation loss: 2.3528481298500674

Epoch: 5| Step: 2
Training loss: 2.681207164786815
Validation loss: 2.3350656289613094

Epoch: 5| Step: 3
Training loss: 1.9709341255958694
Validation loss: 2.3424728140421895

Epoch: 5| Step: 4
Training loss: 2.72287358602832
Validation loss: 2.356825806030938

Epoch: 5| Step: 5
Training loss: 2.554250230609771
Validation loss: 2.384378274834634

Epoch: 5| Step: 6
Training loss: 2.247557904236941
Validation loss: 2.392277546883487

Epoch: 5| Step: 7
Training loss: 2.0652818126363988
Validation loss: 2.418634473483682

Epoch: 5| Step: 8
Training loss: 1.4929171870183966
Validation loss: 2.4562958445744734

Epoch: 5| Step: 9
Training loss: 2.3347207667416643
Validation loss: 2.460066424472716

Epoch: 5| Step: 10
Training loss: 2.1623955100509313
Validation loss: 2.458286731988096

Epoch: 286| Step: 0
Training loss: 1.429702258424722
Validation loss: 2.4364523833193594

Epoch: 5| Step: 1
Training loss: 2.2019060157932433
Validation loss: 2.4512204254850065

Epoch: 5| Step: 2
Training loss: 2.23491230086411
Validation loss: 2.4186387774219797

Epoch: 5| Step: 3
Training loss: 2.1612276865754367
Validation loss: 2.4057534532128964

Epoch: 5| Step: 4
Training loss: 2.35068868326157
Validation loss: 2.393241478358749

Epoch: 5| Step: 5
Training loss: 2.9526957850906332
Validation loss: 2.361743065938577

Epoch: 5| Step: 6
Training loss: 2.231172200190262
Validation loss: 2.369713650653963

Epoch: 5| Step: 7
Training loss: 2.3327713244126507
Validation loss: 2.356384406291942

Epoch: 5| Step: 8
Training loss: 1.9668018450858877
Validation loss: 2.356402865555284

Epoch: 5| Step: 9
Training loss: 1.663930896695064
Validation loss: 2.369401941410841

Epoch: 5| Step: 10
Training loss: 1.9732088731273547
Validation loss: 2.4129935714639923

Epoch: 287| Step: 0
Training loss: 2.281820356581445
Validation loss: 2.431167734598933

Epoch: 5| Step: 1
Training loss: 2.4850745985473877
Validation loss: 2.4504393980689203

Epoch: 5| Step: 2
Training loss: 2.248244342367137
Validation loss: 2.428764910650135

Epoch: 5| Step: 3
Training loss: 2.2252538214790967
Validation loss: 2.4006395603629036

Epoch: 5| Step: 4
Training loss: 1.8170746260640456
Validation loss: 2.3858275431551554

Epoch: 5| Step: 5
Training loss: 2.0564208171355487
Validation loss: 2.3750974638391336

Epoch: 5| Step: 6
Training loss: 1.8608481077412602
Validation loss: 2.3493783881403756

Epoch: 5| Step: 7
Training loss: 1.9036100273748353
Validation loss: 2.3783616732932558

Epoch: 5| Step: 8
Training loss: 2.4404699376432664
Validation loss: 2.3607782478720085

Epoch: 5| Step: 9
Training loss: 2.328137391332638
Validation loss: 2.3645685464789588

Epoch: 5| Step: 10
Training loss: 2.390287288174232
Validation loss: 2.357276539087465

Epoch: 288| Step: 0
Training loss: 1.663723906692879
Validation loss: 2.3653738724986892

Epoch: 5| Step: 1
Training loss: 2.613791195049046
Validation loss: 2.367518263222715

Epoch: 5| Step: 2
Training loss: 1.9915614322436224
Validation loss: 2.379636210593552

Epoch: 5| Step: 3
Training loss: 1.6890551147864101
Validation loss: 2.4002658878301317

Epoch: 5| Step: 4
Training loss: 2.0790292020419328
Validation loss: 2.4230569634027486

Epoch: 5| Step: 5
Training loss: 2.279033890877677
Validation loss: 2.4626230900272326

Epoch: 5| Step: 6
Training loss: 1.8740316433550477
Validation loss: 2.462981505973592

Epoch: 5| Step: 7
Training loss: 2.197836188941667
Validation loss: 2.4858936464785804

Epoch: 5| Step: 8
Training loss: 2.6018117607691305
Validation loss: 2.4959723936260203

Epoch: 5| Step: 9
Training loss: 2.0457604555200564
Validation loss: 2.4910882127606997

Epoch: 5| Step: 10
Training loss: 2.3902356198415617
Validation loss: 2.4560824817657094

Epoch: 289| Step: 0
Training loss: 2.255988100020495
Validation loss: 2.447248721625175

Epoch: 5| Step: 1
Training loss: 1.6947251106547025
Validation loss: 2.430372578071248

Epoch: 5| Step: 2
Training loss: 2.2454694062626794
Validation loss: 2.4292384323753478

Epoch: 5| Step: 3
Training loss: 1.9609069821844025
Validation loss: 2.40759895824047

Epoch: 5| Step: 4
Training loss: 2.6411031256304334
Validation loss: 2.3899064334957942

Epoch: 5| Step: 5
Training loss: 2.399436717689138
Validation loss: 2.357318731045161

Epoch: 5| Step: 6
Training loss: 1.8601025352108422
Validation loss: 2.3438241215405498

Epoch: 5| Step: 7
Training loss: 2.1871283079166908
Validation loss: 2.356150594754421

Epoch: 5| Step: 8
Training loss: 2.049522260498006
Validation loss: 2.3557597670510955

Epoch: 5| Step: 9
Training loss: 2.279080443579042
Validation loss: 2.3774549094634145

Epoch: 5| Step: 10
Training loss: 2.4031326115243363
Validation loss: 2.4099481230547557

Epoch: 290| Step: 0
Training loss: 2.3621985106874575
Validation loss: 2.4300355271929646

Epoch: 5| Step: 1
Training loss: 2.712218935419835
Validation loss: 2.391412659783783

Epoch: 5| Step: 2
Training loss: 1.9595597126850013
Validation loss: 2.386598834597535

Epoch: 5| Step: 3
Training loss: 1.8611922159441678
Validation loss: 2.3953067759110658

Epoch: 5| Step: 4
Training loss: 2.5502829189055047
Validation loss: 2.4014941263379663

Epoch: 5| Step: 5
Training loss: 1.8465615511607898
Validation loss: 2.4400849257482666

Epoch: 5| Step: 6
Training loss: 2.251921363202944
Validation loss: 2.447100013825563

Epoch: 5| Step: 7
Training loss: 2.1945889729845676
Validation loss: 2.450930370655214

Epoch: 5| Step: 8
Training loss: 1.8715546424587401
Validation loss: 2.464271190937407

Epoch: 5| Step: 9
Training loss: 1.6122912308739623
Validation loss: 2.462807686197966

Epoch: 5| Step: 10
Training loss: 1.8004963084625054
Validation loss: 2.4697273472476082

Epoch: 291| Step: 0
Training loss: 1.7911906016498074
Validation loss: 2.4500570378916584

Epoch: 5| Step: 1
Training loss: 2.7754602067830185
Validation loss: 2.461452570732856

Epoch: 5| Step: 2
Training loss: 2.079517442957078
Validation loss: 2.4320937141978445

Epoch: 5| Step: 3
Training loss: 1.6316351775630276
Validation loss: 2.4282897763232976

Epoch: 5| Step: 4
Training loss: 2.3062661147136123
Validation loss: 2.429296867232981

Epoch: 5| Step: 5
Training loss: 1.825652316841442
Validation loss: 2.4292268659651177

Epoch: 5| Step: 6
Training loss: 1.6556424160102878
Validation loss: 2.4405243377306665

Epoch: 5| Step: 7
Training loss: 1.8019328706877755
Validation loss: 2.425428602161416

Epoch: 5| Step: 8
Training loss: 2.473057429595873
Validation loss: 2.4425596223444277

Epoch: 5| Step: 9
Training loss: 2.365070869722731
Validation loss: 2.4370467703555505

Epoch: 5| Step: 10
Training loss: 1.7489247424694343
Validation loss: 2.4380335890311464

Epoch: 292| Step: 0
Training loss: 2.1494417929691196
Validation loss: 2.428505622105421

Epoch: 5| Step: 1
Training loss: 2.4074333550883384
Validation loss: 2.447893621632519

Epoch: 5| Step: 2
Training loss: 2.108943866892529
Validation loss: 2.413786584596385

Epoch: 5| Step: 3
Training loss: 2.0934790820308273
Validation loss: 2.427522638469096

Epoch: 5| Step: 4
Training loss: 2.208635297559222
Validation loss: 2.4060220768917535

Epoch: 5| Step: 5
Training loss: 1.7460538787044537
Validation loss: 2.4347807843820193

Epoch: 5| Step: 6
Training loss: 2.0891977042454157
Validation loss: 2.428305623972281

Epoch: 5| Step: 7
Training loss: 1.9610474088346934
Validation loss: 2.4322357758040742

Epoch: 5| Step: 8
Training loss: 1.3232934920721795
Validation loss: 2.431540299340976

Epoch: 5| Step: 9
Training loss: 2.1441770167223897
Validation loss: 2.441191262375608

Epoch: 5| Step: 10
Training loss: 2.3350208742241993
Validation loss: 2.4622977028398556

Epoch: 293| Step: 0
Training loss: 1.930860031902642
Validation loss: 2.424782868798438

Epoch: 5| Step: 1
Training loss: 2.231535915146422
Validation loss: 2.4041228708190268

Epoch: 5| Step: 2
Training loss: 2.1051128136131636
Validation loss: 2.404713045401518

Epoch: 5| Step: 3
Training loss: 2.2072548542010373
Validation loss: 2.3972905992135036

Epoch: 5| Step: 4
Training loss: 2.137293429738525
Validation loss: 2.4132480667218745

Epoch: 5| Step: 5
Training loss: 2.1013527237236334
Validation loss: 2.394698191804461

Epoch: 5| Step: 6
Training loss: 1.9250213175992805
Validation loss: 2.3814398421628895

Epoch: 5| Step: 7
Training loss: 1.9155784364800552
Validation loss: 2.359592225912704

Epoch: 5| Step: 8
Training loss: 2.1193054416393493
Validation loss: 2.3610695003033477

Epoch: 5| Step: 9
Training loss: 2.2306305781514073
Validation loss: 2.3796365327135867

Epoch: 5| Step: 10
Training loss: 1.9593921666708989
Validation loss: 2.4012893567863

Epoch: 294| Step: 0
Training loss: 1.8054250555887543
Validation loss: 2.4111883795108056

Epoch: 5| Step: 1
Training loss: 2.058296544084723
Validation loss: 2.4315047808852333

Epoch: 5| Step: 2
Training loss: 2.3410144354608606
Validation loss: 2.4529938363277233

Epoch: 5| Step: 3
Training loss: 1.8457064189578742
Validation loss: 2.475813798845752

Epoch: 5| Step: 4
Training loss: 1.7527426617237107
Validation loss: 2.4909156199815254

Epoch: 5| Step: 5
Training loss: 2.061185244346376
Validation loss: 2.5515616999907746

Epoch: 5| Step: 6
Training loss: 1.6631460755742775
Validation loss: 2.5234690201060452

Epoch: 5| Step: 7
Training loss: 2.0020329157117427
Validation loss: 2.485541207922926

Epoch: 5| Step: 8
Training loss: 2.7855246622571785
Validation loss: 2.4376062954258746

Epoch: 5| Step: 9
Training loss: 2.0861017398254065
Validation loss: 2.40873628380548

Epoch: 5| Step: 10
Training loss: 1.8770790653271971
Validation loss: 2.3897173613810505

Epoch: 295| Step: 0
Training loss: 2.164864291723805
Validation loss: 2.388888787098442

Epoch: 5| Step: 1
Training loss: 2.3566615182945347
Validation loss: 2.3972228138466387

Epoch: 5| Step: 2
Training loss: 1.925806815265937
Validation loss: 2.3757490348868817

Epoch: 5| Step: 3
Training loss: 2.24549159727391
Validation loss: 2.389347325597355

Epoch: 5| Step: 4
Training loss: 1.7725392894398793
Validation loss: 2.3627066621306714

Epoch: 5| Step: 5
Training loss: 2.2053958741598922
Validation loss: 2.344414854194236

Epoch: 5| Step: 6
Training loss: 1.8744779495810497
Validation loss: 2.3397319169232387

Epoch: 5| Step: 7
Training loss: 1.8823998343275121
Validation loss: 2.355533014585822

Epoch: 5| Step: 8
Training loss: 2.4089237567369133
Validation loss: 2.386054249384891

Epoch: 5| Step: 9
Training loss: 2.166642066620288
Validation loss: 2.412463214255254

Epoch: 5| Step: 10
Training loss: 2.266650263876562
Validation loss: 2.455783515116246

Epoch: 296| Step: 0
Training loss: 1.9502795434754923
Validation loss: 2.468843359925848

Epoch: 5| Step: 1
Training loss: 2.2892472645009105
Validation loss: 2.4620576136646344

Epoch: 5| Step: 2
Training loss: 1.8705523828647557
Validation loss: 2.4340338630216545

Epoch: 5| Step: 3
Training loss: 1.8409193260216603
Validation loss: 2.4370554352160823

Epoch: 5| Step: 4
Training loss: 2.0929561647362145
Validation loss: 2.428797535889347

Epoch: 5| Step: 5
Training loss: 2.1779197169238076
Validation loss: 2.439898123953578

Epoch: 5| Step: 6
Training loss: 1.7576038830199863
Validation loss: 2.467365018148105

Epoch: 5| Step: 7
Training loss: 2.1500914709460757
Validation loss: 2.454726787848111

Epoch: 5| Step: 8
Training loss: 2.145430246165582
Validation loss: 2.4160556112621987

Epoch: 5| Step: 9
Training loss: 2.4146500647086646
Validation loss: 2.3978135865791343

Epoch: 5| Step: 10
Training loss: 2.2973456906041485
Validation loss: 2.4034373829682254

Epoch: 297| Step: 0
Training loss: 1.6179447336224184
Validation loss: 2.4336364760251548

Epoch: 5| Step: 1
Training loss: 2.1815563653505303
Validation loss: 2.4644534260891517

Epoch: 5| Step: 2
Training loss: 2.0028011256582587
Validation loss: 2.51107026918104

Epoch: 5| Step: 3
Training loss: 2.6075091058091133
Validation loss: 2.5136972005025857

Epoch: 5| Step: 4
Training loss: 2.1056954398054066
Validation loss: 2.460027957053419

Epoch: 5| Step: 5
Training loss: 2.013597281671871
Validation loss: 2.4020068693024617

Epoch: 5| Step: 6
Training loss: 1.9090819038657625
Validation loss: 2.408365878852416

Epoch: 5| Step: 7
Training loss: 1.9675122563369356
Validation loss: 2.3743248526614935

Epoch: 5| Step: 8
Training loss: 1.769077941902608
Validation loss: 2.3381871745145806

Epoch: 5| Step: 9
Training loss: 2.0967097073712573
Validation loss: 2.3470233921936536

Epoch: 5| Step: 10
Training loss: 1.8583338411042527
Validation loss: 2.3645886754574663

Epoch: 298| Step: 0
Training loss: 2.043025699791798
Validation loss: 2.3512672481802763

Epoch: 5| Step: 1
Training loss: 2.209181556704242
Validation loss: 2.355861889431676

Epoch: 5| Step: 2
Training loss: 2.201750630989907
Validation loss: 2.392518143980841

Epoch: 5| Step: 3
Training loss: 2.1646475431472596
Validation loss: 2.40118768933242

Epoch: 5| Step: 4
Training loss: 1.8551505689358079
Validation loss: 2.3829420915528914

Epoch: 5| Step: 5
Training loss: 1.9605853611858102
Validation loss: 2.392409325028352

Epoch: 5| Step: 6
Training loss: 1.7675796761690363
Validation loss: 2.3928786707166254

Epoch: 5| Step: 7
Training loss: 2.1579616221638265
Validation loss: 2.434509836007173

Epoch: 5| Step: 8
Training loss: 1.967766410114623
Validation loss: 2.4485372503317957

Epoch: 5| Step: 9
Training loss: 1.8915029961897303
Validation loss: 2.4539301862169993

Epoch: 5| Step: 10
Training loss: 1.8117551917539556
Validation loss: 2.4566173202515973

Epoch: 299| Step: 0
Training loss: 1.9585732725615117
Validation loss: 2.473158522604392

Epoch: 5| Step: 1
Training loss: 2.110292136411681
Validation loss: 2.4947693053688953

Epoch: 5| Step: 2
Training loss: 1.894566486463555
Validation loss: 2.497773108751087

Epoch: 5| Step: 3
Training loss: 2.405558895591353
Validation loss: 2.490660836147033

Epoch: 5| Step: 4
Training loss: 2.2546857150487782
Validation loss: 2.4556514995784187

Epoch: 5| Step: 5
Training loss: 1.7582124382269029
Validation loss: 2.397709089114272

Epoch: 5| Step: 6
Training loss: 1.78928137360746
Validation loss: 2.3541096016031995

Epoch: 5| Step: 7
Training loss: 2.0207916989576566
Validation loss: 2.333256039752904

Epoch: 5| Step: 8
Training loss: 2.2861711905418147
Validation loss: 2.33074492458769

Epoch: 5| Step: 9
Training loss: 1.7046598465422156
Validation loss: 2.3504380596537544

Epoch: 5| Step: 10
Training loss: 2.042315347605492
Validation loss: 2.3509740218847113

Epoch: 300| Step: 0
Training loss: 2.2315134785129924
Validation loss: 2.341440504863424

Epoch: 5| Step: 1
Training loss: 1.304366066449239
Validation loss: 2.349723554486625

Epoch: 5| Step: 2
Training loss: 1.951866415776295
Validation loss: 2.3427431696316203

Epoch: 5| Step: 3
Training loss: 2.0444926601174607
Validation loss: 2.368591098237669

Epoch: 5| Step: 4
Training loss: 1.9875714247243386
Validation loss: 2.428483625523918

Epoch: 5| Step: 5
Training loss: 1.93304978242523
Validation loss: 2.4671460994729464

Epoch: 5| Step: 6
Training loss: 2.5095891155708534
Validation loss: 2.4960580254802998

Epoch: 5| Step: 7
Training loss: 2.177467336661513
Validation loss: 2.518357856335572

Epoch: 5| Step: 8
Training loss: 1.7156791998078902
Validation loss: 2.51442153934454

Epoch: 5| Step: 9
Training loss: 1.84853524395438
Validation loss: 2.5311948212433344

Epoch: 5| Step: 10
Training loss: 1.9835019331149275
Validation loss: 2.4800423240490317

Epoch: 301| Step: 0
Training loss: 1.634681763315317
Validation loss: 2.456948804151127

Epoch: 5| Step: 1
Training loss: 2.038419073905515
Validation loss: 2.4219442547526637

Epoch: 5| Step: 2
Training loss: 2.1731583350858323
Validation loss: 2.4311435139109734

Epoch: 5| Step: 3
Training loss: 1.3795322801795886
Validation loss: 2.4450976996126945

Epoch: 5| Step: 4
Training loss: 2.107065363329533
Validation loss: 2.4334126856793468

Epoch: 5| Step: 5
Training loss: 1.8027661156468993
Validation loss: 2.4283534661207717

Epoch: 5| Step: 6
Training loss: 2.0164982286630386
Validation loss: 2.444466582002579

Epoch: 5| Step: 7
Training loss: 2.2291512414511456
Validation loss: 2.4578773902342044

Epoch: 5| Step: 8
Training loss: 1.8477952191147826
Validation loss: 2.429797807309079

Epoch: 5| Step: 9
Training loss: 1.8563911153155364
Validation loss: 2.448841171912069

Epoch: 5| Step: 10
Training loss: 2.038341175395928
Validation loss: 2.463340141397656

Epoch: 302| Step: 0
Training loss: 2.192588120258818
Validation loss: 2.4801527030453596

Epoch: 5| Step: 1
Training loss: 2.122889087361841
Validation loss: 2.4801065774984443

Epoch: 5| Step: 2
Training loss: 1.6428376309201658
Validation loss: 2.459034378833639

Epoch: 5| Step: 3
Training loss: 2.108768856414262
Validation loss: 2.456993587523542

Epoch: 5| Step: 4
Training loss: 1.6391928098242565
Validation loss: 2.4566332168306566

Epoch: 5| Step: 5
Training loss: 2.2806044409785176
Validation loss: 2.418199936095135

Epoch: 5| Step: 6
Training loss: 1.959704737319044
Validation loss: 2.3944258169916477

Epoch: 5| Step: 7
Training loss: 1.55395544251395
Validation loss: 2.365673695411751

Epoch: 5| Step: 8
Training loss: 1.5401327991199885
Validation loss: 2.378987271047103

Epoch: 5| Step: 9
Training loss: 1.6064076149642217
Validation loss: 2.3653675047738685

Epoch: 5| Step: 10
Training loss: 2.1777946977001323
Validation loss: 2.3658526632430266

Epoch: 303| Step: 0
Training loss: 1.8047050706412644
Validation loss: 2.3577297259906667

Epoch: 5| Step: 1
Training loss: 1.9751722550420794
Validation loss: 2.3750599366220495

Epoch: 5| Step: 2
Training loss: 2.0746889317836956
Validation loss: 2.3596643298860323

Epoch: 5| Step: 3
Training loss: 1.6668407190357146
Validation loss: 2.377881038919688

Epoch: 5| Step: 4
Training loss: 1.403367457862159
Validation loss: 2.3917045721316215

Epoch: 5| Step: 5
Training loss: 2.18842731983868
Validation loss: 2.4129471831293157

Epoch: 5| Step: 6
Training loss: 1.6518289832851196
Validation loss: 2.4310825082163103

Epoch: 5| Step: 7
Training loss: 2.172272131309376
Validation loss: 2.4124398248814445

Epoch: 5| Step: 8
Training loss: 1.4793044370866426
Validation loss: 2.408980891190522

Epoch: 5| Step: 9
Training loss: 2.068076715075743
Validation loss: 2.4295952913341883

Epoch: 5| Step: 10
Training loss: 2.0754334651949042
Validation loss: 2.4410348633854064

Epoch: 304| Step: 0
Training loss: 1.7083972205644746
Validation loss: 2.440592998160223

Epoch: 5| Step: 1
Training loss: 1.9862939162107727
Validation loss: 2.4501104853556646

Epoch: 5| Step: 2
Training loss: 2.5334588291639166
Validation loss: 2.4339628825690798

Epoch: 5| Step: 3
Training loss: 1.7643986046428608
Validation loss: 2.433205703007181

Epoch: 5| Step: 4
Training loss: 2.0827233629548356
Validation loss: 2.4120974224847798

Epoch: 5| Step: 5
Training loss: 1.8940007361679498
Validation loss: 2.3983450037992333

Epoch: 5| Step: 6
Training loss: 1.6680951751752635
Validation loss: 2.4104448288882176

Epoch: 5| Step: 7
Training loss: 1.0979513945808623
Validation loss: 2.394959293992089

Epoch: 5| Step: 8
Training loss: 1.8197372902962066
Validation loss: 2.387874932730739

Epoch: 5| Step: 9
Training loss: 2.1169687981628402
Validation loss: 2.3815630766102815

Epoch: 5| Step: 10
Training loss: 1.6101562677686043
Validation loss: 2.3783280155673667

Epoch: 305| Step: 0
Training loss: 1.5452615048718197
Validation loss: 2.4140909157897306

Epoch: 5| Step: 1
Training loss: 1.5033014047253122
Validation loss: 2.4011408935469527

Epoch: 5| Step: 2
Training loss: 1.3802250939077292
Validation loss: 2.404023121140425

Epoch: 5| Step: 3
Training loss: 1.9910397084145255
Validation loss: 2.4160770673689482

Epoch: 5| Step: 4
Training loss: 2.2318993571845005
Validation loss: 2.4371718771388573

Epoch: 5| Step: 5
Training loss: 1.0571371382113088
Validation loss: 2.4495578232911095

Epoch: 5| Step: 6
Training loss: 1.8304404568734427
Validation loss: 2.465267746811693

Epoch: 5| Step: 7
Training loss: 2.1106589471664203
Validation loss: 2.475083478023431

Epoch: 5| Step: 8
Training loss: 1.9534317386086375
Validation loss: 2.505302393834273

Epoch: 5| Step: 9
Training loss: 1.9234098182998027
Validation loss: 2.5160643246762375

Epoch: 5| Step: 10
Training loss: 2.434486678454668
Validation loss: 2.515469501886554

Epoch: 306| Step: 0
Training loss: 1.9015847323143775
Validation loss: 2.507970405835911

Epoch: 5| Step: 1
Training loss: 1.1822168379755036
Validation loss: 2.453879951960642

Epoch: 5| Step: 2
Training loss: 1.8241516362328065
Validation loss: 2.4149204334136654

Epoch: 5| Step: 3
Training loss: 1.9558954959716301
Validation loss: 2.367623936185732

Epoch: 5| Step: 4
Training loss: 1.660824055713568
Validation loss: 2.3546496509397126

Epoch: 5| Step: 5
Training loss: 1.8611173400331835
Validation loss: 2.3386107137050534

Epoch: 5| Step: 6
Training loss: 1.8763333348237918
Validation loss: 2.3309956815105797

Epoch: 5| Step: 7
Training loss: 2.0436892579177655
Validation loss: 2.344489965086181

Epoch: 5| Step: 8
Training loss: 2.5817617948116216
Validation loss: 2.333171633055778

Epoch: 5| Step: 9
Training loss: 1.7115925270944432
Validation loss: 2.3503449975489947

Epoch: 5| Step: 10
Training loss: 1.6599601360498197
Validation loss: 2.3940572906772037

Epoch: 307| Step: 0
Training loss: 1.7144035869333016
Validation loss: 2.4264983094826307

Epoch: 5| Step: 1
Training loss: 1.9613031905032239
Validation loss: 2.4174865563112977

Epoch: 5| Step: 2
Training loss: 1.8394143156152603
Validation loss: 2.4186995230293844

Epoch: 5| Step: 3
Training loss: 1.8446459775319834
Validation loss: 2.445016955738322

Epoch: 5| Step: 4
Training loss: 2.0198860963490297
Validation loss: 2.4340709876144446

Epoch: 5| Step: 5
Training loss: 1.746122492269905
Validation loss: 2.4453872134047216

Epoch: 5| Step: 6
Training loss: 1.6275290103090583
Validation loss: 2.441420536122516

Epoch: 5| Step: 7
Training loss: 1.831005988935742
Validation loss: 2.453544904727186

Epoch: 5| Step: 8
Training loss: 1.4482923976145277
Validation loss: 2.446364696560654

Epoch: 5| Step: 9
Training loss: 2.009276572467197
Validation loss: 2.4428339145185642

Epoch: 5| Step: 10
Training loss: 1.7884997686397157
Validation loss: 2.420982623554119

Epoch: 308| Step: 0
Training loss: 2.321714754594733
Validation loss: 2.438008600586136

Epoch: 5| Step: 1
Training loss: 1.7771008000590616
Validation loss: 2.4296736376383787

Epoch: 5| Step: 2
Training loss: 1.4696595642432735
Validation loss: 2.415982754998928

Epoch: 5| Step: 3
Training loss: 1.971805986021911
Validation loss: 2.4128200510199544

Epoch: 5| Step: 4
Training loss: 1.418980177302012
Validation loss: 2.4274548260312216

Epoch: 5| Step: 5
Training loss: 1.888606609806612
Validation loss: 2.396321097680332

Epoch: 5| Step: 6
Training loss: 1.756697915949584
Validation loss: 2.39931602537676

Epoch: 5| Step: 7
Training loss: 1.8047031550533448
Validation loss: 2.3879601638420715

Epoch: 5| Step: 8
Training loss: 1.8952777453677288
Validation loss: 2.3592772039453203

Epoch: 5| Step: 9
Training loss: 1.8420761398293473
Validation loss: 2.345919705570182

Epoch: 5| Step: 10
Training loss: 1.5046808006953505
Validation loss: 2.353761511969652

Epoch: 309| Step: 0
Training loss: 1.5793564778831812
Validation loss: 2.3391145079983575

Epoch: 5| Step: 1
Training loss: 1.6849533928104965
Validation loss: 2.3385567646227594

Epoch: 5| Step: 2
Training loss: 1.7712414289979173
Validation loss: 2.374809229409828

Epoch: 5| Step: 3
Training loss: 1.8220789773910635
Validation loss: 2.377589737903034

Epoch: 5| Step: 4
Training loss: 1.1322790007714856
Validation loss: 2.384724544314322

Epoch: 5| Step: 5
Training loss: 1.184333544888859
Validation loss: 2.427880813986408

Epoch: 5| Step: 6
Training loss: 2.313370308905755
Validation loss: 2.4707073180019483

Epoch: 5| Step: 7
Training loss: 2.0564205852583077
Validation loss: 2.4771611667689206

Epoch: 5| Step: 8
Training loss: 2.0440211311636567
Validation loss: 2.44572146362289

Epoch: 5| Step: 9
Training loss: 1.8054675113371657
Validation loss: 2.427376769839089

Epoch: 5| Step: 10
Training loss: 1.7051692208581777
Validation loss: 2.418255535778644

Epoch: 310| Step: 0
Training loss: 1.1541981921153897
Validation loss: 2.3828171069502275

Epoch: 5| Step: 1
Training loss: 1.9622509573590152
Validation loss: 2.3648629279149906

Epoch: 5| Step: 2
Training loss: 1.7625304929652146
Validation loss: 2.378885361179169

Epoch: 5| Step: 3
Training loss: 1.8494194924229217
Validation loss: 2.404863942514485

Epoch: 5| Step: 4
Training loss: 1.099993894299988
Validation loss: 2.4137819411669654

Epoch: 5| Step: 5
Training loss: 1.3829389180301863
Validation loss: 2.4430193910396563

Epoch: 5| Step: 6
Training loss: 2.022438067606691
Validation loss: 2.4788594516155817

Epoch: 5| Step: 7
Training loss: 2.282246202311729
Validation loss: 2.4890662399552386

Epoch: 5| Step: 8
Training loss: 1.9280570242351216
Validation loss: 2.4889293574920597

Epoch: 5| Step: 9
Training loss: 1.729952491923797
Validation loss: 2.483251805717711

Epoch: 5| Step: 10
Training loss: 1.932925885389508
Validation loss: 2.4594755701482836

Epoch: 311| Step: 0
Training loss: 1.6933207259997924
Validation loss: 2.443984431281292

Epoch: 5| Step: 1
Training loss: 1.993752736056851
Validation loss: 2.412568295206209

Epoch: 5| Step: 2
Training loss: 1.8583109399561062
Validation loss: 2.387801589175927

Epoch: 5| Step: 3
Training loss: 1.462013215784126
Validation loss: 2.387385915598884

Epoch: 5| Step: 4
Training loss: 1.7524636501836048
Validation loss: 2.3662390205638175

Epoch: 5| Step: 5
Training loss: 1.7737855275677603
Validation loss: 2.356120341508369

Epoch: 5| Step: 6
Training loss: 1.858677324466077
Validation loss: 2.348719745976775

Epoch: 5| Step: 7
Training loss: 2.3178988146284465
Validation loss: 2.367955819604821

Epoch: 5| Step: 8
Training loss: 1.079874912894725
Validation loss: 2.3586824527069314

Epoch: 5| Step: 9
Training loss: 1.796215500258059
Validation loss: 2.3679939942206856

Epoch: 5| Step: 10
Training loss: 1.5526185958210585
Validation loss: 2.42703274973387

Epoch: 312| Step: 0
Training loss: 1.4037328444236794
Validation loss: 2.467514243865844

Epoch: 5| Step: 1
Training loss: 1.420478638184572
Validation loss: 2.4771405108998303

Epoch: 5| Step: 2
Training loss: 1.7066302144856575
Validation loss: 2.4658830766092557

Epoch: 5| Step: 3
Training loss: 1.889063986753221
Validation loss: 2.477491717965189

Epoch: 5| Step: 4
Training loss: 2.2473121058727896
Validation loss: 2.4439023614116135

Epoch: 5| Step: 5
Training loss: 1.7842524471386438
Validation loss: 2.4063605357856144

Epoch: 5| Step: 6
Training loss: 1.7266405182899638
Validation loss: 2.406328861354358

Epoch: 5| Step: 7
Training loss: 1.7570099079197932
Validation loss: 2.3975127762552413

Epoch: 5| Step: 8
Training loss: 1.5409285952284264
Validation loss: 2.382767491930096

Epoch: 5| Step: 9
Training loss: 1.7653309399976573
Validation loss: 2.4010893616092077

Epoch: 5| Step: 10
Training loss: 1.923811332513165
Validation loss: 2.3942275019006254

Epoch: 313| Step: 0
Training loss: 1.039983011803894
Validation loss: 2.404359238458709

Epoch: 5| Step: 1
Training loss: 1.6411700115482917
Validation loss: 2.3802974085860558

Epoch: 5| Step: 2
Training loss: 1.50012818424563
Validation loss: 2.402696611761702

Epoch: 5| Step: 3
Training loss: 2.0673235351828927
Validation loss: 2.4095250378104813

Epoch: 5| Step: 4
Training loss: 1.9145451151368273
Validation loss: 2.40784552629505

Epoch: 5| Step: 5
Training loss: 1.3229337776258947
Validation loss: 2.4085358229021248

Epoch: 5| Step: 6
Training loss: 1.379128370684928
Validation loss: 2.393808111509653

Epoch: 5| Step: 7
Training loss: 1.824300106611449
Validation loss: 2.388564946916359

Epoch: 5| Step: 8
Training loss: 2.130628760399693
Validation loss: 2.367998943959901

Epoch: 5| Step: 9
Training loss: 1.8969563172961086
Validation loss: 2.371043725317291

Epoch: 5| Step: 10
Training loss: 1.7565934765074058
Validation loss: 2.3951557487091395

Epoch: 314| Step: 0
Training loss: 1.712060707718287
Validation loss: 2.399187565092294

Epoch: 5| Step: 1
Training loss: 1.4231844730540173
Validation loss: 2.375758713201252

Epoch: 5| Step: 2
Training loss: 1.686799645791979
Validation loss: 2.3827169817777962

Epoch: 5| Step: 3
Training loss: 1.9527647983281862
Validation loss: 2.40487622680088

Epoch: 5| Step: 4
Training loss: 1.782562107218685
Validation loss: 2.368424458355252

Epoch: 5| Step: 5
Training loss: 1.4469962545055113
Validation loss: 2.36483351841373

Epoch: 5| Step: 6
Training loss: 1.7286027272148294
Validation loss: 2.3702464780951282

Epoch: 5| Step: 7
Training loss: 1.4257400297712293
Validation loss: 2.3969274937367695

Epoch: 5| Step: 8
Training loss: 1.7939431196187945
Validation loss: 2.364441323164099

Epoch: 5| Step: 9
Training loss: 1.7204705383163996
Validation loss: 2.4053165786530952

Epoch: 5| Step: 10
Training loss: 1.8382983024120767
Validation loss: 2.4253924006978314

Epoch: 315| Step: 0
Training loss: 1.7772832503868687
Validation loss: 2.430932847334925

Epoch: 5| Step: 1
Training loss: 1.9743620795937837
Validation loss: 2.4600230403334398

Epoch: 5| Step: 2
Training loss: 1.5969662097181923
Validation loss: 2.4702271507186926

Epoch: 5| Step: 3
Training loss: 1.3256980262940203
Validation loss: 2.4403890422283188

Epoch: 5| Step: 4
Training loss: 1.8590803794494815
Validation loss: 2.4112694725984167

Epoch: 5| Step: 5
Training loss: 1.6553865017156133
Validation loss: 2.3824278904536373

Epoch: 5| Step: 6
Training loss: 2.039329306733287
Validation loss: 2.366928120489648

Epoch: 5| Step: 7
Training loss: 1.8567058093512385
Validation loss: 2.3324219891339135

Epoch: 5| Step: 8
Training loss: 1.691861203788816
Validation loss: 2.3437817145495465

Epoch: 5| Step: 9
Training loss: 1.5384949542964879
Validation loss: 2.3433506713637944

Epoch: 5| Step: 10
Training loss: 1.165998551389079
Validation loss: 2.3499332805126087

Epoch: 316| Step: 0
Training loss: 1.9973482791921202
Validation loss: 2.3644740585513158

Epoch: 5| Step: 1
Training loss: 1.5019338380842693
Validation loss: 2.3696834569703817

Epoch: 5| Step: 2
Training loss: 1.3947515233563672
Validation loss: 2.3590137944341314

Epoch: 5| Step: 3
Training loss: 1.6232572159882157
Validation loss: 2.375932989490602

Epoch: 5| Step: 4
Training loss: 1.0757296946686101
Validation loss: 2.3688868650072226

Epoch: 5| Step: 5
Training loss: 1.7320939606294736
Validation loss: 2.3849285389530697

Epoch: 5| Step: 6
Training loss: 1.9701478022593109
Validation loss: 2.4118129551247276

Epoch: 5| Step: 7
Training loss: 1.4689828404046938
Validation loss: 2.402084384339494

Epoch: 5| Step: 8
Training loss: 1.7387567791234149
Validation loss: 2.421230899242193

Epoch: 5| Step: 9
Training loss: 1.5475476276420563
Validation loss: 2.3891859404863878

Epoch: 5| Step: 10
Training loss: 2.043869607674386
Validation loss: 2.3827795861908014

Epoch: 317| Step: 0
Training loss: 1.780537780789377
Validation loss: 2.4057418101223185

Epoch: 5| Step: 1
Training loss: 1.5489497287342788
Validation loss: 2.4105117808723775

Epoch: 5| Step: 2
Training loss: 1.349969354917477
Validation loss: 2.394963702561481

Epoch: 5| Step: 3
Training loss: 1.4834032592293263
Validation loss: 2.4001649460630596

Epoch: 5| Step: 4
Training loss: 1.7581668750862742
Validation loss: 2.409572700663331

Epoch: 5| Step: 5
Training loss: 1.3805899134572925
Validation loss: 2.4138109082886237

Epoch: 5| Step: 6
Training loss: 1.8841291706932675
Validation loss: 2.411679533991086

Epoch: 5| Step: 7
Training loss: 1.2706979408475032
Validation loss: 2.415471253017183

Epoch: 5| Step: 8
Training loss: 1.7621148926452561
Validation loss: 2.382436459121655

Epoch: 5| Step: 9
Training loss: 1.7446806307709877
Validation loss: 2.399272967056703

Epoch: 5| Step: 10
Training loss: 2.1567154534003867
Validation loss: 2.40060954954309

Epoch: 318| Step: 0
Training loss: 1.7672483020579506
Validation loss: 2.3847895083192645

Epoch: 5| Step: 1
Training loss: 1.506317741801831
Validation loss: 2.348625264447624

Epoch: 5| Step: 2
Training loss: 1.4941367953382294
Validation loss: 2.3426691835103135

Epoch: 5| Step: 3
Training loss: 1.7490122596132205
Validation loss: 2.3488702346662342

Epoch: 5| Step: 4
Training loss: 1.7959203423164527
Validation loss: 2.3578885660605464

Epoch: 5| Step: 5
Training loss: 1.323223178628456
Validation loss: 2.3652551443016367

Epoch: 5| Step: 6
Training loss: 1.631257261062773
Validation loss: 2.3760389916926146

Epoch: 5| Step: 7
Training loss: 1.9264846971677794
Validation loss: 2.3562878384988317

Epoch: 5| Step: 8
Training loss: 1.6576711927012462
Validation loss: 2.3526963613622414

Epoch: 5| Step: 9
Training loss: 1.7492713773783324
Validation loss: 2.3545773302525794

Epoch: 5| Step: 10
Training loss: 1.3842103433961959
Validation loss: 2.364017273717718

Epoch: 319| Step: 0
Training loss: 1.7402317719274163
Validation loss: 2.3636153657934837

Epoch: 5| Step: 1
Training loss: 1.630191213824618
Validation loss: 2.3586581104764295

Epoch: 5| Step: 2
Training loss: 1.4986293411363827
Validation loss: 2.3671917106617775

Epoch: 5| Step: 3
Training loss: 2.1473154918202244
Validation loss: 2.373048158415125

Epoch: 5| Step: 4
Training loss: 1.528002974741971
Validation loss: 2.390394040545599

Epoch: 5| Step: 5
Training loss: 1.514717144763585
Validation loss: 2.3820668173170363

Epoch: 5| Step: 6
Training loss: 1.4240575953472996
Validation loss: 2.414258086208951

Epoch: 5| Step: 7
Training loss: 1.752296779783695
Validation loss: 2.393259614779802

Epoch: 5| Step: 8
Training loss: 1.580280305165988
Validation loss: 2.3882900875340414

Epoch: 5| Step: 9
Training loss: 1.6234048203087874
Validation loss: 2.3947184786132256

Epoch: 5| Step: 10
Training loss: 1.2022416971879393
Validation loss: 2.3869579999456794

Epoch: 320| Step: 0
Training loss: 1.768458632878644
Validation loss: 2.3682539649494476

Epoch: 5| Step: 1
Training loss: 1.8171807063493157
Validation loss: 2.347547013606169

Epoch: 5| Step: 2
Training loss: 1.508328917621591
Validation loss: 2.340403689626492

Epoch: 5| Step: 3
Training loss: 1.3198705080123723
Validation loss: 2.324367454392657

Epoch: 5| Step: 4
Training loss: 1.7703353031908609
Validation loss: 2.349664529067105

Epoch: 5| Step: 5
Training loss: 1.4040216804987764
Validation loss: 2.3790094596468405

Epoch: 5| Step: 6
Training loss: 1.7179908463053264
Validation loss: 2.3861734787714375

Epoch: 5| Step: 7
Training loss: 1.505566599446824
Validation loss: 2.403605548185663

Epoch: 5| Step: 8
Training loss: 1.1655424809841286
Validation loss: 2.3869774321104744

Epoch: 5| Step: 9
Training loss: 1.751093522786037
Validation loss: 2.402218188987894

Epoch: 5| Step: 10
Training loss: 1.920073246154783
Validation loss: 2.393465709680462

Epoch: 321| Step: 0
Training loss: 1.3694499886619547
Validation loss: 2.3706896007827276

Epoch: 5| Step: 1
Training loss: 1.2940218690501162
Validation loss: 2.3790801782650126

Epoch: 5| Step: 2
Training loss: 1.3573391896045335
Validation loss: 2.3664657026785227

Epoch: 5| Step: 3
Training loss: 1.3343945789910854
Validation loss: 2.341541245439019

Epoch: 5| Step: 4
Training loss: 1.7827640590388862
Validation loss: 2.3483960999233764

Epoch: 5| Step: 5
Training loss: 2.2043559646325352
Validation loss: 2.3468402624300535

Epoch: 5| Step: 6
Training loss: 1.8706182779636809
Validation loss: 2.3269761945465905

Epoch: 5| Step: 7
Training loss: 1.8841498599455049
Validation loss: 2.366110398904998

Epoch: 5| Step: 8
Training loss: 1.4374090248842621
Validation loss: 2.3652398095901255

Epoch: 5| Step: 9
Training loss: 1.5434969613577019
Validation loss: 2.407240217594834

Epoch: 5| Step: 10
Training loss: 1.2928296616530686
Validation loss: 2.4143399978674402

Epoch: 322| Step: 0
Training loss: 2.001877261329348
Validation loss: 2.3971635393804633

Epoch: 5| Step: 1
Training loss: 1.1669195048789802
Validation loss: 2.3700407289244647

Epoch: 5| Step: 2
Training loss: 1.2605679581483462
Validation loss: 2.367893772767414

Epoch: 5| Step: 3
Training loss: 1.25748794822909
Validation loss: 2.369964201356406

Epoch: 5| Step: 4
Training loss: 1.3684004716203864
Validation loss: 2.3614592733621547

Epoch: 5| Step: 5
Training loss: 1.6502863202061842
Validation loss: 2.3789909360247137

Epoch: 5| Step: 6
Training loss: 1.8081034249034829
Validation loss: 2.351518836553104

Epoch: 5| Step: 7
Training loss: 1.7288871753741883
Validation loss: 2.366721527969287

Epoch: 5| Step: 8
Training loss: 1.624749164295231
Validation loss: 2.3819355766330386

Epoch: 5| Step: 9
Training loss: 2.0358906480692904
Validation loss: 2.3918657385366373

Epoch: 5| Step: 10
Training loss: 1.1024019005656642
Validation loss: 2.4119580489795776

Epoch: 323| Step: 0
Training loss: 1.9945140940985142
Validation loss: 2.4152332682937887

Epoch: 5| Step: 1
Training loss: 1.3138216721051377
Validation loss: 2.4126236830485612

Epoch: 5| Step: 2
Training loss: 1.3345728814585895
Validation loss: 2.427063039601254

Epoch: 5| Step: 3
Training loss: 1.4359982980967774
Validation loss: 2.379471043997356

Epoch: 5| Step: 4
Training loss: 1.664502940745118
Validation loss: 2.3813624905292436

Epoch: 5| Step: 5
Training loss: 1.6872699015533543
Validation loss: 2.37743337006283

Epoch: 5| Step: 6
Training loss: 1.5939341420026576
Validation loss: 2.3605851126972714

Epoch: 5| Step: 7
Training loss: 1.17444806223392
Validation loss: 2.350951811857378

Epoch: 5| Step: 8
Training loss: 1.6591298240097732
Validation loss: 2.3699966214022083

Epoch: 5| Step: 9
Training loss: 1.687899648178338
Validation loss: 2.3674795059391434

Epoch: 5| Step: 10
Training loss: 1.6093301118683092
Validation loss: 2.3878796759243306

Epoch: 324| Step: 0
Training loss: 1.6470184726941444
Validation loss: 2.3449459511174306

Epoch: 5| Step: 1
Training loss: 1.378069831972238
Validation loss: 2.3722664278958074

Epoch: 5| Step: 2
Training loss: 1.3882403984349183
Validation loss: 2.348140778277553

Epoch: 5| Step: 3
Training loss: 1.5079163826847926
Validation loss: 2.3512888130337943

Epoch: 5| Step: 4
Training loss: 1.4536253365147154
Validation loss: 2.375932391722442

Epoch: 5| Step: 5
Training loss: 1.6924883264226387
Validation loss: 2.3825313160807124

Epoch: 5| Step: 6
Training loss: 1.5979381210034098
Validation loss: 2.3762645247937497

Epoch: 5| Step: 7
Training loss: 1.6225455895177419
Validation loss: 2.3975113947299005

Epoch: 5| Step: 8
Training loss: 1.8167952582434754
Validation loss: 2.3624019719009066

Epoch: 5| Step: 9
Training loss: 1.4945653374110237
Validation loss: 2.4123411290032206

Epoch: 5| Step: 10
Training loss: 1.4320018775703864
Validation loss: 2.4000763137111503

Epoch: 325| Step: 0
Training loss: 1.7699380369170432
Validation loss: 2.4162538207275137

Epoch: 5| Step: 1
Training loss: 1.6462919183838232
Validation loss: 2.387570743149458

Epoch: 5| Step: 2
Training loss: 1.370330598161424
Validation loss: 2.3837789005723455

Epoch: 5| Step: 3
Training loss: 1.641837335161064
Validation loss: 2.3789149369625195

Epoch: 5| Step: 4
Training loss: 1.500588937220417
Validation loss: 2.3714033644599923

Epoch: 5| Step: 5
Training loss: 1.636087154622501
Validation loss: 2.363754038857793

Epoch: 5| Step: 6
Training loss: 0.9271247868789031
Validation loss: 2.369740640135304

Epoch: 5| Step: 7
Training loss: 1.571904528361363
Validation loss: 2.3548344253032445

Epoch: 5| Step: 8
Training loss: 1.7041638207198102
Validation loss: 2.3486107478865135

Epoch: 5| Step: 9
Training loss: 1.4442734566174178
Validation loss: 2.3481987911918383

Epoch: 5| Step: 10
Training loss: 1.5398103862304646
Validation loss: 2.37242603554056

Epoch: 326| Step: 0
Training loss: 1.442348596041769
Validation loss: 2.368680027178158

Epoch: 5| Step: 1
Training loss: 0.8278628960170552
Validation loss: 2.38944669656988

Epoch: 5| Step: 2
Training loss: 1.6527984210024342
Validation loss: 2.4152898098197495

Epoch: 5| Step: 3
Training loss: 1.683167724520402
Validation loss: 2.4092052079989617

Epoch: 5| Step: 4
Training loss: 1.4570802572972583
Validation loss: 2.385045712473791

Epoch: 5| Step: 5
Training loss: 1.533633653973735
Validation loss: 2.381525068905703

Epoch: 5| Step: 6
Training loss: 1.8892202912493843
Validation loss: 2.35913222357632

Epoch: 5| Step: 7
Training loss: 1.103312948063579
Validation loss: 2.3553287259936875

Epoch: 5| Step: 8
Training loss: 1.6777112823779998
Validation loss: 2.3311329826183766

Epoch: 5| Step: 9
Training loss: 1.741635085310853
Validation loss: 2.344530883648634

Epoch: 5| Step: 10
Training loss: 1.4866873147981763
Validation loss: 2.349847365086953

Epoch: 327| Step: 0
Training loss: 1.555070762741419
Validation loss: 2.3548512506579486

Epoch: 5| Step: 1
Training loss: 1.3697918310515833
Validation loss: 2.3612905586337987

Epoch: 5| Step: 2
Training loss: 1.4928287107063816
Validation loss: 2.3710232900059154

Epoch: 5| Step: 3
Training loss: 1.4490432838677867
Validation loss: 2.3907149843045477

Epoch: 5| Step: 4
Training loss: 1.5417700638335394
Validation loss: 2.4140943097752916

Epoch: 5| Step: 5
Training loss: 1.4723529047915682
Validation loss: 2.4467416572355685

Epoch: 5| Step: 6
Training loss: 1.5388608693916577
Validation loss: 2.426504938071373

Epoch: 5| Step: 7
Training loss: 1.3738459599226414
Validation loss: 2.4351435772779655

Epoch: 5| Step: 8
Training loss: 1.5312211948721624
Validation loss: 2.422607525976944

Epoch: 5| Step: 9
Training loss: 1.7656611211002011
Validation loss: 2.3875855017201633

Epoch: 5| Step: 10
Training loss: 1.4981513552680936
Validation loss: 2.3728990637147485

Epoch: 328| Step: 0
Training loss: 1.452204833381825
Validation loss: 2.3842742073092364

Epoch: 5| Step: 1
Training loss: 1.4735326612857051
Validation loss: 2.3462588751026585

Epoch: 5| Step: 2
Training loss: 1.3189550339826186
Validation loss: 2.3578844181556082

Epoch: 5| Step: 3
Training loss: 1.815145075230771
Validation loss: 2.3679556214819284

Epoch: 5| Step: 4
Training loss: 1.530516000887736
Validation loss: 2.3344962046734765

Epoch: 5| Step: 5
Training loss: 1.4236358805830227
Validation loss: 2.362273680144618

Epoch: 5| Step: 6
Training loss: 1.5712301125857304
Validation loss: 2.364836779288398

Epoch: 5| Step: 7
Training loss: 1.2480654528552984
Validation loss: 2.3544601326846792

Epoch: 5| Step: 8
Training loss: 1.4687426140782127
Validation loss: 2.3540630243348235

Epoch: 5| Step: 9
Training loss: 1.6306476752567713
Validation loss: 2.3482546017629065

Epoch: 5| Step: 10
Training loss: 1.445309943119571
Validation loss: 2.3527160013237376

Epoch: 329| Step: 0
Training loss: 1.3841435120491052
Validation loss: 2.3395132348769043

Epoch: 5| Step: 1
Training loss: 1.653146823674104
Validation loss: 2.355102366901926

Epoch: 5| Step: 2
Training loss: 1.1153765318903952
Validation loss: 2.376164613333134

Epoch: 5| Step: 3
Training loss: 1.663699759764441
Validation loss: 2.347943651177284

Epoch: 5| Step: 4
Training loss: 1.5924735848288616
Validation loss: 2.3721754952139498

Epoch: 5| Step: 5
Training loss: 1.7521637754839483
Validation loss: 2.35382278338129

Epoch: 5| Step: 6
Training loss: 1.491464729421476
Validation loss: 2.377320648150452

Epoch: 5| Step: 7
Training loss: 1.5945774996833293
Validation loss: 2.358647437031266

Epoch: 5| Step: 8
Training loss: 1.3125925485588072
Validation loss: 2.3520249452476323

Epoch: 5| Step: 9
Training loss: 1.4210119457722605
Validation loss: 2.338036978470215

Epoch: 5| Step: 10
Training loss: 1.1787960903505459
Validation loss: 2.3132496200555552

Epoch: 330| Step: 0
Training loss: 1.2694029288363171
Validation loss: 2.325034251045139

Epoch: 5| Step: 1
Training loss: 1.8672949468749918
Validation loss: 2.3162165699716417

Epoch: 5| Step: 2
Training loss: 1.422952264849658
Validation loss: 2.3502895496698812

Epoch: 5| Step: 3
Training loss: 1.2810533419155772
Validation loss: 2.3225357068478782

Epoch: 5| Step: 4
Training loss: 1.6234591588180904
Validation loss: 2.3688682476203784

Epoch: 5| Step: 5
Training loss: 1.3030577662845477
Validation loss: 2.3838593581071237

Epoch: 5| Step: 6
Training loss: 1.8700181899996495
Validation loss: 2.397384690929245

Epoch: 5| Step: 7
Training loss: 1.1702078595510517
Validation loss: 2.3730066199217705

Epoch: 5| Step: 8
Training loss: 1.4934452208826072
Validation loss: 2.3768646862547493

Epoch: 5| Step: 9
Training loss: 1.478903070880679
Validation loss: 2.376440296926904

Epoch: 5| Step: 10
Training loss: 1.304215168685813
Validation loss: 2.3975215150261535

Epoch: 331| Step: 0
Training loss: 0.8170450804913676
Validation loss: 2.3856222412783246

Epoch: 5| Step: 1
Training loss: 1.541627092970449
Validation loss: 2.379230741094885

Epoch: 5| Step: 2
Training loss: 1.3603346057500467
Validation loss: 2.363009138924426

Epoch: 5| Step: 3
Training loss: 1.0462400304212214
Validation loss: 2.355027936295056

Epoch: 5| Step: 4
Training loss: 1.4855220177712625
Validation loss: 2.36159047848898

Epoch: 5| Step: 5
Training loss: 1.0890690500946316
Validation loss: 2.351096796176899

Epoch: 5| Step: 6
Training loss: 1.547606632336573
Validation loss: 2.3837314005948746

Epoch: 5| Step: 7
Training loss: 1.6473306130608443
Validation loss: 2.3749746484272354

Epoch: 5| Step: 8
Training loss: 1.893038950463461
Validation loss: 2.3646230968496367

Epoch: 5| Step: 9
Training loss: 1.6677791300067901
Validation loss: 2.39207240740519

Epoch: 5| Step: 10
Training loss: 1.7983820690425218
Validation loss: 2.3638250880672693

Epoch: 332| Step: 0
Training loss: 1.2793249229093737
Validation loss: 2.342852434137729

Epoch: 5| Step: 1
Training loss: 1.4765215671254672
Validation loss: 2.3576380140743622

Epoch: 5| Step: 2
Training loss: 1.609970056835866
Validation loss: 2.3671099273968355

Epoch: 5| Step: 3
Training loss: 1.4649820084492355
Validation loss: 2.358460784687899

Epoch: 5| Step: 4
Training loss: 1.474916701470166
Validation loss: 2.3615143069955913

Epoch: 5| Step: 5
Training loss: 1.2382464960558164
Validation loss: 2.3324957485463798

Epoch: 5| Step: 6
Training loss: 1.555721380084227
Validation loss: 2.3553209272879867

Epoch: 5| Step: 7
Training loss: 1.646606802772417
Validation loss: 2.3627437236871525

Epoch: 5| Step: 8
Training loss: 1.7225814422488284
Validation loss: 2.4074237636464186

Epoch: 5| Step: 9
Training loss: 1.2494920175243196
Validation loss: 2.4287022381188548

Epoch: 5| Step: 10
Training loss: 1.4578433803219268
Validation loss: 2.4187685952501616

Epoch: 333| Step: 0
Training loss: 1.1493197834303344
Validation loss: 2.429796310672054

Epoch: 5| Step: 1
Training loss: 1.4888575281727856
Validation loss: 2.4023914774280457

Epoch: 5| Step: 2
Training loss: 1.2718838534410215
Validation loss: 2.367478099308097

Epoch: 5| Step: 3
Training loss: 1.651659523993072
Validation loss: 2.398034006810099

Epoch: 5| Step: 4
Training loss: 0.9471189719656884
Validation loss: 2.3645011360294568

Epoch: 5| Step: 5
Training loss: 1.5313147706326784
Validation loss: 2.3838547155314775

Epoch: 5| Step: 6
Training loss: 1.3725302363193683
Validation loss: 2.3512770785114183

Epoch: 5| Step: 7
Training loss: 1.2588273213493524
Validation loss: 2.34595144160272

Epoch: 5| Step: 8
Training loss: 1.3462581735573587
Validation loss: 2.375456412629747

Epoch: 5| Step: 9
Training loss: 1.933172684879025
Validation loss: 2.3839166878478504

Epoch: 5| Step: 10
Training loss: 1.723278253414168
Validation loss: 2.3935108925278223

Epoch: 334| Step: 0
Training loss: 1.5384390870620195
Validation loss: 2.361928362100494

Epoch: 5| Step: 1
Training loss: 1.7731899811351286
Validation loss: 2.391735728511829

Epoch: 5| Step: 2
Training loss: 1.4149770571732463
Validation loss: 2.3836701591043563

Epoch: 5| Step: 3
Training loss: 0.9615117969850524
Validation loss: 2.370012105979477

Epoch: 5| Step: 4
Training loss: 1.533976560241983
Validation loss: 2.3573470391242464

Epoch: 5| Step: 5
Training loss: 0.8326799970788585
Validation loss: 2.374331402322391

Epoch: 5| Step: 6
Training loss: 1.6792677953792905
Validation loss: 2.356022900011189

Epoch: 5| Step: 7
Training loss: 1.5968264637716933
Validation loss: 2.3767644483908223

Epoch: 5| Step: 8
Training loss: 1.3609063303692368
Validation loss: 2.3731602212140634

Epoch: 5| Step: 9
Training loss: 1.607529554317858
Validation loss: 2.372801888805505

Epoch: 5| Step: 10
Training loss: 1.09577601661232
Validation loss: 2.3973355752320398

Epoch: 335| Step: 0
Training loss: 1.9495621801039835
Validation loss: 2.4105135457922215

Epoch: 5| Step: 1
Training loss: 1.4895824441262462
Validation loss: 2.389558308965616

Epoch: 5| Step: 2
Training loss: 0.7743510236253399
Validation loss: 2.3872065839672922

Epoch: 5| Step: 3
Training loss: 1.191195009609501
Validation loss: 2.380240060603749

Epoch: 5| Step: 4
Training loss: 0.9803379169120457
Validation loss: 2.408498250957403

Epoch: 5| Step: 5
Training loss: 1.3800013356962513
Validation loss: 2.39245111064276

Epoch: 5| Step: 6
Training loss: 1.2813595515611111
Validation loss: 2.4031022589904607

Epoch: 5| Step: 7
Training loss: 1.5328887422753348
Validation loss: 2.4072120617311183

Epoch: 5| Step: 8
Training loss: 1.4434873862275341
Validation loss: 2.401652632734917

Epoch: 5| Step: 9
Training loss: 1.4589537345395767
Validation loss: 2.39646912030767

Epoch: 5| Step: 10
Training loss: 1.7916893477076223
Validation loss: 2.4058300547336966

Epoch: 336| Step: 0
Training loss: 1.472519359752802
Validation loss: 2.385287823609468

Epoch: 5| Step: 1
Training loss: 1.450499921975566
Validation loss: 2.3649952287471243

Epoch: 5| Step: 2
Training loss: 1.27560282836067
Validation loss: 2.3993620292253723

Epoch: 5| Step: 3
Training loss: 1.642334692081431
Validation loss: 2.39019573791198

Epoch: 5| Step: 4
Training loss: 1.413301969411114
Validation loss: 2.422026899313159

Epoch: 5| Step: 5
Training loss: 1.3994105699047048
Validation loss: 2.4429580952954253

Epoch: 5| Step: 6
Training loss: 1.1538429465004776
Validation loss: 2.4414822432309284

Epoch: 5| Step: 7
Training loss: 1.5030825254026394
Validation loss: 2.4267261116725565

Epoch: 5| Step: 8
Training loss: 0.8742879627091572
Validation loss: 2.435062238030036

Epoch: 5| Step: 9
Training loss: 1.7519046092040418
Validation loss: 2.402276142435274

Epoch: 5| Step: 10
Training loss: 1.4832067610641086
Validation loss: 2.4016610084554086

Epoch: 337| Step: 0
Training loss: 1.4336876279771924
Validation loss: 2.3572959222944987

Epoch: 5| Step: 1
Training loss: 1.3331320680269065
Validation loss: 2.3511189007022177

Epoch: 5| Step: 2
Training loss: 1.502204943357848
Validation loss: 2.3453642232408907

Epoch: 5| Step: 3
Training loss: 1.6218011622443664
Validation loss: 2.3638235496601157

Epoch: 5| Step: 4
Training loss: 1.4833833293132865
Validation loss: 2.3442536368742015

Epoch: 5| Step: 5
Training loss: 1.1443389626896137
Validation loss: 2.36827936789737

Epoch: 5| Step: 6
Training loss: 1.4571590418678118
Validation loss: 2.358229145589602

Epoch: 5| Step: 7
Training loss: 1.4733494915371053
Validation loss: 2.389884022647181

Epoch: 5| Step: 8
Training loss: 1.1285698729430198
Validation loss: 2.4217759338716642

Epoch: 5| Step: 9
Training loss: 0.9832801785623098
Validation loss: 2.408810642761609

Epoch: 5| Step: 10
Training loss: 1.8595493138773107
Validation loss: 2.3988503063488142

Epoch: 338| Step: 0
Training loss: 1.3434080975286073
Validation loss: 2.4173498786235075

Epoch: 5| Step: 1
Training loss: 1.56445754451818
Validation loss: 2.4087803990255563

Epoch: 5| Step: 2
Training loss: 1.7188834398661799
Validation loss: 2.3915347703898697

Epoch: 5| Step: 3
Training loss: 1.1815037167265068
Validation loss: 2.373970517799375

Epoch: 5| Step: 4
Training loss: 1.2270301850514787
Validation loss: 2.35640701606815

Epoch: 5| Step: 5
Training loss: 0.9092275113189905
Validation loss: 2.336255541817556

Epoch: 5| Step: 6
Training loss: 1.317149328943506
Validation loss: 2.3547360247813054

Epoch: 5| Step: 7
Training loss: 1.8280004475215306
Validation loss: 2.3656097149792337

Epoch: 5| Step: 8
Training loss: 1.7120424647902626
Validation loss: 2.3479621243911795

Epoch: 5| Step: 9
Training loss: 1.0067873331616677
Validation loss: 2.3558437066863815

Epoch: 5| Step: 10
Training loss: 1.4879774849941814
Validation loss: 2.36891777497899

Epoch: 339| Step: 0
Training loss: 1.3224789603710467
Validation loss: 2.3654954141523423

Epoch: 5| Step: 1
Training loss: 1.3922181165691652
Validation loss: 2.3686624033551387

Epoch: 5| Step: 2
Training loss: 1.302314381763153
Validation loss: 2.392051216119063

Epoch: 5| Step: 3
Training loss: 1.3979020612079704
Validation loss: 2.372745614066955

Epoch: 5| Step: 4
Training loss: 1.6859042782201619
Validation loss: 2.3873016465728543

Epoch: 5| Step: 5
Training loss: 1.2119970792728898
Validation loss: 2.3898935117771245

Epoch: 5| Step: 6
Training loss: 1.0938808362907777
Validation loss: 2.385340914607348

Epoch: 5| Step: 7
Training loss: 1.610060906768635
Validation loss: 2.3893603640014707

Epoch: 5| Step: 8
Training loss: 1.0017428707347975
Validation loss: 2.373354802353708

Epoch: 5| Step: 9
Training loss: 1.8444998557922356
Validation loss: 2.3810751630764355

Epoch: 5| Step: 10
Training loss: 1.1857320273298184
Validation loss: 2.405232605825236

Epoch: 340| Step: 0
Training loss: 1.473193488036157
Validation loss: 2.398492867852587

Epoch: 5| Step: 1
Training loss: 1.0154882485683163
Validation loss: 2.4353855060290024

Epoch: 5| Step: 2
Training loss: 1.4287264569496296
Validation loss: 2.4341665854687853

Epoch: 5| Step: 3
Training loss: 1.3789738970797125
Validation loss: 2.447195818210015

Epoch: 5| Step: 4
Training loss: 1.3812334344483292
Validation loss: 2.4088522726426773

Epoch: 5| Step: 5
Training loss: 1.5196556687595442
Validation loss: 2.4003420044308914

Epoch: 5| Step: 6
Training loss: 1.4457898975337562
Validation loss: 2.371492300909926

Epoch: 5| Step: 7
Training loss: 1.3464990927675111
Validation loss: 2.336769508138597

Epoch: 5| Step: 8
Training loss: 1.2049191955920484
Validation loss: 2.3592672276549553

Epoch: 5| Step: 9
Training loss: 1.4568917460810855
Validation loss: 2.3384651394283216

Epoch: 5| Step: 10
Training loss: 1.7236375154857935
Validation loss: 2.3383730112630774

Epoch: 341| Step: 0
Training loss: 1.9828591151127561
Validation loss: 2.355059339494497

Epoch: 5| Step: 1
Training loss: 1.2672693379007185
Validation loss: 2.3542008934251735

Epoch: 5| Step: 2
Training loss: 1.1730013711178207
Validation loss: 2.3651277031954607

Epoch: 5| Step: 3
Training loss: 1.0071364508370022
Validation loss: 2.375336672284864

Epoch: 5| Step: 4
Training loss: 1.5361704497385777
Validation loss: 2.3837204135293506

Epoch: 5| Step: 5
Training loss: 1.5150331737801714
Validation loss: 2.395269460429025

Epoch: 5| Step: 6
Training loss: 1.3600543725140029
Validation loss: 2.3937459840207773

Epoch: 5| Step: 7
Training loss: 1.0381621855817025
Validation loss: 2.3862109461653276

Epoch: 5| Step: 8
Training loss: 1.618839617866459
Validation loss: 2.3855369481302566

Epoch: 5| Step: 9
Training loss: 1.2410969775668317
Validation loss: 2.372452203716146

Epoch: 5| Step: 10
Training loss: 1.2076891738681794
Validation loss: 2.3551512095187617

Epoch: 342| Step: 0
Training loss: 1.3994765018181747
Validation loss: 2.3508793550573954

Epoch: 5| Step: 1
Training loss: 1.5414779994407997
Validation loss: 2.342152364515828

Epoch: 5| Step: 2
Training loss: 1.4558059408270774
Validation loss: 2.3262606176518745

Epoch: 5| Step: 3
Training loss: 1.2614171757219574
Validation loss: 2.3322207457922803

Epoch: 5| Step: 4
Training loss: 1.2883390303794637
Validation loss: 2.3567258428180438

Epoch: 5| Step: 5
Training loss: 0.9253205066297144
Validation loss: 2.334726589694683

Epoch: 5| Step: 6
Training loss: 1.5271337808739218
Validation loss: 2.3660723445054606

Epoch: 5| Step: 7
Training loss: 1.3014596996948502
Validation loss: 2.350763598056249

Epoch: 5| Step: 8
Training loss: 1.4641573912851986
Validation loss: 2.4019023984397965

Epoch: 5| Step: 9
Training loss: 1.3542829268017527
Validation loss: 2.4413531727261293

Epoch: 5| Step: 10
Training loss: 1.320121299848996
Validation loss: 2.4411826710041455

Epoch: 343| Step: 0
Training loss: 1.6125720961665817
Validation loss: 2.449977227608058

Epoch: 5| Step: 1
Training loss: 1.4254877493822653
Validation loss: 2.440551076703879

Epoch: 5| Step: 2
Training loss: 1.216685429302101
Validation loss: 2.4697506985649746

Epoch: 5| Step: 3
Training loss: 1.5404600198244718
Validation loss: 2.451396157629653

Epoch: 5| Step: 4
Training loss: 1.2147961573462431
Validation loss: 2.4318678295295557

Epoch: 5| Step: 5
Training loss: 1.5659975198796732
Validation loss: 2.3800410218192263

Epoch: 5| Step: 6
Training loss: 1.203082492622416
Validation loss: 2.407302910546815

Epoch: 5| Step: 7
Training loss: 1.22312153016048
Validation loss: 2.3894810516976883

Epoch: 5| Step: 8
Training loss: 0.9578643909231727
Validation loss: 2.394981692673178

Epoch: 5| Step: 9
Training loss: 1.517755957043688
Validation loss: 2.3765418008656916

Epoch: 5| Step: 10
Training loss: 1.2852979773200182
Validation loss: 2.3726220653466403

Epoch: 344| Step: 0
Training loss: 1.3721268285874864
Validation loss: 2.3836427616237907

Epoch: 5| Step: 1
Training loss: 1.5383133977395234
Validation loss: 2.3739619671695515

Epoch: 5| Step: 2
Training loss: 1.6610316223864092
Validation loss: 2.39509104339836

Epoch: 5| Step: 3
Training loss: 1.5958954077750125
Validation loss: 2.4116321647155776

Epoch: 5| Step: 4
Training loss: 0.9876440957119202
Validation loss: 2.3962772569818935

Epoch: 5| Step: 5
Training loss: 1.248672257028161
Validation loss: 2.413245304689426

Epoch: 5| Step: 6
Training loss: 0.935334502068748
Validation loss: 2.4070513652977836

Epoch: 5| Step: 7
Training loss: 1.2860114779694294
Validation loss: 2.4094435168046373

Epoch: 5| Step: 8
Training loss: 1.4636412707698332
Validation loss: 2.4148338108607508

Epoch: 5| Step: 9
Training loss: 0.9701409966941903
Validation loss: 2.423719646653437

Epoch: 5| Step: 10
Training loss: 1.3211160505635762
Validation loss: 2.4167397203920618

Epoch: 345| Step: 0
Training loss: 1.3545186783469783
Validation loss: 2.4082948891611857

Epoch: 5| Step: 1
Training loss: 1.1573434247592878
Validation loss: 2.3800757335237352

Epoch: 5| Step: 2
Training loss: 1.4906046196206095
Validation loss: 2.3827084636116247

Epoch: 5| Step: 3
Training loss: 1.3486226473017067
Validation loss: 2.3697754497079124

Epoch: 5| Step: 4
Training loss: 1.5838875135352375
Validation loss: 2.3444473246495945

Epoch: 5| Step: 5
Training loss: 1.0206826676232188
Validation loss: 2.37429668977755

Epoch: 5| Step: 6
Training loss: 1.0037108353590445
Validation loss: 2.3698918785336374

Epoch: 5| Step: 7
Training loss: 1.536629317085559
Validation loss: 2.372416475464056

Epoch: 5| Step: 8
Training loss: 1.2944499402936873
Validation loss: 2.3874864129988413

Epoch: 5| Step: 9
Training loss: 1.3047259662005857
Validation loss: 2.4050475968992813

Epoch: 5| Step: 10
Training loss: 1.3374022991825247
Validation loss: 2.4118707518983977

Epoch: 346| Step: 0
Training loss: 1.571680336761625
Validation loss: 2.427766994024571

Epoch: 5| Step: 1
Training loss: 1.2096102916899087
Validation loss: 2.4060745782597546

Epoch: 5| Step: 2
Training loss: 1.39071937840838
Validation loss: 2.3549697682948536

Epoch: 5| Step: 3
Training loss: 1.2411814520310254
Validation loss: 2.364549891839051

Epoch: 5| Step: 4
Training loss: 1.7122746646512121
Validation loss: 2.3503627516323586

Epoch: 5| Step: 5
Training loss: 0.7231020815159251
Validation loss: 2.340046327286781

Epoch: 5| Step: 6
Training loss: 1.2611652494751688
Validation loss: 2.3376751857158578

Epoch: 5| Step: 7
Training loss: 1.3972731703377748
Validation loss: 2.3487108469151763

Epoch: 5| Step: 8
Training loss: 0.9818705230746806
Validation loss: 2.356241799338623

Epoch: 5| Step: 9
Training loss: 1.5597465668738482
Validation loss: 2.353364182790339

Epoch: 5| Step: 10
Training loss: 0.903209617636945
Validation loss: 2.374134020261947

Epoch: 347| Step: 0
Training loss: 1.6236870670236532
Validation loss: 2.358571979178605

Epoch: 5| Step: 1
Training loss: 1.6989727675313788
Validation loss: 2.358941126645049

Epoch: 5| Step: 2
Training loss: 0.8934158300685201
Validation loss: 2.3914979706336723

Epoch: 5| Step: 3
Training loss: 0.8963766594295438
Validation loss: 2.3805917823368095

Epoch: 5| Step: 4
Training loss: 0.9481774729401625
Validation loss: 2.353210215358858

Epoch: 5| Step: 5
Training loss: 1.2840058995999666
Validation loss: 2.3699187999989966

Epoch: 5| Step: 6
Training loss: 1.2220753029941953
Validation loss: 2.3800160136967645

Epoch: 5| Step: 7
Training loss: 1.2816650369697464
Validation loss: 2.3828615503290735

Epoch: 5| Step: 8
Training loss: 1.2355062877876344
Validation loss: 2.368958206673764

Epoch: 5| Step: 9
Training loss: 1.4717648183479362
Validation loss: 2.3603687384436802

Epoch: 5| Step: 10
Training loss: 1.4144536104493781
Validation loss: 2.3732720767216198

Epoch: 348| Step: 0
Training loss: 1.4304984872457325
Validation loss: 2.358874992680593

Epoch: 5| Step: 1
Training loss: 1.567263703856354
Validation loss: 2.3547560505527025

Epoch: 5| Step: 2
Training loss: 0.9579862539682946
Validation loss: 2.337608204999453

Epoch: 5| Step: 3
Training loss: 1.4166334185719134
Validation loss: 2.3310188900294206

Epoch: 5| Step: 4
Training loss: 1.3537492646755147
Validation loss: 2.360750572776048

Epoch: 5| Step: 5
Training loss: 1.25654082846198
Validation loss: 2.344813612373764

Epoch: 5| Step: 6
Training loss: 1.3504327009960302
Validation loss: 2.3295125703096136

Epoch: 5| Step: 7
Training loss: 1.0787079382306834
Validation loss: 2.334403341670695

Epoch: 5| Step: 8
Training loss: 0.9745909358480055
Validation loss: 2.304790972678851

Epoch: 5| Step: 9
Training loss: 1.5951025963913814
Validation loss: 2.346616315547373

Epoch: 5| Step: 10
Training loss: 1.0160808420571268
Validation loss: 2.3621480154466075

Epoch: 349| Step: 0
Training loss: 1.1962584697937753
Validation loss: 2.366014158728141

Epoch: 5| Step: 1
Training loss: 1.6452708268933398
Validation loss: 2.3983390734198227

Epoch: 5| Step: 2
Training loss: 1.3735801995869283
Validation loss: 2.3817484819578816

Epoch: 5| Step: 3
Training loss: 1.1801622458625967
Validation loss: 2.4317103438240424

Epoch: 5| Step: 4
Training loss: 0.9821421109233845
Validation loss: 2.4372119139082424

Epoch: 5| Step: 5
Training loss: 1.3962355598789014
Validation loss: 2.4582225592280134

Epoch: 5| Step: 6
Training loss: 1.06976850287083
Validation loss: 2.416007756910875

Epoch: 5| Step: 7
Training loss: 1.3266610548165894
Validation loss: 2.408500872076861

Epoch: 5| Step: 8
Training loss: 1.22716245131723
Validation loss: 2.4061627350202683

Epoch: 5| Step: 9
Training loss: 1.238787815198137
Validation loss: 2.412970134640161

Epoch: 5| Step: 10
Training loss: 1.3165016932087235
Validation loss: 2.3989344197630906

Epoch: 350| Step: 0
Training loss: 0.9396166431136066
Validation loss: 2.4297140364207914

Epoch: 5| Step: 1
Training loss: 1.4331251828658949
Validation loss: 2.403958073303705

Epoch: 5| Step: 2
Training loss: 1.0287439355868466
Validation loss: 2.398042598824565

Epoch: 5| Step: 3
Training loss: 1.0999669091709336
Validation loss: 2.413971278997933

Epoch: 5| Step: 4
Training loss: 1.5709291831942809
Validation loss: 2.4463194157513164

Epoch: 5| Step: 5
Training loss: 1.2256588857149775
Validation loss: 2.4103877706145793

Epoch: 5| Step: 6
Training loss: 1.1583399571199644
Validation loss: 2.430023057288833

Epoch: 5| Step: 7
Training loss: 1.795601302142233
Validation loss: 2.4048593852612

Epoch: 5| Step: 8
Training loss: 1.2392176989112123
Validation loss: 2.3897557140257515

Epoch: 5| Step: 9
Training loss: 1.0751453634053805
Validation loss: 2.379770591192879

Epoch: 5| Step: 10
Training loss: 0.9566765887103672
Validation loss: 2.37216851271769

Epoch: 351| Step: 0
Training loss: 1.0207884772170561
Validation loss: 2.3559676292878584

Epoch: 5| Step: 1
Training loss: 1.1454919422087708
Validation loss: 2.33631493398729

Epoch: 5| Step: 2
Training loss: 1.4368357574958088
Validation loss: 2.3547561594234527

Epoch: 5| Step: 3
Training loss: 1.233004859837393
Validation loss: 2.35704437084382

Epoch: 5| Step: 4
Training loss: 1.34174845467925
Validation loss: 2.3665019795516073

Epoch: 5| Step: 5
Training loss: 1.2570082184060858
Validation loss: 2.3564917926375735

Epoch: 5| Step: 6
Training loss: 1.3020102620284404
Validation loss: 2.3421295667816446

Epoch: 5| Step: 7
Training loss: 1.0843026458610854
Validation loss: 2.3899533098067267

Epoch: 5| Step: 8
Training loss: 0.9685379842282144
Validation loss: 2.403373237693771

Epoch: 5| Step: 9
Training loss: 1.5486838043820308
Validation loss: 2.434760909822213

Epoch: 5| Step: 10
Training loss: 1.3284937627126927
Validation loss: 2.4540316242280027

Epoch: 352| Step: 0
Training loss: 1.4598475995932199
Validation loss: 2.469491416595182

Epoch: 5| Step: 1
Training loss: 0.8829310852344853
Validation loss: 2.4084098944118972

Epoch: 5| Step: 2
Training loss: 1.2641265852895682
Validation loss: 2.4155681505196993

Epoch: 5| Step: 3
Training loss: 1.004735819127796
Validation loss: 2.3964664405638216

Epoch: 5| Step: 4
Training loss: 0.9823837727918137
Validation loss: 2.4067384133339216

Epoch: 5| Step: 5
Training loss: 1.602257480093783
Validation loss: 2.3785679510632813

Epoch: 5| Step: 6
Training loss: 1.3362073123918508
Validation loss: 2.404206346584015

Epoch: 5| Step: 7
Training loss: 1.210596738061019
Validation loss: 2.3664581757562257

Epoch: 5| Step: 8
Training loss: 1.431819972192655
Validation loss: 2.3753743203238322

Epoch: 5| Step: 9
Training loss: 1.2789892394602667
Validation loss: 2.390002292960274

Epoch: 5| Step: 10
Training loss: 0.9295519241083281
Validation loss: 2.411483033812372

Epoch: 353| Step: 0
Training loss: 1.777972703254315
Validation loss: 2.383074892613257

Epoch: 5| Step: 1
Training loss: 0.9879254390424144
Validation loss: 2.3886429507537876

Epoch: 5| Step: 2
Training loss: 0.9962879365616647
Validation loss: 2.4131152274404335

Epoch: 5| Step: 3
Training loss: 1.28397869669393
Validation loss: 2.3942315349109857

Epoch: 5| Step: 4
Training loss: 1.0947900459333209
Validation loss: 2.4208361411121184

Epoch: 5| Step: 5
Training loss: 1.2518558553678267
Validation loss: 2.386810288626501

Epoch: 5| Step: 6
Training loss: 1.1580621077068347
Validation loss: 2.397826524955005

Epoch: 5| Step: 7
Training loss: 1.1681812820224187
Validation loss: 2.396724526259454

Epoch: 5| Step: 8
Training loss: 1.2647382667481344
Validation loss: 2.3798063399225327

Epoch: 5| Step: 9
Training loss: 1.2586270650554419
Validation loss: 2.392185738427597

Epoch: 5| Step: 10
Training loss: 1.063656009775697
Validation loss: 2.3880353168022346

Epoch: 354| Step: 0
Training loss: 0.9338411139139633
Validation loss: 2.3960908873497235

Epoch: 5| Step: 1
Training loss: 0.9337063645632014
Validation loss: 2.3960950290308154

Epoch: 5| Step: 2
Training loss: 1.2995947389549594
Validation loss: 2.427618119301616

Epoch: 5| Step: 3
Training loss: 1.6332282308251451
Validation loss: 2.440292268849092

Epoch: 5| Step: 4
Training loss: 1.583300121695223
Validation loss: 2.4271456218276994

Epoch: 5| Step: 5
Training loss: 0.9831668766752455
Validation loss: 2.4320468121030308

Epoch: 5| Step: 6
Training loss: 1.3103305962238887
Validation loss: 2.444665460400438

Epoch: 5| Step: 7
Training loss: 1.0761334365654045
Validation loss: 2.429816467451928

Epoch: 5| Step: 8
Training loss: 1.0135735554136596
Validation loss: 2.4141497831345253

Epoch: 5| Step: 9
Training loss: 1.23206364039367
Validation loss: 2.4055805657462517

Epoch: 5| Step: 10
Training loss: 1.1803207213762108
Validation loss: 2.4122023998076902

Epoch: 355| Step: 0
Training loss: 1.2225472398613588
Validation loss: 2.396151643146322

Epoch: 5| Step: 1
Training loss: 1.5268243164944422
Validation loss: 2.395311505458403

Epoch: 5| Step: 2
Training loss: 0.9394943957869671
Validation loss: 2.3877860556937787

Epoch: 5| Step: 3
Training loss: 1.1555511321437568
Validation loss: 2.3951485302981834

Epoch: 5| Step: 4
Training loss: 0.8593266213411164
Validation loss: 2.4060185617716243

Epoch: 5| Step: 5
Training loss: 1.2720371339823782
Validation loss: 2.4343081543516747

Epoch: 5| Step: 6
Training loss: 1.0615871659479765
Validation loss: 2.4393805765940426

Epoch: 5| Step: 7
Training loss: 1.1167252658063043
Validation loss: 2.4545697650753087

Epoch: 5| Step: 8
Training loss: 1.7235158561816017
Validation loss: 2.445708639733405

Epoch: 5| Step: 9
Training loss: 1.2628090697319567
Validation loss: 2.442802421789792

Epoch: 5| Step: 10
Training loss: 1.127431520044491
Validation loss: 2.3952556322008576

Epoch: 356| Step: 0
Training loss: 1.0725700905044853
Validation loss: 2.3356240721044323

Epoch: 5| Step: 1
Training loss: 1.5816821808183097
Validation loss: 2.328151573067491

Epoch: 5| Step: 2
Training loss: 1.2527277271557073
Validation loss: 2.353859360747589

Epoch: 5| Step: 3
Training loss: 1.2854575873507315
Validation loss: 2.3446196678359685

Epoch: 5| Step: 4
Training loss: 1.2133794466013637
Validation loss: 2.3171963937352915

Epoch: 5| Step: 5
Training loss: 1.2808277550854863
Validation loss: 2.300007008826771

Epoch: 5| Step: 6
Training loss: 1.0892817097395961
Validation loss: 2.329755070510157

Epoch: 5| Step: 7
Training loss: 1.3816532944391462
Validation loss: 2.348602673631384

Epoch: 5| Step: 8
Training loss: 1.1963240886932283
Validation loss: 2.3889727490307022

Epoch: 5| Step: 9
Training loss: 0.925860824062368
Validation loss: 2.411310644328571

Epoch: 5| Step: 10
Training loss: 1.1203769957892684
Validation loss: 2.4083273893273676

Epoch: 357| Step: 0
Training loss: 1.1840461898570367
Validation loss: 2.39983238293748

Epoch: 5| Step: 1
Training loss: 0.8340447647421636
Validation loss: 2.4235997182751436

Epoch: 5| Step: 2
Training loss: 1.0872347650782863
Validation loss: 2.4133716726706593

Epoch: 5| Step: 3
Training loss: 0.9817098839793738
Validation loss: 2.4161003186086107

Epoch: 5| Step: 4
Training loss: 1.3184887631819564
Validation loss: 2.407798455310181

Epoch: 5| Step: 5
Training loss: 1.5493596476986453
Validation loss: 2.4250320134334866

Epoch: 5| Step: 6
Training loss: 1.1656944049697988
Validation loss: 2.429328069132145

Epoch: 5| Step: 7
Training loss: 0.8699446142039916
Validation loss: 2.4144052958423514

Epoch: 5| Step: 8
Training loss: 1.2524116140767054
Validation loss: 2.4144475948124415

Epoch: 5| Step: 9
Training loss: 1.336985617506779
Validation loss: 2.4111231007410283

Epoch: 5| Step: 10
Training loss: 1.4250815150721097
Validation loss: 2.413406586152555

Epoch: 358| Step: 0
Training loss: 1.2407708396998518
Validation loss: 2.3896958198645466

Epoch: 5| Step: 1
Training loss: 1.0477146937420665
Validation loss: 2.368701142366144

Epoch: 5| Step: 2
Training loss: 0.9383079544066031
Validation loss: 2.3434145101437847

Epoch: 5| Step: 3
Training loss: 1.2735057414673931
Validation loss: 2.3619204484247507

Epoch: 5| Step: 4
Training loss: 1.0301701643108376
Validation loss: 2.373634919178573

Epoch: 5| Step: 5
Training loss: 1.665233289739303
Validation loss: 2.399104478912551

Epoch: 5| Step: 6
Training loss: 1.1454895486375696
Validation loss: 2.4123260766050287

Epoch: 5| Step: 7
Training loss: 1.1424472831734174
Validation loss: 2.384748678523522

Epoch: 5| Step: 8
Training loss: 0.7807984000554069
Validation loss: 2.418439913270735

Epoch: 5| Step: 9
Training loss: 1.326277850808712
Validation loss: 2.406819340535406

Epoch: 5| Step: 10
Training loss: 1.2441333429192303
Validation loss: 2.3879091483592787

Epoch: 359| Step: 0
Training loss: 0.9943546147297966
Validation loss: 2.403546917498686

Epoch: 5| Step: 1
Training loss: 1.2139302342461626
Validation loss: 2.401232290216143

Epoch: 5| Step: 2
Training loss: 1.0236072545098978
Validation loss: 2.3849093470052507

Epoch: 5| Step: 3
Training loss: 1.098703177000143
Validation loss: 2.3605917558670586

Epoch: 5| Step: 4
Training loss: 1.5179801025594366
Validation loss: 2.3595666696827218

Epoch: 5| Step: 5
Training loss: 1.4887668087872779
Validation loss: 2.3718892684283186

Epoch: 5| Step: 6
Training loss: 1.0830367611592595
Validation loss: 2.3347904304000697

Epoch: 5| Step: 7
Training loss: 0.9369622913740169
Validation loss: 2.370998037015794

Epoch: 5| Step: 8
Training loss: 0.9204086344172597
Validation loss: 2.388610564841705

Epoch: 5| Step: 9
Training loss: 1.163910516635563
Validation loss: 2.386642618913481

Epoch: 5| Step: 10
Training loss: 1.4078782721427847
Validation loss: 2.4061465614692974

Epoch: 360| Step: 0
Training loss: 0.8725512503734957
Validation loss: 2.4137824711471243

Epoch: 5| Step: 1
Training loss: 0.9303062047159142
Validation loss: 2.4438215979748206

Epoch: 5| Step: 2
Training loss: 1.298315787549797
Validation loss: 2.4474174997702614

Epoch: 5| Step: 3
Training loss: 1.30851636059933
Validation loss: 2.468740013333931

Epoch: 5| Step: 4
Training loss: 0.8106951842149364
Validation loss: 2.4614449280813533

Epoch: 5| Step: 5
Training loss: 1.071607822228475
Validation loss: 2.4588046111443416

Epoch: 5| Step: 6
Training loss: 1.5895591687340147
Validation loss: 2.4550904373621316

Epoch: 5| Step: 7
Training loss: 1.2903487752747422
Validation loss: 2.442688473772641

Epoch: 5| Step: 8
Training loss: 0.8647372020779097
Validation loss: 2.427940360639713

Epoch: 5| Step: 9
Training loss: 1.551971055989889
Validation loss: 2.383025361493118

Epoch: 5| Step: 10
Training loss: 0.9471837273814887
Validation loss: 2.367647691406689

Epoch: 361| Step: 0
Training loss: 1.166887937861242
Validation loss: 2.3592031234683204

Epoch: 5| Step: 1
Training loss: 1.208032384204675
Validation loss: 2.35711704979683

Epoch: 5| Step: 2
Training loss: 0.8870243100594849
Validation loss: 2.3758734347500328

Epoch: 5| Step: 3
Training loss: 1.165745740676157
Validation loss: 2.3671133053512534

Epoch: 5| Step: 4
Training loss: 1.6554216436693274
Validation loss: 2.383954520850148

Epoch: 5| Step: 5
Training loss: 1.2845144785491587
Validation loss: 2.421033373093642

Epoch: 5| Step: 6
Training loss: 0.9841863057768888
Validation loss: 2.4395866008428517

Epoch: 5| Step: 7
Training loss: 1.338099732033469
Validation loss: 2.450561464166894

Epoch: 5| Step: 8
Training loss: 0.793660956366882
Validation loss: 2.485799170587322

Epoch: 5| Step: 9
Training loss: 1.0248044618315872
Validation loss: 2.459520841187646

Epoch: 5| Step: 10
Training loss: 1.0892583443823507
Validation loss: 2.447430017220698

Epoch: 362| Step: 0
Training loss: 1.343592656704391
Validation loss: 2.3901736150809416

Epoch: 5| Step: 1
Training loss: 0.9284028225087886
Validation loss: 2.402213279875547

Epoch: 5| Step: 2
Training loss: 1.5934168149447532
Validation loss: 2.398914621721926

Epoch: 5| Step: 3
Training loss: 0.9934414426539958
Validation loss: 2.4043802690210074

Epoch: 5| Step: 4
Training loss: 1.248320022804047
Validation loss: 2.396020820062253

Epoch: 5| Step: 5
Training loss: 0.985394298280774
Validation loss: 2.3986270866086326

Epoch: 5| Step: 6
Training loss: 1.2668772024729271
Validation loss: 2.3964281172245454

Epoch: 5| Step: 7
Training loss: 1.1619239979837124
Validation loss: 2.3893079824898233

Epoch: 5| Step: 8
Training loss: 0.573387894316832
Validation loss: 2.4169468994803354

Epoch: 5| Step: 9
Training loss: 1.075894134737804
Validation loss: 2.39299659161746

Epoch: 5| Step: 10
Training loss: 1.1451065648559084
Validation loss: 2.3784037984054867

Epoch: 363| Step: 0
Training loss: 1.23152594790147
Validation loss: 2.3927966200790456

Epoch: 5| Step: 1
Training loss: 1.3067199500485631
Validation loss: 2.3765007495418926

Epoch: 5| Step: 2
Training loss: 1.542701562853305
Validation loss: 2.357378131943764

Epoch: 5| Step: 3
Training loss: 0.7010344474235605
Validation loss: 2.3952154817234317

Epoch: 5| Step: 4
Training loss: 1.2794546248457521
Validation loss: 2.4195635723665525

Epoch: 5| Step: 5
Training loss: 0.97527313563665
Validation loss: 2.413662041582384

Epoch: 5| Step: 6
Training loss: 1.1375495522573698
Validation loss: 2.412915955337148

Epoch: 5| Step: 7
Training loss: 1.0413682064997394
Validation loss: 2.4217930510301917

Epoch: 5| Step: 8
Training loss: 0.7265992924388335
Validation loss: 2.4277962494004135

Epoch: 5| Step: 9
Training loss: 1.141915049067221
Validation loss: 2.430846644568118

Epoch: 5| Step: 10
Training loss: 1.1883940092078955
Validation loss: 2.4469973225215442

Epoch: 364| Step: 0
Training loss: 1.02810205822425
Validation loss: 2.4263047924575902

Epoch: 5| Step: 1
Training loss: 1.076119478753684
Validation loss: 2.415139736072557

Epoch: 5| Step: 2
Training loss: 0.9755719463578515
Validation loss: 2.4081218136789273

Epoch: 5| Step: 3
Training loss: 1.1263780630720082
Validation loss: 2.4228438509905645

Epoch: 5| Step: 4
Training loss: 1.2041150762908788
Validation loss: 2.419100402284742

Epoch: 5| Step: 5
Training loss: 1.0662906011116209
Validation loss: 2.386190081001441

Epoch: 5| Step: 6
Training loss: 1.6099182989584562
Validation loss: 2.3992831189229067

Epoch: 5| Step: 7
Training loss: 1.1191836044287184
Validation loss: 2.4295784982156534

Epoch: 5| Step: 8
Training loss: 1.1646212062694064
Validation loss: 2.425208650080039

Epoch: 5| Step: 9
Training loss: 0.7847367109988511
Validation loss: 2.4152390393709204

Epoch: 5| Step: 10
Training loss: 1.0965919085842615
Validation loss: 2.443351029427651

Epoch: 365| Step: 0
Training loss: 1.062895196458322
Validation loss: 2.4341877555549396

Epoch: 5| Step: 1
Training loss: 0.7505630525410182
Validation loss: 2.4175426315687143

Epoch: 5| Step: 2
Training loss: 1.0673219431337482
Validation loss: 2.4179076875665877

Epoch: 5| Step: 3
Training loss: 0.7034792961132311
Validation loss: 2.4090543997749148

Epoch: 5| Step: 4
Training loss: 1.1031849053302492
Validation loss: 2.4021675698218026

Epoch: 5| Step: 5
Training loss: 1.1072767051530512
Validation loss: 2.4046212948759274

Epoch: 5| Step: 6
Training loss: 1.1080171038343796
Validation loss: 2.3852012233558963

Epoch: 5| Step: 7
Training loss: 1.2901040233395862
Validation loss: 2.3973035142120303

Epoch: 5| Step: 8
Training loss: 0.7754951233676682
Validation loss: 2.3951415933676303

Epoch: 5| Step: 9
Training loss: 1.3308042541142384
Validation loss: 2.4147015270163985

Epoch: 5| Step: 10
Training loss: 1.6980895752032101
Validation loss: 2.437129577054694

Epoch: 366| Step: 0
Training loss: 1.0583736289355514
Validation loss: 2.40448327709477

Epoch: 5| Step: 1
Training loss: 1.0397247269263064
Validation loss: 2.4264683802387

Epoch: 5| Step: 2
Training loss: 1.0368561803801044
Validation loss: 2.397334896181493

Epoch: 5| Step: 3
Training loss: 1.4710566487143881
Validation loss: 2.4300255565497038

Epoch: 5| Step: 4
Training loss: 0.817302449239769
Validation loss: 2.4230188934591195

Epoch: 5| Step: 5
Training loss: 0.7796087955358401
Validation loss: 2.435885559175302

Epoch: 5| Step: 6
Training loss: 1.543472246519239
Validation loss: 2.42760403391573

Epoch: 5| Step: 7
Training loss: 1.1701154596465293
Validation loss: 2.4072404774477048

Epoch: 5| Step: 8
Training loss: 1.076908364955264
Validation loss: 2.407692078521851

Epoch: 5| Step: 9
Training loss: 1.048406875094853
Validation loss: 2.4080628394298595

Epoch: 5| Step: 10
Training loss: 0.8371975395281305
Validation loss: 2.384901800896315

Epoch: 367| Step: 0
Training loss: 1.5480226825264722
Validation loss: 2.4260059377006886

Epoch: 5| Step: 1
Training loss: 0.9063822222311302
Validation loss: 2.423308401300994

Epoch: 5| Step: 2
Training loss: 0.9761375112846766
Validation loss: 2.4147300637480393

Epoch: 5| Step: 3
Training loss: 1.138476713281642
Validation loss: 2.4180384622612383

Epoch: 5| Step: 4
Training loss: 1.120624829625778
Validation loss: 2.4193240605724355

Epoch: 5| Step: 5
Training loss: 1.4369582108889976
Validation loss: 2.4576739752594197

Epoch: 5| Step: 6
Training loss: 0.9356025886272321
Validation loss: 2.4616156822549784

Epoch: 5| Step: 7
Training loss: 1.021390308841035
Validation loss: 2.4623810383085645

Epoch: 5| Step: 8
Training loss: 1.1362992918697676
Validation loss: 2.4427815488505873

Epoch: 5| Step: 9
Training loss: 0.6298215614523278
Validation loss: 2.408664323708686

Epoch: 5| Step: 10
Training loss: 1.1461780665299772
Validation loss: 2.36860267608953

Epoch: 368| Step: 0
Training loss: 1.2596223025151592
Validation loss: 2.3576779351407278

Epoch: 5| Step: 1
Training loss: 1.215196024854561
Validation loss: 2.3494596090835858

Epoch: 5| Step: 2
Training loss: 0.938887205598916
Validation loss: 2.35883660962374

Epoch: 5| Step: 3
Training loss: 1.152551768002911
Validation loss: 2.382847840524325

Epoch: 5| Step: 4
Training loss: 1.1061276470561756
Validation loss: 2.3883002050418574

Epoch: 5| Step: 5
Training loss: 1.0035943166394736
Validation loss: 2.3802750386645437

Epoch: 5| Step: 6
Training loss: 0.8956768579370543
Validation loss: 2.426031262175872

Epoch: 5| Step: 7
Training loss: 1.1539320522515089
Validation loss: 2.4131812267738733

Epoch: 5| Step: 8
Training loss: 0.8331608872006829
Validation loss: 2.449801840521114

Epoch: 5| Step: 9
Training loss: 0.7675116124346363
Validation loss: 2.428788331223172

Epoch: 5| Step: 10
Training loss: 1.5581187812812671
Validation loss: 2.438700272903934

Epoch: 369| Step: 0
Training loss: 1.0450575125532888
Validation loss: 2.4146704344518786

Epoch: 5| Step: 1
Training loss: 0.5957563032584396
Validation loss: 2.405721963669995

Epoch: 5| Step: 2
Training loss: 0.8688361502545084
Validation loss: 2.4292260364740925

Epoch: 5| Step: 3
Training loss: 1.1103729272831866
Validation loss: 2.3960162042608117

Epoch: 5| Step: 4
Training loss: 1.3625388323648426
Validation loss: 2.3982802605360205

Epoch: 5| Step: 5
Training loss: 1.4020092493505838
Validation loss: 2.370646864935986

Epoch: 5| Step: 6
Training loss: 1.2964983473596952
Validation loss: 2.3949149493377653

Epoch: 5| Step: 7
Training loss: 1.0544635676262362
Validation loss: 2.4055842530847373

Epoch: 5| Step: 8
Training loss: 1.2398042188182175
Validation loss: 2.425018603354281

Epoch: 5| Step: 9
Training loss: 0.7125107262456518
Validation loss: 2.4384982891641656

Epoch: 5| Step: 10
Training loss: 0.7786318587428078
Validation loss: 2.4508461547250193

Epoch: 370| Step: 0
Training loss: 1.3476568249687406
Validation loss: 2.4407902763767275

Epoch: 5| Step: 1
Training loss: 0.8208340394715758
Validation loss: 2.4477301476572415

Epoch: 5| Step: 2
Training loss: 0.83107953869323
Validation loss: 2.427901328255297

Epoch: 5| Step: 3
Training loss: 0.801146075253187
Validation loss: 2.453341058951426

Epoch: 5| Step: 4
Training loss: 1.0666987538478572
Validation loss: 2.42406400210869

Epoch: 5| Step: 5
Training loss: 1.476523262592502
Validation loss: 2.4323802237201475

Epoch: 5| Step: 6
Training loss: 0.9783231199425679
Validation loss: 2.4032398675148112

Epoch: 5| Step: 7
Training loss: 0.7632709045646131
Validation loss: 2.382466763960111

Epoch: 5| Step: 8
Training loss: 0.9298140816305527
Validation loss: 2.385017920991482

Epoch: 5| Step: 9
Training loss: 1.3526622289221628
Validation loss: 2.3847088112584625

Epoch: 5| Step: 10
Training loss: 1.172120793315006
Validation loss: 2.3910995367378347

Epoch: 371| Step: 0
Training loss: 1.3189543561203123
Validation loss: 2.395472366583584

Epoch: 5| Step: 1
Training loss: 1.0491887046392108
Validation loss: 2.3782727614296677

Epoch: 5| Step: 2
Training loss: 0.8885553639926248
Validation loss: 2.417929605417006

Epoch: 5| Step: 3
Training loss: 0.8968628394070065
Validation loss: 2.379140813793476

Epoch: 5| Step: 4
Training loss: 0.7421583471093909
Validation loss: 2.405849200204065

Epoch: 5| Step: 5
Training loss: 0.9853272751687313
Validation loss: 2.4150461938597485

Epoch: 5| Step: 6
Training loss: 1.0289856876419659
Validation loss: 2.3969666984106937

Epoch: 5| Step: 7
Training loss: 0.9804235805122327
Validation loss: 2.410649557721001

Epoch: 5| Step: 8
Training loss: 1.5912400471150556
Validation loss: 2.4142452045673006

Epoch: 5| Step: 9
Training loss: 0.7782624150164245
Validation loss: 2.4116915055854746

Epoch: 5| Step: 10
Training loss: 1.101963646536613
Validation loss: 2.391658007769842

Epoch: 372| Step: 0
Training loss: 0.9504286978323998
Validation loss: 2.3945695544493746

Epoch: 5| Step: 1
Training loss: 0.6227450222549978
Validation loss: 2.388011563638113

Epoch: 5| Step: 2
Training loss: 1.0250992424534622
Validation loss: 2.383142555438316

Epoch: 5| Step: 3
Training loss: 1.029738850680694
Validation loss: 2.4136798004537585

Epoch: 5| Step: 4
Training loss: 1.0129371876575202
Validation loss: 2.4087256965645945

Epoch: 5| Step: 5
Training loss: 1.2142410009630706
Validation loss: 2.4171331596840764

Epoch: 5| Step: 6
Training loss: 1.4736520653459846
Validation loss: 2.4523848125024656

Epoch: 5| Step: 7
Training loss: 0.8061815484138736
Validation loss: 2.432152614864209

Epoch: 5| Step: 8
Training loss: 0.9884626501009187
Validation loss: 2.4330362635323866

Epoch: 5| Step: 9
Training loss: 1.1634195075230729
Validation loss: 2.423881424209135

Epoch: 5| Step: 10
Training loss: 1.0718666543441047
Validation loss: 2.3985249434364926

Epoch: 373| Step: 0
Training loss: 0.938266694958923
Validation loss: 2.405855991710584

Epoch: 5| Step: 1
Training loss: 1.285499132788895
Validation loss: 2.4132914482760115

Epoch: 5| Step: 2
Training loss: 0.8994263224641142
Validation loss: 2.4493765857577117

Epoch: 5| Step: 3
Training loss: 0.6490424218559618
Validation loss: 2.436700945000147

Epoch: 5| Step: 4
Training loss: 1.0335745765712665
Validation loss: 2.4296288392373824

Epoch: 5| Step: 5
Training loss: 0.4961712694051774
Validation loss: 2.432859065052618

Epoch: 5| Step: 6
Training loss: 1.0230978482231694
Validation loss: 2.444077709271873

Epoch: 5| Step: 7
Training loss: 1.398850449269684
Validation loss: 2.464633070223245

Epoch: 5| Step: 8
Training loss: 1.5590753791110434
Validation loss: 2.46665040451552

Epoch: 5| Step: 9
Training loss: 0.8719464905117896
Validation loss: 2.4492143354640894

Epoch: 5| Step: 10
Training loss: 0.972283012139646
Validation loss: 2.416238488726289

Epoch: 374| Step: 0
Training loss: 0.8828774824954154
Validation loss: 2.3871782444365834

Epoch: 5| Step: 1
Training loss: 0.9840811639047359
Validation loss: 2.380356947956486

Epoch: 5| Step: 2
Training loss: 0.9548387910180091
Validation loss: 2.390233488152956

Epoch: 5| Step: 3
Training loss: 0.940451173150688
Validation loss: 2.4045921701405044

Epoch: 5| Step: 4
Training loss: 1.2004245324998732
Validation loss: 2.3972543727899933

Epoch: 5| Step: 5
Training loss: 0.8514836826071395
Validation loss: 2.3940370764372303

Epoch: 5| Step: 6
Training loss: 1.0484789048502672
Validation loss: 2.4300067281585567

Epoch: 5| Step: 7
Training loss: 1.013876304519335
Validation loss: 2.4427914648045506

Epoch: 5| Step: 8
Training loss: 0.8726522419973214
Validation loss: 2.4591519275728886

Epoch: 5| Step: 9
Training loss: 1.6222320604606637
Validation loss: 2.438733730246649

Epoch: 5| Step: 10
Training loss: 1.1011470254649778
Validation loss: 2.4356710378611384

Epoch: 375| Step: 0
Training loss: 1.1825640640486348
Validation loss: 2.420430313876369

Epoch: 5| Step: 1
Training loss: 0.9830705082676504
Validation loss: 2.4085077433878523

Epoch: 5| Step: 2
Training loss: 0.775558876212965
Validation loss: 2.4233295630984415

Epoch: 5| Step: 3
Training loss: 0.7271799314832077
Validation loss: 2.4275547713835817

Epoch: 5| Step: 4
Training loss: 1.0217603963346815
Validation loss: 2.4321339526177224

Epoch: 5| Step: 5
Training loss: 0.9639048776726578
Validation loss: 2.46272346211834

Epoch: 5| Step: 6
Training loss: 1.2504104417245334
Validation loss: 2.4473677509136857

Epoch: 5| Step: 7
Training loss: 1.1830307531124258
Validation loss: 2.4648713224305556

Epoch: 5| Step: 8
Training loss: 1.372025002379638
Validation loss: 2.465085486581438

Epoch: 5| Step: 9
Training loss: 0.6556480917123267
Validation loss: 2.459147727378169

Epoch: 5| Step: 10
Training loss: 1.0269578564325557
Validation loss: 2.4532631246769503

Epoch: 376| Step: 0
Training loss: 0.6566523499267493
Validation loss: 2.409461509990453

Epoch: 5| Step: 1
Training loss: 1.444690714937132
Validation loss: 2.4200558523236317

Epoch: 5| Step: 2
Training loss: 1.3709113714312084
Validation loss: 2.3941165633446557

Epoch: 5| Step: 3
Training loss: 0.8623119453306184
Validation loss: 2.4223741538978665

Epoch: 5| Step: 4
Training loss: 0.8150827732061506
Validation loss: 2.397974772708069

Epoch: 5| Step: 5
Training loss: 0.965705517618613
Validation loss: 2.4129848255111614

Epoch: 5| Step: 6
Training loss: 0.8272888352681795
Validation loss: 2.4280442728834877

Epoch: 5| Step: 7
Training loss: 0.8743968315207582
Validation loss: 2.394552610978193

Epoch: 5| Step: 8
Training loss: 1.1009314603095768
Validation loss: 2.380234300526463

Epoch: 5| Step: 9
Training loss: 1.0703468595683845
Validation loss: 2.3803769789655327

Epoch: 5| Step: 10
Training loss: 1.061052008897456
Validation loss: 2.383943884310788

Epoch: 377| Step: 0
Training loss: 1.014866354839604
Validation loss: 2.417339526894929

Epoch: 5| Step: 1
Training loss: 1.3557184962193334
Validation loss: 2.415396400726134

Epoch: 5| Step: 2
Training loss: 1.178238439790158
Validation loss: 2.4349670269893564

Epoch: 5| Step: 3
Training loss: 0.9976537419155441
Validation loss: 2.4267170539153895

Epoch: 5| Step: 4
Training loss: 0.7529966965282466
Validation loss: 2.4702627382021234

Epoch: 5| Step: 5
Training loss: 1.1578460194295537
Validation loss: 2.429901265582238

Epoch: 5| Step: 6
Training loss: 0.9178265075861568
Validation loss: 2.4486386390175565

Epoch: 5| Step: 7
Training loss: 0.7238198886655953
Validation loss: 2.436164939436497

Epoch: 5| Step: 8
Training loss: 1.110866833034081
Validation loss: 2.456119369117984

Epoch: 5| Step: 9
Training loss: 0.9004964373262326
Validation loss: 2.4229369144036124

Epoch: 5| Step: 10
Training loss: 0.8738312067651953
Validation loss: 2.411205935451448

Epoch: 378| Step: 0
Training loss: 0.8625452347655479
Validation loss: 2.3952772703458334

Epoch: 5| Step: 1
Training loss: 0.8796241710355907
Validation loss: 2.3953773424846423

Epoch: 5| Step: 2
Training loss: 1.0317944332211468
Validation loss: 2.416846647515974

Epoch: 5| Step: 3
Training loss: 0.837921142022391
Validation loss: 2.4106640463201203

Epoch: 5| Step: 4
Training loss: 0.6322694968328091
Validation loss: 2.4026027291406233

Epoch: 5| Step: 5
Training loss: 0.9814006130990103
Validation loss: 2.4008147540175515

Epoch: 5| Step: 6
Training loss: 1.446751388641424
Validation loss: 2.3996102481256787

Epoch: 5| Step: 7
Training loss: 0.6085627595701719
Validation loss: 2.4020297828665282

Epoch: 5| Step: 8
Training loss: 1.075734459795131
Validation loss: 2.432852782022398

Epoch: 5| Step: 9
Training loss: 1.398198709399414
Validation loss: 2.4258638748048442

Epoch: 5| Step: 10
Training loss: 1.0012233522943341
Validation loss: 2.4306807996023445

Epoch: 379| Step: 0
Training loss: 0.7623638453633098
Validation loss: 2.4486439822011117

Epoch: 5| Step: 1
Training loss: 0.8337219683096996
Validation loss: 2.4253009224622235

Epoch: 5| Step: 2
Training loss: 1.1691473178436167
Validation loss: 2.4247071774110274

Epoch: 5| Step: 3
Training loss: 0.8646648246017086
Validation loss: 2.4150295500952796

Epoch: 5| Step: 4
Training loss: 0.859202038092034
Validation loss: 2.4146312470156412

Epoch: 5| Step: 5
Training loss: 1.0983409443033463
Validation loss: 2.3806755339978265

Epoch: 5| Step: 6
Training loss: 1.4279108734206283
Validation loss: 2.412612094365205

Epoch: 5| Step: 7
Training loss: 0.8556535773733087
Validation loss: 2.3814597370365043

Epoch: 5| Step: 8
Training loss: 0.8033652692068672
Validation loss: 2.3802252155594816

Epoch: 5| Step: 9
Training loss: 1.068324226205684
Validation loss: 2.3890122854508675

Epoch: 5| Step: 10
Training loss: 1.1021572157979873
Validation loss: 2.403293998273425

Epoch: 380| Step: 0
Training loss: 0.6437793854608251
Validation loss: 2.3901105849120974

Epoch: 5| Step: 1
Training loss: 0.7023750120001047
Validation loss: 2.4056358944123453

Epoch: 5| Step: 2
Training loss: 1.018987225487087
Validation loss: 2.434958287314909

Epoch: 5| Step: 3
Training loss: 1.0560479326351382
Validation loss: 2.436398448940402

Epoch: 5| Step: 4
Training loss: 0.8761133535827189
Validation loss: 2.413169895201782

Epoch: 5| Step: 5
Training loss: 1.0155133699544652
Validation loss: 2.4073726579850514

Epoch: 5| Step: 6
Training loss: 1.327344507999664
Validation loss: 2.4049777100781364

Epoch: 5| Step: 7
Training loss: 0.914716633240531
Validation loss: 2.4257306970229084

Epoch: 5| Step: 8
Training loss: 0.9396613637716601
Validation loss: 2.410686421910174

Epoch: 5| Step: 9
Training loss: 1.3703399933826603
Validation loss: 2.419261362293552

Epoch: 5| Step: 10
Training loss: 0.730376334642728
Validation loss: 2.4088031598216944

Epoch: 381| Step: 0
Training loss: 0.6784162581468758
Validation loss: 2.408434544902726

Epoch: 5| Step: 1
Training loss: 1.038821429058699
Validation loss: 2.3964212332078434

Epoch: 5| Step: 2
Training loss: 0.6761606287117394
Validation loss: 2.389359832896044

Epoch: 5| Step: 3
Training loss: 1.3790045424919748
Validation loss: 2.4150419350031997

Epoch: 5| Step: 4
Training loss: 1.0717684456492818
Validation loss: 2.4019595072578084

Epoch: 5| Step: 5
Training loss: 0.999492128866937
Validation loss: 2.426862121863755

Epoch: 5| Step: 6
Training loss: 1.1084652246191864
Validation loss: 2.435720868794298

Epoch: 5| Step: 7
Training loss: 1.0162896549047031
Validation loss: 2.4838475968846607

Epoch: 5| Step: 8
Training loss: 0.7041202283440573
Validation loss: 2.450218707144844

Epoch: 5| Step: 9
Training loss: 1.0072968812562288
Validation loss: 2.474554736922111

Epoch: 5| Step: 10
Training loss: 0.9641597655457909
Validation loss: 2.4539381092701085

Epoch: 382| Step: 0
Training loss: 0.6817073625395579
Validation loss: 2.4555699104735598

Epoch: 5| Step: 1
Training loss: 1.090122857125714
Validation loss: 2.429917939361609

Epoch: 5| Step: 2
Training loss: 0.8772905206200995
Validation loss: 2.4235044144564633

Epoch: 5| Step: 3
Training loss: 0.7613511983820818
Validation loss: 2.410800886120603

Epoch: 5| Step: 4
Training loss: 0.9595144636446594
Validation loss: 2.3705271736460456

Epoch: 5| Step: 5
Training loss: 0.7493163012501148
Validation loss: 2.399265409492798

Epoch: 5| Step: 6
Training loss: 1.0178172586509582
Validation loss: 2.4098792746051165

Epoch: 5| Step: 7
Training loss: 0.7694637055937559
Validation loss: 2.3980370108649427

Epoch: 5| Step: 8
Training loss: 1.602090739153283
Validation loss: 2.42391706600652

Epoch: 5| Step: 9
Training loss: 0.9284405720909341
Validation loss: 2.4288073585242764

Epoch: 5| Step: 10
Training loss: 0.9715130687076102
Validation loss: 2.4406248287422345

Epoch: 383| Step: 0
Training loss: 0.8117864116118831
Validation loss: 2.423642334887407

Epoch: 5| Step: 1
Training loss: 1.0525543115516032
Validation loss: 2.4553249399955086

Epoch: 5| Step: 2
Training loss: 0.9821209000944556
Validation loss: 2.396415024203634

Epoch: 5| Step: 3
Training loss: 1.1632201456042564
Validation loss: 2.433986519075853

Epoch: 5| Step: 4
Training loss: 0.7259292714395259
Validation loss: 2.42953979235243

Epoch: 5| Step: 5
Training loss: 0.8190551203832271
Validation loss: 2.429172244009536

Epoch: 5| Step: 6
Training loss: 0.952591699956983
Validation loss: 2.4134112589848504

Epoch: 5| Step: 7
Training loss: 0.6896327922021958
Validation loss: 2.3812423576094757

Epoch: 5| Step: 8
Training loss: 0.902009877451083
Validation loss: 2.4030557586600056

Epoch: 5| Step: 9
Training loss: 1.375015822232852
Validation loss: 2.419009872542671

Epoch: 5| Step: 10
Training loss: 0.9794462122828795
Validation loss: 2.3922792866770424

Epoch: 384| Step: 0
Training loss: 0.8406882365099232
Validation loss: 2.4098684205824337

Epoch: 5| Step: 1
Training loss: 0.7062576445444307
Validation loss: 2.410398893510336

Epoch: 5| Step: 2
Training loss: 1.0111229515663287
Validation loss: 2.412241260579317

Epoch: 5| Step: 3
Training loss: 1.0608486919285158
Validation loss: 2.424238668835179

Epoch: 5| Step: 4
Training loss: 0.6481207338154097
Validation loss: 2.4297524720395605

Epoch: 5| Step: 5
Training loss: 1.5172457337130123
Validation loss: 2.4239656896306947

Epoch: 5| Step: 6
Training loss: 0.6811855294405338
Validation loss: 2.4161435449683717

Epoch: 5| Step: 7
Training loss: 0.9066862503267183
Validation loss: 2.402379708129789

Epoch: 5| Step: 8
Training loss: 1.0074839093269905
Validation loss: 2.420847911754462

Epoch: 5| Step: 9
Training loss: 0.5058322148046219
Validation loss: 2.413069314211717

Epoch: 5| Step: 10
Training loss: 1.2848585995754611
Validation loss: 2.440681208493908

Epoch: 385| Step: 0
Training loss: 0.5065590574417003
Validation loss: 2.429625245368919

Epoch: 5| Step: 1
Training loss: 0.995957728055721
Validation loss: 2.4152942640711452

Epoch: 5| Step: 2
Training loss: 1.2785970622885348
Validation loss: 2.417598396946785

Epoch: 5| Step: 3
Training loss: 0.6426542984821304
Validation loss: 2.428502966100301

Epoch: 5| Step: 4
Training loss: 0.8746368131299126
Validation loss: 2.4285503166620557

Epoch: 5| Step: 5
Training loss: 1.3575737518312114
Validation loss: 2.411977077783693

Epoch: 5| Step: 6
Training loss: 0.8323019241127434
Validation loss: 2.4221491896289136

Epoch: 5| Step: 7
Training loss: 0.9846575498006063
Validation loss: 2.383599040512171

Epoch: 5| Step: 8
Training loss: 0.7456918003187524
Validation loss: 2.4144888652448384

Epoch: 5| Step: 9
Training loss: 0.8644258669810387
Validation loss: 2.3891145654508747

Epoch: 5| Step: 10
Training loss: 1.1060977938842569
Validation loss: 2.406664119776832

Epoch: 386| Step: 0
Training loss: 0.7625096836413224
Validation loss: 2.39975915806163

Epoch: 5| Step: 1
Training loss: 0.8395830326379533
Validation loss: 2.4492116490567777

Epoch: 5| Step: 2
Training loss: 0.6539139267483363
Validation loss: 2.4131219990285855

Epoch: 5| Step: 3
Training loss: 0.8905899977916689
Validation loss: 2.4449782253288688

Epoch: 5| Step: 4
Training loss: 0.618861812545819
Validation loss: 2.4321518063982097

Epoch: 5| Step: 5
Training loss: 0.7404495771911885
Validation loss: 2.43962004130156

Epoch: 5| Step: 6
Training loss: 0.8888876516777277
Validation loss: 2.445668587968644

Epoch: 5| Step: 7
Training loss: 1.6599701182422024
Validation loss: 2.4324719041929503

Epoch: 5| Step: 8
Training loss: 0.7860809498614678
Validation loss: 2.421762534344283

Epoch: 5| Step: 9
Training loss: 1.0282606667286023
Validation loss: 2.4064039988913835

Epoch: 5| Step: 10
Training loss: 1.152705817804442
Validation loss: 2.392652566106249

Epoch: 387| Step: 0
Training loss: 0.9502382180543074
Validation loss: 2.396220007925102

Epoch: 5| Step: 1
Training loss: 0.8134243182456292
Validation loss: 2.3912035521960395

Epoch: 5| Step: 2
Training loss: 0.8572842567899226
Validation loss: 2.4181525005378233

Epoch: 5| Step: 3
Training loss: 1.0506209353992961
Validation loss: 2.4316981608329753

Epoch: 5| Step: 4
Training loss: 1.0810412894558477
Validation loss: 2.430406232857642

Epoch: 5| Step: 5
Training loss: 0.9558618992131822
Validation loss: 2.4201330170143054

Epoch: 5| Step: 6
Training loss: 0.7352489384627632
Validation loss: 2.4877373480572618

Epoch: 5| Step: 7
Training loss: 1.6554801159225947
Validation loss: 2.4528147674564655

Epoch: 5| Step: 8
Training loss: 0.42482287488567594
Validation loss: 2.443345827332803

Epoch: 5| Step: 9
Training loss: 0.49275271946327415
Validation loss: 2.4777349748609576

Epoch: 5| Step: 10
Training loss: 0.7971028768799302
Validation loss: 2.449006925998022

Epoch: 388| Step: 0
Training loss: 0.879513374020904
Validation loss: 2.450049458051188

Epoch: 5| Step: 1
Training loss: 1.4810962806484456
Validation loss: 2.418446184453348

Epoch: 5| Step: 2
Training loss: 0.8951802793537988
Validation loss: 2.4420340275702923

Epoch: 5| Step: 3
Training loss: 1.0943120329828262
Validation loss: 2.4293777990677388

Epoch: 5| Step: 4
Training loss: 0.6019665240678486
Validation loss: 2.452572636741168

Epoch: 5| Step: 5
Training loss: 0.8594837466706485
Validation loss: 2.4234783537693443

Epoch: 5| Step: 6
Training loss: 0.7018143412125685
Validation loss: 2.4372106863705967

Epoch: 5| Step: 7
Training loss: 0.946599069054551
Validation loss: 2.448726616581189

Epoch: 5| Step: 8
Training loss: 0.7884457888112701
Validation loss: 2.433910125386655

Epoch: 5| Step: 9
Training loss: 1.07288152519872
Validation loss: 2.4531991515151934

Epoch: 5| Step: 10
Training loss: 0.6767908613934508
Validation loss: 2.40934144328383

Epoch: 389| Step: 0
Training loss: 0.8913760448423474
Validation loss: 2.388502226883868

Epoch: 5| Step: 1
Training loss: 0.6921719336212484
Validation loss: 2.4033915419276255

Epoch: 5| Step: 2
Training loss: 0.8360616288763394
Validation loss: 2.429362037558451

Epoch: 5| Step: 3
Training loss: 1.0654309742165409
Validation loss: 2.430210529533496

Epoch: 5| Step: 4
Training loss: 1.5408129347253334
Validation loss: 2.4156484587593074

Epoch: 5| Step: 5
Training loss: 1.1721750002555336
Validation loss: 2.4577820668880364

Epoch: 5| Step: 6
Training loss: 0.6578747300820266
Validation loss: 2.4384292795801836

Epoch: 5| Step: 7
Training loss: 0.6710903109905336
Validation loss: 2.4224894315490197

Epoch: 5| Step: 8
Training loss: 0.8374556543936321
Validation loss: 2.4317611182806207

Epoch: 5| Step: 9
Training loss: 0.6569278032329207
Validation loss: 2.454104303620976

Epoch: 5| Step: 10
Training loss: 0.7580760222336113
Validation loss: 2.452533682791672

Epoch: 390| Step: 0
Training loss: 1.014217810353414
Validation loss: 2.437293651587614

Epoch: 5| Step: 1
Training loss: 0.7337148418159143
Validation loss: 2.453570142960701

Epoch: 5| Step: 2
Training loss: 0.732295724813215
Validation loss: 2.466138324599858

Epoch: 5| Step: 3
Training loss: 0.7969063771372183
Validation loss: 2.460656698691843

Epoch: 5| Step: 4
Training loss: 1.0523155384204508
Validation loss: 2.4291279962381798

Epoch: 5| Step: 5
Training loss: 0.937194074942843
Validation loss: 2.441143423457875

Epoch: 5| Step: 6
Training loss: 0.909188767335585
Validation loss: 2.4105147502336153

Epoch: 5| Step: 7
Training loss: 0.5054979837681135
Validation loss: 2.3956578415581475

Epoch: 5| Step: 8
Training loss: 0.9322253617447386
Validation loss: 2.396249785393875

Epoch: 5| Step: 9
Training loss: 0.9456777261177628
Validation loss: 2.4012993698800242

Epoch: 5| Step: 10
Training loss: 1.4562549312655408
Validation loss: 2.3994476824717115

Epoch: 391| Step: 0
Training loss: 0.7716979684790861
Validation loss: 2.4420681079507927

Epoch: 5| Step: 1
Training loss: 0.88547108800851
Validation loss: 2.428042234044163

Epoch: 5| Step: 2
Training loss: 0.7970902395339734
Validation loss: 2.450186684690702

Epoch: 5| Step: 3
Training loss: 1.0603408191788017
Validation loss: 2.4828896917290963

Epoch: 5| Step: 4
Training loss: 0.653785847616488
Validation loss: 2.432408329082699

Epoch: 5| Step: 5
Training loss: 1.0686000294897584
Validation loss: 2.444874303003231

Epoch: 5| Step: 6
Training loss: 0.6645944820612935
Validation loss: 2.463069677953779

Epoch: 5| Step: 7
Training loss: 0.8995970499483913
Validation loss: 2.4230070307331437

Epoch: 5| Step: 8
Training loss: 0.7821523033450065
Validation loss: 2.456486607087265

Epoch: 5| Step: 9
Training loss: 0.7305233776861058
Validation loss: 2.4208681816936557

Epoch: 5| Step: 10
Training loss: 1.5901597667294238
Validation loss: 2.4605178050621928

Epoch: 392| Step: 0
Training loss: 1.3686312218954149
Validation loss: 2.4210460100146522

Epoch: 5| Step: 1
Training loss: 0.8003936573900128
Validation loss: 2.4611977195637893

Epoch: 5| Step: 2
Training loss: 0.8571889991204771
Validation loss: 2.485770467908806

Epoch: 5| Step: 3
Training loss: 0.9769731497437798
Validation loss: 2.4913597145316504

Epoch: 5| Step: 4
Training loss: 0.5442444613941086
Validation loss: 2.490815147832185

Epoch: 5| Step: 5
Training loss: 0.7913115901388914
Validation loss: 2.4655535466908955

Epoch: 5| Step: 6
Training loss: 0.7281184200267878
Validation loss: 2.4248055639655206

Epoch: 5| Step: 7
Training loss: 1.1028184156726697
Validation loss: 2.4415494639404653

Epoch: 5| Step: 8
Training loss: 0.7941289973123091
Validation loss: 2.4094739862936176

Epoch: 5| Step: 9
Training loss: 0.8650499065423153
Validation loss: 2.3847945274731517

Epoch: 5| Step: 10
Training loss: 1.1354145026696725
Validation loss: 2.413003469056535

Epoch: 393| Step: 0
Training loss: 0.813189617348611
Validation loss: 2.4274651145580672

Epoch: 5| Step: 1
Training loss: 0.873970720629984
Validation loss: 2.4676831807656634

Epoch: 5| Step: 2
Training loss: 0.6295112164326035
Validation loss: 2.4571222423144126

Epoch: 5| Step: 3
Training loss: 0.89413133368908
Validation loss: 2.5127455717724714

Epoch: 5| Step: 4
Training loss: 1.0172963402056336
Validation loss: 2.496979956627355

Epoch: 5| Step: 5
Training loss: 1.0621207065125116
Validation loss: 2.5195623244715697

Epoch: 5| Step: 6
Training loss: 0.6800696077202371
Validation loss: 2.5029613578058667

Epoch: 5| Step: 7
Training loss: 1.4566053325360095
Validation loss: 2.4685198176947494

Epoch: 5| Step: 8
Training loss: 0.8720811798341289
Validation loss: 2.443498416813276

Epoch: 5| Step: 9
Training loss: 0.8365032385098187
Validation loss: 2.4458283456208316

Epoch: 5| Step: 10
Training loss: 0.6572458794349652
Validation loss: 2.385222319653925

Epoch: 394| Step: 0
Training loss: 0.7253244989233463
Validation loss: 2.3735210107592364

Epoch: 5| Step: 1
Training loss: 0.9213928642937272
Validation loss: 2.3684044496540437

Epoch: 5| Step: 2
Training loss: 0.6326866495710259
Validation loss: 2.385254753719645

Epoch: 5| Step: 3
Training loss: 0.8555309673659577
Validation loss: 2.417484707933972

Epoch: 5| Step: 4
Training loss: 0.7860771206859954
Validation loss: 2.439218700315025

Epoch: 5| Step: 5
Training loss: 0.7397199468744402
Validation loss: 2.4928439719671585

Epoch: 5| Step: 6
Training loss: 0.9992580939951222
Validation loss: 2.4928321875041877

Epoch: 5| Step: 7
Training loss: 1.4020889178198384
Validation loss: 2.5271931128022884

Epoch: 5| Step: 8
Training loss: 1.085941342134334
Validation loss: 2.5052602873118794

Epoch: 5| Step: 9
Training loss: 0.9692535629797331
Validation loss: 2.510718889663979

Epoch: 5| Step: 10
Training loss: 0.7815387954991353
Validation loss: 2.5100966368576536

Epoch: 395| Step: 0
Training loss: 0.5209916605309424
Validation loss: 2.4905725704457455

Epoch: 5| Step: 1
Training loss: 1.0907384556560067
Validation loss: 2.471473658714824

Epoch: 5| Step: 2
Training loss: 0.7317479809940741
Validation loss: 2.4611456243115297

Epoch: 5| Step: 3
Training loss: 0.9894740328742755
Validation loss: 2.4361273342630123

Epoch: 5| Step: 4
Training loss: 0.6585582375143664
Validation loss: 2.411018684633459

Epoch: 5| Step: 5
Training loss: 0.7926437012385765
Validation loss: 2.427307416076272

Epoch: 5| Step: 6
Training loss: 0.7705502806588929
Validation loss: 2.416455675135947

Epoch: 5| Step: 7
Training loss: 0.8451741879280926
Validation loss: 2.4090588831140822

Epoch: 5| Step: 8
Training loss: 1.1036834859193394
Validation loss: 2.411070083033883

Epoch: 5| Step: 9
Training loss: 1.3863129357790047
Validation loss: 2.4113030479447386

Epoch: 5| Step: 10
Training loss: 0.8243711068594326
Validation loss: 2.4213037701724573

Epoch: 396| Step: 0
Training loss: 1.0121751735180484
Validation loss: 2.419491318678115

Epoch: 5| Step: 1
Training loss: 1.0575207554469033
Validation loss: 2.4391648786049522

Epoch: 5| Step: 2
Training loss: 0.8709139103700911
Validation loss: 2.415447305312505

Epoch: 5| Step: 3
Training loss: 0.8029575455346505
Validation loss: 2.406972860988258

Epoch: 5| Step: 4
Training loss: 0.8699093965509872
Validation loss: 2.411386559541017

Epoch: 5| Step: 5
Training loss: 0.8832104216539521
Validation loss: 2.3988223982710117

Epoch: 5| Step: 6
Training loss: 0.7870644682007866
Validation loss: 2.4088877717755697

Epoch: 5| Step: 7
Training loss: 0.6643765772659943
Validation loss: 2.4141141235043957

Epoch: 5| Step: 8
Training loss: 0.6079505508667579
Validation loss: 2.4591195987112866

Epoch: 5| Step: 9
Training loss: 0.7965712622919708
Validation loss: 2.425963142805217

Epoch: 5| Step: 10
Training loss: 1.512227921407815
Validation loss: 2.4197305119665904

Epoch: 397| Step: 0
Training loss: 0.8741936715000171
Validation loss: 2.4361575657743826

Epoch: 5| Step: 1
Training loss: 0.8193168046829334
Validation loss: 2.440305735242947

Epoch: 5| Step: 2
Training loss: 0.902162277667198
Validation loss: 2.4621568577422956

Epoch: 5| Step: 3
Training loss: 1.2059144220370603
Validation loss: 2.457290095042954

Epoch: 5| Step: 4
Training loss: 0.751172857338456
Validation loss: 2.401964809658861

Epoch: 5| Step: 5
Training loss: 1.1356524418069789
Validation loss: 2.394697546263609

Epoch: 5| Step: 6
Training loss: 0.6531346032928737
Validation loss: 2.388971571287552

Epoch: 5| Step: 7
Training loss: 0.9969540340460393
Validation loss: 2.364662083629057

Epoch: 5| Step: 8
Training loss: 1.0300830249286486
Validation loss: 2.3676937394100017

Epoch: 5| Step: 9
Training loss: 0.8235130000382475
Validation loss: 2.3603799612815695

Epoch: 5| Step: 10
Training loss: 0.5292108613680101
Validation loss: 2.357816205546122

Epoch: 398| Step: 0
Training loss: 1.0545360880356554
Validation loss: 2.357637921647341

Epoch: 5| Step: 1
Training loss: 1.31492803420199
Validation loss: 2.380321283425636

Epoch: 5| Step: 2
Training loss: 0.7573678983565375
Validation loss: 2.3907688716067903

Epoch: 5| Step: 3
Training loss: 0.755103154367035
Validation loss: 2.383270040070797

Epoch: 5| Step: 4
Training loss: 1.0017545328516089
Validation loss: 2.4223446224300575

Epoch: 5| Step: 5
Training loss: 0.7961441503261846
Validation loss: 2.458097995848672

Epoch: 5| Step: 6
Training loss: 0.89954861474252
Validation loss: 2.4685394604400552

Epoch: 5| Step: 7
Training loss: 0.7864987108252764
Validation loss: 2.457618542372558

Epoch: 5| Step: 8
Training loss: 0.7891808600460202
Validation loss: 2.4636234468547333

Epoch: 5| Step: 9
Training loss: 0.5834648347406262
Validation loss: 2.469619211659592

Epoch: 5| Step: 10
Training loss: 0.6896049829371044
Validation loss: 2.4352081868834725

Epoch: 399| Step: 0
Training loss: 0.600229867970145
Validation loss: 2.4386129896218374

Epoch: 5| Step: 1
Training loss: 0.777815555797933
Validation loss: 2.388802145141973

Epoch: 5| Step: 2
Training loss: 0.7089150134750013
Validation loss: 2.4120340400042286

Epoch: 5| Step: 3
Training loss: 1.2330860699841981
Validation loss: 2.4117240258846073

Epoch: 5| Step: 4
Training loss: 0.9014855799926036
Validation loss: 2.4409483851150715

Epoch: 5| Step: 5
Training loss: 1.0788449081451368
Validation loss: 2.425788355063885

Epoch: 5| Step: 6
Training loss: 0.8568759648869241
Validation loss: 2.391844305866391

Epoch: 5| Step: 7
Training loss: 0.8890597660176858
Validation loss: 2.3950352463479425

Epoch: 5| Step: 8
Training loss: 0.7836866146903754
Validation loss: 2.382867009268844

Epoch: 5| Step: 9
Training loss: 0.8121293763178863
Validation loss: 2.4154515300217763

Epoch: 5| Step: 10
Training loss: 0.6283434843724062
Validation loss: 2.4356184860885453

Epoch: 400| Step: 0
Training loss: 0.8538384776256124
Validation loss: 2.4574153000115118

Epoch: 5| Step: 1
Training loss: 0.912986121612224
Validation loss: 2.4288915216566713

Epoch: 5| Step: 2
Training loss: 0.96192778756666
Validation loss: 2.4084729087097343

Epoch: 5| Step: 3
Training loss: 0.7517913644369276
Validation loss: 2.3920121897090088

Epoch: 5| Step: 4
Training loss: 0.5939090415369118
Validation loss: 2.390441146988317

Epoch: 5| Step: 5
Training loss: 0.6598623851878999
Validation loss: 2.3814514124499597

Epoch: 5| Step: 6
Training loss: 0.7178507445347801
Validation loss: 2.3686964668339385

Epoch: 5| Step: 7
Training loss: 0.7849683014732376
Validation loss: 2.3563935848079947

Epoch: 5| Step: 8
Training loss: 0.5732873642128309
Validation loss: 2.3975955711552377

Epoch: 5| Step: 9
Training loss: 0.9717056961029236
Validation loss: 2.4171713875533976

Epoch: 5| Step: 10
Training loss: 1.458447624450944
Validation loss: 2.389289236668199

Epoch: 401| Step: 0
Training loss: 0.9779241605541154
Validation loss: 2.417549739636921

Epoch: 5| Step: 1
Training loss: 0.6363973215789465
Validation loss: 2.423899526508617

Epoch: 5| Step: 2
Training loss: 0.7794566743541824
Validation loss: 2.4081861156396567

Epoch: 5| Step: 3
Training loss: 0.7029995276502431
Validation loss: 2.4448235156641585

Epoch: 5| Step: 4
Training loss: 0.9312259542957882
Validation loss: 2.4132362356398827

Epoch: 5| Step: 5
Training loss: 1.0502777595074975
Validation loss: 2.432088677760487

Epoch: 5| Step: 6
Training loss: 0.7280839147150281
Validation loss: 2.388984404095848

Epoch: 5| Step: 7
Training loss: 0.9651061407824915
Validation loss: 2.3723061276508868

Epoch: 5| Step: 8
Training loss: 0.4840796092921086
Validation loss: 2.3451646933770913

Epoch: 5| Step: 9
Training loss: 0.7342810875114446
Validation loss: 2.3198380402101146

Epoch: 5| Step: 10
Training loss: 1.3634922771479947
Validation loss: 2.370287550130014

Epoch: 402| Step: 0
Training loss: 0.848590599564148
Validation loss: 2.3947050625750874

Epoch: 5| Step: 1
Training loss: 0.4612798389356119
Validation loss: 2.3988433491307273

Epoch: 5| Step: 2
Training loss: 0.7115808866367731
Validation loss: 2.4065211515799763

Epoch: 5| Step: 3
Training loss: 1.009929946131785
Validation loss: 2.4091055687261838

Epoch: 5| Step: 4
Training loss: 0.5961697611210793
Validation loss: 2.4371123509179258

Epoch: 5| Step: 5
Training loss: 0.8674251814906928
Validation loss: 2.3960381896906284

Epoch: 5| Step: 6
Training loss: 0.9807805329314572
Validation loss: 2.38038490559389

Epoch: 5| Step: 7
Training loss: 0.916054568245766
Validation loss: 2.4128083081528313

Epoch: 5| Step: 8
Training loss: 0.6450475763177073
Validation loss: 2.3701712743215895

Epoch: 5| Step: 9
Training loss: 1.1928933789938903
Validation loss: 2.3965105687704242

Epoch: 5| Step: 10
Training loss: 0.9249676376558272
Validation loss: 2.374138535530686

Epoch: 403| Step: 0
Training loss: 0.6238212198103394
Validation loss: 2.3935973859963107

Epoch: 5| Step: 1
Training loss: 1.0029279045824586
Validation loss: 2.3600099726869983

Epoch: 5| Step: 2
Training loss: 0.6338393275191228
Validation loss: 2.365261131618895

Epoch: 5| Step: 3
Training loss: 0.6591903572631844
Validation loss: 2.4038407274473674

Epoch: 5| Step: 4
Training loss: 0.8656362801378037
Validation loss: 2.373056795521586

Epoch: 5| Step: 5
Training loss: 0.6146469945317905
Validation loss: 2.3823324703398523

Epoch: 5| Step: 6
Training loss: 0.7990859904918544
Validation loss: 2.387455583973269

Epoch: 5| Step: 7
Training loss: 1.0716856897741174
Validation loss: 2.3782971578319776

Epoch: 5| Step: 8
Training loss: 0.8848715880816289
Validation loss: 2.3835394283221114

Epoch: 5| Step: 9
Training loss: 1.0478513918518326
Validation loss: 2.3743385539138497

Epoch: 5| Step: 10
Training loss: 0.8543670388264525
Validation loss: 2.350880489725337

Epoch: 404| Step: 0
Training loss: 0.7760143317885143
Validation loss: 2.3660010956884676

Epoch: 5| Step: 1
Training loss: 1.1744237014067902
Validation loss: 2.406595495356624

Epoch: 5| Step: 2
Training loss: 0.7440721375194913
Validation loss: 2.3816117640802243

Epoch: 5| Step: 3
Training loss: 0.7648951496625301
Validation loss: 2.409067735901953

Epoch: 5| Step: 4
Training loss: 0.8984551137773249
Validation loss: 2.4117443980187074

Epoch: 5| Step: 5
Training loss: 0.8592132416122132
Validation loss: 2.421862325062897

Epoch: 5| Step: 6
Training loss: 0.6360605734688849
Validation loss: 2.4373543324787823

Epoch: 5| Step: 7
Training loss: 0.5410772350499713
Validation loss: 2.4307589242432828

Epoch: 5| Step: 8
Training loss: 0.7936898696831596
Validation loss: 2.429539691581211

Epoch: 5| Step: 9
Training loss: 0.8947367869294448
Validation loss: 2.4414743007568998

Epoch: 5| Step: 10
Training loss: 0.7157228411292869
Validation loss: 2.4333079417521177

Epoch: 405| Step: 0
Training loss: 0.4277219030225432
Validation loss: 2.386033769647737

Epoch: 5| Step: 1
Training loss: 0.9605886865228794
Validation loss: 2.394162828789943

Epoch: 5| Step: 2
Training loss: 0.4808044036506871
Validation loss: 2.37294274969368

Epoch: 5| Step: 3
Training loss: 0.7739589744212669
Validation loss: 2.3605103065129884

Epoch: 5| Step: 4
Training loss: 0.7677809275065527
Validation loss: 2.351981347065399

Epoch: 5| Step: 5
Training loss: 0.7236002761589354
Validation loss: 2.355446254205341

Epoch: 5| Step: 6
Training loss: 0.7748758062711393
Validation loss: 2.3487479688661854

Epoch: 5| Step: 7
Training loss: 0.8661823805581971
Validation loss: 2.330507304845139

Epoch: 5| Step: 8
Training loss: 1.1846173081349047
Validation loss: 2.34412584579558

Epoch: 5| Step: 9
Training loss: 0.8656426493363746
Validation loss: 2.3704269262696487

Epoch: 5| Step: 10
Training loss: 0.8463637874741146
Validation loss: 2.3811057963950693

Epoch: 406| Step: 0
Training loss: 0.6680815305923034
Validation loss: 2.3871820128220866

Epoch: 5| Step: 1
Training loss: 0.8900897442114456
Validation loss: 2.3763939545263093

Epoch: 5| Step: 2
Training loss: 0.7582020495729912
Validation loss: 2.391110750430164

Epoch: 5| Step: 3
Training loss: 0.799391009578298
Validation loss: 2.400344825100166

Epoch: 5| Step: 4
Training loss: 0.6346605888908481
Validation loss: 2.3915535318408683

Epoch: 5| Step: 5
Training loss: 0.7923176916159527
Validation loss: 2.401696413738399

Epoch: 5| Step: 6
Training loss: 0.7481832355087434
Validation loss: 2.4040228225495266

Epoch: 5| Step: 7
Training loss: 1.0368493970178372
Validation loss: 2.413021763984395

Epoch: 5| Step: 8
Training loss: 0.6306844179348237
Validation loss: 2.4023581110133785

Epoch: 5| Step: 9
Training loss: 0.5751464253037022
Validation loss: 2.380333202715724

Epoch: 5| Step: 10
Training loss: 1.204507207181468
Validation loss: 2.3711976516138855

Epoch: 407| Step: 0
Training loss: 0.5886316286946344
Validation loss: 2.3627495969307777

Epoch: 5| Step: 1
Training loss: 0.42320532680063355
Validation loss: 2.353205396837306

Epoch: 5| Step: 2
Training loss: 0.8398888864142785
Validation loss: 2.371126588159271

Epoch: 5| Step: 3
Training loss: 0.8696493995646447
Validation loss: 2.367347842084309

Epoch: 5| Step: 4
Training loss: 0.7702421980341686
Validation loss: 2.3946740004970772

Epoch: 5| Step: 5
Training loss: 1.0843843838948033
Validation loss: 2.394449532221607

Epoch: 5| Step: 6
Training loss: 0.8786600064662943
Validation loss: 2.420751063558404

Epoch: 5| Step: 7
Training loss: 0.9563150957178398
Validation loss: 2.4181085843943397

Epoch: 5| Step: 8
Training loss: 0.8352652725700521
Validation loss: 2.406230196094242

Epoch: 5| Step: 9
Training loss: 0.7547754603713385
Validation loss: 2.4167817029705816

Epoch: 5| Step: 10
Training loss: 0.6263378368384621
Validation loss: 2.3886608859742067

Epoch: 408| Step: 0
Training loss: 0.6537914088685107
Validation loss: 2.351060481148418

Epoch: 5| Step: 1
Training loss: 1.2054050688323557
Validation loss: 2.351270483166235

Epoch: 5| Step: 2
Training loss: 0.6209540539912123
Validation loss: 2.325357014360192

Epoch: 5| Step: 3
Training loss: 0.7923669269521809
Validation loss: 2.3359342558519947

Epoch: 5| Step: 4
Training loss: 0.9342343674276431
Validation loss: 2.3538691595602006

Epoch: 5| Step: 5
Training loss: 0.6225744626883764
Validation loss: 2.3473511477591527

Epoch: 5| Step: 6
Training loss: 0.9579007927927651
Validation loss: 2.3341006494722483

Epoch: 5| Step: 7
Training loss: 0.36685595864266957
Validation loss: 2.3570463068610255

Epoch: 5| Step: 8
Training loss: 0.8894104288514426
Validation loss: 2.3921118925947273

Epoch: 5| Step: 9
Training loss: 0.6329493198129253
Validation loss: 2.3891808833450003

Epoch: 5| Step: 10
Training loss: 0.7544586450683547
Validation loss: 2.41319242496858

Epoch: 409| Step: 0
Training loss: 0.7313692794417003
Validation loss: 2.3886369436966532

Epoch: 5| Step: 1
Training loss: 1.1198929260365666
Validation loss: 2.4110291177286696

Epoch: 5| Step: 2
Training loss: 0.565350330957397
Validation loss: 2.370828758647822

Epoch: 5| Step: 3
Training loss: 0.5031606791859107
Validation loss: 2.383898980944809

Epoch: 5| Step: 4
Training loss: 0.807036369728474
Validation loss: 2.3881334713543967

Epoch: 5| Step: 5
Training loss: 0.91736381564695
Validation loss: 2.390259631908733

Epoch: 5| Step: 6
Training loss: 0.8375373575789148
Validation loss: 2.3781831703468392

Epoch: 5| Step: 7
Training loss: 0.5042409450680656
Validation loss: 2.379972630977056

Epoch: 5| Step: 8
Training loss: 0.6549017771754585
Validation loss: 2.392398027410191

Epoch: 5| Step: 9
Training loss: 0.9166933005249496
Validation loss: 2.391856285634286

Epoch: 5| Step: 10
Training loss: 0.8575152995799387
Validation loss: 2.3867770593820947

Epoch: 410| Step: 0
Training loss: 0.8783872640352627
Validation loss: 2.4311301001077643

Epoch: 5| Step: 1
Training loss: 0.7825649639133808
Validation loss: 2.4353742788240464

Epoch: 5| Step: 2
Training loss: 0.5457694732155527
Validation loss: 2.436994010504653

Epoch: 5| Step: 3
Training loss: 0.8318417830395065
Validation loss: 2.4296570376253346

Epoch: 5| Step: 4
Training loss: 0.7316396783516091
Validation loss: 2.4365149380434157

Epoch: 5| Step: 5
Training loss: 0.7478484844344668
Validation loss: 2.4411087620123126

Epoch: 5| Step: 6
Training loss: 0.530755738730902
Validation loss: 2.424268103206132

Epoch: 5| Step: 7
Training loss: 1.1065894064208146
Validation loss: 2.4189446628317697

Epoch: 5| Step: 8
Training loss: 0.6501810463611907
Validation loss: 2.3927700513715786

Epoch: 5| Step: 9
Training loss: 0.9624318854270202
Validation loss: 2.3534956850761026

Epoch: 5| Step: 10
Training loss: 0.5049409814377679
Validation loss: 2.3347836040156014

Epoch: 411| Step: 0
Training loss: 0.542156929891249
Validation loss: 2.3697546810782963

Epoch: 5| Step: 1
Training loss: 0.680295409275711
Validation loss: 2.3612089401244374

Epoch: 5| Step: 2
Training loss: 0.7787730050401153
Validation loss: 2.356290223393129

Epoch: 5| Step: 3
Training loss: 0.8543703526424209
Validation loss: 2.392262736886505

Epoch: 5| Step: 4
Training loss: 1.0636535441219654
Validation loss: 2.4260590178774546

Epoch: 5| Step: 5
Training loss: 0.8863174269708534
Validation loss: 2.4011435285700093

Epoch: 5| Step: 6
Training loss: 0.8096908277165688
Validation loss: 2.396260774922756

Epoch: 5| Step: 7
Training loss: 0.7968231259085649
Validation loss: 2.376447315416435

Epoch: 5| Step: 8
Training loss: 0.4040788624777668
Validation loss: 2.4181931872077436

Epoch: 5| Step: 9
Training loss: 0.8137292366484549
Validation loss: 2.39604195805094

Epoch: 5| Step: 10
Training loss: 0.5765670197265789
Validation loss: 2.365352106302886

Epoch: 412| Step: 0
Training loss: 0.799529012975495
Validation loss: 2.3775591811262826

Epoch: 5| Step: 1
Training loss: 0.6983256043444195
Validation loss: 2.368551328096502

Epoch: 5| Step: 2
Training loss: 0.5717359050586286
Validation loss: 2.3630757761099974

Epoch: 5| Step: 3
Training loss: 1.1715444988863157
Validation loss: 2.3633210827921443

Epoch: 5| Step: 4
Training loss: 0.7082006152487805
Validation loss: 2.3539849876483196

Epoch: 5| Step: 5
Training loss: 0.7981984984536458
Validation loss: 2.362087879260719

Epoch: 5| Step: 6
Training loss: 0.7070912709761892
Validation loss: 2.357907800719109

Epoch: 5| Step: 7
Training loss: 0.544164808493105
Validation loss: 2.353522742353463

Epoch: 5| Step: 8
Training loss: 0.944397223139796
Validation loss: 2.3707941180912475

Epoch: 5| Step: 9
Training loss: 0.6466003959247475
Validation loss: 2.4086837127339766

Epoch: 5| Step: 10
Training loss: 0.5567974204366771
Validation loss: 2.3882958045672247

Epoch: 413| Step: 0
Training loss: 0.6717342850352157
Validation loss: 2.3795942990654426

Epoch: 5| Step: 1
Training loss: 0.4334166912757785
Validation loss: 2.3875509958351464

Epoch: 5| Step: 2
Training loss: 0.3958518709894765
Validation loss: 2.4071878662540205

Epoch: 5| Step: 3
Training loss: 1.1320979528474153
Validation loss: 2.4037809752027988

Epoch: 5| Step: 4
Training loss: 0.6394164152333397
Validation loss: 2.414889618621396

Epoch: 5| Step: 5
Training loss: 0.6597780125992558
Validation loss: 2.3992832460747318

Epoch: 5| Step: 6
Training loss: 1.0989623529200994
Validation loss: 2.3824571785350104

Epoch: 5| Step: 7
Training loss: 0.8514282050673719
Validation loss: 2.3995716486075387

Epoch: 5| Step: 8
Training loss: 0.8505733239413489
Validation loss: 2.3748607691835546

Epoch: 5| Step: 9
Training loss: 0.6338671855064933
Validation loss: 2.359447845114609

Epoch: 5| Step: 10
Training loss: 0.524369761835245
Validation loss: 2.3843035345359023

Epoch: 414| Step: 0
Training loss: 0.6414539742226172
Validation loss: 2.37935917983819

Epoch: 5| Step: 1
Training loss: 0.7562448863967901
Validation loss: 2.338883038747825

Epoch: 5| Step: 2
Training loss: 0.6063422516311465
Validation loss: 2.341444553796059

Epoch: 5| Step: 3
Training loss: 1.073250518016748
Validation loss: 2.3419427309448437

Epoch: 5| Step: 4
Training loss: 0.6603479953366016
Validation loss: 2.347297622910661

Epoch: 5| Step: 5
Training loss: 0.542211072557734
Validation loss: 2.3172305554974297

Epoch: 5| Step: 6
Training loss: 0.92307371664713
Validation loss: 2.3367082179926646

Epoch: 5| Step: 7
Training loss: 0.6598987415694233
Validation loss: 2.3499270544990405

Epoch: 5| Step: 8
Training loss: 1.11695907498336
Validation loss: 2.387255922020139

Epoch: 5| Step: 9
Training loss: 0.3601117253450484
Validation loss: 2.426819607217441

Epoch: 5| Step: 10
Training loss: 0.6667363805878158
Validation loss: 2.401929644744719

Epoch: 415| Step: 0
Training loss: 0.6245120527968956
Validation loss: 2.4261594317731596

Epoch: 5| Step: 1
Training loss: 0.8008672156362712
Validation loss: 2.4246233125846697

Epoch: 5| Step: 2
Training loss: 0.7445193150655504
Validation loss: 2.361295985472501

Epoch: 5| Step: 3
Training loss: 1.0821557369302015
Validation loss: 2.3949728691699543

Epoch: 5| Step: 4
Training loss: 0.7683231533338778
Validation loss: 2.3707427472739413

Epoch: 5| Step: 5
Training loss: 0.6563543963274251
Validation loss: 2.3715760377303674

Epoch: 5| Step: 6
Training loss: 0.6059274720045325
Validation loss: 2.351585156137371

Epoch: 5| Step: 7
Training loss: 0.5898988458025579
Validation loss: 2.3283375452185147

Epoch: 5| Step: 8
Training loss: 0.6991544725933184
Validation loss: 2.3587972466975935

Epoch: 5| Step: 9
Training loss: 0.7191501830220595
Validation loss: 2.3855050745826136

Epoch: 5| Step: 10
Training loss: 0.860924243305697
Validation loss: 2.3636121357725846

Epoch: 416| Step: 0
Training loss: 0.6102435939660432
Validation loss: 2.3639709545588974

Epoch: 5| Step: 1
Training loss: 0.9140191027128777
Validation loss: 2.389917415721773

Epoch: 5| Step: 2
Training loss: 0.6113894252085332
Validation loss: 2.3628427498524047

Epoch: 5| Step: 3
Training loss: 0.8699315619132763
Validation loss: 2.3775626531394654

Epoch: 5| Step: 4
Training loss: 0.6668022410305903
Validation loss: 2.383755002825747

Epoch: 5| Step: 5
Training loss: 1.041051180520416
Validation loss: 2.3765141712615034

Epoch: 5| Step: 6
Training loss: 0.4309299539150164
Validation loss: 2.3764785143256857

Epoch: 5| Step: 7
Training loss: 0.9628033704860348
Validation loss: 2.368536597042487

Epoch: 5| Step: 8
Training loss: 0.5638213268164608
Validation loss: 2.3400090086798335

Epoch: 5| Step: 9
Training loss: 0.7351566780891753
Validation loss: 2.3252128650060855

Epoch: 5| Step: 10
Training loss: 0.6550097780735401
Validation loss: 2.3204263323814533

Epoch: 417| Step: 0
Training loss: 0.8397638327256232
Validation loss: 2.3222792895223034

Epoch: 5| Step: 1
Training loss: 0.8988564882606913
Validation loss: 2.330186276991549

Epoch: 5| Step: 2
Training loss: 0.9686184147714184
Validation loss: 2.3189587022332643

Epoch: 5| Step: 3
Training loss: 0.6008755117612199
Validation loss: 2.3316793827832876

Epoch: 5| Step: 4
Training loss: 0.6516810265915866
Validation loss: 2.343176375439975

Epoch: 5| Step: 5
Training loss: 0.7046553170918117
Validation loss: 2.422381676406028

Epoch: 5| Step: 6
Training loss: 0.8148375411267975
Validation loss: 2.3784502870379414

Epoch: 5| Step: 7
Training loss: 0.7998834182312964
Validation loss: 2.390095142055385

Epoch: 5| Step: 8
Training loss: 0.7182792282822881
Validation loss: 2.3467541174253115

Epoch: 5| Step: 9
Training loss: 0.7478287182016483
Validation loss: 2.3543885885346127

Epoch: 5| Step: 10
Training loss: 0.6116757607974984
Validation loss: 2.3088587046408566

Epoch: 418| Step: 0
Training loss: 0.9257113917266007
Validation loss: 2.3348244478308855

Epoch: 5| Step: 1
Training loss: 0.5311514819180818
Validation loss: 2.32854401684908

Epoch: 5| Step: 2
Training loss: 0.6573058898120425
Validation loss: 2.341507807331595

Epoch: 5| Step: 3
Training loss: 0.8909073766822814
Validation loss: 2.353578987642156

Epoch: 5| Step: 4
Training loss: 0.6701074904716133
Validation loss: 2.378678941726753

Epoch: 5| Step: 5
Training loss: 1.0426208830348433
Validation loss: 2.3261205227524635

Epoch: 5| Step: 6
Training loss: 0.7152634519440726
Validation loss: 2.37074156317786

Epoch: 5| Step: 7
Training loss: 0.7610805870426236
Validation loss: 2.3675791493826956

Epoch: 5| Step: 8
Training loss: 0.6867326876079793
Validation loss: 2.3674301661502115

Epoch: 5| Step: 9
Training loss: 0.42099780261764275
Validation loss: 2.377061574105347

Epoch: 5| Step: 10
Training loss: 0.6552280688889197
Validation loss: 2.3759364336681164

Epoch: 419| Step: 0
Training loss: 0.8891201355928582
Validation loss: 2.404379805207609

Epoch: 5| Step: 1
Training loss: 0.6386526495696766
Validation loss: 2.3715169394861557

Epoch: 5| Step: 2
Training loss: 0.6447784181095504
Validation loss: 2.358354632115743

Epoch: 5| Step: 3
Training loss: 0.718833959900108
Validation loss: 2.4024669227134114

Epoch: 5| Step: 4
Training loss: 0.7606937652573096
Validation loss: 2.403601661560407

Epoch: 5| Step: 5
Training loss: 0.5785776891907878
Validation loss: 2.3862341252887678

Epoch: 5| Step: 6
Training loss: 0.8018427814246017
Validation loss: 2.353641453237303

Epoch: 5| Step: 7
Training loss: 0.697792559354609
Validation loss: 2.3736584840979718

Epoch: 5| Step: 8
Training loss: 0.734859631298037
Validation loss: 2.396639289137655

Epoch: 5| Step: 9
Training loss: 0.7020387099561868
Validation loss: 2.3957585505459473

Epoch: 5| Step: 10
Training loss: 0.8362915145080447
Validation loss: 2.367843214923063

Epoch: 420| Step: 0
Training loss: 0.5925040473477836
Validation loss: 2.374577562967273

Epoch: 5| Step: 1
Training loss: 0.5775809692411851
Validation loss: 2.3900150371041917

Epoch: 5| Step: 2
Training loss: 0.6158384475917209
Validation loss: 2.3901311621826093

Epoch: 5| Step: 3
Training loss: 0.7054816911256047
Validation loss: 2.386790395388104

Epoch: 5| Step: 4
Training loss: 0.6071100201061504
Validation loss: 2.3709750652165256

Epoch: 5| Step: 5
Training loss: 0.9658506136037638
Validation loss: 2.346917628400098

Epoch: 5| Step: 6
Training loss: 0.8642236045490009
Validation loss: 2.380602862454497

Epoch: 5| Step: 7
Training loss: 0.7523264565069737
Validation loss: 2.3714381971921603

Epoch: 5| Step: 8
Training loss: 0.7716001785861492
Validation loss: 2.366682131536352

Epoch: 5| Step: 9
Training loss: 0.6837797947168107
Validation loss: 2.369492715457369

Epoch: 5| Step: 10
Training loss: 0.7929113583396258
Validation loss: 2.393877420027748

Epoch: 421| Step: 0
Training loss: 0.7203642919625914
Validation loss: 2.3258795096737277

Epoch: 5| Step: 1
Training loss: 0.8238524576702295
Validation loss: 2.3233445524520753

Epoch: 5| Step: 2
Training loss: 0.48485509091438883
Validation loss: 2.3395924566509967

Epoch: 5| Step: 3
Training loss: 0.7067338096537282
Validation loss: 2.3225390260054093

Epoch: 5| Step: 4
Training loss: 0.8092952762650203
Validation loss: 2.343371376437478

Epoch: 5| Step: 5
Training loss: 0.7595973281980093
Validation loss: 2.34499361467593

Epoch: 5| Step: 6
Training loss: 0.6243351738249695
Validation loss: 2.3527370554767644

Epoch: 5| Step: 7
Training loss: 0.7006218328072579
Validation loss: 2.3349064220823093

Epoch: 5| Step: 8
Training loss: 0.8785898614017538
Validation loss: 2.3248091503033894

Epoch: 5| Step: 9
Training loss: 0.7077417334070775
Validation loss: 2.2905856210669295

Epoch: 5| Step: 10
Training loss: 0.3426706100078025
Validation loss: 2.308487207252109

Epoch: 422| Step: 0
Training loss: 0.777428473834742
Validation loss: 2.329001476507083

Epoch: 5| Step: 1
Training loss: 0.7815053141163703
Validation loss: 2.3333031631165797

Epoch: 5| Step: 2
Training loss: 0.5862462819597652
Validation loss: 2.3245348274146473

Epoch: 5| Step: 3
Training loss: 1.0569659453277194
Validation loss: 2.323374239960349

Epoch: 5| Step: 4
Training loss: 0.6537983831586943
Validation loss: 2.313985074461504

Epoch: 5| Step: 5
Training loss: 0.5637520524894754
Validation loss: 2.31645142192782

Epoch: 5| Step: 6
Training loss: 0.716314168855051
Validation loss: 2.3199345483297287

Epoch: 5| Step: 7
Training loss: 0.6879928512908785
Validation loss: 2.354061603152805

Epoch: 5| Step: 8
Training loss: 0.7076169954489716
Validation loss: 2.361402176810259

Epoch: 5| Step: 9
Training loss: 0.4618411984547733
Validation loss: 2.350098059324796

Epoch: 5| Step: 10
Training loss: 0.41661862652719467
Validation loss: 2.3395373456591804

Epoch: 423| Step: 0
Training loss: 0.5844645997578093
Validation loss: 2.345093827651771

Epoch: 5| Step: 1
Training loss: 0.6859243283060747
Validation loss: 2.36096901205632

Epoch: 5| Step: 2
Training loss: 0.5821986117815237
Validation loss: 2.359171730873791

Epoch: 5| Step: 3
Training loss: 0.5148280950316615
Validation loss: 2.3140296654914536

Epoch: 5| Step: 4
Training loss: 1.0323657155864794
Validation loss: 2.334258430844126

Epoch: 5| Step: 5
Training loss: 0.6921707926298909
Validation loss: 2.355276149264993

Epoch: 5| Step: 6
Training loss: 0.5666472612826263
Validation loss: 2.3307057823886668

Epoch: 5| Step: 7
Training loss: 0.7371199420602113
Validation loss: 2.3290996494836995

Epoch: 5| Step: 8
Training loss: 0.7819071104315488
Validation loss: 2.326663503130209

Epoch: 5| Step: 9
Training loss: 0.7649964068209966
Validation loss: 2.368521222963061

Epoch: 5| Step: 10
Training loss: 0.5714898954634601
Validation loss: 2.3443343223748307

Epoch: 424| Step: 0
Training loss: 0.5384562856947224
Validation loss: 2.3359974643452883

Epoch: 5| Step: 1
Training loss: 0.6153414920623843
Validation loss: 2.3665009509544066

Epoch: 5| Step: 2
Training loss: 0.5896664536141326
Validation loss: 2.372312513763441

Epoch: 5| Step: 3
Training loss: 0.7101976926018958
Validation loss: 2.3370085271464163

Epoch: 5| Step: 4
Training loss: 0.7410681867282364
Validation loss: 2.396087994267287

Epoch: 5| Step: 5
Training loss: 0.35377372887896363
Validation loss: 2.355976737066071

Epoch: 5| Step: 6
Training loss: 0.7549970572458479
Validation loss: 2.3228685217783434

Epoch: 5| Step: 7
Training loss: 0.9476335892322639
Validation loss: 2.3430777533862446

Epoch: 5| Step: 8
Training loss: 0.5465148284694287
Validation loss: 2.30393224555954

Epoch: 5| Step: 9
Training loss: 1.0338738901609474
Validation loss: 2.3251516202970004

Epoch: 5| Step: 10
Training loss: 0.5674954957405175
Validation loss: 2.288960896799381

Epoch: 425| Step: 0
Training loss: 0.5891738776188793
Validation loss: 2.322582111705695

Epoch: 5| Step: 1
Training loss: 0.4216634078459027
Validation loss: 2.3670807683776554

Epoch: 5| Step: 2
Training loss: 0.8297310137069221
Validation loss: 2.3360435839558322

Epoch: 5| Step: 3
Training loss: 0.6925005254502489
Validation loss: 2.3523739010514615

Epoch: 5| Step: 4
Training loss: 0.8280999521749994
Validation loss: 2.3841506156784384

Epoch: 5| Step: 5
Training loss: 0.6468351858666711
Validation loss: 2.3568925299345125

Epoch: 5| Step: 6
Training loss: 0.6814280399791419
Validation loss: 2.3418509092672877

Epoch: 5| Step: 7
Training loss: 0.6930364152112339
Validation loss: 2.329824313761947

Epoch: 5| Step: 8
Training loss: 0.5800285446607842
Validation loss: 2.330396047904872

Epoch: 5| Step: 9
Training loss: 0.7720537233584908
Validation loss: 2.33455016413327

Epoch: 5| Step: 10
Training loss: 0.7054782904806771
Validation loss: 2.3177654392516365

Epoch: 426| Step: 0
Training loss: 0.6726356680420528
Validation loss: 2.255065269643389

Epoch: 5| Step: 1
Training loss: 0.7238034601841921
Validation loss: 2.3039324491880175

Epoch: 5| Step: 2
Training loss: 0.632404360608178
Validation loss: 2.301421033771351

Epoch: 5| Step: 3
Training loss: 0.7629507421039803
Validation loss: 2.3414421504958938

Epoch: 5| Step: 4
Training loss: 0.4208586955060584
Validation loss: 2.304163496383957

Epoch: 5| Step: 5
Training loss: 0.5251216554469382
Validation loss: 2.3272339483257953

Epoch: 5| Step: 6
Training loss: 0.5096579251576143
Validation loss: 2.344717711698186

Epoch: 5| Step: 7
Training loss: 1.0552171295693125
Validation loss: 2.3599899339243975

Epoch: 5| Step: 8
Training loss: 0.6584480803318097
Validation loss: 2.3908182283631745

Epoch: 5| Step: 9
Training loss: 0.7460400626953517
Validation loss: 2.396854396706435

Epoch: 5| Step: 10
Training loss: 0.6181885532149959
Validation loss: 2.4089502494471415

Epoch: 427| Step: 0
Training loss: 0.6199608072460173
Validation loss: 2.370487578742486

Epoch: 5| Step: 1
Training loss: 0.510856426001235
Validation loss: 2.4126454385100904

Epoch: 5| Step: 2
Training loss: 0.6483475956005924
Validation loss: 2.3461757846727216

Epoch: 5| Step: 3
Training loss: 0.9152442596201348
Validation loss: 2.392153276163425

Epoch: 5| Step: 4
Training loss: 0.5973068412695529
Validation loss: 2.3938890297954427

Epoch: 5| Step: 5
Training loss: 0.6482771250018226
Validation loss: 2.3925386834006614

Epoch: 5| Step: 6
Training loss: 0.5816078181906832
Validation loss: 2.4022292536634584

Epoch: 5| Step: 7
Training loss: 0.5205087572271709
Validation loss: 2.39025083065823

Epoch: 5| Step: 8
Training loss: 0.360070881686913
Validation loss: 2.37663192682673

Epoch: 5| Step: 9
Training loss: 0.7103887263496791
Validation loss: 2.3967125462231325

Epoch: 5| Step: 10
Training loss: 1.0675442391191579
Validation loss: 2.391972037305401

Epoch: 428| Step: 0
Training loss: 0.6629719474691999
Validation loss: 2.385913751588221

Epoch: 5| Step: 1
Training loss: 0.7660498316245575
Validation loss: 2.3847311326014133

Epoch: 5| Step: 2
Training loss: 0.6207015280585995
Validation loss: 2.3869191464188853

Epoch: 5| Step: 3
Training loss: 0.5901107183924899
Validation loss: 2.3408872516843786

Epoch: 5| Step: 4
Training loss: 0.4216371148136317
Validation loss: 2.3415131732707213

Epoch: 5| Step: 5
Training loss: 0.4682315184209177
Validation loss: 2.3433922651180423

Epoch: 5| Step: 6
Training loss: 0.9032432399552749
Validation loss: 2.346486798002165

Epoch: 5| Step: 7
Training loss: 0.7634088790219296
Validation loss: 2.3134150076413906

Epoch: 5| Step: 8
Training loss: 0.6853079094061151
Validation loss: 2.327775266996141

Epoch: 5| Step: 9
Training loss: 0.7892971256530962
Validation loss: 2.326015534488882

Epoch: 5| Step: 10
Training loss: 0.5384057231875922
Validation loss: 2.336761425880951

Epoch: 429| Step: 0
Training loss: 0.7755534580013191
Validation loss: 2.3523600538846603

Epoch: 5| Step: 1
Training loss: 0.9507167283344407
Validation loss: 2.345951507170333

Epoch: 5| Step: 2
Training loss: 0.7820244574466183
Validation loss: 2.3729941641738463

Epoch: 5| Step: 3
Training loss: 0.46871550750984264
Validation loss: 2.362837945549505

Epoch: 5| Step: 4
Training loss: 0.703042300977006
Validation loss: 2.364939305919535

Epoch: 5| Step: 5
Training loss: 0.6520172489874346
Validation loss: 2.373246374521539

Epoch: 5| Step: 6
Training loss: 0.5879143238043475
Validation loss: 2.3909688653083516

Epoch: 5| Step: 7
Training loss: 0.6661237254188729
Validation loss: 2.343296642140789

Epoch: 5| Step: 8
Training loss: 0.5087889453499745
Validation loss: 2.3632010204663763

Epoch: 5| Step: 9
Training loss: 0.5134275021917568
Validation loss: 2.3568083247129104

Epoch: 5| Step: 10
Training loss: 0.42541344531511904
Validation loss: 2.3784554327444636

Epoch: 430| Step: 0
Training loss: 0.40706289098841797
Validation loss: 2.362532876180896

Epoch: 5| Step: 1
Training loss: 0.6389231289681517
Validation loss: 2.3917151580790583

Epoch: 5| Step: 2
Training loss: 0.7121445187315474
Validation loss: 2.3687350299580894

Epoch: 5| Step: 3
Training loss: 0.7219691541296054
Validation loss: 2.366986749525045

Epoch: 5| Step: 4
Training loss: 0.46842707000786465
Validation loss: 2.3875290235213376

Epoch: 5| Step: 5
Training loss: 0.5453681895503825
Validation loss: 2.3793322811459805

Epoch: 5| Step: 6
Training loss: 0.6923439649866967
Validation loss: 2.386189641048671

Epoch: 5| Step: 7
Training loss: 1.0817939690932221
Validation loss: 2.4114337709839235

Epoch: 5| Step: 8
Training loss: 0.5136047145321858
Validation loss: 2.378894549868973

Epoch: 5| Step: 9
Training loss: 0.5681398892104
Validation loss: 2.3840774328303884

Epoch: 5| Step: 10
Training loss: 0.5998377163288697
Validation loss: 2.36573626644723

Epoch: 431| Step: 0
Training loss: 0.47550543822499014
Validation loss: 2.34346117543893

Epoch: 5| Step: 1
Training loss: 0.5257147317558301
Validation loss: 2.342392384001051

Epoch: 5| Step: 2
Training loss: 0.42605270691660746
Validation loss: 2.312159420343787

Epoch: 5| Step: 3
Training loss: 0.6979138008931854
Validation loss: 2.34914738402482

Epoch: 5| Step: 4
Training loss: 1.0215747567156575
Validation loss: 2.3065839864715136

Epoch: 5| Step: 5
Training loss: 0.7690175079490688
Validation loss: 2.3464928780029837

Epoch: 5| Step: 6
Training loss: 0.6017073915053878
Validation loss: 2.3507484801674856

Epoch: 5| Step: 7
Training loss: 0.7202685526848687
Validation loss: 2.3721191364479455

Epoch: 5| Step: 8
Training loss: 0.7157730149363922
Validation loss: 2.349809782646432

Epoch: 5| Step: 9
Training loss: 0.5094464351435355
Validation loss: 2.35526633671351

Epoch: 5| Step: 10
Training loss: 0.6193120099476804
Validation loss: 2.343674129228823

Epoch: 432| Step: 0
Training loss: 0.388339585924497
Validation loss: 2.3878832306293316

Epoch: 5| Step: 1
Training loss: 0.6665762725780732
Validation loss: 2.355061982534469

Epoch: 5| Step: 2
Training loss: 0.5311862121882405
Validation loss: 2.357797589903186

Epoch: 5| Step: 3
Training loss: 0.6969581588599247
Validation loss: 2.376791591866589

Epoch: 5| Step: 4
Training loss: 0.5226157841320372
Validation loss: 2.3841134879598647

Epoch: 5| Step: 5
Training loss: 0.598178261564891
Validation loss: 2.436090817700216

Epoch: 5| Step: 6
Training loss: 0.8753627638189736
Validation loss: 2.3923469768987156

Epoch: 5| Step: 7
Training loss: 0.5327060884058672
Validation loss: 2.402407197125273

Epoch: 5| Step: 8
Training loss: 0.9106914272965873
Validation loss: 2.3723752387504704

Epoch: 5| Step: 9
Training loss: 0.5636632071375168
Validation loss: 2.392005947825039

Epoch: 5| Step: 10
Training loss: 0.6553798083227741
Validation loss: 2.3850730680417236

Epoch: 433| Step: 0
Training loss: 0.6637233541280373
Validation loss: 2.3715896559536436

Epoch: 5| Step: 1
Training loss: 0.5227075582959463
Validation loss: 2.34078357628742

Epoch: 5| Step: 2
Training loss: 0.7952986065863269
Validation loss: 2.335607938050881

Epoch: 5| Step: 3
Training loss: 0.5810084476825252
Validation loss: 2.33932055720696

Epoch: 5| Step: 4
Training loss: 0.7982721982522262
Validation loss: 2.330691516100293

Epoch: 5| Step: 5
Training loss: 0.6987897953036215
Validation loss: 2.353324733776402

Epoch: 5| Step: 6
Training loss: 0.6908747036061722
Validation loss: 2.346365268974146

Epoch: 5| Step: 7
Training loss: 0.5150033497932895
Validation loss: 2.3591830159125085

Epoch: 5| Step: 8
Training loss: 0.64705404669355
Validation loss: 2.3779583323845728

Epoch: 5| Step: 9
Training loss: 0.6211969301901387
Validation loss: 2.3998660782353824

Epoch: 5| Step: 10
Training loss: 0.5563803616473016
Validation loss: 2.3948578341742244

Epoch: 434| Step: 0
Training loss: 0.3513190592214733
Validation loss: 2.395964503253204

Epoch: 5| Step: 1
Training loss: 0.7322630443016753
Validation loss: 2.3657650018087093

Epoch: 5| Step: 2
Training loss: 0.737600103147214
Validation loss: 2.349443830830611

Epoch: 5| Step: 3
Training loss: 0.7246177652289687
Validation loss: 2.354950986453635

Epoch: 5| Step: 4
Training loss: 0.5567038516894511
Validation loss: 2.3427832334378493

Epoch: 5| Step: 5
Training loss: 0.4457491356974474
Validation loss: 2.343411698622239

Epoch: 5| Step: 6
Training loss: 0.615032683721313
Validation loss: 2.3570278047798885

Epoch: 5| Step: 7
Training loss: 0.707768766892126
Validation loss: 2.3516473743582313

Epoch: 5| Step: 8
Training loss: 0.7323183927547169
Validation loss: 2.3522947838731696

Epoch: 5| Step: 9
Training loss: 0.6832807205655245
Validation loss: 2.357986633889688

Epoch: 5| Step: 10
Training loss: 0.5274460587334295
Validation loss: 2.3797753273783244

Epoch: 435| Step: 0
Training loss: 0.4580874993925547
Validation loss: 2.367184164388131

Epoch: 5| Step: 1
Training loss: 0.5136502047417016
Validation loss: 2.372944499881837

Epoch: 5| Step: 2
Training loss: 0.4740044620269695
Validation loss: 2.374745230618904

Epoch: 5| Step: 3
Training loss: 0.7458069334916511
Validation loss: 2.3763301343466066

Epoch: 5| Step: 4
Training loss: 0.6056596516556524
Validation loss: 2.334695045871793

Epoch: 5| Step: 5
Training loss: 0.6804327332242166
Validation loss: 2.387458408592394

Epoch: 5| Step: 6
Training loss: 0.5904307192213891
Validation loss: 2.3758699543336075

Epoch: 5| Step: 7
Training loss: 0.8675300677582655
Validation loss: 2.3524572852970658

Epoch: 5| Step: 8
Training loss: 0.4978874699426632
Validation loss: 2.356440831324153

Epoch: 5| Step: 9
Training loss: 0.597069870259499
Validation loss: 2.337465224095927

Epoch: 5| Step: 10
Training loss: 0.7479200131085548
Validation loss: 2.3560022136307275

Epoch: 436| Step: 0
Training loss: 0.7016582449168253
Validation loss: 2.3634782172598996

Epoch: 5| Step: 1
Training loss: 0.3283997248477689
Validation loss: 2.3702340332600182

Epoch: 5| Step: 2
Training loss: 0.3559365600225213
Validation loss: 2.352841731766788

Epoch: 5| Step: 3
Training loss: 0.889502973001539
Validation loss: 2.330556973116191

Epoch: 5| Step: 4
Training loss: 0.5717331684355549
Validation loss: 2.32292692746045

Epoch: 5| Step: 5
Training loss: 0.7738215331134278
Validation loss: 2.3381083755065957

Epoch: 5| Step: 6
Training loss: 0.49068674743754004
Validation loss: 2.3626020561503216

Epoch: 5| Step: 7
Training loss: 0.5323872175012745
Validation loss: 2.3362008201296525

Epoch: 5| Step: 8
Training loss: 0.7066249206721074
Validation loss: 2.359236071714337

Epoch: 5| Step: 9
Training loss: 0.43191992237621346
Validation loss: 2.3801629850267703

Epoch: 5| Step: 10
Training loss: 0.7386415197952741
Validation loss: 2.365986672734661

Epoch: 437| Step: 0
Training loss: 0.7961756685615953
Validation loss: 2.341049021691027

Epoch: 5| Step: 1
Training loss: 0.6947449500197918
Validation loss: 2.3482148256356012

Epoch: 5| Step: 2
Training loss: 0.5842768214365458
Validation loss: 2.3596137554255217

Epoch: 5| Step: 3
Training loss: 0.5407004143920208
Validation loss: 2.3965194015884363

Epoch: 5| Step: 4
Training loss: 0.5940124283126178
Validation loss: 2.367981271221489

Epoch: 5| Step: 5
Training loss: 0.3659230232144197
Validation loss: 2.403182652043252

Epoch: 5| Step: 6
Training loss: 0.764980823675421
Validation loss: 2.4262679362842463

Epoch: 5| Step: 7
Training loss: 0.6795661204029463
Validation loss: 2.4098312476044916

Epoch: 5| Step: 8
Training loss: 0.6665034367486327
Validation loss: 2.4113786779424258

Epoch: 5| Step: 9
Training loss: 0.4800315511536285
Validation loss: 2.3779839313693856

Epoch: 5| Step: 10
Training loss: 0.38062259454076697
Validation loss: 2.3847096788099247

Epoch: 438| Step: 0
Training loss: 0.6491255499346934
Validation loss: 2.338686038411594

Epoch: 5| Step: 1
Training loss: 0.32997078815043535
Validation loss: 2.317324916478562

Epoch: 5| Step: 2
Training loss: 0.42810001161143574
Validation loss: 2.3189592864971855

Epoch: 5| Step: 3
Training loss: 0.8851910172694046
Validation loss: 2.2969257727776093

Epoch: 5| Step: 4
Training loss: 0.6284111396045016
Validation loss: 2.3272923435932

Epoch: 5| Step: 5
Training loss: 0.7236662945742758
Validation loss: 2.338059187277481

Epoch: 5| Step: 6
Training loss: 0.7157116816633488
Validation loss: 2.3625101286213126

Epoch: 5| Step: 7
Training loss: 0.7092588119470381
Validation loss: 2.3726469655569593

Epoch: 5| Step: 8
Training loss: 0.48300237903246007
Validation loss: 2.3965006586885487

Epoch: 5| Step: 9
Training loss: 0.4055492519661005
Validation loss: 2.3856173560445852

Epoch: 5| Step: 10
Training loss: 0.6101530683095037
Validation loss: 2.3720617506974007

Epoch: 439| Step: 0
Training loss: 0.5630656947619994
Validation loss: 2.379849302322971

Epoch: 5| Step: 1
Training loss: 0.45220292753780295
Validation loss: 2.3845384135172947

Epoch: 5| Step: 2
Training loss: 0.582422777631893
Validation loss: 2.3856831994712113

Epoch: 5| Step: 3
Training loss: 0.6472540937834252
Validation loss: 2.3517028986899216

Epoch: 5| Step: 4
Training loss: 0.4357472630183395
Validation loss: 2.3777692708474163

Epoch: 5| Step: 5
Training loss: 0.5987574834893508
Validation loss: 2.385138397672892

Epoch: 5| Step: 6
Training loss: 0.733420096127115
Validation loss: 2.381518493278746

Epoch: 5| Step: 7
Training loss: 0.6560764310276592
Validation loss: 2.3531901677168667

Epoch: 5| Step: 8
Training loss: 0.5666015814354153
Validation loss: 2.3514509822246006

Epoch: 5| Step: 9
Training loss: 0.8278281921535302
Validation loss: 2.3657439690505297

Epoch: 5| Step: 10
Training loss: 0.5550353343128844
Validation loss: 2.368327302811258

Epoch: 440| Step: 0
Training loss: 0.4224658995754479
Validation loss: 2.352935229546305

Epoch: 5| Step: 1
Training loss: 0.8663750356515402
Validation loss: 2.3261746765000275

Epoch: 5| Step: 2
Training loss: 0.47222721710399523
Validation loss: 2.3309683907902983

Epoch: 5| Step: 3
Training loss: 0.7650204042443687
Validation loss: 2.3655642224617237

Epoch: 5| Step: 4
Training loss: 0.5255229740710429
Validation loss: 2.3492961484470367

Epoch: 5| Step: 5
Training loss: 0.3758157361359281
Validation loss: 2.3567161722778414

Epoch: 5| Step: 6
Training loss: 0.4251301187590134
Validation loss: 2.3524037049869375

Epoch: 5| Step: 7
Training loss: 0.47237313674131276
Validation loss: 2.3744850858042224

Epoch: 5| Step: 8
Training loss: 0.6216026955980598
Validation loss: 2.375147715078356

Epoch: 5| Step: 9
Training loss: 0.7047503864115413
Validation loss: 2.391974390908193

Epoch: 5| Step: 10
Training loss: 0.7041343861202666
Validation loss: 2.363279823513646

Epoch: 441| Step: 0
Training loss: 0.4126847214790849
Validation loss: 2.407311249036883

Epoch: 5| Step: 1
Training loss: 0.33238750867342587
Validation loss: 2.387143553317318

Epoch: 5| Step: 2
Training loss: 0.6826661492116961
Validation loss: 2.3747028452061048

Epoch: 5| Step: 3
Training loss: 0.6285223411073202
Validation loss: 2.373612339578984

Epoch: 5| Step: 4
Training loss: 0.5244240928557313
Validation loss: 2.401562197324258

Epoch: 5| Step: 5
Training loss: 0.8066350461014136
Validation loss: 2.3862969629478625

Epoch: 5| Step: 6
Training loss: 0.7919804093582242
Validation loss: 2.3885429372410627

Epoch: 5| Step: 7
Training loss: 0.43973786348269156
Validation loss: 2.3577042169876625

Epoch: 5| Step: 8
Training loss: 0.6792528143660529
Validation loss: 2.3677392797965693

Epoch: 5| Step: 9
Training loss: 0.5979154436141031
Validation loss: 2.381918580961914

Epoch: 5| Step: 10
Training loss: 0.4047717378644742
Validation loss: 2.366922250574321

Epoch: 442| Step: 0
Training loss: 0.6597446309572628
Validation loss: 2.367005769450835

Epoch: 5| Step: 1
Training loss: 0.4547331816544863
Validation loss: 2.3992718526033494

Epoch: 5| Step: 2
Training loss: 0.6223784780809283
Validation loss: 2.369589018831331

Epoch: 5| Step: 3
Training loss: 0.7163622627357354
Validation loss: 2.3571606639236875

Epoch: 5| Step: 4
Training loss: 0.4987103997669322
Validation loss: 2.365662164995325

Epoch: 5| Step: 5
Training loss: 0.4872234330252277
Validation loss: 2.370756813641325

Epoch: 5| Step: 6
Training loss: 0.7611774183852764
Validation loss: 2.348553210162583

Epoch: 5| Step: 7
Training loss: 0.5912297619184727
Validation loss: 2.3717392069628414

Epoch: 5| Step: 8
Training loss: 0.5272928566569457
Validation loss: 2.3451789623533847

Epoch: 5| Step: 9
Training loss: 0.6381089882705276
Validation loss: 2.3381168368675804

Epoch: 5| Step: 10
Training loss: 0.255853900414057
Validation loss: 2.3217241750696926

Epoch: 443| Step: 0
Training loss: 0.3452868137040834
Validation loss: 2.336744773072738

Epoch: 5| Step: 1
Training loss: 0.6170135204543306
Validation loss: 2.3474902503025095

Epoch: 5| Step: 2
Training loss: 0.38391309291903236
Validation loss: 2.3655949688583373

Epoch: 5| Step: 3
Training loss: 0.7985057973298916
Validation loss: 2.3490931901927645

Epoch: 5| Step: 4
Training loss: 0.3195723378968598
Validation loss: 2.349792956105246

Epoch: 5| Step: 5
Training loss: 0.7336451373317467
Validation loss: 2.350492671839125

Epoch: 5| Step: 6
Training loss: 0.6492880562743497
Validation loss: 2.341550728478638

Epoch: 5| Step: 7
Training loss: 0.49968676888494107
Validation loss: 2.3464320084539576

Epoch: 5| Step: 8
Training loss: 0.42488100966681047
Validation loss: 2.348855968467951

Epoch: 5| Step: 9
Training loss: 0.48631160968482817
Validation loss: 2.3518719365828558

Epoch: 5| Step: 10
Training loss: 0.8930414445578648
Validation loss: 2.3751872635973332

Epoch: 444| Step: 0
Training loss: 0.49884684026466275
Validation loss: 2.36727029314555

Epoch: 5| Step: 1
Training loss: 0.6225629499694405
Validation loss: 2.357048110183487

Epoch: 5| Step: 2
Training loss: 0.6934231581027831
Validation loss: 2.3729926533178043

Epoch: 5| Step: 3
Training loss: 0.6520790431051121
Validation loss: 2.3643596486088354

Epoch: 5| Step: 4
Training loss: 0.3836943725564482
Validation loss: 2.341616920919646

Epoch: 5| Step: 5
Training loss: 0.40809905628388743
Validation loss: 2.3469394615178176

Epoch: 5| Step: 6
Training loss: 0.6254215011265813
Validation loss: 2.366679569716451

Epoch: 5| Step: 7
Training loss: 0.5909467577599945
Validation loss: 2.399438001946896

Epoch: 5| Step: 8
Training loss: 0.3966858638430977
Validation loss: 2.385281040713545

Epoch: 5| Step: 9
Training loss: 0.8226616420007626
Validation loss: 2.380316801963911

Epoch: 5| Step: 10
Training loss: 0.5503109757219787
Validation loss: 2.3892926970006423

Epoch: 445| Step: 0
Training loss: 0.5972917729424111
Validation loss: 2.39443964091147

Epoch: 5| Step: 1
Training loss: 0.45540885204277803
Validation loss: 2.383198706228428

Epoch: 5| Step: 2
Training loss: 0.5157844412542272
Validation loss: 2.3990205093127632

Epoch: 5| Step: 3
Training loss: 0.4180460885057802
Validation loss: 2.384194776136043

Epoch: 5| Step: 4
Training loss: 0.5460061937686495
Validation loss: 2.3964135329276566

Epoch: 5| Step: 5
Training loss: 0.4553798444816417
Validation loss: 2.3678962450363996

Epoch: 5| Step: 6
Training loss: 0.4099537122288743
Validation loss: 2.3885783427041054

Epoch: 5| Step: 7
Training loss: 0.7471390038119753
Validation loss: 2.381078519065509

Epoch: 5| Step: 8
Training loss: 0.6604816154127594
Validation loss: 2.392038965105811

Epoch: 5| Step: 9
Training loss: 0.5000893393809933
Validation loss: 2.3602812282374757

Epoch: 5| Step: 10
Training loss: 0.9216825639987429
Validation loss: 2.3324021931253776

Epoch: 446| Step: 0
Training loss: 0.3953214606675534
Validation loss: 2.339312759928616

Epoch: 5| Step: 1
Training loss: 0.6924251656430962
Validation loss: 2.350845381286136

Epoch: 5| Step: 2
Training loss: 0.6570730270911136
Validation loss: 2.352139478865496

Epoch: 5| Step: 3
Training loss: 0.6565868103741243
Validation loss: 2.340989643949558

Epoch: 5| Step: 4
Training loss: 0.4040393469860177
Validation loss: 2.3198912615110987

Epoch: 5| Step: 5
Training loss: 0.599736774839406
Validation loss: 2.3454249521735893

Epoch: 5| Step: 6
Training loss: 0.5990073446594101
Validation loss: 2.353252437735804

Epoch: 5| Step: 7
Training loss: 0.6124481081876454
Validation loss: 2.3154538121258135

Epoch: 5| Step: 8
Training loss: 0.5830055888531323
Validation loss: 2.3317031215887187

Epoch: 5| Step: 9
Training loss: 0.621624797539493
Validation loss: 2.308465561841326

Epoch: 5| Step: 10
Training loss: 0.44682518541345767
Validation loss: 2.3082279576052334

Epoch: 447| Step: 0
Training loss: 0.5683020598886221
Validation loss: 2.3480694395448327

Epoch: 5| Step: 1
Training loss: 0.6357615478192884
Validation loss: 2.291132693759852

Epoch: 5| Step: 2
Training loss: 0.5425868990074051
Validation loss: 2.3362542749510413

Epoch: 5| Step: 3
Training loss: 0.5417419130683768
Validation loss: 2.361124497962206

Epoch: 5| Step: 4
Training loss: 0.4147435830662065
Validation loss: 2.36593784142785

Epoch: 5| Step: 5
Training loss: 0.6206261896235348
Validation loss: 2.362324718564781

Epoch: 5| Step: 6
Training loss: 0.8109853638505391
Validation loss: 2.3971593439341166

Epoch: 5| Step: 7
Training loss: 0.638697399131003
Validation loss: 2.377282169839292

Epoch: 5| Step: 8
Training loss: 0.3985454749613204
Validation loss: 2.3727934528118557

Epoch: 5| Step: 9
Training loss: 0.5638554718840629
Validation loss: 2.392637073760858

Epoch: 5| Step: 10
Training loss: 0.4554469369994491
Validation loss: 2.348291885948302

Epoch: 448| Step: 0
Training loss: 0.3961893496743248
Validation loss: 2.373638786288778

Epoch: 5| Step: 1
Training loss: 0.521971828363688
Validation loss: 2.361635878209663

Epoch: 5| Step: 2
Training loss: 0.33228128779753807
Validation loss: 2.3118278171694753

Epoch: 5| Step: 3
Training loss: 0.5467353369984083
Validation loss: 2.3366690890128035

Epoch: 5| Step: 4
Training loss: 0.687864423747817
Validation loss: 2.2914447281687895

Epoch: 5| Step: 5
Training loss: 0.9672852178705496
Validation loss: 2.3138095714024516

Epoch: 5| Step: 6
Training loss: 0.6188073208777778
Validation loss: 2.339526080367324

Epoch: 5| Step: 7
Training loss: 0.3885889012701838
Validation loss: 2.330093050231599

Epoch: 5| Step: 8
Training loss: 0.5004607700136874
Validation loss: 2.34378610453262

Epoch: 5| Step: 9
Training loss: 0.3782377933907629
Validation loss: 2.3627352181455183

Epoch: 5| Step: 10
Training loss: 0.7204753650236679
Validation loss: 2.321969659844622

Epoch: 449| Step: 0
Training loss: 0.4584128859867448
Validation loss: 2.349240415000501

Epoch: 5| Step: 1
Training loss: 0.6316928377198666
Validation loss: 2.344606884148016

Epoch: 5| Step: 2
Training loss: 0.537964490418823
Validation loss: 2.3411431125305353

Epoch: 5| Step: 3
Training loss: 0.49425877602291174
Validation loss: 2.3649281196234946

Epoch: 5| Step: 4
Training loss: 0.6336356801788343
Validation loss: 2.36372197678314

Epoch: 5| Step: 5
Training loss: 0.6915001024244761
Validation loss: 2.3768579408007997

Epoch: 5| Step: 6
Training loss: 0.5531195925863143
Validation loss: 2.388819771163678

Epoch: 5| Step: 7
Training loss: 0.5761827112245699
Validation loss: 2.4106556609370147

Epoch: 5| Step: 8
Training loss: 0.5916389279735994
Validation loss: 2.402575394968835

Epoch: 5| Step: 9
Training loss: 0.7005568333183143
Validation loss: 2.4186149866858018

Epoch: 5| Step: 10
Training loss: 0.3199332713797636
Validation loss: 2.3850390954963627

Epoch: 450| Step: 0
Training loss: 0.6381985371481144
Validation loss: 2.4023726106676366

Epoch: 5| Step: 1
Training loss: 0.3348752459916382
Validation loss: 2.4141511838102585

Epoch: 5| Step: 2
Training loss: 0.4008490752296682
Validation loss: 2.4136254846617895

Epoch: 5| Step: 3
Training loss: 0.5454856116847485
Validation loss: 2.3802944268395234

Epoch: 5| Step: 4
Training loss: 0.48720788089680406
Validation loss: 2.3343388599951553

Epoch: 5| Step: 5
Training loss: 0.5184137185076326
Validation loss: 2.308663475808042

Epoch: 5| Step: 6
Training loss: 0.5559444692088022
Validation loss: 2.2816666292735426

Epoch: 5| Step: 7
Training loss: 0.6800005400178672
Validation loss: 2.2854775973321098

Epoch: 5| Step: 8
Training loss: 0.8813125222935656
Validation loss: 2.2897710630627994

Epoch: 5| Step: 9
Training loss: 0.6246030500615405
Validation loss: 2.3144160788199164

Epoch: 5| Step: 10
Training loss: 0.7104778270925998
Validation loss: 2.366579190771834

Epoch: 451| Step: 0
Training loss: 0.27566182195491584
Validation loss: 2.4233391767467123

Epoch: 5| Step: 1
Training loss: 0.7635960846192585
Validation loss: 2.5207169486501586

Epoch: 5| Step: 2
Training loss: 0.6338135842397821
Validation loss: 2.5500216472494293

Epoch: 5| Step: 3
Training loss: 0.5568622883931049
Validation loss: 2.473597434143881

Epoch: 5| Step: 4
Training loss: 0.5395248752088134
Validation loss: 2.4385661635046896

Epoch: 5| Step: 5
Training loss: 0.676073595438208
Validation loss: 2.311701610446074

Epoch: 5| Step: 6
Training loss: 0.9511718123355665
Validation loss: 2.29531172513748

Epoch: 5| Step: 7
Training loss: 0.7262108474788022
Validation loss: 2.3135299118590034

Epoch: 5| Step: 8
Training loss: 0.619207962177031
Validation loss: 2.301109493482631

Epoch: 5| Step: 9
Training loss: 0.5439083285402967
Validation loss: 2.3036472203748293

Epoch: 5| Step: 10
Training loss: 0.7646621956202603
Validation loss: 2.300127538209721

Epoch: 452| Step: 0
Training loss: 0.42895410545208446
Validation loss: 2.353863328416652

Epoch: 5| Step: 1
Training loss: 0.5414319691459744
Validation loss: 2.3802858876180686

Epoch: 5| Step: 2
Training loss: 0.5941372913314723
Validation loss: 2.389325184181284

Epoch: 5| Step: 3
Training loss: 0.38363188031596734
Validation loss: 2.4002789513009097

Epoch: 5| Step: 4
Training loss: 0.5970280655728804
Validation loss: 2.421796953979456

Epoch: 5| Step: 5
Training loss: 0.7209898422282265
Validation loss: 2.4458301086398935

Epoch: 5| Step: 6
Training loss: 0.5943179175145719
Validation loss: 2.422575613164394

Epoch: 5| Step: 7
Training loss: 0.6459668903280693
Validation loss: 2.3497889597430945

Epoch: 5| Step: 8
Training loss: 0.36247181700625697
Validation loss: 2.3087005354560834

Epoch: 5| Step: 9
Training loss: 0.7741465545467247
Validation loss: 2.289358023995717

Epoch: 5| Step: 10
Training loss: 0.8315901684091345
Validation loss: 2.2723375478691996

Epoch: 453| Step: 0
Training loss: 0.7057491501422323
Validation loss: 2.269213245208694

Epoch: 5| Step: 1
Training loss: 0.7696992332564702
Validation loss: 2.264572572383039

Epoch: 5| Step: 2
Training loss: 0.6816391821903381
Validation loss: 2.2537550816599716

Epoch: 5| Step: 3
Training loss: 0.3747652829255942
Validation loss: 2.2627974232266803

Epoch: 5| Step: 4
Training loss: 0.3420848178521554
Validation loss: 2.285672544273658

Epoch: 5| Step: 5
Training loss: 0.4009516251618739
Validation loss: 2.3090283587359384

Epoch: 5| Step: 6
Training loss: 0.42059098983370274
Validation loss: 2.350808450038088

Epoch: 5| Step: 7
Training loss: 0.7424106463217722
Validation loss: 2.366403415267523

Epoch: 5| Step: 8
Training loss: 0.5836448575561507
Validation loss: 2.3829245780516546

Epoch: 5| Step: 9
Training loss: 0.49950775115077195
Validation loss: 2.3936675049442235

Epoch: 5| Step: 10
Training loss: 0.5956794108689187
Validation loss: 2.379341317804437

Epoch: 454| Step: 0
Training loss: 0.9090565926945726
Validation loss: 2.4119272473591358

Epoch: 5| Step: 1
Training loss: 0.8281277350614474
Validation loss: 2.371285856294365

Epoch: 5| Step: 2
Training loss: 0.4271892575197825
Validation loss: 2.3972781044182314

Epoch: 5| Step: 3
Training loss: 0.49716076280882476
Validation loss: 2.3786360174652876

Epoch: 5| Step: 4
Training loss: 0.44959329664181374
Validation loss: 2.360512604601215

Epoch: 5| Step: 5
Training loss: 0.5951985207526478
Validation loss: 2.3429632593308103

Epoch: 5| Step: 6
Training loss: 0.5413094283993374
Validation loss: 2.343328206928668

Epoch: 5| Step: 7
Training loss: 0.36329726727358536
Validation loss: 2.358038784886803

Epoch: 5| Step: 8
Training loss: 0.4764204282518149
Validation loss: 2.3829582343276474

Epoch: 5| Step: 9
Training loss: 0.42192681312277697
Validation loss: 2.3925885292146782

Epoch: 5| Step: 10
Training loss: 0.5528098011112695
Validation loss: 2.392536308386904

Epoch: 455| Step: 0
Training loss: 0.5657549039768912
Validation loss: 2.4008184294549415

Epoch: 5| Step: 1
Training loss: 0.4383277385624162
Validation loss: 2.396636617071856

Epoch: 5| Step: 2
Training loss: 0.8623581866455405
Validation loss: 2.383415854521513

Epoch: 5| Step: 3
Training loss: 0.5029597893752478
Validation loss: 2.3608915239738177

Epoch: 5| Step: 4
Training loss: 0.3579874618748167
Validation loss: 2.331982475011579

Epoch: 5| Step: 5
Training loss: 0.599613400921058
Validation loss: 2.3107690116753816

Epoch: 5| Step: 6
Training loss: 0.459257685674358
Validation loss: 2.313465266160601

Epoch: 5| Step: 7
Training loss: 0.48799662114365056
Validation loss: 2.3162672369848822

Epoch: 5| Step: 8
Training loss: 0.7560299229982164
Validation loss: 2.329111838056354

Epoch: 5| Step: 9
Training loss: 0.489806699188139
Validation loss: 2.3297894387570146

Epoch: 5| Step: 10
Training loss: 0.6212449039810527
Validation loss: 2.3196361389175464

Epoch: 456| Step: 0
Training loss: 0.614862771812425
Validation loss: 2.3285545827663148

Epoch: 5| Step: 1
Training loss: 0.5248281027166889
Validation loss: 2.3548945921308806

Epoch: 5| Step: 2
Training loss: 0.40890446331259167
Validation loss: 2.34133771787807

Epoch: 5| Step: 3
Training loss: 0.672403659868577
Validation loss: 2.3674307195013644

Epoch: 5| Step: 4
Training loss: 0.709915852328563
Validation loss: 2.3983933591466773

Epoch: 5| Step: 5
Training loss: 0.556605421592757
Validation loss: 2.392200719832037

Epoch: 5| Step: 6
Training loss: 0.4883017268655566
Validation loss: 2.397149614063678

Epoch: 5| Step: 7
Training loss: 0.7494963703385733
Validation loss: 2.398146816108259

Epoch: 5| Step: 8
Training loss: 0.3984781132363019
Validation loss: 2.369379627268936

Epoch: 5| Step: 9
Training loss: 0.5778346750348167
Validation loss: 2.360690836465945

Epoch: 5| Step: 10
Training loss: 0.3379949397654931
Validation loss: 2.368476560284975

Epoch: 457| Step: 0
Training loss: 0.4622400758409339
Validation loss: 2.348020136260341

Epoch: 5| Step: 1
Training loss: 0.6152282714540993
Validation loss: 2.345076714742914

Epoch: 5| Step: 2
Training loss: 0.527734710444775
Validation loss: 2.369878197548021

Epoch: 5| Step: 3
Training loss: 0.5864020731101529
Validation loss: 2.38914884702305

Epoch: 5| Step: 4
Training loss: 0.6219266429141693
Validation loss: 2.395283146229181

Epoch: 5| Step: 5
Training loss: 0.4071245134225994
Validation loss: 2.388680012363023

Epoch: 5| Step: 6
Training loss: 0.28553339434529623
Validation loss: 2.3961109612227043

Epoch: 5| Step: 7
Training loss: 0.6293432245879772
Validation loss: 2.402688238584313

Epoch: 5| Step: 8
Training loss: 0.7619271017883773
Validation loss: 2.435721611345801

Epoch: 5| Step: 9
Training loss: 0.45942643973984365
Validation loss: 2.401793848824846

Epoch: 5| Step: 10
Training loss: 0.5010116594598711
Validation loss: 2.4305909606495684

Epoch: 458| Step: 0
Training loss: 0.718898716343832
Validation loss: 2.4368607361425427

Epoch: 5| Step: 1
Training loss: 0.722289409833811
Validation loss: 2.4118146127973046

Epoch: 5| Step: 2
Training loss: 0.4647946051255782
Validation loss: 2.3717877156216165

Epoch: 5| Step: 3
Training loss: 0.6392491149776868
Validation loss: 2.3907849851251086

Epoch: 5| Step: 4
Training loss: 0.5401383872550392
Validation loss: 2.3617338197449524

Epoch: 5| Step: 5
Training loss: 0.24190093591409662
Validation loss: 2.3926293420154465

Epoch: 5| Step: 6
Training loss: 0.4861234364385122
Validation loss: 2.365329283433099

Epoch: 5| Step: 7
Training loss: 0.47243374718291975
Validation loss: 2.378860492321123

Epoch: 5| Step: 8
Training loss: 0.524341429043835
Validation loss: 2.354541244203677

Epoch: 5| Step: 9
Training loss: 0.40288485094052695
Validation loss: 2.3524025705088123

Epoch: 5| Step: 10
Training loss: 0.3435191658224468
Validation loss: 2.3716639937730064

Epoch: 459| Step: 0
Training loss: 0.32263991843356854
Validation loss: 2.353689929701287

Epoch: 5| Step: 1
Training loss: 0.5740101493758909
Validation loss: 2.381336613509256

Epoch: 5| Step: 2
Training loss: 0.5943847826725255
Validation loss: 2.3829902484454277

Epoch: 5| Step: 3
Training loss: 0.5662708252115175
Validation loss: 2.37938239661831

Epoch: 5| Step: 4
Training loss: 0.45117245298406394
Validation loss: 2.3655469195131524

Epoch: 5| Step: 5
Training loss: 0.5663312401924647
Validation loss: 2.3995471474550594

Epoch: 5| Step: 6
Training loss: 0.7164606870313271
Validation loss: 2.3872053468247687

Epoch: 5| Step: 7
Training loss: 0.47261256812149455
Validation loss: 2.3916618109012737

Epoch: 5| Step: 8
Training loss: 0.45555044393592115
Validation loss: 2.3499699947839003

Epoch: 5| Step: 9
Training loss: 0.5012759973914176
Validation loss: 2.3754515798766045

Epoch: 5| Step: 10
Training loss: 0.44987822514167863
Validation loss: 2.3501679653027234

Epoch: 460| Step: 0
Training loss: 0.609447719440955
Validation loss: 2.3623846463334797

Epoch: 5| Step: 1
Training loss: 0.44645415743668154
Validation loss: 2.3537980058789176

Epoch: 5| Step: 2
Training loss: 0.5536983966248198
Validation loss: 2.3534520101104492

Epoch: 5| Step: 3
Training loss: 0.5857722748816467
Validation loss: 2.357881132987974

Epoch: 5| Step: 4
Training loss: 0.37676212432909423
Validation loss: 2.361018189896596

Epoch: 5| Step: 5
Training loss: 0.37880351453357164
Validation loss: 2.3503935245501615

Epoch: 5| Step: 6
Training loss: 0.6135175213383113
Validation loss: 2.358004500041412

Epoch: 5| Step: 7
Training loss: 0.6978507058207487
Validation loss: 2.3730339479028904

Epoch: 5| Step: 8
Training loss: 0.4204773179127194
Validation loss: 2.3645760642377205

Epoch: 5| Step: 9
Training loss: 0.32483726700501275
Validation loss: 2.363105060488182

Epoch: 5| Step: 10
Training loss: 0.5604044238127608
Validation loss: 2.340651555316433

Epoch: 461| Step: 0
Training loss: 0.503396419504229
Validation loss: 2.400591876596212

Epoch: 5| Step: 1
Training loss: 0.5740966407537397
Validation loss: 2.4091547924359826

Epoch: 5| Step: 2
Training loss: 0.8228117155599423
Validation loss: 2.383815001083684

Epoch: 5| Step: 3
Training loss: 0.5458748800418652
Validation loss: 2.360522117315969

Epoch: 5| Step: 4
Training loss: 0.4452402825941711
Validation loss: 2.390630798311365

Epoch: 5| Step: 5
Training loss: 0.2389421131842187
Validation loss: 2.3779802324975194

Epoch: 5| Step: 6
Training loss: 0.48892901369122815
Validation loss: 2.3480088292336525

Epoch: 5| Step: 7
Training loss: 0.4369840645165138
Validation loss: 2.36754598481654

Epoch: 5| Step: 8
Training loss: 0.3620880589800501
Validation loss: 2.3854875831220403

Epoch: 5| Step: 9
Training loss: 0.5440023998389885
Validation loss: 2.3519373676607223

Epoch: 5| Step: 10
Training loss: 0.4031436339219089
Validation loss: 2.3678089182973285

Epoch: 462| Step: 0
Training loss: 0.6031008779811272
Validation loss: 2.396645286834147

Epoch: 5| Step: 1
Training loss: 0.4378617868447221
Validation loss: 2.3720468569023345

Epoch: 5| Step: 2
Training loss: 0.4768864203069256
Validation loss: 2.3637551234207406

Epoch: 5| Step: 3
Training loss: 0.2972330769830033
Validation loss: 2.3979822236895614

Epoch: 5| Step: 4
Training loss: 0.48942598052991754
Validation loss: 2.421431088923663

Epoch: 5| Step: 5
Training loss: 0.7020098850608476
Validation loss: 2.393175371541955

Epoch: 5| Step: 6
Training loss: 0.41343000075040187
Validation loss: 2.38357117650274

Epoch: 5| Step: 7
Training loss: 0.519920662091085
Validation loss: 2.3895816262010716

Epoch: 5| Step: 8
Training loss: 0.5441078751259658
Validation loss: 2.3977297802647293

Epoch: 5| Step: 9
Training loss: 0.5409418599764547
Validation loss: 2.393326651716416

Epoch: 5| Step: 10
Training loss: 0.5700255416702247
Validation loss: 2.4161817046736367

Epoch: 463| Step: 0
Training loss: 0.48137337725615204
Validation loss: 2.4065814930565157

Epoch: 5| Step: 1
Training loss: 0.6449615660387051
Validation loss: 2.3749621312177696

Epoch: 5| Step: 2
Training loss: 0.4486289423176525
Validation loss: 2.3544723042998923

Epoch: 5| Step: 3
Training loss: 0.7167564193576498
Validation loss: 2.36785921161668

Epoch: 5| Step: 4
Training loss: 0.3277011813607805
Validation loss: 2.331693452268423

Epoch: 5| Step: 5
Training loss: 0.5024657544760218
Validation loss: 2.341452195069807

Epoch: 5| Step: 6
Training loss: 0.5798578582667359
Validation loss: 2.341262133563782

Epoch: 5| Step: 7
Training loss: 0.5062982430253725
Validation loss: 2.3418471007784603

Epoch: 5| Step: 8
Training loss: 0.36844897186823317
Validation loss: 2.3238322468057784

Epoch: 5| Step: 9
Training loss: 0.3991857683028632
Validation loss: 2.3331639251064313

Epoch: 5| Step: 10
Training loss: 0.320673065077762
Validation loss: 2.33459473792107

Epoch: 464| Step: 0
Training loss: 0.631959174989415
Validation loss: 2.3347303153667918

Epoch: 5| Step: 1
Training loss: 0.46424001066608045
Validation loss: 2.336486757319225

Epoch: 5| Step: 2
Training loss: 0.29401550215362626
Validation loss: 2.3292098665990673

Epoch: 5| Step: 3
Training loss: 0.5904187059154125
Validation loss: 2.3521375725970417

Epoch: 5| Step: 4
Training loss: 0.4719856170447011
Validation loss: 2.3617785361204047

Epoch: 5| Step: 5
Training loss: 0.47227188118828717
Validation loss: 2.365704684211095

Epoch: 5| Step: 6
Training loss: 0.622533987718392
Validation loss: 2.360875347590872

Epoch: 5| Step: 7
Training loss: 0.5911585320496577
Validation loss: 2.3734155593094814

Epoch: 5| Step: 8
Training loss: 0.30349451431049024
Validation loss: 2.3589314363868144

Epoch: 5| Step: 9
Training loss: 0.3697408408396913
Validation loss: 2.35638771149748

Epoch: 5| Step: 10
Training loss: 0.5973851206006586
Validation loss: 2.3455570083189974

Epoch: 465| Step: 0
Training loss: 0.4026825043568085
Validation loss: 2.34946467097784

Epoch: 5| Step: 1
Training loss: 0.20278657634381084
Validation loss: 2.3681763168608225

Epoch: 5| Step: 2
Training loss: 0.3784343100680313
Validation loss: 2.3674763699845642

Epoch: 5| Step: 3
Training loss: 0.4016314376851749
Validation loss: 2.3298377898064175

Epoch: 5| Step: 4
Training loss: 0.6014854332245311
Validation loss: 2.3464668365877217

Epoch: 5| Step: 5
Training loss: 0.4848078055400994
Validation loss: 2.354611643224551

Epoch: 5| Step: 6
Training loss: 0.6508698173054335
Validation loss: 2.357986821706233

Epoch: 5| Step: 7
Training loss: 0.5555159332795565
Validation loss: 2.4067161608190712

Epoch: 5| Step: 8
Training loss: 0.5921732898305624
Validation loss: 2.3575165270450054

Epoch: 5| Step: 9
Training loss: 0.6408994830986696
Validation loss: 2.360365153163115

Epoch: 5| Step: 10
Training loss: 0.46213548768689755
Validation loss: 2.396693048585981

Epoch: 466| Step: 0
Training loss: 0.5102456708179605
Validation loss: 2.3644878309799937

Epoch: 5| Step: 1
Training loss: 0.2240972402340995
Validation loss: 2.3562284568989242

Epoch: 5| Step: 2
Training loss: 0.6026958836485957
Validation loss: 2.3203225487589885

Epoch: 5| Step: 3
Training loss: 0.3494271277537905
Validation loss: 2.313989036272306

Epoch: 5| Step: 4
Training loss: 0.7404992024908723
Validation loss: 2.3269342732030247

Epoch: 5| Step: 5
Training loss: 0.4077562505288572
Validation loss: 2.3471714327459234

Epoch: 5| Step: 6
Training loss: 0.2565985042664455
Validation loss: 2.3346550930818215

Epoch: 5| Step: 7
Training loss: 0.5410499974979026
Validation loss: 2.3194827952497596

Epoch: 5| Step: 8
Training loss: 0.5416426072523884
Validation loss: 2.3513679090013357

Epoch: 5| Step: 9
Training loss: 0.5223774780923011
Validation loss: 2.3898863085805275

Epoch: 5| Step: 10
Training loss: 0.38318798568015366
Validation loss: 2.3655665394823067

Epoch: 467| Step: 0
Training loss: 0.5519696664457558
Validation loss: 2.3622302418146806

Epoch: 5| Step: 1
Training loss: 0.3099174358414448
Validation loss: 2.3776927842033944

Epoch: 5| Step: 2
Training loss: 0.45564565347502817
Validation loss: 2.350431973497513

Epoch: 5| Step: 3
Training loss: 0.38908111650286525
Validation loss: 2.3626668862537152

Epoch: 5| Step: 4
Training loss: 0.5859809350762942
Validation loss: 2.347278074134927

Epoch: 5| Step: 5
Training loss: 0.5943882673770381
Validation loss: 2.3630661467443743

Epoch: 5| Step: 6
Training loss: 0.4850004219269638
Validation loss: 2.3628300403451084

Epoch: 5| Step: 7
Training loss: 0.5181790012890699
Validation loss: 2.315000908370677

Epoch: 5| Step: 8
Training loss: 0.3491310278272787
Validation loss: 2.291492666610068

Epoch: 5| Step: 9
Training loss: 0.6641867801830713
Validation loss: 2.2803960537211885

Epoch: 5| Step: 10
Training loss: 0.36039262243048537
Validation loss: 2.274153444693945

Epoch: 468| Step: 0
Training loss: 0.41369178659212597
Validation loss: 2.27108689362334

Epoch: 5| Step: 1
Training loss: 0.5945010705173053
Validation loss: 2.3036098062189234

Epoch: 5| Step: 2
Training loss: 0.4923840387700573
Validation loss: 2.302497096795009

Epoch: 5| Step: 3
Training loss: 0.5220025163750632
Validation loss: 2.317799744157797

Epoch: 5| Step: 4
Training loss: 0.5484783646446839
Validation loss: 2.3158089771575256

Epoch: 5| Step: 5
Training loss: 0.4773366456197696
Validation loss: 2.3433492436850054

Epoch: 5| Step: 6
Training loss: 0.49452155587335517
Validation loss: 2.3404559618601737

Epoch: 5| Step: 7
Training loss: 0.4240482830849465
Validation loss: 2.3811914861981505

Epoch: 5| Step: 8
Training loss: 0.4538181199678167
Validation loss: 2.3699837198542446

Epoch: 5| Step: 9
Training loss: 0.5418327578190814
Validation loss: 2.35149186796537

Epoch: 5| Step: 10
Training loss: 0.4174662983591991
Validation loss: 2.3742754704871745

Epoch: 469| Step: 0
Training loss: 0.4386474004696503
Validation loss: 2.3625677154510734

Epoch: 5| Step: 1
Training loss: 0.6729567934085202
Validation loss: 2.3628197329430765

Epoch: 5| Step: 2
Training loss: 0.4596020539650783
Validation loss: 2.3326078428239425

Epoch: 5| Step: 3
Training loss: 0.600855374569063
Validation loss: 2.337142582185094

Epoch: 5| Step: 4
Training loss: 0.4777646302369014
Validation loss: 2.3426316533458027

Epoch: 5| Step: 5
Training loss: 0.516787230617179
Validation loss: 2.340916833896526

Epoch: 5| Step: 6
Training loss: 0.3313343588456901
Validation loss: 2.345732449757608

Epoch: 5| Step: 7
Training loss: 0.16685487444563143
Validation loss: 2.3457552354269717

Epoch: 5| Step: 8
Training loss: 0.5189170935972969
Validation loss: 2.3512928902555252

Epoch: 5| Step: 9
Training loss: 0.5140007619685154
Validation loss: 2.35401225275569

Epoch: 5| Step: 10
Training loss: 0.5124355275608984
Validation loss: 2.3547243950798844

Epoch: 470| Step: 0
Training loss: 0.2975152915943506
Validation loss: 2.354857489780277

Epoch: 5| Step: 1
Training loss: 0.3270447865731524
Validation loss: 2.378358132652259

Epoch: 5| Step: 2
Training loss: 0.6669040024018231
Validation loss: 2.3776154454456853

Epoch: 5| Step: 3
Training loss: 0.5791298664760504
Validation loss: 2.415338862387516

Epoch: 5| Step: 4
Training loss: 0.40224496313845187
Validation loss: 2.3839891196541716

Epoch: 5| Step: 5
Training loss: 0.4813406871214527
Validation loss: 2.380318544037574

Epoch: 5| Step: 6
Training loss: 0.3585501409538076
Validation loss: 2.3860804222782304

Epoch: 5| Step: 7
Training loss: 0.5979812087691643
Validation loss: 2.374451244106496

Epoch: 5| Step: 8
Training loss: 0.3803561480699114
Validation loss: 2.453473675284113

Epoch: 5| Step: 9
Training loss: 0.5965055970299485
Validation loss: 2.3851615205800205

Epoch: 5| Step: 10
Training loss: 0.418961904770728
Validation loss: 2.3954441783527667

Epoch: 471| Step: 0
Training loss: 0.5819381793066023
Validation loss: 2.381226381380635

Epoch: 5| Step: 1
Training loss: 0.40399538307337307
Validation loss: 2.3819658135813357

Epoch: 5| Step: 2
Training loss: 0.4320602965980917
Validation loss: 2.369336883347997

Epoch: 5| Step: 3
Training loss: 0.5059239408903916
Validation loss: 2.318070338590638

Epoch: 5| Step: 4
Training loss: 0.3673359996735808
Validation loss: 2.3452767172091824

Epoch: 5| Step: 5
Training loss: 0.4181194390296348
Validation loss: 2.3475106949911884

Epoch: 5| Step: 6
Training loss: 0.38568897121669954
Validation loss: 2.3363652973642224

Epoch: 5| Step: 7
Training loss: 0.6269317338092855
Validation loss: 2.3186248799493328

Epoch: 5| Step: 8
Training loss: 0.38794540679185024
Validation loss: 2.3479947739863873

Epoch: 5| Step: 9
Training loss: 0.6440608533294965
Validation loss: 2.3479123973872222

Epoch: 5| Step: 10
Training loss: 0.29921897559493604
Validation loss: 2.3155844731270676

Epoch: 472| Step: 0
Training loss: 0.5332444003831004
Validation loss: 2.3470114905231028

Epoch: 5| Step: 1
Training loss: 0.5143796157166308
Validation loss: 2.414002230827378

Epoch: 5| Step: 2
Training loss: 0.46966422256179424
Validation loss: 2.345618668917552

Epoch: 5| Step: 3
Training loss: 0.3863255785172548
Validation loss: 2.3551029590716555

Epoch: 5| Step: 4
Training loss: 0.6290017997233808
Validation loss: 2.368062153991482

Epoch: 5| Step: 5
Training loss: 0.39600230257973595
Validation loss: 2.3568695006007516

Epoch: 5| Step: 6
Training loss: 0.2361074789007838
Validation loss: 2.3664783709936876

Epoch: 5| Step: 7
Training loss: 0.5169305745222321
Validation loss: 2.341849017612789

Epoch: 5| Step: 8
Training loss: 0.2804481546602426
Validation loss: 2.3412551486611632

Epoch: 5| Step: 9
Training loss: 0.27931364049143026
Validation loss: 2.3319397344957

Epoch: 5| Step: 10
Training loss: 0.6737905961794982
Validation loss: 2.3274816788845745

Epoch: 473| Step: 0
Training loss: 0.2420177710974457
Validation loss: 2.3116627690560176

Epoch: 5| Step: 1
Training loss: 0.6121556345507002
Validation loss: 2.315686004195137

Epoch: 5| Step: 2
Training loss: 0.43707885226536697
Validation loss: 2.3243057318805103

Epoch: 5| Step: 3
Training loss: 0.48630564993894965
Validation loss: 2.33655399949601

Epoch: 5| Step: 4
Training loss: 0.41084480618145036
Validation loss: 2.3760814503750147

Epoch: 5| Step: 5
Training loss: 0.593158201126516
Validation loss: 2.39684428001092

Epoch: 5| Step: 6
Training loss: 0.43359218631496793
Validation loss: 2.3702024763436755

Epoch: 5| Step: 7
Training loss: 0.3903979404474773
Validation loss: 2.362623971109647

Epoch: 5| Step: 8
Training loss: 0.39921689938230137
Validation loss: 2.364634563488644

Epoch: 5| Step: 9
Training loss: 0.5842889865261642
Validation loss: 2.3557342383488287

Epoch: 5| Step: 10
Training loss: 0.4030851366604623
Validation loss: 2.3293926220621324

Epoch: 474| Step: 0
Training loss: 0.4300840108886203
Validation loss: 2.3566037409049994

Epoch: 5| Step: 1
Training loss: 0.2922504392959974
Validation loss: 2.340027627248092

Epoch: 5| Step: 2
Training loss: 0.3084082106043721
Validation loss: 2.3625942912190725

Epoch: 5| Step: 3
Training loss: 0.34571650850930885
Validation loss: 2.395449669620375

Epoch: 5| Step: 4
Training loss: 0.605265207840942
Validation loss: 2.4138633060970824

Epoch: 5| Step: 5
Training loss: 0.27720414261168586
Validation loss: 2.3614584075823357

Epoch: 5| Step: 6
Training loss: 0.5935897108855849
Validation loss: 2.401258766360865

Epoch: 5| Step: 7
Training loss: 0.5758981345390077
Validation loss: 2.3984566008003068

Epoch: 5| Step: 8
Training loss: 0.5932433828024221
Validation loss: 2.3887175016156035

Epoch: 5| Step: 9
Training loss: 0.4753806044965126
Validation loss: 2.3719043099364763

Epoch: 5| Step: 10
Training loss: 0.301253653777192
Validation loss: 2.3591881167105613

Epoch: 475| Step: 0
Training loss: 0.5242630156746357
Validation loss: 2.345496146726255

Epoch: 5| Step: 1
Training loss: 0.3761759637945153
Validation loss: 2.3662739978432734

Epoch: 5| Step: 2
Training loss: 0.4544274422134979
Validation loss: 2.362378308261803

Epoch: 5| Step: 3
Training loss: 0.5424046502063101
Validation loss: 2.3257626864079044

Epoch: 5| Step: 4
Training loss: 0.3448169470889731
Validation loss: 2.3595606722618925

Epoch: 5| Step: 5
Training loss: 0.4408540732216864
Validation loss: 2.3464136024054545

Epoch: 5| Step: 6
Training loss: 0.5979044529756211
Validation loss: 2.3493413994581176

Epoch: 5| Step: 7
Training loss: 0.32987169435600394
Validation loss: 2.346073588701725

Epoch: 5| Step: 8
Training loss: 0.619310542235291
Validation loss: 2.356218598263898

Epoch: 5| Step: 9
Training loss: 0.30924923006854665
Validation loss: 2.3499639554162375

Epoch: 5| Step: 10
Training loss: 0.29574540716556796
Validation loss: 2.3631888965205126

Epoch: 476| Step: 0
Training loss: 0.3454704255814379
Validation loss: 2.3629261422277095

Epoch: 5| Step: 1
Training loss: 0.3960552430104319
Validation loss: 2.3364887981480393

Epoch: 5| Step: 2
Training loss: 0.5486903713475778
Validation loss: 2.3607079105755684

Epoch: 5| Step: 3
Training loss: 0.5751781882050765
Validation loss: 2.3460774023495956

Epoch: 5| Step: 4
Training loss: 0.5582664170898449
Validation loss: 2.3150361877698136

Epoch: 5| Step: 5
Training loss: 0.2259004885220744
Validation loss: 2.356882349391257

Epoch: 5| Step: 6
Training loss: 0.6495801670208542
Validation loss: 2.3770570455153432

Epoch: 5| Step: 7
Training loss: 0.36023563494820815
Validation loss: 2.3387048697572483

Epoch: 5| Step: 8
Training loss: 0.2969138220449949
Validation loss: 2.3411015379492683

Epoch: 5| Step: 9
Training loss: 0.42259121956886075
Validation loss: 2.3478025144762897

Epoch: 5| Step: 10
Training loss: 0.36862887882560436
Validation loss: 2.3220129576005624

Epoch: 477| Step: 0
Training loss: 0.32046195939493793
Validation loss: 2.3573197614739017

Epoch: 5| Step: 1
Training loss: 0.3452167429999912
Validation loss: 2.3490722005100935

Epoch: 5| Step: 2
Training loss: 0.3969869388202201
Validation loss: 2.323848207365767

Epoch: 5| Step: 3
Training loss: 0.3685003914837459
Validation loss: 2.3439942121260335

Epoch: 5| Step: 4
Training loss: 0.4305268326359874
Validation loss: 2.3643756889304157

Epoch: 5| Step: 5
Training loss: 0.3842283457596782
Validation loss: 2.3700797739635324

Epoch: 5| Step: 6
Training loss: 0.5437082702145947
Validation loss: 2.3976958288070795

Epoch: 5| Step: 7
Training loss: 0.5987802544836335
Validation loss: 2.349789831459033

Epoch: 5| Step: 8
Training loss: 0.40559839296582184
Validation loss: 2.400229676940113

Epoch: 5| Step: 9
Training loss: 0.6383668596993491
Validation loss: 2.3553278770081367

Epoch: 5| Step: 10
Training loss: 0.33128670633020396
Validation loss: 2.3741791963185275

Epoch: 478| Step: 0
Training loss: 0.42486648986948805
Validation loss: 2.3640997576810134

Epoch: 5| Step: 1
Training loss: 0.27891903108007404
Validation loss: 2.343349912123229

Epoch: 5| Step: 2
Training loss: 0.5332753897522932
Validation loss: 2.3466119510699786

Epoch: 5| Step: 3
Training loss: 0.43808982463035634
Validation loss: 2.335548137135127

Epoch: 5| Step: 4
Training loss: 0.49120766124808257
Validation loss: 2.36276989981752

Epoch: 5| Step: 5
Training loss: 0.32503159442799373
Validation loss: 2.362241327748295

Epoch: 5| Step: 6
Training loss: 0.46500418002290483
Validation loss: 2.392812469236473

Epoch: 5| Step: 7
Training loss: 0.3341433275107692
Validation loss: 2.3738604371553844

Epoch: 5| Step: 8
Training loss: 0.5302779055243826
Validation loss: 2.3571456931047905

Epoch: 5| Step: 9
Training loss: 0.4547455845598017
Validation loss: 2.375061925956146

Epoch: 5| Step: 10
Training loss: 0.5133219930657434
Validation loss: 2.402918937623126

Epoch: 479| Step: 0
Training loss: 0.5996691894518825
Validation loss: 2.362360071492942

Epoch: 5| Step: 1
Training loss: 0.4092743975661415
Validation loss: 2.389253096549366

Epoch: 5| Step: 2
Training loss: 0.47517262697456697
Validation loss: 2.376995004904861

Epoch: 5| Step: 3
Training loss: 0.44480294638393714
Validation loss: 2.3664412249268807

Epoch: 5| Step: 4
Training loss: 0.4340379003827852
Validation loss: 2.343441457914403

Epoch: 5| Step: 5
Training loss: 0.4427640674139753
Validation loss: 2.306755534921905

Epoch: 5| Step: 6
Training loss: 0.3129553576692657
Validation loss: 2.321028389774324

Epoch: 5| Step: 7
Training loss: 0.3864613263853141
Validation loss: 2.2939875126096037

Epoch: 5| Step: 8
Training loss: 0.31790891032716834
Validation loss: 2.2972812144098023

Epoch: 5| Step: 9
Training loss: 0.43077859199044277
Validation loss: 2.3149522640434617

Epoch: 5| Step: 10
Training loss: 0.5690760338235471
Validation loss: 2.3243906943505563

Epoch: 480| Step: 0
Training loss: 0.5374137986723247
Validation loss: 2.308457745855835

Epoch: 5| Step: 1
Training loss: 0.44120882058279576
Validation loss: 2.33647005427532

Epoch: 5| Step: 2
Training loss: 0.3589840711523852
Validation loss: 2.314793935328378

Epoch: 5| Step: 3
Training loss: 0.42439158731665155
Validation loss: 2.3568770918650017

Epoch: 5| Step: 4
Training loss: 0.5242346771140218
Validation loss: 2.3659691323279803

Epoch: 5| Step: 5
Training loss: 0.4779954691187347
Validation loss: 2.345384063965716

Epoch: 5| Step: 6
Training loss: 0.2891779359802851
Validation loss: 2.3881659775248805

Epoch: 5| Step: 7
Training loss: 0.45387477338843546
Validation loss: 2.3791848862140053

Epoch: 5| Step: 8
Training loss: 0.2771915904907693
Validation loss: 2.4119070691562245

Epoch: 5| Step: 9
Training loss: 0.3655590919039665
Validation loss: 2.3967492156418664

Epoch: 5| Step: 10
Training loss: 0.5753827914800849
Validation loss: 2.3580606460399247

Epoch: 481| Step: 0
Training loss: 0.4140422024340313
Validation loss: 2.387234689589311

Epoch: 5| Step: 1
Training loss: 0.42843956493990254
Validation loss: 2.369009594003741

Epoch: 5| Step: 2
Training loss: 0.5993847255295639
Validation loss: 2.367239558761839

Epoch: 5| Step: 3
Training loss: 0.33252182790268386
Validation loss: 2.386803980508332

Epoch: 5| Step: 4
Training loss: 0.5136774157091119
Validation loss: 2.3853166230269163

Epoch: 5| Step: 5
Training loss: 0.5196233108526089
Validation loss: 2.35235867635629

Epoch: 5| Step: 6
Training loss: 0.2223971934504017
Validation loss: 2.378709955632212

Epoch: 5| Step: 7
Training loss: 0.48051274105986974
Validation loss: 2.3779958462040267

Epoch: 5| Step: 8
Training loss: 0.5162802492012764
Validation loss: 2.3723061930304152

Epoch: 5| Step: 9
Training loss: 0.32305023163939345
Validation loss: 2.372750256769893

Epoch: 5| Step: 10
Training loss: 0.23160592473799357
Validation loss: 2.372545887124814

Epoch: 482| Step: 0
Training loss: 0.5086785194550069
Validation loss: 2.3818969839826476

Epoch: 5| Step: 1
Training loss: 0.29379712294974
Validation loss: 2.3735978284060892

Epoch: 5| Step: 2
Training loss: 0.5931411934703136
Validation loss: 2.3632286440849533

Epoch: 5| Step: 3
Training loss: 0.18658891497244343
Validation loss: 2.396878129620922

Epoch: 5| Step: 4
Training loss: 0.30626894055398285
Validation loss: 2.3783414474554587

Epoch: 5| Step: 5
Training loss: 0.6355631352028592
Validation loss: 2.378201091743941

Epoch: 5| Step: 6
Training loss: 0.5301841534220357
Validation loss: 2.3875076362115357

Epoch: 5| Step: 7
Training loss: 0.4413287508287009
Validation loss: 2.385885107122725

Epoch: 5| Step: 8
Training loss: 0.2701140750421589
Validation loss: 2.3592009371167943

Epoch: 5| Step: 9
Training loss: 0.2945147729813065
Validation loss: 2.381782714556938

Epoch: 5| Step: 10
Training loss: 0.3854909344162588
Validation loss: 2.3612232842321546

Epoch: 483| Step: 0
Training loss: 0.5284671544124293
Validation loss: 2.3686055875905345

Epoch: 5| Step: 1
Training loss: 0.4569274262747642
Validation loss: 2.3464936963163567

Epoch: 5| Step: 2
Training loss: 0.41104338844558697
Validation loss: 2.364026932826704

Epoch: 5| Step: 3
Training loss: 0.49940619374842943
Validation loss: 2.3290821631430654

Epoch: 5| Step: 4
Training loss: 0.4537266157498261
Validation loss: 2.3699789284045907

Epoch: 5| Step: 5
Training loss: 0.27788498948640394
Validation loss: 2.3749749101912165

Epoch: 5| Step: 6
Training loss: 0.497572055443622
Validation loss: 2.3569107807283567

Epoch: 5| Step: 7
Training loss: 0.2764045231809958
Validation loss: 2.386436436441232

Epoch: 5| Step: 8
Training loss: 0.5601814487806731
Validation loss: 2.332997462348329

Epoch: 5| Step: 9
Training loss: 0.19021834358797357
Validation loss: 2.3356657156462077

Epoch: 5| Step: 10
Training loss: 0.13017235656262746
Validation loss: 2.3372065551592303

Epoch: 484| Step: 0
Training loss: 0.3577728424417175
Validation loss: 2.3117962625305055

Epoch: 5| Step: 1
Training loss: 0.34953051482162956
Validation loss: 2.3335333407361207

Epoch: 5| Step: 2
Training loss: 0.26029441189059954
Validation loss: 2.3348043674939696

Epoch: 5| Step: 3
Training loss: 0.4015538693402282
Validation loss: 2.335477997999238

Epoch: 5| Step: 4
Training loss: 0.502056215142207
Validation loss: 2.330628536598106

Epoch: 5| Step: 5
Training loss: 0.3972096316506675
Validation loss: 2.355525095749405

Epoch: 5| Step: 6
Training loss: 0.4670293061722307
Validation loss: 2.357649999109849

Epoch: 5| Step: 7
Training loss: 0.6129384145588868
Validation loss: 2.3554126456168154

Epoch: 5| Step: 8
Training loss: 0.41049946548436406
Validation loss: 2.350992852399471

Epoch: 5| Step: 9
Training loss: 0.48643967295218554
Validation loss: 2.378247592962419

Epoch: 5| Step: 10
Training loss: 0.4315181748362897
Validation loss: 2.3483693138079405

Epoch: 485| Step: 0
Training loss: 0.7058446210238627
Validation loss: 2.301941444420502

Epoch: 5| Step: 1
Training loss: 0.5102950230144379
Validation loss: 2.3217136802065417

Epoch: 5| Step: 2
Training loss: 0.5190086891718505
Validation loss: 2.308318522650756

Epoch: 5| Step: 3
Training loss: 0.39707196672041517
Validation loss: 2.3228538420444194

Epoch: 5| Step: 4
Training loss: 0.3259102348744615
Validation loss: 2.327342060647814

Epoch: 5| Step: 5
Training loss: 0.3784779950186748
Validation loss: 2.3335236806475446

Epoch: 5| Step: 6
Training loss: 0.23584759148612733
Validation loss: 2.345127106403166

Epoch: 5| Step: 7
Training loss: 0.3973490864601257
Validation loss: 2.3749400456734997

Epoch: 5| Step: 8
Training loss: 0.3888101763009688
Validation loss: 2.394083890073914

Epoch: 5| Step: 9
Training loss: 0.424997150187194
Validation loss: 2.409405872297262

Epoch: 5| Step: 10
Training loss: 0.29980092248198936
Validation loss: 2.393864135283066

Epoch: 486| Step: 0
Training loss: 0.3481863566523473
Validation loss: 2.3916144942849162

Epoch: 5| Step: 1
Training loss: 0.2533503094797181
Validation loss: 2.3756293600108824

Epoch: 5| Step: 2
Training loss: 0.3290505185712824
Validation loss: 2.366410919613743

Epoch: 5| Step: 3
Training loss: 0.49249386713401766
Validation loss: 2.3648117610663966

Epoch: 5| Step: 4
Training loss: 0.37459783049009676
Validation loss: 2.349985670230614

Epoch: 5| Step: 5
Training loss: 0.49249318636136047
Validation loss: 2.3313604758713447

Epoch: 5| Step: 6
Training loss: 0.4210738239280286
Validation loss: 2.3249356660202003

Epoch: 5| Step: 7
Training loss: 0.5401506636300072
Validation loss: 2.3221333449998487

Epoch: 5| Step: 8
Training loss: 0.33537577084592424
Validation loss: 2.2868622562212653

Epoch: 5| Step: 9
Training loss: 0.438438057005264
Validation loss: 2.314144975114044

Epoch: 5| Step: 10
Training loss: 0.7144349393621013
Validation loss: 2.3045212218666387

Epoch: 487| Step: 0
Training loss: 0.4710124570379685
Validation loss: 2.316978947535852

Epoch: 5| Step: 1
Training loss: 0.5845504109888326
Validation loss: 2.3213241690249062

Epoch: 5| Step: 2
Training loss: 0.34540147066722676
Validation loss: 2.3246552435686163

Epoch: 5| Step: 3
Training loss: 0.532000656480671
Validation loss: 2.3326332844744173

Epoch: 5| Step: 4
Training loss: 0.4725758665475154
Validation loss: 2.3061934072818198

Epoch: 5| Step: 5
Training loss: 0.39081669872010555
Validation loss: 2.3112306744641327

Epoch: 5| Step: 6
Training loss: 0.6339661008559768
Validation loss: 2.380056431353713

Epoch: 5| Step: 7
Training loss: 0.4764461218894369
Validation loss: 2.3461088488635484

Epoch: 5| Step: 8
Training loss: 0.30559713343869277
Validation loss: 2.389831415540322

Epoch: 5| Step: 9
Training loss: 0.4318963066012487
Validation loss: 2.3524505428718405

Epoch: 5| Step: 10
Training loss: 0.36998939824380483
Validation loss: 2.416120415105154

Epoch: 488| Step: 0
Training loss: 0.5216602785990914
Validation loss: 2.434093517188694

Epoch: 5| Step: 1
Training loss: 0.46516433047604694
Validation loss: 2.4679574313365467

Epoch: 5| Step: 2
Training loss: 0.56613497321537
Validation loss: 2.427041241730047

Epoch: 5| Step: 3
Training loss: 0.36441985506910185
Validation loss: 2.4081644391233707

Epoch: 5| Step: 4
Training loss: 0.45172724045196766
Validation loss: 2.3229295562941283

Epoch: 5| Step: 5
Training loss: 0.44242703719902243
Validation loss: 2.3323938171006082

Epoch: 5| Step: 6
Training loss: 0.39184650171501567
Validation loss: 2.292858026281831

Epoch: 5| Step: 7
Training loss: 0.5721351292475895
Validation loss: 2.2331358673848043

Epoch: 5| Step: 8
Training loss: 0.4204336020282024
Validation loss: 2.238546227960152

Epoch: 5| Step: 9
Training loss: 0.25353064999485286
Validation loss: 2.2703901031252838

Epoch: 5| Step: 10
Training loss: 0.473214631453231
Validation loss: 2.2828721164995778

Epoch: 489| Step: 0
Training loss: 0.3596974253341481
Validation loss: 2.2778209818826025

Epoch: 5| Step: 1
Training loss: 0.29020212387037975
Validation loss: 2.2791619611036404

Epoch: 5| Step: 2
Training loss: 0.5845148745325517
Validation loss: 2.300466525873782

Epoch: 5| Step: 3
Training loss: 0.46597797596646967
Validation loss: 2.3358763806358134

Epoch: 5| Step: 4
Training loss: 0.45097625917446793
Validation loss: 2.3403807718913057

Epoch: 5| Step: 5
Training loss: 0.5616794800593826
Validation loss: 2.3422949821396744

Epoch: 5| Step: 6
Training loss: 0.32669932725003403
Validation loss: 2.3680868683118264

Epoch: 5| Step: 7
Training loss: 0.41546569438612646
Validation loss: 2.3254651786645804

Epoch: 5| Step: 8
Training loss: 0.37274603172021814
Validation loss: 2.3627447132315313

Epoch: 5| Step: 9
Training loss: 0.43555588990876337
Validation loss: 2.300472675126536

Epoch: 5| Step: 10
Training loss: 0.403262450568161
Validation loss: 2.341647133825846

Epoch: 490| Step: 0
Training loss: 0.22985329320974385
Validation loss: 2.3194568733503087

Epoch: 5| Step: 1
Training loss: 0.525474825213406
Validation loss: 2.3403300458049605

Epoch: 5| Step: 2
Training loss: 0.4827783479926182
Validation loss: 2.349703843143254

Epoch: 5| Step: 3
Training loss: 0.3107657231229974
Validation loss: 2.3912041890311317

Epoch: 5| Step: 4
Training loss: 0.4829821402780127
Validation loss: 2.3647146321786394

Epoch: 5| Step: 5
Training loss: 0.2693686340270179
Validation loss: 2.3452905318668265

Epoch: 5| Step: 6
Training loss: 0.4018894704939553
Validation loss: 2.3609387863493487

Epoch: 5| Step: 7
Training loss: 0.5894190794236811
Validation loss: 2.3675490881941696

Epoch: 5| Step: 8
Training loss: 0.22429943261304378
Validation loss: 2.3501321366216406

Epoch: 5| Step: 9
Training loss: 0.4918260761102815
Validation loss: 2.35741438880063

Epoch: 5| Step: 10
Training loss: 0.3781941594962422
Validation loss: 2.365466877369585

Epoch: 491| Step: 0
Training loss: 0.2174305204563511
Validation loss: 2.3599072623172956

Epoch: 5| Step: 1
Training loss: 0.5585952438654631
Validation loss: 2.3680941186015825

Epoch: 5| Step: 2
Training loss: 0.45141576805128586
Validation loss: 2.342035987901551

Epoch: 5| Step: 3
Training loss: 0.3242564007142783
Validation loss: 2.370836638262998

Epoch: 5| Step: 4
Training loss: 0.23799693233151853
Validation loss: 2.346342841596067

Epoch: 5| Step: 5
Training loss: 0.6388688090066791
Validation loss: 2.3653007316397665

Epoch: 5| Step: 6
Training loss: 0.34688683352175265
Validation loss: 2.32015595139839

Epoch: 5| Step: 7
Training loss: 0.32259461920363464
Validation loss: 2.3138965191292846

Epoch: 5| Step: 8
Training loss: 0.513200260548663
Validation loss: 2.2972428305856605

Epoch: 5| Step: 9
Training loss: 0.40092161371597285
Validation loss: 2.3197820283635107

Epoch: 5| Step: 10
Training loss: 0.19103557349887698
Validation loss: 2.3021571564622216

Epoch: 492| Step: 0
Training loss: 0.3016425718231332
Validation loss: 2.2942660936486794

Epoch: 5| Step: 1
Training loss: 0.41322347817697797
Validation loss: 2.319235601961015

Epoch: 5| Step: 2
Training loss: 0.507832277353005
Validation loss: 2.3275178837720527

Epoch: 5| Step: 3
Training loss: 0.37977451457668787
Validation loss: 2.328784953423491

Epoch: 5| Step: 4
Training loss: 0.512990608551364
Validation loss: 2.3322907984938976

Epoch: 5| Step: 5
Training loss: 0.2793840259015653
Validation loss: 2.311065065666636

Epoch: 5| Step: 6
Training loss: 0.20930320270252736
Validation loss: 2.3313041970808728

Epoch: 5| Step: 7
Training loss: 0.514563797825743
Validation loss: 2.374740951304852

Epoch: 5| Step: 8
Training loss: 0.24702294841814337
Validation loss: 2.3420363277811957

Epoch: 5| Step: 9
Training loss: 0.4576226996473666
Validation loss: 2.3666345624755243

Epoch: 5| Step: 10
Training loss: 0.4146035276539375
Validation loss: 2.3195591710446424

Epoch: 493| Step: 0
Training loss: 0.3661996051306499
Validation loss: 2.3336912834997463

Epoch: 5| Step: 1
Training loss: 0.38589640564609984
Validation loss: 2.319368101388115

Epoch: 5| Step: 2
Training loss: 0.32165666322932673
Validation loss: 2.34755953939563

Epoch: 5| Step: 3
Training loss: 0.49345694428123615
Validation loss: 2.334641705787694

Epoch: 5| Step: 4
Training loss: 0.41196106325571435
Validation loss: 2.3066867672566467

Epoch: 5| Step: 5
Training loss: 0.34283269603636324
Validation loss: 2.3351337497250086

Epoch: 5| Step: 6
Training loss: 0.29879588532908546
Validation loss: 2.32951019211672

Epoch: 5| Step: 7
Training loss: 0.5737817879308587
Validation loss: 2.3691722425895607

Epoch: 5| Step: 8
Training loss: 0.48226884584696966
Validation loss: 2.3267537830630416

Epoch: 5| Step: 9
Training loss: 0.28635443479391964
Validation loss: 2.3461336185153

Epoch: 5| Step: 10
Training loss: 0.30600787439530486
Validation loss: 2.372707872995649

Epoch: 494| Step: 0
Training loss: 0.3742930185290112
Validation loss: 2.3530886070414625

Epoch: 5| Step: 1
Training loss: 0.34046836979053935
Validation loss: 2.3077100019312997

Epoch: 5| Step: 2
Training loss: 0.39719010482041994
Validation loss: 2.336463318382207

Epoch: 5| Step: 3
Training loss: 0.42257124350938086
Validation loss: 2.3222236296596868

Epoch: 5| Step: 4
Training loss: 0.3764082572949997
Validation loss: 2.342379692131246

Epoch: 5| Step: 5
Training loss: 0.257429488652678
Validation loss: 2.347417220870518

Epoch: 5| Step: 6
Training loss: 0.40773593139936126
Validation loss: 2.3415946566272474

Epoch: 5| Step: 7
Training loss: 0.3997475647103645
Validation loss: 2.3248213740516186

Epoch: 5| Step: 8
Training loss: 0.5597679494848125
Validation loss: 2.3235941341878608

Epoch: 5| Step: 9
Training loss: 0.339378828164107
Validation loss: 2.359589589033657

Epoch: 5| Step: 10
Training loss: 0.2752830213987112
Validation loss: 2.3676170290552467

Epoch: 495| Step: 0
Training loss: 0.5713427917776224
Validation loss: 2.3501368987206224

Epoch: 5| Step: 1
Training loss: 0.27148571974606533
Validation loss: 2.338455257431312

Epoch: 5| Step: 2
Training loss: 0.3712577858824494
Validation loss: 2.315917957126865

Epoch: 5| Step: 3
Training loss: 0.3167763888018161
Validation loss: 2.334330471700426

Epoch: 5| Step: 4
Training loss: 0.2848412066757818
Validation loss: 2.3397451551144646

Epoch: 5| Step: 5
Training loss: 0.2935175523854572
Validation loss: 2.2960389014657983

Epoch: 5| Step: 6
Training loss: 0.5243921825881039
Validation loss: 2.3519201377733463

Epoch: 5| Step: 7
Training loss: 0.17875043505502322
Validation loss: 2.3443982787139803

Epoch: 5| Step: 8
Training loss: 0.2677328539477582
Validation loss: 2.336086459816641

Epoch: 5| Step: 9
Training loss: 0.5675811158407951
Validation loss: 2.33248207353312

Epoch: 5| Step: 10
Training loss: 0.33909433320909094
Validation loss: 2.338447665564774

Epoch: 496| Step: 0
Training loss: 0.4010312235905108
Validation loss: 2.348975781759123

Epoch: 5| Step: 1
Training loss: 0.36312930713535047
Validation loss: 2.344005892604048

Epoch: 5| Step: 2
Training loss: 0.1599569883778983
Validation loss: 2.344065916584906

Epoch: 5| Step: 3
Training loss: 0.4405970794543277
Validation loss: 2.360524223162357

Epoch: 5| Step: 4
Training loss: 0.5115594397507506
Validation loss: 2.3541768391707305

Epoch: 5| Step: 5
Training loss: 0.31756790632673515
Validation loss: 2.360628111061832

Epoch: 5| Step: 6
Training loss: 0.3417332508270469
Validation loss: 2.3501005323153334

Epoch: 5| Step: 7
Training loss: 0.28023766744618767
Validation loss: 2.3453167902044436

Epoch: 5| Step: 8
Training loss: 0.44078259591942065
Validation loss: 2.3403192767217194

Epoch: 5| Step: 9
Training loss: 0.23855862342057368
Validation loss: 2.3710150725823773

Epoch: 5| Step: 10
Training loss: 0.5324548354270418
Validation loss: 2.3565977579727657

Epoch: 497| Step: 0
Training loss: 0.3057249940828988
Validation loss: 2.339404963958309

Epoch: 5| Step: 1
Training loss: 0.42646999823353404
Validation loss: 2.3694717625826316

Epoch: 5| Step: 2
Training loss: 0.32842752724632174
Validation loss: 2.364393316514924

Epoch: 5| Step: 3
Training loss: 0.4436666961168833
Validation loss: 2.3497775139409947

Epoch: 5| Step: 4
Training loss: 0.3841933821548548
Validation loss: 2.3369777721444738

Epoch: 5| Step: 5
Training loss: 0.39368601233671685
Validation loss: 2.3454306545504333

Epoch: 5| Step: 6
Training loss: 0.245843631554276
Validation loss: 2.353643164950779

Epoch: 5| Step: 7
Training loss: 0.22576994224136174
Validation loss: 2.37754845074045

Epoch: 5| Step: 8
Training loss: 0.48339427599416096
Validation loss: 2.35657133895301

Epoch: 5| Step: 9
Training loss: 0.4378068392902947
Validation loss: 2.3395264008872965

Epoch: 5| Step: 10
Training loss: 0.4303367391559134
Validation loss: 2.366413504474709

Epoch: 498| Step: 0
Training loss: 0.41432753663651195
Validation loss: 2.3436075223323143

Epoch: 5| Step: 1
Training loss: 0.3617812743228543
Validation loss: 2.315597906384971

Epoch: 5| Step: 2
Training loss: 0.42053564593471054
Validation loss: 2.345965004224431

Epoch: 5| Step: 3
Training loss: 0.36591198735353514
Validation loss: 2.329072797195237

Epoch: 5| Step: 4
Training loss: 0.4067955022634514
Validation loss: 2.301832801758799

Epoch: 5| Step: 5
Training loss: 0.36576498726301904
Validation loss: 2.2759751872206286

Epoch: 5| Step: 6
Training loss: 0.3651062847879582
Validation loss: 2.2934560928514496

Epoch: 5| Step: 7
Training loss: 0.30159721915847
Validation loss: 2.2729962344306727

Epoch: 5| Step: 8
Training loss: 0.24606348790190155
Validation loss: 2.3228551807834905

Epoch: 5| Step: 9
Training loss: 0.3868784333971842
Validation loss: 2.3198562217087972

Epoch: 5| Step: 10
Training loss: 0.4232997501311273
Validation loss: 2.311019416281375

Epoch: 499| Step: 0
Training loss: 0.3852923704026571
Validation loss: 2.35450905232028

Epoch: 5| Step: 1
Training loss: 0.372619523931765
Validation loss: 2.3721967159973443

Epoch: 5| Step: 2
Training loss: 0.42725953871144207
Validation loss: 2.3478475518705406

Epoch: 5| Step: 3
Training loss: 0.4823783051742561
Validation loss: 2.3675053064795977

Epoch: 5| Step: 4
Training loss: 0.19743885328065142
Validation loss: 2.346277247400427

Epoch: 5| Step: 5
Training loss: 0.3882442978712259
Validation loss: 2.3856354719799135

Epoch: 5| Step: 6
Training loss: 0.3658779003235576
Validation loss: 2.3924787796152165

Epoch: 5| Step: 7
Training loss: 0.38483846526828874
Validation loss: 2.4191457570221018

Epoch: 5| Step: 8
Training loss: 0.2842043574266254
Validation loss: 2.346488631836955

Epoch: 5| Step: 9
Training loss: 0.4166339881321154
Validation loss: 2.3907017313142735

Epoch: 5| Step: 10
Training loss: 0.20414436840562486
Validation loss: 2.3775975897203536

Epoch: 500| Step: 0
Training loss: 0.4458879299989362
Validation loss: 2.4073519858196843

Epoch: 5| Step: 1
Training loss: 0.36552839633179623
Validation loss: 2.350394164807562

Epoch: 5| Step: 2
Training loss: 0.5055682843420091
Validation loss: 2.358335080420262

Epoch: 5| Step: 3
Training loss: 0.23525956441203977
Validation loss: 2.3209674400194795

Epoch: 5| Step: 4
Training loss: 0.37701079564865153
Validation loss: 2.3666920386581682

Epoch: 5| Step: 5
Training loss: 0.2350331047384601
Validation loss: 2.303406484693691

Epoch: 5| Step: 6
Training loss: 0.41007678760812666
Validation loss: 2.3290749424838273

Epoch: 5| Step: 7
Training loss: 0.4255656475186604
Validation loss: 2.3305831560047268

Epoch: 5| Step: 8
Training loss: 0.17006982194313783
Validation loss: 2.318364034834406

Epoch: 5| Step: 9
Training loss: 0.2214513770925167
Validation loss: 2.3418849106205664

Epoch: 5| Step: 10
Training loss: 0.40868283790347915
Validation loss: 2.387121830704533

Epoch: 501| Step: 0
Training loss: 0.405764234330772
Validation loss: 2.360167113617143

Epoch: 5| Step: 1
Training loss: 0.30830884408784165
Validation loss: 2.364286249480434

Epoch: 5| Step: 2
Training loss: 0.437047281363332
Validation loss: 2.354675404250381

Epoch: 5| Step: 3
Training loss: 0.20345421851294712
Validation loss: 2.37467749154055

Epoch: 5| Step: 4
Training loss: 0.39671322837133133
Validation loss: 2.332869103025937

Epoch: 5| Step: 5
Training loss: 0.33295453671820213
Validation loss: 2.3478469917201163

Epoch: 5| Step: 6
Training loss: 0.4582201987855464
Validation loss: 2.345244659413095

Epoch: 5| Step: 7
Training loss: 0.3244234840453479
Validation loss: 2.3559455027896736

Epoch: 5| Step: 8
Training loss: 0.32542822346983596
Validation loss: 2.349504454315453

Epoch: 5| Step: 9
Training loss: 0.43580272669510317
Validation loss: 2.3241547137695835

Epoch: 5| Step: 10
Training loss: 0.27115530200232885
Validation loss: 2.3614093835714143

Epoch: 502| Step: 0
Training loss: 0.33706190762997407
Validation loss: 2.386289227849181

Epoch: 5| Step: 1
Training loss: 0.3865054727305038
Validation loss: 2.3622605953352633

Epoch: 5| Step: 2
Training loss: 0.5210952163973054
Validation loss: 2.3951155312652377

Epoch: 5| Step: 3
Training loss: 0.2954637715259648
Validation loss: 2.379652924148746

Epoch: 5| Step: 4
Training loss: 0.38965773033590856
Validation loss: 2.4068102195781376

Epoch: 5| Step: 5
Training loss: 0.28666483920553554
Validation loss: 2.375723457682233

Epoch: 5| Step: 6
Training loss: 0.25222290735903247
Validation loss: 2.3855794559195242

Epoch: 5| Step: 7
Training loss: 0.24980527774839484
Validation loss: 2.332191047780135

Epoch: 5| Step: 8
Training loss: 0.28031711038733953
Validation loss: 2.375432149746246

Epoch: 5| Step: 9
Training loss: 0.47600510315603844
Validation loss: 2.362341840009355

Epoch: 5| Step: 10
Training loss: 0.3812212081105703
Validation loss: 2.367111804279446

Epoch: 503| Step: 0
Training loss: 0.35510860266152294
Validation loss: 2.368308902392288

Epoch: 5| Step: 1
Training loss: 0.19450350107729167
Validation loss: 2.3675336633060446

Epoch: 5| Step: 2
Training loss: 0.5298779946827747
Validation loss: 2.3567527101769783

Epoch: 5| Step: 3
Training loss: 0.2465756481590868
Validation loss: 2.3754682915772074

Epoch: 5| Step: 4
Training loss: 0.12487062822551626
Validation loss: 2.3398083066764737

Epoch: 5| Step: 5
Training loss: 0.33565237453998215
Validation loss: 2.3568441052021667

Epoch: 5| Step: 6
Training loss: 0.3780478556415904
Validation loss: 2.380204011423978

Epoch: 5| Step: 7
Training loss: 0.3426653699796228
Validation loss: 2.368058923540431

Epoch: 5| Step: 8
Training loss: 0.32145060736188946
Validation loss: 2.3586782192463294

Epoch: 5| Step: 9
Training loss: 0.4310691468095704
Validation loss: 2.3575503546597094

Epoch: 5| Step: 10
Training loss: 0.37548407464219574
Validation loss: 2.371418066895303

Epoch: 504| Step: 0
Training loss: 0.2035750575058856
Validation loss: 2.359089953208498

Epoch: 5| Step: 1
Training loss: 0.3007895109355056
Validation loss: 2.4158322586045515

Epoch: 5| Step: 2
Training loss: 0.5233496407177152
Validation loss: 2.4091404831113548

Epoch: 5| Step: 3
Training loss: 0.2105035733794049
Validation loss: 2.368141176878354

Epoch: 5| Step: 4
Training loss: 0.3705683552650488
Validation loss: 2.3661630642655185

Epoch: 5| Step: 5
Training loss: 0.4468145969889667
Validation loss: 2.377004715354932

Epoch: 5| Step: 6
Training loss: 0.33755502958600664
Validation loss: 2.3788950631047197

Epoch: 5| Step: 7
Training loss: 0.39601396739053657
Validation loss: 2.334023969666849

Epoch: 5| Step: 8
Training loss: 0.2681620276166222
Validation loss: 2.3748065511332217

Epoch: 5| Step: 9
Training loss: 0.3275280244863349
Validation loss: 2.3436154185387292

Epoch: 5| Step: 10
Training loss: 0.2836466374749534
Validation loss: 2.3274941430341385

Epoch: 505| Step: 0
Training loss: 0.3044510437363457
Validation loss: 2.304887182095909

Epoch: 5| Step: 1
Training loss: 0.42561946209905227
Validation loss: 2.329709028611111

Epoch: 5| Step: 2
Training loss: 0.2835608492175341
Validation loss: 2.3390077760930312

Epoch: 5| Step: 3
Training loss: 0.23430971189963176
Validation loss: 2.386489931578815

Epoch: 5| Step: 4
Training loss: 0.2971739267885847
Validation loss: 2.3710923822740977

Epoch: 5| Step: 5
Training loss: 0.46812210945388005
Validation loss: 2.3944454476513393

Epoch: 5| Step: 6
Training loss: 0.364482084475025
Validation loss: 2.3784909253130704

Epoch: 5| Step: 7
Training loss: 0.16833732332227566
Validation loss: 2.339457397677297

Epoch: 5| Step: 8
Training loss: 0.36083625099964206
Validation loss: 2.3992926723870673

Epoch: 5| Step: 9
Training loss: 0.2836008107801262
Validation loss: 2.363272025011432

Epoch: 5| Step: 10
Training loss: 0.44575154261340844
Validation loss: 2.371358319306353

Epoch: 506| Step: 0
Training loss: 0.29008650471989206
Validation loss: 2.3882597395838805

Epoch: 5| Step: 1
Training loss: 0.35220777844163764
Validation loss: 2.3591351674122265

Epoch: 5| Step: 2
Training loss: 0.45312315841826745
Validation loss: 2.345026571255021

Epoch: 5| Step: 3
Training loss: 0.28026170074664025
Validation loss: 2.316788142836421

Epoch: 5| Step: 4
Training loss: 0.3771098507818299
Validation loss: 2.341658444200949

Epoch: 5| Step: 5
Training loss: 0.1995724268719318
Validation loss: 2.3078636901640444

Epoch: 5| Step: 6
Training loss: 0.22650509139837482
Validation loss: 2.321802740662376

Epoch: 5| Step: 7
Training loss: 0.2746190021938188
Validation loss: 2.306990868286356

Epoch: 5| Step: 8
Training loss: 0.44330620131729864
Validation loss: 2.3366432584802754

Epoch: 5| Step: 9
Training loss: 0.4863002263535168
Validation loss: 2.321298858541701

Epoch: 5| Step: 10
Training loss: 0.22589357050600503
Validation loss: 2.35692486982251

Epoch: 507| Step: 0
Training loss: 0.34221201072942425
Validation loss: 2.3228261731259736

Epoch: 5| Step: 1
Training loss: 0.202560088593802
Validation loss: 2.3525704618716357

Epoch: 5| Step: 2
Training loss: 0.3657153018064252
Validation loss: 2.368467856685129

Epoch: 5| Step: 3
Training loss: 0.4218267307218181
Validation loss: 2.339543972163308

Epoch: 5| Step: 4
Training loss: 0.08284906747326423
Validation loss: 2.3396918633235515

Epoch: 5| Step: 5
Training loss: 0.4137689521574821
Validation loss: 2.342666918530773

Epoch: 5| Step: 6
Training loss: 0.4437749822058585
Validation loss: 2.329348316322694

Epoch: 5| Step: 7
Training loss: 0.2855490239554349
Validation loss: 2.3275667908674524

Epoch: 5| Step: 8
Training loss: 0.35974079671835246
Validation loss: 2.3199365689103804

Epoch: 5| Step: 9
Training loss: 0.2450288788284604
Validation loss: 2.344477949954573

Epoch: 5| Step: 10
Training loss: 0.37605274964306107
Validation loss: 2.3371110833111146

Epoch: 508| Step: 0
Training loss: 0.23369089262826592
Validation loss: 2.349688187637504

Epoch: 5| Step: 1
Training loss: 0.18134690193672637
Validation loss: 2.3520031696921446

Epoch: 5| Step: 2
Training loss: 0.3914408365832545
Validation loss: 2.3737063711362314

Epoch: 5| Step: 3
Training loss: 0.4236370306301857
Validation loss: 2.379557696035877

Epoch: 5| Step: 4
Training loss: 0.27775759110347903
Validation loss: 2.356740390977788

Epoch: 5| Step: 5
Training loss: 0.24566002120474215
Validation loss: 2.390268411676177

Epoch: 5| Step: 6
Training loss: 0.28160295591672396
Validation loss: 2.3664994283697354

Epoch: 5| Step: 7
Training loss: 0.2682265756846103
Validation loss: 2.337504466970915

Epoch: 5| Step: 8
Training loss: 0.35980431165417753
Validation loss: 2.322667587554645

Epoch: 5| Step: 9
Training loss: 0.45480670939317724
Validation loss: 2.348783626561816

Epoch: 5| Step: 10
Training loss: 0.4268380445398841
Validation loss: 2.3494866970197443

Epoch: 509| Step: 0
Training loss: 0.3279624945274353
Validation loss: 2.3552752349524386

Epoch: 5| Step: 1
Training loss: 0.28730996578925355
Validation loss: 2.3306532711271597

Epoch: 5| Step: 2
Training loss: 0.37931561723283996
Validation loss: 2.3503719683887425

Epoch: 5| Step: 3
Training loss: 0.3592797028613683
Validation loss: 2.3569172281336668

Epoch: 5| Step: 4
Training loss: 0.2899945414374725
Validation loss: 2.3404613663576295

Epoch: 5| Step: 5
Training loss: 0.4190340459438588
Validation loss: 2.345955854298979

Epoch: 5| Step: 6
Training loss: 0.210466335512173
Validation loss: 2.370722166626626

Epoch: 5| Step: 7
Training loss: 0.3664369216477152
Validation loss: 2.3920812887628116

Epoch: 5| Step: 8
Training loss: 0.3262259387135877
Validation loss: 2.3762682069169387

Epoch: 5| Step: 9
Training loss: 0.3249937584167631
Validation loss: 2.367857831195603

Epoch: 5| Step: 10
Training loss: 0.29462300245055373
Validation loss: 2.386706840042746

Epoch: 510| Step: 0
Training loss: 0.12462609965098477
Validation loss: 2.3774225415204975

Epoch: 5| Step: 1
Training loss: 0.2932457567990924
Validation loss: 2.3831474672599158

Epoch: 5| Step: 2
Training loss: 0.26891131217310127
Validation loss: 2.3887987404415343

Epoch: 5| Step: 3
Training loss: 0.34929815750722765
Validation loss: 2.38741276435675

Epoch: 5| Step: 4
Training loss: 0.40347987013809167
Validation loss: 2.393245643181316

Epoch: 5| Step: 5
Training loss: 0.2770980633259802
Validation loss: 2.351761440727498

Epoch: 5| Step: 6
Training loss: 0.3323976514621711
Validation loss: 2.3782847712926594

Epoch: 5| Step: 7
Training loss: 0.24401773029930468
Validation loss: 2.3419844575266766

Epoch: 5| Step: 8
Training loss: 0.42094081302463354
Validation loss: 2.364943325460914

Epoch: 5| Step: 9
Training loss: 0.3618345063041313
Validation loss: 2.381809033412178

Epoch: 5| Step: 10
Training loss: 0.4506218434989099
Validation loss: 2.3556922185265035

Epoch: 511| Step: 0
Training loss: 0.33363613020267097
Validation loss: 2.3551272977718223

Epoch: 5| Step: 1
Training loss: 0.21415285514635632
Validation loss: 2.364362416787828

Epoch: 5| Step: 2
Training loss: 0.3053636750679404
Validation loss: 2.387562425911107

Epoch: 5| Step: 3
Training loss: 0.4463078100494653
Validation loss: 2.386437040709442

Epoch: 5| Step: 4
Training loss: 0.23126842483373114
Validation loss: 2.4037748891933175

Epoch: 5| Step: 5
Training loss: 0.30179251313914846
Validation loss: 2.4002679353103824

Epoch: 5| Step: 6
Training loss: 0.3446960976082608
Validation loss: 2.3772615848760257

Epoch: 5| Step: 7
Training loss: 0.524003050724278
Validation loss: 2.343460195255211

Epoch: 5| Step: 8
Training loss: 0.26643373286093885
Validation loss: 2.3256991529028546

Epoch: 5| Step: 9
Training loss: 0.32174340909966764
Validation loss: 2.3448741811858635

Epoch: 5| Step: 10
Training loss: 0.24466370051508513
Validation loss: 2.3193598661974812

Epoch: 512| Step: 0
Training loss: 0.31380270988222414
Validation loss: 2.299439308659918

Epoch: 5| Step: 1
Training loss: 0.4447589411820469
Validation loss: 2.339705384434826

Epoch: 5| Step: 2
Training loss: 0.3764219939983944
Validation loss: 2.3699561373812075

Epoch: 5| Step: 3
Training loss: 0.3316501225166319
Validation loss: 2.328968783550948

Epoch: 5| Step: 4
Training loss: 0.21469056997644556
Validation loss: 2.3625693734951967

Epoch: 5| Step: 5
Training loss: 0.2684077467766183
Validation loss: 2.3580859891988535

Epoch: 5| Step: 6
Training loss: 0.4598124075968957
Validation loss: 2.406188239572973

Epoch: 5| Step: 7
Training loss: 0.2602916353800815
Validation loss: 2.340692014164911

Epoch: 5| Step: 8
Training loss: 0.29199522393220273
Validation loss: 2.366915810926323

Epoch: 5| Step: 9
Training loss: 0.3228355569904855
Validation loss: 2.3580644522603613

Epoch: 5| Step: 10
Training loss: 0.2953081821953521
Validation loss: 2.3559083810797077

Epoch: 513| Step: 0
Training loss: 0.38311160333308125
Validation loss: 2.3593944300749476

Epoch: 5| Step: 1
Training loss: 0.35249033456429196
Validation loss: 2.3367363851863576

Epoch: 5| Step: 2
Training loss: 0.30802224753739654
Validation loss: 2.37391593600181

Epoch: 5| Step: 3
Training loss: 0.44597292331006977
Validation loss: 2.337513874809671

Epoch: 5| Step: 4
Training loss: 0.4369612510139719
Validation loss: 2.341760470489751

Epoch: 5| Step: 5
Training loss: 0.26690888071410684
Validation loss: 2.3075828734216226

Epoch: 5| Step: 6
Training loss: 0.2963674121080027
Validation loss: 2.3281655377910115

Epoch: 5| Step: 7
Training loss: 0.16537465167495477
Validation loss: 2.3328741921270866

Epoch: 5| Step: 8
Training loss: 0.11405544618455746
Validation loss: 2.3263432672498796

Epoch: 5| Step: 9
Training loss: 0.16715115793915675
Validation loss: 2.3359765553581697

Epoch: 5| Step: 10
Training loss: 0.5233550789692765
Validation loss: 2.3602057612486114

Epoch: 514| Step: 0
Training loss: 0.21697950832567742
Validation loss: 2.3658643639391683

Epoch: 5| Step: 1
Training loss: 0.2679178072715752
Validation loss: 2.357636765765584

Epoch: 5| Step: 2
Training loss: 0.3151038054261882
Validation loss: 2.3524091583208375

Epoch: 5| Step: 3
Training loss: 0.34222850249077724
Validation loss: 2.3623539683024366

Epoch: 5| Step: 4
Training loss: 0.5805352975067978
Validation loss: 2.323046189860624

Epoch: 5| Step: 5
Training loss: 0.2712429812178083
Validation loss: 2.3297618230474346

Epoch: 5| Step: 6
Training loss: 0.3177822358004236
Validation loss: 2.307010273385411

Epoch: 5| Step: 7
Training loss: 0.38548411174420527
Validation loss: 2.3381070948418015

Epoch: 5| Step: 8
Training loss: 0.23871002547911213
Validation loss: 2.3439878850280333

Epoch: 5| Step: 9
Training loss: 0.2766834377156915
Validation loss: 2.3362637893267264

Epoch: 5| Step: 10
Training loss: 0.3829541819994951
Validation loss: 2.393302589547189

Epoch: 515| Step: 0
Training loss: 0.38237747464559235
Validation loss: 2.435737799543821

Epoch: 5| Step: 1
Training loss: 0.46290303467159416
Validation loss: 2.369566447200178

Epoch: 5| Step: 2
Training loss: 0.295104645942885
Validation loss: 2.360059810862174

Epoch: 5| Step: 3
Training loss: 0.4056003401127072
Validation loss: 2.3375642962537984

Epoch: 5| Step: 4
Training loss: 0.24371775817375804
Validation loss: 2.33336960820012

Epoch: 5| Step: 5
Training loss: 0.22303578170474073
Validation loss: 2.311108514471182

Epoch: 5| Step: 6
Training loss: 0.3732829320717202
Validation loss: 2.33020775584324

Epoch: 5| Step: 7
Training loss: 0.3419186838265467
Validation loss: 2.3066838220574466

Epoch: 5| Step: 8
Training loss: 0.3714272456158566
Validation loss: 2.2996300620513797

Epoch: 5| Step: 9
Training loss: 0.3159909407284334
Validation loss: 2.308081893210256

Epoch: 5| Step: 10
Training loss: 0.4709937437071238
Validation loss: 2.322850356132014

Epoch: 516| Step: 0
Training loss: 0.16629990192666777
Validation loss: 2.3414114942424216

Epoch: 5| Step: 1
Training loss: 0.2584063885561892
Validation loss: 2.38088456054348

Epoch: 5| Step: 2
Training loss: 0.2938908624753044
Validation loss: 2.3963914172173744

Epoch: 5| Step: 3
Training loss: 0.2538272147780207
Validation loss: 2.390541759920848

Epoch: 5| Step: 4
Training loss: 0.521740082758487
Validation loss: 2.3617199199927175

Epoch: 5| Step: 5
Training loss: 0.4482047370773935
Validation loss: 2.369609782421609

Epoch: 5| Step: 6
Training loss: 0.37899883358280184
Validation loss: 2.3661996437250723

Epoch: 5| Step: 7
Training loss: 0.2875945474816063
Validation loss: 2.366080442574552

Epoch: 5| Step: 8
Training loss: 0.40828766015937284
Validation loss: 2.3551843728278534

Epoch: 5| Step: 9
Training loss: 0.38800415114143577
Validation loss: 2.3315436906023694

Epoch: 5| Step: 10
Training loss: 0.402372636961716
Validation loss: 2.346723049893316

Epoch: 517| Step: 0
Training loss: 0.36147932033826125
Validation loss: 2.3739429122642144

Epoch: 5| Step: 1
Training loss: 0.28797988232576094
Validation loss: 2.369263073046406

Epoch: 5| Step: 2
Training loss: 0.31525541516583316
Validation loss: 2.369449025377109

Epoch: 5| Step: 3
Training loss: 0.4737960062360251
Validation loss: 2.374579561342434

Epoch: 5| Step: 4
Training loss: 0.2836167045109777
Validation loss: 2.3707237519224353

Epoch: 5| Step: 5
Training loss: 0.3855634830689261
Validation loss: 2.375385349230987

Epoch: 5| Step: 6
Training loss: 0.2631724112829714
Validation loss: 2.3249573637402476

Epoch: 5| Step: 7
Training loss: 0.32975211210926497
Validation loss: 2.313114871622488

Epoch: 5| Step: 8
Training loss: 0.459045406098601
Validation loss: 2.2987399448743475

Epoch: 5| Step: 9
Training loss: 0.22401051504816943
Validation loss: 2.282995771663202

Epoch: 5| Step: 10
Training loss: 0.3589309146163413
Validation loss: 2.2747402835783848

Epoch: 518| Step: 0
Training loss: 0.2789578948303567
Validation loss: 2.2892995816081654

Epoch: 5| Step: 1
Training loss: 0.3160594051670465
Validation loss: 2.30634822171092

Epoch: 5| Step: 2
Training loss: 0.4009723066651319
Validation loss: 2.2955962206844833

Epoch: 5| Step: 3
Training loss: 0.22994394680555078
Validation loss: 2.333687750609778

Epoch: 5| Step: 4
Training loss: 0.3040174427933907
Validation loss: 2.359306429528202

Epoch: 5| Step: 5
Training loss: 0.2982351365970311
Validation loss: 2.385477040468041

Epoch: 5| Step: 6
Training loss: 0.4624348259446513
Validation loss: 2.3843781511886992

Epoch: 5| Step: 7
Training loss: 0.4539646885820785
Validation loss: 2.3819424088780305

Epoch: 5| Step: 8
Training loss: 0.4442700683062437
Validation loss: 2.3605332829504038

Epoch: 5| Step: 9
Training loss: 0.29033559674467624
Validation loss: 2.3699643365715586

Epoch: 5| Step: 10
Training loss: 0.246898455652372
Validation loss: 2.319636871106369

Epoch: 519| Step: 0
Training loss: 0.2876705990371888
Validation loss: 2.3151134687935127

Epoch: 5| Step: 1
Training loss: 0.4670293061722307
Validation loss: 2.323124076213646

Epoch: 5| Step: 2
Training loss: 0.358105740054246
Validation loss: 2.318733024396827

Epoch: 5| Step: 3
Training loss: 0.21473047564839043
Validation loss: 2.319147161585071

Epoch: 5| Step: 4
Training loss: 0.2609443452359806
Validation loss: 2.337708672612762

Epoch: 5| Step: 5
Training loss: 0.4874630901840295
Validation loss: 2.3457753302168087

Epoch: 5| Step: 6
Training loss: 0.45752925312864146
Validation loss: 2.3400084559653576

Epoch: 5| Step: 7
Training loss: 0.17441506892786424
Validation loss: 2.353775679818371

Epoch: 5| Step: 8
Training loss: 0.4243573870255371
Validation loss: 2.3855678798624536

Epoch: 5| Step: 9
Training loss: 0.3895201125161327
Validation loss: 2.339458687465348

Epoch: 5| Step: 10
Training loss: 0.2078164792217665
Validation loss: 2.3683854647744447

Epoch: 520| Step: 0
Training loss: 0.21026512998398078
Validation loss: 2.374683971676052

Epoch: 5| Step: 1
Training loss: 0.32597954156153175
Validation loss: 2.364129652900015

Epoch: 5| Step: 2
Training loss: 0.31728262860672973
Validation loss: 2.394362934627871

Epoch: 5| Step: 3
Training loss: 0.3276647677972095
Validation loss: 2.339746618958854

Epoch: 5| Step: 4
Training loss: 0.40473194025592485
Validation loss: 2.3515221676760754

Epoch: 5| Step: 5
Training loss: 0.4044222798484907
Validation loss: 2.3916881057237416

Epoch: 5| Step: 6
Training loss: 0.28083930229009063
Validation loss: 2.3759654457021004

Epoch: 5| Step: 7
Training loss: 0.33965146994045947
Validation loss: 2.3744682532786223

Epoch: 5| Step: 8
Training loss: 0.3846696259462173
Validation loss: 2.395323411161478

Epoch: 5| Step: 9
Training loss: 0.31662770751084657
Validation loss: 2.398122754197477

Epoch: 5| Step: 10
Training loss: 0.3376117503628658
Validation loss: 2.344608162355935

Epoch: 521| Step: 0
Training loss: 0.3598976481162365
Validation loss: 2.3407293300968335

Epoch: 5| Step: 1
Training loss: 0.1881077077433502
Validation loss: 2.345135093145777

Epoch: 5| Step: 2
Training loss: 0.2490265266376449
Validation loss: 2.3244033349989213

Epoch: 5| Step: 3
Training loss: 0.33717379302623895
Validation loss: 2.325617568983032

Epoch: 5| Step: 4
Training loss: 0.45722921273735667
Validation loss: 2.3383143988043784

Epoch: 5| Step: 5
Training loss: 0.2976886366198375
Validation loss: 2.3001785116977334

Epoch: 5| Step: 6
Training loss: 0.3070245392626556
Validation loss: 2.2844540953513444

Epoch: 5| Step: 7
Training loss: 0.39988401042568383
Validation loss: 2.270203671214333

Epoch: 5| Step: 8
Training loss: 0.3396541022452962
Validation loss: 2.287661546399877

Epoch: 5| Step: 9
Training loss: 0.3894358081086014
Validation loss: 2.293557813801802

Epoch: 5| Step: 10
Training loss: 0.1670240628343957
Validation loss: 2.340855439328128

Epoch: 522| Step: 0
Training loss: 0.44979383726363376
Validation loss: 2.341223214283811

Epoch: 5| Step: 1
Training loss: 0.3946217725789161
Validation loss: 2.334262910673771

Epoch: 5| Step: 2
Training loss: 0.25555425023929584
Validation loss: 2.304476376765687

Epoch: 5| Step: 3
Training loss: 0.2646125543908487
Validation loss: 2.3084347286354405

Epoch: 5| Step: 4
Training loss: 0.2613798338362367
Validation loss: 2.319697551626028

Epoch: 5| Step: 5
Training loss: 0.33022941417771856
Validation loss: 2.323806242694066

Epoch: 5| Step: 6
Training loss: 0.23162570795979312
Validation loss: 2.3219105609937594

Epoch: 5| Step: 7
Training loss: 0.25719894747559496
Validation loss: 2.345797190905693

Epoch: 5| Step: 8
Training loss: 0.22918757249380048
Validation loss: 2.3409041685238283

Epoch: 5| Step: 9
Training loss: 0.4584899511931287
Validation loss: 2.3538245096662704

Epoch: 5| Step: 10
Training loss: 0.2939621549831474
Validation loss: 2.354752588460223

Epoch: 523| Step: 0
Training loss: 0.2527234182680175
Validation loss: 2.355722925906212

Epoch: 5| Step: 1
Training loss: 0.41927449203063755
Validation loss: 2.393266303293519

Epoch: 5| Step: 2
Training loss: 0.3658371709145853
Validation loss: 2.3992121105211948

Epoch: 5| Step: 3
Training loss: 0.27891778895339714
Validation loss: 2.3956922242571728

Epoch: 5| Step: 4
Training loss: 0.2705436297229483
Validation loss: 2.382302222441556

Epoch: 5| Step: 5
Training loss: 0.3272251323929632
Validation loss: 2.4246933579441956

Epoch: 5| Step: 6
Training loss: 0.3519733465484392
Validation loss: 2.4015275725432037

Epoch: 5| Step: 7
Training loss: 0.2793143473675271
Validation loss: 2.362805619324285

Epoch: 5| Step: 8
Training loss: 0.24247009187541657
Validation loss: 2.401093054777101

Epoch: 5| Step: 9
Training loss: 0.335769722315966
Validation loss: 2.390941483376046

Epoch: 5| Step: 10
Training loss: 0.38389946900132527
Validation loss: 2.421518171039074

Epoch: 524| Step: 0
Training loss: 0.25164287894186105
Validation loss: 2.3862866591462817

Epoch: 5| Step: 1
Training loss: 0.31981750947161103
Validation loss: 2.385560412942701

Epoch: 5| Step: 2
Training loss: 0.2325957873771684
Validation loss: 2.3360116137264906

Epoch: 5| Step: 3
Training loss: 0.5027108614505329
Validation loss: 2.356283087199029

Epoch: 5| Step: 4
Training loss: 0.22776925227219724
Validation loss: 2.327971703971117

Epoch: 5| Step: 5
Training loss: 0.3708703623546958
Validation loss: 2.347205852889884

Epoch: 5| Step: 6
Training loss: 0.27219015085131715
Validation loss: 2.3488203181464398

Epoch: 5| Step: 7
Training loss: 0.4385760901646258
Validation loss: 2.340151501128124

Epoch: 5| Step: 8
Training loss: 0.17896171859348936
Validation loss: 2.3897652937768763

Epoch: 5| Step: 9
Training loss: 0.27225973705782897
Validation loss: 2.3706292038268537

Epoch: 5| Step: 10
Training loss: 0.15077922824630804
Validation loss: 2.3396835544852115

Epoch: 525| Step: 0
Training loss: 0.3801473760294288
Validation loss: 2.379178511005324

Epoch: 5| Step: 1
Training loss: 0.32308568940391236
Validation loss: 2.3773275745361824

Epoch: 5| Step: 2
Training loss: 0.2617699729555146
Validation loss: 2.367067275298621

Epoch: 5| Step: 3
Training loss: 0.18431542977869425
Validation loss: 2.346157105625063

Epoch: 5| Step: 4
Training loss: 0.3253298529834677
Validation loss: 2.347462794228463

Epoch: 5| Step: 5
Training loss: 0.3207434337342274
Validation loss: 2.3101557728621263

Epoch: 5| Step: 6
Training loss: 0.26903070051465244
Validation loss: 2.3343015484357585

Epoch: 5| Step: 7
Training loss: 0.23706610188914629
Validation loss: 2.3030757178428334

Epoch: 5| Step: 8
Training loss: 0.2946957106270668
Validation loss: 2.302168351274259

Epoch: 5| Step: 9
Training loss: 0.2656295299143768
Validation loss: 2.3301907140414713

Epoch: 5| Step: 10
Training loss: 0.36005856974647965
Validation loss: 2.309377150887247

Epoch: 526| Step: 0
Training loss: 0.22105637696155295
Validation loss: 2.281050525709171

Epoch: 5| Step: 1
Training loss: 0.3099587828015033
Validation loss: 2.3232234608950075

Epoch: 5| Step: 2
Training loss: 0.3347504179448374
Validation loss: 2.2990109828717022

Epoch: 5| Step: 3
Training loss: 0.22896139567765356
Validation loss: 2.2735773986571073

Epoch: 5| Step: 4
Training loss: 0.27546158005010807
Validation loss: 2.3135181193453063

Epoch: 5| Step: 5
Training loss: 0.29858489515987546
Validation loss: 2.333971440245123

Epoch: 5| Step: 6
Training loss: 0.4257510813253025
Validation loss: 2.3229749241752407

Epoch: 5| Step: 7
Training loss: 0.13617700464257132
Validation loss: 2.314366301200914

Epoch: 5| Step: 8
Training loss: 0.3049066318002484
Validation loss: 2.2765530375289074

Epoch: 5| Step: 9
Training loss: 0.3342091880097491
Validation loss: 2.2768570738006884

Epoch: 5| Step: 10
Training loss: 0.31528431757942216
Validation loss: 2.285805394381964

Epoch: 527| Step: 0
Training loss: 0.24040747818062247
Validation loss: 2.2917857932472736

Epoch: 5| Step: 1
Training loss: 0.20919127338711432
Validation loss: 2.302863915270578

Epoch: 5| Step: 2
Training loss: 0.33588228215471255
Validation loss: 2.3109352626488935

Epoch: 5| Step: 3
Training loss: 0.28298806542161825
Validation loss: 2.3144370992353274

Epoch: 5| Step: 4
Training loss: 0.37559456183043244
Validation loss: 2.3353934040363478

Epoch: 5| Step: 5
Training loss: 0.2682624197535179
Validation loss: 2.3053226564170863

Epoch: 5| Step: 6
Training loss: 0.2987749014934945
Validation loss: 2.3433582385938556

Epoch: 5| Step: 7
Training loss: 0.2387911000875451
Validation loss: 2.335338470038867

Epoch: 5| Step: 8
Training loss: 0.44966186561712573
Validation loss: 2.357784013797558

Epoch: 5| Step: 9
Training loss: 0.2090292463527374
Validation loss: 2.3553048193143096

Epoch: 5| Step: 10
Training loss: 0.19368543010392217
Validation loss: 2.349143626106671

Epoch: 528| Step: 0
Training loss: 0.3193228016056037
Validation loss: 2.335155229179175

Epoch: 5| Step: 1
Training loss: 0.40357335167943853
Validation loss: 2.3031762069481845

Epoch: 5| Step: 2
Training loss: 0.40453904496186616
Validation loss: 2.3275479035521

Epoch: 5| Step: 3
Training loss: 0.24109081412386335
Validation loss: 2.3264882082781204

Epoch: 5| Step: 4
Training loss: 0.2890429619037022
Validation loss: 2.321718342142244

Epoch: 5| Step: 5
Training loss: 0.2359392892378106
Validation loss: 2.30000850687955

Epoch: 5| Step: 6
Training loss: 0.11199172406055799
Validation loss: 2.290835443659708

Epoch: 5| Step: 7
Training loss: 0.284881773235016
Validation loss: 2.317668064307294

Epoch: 5| Step: 8
Training loss: 0.28758761739777766
Validation loss: 2.3131702868462383

Epoch: 5| Step: 9
Training loss: 0.2551528406470214
Validation loss: 2.32333981653944

Epoch: 5| Step: 10
Training loss: 0.2742903080792202
Validation loss: 2.3336851036851356

Epoch: 529| Step: 0
Training loss: 0.21370544588301793
Validation loss: 2.3237136591189564

Epoch: 5| Step: 1
Training loss: 0.18176660988244986
Validation loss: 2.3292558556292335

Epoch: 5| Step: 2
Training loss: 0.4525906602126763
Validation loss: 2.3001214771996628

Epoch: 5| Step: 3
Training loss: 0.14699041062902304
Validation loss: 2.300195706197151

Epoch: 5| Step: 4
Training loss: 0.22280840108881153
Validation loss: 2.301951676390585

Epoch: 5| Step: 5
Training loss: 0.20441732666803528
Validation loss: 2.299861867518797

Epoch: 5| Step: 6
Training loss: 0.2382393237265667
Validation loss: 2.31076171493088

Epoch: 5| Step: 7
Training loss: 0.48734997250326056
Validation loss: 2.29677977541397

Epoch: 5| Step: 8
Training loss: 0.3409856925141457
Validation loss: 2.276655160689313

Epoch: 5| Step: 9
Training loss: 0.2528504206930564
Validation loss: 2.315970531843322

Epoch: 5| Step: 10
Training loss: 0.24349603627403796
Validation loss: 2.331367577839486

Epoch: 530| Step: 0
Training loss: 0.16074573378515555
Validation loss: 2.279411515700962

Epoch: 5| Step: 1
Training loss: 0.3568033588739921
Validation loss: 2.3175840550270426

Epoch: 5| Step: 2
Training loss: 0.3803619657897658
Validation loss: 2.303990004667746

Epoch: 5| Step: 3
Training loss: 0.44206711576067254
Validation loss: 2.270595584001629

Epoch: 5| Step: 4
Training loss: 0.19118720775331258
Validation loss: 2.277067309334277

Epoch: 5| Step: 5
Training loss: 0.20947589293782543
Validation loss: 2.297594401021508

Epoch: 5| Step: 6
Training loss: 0.3829034191298736
Validation loss: 2.2807366859411693

Epoch: 5| Step: 7
Training loss: 0.1363023069467582
Validation loss: 2.295130340735827

Epoch: 5| Step: 8
Training loss: 0.25422639470718955
Validation loss: 2.287460525354099

Epoch: 5| Step: 9
Training loss: 0.2402722553688605
Validation loss: 2.3136963309279586

Epoch: 5| Step: 10
Training loss: 0.2268264236281278
Validation loss: 2.2710527304368338

Epoch: 531| Step: 0
Training loss: 0.15771006054312464
Validation loss: 2.296818924298114

Epoch: 5| Step: 1
Training loss: 0.2957957879718967
Validation loss: 2.303520189836338

Epoch: 5| Step: 2
Training loss: 0.3311573533287002
Validation loss: 2.3055216852691665

Epoch: 5| Step: 3
Training loss: 0.3792231895774747
Validation loss: 2.299196843435012

Epoch: 5| Step: 4
Training loss: 0.27095314579088026
Validation loss: 2.2942108537177526

Epoch: 5| Step: 5
Training loss: 0.19486928241776538
Validation loss: 2.2967107045915895

Epoch: 5| Step: 6
Training loss: 0.3759298914886989
Validation loss: 2.312535732162841

Epoch: 5| Step: 7
Training loss: 0.31458054798147855
Validation loss: 2.312876603341486

Epoch: 5| Step: 8
Training loss: 0.3468202332916386
Validation loss: 2.2990317505095708

Epoch: 5| Step: 9
Training loss: 0.4067018270470743
Validation loss: 2.313379986658925

Epoch: 5| Step: 10
Training loss: 0.2134826285851931
Validation loss: 2.2681970070003112

Epoch: 532| Step: 0
Training loss: 0.40982999995992164
Validation loss: 2.27907581422347

Epoch: 5| Step: 1
Training loss: 0.2149413580679937
Validation loss: 2.284531913220655

Epoch: 5| Step: 2
Training loss: 0.21771418188686964
Validation loss: 2.3212052809100943

Epoch: 5| Step: 3
Training loss: 0.3306380494324198
Validation loss: 2.338762888729138

Epoch: 5| Step: 4
Training loss: 0.3554571380395407
Validation loss: 2.3183244900807423

Epoch: 5| Step: 5
Training loss: 0.40904641541636944
Validation loss: 2.3127837845344246

Epoch: 5| Step: 6
Training loss: 0.18918814267457976
Validation loss: 2.3426242588640074

Epoch: 5| Step: 7
Training loss: 0.1543571981984557
Validation loss: 2.342178371262549

Epoch: 5| Step: 8
Training loss: 0.2258153384785459
Validation loss: 2.3429087758292524

Epoch: 5| Step: 9
Training loss: 0.3537373979972531
Validation loss: 2.384919635258609

Epoch: 5| Step: 10
Training loss: 0.21855859386508658
Validation loss: 2.388583758526459

Epoch: 533| Step: 0
Training loss: 0.2036992813096503
Validation loss: 2.3693274309103027

Epoch: 5| Step: 1
Training loss: 0.14568602126625851
Validation loss: 2.3640260381651856

Epoch: 5| Step: 2
Training loss: 0.290429735215779
Validation loss: 2.3398585619924903

Epoch: 5| Step: 3
Training loss: 0.33525070691158626
Validation loss: 2.3489534748029786

Epoch: 5| Step: 4
Training loss: 0.3324745136546278
Validation loss: 2.3463556344002647

Epoch: 5| Step: 5
Training loss: 0.3099236742971822
Validation loss: 2.3685907865213274

Epoch: 5| Step: 6
Training loss: 0.3014683986759442
Validation loss: 2.3702652252624867

Epoch: 5| Step: 7
Training loss: 0.24305082848281537
Validation loss: 2.3682114130210037

Epoch: 5| Step: 8
Training loss: 0.28093841300111616
Validation loss: 2.360624682559339

Epoch: 5| Step: 9
Training loss: 0.2992684355437347
Validation loss: 2.3621004630652562

Epoch: 5| Step: 10
Training loss: 0.34498779729671863
Validation loss: 2.3903397930131076

Epoch: 534| Step: 0
Training loss: 0.15832330118780122
Validation loss: 2.3600831186466786

Epoch: 5| Step: 1
Training loss: 0.22690948683974504
Validation loss: 2.321817224981982

Epoch: 5| Step: 2
Training loss: 0.33845282513764696
Validation loss: 2.350917952543649

Epoch: 5| Step: 3
Training loss: 0.2103030943219798
Validation loss: 2.334745764269969

Epoch: 5| Step: 4
Training loss: 0.19771360763801002
Validation loss: 2.363638483416631

Epoch: 5| Step: 5
Training loss: 0.1713326741183002
Validation loss: 2.353354369892208

Epoch: 5| Step: 6
Training loss: 0.35745564285607473
Validation loss: 2.344014218111604

Epoch: 5| Step: 7
Training loss: 0.23285994398330012
Validation loss: 2.3468282134511558

Epoch: 5| Step: 8
Training loss: 0.35953584471630123
Validation loss: 2.3379168918844093

Epoch: 5| Step: 9
Training loss: 0.42074075741286227
Validation loss: 2.3201348076606685

Epoch: 5| Step: 10
Training loss: 0.28510622343427877
Validation loss: 2.3467089640038195

Epoch: 535| Step: 0
Training loss: 0.35683985782634997
Validation loss: 2.3146444885138315

Epoch: 5| Step: 1
Training loss: 0.26975016066004626
Validation loss: 2.352180481246935

Epoch: 5| Step: 2
Training loss: 0.2899331178697875
Validation loss: 2.318254155789967

Epoch: 5| Step: 3
Training loss: 0.2321422882780504
Validation loss: 2.320843447432356

Epoch: 5| Step: 4
Training loss: 0.29766965220158426
Validation loss: 2.3222756255659394

Epoch: 5| Step: 5
Training loss: 0.1503693516039855
Validation loss: 2.2773495609348124

Epoch: 5| Step: 6
Training loss: 0.28475704729638357
Validation loss: 2.3055975372700153

Epoch: 5| Step: 7
Training loss: 0.24547098470796114
Validation loss: 2.3129847793607836

Epoch: 5| Step: 8
Training loss: 0.3555527053452203
Validation loss: 2.299888657901751

Epoch: 5| Step: 9
Training loss: 0.17345931006241422
Validation loss: 2.30190250627729

Epoch: 5| Step: 10
Training loss: 0.36218922052641267
Validation loss: 2.324264804697122

Epoch: 536| Step: 0
Training loss: 0.42860724166122816
Validation loss: 2.3134332085910003

Epoch: 5| Step: 1
Training loss: 0.15533065341533595
Validation loss: 2.3226828501373857

Epoch: 5| Step: 2
Training loss: 0.23036430707882324
Validation loss: 2.3074168750427932

Epoch: 5| Step: 3
Training loss: 0.16189710093375753
Validation loss: 2.3110851861526536

Epoch: 5| Step: 4
Training loss: 0.2861055745254737
Validation loss: 2.3297155859592005

Epoch: 5| Step: 5
Training loss: 0.17528418091234488
Validation loss: 2.3410174973533553

Epoch: 5| Step: 6
Training loss: 0.3964227713095543
Validation loss: 2.384720815584093

Epoch: 5| Step: 7
Training loss: 0.31936156610427524
Validation loss: 2.381481207725756

Epoch: 5| Step: 8
Training loss: 0.3163743179597289
Validation loss: 2.347636117801596

Epoch: 5| Step: 9
Training loss: 0.22730904114299239
Validation loss: 2.322592857066959

Epoch: 5| Step: 10
Training loss: 0.2166056777934656
Validation loss: 2.3807511387362337

Epoch: 537| Step: 0
Training loss: 0.20899670109985802
Validation loss: 2.366382634376879

Epoch: 5| Step: 1
Training loss: 0.26259940286199485
Validation loss: 2.339515608380382

Epoch: 5| Step: 2
Training loss: 0.156265687155027
Validation loss: 2.350509413206698

Epoch: 5| Step: 3
Training loss: 0.2402359411917395
Validation loss: 2.3800647457395567

Epoch: 5| Step: 4
Training loss: 0.2584233849348313
Validation loss: 2.3654882688803047

Epoch: 5| Step: 5
Training loss: 0.4004379988765928
Validation loss: 2.3418318382986

Epoch: 5| Step: 6
Training loss: 0.33013584828562453
Validation loss: 2.3870815949676594

Epoch: 5| Step: 7
Training loss: 0.3506378092950446
Validation loss: 2.363115995319829

Epoch: 5| Step: 8
Training loss: 0.4454592412805491
Validation loss: 2.365017750241209

Epoch: 5| Step: 9
Training loss: 0.18079017155557955
Validation loss: 2.371943621253671

Epoch: 5| Step: 10
Training loss: 0.16124465413251324
Validation loss: 2.390007134906301

Epoch: 538| Step: 0
Training loss: 0.33492269937223823
Validation loss: 2.4014307383575404

Epoch: 5| Step: 1
Training loss: 0.14206503949830418
Validation loss: 2.3610945489492754

Epoch: 5| Step: 2
Training loss: 0.1962012099099451
Validation loss: 2.3875935236012644

Epoch: 5| Step: 3
Training loss: 0.3675260200825739
Validation loss: 2.3634195104088995

Epoch: 5| Step: 4
Training loss: 0.22637151198909597
Validation loss: 2.343116076204363

Epoch: 5| Step: 5
Training loss: 0.24904002714061527
Validation loss: 2.3210648322820813

Epoch: 5| Step: 6
Training loss: 0.14841055625520444
Validation loss: 2.3596974031500206

Epoch: 5| Step: 7
Training loss: 0.37618632224475795
Validation loss: 2.3057439280452847

Epoch: 5| Step: 8
Training loss: 0.3270308325883778
Validation loss: 2.3026893670677113

Epoch: 5| Step: 9
Training loss: 0.32476583536346354
Validation loss: 2.3074590632027845

Epoch: 5| Step: 10
Training loss: 0.28024333034528115
Validation loss: 2.331985486650415

Epoch: 539| Step: 0
Training loss: 0.26614995581214274
Validation loss: 2.2963032170175364

Epoch: 5| Step: 1
Training loss: 0.19836641750627199
Validation loss: 2.354740325208681

Epoch: 5| Step: 2
Training loss: 0.20461221176633798
Validation loss: 2.3384164504009357

Epoch: 5| Step: 3
Training loss: 0.3728601877324919
Validation loss: 2.3393241632339254

Epoch: 5| Step: 4
Training loss: 0.17864082086572894
Validation loss: 2.331488538898214

Epoch: 5| Step: 5
Training loss: 0.32722085179781535
Validation loss: 2.346639731731288

Epoch: 5| Step: 6
Training loss: 0.2991851718079662
Validation loss: 2.3323165096048846

Epoch: 5| Step: 7
Training loss: 0.3566174026399357
Validation loss: 2.332168658326596

Epoch: 5| Step: 8
Training loss: 0.14771190028553496
Validation loss: 2.3257209779805015

Epoch: 5| Step: 9
Training loss: 0.22411153602582143
Validation loss: 2.328453328766835

Epoch: 5| Step: 10
Training loss: 0.3505374481756409
Validation loss: 2.3267723162601484

Epoch: 540| Step: 0
Training loss: 0.29865226058554656
Validation loss: 2.3049005269882494

Epoch: 5| Step: 1
Training loss: 0.17454041585017216
Validation loss: 2.3173132649700228

Epoch: 5| Step: 2
Training loss: 0.3506140099977338
Validation loss: 2.310375124266968

Epoch: 5| Step: 3
Training loss: 0.4121159376733736
Validation loss: 2.3218302699567874

Epoch: 5| Step: 4
Training loss: 0.11579945185029007
Validation loss: 2.292439816586568

Epoch: 5| Step: 5
Training loss: 0.33473063077935067
Validation loss: 2.3194953587506584

Epoch: 5| Step: 6
Training loss: 0.13190180228171877
Validation loss: 2.3177328394421197

Epoch: 5| Step: 7
Training loss: 0.19344008331545903
Validation loss: 2.3267809867311677

Epoch: 5| Step: 8
Training loss: 0.24181464165414304
Validation loss: 2.3376901079544155

Epoch: 5| Step: 9
Training loss: 0.357285874971357
Validation loss: 2.3223833843410726

Epoch: 5| Step: 10
Training loss: 0.13200937095481163
Validation loss: 2.294713159066652

Epoch: 541| Step: 0
Training loss: 0.2792137128891137
Validation loss: 2.335946702337129

Epoch: 5| Step: 1
Training loss: 0.19591560706889583
Validation loss: 2.3174777187324955

Epoch: 5| Step: 2
Training loss: 0.3022556827238128
Validation loss: 2.328995465872098

Epoch: 5| Step: 3
Training loss: 0.40426086412834084
Validation loss: 2.2722082112590702

Epoch: 5| Step: 4
Training loss: 0.15734747863298876
Validation loss: 2.3295214348619204

Epoch: 5| Step: 5
Training loss: 0.2763404833289861
Validation loss: 2.312776150521114

Epoch: 5| Step: 6
Training loss: 0.3697094848364379
Validation loss: 2.3243172896038122

Epoch: 5| Step: 7
Training loss: 0.12917434383721804
Validation loss: 2.3266372105707513

Epoch: 5| Step: 8
Training loss: 0.2260190678138799
Validation loss: 2.3018642546429917

Epoch: 5| Step: 9
Training loss: 0.28841634650067055
Validation loss: 2.327233361182147

Epoch: 5| Step: 10
Training loss: 0.16061301922367985
Validation loss: 2.3020329631134815

Epoch: 542| Step: 0
Training loss: 0.33870666835568247
Validation loss: 2.3187332720559866

Epoch: 5| Step: 1
Training loss: 0.20731950881215155
Validation loss: 2.305745755925425

Epoch: 5| Step: 2
Training loss: 0.2530562919803023
Validation loss: 2.3262636063922097

Epoch: 5| Step: 3
Training loss: 0.28317105341872484
Validation loss: 2.3312269738681732

Epoch: 5| Step: 4
Training loss: 0.39073734575235186
Validation loss: 2.323526946155769

Epoch: 5| Step: 5
Training loss: 0.22972019313213135
Validation loss: 2.3275633037527697

Epoch: 5| Step: 6
Training loss: 0.18988183271433495
Validation loss: 2.2833479661280287

Epoch: 5| Step: 7
Training loss: 0.2452997538419951
Validation loss: 2.330619627032467

Epoch: 5| Step: 8
Training loss: 0.27451668717520117
Validation loss: 2.327281095587396

Epoch: 5| Step: 9
Training loss: 0.22663993991825848
Validation loss: 2.2792404748057438

Epoch: 5| Step: 10
Training loss: 0.22434928596606973
Validation loss: 2.331961171911887

Epoch: 543| Step: 0
Training loss: 0.2993345395144783
Validation loss: 2.3463338870833046

Epoch: 5| Step: 1
Training loss: 0.25423931870956196
Validation loss: 2.361316907754214

Epoch: 5| Step: 2
Training loss: 0.16328282948692807
Validation loss: 2.3086599462602866

Epoch: 5| Step: 3
Training loss: 0.2560295965615531
Validation loss: 2.3586903892023274

Epoch: 5| Step: 4
Training loss: 0.38591501734186257
Validation loss: 2.3420162797235955

Epoch: 5| Step: 5
Training loss: 0.16599546197855616
Validation loss: 2.324872560919539

Epoch: 5| Step: 6
Training loss: 0.34009715750201
Validation loss: 2.31540854655237

Epoch: 5| Step: 7
Training loss: 0.34611722423089253
Validation loss: 2.315665199650799

Epoch: 5| Step: 8
Training loss: 0.12161248373415173
Validation loss: 2.30677203192167

Epoch: 5| Step: 9
Training loss: 0.19378755343956325
Validation loss: 2.3013548779845427

Epoch: 5| Step: 10
Training loss: 0.24141500697872872
Validation loss: 2.3161928179922247

Epoch: 544| Step: 0
Training loss: 0.3253231083865287
Validation loss: 2.2927334074866876

Epoch: 5| Step: 1
Training loss: 0.16410662421011565
Validation loss: 2.2780732238693413

Epoch: 5| Step: 2
Training loss: 0.2459719371557663
Validation loss: 2.2574872827549295

Epoch: 5| Step: 3
Training loss: 0.34720542694903955
Validation loss: 2.284849021865545

Epoch: 5| Step: 4
Training loss: 0.1915650584748565
Validation loss: 2.303168128132369

Epoch: 5| Step: 5
Training loss: 0.30116412329686143
Validation loss: 2.286640490088478

Epoch: 5| Step: 6
Training loss: 0.3358294290989305
Validation loss: 2.3071562761726714

Epoch: 5| Step: 7
Training loss: 0.1853338122536054
Validation loss: 2.288773733463926

Epoch: 5| Step: 8
Training loss: 0.31446570614116187
Validation loss: 2.3058316602103095

Epoch: 5| Step: 9
Training loss: 0.1832807287060803
Validation loss: 2.2970218439900094

Epoch: 5| Step: 10
Training loss: 0.2864305815114014
Validation loss: 2.2946783928315058

Epoch: 545| Step: 0
Training loss: 0.29143435161181724
Validation loss: 2.3140853230290066

Epoch: 5| Step: 1
Training loss: 0.3812724099061072
Validation loss: 2.308357156269515

Epoch: 5| Step: 2
Training loss: 0.2780133612667135
Validation loss: 2.3098210351812565

Epoch: 5| Step: 3
Training loss: 0.15558034926561265
Validation loss: 2.304552606910982

Epoch: 5| Step: 4
Training loss: 0.3132709292188645
Validation loss: 2.284957808972562

Epoch: 5| Step: 5
Training loss: 0.3453724783164382
Validation loss: 2.290981287187012

Epoch: 5| Step: 6
Training loss: 0.31518484953220327
Validation loss: 2.2843536950551813

Epoch: 5| Step: 7
Training loss: 0.23844797523856326
Validation loss: 2.3360607863574425

Epoch: 5| Step: 8
Training loss: 0.19140688253804225
Validation loss: 2.3416844515066164

Epoch: 5| Step: 9
Training loss: 0.23319773643823963
Validation loss: 2.33239901715312

Epoch: 5| Step: 10
Training loss: 0.1469663194069697
Validation loss: 2.3351412513631167

Epoch: 546| Step: 0
Training loss: 0.22470926468529617
Validation loss: 2.3434912584562637

Epoch: 5| Step: 1
Training loss: 0.36475403967274744
Validation loss: 2.3316449445386582

Epoch: 5| Step: 2
Training loss: 0.1711685661577629
Validation loss: 2.3593434662624335

Epoch: 5| Step: 3
Training loss: 0.16663380139880302
Validation loss: 2.3805822162844987

Epoch: 5| Step: 4
Training loss: 0.2861048063040818
Validation loss: 2.3615410075184737

Epoch: 5| Step: 5
Training loss: 0.26213609812194627
Validation loss: 2.3628717447197087

Epoch: 5| Step: 6
Training loss: 0.2191632063683756
Validation loss: 2.370347356073895

Epoch: 5| Step: 7
Training loss: 0.14548208662127582
Validation loss: 2.3346682584880636

Epoch: 5| Step: 8
Training loss: 0.4265276814317831
Validation loss: 2.350444004547965

Epoch: 5| Step: 9
Training loss: 0.2864500376916236
Validation loss: 2.341756465893388

Epoch: 5| Step: 10
Training loss: 0.28497312492261057
Validation loss: 2.3405166450842696

Epoch: 547| Step: 0
Training loss: 0.38371441141796925
Validation loss: 2.3128813950398284

Epoch: 5| Step: 1
Training loss: 0.25078942413318267
Validation loss: 2.3287616901657913

Epoch: 5| Step: 2
Training loss: 0.23182681386296233
Validation loss: 2.3150879475600226

Epoch: 5| Step: 3
Training loss: 0.3090487879612856
Validation loss: 2.3529696302025096

Epoch: 5| Step: 4
Training loss: 0.24960649336463378
Validation loss: 2.327150549310656

Epoch: 5| Step: 5
Training loss: 0.1618543250088509
Validation loss: 2.3697417490039254

Epoch: 5| Step: 6
Training loss: 0.20649237948839516
Validation loss: 2.34906403944209

Epoch: 5| Step: 7
Training loss: 0.3899919339103916
Validation loss: 2.372738145962556

Epoch: 5| Step: 8
Training loss: 0.13701012080940378
Validation loss: 2.3951027206034547

Epoch: 5| Step: 9
Training loss: 0.27269016044065564
Validation loss: 2.3924026266177245

Epoch: 5| Step: 10
Training loss: 0.3255385228754748
Validation loss: 2.3685697683029563

Epoch: 548| Step: 0
Training loss: 0.2938333849548955
Validation loss: 2.375988593140861

Epoch: 5| Step: 1
Training loss: 0.2436232081176601
Validation loss: 2.3721892007752303

Epoch: 5| Step: 2
Training loss: 0.2317764713730294
Validation loss: 2.3750442849948894

Epoch: 5| Step: 3
Training loss: 0.17836187490414807
Validation loss: 2.379981681361663

Epoch: 5| Step: 4
Training loss: 0.24289072139194523
Validation loss: 2.3369783143315894

Epoch: 5| Step: 5
Training loss: 0.2640104451307737
Validation loss: 2.3380769639300243

Epoch: 5| Step: 6
Training loss: 0.23718758821799907
Validation loss: 2.330382948020619

Epoch: 5| Step: 7
Training loss: 0.3962061051144822
Validation loss: 2.3231056129544694

Epoch: 5| Step: 8
Training loss: 0.29465629291038514
Validation loss: 2.3264753596712597

Epoch: 5| Step: 9
Training loss: 0.13981577710670978
Validation loss: 2.321010539430136

Epoch: 5| Step: 10
Training loss: 0.30082530157343107
Validation loss: 2.305528513508094

Epoch: 549| Step: 0
Training loss: 0.36125023492059694
Validation loss: 2.2878665327377328

Epoch: 5| Step: 1
Training loss: 0.2391995261682407
Validation loss: 2.2998069659886435

Epoch: 5| Step: 2
Training loss: 0.3303398020530697
Validation loss: 2.3203471152778996

Epoch: 5| Step: 3
Training loss: 0.25191192881585145
Validation loss: 2.2798866258159083

Epoch: 5| Step: 4
Training loss: 0.29576585021235363
Validation loss: 2.3309505874209213

Epoch: 5| Step: 5
Training loss: 0.13532790765853886
Validation loss: 2.3060382536718027

Epoch: 5| Step: 6
Training loss: 0.23322692858235636
Validation loss: 2.3051246168749824

Epoch: 5| Step: 7
Training loss: 0.17747016803801638
Validation loss: 2.306826113113973

Epoch: 5| Step: 8
Training loss: 0.3482070374520444
Validation loss: 2.3397989738031684

Epoch: 5| Step: 9
Training loss: 0.23120636818352516
Validation loss: 2.34257720152901

Epoch: 5| Step: 10
Training loss: 0.23707455594659715
Validation loss: 2.342051487129425

Epoch: 550| Step: 0
Training loss: 0.3387046006174909
Validation loss: 2.3577386932204054

Epoch: 5| Step: 1
Training loss: 0.29139684503427443
Validation loss: 2.36911278788383

Epoch: 5| Step: 2
Training loss: 0.24995266943168296
Validation loss: 2.355049298528125

Epoch: 5| Step: 3
Training loss: 0.2587226926519533
Validation loss: 2.380435119525103

Epoch: 5| Step: 4
Training loss: 0.19184139962441304
Validation loss: 2.355726326718385

Epoch: 5| Step: 5
Training loss: 0.16307495559904941
Validation loss: 2.362444408722177

Epoch: 5| Step: 6
Training loss: 0.21419516545580175
Validation loss: 2.3714673226325527

Epoch: 5| Step: 7
Training loss: 0.16093984666983785
Validation loss: 2.372042271995015

Epoch: 5| Step: 8
Training loss: 0.21059852313411861
Validation loss: 2.353574883337015

Epoch: 5| Step: 9
Training loss: 0.26509939812728955
Validation loss: 2.383698788780164

Epoch: 5| Step: 10
Training loss: 0.45263624139820263
Validation loss: 2.3769203058591324

Epoch: 551| Step: 0
Training loss: 0.42884968660856193
Validation loss: 2.3512734303032596

Epoch: 5| Step: 1
Training loss: 0.18925717632237957
Validation loss: 2.3695409493181416

Epoch: 5| Step: 2
Training loss: 0.22436620568863216
Validation loss: 2.396016855866144

Epoch: 5| Step: 3
Training loss: 0.15485748622721238
Validation loss: 2.37968327089884

Epoch: 5| Step: 4
Training loss: 0.19861944598120382
Validation loss: 2.3687355673113246

Epoch: 5| Step: 5
Training loss: 0.2663929161247568
Validation loss: 2.3545738885843583

Epoch: 5| Step: 6
Training loss: 0.38430134602563343
Validation loss: 2.352075023464414

Epoch: 5| Step: 7
Training loss: 0.28502224686862787
Validation loss: 2.343603511047077

Epoch: 5| Step: 8
Training loss: 0.24158116549813938
Validation loss: 2.29824600894901

Epoch: 5| Step: 9
Training loss: 0.1578471452623131
Validation loss: 2.3247891422541933

Epoch: 5| Step: 10
Training loss: 0.2333476198809645
Validation loss: 2.3141831090578746

Epoch: 552| Step: 0
Training loss: 0.20526015059918423
Validation loss: 2.329273982876554

Epoch: 5| Step: 1
Training loss: 0.2531337136075711
Validation loss: 2.287334741631886

Epoch: 5| Step: 2
Training loss: 0.29191846140034744
Validation loss: 2.2882455036083584

Epoch: 5| Step: 3
Training loss: 0.24734989375510633
Validation loss: 2.342302302140746

Epoch: 5| Step: 4
Training loss: 0.14011195425869474
Validation loss: 2.336495067650786

Epoch: 5| Step: 5
Training loss: 0.29336866422491154
Validation loss: 2.295487934399631

Epoch: 5| Step: 6
Training loss: 0.1667476614951823
Validation loss: 2.3336344462748775

Epoch: 5| Step: 7
Training loss: 0.32008369926978614
Validation loss: 2.33696685158611

Epoch: 5| Step: 8
Training loss: 0.31853394899859344
Validation loss: 2.315221337662312

Epoch: 5| Step: 9
Training loss: 0.3095877609389835
Validation loss: 2.3580519714003265

Epoch: 5| Step: 10
Training loss: 0.14196388980608057
Validation loss: 2.364207856792446

Epoch: 553| Step: 0
Training loss: 0.3195105958712847
Validation loss: 2.352530357692667

Epoch: 5| Step: 1
Training loss: 0.3104482770139337
Validation loss: 2.3373515700253042

Epoch: 5| Step: 2
Training loss: 0.3272087155507498
Validation loss: 2.3569836552321335

Epoch: 5| Step: 3
Training loss: 0.3334570732020596
Validation loss: 2.3557777094001433

Epoch: 5| Step: 4
Training loss: 0.28333169057781227
Validation loss: 2.354791916660314

Epoch: 5| Step: 5
Training loss: 0.22117760385729238
Validation loss: 2.359714369830501

Epoch: 5| Step: 6
Training loss: 0.1295928514903398
Validation loss: 2.322654600814654

Epoch: 5| Step: 7
Training loss: 0.29819994704142433
Validation loss: 2.3169610076278015

Epoch: 5| Step: 8
Training loss: 0.14295235602392692
Validation loss: 2.308206090962582

Epoch: 5| Step: 9
Training loss: 0.16732677046779432
Validation loss: 2.328413205567534

Epoch: 5| Step: 10
Training loss: 0.22395693516110002
Validation loss: 2.33726119077929

Epoch: 554| Step: 0
Training loss: 0.13478557466652896
Validation loss: 2.323001887783697

Epoch: 5| Step: 1
Training loss: 0.12542203349398925
Validation loss: 2.3144497012023955

Epoch: 5| Step: 2
Training loss: 0.2656811206099314
Validation loss: 2.318623118611775

Epoch: 5| Step: 3
Training loss: 0.3008865568432042
Validation loss: 2.273790512302228

Epoch: 5| Step: 4
Training loss: 0.34951318451157576
Validation loss: 2.286591245792918

Epoch: 5| Step: 5
Training loss: 0.23959962989833472
Validation loss: 2.3036900409454484

Epoch: 5| Step: 6
Training loss: 0.336681230229261
Validation loss: 2.3188783117522234

Epoch: 5| Step: 7
Training loss: 0.27755313008123494
Validation loss: 2.283120137641817

Epoch: 5| Step: 8
Training loss: 0.13410229456874243
Validation loss: 2.3225855157885418

Epoch: 5| Step: 9
Training loss: 0.17630988211312648
Validation loss: 2.3269663452856317

Epoch: 5| Step: 10
Training loss: 0.2895323568982758
Validation loss: 2.312447234407874

Epoch: 555| Step: 0
Training loss: 0.2731263161110321
Validation loss: 2.321375409815393

Epoch: 5| Step: 1
Training loss: 0.19149103038712623
Validation loss: 2.330973386157604

Epoch: 5| Step: 2
Training loss: 0.15889178609709823
Validation loss: 2.3396305691957897

Epoch: 5| Step: 3
Training loss: 0.37105588217821167
Validation loss: 2.338210226680484

Epoch: 5| Step: 4
Training loss: 0.2414207781274903
Validation loss: 2.3351081179399262

Epoch: 5| Step: 5
Training loss: 0.21594346101706252
Validation loss: 2.3301765920253144

Epoch: 5| Step: 6
Training loss: 0.14133244954373056
Validation loss: 2.3299771748709515

Epoch: 5| Step: 7
Training loss: 0.1557075501964897
Validation loss: 2.31081171774865

Epoch: 5| Step: 8
Training loss: 0.25117343943629267
Validation loss: 2.299193671213086

Epoch: 5| Step: 9
Training loss: 0.38163705314596824
Validation loss: 2.334014015045591

Epoch: 5| Step: 10
Training loss: 0.21656334817673467
Validation loss: 2.3276789261897686

Epoch: 556| Step: 0
Training loss: 0.23484891819803233
Validation loss: 2.3211936356261167

Epoch: 5| Step: 1
Training loss: 0.2260127632864501
Validation loss: 2.3665534532561376

Epoch: 5| Step: 2
Training loss: 0.2160864350079995
Validation loss: 2.4019009095034445

Epoch: 5| Step: 3
Training loss: 0.20835516139755705
Validation loss: 2.427141053599043

Epoch: 5| Step: 4
Training loss: 0.3403426925324714
Validation loss: 2.407776623047004

Epoch: 5| Step: 5
Training loss: 0.23018961505969485
Validation loss: 2.379355914084888

Epoch: 5| Step: 6
Training loss: 0.26152770343061854
Validation loss: 2.410261823478233

Epoch: 5| Step: 7
Training loss: 0.3697511982153615
Validation loss: 2.3353650159148938

Epoch: 5| Step: 8
Training loss: 0.32697640066120287
Validation loss: 2.329860096576535

Epoch: 5| Step: 9
Training loss: 0.12115510032478291
Validation loss: 2.3380303139776792

Epoch: 5| Step: 10
Training loss: 0.15938973756043323
Validation loss: 2.3224131049715346

Epoch: 557| Step: 0
Training loss: 0.32564149781825774
Validation loss: 2.3131090286223555

Epoch: 5| Step: 1
Training loss: 0.3602247144123073
Validation loss: 2.2828365096046634

Epoch: 5| Step: 2
Training loss: 0.2286579064083332
Validation loss: 2.3403451789614724

Epoch: 5| Step: 3
Training loss: 0.1706520866283656
Validation loss: 2.3165280891214657

Epoch: 5| Step: 4
Training loss: 0.20330203117978063
Validation loss: 2.2939319396383655

Epoch: 5| Step: 5
Training loss: 0.29949929404692965
Validation loss: 2.297385955782692

Epoch: 5| Step: 6
Training loss: 0.24099688743079115
Validation loss: 2.328679010808174

Epoch: 5| Step: 7
Training loss: 0.14533273033093916
Validation loss: 2.2998452808225465

Epoch: 5| Step: 8
Training loss: 0.24077229636029682
Validation loss: 2.3090413432854007

Epoch: 5| Step: 9
Training loss: 0.3655204468590357
Validation loss: 2.3369388380088423

Epoch: 5| Step: 10
Training loss: 0.44027150563640427
Validation loss: 2.3411484513821414

Epoch: 558| Step: 0
Training loss: 0.35268403345676125
Validation loss: 2.2839755729702493

Epoch: 5| Step: 1
Training loss: 0.2973205961713263
Validation loss: 2.2950733522488966

Epoch: 5| Step: 2
Training loss: 0.18465250193571417
Validation loss: 2.3107577331641282

Epoch: 5| Step: 3
Training loss: 0.388491718194144
Validation loss: 2.3020191750703596

Epoch: 5| Step: 4
Training loss: 0.3918009604700281
Validation loss: 2.3357518201498935

Epoch: 5| Step: 5
Training loss: 0.3088305566693434
Validation loss: 2.3074956911261206

Epoch: 5| Step: 6
Training loss: 0.2689203720330044
Validation loss: 2.3536970617764332

Epoch: 5| Step: 7
Training loss: 0.3432607094545028
Validation loss: 2.4047381815411946

Epoch: 5| Step: 8
Training loss: 0.3793573349008901
Validation loss: 2.4191051605556773

Epoch: 5| Step: 9
Training loss: 0.2918089224538265
Validation loss: 2.3907840758138628

Epoch: 5| Step: 10
Training loss: 0.349067940033517
Validation loss: 2.4090040778972153

Epoch: 559| Step: 0
Training loss: 0.381113075463908
Validation loss: 2.3719329621973055

Epoch: 5| Step: 1
Training loss: 0.22859970404431817
Validation loss: 2.3552263012974883

Epoch: 5| Step: 2
Training loss: 0.31726184593792467
Validation loss: 2.3642571272020145

Epoch: 5| Step: 3
Training loss: 0.3512061114059717
Validation loss: 2.3560642461127554

Epoch: 5| Step: 4
Training loss: 0.2785275808499485
Validation loss: 2.3773932216089166

Epoch: 5| Step: 5
Training loss: 0.17017964838004127
Validation loss: 2.350406343844423

Epoch: 5| Step: 6
Training loss: 0.3216800803186164
Validation loss: 2.33323121030498

Epoch: 5| Step: 7
Training loss: 0.2119526630175822
Validation loss: 2.343914053039487

Epoch: 5| Step: 8
Training loss: 0.2908177695281661
Validation loss: 2.3358109529383104

Epoch: 5| Step: 9
Training loss: 0.21230740233986806
Validation loss: 2.342585855772159

Epoch: 5| Step: 10
Training loss: 0.20821242499559986
Validation loss: 2.3536322449272187

Epoch: 560| Step: 0
Training loss: 0.2004689091587401
Validation loss: 2.3341889435108176

Epoch: 5| Step: 1
Training loss: 0.262000800213429
Validation loss: 2.3093568814740117

Epoch: 5| Step: 2
Training loss: 0.15960005969677432
Validation loss: 2.299707960007924

Epoch: 5| Step: 3
Training loss: 0.33414010549794326
Validation loss: 2.3282852838936927

Epoch: 5| Step: 4
Training loss: 0.2180904083094329
Validation loss: 2.3395307237934024

Epoch: 5| Step: 5
Training loss: 0.21541620629081254
Validation loss: 2.3564056411775747

Epoch: 5| Step: 6
Training loss: 0.3543999922482208
Validation loss: 2.3383622397449595

Epoch: 5| Step: 7
Training loss: 0.2882269174915198
Validation loss: 2.3599129742392697

Epoch: 5| Step: 8
Training loss: 0.40106510944299284
Validation loss: 2.3851388286834374

Epoch: 5| Step: 9
Training loss: 0.2851161797993438
Validation loss: 2.366723737703045

Epoch: 5| Step: 10
Training loss: 0.16583259253979404
Validation loss: 2.393820827360223

Epoch: 561| Step: 0
Training loss: 0.27168336614864774
Validation loss: 2.368299811730443

Epoch: 5| Step: 1
Training loss: 0.32698262126045996
Validation loss: 2.3751300372462305

Epoch: 5| Step: 2
Training loss: 0.13782869466575887
Validation loss: 2.4119880211646842

Epoch: 5| Step: 3
Training loss: 0.3226646265231086
Validation loss: 2.392316399649644

Epoch: 5| Step: 4
Training loss: 0.31790741040606646
Validation loss: 2.363180560729237

Epoch: 5| Step: 5
Training loss: 0.16499322333652633
Validation loss: 2.368541856829417

Epoch: 5| Step: 6
Training loss: 0.2773156487641001
Validation loss: 2.3710971314691514

Epoch: 5| Step: 7
Training loss: 0.1460403196782435
Validation loss: 2.367592035068676

Epoch: 5| Step: 8
Training loss: 0.26621061172521393
Validation loss: 2.3785481139160467

Epoch: 5| Step: 9
Training loss: 0.27296214337534175
Validation loss: 2.368013077508695

Epoch: 5| Step: 10
Training loss: 0.1802329822911432
Validation loss: 2.3675967558233295

Epoch: 562| Step: 0
Training loss: 0.26972521837522484
Validation loss: 2.3488025952442415

Epoch: 5| Step: 1
Training loss: 0.170172161719214
Validation loss: 2.3429112202992424

Epoch: 5| Step: 2
Training loss: 0.23969529307104143
Validation loss: 2.379604899025294

Epoch: 5| Step: 3
Training loss: 0.22382751884178648
Validation loss: 2.3844769121427345

Epoch: 5| Step: 4
Training loss: 0.36113698904326075
Validation loss: 2.359113449880042

Epoch: 5| Step: 5
Training loss: 0.32894833900283377
Validation loss: 2.3766770047056145

Epoch: 5| Step: 6
Training loss: 0.19356978171856581
Validation loss: 2.40782390740122

Epoch: 5| Step: 7
Training loss: 0.3277786220467375
Validation loss: 2.366789955100733

Epoch: 5| Step: 8
Training loss: 0.2591236470744269
Validation loss: 2.3445333362684644

Epoch: 5| Step: 9
Training loss: 0.28107558246319103
Validation loss: 2.3075007878586833

Epoch: 5| Step: 10
Training loss: 0.1859299169324444
Validation loss: 2.2781038535703524

Epoch: 563| Step: 0
Training loss: 0.15929145633523306
Validation loss: 2.2729871883441364

Epoch: 5| Step: 1
Training loss: 0.26062399081851234
Validation loss: 2.264984139797075

Epoch: 5| Step: 2
Training loss: 0.34626560465219314
Validation loss: 2.2832634379437073

Epoch: 5| Step: 3
Training loss: 0.1987204021931673
Validation loss: 2.2834997165979853

Epoch: 5| Step: 4
Training loss: 0.4533010173801759
Validation loss: 2.2921973591891573

Epoch: 5| Step: 5
Training loss: 0.2979057762960951
Validation loss: 2.2922584526568586

Epoch: 5| Step: 6
Training loss: 0.25395143547005405
Validation loss: 2.293239081647837

Epoch: 5| Step: 7
Training loss: 0.29058357784453126
Validation loss: 2.361349963300396

Epoch: 5| Step: 8
Training loss: 0.26349513877043557
Validation loss: 2.3608672512136644

Epoch: 5| Step: 9
Training loss: 0.3093132492051731
Validation loss: 2.407146839673023

Epoch: 5| Step: 10
Training loss: 0.2606615520478168
Validation loss: 2.3783073324025175

Epoch: 564| Step: 0
Training loss: 0.29869234827644264
Validation loss: 2.3838468262508514

Epoch: 5| Step: 1
Training loss: 0.10394772279160443
Validation loss: 2.3778543100233254

Epoch: 5| Step: 2
Training loss: 0.2057112321802632
Validation loss: 2.355482204491818

Epoch: 5| Step: 3
Training loss: 0.24778054424584217
Validation loss: 2.373951021281729

Epoch: 5| Step: 4
Training loss: 0.15790959784527564
Validation loss: 2.3639525836728144

Epoch: 5| Step: 5
Training loss: 0.3032740182422184
Validation loss: 2.3819595507523794

Epoch: 5| Step: 6
Training loss: 0.3018832640375619
Validation loss: 2.353400909987181

Epoch: 5| Step: 7
Training loss: 0.1299967087159386
Validation loss: 2.339181149674681

Epoch: 5| Step: 8
Training loss: 0.36638151138178426
Validation loss: 2.342043065159787

Epoch: 5| Step: 9
Training loss: 0.38394266796530574
Validation loss: 2.3763837124296243

Epoch: 5| Step: 10
Training loss: 0.3853600649468468
Validation loss: 2.355877077341109

Epoch: 565| Step: 0
Training loss: 0.3077045861474261
Validation loss: 2.3522113393727375

Epoch: 5| Step: 1
Training loss: 0.2929925146001142
Validation loss: 2.3644309859216355

Epoch: 5| Step: 2
Training loss: 0.23705734109331503
Validation loss: 2.3443966854583853

Epoch: 5| Step: 3
Training loss: 0.22930281922208115
Validation loss: 2.327773366656454

Epoch: 5| Step: 4
Training loss: 0.36527937341606664
Validation loss: 2.3127362220150833

Epoch: 5| Step: 5
Training loss: 0.3156321203731688
Validation loss: 2.3451854901105387

Epoch: 5| Step: 6
Training loss: 0.2442577386340773
Validation loss: 2.31504198936226

Epoch: 5| Step: 7
Training loss: 0.2942919287533011
Validation loss: 2.3764442387617253

Epoch: 5| Step: 8
Training loss: 0.24615128162557148
Validation loss: 2.37862370651871

Epoch: 5| Step: 9
Training loss: 0.2786419799870997
Validation loss: 2.4098296752694583

Epoch: 5| Step: 10
Training loss: 0.39745775076223633
Validation loss: 2.3989397224385907

Epoch: 566| Step: 0
Training loss: 0.30667427510087003
Validation loss: 2.4311211837181625

Epoch: 5| Step: 1
Training loss: 0.4051513855771218
Validation loss: 2.415083595734645

Epoch: 5| Step: 2
Training loss: 0.30618616918090474
Validation loss: 2.454277371424162

Epoch: 5| Step: 3
Training loss: 0.3154118653922628
Validation loss: 2.4238856199397913

Epoch: 5| Step: 4
Training loss: 0.18517926592163875
Validation loss: 2.3902414115896824

Epoch: 5| Step: 5
Training loss: 0.23734334152065986
Validation loss: 2.3787166667352952

Epoch: 5| Step: 6
Training loss: 0.17322892952197602
Validation loss: 2.3700367064000467

Epoch: 5| Step: 7
Training loss: 0.1717844475279756
Validation loss: 2.314042299866604

Epoch: 5| Step: 8
Training loss: 0.23641472798113852
Validation loss: 2.3305027946954584

Epoch: 5| Step: 9
Training loss: 0.36556962889987166
Validation loss: 2.297236126421266

Epoch: 5| Step: 10
Training loss: 0.32650531925261456
Validation loss: 2.2716998102682506

Epoch: 567| Step: 0
Training loss: 0.22501780651415923
Validation loss: 2.302396755647442

Epoch: 5| Step: 1
Training loss: 0.3073709743875288
Validation loss: 2.292704233972083

Epoch: 5| Step: 2
Training loss: 0.20825712280296613
Validation loss: 2.293825199816543

Epoch: 5| Step: 3
Training loss: 0.3011594227988563
Validation loss: 2.3543690158811468

Epoch: 5| Step: 4
Training loss: 0.2961729683499895
Validation loss: 2.374155368234329

Epoch: 5| Step: 5
Training loss: 0.3409423281802398
Validation loss: 2.3536094995715917

Epoch: 5| Step: 6
Training loss: 0.2369043088762238
Validation loss: 2.318701667106118

Epoch: 5| Step: 7
Training loss: 0.27746859950609204
Validation loss: 2.2665541370599884

Epoch: 5| Step: 8
Training loss: 0.22674015906301678
Validation loss: 2.2418365964270914

Epoch: 5| Step: 9
Training loss: 0.34919421090566066
Validation loss: 2.239389911912078

Epoch: 5| Step: 10
Training loss: 0.3579761189335438
Validation loss: 2.245322023475528

Epoch: 568| Step: 0
Training loss: 0.39950064394568346
Validation loss: 2.234858904436212

Epoch: 5| Step: 1
Training loss: 0.2782955225562067
Validation loss: 2.244188911921426

Epoch: 5| Step: 2
Training loss: 0.3252937809325048
Validation loss: 2.2581292022648447

Epoch: 5| Step: 3
Training loss: 0.2501103783365309
Validation loss: 2.2611730918602366

Epoch: 5| Step: 4
Training loss: 0.22185531246792017
Validation loss: 2.3149040195910193

Epoch: 5| Step: 5
Training loss: 0.3035984382915286
Validation loss: 2.331583725845177

Epoch: 5| Step: 6
Training loss: 0.271334819628732
Validation loss: 2.3622391541117405

Epoch: 5| Step: 7
Training loss: 0.2518489237745115
Validation loss: 2.4078708873897208

Epoch: 5| Step: 8
Training loss: 0.2948439286660531
Validation loss: 2.3850354441122317

Epoch: 5| Step: 9
Training loss: 0.28859705439288325
Validation loss: 2.389742449278962

Epoch: 5| Step: 10
Training loss: 0.25950321050635095
Validation loss: 2.3338959622801005

Epoch: 569| Step: 0
Training loss: 0.12983541412541838
Validation loss: 2.3564300216354734

Epoch: 5| Step: 1
Training loss: 0.32115771266822807
Validation loss: 2.3473055105263523

Epoch: 5| Step: 2
Training loss: 0.19004142501005525
Validation loss: 2.330656069990363

Epoch: 5| Step: 3
Training loss: 0.4424046896268178
Validation loss: 2.332343895566942

Epoch: 5| Step: 4
Training loss: 0.42413559760815217
Validation loss: 2.337746116768089

Epoch: 5| Step: 5
Training loss: 0.24610997706607182
Validation loss: 2.341766620783241

Epoch: 5| Step: 6
Training loss: 0.3222388632095122
Validation loss: 2.331115704536178

Epoch: 5| Step: 7
Training loss: 0.21698946603464173
Validation loss: 2.3500122917410633

Epoch: 5| Step: 8
Training loss: 0.5248130544968692
Validation loss: 2.3891759023775405

Epoch: 5| Step: 9
Training loss: 0.36913132025077505
Validation loss: 2.3930338696932743

Epoch: 5| Step: 10
Training loss: 0.19834606850198933
Validation loss: 2.3624402188986053

Epoch: 570| Step: 0
Training loss: 0.2982934769032304
Validation loss: 2.3440825578479214

Epoch: 5| Step: 1
Training loss: 0.3091064250654686
Validation loss: 2.291317649358974

Epoch: 5| Step: 2
Training loss: 0.4737405713383636
Validation loss: 2.324224834204956

Epoch: 5| Step: 3
Training loss: 0.3331396339809337
Validation loss: 2.3127679373055754

Epoch: 5| Step: 4
Training loss: 0.2868555984501972
Validation loss: 2.302480277448336

Epoch: 5| Step: 5
Training loss: 0.19413281852945985
Validation loss: 2.3053671103012507

Epoch: 5| Step: 6
Training loss: 0.21961724847001118
Validation loss: 2.3240072345597387

Epoch: 5| Step: 7
Training loss: 0.36075625141778445
Validation loss: 2.3497806407856126

Epoch: 5| Step: 8
Training loss: 0.24622917990121393
Validation loss: 2.34859353834833

Epoch: 5| Step: 9
Training loss: 0.2866871772242031
Validation loss: 2.340531550302209

Epoch: 5| Step: 10
Training loss: 0.31341692395813764
Validation loss: 2.2980604016928052

Epoch: 571| Step: 0
Training loss: 0.33897745498588616
Validation loss: 2.303369673766716

Epoch: 5| Step: 1
Training loss: 0.2018206145042458
Validation loss: 2.3334960715028132

Epoch: 5| Step: 2
Training loss: 0.24853002246883066
Validation loss: 2.34305126863308

Epoch: 5| Step: 3
Training loss: 0.2483564082541781
Validation loss: 2.3202120475836288

Epoch: 5| Step: 4
Training loss: 0.35714306405606405
Validation loss: 2.3253285571828295

Epoch: 5| Step: 5
Training loss: 0.3951350586602551
Validation loss: 2.2897251526127724

Epoch: 5| Step: 6
Training loss: 0.31362252090602427
Validation loss: 2.2927166224600324

Epoch: 5| Step: 7
Training loss: 0.18776578741200703
Validation loss: 2.2868667347307525

Epoch: 5| Step: 8
Training loss: 0.2882755754527441
Validation loss: 2.266810636574797

Epoch: 5| Step: 9
Training loss: 0.2844493150547583
Validation loss: 2.252215966845866

Epoch: 5| Step: 10
Training loss: 0.42264349137261875
Validation loss: 2.2455758530748446

Epoch: 572| Step: 0
Training loss: 0.2324788881145752
Validation loss: 2.2502927373232513

Epoch: 5| Step: 1
Training loss: 0.31299887414583516
Validation loss: 2.2747851153423766

Epoch: 5| Step: 2
Training loss: 0.2024162471906143
Validation loss: 2.2690433534582555

Epoch: 5| Step: 3
Training loss: 0.30862237097407214
Validation loss: 2.2573092240676016

Epoch: 5| Step: 4
Training loss: 0.29332632495805544
Validation loss: 2.3388268368398655

Epoch: 5| Step: 5
Training loss: 0.16649922451026275
Validation loss: 2.3032953314077624

Epoch: 5| Step: 6
Training loss: 0.29972265407281506
Validation loss: 2.3656463896907556

Epoch: 5| Step: 7
Training loss: 0.23982938108364432
Validation loss: 2.344267127300061

Epoch: 5| Step: 8
Training loss: 0.3146392082125247
Validation loss: 2.363154404335406

Epoch: 5| Step: 9
Training loss: 0.33845224177553174
Validation loss: 2.3799558388785527

Epoch: 5| Step: 10
Training loss: 0.2784321744219
Validation loss: 2.35035756678198

Epoch: 573| Step: 0
Training loss: 0.24706681441292186
Validation loss: 2.3323971073909413

Epoch: 5| Step: 1
Training loss: 0.13356571628391345
Validation loss: 2.3533624474528727

Epoch: 5| Step: 2
Training loss: 0.33219058757577974
Validation loss: 2.324026461725115

Epoch: 5| Step: 3
Training loss: 0.38398760835949114
Validation loss: 2.3468250296920474

Epoch: 5| Step: 4
Training loss: 0.2869611084801412
Validation loss: 2.3043247911496687

Epoch: 5| Step: 5
Training loss: 0.23588819778132583
Validation loss: 2.3039421877267623

Epoch: 5| Step: 6
Training loss: 0.23261041767509086
Validation loss: 2.2802246763097846

Epoch: 5| Step: 7
Training loss: 0.27726397911823664
Validation loss: 2.2868116209887006

Epoch: 5| Step: 8
Training loss: 0.22713650141521635
Validation loss: 2.2893635054476156

Epoch: 5| Step: 9
Training loss: 0.2853419861697748
Validation loss: 2.257208053638099

Epoch: 5| Step: 10
Training loss: 0.22540713734031007
Validation loss: 2.3001425741937602

Epoch: 574| Step: 0
Training loss: 0.2652860610782691
Validation loss: 2.2848446325287863

Epoch: 5| Step: 1
Training loss: 0.2813343213094709
Validation loss: 2.2595621256097522

Epoch: 5| Step: 2
Training loss: 0.25741458297844055
Validation loss: 2.294759236168883

Epoch: 5| Step: 3
Training loss: 0.3286043593852063
Validation loss: 2.314237609717883

Epoch: 5| Step: 4
Training loss: 0.1764187748975909
Validation loss: 2.3055611571756094

Epoch: 5| Step: 5
Training loss: 0.1923789977649134
Validation loss: 2.298168292350215

Epoch: 5| Step: 6
Training loss: 0.2337195210934418
Validation loss: 2.3191563618715323

Epoch: 5| Step: 7
Training loss: 0.20576021205674538
Validation loss: 2.3216568484480535

Epoch: 5| Step: 8
Training loss: 0.44599955243999106
Validation loss: 2.3304558182175317

Epoch: 5| Step: 9
Training loss: 0.2686554736971136
Validation loss: 2.3087274703423435

Epoch: 5| Step: 10
Training loss: 0.26651128001791086
Validation loss: 2.3247249805808847

Epoch: 575| Step: 0
Training loss: 0.25337648144003316
Validation loss: 2.3480738919330046

Epoch: 5| Step: 1
Training loss: 0.41270550102803816
Validation loss: 2.3488525369710205

Epoch: 5| Step: 2
Training loss: 0.19106291125187463
Validation loss: 2.37219073321676

Epoch: 5| Step: 3
Training loss: 0.19918252578212342
Validation loss: 2.3608297171494668

Epoch: 5| Step: 4
Training loss: 0.1455169073245175
Validation loss: 2.402452449772143

Epoch: 5| Step: 5
Training loss: 0.2502747158817503
Validation loss: 2.39159494007843

Epoch: 5| Step: 6
Training loss: 0.23337038422225367
Validation loss: 2.375432700963549

Epoch: 5| Step: 7
Training loss: 0.2884238120620069
Validation loss: 2.385505509825604

Epoch: 5| Step: 8
Training loss: 0.18603459555874333
Validation loss: 2.3923844831641397

Epoch: 5| Step: 9
Training loss: 0.3124530399324492
Validation loss: 2.385174094970676

Epoch: 5| Step: 10
Training loss: 0.17333721642450717
Validation loss: 2.387161816611879

Epoch: 576| Step: 0
Training loss: 0.16176142175660116
Validation loss: 2.385523741599542

Epoch: 5| Step: 1
Training loss: 0.24531907054581525
Validation loss: 2.3447765713626363

Epoch: 5| Step: 2
Training loss: 0.21420996556819263
Validation loss: 2.35726109428871

Epoch: 5| Step: 3
Training loss: 0.13960072562647716
Validation loss: 2.330560885580585

Epoch: 5| Step: 4
Training loss: 0.23754288449354688
Validation loss: 2.353757425409495

Epoch: 5| Step: 5
Training loss: 0.28779347979212533
Validation loss: 2.3217055720379

Epoch: 5| Step: 6
Training loss: 0.37851569113716044
Validation loss: 2.326720150895427

Epoch: 5| Step: 7
Training loss: 0.172750066064361
Validation loss: 2.3180035655537066

Epoch: 5| Step: 8
Training loss: 0.3235252385759605
Validation loss: 2.317329598306359

Epoch: 5| Step: 9
Training loss: 0.23411063543491
Validation loss: 2.2993861374374047

Epoch: 5| Step: 10
Training loss: 0.24327360696124253
Validation loss: 2.3048076172164267

Epoch: 577| Step: 0
Training loss: 0.2245868008091709
Validation loss: 2.360773176572051

Epoch: 5| Step: 1
Training loss: 0.31430709006796065
Validation loss: 2.3395051610021707

Epoch: 5| Step: 2
Training loss: 0.21332304897764032
Validation loss: 2.3276997081625623

Epoch: 5| Step: 3
Training loss: 0.21195624850116243
Validation loss: 2.2926399330744607

Epoch: 5| Step: 4
Training loss: 0.3043490265998797
Validation loss: 2.297248360739334

Epoch: 5| Step: 5
Training loss: 0.20798891724922605
Validation loss: 2.270842626017711

Epoch: 5| Step: 6
Training loss: 0.15810345229617773
Validation loss: 2.281971759825848

Epoch: 5| Step: 7
Training loss: 0.26073225766822616
Validation loss: 2.2885509480603377

Epoch: 5| Step: 8
Training loss: 0.1188212436674904
Validation loss: 2.274690501591284

Epoch: 5| Step: 9
Training loss: 0.18678133047496892
Validation loss: 2.279101095868408

Epoch: 5| Step: 10
Training loss: 0.2994949654544488
Validation loss: 2.282669904362032

Epoch: 578| Step: 0
Training loss: 0.23256681234712984
Validation loss: 2.283641389431956

Epoch: 5| Step: 1
Training loss: 0.3210338518097981
Validation loss: 2.31626270906862

Epoch: 5| Step: 2
Training loss: 0.34581032938838746
Validation loss: 2.2903767450373262

Epoch: 5| Step: 3
Training loss: 0.16580836878740687
Validation loss: 2.3042655557184055

Epoch: 5| Step: 4
Training loss: 0.1926367192760051
Validation loss: 2.293542039399837

Epoch: 5| Step: 5
Training loss: 0.16038328454063708
Validation loss: 2.285324529974848

Epoch: 5| Step: 6
Training loss: 0.1979791088901652
Validation loss: 2.3345505676961777

Epoch: 5| Step: 7
Training loss: 0.21673098413414962
Validation loss: 2.3395431456662155

Epoch: 5| Step: 8
Training loss: 0.30173400982553206
Validation loss: 2.320074821732396

Epoch: 5| Step: 9
Training loss: 0.16167789509847214
Validation loss: 2.330058958774171

Epoch: 5| Step: 10
Training loss: 0.20974303182478235
Validation loss: 2.316862287102166

Epoch: 579| Step: 0
Training loss: 0.21501843546684224
Validation loss: 2.3153651756716678

Epoch: 5| Step: 1
Training loss: 0.12207946743014049
Validation loss: 2.3152285406265043

Epoch: 5| Step: 2
Training loss: 0.25966963751329497
Validation loss: 2.3234822505185933

Epoch: 5| Step: 3
Training loss: 0.14651467327855547
Validation loss: 2.3106834351779266

Epoch: 5| Step: 4
Training loss: 0.3016773227637003
Validation loss: 2.3288060202759127

Epoch: 5| Step: 5
Training loss: 0.19771336269379775
Validation loss: 2.314612875913685

Epoch: 5| Step: 6
Training loss: 0.24157429558995608
Validation loss: 2.325929013341513

Epoch: 5| Step: 7
Training loss: 0.26337292996458933
Validation loss: 2.288371661299116

Epoch: 5| Step: 8
Training loss: 0.11799951793154952
Validation loss: 2.2958462406162847

Epoch: 5| Step: 9
Training loss: 0.30844058086475995
Validation loss: 2.2966380864592555

Epoch: 5| Step: 10
Training loss: 0.10901495306309034
Validation loss: 2.3076897323166494

Epoch: 580| Step: 0
Training loss: 0.28282943274457656
Validation loss: 2.278889687330054

Epoch: 5| Step: 1
Training loss: 0.11571068842686383
Validation loss: 2.2986835616859795

Epoch: 5| Step: 2
Training loss: 0.16618530353688515
Validation loss: 2.316572920591251

Epoch: 5| Step: 3
Training loss: 0.11364807554871653
Validation loss: 2.3161891499419105

Epoch: 5| Step: 4
Training loss: 0.1802675897180885
Validation loss: 2.3223214074943512

Epoch: 5| Step: 5
Training loss: 0.17761035406870238
Validation loss: 2.318910344901171

Epoch: 5| Step: 6
Training loss: 0.18762625973155955
Validation loss: 2.324370658434642

Epoch: 5| Step: 7
Training loss: 0.2733932868089723
Validation loss: 2.3072137062299714

Epoch: 5| Step: 8
Training loss: 0.26375625108027495
Validation loss: 2.3318896179948605

Epoch: 5| Step: 9
Training loss: 0.3870517568503294
Validation loss: 2.3174366162038407

Epoch: 5| Step: 10
Training loss: 0.1689175599517156
Validation loss: 2.304258330166572

Epoch: 581| Step: 0
Training loss: 0.2228794902850891
Validation loss: 2.306234148270446

Epoch: 5| Step: 1
Training loss: 0.15547265761942272
Validation loss: 2.2696534836354165

Epoch: 5| Step: 2
Training loss: 0.26572644876944174
Validation loss: 2.3111803179909587

Epoch: 5| Step: 3
Training loss: 0.2256142569597002
Validation loss: 2.308876804380834

Epoch: 5| Step: 4
Training loss: 0.329542786806394
Validation loss: 2.2971117038459576

Epoch: 5| Step: 5
Training loss: 0.1367863556059555
Validation loss: 2.3182653701845317

Epoch: 5| Step: 6
Training loss: 0.22369914341339667
Validation loss: 2.3372065052510824

Epoch: 5| Step: 7
Training loss: 0.14190570789906498
Validation loss: 2.3298321416950385

Epoch: 5| Step: 8
Training loss: 0.23740059284300483
Validation loss: 2.2919524058486362

Epoch: 5| Step: 9
Training loss: 0.22859121360336415
Validation loss: 2.3278765923373803

Epoch: 5| Step: 10
Training loss: 0.13669934816295756
Validation loss: 2.338901596129649

Epoch: 582| Step: 0
Training loss: 0.2039912167369311
Validation loss: 2.334593797390103

Epoch: 5| Step: 1
Training loss: 0.2317202580737931
Validation loss: 2.3863764997942742

Epoch: 5| Step: 2
Training loss: 0.19102975250922735
Validation loss: 2.3178094919013064

Epoch: 5| Step: 3
Training loss: 0.19327643571191358
Validation loss: 2.3428923888419226

Epoch: 5| Step: 4
Training loss: 0.2731978047054414
Validation loss: 2.3297156871968516

Epoch: 5| Step: 5
Training loss: 0.1940522159548182
Validation loss: 2.349055554760625

Epoch: 5| Step: 6
Training loss: 0.19332944272260577
Validation loss: 2.3628571062838

Epoch: 5| Step: 7
Training loss: 0.2616296730471671
Validation loss: 2.3552685005941556

Epoch: 5| Step: 8
Training loss: 0.29195346384128323
Validation loss: 2.334775226102929

Epoch: 5| Step: 9
Training loss: 0.17931440222014738
Validation loss: 2.3322744231900687

Epoch: 5| Step: 10
Training loss: 0.18359226875519274
Validation loss: 2.3421685519982978

Epoch: 583| Step: 0
Training loss: 0.29446181989156384
Validation loss: 2.3473342233205723

Epoch: 5| Step: 1
Training loss: 0.16499431838743964
Validation loss: 2.3243121941756364

Epoch: 5| Step: 2
Training loss: 0.1989533114590075
Validation loss: 2.3184411164695353

Epoch: 5| Step: 3
Training loss: 0.19170731592008552
Validation loss: 2.3387108822947824

Epoch: 5| Step: 4
Training loss: 0.11937033677230151
Validation loss: 2.323654676337407

Epoch: 5| Step: 5
Training loss: 0.21350794715909205
Validation loss: 2.3118132120438712

Epoch: 5| Step: 6
Training loss: 0.21781300069896445
Validation loss: 2.2872959751356197

Epoch: 5| Step: 7
Training loss: 0.19069697865946747
Validation loss: 2.2694375796098396

Epoch: 5| Step: 8
Training loss: 0.2398013577600574
Validation loss: 2.3081465253016757

Epoch: 5| Step: 9
Training loss: 0.21885403645520798
Validation loss: 2.2520384800486166

Epoch: 5| Step: 10
Training loss: 0.2624838733260695
Validation loss: 2.2654578826565044

Epoch: 584| Step: 0
Training loss: 0.1785469657882362
Validation loss: 2.2533576744041803

Epoch: 5| Step: 1
Training loss: 0.13581998914450288
Validation loss: 2.251887103788926

Epoch: 5| Step: 2
Training loss: 0.18271746406735517
Validation loss: 2.2597362794244384

Epoch: 5| Step: 3
Training loss: 0.34878803719126245
Validation loss: 2.2847722341841594

Epoch: 5| Step: 4
Training loss: 0.20667084326933216
Validation loss: 2.2501732646720174

Epoch: 5| Step: 5
Training loss: 0.17467513691516118
Validation loss: 2.272925578580266

Epoch: 5| Step: 6
Training loss: 0.334356413084005
Validation loss: 2.283805453116458

Epoch: 5| Step: 7
Training loss: 0.218710512616303
Validation loss: 2.3211306320142184

Epoch: 5| Step: 8
Training loss: 0.24365792430533845
Validation loss: 2.3471371977782622

Epoch: 5| Step: 9
Training loss: 0.17793087001034916
Validation loss: 2.3476030919299524

Epoch: 5| Step: 10
Training loss: 0.19413205095235642
Validation loss: 2.318874626944364

Epoch: 585| Step: 0
Training loss: 0.15557578777562497
Validation loss: 2.338127139139034

Epoch: 5| Step: 1
Training loss: 0.22460551051256855
Validation loss: 2.377924844679995

Epoch: 5| Step: 2
Training loss: 0.18370739483443982
Validation loss: 2.3058413885042817

Epoch: 5| Step: 3
Training loss: 0.17088123234927025
Validation loss: 2.2943963500288205

Epoch: 5| Step: 4
Training loss: 0.19670949102098909
Validation loss: 2.310881191368241

Epoch: 5| Step: 5
Training loss: 0.27773586278160123
Validation loss: 2.280025829677286

Epoch: 5| Step: 6
Training loss: 0.12318099372240393
Validation loss: 2.290503285086461

Epoch: 5| Step: 7
Training loss: 0.20324426597516346
Validation loss: 2.281041630696482

Epoch: 5| Step: 8
Training loss: 0.23144075735253228
Validation loss: 2.3062915468223917

Epoch: 5| Step: 9
Training loss: 0.28355833993743707
Validation loss: 2.3076314275760637

Epoch: 5| Step: 10
Training loss: 0.274743110248412
Validation loss: 2.3014739457810958

Epoch: 586| Step: 0
Training loss: 0.25061060426516274
Validation loss: 2.3324986666488603

Epoch: 5| Step: 1
Training loss: 0.16861163798370699
Validation loss: 2.328821654339796

Epoch: 5| Step: 2
Training loss: 0.24887150636325533
Validation loss: 2.318585963254579

Epoch: 5| Step: 3
Training loss: 0.11556051057105807
Validation loss: 2.2906626559438505

Epoch: 5| Step: 4
Training loss: 0.15957131216233328
Validation loss: 2.2988963465729397

Epoch: 5| Step: 5
Training loss: 0.28649331515021276
Validation loss: 2.334627327387031

Epoch: 5| Step: 6
Training loss: 0.2575728284981426
Validation loss: 2.32839229921517

Epoch: 5| Step: 7
Training loss: 0.10167035006846183
Validation loss: 2.336606984331755

Epoch: 5| Step: 8
Training loss: 0.12060346872007278
Validation loss: 2.3064432610488854

Epoch: 5| Step: 9
Training loss: 0.1868452122719279
Validation loss: 2.2979908282958905

Epoch: 5| Step: 10
Training loss: 0.2627004176214563
Validation loss: 2.3151083616902057

Epoch: 587| Step: 0
Training loss: 0.2224566250752348
Validation loss: 2.32858038026965

Epoch: 5| Step: 1
Training loss: 0.12155841306911216
Validation loss: 2.3079913597001362

Epoch: 5| Step: 2
Training loss: 0.2873342243418262
Validation loss: 2.316885374402454

Epoch: 5| Step: 3
Training loss: 0.243979645108204
Validation loss: 2.296095399281978

Epoch: 5| Step: 4
Training loss: 0.12489074536860266
Validation loss: 2.304658856569345

Epoch: 5| Step: 5
Training loss: 0.14426614960895595
Validation loss: 2.313038846077241

Epoch: 5| Step: 6
Training loss: 0.18111854299576044
Validation loss: 2.2741366592171217

Epoch: 5| Step: 7
Training loss: 0.27281957014170805
Validation loss: 2.2783132280235776

Epoch: 5| Step: 8
Training loss: 0.1708122690131548
Validation loss: 2.297277357698914

Epoch: 5| Step: 9
Training loss: 0.15563298229826592
Validation loss: 2.3044549684622457

Epoch: 5| Step: 10
Training loss: 0.24787205821035943
Validation loss: 2.298240330048427

Epoch: 588| Step: 0
Training loss: 0.2237453011200505
Validation loss: 2.285952341616399

Epoch: 5| Step: 1
Training loss: 0.16479199442205938
Validation loss: 2.313530750142433

Epoch: 5| Step: 2
Training loss: 0.24700019806543122
Validation loss: 2.289722401684864

Epoch: 5| Step: 3
Training loss: 0.17439510268037534
Validation loss: 2.3123755894092484

Epoch: 5| Step: 4
Training loss: 0.09275436205258956
Validation loss: 2.2982669502616524

Epoch: 5| Step: 5
Training loss: 0.12610414240009338
Validation loss: 2.3220931379907177

Epoch: 5| Step: 6
Training loss: 0.2823683306745272
Validation loss: 2.3195075077139924

Epoch: 5| Step: 7
Training loss: 0.3267581832527935
Validation loss: 2.3061310699528628

Epoch: 5| Step: 8
Training loss: 0.2395130119920296
Validation loss: 2.3306092681999284

Epoch: 5| Step: 9
Training loss: 0.07867568956690528
Validation loss: 2.294608817442884

Epoch: 5| Step: 10
Training loss: 0.10145994198425959
Validation loss: 2.3037227907874653

Epoch: 589| Step: 0
Training loss: 0.12707459434052026
Validation loss: 2.2977520304406704

Epoch: 5| Step: 1
Training loss: 0.2031430914965086
Validation loss: 2.294460978798474

Epoch: 5| Step: 2
Training loss: 0.1418233187374767
Validation loss: 2.3058867140304637

Epoch: 5| Step: 3
Training loss: 0.29124368781506593
Validation loss: 2.3195452362941844

Epoch: 5| Step: 4
Training loss: 0.2744296059329922
Validation loss: 2.2894175857899706

Epoch: 5| Step: 5
Training loss: 0.16990445584866623
Validation loss: 2.303505139172772

Epoch: 5| Step: 6
Training loss: 0.12752099310793208
Validation loss: 2.3063338900666306

Epoch: 5| Step: 7
Training loss: 0.1739342290678344
Validation loss: 2.2984886737434596

Epoch: 5| Step: 8
Training loss: 0.1898730137723009
Validation loss: 2.280589091262427

Epoch: 5| Step: 9
Training loss: 0.29897672411656523
Validation loss: 2.312264474516751

Epoch: 5| Step: 10
Training loss: 0.09315542085023291
Validation loss: 2.3226678921891835

Epoch: 590| Step: 0
Training loss: 0.11232523937421644
Validation loss: 2.320552712536243

Epoch: 5| Step: 1
Training loss: 0.11533994203419203
Validation loss: 2.3050882637938463

Epoch: 5| Step: 2
Training loss: 0.3066515707990234
Validation loss: 2.3040077843697295

Epoch: 5| Step: 3
Training loss: 0.15825905223390418
Validation loss: 2.293163077989118

Epoch: 5| Step: 4
Training loss: 0.1294237931471026
Validation loss: 2.2935492358379856

Epoch: 5| Step: 5
Training loss: 0.30115041742934007
Validation loss: 2.2800138650007358

Epoch: 5| Step: 6
Training loss: 0.21881497644255948
Validation loss: 2.3016255996952313

Epoch: 5| Step: 7
Training loss: 0.18107436730546714
Validation loss: 2.3048051812751718

Epoch: 5| Step: 8
Training loss: 0.18764126939398465
Validation loss: 2.2837209609489872

Epoch: 5| Step: 9
Training loss: 0.2515426811561981
Validation loss: 2.295501041330036

Epoch: 5| Step: 10
Training loss: 0.16104092145215226
Validation loss: 2.3110053374103785

Epoch: 591| Step: 0
Training loss: 0.14115164740108146
Validation loss: 2.3175091661466074

Epoch: 5| Step: 1
Training loss: 0.270754429743097
Validation loss: 2.3270743455527003

Epoch: 5| Step: 2
Training loss: 0.16268530193181957
Validation loss: 2.310482001594237

Epoch: 5| Step: 3
Training loss: 0.12912089366144325
Validation loss: 2.3029797026971153

Epoch: 5| Step: 4
Training loss: 0.15845534152711405
Validation loss: 2.3302757248781085

Epoch: 5| Step: 5
Training loss: 0.244227058369384
Validation loss: 2.303499487705842

Epoch: 5| Step: 6
Training loss: 0.2756312651365481
Validation loss: 2.2841247895154044

Epoch: 5| Step: 7
Training loss: 0.11843306683494502
Validation loss: 2.2868030970343347

Epoch: 5| Step: 8
Training loss: 0.22995055666250844
Validation loss: 2.288045084008519

Epoch: 5| Step: 9
Training loss: 0.22251649285117697
Validation loss: 2.2663092508167773

Epoch: 5| Step: 10
Training loss: 0.29410741144840213
Validation loss: 2.2570521871398093

Epoch: 592| Step: 0
Training loss: 0.14291537257735615
Validation loss: 2.2959302876799015

Epoch: 5| Step: 1
Training loss: 0.2828100436193529
Validation loss: 2.2755877496786003

Epoch: 5| Step: 2
Training loss: 0.10589825630524266
Validation loss: 2.295400270385424

Epoch: 5| Step: 3
Training loss: 0.10027101438007197
Validation loss: 2.291971845992843

Epoch: 5| Step: 4
Training loss: 0.1020165253598175
Validation loss: 2.3184317235678407

Epoch: 5| Step: 5
Training loss: 0.24145359698420843
Validation loss: 2.2945927290559274

Epoch: 5| Step: 6
Training loss: 0.16179729203741902
Validation loss: 2.290609014622901

Epoch: 5| Step: 7
Training loss: 0.308859071269127
Validation loss: 2.314776946173938

Epoch: 5| Step: 8
Training loss: 0.15608770763551122
Validation loss: 2.3248955025126223

Epoch: 5| Step: 9
Training loss: 0.2758713982834835
Validation loss: 2.3062494890392693

Epoch: 5| Step: 10
Training loss: 0.23954068025363884
Validation loss: 2.2983013002494026

Epoch: 593| Step: 0
Training loss: 0.18132138655146907
Validation loss: 2.3492914823097975

Epoch: 5| Step: 1
Training loss: 0.19737253974289587
Validation loss: 2.2768329410601806

Epoch: 5| Step: 2
Training loss: 0.21378032888831047
Validation loss: 2.302516159537667

Epoch: 5| Step: 3
Training loss: 0.23228138596546016
Validation loss: 2.2992384565603103

Epoch: 5| Step: 4
Training loss: 0.27677569173430616
Validation loss: 2.2753394815329857

Epoch: 5| Step: 5
Training loss: 0.2625113768609904
Validation loss: 2.284381164467946

Epoch: 5| Step: 6
Training loss: 0.18647282098360554
Validation loss: 2.28311860605049

Epoch: 5| Step: 7
Training loss: 0.11816918149216543
Validation loss: 2.2798101441253347

Epoch: 5| Step: 8
Training loss: 0.1305069019590719
Validation loss: 2.2983029109589213

Epoch: 5| Step: 9
Training loss: 0.17496325583943664
Validation loss: 2.266844579405792

Epoch: 5| Step: 10
Training loss: 0.18925277695388476
Validation loss: 2.2875024618109445

Epoch: 594| Step: 0
Training loss: 0.12861308805296226
Validation loss: 2.2835401097242785

Epoch: 5| Step: 1
Training loss: 0.10653625767845193
Validation loss: 2.2944688916249905

Epoch: 5| Step: 2
Training loss: 0.1830512615073904
Validation loss: 2.325260367464979

Epoch: 5| Step: 3
Training loss: 0.18078100183019857
Validation loss: 2.32274172128853

Epoch: 5| Step: 4
Training loss: 0.29397245769690955
Validation loss: 2.341182179874746

Epoch: 5| Step: 5
Training loss: 0.15145764263062048
Validation loss: 2.3103765811988133

Epoch: 5| Step: 6
Training loss: 0.17832901798654083
Validation loss: 2.348821170848482

Epoch: 5| Step: 7
Training loss: 0.2462492179253063
Validation loss: 2.3217163556861817

Epoch: 5| Step: 8
Training loss: 0.3101198751609649
Validation loss: 2.329915696970108

Epoch: 5| Step: 9
Training loss: 0.14967015080265766
Validation loss: 2.30793907738803

Epoch: 5| Step: 10
Training loss: 0.14622724217446795
Validation loss: 2.3008500370647424

Epoch: 595| Step: 0
Training loss: 0.18602229997561767
Validation loss: 2.307448484015279

Epoch: 5| Step: 1
Training loss: 0.16229817300477425
Validation loss: 2.308377327845343

Epoch: 5| Step: 2
Training loss: 0.10899523386985031
Validation loss: 2.3022481988943713

Epoch: 5| Step: 3
Training loss: 0.33422188372611944
Validation loss: 2.27032065853506

Epoch: 5| Step: 4
Training loss: 0.31121672356676733
Validation loss: 2.3067151337779963

Epoch: 5| Step: 5
Training loss: 0.18415314087637458
Validation loss: 2.3161171115326593

Epoch: 5| Step: 6
Training loss: 0.1090929063517421
Validation loss: 2.3037458445141117

Epoch: 5| Step: 7
Training loss: 0.13679615281991178
Validation loss: 2.306335431807134

Epoch: 5| Step: 8
Training loss: 0.18725122398796407
Validation loss: 2.3097868248769613

Epoch: 5| Step: 9
Training loss: 0.13416478381059926
Validation loss: 2.2848565202963336

Epoch: 5| Step: 10
Training loss: 0.17581879426766384
Validation loss: 2.2903550057034674

Epoch: 596| Step: 0
Training loss: 0.10400352567504598
Validation loss: 2.289201743904586

Epoch: 5| Step: 1
Training loss: 0.28645824374573203
Validation loss: 2.2818798286376856

Epoch: 5| Step: 2
Training loss: 0.19890980981786238
Validation loss: 2.2835357689527296

Epoch: 5| Step: 3
Training loss: 0.2559036624231206
Validation loss: 2.28144431034678

Epoch: 5| Step: 4
Training loss: 0.21624596509311364
Validation loss: 2.262349915091429

Epoch: 5| Step: 5
Training loss: 0.21049764478729574
Validation loss: 2.2860367378545843

Epoch: 5| Step: 6
Training loss: 0.21003077920078522
Validation loss: 2.2406408306316647

Epoch: 5| Step: 7
Training loss: 0.19147189629996936
Validation loss: 2.28107535895793

Epoch: 5| Step: 8
Training loss: 0.1534153224782405
Validation loss: 2.278712391996069

Epoch: 5| Step: 9
Training loss: 0.17988088815925135
Validation loss: 2.315780801734939

Epoch: 5| Step: 10
Training loss: 0.15036657066692388
Validation loss: 2.2855173391340493

Epoch: 597| Step: 0
Training loss: 0.10788823245943167
Validation loss: 2.3261118248842645

Epoch: 5| Step: 1
Training loss: 0.1958608463842254
Validation loss: 2.313824275000486

Epoch: 5| Step: 2
Training loss: 0.25992878830443966
Validation loss: 2.296837629000684

Epoch: 5| Step: 3
Training loss: 0.11941144992165409
Validation loss: 2.3174826162406434

Epoch: 5| Step: 4
Training loss: 0.14112086424203216
Validation loss: 2.3348096675865486

Epoch: 5| Step: 5
Training loss: 0.16560788291073994
Validation loss: 2.3418721005099457

Epoch: 5| Step: 6
Training loss: 0.2011380491243647
Validation loss: 2.352932764438085

Epoch: 5| Step: 7
Training loss: 0.2109080223396771
Validation loss: 2.3302822212238796

Epoch: 5| Step: 8
Training loss: 0.336325133484264
Validation loss: 2.3237699904589753

Epoch: 5| Step: 9
Training loss: 0.19260229380762803
Validation loss: 2.327978328982964

Epoch: 5| Step: 10
Training loss: 0.08091872370756975
Validation loss: 2.308265188619625

Epoch: 598| Step: 0
Training loss: 0.14062349663036802
Validation loss: 2.340231689404698

Epoch: 5| Step: 1
Training loss: 0.16861346624482001
Validation loss: 2.309773936640786

Epoch: 5| Step: 2
Training loss: 0.24043558579871094
Validation loss: 2.3490725595615114

Epoch: 5| Step: 3
Training loss: 0.1649627339750583
Validation loss: 2.3106107025377387

Epoch: 5| Step: 4
Training loss: 0.14629210251220182
Validation loss: 2.3152940981971306

Epoch: 5| Step: 5
Training loss: 0.204340534760119
Validation loss: 2.3077561983462234

Epoch: 5| Step: 6
Training loss: 0.2234946577950602
Validation loss: 2.3153786074338236

Epoch: 5| Step: 7
Training loss: 0.18395743972680803
Validation loss: 2.332589262297715

Epoch: 5| Step: 8
Training loss: 0.14781692935767068
Validation loss: 2.3039947886995544

Epoch: 5| Step: 9
Training loss: 0.2558238754688376
Validation loss: 2.3085563382765177

Epoch: 5| Step: 10
Training loss: 0.21428149952177863
Validation loss: 2.3067014551311957

Epoch: 599| Step: 0
Training loss: 0.17837636929329298
Validation loss: 2.2929941126946214

Epoch: 5| Step: 1
Training loss: 0.16174477630387504
Validation loss: 2.3011024284767747

Epoch: 5| Step: 2
Training loss: 0.29528711452064144
Validation loss: 2.2911622067383353

Epoch: 5| Step: 3
Training loss: 0.2280971248788347
Validation loss: 2.2953144794187157

Epoch: 5| Step: 4
Training loss: 0.1237166093622795
Validation loss: 2.297064435953112

Epoch: 5| Step: 5
Training loss: 0.2861853281202378
Validation loss: 2.2991883414243888

Epoch: 5| Step: 6
Training loss: 0.15680670507358077
Validation loss: 2.3048111037223866

Epoch: 5| Step: 7
Training loss: 0.1280878705213036
Validation loss: 2.2966501598740408

Epoch: 5| Step: 8
Training loss: 0.2394167625111929
Validation loss: 2.330459335655915

Epoch: 5| Step: 9
Training loss: 0.13962089160195576
Validation loss: 2.299084342286069

Epoch: 5| Step: 10
Training loss: 0.13820188421508606
Validation loss: 2.3317143111560408

Epoch: 600| Step: 0
Training loss: 0.16024910747031063
Validation loss: 2.335667037163423

Epoch: 5| Step: 1
Training loss: 0.20658642286949006
Validation loss: 2.3329989743809945

Epoch: 5| Step: 2
Training loss: 0.11677308318689932
Validation loss: 2.345922662707705

Epoch: 5| Step: 3
Training loss: 0.211785686300104
Validation loss: 2.3330447315862117

Epoch: 5| Step: 4
Training loss: 0.1783104771620676
Validation loss: 2.2885346319718076

Epoch: 5| Step: 5
Training loss: 0.25871984167844353
Validation loss: 2.3249983636358764

Epoch: 5| Step: 6
Training loss: 0.16818527748010229
Validation loss: 2.306741774551236

Epoch: 5| Step: 7
Training loss: 0.25909965159014764
Validation loss: 2.3254274843951315

Epoch: 5| Step: 8
Training loss: 0.17526133259783788
Validation loss: 2.3026926179731433

Epoch: 5| Step: 9
Training loss: 0.2847266946353467
Validation loss: 2.3060529459548356

Epoch: 5| Step: 10
Training loss: 0.17618083571590634
Validation loss: 2.2801791217510794

Epoch: 601| Step: 0
Training loss: 0.12763329014627758
Validation loss: 2.282105699911907

Epoch: 5| Step: 1
Training loss: 0.1000225157274772
Validation loss: 2.290809034209717

Epoch: 5| Step: 2
Training loss: 0.19826366514923363
Validation loss: 2.309679456414912

Epoch: 5| Step: 3
Training loss: 0.3110444503186082
Validation loss: 2.2803303877570307

Epoch: 5| Step: 4
Training loss: 0.23004654827948445
Validation loss: 2.2762664299478983

Epoch: 5| Step: 5
Training loss: 0.2075923298321035
Validation loss: 2.2977531216114815

Epoch: 5| Step: 6
Training loss: 0.1429574701414155
Validation loss: 2.3375040474668474

Epoch: 5| Step: 7
Training loss: 0.19262003916430281
Validation loss: 2.3114790776130376

Epoch: 5| Step: 8
Training loss: 0.1050044675498189
Validation loss: 2.297972558027327

Epoch: 5| Step: 9
Training loss: 0.18006963109901164
Validation loss: 2.29302226344781

Epoch: 5| Step: 10
Training loss: 0.34311110555244606
Validation loss: 2.2996378021341313

Epoch: 602| Step: 0
Training loss: 0.13709209420182694
Validation loss: 2.3230324801884996

Epoch: 5| Step: 1
Training loss: 0.2464615858155753
Validation loss: 2.307680061805844

Epoch: 5| Step: 2
Training loss: 0.15258543699199137
Validation loss: 2.2911220358289888

Epoch: 5| Step: 3
Training loss: 0.19024596521683274
Validation loss: 2.314075222258618

Epoch: 5| Step: 4
Training loss: 0.2585287260146518
Validation loss: 2.3227579474710676

Epoch: 5| Step: 5
Training loss: 0.24674157750326936
Validation loss: 2.3340115250106623

Epoch: 5| Step: 6
Training loss: 0.060386188767926306
Validation loss: 2.2902047969608774

Epoch: 5| Step: 7
Training loss: 0.2430276143195849
Validation loss: 2.307180229519425

Epoch: 5| Step: 8
Training loss: 0.2440056771205189
Validation loss: 2.3232468485754745

Epoch: 5| Step: 9
Training loss: 0.2645167202460124
Validation loss: 2.351106345898171

Epoch: 5| Step: 10
Training loss: 0.12908605837387746
Validation loss: 2.3321285328167702

Epoch: 603| Step: 0
Training loss: 0.23334505755624071
Validation loss: 2.3331509605309155

Epoch: 5| Step: 1
Training loss: 0.2654655482843967
Validation loss: 2.3199401105856463

Epoch: 5| Step: 2
Training loss: 0.2641600716356294
Validation loss: 2.336536453188504

Epoch: 5| Step: 3
Training loss: 0.18983956870038687
Validation loss: 2.3058413740508468

Epoch: 5| Step: 4
Training loss: 0.19582916586750035
Validation loss: 2.2726609119019514

Epoch: 5| Step: 5
Training loss: 0.268630429770833
Validation loss: 2.284647486288327

Epoch: 5| Step: 6
Training loss: 0.1313861024880959
Validation loss: 2.2603080036857555

Epoch: 5| Step: 7
Training loss: 0.12664411791785804
Validation loss: 2.2396490874848203

Epoch: 5| Step: 8
Training loss: 0.20024475789620308
Validation loss: 2.227581783506006

Epoch: 5| Step: 9
Training loss: 0.24921912937673554
Validation loss: 2.244833073589715

Epoch: 5| Step: 10
Training loss: 0.15039662559725278
Validation loss: 2.2675125265066587

Epoch: 604| Step: 0
Training loss: 0.34181061853297995
Validation loss: 2.2355908218896685

Epoch: 5| Step: 1
Training loss: 0.18163546688180285
Validation loss: 2.283840246798087

Epoch: 5| Step: 2
Training loss: 0.18638867607955736
Validation loss: 2.3086633492174653

Epoch: 5| Step: 3
Training loss: 0.13122276125684448
Validation loss: 2.2921342777243963

Epoch: 5| Step: 4
Training loss: 0.15553926708904087
Validation loss: 2.315262271903745

Epoch: 5| Step: 5
Training loss: 0.2858665060283489
Validation loss: 2.3038931185143317

Epoch: 5| Step: 6
Training loss: 0.216092848124246
Validation loss: 2.357036146015917

Epoch: 5| Step: 7
Training loss: 0.20560042763479547
Validation loss: 2.326550277289655

Epoch: 5| Step: 8
Training loss: 0.10935278224080838
Validation loss: 2.3233080640482577

Epoch: 5| Step: 9
Training loss: 0.22860557057553246
Validation loss: 2.3518772028453427

Epoch: 5| Step: 10
Training loss: 0.23595657776759874
Validation loss: 2.331079023241316

Epoch: 605| Step: 0
Training loss: 0.18128616860037652
Validation loss: 2.339818723118368

Epoch: 5| Step: 1
Training loss: 0.1561754048622664
Validation loss: 2.345114423321297

Epoch: 5| Step: 2
Training loss: 0.15726994573434724
Validation loss: 2.3340120148898214

Epoch: 5| Step: 3
Training loss: 0.234011097370796
Validation loss: 2.326537148037879

Epoch: 5| Step: 4
Training loss: 0.19164886474001935
Validation loss: 2.356072459100081

Epoch: 5| Step: 5
Training loss: 0.23832887423757748
Validation loss: 2.340738534404766

Epoch: 5| Step: 6
Training loss: 0.2253436318898318
Validation loss: 2.338960655862887

Epoch: 5| Step: 7
Training loss: 0.269760034736889
Validation loss: 2.339663802385446

Epoch: 5| Step: 8
Training loss: 0.1645886182439512
Validation loss: 2.327905052505832

Epoch: 5| Step: 9
Training loss: 0.21324343712938965
Validation loss: 2.3382420487119826

Epoch: 5| Step: 10
Training loss: 0.10451059535803484
Validation loss: 2.328782797960111

Epoch: 606| Step: 0
Training loss: 0.2471395177001805
Validation loss: 2.3079228221371486

Epoch: 5| Step: 1
Training loss: 0.2009251201547641
Validation loss: 2.312327475238568

Epoch: 5| Step: 2
Training loss: 0.2674856513399765
Validation loss: 2.3151490421352925

Epoch: 5| Step: 3
Training loss: 0.1391253645387451
Validation loss: 2.3026650753109204

Epoch: 5| Step: 4
Training loss: 0.25580144910804564
Validation loss: 2.307050221539159

Epoch: 5| Step: 5
Training loss: 0.17602478217708914
Validation loss: 2.324783318119552

Epoch: 5| Step: 6
Training loss: 0.15744480836857896
Validation loss: 2.3218228103314305

Epoch: 5| Step: 7
Training loss: 0.21681439268804134
Validation loss: 2.3325133010700787

Epoch: 5| Step: 8
Training loss: 0.17185370356661947
Validation loss: 2.323533096165785

Epoch: 5| Step: 9
Training loss: 0.2175851016064686
Validation loss: 2.3182954539316514

Epoch: 5| Step: 10
Training loss: 0.10309981558798977
Validation loss: 2.2951981567440405

Epoch: 607| Step: 0
Training loss: 0.11638051971145781
Validation loss: 2.295568072459723

Epoch: 5| Step: 1
Training loss: 0.13114855967478653
Validation loss: 2.297308922611518

Epoch: 5| Step: 2
Training loss: 0.2775700680019448
Validation loss: 2.304720525155609

Epoch: 5| Step: 3
Training loss: 0.2233031729419369
Validation loss: 2.2940434597215167

Epoch: 5| Step: 4
Training loss: 0.18377833522579695
Validation loss: 2.2814585160163494

Epoch: 5| Step: 5
Training loss: 0.14458558633470736
Validation loss: 2.3000681991417395

Epoch: 5| Step: 6
Training loss: 0.3392904754534062
Validation loss: 2.2852955344773482

Epoch: 5| Step: 7
Training loss: 0.1613329944383724
Validation loss: 2.307300849180913

Epoch: 5| Step: 8
Training loss: 0.15347084625077068
Validation loss: 2.3021530696128694

Epoch: 5| Step: 9
Training loss: 0.16857115708179468
Validation loss: 2.320888694821181

Epoch: 5| Step: 10
Training loss: 0.2927974327184283
Validation loss: 2.3524085229710354

Epoch: 608| Step: 0
Training loss: 0.3211390716236019
Validation loss: 2.308939161401035

Epoch: 5| Step: 1
Training loss: 0.11131034257314518
Validation loss: 2.340729026717672

Epoch: 5| Step: 2
Training loss: 0.13435313773292348
Validation loss: 2.299781955996545

Epoch: 5| Step: 3
Training loss: 0.23628925760506742
Validation loss: 2.295450248207326

Epoch: 5| Step: 4
Training loss: 0.19386882330108077
Validation loss: 2.3083381228828372

Epoch: 5| Step: 5
Training loss: 0.20235879982024224
Validation loss: 2.3099808589478057

Epoch: 5| Step: 6
Training loss: 0.1656122468140963
Validation loss: 2.3302640017060234

Epoch: 5| Step: 7
Training loss: 0.12803335575795707
Validation loss: 2.306565670900951

Epoch: 5| Step: 8
Training loss: 0.12562310364463825
Validation loss: 2.313422918248578

Epoch: 5| Step: 9
Training loss: 0.31007892211596316
Validation loss: 2.3238091016547218

Epoch: 5| Step: 10
Training loss: 0.12717649176710466
Validation loss: 2.305205498672088

Epoch: 609| Step: 0
Training loss: 0.14407569384201793
Validation loss: 2.2940982063984388

Epoch: 5| Step: 1
Training loss: 0.22153191535614095
Validation loss: 2.329824163012907

Epoch: 5| Step: 2
Training loss: 0.15741204640491183
Validation loss: 2.3164199745413403

Epoch: 5| Step: 3
Training loss: 0.2379243554316499
Validation loss: 2.3173725596087458

Epoch: 5| Step: 4
Training loss: 0.2317239396021524
Validation loss: 2.330752506346626

Epoch: 5| Step: 5
Training loss: 0.17852425335288716
Validation loss: 2.290034801775589

Epoch: 5| Step: 6
Training loss: 0.24809541002153765
Validation loss: 2.3123425471950316

Epoch: 5| Step: 7
Training loss: 0.24284961392248455
Validation loss: 2.34880128002608

Epoch: 5| Step: 8
Training loss: 0.12616149871487042
Validation loss: 2.322081726796962

Epoch: 5| Step: 9
Training loss: 0.17636629866907294
Validation loss: 2.2816844554016438

Epoch: 5| Step: 10
Training loss: 0.13891484908701907
Validation loss: 2.3335931339599063

Epoch: 610| Step: 0
Training loss: 0.2594259378673051
Validation loss: 2.3066720851234335

Epoch: 5| Step: 1
Training loss: 0.19078098075279087
Validation loss: 2.287626123876666

Epoch: 5| Step: 2
Training loss: 0.14522177468686503
Validation loss: 2.2655981348670515

Epoch: 5| Step: 3
Training loss: 0.18052226507547664
Validation loss: 2.2652930922170693

Epoch: 5| Step: 4
Training loss: 0.159365399389382
Validation loss: 2.2781101374583947

Epoch: 5| Step: 5
Training loss: 0.2554401574189104
Validation loss: 2.2723351529912765

Epoch: 5| Step: 6
Training loss: 0.16265805586069848
Validation loss: 2.2874745681400652

Epoch: 5| Step: 7
Training loss: 0.18673702812911475
Validation loss: 2.274396032292209

Epoch: 5| Step: 8
Training loss: 0.15127091576451795
Validation loss: 2.2812448113259265

Epoch: 5| Step: 9
Training loss: 0.31418987177508884
Validation loss: 2.291747852091832

Epoch: 5| Step: 10
Training loss: 0.12632598765445952
Validation loss: 2.3061033465779364

Epoch: 611| Step: 0
Training loss: 0.19248938150349026
Validation loss: 2.2959337770588872

Epoch: 5| Step: 1
Training loss: 0.12147350906645332
Validation loss: 2.3165835239555204

Epoch: 5| Step: 2
Training loss: 0.18949198570075582
Validation loss: 2.3511527418567963

Epoch: 5| Step: 3
Training loss: 0.17643992676114953
Validation loss: 2.3092414548810654

Epoch: 5| Step: 4
Training loss: 0.16763903171259664
Validation loss: 2.310572282181644

Epoch: 5| Step: 5
Training loss: 0.25141361047983807
Validation loss: 2.318378577681674

Epoch: 5| Step: 6
Training loss: 0.10964416269300699
Validation loss: 2.309584052133397

Epoch: 5| Step: 7
Training loss: 0.25230074713914236
Validation loss: 2.3120601871042643

Epoch: 5| Step: 8
Training loss: 0.179765404523294
Validation loss: 2.2636903564244553

Epoch: 5| Step: 9
Training loss: 0.25923742644370895
Validation loss: 2.300511712412824

Epoch: 5| Step: 10
Training loss: 0.20088421522959332
Validation loss: 2.2971647882132915

Epoch: 612| Step: 0
Training loss: 0.16936295765651568
Validation loss: 2.293436723414791

Epoch: 5| Step: 1
Training loss: 0.23197734219387905
Validation loss: 2.2923888415660554

Epoch: 5| Step: 2
Training loss: 0.22203128508662162
Validation loss: 2.3140985794269766

Epoch: 5| Step: 3
Training loss: 0.27409939355577856
Validation loss: 2.3109351497723254

Epoch: 5| Step: 4
Training loss: 0.21407183779933944
Validation loss: 2.3267768215210785

Epoch: 5| Step: 5
Training loss: 0.20316778245955391
Validation loss: 2.303027940359789

Epoch: 5| Step: 6
Training loss: 0.11054908325631715
Validation loss: 2.328037128991163

Epoch: 5| Step: 7
Training loss: 0.13750716131158108
Validation loss: 2.3188285580602552

Epoch: 5| Step: 8
Training loss: 0.20156378671693773
Validation loss: 2.342650351201708

Epoch: 5| Step: 9
Training loss: 0.08850674314456472
Validation loss: 2.338309290845084

Epoch: 5| Step: 10
Training loss: 0.1989808251281817
Validation loss: 2.307495440038841

Epoch: 613| Step: 0
Training loss: 0.1600041830551686
Validation loss: 2.319891798574721

Epoch: 5| Step: 1
Training loss: 0.2419376468850165
Validation loss: 2.310612081655543

Epoch: 5| Step: 2
Training loss: 0.2067633190679381
Validation loss: 2.3518505046123326

Epoch: 5| Step: 3
Training loss: 0.11857262040557866
Validation loss: 2.2820713319462325

Epoch: 5| Step: 4
Training loss: 0.15544007913959876
Validation loss: 2.3213836726431185

Epoch: 5| Step: 5
Training loss: 0.3040404785783545
Validation loss: 2.3311164743598916

Epoch: 5| Step: 6
Training loss: 0.125398165633544
Validation loss: 2.3041660231250933

Epoch: 5| Step: 7
Training loss: 0.1480377171786602
Validation loss: 2.312452997042031

Epoch: 5| Step: 8
Training loss: 0.17916468565607135
Validation loss: 2.337356609881598

Epoch: 5| Step: 9
Training loss: 0.18325267723503538
Validation loss: 2.315992151389366

Epoch: 5| Step: 10
Training loss: 0.18017891361646146
Validation loss: 2.3083320467814907

Epoch: 614| Step: 0
Training loss: 0.1247937243904389
Validation loss: 2.2934614907337543

Epoch: 5| Step: 1
Training loss: 0.2731646948018414
Validation loss: 2.345803119693112

Epoch: 5| Step: 2
Training loss: 0.10705010063652402
Validation loss: 2.323471217981733

Epoch: 5| Step: 3
Training loss: 0.252855341526682
Validation loss: 2.3232365752172637

Epoch: 5| Step: 4
Training loss: 0.12453180412901502
Validation loss: 2.3310159211335733

Epoch: 5| Step: 5
Training loss: 0.18105355625560476
Validation loss: 2.349352512928601

Epoch: 5| Step: 6
Training loss: 0.17735346124754395
Validation loss: 2.3321002453863287

Epoch: 5| Step: 7
Training loss: 0.14320374104210706
Validation loss: 2.296977063416356

Epoch: 5| Step: 8
Training loss: 0.1524126740576727
Validation loss: 2.3097147421749575

Epoch: 5| Step: 9
Training loss: 0.25483004436674117
Validation loss: 2.320853557407605

Epoch: 5| Step: 10
Training loss: 0.11182174919723029
Validation loss: 2.330803896229072

Epoch: 615| Step: 0
Training loss: 0.11002505789172126
Validation loss: 2.3098093757875473

Epoch: 5| Step: 1
Training loss: 0.17154821845405108
Validation loss: 2.2999237098721266

Epoch: 5| Step: 2
Training loss: 0.1216396593534524
Validation loss: 2.273614017653607

Epoch: 5| Step: 3
Training loss: 0.21612501427146816
Validation loss: 2.284433235308365

Epoch: 5| Step: 4
Training loss: 0.22906074550576042
Validation loss: 2.2511428382589243

Epoch: 5| Step: 5
Training loss: 0.1989156343084772
Validation loss: 2.301484912502174

Epoch: 5| Step: 6
Training loss: 0.16052482806298873
Validation loss: 2.299132144294758

Epoch: 5| Step: 7
Training loss: 0.2764029058552786
Validation loss: 2.293405172836605

Epoch: 5| Step: 8
Training loss: 0.09402277621744705
Validation loss: 2.2912735069467263

Epoch: 5| Step: 9
Training loss: 0.08175555517230783
Validation loss: 2.30349487125506

Epoch: 5| Step: 10
Training loss: 0.21234255420553025
Validation loss: 2.304404126838208

Epoch: 616| Step: 0
Training loss: 0.29008059734068625
Validation loss: 2.270609218499812

Epoch: 5| Step: 1
Training loss: 0.18591191372216934
Validation loss: 2.2853532570014616

Epoch: 5| Step: 2
Training loss: 0.12016104075997076
Validation loss: 2.3088989733432927

Epoch: 5| Step: 3
Training loss: 0.18801398163531166
Validation loss: 2.2821137909433373

Epoch: 5| Step: 4
Training loss: 0.09155421446557509
Validation loss: 2.2745629606723967

Epoch: 5| Step: 5
Training loss: 0.15898869763995535
Validation loss: 2.2934187175613743

Epoch: 5| Step: 6
Training loss: 0.10551367791773224
Validation loss: 2.302219998374219

Epoch: 5| Step: 7
Training loss: 0.22740740917120583
Validation loss: 2.2638525162715073

Epoch: 5| Step: 8
Training loss: 0.22339702653114135
Validation loss: 2.2928369422054606

Epoch: 5| Step: 9
Training loss: 0.10678177773588331
Validation loss: 2.2935955215880193

Epoch: 5| Step: 10
Training loss: 0.18040477601358912
Validation loss: 2.312694177786867

Epoch: 617| Step: 0
Training loss: 0.1930874347570836
Validation loss: 2.322515223335431

Epoch: 5| Step: 1
Training loss: 0.10771700026012623
Validation loss: 2.319560397294254

Epoch: 5| Step: 2
Training loss: 0.23841899267542255
Validation loss: 2.3246569457469857

Epoch: 5| Step: 3
Training loss: 0.14849707386757574
Validation loss: 2.3448736755365918

Epoch: 5| Step: 4
Training loss: 0.22265894369537148
Validation loss: 2.388137045004443

Epoch: 5| Step: 5
Training loss: 0.09546369653178936
Validation loss: 2.335927066250829

Epoch: 5| Step: 6
Training loss: 0.09613487596401463
Validation loss: 2.2982507798393215

Epoch: 5| Step: 7
Training loss: 0.2548585346688211
Validation loss: 2.3260932839449024

Epoch: 5| Step: 8
Training loss: 0.238753429408184
Validation loss: 2.3140209842173967

Epoch: 5| Step: 9
Training loss: 0.17973886667877145
Validation loss: 2.2921884392086898

Epoch: 5| Step: 10
Training loss: 0.2399089749395031
Validation loss: 2.2968453533800486

Epoch: 618| Step: 0
Training loss: 0.21348986152344784
Validation loss: 2.3098521395585974

Epoch: 5| Step: 1
Training loss: 0.13690373304204564
Validation loss: 2.3343800020686643

Epoch: 5| Step: 2
Training loss: 0.2376767448250903
Validation loss: 2.3026617976464943

Epoch: 5| Step: 3
Training loss: 0.1696359981005313
Validation loss: 2.2840235637932462

Epoch: 5| Step: 4
Training loss: 0.15210343627034156
Validation loss: 2.299679869357189

Epoch: 5| Step: 5
Training loss: 0.10895060046668631
Validation loss: 2.298976681959348

Epoch: 5| Step: 6
Training loss: 0.12428649278746921
Validation loss: 2.3081663832843686

Epoch: 5| Step: 7
Training loss: 0.11666128906844467
Validation loss: 2.320103944452012

Epoch: 5| Step: 8
Training loss: 0.253428640857519
Validation loss: 2.3097754350184765

Epoch: 5| Step: 9
Training loss: 0.22439626452168124
Validation loss: 2.2813301999453013

Epoch: 5| Step: 10
Training loss: 0.1821692373502135
Validation loss: 2.2910114231607333

Epoch: 619| Step: 0
Training loss: 0.07333451491703544
Validation loss: 2.2876923032257723

Epoch: 5| Step: 1
Training loss: 0.1423315895363293
Validation loss: 2.3192017737175727

Epoch: 5| Step: 2
Training loss: 0.10984272234667947
Validation loss: 2.3385781073981544

Epoch: 5| Step: 3
Training loss: 0.11957796140879157
Validation loss: 2.3295053498839797

Epoch: 5| Step: 4
Training loss: 0.1555073673363614
Validation loss: 2.3026801587418313

Epoch: 5| Step: 5
Training loss: 0.15840718566217837
Validation loss: 2.3293965488634756

Epoch: 5| Step: 6
Training loss: 0.26972570177475413
Validation loss: 2.3563088683526154

Epoch: 5| Step: 7
Training loss: 0.2597491897317036
Validation loss: 2.299861429444285

Epoch: 5| Step: 8
Training loss: 0.2409471776332315
Validation loss: 2.3008567468551018

Epoch: 5| Step: 9
Training loss: 0.2062356253874421
Validation loss: 2.309981305091518

Epoch: 5| Step: 10
Training loss: 0.22612064947621432
Validation loss: 2.3108536797407275

Epoch: 620| Step: 0
Training loss: 0.21590911108626037
Validation loss: 2.2836189101613567

Epoch: 5| Step: 1
Training loss: 0.12481358530745562
Validation loss: 2.3041479297727565

Epoch: 5| Step: 2
Training loss: 0.20614876791465345
Validation loss: 2.3020146280382736

Epoch: 5| Step: 3
Training loss: 0.11857319770615919
Validation loss: 2.258740568441352

Epoch: 5| Step: 4
Training loss: 0.09270704302889973
Validation loss: 2.2775874925865742

Epoch: 5| Step: 5
Training loss: 0.19293294952903517
Validation loss: 2.2794451319967552

Epoch: 5| Step: 6
Training loss: 0.17640835903518692
Validation loss: 2.2890579143510297

Epoch: 5| Step: 7
Training loss: 0.23063377355929224
Validation loss: 2.2730666726686386

Epoch: 5| Step: 8
Training loss: 0.1918299908610566
Validation loss: 2.304574818582669

Epoch: 5| Step: 9
Training loss: 0.19317691555788996
Validation loss: 2.3106736163219623

Epoch: 5| Step: 10
Training loss: 0.24533168177112474
Validation loss: 2.300474630893041

Epoch: 621| Step: 0
Training loss: 0.18563494349026702
Validation loss: 2.3166075380749667

Epoch: 5| Step: 1
Training loss: 0.1695010026414018
Validation loss: 2.3045254691570665

Epoch: 5| Step: 2
Training loss: 0.13135718555697184
Validation loss: 2.291611409196992

Epoch: 5| Step: 3
Training loss: 0.22965677730589568
Validation loss: 2.3268565904094203

Epoch: 5| Step: 4
Training loss: 0.13241334144980693
Validation loss: 2.314583980941634

Epoch: 5| Step: 5
Training loss: 0.23658056411911807
Validation loss: 2.348648376802135

Epoch: 5| Step: 6
Training loss: 0.06801144407261897
Validation loss: 2.324406966925399

Epoch: 5| Step: 7
Training loss: 0.22268174677977584
Validation loss: 2.3262476333378928

Epoch: 5| Step: 8
Training loss: 0.2112152602055173
Validation loss: 2.2867463175060876

Epoch: 5| Step: 9
Training loss: 0.18475282314218644
Validation loss: 2.3443027722273224

Epoch: 5| Step: 10
Training loss: 0.10666609100221228
Validation loss: 2.345634937401016

Epoch: 622| Step: 0
Training loss: 0.09695582978550918
Validation loss: 2.310410953649556

Epoch: 5| Step: 1
Training loss: 0.19499947258987996
Validation loss: 2.3572439179962803

Epoch: 5| Step: 2
Training loss: 0.14435128658173543
Validation loss: 2.3248075921430424

Epoch: 5| Step: 3
Training loss: 0.18544092667026488
Validation loss: 2.350658002546797

Epoch: 5| Step: 4
Training loss: 0.25152206510574343
Validation loss: 2.353419752674027

Epoch: 5| Step: 5
Training loss: 0.14482266456762968
Validation loss: 2.3367905973565906

Epoch: 5| Step: 6
Training loss: 0.18251621290265224
Validation loss: 2.3487278875025535

Epoch: 5| Step: 7
Training loss: 0.12064325844857697
Validation loss: 2.3310366708814216

Epoch: 5| Step: 8
Training loss: 0.22842440455431012
Validation loss: 2.3178728318793373

Epoch: 5| Step: 9
Training loss: 0.20513555540023554
Validation loss: 2.312872586420861

Epoch: 5| Step: 10
Training loss: 0.218304265118967
Validation loss: 2.2980486112336145

Epoch: 623| Step: 0
Training loss: 0.16590403003755821
Validation loss: 2.311413983591296

Epoch: 5| Step: 1
Training loss: 0.1991335649312637
Validation loss: 2.304515053380875

Epoch: 5| Step: 2
Training loss: 0.09833909198280442
Validation loss: 2.3305482357045015

Epoch: 5| Step: 3
Training loss: 0.15568596842520505
Validation loss: 2.3315912026208023

Epoch: 5| Step: 4
Training loss: 0.17269759675598825
Validation loss: 2.334914284306936

Epoch: 5| Step: 5
Training loss: 0.19198127901864592
Validation loss: 2.354435934627704

Epoch: 5| Step: 6
Training loss: 0.10734824778505343
Validation loss: 2.3437309980818535

Epoch: 5| Step: 7
Training loss: 0.22763328075062925
Validation loss: 2.342517509581058

Epoch: 5| Step: 8
Training loss: 0.24425617535309527
Validation loss: 2.3296388916724924

Epoch: 5| Step: 9
Training loss: 0.16337511271412294
Validation loss: 2.345193511635015

Epoch: 5| Step: 10
Training loss: 0.25088080572149446
Validation loss: 2.3202827003951674

Epoch: 624| Step: 0
Training loss: 0.12248426440317052
Validation loss: 2.322045221861352

Epoch: 5| Step: 1
Training loss: 0.19073254881408258
Validation loss: 2.3164515990014602

Epoch: 5| Step: 2
Training loss: 0.1419805060176783
Validation loss: 2.346176679038555

Epoch: 5| Step: 3
Training loss: 0.18405208799449363
Validation loss: 2.3284745472540624

Epoch: 5| Step: 4
Training loss: 0.0826922589649631
Validation loss: 2.3342281239502296

Epoch: 5| Step: 5
Training loss: 0.17309138261705376
Validation loss: 2.3215722519291915

Epoch: 5| Step: 6
Training loss: 0.0922196423132891
Validation loss: 2.3216375102824878

Epoch: 5| Step: 7
Training loss: 0.2117356459009633
Validation loss: 2.3132961435914186

Epoch: 5| Step: 8
Training loss: 0.25613856916661965
Validation loss: 2.338952163576514

Epoch: 5| Step: 9
Training loss: 0.28267217389869503
Validation loss: 2.3352220980166023

Epoch: 5| Step: 10
Training loss: 0.17875691640584349
Validation loss: 2.332412898191915

Epoch: 625| Step: 0
Training loss: 0.11609421806959876
Validation loss: 2.348495557501577

Epoch: 5| Step: 1
Training loss: 0.2595151970461497
Validation loss: 2.3409983495085047

Epoch: 5| Step: 2
Training loss: 0.21443199234251656
Validation loss: 2.3039421187381732

Epoch: 5| Step: 3
Training loss: 0.14650185798583243
Validation loss: 2.3104928243109586

Epoch: 5| Step: 4
Training loss: 0.14777430653852247
Validation loss: 2.2966806099140666

Epoch: 5| Step: 5
Training loss: 0.14566136265342347
Validation loss: 2.3117657454415053

Epoch: 5| Step: 6
Training loss: 0.21205020521833567
Validation loss: 2.3023850608837515

Epoch: 5| Step: 7
Training loss: 0.22696982140112906
Validation loss: 2.3206944503964646

Epoch: 5| Step: 8
Training loss: 0.16701431573966138
Validation loss: 2.2881401735229727

Epoch: 5| Step: 9
Training loss: 0.13197681529407546
Validation loss: 2.286820524947348

Epoch: 5| Step: 10
Training loss: 0.1546758331850565
Validation loss: 2.3070617570864362

Epoch: 626| Step: 0
Training loss: 0.19702780901318992
Validation loss: 2.2938234624649447

Epoch: 5| Step: 1
Training loss: 0.27698044420234375
Validation loss: 2.3033284280012802

Epoch: 5| Step: 2
Training loss: 0.17509617823473217
Validation loss: 2.3158359206952124

Epoch: 5| Step: 3
Training loss: 0.20399767225646132
Validation loss: 2.3295282876714793

Epoch: 5| Step: 4
Training loss: 0.13939356052722923
Validation loss: 2.321559932669781

Epoch: 5| Step: 5
Training loss: 0.14685196848128937
Validation loss: 2.308381194886103

Epoch: 5| Step: 6
Training loss: 0.14833103301933684
Validation loss: 2.316815674729593

Epoch: 5| Step: 7
Training loss: 0.1914026590905737
Validation loss: 2.3323344130147494

Epoch: 5| Step: 8
Training loss: 0.11494013024774871
Validation loss: 2.3191342075010684

Epoch: 5| Step: 9
Training loss: 0.1435337894824664
Validation loss: 2.3566951025461442

Epoch: 5| Step: 10
Training loss: 0.23157626282311497
Validation loss: 2.3682378177471324

Epoch: 627| Step: 0
Training loss: 0.13588461504907273
Validation loss: 2.3524876335997424

Epoch: 5| Step: 1
Training loss: 0.22515930357694972
Validation loss: 2.3328829504980177

Epoch: 5| Step: 2
Training loss: 0.16504798955305391
Validation loss: 2.3177786159793414

Epoch: 5| Step: 3
Training loss: 0.14650444529049877
Validation loss: 2.3373150589855887

Epoch: 5| Step: 4
Training loss: 0.21692979878851273
Validation loss: 2.3384665744741153

Epoch: 5| Step: 5
Training loss: 0.11733905608240676
Validation loss: 2.2824627322765823

Epoch: 5| Step: 6
Training loss: 0.16720775722171838
Validation loss: 2.3113944080555773

Epoch: 5| Step: 7
Training loss: 0.10049839284012717
Validation loss: 2.301717001189428

Epoch: 5| Step: 8
Training loss: 0.2292864587552726
Validation loss: 2.3518925208575143

Epoch: 5| Step: 9
Training loss: 0.24649767801988248
Validation loss: 2.2808901696449007

Epoch: 5| Step: 10
Training loss: 0.21982911154048226
Validation loss: 2.2910680964274066

Epoch: 628| Step: 0
Training loss: 0.13597781498832695
Validation loss: 2.2751843472984605

Epoch: 5| Step: 1
Training loss: 0.12767137408692233
Validation loss: 2.290113633968949

Epoch: 5| Step: 2
Training loss: 0.21978037704984343
Validation loss: 2.299309967917487

Epoch: 5| Step: 3
Training loss: 0.2157456109063514
Validation loss: 2.3185007195122576

Epoch: 5| Step: 4
Training loss: 0.12855220349490157
Validation loss: 2.306409121799699

Epoch: 5| Step: 5
Training loss: 0.10914230713336473
Validation loss: 2.3186907373131254

Epoch: 5| Step: 6
Training loss: 0.2503343373082529
Validation loss: 2.3250829027567668

Epoch: 5| Step: 7
Training loss: 0.1516794552286724
Validation loss: 2.3326473558992284

Epoch: 5| Step: 8
Training loss: 0.10343941096128176
Validation loss: 2.344005021197938

Epoch: 5| Step: 9
Training loss: 0.280001771167705
Validation loss: 2.3474797324832046

Epoch: 5| Step: 10
Training loss: 0.14590141007383892
Validation loss: 2.3507383820724956

Epoch: 629| Step: 0
Training loss: 0.12920805251412792
Validation loss: 2.367894507898247

Epoch: 5| Step: 1
Training loss: 0.32147313558368773
Validation loss: 2.3892532741289245

Epoch: 5| Step: 2
Training loss: 0.16500428075908877
Validation loss: 2.352592781389485

Epoch: 5| Step: 3
Training loss: 0.12467378652660772
Validation loss: 2.3741524397833165

Epoch: 5| Step: 4
Training loss: 0.17191947014920936
Validation loss: 2.38653957126099

Epoch: 5| Step: 5
Training loss: 0.16876099294601718
Validation loss: 2.372044568637776

Epoch: 5| Step: 6
Training loss: 0.1361388031395327
Validation loss: 2.352371647868177

Epoch: 5| Step: 7
Training loss: 0.13686815000838298
Validation loss: 2.3620879161618786

Epoch: 5| Step: 8
Training loss: 0.1802229987408134
Validation loss: 2.343625821888168

Epoch: 5| Step: 9
Training loss: 0.23780664486889258
Validation loss: 2.3270130539891727

Epoch: 5| Step: 10
Training loss: 0.1428756092580853
Validation loss: 2.356087415248592

Epoch: 630| Step: 0
Training loss: 0.15461677875689325
Validation loss: 2.3387020306502873

Epoch: 5| Step: 1
Training loss: 0.1311056538270739
Validation loss: 2.373281276882522

Epoch: 5| Step: 2
Training loss: 0.25539103442906386
Validation loss: 2.32096752507036

Epoch: 5| Step: 3
Training loss: 0.24982632624578469
Validation loss: 2.343893155884037

Epoch: 5| Step: 4
Training loss: 0.10151952512892916
Validation loss: 2.3208605054011175

Epoch: 5| Step: 5
Training loss: 0.2493092411504379
Validation loss: 2.2740428059400193

Epoch: 5| Step: 6
Training loss: 0.13356647631331794
Validation loss: 2.3206982444403392

Epoch: 5| Step: 7
Training loss: 0.2591473240830306
Validation loss: 2.29969942532897

Epoch: 5| Step: 8
Training loss: 0.16480819648683404
Validation loss: 2.3155421495793878

Epoch: 5| Step: 9
Training loss: 0.1479254977406297
Validation loss: 2.3056387691287745

Epoch: 5| Step: 10
Training loss: 0.11900086100200712
Validation loss: 2.3423209249171353

Epoch: 631| Step: 0
Training loss: 0.13387487263099104
Validation loss: 2.306210427987288

Epoch: 5| Step: 1
Training loss: 0.21734537725984399
Validation loss: 2.325881420929671

Epoch: 5| Step: 2
Training loss: 0.18757182970648464
Validation loss: 2.3440125185063025

Epoch: 5| Step: 3
Training loss: 0.19777626570522142
Validation loss: 2.315292925604792

Epoch: 5| Step: 4
Training loss: 0.1954354947965964
Validation loss: 2.2963496205785208

Epoch: 5| Step: 5
Training loss: 0.3351462493862759
Validation loss: 2.2787208736503795

Epoch: 5| Step: 6
Training loss: 0.1048862344833571
Validation loss: 2.287201722555806

Epoch: 5| Step: 7
Training loss: 0.21252005812000574
Validation loss: 2.273624436302073

Epoch: 5| Step: 8
Training loss: 0.12225719261341367
Validation loss: 2.2809823924776085

Epoch: 5| Step: 9
Training loss: 0.20437072272593232
Validation loss: 2.2984264291615597

Epoch: 5| Step: 10
Training loss: 0.19226335796211644
Validation loss: 2.299190693000046

Epoch: 632| Step: 0
Training loss: 0.2196441665443131
Validation loss: 2.3277684013164865

Epoch: 5| Step: 1
Training loss: 0.16008485388960347
Validation loss: 2.342337472413017

Epoch: 5| Step: 2
Training loss: 0.2566206287043322
Validation loss: 2.3485884205439853

Epoch: 5| Step: 3
Training loss: 0.19373419104960493
Validation loss: 2.3628178732659637

Epoch: 5| Step: 4
Training loss: 0.22851166354927174
Validation loss: 2.402732978594585

Epoch: 5| Step: 5
Training loss: 0.17659303983371058
Validation loss: 2.368339671609774

Epoch: 5| Step: 6
Training loss: 0.10300033902429599
Validation loss: 2.3767065265315273

Epoch: 5| Step: 7
Training loss: 0.23177133606559722
Validation loss: 2.33472439469675

Epoch: 5| Step: 8
Training loss: 0.19951810971264192
Validation loss: 2.3043804038489695

Epoch: 5| Step: 9
Training loss: 0.1777946349054073
Validation loss: 2.2982242414271354

Epoch: 5| Step: 10
Training loss: 0.2712464147322017
Validation loss: 2.28156208146167

Epoch: 633| Step: 0
Training loss: 0.25605287587611025
Validation loss: 2.2597755708933893

Epoch: 5| Step: 1
Training loss: 0.339884547273106
Validation loss: 2.2631753704741437

Epoch: 5| Step: 2
Training loss: 0.15704049775900672
Validation loss: 2.2639402072130568

Epoch: 5| Step: 3
Training loss: 0.14036497606730913
Validation loss: 2.231445870850763

Epoch: 5| Step: 4
Training loss: 0.23826413796687734
Validation loss: 2.2713768624580615

Epoch: 5| Step: 5
Training loss: 0.24784482401171543
Validation loss: 2.2469014639862444

Epoch: 5| Step: 6
Training loss: 0.1319306633748792
Validation loss: 2.2542761624611596

Epoch: 5| Step: 7
Training loss: 0.20789432563914206
Validation loss: 2.2848688332430243

Epoch: 5| Step: 8
Training loss: 0.17233577649303414
Validation loss: 2.262556268362504

Epoch: 5| Step: 9
Training loss: 0.2280500429279067
Validation loss: 2.262798645681448

Epoch: 5| Step: 10
Training loss: 0.21066214108063896
Validation loss: 2.316099762386704

Epoch: 634| Step: 0
Training loss: 0.22174809782498256
Validation loss: 2.324677107670986

Epoch: 5| Step: 1
Training loss: 0.22376079312191294
Validation loss: 2.329264758579684

Epoch: 5| Step: 2
Training loss: 0.17554013351785333
Validation loss: 2.2984492437822324

Epoch: 5| Step: 3
Training loss: 0.14380184617299888
Validation loss: 2.302441617871245

Epoch: 5| Step: 4
Training loss: 0.16945484808594918
Validation loss: 2.313354766568864

Epoch: 5| Step: 5
Training loss: 0.19474104250653437
Validation loss: 2.3123521843484087

Epoch: 5| Step: 6
Training loss: 0.2506534708409032
Validation loss: 2.3154872101843926

Epoch: 5| Step: 7
Training loss: 0.2443289068904436
Validation loss: 2.334682146898203

Epoch: 5| Step: 8
Training loss: 0.1902383674656948
Validation loss: 2.3165163185104376

Epoch: 5| Step: 9
Training loss: 0.2041924561703852
Validation loss: 2.3509798302070704

Epoch: 5| Step: 10
Training loss: 0.20632195879133405
Validation loss: 2.337082339254915

Epoch: 635| Step: 0
Training loss: 0.21925380286514848
Validation loss: 2.3104108804157075

Epoch: 5| Step: 1
Training loss: 0.22476425635882763
Validation loss: 2.283890887293438

Epoch: 5| Step: 2
Training loss: 0.15875909388770165
Validation loss: 2.2691712611004

Epoch: 5| Step: 3
Training loss: 0.24242967372376828
Validation loss: 2.295929193409559

Epoch: 5| Step: 4
Training loss: 0.14651379607699497
Validation loss: 2.2664929157175133

Epoch: 5| Step: 5
Training loss: 0.1528886623090904
Validation loss: 2.2197285853683133

Epoch: 5| Step: 6
Training loss: 0.1315081017041804
Validation loss: 2.235190357150277

Epoch: 5| Step: 7
Training loss: 0.1465503925332871
Validation loss: 2.24386513223513

Epoch: 5| Step: 8
Training loss: 0.23866052616190053
Validation loss: 2.3049054398200557

Epoch: 5| Step: 9
Training loss: 0.16617657208675402
Validation loss: 2.2636333612605717

Epoch: 5| Step: 10
Training loss: 0.19393813090171072
Validation loss: 2.2980651986264364

Epoch: 636| Step: 0
Training loss: 0.1762567129784358
Validation loss: 2.2751357012725393

Epoch: 5| Step: 1
Training loss: 0.19290545193747952
Validation loss: 2.3522607379066836

Epoch: 5| Step: 2
Training loss: 0.1419208084842499
Validation loss: 2.33446326662945

Epoch: 5| Step: 3
Training loss: 0.2662937777083436
Validation loss: 2.3241044740683683

Epoch: 5| Step: 4
Training loss: 0.14129822567099415
Validation loss: 2.3362596364966173

Epoch: 5| Step: 5
Training loss: 0.2033188426819368
Validation loss: 2.3090117313003127

Epoch: 5| Step: 6
Training loss: 0.1433177341822938
Validation loss: 2.3392753781111457

Epoch: 5| Step: 7
Training loss: 0.19014268423948566
Validation loss: 2.3279594125199607

Epoch: 5| Step: 8
Training loss: 0.10883523810308914
Validation loss: 2.2939502845561184

Epoch: 5| Step: 9
Training loss: 0.0913832150476758
Validation loss: 2.307474751908566

Epoch: 5| Step: 10
Training loss: 0.28466467094801307
Validation loss: 2.272477850423232

Epoch: 637| Step: 0
Training loss: 0.25598006277661495
Validation loss: 2.29288329404583

Epoch: 5| Step: 1
Training loss: 0.14898969185698147
Validation loss: 2.3104737352857843

Epoch: 5| Step: 2
Training loss: 0.1712215312210394
Validation loss: 2.3100912813273036

Epoch: 5| Step: 3
Training loss: 0.24501888994214333
Validation loss: 2.3054820436665877

Epoch: 5| Step: 4
Training loss: 0.179889886325581
Validation loss: 2.32349168313608

Epoch: 5| Step: 5
Training loss: 0.1539313900935743
Validation loss: 2.3272551432310484

Epoch: 5| Step: 6
Training loss: 0.1828252861246577
Validation loss: 2.3207508671726784

Epoch: 5| Step: 7
Training loss: 0.22626036196105734
Validation loss: 2.320866597305183

Epoch: 5| Step: 8
Training loss: 0.2136617658131045
Validation loss: 2.333540969464266

Epoch: 5| Step: 9
Training loss: 0.12810264427257337
Validation loss: 2.3563421791089376

Epoch: 5| Step: 10
Training loss: 0.13215622319969686
Validation loss: 2.3230076540320006

Epoch: 638| Step: 0
Training loss: 0.22372441310671315
Validation loss: 2.321985283630414

Epoch: 5| Step: 1
Training loss: 0.19275146830713233
Validation loss: 2.3259793370776314

Epoch: 5| Step: 2
Training loss: 0.11071729397065336
Validation loss: 2.345818640477253

Epoch: 5| Step: 3
Training loss: 0.16153336071267088
Validation loss: 2.331641246921526

Epoch: 5| Step: 4
Training loss: 0.15082357064704355
Validation loss: 2.344710360286456

Epoch: 5| Step: 5
Training loss: 0.12542034789187315
Validation loss: 2.3118608007604404

Epoch: 5| Step: 6
Training loss: 0.1708940450921305
Validation loss: 2.3318017772592903

Epoch: 5| Step: 7
Training loss: 0.14850004033126668
Validation loss: 2.305434243771952

Epoch: 5| Step: 8
Training loss: 0.218234792324259
Validation loss: 2.2969094840909925

Epoch: 5| Step: 9
Training loss: 0.14814717988857062
Validation loss: 2.3367473463173085

Epoch: 5| Step: 10
Training loss: 0.21855109401881567
Validation loss: 2.3106742043450192

Epoch: 639| Step: 0
Training loss: 0.2477311204680261
Validation loss: 2.3021954488859735

Epoch: 5| Step: 1
Training loss: 0.17837159713528059
Validation loss: 2.3126192735611517

Epoch: 5| Step: 2
Training loss: 0.1423470047872793
Validation loss: 2.3262703420643134

Epoch: 5| Step: 3
Training loss: 0.18264319494761155
Validation loss: 2.333926188908589

Epoch: 5| Step: 4
Training loss: 0.18677882740325424
Validation loss: 2.3129699216265687

Epoch: 5| Step: 5
Training loss: 0.12746774832380353
Validation loss: 2.3212229535992805

Epoch: 5| Step: 6
Training loss: 0.17805217793607453
Validation loss: 2.3149098990360137

Epoch: 5| Step: 7
Training loss: 0.24099751347232526
Validation loss: 2.329331442676753

Epoch: 5| Step: 8
Training loss: 0.2513553418004094
Validation loss: 2.3146874055106075

Epoch: 5| Step: 9
Training loss: 0.15365370565925884
Validation loss: 2.3137211589352287

Epoch: 5| Step: 10
Training loss: 0.12411719630475414
Validation loss: 2.293198048302406

Epoch: 640| Step: 0
Training loss: 0.24503117454234769
Validation loss: 2.3111845319684745

Epoch: 5| Step: 1
Training loss: 0.08092642022482867
Validation loss: 2.3427071683053082

Epoch: 5| Step: 2
Training loss: 0.19538580472507355
Validation loss: 2.321241990120762

Epoch: 5| Step: 3
Training loss: 0.18072613861083084
Validation loss: 2.30137955897481

Epoch: 5| Step: 4
Training loss: 0.14574116678118196
Validation loss: 2.341318711711455

Epoch: 5| Step: 5
Training loss: 0.21588674877723624
Validation loss: 2.292985086805079

Epoch: 5| Step: 6
Training loss: 0.1905407019565796
Validation loss: 2.3132869508897476

Epoch: 5| Step: 7
Training loss: 0.17952350720939145
Validation loss: 2.3136505705754113

Epoch: 5| Step: 8
Training loss: 0.1861861109603335
Validation loss: 2.2992826434091582

Epoch: 5| Step: 9
Training loss: 0.24550358078980902
Validation loss: 2.3019544906616196

Epoch: 5| Step: 10
Training loss: 0.09403446868162119
Validation loss: 2.3311025856012684

Epoch: 641| Step: 0
Training loss: 0.12944076719678016
Validation loss: 2.334322860927752

Epoch: 5| Step: 1
Training loss: 0.23369754794347955
Validation loss: 2.3042725882184962

Epoch: 5| Step: 2
Training loss: 0.14334913056069684
Validation loss: 2.3431994873832718

Epoch: 5| Step: 3
Training loss: 0.12871237827820223
Validation loss: 2.3382750171253655

Epoch: 5| Step: 4
Training loss: 0.24878895509669316
Validation loss: 2.3285375519858005

Epoch: 5| Step: 5
Training loss: 0.16323901889717155
Validation loss: 2.3503430571025588

Epoch: 5| Step: 6
Training loss: 0.18845476014528792
Validation loss: 2.399035746713023

Epoch: 5| Step: 7
Training loss: 0.14444129309466816
Validation loss: 2.340960219260167

Epoch: 5| Step: 8
Training loss: 0.2510725498329463
Validation loss: 2.359972106702014

Epoch: 5| Step: 9
Training loss: 0.14272403436336778
Validation loss: 2.3365705933189225

Epoch: 5| Step: 10
Training loss: 0.11214438483244507
Validation loss: 2.3235910625755936

Epoch: 642| Step: 0
Training loss: 0.20869148979131788
Validation loss: 2.337395692254678

Epoch: 5| Step: 1
Training loss: 0.1364837738945339
Validation loss: 2.3144493079804116

Epoch: 5| Step: 2
Training loss: 0.13138647108648668
Validation loss: 2.3246257036553084

Epoch: 5| Step: 3
Training loss: 0.13206323174239146
Validation loss: 2.3215227028433185

Epoch: 5| Step: 4
Training loss: 0.22756415953184278
Validation loss: 2.316783542905809

Epoch: 5| Step: 5
Training loss: 0.14552013293852994
Validation loss: 2.3242482476565605

Epoch: 5| Step: 6
Training loss: 0.20983018574223625
Validation loss: 2.333030391692657

Epoch: 5| Step: 7
Training loss: 0.2201007115883787
Validation loss: 2.3302254845756947

Epoch: 5| Step: 8
Training loss: 0.1942468371839552
Validation loss: 2.3521399039337227

Epoch: 5| Step: 9
Training loss: 0.11536874856885304
Validation loss: 2.329114028162244

Epoch: 5| Step: 10
Training loss: 0.2374159940422423
Validation loss: 2.3311172862486966

Epoch: 643| Step: 0
Training loss: 0.23188364394545793
Validation loss: 2.26084726435334

Epoch: 5| Step: 1
Training loss: 0.16787312247319242
Validation loss: 2.276001281072113

Epoch: 5| Step: 2
Training loss: 0.25804172786761403
Validation loss: 2.2934998187979425

Epoch: 5| Step: 3
Training loss: 0.23110963324487963
Validation loss: 2.294180389894031

Epoch: 5| Step: 4
Training loss: 0.09836926990728898
Validation loss: 2.3060814319972014

Epoch: 5| Step: 5
Training loss: 0.10543378055962008
Validation loss: 2.311674750691928

Epoch: 5| Step: 6
Training loss: 0.1442834430880704
Validation loss: 2.3230012223190957

Epoch: 5| Step: 7
Training loss: 0.1149926316969118
Validation loss: 2.3076826202459015

Epoch: 5| Step: 8
Training loss: 0.1559584102199408
Validation loss: 2.311803176753752

Epoch: 5| Step: 9
Training loss: 0.19040940005490445
Validation loss: 2.3237241477075226

Epoch: 5| Step: 10
Training loss: 0.18394765831728843
Validation loss: 2.337842320970964

Epoch: 644| Step: 0
Training loss: 0.12747205899089636
Validation loss: 2.3324702622556637

Epoch: 5| Step: 1
Training loss: 0.2723169117023633
Validation loss: 2.3593875434018874

Epoch: 5| Step: 2
Training loss: 0.14191429200115804
Validation loss: 2.32824530314419

Epoch: 5| Step: 3
Training loss: 0.15122768988279986
Validation loss: 2.3245317283709577

Epoch: 5| Step: 4
Training loss: 0.18775992457360177
Validation loss: 2.2930517565783917

Epoch: 5| Step: 5
Training loss: 0.18169363335360342
Validation loss: 2.3121908292155218

Epoch: 5| Step: 6
Training loss: 0.08334063954908731
Validation loss: 2.297684807517699

Epoch: 5| Step: 7
Training loss: 0.22820532344867908
Validation loss: 2.316430288091629

Epoch: 5| Step: 8
Training loss: 0.10896494326439084
Validation loss: 2.3446197624163023

Epoch: 5| Step: 9
Training loss: 0.13143771037639518
Validation loss: 2.3459548472913885

Epoch: 5| Step: 10
Training loss: 0.20176262826702185
Validation loss: 2.3276996013304196

Epoch: 645| Step: 0
Training loss: 0.169128478541341
Validation loss: 2.341319009539429

Epoch: 5| Step: 1
Training loss: 0.17022072611726738
Validation loss: 2.3386667607619693

Epoch: 5| Step: 2
Training loss: 0.19048619532315766
Validation loss: 2.3576779155682783

Epoch: 5| Step: 3
Training loss: 0.11644943591510896
Validation loss: 2.332821285153043

Epoch: 5| Step: 4
Training loss: 0.21235362403991415
Validation loss: 2.3217421916284984

Epoch: 5| Step: 5
Training loss: 0.10357733902177674
Validation loss: 2.357581279512583

Epoch: 5| Step: 6
Training loss: 0.159687787613731
Validation loss: 2.3320782354169354

Epoch: 5| Step: 7
Training loss: 0.17309723652966175
Validation loss: 2.299945737743489

Epoch: 5| Step: 8
Training loss: 0.23088909867925733
Validation loss: 2.311017257005346

Epoch: 5| Step: 9
Training loss: 0.24928499585010866
Validation loss: 2.301492753838614

Epoch: 5| Step: 10
Training loss: 0.14998486512043754
Validation loss: 2.298880826818337

Epoch: 646| Step: 0
Training loss: 0.12958847482126407
Validation loss: 2.303291157256982

Epoch: 5| Step: 1
Training loss: 0.10215490222262377
Validation loss: 2.3040748367238213

Epoch: 5| Step: 2
Training loss: 0.1645248460564895
Validation loss: 2.3238939405249437

Epoch: 5| Step: 3
Training loss: 0.2019936618666287
Validation loss: 2.33401379207389

Epoch: 5| Step: 4
Training loss: 0.15806340888671994
Validation loss: 2.3285193590023385

Epoch: 5| Step: 5
Training loss: 0.12224738058036712
Validation loss: 2.3472355487873395

Epoch: 5| Step: 6
Training loss: 0.3014249601632882
Validation loss: 2.343148027454153

Epoch: 5| Step: 7
Training loss: 0.2080430909807175
Validation loss: 2.309439532140022

Epoch: 5| Step: 8
Training loss: 0.11639643538146192
Validation loss: 2.3002821883171105

Epoch: 5| Step: 9
Training loss: 0.164884088199961
Validation loss: 2.283194638662661

Epoch: 5| Step: 10
Training loss: 0.12382786642462752
Validation loss: 2.281833530783886

Epoch: 647| Step: 0
Training loss: 0.20878472105103396
Validation loss: 2.309014178347632

Epoch: 5| Step: 1
Training loss: 0.17154883735049284
Validation loss: 2.291256364932003

Epoch: 5| Step: 2
Training loss: 0.12008091526227067
Validation loss: 2.3134530056803744

Epoch: 5| Step: 3
Training loss: 0.08355426992425283
Validation loss: 2.279866162806422

Epoch: 5| Step: 4
Training loss: 0.13330914397783813
Validation loss: 2.324635631207811

Epoch: 5| Step: 5
Training loss: 0.1558726343332542
Validation loss: 2.351835113565017

Epoch: 5| Step: 6
Training loss: 0.16520499177846937
Validation loss: 2.3363613833727688

Epoch: 5| Step: 7
Training loss: 0.22992586593197337
Validation loss: 2.3666452020656497

Epoch: 5| Step: 8
Training loss: 0.2358110303633306
Validation loss: 2.349571584715194

Epoch: 5| Step: 9
Training loss: 0.20601141958967764
Validation loss: 2.3492684952285448

Epoch: 5| Step: 10
Training loss: 0.11521229289920813
Validation loss: 2.323067953233376

Epoch: 648| Step: 0
Training loss: 0.285115905415989
Validation loss: 2.3017168252098283

Epoch: 5| Step: 1
Training loss: 0.21845784432298682
Validation loss: 2.3065427348311687

Epoch: 5| Step: 2
Training loss: 0.12874417519818865
Validation loss: 2.311028920288926

Epoch: 5| Step: 3
Training loss: 0.2586905525858738
Validation loss: 2.3055347434974784

Epoch: 5| Step: 4
Training loss: 0.15873744003478907
Validation loss: 2.286939051635729

Epoch: 5| Step: 5
Training loss: 0.15221379312429767
Validation loss: 2.2889394979423687

Epoch: 5| Step: 6
Training loss: 0.20210585399048245
Validation loss: 2.311029234222795

Epoch: 5| Step: 7
Training loss: 0.14189388093845287
Validation loss: 2.2571538262520816

Epoch: 5| Step: 8
Training loss: 0.14428763865520652
Validation loss: 2.315310625706701

Epoch: 5| Step: 9
Training loss: 0.20346252202559256
Validation loss: 2.3288499268280103

Epoch: 5| Step: 10
Training loss: 0.11786185783856988
Validation loss: 2.2875219285652344

Epoch: 649| Step: 0
Training loss: 0.2060155153328492
Validation loss: 2.288807174731857

Epoch: 5| Step: 1
Training loss: 0.14758302043349952
Validation loss: 2.2957779948483195

Epoch: 5| Step: 2
Training loss: 0.24933189287211563
Validation loss: 2.3179614564984865

Epoch: 5| Step: 3
Training loss: 0.12366379384322472
Validation loss: 2.30943039901714

Epoch: 5| Step: 4
Training loss: 0.17911610767869104
Validation loss: 2.3191324902148547

Epoch: 5| Step: 5
Training loss: 0.10920106733078035
Validation loss: 2.3339540832204153

Epoch: 5| Step: 6
Training loss: 0.2845401771523368
Validation loss: 2.3308985513108036

Epoch: 5| Step: 7
Training loss: 0.18143904175203512
Validation loss: 2.3580618495498786

Epoch: 5| Step: 8
Training loss: 0.10392125297449704
Validation loss: 2.392228244883987

Epoch: 5| Step: 9
Training loss: 0.1857647068881111
Validation loss: 2.380097277016477

Epoch: 5| Step: 10
Training loss: 0.1833678438386917
Validation loss: 2.390045207770786

Epoch: 650| Step: 0
Training loss: 0.0913293835232629
Validation loss: 2.3458612494305844

Epoch: 5| Step: 1
Training loss: 0.14441717646458024
Validation loss: 2.2901860492798147

Epoch: 5| Step: 2
Training loss: 0.17869684549438858
Validation loss: 2.2931681322334723

Epoch: 5| Step: 3
Training loss: 0.2312326460203433
Validation loss: 2.272935272889873

Epoch: 5| Step: 4
Training loss: 0.2002019927608288
Validation loss: 2.3160182670359424

Epoch: 5| Step: 5
Training loss: 0.13213350128732296
Validation loss: 2.2737125159485236

Epoch: 5| Step: 6
Training loss: 0.21017085382708206
Validation loss: 2.3103203660435163

Epoch: 5| Step: 7
Training loss: 0.17673561315074968
Validation loss: 2.2999634573085737

Epoch: 5| Step: 8
Training loss: 0.2432089538194332
Validation loss: 2.301277095932401

Epoch: 5| Step: 9
Training loss: 0.14237482129605727
Validation loss: 2.3068773703295506

Epoch: 5| Step: 10
Training loss: 0.3233226894850333
Validation loss: 2.3293673926458314

Epoch: 651| Step: 0
Training loss: 0.1094932427901531
Validation loss: 2.309832223926297

Epoch: 5| Step: 1
Training loss: 0.1871259056864438
Validation loss: 2.3283280122166925

Epoch: 5| Step: 2
Training loss: 0.12888513738960147
Validation loss: 2.3144835058589135

Epoch: 5| Step: 3
Training loss: 0.23387133999717724
Validation loss: 2.3362240724084993

Epoch: 5| Step: 4
Training loss: 0.23277968425021867
Validation loss: 2.300766502324888

Epoch: 5| Step: 5
Training loss: 0.15980761659371984
Validation loss: 2.2984238436873152

Epoch: 5| Step: 6
Training loss: 0.23229581956757706
Validation loss: 2.331535328536467

Epoch: 5| Step: 7
Training loss: 0.165336369312784
Validation loss: 2.3130426986746335

Epoch: 5| Step: 8
Training loss: 0.162975405166735
Validation loss: 2.316506598525838

Epoch: 5| Step: 9
Training loss: 0.1284283753446454
Validation loss: 2.324986655203278

Epoch: 5| Step: 10
Training loss: 0.13569069990508
Validation loss: 2.3464939661739748

Epoch: 652| Step: 0
Training loss: 0.19916572987231065
Validation loss: 2.353681551010262

Epoch: 5| Step: 1
Training loss: 0.1855070673754297
Validation loss: 2.3563573182280195

Epoch: 5| Step: 2
Training loss: 0.13971478546693403
Validation loss: 2.347452264273097

Epoch: 5| Step: 3
Training loss: 0.2095081059263594
Validation loss: 2.3295436912875376

Epoch: 5| Step: 4
Training loss: 0.27247305128725624
Validation loss: 2.3234003895906903

Epoch: 5| Step: 5
Training loss: 0.16100978778732666
Validation loss: 2.364153937709051

Epoch: 5| Step: 6
Training loss: 0.23160104300829473
Validation loss: 2.341196940693927

Epoch: 5| Step: 7
Training loss: 0.1479724261523091
Validation loss: 2.3346675030124038

Epoch: 5| Step: 8
Training loss: 0.2152945124665897
Validation loss: 2.357388789929817

Epoch: 5| Step: 9
Training loss: 0.11292298160146415
Validation loss: 2.3741151881026727

Epoch: 5| Step: 10
Training loss: 0.22051947894796908
Validation loss: 2.3696736104975744

Epoch: 653| Step: 0
Training loss: 0.16550702558289418
Validation loss: 2.3911115379276633

Epoch: 5| Step: 1
Training loss: 0.14462930343130362
Validation loss: 2.3747845456462358

Epoch: 5| Step: 2
Training loss: 0.17880294599212934
Validation loss: 2.359456678689546

Epoch: 5| Step: 3
Training loss: 0.2517321748900791
Validation loss: 2.4078468252325016

Epoch: 5| Step: 4
Training loss: 0.15750263097435097
Validation loss: 2.366194415027059

Epoch: 5| Step: 5
Training loss: 0.17997635553620234
Validation loss: 2.335046429565213

Epoch: 5| Step: 6
Training loss: 0.17891382467901146
Validation loss: 2.314181387543698

Epoch: 5| Step: 7
Training loss: 0.14057373728470798
Validation loss: 2.2891184375702127

Epoch: 5| Step: 8
Training loss: 0.19567502709036783
Validation loss: 2.3058149608031306

Epoch: 5| Step: 9
Training loss: 0.14946722194473558
Validation loss: 2.3110519626997483

Epoch: 5| Step: 10
Training loss: 0.26292425056790325
Validation loss: 2.300950112526847

Epoch: 654| Step: 0
Training loss: 0.11170521667513496
Validation loss: 2.3019718701289706

Epoch: 5| Step: 1
Training loss: 0.2861687569288238
Validation loss: 2.3080969401315055

Epoch: 5| Step: 2
Training loss: 0.1414915644158215
Validation loss: 2.320968757755505

Epoch: 5| Step: 3
Training loss: 0.18843498166617254
Validation loss: 2.3337750232903733

Epoch: 5| Step: 4
Training loss: 0.22335573380909093
Validation loss: 2.3501275048697936

Epoch: 5| Step: 5
Training loss: 0.20222643024925843
Validation loss: 2.336881907535963

Epoch: 5| Step: 6
Training loss: 0.19744311741864667
Validation loss: 2.3342056480508817

Epoch: 5| Step: 7
Training loss: 0.13583298260647403
Validation loss: 2.336518575393246

Epoch: 5| Step: 8
Training loss: 0.19642621083822817
Validation loss: 2.311907493627032

Epoch: 5| Step: 9
Training loss: 0.16520610233771188
Validation loss: 2.348169046337291

Epoch: 5| Step: 10
Training loss: 0.15919055784588773
Validation loss: 2.321251093888663

Epoch: 655| Step: 0
Training loss: 0.15555761232203724
Validation loss: 2.3441759134055427

Epoch: 5| Step: 1
Training loss: 0.2144455948360527
Validation loss: 2.3332627277708142

Epoch: 5| Step: 2
Training loss: 0.1602813999318868
Validation loss: 2.3404620071413604

Epoch: 5| Step: 3
Training loss: 0.12518301619252667
Validation loss: 2.335635558727472

Epoch: 5| Step: 4
Training loss: 0.15004639429613054
Validation loss: 2.350212501953497

Epoch: 5| Step: 5
Training loss: 0.20100063146484878
Validation loss: 2.3578387814777715

Epoch: 5| Step: 6
Training loss: 0.23016219036259844
Validation loss: 2.395943812640358

Epoch: 5| Step: 7
Training loss: 0.1366678960772011
Validation loss: 2.36757152313287

Epoch: 5| Step: 8
Training loss: 0.10970696242651021
Validation loss: 2.359957634409315

Epoch: 5| Step: 9
Training loss: 0.09575246979040554
Validation loss: 2.341578744907573

Epoch: 5| Step: 10
Training loss: 0.2591102909646346
Validation loss: 2.340718105041661

Epoch: 656| Step: 0
Training loss: 0.1720970031353917
Validation loss: 2.3545977144937775

Epoch: 5| Step: 1
Training loss: 0.15582450510095155
Validation loss: 2.3400528622407513

Epoch: 5| Step: 2
Training loss: 0.26072202740287
Validation loss: 2.335054930017812

Epoch: 5| Step: 3
Training loss: 0.14254880629835479
Validation loss: 2.338067066586382

Epoch: 5| Step: 4
Training loss: 0.12201052155082132
Validation loss: 2.3152389580329995

Epoch: 5| Step: 5
Training loss: 0.1722422653155156
Validation loss: 2.315576114320918

Epoch: 5| Step: 6
Training loss: 0.18094450345757573
Validation loss: 2.294235234989296

Epoch: 5| Step: 7
Training loss: 0.2568740526353579
Validation loss: 2.294401622790982

Epoch: 5| Step: 8
Training loss: 0.18717783828153706
Validation loss: 2.3136023632476155

Epoch: 5| Step: 9
Training loss: 0.2144265024583306
Validation loss: 2.3035242264045777

Epoch: 5| Step: 10
Training loss: 0.14252747981816977
Validation loss: 2.3359215722436324

Epoch: 657| Step: 0
Training loss: 0.1699660945224805
Validation loss: 2.324461594032624

Epoch: 5| Step: 1
Training loss: 0.19739435735534855
Validation loss: 2.35423687470731

Epoch: 5| Step: 2
Training loss: 0.1627437977253586
Validation loss: 2.314688665906392

Epoch: 5| Step: 3
Training loss: 0.3074721827175336
Validation loss: 2.340669895506438

Epoch: 5| Step: 4
Training loss: 0.11627653818853917
Validation loss: 2.3434149849295802

Epoch: 5| Step: 5
Training loss: 0.13511031753971833
Validation loss: 2.340072282942607

Epoch: 5| Step: 6
Training loss: 0.22879074522014778
Validation loss: 2.3245929210362566

Epoch: 5| Step: 7
Training loss: 0.12069599908330601
Validation loss: 2.352332018462395

Epoch: 5| Step: 8
Training loss: 0.1392740620017969
Validation loss: 2.362074497668516

Epoch: 5| Step: 9
Training loss: 0.15652625577144455
Validation loss: 2.3804705039596548

Epoch: 5| Step: 10
Training loss: 0.09689428614327991
Validation loss: 2.3686882651489016

Epoch: 658| Step: 0
Training loss: 0.28405174180443404
Validation loss: 2.3552876663073796

Epoch: 5| Step: 1
Training loss: 0.2095403939654945
Validation loss: 2.375613217615364

Epoch: 5| Step: 2
Training loss: 0.17827088213034978
Validation loss: 2.3459638256530906

Epoch: 5| Step: 3
Training loss: 0.1533618433399524
Validation loss: 2.3684401523759298

Epoch: 5| Step: 4
Training loss: 0.18295515884622915
Validation loss: 2.37960037204344

Epoch: 5| Step: 5
Training loss: 0.14297808111205673
Validation loss: 2.342503998135173

Epoch: 5| Step: 6
Training loss: 0.13822249683792992
Validation loss: 2.3662120296043105

Epoch: 5| Step: 7
Training loss: 0.14988119988944687
Validation loss: 2.364033871050837

Epoch: 5| Step: 8
Training loss: 0.10772845994065515
Validation loss: 2.355196865074348

Epoch: 5| Step: 9
Training loss: 0.09839920669079355
Validation loss: 2.340759758717482

Epoch: 5| Step: 10
Training loss: 0.11094983143169401
Validation loss: 2.331481586291054

Epoch: 659| Step: 0
Training loss: 0.16978127044510502
Validation loss: 2.328593948285345

Epoch: 5| Step: 1
Training loss: 0.22491898137649735
Validation loss: 2.3160424071155883

Epoch: 5| Step: 2
Training loss: 0.11638967408821
Validation loss: 2.3122921899901487

Epoch: 5| Step: 3
Training loss: 0.18618610095612217
Validation loss: 2.331458849152635

Epoch: 5| Step: 4
Training loss: 0.11977927430641111
Validation loss: 2.309741764572428

Epoch: 5| Step: 5
Training loss: 0.10898327502170696
Validation loss: 2.3367556666930636

Epoch: 5| Step: 6
Training loss: 0.16309205917473077
Validation loss: 2.29308290702789

Epoch: 5| Step: 7
Training loss: 0.08813069986702997
Validation loss: 2.320291783067116

Epoch: 5| Step: 8
Training loss: 0.18626150743726794
Validation loss: 2.2943791450299935

Epoch: 5| Step: 9
Training loss: 0.192383228824378
Validation loss: 2.2801023780593295

Epoch: 5| Step: 10
Training loss: 0.2117804884191168
Validation loss: 2.3120681605593347

Epoch: 660| Step: 0
Training loss: 0.2062425435047725
Validation loss: 2.276747360267219

Epoch: 5| Step: 1
Training loss: 0.24553896418811072
Validation loss: 2.2981268517190183

Epoch: 5| Step: 2
Training loss: 0.18251846827508234
Validation loss: 2.2866881065860767

Epoch: 5| Step: 3
Training loss: 0.13299051443984986
Validation loss: 2.2974701205929575

Epoch: 5| Step: 4
Training loss: 0.15299790494199678
Validation loss: 2.2879964783613667

Epoch: 5| Step: 5
Training loss: 0.11351140253991843
Validation loss: 2.278772980173606

Epoch: 5| Step: 6
Training loss: 0.24235324417986287
Validation loss: 2.2794684666859326

Epoch: 5| Step: 7
Training loss: 0.18663533833594287
Validation loss: 2.2866286878332773

Epoch: 5| Step: 8
Training loss: 0.1470629835899012
Validation loss: 2.3021711173966883

Epoch: 5| Step: 9
Training loss: 0.2113247425140054
Validation loss: 2.300641963684355

Epoch: 5| Step: 10
Training loss: 0.11489439775198931
Validation loss: 2.335017713341799

Epoch: 661| Step: 0
Training loss: 0.11130175361828425
Validation loss: 2.336596379122242

Epoch: 5| Step: 1
Training loss: 0.1191290982720766
Validation loss: 2.3226806150604853

Epoch: 5| Step: 2
Training loss: 0.1320384271916882
Validation loss: 2.2943901140976006

Epoch: 5| Step: 3
Training loss: 0.1423864447885206
Validation loss: 2.343634984738997

Epoch: 5| Step: 4
Training loss: 0.14178663852617937
Validation loss: 2.332340350743493

Epoch: 5| Step: 5
Training loss: 0.17919000918970318
Validation loss: 2.3358131414275056

Epoch: 5| Step: 6
Training loss: 0.09235753647121954
Validation loss: 2.338049509155975

Epoch: 5| Step: 7
Training loss: 0.22640110712943295
Validation loss: 2.3585000352922867

Epoch: 5| Step: 8
Training loss: 0.22087007301687997
Validation loss: 2.3315362180725825

Epoch: 5| Step: 9
Training loss: 0.24218425440920813
Validation loss: 2.3456173109285263

Epoch: 5| Step: 10
Training loss: 0.20387926727017966
Validation loss: 2.320915221503898

Epoch: 662| Step: 0
Training loss: 0.18684771445432968
Validation loss: 2.3321660767322747

Epoch: 5| Step: 1
Training loss: 0.1086696848110418
Validation loss: 2.3359450681978577

Epoch: 5| Step: 2
Training loss: 0.1263801924721675
Validation loss: 2.330931298038483

Epoch: 5| Step: 3
Training loss: 0.11733109894886391
Validation loss: 2.3413941373519327

Epoch: 5| Step: 4
Training loss: 0.11441083996012434
Validation loss: 2.346416602077319

Epoch: 5| Step: 5
Training loss: 0.2609974329756417
Validation loss: 2.351098696746807

Epoch: 5| Step: 6
Training loss: 0.19048083669915095
Validation loss: 2.376906698223831

Epoch: 5| Step: 7
Training loss: 0.27476855964384195
Validation loss: 2.316269532483415

Epoch: 5| Step: 8
Training loss: 0.10358374081958194
Validation loss: 2.345344690049212

Epoch: 5| Step: 9
Training loss: 0.15489802772859113
Validation loss: 2.3068377020140827

Epoch: 5| Step: 10
Training loss: 0.1513516079668211
Validation loss: 2.3225952158519867

Epoch: 663| Step: 0
Training loss: 0.13659707513365038
Validation loss: 2.3087616857949635

Epoch: 5| Step: 1
Training loss: 0.22766533814501533
Validation loss: 2.2809427750944025

Epoch: 5| Step: 2
Training loss: 0.20459022612979816
Validation loss: 2.2895582726800883

Epoch: 5| Step: 3
Training loss: 0.17029773862546085
Validation loss: 2.2794435984984784

Epoch: 5| Step: 4
Training loss: 0.10660129457623901
Validation loss: 2.2852952360789818

Epoch: 5| Step: 5
Training loss: 0.07129208675919757
Validation loss: 2.2595497493580745

Epoch: 5| Step: 6
Training loss: 0.17461076027578823
Validation loss: 2.2861352773082775

Epoch: 5| Step: 7
Training loss: 0.1691173052845304
Validation loss: 2.286685073967637

Epoch: 5| Step: 8
Training loss: 0.25043095756307476
Validation loss: 2.285438543580252

Epoch: 5| Step: 9
Training loss: 0.17820035193935152
Validation loss: 2.3126466455720496

Epoch: 5| Step: 10
Training loss: 0.11439855579879929
Validation loss: 2.325168178622762

Epoch: 664| Step: 0
Training loss: 0.20615305970472864
Validation loss: 2.3360276599407266

Epoch: 5| Step: 1
Training loss: 0.17139342966009782
Validation loss: 2.3439097546237995

Epoch: 5| Step: 2
Training loss: 0.10009525110099923
Validation loss: 2.3327435522313538

Epoch: 5| Step: 3
Training loss: 0.20139183130434998
Validation loss: 2.3320433457490424

Epoch: 5| Step: 4
Training loss: 0.1023664110881082
Validation loss: 2.306398558359613

Epoch: 5| Step: 5
Training loss: 0.23523189145553702
Validation loss: 2.293488023895966

Epoch: 5| Step: 6
Training loss: 0.1549796558111223
Validation loss: 2.279108662703402

Epoch: 5| Step: 7
Training loss: 0.1782485420553979
Validation loss: 2.3102324470192053

Epoch: 5| Step: 8
Training loss: 0.19655278268274182
Validation loss: 2.288651487112436

Epoch: 5| Step: 9
Training loss: 0.2600061980526595
Validation loss: 2.272342208439375

Epoch: 5| Step: 10
Training loss: 0.1615305644150124
Validation loss: 2.298224069642039

Epoch: 665| Step: 0
Training loss: 0.1907907925811587
Validation loss: 2.2877732174999106

Epoch: 5| Step: 1
Training loss: 0.1935898149412169
Validation loss: 2.337906770714419

Epoch: 5| Step: 2
Training loss: 0.20268872064886911
Validation loss: 2.344576145716572

Epoch: 5| Step: 3
Training loss: 0.10664540479239461
Validation loss: 2.378498859304764

Epoch: 5| Step: 4
Training loss: 0.2252664243672427
Validation loss: 2.3572917461583303

Epoch: 5| Step: 5
Training loss: 0.11889768674269918
Validation loss: 2.3346842993857466

Epoch: 5| Step: 6
Training loss: 0.06388024567033931
Validation loss: 2.323978044925617

Epoch: 5| Step: 7
Training loss: 0.1118418152437421
Validation loss: 2.2986924006993745

Epoch: 5| Step: 8
Training loss: 0.14304300188397387
Validation loss: 2.2932896984903683

Epoch: 5| Step: 9
Training loss: 0.2795415753354795
Validation loss: 2.331885354032613

Epoch: 5| Step: 10
Training loss: 0.13426620437193418
Validation loss: 2.2927199951295125

Epoch: 666| Step: 0
Training loss: 0.08779419271190889
Validation loss: 2.2981895428080157

Epoch: 5| Step: 1
Training loss: 0.1928598617953051
Validation loss: 2.334048705008878

Epoch: 5| Step: 2
Training loss: 0.16044138902632468
Validation loss: 2.3076551704689474

Epoch: 5| Step: 3
Training loss: 0.1665405781206259
Validation loss: 2.337359858636303

Epoch: 5| Step: 4
Training loss: 0.20983139299947937
Validation loss: 2.3240366929832126

Epoch: 5| Step: 5
Training loss: 0.17860363516562908
Validation loss: 2.343831984750696

Epoch: 5| Step: 6
Training loss: 0.18524845620012712
Validation loss: 2.34461904732328

Epoch: 5| Step: 7
Training loss: 0.19324688577425092
Validation loss: 2.3217918365092785

Epoch: 5| Step: 8
Training loss: 0.12151828304923656
Validation loss: 2.312630085167264

Epoch: 5| Step: 9
Training loss: 0.08352366209834006
Validation loss: 2.3213553953621813

Epoch: 5| Step: 10
Training loss: 0.18689431272500517
Validation loss: 2.335868931844054

Epoch: 667| Step: 0
Training loss: 0.26097022667970543
Validation loss: 2.326051443677609

Epoch: 5| Step: 1
Training loss: 0.09047138188047119
Validation loss: 2.2981701262557377

Epoch: 5| Step: 2
Training loss: 0.1327137088797287
Validation loss: 2.3012604826741088

Epoch: 5| Step: 3
Training loss: 0.22121417536817026
Validation loss: 2.3103486430112827

Epoch: 5| Step: 4
Training loss: 0.15960637925819426
Validation loss: 2.3004358027661684

Epoch: 5| Step: 5
Training loss: 0.1364729033279923
Validation loss: 2.3148059096170766

Epoch: 5| Step: 6
Training loss: 0.15868354777905527
Validation loss: 2.3507436865904623

Epoch: 5| Step: 7
Training loss: 0.14654818098887684
Validation loss: 2.348246557943237

Epoch: 5| Step: 8
Training loss: 0.17186406490912767
Validation loss: 2.3230263222316787

Epoch: 5| Step: 9
Training loss: 0.20462798716695615
Validation loss: 2.323301086408851

Epoch: 5| Step: 10
Training loss: 0.2660408131330077
Validation loss: 2.319060768751283

Epoch: 668| Step: 0
Training loss: 0.13402599044320698
Validation loss: 2.312968328889531

Epoch: 5| Step: 1
Training loss: 0.21036501303963637
Validation loss: 2.293312323310475

Epoch: 5| Step: 2
Training loss: 0.18666458780828424
Validation loss: 2.2990433619727524

Epoch: 5| Step: 3
Training loss: 0.2694123600234944
Validation loss: 2.309692080455449

Epoch: 5| Step: 4
Training loss: 0.2518540268820128
Validation loss: 2.340523742818936

Epoch: 5| Step: 5
Training loss: 0.13276388877522638
Validation loss: 2.311715606893697

Epoch: 5| Step: 6
Training loss: 0.09271691256734871
Validation loss: 2.348411301183637

Epoch: 5| Step: 7
Training loss: 0.23311784868802743
Validation loss: 2.3811606451147447

Epoch: 5| Step: 8
Training loss: 0.14064273457491375
Validation loss: 2.414622555833484

Epoch: 5| Step: 9
Training loss: 0.15396387647948953
Validation loss: 2.4028008208350564

Epoch: 5| Step: 10
Training loss: 0.1276929791185674
Validation loss: 2.4011939719415016

Epoch: 669| Step: 0
Training loss: 0.14424198432564664
Validation loss: 2.4064659711050433

Epoch: 5| Step: 1
Training loss: 0.14348004794645214
Validation loss: 2.384464525450993

Epoch: 5| Step: 2
Training loss: 0.23739805857134502
Validation loss: 2.3619782607375104

Epoch: 5| Step: 3
Training loss: 0.08047869560666876
Validation loss: 2.32430562489237

Epoch: 5| Step: 4
Training loss: 0.1695012114321198
Validation loss: 2.3045929363936275

Epoch: 5| Step: 5
Training loss: 0.10646647496671732
Validation loss: 2.2673726697272216

Epoch: 5| Step: 6
Training loss: 0.2211897052084754
Validation loss: 2.265012146320647

Epoch: 5| Step: 7
Training loss: 0.23366753774716165
Validation loss: 2.2552984551646396

Epoch: 5| Step: 8
Training loss: 0.19159049294757807
Validation loss: 2.2553587214964446

Epoch: 5| Step: 9
Training loss: 0.1609146490818383
Validation loss: 2.275952184486638

Epoch: 5| Step: 10
Training loss: 0.10642443898475183
Validation loss: 2.2957328315520615

Epoch: 670| Step: 0
Training loss: 0.12460339854745694
Validation loss: 2.3206876123748064

Epoch: 5| Step: 1
Training loss: 0.2203180278598616
Validation loss: 2.3397862338998796

Epoch: 5| Step: 2
Training loss: 0.1886349541216101
Validation loss: 2.3391993633037793

Epoch: 5| Step: 3
Training loss: 0.09051118045940029
Validation loss: 2.4037987545489674

Epoch: 5| Step: 4
Training loss: 0.16917058776220575
Validation loss: 2.388017279593589

Epoch: 5| Step: 5
Training loss: 0.22090118939399853
Validation loss: 2.3821166524856525

Epoch: 5| Step: 6
Training loss: 0.18010879966979518
Validation loss: 2.40101879314425

Epoch: 5| Step: 7
Training loss: 0.10565814038672572
Validation loss: 2.3825934282660692

Epoch: 5| Step: 8
Training loss: 0.1893714453423393
Validation loss: 2.3604923463768452

Epoch: 5| Step: 9
Training loss: 0.15116521219361165
Validation loss: 2.347047548161203

Epoch: 5| Step: 10
Training loss: 0.10968977897265396
Validation loss: 2.3666079427090922

Epoch: 671| Step: 0
Training loss: 0.20742043316873413
Validation loss: 2.326487155929197

Epoch: 5| Step: 1
Training loss: 0.11173255141579458
Validation loss: 2.3553082827719636

Epoch: 5| Step: 2
Training loss: 0.12444175923945795
Validation loss: 2.391126876118592

Epoch: 5| Step: 3
Training loss: 0.2190897551055233
Validation loss: 2.31349351577068

Epoch: 5| Step: 4
Training loss: 0.12073647954870732
Validation loss: 2.337873516386312

Epoch: 5| Step: 5
Training loss: 0.18099312584426672
Validation loss: 2.314775670874817

Epoch: 5| Step: 6
Training loss: 0.1121625498359924
Validation loss: 2.334422062602891

Epoch: 5| Step: 7
Training loss: 0.15636078959862285
Validation loss: 2.306707875889381

Epoch: 5| Step: 8
Training loss: 0.08888716001658839
Validation loss: 2.312468156315406

Epoch: 5| Step: 9
Training loss: 0.1224455977449762
Validation loss: 2.329572037548645

Epoch: 5| Step: 10
Training loss: 0.228925142387395
Validation loss: 2.353088298174144

Epoch: 672| Step: 0
Training loss: 0.16510652822215544
Validation loss: 2.3031971429483957

Epoch: 5| Step: 1
Training loss: 0.11548052376741079
Validation loss: 2.329115841278881

Epoch: 5| Step: 2
Training loss: 0.15689777566088006
Validation loss: 2.3104827405674855

Epoch: 5| Step: 3
Training loss: 0.0759710298843
Validation loss: 2.289909459493475

Epoch: 5| Step: 4
Training loss: 0.08919630832321711
Validation loss: 2.3026972978215854

Epoch: 5| Step: 5
Training loss: 0.08257552791993913
Validation loss: 2.2928916014095173

Epoch: 5| Step: 6
Training loss: 0.11800222111486583
Validation loss: 2.2747279732840466

Epoch: 5| Step: 7
Training loss: 0.11617221908544033
Validation loss: 2.3132263812100624

Epoch: 5| Step: 8
Training loss: 0.23158688782313366
Validation loss: 2.2991023689991783

Epoch: 5| Step: 9
Training loss: 0.09179053893441268
Validation loss: 2.301143708570728

Epoch: 5| Step: 10
Training loss: 0.2440611671846071
Validation loss: 2.300451746649247

Epoch: 673| Step: 0
Training loss: 0.11060164395643456
Validation loss: 2.3095767954903796

Epoch: 5| Step: 1
Training loss: 0.09752781528528964
Validation loss: 2.3052308835408057

Epoch: 5| Step: 2
Training loss: 0.09340532839828697
Validation loss: 2.299000203675568

Epoch: 5| Step: 3
Training loss: 0.23961824788125755
Validation loss: 2.3042044429341155

Epoch: 5| Step: 4
Training loss: 0.12403716364319688
Validation loss: 2.3060657893970626

Epoch: 5| Step: 5
Training loss: 0.08649486539290899
Validation loss: 2.331713127855445

Epoch: 5| Step: 6
Training loss: 0.21465808475325038
Validation loss: 2.337264426915685

Epoch: 5| Step: 7
Training loss: 0.09815265375184702
Validation loss: 2.3409427054314853

Epoch: 5| Step: 8
Training loss: 0.20161243455970804
Validation loss: 2.318208753580573

Epoch: 5| Step: 9
Training loss: 0.15387483411713374
Validation loss: 2.3362803687511478

Epoch: 5| Step: 10
Training loss: 0.17762018035521607
Validation loss: 2.3445017494342077

Epoch: 674| Step: 0
Training loss: 0.10181188226832077
Validation loss: 2.3273936580152723

Epoch: 5| Step: 1
Training loss: 0.08390219959680174
Validation loss: 2.349391288266017

Epoch: 5| Step: 2
Training loss: 0.10987515703229131
Validation loss: 2.325755377180757

Epoch: 5| Step: 3
Training loss: 0.20932362552461733
Validation loss: 2.34617770561932

Epoch: 5| Step: 4
Training loss: 0.12356530074282054
Validation loss: 2.3453975467964523

Epoch: 5| Step: 5
Training loss: 0.144235701851067
Validation loss: 2.3635949541130823

Epoch: 5| Step: 6
Training loss: 0.09022156430417848
Validation loss: 2.3444309954369356

Epoch: 5| Step: 7
Training loss: 0.0889522910029589
Validation loss: 2.353608696803133

Epoch: 5| Step: 8
Training loss: 0.13798873156172375
Validation loss: 2.3398130388387948

Epoch: 5| Step: 9
Training loss: 0.21275372434352843
Validation loss: 2.341454516242737

Epoch: 5| Step: 10
Training loss: 0.22710265520702927
Validation loss: 2.3694347813777448

Epoch: 675| Step: 0
Training loss: 0.09278523219573659
Validation loss: 2.3392674261580573

Epoch: 5| Step: 1
Training loss: 0.18663324249663882
Validation loss: 2.359350259617622

Epoch: 5| Step: 2
Training loss: 0.0843303120562564
Validation loss: 2.326697694472416

Epoch: 5| Step: 3
Training loss: 0.15202364547741143
Validation loss: 2.2875158834665243

Epoch: 5| Step: 4
Training loss: 0.20417399239210315
Validation loss: 2.3234925128603385

Epoch: 5| Step: 5
Training loss: 0.17891720817355453
Validation loss: 2.3081258252359538

Epoch: 5| Step: 6
Training loss: 0.15185001032301385
Validation loss: 2.2914973956227076

Epoch: 5| Step: 7
Training loss: 0.12820457453027403
Validation loss: 2.3167032113966006

Epoch: 5| Step: 8
Training loss: 0.12552560629680198
Validation loss: 2.3306573272502793

Epoch: 5| Step: 9
Training loss: 0.19687287730631825
Validation loss: 2.323532809849749

Epoch: 5| Step: 10
Training loss: 0.09276603870000823
Validation loss: 2.3182458807019812

Epoch: 676| Step: 0
Training loss: 0.1002228767745561
Validation loss: 2.3428970567814784

Epoch: 5| Step: 1
Training loss: 0.2037089646738555
Validation loss: 2.3301382038249576

Epoch: 5| Step: 2
Training loss: 0.08447476478106024
Validation loss: 2.3778003807140093

Epoch: 5| Step: 3
Training loss: 0.13739684066109165
Validation loss: 2.3820353515093755

Epoch: 5| Step: 4
Training loss: 0.1888177382895724
Validation loss: 2.3877226006702736

Epoch: 5| Step: 5
Training loss: 0.142072814235524
Validation loss: 2.3613983672845733

Epoch: 5| Step: 6
Training loss: 0.13793007472742044
Validation loss: 2.4098392401144126

Epoch: 5| Step: 7
Training loss: 0.18392889397125958
Validation loss: 2.350670956723683

Epoch: 5| Step: 8
Training loss: 0.0935512562005055
Validation loss: 2.362570849240296

Epoch: 5| Step: 9
Training loss: 0.13822733453021763
Validation loss: 2.3459932613468526

Epoch: 5| Step: 10
Training loss: 0.17360655454113205
Validation loss: 2.34107456871952

Epoch: 677| Step: 0
Training loss: 0.0985117726703431
Validation loss: 2.3617341193404293

Epoch: 5| Step: 1
Training loss: 0.14540958929623865
Validation loss: 2.3395541002218

Epoch: 5| Step: 2
Training loss: 0.18085295622539602
Validation loss: 2.3424472505247174

Epoch: 5| Step: 3
Training loss: 0.13471184224014776
Validation loss: 2.367078586594715

Epoch: 5| Step: 4
Training loss: 0.17516559765600995
Validation loss: 2.3482814066541753

Epoch: 5| Step: 5
Training loss: 0.2562643297189564
Validation loss: 2.3206326438632736

Epoch: 5| Step: 6
Training loss: 0.09967991257435908
Validation loss: 2.3053147497077475

Epoch: 5| Step: 7
Training loss: 0.19818330463430817
Validation loss: 2.3432559454519555

Epoch: 5| Step: 8
Training loss: 0.10138660568322123
Validation loss: 2.337611602554655

Epoch: 5| Step: 9
Training loss: 0.10777591105184228
Validation loss: 2.309065075011619

Epoch: 5| Step: 10
Training loss: 0.09684816765656924
Validation loss: 2.3081189844104233

Epoch: 678| Step: 0
Training loss: 0.09485908951431267
Validation loss: 2.283083811477185

Epoch: 5| Step: 1
Training loss: 0.10607812703236999
Validation loss: 2.3171402555220664

Epoch: 5| Step: 2
Training loss: 0.1122892825300258
Validation loss: 2.2876478017325756

Epoch: 5| Step: 3
Training loss: 0.11125856451623238
Validation loss: 2.336268505624766

Epoch: 5| Step: 4
Training loss: 0.21074065984785653
Validation loss: 2.309474577909038

Epoch: 5| Step: 5
Training loss: 0.1816229555293228
Validation loss: 2.295024942925655

Epoch: 5| Step: 6
Training loss: 0.16832241816607896
Validation loss: 2.3352267840330128

Epoch: 5| Step: 7
Training loss: 0.09220404819898402
Validation loss: 2.362901391289

Epoch: 5| Step: 8
Training loss: 0.1738305252423822
Validation loss: 2.3526390826531633

Epoch: 5| Step: 9
Training loss: 0.1268354090217598
Validation loss: 2.3581586599659694

Epoch: 5| Step: 10
Training loss: 0.21268819231318037
Validation loss: 2.3529437438195617

Epoch: 679| Step: 0
Training loss: 0.1446802299353803
Validation loss: 2.3457236278878657

Epoch: 5| Step: 1
Training loss: 0.10844720138829582
Validation loss: 2.360812835041726

Epoch: 5| Step: 2
Training loss: 0.12540171565269378
Validation loss: 2.4050406645371427

Epoch: 5| Step: 3
Training loss: 0.23184684335691666
Validation loss: 2.396783260729989

Epoch: 5| Step: 4
Training loss: 0.13128266978114728
Validation loss: 2.3138200478260305

Epoch: 5| Step: 5
Training loss: 0.10482797858665387
Validation loss: 2.3416217257902443

Epoch: 5| Step: 6
Training loss: 0.13490786854681192
Validation loss: 2.3246756144870404

Epoch: 5| Step: 7
Training loss: 0.18745877885698414
Validation loss: 2.3279171212389906

Epoch: 5| Step: 8
Training loss: 0.207539779572816
Validation loss: 2.299024844710946

Epoch: 5| Step: 9
Training loss: 0.19955208883896008
Validation loss: 2.323943181469591

Epoch: 5| Step: 10
Training loss: 0.11706049315035329
Validation loss: 2.3246351305302175

Epoch: 680| Step: 0
Training loss: 0.12924788460254752
Validation loss: 2.3234925316173993

Epoch: 5| Step: 1
Training loss: 0.12217786247265607
Validation loss: 2.3438989306203712

Epoch: 5| Step: 2
Training loss: 0.23559312571958851
Validation loss: 2.34697003737228

Epoch: 5| Step: 3
Training loss: 0.12654948255916584
Validation loss: 2.313230733316448

Epoch: 5| Step: 4
Training loss: 0.10420582651139082
Validation loss: 2.31591350297127

Epoch: 5| Step: 5
Training loss: 0.1527508102413453
Validation loss: 2.327373844021241

Epoch: 5| Step: 6
Training loss: 0.15940798436836476
Validation loss: 2.3252080292597803

Epoch: 5| Step: 7
Training loss: 0.21976594360089796
Validation loss: 2.337742471569812

Epoch: 5| Step: 8
Training loss: 0.10090956429785698
Validation loss: 2.2819056606095303

Epoch: 5| Step: 9
Training loss: 0.11316056235249533
Validation loss: 2.2910910783148464

Epoch: 5| Step: 10
Training loss: 0.089265121060576
Validation loss: 2.3076194482762524

Epoch: 681| Step: 0
Training loss: 0.16458355947873315
Validation loss: 2.269759735991355

Epoch: 5| Step: 1
Training loss: 0.14302551935145305
Validation loss: 2.2797548128392364

Epoch: 5| Step: 2
Training loss: 0.19179933433742882
Validation loss: 2.2816770555332857

Epoch: 5| Step: 3
Training loss: 0.13686402640488401
Validation loss: 2.257388929378028

Epoch: 5| Step: 4
Training loss: 0.13325005568750087
Validation loss: 2.3111497794578604

Epoch: 5| Step: 5
Training loss: 0.1146778756125931
Validation loss: 2.326325824658035

Epoch: 5| Step: 6
Training loss: 0.14102937256222506
Validation loss: 2.298745397263266

Epoch: 5| Step: 7
Training loss: 0.12476766123629836
Validation loss: 2.3154056600573227

Epoch: 5| Step: 8
Training loss: 0.1917132426421439
Validation loss: 2.3359605644893584

Epoch: 5| Step: 9
Training loss: 0.19365245109243492
Validation loss: 2.333499953770999

Epoch: 5| Step: 10
Training loss: 0.18882994062618527
Validation loss: 2.2826454669455334

Epoch: 682| Step: 0
Training loss: 0.12013376710801084
Validation loss: 2.3126804477626064

Epoch: 5| Step: 1
Training loss: 0.12666130271280998
Validation loss: 2.3122491298602394

Epoch: 5| Step: 2
Training loss: 0.12522409884769622
Validation loss: 2.308536627458565

Epoch: 5| Step: 3
Training loss: 0.20261221128508247
Validation loss: 2.3138717888408102

Epoch: 5| Step: 4
Training loss: 0.1816025150476764
Validation loss: 2.318154141692607

Epoch: 5| Step: 5
Training loss: 0.12156273792189627
Validation loss: 2.3424360479295303

Epoch: 5| Step: 6
Training loss: 0.1752918636531583
Validation loss: 2.3294762302448278

Epoch: 5| Step: 7
Training loss: 0.18707681623469583
Validation loss: 2.355918651253104

Epoch: 5| Step: 8
Training loss: 0.13170350098496858
Validation loss: 2.3546449926894697

Epoch: 5| Step: 9
Training loss: 0.19688290587703394
Validation loss: 2.3720561977218098

Epoch: 5| Step: 10
Training loss: 0.16348644007986643
Validation loss: 2.3868210047631475

Epoch: 683| Step: 0
Training loss: 0.22252430268767578
Validation loss: 2.3513457294065496

Epoch: 5| Step: 1
Training loss: 0.17408832620413853
Validation loss: 2.3510384349570073

Epoch: 5| Step: 2
Training loss: 0.1993505565463799
Validation loss: 2.3086579946518095

Epoch: 5| Step: 3
Training loss: 0.08286026013775745
Validation loss: 2.3044210044549422

Epoch: 5| Step: 4
Training loss: 0.15290590639697524
Validation loss: 2.2712114331109694

Epoch: 5| Step: 5
Training loss: 0.12397898605812471
Validation loss: 2.2312917492483004

Epoch: 5| Step: 6
Training loss: 0.13601871837536195
Validation loss: 2.2578421936115043

Epoch: 5| Step: 7
Training loss: 0.1883668926357423
Validation loss: 2.2517482393032147

Epoch: 5| Step: 8
Training loss: 0.20370618498279178
Validation loss: 2.258617463287847

Epoch: 5| Step: 9
Training loss: 0.12725010394952121
Validation loss: 2.2235779115695085

Epoch: 5| Step: 10
Training loss: 0.10769191957981197
Validation loss: 2.2626759346662735

Epoch: 684| Step: 0
Training loss: 0.18380783666216255
Validation loss: 2.263054287363209

Epoch: 5| Step: 1
Training loss: 0.1542822975805398
Validation loss: 2.292887792660306

Epoch: 5| Step: 2
Training loss: 0.16087964138221036
Validation loss: 2.2959194275819597

Epoch: 5| Step: 3
Training loss: 0.1027554816694638
Validation loss: 2.306135840649789

Epoch: 5| Step: 4
Training loss: 0.2468705783520456
Validation loss: 2.2996356918131298

Epoch: 5| Step: 5
Training loss: 0.10233742097402158
Validation loss: 2.3178991088295398

Epoch: 5| Step: 6
Training loss: 0.13921323734290955
Validation loss: 2.2911716554882506

Epoch: 5| Step: 7
Training loss: 0.17670848853744506
Validation loss: 2.337842692712932

Epoch: 5| Step: 8
Training loss: 0.12712758621372083
Validation loss: 2.337548455256027

Epoch: 5| Step: 9
Training loss: 0.12336614604677287
Validation loss: 2.355636901681746

Epoch: 5| Step: 10
Training loss: 0.19983104968184578
Validation loss: 2.3549392837874366

Epoch: 685| Step: 0
Training loss: 0.14575834276260632
Validation loss: 2.3918581934740417

Epoch: 5| Step: 1
Training loss: 0.11608685352331916
Validation loss: 2.3513794877068253

Epoch: 5| Step: 2
Training loss: 0.15795453874561177
Validation loss: 2.378344352424087

Epoch: 5| Step: 3
Training loss: 0.1911559609390226
Validation loss: 2.3909453862922665

Epoch: 5| Step: 4
Training loss: 0.19530126539343878
Validation loss: 2.3865073179385874

Epoch: 5| Step: 5
Training loss: 0.17902955591016514
Validation loss: 2.3626782262120227

Epoch: 5| Step: 6
Training loss: 0.18042493924196332
Validation loss: 2.37923998394228

Epoch: 5| Step: 7
Training loss: 0.07943567310328944
Validation loss: 2.350510010350901

Epoch: 5| Step: 8
Training loss: 0.10730186607975925
Validation loss: 2.3686895530902365

Epoch: 5| Step: 9
Training loss: 0.0962056570582635
Validation loss: 2.3532762241888254

Epoch: 5| Step: 10
Training loss: 0.08544595439670129
Validation loss: 2.3489682042499043

Epoch: 686| Step: 0
Training loss: 0.09995017002276357
Validation loss: 2.32190187937426

Epoch: 5| Step: 1
Training loss: 0.10677799243496208
Validation loss: 2.3420975064083787

Epoch: 5| Step: 2
Training loss: 0.15713152174968822
Validation loss: 2.3695711507680457

Epoch: 5| Step: 3
Training loss: 0.17724636697879464
Validation loss: 2.319456172605049

Epoch: 5| Step: 4
Training loss: 0.2442389938545432
Validation loss: 2.320020865944836

Epoch: 5| Step: 5
Training loss: 0.14582081865927413
Validation loss: 2.3393404820665826

Epoch: 5| Step: 6
Training loss: 0.058433839025415546
Validation loss: 2.352462394139774

Epoch: 5| Step: 7
Training loss: 0.19180581174956582
Validation loss: 2.342155797072678

Epoch: 5| Step: 8
Training loss: 0.09854357053068136
Validation loss: 2.326149071634111

Epoch: 5| Step: 9
Training loss: 0.10102238454720605
Validation loss: 2.323146604700326

Epoch: 5| Step: 10
Training loss: 0.0790424862180723
Validation loss: 2.344235060072042

Epoch: 687| Step: 0
Training loss: 0.13694612805064207
Validation loss: 2.277409311839347

Epoch: 5| Step: 1
Training loss: 0.09024168600049225
Validation loss: 2.273282259651951

Epoch: 5| Step: 2
Training loss: 0.17232905904558443
Validation loss: 2.3176018023414424

Epoch: 5| Step: 3
Training loss: 0.1340257680807606
Validation loss: 2.297753693973877

Epoch: 5| Step: 4
Training loss: 0.07033563604123948
Validation loss: 2.2705289232690826

Epoch: 5| Step: 5
Training loss: 0.12393141884752591
Validation loss: 2.2884497940539315

Epoch: 5| Step: 6
Training loss: 0.08141935996184886
Validation loss: 2.3346249994262496

Epoch: 5| Step: 7
Training loss: 0.09415005719747341
Validation loss: 2.3201338701075955

Epoch: 5| Step: 8
Training loss: 0.08511515301570288
Validation loss: 2.3235635905524874

Epoch: 5| Step: 9
Training loss: 0.2579192605193751
Validation loss: 2.3214926269600147

Epoch: 5| Step: 10
Training loss: 0.1681529576426418
Validation loss: 2.30881296222033

Epoch: 688| Step: 0
Training loss: 0.23871510515303102
Validation loss: 2.343740028715628

Epoch: 5| Step: 1
Training loss: 0.06765524069449493
Validation loss: 2.3187774201953695

Epoch: 5| Step: 2
Training loss: 0.09704574009144658
Validation loss: 2.318858301174058

Epoch: 5| Step: 3
Training loss: 0.07053158655137036
Validation loss: 2.335266312076259

Epoch: 5| Step: 4
Training loss: 0.0911778927233276
Validation loss: 2.313490387530917

Epoch: 5| Step: 5
Training loss: 0.13534467109872317
Validation loss: 2.3274959240935384

Epoch: 5| Step: 6
Training loss: 0.14122697678433624
Validation loss: 2.332258990892985

Epoch: 5| Step: 7
Training loss: 0.1325287452367515
Validation loss: 2.3002467612053175

Epoch: 5| Step: 8
Training loss: 0.18261508634449858
Validation loss: 2.3116042135175885

Epoch: 5| Step: 9
Training loss: 0.08088486184543774
Validation loss: 2.2841756930660027

Epoch: 5| Step: 10
Training loss: 0.21813312471664653
Validation loss: 2.328585861872007

Epoch: 689| Step: 0
Training loss: 0.10753545392013357
Validation loss: 2.3549308317047224

Epoch: 5| Step: 1
Training loss: 0.10148591124830614
Validation loss: 2.2996428733624703

Epoch: 5| Step: 2
Training loss: 0.1454226481424406
Validation loss: 2.352617288400085

Epoch: 5| Step: 3
Training loss: 0.10476032506805924
Validation loss: 2.3046172895907526

Epoch: 5| Step: 4
Training loss: 0.2512982603714596
Validation loss: 2.3611008253201233

Epoch: 5| Step: 5
Training loss: 0.11961344015612269
Validation loss: 2.339220724326813

Epoch: 5| Step: 6
Training loss: 0.11725125962467345
Validation loss: 2.334480180328494

Epoch: 5| Step: 7
Training loss: 0.21322517181782705
Validation loss: 2.3391210872030266

Epoch: 5| Step: 8
Training loss: 0.12564160668983823
Validation loss: 2.340064788895532

Epoch: 5| Step: 9
Training loss: 0.1337416627549282
Validation loss: 2.304334287723874

Epoch: 5| Step: 10
Training loss: 0.1638985620864852
Validation loss: 2.313977367966699

Epoch: 690| Step: 0
Training loss: 0.1561807240454658
Validation loss: 2.3211955557103927

Epoch: 5| Step: 1
Training loss: 0.13776870557177492
Validation loss: 2.3332436690117846

Epoch: 5| Step: 2
Training loss: 0.15675997361139082
Validation loss: 2.320266532587636

Epoch: 5| Step: 3
Training loss: 0.11733353575431411
Validation loss: 2.316950131586

Epoch: 5| Step: 4
Training loss: 0.17861262467870073
Validation loss: 2.3158731467411644

Epoch: 5| Step: 5
Training loss: 0.0779663203000379
Validation loss: 2.34342142898857

Epoch: 5| Step: 6
Training loss: 0.103328837708225
Validation loss: 2.333448498018254

Epoch: 5| Step: 7
Training loss: 0.12485861978551915
Validation loss: 2.324820810558639

Epoch: 5| Step: 8
Training loss: 0.15785296270763788
Validation loss: 2.3555181836152084

Epoch: 5| Step: 9
Training loss: 0.18074809001900122
Validation loss: 2.332991830677345

Epoch: 5| Step: 10
Training loss: 0.20318973866757503
Validation loss: 2.3524334486067824

Epoch: 691| Step: 0
Training loss: 0.12740710589795295
Validation loss: 2.328214240788061

Epoch: 5| Step: 1
Training loss: 0.086321163975658
Validation loss: 2.299722359419933

Epoch: 5| Step: 2
Training loss: 0.09257249654085999
Validation loss: 2.355925961569638

Epoch: 5| Step: 3
Training loss: 0.1673167126003773
Validation loss: 2.344074038730303

Epoch: 5| Step: 4
Training loss: 0.1186586346940469
Validation loss: 2.3178186356965162

Epoch: 5| Step: 5
Training loss: 0.19807925364043458
Validation loss: 2.3351389958240882

Epoch: 5| Step: 6
Training loss: 0.10151222249987678
Validation loss: 2.27428550228131

Epoch: 5| Step: 7
Training loss: 0.09515399455700137
Validation loss: 2.319576703755181

Epoch: 5| Step: 8
Training loss: 0.21024932572849758
Validation loss: 2.2953072228969247

Epoch: 5| Step: 9
Training loss: 0.18001725167148017
Validation loss: 2.2749867057124504

Epoch: 5| Step: 10
Training loss: 0.09177154840947789
Validation loss: 2.2599120181863843

Epoch: 692| Step: 0
Training loss: 0.1616232142928769
Validation loss: 2.2913787399895056

Epoch: 5| Step: 1
Training loss: 0.11658389885816141
Validation loss: 2.277632443896872

Epoch: 5| Step: 2
Training loss: 0.11712079931474759
Validation loss: 2.255389934750481

Epoch: 5| Step: 3
Training loss: 0.17387038156613321
Validation loss: 2.2730670741773125

Epoch: 5| Step: 4
Training loss: 0.18640939111932872
Validation loss: 2.287760672534622

Epoch: 5| Step: 5
Training loss: 0.19501320795725743
Validation loss: 2.302432006599462

Epoch: 5| Step: 6
Training loss: 0.11728362273802637
Validation loss: 2.319845741602032

Epoch: 5| Step: 7
Training loss: 0.1128348730943407
Validation loss: 2.307954649114258

Epoch: 5| Step: 8
Training loss: 0.1085163797938638
Validation loss: 2.297494663664961

Epoch: 5| Step: 9
Training loss: 0.14125780274985203
Validation loss: 2.291773874305249

Epoch: 5| Step: 10
Training loss: 0.14993518134181183
Validation loss: 2.3331201656668763

Epoch: 693| Step: 0
Training loss: 0.14887124610839633
Validation loss: 2.318740873742006

Epoch: 5| Step: 1
Training loss: 0.0647535870676458
Validation loss: 2.338607682644386

Epoch: 5| Step: 2
Training loss: 0.17773798006195327
Validation loss: 2.362414299558088

Epoch: 5| Step: 3
Training loss: 0.10505449656893764
Validation loss: 2.3061791549914226

Epoch: 5| Step: 4
Training loss: 0.19706938207461522
Validation loss: 2.3312018000446346

Epoch: 5| Step: 5
Training loss: 0.12471552232170643
Validation loss: 2.3361265571251417

Epoch: 5| Step: 6
Training loss: 0.10275808285619843
Validation loss: 2.316006422990785

Epoch: 5| Step: 7
Training loss: 0.14679721487106437
Validation loss: 2.3174288636623044

Epoch: 5| Step: 8
Training loss: 0.15903642561554956
Validation loss: 2.278140363797992

Epoch: 5| Step: 9
Training loss: 0.15740222476964671
Validation loss: 2.2897465082996735

Epoch: 5| Step: 10
Training loss: 0.10784681109387023
Validation loss: 2.3243525315502818

Epoch: 694| Step: 0
Training loss: 0.059729088963101695
Validation loss: 2.2824947193969143

Epoch: 5| Step: 1
Training loss: 0.21165900988759848
Validation loss: 2.298993792335385

Epoch: 5| Step: 2
Training loss: 0.1158177753447206
Validation loss: 2.3289974384143983

Epoch: 5| Step: 3
Training loss: 0.11595292660935638
Validation loss: 2.312962556455502

Epoch: 5| Step: 4
Training loss: 0.16437263920397716
Validation loss: 2.351442501249825

Epoch: 5| Step: 5
Training loss: 0.22920009611243833
Validation loss: 2.303517930601509

Epoch: 5| Step: 6
Training loss: 0.08222128223672225
Validation loss: 2.356749047601482

Epoch: 5| Step: 7
Training loss: 0.19981357185546406
Validation loss: 2.339179192295668

Epoch: 5| Step: 8
Training loss: 0.09207155849113788
Validation loss: 2.3359036458426283

Epoch: 5| Step: 9
Training loss: 0.0772335693391441
Validation loss: 2.325758302638023

Epoch: 5| Step: 10
Training loss: 0.08756034571068957
Validation loss: 2.360847531380475

Epoch: 695| Step: 0
Training loss: 0.22194999649651978
Validation loss: 2.3500702311839428

Epoch: 5| Step: 1
Training loss: 0.07614986700847413
Validation loss: 2.333123300551194

Epoch: 5| Step: 2
Training loss: 0.16598508778379267
Validation loss: 2.3470897404978897

Epoch: 5| Step: 3
Training loss: 0.08807765610921804
Validation loss: 2.360141766735934

Epoch: 5| Step: 4
Training loss: 0.0999492801623283
Validation loss: 2.363203660909473

Epoch: 5| Step: 5
Training loss: 0.157630815354086
Validation loss: 2.371216381530784

Epoch: 5| Step: 6
Training loss: 0.17741326259537027
Validation loss: 2.36624751838633

Epoch: 5| Step: 7
Training loss: 0.13786218555235413
Validation loss: 2.383720807692278

Epoch: 5| Step: 8
Training loss: 0.08200659551695968
Validation loss: 2.3705743617919453

Epoch: 5| Step: 9
Training loss: 0.09929629284427685
Validation loss: 2.3423247008954693

Epoch: 5| Step: 10
Training loss: 0.12245647766047534
Validation loss: 2.3521012229554823

Epoch: 696| Step: 0
Training loss: 0.09381638600384588
Validation loss: 2.345779892968026

Epoch: 5| Step: 1
Training loss: 0.1110275208893519
Validation loss: 2.3507072717715487

Epoch: 5| Step: 2
Training loss: 0.066950068426302
Validation loss: 2.3022405717038588

Epoch: 5| Step: 3
Training loss: 0.16991412484921498
Validation loss: 2.311810110917098

Epoch: 5| Step: 4
Training loss: 0.20222559207464574
Validation loss: 2.334338462435913

Epoch: 5| Step: 5
Training loss: 0.10150960315001918
Validation loss: 2.283591980548061

Epoch: 5| Step: 6
Training loss: 0.19272806199786413
Validation loss: 2.2773582194759765

Epoch: 5| Step: 7
Training loss: 0.09615386191468843
Validation loss: 2.3172453754031297

Epoch: 5| Step: 8
Training loss: 0.11816530384641216
Validation loss: 2.292107763563775

Epoch: 5| Step: 9
Training loss: 0.11917489762684927
Validation loss: 2.29741657237946

Epoch: 5| Step: 10
Training loss: 0.12459892510152157
Validation loss: 2.3001370264782426

Epoch: 697| Step: 0
Training loss: 0.17872743582525705
Validation loss: 2.282818953573825

Epoch: 5| Step: 1
Training loss: 0.15427477593849973
Validation loss: 2.3128660389582993

Epoch: 5| Step: 2
Training loss: 0.11281862008514879
Validation loss: 2.3106478496703424

Epoch: 5| Step: 3
Training loss: 0.12118422297138622
Validation loss: 2.3361324874101976

Epoch: 5| Step: 4
Training loss: 0.2278778844311828
Validation loss: 2.3342235496013903

Epoch: 5| Step: 5
Training loss: 0.10968115227147306
Validation loss: 2.353704836998974

Epoch: 5| Step: 6
Training loss: 0.09307019305055411
Validation loss: 2.379477748105575

Epoch: 5| Step: 7
Training loss: 0.12348806667348455
Validation loss: 2.37334748631113

Epoch: 5| Step: 8
Training loss: 0.10648755888821411
Validation loss: 2.3535611412696147

Epoch: 5| Step: 9
Training loss: 0.09802173885017737
Validation loss: 2.3370387211965586

Epoch: 5| Step: 10
Training loss: 0.06885260706206253
Validation loss: 2.363150530374315

Epoch: 698| Step: 0
Training loss: 0.11694558127568154
Validation loss: 2.3580203047266974

Epoch: 5| Step: 1
Training loss: 0.15052379557940723
Validation loss: 2.3314159176023197

Epoch: 5| Step: 2
Training loss: 0.12856797424663913
Validation loss: 2.3458988011461743

Epoch: 5| Step: 3
Training loss: 0.17845772695390116
Validation loss: 2.34698766733934

Epoch: 5| Step: 4
Training loss: 0.19157999288645364
Validation loss: 2.3062592661486065

Epoch: 5| Step: 5
Training loss: 0.08124036949651803
Validation loss: 2.28559606915894

Epoch: 5| Step: 6
Training loss: 0.0872858939328522
Validation loss: 2.3030905152926273

Epoch: 5| Step: 7
Training loss: 0.12632580334494584
Validation loss: 2.303501486532674

Epoch: 5| Step: 8
Training loss: 0.18009754746428305
Validation loss: 2.2993021397639137

Epoch: 5| Step: 9
Training loss: 0.08350719690394863
Validation loss: 2.269725461622279

Epoch: 5| Step: 10
Training loss: 0.11467623105672185
Validation loss: 2.286295592352665

Epoch: 699| Step: 0
Training loss: 0.09809117741111277
Validation loss: 2.3130920259843273

Epoch: 5| Step: 1
Training loss: 0.1730106289966576
Validation loss: 2.3068576718372578

Epoch: 5| Step: 2
Training loss: 0.11732990037126326
Validation loss: 2.3023604719566326

Epoch: 5| Step: 3
Training loss: 0.0964979428624248
Validation loss: 2.304571330050618

Epoch: 5| Step: 4
Training loss: 0.05701621874881419
Validation loss: 2.281191337529067

Epoch: 5| Step: 5
Training loss: 0.09405829977086774
Validation loss: 2.281693643968824

Epoch: 5| Step: 6
Training loss: 0.17561789445655446
Validation loss: 2.279524125163403

Epoch: 5| Step: 7
Training loss: 0.09009324034646933
Validation loss: 2.2722125697215683

Epoch: 5| Step: 8
Training loss: 0.14998149956419612
Validation loss: 2.2804652061103656

Epoch: 5| Step: 9
Training loss: 0.176144087687106
Validation loss: 2.287164772996285

Epoch: 5| Step: 10
Training loss: 0.1766248540152144
Validation loss: 2.3169404687451607

Epoch: 700| Step: 0
Training loss: 0.19503480243060559
Validation loss: 2.320331973228971

Epoch: 5| Step: 1
Training loss: 0.0791627064794588
Validation loss: 2.313030380537183

Epoch: 5| Step: 2
Training loss: 0.15461333331938973
Validation loss: 2.3082197354253724

Epoch: 5| Step: 3
Training loss: 0.08293439479356755
Validation loss: 2.315360606130995

Epoch: 5| Step: 4
Training loss: 0.16370662056381396
Validation loss: 2.311659422082946

Epoch: 5| Step: 5
Training loss: 0.1322863408453414
Validation loss: 2.312808485443881

Epoch: 5| Step: 6
Training loss: 0.10156138584552875
Validation loss: 2.32635849028956

Epoch: 5| Step: 7
Training loss: 0.16950093121293927
Validation loss: 2.317442019072761

Epoch: 5| Step: 8
Training loss: 0.1348464419426643
Validation loss: 2.3306278194121943

Epoch: 5| Step: 9
Training loss: 0.10134090034961274
Validation loss: 2.3108257151486487

Epoch: 5| Step: 10
Training loss: 0.07004220321472647
Validation loss: 2.330537462396693

Testing loss: 2.6031339097986774
