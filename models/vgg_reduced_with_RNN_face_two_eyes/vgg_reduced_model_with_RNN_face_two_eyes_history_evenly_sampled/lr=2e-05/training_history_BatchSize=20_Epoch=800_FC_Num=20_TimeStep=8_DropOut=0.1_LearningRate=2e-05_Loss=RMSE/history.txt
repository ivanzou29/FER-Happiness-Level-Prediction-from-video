Epoch: 1| Step: 0
Training loss: 5.663501453894201
Validation loss: 5.821661642993472

Epoch: 5| Step: 1
Training loss: 5.697957579787225
Validation loss: 5.803743012785744

Epoch: 5| Step: 2
Training loss: 5.88934555122456
Validation loss: 5.785300191081327

Epoch: 5| Step: 3
Training loss: 6.004820476710318
Validation loss: 5.764746241633885

Epoch: 5| Step: 4
Training loss: 5.964689301475373
Validation loss: 5.7404014918883615

Epoch: 5| Step: 5
Training loss: 6.405404979520043
Validation loss: 5.711940258465937

Epoch: 5| Step: 6
Training loss: 6.3958471175882945
Validation loss: 5.679772761350511

Epoch: 5| Step: 7
Training loss: 5.189545377543773
Validation loss: 5.64162116511397

Epoch: 5| Step: 8
Training loss: 4.596098630319949
Validation loss: 5.599590422848121

Epoch: 5| Step: 9
Training loss: 4.553613028883909
Validation loss: 5.552776713636909

Epoch: 5| Step: 10
Training loss: 6.405135490419759
Validation loss: 5.500465494558038

Epoch: 2| Step: 0
Training loss: 5.334489975122058
Validation loss: 5.4451361287901365

Epoch: 5| Step: 1
Training loss: 5.360144023383701
Validation loss: 5.385644191442842

Epoch: 5| Step: 2
Training loss: 5.385826739618483
Validation loss: 5.323881693181993

Epoch: 5| Step: 3
Training loss: 4.6260075889225
Validation loss: 5.2610152436943425

Epoch: 5| Step: 4
Training loss: 5.261061323593402
Validation loss: 5.199557742613404

Epoch: 5| Step: 5
Training loss: 4.895794071554119
Validation loss: 5.137819495767004

Epoch: 5| Step: 6
Training loss: 5.111010181886327
Validation loss: 5.078672386686236

Epoch: 5| Step: 7
Training loss: 5.8323553446242276
Validation loss: 5.020062241308334

Epoch: 5| Step: 8
Training loss: 4.829884032758702
Validation loss: 4.95635044898356

Epoch: 5| Step: 9
Training loss: 5.287544787783125
Validation loss: 4.887569177974772

Epoch: 5| Step: 10
Training loss: 5.070329428058221
Validation loss: 4.8215433934690575

Epoch: 3| Step: 0
Training loss: 5.251343509792224
Validation loss: 4.75139486042615

Epoch: 5| Step: 1
Training loss: 4.354235391515549
Validation loss: 4.6754716376979575

Epoch: 5| Step: 2
Training loss: 4.432878263440846
Validation loss: 4.600680309956806

Epoch: 5| Step: 3
Training loss: 3.924937477342767
Validation loss: 4.528833655756325

Epoch: 5| Step: 4
Training loss: 5.576416095790258
Validation loss: 4.476680685977707

Epoch: 5| Step: 5
Training loss: 3.8584987865810407
Validation loss: 4.4228799494652415

Epoch: 5| Step: 6
Training loss: 4.559685034665931
Validation loss: 4.379200446279162

Epoch: 5| Step: 7
Training loss: 4.085615856574163
Validation loss: 4.3393940432173475

Epoch: 5| Step: 8
Training loss: 4.196411443518842
Validation loss: 4.296920343571847

Epoch: 5| Step: 9
Training loss: 4.789034222617373
Validation loss: 4.26004347450542

Epoch: 5| Step: 10
Training loss: 4.833083486128366
Validation loss: 4.221631645984072

Epoch: 4| Step: 0
Training loss: 4.397182576931297
Validation loss: 4.1921275831206914

Epoch: 5| Step: 1
Training loss: 3.6095437014568823
Validation loss: 4.157979596231853

Epoch: 5| Step: 2
Training loss: 4.180024948045667
Validation loss: 4.124891252970474

Epoch: 5| Step: 3
Training loss: 4.710461745903382
Validation loss: 4.095162031739906

Epoch: 5| Step: 4
Training loss: 4.21788728158034
Validation loss: 4.065753291056453

Epoch: 5| Step: 5
Training loss: 3.8008267908612225
Validation loss: 4.035346472356878

Epoch: 5| Step: 6
Training loss: 3.9969673581521517
Validation loss: 4.008475585358302

Epoch: 5| Step: 7
Training loss: 3.6011776004757747
Validation loss: 3.987300342436301

Epoch: 5| Step: 8
Training loss: 5.293806149163556
Validation loss: 3.9681381065234858

Epoch: 5| Step: 9
Training loss: 3.736014417289672
Validation loss: 3.9449823284206964

Epoch: 5| Step: 10
Training loss: 4.269178538224344
Validation loss: 3.9246337297527734

Epoch: 5| Step: 0
Training loss: 3.9569949782009233
Validation loss: 3.9091576643572403

Epoch: 5| Step: 1
Training loss: 4.546121960972143
Validation loss: 3.893339814170026

Epoch: 5| Step: 2
Training loss: 3.948451721383174
Validation loss: 3.87601616800702

Epoch: 5| Step: 3
Training loss: 3.6410688530819217
Validation loss: 3.888654684133009

Epoch: 5| Step: 4
Training loss: 4.286217028785019
Validation loss: 3.8655500123671045

Epoch: 5| Step: 5
Training loss: 3.5345848338255745
Validation loss: 3.832660164294849

Epoch: 5| Step: 6
Training loss: 4.34654508171017
Validation loss: 3.8254741585799805

Epoch: 5| Step: 7
Training loss: 4.228733034249286
Validation loss: 3.8481400047395216

Epoch: 5| Step: 8
Training loss: 3.6200567281082323
Validation loss: 3.806404826695515

Epoch: 5| Step: 9
Training loss: 3.9264318733634678
Validation loss: 3.790111261034982

Epoch: 5| Step: 10
Training loss: 3.9736480525097897
Validation loss: 3.7803834379668304

Epoch: 6| Step: 0
Training loss: 3.3691355298874517
Validation loss: 3.766199859745744

Epoch: 5| Step: 1
Training loss: 4.135841456711526
Validation loss: 3.751534233580095

Epoch: 5| Step: 2
Training loss: 3.62541170084314
Validation loss: 3.7395025354196805

Epoch: 5| Step: 3
Training loss: 4.201701437233655
Validation loss: 3.7257926835276867

Epoch: 5| Step: 4
Training loss: 3.5486895923102093
Validation loss: 3.7178589465204106

Epoch: 5| Step: 5
Training loss: 4.6434714068176
Validation loss: 3.718441353468426

Epoch: 5| Step: 6
Training loss: 3.5617446098551926
Validation loss: 3.6903519250223105

Epoch: 5| Step: 7
Training loss: 3.7218596976195446
Validation loss: 3.6833831737707805

Epoch: 5| Step: 8
Training loss: 2.8404055201109504
Validation loss: 3.6789170286709667

Epoch: 5| Step: 9
Training loss: 3.8335900980883615
Validation loss: 3.664234108643616

Epoch: 5| Step: 10
Training loss: 5.038267560843552
Validation loss: 3.6523327551621354

Epoch: 7| Step: 0
Training loss: 3.677542610051266
Validation loss: 3.649206350092533

Epoch: 5| Step: 1
Training loss: 3.9699076968976503
Validation loss: 3.652086207726446

Epoch: 5| Step: 2
Training loss: 3.3384008670501353
Validation loss: 3.633507829171154

Epoch: 5| Step: 3
Training loss: 3.3849629885567323
Validation loss: 3.6028247297988365

Epoch: 5| Step: 4
Training loss: 3.4838517826844155
Validation loss: 3.606044881418468

Epoch: 5| Step: 5
Training loss: 4.064751573317022
Validation loss: 3.5970782675613315

Epoch: 5| Step: 6
Training loss: 3.968390140588796
Validation loss: 3.5863558267203897

Epoch: 5| Step: 7
Training loss: 3.911969201885289
Validation loss: 3.580207682502415

Epoch: 5| Step: 8
Training loss: 3.661549175902696
Validation loss: 3.6076334485251746

Epoch: 5| Step: 9
Training loss: 3.843927394836232
Validation loss: 3.57321166826695

Epoch: 5| Step: 10
Training loss: 4.485175616208081
Validation loss: 3.562497337410836

Epoch: 8| Step: 0
Training loss: 3.6288908762036427
Validation loss: 3.5572405197239783

Epoch: 5| Step: 1
Training loss: 3.1044014110175153
Validation loss: 3.5541351476995486

Epoch: 5| Step: 2
Training loss: 3.516484269990945
Validation loss: 3.5485413690723497

Epoch: 5| Step: 3
Training loss: 4.385702937818413
Validation loss: 3.5432863174214986

Epoch: 5| Step: 4
Training loss: 3.9990414424579415
Validation loss: 3.5301265383203253

Epoch: 5| Step: 5
Training loss: 3.4087271825784216
Validation loss: 3.5246616270064886

Epoch: 5| Step: 6
Training loss: 3.213359578237819
Validation loss: 3.5328960322997585

Epoch: 5| Step: 7
Training loss: 3.527653305647911
Validation loss: 3.5259096457754886

Epoch: 5| Step: 8
Training loss: 3.962278481437837
Validation loss: 3.5084852356489913

Epoch: 5| Step: 9
Training loss: 4.1443255316817025
Validation loss: 3.4866530144792667

Epoch: 5| Step: 10
Training loss: 3.9955906406776824
Validation loss: 3.479560370468792

Epoch: 9| Step: 0
Training loss: 4.964137401502018
Validation loss: 3.476462820351704

Epoch: 5| Step: 1
Training loss: 3.212933367876778
Validation loss: 3.458066238860673

Epoch: 5| Step: 2
Training loss: 3.120289724053863
Validation loss: 3.453459331924226

Epoch: 5| Step: 3
Training loss: 3.877605915602919
Validation loss: 3.483207993907512

Epoch: 5| Step: 4
Training loss: 3.346604171893862
Validation loss: 3.4375981082880767

Epoch: 5| Step: 5
Training loss: 3.510887242743949
Validation loss: 3.4280000197425577

Epoch: 5| Step: 6
Training loss: 3.4656315437991223
Validation loss: 3.428842719747476

Epoch: 5| Step: 7
Training loss: 3.457513014850959
Validation loss: 3.4228134273219593

Epoch: 5| Step: 8
Training loss: 4.03085632767716
Validation loss: 3.4171212091833634

Epoch: 5| Step: 9
Training loss: 3.4561334683465845
Validation loss: 3.4055763730813915

Epoch: 5| Step: 10
Training loss: 3.4208079725495546
Validation loss: 3.393871614711845

Epoch: 10| Step: 0
Training loss: 3.726212011205698
Validation loss: 3.389722611487489

Epoch: 5| Step: 1
Training loss: 3.538527829368981
Validation loss: 3.380446144358178

Epoch: 5| Step: 2
Training loss: 3.3803991294270204
Validation loss: 3.3724526348011135

Epoch: 5| Step: 3
Training loss: 3.111281534098743
Validation loss: 3.359943590745427

Epoch: 5| Step: 4
Training loss: 4.049713435454632
Validation loss: 3.3506721040315077

Epoch: 5| Step: 5
Training loss: 3.9021005793385712
Validation loss: 3.3429663844645017

Epoch: 5| Step: 6
Training loss: 4.126520743514477
Validation loss: 3.3339068862756047

Epoch: 5| Step: 7
Training loss: 3.6559613757858265
Validation loss: 3.324672108119955

Epoch: 5| Step: 8
Training loss: 3.1821368107471453
Validation loss: 3.3123883325101082

Epoch: 5| Step: 9
Training loss: 3.2156746996717325
Validation loss: 3.3118636529457315

Epoch: 5| Step: 10
Training loss: 3.2611450421721484
Validation loss: 3.301305230779266

Epoch: 11| Step: 0
Training loss: 3.6258483420216048
Validation loss: 3.29645662462691

Epoch: 5| Step: 1
Training loss: 3.5381798727783456
Validation loss: 3.2900073982552307

Epoch: 5| Step: 2
Training loss: 3.01871233614533
Validation loss: 3.282563595367352

Epoch: 5| Step: 3
Training loss: 3.1142088155639205
Validation loss: 3.278337564899243

Epoch: 5| Step: 4
Training loss: 3.4386392266178434
Validation loss: 3.2700780390067274

Epoch: 5| Step: 5
Training loss: 3.954734504748929
Validation loss: 3.268116662161566

Epoch: 5| Step: 6
Training loss: 3.784922684115416
Validation loss: 3.2607543360536204

Epoch: 5| Step: 7
Training loss: 3.7648198070188283
Validation loss: 3.255339498260487

Epoch: 5| Step: 8
Training loss: 3.1805451757121914
Validation loss: 3.254372850401614

Epoch: 5| Step: 9
Training loss: 3.889902315850035
Validation loss: 3.2537973683108383

Epoch: 5| Step: 10
Training loss: 3.1624504598122325
Validation loss: 3.2489346524261924

Epoch: 12| Step: 0
Training loss: 4.3270022041063045
Validation loss: 3.248827995083062

Epoch: 5| Step: 1
Training loss: 2.9435294747008425
Validation loss: 3.237553786958853

Epoch: 5| Step: 2
Training loss: 3.2375076529511833
Validation loss: 3.2388516908822904

Epoch: 5| Step: 3
Training loss: 3.9915800882930212
Validation loss: 3.223017156981167

Epoch: 5| Step: 4
Training loss: 3.577002869939466
Validation loss: 3.223289871447946

Epoch: 5| Step: 5
Training loss: 2.814509796906222
Validation loss: 3.2243217393192865

Epoch: 5| Step: 6
Training loss: 3.3677857613190105
Validation loss: 3.2155609038687776

Epoch: 5| Step: 7
Training loss: 3.51686298190013
Validation loss: 3.2145766894651784

Epoch: 5| Step: 8
Training loss: 3.6388705368808725
Validation loss: 3.2136364444178427

Epoch: 5| Step: 9
Training loss: 3.250635965186139
Validation loss: 3.2072954665929796

Epoch: 5| Step: 10
Training loss: 3.28194659876922
Validation loss: 3.2041839265877887

Epoch: 13| Step: 0
Training loss: 2.603634853737966
Validation loss: 3.1963600735886653

Epoch: 5| Step: 1
Training loss: 3.236951897962291
Validation loss: 3.192838971311606

Epoch: 5| Step: 2
Training loss: 2.774046753063761
Validation loss: 3.184862337580322

Epoch: 5| Step: 3
Training loss: 3.3257764669737453
Validation loss: 3.178201473747533

Epoch: 5| Step: 4
Training loss: 3.688091295324578
Validation loss: 3.174374049990371

Epoch: 5| Step: 5
Training loss: 4.093405672691225
Validation loss: 3.1702252865529754

Epoch: 5| Step: 6
Training loss: 3.981945299310278
Validation loss: 3.1656152656132672

Epoch: 5| Step: 7
Training loss: 3.441530673563029
Validation loss: 3.162326585193994

Epoch: 5| Step: 8
Training loss: 3.856338603827232
Validation loss: 3.1581883553513777

Epoch: 5| Step: 9
Training loss: 2.809743505290339
Validation loss: 3.1579245007225367

Epoch: 5| Step: 10
Training loss: 3.5988638939545177
Validation loss: 3.1528105626935856

Epoch: 14| Step: 0
Training loss: 2.791988088598775
Validation loss: 3.150495382597726

Epoch: 5| Step: 1
Training loss: 2.8657216162914496
Validation loss: 3.1475006739685485

Epoch: 5| Step: 2
Training loss: 3.6104503532433267
Validation loss: 3.1456790053084935

Epoch: 5| Step: 3
Training loss: 3.277863562443773
Validation loss: 3.141234391263796

Epoch: 5| Step: 4
Training loss: 2.858331708842744
Validation loss: 3.1433195259562545

Epoch: 5| Step: 5
Training loss: 3.838691546318975
Validation loss: 3.1378391149769196

Epoch: 5| Step: 6
Training loss: 3.7131455447815345
Validation loss: 3.137751426700682

Epoch: 5| Step: 7
Training loss: 3.2004940486042726
Validation loss: 3.1330700946588794

Epoch: 5| Step: 8
Training loss: 3.241676823486525
Validation loss: 3.1383589645324648

Epoch: 5| Step: 9
Training loss: 3.9872880646160356
Validation loss: 3.1421065725733173

Epoch: 5| Step: 10
Training loss: 3.9155347419437683
Validation loss: 3.1335767071089853

Epoch: 15| Step: 0
Training loss: 2.7179252864457877
Validation loss: 3.127258187928023

Epoch: 5| Step: 1
Training loss: 3.068520059147985
Validation loss: 3.132500403695503

Epoch: 5| Step: 2
Training loss: 4.06799250288641
Validation loss: 3.1782141410792426

Epoch: 5| Step: 3
Training loss: 3.3360628555651854
Validation loss: 3.120370230288918

Epoch: 5| Step: 4
Training loss: 3.5747938350105715
Validation loss: 3.1322951846255407

Epoch: 5| Step: 5
Training loss: 3.4427148277386896
Validation loss: 3.155311156494521

Epoch: 5| Step: 6
Training loss: 3.6625366938188257
Validation loss: 3.161438005785495

Epoch: 5| Step: 7
Training loss: 3.410114441011248
Validation loss: 3.154189818344126

Epoch: 5| Step: 8
Training loss: 3.471393574488353
Validation loss: 3.144906466846586

Epoch: 5| Step: 9
Training loss: 3.3784554770667707
Validation loss: 3.1411813296177784

Epoch: 5| Step: 10
Training loss: 3.313903511258829
Validation loss: 3.1468417539745768

Epoch: 16| Step: 0
Training loss: 2.992609776114274
Validation loss: 3.1436028046101456

Epoch: 5| Step: 1
Training loss: 2.787697423264501
Validation loss: 3.1450766294605286

Epoch: 5| Step: 2
Training loss: 4.087603898434041
Validation loss: 3.140350372236392

Epoch: 5| Step: 3
Training loss: 3.023324417246913
Validation loss: 3.143109130905446

Epoch: 5| Step: 4
Training loss: 3.033208469992876
Validation loss: 3.133350042138443

Epoch: 5| Step: 5
Training loss: 3.861959109658316
Validation loss: 3.1271967019178204

Epoch: 5| Step: 6
Training loss: 3.229738016753116
Validation loss: 3.1269763119851377

Epoch: 5| Step: 7
Training loss: 3.963787550782925
Validation loss: 3.124412637291252

Epoch: 5| Step: 8
Training loss: 3.1575020299136294
Validation loss: 3.120885168667774

Epoch: 5| Step: 9
Training loss: 3.740080238134351
Validation loss: 3.120682084021803

Epoch: 5| Step: 10
Training loss: 3.255039709174188
Validation loss: 3.118167107792065

Epoch: 17| Step: 0
Training loss: 3.3367220025391693
Validation loss: 3.1094738726108604

Epoch: 5| Step: 1
Training loss: 3.010651751956313
Validation loss: 3.109063610130027

Epoch: 5| Step: 2
Training loss: 3.3579062866348397
Validation loss: 3.103317026089931

Epoch: 5| Step: 3
Training loss: 3.381474677499134
Validation loss: 3.1032311636926875

Epoch: 5| Step: 4
Training loss: 3.656397498652445
Validation loss: 3.0973871734892113

Epoch: 5| Step: 5
Training loss: 3.878771269601966
Validation loss: 3.0938442759041322

Epoch: 5| Step: 6
Training loss: 2.854499370554168
Validation loss: 3.088825021851589

Epoch: 5| Step: 7
Training loss: 2.9019785018429567
Validation loss: 3.087061569998177

Epoch: 5| Step: 8
Training loss: 3.4152828453522446
Validation loss: 3.0849901191916307

Epoch: 5| Step: 9
Training loss: 3.454227737482017
Validation loss: 3.083951266781899

Epoch: 5| Step: 10
Training loss: 3.78228997675505
Validation loss: 3.0811437272527704

Epoch: 18| Step: 0
Training loss: 3.1412527491310436
Validation loss: 3.083144040492864

Epoch: 5| Step: 1
Training loss: 3.1661291837476737
Validation loss: 3.085978115069449

Epoch: 5| Step: 2
Training loss: 3.8542565137683535
Validation loss: 3.080080755160866

Epoch: 5| Step: 3
Training loss: 3.334420996279883
Validation loss: 3.079006490485321

Epoch: 5| Step: 4
Training loss: 2.8903049601125437
Validation loss: 3.0757291414738734

Epoch: 5| Step: 5
Training loss: 3.063322929832329
Validation loss: 3.0729782078863477

Epoch: 5| Step: 6
Training loss: 3.0348073005147005
Validation loss: 3.0742046084175607

Epoch: 5| Step: 7
Training loss: 3.5692458948970924
Validation loss: 3.113443464358617

Epoch: 5| Step: 8
Training loss: 4.0349028841075825
Validation loss: 3.0680713583271086

Epoch: 5| Step: 9
Training loss: 3.4341887738569152
Validation loss: 3.0675289425360086

Epoch: 5| Step: 10
Training loss: 3.244231606895113
Validation loss: 3.066985362557107

Epoch: 19| Step: 0
Training loss: 3.0696604572616786
Validation loss: 3.0783747539490376

Epoch: 5| Step: 1
Training loss: 3.469891746877183
Validation loss: 3.1049372780576494

Epoch: 5| Step: 2
Training loss: 3.1705015619644388
Validation loss: 3.0751673158602357

Epoch: 5| Step: 3
Training loss: 3.4404393893561758
Validation loss: 3.0680048699466593

Epoch: 5| Step: 4
Training loss: 3.757310988494007
Validation loss: 3.06780047244976

Epoch: 5| Step: 5
Training loss: 3.486939175267002
Validation loss: 3.0640235227005714

Epoch: 5| Step: 6
Training loss: 3.9164697854629664
Validation loss: 3.0602882540312737

Epoch: 5| Step: 7
Training loss: 3.0819045356258887
Validation loss: 3.060901083818567

Epoch: 5| Step: 8
Training loss: 2.422343251891972
Validation loss: 3.061110904119068

Epoch: 5| Step: 9
Training loss: 3.143370988875805
Validation loss: 3.066796901950521

Epoch: 5| Step: 10
Training loss: 3.697470552999092
Validation loss: 3.0516361232458555

Epoch: 20| Step: 0
Training loss: 2.907386147524169
Validation loss: 3.050278292231136

Epoch: 5| Step: 1
Training loss: 3.3897386086663097
Validation loss: 3.0500143003405875

Epoch: 5| Step: 2
Training loss: 3.671258882817714
Validation loss: 3.0495900382073566

Epoch: 5| Step: 3
Training loss: 2.3853056325155175
Validation loss: 3.0450056872606135

Epoch: 5| Step: 4
Training loss: 3.1462897839037134
Validation loss: 3.0455622695098197

Epoch: 5| Step: 5
Training loss: 3.1259840369619325
Validation loss: 3.0389123690743394

Epoch: 5| Step: 6
Training loss: 3.3654233909301405
Validation loss: 3.038628582401033

Epoch: 5| Step: 7
Training loss: 3.219131298998292
Validation loss: 3.0385709059658725

Epoch: 5| Step: 8
Training loss: 4.072140332679866
Validation loss: 3.0353674419799965

Epoch: 5| Step: 9
Training loss: 3.490932981723617
Validation loss: 3.030892954431181

Epoch: 5| Step: 10
Training loss: 3.6106574352274112
Validation loss: 3.0311501362534594

Epoch: 21| Step: 0
Training loss: 2.756583482977925
Validation loss: 3.027831082531659

Epoch: 5| Step: 1
Training loss: 3.6012269896090245
Validation loss: 3.0257486977415633

Epoch: 5| Step: 2
Training loss: 3.6557654687376417
Validation loss: 3.026625562804072

Epoch: 5| Step: 3
Training loss: 2.779253124930164
Validation loss: 3.022272928061326

Epoch: 5| Step: 4
Training loss: 3.743565697822216
Validation loss: 3.0188505534700685

Epoch: 5| Step: 5
Training loss: 3.691351866952249
Validation loss: 3.0195286154916263

Epoch: 5| Step: 6
Training loss: 3.26029555285713
Validation loss: 3.015492341085672

Epoch: 5| Step: 7
Training loss: 3.493017725216166
Validation loss: 3.0151988340491593

Epoch: 5| Step: 8
Training loss: 2.9724629523532826
Validation loss: 3.0145764337326026

Epoch: 5| Step: 9
Training loss: 3.003650193034585
Validation loss: 3.0150265867955874

Epoch: 5| Step: 10
Training loss: 3.2629336715629895
Validation loss: 3.0129951283590404

Epoch: 22| Step: 0
Training loss: 3.653727386644763
Validation loss: 3.011435885929266

Epoch: 5| Step: 1
Training loss: 3.131228990922144
Validation loss: 3.0073033601215755

Epoch: 5| Step: 2
Training loss: 3.3855654326788893
Validation loss: 3.0068049110768813

Epoch: 5| Step: 3
Training loss: 3.332946436998995
Validation loss: 3.0060177508470263

Epoch: 5| Step: 4
Training loss: 3.4830932996872437
Validation loss: 3.0051989754706194

Epoch: 5| Step: 5
Training loss: 3.0782503209042265
Validation loss: 3.027785635992518

Epoch: 5| Step: 6
Training loss: 3.6052141523309653
Validation loss: 3.0188959077822908

Epoch: 5| Step: 7
Training loss: 3.541907373364202
Validation loss: 2.998500697141694

Epoch: 5| Step: 8
Training loss: 2.2240454651487194
Validation loss: 2.9995745353756083

Epoch: 5| Step: 9
Training loss: 3.591227699473445
Validation loss: 3.015011733079612

Epoch: 5| Step: 10
Training loss: 2.9619914974525914
Validation loss: 2.9985538726434706

Epoch: 23| Step: 0
Training loss: 3.170663235714112
Validation loss: 3.003977336933455

Epoch: 5| Step: 1
Training loss: 3.267084844902113
Validation loss: 3.007754469589929

Epoch: 5| Step: 2
Training loss: 2.5612706282507784
Validation loss: 3.0041011069315076

Epoch: 5| Step: 3
Training loss: 3.221077531158006
Validation loss: 3.009463148197936

Epoch: 5| Step: 4
Training loss: 2.956765327943496
Validation loss: 3.0105692892938594

Epoch: 5| Step: 5
Training loss: 3.656571594180026
Validation loss: 3.0303417976944265

Epoch: 5| Step: 6
Training loss: 3.741586656854869
Validation loss: 3.0273035838161486

Epoch: 5| Step: 7
Training loss: 3.0249700875813166
Validation loss: 3.00556063855152

Epoch: 5| Step: 8
Training loss: 4.291258314142971
Validation loss: 3.0132770641915423

Epoch: 5| Step: 9
Training loss: 3.5029145775653348
Validation loss: 3.005422306481633

Epoch: 5| Step: 10
Training loss: 2.49127343135673
Validation loss: 3.0005881568708617

Epoch: 24| Step: 0
Training loss: 2.755132999844522
Validation loss: 3.0017782874766654

Epoch: 5| Step: 1
Training loss: 3.4245156328510333
Validation loss: 3.0006594650893654

Epoch: 5| Step: 2
Training loss: 3.3644100337478346
Validation loss: 3.0006377728341227

Epoch: 5| Step: 3
Training loss: 3.329916888050397
Validation loss: 2.9991346721232026

Epoch: 5| Step: 4
Training loss: 2.7669820958072835
Validation loss: 2.9947542606423494

Epoch: 5| Step: 5
Training loss: 3.720961738469676
Validation loss: 2.989913910718999

Epoch: 5| Step: 6
Training loss: 3.4896848445570345
Validation loss: 2.987799350402632

Epoch: 5| Step: 7
Training loss: 2.6701811836860316
Validation loss: 2.9866578375155535

Epoch: 5| Step: 8
Training loss: 3.6345103244401322
Validation loss: 2.982771436809072

Epoch: 5| Step: 9
Training loss: 3.4429990306169276
Validation loss: 2.9814970742072133

Epoch: 5| Step: 10
Training loss: 3.396340470778044
Validation loss: 2.9825768470021736

Epoch: 25| Step: 0
Training loss: 3.3214248768541266
Validation loss: 2.978956202335594

Epoch: 5| Step: 1
Training loss: 3.2210018836000818
Validation loss: 2.976929592640526

Epoch: 5| Step: 2
Training loss: 3.1393423925001605
Validation loss: 2.9760155707558535

Epoch: 5| Step: 3
Training loss: 3.0221840480500335
Validation loss: 2.9718244814419554

Epoch: 5| Step: 4
Training loss: 3.0599625643765225
Validation loss: 2.9691310083250184

Epoch: 5| Step: 5
Training loss: 3.369763585975463
Validation loss: 2.966497366059759

Epoch: 5| Step: 6
Training loss: 3.987991427091913
Validation loss: 2.9649635230329094

Epoch: 5| Step: 7
Training loss: 3.4192825321056453
Validation loss: 2.960436508545088

Epoch: 5| Step: 8
Training loss: 2.8179886561558662
Validation loss: 2.957766492602056

Epoch: 5| Step: 9
Training loss: 3.4284391803440046
Validation loss: 2.9571238490109133

Epoch: 5| Step: 10
Training loss: 2.9183945760032377
Validation loss: 2.951675280566307

Epoch: 26| Step: 0
Training loss: 3.0969505323943514
Validation loss: 2.954791266793563

Epoch: 5| Step: 1
Training loss: 2.946854003313653
Validation loss: 2.953288528507885

Epoch: 5| Step: 2
Training loss: 3.8649597533031725
Validation loss: 2.9491089811639357

Epoch: 5| Step: 3
Training loss: 3.3389694407967716
Validation loss: 2.9466761384140896

Epoch: 5| Step: 4
Training loss: 3.2120691982810547
Validation loss: 2.9466856737191534

Epoch: 5| Step: 5
Training loss: 3.218291611113735
Validation loss: 2.9448056492514745

Epoch: 5| Step: 6
Training loss: 3.3048613662614534
Validation loss: 2.9464675928792157

Epoch: 5| Step: 7
Training loss: 3.220973015668336
Validation loss: 2.9397362318118923

Epoch: 5| Step: 8
Training loss: 3.374454030275328
Validation loss: 2.93975863420046

Epoch: 5| Step: 9
Training loss: 2.975623595973138
Validation loss: 2.9407242931415736

Epoch: 5| Step: 10
Training loss: 3.0198371209185177
Validation loss: 2.945802014856788

Epoch: 27| Step: 0
Training loss: 3.093439259962627
Validation loss: 2.9393729280757888

Epoch: 5| Step: 1
Training loss: 3.1896120441788223
Validation loss: 2.9380578301455667

Epoch: 5| Step: 2
Training loss: 2.5066308776180866
Validation loss: 2.9381764300087827

Epoch: 5| Step: 3
Training loss: 3.838655771175326
Validation loss: 2.9371481880917463

Epoch: 5| Step: 4
Training loss: 3.278955002141215
Validation loss: 2.933110027282752

Epoch: 5| Step: 5
Training loss: 3.239183031149915
Validation loss: 2.931316656819762

Epoch: 5| Step: 6
Training loss: 2.7098595842533295
Validation loss: 2.9313078009139257

Epoch: 5| Step: 7
Training loss: 3.6713623987694466
Validation loss: 2.9284628709385325

Epoch: 5| Step: 8
Training loss: 2.977862697389998
Validation loss: 2.931212731612995

Epoch: 5| Step: 9
Training loss: 3.133821015924661
Validation loss: 2.9330424094126117

Epoch: 5| Step: 10
Training loss: 3.789843669475365
Validation loss: 2.9364783177875107

Epoch: 28| Step: 0
Training loss: 3.4845260792639094
Validation loss: 2.9387077897867915

Epoch: 5| Step: 1
Training loss: 2.963585788999496
Validation loss: 2.931151049751356

Epoch: 5| Step: 2
Training loss: 3.5891068691223107
Validation loss: 2.9258118896509813

Epoch: 5| Step: 3
Training loss: 3.017628532902194
Validation loss: 2.920808695924659

Epoch: 5| Step: 4
Training loss: 3.4932886900730638
Validation loss: 2.9310298381598807

Epoch: 5| Step: 5
Training loss: 3.486226090506176
Validation loss: 2.9382975570572976

Epoch: 5| Step: 6
Training loss: 2.6956594934872395
Validation loss: 2.9219869324930987

Epoch: 5| Step: 7
Training loss: 3.4135800507410665
Validation loss: 2.915388868674348

Epoch: 5| Step: 8
Training loss: 2.5577892640304545
Validation loss: 2.914128731954719

Epoch: 5| Step: 9
Training loss: 2.940591038052754
Validation loss: 2.9118663158506957

Epoch: 5| Step: 10
Training loss: 3.6863169954614365
Validation loss: 2.911072931458361

Epoch: 29| Step: 0
Training loss: 3.2267753032124618
Validation loss: 2.9240735740442148

Epoch: 5| Step: 1
Training loss: 2.735710907620625
Validation loss: 2.914051689636612

Epoch: 5| Step: 2
Training loss: 2.9246729545667693
Validation loss: 2.912623411828914

Epoch: 5| Step: 3
Training loss: 2.779638187685091
Validation loss: 2.9147676417903083

Epoch: 5| Step: 4
Training loss: 3.399063508704428
Validation loss: 2.916394977543345

Epoch: 5| Step: 5
Training loss: 2.99385681598896
Validation loss: 2.9185029245533074

Epoch: 5| Step: 6
Training loss: 3.795198046677008
Validation loss: 2.913031712271162

Epoch: 5| Step: 7
Training loss: 3.8020765051932837
Validation loss: 2.9124672755617986

Epoch: 5| Step: 8
Training loss: 3.1581623591408876
Validation loss: 2.911348610748611

Epoch: 5| Step: 9
Training loss: 3.0358083213538802
Validation loss: 2.9108866386516112

Epoch: 5| Step: 10
Training loss: 3.40986203806728
Validation loss: 2.907991628203375

Epoch: 30| Step: 0
Training loss: 3.098952110134683
Validation loss: 2.9025530572031877

Epoch: 5| Step: 1
Training loss: 3.3334900501286397
Validation loss: 2.91864982693595

Epoch: 5| Step: 2
Training loss: 2.8296954605100098
Validation loss: 2.9125408134362947

Epoch: 5| Step: 3
Training loss: 3.0307654553933183
Validation loss: 2.900016306688787

Epoch: 5| Step: 4
Training loss: 3.4536858702983166
Validation loss: 2.9024193294755496

Epoch: 5| Step: 5
Training loss: 3.0993812251119834
Validation loss: 2.8982890875276377

Epoch: 5| Step: 6
Training loss: 3.1912828325853084
Validation loss: 2.895588570926883

Epoch: 5| Step: 7
Training loss: 3.563343951997794
Validation loss: 2.8940547170948876

Epoch: 5| Step: 8
Training loss: 3.393266764988999
Validation loss: 2.894526254736722

Epoch: 5| Step: 9
Training loss: 3.2538426497198265
Validation loss: 2.8940718605130744

Epoch: 5| Step: 10
Training loss: 2.9195580093100673
Validation loss: 2.891519791039573

Epoch: 31| Step: 0
Training loss: 3.377382497148266
Validation loss: 2.8892414652150746

Epoch: 5| Step: 1
Training loss: 3.224549189559854
Validation loss: 2.8914348147510918

Epoch: 5| Step: 2
Training loss: 3.410309079165977
Validation loss: 2.893908407047916

Epoch: 5| Step: 3
Training loss: 3.2630929576131313
Validation loss: 2.8953043194131123

Epoch: 5| Step: 4
Training loss: 2.7520090047389574
Validation loss: 2.8959444756086032

Epoch: 5| Step: 5
Training loss: 2.9502824292520735
Validation loss: 2.9025335596932402

Epoch: 5| Step: 6
Training loss: 3.252658197072798
Validation loss: 2.9134437180964605

Epoch: 5| Step: 7
Training loss: 3.2258616279682317
Validation loss: 2.9074908944082245

Epoch: 5| Step: 8
Training loss: 3.2545015997133295
Validation loss: 2.886369461631941

Epoch: 5| Step: 9
Training loss: 3.2285058770837414
Validation loss: 2.884961180058334

Epoch: 5| Step: 10
Training loss: 3.2481389219049195
Validation loss: 2.8921241976566634

Epoch: 32| Step: 0
Training loss: 2.521002950295126
Validation loss: 2.899859470403796

Epoch: 5| Step: 1
Training loss: 2.5816182832101804
Validation loss: 2.8953631740827723

Epoch: 5| Step: 2
Training loss: 3.3765036447630474
Validation loss: 2.8912507244378913

Epoch: 5| Step: 3
Training loss: 3.4940677505152116
Validation loss: 2.8821404818185052

Epoch: 5| Step: 4
Training loss: 3.5507488857762537
Validation loss: 2.8925497017887443

Epoch: 5| Step: 5
Training loss: 3.1996011843114855
Validation loss: 2.9229484702029493

Epoch: 5| Step: 6
Training loss: 3.0493057336307423
Validation loss: 2.9172470118955256

Epoch: 5| Step: 7
Training loss: 3.416895339260547
Validation loss: 2.909371999594961

Epoch: 5| Step: 8
Training loss: 2.7780416607022675
Validation loss: 2.8768462342996797

Epoch: 5| Step: 9
Training loss: 3.5059258839878678
Validation loss: 2.886099982381749

Epoch: 5| Step: 10
Training loss: 3.5706483778946945
Validation loss: 2.902896010901238

Epoch: 33| Step: 0
Training loss: 3.3169854942190904
Validation loss: 2.911530324388644

Epoch: 5| Step: 1
Training loss: 3.4896075043861265
Validation loss: 2.9052237697790932

Epoch: 5| Step: 2
Training loss: 3.0909917075799678
Validation loss: 2.885882253471323

Epoch: 5| Step: 3
Training loss: 3.2958812210198487
Validation loss: 2.8800692245522495

Epoch: 5| Step: 4
Training loss: 2.450883947232658
Validation loss: 2.8786364024956135

Epoch: 5| Step: 5
Training loss: 3.5919707828174574
Validation loss: 2.875565371179494

Epoch: 5| Step: 6
Training loss: 3.1123875731726676
Validation loss: 2.8831467982531294

Epoch: 5| Step: 7
Training loss: 2.74827217962434
Validation loss: 2.8894870530300762

Epoch: 5| Step: 8
Training loss: 3.4395476744705915
Validation loss: 2.911773828032608

Epoch: 5| Step: 9
Training loss: 3.3080238472979593
Validation loss: 2.899848250816579

Epoch: 5| Step: 10
Training loss: 3.170522467220336
Validation loss: 2.88341511049611

Epoch: 34| Step: 0
Training loss: 3.0182883405219525
Validation loss: 2.8724138238889547

Epoch: 5| Step: 1
Training loss: 3.3660970457778308
Validation loss: 2.874884595512048

Epoch: 5| Step: 2
Training loss: 2.8264107751480583
Validation loss: 2.881529199961332

Epoch: 5| Step: 3
Training loss: 2.706184023433914
Validation loss: 2.8857122302242035

Epoch: 5| Step: 4
Training loss: 3.335619444503861
Validation loss: 2.890932013945587

Epoch: 5| Step: 5
Training loss: 3.62388146342591
Validation loss: 2.9066843287620094

Epoch: 5| Step: 6
Training loss: 2.652894087988388
Validation loss: 2.8843788915671964

Epoch: 5| Step: 7
Training loss: 3.812304632465482
Validation loss: 2.8762095610133196

Epoch: 5| Step: 8
Training loss: 3.5122864193312107
Validation loss: 2.870286059706191

Epoch: 5| Step: 9
Training loss: 3.18866543874917
Validation loss: 2.8646732087266793

Epoch: 5| Step: 10
Training loss: 2.829385550285271
Validation loss: 2.859569625197546

Epoch: 35| Step: 0
Training loss: 3.3907058635860667
Validation loss: 2.8620323037302353

Epoch: 5| Step: 1
Training loss: 3.5801973297035876
Validation loss: 2.860964142463786

Epoch: 5| Step: 2
Training loss: 3.1054561590743184
Validation loss: 2.8605971508094594

Epoch: 5| Step: 3
Training loss: 3.686501965997074
Validation loss: 2.86376574053174

Epoch: 5| Step: 4
Training loss: 3.124205526451291
Validation loss: 2.8689788357478934

Epoch: 5| Step: 5
Training loss: 3.0216608076114175
Validation loss: 2.8672130827561415

Epoch: 5| Step: 6
Training loss: 2.5112115279612115
Validation loss: 2.857118551510531

Epoch: 5| Step: 7
Training loss: 3.483704643597566
Validation loss: 2.856107270479421

Epoch: 5| Step: 8
Training loss: 3.008084371590811
Validation loss: 2.8559800302143916

Epoch: 5| Step: 9
Training loss: 2.864067687817093
Validation loss: 2.854650643380277

Epoch: 5| Step: 10
Training loss: 2.8690601854363824
Validation loss: 2.853553284502579

Epoch: 36| Step: 0
Training loss: 3.0764457653366986
Validation loss: 2.851793992662881

Epoch: 5| Step: 1
Training loss: 2.906066232429265
Validation loss: 2.8526199544538526

Epoch: 5| Step: 2
Training loss: 2.7094257987956945
Validation loss: 2.850241419813102

Epoch: 5| Step: 3
Training loss: 3.3646630119282213
Validation loss: 2.850789645597237

Epoch: 5| Step: 4
Training loss: 3.3621722263698732
Validation loss: 2.8508213088543397

Epoch: 5| Step: 5
Training loss: 3.127382667103049
Validation loss: 2.853489671475575

Epoch: 5| Step: 6
Training loss: 3.2984712180650915
Validation loss: 2.8527862795236967

Epoch: 5| Step: 7
Training loss: 3.0787021463805053
Validation loss: 2.860959432685683

Epoch: 5| Step: 8
Training loss: 3.5125911931590883
Validation loss: 2.866479879829659

Epoch: 5| Step: 9
Training loss: 3.192987990875551
Validation loss: 2.8595069546833534

Epoch: 5| Step: 10
Training loss: 3.1105341452003112
Validation loss: 2.851266024004679

Epoch: 37| Step: 0
Training loss: 3.7304516217702335
Validation loss: 2.8442128681581056

Epoch: 5| Step: 1
Training loss: 3.4068241860339517
Validation loss: 2.841732636142081

Epoch: 5| Step: 2
Training loss: 3.1641979800759463
Validation loss: 2.8417034950668945

Epoch: 5| Step: 3
Training loss: 2.9231018102026582
Validation loss: 2.8390377541800587

Epoch: 5| Step: 4
Training loss: 3.4352267985314495
Validation loss: 2.8393626860342045

Epoch: 5| Step: 5
Training loss: 3.3103437783387593
Validation loss: 2.8413701530248607

Epoch: 5| Step: 6
Training loss: 2.9970634711452546
Validation loss: 2.846327208729535

Epoch: 5| Step: 7
Training loss: 3.0995186093555254
Validation loss: 2.8470533914346867

Epoch: 5| Step: 8
Training loss: 2.600354438244581
Validation loss: 2.8463997993105927

Epoch: 5| Step: 9
Training loss: 3.0929413326211237
Validation loss: 2.8447283964221355

Epoch: 5| Step: 10
Training loss: 2.8258803084742046
Validation loss: 2.8408971389116364

Epoch: 38| Step: 0
Training loss: 3.534889168951069
Validation loss: 2.840954463629972

Epoch: 5| Step: 1
Training loss: 2.4829071314970514
Validation loss: 2.837442610948464

Epoch: 5| Step: 2
Training loss: 3.093999833317205
Validation loss: 2.837120383262686

Epoch: 5| Step: 3
Training loss: 3.1880784351363665
Validation loss: 2.8338889048422353

Epoch: 5| Step: 4
Training loss: 3.3702893761702386
Validation loss: 2.832999941509625

Epoch: 5| Step: 5
Training loss: 4.1303299657061725
Validation loss: 2.8450958013560563

Epoch: 5| Step: 6
Training loss: 2.654869798100642
Validation loss: 2.8323686246444066

Epoch: 5| Step: 7
Training loss: 2.568781434398174
Validation loss: 2.831038047200194

Epoch: 5| Step: 8
Training loss: 2.7379961722481654
Validation loss: 2.8309502276112144

Epoch: 5| Step: 9
Training loss: 3.1240823542818856
Validation loss: 2.8312432070436504

Epoch: 5| Step: 10
Training loss: 3.4340102080969364
Validation loss: 2.829514485701933

Epoch: 39| Step: 0
Training loss: 3.3853999367325005
Validation loss: 2.829315921049916

Epoch: 5| Step: 1
Training loss: 2.5681055676042335
Validation loss: 2.8293292633278386

Epoch: 5| Step: 2
Training loss: 3.6582357116974937
Validation loss: 2.8301789240402293

Epoch: 5| Step: 3
Training loss: 2.8849137254637514
Validation loss: 2.829128107653928

Epoch: 5| Step: 4
Training loss: 2.8921255804736385
Validation loss: 2.8286599706083813

Epoch: 5| Step: 5
Training loss: 2.4617474872990415
Validation loss: 2.830468075991837

Epoch: 5| Step: 6
Training loss: 3.4477974370680804
Validation loss: 2.83174156871493

Epoch: 5| Step: 7
Training loss: 3.0775117989506824
Validation loss: 2.8330999054442585

Epoch: 5| Step: 8
Training loss: 3.459686535433798
Validation loss: 2.838536610203229

Epoch: 5| Step: 9
Training loss: 3.039626669798126
Validation loss: 2.8324729154670654

Epoch: 5| Step: 10
Training loss: 3.5201254289127712
Validation loss: 2.8281243128875713

Epoch: 40| Step: 0
Training loss: 3.3409758851894575
Validation loss: 2.824193779022799

Epoch: 5| Step: 1
Training loss: 3.5097879059879857
Validation loss: 2.8224607518071876

Epoch: 5| Step: 2
Training loss: 2.6806989267996917
Validation loss: 2.8217974614868497

Epoch: 5| Step: 3
Training loss: 2.8885497195689527
Validation loss: 2.8205457339885953

Epoch: 5| Step: 4
Training loss: 3.085847259360947
Validation loss: 2.818362942533757

Epoch: 5| Step: 5
Training loss: 2.697751829396825
Validation loss: 2.818220562411884

Epoch: 5| Step: 6
Training loss: 2.963748935810286
Validation loss: 2.8175596604692648

Epoch: 5| Step: 7
Training loss: 3.304294138915258
Validation loss: 2.8178200160058244

Epoch: 5| Step: 8
Training loss: 2.7471795790958087
Validation loss: 2.8159274019502023

Epoch: 5| Step: 9
Training loss: 3.4628584032447605
Validation loss: 2.8145774470048575

Epoch: 5| Step: 10
Training loss: 3.69761047528383
Validation loss: 2.8152654180324848

Epoch: 41| Step: 0
Training loss: 2.8971656826309995
Validation loss: 2.815559793757291

Epoch: 5| Step: 1
Training loss: 3.188189562839486
Validation loss: 2.8131420218519585

Epoch: 5| Step: 2
Training loss: 3.482107202815475
Validation loss: 2.816359598266287

Epoch: 5| Step: 3
Training loss: 2.679587315057323
Validation loss: 2.8158504951605527

Epoch: 5| Step: 4
Training loss: 2.656586928596897
Validation loss: 2.8293832579100116

Epoch: 5| Step: 5
Training loss: 3.5945201546112853
Validation loss: 2.83321860809221

Epoch: 5| Step: 6
Training loss: 2.8597673657644784
Validation loss: 2.840951004778145

Epoch: 5| Step: 7
Training loss: 3.2433635738749467
Validation loss: 2.819445931439813

Epoch: 5| Step: 8
Training loss: 2.8487697355248773
Validation loss: 2.807667851415835

Epoch: 5| Step: 9
Training loss: 3.4891405574337084
Validation loss: 2.8056224944429755

Epoch: 5| Step: 10
Training loss: 3.329428977006004
Validation loss: 2.8008241585367304

Epoch: 42| Step: 0
Training loss: 3.137799410572832
Validation loss: 2.8067646007079583

Epoch: 5| Step: 1
Training loss: 3.3439761646826702
Validation loss: 2.809752354749843

Epoch: 5| Step: 2
Training loss: 3.3534749583476313
Validation loss: 2.805265160285347

Epoch: 5| Step: 3
Training loss: 2.9874778714816905
Validation loss: 2.8024270305526953

Epoch: 5| Step: 4
Training loss: 3.2195520975631595
Validation loss: 2.797569862293294

Epoch: 5| Step: 5
Training loss: 2.920727509573713
Validation loss: 2.794300410660971

Epoch: 5| Step: 6
Training loss: 3.362467349436332
Validation loss: 2.7964666080675507

Epoch: 5| Step: 7
Training loss: 3.1722278116878058
Validation loss: 2.807765644815689

Epoch: 5| Step: 8
Training loss: 2.53316651305342
Validation loss: 2.8180318685358254

Epoch: 5| Step: 9
Training loss: 3.0604914092373505
Validation loss: 2.8300475123679893

Epoch: 5| Step: 10
Training loss: 3.220276109692498
Validation loss: 2.792894089591036

Epoch: 43| Step: 0
Training loss: 3.1027803504301006
Validation loss: 2.7936586351346584

Epoch: 5| Step: 1
Training loss: 2.4773500556107666
Validation loss: 2.796695771544099

Epoch: 5| Step: 2
Training loss: 3.591503469442917
Validation loss: 2.802059021756737

Epoch: 5| Step: 3
Training loss: 2.943285662076725
Validation loss: 2.805039126160022

Epoch: 5| Step: 4
Training loss: 3.510495389665022
Validation loss: 2.8028753649285933

Epoch: 5| Step: 5
Training loss: 2.6939196539822445
Validation loss: 2.8077626965639455

Epoch: 5| Step: 6
Training loss: 3.166111864042761
Validation loss: 2.8058278150256384

Epoch: 5| Step: 7
Training loss: 3.198594028833841
Validation loss: 2.8055610695942486

Epoch: 5| Step: 8
Training loss: 3.1822758667465707
Validation loss: 2.7989189144043807

Epoch: 5| Step: 9
Training loss: 3.155284318400459
Validation loss: 2.7928528565246413

Epoch: 5| Step: 10
Training loss: 3.2089340010976977
Validation loss: 2.78980819896316

Epoch: 44| Step: 0
Training loss: 3.0658496521618024
Validation loss: 2.7861824638946073

Epoch: 5| Step: 1
Training loss: 3.6683335127968393
Validation loss: 2.786159728393349

Epoch: 5| Step: 2
Training loss: 2.3150189058261006
Validation loss: 2.7853925363937964

Epoch: 5| Step: 3
Training loss: 2.545623284481453
Validation loss: 2.7837849091948876

Epoch: 5| Step: 4
Training loss: 3.510602151892474
Validation loss: 2.7855609148277254

Epoch: 5| Step: 5
Training loss: 3.350280374209811
Validation loss: 2.783524065984356

Epoch: 5| Step: 6
Training loss: 2.891349577947463
Validation loss: 2.788697867351672

Epoch: 5| Step: 7
Training loss: 3.184056984367539
Validation loss: 2.7880415088209864

Epoch: 5| Step: 8
Training loss: 3.043467959392481
Validation loss: 2.7838922430071116

Epoch: 5| Step: 9
Training loss: 3.2688533029953954
Validation loss: 2.781370169815795

Epoch: 5| Step: 10
Training loss: 3.0585599193431543
Validation loss: 2.782587396962691

Epoch: 45| Step: 0
Training loss: 3.4271855363225403
Validation loss: 2.7829537265493234

Epoch: 5| Step: 1
Training loss: 2.8792282193602086
Validation loss: 2.780434241218426

Epoch: 5| Step: 2
Training loss: 3.2328921249709555
Validation loss: 2.7822691647161193

Epoch: 5| Step: 3
Training loss: 2.8748809126363515
Validation loss: 2.7801480665338487

Epoch: 5| Step: 4
Training loss: 3.6457428548575828
Validation loss: 2.7797770898297225

Epoch: 5| Step: 5
Training loss: 2.679280597722416
Validation loss: 2.7763452996252846

Epoch: 5| Step: 6
Training loss: 2.922847157687543
Validation loss: 2.776787767948343

Epoch: 5| Step: 7
Training loss: 3.1064182965070133
Validation loss: 2.7751009324747415

Epoch: 5| Step: 8
Training loss: 2.7296743915594672
Validation loss: 2.7735031774134313

Epoch: 5| Step: 9
Training loss: 3.2131659207189758
Validation loss: 2.7709045111110675

Epoch: 5| Step: 10
Training loss: 3.2518108898136053
Validation loss: 2.769109726648271

Epoch: 46| Step: 0
Training loss: 3.6120175682984
Validation loss: 2.768084167406469

Epoch: 5| Step: 1
Training loss: 3.2511720744660817
Validation loss: 2.767399328053556

Epoch: 5| Step: 2
Training loss: 2.560721361629714
Validation loss: 2.767841492592533

Epoch: 5| Step: 3
Training loss: 3.6405304335726347
Validation loss: 2.765612404355876

Epoch: 5| Step: 4
Training loss: 3.423762388844131
Validation loss: 2.7678283485195294

Epoch: 5| Step: 5
Training loss: 3.492746056727381
Validation loss: 2.7655999347229225

Epoch: 5| Step: 6
Training loss: 1.815800457091179
Validation loss: 2.7663184116403743

Epoch: 5| Step: 7
Training loss: 3.254161078285046
Validation loss: 2.763524628835898

Epoch: 5| Step: 8
Training loss: 2.0538720663134584
Validation loss: 2.7640836311490276

Epoch: 5| Step: 9
Training loss: 3.4039782026424525
Validation loss: 2.7620484228343027

Epoch: 5| Step: 10
Training loss: 2.866567934539078
Validation loss: 2.7620993295095904

Epoch: 47| Step: 0
Training loss: 3.3854626148724813
Validation loss: 2.7629040560439657

Epoch: 5| Step: 1
Training loss: 2.6585599840538214
Validation loss: 2.7655200543221063

Epoch: 5| Step: 2
Training loss: 3.118178590094955
Validation loss: 2.772257076785798

Epoch: 5| Step: 3
Training loss: 2.9532929226397546
Validation loss: 2.7779803319796894

Epoch: 5| Step: 4
Training loss: 3.1946076079637487
Validation loss: 2.7911831090005936

Epoch: 5| Step: 5
Training loss: 3.545524978827294
Validation loss: 2.7942495676789276

Epoch: 5| Step: 6
Training loss: 2.989182679092942
Validation loss: 2.779394524738041

Epoch: 5| Step: 7
Training loss: 2.687096853846754
Validation loss: 2.7609297167447218

Epoch: 5| Step: 8
Training loss: 3.8864341133212976
Validation loss: 2.7558533353394803

Epoch: 5| Step: 9
Training loss: 2.8158187782594055
Validation loss: 2.7564495857560756

Epoch: 5| Step: 10
Training loss: 2.447744701648986
Validation loss: 2.758195554571667

Epoch: 48| Step: 0
Training loss: 3.284635849601862
Validation loss: 2.7568827995589285

Epoch: 5| Step: 1
Training loss: 3.4003586523841496
Validation loss: 2.7608244152292833

Epoch: 5| Step: 2
Training loss: 2.810316382547244
Validation loss: 2.758960370534717

Epoch: 5| Step: 3
Training loss: 2.9486143187532745
Validation loss: 2.7586028635036404

Epoch: 5| Step: 4
Training loss: 3.317439013957623
Validation loss: 2.7542726934887716

Epoch: 5| Step: 5
Training loss: 1.9212731139977357
Validation loss: 2.7537502789523884

Epoch: 5| Step: 6
Training loss: 3.0494683599674195
Validation loss: 2.75281664930006

Epoch: 5| Step: 7
Training loss: 3.1024050396965372
Validation loss: 2.7513183200675964

Epoch: 5| Step: 8
Training loss: 3.5039389108009575
Validation loss: 2.752133976178809

Epoch: 5| Step: 9
Training loss: 2.891920304694798
Validation loss: 2.755965679230639

Epoch: 5| Step: 10
Training loss: 3.5083079508560178
Validation loss: 2.7618705145160165

Epoch: 49| Step: 0
Training loss: 2.7496062777177026
Validation loss: 2.7595810080183423

Epoch: 5| Step: 1
Training loss: 3.0089510261503087
Validation loss: 2.7609784601540106

Epoch: 5| Step: 2
Training loss: 3.4013342427255373
Validation loss: 2.758301186015652

Epoch: 5| Step: 3
Training loss: 3.0117228665057794
Validation loss: 2.751439293083087

Epoch: 5| Step: 4
Training loss: 2.9342805792391764
Validation loss: 2.766255003790497

Epoch: 5| Step: 5
Training loss: 2.9983495304786243
Validation loss: 2.7618679544669074

Epoch: 5| Step: 6
Training loss: 3.4262725582166516
Validation loss: 2.7577324377206693

Epoch: 5| Step: 7
Training loss: 2.9630071407132936
Validation loss: 2.748118658507399

Epoch: 5| Step: 8
Training loss: 3.064067050399397
Validation loss: 2.7463425994241932

Epoch: 5| Step: 9
Training loss: 3.297120288564799
Validation loss: 2.743177940622587

Epoch: 5| Step: 10
Training loss: 2.8876465995531952
Validation loss: 2.7430749660843783

Epoch: 50| Step: 0
Training loss: 2.6769583013605014
Validation loss: 2.7439769376227896

Epoch: 5| Step: 1
Training loss: 3.2233690617924142
Validation loss: 2.7434364085261524

Epoch: 5| Step: 2
Training loss: 3.3215941345390907
Validation loss: 2.7452909044343445

Epoch: 5| Step: 3
Training loss: 3.1406161939203345
Validation loss: 2.746778992060458

Epoch: 5| Step: 4
Training loss: 3.2746840404656403
Validation loss: 2.744490768310469

Epoch: 5| Step: 5
Training loss: 2.0941708269949513
Validation loss: 2.7460285363927226

Epoch: 5| Step: 6
Training loss: 3.3829301985424483
Validation loss: 2.746207578361293

Epoch: 5| Step: 7
Training loss: 2.7331262843479895
Validation loss: 2.7461874945312337

Epoch: 5| Step: 8
Training loss: 3.3233839481775793
Validation loss: 2.7511836270652417

Epoch: 5| Step: 9
Training loss: 3.208964166095831
Validation loss: 2.7457348515164366

Epoch: 5| Step: 10
Training loss: 3.263927547866179
Validation loss: 2.746085222858521

Epoch: 51| Step: 0
Training loss: 2.8884176538320685
Validation loss: 2.745509661751613

Epoch: 5| Step: 1
Training loss: 2.8645309905847602
Validation loss: 2.7423247952806373

Epoch: 5| Step: 2
Training loss: 3.3450247928173846
Validation loss: 2.7384523898777258

Epoch: 5| Step: 3
Training loss: 3.04473457469959
Validation loss: 2.7366117399371057

Epoch: 5| Step: 4
Training loss: 2.6628542310732715
Validation loss: 2.738315332033357

Epoch: 5| Step: 5
Training loss: 3.0590921241977354
Validation loss: 2.735117667931311

Epoch: 5| Step: 6
Training loss: 3.2635155394371056
Validation loss: 2.734990086439374

Epoch: 5| Step: 7
Training loss: 3.165802051228642
Validation loss: 2.736105547233146

Epoch: 5| Step: 8
Training loss: 3.1201451546575223
Validation loss: 2.7349189322770893

Epoch: 5| Step: 9
Training loss: 3.612183506179055
Validation loss: 2.732932808021246

Epoch: 5| Step: 10
Training loss: 2.453347943131165
Validation loss: 2.7342270415278587

Epoch: 52| Step: 0
Training loss: 2.1902861154811895
Validation loss: 2.735232910955008

Epoch: 5| Step: 1
Training loss: 3.2314463454308564
Validation loss: 2.7486798911171237

Epoch: 5| Step: 2
Training loss: 3.4999986376078542
Validation loss: 2.7445621983369555

Epoch: 5| Step: 3
Training loss: 3.550363312518721
Validation loss: 2.7342020503370246

Epoch: 5| Step: 4
Training loss: 3.0937590936084
Validation loss: 2.729776950307879

Epoch: 5| Step: 5
Training loss: 2.914493477785748
Validation loss: 2.7289228517509936

Epoch: 5| Step: 6
Training loss: 2.951333607673273
Validation loss: 2.7289903557651254

Epoch: 5| Step: 7
Training loss: 3.213781280899489
Validation loss: 2.7280226558452663

Epoch: 5| Step: 8
Training loss: 2.518916659840335
Validation loss: 2.7310807492881946

Epoch: 5| Step: 9
Training loss: 3.1393253806869392
Validation loss: 2.7271741989568805

Epoch: 5| Step: 10
Training loss: 3.260001419160686
Validation loss: 2.7312321671965116

Epoch: 53| Step: 0
Training loss: 3.037099640760124
Validation loss: 2.7358401094059324

Epoch: 5| Step: 1
Training loss: 2.5570980912938275
Validation loss: 2.732687503196217

Epoch: 5| Step: 2
Training loss: 3.31668876819499
Validation loss: 2.7371642875165496

Epoch: 5| Step: 3
Training loss: 3.079285688427131
Validation loss: 2.733190545174947

Epoch: 5| Step: 4
Training loss: 2.9269938788993493
Validation loss: 2.729342222888373

Epoch: 5| Step: 5
Training loss: 2.9812807349454093
Validation loss: 2.7277413658777396

Epoch: 5| Step: 6
Training loss: 3.3304429556384414
Validation loss: 2.727945219909727

Epoch: 5| Step: 7
Training loss: 3.0103070900233946
Validation loss: 2.724342629817914

Epoch: 5| Step: 8
Training loss: 3.10309630166543
Validation loss: 2.7254002111169346

Epoch: 5| Step: 9
Training loss: 2.871269127296706
Validation loss: 2.7220788292987037

Epoch: 5| Step: 10
Training loss: 3.3447814491390737
Validation loss: 2.721164401225119

Epoch: 54| Step: 0
Training loss: 3.0656693854895587
Validation loss: 2.722386758646771

Epoch: 5| Step: 1
Training loss: 2.1918135483793724
Validation loss: 2.7189698545892034

Epoch: 5| Step: 2
Training loss: 2.773477129585925
Validation loss: 2.7168942630244524

Epoch: 5| Step: 3
Training loss: 3.2270913787472253
Validation loss: 2.720242586700725

Epoch: 5| Step: 4
Training loss: 3.378169231848634
Validation loss: 2.718502457263578

Epoch: 5| Step: 5
Training loss: 2.890516619325881
Validation loss: 2.719758611983527

Epoch: 5| Step: 6
Training loss: 3.4179677734373604
Validation loss: 2.719392241651833

Epoch: 5| Step: 7
Training loss: 2.7917940670568817
Validation loss: 2.722625384327414

Epoch: 5| Step: 8
Training loss: 3.156953940876308
Validation loss: 2.72198878795522

Epoch: 5| Step: 9
Training loss: 3.6766099634118223
Validation loss: 2.718340295820043

Epoch: 5| Step: 10
Training loss: 2.6716929591220366
Validation loss: 2.715958016581621

Epoch: 55| Step: 0
Training loss: 2.6075479655549345
Validation loss: 2.7164649889525547

Epoch: 5| Step: 1
Training loss: 2.792520724555202
Validation loss: 2.7160656069008438

Epoch: 5| Step: 2
Training loss: 3.8418198368101932
Validation loss: 2.7148636738189267

Epoch: 5| Step: 3
Training loss: 3.052864174453815
Validation loss: 2.713002017531339

Epoch: 5| Step: 4
Training loss: 3.201343171038507
Validation loss: 2.7130301805582846

Epoch: 5| Step: 5
Training loss: 2.902368229676794
Validation loss: 2.7134003964506594

Epoch: 5| Step: 6
Training loss: 2.9079811108800815
Validation loss: 2.7152906216350665

Epoch: 5| Step: 7
Training loss: 2.7291505439417962
Validation loss: 2.7256094369320465

Epoch: 5| Step: 8
Training loss: 3.2938956588590047
Validation loss: 2.7381348377320354

Epoch: 5| Step: 9
Training loss: 3.2315829845163235
Validation loss: 2.730644150844429

Epoch: 5| Step: 10
Training loss: 2.7512830862077573
Validation loss: 2.7243694560719294

Epoch: 56| Step: 0
Training loss: 2.466592062861537
Validation loss: 2.716944488093689

Epoch: 5| Step: 1
Training loss: 3.153761231851856
Validation loss: 2.714055370286709

Epoch: 5| Step: 2
Training loss: 3.1549822083468793
Validation loss: 2.7086993258091607

Epoch: 5| Step: 3
Training loss: 2.5371540115576425
Validation loss: 2.7102659620185388

Epoch: 5| Step: 4
Training loss: 3.430758715202583
Validation loss: 2.7098406482130475

Epoch: 5| Step: 5
Training loss: 2.944400717052719
Validation loss: 2.71046989701219

Epoch: 5| Step: 6
Training loss: 3.1698301141024117
Validation loss: 2.714794658914355

Epoch: 5| Step: 7
Training loss: 3.280198282900972
Validation loss: 2.710006492059656

Epoch: 5| Step: 8
Training loss: 2.5587482434869133
Validation loss: 2.710430922908241

Epoch: 5| Step: 9
Training loss: 3.3832018057777997
Validation loss: 2.7097050940498892

Epoch: 5| Step: 10
Training loss: 3.259860851617998
Validation loss: 2.7058919638751617

Epoch: 57| Step: 0
Training loss: 2.5871313744723703
Validation loss: 2.708139521161528

Epoch: 5| Step: 1
Training loss: 3.6999298346800007
Validation loss: 2.7135809280124636

Epoch: 5| Step: 2
Training loss: 2.6680733030506603
Validation loss: 2.7177204327374564

Epoch: 5| Step: 3
Training loss: 3.0204332985676396
Validation loss: 2.7180087416012837

Epoch: 5| Step: 4
Training loss: 2.9755300097816737
Validation loss: 2.7156140486809837

Epoch: 5| Step: 5
Training loss: 2.759011675199864
Validation loss: 2.7107267747938595

Epoch: 5| Step: 6
Training loss: 3.8686454105567845
Validation loss: 2.704166632512179

Epoch: 5| Step: 7
Training loss: 3.281077643817766
Validation loss: 2.704869220847559

Epoch: 5| Step: 8
Training loss: 3.0285963260521793
Validation loss: 2.7033019635356323

Epoch: 5| Step: 9
Training loss: 2.8857253330726076
Validation loss: 2.703608764364226

Epoch: 5| Step: 10
Training loss: 2.188161586443618
Validation loss: 2.7058433574863736

Epoch: 58| Step: 0
Training loss: 2.6245758077204004
Validation loss: 2.7080067597818624

Epoch: 5| Step: 1
Training loss: 2.780152007688078
Validation loss: 2.7091211111944684

Epoch: 5| Step: 2
Training loss: 2.9602278611397743
Validation loss: 2.7117115880315286

Epoch: 5| Step: 3
Training loss: 2.9475215651586324
Validation loss: 2.716574271071731

Epoch: 5| Step: 4
Training loss: 2.9480199537391267
Validation loss: 2.7343264527120366

Epoch: 5| Step: 5
Training loss: 3.091470668643092
Validation loss: 2.7152187567349713

Epoch: 5| Step: 6
Training loss: 3.5611498767278866
Validation loss: 2.7011305610313046

Epoch: 5| Step: 7
Training loss: 3.1760324376465223
Validation loss: 2.698799000106523

Epoch: 5| Step: 8
Training loss: 3.288787177878708
Validation loss: 2.6951192369528005

Epoch: 5| Step: 9
Training loss: 2.9205263666714005
Validation loss: 2.6962635656371887

Epoch: 5| Step: 10
Training loss: 2.9900034610383788
Validation loss: 2.697239914959042

Epoch: 59| Step: 0
Training loss: 2.7751237068439587
Validation loss: 2.6966395761859676

Epoch: 5| Step: 1
Training loss: 2.362840847879096
Validation loss: 2.6940127341472415

Epoch: 5| Step: 2
Training loss: 2.900421697276741
Validation loss: 2.69249030322402

Epoch: 5| Step: 3
Training loss: 2.9642714600212123
Validation loss: 2.697486088282827

Epoch: 5| Step: 4
Training loss: 3.6392010044521674
Validation loss: 2.6985002834231584

Epoch: 5| Step: 5
Training loss: 3.082991108503212
Validation loss: 2.7077093789223814

Epoch: 5| Step: 6
Training loss: 2.8021434413508817
Validation loss: 2.6951129570172183

Epoch: 5| Step: 7
Training loss: 3.6007026092688506
Validation loss: 2.691913179735161

Epoch: 5| Step: 8
Training loss: 2.5587095744000936
Validation loss: 2.6884578591856276

Epoch: 5| Step: 9
Training loss: 3.115963497158624
Validation loss: 2.6891755425295245

Epoch: 5| Step: 10
Training loss: 3.331594172406696
Validation loss: 2.687465887861974

Epoch: 60| Step: 0
Training loss: 3.127378550366111
Validation loss: 2.689800023251119

Epoch: 5| Step: 1
Training loss: 2.747362606094739
Validation loss: 2.693494389774867

Epoch: 5| Step: 2
Training loss: 2.896510056570234
Validation loss: 2.6972770704040965

Epoch: 5| Step: 3
Training loss: 2.572288611562061
Validation loss: 2.7155752555559745

Epoch: 5| Step: 4
Training loss: 3.218891325875705
Validation loss: 2.715425372047398

Epoch: 5| Step: 5
Training loss: 3.792711274731648
Validation loss: 2.719498612955277

Epoch: 5| Step: 6
Training loss: 2.593212945328975
Validation loss: 2.7090834841624303

Epoch: 5| Step: 7
Training loss: 3.1223832427919804
Validation loss: 2.704092344532476

Epoch: 5| Step: 8
Training loss: 3.064837128386296
Validation loss: 2.698827375939798

Epoch: 5| Step: 9
Training loss: 3.231932229011364
Validation loss: 2.6922593382191913

Epoch: 5| Step: 10
Training loss: 2.848142982611978
Validation loss: 2.690225638935929

Epoch: 61| Step: 0
Training loss: 3.050308874780943
Validation loss: 2.6871559178449864

Epoch: 5| Step: 1
Training loss: 2.7988478878838197
Validation loss: 2.7082599210294727

Epoch: 5| Step: 2
Training loss: 2.8001930544920537
Validation loss: 2.722995585489962

Epoch: 5| Step: 3
Training loss: 2.0932653065377758
Validation loss: 2.743276183573574

Epoch: 5| Step: 4
Training loss: 3.3137681081213053
Validation loss: 2.762530722832621

Epoch: 5| Step: 5
Training loss: 2.8895990974053105
Validation loss: 2.7215645035790934

Epoch: 5| Step: 6
Training loss: 3.040638179299627
Validation loss: 2.694709127956408

Epoch: 5| Step: 7
Training loss: 3.387908972795281
Validation loss: 2.6851828273459053

Epoch: 5| Step: 8
Training loss: 3.0154012488336086
Validation loss: 2.685752585787352

Epoch: 5| Step: 9
Training loss: 3.463698962471264
Validation loss: 2.686136030767373

Epoch: 5| Step: 10
Training loss: 3.2964474369153383
Validation loss: 2.685782734556612

Epoch: 62| Step: 0
Training loss: 3.024421787960346
Validation loss: 2.6898856710064574

Epoch: 5| Step: 1
Training loss: 2.943573051042513
Validation loss: 2.6879883341825423

Epoch: 5| Step: 2
Training loss: 2.8442261684962036
Validation loss: 2.684569409113548

Epoch: 5| Step: 3
Training loss: 2.4971353330713946
Validation loss: 2.6852264278742743

Epoch: 5| Step: 4
Training loss: 3.426675294897396
Validation loss: 2.684387252118589

Epoch: 5| Step: 5
Training loss: 3.1002737293601106
Validation loss: 2.6830376325000365

Epoch: 5| Step: 6
Training loss: 2.8106732687984186
Validation loss: 2.6798387241615647

Epoch: 5| Step: 7
Training loss: 3.3508731159719045
Validation loss: 2.687544812541653

Epoch: 5| Step: 8
Training loss: 2.889777641849964
Validation loss: 2.6831927571523577

Epoch: 5| Step: 9
Training loss: 3.0564465543422776
Validation loss: 2.679605096775608

Epoch: 5| Step: 10
Training loss: 3.2729236864143787
Validation loss: 2.6790824663202386

Epoch: 63| Step: 0
Training loss: 2.7620580052079466
Validation loss: 2.673587332175283

Epoch: 5| Step: 1
Training loss: 3.508076477313274
Validation loss: 2.673790012811495

Epoch: 5| Step: 2
Training loss: 2.7267476978091176
Validation loss: 2.673877594289887

Epoch: 5| Step: 3
Training loss: 3.3184694448159013
Validation loss: 2.6745190589539227

Epoch: 5| Step: 4
Training loss: 2.793963147252803
Validation loss: 2.6724530203898222

Epoch: 5| Step: 5
Training loss: 2.2569279505461175
Validation loss: 2.670849979434445

Epoch: 5| Step: 6
Training loss: 3.0777524151390154
Validation loss: 2.6722030855595293

Epoch: 5| Step: 7
Training loss: 3.2483466417781472
Validation loss: 2.673374796374927

Epoch: 5| Step: 8
Training loss: 3.0733298503445012
Validation loss: 2.6783403152751664

Epoch: 5| Step: 9
Training loss: 3.1120633719103687
Validation loss: 2.677754780768704

Epoch: 5| Step: 10
Training loss: 3.035221290627926
Validation loss: 2.6773617504185556

Epoch: 64| Step: 0
Training loss: 3.108771030675465
Validation loss: 2.676831155299026

Epoch: 5| Step: 1
Training loss: 3.1441236148828597
Validation loss: 2.7015992320227094

Epoch: 5| Step: 2
Training loss: 3.0909224410457243
Validation loss: 2.7187019073264755

Epoch: 5| Step: 3
Training loss: 2.198126350513051
Validation loss: 2.768468112087093

Epoch: 5| Step: 4
Training loss: 2.7341396557482227
Validation loss: 2.84111323871385

Epoch: 5| Step: 5
Training loss: 2.9028953962412345
Validation loss: 2.875589370061587

Epoch: 5| Step: 6
Training loss: 3.2740151708178016
Validation loss: 2.8704626116701504

Epoch: 5| Step: 7
Training loss: 3.5203172354363677
Validation loss: 2.723322719113436

Epoch: 5| Step: 8
Training loss: 3.2459434722378298
Validation loss: 2.664629323945487

Epoch: 5| Step: 9
Training loss: 3.007023061224317
Validation loss: 2.6891415450723817

Epoch: 5| Step: 10
Training loss: 3.3623517709272357
Validation loss: 2.74875966307097

Epoch: 65| Step: 0
Training loss: 2.7865235127939467
Validation loss: 2.7361551395106214

Epoch: 5| Step: 1
Training loss: 3.0066094705028914
Validation loss: 2.690262609187515

Epoch: 5| Step: 2
Training loss: 3.4556873877653413
Validation loss: 2.6804693664668093

Epoch: 5| Step: 3
Training loss: 2.9908138139806466
Validation loss: 2.6733343896282493

Epoch: 5| Step: 4
Training loss: 3.291715372103485
Validation loss: 2.6667454410526013

Epoch: 5| Step: 5
Training loss: 2.9462456881750936
Validation loss: 2.666416357069978

Epoch: 5| Step: 6
Training loss: 3.1332573705623203
Validation loss: 2.663914462585796

Epoch: 5| Step: 7
Training loss: 3.0973294291357405
Validation loss: 2.664448070594243

Epoch: 5| Step: 8
Training loss: 3.1660803871190946
Validation loss: 2.6693041343422506

Epoch: 5| Step: 9
Training loss: 2.511483236279323
Validation loss: 2.6757553699338565

Epoch: 5| Step: 10
Training loss: 2.735111333613896
Validation loss: 2.6965601770964662

Epoch: 66| Step: 0
Training loss: 3.2412628693772
Validation loss: 2.6980777099628774

Epoch: 5| Step: 1
Training loss: 2.8906579917880775
Validation loss: 2.728149726835587

Epoch: 5| Step: 2
Training loss: 2.9029648784913666
Validation loss: 2.7307579247351024

Epoch: 5| Step: 3
Training loss: 2.799659664042498
Validation loss: 2.6998597961326367

Epoch: 5| Step: 4
Training loss: 2.7259605639565545
Validation loss: 2.6786584776500604

Epoch: 5| Step: 5
Training loss: 2.769132986339355
Validation loss: 2.6679018804058208

Epoch: 5| Step: 6
Training loss: 3.166802470323554
Validation loss: 2.668995590765667

Epoch: 5| Step: 7
Training loss: 3.438260219780961
Validation loss: 2.6683834385857224

Epoch: 5| Step: 8
Training loss: 2.410518476819334
Validation loss: 2.665397177153378

Epoch: 5| Step: 9
Training loss: 3.2727647331290233
Validation loss: 2.6681494019504086

Epoch: 5| Step: 10
Training loss: 3.369018906315796
Validation loss: 2.6700357476358123

Epoch: 67| Step: 0
Training loss: 2.6593980871110627
Validation loss: 2.6711374754663013

Epoch: 5| Step: 1
Training loss: 2.841365611069192
Validation loss: 2.668228849960599

Epoch: 5| Step: 2
Training loss: 3.284647027826903
Validation loss: 2.669318452175727

Epoch: 5| Step: 3
Training loss: 3.2832741443185167
Validation loss: 2.6709172647354826

Epoch: 5| Step: 4
Training loss: 3.199584492887166
Validation loss: 2.6681410417468534

Epoch: 5| Step: 5
Training loss: 3.3614372133754533
Validation loss: 2.6691690782810262

Epoch: 5| Step: 6
Training loss: 3.155191678422706
Validation loss: 2.6723111471975405

Epoch: 5| Step: 7
Training loss: 2.518050262713061
Validation loss: 2.6707086719047486

Epoch: 5| Step: 8
Training loss: 2.79524174745169
Validation loss: 2.675203000971085

Epoch: 5| Step: 9
Training loss: 2.601958923379198
Validation loss: 2.675137436320232

Epoch: 5| Step: 10
Training loss: 3.3668134795807476
Validation loss: 2.6707626547919503

Epoch: 68| Step: 0
Training loss: 3.315903408719046
Validation loss: 2.674316407687923

Epoch: 5| Step: 1
Training loss: 3.397995492538148
Validation loss: 2.668150716366881

Epoch: 5| Step: 2
Training loss: 3.0212173393229724
Validation loss: 2.6634749335747623

Epoch: 5| Step: 3
Training loss: 2.744992812795211
Validation loss: 2.6621387707487543

Epoch: 5| Step: 4
Training loss: 2.960011360043558
Validation loss: 2.659520568253044

Epoch: 5| Step: 5
Training loss: 2.8458515827567505
Validation loss: 2.6599525334023464

Epoch: 5| Step: 6
Training loss: 2.9099201285815597
Validation loss: 2.6570854267866735

Epoch: 5| Step: 7
Training loss: 3.294149130682796
Validation loss: 2.6611614762902116

Epoch: 5| Step: 8
Training loss: 2.661475483241258
Validation loss: 2.6616638276361533

Epoch: 5| Step: 9
Training loss: 2.7547722935946783
Validation loss: 2.669427663946493

Epoch: 5| Step: 10
Training loss: 2.9615661436877447
Validation loss: 2.67962739790297

Epoch: 69| Step: 0
Training loss: 3.1174574809168942
Validation loss: 2.7037046504400264

Epoch: 5| Step: 1
Training loss: 2.899128875120612
Validation loss: 2.7048313043517584

Epoch: 5| Step: 2
Training loss: 2.822702847837069
Validation loss: 2.7120792218493692

Epoch: 5| Step: 3
Training loss: 2.453158724607704
Validation loss: 2.6834663470372573

Epoch: 5| Step: 4
Training loss: 3.0597606006796805
Validation loss: 2.684384247627361

Epoch: 5| Step: 5
Training loss: 2.965976262569293
Validation loss: 2.696059382368458

Epoch: 5| Step: 6
Training loss: 3.0714446254323335
Validation loss: 2.7230605881261427

Epoch: 5| Step: 7
Training loss: 3.4192676103532667
Validation loss: 2.720395024395347

Epoch: 5| Step: 8
Training loss: 2.844793945520178
Validation loss: 2.7172650525305078

Epoch: 5| Step: 9
Training loss: 2.892990546539716
Validation loss: 2.7209588171641403

Epoch: 5| Step: 10
Training loss: 3.583881262353557
Validation loss: 2.709378784879511

Epoch: 70| Step: 0
Training loss: 3.096248966073644
Validation loss: 2.6920501487877133

Epoch: 5| Step: 1
Training loss: 2.9802276393812166
Validation loss: 2.6848422963046086

Epoch: 5| Step: 2
Training loss: 3.0977212098130433
Validation loss: 2.6840720343891116

Epoch: 5| Step: 3
Training loss: 2.5449598167559713
Validation loss: 2.6771357046675153

Epoch: 5| Step: 4
Training loss: 2.660534533521194
Validation loss: 2.680718741944584

Epoch: 5| Step: 5
Training loss: 3.2521104562635585
Validation loss: 2.6772337387223093

Epoch: 5| Step: 6
Training loss: 3.1255353850462595
Validation loss: 2.6759762909586313

Epoch: 5| Step: 7
Training loss: 2.948503379712457
Validation loss: 2.6776505483011923

Epoch: 5| Step: 8
Training loss: 3.042816275815334
Validation loss: 2.674552847369552

Epoch: 5| Step: 9
Training loss: 3.205773723839072
Validation loss: 2.6702443267883877

Epoch: 5| Step: 10
Training loss: 3.2004715512451583
Validation loss: 2.664656591652284

Epoch: 71| Step: 0
Training loss: 3.2073379723052744
Validation loss: 2.6662790903827744

Epoch: 5| Step: 1
Training loss: 2.565479871987262
Validation loss: 2.6524907852963366

Epoch: 5| Step: 2
Training loss: 3.500020980772076
Validation loss: 2.6442739361177416

Epoch: 5| Step: 3
Training loss: 2.997591164215154
Validation loss: 2.647287688172698

Epoch: 5| Step: 4
Training loss: 2.8384222069663982
Validation loss: 2.649464284690881

Epoch: 5| Step: 5
Training loss: 3.220584383707871
Validation loss: 2.6480430158956545

Epoch: 5| Step: 6
Training loss: 2.838677713942753
Validation loss: 2.6453947524608137

Epoch: 5| Step: 7
Training loss: 2.8231955715409547
Validation loss: 2.6467192909559603

Epoch: 5| Step: 8
Training loss: 2.8413394310735285
Validation loss: 2.6438119511446523

Epoch: 5| Step: 9
Training loss: 3.10243101475181
Validation loss: 2.6391337883576615

Epoch: 5| Step: 10
Training loss: 3.0075418722102847
Validation loss: 2.634338215316024

Epoch: 72| Step: 0
Training loss: 2.4702763727913504
Validation loss: 2.632063172753309

Epoch: 5| Step: 1
Training loss: 3.082784621068663
Validation loss: 2.6297424631594177

Epoch: 5| Step: 2
Training loss: 3.1122035670543218
Validation loss: 2.6288880044339056

Epoch: 5| Step: 3
Training loss: 2.659474110353424
Validation loss: 2.6293322114116293

Epoch: 5| Step: 4
Training loss: 2.7451742485898505
Validation loss: 2.639421535729551

Epoch: 5| Step: 5
Training loss: 3.0936348633582544
Validation loss: 2.6530967415701316

Epoch: 5| Step: 6
Training loss: 2.934566737726608
Validation loss: 2.6855049984706993

Epoch: 5| Step: 7
Training loss: 3.6206263762144992
Validation loss: 2.714678639853122

Epoch: 5| Step: 8
Training loss: 2.585724144745949
Validation loss: 2.689214349936602

Epoch: 5| Step: 9
Training loss: 3.060921086826688
Validation loss: 2.6619774478898757

Epoch: 5| Step: 10
Training loss: 3.382191519531749
Validation loss: 2.637762967295156

Epoch: 73| Step: 0
Training loss: 2.707907442694577
Validation loss: 2.6263125800798366

Epoch: 5| Step: 1
Training loss: 3.148687537324502
Validation loss: 2.6239390614654505

Epoch: 5| Step: 2
Training loss: 2.8876647637989312
Validation loss: 2.6219540359998637

Epoch: 5| Step: 3
Training loss: 2.6153596330977145
Validation loss: 2.625086701382771

Epoch: 5| Step: 4
Training loss: 2.6167197649320486
Validation loss: 2.6222552908589205

Epoch: 5| Step: 5
Training loss: 3.1633765713383357
Validation loss: 2.623994329921162

Epoch: 5| Step: 6
Training loss: 3.101385385371149
Validation loss: 2.6262746607918515

Epoch: 5| Step: 7
Training loss: 3.6763087997740866
Validation loss: 2.624979051310074

Epoch: 5| Step: 8
Training loss: 2.504020795418916
Validation loss: 2.624319274424963

Epoch: 5| Step: 9
Training loss: 2.8262764806574014
Validation loss: 2.624000146968574

Epoch: 5| Step: 10
Training loss: 3.389358494919072
Validation loss: 2.6199236028273214

Epoch: 74| Step: 0
Training loss: 2.6984164291822643
Validation loss: 2.6212906399866704

Epoch: 5| Step: 1
Training loss: 2.887023661903319
Validation loss: 2.6199545198782994

Epoch: 5| Step: 2
Training loss: 2.869857168863589
Validation loss: 2.619720096589498

Epoch: 5| Step: 3
Training loss: 3.172864637409579
Validation loss: 2.6170021252281255

Epoch: 5| Step: 4
Training loss: 2.9552941807480324
Validation loss: 2.6171106176910315

Epoch: 5| Step: 5
Training loss: 2.967988408428496
Validation loss: 2.6146759093947574

Epoch: 5| Step: 6
Training loss: 3.3129286578666703
Validation loss: 2.614307926545639

Epoch: 5| Step: 7
Training loss: 3.1660439397638855
Validation loss: 2.6129426588911033

Epoch: 5| Step: 8
Training loss: 3.166669209797156
Validation loss: 2.6152680216344915

Epoch: 5| Step: 9
Training loss: 2.6309084020406295
Validation loss: 2.629408845567267

Epoch: 5| Step: 10
Training loss: 2.817302079919987
Validation loss: 2.6417188937437435

Epoch: 75| Step: 0
Training loss: 3.4430378089178304
Validation loss: 2.658103218216498

Epoch: 5| Step: 1
Training loss: 2.9775674079804446
Validation loss: 2.631266162738786

Epoch: 5| Step: 2
Training loss: 2.4298582354350478
Validation loss: 2.6149819565412487

Epoch: 5| Step: 3
Training loss: 2.959221737849701
Validation loss: 2.6116004655983462

Epoch: 5| Step: 4
Training loss: 2.987156395724792
Validation loss: 2.6128991522099563

Epoch: 5| Step: 5
Training loss: 3.079525546649721
Validation loss: 2.6123205258020894

Epoch: 5| Step: 6
Training loss: 3.136149847712888
Validation loss: 2.6138871423099994

Epoch: 5| Step: 7
Training loss: 2.7487046051787307
Validation loss: 2.6149963531832623

Epoch: 5| Step: 8
Training loss: 2.423787008301036
Validation loss: 2.614815337951093

Epoch: 5| Step: 9
Training loss: 3.3821215904120807
Validation loss: 2.638118653689126

Epoch: 5| Step: 10
Training loss: 3.070118206370306
Validation loss: 2.617353200648896

Epoch: 76| Step: 0
Training loss: 2.8910700275037726
Validation loss: 2.617298206283109

Epoch: 5| Step: 1
Training loss: 3.153720862170471
Validation loss: 2.6224523712697145

Epoch: 5| Step: 2
Training loss: 2.822211727696862
Validation loss: 2.6309313225240287

Epoch: 5| Step: 3
Training loss: 2.555005814905884
Validation loss: 2.635878721879583

Epoch: 5| Step: 4
Training loss: 3.08096461338224
Validation loss: 2.6407134367789893

Epoch: 5| Step: 5
Training loss: 3.293012770316682
Validation loss: 2.6640012610935466

Epoch: 5| Step: 6
Training loss: 2.8272260217117835
Validation loss: 2.6425862187705738

Epoch: 5| Step: 7
Training loss: 1.8852664894725426
Validation loss: 2.6323688793401816

Epoch: 5| Step: 8
Training loss: 2.9052417605941163
Validation loss: 2.6283134266579258

Epoch: 5| Step: 9
Training loss: 3.5578482524296753
Validation loss: 2.6246962032129844

Epoch: 5| Step: 10
Training loss: 3.4264587637127386
Validation loss: 2.622956013390287

Epoch: 77| Step: 0
Training loss: 2.257162878437474
Validation loss: 2.6262963429683532

Epoch: 5| Step: 1
Training loss: 2.576106905750605
Validation loss: 2.616166250467815

Epoch: 5| Step: 2
Training loss: 2.904416890541036
Validation loss: 2.6174845013175925

Epoch: 5| Step: 3
Training loss: 3.434148090561931
Validation loss: 2.615909548108491

Epoch: 5| Step: 4
Training loss: 2.7164851434204142
Validation loss: 2.614080691503682

Epoch: 5| Step: 5
Training loss: 3.2039085360269826
Validation loss: 2.6092229843930372

Epoch: 5| Step: 6
Training loss: 2.72015695231265
Validation loss: 2.6140373361606635

Epoch: 5| Step: 7
Training loss: 2.9802373993802975
Validation loss: 2.613724733818264

Epoch: 5| Step: 8
Training loss: 2.850624578200336
Validation loss: 2.6090619731678104

Epoch: 5| Step: 9
Training loss: 3.431933386727525
Validation loss: 2.612323309933874

Epoch: 5| Step: 10
Training loss: 3.3799630866207613
Validation loss: 2.608180497188133

Epoch: 78| Step: 0
Training loss: 3.569093992954233
Validation loss: 2.606158776726747

Epoch: 5| Step: 1
Training loss: 2.5375192500544648
Validation loss: 2.604776610449483

Epoch: 5| Step: 2
Training loss: 2.840250565932998
Validation loss: 2.6093057288351065

Epoch: 5| Step: 3
Training loss: 3.0011522941144224
Validation loss: 2.6047510386450976

Epoch: 5| Step: 4
Training loss: 2.9667878744103104
Validation loss: 2.6058705281427157

Epoch: 5| Step: 5
Training loss: 2.3949372536995024
Validation loss: 2.6044092182700864

Epoch: 5| Step: 6
Training loss: 2.613004798122691
Validation loss: 2.6010868852656914

Epoch: 5| Step: 7
Training loss: 2.808462678400195
Validation loss: 2.5999009386837355

Epoch: 5| Step: 8
Training loss: 3.443625385224445
Validation loss: 2.599319677189333

Epoch: 5| Step: 9
Training loss: 3.1126719109425744
Validation loss: 2.601021901636435

Epoch: 5| Step: 10
Training loss: 3.046695645261994
Validation loss: 2.615561582997395

Epoch: 79| Step: 0
Training loss: 2.9066275074563737
Validation loss: 2.623197953661763

Epoch: 5| Step: 1
Training loss: 2.8247734147747345
Validation loss: 2.629615862353919

Epoch: 5| Step: 2
Training loss: 2.9550902271212034
Validation loss: 2.61426776987961

Epoch: 5| Step: 3
Training loss: 2.5948643875702584
Validation loss: 2.6015261346650944

Epoch: 5| Step: 4
Training loss: 3.2931057323414143
Validation loss: 2.6020339676078796

Epoch: 5| Step: 5
Training loss: 2.6799233558000584
Validation loss: 2.6053210171385435

Epoch: 5| Step: 6
Training loss: 2.9270173378741404
Validation loss: 2.6093911940531624

Epoch: 5| Step: 7
Training loss: 2.9506331330106286
Validation loss: 2.611712496313037

Epoch: 5| Step: 8
Training loss: 2.402334123297531
Validation loss: 2.6147984774602175

Epoch: 5| Step: 9
Training loss: 3.6175801865259083
Validation loss: 2.612999122405144

Epoch: 5| Step: 10
Training loss: 3.180743817602312
Validation loss: 2.607515866119219

Epoch: 80| Step: 0
Training loss: 2.636274738367529
Validation loss: 2.608435998459762

Epoch: 5| Step: 1
Training loss: 3.282427767142605
Validation loss: 2.6074379464846658

Epoch: 5| Step: 2
Training loss: 3.050410327513125
Validation loss: 2.60245867201405

Epoch: 5| Step: 3
Training loss: 2.941507406129126
Validation loss: 2.6025653549270236

Epoch: 5| Step: 4
Training loss: 2.6900873371396714
Validation loss: 2.6070646123521355

Epoch: 5| Step: 5
Training loss: 3.1547385647605264
Validation loss: 2.6054980389568816

Epoch: 5| Step: 6
Training loss: 3.287734245976698
Validation loss: 2.6078831420941646

Epoch: 5| Step: 7
Training loss: 3.017093597325813
Validation loss: 2.6072483161218845

Epoch: 5| Step: 8
Training loss: 2.7544217540286313
Validation loss: 2.6124915564678752

Epoch: 5| Step: 9
Training loss: 3.3891778485729858
Validation loss: 2.6110122983858575

Epoch: 5| Step: 10
Training loss: 1.8942943936185908
Validation loss: 2.6110135276705

Epoch: 81| Step: 0
Training loss: 3.1368677239296594
Validation loss: 2.6102653960514974

Epoch: 5| Step: 1
Training loss: 2.8080533798393326
Validation loss: 2.6105323441852084

Epoch: 5| Step: 2
Training loss: 2.8507854918482076
Validation loss: 2.604268327923167

Epoch: 5| Step: 3
Training loss: 2.8395189941759735
Validation loss: 2.6098243680625535

Epoch: 5| Step: 4
Training loss: 2.894375074860653
Validation loss: 2.6069128278458664

Epoch: 5| Step: 5
Training loss: 2.738707505161536
Validation loss: 2.600894921036518

Epoch: 5| Step: 6
Training loss: 2.8472010872736178
Validation loss: 2.5984826161909185

Epoch: 5| Step: 7
Training loss: 2.894348056365495
Validation loss: 2.603557503281154

Epoch: 5| Step: 8
Training loss: 2.8636332838033653
Validation loss: 2.616605393396624

Epoch: 5| Step: 9
Training loss: 2.9962945942908163
Validation loss: 2.616963157044219

Epoch: 5| Step: 10
Training loss: 3.551137774103058
Validation loss: 2.612783003296908

Epoch: 82| Step: 0
Training loss: 2.657855098681254
Validation loss: 2.6130379505421724

Epoch: 5| Step: 1
Training loss: 3.0065219240669143
Validation loss: 2.609937530946795

Epoch: 5| Step: 2
Training loss: 3.041481291116858
Validation loss: 2.613125475088027

Epoch: 5| Step: 3
Training loss: 2.9735502284817237
Validation loss: 2.6101536509173693

Epoch: 5| Step: 4
Training loss: 3.2826661459950524
Validation loss: 2.6095106524238934

Epoch: 5| Step: 5
Training loss: 2.8651767925152827
Validation loss: 2.6011713176001727

Epoch: 5| Step: 6
Training loss: 2.804881054673349
Validation loss: 2.5922392858666683

Epoch: 5| Step: 7
Training loss: 3.090114885435166
Validation loss: 2.589189482813727

Epoch: 5| Step: 8
Training loss: 2.959452153361272
Validation loss: 2.5860721840684278

Epoch: 5| Step: 9
Training loss: 3.0722156479366416
Validation loss: 2.585281285339066

Epoch: 5| Step: 10
Training loss: 2.3789020406751553
Validation loss: 2.588532909049112

Epoch: 83| Step: 0
Training loss: 3.161694052307324
Validation loss: 2.586477238887962

Epoch: 5| Step: 1
Training loss: 2.2481837889657745
Validation loss: 2.585624607241648

Epoch: 5| Step: 2
Training loss: 2.883185137723749
Validation loss: 2.5848733166937117

Epoch: 5| Step: 3
Training loss: 3.4749904550105675
Validation loss: 2.5848000643405737

Epoch: 5| Step: 4
Training loss: 2.5995482932695304
Validation loss: 2.585699468193977

Epoch: 5| Step: 5
Training loss: 2.6827590288311214
Validation loss: 2.5903725188923903

Epoch: 5| Step: 6
Training loss: 3.131234930005995
Validation loss: 2.592977832638296

Epoch: 5| Step: 7
Training loss: 2.955529581241037
Validation loss: 2.593314519628849

Epoch: 5| Step: 8
Training loss: 2.7972820987330858
Validation loss: 2.6108990642567744

Epoch: 5| Step: 9
Training loss: 3.138724439996205
Validation loss: 2.6384496260283163

Epoch: 5| Step: 10
Training loss: 3.0865661753313676
Validation loss: 2.6111845712910777

Epoch: 84| Step: 0
Training loss: 2.9804297128423207
Validation loss: 2.6306523615413626

Epoch: 5| Step: 1
Training loss: 3.0402318278810156
Validation loss: 2.618080517961291

Epoch: 5| Step: 2
Training loss: 2.7108599297146863
Validation loss: 2.607352649285491

Epoch: 5| Step: 3
Training loss: 2.7329220644589363
Validation loss: 2.612905308906062

Epoch: 5| Step: 4
Training loss: 2.760884332927529
Validation loss: 2.6120259239452923

Epoch: 5| Step: 5
Training loss: 3.0785726618677387
Validation loss: 2.621501476128102

Epoch: 5| Step: 6
Training loss: 2.9116580646681154
Validation loss: 2.606142901961576

Epoch: 5| Step: 7
Training loss: 3.0749566672148445
Validation loss: 2.5989616115032432

Epoch: 5| Step: 8
Training loss: 2.748328481206858
Validation loss: 2.579532203201843

Epoch: 5| Step: 9
Training loss: 3.2206240633299323
Validation loss: 2.578353437170637

Epoch: 5| Step: 10
Training loss: 2.8043370785071713
Validation loss: 2.581626763726146

Epoch: 85| Step: 0
Training loss: 3.3198889608083535
Validation loss: 2.58875543472587

Epoch: 5| Step: 1
Training loss: 3.213462115539153
Validation loss: 2.608169855058948

Epoch: 5| Step: 2
Training loss: 2.993633667790077
Validation loss: 2.621826350202591

Epoch: 5| Step: 3
Training loss: 2.780623633327993
Validation loss: 2.6144025555696833

Epoch: 5| Step: 4
Training loss: 3.3148226961846863
Validation loss: 2.6119423440417564

Epoch: 5| Step: 5
Training loss: 2.6389373261763565
Validation loss: 2.5968231772527117

Epoch: 5| Step: 6
Training loss: 2.763216338340287
Validation loss: 2.5821261901761385

Epoch: 5| Step: 7
Training loss: 3.154488251257141
Validation loss: 2.5812610444729445

Epoch: 5| Step: 8
Training loss: 2.701815249267484
Validation loss: 2.5820045136572665

Epoch: 5| Step: 9
Training loss: 3.0947194747867717
Validation loss: 2.573928896609504

Epoch: 5| Step: 10
Training loss: 2.501432580570414
Validation loss: 2.574218381520397

Epoch: 86| Step: 0
Training loss: 2.67711202009889
Validation loss: 2.571064016031303

Epoch: 5| Step: 1
Training loss: 2.934762043965355
Validation loss: 2.576906765476858

Epoch: 5| Step: 2
Training loss: 2.843327752928123
Validation loss: 2.5984653231590915

Epoch: 5| Step: 3
Training loss: 3.737565596907501
Validation loss: 2.649530037620131

Epoch: 5| Step: 4
Training loss: 3.038733614112804
Validation loss: 2.652263789424732

Epoch: 5| Step: 5
Training loss: 2.7493574085266825
Validation loss: 2.6355265861512156

Epoch: 5| Step: 6
Training loss: 3.038243357431167
Validation loss: 2.607632181804664

Epoch: 5| Step: 7
Training loss: 2.4937528758402903
Validation loss: 2.5947772395051603

Epoch: 5| Step: 8
Training loss: 2.860801799395548
Validation loss: 2.57723099418023

Epoch: 5| Step: 9
Training loss: 3.2865357467956775
Validation loss: 2.581061803155583

Epoch: 5| Step: 10
Training loss: 2.332049448015784
Validation loss: 2.5899794553561986

Epoch: 87| Step: 0
Training loss: 2.771625969504461
Validation loss: 2.5979364172967934

Epoch: 5| Step: 1
Training loss: 3.4988976513725394
Validation loss: 2.611189939725289

Epoch: 5| Step: 2
Training loss: 2.8571885718366894
Validation loss: 2.618649304466458

Epoch: 5| Step: 3
Training loss: 2.4998125959727724
Validation loss: 2.6206842167375757

Epoch: 5| Step: 4
Training loss: 3.6953690183805508
Validation loss: 2.6211361758536613

Epoch: 5| Step: 5
Training loss: 3.1033137299614717
Validation loss: 2.6208996789328354

Epoch: 5| Step: 6
Training loss: 2.9262445589753954
Validation loss: 2.6332696621405245

Epoch: 5| Step: 7
Training loss: 2.944762646577434
Validation loss: 2.633842737245912

Epoch: 5| Step: 8
Training loss: 2.491863648231125
Validation loss: 2.644755630303556

Epoch: 5| Step: 9
Training loss: 2.375516534149176
Validation loss: 2.6331493237329804

Epoch: 5| Step: 10
Training loss: 2.8599622779972784
Validation loss: 2.632190219771452

Epoch: 88| Step: 0
Training loss: 2.5467012498248347
Validation loss: 2.638440447352647

Epoch: 5| Step: 1
Training loss: 3.143730791461726
Validation loss: 2.637013289067231

Epoch: 5| Step: 2
Training loss: 2.691930091494331
Validation loss: 2.6305890701515895

Epoch: 5| Step: 3
Training loss: 3.172439449805639
Validation loss: 2.6279185370971683

Epoch: 5| Step: 4
Training loss: 3.356798754394198
Validation loss: 2.618540076863163

Epoch: 5| Step: 5
Training loss: 2.796785832693937
Validation loss: 2.6164650363282878

Epoch: 5| Step: 6
Training loss: 3.2267659933654844
Validation loss: 2.6138790253861663

Epoch: 5| Step: 7
Training loss: 2.7473011645357825
Validation loss: 2.6075580970139813

Epoch: 5| Step: 8
Training loss: 3.0381488750612817
Validation loss: 2.6068704724214795

Epoch: 5| Step: 9
Training loss: 2.839573234676354
Validation loss: 2.611962516884633

Epoch: 5| Step: 10
Training loss: 2.577553425632009
Validation loss: 2.6137716571791425

Epoch: 89| Step: 0
Training loss: 3.0469325916031416
Validation loss: 2.6179844071101175

Epoch: 5| Step: 1
Training loss: 2.545822113145576
Validation loss: 2.626435304953322

Epoch: 5| Step: 2
Training loss: 2.294812476614577
Validation loss: 2.6323614933396824

Epoch: 5| Step: 3
Training loss: 3.1511629107560455
Validation loss: 2.645207485535426

Epoch: 5| Step: 4
Training loss: 2.3116714436601575
Validation loss: 2.651540374281644

Epoch: 5| Step: 5
Training loss: 2.6118132569298877
Validation loss: 2.6636376026894903

Epoch: 5| Step: 6
Training loss: 2.446836538974746
Validation loss: 2.6632760979969112

Epoch: 5| Step: 7
Training loss: 3.36100892541274
Validation loss: 2.64679974544404

Epoch: 5| Step: 8
Training loss: 3.6921670119677272
Validation loss: 2.6376856991774855

Epoch: 5| Step: 9
Training loss: 2.826573657703888
Validation loss: 2.6240108773062083

Epoch: 5| Step: 10
Training loss: 3.6339271066059498
Validation loss: 2.6097389121186465

Epoch: 90| Step: 0
Training loss: 3.2463530105269696
Validation loss: 2.6046119699708683

Epoch: 5| Step: 1
Training loss: 2.877519415848732
Validation loss: 2.6073907827966414

Epoch: 5| Step: 2
Training loss: 2.786743909991201
Validation loss: 2.6057257086102563

Epoch: 5| Step: 3
Training loss: 2.913707721784785
Validation loss: 2.6015545042620225

Epoch: 5| Step: 4
Training loss: 2.959740550295082
Validation loss: 2.602848648422804

Epoch: 5| Step: 5
Training loss: 3.2364383326512938
Validation loss: 2.6193907361687794

Epoch: 5| Step: 6
Training loss: 3.143494163705569
Validation loss: 2.6245684740245223

Epoch: 5| Step: 7
Training loss: 2.2681519195565336
Validation loss: 2.620033115219016

Epoch: 5| Step: 8
Training loss: 2.619207803773527
Validation loss: 2.6144593631103095

Epoch: 5| Step: 9
Training loss: 2.9127981598133457
Validation loss: 2.6080495488969553

Epoch: 5| Step: 10
Training loss: 3.490187104027256
Validation loss: 2.607945750847414

Epoch: 91| Step: 0
Training loss: 2.859584279557448
Validation loss: 2.601461981912241

Epoch: 5| Step: 1
Training loss: 3.48874421160555
Validation loss: 2.6030964505898213

Epoch: 5| Step: 2
Training loss: 2.646620765915786
Validation loss: 2.6036004600676206

Epoch: 5| Step: 3
Training loss: 2.9134782711729086
Validation loss: 2.614505403052876

Epoch: 5| Step: 4
Training loss: 3.2946707783046474
Validation loss: 2.6193015735884693

Epoch: 5| Step: 5
Training loss: 2.799900400570133
Validation loss: 2.6197291593267304

Epoch: 5| Step: 6
Training loss: 3.4136605102475603
Validation loss: 2.6333087326786506

Epoch: 5| Step: 7
Training loss: 2.5019369251402743
Validation loss: 2.627492905580029

Epoch: 5| Step: 8
Training loss: 2.795255309234727
Validation loss: 2.6150381113298327

Epoch: 5| Step: 9
Training loss: 2.6711848745230298
Validation loss: 2.606640362365165

Epoch: 5| Step: 10
Training loss: 2.4802781399758063
Validation loss: 2.599891089965738

Epoch: 92| Step: 0
Training loss: 3.3438609452425148
Validation loss: 2.5943788669720496

Epoch: 5| Step: 1
Training loss: 2.783302921045259
Validation loss: 2.594668420848682

Epoch: 5| Step: 2
Training loss: 2.7435568843649993
Validation loss: 2.5917966178245226

Epoch: 5| Step: 3
Training loss: 3.025613007028219
Validation loss: 2.595109059424176

Epoch: 5| Step: 4
Training loss: 2.7598985773607905
Validation loss: 2.5933252434789273

Epoch: 5| Step: 5
Training loss: 3.0052468194375894
Validation loss: 2.5929333176619966

Epoch: 5| Step: 6
Training loss: 2.7710519766529123
Validation loss: 2.5918103925028184

Epoch: 5| Step: 7
Training loss: 2.596968894023076
Validation loss: 2.5921037571723478

Epoch: 5| Step: 8
Training loss: 2.6906242840242043
Validation loss: 2.5919170097557322

Epoch: 5| Step: 9
Training loss: 3.293884222491616
Validation loss: 2.5917621125571646

Epoch: 5| Step: 10
Training loss: 2.884936534904157
Validation loss: 2.599997513898445

Epoch: 93| Step: 0
Training loss: 2.512116443717216
Validation loss: 2.6030001892959245

Epoch: 5| Step: 1
Training loss: 2.9905394156236973
Validation loss: 2.6089551063546184

Epoch: 5| Step: 2
Training loss: 2.660351537406624
Validation loss: 2.6118895541164187

Epoch: 5| Step: 3
Training loss: 3.085653634837684
Validation loss: 2.608506402302786

Epoch: 5| Step: 4
Training loss: 2.958676564538578
Validation loss: 2.6016298863229346

Epoch: 5| Step: 5
Training loss: 3.1631784970248717
Validation loss: 2.597659489021068

Epoch: 5| Step: 6
Training loss: 2.531719399715633
Validation loss: 2.5928755312896308

Epoch: 5| Step: 7
Training loss: 2.899926802928189
Validation loss: 2.5915711551245932

Epoch: 5| Step: 8
Training loss: 2.4541351765380974
Validation loss: 2.588023921654898

Epoch: 5| Step: 9
Training loss: 3.31736786361439
Validation loss: 2.5856808493322654

Epoch: 5| Step: 10
Training loss: 3.2578706072924173
Validation loss: 2.5819294542244053

Epoch: 94| Step: 0
Training loss: 3.511341520252706
Validation loss: 2.589655818965364

Epoch: 5| Step: 1
Training loss: 3.2836954359292188
Validation loss: 2.5880954929275064

Epoch: 5| Step: 2
Training loss: 2.883670172741871
Validation loss: 2.5901732707720524

Epoch: 5| Step: 3
Training loss: 2.6395697657821806
Validation loss: 2.591498918119312

Epoch: 5| Step: 4
Training loss: 2.397013188522781
Validation loss: 2.599316296240891

Epoch: 5| Step: 5
Training loss: 2.6146056236340254
Validation loss: 2.591878545716799

Epoch: 5| Step: 6
Training loss: 3.005853822738943
Validation loss: 2.5891020793729975

Epoch: 5| Step: 7
Training loss: 3.218353247031883
Validation loss: 2.5889132755731845

Epoch: 5| Step: 8
Training loss: 2.1248630030733358
Validation loss: 2.5856456933354806

Epoch: 5| Step: 9
Training loss: 3.2752100986326886
Validation loss: 2.578004661080873

Epoch: 5| Step: 10
Training loss: 2.5311317887195157
Validation loss: 2.577929853136779

Epoch: 95| Step: 0
Training loss: 2.987354808136259
Validation loss: 2.581308146300072

Epoch: 5| Step: 1
Training loss: 2.579555137930811
Validation loss: 2.5829917458263045

Epoch: 5| Step: 2
Training loss: 3.244468383033032
Validation loss: 2.5795873984617352

Epoch: 5| Step: 3
Training loss: 2.490398949065509
Validation loss: 2.5726232608414854

Epoch: 5| Step: 4
Training loss: 2.7439005573648756
Validation loss: 2.5801714926473376

Epoch: 5| Step: 5
Training loss: 2.8223729096714982
Validation loss: 2.5798288750183844

Epoch: 5| Step: 6
Training loss: 2.9624256430521245
Validation loss: 2.5866533688926627

Epoch: 5| Step: 7
Training loss: 2.6140394721695666
Validation loss: 2.590404470523617

Epoch: 5| Step: 8
Training loss: 2.9197294956483195
Validation loss: 2.599608992368421

Epoch: 5| Step: 9
Training loss: 3.169661778598854
Validation loss: 2.601648760565913

Epoch: 5| Step: 10
Training loss: 3.1983882958038197
Validation loss: 2.595637098913197

Epoch: 96| Step: 0
Training loss: 2.4690490734651176
Validation loss: 2.594550513175791

Epoch: 5| Step: 1
Training loss: 3.4055996895261034
Validation loss: 2.588154590507851

Epoch: 5| Step: 2
Training loss: 2.636539074462621
Validation loss: 2.5829386659393303

Epoch: 5| Step: 3
Training loss: 2.8522503584965935
Validation loss: 2.571053893323038

Epoch: 5| Step: 4
Training loss: 3.3167234163525086
Validation loss: 2.56625363909182

Epoch: 5| Step: 5
Training loss: 2.9130389586703855
Validation loss: 2.5679961528302018

Epoch: 5| Step: 6
Training loss: 2.6736399749474886
Validation loss: 2.551810311301544

Epoch: 5| Step: 7
Training loss: 2.5918547358662436
Validation loss: 2.556153486587929

Epoch: 5| Step: 8
Training loss: 2.786905860019948
Validation loss: 2.5793832482208114

Epoch: 5| Step: 9
Training loss: 3.277014623763579
Validation loss: 2.6096162753860246

Epoch: 5| Step: 10
Training loss: 2.8930828470656267
Validation loss: 2.5641701270700272

Epoch: 97| Step: 0
Training loss: 2.9844964287305604
Validation loss: 2.5852736805228855

Epoch: 5| Step: 1
Training loss: 2.6536524918871676
Validation loss: 2.6031675395073197

Epoch: 5| Step: 2
Training loss: 2.914676059632146
Validation loss: 2.6254296368706713

Epoch: 5| Step: 3
Training loss: 2.9940052536871815
Validation loss: 2.632599017278188

Epoch: 5| Step: 4
Training loss: 2.522336453900634
Validation loss: 2.6159528498824534

Epoch: 5| Step: 5
Training loss: 2.8225506384524652
Validation loss: 2.5927183340940863

Epoch: 5| Step: 6
Training loss: 3.1865910748836024
Validation loss: 2.5950079322551605

Epoch: 5| Step: 7
Training loss: 3.2168290415153282
Validation loss: 2.5703181732291664

Epoch: 5| Step: 8
Training loss: 3.1521310651803796
Validation loss: 2.5561767534335007

Epoch: 5| Step: 9
Training loss: 2.441166980462718
Validation loss: 2.5493238272035104

Epoch: 5| Step: 10
Training loss: 2.5629718625194475
Validation loss: 2.550795951702526

Epoch: 98| Step: 0
Training loss: 3.0841845978287172
Validation loss: 2.549044858105111

Epoch: 5| Step: 1
Training loss: 2.49416069912879
Validation loss: 2.549308651408435

Epoch: 5| Step: 2
Training loss: 2.5573231577957523
Validation loss: 2.5470305847683927

Epoch: 5| Step: 3
Training loss: 3.2889315835083184
Validation loss: 2.548047850895859

Epoch: 5| Step: 4
Training loss: 2.6047969106339544
Validation loss: 2.5485160478482927

Epoch: 5| Step: 5
Training loss: 2.706433426981687
Validation loss: 2.5513747011004053

Epoch: 5| Step: 6
Training loss: 2.840885606148491
Validation loss: 2.5666899492523307

Epoch: 5| Step: 7
Training loss: 2.9559922603975597
Validation loss: 2.5872336710835744

Epoch: 5| Step: 8
Training loss: 3.150444810735964
Validation loss: 2.6242197344964344

Epoch: 5| Step: 9
Training loss: 2.897194485294371
Validation loss: 2.6208265580486985

Epoch: 5| Step: 10
Training loss: 3.128392476203786
Validation loss: 2.6083117293443037

Epoch: 99| Step: 0
Training loss: 2.6179737333491064
Validation loss: 2.57237791475853

Epoch: 5| Step: 1
Training loss: 2.5222541231032274
Validation loss: 2.5441847568636233

Epoch: 5| Step: 2
Training loss: 2.503454301487493
Validation loss: 2.537970751725779

Epoch: 5| Step: 3
Training loss: 3.202274116453296
Validation loss: 2.5628562877644527

Epoch: 5| Step: 4
Training loss: 2.9472253390946976
Validation loss: 2.562673046152757

Epoch: 5| Step: 5
Training loss: 2.4907840615745966
Validation loss: 2.576253017088161

Epoch: 5| Step: 6
Training loss: 3.165247113794093
Validation loss: 2.5798411554436003

Epoch: 5| Step: 7
Training loss: 2.948649249132419
Validation loss: 2.583663614325821

Epoch: 5| Step: 8
Training loss: 3.2032647823444296
Validation loss: 2.5928295057364106

Epoch: 5| Step: 9
Training loss: 3.296902046273466
Validation loss: 2.598484103970343

Epoch: 5| Step: 10
Training loss: 2.8591241778651595
Validation loss: 2.587432378688147

Epoch: 100| Step: 0
Training loss: 2.8023748612518053
Validation loss: 2.5913483835122753

Epoch: 5| Step: 1
Training loss: 2.5866478811479854
Validation loss: 2.6215443745604103

Epoch: 5| Step: 2
Training loss: 2.473866243488889
Validation loss: 2.6542736269975205

Epoch: 5| Step: 3
Training loss: 3.2013395962583053
Validation loss: 2.6562837216132635

Epoch: 5| Step: 4
Training loss: 3.063910490367001
Validation loss: 2.622350250948431

Epoch: 5| Step: 5
Training loss: 3.360664155805402
Validation loss: 2.6023761649881214

Epoch: 5| Step: 6
Training loss: 2.8706517716248876
Validation loss: 2.5535124128717976

Epoch: 5| Step: 7
Training loss: 3.1413127089289152
Validation loss: 2.5376529579408427

Epoch: 5| Step: 8
Training loss: 2.7106000266970827
Validation loss: 2.5290968870651667

Epoch: 5| Step: 9
Training loss: 2.886232079557261
Validation loss: 2.5336403568673234

Epoch: 5| Step: 10
Training loss: 2.755680373101182
Validation loss: 2.539074951343281

Epoch: 101| Step: 0
Training loss: 2.5722824015030454
Validation loss: 2.534888549627824

Epoch: 5| Step: 1
Training loss: 3.387942611100194
Validation loss: 2.537399740565666

Epoch: 5| Step: 2
Training loss: 2.589040686377913
Validation loss: 2.53741565642773

Epoch: 5| Step: 3
Training loss: 2.6230077903943094
Validation loss: 2.5357084863708272

Epoch: 5| Step: 4
Training loss: 2.622148236301378
Validation loss: 2.534516918726952

Epoch: 5| Step: 5
Training loss: 2.8880359499059596
Validation loss: 2.535834184837017

Epoch: 5| Step: 6
Training loss: 3.351463761020051
Validation loss: 2.5364659286890325

Epoch: 5| Step: 7
Training loss: 3.2141523394085247
Validation loss: 2.538222397115117

Epoch: 5| Step: 8
Training loss: 3.1513125636825423
Validation loss: 2.5354921253794274

Epoch: 5| Step: 9
Training loss: 2.5151735457499704
Validation loss: 2.534061071641442

Epoch: 5| Step: 10
Training loss: 2.9614268681083127
Validation loss: 2.528646502805159

Epoch: 102| Step: 0
Training loss: 2.9768200860493788
Validation loss: 2.534105720415032

Epoch: 5| Step: 1
Training loss: 3.110897898936875
Validation loss: 2.5369482747021896

Epoch: 5| Step: 2
Training loss: 3.024763265126478
Validation loss: 2.5422383171055936

Epoch: 5| Step: 3
Training loss: 3.4104498772857688
Validation loss: 2.5347910300584893

Epoch: 5| Step: 4
Training loss: 2.4172378939188257
Validation loss: 2.5496080366345386

Epoch: 5| Step: 5
Training loss: 2.8787114609305617
Validation loss: 2.558344020208583

Epoch: 5| Step: 6
Training loss: 2.7051618542434404
Validation loss: 2.5905419634412956

Epoch: 5| Step: 7
Training loss: 2.4819694725083505
Validation loss: 2.634368031890244

Epoch: 5| Step: 8
Training loss: 2.895406531481192
Validation loss: 2.6850321256817344

Epoch: 5| Step: 9
Training loss: 2.9142344733416343
Validation loss: 2.687980152992707

Epoch: 5| Step: 10
Training loss: 3.1436502490134868
Validation loss: 2.6258927666592298

Epoch: 103| Step: 0
Training loss: 2.8938977658998217
Validation loss: 2.5457503644540105

Epoch: 5| Step: 1
Training loss: 3.0172432624172103
Validation loss: 2.5245245547744557

Epoch: 5| Step: 2
Training loss: 2.8531396136374445
Validation loss: 2.527097382001006

Epoch: 5| Step: 3
Training loss: 3.2605598263902054
Validation loss: 2.5288668389627866

Epoch: 5| Step: 4
Training loss: 3.0196247357779202
Validation loss: 2.564834065966419

Epoch: 5| Step: 5
Training loss: 2.296086805397375
Validation loss: 2.558685114235247

Epoch: 5| Step: 6
Training loss: 3.3465601440843153
Validation loss: 2.5873948358279533

Epoch: 5| Step: 7
Training loss: 2.9540610469845614
Validation loss: 2.5772941147885216

Epoch: 5| Step: 8
Training loss: 2.587629888103238
Validation loss: 2.5353036434384193

Epoch: 5| Step: 9
Training loss: 2.5723262423452637
Validation loss: 2.52869854769856

Epoch: 5| Step: 10
Training loss: 3.1653040581077576
Validation loss: 2.5211450588625537

Epoch: 104| Step: 0
Training loss: 3.069798860950322
Validation loss: 2.528329625796164

Epoch: 5| Step: 1
Training loss: 2.7307965214234575
Validation loss: 2.5492582079087356

Epoch: 5| Step: 2
Training loss: 3.035541446157158
Validation loss: 2.566840314990592

Epoch: 5| Step: 3
Training loss: 3.337286147220549
Validation loss: 2.573344645717868

Epoch: 5| Step: 4
Training loss: 3.0334002546816237
Validation loss: 2.577588510984913

Epoch: 5| Step: 5
Training loss: 2.816796814057949
Validation loss: 2.5921777130023096

Epoch: 5| Step: 6
Training loss: 2.6343418286679836
Validation loss: 2.582689218540703

Epoch: 5| Step: 7
Training loss: 3.3228680996748747
Validation loss: 2.565539008878523

Epoch: 5| Step: 8
Training loss: 2.5273324296983724
Validation loss: 2.542856433879963

Epoch: 5| Step: 9
Training loss: 2.407736678170491
Validation loss: 2.5261369283609687

Epoch: 5| Step: 10
Training loss: 2.6732053066175303
Validation loss: 2.5160810072183173

Epoch: 105| Step: 0
Training loss: 3.2180655038638046
Validation loss: 2.5175585583594464

Epoch: 5| Step: 1
Training loss: 2.875525882557367
Validation loss: 2.520286372241145

Epoch: 5| Step: 2
Training loss: 2.906651294854257
Validation loss: 2.525428355671206

Epoch: 5| Step: 3
Training loss: 2.9174000136003753
Validation loss: 2.5287764675518503

Epoch: 5| Step: 4
Training loss: 2.881277114839876
Validation loss: 2.528648149279283

Epoch: 5| Step: 5
Training loss: 3.3429695715995718
Validation loss: 2.527488923301966

Epoch: 5| Step: 6
Training loss: 2.5998570806396644
Validation loss: 2.5300042537932472

Epoch: 5| Step: 7
Training loss: 2.9239054270217073
Validation loss: 2.525576643685715

Epoch: 5| Step: 8
Training loss: 2.9178123585412004
Validation loss: 2.522205045339308

Epoch: 5| Step: 9
Training loss: 2.5899856091250495
Validation loss: 2.5213629204358017

Epoch: 5| Step: 10
Training loss: 2.15787897912223
Validation loss: 2.5184228505345185

Epoch: 106| Step: 0
Training loss: 2.861892675747992
Validation loss: 2.5107991430954533

Epoch: 5| Step: 1
Training loss: 2.983944527302175
Validation loss: 2.510343532614341

Epoch: 5| Step: 2
Training loss: 2.80713582830128
Validation loss: 2.507175979540038

Epoch: 5| Step: 3
Training loss: 2.87241811504466
Validation loss: 2.5182276022886563

Epoch: 5| Step: 4
Training loss: 2.6087857797505922
Validation loss: 2.5239523918522715

Epoch: 5| Step: 5
Training loss: 2.93819857468106
Validation loss: 2.5353884595432583

Epoch: 5| Step: 6
Training loss: 2.93705194180946
Validation loss: 2.553749652160396

Epoch: 5| Step: 7
Training loss: 2.3445021376157693
Validation loss: 2.556401114830225

Epoch: 5| Step: 8
Training loss: 2.972240764841329
Validation loss: 2.5589950481030064

Epoch: 5| Step: 9
Training loss: 2.9850127652149316
Validation loss: 2.5502805425223825

Epoch: 5| Step: 10
Training loss: 3.0084885667251124
Validation loss: 2.5408744390981233

Epoch: 107| Step: 0
Training loss: 2.6492358779466034
Validation loss: 2.5260904104242528

Epoch: 5| Step: 1
Training loss: 2.5653920484903034
Validation loss: 2.524990843004249

Epoch: 5| Step: 2
Training loss: 3.0623172004794896
Validation loss: 2.5224791804715045

Epoch: 5| Step: 3
Training loss: 2.7724390086146236
Validation loss: 2.523395741805904

Epoch: 5| Step: 4
Training loss: 2.3673722097516467
Validation loss: 2.51410351387753

Epoch: 5| Step: 5
Training loss: 3.583301780620909
Validation loss: 2.505522290372097

Epoch: 5| Step: 6
Training loss: 2.7642028082929726
Validation loss: 2.5026819712302304

Epoch: 5| Step: 7
Training loss: 2.7381846891130475
Validation loss: 2.4975345760416725

Epoch: 5| Step: 8
Training loss: 3.004279263556006
Validation loss: 2.498288255643993

Epoch: 5| Step: 9
Training loss: 2.758359946576797
Validation loss: 2.495174789494276

Epoch: 5| Step: 10
Training loss: 2.6855331143113363
Validation loss: 2.4888092514710314

Epoch: 108| Step: 0
Training loss: 2.570285228828065
Validation loss: 2.4870436442866506

Epoch: 5| Step: 1
Training loss: 2.8915159759687006
Validation loss: 2.4880053313986603

Epoch: 5| Step: 2
Training loss: 2.774893279214365
Validation loss: 2.4884675799834315

Epoch: 5| Step: 3
Training loss: 3.0300849169927586
Validation loss: 2.4888980746359133

Epoch: 5| Step: 4
Training loss: 3.3413061320067103
Validation loss: 2.483143896712388

Epoch: 5| Step: 5
Training loss: 2.913786274190363
Validation loss: 2.4839348707900335

Epoch: 5| Step: 6
Training loss: 2.7039614579484224
Validation loss: 2.4812958743662517

Epoch: 5| Step: 7
Training loss: 2.5124638758857043
Validation loss: 2.4829780431475763

Epoch: 5| Step: 8
Training loss: 2.949937018029259
Validation loss: 2.485500370516085

Epoch: 5| Step: 9
Training loss: 2.6357912141721376
Validation loss: 2.483387057272529

Epoch: 5| Step: 10
Training loss: 2.5649542801855434
Validation loss: 2.4815090172057075

Epoch: 109| Step: 0
Training loss: 3.335283344820103
Validation loss: 2.4814703398019917

Epoch: 5| Step: 1
Training loss: 3.164136494842725
Validation loss: 2.4819990981353706

Epoch: 5| Step: 2
Training loss: 2.4649632057709185
Validation loss: 2.481838222863988

Epoch: 5| Step: 3
Training loss: 2.896820028332843
Validation loss: 2.4848204440607984

Epoch: 5| Step: 4
Training loss: 2.644120380258174
Validation loss: 2.4850819008245857

Epoch: 5| Step: 5
Training loss: 2.9663456868179767
Validation loss: 2.4828940092201366

Epoch: 5| Step: 6
Training loss: 2.489844006627252
Validation loss: 2.48183206951118

Epoch: 5| Step: 7
Training loss: 2.458910782661922
Validation loss: 2.491374157711191

Epoch: 5| Step: 8
Training loss: 3.002976212800154
Validation loss: 2.4871798131521667

Epoch: 5| Step: 9
Training loss: 2.791590466574359
Validation loss: 2.4897054318874012

Epoch: 5| Step: 10
Training loss: 2.5829360000059918
Validation loss: 2.4928358393670265

Epoch: 110| Step: 0
Training loss: 2.9495558388173073
Validation loss: 2.4917459965104762

Epoch: 5| Step: 1
Training loss: 2.859207065007426
Validation loss: 2.496874715962719

Epoch: 5| Step: 2
Training loss: 2.8444092374185734
Validation loss: 2.4897060224181975

Epoch: 5| Step: 3
Training loss: 2.5218896045285564
Validation loss: 2.480154296952293

Epoch: 5| Step: 4
Training loss: 2.5676760616686085
Validation loss: 2.476200797689011

Epoch: 5| Step: 5
Training loss: 2.8070277913956394
Validation loss: 2.4813770148337477

Epoch: 5| Step: 6
Training loss: 3.021520198912952
Validation loss: 2.472283626394662

Epoch: 5| Step: 7
Training loss: 2.3036048544552883
Validation loss: 2.477580987226984

Epoch: 5| Step: 8
Training loss: 3.0120350712409945
Validation loss: 2.48026022227931

Epoch: 5| Step: 9
Training loss: 3.448985661097202
Validation loss: 2.481073081008441

Epoch: 5| Step: 10
Training loss: 2.399774334152776
Validation loss: 2.4764635480290917

Epoch: 111| Step: 0
Training loss: 2.8709417808951736
Validation loss: 2.47784960341447

Epoch: 5| Step: 1
Training loss: 2.7910012737997025
Validation loss: 2.4783410937964705

Epoch: 5| Step: 2
Training loss: 2.8277221730012845
Validation loss: 2.479927299611869

Epoch: 5| Step: 3
Training loss: 2.5130285286003184
Validation loss: 2.483171162702714

Epoch: 5| Step: 4
Training loss: 3.012879856584461
Validation loss: 2.4833513378435708

Epoch: 5| Step: 5
Training loss: 3.358740316362125
Validation loss: 2.4933138355071627

Epoch: 5| Step: 6
Training loss: 2.609250459725622
Validation loss: 2.4878738107606204

Epoch: 5| Step: 7
Training loss: 2.6385432055971214
Validation loss: 2.4915952433625486

Epoch: 5| Step: 8
Training loss: 2.850288336372983
Validation loss: 2.4910476407291187

Epoch: 5| Step: 9
Training loss: 2.7995202539075468
Validation loss: 2.4949601574405604

Epoch: 5| Step: 10
Training loss: 2.4480204350547314
Validation loss: 2.4873453561425407

Epoch: 112| Step: 0
Training loss: 2.994793825010545
Validation loss: 2.483507872489947

Epoch: 5| Step: 1
Training loss: 2.4316842561660406
Validation loss: 2.485799535672615

Epoch: 5| Step: 2
Training loss: 3.086566947770822
Validation loss: 2.4806766731955117

Epoch: 5| Step: 3
Training loss: 3.4065019706833475
Validation loss: 2.47807792285022

Epoch: 5| Step: 4
Training loss: 2.276480300037213
Validation loss: 2.4633389685090092

Epoch: 5| Step: 5
Training loss: 2.7158966876733794
Validation loss: 2.4775431052761334

Epoch: 5| Step: 6
Training loss: 2.8521094228825117
Validation loss: 2.4691134717839978

Epoch: 5| Step: 7
Training loss: 2.3499172196113376
Validation loss: 2.472438764135367

Epoch: 5| Step: 8
Training loss: 3.1912238116745635
Validation loss: 2.4662707865711653

Epoch: 5| Step: 9
Training loss: 2.609554809953672
Validation loss: 2.4668397004094897

Epoch: 5| Step: 10
Training loss: 2.633167729622988
Validation loss: 2.4722238028453924

Epoch: 113| Step: 0
Training loss: 2.514185049082317
Validation loss: 2.4874475154203206

Epoch: 5| Step: 1
Training loss: 2.7904815910373273
Validation loss: 2.5001216017979613

Epoch: 5| Step: 2
Training loss: 3.356091975464665
Validation loss: 2.495318044325666

Epoch: 5| Step: 3
Training loss: 2.85205926617949
Validation loss: 2.4885723391730856

Epoch: 5| Step: 4
Training loss: 2.3165279054136296
Validation loss: 2.4768647868316895

Epoch: 5| Step: 5
Training loss: 2.4797172789777644
Validation loss: 2.4732876218312976

Epoch: 5| Step: 6
Training loss: 3.1337587825254936
Validation loss: 2.460385870582989

Epoch: 5| Step: 7
Training loss: 2.3997125373981767
Validation loss: 2.4583715616976423

Epoch: 5| Step: 8
Training loss: 2.9341603225976005
Validation loss: 2.462366896178638

Epoch: 5| Step: 9
Training loss: 3.3279854472098913
Validation loss: 2.462720300146016

Epoch: 5| Step: 10
Training loss: 2.38113474329162
Validation loss: 2.467878048279906

Epoch: 114| Step: 0
Training loss: 2.5295755947118033
Validation loss: 2.472554161827052

Epoch: 5| Step: 1
Training loss: 3.39060418610403
Validation loss: 2.4756392366391937

Epoch: 5| Step: 2
Training loss: 2.4882106321844955
Validation loss: 2.4796105850235843

Epoch: 5| Step: 3
Training loss: 3.1635443369117566
Validation loss: 2.4793524086140626

Epoch: 5| Step: 4
Training loss: 2.9458633838579447
Validation loss: 2.4808498486103305

Epoch: 5| Step: 5
Training loss: 2.7115629062913866
Validation loss: 2.4950543059709394

Epoch: 5| Step: 6
Training loss: 2.860748294759474
Validation loss: 2.4828891047397197

Epoch: 5| Step: 7
Training loss: 2.334385384941237
Validation loss: 2.4796315459885347

Epoch: 5| Step: 8
Training loss: 2.5546879666295923
Validation loss: 2.4787079550541575

Epoch: 5| Step: 9
Training loss: 2.740217843688998
Validation loss: 2.481962057266616

Epoch: 5| Step: 10
Training loss: 2.718265446420001
Validation loss: 2.473977675219294

Epoch: 115| Step: 0
Training loss: 3.0072937357020795
Validation loss: 2.479727465420999

Epoch: 5| Step: 1
Training loss: 2.6351883579518116
Validation loss: 2.479041643334629

Epoch: 5| Step: 2
Training loss: 3.282369658765177
Validation loss: 2.4719621522992

Epoch: 5| Step: 3
Training loss: 2.5558131359966074
Validation loss: 2.4758812776910166

Epoch: 5| Step: 4
Training loss: 2.7370648042521357
Validation loss: 2.474875082851701

Epoch: 5| Step: 5
Training loss: 2.852276271167116
Validation loss: 2.4800743171183117

Epoch: 5| Step: 6
Training loss: 2.625803778976498
Validation loss: 2.5016362803575163

Epoch: 5| Step: 7
Training loss: 2.3609700653233676
Validation loss: 2.5064453583632167

Epoch: 5| Step: 8
Training loss: 2.459264374199535
Validation loss: 2.518247768438041

Epoch: 5| Step: 9
Training loss: 3.245343907828279
Validation loss: 2.526807312817876

Epoch: 5| Step: 10
Training loss: 2.8331683802739094
Validation loss: 2.5282556721080156

Epoch: 116| Step: 0
Training loss: 2.782321509217052
Validation loss: 2.510628428663462

Epoch: 5| Step: 1
Training loss: 3.136295503823689
Validation loss: 2.481935105429014

Epoch: 5| Step: 2
Training loss: 3.0172171861402095
Validation loss: 2.4747682246815406

Epoch: 5| Step: 3
Training loss: 2.5731750132064644
Validation loss: 2.4712986270725232

Epoch: 5| Step: 4
Training loss: 2.694706680103954
Validation loss: 2.4678419703666794

Epoch: 5| Step: 5
Training loss: 2.8682915747212987
Validation loss: 2.4718392142060797

Epoch: 5| Step: 6
Training loss: 2.7595587110872897
Validation loss: 2.469099402997782

Epoch: 5| Step: 7
Training loss: 3.067630596287754
Validation loss: 2.4686725272518544

Epoch: 5| Step: 8
Training loss: 2.610744185627789
Validation loss: 2.461018896571687

Epoch: 5| Step: 9
Training loss: 2.310459370701443
Validation loss: 2.4619959588822757

Epoch: 5| Step: 10
Training loss: 2.665223168052248
Validation loss: 2.4563160171619267

Epoch: 117| Step: 0
Training loss: 3.260166845206169
Validation loss: 2.4663180481827363

Epoch: 5| Step: 1
Training loss: 2.521466787736399
Validation loss: 2.4754534152646355

Epoch: 5| Step: 2
Training loss: 2.904122835446079
Validation loss: 2.4863789698394836

Epoch: 5| Step: 3
Training loss: 2.8384477418998038
Validation loss: 2.4989088917879183

Epoch: 5| Step: 4
Training loss: 2.4595670244607977
Validation loss: 2.511149532336842

Epoch: 5| Step: 5
Training loss: 2.248960148744497
Validation loss: 2.5210357923029685

Epoch: 5| Step: 6
Training loss: 2.4040554988376828
Validation loss: 2.5329368456987313

Epoch: 5| Step: 7
Training loss: 3.2064367526211353
Validation loss: 2.5360417396723443

Epoch: 5| Step: 8
Training loss: 2.921685034140522
Validation loss: 2.508299947246709

Epoch: 5| Step: 9
Training loss: 2.8254466994912963
Validation loss: 2.4770906252152436

Epoch: 5| Step: 10
Training loss: 2.907882724018544
Validation loss: 2.45770020115822

Epoch: 118| Step: 0
Training loss: 2.237402725236344
Validation loss: 2.465327388717372

Epoch: 5| Step: 1
Training loss: 2.414835685684428
Validation loss: 2.475136261299926

Epoch: 5| Step: 2
Training loss: 2.775758443749981
Validation loss: 2.4784747928542035

Epoch: 5| Step: 3
Training loss: 2.8010291251888564
Validation loss: 2.475592955542758

Epoch: 5| Step: 4
Training loss: 3.03270977304207
Validation loss: 2.469844416133594

Epoch: 5| Step: 5
Training loss: 2.889472855534991
Validation loss: 2.4720693495441326

Epoch: 5| Step: 6
Training loss: 2.8695291628727437
Validation loss: 2.4651206647080617

Epoch: 5| Step: 7
Training loss: 3.2406898072695753
Validation loss: 2.465849736039252

Epoch: 5| Step: 8
Training loss: 2.466487862146293
Validation loss: 2.4625857348123796

Epoch: 5| Step: 9
Training loss: 2.953927874542723
Validation loss: 2.4646024536304285

Epoch: 5| Step: 10
Training loss: 3.174541686613037
Validation loss: 2.460795353464279

Epoch: 119| Step: 0
Training loss: 2.584502960321462
Validation loss: 2.4764668762020867

Epoch: 5| Step: 1
Training loss: 2.5447635440362926
Validation loss: 2.4881241707721964

Epoch: 5| Step: 2
Training loss: 2.644227318928208
Validation loss: 2.507194332706199

Epoch: 5| Step: 3
Training loss: 2.837866765320381
Validation loss: 2.5131376281525952

Epoch: 5| Step: 4
Training loss: 2.659815650230837
Validation loss: 2.514207764182174

Epoch: 5| Step: 5
Training loss: 2.9044167263644765
Validation loss: 2.513681632161467

Epoch: 5| Step: 6
Training loss: 2.6963601550297995
Validation loss: 2.5296223667811586

Epoch: 5| Step: 7
Training loss: 2.681786607518234
Validation loss: 2.5179869316867265

Epoch: 5| Step: 8
Training loss: 3.445730862983171
Validation loss: 2.5182740577932963

Epoch: 5| Step: 9
Training loss: 2.804227488416946
Validation loss: 2.5098876683407214

Epoch: 5| Step: 10
Training loss: 2.673290480066506
Validation loss: 2.500737300971676

Epoch: 120| Step: 0
Training loss: 2.9342458028250604
Validation loss: 2.4924054349642106

Epoch: 5| Step: 1
Training loss: 2.4525894260726355
Validation loss: 2.492784596588485

Epoch: 5| Step: 2
Training loss: 2.3811932174040056
Validation loss: 2.487512182555365

Epoch: 5| Step: 3
Training loss: 2.3627097707796234
Validation loss: 2.482065838681843

Epoch: 5| Step: 4
Training loss: 2.755835583730801
Validation loss: 2.4635957210163792

Epoch: 5| Step: 5
Training loss: 2.935620457379938
Validation loss: 2.4690710263754805

Epoch: 5| Step: 6
Training loss: 2.6701776121120875
Validation loss: 2.4680314831143897

Epoch: 5| Step: 7
Training loss: 2.495202133613939
Validation loss: 2.473056694626495

Epoch: 5| Step: 8
Training loss: 3.4169320414380007
Validation loss: 2.487599502575229

Epoch: 5| Step: 9
Training loss: 3.081032556130895
Validation loss: 2.500160531048008

Epoch: 5| Step: 10
Training loss: 2.720484213364153
Validation loss: 2.502063086588487

Epoch: 121| Step: 0
Training loss: 2.189333120387102
Validation loss: 2.494816520348412

Epoch: 5| Step: 1
Training loss: 2.4967803249624074
Validation loss: 2.488864774560913

Epoch: 5| Step: 2
Training loss: 3.581849803925801
Validation loss: 2.472686055637885

Epoch: 5| Step: 3
Training loss: 3.1963083072576
Validation loss: 2.4648909370473264

Epoch: 5| Step: 4
Training loss: 2.5436039613234893
Validation loss: 2.467948842769586

Epoch: 5| Step: 5
Training loss: 3.283150258906618
Validation loss: 2.474675430141555

Epoch: 5| Step: 6
Training loss: 2.776396556354075
Validation loss: 2.478292081552613

Epoch: 5| Step: 7
Training loss: 2.2825963476095823
Validation loss: 2.480385646537386

Epoch: 5| Step: 8
Training loss: 2.420161274667031
Validation loss: 2.4835481243425552

Epoch: 5| Step: 9
Training loss: 2.49047812073032
Validation loss: 2.501352550346822

Epoch: 5| Step: 10
Training loss: 2.7392613810415702
Validation loss: 2.510688037592867

Epoch: 122| Step: 0
Training loss: 2.65767550645206
Validation loss: 2.5199150396652668

Epoch: 5| Step: 1
Training loss: 2.911411583012729
Validation loss: 2.514254189957228

Epoch: 5| Step: 2
Training loss: 2.8966736889202775
Validation loss: 2.5082503680123938

Epoch: 5| Step: 3
Training loss: 2.2746021132408125
Validation loss: 2.4720991187029124

Epoch: 5| Step: 4
Training loss: 2.1922020648627436
Validation loss: 2.464954863140039

Epoch: 5| Step: 5
Training loss: 3.201214178526153
Validation loss: 2.4662641785841424

Epoch: 5| Step: 6
Training loss: 2.9053620653498466
Validation loss: 2.4762146780793652

Epoch: 5| Step: 7
Training loss: 2.7890854949430657
Validation loss: 2.474352379047974

Epoch: 5| Step: 8
Training loss: 2.8091836662611747
Validation loss: 2.4759423765173008

Epoch: 5| Step: 9
Training loss: 2.8720648336504184
Validation loss: 2.476112787349698

Epoch: 5| Step: 10
Training loss: 3.117144668017135
Validation loss: 2.47073779980197

Epoch: 123| Step: 0
Training loss: 3.2903626832804336
Validation loss: 2.470063557518892

Epoch: 5| Step: 1
Training loss: 3.0902573107400024
Validation loss: 2.4660390473920835

Epoch: 5| Step: 2
Training loss: 2.7303589019726955
Validation loss: 2.4630126745929672

Epoch: 5| Step: 3
Training loss: 2.530182601611504
Validation loss: 2.4611809670809084

Epoch: 5| Step: 4
Training loss: 2.6435900412070774
Validation loss: 2.4723068550580227

Epoch: 5| Step: 5
Training loss: 2.710069412947193
Validation loss: 2.4815249991717794

Epoch: 5| Step: 6
Training loss: 2.3062823450978542
Validation loss: 2.508731322445409

Epoch: 5| Step: 7
Training loss: 3.021402941089102
Validation loss: 2.5265148613153476

Epoch: 5| Step: 8
Training loss: 3.2156838933446963
Validation loss: 2.535009620620579

Epoch: 5| Step: 9
Training loss: 2.3269695512577013
Validation loss: 2.507799658315816

Epoch: 5| Step: 10
Training loss: 2.783294012359208
Validation loss: 2.4835818239544833

Epoch: 124| Step: 0
Training loss: 2.5737459851345266
Validation loss: 2.476791416285718

Epoch: 5| Step: 1
Training loss: 2.5112045022688965
Validation loss: 2.46096873096729

Epoch: 5| Step: 2
Training loss: 3.0135128550377925
Validation loss: 2.4566594319255057

Epoch: 5| Step: 3
Training loss: 3.172117628016288
Validation loss: 2.448862407762481

Epoch: 5| Step: 4
Training loss: 2.5589490338072953
Validation loss: 2.448816498941209

Epoch: 5| Step: 5
Training loss: 3.084472772194572
Validation loss: 2.4526032561223183

Epoch: 5| Step: 6
Training loss: 2.2648425625616713
Validation loss: 2.457574718619953

Epoch: 5| Step: 7
Training loss: 2.6548123227613836
Validation loss: 2.4593817159761646

Epoch: 5| Step: 8
Training loss: 2.858136351742402
Validation loss: 2.4682682907493962

Epoch: 5| Step: 9
Training loss: 2.78587608077146
Validation loss: 2.495663389731422

Epoch: 5| Step: 10
Training loss: 2.736714697248685
Validation loss: 2.515801966378904

Epoch: 125| Step: 0
Training loss: 2.72330838114569
Validation loss: 2.5505167335220102

Epoch: 5| Step: 1
Training loss: 2.6082094067596024
Validation loss: 2.615918550546046

Epoch: 5| Step: 2
Training loss: 3.234403600888792
Validation loss: 2.616398677802049

Epoch: 5| Step: 3
Training loss: 2.613346024923582
Validation loss: 2.5791624048470734

Epoch: 5| Step: 4
Training loss: 2.8496789851847377
Validation loss: 2.5482310325135638

Epoch: 5| Step: 5
Training loss: 2.72138209473122
Validation loss: 2.522471708491552

Epoch: 5| Step: 6
Training loss: 2.6540992556584464
Validation loss: 2.517199479683726

Epoch: 5| Step: 7
Training loss: 2.257521455479049
Validation loss: 2.4945536806155673

Epoch: 5| Step: 8
Training loss: 2.5082751646510446
Validation loss: 2.468643320129968

Epoch: 5| Step: 9
Training loss: 3.1263403497610343
Validation loss: 2.456025512994358

Epoch: 5| Step: 10
Training loss: 3.314971146033649
Validation loss: 2.45772256836801

Epoch: 126| Step: 0
Training loss: 2.8399730374842815
Validation loss: 2.4596230210896026

Epoch: 5| Step: 1
Training loss: 3.050252284888062
Validation loss: 2.4663466612508977

Epoch: 5| Step: 2
Training loss: 3.2627360876025127
Validation loss: 2.4634006979100294

Epoch: 5| Step: 3
Training loss: 2.889656688269735
Validation loss: 2.4628354000891615

Epoch: 5| Step: 4
Training loss: 2.8394308301612172
Validation loss: 2.460571305569919

Epoch: 5| Step: 5
Training loss: 2.3196453329820046
Validation loss: 2.4545773226014154

Epoch: 5| Step: 6
Training loss: 3.0880884327949882
Validation loss: 2.4633765037908097

Epoch: 5| Step: 7
Training loss: 2.839868768427021
Validation loss: 2.4764916737968914

Epoch: 5| Step: 8
Training loss: 2.2736363274847196
Validation loss: 2.4946373305124516

Epoch: 5| Step: 9
Training loss: 2.585060639398793
Validation loss: 2.5084888781914025

Epoch: 5| Step: 10
Training loss: 2.1889131613524313
Validation loss: 2.5119086571913987

Epoch: 127| Step: 0
Training loss: 2.9059923939720216
Validation loss: 2.5284209576537484

Epoch: 5| Step: 1
Training loss: 2.583011596907672
Validation loss: 2.5320663776389654

Epoch: 5| Step: 2
Training loss: 3.1015658822990058
Validation loss: 2.523000678529493

Epoch: 5| Step: 3
Training loss: 2.863150017243287
Validation loss: 2.5075774020158503

Epoch: 5| Step: 4
Training loss: 2.051679142165919
Validation loss: 2.5021155327872306

Epoch: 5| Step: 5
Training loss: 2.990343925318125
Validation loss: 2.5002873922073334

Epoch: 5| Step: 6
Training loss: 2.129370066662519
Validation loss: 2.481463830144966

Epoch: 5| Step: 7
Training loss: 3.0770029259371183
Validation loss: 2.4702930905755265

Epoch: 5| Step: 8
Training loss: 2.668821765372489
Validation loss: 2.461742944749155

Epoch: 5| Step: 9
Training loss: 2.8553261362514006
Validation loss: 2.459333244255191

Epoch: 5| Step: 10
Training loss: 2.954867056036135
Validation loss: 2.46040553033589

Epoch: 128| Step: 0
Training loss: 2.8893238335233073
Validation loss: 2.4519189791345934

Epoch: 5| Step: 1
Training loss: 2.7336000924855863
Validation loss: 2.457211438848238

Epoch: 5| Step: 2
Training loss: 2.8522013745472528
Validation loss: 2.4653745571491705

Epoch: 5| Step: 3
Training loss: 2.5703926421776377
Validation loss: 2.469786572135922

Epoch: 5| Step: 4
Training loss: 2.9039983743500164
Validation loss: 2.472123426563631

Epoch: 5| Step: 5
Training loss: 2.682263084679079
Validation loss: 2.4828862446487725

Epoch: 5| Step: 6
Training loss: 3.0116063355519946
Validation loss: 2.4884841163214033

Epoch: 5| Step: 7
Training loss: 2.521340080168822
Validation loss: 2.499743266920755

Epoch: 5| Step: 8
Training loss: 2.880814022418437
Validation loss: 2.4921602801919738

Epoch: 5| Step: 9
Training loss: 2.6908415491241167
Validation loss: 2.4768643355565834

Epoch: 5| Step: 10
Training loss: 2.472845422821341
Validation loss: 2.4768282301765656

Epoch: 129| Step: 0
Training loss: 2.6202161886113586
Validation loss: 2.4597644693338174

Epoch: 5| Step: 1
Training loss: 2.478885463720023
Validation loss: 2.464616405582178

Epoch: 5| Step: 2
Training loss: 2.689090524247039
Validation loss: 2.4621611907648178

Epoch: 5| Step: 3
Training loss: 2.582153594426788
Validation loss: 2.451124657081062

Epoch: 5| Step: 4
Training loss: 2.5254397169919054
Validation loss: 2.4580417141677535

Epoch: 5| Step: 5
Training loss: 3.2835464434196373
Validation loss: 2.456310844612353

Epoch: 5| Step: 6
Training loss: 2.4564303344066096
Validation loss: 2.463116215694899

Epoch: 5| Step: 7
Training loss: 3.048354977850166
Validation loss: 2.465598469065895

Epoch: 5| Step: 8
Training loss: 2.889097232723294
Validation loss: 2.462006754906427

Epoch: 5| Step: 9
Training loss: 2.7591221107042987
Validation loss: 2.461267660442785

Epoch: 5| Step: 10
Training loss: 2.6239313039161103
Validation loss: 2.4650481541216713

Epoch: 130| Step: 0
Training loss: 2.993689416578983
Validation loss: 2.4657766667461676

Epoch: 5| Step: 1
Training loss: 1.7245666567738127
Validation loss: 2.469243941161809

Epoch: 5| Step: 2
Training loss: 3.152233173837045
Validation loss: 2.4584042945771793

Epoch: 5| Step: 3
Training loss: 2.8186499431977747
Validation loss: 2.455700912541846

Epoch: 5| Step: 4
Training loss: 2.6438012517195295
Validation loss: 2.4566213974579116

Epoch: 5| Step: 5
Training loss: 2.5130205592548966
Validation loss: 2.454394687362521

Epoch: 5| Step: 6
Training loss: 2.76830045955767
Validation loss: 2.460413062642885

Epoch: 5| Step: 7
Training loss: 3.1270484314118034
Validation loss: 2.471543755860893

Epoch: 5| Step: 8
Training loss: 2.8643568654561093
Validation loss: 2.4824850806402496

Epoch: 5| Step: 9
Training loss: 2.7388284220886985
Validation loss: 2.486733250485191

Epoch: 5| Step: 10
Training loss: 2.2986049235844255
Validation loss: 2.4932229805276247

Epoch: 131| Step: 0
Training loss: 3.135645928772093
Validation loss: 2.499636243177374

Epoch: 5| Step: 1
Training loss: 3.3731253327133977
Validation loss: 2.5110284431495056

Epoch: 5| Step: 2
Training loss: 2.1847714436844226
Validation loss: 2.500452926584476

Epoch: 5| Step: 3
Training loss: 2.962491958542867
Validation loss: 2.5078182900835078

Epoch: 5| Step: 4
Training loss: 2.4448856066445392
Validation loss: 2.49498144875088

Epoch: 5| Step: 5
Training loss: 2.7722883395828193
Validation loss: 2.4875525128646703

Epoch: 5| Step: 6
Training loss: 2.466026155548114
Validation loss: 2.472869103395335

Epoch: 5| Step: 7
Training loss: 2.1646378506308035
Validation loss: 2.4778393068231916

Epoch: 5| Step: 8
Training loss: 2.684896760799175
Validation loss: 2.464935980702666

Epoch: 5| Step: 9
Training loss: 2.9712332529022114
Validation loss: 2.4602736294323977

Epoch: 5| Step: 10
Training loss: 2.543666948841939
Validation loss: 2.462069705780361

Epoch: 132| Step: 0
Training loss: 2.535117597241209
Validation loss: 2.4685817415577036

Epoch: 5| Step: 1
Training loss: 3.032721722603795
Validation loss: 2.467608541936526

Epoch: 5| Step: 2
Training loss: 2.4741613257934993
Validation loss: 2.4779778850911076

Epoch: 5| Step: 3
Training loss: 2.7085775607593234
Validation loss: 2.492735800455867

Epoch: 5| Step: 4
Training loss: 2.687926236440495
Validation loss: 2.4876834187724737

Epoch: 5| Step: 5
Training loss: 2.0741479434124535
Validation loss: 2.4887922316134294

Epoch: 5| Step: 6
Training loss: 2.997071426207434
Validation loss: 2.5160123674215673

Epoch: 5| Step: 7
Training loss: 2.9288700031307737
Validation loss: 2.525100646058443

Epoch: 5| Step: 8
Training loss: 2.423316477367577
Validation loss: 2.48599181678926

Epoch: 5| Step: 9
Training loss: 2.7096163033955927
Validation loss: 2.4678269645834847

Epoch: 5| Step: 10
Training loss: 3.45407519493576
Validation loss: 2.455122192758991

Epoch: 133| Step: 0
Training loss: 2.6337877046541274
Validation loss: 2.4477253329649016

Epoch: 5| Step: 1
Training loss: 2.2500347558622047
Validation loss: 2.4486834942811386

Epoch: 5| Step: 2
Training loss: 2.929496575810101
Validation loss: 2.450742899652298

Epoch: 5| Step: 3
Training loss: 2.737871822380239
Validation loss: 2.4453699122955803

Epoch: 5| Step: 4
Training loss: 3.6953128871151355
Validation loss: 2.4502576597085928

Epoch: 5| Step: 5
Training loss: 2.8611986358818515
Validation loss: 2.446156583817639

Epoch: 5| Step: 6
Training loss: 2.9156712241152616
Validation loss: 2.4601163771345655

Epoch: 5| Step: 7
Training loss: 2.1505509402519745
Validation loss: 2.4688109461368395

Epoch: 5| Step: 8
Training loss: 2.4827096983823242
Validation loss: 2.470810989035093

Epoch: 5| Step: 9
Training loss: 2.5633686733248693
Validation loss: 2.4788037530235774

Epoch: 5| Step: 10
Training loss: 2.8730760854225483
Validation loss: 2.4865852317560804

Epoch: 134| Step: 0
Training loss: 2.2480839942499116
Validation loss: 2.482025515277911

Epoch: 5| Step: 1
Training loss: 2.8833212468182445
Validation loss: 2.4697012864350856

Epoch: 5| Step: 2
Training loss: 2.7040960078321876
Validation loss: 2.4794728424487644

Epoch: 5| Step: 3
Training loss: 2.9433337781941074
Validation loss: 2.46057073774069

Epoch: 5| Step: 4
Training loss: 3.0719073863374162
Validation loss: 2.454322525260174

Epoch: 5| Step: 5
Training loss: 2.4662193171917015
Validation loss: 2.4448606106374857

Epoch: 5| Step: 6
Training loss: 2.5805684850245885
Validation loss: 2.4489856254512765

Epoch: 5| Step: 7
Training loss: 2.7590488331791425
Validation loss: 2.4507092118874696

Epoch: 5| Step: 8
Training loss: 2.583741514711514
Validation loss: 2.452256200840325

Epoch: 5| Step: 9
Training loss: 2.8772584088917155
Validation loss: 2.4553254317734394

Epoch: 5| Step: 10
Training loss: 2.7693609661486236
Validation loss: 2.4727348150952655

Epoch: 135| Step: 0
Training loss: 2.31170125002617
Validation loss: 2.4818226013545

Epoch: 5| Step: 1
Training loss: 2.478541212498437
Validation loss: 2.494555637346302

Epoch: 5| Step: 2
Training loss: 2.780878106445465
Validation loss: 2.48558940681361

Epoch: 5| Step: 3
Training loss: 2.7001784477603987
Validation loss: 2.5191872374207587

Epoch: 5| Step: 4
Training loss: 2.653073734286891
Validation loss: 2.5308662730358713

Epoch: 5| Step: 5
Training loss: 2.8730817283108587
Validation loss: 2.5540423301575808

Epoch: 5| Step: 6
Training loss: 3.2987134968890683
Validation loss: 2.5596621727017803

Epoch: 5| Step: 7
Training loss: 3.5895678525219283
Validation loss: 2.5262320146222197

Epoch: 5| Step: 8
Training loss: 1.786545561356022
Validation loss: 2.4695852021360074

Epoch: 5| Step: 9
Training loss: 2.4266065093677947
Validation loss: 2.4334464748823583

Epoch: 5| Step: 10
Training loss: 2.899495304520264
Validation loss: 2.443614075418535

Epoch: 136| Step: 0
Training loss: 2.6060077618697792
Validation loss: 2.4561250869211295

Epoch: 5| Step: 1
Training loss: 2.79560311663442
Validation loss: 2.4637978770952653

Epoch: 5| Step: 2
Training loss: 3.108423135259642
Validation loss: 2.4781563341656305

Epoch: 5| Step: 3
Training loss: 2.8392660820651567
Validation loss: 2.4738283896308495

Epoch: 5| Step: 4
Training loss: 2.698272936849762
Validation loss: 2.5103791059229366

Epoch: 5| Step: 5
Training loss: 2.4256492492831883
Validation loss: 2.4922238817650877

Epoch: 5| Step: 6
Training loss: 2.43776750319379
Validation loss: 2.4699713532542464

Epoch: 5| Step: 7
Training loss: 2.8887821406017062
Validation loss: 2.456834392075064

Epoch: 5| Step: 8
Training loss: 3.3208344890699366
Validation loss: 2.441301100831258

Epoch: 5| Step: 9
Training loss: 3.013775510359599
Validation loss: 2.444107358897995

Epoch: 5| Step: 10
Training loss: 2.718822960587104
Validation loss: 2.4578537070737068

Epoch: 137| Step: 0
Training loss: 2.858909694146044
Validation loss: 2.4994526827986845

Epoch: 5| Step: 1
Training loss: 2.8537236633288563
Validation loss: 2.515264849269248

Epoch: 5| Step: 2
Training loss: 2.927296387508416
Validation loss: 2.532046509866936

Epoch: 5| Step: 3
Training loss: 2.3201980305702383
Validation loss: 2.5505965619402864

Epoch: 5| Step: 4
Training loss: 2.976105902787146
Validation loss: 2.575792374931603

Epoch: 5| Step: 5
Training loss: 2.925771145363893
Validation loss: 2.580369490273871

Epoch: 5| Step: 6
Training loss: 3.162595809269281
Validation loss: 2.565731430668977

Epoch: 5| Step: 7
Training loss: 2.8732910052528093
Validation loss: 2.5624646640345126

Epoch: 5| Step: 8
Training loss: 2.4295232294121862
Validation loss: 2.5441493015423466

Epoch: 5| Step: 9
Training loss: 2.55404403002133
Validation loss: 2.5448188285215396

Epoch: 5| Step: 10
Training loss: 3.047229452790134
Validation loss: 2.5379248385836615

Epoch: 138| Step: 0
Training loss: 2.7963512079359774
Validation loss: 2.5288739240568003

Epoch: 5| Step: 1
Training loss: 2.8310137584894983
Validation loss: 2.5189666148432965

Epoch: 5| Step: 2
Training loss: 3.0634342247831525
Validation loss: 2.5163802277754805

Epoch: 5| Step: 3
Training loss: 2.4188681364164624
Validation loss: 2.5172237818091796

Epoch: 5| Step: 4
Training loss: 2.640220746579294
Validation loss: 2.512209544164672

Epoch: 5| Step: 5
Training loss: 2.900906809075639
Validation loss: 2.521983415603936

Epoch: 5| Step: 6
Training loss: 2.302422914156903
Validation loss: 2.5249146298719216

Epoch: 5| Step: 7
Training loss: 2.735989339305788
Validation loss: 2.5197383529991186

Epoch: 5| Step: 8
Training loss: 2.947199452278592
Validation loss: 2.5317076660872115

Epoch: 5| Step: 9
Training loss: 2.746067182648424
Validation loss: 2.535987939926191

Epoch: 5| Step: 10
Training loss: 3.020342363820688
Validation loss: 2.547655544762725

Epoch: 139| Step: 0
Training loss: 2.8160775213679328
Validation loss: 2.5339053724390594

Epoch: 5| Step: 1
Training loss: 2.8139289616698684
Validation loss: 2.515537695343299

Epoch: 5| Step: 2
Training loss: 2.6866598368511365
Validation loss: 2.505734203740239

Epoch: 5| Step: 3
Training loss: 2.8458477289851305
Validation loss: 2.5074343624502196

Epoch: 5| Step: 4
Training loss: 3.2073088327171257
Validation loss: 2.5066122053190143

Epoch: 5| Step: 5
Training loss: 2.20224717420002
Validation loss: 2.513410021759606

Epoch: 5| Step: 6
Training loss: 2.821803494008977
Validation loss: 2.5046002732207815

Epoch: 5| Step: 7
Training loss: 2.9270197815065355
Validation loss: 2.4991117376053835

Epoch: 5| Step: 8
Training loss: 2.225294535140785
Validation loss: 2.488362554699444

Epoch: 5| Step: 9
Training loss: 2.573796655899924
Validation loss: 2.48470445634673

Epoch: 5| Step: 10
Training loss: 2.9884851722700465
Validation loss: 2.4779135185063104

Epoch: 140| Step: 0
Training loss: 2.346760558323543
Validation loss: 2.4693713446642884

Epoch: 5| Step: 1
Training loss: 3.0953630037919853
Validation loss: 2.4652919972427685

Epoch: 5| Step: 2
Training loss: 2.01151584231562
Validation loss: 2.468367269020052

Epoch: 5| Step: 3
Training loss: 2.9835379659987007
Validation loss: 2.480255989611598

Epoch: 5| Step: 4
Training loss: 3.0679697509328805
Validation loss: 2.487798663735046

Epoch: 5| Step: 5
Training loss: 2.2571616109065484
Validation loss: 2.4832196022003257

Epoch: 5| Step: 6
Training loss: 3.381906577509057
Validation loss: 2.4815722109720246

Epoch: 5| Step: 7
Training loss: 2.382343884023544
Validation loss: 2.4683448601337714

Epoch: 5| Step: 8
Training loss: 2.7545572147295743
Validation loss: 2.450884950352724

Epoch: 5| Step: 9
Training loss: 2.8554041238091172
Validation loss: 2.4423854712552786

Epoch: 5| Step: 10
Training loss: 2.5235153516918833
Validation loss: 2.433610510144153

Epoch: 141| Step: 0
Training loss: 2.315874781759856
Validation loss: 2.428977509896048

Epoch: 5| Step: 1
Training loss: 2.741031239935215
Validation loss: 2.4447982358975096

Epoch: 5| Step: 2
Training loss: 2.4949546447484385
Validation loss: 2.4753920930969158

Epoch: 5| Step: 3
Training loss: 2.760992534717165
Validation loss: 2.4973324644227186

Epoch: 5| Step: 4
Training loss: 3.083228049327944
Validation loss: 2.4679980115995677

Epoch: 5| Step: 5
Training loss: 2.862848225697427
Validation loss: 2.4538407481751268

Epoch: 5| Step: 6
Training loss: 2.9622002880578187
Validation loss: 2.4518611545267026

Epoch: 5| Step: 7
Training loss: 2.9261291867443395
Validation loss: 2.4439821157021453

Epoch: 5| Step: 8
Training loss: 2.9827972555595257
Validation loss: 2.4509803348398895

Epoch: 5| Step: 9
Training loss: 2.8646518398531815
Validation loss: 2.452795280984636

Epoch: 5| Step: 10
Training loss: 1.8764353026924296
Validation loss: 2.4592436524488432

Epoch: 142| Step: 0
Training loss: 2.4833201922211936
Validation loss: 2.4612994652977744

Epoch: 5| Step: 1
Training loss: 2.965313337729753
Validation loss: 2.4611416212656

Epoch: 5| Step: 2
Training loss: 2.8429648185214296
Validation loss: 2.463537644967042

Epoch: 5| Step: 3
Training loss: 2.5121268835156068
Validation loss: 2.455609871736212

Epoch: 5| Step: 4
Training loss: 3.1621822091963194
Validation loss: 2.4595435545691324

Epoch: 5| Step: 5
Training loss: 2.331148271156401
Validation loss: 2.464256317379289

Epoch: 5| Step: 6
Training loss: 2.710197237726954
Validation loss: 2.4659404143905395

Epoch: 5| Step: 7
Training loss: 2.702532752982806
Validation loss: 2.4620043849499336

Epoch: 5| Step: 8
Training loss: 2.0549464769656067
Validation loss: 2.470739826236385

Epoch: 5| Step: 9
Training loss: 2.7806308357175817
Validation loss: 2.481471558875683

Epoch: 5| Step: 10
Training loss: 3.283084029852162
Validation loss: 2.4828648072845882

Epoch: 143| Step: 0
Training loss: 2.6113593499792636
Validation loss: 2.4783687627718685

Epoch: 5| Step: 1
Training loss: 2.8682134388306038
Validation loss: 2.486978280500501

Epoch: 5| Step: 2
Training loss: 3.048640751869587
Validation loss: 2.506968235522647

Epoch: 5| Step: 3
Training loss: 2.5975719925832337
Validation loss: 2.5119862477248964

Epoch: 5| Step: 4
Training loss: 2.2233703217105734
Validation loss: 2.504902882417527

Epoch: 5| Step: 5
Training loss: 2.6246096002823056
Validation loss: 2.4921890790092553

Epoch: 5| Step: 6
Training loss: 3.0791710949471462
Validation loss: 2.4862784525306223

Epoch: 5| Step: 7
Training loss: 2.8498391156211462
Validation loss: 2.4605347079267403

Epoch: 5| Step: 8
Training loss: 2.740687468109336
Validation loss: 2.463543245651994

Epoch: 5| Step: 9
Training loss: 2.7941473761473907
Validation loss: 2.4878884802669

Epoch: 5| Step: 10
Training loss: 2.4181061984485086
Validation loss: 2.479998632944043

Epoch: 144| Step: 0
Training loss: 2.5170534236726225
Validation loss: 2.502917059416484

Epoch: 5| Step: 1
Training loss: 2.562738174906871
Validation loss: 2.5012884419200936

Epoch: 5| Step: 2
Training loss: 2.861870349114649
Validation loss: 2.504017661535639

Epoch: 5| Step: 3
Training loss: 2.923550864651259
Validation loss: 2.499656908016823

Epoch: 5| Step: 4
Training loss: 3.04685152484947
Validation loss: 2.47080798526662

Epoch: 5| Step: 5
Training loss: 3.1071502547653655
Validation loss: 2.4581363881350042

Epoch: 5| Step: 6
Training loss: 2.658898861640492
Validation loss: 2.457808771440839

Epoch: 5| Step: 7
Training loss: 2.6414836864296225
Validation loss: 2.4635108287277094

Epoch: 5| Step: 8
Training loss: 2.3378842002378826
Validation loss: 2.457586190210239

Epoch: 5| Step: 9
Training loss: 2.4318702436139357
Validation loss: 2.459625857159231

Epoch: 5| Step: 10
Training loss: 2.7216950174207217
Validation loss: 2.4700633115402577

Epoch: 145| Step: 0
Training loss: 2.8092478280992186
Validation loss: 2.49348336037508

Epoch: 5| Step: 1
Training loss: 2.9565950220567383
Validation loss: 2.5149948216387448

Epoch: 5| Step: 2
Training loss: 3.297659685665854
Validation loss: 2.530929780143465

Epoch: 5| Step: 3
Training loss: 2.4395423549095647
Validation loss: 2.5316251423347054

Epoch: 5| Step: 4
Training loss: 2.8246851281427166
Validation loss: 2.5440249611683883

Epoch: 5| Step: 5
Training loss: 2.9617107257417348
Validation loss: 2.546285171803519

Epoch: 5| Step: 6
Training loss: 2.861449609462427
Validation loss: 2.549979484921153

Epoch: 5| Step: 7
Training loss: 2.7862364398391866
Validation loss: 2.5498897602252764

Epoch: 5| Step: 8
Training loss: 2.114601272982964
Validation loss: 2.55533722473491

Epoch: 5| Step: 9
Training loss: 2.067522349669245
Validation loss: 2.5736445569373783

Epoch: 5| Step: 10
Training loss: 3.2812183196945344
Validation loss: 2.6057909310796603

Epoch: 146| Step: 0
Training loss: 2.231034776581577
Validation loss: 2.5508833249825154

Epoch: 5| Step: 1
Training loss: 2.9564800277801786
Validation loss: 2.543427422468368

Epoch: 5| Step: 2
Training loss: 2.6753034401744555
Validation loss: 2.557781228677602

Epoch: 5| Step: 3
Training loss: 2.5429828133611703
Validation loss: 2.568289480697461

Epoch: 5| Step: 4
Training loss: 2.930722798842843
Validation loss: 2.5762962102263596

Epoch: 5| Step: 5
Training loss: 2.844687003565488
Validation loss: 2.5598766285416024

Epoch: 5| Step: 6
Training loss: 2.6429658705390944
Validation loss: 2.53687660548796

Epoch: 5| Step: 7
Training loss: 2.830793439082226
Validation loss: 2.5160183999897625

Epoch: 5| Step: 8
Training loss: 2.921618608455581
Validation loss: 2.504125568881955

Epoch: 5| Step: 9
Training loss: 2.7546624626627354
Validation loss: 2.488791776320597

Epoch: 5| Step: 10
Training loss: 3.221691380179221
Validation loss: 2.4809173051804834

Epoch: 147| Step: 0
Training loss: 2.9222299288836227
Validation loss: 2.456476673883952

Epoch: 5| Step: 1
Training loss: 2.4227393792045278
Validation loss: 2.4610800404114626

Epoch: 5| Step: 2
Training loss: 2.9321017071100046
Validation loss: 2.4459084977654273

Epoch: 5| Step: 3
Training loss: 2.5085047066613777
Validation loss: 2.4489642744715927

Epoch: 5| Step: 4
Training loss: 2.789941814731957
Validation loss: 2.463435779377101

Epoch: 5| Step: 5
Training loss: 2.566056737223459
Validation loss: 2.481601583076881

Epoch: 5| Step: 6
Training loss: 2.5113612464884
Validation loss: 2.523235230012851

Epoch: 5| Step: 7
Training loss: 2.6699854543911203
Validation loss: 2.5476801128345152

Epoch: 5| Step: 8
Training loss: 3.1644645529666504
Validation loss: 2.4732419777436148

Epoch: 5| Step: 9
Training loss: 2.956713882407609
Validation loss: 2.440998104114635

Epoch: 5| Step: 10
Training loss: 2.57062925108844
Validation loss: 2.4389829560281235

Epoch: 148| Step: 0
Training loss: 2.952007102296137
Validation loss: 2.4386087361797775

Epoch: 5| Step: 1
Training loss: 2.8095669181201255
Validation loss: 2.438787433225993

Epoch: 5| Step: 2
Training loss: 2.3095163222085286
Validation loss: 2.448825041545813

Epoch: 5| Step: 3
Training loss: 2.723904076079026
Validation loss: 2.4506546958096616

Epoch: 5| Step: 4
Training loss: 2.717486032908043
Validation loss: 2.446966666518025

Epoch: 5| Step: 5
Training loss: 2.7297371032784707
Validation loss: 2.4813055051926494

Epoch: 5| Step: 6
Training loss: 2.662627071160072
Validation loss: 2.501585662614249

Epoch: 5| Step: 7
Training loss: 2.677358699742375
Validation loss: 2.5194651345814285

Epoch: 5| Step: 8
Training loss: 3.184704321247034
Validation loss: 2.503233068066826

Epoch: 5| Step: 9
Training loss: 2.5939316283827933
Validation loss: 2.510184763958704

Epoch: 5| Step: 10
Training loss: 2.3929382302345923
Validation loss: 2.499629770572793

Epoch: 149| Step: 0
Training loss: 2.7321857516699737
Validation loss: 2.4885900095341227

Epoch: 5| Step: 1
Training loss: 2.760257145332988
Validation loss: 2.486163675882212

Epoch: 5| Step: 2
Training loss: 2.439945656843531
Validation loss: 2.4889578640913737

Epoch: 5| Step: 3
Training loss: 2.7802784969604035
Validation loss: 2.4931562898106443

Epoch: 5| Step: 4
Training loss: 2.3763417920840375
Validation loss: 2.4871986705051325

Epoch: 5| Step: 5
Training loss: 2.5571505837198174
Validation loss: 2.482419513173841

Epoch: 5| Step: 6
Training loss: 2.815241600631814
Validation loss: 2.483134872336658

Epoch: 5| Step: 7
Training loss: 3.172009996068917
Validation loss: 2.4581168645872014

Epoch: 5| Step: 8
Training loss: 2.6650882659093846
Validation loss: 2.4630719599758994

Epoch: 5| Step: 9
Training loss: 2.366991494502333
Validation loss: 2.4404820138173564

Epoch: 5| Step: 10
Training loss: 2.821093253064594
Validation loss: 2.4290334845248664

Epoch: 150| Step: 0
Training loss: 2.8645719400815097
Validation loss: 2.4260277327217863

Epoch: 5| Step: 1
Training loss: 3.0510930525981657
Validation loss: 2.416681579937038

Epoch: 5| Step: 2
Training loss: 2.5304142078387923
Validation loss: 2.4273926060226576

Epoch: 5| Step: 3
Training loss: 2.1125795112408663
Validation loss: 2.4257972820721116

Epoch: 5| Step: 4
Training loss: 2.322064184847664
Validation loss: 2.4226327886218977

Epoch: 5| Step: 5
Training loss: 2.5186422509557724
Validation loss: 2.425685163143182

Epoch: 5| Step: 6
Training loss: 2.1575340096808873
Validation loss: 2.4307598744978467

Epoch: 5| Step: 7
Training loss: 2.5833608461781257
Validation loss: 2.4457160663606126

Epoch: 5| Step: 8
Training loss: 3.3567599742034075
Validation loss: 2.4829715493169497

Epoch: 5| Step: 9
Training loss: 3.2782849675541037
Validation loss: 2.5163492892406136

Epoch: 5| Step: 10
Training loss: 2.296006226534492
Validation loss: 2.552584402599538

Epoch: 151| Step: 0
Training loss: 2.1759445156568873
Validation loss: 2.583817545445689

Epoch: 5| Step: 1
Training loss: 3.097307721959786
Validation loss: 2.569240915836093

Epoch: 5| Step: 2
Training loss: 2.3521834152549084
Validation loss: 2.5348156317929504

Epoch: 5| Step: 3
Training loss: 2.777337740906386
Validation loss: 2.4558928570005154

Epoch: 5| Step: 4
Training loss: 2.329408125625211
Validation loss: 2.424227426490462

Epoch: 5| Step: 5
Training loss: 2.3533625509413323
Validation loss: 2.4192326066713563

Epoch: 5| Step: 6
Training loss: 2.7207779610467795
Validation loss: 2.4248577516828167

Epoch: 5| Step: 7
Training loss: 2.8141949103010018
Validation loss: 2.419184367966019

Epoch: 5| Step: 8
Training loss: 3.0782074118488714
Validation loss: 2.425065625521355

Epoch: 5| Step: 9
Training loss: 2.988991247864331
Validation loss: 2.43290260429387

Epoch: 5| Step: 10
Training loss: 3.09571667978105
Validation loss: 2.4303981771854195

Epoch: 152| Step: 0
Training loss: 2.3575077373098545
Validation loss: 2.4341476111183944

Epoch: 5| Step: 1
Training loss: 3.067375506149767
Validation loss: 2.437912184890898

Epoch: 5| Step: 2
Training loss: 2.7397638026990716
Validation loss: 2.426610514447972

Epoch: 5| Step: 3
Training loss: 2.625728233685206
Validation loss: 2.4292098402357016

Epoch: 5| Step: 4
Training loss: 2.2404665839085482
Validation loss: 2.424852366129833

Epoch: 5| Step: 5
Training loss: 3.1972754681621542
Validation loss: 2.42077365991115

Epoch: 5| Step: 6
Training loss: 2.790744989940312
Validation loss: 2.414251379396271

Epoch: 5| Step: 7
Training loss: 2.8034021519103702
Validation loss: 2.4191031062342847

Epoch: 5| Step: 8
Training loss: 2.1602151873034647
Validation loss: 2.4315431412800126

Epoch: 5| Step: 9
Training loss: 2.778442079795364
Validation loss: 2.4364657483554515

Epoch: 5| Step: 10
Training loss: 3.0515281163557493
Validation loss: 2.4561203575744996

Epoch: 153| Step: 0
Training loss: 2.7318668742551027
Validation loss: 2.4821811575225268

Epoch: 5| Step: 1
Training loss: 2.86840229129596
Validation loss: 2.499836897913224

Epoch: 5| Step: 2
Training loss: 2.7324353995544044
Validation loss: 2.5084705191668504

Epoch: 5| Step: 3
Training loss: 2.571628871185915
Validation loss: 2.4981496331281305

Epoch: 5| Step: 4
Training loss: 2.215677847722935
Validation loss: 2.488045115854074

Epoch: 5| Step: 5
Training loss: 2.8894058543411782
Validation loss: 2.4774753426341083

Epoch: 5| Step: 6
Training loss: 2.187489754789066
Validation loss: 2.472654292009577

Epoch: 5| Step: 7
Training loss: 2.7209023911346986
Validation loss: 2.459904583803695

Epoch: 5| Step: 8
Training loss: 2.9091896858568536
Validation loss: 2.4584242183625435

Epoch: 5| Step: 9
Training loss: 2.8007026778389994
Validation loss: 2.443916059146078

Epoch: 5| Step: 10
Training loss: 2.554751240812949
Validation loss: 2.4272946047435306

Epoch: 154| Step: 0
Training loss: 2.434823939168106
Validation loss: 2.4316653341365746

Epoch: 5| Step: 1
Training loss: 2.64418214553196
Validation loss: 2.42464461991881

Epoch: 5| Step: 2
Training loss: 2.29496249548492
Validation loss: 2.4260670763339363

Epoch: 5| Step: 3
Training loss: 2.585614602019841
Validation loss: 2.436050354183681

Epoch: 5| Step: 4
Training loss: 3.0591627349315607
Validation loss: 2.435812137255816

Epoch: 5| Step: 5
Training loss: 2.761462770331603
Validation loss: 2.4450200268412394

Epoch: 5| Step: 6
Training loss: 2.715323119070858
Validation loss: 2.4689370195219706

Epoch: 5| Step: 7
Training loss: 2.8445264154616807
Validation loss: 2.483166272191004

Epoch: 5| Step: 8
Training loss: 2.2093178575779873
Validation loss: 2.480432755481466

Epoch: 5| Step: 9
Training loss: 2.667714767319203
Validation loss: 2.475691364487785

Epoch: 5| Step: 10
Training loss: 2.800354226730257
Validation loss: 2.4665933838689402

Epoch: 155| Step: 0
Training loss: 2.5902266873754867
Validation loss: 2.437998223008603

Epoch: 5| Step: 1
Training loss: 2.6558729913976586
Validation loss: 2.4216850171843762

Epoch: 5| Step: 2
Training loss: 2.6456898527715045
Validation loss: 2.4085324067144236

Epoch: 5| Step: 3
Training loss: 2.680235247891369
Validation loss: 2.40503992583727

Epoch: 5| Step: 4
Training loss: 2.978390910555003
Validation loss: 2.402283091846033

Epoch: 5| Step: 5
Training loss: 2.9191491779134204
Validation loss: 2.399083293640182

Epoch: 5| Step: 6
Training loss: 2.8545484821146694
Validation loss: 2.4006940946767252

Epoch: 5| Step: 7
Training loss: 2.7144160311112246
Validation loss: 2.3972382776257297

Epoch: 5| Step: 8
Training loss: 2.5140970458886907
Validation loss: 2.40916072598688

Epoch: 5| Step: 9
Training loss: 2.3831776823778146
Validation loss: 2.424664690004438

Epoch: 5| Step: 10
Training loss: 2.090653022156358
Validation loss: 2.426816471883319

Epoch: 156| Step: 0
Training loss: 2.646332030468705
Validation loss: 2.449947431367431

Epoch: 5| Step: 1
Training loss: 2.7570343216457105
Validation loss: 2.4849378098334562

Epoch: 5| Step: 2
Training loss: 2.971137442055645
Validation loss: 2.4972200401203204

Epoch: 5| Step: 3
Training loss: 2.7407414897663744
Validation loss: 2.506813865333809

Epoch: 5| Step: 4
Training loss: 2.7126803992970623
Validation loss: 2.4977082905602175

Epoch: 5| Step: 5
Training loss: 2.7395876653562072
Validation loss: 2.4803533773839814

Epoch: 5| Step: 6
Training loss: 2.4799061054482685
Validation loss: 2.4688711472850833

Epoch: 5| Step: 7
Training loss: 2.6437069215263387
Validation loss: 2.46036905422174

Epoch: 5| Step: 8
Training loss: 2.7570604374141308
Validation loss: 2.460399873536294

Epoch: 5| Step: 9
Training loss: 2.243273854008005
Validation loss: 2.443715891293056

Epoch: 5| Step: 10
Training loss: 2.288586459606292
Validation loss: 2.445656270103042

Epoch: 157| Step: 0
Training loss: 2.3849221817852646
Validation loss: 2.4449824886607985

Epoch: 5| Step: 1
Training loss: 2.871013863418787
Validation loss: 2.44690211175019

Epoch: 5| Step: 2
Training loss: 2.034956733749797
Validation loss: 2.438572818162383

Epoch: 5| Step: 3
Training loss: 3.2009832898043133
Validation loss: 2.4489778528201396

Epoch: 5| Step: 4
Training loss: 2.4038065604837278
Validation loss: 2.447303541413669

Epoch: 5| Step: 5
Training loss: 2.9333131861717296
Validation loss: 2.4582009138174454

Epoch: 5| Step: 6
Training loss: 2.5501764348644564
Validation loss: 2.4580628924342514

Epoch: 5| Step: 7
Training loss: 2.12114208299847
Validation loss: 2.4686053778750856

Epoch: 5| Step: 8
Training loss: 2.867684219948102
Validation loss: 2.46813972877395

Epoch: 5| Step: 9
Training loss: 2.7143240671388105
Validation loss: 2.4595886878152773

Epoch: 5| Step: 10
Training loss: 2.8108066123358046
Validation loss: 2.4757206458588765

Epoch: 158| Step: 0
Training loss: 2.6277197417646665
Validation loss: 2.473382059453775

Epoch: 5| Step: 1
Training loss: 2.786458228755961
Validation loss: 2.4609666964870596

Epoch: 5| Step: 2
Training loss: 2.4272220773838256
Validation loss: 2.460805176515705

Epoch: 5| Step: 3
Training loss: 2.903911839547267
Validation loss: 2.4598389459711996

Epoch: 5| Step: 4
Training loss: 2.468531635139664
Validation loss: 2.4666071457930503

Epoch: 5| Step: 5
Training loss: 2.358258924444922
Validation loss: 2.4426347064762264

Epoch: 5| Step: 6
Training loss: 2.4152041208000194
Validation loss: 2.440677255913993

Epoch: 5| Step: 7
Training loss: 3.1722509602946505
Validation loss: 2.4369152199553845

Epoch: 5| Step: 8
Training loss: 2.548312477773281
Validation loss: 2.4365220859852723

Epoch: 5| Step: 9
Training loss: 2.474458107242778
Validation loss: 2.4407938065407193

Epoch: 5| Step: 10
Training loss: 2.5082360025914716
Validation loss: 2.4542231988860954

Epoch: 159| Step: 0
Training loss: 2.5476977183813636
Validation loss: 2.4538274015069663

Epoch: 5| Step: 1
Training loss: 2.2844822598806123
Validation loss: 2.4440640082476737

Epoch: 5| Step: 2
Training loss: 2.766785286654664
Validation loss: 2.4443843563198406

Epoch: 5| Step: 3
Training loss: 2.9233791131408102
Validation loss: 2.4359114718631685

Epoch: 5| Step: 4
Training loss: 2.5227216998576876
Validation loss: 2.4261126632769563

Epoch: 5| Step: 5
Training loss: 2.6507675139062576
Validation loss: 2.4169734039521424

Epoch: 5| Step: 6
Training loss: 2.1956024521458004
Validation loss: 2.407346750660413

Epoch: 5| Step: 7
Training loss: 2.3034054051048227
Validation loss: 2.410562259515976

Epoch: 5| Step: 8
Training loss: 3.12121551237963
Validation loss: 2.406206097286902

Epoch: 5| Step: 9
Training loss: 2.8678223949011015
Validation loss: 2.3999988769542293

Epoch: 5| Step: 10
Training loss: 2.5799485664268027
Validation loss: 2.4086836068328794

Epoch: 160| Step: 0
Training loss: 2.7976402216209553
Validation loss: 2.4196543928873773

Epoch: 5| Step: 1
Training loss: 2.7047927210112155
Validation loss: 2.4310046407414063

Epoch: 5| Step: 2
Training loss: 2.5571891831466242
Validation loss: 2.4375001220029975

Epoch: 5| Step: 3
Training loss: 2.567612363145085
Validation loss: 2.4508201923048674

Epoch: 5| Step: 4
Training loss: 2.273667051910978
Validation loss: 2.4455129098409243

Epoch: 5| Step: 5
Training loss: 2.8756036539328083
Validation loss: 2.449100339290398

Epoch: 5| Step: 6
Training loss: 2.2254229925746984
Validation loss: 2.447850728679638

Epoch: 5| Step: 7
Training loss: 2.9478837585409687
Validation loss: 2.449936379198262

Epoch: 5| Step: 8
Training loss: 2.317184549073844
Validation loss: 2.443563590267612

Epoch: 5| Step: 9
Training loss: 2.4371273049283344
Validation loss: 2.4517629831951053

Epoch: 5| Step: 10
Training loss: 2.8771805165142794
Validation loss: 2.4444243504688683

Epoch: 161| Step: 0
Training loss: 3.014231780001627
Validation loss: 2.432539938254508

Epoch: 5| Step: 1
Training loss: 2.581573399565891
Validation loss: 2.4162102042947713

Epoch: 5| Step: 2
Training loss: 2.611515377980281
Validation loss: 2.4127174243760527

Epoch: 5| Step: 3
Training loss: 2.124306733980905
Validation loss: 2.4128029764557883

Epoch: 5| Step: 4
Training loss: 2.6364237754563478
Validation loss: 2.411440018393602

Epoch: 5| Step: 5
Training loss: 2.804179025956267
Validation loss: 2.410701926938088

Epoch: 5| Step: 6
Training loss: 2.429380145978961
Validation loss: 2.4192611689021137

Epoch: 5| Step: 7
Training loss: 2.614871147292608
Validation loss: 2.416155072149976

Epoch: 5| Step: 8
Training loss: 2.854327139322668
Validation loss: 2.4172895482402232

Epoch: 5| Step: 9
Training loss: 2.3803867687785174
Validation loss: 2.4244226484105145

Epoch: 5| Step: 10
Training loss: 2.391192400049644
Validation loss: 2.424669935880004

Epoch: 162| Step: 0
Training loss: 2.8996012117521994
Validation loss: 2.42564466238305

Epoch: 5| Step: 1
Training loss: 2.5631499047826303
Validation loss: 2.4319147735532822

Epoch: 5| Step: 2
Training loss: 2.739499070258069
Validation loss: 2.4360536691654477

Epoch: 5| Step: 3
Training loss: 2.656884869270238
Validation loss: 2.4338939571583995

Epoch: 5| Step: 4
Training loss: 2.785510967506259
Validation loss: 2.4334734643994493

Epoch: 5| Step: 5
Training loss: 2.5836091868467426
Validation loss: 2.4333538007641

Epoch: 5| Step: 6
Training loss: 2.1862534377178475
Validation loss: 2.4409865157082904

Epoch: 5| Step: 7
Training loss: 2.549788604650543
Validation loss: 2.4474040086104676

Epoch: 5| Step: 8
Training loss: 2.380268377190865
Validation loss: 2.4581420449288562

Epoch: 5| Step: 9
Training loss: 2.896173379450106
Validation loss: 2.471207592398883

Epoch: 5| Step: 10
Training loss: 2.072262173433153
Validation loss: 2.4724357737502576

Epoch: 163| Step: 0
Training loss: 2.322806203180054
Validation loss: 2.445941471848808

Epoch: 5| Step: 1
Training loss: 2.6326777483134625
Validation loss: 2.42336899864929

Epoch: 5| Step: 2
Training loss: 1.826342308536669
Validation loss: 2.4064389769754007

Epoch: 5| Step: 3
Training loss: 2.95807406583322
Validation loss: 2.4113103732194126

Epoch: 5| Step: 4
Training loss: 2.2486089008842205
Validation loss: 2.406693467633029

Epoch: 5| Step: 5
Training loss: 2.658149488862348
Validation loss: 2.4095486682681115

Epoch: 5| Step: 6
Training loss: 2.7787373368922377
Validation loss: 2.4259696640110913

Epoch: 5| Step: 7
Training loss: 3.142842890347948
Validation loss: 2.4377921102674334

Epoch: 5| Step: 8
Training loss: 2.689702927589603
Validation loss: 2.4732838820226624

Epoch: 5| Step: 9
Training loss: 2.712958997574783
Validation loss: 2.4973605727871515

Epoch: 5| Step: 10
Training loss: 2.4513587181340726
Validation loss: 2.528489822301641

Epoch: 164| Step: 0
Training loss: 2.4807826526895203
Validation loss: 2.517710032672874

Epoch: 5| Step: 1
Training loss: 2.263922847760942
Validation loss: 2.478507989452283

Epoch: 5| Step: 2
Training loss: 2.5759236503209317
Validation loss: 2.4480602210966143

Epoch: 5| Step: 3
Training loss: 2.4408079344979012
Validation loss: 2.416610939548843

Epoch: 5| Step: 4
Training loss: 3.0943149859934986
Validation loss: 2.410811524329872

Epoch: 5| Step: 5
Training loss: 2.5297406252866295
Validation loss: 2.408179146004121

Epoch: 5| Step: 6
Training loss: 2.3527519791634997
Validation loss: 2.4006684644777416

Epoch: 5| Step: 7
Training loss: 3.078342178351296
Validation loss: 2.4017476711366914

Epoch: 5| Step: 8
Training loss: 2.5681809512050204
Validation loss: 2.410364358974175

Epoch: 5| Step: 9
Training loss: 2.6090382798450893
Validation loss: 2.4207157606373317

Epoch: 5| Step: 10
Training loss: 2.719224910254543
Validation loss: 2.4215861116111457

Epoch: 165| Step: 0
Training loss: 2.8545785500000025
Validation loss: 2.437224732015053

Epoch: 5| Step: 1
Training loss: 2.7141134254013046
Validation loss: 2.473565711756623

Epoch: 5| Step: 2
Training loss: 2.653485194401959
Validation loss: 2.5099615733744027

Epoch: 5| Step: 3
Training loss: 2.598545742475688
Validation loss: 2.5143405272203565

Epoch: 5| Step: 4
Training loss: 2.165086304351803
Validation loss: 2.501174389428362

Epoch: 5| Step: 5
Training loss: 2.5888689372813305
Validation loss: 2.49065169027283

Epoch: 5| Step: 6
Training loss: 2.5897730476774528
Validation loss: 2.461067627804661

Epoch: 5| Step: 7
Training loss: 2.8870837815762846
Validation loss: 2.4404438138884164

Epoch: 5| Step: 8
Training loss: 2.756204541581887
Validation loss: 2.42163627789674

Epoch: 5| Step: 9
Training loss: 2.431489527653697
Validation loss: 2.419215939783395

Epoch: 5| Step: 10
Training loss: 2.320074615100775
Validation loss: 2.416894814079511

Epoch: 166| Step: 0
Training loss: 2.5141122190728784
Validation loss: 2.4157903068491655

Epoch: 5| Step: 1
Training loss: 2.1842652518408037
Validation loss: 2.4095265592742114

Epoch: 5| Step: 2
Training loss: 2.9856256390994744
Validation loss: 2.4093435788153004

Epoch: 5| Step: 3
Training loss: 2.7522598864523067
Validation loss: 2.4088072700669203

Epoch: 5| Step: 4
Training loss: 2.5656568109396463
Validation loss: 2.411410417339625

Epoch: 5| Step: 5
Training loss: 2.5387480086183087
Validation loss: 2.4149687137665055

Epoch: 5| Step: 6
Training loss: 2.286740528207599
Validation loss: 2.434847006122598

Epoch: 5| Step: 7
Training loss: 2.753134848049879
Validation loss: 2.441185114733099

Epoch: 5| Step: 8
Training loss: 2.706372553845372
Validation loss: 2.4493846742575505

Epoch: 5| Step: 9
Training loss: 2.6925115654855483
Validation loss: 2.465386399029082

Epoch: 5| Step: 10
Training loss: 2.3119773274072277
Validation loss: 2.4500474547887694

Epoch: 167| Step: 0
Training loss: 2.9677935213926383
Validation loss: 2.4516753237242916

Epoch: 5| Step: 1
Training loss: 2.981451070150844
Validation loss: 2.4463096508567714

Epoch: 5| Step: 2
Training loss: 2.025932511737313
Validation loss: 2.4384842329828524

Epoch: 5| Step: 3
Training loss: 2.506411342231615
Validation loss: 2.43625989267857

Epoch: 5| Step: 4
Training loss: 3.016091740515701
Validation loss: 2.440942956293527

Epoch: 5| Step: 5
Training loss: 2.3005754414396784
Validation loss: 2.431566298926547

Epoch: 5| Step: 6
Training loss: 2.7905114094169954
Validation loss: 2.44394419706034

Epoch: 5| Step: 7
Training loss: 2.1230466503995973
Validation loss: 2.444502837110423

Epoch: 5| Step: 8
Training loss: 2.8084278720899944
Validation loss: 2.4497412471484585

Epoch: 5| Step: 9
Training loss: 2.3226030648381686
Validation loss: 2.450868134700796

Epoch: 5| Step: 10
Training loss: 2.251368212606581
Validation loss: 2.4516216588862445

Epoch: 168| Step: 0
Training loss: 2.2452234854471107
Validation loss: 2.4676995951042793

Epoch: 5| Step: 1
Training loss: 2.595126970011008
Validation loss: 2.475396140932917

Epoch: 5| Step: 2
Training loss: 2.6496037528849943
Validation loss: 2.4799287716804987

Epoch: 5| Step: 3
Training loss: 3.0255258528727476
Validation loss: 2.4841236903984707

Epoch: 5| Step: 4
Training loss: 2.7819654423194264
Validation loss: 2.469351980021319

Epoch: 5| Step: 5
Training loss: 2.5270755395562063
Validation loss: 2.4747078758907484

Epoch: 5| Step: 6
Training loss: 2.532233153252607
Validation loss: 2.4602104575382753

Epoch: 5| Step: 7
Training loss: 2.6827657829931644
Validation loss: 2.465304942840496

Epoch: 5| Step: 8
Training loss: 2.5039593814443837
Validation loss: 2.459681985337464

Epoch: 5| Step: 9
Training loss: 2.28052195597699
Validation loss: 2.463391344155361

Epoch: 5| Step: 10
Training loss: 2.6316546602400055
Validation loss: 2.467342127400924

Epoch: 169| Step: 0
Training loss: 2.706096625441898
Validation loss: 2.4725014006737225

Epoch: 5| Step: 1
Training loss: 2.550830881474224
Validation loss: 2.4770541298505746

Epoch: 5| Step: 2
Training loss: 2.9423727648766382
Validation loss: 2.45334777071342

Epoch: 5| Step: 3
Training loss: 2.7694315603201614
Validation loss: 2.4531068264964935

Epoch: 5| Step: 4
Training loss: 2.2998550701089533
Validation loss: 2.4468171976773525

Epoch: 5| Step: 5
Training loss: 2.3416553546817824
Validation loss: 2.4430775812740975

Epoch: 5| Step: 6
Training loss: 1.9440083249270987
Validation loss: 2.442106049948966

Epoch: 5| Step: 7
Training loss: 2.838142315598157
Validation loss: 2.4309915356870127

Epoch: 5| Step: 8
Training loss: 2.205411549609146
Validation loss: 2.4400039466484396

Epoch: 5| Step: 9
Training loss: 2.886782179614365
Validation loss: 2.4541510933735124

Epoch: 5| Step: 10
Training loss: 2.6305518703396835
Validation loss: 2.4523281843518214

Epoch: 170| Step: 0
Training loss: 2.406010306173751
Validation loss: 2.4695638185198296

Epoch: 5| Step: 1
Training loss: 2.316151391044064
Validation loss: 2.478258685516472

Epoch: 5| Step: 2
Training loss: 2.173694644199015
Validation loss: 2.497953970239029

Epoch: 5| Step: 3
Training loss: 2.4319710258088056
Validation loss: 2.4985822123410752

Epoch: 5| Step: 4
Training loss: 2.5703026675700045
Validation loss: 2.501789940177435

Epoch: 5| Step: 5
Training loss: 2.890308589629511
Validation loss: 2.4854096837622097

Epoch: 5| Step: 6
Training loss: 2.934876914359682
Validation loss: 2.459402125933283

Epoch: 5| Step: 7
Training loss: 2.405938859119916
Validation loss: 2.446646278294498

Epoch: 5| Step: 8
Training loss: 3.075093436953761
Validation loss: 2.4442702119745014

Epoch: 5| Step: 9
Training loss: 2.565943009883162
Validation loss: 2.430865910448854

Epoch: 5| Step: 10
Training loss: 2.3569561009096014
Validation loss: 2.427387152164439

Epoch: 171| Step: 0
Training loss: 2.6861656779975616
Validation loss: 2.4341234106027456

Epoch: 5| Step: 1
Training loss: 2.314241011673919
Validation loss: 2.4251697095665747

Epoch: 5| Step: 2
Training loss: 2.634308794486142
Validation loss: 2.4309232631902837

Epoch: 5| Step: 3
Training loss: 2.7263190480495516
Validation loss: 2.4267606584551205

Epoch: 5| Step: 4
Training loss: 1.9917773254596227
Validation loss: 2.4353666243364636

Epoch: 5| Step: 5
Training loss: 2.342591368075009
Validation loss: 2.432629624083101

Epoch: 5| Step: 6
Training loss: 2.554435600904094
Validation loss: 2.431117469732502

Epoch: 5| Step: 7
Training loss: 2.8119987888903335
Validation loss: 2.445810754142839

Epoch: 5| Step: 8
Training loss: 3.062172697054644
Validation loss: 2.456179231080659

Epoch: 5| Step: 9
Training loss: 2.7498187092065174
Validation loss: 2.4690185126704307

Epoch: 5| Step: 10
Training loss: 2.244105140398852
Validation loss: 2.4885745045794057

Epoch: 172| Step: 0
Training loss: 2.1636271675809096
Validation loss: 2.5014259117391284

Epoch: 5| Step: 1
Training loss: 2.402120043255431
Validation loss: 2.518266615075009

Epoch: 5| Step: 2
Training loss: 2.13547693183031
Validation loss: 2.535873868457063

Epoch: 5| Step: 3
Training loss: 3.494354053885532
Validation loss: 2.507338123666599

Epoch: 5| Step: 4
Training loss: 2.571507973050569
Validation loss: 2.4886107310738277

Epoch: 5| Step: 5
Training loss: 2.1288802679033783
Validation loss: 2.487069452252551

Epoch: 5| Step: 6
Training loss: 2.07637282768964
Validation loss: 2.496714477808537

Epoch: 5| Step: 7
Training loss: 2.998926924478864
Validation loss: 2.517686467364669

Epoch: 5| Step: 8
Training loss: 2.881539081626843
Validation loss: 2.52774567559077

Epoch: 5| Step: 9
Training loss: 2.147686525355562
Validation loss: 2.47795430196443

Epoch: 5| Step: 10
Training loss: 2.7749328880099036
Validation loss: 2.4751573036573005

Epoch: 173| Step: 0
Training loss: 3.2917547737272965
Validation loss: 2.4580828221156517

Epoch: 5| Step: 1
Training loss: 2.6213584345562957
Validation loss: 2.4708196983866633

Epoch: 5| Step: 2
Training loss: 2.4065640727584015
Validation loss: 2.4655853196548465

Epoch: 5| Step: 3
Training loss: 2.209759293820754
Validation loss: 2.481726675094046

Epoch: 5| Step: 4
Training loss: 2.1584115734672324
Validation loss: 2.4691194201049953

Epoch: 5| Step: 5
Training loss: 1.8649383150182857
Validation loss: 2.458830911521721

Epoch: 5| Step: 6
Training loss: 2.808980562315979
Validation loss: 2.448157985908545

Epoch: 5| Step: 7
Training loss: 2.479786408055669
Validation loss: 2.44452584104885

Epoch: 5| Step: 8
Training loss: 2.088054711198734
Validation loss: 2.4627587905720523

Epoch: 5| Step: 9
Training loss: 3.052224808018984
Validation loss: 2.467347325658776

Epoch: 5| Step: 10
Training loss: 2.385184086506926
Validation loss: 2.459775467963759

Epoch: 174| Step: 0
Training loss: 2.6975849689044513
Validation loss: 2.4637282692235423

Epoch: 5| Step: 1
Training loss: 2.1682720350221016
Validation loss: 2.470646049245252

Epoch: 5| Step: 2
Training loss: 2.4964950788110585
Validation loss: 2.4610748882913986

Epoch: 5| Step: 3
Training loss: 2.1453587893099337
Validation loss: 2.4725960269585965

Epoch: 5| Step: 4
Training loss: 2.6391958850061874
Validation loss: 2.4680802161137154

Epoch: 5| Step: 5
Training loss: 2.553623082708421
Validation loss: 2.488084031073781

Epoch: 5| Step: 6
Training loss: 2.462228200406385
Validation loss: 2.5151026107009997

Epoch: 5| Step: 7
Training loss: 2.0064106957082077
Validation loss: 2.50336632045594

Epoch: 5| Step: 8
Training loss: 2.936693121292632
Validation loss: 2.4839513800229485

Epoch: 5| Step: 9
Training loss: 2.865036659205908
Validation loss: 2.4883126487894516

Epoch: 5| Step: 10
Training loss: 2.6869915325966955
Validation loss: 2.4755954108692357

Epoch: 175| Step: 0
Training loss: 2.430460816005312
Validation loss: 2.479157214527168

Epoch: 5| Step: 1
Training loss: 2.0989014749579864
Validation loss: 2.4734837890482617

Epoch: 5| Step: 2
Training loss: 2.4939263953059756
Validation loss: 2.4681509964950634

Epoch: 5| Step: 3
Training loss: 2.631718892341677
Validation loss: 2.464826636424564

Epoch: 5| Step: 4
Training loss: 2.079061540941424
Validation loss: 2.4654684265065425

Epoch: 5| Step: 5
Training loss: 3.0694611512003256
Validation loss: 2.4585053957428253

Epoch: 5| Step: 6
Training loss: 2.325212128509121
Validation loss: 2.486817189212808

Epoch: 5| Step: 7
Training loss: 2.9495880097888643
Validation loss: 2.5074409447548236

Epoch: 5| Step: 8
Training loss: 2.2117051588022885
Validation loss: 2.494994192007942

Epoch: 5| Step: 9
Training loss: 2.6533434055686715
Validation loss: 2.5054642468546184

Epoch: 5| Step: 10
Training loss: 2.641718350294966
Validation loss: 2.481038709778733

Epoch: 176| Step: 0
Training loss: 3.2222231302223534
Validation loss: 2.481346234966337

Epoch: 5| Step: 1
Training loss: 2.217085415383274
Validation loss: 2.483191122126358

Epoch: 5| Step: 2
Training loss: 2.233897978540612
Validation loss: 2.4836646357090175

Epoch: 5| Step: 3
Training loss: 2.514230851249834
Validation loss: 2.4710609084568707

Epoch: 5| Step: 4
Training loss: 2.0579902589528514
Validation loss: 2.463949344628578

Epoch: 5| Step: 5
Training loss: 2.5852660261025777
Validation loss: 2.45126054341377

Epoch: 5| Step: 6
Training loss: 2.3583482946274015
Validation loss: 2.458146768821491

Epoch: 5| Step: 7
Training loss: 2.4783331380748694
Validation loss: 2.4593749372895055

Epoch: 5| Step: 8
Training loss: 2.8183623358168353
Validation loss: 2.4778817572250267

Epoch: 5| Step: 9
Training loss: 2.178967756987797
Validation loss: 2.4753671224058875

Epoch: 5| Step: 10
Training loss: 2.6352742172965415
Validation loss: 2.489174903596653

Epoch: 177| Step: 0
Training loss: 2.279061194936927
Validation loss: 2.4914660977610574

Epoch: 5| Step: 1
Training loss: 2.392919000749237
Validation loss: 2.5097234156207255

Epoch: 5| Step: 2
Training loss: 2.321258249427381
Validation loss: 2.5354889151292004

Epoch: 5| Step: 3
Training loss: 2.269548373395762
Validation loss: 2.548878419101957

Epoch: 5| Step: 4
Training loss: 1.8867815532459473
Validation loss: 2.536067127863427

Epoch: 5| Step: 5
Training loss: 2.73225416496351
Validation loss: 2.530985223981361

Epoch: 5| Step: 6
Training loss: 2.487546132489001
Validation loss: 2.5486882620679605

Epoch: 5| Step: 7
Training loss: 3.0195969430111345
Validation loss: 2.522066879469927

Epoch: 5| Step: 8
Training loss: 3.0058895156667864
Validation loss: 2.522465054630055

Epoch: 5| Step: 9
Training loss: 2.3771323619960616
Validation loss: 2.4853747701146616

Epoch: 5| Step: 10
Training loss: 2.330069222956853
Validation loss: 2.4715305613229956

Epoch: 178| Step: 0
Training loss: 1.0756873616876812
Validation loss: 2.4724110811602196

Epoch: 5| Step: 1
Training loss: 2.6647583173054246
Validation loss: 2.4653896412901117

Epoch: 5| Step: 2
Training loss: 2.2892445566733994
Validation loss: 2.4623484004593337

Epoch: 5| Step: 3
Training loss: 2.2703486167308533
Validation loss: 2.476489176398569

Epoch: 5| Step: 4
Training loss: 2.4617277299577367
Validation loss: 2.4817132015492303

Epoch: 5| Step: 5
Training loss: 2.901440486283801
Validation loss: 2.468310916141301

Epoch: 5| Step: 6
Training loss: 2.6486792890067274
Validation loss: 2.4740680390900125

Epoch: 5| Step: 7
Training loss: 2.7073252244439794
Validation loss: 2.4649787406800874

Epoch: 5| Step: 8
Training loss: 2.48492886109485
Validation loss: 2.4632751331760954

Epoch: 5| Step: 9
Training loss: 2.4898952357915154
Validation loss: 2.460010037760611

Epoch: 5| Step: 10
Training loss: 3.0644543698212896
Validation loss: 2.46164637244577

Epoch: 179| Step: 0
Training loss: 2.4878149628719872
Validation loss: 2.477678074542836

Epoch: 5| Step: 1
Training loss: 1.9818061962473155
Validation loss: 2.4947435544499217

Epoch: 5| Step: 2
Training loss: 2.7038790141808557
Validation loss: 2.5215446250378477

Epoch: 5| Step: 3
Training loss: 2.340764904042808
Validation loss: 2.5213651985030334

Epoch: 5| Step: 4
Training loss: 2.2036430886008915
Validation loss: 2.5238223107398254

Epoch: 5| Step: 5
Training loss: 2.4187953934857935
Validation loss: 2.527553653288152

Epoch: 5| Step: 6
Training loss: 2.7928494941486828
Validation loss: 2.5351064421050133

Epoch: 5| Step: 7
Training loss: 2.275086319511958
Validation loss: 2.5310829236082992

Epoch: 5| Step: 8
Training loss: 2.652164683526444
Validation loss: 2.497354719962225

Epoch: 5| Step: 9
Training loss: 3.0514273258551623
Validation loss: 2.477398014426663

Epoch: 5| Step: 10
Training loss: 2.207058472592067
Validation loss: 2.4723815386936447

Epoch: 180| Step: 0
Training loss: 2.5786933965938013
Validation loss: 2.453039943917937

Epoch: 5| Step: 1
Training loss: 2.8435672240154823
Validation loss: 2.4561543609670573

Epoch: 5| Step: 2
Training loss: 2.832083276731165
Validation loss: 2.4551266890836545

Epoch: 5| Step: 3
Training loss: 2.2973749563830594
Validation loss: 2.483004057018077

Epoch: 5| Step: 4
Training loss: 2.189628981947116
Validation loss: 2.4975454837856477

Epoch: 5| Step: 5
Training loss: 2.3747213099748836
Validation loss: 2.512211761650333

Epoch: 5| Step: 6
Training loss: 2.73258817874228
Validation loss: 2.5131615431600434

Epoch: 5| Step: 7
Training loss: 2.6473598932326663
Validation loss: 2.5492029573490282

Epoch: 5| Step: 8
Training loss: 2.6150048107445776
Validation loss: 2.539977081638074

Epoch: 5| Step: 9
Training loss: 2.223734455022145
Validation loss: 2.499316105565517

Epoch: 5| Step: 10
Training loss: 1.9384273032744757
Validation loss: 2.48938779045401

Epoch: 181| Step: 0
Training loss: 2.045205869874937
Validation loss: 2.465904172975803

Epoch: 5| Step: 1
Training loss: 2.4092806271922673
Validation loss: 2.465783875938476

Epoch: 5| Step: 2
Training loss: 2.8393000065117353
Validation loss: 2.481332540323519

Epoch: 5| Step: 3
Training loss: 2.6359786287636755
Validation loss: 2.5006450128629862

Epoch: 5| Step: 4
Training loss: 2.3516398572396153
Validation loss: 2.497571160138473

Epoch: 5| Step: 5
Training loss: 1.9488660841177525
Validation loss: 2.4656677309351056

Epoch: 5| Step: 6
Training loss: 2.5871650110385387
Validation loss: 2.469161046529842

Epoch: 5| Step: 7
Training loss: 2.4224662797311187
Validation loss: 2.4885612741440126

Epoch: 5| Step: 8
Training loss: 2.4006550133459466
Validation loss: 2.5036276923026564

Epoch: 5| Step: 9
Training loss: 3.0162547348371036
Validation loss: 2.5063846379611934

Epoch: 5| Step: 10
Training loss: 2.198414196332824
Validation loss: 2.525801698335808

Epoch: 182| Step: 0
Training loss: 2.0581808237057473
Validation loss: 2.5265788136537473

Epoch: 5| Step: 1
Training loss: 2.6080584831174862
Validation loss: 2.547982931717149

Epoch: 5| Step: 2
Training loss: 1.85331977476791
Validation loss: 2.5662104417569833

Epoch: 5| Step: 3
Training loss: 2.555835244404323
Validation loss: 2.539716391597527

Epoch: 5| Step: 4
Training loss: 1.8276692009703668
Validation loss: 2.5031213778554497

Epoch: 5| Step: 5
Training loss: 2.388197021197046
Validation loss: 2.495525048763135

Epoch: 5| Step: 6
Training loss: 3.0207725431091546
Validation loss: 2.465287551694894

Epoch: 5| Step: 7
Training loss: 2.421012084804722
Validation loss: 2.4541644267906233

Epoch: 5| Step: 8
Training loss: 2.1566172853660315
Validation loss: 2.458515601251777

Epoch: 5| Step: 9
Training loss: 3.3166000615114233
Validation loss: 2.465747628064142

Epoch: 5| Step: 10
Training loss: 2.298792343703849
Validation loss: 2.4790844195745

Epoch: 183| Step: 0
Training loss: 2.784981185739957
Validation loss: 2.484996938376114

Epoch: 5| Step: 1
Training loss: 2.566981978266619
Validation loss: 2.48311356410782

Epoch: 5| Step: 2
Training loss: 2.64201841890555
Validation loss: 2.4913427172428912

Epoch: 5| Step: 3
Training loss: 2.3342096068429625
Validation loss: 2.499345560451408

Epoch: 5| Step: 4
Training loss: 2.1565738379513872
Validation loss: 2.499671286845461

Epoch: 5| Step: 5
Training loss: 2.673801731288651
Validation loss: 2.5079219838812645

Epoch: 5| Step: 6
Training loss: 2.341515658612773
Validation loss: 2.543542519374698

Epoch: 5| Step: 7
Training loss: 2.300468902888439
Validation loss: 2.5541584869185803

Epoch: 5| Step: 8
Training loss: 2.011844608851184
Validation loss: 2.558353982772402

Epoch: 5| Step: 9
Training loss: 2.3625753562252303
Validation loss: 2.5606006212967802

Epoch: 5| Step: 10
Training loss: 2.2297255151257374
Validation loss: 2.536992409852897

Epoch: 184| Step: 0
Training loss: 2.6950502129797465
Validation loss: 2.5300039781769947

Epoch: 5| Step: 1
Training loss: 2.343703205913075
Validation loss: 2.5207131154673386

Epoch: 5| Step: 2
Training loss: 2.488866716193405
Validation loss: 2.523511850896157

Epoch: 5| Step: 3
Training loss: 2.2653680063699735
Validation loss: 2.532327003303488

Epoch: 5| Step: 4
Training loss: 2.133720567943856
Validation loss: 2.5564664374640107

Epoch: 5| Step: 5
Training loss: 2.49731911921627
Validation loss: 2.563205580835536

Epoch: 5| Step: 6
Training loss: 2.5963817251892545
Validation loss: 2.5837764763474826

Epoch: 5| Step: 7
Training loss: 2.288585313656566
Validation loss: 2.5865424214211146

Epoch: 5| Step: 8
Training loss: 2.5548116204676736
Validation loss: 2.5971631650681277

Epoch: 5| Step: 9
Training loss: 2.2414377268152954
Validation loss: 2.6186556718324097

Epoch: 5| Step: 10
Training loss: 2.1536923041782594
Validation loss: 2.589220024260453

Epoch: 185| Step: 0
Training loss: 2.342333454574872
Validation loss: 2.5594747109296847

Epoch: 5| Step: 1
Training loss: 2.5131915151450106
Validation loss: 2.5374675871312915

Epoch: 5| Step: 2
Training loss: 2.939044627450144
Validation loss: 2.5223028777169563

Epoch: 5| Step: 3
Training loss: 2.3020062901189724
Validation loss: 2.5129430404439836

Epoch: 5| Step: 4
Training loss: 1.7331839931172348
Validation loss: 2.522223750600309

Epoch: 5| Step: 5
Training loss: 2.001045311509612
Validation loss: 2.5104815532958673

Epoch: 5| Step: 6
Training loss: 2.810301027023225
Validation loss: 2.512987348276154

Epoch: 5| Step: 7
Training loss: 2.3719486913680115
Validation loss: 2.514239940411757

Epoch: 5| Step: 8
Training loss: 2.2731516025802123
Validation loss: 2.5162469676780796

Epoch: 5| Step: 9
Training loss: 2.119274504339552
Validation loss: 2.5138559767777187

Epoch: 5| Step: 10
Training loss: 2.8280555337204114
Validation loss: 2.518563310128985

Epoch: 186| Step: 0
Training loss: 2.2274152227124913
Validation loss: 2.5497471583702587

Epoch: 5| Step: 1
Training loss: 2.233349544788944
Validation loss: 2.5366136245169884

Epoch: 5| Step: 2
Training loss: 2.105986183012498
Validation loss: 2.5075932766221274

Epoch: 5| Step: 3
Training loss: 2.7848169834400434
Validation loss: 2.497706341431296

Epoch: 5| Step: 4
Training loss: 2.4071467326392995
Validation loss: 2.4946909738219354

Epoch: 5| Step: 5
Training loss: 2.4169167246742305
Validation loss: 2.5059425851014323

Epoch: 5| Step: 6
Training loss: 2.9417706551331197
Validation loss: 2.5231898859463913

Epoch: 5| Step: 7
Training loss: 2.1653999024471924
Validation loss: 2.5621161124554233

Epoch: 5| Step: 8
Training loss: 2.5485322393212173
Validation loss: 2.5833493634803975

Epoch: 5| Step: 9
Training loss: 2.560557024227836
Validation loss: 2.586467388614097

Epoch: 5| Step: 10
Training loss: 2.162601569993213
Validation loss: 2.594804494337706

Epoch: 187| Step: 0
Training loss: 2.441984306566204
Validation loss: 2.5968520108818196

Epoch: 5| Step: 1
Training loss: 2.083184529394432
Validation loss: 2.5944979088872775

Epoch: 5| Step: 2
Training loss: 2.6951601731752093
Validation loss: 2.5807088096137534

Epoch: 5| Step: 3
Training loss: 2.2984638557504895
Validation loss: 2.555949809655659

Epoch: 5| Step: 4
Training loss: 2.4321883599658296
Validation loss: 2.549744712111759

Epoch: 5| Step: 5
Training loss: 2.2492757267309047
Validation loss: 2.554060710407597

Epoch: 5| Step: 6
Training loss: 2.1546352808920006
Validation loss: 2.5373675276384273

Epoch: 5| Step: 7
Training loss: 2.6204081745912875
Validation loss: 2.561630385592933

Epoch: 5| Step: 8
Training loss: 2.167269537266158
Validation loss: 2.5630223051820877

Epoch: 5| Step: 9
Training loss: 3.175505866654205
Validation loss: 2.587978372477366

Epoch: 5| Step: 10
Training loss: 1.6098880875828032
Validation loss: 2.5915768668893224

Epoch: 188| Step: 0
Training loss: 2.5523943860717884
Validation loss: 2.584599011876364

Epoch: 5| Step: 1
Training loss: 2.5330008585582413
Validation loss: 2.564965358484934

Epoch: 5| Step: 2
Training loss: 2.455409061824256
Validation loss: 2.531942755100985

Epoch: 5| Step: 3
Training loss: 2.120655105786359
Validation loss: 2.507695570982346

Epoch: 5| Step: 4
Training loss: 2.695564236149548
Validation loss: 2.4933295012069467

Epoch: 5| Step: 5
Training loss: 2.5036152448875995
Validation loss: 2.493101076180934

Epoch: 5| Step: 6
Training loss: 1.7322873447140263
Validation loss: 2.474949909621887

Epoch: 5| Step: 7
Training loss: 2.3946347984340104
Validation loss: 2.4842054954568447

Epoch: 5| Step: 8
Training loss: 2.341052626698182
Validation loss: 2.503694521862473

Epoch: 5| Step: 9
Training loss: 2.1026211592773714
Validation loss: 2.5328681955821293

Epoch: 5| Step: 10
Training loss: 2.668050962999416
Validation loss: 2.5944526818636335

Epoch: 189| Step: 0
Training loss: 2.387054669454514
Validation loss: 2.6730842801791437

Epoch: 5| Step: 1
Training loss: 2.4740856793739088
Validation loss: 2.701509630720787

Epoch: 5| Step: 2
Training loss: 2.5243209378979063
Validation loss: 2.6044631510309992

Epoch: 5| Step: 3
Training loss: 2.4037255259838544
Validation loss: 2.540401273525229

Epoch: 5| Step: 4
Training loss: 2.9045552880791905
Validation loss: 2.5028021193155148

Epoch: 5| Step: 5
Training loss: 2.5860820626133103
Validation loss: 2.4857524567598133

Epoch: 5| Step: 6
Training loss: 2.1585908429308827
Validation loss: 2.480521788162085

Epoch: 5| Step: 7
Training loss: 1.7335327440266095
Validation loss: 2.491622308834289

Epoch: 5| Step: 8
Training loss: 2.5720277761736345
Validation loss: 2.470999859596966

Epoch: 5| Step: 9
Training loss: 2.137954828604106
Validation loss: 2.4796826242873675

Epoch: 5| Step: 10
Training loss: 2.3856697336969312
Validation loss: 2.495544441964535

Epoch: 190| Step: 0
Training loss: 2.0484337149788043
Validation loss: 2.48318591367484

Epoch: 5| Step: 1
Training loss: 2.2712938617508307
Validation loss: 2.492892249735689

Epoch: 5| Step: 2
Training loss: 2.008724495346628
Validation loss: 2.5088771864833164

Epoch: 5| Step: 3
Training loss: 2.260926946418981
Validation loss: 2.554316452319158

Epoch: 5| Step: 4
Training loss: 1.8592766487332266
Validation loss: 2.5992873863878243

Epoch: 5| Step: 5
Training loss: 2.421000661226708
Validation loss: 2.6243479896064326

Epoch: 5| Step: 6
Training loss: 2.2608901434778392
Validation loss: 2.623192892241354

Epoch: 5| Step: 7
Training loss: 2.1797913010468193
Validation loss: 2.6060019017090155

Epoch: 5| Step: 8
Training loss: 2.6865355956933623
Validation loss: 2.594436276485144

Epoch: 5| Step: 9
Training loss: 2.6056815865444003
Validation loss: 2.56111180450333

Epoch: 5| Step: 10
Training loss: 2.9370483700565364
Validation loss: 2.519184883095803

Epoch: 191| Step: 0
Training loss: 2.547106586060818
Validation loss: 2.485967773439618

Epoch: 5| Step: 1
Training loss: 2.272309852761187
Validation loss: 2.4591322859453957

Epoch: 5| Step: 2
Training loss: 1.835910293702175
Validation loss: 2.4740470558582675

Epoch: 5| Step: 3
Training loss: 2.176748940615332
Validation loss: 2.4983254084755258

Epoch: 5| Step: 4
Training loss: 2.323068029378889
Validation loss: 2.501205096458892

Epoch: 5| Step: 5
Training loss: 2.82411161987231
Validation loss: 2.524950419251591

Epoch: 5| Step: 6
Training loss: 2.5551680833207424
Validation loss: 2.4912389024315127

Epoch: 5| Step: 7
Training loss: 2.2813250385641215
Validation loss: 2.48626583164297

Epoch: 5| Step: 8
Training loss: 2.432607092543536
Validation loss: 2.491952109448153

Epoch: 5| Step: 9
Training loss: 2.1882956011681878
Validation loss: 2.523874935565588

Epoch: 5| Step: 10
Training loss: 2.0749227762214946
Validation loss: 2.5591051096836384

Epoch: 192| Step: 0
Training loss: 2.1732255866639814
Validation loss: 2.5559518367360226

Epoch: 5| Step: 1
Training loss: 2.376988030634214
Validation loss: 2.5330127590108567

Epoch: 5| Step: 2
Training loss: 2.755522558013
Validation loss: 2.5148229240701965

Epoch: 5| Step: 3
Training loss: 1.9510371531121842
Validation loss: 2.502590604570805

Epoch: 5| Step: 4
Training loss: 2.196017657752692
Validation loss: 2.5246451428740193

Epoch: 5| Step: 5
Training loss: 2.343317220785313
Validation loss: 2.5326477894818753

Epoch: 5| Step: 6
Training loss: 2.4869377305871314
Validation loss: 2.5149174870259254

Epoch: 5| Step: 7
Training loss: 2.051699013391763
Validation loss: 2.5255845500645235

Epoch: 5| Step: 8
Training loss: 2.4707137397869805
Validation loss: 2.526464569513231

Epoch: 5| Step: 9
Training loss: 2.4780535616685713
Validation loss: 2.5412912990968053

Epoch: 5| Step: 10
Training loss: 2.178726367220408
Validation loss: 2.549801643067414

Epoch: 193| Step: 0
Training loss: 2.1743309351180597
Validation loss: 2.58597310904855

Epoch: 5| Step: 1
Training loss: 2.0174265063205006
Validation loss: 2.6469233490241675

Epoch: 5| Step: 2
Training loss: 2.3689769867616173
Validation loss: 2.6525766374131394

Epoch: 5| Step: 3
Training loss: 2.2299598874987674
Validation loss: 2.6637589332186433

Epoch: 5| Step: 4
Training loss: 2.5305956712993725
Validation loss: 2.636266157470609

Epoch: 5| Step: 5
Training loss: 2.2518762606813922
Validation loss: 2.621139109067904

Epoch: 5| Step: 6
Training loss: 2.8505479653924315
Validation loss: 2.5829681299768796

Epoch: 5| Step: 7
Training loss: 1.8109888814988218
Validation loss: 2.524257518420717

Epoch: 5| Step: 8
Training loss: 2.3216574524611944
Validation loss: 2.4799092863417544

Epoch: 5| Step: 9
Training loss: 2.296325098760626
Validation loss: 2.4798064009253094

Epoch: 5| Step: 10
Training loss: 2.179627120299461
Validation loss: 2.4594127665628567

Epoch: 194| Step: 0
Training loss: 1.9071703080701459
Validation loss: 2.430216833636116

Epoch: 5| Step: 1
Training loss: 2.0485885087255262
Validation loss: 2.418976589632606

Epoch: 5| Step: 2
Training loss: 2.3930539027901014
Validation loss: 2.4178017555573863

Epoch: 5| Step: 3
Training loss: 2.052119517773824
Validation loss: 2.4286286660644247

Epoch: 5| Step: 4
Training loss: 2.3171145818018957
Validation loss: 2.439039104654515

Epoch: 5| Step: 5
Training loss: 2.5549485192832644
Validation loss: 2.4572120836155866

Epoch: 5| Step: 6
Training loss: 2.3557162178578235
Validation loss: 2.4581360961172694

Epoch: 5| Step: 7
Training loss: 1.6478700067768146
Validation loss: 2.467629509271746

Epoch: 5| Step: 8
Training loss: 2.8590027613751583
Validation loss: 2.467288678118443

Epoch: 5| Step: 9
Training loss: 2.230930474320076
Validation loss: 2.4852042330855584

Epoch: 5| Step: 10
Training loss: 2.643366186539916
Validation loss: 2.5107839856264804

Epoch: 195| Step: 0
Training loss: 2.4359683579893825
Validation loss: 2.5344080880684254

Epoch: 5| Step: 1
Training loss: 2.3282173701657882
Validation loss: 2.5248671035045644

Epoch: 5| Step: 2
Training loss: 2.1595712045393607
Validation loss: 2.5148034511870176

Epoch: 5| Step: 3
Training loss: 1.8955293209028943
Validation loss: 2.5152024918286986

Epoch: 5| Step: 4
Training loss: 1.9125934179092048
Validation loss: 2.4814835026668396

Epoch: 5| Step: 5
Training loss: 2.444317014821382
Validation loss: 2.4640504315637144

Epoch: 5| Step: 6
Training loss: 2.442520448878264
Validation loss: 2.4612020402130153

Epoch: 5| Step: 7
Training loss: 2.3359084111574586
Validation loss: 2.4521651157807067

Epoch: 5| Step: 8
Training loss: 2.478766678885298
Validation loss: 2.4636926357376128

Epoch: 5| Step: 9
Training loss: 2.4926017010447676
Validation loss: 2.488556743453169

Epoch: 5| Step: 10
Training loss: 1.9236836180657544
Validation loss: 2.5122894213965155

Epoch: 196| Step: 0
Training loss: 2.249352149942713
Validation loss: 2.545949756147524

Epoch: 5| Step: 1
Training loss: 2.538292589100654
Validation loss: 2.5399050088608806

Epoch: 5| Step: 2
Training loss: 2.405795264934447
Validation loss: 2.5385013790127395

Epoch: 5| Step: 3
Training loss: 2.415944967262058
Validation loss: 2.5577639541370503

Epoch: 5| Step: 4
Training loss: 2.1165441682867367
Validation loss: 2.5231275404616573

Epoch: 5| Step: 5
Training loss: 2.0818148101470406
Validation loss: 2.490137209974182

Epoch: 5| Step: 6
Training loss: 2.111933082488569
Validation loss: 2.487604228240657

Epoch: 5| Step: 7
Training loss: 2.0614658421756666
Validation loss: 2.5046747743920457

Epoch: 5| Step: 8
Training loss: 2.647785477848714
Validation loss: 2.5057178758814653

Epoch: 5| Step: 9
Training loss: 1.9728823692726996
Validation loss: 2.5299555624738335

Epoch: 5| Step: 10
Training loss: 1.810406890362798
Validation loss: 2.534484594308197

Epoch: 197| Step: 0
Training loss: 1.938397907035381
Validation loss: 2.5141671762321085

Epoch: 5| Step: 1
Training loss: 2.602182858480027
Validation loss: 2.5115541796440857

Epoch: 5| Step: 2
Training loss: 2.330648808008614
Validation loss: 2.4916231967784475

Epoch: 5| Step: 3
Training loss: 2.2325273891020507
Validation loss: 2.4884465723966342

Epoch: 5| Step: 4
Training loss: 2.3792290429413545
Validation loss: 2.488073349232176

Epoch: 5| Step: 5
Training loss: 2.325619674467383
Validation loss: 2.4897802824801762

Epoch: 5| Step: 6
Training loss: 2.231428751477112
Validation loss: 2.5047193917397954

Epoch: 5| Step: 7
Training loss: 2.675663810436029
Validation loss: 2.5106800756241747

Epoch: 5| Step: 8
Training loss: 1.552080354965049
Validation loss: 2.5153648829487225

Epoch: 5| Step: 9
Training loss: 1.8176411030604782
Validation loss: 2.5189190775167534

Epoch: 5| Step: 10
Training loss: 2.1045888219185436
Validation loss: 2.5192095588764887

Epoch: 198| Step: 0
Training loss: 1.7455328738182854
Validation loss: 2.5010446375820816

Epoch: 5| Step: 1
Training loss: 2.293071997948311
Validation loss: 2.5011283604629932

Epoch: 5| Step: 2
Training loss: 1.7607014969256558
Validation loss: 2.4961782150976464

Epoch: 5| Step: 3
Training loss: 2.1499286817210512
Validation loss: 2.5183858455696666

Epoch: 5| Step: 4
Training loss: 2.2223095346888
Validation loss: 2.512771407550991

Epoch: 5| Step: 5
Training loss: 1.8978747880030178
Validation loss: 2.53339414785324

Epoch: 5| Step: 6
Training loss: 2.463381277485851
Validation loss: 2.5444316708426724

Epoch: 5| Step: 7
Training loss: 2.3524073100300287
Validation loss: 2.542626259454015

Epoch: 5| Step: 8
Training loss: 2.7226265641595857
Validation loss: 2.540911776396992

Epoch: 5| Step: 9
Training loss: 2.4346507120762175
Validation loss: 2.5323166427331905

Epoch: 5| Step: 10
Training loss: 1.9490501927214596
Validation loss: 2.5276362029662516

Epoch: 199| Step: 0
Training loss: 2.177978720877169
Validation loss: 2.5267967256844845

Epoch: 5| Step: 1
Training loss: 2.30440227230644
Validation loss: 2.5477680840095327

Epoch: 5| Step: 2
Training loss: 2.3828315108744698
Validation loss: 2.5582723821997986

Epoch: 5| Step: 3
Training loss: 1.9655907123043492
Validation loss: 2.531927591568142

Epoch: 5| Step: 4
Training loss: 2.4771688302709145
Validation loss: 2.536630742929562

Epoch: 5| Step: 5
Training loss: 2.062850691140294
Validation loss: 2.5323663455481276

Epoch: 5| Step: 6
Training loss: 2.2062111740370187
Validation loss: 2.545388215632696

Epoch: 5| Step: 7
Training loss: 2.283533286182622
Validation loss: 2.5775805920568113

Epoch: 5| Step: 8
Training loss: 1.8802129757754285
Validation loss: 2.549334753699915

Epoch: 5| Step: 9
Training loss: 1.799884034765778
Validation loss: 2.546492007707842

Epoch: 5| Step: 10
Training loss: 2.3559408900839554
Validation loss: 2.530265493086767

Epoch: 200| Step: 0
Training loss: 1.864912874165643
Validation loss: 2.51538231923094

Epoch: 5| Step: 1
Training loss: 2.11894946664464
Validation loss: 2.511350604447041

Epoch: 5| Step: 2
Training loss: 2.5794053106465835
Validation loss: 2.489102407795634

Epoch: 5| Step: 3
Training loss: 2.565389074520318
Validation loss: 2.479991490916455

Epoch: 5| Step: 4
Training loss: 2.242970612304935
Validation loss: 2.474040140160575

Epoch: 5| Step: 5
Training loss: 1.8920640749253306
Validation loss: 2.470256482331005

Epoch: 5| Step: 6
Training loss: 1.9513489239070627
Validation loss: 2.474851598606777

Epoch: 5| Step: 7
Training loss: 1.709023297547836
Validation loss: 2.4814252553501643

Epoch: 5| Step: 8
Training loss: 2.22832625284071
Validation loss: 2.5044734452493222

Epoch: 5| Step: 9
Training loss: 2.065246949104371
Validation loss: 2.512758132097455

Epoch: 5| Step: 10
Training loss: 2.153336588480155
Validation loss: 2.5240202464247607

Epoch: 201| Step: 0
Training loss: 2.076392003301229
Validation loss: 2.513358302375755

Epoch: 5| Step: 1
Training loss: 2.1984651673615505
Validation loss: 2.5032707916781343

Epoch: 5| Step: 2
Training loss: 2.5525421560544417
Validation loss: 2.5155513010991615

Epoch: 5| Step: 3
Training loss: 1.994283254456379
Validation loss: 2.5103761852419666

Epoch: 5| Step: 4
Training loss: 2.0113529798698555
Validation loss: 2.4999142560303556

Epoch: 5| Step: 5
Training loss: 2.2987106150602714
Validation loss: 2.490906998905495

Epoch: 5| Step: 6
Training loss: 2.296548729384327
Validation loss: 2.4909560938184376

Epoch: 5| Step: 7
Training loss: 1.893792139975661
Validation loss: 2.488715619696655

Epoch: 5| Step: 8
Training loss: 2.007269403650588
Validation loss: 2.512548964048877

Epoch: 5| Step: 9
Training loss: 2.1789660062970007
Validation loss: 2.5357026447164204

Epoch: 5| Step: 10
Training loss: 2.0792150865113888
Validation loss: 2.546436729345516

Epoch: 202| Step: 0
Training loss: 1.8823817856591158
Validation loss: 2.528948480060991

Epoch: 5| Step: 1
Training loss: 2.3608761489743375
Validation loss: 2.511564405383913

Epoch: 5| Step: 2
Training loss: 1.894769649646832
Validation loss: 2.496591477832212

Epoch: 5| Step: 3
Training loss: 2.015400127316473
Validation loss: 2.501905267483536

Epoch: 5| Step: 4
Training loss: 2.2121899834802288
Validation loss: 2.518249503153025

Epoch: 5| Step: 5
Training loss: 2.4457034447497197
Validation loss: 2.516092773474154

Epoch: 5| Step: 6
Training loss: 2.4231035623495027
Validation loss: 2.50625086275379

Epoch: 5| Step: 7
Training loss: 2.1544352095346286
Validation loss: 2.5076153777098695

Epoch: 5| Step: 8
Training loss: 1.6751659481912506
Validation loss: 2.482874179055554

Epoch: 5| Step: 9
Training loss: 2.263908314637804
Validation loss: 2.477882060365666

Epoch: 5| Step: 10
Training loss: 2.0623970006019796
Validation loss: 2.4678317712226208

Epoch: 203| Step: 0
Training loss: 1.6488491466404909
Validation loss: 2.463856642584369

Epoch: 5| Step: 1
Training loss: 2.078427859157651
Validation loss: 2.4742217537101094

Epoch: 5| Step: 2
Training loss: 2.216927115357731
Validation loss: 2.4784052620519206

Epoch: 5| Step: 3
Training loss: 2.5675644489285667
Validation loss: 2.475445329093976

Epoch: 5| Step: 4
Training loss: 2.274063705773222
Validation loss: 2.4765844049426673

Epoch: 5| Step: 5
Training loss: 1.8047507138761436
Validation loss: 2.453269248323135

Epoch: 5| Step: 6
Training loss: 2.182054116757197
Validation loss: 2.4341208671017287

Epoch: 5| Step: 7
Training loss: 2.5731461972134206
Validation loss: 2.4306954456588885

Epoch: 5| Step: 8
Training loss: 1.924820913926721
Validation loss: 2.433416637943626

Epoch: 5| Step: 9
Training loss: 2.368558279044032
Validation loss: 2.432085351049807

Epoch: 5| Step: 10
Training loss: 1.8305042141300845
Validation loss: 2.485443591244064

Epoch: 204| Step: 0
Training loss: 2.474191390989308
Validation loss: 2.4896148941882315

Epoch: 5| Step: 1
Training loss: 2.575892736251235
Validation loss: 2.527062151568963

Epoch: 5| Step: 2
Training loss: 2.1047459425030164
Validation loss: 2.5784370698363897

Epoch: 5| Step: 3
Training loss: 2.109660376565257
Validation loss: 2.5654856138614304

Epoch: 5| Step: 4
Training loss: 1.7016722756697187
Validation loss: 2.5322351284502393

Epoch: 5| Step: 5
Training loss: 1.9879915217443318
Validation loss: 2.5022889169912688

Epoch: 5| Step: 6
Training loss: 2.212702070588364
Validation loss: 2.4898666565242094

Epoch: 5| Step: 7
Training loss: 2.099945467286275
Validation loss: 2.4853959754073145

Epoch: 5| Step: 8
Training loss: 2.016897347027673
Validation loss: 2.4775392580682833

Epoch: 5| Step: 9
Training loss: 1.9329005376306363
Validation loss: 2.4768432538792657

Epoch: 5| Step: 10
Training loss: 2.013707394661269
Validation loss: 2.497356066785558

Epoch: 205| Step: 0
Training loss: 1.7378240434098244
Validation loss: 2.508396030062592

Epoch: 5| Step: 1
Training loss: 2.332491779701328
Validation loss: 2.494023518583469

Epoch: 5| Step: 2
Training loss: 2.673247224779721
Validation loss: 2.4764115710138936

Epoch: 5| Step: 3
Training loss: 2.3161119656881355
Validation loss: 2.454988071940731

Epoch: 5| Step: 4
Training loss: 2.2339577451994086
Validation loss: 2.465957760386944

Epoch: 5| Step: 5
Training loss: 1.9444213419253278
Validation loss: 2.4498821462496223

Epoch: 5| Step: 6
Training loss: 2.137127099776844
Validation loss: 2.4487852553673277

Epoch: 5| Step: 7
Training loss: 1.5717736274080405
Validation loss: 2.504285825233577

Epoch: 5| Step: 8
Training loss: 1.9823149553602406
Validation loss: 2.5418401269275854

Epoch: 5| Step: 9
Training loss: 2.1673472020411397
Validation loss: 2.5959329602345576

Epoch: 5| Step: 10
Training loss: 1.6479409722015887
Validation loss: 2.574432365677506

Epoch: 206| Step: 0
Training loss: 2.4303179839755256
Validation loss: 2.5656692960902965

Epoch: 5| Step: 1
Training loss: 2.029318727700553
Validation loss: 2.5293546878366393

Epoch: 5| Step: 2
Training loss: 1.9654178576950703
Validation loss: 2.474552141738798

Epoch: 5| Step: 3
Training loss: 2.0874242163510486
Validation loss: 2.4637576251389763

Epoch: 5| Step: 4
Training loss: 2.240589702333491
Validation loss: 2.466115308116304

Epoch: 5| Step: 5
Training loss: 2.4408439782213214
Validation loss: 2.439922940694753

Epoch: 5| Step: 6
Training loss: 2.095528601554768
Validation loss: 2.4386949515599383

Epoch: 5| Step: 7
Training loss: 2.0436792250578026
Validation loss: 2.4545709734872783

Epoch: 5| Step: 8
Training loss: 2.068836996317976
Validation loss: 2.445659385477516

Epoch: 5| Step: 9
Training loss: 1.7860162111894364
Validation loss: 2.469648645993714

Epoch: 5| Step: 10
Training loss: 1.6482982124673011
Validation loss: 2.48406507359958

Epoch: 207| Step: 0
Training loss: 2.1366770180596775
Validation loss: 2.5112646416407913

Epoch: 5| Step: 1
Training loss: 2.1075319503588665
Validation loss: 2.509486835059368

Epoch: 5| Step: 2
Training loss: 2.059416923038346
Validation loss: 2.5563317610424434

Epoch: 5| Step: 3
Training loss: 1.927085388457431
Validation loss: 2.571878362637069

Epoch: 5| Step: 4
Training loss: 2.306315322405747
Validation loss: 2.5789706427144266

Epoch: 5| Step: 5
Training loss: 1.820072403819492
Validation loss: 2.5719537153991894

Epoch: 5| Step: 6
Training loss: 1.992671533760941
Validation loss: 2.577974078253406

Epoch: 5| Step: 7
Training loss: 1.8045938310631242
Validation loss: 2.551572452630725

Epoch: 5| Step: 8
Training loss: 1.8854861448634206
Validation loss: 2.5222756972986695

Epoch: 5| Step: 9
Training loss: 2.238797592602898
Validation loss: 2.5202680838979137

Epoch: 5| Step: 10
Training loss: 2.3156569299800225
Validation loss: 2.4771940115125535

Epoch: 208| Step: 0
Training loss: 2.0018046105354506
Validation loss: 2.4717850342533416

Epoch: 5| Step: 1
Training loss: 2.091694976290839
Validation loss: 2.442522932202677

Epoch: 5| Step: 2
Training loss: 2.1727266905832074
Validation loss: 2.42949749287033

Epoch: 5| Step: 3
Training loss: 2.0481817136705316
Validation loss: 2.4210318302707976

Epoch: 5| Step: 4
Training loss: 1.8966726254848383
Validation loss: 2.4264664172021044

Epoch: 5| Step: 5
Training loss: 2.069931974168607
Validation loss: 2.435962614974128

Epoch: 5| Step: 6
Training loss: 1.8225272789105371
Validation loss: 2.470799722031159

Epoch: 5| Step: 7
Training loss: 2.4529677419613627
Validation loss: 2.5039873043339185

Epoch: 5| Step: 8
Training loss: 2.0838736278563057
Validation loss: 2.5367970375759197

Epoch: 5| Step: 9
Training loss: 2.029226615798285
Validation loss: 2.5530455077433056

Epoch: 5| Step: 10
Training loss: 2.0786054242312453
Validation loss: 2.5812915655141118

Epoch: 209| Step: 0
Training loss: 2.2046894984570806
Validation loss: 2.5096484917644495

Epoch: 5| Step: 1
Training loss: 1.730875212937617
Validation loss: 2.4807718040332674

Epoch: 5| Step: 2
Training loss: 2.0538284188342586
Validation loss: 2.4380524437600934

Epoch: 5| Step: 3
Training loss: 1.588551063718257
Validation loss: 2.4317461217827274

Epoch: 5| Step: 4
Training loss: 2.3676696890549844
Validation loss: 2.4331959739880005

Epoch: 5| Step: 5
Training loss: 1.7496314341846573
Validation loss: 2.431637273427768

Epoch: 5| Step: 6
Training loss: 2.186765492966273
Validation loss: 2.4565285581998904

Epoch: 5| Step: 7
Training loss: 2.4366896822982205
Validation loss: 2.4928263965499236

Epoch: 5| Step: 8
Training loss: 2.212531172538169
Validation loss: 2.4986215133967424

Epoch: 5| Step: 9
Training loss: 1.9061566314344163
Validation loss: 2.5339331504816984

Epoch: 5| Step: 10
Training loss: 2.1016470172436454
Validation loss: 2.529241727626162

Epoch: 210| Step: 0
Training loss: 1.693292284277734
Validation loss: 2.512239799460002

Epoch: 5| Step: 1
Training loss: 1.9165073273257682
Validation loss: 2.480488544101235

Epoch: 5| Step: 2
Training loss: 1.935366347869808
Validation loss: 2.481520308935135

Epoch: 5| Step: 3
Training loss: 2.1219322275526182
Validation loss: 2.4335456937814097

Epoch: 5| Step: 4
Training loss: 1.9877846328084547
Validation loss: 2.4645101958828737

Epoch: 5| Step: 5
Training loss: 1.6340676188210936
Validation loss: 2.44981524783978

Epoch: 5| Step: 6
Training loss: 2.3190548760623315
Validation loss: 2.4680264815808792

Epoch: 5| Step: 7
Training loss: 2.3096168690801724
Validation loss: 2.464383590188222

Epoch: 5| Step: 8
Training loss: 1.71116267425219
Validation loss: 2.4998628209532576

Epoch: 5| Step: 9
Training loss: 2.0836133260132716
Validation loss: 2.4853221759170503

Epoch: 5| Step: 10
Training loss: 2.220016655215085
Validation loss: 2.5031076630567584

Epoch: 211| Step: 0
Training loss: 2.3992677922703582
Validation loss: 2.500509519850654

Epoch: 5| Step: 1
Training loss: 1.3805355140072206
Validation loss: 2.5042388768285364

Epoch: 5| Step: 2
Training loss: 2.127302605227226
Validation loss: 2.4803675652794146

Epoch: 5| Step: 3
Training loss: 2.165945507734293
Validation loss: 2.4977471978934105

Epoch: 5| Step: 4
Training loss: 2.136225279011553
Validation loss: 2.5214689071006853

Epoch: 5| Step: 5
Training loss: 1.7651519141591792
Validation loss: 2.5243094242826087

Epoch: 5| Step: 6
Training loss: 1.7254779568162029
Validation loss: 2.532536430805055

Epoch: 5| Step: 7
Training loss: 1.8905067722145785
Validation loss: 2.522662589703675

Epoch: 5| Step: 8
Training loss: 1.9014036765807247
Validation loss: 2.521042165205569

Epoch: 5| Step: 9
Training loss: 2.051044788684345
Validation loss: 2.506275098174434

Epoch: 5| Step: 10
Training loss: 1.9120777037883965
Validation loss: 2.5086224042687224

Epoch: 212| Step: 0
Training loss: 1.247334164851768
Validation loss: 2.496372119371943

Epoch: 5| Step: 1
Training loss: 2.4016171728995475
Validation loss: 2.4820088925282775

Epoch: 5| Step: 2
Training loss: 2.244371048773249
Validation loss: 2.469383510492991

Epoch: 5| Step: 3
Training loss: 2.1980780833001416
Validation loss: 2.4757598034690593

Epoch: 5| Step: 4
Training loss: 1.9518175555548523
Validation loss: 2.4443684335707054

Epoch: 5| Step: 5
Training loss: 1.832553488144619
Validation loss: 2.4823817432716355

Epoch: 5| Step: 6
Training loss: 1.9111282590286518
Validation loss: 2.506162975806217

Epoch: 5| Step: 7
Training loss: 1.9396604367619543
Validation loss: 2.5051000881817376

Epoch: 5| Step: 8
Training loss: 2.1685882508041674
Validation loss: 2.5070486008361748

Epoch: 5| Step: 9
Training loss: 1.5541348649249345
Validation loss: 2.486546929209449

Epoch: 5| Step: 10
Training loss: 2.020056178567589
Validation loss: 2.5011190637534977

Epoch: 213| Step: 0
Training loss: 2.194753338069183
Validation loss: 2.515981740744848

Epoch: 5| Step: 1
Training loss: 2.3730157292837784
Validation loss: 2.4937864180187983

Epoch: 5| Step: 2
Training loss: 1.8302691674439637
Validation loss: 2.501505874025991

Epoch: 5| Step: 3
Training loss: 1.7981434201333597
Validation loss: 2.511859674292291

Epoch: 5| Step: 4
Training loss: 1.875607900621009
Validation loss: 2.498740553737265

Epoch: 5| Step: 5
Training loss: 2.2472982079676624
Validation loss: 2.5092691009438908

Epoch: 5| Step: 6
Training loss: 1.8304001434272763
Validation loss: 2.5104608662504266

Epoch: 5| Step: 7
Training loss: 2.1711669426351694
Validation loss: 2.5249604475785157

Epoch: 5| Step: 8
Training loss: 2.216079824490351
Validation loss: 2.529260135557538

Epoch: 5| Step: 9
Training loss: 1.0819856930172893
Validation loss: 2.5012831758343315

Epoch: 5| Step: 10
Training loss: 1.6847638447480378
Validation loss: 2.5082464958470916

Epoch: 214| Step: 0
Training loss: 2.183733722383725
Validation loss: 2.49677694788527

Epoch: 5| Step: 1
Training loss: 1.7888195422587616
Validation loss: 2.485007880004371

Epoch: 5| Step: 2
Training loss: 1.577444930891252
Validation loss: 2.4854532271434566

Epoch: 5| Step: 3
Training loss: 1.7828305911350668
Validation loss: 2.476538329910493

Epoch: 5| Step: 4
Training loss: 1.9593762265434258
Validation loss: 2.4806207182846096

Epoch: 5| Step: 5
Training loss: 1.752214665278011
Validation loss: 2.4704794754658184

Epoch: 5| Step: 6
Training loss: 1.807625562915328
Validation loss: 2.4982939446622514

Epoch: 5| Step: 7
Training loss: 2.596215420723639
Validation loss: 2.51421311841854

Epoch: 5| Step: 8
Training loss: 1.6995146395127678
Validation loss: 2.51549887667426

Epoch: 5| Step: 9
Training loss: 2.526159749105929
Validation loss: 2.5086636869019507

Epoch: 5| Step: 10
Training loss: 1.2296460989316638
Validation loss: 2.5305675020469423

Epoch: 215| Step: 0
Training loss: 2.0645228782858815
Validation loss: 2.513367913874241

Epoch: 5| Step: 1
Training loss: 2.0335752822676376
Validation loss: 2.519271985039377

Epoch: 5| Step: 2
Training loss: 1.507729483577274
Validation loss: 2.5152213419182656

Epoch: 5| Step: 3
Training loss: 2.3704017496625895
Validation loss: 2.5151058306632987

Epoch: 5| Step: 4
Training loss: 1.7781299906092436
Validation loss: 2.4949872912166002

Epoch: 5| Step: 5
Training loss: 1.5409945062270813
Validation loss: 2.4976872544623343

Epoch: 5| Step: 6
Training loss: 2.221618517358442
Validation loss: 2.486297480666109

Epoch: 5| Step: 7
Training loss: 2.026127739052925
Validation loss: 2.483130391109181

Epoch: 5| Step: 8
Training loss: 1.8207252918490768
Validation loss: 2.501987934362715

Epoch: 5| Step: 9
Training loss: 1.807055616400043
Validation loss: 2.5075250133129345

Epoch: 5| Step: 10
Training loss: 1.7823243498429833
Validation loss: 2.5399295368373425

Epoch: 216| Step: 0
Training loss: 1.885210717967983
Validation loss: 2.5488695439809694

Epoch: 5| Step: 1
Training loss: 2.473388659825813
Validation loss: 2.5449663050267

Epoch: 5| Step: 2
Training loss: 1.9286976487872904
Validation loss: 2.562893159780314

Epoch: 5| Step: 3
Training loss: 1.7544626147901148
Validation loss: 2.544287728262049

Epoch: 5| Step: 4
Training loss: 2.048816604509138
Validation loss: 2.5341493203456666

Epoch: 5| Step: 5
Training loss: 1.7423181185488932
Validation loss: 2.526961797738349

Epoch: 5| Step: 6
Training loss: 1.5301249516645035
Validation loss: 2.5003857520091888

Epoch: 5| Step: 7
Training loss: 1.7748453207182833
Validation loss: 2.470334245793178

Epoch: 5| Step: 8
Training loss: 1.7114417321608666
Validation loss: 2.440008149327589

Epoch: 5| Step: 9
Training loss: 1.8308773351610015
Validation loss: 2.442585386561615

Epoch: 5| Step: 10
Training loss: 2.4822294939530942
Validation loss: 2.4468107624187216

Epoch: 217| Step: 0
Training loss: 1.9658594861891063
Validation loss: 2.4421142265649984

Epoch: 5| Step: 1
Training loss: 2.393561460873729
Validation loss: 2.456813219914339

Epoch: 5| Step: 2
Training loss: 1.712092249421501
Validation loss: 2.4707385551755663

Epoch: 5| Step: 3
Training loss: 1.9054558772691974
Validation loss: 2.471692239733345

Epoch: 5| Step: 4
Training loss: 2.4451983245422024
Validation loss: 2.506420975255812

Epoch: 5| Step: 5
Training loss: 1.7833922370499553
Validation loss: 2.5076558917755247

Epoch: 5| Step: 6
Training loss: 1.7332646020075844
Validation loss: 2.499174438059522

Epoch: 5| Step: 7
Training loss: 1.9746375077202782
Validation loss: 2.4732416242798103

Epoch: 5| Step: 8
Training loss: 1.630071209715292
Validation loss: 2.4778474989900285

Epoch: 5| Step: 9
Training loss: 1.5010226260620443
Validation loss: 2.4955737276936047

Epoch: 5| Step: 10
Training loss: 1.5303709660010874
Validation loss: 2.4856130856163943

Epoch: 218| Step: 0
Training loss: 1.740176626974819
Validation loss: 2.480981554568993

Epoch: 5| Step: 1
Training loss: 1.4594475803665052
Validation loss: 2.4761790726047064

Epoch: 5| Step: 2
Training loss: 2.325338449762706
Validation loss: 2.4762429252151112

Epoch: 5| Step: 3
Training loss: 1.9292809061894494
Validation loss: 2.4791299054246876

Epoch: 5| Step: 4
Training loss: 1.8778620175584055
Validation loss: 2.490439352035941

Epoch: 5| Step: 5
Training loss: 1.8950680945448994
Validation loss: 2.4890065828812933

Epoch: 5| Step: 6
Training loss: 1.6700428701368994
Validation loss: 2.486050115919335

Epoch: 5| Step: 7
Training loss: 1.9579502163832474
Validation loss: 2.486786427196989

Epoch: 5| Step: 8
Training loss: 1.722104769294186
Validation loss: 2.486012517705291

Epoch: 5| Step: 9
Training loss: 2.1088700431841
Validation loss: 2.4869700287286642

Epoch: 5| Step: 10
Training loss: 1.562005613314498
Validation loss: 2.493229879004561

Epoch: 219| Step: 0
Training loss: 1.3322429320981317
Validation loss: 2.4893644992456676

Epoch: 5| Step: 1
Training loss: 1.4082618309619743
Validation loss: 2.487874773204889

Epoch: 5| Step: 2
Training loss: 2.316669519912097
Validation loss: 2.4758172355813284

Epoch: 5| Step: 3
Training loss: 2.2079815734357005
Validation loss: 2.4864195216480343

Epoch: 5| Step: 4
Training loss: 1.9062481239184543
Validation loss: 2.4840221271803835

Epoch: 5| Step: 5
Training loss: 1.725521412427233
Validation loss: 2.461559802817524

Epoch: 5| Step: 6
Training loss: 2.0135220935368174
Validation loss: 2.471093851919262

Epoch: 5| Step: 7
Training loss: 1.7469052470801045
Validation loss: 2.450579834389998

Epoch: 5| Step: 8
Training loss: 1.4366956201779317
Validation loss: 2.455618446039493

Epoch: 5| Step: 9
Training loss: 1.9640145647243095
Validation loss: 2.470813075588522

Epoch: 5| Step: 10
Training loss: 1.9732812476801904
Validation loss: 2.439550123975349

Epoch: 220| Step: 0
Training loss: 1.8230445235690655
Validation loss: 2.445016907506562

Epoch: 5| Step: 1
Training loss: 1.988366265718348
Validation loss: 2.471893699439092

Epoch: 5| Step: 2
Training loss: 2.166260852467361
Validation loss: 2.452603846701647

Epoch: 5| Step: 3
Training loss: 1.7008902911240882
Validation loss: 2.469406784085243

Epoch: 5| Step: 4
Training loss: 1.7776327380315122
Validation loss: 2.4701282573522447

Epoch: 5| Step: 5
Training loss: 1.9947109023461518
Validation loss: 2.4806663263317508

Epoch: 5| Step: 6
Training loss: 1.5414643885247845
Validation loss: 2.4915832780770097

Epoch: 5| Step: 7
Training loss: 1.8662508606445618
Validation loss: 2.499813762003669

Epoch: 5| Step: 8
Training loss: 1.994928247409112
Validation loss: 2.5147786546955775

Epoch: 5| Step: 9
Training loss: 1.5463226565264956
Validation loss: 2.5290619754107375

Epoch: 5| Step: 10
Training loss: 1.7101768997778959
Validation loss: 2.5214641437392618

Epoch: 221| Step: 0
Training loss: 2.234274588509463
Validation loss: 2.4806285969107957

Epoch: 5| Step: 1
Training loss: 1.7686322014608322
Validation loss: 2.4487730306504574

Epoch: 5| Step: 2
Training loss: 1.8190974817941048
Validation loss: 2.46231183755855

Epoch: 5| Step: 3
Training loss: 1.8860960380964422
Validation loss: 2.430792964429234

Epoch: 5| Step: 4
Training loss: 1.6758977676111784
Validation loss: 2.4551542505594255

Epoch: 5| Step: 5
Training loss: 1.632140463922385
Validation loss: 2.452136565146317

Epoch: 5| Step: 6
Training loss: 2.068701696840377
Validation loss: 2.472734630551396

Epoch: 5| Step: 7
Training loss: 1.8603834735206028
Validation loss: 2.440253632067311

Epoch: 5| Step: 8
Training loss: 1.8189200777318462
Validation loss: 2.4297809976536566

Epoch: 5| Step: 9
Training loss: 1.3955212239394477
Validation loss: 2.431788512347495

Epoch: 5| Step: 10
Training loss: 1.8856981253550769
Validation loss: 2.437510817224792

Epoch: 222| Step: 0
Training loss: 1.87841974570198
Validation loss: 2.450736610690988

Epoch: 5| Step: 1
Training loss: 1.65743990206619
Validation loss: 2.448051180489573

Epoch: 5| Step: 2
Training loss: 1.7355471937070661
Validation loss: 2.4121941281762225

Epoch: 5| Step: 3
Training loss: 1.3832233486727794
Validation loss: 2.378724397898267

Epoch: 5| Step: 4
Training loss: 1.8586158805642428
Validation loss: 2.4087373906869876

Epoch: 5| Step: 5
Training loss: 1.7802578354662943
Validation loss: 2.4049756229026418

Epoch: 5| Step: 6
Training loss: 1.871858317152775
Validation loss: 2.4195314964962282

Epoch: 5| Step: 7
Training loss: 2.3298690714907795
Validation loss: 2.414537271019947

Epoch: 5| Step: 8
Training loss: 1.8564885920537022
Validation loss: 2.4695712497081796

Epoch: 5| Step: 9
Training loss: 1.2579079348924567
Validation loss: 2.5054526762583578

Epoch: 5| Step: 10
Training loss: 2.377098762357378
Validation loss: 2.489636235330017

Epoch: 223| Step: 0
Training loss: 1.5228522325792901
Validation loss: 2.4901288121831517

Epoch: 5| Step: 1
Training loss: 1.8080957110103297
Validation loss: 2.457446154283251

Epoch: 5| Step: 2
Training loss: 1.7459239493124656
Validation loss: 2.442809613252122

Epoch: 5| Step: 3
Training loss: 1.527781548158251
Validation loss: 2.4084574750188015

Epoch: 5| Step: 4
Training loss: 1.7994255208816494
Validation loss: 2.3787825168806864

Epoch: 5| Step: 5
Training loss: 1.646703884203525
Validation loss: 2.376536046927049

Epoch: 5| Step: 6
Training loss: 1.2748882712234388
Validation loss: 2.373379606303053

Epoch: 5| Step: 7
Training loss: 2.10091551851334
Validation loss: 2.3521575567313615

Epoch: 5| Step: 8
Training loss: 1.7544569752359565
Validation loss: 2.3517570160324808

Epoch: 5| Step: 9
Training loss: 2.1754264062783877
Validation loss: 2.3462954387235224

Epoch: 5| Step: 10
Training loss: 1.9381329517761097
Validation loss: 2.371572643431712

Epoch: 224| Step: 0
Training loss: 1.345713533712807
Validation loss: 2.3796336142398427

Epoch: 5| Step: 1
Training loss: 1.5615422937758856
Validation loss: 2.3784619203715716

Epoch: 5| Step: 2
Training loss: 1.9528430582635488
Validation loss: 2.4141521326375206

Epoch: 5| Step: 3
Training loss: 1.9693057169057255
Validation loss: 2.4428392488849515

Epoch: 5| Step: 4
Training loss: 1.5179075376976252
Validation loss: 2.4559231374864448

Epoch: 5| Step: 5
Training loss: 1.865182925807939
Validation loss: 2.468897474377198

Epoch: 5| Step: 6
Training loss: 2.0737723752056927
Validation loss: 2.477381172807787

Epoch: 5| Step: 7
Training loss: 1.6903877980349247
Validation loss: 2.504217949846959

Epoch: 5| Step: 8
Training loss: 1.5481816177579815
Validation loss: 2.460322143062139

Epoch: 5| Step: 9
Training loss: 1.9162497343397857
Validation loss: 2.4866643727779763

Epoch: 5| Step: 10
Training loss: 1.7801601355024852
Validation loss: 2.452888143441145

Epoch: 225| Step: 0
Training loss: 1.6676775568692237
Validation loss: 2.4264864299582336

Epoch: 5| Step: 1
Training loss: 1.7965163163151001
Validation loss: 2.3850963388378

Epoch: 5| Step: 2
Training loss: 1.4680606766564006
Validation loss: 2.3698139812108985

Epoch: 5| Step: 3
Training loss: 2.0977468346726567
Validation loss: 2.3483689208072738

Epoch: 5| Step: 4
Training loss: 2.1048645398190233
Validation loss: 2.3444173249783433

Epoch: 5| Step: 5
Training loss: 1.7981143823548185
Validation loss: 2.342029692183206

Epoch: 5| Step: 6
Training loss: 1.5577048154475486
Validation loss: 2.3620276015328807

Epoch: 5| Step: 7
Training loss: 2.227530285835954
Validation loss: 2.40451627657436

Epoch: 5| Step: 8
Training loss: 1.5240022052839048
Validation loss: 2.4659568486465693

Epoch: 5| Step: 9
Training loss: 1.1341056020434357
Validation loss: 2.455462340589228

Epoch: 5| Step: 10
Training loss: 2.0343025159448125
Validation loss: 2.4706893890036645

Epoch: 226| Step: 0
Training loss: 2.0297405796877834
Validation loss: 2.4449609276168762

Epoch: 5| Step: 1
Training loss: 1.6103892417372125
Validation loss: 2.4315099492703167

Epoch: 5| Step: 2
Training loss: 1.6096996239227994
Validation loss: 2.435212874729392

Epoch: 5| Step: 3
Training loss: 1.2892905756002422
Validation loss: 2.4066189846725763

Epoch: 5| Step: 4
Training loss: 1.3759553364835053
Validation loss: 2.3875441109193964

Epoch: 5| Step: 5
Training loss: 2.29337682780709
Validation loss: 2.3733564582627693

Epoch: 5| Step: 6
Training loss: 2.2171753144416617
Validation loss: 2.3939060561391905

Epoch: 5| Step: 7
Training loss: 1.126933079480111
Validation loss: 2.409304644172159

Epoch: 5| Step: 8
Training loss: 1.7101090049578391
Validation loss: 2.425856326635338

Epoch: 5| Step: 9
Training loss: 2.0693474589698138
Validation loss: 2.424681306750801

Epoch: 5| Step: 10
Training loss: 1.100082593764781
Validation loss: 2.427568540767499

Epoch: 227| Step: 0
Training loss: 1.5552910634763888
Validation loss: 2.419158993009991

Epoch: 5| Step: 1
Training loss: 1.5789592539607649
Validation loss: 2.4276156603315684

Epoch: 5| Step: 2
Training loss: 1.7792574797539151
Validation loss: 2.44321752105141

Epoch: 5| Step: 3
Training loss: 1.8680455618413359
Validation loss: 2.420632463401135

Epoch: 5| Step: 4
Training loss: 2.0552130777568807
Validation loss: 2.412984849947177

Epoch: 5| Step: 5
Training loss: 1.6111655043412363
Validation loss: 2.3723316174255498

Epoch: 5| Step: 6
Training loss: 1.9070022849602855
Validation loss: 2.3836434486081184

Epoch: 5| Step: 7
Training loss: 1.4253470817975764
Validation loss: 2.415535381622185

Epoch: 5| Step: 8
Training loss: 1.790823789949522
Validation loss: 2.411931845465828

Epoch: 5| Step: 9
Training loss: 1.7629394362200959
Validation loss: 2.4494439744542063

Epoch: 5| Step: 10
Training loss: 1.4361694646687584
Validation loss: 2.461955992980011

Epoch: 228| Step: 0
Training loss: 1.3259336007497158
Validation loss: 2.463392374443831

Epoch: 5| Step: 1
Training loss: 1.9281388837169182
Validation loss: 2.4394896847620413

Epoch: 5| Step: 2
Training loss: 1.4692442042243108
Validation loss: 2.430383519316585

Epoch: 5| Step: 3
Training loss: 1.850884937298087
Validation loss: 2.403194733171249

Epoch: 5| Step: 4
Training loss: 1.9264796849478387
Validation loss: 2.4118447818139725

Epoch: 5| Step: 5
Training loss: 1.8104945960207832
Validation loss: 2.414708020243354

Epoch: 5| Step: 6
Training loss: 1.5323783454089899
Validation loss: 2.38240737631523

Epoch: 5| Step: 7
Training loss: 1.3572698494286575
Validation loss: 2.3975717138228614

Epoch: 5| Step: 8
Training loss: 2.0887927683681338
Validation loss: 2.41300337768779

Epoch: 5| Step: 9
Training loss: 1.6918397836786128
Validation loss: 2.397799407369031

Epoch: 5| Step: 10
Training loss: 1.6984910831930438
Validation loss: 2.388870139937561

Epoch: 229| Step: 0
Training loss: 1.1087113665502069
Validation loss: 2.3770698277862508

Epoch: 5| Step: 1
Training loss: 1.8058590079704702
Validation loss: 2.3723684173149264

Epoch: 5| Step: 2
Training loss: 1.4463086793381816
Validation loss: 2.387864914877366

Epoch: 5| Step: 3
Training loss: 1.6751373405517214
Validation loss: 2.378590311172276

Epoch: 5| Step: 4
Training loss: 1.2914123848863421
Validation loss: 2.3937798854749013

Epoch: 5| Step: 5
Training loss: 1.7904294051949026
Validation loss: 2.39643247227758

Epoch: 5| Step: 6
Training loss: 1.7643078642668746
Validation loss: 2.4093747316097534

Epoch: 5| Step: 7
Training loss: 1.5808635405270437
Validation loss: 2.408125293791575

Epoch: 5| Step: 8
Training loss: 1.9983501185565153
Validation loss: 2.3923023400277734

Epoch: 5| Step: 9
Training loss: 1.8565082408949178
Validation loss: 2.390431898654463

Epoch: 5| Step: 10
Training loss: 1.6914474799436834
Validation loss: 2.419269668043862

Epoch: 230| Step: 0
Training loss: 1.955454299513689
Validation loss: 2.538493862292182

Epoch: 5| Step: 1
Training loss: 1.8235383490464672
Validation loss: 2.5760503799964325

Epoch: 5| Step: 2
Training loss: 2.273590921685056
Validation loss: 2.5770914590856204

Epoch: 5| Step: 3
Training loss: 1.5905497714916188
Validation loss: 2.4449311688068898

Epoch: 5| Step: 4
Training loss: 1.5365124019441316
Validation loss: 2.4161628516932248

Epoch: 5| Step: 5
Training loss: 1.5908947219447445
Validation loss: 2.475714251558536

Epoch: 5| Step: 6
Training loss: 1.3336808625940135
Validation loss: 2.431077683753337

Epoch: 5| Step: 7
Training loss: 1.9577354032371521
Validation loss: 2.452634487643622

Epoch: 5| Step: 8
Training loss: 1.8222696155042386
Validation loss: 2.4327669581565528

Epoch: 5| Step: 9
Training loss: 1.8547780247026326
Validation loss: 2.365672117568612

Epoch: 5| Step: 10
Training loss: 1.5338415675355543
Validation loss: 2.349378293206013

Epoch: 231| Step: 0
Training loss: 1.8423239155121363
Validation loss: 2.3713502068283363

Epoch: 5| Step: 1
Training loss: 1.7870796909889581
Validation loss: 2.3806603955322414

Epoch: 5| Step: 2
Training loss: 1.4737247870620547
Validation loss: 2.3782199853316572

Epoch: 5| Step: 3
Training loss: 1.3104786066276128
Validation loss: 2.44688362695574

Epoch: 5| Step: 4
Training loss: 2.0652222441260544
Validation loss: 2.541180953752099

Epoch: 5| Step: 5
Training loss: 1.8098537595693254
Validation loss: 2.5708023822778934

Epoch: 5| Step: 6
Training loss: 1.2869411700125388
Validation loss: 2.524432174570991

Epoch: 5| Step: 7
Training loss: 1.8418120851829196
Validation loss: 2.4932019662240994

Epoch: 5| Step: 8
Training loss: 1.9725420323910872
Validation loss: 2.44278934119754

Epoch: 5| Step: 9
Training loss: 1.8622464359416802
Validation loss: 2.431600960390996

Epoch: 5| Step: 10
Training loss: 2.029071167481283
Validation loss: 2.4021876466757512

Epoch: 232| Step: 0
Training loss: 1.634165080431386
Validation loss: 2.3799471147824067

Epoch: 5| Step: 1
Training loss: 1.934849433462376
Validation loss: 2.356566084540436

Epoch: 5| Step: 2
Training loss: 1.6159552703275741
Validation loss: 2.363975420376104

Epoch: 5| Step: 3
Training loss: 1.4280903551169057
Validation loss: 2.344732125531651

Epoch: 5| Step: 4
Training loss: 1.6465287570243436
Validation loss: 2.3389385076786224

Epoch: 5| Step: 5
Training loss: 1.5954952781652803
Validation loss: 2.347891245375695

Epoch: 5| Step: 6
Training loss: 1.739046901142804
Validation loss: 2.3727518093776223

Epoch: 5| Step: 7
Training loss: 2.1760037923036517
Validation loss: 2.431394896858231

Epoch: 5| Step: 8
Training loss: 1.4216735194057104
Validation loss: 2.4642830412403973

Epoch: 5| Step: 9
Training loss: 1.5961291936149657
Validation loss: 2.5339414820140127

Epoch: 5| Step: 10
Training loss: 1.6095686860800165
Validation loss: 2.4599925232061746

Epoch: 233| Step: 0
Training loss: 1.184860307209807
Validation loss: 2.424069135594628

Epoch: 5| Step: 1
Training loss: 1.9978341654058198
Validation loss: 2.422265359604432

Epoch: 5| Step: 2
Training loss: 1.59956771554135
Validation loss: 2.3995396177315214

Epoch: 5| Step: 3
Training loss: 1.285107550814341
Validation loss: 2.3773358186666447

Epoch: 5| Step: 4
Training loss: 1.8684255413994058
Validation loss: 2.408125884633083

Epoch: 5| Step: 5
Training loss: 1.8294066802456186
Validation loss: 2.4159556167764555

Epoch: 5| Step: 6
Training loss: 1.660749118632999
Validation loss: 2.4178642902303635

Epoch: 5| Step: 7
Training loss: 1.5282841199788064
Validation loss: 2.4328365535520273

Epoch: 5| Step: 8
Training loss: 1.8335512927568092
Validation loss: 2.4248456600741313

Epoch: 5| Step: 9
Training loss: 1.6058552594643656
Validation loss: 2.4294750757931016

Epoch: 5| Step: 10
Training loss: 1.717649558384035
Validation loss: 2.433178389166524

Epoch: 234| Step: 0
Training loss: 1.096693057541775
Validation loss: 2.398986012951422

Epoch: 5| Step: 1
Training loss: 1.6430586430676557
Validation loss: 2.417600320526098

Epoch: 5| Step: 2
Training loss: 1.0860308051333012
Validation loss: 2.4392823065461364

Epoch: 5| Step: 3
Training loss: 1.773302316764876
Validation loss: 2.4299356058044523

Epoch: 5| Step: 4
Training loss: 1.870672062958275
Validation loss: 2.4228409644587656

Epoch: 5| Step: 5
Training loss: 1.768050291951387
Validation loss: 2.392000381131124

Epoch: 5| Step: 6
Training loss: 1.959025389222012
Validation loss: 2.358379331852029

Epoch: 5| Step: 7
Training loss: 1.3668851681624556
Validation loss: 2.3847819371061263

Epoch: 5| Step: 8
Training loss: 1.664065222223052
Validation loss: 2.3654981322328683

Epoch: 5| Step: 9
Training loss: 1.377302842336004
Validation loss: 2.3528003137809343

Epoch: 5| Step: 10
Training loss: 1.3204742874247875
Validation loss: 2.345581382133297

Epoch: 235| Step: 0
Training loss: 1.0496961812565773
Validation loss: 2.357638304403922

Epoch: 5| Step: 1
Training loss: 2.0785079259072075
Validation loss: 2.3901643866272133

Epoch: 5| Step: 2
Training loss: 1.2945971880219398
Validation loss: 2.382828418793501

Epoch: 5| Step: 3
Training loss: 1.6229566785444796
Validation loss: 2.364989373004293

Epoch: 5| Step: 4
Training loss: 1.7552688844765418
Validation loss: 2.3759721909924045

Epoch: 5| Step: 5
Training loss: 1.6710252117353002
Validation loss: 2.388254522686032

Epoch: 5| Step: 6
Training loss: 1.4021350843487435
Validation loss: 2.3912233240239518

Epoch: 5| Step: 7
Training loss: 1.4337336084814052
Validation loss: 2.401963666036113

Epoch: 5| Step: 8
Training loss: 1.6418580280961652
Validation loss: 2.4015168270224505

Epoch: 5| Step: 9
Training loss: 1.2934693810754327
Validation loss: 2.406296588290616

Epoch: 5| Step: 10
Training loss: 1.6398444362455389
Validation loss: 2.39635264977724

Epoch: 236| Step: 0
Training loss: 1.6304489624401968
Validation loss: 2.4104365310178717

Epoch: 5| Step: 1
Training loss: 1.6108148300573806
Validation loss: 2.380490795709078

Epoch: 5| Step: 2
Training loss: 1.3667222457532266
Validation loss: 2.375329441133759

Epoch: 5| Step: 3
Training loss: 1.4754199900998628
Validation loss: 2.3845675627913496

Epoch: 5| Step: 4
Training loss: 1.4583304087291638
Validation loss: 2.3597408278090612

Epoch: 5| Step: 5
Training loss: 1.8492868982222974
Validation loss: 2.3765477155203834

Epoch: 5| Step: 6
Training loss: 1.2784768308167027
Validation loss: 2.366153141385584

Epoch: 5| Step: 7
Training loss: 0.9232963337927413
Validation loss: 2.3847912175632606

Epoch: 5| Step: 8
Training loss: 1.4635480109062569
Validation loss: 2.381607042849358

Epoch: 5| Step: 9
Training loss: 1.5378046462771837
Validation loss: 2.3998626117836723

Epoch: 5| Step: 10
Training loss: 1.8888238571541
Validation loss: 2.401625359269443

Epoch: 237| Step: 0
Training loss: 1.190642365256402
Validation loss: 2.3773201434713944

Epoch: 5| Step: 1
Training loss: 1.5451129934972232
Validation loss: 2.354372234627438

Epoch: 5| Step: 2
Training loss: 1.5749963397028943
Validation loss: 2.3765680504720232

Epoch: 5| Step: 3
Training loss: 1.4783112196933088
Validation loss: 2.367178896710984

Epoch: 5| Step: 4
Training loss: 1.5228265564330639
Validation loss: 2.3721462757995813

Epoch: 5| Step: 5
Training loss: 1.3263569451303014
Validation loss: 2.375177531955291

Epoch: 5| Step: 6
Training loss: 1.3052130913958497
Validation loss: 2.369819563239785

Epoch: 5| Step: 7
Training loss: 1.5536874593115322
Validation loss: 2.373651835376616

Epoch: 5| Step: 8
Training loss: 1.4781014632111271
Validation loss: 2.3803917002873223

Epoch: 5| Step: 9
Training loss: 1.5580223776222706
Validation loss: 2.4004759499879342

Epoch: 5| Step: 10
Training loss: 1.8288285295543933
Validation loss: 2.389974526130433

Epoch: 238| Step: 0
Training loss: 1.581764631999243
Validation loss: 2.3899283769799267

Epoch: 5| Step: 1
Training loss: 1.3423108667025447
Validation loss: 2.3630716535833263

Epoch: 5| Step: 2
Training loss: 1.3659074731239313
Validation loss: 2.3772589589687905

Epoch: 5| Step: 3
Training loss: 1.578652246609654
Validation loss: 2.38147088847054

Epoch: 5| Step: 4
Training loss: 1.3319629640499424
Validation loss: 2.3624270297499397

Epoch: 5| Step: 5
Training loss: 1.2734737274071901
Validation loss: 2.359105593050325

Epoch: 5| Step: 6
Training loss: 1.3324241170693767
Validation loss: 2.359532108249511

Epoch: 5| Step: 7
Training loss: 1.5685109294477737
Validation loss: 2.3648283856166104

Epoch: 5| Step: 8
Training loss: 1.7234226865987778
Validation loss: 2.3713361699271513

Epoch: 5| Step: 9
Training loss: 0.96241782692232
Validation loss: 2.3689771501695884

Epoch: 5| Step: 10
Training loss: 1.7654918519174796
Validation loss: 2.3467858072169783

Epoch: 239| Step: 0
Training loss: 1.1842313251565058
Validation loss: 2.3657167757579813

Epoch: 5| Step: 1
Training loss: 1.3187343036024826
Validation loss: 2.3488850312122986

Epoch: 5| Step: 2
Training loss: 1.4678658604155845
Validation loss: 2.353964224548926

Epoch: 5| Step: 3
Training loss: 1.5014747681328513
Validation loss: 2.3530212670147908

Epoch: 5| Step: 4
Training loss: 1.1234463984491176
Validation loss: 2.384607425967412

Epoch: 5| Step: 5
Training loss: 1.9313569048578931
Validation loss: 2.364801149002087

Epoch: 5| Step: 6
Training loss: 1.3067093219574328
Validation loss: 2.402105997257545

Epoch: 5| Step: 7
Training loss: 1.5235737275079488
Validation loss: 2.3798310098416375

Epoch: 5| Step: 8
Training loss: 1.4408451632000632
Validation loss: 2.364425755480917

Epoch: 5| Step: 9
Training loss: 1.4516530939745802
Validation loss: 2.3379527926259054

Epoch: 5| Step: 10
Training loss: 1.2914323235272205
Validation loss: 2.3389050663398727

Epoch: 240| Step: 0
Training loss: 1.1550395403117302
Validation loss: 2.3222948604444142

Epoch: 5| Step: 1
Training loss: 1.8607284364405428
Validation loss: 2.3265696410102032

Epoch: 5| Step: 2
Training loss: 1.209916256379034
Validation loss: 2.3569580076316714

Epoch: 5| Step: 3
Training loss: 1.362334570334775
Validation loss: 2.329207469386065

Epoch: 5| Step: 4
Training loss: 1.4962174884830104
Validation loss: 2.362581952564952

Epoch: 5| Step: 5
Training loss: 1.3934137049831479
Validation loss: 2.3881014832447733

Epoch: 5| Step: 6
Training loss: 1.3839808555254651
Validation loss: 2.3565576807195754

Epoch: 5| Step: 7
Training loss: 1.503588357991264
Validation loss: 2.378358585102224

Epoch: 5| Step: 8
Training loss: 1.2438739388980504
Validation loss: 2.3729280653481193

Epoch: 5| Step: 9
Training loss: 1.4752116003037585
Validation loss: 2.3777305480393287

Epoch: 5| Step: 10
Training loss: 1.411442516092822
Validation loss: 2.3979197879289598

Epoch: 241| Step: 0
Training loss: 1.1359260128232742
Validation loss: 2.3651233197652033

Epoch: 5| Step: 1
Training loss: 1.6891117875691801
Validation loss: 2.4052985432692977

Epoch: 5| Step: 2
Training loss: 0.9523472974427943
Validation loss: 2.3820799757496336

Epoch: 5| Step: 3
Training loss: 1.5796800260433046
Validation loss: 2.3979554499745452

Epoch: 5| Step: 4
Training loss: 1.2057717180536474
Validation loss: 2.389669232773931

Epoch: 5| Step: 5
Training loss: 1.2844962886520588
Validation loss: 2.3983339505991994

Epoch: 5| Step: 6
Training loss: 1.3318248152530665
Validation loss: 2.3537309072519803

Epoch: 5| Step: 7
Training loss: 1.2675063666911741
Validation loss: 2.34245365182728

Epoch: 5| Step: 8
Training loss: 1.3922130646590078
Validation loss: 2.3304414436924983

Epoch: 5| Step: 9
Training loss: 1.568875998494184
Validation loss: 2.349755766654302

Epoch: 5| Step: 10
Training loss: 1.808478201353253
Validation loss: 2.3587022460723635

Epoch: 242| Step: 0
Training loss: 1.1616396170923555
Validation loss: 2.3074534475290043

Epoch: 5| Step: 1
Training loss: 1.2829583107232414
Validation loss: 2.3739489991594986

Epoch: 5| Step: 2
Training loss: 1.617813652558383
Validation loss: 2.357697168799294

Epoch: 5| Step: 3
Training loss: 1.17588613048698
Validation loss: 2.3621333410517455

Epoch: 5| Step: 4
Training loss: 1.452452309066816
Validation loss: 2.3506195016747964

Epoch: 5| Step: 5
Training loss: 1.3614253662056206
Validation loss: 2.3486723774328104

Epoch: 5| Step: 6
Training loss: 1.3262692220519114
Validation loss: 2.3283892746709802

Epoch: 5| Step: 7
Training loss: 1.2473083603464301
Validation loss: 2.303472362029694

Epoch: 5| Step: 8
Training loss: 1.737150566036465
Validation loss: 2.297597477261813

Epoch: 5| Step: 9
Training loss: 1.1988130063234421
Validation loss: 2.310791332226065

Epoch: 5| Step: 10
Training loss: 1.3936119148036306
Validation loss: 2.3224694496430045

Epoch: 243| Step: 0
Training loss: 1.470641196924094
Validation loss: 2.3340334859946483

Epoch: 5| Step: 1
Training loss: 1.2960737119922692
Validation loss: 2.337770125147711

Epoch: 5| Step: 2
Training loss: 1.3835437802252326
Validation loss: 2.3757690302905923

Epoch: 5| Step: 3
Training loss: 1.4067098501471138
Validation loss: 2.3926780496658067

Epoch: 5| Step: 4
Training loss: 1.627995151606283
Validation loss: 2.4169965139851444

Epoch: 5| Step: 5
Training loss: 1.3520215087455056
Validation loss: 2.353514081487846

Epoch: 5| Step: 6
Training loss: 1.394038179993964
Validation loss: 2.3385302823844736

Epoch: 5| Step: 7
Training loss: 1.22801783048005
Validation loss: 2.311716923804124

Epoch: 5| Step: 8
Training loss: 1.2788575794091266
Validation loss: 2.322144483252696

Epoch: 5| Step: 9
Training loss: 1.3899951751542914
Validation loss: 2.308571740237732

Epoch: 5| Step: 10
Training loss: 1.201346333557928
Validation loss: 2.314851450553855

Epoch: 244| Step: 0
Training loss: 1.2383768423830488
Validation loss: 2.311569221662472

Epoch: 5| Step: 1
Training loss: 1.1471412245754589
Validation loss: 2.3355746482474626

Epoch: 5| Step: 2
Training loss: 1.6126532637039297
Validation loss: 2.371550250127226

Epoch: 5| Step: 3
Training loss: 1.0124952951957749
Validation loss: 2.3864789453966484

Epoch: 5| Step: 4
Training loss: 1.359041852796404
Validation loss: 2.368301012743317

Epoch: 5| Step: 5
Training loss: 1.2963569249754339
Validation loss: 2.361436017157511

Epoch: 5| Step: 6
Training loss: 1.2054264795453564
Validation loss: 2.3363088307913418

Epoch: 5| Step: 7
Training loss: 1.6997674165830143
Validation loss: 2.351879611560384

Epoch: 5| Step: 8
Training loss: 1.1576973388069265
Validation loss: 2.3382989948580195

Epoch: 5| Step: 9
Training loss: 1.6053202391013326
Validation loss: 2.332407027695368

Epoch: 5| Step: 10
Training loss: 1.2498172626438
Validation loss: 2.316565174565875

Epoch: 245| Step: 0
Training loss: 1.4015563624491103
Validation loss: 2.3247276084840705

Epoch: 5| Step: 1
Training loss: 1.7162214232619666
Validation loss: 2.316206212856857

Epoch: 5| Step: 2
Training loss: 1.2402079421703394
Validation loss: 2.3046402898742846

Epoch: 5| Step: 3
Training loss: 1.2808660071347577
Validation loss: 2.3186733521414737

Epoch: 5| Step: 4
Training loss: 1.2144478401174612
Validation loss: 2.315926925741728

Epoch: 5| Step: 5
Training loss: 1.5447843661642737
Validation loss: 2.314992396849979

Epoch: 5| Step: 6
Training loss: 1.6448437898899848
Validation loss: 2.3110758601393377

Epoch: 5| Step: 7
Training loss: 1.2926340736046351
Validation loss: 2.3055467180618985

Epoch: 5| Step: 8
Training loss: 0.960656784117529
Validation loss: 2.3075756954744735

Epoch: 5| Step: 9
Training loss: 0.9430245383762322
Validation loss: 2.3117147485449387

Epoch: 5| Step: 10
Training loss: 0.8648130196036815
Validation loss: 2.31258984485157

Epoch: 246| Step: 0
Training loss: 1.4005495457409114
Validation loss: 2.340013286323926

Epoch: 5| Step: 1
Training loss: 1.0866731854888787
Validation loss: 2.3310351911193856

Epoch: 5| Step: 2
Training loss: 1.2933720077962265
Validation loss: 2.359208495886127

Epoch: 5| Step: 3
Training loss: 1.4414366018516362
Validation loss: 2.345085634154392

Epoch: 5| Step: 4
Training loss: 1.2170267882897718
Validation loss: 2.3553116275833994

Epoch: 5| Step: 5
Training loss: 1.0317189277534384
Validation loss: 2.336680045522351

Epoch: 5| Step: 6
Training loss: 1.6563897703682595
Validation loss: 2.3515259675816593

Epoch: 5| Step: 7
Training loss: 1.4593261155103483
Validation loss: 2.298107289616305

Epoch: 5| Step: 8
Training loss: 1.0618617440800142
Validation loss: 2.3070391359805584

Epoch: 5| Step: 9
Training loss: 1.0562279083830945
Validation loss: 2.28597488877972

Epoch: 5| Step: 10
Training loss: 1.5392816068109592
Validation loss: 2.36520133255334

Epoch: 247| Step: 0
Training loss: 1.150027776465619
Validation loss: 2.335424868721576

Epoch: 5| Step: 1
Training loss: 1.3052830964170157
Validation loss: 2.3027361896828547

Epoch: 5| Step: 2
Training loss: 1.1813677007578636
Validation loss: 2.290438140583599

Epoch: 5| Step: 3
Training loss: 1.09103241227043
Validation loss: 2.2572306380600033

Epoch: 5| Step: 4
Training loss: 1.1318844907416434
Validation loss: 2.277354246144994

Epoch: 5| Step: 5
Training loss: 1.6323366338706746
Validation loss: 2.3226697199955764

Epoch: 5| Step: 6
Training loss: 1.3379331261782563
Validation loss: 2.3045835371086687

Epoch: 5| Step: 7
Training loss: 1.3695051331105295
Validation loss: 2.3298768981731603

Epoch: 5| Step: 8
Training loss: 1.2075879933300209
Validation loss: 2.3417202906562458

Epoch: 5| Step: 9
Training loss: 1.6351799115229173
Validation loss: 2.3958222170050685

Epoch: 5| Step: 10
Training loss: 1.687862922354604
Validation loss: 2.342109303888673

Epoch: 248| Step: 0
Training loss: 1.1855721133215054
Validation loss: 2.328766237814084

Epoch: 5| Step: 1
Training loss: 1.4519261983448275
Validation loss: 2.3423184371460546

Epoch: 5| Step: 2
Training loss: 1.5689641373220997
Validation loss: 2.357279363436086

Epoch: 5| Step: 3
Training loss: 1.4492843900966041
Validation loss: 2.3557002437237706

Epoch: 5| Step: 4
Training loss: 1.4459998893262893
Validation loss: 2.386584369623818

Epoch: 5| Step: 5
Training loss: 1.0682321643585793
Validation loss: 2.407728180375776

Epoch: 5| Step: 6
Training loss: 1.161640591996929
Validation loss: 2.3405153810718566

Epoch: 5| Step: 7
Training loss: 1.2965898774870628
Validation loss: 2.342986597682523

Epoch: 5| Step: 8
Training loss: 1.3754203760666601
Validation loss: 2.3420911161729565

Epoch: 5| Step: 9
Training loss: 0.968633737047907
Validation loss: 2.3370419193845438

Epoch: 5| Step: 10
Training loss: 1.5923988748538296
Validation loss: 2.3601184497545145

Epoch: 249| Step: 0
Training loss: 1.4758702022629266
Validation loss: 2.3457464453367045

Epoch: 5| Step: 1
Training loss: 1.0158040402397597
Validation loss: 2.3438378856957756

Epoch: 5| Step: 2
Training loss: 1.4029611912455866
Validation loss: 2.3880805975626367

Epoch: 5| Step: 3
Training loss: 1.4151231360354555
Validation loss: 2.3781203274292007

Epoch: 5| Step: 4
Training loss: 1.262290706849267
Validation loss: 2.3728162146919396

Epoch: 5| Step: 5
Training loss: 1.2239764218989029
Validation loss: 2.439107425359489

Epoch: 5| Step: 6
Training loss: 1.3930905377116007
Validation loss: 2.4888819824192265

Epoch: 5| Step: 7
Training loss: 1.4588192357333982
Validation loss: 2.452444236679783

Epoch: 5| Step: 8
Training loss: 1.218965071261455
Validation loss: 2.4134658993273845

Epoch: 5| Step: 9
Training loss: 1.322666349783662
Validation loss: 2.401955580079435

Epoch: 5| Step: 10
Training loss: 1.391185947393525
Validation loss: 2.3816598730613916

Epoch: 250| Step: 0
Training loss: 0.9247314037382711
Validation loss: 2.380527012853411

Epoch: 5| Step: 1
Training loss: 1.3460950571364898
Validation loss: 2.3410944660576987

Epoch: 5| Step: 2
Training loss: 0.9303498353088007
Validation loss: 2.347158304157961

Epoch: 5| Step: 3
Training loss: 0.7967139062549068
Validation loss: 2.3212304366887877

Epoch: 5| Step: 4
Training loss: 1.390304614246424
Validation loss: 2.3160719685050877

Epoch: 5| Step: 5
Training loss: 1.868057431389845
Validation loss: 2.308645449906329

Epoch: 5| Step: 6
Training loss: 0.9062302028203679
Validation loss: 2.284717351559564

Epoch: 5| Step: 7
Training loss: 1.2601634735449059
Validation loss: 2.2961898687627262

Epoch: 5| Step: 8
Training loss: 1.1421792401851383
Validation loss: 2.3143217648432683

Epoch: 5| Step: 9
Training loss: 1.4486775583055853
Validation loss: 2.3549445864632053

Epoch: 5| Step: 10
Training loss: 1.7222137920966334
Validation loss: 2.370220894510639

Epoch: 251| Step: 0
Training loss: 1.2876772749250958
Validation loss: 2.4072093982064215

Epoch: 5| Step: 1
Training loss: 0.9876572821704822
Validation loss: 2.396793899119196

Epoch: 5| Step: 2
Training loss: 1.2412540599376283
Validation loss: 2.4277402610292653

Epoch: 5| Step: 3
Training loss: 1.2030778355457088
Validation loss: 2.434955176147479

Epoch: 5| Step: 4
Training loss: 1.3138096950626823
Validation loss: 2.439056780709099

Epoch: 5| Step: 5
Training loss: 1.1954920016874362
Validation loss: 2.3797168480511406

Epoch: 5| Step: 6
Training loss: 1.0658689829273011
Validation loss: 2.355104180421251

Epoch: 5| Step: 7
Training loss: 1.3260613958664582
Validation loss: 2.341843133550399

Epoch: 5| Step: 8
Training loss: 0.9058773326862168
Validation loss: 2.3219644761824805

Epoch: 5| Step: 9
Training loss: 1.8099901645877916
Validation loss: 2.3297049185672805

Epoch: 5| Step: 10
Training loss: 1.1722882368734617
Validation loss: 2.292382673424468

Epoch: 252| Step: 0
Training loss: 1.411345764776327
Validation loss: 2.2797304363866244

Epoch: 5| Step: 1
Training loss: 1.481897957638868
Validation loss: 2.2517462790706677

Epoch: 5| Step: 2
Training loss: 1.2068509951811375
Validation loss: 2.2408223446303555

Epoch: 5| Step: 3
Training loss: 1.202822064990781
Validation loss: 2.283600629312912

Epoch: 5| Step: 4
Training loss: 1.35904987875805
Validation loss: 2.261422298549364

Epoch: 5| Step: 5
Training loss: 1.228296936657067
Validation loss: 2.2551630752555263

Epoch: 5| Step: 6
Training loss: 1.208648585707318
Validation loss: 2.2563069558370863

Epoch: 5| Step: 7
Training loss: 1.1475384884864117
Validation loss: 2.2847177285791465

Epoch: 5| Step: 8
Training loss: 0.6404217653520382
Validation loss: 2.260225591801043

Epoch: 5| Step: 9
Training loss: 1.0198240480876701
Validation loss: 2.3032806385081597

Epoch: 5| Step: 10
Training loss: 1.495805996544982
Validation loss: 2.3176655932130417

Epoch: 253| Step: 0
Training loss: 0.8824688065178742
Validation loss: 2.3079272514478375

Epoch: 5| Step: 1
Training loss: 1.3061808645396653
Validation loss: 2.3408098709448746

Epoch: 5| Step: 2
Training loss: 1.121834540102426
Validation loss: 2.336090606370166

Epoch: 5| Step: 3
Training loss: 0.9210512392492455
Validation loss: 2.324104115020356

Epoch: 5| Step: 4
Training loss: 1.2183065341205934
Validation loss: 2.314562511061532

Epoch: 5| Step: 5
Training loss: 1.19607669113024
Validation loss: 2.3253096031776863

Epoch: 5| Step: 6
Training loss: 1.4110281407167802
Validation loss: 2.2940775673116938

Epoch: 5| Step: 7
Training loss: 1.1730851092539991
Validation loss: 2.289221684474029

Epoch: 5| Step: 8
Training loss: 1.4135401482832795
Validation loss: 2.3271433116417515

Epoch: 5| Step: 9
Training loss: 0.9731347619009912
Validation loss: 2.3168831813124546

Epoch: 5| Step: 10
Training loss: 1.4739121159113584
Validation loss: 2.3428832991354676

Epoch: 254| Step: 0
Training loss: 1.1769973700987442
Validation loss: 2.3377278534341825

Epoch: 5| Step: 1
Training loss: 0.9915687854662606
Validation loss: 2.286879601848887

Epoch: 5| Step: 2
Training loss: 0.9462803071584451
Validation loss: 2.2992774297842757

Epoch: 5| Step: 3
Training loss: 1.5531119793167656
Validation loss: 2.2676370186698236

Epoch: 5| Step: 4
Training loss: 1.392062569267077
Validation loss: 2.235936922407928

Epoch: 5| Step: 5
Training loss: 1.3022795974317822
Validation loss: 2.222858477930513

Epoch: 5| Step: 6
Training loss: 0.9408117609504539
Validation loss: 2.2255302300234447

Epoch: 5| Step: 7
Training loss: 1.5025707309469372
Validation loss: 2.228468746506746

Epoch: 5| Step: 8
Training loss: 1.145087045334335
Validation loss: 2.2512588614022553

Epoch: 5| Step: 9
Training loss: 1.0528211681703223
Validation loss: 2.261536676614971

Epoch: 5| Step: 10
Training loss: 0.8064757541150278
Validation loss: 2.2154929464111577

Epoch: 255| Step: 0
Training loss: 1.1024399637670217
Validation loss: 2.2701670514122916

Epoch: 5| Step: 1
Training loss: 1.2719424311877956
Validation loss: 2.2979106910547618

Epoch: 5| Step: 2
Training loss: 1.111904001785132
Validation loss: 2.30692726508945

Epoch: 5| Step: 3
Training loss: 1.276165526730126
Validation loss: 2.330078064486906

Epoch: 5| Step: 4
Training loss: 1.2018365773106203
Validation loss: 2.3300124327102436

Epoch: 5| Step: 5
Training loss: 1.2208128368666453
Validation loss: 2.321627535402078

Epoch: 5| Step: 6
Training loss: 1.2313526672314568
Validation loss: 2.2939783408766976

Epoch: 5| Step: 7
Training loss: 1.2089164850403973
Validation loss: 2.301881931596725

Epoch: 5| Step: 8
Training loss: 0.996202500334556
Validation loss: 2.306311051177885

Epoch: 5| Step: 9
Training loss: 1.2167384836260506
Validation loss: 2.260571739064728

Epoch: 5| Step: 10
Training loss: 0.9526165090477079
Validation loss: 2.2510382810052243

Epoch: 256| Step: 0
Training loss: 1.0315117937191338
Validation loss: 2.249377697850869

Epoch: 5| Step: 1
Training loss: 1.1335662964665112
Validation loss: 2.228047620678669

Epoch: 5| Step: 2
Training loss: 1.243021463155154
Validation loss: 2.23848656147944

Epoch: 5| Step: 3
Training loss: 1.241659952098604
Validation loss: 2.23753117039905

Epoch: 5| Step: 4
Training loss: 0.897235298225485
Validation loss: 2.2393526187849244

Epoch: 5| Step: 5
Training loss: 1.0869880370049423
Validation loss: 2.2513419232077228

Epoch: 5| Step: 6
Training loss: 1.2231755235594508
Validation loss: 2.249518224393551

Epoch: 5| Step: 7
Training loss: 1.1210277152467911
Validation loss: 2.275473551757647

Epoch: 5| Step: 8
Training loss: 1.4934707635981403
Validation loss: 2.308368708607978

Epoch: 5| Step: 9
Training loss: 0.9568923226550725
Validation loss: 2.287201413757926

Epoch: 5| Step: 10
Training loss: 1.0351949432626883
Validation loss: 2.2848811764174086

Epoch: 257| Step: 0
Training loss: 1.2332464926449593
Validation loss: 2.302672404392178

Epoch: 5| Step: 1
Training loss: 0.7880725504932927
Validation loss: 2.280732425823312

Epoch: 5| Step: 2
Training loss: 1.3146960188524148
Validation loss: 2.2710563459468807

Epoch: 5| Step: 3
Training loss: 1.2827064795597112
Validation loss: 2.3189697169929424

Epoch: 5| Step: 4
Training loss: 1.166355256117623
Validation loss: 2.298558453463554

Epoch: 5| Step: 5
Training loss: 1.2709836193502804
Validation loss: 2.298740521451983

Epoch: 5| Step: 6
Training loss: 0.8823239823105141
Validation loss: 2.270575695507223

Epoch: 5| Step: 7
Training loss: 1.045779779793096
Validation loss: 2.2332573133297253

Epoch: 5| Step: 8
Training loss: 1.1922028426836715
Validation loss: 2.267688166840474

Epoch: 5| Step: 9
Training loss: 0.7483949573507012
Validation loss: 2.2422853837012857

Epoch: 5| Step: 10
Training loss: 1.301238429286497
Validation loss: 2.232113367732626

Epoch: 258| Step: 0
Training loss: 1.214089702365276
Validation loss: 2.225456231529598

Epoch: 5| Step: 1
Training loss: 1.08078283460103
Validation loss: 2.2477724865733695

Epoch: 5| Step: 2
Training loss: 0.9895090610673338
Validation loss: 2.2708138130781252

Epoch: 5| Step: 3
Training loss: 1.0422920574945154
Validation loss: 2.2545071002152834

Epoch: 5| Step: 4
Training loss: 1.2935509422601679
Validation loss: 2.2720132780063316

Epoch: 5| Step: 5
Training loss: 1.131099537069074
Validation loss: 2.301392785519513

Epoch: 5| Step: 6
Training loss: 0.7621265982319706
Validation loss: 2.2934004606129084

Epoch: 5| Step: 7
Training loss: 1.193376556622425
Validation loss: 2.2504020671217995

Epoch: 5| Step: 8
Training loss: 1.1428759586113668
Validation loss: 2.2705769075643647

Epoch: 5| Step: 9
Training loss: 1.273110938764703
Validation loss: 2.267591687196935

Epoch: 5| Step: 10
Training loss: 0.915292320094131
Validation loss: 2.2768192627619506

Epoch: 259| Step: 0
Training loss: 0.580805646595882
Validation loss: 2.259730206509255

Epoch: 5| Step: 1
Training loss: 0.9553204874460355
Validation loss: 2.252966610805666

Epoch: 5| Step: 2
Training loss: 1.1252990960845937
Validation loss: 2.2370909495404705

Epoch: 5| Step: 3
Training loss: 1.461571703660202
Validation loss: 2.247398059249603

Epoch: 5| Step: 4
Training loss: 1.2199603697327905
Validation loss: 2.2544095185953723

Epoch: 5| Step: 5
Training loss: 1.1595988877450663
Validation loss: 2.244018661040861

Epoch: 5| Step: 6
Training loss: 1.4144187183509462
Validation loss: 2.2507708447065746

Epoch: 5| Step: 7
Training loss: 0.9699062092653203
Validation loss: 2.255465411978649

Epoch: 5| Step: 8
Training loss: 0.6509456156766354
Validation loss: 2.225183134733252

Epoch: 5| Step: 9
Training loss: 0.6666446076160948
Validation loss: 2.262621439496807

Epoch: 5| Step: 10
Training loss: 1.2955195225842455
Validation loss: 2.262747057289524

Epoch: 260| Step: 0
Training loss: 0.9413631951707948
Validation loss: 2.2722703718692387

Epoch: 5| Step: 1
Training loss: 1.1326174337877222
Validation loss: 2.314468205821106

Epoch: 5| Step: 2
Training loss: 1.231809920590713
Validation loss: 2.2799288320201474

Epoch: 5| Step: 3
Training loss: 1.1261868574116383
Validation loss: 2.2279483761692

Epoch: 5| Step: 4
Training loss: 1.2066500657522088
Validation loss: 2.249250894583303

Epoch: 5| Step: 5
Training loss: 1.011810652045758
Validation loss: 2.2431140466060215

Epoch: 5| Step: 6
Training loss: 0.9082167101428505
Validation loss: 2.233027773652878

Epoch: 5| Step: 7
Training loss: 1.0754245718057378
Validation loss: 2.2355680452307234

Epoch: 5| Step: 8
Training loss: 1.1835181083051316
Validation loss: 2.242618940755433

Epoch: 5| Step: 9
Training loss: 1.1301441203684355
Validation loss: 2.2685913129879114

Epoch: 5| Step: 10
Training loss: 1.0378185082054645
Validation loss: 2.231052009289256

Epoch: 261| Step: 0
Training loss: 1.2203851148269593
Validation loss: 2.2812976958598243

Epoch: 5| Step: 1
Training loss: 0.982661527066612
Validation loss: 2.2839916104310842

Epoch: 5| Step: 2
Training loss: 1.0802506210795026
Validation loss: 2.2743784268895033

Epoch: 5| Step: 3
Training loss: 0.9556312129715016
Validation loss: 2.289694648141834

Epoch: 5| Step: 4
Training loss: 0.9815258998902966
Validation loss: 2.2884508470906417

Epoch: 5| Step: 5
Training loss: 0.8253572384120379
Validation loss: 2.287628945124969

Epoch: 5| Step: 6
Training loss: 1.0925693679365887
Validation loss: 2.295282569315442

Epoch: 5| Step: 7
Training loss: 1.3558975113253442
Validation loss: 2.2630210919984637

Epoch: 5| Step: 8
Training loss: 1.4817102707038257
Validation loss: 2.264196308776553

Epoch: 5| Step: 9
Training loss: 0.5604009139199875
Validation loss: 2.2836248746438055

Epoch: 5| Step: 10
Training loss: 0.7508196722672624
Validation loss: 2.275754885788723

Epoch: 262| Step: 0
Training loss: 0.7689312372331651
Validation loss: 2.2547625313473008

Epoch: 5| Step: 1
Training loss: 1.3194562855685545
Validation loss: 2.275191324332429

Epoch: 5| Step: 2
Training loss: 0.9929481654280801
Validation loss: 2.2616720269675645

Epoch: 5| Step: 3
Training loss: 1.0233436133730909
Validation loss: 2.246942927203621

Epoch: 5| Step: 4
Training loss: 1.1252276931921332
Validation loss: 2.1957436765359257

Epoch: 5| Step: 5
Training loss: 1.056700755892155
Validation loss: 2.2270482550783415

Epoch: 5| Step: 6
Training loss: 1.23653300487557
Validation loss: 2.203617858565671

Epoch: 5| Step: 7
Training loss: 1.3663997451513978
Validation loss: 2.2415880812141573

Epoch: 5| Step: 8
Training loss: 0.8805527248464092
Validation loss: 2.2106732234763835

Epoch: 5| Step: 9
Training loss: 1.0741496670790676
Validation loss: 2.229353966912271

Epoch: 5| Step: 10
Training loss: 0.6649964664838602
Validation loss: 2.252383720673824

Epoch: 263| Step: 0
Training loss: 1.2415812230420709
Validation loss: 2.2969675152186095

Epoch: 5| Step: 1
Training loss: 1.2570168010101737
Validation loss: 2.2726468723372553

Epoch: 5| Step: 2
Training loss: 1.0523886033137395
Validation loss: 2.267952281193302

Epoch: 5| Step: 3
Training loss: 0.7037314872271666
Validation loss: 2.2561706285625394

Epoch: 5| Step: 4
Training loss: 1.113246234543911
Validation loss: 2.2813733323635335

Epoch: 5| Step: 5
Training loss: 1.179899133557686
Validation loss: 2.3291963803176907

Epoch: 5| Step: 6
Training loss: 0.9727481047985131
Validation loss: 2.3284558313516888

Epoch: 5| Step: 7
Training loss: 0.9556137798341723
Validation loss: 2.361388649655027

Epoch: 5| Step: 8
Training loss: 1.2548830974890242
Validation loss: 2.3165685598239545

Epoch: 5| Step: 9
Training loss: 0.7824656755639966
Validation loss: 2.3253536760730524

Epoch: 5| Step: 10
Training loss: 1.3525350522419113
Validation loss: 2.346856323087472

Epoch: 264| Step: 0
Training loss: 0.8373092021246488
Validation loss: 2.324658995307042

Epoch: 5| Step: 1
Training loss: 1.00235631612273
Validation loss: 2.3300813657489514

Epoch: 5| Step: 2
Training loss: 1.3174822114471045
Validation loss: 2.2497040794410985

Epoch: 5| Step: 3
Training loss: 1.0391995906024387
Validation loss: 2.2399874908939226

Epoch: 5| Step: 4
Training loss: 0.9309245622599591
Validation loss: 2.2692930396486184

Epoch: 5| Step: 5
Training loss: 0.7888518326037771
Validation loss: 2.270921702235223

Epoch: 5| Step: 6
Training loss: 0.8911759529545502
Validation loss: 2.2469040183248756

Epoch: 5| Step: 7
Training loss: 1.3331414571426778
Validation loss: 2.2635294019236962

Epoch: 5| Step: 8
Training loss: 0.7802928019807485
Validation loss: 2.2271611811888996

Epoch: 5| Step: 9
Training loss: 0.9529541988234465
Validation loss: 2.264846501670641

Epoch: 5| Step: 10
Training loss: 1.114702568925536
Validation loss: 2.2390178337542737

Epoch: 265| Step: 0
Training loss: 0.8778292690806123
Validation loss: 2.26561576663163

Epoch: 5| Step: 1
Training loss: 0.8702262013794059
Validation loss: 2.277500009678686

Epoch: 5| Step: 2
Training loss: 0.9021299034472733
Validation loss: 2.2943058653519257

Epoch: 5| Step: 3
Training loss: 0.8105946722070616
Validation loss: 2.3158084690365226

Epoch: 5| Step: 4
Training loss: 1.1516234134624637
Validation loss: 2.2807868063608625

Epoch: 5| Step: 5
Training loss: 0.8950631505115298
Validation loss: 2.2580047785567086

Epoch: 5| Step: 6
Training loss: 0.940374576779957
Validation loss: 2.306218985814698

Epoch: 5| Step: 7
Training loss: 1.2799427527798564
Validation loss: 2.2876654327694252

Epoch: 5| Step: 8
Training loss: 1.0281103486753476
Validation loss: 2.2844341720827686

Epoch: 5| Step: 9
Training loss: 1.1345247679486994
Validation loss: 2.2582091210101907

Epoch: 5| Step: 10
Training loss: 0.9904268517864527
Validation loss: 2.245149184290444

Epoch: 266| Step: 0
Training loss: 1.1138820164934347
Validation loss: 2.2324209287450136

Epoch: 5| Step: 1
Training loss: 0.8080778826012782
Validation loss: 2.2010306273447076

Epoch: 5| Step: 2
Training loss: 1.0638562690198392
Validation loss: 2.2547687176970244

Epoch: 5| Step: 3
Training loss: 1.1264314022317186
Validation loss: 2.2291117759051673

Epoch: 5| Step: 4
Training loss: 0.7616989524420433
Validation loss: 2.25265752750614

Epoch: 5| Step: 5
Training loss: 0.9244081962458958
Validation loss: 2.2371808050158273

Epoch: 5| Step: 6
Training loss: 0.998920633017669
Validation loss: 2.2621391220695726

Epoch: 5| Step: 7
Training loss: 1.0440795926268007
Validation loss: 2.2389278458993873

Epoch: 5| Step: 8
Training loss: 1.1066451536140463
Validation loss: 2.218845201316208

Epoch: 5| Step: 9
Training loss: 1.0205469443379536
Validation loss: 2.223299066573437

Epoch: 5| Step: 10
Training loss: 0.5942665663846549
Validation loss: 2.2262556151329584

Epoch: 267| Step: 0
Training loss: 1.1673024806490158
Validation loss: 2.2343529877201176

Epoch: 5| Step: 1
Training loss: 0.4047970833303898
Validation loss: 2.2485163125383383

Epoch: 5| Step: 2
Training loss: 1.2322527350722159
Validation loss: 2.2474183422111604

Epoch: 5| Step: 3
Training loss: 0.8891355541497928
Validation loss: 2.2255717466880585

Epoch: 5| Step: 4
Training loss: 0.7513291184945453
Validation loss: 2.210269270568554

Epoch: 5| Step: 5
Training loss: 0.8598114985871741
Validation loss: 2.2300917117090098

Epoch: 5| Step: 6
Training loss: 0.9197637012992642
Validation loss: 2.214131638565096

Epoch: 5| Step: 7
Training loss: 1.234374130828165
Validation loss: 2.218827411642067

Epoch: 5| Step: 8
Training loss: 0.9893248705716212
Validation loss: 2.2023614278607226

Epoch: 5| Step: 9
Training loss: 1.0402003203550145
Validation loss: 2.2407147910291836

Epoch: 5| Step: 10
Training loss: 0.8417176034514863
Validation loss: 2.2311240170571063

Epoch: 268| Step: 0
Training loss: 1.1554976928470015
Validation loss: 2.2562783458643607

Epoch: 5| Step: 1
Training loss: 1.108130388155347
Validation loss: 2.2724101596176185

Epoch: 5| Step: 2
Training loss: 1.027034408353229
Validation loss: 2.2612722029242414

Epoch: 5| Step: 3
Training loss: 1.0268346300971902
Validation loss: 2.257841915996808

Epoch: 5| Step: 4
Training loss: 0.932908161568104
Validation loss: 2.2382973336777243

Epoch: 5| Step: 5
Training loss: 0.8758695232949101
Validation loss: 2.2308251375084454

Epoch: 5| Step: 6
Training loss: 1.126955081931387
Validation loss: 2.235079518215108

Epoch: 5| Step: 7
Training loss: 0.8659886845935255
Validation loss: 2.259737804173978

Epoch: 5| Step: 8
Training loss: 0.6642113687037375
Validation loss: 2.220691415611551

Epoch: 5| Step: 9
Training loss: 0.6098028295042829
Validation loss: 2.235519824963884

Epoch: 5| Step: 10
Training loss: 1.008490400980713
Validation loss: 2.2132575029437827

Epoch: 269| Step: 0
Training loss: 0.9469779610128759
Validation loss: 2.2266535960720093

Epoch: 5| Step: 1
Training loss: 1.0765771673833873
Validation loss: 2.2247648761978245

Epoch: 5| Step: 2
Training loss: 0.788439325186136
Validation loss: 2.239689027810999

Epoch: 5| Step: 3
Training loss: 0.7314032630394908
Validation loss: 2.2869075263177967

Epoch: 5| Step: 4
Training loss: 1.0658245246668359
Validation loss: 2.3026534086301846

Epoch: 5| Step: 5
Training loss: 1.258368990984486
Validation loss: 2.303220202492967

Epoch: 5| Step: 6
Training loss: 1.0008943849651353
Validation loss: 2.2278554550638554

Epoch: 5| Step: 7
Training loss: 0.9213741687754865
Validation loss: 2.225077580565841

Epoch: 5| Step: 8
Training loss: 1.094103946636206
Validation loss: 2.1918362323294924

Epoch: 5| Step: 9
Training loss: 1.096820716927558
Validation loss: 2.244867969974191

Epoch: 5| Step: 10
Training loss: 0.7780761335724222
Validation loss: 2.2520611100517924

Epoch: 270| Step: 0
Training loss: 1.5644161681954714
Validation loss: 2.2875504907121242

Epoch: 5| Step: 1
Training loss: 0.5818610742625544
Validation loss: 2.2452250217651284

Epoch: 5| Step: 2
Training loss: 0.9697009925505972
Validation loss: 2.2277930977568325

Epoch: 5| Step: 3
Training loss: 0.7086746337890756
Validation loss: 2.2002733355841775

Epoch: 5| Step: 4
Training loss: 0.9280032119736498
Validation loss: 2.247354810906381

Epoch: 5| Step: 5
Training loss: 1.096716971031145
Validation loss: 2.251702817370707

Epoch: 5| Step: 6
Training loss: 0.992972326384796
Validation loss: 2.2410311285837157

Epoch: 5| Step: 7
Training loss: 0.9550801220582393
Validation loss: 2.2993398787781185

Epoch: 5| Step: 8
Training loss: 0.5907920389267285
Validation loss: 2.2660470775165513

Epoch: 5| Step: 9
Training loss: 1.0390636472767398
Validation loss: 2.2447538343877578

Epoch: 5| Step: 10
Training loss: 1.1184136124708877
Validation loss: 2.210352951794982

Epoch: 271| Step: 0
Training loss: 1.0615265819008166
Validation loss: 2.214654626812858

Epoch: 5| Step: 1
Training loss: 0.8078899176741778
Validation loss: 2.1859045615281487

Epoch: 5| Step: 2
Training loss: 1.096511297979218
Validation loss: 2.19302035498672

Epoch: 5| Step: 3
Training loss: 0.9628322808036138
Validation loss: 2.2005494125286034

Epoch: 5| Step: 4
Training loss: 0.6434201923430714
Validation loss: 2.193391534825591

Epoch: 5| Step: 5
Training loss: 1.1207618354956983
Validation loss: 2.2003571905947834

Epoch: 5| Step: 6
Training loss: 1.0160032301648674
Validation loss: 2.2195680685306973

Epoch: 5| Step: 7
Training loss: 0.9331409202081205
Validation loss: 2.2157529456616576

Epoch: 5| Step: 8
Training loss: 0.7640092109554332
Validation loss: 2.222639286113419

Epoch: 5| Step: 9
Training loss: 0.8468034383232793
Validation loss: 2.2293752316451223

Epoch: 5| Step: 10
Training loss: 1.035237492666112
Validation loss: 2.2107481968745777

Epoch: 272| Step: 0
Training loss: 0.9749337614007207
Validation loss: 2.2433195054607937

Epoch: 5| Step: 1
Training loss: 0.892697148974466
Validation loss: 2.2225598773701614

Epoch: 5| Step: 2
Training loss: 1.0256442673644164
Validation loss: 2.2177232662843314

Epoch: 5| Step: 3
Training loss: 0.8406957873068603
Validation loss: 2.21036815251603

Epoch: 5| Step: 4
Training loss: 1.0057337413955758
Validation loss: 2.2158285917715683

Epoch: 5| Step: 5
Training loss: 0.5495414849207569
Validation loss: 2.2328227317939193

Epoch: 5| Step: 6
Training loss: 1.0705236519022951
Validation loss: 2.205403607860423

Epoch: 5| Step: 7
Training loss: 0.6818859019749751
Validation loss: 2.231308184904569

Epoch: 5| Step: 8
Training loss: 1.14710526818253
Validation loss: 2.2062794399380126

Epoch: 5| Step: 9
Training loss: 0.7676846573455661
Validation loss: 2.207350670338616

Epoch: 5| Step: 10
Training loss: 1.108002902133873
Validation loss: 2.2027242972926064

Epoch: 273| Step: 0
Training loss: 0.8535590957291042
Validation loss: 2.1687855691035924

Epoch: 5| Step: 1
Training loss: 0.7605105477127672
Validation loss: 2.185228508549228

Epoch: 5| Step: 2
Training loss: 1.0976118302775395
Validation loss: 2.207873514991315

Epoch: 5| Step: 3
Training loss: 0.8492535426953358
Validation loss: 2.2169684456410867

Epoch: 5| Step: 4
Training loss: 1.0464359330616297
Validation loss: 2.239269719030627

Epoch: 5| Step: 5
Training loss: 1.2469361904493623
Validation loss: 2.231501330699356

Epoch: 5| Step: 6
Training loss: 0.7801194976089378
Validation loss: 2.225019142351515

Epoch: 5| Step: 7
Training loss: 1.0938356093553931
Validation loss: 2.245635997322811

Epoch: 5| Step: 8
Training loss: 0.6386604891354173
Validation loss: 2.2816233108254327

Epoch: 5| Step: 9
Training loss: 0.8628964494307446
Validation loss: 2.2889168506194633

Epoch: 5| Step: 10
Training loss: 0.5476165104051025
Validation loss: 2.2359451145794518

Epoch: 274| Step: 0
Training loss: 0.8291816448092064
Validation loss: 2.2571814057739967

Epoch: 5| Step: 1
Training loss: 0.6240917520634828
Validation loss: 2.2272267785439914

Epoch: 5| Step: 2
Training loss: 0.7498923065431854
Validation loss: 2.2023780945473375

Epoch: 5| Step: 3
Training loss: 0.8366577396891787
Validation loss: 2.2190063885350955

Epoch: 5| Step: 4
Training loss: 1.119214865999833
Validation loss: 2.2003318344787854

Epoch: 5| Step: 5
Training loss: 0.8577350922003111
Validation loss: 2.1884510966992767

Epoch: 5| Step: 6
Training loss: 1.1256563603143337
Validation loss: 2.209863750204794

Epoch: 5| Step: 7
Training loss: 0.71524111850295
Validation loss: 2.230916800718968

Epoch: 5| Step: 8
Training loss: 1.1452141504878466
Validation loss: 2.1935062401099388

Epoch: 5| Step: 9
Training loss: 0.9127166490858785
Validation loss: 2.230271774394868

Epoch: 5| Step: 10
Training loss: 1.1032526023483098
Validation loss: 2.2580709745531555

Epoch: 275| Step: 0
Training loss: 1.0356914935869201
Validation loss: 2.236189167903421

Epoch: 5| Step: 1
Training loss: 0.7226602090263176
Validation loss: 2.2673466761378087

Epoch: 5| Step: 2
Training loss: 0.8396782290561249
Validation loss: 2.270613706485403

Epoch: 5| Step: 3
Training loss: 0.8856525480929887
Validation loss: 2.2671864776135235

Epoch: 5| Step: 4
Training loss: 0.9089057747398788
Validation loss: 2.2764287170703463

Epoch: 5| Step: 5
Training loss: 1.2551305385346208
Validation loss: 2.2622756789468634

Epoch: 5| Step: 6
Training loss: 0.9086754667840669
Validation loss: 2.2530102253502196

Epoch: 5| Step: 7
Training loss: 0.7531299052731649
Validation loss: 2.2375613101697254

Epoch: 5| Step: 8
Training loss: 0.6480628620403852
Validation loss: 2.2360057196645142

Epoch: 5| Step: 9
Training loss: 0.9589341533119903
Validation loss: 2.243899590102844

Epoch: 5| Step: 10
Training loss: 1.3931227979133491
Validation loss: 2.2617984580362376

Epoch: 276| Step: 0
Training loss: 0.9660463136209244
Validation loss: 2.312774633026574

Epoch: 5| Step: 1
Training loss: 0.8874113763966811
Validation loss: 2.267769808995344

Epoch: 5| Step: 2
Training loss: 0.8007273958286756
Validation loss: 2.243112972285802

Epoch: 5| Step: 3
Training loss: 1.0535383392476563
Validation loss: 2.1982149968421996

Epoch: 5| Step: 4
Training loss: 0.9921068173742096
Validation loss: 2.2259561815254574

Epoch: 5| Step: 5
Training loss: 0.8813688914945246
Validation loss: 2.2275523948839595

Epoch: 5| Step: 6
Training loss: 1.0035081363456473
Validation loss: 2.2605197290029917

Epoch: 5| Step: 7
Training loss: 1.0119719317392413
Validation loss: 2.2332244085963127

Epoch: 5| Step: 8
Training loss: 0.9094332332252765
Validation loss: 2.2384903328049623

Epoch: 5| Step: 9
Training loss: 1.11837177596177
Validation loss: 2.231172115163472

Epoch: 5| Step: 10
Training loss: 0.7669981495562617
Validation loss: 2.1920495182863657

Epoch: 277| Step: 0
Training loss: 0.7493964786967043
Validation loss: 2.1716762766676876

Epoch: 5| Step: 1
Training loss: 0.8520578116315437
Validation loss: 2.1715172996651972

Epoch: 5| Step: 2
Training loss: 0.8721575207480095
Validation loss: 2.1912000874026742

Epoch: 5| Step: 3
Training loss: 0.670829958245769
Validation loss: 2.1915415180187003

Epoch: 5| Step: 4
Training loss: 0.7686275462184241
Validation loss: 2.2007874418279294

Epoch: 5| Step: 5
Training loss: 1.1798353292038155
Validation loss: 2.2144469737907593

Epoch: 5| Step: 6
Training loss: 0.9612463478048762
Validation loss: 2.2431419410361046

Epoch: 5| Step: 7
Training loss: 1.0527709501632776
Validation loss: 2.226709453897961

Epoch: 5| Step: 8
Training loss: 0.7300338266321577
Validation loss: 2.2109483235736818

Epoch: 5| Step: 9
Training loss: 0.9600260684328409
Validation loss: 2.227396019626275

Epoch: 5| Step: 10
Training loss: 0.6803546568986397
Validation loss: 2.2525294270452436

Epoch: 278| Step: 0
Training loss: 0.7174003617622096
Validation loss: 2.258840549482076

Epoch: 5| Step: 1
Training loss: 0.9758115704164968
Validation loss: 2.1947185285180204

Epoch: 5| Step: 2
Training loss: 0.7897973368635798
Validation loss: 2.225079515326095

Epoch: 5| Step: 3
Training loss: 0.7435965163277031
Validation loss: 2.2418311640108244

Epoch: 5| Step: 4
Training loss: 1.0877089288769952
Validation loss: 2.220401146653261

Epoch: 5| Step: 5
Training loss: 0.9106666541800026
Validation loss: 2.224101943484754

Epoch: 5| Step: 6
Training loss: 0.9307955702006195
Validation loss: 2.197015536096215

Epoch: 5| Step: 7
Training loss: 1.020856675380688
Validation loss: 2.1880833224533633

Epoch: 5| Step: 8
Training loss: 0.6655814805825535
Validation loss: 2.1799637190953347

Epoch: 5| Step: 9
Training loss: 0.7322997131194986
Validation loss: 2.159113793115189

Epoch: 5| Step: 10
Training loss: 0.8582457665956553
Validation loss: 2.176674927925697

Epoch: 279| Step: 0
Training loss: 1.0239853884801886
Validation loss: 2.188805340975448

Epoch: 5| Step: 1
Training loss: 1.0538059082223277
Validation loss: 2.1985952273379414

Epoch: 5| Step: 2
Training loss: 0.7210427081227233
Validation loss: 2.21546656051641

Epoch: 5| Step: 3
Training loss: 0.5681706537970492
Validation loss: 2.1726433300948003

Epoch: 5| Step: 4
Training loss: 0.9264030782561969
Validation loss: 2.174054423695423

Epoch: 5| Step: 5
Training loss: 0.6030122206795476
Validation loss: 2.1976411972742707

Epoch: 5| Step: 6
Training loss: 0.8853121789351991
Validation loss: 2.1768397894533296

Epoch: 5| Step: 7
Training loss: 0.8916453155445008
Validation loss: 2.209394880870433

Epoch: 5| Step: 8
Training loss: 0.8284488620504125
Validation loss: 2.2125566543306494

Epoch: 5| Step: 9
Training loss: 1.0040610821141367
Validation loss: 2.2351138144582174

Epoch: 5| Step: 10
Training loss: 0.724939564126167
Validation loss: 2.2198969516545013

Epoch: 280| Step: 0
Training loss: 0.5665736773104273
Validation loss: 2.2540004424268063

Epoch: 5| Step: 1
Training loss: 0.6768387254838186
Validation loss: 2.208866864851336

Epoch: 5| Step: 2
Training loss: 0.8610255256971767
Validation loss: 2.2188518916156084

Epoch: 5| Step: 3
Training loss: 0.828877880534973
Validation loss: 2.2217563410835424

Epoch: 5| Step: 4
Training loss: 1.037959093757859
Validation loss: 2.224580055436934

Epoch: 5| Step: 5
Training loss: 0.6076128496918298
Validation loss: 2.233901682444448

Epoch: 5| Step: 6
Training loss: 1.175890134921421
Validation loss: 2.243982445627266

Epoch: 5| Step: 7
Training loss: 0.8125605560624538
Validation loss: 2.2463307365243472

Epoch: 5| Step: 8
Training loss: 0.8589731143700787
Validation loss: 2.2078032047862837

Epoch: 5| Step: 9
Training loss: 0.9718461243979387
Validation loss: 2.2208859660815543

Epoch: 5| Step: 10
Training loss: 0.8517590917041028
Validation loss: 2.215060429195159

Epoch: 281| Step: 0
Training loss: 0.7196617149010694
Validation loss: 2.2236551441860044

Epoch: 5| Step: 1
Training loss: 0.8352112155165834
Validation loss: 2.222574447867311

Epoch: 5| Step: 2
Training loss: 0.6986781326622834
Validation loss: 2.228617547808249

Epoch: 5| Step: 3
Training loss: 0.9512814061197403
Validation loss: 2.2075631843255485

Epoch: 5| Step: 4
Training loss: 0.8526046046071607
Validation loss: 2.198704862864864

Epoch: 5| Step: 5
Training loss: 0.7204338749304323
Validation loss: 2.176358748026703

Epoch: 5| Step: 6
Training loss: 0.5741047648745269
Validation loss: 2.165381461771859

Epoch: 5| Step: 7
Training loss: 1.0981378550854475
Validation loss: 2.204967410584547

Epoch: 5| Step: 8
Training loss: 0.8122885869148719
Validation loss: 2.2124201845075864

Epoch: 5| Step: 9
Training loss: 0.9202137542753785
Validation loss: 2.200247061957748

Epoch: 5| Step: 10
Training loss: 0.9439913131710197
Validation loss: 2.2163710191232373

Epoch: 282| Step: 0
Training loss: 0.691083886811201
Validation loss: 2.2129715658138793

Epoch: 5| Step: 1
Training loss: 0.7348468157675706
Validation loss: 2.1851885313033503

Epoch: 5| Step: 2
Training loss: 0.7455905995263424
Validation loss: 2.206491931617252

Epoch: 5| Step: 3
Training loss: 0.8727380944704528
Validation loss: 2.2148549173532257

Epoch: 5| Step: 4
Training loss: 0.3651810673452843
Validation loss: 2.2007573389415103

Epoch: 5| Step: 5
Training loss: 1.0219104235747525
Validation loss: 2.211599755981946

Epoch: 5| Step: 6
Training loss: 0.7960638517955447
Validation loss: 2.208925303287716

Epoch: 5| Step: 7
Training loss: 0.9690652764953184
Validation loss: 2.217081121417578

Epoch: 5| Step: 8
Training loss: 0.5445765012659366
Validation loss: 2.2041055485180054

Epoch: 5| Step: 9
Training loss: 0.8027267641323925
Validation loss: 2.2315449104153675

Epoch: 5| Step: 10
Training loss: 1.1368194220884422
Validation loss: 2.2034532937598317

Epoch: 283| Step: 0
Training loss: 0.6999568559770404
Validation loss: 2.1725975611740624

Epoch: 5| Step: 1
Training loss: 0.7910536015189326
Validation loss: 2.193604442833561

Epoch: 5| Step: 2
Training loss: 0.8642323635686417
Validation loss: 2.20563170205156

Epoch: 5| Step: 3
Training loss: 0.3933109636263116
Validation loss: 2.1760333045511304

Epoch: 5| Step: 4
Training loss: 0.964250328030282
Validation loss: 2.224340140698757

Epoch: 5| Step: 5
Training loss: 0.5519890764734713
Validation loss: 2.1915360223442137

Epoch: 5| Step: 6
Training loss: 1.0506338136610776
Validation loss: 2.169923363027892

Epoch: 5| Step: 7
Training loss: 0.9042612155285212
Validation loss: 2.182486497203214

Epoch: 5| Step: 8
Training loss: 0.4383855100709189
Validation loss: 2.2130791911484993

Epoch: 5| Step: 9
Training loss: 0.9049383734696148
Validation loss: 2.202555143824319

Epoch: 5| Step: 10
Training loss: 0.9154597305762456
Validation loss: 2.178768658661327

Epoch: 284| Step: 0
Training loss: 0.6962793464571277
Validation loss: 2.176639943504921

Epoch: 5| Step: 1
Training loss: 0.6728458930276383
Validation loss: 2.206709027760029

Epoch: 5| Step: 2
Training loss: 0.8529348601683837
Validation loss: 2.1680752984577745

Epoch: 5| Step: 3
Training loss: 0.5426372366797257
Validation loss: 2.212039820698933

Epoch: 5| Step: 4
Training loss: 0.7981757225701254
Validation loss: 2.1743047164686358

Epoch: 5| Step: 5
Training loss: 1.1405969903720599
Validation loss: 2.1878335584182307

Epoch: 5| Step: 6
Training loss: 0.9647734767017585
Validation loss: 2.1920449559932043

Epoch: 5| Step: 7
Training loss: 0.8591869842157018
Validation loss: 2.2080195601246233

Epoch: 5| Step: 8
Training loss: 0.684372703339368
Validation loss: 2.1602340880334485

Epoch: 5| Step: 9
Training loss: 0.4482422706088652
Validation loss: 2.2139564729672037

Epoch: 5| Step: 10
Training loss: 0.7039735548080912
Validation loss: 2.1594197511714195

Epoch: 285| Step: 0
Training loss: 0.6793473368103919
Validation loss: 2.2143404453285

Epoch: 5| Step: 1
Training loss: 0.4895145861738755
Validation loss: 2.205162572875406

Epoch: 5| Step: 2
Training loss: 0.8069600726606045
Validation loss: 2.2192880364343694

Epoch: 5| Step: 3
Training loss: 0.7573063526714733
Validation loss: 2.17039281530713

Epoch: 5| Step: 4
Training loss: 1.1204682309754999
Validation loss: 2.1926715865191007

Epoch: 5| Step: 5
Training loss: 0.6460024832642365
Validation loss: 2.1797188865273998

Epoch: 5| Step: 6
Training loss: 0.7506718407975457
Validation loss: 2.2087427024145754

Epoch: 5| Step: 7
Training loss: 0.7957599917331901
Validation loss: 2.1659449609051515

Epoch: 5| Step: 8
Training loss: 0.7931347001536944
Validation loss: 2.17890637137519

Epoch: 5| Step: 9
Training loss: 0.6964618527316551
Validation loss: 2.177627594556194

Epoch: 5| Step: 10
Training loss: 0.8329009404557609
Validation loss: 2.152231162604

Epoch: 286| Step: 0
Training loss: 0.7936232923764802
Validation loss: 2.179384311997605

Epoch: 5| Step: 1
Training loss: 0.6257063212404171
Validation loss: 2.1735693132542795

Epoch: 5| Step: 2
Training loss: 0.6577756042281674
Validation loss: 2.2044257940079706

Epoch: 5| Step: 3
Training loss: 0.7479747607975968
Validation loss: 2.197951372886676

Epoch: 5| Step: 4
Training loss: 1.0495827231734136
Validation loss: 2.1994743789468014

Epoch: 5| Step: 5
Training loss: 1.0156941903828043
Validation loss: 2.1954192271845607

Epoch: 5| Step: 6
Training loss: 0.5287252626426622
Validation loss: 2.1932501730065095

Epoch: 5| Step: 7
Training loss: 0.8903720898166296
Validation loss: 2.1757058481654146

Epoch: 5| Step: 8
Training loss: 0.7952235069023194
Validation loss: 2.202251232256321

Epoch: 5| Step: 9
Training loss: 0.7034923017957717
Validation loss: 2.194395330100212

Epoch: 5| Step: 10
Training loss: 0.7069943455290584
Validation loss: 2.1726308451561933

Epoch: 287| Step: 0
Training loss: 0.952763660914534
Validation loss: 2.1821054722849555

Epoch: 5| Step: 1
Training loss: 0.7929068855996032
Validation loss: 2.198352347332184

Epoch: 5| Step: 2
Training loss: 0.7288763467393214
Validation loss: 2.150973567546636

Epoch: 5| Step: 3
Training loss: 1.0493421946357018
Validation loss: 2.1657114250189227

Epoch: 5| Step: 4
Training loss: 0.5391126968674602
Validation loss: 2.1942998928410473

Epoch: 5| Step: 5
Training loss: 0.5816678442392025
Validation loss: 2.184248560794356

Epoch: 5| Step: 6
Training loss: 0.5337852681677998
Validation loss: 2.1970233337188825

Epoch: 5| Step: 7
Training loss: 0.7777620273274444
Validation loss: 2.2077713408184345

Epoch: 5| Step: 8
Training loss: 1.086394892907112
Validation loss: 2.1832077709881865

Epoch: 5| Step: 9
Training loss: 0.5232964795443055
Validation loss: 2.19964348028809

Epoch: 5| Step: 10
Training loss: 0.7028478924094641
Validation loss: 2.1977801921841356

Epoch: 288| Step: 0
Training loss: 0.8114382702587932
Validation loss: 2.2053706107041537

Epoch: 5| Step: 1
Training loss: 0.7887879451082036
Validation loss: 2.200798172040987

Epoch: 5| Step: 2
Training loss: 0.7006625394947636
Validation loss: 2.200085587528705

Epoch: 5| Step: 3
Training loss: 0.8264961417951031
Validation loss: 2.2070236474538834

Epoch: 5| Step: 4
Training loss: 0.5307906633361553
Validation loss: 2.1984646379499386

Epoch: 5| Step: 5
Training loss: 0.49345203716469443
Validation loss: 2.172930561513192

Epoch: 5| Step: 6
Training loss: 0.8072171494742505
Validation loss: 2.200555853805608

Epoch: 5| Step: 7
Training loss: 0.9770470599590241
Validation loss: 2.153550794083429

Epoch: 5| Step: 8
Training loss: 0.7849745279176406
Validation loss: 2.181537007134428

Epoch: 5| Step: 9
Training loss: 0.8169593944894494
Validation loss: 2.1656215334401385

Epoch: 5| Step: 10
Training loss: 0.6743152571439792
Validation loss: 2.1553289334557935

Epoch: 289| Step: 0
Training loss: 1.050431941515393
Validation loss: 2.1472306612692975

Epoch: 5| Step: 1
Training loss: 1.0889956000863577
Validation loss: 2.190322496563788

Epoch: 5| Step: 2
Training loss: 0.6391798093614169
Validation loss: 2.174394515533278

Epoch: 5| Step: 3
Training loss: 0.5966119306336908
Validation loss: 2.166484932420479

Epoch: 5| Step: 4
Training loss: 0.7210685816512741
Validation loss: 2.1501233312342576

Epoch: 5| Step: 5
Training loss: 0.6912508860025367
Validation loss: 2.170400855044243

Epoch: 5| Step: 6
Training loss: 0.6810739779769341
Validation loss: 2.1487790549386148

Epoch: 5| Step: 7
Training loss: 0.7975362390398238
Validation loss: 2.153887592539729

Epoch: 5| Step: 8
Training loss: 0.7244554546396494
Validation loss: 2.181916636788323

Epoch: 5| Step: 9
Training loss: 0.3078224103077767
Validation loss: 2.1769868472429157

Epoch: 5| Step: 10
Training loss: 0.721876146059654
Validation loss: 2.151177975229687

Epoch: 290| Step: 0
Training loss: 1.028067446318128
Validation loss: 2.1623910825880968

Epoch: 5| Step: 1
Training loss: 0.6462368678634687
Validation loss: 2.171371302400558

Epoch: 5| Step: 2
Training loss: 0.7275914115761688
Validation loss: 2.158947215229903

Epoch: 5| Step: 3
Training loss: 0.7481709270354577
Validation loss: 2.2032532257185555

Epoch: 5| Step: 4
Training loss: 0.6979460188163952
Validation loss: 2.171344986619226

Epoch: 5| Step: 5
Training loss: 0.7621750858511166
Validation loss: 2.1952978758503123

Epoch: 5| Step: 6
Training loss: 0.324771788600331
Validation loss: 2.1794049891498957

Epoch: 5| Step: 7
Training loss: 0.9973425423484685
Validation loss: 2.210137349173479

Epoch: 5| Step: 8
Training loss: 0.774482329583823
Validation loss: 2.2141588155416834

Epoch: 5| Step: 9
Training loss: 0.5804891446665071
Validation loss: 2.1872103620942047

Epoch: 5| Step: 10
Training loss: 0.5004233118082422
Validation loss: 2.169245005371134

Epoch: 291| Step: 0
Training loss: 0.4842482831773865
Validation loss: 2.1684910298943723

Epoch: 5| Step: 1
Training loss: 0.9555089871908629
Validation loss: 2.197012229172386

Epoch: 5| Step: 2
Training loss: 0.8798781044481595
Validation loss: 2.186454765825274

Epoch: 5| Step: 3
Training loss: 0.63512396454722
Validation loss: 2.1755765765370363

Epoch: 5| Step: 4
Training loss: 0.6190728472365323
Validation loss: 2.169631273543619

Epoch: 5| Step: 5
Training loss: 0.5254658641616838
Validation loss: 2.1579042865435976

Epoch: 5| Step: 6
Training loss: 0.900655810843674
Validation loss: 2.2026927346187937

Epoch: 5| Step: 7
Training loss: 0.6059839333365247
Validation loss: 2.1924027531621384

Epoch: 5| Step: 8
Training loss: 0.6530502057483998
Validation loss: 2.181242628385075

Epoch: 5| Step: 9
Training loss: 0.7222345719952545
Validation loss: 2.152286910312333

Epoch: 5| Step: 10
Training loss: 0.8754797029261133
Validation loss: 2.1637586510108084

Epoch: 292| Step: 0
Training loss: 0.6839593835923908
Validation loss: 2.1663765756473516

Epoch: 5| Step: 1
Training loss: 0.4188983597487234
Validation loss: 2.178638002263595

Epoch: 5| Step: 2
Training loss: 0.32035566829919804
Validation loss: 2.192167697199848

Epoch: 5| Step: 3
Training loss: 0.8820868353818467
Validation loss: 2.1936896198841107

Epoch: 5| Step: 4
Training loss: 0.8146933514641327
Validation loss: 2.1595574180360533

Epoch: 5| Step: 5
Training loss: 0.5267105539612721
Validation loss: 2.1709585994236678

Epoch: 5| Step: 6
Training loss: 0.6722924909260554
Validation loss: 2.1544036569529714

Epoch: 5| Step: 7
Training loss: 0.7760700928945711
Validation loss: 2.18179994243903

Epoch: 5| Step: 8
Training loss: 0.693372205158857
Validation loss: 2.157497253341123

Epoch: 5| Step: 9
Training loss: 0.8787339444274124
Validation loss: 2.1381238998693846

Epoch: 5| Step: 10
Training loss: 0.9854768308589762
Validation loss: 2.15289002887901

Epoch: 293| Step: 0
Training loss: 0.8961499157492261
Validation loss: 2.1553563255563377

Epoch: 5| Step: 1
Training loss: 0.7855626662842418
Validation loss: 2.2057193935505293

Epoch: 5| Step: 2
Training loss: 0.7180036733474912
Validation loss: 2.180438057092757

Epoch: 5| Step: 3
Training loss: 0.4872015956775016
Validation loss: 2.1702072992405164

Epoch: 5| Step: 4
Training loss: 0.8263379013581047
Validation loss: 2.1829110549820085

Epoch: 5| Step: 5
Training loss: 0.6128044218535659
Validation loss: 2.2018863509740476

Epoch: 5| Step: 6
Training loss: 0.7809917022957866
Validation loss: 2.171320683583787

Epoch: 5| Step: 7
Training loss: 0.6757093402331037
Validation loss: 2.175112549469112

Epoch: 5| Step: 8
Training loss: 0.6214477681732431
Validation loss: 2.1684954466761472

Epoch: 5| Step: 9
Training loss: 0.6378782281646286
Validation loss: 2.1640873086432135

Epoch: 5| Step: 10
Training loss: 0.8129838456499682
Validation loss: 2.1494493713757254

Epoch: 294| Step: 0
Training loss: 0.6511730265020796
Validation loss: 2.1605009739884493

Epoch: 5| Step: 1
Training loss: 0.6335435576966286
Validation loss: 2.160312228244018

Epoch: 5| Step: 2
Training loss: 0.7575850784566435
Validation loss: 2.1546526320517017

Epoch: 5| Step: 3
Training loss: 0.6860481451033519
Validation loss: 2.170614870131033

Epoch: 5| Step: 4
Training loss: 0.5101324055402195
Validation loss: 2.161023015291332

Epoch: 5| Step: 5
Training loss: 0.9389433875684912
Validation loss: 2.188781346594157

Epoch: 5| Step: 6
Training loss: 0.7567901400584115
Validation loss: 2.150435221397212

Epoch: 5| Step: 7
Training loss: 0.8880232906960115
Validation loss: 2.1878709176845286

Epoch: 5| Step: 8
Training loss: 0.4036604622271663
Validation loss: 2.214649863364674

Epoch: 5| Step: 9
Training loss: 0.628390011465635
Validation loss: 2.209346862159864

Epoch: 5| Step: 10
Training loss: 0.8380506669434611
Validation loss: 2.1855310054615904

Epoch: 295| Step: 0
Training loss: 0.4358647986602975
Validation loss: 2.188290050480827

Epoch: 5| Step: 1
Training loss: 0.6192445878310973
Validation loss: 2.181552345770284

Epoch: 5| Step: 2
Training loss: 0.9281956218733769
Validation loss: 2.1831590852839993

Epoch: 5| Step: 3
Training loss: 0.8275181328091978
Validation loss: 2.167830130784858

Epoch: 5| Step: 4
Training loss: 0.6813928760527334
Validation loss: 2.1678798120361726

Epoch: 5| Step: 5
Training loss: 0.8257952614049381
Validation loss: 2.179996933829078

Epoch: 5| Step: 6
Training loss: 0.5866990036568602
Validation loss: 2.1832603058965803

Epoch: 5| Step: 7
Training loss: 0.6550288191490408
Validation loss: 2.1593197293197304

Epoch: 5| Step: 8
Training loss: 0.5747600002721367
Validation loss: 2.163315045053042

Epoch: 5| Step: 9
Training loss: 0.578453022456444
Validation loss: 2.1343698724603346

Epoch: 5| Step: 10
Training loss: 0.8610360478598509
Validation loss: 2.167696221511007

Epoch: 296| Step: 0
Training loss: 0.6824369397217426
Validation loss: 2.180225067413885

Epoch: 5| Step: 1
Training loss: 0.7901205768192843
Validation loss: 2.170300430902985

Epoch: 5| Step: 2
Training loss: 0.6423873154275636
Validation loss: 2.188479823750467

Epoch: 5| Step: 3
Training loss: 0.46627548659468354
Validation loss: 2.1842133884065373

Epoch: 5| Step: 4
Training loss: 0.8161429021539657
Validation loss: 2.157745777025324

Epoch: 5| Step: 5
Training loss: 0.6766206456454253
Validation loss: 2.205541823567837

Epoch: 5| Step: 6
Training loss: 0.39513219257096954
Validation loss: 2.1789271483643877

Epoch: 5| Step: 7
Training loss: 0.5149760642091026
Validation loss: 2.157554106668351

Epoch: 5| Step: 8
Training loss: 0.7025003625658396
Validation loss: 2.159797584534138

Epoch: 5| Step: 9
Training loss: 0.9927349232451256
Validation loss: 2.154726899099805

Epoch: 5| Step: 10
Training loss: 0.7408287460205147
Validation loss: 2.1424323197151782

Epoch: 297| Step: 0
Training loss: 0.6739045915200699
Validation loss: 2.1590225023669904

Epoch: 5| Step: 1
Training loss: 0.8778619283935691
Validation loss: 2.179443973835377

Epoch: 5| Step: 2
Training loss: 0.8450429687635426
Validation loss: 2.1731344457588557

Epoch: 5| Step: 3
Training loss: 0.7347296000708947
Validation loss: 2.2086453338329406

Epoch: 5| Step: 4
Training loss: 0.7648930846406518
Validation loss: 2.183748485022454

Epoch: 5| Step: 5
Training loss: 0.9308379292068701
Validation loss: 2.1657263436508667

Epoch: 5| Step: 6
Training loss: 0.5335649094390356
Validation loss: 2.164547578104438

Epoch: 5| Step: 7
Training loss: 0.6058333252964081
Validation loss: 2.1803409127627456

Epoch: 5| Step: 8
Training loss: 0.9558947607676406
Validation loss: 2.1796603872090694

Epoch: 5| Step: 9
Training loss: 0.6581228190256408
Validation loss: 2.1837672354842037

Epoch: 5| Step: 10
Training loss: 0.6700506058839851
Validation loss: 2.195163208929297

Epoch: 298| Step: 0
Training loss: 0.9176280261843218
Validation loss: 2.1937622364227516

Epoch: 5| Step: 1
Training loss: 0.6269976401048873
Validation loss: 2.2040085060643793

Epoch: 5| Step: 2
Training loss: 0.8446266071077904
Validation loss: 2.235875265751721

Epoch: 5| Step: 3
Training loss: 0.9049601748434422
Validation loss: 2.238252902701959

Epoch: 5| Step: 4
Training loss: 0.6417859885092884
Validation loss: 2.248428996054069

Epoch: 5| Step: 5
Training loss: 0.5554856749798354
Validation loss: 2.2319134072595856

Epoch: 5| Step: 6
Training loss: 0.8481022237307084
Validation loss: 2.2210705275066394

Epoch: 5| Step: 7
Training loss: 0.6809680976663234
Validation loss: 2.200284462704507

Epoch: 5| Step: 8
Training loss: 0.5481878598226911
Validation loss: 2.2156107056548864

Epoch: 5| Step: 9
Training loss: 0.6493801022018
Validation loss: 2.1923499257388053

Epoch: 5| Step: 10
Training loss: 0.4845117252946654
Validation loss: 2.194622124070713

Epoch: 299| Step: 0
Training loss: 0.5243604693030651
Validation loss: 2.206806898243607

Epoch: 5| Step: 1
Training loss: 0.5775073076586736
Validation loss: 2.221096389755839

Epoch: 5| Step: 2
Training loss: 0.7433335139897331
Validation loss: 2.2056250012906395

Epoch: 5| Step: 3
Training loss: 0.5669691511488221
Validation loss: 2.214249858066865

Epoch: 5| Step: 4
Training loss: 0.7817830746628601
Validation loss: 2.199989848845285

Epoch: 5| Step: 5
Training loss: 0.7041646053539856
Validation loss: 2.2036715408282883

Epoch: 5| Step: 6
Training loss: 0.7397113653409602
Validation loss: 2.205424436291025

Epoch: 5| Step: 7
Training loss: 0.793161528507441
Validation loss: 2.22272874889918

Epoch: 5| Step: 8
Training loss: 0.8209038192641589
Validation loss: 2.2006778442342947

Epoch: 5| Step: 9
Training loss: 0.9200860786078018
Validation loss: 2.208777951945791

Epoch: 5| Step: 10
Training loss: 0.6205707483311106
Validation loss: 2.1721994566820957

Epoch: 300| Step: 0
Training loss: 0.7641823079856382
Validation loss: 2.133889820316893

Epoch: 5| Step: 1
Training loss: 0.7114637334645663
Validation loss: 2.1871728889839477

Epoch: 5| Step: 2
Training loss: 0.5338304902075546
Validation loss: 2.1640457360575778

Epoch: 5| Step: 3
Training loss: 0.8345403314584503
Validation loss: 2.1727643096022677

Epoch: 5| Step: 4
Training loss: 0.7284015637816182
Validation loss: 2.1881943065227976

Epoch: 5| Step: 5
Training loss: 0.7351582185595239
Validation loss: 2.158769329758388

Epoch: 5| Step: 6
Training loss: 0.8599000887165718
Validation loss: 2.174435444604075

Epoch: 5| Step: 7
Training loss: 0.630981858589685
Validation loss: 2.1686023339532907

Epoch: 5| Step: 8
Training loss: 0.7085074089298243
Validation loss: 2.1893070544678817

Epoch: 5| Step: 9
Training loss: 0.5595401136627829
Validation loss: 2.169493117421575

Epoch: 5| Step: 10
Training loss: 0.4315339901765517
Validation loss: 2.151871205999846

Epoch: 301| Step: 0
Training loss: 0.8972777801341358
Validation loss: 2.171817163497177

Epoch: 5| Step: 1
Training loss: 0.41828683532360167
Validation loss: 2.155031952525086

Epoch: 5| Step: 2
Training loss: 0.7856782534932716
Validation loss: 2.181395736782258

Epoch: 5| Step: 3
Training loss: 0.4048346292520268
Validation loss: 2.171008811317982

Epoch: 5| Step: 4
Training loss: 0.5923634954535958
Validation loss: 2.1545114932146174

Epoch: 5| Step: 5
Training loss: 0.8169783271637053
Validation loss: 2.202054583706359

Epoch: 5| Step: 6
Training loss: 0.4677214145601068
Validation loss: 2.16946989615789

Epoch: 5| Step: 7
Training loss: 0.7164356454457348
Validation loss: 2.1911041687378368

Epoch: 5| Step: 8
Training loss: 0.6612275364238513
Validation loss: 2.2028322370784315

Epoch: 5| Step: 9
Training loss: 0.6500801972286395
Validation loss: 2.1998499400550453

Epoch: 5| Step: 10
Training loss: 0.6231987268876819
Validation loss: 2.226178766965117

Epoch: 302| Step: 0
Training loss: 0.9001625417586472
Validation loss: 2.201654469834149

Epoch: 5| Step: 1
Training loss: 0.6081269027194046
Validation loss: 2.1948884319314965

Epoch: 5| Step: 2
Training loss: 0.6997639326130695
Validation loss: 2.226362325395202

Epoch: 5| Step: 3
Training loss: 0.5808726306010766
Validation loss: 2.208078458112594

Epoch: 5| Step: 4
Training loss: 0.4025426946825039
Validation loss: 2.1751788743651095

Epoch: 5| Step: 5
Training loss: 0.6413202699748768
Validation loss: 2.175874393161949

Epoch: 5| Step: 6
Training loss: 0.8042986402450539
Validation loss: 2.1745476298134157

Epoch: 5| Step: 7
Training loss: 0.7012376037222767
Validation loss: 2.1455749474031496

Epoch: 5| Step: 8
Training loss: 0.7087438506409637
Validation loss: 2.1606443265758744

Epoch: 5| Step: 9
Training loss: 0.683898291189639
Validation loss: 2.129059850505248

Epoch: 5| Step: 10
Training loss: 0.4341197560655701
Validation loss: 2.161597621287938

Epoch: 303| Step: 0
Training loss: 0.7607567214067167
Validation loss: 2.1563153618882267

Epoch: 5| Step: 1
Training loss: 0.6495947335543577
Validation loss: 2.1611103881344547

Epoch: 5| Step: 2
Training loss: 0.8029513843066699
Validation loss: 2.1308213422081757

Epoch: 5| Step: 3
Training loss: 0.5918506811880072
Validation loss: 2.174438454566973

Epoch: 5| Step: 4
Training loss: 0.870305341763054
Validation loss: 2.194652836769366

Epoch: 5| Step: 5
Training loss: 0.6449155182181464
Validation loss: 2.195762165780646

Epoch: 5| Step: 6
Training loss: 0.597575637267604
Validation loss: 2.1861577728433454

Epoch: 5| Step: 7
Training loss: 0.5808854313376143
Validation loss: 2.1753861074813723

Epoch: 5| Step: 8
Training loss: 0.46930440859513184
Validation loss: 2.1729952741925214

Epoch: 5| Step: 9
Training loss: 0.6267936955418516
Validation loss: 2.1837787202386134

Epoch: 5| Step: 10
Training loss: 0.4340570569229222
Validation loss: 2.181439677583337

Epoch: 304| Step: 0
Training loss: 0.5408481379962617
Validation loss: 2.1685126420109406

Epoch: 5| Step: 1
Training loss: 0.45811334301116013
Validation loss: 2.148217741316179

Epoch: 5| Step: 2
Training loss: 0.6952160757691294
Validation loss: 2.1291485365108613

Epoch: 5| Step: 3
Training loss: 0.6277331197330859
Validation loss: 2.1830262625124304

Epoch: 5| Step: 4
Training loss: 0.6745307465693451
Validation loss: 2.171833327418798

Epoch: 5| Step: 5
Training loss: 0.24623515592652515
Validation loss: 2.181238360235372

Epoch: 5| Step: 6
Training loss: 0.7330650658918304
Validation loss: 2.169394654885523

Epoch: 5| Step: 7
Training loss: 0.6847856430548551
Validation loss: 2.1693543911685

Epoch: 5| Step: 8
Training loss: 0.7533416610513481
Validation loss: 2.181213995833868

Epoch: 5| Step: 9
Training loss: 0.8447593021112096
Validation loss: 2.20703041366313

Epoch: 5| Step: 10
Training loss: 0.5506219565906051
Validation loss: 2.1904436454375595

Epoch: 305| Step: 0
Training loss: 0.5525813885116045
Validation loss: 2.1903218668670825

Epoch: 5| Step: 1
Training loss: 0.5841262798070816
Validation loss: 2.198443383251119

Epoch: 5| Step: 2
Training loss: 0.527922531683462
Validation loss: 2.1876957162710053

Epoch: 5| Step: 3
Training loss: 0.19490039263669096
Validation loss: 2.1681033176119087

Epoch: 5| Step: 4
Training loss: 0.71010075049082
Validation loss: 2.194518678736241

Epoch: 5| Step: 5
Training loss: 0.48742694123893054
Validation loss: 2.1732702370516175

Epoch: 5| Step: 6
Training loss: 0.6220016561375737
Validation loss: 2.1686105298713074

Epoch: 5| Step: 7
Training loss: 0.8616943618767925
Validation loss: 2.139699780425566

Epoch: 5| Step: 8
Training loss: 0.5894690074765385
Validation loss: 2.1802665948852513

Epoch: 5| Step: 9
Training loss: 0.9030137650252815
Validation loss: 2.157133504288254

Epoch: 5| Step: 10
Training loss: 0.6406840087881838
Validation loss: 2.1587175882973075

Epoch: 306| Step: 0
Training loss: 0.5808569820229058
Validation loss: 2.1386196041494974

Epoch: 5| Step: 1
Training loss: 0.8677714675582172
Validation loss: 2.126218245099404

Epoch: 5| Step: 2
Training loss: 0.7565412575261804
Validation loss: 2.1870747904471712

Epoch: 5| Step: 3
Training loss: 0.6101012426142034
Validation loss: 2.1458112255773147

Epoch: 5| Step: 4
Training loss: 0.7019979344810355
Validation loss: 2.149055740136887

Epoch: 5| Step: 5
Training loss: 0.5631673351128457
Validation loss: 2.167646072735437

Epoch: 5| Step: 6
Training loss: 0.3815867984417512
Validation loss: 2.1542958503988237

Epoch: 5| Step: 7
Training loss: 0.2932868121091736
Validation loss: 2.160065784246373

Epoch: 5| Step: 8
Training loss: 0.6248915816684548
Validation loss: 2.1682365218856154

Epoch: 5| Step: 9
Training loss: 0.6986860665022478
Validation loss: 2.2038169192637844

Epoch: 5| Step: 10
Training loss: 0.562115564371884
Validation loss: 2.1796104784209076

Epoch: 307| Step: 0
Training loss: 0.7243247488528124
Validation loss: 2.159579022807463

Epoch: 5| Step: 1
Training loss: 0.6543645339828401
Validation loss: 2.1949610672078044

Epoch: 5| Step: 2
Training loss: 0.5248453934403288
Validation loss: 2.211487339394821

Epoch: 5| Step: 3
Training loss: 0.736033413543197
Validation loss: 2.2133698128300177

Epoch: 5| Step: 4
Training loss: 0.4699468433218912
Validation loss: 2.1746547070812015

Epoch: 5| Step: 5
Training loss: 0.6441443466902558
Validation loss: 2.189905275796814

Epoch: 5| Step: 6
Training loss: 0.6389595107308274
Validation loss: 2.161795938760394

Epoch: 5| Step: 7
Training loss: 0.6760189321973344
Validation loss: 2.1627068883978366

Epoch: 5| Step: 8
Training loss: 0.4530216460908868
Validation loss: 2.1480014356252144

Epoch: 5| Step: 9
Training loss: 0.6298940258358718
Validation loss: 2.1765814762730966

Epoch: 5| Step: 10
Training loss: 0.5779972966371827
Validation loss: 2.147880268044136

Epoch: 308| Step: 0
Training loss: 0.6389504154843685
Validation loss: 2.1335766091508708

Epoch: 5| Step: 1
Training loss: 0.7305521789886936
Validation loss: 2.139899891294466

Epoch: 5| Step: 2
Training loss: 0.7037395970132946
Validation loss: 2.1218441494121283

Epoch: 5| Step: 3
Training loss: 0.28455595295741487
Validation loss: 2.186466975140473

Epoch: 5| Step: 4
Training loss: 0.29409721479724893
Validation loss: 2.180655562723149

Epoch: 5| Step: 5
Training loss: 0.7141951656849864
Validation loss: 2.18843694565014

Epoch: 5| Step: 6
Training loss: 0.5692183829596166
Validation loss: 2.2123685314898704

Epoch: 5| Step: 7
Training loss: 0.6714370986069444
Validation loss: 2.185119936172461

Epoch: 5| Step: 8
Training loss: 0.7104257691174046
Validation loss: 2.196618452029287

Epoch: 5| Step: 9
Training loss: 0.7034304061525178
Validation loss: 2.2343510847979617

Epoch: 5| Step: 10
Training loss: 0.6129240708862338
Validation loss: 2.18073102147843

Epoch: 309| Step: 0
Training loss: 0.7145443482140036
Validation loss: 2.129834676653942

Epoch: 5| Step: 1
Training loss: 0.665384748915968
Validation loss: 2.157874868509386

Epoch: 5| Step: 2
Training loss: 0.7097310739609289
Validation loss: 2.1646098647855947

Epoch: 5| Step: 3
Training loss: 0.629952502276691
Validation loss: 2.1786328964820285

Epoch: 5| Step: 4
Training loss: 0.6350440251114906
Validation loss: 2.1712994429992145

Epoch: 5| Step: 5
Training loss: 0.3758821244967998
Validation loss: 2.1409627589428557

Epoch: 5| Step: 6
Training loss: 0.4606621938412163
Validation loss: 2.158808239987972

Epoch: 5| Step: 7
Training loss: 0.4049432903487544
Validation loss: 2.1424227423836517

Epoch: 5| Step: 8
Training loss: 0.7409707385088736
Validation loss: 2.151728722477559

Epoch: 5| Step: 9
Training loss: 0.5717605080149758
Validation loss: 2.199742498411568

Epoch: 5| Step: 10
Training loss: 0.6853662453940567
Validation loss: 2.1624745905147575

Epoch: 310| Step: 0
Training loss: 0.5839452570951496
Validation loss: 2.164549778083828

Epoch: 5| Step: 1
Training loss: 0.7641165528943641
Validation loss: 2.186700954496078

Epoch: 5| Step: 2
Training loss: 0.44565050782421156
Validation loss: 2.1595628484817753

Epoch: 5| Step: 3
Training loss: 0.6142774375606651
Validation loss: 2.179121039338427

Epoch: 5| Step: 4
Training loss: 0.5678361142275811
Validation loss: 2.1691303160144733

Epoch: 5| Step: 5
Training loss: 0.6436061809586767
Validation loss: 2.153816587077165

Epoch: 5| Step: 6
Training loss: 0.6760163532175127
Validation loss: 2.1652742746050175

Epoch: 5| Step: 7
Training loss: 0.45575003076658915
Validation loss: 2.1512643983367243

Epoch: 5| Step: 8
Training loss: 0.7037840403697188
Validation loss: 2.1506797376592686

Epoch: 5| Step: 9
Training loss: 0.5197357119586712
Validation loss: 2.107533350455976

Epoch: 5| Step: 10
Training loss: 0.6055610094228276
Validation loss: 2.1686604341038658

Epoch: 311| Step: 0
Training loss: 0.3834670951259799
Validation loss: 2.157617381815179

Epoch: 5| Step: 1
Training loss: 0.582907688866121
Validation loss: 2.18767734400545

Epoch: 5| Step: 2
Training loss: 0.5531371573281324
Validation loss: 2.198018537698537

Epoch: 5| Step: 3
Training loss: 0.7259603076230622
Validation loss: 2.197367241737225

Epoch: 5| Step: 4
Training loss: 0.5490768520626726
Validation loss: 2.210783574455268

Epoch: 5| Step: 5
Training loss: 0.736005960507721
Validation loss: 2.194816023187937

Epoch: 5| Step: 6
Training loss: 0.4384249038681392
Validation loss: 2.1987804594724163

Epoch: 5| Step: 7
Training loss: 0.8479034836765136
Validation loss: 2.219908624236681

Epoch: 5| Step: 8
Training loss: 0.6178869557413412
Validation loss: 2.232432977388984

Epoch: 5| Step: 9
Training loss: 0.3913373364906385
Validation loss: 2.1729726649096976

Epoch: 5| Step: 10
Training loss: 0.5479422101592554
Validation loss: 2.1863144194646944

Epoch: 312| Step: 0
Training loss: 0.36861376023644193
Validation loss: 2.1678015711997256

Epoch: 5| Step: 1
Training loss: 0.40385335284408475
Validation loss: 2.165188474045172

Epoch: 5| Step: 2
Training loss: 0.9648220662139886
Validation loss: 2.159511570616888

Epoch: 5| Step: 3
Training loss: 0.399918105265457
Validation loss: 2.179463382401345

Epoch: 5| Step: 4
Training loss: 0.4267856056363731
Validation loss: 2.1373758300243364

Epoch: 5| Step: 5
Training loss: 0.571551036271334
Validation loss: 2.1512605521532637

Epoch: 5| Step: 6
Training loss: 0.5181755217066211
Validation loss: 2.1966930350861693

Epoch: 5| Step: 7
Training loss: 0.5098924150310127
Validation loss: 2.1514808663069522

Epoch: 5| Step: 8
Training loss: 0.8713859444383607
Validation loss: 2.167078629399779

Epoch: 5| Step: 9
Training loss: 0.4209335206317354
Validation loss: 2.130391849052705

Epoch: 5| Step: 10
Training loss: 0.7517739615089637
Validation loss: 2.173786568287519

Epoch: 313| Step: 0
Training loss: 0.6072473551275229
Validation loss: 2.1707835092551098

Epoch: 5| Step: 1
Training loss: 0.5743627821709347
Validation loss: 2.1646823737896623

Epoch: 5| Step: 2
Training loss: 0.6433776936242144
Validation loss: 2.1842293678698743

Epoch: 5| Step: 3
Training loss: 0.5881151803359338
Validation loss: 2.1588695199063914

Epoch: 5| Step: 4
Training loss: 0.7692085402743125
Validation loss: 2.1904704585663106

Epoch: 5| Step: 5
Training loss: 0.6376952657655754
Validation loss: 2.2239120698375157

Epoch: 5| Step: 6
Training loss: 0.693332596382642
Validation loss: 2.2025496116135694

Epoch: 5| Step: 7
Training loss: 0.49520826536581203
Validation loss: 2.1989195234384113

Epoch: 5| Step: 8
Training loss: 0.4607839490230002
Validation loss: 2.213395141345987

Epoch: 5| Step: 9
Training loss: 0.38705162210330313
Validation loss: 2.1821504766948583

Epoch: 5| Step: 10
Training loss: 0.5529528075046464
Validation loss: 2.2049704370020633

Epoch: 314| Step: 0
Training loss: 0.22050985803322679
Validation loss: 2.1613170029510615

Epoch: 5| Step: 1
Training loss: 0.6508883613649443
Validation loss: 2.1549820782782483

Epoch: 5| Step: 2
Training loss: 0.683471189138649
Validation loss: 2.179088291255296

Epoch: 5| Step: 3
Training loss: 0.4773537992178187
Validation loss: 2.1823729921044617

Epoch: 5| Step: 4
Training loss: 0.5068712755059355
Validation loss: 2.1746483588435126

Epoch: 5| Step: 5
Training loss: 0.6896471609634776
Validation loss: 2.1539487580444217

Epoch: 5| Step: 6
Training loss: 0.6878057363577074
Validation loss: 2.1632674765462148

Epoch: 5| Step: 7
Training loss: 0.6587597448869624
Validation loss: 2.148743766068317

Epoch: 5| Step: 8
Training loss: 0.4297295289725665
Validation loss: 2.128867042965467

Epoch: 5| Step: 9
Training loss: 0.7110650084455407
Validation loss: 2.165900499209683

Epoch: 5| Step: 10
Training loss: 0.6026843373461821
Validation loss: 2.157997085802582

Epoch: 315| Step: 0
Training loss: 0.5856576378357415
Validation loss: 2.117592158585464

Epoch: 5| Step: 1
Training loss: 0.4220366874550743
Validation loss: 2.1890495273499972

Epoch: 5| Step: 2
Training loss: 0.6064124351840651
Validation loss: 2.1795976520082685

Epoch: 5| Step: 3
Training loss: 0.38244391232703867
Validation loss: 2.1534317393675746

Epoch: 5| Step: 4
Training loss: 0.7825274132993696
Validation loss: 2.1711331535654135

Epoch: 5| Step: 5
Training loss: 0.6421120063234915
Validation loss: 2.1476606128930187

Epoch: 5| Step: 6
Training loss: 0.40859683456861245
Validation loss: 2.187122590165555

Epoch: 5| Step: 7
Training loss: 0.602468007255289
Validation loss: 2.1670518876593827

Epoch: 5| Step: 8
Training loss: 0.687148481148584
Validation loss: 2.177068861791439

Epoch: 5| Step: 9
Training loss: 0.38753540815582393
Validation loss: 2.1539899000637033

Epoch: 5| Step: 10
Training loss: 0.6611189058945803
Validation loss: 2.1686072080043313

Epoch: 316| Step: 0
Training loss: 0.39875362047805957
Validation loss: 2.2010663579540233

Epoch: 5| Step: 1
Training loss: 0.3736592205185078
Validation loss: 2.1674241715008313

Epoch: 5| Step: 2
Training loss: 0.5774609128101372
Validation loss: 2.178335969818526

Epoch: 5| Step: 3
Training loss: 0.674031301633267
Validation loss: 2.1638553648047427

Epoch: 5| Step: 4
Training loss: 0.5811519252933924
Validation loss: 2.1606780423721417

Epoch: 5| Step: 5
Training loss: 0.5531180839321714
Validation loss: 2.1462702530852

Epoch: 5| Step: 6
Training loss: 0.696238618925481
Validation loss: 2.12287404219051

Epoch: 5| Step: 7
Training loss: 0.5952098367431937
Validation loss: 2.1556136286197773

Epoch: 5| Step: 8
Training loss: 0.509802250624291
Validation loss: 2.129145810799102

Epoch: 5| Step: 9
Training loss: 0.6380329027137215
Validation loss: 2.1477281985478474

Epoch: 5| Step: 10
Training loss: 0.6006179925071167
Validation loss: 2.111815162557321

Epoch: 317| Step: 0
Training loss: 0.3922073739172232
Validation loss: 2.134778637915766

Epoch: 5| Step: 1
Training loss: 0.6664061086817745
Validation loss: 2.1014444604945397

Epoch: 5| Step: 2
Training loss: 0.4899884249088802
Validation loss: 2.1195631605251215

Epoch: 5| Step: 3
Training loss: 0.4551123904970006
Validation loss: 2.1347019150885993

Epoch: 5| Step: 4
Training loss: 0.7356909871545763
Validation loss: 2.131713109048525

Epoch: 5| Step: 5
Training loss: 0.6992529109516455
Validation loss: 2.1729917384106785

Epoch: 5| Step: 6
Training loss: 0.6292611299636066
Validation loss: 2.1462824449355073

Epoch: 5| Step: 7
Training loss: 0.48458493205676256
Validation loss: 2.148495288120168

Epoch: 5| Step: 8
Training loss: 0.646006542994961
Validation loss: 2.151430915101397

Epoch: 5| Step: 9
Training loss: 0.3232019520407036
Validation loss: 2.1696111684925667

Epoch: 5| Step: 10
Training loss: 0.4830942294893674
Validation loss: 2.1568961142214746

Epoch: 318| Step: 0
Training loss: 0.5458432410216998
Validation loss: 2.135678130999505

Epoch: 5| Step: 1
Training loss: 0.7741607213142774
Validation loss: 2.17101852587248

Epoch: 5| Step: 2
Training loss: 0.3845500438922782
Validation loss: 2.152662681306176

Epoch: 5| Step: 3
Training loss: 0.3508511658385349
Validation loss: 2.148085242187207

Epoch: 5| Step: 4
Training loss: 0.5876897677879145
Validation loss: 2.137554352880096

Epoch: 5| Step: 5
Training loss: 0.5663556832728293
Validation loss: 2.159822851669996

Epoch: 5| Step: 6
Training loss: 0.7222769076681795
Validation loss: 2.1331280232984025

Epoch: 5| Step: 7
Training loss: 0.5299950249906279
Validation loss: 2.1555692588839044

Epoch: 5| Step: 8
Training loss: 0.38286782857472385
Validation loss: 2.1568536102307556

Epoch: 5| Step: 9
Training loss: 0.5039503980119346
Validation loss: 2.1429370286341762

Epoch: 5| Step: 10
Training loss: 0.6531579652707792
Validation loss: 2.113416694138805

Epoch: 319| Step: 0
Training loss: 0.7577072935715189
Validation loss: 2.138893786080581

Epoch: 5| Step: 1
Training loss: 0.6008079800655499
Validation loss: 2.152951319175834

Epoch: 5| Step: 2
Training loss: 0.3565078262483917
Validation loss: 2.1484390154373627

Epoch: 5| Step: 3
Training loss: 0.5258403965868079
Validation loss: 2.149385536121102

Epoch: 5| Step: 4
Training loss: 0.5941687161578356
Validation loss: 2.1821784725480833

Epoch: 5| Step: 5
Training loss: 0.4701851808692848
Validation loss: 2.118221575773531

Epoch: 5| Step: 6
Training loss: 0.5078775217536814
Validation loss: 2.1422141936372756

Epoch: 5| Step: 7
Training loss: 0.6408062887706487
Validation loss: 2.162251637766606

Epoch: 5| Step: 8
Training loss: 0.6357094892539786
Validation loss: 2.1530227836186513

Epoch: 5| Step: 9
Training loss: 0.5284830290560659
Validation loss: 2.1736674920396775

Epoch: 5| Step: 10
Training loss: 0.40274566649361593
Validation loss: 2.171820017143087

Epoch: 320| Step: 0
Training loss: 0.42743132145545587
Validation loss: 2.1610916765680086

Epoch: 5| Step: 1
Training loss: 0.6762010009416349
Validation loss: 2.185141833748927

Epoch: 5| Step: 2
Training loss: 0.7619729424876667
Validation loss: 2.1492351929741873

Epoch: 5| Step: 3
Training loss: 0.6121006675933452
Validation loss: 2.1347929212888377

Epoch: 5| Step: 4
Training loss: 0.4625942069841687
Validation loss: 2.1250244008930785

Epoch: 5| Step: 5
Training loss: 0.3779864995478123
Validation loss: 2.15011011906696

Epoch: 5| Step: 6
Training loss: 0.4014567068839405
Validation loss: 2.1357605191844087

Epoch: 5| Step: 7
Training loss: 0.4697096855319849
Validation loss: 2.1360552269471627

Epoch: 5| Step: 8
Training loss: 0.7276780373373253
Validation loss: 2.1316048070669313

Epoch: 5| Step: 9
Training loss: 0.557873668575899
Validation loss: 2.144108258571958

Epoch: 5| Step: 10
Training loss: 0.2879078330664431
Validation loss: 2.1530490756782

Epoch: 321| Step: 0
Training loss: 0.6484835275147647
Validation loss: 2.1125585768412414

Epoch: 5| Step: 1
Training loss: 0.4868095956094475
Validation loss: 2.1374149324052496

Epoch: 5| Step: 2
Training loss: 0.6022412075526787
Validation loss: 2.1246396747926406

Epoch: 5| Step: 3
Training loss: 0.8082091296688753
Validation loss: 2.1428521336195643

Epoch: 5| Step: 4
Training loss: 0.6636416279600615
Validation loss: 2.1146832421357455

Epoch: 5| Step: 5
Training loss: 0.42410680512723165
Validation loss: 2.140800468283793

Epoch: 5| Step: 6
Training loss: 0.34180378498177
Validation loss: 2.1314155468849307

Epoch: 5| Step: 7
Training loss: 0.24042707948486497
Validation loss: 2.144017597555735

Epoch: 5| Step: 8
Training loss: 0.4195000592505648
Validation loss: 2.145228576584083

Epoch: 5| Step: 9
Training loss: 0.6671407598342615
Validation loss: 2.151023223669967

Epoch: 5| Step: 10
Training loss: 0.4902091152780989
Validation loss: 2.194178722040284

Epoch: 322| Step: 0
Training loss: 0.397500788310007
Validation loss: 2.1176030603657736

Epoch: 5| Step: 1
Training loss: 0.5472466976751001
Validation loss: 2.1297417902092644

Epoch: 5| Step: 2
Training loss: 0.5274858636453422
Validation loss: 2.1484975606180576

Epoch: 5| Step: 3
Training loss: 0.5814787271090298
Validation loss: 2.132197987533877

Epoch: 5| Step: 4
Training loss: 0.5099279211102874
Validation loss: 2.1415761330539715

Epoch: 5| Step: 5
Training loss: 0.7192168585441426
Validation loss: 2.1389300935327933

Epoch: 5| Step: 6
Training loss: 0.5820353975084241
Validation loss: 2.12062319566238

Epoch: 5| Step: 7
Training loss: 0.3991825206763185
Validation loss: 2.1368219005356615

Epoch: 5| Step: 8
Training loss: 0.5683504870791448
Validation loss: 2.154740407765124

Epoch: 5| Step: 9
Training loss: 0.6029079797888299
Validation loss: 2.160271074312999

Epoch: 5| Step: 10
Training loss: 0.40453676119071147
Validation loss: 2.153030431579779

Epoch: 323| Step: 0
Training loss: 0.5492189041072363
Validation loss: 2.130264192036299

Epoch: 5| Step: 1
Training loss: 0.5372713156971903
Validation loss: 2.1185178412149126

Epoch: 5| Step: 2
Training loss: 0.6413640202363279
Validation loss: 2.1675768763298895

Epoch: 5| Step: 3
Training loss: 0.4600676556518456
Validation loss: 2.1424376344201774

Epoch: 5| Step: 4
Training loss: 0.5983855590988372
Validation loss: 2.1619152828980246

Epoch: 5| Step: 5
Training loss: 0.36428209075608187
Validation loss: 2.13957952243495

Epoch: 5| Step: 6
Training loss: 0.6378459664834674
Validation loss: 2.1280844682944533

Epoch: 5| Step: 7
Training loss: 0.24830325836335915
Validation loss: 2.124848628820597

Epoch: 5| Step: 8
Training loss: 0.5487871528074729
Validation loss: 2.121930187567911

Epoch: 5| Step: 9
Training loss: 0.7142371850898649
Validation loss: 2.150541403546671

Epoch: 5| Step: 10
Training loss: 0.2780778196585768
Validation loss: 2.1465023259145664

Epoch: 324| Step: 0
Training loss: 0.47053893775332156
Validation loss: 2.150186734438209

Epoch: 5| Step: 1
Training loss: 0.4887143160093641
Validation loss: 2.116062152962406

Epoch: 5| Step: 2
Training loss: 0.5635655959214471
Validation loss: 2.132801196963003

Epoch: 5| Step: 3
Training loss: 0.3697553692944332
Validation loss: 2.1504164598599673

Epoch: 5| Step: 4
Training loss: 0.44353765524678795
Validation loss: 2.1929185052564693

Epoch: 5| Step: 5
Training loss: 0.4246885996082209
Validation loss: 2.162154288739311

Epoch: 5| Step: 6
Training loss: 0.9918143103720828
Validation loss: 2.162695080447748

Epoch: 5| Step: 7
Training loss: 0.49316904801974126
Validation loss: 2.152247343786534

Epoch: 5| Step: 8
Training loss: 0.4657230235614476
Validation loss: 2.143960149705978

Epoch: 5| Step: 9
Training loss: 0.440174544837462
Validation loss: 2.1654695283141576

Epoch: 5| Step: 10
Training loss: 0.5044862233635311
Validation loss: 2.1473189701916935

Epoch: 325| Step: 0
Training loss: 0.8126221711667402
Validation loss: 2.185759995876639

Epoch: 5| Step: 1
Training loss: 0.1844325585958866
Validation loss: 2.1656965074679593

Epoch: 5| Step: 2
Training loss: 0.5098324728211624
Validation loss: 2.215937304669129

Epoch: 5| Step: 3
Training loss: 0.4744425193823627
Validation loss: 2.1696686425664136

Epoch: 5| Step: 4
Training loss: 0.3335420568469067
Validation loss: 2.203632850967532

Epoch: 5| Step: 5
Training loss: 0.5557815079022169
Validation loss: 2.183188229551436

Epoch: 5| Step: 6
Training loss: 0.653517210160982
Validation loss: 2.168332834961221

Epoch: 5| Step: 7
Training loss: 0.36902418772707096
Validation loss: 2.131083948575187

Epoch: 5| Step: 8
Training loss: 0.6109677797506574
Validation loss: 2.1612844512616656

Epoch: 5| Step: 9
Training loss: 0.5108437665067854
Validation loss: 2.145749304807042

Epoch: 5| Step: 10
Training loss: 0.4637986142519441
Validation loss: 2.1509159377847955

Epoch: 326| Step: 0
Training loss: 0.48082326200285463
Validation loss: 2.1294337687528464

Epoch: 5| Step: 1
Training loss: 0.4127544037614598
Validation loss: 2.1180826211181

Epoch: 5| Step: 2
Training loss: 0.4266687470468576
Validation loss: 2.1261854394019273

Epoch: 5| Step: 3
Training loss: 0.42534492604507396
Validation loss: 2.132844657464705

Epoch: 5| Step: 4
Training loss: 0.7373858880808789
Validation loss: 2.1485322939188656

Epoch: 5| Step: 5
Training loss: 0.5371572299792765
Validation loss: 2.1239777735694387

Epoch: 5| Step: 6
Training loss: 0.6417274525778877
Validation loss: 2.1450284605674037

Epoch: 5| Step: 7
Training loss: 0.49711568209399853
Validation loss: 2.170119349062878

Epoch: 5| Step: 8
Training loss: 0.3288148259115262
Validation loss: 2.18484885358499

Epoch: 5| Step: 9
Training loss: 0.4015505480935811
Validation loss: 2.203452109352213

Epoch: 5| Step: 10
Training loss: 0.7055426676099584
Validation loss: 2.1943743619358496

Epoch: 327| Step: 0
Training loss: 0.5748205858702753
Validation loss: 2.1957933692387726

Epoch: 5| Step: 1
Training loss: 0.7592956737010726
Validation loss: 2.207603368965317

Epoch: 5| Step: 2
Training loss: 0.4568114118773162
Validation loss: 2.1758700526257715

Epoch: 5| Step: 3
Training loss: 0.36726342085952063
Validation loss: 2.1550089715786545

Epoch: 5| Step: 4
Training loss: 0.6163554800420473
Validation loss: 2.1774990059622743

Epoch: 5| Step: 5
Training loss: 0.607960305960434
Validation loss: 2.16201190958722

Epoch: 5| Step: 6
Training loss: 0.30823460939059744
Validation loss: 2.1428515225743032

Epoch: 5| Step: 7
Training loss: 0.625955352185816
Validation loss: 2.154977410742946

Epoch: 5| Step: 8
Training loss: 0.34003620617590957
Validation loss: 2.1472376779776883

Epoch: 5| Step: 9
Training loss: 0.439900522311699
Validation loss: 2.1603125522128557

Epoch: 5| Step: 10
Training loss: 0.4486227310901322
Validation loss: 2.147833565617173

Epoch: 328| Step: 0
Training loss: 0.3718407791484513
Validation loss: 2.1530166430827915

Epoch: 5| Step: 1
Training loss: 0.7025655003892439
Validation loss: 2.1452728632296623

Epoch: 5| Step: 2
Training loss: 0.3920481506450963
Validation loss: 2.1433111908319953

Epoch: 5| Step: 3
Training loss: 0.5374894895191313
Validation loss: 2.1299421325268604

Epoch: 5| Step: 4
Training loss: 0.4165673336197909
Validation loss: 2.1584191295851047

Epoch: 5| Step: 5
Training loss: 0.5798691652567297
Validation loss: 2.137364987116036

Epoch: 5| Step: 6
Training loss: 0.5574485670835169
Validation loss: 2.1505588783348006

Epoch: 5| Step: 7
Training loss: 0.5449927499271385
Validation loss: 2.105342777130458

Epoch: 5| Step: 8
Training loss: 0.36540342692259525
Validation loss: 2.09564442243631

Epoch: 5| Step: 9
Training loss: 0.6546152279823548
Validation loss: 2.1520631079134396

Epoch: 5| Step: 10
Training loss: 0.46398919358186547
Validation loss: 2.1014318194161468

Epoch: 329| Step: 0
Training loss: 0.5601461752779606
Validation loss: 2.1116323263020726

Epoch: 5| Step: 1
Training loss: 0.38896009407332816
Validation loss: 2.120355355217051

Epoch: 5| Step: 2
Training loss: 0.6816638406991868
Validation loss: 2.1088418886215887

Epoch: 5| Step: 3
Training loss: 0.5788106975900135
Validation loss: 2.1787912536879537

Epoch: 5| Step: 4
Training loss: 0.6640780727580057
Validation loss: 2.0953201824686465

Epoch: 5| Step: 5
Training loss: 0.5721737003381159
Validation loss: 2.167410425486316

Epoch: 5| Step: 6
Training loss: 0.38408472839541324
Validation loss: 2.145839174642795

Epoch: 5| Step: 7
Training loss: 0.422848091375539
Validation loss: 2.1117728195135648

Epoch: 5| Step: 8
Training loss: 0.29137583975341574
Validation loss: 2.133950908482613

Epoch: 5| Step: 9
Training loss: 0.15600597877079986
Validation loss: 2.144522291416137

Epoch: 5| Step: 10
Training loss: 0.5460746357946653
Validation loss: 2.1591851699504296

Epoch: 330| Step: 0
Training loss: 0.5510874499054698
Validation loss: 2.1382531191063436

Epoch: 5| Step: 1
Training loss: 0.63564992490078
Validation loss: 2.1553561400056

Epoch: 5| Step: 2
Training loss: 0.3841947008621377
Validation loss: 2.107319151545563

Epoch: 5| Step: 3
Training loss: 0.315354719199347
Validation loss: 2.150776414984344

Epoch: 5| Step: 4
Training loss: 0.3577790898545975
Validation loss: 2.1414205262907826

Epoch: 5| Step: 5
Training loss: 0.5025685022643492
Validation loss: 2.1693114204383193

Epoch: 5| Step: 6
Training loss: 0.5277368281467664
Validation loss: 2.157320503797171

Epoch: 5| Step: 7
Training loss: 0.4828185639725887
Validation loss: 2.1749513489351875

Epoch: 5| Step: 8
Training loss: 0.5033625545398328
Validation loss: 2.127915725511985

Epoch: 5| Step: 9
Training loss: 0.6315867243542077
Validation loss: 2.169598671718103

Epoch: 5| Step: 10
Training loss: 0.37146629907250844
Validation loss: 2.1477773525857655

Epoch: 331| Step: 0
Training loss: 0.18381233594978533
Validation loss: 2.1370732772434735

Epoch: 5| Step: 1
Training loss: 0.6800690818505277
Validation loss: 2.162087601054423

Epoch: 5| Step: 2
Training loss: 0.5071413740524006
Validation loss: 2.144073163051254

Epoch: 5| Step: 3
Training loss: 0.3710611831027413
Validation loss: 2.1177686691213475

Epoch: 5| Step: 4
Training loss: 0.763842200287769
Validation loss: 2.1280786674967973

Epoch: 5| Step: 5
Training loss: 0.5656440078323549
Validation loss: 2.1191715703029574

Epoch: 5| Step: 6
Training loss: 0.4741166150935401
Validation loss: 2.1436968676248065

Epoch: 5| Step: 7
Training loss: 0.320535721572044
Validation loss: 2.105575704615716

Epoch: 5| Step: 8
Training loss: 0.4662411466223282
Validation loss: 2.1521454239508166

Epoch: 5| Step: 9
Training loss: 0.28240888309802525
Validation loss: 2.1654833594567817

Epoch: 5| Step: 10
Training loss: 0.3595038058778496
Validation loss: 2.1146410504771995

Epoch: 332| Step: 0
Training loss: 0.4551467843713307
Validation loss: 2.123783225268261

Epoch: 5| Step: 1
Training loss: 0.4288337722715041
Validation loss: 2.1485113399342026

Epoch: 5| Step: 2
Training loss: 0.42043576400691046
Validation loss: 2.113241124217159

Epoch: 5| Step: 3
Training loss: 0.5015010356378939
Validation loss: 2.1323746734373996

Epoch: 5| Step: 4
Training loss: 0.6475361914075434
Validation loss: 2.1333452043504266

Epoch: 5| Step: 5
Training loss: 0.4901001735150276
Validation loss: 2.1600352111728083

Epoch: 5| Step: 6
Training loss: 0.41502017707492606
Validation loss: 2.185485864211617

Epoch: 5| Step: 7
Training loss: 0.23803840832478118
Validation loss: 2.1853527130313704

Epoch: 5| Step: 8
Training loss: 0.6358928824104245
Validation loss: 2.1528158080197213

Epoch: 5| Step: 9
Training loss: 0.3544514109801499
Validation loss: 2.127469101983874

Epoch: 5| Step: 10
Training loss: 0.5248777020015335
Validation loss: 2.1624207729128555

Epoch: 333| Step: 0
Training loss: 0.3235979341119488
Validation loss: 2.186051015678552

Epoch: 5| Step: 1
Training loss: 0.5720405787082666
Validation loss: 2.1505897732792594

Epoch: 5| Step: 2
Training loss: 0.4103238989299099
Validation loss: 2.17402792105876

Epoch: 5| Step: 3
Training loss: 0.4278391182910469
Validation loss: 2.1555347799090643

Epoch: 5| Step: 4
Training loss: 0.4439138398802244
Validation loss: 2.1279599532190305

Epoch: 5| Step: 5
Training loss: 0.5012623527602931
Validation loss: 2.098861864232854

Epoch: 5| Step: 6
Training loss: 0.5298369070346367
Validation loss: 2.1263791385757336

Epoch: 5| Step: 7
Training loss: 0.3683019121966618
Validation loss: 2.166893159972251

Epoch: 5| Step: 8
Training loss: 0.49264706243434636
Validation loss: 2.120390477566551

Epoch: 5| Step: 9
Training loss: 0.5505734044732842
Validation loss: 2.1166560426225303

Epoch: 5| Step: 10
Training loss: 0.5327667015282521
Validation loss: 2.1592916674246005

Epoch: 334| Step: 0
Training loss: 0.34747183119543923
Validation loss: 2.0963520551174204

Epoch: 5| Step: 1
Training loss: 0.4455178105404354
Validation loss: 2.1077252097020684

Epoch: 5| Step: 2
Training loss: 0.4423338502984139
Validation loss: 2.1041471804708807

Epoch: 5| Step: 3
Training loss: 0.5764071226746759
Validation loss: 2.136023966953627

Epoch: 5| Step: 4
Training loss: 0.46800778756325867
Validation loss: 2.127966764813831

Epoch: 5| Step: 5
Training loss: 0.46208724793626865
Validation loss: 2.1328490801524542

Epoch: 5| Step: 6
Training loss: 0.29533303255020293
Validation loss: 2.137799370476013

Epoch: 5| Step: 7
Training loss: 0.5588130387112796
Validation loss: 2.140808437731169

Epoch: 5| Step: 8
Training loss: 0.6734420554942966
Validation loss: 2.1339115215719

Epoch: 5| Step: 9
Training loss: 0.3140565610675197
Validation loss: 2.12867337522706

Epoch: 5| Step: 10
Training loss: 0.4714211333811007
Validation loss: 2.1518508605536133

Epoch: 335| Step: 0
Training loss: 0.5784680920738776
Validation loss: 2.170279565420389

Epoch: 5| Step: 1
Training loss: 0.38378785887861916
Validation loss: 2.1685725639385582

Epoch: 5| Step: 2
Training loss: 0.6387466713506933
Validation loss: 2.170856217113409

Epoch: 5| Step: 3
Training loss: 0.5610003614135503
Validation loss: 2.146376014812453

Epoch: 5| Step: 4
Training loss: 0.3838619328010406
Validation loss: 2.117967114909939

Epoch: 5| Step: 5
Training loss: 0.2555680399905539
Validation loss: 2.1269220693249853

Epoch: 5| Step: 6
Training loss: 0.354256585804974
Validation loss: 2.160006314710504

Epoch: 5| Step: 7
Training loss: 0.25955561703200114
Validation loss: 2.136649713444979

Epoch: 5| Step: 8
Training loss: 0.6439075804865346
Validation loss: 2.1118127091604393

Epoch: 5| Step: 9
Training loss: 0.44001412081817776
Validation loss: 2.134370584125563

Epoch: 5| Step: 10
Training loss: 0.4633341728461273
Validation loss: 2.1416061245176166

Epoch: 336| Step: 0
Training loss: 0.27997803489071593
Validation loss: 2.121223726884741

Epoch: 5| Step: 1
Training loss: 0.46545098016324044
Validation loss: 2.149429335771025

Epoch: 5| Step: 2
Training loss: 0.4302761900299037
Validation loss: 2.1539555927859344

Epoch: 5| Step: 3
Training loss: 0.36058847139889993
Validation loss: 2.1866317432232405

Epoch: 5| Step: 4
Training loss: 0.5463270984947133
Validation loss: 2.135635705894434

Epoch: 5| Step: 5
Training loss: 0.36879568786779127
Validation loss: 2.1546652149163235

Epoch: 5| Step: 6
Training loss: 0.48914974031727093
Validation loss: 2.172546900717293

Epoch: 5| Step: 7
Training loss: 0.6558653976045764
Validation loss: 2.160739933385249

Epoch: 5| Step: 8
Training loss: 0.4167543219712379
Validation loss: 2.1604961480993454

Epoch: 5| Step: 9
Training loss: 0.40153447955145954
Validation loss: 2.1702016771865758

Epoch: 5| Step: 10
Training loss: 0.5900752895210835
Validation loss: 2.189030726687353

Epoch: 337| Step: 0
Training loss: 0.4910169487618968
Validation loss: 2.196945911113094

Epoch: 5| Step: 1
Training loss: 0.4929716433577711
Validation loss: 2.161716646686284

Epoch: 5| Step: 2
Training loss: 0.4359392870247696
Validation loss: 2.1784896920267216

Epoch: 5| Step: 3
Training loss: 0.548674049335111
Validation loss: 2.1782921788402048

Epoch: 5| Step: 4
Training loss: 0.5434982955909402
Validation loss: 2.1414600237988672

Epoch: 5| Step: 5
Training loss: 0.4291158167642334
Validation loss: 2.1476615642636037

Epoch: 5| Step: 6
Training loss: 0.4156998523912404
Validation loss: 2.1495260091052937

Epoch: 5| Step: 7
Training loss: 0.21581248446115658
Validation loss: 2.1254748827796295

Epoch: 5| Step: 8
Training loss: 0.48777240942776945
Validation loss: 2.106784940724823

Epoch: 5| Step: 9
Training loss: 0.4971399464574882
Validation loss: 2.133346176525393

Epoch: 5| Step: 10
Training loss: 0.39766777711360446
Validation loss: 2.1544925589406563

Epoch: 338| Step: 0
Training loss: 0.3628143468542021
Validation loss: 2.0936606799367286

Epoch: 5| Step: 1
Training loss: 0.35419640930424645
Validation loss: 2.139083539640168

Epoch: 5| Step: 2
Training loss: 0.6313463817326898
Validation loss: 2.093575976821029

Epoch: 5| Step: 3
Training loss: 0.5078267902417642
Validation loss: 2.135808553885099

Epoch: 5| Step: 4
Training loss: 0.5177900923932194
Validation loss: 2.1282122796979435

Epoch: 5| Step: 5
Training loss: 0.5415873897443819
Validation loss: 2.1218055164354337

Epoch: 5| Step: 6
Training loss: 0.5755556334824224
Validation loss: 2.1455383249322466

Epoch: 5| Step: 7
Training loss: 0.25601450752524285
Validation loss: 2.128384072556452

Epoch: 5| Step: 8
Training loss: 0.2931056020902507
Validation loss: 2.1705564478874746

Epoch: 5| Step: 9
Training loss: 0.3100797751092772
Validation loss: 2.118590914896032

Epoch: 5| Step: 10
Training loss: 0.376165486219112
Validation loss: 2.121291116709289

Epoch: 339| Step: 0
Training loss: 0.37196659034115515
Validation loss: 2.134084171650407

Epoch: 5| Step: 1
Training loss: 0.3739865237513569
Validation loss: 2.0865552976010697

Epoch: 5| Step: 2
Training loss: 0.5327044100487026
Validation loss: 2.138779350753447

Epoch: 5| Step: 3
Training loss: 0.3048546528198527
Validation loss: 2.1362385230502925

Epoch: 5| Step: 4
Training loss: 0.37017358838330877
Validation loss: 2.1362318782397423

Epoch: 5| Step: 5
Training loss: 0.5798933203603753
Validation loss: 2.142857058464533

Epoch: 5| Step: 6
Training loss: 0.5140338970911389
Validation loss: 2.130538250165401

Epoch: 5| Step: 7
Training loss: 0.3041902666320768
Validation loss: 2.1549238347793946

Epoch: 5| Step: 8
Training loss: 0.43228212215810197
Validation loss: 2.1373983360801025

Epoch: 5| Step: 9
Training loss: 0.5661788220753807
Validation loss: 2.1079036939606293

Epoch: 5| Step: 10
Training loss: 0.5094694248979552
Validation loss: 2.134695323140058

Epoch: 340| Step: 0
Training loss: 0.32629940258161994
Validation loss: 2.161894366132098

Epoch: 5| Step: 1
Training loss: 0.5036715766878637
Validation loss: 2.1567493494814736

Epoch: 5| Step: 2
Training loss: 0.4774866367886829
Validation loss: 2.138855266588671

Epoch: 5| Step: 3
Training loss: 0.5315527894547656
Validation loss: 2.122768543060068

Epoch: 5| Step: 4
Training loss: 0.11334528017786
Validation loss: 2.136528592628765

Epoch: 5| Step: 5
Training loss: 0.5106617151178849
Validation loss: 2.1371432771613152

Epoch: 5| Step: 6
Training loss: 0.6546504645239676
Validation loss: 2.121525265839238

Epoch: 5| Step: 7
Training loss: 0.40320616947318905
Validation loss: 2.163111406813058

Epoch: 5| Step: 8
Training loss: 0.3988626306385777
Validation loss: 2.1550703241399716

Epoch: 5| Step: 9
Training loss: 0.41115635240447274
Validation loss: 2.1467720254107268

Epoch: 5| Step: 10
Training loss: 0.3040330288984272
Validation loss: 2.1781467498509266

Epoch: 341| Step: 0
Training loss: 0.5680231102452924
Validation loss: 2.173784154760106

Epoch: 5| Step: 1
Training loss: 0.4301968070357301
Validation loss: 2.1537716357570336

Epoch: 5| Step: 2
Training loss: 0.3920409289640387
Validation loss: 2.1445920129324287

Epoch: 5| Step: 3
Training loss: 0.6120913680007805
Validation loss: 2.146746961732276

Epoch: 5| Step: 4
Training loss: 0.5374402223658492
Validation loss: 2.1391702967688193

Epoch: 5| Step: 5
Training loss: 0.42356350983928087
Validation loss: 2.14996339190167

Epoch: 5| Step: 6
Training loss: 0.31914306789102903
Validation loss: 2.104836595674716

Epoch: 5| Step: 7
Training loss: 0.2732561054734275
Validation loss: 2.152457623178886

Epoch: 5| Step: 8
Training loss: 0.47461519904939153
Validation loss: 2.183388256948381

Epoch: 5| Step: 9
Training loss: 0.48773903305124455
Validation loss: 2.1841339958120507

Epoch: 5| Step: 10
Training loss: 0.3190867066798239
Validation loss: 2.1405341674992164

Epoch: 342| Step: 0
Training loss: 0.40948696934807605
Validation loss: 2.2110525521836077

Epoch: 5| Step: 1
Training loss: 0.4987513029707713
Validation loss: 2.1633447120317704

Epoch: 5| Step: 2
Training loss: 0.4452512263924246
Validation loss: 2.1550864798415175

Epoch: 5| Step: 3
Training loss: 0.5199224103757193
Validation loss: 2.111855330607894

Epoch: 5| Step: 4
Training loss: 0.4437869190922811
Validation loss: 2.1193559516322193

Epoch: 5| Step: 5
Training loss: 0.3927523667551333
Validation loss: 2.0948454443575857

Epoch: 5| Step: 6
Training loss: 0.29292407648898633
Validation loss: 2.103108713241496

Epoch: 5| Step: 7
Training loss: 0.4541515363861911
Validation loss: 2.119145258355986

Epoch: 5| Step: 8
Training loss: 0.6121971607857748
Validation loss: 2.1322441589403507

Epoch: 5| Step: 9
Training loss: 0.3793076620718949
Validation loss: 2.1057006579152726

Epoch: 5| Step: 10
Training loss: 0.4017078411233941
Validation loss: 2.1271409051153025

Epoch: 343| Step: 0
Training loss: 0.40586209117285255
Validation loss: 2.124669164471787

Epoch: 5| Step: 1
Training loss: 0.46418446180839634
Validation loss: 2.182506576443792

Epoch: 5| Step: 2
Training loss: 0.3707997412236246
Validation loss: 2.1728305539752473

Epoch: 5| Step: 3
Training loss: 0.33436414531665326
Validation loss: 2.170606377064792

Epoch: 5| Step: 4
Training loss: 0.5118383893811147
Validation loss: 2.173129504591488

Epoch: 5| Step: 5
Training loss: 0.5191132434199869
Validation loss: 2.1441811225091065

Epoch: 5| Step: 6
Training loss: 0.6162266555450039
Validation loss: 2.1710963281231668

Epoch: 5| Step: 7
Training loss: 0.3033902600383395
Validation loss: 2.2007600682775337

Epoch: 5| Step: 8
Training loss: 0.5108114454528535
Validation loss: 2.1675738154434585

Epoch: 5| Step: 9
Training loss: 0.14612237705922837
Validation loss: 2.137362850912682

Epoch: 5| Step: 10
Training loss: 0.4790777369226689
Validation loss: 2.141151392842561

Epoch: 344| Step: 0
Training loss: 0.46482948473671504
Validation loss: 2.118689371666253

Epoch: 5| Step: 1
Training loss: 0.47768749278386846
Validation loss: 2.1073735077315603

Epoch: 5| Step: 2
Training loss: 0.446011580132996
Validation loss: 2.1251513833178035

Epoch: 5| Step: 3
Training loss: 0.5047873548805559
Validation loss: 2.133491308625826

Epoch: 5| Step: 4
Training loss: 0.300054613745138
Validation loss: 2.1142467334131823

Epoch: 5| Step: 5
Training loss: 0.2904667895385839
Validation loss: 2.143562369242105

Epoch: 5| Step: 6
Training loss: 0.6248484666230895
Validation loss: 2.1657856185400295

Epoch: 5| Step: 7
Training loss: 0.49783359523600706
Validation loss: 2.1708926226801184

Epoch: 5| Step: 8
Training loss: 0.34862569593330694
Validation loss: 2.1611590118263653

Epoch: 5| Step: 9
Training loss: 0.33607752786996803
Validation loss: 2.1392340881165985

Epoch: 5| Step: 10
Training loss: 0.3801678174348601
Validation loss: 2.136923306545714

Epoch: 345| Step: 0
Training loss: 0.6120489581197468
Validation loss: 2.1354687768163974

Epoch: 5| Step: 1
Training loss: 0.2280457466753614
Validation loss: 2.1246579104187164

Epoch: 5| Step: 2
Training loss: 0.2997144134497315
Validation loss: 2.1407629252611375

Epoch: 5| Step: 3
Training loss: 0.5384337310304868
Validation loss: 2.112815214307825

Epoch: 5| Step: 4
Training loss: 0.40957127590548204
Validation loss: 2.108294365684199

Epoch: 5| Step: 5
Training loss: 0.3005127389479973
Validation loss: 2.1795946327032776

Epoch: 5| Step: 6
Training loss: 0.429260023928705
Validation loss: 2.103778668912764

Epoch: 5| Step: 7
Training loss: 0.42394086331576125
Validation loss: 2.1227407829780036

Epoch: 5| Step: 8
Training loss: 0.40412488218329967
Validation loss: 2.12673685464071

Epoch: 5| Step: 9
Training loss: 0.5228489940923648
Validation loss: 2.1559463912609558

Epoch: 5| Step: 10
Training loss: 0.3895653275121426
Validation loss: 2.1634464591711797

Epoch: 346| Step: 0
Training loss: 0.2573726543321476
Validation loss: 2.1491839144252483

Epoch: 5| Step: 1
Training loss: 0.2893686992544288
Validation loss: 2.118500432494062

Epoch: 5| Step: 2
Training loss: 0.47751887304146845
Validation loss: 2.180026610161146

Epoch: 5| Step: 3
Training loss: 0.5180571444705508
Validation loss: 2.1295839195801127

Epoch: 5| Step: 4
Training loss: 0.4325179250949607
Validation loss: 2.153293017723013

Epoch: 5| Step: 5
Training loss: 0.4458324341750065
Validation loss: 2.147177594057914

Epoch: 5| Step: 6
Training loss: 0.6330918060669065
Validation loss: 2.132371152053604

Epoch: 5| Step: 7
Training loss: 0.5326209890343941
Validation loss: 2.109313610281961

Epoch: 5| Step: 8
Training loss: 0.49721673334041316
Validation loss: 2.13106419563474

Epoch: 5| Step: 9
Training loss: 0.15928097878055633
Validation loss: 2.1097014447658933

Epoch: 5| Step: 10
Training loss: 0.2749091193277182
Validation loss: 2.1148964273112916

Epoch: 347| Step: 0
Training loss: 0.30157992604164896
Validation loss: 2.1494878855844486

Epoch: 5| Step: 1
Training loss: 0.4231205144388065
Validation loss: 2.1517397247375913

Epoch: 5| Step: 2
Training loss: 0.340763415202675
Validation loss: 2.1405158820865493

Epoch: 5| Step: 3
Training loss: 0.4297284193495556
Validation loss: 2.172943519304686

Epoch: 5| Step: 4
Training loss: 0.40240400289086004
Validation loss: 2.1608545564336814

Epoch: 5| Step: 5
Training loss: 0.4338731638705506
Validation loss: 2.1384808777069737

Epoch: 5| Step: 6
Training loss: 0.48516092835656977
Validation loss: 2.1781524487927992

Epoch: 5| Step: 7
Training loss: 0.5889564054349856
Validation loss: 2.1966455848393407

Epoch: 5| Step: 8
Training loss: 0.17898176340356609
Validation loss: 2.195768238148918

Epoch: 5| Step: 9
Training loss: 0.600219143147056
Validation loss: 2.1653671362800937

Epoch: 5| Step: 10
Training loss: 0.3806544608504787
Validation loss: 2.1892380262928173

Epoch: 348| Step: 0
Training loss: 0.32684625362448017
Validation loss: 2.1790658551931026

Epoch: 5| Step: 1
Training loss: 0.5380206059778206
Validation loss: 2.231642004166258

Epoch: 5| Step: 2
Training loss: 0.45802329877037007
Validation loss: 2.1832562137157425

Epoch: 5| Step: 3
Training loss: 0.39711502731596343
Validation loss: 2.1865642145732056

Epoch: 5| Step: 4
Training loss: 0.37810431494764135
Validation loss: 2.171898089610966

Epoch: 5| Step: 5
Training loss: 0.5100573293402563
Validation loss: 2.165125923387154

Epoch: 5| Step: 6
Training loss: 0.40493661143068094
Validation loss: 2.134669554418623

Epoch: 5| Step: 7
Training loss: 0.4134412639616702
Validation loss: 2.1444905738552538

Epoch: 5| Step: 8
Training loss: 0.2860778000581977
Validation loss: 2.1468613222388067

Epoch: 5| Step: 9
Training loss: 0.47481260932518393
Validation loss: 2.1256183228966763

Epoch: 5| Step: 10
Training loss: 0.4294546536797833
Validation loss: 2.150098405585877

Epoch: 349| Step: 0
Training loss: 0.46588740475441687
Validation loss: 2.126448063706316

Epoch: 5| Step: 1
Training loss: 0.3945995120679678
Validation loss: 2.114626313960891

Epoch: 5| Step: 2
Training loss: 0.6039480986906225
Validation loss: 2.1393878677178333

Epoch: 5| Step: 3
Training loss: 0.5863731799011022
Validation loss: 2.143348263111527

Epoch: 5| Step: 4
Training loss: 0.35630145370605465
Validation loss: 2.1481884543717094

Epoch: 5| Step: 5
Training loss: 0.43287635428591054
Validation loss: 2.149083083362055

Epoch: 5| Step: 6
Training loss: 0.1582930332949319
Validation loss: 2.1315287911598984

Epoch: 5| Step: 7
Training loss: 0.29164900754648226
Validation loss: 2.1100148065089597

Epoch: 5| Step: 8
Training loss: 0.46644529565795634
Validation loss: 2.1498676743199963

Epoch: 5| Step: 9
Training loss: 0.1625830268579166
Validation loss: 2.111516004359268

Epoch: 5| Step: 10
Training loss: 0.4128890233292998
Validation loss: 2.1162508815922507

Epoch: 350| Step: 0
Training loss: 0.5020373975019433
Validation loss: 2.1524863047659153

Epoch: 5| Step: 1
Training loss: 0.510046461363851
Validation loss: 2.121258623964907

Epoch: 5| Step: 2
Training loss: 0.4006364765398035
Validation loss: 2.156818420191217

Epoch: 5| Step: 3
Training loss: 0.3804779686094927
Validation loss: 2.1702322700563146

Epoch: 5| Step: 4
Training loss: 0.5126339539641441
Validation loss: 2.161681809766011

Epoch: 5| Step: 5
Training loss: 0.2531044257008793
Validation loss: 2.195419465983818

Epoch: 5| Step: 6
Training loss: 0.5084239506337536
Validation loss: 2.1511891691960225

Epoch: 5| Step: 7
Training loss: 0.3347398567742671
Validation loss: 2.110890420895271

Epoch: 5| Step: 8
Training loss: 0.36970622011255216
Validation loss: 2.148235428928809

Epoch: 5| Step: 9
Training loss: 0.410820033323696
Validation loss: 2.144811286695685

Epoch: 5| Step: 10
Training loss: 0.4165895291292662
Validation loss: 2.140092037720399

Epoch: 351| Step: 0
Training loss: 0.36171297764961313
Validation loss: 2.101432037177116

Epoch: 5| Step: 1
Training loss: 0.3553452119891967
Validation loss: 2.1306338639019717

Epoch: 5| Step: 2
Training loss: 0.6015901683042676
Validation loss: 2.152680172219813

Epoch: 5| Step: 3
Training loss: 0.24961541068550963
Validation loss: 2.088459200966474

Epoch: 5| Step: 4
Training loss: 0.5070545408662673
Validation loss: 2.117382184551776

Epoch: 5| Step: 5
Training loss: 0.4575003474395767
Validation loss: 2.146985856081961

Epoch: 5| Step: 6
Training loss: 0.40387510330850596
Validation loss: 2.1684157428339463

Epoch: 5| Step: 7
Training loss: 0.5378488063139053
Validation loss: 2.115673259741424

Epoch: 5| Step: 8
Training loss: 0.2776795087613646
Validation loss: 2.1333764993895157

Epoch: 5| Step: 9
Training loss: 0.3203354222539345
Validation loss: 2.149647574671487

Epoch: 5| Step: 10
Training loss: 0.4040361568127301
Validation loss: 2.194963654251714

Epoch: 352| Step: 0
Training loss: 0.6114298580455995
Validation loss: 2.1452165580018323

Epoch: 5| Step: 1
Training loss: 0.30853823874761105
Validation loss: 2.176516048070367

Epoch: 5| Step: 2
Training loss: 0.35641935071067604
Validation loss: 2.1804233096647665

Epoch: 5| Step: 3
Training loss: 0.413254813807213
Validation loss: 2.1880397189407708

Epoch: 5| Step: 4
Training loss: 0.506317844083427
Validation loss: 2.180970533297264

Epoch: 5| Step: 5
Training loss: 0.4515112389108811
Validation loss: 2.1650106940405234

Epoch: 5| Step: 6
Training loss: 0.360204278883759
Validation loss: 2.177344904739232

Epoch: 5| Step: 7
Training loss: 0.38844365459547214
Validation loss: 2.1915811208593534

Epoch: 5| Step: 8
Training loss: 0.39500480030257523
Validation loss: 2.148126680892625

Epoch: 5| Step: 9
Training loss: 0.38112218543490056
Validation loss: 2.1699473769041937

Epoch: 5| Step: 10
Training loss: 0.2379334600685309
Validation loss: 2.1393109791491853

Epoch: 353| Step: 0
Training loss: 0.38829724069745203
Validation loss: 2.1672531565488202

Epoch: 5| Step: 1
Training loss: 0.3995926884274393
Validation loss: 2.1260663131342628

Epoch: 5| Step: 2
Training loss: 0.4014105112125075
Validation loss: 2.113956849821187

Epoch: 5| Step: 3
Training loss: 0.32618457518196564
Validation loss: 2.1424955323200803

Epoch: 5| Step: 4
Training loss: 0.5029496864860931
Validation loss: 2.114031092532134

Epoch: 5| Step: 5
Training loss: 0.43968264202262014
Validation loss: 2.126135870585818

Epoch: 5| Step: 6
Training loss: 0.3520333739486264
Validation loss: 2.1566289111366337

Epoch: 5| Step: 7
Training loss: 0.3898702960254951
Validation loss: 2.145453363171891

Epoch: 5| Step: 8
Training loss: 0.2996822069713015
Validation loss: 2.1795916463277676

Epoch: 5| Step: 9
Training loss: 0.5188266019679622
Validation loss: 2.156167259251719

Epoch: 5| Step: 10
Training loss: 0.40940086195696135
Validation loss: 2.1357522188111773

Epoch: 354| Step: 0
Training loss: 0.45959735276889113
Validation loss: 2.143848469713514

Epoch: 5| Step: 1
Training loss: 0.25566970550860635
Validation loss: 2.132669400404329

Epoch: 5| Step: 2
Training loss: 0.6374119922251926
Validation loss: 2.1324073214016717

Epoch: 5| Step: 3
Training loss: 0.3126229640317846
Validation loss: 2.1400292458776975

Epoch: 5| Step: 4
Training loss: 0.4391853025030464
Validation loss: 2.1150977164102307

Epoch: 5| Step: 5
Training loss: 0.46110379726796297
Validation loss: 2.0928678936419023

Epoch: 5| Step: 6
Training loss: 0.401333828396006
Validation loss: 2.1186280887890896

Epoch: 5| Step: 7
Training loss: 0.2073673183726891
Validation loss: 2.0850293094023584

Epoch: 5| Step: 8
Training loss: 0.5593043788891956
Validation loss: 2.0850361413666807

Epoch: 5| Step: 9
Training loss: 0.2713915027966816
Validation loss: 2.1012809324785633

Epoch: 5| Step: 10
Training loss: 0.43697572698440457
Validation loss: 2.127367698425544

Epoch: 355| Step: 0
Training loss: 0.5040083789091105
Validation loss: 2.1605881015626753

Epoch: 5| Step: 1
Training loss: 0.3399820484828796
Validation loss: 2.1630230155149937

Epoch: 5| Step: 2
Training loss: 0.5055857916437336
Validation loss: 2.129436023669829

Epoch: 5| Step: 3
Training loss: 0.2812775757304567
Validation loss: 2.1491592415031566

Epoch: 5| Step: 4
Training loss: 0.53965099664082
Validation loss: 2.170133242713939

Epoch: 5| Step: 5
Training loss: 0.19675529678308676
Validation loss: 2.1829477222184015

Epoch: 5| Step: 6
Training loss: 0.2639139406473775
Validation loss: 2.1523696793333835

Epoch: 5| Step: 7
Training loss: 0.3812165566143719
Validation loss: 2.128209777746056

Epoch: 5| Step: 8
Training loss: 0.3312565685916508
Validation loss: 2.109998861566347

Epoch: 5| Step: 9
Training loss: 0.6068464540393527
Validation loss: 2.1163235223522405

Epoch: 5| Step: 10
Training loss: 0.22096179050312875
Validation loss: 2.147475858764653

Epoch: 356| Step: 0
Training loss: 0.3207893892120573
Validation loss: 2.1149244176343265

Epoch: 5| Step: 1
Training loss: 0.5008415650036656
Validation loss: 2.1155989655988434

Epoch: 5| Step: 2
Training loss: 0.48185413946277855
Validation loss: 2.132339081825991

Epoch: 5| Step: 3
Training loss: 0.29263248218778753
Validation loss: 2.1633645595105304

Epoch: 5| Step: 4
Training loss: 0.5122005727704416
Validation loss: 2.134699546240788

Epoch: 5| Step: 5
Training loss: 0.3632372142395095
Validation loss: 2.117803282978064

Epoch: 5| Step: 6
Training loss: 0.4939496723071634
Validation loss: 2.1667660628474943

Epoch: 5| Step: 7
Training loss: 0.3923885589983911
Validation loss: 2.1602465410752827

Epoch: 5| Step: 8
Training loss: 0.34258625973446244
Validation loss: 2.1373314031374697

Epoch: 5| Step: 9
Training loss: 0.26963978116474346
Validation loss: 2.1836875449098403

Epoch: 5| Step: 10
Training loss: 0.3595594264614722
Validation loss: 2.1501199509970363

Epoch: 357| Step: 0
Training loss: 0.4569166479945012
Validation loss: 2.173416833356223

Epoch: 5| Step: 1
Training loss: 0.30635399998817375
Validation loss: 2.118033963214463

Epoch: 5| Step: 2
Training loss: 0.49007438997572134
Validation loss: 2.142416892457295

Epoch: 5| Step: 3
Training loss: 0.3736613939184365
Validation loss: 2.1155708581737023

Epoch: 5| Step: 4
Training loss: 0.448337553097792
Validation loss: 2.091747599819975

Epoch: 5| Step: 5
Training loss: 0.24810806030419041
Validation loss: 2.0952775440106803

Epoch: 5| Step: 6
Training loss: 0.2547281607250284
Validation loss: 2.094805938978363

Epoch: 5| Step: 7
Training loss: 0.49054730826776566
Validation loss: 2.117868017506482

Epoch: 5| Step: 8
Training loss: 0.49513395081682704
Validation loss: 2.151921792684056

Epoch: 5| Step: 9
Training loss: 0.23708627798841825
Validation loss: 2.139515000278672

Epoch: 5| Step: 10
Training loss: 0.444239561926471
Validation loss: 2.139351224714187

Epoch: 358| Step: 0
Training loss: 0.4066445378858238
Validation loss: 2.1733746129404423

Epoch: 5| Step: 1
Training loss: 0.1825497242552462
Validation loss: 2.095861947762884

Epoch: 5| Step: 2
Training loss: 0.3775490512306034
Validation loss: 2.17056604783362

Epoch: 5| Step: 3
Training loss: 0.520857187360647
Validation loss: 2.163450348864306

Epoch: 5| Step: 4
Training loss: 0.4036398815413541
Validation loss: 2.1598901546750433

Epoch: 5| Step: 5
Training loss: 0.46048606166910605
Validation loss: 2.115996995481293

Epoch: 5| Step: 6
Training loss: 0.5012480537395791
Validation loss: 2.1425442440313915

Epoch: 5| Step: 7
Training loss: 0.26945212488163034
Validation loss: 2.1312094572721425

Epoch: 5| Step: 8
Training loss: 0.3339292469593381
Validation loss: 2.1166946166771083

Epoch: 5| Step: 9
Training loss: 0.3798828517256768
Validation loss: 2.1299450804907445

Epoch: 5| Step: 10
Training loss: 0.3598525150505354
Validation loss: 2.157045570429369

Epoch: 359| Step: 0
Training loss: 0.2230702783762725
Validation loss: 2.1539482650019335

Epoch: 5| Step: 1
Training loss: 0.39400751457818034
Validation loss: 2.1278702728175625

Epoch: 5| Step: 2
Training loss: 0.33753078240841733
Validation loss: 2.1420569923957373

Epoch: 5| Step: 3
Training loss: 0.3871377543835535
Validation loss: 2.119956908344329

Epoch: 5| Step: 4
Training loss: 0.42651950633486146
Validation loss: 2.1497442453468167

Epoch: 5| Step: 5
Training loss: 0.4009919466020963
Validation loss: 2.102742211182624

Epoch: 5| Step: 6
Training loss: 0.4593481529591095
Validation loss: 2.1228077454359124

Epoch: 5| Step: 7
Training loss: 0.4437035052696877
Validation loss: 2.1506500348460764

Epoch: 5| Step: 8
Training loss: 0.25968069825061363
Validation loss: 2.1324460796907263

Epoch: 5| Step: 9
Training loss: 0.5422674081715617
Validation loss: 2.1385727780059076

Epoch: 5| Step: 10
Training loss: 0.22901589498473401
Validation loss: 2.1272439123876796

Epoch: 360| Step: 0
Training loss: 0.3558580342004769
Validation loss: 2.0983420718001478

Epoch: 5| Step: 1
Training loss: 0.41739800960594453
Validation loss: 2.0589983441484345

Epoch: 5| Step: 2
Training loss: 0.34399585168438673
Validation loss: 2.0710128986316465

Epoch: 5| Step: 3
Training loss: 0.3088715305025445
Validation loss: 2.074010456437424

Epoch: 5| Step: 4
Training loss: 0.37308168498497285
Validation loss: 2.1189989313561175

Epoch: 5| Step: 5
Training loss: 0.3149887877315617
Validation loss: 2.1084764287169557

Epoch: 5| Step: 6
Training loss: 0.6365912842270456
Validation loss: 2.0990316340074573

Epoch: 5| Step: 7
Training loss: 0.3364058268571417
Validation loss: 2.0992993698333016

Epoch: 5| Step: 8
Training loss: 0.26479799893838984
Validation loss: 2.128501646669144

Epoch: 5| Step: 9
Training loss: 0.45397438811643226
Validation loss: 2.103392804013634

Epoch: 5| Step: 10
Training loss: 0.38457608274332095
Validation loss: 2.0926494218931504

Epoch: 361| Step: 0
Training loss: 0.4861034502455125
Validation loss: 2.0950872283114657

Epoch: 5| Step: 1
Training loss: 0.3886710698871804
Validation loss: 2.1033251887152846

Epoch: 5| Step: 2
Training loss: 0.3525895058848868
Validation loss: 2.1523984549951614

Epoch: 5| Step: 3
Training loss: 0.27881118586148645
Validation loss: 2.1395360465646123

Epoch: 5| Step: 4
Training loss: 0.4403151809469981
Validation loss: 2.1077634427452008

Epoch: 5| Step: 5
Training loss: 0.38814132748229246
Validation loss: 2.175738650694171

Epoch: 5| Step: 6
Training loss: 0.42125209103186995
Validation loss: 2.095159863775876

Epoch: 5| Step: 7
Training loss: 0.3483857420040936
Validation loss: 2.123570902057312

Epoch: 5| Step: 8
Training loss: 0.264716347290022
Validation loss: 2.1190648942033623

Epoch: 5| Step: 9
Training loss: 0.43849392794947173
Validation loss: 2.0915996815168794

Epoch: 5| Step: 10
Training loss: 0.3124032586082235
Validation loss: 2.1472975094990048

Epoch: 362| Step: 0
Training loss: 0.5354989061638269
Validation loss: 2.1134155927060823

Epoch: 5| Step: 1
Training loss: 0.30278449105165856
Validation loss: 2.1178583257619805

Epoch: 5| Step: 2
Training loss: 0.32705577847663053
Validation loss: 2.0903806714109754

Epoch: 5| Step: 3
Training loss: 0.3206674191186196
Validation loss: 2.1229677719251994

Epoch: 5| Step: 4
Training loss: 0.33365687548042927
Validation loss: 2.102943540890446

Epoch: 5| Step: 5
Training loss: 0.22994785118030092
Validation loss: 2.1496818457559925

Epoch: 5| Step: 6
Training loss: 0.5056668065992316
Validation loss: 2.1427699654606482

Epoch: 5| Step: 7
Training loss: 0.3782476423319918
Validation loss: 2.1324846851989734

Epoch: 5| Step: 8
Training loss: 0.347246914886271
Validation loss: 2.0984598020324854

Epoch: 5| Step: 9
Training loss: 0.21196206599498907
Validation loss: 2.131891649739852

Epoch: 5| Step: 10
Training loss: 0.4738508528803675
Validation loss: 2.120891784952652

Epoch: 363| Step: 0
Training loss: 0.25177434744149496
Validation loss: 2.1265170179474033

Epoch: 5| Step: 1
Training loss: 0.42974400582274647
Validation loss: 2.17651518822923

Epoch: 5| Step: 2
Training loss: 0.3657614836307824
Validation loss: 2.1169922077960677

Epoch: 5| Step: 3
Training loss: 0.28523208968313546
Validation loss: 2.109861461675461

Epoch: 5| Step: 4
Training loss: 0.08785128242716027
Validation loss: 2.11711862575644

Epoch: 5| Step: 5
Training loss: 0.417890630534128
Validation loss: 2.1067154671959316

Epoch: 5| Step: 6
Training loss: 0.21005349891261907
Validation loss: 2.095801405022413

Epoch: 5| Step: 7
Training loss: 0.602875057868235
Validation loss: 2.0670082240069836

Epoch: 5| Step: 8
Training loss: 0.32613309755357406
Validation loss: 2.1062352344249398

Epoch: 5| Step: 9
Training loss: 0.3043464928697401
Validation loss: 2.1177699311074205

Epoch: 5| Step: 10
Training loss: 0.4928849743059489
Validation loss: 2.114344498257063

Epoch: 364| Step: 0
Training loss: 0.30305604150317245
Validation loss: 2.1125823532841115

Epoch: 5| Step: 1
Training loss: 0.4145711437746457
Validation loss: 2.094522286931665

Epoch: 5| Step: 2
Training loss: 0.3228396764876184
Validation loss: 2.1598030695705224

Epoch: 5| Step: 3
Training loss: 0.3189942751583024
Validation loss: 2.1454912226167155

Epoch: 5| Step: 4
Training loss: 0.3882503811944293
Validation loss: 2.133036510986892

Epoch: 5| Step: 5
Training loss: 0.281095237007046
Validation loss: 2.130393295347453

Epoch: 5| Step: 6
Training loss: 0.34656151920176376
Validation loss: 2.12993821052796

Epoch: 5| Step: 7
Training loss: 0.2888685039415469
Validation loss: 2.112811836264546

Epoch: 5| Step: 8
Training loss: 0.4202179508151984
Validation loss: 2.125548503668778

Epoch: 5| Step: 9
Training loss: 0.4924124551798374
Validation loss: 2.1529697841566735

Epoch: 5| Step: 10
Training loss: 0.41730009052701617
Validation loss: 2.1049550322954604

Epoch: 365| Step: 0
Training loss: 0.3960103362846512
Validation loss: 2.1239020305707776

Epoch: 5| Step: 1
Training loss: 0.3164718348029852
Validation loss: 2.082535021222441

Epoch: 5| Step: 2
Training loss: 0.33146958810163196
Validation loss: 2.0798324428316453

Epoch: 5| Step: 3
Training loss: 0.3704680538613397
Validation loss: 2.1019615388881245

Epoch: 5| Step: 4
Training loss: 0.42309103653365404
Validation loss: 2.117347806572289

Epoch: 5| Step: 5
Training loss: 0.45638748213938873
Validation loss: 2.099301910514822

Epoch: 5| Step: 6
Training loss: 0.35309456677236434
Validation loss: 2.1432781001329024

Epoch: 5| Step: 7
Training loss: 0.23317382890465083
Validation loss: 2.152503861426976

Epoch: 5| Step: 8
Training loss: 0.2495275070659753
Validation loss: 2.1289465911044556

Epoch: 5| Step: 9
Training loss: 0.4179709069027017
Validation loss: 2.1676094961457277

Epoch: 5| Step: 10
Training loss: 0.5339990341752852
Validation loss: 2.159313416137471

Epoch: 366| Step: 0
Training loss: 0.45931355461179135
Validation loss: 2.1712675852748884

Epoch: 5| Step: 1
Training loss: 0.4110595927878791
Validation loss: 2.170556904972487

Epoch: 5| Step: 2
Training loss: 0.3928166134785064
Validation loss: 2.127916895339504

Epoch: 5| Step: 3
Training loss: 0.39501068520278004
Validation loss: 2.196531887039209

Epoch: 5| Step: 4
Training loss: 0.32971761981725944
Validation loss: 2.142256925258263

Epoch: 5| Step: 5
Training loss: 0.3263778150598511
Validation loss: 2.1471492848201255

Epoch: 5| Step: 6
Training loss: 0.4374432697299883
Validation loss: 2.1045009309358496

Epoch: 5| Step: 7
Training loss: 0.2751781915844352
Validation loss: 2.1157442845430547

Epoch: 5| Step: 8
Training loss: 0.35373937786316534
Validation loss: 2.1203041611093654

Epoch: 5| Step: 9
Training loss: 0.25648521002576313
Validation loss: 2.1151784846043395

Epoch: 5| Step: 10
Training loss: 0.2984919683072369
Validation loss: 2.1096025800669027

Epoch: 367| Step: 0
Training loss: 0.2220016192074312
Validation loss: 2.097737964706671

Epoch: 5| Step: 1
Training loss: 0.31357212927260847
Validation loss: 2.135670502525392

Epoch: 5| Step: 2
Training loss: 0.4081789219448042
Validation loss: 2.1103472490687922

Epoch: 5| Step: 3
Training loss: 0.3108420738358337
Validation loss: 2.099819541995198

Epoch: 5| Step: 4
Training loss: 0.48757048182952223
Validation loss: 2.083249786506539

Epoch: 5| Step: 5
Training loss: 0.2854070083464406
Validation loss: 2.109549449025363

Epoch: 5| Step: 6
Training loss: 0.4301668267936413
Validation loss: 2.079720372573306

Epoch: 5| Step: 7
Training loss: 0.3269687101963314
Validation loss: 2.0708452848284877

Epoch: 5| Step: 8
Training loss: 0.4229771029067162
Validation loss: 2.0999220312091618

Epoch: 5| Step: 9
Training loss: 0.39364679740040043
Validation loss: 2.118123143856677

Epoch: 5| Step: 10
Training loss: 0.2632687489289542
Validation loss: 2.085272607104258

Epoch: 368| Step: 0
Training loss: 0.488287185632868
Validation loss: 2.13549014089394

Epoch: 5| Step: 1
Training loss: 0.19949258422214552
Validation loss: 2.1579625642410902

Epoch: 5| Step: 2
Training loss: 0.39427225657734893
Validation loss: 2.1149590047057747

Epoch: 5| Step: 3
Training loss: 0.14154142220737764
Validation loss: 2.129944791321455

Epoch: 5| Step: 4
Training loss: 0.4923814209884719
Validation loss: 2.1237986351826206

Epoch: 5| Step: 5
Training loss: 0.355501990807669
Validation loss: 2.1481777573353287

Epoch: 5| Step: 6
Training loss: 0.2976660979636791
Validation loss: 2.1253070693885556

Epoch: 5| Step: 7
Training loss: 0.4169500718300709
Validation loss: 2.1367035475475764

Epoch: 5| Step: 8
Training loss: 0.2764356952852405
Validation loss: 2.1490975006998636

Epoch: 5| Step: 9
Training loss: 0.301973925980702
Validation loss: 2.1492026294660387

Epoch: 5| Step: 10
Training loss: 0.335719392634017
Validation loss: 2.1601394165785957

Epoch: 369| Step: 0
Training loss: 0.14252082117329987
Validation loss: 2.132911549111455

Epoch: 5| Step: 1
Training loss: 0.4543794007593258
Validation loss: 2.1237496238797537

Epoch: 5| Step: 2
Training loss: 0.2803029167808112
Validation loss: 2.131368858961999

Epoch: 5| Step: 3
Training loss: 0.22368622854041437
Validation loss: 2.1172479034308793

Epoch: 5| Step: 4
Training loss: 0.32368823390154916
Validation loss: 2.1109450743539426

Epoch: 5| Step: 5
Training loss: 0.23575901834222704
Validation loss: 2.1117144871812568

Epoch: 5| Step: 6
Training loss: 0.47971683685853617
Validation loss: 2.1127136043109647

Epoch: 5| Step: 7
Training loss: 0.4241020969578289
Validation loss: 2.1119530689851502

Epoch: 5| Step: 8
Training loss: 0.28576898716416005
Validation loss: 2.106427086550244

Epoch: 5| Step: 9
Training loss: 0.4677214942077318
Validation loss: 2.1070310007452955

Epoch: 5| Step: 10
Training loss: 0.40345680568844067
Validation loss: 2.1088736664155903

Epoch: 370| Step: 0
Training loss: 0.20072182061538402
Validation loss: 2.1487291017723362

Epoch: 5| Step: 1
Training loss: 0.353530767548538
Validation loss: 2.143363950691186

Epoch: 5| Step: 2
Training loss: 0.5713489468480107
Validation loss: 2.1528285236797235

Epoch: 5| Step: 3
Training loss: 0.21441150011174076
Validation loss: 2.1413461135096754

Epoch: 5| Step: 4
Training loss: 0.24913210274399275
Validation loss: 2.1138637683753805

Epoch: 5| Step: 5
Training loss: 0.2724510655956183
Validation loss: 2.1400002589688985

Epoch: 5| Step: 6
Training loss: 0.4497584542396443
Validation loss: 2.162754528206082

Epoch: 5| Step: 7
Training loss: 0.24755460596728826
Validation loss: 2.1230485498420397

Epoch: 5| Step: 8
Training loss: 0.4342447154108426
Validation loss: 2.1568249017342382

Epoch: 5| Step: 9
Training loss: 0.35177353776670284
Validation loss: 2.1272789872859166

Epoch: 5| Step: 10
Training loss: 0.28722933125234684
Validation loss: 2.0967187112925147

Epoch: 371| Step: 0
Training loss: 0.4585629577956788
Validation loss: 2.1253453347483866

Epoch: 5| Step: 1
Training loss: 0.42156149553726463
Validation loss: 2.1162615261967286

Epoch: 5| Step: 2
Training loss: 0.36057553657852043
Validation loss: 2.1286876224890303

Epoch: 5| Step: 3
Training loss: 0.29575893525486036
Validation loss: 2.09566976332626

Epoch: 5| Step: 4
Training loss: 0.17078270944702917
Validation loss: 2.0926409005997746

Epoch: 5| Step: 5
Training loss: 0.3675162081809708
Validation loss: 2.1039934670841944

Epoch: 5| Step: 6
Training loss: 0.39587202845049274
Validation loss: 2.1412813123494345

Epoch: 5| Step: 7
Training loss: 0.30537519119778245
Validation loss: 2.095617970452986

Epoch: 5| Step: 8
Training loss: 0.27632670560973216
Validation loss: 2.1083879003240713

Epoch: 5| Step: 9
Training loss: 0.4169563081479376
Validation loss: 2.126947997599551

Epoch: 5| Step: 10
Training loss: 0.36055241391441556
Validation loss: 2.1468427569533444

Epoch: 372| Step: 0
Training loss: 0.41159823208240154
Validation loss: 2.1371142469099325

Epoch: 5| Step: 1
Training loss: 0.3602184266808479
Validation loss: 2.1300524378192462

Epoch: 5| Step: 2
Training loss: 0.24994842176047852
Validation loss: 2.1459850291908205

Epoch: 5| Step: 3
Training loss: 0.24461144634382284
Validation loss: 2.138767829331122

Epoch: 5| Step: 4
Training loss: 0.32922080395550735
Validation loss: 2.115338654380608

Epoch: 5| Step: 5
Training loss: 0.29351148560290496
Validation loss: 2.1378908521899804

Epoch: 5| Step: 6
Training loss: 0.5362339167639497
Validation loss: 2.147717310024256

Epoch: 5| Step: 7
Training loss: 0.2356668236468137
Validation loss: 2.1115674133534514

Epoch: 5| Step: 8
Training loss: 0.19167055643495273
Validation loss: 2.151377935409091

Epoch: 5| Step: 9
Training loss: 0.532974865021933
Validation loss: 2.1444103262835306

Epoch: 5| Step: 10
Training loss: 0.2121498448664637
Validation loss: 2.0942529623083352

Epoch: 373| Step: 0
Training loss: 0.38486618819127444
Validation loss: 2.1081095495221134

Epoch: 5| Step: 1
Training loss: 0.44141507772885025
Validation loss: 2.1049328869659085

Epoch: 5| Step: 2
Training loss: 0.5238901145718906
Validation loss: 2.0916951031433677

Epoch: 5| Step: 3
Training loss: 0.2858392426771511
Validation loss: 2.126884683912632

Epoch: 5| Step: 4
Training loss: 0.14343194839646273
Validation loss: 2.111730826011472

Epoch: 5| Step: 5
Training loss: 0.4122411688916513
Validation loss: 2.083229231130561

Epoch: 5| Step: 6
Training loss: 0.23070636719861473
Validation loss: 2.1065642559060387

Epoch: 5| Step: 7
Training loss: 0.2944550767339453
Validation loss: 2.115010982736937

Epoch: 5| Step: 8
Training loss: 0.23079358662592195
Validation loss: 2.112620085839211

Epoch: 5| Step: 9
Training loss: 0.21099130509414085
Validation loss: 2.114996871224472

Epoch: 5| Step: 10
Training loss: 0.5291000225372828
Validation loss: 2.1127972416965224

Epoch: 374| Step: 0
Training loss: 0.2965432999347816
Validation loss: 2.071168431217552

Epoch: 5| Step: 1
Training loss: 0.2307200355028955
Validation loss: 2.0681113462034255

Epoch: 5| Step: 2
Training loss: 0.42232470032989505
Validation loss: 2.112004656700011

Epoch: 5| Step: 3
Training loss: 0.18595453953603633
Validation loss: 2.0567034971868012

Epoch: 5| Step: 4
Training loss: 0.166398504461992
Validation loss: 2.0325830103856846

Epoch: 5| Step: 5
Training loss: 0.4488098605617124
Validation loss: 2.046142370611112

Epoch: 5| Step: 6
Training loss: 0.2922354740394853
Validation loss: 2.073558017649278

Epoch: 5| Step: 7
Training loss: 0.43400277786310765
Validation loss: 2.049194218769025

Epoch: 5| Step: 8
Training loss: 0.3508562411412749
Validation loss: 2.0694140877343576

Epoch: 5| Step: 9
Training loss: 0.3694200215278038
Validation loss: 2.0962727457442285

Epoch: 5| Step: 10
Training loss: 0.3590185014279366
Validation loss: 2.116547063145734

Epoch: 375| Step: 0
Training loss: 0.4569939003053185
Validation loss: 2.113724997525339

Epoch: 5| Step: 1
Training loss: 0.3740695098309374
Validation loss: 2.1282363022615383

Epoch: 5| Step: 2
Training loss: 0.10703173797384806
Validation loss: 2.1107946251565743

Epoch: 5| Step: 3
Training loss: 0.24337074963483304
Validation loss: 2.1404501557118327

Epoch: 5| Step: 4
Training loss: 0.24658092083067193
Validation loss: 2.130329860222698

Epoch: 5| Step: 5
Training loss: 0.39459890786356727
Validation loss: 2.0974553031959497

Epoch: 5| Step: 6
Training loss: 0.38801905185708674
Validation loss: 2.085588714320246

Epoch: 5| Step: 7
Training loss: 0.31648172255482526
Validation loss: 2.124025041567572

Epoch: 5| Step: 8
Training loss: 0.2589664355202554
Validation loss: 2.0871793448479568

Epoch: 5| Step: 9
Training loss: 0.3143695933595635
Validation loss: 2.083714758709222

Epoch: 5| Step: 10
Training loss: 0.47838486422398013
Validation loss: 2.095540056087839

Epoch: 376| Step: 0
Training loss: 0.16086420153861336
Validation loss: 2.112220902563577

Epoch: 5| Step: 1
Training loss: 0.4825758437352407
Validation loss: 2.155831369902488

Epoch: 5| Step: 2
Training loss: 0.5206133250636754
Validation loss: 2.1020796371670243

Epoch: 5| Step: 3
Training loss: 0.2693867226813568
Validation loss: 2.082885613067631

Epoch: 5| Step: 4
Training loss: 0.18700253536295683
Validation loss: 2.084059053172021

Epoch: 5| Step: 5
Training loss: 0.2862176216129068
Validation loss: 2.1121451724819647

Epoch: 5| Step: 6
Training loss: 0.18756972447038248
Validation loss: 2.1556725593032127

Epoch: 5| Step: 7
Training loss: 0.25684040486326865
Validation loss: 2.097479033896246

Epoch: 5| Step: 8
Training loss: 0.36847665402360624
Validation loss: 2.1323255616910326

Epoch: 5| Step: 9
Training loss: 0.4801843002770808
Validation loss: 2.138426567749898

Epoch: 5| Step: 10
Training loss: 0.14080140519953077
Validation loss: 2.1181836355847947

Epoch: 377| Step: 0
Training loss: 0.3529368874301529
Validation loss: 2.1232475000838424

Epoch: 5| Step: 1
Training loss: 0.17945227568395944
Validation loss: 2.130429063867154

Epoch: 5| Step: 2
Training loss: 0.3593007301211669
Validation loss: 2.1096220290369634

Epoch: 5| Step: 3
Training loss: 0.3471924334569548
Validation loss: 2.1006480789819393

Epoch: 5| Step: 4
Training loss: 0.3366154439223488
Validation loss: 2.1232168882735984

Epoch: 5| Step: 5
Training loss: 0.2950076048080923
Validation loss: 2.145961288936515

Epoch: 5| Step: 6
Training loss: 0.442926220475322
Validation loss: 2.0785173910303363

Epoch: 5| Step: 7
Training loss: 0.32745462010380805
Validation loss: 2.0925283680657873

Epoch: 5| Step: 8
Training loss: 0.3425603568363781
Validation loss: 2.142668403032764

Epoch: 5| Step: 9
Training loss: 0.2656545482357073
Validation loss: 2.110495458347094

Epoch: 5| Step: 10
Training loss: 0.3492045162807658
Validation loss: 2.100320758045201

Epoch: 378| Step: 0
Training loss: 0.4402702025869278
Validation loss: 2.088834724265484

Epoch: 5| Step: 1
Training loss: 0.27292478721612456
Validation loss: 2.0484293196617847

Epoch: 5| Step: 2
Training loss: 0.2416332193294925
Validation loss: 2.094314216637565

Epoch: 5| Step: 3
Training loss: 0.3882551978906133
Validation loss: 2.091973328606034

Epoch: 5| Step: 4
Training loss: 0.29621364310054044
Validation loss: 2.1055790139100607

Epoch: 5| Step: 5
Training loss: 0.40513840229637427
Validation loss: 2.1320835757910177

Epoch: 5| Step: 6
Training loss: 0.23784831066918977
Validation loss: 2.146984806498582

Epoch: 5| Step: 7
Training loss: 0.3797469496789692
Validation loss: 2.0727428789689863

Epoch: 5| Step: 8
Training loss: 0.33479449527133465
Validation loss: 2.1402398980033093

Epoch: 5| Step: 9
Training loss: 0.22238066835239195
Validation loss: 2.139346472746341

Epoch: 5| Step: 10
Training loss: 0.37578030703103127
Validation loss: 2.1411204284600314

Epoch: 379| Step: 0
Training loss: 0.36775093273119763
Validation loss: 2.160269949300502

Epoch: 5| Step: 1
Training loss: 0.26116382069539285
Validation loss: 2.1274394534904344

Epoch: 5| Step: 2
Training loss: 0.2677094909751789
Validation loss: 2.1523803620873823

Epoch: 5| Step: 3
Training loss: 0.30589400347537093
Validation loss: 2.128758702015307

Epoch: 5| Step: 4
Training loss: 0.31400273926414796
Validation loss: 2.1343246202740813

Epoch: 5| Step: 5
Training loss: 0.20160699286757583
Validation loss: 2.1102927152768407

Epoch: 5| Step: 6
Training loss: 0.47014393177674263
Validation loss: 2.0986471287175736

Epoch: 5| Step: 7
Training loss: 0.43295750031023844
Validation loss: 2.1094168211856132

Epoch: 5| Step: 8
Training loss: 0.38571464343659906
Validation loss: 2.1178347774161077

Epoch: 5| Step: 9
Training loss: 0.20765985569001383
Validation loss: 2.097302894378104

Epoch: 5| Step: 10
Training loss: 0.2501743870723943
Validation loss: 2.0894069966227615

Epoch: 380| Step: 0
Training loss: 0.5599101634002985
Validation loss: 2.1172411929654236

Epoch: 5| Step: 1
Training loss: 0.3457487043948113
Validation loss: 2.1129909488325

Epoch: 5| Step: 2
Training loss: 0.28999479835876696
Validation loss: 2.1285170934844655

Epoch: 5| Step: 3
Training loss: 0.32379763037434195
Validation loss: 2.140925046333994

Epoch: 5| Step: 4
Training loss: 0.18855503405469393
Validation loss: 2.1320538435681744

Epoch: 5| Step: 5
Training loss: 0.29014310672472504
Validation loss: 2.118442102676631

Epoch: 5| Step: 6
Training loss: 0.3584603612139533
Validation loss: 2.117915162825881

Epoch: 5| Step: 7
Training loss: 0.40819850718245354
Validation loss: 2.119759530488533

Epoch: 5| Step: 8
Training loss: 0.1854984421009132
Validation loss: 2.1231898524850017

Epoch: 5| Step: 9
Training loss: 0.24902188169703948
Validation loss: 2.143049277692982

Epoch: 5| Step: 10
Training loss: 0.27979639373633947
Validation loss: 2.1302952086168485

Epoch: 381| Step: 0
Training loss: 0.43801636536716315
Validation loss: 2.135894630259308

Epoch: 5| Step: 1
Training loss: 0.3500628912994535
Validation loss: 2.1468639356000225

Epoch: 5| Step: 2
Training loss: 0.3736769463196789
Validation loss: 2.1369693056766264

Epoch: 5| Step: 3
Training loss: 0.3853906502405665
Validation loss: 2.0898411478312573

Epoch: 5| Step: 4
Training loss: 0.2965774802071359
Validation loss: 2.165885482351103

Epoch: 5| Step: 5
Training loss: 0.3584821639631883
Validation loss: 2.1143540199904396

Epoch: 5| Step: 6
Training loss: 0.19202552575813056
Validation loss: 2.101873578903886

Epoch: 5| Step: 7
Training loss: 0.13061050691694845
Validation loss: 2.1024035477039

Epoch: 5| Step: 8
Training loss: 0.22858323621266863
Validation loss: 2.0977462248484198

Epoch: 5| Step: 9
Training loss: 0.3944751397447697
Validation loss: 2.0983174265989257

Epoch: 5| Step: 10
Training loss: 0.16796067684200733
Validation loss: 2.0668207591773995

Epoch: 382| Step: 0
Training loss: 0.2876919136960189
Validation loss: 2.111684871221223

Epoch: 5| Step: 1
Training loss: 0.4518294723284333
Validation loss: 2.1201405321405296

Epoch: 5| Step: 2
Training loss: 0.2652731416262753
Validation loss: 2.076959792654367

Epoch: 5| Step: 3
Training loss: 0.314664047299174
Validation loss: 2.1030789699983425

Epoch: 5| Step: 4
Training loss: 0.19859618727946454
Validation loss: 2.0943434022374987

Epoch: 5| Step: 5
Training loss: 0.3893910564216479
Validation loss: 2.1031958835101867

Epoch: 5| Step: 6
Training loss: 0.3740449904165649
Validation loss: 2.1055881089637545

Epoch: 5| Step: 7
Training loss: 0.27901552608061203
Validation loss: 2.1258415628377176

Epoch: 5| Step: 8
Training loss: 0.22053958944299415
Validation loss: 2.1125291762861687

Epoch: 5| Step: 9
Training loss: 0.21380785114594608
Validation loss: 2.1210977868567276

Epoch: 5| Step: 10
Training loss: 0.40881981877498696
Validation loss: 2.1151840623173954

Epoch: 383| Step: 0
Training loss: 0.2804583162369981
Validation loss: 2.1096819679712597

Epoch: 5| Step: 1
Training loss: 0.35473897451213066
Validation loss: 2.1121928181549054

Epoch: 5| Step: 2
Training loss: 0.3620682019114468
Validation loss: 2.0876683254068578

Epoch: 5| Step: 3
Training loss: 0.2713376753488551
Validation loss: 2.1028050740775015

Epoch: 5| Step: 4
Training loss: 0.3325703675877762
Validation loss: 2.1182386067614165

Epoch: 5| Step: 5
Training loss: 0.34772605409524815
Validation loss: 2.106409004665216

Epoch: 5| Step: 6
Training loss: 0.1911791018050351
Validation loss: 2.1677015848528742

Epoch: 5| Step: 7
Training loss: 0.23630216944637386
Validation loss: 2.1041004385120727

Epoch: 5| Step: 8
Training loss: 0.312182431986533
Validation loss: 2.097635900571703

Epoch: 5| Step: 9
Training loss: 0.458539024350036
Validation loss: 2.1604984566247256

Epoch: 5| Step: 10
Training loss: 0.25246324573838663
Validation loss: 2.0885787065341503

Epoch: 384| Step: 0
Training loss: 0.26168216620440227
Validation loss: 2.1516236498175467

Epoch: 5| Step: 1
Training loss: 0.4127936986587818
Validation loss: 2.12670980212176

Epoch: 5| Step: 2
Training loss: 0.22981333075542584
Validation loss: 2.162440830708446

Epoch: 5| Step: 3
Training loss: 0.34290890312715455
Validation loss: 2.1590034158861053

Epoch: 5| Step: 4
Training loss: 0.3423602230020954
Validation loss: 2.1687705208015378

Epoch: 5| Step: 5
Training loss: 0.30204728201890574
Validation loss: 2.1657995053690606

Epoch: 5| Step: 6
Training loss: 0.2800310795003063
Validation loss: 2.170318037769734

Epoch: 5| Step: 7
Training loss: 0.3671699276229688
Validation loss: 2.1830354412261395

Epoch: 5| Step: 8
Training loss: 0.12126009037613038
Validation loss: 2.173818186251579

Epoch: 5| Step: 9
Training loss: 0.28759883498256295
Validation loss: 2.1448848211816776

Epoch: 5| Step: 10
Training loss: 0.3543294738105973
Validation loss: 2.095585668682426

Epoch: 385| Step: 0
Training loss: 0.2868240911319909
Validation loss: 2.1453572979861324

Epoch: 5| Step: 1
Training loss: 0.23717534500258622
Validation loss: 2.12597176074032

Epoch: 5| Step: 2
Training loss: 0.20839647687223875
Validation loss: 2.1293528923433542

Epoch: 5| Step: 3
Training loss: 0.3039076434890455
Validation loss: 2.12888318452272

Epoch: 5| Step: 4
Training loss: 0.2794021728067964
Validation loss: 2.1434075295229413

Epoch: 5| Step: 5
Training loss: 0.4722857639003893
Validation loss: 2.1222248523136567

Epoch: 5| Step: 6
Training loss: 0.19130434515433228
Validation loss: 2.1322110010907345

Epoch: 5| Step: 7
Training loss: 0.3368031526536641
Validation loss: 2.0983357736910424

Epoch: 5| Step: 8
Training loss: 0.30314609464020187
Validation loss: 2.1716575404507354

Epoch: 5| Step: 9
Training loss: 0.40206947978107765
Validation loss: 2.1263606175047527

Epoch: 5| Step: 10
Training loss: 0.31196608232031836
Validation loss: 2.1305709930514296

Epoch: 386| Step: 0
Training loss: 0.16692441267673222
Validation loss: 2.1127302835159387

Epoch: 5| Step: 1
Training loss: 0.4288318958696977
Validation loss: 2.1300139452947495

Epoch: 5| Step: 2
Training loss: 0.32594510721489267
Validation loss: 2.107834461026329

Epoch: 5| Step: 3
Training loss: 0.21594131322825488
Validation loss: 2.114454832182975

Epoch: 5| Step: 4
Training loss: 0.46469213112714863
Validation loss: 2.1319669994636947

Epoch: 5| Step: 5
Training loss: 0.3014498005911426
Validation loss: 2.1488875916056003

Epoch: 5| Step: 6
Training loss: 0.28670432914619476
Validation loss: 2.1037455559450113

Epoch: 5| Step: 7
Training loss: 0.27703547470735634
Validation loss: 2.1196405734296917

Epoch: 5| Step: 8
Training loss: 0.25376991132779525
Validation loss: 2.096384160729064

Epoch: 5| Step: 9
Training loss: 0.3438240643386963
Validation loss: 2.1212391251788336

Epoch: 5| Step: 10
Training loss: 0.21907150960181399
Validation loss: 2.148081679724465

Epoch: 387| Step: 0
Training loss: 0.16292717910002685
Validation loss: 2.094146304703169

Epoch: 5| Step: 1
Training loss: 0.234966905538689
Validation loss: 2.1318925269774263

Epoch: 5| Step: 2
Training loss: 0.34239351785726185
Validation loss: 2.1157429395591496

Epoch: 5| Step: 3
Training loss: 0.27852332758585013
Validation loss: 2.1140929940266036

Epoch: 5| Step: 4
Training loss: 0.40850173030706266
Validation loss: 2.1265865317246244

Epoch: 5| Step: 5
Training loss: 0.4001190008531837
Validation loss: 2.1556386284511886

Epoch: 5| Step: 6
Training loss: 0.20702639160213687
Validation loss: 2.1253770328488195

Epoch: 5| Step: 7
Training loss: 0.39250924564211626
Validation loss: 2.1454236931551818

Epoch: 5| Step: 8
Training loss: 0.33227133205382053
Validation loss: 2.143891422267599

Epoch: 5| Step: 9
Training loss: 0.3986355532412251
Validation loss: 2.1263182403933425

Epoch: 5| Step: 10
Training loss: 0.15287694788960535
Validation loss: 2.1315392933191815

Epoch: 388| Step: 0
Training loss: 0.37601540104795755
Validation loss: 2.136985978512528

Epoch: 5| Step: 1
Training loss: 0.27361588789927477
Validation loss: 2.111524359938818

Epoch: 5| Step: 2
Training loss: 0.36539129466349646
Validation loss: 2.12958419284776

Epoch: 5| Step: 3
Training loss: 0.3072689689184636
Validation loss: 2.158957739568531

Epoch: 5| Step: 4
Training loss: 0.3440577040155273
Validation loss: 2.1285761854010667

Epoch: 5| Step: 5
Training loss: 0.24141185130562165
Validation loss: 2.142230181819588

Epoch: 5| Step: 6
Training loss: 0.2668310721557931
Validation loss: 2.1352162212794727

Epoch: 5| Step: 7
Training loss: 0.3413886329767006
Validation loss: 2.1275278157232163

Epoch: 5| Step: 8
Training loss: 0.19638180795350335
Validation loss: 2.105408599187287

Epoch: 5| Step: 9
Training loss: 0.32390174535037897
Validation loss: 2.0879990834919067

Epoch: 5| Step: 10
Training loss: 0.3284345483692647
Validation loss: 2.127780548876494

Epoch: 389| Step: 0
Training loss: 0.3111378546603758
Validation loss: 2.125263254506454

Epoch: 5| Step: 1
Training loss: 0.30229629075115205
Validation loss: 2.1707408473019747

Epoch: 5| Step: 2
Training loss: 0.1957686628601798
Validation loss: 2.11752257593906

Epoch: 5| Step: 3
Training loss: 0.2793030638109124
Validation loss: 2.094981886751411

Epoch: 5| Step: 4
Training loss: 0.26635346379123326
Validation loss: 2.1289278184156237

Epoch: 5| Step: 5
Training loss: 0.4073968618144734
Validation loss: 2.0839410605078514

Epoch: 5| Step: 6
Training loss: 0.32840982064612745
Validation loss: 2.0945890273297616

Epoch: 5| Step: 7
Training loss: 0.3716852192710126
Validation loss: 2.1304286667633487

Epoch: 5| Step: 8
Training loss: 0.3090491013664903
Validation loss: 2.119264403803088

Epoch: 5| Step: 9
Training loss: 0.31486914936913324
Validation loss: 2.1323982253222207

Epoch: 5| Step: 10
Training loss: 0.2598732173357615
Validation loss: 2.1665050676661424

Epoch: 390| Step: 0
Training loss: 0.13936673274560238
Validation loss: 2.1341374737466468

Epoch: 5| Step: 1
Training loss: 0.338049382746409
Validation loss: 2.1386429961588433

Epoch: 5| Step: 2
Training loss: 0.28491945755740766
Validation loss: 2.1501513020462206

Epoch: 5| Step: 3
Training loss: 0.19289074568283118
Validation loss: 2.1676173238586713

Epoch: 5| Step: 4
Training loss: 0.22324565207261862
Validation loss: 2.1617199660966424

Epoch: 5| Step: 5
Training loss: 0.2635436275972131
Validation loss: 2.147423573596779

Epoch: 5| Step: 6
Training loss: 0.3263169382930021
Validation loss: 2.1421191320950856

Epoch: 5| Step: 7
Training loss: 0.4967073265602864
Validation loss: 2.151038237021766

Epoch: 5| Step: 8
Training loss: 0.35893504537506626
Validation loss: 2.120618010040543

Epoch: 5| Step: 9
Training loss: 0.2608320959862152
Validation loss: 2.1115626067511317

Epoch: 5| Step: 10
Training loss: 0.42031646641557924
Validation loss: 2.0887129215803317

Epoch: 391| Step: 0
Training loss: 0.3795376658613877
Validation loss: 2.1156310387502772

Epoch: 5| Step: 1
Training loss: 0.25673244117081395
Validation loss: 2.1352451746820176

Epoch: 5| Step: 2
Training loss: 0.289039404693928
Validation loss: 2.0993227560769396

Epoch: 5| Step: 3
Training loss: 0.32361863219758286
Validation loss: 2.108231721188755

Epoch: 5| Step: 4
Training loss: 0.3184029952981849
Validation loss: 2.1697275176176283

Epoch: 5| Step: 5
Training loss: 0.2790524940790058
Validation loss: 2.14948330212923

Epoch: 5| Step: 6
Training loss: 0.3291637011084584
Validation loss: 2.144284095196996

Epoch: 5| Step: 7
Training loss: 0.19249499385690352
Validation loss: 2.11957300896737

Epoch: 5| Step: 8
Training loss: 0.33134400545330034
Validation loss: 2.1533057531856534

Epoch: 5| Step: 9
Training loss: 0.21389623122510953
Validation loss: 2.0858652427196165

Epoch: 5| Step: 10
Training loss: 0.5065093706474846
Validation loss: 2.1709474223698613

Epoch: 392| Step: 0
Training loss: 0.41553745638491363
Validation loss: 2.123920621362486

Epoch: 5| Step: 1
Training loss: 0.3819768699214237
Validation loss: 2.0923865759480615

Epoch: 5| Step: 2
Training loss: 0.2860358532877224
Validation loss: 2.1275528684338036

Epoch: 5| Step: 3
Training loss: 0.2931333333886661
Validation loss: 2.0776880569625096

Epoch: 5| Step: 4
Training loss: 0.25421519923529295
Validation loss: 2.1417660978319426

Epoch: 5| Step: 5
Training loss: 0.43312891538647524
Validation loss: 2.1007862285144276

Epoch: 5| Step: 6
Training loss: 0.2277859915575951
Validation loss: 2.143801120997713

Epoch: 5| Step: 7
Training loss: 0.23488711198544607
Validation loss: 2.136398869190495

Epoch: 5| Step: 8
Training loss: 0.2637133812907669
Validation loss: 2.1362898561253583

Epoch: 5| Step: 9
Training loss: 0.31308550819753056
Validation loss: 2.1275507597325802

Epoch: 5| Step: 10
Training loss: 0.24568842251065148
Validation loss: 2.1236932791598675

Epoch: 393| Step: 0
Training loss: 0.3353399906816889
Validation loss: 2.098681092620114

Epoch: 5| Step: 1
Training loss: 0.12319358526293063
Validation loss: 2.129064883715182

Epoch: 5| Step: 2
Training loss: 0.20547357306965996
Validation loss: 2.104472766039806

Epoch: 5| Step: 3
Training loss: 0.5599358980496767
Validation loss: 2.1327226762541613

Epoch: 5| Step: 4
Training loss: 0.365479657229346
Validation loss: 2.136795587574067

Epoch: 5| Step: 5
Training loss: 0.2701020347554234
Validation loss: 2.1239081695815423

Epoch: 5| Step: 6
Training loss: 0.35902698915609343
Validation loss: 2.10898883768365

Epoch: 5| Step: 7
Training loss: 0.27554897057710087
Validation loss: 2.132779027042196

Epoch: 5| Step: 8
Training loss: 0.2041852314125052
Validation loss: 2.137806228667422

Epoch: 5| Step: 9
Training loss: 0.21655197745516674
Validation loss: 2.124718854982509

Epoch: 5| Step: 10
Training loss: 0.3330074657091589
Validation loss: 2.150219271716244

Epoch: 394| Step: 0
Training loss: 0.23575410409815756
Validation loss: 2.147861725292195

Epoch: 5| Step: 1
Training loss: 0.22144865188597407
Validation loss: 2.172458359344167

Epoch: 5| Step: 2
Training loss: 0.2980935036517956
Validation loss: 2.1558109779932937

Epoch: 5| Step: 3
Training loss: 0.3875123368114471
Validation loss: 2.1436995966600048

Epoch: 5| Step: 4
Training loss: 0.2999988635359537
Validation loss: 2.1839314301519854

Epoch: 5| Step: 5
Training loss: 0.2996383603236151
Validation loss: 2.1668927234101227

Epoch: 5| Step: 6
Training loss: 0.37538544396229934
Validation loss: 2.14343538060899

Epoch: 5| Step: 7
Training loss: 0.31693778896299807
Validation loss: 2.133641993957902

Epoch: 5| Step: 8
Training loss: 0.3178281857643465
Validation loss: 2.126810504772129

Epoch: 5| Step: 9
Training loss: 0.2664891239929674
Validation loss: 2.106816348598468

Epoch: 5| Step: 10
Training loss: 0.25260028967225356
Validation loss: 2.114310400084625

Epoch: 395| Step: 0
Training loss: 0.3238564730799621
Validation loss: 2.1012168655251933

Epoch: 5| Step: 1
Training loss: 0.18150610711132256
Validation loss: 2.097213336602319

Epoch: 5| Step: 2
Training loss: 0.25339115419912983
Validation loss: 2.067279891447707

Epoch: 5| Step: 3
Training loss: 0.34557560007202887
Validation loss: 2.111979218053278

Epoch: 5| Step: 4
Training loss: 0.34968349800512954
Validation loss: 2.0886193368081356

Epoch: 5| Step: 5
Training loss: 0.28576967807239717
Validation loss: 2.0994856386385146

Epoch: 5| Step: 6
Training loss: 0.3069834887991316
Validation loss: 2.1028693370764726

Epoch: 5| Step: 7
Training loss: 0.2205838412777517
Validation loss: 2.0897592988468325

Epoch: 5| Step: 8
Training loss: 0.252166332552458
Validation loss: 2.0987735294310377

Epoch: 5| Step: 9
Training loss: 0.46659945858352914
Validation loss: 2.1897788909062363

Epoch: 5| Step: 10
Training loss: 0.1624405247713798
Validation loss: 2.1495309443015773

Epoch: 396| Step: 0
Training loss: 0.2826980691258556
Validation loss: 2.132621469604173

Epoch: 5| Step: 1
Training loss: 0.30533205227439103
Validation loss: 2.1393772204457875

Epoch: 5| Step: 2
Training loss: 0.476800577698428
Validation loss: 2.127607325220203

Epoch: 5| Step: 3
Training loss: 0.20196419764846033
Validation loss: 2.1100327013696356

Epoch: 5| Step: 4
Training loss: 0.30947975735568944
Validation loss: 2.0973944562604863

Epoch: 5| Step: 5
Training loss: 0.3158901503046555
Validation loss: 2.1032329141631476

Epoch: 5| Step: 6
Training loss: 0.20227038809957512
Validation loss: 2.120655854089687

Epoch: 5| Step: 7
Training loss: 0.3048171354492401
Validation loss: 2.0855505621555976

Epoch: 5| Step: 8
Training loss: 0.22611947976307262
Validation loss: 2.1170045585711317

Epoch: 5| Step: 9
Training loss: 0.2619366948236657
Validation loss: 2.111129915207742

Epoch: 5| Step: 10
Training loss: 0.20240349274253694
Validation loss: 2.034110142674133

Epoch: 397| Step: 0
Training loss: 0.35121471368632595
Validation loss: 2.1274388690480066

Epoch: 5| Step: 1
Training loss: 0.339635171132125
Validation loss: 2.1244568718807613

Epoch: 5| Step: 2
Training loss: 0.24121812663002085
Validation loss: 2.084027128264187

Epoch: 5| Step: 3
Training loss: 0.2973797547736758
Validation loss: 2.1124953094243946

Epoch: 5| Step: 4
Training loss: 0.35515868109337984
Validation loss: 2.134350258032451

Epoch: 5| Step: 5
Training loss: 0.34784425516822687
Validation loss: 2.139596240231998

Epoch: 5| Step: 6
Training loss: 0.3023339237913074
Validation loss: 2.087331900246047

Epoch: 5| Step: 7
Training loss: 0.2381165200823645
Validation loss: 2.151541285220677

Epoch: 5| Step: 8
Training loss: 0.16423626054130175
Validation loss: 2.135761763937526

Epoch: 5| Step: 9
Training loss: 0.24579431088054482
Validation loss: 2.1397367436457477

Epoch: 5| Step: 10
Training loss: 0.22370686200470938
Validation loss: 2.1502663121907672

Epoch: 398| Step: 0
Training loss: 0.230749726760781
Validation loss: 2.1476063434865322

Epoch: 5| Step: 1
Training loss: 0.1786635184825408
Validation loss: 2.1580521333582214

Epoch: 5| Step: 2
Training loss: 0.39442228946604324
Validation loss: 2.0996487167423323

Epoch: 5| Step: 3
Training loss: 0.23356143893806525
Validation loss: 2.0989270000418814

Epoch: 5| Step: 4
Training loss: 0.25014232518113166
Validation loss: 2.1354470733790767

Epoch: 5| Step: 5
Training loss: 0.26845731877449985
Validation loss: 2.1224052686171406

Epoch: 5| Step: 6
Training loss: 0.3688961208298796
Validation loss: 2.138934861707322

Epoch: 5| Step: 7
Training loss: 0.29521289891679076
Validation loss: 2.1156546497949855

Epoch: 5| Step: 8
Training loss: 0.36578492880971086
Validation loss: 2.130973023577327

Epoch: 5| Step: 9
Training loss: 0.3056663293723974
Validation loss: 2.136567499935142

Epoch: 5| Step: 10
Training loss: 0.34599458940153643
Validation loss: 2.1274105926880305

Epoch: 399| Step: 0
Training loss: 0.25358993193642604
Validation loss: 2.1639405707789843

Epoch: 5| Step: 1
Training loss: 0.38635095773768013
Validation loss: 2.12332971620122

Epoch: 5| Step: 2
Training loss: 0.14935235388525625
Validation loss: 2.1477771532503898

Epoch: 5| Step: 3
Training loss: 0.3548338743487621
Validation loss: 2.1063124123717247

Epoch: 5| Step: 4
Training loss: 0.293940369827436
Validation loss: 2.091647748008129

Epoch: 5| Step: 5
Training loss: 0.32477417445268375
Validation loss: 2.0850168608209496

Epoch: 5| Step: 6
Training loss: 0.27456685221292476
Validation loss: 2.082252929450627

Epoch: 5| Step: 7
Training loss: 0.4220517106306146
Validation loss: 2.0769839115074356

Epoch: 5| Step: 8
Training loss: 0.16994241064222254
Validation loss: 2.1179911501855075

Epoch: 5| Step: 9
Training loss: 0.18619222343295108
Validation loss: 2.132455281359775

Epoch: 5| Step: 10
Training loss: 0.4235496836909127
Validation loss: 2.123373605390318

Epoch: 400| Step: 0
Training loss: 0.3150599057136733
Validation loss: 2.135944318272507

Epoch: 5| Step: 1
Training loss: 0.2918451123792475
Validation loss: 2.1197685695370576

Epoch: 5| Step: 2
Training loss: 0.1889050608456323
Validation loss: 2.1382148215710246

Epoch: 5| Step: 3
Training loss: 0.292951583359361
Validation loss: 2.1413752617792374

Epoch: 5| Step: 4
Training loss: 0.29033959998290537
Validation loss: 2.129443194121417

Epoch: 5| Step: 5
Training loss: 0.1498615694041468
Validation loss: 2.094218984431819

Epoch: 5| Step: 6
Training loss: 0.261757150366543
Validation loss: 2.1208919626397744

Epoch: 5| Step: 7
Training loss: 0.19942685085318615
Validation loss: 2.0781907475140677

Epoch: 5| Step: 8
Training loss: 0.28213671141668845
Validation loss: 2.0868579344984126

Epoch: 5| Step: 9
Training loss: 0.4708939952791123
Validation loss: 2.108780376402445

Epoch: 5| Step: 10
Training loss: 0.35096008822540425
Validation loss: 2.1220655659299816

Epoch: 401| Step: 0
Training loss: 0.20990585669224682
Validation loss: 2.127112166509096

Epoch: 5| Step: 1
Training loss: 0.3143514504343243
Validation loss: 2.089891402389683

Epoch: 5| Step: 2
Training loss: 0.15556108474011035
Validation loss: 2.118542549106551

Epoch: 5| Step: 3
Training loss: 0.19742160711055162
Validation loss: 2.114048985531736

Epoch: 5| Step: 4
Training loss: 0.22031342864686299
Validation loss: 2.1159160864841926

Epoch: 5| Step: 5
Training loss: 0.2264189429769516
Validation loss: 2.1046560659119025

Epoch: 5| Step: 6
Training loss: 0.20796629442102268
Validation loss: 2.0853526636835595

Epoch: 5| Step: 7
Training loss: 0.2902365118387044
Validation loss: 2.149109294788035

Epoch: 5| Step: 8
Training loss: 0.3798497438134418
Validation loss: 2.07046306091275

Epoch: 5| Step: 9
Training loss: 0.4071653397825161
Validation loss: 2.1006563789374106

Epoch: 5| Step: 10
Training loss: 0.38745870985499703
Validation loss: 2.0724552129632983

Epoch: 402| Step: 0
Training loss: 0.34013233866514997
Validation loss: 2.1108159335138965

Epoch: 5| Step: 1
Training loss: 0.275995995984024
Validation loss: 2.079132940357611

Epoch: 5| Step: 2
Training loss: 0.35474569540658296
Validation loss: 2.0681558971180642

Epoch: 5| Step: 3
Training loss: 0.1913574409533523
Validation loss: 2.0776654698476706

Epoch: 5| Step: 4
Training loss: 0.25217645195510574
Validation loss: 2.114580847181379

Epoch: 5| Step: 5
Training loss: 0.18602858804637024
Validation loss: 2.0631389044744153

Epoch: 5| Step: 6
Training loss: 0.21225965245071515
Validation loss: 2.1050374245648293

Epoch: 5| Step: 7
Training loss: 0.28035845115163716
Validation loss: 2.1164462906528505

Epoch: 5| Step: 8
Training loss: 0.27159724187795337
Validation loss: 2.1362693631851903

Epoch: 5| Step: 9
Training loss: 0.3434697439245115
Validation loss: 2.068713821636577

Epoch: 5| Step: 10
Training loss: 0.3122215580237912
Validation loss: 2.1380135073913564

Epoch: 403| Step: 0
Training loss: 0.285420151965355
Validation loss: 2.179478201019171

Epoch: 5| Step: 1
Training loss: 0.12845020107249466
Validation loss: 2.138924875885783

Epoch: 5| Step: 2
Training loss: 0.29365848728929944
Validation loss: 2.1080672950053763

Epoch: 5| Step: 3
Training loss: 0.25521025689366794
Validation loss: 2.145039556652815

Epoch: 5| Step: 4
Training loss: 0.17236748493028697
Validation loss: 2.1197534429566773

Epoch: 5| Step: 5
Training loss: 0.370741345572729
Validation loss: 2.0971537356458496

Epoch: 5| Step: 6
Training loss: 0.3097520890230882
Validation loss: 2.143323263158298

Epoch: 5| Step: 7
Training loss: 0.23963215406540864
Validation loss: 2.087769911054563

Epoch: 5| Step: 8
Training loss: 0.3874365570061806
Validation loss: 2.1279621548820975

Epoch: 5| Step: 9
Training loss: 0.21327917705828026
Validation loss: 2.102670882526724

Epoch: 5| Step: 10
Training loss: 0.29555002479578935
Validation loss: 2.1516051583904736

Epoch: 404| Step: 0
Training loss: 0.22556849820984212
Validation loss: 2.078943940402

Epoch: 5| Step: 1
Training loss: 0.24747661309094662
Validation loss: 2.1170946798709083

Epoch: 5| Step: 2
Training loss: 0.37198561858378193
Validation loss: 2.0717990212259374

Epoch: 5| Step: 3
Training loss: 0.2486541253459731
Validation loss: 2.1456600477254715

Epoch: 5| Step: 4
Training loss: 0.31042017241339537
Validation loss: 2.1101381332013927

Epoch: 5| Step: 5
Training loss: 0.16070064040188758
Validation loss: 2.092573275710721

Epoch: 5| Step: 6
Training loss: 0.3735479016093047
Validation loss: 2.0711224263208527

Epoch: 5| Step: 7
Training loss: 0.2833330842793062
Validation loss: 2.06846150180181

Epoch: 5| Step: 8
Training loss: 0.251265659888074
Validation loss: 2.1144770978421197

Epoch: 5| Step: 9
Training loss: 0.27215342789081537
Validation loss: 2.1045659710912177

Epoch: 5| Step: 10
Training loss: 0.1331270504063767
Validation loss: 2.148442558215499

Epoch: 405| Step: 0
Training loss: 0.11936693897042928
Validation loss: 2.1174870064894122

Epoch: 5| Step: 1
Training loss: 0.24079975031108283
Validation loss: 2.13772920915854

Epoch: 5| Step: 2
Training loss: 0.1434742189502079
Validation loss: 2.1107021287612824

Epoch: 5| Step: 3
Training loss: 0.3321714778312621
Validation loss: 2.12824881514824

Epoch: 5| Step: 4
Training loss: 0.2710429383076289
Validation loss: 2.110505169933841

Epoch: 5| Step: 5
Training loss: 0.3062995058061621
Validation loss: 2.147758499196929

Epoch: 5| Step: 6
Training loss: 0.17605356210569412
Validation loss: 2.1160062704981826

Epoch: 5| Step: 7
Training loss: 0.20145921648444048
Validation loss: 2.1360739039928913

Epoch: 5| Step: 8
Training loss: 0.34863176532662893
Validation loss: 2.1315171066651164

Epoch: 5| Step: 9
Training loss: 0.25937570261572845
Validation loss: 2.1306523821187366

Epoch: 5| Step: 10
Training loss: 0.46124323710727594
Validation loss: 2.115412454732419

Epoch: 406| Step: 0
Training loss: 0.13047236534637396
Validation loss: 2.0921979847653676

Epoch: 5| Step: 1
Training loss: 0.197017381287385
Validation loss: 2.113861975590323

Epoch: 5| Step: 2
Training loss: 0.28484371773305805
Validation loss: 2.1064115951904774

Epoch: 5| Step: 3
Training loss: 0.17626623430629476
Validation loss: 2.101566282214727

Epoch: 5| Step: 4
Training loss: 0.2718815128598657
Validation loss: 2.130900206678963

Epoch: 5| Step: 5
Training loss: 0.3141011465786468
Validation loss: 2.1019599917716416

Epoch: 5| Step: 6
Training loss: 0.29146378846524834
Validation loss: 2.099846109378435

Epoch: 5| Step: 7
Training loss: 0.42096647699498657
Validation loss: 2.078722338487322

Epoch: 5| Step: 8
Training loss: 0.33495864644949225
Validation loss: 2.068253974545648

Epoch: 5| Step: 9
Training loss: 0.19339049695717977
Validation loss: 2.065029117526231

Epoch: 5| Step: 10
Training loss: 0.264836487346983
Validation loss: 2.1128635292000166

Epoch: 407| Step: 0
Training loss: 0.1596959640738215
Validation loss: 2.1109892022062633

Epoch: 5| Step: 1
Training loss: 0.35503973590737864
Validation loss: 2.1061147247211407

Epoch: 5| Step: 2
Training loss: 0.4025821535015144
Validation loss: 2.109062214171151

Epoch: 5| Step: 3
Training loss: 0.21070009576630555
Validation loss: 2.139942747597462

Epoch: 5| Step: 4
Training loss: 0.270295634873673
Validation loss: 2.138866217307106

Epoch: 5| Step: 5
Training loss: 0.23434956730500894
Validation loss: 2.1419646769652894

Epoch: 5| Step: 6
Training loss: 0.36986521092540126
Validation loss: 2.125529061725135

Epoch: 5| Step: 7
Training loss: 0.192578927400167
Validation loss: 2.111407304750786

Epoch: 5| Step: 8
Training loss: 0.21604820233455477
Validation loss: 2.072971112216524

Epoch: 5| Step: 9
Training loss: 0.2066021376825564
Validation loss: 2.1153239324196944

Epoch: 5| Step: 10
Training loss: 0.24292311929870028
Validation loss: 2.082948201072099

Epoch: 408| Step: 0
Training loss: 0.22619753248981547
Validation loss: 2.097614239558278

Epoch: 5| Step: 1
Training loss: 0.11633186700027393
Validation loss: 2.1048813902269963

Epoch: 5| Step: 2
Training loss: 0.3540957838071941
Validation loss: 2.081227521335534

Epoch: 5| Step: 3
Training loss: 0.24424216638378343
Validation loss: 2.103093236446174

Epoch: 5| Step: 4
Training loss: 0.26404113344505165
Validation loss: 2.1190675968905444

Epoch: 5| Step: 5
Training loss: 0.10558431969185424
Validation loss: 2.137923991498015

Epoch: 5| Step: 6
Training loss: 0.3247751609057466
Validation loss: 2.123458445511499

Epoch: 5| Step: 7
Training loss: 0.3396836375005508
Validation loss: 2.1020438533561747

Epoch: 5| Step: 8
Training loss: 0.2104969811285334
Validation loss: 2.112232236535751

Epoch: 5| Step: 9
Training loss: 0.31640500197929744
Validation loss: 2.1183620724879053

Epoch: 5| Step: 10
Training loss: 0.3749031498138435
Validation loss: 2.108387694224848

Epoch: 409| Step: 0
Training loss: 0.1539182120965713
Validation loss: 2.105447695584591

Epoch: 5| Step: 1
Training loss: 0.3771822929496981
Validation loss: 2.1116816601196384

Epoch: 5| Step: 2
Training loss: 0.24367293765810807
Validation loss: 2.092082821061483

Epoch: 5| Step: 3
Training loss: 0.3040515547386897
Validation loss: 2.1004202768860325

Epoch: 5| Step: 4
Training loss: 0.3388426274350773
Validation loss: 2.123202355568787

Epoch: 5| Step: 5
Training loss: 0.24832536427914617
Validation loss: 2.1122219257276456

Epoch: 5| Step: 6
Training loss: 0.2176691498394482
Validation loss: 2.0355137591757066

Epoch: 5| Step: 7
Training loss: 0.23452698230354982
Validation loss: 2.066533455076754

Epoch: 5| Step: 8
Training loss: 0.3415233934845951
Validation loss: 2.0657552521826568

Epoch: 5| Step: 9
Training loss: 0.16882499092614098
Validation loss: 2.1200593229771303

Epoch: 5| Step: 10
Training loss: 0.36442731743438356
Validation loss: 2.071052161266787

Epoch: 410| Step: 0
Training loss: 0.2707320017639892
Validation loss: 2.1169939510047397

Epoch: 5| Step: 1
Training loss: 0.32946576078633355
Validation loss: 2.149592034605305

Epoch: 5| Step: 2
Training loss: 0.17751439073145447
Validation loss: 2.1106644870238234

Epoch: 5| Step: 3
Training loss: 0.3146171023810213
Validation loss: 2.124007239849869

Epoch: 5| Step: 4
Training loss: 0.1869806707121589
Validation loss: 2.1237544741201946

Epoch: 5| Step: 5
Training loss: 0.2558220260965805
Validation loss: 2.1159643578329335

Epoch: 5| Step: 6
Training loss: 0.15505813570696103
Validation loss: 2.1793140555017225

Epoch: 5| Step: 7
Training loss: 0.2762664233801834
Validation loss: 2.1450806251448036

Epoch: 5| Step: 8
Training loss: 0.3720036244138922
Validation loss: 2.129790073803074

Epoch: 5| Step: 9
Training loss: 0.2607254851631642
Validation loss: 2.1428940276396

Epoch: 5| Step: 10
Training loss: 0.3460623173615888
Validation loss: 2.137143709004395

Epoch: 411| Step: 0
Training loss: 0.25169012848225397
Validation loss: 2.125780195205109

Epoch: 5| Step: 1
Training loss: 0.17725535176796986
Validation loss: 2.111335204563564

Epoch: 5| Step: 2
Training loss: 0.10729671469482428
Validation loss: 2.0884471883499964

Epoch: 5| Step: 3
Training loss: 0.35303804373453285
Validation loss: 2.104784151711615

Epoch: 5| Step: 4
Training loss: 0.277189977757369
Validation loss: 2.089591210139357

Epoch: 5| Step: 5
Training loss: 0.16294659583760615
Validation loss: 2.1104162783983216

Epoch: 5| Step: 6
Training loss: 0.3521484366537
Validation loss: 2.0722704194518644

Epoch: 5| Step: 7
Training loss: 0.3455496625207824
Validation loss: 2.1045723626238058

Epoch: 5| Step: 8
Training loss: 0.3270864627267276
Validation loss: 2.078272199109141

Epoch: 5| Step: 9
Training loss: 0.24701420143070013
Validation loss: 2.1354579122198167

Epoch: 5| Step: 10
Training loss: 0.2566784713221689
Validation loss: 2.103639647735554

Epoch: 412| Step: 0
Training loss: 0.22736704959307474
Validation loss: 2.1263224168342303

Epoch: 5| Step: 1
Training loss: 0.35250081834968644
Validation loss: 2.088748493151447

Epoch: 5| Step: 2
Training loss: 0.19945546653499732
Validation loss: 2.138646730777216

Epoch: 5| Step: 3
Training loss: 0.21541354308240226
Validation loss: 2.117104569463644

Epoch: 5| Step: 4
Training loss: 0.23916058803159554
Validation loss: 2.089650299285303

Epoch: 5| Step: 5
Training loss: 0.295036533627202
Validation loss: 2.1367952360445277

Epoch: 5| Step: 6
Training loss: 0.4247136336335524
Validation loss: 2.134552973397837

Epoch: 5| Step: 7
Training loss: 0.21601605924041864
Validation loss: 2.0890988754897633

Epoch: 5| Step: 8
Training loss: 0.2526135918081306
Validation loss: 2.1112964296831933

Epoch: 5| Step: 9
Training loss: 0.3159834898463891
Validation loss: 2.15288533775538

Epoch: 5| Step: 10
Training loss: 0.1924827335559249
Validation loss: 2.1453615449103203

Epoch: 413| Step: 0
Training loss: 0.21609996783950475
Validation loss: 2.142943151396466

Epoch: 5| Step: 1
Training loss: 0.30956826675653654
Validation loss: 2.096886809995125

Epoch: 5| Step: 2
Training loss: 0.14091005838441684
Validation loss: 2.0927436116793716

Epoch: 5| Step: 3
Training loss: 0.2302288002449866
Validation loss: 2.08733067758232

Epoch: 5| Step: 4
Training loss: 0.23912706500556138
Validation loss: 2.0765422974906853

Epoch: 5| Step: 5
Training loss: 0.2142552465182607
Validation loss: 2.0988675668382335

Epoch: 5| Step: 6
Training loss: 0.24916605138117967
Validation loss: 2.1181212272887975

Epoch: 5| Step: 7
Training loss: 0.3886065404218861
Validation loss: 2.107158510885483

Epoch: 5| Step: 8
Training loss: 0.2825556226001813
Validation loss: 2.09663624950641

Epoch: 5| Step: 9
Training loss: 0.24247013796716235
Validation loss: 2.093246317340265

Epoch: 5| Step: 10
Training loss: 0.25726572490265054
Validation loss: 2.072839371176981

Epoch: 414| Step: 0
Training loss: 0.3022873808681624
Validation loss: 2.077598815420298

Epoch: 5| Step: 1
Training loss: 0.18273627126491854
Validation loss: 2.0834614193416905

Epoch: 5| Step: 2
Training loss: 0.29424475945381584
Validation loss: 2.1307378474302014

Epoch: 5| Step: 3
Training loss: 0.18328520028295558
Validation loss: 2.109562318689065

Epoch: 5| Step: 4
Training loss: 0.23183165870066702
Validation loss: 2.1302683523170076

Epoch: 5| Step: 5
Training loss: 0.3727598634063437
Validation loss: 2.142339908271581

Epoch: 5| Step: 6
Training loss: 0.27588409148888143
Validation loss: 2.1288291878820824

Epoch: 5| Step: 7
Training loss: 0.301936149366734
Validation loss: 2.138670961585182

Epoch: 5| Step: 8
Training loss: 0.24084486577087494
Validation loss: 2.143574404274845

Epoch: 5| Step: 9
Training loss: 0.16017764809177237
Validation loss: 2.115913853809984

Epoch: 5| Step: 10
Training loss: 0.31190279878786686
Validation loss: 2.1211433339129173

Epoch: 415| Step: 0
Training loss: 0.27141292921773835
Validation loss: 2.113012495286329

Epoch: 5| Step: 1
Training loss: 0.23933523832667006
Validation loss: 2.1282520696130103

Epoch: 5| Step: 2
Training loss: 0.19165716463011007
Validation loss: 2.1272532962404966

Epoch: 5| Step: 3
Training loss: 0.22605569652373705
Validation loss: 2.1253006400939602

Epoch: 5| Step: 4
Training loss: 0.16844592956228957
Validation loss: 2.0965042707638926

Epoch: 5| Step: 5
Training loss: 0.3110052360863572
Validation loss: 2.124839044322735

Epoch: 5| Step: 6
Training loss: 0.3865065522286227
Validation loss: 2.145945195947014

Epoch: 5| Step: 7
Training loss: 0.2925135955136997
Validation loss: 2.117378946372966

Epoch: 5| Step: 8
Training loss: 0.347639447781299
Validation loss: 2.152737988163703

Epoch: 5| Step: 9
Training loss: 0.26621286471278716
Validation loss: 2.1406199221142486

Epoch: 5| Step: 10
Training loss: 0.15221705425855223
Validation loss: 2.119525876333295

Epoch: 416| Step: 0
Training loss: 0.2770996362627327
Validation loss: 2.130698570774777

Epoch: 5| Step: 1
Training loss: 0.16850997535102427
Validation loss: 2.138286476998536

Epoch: 5| Step: 2
Training loss: 0.2759090710918179
Validation loss: 2.1388785987879575

Epoch: 5| Step: 3
Training loss: 0.3870359911299061
Validation loss: 2.1659619137279544

Epoch: 5| Step: 4
Training loss: 0.2617219526180347
Validation loss: 2.134815980556614

Epoch: 5| Step: 5
Training loss: 0.2410613920756509
Validation loss: 2.152682590949391

Epoch: 5| Step: 6
Training loss: 0.24430397672367735
Validation loss: 2.1040893763046795

Epoch: 5| Step: 7
Training loss: 0.2611279723261666
Validation loss: 2.1284946904468134

Epoch: 5| Step: 8
Training loss: 0.15126761576238285
Validation loss: 2.10676654066007

Epoch: 5| Step: 9
Training loss: 0.24789590070744785
Validation loss: 2.1232822813467664

Epoch: 5| Step: 10
Training loss: 0.2824990300355987
Validation loss: 2.1341920375980443

Epoch: 417| Step: 0
Training loss: 0.18516909639241977
Validation loss: 2.1289232828166917

Epoch: 5| Step: 1
Training loss: 0.27811607764430446
Validation loss: 2.1238218464115866

Epoch: 5| Step: 2
Training loss: 0.3208191516557493
Validation loss: 2.1170802104912783

Epoch: 5| Step: 3
Training loss: 0.11020892976952217
Validation loss: 2.126270169136915

Epoch: 5| Step: 4
Training loss: 0.2650864414717222
Validation loss: 2.1019360311399655

Epoch: 5| Step: 5
Training loss: 0.1363036871596966
Validation loss: 2.1388951620528345

Epoch: 5| Step: 6
Training loss: 0.3581660502142828
Validation loss: 2.128543747257755

Epoch: 5| Step: 7
Training loss: 0.1777588754053041
Validation loss: 2.1368721164575377

Epoch: 5| Step: 8
Training loss: 0.3366599520617217
Validation loss: 2.1376685737553554

Epoch: 5| Step: 9
Training loss: 0.19715178386885893
Validation loss: 2.1306924260615907

Epoch: 5| Step: 10
Training loss: 0.297829448942169
Validation loss: 2.1380223745398195

Epoch: 418| Step: 0
Training loss: 0.143570373612363
Validation loss: 2.1381513457247596

Epoch: 5| Step: 1
Training loss: 0.21639831094604878
Validation loss: 2.126075696758506

Epoch: 5| Step: 2
Training loss: 0.29021711696076175
Validation loss: 2.098162168126141

Epoch: 5| Step: 3
Training loss: 0.20465408263527424
Validation loss: 2.157206264591186

Epoch: 5| Step: 4
Training loss: 0.19362091909840098
Validation loss: 2.1330391262626147

Epoch: 5| Step: 5
Training loss: 0.4162865772729747
Validation loss: 2.125606068002508

Epoch: 5| Step: 6
Training loss: 0.24590639521150595
Validation loss: 2.1346479815670625

Epoch: 5| Step: 7
Training loss: 0.17996638879950913
Validation loss: 2.1497221750280366

Epoch: 5| Step: 8
Training loss: 0.27084921215654745
Validation loss: 2.1183326341815008

Epoch: 5| Step: 9
Training loss: 0.29805581015696164
Validation loss: 2.1086217461270285

Epoch: 5| Step: 10
Training loss: 0.15253888983722835
Validation loss: 2.17105421195529

Epoch: 419| Step: 0
Training loss: 0.3837891013264333
Validation loss: 2.1307067440460576

Epoch: 5| Step: 1
Training loss: 0.27163974514967687
Validation loss: 2.118975409599153

Epoch: 5| Step: 2
Training loss: 0.22910448155409394
Validation loss: 2.068037484275392

Epoch: 5| Step: 3
Training loss: 0.23202651722252382
Validation loss: 2.079916334410025

Epoch: 5| Step: 4
Training loss: 0.11150930117988009
Validation loss: 2.1082642195375105

Epoch: 5| Step: 5
Training loss: 0.15188457909151154
Validation loss: 2.0775295875394795

Epoch: 5| Step: 6
Training loss: 0.23468670780134532
Validation loss: 2.1249069613333527

Epoch: 5| Step: 7
Training loss: 0.12847899665741888
Validation loss: 2.1241927619328593

Epoch: 5| Step: 8
Training loss: 0.3478130030050008
Validation loss: 2.079941281459301

Epoch: 5| Step: 9
Training loss: 0.23962682954580294
Validation loss: 2.1320899912449836

Epoch: 5| Step: 10
Training loss: 0.25069757830462425
Validation loss: 2.1605325490627676

Epoch: 420| Step: 0
Training loss: 0.32728833296203275
Validation loss: 2.1066604606235337

Epoch: 5| Step: 1
Training loss: 0.17815145873268295
Validation loss: 2.1523947805648564

Epoch: 5| Step: 2
Training loss: 0.3348944350530326
Validation loss: 2.153597587394917

Epoch: 5| Step: 3
Training loss: 0.33844536242946205
Validation loss: 2.153558537188714

Epoch: 5| Step: 4
Training loss: 0.1979069435508643
Validation loss: 2.1228351363092726

Epoch: 5| Step: 5
Training loss: 0.18397644414634287
Validation loss: 2.1636044959498375

Epoch: 5| Step: 6
Training loss: 0.3279161469763613
Validation loss: 2.1352996790124568

Epoch: 5| Step: 7
Training loss: 0.29969949771863197
Validation loss: 2.137472341478826

Epoch: 5| Step: 8
Training loss: 0.1259267841730733
Validation loss: 2.10500993606989

Epoch: 5| Step: 9
Training loss: 0.3679484132949969
Validation loss: 2.115757681020758

Epoch: 5| Step: 10
Training loss: 0.14558275584190233
Validation loss: 2.1000591444807464

Epoch: 421| Step: 0
Training loss: 0.14177103752996953
Validation loss: 2.0738068086152053

Epoch: 5| Step: 1
Training loss: 0.2730301956954532
Validation loss: 2.106100119044495

Epoch: 5| Step: 2
Training loss: 0.3164960239350483
Validation loss: 2.0868291475817946

Epoch: 5| Step: 3
Training loss: 0.25755829271649106
Validation loss: 2.076482098278114

Epoch: 5| Step: 4
Training loss: 0.2769988427137995
Validation loss: 2.084621529521602

Epoch: 5| Step: 5
Training loss: 0.3612690232887869
Validation loss: 2.0806466241945714

Epoch: 5| Step: 6
Training loss: 0.2781174572982686
Validation loss: 2.0326529410556646

Epoch: 5| Step: 7
Training loss: 0.33617244311725075
Validation loss: 2.062043974558075

Epoch: 5| Step: 8
Training loss: 0.21293497061171876
Validation loss: 2.0628744862430395

Epoch: 5| Step: 9
Training loss: 0.2021065083386317
Validation loss: 2.041151558958074

Epoch: 5| Step: 10
Training loss: 0.21967631295264273
Validation loss: 2.0711283108258502

Epoch: 422| Step: 0
Training loss: 0.2503762840651344
Validation loss: 2.0568267850511077

Epoch: 5| Step: 1
Training loss: 0.22921507316922035
Validation loss: 2.0903232579826447

Epoch: 5| Step: 2
Training loss: 0.24476076330086333
Validation loss: 2.095998687555782

Epoch: 5| Step: 3
Training loss: 0.22070380860619465
Validation loss: 2.1251896406240554

Epoch: 5| Step: 4
Training loss: 0.2920802312179226
Validation loss: 2.09262452159824

Epoch: 5| Step: 5
Training loss: 0.12596900680712653
Validation loss: 2.122378050664654

Epoch: 5| Step: 6
Training loss: 0.33842255502110535
Validation loss: 2.114815511363094

Epoch: 5| Step: 7
Training loss: 0.27979434332818237
Validation loss: 2.1275989737598993

Epoch: 5| Step: 8
Training loss: 0.3248346407825515
Validation loss: 2.1347193550116956

Epoch: 5| Step: 9
Training loss: 0.18807625631766955
Validation loss: 2.147956394833791

Epoch: 5| Step: 10
Training loss: 0.22265899388814367
Validation loss: 2.1873429061805636

Epoch: 423| Step: 0
Training loss: 0.2692551096685493
Validation loss: 2.157542354584506

Epoch: 5| Step: 1
Training loss: 0.1406157079911616
Validation loss: 2.1426755196305334

Epoch: 5| Step: 2
Training loss: 0.35454203777956567
Validation loss: 2.1562990317076287

Epoch: 5| Step: 3
Training loss: 0.30952364211767863
Validation loss: 2.1343579035368694

Epoch: 5| Step: 4
Training loss: 0.22420790908604143
Validation loss: 2.169780639436415

Epoch: 5| Step: 5
Training loss: 0.31100220558098907
Validation loss: 2.1194231843278764

Epoch: 5| Step: 6
Training loss: 0.3059098471241925
Validation loss: 2.1268873597881384

Epoch: 5| Step: 7
Training loss: 0.11115030677281601
Validation loss: 2.1300127910619144

Epoch: 5| Step: 8
Training loss: 0.2198161811325143
Validation loss: 2.141017298525992

Epoch: 5| Step: 9
Training loss: 0.13682239554758185
Validation loss: 2.143358642170374

Epoch: 5| Step: 10
Training loss: 0.15216213796336403
Validation loss: 2.1051329683759565

Epoch: 424| Step: 0
Training loss: 0.18348457255592812
Validation loss: 2.1018597200957037

Epoch: 5| Step: 1
Training loss: 0.18511937735993564
Validation loss: 2.1025783945379106

Epoch: 5| Step: 2
Training loss: 0.24997035238184231
Validation loss: 2.1313409727361754

Epoch: 5| Step: 3
Training loss: 0.24169291478422822
Validation loss: 2.0940278832655674

Epoch: 5| Step: 4
Training loss: 0.16348016796443063
Validation loss: 2.083663721856516

Epoch: 5| Step: 5
Training loss: 0.31070905325348636
Validation loss: 2.0685242458366746

Epoch: 5| Step: 6
Training loss: 0.2613804039316692
Validation loss: 2.118458486884771

Epoch: 5| Step: 7
Training loss: 0.316639072801243
Validation loss: 2.0969872473312248

Epoch: 5| Step: 8
Training loss: 0.34904881509441243
Validation loss: 2.063460729433516

Epoch: 5| Step: 9
Training loss: 0.11589758966211025
Validation loss: 2.1035425736273097

Epoch: 5| Step: 10
Training loss: 0.142293037557584
Validation loss: 2.111213513027853

Epoch: 425| Step: 0
Training loss: 0.20425316322916826
Validation loss: 2.1245344389116148

Epoch: 5| Step: 1
Training loss: 0.2672615127224808
Validation loss: 2.078481395211163

Epoch: 5| Step: 2
Training loss: 0.10652660625348373
Validation loss: 2.1222328057490794

Epoch: 5| Step: 3
Training loss: 0.25614088165897714
Validation loss: 2.1269107217257974

Epoch: 5| Step: 4
Training loss: 0.15200419364574408
Validation loss: 2.0926797997169597

Epoch: 5| Step: 5
Training loss: 0.18728880113807733
Validation loss: 2.116282059338511

Epoch: 5| Step: 6
Training loss: 0.19511404445434544
Validation loss: 2.110566882105953

Epoch: 5| Step: 7
Training loss: 0.19515405904121863
Validation loss: 2.113246514762755

Epoch: 5| Step: 8
Training loss: 0.11272879835229117
Validation loss: 2.0909963875253545

Epoch: 5| Step: 9
Training loss: 0.452870396084486
Validation loss: 2.0870515334879904

Epoch: 5| Step: 10
Training loss: 0.28944438761549685
Validation loss: 2.1092250094606473

Epoch: 426| Step: 0
Training loss: 0.22741206148938048
Validation loss: 2.1232362620400624

Epoch: 5| Step: 1
Training loss: 0.32918157086049193
Validation loss: 2.114632864209892

Epoch: 5| Step: 2
Training loss: 0.32984986397603233
Validation loss: 2.098160265703945

Epoch: 5| Step: 3
Training loss: 0.21772024762407968
Validation loss: 2.1236504299287198

Epoch: 5| Step: 4
Training loss: 0.15177044834274897
Validation loss: 2.092635218697349

Epoch: 5| Step: 5
Training loss: 0.28033651246953084
Validation loss: 2.1072733628692393

Epoch: 5| Step: 6
Training loss: 0.16128289140465854
Validation loss: 2.078721872925169

Epoch: 5| Step: 7
Training loss: 0.2285909691522172
Validation loss: 2.097592242220994

Epoch: 5| Step: 8
Training loss: 0.2360365779582946
Validation loss: 2.1045270562640996

Epoch: 5| Step: 9
Training loss: 0.19192868576692101
Validation loss: 2.1025468191072902

Epoch: 5| Step: 10
Training loss: 0.22607694587133745
Validation loss: 2.1206701382912803

Epoch: 427| Step: 0
Training loss: 0.23168339133497795
Validation loss: 2.139739794032401

Epoch: 5| Step: 1
Training loss: 0.15467347288592487
Validation loss: 2.1175128051296634

Epoch: 5| Step: 2
Training loss: 0.2180476579067782
Validation loss: 2.1060115151068857

Epoch: 5| Step: 3
Training loss: 0.2304818505265356
Validation loss: 2.071876657235632

Epoch: 5| Step: 4
Training loss: 0.1480773836471324
Validation loss: 2.092213652129346

Epoch: 5| Step: 5
Training loss: 0.3175932318741298
Validation loss: 2.098004537372458

Epoch: 5| Step: 6
Training loss: 0.23797804662137056
Validation loss: 2.089538153806505

Epoch: 5| Step: 7
Training loss: 0.2567930729709039
Validation loss: 2.0929739329120753

Epoch: 5| Step: 8
Training loss: 0.42276481108547115
Validation loss: 2.092841766702601

Epoch: 5| Step: 9
Training loss: 0.15084502694692095
Validation loss: 2.0576041749981497

Epoch: 5| Step: 10
Training loss: 0.1932765128095596
Validation loss: 2.095751144473279

Epoch: 428| Step: 0
Training loss: 0.22356085473325163
Validation loss: 2.099960971553594

Epoch: 5| Step: 1
Training loss: 0.20952648191552672
Validation loss: 2.0908412990250675

Epoch: 5| Step: 2
Training loss: 0.3208358606119236
Validation loss: 2.106137511273326

Epoch: 5| Step: 3
Training loss: 0.3545831400732163
Validation loss: 2.1124706454857916

Epoch: 5| Step: 4
Training loss: 0.23598158468715816
Validation loss: 2.134991315071993

Epoch: 5| Step: 5
Training loss: 0.2381791224261354
Validation loss: 2.1236650229440803

Epoch: 5| Step: 6
Training loss: 0.1529906914885296
Validation loss: 2.1324215353006353

Epoch: 5| Step: 7
Training loss: 0.29481376788635183
Validation loss: 2.161735311928941

Epoch: 5| Step: 8
Training loss: 0.12239762484138926
Validation loss: 2.117775946261399

Epoch: 5| Step: 9
Training loss: 0.31439894452303097
Validation loss: 2.1443247925939075

Epoch: 5| Step: 10
Training loss: 0.3362875600491687
Validation loss: 2.112562622726543

Epoch: 429| Step: 0
Training loss: 0.1906111903738566
Validation loss: 2.12655738810121

Epoch: 5| Step: 1
Training loss: 0.22406606060854056
Validation loss: 2.108997676133465

Epoch: 5| Step: 2
Training loss: 0.3054291672683268
Validation loss: 2.1368384215554483

Epoch: 5| Step: 3
Training loss: 0.3489826594836391
Validation loss: 2.097314835492637

Epoch: 5| Step: 4
Training loss: 0.2844880256730776
Validation loss: 2.1124185242425635

Epoch: 5| Step: 5
Training loss: 0.3109955814881775
Validation loss: 2.1007718942303666

Epoch: 5| Step: 6
Training loss: 0.18137063706104248
Validation loss: 2.1120788150946885

Epoch: 5| Step: 7
Training loss: 0.20745202256708728
Validation loss: 2.0771329036550874

Epoch: 5| Step: 8
Training loss: 0.2510204796272661
Validation loss: 2.1314396824898454

Epoch: 5| Step: 9
Training loss: 0.1805163733494007
Validation loss: 2.1051928944701075

Epoch: 5| Step: 10
Training loss: 0.1629492992504716
Validation loss: 2.1087472848361517

Epoch: 430| Step: 0
Training loss: 0.3092457366393525
Validation loss: 2.117769717447481

Epoch: 5| Step: 1
Training loss: 0.19180285955287307
Validation loss: 2.1264006324067126

Epoch: 5| Step: 2
Training loss: 0.15938319320749172
Validation loss: 2.110746751162731

Epoch: 5| Step: 3
Training loss: 0.19068606797714932
Validation loss: 2.09359804574537

Epoch: 5| Step: 4
Training loss: 0.23528496999151996
Validation loss: 2.0982937499752

Epoch: 5| Step: 5
Training loss: 0.13041093481841812
Validation loss: 2.1041982267245185

Epoch: 5| Step: 6
Training loss: 0.2931642134613319
Validation loss: 2.1060896787050103

Epoch: 5| Step: 7
Training loss: 0.24293556354713686
Validation loss: 2.124724539770719

Epoch: 5| Step: 8
Training loss: 0.21949677213574276
Validation loss: 2.1280345747739027

Epoch: 5| Step: 9
Training loss: 0.30993266514543505
Validation loss: 2.1238914085676526

Epoch: 5| Step: 10
Training loss: 0.2172305091975446
Validation loss: 2.1580945962220524

Epoch: 431| Step: 0
Training loss: 0.13945582250983393
Validation loss: 2.1395264913164396

Epoch: 5| Step: 1
Training loss: 0.2416825259831043
Validation loss: 2.156631823513113

Epoch: 5| Step: 2
Training loss: 0.3099950650229961
Validation loss: 2.1262192693649986

Epoch: 5| Step: 3
Training loss: 0.14116434143687404
Validation loss: 2.110951292337007

Epoch: 5| Step: 4
Training loss: 0.2917568317192039
Validation loss: 2.1619892245751324

Epoch: 5| Step: 5
Training loss: 0.15085406546432809
Validation loss: 2.1306903024195663

Epoch: 5| Step: 6
Training loss: 0.3772787752938453
Validation loss: 2.104095462856143

Epoch: 5| Step: 7
Training loss: 0.17078922596879967
Validation loss: 2.140347916661568

Epoch: 5| Step: 8
Training loss: 0.1701078712373787
Validation loss: 2.0843820463208016

Epoch: 5| Step: 9
Training loss: 0.184859296833351
Validation loss: 2.0995412868058527

Epoch: 5| Step: 10
Training loss: 0.2816594640010281
Validation loss: 2.108278527504652

Epoch: 432| Step: 0
Training loss: 0.27946093882406925
Validation loss: 2.086756270055849

Epoch: 5| Step: 1
Training loss: 0.36312803503531044
Validation loss: 2.067241648788116

Epoch: 5| Step: 2
Training loss: 0.18590532112562821
Validation loss: 2.0977732714216866

Epoch: 5| Step: 3
Training loss: 0.2507511269371974
Validation loss: 2.1015477138599454

Epoch: 5| Step: 4
Training loss: 0.13010555184387693
Validation loss: 2.116140932063709

Epoch: 5| Step: 5
Training loss: 0.09390693681754554
Validation loss: 2.1010490546892595

Epoch: 5| Step: 6
Training loss: 0.3950426733832113
Validation loss: 2.1424652948446528

Epoch: 5| Step: 7
Training loss: 0.1959109198719072
Validation loss: 2.07454159427654

Epoch: 5| Step: 8
Training loss: 0.15389679090603817
Validation loss: 2.1252424221269

Epoch: 5| Step: 9
Training loss: 0.1457408856098855
Validation loss: 2.087859906133563

Epoch: 5| Step: 10
Training loss: 0.13351328473302926
Validation loss: 2.0959890983376783

Epoch: 433| Step: 0
Training loss: 0.1505401846107261
Validation loss: 2.0916211026895586

Epoch: 5| Step: 1
Training loss: 0.30700513714117467
Validation loss: 2.1080613920016646

Epoch: 5| Step: 2
Training loss: 0.2746402717670965
Validation loss: 2.142128171338784

Epoch: 5| Step: 3
Training loss: 0.27566744371621404
Validation loss: 2.081168064321587

Epoch: 5| Step: 4
Training loss: 0.26212860866876786
Validation loss: 2.1020096922431337

Epoch: 5| Step: 5
Training loss: 0.13476910793945265
Validation loss: 2.1176671648463437

Epoch: 5| Step: 6
Training loss: 0.17121212100073172
Validation loss: 2.1008065992904084

Epoch: 5| Step: 7
Training loss: 0.13652443019085822
Validation loss: 2.1146904710968855

Epoch: 5| Step: 8
Training loss: 0.32156282721485213
Validation loss: 2.1040797398888293

Epoch: 5| Step: 9
Training loss: 0.11635828294007214
Validation loss: 2.1259267898412815

Epoch: 5| Step: 10
Training loss: 0.19775806940665078
Validation loss: 2.086900509120162

Epoch: 434| Step: 0
Training loss: 0.32613154407528244
Validation loss: 2.1008442394934788

Epoch: 5| Step: 1
Training loss: 0.13420401218044226
Validation loss: 2.1041272770003037

Epoch: 5| Step: 2
Training loss: 0.21431990830329067
Validation loss: 2.1138331850064973

Epoch: 5| Step: 3
Training loss: 0.20801053470746594
Validation loss: 2.1228981369354525

Epoch: 5| Step: 4
Training loss: 0.21069669223593762
Validation loss: 2.1193853104055047

Epoch: 5| Step: 5
Training loss: 0.22175548114797608
Validation loss: 2.101407396495799

Epoch: 5| Step: 6
Training loss: 0.3363396987075611
Validation loss: 2.1260018300441486

Epoch: 5| Step: 7
Training loss: 0.15810122563757478
Validation loss: 2.108155102362124

Epoch: 5| Step: 8
Training loss: 0.15874587078055827
Validation loss: 2.161589116512127

Epoch: 5| Step: 9
Training loss: 0.32030185821347307
Validation loss: 2.1329739897989137

Epoch: 5| Step: 10
Training loss: 0.21133760194805878
Validation loss: 2.0868068108205584

Epoch: 435| Step: 0
Training loss: 0.2301127545343065
Validation loss: 2.1269248590568917

Epoch: 5| Step: 1
Training loss: 0.2142508040527693
Validation loss: 2.0999672025276777

Epoch: 5| Step: 2
Training loss: 0.2588332228499662
Validation loss: 2.114378444925907

Epoch: 5| Step: 3
Training loss: 0.27330974591688795
Validation loss: 2.121524255620733

Epoch: 5| Step: 4
Training loss: 0.22566170679163355
Validation loss: 2.1057559665282475

Epoch: 5| Step: 5
Training loss: 0.23403777657840757
Validation loss: 2.0859583095145338

Epoch: 5| Step: 6
Training loss: 0.24941048556087725
Validation loss: 2.0507473387993276

Epoch: 5| Step: 7
Training loss: 0.08762549305690726
Validation loss: 2.089152038080392

Epoch: 5| Step: 8
Training loss: 0.2697453132536898
Validation loss: 2.0767267769210727

Epoch: 5| Step: 9
Training loss: 0.19816528670348105
Validation loss: 2.1018341239021874

Epoch: 5| Step: 10
Training loss: 0.13762368036654374
Validation loss: 2.0818128182836473

Epoch: 436| Step: 0
Training loss: 0.2563923242798487
Validation loss: 2.087699840670452

Epoch: 5| Step: 1
Training loss: 0.14310894096226226
Validation loss: 2.104795317146965

Epoch: 5| Step: 2
Training loss: 0.207233995453525
Validation loss: 2.147102619327777

Epoch: 5| Step: 3
Training loss: 0.18768041593283796
Validation loss: 2.1362204048822084

Epoch: 5| Step: 4
Training loss: 0.1905182656882828
Validation loss: 2.0889406338442136

Epoch: 5| Step: 5
Training loss: 0.14025259377763621
Validation loss: 2.127367796036731

Epoch: 5| Step: 6
Training loss: 0.33403391777355806
Validation loss: 2.1056115793779773

Epoch: 5| Step: 7
Training loss: 0.3080217153910466
Validation loss: 2.1259363947588317

Epoch: 5| Step: 8
Training loss: 0.24308411689627
Validation loss: 2.152007566455117

Epoch: 5| Step: 9
Training loss: 0.2588447223043136
Validation loss: 2.121236291108297

Epoch: 5| Step: 10
Training loss: 0.20299492852918224
Validation loss: 2.1246467655051195

Epoch: 437| Step: 0
Training loss: 0.3500400000943735
Validation loss: 2.116975726259319

Epoch: 5| Step: 1
Training loss: 0.2715391885872559
Validation loss: 2.1183895111625506

Epoch: 5| Step: 2
Training loss: 0.2267586335948499
Validation loss: 2.130090977789581

Epoch: 5| Step: 3
Training loss: 0.16018056103482542
Validation loss: 2.0850910102101676

Epoch: 5| Step: 4
Training loss: 0.26132043733108845
Validation loss: 2.1031081116763812

Epoch: 5| Step: 5
Training loss: 0.1640661159752679
Validation loss: 2.125689834903813

Epoch: 5| Step: 6
Training loss: 0.18536019219748373
Validation loss: 2.1024730536687346

Epoch: 5| Step: 7
Training loss: 0.20037763713367318
Validation loss: 2.1060475163458183

Epoch: 5| Step: 8
Training loss: 0.23943124829870616
Validation loss: 2.0839090581346404

Epoch: 5| Step: 9
Training loss: 0.2027873019771647
Validation loss: 2.091576634850316

Epoch: 5| Step: 10
Training loss: 0.2333750932582961
Validation loss: 2.0966029473114953

Epoch: 438| Step: 0
Training loss: 0.2568570117499447
Validation loss: 2.1093346595324918

Epoch: 5| Step: 1
Training loss: 0.22676217389574044
Validation loss: 2.1347128940183766

Epoch: 5| Step: 2
Training loss: 0.17774997894203823
Validation loss: 2.1325507851025653

Epoch: 5| Step: 3
Training loss: 0.2014114934240206
Validation loss: 2.1383932282277045

Epoch: 5| Step: 4
Training loss: 0.18538545312752683
Validation loss: 2.1669978246831008

Epoch: 5| Step: 5
Training loss: 0.14872354001633367
Validation loss: 2.16606141049982

Epoch: 5| Step: 6
Training loss: 0.18006528655520693
Validation loss: 2.132769453541421

Epoch: 5| Step: 7
Training loss: 0.23158423362959363
Validation loss: 2.115892621327038

Epoch: 5| Step: 8
Training loss: 0.20078608176803878
Validation loss: 2.118050296717969

Epoch: 5| Step: 9
Training loss: 0.3386940087606204
Validation loss: 2.1100719726970842

Epoch: 5| Step: 10
Training loss: 0.3917619942592062
Validation loss: 2.0767681211163933

Epoch: 439| Step: 0
Training loss: 0.26373074192320284
Validation loss: 2.1117286534061024

Epoch: 5| Step: 1
Training loss: 0.17408174058292228
Validation loss: 2.072211958670914

Epoch: 5| Step: 2
Training loss: 0.20682778346889488
Validation loss: 2.080888652242696

Epoch: 5| Step: 3
Training loss: 0.22038752854209492
Validation loss: 2.0650944344043825

Epoch: 5| Step: 4
Training loss: 0.29767428265913903
Validation loss: 2.078972039901575

Epoch: 5| Step: 5
Training loss: 0.13593119902641615
Validation loss: 2.04820114664101

Epoch: 5| Step: 6
Training loss: 0.1657568597873627
Validation loss: 2.064960900932481

Epoch: 5| Step: 7
Training loss: 0.3384881882121037
Validation loss: 2.077193676415379

Epoch: 5| Step: 8
Training loss: 0.24493545847433998
Validation loss: 2.109262510982036

Epoch: 5| Step: 9
Training loss: 0.18776329746408404
Validation loss: 2.0930415917062635

Epoch: 5| Step: 10
Training loss: 0.21142161411469187
Validation loss: 2.1463918161253233

Epoch: 440| Step: 0
Training loss: 0.3256768221630174
Validation loss: 2.129951813219335

Epoch: 5| Step: 1
Training loss: 0.19464319945132802
Validation loss: 2.131847992735276

Epoch: 5| Step: 2
Training loss: 0.23175551153108384
Validation loss: 2.138214324001287

Epoch: 5| Step: 3
Training loss: 0.16345123678213835
Validation loss: 2.1821442054805114

Epoch: 5| Step: 4
Training loss: 0.3548777141635212
Validation loss: 2.152559224534351

Epoch: 5| Step: 5
Training loss: 0.3131782800112434
Validation loss: 2.127750134817533

Epoch: 5| Step: 6
Training loss: 0.15707072834034794
Validation loss: 2.1424081093110723

Epoch: 5| Step: 7
Training loss: 0.13286673616494254
Validation loss: 2.1222769127092387

Epoch: 5| Step: 8
Training loss: 0.1658823600399602
Validation loss: 2.088368605033403

Epoch: 5| Step: 9
Training loss: 0.1378804443534691
Validation loss: 2.1082962626098167

Epoch: 5| Step: 10
Training loss: 0.12449244929783766
Validation loss: 2.1035222817525474

Epoch: 441| Step: 0
Training loss: 0.10403455363293777
Validation loss: 2.0798350300969632

Epoch: 5| Step: 1
Training loss: 0.14874892442779203
Validation loss: 2.078635792699214

Epoch: 5| Step: 2
Training loss: 0.3139943632543219
Validation loss: 2.0747264304651116

Epoch: 5| Step: 3
Training loss: 0.2269372799934533
Validation loss: 2.079733856257246

Epoch: 5| Step: 4
Training loss: 0.18961841215925065
Validation loss: 2.10280038033409

Epoch: 5| Step: 5
Training loss: 0.3004689515064058
Validation loss: 2.089904621116785

Epoch: 5| Step: 6
Training loss: 0.23433789118406884
Validation loss: 2.110534926953451

Epoch: 5| Step: 7
Training loss: 0.26951203761526643
Validation loss: 2.114023353202026

Epoch: 5| Step: 8
Training loss: 0.20234689783718693
Validation loss: 2.0683964182926196

Epoch: 5| Step: 9
Training loss: 0.14257071750158373
Validation loss: 2.1312900286728493

Epoch: 5| Step: 10
Training loss: 0.23711316107252012
Validation loss: 2.0858928477001766

Epoch: 442| Step: 0
Training loss: 0.1273729279212013
Validation loss: 2.119863607223876

Epoch: 5| Step: 1
Training loss: 0.27641659891390113
Validation loss: 2.1013864172861862

Epoch: 5| Step: 2
Training loss: 0.15311510482267782
Validation loss: 2.116778255118302

Epoch: 5| Step: 3
Training loss: 0.12149027153865659
Validation loss: 2.0546259236654842

Epoch: 5| Step: 4
Training loss: 0.1702035017059284
Validation loss: 2.0831965471298077

Epoch: 5| Step: 5
Training loss: 0.25416560498521373
Validation loss: 2.104494389959991

Epoch: 5| Step: 6
Training loss: 0.097997983011587
Validation loss: 2.11328494452042

Epoch: 5| Step: 7
Training loss: 0.2073060946419477
Validation loss: 2.122255344347509

Epoch: 5| Step: 8
Training loss: 0.17090574521380644
Validation loss: 2.0852906417552433

Epoch: 5| Step: 9
Training loss: 0.3197148725811252
Validation loss: 2.1036698851359406

Epoch: 5| Step: 10
Training loss: 0.3154547005293342
Validation loss: 2.119231536126458

Epoch: 443| Step: 0
Training loss: 0.1380366565223285
Validation loss: 2.07208826145487

Epoch: 5| Step: 1
Training loss: 0.19299553828072935
Validation loss: 2.095328245675564

Epoch: 5| Step: 2
Training loss: 0.2681159857810792
Validation loss: 2.0812888018066746

Epoch: 5| Step: 3
Training loss: 0.25559178402367655
Validation loss: 2.098145722258514

Epoch: 5| Step: 4
Training loss: 0.33173003277702195
Validation loss: 2.0701283424649293

Epoch: 5| Step: 5
Training loss: 0.12164573838763292
Validation loss: 2.094315935572984

Epoch: 5| Step: 6
Training loss: 0.17305443060506578
Validation loss: 2.0966019862225087

Epoch: 5| Step: 7
Training loss: 0.2647000786766062
Validation loss: 2.0852808317948672

Epoch: 5| Step: 8
Training loss: 0.18652148021050527
Validation loss: 2.0623432272615387

Epoch: 5| Step: 9
Training loss: 0.10823334330478304
Validation loss: 2.0707129993669064

Epoch: 5| Step: 10
Training loss: 0.20760497185556848
Validation loss: 2.0943609771761915

Epoch: 444| Step: 0
Training loss: 0.2965956553224235
Validation loss: 2.069330734234541

Epoch: 5| Step: 1
Training loss: 0.12425653449789104
Validation loss: 2.1010431832147463

Epoch: 5| Step: 2
Training loss: 0.35990965504288824
Validation loss: 2.1136479483332775

Epoch: 5| Step: 3
Training loss: 0.2832665734084507
Validation loss: 2.0881972277598035

Epoch: 5| Step: 4
Training loss: 0.162088335349445
Validation loss: 2.1126847395286865

Epoch: 5| Step: 5
Training loss: 0.2181043719099027
Validation loss: 2.075798472394172

Epoch: 5| Step: 6
Training loss: 0.17048866190645512
Validation loss: 2.0821747002700524

Epoch: 5| Step: 7
Training loss: 0.20571154909309927
Validation loss: 2.1008641417299745

Epoch: 5| Step: 8
Training loss: 0.17067414960958072
Validation loss: 2.1048771761152087

Epoch: 5| Step: 9
Training loss: 0.19301754184049946
Validation loss: 2.1298001325467246

Epoch: 5| Step: 10
Training loss: 0.28229203834133854
Validation loss: 2.094239181604701

Epoch: 445| Step: 0
Training loss: 0.21748937375320307
Validation loss: 2.1220554034745844

Epoch: 5| Step: 1
Training loss: 0.1867799642607008
Validation loss: 2.0907467329325393

Epoch: 5| Step: 2
Training loss: 0.2355618388292442
Validation loss: 2.097855915811522

Epoch: 5| Step: 3
Training loss: 0.16965161678278523
Validation loss: 2.1315217624297973

Epoch: 5| Step: 4
Training loss: 0.25025863977622465
Validation loss: 2.1411607079619053

Epoch: 5| Step: 5
Training loss: 0.2175917444811932
Validation loss: 2.0819746874503777

Epoch: 5| Step: 6
Training loss: 0.32431270203259716
Validation loss: 2.08183973321512

Epoch: 5| Step: 7
Training loss: 0.20361216519642236
Validation loss: 2.1065571402284275

Epoch: 5| Step: 8
Training loss: 0.13857291276785463
Validation loss: 2.0732555470025003

Epoch: 5| Step: 9
Training loss: 0.300019339593747
Validation loss: 2.081875305855497

Epoch: 5| Step: 10
Training loss: 0.3962798319155659
Validation loss: 2.0832741811004656

Epoch: 446| Step: 0
Training loss: 0.21559470454528734
Validation loss: 2.0955064630423363

Epoch: 5| Step: 1
Training loss: 0.15872911445393847
Validation loss: 2.075200659188242

Epoch: 5| Step: 2
Training loss: 0.2617653477877407
Validation loss: 2.0895801297033008

Epoch: 5| Step: 3
Training loss: 0.20957377022968635
Validation loss: 2.110268448359941

Epoch: 5| Step: 4
Training loss: 0.39125298565953265
Validation loss: 2.121954533754322

Epoch: 5| Step: 5
Training loss: 0.24027508491518185
Validation loss: 2.146462512422585

Epoch: 5| Step: 6
Training loss: 0.31393309057390645
Validation loss: 2.1303969263476947

Epoch: 5| Step: 7
Training loss: 0.12114901204611626
Validation loss: 2.1428713507994304

Epoch: 5| Step: 8
Training loss: 0.25909011891463585
Validation loss: 2.1178348948346795

Epoch: 5| Step: 9
Training loss: 0.1471122509659536
Validation loss: 2.1347972925054868

Epoch: 5| Step: 10
Training loss: 0.2628469065212592
Validation loss: 2.126669949597717

Epoch: 447| Step: 0
Training loss: 0.2693235868923799
Validation loss: 2.1047841456215823

Epoch: 5| Step: 1
Training loss: 0.1538067893270582
Validation loss: 2.0851822403291584

Epoch: 5| Step: 2
Training loss: 0.12314192567227221
Validation loss: 2.1128522353182864

Epoch: 5| Step: 3
Training loss: 0.2850296183513175
Validation loss: 2.1088179201736956

Epoch: 5| Step: 4
Training loss: 0.18865825611821582
Validation loss: 2.0780485923895524

Epoch: 5| Step: 5
Training loss: 0.23085430998175638
Validation loss: 2.1200306289497255

Epoch: 5| Step: 6
Training loss: 0.24754638942754434
Validation loss: 2.1102249432403832

Epoch: 5| Step: 7
Training loss: 0.22261661042839634
Validation loss: 2.0973960684706685

Epoch: 5| Step: 8
Training loss: 0.18894152041469273
Validation loss: 2.115752987537612

Epoch: 5| Step: 9
Training loss: 0.2629964300990318
Validation loss: 2.0968742661460866

Epoch: 5| Step: 10
Training loss: 0.22252851302171703
Validation loss: 2.1174493340260736

Epoch: 448| Step: 0
Training loss: 0.1804234732767435
Validation loss: 2.136162455114482

Epoch: 5| Step: 1
Training loss: 0.1726720168392989
Validation loss: 2.1194953214457906

Epoch: 5| Step: 2
Training loss: 0.27607579590084136
Validation loss: 2.1104281441006414

Epoch: 5| Step: 3
Training loss: 0.178568559223351
Validation loss: 2.109096547916026

Epoch: 5| Step: 4
Training loss: 0.1955329223422292
Validation loss: 2.1358318350460768

Epoch: 5| Step: 5
Training loss: 0.25332260542561996
Validation loss: 2.0950433155556683

Epoch: 5| Step: 6
Training loss: 0.19632800271105952
Validation loss: 2.105466678539297

Epoch: 5| Step: 7
Training loss: 0.24385250638233366
Validation loss: 2.125683542445434

Epoch: 5| Step: 8
Training loss: 0.2184820663028988
Validation loss: 2.102221144396385

Epoch: 5| Step: 9
Training loss: 0.23314728251985609
Validation loss: 2.104667222282166

Epoch: 5| Step: 10
Training loss: 0.175804194966172
Validation loss: 2.1069096148483166

Epoch: 449| Step: 0
Training loss: 0.31594176401794455
Validation loss: 2.0977977537600205

Epoch: 5| Step: 1
Training loss: 0.19204467257837596
Validation loss: 2.072566539942566

Epoch: 5| Step: 2
Training loss: 0.17399568732510315
Validation loss: 2.119478697897303

Epoch: 5| Step: 3
Training loss: 0.19499729470980692
Validation loss: 2.0903038220012986

Epoch: 5| Step: 4
Training loss: 0.14272173090044174
Validation loss: 2.0956841909207724

Epoch: 5| Step: 5
Training loss: 0.25749274857041904
Validation loss: 2.111428725610453

Epoch: 5| Step: 6
Training loss: 0.2302189135529512
Validation loss: 2.13798624045459

Epoch: 5| Step: 7
Training loss: 0.18815952774674954
Validation loss: 2.098064074447697

Epoch: 5| Step: 8
Training loss: 0.2878419262964218
Validation loss: 2.09841807645228

Epoch: 5| Step: 9
Training loss: 0.1890268150259604
Validation loss: 2.0805099991823295

Epoch: 5| Step: 10
Training loss: 0.18776833684638558
Validation loss: 2.1169927018768933

Epoch: 450| Step: 0
Training loss: 0.4162511561781489
Validation loss: 2.0871452941921778

Epoch: 5| Step: 1
Training loss: 0.19869486796855415
Validation loss: 2.091022143969074

Epoch: 5| Step: 2
Training loss: 0.10337268208819139
Validation loss: 2.0756429782797325

Epoch: 5| Step: 3
Training loss: 0.14284755124308843
Validation loss: 2.068978750025438

Epoch: 5| Step: 4
Training loss: 0.17606649566994104
Validation loss: 2.0852509996178905

Epoch: 5| Step: 5
Training loss: 0.22022055303442586
Validation loss: 2.0731781536801046

Epoch: 5| Step: 6
Training loss: 0.19851748138724726
Validation loss: 2.0970772252109873

Epoch: 5| Step: 7
Training loss: 0.18604182434146546
Validation loss: 2.0896618599563888

Epoch: 5| Step: 8
Training loss: 0.2077428625782362
Validation loss: 2.103985471507175

Epoch: 5| Step: 9
Training loss: 0.20609022801233495
Validation loss: 2.092819216352417

Epoch: 5| Step: 10
Training loss: 0.2065817523733332
Validation loss: 2.1202763802484728

Epoch: 451| Step: 0
Training loss: 0.17372339286782698
Validation loss: 2.0912452019997936

Epoch: 5| Step: 1
Training loss: 0.19616383025986545
Validation loss: 2.0773548651725164

Epoch: 5| Step: 2
Training loss: 0.18254599994167905
Validation loss: 2.12211588096489

Epoch: 5| Step: 3
Training loss: 0.19619567509474398
Validation loss: 2.106206534033249

Epoch: 5| Step: 4
Training loss: 0.15520781803898964
Validation loss: 2.1233619707959144

Epoch: 5| Step: 5
Training loss: 0.3541925388123833
Validation loss: 2.123589754093015

Epoch: 5| Step: 6
Training loss: 0.1927163384467454
Validation loss: 2.117594077750804

Epoch: 5| Step: 7
Training loss: 0.24465956657589172
Validation loss: 2.085012089531539

Epoch: 5| Step: 8
Training loss: 0.20839270500729046
Validation loss: 2.1139785064883827

Epoch: 5| Step: 9
Training loss: 0.22964636311029732
Validation loss: 2.1149253903977594

Epoch: 5| Step: 10
Training loss: 0.16802985721008773
Validation loss: 2.1613412607162785

Epoch: 452| Step: 0
Training loss: 0.17833115919702644
Validation loss: 2.1443579006157396

Epoch: 5| Step: 1
Training loss: 0.13284931654294882
Validation loss: 2.1118579010991887

Epoch: 5| Step: 2
Training loss: 0.21413288421167592
Validation loss: 2.1681432480646396

Epoch: 5| Step: 3
Training loss: 0.292188113002848
Validation loss: 2.127354282267532

Epoch: 5| Step: 4
Training loss: 0.15917870456883543
Validation loss: 2.118483475613798

Epoch: 5| Step: 5
Training loss: 0.2650013643130684
Validation loss: 2.123222549916071

Epoch: 5| Step: 6
Training loss: 0.1883033193419775
Validation loss: 2.095958548924508

Epoch: 5| Step: 7
Training loss: 0.13494547991415662
Validation loss: 2.122996701577856

Epoch: 5| Step: 8
Training loss: 0.18802480962005927
Validation loss: 2.125880507759859

Epoch: 5| Step: 9
Training loss: 0.18918671507683585
Validation loss: 2.127141516455399

Epoch: 5| Step: 10
Training loss: 0.3045945025617015
Validation loss: 2.108332635220434

Epoch: 453| Step: 0
Training loss: 0.13786708317435642
Validation loss: 2.1007117929004697

Epoch: 5| Step: 1
Training loss: 0.12716280420942488
Validation loss: 2.1328327343720996

Epoch: 5| Step: 2
Training loss: 0.21335914223489597
Validation loss: 2.108655914404396

Epoch: 5| Step: 3
Training loss: 0.3152553442654038
Validation loss: 2.0899376172757407

Epoch: 5| Step: 4
Training loss: 0.12001318422052332
Validation loss: 2.0865702397423065

Epoch: 5| Step: 5
Training loss: 0.11835590269327159
Validation loss: 2.07391328228767

Epoch: 5| Step: 6
Training loss: 0.2040659038294867
Validation loss: 2.0567043136313132

Epoch: 5| Step: 7
Training loss: 0.33727779932871516
Validation loss: 2.0960478303869277

Epoch: 5| Step: 8
Training loss: 0.2202806395631694
Validation loss: 2.081177386773343

Epoch: 5| Step: 9
Training loss: 0.23815547250025862
Validation loss: 2.06840602760131

Epoch: 5| Step: 10
Training loss: 0.1731845912644343
Validation loss: 2.038332835194126

Epoch: 454| Step: 0
Training loss: 0.18675698642990846
Validation loss: 2.074875176054721

Epoch: 5| Step: 1
Training loss: 0.18366334488895777
Validation loss: 2.0955456273504356

Epoch: 5| Step: 2
Training loss: 0.11779387867607254
Validation loss: 2.0438922415248766

Epoch: 5| Step: 3
Training loss: 0.3300525158760969
Validation loss: 2.0505279356440735

Epoch: 5| Step: 4
Training loss: 0.22687343110837283
Validation loss: 2.082545628272529

Epoch: 5| Step: 5
Training loss: 0.1752322205926823
Validation loss: 2.0401351088406727

Epoch: 5| Step: 6
Training loss: 0.2017911434799565
Validation loss: 2.0682857797455467

Epoch: 5| Step: 7
Training loss: 0.19026197237210152
Validation loss: 2.0660520918057377

Epoch: 5| Step: 8
Training loss: 0.1040805301568752
Validation loss: 2.092801624485133

Epoch: 5| Step: 9
Training loss: 0.3155544730979042
Validation loss: 2.052556521529141

Epoch: 5| Step: 10
Training loss: 0.17998147841039433
Validation loss: 2.131805339582356

Epoch: 455| Step: 0
Training loss: 0.16407116231302724
Validation loss: 2.1068884166489736

Epoch: 5| Step: 1
Training loss: 0.24564842015400326
Validation loss: 2.0998680235883267

Epoch: 5| Step: 2
Training loss: 0.16316921141073334
Validation loss: 2.133741885847077

Epoch: 5| Step: 3
Training loss: 0.1709235145698747
Validation loss: 2.1122808557432498

Epoch: 5| Step: 4
Training loss: 0.16769017917001314
Validation loss: 2.0932928212792787

Epoch: 5| Step: 5
Training loss: 0.19787446103230452
Validation loss: 2.1041041719977485

Epoch: 5| Step: 6
Training loss: 0.2859086730892711
Validation loss: 2.1365304794853848

Epoch: 5| Step: 7
Training loss: 0.1408131916399113
Validation loss: 2.0493094351879932

Epoch: 5| Step: 8
Training loss: 0.2218390408779304
Validation loss: 2.0759225517996946

Epoch: 5| Step: 9
Training loss: 0.24341351379906662
Validation loss: 2.066960466071304

Epoch: 5| Step: 10
Training loss: 0.12415463349326733
Validation loss: 2.0835247009328732

Epoch: 456| Step: 0
Training loss: 0.13553635339273928
Validation loss: 2.0681321330309093

Epoch: 5| Step: 1
Training loss: 0.22908943222206413
Validation loss: 2.0901875843765074

Epoch: 5| Step: 2
Training loss: 0.2683547090349644
Validation loss: 2.103490431036164

Epoch: 5| Step: 3
Training loss: 0.3057070814579064
Validation loss: 2.123345217544098

Epoch: 5| Step: 4
Training loss: 0.18788187557794075
Validation loss: 2.1050829561999236

Epoch: 5| Step: 5
Training loss: 0.14937923997982552
Validation loss: 2.080572357690205

Epoch: 5| Step: 6
Training loss: 0.11444186604424995
Validation loss: 2.107514931380365

Epoch: 5| Step: 7
Training loss: 0.10888171077553258
Validation loss: 2.073516041333544

Epoch: 5| Step: 8
Training loss: 0.17112097284093872
Validation loss: 2.0955454083660854

Epoch: 5| Step: 9
Training loss: 0.2476603131607754
Validation loss: 2.0794867335441896

Epoch: 5| Step: 10
Training loss: 0.20167580236741345
Validation loss: 2.1038580718639888

Epoch: 457| Step: 0
Training loss: 0.256148778881146
Validation loss: 2.1047292371752424

Epoch: 5| Step: 1
Training loss: 0.24846336362074237
Validation loss: 2.0861076005103305

Epoch: 5| Step: 2
Training loss: 0.12125404577289313
Validation loss: 2.1068986586492238

Epoch: 5| Step: 3
Training loss: 0.13640874730388045
Validation loss: 2.081557139867337

Epoch: 5| Step: 4
Training loss: 0.22748016446488642
Validation loss: 2.119302146520872

Epoch: 5| Step: 5
Training loss: 0.17392546360815772
Validation loss: 2.1127447766194662

Epoch: 5| Step: 6
Training loss: 0.12092839764931673
Validation loss: 2.0879155510547673

Epoch: 5| Step: 7
Training loss: 0.19317351184099954
Validation loss: 2.1302061668866568

Epoch: 5| Step: 8
Training loss: 0.3207272542595207
Validation loss: 2.097007290699349

Epoch: 5| Step: 9
Training loss: 0.13565037043988765
Validation loss: 2.1463872153090895

Epoch: 5| Step: 10
Training loss: 0.12038628743036034
Validation loss: 2.1187102285491544

Epoch: 458| Step: 0
Training loss: 0.3912707903399061
Validation loss: 2.0939229331475593

Epoch: 5| Step: 1
Training loss: 0.17935800403729338
Validation loss: 2.1123157986187833

Epoch: 5| Step: 2
Training loss: 0.1667286706616607
Validation loss: 2.070906880258816

Epoch: 5| Step: 3
Training loss: 0.10134764558296198
Validation loss: 2.108340928634989

Epoch: 5| Step: 4
Training loss: 0.17438566611083597
Validation loss: 2.1114677521224556

Epoch: 5| Step: 5
Training loss: 0.25469759353576216
Validation loss: 2.088935330300929

Epoch: 5| Step: 6
Training loss: 0.18639722018821886
Validation loss: 2.0729549893131503

Epoch: 5| Step: 7
Training loss: 0.1494210247836147
Validation loss: 2.093964627094967

Epoch: 5| Step: 8
Training loss: 0.134746785160032
Validation loss: 2.0936261359137616

Epoch: 5| Step: 9
Training loss: 0.10781433632572165
Validation loss: 2.090310870056624

Epoch: 5| Step: 10
Training loss: 0.13996677528107468
Validation loss: 2.0973002669326295

Epoch: 459| Step: 0
Training loss: 0.13124596725807916
Validation loss: 2.06423199677068

Epoch: 5| Step: 1
Training loss: 0.23565493614853372
Validation loss: 2.1457679709509234

Epoch: 5| Step: 2
Training loss: 0.2717691752679401
Validation loss: 2.1085129325713434

Epoch: 5| Step: 3
Training loss: 0.22437386812652466
Validation loss: 2.092176237430362

Epoch: 5| Step: 4
Training loss: 0.190687875071519
Validation loss: 2.119709307676707

Epoch: 5| Step: 5
Training loss: 0.1655851617620808
Validation loss: 2.1043687388558254

Epoch: 5| Step: 6
Training loss: 0.09619142077295803
Validation loss: 2.106813261494525

Epoch: 5| Step: 7
Training loss: 0.20523553892225965
Validation loss: 2.098075197443953

Epoch: 5| Step: 8
Training loss: 0.2641334731750882
Validation loss: 2.0791994478896347

Epoch: 5| Step: 9
Training loss: 0.08616564550907622
Validation loss: 2.085927066897484

Epoch: 5| Step: 10
Training loss: 0.225991104040563
Validation loss: 2.083412087910564

Epoch: 460| Step: 0
Training loss: 0.11904943603522632
Validation loss: 2.075419600293469

Epoch: 5| Step: 1
Training loss: 0.2123039456155373
Validation loss: 2.120434345983988

Epoch: 5| Step: 2
Training loss: 0.18158751911192902
Validation loss: 2.119860413348574

Epoch: 5| Step: 3
Training loss: 0.2029794758582877
Validation loss: 2.1027799130520566

Epoch: 5| Step: 4
Training loss: 0.18898657740318497
Validation loss: 2.0842347621132835

Epoch: 5| Step: 5
Training loss: 0.3103620951109423
Validation loss: 2.0941727207995156

Epoch: 5| Step: 6
Training loss: 0.15177904518085858
Validation loss: 2.0955116845030157

Epoch: 5| Step: 7
Training loss: 0.1487344920365011
Validation loss: 2.1335331803814888

Epoch: 5| Step: 8
Training loss: 0.26302120315727195
Validation loss: 2.1530888126216734

Epoch: 5| Step: 9
Training loss: 0.2928140867794852
Validation loss: 2.1354832248434583

Epoch: 5| Step: 10
Training loss: 0.14936824170789137
Validation loss: 2.1427049489281993

Epoch: 461| Step: 0
Training loss: 0.15044542032731112
Validation loss: 2.1124027564271963

Epoch: 5| Step: 1
Training loss: 0.16474420402813358
Validation loss: 2.092236311626184

Epoch: 5| Step: 2
Training loss: 0.2012414811831044
Validation loss: 2.11784388823058

Epoch: 5| Step: 3
Training loss: 0.09770132455092659
Validation loss: 2.1024948158213417

Epoch: 5| Step: 4
Training loss: 0.18283264179614767
Validation loss: 2.1357640913958447

Epoch: 5| Step: 5
Training loss: 0.21684919190000054
Validation loss: 2.1155683467246766

Epoch: 5| Step: 6
Training loss: 0.22424239987579028
Validation loss: 2.1007064055807363

Epoch: 5| Step: 7
Training loss: 0.26039218628578675
Validation loss: 2.1128435828633263

Epoch: 5| Step: 8
Training loss: 0.32730812616359595
Validation loss: 2.1474135956127074

Epoch: 5| Step: 9
Training loss: 0.17843723704624342
Validation loss: 2.150754770063827

Epoch: 5| Step: 10
Training loss: 0.2065639440108019
Validation loss: 2.117371842218706

Epoch: 462| Step: 0
Training loss: 0.1815068357233911
Validation loss: 2.1040923955190767

Epoch: 5| Step: 1
Training loss: 0.13542999758270916
Validation loss: 2.1499992951060247

Epoch: 5| Step: 2
Training loss: 0.14133434733225367
Validation loss: 2.1271594112572956

Epoch: 5| Step: 3
Training loss: 0.12730094506193115
Validation loss: 2.1074287164832843

Epoch: 5| Step: 4
Training loss: 0.25793433922803777
Validation loss: 2.0896940241898903

Epoch: 5| Step: 5
Training loss: 0.19338093261766678
Validation loss: 2.112432267055264

Epoch: 5| Step: 6
Training loss: 0.2469474124941651
Validation loss: 2.1208639241529927

Epoch: 5| Step: 7
Training loss: 0.2511452579188443
Validation loss: 2.097533282695067

Epoch: 5| Step: 8
Training loss: 0.1606156053560261
Validation loss: 2.0955375640624228

Epoch: 5| Step: 9
Training loss: 0.11404680673210713
Validation loss: 2.113740075677295

Epoch: 5| Step: 10
Training loss: 0.264852508467616
Validation loss: 2.1100542920031864

Epoch: 463| Step: 0
Training loss: 0.15033218561208916
Validation loss: 2.1211274091730505

Epoch: 5| Step: 1
Training loss: 0.1315878759589142
Validation loss: 2.091727583878586

Epoch: 5| Step: 2
Training loss: 0.14056452139422493
Validation loss: 2.116189076533676

Epoch: 5| Step: 3
Training loss: 0.22244512017797446
Validation loss: 2.0959142318221704

Epoch: 5| Step: 4
Training loss: 0.113569001055822
Validation loss: 2.113626181542939

Epoch: 5| Step: 5
Training loss: 0.2363130154784401
Validation loss: 2.121743106532067

Epoch: 5| Step: 6
Training loss: 0.28859475671069035
Validation loss: 2.131177640220684

Epoch: 5| Step: 7
Training loss: 0.1535079561021525
Validation loss: 2.124890267315467

Epoch: 5| Step: 8
Training loss: 0.232882787987859
Validation loss: 2.0888594592561742

Epoch: 5| Step: 9
Training loss: 0.20004249881175876
Validation loss: 2.1151655868440806

Epoch: 5| Step: 10
Training loss: 0.11656870386984738
Validation loss: 2.1429426991883607

Epoch: 464| Step: 0
Training loss: 0.13174282600588785
Validation loss: 2.0932614934031655

Epoch: 5| Step: 1
Training loss: 0.2184634460544199
Validation loss: 2.152655638216865

Epoch: 5| Step: 2
Training loss: 0.1091290245499287
Validation loss: 2.129437822304514

Epoch: 5| Step: 3
Training loss: 0.23873530573588267
Validation loss: 2.1247062636925795

Epoch: 5| Step: 4
Training loss: 0.12498699433497878
Validation loss: 2.1185316606314877

Epoch: 5| Step: 5
Training loss: 0.24019262679914574
Validation loss: 2.101603089682555

Epoch: 5| Step: 6
Training loss: 0.1597438130494007
Validation loss: 2.129796623758039

Epoch: 5| Step: 7
Training loss: 0.2796316075019685
Validation loss: 2.140083533730519

Epoch: 5| Step: 8
Training loss: 0.16435414459366016
Validation loss: 2.119157986120646

Epoch: 5| Step: 9
Training loss: 0.12018265916996151
Validation loss: 2.1026252937819683

Epoch: 5| Step: 10
Training loss: 0.10653391921145157
Validation loss: 2.1308379608844144

Epoch: 465| Step: 0
Training loss: 0.12652684315793858
Validation loss: 2.1010198057494085

Epoch: 5| Step: 1
Training loss: 0.2377817358853503
Validation loss: 2.0609039645741314

Epoch: 5| Step: 2
Training loss: 0.17644050738548173
Validation loss: 2.095574287188566

Epoch: 5| Step: 3
Training loss: 0.16313400245540516
Validation loss: 2.125908537062147

Epoch: 5| Step: 4
Training loss: 0.13861540195175298
Validation loss: 2.107878603525413

Epoch: 5| Step: 5
Training loss: 0.15327296163643656
Validation loss: 2.0856291318054248

Epoch: 5| Step: 6
Training loss: 0.24774385701790722
Validation loss: 2.1239029032625365

Epoch: 5| Step: 7
Training loss: 0.12969967112821193
Validation loss: 2.1037620412060436

Epoch: 5| Step: 8
Training loss: 0.19775757962806428
Validation loss: 2.1092665425275725

Epoch: 5| Step: 9
Training loss: 0.22624132806270972
Validation loss: 2.117386928302258

Epoch: 5| Step: 10
Training loss: 0.1954430906498317
Validation loss: 2.0887751886150236

Epoch: 466| Step: 0
Training loss: 0.28720429855961127
Validation loss: 2.0662940141960733

Epoch: 5| Step: 1
Training loss: 0.1523560127800405
Validation loss: 2.069949902825966

Epoch: 5| Step: 2
Training loss: 0.12289580653738319
Validation loss: 2.0382837400342306

Epoch: 5| Step: 3
Training loss: 0.1565983346562182
Validation loss: 2.0762582885834955

Epoch: 5| Step: 4
Training loss: 0.2693728382262825
Validation loss: 2.017732868018625

Epoch: 5| Step: 5
Training loss: 0.20614436760764115
Validation loss: 2.066205700259607

Epoch: 5| Step: 6
Training loss: 0.13157720962666253
Validation loss: 2.101069269176875

Epoch: 5| Step: 7
Training loss: 0.1412012360697526
Validation loss: 2.103764156691454

Epoch: 5| Step: 8
Training loss: 0.2014142955359791
Validation loss: 2.097998084895854

Epoch: 5| Step: 9
Training loss: 0.22758906555854613
Validation loss: 2.101809479396645

Epoch: 5| Step: 10
Training loss: 0.20977748574479985
Validation loss: 2.0715194648033175

Epoch: 467| Step: 0
Training loss: 0.3228506269401015
Validation loss: 2.0792913304286627

Epoch: 5| Step: 1
Training loss: 0.22313846271034324
Validation loss: 2.1043005469913636

Epoch: 5| Step: 2
Training loss: 0.1279462410503607
Validation loss: 2.053229110844388

Epoch: 5| Step: 3
Training loss: 0.06897750405539457
Validation loss: 2.0884220789841805

Epoch: 5| Step: 4
Training loss: 0.13521697989747297
Validation loss: 2.070451870679371

Epoch: 5| Step: 5
Training loss: 0.1447959872385598
Validation loss: 2.1062316906393894

Epoch: 5| Step: 6
Training loss: 0.1501309394542915
Validation loss: 2.094427269517685

Epoch: 5| Step: 7
Training loss: 0.15619702633278246
Validation loss: 2.1199367046562148

Epoch: 5| Step: 8
Training loss: 0.14742256448419735
Validation loss: 2.0888644506470317

Epoch: 5| Step: 9
Training loss: 0.20307065163309865
Validation loss: 2.120942787798124

Epoch: 5| Step: 10
Training loss: 0.2481844287851362
Validation loss: 2.107961299278027

Epoch: 468| Step: 0
Training loss: 0.10572669047085265
Validation loss: 2.125633747246748

Epoch: 5| Step: 1
Training loss: 0.21604692635866993
Validation loss: 2.1102814726301276

Epoch: 5| Step: 2
Training loss: 0.1770685531020513
Validation loss: 2.1004444207996693

Epoch: 5| Step: 3
Training loss: 0.2774205571591556
Validation loss: 2.097747144473078

Epoch: 5| Step: 4
Training loss: 0.13416604718169944
Validation loss: 2.0870608689667467

Epoch: 5| Step: 5
Training loss: 0.11812979619063177
Validation loss: 2.0935398633669533

Epoch: 5| Step: 6
Training loss: 0.21821890801570568
Validation loss: 2.1436055517691863

Epoch: 5| Step: 7
Training loss: 0.19167244170824949
Validation loss: 2.1334691200412603

Epoch: 5| Step: 8
Training loss: 0.11640843670986518
Validation loss: 2.083385935293642

Epoch: 5| Step: 9
Training loss: 0.17746852023067333
Validation loss: 2.0850476916573197

Epoch: 5| Step: 10
Training loss: 0.19909594060315092
Validation loss: 2.081947668058203

Epoch: 469| Step: 0
Training loss: 0.14104841648847127
Validation loss: 2.1066549777760937

Epoch: 5| Step: 1
Training loss: 0.13321990050119503
Validation loss: 2.119474712387166

Epoch: 5| Step: 2
Training loss: 0.28187478393241905
Validation loss: 2.124402964565403

Epoch: 5| Step: 3
Training loss: 0.238855989869007
Validation loss: 2.097944985165884

Epoch: 5| Step: 4
Training loss: 0.19771127123470464
Validation loss: 2.100520750308244

Epoch: 5| Step: 5
Training loss: 0.2233754388610636
Validation loss: 2.1025147530354404

Epoch: 5| Step: 6
Training loss: 0.10529384415251478
Validation loss: 2.1142574578294653

Epoch: 5| Step: 7
Training loss: 0.10655751570458294
Validation loss: 2.1113526049747637

Epoch: 5| Step: 8
Training loss: 0.21073909541593638
Validation loss: 2.078111120364698

Epoch: 5| Step: 9
Training loss: 0.12513102429613815
Validation loss: 2.1151615026076382

Epoch: 5| Step: 10
Training loss: 0.2773735943707491
Validation loss: 2.09104499077746

Epoch: 470| Step: 0
Training loss: 0.2642835797634236
Validation loss: 2.124156122623637

Epoch: 5| Step: 1
Training loss: 0.2127173357194041
Validation loss: 2.081923291476208

Epoch: 5| Step: 2
Training loss: 0.1121793379112358
Validation loss: 2.0731419328402816

Epoch: 5| Step: 3
Training loss: 0.14261558119099912
Validation loss: 2.0982358700797525

Epoch: 5| Step: 4
Training loss: 0.18368509739086197
Validation loss: 2.08564165847321

Epoch: 5| Step: 5
Training loss: 0.1362820941087158
Validation loss: 2.065530281736755

Epoch: 5| Step: 6
Training loss: 0.19589984318998097
Validation loss: 2.107382729768448

Epoch: 5| Step: 7
Training loss: 0.24719890821344664
Validation loss: 2.110651503377664

Epoch: 5| Step: 8
Training loss: 0.23989860982084638
Validation loss: 2.070948421724827

Epoch: 5| Step: 9
Training loss: 0.23990908363500393
Validation loss: 2.123694037257116

Epoch: 5| Step: 10
Training loss: 0.10140376799915439
Validation loss: 2.116436662047647

Epoch: 471| Step: 0
Training loss: 0.09883221214497705
Validation loss: 2.096376097303349

Epoch: 5| Step: 1
Training loss: 0.20734615488389704
Validation loss: 2.131211125699503

Epoch: 5| Step: 2
Training loss: 0.1335154610728267
Validation loss: 2.1254578494670207

Epoch: 5| Step: 3
Training loss: 0.28561527721876734
Validation loss: 2.0905499321397762

Epoch: 5| Step: 4
Training loss: 0.22832319520512478
Validation loss: 2.0938405442989185

Epoch: 5| Step: 5
Training loss: 0.22576306972764434
Validation loss: 2.0950944734942683

Epoch: 5| Step: 6
Training loss: 0.20263226056078001
Validation loss: 2.103808620387967

Epoch: 5| Step: 7
Training loss: 0.17161575185776382
Validation loss: 2.062960856916122

Epoch: 5| Step: 8
Training loss: 0.14550774849499826
Validation loss: 2.063765015131251

Epoch: 5| Step: 9
Training loss: 0.27626628853602964
Validation loss: 2.1013443508785916

Epoch: 5| Step: 10
Training loss: 0.1517627776621214
Validation loss: 2.0882763012136096

Epoch: 472| Step: 0
Training loss: 0.22998103568944683
Validation loss: 2.0978318404812812

Epoch: 5| Step: 1
Training loss: 0.2556709877282716
Validation loss: 2.0938131894974905

Epoch: 5| Step: 2
Training loss: 0.1320866637782766
Validation loss: 2.0388746365609394

Epoch: 5| Step: 3
Training loss: 0.12740692315240748
Validation loss: 2.076112759721265

Epoch: 5| Step: 4
Training loss: 0.10043382716985413
Validation loss: 2.101932133113124

Epoch: 5| Step: 5
Training loss: 0.19149624402145143
Validation loss: 2.096464953166767

Epoch: 5| Step: 6
Training loss: 0.1694422562992928
Validation loss: 2.062020002030484

Epoch: 5| Step: 7
Training loss: 0.23828837899972105
Validation loss: 2.08431098292238

Epoch: 5| Step: 8
Training loss: 0.3002203876891049
Validation loss: 2.0792310354170898

Epoch: 5| Step: 9
Training loss: 0.153279517754071
Validation loss: 2.106560325066068

Epoch: 5| Step: 10
Training loss: 0.21206582256292253
Validation loss: 2.079760525675149

Epoch: 473| Step: 0
Training loss: 0.13460909695632567
Validation loss: 2.09491916020348

Epoch: 5| Step: 1
Training loss: 0.2526302553580615
Validation loss: 2.071452666757332

Epoch: 5| Step: 2
Training loss: 0.13130741140981447
Validation loss: 2.080218973436107

Epoch: 5| Step: 3
Training loss: 0.28952537026279135
Validation loss: 2.0927929675318744

Epoch: 5| Step: 4
Training loss: 0.18611108426924966
Validation loss: 2.1039387756094805

Epoch: 5| Step: 5
Training loss: 0.12842033297026847
Validation loss: 2.0764026429668316

Epoch: 5| Step: 6
Training loss: 0.14456159041242672
Validation loss: 2.071009348732591

Epoch: 5| Step: 7
Training loss: 0.15997546156828427
Validation loss: 2.097763596215127

Epoch: 5| Step: 8
Training loss: 0.1979670376842846
Validation loss: 2.0883535309039014

Epoch: 5| Step: 9
Training loss: 0.16437790842710473
Validation loss: 2.0804747611627374

Epoch: 5| Step: 10
Training loss: 0.1699854907074514
Validation loss: 2.070295259261131

Epoch: 474| Step: 0
Training loss: 0.25123621352409325
Validation loss: 2.0605220107142475

Epoch: 5| Step: 1
Training loss: 0.14121129417110578
Validation loss: 2.0667872550343036

Epoch: 5| Step: 2
Training loss: 0.1217383601449888
Validation loss: 2.0729231314626073

Epoch: 5| Step: 3
Training loss: 0.1769668228540266
Validation loss: 2.037023505278525

Epoch: 5| Step: 4
Training loss: 0.17321288603970672
Validation loss: 2.065060426782911

Epoch: 5| Step: 5
Training loss: 0.10846819652019415
Validation loss: 2.07062937872589

Epoch: 5| Step: 6
Training loss: 0.262972915489493
Validation loss: 2.0876747668305473

Epoch: 5| Step: 7
Training loss: 0.1375713737516615
Validation loss: 2.1109276529737677

Epoch: 5| Step: 8
Training loss: 0.15988643527499183
Validation loss: 2.0744108529756593

Epoch: 5| Step: 9
Training loss: 0.24828133053115106
Validation loss: 2.0942670660898055

Epoch: 5| Step: 10
Training loss: 0.1321823302513842
Validation loss: 2.1047482409216234

Epoch: 475| Step: 0
Training loss: 0.2526696831335242
Validation loss: 2.0929366080544702

Epoch: 5| Step: 1
Training loss: 0.12172566780465172
Validation loss: 2.1271117464894735

Epoch: 5| Step: 2
Training loss: 0.16872080731431469
Validation loss: 2.1125483589440477

Epoch: 5| Step: 3
Training loss: 0.22411776937042924
Validation loss: 2.0918464737873195

Epoch: 5| Step: 4
Training loss: 0.11991679525644611
Validation loss: 2.1006276779889252

Epoch: 5| Step: 5
Training loss: 0.15550561855927414
Validation loss: 2.1012613166309673

Epoch: 5| Step: 6
Training loss: 0.13962530064486423
Validation loss: 2.103586177949266

Epoch: 5| Step: 7
Training loss: 0.17237038638245794
Validation loss: 2.1157236919581965

Epoch: 5| Step: 8
Training loss: 0.16540052681619047
Validation loss: 2.115441394393565

Epoch: 5| Step: 9
Training loss: 0.25814848017177755
Validation loss: 2.0916920605189926

Epoch: 5| Step: 10
Training loss: 0.12375587602955426
Validation loss: 2.1184254702583227

Epoch: 476| Step: 0
Training loss: 0.1280797994945596
Validation loss: 2.110657108236631

Epoch: 5| Step: 1
Training loss: 0.2019299971657496
Validation loss: 2.0907197493486396

Epoch: 5| Step: 2
Training loss: 0.22291443729325677
Validation loss: 2.0855642097398586

Epoch: 5| Step: 3
Training loss: 0.22511586014294901
Validation loss: 2.087790652574239

Epoch: 5| Step: 4
Training loss: 0.13041162039537743
Validation loss: 2.1471198307695176

Epoch: 5| Step: 5
Training loss: 0.13756526730972007
Validation loss: 2.1174117135597816

Epoch: 5| Step: 6
Training loss: 0.1400345685868267
Validation loss: 2.1077802590317507

Epoch: 5| Step: 7
Training loss: 0.1720734826530935
Validation loss: 2.1136844817362497

Epoch: 5| Step: 8
Training loss: 0.14282642586672561
Validation loss: 2.115144254431705

Epoch: 5| Step: 9
Training loss: 0.14744303765192165
Validation loss: 2.1242122842950018

Epoch: 5| Step: 10
Training loss: 0.19763639749937603
Validation loss: 2.092151796528167

Epoch: 477| Step: 0
Training loss: 0.12948408087071767
Validation loss: 2.0871052414003626

Epoch: 5| Step: 1
Training loss: 0.1782383846501781
Validation loss: 2.094303665213687

Epoch: 5| Step: 2
Training loss: 0.12140877953647188
Validation loss: 2.114657949669542

Epoch: 5| Step: 3
Training loss: 0.21555709322427907
Validation loss: 2.0988262726018743

Epoch: 5| Step: 4
Training loss: 0.32990637379461774
Validation loss: 2.0685909290013362

Epoch: 5| Step: 5
Training loss: 0.17302963007299033
Validation loss: 2.0971260915539864

Epoch: 5| Step: 6
Training loss: 0.16864310229880092
Validation loss: 2.0836482464267143

Epoch: 5| Step: 7
Training loss: 0.09683744006204922
Validation loss: 2.1053279347370037

Epoch: 5| Step: 8
Training loss: 0.10359611171228227
Validation loss: 2.1080120862560547

Epoch: 5| Step: 9
Training loss: 0.1626567446823
Validation loss: 2.0967033285513885

Epoch: 5| Step: 10
Training loss: 0.10257088757685773
Validation loss: 2.086980471929013

Epoch: 478| Step: 0
Training loss: 0.11509220599118407
Validation loss: 2.0741504376528996

Epoch: 5| Step: 1
Training loss: 0.1700521550657891
Validation loss: 2.0850500462169133

Epoch: 5| Step: 2
Training loss: 0.26659302470750557
Validation loss: 2.069042862390238

Epoch: 5| Step: 3
Training loss: 0.17620695276644885
Validation loss: 2.1099699505332863

Epoch: 5| Step: 4
Training loss: 0.2171167299521737
Validation loss: 2.0971940008423893

Epoch: 5| Step: 5
Training loss: 0.1620622014728155
Validation loss: 2.059642720244369

Epoch: 5| Step: 6
Training loss: 0.16832170994466888
Validation loss: 2.1099988445564004

Epoch: 5| Step: 7
Training loss: 0.17428480123595785
Validation loss: 2.0720860338289864

Epoch: 5| Step: 8
Training loss: 0.11522842650496791
Validation loss: 2.1017271325735196

Epoch: 5| Step: 9
Training loss: 0.1998515270888217
Validation loss: 2.1289086355297777

Epoch: 5| Step: 10
Training loss: 0.09850352850575064
Validation loss: 2.1193809436902207

Epoch: 479| Step: 0
Training loss: 0.24287210885308588
Validation loss: 2.1189081245842005

Epoch: 5| Step: 1
Training loss: 0.15331186890890158
Validation loss: 2.131294143648301

Epoch: 5| Step: 2
Training loss: 0.09507745954927951
Validation loss: 2.1390530082419956

Epoch: 5| Step: 3
Training loss: 0.09361114251988444
Validation loss: 2.082499308433172

Epoch: 5| Step: 4
Training loss: 0.159528373800685
Validation loss: 2.0808934034189845

Epoch: 5| Step: 5
Training loss: 0.23972510034203207
Validation loss: 2.113750925767392

Epoch: 5| Step: 6
Training loss: 0.23584568024357574
Validation loss: 2.0791821408960307

Epoch: 5| Step: 7
Training loss: 0.07802121301850616
Validation loss: 2.0927518700962877

Epoch: 5| Step: 8
Training loss: 0.15049656938606462
Validation loss: 2.0783257428728716

Epoch: 5| Step: 9
Training loss: 0.2200429037914474
Validation loss: 2.100714096953259

Epoch: 5| Step: 10
Training loss: 0.16951725458133143
Validation loss: 2.077889432099309

Epoch: 480| Step: 0
Training loss: 0.2829558904707432
Validation loss: 2.0770616064326823

Epoch: 5| Step: 1
Training loss: 0.18327302514277866
Validation loss: 2.0819885844260826

Epoch: 5| Step: 2
Training loss: 0.07834237969801232
Validation loss: 2.086430364384063

Epoch: 5| Step: 3
Training loss: 0.1359881498533231
Validation loss: 2.0563669161935585

Epoch: 5| Step: 4
Training loss: 0.17784409751784402
Validation loss: 2.054231084310975

Epoch: 5| Step: 5
Training loss: 0.22278184861824987
Validation loss: 2.06289381715411

Epoch: 5| Step: 6
Training loss: 0.16312733998392476
Validation loss: 2.0550512282537197

Epoch: 5| Step: 7
Training loss: 0.13851408645068028
Validation loss: 2.0903980825241884

Epoch: 5| Step: 8
Training loss: 0.13991768097462515
Validation loss: 2.1101322183744293

Epoch: 5| Step: 9
Training loss: 0.16996946983689953
Validation loss: 2.0540029045845936

Epoch: 5| Step: 10
Training loss: 0.17281250054323222
Validation loss: 2.051513666095444

Epoch: 481| Step: 0
Training loss: 0.08316452156144458
Validation loss: 2.0985605345408835

Epoch: 5| Step: 1
Training loss: 0.19489916934860982
Validation loss: 2.0701434421839306

Epoch: 5| Step: 2
Training loss: 0.22862542603704886
Validation loss: 2.050364500360831

Epoch: 5| Step: 3
Training loss: 0.14801360765570554
Validation loss: 2.0802523832551736

Epoch: 5| Step: 4
Training loss: 0.12944937209615778
Validation loss: 2.113337549035106

Epoch: 5| Step: 5
Training loss: 0.11398980914072654
Validation loss: 2.123473435232561

Epoch: 5| Step: 6
Training loss: 0.24749857458994992
Validation loss: 2.1202567859773325

Epoch: 5| Step: 7
Training loss: 0.22044100429344213
Validation loss: 2.1355030479537613

Epoch: 5| Step: 8
Training loss: 0.09989415859576095
Validation loss: 2.100353532286123

Epoch: 5| Step: 9
Training loss: 0.2262513062402522
Validation loss: 2.0883789283463403

Epoch: 5| Step: 10
Training loss: 0.14547602415079977
Validation loss: 2.132064871605459

Epoch: 482| Step: 0
Training loss: 0.16186274876131695
Validation loss: 2.112113721258061

Epoch: 5| Step: 1
Training loss: 0.2209396445293024
Validation loss: 2.10750551529259

Epoch: 5| Step: 2
Training loss: 0.11418459249760916
Validation loss: 2.075237515507175

Epoch: 5| Step: 3
Training loss: 0.17635198762099116
Validation loss: 2.09794887838117

Epoch: 5| Step: 4
Training loss: 0.12449664604359188
Validation loss: 2.0802558055438563

Epoch: 5| Step: 5
Training loss: 0.15989012821925175
Validation loss: 2.1099810727317423

Epoch: 5| Step: 6
Training loss: 0.29873093414519797
Validation loss: 2.115301450251548

Epoch: 5| Step: 7
Training loss: 0.2038735571774545
Validation loss: 2.1030549489749912

Epoch: 5| Step: 8
Training loss: 0.17579368441365503
Validation loss: 2.094022243078821

Epoch: 5| Step: 9
Training loss: 0.10916759205594609
Validation loss: 2.1117283231978123

Epoch: 5| Step: 10
Training loss: 0.2494020762360179
Validation loss: 2.1114756671578436

Epoch: 483| Step: 0
Training loss: 0.1388338915561606
Validation loss: 2.123360138792732

Epoch: 5| Step: 1
Training loss: 0.13042336034151766
Validation loss: 2.096639034294506

Epoch: 5| Step: 2
Training loss: 0.2286958798632225
Validation loss: 2.104698437635677

Epoch: 5| Step: 3
Training loss: 0.15058491282231956
Validation loss: 2.1106308759838153

Epoch: 5| Step: 4
Training loss: 0.10161129989513645
Validation loss: 2.082740376494302

Epoch: 5| Step: 5
Training loss: 0.2807069675300405
Validation loss: 2.0974533628535807

Epoch: 5| Step: 6
Training loss: 0.17434834206443472
Validation loss: 2.1034390013607793

Epoch: 5| Step: 7
Training loss: 0.22044542340617432
Validation loss: 2.078828360614957

Epoch: 5| Step: 8
Training loss: 0.15470409376555594
Validation loss: 2.0871394272088195

Epoch: 5| Step: 9
Training loss: 0.11825220902982532
Validation loss: 2.116780161093869

Epoch: 5| Step: 10
Training loss: 0.18425334982434274
Validation loss: 2.122750355211234

Epoch: 484| Step: 0
Training loss: 0.15027416971780408
Validation loss: 2.090433499717288

Epoch: 5| Step: 1
Training loss: 0.16982845500731827
Validation loss: 2.044272637717524

Epoch: 5| Step: 2
Training loss: 0.25166270055287776
Validation loss: 2.0916503310765773

Epoch: 5| Step: 3
Training loss: 0.23497999309028408
Validation loss: 2.0821170183949502

Epoch: 5| Step: 4
Training loss: 0.21645220430421072
Validation loss: 2.0384676926222873

Epoch: 5| Step: 5
Training loss: 0.16109700816621586
Validation loss: 2.0747215085469617

Epoch: 5| Step: 6
Training loss: 0.18693501067090387
Validation loss: 2.0287010348275243

Epoch: 5| Step: 7
Training loss: 0.13198054824272573
Validation loss: 2.0748330768804037

Epoch: 5| Step: 8
Training loss: 0.15511379792528635
Validation loss: 2.0676217094467657

Epoch: 5| Step: 9
Training loss: 0.1924200070438021
Validation loss: 2.0273868428888595

Epoch: 5| Step: 10
Training loss: 0.15956051445042016
Validation loss: 2.0769006942476906

Epoch: 485| Step: 0
Training loss: 0.23689830189837416
Validation loss: 2.1058143099127484

Epoch: 5| Step: 1
Training loss: 0.18738048439893734
Validation loss: 2.0914271654827057

Epoch: 5| Step: 2
Training loss: 0.0870543135905681
Validation loss: 2.069415024285381

Epoch: 5| Step: 3
Training loss: 0.24397406427716245
Validation loss: 2.0450293298062157

Epoch: 5| Step: 4
Training loss: 0.10881564467891067
Validation loss: 2.1073300626756195

Epoch: 5| Step: 5
Training loss: 0.26968891950125423
Validation loss: 2.0781526084914566

Epoch: 5| Step: 6
Training loss: 0.09844434313224576
Validation loss: 2.0746163927033163

Epoch: 5| Step: 7
Training loss: 0.16765722506471564
Validation loss: 2.0779642460356778

Epoch: 5| Step: 8
Training loss: 0.20126504499755948
Validation loss: 2.0652035035481875

Epoch: 5| Step: 9
Training loss: 0.17937494128422324
Validation loss: 2.0483220363350707

Epoch: 5| Step: 10
Training loss: 0.15589646039228572
Validation loss: 2.0631208159781695

Epoch: 486| Step: 0
Training loss: 0.18954058722432338
Validation loss: 2.0943423697270678

Epoch: 5| Step: 1
Training loss: 0.2063881404246893
Validation loss: 2.0727864055133494

Epoch: 5| Step: 2
Training loss: 0.15357105744295646
Validation loss: 2.0570749101410652

Epoch: 5| Step: 3
Training loss: 0.23025014984434555
Validation loss: 2.1106889637641335

Epoch: 5| Step: 4
Training loss: 0.2401984428267543
Validation loss: 2.0731178722371406

Epoch: 5| Step: 5
Training loss: 0.17153208292729183
Validation loss: 2.102069607370573

Epoch: 5| Step: 6
Training loss: 0.13522237279291272
Validation loss: 2.054909349031994

Epoch: 5| Step: 7
Training loss: 0.1231394222933136
Validation loss: 2.102938900638247

Epoch: 5| Step: 8
Training loss: 0.17268297627240028
Validation loss: 2.103092384374979

Epoch: 5| Step: 9
Training loss: 0.15025871858237827
Validation loss: 2.0900127377450404

Epoch: 5| Step: 10
Training loss: 0.1573470347155378
Validation loss: 2.115908872614767

Epoch: 487| Step: 0
Training loss: 0.15043416569576212
Validation loss: 2.105905080828966

Epoch: 5| Step: 1
Training loss: 0.24238851111734624
Validation loss: 2.0815596489378962

Epoch: 5| Step: 2
Training loss: 0.07426860665656869
Validation loss: 2.08290834296447

Epoch: 5| Step: 3
Training loss: 0.21230932369276195
Validation loss: 2.12940895036237

Epoch: 5| Step: 4
Training loss: 0.15555228979283967
Validation loss: 2.091519440563034

Epoch: 5| Step: 5
Training loss: 0.14006116205876076
Validation loss: 2.088029234918145

Epoch: 5| Step: 6
Training loss: 0.20574343708296938
Validation loss: 2.0778077141086873

Epoch: 5| Step: 7
Training loss: 0.20014798605160802
Validation loss: 2.0847491303996146

Epoch: 5| Step: 8
Training loss: 0.16950718933095002
Validation loss: 2.058724037896959

Epoch: 5| Step: 9
Training loss: 0.14234853575247844
Validation loss: 2.084648682659304

Epoch: 5| Step: 10
Training loss: 0.09500552914239757
Validation loss: 2.056045671635336

Epoch: 488| Step: 0
Training loss: 0.10885360453732769
Validation loss: 2.0621466086863447

Epoch: 5| Step: 1
Training loss: 0.1540650727035946
Validation loss: 2.076885593047308

Epoch: 5| Step: 2
Training loss: 0.26591474494002587
Validation loss: 2.0511099765688474

Epoch: 5| Step: 3
Training loss: 0.12476380205345441
Validation loss: 2.0781520000106726

Epoch: 5| Step: 4
Training loss: 0.07698850109036631
Validation loss: 2.0604168056393135

Epoch: 5| Step: 5
Training loss: 0.15536073713713533
Validation loss: 2.0559186810132752

Epoch: 5| Step: 6
Training loss: 0.12846882614452693
Validation loss: 2.066833752104401

Epoch: 5| Step: 7
Training loss: 0.20360153493686725
Validation loss: 2.0677691584741944

Epoch: 5| Step: 8
Training loss: 0.22058323329742646
Validation loss: 2.04597535660942

Epoch: 5| Step: 9
Training loss: 0.0673636049731255
Validation loss: 2.097137142816609

Epoch: 5| Step: 10
Training loss: 0.0868112540030336
Validation loss: 2.0774066876224153

Epoch: 489| Step: 0
Training loss: 0.1310078504526949
Validation loss: 2.056288179083723

Epoch: 5| Step: 1
Training loss: 0.11579170661817252
Validation loss: 2.0593926398384976

Epoch: 5| Step: 2
Training loss: 0.22722856677782838
Validation loss: 2.132576671389054

Epoch: 5| Step: 3
Training loss: 0.11883783558475831
Validation loss: 2.089234981475331

Epoch: 5| Step: 4
Training loss: 0.1694350283779124
Validation loss: 2.0765207525571743

Epoch: 5| Step: 5
Training loss: 0.104047287145458
Validation loss: 2.1036543311236233

Epoch: 5| Step: 6
Training loss: 0.18426898801910033
Validation loss: 2.114088365362185

Epoch: 5| Step: 7
Training loss: 0.12177929712241602
Validation loss: 2.0853790577880575

Epoch: 5| Step: 8
Training loss: 0.25761011155875163
Validation loss: 2.1102518034540236

Epoch: 5| Step: 9
Training loss: 0.1817373305454221
Validation loss: 2.10903203767115

Epoch: 5| Step: 10
Training loss: 0.0605646864780053
Validation loss: 2.059235699004119

Epoch: 490| Step: 0
Training loss: 0.12696044607327336
Validation loss: 2.109315627222249

Epoch: 5| Step: 1
Training loss: 0.08838124035023973
Validation loss: 2.0920393151930985

Epoch: 5| Step: 2
Training loss: 0.2723478814193056
Validation loss: 2.091622482795353

Epoch: 5| Step: 3
Training loss: 0.17654774232815582
Validation loss: 2.0688204595289132

Epoch: 5| Step: 4
Training loss: 0.1579372149269783
Validation loss: 2.0524081026315155

Epoch: 5| Step: 5
Training loss: 0.23301297043801517
Validation loss: 2.0910522536440257

Epoch: 5| Step: 6
Training loss: 0.09737902392543593
Validation loss: 2.062975298277648

Epoch: 5| Step: 7
Training loss: 0.1295613922415898
Validation loss: 2.0654809639041014

Epoch: 5| Step: 8
Training loss: 0.1378603953436489
Validation loss: 2.0774662658610894

Epoch: 5| Step: 9
Training loss: 0.13095036232941146
Validation loss: 2.067845498358458

Epoch: 5| Step: 10
Training loss: 0.12747322796023658
Validation loss: 2.0673892842668415

Epoch: 491| Step: 0
Training loss: 0.20400310496113092
Validation loss: 2.0495573852571747

Epoch: 5| Step: 1
Training loss: 0.13292034763164015
Validation loss: 2.055736340647377

Epoch: 5| Step: 2
Training loss: 0.17968214068506
Validation loss: 2.090485646071466

Epoch: 5| Step: 3
Training loss: 0.0896849680420229
Validation loss: 2.0602854227828504

Epoch: 5| Step: 4
Training loss: 0.17386874249426518
Validation loss: 2.0868826708070234

Epoch: 5| Step: 5
Training loss: 0.09260971781720459
Validation loss: 2.052988738894757

Epoch: 5| Step: 6
Training loss: 0.10928391171814483
Validation loss: 2.091984811949902

Epoch: 5| Step: 7
Training loss: 0.17027460954179188
Validation loss: 2.0773269998747104

Epoch: 5| Step: 8
Training loss: 0.2331665275521394
Validation loss: 2.086066377511515

Epoch: 5| Step: 9
Training loss: 0.09604268752632637
Validation loss: 2.1175780860655764

Epoch: 5| Step: 10
Training loss: 0.2626581272055893
Validation loss: 2.1160816600781924

Epoch: 492| Step: 0
Training loss: 0.0821329803000628
Validation loss: 2.0987088396043423

Epoch: 5| Step: 1
Training loss: 0.17166175401434283
Validation loss: 2.098076063771736

Epoch: 5| Step: 2
Training loss: 0.2319749815303114
Validation loss: 2.0413896168858052

Epoch: 5| Step: 3
Training loss: 0.14127231335151824
Validation loss: 2.0502891394646747

Epoch: 5| Step: 4
Training loss: 0.1198114170675732
Validation loss: 2.030241421309653

Epoch: 5| Step: 5
Training loss: 0.23664826391817648
Validation loss: 2.0461473496857043

Epoch: 5| Step: 6
Training loss: 0.17166734744391435
Validation loss: 2.040967433129107

Epoch: 5| Step: 7
Training loss: 0.1005902706064744
Validation loss: 2.071876383162156

Epoch: 5| Step: 8
Training loss: 0.181495536776251
Validation loss: 2.053365223831639

Epoch: 5| Step: 9
Training loss: 0.20969030992356322
Validation loss: 2.044571208237764

Epoch: 5| Step: 10
Training loss: 0.13625294489696507
Validation loss: 2.0246668074723604

Epoch: 493| Step: 0
Training loss: 0.09561105113735205
Validation loss: 2.037544735119775

Epoch: 5| Step: 1
Training loss: 0.24198457461152015
Validation loss: 2.026091208515091

Epoch: 5| Step: 2
Training loss: 0.17831696405849776
Validation loss: 2.06512189557831

Epoch: 5| Step: 3
Training loss: 0.14302038813181592
Validation loss: 2.0221488987104297

Epoch: 5| Step: 4
Training loss: 0.08276156476244557
Validation loss: 2.069443348559473

Epoch: 5| Step: 5
Training loss: 0.2275020995016999
Validation loss: 2.0918635779604515

Epoch: 5| Step: 6
Training loss: 0.09797852744208202
Validation loss: 2.113134575171864

Epoch: 5| Step: 7
Training loss: 0.20371342673019802
Validation loss: 2.1351485049238583

Epoch: 5| Step: 8
Training loss: 0.17979182449067205
Validation loss: 2.1259807040391596

Epoch: 5| Step: 9
Training loss: 0.14808594331613026
Validation loss: 2.107773935303975

Epoch: 5| Step: 10
Training loss: 0.24224624382813442
Validation loss: 2.115630787915593

Epoch: 494| Step: 0
Training loss: 0.16603999239541323
Validation loss: 2.141860975156766

Epoch: 5| Step: 1
Training loss: 0.11139500432817455
Validation loss: 2.112915416215193

Epoch: 5| Step: 2
Training loss: 0.3203517959495264
Validation loss: 2.1010647850841666

Epoch: 5| Step: 3
Training loss: 0.09770209190155553
Validation loss: 2.0941280114973644

Epoch: 5| Step: 4
Training loss: 0.12800320121973527
Validation loss: 2.0884156300450467

Epoch: 5| Step: 5
Training loss: 0.08554756771747792
Validation loss: 2.122678770744713

Epoch: 5| Step: 6
Training loss: 0.12431046920467792
Validation loss: 2.106865536006653

Epoch: 5| Step: 7
Training loss: 0.2764940812993305
Validation loss: 2.0632907834331564

Epoch: 5| Step: 8
Training loss: 0.23071930891524986
Validation loss: 2.122333597015224

Epoch: 5| Step: 9
Training loss: 0.3362504255724628
Validation loss: 2.0905205835175615

Epoch: 5| Step: 10
Training loss: 0.23926617354750693
Validation loss: 2.077553292258751

Epoch: 495| Step: 0
Training loss: 0.16159801375983437
Validation loss: 2.036907439106518

Epoch: 5| Step: 1
Training loss: 0.16390489774060701
Validation loss: 2.0214938908945923

Epoch: 5| Step: 2
Training loss: 0.30417547240422416
Validation loss: 1.9934514430152708

Epoch: 5| Step: 3
Training loss: 0.2404044719894592
Validation loss: 2.038341259662449

Epoch: 5| Step: 4
Training loss: 0.16043585700169785
Validation loss: 2.0188040713111146

Epoch: 5| Step: 5
Training loss: 0.22728784142435882
Validation loss: 2.029698489754137

Epoch: 5| Step: 6
Training loss: 0.3412945352914308
Validation loss: 2.0249275485610854

Epoch: 5| Step: 7
Training loss: 0.21850178464361478
Validation loss: 2.067149078731627

Epoch: 5| Step: 8
Training loss: 0.24446537544274713
Validation loss: 2.1197484033596132

Epoch: 5| Step: 9
Training loss: 0.27375679447503737
Validation loss: 2.0774224665383993

Epoch: 5| Step: 10
Training loss: 0.16439485944869484
Validation loss: 2.0988236928684203

Epoch: 496| Step: 0
Training loss: 0.15256555622677723
Validation loss: 2.104632128056642

Epoch: 5| Step: 1
Training loss: 0.19244629640288605
Validation loss: 2.1088207141006303

Epoch: 5| Step: 2
Training loss: 0.1608891986381
Validation loss: 2.109796726328468

Epoch: 5| Step: 3
Training loss: 0.15296999277188666
Validation loss: 2.09323777367609

Epoch: 5| Step: 4
Training loss: 0.20879126923182667
Validation loss: 2.1218025822336233

Epoch: 5| Step: 5
Training loss: 0.19621504151846056
Validation loss: 2.100386124762957

Epoch: 5| Step: 6
Training loss: 0.1800005611271854
Validation loss: 2.0613824321804493

Epoch: 5| Step: 7
Training loss: 0.1863657299617204
Validation loss: 2.0780503590141843

Epoch: 5| Step: 8
Training loss: 0.26181230723250326
Validation loss: 2.053565613143453

Epoch: 5| Step: 9
Training loss: 0.32776600636184866
Validation loss: 2.067951510349647

Epoch: 5| Step: 10
Training loss: 0.2831303996398582
Validation loss: 2.0901403729345587

Epoch: 497| Step: 0
Training loss: 0.2228723197049491
Validation loss: 2.1007786618795308

Epoch: 5| Step: 1
Training loss: 0.11357410165218178
Validation loss: 2.0534292375277423

Epoch: 5| Step: 2
Training loss: 0.1723239140495435
Validation loss: 2.09113128779237

Epoch: 5| Step: 3
Training loss: 0.17500588756262314
Validation loss: 2.0518761459388917

Epoch: 5| Step: 4
Training loss: 0.21231365763955323
Validation loss: 2.1128456161509592

Epoch: 5| Step: 5
Training loss: 0.15527788791636477
Validation loss: 2.1049067879885506

Epoch: 5| Step: 6
Training loss: 0.17468234528014576
Validation loss: 2.118200974291794

Epoch: 5| Step: 7
Training loss: 0.1449477599334235
Validation loss: 2.1167379449226824

Epoch: 5| Step: 8
Training loss: 0.21682572387654528
Validation loss: 2.1378716989142283

Epoch: 5| Step: 9
Training loss: 0.3423742377017484
Validation loss: 2.1231236304942485

Epoch: 5| Step: 10
Training loss: 0.1797425455283894
Validation loss: 2.0982711702494075

Epoch: 498| Step: 0
Training loss: 0.19017882818809795
Validation loss: 2.103177438637549

Epoch: 5| Step: 1
Training loss: 0.2494700074090703
Validation loss: 2.1099018090814554

Epoch: 5| Step: 2
Training loss: 0.21170738795011254
Validation loss: 2.098580703825572

Epoch: 5| Step: 3
Training loss: 0.1057470103609495
Validation loss: 2.122648737097893

Epoch: 5| Step: 4
Training loss: 0.2625092340162205
Validation loss: 2.1126861795918583

Epoch: 5| Step: 5
Training loss: 0.16455450534851224
Validation loss: 2.125947519044133

Epoch: 5| Step: 6
Training loss: 0.1387259552500812
Validation loss: 2.1085514486017054

Epoch: 5| Step: 7
Training loss: 0.16778930238224463
Validation loss: 2.096948064713347

Epoch: 5| Step: 8
Training loss: 0.09986902503556991
Validation loss: 2.093978169644264

Epoch: 5| Step: 9
Training loss: 0.2231241797050122
Validation loss: 2.103564906650588

Epoch: 5| Step: 10
Training loss: 0.1865330938266318
Validation loss: 2.1114189915597126

Epoch: 499| Step: 0
Training loss: 0.16098693833656352
Validation loss: 2.093556217451472

Epoch: 5| Step: 1
Training loss: 0.12566549501322938
Validation loss: 2.084962306644553

Epoch: 5| Step: 2
Training loss: 0.18524385102230442
Validation loss: 2.1242119608547565

Epoch: 5| Step: 3
Training loss: 0.23976702317134407
Validation loss: 2.1211592174407063

Epoch: 5| Step: 4
Training loss: 0.1241345621120515
Validation loss: 2.053203866703474

Epoch: 5| Step: 5
Training loss: 0.11751107208101412
Validation loss: 2.055538997811646

Epoch: 5| Step: 6
Training loss: 0.1689473576504617
Validation loss: 2.0770040420694413

Epoch: 5| Step: 7
Training loss: 0.1764477597502481
Validation loss: 2.062980707704055

Epoch: 5| Step: 8
Training loss: 0.16084044548436294
Validation loss: 2.0312526207489703

Epoch: 5| Step: 9
Training loss: 0.20369623630395986
Validation loss: 2.08255076774525

Epoch: 5| Step: 10
Training loss: 0.27758760880025685
Validation loss: 2.023314988873041

Epoch: 500| Step: 0
Training loss: 0.16612264325348125
Validation loss: 2.0535093901041517

Epoch: 5| Step: 1
Training loss: 0.1480755156741678
Validation loss: 2.0971240830607454

Epoch: 5| Step: 2
Training loss: 0.25342817047106314
Validation loss: 2.1040847317258904

Epoch: 5| Step: 3
Training loss: 0.16084535562674748
Validation loss: 2.085692708383627

Epoch: 5| Step: 4
Training loss: 0.16421083148118212
Validation loss: 2.085076865877015

Epoch: 5| Step: 5
Training loss: 0.2183921304882719
Validation loss: 2.0553678561109163

Epoch: 5| Step: 6
Training loss: 0.11804791724592553
Validation loss: 2.0917482499993487

Epoch: 5| Step: 7
Training loss: 0.07616769644695759
Validation loss: 2.0502439396032295

Epoch: 5| Step: 8
Training loss: 0.18101042460551903
Validation loss: 2.047427987832873

Epoch: 5| Step: 9
Training loss: 0.2104933442413643
Validation loss: 2.0166133013527157

Epoch: 5| Step: 10
Training loss: 0.11487989943389978
Validation loss: 2.063135374887804

Epoch: 501| Step: 0
Training loss: 0.13795764094263174
Validation loss: 2.0374577299275938

Epoch: 5| Step: 1
Training loss: 0.20463216521418856
Validation loss: 2.022971632035312

Epoch: 5| Step: 2
Training loss: 0.166800818742857
Validation loss: 2.015879936468389

Epoch: 5| Step: 3
Training loss: 0.14483290200622842
Validation loss: 2.026209504285599

Epoch: 5| Step: 4
Training loss: 0.1598540805040188
Validation loss: 2.077652205486902

Epoch: 5| Step: 5
Training loss: 0.19549886395290186
Validation loss: 2.043994606866475

Epoch: 5| Step: 6
Training loss: 0.15533814191700185
Validation loss: 2.063274880602975

Epoch: 5| Step: 7
Training loss: 0.10526247073573906
Validation loss: 2.0961793474421553

Epoch: 5| Step: 8
Training loss: 0.14926155884310807
Validation loss: 2.092084269485107

Epoch: 5| Step: 9
Training loss: 0.11943980471415007
Validation loss: 2.1121589607683666

Epoch: 5| Step: 10
Training loss: 0.21953240187264708
Validation loss: 2.111406568347008

Epoch: 502| Step: 0
Training loss: 0.18515870499089945
Validation loss: 2.087537610743908

Epoch: 5| Step: 1
Training loss: 0.11639057028220308
Validation loss: 2.129785507841206

Epoch: 5| Step: 2
Training loss: 0.1071375769459345
Validation loss: 2.089966724462732

Epoch: 5| Step: 3
Training loss: 0.18310123693026506
Validation loss: 2.1164907023150397

Epoch: 5| Step: 4
Training loss: 0.19161286199228048
Validation loss: 2.1196281158571804

Epoch: 5| Step: 5
Training loss: 0.12482456845894228
Validation loss: 2.106752781575348

Epoch: 5| Step: 6
Training loss: 0.15531695853613145
Validation loss: 2.0943762127914294

Epoch: 5| Step: 7
Training loss: 0.09564271791564725
Validation loss: 2.0900596123054216

Epoch: 5| Step: 8
Training loss: 0.22233004683933957
Validation loss: 2.0926852505767393

Epoch: 5| Step: 9
Training loss: 0.1376422346906348
Validation loss: 2.0724323832635054

Epoch: 5| Step: 10
Training loss: 0.11325626262134023
Validation loss: 2.0815438401110034

Epoch: 503| Step: 0
Training loss: 0.2263712404561356
Validation loss: 2.069479862689209

Epoch: 5| Step: 1
Training loss: 0.0790905503272394
Validation loss: 2.076309632480324

Epoch: 5| Step: 2
Training loss: 0.21102366630205957
Validation loss: 2.0942601106109575

Epoch: 5| Step: 3
Training loss: 0.10092990358011959
Validation loss: 2.093457365148518

Epoch: 5| Step: 4
Training loss: 0.13469980539900436
Validation loss: 2.1010753303128284

Epoch: 5| Step: 5
Training loss: 0.09606785270195435
Validation loss: 2.090777096098616

Epoch: 5| Step: 6
Training loss: 0.14620037522766843
Validation loss: 2.120246827658134

Epoch: 5| Step: 7
Training loss: 0.19039518581745962
Validation loss: 2.0766230467952695

Epoch: 5| Step: 8
Training loss: 0.15118020722248288
Validation loss: 2.1063433434921706

Epoch: 5| Step: 9
Training loss: 0.1914015496902999
Validation loss: 2.087410203273302

Epoch: 5| Step: 10
Training loss: 0.1321583161818333
Validation loss: 2.0768432426917403

Epoch: 504| Step: 0
Training loss: 0.12031807035085083
Validation loss: 2.106108477851918

Epoch: 5| Step: 1
Training loss: 0.18066301087769313
Validation loss: 2.1036659199446155

Epoch: 5| Step: 2
Training loss: 0.21785285596376336
Validation loss: 2.117034366523

Epoch: 5| Step: 3
Training loss: 0.2516081466488471
Validation loss: 2.0805612711168453

Epoch: 5| Step: 4
Training loss: 0.1584541895313125
Validation loss: 2.092119316864759

Epoch: 5| Step: 5
Training loss: 0.2247903095091849
Validation loss: 2.112069158840814

Epoch: 5| Step: 6
Training loss: 0.2014340109444556
Validation loss: 2.09652750659989

Epoch: 5| Step: 7
Training loss: 0.11841994945034234
Validation loss: 2.121467698326274

Epoch: 5| Step: 8
Training loss: 0.17150570469590903
Validation loss: 2.087970912709648

Epoch: 5| Step: 9
Training loss: 0.09574734386377974
Validation loss: 2.0525869650246604

Epoch: 5| Step: 10
Training loss: 0.14956758129528355
Validation loss: 2.1101508144567687

Epoch: 505| Step: 0
Training loss: 0.09509821375512846
Validation loss: 2.0738980542618863

Epoch: 5| Step: 1
Training loss: 0.12850177046700928
Validation loss: 2.0508899678264028

Epoch: 5| Step: 2
Training loss: 0.2484369439892575
Validation loss: 2.043484340342194

Epoch: 5| Step: 3
Training loss: 0.11938398552076095
Validation loss: 2.0706381896265533

Epoch: 5| Step: 4
Training loss: 0.10066656473711334
Validation loss: 2.0026830300339915

Epoch: 5| Step: 5
Training loss: 0.1424276720814294
Validation loss: 2.031355469697152

Epoch: 5| Step: 6
Training loss: 0.28031636617114325
Validation loss: 2.040738720074366

Epoch: 5| Step: 7
Training loss: 0.1345926432359236
Validation loss: 1.9951558193708387

Epoch: 5| Step: 8
Training loss: 0.13568778285660818
Validation loss: 2.017744755296427

Epoch: 5| Step: 9
Training loss: 0.09083826133811339
Validation loss: 2.0331284702565044

Epoch: 5| Step: 10
Training loss: 0.1785733469791906
Validation loss: 2.0417449710973927

Epoch: 506| Step: 0
Training loss: 0.14265734940572145
Validation loss: 2.0475060546083115

Epoch: 5| Step: 1
Training loss: 0.15537427830624403
Validation loss: 2.052328000730252

Epoch: 5| Step: 2
Training loss: 0.2008096155398161
Validation loss: 2.105593788786595

Epoch: 5| Step: 3
Training loss: 0.11197940323678984
Validation loss: 2.1007710012517244

Epoch: 5| Step: 4
Training loss: 0.16420678764822663
Validation loss: 2.0840936561321834

Epoch: 5| Step: 5
Training loss: 0.18558390398463076
Validation loss: 2.110227741075035

Epoch: 5| Step: 6
Training loss: 0.22446928216424225
Validation loss: 2.099408293374594

Epoch: 5| Step: 7
Training loss: 0.09624028295383166
Validation loss: 2.098235441225224

Epoch: 5| Step: 8
Training loss: 0.11635912334880558
Validation loss: 2.1016341590336873

Epoch: 5| Step: 9
Training loss: 0.08068572370072057
Validation loss: 2.1137917531894983

Epoch: 5| Step: 10
Training loss: 0.09389440025361397
Validation loss: 2.098778645349766

Epoch: 507| Step: 0
Training loss: 0.12543478987160517
Validation loss: 2.0616237227587715

Epoch: 5| Step: 1
Training loss: 0.1470737173185321
Validation loss: 2.071035663208881

Epoch: 5| Step: 2
Training loss: 0.12723833471781998
Validation loss: 2.0851173842663635

Epoch: 5| Step: 3
Training loss: 0.10434023780772621
Validation loss: 2.0720153956280183

Epoch: 5| Step: 4
Training loss: 0.061352027423393546
Validation loss: 2.069475465926836

Epoch: 5| Step: 5
Training loss: 0.08026583988312422
Validation loss: 2.052321971757448

Epoch: 5| Step: 6
Training loss: 0.17709220952807384
Validation loss: 2.0832067440909854

Epoch: 5| Step: 7
Training loss: 0.24430547108057482
Validation loss: 2.085199493834066

Epoch: 5| Step: 8
Training loss: 0.12353689396054449
Validation loss: 2.1051811612239892

Epoch: 5| Step: 9
Training loss: 0.11278268428666303
Validation loss: 2.087332939908813

Epoch: 5| Step: 10
Training loss: 0.22551453686588233
Validation loss: 2.100175282211432

Epoch: 508| Step: 0
Training loss: 0.16490878657236582
Validation loss: 2.108298265323665

Epoch: 5| Step: 1
Training loss: 0.2047915227115962
Validation loss: 2.0884325168080617

Epoch: 5| Step: 2
Training loss: 0.12573423662079689
Validation loss: 2.0809155169126448

Epoch: 5| Step: 3
Training loss: 0.18779875874830246
Validation loss: 2.084104110713746

Epoch: 5| Step: 4
Training loss: 0.11572082131778032
Validation loss: 2.12014013190049

Epoch: 5| Step: 5
Training loss: 0.10284514384337964
Validation loss: 2.0721281974750534

Epoch: 5| Step: 6
Training loss: 0.18176427344770113
Validation loss: 2.0550239712020373

Epoch: 5| Step: 7
Training loss: 0.11459874371013537
Validation loss: 2.101219687555087

Epoch: 5| Step: 8
Training loss: 0.1388239630964586
Validation loss: 2.093364728494017

Epoch: 5| Step: 9
Training loss: 0.07295551464381289
Validation loss: 2.1233464442208114

Epoch: 5| Step: 10
Training loss: 0.23110127531570063
Validation loss: 2.0702776431715026

Epoch: 509| Step: 0
Training loss: 0.19002937888146568
Validation loss: 2.080110639855007

Epoch: 5| Step: 1
Training loss: 0.17710005573713933
Validation loss: 2.08837318022102

Epoch: 5| Step: 2
Training loss: 0.10508722599139472
Validation loss: 2.0957166483638043

Epoch: 5| Step: 3
Training loss: 0.14513816219839465
Validation loss: 2.105488746720551

Epoch: 5| Step: 4
Training loss: 0.14449934993996966
Validation loss: 2.0962819163343647

Epoch: 5| Step: 5
Training loss: 0.1285486535412622
Validation loss: 2.097687093664148

Epoch: 5| Step: 6
Training loss: 0.08422457920772145
Validation loss: 2.1067344487664976

Epoch: 5| Step: 7
Training loss: 0.22373172288440746
Validation loss: 2.106179163041552

Epoch: 5| Step: 8
Training loss: 0.11316961509874078
Validation loss: 2.0837195624969196

Epoch: 5| Step: 9
Training loss: 0.11145932848506897
Validation loss: 2.1163710273218532

Epoch: 5| Step: 10
Training loss: 0.09644238894370334
Validation loss: 2.1079878085907926

Epoch: 510| Step: 0
Training loss: 0.1362928842285888
Validation loss: 2.103328633795656

Epoch: 5| Step: 1
Training loss: 0.25638238580779066
Validation loss: 2.0990396081502216

Epoch: 5| Step: 2
Training loss: 0.1817014448826456
Validation loss: 2.0893990765135184

Epoch: 5| Step: 3
Training loss: 0.11600708512622743
Validation loss: 2.0516180615883632

Epoch: 5| Step: 4
Training loss: 0.1279365595944667
Validation loss: 2.08059415084408

Epoch: 5| Step: 5
Training loss: 0.09955351329016103
Validation loss: 2.0886151537117326

Epoch: 5| Step: 6
Training loss: 0.13500528862757777
Validation loss: 2.0833882117478044

Epoch: 5| Step: 7
Training loss: 0.1591944014880799
Validation loss: 2.072279953889426

Epoch: 5| Step: 8
Training loss: 0.13721924859766246
Validation loss: 2.079957559124384

Epoch: 5| Step: 9
Training loss: 0.15629674689049214
Validation loss: 2.0844955533205134

Epoch: 5| Step: 10
Training loss: 0.14566925232926234
Validation loss: 2.100006585176752

Epoch: 511| Step: 0
Training loss: 0.09123704013992101
Validation loss: 2.1025382419062164

Epoch: 5| Step: 1
Training loss: 0.14029895549301755
Validation loss: 2.1008451809475237

Epoch: 5| Step: 2
Training loss: 0.15777748446505369
Validation loss: 2.1128333912184605

Epoch: 5| Step: 3
Training loss: 0.13654680338634076
Validation loss: 2.1210536795501156

Epoch: 5| Step: 4
Training loss: 0.09730999597122036
Validation loss: 2.1094805224301734

Epoch: 5| Step: 5
Training loss: 0.13870063671515637
Validation loss: 2.1158720280655166

Epoch: 5| Step: 6
Training loss: 0.20032913573363942
Validation loss: 2.115838856578422

Epoch: 5| Step: 7
Training loss: 0.14095977829154877
Validation loss: 2.1286752395403044

Epoch: 5| Step: 8
Training loss: 0.26355155742816894
Validation loss: 2.0684370889865575

Epoch: 5| Step: 9
Training loss: 0.14579555044736636
Validation loss: 2.0721016562344974

Epoch: 5| Step: 10
Training loss: 0.12545026210664026
Validation loss: 2.0866605236786424

Epoch: 512| Step: 0
Training loss: 0.11384827422404435
Validation loss: 2.053919986602514

Epoch: 5| Step: 1
Training loss: 0.10917535510534997
Validation loss: 2.070480760240559

Epoch: 5| Step: 2
Training loss: 0.27489616427751584
Validation loss: 2.082601237309044

Epoch: 5| Step: 3
Training loss: 0.173126347119981
Validation loss: 2.0646628462099543

Epoch: 5| Step: 4
Training loss: 0.1619725856691154
Validation loss: 2.087979641377048

Epoch: 5| Step: 5
Training loss: 0.17316764552468786
Validation loss: 2.090020656755431

Epoch: 5| Step: 6
Training loss: 0.123088152334951
Validation loss: 2.103033338291581

Epoch: 5| Step: 7
Training loss: 0.1673427994662803
Validation loss: 2.1120445055536536

Epoch: 5| Step: 8
Training loss: 0.11130537670685485
Validation loss: 2.092443426758752

Epoch: 5| Step: 9
Training loss: 0.17087595110505072
Validation loss: 2.110975037091318

Epoch: 5| Step: 10
Training loss: 0.16831285139232038
Validation loss: 2.087370670166814

Epoch: 513| Step: 0
Training loss: 0.12850529272640276
Validation loss: 2.08654219280729

Epoch: 5| Step: 1
Training loss: 0.14131687749007021
Validation loss: 2.0699239634417217

Epoch: 5| Step: 2
Training loss: 0.13276148265003104
Validation loss: 2.0871535090466375

Epoch: 5| Step: 3
Training loss: 0.15066683163618907
Validation loss: 2.082556559638828

Epoch: 5| Step: 4
Training loss: 0.0869911500271965
Validation loss: 2.111761205377244

Epoch: 5| Step: 5
Training loss: 0.15657349715375754
Validation loss: 2.1081802782778354

Epoch: 5| Step: 6
Training loss: 0.13198460567585624
Validation loss: 2.0945821353409375

Epoch: 5| Step: 7
Training loss: 0.10432003671299271
Validation loss: 2.1088093937045844

Epoch: 5| Step: 8
Training loss: 0.26678218940765186
Validation loss: 2.0934552631275105

Epoch: 5| Step: 9
Training loss: 0.18407435110245382
Validation loss: 2.1108433725121003

Epoch: 5| Step: 10
Training loss: 0.1240758972657327
Validation loss: 2.0900023605577496

Epoch: 514| Step: 0
Training loss: 0.11898063251147571
Validation loss: 2.1017367218368292

Epoch: 5| Step: 1
Training loss: 0.19178732092654513
Validation loss: 2.0994141498834864

Epoch: 5| Step: 2
Training loss: 0.18689559837353187
Validation loss: 2.1022480937644

Epoch: 5| Step: 3
Training loss: 0.14823954332328046
Validation loss: 2.079922839283357

Epoch: 5| Step: 4
Training loss: 0.12131099287666208
Validation loss: 2.101383482022293

Epoch: 5| Step: 5
Training loss: 0.10650304226268648
Validation loss: 2.116503505394934

Epoch: 5| Step: 6
Training loss: 0.19224832161640765
Validation loss: 2.113202680317902

Epoch: 5| Step: 7
Training loss: 0.1646516586929843
Validation loss: 2.090694512773351

Epoch: 5| Step: 8
Training loss: 0.1407680975499636
Validation loss: 2.0851915349987724

Epoch: 5| Step: 9
Training loss: 0.12519465132373583
Validation loss: 2.0988835309972917

Epoch: 5| Step: 10
Training loss: 0.16733362750507078
Validation loss: 2.0759698877606474

Epoch: 515| Step: 0
Training loss: 0.1553417811145224
Validation loss: 2.0503979152671534

Epoch: 5| Step: 1
Training loss: 0.130887782870772
Validation loss: 2.0369989236618222

Epoch: 5| Step: 2
Training loss: 0.1882011793359854
Validation loss: 2.036824399749448

Epoch: 5| Step: 3
Training loss: 0.12777519361314862
Validation loss: 2.0821333175273677

Epoch: 5| Step: 4
Training loss: 0.12390667006696808
Validation loss: 2.0852267664612114

Epoch: 5| Step: 5
Training loss: 0.1946929738146245
Validation loss: 2.0621201795346584

Epoch: 5| Step: 6
Training loss: 0.22885968317274288
Validation loss: 2.0426634554108136

Epoch: 5| Step: 7
Training loss: 0.08437733978100243
Validation loss: 2.0924618786504787

Epoch: 5| Step: 8
Training loss: 0.13134302606185727
Validation loss: 2.089513816393221

Epoch: 5| Step: 9
Training loss: 0.12152003810472391
Validation loss: 2.0873612685240963

Epoch: 5| Step: 10
Training loss: 0.1098957564781547
Validation loss: 2.0742791224238477

Epoch: 516| Step: 0
Training loss: 0.11252318563885355
Validation loss: 2.0962380692691487

Epoch: 5| Step: 1
Training loss: 0.1283265430209408
Validation loss: 2.097048576744389

Epoch: 5| Step: 2
Training loss: 0.0909001348277179
Validation loss: 2.0689883549257853

Epoch: 5| Step: 3
Training loss: 0.17017275825616623
Validation loss: 2.0652611839384596

Epoch: 5| Step: 4
Training loss: 0.18031131226662453
Validation loss: 2.0512684808075923

Epoch: 5| Step: 5
Training loss: 0.21962313443033676
Validation loss: 2.0731218442282864

Epoch: 5| Step: 6
Training loss: 0.17450399483108553
Validation loss: 2.0836986291220643

Epoch: 5| Step: 7
Training loss: 0.14373199386399213
Validation loss: 2.098713503409481

Epoch: 5| Step: 8
Training loss: 0.15239680417895193
Validation loss: 2.098578234193101

Epoch: 5| Step: 9
Training loss: 0.0789333397328893
Validation loss: 2.1203552324972756

Epoch: 5| Step: 10
Training loss: 0.09717216674324156
Validation loss: 2.091893468412697

Epoch: 517| Step: 0
Training loss: 0.19720893460738273
Validation loss: 2.1135322758803055

Epoch: 5| Step: 1
Training loss: 0.12348388090231512
Validation loss: 2.1263956894913436

Epoch: 5| Step: 2
Training loss: 0.154726679252228
Validation loss: 2.1057573647625816

Epoch: 5| Step: 3
Training loss: 0.12607382930160638
Validation loss: 2.0838829708053694

Epoch: 5| Step: 4
Training loss: 0.2149470687737336
Validation loss: 2.081289142387269

Epoch: 5| Step: 5
Training loss: 0.09376071828924958
Validation loss: 2.0631878589260273

Epoch: 5| Step: 6
Training loss: 0.10206944235698326
Validation loss: 2.0645646220887124

Epoch: 5| Step: 7
Training loss: 0.07230819917226718
Validation loss: 2.0700706150243833

Epoch: 5| Step: 8
Training loss: 0.13292474771715682
Validation loss: 2.0707435262931595

Epoch: 5| Step: 9
Training loss: 0.07348156276726193
Validation loss: 2.066967668141479

Epoch: 5| Step: 10
Training loss: 0.20202197850926149
Validation loss: 2.0578550050077355

Epoch: 518| Step: 0
Training loss: 0.0825726039343662
Validation loss: 2.057063936521775

Epoch: 5| Step: 1
Training loss: 0.08219526277349712
Validation loss: 2.0698063918069036

Epoch: 5| Step: 2
Training loss: 0.21673950948484932
Validation loss: 2.095002365667016

Epoch: 5| Step: 3
Training loss: 0.11146979352897321
Validation loss: 2.092943484638705

Epoch: 5| Step: 4
Training loss: 0.1503163129338772
Validation loss: 2.0975951284031003

Epoch: 5| Step: 5
Training loss: 0.1005816134662256
Validation loss: 2.091187111077545

Epoch: 5| Step: 6
Training loss: 0.08114554586755438
Validation loss: 2.0713254859217596

Epoch: 5| Step: 7
Training loss: 0.14763793049554877
Validation loss: 2.060426786860254

Epoch: 5| Step: 8
Training loss: 0.10347011303414329
Validation loss: 2.109901716129967

Epoch: 5| Step: 9
Training loss: 0.1776463951088387
Validation loss: 2.0930434951064405

Epoch: 5| Step: 10
Training loss: 0.24924847028018007
Validation loss: 2.1286503120438134

Epoch: 519| Step: 0
Training loss: 0.14573824001703173
Validation loss: 2.084043623732305

Epoch: 5| Step: 1
Training loss: 0.08841471710529036
Validation loss: 2.1002947375488166

Epoch: 5| Step: 2
Training loss: 0.13848215880068446
Validation loss: 2.0987520166624

Epoch: 5| Step: 3
Training loss: 0.2546734004418228
Validation loss: 2.1142872608597614

Epoch: 5| Step: 4
Training loss: 0.13138574097713127
Validation loss: 2.0668052029082427

Epoch: 5| Step: 5
Training loss: 0.09768804986094863
Validation loss: 2.090520706762402

Epoch: 5| Step: 6
Training loss: 0.12216375970336368
Validation loss: 2.0926315563245104

Epoch: 5| Step: 7
Training loss: 0.09467091843228341
Validation loss: 2.115831041468786

Epoch: 5| Step: 8
Training loss: 0.13409343262587972
Validation loss: 2.0889006504535574

Epoch: 5| Step: 9
Training loss: 0.10825296899631168
Validation loss: 2.095273637267059

Epoch: 5| Step: 10
Training loss: 0.20814221477051756
Validation loss: 2.0803717256238885

Epoch: 520| Step: 0
Training loss: 0.08461887185680853
Validation loss: 2.1123544279618613

Epoch: 5| Step: 1
Training loss: 0.09953875937047804
Validation loss: 2.0857409644697804

Epoch: 5| Step: 2
Training loss: 0.1766506998073241
Validation loss: 2.115516985877833

Epoch: 5| Step: 3
Training loss: 0.13733983654874019
Validation loss: 2.10118983948621

Epoch: 5| Step: 4
Training loss: 0.11252029288904399
Validation loss: 2.075840578542011

Epoch: 5| Step: 5
Training loss: 0.19149606893902
Validation loss: 2.107864946565328

Epoch: 5| Step: 6
Training loss: 0.14135192702291777
Validation loss: 2.1011045461460394

Epoch: 5| Step: 7
Training loss: 0.19342832588232084
Validation loss: 2.102775260704264

Epoch: 5| Step: 8
Training loss: 0.10695163365613763
Validation loss: 2.1098173880023485

Epoch: 5| Step: 9
Training loss: 0.1067295522863734
Validation loss: 2.105494311139853

Epoch: 5| Step: 10
Training loss: 0.11910090409694613
Validation loss: 2.125909866268911

Epoch: 521| Step: 0
Training loss: 0.1472534336538179
Validation loss: 2.1092732406858303

Epoch: 5| Step: 1
Training loss: 0.11034105892324574
Validation loss: 2.117796461088521

Epoch: 5| Step: 2
Training loss: 0.07103787875576262
Validation loss: 2.071933435445555

Epoch: 5| Step: 3
Training loss: 0.17872230827136418
Validation loss: 2.0300417288938593

Epoch: 5| Step: 4
Training loss: 0.13041619081633818
Validation loss: 2.0765806947889085

Epoch: 5| Step: 5
Training loss: 0.10730706061261953
Validation loss: 2.082507825368278

Epoch: 5| Step: 6
Training loss: 0.17088883509225658
Validation loss: 2.1072315023370187

Epoch: 5| Step: 7
Training loss: 0.18007051033917104
Validation loss: 2.084131149199482

Epoch: 5| Step: 8
Training loss: 0.19968499059697303
Validation loss: 2.0980716692012242

Epoch: 5| Step: 9
Training loss: 0.12376589204031953
Validation loss: 2.12136078420829

Epoch: 5| Step: 10
Training loss: 0.09334129912667996
Validation loss: 2.1468427044109823

Epoch: 522| Step: 0
Training loss: 0.11178208119966113
Validation loss: 2.119970804239042

Epoch: 5| Step: 1
Training loss: 0.10745067210446554
Validation loss: 2.1360377199189142

Epoch: 5| Step: 2
Training loss: 0.1688220340577959
Validation loss: 2.109899158443622

Epoch: 5| Step: 3
Training loss: 0.13806845785007077
Validation loss: 2.1032572470183526

Epoch: 5| Step: 4
Training loss: 0.14617508342897773
Validation loss: 2.1070659698482936

Epoch: 5| Step: 5
Training loss: 0.09513851921368606
Validation loss: 2.08903070795738

Epoch: 5| Step: 6
Training loss: 0.18011249164655674
Validation loss: 2.0808764764184398

Epoch: 5| Step: 7
Training loss: 0.19009135586323517
Validation loss: 2.100925620322666

Epoch: 5| Step: 8
Training loss: 0.15886935307396424
Validation loss: 2.10922129628211

Epoch: 5| Step: 9
Training loss: 0.10180034206309257
Validation loss: 2.138471481382856

Epoch: 5| Step: 10
Training loss: 0.08533259744122355
Validation loss: 2.0698606029244253

Epoch: 523| Step: 0
Training loss: 0.07817506080337022
Validation loss: 2.0979196800069113

Epoch: 5| Step: 1
Training loss: 0.11181031756086265
Validation loss: 2.1038580377447964

Epoch: 5| Step: 2
Training loss: 0.17874051459027396
Validation loss: 2.0985450135134465

Epoch: 5| Step: 3
Training loss: 0.12897676648782308
Validation loss: 2.074114086706306

Epoch: 5| Step: 4
Training loss: 0.1544232333948683
Validation loss: 2.035262221393801

Epoch: 5| Step: 5
Training loss: 0.10157665740887722
Validation loss: 2.093994066402865

Epoch: 5| Step: 6
Training loss: 0.09963838304483212
Validation loss: 2.100342253220267

Epoch: 5| Step: 7
Training loss: 0.18438732825297033
Validation loss: 2.087527024760597

Epoch: 5| Step: 8
Training loss: 0.21291362568207156
Validation loss: 2.114108067734998

Epoch: 5| Step: 9
Training loss: 0.12917807846520685
Validation loss: 2.0954927658217035

Epoch: 5| Step: 10
Training loss: 0.15943183703554675
Validation loss: 2.103160573358662

Epoch: 524| Step: 0
Training loss: 0.2153871340325194
Validation loss: 2.111654886990713

Epoch: 5| Step: 1
Training loss: 0.13845647954111148
Validation loss: 2.1039348959151645

Epoch: 5| Step: 2
Training loss: 0.21530352726027863
Validation loss: 2.0916077563086546

Epoch: 5| Step: 3
Training loss: 0.1114627584540068
Validation loss: 2.088170500967404

Epoch: 5| Step: 4
Training loss: 0.15343556658309446
Validation loss: 2.102910089275043

Epoch: 5| Step: 5
Training loss: 0.09929498912301991
Validation loss: 2.109576214392473

Epoch: 5| Step: 6
Training loss: 0.13599977135770525
Validation loss: 2.0986562220516958

Epoch: 5| Step: 7
Training loss: 0.1239200145801595
Validation loss: 2.11362930114796

Epoch: 5| Step: 8
Training loss: 0.12365308794211309
Validation loss: 2.0807787691014017

Epoch: 5| Step: 9
Training loss: 0.09318956110150539
Validation loss: 2.0656570170217576

Epoch: 5| Step: 10
Training loss: 0.09403342875006805
Validation loss: 2.0824961729710916

Epoch: 525| Step: 0
Training loss: 0.09785208140405058
Validation loss: 2.094774161334233

Epoch: 5| Step: 1
Training loss: 0.10677330859346676
Validation loss: 2.0930957209638406

Epoch: 5| Step: 2
Training loss: 0.10290982110777441
Validation loss: 2.071611061484302

Epoch: 5| Step: 3
Training loss: 0.19771910938189882
Validation loss: 2.0581867688777846

Epoch: 5| Step: 4
Training loss: 0.09031490472872185
Validation loss: 2.0719795021403713

Epoch: 5| Step: 5
Training loss: 0.1901597579688904
Validation loss: 2.08874217900246

Epoch: 5| Step: 6
Training loss: 0.1497522963780051
Validation loss: 2.067915003325455

Epoch: 5| Step: 7
Training loss: 0.11551304032947883
Validation loss: 2.0608776693831747

Epoch: 5| Step: 8
Training loss: 0.114332138242114
Validation loss: 2.084800526801054

Epoch: 5| Step: 9
Training loss: 0.1362965331322011
Validation loss: 2.0700092244459167

Epoch: 5| Step: 10
Training loss: 0.19777520147505503
Validation loss: 2.0650558359469797

Epoch: 526| Step: 0
Training loss: 0.1723559056505982
Validation loss: 2.0773578603041813

Epoch: 5| Step: 1
Training loss: 0.20354189639109438
Validation loss: 2.0848480952574553

Epoch: 5| Step: 2
Training loss: 0.11834383916083423
Validation loss: 2.090378918272958

Epoch: 5| Step: 3
Training loss: 0.16545619391944485
Validation loss: 2.0718889595709356

Epoch: 5| Step: 4
Training loss: 0.12148126386602241
Validation loss: 2.0726692838241885

Epoch: 5| Step: 5
Training loss: 0.1177642695336408
Validation loss: 2.0920153346824244

Epoch: 5| Step: 6
Training loss: 0.09088336642593393
Validation loss: 2.102411797136223

Epoch: 5| Step: 7
Training loss: 0.0800520517189511
Validation loss: 2.0642017318504937

Epoch: 5| Step: 8
Training loss: 0.19271231767470487
Validation loss: 2.0726525450761963

Epoch: 5| Step: 9
Training loss: 0.09160316604154216
Validation loss: 2.0660740390514434

Epoch: 5| Step: 10
Training loss: 0.12274994673067402
Validation loss: 2.0691765183725086

Epoch: 527| Step: 0
Training loss: 0.09072866224892537
Validation loss: 2.0841801942304294

Epoch: 5| Step: 1
Training loss: 0.13269779918318192
Validation loss: 2.0666552984273654

Epoch: 5| Step: 2
Training loss: 0.11764823622850674
Validation loss: 2.0638812105498476

Epoch: 5| Step: 3
Training loss: 0.19018522367829466
Validation loss: 2.027422938492701

Epoch: 5| Step: 4
Training loss: 0.126007046818469
Validation loss: 2.0438104662280017

Epoch: 5| Step: 5
Training loss: 0.11064233701976257
Validation loss: 2.072717577811589

Epoch: 5| Step: 6
Training loss: 0.10657564111546289
Validation loss: 2.0667432973106625

Epoch: 5| Step: 7
Training loss: 0.0925562524911964
Validation loss: 2.0722318785739517

Epoch: 5| Step: 8
Training loss: 0.177434080704344
Validation loss: 2.083799586471546

Epoch: 5| Step: 9
Training loss: 0.07637993810995852
Validation loss: 2.063828133613755

Epoch: 5| Step: 10
Training loss: 0.18357970813052685
Validation loss: 2.0572144860063144

Epoch: 528| Step: 0
Training loss: 0.1151343331643919
Validation loss: 2.0557951782897916

Epoch: 5| Step: 1
Training loss: 0.07066215887927037
Validation loss: 2.0608590510133005

Epoch: 5| Step: 2
Training loss: 0.11040282535694255
Validation loss: 2.079344471296062

Epoch: 5| Step: 3
Training loss: 0.09862878054696526
Validation loss: 2.0790451594638446

Epoch: 5| Step: 4
Training loss: 0.2142930776389652
Validation loss: 2.074705728859813

Epoch: 5| Step: 5
Training loss: 0.0827065414126297
Validation loss: 2.105058839304118

Epoch: 5| Step: 6
Training loss: 0.10489201478706525
Validation loss: 2.0343039217043386

Epoch: 5| Step: 7
Training loss: 0.1487348927812353
Validation loss: 2.09235780138269

Epoch: 5| Step: 8
Training loss: 0.0711628927420934
Validation loss: 2.1208360895806644

Epoch: 5| Step: 9
Training loss: 0.1487126059772992
Validation loss: 2.098285673422984

Epoch: 5| Step: 10
Training loss: 0.18352162182048476
Validation loss: 2.0834558619081496

Epoch: 529| Step: 0
Training loss: 0.12066811313048141
Validation loss: 2.1029780245114686

Epoch: 5| Step: 1
Training loss: 0.08293435268244405
Validation loss: 2.0934164840432268

Epoch: 5| Step: 2
Training loss: 0.12589362467562756
Validation loss: 2.0942112294197512

Epoch: 5| Step: 3
Training loss: 0.10508090692687738
Validation loss: 2.0985483583273155

Epoch: 5| Step: 4
Training loss: 0.09570056074950033
Validation loss: 2.0831898051217297

Epoch: 5| Step: 5
Training loss: 0.2037810588052476
Validation loss: 2.0886578588289435

Epoch: 5| Step: 6
Training loss: 0.18412633509452944
Validation loss: 2.045118927365649

Epoch: 5| Step: 7
Training loss: 0.17436456949902554
Validation loss: 2.1068233418699718

Epoch: 5| Step: 8
Training loss: 0.11349112701183141
Validation loss: 2.0970509318881687

Epoch: 5| Step: 9
Training loss: 0.12499647210030305
Validation loss: 2.077837630942848

Epoch: 5| Step: 10
Training loss: 0.10289960779994851
Validation loss: 2.0506676220801157

Epoch: 530| Step: 0
Training loss: 0.1405508388895433
Validation loss: 2.1222896651793404

Epoch: 5| Step: 1
Training loss: 0.137234186220783
Validation loss: 2.0763123834127777

Epoch: 5| Step: 2
Training loss: 0.21681989942753294
Validation loss: 2.052140858853072

Epoch: 5| Step: 3
Training loss: 0.20108209847438518
Validation loss: 2.0707989836807448

Epoch: 5| Step: 4
Training loss: 0.10918333511537541
Validation loss: 2.0716186266821284

Epoch: 5| Step: 5
Training loss: 0.110668545748959
Validation loss: 2.076909397693308

Epoch: 5| Step: 6
Training loss: 0.09058403227802418
Validation loss: 2.0863116045129333

Epoch: 5| Step: 7
Training loss: 0.07332067099327605
Validation loss: 2.075464269167567

Epoch: 5| Step: 8
Training loss: 0.11415136709716728
Validation loss: 2.0611169071400663

Epoch: 5| Step: 9
Training loss: 0.07185512013829061
Validation loss: 2.0759833161529735

Epoch: 5| Step: 10
Training loss: 0.11662296373525627
Validation loss: 2.0456009179190024

Epoch: 531| Step: 0
Training loss: 0.1764595402489034
Validation loss: 2.094723854108129

Epoch: 5| Step: 1
Training loss: 0.08523301155825005
Validation loss: 2.0740894752952888

Epoch: 5| Step: 2
Training loss: 0.16013334273292268
Validation loss: 2.080237992820876

Epoch: 5| Step: 3
Training loss: 0.09391050209313993
Validation loss: 2.0706039709563395

Epoch: 5| Step: 4
Training loss: 0.117440467233106
Validation loss: 2.0959443476653985

Epoch: 5| Step: 5
Training loss: 0.10406098568017835
Validation loss: 2.0724158695971053

Epoch: 5| Step: 6
Training loss: 0.09748832570083497
Validation loss: 2.0867404422421933

Epoch: 5| Step: 7
Training loss: 0.23539315643620595
Validation loss: 2.0684170969044087

Epoch: 5| Step: 8
Training loss: 0.121155530797552
Validation loss: 2.065661692155754

Epoch: 5| Step: 9
Training loss: 0.12068818996830794
Validation loss: 2.0466474155910053

Epoch: 5| Step: 10
Training loss: 0.09106191166253726
Validation loss: 2.077897120948694

Epoch: 532| Step: 0
Training loss: 0.0784394344104602
Validation loss: 2.070699527511401

Epoch: 5| Step: 1
Training loss: 0.06533639933149098
Validation loss: 2.0861473093199914

Epoch: 5| Step: 2
Training loss: 0.22643129890725872
Validation loss: 2.089365183505506

Epoch: 5| Step: 3
Training loss: 0.11897343098059136
Validation loss: 2.0810467633210328

Epoch: 5| Step: 4
Training loss: 0.10898229655126299
Validation loss: 2.101282171120835

Epoch: 5| Step: 5
Training loss: 0.12766688048131725
Validation loss: 2.111052198411988

Epoch: 5| Step: 6
Training loss: 0.18643066335912742
Validation loss: 2.094469693948365

Epoch: 5| Step: 7
Training loss: 0.09021007450081125
Validation loss: 2.095505602533846

Epoch: 5| Step: 8
Training loss: 0.1134186478718139
Validation loss: 2.091015964192473

Epoch: 5| Step: 9
Training loss: 0.09814694150176118
Validation loss: 2.09785915479672

Epoch: 5| Step: 10
Training loss: 0.1393022247053109
Validation loss: 2.0911669579830385

Epoch: 533| Step: 0
Training loss: 0.13576403105918852
Validation loss: 2.073161958191796

Epoch: 5| Step: 1
Training loss: 0.2153451098148789
Validation loss: 2.090433383825514

Epoch: 5| Step: 2
Training loss: 0.13704474955737178
Validation loss: 2.0430722595594424

Epoch: 5| Step: 3
Training loss: 0.13098667841800274
Validation loss: 2.09317017756238

Epoch: 5| Step: 4
Training loss: 0.0862242509580989
Validation loss: 2.054416195179735

Epoch: 5| Step: 5
Training loss: 0.13030568457237476
Validation loss: 2.092081645901477

Epoch: 5| Step: 6
Training loss: 0.09683329488203765
Validation loss: 2.036500015841403

Epoch: 5| Step: 7
Training loss: 0.09982788204605982
Validation loss: 2.073130728006592

Epoch: 5| Step: 8
Training loss: 0.06499298098497394
Validation loss: 2.0837557083526983

Epoch: 5| Step: 9
Training loss: 0.17827831078663292
Validation loss: 2.100285532603928

Epoch: 5| Step: 10
Training loss: 0.13252307406407518
Validation loss: 2.104217909614682

Epoch: 534| Step: 0
Training loss: 0.11725816582878071
Validation loss: 2.0721320179505405

Epoch: 5| Step: 1
Training loss: 0.07982025553397074
Validation loss: 2.095039128766243

Epoch: 5| Step: 2
Training loss: 0.14795200735554911
Validation loss: 2.0677365338596

Epoch: 5| Step: 3
Training loss: 0.2276277410241615
Validation loss: 2.08591453702758

Epoch: 5| Step: 4
Training loss: 0.0973305516150991
Validation loss: 2.0955363345642555

Epoch: 5| Step: 5
Training loss: 0.1943515119589732
Validation loss: 2.078612107724951

Epoch: 5| Step: 6
Training loss: 0.08233519002497496
Validation loss: 2.0934338270461916

Epoch: 5| Step: 7
Training loss: 0.10464858890592267
Validation loss: 2.096263063000582

Epoch: 5| Step: 8
Training loss: 0.08208778681005716
Validation loss: 2.084582079038975

Epoch: 5| Step: 9
Training loss: 0.0689434879320908
Validation loss: 2.1127766722605417

Epoch: 5| Step: 10
Training loss: 0.06944653930915083
Validation loss: 2.063755368064089

Epoch: 535| Step: 0
Training loss: 0.21330644961711626
Validation loss: 2.074009858175134

Epoch: 5| Step: 1
Training loss: 0.11847024845437468
Validation loss: 2.0938679676130247

Epoch: 5| Step: 2
Training loss: 0.12874253309226527
Validation loss: 2.1124471463040835

Epoch: 5| Step: 3
Training loss: 0.08867434128511792
Validation loss: 2.0752072029328072

Epoch: 5| Step: 4
Training loss: 0.12134282199962569
Validation loss: 2.0939448974094996

Epoch: 5| Step: 5
Training loss: 0.10134336783377937
Validation loss: 2.124493861378326

Epoch: 5| Step: 6
Training loss: 0.11472767215331099
Validation loss: 2.0908949617005104

Epoch: 5| Step: 7
Training loss: 0.1975280696653307
Validation loss: 2.080503861498374

Epoch: 5| Step: 8
Training loss: 0.06657837900521975
Validation loss: 2.1168827430417356

Epoch: 5| Step: 9
Training loss: 0.10201376832396311
Validation loss: 2.103140043758182

Epoch: 5| Step: 10
Training loss: 0.12708363793550267
Validation loss: 2.108065618597783

Epoch: 536| Step: 0
Training loss: 0.11845380553832642
Validation loss: 2.1159826240012984

Epoch: 5| Step: 1
Training loss: 0.09826267305660258
Validation loss: 2.10857669759734

Epoch: 5| Step: 2
Training loss: 0.11519867942238583
Validation loss: 2.1399223480419782

Epoch: 5| Step: 3
Training loss: 0.17736155844856624
Validation loss: 2.1012821506852264

Epoch: 5| Step: 4
Training loss: 0.11606710011276732
Validation loss: 2.06378460974358

Epoch: 5| Step: 5
Training loss: 0.11184678643648835
Validation loss: 2.0661494756183876

Epoch: 5| Step: 6
Training loss: 0.09693458459006829
Validation loss: 2.1115315827169896

Epoch: 5| Step: 7
Training loss: 0.11263367522605763
Validation loss: 2.046109175635569

Epoch: 5| Step: 8
Training loss: 0.1178036465973578
Validation loss: 2.0444582916228575

Epoch: 5| Step: 9
Training loss: 0.1745021802518719
Validation loss: 2.0869796231064854

Epoch: 5| Step: 10
Training loss: 0.21008939140413974
Validation loss: 2.069158731691276

Epoch: 537| Step: 0
Training loss: 0.1299253838547583
Validation loss: 2.0632506390813554

Epoch: 5| Step: 1
Training loss: 0.0912890795902339
Validation loss: 2.078918666928686

Epoch: 5| Step: 2
Training loss: 0.105276572900908
Validation loss: 2.060537208511516

Epoch: 5| Step: 3
Training loss: 0.13658731818825487
Validation loss: 2.06768248960781

Epoch: 5| Step: 4
Training loss: 0.26157275440710875
Validation loss: 2.0879569751286096

Epoch: 5| Step: 5
Training loss: 0.16454664955272233
Validation loss: 2.0435890901839775

Epoch: 5| Step: 6
Training loss: 0.10730079416072678
Validation loss: 2.0488867875309373

Epoch: 5| Step: 7
Training loss: 0.12812794908758177
Validation loss: 2.053798239020732

Epoch: 5| Step: 8
Training loss: 0.12100312856770391
Validation loss: 2.0673179802499275

Epoch: 5| Step: 9
Training loss: 0.14663504163612764
Validation loss: 2.0841057295147207

Epoch: 5| Step: 10
Training loss: 0.12530410550603868
Validation loss: 2.0964367750815205

Epoch: 538| Step: 0
Training loss: 0.1630312719496803
Validation loss: 2.110956441590368

Epoch: 5| Step: 1
Training loss: 0.08899187416448144
Validation loss: 2.0697779554526265

Epoch: 5| Step: 2
Training loss: 0.10754182360977718
Validation loss: 2.10351858410095

Epoch: 5| Step: 3
Training loss: 0.12147459009144158
Validation loss: 2.0871675729792862

Epoch: 5| Step: 4
Training loss: 0.12595844138467116
Validation loss: 2.098026130204951

Epoch: 5| Step: 5
Training loss: 0.04339783767891706
Validation loss: 2.0951132942109485

Epoch: 5| Step: 6
Training loss: 0.2537396251032653
Validation loss: 2.1218246699014003

Epoch: 5| Step: 7
Training loss: 0.09722048332394433
Validation loss: 2.1136761471279284

Epoch: 5| Step: 8
Training loss: 0.1281019972295795
Validation loss: 2.0729813792635294

Epoch: 5| Step: 9
Training loss: 0.19354403954403976
Validation loss: 2.051851497996813

Epoch: 5| Step: 10
Training loss: 0.10052895089053047
Validation loss: 2.091725786521877

Epoch: 539| Step: 0
Training loss: 0.114463620794978
Validation loss: 2.071895609668867

Epoch: 5| Step: 1
Training loss: 0.11653492747176862
Validation loss: 2.071780286930617

Epoch: 5| Step: 2
Training loss: 0.18148491450872872
Validation loss: 2.0603798534246267

Epoch: 5| Step: 3
Training loss: 0.13657836518562755
Validation loss: 2.1051909606505466

Epoch: 5| Step: 4
Training loss: 0.12683248656770754
Validation loss: 2.1112174798294703

Epoch: 5| Step: 5
Training loss: 0.1704168345719453
Validation loss: 2.086713637206297

Epoch: 5| Step: 6
Training loss: 0.1204614822258605
Validation loss: 2.1037745391120537

Epoch: 5| Step: 7
Training loss: 0.08157459376732606
Validation loss: 2.078218159301863

Epoch: 5| Step: 8
Training loss: 0.09900399041562652
Validation loss: 2.0801516998865326

Epoch: 5| Step: 9
Training loss: 0.1823292466437328
Validation loss: 2.0624557725297907

Epoch: 5| Step: 10
Training loss: 0.13853918362545886
Validation loss: 2.075135121774938

Epoch: 540| Step: 0
Training loss: 0.11116634292134799
Validation loss: 2.113042907940059

Epoch: 5| Step: 1
Training loss: 0.18680062593772828
Validation loss: 2.0898819642458797

Epoch: 5| Step: 2
Training loss: 0.0792112708182075
Validation loss: 2.104589599078626

Epoch: 5| Step: 3
Training loss: 0.18956656844731476
Validation loss: 2.1067407388039867

Epoch: 5| Step: 4
Training loss: 0.10044861651111554
Validation loss: 2.0770941956616684

Epoch: 5| Step: 5
Training loss: 0.14564780087488663
Validation loss: 2.0612440719682925

Epoch: 5| Step: 6
Training loss: 0.09062927416883834
Validation loss: 2.1122122171793527

Epoch: 5| Step: 7
Training loss: 0.14235215373727986
Validation loss: 2.1336221277236787

Epoch: 5| Step: 8
Training loss: 0.15496916318062565
Validation loss: 2.103341927742972

Epoch: 5| Step: 9
Training loss: 0.1232824832494379
Validation loss: 2.1016842410800862

Epoch: 5| Step: 10
Training loss: 0.109029684595103
Validation loss: 2.106074292590959

Epoch: 541| Step: 0
Training loss: 0.12686205311661825
Validation loss: 2.09700464148931

Epoch: 5| Step: 1
Training loss: 0.1680365303700423
Validation loss: 2.0822838338364305

Epoch: 5| Step: 2
Training loss: 0.12402234489980905
Validation loss: 2.075964990092905

Epoch: 5| Step: 3
Training loss: 0.10910190394423581
Validation loss: 2.0456533561817474

Epoch: 5| Step: 4
Training loss: 0.14406546077664711
Validation loss: 2.058575322682679

Epoch: 5| Step: 5
Training loss: 0.1063014072636262
Validation loss: 2.0499877188239903

Epoch: 5| Step: 6
Training loss: 0.11768140423268401
Validation loss: 2.064403695748134

Epoch: 5| Step: 7
Training loss: 0.17538705707480798
Validation loss: 2.0905871720756495

Epoch: 5| Step: 8
Training loss: 0.10615449515428754
Validation loss: 2.0412103943807742

Epoch: 5| Step: 9
Training loss: 0.07024921443460105
Validation loss: 2.1072516914296955

Epoch: 5| Step: 10
Training loss: 0.14270018225964307
Validation loss: 2.0704706399011927

Epoch: 542| Step: 0
Training loss: 0.08816790552091805
Validation loss: 2.074449728750245

Epoch: 5| Step: 1
Training loss: 0.15466755391616963
Validation loss: 2.0924708769592915

Epoch: 5| Step: 2
Training loss: 0.08559263183602232
Validation loss: 2.068760838009467

Epoch: 5| Step: 3
Training loss: 0.17951265411415496
Validation loss: 2.086569498873129

Epoch: 5| Step: 4
Training loss: 0.19851236770821962
Validation loss: 2.02900320255778

Epoch: 5| Step: 5
Training loss: 0.12379909861102446
Validation loss: 2.066385129447728

Epoch: 5| Step: 6
Training loss: 0.10948232936404373
Validation loss: 2.084281162693767

Epoch: 5| Step: 7
Training loss: 0.1761796304640839
Validation loss: 2.0508337414377142

Epoch: 5| Step: 8
Training loss: 0.14331898834997553
Validation loss: 2.055646781214475

Epoch: 5| Step: 9
Training loss: 0.1161719705662081
Validation loss: 2.0729403330313056

Epoch: 5| Step: 10
Training loss: 0.09380607120284144
Validation loss: 2.086080368893127

Epoch: 543| Step: 0
Training loss: 0.13092822782921845
Validation loss: 2.090794190627667

Epoch: 5| Step: 1
Training loss: 0.19837261475785814
Validation loss: 2.09287736915505

Epoch: 5| Step: 2
Training loss: 0.12844791715844325
Validation loss: 2.072552584737526

Epoch: 5| Step: 3
Training loss: 0.13133335390182557
Validation loss: 2.0734794987513823

Epoch: 5| Step: 4
Training loss: 0.28189726365210305
Validation loss: 2.1335864559904163

Epoch: 5| Step: 5
Training loss: 0.24934762534373714
Validation loss: 2.1218345042222526

Epoch: 5| Step: 6
Training loss: 0.13940920044513802
Validation loss: 2.1109897274455376

Epoch: 5| Step: 7
Training loss: 0.3189533169566
Validation loss: 2.0987520875098147

Epoch: 5| Step: 8
Training loss: 0.19907308376687757
Validation loss: 2.096163484989884

Epoch: 5| Step: 9
Training loss: 0.16828898465224837
Validation loss: 2.0726028920559703

Epoch: 5| Step: 10
Training loss: 0.21810420964689672
Validation loss: 2.0716044930770328

Epoch: 544| Step: 0
Training loss: 0.22800771395962344
Validation loss: 2.037903602809098

Epoch: 5| Step: 1
Training loss: 0.2081714935322145
Validation loss: 2.0813030633404255

Epoch: 5| Step: 2
Training loss: 0.11537982360659066
Validation loss: 2.0949449369471136

Epoch: 5| Step: 3
Training loss: 0.14221991651555785
Validation loss: 2.0603148493388788

Epoch: 5| Step: 4
Training loss: 0.15664403226766332
Validation loss: 2.0925773222580655

Epoch: 5| Step: 5
Training loss: 0.18606236776950125
Validation loss: 2.1352682981013134

Epoch: 5| Step: 6
Training loss: 0.21931962371240785
Validation loss: 2.1404463679475336

Epoch: 5| Step: 7
Training loss: 0.1459976438612283
Validation loss: 2.1182948012725995

Epoch: 5| Step: 8
Training loss: 0.19534591388983752
Validation loss: 2.1038563451884493

Epoch: 5| Step: 9
Training loss: 0.24031189698936098
Validation loss: 2.131574806278533

Epoch: 5| Step: 10
Training loss: 0.23971578402543603
Validation loss: 2.112372473517704

Epoch: 545| Step: 0
Training loss: 0.19125521792979183
Validation loss: 2.099329553737019

Epoch: 5| Step: 1
Training loss: 0.18687732937486945
Validation loss: 2.066517927038572

Epoch: 5| Step: 2
Training loss: 0.15456690277665394
Validation loss: 2.0939852325726642

Epoch: 5| Step: 3
Training loss: 0.208403502012169
Validation loss: 2.0784729043301655

Epoch: 5| Step: 4
Training loss: 0.3221195005259022
Validation loss: 2.057210663685357

Epoch: 5| Step: 5
Training loss: 0.1520490669540954
Validation loss: 2.071492855121826

Epoch: 5| Step: 6
Training loss: 0.2073920542802018
Validation loss: 2.0999119703531997

Epoch: 5| Step: 7
Training loss: 0.3597712405550365
Validation loss: 2.113137062216594

Epoch: 5| Step: 8
Training loss: 0.17586413654539593
Validation loss: 2.1202830198970504

Epoch: 5| Step: 9
Training loss: 0.12346790956193292
Validation loss: 2.071085799419321

Epoch: 5| Step: 10
Training loss: 0.14337571983813546
Validation loss: 2.0617854700672344

Epoch: 546| Step: 0
Training loss: 0.15675710404647333
Validation loss: 2.0534290976993246

Epoch: 5| Step: 1
Training loss: 0.23230289972341253
Validation loss: 2.0611659396998157

Epoch: 5| Step: 2
Training loss: 0.2253874859516909
Validation loss: 2.0740138346384014

Epoch: 5| Step: 3
Training loss: 0.1770292589895501
Validation loss: 2.0596371486411957

Epoch: 5| Step: 4
Training loss: 0.11922147618372766
Validation loss: 2.089804735223011

Epoch: 5| Step: 5
Training loss: 0.1810800865818248
Validation loss: 2.136356782099897

Epoch: 5| Step: 6
Training loss: 0.2700571237508767
Validation loss: 2.14725639923624

Epoch: 5| Step: 7
Training loss: 0.24985348610340127
Validation loss: 2.094879612158851

Epoch: 5| Step: 8
Training loss: 0.20943051249926847
Validation loss: 2.1097191265941238

Epoch: 5| Step: 9
Training loss: 0.1862435362801541
Validation loss: 2.0692184284719026

Epoch: 5| Step: 10
Training loss: 0.14866185174050278
Validation loss: 2.059455617222123

Epoch: 547| Step: 0
Training loss: 0.16306830213758
Validation loss: 2.047282536802434

Epoch: 5| Step: 1
Training loss: 0.20566195987738767
Validation loss: 2.0603318861633553

Epoch: 5| Step: 2
Training loss: 0.16608352394598694
Validation loss: 2.0659773974550437

Epoch: 5| Step: 3
Training loss: 0.18654781202264195
Validation loss: 2.0547275496419877

Epoch: 5| Step: 4
Training loss: 0.20574959319550726
Validation loss: 2.06389189359406

Epoch: 5| Step: 5
Training loss: 0.1660080122604723
Validation loss: 2.09539130560658

Epoch: 5| Step: 6
Training loss: 0.31053485487221477
Validation loss: 2.049051572421758

Epoch: 5| Step: 7
Training loss: 0.3269037726742086
Validation loss: 2.0565874911499376

Epoch: 5| Step: 8
Training loss: 0.1829871545651689
Validation loss: 2.0340724611169443

Epoch: 5| Step: 9
Training loss: 0.14142511489599496
Validation loss: 2.073822306800676

Epoch: 5| Step: 10
Training loss: 0.2117706376009323
Validation loss: 2.055778516015491

Epoch: 548| Step: 0
Training loss: 0.28105800751295196
Validation loss: 2.0733603197862673

Epoch: 5| Step: 1
Training loss: 0.20285919110465306
Validation loss: 2.0674681764395766

Epoch: 5| Step: 2
Training loss: 0.27253563516678053
Validation loss: 2.029634777241549

Epoch: 5| Step: 3
Training loss: 0.14391218811027204
Validation loss: 2.072309596716219

Epoch: 5| Step: 4
Training loss: 0.211139317499642
Validation loss: 2.0830096216867324

Epoch: 5| Step: 5
Training loss: 0.16560284403392245
Validation loss: 2.0789675081476973

Epoch: 5| Step: 6
Training loss: 0.1964692195257514
Validation loss: 2.0837995692477356

Epoch: 5| Step: 7
Training loss: 0.1931686906096212
Validation loss: 2.0925143076969777

Epoch: 5| Step: 8
Training loss: 0.18445348321927552
Validation loss: 2.1016117932946443

Epoch: 5| Step: 9
Training loss: 0.16114677599890323
Validation loss: 2.059333745634176

Epoch: 5| Step: 10
Training loss: 0.15005315966177632
Validation loss: 2.0938343134583506

Epoch: 549| Step: 0
Training loss: 0.21902078659932567
Validation loss: 2.0809253505320475

Epoch: 5| Step: 1
Training loss: 0.3006347448074212
Validation loss: 2.117379914376461

Epoch: 5| Step: 2
Training loss: 0.16708823002047693
Validation loss: 2.104819476037744

Epoch: 5| Step: 3
Training loss: 0.12784382071454636
Validation loss: 2.097198116708421

Epoch: 5| Step: 4
Training loss: 0.2056513450001687
Validation loss: 2.139285328939616

Epoch: 5| Step: 5
Training loss: 0.12714083073095298
Validation loss: 2.109438449113487

Epoch: 5| Step: 6
Training loss: 0.13009867978291126
Validation loss: 2.099962569585348

Epoch: 5| Step: 7
Training loss: 0.1812906174530369
Validation loss: 2.114756556209696

Epoch: 5| Step: 8
Training loss: 0.09510042211208768
Validation loss: 2.0977228277505735

Epoch: 5| Step: 9
Training loss: 0.24038377628730162
Validation loss: 2.131422654146244

Epoch: 5| Step: 10
Training loss: 0.21525941865752585
Validation loss: 2.1186555007254495

Epoch: 550| Step: 0
Training loss: 0.11123133098880995
Validation loss: 2.132006879230361

Epoch: 5| Step: 1
Training loss: 0.18985260797564926
Validation loss: 2.1175292322430925

Epoch: 5| Step: 2
Training loss: 0.15102773566511282
Validation loss: 2.073808345211631

Epoch: 5| Step: 3
Training loss: 0.2593025583194336
Validation loss: 2.0884205292028715

Epoch: 5| Step: 4
Training loss: 0.1652597441711192
Validation loss: 2.097787230550697

Epoch: 5| Step: 5
Training loss: 0.12568362131540844
Validation loss: 2.0834469950854504

Epoch: 5| Step: 6
Training loss: 0.12778843660172767
Validation loss: 2.0568586463617247

Epoch: 5| Step: 7
Training loss: 0.1985362460532912
Validation loss: 2.0662469435529776

Epoch: 5| Step: 8
Training loss: 0.1799819648171318
Validation loss: 2.038829231426989

Epoch: 5| Step: 9
Training loss: 0.1671044212327559
Validation loss: 2.024943976321705

Epoch: 5| Step: 10
Training loss: 0.17836680396403318
Validation loss: 2.0266085810418315

Epoch: 551| Step: 0
Training loss: 0.15882162180251158
Validation loss: 2.0261837685147417

Epoch: 5| Step: 1
Training loss: 0.13243958065078182
Validation loss: 2.04706135715343

Epoch: 5| Step: 2
Training loss: 0.19690813588018907
Validation loss: 2.046395795635058

Epoch: 5| Step: 3
Training loss: 0.14863727327287324
Validation loss: 2.0930100944077132

Epoch: 5| Step: 4
Training loss: 0.20433831059108465
Validation loss: 2.059599495348731

Epoch: 5| Step: 5
Training loss: 0.14991524730899827
Validation loss: 2.061128721681679

Epoch: 5| Step: 6
Training loss: 0.22820667836087924
Validation loss: 2.0453724014859893

Epoch: 5| Step: 7
Training loss: 0.1627177576745803
Validation loss: 2.0523300468170698

Epoch: 5| Step: 8
Training loss: 0.19678228480948548
Validation loss: 2.0632992212394496

Epoch: 5| Step: 9
Training loss: 0.18759550205564635
Validation loss: 2.0297725564148505

Epoch: 5| Step: 10
Training loss: 0.21391138290756023
Validation loss: 2.1076861056818696

Epoch: 552| Step: 0
Training loss: 0.1545406660946815
Validation loss: 2.0665327764951154

Epoch: 5| Step: 1
Training loss: 0.14751471871347246
Validation loss: 2.0714855026388053

Epoch: 5| Step: 2
Training loss: 0.17267869937166835
Validation loss: 2.0501794525675217

Epoch: 5| Step: 3
Training loss: 0.14369106950677651
Validation loss: 2.073328026738475

Epoch: 5| Step: 4
Training loss: 0.1864541409374586
Validation loss: 2.045845435987045

Epoch: 5| Step: 5
Training loss: 0.2360357967142326
Validation loss: 2.0575006601315637

Epoch: 5| Step: 6
Training loss: 0.1717480982119201
Validation loss: 2.0373531348261773

Epoch: 5| Step: 7
Training loss: 0.23947596044386635
Validation loss: 2.0811455747203023

Epoch: 5| Step: 8
Training loss: 0.20230456786622647
Validation loss: 2.075612679655118

Epoch: 5| Step: 9
Training loss: 0.1805646261867095
Validation loss: 2.0652820478633154

Epoch: 5| Step: 10
Training loss: 0.1638000978390957
Validation loss: 2.0897848227343716

Epoch: 553| Step: 0
Training loss: 0.13634764168191024
Validation loss: 2.0849686771203157

Epoch: 5| Step: 1
Training loss: 0.15513287785988766
Validation loss: 2.0904073809828074

Epoch: 5| Step: 2
Training loss: 0.2283387600092612
Validation loss: 2.0875488745641864

Epoch: 5| Step: 3
Training loss: 0.1425952966356638
Validation loss: 2.0426148687882013

Epoch: 5| Step: 4
Training loss: 0.1861919233162304
Validation loss: 2.0303152194158627

Epoch: 5| Step: 5
Training loss: 0.2253567906575153
Validation loss: 2.0490290518636383

Epoch: 5| Step: 6
Training loss: 0.1204507816461345
Validation loss: 2.064605646097806

Epoch: 5| Step: 7
Training loss: 0.2723632145030479
Validation loss: 2.0128032026124196

Epoch: 5| Step: 8
Training loss: 0.23567682164355058
Validation loss: 2.007100557588113

Epoch: 5| Step: 9
Training loss: 0.1739519085716068
Validation loss: 2.008533509046701

Epoch: 5| Step: 10
Training loss: 0.14115684655168811
Validation loss: 2.019733763687813

Epoch: 554| Step: 0
Training loss: 0.15238400685444434
Validation loss: 2.0131117744175766

Epoch: 5| Step: 1
Training loss: 0.13524217933468333
Validation loss: 2.0476333727499214

Epoch: 5| Step: 2
Training loss: 0.2639586408071877
Validation loss: 2.0423564570188444

Epoch: 5| Step: 3
Training loss: 0.15296491507066776
Validation loss: 2.083420269495578

Epoch: 5| Step: 4
Training loss: 0.18616658171613673
Validation loss: 2.083311344358831

Epoch: 5| Step: 5
Training loss: 0.13459786048698966
Validation loss: 2.048650047848065

Epoch: 5| Step: 6
Training loss: 0.08432825237241226
Validation loss: 2.070660683779383

Epoch: 5| Step: 7
Training loss: 0.12225902847313279
Validation loss: 2.092433287062245

Epoch: 5| Step: 8
Training loss: 0.13730461750055864
Validation loss: 2.101202654662066

Epoch: 5| Step: 9
Training loss: 0.18268400387676442
Validation loss: 2.107063454345574

Epoch: 5| Step: 10
Training loss: 0.12803761828736526
Validation loss: 2.1261464825816168

Epoch: 555| Step: 0
Training loss: 0.21174786462517792
Validation loss: 2.1190173836904487

Epoch: 5| Step: 1
Training loss: 0.18837467463730403
Validation loss: 2.0941147710732855

Epoch: 5| Step: 2
Training loss: 0.14380523330594017
Validation loss: 2.1149591204657843

Epoch: 5| Step: 3
Training loss: 0.18300736914777435
Validation loss: 2.0613298623759517

Epoch: 5| Step: 4
Training loss: 0.11826112402113567
Validation loss: 2.0915790638752894

Epoch: 5| Step: 5
Training loss: 0.16694683998498416
Validation loss: 2.0704727627806636

Epoch: 5| Step: 6
Training loss: 0.14107515552626423
Validation loss: 2.0676643584085608

Epoch: 5| Step: 7
Training loss: 0.17219781903537262
Validation loss: 2.029247980340928

Epoch: 5| Step: 8
Training loss: 0.18155088566451386
Validation loss: 2.031974138369604

Epoch: 5| Step: 9
Training loss: 0.15045466855273806
Validation loss: 2.0640130880232928

Epoch: 5| Step: 10
Training loss: 0.22178407975469439
Validation loss: 2.0505757484272635

Epoch: 556| Step: 0
Training loss: 0.12867198956825515
Validation loss: 2.0703760726681284

Epoch: 5| Step: 1
Training loss: 0.19845238239319685
Validation loss: 2.103421450778548

Epoch: 5| Step: 2
Training loss: 0.128549870679268
Validation loss: 2.0593430424395582

Epoch: 5| Step: 3
Training loss: 0.08953523012038962
Validation loss: 2.0743024490247697

Epoch: 5| Step: 4
Training loss: 0.19794289306409846
Validation loss: 2.0905995022625548

Epoch: 5| Step: 5
Training loss: 0.19719485155841152
Validation loss: 2.0924690514494335

Epoch: 5| Step: 6
Training loss: 0.13854243725249257
Validation loss: 2.1350042401570164

Epoch: 5| Step: 7
Training loss: 0.1878270733712401
Validation loss: 2.12624908498368

Epoch: 5| Step: 8
Training loss: 0.1960271064767963
Validation loss: 2.122125790647589

Epoch: 5| Step: 9
Training loss: 0.1293600144322683
Validation loss: 2.138922530292662

Epoch: 5| Step: 10
Training loss: 0.1377591330162581
Validation loss: 2.138081568258656

Epoch: 557| Step: 0
Training loss: 0.1634274749708211
Validation loss: 2.135671395616453

Epoch: 5| Step: 1
Training loss: 0.1426955484199819
Validation loss: 2.13500951751734

Epoch: 5| Step: 2
Training loss: 0.16474614304483579
Validation loss: 2.1150695647493425

Epoch: 5| Step: 3
Training loss: 0.11982356213527307
Validation loss: 2.1189981485922504

Epoch: 5| Step: 4
Training loss: 0.10351908426082847
Validation loss: 2.1055203395203796

Epoch: 5| Step: 5
Training loss: 0.10016988613836042
Validation loss: 2.1084826357420865

Epoch: 5| Step: 6
Training loss: 0.09927279040701428
Validation loss: 2.0933696448485852

Epoch: 5| Step: 7
Training loss: 0.13009619572988942
Validation loss: 2.0905670242343293

Epoch: 5| Step: 8
Training loss: 0.08183505802091652
Validation loss: 2.098910541540464

Epoch: 5| Step: 9
Training loss: 0.18892243375152123
Validation loss: 2.073093089783654

Epoch: 5| Step: 10
Training loss: 0.15570780738914083
Validation loss: 2.075029218576465

Epoch: 558| Step: 0
Training loss: 0.15120358393296832
Validation loss: 2.0802812611810095

Epoch: 5| Step: 1
Training loss: 0.19451483921551432
Validation loss: 2.0487493915954

Epoch: 5| Step: 2
Training loss: 0.20249245345512024
Validation loss: 2.07197103596256

Epoch: 5| Step: 3
Training loss: 0.1453007818952691
Validation loss: 2.1078172602279306

Epoch: 5| Step: 4
Training loss: 0.15045978145075026
Validation loss: 2.096659548072906

Epoch: 5| Step: 5
Training loss: 0.07859604806554872
Validation loss: 2.1192728162326433

Epoch: 5| Step: 6
Training loss: 0.1632442676606086
Validation loss: 2.095103738567183

Epoch: 5| Step: 7
Training loss: 0.1162673108225132
Validation loss: 2.1209537605926854

Epoch: 5| Step: 8
Training loss: 0.15093065503989767
Validation loss: 2.108584043238999

Epoch: 5| Step: 9
Training loss: 0.09832505566686096
Validation loss: 2.1393436650599624

Epoch: 5| Step: 10
Training loss: 0.10404934584471788
Validation loss: 2.1318984704178288

Epoch: 559| Step: 0
Training loss: 0.12048554346094094
Validation loss: 2.1412900621051474

Epoch: 5| Step: 1
Training loss: 0.10989963777640137
Validation loss: 2.1005364907618387

Epoch: 5| Step: 2
Training loss: 0.1490383160764349
Validation loss: 2.1252175508692206

Epoch: 5| Step: 3
Training loss: 0.13048866770949316
Validation loss: 2.1072392451694393

Epoch: 5| Step: 4
Training loss: 0.16672980458685185
Validation loss: 2.1024796570228346

Epoch: 5| Step: 5
Training loss: 0.16037905709404301
Validation loss: 2.069872245948105

Epoch: 5| Step: 6
Training loss: 0.1772174234032861
Validation loss: 2.0626481824279024

Epoch: 5| Step: 7
Training loss: 0.10318997279819667
Validation loss: 2.064521904125423

Epoch: 5| Step: 8
Training loss: 0.12152065505052242
Validation loss: 2.0617515981105154

Epoch: 5| Step: 9
Training loss: 0.20593492363054774
Validation loss: 2.0595787636814324

Epoch: 5| Step: 10
Training loss: 0.11333725629998884
Validation loss: 2.0919157517794673

Epoch: 560| Step: 0
Training loss: 0.09940731366675847
Validation loss: 2.0527078246633397

Epoch: 5| Step: 1
Training loss: 0.12196893296923195
Validation loss: 2.081796641326834

Epoch: 5| Step: 2
Training loss: 0.16064973724185247
Validation loss: 2.0664125908379574

Epoch: 5| Step: 3
Training loss: 0.09193014555397397
Validation loss: 2.0673912522057214

Epoch: 5| Step: 4
Training loss: 0.10874617705531574
Validation loss: 2.0667006988068644

Epoch: 5| Step: 5
Training loss: 0.13278982024928487
Validation loss: 2.0729548347246074

Epoch: 5| Step: 6
Training loss: 0.20766731834047863
Validation loss: 2.080995009960166

Epoch: 5| Step: 7
Training loss: 0.15924245965725992
Validation loss: 2.0612195994785463

Epoch: 5| Step: 8
Training loss: 0.10488514231646164
Validation loss: 2.0503818205406836

Epoch: 5| Step: 9
Training loss: 0.0920777285586914
Validation loss: 2.056821420202363

Epoch: 5| Step: 10
Training loss: 0.09888088548164024
Validation loss: 2.0489986904752593

Epoch: 561| Step: 0
Training loss: 0.12037726677833041
Validation loss: 2.091041009921427

Epoch: 5| Step: 1
Training loss: 0.1620618451771304
Validation loss: 2.0504668132720334

Epoch: 5| Step: 2
Training loss: 0.12015821950114372
Validation loss: 2.0763226129478483

Epoch: 5| Step: 3
Training loss: 0.12426164234426804
Validation loss: 2.0497399877812654

Epoch: 5| Step: 4
Training loss: 0.09263870092366862
Validation loss: 2.103275262145306

Epoch: 5| Step: 5
Training loss: 0.08666380202487146
Validation loss: 2.0743460543823447

Epoch: 5| Step: 6
Training loss: 0.08580597110459563
Validation loss: 2.103165617354048

Epoch: 5| Step: 7
Training loss: 0.13622585411869875
Validation loss: 2.0817336624910032

Epoch: 5| Step: 8
Training loss: 0.21573955872035974
Validation loss: 2.0591116648695373

Epoch: 5| Step: 9
Training loss: 0.13064202007264678
Validation loss: 2.0641961989444013

Epoch: 5| Step: 10
Training loss: 0.08828901756767504
Validation loss: 2.0617944002044566

Epoch: 562| Step: 0
Training loss: 0.10505549832471785
Validation loss: 2.0575491568968873

Epoch: 5| Step: 1
Training loss: 0.14854840477239684
Validation loss: 2.082862890307698

Epoch: 5| Step: 2
Training loss: 0.12461607057048027
Validation loss: 2.0742232893480517

Epoch: 5| Step: 3
Training loss: 0.07205314909988406
Validation loss: 2.0563272525456076

Epoch: 5| Step: 4
Training loss: 0.08071140188700764
Validation loss: 2.068830366748126

Epoch: 5| Step: 5
Training loss: 0.18613407178614913
Validation loss: 2.0720205791604527

Epoch: 5| Step: 6
Training loss: 0.11402491936761305
Validation loss: 2.037514066241834

Epoch: 5| Step: 7
Training loss: 0.09776640877814187
Validation loss: 2.0574722773592233

Epoch: 5| Step: 8
Training loss: 0.08530953843614536
Validation loss: 2.031458427646618

Epoch: 5| Step: 9
Training loss: 0.17777165870723757
Validation loss: 2.0088434526413743

Epoch: 5| Step: 10
Training loss: 0.1749267578125
Validation loss: 2.0414765709792317

Epoch: 563| Step: 0
Training loss: 0.12299769796372703
Validation loss: 2.057078091516979

Epoch: 5| Step: 1
Training loss: 0.0692028157932904
Validation loss: 2.030214291439042

Epoch: 5| Step: 2
Training loss: 0.17217784448645776
Validation loss: 2.058992274942633

Epoch: 5| Step: 3
Training loss: 0.12652141822647503
Validation loss: 2.063624687227006

Epoch: 5| Step: 4
Training loss: 0.13199058222408394
Validation loss: 2.093080976059349

Epoch: 5| Step: 5
Training loss: 0.15063915524509103
Validation loss: 2.1086435694395136

Epoch: 5| Step: 6
Training loss: 0.11730034084314248
Validation loss: 2.0689162335229665

Epoch: 5| Step: 7
Training loss: 0.09098713432987426
Validation loss: 2.0748885973229783

Epoch: 5| Step: 8
Training loss: 0.13229092393751732
Validation loss: 2.090063975271994

Epoch: 5| Step: 9
Training loss: 0.16816084988280042
Validation loss: 2.096867618853756

Epoch: 5| Step: 10
Training loss: 0.08381416293851299
Validation loss: 2.084894319877192

Epoch: 564| Step: 0
Training loss: 0.07142265748496864
Validation loss: 2.0738257656604313

Epoch: 5| Step: 1
Training loss: 0.22257811865332913
Validation loss: 2.1084108507752792

Epoch: 5| Step: 2
Training loss: 0.10168438713359476
Validation loss: 2.076723343878951

Epoch: 5| Step: 3
Training loss: 0.07467975305438045
Validation loss: 2.05553097651556

Epoch: 5| Step: 4
Training loss: 0.14054321851527646
Validation loss: 2.0936714504141247

Epoch: 5| Step: 5
Training loss: 0.1308584853754122
Validation loss: 2.0541469050436567

Epoch: 5| Step: 6
Training loss: 0.0749983840758368
Validation loss: 2.0723951733630877

Epoch: 5| Step: 7
Training loss: 0.11758026425262671
Validation loss: 2.0790985982405368

Epoch: 5| Step: 8
Training loss: 0.1466692838268243
Validation loss: 2.066455317479817

Epoch: 5| Step: 9
Training loss: 0.09322143603440816
Validation loss: 2.062944486769316

Epoch: 5| Step: 10
Training loss: 0.13261707738498166
Validation loss: 2.0447074512176595

Epoch: 565| Step: 0
Training loss: 0.08764521722754227
Validation loss: 2.0819800296577995

Epoch: 5| Step: 1
Training loss: 0.07761819486535479
Validation loss: 2.071190131776274

Epoch: 5| Step: 2
Training loss: 0.08496759651659605
Validation loss: 2.0714063228738073

Epoch: 5| Step: 3
Training loss: 0.1618950472572802
Validation loss: 2.0658381518009623

Epoch: 5| Step: 4
Training loss: 0.12989581910596992
Validation loss: 2.0645779483378455

Epoch: 5| Step: 5
Training loss: 0.11622986118527723
Validation loss: 2.0718463734438495

Epoch: 5| Step: 6
Training loss: 0.10000818487288306
Validation loss: 2.0888543856246233

Epoch: 5| Step: 7
Training loss: 0.1312776825866676
Validation loss: 2.090830693904052

Epoch: 5| Step: 8
Training loss: 0.20908390776617516
Validation loss: 2.0681360563367686

Epoch: 5| Step: 9
Training loss: 0.11642782024254889
Validation loss: 2.0631142475669226

Epoch: 5| Step: 10
Training loss: 0.09281058822454626
Validation loss: 2.076692530189283

Epoch: 566| Step: 0
Training loss: 0.10941643440974169
Validation loss: 2.073090789967336

Epoch: 5| Step: 1
Training loss: 0.10917387078474088
Validation loss: 2.112151466433196

Epoch: 5| Step: 2
Training loss: 0.11081630608110621
Validation loss: 2.071477314446874

Epoch: 5| Step: 3
Training loss: 0.11341046905159101
Validation loss: 2.0392621174089363

Epoch: 5| Step: 4
Training loss: 0.10082089195247528
Validation loss: 2.0460498903046838

Epoch: 5| Step: 5
Training loss: 0.15543808395013764
Validation loss: 2.059897731061768

Epoch: 5| Step: 6
Training loss: 0.13821633156685936
Validation loss: 2.0445515661615676

Epoch: 5| Step: 7
Training loss: 0.10579939952058652
Validation loss: 2.0692558546984965

Epoch: 5| Step: 8
Training loss: 0.16431212734907108
Validation loss: 2.0553892033755887

Epoch: 5| Step: 9
Training loss: 0.1179530805955814
Validation loss: 2.0651221811001026

Epoch: 5| Step: 10
Training loss: 0.11763077979476491
Validation loss: 2.0616043106124016

Epoch: 567| Step: 0
Training loss: 0.11980539265721438
Validation loss: 2.06100725813144

Epoch: 5| Step: 1
Training loss: 0.12326446096156202
Validation loss: 2.045040253612788

Epoch: 5| Step: 2
Training loss: 0.18081240363304715
Validation loss: 2.057963674586371

Epoch: 5| Step: 3
Training loss: 0.13678081329926153
Validation loss: 2.0451036641922253

Epoch: 5| Step: 4
Training loss: 0.1205306767206996
Validation loss: 2.0712702295259082

Epoch: 5| Step: 5
Training loss: 0.10027087041513495
Validation loss: 2.067793170972555

Epoch: 5| Step: 6
Training loss: 0.10741544184061663
Validation loss: 2.069007342334916

Epoch: 5| Step: 7
Training loss: 0.1152187393378327
Validation loss: 2.0624326481765

Epoch: 5| Step: 8
Training loss: 0.09187955886370962
Validation loss: 2.041536979268968

Epoch: 5| Step: 9
Training loss: 0.16473390933273743
Validation loss: 2.0437390232108137

Epoch: 5| Step: 10
Training loss: 0.08038206686059095
Validation loss: 2.0403637331271796

Epoch: 568| Step: 0
Training loss: 0.08207908439148145
Validation loss: 2.066697228642702

Epoch: 5| Step: 1
Training loss: 0.11718109828629485
Validation loss: 2.046642136480734

Epoch: 5| Step: 2
Training loss: 0.12044768881595479
Validation loss: 2.033274624896696

Epoch: 5| Step: 3
Training loss: 0.12444384351700681
Validation loss: 2.0436500883396795

Epoch: 5| Step: 4
Training loss: 0.17773479419700736
Validation loss: 2.0300772715297666

Epoch: 5| Step: 5
Training loss: 0.12438450466672818
Validation loss: 2.050462202889944

Epoch: 5| Step: 6
Training loss: 0.12024038091609442
Validation loss: 2.0593349799406275

Epoch: 5| Step: 7
Training loss: 0.10568109523122957
Validation loss: 2.0304911474634846

Epoch: 5| Step: 8
Training loss: 0.09008936893728528
Validation loss: 2.027017632000931

Epoch: 5| Step: 9
Training loss: 0.13878197396082464
Validation loss: 2.0286465464926176

Epoch: 5| Step: 10
Training loss: 0.18816930798803158
Validation loss: 2.080097956632439

Epoch: 569| Step: 0
Training loss: 0.11803035422296544
Validation loss: 2.0673156730789413

Epoch: 5| Step: 1
Training loss: 0.06352857512834799
Validation loss: 2.07790803605556

Epoch: 5| Step: 2
Training loss: 0.11758758278762013
Validation loss: 2.0818605867679723

Epoch: 5| Step: 3
Training loss: 0.08456361702278516
Validation loss: 2.1007451489436044

Epoch: 5| Step: 4
Training loss: 0.09168137731242275
Validation loss: 2.083428121276762

Epoch: 5| Step: 5
Training loss: 0.10478594300613762
Validation loss: 2.050342523745889

Epoch: 5| Step: 6
Training loss: 0.1742048467553931
Validation loss: 2.1109744049781347

Epoch: 5| Step: 7
Training loss: 0.15543930623140492
Validation loss: 2.065699213228886

Epoch: 5| Step: 8
Training loss: 0.12475077549678058
Validation loss: 2.0627981954164736

Epoch: 5| Step: 9
Training loss: 0.14043839312270684
Validation loss: 2.067921099031713

Epoch: 5| Step: 10
Training loss: 0.11787465018253866
Validation loss: 2.0461469537657724

Epoch: 570| Step: 0
Training loss: 0.10426194234610166
Validation loss: 2.0641852622518266

Epoch: 5| Step: 1
Training loss: 0.09003380182914032
Validation loss: 2.039820655428754

Epoch: 5| Step: 2
Training loss: 0.09528642067027106
Validation loss: 2.050075433375186

Epoch: 5| Step: 3
Training loss: 0.11276587041024991
Validation loss: 2.074948158288661

Epoch: 5| Step: 4
Training loss: 0.10940616453184326
Validation loss: 2.0580448834648477

Epoch: 5| Step: 5
Training loss: 0.15829603386925567
Validation loss: 2.0510447149391

Epoch: 5| Step: 6
Training loss: 0.09581514050645594
Validation loss: 2.0765433771234747

Epoch: 5| Step: 7
Training loss: 0.13371799837058532
Validation loss: 2.0535190878019223

Epoch: 5| Step: 8
Training loss: 0.1766709172064396
Validation loss: 2.102273526997437

Epoch: 5| Step: 9
Training loss: 0.1853854430801085
Validation loss: 2.06552565036638

Epoch: 5| Step: 10
Training loss: 0.11879339193942529
Validation loss: 2.0434806024254852

Epoch: 571| Step: 0
Training loss: 0.2560338742943346
Validation loss: 2.053011131103881

Epoch: 5| Step: 1
Training loss: 0.16703237083565722
Validation loss: 2.054073630542423

Epoch: 5| Step: 2
Training loss: 0.14035832763301484
Validation loss: 2.085001777828569

Epoch: 5| Step: 3
Training loss: 0.16610466869168658
Validation loss: 2.0953151856567382

Epoch: 5| Step: 4
Training loss: 0.15870711615635585
Validation loss: 2.078759389500725

Epoch: 5| Step: 5
Training loss: 0.10057831707577976
Validation loss: 2.101217887947184

Epoch: 5| Step: 6
Training loss: 0.14697197188411315
Validation loss: 2.105951988462379

Epoch: 5| Step: 7
Training loss: 0.1581425315294241
Validation loss: 2.0966750980361377

Epoch: 5| Step: 8
Training loss: 0.15182240853025575
Validation loss: 2.0914279769524042

Epoch: 5| Step: 9
Training loss: 0.07638754329465589
Validation loss: 2.04620083701248

Epoch: 5| Step: 10
Training loss: 0.1508311964730209
Validation loss: 2.067471190853976

Epoch: 572| Step: 0
Training loss: 0.07719798247591432
Validation loss: 2.0270050513242537

Epoch: 5| Step: 1
Training loss: 0.12719699471530876
Validation loss: 2.0348632090096888

Epoch: 5| Step: 2
Training loss: 0.12610723682160574
Validation loss: 2.0437864629673816

Epoch: 5| Step: 3
Training loss: 0.17112279606222625
Validation loss: 2.058254987034285

Epoch: 5| Step: 4
Training loss: 0.19349890789566576
Validation loss: 2.0580037417540478

Epoch: 5| Step: 5
Training loss: 0.15678690218607358
Validation loss: 2.022815111497039

Epoch: 5| Step: 6
Training loss: 0.16184817378149874
Validation loss: 2.043577388365628

Epoch: 5| Step: 7
Training loss: 0.2212074560275069
Validation loss: 2.0170232386236986

Epoch: 5| Step: 8
Training loss: 0.07975910186248512
Validation loss: 2.0740887828083334

Epoch: 5| Step: 9
Training loss: 0.09038519454772839
Validation loss: 2.052462213708072

Epoch: 5| Step: 10
Training loss: 0.16349154418513964
Validation loss: 2.098431904846663

Epoch: 573| Step: 0
Training loss: 0.12772271835148769
Validation loss: 2.0967525028573233

Epoch: 5| Step: 1
Training loss: 0.125138303122412
Validation loss: 2.107988880023377

Epoch: 5| Step: 2
Training loss: 0.10254515221087472
Validation loss: 2.1060932732453628

Epoch: 5| Step: 3
Training loss: 0.07239866254044376
Validation loss: 2.0909713234841503

Epoch: 5| Step: 4
Training loss: 0.2035479177675355
Validation loss: 2.1076043491218686

Epoch: 5| Step: 5
Training loss: 0.10153192279929729
Validation loss: 2.0964663875572787

Epoch: 5| Step: 6
Training loss: 0.14520534979461125
Validation loss: 2.0990007905587933

Epoch: 5| Step: 7
Training loss: 0.13907808259389703
Validation loss: 2.0543859316572903

Epoch: 5| Step: 8
Training loss: 0.08780687368430617
Validation loss: 2.0565118649547602

Epoch: 5| Step: 9
Training loss: 0.18624145603424336
Validation loss: 2.066735377180067

Epoch: 5| Step: 10
Training loss: 0.13715571329607615
Validation loss: 2.04388446426359

Epoch: 574| Step: 0
Training loss: 0.09373985672755551
Validation loss: 2.0288066812620786

Epoch: 5| Step: 1
Training loss: 0.17737236464292092
Validation loss: 2.0161312046654594

Epoch: 5| Step: 2
Training loss: 0.15213231550993622
Validation loss: 2.0044304308205017

Epoch: 5| Step: 3
Training loss: 0.12237670212902314
Validation loss: 2.0323971490010915

Epoch: 5| Step: 4
Training loss: 0.1997844201004558
Validation loss: 2.011182108737099

Epoch: 5| Step: 5
Training loss: 0.1460359703899412
Validation loss: 2.0300178823345694

Epoch: 5| Step: 6
Training loss: 0.12472379612087424
Validation loss: 2.032022831176744

Epoch: 5| Step: 7
Training loss: 0.07941875322883331
Validation loss: 2.06143980598424

Epoch: 5| Step: 8
Training loss: 0.0873854263811693
Validation loss: 2.0744177446279255

Epoch: 5| Step: 9
Training loss: 0.18983222942168082
Validation loss: 2.0646613546470913

Epoch: 5| Step: 10
Training loss: 0.08532799978199887
Validation loss: 2.093819459275136

Epoch: 575| Step: 0
Training loss: 0.15122855205816518
Validation loss: 2.1057879333297755

Epoch: 5| Step: 1
Training loss: 0.14182775124490848
Validation loss: 2.097323066742362

Epoch: 5| Step: 2
Training loss: 0.08468970489446935
Validation loss: 2.0781400588861847

Epoch: 5| Step: 3
Training loss: 0.09974628277415809
Validation loss: 2.1084845811330775

Epoch: 5| Step: 4
Training loss: 0.10135254340703155
Validation loss: 2.0914851345168324

Epoch: 5| Step: 5
Training loss: 0.1535517955712465
Validation loss: 2.1044636698204084

Epoch: 5| Step: 6
Training loss: 0.11645067154646481
Validation loss: 2.061639099580747

Epoch: 5| Step: 7
Training loss: 0.08055157958498486
Validation loss: 2.0755028383379654

Epoch: 5| Step: 8
Training loss: 0.10595776957593063
Validation loss: 2.080648851896159

Epoch: 5| Step: 9
Training loss: 0.10085694830181652
Validation loss: 2.0523546265558896

Epoch: 5| Step: 10
Training loss: 0.16183354569568345
Validation loss: 2.037743963695223

Epoch: 576| Step: 0
Training loss: 0.10812325817976355
Validation loss: 2.0369997977163044

Epoch: 5| Step: 1
Training loss: 0.09939586907609148
Validation loss: 2.056894111357683

Epoch: 5| Step: 2
Training loss: 0.1117040494436883
Validation loss: 2.0509145016993

Epoch: 5| Step: 3
Training loss: 0.11498008164861803
Validation loss: 2.0701439982200327

Epoch: 5| Step: 4
Training loss: 0.08960411517795809
Validation loss: 2.073398225175882

Epoch: 5| Step: 5
Training loss: 0.20895094916157092
Validation loss: 2.079265323870898

Epoch: 5| Step: 6
Training loss: 0.12466974888552151
Validation loss: 2.06112666318464

Epoch: 5| Step: 7
Training loss: 0.09975228622990684
Validation loss: 2.099043027288234

Epoch: 5| Step: 8
Training loss: 0.1653843996735059
Validation loss: 2.063689419972208

Epoch: 5| Step: 9
Training loss: 0.08747111444013489
Validation loss: 2.0778541545730795

Epoch: 5| Step: 10
Training loss: 0.1458146936277781
Validation loss: 2.041563818347859

Epoch: 577| Step: 0
Training loss: 0.08891288923604442
Validation loss: 2.05537378073187

Epoch: 5| Step: 1
Training loss: 0.14404604633728935
Validation loss: 2.048394299461292

Epoch: 5| Step: 2
Training loss: 0.12087704125606877
Validation loss: 2.0022293325268983

Epoch: 5| Step: 3
Training loss: 0.10823179013340575
Validation loss: 2.0363476702212187

Epoch: 5| Step: 4
Training loss: 0.1571620666715473
Validation loss: 2.0326867997247495

Epoch: 5| Step: 5
Training loss: 0.16953535074996454
Validation loss: 2.0653930291548117

Epoch: 5| Step: 6
Training loss: 0.10357963184596249
Validation loss: 2.058894815951062

Epoch: 5| Step: 7
Training loss: 0.18136357128211567
Validation loss: 2.0663084272995276

Epoch: 5| Step: 8
Training loss: 0.10752226300281673
Validation loss: 2.070372386398244

Epoch: 5| Step: 9
Training loss: 0.09187388233718172
Validation loss: 2.0704164893327692

Epoch: 5| Step: 10
Training loss: 0.11784797353214037
Validation loss: 2.068256576294938

Epoch: 578| Step: 0
Training loss: 0.11251772287296524
Validation loss: 2.05537956564002

Epoch: 5| Step: 1
Training loss: 0.1678595354185427
Validation loss: 2.045628324339869

Epoch: 5| Step: 2
Training loss: 0.1001391115641172
Validation loss: 2.0791614435819037

Epoch: 5| Step: 3
Training loss: 0.11607918362989073
Validation loss: 2.0802404082813886

Epoch: 5| Step: 4
Training loss: 0.11279705172328207
Validation loss: 2.073278019558992

Epoch: 5| Step: 5
Training loss: 0.19780582641203776
Validation loss: 2.044408413424768

Epoch: 5| Step: 6
Training loss: 0.10610271581707333
Validation loss: 2.050214587324755

Epoch: 5| Step: 7
Training loss: 0.09169800994206304
Validation loss: 2.062612341577243

Epoch: 5| Step: 8
Training loss: 0.08339217897289214
Validation loss: 2.061235571646429

Epoch: 5| Step: 9
Training loss: 0.12051381941651651
Validation loss: 2.0621864276868136

Epoch: 5| Step: 10
Training loss: 0.12331636375990339
Validation loss: 2.080200517084653

Epoch: 579| Step: 0
Training loss: 0.1692455468486469
Validation loss: 2.069840301015446

Epoch: 5| Step: 1
Training loss: 0.15607754607956806
Validation loss: 2.0391474490696275

Epoch: 5| Step: 2
Training loss: 0.10107489599470938
Validation loss: 2.0928572121251867

Epoch: 5| Step: 3
Training loss: 0.11590720402290765
Validation loss: 2.058232730344767

Epoch: 5| Step: 4
Training loss: 0.16124478120084104
Validation loss: 2.067216718379768

Epoch: 5| Step: 5
Training loss: 0.08593418375032334
Validation loss: 2.080947489557342

Epoch: 5| Step: 6
Training loss: 0.10837682731973237
Validation loss: 2.0551747053611895

Epoch: 5| Step: 7
Training loss: 0.1227755127724426
Validation loss: 2.0500504205137187

Epoch: 5| Step: 8
Training loss: 0.16749728371424713
Validation loss: 2.0645220239552557

Epoch: 5| Step: 9
Training loss: 0.13246473895833144
Validation loss: 2.048191421573651

Epoch: 5| Step: 10
Training loss: 0.1167387276970105
Validation loss: 2.0547452740949432

Epoch: 580| Step: 0
Training loss: 0.10624550080590614
Validation loss: 2.060472381089697

Epoch: 5| Step: 1
Training loss: 0.07408744088256315
Validation loss: 2.0429634155813656

Epoch: 5| Step: 2
Training loss: 0.11852665118763257
Validation loss: 2.05806840029649

Epoch: 5| Step: 3
Training loss: 0.1152934311009797
Validation loss: 2.065878374930202

Epoch: 5| Step: 4
Training loss: 0.13780825291574725
Validation loss: 2.0654651846795717

Epoch: 5| Step: 5
Training loss: 0.07912938193926657
Validation loss: 2.0619693382933715

Epoch: 5| Step: 6
Training loss: 0.1858768941376152
Validation loss: 2.0992643940874274

Epoch: 5| Step: 7
Training loss: 0.14435678339263958
Validation loss: 2.0791411788548406

Epoch: 5| Step: 8
Training loss: 0.14885558678483715
Validation loss: 2.0753175398114694

Epoch: 5| Step: 9
Training loss: 0.0874117414654049
Validation loss: 2.0511177823649267

Epoch: 5| Step: 10
Training loss: 0.16007838449787573
Validation loss: 2.083205399943365

Epoch: 581| Step: 0
Training loss: 0.11006249062951312
Validation loss: 2.076742725493788

Epoch: 5| Step: 1
Training loss: 0.09665478279623256
Validation loss: 2.0852642465316253

Epoch: 5| Step: 2
Training loss: 0.15915828397115173
Validation loss: 2.080544386389314

Epoch: 5| Step: 3
Training loss: 0.14711684697765942
Validation loss: 2.06334672379241

Epoch: 5| Step: 4
Training loss: 0.09758867309861284
Validation loss: 2.066811432748224

Epoch: 5| Step: 5
Training loss: 0.08717151080778701
Validation loss: 2.0396840533509817

Epoch: 5| Step: 6
Training loss: 0.11780797885193069
Validation loss: 2.100148183259808

Epoch: 5| Step: 7
Training loss: 0.08900784270953109
Validation loss: 2.0696163784886843

Epoch: 5| Step: 8
Training loss: 0.12488921665407929
Validation loss: 2.055475982120601

Epoch: 5| Step: 9
Training loss: 0.14008120191421197
Validation loss: 2.062466297638732

Epoch: 5| Step: 10
Training loss: 0.07571763534370947
Validation loss: 2.0829501724650714

Epoch: 582| Step: 0
Training loss: 0.20094102743680434
Validation loss: 2.0643293900701374

Epoch: 5| Step: 1
Training loss: 0.10660119847465808
Validation loss: 2.055740583787943

Epoch: 5| Step: 2
Training loss: 0.12450427612799336
Validation loss: 2.08065402531729

Epoch: 5| Step: 3
Training loss: 0.14186030458813179
Validation loss: 2.0520807964466887

Epoch: 5| Step: 4
Training loss: 0.14804427866810535
Validation loss: 2.039370079103352

Epoch: 5| Step: 5
Training loss: 0.10808849701161849
Validation loss: 2.0139149468131317

Epoch: 5| Step: 6
Training loss: 0.07621034543263494
Validation loss: 2.0444280167494493

Epoch: 5| Step: 7
Training loss: 0.1333240376959914
Validation loss: 2.0131954919720836

Epoch: 5| Step: 8
Training loss: 0.18331792077569553
Validation loss: 2.033067163355849

Epoch: 5| Step: 9
Training loss: 0.13070713268504217
Validation loss: 2.0269733613574434

Epoch: 5| Step: 10
Training loss: 0.08597978721924966
Validation loss: 2.041182807284563

Epoch: 583| Step: 0
Training loss: 0.0903653160838706
Validation loss: 2.0574683748375837

Epoch: 5| Step: 1
Training loss: 0.1235149201114237
Validation loss: 2.0546957235968315

Epoch: 5| Step: 2
Training loss: 0.20219420868534826
Validation loss: 2.0531961890169104

Epoch: 5| Step: 3
Training loss: 0.11847269327352475
Validation loss: 2.051910737519045

Epoch: 5| Step: 4
Training loss: 0.12328897229002733
Validation loss: 2.051631320734103

Epoch: 5| Step: 5
Training loss: 0.11403360948084314
Validation loss: 2.048153132290204

Epoch: 5| Step: 6
Training loss: 0.1522514234665785
Validation loss: 2.08176161842809

Epoch: 5| Step: 7
Training loss: 0.1273829007959981
Validation loss: 2.0500792049110617

Epoch: 5| Step: 8
Training loss: 0.11977650625935518
Validation loss: 2.0463342347609847

Epoch: 5| Step: 9
Training loss: 0.06960049379893979
Validation loss: 2.046108477750972

Epoch: 5| Step: 10
Training loss: 0.09650888672178863
Validation loss: 2.0477544076972154

Epoch: 584| Step: 0
Training loss: 0.08062983819025524
Validation loss: 2.029468083559863

Epoch: 5| Step: 1
Training loss: 0.14625896276617997
Validation loss: 2.0481813916792744

Epoch: 5| Step: 2
Training loss: 0.0932892563992536
Validation loss: 2.047050339716826

Epoch: 5| Step: 3
Training loss: 0.11095298336671644
Validation loss: 2.0613218182194646

Epoch: 5| Step: 4
Training loss: 0.16401212918100302
Validation loss: 2.031529658954417

Epoch: 5| Step: 5
Training loss: 0.12150395425716765
Validation loss: 2.011437658975398

Epoch: 5| Step: 6
Training loss: 0.14465852237151913
Validation loss: 2.020644528502451

Epoch: 5| Step: 7
Training loss: 0.08460136761820353
Validation loss: 2.034852044109002

Epoch: 5| Step: 8
Training loss: 0.10976694757879754
Validation loss: 2.042403256725144

Epoch: 5| Step: 9
Training loss: 0.12932619413580038
Validation loss: 2.039041405509237

Epoch: 5| Step: 10
Training loss: 0.1897998174218032
Validation loss: 2.0592532794572533

Epoch: 585| Step: 0
Training loss: 0.11765210716836524
Validation loss: 2.0676937419434065

Epoch: 5| Step: 1
Training loss: 0.10142488509703614
Validation loss: 2.0578722403423817

Epoch: 5| Step: 2
Training loss: 0.10415954317133855
Validation loss: 2.0513439550689503

Epoch: 5| Step: 3
Training loss: 0.09694473944248776
Validation loss: 2.0510284321740877

Epoch: 5| Step: 4
Training loss: 0.10069694227056503
Validation loss: 2.0280877651488414

Epoch: 5| Step: 5
Training loss: 0.10934487847680462
Validation loss: 2.0395693358304756

Epoch: 5| Step: 6
Training loss: 0.10542030899803673
Validation loss: 2.051547609302722

Epoch: 5| Step: 7
Training loss: 0.18688164512595312
Validation loss: 2.02648099893741

Epoch: 5| Step: 8
Training loss: 0.16034320061425417
Validation loss: 2.0331354274474602

Epoch: 5| Step: 9
Training loss: 0.10341749398299936
Validation loss: 2.029711400761048

Epoch: 5| Step: 10
Training loss: 0.1299885699286174
Validation loss: 2.041415156563795

Epoch: 586| Step: 0
Training loss: 0.12506454261787425
Validation loss: 2.039960928639687

Epoch: 5| Step: 1
Training loss: 0.11246846737286881
Validation loss: 2.046244595825124

Epoch: 5| Step: 2
Training loss: 0.12490144211814257
Validation loss: 2.038578078843691

Epoch: 5| Step: 3
Training loss: 0.07764158293643049
Validation loss: 2.0806444063477016

Epoch: 5| Step: 4
Training loss: 0.1109457182526581
Validation loss: 2.0322651865414914

Epoch: 5| Step: 5
Training loss: 0.07235861285719947
Validation loss: 2.0579754637082455

Epoch: 5| Step: 6
Training loss: 0.1276136016925753
Validation loss: 2.0475692504745533

Epoch: 5| Step: 7
Training loss: 0.16176270564807355
Validation loss: 2.031455314362975

Epoch: 5| Step: 8
Training loss: 0.06793529232367777
Validation loss: 2.040868224658033

Epoch: 5| Step: 9
Training loss: 0.18735842525599994
Validation loss: 2.0643558890450806

Epoch: 5| Step: 10
Training loss: 0.16729645031217508
Validation loss: 2.0629652510972343

Epoch: 587| Step: 0
Training loss: 0.09033691805431328
Validation loss: 2.068245279919525

Epoch: 5| Step: 1
Training loss: 0.09742963246079452
Validation loss: 2.071916312439653

Epoch: 5| Step: 2
Training loss: 0.08433126733490369
Validation loss: 2.0390137515057445

Epoch: 5| Step: 3
Training loss: 0.11509242042816546
Validation loss: 2.052962735991318

Epoch: 5| Step: 4
Training loss: 0.14699188055999363
Validation loss: 2.0519778212706186

Epoch: 5| Step: 5
Training loss: 0.09697665257205036
Validation loss: 2.076078107709443

Epoch: 5| Step: 6
Training loss: 0.11684044070096282
Validation loss: 2.085098374963174

Epoch: 5| Step: 7
Training loss: 0.11407965439650469
Validation loss: 2.0432830319717805

Epoch: 5| Step: 8
Training loss: 0.13746457347955499
Validation loss: 2.0585730025998803

Epoch: 5| Step: 9
Training loss: 0.0619256029895875
Validation loss: 2.044885541674976

Epoch: 5| Step: 10
Training loss: 0.1979260484245337
Validation loss: 2.0661165729254085

Epoch: 588| Step: 0
Training loss: 0.1190602390945715
Validation loss: 2.088144329065916

Epoch: 5| Step: 1
Training loss: 0.14500757290121732
Validation loss: 2.043349816826734

Epoch: 5| Step: 2
Training loss: 0.0893260719846753
Validation loss: 2.0574631752019434

Epoch: 5| Step: 3
Training loss: 0.1621930641715609
Validation loss: 2.075890601175677

Epoch: 5| Step: 4
Training loss: 0.1250651011217929
Validation loss: 2.0509076154444323

Epoch: 5| Step: 5
Training loss: 0.0883094978713148
Validation loss: 2.0356364013359034

Epoch: 5| Step: 6
Training loss: 0.08901484243321145
Validation loss: 2.0744713872603064

Epoch: 5| Step: 7
Training loss: 0.08424315947239293
Validation loss: 2.0705278590684526

Epoch: 5| Step: 8
Training loss: 0.09163652273461463
Validation loss: 2.076243822619616

Epoch: 5| Step: 9
Training loss: 0.17808614231707826
Validation loss: 2.098456890773539

Epoch: 5| Step: 10
Training loss: 0.11257394770986694
Validation loss: 2.07257908124016

Epoch: 589| Step: 0
Training loss: 0.08582723652997701
Validation loss: 2.0863039810804955

Epoch: 5| Step: 1
Training loss: 0.16531612344495308
Validation loss: 2.0949442336099153

Epoch: 5| Step: 2
Training loss: 0.07631226891776331
Validation loss: 2.0681739267020824

Epoch: 5| Step: 3
Training loss: 0.1055597469053829
Validation loss: 2.0549318031190573

Epoch: 5| Step: 4
Training loss: 0.11050028611163387
Validation loss: 2.08679117104492

Epoch: 5| Step: 5
Training loss: 0.09454154104380937
Validation loss: 2.0753177973715915

Epoch: 5| Step: 6
Training loss: 0.11137621660670514
Validation loss: 2.065261120010712

Epoch: 5| Step: 7
Training loss: 0.10149319741809083
Validation loss: 2.092739515840395

Epoch: 5| Step: 8
Training loss: 0.10493320909466614
Validation loss: 2.0557069632837672

Epoch: 5| Step: 9
Training loss: 0.10626260580988275
Validation loss: 2.057348490800342

Epoch: 5| Step: 10
Training loss: 0.1596961740202083
Validation loss: 2.090933977591245

Epoch: 590| Step: 0
Training loss: 0.09115247077843132
Validation loss: 2.048876141988527

Epoch: 5| Step: 1
Training loss: 0.11268844137285192
Validation loss: 2.0834312421085417

Epoch: 5| Step: 2
Training loss: 0.09850225683866669
Validation loss: 2.083363579151088

Epoch: 5| Step: 3
Training loss: 0.06941147168830275
Validation loss: 2.069528821990692

Epoch: 5| Step: 4
Training loss: 0.09211837997939369
Validation loss: 2.089111296679432

Epoch: 5| Step: 5
Training loss: 0.1108579452790752
Validation loss: 2.0809723004346217

Epoch: 5| Step: 6
Training loss: 0.12971240172248727
Validation loss: 2.0813422519540934

Epoch: 5| Step: 7
Training loss: 0.16865681397699106
Validation loss: 2.0652115983765142

Epoch: 5| Step: 8
Training loss: 0.12197504904043913
Validation loss: 2.079840308157537

Epoch: 5| Step: 9
Training loss: 0.10152712536021798
Validation loss: 2.0431574804471264

Epoch: 5| Step: 10
Training loss: 0.17338945457907054
Validation loss: 2.0562249073874215

Epoch: 591| Step: 0
Training loss: 0.07137749686734063
Validation loss: 2.0426906910253706

Epoch: 5| Step: 1
Training loss: 0.13187767357172597
Validation loss: 2.048225665471504

Epoch: 5| Step: 2
Training loss: 0.10212649954088296
Validation loss: 2.071877858085358

Epoch: 5| Step: 3
Training loss: 0.0848604243492298
Validation loss: 2.0178508101946124

Epoch: 5| Step: 4
Training loss: 0.132213363101346
Validation loss: 2.020480725761313

Epoch: 5| Step: 5
Training loss: 0.10820451780311058
Validation loss: 2.0471580539486696

Epoch: 5| Step: 6
Training loss: 0.11420131982182226
Validation loss: 2.0321394570288147

Epoch: 5| Step: 7
Training loss: 0.15371259690858904
Validation loss: 2.023610597847082

Epoch: 5| Step: 8
Training loss: 0.11634509973437257
Validation loss: 2.0444869585121426

Epoch: 5| Step: 9
Training loss: 0.1438074999851472
Validation loss: 2.0425134911260243

Epoch: 5| Step: 10
Training loss: 0.11111439718248331
Validation loss: 2.053191197069343

Epoch: 592| Step: 0
Training loss: 0.1784334268956866
Validation loss: 2.0466768916778753

Epoch: 5| Step: 1
Training loss: 0.09685219200116174
Validation loss: 2.0738338997682133

Epoch: 5| Step: 2
Training loss: 0.08475412761045549
Validation loss: 2.045869248430851

Epoch: 5| Step: 3
Training loss: 0.09248423422667199
Validation loss: 2.086448683918184

Epoch: 5| Step: 4
Training loss: 0.06660035459480239
Validation loss: 2.055363947410848

Epoch: 5| Step: 5
Training loss: 0.1402345973467326
Validation loss: 2.0875349347794145

Epoch: 5| Step: 6
Training loss: 0.07129647921820811
Validation loss: 2.06856430891296

Epoch: 5| Step: 7
Training loss: 0.09505821452115129
Validation loss: 2.07599112135066

Epoch: 5| Step: 8
Training loss: 0.15662052805682222
Validation loss: 2.0757382324663927

Epoch: 5| Step: 9
Training loss: 0.08937673367806205
Validation loss: 2.0590731945556975

Epoch: 5| Step: 10
Training loss: 0.10326040943542987
Validation loss: 2.0560432794961496

Epoch: 593| Step: 0
Training loss: 0.08597400009361245
Validation loss: 2.0663861951574582

Epoch: 5| Step: 1
Training loss: 0.09583569608847486
Validation loss: 2.0645072817292403

Epoch: 5| Step: 2
Training loss: 0.06104483336980955
Validation loss: 2.0677607165914784

Epoch: 5| Step: 3
Training loss: 0.08799919733885711
Validation loss: 2.0595083792623203

Epoch: 5| Step: 4
Training loss: 0.08535773148055119
Validation loss: 2.029311577403578

Epoch: 5| Step: 5
Training loss: 0.10582007949200757
Validation loss: 2.0402036497479634

Epoch: 5| Step: 6
Training loss: 0.07887595286696801
Validation loss: 2.0865458271658097

Epoch: 5| Step: 7
Training loss: 0.14909603830227366
Validation loss: 2.0559177316117463

Epoch: 5| Step: 8
Training loss: 0.07974776590683692
Validation loss: 2.0513550477054148

Epoch: 5| Step: 9
Training loss: 0.0991053451279303
Validation loss: 2.060498499179722

Epoch: 5| Step: 10
Training loss: 0.19011296073395736
Validation loss: 2.069040032095983

Epoch: 594| Step: 0
Training loss: 0.08463159393578436
Validation loss: 2.0642702666231076

Epoch: 5| Step: 1
Training loss: 0.06666667795119091
Validation loss: 2.042729542030558

Epoch: 5| Step: 2
Training loss: 0.15906687992788246
Validation loss: 2.061048788296277

Epoch: 5| Step: 3
Training loss: 0.08858744639218359
Validation loss: 2.0777052835520955

Epoch: 5| Step: 4
Training loss: 0.12475261572038253
Validation loss: 2.035112310713109

Epoch: 5| Step: 5
Training loss: 0.059273957795247474
Validation loss: 2.0763535605343417

Epoch: 5| Step: 6
Training loss: 0.11587018053928039
Validation loss: 2.0445606110695684

Epoch: 5| Step: 7
Training loss: 0.1526160862621513
Validation loss: 2.1012383417727967

Epoch: 5| Step: 8
Training loss: 0.10028038094483685
Validation loss: 2.0459280922856258

Epoch: 5| Step: 9
Training loss: 0.0794260117453325
Validation loss: 2.0731498470445575

Epoch: 5| Step: 10
Training loss: 0.1454914839114629
Validation loss: 2.0695721971865404

Epoch: 595| Step: 0
Training loss: 0.11695414594944907
Validation loss: 2.0202346966330533

Epoch: 5| Step: 1
Training loss: 0.15776711887854897
Validation loss: 2.0698506876314653

Epoch: 5| Step: 2
Training loss: 0.14535160128257948
Validation loss: 2.053621491346986

Epoch: 5| Step: 3
Training loss: 0.10774525604735596
Validation loss: 2.0378196724729465

Epoch: 5| Step: 4
Training loss: 0.13387997872536284
Validation loss: 2.0659409473736323

Epoch: 5| Step: 5
Training loss: 0.1045448803176183
Validation loss: 2.0765407326702947

Epoch: 5| Step: 6
Training loss: 0.06238144941160493
Validation loss: 2.0537372745195586

Epoch: 5| Step: 7
Training loss: 0.1521484823067713
Validation loss: 2.0165535512286703

Epoch: 5| Step: 8
Training loss: 0.06567966335990882
Validation loss: 2.0551256333179126

Epoch: 5| Step: 9
Training loss: 0.09026049281383251
Validation loss: 2.0599058784760675

Epoch: 5| Step: 10
Training loss: 0.08402956257037693
Validation loss: 2.07891177539913

Epoch: 596| Step: 0
Training loss: 0.07117365287377517
Validation loss: 2.034682885596726

Epoch: 5| Step: 1
Training loss: 0.18607589195590696
Validation loss: 2.0822483014173456

Epoch: 5| Step: 2
Training loss: 0.10110646346275376
Validation loss: 2.080437562021062

Epoch: 5| Step: 3
Training loss: 0.15880905485338428
Validation loss: 2.079880900211273

Epoch: 5| Step: 4
Training loss: 0.08695142457264199
Validation loss: 2.054528771020548

Epoch: 5| Step: 5
Training loss: 0.1232971303197779
Validation loss: 2.085904531512925

Epoch: 5| Step: 6
Training loss: 0.08070391854914347
Validation loss: 2.0740142913687736

Epoch: 5| Step: 7
Training loss: 0.10978047111000372
Validation loss: 2.0529766941777945

Epoch: 5| Step: 8
Training loss: 0.07141813586204593
Validation loss: 2.0552723819192478

Epoch: 5| Step: 9
Training loss: 0.07375539269976626
Validation loss: 2.070149195107028

Epoch: 5| Step: 10
Training loss: 0.13403192460470026
Validation loss: 2.03976265216222

Epoch: 597| Step: 0
Training loss: 0.10986035237116956
Validation loss: 2.0558363888270725

Epoch: 5| Step: 1
Training loss: 0.15345663339845622
Validation loss: 2.0667352363912537

Epoch: 5| Step: 2
Training loss: 0.11417798163372661
Validation loss: 2.0743889401746687

Epoch: 5| Step: 3
Training loss: 0.11869674997633713
Validation loss: 2.077033567487074

Epoch: 5| Step: 4
Training loss: 0.14364972504407897
Validation loss: 2.0523677254284656

Epoch: 5| Step: 5
Training loss: 0.13244945328971525
Validation loss: 2.0874891456585605

Epoch: 5| Step: 6
Training loss: 0.1235270327886314
Validation loss: 2.0704658833803204

Epoch: 5| Step: 7
Training loss: 0.1330224439440819
Validation loss: 2.086292139760479

Epoch: 5| Step: 8
Training loss: 0.11466208284138527
Validation loss: 2.062824038609171

Epoch: 5| Step: 9
Training loss: 0.15671600349849288
Validation loss: 2.104571374720952

Epoch: 5| Step: 10
Training loss: 0.11596314273899534
Validation loss: 2.0857060797087246

Epoch: 598| Step: 0
Training loss: 0.06996359286548626
Validation loss: 2.0733680285225047

Epoch: 5| Step: 1
Training loss: 0.08135337832362374
Validation loss: 2.0507153272214595

Epoch: 5| Step: 2
Training loss: 0.1462198348297588
Validation loss: 2.104500859672883

Epoch: 5| Step: 3
Training loss: 0.22989267345919268
Validation loss: 2.0731353207467627

Epoch: 5| Step: 4
Training loss: 0.06541806801063905
Validation loss: 2.0773475840350897

Epoch: 5| Step: 5
Training loss: 0.09883959971219403
Validation loss: 2.0782874074200453

Epoch: 5| Step: 6
Training loss: 0.10203476374010209
Validation loss: 2.065163617342023

Epoch: 5| Step: 7
Training loss: 0.09571597441224315
Validation loss: 2.0782449314355245

Epoch: 5| Step: 8
Training loss: 0.11014407831271988
Validation loss: 2.108759296089243

Epoch: 5| Step: 9
Training loss: 0.10749578534225547
Validation loss: 2.037821265139766

Epoch: 5| Step: 10
Training loss: 0.10421846760764461
Validation loss: 2.0595126557092374

Epoch: 599| Step: 0
Training loss: 0.15009020859477626
Validation loss: 2.0880883222247335

Epoch: 5| Step: 1
Training loss: 0.10782833795038634
Validation loss: 2.0460333898665364

Epoch: 5| Step: 2
Training loss: 0.11377207708170814
Validation loss: 2.063613291579035

Epoch: 5| Step: 3
Training loss: 0.09783563350991842
Validation loss: 2.040580133506037

Epoch: 5| Step: 4
Training loss: 0.12050059619979653
Validation loss: 2.059963030813434

Epoch: 5| Step: 5
Training loss: 0.1556925964049649
Validation loss: 2.0633449998684434

Epoch: 5| Step: 6
Training loss: 0.07624180957901051
Validation loss: 2.064891082984846

Epoch: 5| Step: 7
Training loss: 0.12025891835540584
Validation loss: 2.070943361775584

Epoch: 5| Step: 8
Training loss: 0.14403899882390134
Validation loss: 2.0564479403590674

Epoch: 5| Step: 9
Training loss: 0.14236087446916756
Validation loss: 2.054604068121034

Epoch: 5| Step: 10
Training loss: 0.09153151711339971
Validation loss: 2.052020939670212

Epoch: 600| Step: 0
Training loss: 0.10404423482506611
Validation loss: 2.037026274341552

Epoch: 5| Step: 1
Training loss: 0.10479235984308813
Validation loss: 2.0745146047397856

Epoch: 5| Step: 2
Training loss: 0.12192738748960867
Validation loss: 2.0851674413100425

Epoch: 5| Step: 3
Training loss: 0.09225983247008145
Validation loss: 2.084624276479833

Epoch: 5| Step: 4
Training loss: 0.1616926351829589
Validation loss: 2.063855052664324

Epoch: 5| Step: 5
Training loss: 0.16498313610819493
Validation loss: 2.046685997964282

Epoch: 5| Step: 6
Training loss: 0.16229508574691148
Validation loss: 2.085771627276869

Epoch: 5| Step: 7
Training loss: 0.20341412434857387
Validation loss: 2.0805962144156918

Epoch: 5| Step: 8
Training loss: 0.07105844572151555
Validation loss: 2.0861508220923413

Epoch: 5| Step: 9
Training loss: 0.07991523574331844
Validation loss: 2.039488647975423

Epoch: 5| Step: 10
Training loss: 0.14829550401252645
Validation loss: 2.035297371821616

Epoch: 601| Step: 0
Training loss: 0.14045913504259788
Validation loss: 2.0641789853639385

Epoch: 5| Step: 1
Training loss: 0.10061602003739928
Validation loss: 2.025704315879696

Epoch: 5| Step: 2
Training loss: 0.1180188058608576
Validation loss: 2.0511006518204646

Epoch: 5| Step: 3
Training loss: 0.10270437357335238
Validation loss: 2.0678731858249835

Epoch: 5| Step: 4
Training loss: 0.16505439393651222
Validation loss: 2.0438650432449066

Epoch: 5| Step: 5
Training loss: 0.12844735886216505
Validation loss: 2.0534266149630342

Epoch: 5| Step: 6
Training loss: 0.10255517832950327
Validation loss: 2.075856629016722

Epoch: 5| Step: 7
Training loss: 0.17310741046004605
Validation loss: 2.091523994149488

Epoch: 5| Step: 8
Training loss: 0.11722748392182156
Validation loss: 2.0757905114772313

Epoch: 5| Step: 9
Training loss: 0.12185582199571307
Validation loss: 2.1170945103415493

Epoch: 5| Step: 10
Training loss: 0.11500357694220119
Validation loss: 2.1035428137161873

Epoch: 602| Step: 0
Training loss: 0.12519087225647077
Validation loss: 2.118406079118862

Epoch: 5| Step: 1
Training loss: 0.13632302233702406
Validation loss: 2.134378990165166

Epoch: 5| Step: 2
Training loss: 0.09460793273576167
Validation loss: 2.113061721053791

Epoch: 5| Step: 3
Training loss: 0.13786981901159642
Validation loss: 2.105831910857108

Epoch: 5| Step: 4
Training loss: 0.17180382273469688
Validation loss: 2.0795366314868624

Epoch: 5| Step: 5
Training loss: 0.10231344742647977
Validation loss: 2.064569919320295

Epoch: 5| Step: 6
Training loss: 0.08965505604632058
Validation loss: 2.0463211639787886

Epoch: 5| Step: 7
Training loss: 0.12473042671174472
Validation loss: 2.050691979843877

Epoch: 5| Step: 8
Training loss: 0.1209002263579269
Validation loss: 2.03977344078657

Epoch: 5| Step: 9
Training loss: 0.16971855495865218
Validation loss: 2.0440840698063125

Epoch: 5| Step: 10
Training loss: 0.10825006107368244
Validation loss: 2.022672415352955

Epoch: 603| Step: 0
Training loss: 0.11425691995516646
Validation loss: 2.0617033226784103

Epoch: 5| Step: 1
Training loss: 0.15683238451817985
Validation loss: 2.0631500769027005

Epoch: 5| Step: 2
Training loss: 0.13130504952328217
Validation loss: 2.0474222368037545

Epoch: 5| Step: 3
Training loss: 0.10433003955568051
Validation loss: 2.0695056675040524

Epoch: 5| Step: 4
Training loss: 0.10447869258264682
Validation loss: 2.0528115687245343

Epoch: 5| Step: 5
Training loss: 0.12492000359546396
Validation loss: 2.0735726096027607

Epoch: 5| Step: 6
Training loss: 0.17703548771431646
Validation loss: 2.104082801152283

Epoch: 5| Step: 7
Training loss: 0.14222859297101612
Validation loss: 2.087471218732314

Epoch: 5| Step: 8
Training loss: 0.182286764260629
Validation loss: 2.068920798445185

Epoch: 5| Step: 9
Training loss: 0.09786685645150314
Validation loss: 2.1015150012444357

Epoch: 5| Step: 10
Training loss: 0.12516310600428168
Validation loss: 2.0613692910986705

Epoch: 604| Step: 0
Training loss: 0.1558951998770874
Validation loss: 2.0657543239005554

Epoch: 5| Step: 1
Training loss: 0.158261264902533
Validation loss: 2.072632928236859

Epoch: 5| Step: 2
Training loss: 0.12590990594842505
Validation loss: 2.0895997969308087

Epoch: 5| Step: 3
Training loss: 0.17249955147878412
Validation loss: 2.092439737708592

Epoch: 5| Step: 4
Training loss: 0.12217145544332085
Validation loss: 2.0770938809294752

Epoch: 5| Step: 5
Training loss: 0.08552675544046855
Validation loss: 2.054345462296878

Epoch: 5| Step: 6
Training loss: 0.17849298120705293
Validation loss: 2.087159162881782

Epoch: 5| Step: 7
Training loss: 0.10555166940931998
Validation loss: 2.0450384346538653

Epoch: 5| Step: 8
Training loss: 0.1568716082263264
Validation loss: 2.077713144591734

Epoch: 5| Step: 9
Training loss: 0.16951234839584303
Validation loss: 2.041005326527836

Epoch: 5| Step: 10
Training loss: 0.13873716617203463
Validation loss: 2.064719978930492

Epoch: 605| Step: 0
Training loss: 0.09350382252359664
Validation loss: 2.0465402148538807

Epoch: 5| Step: 1
Training loss: 0.19298387923758792
Validation loss: 2.045339271725356

Epoch: 5| Step: 2
Training loss: 0.08295209080264651
Validation loss: 2.0659130255359694

Epoch: 5| Step: 3
Training loss: 0.08632145797652374
Validation loss: 2.0546472758312593

Epoch: 5| Step: 4
Training loss: 0.10660530892397506
Validation loss: 2.0581951404181766

Epoch: 5| Step: 5
Training loss: 0.11837467230088818
Validation loss: 2.0707065088937706

Epoch: 5| Step: 6
Training loss: 0.1550506877409233
Validation loss: 2.1087907231849576

Epoch: 5| Step: 7
Training loss: 0.153731026845352
Validation loss: 2.1010571267197564

Epoch: 5| Step: 8
Training loss: 0.09035113364652654
Validation loss: 2.0323876929866795

Epoch: 5| Step: 9
Training loss: 0.09747595833746084
Validation loss: 2.0515743948956806

Epoch: 5| Step: 10
Training loss: 0.16619132225401217
Validation loss: 2.084457112417904

Epoch: 606| Step: 0
Training loss: 0.1528477645429474
Validation loss: 2.068420867840907

Epoch: 5| Step: 1
Training loss: 0.1223154658049123
Validation loss: 2.0665088572804193

Epoch: 5| Step: 2
Training loss: 0.09853888751281865
Validation loss: 2.0838003615428677

Epoch: 5| Step: 3
Training loss: 0.12016739610036378
Validation loss: 2.0758142731059923

Epoch: 5| Step: 4
Training loss: 0.13861712194171485
Validation loss: 2.0704911386909957

Epoch: 5| Step: 5
Training loss: 0.12958660624756937
Validation loss: 2.066402666444058

Epoch: 5| Step: 6
Training loss: 0.15016316266973867
Validation loss: 2.0812390570411545

Epoch: 5| Step: 7
Training loss: 0.12020999920377753
Validation loss: 2.0649000220387137

Epoch: 5| Step: 8
Training loss: 0.12508787106458655
Validation loss: 2.069587667624476

Epoch: 5| Step: 9
Training loss: 0.05554054593728972
Validation loss: 2.0798048973162087

Epoch: 5| Step: 10
Training loss: 0.11056410736055257
Validation loss: 2.086420152766693

Epoch: 607| Step: 0
Training loss: 0.09243555277320352
Validation loss: 2.07325248040828

Epoch: 5| Step: 1
Training loss: 0.07758623257036328
Validation loss: 2.0761353760768024

Epoch: 5| Step: 2
Training loss: 0.06554730362916823
Validation loss: 2.0986465881735668

Epoch: 5| Step: 3
Training loss: 0.12340457332241957
Validation loss: 2.081035821252214

Epoch: 5| Step: 4
Training loss: 0.0866011306268422
Validation loss: 2.104528898113998

Epoch: 5| Step: 5
Training loss: 0.15765436388745727
Validation loss: 2.07518714913796

Epoch: 5| Step: 6
Training loss: 0.09637793739613275
Validation loss: 2.0889322836568196

Epoch: 5| Step: 7
Training loss: 0.08056990586974128
Validation loss: 2.132126659543629

Epoch: 5| Step: 8
Training loss: 0.14811735387978192
Validation loss: 2.1065241403051678

Epoch: 5| Step: 9
Training loss: 0.11195702019601539
Validation loss: 2.0735827747648305

Epoch: 5| Step: 10
Training loss: 0.1496414125367411
Validation loss: 2.0811433746509507

Epoch: 608| Step: 0
Training loss: 0.0672363576286434
Validation loss: 2.068150775175256

Epoch: 5| Step: 1
Training loss: 0.09346408757563811
Validation loss: 2.0916002085610095

Epoch: 5| Step: 2
Training loss: 0.13472394022127476
Validation loss: 2.073039873996022

Epoch: 5| Step: 3
Training loss: 0.1554918791947995
Validation loss: 2.0342260048674214

Epoch: 5| Step: 4
Training loss: 0.08125146282236366
Validation loss: 2.0542901834563083

Epoch: 5| Step: 5
Training loss: 0.10071852195647649
Validation loss: 2.058366998587572

Epoch: 5| Step: 6
Training loss: 0.07459413500116345
Validation loss: 2.0446502498566526

Epoch: 5| Step: 7
Training loss: 0.10196750839031625
Validation loss: 2.0604600874195618

Epoch: 5| Step: 8
Training loss: 0.17758420741635714
Validation loss: 2.0442326133723525

Epoch: 5| Step: 9
Training loss: 0.12054026922444867
Validation loss: 2.070492366346062

Epoch: 5| Step: 10
Training loss: 0.1330130969550825
Validation loss: 2.055607686088021

Epoch: 609| Step: 0
Training loss: 0.0810767310398165
Validation loss: 2.0820037415790895

Epoch: 5| Step: 1
Training loss: 0.0796570698754644
Validation loss: 2.0574902136621804

Epoch: 5| Step: 2
Training loss: 0.12533511005393128
Validation loss: 2.0901751953397545

Epoch: 5| Step: 3
Training loss: 0.08430364271366195
Validation loss: 2.0595314001470175

Epoch: 5| Step: 4
Training loss: 0.08654605180297553
Validation loss: 2.099943424865205

Epoch: 5| Step: 5
Training loss: 0.1477217420525556
Validation loss: 2.1114212132025996

Epoch: 5| Step: 6
Training loss: 0.10834821620215675
Validation loss: 2.0790120335885454

Epoch: 5| Step: 7
Training loss: 0.10251443203791731
Validation loss: 2.0843841224388746

Epoch: 5| Step: 8
Training loss: 0.09960010429324441
Validation loss: 2.0729079307915823

Epoch: 5| Step: 9
Training loss: 0.10574902716345873
Validation loss: 2.0554585576925777

Epoch: 5| Step: 10
Training loss: 0.15242320214128327
Validation loss: 2.055837902380239

Epoch: 610| Step: 0
Training loss: 0.10306335561089487
Validation loss: 2.064996879792984

Epoch: 5| Step: 1
Training loss: 0.08424325067750832
Validation loss: 2.0368198623260025

Epoch: 5| Step: 2
Training loss: 0.13604828058535104
Validation loss: 2.061081886322941

Epoch: 5| Step: 3
Training loss: 0.09110975800435189
Validation loss: 2.0141962763287427

Epoch: 5| Step: 4
Training loss: 0.1054341162224533
Validation loss: 2.019845669367112

Epoch: 5| Step: 5
Training loss: 0.11030853749309605
Validation loss: 2.040565308766303

Epoch: 5| Step: 6
Training loss: 0.1371664211137543
Validation loss: 2.045143328651184

Epoch: 5| Step: 7
Training loss: 0.09483559223014465
Validation loss: 2.010261289481619

Epoch: 5| Step: 8
Training loss: 0.09407075509096412
Validation loss: 2.04421403715984

Epoch: 5| Step: 9
Training loss: 0.15275407820149176
Validation loss: 2.037320307529539

Epoch: 5| Step: 10
Training loss: 0.09946653933380041
Validation loss: 2.0166814359454444

Epoch: 611| Step: 0
Training loss: 0.1208418911097188
Validation loss: 2.059207173943618

Epoch: 5| Step: 1
Training loss: 0.09547242755331056
Validation loss: 2.0360335352908963

Epoch: 5| Step: 2
Training loss: 0.05086436942623754
Validation loss: 2.0350814124405523

Epoch: 5| Step: 3
Training loss: 0.09000830507702404
Validation loss: 2.044076108910348

Epoch: 5| Step: 4
Training loss: 0.061208003393130726
Validation loss: 2.070689692376316

Epoch: 5| Step: 5
Training loss: 0.08861662576075817
Validation loss: 2.062133980320736

Epoch: 5| Step: 6
Training loss: 0.07422132864036231
Validation loss: 2.0739143126074797

Epoch: 5| Step: 7
Training loss: 0.07549186848534843
Validation loss: 2.083465299631069

Epoch: 5| Step: 8
Training loss: 0.09122468285250661
Validation loss: 2.0840741245354955

Epoch: 5| Step: 9
Training loss: 0.08079542496825412
Validation loss: 2.0464437957838033

Epoch: 5| Step: 10
Training loss: 0.2041766653645515
Validation loss: 2.048815341968512

Epoch: 612| Step: 0
Training loss: 0.1420746431380292
Validation loss: 2.0750514186552618

Epoch: 5| Step: 1
Training loss: 0.1270934576420907
Validation loss: 2.0658112920982368

Epoch: 5| Step: 2
Training loss: 0.10921701021950797
Validation loss: 2.059632221470601

Epoch: 5| Step: 3
Training loss: 0.06855902128296584
Validation loss: 2.038227192933337

Epoch: 5| Step: 4
Training loss: 0.06143383282653545
Validation loss: 2.0389974053553197

Epoch: 5| Step: 5
Training loss: 0.08909178218989872
Validation loss: 2.062519979519992

Epoch: 5| Step: 6
Training loss: 0.14307722499939696
Validation loss: 2.061666655585936

Epoch: 5| Step: 7
Training loss: 0.1352971830574896
Validation loss: 2.0639467171554435

Epoch: 5| Step: 8
Training loss: 0.1158734598492093
Validation loss: 2.0772860993652804

Epoch: 5| Step: 9
Training loss: 0.1465056467505944
Validation loss: 2.0690943732550986

Epoch: 5| Step: 10
Training loss: 0.07442081075392336
Validation loss: 2.082995258916129

Epoch: 613| Step: 0
Training loss: 0.06989806611668177
Validation loss: 2.077320412826264

Epoch: 5| Step: 1
Training loss: 0.054137381512227745
Validation loss: 2.056997037335522

Epoch: 5| Step: 2
Training loss: 0.054243872693946406
Validation loss: 2.1120406249694046

Epoch: 5| Step: 3
Training loss: 0.15679240257905863
Validation loss: 2.0726175136167013

Epoch: 5| Step: 4
Training loss: 0.13344574476227553
Validation loss: 2.0877270134041033

Epoch: 5| Step: 5
Training loss: 0.07683611375258088
Validation loss: 2.0786469475083416

Epoch: 5| Step: 6
Training loss: 0.11516292021518536
Validation loss: 2.061095670428614

Epoch: 5| Step: 7
Training loss: 0.10732895560393715
Validation loss: 2.091586734574841

Epoch: 5| Step: 8
Training loss: 0.10019648255674468
Validation loss: 2.0798356926286554

Epoch: 5| Step: 9
Training loss: 0.13499193263453438
Validation loss: 2.058642348658616

Epoch: 5| Step: 10
Training loss: 0.1563252744553007
Validation loss: 2.08094103100567

Epoch: 614| Step: 0
Training loss: 0.10633994933647438
Validation loss: 2.0828992547279115

Epoch: 5| Step: 1
Training loss: 0.09210305184944594
Validation loss: 2.0609197345616557

Epoch: 5| Step: 2
Training loss: 0.08261002426115993
Validation loss: 2.0632566069206146

Epoch: 5| Step: 3
Training loss: 0.07985350460590307
Validation loss: 2.0884274378428844

Epoch: 5| Step: 4
Training loss: 0.16368564966546242
Validation loss: 2.043840977909005

Epoch: 5| Step: 5
Training loss: 0.0849469326797664
Validation loss: 2.0508476756755343

Epoch: 5| Step: 6
Training loss: 0.13038773019775998
Validation loss: 2.0117625554213032

Epoch: 5| Step: 7
Training loss: 0.13571555061530657
Validation loss: 2.030349293841841

Epoch: 5| Step: 8
Training loss: 0.08222780634467088
Validation loss: 2.0792520325732156

Epoch: 5| Step: 9
Training loss: 0.09970597650491281
Validation loss: 2.0608007417235723

Epoch: 5| Step: 10
Training loss: 0.09215229299645035
Validation loss: 2.041691421030575

Epoch: 615| Step: 0
Training loss: 0.12465536022418601
Validation loss: 2.0975469177025343

Epoch: 5| Step: 1
Training loss: 0.08312973156885849
Validation loss: 2.095495781212075

Epoch: 5| Step: 2
Training loss: 0.1282094197584683
Validation loss: 2.0676730883339647

Epoch: 5| Step: 3
Training loss: 0.10687424916009225
Validation loss: 2.0566530789288624

Epoch: 5| Step: 4
Training loss: 0.10407059282188214
Validation loss: 2.063930328122537

Epoch: 5| Step: 5
Training loss: 0.16108372836571058
Validation loss: 2.0516470551590795

Epoch: 5| Step: 6
Training loss: 0.1507890056928007
Validation loss: 2.0386033160932073

Epoch: 5| Step: 7
Training loss: 0.09292857600377594
Validation loss: 2.079983279707851

Epoch: 5| Step: 8
Training loss: 0.12891830763633444
Validation loss: 2.048943325094756

Epoch: 5| Step: 9
Training loss: 0.07319483815964856
Validation loss: 2.055166534824885

Epoch: 5| Step: 10
Training loss: 0.07636621942906568
Validation loss: 2.08355961391117

Epoch: 616| Step: 0
Training loss: 0.07305051200400546
Validation loss: 2.043772367693887

Epoch: 5| Step: 1
Training loss: 0.13376445265475567
Validation loss: 2.0606167393651926

Epoch: 5| Step: 2
Training loss: 0.06302879937651067
Validation loss: 2.0205523231353855

Epoch: 5| Step: 3
Training loss: 0.08744813476093777
Validation loss: 2.0360278106265755

Epoch: 5| Step: 4
Training loss: 0.10437092474017123
Validation loss: 2.024599187266113

Epoch: 5| Step: 5
Training loss: 0.1288931579877384
Validation loss: 2.090077526536576

Epoch: 5| Step: 6
Training loss: 0.09716059306919983
Validation loss: 2.0679850582341017

Epoch: 5| Step: 7
Training loss: 0.09856953810283103
Validation loss: 2.0611207722025235

Epoch: 5| Step: 8
Training loss: 0.12880201894134052
Validation loss: 2.060326474759571

Epoch: 5| Step: 9
Training loss: 0.0844543222144893
Validation loss: 2.065579012581233

Epoch: 5| Step: 10
Training loss: 0.10004469237895078
Validation loss: 2.0979904706302293

Epoch: 617| Step: 0
Training loss: 0.17665238687565218
Validation loss: 2.0736060671642913

Epoch: 5| Step: 1
Training loss: 0.09608443843107338
Validation loss: 2.0795994783839804

Epoch: 5| Step: 2
Training loss: 0.14028541305612385
Validation loss: 2.0681115680926627

Epoch: 5| Step: 3
Training loss: 0.11053851840781569
Validation loss: 2.0693663565191476

Epoch: 5| Step: 4
Training loss: 0.05644699410966244
Validation loss: 2.0321078834012125

Epoch: 5| Step: 5
Training loss: 0.0777173942680433
Validation loss: 2.064524399440553

Epoch: 5| Step: 6
Training loss: 0.11576576073960769
Validation loss: 2.0655274345281116

Epoch: 5| Step: 7
Training loss: 0.10817405744051167
Validation loss: 2.0545367494371205

Epoch: 5| Step: 8
Training loss: 0.08470138277655677
Validation loss: 2.085181266599468

Epoch: 5| Step: 9
Training loss: 0.08408738350752412
Validation loss: 2.087219176359848

Epoch: 5| Step: 10
Training loss: 0.10603515539979118
Validation loss: 2.0621551574666372

Epoch: 618| Step: 0
Training loss: 0.09364519121782994
Validation loss: 2.0642387975920107

Epoch: 5| Step: 1
Training loss: 0.06494528536576312
Validation loss: 2.062497701733733

Epoch: 5| Step: 2
Training loss: 0.06876734520195761
Validation loss: 2.059412203229307

Epoch: 5| Step: 3
Training loss: 0.08295803541030265
Validation loss: 2.0386775194806606

Epoch: 5| Step: 4
Training loss: 0.13858384037823496
Validation loss: 2.016694538023352

Epoch: 5| Step: 5
Training loss: 0.15167182292880355
Validation loss: 2.0484910271972563

Epoch: 5| Step: 6
Training loss: 0.1037300336538106
Validation loss: 2.0695097874152553

Epoch: 5| Step: 7
Training loss: 0.10060899896043415
Validation loss: 2.048506386524267

Epoch: 5| Step: 8
Training loss: 0.11713708349361872
Validation loss: 2.0274528533967655

Epoch: 5| Step: 9
Training loss: 0.13084028588741461
Validation loss: 2.049448587984543

Epoch: 5| Step: 10
Training loss: 0.10932629215971586
Validation loss: 2.0661681111461787

Epoch: 619| Step: 0
Training loss: 0.09688021353567162
Validation loss: 2.065018103308474

Epoch: 5| Step: 1
Training loss: 0.10495893568054386
Validation loss: 2.0681325148252974

Epoch: 5| Step: 2
Training loss: 0.14374699978185387
Validation loss: 2.098427542785458

Epoch: 5| Step: 3
Training loss: 0.10226706806152631
Validation loss: 2.074999026508204

Epoch: 5| Step: 4
Training loss: 0.06810709518424715
Validation loss: 2.0702375339983052

Epoch: 5| Step: 5
Training loss: 0.14702783860354632
Validation loss: 2.0930204092196494

Epoch: 5| Step: 6
Training loss: 0.13012630899065922
Validation loss: 2.062554857451131

Epoch: 5| Step: 7
Training loss: 0.07391263235107894
Validation loss: 2.0820878787336277

Epoch: 5| Step: 8
Training loss: 0.08509482872174493
Validation loss: 2.066235157889157

Epoch: 5| Step: 9
Training loss: 0.07311625462489328
Validation loss: 2.0473084813082916

Epoch: 5| Step: 10
Training loss: 0.11280618317716375
Validation loss: 2.073607842519039

Epoch: 620| Step: 0
Training loss: 0.12058659456035113
Validation loss: 2.056551255159216

Epoch: 5| Step: 1
Training loss: 0.0713631134300591
Validation loss: 2.0365293300709353

Epoch: 5| Step: 2
Training loss: 0.09086570835754515
Validation loss: 2.072189350836646

Epoch: 5| Step: 3
Training loss: 0.10900087317146527
Validation loss: 2.0358537046453185

Epoch: 5| Step: 4
Training loss: 0.08709570570041036
Validation loss: 2.009717902629215

Epoch: 5| Step: 5
Training loss: 0.0728310809350922
Validation loss: 2.056158560357891

Epoch: 5| Step: 6
Training loss: 0.11597617663547032
Validation loss: 2.045597257811545

Epoch: 5| Step: 7
Training loss: 0.1308360007747124
Validation loss: 2.043274241752978

Epoch: 5| Step: 8
Training loss: 0.10301030275692992
Validation loss: 2.0661956538984496

Epoch: 5| Step: 9
Training loss: 0.1499779352211828
Validation loss: 2.025744599366802

Epoch: 5| Step: 10
Training loss: 0.09114196689670113
Validation loss: 2.060130599499889

Epoch: 621| Step: 0
Training loss: 0.09162560169886305
Validation loss: 2.0578728669658513

Epoch: 5| Step: 1
Training loss: 0.16138570764661855
Validation loss: 2.0713926457473635

Epoch: 5| Step: 2
Training loss: 0.0883330916633464
Validation loss: 2.067019615821528

Epoch: 5| Step: 3
Training loss: 0.07782826396578973
Validation loss: 2.0725799947146855

Epoch: 5| Step: 4
Training loss: 0.06034597205839733
Validation loss: 2.0830069417514037

Epoch: 5| Step: 5
Training loss: 0.04787979460903044
Validation loss: 2.0613988781576733

Epoch: 5| Step: 6
Training loss: 0.12956078123699857
Validation loss: 2.0961269972250003

Epoch: 5| Step: 7
Training loss: 0.09874625339221262
Validation loss: 2.1031544731310667

Epoch: 5| Step: 8
Training loss: 0.14052847357448847
Validation loss: 2.079450159040321

Epoch: 5| Step: 9
Training loss: 0.12885146710917256
Validation loss: 2.1097447310185973

Epoch: 5| Step: 10
Training loss: 0.06476199313036088
Validation loss: 2.1132814280237473

Epoch: 622| Step: 0
Training loss: 0.10806877681738905
Validation loss: 2.0868773958162654

Epoch: 5| Step: 1
Training loss: 0.12020019438892703
Validation loss: 2.089210492973296

Epoch: 5| Step: 2
Training loss: 0.09287825234919325
Validation loss: 2.0846113882883177

Epoch: 5| Step: 3
Training loss: 0.07469327338700789
Validation loss: 2.039782723055108

Epoch: 5| Step: 4
Training loss: 0.10606792465694904
Validation loss: 2.0371815444479218

Epoch: 5| Step: 5
Training loss: 0.1907016474984211
Validation loss: 2.039625037209367

Epoch: 5| Step: 6
Training loss: 0.10638766083668771
Validation loss: 2.05004498322098

Epoch: 5| Step: 7
Training loss: 0.10190206396401044
Validation loss: 2.0448490509910617

Epoch: 5| Step: 8
Training loss: 0.1327920084460053
Validation loss: 2.0407924069415877

Epoch: 5| Step: 9
Training loss: 0.06716059240207219
Validation loss: 2.0670940350105904

Epoch: 5| Step: 10
Training loss: 0.1057946151336545
Validation loss: 2.0669029425614296

Epoch: 623| Step: 0
Training loss: 0.1342383657583112
Validation loss: 2.09718478626064

Epoch: 5| Step: 1
Training loss: 0.09487213668347368
Validation loss: 2.05572555785561

Epoch: 5| Step: 2
Training loss: 0.0889063581137511
Validation loss: 2.0854645959944764

Epoch: 5| Step: 3
Training loss: 0.16727565108161
Validation loss: 2.0530210877664286

Epoch: 5| Step: 4
Training loss: 0.08118381612967787
Validation loss: 2.080239731706252

Epoch: 5| Step: 5
Training loss: 0.14664219302120016
Validation loss: 2.0969668749063937

Epoch: 5| Step: 6
Training loss: 0.08712323339414393
Validation loss: 2.0680845928808025

Epoch: 5| Step: 7
Training loss: 0.09799780244516434
Validation loss: 2.060295374776907

Epoch: 5| Step: 8
Training loss: 0.10551816171381467
Validation loss: 2.07606503680356

Epoch: 5| Step: 9
Training loss: 0.07922107886384253
Validation loss: 2.07168183195946

Epoch: 5| Step: 10
Training loss: 0.06985568291325668
Validation loss: 2.093513198658381

Epoch: 624| Step: 0
Training loss: 0.08413414021635542
Validation loss: 2.0874646038237454

Epoch: 5| Step: 1
Training loss: 0.13611909285471124
Validation loss: 2.0821683421770194

Epoch: 5| Step: 2
Training loss: 0.07074230015038506
Validation loss: 2.070809238594326

Epoch: 5| Step: 3
Training loss: 0.14695556515904115
Validation loss: 2.07107088481885

Epoch: 5| Step: 4
Training loss: 0.11019923237316459
Validation loss: 2.0807652096402216

Epoch: 5| Step: 5
Training loss: 0.09106395711073391
Validation loss: 2.099088430641321

Epoch: 5| Step: 6
Training loss: 0.0575547809781304
Validation loss: 2.0652319879924854

Epoch: 5| Step: 7
Training loss: 0.10114978416549955
Validation loss: 2.1033287898083604

Epoch: 5| Step: 8
Training loss: 0.0777790875492527
Validation loss: 2.0899487859754298

Epoch: 5| Step: 9
Training loss: 0.1327305218191767
Validation loss: 2.0884775653075565

Epoch: 5| Step: 10
Training loss: 0.09335290734780291
Validation loss: 2.0813447201749384

Epoch: 625| Step: 0
Training loss: 0.0823616628236815
Validation loss: 2.082779258347859

Epoch: 5| Step: 1
Training loss: 0.061718802738770756
Validation loss: 2.09331323313457

Epoch: 5| Step: 2
Training loss: 0.09635284837473919
Validation loss: 2.0653277179960217

Epoch: 5| Step: 3
Training loss: 0.1077159800257716
Validation loss: 2.078196608612433

Epoch: 5| Step: 4
Training loss: 0.08135885594310284
Validation loss: 2.087727893849648

Epoch: 5| Step: 5
Training loss: 0.1473556736523829
Validation loss: 2.0941202922625655

Epoch: 5| Step: 6
Training loss: 0.17231251020192812
Validation loss: 2.092178740811574

Epoch: 5| Step: 7
Training loss: 0.09747196930121294
Validation loss: 2.080827756392576

Epoch: 5| Step: 8
Training loss: 0.10802573491651866
Validation loss: 2.068807803281656

Epoch: 5| Step: 9
Training loss: 0.11255663102050681
Validation loss: 2.0602610378300223

Epoch: 5| Step: 10
Training loss: 0.10890581622098902
Validation loss: 2.0716782067928454

Epoch: 626| Step: 0
Training loss: 0.09962781567136501
Validation loss: 2.0622091880710967

Epoch: 5| Step: 1
Training loss: 0.09937578281208224
Validation loss: 2.0719946137332657

Epoch: 5| Step: 2
Training loss: 0.12856106346173438
Validation loss: 2.071431966468974

Epoch: 5| Step: 3
Training loss: 0.10772816168452747
Validation loss: 2.0440634780183293

Epoch: 5| Step: 4
Training loss: 0.11085591220756932
Validation loss: 2.077543417998874

Epoch: 5| Step: 5
Training loss: 0.132484100148055
Validation loss: 2.086314344714757

Epoch: 5| Step: 6
Training loss: 0.08187833793766486
Validation loss: 2.07016179129645

Epoch: 5| Step: 7
Training loss: 0.07009909949061835
Validation loss: 2.062521858882575

Epoch: 5| Step: 8
Training loss: 0.1333827510787348
Validation loss: 2.056570254085865

Epoch: 5| Step: 9
Training loss: 0.14021991293883787
Validation loss: 2.070071839832764

Epoch: 5| Step: 10
Training loss: 0.06935942950335736
Validation loss: 2.0680036738117047

Epoch: 627| Step: 0
Training loss: 0.13093619440424742
Validation loss: 2.0472389673497586

Epoch: 5| Step: 1
Training loss: 0.054236598914254586
Validation loss: 2.074091893281171

Epoch: 5| Step: 2
Training loss: 0.07194425353717503
Validation loss: 2.039249910530349

Epoch: 5| Step: 3
Training loss: 0.08293415054875361
Validation loss: 2.06650996882726

Epoch: 5| Step: 4
Training loss: 0.05709120941290522
Validation loss: 2.0666313316312874

Epoch: 5| Step: 5
Training loss: 0.10623685303160145
Validation loss: 2.0383521356740815

Epoch: 5| Step: 6
Training loss: 0.15059657671559812
Validation loss: 2.0522248537011443

Epoch: 5| Step: 7
Training loss: 0.09953794536198719
Validation loss: 2.0723804030245616

Epoch: 5| Step: 8
Training loss: 0.08370880727242544
Validation loss: 2.0746343000321428

Epoch: 5| Step: 9
Training loss: 0.1866879761047729
Validation loss: 2.091908602206157

Epoch: 5| Step: 10
Training loss: 0.07668653872446288
Validation loss: 2.079145321826968

Epoch: 628| Step: 0
Training loss: 0.12561947091589107
Validation loss: 2.1011654558467985

Epoch: 5| Step: 1
Training loss: 0.13487407218527364
Validation loss: 2.0588789277276938

Epoch: 5| Step: 2
Training loss: 0.08915302398499685
Validation loss: 2.057101423741448

Epoch: 5| Step: 3
Training loss: 0.07238581688745073
Validation loss: 2.04416266999663

Epoch: 5| Step: 4
Training loss: 0.05277090882244037
Validation loss: 2.086363251796789

Epoch: 5| Step: 5
Training loss: 0.09590768361628224
Validation loss: 2.0198659565735824

Epoch: 5| Step: 6
Training loss: 0.07375927545522748
Validation loss: 2.0495831221010916

Epoch: 5| Step: 7
Training loss: 0.056424132088962166
Validation loss: 2.0284484462274692

Epoch: 5| Step: 8
Training loss: 0.09531690067544324
Validation loss: 2.0442848177394235

Epoch: 5| Step: 9
Training loss: 0.11189757653418993
Validation loss: 2.0498553404852085

Epoch: 5| Step: 10
Training loss: 0.1524968050891742
Validation loss: 2.0525011345544937

Epoch: 629| Step: 0
Training loss: 0.07715928327400398
Validation loss: 2.052411527631031

Epoch: 5| Step: 1
Training loss: 0.12748515814058958
Validation loss: 2.058377716478049

Epoch: 5| Step: 2
Training loss: 0.09544643212253671
Validation loss: 2.075760683085034

Epoch: 5| Step: 3
Training loss: 0.07992692955642305
Validation loss: 2.054148901269532

Epoch: 5| Step: 4
Training loss: 0.07343532211544063
Validation loss: 2.0705216113137523

Epoch: 5| Step: 5
Training loss: 0.06806462639954051
Validation loss: 2.0261101033540507

Epoch: 5| Step: 6
Training loss: 0.08737135982622145
Validation loss: 2.0797839929515303

Epoch: 5| Step: 7
Training loss: 0.08685671596776798
Validation loss: 2.031309589177684

Epoch: 5| Step: 8
Training loss: 0.1170058551313108
Validation loss: 2.020269626952787

Epoch: 5| Step: 9
Training loss: 0.1351488442128445
Validation loss: 2.0248610054777525

Epoch: 5| Step: 10
Training loss: 0.08727817399494364
Validation loss: 2.0146812282920252

Epoch: 630| Step: 0
Training loss: 0.13065758134537242
Validation loss: 2.025428553512766

Epoch: 5| Step: 1
Training loss: 0.12058837862203794
Validation loss: 2.0882382896117004

Epoch: 5| Step: 2
Training loss: 0.09091853910896218
Validation loss: 2.031275277497148

Epoch: 5| Step: 3
Training loss: 0.07100149839836604
Validation loss: 2.0764804969914046

Epoch: 5| Step: 4
Training loss: 0.07139154475294436
Validation loss: 2.0292685961343695

Epoch: 5| Step: 5
Training loss: 0.0989094480642313
Validation loss: 2.0731719312244925

Epoch: 5| Step: 6
Training loss: 0.07108946187323267
Validation loss: 2.07332645609181

Epoch: 5| Step: 7
Training loss: 0.06414169150335848
Validation loss: 2.052423807368965

Epoch: 5| Step: 8
Training loss: 0.07349983040593816
Validation loss: 2.048681528271535

Epoch: 5| Step: 9
Training loss: 0.12518148360743156
Validation loss: 2.0909751444733007

Epoch: 5| Step: 10
Training loss: 0.08159530410670864
Validation loss: 2.0742941882197283

Epoch: 631| Step: 0
Training loss: 0.09569064370335136
Validation loss: 2.07568657184072

Epoch: 5| Step: 1
Training loss: 0.12427636136115298
Validation loss: 2.102735651934392

Epoch: 5| Step: 2
Training loss: 0.07616696586439695
Validation loss: 2.110536389436832

Epoch: 5| Step: 3
Training loss: 0.09469892157544307
Validation loss: 2.082477653090136

Epoch: 5| Step: 4
Training loss: 0.13052772371224539
Validation loss: 2.039022492826542

Epoch: 5| Step: 5
Training loss: 0.13576986867660404
Validation loss: 2.0794431318094686

Epoch: 5| Step: 6
Training loss: 0.06438033733417231
Validation loss: 2.0644617598474873

Epoch: 5| Step: 7
Training loss: 0.12291956931124476
Validation loss: 2.0819125020885556

Epoch: 5| Step: 8
Training loss: 0.12185767536638632
Validation loss: 2.088067306802582

Epoch: 5| Step: 9
Training loss: 0.10745396134873532
Validation loss: 2.0498239440612216

Epoch: 5| Step: 10
Training loss: 0.11465574725371727
Validation loss: 2.0595826117923957

Epoch: 632| Step: 0
Training loss: 0.04856473215400012
Validation loss: 2.063256910095831

Epoch: 5| Step: 1
Training loss: 0.08197897994158725
Validation loss: 2.0697936522545435

Epoch: 5| Step: 2
Training loss: 0.1341664775581488
Validation loss: 2.0911515760847963

Epoch: 5| Step: 3
Training loss: 0.10296375337063376
Validation loss: 2.042305211340528

Epoch: 5| Step: 4
Training loss: 0.13175336583152303
Validation loss: 2.0674065176188323

Epoch: 5| Step: 5
Training loss: 0.0844913969033792
Validation loss: 2.110565617634913

Epoch: 5| Step: 6
Training loss: 0.12901742793566653
Validation loss: 2.0997966241580293

Epoch: 5| Step: 7
Training loss: 0.08059074149926743
Validation loss: 2.0843503077772927

Epoch: 5| Step: 8
Training loss: 0.14081244426866724
Validation loss: 2.0931644199363006

Epoch: 5| Step: 9
Training loss: 0.1102438629009024
Validation loss: 2.0706030962296817

Epoch: 5| Step: 10
Training loss: 0.07519850166790946
Validation loss: 2.0657222184861546

Epoch: 633| Step: 0
Training loss: 0.05948450208554672
Validation loss: 2.092913419320735

Epoch: 5| Step: 1
Training loss: 0.11635699830356329
Validation loss: 2.0849618403239787

Epoch: 5| Step: 2
Training loss: 0.07855713657903475
Validation loss: 2.0276747205045376

Epoch: 5| Step: 3
Training loss: 0.14943127751128973
Validation loss: 2.0587505218536877

Epoch: 5| Step: 4
Training loss: 0.07692830755430058
Validation loss: 2.0283384674083056

Epoch: 5| Step: 5
Training loss: 0.10814838953009547
Validation loss: 2.023420554165458

Epoch: 5| Step: 6
Training loss: 0.0777203511282924
Validation loss: 2.029305884940659

Epoch: 5| Step: 7
Training loss: 0.07457715632035142
Validation loss: 2.045680116503621

Epoch: 5| Step: 8
Training loss: 0.08825850847909761
Validation loss: 2.0417428641784254

Epoch: 5| Step: 9
Training loss: 0.11453373514682429
Validation loss: 2.053761090953384

Epoch: 5| Step: 10
Training loss: 0.16552968994098277
Validation loss: 2.03611445449773

Epoch: 634| Step: 0
Training loss: 0.07482881219257205
Validation loss: 2.0335707212059932

Epoch: 5| Step: 1
Training loss: 0.125201666100925
Validation loss: 2.0461596620056026

Epoch: 5| Step: 2
Training loss: 0.0954445488983431
Validation loss: 2.0233175825221

Epoch: 5| Step: 3
Training loss: 0.10127311983436108
Validation loss: 2.071354474069395

Epoch: 5| Step: 4
Training loss: 0.1214173285266747
Validation loss: 2.052126819713465

Epoch: 5| Step: 5
Training loss: 0.12703707926796026
Validation loss: 2.0510279397018647

Epoch: 5| Step: 6
Training loss: 0.08825359364907862
Validation loss: 2.06692617256157

Epoch: 5| Step: 7
Training loss: 0.11375196673322642
Validation loss: 2.064516986129247

Epoch: 5| Step: 8
Training loss: 0.09665743735546431
Validation loss: 2.0588886069824412

Epoch: 5| Step: 9
Training loss: 0.07823645866435149
Validation loss: 2.0506270793384394

Epoch: 5| Step: 10
Training loss: 0.07050236921353821
Validation loss: 2.055267600203746

Epoch: 635| Step: 0
Training loss: 0.0928097904657527
Validation loss: 2.065720176976947

Epoch: 5| Step: 1
Training loss: 0.08729034045656522
Validation loss: 2.034845982885287

Epoch: 5| Step: 2
Training loss: 0.15488123995161818
Validation loss: 2.0262234509744337

Epoch: 5| Step: 3
Training loss: 0.07230710115221939
Validation loss: 2.045922318244611

Epoch: 5| Step: 4
Training loss: 0.07122268591353836
Validation loss: 2.037040599722723

Epoch: 5| Step: 5
Training loss: 0.09467022980669061
Validation loss: 2.020734246880706

Epoch: 5| Step: 6
Training loss: 0.09261399672670033
Validation loss: 2.001129804177876

Epoch: 5| Step: 7
Training loss: 0.06229873377655938
Validation loss: 2.022589239309131

Epoch: 5| Step: 8
Training loss: 0.07086228297406089
Validation loss: 2.018722914769262

Epoch: 5| Step: 9
Training loss: 0.10095458852270661
Validation loss: 2.030370075854769

Epoch: 5| Step: 10
Training loss: 0.15598656381307321
Validation loss: 2.0174005701877356

Epoch: 636| Step: 0
Training loss: 0.09201620157002559
Validation loss: 2.02245786297086

Epoch: 5| Step: 1
Training loss: 0.1025108798216239
Validation loss: 2.0307048340530396

Epoch: 5| Step: 2
Training loss: 0.10384392410755054
Validation loss: 2.04100950797255

Epoch: 5| Step: 3
Training loss: 0.11533312688011552
Validation loss: 2.0083548016686366

Epoch: 5| Step: 4
Training loss: 0.14509265995293996
Validation loss: 2.001614438792661

Epoch: 5| Step: 5
Training loss: 0.05458959688598281
Validation loss: 2.0385747132875784

Epoch: 5| Step: 6
Training loss: 0.1153327796517686
Validation loss: 2.0482031095475866

Epoch: 5| Step: 7
Training loss: 0.07507114562541863
Validation loss: 2.0445842297080423

Epoch: 5| Step: 8
Training loss: 0.12123658616057555
Validation loss: 2.061527327371052

Epoch: 5| Step: 9
Training loss: 0.11873426866482685
Validation loss: 2.0759177824543746

Epoch: 5| Step: 10
Training loss: 0.09282333638287509
Validation loss: 2.051683258123239

Epoch: 637| Step: 0
Training loss: 0.13999634866763913
Validation loss: 2.054253585278789

Epoch: 5| Step: 1
Training loss: 0.08932706767169259
Validation loss: 2.084642434183146

Epoch: 5| Step: 2
Training loss: 0.11139268843406055
Validation loss: 2.053219701451157

Epoch: 5| Step: 3
Training loss: 0.07243476225251896
Validation loss: 2.068939146010061

Epoch: 5| Step: 4
Training loss: 0.1161764157734743
Validation loss: 2.041556672010203

Epoch: 5| Step: 5
Training loss: 0.13079498614249643
Validation loss: 2.03731302676413

Epoch: 5| Step: 6
Training loss: 0.06859280716480529
Validation loss: 2.043505689430005

Epoch: 5| Step: 7
Training loss: 0.10150452481335148
Validation loss: 2.0777841356754263

Epoch: 5| Step: 8
Training loss: 0.0869407532460004
Validation loss: 2.051377102827843

Epoch: 5| Step: 9
Training loss: 0.08755886990454491
Validation loss: 2.051598238312148

Epoch: 5| Step: 10
Training loss: 0.12583956551302733
Validation loss: 2.0657658783768587

Epoch: 638| Step: 0
Training loss: 0.10079054253637823
Validation loss: 2.090238920641987

Epoch: 5| Step: 1
Training loss: 0.11032095206060234
Validation loss: 2.0657912736736987

Epoch: 5| Step: 2
Training loss: 0.06909867781488255
Validation loss: 2.051425256354296

Epoch: 5| Step: 3
Training loss: 0.14260575275036022
Validation loss: 2.06443006586233

Epoch: 5| Step: 4
Training loss: 0.09551594393386899
Validation loss: 2.050301272491584

Epoch: 5| Step: 5
Training loss: 0.10476667680290602
Validation loss: 2.042323390680253

Epoch: 5| Step: 6
Training loss: 0.12607970931244
Validation loss: 2.074076670892901

Epoch: 5| Step: 7
Training loss: 0.07197595870827739
Validation loss: 2.0399796302935793

Epoch: 5| Step: 8
Training loss: 0.061026254004714904
Validation loss: 2.04190044203152

Epoch: 5| Step: 9
Training loss: 0.08950712019452924
Validation loss: 2.0718592720583655

Epoch: 5| Step: 10
Training loss: 0.11083426020334484
Validation loss: 2.077024629121893

Epoch: 639| Step: 0
Training loss: 0.08307748563253918
Validation loss: 2.100950408811107

Epoch: 5| Step: 1
Training loss: 0.15179993083035673
Validation loss: 2.0615745300231367

Epoch: 5| Step: 2
Training loss: 0.07731529191537743
Validation loss: 2.0563275165361126

Epoch: 5| Step: 3
Training loss: 0.13957566585998593
Validation loss: 2.029773289597056

Epoch: 5| Step: 4
Training loss: 0.09982626806703342
Validation loss: 2.0338588296117988

Epoch: 5| Step: 5
Training loss: 0.08379425941925456
Validation loss: 2.059285413520821

Epoch: 5| Step: 6
Training loss: 0.07542117986996895
Validation loss: 2.065004203857856

Epoch: 5| Step: 7
Training loss: 0.07683946207725575
Validation loss: 2.051187694175935

Epoch: 5| Step: 8
Training loss: 0.06250089778851374
Validation loss: 2.050389723195325

Epoch: 5| Step: 9
Training loss: 0.07540286204488934
Validation loss: 2.0716548964301746

Epoch: 5| Step: 10
Training loss: 0.09467722896069196
Validation loss: 2.0741208922057104

Epoch: 640| Step: 0
Training loss: 0.0775098003162923
Validation loss: 2.0548336033722165

Epoch: 5| Step: 1
Training loss: 0.12182419188578018
Validation loss: 2.05568450503685

Epoch: 5| Step: 2
Training loss: 0.13009925246852275
Validation loss: 2.0565674430884906

Epoch: 5| Step: 3
Training loss: 0.10215384011359503
Validation loss: 2.052901389837003

Epoch: 5| Step: 4
Training loss: 0.07710656103934264
Validation loss: 2.063411388227249

Epoch: 5| Step: 5
Training loss: 0.1274500657570618
Validation loss: 2.0894894762426226

Epoch: 5| Step: 6
Training loss: 0.08989276792722739
Validation loss: 2.1038262030786146

Epoch: 5| Step: 7
Training loss: 0.11075822623230015
Validation loss: 2.1171328832683938

Epoch: 5| Step: 8
Training loss: 0.07140461492544573
Validation loss: 2.090484715281207

Epoch: 5| Step: 9
Training loss: 0.15683428477251385
Validation loss: 2.093201359835619

Epoch: 5| Step: 10
Training loss: 0.09721216318151361
Validation loss: 2.107826762188892

Epoch: 641| Step: 0
Training loss: 0.08505100102484485
Validation loss: 2.113071042925073

Epoch: 5| Step: 1
Training loss: 0.08631873640730535
Validation loss: 2.1014321305032384

Epoch: 5| Step: 2
Training loss: 0.1342507075854076
Validation loss: 2.09324688193611

Epoch: 5| Step: 3
Training loss: 0.08925609586972312
Validation loss: 2.06920702893953

Epoch: 5| Step: 4
Training loss: 0.11919912090419384
Validation loss: 2.0326631033821334

Epoch: 5| Step: 5
Training loss: 0.07982795587578877
Validation loss: 2.0608851262624523

Epoch: 5| Step: 6
Training loss: 0.09958149482397918
Validation loss: 2.0462252930508367

Epoch: 5| Step: 7
Training loss: 0.1287530291881498
Validation loss: 2.053728502832235

Epoch: 5| Step: 8
Training loss: 0.07696008929094127
Validation loss: 2.093621474245378

Epoch: 5| Step: 9
Training loss: 0.08902621973334177
Validation loss: 2.0805189715540284

Epoch: 5| Step: 10
Training loss: 0.10984880987860936
Validation loss: 2.080722412762098

Epoch: 642| Step: 0
Training loss: 0.141774749080481
Validation loss: 2.074579560568299

Epoch: 5| Step: 1
Training loss: 0.08774047848165856
Validation loss: 2.059949557724904

Epoch: 5| Step: 2
Training loss: 0.06446619695983619
Validation loss: 2.0761213862065984

Epoch: 5| Step: 3
Training loss: 0.13671479900645703
Validation loss: 2.0853826345507587

Epoch: 5| Step: 4
Training loss: 0.12688371521514907
Validation loss: 2.0857171032130797

Epoch: 5| Step: 5
Training loss: 0.1097012702810645
Validation loss: 2.0500603108972295

Epoch: 5| Step: 6
Training loss: 0.09721786329833125
Validation loss: 2.073711376699705

Epoch: 5| Step: 7
Training loss: 0.08606344985333862
Validation loss: 2.0345530521928232

Epoch: 5| Step: 8
Training loss: 0.10414090334661193
Validation loss: 2.0518271008966686

Epoch: 5| Step: 9
Training loss: 0.12004216495207692
Validation loss: 2.05711282929189

Epoch: 5| Step: 10
Training loss: 0.13144653880892065
Validation loss: 2.070830846354892

Epoch: 643| Step: 0
Training loss: 0.1257712443145302
Validation loss: 2.0346370378996275

Epoch: 5| Step: 1
Training loss: 0.06768313116150108
Validation loss: 2.046307266256596

Epoch: 5| Step: 2
Training loss: 0.09283763270671025
Validation loss: 2.0645669068784973

Epoch: 5| Step: 3
Training loss: 0.11660969464619762
Validation loss: 2.054640348746471

Epoch: 5| Step: 4
Training loss: 0.08544010113710084
Validation loss: 2.094856547730346

Epoch: 5| Step: 5
Training loss: 0.16976380395066182
Validation loss: 2.1101597513064254

Epoch: 5| Step: 6
Training loss: 0.1538017089756088
Validation loss: 2.0994650212062957

Epoch: 5| Step: 7
Training loss: 0.126986645894746
Validation loss: 2.0732159504923207

Epoch: 5| Step: 8
Training loss: 0.10795928302863335
Validation loss: 2.1069479271794216

Epoch: 5| Step: 9
Training loss: 0.0874664375318749
Validation loss: 2.138918844697866

Epoch: 5| Step: 10
Training loss: 0.1697011259133512
Validation loss: 2.0783645007055163

Epoch: 644| Step: 0
Training loss: 0.11707673401097275
Validation loss: 2.1289247140030083

Epoch: 5| Step: 1
Training loss: 0.1587742515873077
Validation loss: 2.0638199488907314

Epoch: 5| Step: 2
Training loss: 0.06715004911258496
Validation loss: 2.0865713645605966

Epoch: 5| Step: 3
Training loss: 0.09555643868169171
Validation loss: 2.059567086739816

Epoch: 5| Step: 4
Training loss: 0.08822009797997056
Validation loss: 2.065502597617047

Epoch: 5| Step: 5
Training loss: 0.12965231354917006
Validation loss: 2.0243561515797737

Epoch: 5| Step: 6
Training loss: 0.1444074577428805
Validation loss: 2.0336143969222724

Epoch: 5| Step: 7
Training loss: 0.10142477031713021
Validation loss: 2.061419265067538

Epoch: 5| Step: 8
Training loss: 0.08320131467810854
Validation loss: 2.0490951552544243

Epoch: 5| Step: 9
Training loss: 0.10938806966623037
Validation loss: 2.062501205687607

Epoch: 5| Step: 10
Training loss: 0.10786290234530371
Validation loss: 2.0648353458695516

Epoch: 645| Step: 0
Training loss: 0.10726614848465511
Validation loss: 2.0730430253065038

Epoch: 5| Step: 1
Training loss: 0.12618776109204577
Validation loss: 2.0708158234513987

Epoch: 5| Step: 2
Training loss: 0.13877967888643486
Validation loss: 2.0812854936145087

Epoch: 5| Step: 3
Training loss: 0.12333122579711311
Validation loss: 2.0647213863298974

Epoch: 5| Step: 4
Training loss: 0.08182102183520128
Validation loss: 2.067376506878983

Epoch: 5| Step: 5
Training loss: 0.10050567646922148
Validation loss: 2.068026172447171

Epoch: 5| Step: 6
Training loss: 0.10317396966407263
Validation loss: 2.069580310850451

Epoch: 5| Step: 7
Training loss: 0.15225401705420677
Validation loss: 2.054506587515544

Epoch: 5| Step: 8
Training loss: 0.13452654515766566
Validation loss: 2.0538290055000754

Epoch: 5| Step: 9
Training loss: 0.13152025362244832
Validation loss: 2.0771568733189554

Epoch: 5| Step: 10
Training loss: 0.09216824952875186
Validation loss: 2.070061709444385

Epoch: 646| Step: 0
Training loss: 0.09928685689252259
Validation loss: 2.0790332428905125

Epoch: 5| Step: 1
Training loss: 0.14336408560598862
Validation loss: 2.0696406686984825

Epoch: 5| Step: 2
Training loss: 0.07910198046726899
Validation loss: 2.0830163898157483

Epoch: 5| Step: 3
Training loss: 0.0680290072903328
Validation loss: 2.0969026559723947

Epoch: 5| Step: 4
Training loss: 0.058910552542492854
Validation loss: 2.0695781567067524

Epoch: 5| Step: 5
Training loss: 0.10621141406250834
Validation loss: 2.087239727447355

Epoch: 5| Step: 6
Training loss: 0.1287681967412858
Validation loss: 2.1085030592183274

Epoch: 5| Step: 7
Training loss: 0.08745634552493713
Validation loss: 2.0457848905070963

Epoch: 5| Step: 8
Training loss: 0.15138142426511741
Validation loss: 2.1045521836110535

Epoch: 5| Step: 9
Training loss: 0.09318960107690022
Validation loss: 2.072476602551365

Epoch: 5| Step: 10
Training loss: 0.09869312104457227
Validation loss: 2.071295439754763

Epoch: 647| Step: 0
Training loss: 0.11081627246429479
Validation loss: 2.067238100783867

Epoch: 5| Step: 1
Training loss: 0.07909951383975404
Validation loss: 2.0846053229400807

Epoch: 5| Step: 2
Training loss: 0.06823049726292878
Validation loss: 2.051515454945321

Epoch: 5| Step: 3
Training loss: 0.1711019122123323
Validation loss: 2.0495006469830095

Epoch: 5| Step: 4
Training loss: 0.1021702901685501
Validation loss: 2.0474128783560657

Epoch: 5| Step: 5
Training loss: 0.07807914759229842
Validation loss: 2.061016325356813

Epoch: 5| Step: 6
Training loss: 0.07579526353828304
Validation loss: 2.0621626575889107

Epoch: 5| Step: 7
Training loss: 0.11101812149800482
Validation loss: 2.049088132769642

Epoch: 5| Step: 8
Training loss: 0.11552156206562712
Validation loss: 2.0316865425107062

Epoch: 5| Step: 9
Training loss: 0.060892124429937175
Validation loss: 2.0195308894836645

Epoch: 5| Step: 10
Training loss: 0.07983831808010915
Validation loss: 2.0545509405603806

Epoch: 648| Step: 0
Training loss: 0.07863157071432578
Validation loss: 2.064044336927128

Epoch: 5| Step: 1
Training loss: 0.11788782824263401
Validation loss: 2.0825393870275253

Epoch: 5| Step: 2
Training loss: 0.1577216285687013
Validation loss: 2.0940065880224505

Epoch: 5| Step: 3
Training loss: 0.10692172659602076
Validation loss: 2.070172557717616

Epoch: 5| Step: 4
Training loss: 0.1176495107237916
Validation loss: 2.081703070130443

Epoch: 5| Step: 5
Training loss: 0.0910288968867392
Validation loss: 2.0524629113058364

Epoch: 5| Step: 6
Training loss: 0.08949072559816067
Validation loss: 2.0820787844531794

Epoch: 5| Step: 7
Training loss: 0.1301215136681192
Validation loss: 2.0798326597725483

Epoch: 5| Step: 8
Training loss: 0.1217001337535232
Validation loss: 2.064709797140143

Epoch: 5| Step: 9
Training loss: 0.05952997874607205
Validation loss: 2.055956304300411

Epoch: 5| Step: 10
Training loss: 0.11991705543078063
Validation loss: 2.0225155373421697

Epoch: 649| Step: 0
Training loss: 0.11075423627564804
Validation loss: 2.038667711571836

Epoch: 5| Step: 1
Training loss: 0.14461845911429422
Validation loss: 2.045462168257451

Epoch: 5| Step: 2
Training loss: 0.12111428686547893
Validation loss: 2.027643654527354

Epoch: 5| Step: 3
Training loss: 0.17035270750014805
Validation loss: 2.034213547852621

Epoch: 5| Step: 4
Training loss: 0.09104612437027675
Validation loss: 2.0560815396737264

Epoch: 5| Step: 5
Training loss: 0.06754228821393359
Validation loss: 2.0159145235367357

Epoch: 5| Step: 6
Training loss: 0.08323288025058995
Validation loss: 2.0623910354805624

Epoch: 5| Step: 7
Training loss: 0.09824806180648671
Validation loss: 2.0643711483412384

Epoch: 5| Step: 8
Training loss: 0.08171973228775953
Validation loss: 2.062701399408254

Epoch: 5| Step: 9
Training loss: 0.07210413183242484
Validation loss: 2.0509232379222024

Epoch: 5| Step: 10
Training loss: 0.06335067002484819
Validation loss: 2.0474458606210395

Epoch: 650| Step: 0
Training loss: 0.0794520384508855
Validation loss: 2.0689151864641975

Epoch: 5| Step: 1
Training loss: 0.06871512013186185
Validation loss: 2.065459779277602

Epoch: 5| Step: 2
Training loss: 0.14431861752875738
Validation loss: 2.07209817284542

Epoch: 5| Step: 3
Training loss: 0.12979279173470037
Validation loss: 2.056238892676687

Epoch: 5| Step: 4
Training loss: 0.11825508363665797
Validation loss: 2.0541444901007266

Epoch: 5| Step: 5
Training loss: 0.1080346662170461
Validation loss: 2.060248781162101

Epoch: 5| Step: 6
Training loss: 0.07553091029922143
Validation loss: 2.0485647754447434

Epoch: 5| Step: 7
Training loss: 0.06882774457382564
Validation loss: 2.059923631799876

Epoch: 5| Step: 8
Training loss: 0.12553965040355666
Validation loss: 2.054329145793623

Epoch: 5| Step: 9
Training loss: 0.10601851881037208
Validation loss: 2.059892764688858

Epoch: 5| Step: 10
Training loss: 0.0938686623221306
Validation loss: 2.0495853347841426

Epoch: 651| Step: 0
Training loss: 0.10855473599702205
Validation loss: 2.058210832138061

Epoch: 5| Step: 1
Training loss: 0.07965435444348733
Validation loss: 2.07490362533372

Epoch: 5| Step: 2
Training loss: 0.09284156506373929
Validation loss: 2.061306253408865

Epoch: 5| Step: 3
Training loss: 0.07506836665999456
Validation loss: 2.0183290469687205

Epoch: 5| Step: 4
Training loss: 0.11970250726591973
Validation loss: 2.0572335756967886

Epoch: 5| Step: 5
Training loss: 0.12357654556681191
Validation loss: 2.1049320819203916

Epoch: 5| Step: 6
Training loss: 0.10802559266492824
Validation loss: 2.0898007765392035

Epoch: 5| Step: 7
Training loss: 0.13507342088229213
Validation loss: 2.062904502204846

Epoch: 5| Step: 8
Training loss: 0.09138061110878025
Validation loss: 2.0909561694202368

Epoch: 5| Step: 9
Training loss: 0.08898727456644469
Validation loss: 2.085626508091412

Epoch: 5| Step: 10
Training loss: 0.09350828959441879
Validation loss: 2.0772824821277474

Epoch: 652| Step: 0
Training loss: 0.07724358329117582
Validation loss: 2.080188973154985

Epoch: 5| Step: 1
Training loss: 0.07293357042948985
Validation loss: 2.0682081099652234

Epoch: 5| Step: 2
Training loss: 0.09719606692957551
Validation loss: 2.0648510988681474

Epoch: 5| Step: 3
Training loss: 0.08403569693802146
Validation loss: 2.092175638848557

Epoch: 5| Step: 4
Training loss: 0.0761438189703012
Validation loss: 2.0294461472000758

Epoch: 5| Step: 5
Training loss: 0.11882634218622866
Validation loss: 2.0329254535434313

Epoch: 5| Step: 6
Training loss: 0.13546745711064934
Validation loss: 2.05781288963908

Epoch: 5| Step: 7
Training loss: 0.08671486991931075
Validation loss: 2.059642741715472

Epoch: 5| Step: 8
Training loss: 0.0807750572112665
Validation loss: 2.0272511525444976

Epoch: 5| Step: 9
Training loss: 0.1487277794016842
Validation loss: 2.080178201268738

Epoch: 5| Step: 10
Training loss: 0.10765970086157496
Validation loss: 2.0349784381164877

Epoch: 653| Step: 0
Training loss: 0.09591621401204538
Validation loss: 2.047844494438881

Epoch: 5| Step: 1
Training loss: 0.07921510365425308
Validation loss: 2.0349846690164983

Epoch: 5| Step: 2
Training loss: 0.0678838951058756
Validation loss: 2.046533270036625

Epoch: 5| Step: 3
Training loss: 0.0679463819715905
Validation loss: 2.047651063458708

Epoch: 5| Step: 4
Training loss: 0.14866969494366383
Validation loss: 2.101440850301438

Epoch: 5| Step: 5
Training loss: 0.1493128639534514
Validation loss: 2.0600431444632146

Epoch: 5| Step: 6
Training loss: 0.0905134081273539
Validation loss: 2.1037674213102147

Epoch: 5| Step: 7
Training loss: 0.08163761026118438
Validation loss: 2.0692883655390997

Epoch: 5| Step: 8
Training loss: 0.0699395514367178
Validation loss: 2.061232953572571

Epoch: 5| Step: 9
Training loss: 0.11128100435320365
Validation loss: 2.07216747083528

Epoch: 5| Step: 10
Training loss: 0.07878408771860614
Validation loss: 2.073235362113764

Epoch: 654| Step: 0
Training loss: 0.06434750210969288
Validation loss: 2.0708177992758325

Epoch: 5| Step: 1
Training loss: 0.0513821296389867
Validation loss: 2.0706705592896135

Epoch: 5| Step: 2
Training loss: 0.12011378368734224
Validation loss: 2.0334857799640664

Epoch: 5| Step: 3
Training loss: 0.07435804083052698
Validation loss: 2.073567298588663

Epoch: 5| Step: 4
Training loss: 0.14148471220324907
Validation loss: 2.0646313077296212

Epoch: 5| Step: 5
Training loss: 0.1297823869052381
Validation loss: 2.0700540973784904

Epoch: 5| Step: 6
Training loss: 0.0747522859074331
Validation loss: 2.055047238488643

Epoch: 5| Step: 7
Training loss: 0.06287288074851259
Validation loss: 2.0483219894007885

Epoch: 5| Step: 8
Training loss: 0.0749270962744483
Validation loss: 2.044313520293215

Epoch: 5| Step: 9
Training loss: 0.12207114410117127
Validation loss: 2.0307986774844045

Epoch: 5| Step: 10
Training loss: 0.16895949023078424
Validation loss: 2.0381951777882015

Epoch: 655| Step: 0
Training loss: 0.05299851264277995
Validation loss: 2.0475836820741895

Epoch: 5| Step: 1
Training loss: 0.09063040967941974
Validation loss: 2.060451516986947

Epoch: 5| Step: 2
Training loss: 0.12288474194364424
Validation loss: 2.036946713800628

Epoch: 5| Step: 3
Training loss: 0.09164256457254327
Validation loss: 2.0246706193750597

Epoch: 5| Step: 4
Training loss: 0.131112103740349
Validation loss: 2.0479174209850544

Epoch: 5| Step: 5
Training loss: 0.11362779162327513
Validation loss: 2.0162653782178763

Epoch: 5| Step: 6
Training loss: 0.09506351476236796
Validation loss: 2.051411685952132

Epoch: 5| Step: 7
Training loss: 0.09743058834863118
Validation loss: 2.0672850273291843

Epoch: 5| Step: 8
Training loss: 0.12528216284925778
Validation loss: 2.039268225849379

Epoch: 5| Step: 9
Training loss: 0.062232482485473334
Validation loss: 2.032052014760919

Epoch: 5| Step: 10
Training loss: 0.1430732608233704
Validation loss: 2.0902219963468758

Epoch: 656| Step: 0
Training loss: 0.09154564893643426
Validation loss: 2.054465602679057

Epoch: 5| Step: 1
Training loss: 0.1337830201058392
Validation loss: 2.0307060188515362

Epoch: 5| Step: 2
Training loss: 0.08789345683727974
Validation loss: 2.0714331725269637

Epoch: 5| Step: 3
Training loss: 0.11786415724425167
Validation loss: 2.0875593842972036

Epoch: 5| Step: 4
Training loss: 0.21789790133489312
Validation loss: 2.056374865661519

Epoch: 5| Step: 5
Training loss: 0.0958163263383652
Validation loss: 2.0423085440746833

Epoch: 5| Step: 6
Training loss: 0.09505836148191518
Validation loss: 2.0381291542003717

Epoch: 5| Step: 7
Training loss: 0.12173992077540317
Validation loss: 2.017362756970669

Epoch: 5| Step: 8
Training loss: 0.04545689300413811
Validation loss: 2.0333394022097395

Epoch: 5| Step: 9
Training loss: 0.09450523337658806
Validation loss: 2.0648061227952987

Epoch: 5| Step: 10
Training loss: 0.07786908853004762
Validation loss: 2.06465527973789

Epoch: 657| Step: 0
Training loss: 0.14147893265357633
Validation loss: 2.042252967668173

Epoch: 5| Step: 1
Training loss: 0.0610873990587201
Validation loss: 2.0546846140599464

Epoch: 5| Step: 2
Training loss: 0.06619131844099113
Validation loss: 2.068724419621821

Epoch: 5| Step: 3
Training loss: 0.0908800871834024
Validation loss: 2.0747341501889447

Epoch: 5| Step: 4
Training loss: 0.08524420804315952
Validation loss: 2.061178190913911

Epoch: 5| Step: 5
Training loss: 0.13673259801214518
Validation loss: 2.0635270730712043

Epoch: 5| Step: 6
Training loss: 0.05857274950709046
Validation loss: 2.063681617316868

Epoch: 5| Step: 7
Training loss: 0.1191217610793491
Validation loss: 2.063073229937841

Epoch: 5| Step: 8
Training loss: 0.1068921771035094
Validation loss: 2.056887543627326

Epoch: 5| Step: 9
Training loss: 0.11092126267437855
Validation loss: 2.0641950433041183

Epoch: 5| Step: 10
Training loss: 0.27784143039780695
Validation loss: 2.0553353152935667

Epoch: 658| Step: 0
Training loss: 0.1574083426553964
Validation loss: 2.087372433814474

Epoch: 5| Step: 1
Training loss: 0.5816418157786931
Validation loss: 2.150016138164548

Epoch: 5| Step: 2
Training loss: 0.3646317676887781
Validation loss: 2.0993585075047587

Epoch: 5| Step: 3
Training loss: 0.5273299886532717
Validation loss: 2.063083661806381

Epoch: 5| Step: 4
Training loss: 0.3982329123830823
Validation loss: 2.0400601567280545

Epoch: 5| Step: 5
Training loss: 0.532972712215479
Validation loss: 2.100737995250068

Epoch: 5| Step: 6
Training loss: 0.41181325895442433
Validation loss: 2.158998226267237

Epoch: 5| Step: 7
Training loss: 0.3673978568225871
Validation loss: 2.1689968560744917

Epoch: 5| Step: 8
Training loss: 0.43990048843776386
Validation loss: 2.118626872993509

Epoch: 5| Step: 9
Training loss: 0.43542078356948805
Validation loss: 2.218069983054423

Epoch: 5| Step: 10
Training loss: 0.6054309956254468
Validation loss: 2.2301276721851466

Epoch: 659| Step: 0
Training loss: 0.785259600617392
Validation loss: 2.304206685919551

Epoch: 5| Step: 1
Training loss: 0.8990939851670198
Validation loss: 2.3193941895229684

Epoch: 5| Step: 2
Training loss: 0.38169182987358863
Validation loss: 2.302885204220723

Epoch: 5| Step: 3
Training loss: 0.5307751384537104
Validation loss: 2.322785952724654

Epoch: 5| Step: 4
Training loss: 0.8532731958025577
Validation loss: 2.280776474383305

Epoch: 5| Step: 5
Training loss: 0.5138924998795165
Validation loss: 2.1711885546825482

Epoch: 5| Step: 6
Training loss: 0.9408164808477611
Validation loss: 2.3224697278113147

Epoch: 5| Step: 7
Training loss: 1.3133794925939979
Validation loss: 2.329506343092766

Epoch: 5| Step: 8
Training loss: 0.4509127644861353
Validation loss: 2.1620620550580707

Epoch: 5| Step: 9
Training loss: 0.8866809047067301
Validation loss: 2.1638187022196047

Epoch: 5| Step: 10
Training loss: 1.0971117399956651
Validation loss: 2.1100794410068398

Epoch: 660| Step: 0
Training loss: 0.6507963684817154
Validation loss: 2.0443138714229754

Epoch: 5| Step: 1
Training loss: 0.5616861124332481
Validation loss: 2.0321400373406235

Epoch: 5| Step: 2
Training loss: 0.6709664211782659
Validation loss: 2.112951384753824

Epoch: 5| Step: 3
Training loss: 0.7091018117108735
Validation loss: 2.1054974622749403

Epoch: 5| Step: 4
Training loss: 0.36915689260978574
Validation loss: 2.1275268330571353

Epoch: 5| Step: 5
Training loss: 0.4583103181377909
Validation loss: 2.070780710161751

Epoch: 5| Step: 6
Training loss: 0.5922376042812328
Validation loss: 2.180680776279929

Epoch: 5| Step: 7
Training loss: 0.7618940494024093
Validation loss: 2.2273908880713833

Epoch: 5| Step: 8
Training loss: 0.6860041818380097
Validation loss: 2.215481260400105

Epoch: 5| Step: 9
Training loss: 0.7805623270474896
Validation loss: 2.1621715493250986

Epoch: 5| Step: 10
Training loss: 0.5115688191689468
Validation loss: 2.0789224835573066

Epoch: 661| Step: 0
Training loss: 0.777051132564506
Validation loss: 2.064316514883018

Epoch: 5| Step: 1
Training loss: 0.5428259133376527
Validation loss: 2.055812071127926

Epoch: 5| Step: 2
Training loss: 0.5447994901436957
Validation loss: 2.0497714430232237

Epoch: 5| Step: 3
Training loss: 0.5988387831643344
Validation loss: 2.030403359587559

Epoch: 5| Step: 4
Training loss: 0.5564361196597444
Validation loss: 2.049534376175049

Epoch: 5| Step: 5
Training loss: 0.45695304201451115
Validation loss: 2.0817171905899143

Epoch: 5| Step: 6
Training loss: 0.4951452815344796
Validation loss: 2.1308052991011976

Epoch: 5| Step: 7
Training loss: 0.6102023255050392
Validation loss: 2.1672440529423915

Epoch: 5| Step: 8
Training loss: 0.7949352216420251
Validation loss: 2.1744723207836225

Epoch: 5| Step: 9
Training loss: 0.4477238535805499
Validation loss: 2.0959819015028245

Epoch: 5| Step: 10
Training loss: 0.39273058839197666
Validation loss: 2.1229055761240216

Epoch: 662| Step: 0
Training loss: 0.6362816650215408
Validation loss: 2.125245296693792

Epoch: 5| Step: 1
Training loss: 0.5561530671688529
Validation loss: 2.1456314965277756

Epoch: 5| Step: 2
Training loss: 0.328338190484952
Validation loss: 2.1185757617560648

Epoch: 5| Step: 3
Training loss: 0.45640970008744963
Validation loss: 2.0641405492555402

Epoch: 5| Step: 4
Training loss: 0.6718218360981106
Validation loss: 2.123078582663044

Epoch: 5| Step: 5
Training loss: 0.43983822373599435
Validation loss: 2.1844779614324352

Epoch: 5| Step: 6
Training loss: 0.4678179056776468
Validation loss: 2.1949500158825117

Epoch: 5| Step: 7
Training loss: 0.43745527720065847
Validation loss: 2.22720415749618

Epoch: 5| Step: 8
Training loss: 0.7035062603960014
Validation loss: 2.2959233491038193

Epoch: 5| Step: 9
Training loss: 0.8854726025733317
Validation loss: 2.2841599812585462

Epoch: 5| Step: 10
Training loss: 0.563903620315555
Validation loss: 2.208473886794828

Epoch: 663| Step: 0
Training loss: 1.106246459006984
Validation loss: 2.1768143111768166

Epoch: 5| Step: 1
Training loss: 0.4558039431305572
Validation loss: 2.1802412895256102

Epoch: 5| Step: 2
Training loss: 0.5579842129511324
Validation loss: 2.1721170425845195

Epoch: 5| Step: 3
Training loss: 0.6216336668611981
Validation loss: 2.2068895659477428

Epoch: 5| Step: 4
Training loss: 0.601533666142628
Validation loss: 2.1811667612637575

Epoch: 5| Step: 5
Training loss: 0.5390603991481367
Validation loss: 2.2079281898695426

Epoch: 5| Step: 6
Training loss: 0.6099606658417033
Validation loss: 2.3010707301026163

Epoch: 5| Step: 7
Training loss: 0.6378462701853947
Validation loss: 2.2295245033944737

Epoch: 5| Step: 8
Training loss: 0.3757146938967728
Validation loss: 2.259421179882461

Epoch: 5| Step: 9
Training loss: 0.7197524833411106
Validation loss: 2.3030956301222707

Epoch: 5| Step: 10
Training loss: 1.1222664684022947
Validation loss: 2.3103680093664947

Epoch: 664| Step: 0
Training loss: 0.539132321023885
Validation loss: 2.305320585773745

Epoch: 5| Step: 1
Training loss: 0.7100051803131243
Validation loss: 2.2711377947808598

Epoch: 5| Step: 2
Training loss: 0.6182364712170874
Validation loss: 2.2651105070964905

Epoch: 5| Step: 3
Training loss: 0.5280011635680816
Validation loss: 2.1982526846483106

Epoch: 5| Step: 4
Training loss: 0.725546259456212
Validation loss: 2.1411845726817247

Epoch: 5| Step: 5
Training loss: 0.6853965094442122
Validation loss: 2.0540896261381394

Epoch: 5| Step: 6
Training loss: 0.6748219555468538
Validation loss: 1.9573541373684917

Epoch: 5| Step: 7
Training loss: 0.6861155398372192
Validation loss: 1.9389822824293124

Epoch: 5| Step: 8
Training loss: 0.5024345553184076
Validation loss: 1.9510669876529088

Epoch: 5| Step: 9
Training loss: 0.6714174797640593
Validation loss: 2.006194388244613

Epoch: 5| Step: 10
Training loss: 1.0247950395493832
Validation loss: 2.0825607770627834

Epoch: 665| Step: 0
Training loss: 0.7150339592691892
Validation loss: 2.047217918289214

Epoch: 5| Step: 1
Training loss: 0.4671790661257889
Validation loss: 1.9713435112126925

Epoch: 5| Step: 2
Training loss: 0.45048516927984306
Validation loss: 2.0408779497633933

Epoch: 5| Step: 3
Training loss: 0.45686183952236414
Validation loss: 2.1831066465817175

Epoch: 5| Step: 4
Training loss: 0.6348548239611272
Validation loss: 2.2198211167741975

Epoch: 5| Step: 5
Training loss: 1.009853041976636
Validation loss: 2.2035395885909295

Epoch: 5| Step: 6
Training loss: 0.6135315353990558
Validation loss: 2.130590356198063

Epoch: 5| Step: 7
Training loss: 0.5172548256008748
Validation loss: 2.0753497080204837

Epoch: 5| Step: 8
Training loss: 0.5778172937073646
Validation loss: 2.064025907347446

Epoch: 5| Step: 9
Training loss: 0.4288852832443053
Validation loss: 2.0454895809239493

Epoch: 5| Step: 10
Training loss: 0.6138949391290822
Validation loss: 2.0325762121166533

Epoch: 666| Step: 0
Training loss: 0.4203225818828803
Validation loss: 1.9628784564596171

Epoch: 5| Step: 1
Training loss: 0.551553252793729
Validation loss: 1.966148904429803

Epoch: 5| Step: 2
Training loss: 0.78100364615582
Validation loss: 1.9755827322749646

Epoch: 5| Step: 3
Training loss: 0.6837677652397822
Validation loss: 1.968949156319279

Epoch: 5| Step: 4
Training loss: 0.5572996020123484
Validation loss: 1.9790572139955889

Epoch: 5| Step: 5
Training loss: 0.4416645779500311
Validation loss: 2.039925908211609

Epoch: 5| Step: 6
Training loss: 0.7156574641697528
Validation loss: 2.045061661045681

Epoch: 5| Step: 7
Training loss: 0.37312899180054976
Validation loss: 2.1094748433500925

Epoch: 5| Step: 8
Training loss: 0.5814769588901118
Validation loss: 2.131685013256948

Epoch: 5| Step: 9
Training loss: 0.5422062631488044
Validation loss: 2.1671809180957107

Epoch: 5| Step: 10
Training loss: 0.6318211502160772
Validation loss: 2.1583662011653035

Epoch: 667| Step: 0
Training loss: 0.3483006901575929
Validation loss: 2.132665625567203

Epoch: 5| Step: 1
Training loss: 0.44537803100809353
Validation loss: 2.161087771359965

Epoch: 5| Step: 2
Training loss: 0.5039683458969191
Validation loss: 2.1909067817730254

Epoch: 5| Step: 3
Training loss: 0.5236558031942009
Validation loss: 2.120508714927002

Epoch: 5| Step: 4
Training loss: 0.45362689733857414
Validation loss: 2.0714064212656216

Epoch: 5| Step: 5
Training loss: 0.3321557204367644
Validation loss: 2.024820043978265

Epoch: 5| Step: 6
Training loss: 0.6583269268842828
Validation loss: 2.1143694949891314

Epoch: 5| Step: 7
Training loss: 0.631210937802173
Validation loss: 2.1268117891170513

Epoch: 5| Step: 8
Training loss: 0.4647408219190959
Validation loss: 2.077654239744591

Epoch: 5| Step: 9
Training loss: 0.4688295455832271
Validation loss: 1.9868107242918456

Epoch: 5| Step: 10
Training loss: 0.47756494557264095
Validation loss: 1.9733488153942558

Epoch: 668| Step: 0
Training loss: 0.27425548274837286
Validation loss: 1.982292678254485

Epoch: 5| Step: 1
Training loss: 0.31885824142107255
Validation loss: 2.0317592995196248

Epoch: 5| Step: 2
Training loss: 0.5313883769510402
Validation loss: 2.0777361537862338

Epoch: 5| Step: 3
Training loss: 0.481810935817193
Validation loss: 2.065519288808822

Epoch: 5| Step: 4
Training loss: 0.4975432598532665
Validation loss: 2.071560719251027

Epoch: 5| Step: 5
Training loss: 0.32611527779936633
Validation loss: 2.119845112067414

Epoch: 5| Step: 6
Training loss: 0.4748150885951903
Validation loss: 2.119972326723406

Epoch: 5| Step: 7
Training loss: 0.35918788599777124
Validation loss: 2.145086406556801

Epoch: 5| Step: 8
Training loss: 0.4753259657156844
Validation loss: 2.15951826013539

Epoch: 5| Step: 9
Training loss: 0.3667225227113133
Validation loss: 2.105835218835779

Epoch: 5| Step: 10
Training loss: 0.26404814540061483
Validation loss: 2.1260131384812344

Epoch: 669| Step: 0
Training loss: 0.3453283703294268
Validation loss: 2.117936241581373

Epoch: 5| Step: 1
Training loss: 0.4446940896463478
Validation loss: 2.103059890827286

Epoch: 5| Step: 2
Training loss: 0.2957297999697832
Validation loss: 2.0927754905935267

Epoch: 5| Step: 3
Training loss: 0.3202733853346271
Validation loss: 2.0979774070215824

Epoch: 5| Step: 4
Training loss: 0.3487009147570235
Validation loss: 2.135886550056681

Epoch: 5| Step: 5
Training loss: 0.38436871112547943
Validation loss: 2.1158259761718434

Epoch: 5| Step: 6
Training loss: 0.32910726751708513
Validation loss: 2.1114786915944257

Epoch: 5| Step: 7
Training loss: 0.24685331472692565
Validation loss: 2.1201271470327194

Epoch: 5| Step: 8
Training loss: 0.4272447335357812
Validation loss: 2.0908712237092777

Epoch: 5| Step: 9
Training loss: 0.2882420779443965
Validation loss: 2.0605311223765277

Epoch: 5| Step: 10
Training loss: 0.2554651090963286
Validation loss: 2.0928433089225726

Epoch: 670| Step: 0
Training loss: 0.37828100863878
Validation loss: 2.066557146988483

Epoch: 5| Step: 1
Training loss: 0.24266038381441488
Validation loss: 2.065735825186564

Epoch: 5| Step: 2
Training loss: 0.26757000820351223
Validation loss: 2.069136378562128

Epoch: 5| Step: 3
Training loss: 0.4204351083260178
Validation loss: 2.0534828029716583

Epoch: 5| Step: 4
Training loss: 0.32378542334395727
Validation loss: 2.0761653404699083

Epoch: 5| Step: 5
Training loss: 0.3417485339175843
Validation loss: 2.0748801016239216

Epoch: 5| Step: 6
Training loss: 0.3071843326207397
Validation loss: 2.0343111729128576

Epoch: 5| Step: 7
Training loss: 0.32142242168416923
Validation loss: 2.0743890217409917

Epoch: 5| Step: 8
Training loss: 0.2834042854152657
Validation loss: 2.091461233455545

Epoch: 5| Step: 9
Training loss: 0.2856366539545506
Validation loss: 2.0942068610155427

Epoch: 5| Step: 10
Training loss: 0.23262941086536795
Validation loss: 2.1076759316698133

Epoch: 671| Step: 0
Training loss: 0.22359995204926303
Validation loss: 2.146493045919592

Epoch: 5| Step: 1
Training loss: 0.21275218346928793
Validation loss: 2.107876083519487

Epoch: 5| Step: 2
Training loss: 0.4126589757734678
Validation loss: 2.1216315454493264

Epoch: 5| Step: 3
Training loss: 0.2479999527892714
Validation loss: 2.1228509757800613

Epoch: 5| Step: 4
Training loss: 0.2454634800156449
Validation loss: 2.124863269709135

Epoch: 5| Step: 5
Training loss: 0.23905621034164637
Validation loss: 2.1103717413326457

Epoch: 5| Step: 6
Training loss: 0.2889125022397338
Validation loss: 2.084317311110042

Epoch: 5| Step: 7
Training loss: 0.2255454254103808
Validation loss: 2.1120862113702197

Epoch: 5| Step: 8
Training loss: 0.17649869736590593
Validation loss: 2.0482157311828115

Epoch: 5| Step: 9
Training loss: 0.2641934499014193
Validation loss: 2.0600031048283096

Epoch: 5| Step: 10
Training loss: 0.27130027401787615
Validation loss: 2.0819078720671222

Epoch: 672| Step: 0
Training loss: 0.21146398644023828
Validation loss: 2.0788756686394665

Epoch: 5| Step: 1
Training loss: 0.13186496838837541
Validation loss: 2.102899234300451

Epoch: 5| Step: 2
Training loss: 0.18167174493147376
Validation loss: 2.09079712359167

Epoch: 5| Step: 3
Training loss: 0.2273957042385008
Validation loss: 2.1035545085706935

Epoch: 5| Step: 4
Training loss: 0.20405105257858808
Validation loss: 2.110632153776708

Epoch: 5| Step: 5
Training loss: 0.2023768401613037
Validation loss: 2.10451089250031

Epoch: 5| Step: 6
Training loss: 0.1925140939853976
Validation loss: 2.1334362576091723

Epoch: 5| Step: 7
Training loss: 0.2692092962924314
Validation loss: 2.123624341879827

Epoch: 5| Step: 8
Training loss: 0.2899999495826875
Validation loss: 2.107639352500933

Epoch: 5| Step: 9
Training loss: 0.23812368530250932
Validation loss: 2.1248598155061234

Epoch: 5| Step: 10
Training loss: 0.20568872106520614
Validation loss: 2.093870069831899

Epoch: 673| Step: 0
Training loss: 0.1368162624840318
Validation loss: 2.1043255405965753

Epoch: 5| Step: 1
Training loss: 0.2158898547920049
Validation loss: 2.10234749454373

Epoch: 5| Step: 2
Training loss: 0.16123713959561137
Validation loss: 2.0795677358839444

Epoch: 5| Step: 3
Training loss: 0.18139689510909926
Validation loss: 2.0778630316903355

Epoch: 5| Step: 4
Training loss: 0.2766115166713143
Validation loss: 2.06851909258258

Epoch: 5| Step: 5
Training loss: 0.18862543502034457
Validation loss: 2.0539144983931346

Epoch: 5| Step: 6
Training loss: 0.1346629553311875
Validation loss: 2.065703878959513

Epoch: 5| Step: 7
Training loss: 0.2072805397283772
Validation loss: 2.082913503696532

Epoch: 5| Step: 8
Training loss: 0.17524472053455264
Validation loss: 2.0653741678637156

Epoch: 5| Step: 9
Training loss: 0.20505567155262452
Validation loss: 2.080337509936113

Epoch: 5| Step: 10
Training loss: 0.1749109286315877
Validation loss: 2.0608066644094873

Epoch: 674| Step: 0
Training loss: 0.15922496011432238
Validation loss: 2.0945869405196986

Epoch: 5| Step: 1
Training loss: 0.12147542577083245
Validation loss: 2.100452709964976

Epoch: 5| Step: 2
Training loss: 0.20225021085504166
Validation loss: 2.1273040700419226

Epoch: 5| Step: 3
Training loss: 0.12717465366281122
Validation loss: 2.103561338867012

Epoch: 5| Step: 4
Training loss: 0.18381667299666937
Validation loss: 2.0887487398502427

Epoch: 5| Step: 5
Training loss: 0.16733819685198384
Validation loss: 2.113313809596406

Epoch: 5| Step: 6
Training loss: 0.14371293616350195
Validation loss: 2.107901667155901

Epoch: 5| Step: 7
Training loss: 0.19384264038668678
Validation loss: 2.0995128203214444

Epoch: 5| Step: 8
Training loss: 0.14156345643947774
Validation loss: 2.1023122067259368

Epoch: 5| Step: 9
Training loss: 0.2346831679928514
Validation loss: 2.0983844696166822

Epoch: 5| Step: 10
Training loss: 0.18503793888020667
Validation loss: 2.083872237697687

Epoch: 675| Step: 0
Training loss: 0.2040963605738017
Validation loss: 2.0639433758875545

Epoch: 5| Step: 1
Training loss: 0.12467197128509235
Validation loss: 2.0716128611333016

Epoch: 5| Step: 2
Training loss: 0.15595030653661388
Validation loss: 2.0903163568348853

Epoch: 5| Step: 3
Training loss: 0.10182697907154672
Validation loss: 2.095612437306169

Epoch: 5| Step: 4
Training loss: 0.16358381784086853
Validation loss: 2.079644149316498

Epoch: 5| Step: 5
Training loss: 0.24957451524717034
Validation loss: 2.069405048013073

Epoch: 5| Step: 6
Training loss: 0.1716787670227997
Validation loss: 2.113513838732187

Epoch: 5| Step: 7
Training loss: 0.20312747587015545
Validation loss: 2.0939210721738646

Epoch: 5| Step: 8
Training loss: 0.15824897125363244
Validation loss: 2.0575965374036826

Epoch: 5| Step: 9
Training loss: 0.13936626496761587
Validation loss: 2.0962775681435697

Epoch: 5| Step: 10
Training loss: 0.18240167273130348
Validation loss: 2.0722543981082793

Epoch: 676| Step: 0
Training loss: 0.14710704704383487
Validation loss: 2.100365066695503

Epoch: 5| Step: 1
Training loss: 0.19226176912548157
Validation loss: 2.0940195111270334

Epoch: 5| Step: 2
Training loss: 0.17264169139672533
Validation loss: 2.1009815329619004

Epoch: 5| Step: 3
Training loss: 0.11695894364462876
Validation loss: 2.078137526257352

Epoch: 5| Step: 4
Training loss: 0.19111066493844314
Validation loss: 2.1252930250337556

Epoch: 5| Step: 5
Training loss: 0.15559971914278292
Validation loss: 2.086719762768147

Epoch: 5| Step: 6
Training loss: 0.1542164677544787
Validation loss: 2.1411685228129014

Epoch: 5| Step: 7
Training loss: 0.16944793948254294
Validation loss: 2.1188304889101577

Epoch: 5| Step: 8
Training loss: 0.25386099778914756
Validation loss: 2.097063906219638

Epoch: 5| Step: 9
Training loss: 0.12945844403368478
Validation loss: 2.0826787857637368

Epoch: 5| Step: 10
Training loss: 0.1178919046103751
Validation loss: 2.0799735753646345

Epoch: 677| Step: 0
Training loss: 0.15769633606773883
Validation loss: 2.0676303862368393

Epoch: 5| Step: 1
Training loss: 0.18770637678071522
Validation loss: 2.063178133984775

Epoch: 5| Step: 2
Training loss: 0.21031251791150496
Validation loss: 2.056206254680482

Epoch: 5| Step: 3
Training loss: 0.14352889056252513
Validation loss: 2.0563597564723604

Epoch: 5| Step: 4
Training loss: 0.16372802677037648
Validation loss: 2.0794663487035483

Epoch: 5| Step: 5
Training loss: 0.15117082472246615
Validation loss: 2.0648026699333135

Epoch: 5| Step: 6
Training loss: 0.1651006617510003
Validation loss: 2.081374738747129

Epoch: 5| Step: 7
Training loss: 0.2055166098113483
Validation loss: 2.084351210558275

Epoch: 5| Step: 8
Training loss: 0.09219742192199666
Validation loss: 2.0972122966424003

Epoch: 5| Step: 9
Training loss: 0.1153438258458924
Validation loss: 2.0905888349076833

Epoch: 5| Step: 10
Training loss: 0.12134454505526339
Validation loss: 2.115373901835145

Epoch: 678| Step: 0
Training loss: 0.16197718550604068
Validation loss: 2.1199535864247583

Epoch: 5| Step: 1
Training loss: 0.18378175078390124
Validation loss: 2.1139451743140074

Epoch: 5| Step: 2
Training loss: 0.13160534224569642
Validation loss: 2.1287521594043235

Epoch: 5| Step: 3
Training loss: 0.17671607773545464
Validation loss: 2.1020303475258584

Epoch: 5| Step: 4
Training loss: 0.1387695049417405
Validation loss: 2.1084822892191277

Epoch: 5| Step: 5
Training loss: 0.13453942125650395
Validation loss: 2.0821230956090013

Epoch: 5| Step: 6
Training loss: 0.18441216692266416
Validation loss: 2.0920021590094047

Epoch: 5| Step: 7
Training loss: 0.13066047526682734
Validation loss: 2.1081393409646583

Epoch: 5| Step: 8
Training loss: 0.13989042776428995
Validation loss: 2.0817599208369604

Epoch: 5| Step: 9
Training loss: 0.1451239097855728
Validation loss: 2.074146894050735

Epoch: 5| Step: 10
Training loss: 0.1815747992901413
Validation loss: 2.0986025501658796

Epoch: 679| Step: 0
Training loss: 0.13103879186931736
Validation loss: 2.0574997032052775

Epoch: 5| Step: 1
Training loss: 0.11511568244517181
Validation loss: 2.0680811380548034

Epoch: 5| Step: 2
Training loss: 0.12803721822664627
Validation loss: 2.0728263243724148

Epoch: 5| Step: 3
Training loss: 0.12221851507694428
Validation loss: 2.0723245933273446

Epoch: 5| Step: 4
Training loss: 0.12902732422876367
Validation loss: 2.07289995506337

Epoch: 5| Step: 5
Training loss: 0.10879321852301252
Validation loss: 2.0633751413066173

Epoch: 5| Step: 6
Training loss: 0.13655831596808707
Validation loss: 2.086109048781474

Epoch: 5| Step: 7
Training loss: 0.1343347877393339
Validation loss: 2.0872540597827713

Epoch: 5| Step: 8
Training loss: 0.10726139479100985
Validation loss: 2.0881925613380625

Epoch: 5| Step: 9
Training loss: 0.14453793200949794
Validation loss: 2.083153563916247

Epoch: 5| Step: 10
Training loss: 0.14499080900133762
Validation loss: 2.100495814561852

Epoch: 680| Step: 0
Training loss: 0.11571981128784911
Validation loss: 2.0676196419153223

Epoch: 5| Step: 1
Training loss: 0.1302623652567037
Validation loss: 2.091880365196909

Epoch: 5| Step: 2
Training loss: 0.08094416977490256
Validation loss: 2.0677952848227754

Epoch: 5| Step: 3
Training loss: 0.10477990797681203
Validation loss: 2.0814034218904505

Epoch: 5| Step: 4
Training loss: 0.12842191392763602
Validation loss: 2.0448412805031415

Epoch: 5| Step: 5
Training loss: 0.15865260310036194
Validation loss: 2.048623663259736

Epoch: 5| Step: 6
Training loss: 0.1338654390615506
Validation loss: 2.0570873349579313

Epoch: 5| Step: 7
Training loss: 0.09295300622875727
Validation loss: 2.0770062378833094

Epoch: 5| Step: 8
Training loss: 0.09036678985774688
Validation loss: 2.0726691935320365

Epoch: 5| Step: 9
Training loss: 0.12551260686432372
Validation loss: 2.0457529103019985

Epoch: 5| Step: 10
Training loss: 0.09810550824877859
Validation loss: 2.0662045612526088

Epoch: 681| Step: 0
Training loss: 0.12639845943138328
Validation loss: 2.04614878426836

Epoch: 5| Step: 1
Training loss: 0.10908775843899711
Validation loss: 2.056455466906036

Epoch: 5| Step: 2
Training loss: 0.13964452938133293
Validation loss: 2.0728178090897673

Epoch: 5| Step: 3
Training loss: 0.18879695205731103
Validation loss: 2.084673592753215

Epoch: 5| Step: 4
Training loss: 0.12456664575519485
Validation loss: 2.069980659598613

Epoch: 5| Step: 5
Training loss: 0.1304469727141334
Validation loss: 2.0921043984258607

Epoch: 5| Step: 6
Training loss: 0.152724657944755
Validation loss: 2.0904496355912507

Epoch: 5| Step: 7
Training loss: 0.10317499870506416
Validation loss: 2.0802630801992956

Epoch: 5| Step: 8
Training loss: 0.11518701291252968
Validation loss: 2.083065017731514

Epoch: 5| Step: 9
Training loss: 0.1035767365850415
Validation loss: 2.1059751157983504

Epoch: 5| Step: 10
Training loss: 0.11217361347648934
Validation loss: 2.0731198835841687

Epoch: 682| Step: 0
Training loss: 0.14893787522534846
Validation loss: 2.081709241839648

Epoch: 5| Step: 1
Training loss: 0.1166259543626687
Validation loss: 2.0843558548313736

Epoch: 5| Step: 2
Training loss: 0.12392912304808669
Validation loss: 2.0938566588146474

Epoch: 5| Step: 3
Training loss: 0.12935563708499886
Validation loss: 2.0868027288206297

Epoch: 5| Step: 4
Training loss: 0.16386913643952217
Validation loss: 2.0517044188117137

Epoch: 5| Step: 5
Training loss: 0.1381101244472277
Validation loss: 2.075662434825042

Epoch: 5| Step: 6
Training loss: 0.11630534897000726
Validation loss: 2.0750154776106515

Epoch: 5| Step: 7
Training loss: 0.11621964446075175
Validation loss: 2.0851119683354664

Epoch: 5| Step: 8
Training loss: 0.18168551392809854
Validation loss: 2.0701547207712054

Epoch: 5| Step: 9
Training loss: 0.13655614038276453
Validation loss: 2.0966406449457793

Epoch: 5| Step: 10
Training loss: 0.10241009912948683
Validation loss: 2.087815632008551

Epoch: 683| Step: 0
Training loss: 0.10563980906549016
Validation loss: 2.0968627907814286

Epoch: 5| Step: 1
Training loss: 0.1504380287665095
Validation loss: 2.1093352015913687

Epoch: 5| Step: 2
Training loss: 0.08428672216753194
Validation loss: 2.1003608749519924

Epoch: 5| Step: 3
Training loss: 0.1455783672938757
Validation loss: 2.098510817433356

Epoch: 5| Step: 4
Training loss: 0.11299748065923002
Validation loss: 2.1067068260434976

Epoch: 5| Step: 5
Training loss: 0.1313642044704206
Validation loss: 2.0892823327063805

Epoch: 5| Step: 6
Training loss: 0.12328181846231344
Validation loss: 2.079645719814478

Epoch: 5| Step: 7
Training loss: 0.17248108596008818
Validation loss: 2.0823764475995774

Epoch: 5| Step: 8
Training loss: 0.0850896052863429
Validation loss: 2.074950317359316

Epoch: 5| Step: 9
Training loss: 0.12105757419065387
Validation loss: 2.0789739339867994

Epoch: 5| Step: 10
Training loss: 0.1170438044426248
Validation loss: 2.0608696433650198

Epoch: 684| Step: 0
Training loss: 0.08080961048240609
Validation loss: 2.053486206203753

Epoch: 5| Step: 1
Training loss: 0.09525158002280067
Validation loss: 2.0704227959106234

Epoch: 5| Step: 2
Training loss: 0.15922739332096608
Validation loss: 2.067452404321865

Epoch: 5| Step: 3
Training loss: 0.10498561846500146
Validation loss: 2.072837418923128

Epoch: 5| Step: 4
Training loss: 0.1545432212636035
Validation loss: 2.0819089519959144

Epoch: 5| Step: 5
Training loss: 0.14275432176903968
Validation loss: 2.1087990357685693

Epoch: 5| Step: 6
Training loss: 0.13107485608881142
Validation loss: 2.0890304103634305

Epoch: 5| Step: 7
Training loss: 0.12023738724081334
Validation loss: 2.0823549596430797

Epoch: 5| Step: 8
Training loss: 0.07061428962047044
Validation loss: 2.0648401172231603

Epoch: 5| Step: 9
Training loss: 0.10202407031042296
Validation loss: 2.101874975451986

Epoch: 5| Step: 10
Training loss: 0.12934852357973975
Validation loss: 2.0879483693026955

Epoch: 685| Step: 0
Training loss: 0.11439373620492797
Validation loss: 2.085906458632119

Epoch: 5| Step: 1
Training loss: 0.09861786417474738
Validation loss: 2.088880648346176

Epoch: 5| Step: 2
Training loss: 0.07201805106562693
Validation loss: 2.0711203257688484

Epoch: 5| Step: 3
Training loss: 0.14773747742984597
Validation loss: 2.091307022203582

Epoch: 5| Step: 4
Training loss: 0.09898093137042459
Validation loss: 2.137638271599145

Epoch: 5| Step: 5
Training loss: 0.0818096158389523
Validation loss: 2.1098062126913937

Epoch: 5| Step: 6
Training loss: 0.13677987367217753
Validation loss: 2.10357916005317

Epoch: 5| Step: 7
Training loss: 0.10069518961393203
Validation loss: 2.118803440104533

Epoch: 5| Step: 8
Training loss: 0.1349739109875567
Validation loss: 2.080752813784532

Epoch: 5| Step: 9
Training loss: 0.06609201060930477
Validation loss: 2.103872549318528

Epoch: 5| Step: 10
Training loss: 0.13449760405053196
Validation loss: 2.0861072895958173

Epoch: 686| Step: 0
Training loss: 0.14501779728633116
Validation loss: 2.1018276057299667

Epoch: 5| Step: 1
Training loss: 0.09789348872867808
Validation loss: 2.1024838393599166

Epoch: 5| Step: 2
Training loss: 0.16024575988594897
Validation loss: 2.0945261051148005

Epoch: 5| Step: 3
Training loss: 0.07270946681583756
Validation loss: 2.110595323394185

Epoch: 5| Step: 4
Training loss: 0.1295611837815237
Validation loss: 2.090489016656966

Epoch: 5| Step: 5
Training loss: 0.10433377084799648
Validation loss: 2.0813766294141556

Epoch: 5| Step: 6
Training loss: 0.13463316502954115
Validation loss: 2.091694117738012

Epoch: 5| Step: 7
Training loss: 0.09060229518535244
Validation loss: 2.061115662939634

Epoch: 5| Step: 8
Training loss: 0.12148144785920913
Validation loss: 2.07532766492669

Epoch: 5| Step: 9
Training loss: 0.11341341710798795
Validation loss: 2.036976480973204

Epoch: 5| Step: 10
Training loss: 0.13562234212318997
Validation loss: 2.0626493445278373

Epoch: 687| Step: 0
Training loss: 0.15467159425475116
Validation loss: 2.088290525155645

Epoch: 5| Step: 1
Training loss: 0.12128218479282785
Validation loss: 2.0717560768720436

Epoch: 5| Step: 2
Training loss: 0.14159878695168412
Validation loss: 2.073107633071695

Epoch: 5| Step: 3
Training loss: 0.06423709529618209
Validation loss: 2.075004525049353

Epoch: 5| Step: 4
Training loss: 0.12068065045199079
Validation loss: 2.0650284539684494

Epoch: 5| Step: 5
Training loss: 0.11349364626478639
Validation loss: 2.0868096145611243

Epoch: 5| Step: 6
Training loss: 0.12709674780691246
Validation loss: 2.105376671679728

Epoch: 5| Step: 7
Training loss: 0.09507183192043082
Validation loss: 2.081820079493931

Epoch: 5| Step: 8
Training loss: 0.11050659446678802
Validation loss: 2.0984200268979127

Epoch: 5| Step: 9
Training loss: 0.12750283584058933
Validation loss: 2.081076673011969

Epoch: 5| Step: 10
Training loss: 0.12036770770825311
Validation loss: 2.070118330001336

Epoch: 688| Step: 0
Training loss: 0.09669665467082109
Validation loss: 2.0605236035628742

Epoch: 5| Step: 1
Training loss: 0.12892740971843264
Validation loss: 2.082544493893788

Epoch: 5| Step: 2
Training loss: 0.08447634683385859
Validation loss: 2.0539916770968847

Epoch: 5| Step: 3
Training loss: 0.09272459651872607
Validation loss: 2.0883852926964313

Epoch: 5| Step: 4
Training loss: 0.0914639614778692
Validation loss: 2.0908430339965336

Epoch: 5| Step: 5
Training loss: 0.13297235461592743
Validation loss: 2.047136610519161

Epoch: 5| Step: 6
Training loss: 0.1650053926692052
Validation loss: 2.0772203417301114

Epoch: 5| Step: 7
Training loss: 0.06369494871379305
Validation loss: 2.0858389641544504

Epoch: 5| Step: 8
Training loss: 0.0938513674681998
Validation loss: 2.0866380680883294

Epoch: 5| Step: 9
Training loss: 0.11153533958885187
Validation loss: 2.1284023784831536

Epoch: 5| Step: 10
Training loss: 0.057790910549455704
Validation loss: 2.0880706622615772

Epoch: 689| Step: 0
Training loss: 0.10984036524510572
Validation loss: 2.1093299438574613

Epoch: 5| Step: 1
Training loss: 0.13232051661193497
Validation loss: 2.1089848603083703

Epoch: 5| Step: 2
Training loss: 0.09952212701334902
Validation loss: 2.1373120707752764

Epoch: 5| Step: 3
Training loss: 0.08282887301442766
Validation loss: 2.1246446113862145

Epoch: 5| Step: 4
Training loss: 0.130267019556997
Validation loss: 2.1205715093337134

Epoch: 5| Step: 5
Training loss: 0.1566324441157607
Validation loss: 2.111917621198355

Epoch: 5| Step: 6
Training loss: 0.09680101218784254
Validation loss: 2.0909904669803794

Epoch: 5| Step: 7
Training loss: 0.13768331326627029
Validation loss: 2.1214296615104855

Epoch: 5| Step: 8
Training loss: 0.08051076181220707
Validation loss: 2.0963341040094865

Epoch: 5| Step: 9
Training loss: 0.15510418502388207
Validation loss: 2.1127143584606833

Epoch: 5| Step: 10
Training loss: 0.09569806455351135
Validation loss: 2.0959278290477865

Epoch: 690| Step: 0
Training loss: 0.10185241127728507
Validation loss: 2.0968238026813864

Epoch: 5| Step: 1
Training loss: 0.17261070237556234
Validation loss: 2.1023779736787738

Epoch: 5| Step: 2
Training loss: 0.10252126357594793
Validation loss: 2.0787706256576475

Epoch: 5| Step: 3
Training loss: 0.11385465883455176
Validation loss: 2.0752293584879142

Epoch: 5| Step: 4
Training loss: 0.0895660555843197
Validation loss: 2.0777561977851637

Epoch: 5| Step: 5
Training loss: 0.09223263371158533
Validation loss: 2.071461594822156

Epoch: 5| Step: 6
Training loss: 0.092056672765476
Validation loss: 2.0810800089454147

Epoch: 5| Step: 7
Training loss: 0.07067693862933022
Validation loss: 2.0943519756654476

Epoch: 5| Step: 8
Training loss: 0.11809252709525002
Validation loss: 2.0775986192231892

Epoch: 5| Step: 9
Training loss: 0.10568369490887057
Validation loss: 2.096354028886105

Epoch: 5| Step: 10
Training loss: 0.06553376162122203
Validation loss: 2.112156263806048

Epoch: 691| Step: 0
Training loss: 0.11305158452398141
Validation loss: 2.0891248897105834

Epoch: 5| Step: 1
Training loss: 0.09591812681395988
Validation loss: 2.105592378268248

Epoch: 5| Step: 2
Training loss: 0.08015021417156222
Validation loss: 2.099512704320311

Epoch: 5| Step: 3
Training loss: 0.14493288476462787
Validation loss: 2.075362832224903

Epoch: 5| Step: 4
Training loss: 0.1119446581149777
Validation loss: 2.0869165611375937

Epoch: 5| Step: 5
Training loss: 0.08064725171889303
Validation loss: 2.0863260501283

Epoch: 5| Step: 6
Training loss: 0.12294992533049734
Validation loss: 2.0796434469682143

Epoch: 5| Step: 7
Training loss: 0.10504509466972826
Validation loss: 2.0885844755742675

Epoch: 5| Step: 8
Training loss: 0.12331982644232733
Validation loss: 2.0825357401375406

Epoch: 5| Step: 9
Training loss: 0.11690833297873449
Validation loss: 2.1120419298272752

Epoch: 5| Step: 10
Training loss: 0.07109695836048438
Validation loss: 2.088943736929302

Epoch: 692| Step: 0
Training loss: 0.08051243621619762
Validation loss: 2.087523320267794

Epoch: 5| Step: 1
Training loss: 0.1115067203906298
Validation loss: 2.075415813971597

Epoch: 5| Step: 2
Training loss: 0.11934298386818577
Validation loss: 2.0860252526293164

Epoch: 5| Step: 3
Training loss: 0.11672485740288925
Validation loss: 2.081085514209411

Epoch: 5| Step: 4
Training loss: 0.12417341160642498
Validation loss: 2.069756467374489

Epoch: 5| Step: 5
Training loss: 0.08374047070795192
Validation loss: 2.0907299289300205

Epoch: 5| Step: 6
Training loss: 0.10664778884467996
Validation loss: 2.0549229181684256

Epoch: 5| Step: 7
Training loss: 0.07904394135042914
Validation loss: 2.0920429118170922

Epoch: 5| Step: 8
Training loss: 0.13350495572035803
Validation loss: 2.089808389055749

Epoch: 5| Step: 9
Training loss: 0.07576668392864534
Validation loss: 2.0756706506618134

Epoch: 5| Step: 10
Training loss: 0.09247035159528547
Validation loss: 2.083052215888265

Epoch: 693| Step: 0
Training loss: 0.09998201808336332
Validation loss: 2.078313552650541

Epoch: 5| Step: 1
Training loss: 0.10614655943046002
Validation loss: 2.0900809143389933

Epoch: 5| Step: 2
Training loss: 0.10557163924269462
Validation loss: 2.106438677763816

Epoch: 5| Step: 3
Training loss: 0.1140851974766327
Validation loss: 2.0961972439233096

Epoch: 5| Step: 4
Training loss: 0.10283304034659047
Validation loss: 2.075726008213633

Epoch: 5| Step: 5
Training loss: 0.11362629169835706
Validation loss: 2.084135401569415

Epoch: 5| Step: 6
Training loss: 0.1230542014226661
Validation loss: 2.1028865420785783

Epoch: 5| Step: 7
Training loss: 0.0897343321721584
Validation loss: 2.0532396963602304

Epoch: 5| Step: 8
Training loss: 0.13662609639255746
Validation loss: 2.0795386242976837

Epoch: 5| Step: 9
Training loss: 0.08899962857991307
Validation loss: 2.065946733714988

Epoch: 5| Step: 10
Training loss: 0.07097484960782798
Validation loss: 2.101293091942856

Epoch: 694| Step: 0
Training loss: 0.13992898943187407
Validation loss: 2.1076838512140688

Epoch: 5| Step: 1
Training loss: 0.0741667063093258
Validation loss: 2.104591633336419

Epoch: 5| Step: 2
Training loss: 0.07205216029277822
Validation loss: 2.091925053296102

Epoch: 5| Step: 3
Training loss: 0.09171607133830252
Validation loss: 2.099217988852572

Epoch: 5| Step: 4
Training loss: 0.15589936372027322
Validation loss: 2.1006568683176754

Epoch: 5| Step: 5
Training loss: 0.06425600542118962
Validation loss: 2.0986371368765395

Epoch: 5| Step: 6
Training loss: 0.1011816642326016
Validation loss: 2.0555945149485697

Epoch: 5| Step: 7
Training loss: 0.06154706856858649
Validation loss: 2.085999640340783

Epoch: 5| Step: 8
Training loss: 0.08663780799462034
Validation loss: 2.0976980799486196

Epoch: 5| Step: 9
Training loss: 0.12915912302995017
Validation loss: 2.066367565628572

Epoch: 5| Step: 10
Training loss: 0.14180839822779487
Validation loss: 2.077309753796083

Epoch: 695| Step: 0
Training loss: 0.10693344569087121
Validation loss: 2.0305336521257673

Epoch: 5| Step: 1
Training loss: 0.0854260576739002
Validation loss: 2.0586052132847525

Epoch: 5| Step: 2
Training loss: 0.166258538867609
Validation loss: 2.0412562934990417

Epoch: 5| Step: 3
Training loss: 0.10763990643577485
Validation loss: 2.0572714361585276

Epoch: 5| Step: 4
Training loss: 0.1362573193850184
Validation loss: 2.064242411605916

Epoch: 5| Step: 5
Training loss: 0.09996981016063762
Validation loss: 2.0568458908037957

Epoch: 5| Step: 6
Training loss: 0.06984732652314032
Validation loss: 2.0632426396894767

Epoch: 5| Step: 7
Training loss: 0.13340465285425715
Validation loss: 2.0841662171538307

Epoch: 5| Step: 8
Training loss: 0.11079103176474926
Validation loss: 2.096861593236825

Epoch: 5| Step: 9
Training loss: 0.08754416100677943
Validation loss: 2.0502645893558036

Epoch: 5| Step: 10
Training loss: 0.10799199880133525
Validation loss: 2.08990540373739

Epoch: 696| Step: 0
Training loss: 0.12086748703781469
Validation loss: 2.085523783620959

Epoch: 5| Step: 1
Training loss: 0.08324195992014873
Validation loss: 2.0817031852767367

Epoch: 5| Step: 2
Training loss: 0.09314263315280571
Validation loss: 2.0991518560481732

Epoch: 5| Step: 3
Training loss: 0.06080650607152292
Validation loss: 2.075972352644026

Epoch: 5| Step: 4
Training loss: 0.07607773012472839
Validation loss: 2.068860324799911

Epoch: 5| Step: 5
Training loss: 0.13922458295023318
Validation loss: 2.068803104742262

Epoch: 5| Step: 6
Training loss: 0.11712501767503408
Validation loss: 2.064292548875958

Epoch: 5| Step: 7
Training loss: 0.0979048473456754
Validation loss: 2.099432840292381

Epoch: 5| Step: 8
Training loss: 0.10756698257735745
Validation loss: 2.048833845806191

Epoch: 5| Step: 9
Training loss: 0.10570777634017321
Validation loss: 2.082884522567902

Epoch: 5| Step: 10
Training loss: 0.09751742031594476
Validation loss: 2.0896732604642825

Epoch: 697| Step: 0
Training loss: 0.10153757761566387
Validation loss: 2.0621600562318387

Epoch: 5| Step: 1
Training loss: 0.11854313506600797
Validation loss: 2.0716526887568123

Epoch: 5| Step: 2
Training loss: 0.14958278006284856
Validation loss: 2.0680068380651337

Epoch: 5| Step: 3
Training loss: 0.09883191059989165
Validation loss: 2.0692115411845027

Epoch: 5| Step: 4
Training loss: 0.07803553584783149
Validation loss: 2.061225011025072

Epoch: 5| Step: 5
Training loss: 0.11507075218154496
Validation loss: 2.0800736917890155

Epoch: 5| Step: 6
Training loss: 0.13984852574893994
Validation loss: 2.0898382236460162

Epoch: 5| Step: 7
Training loss: 0.08245388218573776
Validation loss: 2.0810865760868054

Epoch: 5| Step: 8
Training loss: 0.09366408026925209
Validation loss: 2.076205452430134

Epoch: 5| Step: 9
Training loss: 0.04723288341925002
Validation loss: 2.0926270513949894

Epoch: 5| Step: 10
Training loss: 0.07505248488363571
Validation loss: 2.0890901676051934

Epoch: 698| Step: 0
Training loss: 0.11160853691592823
Validation loss: 2.11054421139781

Epoch: 5| Step: 1
Training loss: 0.10622397430116172
Validation loss: 2.0848313559179545

Epoch: 5| Step: 2
Training loss: 0.13888719792793663
Validation loss: 2.076202043221475

Epoch: 5| Step: 3
Training loss: 0.14769291472992022
Validation loss: 2.1133429475229963

Epoch: 5| Step: 4
Training loss: 0.12182925264365772
Validation loss: 2.089833683560477

Epoch: 5| Step: 5
Training loss: 0.06933177344484738
Validation loss: 2.069530943978127

Epoch: 5| Step: 6
Training loss: 0.049402046910191434
Validation loss: 2.0871300472481664

Epoch: 5| Step: 7
Training loss: 0.10330555851954343
Validation loss: 2.0579035189604795

Epoch: 5| Step: 8
Training loss: 0.0913475330980803
Validation loss: 2.09142176834315

Epoch: 5| Step: 9
Training loss: 0.12513812450597572
Validation loss: 2.053145324398657

Epoch: 5| Step: 10
Training loss: 0.11041585770871465
Validation loss: 2.0852096109224663

Epoch: 699| Step: 0
Training loss: 0.138617303345662
Validation loss: 2.0471421579123636

Epoch: 5| Step: 1
Training loss: 0.13372638375801363
Validation loss: 2.0666038433755083

Epoch: 5| Step: 2
Training loss: 0.11307975508371639
Validation loss: 2.0448768166413727

Epoch: 5| Step: 3
Training loss: 0.07648808916442919
Validation loss: 2.067573133380585

Epoch: 5| Step: 4
Training loss: 0.06324636460282135
Validation loss: 2.047964436606274

Epoch: 5| Step: 5
Training loss: 0.1239995745732812
Validation loss: 2.0326442536924283

Epoch: 5| Step: 6
Training loss: 0.06602110388552802
Validation loss: 2.0644752804795368

Epoch: 5| Step: 7
Training loss: 0.10351163928437959
Validation loss: 2.0736190311751983

Epoch: 5| Step: 8
Training loss: 0.16296048393023627
Validation loss: 2.0739784256766507

Epoch: 5| Step: 9
Training loss: 0.09672728725001922
Validation loss: 2.079057339847662

Epoch: 5| Step: 10
Training loss: 0.09901295480412997
Validation loss: 2.0698525888249146

Epoch: 700| Step: 0
Training loss: 0.10064322960291502
Validation loss: 2.04685309926841

Epoch: 5| Step: 1
Training loss: 0.08658035109318438
Validation loss: 2.0916176505825783

Epoch: 5| Step: 2
Training loss: 0.1181626753292157
Validation loss: 2.0473666714892103

Epoch: 5| Step: 3
Training loss: 0.09232406704161664
Validation loss: 2.1134696131804978

Epoch: 5| Step: 4
Training loss: 0.08461614230347524
Validation loss: 2.079199148888546

Epoch: 5| Step: 5
Training loss: 0.09038432386158343
Validation loss: 2.0844915968526103

Epoch: 5| Step: 6
Training loss: 0.11592125650964082
Validation loss: 2.0944611509905187

Epoch: 5| Step: 7
Training loss: 0.07854364402876464
Validation loss: 2.0885985194379746

Epoch: 5| Step: 8
Training loss: 0.10801567338754504
Validation loss: 2.0462631905627755

Epoch: 5| Step: 9
Training loss: 0.10610815337394469
Validation loss: 2.102755166247363

Epoch: 5| Step: 10
Training loss: 0.06706455300962451
Validation loss: 2.092757306680779

Epoch: 701| Step: 0
Training loss: 0.12545191761186045
Validation loss: 2.085105397273972

Epoch: 5| Step: 1
Training loss: 0.09304148449405159
Validation loss: 2.0768655813806305

Epoch: 5| Step: 2
Training loss: 0.09586656491395538
Validation loss: 2.073288623889746

Epoch: 5| Step: 3
Training loss: 0.08826594747571202
Validation loss: 2.1212265210894117

Epoch: 5| Step: 4
Training loss: 0.08985887275798216
Validation loss: 2.0699971995038267

Epoch: 5| Step: 5
Training loss: 0.08457655388087965
Validation loss: 2.0720037683589743

Epoch: 5| Step: 6
Training loss: 0.11279126368303159
Validation loss: 2.0725561026158337

Epoch: 5| Step: 7
Training loss: 0.11031804377482321
Validation loss: 2.0912277562588417

Epoch: 5| Step: 8
Training loss: 0.08005851412432048
Validation loss: 2.1003563527296962

Epoch: 5| Step: 9
Training loss: 0.10807581307846355
Validation loss: 2.0820885633271904

Epoch: 5| Step: 10
Training loss: 0.08725834284206352
Validation loss: 2.096415459367339

Epoch: 702| Step: 0
Training loss: 0.06749400004569223
Validation loss: 2.1091865020838436

Epoch: 5| Step: 1
Training loss: 0.15785382409612606
Validation loss: 2.1195395658057077

Epoch: 5| Step: 2
Training loss: 0.10517903555791476
Validation loss: 2.0997139017042823

Epoch: 5| Step: 3
Training loss: 0.08819063428905972
Validation loss: 2.0609279681202874

Epoch: 5| Step: 4
Training loss: 0.1073095471295805
Validation loss: 2.068285188193992

Epoch: 5| Step: 5
Training loss: 0.10384076715318598
Validation loss: 2.0752029668581162

Epoch: 5| Step: 6
Training loss: 0.10336122153630183
Validation loss: 2.059150810499202

Epoch: 5| Step: 7
Training loss: 0.07013877958575368
Validation loss: 2.0810120351661294

Epoch: 5| Step: 8
Training loss: 0.07764841387489574
Validation loss: 2.0760406587576643

Epoch: 5| Step: 9
Training loss: 0.06583983771279714
Validation loss: 2.05470429339565

Epoch: 5| Step: 10
Training loss: 0.1114001459426369
Validation loss: 2.074881940137662

Epoch: 703| Step: 0
Training loss: 0.05684754377673909
Validation loss: 2.0747673950259675

Epoch: 5| Step: 1
Training loss: 0.12656094055627895
Validation loss: 2.0628945935557708

Epoch: 5| Step: 2
Training loss: 0.10824299742148893
Validation loss: 2.0447332697945204

Epoch: 5| Step: 3
Training loss: 0.11030945776399702
Validation loss: 2.0823718278430645

Epoch: 5| Step: 4
Training loss: 0.08627114497621462
Validation loss: 2.0501060518935055

Epoch: 5| Step: 5
Training loss: 0.10223682456279065
Validation loss: 2.0761949222666787

Epoch: 5| Step: 6
Training loss: 0.11129499243552995
Validation loss: 2.0635083549902435

Epoch: 5| Step: 7
Training loss: 0.12424832327908737
Validation loss: 2.069814871793112

Epoch: 5| Step: 8
Training loss: 0.08654159394146987
Validation loss: 2.0650482103944867

Epoch: 5| Step: 9
Training loss: 0.09702998576669039
Validation loss: 2.0595425943233137

Epoch: 5| Step: 10
Training loss: 0.062114315316313305
Validation loss: 2.0773995029234933

Epoch: 704| Step: 0
Training loss: 0.08324060334730463
Validation loss: 2.0765862743256513

Epoch: 5| Step: 1
Training loss: 0.06447228594826457
Validation loss: 2.0790686335817776

Epoch: 5| Step: 2
Training loss: 0.10351070356366049
Validation loss: 2.077508277740835

Epoch: 5| Step: 3
Training loss: 0.1069124889014069
Validation loss: 2.0756504210196134

Epoch: 5| Step: 4
Training loss: 0.052253604509483804
Validation loss: 2.066552011158857

Epoch: 5| Step: 5
Training loss: 0.09041653366489268
Validation loss: 2.0550260732370123

Epoch: 5| Step: 6
Training loss: 0.11870725561986474
Validation loss: 2.071317931101871

Epoch: 5| Step: 7
Training loss: 0.12333043289828277
Validation loss: 2.073770826838508

Epoch: 5| Step: 8
Training loss: 0.11657900184635966
Validation loss: 2.095861021806672

Epoch: 5| Step: 9
Training loss: 0.0782084525948858
Validation loss: 2.1225276634050143

Epoch: 5| Step: 10
Training loss: 0.0991508598921443
Validation loss: 2.081685383707283

Epoch: 705| Step: 0
Training loss: 0.11706206443174015
Validation loss: 2.076088725521727

Epoch: 5| Step: 1
Training loss: 0.12375326842268933
Validation loss: 2.1048096493038293

Epoch: 5| Step: 2
Training loss: 0.10473986266247672
Validation loss: 2.051944644485412

Epoch: 5| Step: 3
Training loss: 0.0951706612609316
Validation loss: 2.0721200653319825

Epoch: 5| Step: 4
Training loss: 0.07962349022492422
Validation loss: 2.085767091859805

Epoch: 5| Step: 5
Training loss: 0.0849006537617409
Validation loss: 2.0993182694748995

Epoch: 5| Step: 6
Training loss: 0.10211660461691356
Validation loss: 2.0748750642361946

Epoch: 5| Step: 7
Training loss: 0.09563516617321707
Validation loss: 2.0770058243940848

Epoch: 5| Step: 8
Training loss: 0.11132099731114738
Validation loss: 2.0808235539366007

Epoch: 5| Step: 9
Training loss: 0.11887503162141935
Validation loss: 2.045439862608455

Epoch: 5| Step: 10
Training loss: 0.13376841420573202
Validation loss: 2.0665668188126918

Epoch: 706| Step: 0
Training loss: 0.09693178869654
Validation loss: 2.0708475602128122

Epoch: 5| Step: 1
Training loss: 0.09128016779067732
Validation loss: 2.077692973086989

Epoch: 5| Step: 2
Training loss: 0.08021239619007589
Validation loss: 2.052455552168329

Epoch: 5| Step: 3
Training loss: 0.11970941987146483
Validation loss: 2.1041886340586293

Epoch: 5| Step: 4
Training loss: 0.09974588128600043
Validation loss: 2.061605159312787

Epoch: 5| Step: 5
Training loss: 0.10182288609705058
Validation loss: 2.077181449928756

Epoch: 5| Step: 6
Training loss: 0.09611985890873524
Validation loss: 2.0651614263155667

Epoch: 5| Step: 7
Training loss: 0.08414928192509727
Validation loss: 2.0459103315440696

Epoch: 5| Step: 8
Training loss: 0.11221182757319886
Validation loss: 2.058780736160505

Epoch: 5| Step: 9
Training loss: 0.09989201892290141
Validation loss: 2.080841398915615

Epoch: 5| Step: 10
Training loss: 0.06674000720236374
Validation loss: 2.0785652457320722

Epoch: 707| Step: 0
Training loss: 0.11953031408654113
Validation loss: 2.0937004407962845

Epoch: 5| Step: 1
Training loss: 0.08155612496787344
Validation loss: 2.080835690645743

Epoch: 5| Step: 2
Training loss: 0.06862900894928589
Validation loss: 2.060815471900858

Epoch: 5| Step: 3
Training loss: 0.13966369545552218
Validation loss: 2.080487719340106

Epoch: 5| Step: 4
Training loss: 0.09351321457901007
Validation loss: 2.10538527019401

Epoch: 5| Step: 5
Training loss: 0.0728270495852376
Validation loss: 2.0959481632579697

Epoch: 5| Step: 6
Training loss: 0.06573097408764886
Validation loss: 2.0978061150971614

Epoch: 5| Step: 7
Training loss: 0.10243892775774723
Validation loss: 2.0796740354184053

Epoch: 5| Step: 8
Training loss: 0.10085808870601912
Validation loss: 2.1121009728920126

Epoch: 5| Step: 9
Training loss: 0.10502453256297362
Validation loss: 2.1246918358926035

Epoch: 5| Step: 10
Training loss: 0.058877294649825204
Validation loss: 2.1168562851724193

Epoch: 708| Step: 0
Training loss: 0.10198540395811125
Validation loss: 2.094337118115304

Epoch: 5| Step: 1
Training loss: 0.08416543616453308
Validation loss: 2.100712545867152

Epoch: 5| Step: 2
Training loss: 0.08840809124175038
Validation loss: 2.0743536327782577

Epoch: 5| Step: 3
Training loss: 0.07836826716141271
Validation loss: 2.0771214574598442

Epoch: 5| Step: 4
Training loss: 0.0899969743180304
Validation loss: 2.0872738005129774

Epoch: 5| Step: 5
Training loss: 0.057795736904700724
Validation loss: 2.0617880488939018

Epoch: 5| Step: 6
Training loss: 0.06263436462598483
Validation loss: 2.05042573393345

Epoch: 5| Step: 7
Training loss: 0.07096939070100376
Validation loss: 2.038417381092799

Epoch: 5| Step: 8
Training loss: 0.10207358475121406
Validation loss: 2.0900437635104647

Epoch: 5| Step: 9
Training loss: 0.12506753616973543
Validation loss: 2.0788225984136623

Epoch: 5| Step: 10
Training loss: 0.1250328899863306
Validation loss: 2.056303664685768

Epoch: 709| Step: 0
Training loss: 0.09326267741244848
Validation loss: 2.0990504523983793

Epoch: 5| Step: 1
Training loss: 0.0959247970480856
Validation loss: 2.097349445883231

Epoch: 5| Step: 2
Training loss: 0.08120149794723545
Validation loss: 2.075371750880152

Epoch: 5| Step: 3
Training loss: 0.08826492662925045
Validation loss: 2.0965784907612086

Epoch: 5| Step: 4
Training loss: 0.0773364293602758
Validation loss: 2.086430656205261

Epoch: 5| Step: 5
Training loss: 0.10076898289475941
Validation loss: 2.1052071898229565

Epoch: 5| Step: 6
Training loss: 0.12363885590545749
Validation loss: 2.087277597565292

Epoch: 5| Step: 7
Training loss: 0.08712846585273394
Validation loss: 2.0785550161336523

Epoch: 5| Step: 8
Training loss: 0.1359696300945411
Validation loss: 2.04171832368589

Epoch: 5| Step: 9
Training loss: 0.09087371281718383
Validation loss: 2.084218699281651

Epoch: 5| Step: 10
Training loss: 0.11485096217883994
Validation loss: 2.062514179836042

Epoch: 710| Step: 0
Training loss: 0.10947920314326648
Validation loss: 2.0680692649130585

Epoch: 5| Step: 1
Training loss: 0.10033824663773121
Validation loss: 2.090461451521802

Epoch: 5| Step: 2
Training loss: 0.06873202251424428
Validation loss: 2.044925268659937

Epoch: 5| Step: 3
Training loss: 0.11925894693284264
Validation loss: 2.089411365859953

Epoch: 5| Step: 4
Training loss: 0.1260383661352934
Validation loss: 2.076480946388879

Epoch: 5| Step: 5
Training loss: 0.07874643410450596
Validation loss: 2.0807115601628383

Epoch: 5| Step: 6
Training loss: 0.08524689290496684
Validation loss: 2.079904212057453

Epoch: 5| Step: 7
Training loss: 0.07476782039679712
Validation loss: 2.072535876280218

Epoch: 5| Step: 8
Training loss: 0.09014374983488072
Validation loss: 2.090258231206941

Epoch: 5| Step: 9
Training loss: 0.09689039331084566
Validation loss: 2.06531002602096

Epoch: 5| Step: 10
Training loss: 0.07459522432676953
Validation loss: 2.082866172608856

Epoch: 711| Step: 0
Training loss: 0.10391808940724291
Validation loss: 2.072904221197513

Epoch: 5| Step: 1
Training loss: 0.07701157247948838
Validation loss: 2.045420301568579

Epoch: 5| Step: 2
Training loss: 0.07717321999789865
Validation loss: 2.0890493826598866

Epoch: 5| Step: 3
Training loss: 0.08034191934676624
Validation loss: 2.084724941827902

Epoch: 5| Step: 4
Training loss: 0.09895708110502238
Validation loss: 2.089509854704433

Epoch: 5| Step: 5
Training loss: 0.08242713676398519
Validation loss: 2.0987164931010116

Epoch: 5| Step: 6
Training loss: 0.0745766380648554
Validation loss: 2.0484927992887725

Epoch: 5| Step: 7
Training loss: 0.06866581894445237
Validation loss: 2.0605839081984936

Epoch: 5| Step: 8
Training loss: 0.1370205749237936
Validation loss: 2.0668373702634235

Epoch: 5| Step: 9
Training loss: 0.05908663392857603
Validation loss: 2.075219239687525

Epoch: 5| Step: 10
Training loss: 0.12280164228981352
Validation loss: 2.0563794802409534

Epoch: 712| Step: 0
Training loss: 0.08499017848044005
Validation loss: 2.067468304158581

Epoch: 5| Step: 1
Training loss: 0.10475228817143106
Validation loss: 2.0745624108997727

Epoch: 5| Step: 2
Training loss: 0.05333181002252548
Validation loss: 2.0718045604321276

Epoch: 5| Step: 3
Training loss: 0.12804608473379714
Validation loss: 2.033535566146002

Epoch: 5| Step: 4
Training loss: 0.07765994534248712
Validation loss: 2.0726109555112795

Epoch: 5| Step: 5
Training loss: 0.07598706285635995
Validation loss: 2.088853074259457

Epoch: 5| Step: 6
Training loss: 0.1037074013015563
Validation loss: 2.0933069707196617

Epoch: 5| Step: 7
Training loss: 0.10399799598771266
Validation loss: 2.053273015781742

Epoch: 5| Step: 8
Training loss: 0.10046545238333503
Validation loss: 2.0939011131269947

Epoch: 5| Step: 9
Training loss: 0.08088332180967124
Validation loss: 2.092043343166471

Epoch: 5| Step: 10
Training loss: 0.11158168510892127
Validation loss: 2.0871902961636626

Epoch: 713| Step: 0
Training loss: 0.16129286937327622
Validation loss: 2.1033507664589566

Epoch: 5| Step: 1
Training loss: 0.10915772536187432
Validation loss: 2.108127451435021

Epoch: 5| Step: 2
Training loss: 0.08982493369391734
Validation loss: 2.0783019717189077

Epoch: 5| Step: 3
Training loss: 0.09493481465435032
Validation loss: 2.0885382399521832

Epoch: 5| Step: 4
Training loss: 0.07301498140108166
Validation loss: 2.0795537105471587

Epoch: 5| Step: 5
Training loss: 0.07442894771713196
Validation loss: 2.0694054562074506

Epoch: 5| Step: 6
Training loss: 0.1205891895504429
Validation loss: 2.0664149436796495

Epoch: 5| Step: 7
Training loss: 0.11859776375754608
Validation loss: 2.0492079527295877

Epoch: 5| Step: 8
Training loss: 0.0744327640562278
Validation loss: 2.046579574636419

Epoch: 5| Step: 9
Training loss: 0.09358145046296734
Validation loss: 2.081853855210499

Epoch: 5| Step: 10
Training loss: 0.0754538463701028
Validation loss: 2.080952686567152

Epoch: 714| Step: 0
Training loss: 0.08350208049080357
Validation loss: 2.0522181373628214

Epoch: 5| Step: 1
Training loss: 0.053663679486978096
Validation loss: 2.0412199754642324

Epoch: 5| Step: 2
Training loss: 0.07268283239787875
Validation loss: 2.052018898272485

Epoch: 5| Step: 3
Training loss: 0.1425031504052742
Validation loss: 2.0626596178977965

Epoch: 5| Step: 4
Training loss: 0.08922723521854191
Validation loss: 2.058943530770721

Epoch: 5| Step: 5
Training loss: 0.1022995786130431
Validation loss: 2.0617122618756127

Epoch: 5| Step: 6
Training loss: 0.09355464588873143
Validation loss: 2.065888111358673

Epoch: 5| Step: 7
Training loss: 0.10431807263301655
Validation loss: 2.059398784422611

Epoch: 5| Step: 8
Training loss: 0.08181334117576448
Validation loss: 2.046264140215371

Epoch: 5| Step: 9
Training loss: 0.07575162168280061
Validation loss: 2.063289180606385

Epoch: 5| Step: 10
Training loss: 0.09696239021411113
Validation loss: 2.0971672621854527

Epoch: 715| Step: 0
Training loss: 0.0604394605953713
Validation loss: 2.0883166580896915

Epoch: 5| Step: 1
Training loss: 0.1175931070293961
Validation loss: 2.03948316241276

Epoch: 5| Step: 2
Training loss: 0.11222970781522748
Validation loss: 2.0606399046241206

Epoch: 5| Step: 3
Training loss: 0.08713167251577232
Validation loss: 2.0848124559071404

Epoch: 5| Step: 4
Training loss: 0.10082374626765168
Validation loss: 2.0942505660699124

Epoch: 5| Step: 5
Training loss: 0.09612041119038493
Validation loss: 2.0775485174022523

Epoch: 5| Step: 6
Training loss: 0.05521002272429281
Validation loss: 2.0572182615888512

Epoch: 5| Step: 7
Training loss: 0.08481459785058165
Validation loss: 2.05481466012691

Epoch: 5| Step: 8
Training loss: 0.08044912008551289
Validation loss: 2.0588462550040565

Epoch: 5| Step: 9
Training loss: 0.10162640816691232
Validation loss: 2.061412214923076

Epoch: 5| Step: 10
Training loss: 0.07285845048981736
Validation loss: 2.0628579631725366

Epoch: 716| Step: 0
Training loss: 0.09092341487647128
Validation loss: 2.086448882969216

Epoch: 5| Step: 1
Training loss: 0.09421206885541969
Validation loss: 2.0654048295538416

Epoch: 5| Step: 2
Training loss: 0.10986364152637325
Validation loss: 2.069447015424557

Epoch: 5| Step: 3
Training loss: 0.06015306501502978
Validation loss: 2.083421178216792

Epoch: 5| Step: 4
Training loss: 0.11148754216956915
Validation loss: 2.0832685997863094

Epoch: 5| Step: 5
Training loss: 0.06350445501354743
Validation loss: 2.04422243801812

Epoch: 5| Step: 6
Training loss: 0.10530212273393993
Validation loss: 2.06382686162372

Epoch: 5| Step: 7
Training loss: 0.1387596188574721
Validation loss: 2.0876616309960827

Epoch: 5| Step: 8
Training loss: 0.1084918659117811
Validation loss: 2.0833573108236707

Epoch: 5| Step: 9
Training loss: 0.1112732124422756
Validation loss: 2.083905686133046

Epoch: 5| Step: 10
Training loss: 0.03724948102264298
Validation loss: 2.0751268284576523

Epoch: 717| Step: 0
Training loss: 0.09839362233772808
Validation loss: 2.0647430515923646

Epoch: 5| Step: 1
Training loss: 0.07973666193951207
Validation loss: 2.0673115832849684

Epoch: 5| Step: 2
Training loss: 0.08608236619680174
Validation loss: 2.0837777613289856

Epoch: 5| Step: 3
Training loss: 0.1009862719872192
Validation loss: 2.090383395241242

Epoch: 5| Step: 4
Training loss: 0.09488316990929133
Validation loss: 2.0528755022781953

Epoch: 5| Step: 5
Training loss: 0.1322557687551355
Validation loss: 2.052438000610981

Epoch: 5| Step: 6
Training loss: 0.07283942425729231
Validation loss: 2.092297609985474

Epoch: 5| Step: 7
Training loss: 0.08480643331662661
Validation loss: 2.0574884692561137

Epoch: 5| Step: 8
Training loss: 0.10701588290641988
Validation loss: 2.033451896776668

Epoch: 5| Step: 9
Training loss: 0.09435738069069466
Validation loss: 2.0486472582062794

Epoch: 5| Step: 10
Training loss: 0.06981058587854236
Validation loss: 2.048229879738167

Epoch: 718| Step: 0
Training loss: 0.074398801144752
Validation loss: 2.086321961965402

Epoch: 5| Step: 1
Training loss: 0.0978699539322217
Validation loss: 2.102123667425565

Epoch: 5| Step: 2
Training loss: 0.12407343149669528
Validation loss: 2.085318847516177

Epoch: 5| Step: 3
Training loss: 0.08801253923251509
Validation loss: 2.080724475898483

Epoch: 5| Step: 4
Training loss: 0.05614702987405905
Validation loss: 2.0712279623914376

Epoch: 5| Step: 5
Training loss: 0.085924304686048
Validation loss: 2.104831407394695

Epoch: 5| Step: 6
Training loss: 0.08959432892999857
Validation loss: 2.1189865311084404

Epoch: 5| Step: 7
Training loss: 0.07711114163003112
Validation loss: 2.0765946445285626

Epoch: 5| Step: 8
Training loss: 0.132607596476155
Validation loss: 2.092963995441988

Epoch: 5| Step: 9
Training loss: 0.08102749172951734
Validation loss: 2.0285995343107674

Epoch: 5| Step: 10
Training loss: 0.08513251059034832
Validation loss: 2.0624828368983366

Epoch: 719| Step: 0
Training loss: 0.06165463597161548
Validation loss: 2.082735774162185

Epoch: 5| Step: 1
Training loss: 0.08277222918267126
Validation loss: 2.0551448322258397

Epoch: 5| Step: 2
Training loss: 0.08431218455925815
Validation loss: 2.0639000227568083

Epoch: 5| Step: 3
Training loss: 0.07324645347887311
Validation loss: 2.060674457325971

Epoch: 5| Step: 4
Training loss: 0.08288124757695811
Validation loss: 2.0575991943677794

Epoch: 5| Step: 5
Training loss: 0.09576549249503886
Validation loss: 2.065600429313877

Epoch: 5| Step: 6
Training loss: 0.11440521090081732
Validation loss: 2.068435694340516

Epoch: 5| Step: 7
Training loss: 0.05796121875791364
Validation loss: 2.066114059059949

Epoch: 5| Step: 8
Training loss: 0.0808962514426313
Validation loss: 2.0895678303075305

Epoch: 5| Step: 9
Training loss: 0.08386271280914015
Validation loss: 2.097190506567249

Epoch: 5| Step: 10
Training loss: 0.11353006250756371
Validation loss: 2.0964301618649483

Epoch: 720| Step: 0
Training loss: 0.07501044399340616
Validation loss: 2.104255923734896

Epoch: 5| Step: 1
Training loss: 0.10305939758800461
Validation loss: 2.115123145427906

Epoch: 5| Step: 2
Training loss: 0.07578225319483468
Validation loss: 2.0801571767966958

Epoch: 5| Step: 3
Training loss: 0.08639349576865338
Validation loss: 2.1212042857896227

Epoch: 5| Step: 4
Training loss: 0.11094568467505889
Validation loss: 2.07641212324261

Epoch: 5| Step: 5
Training loss: 0.10442486492695748
Validation loss: 2.081183252086777

Epoch: 5| Step: 6
Training loss: 0.09568824457754699
Validation loss: 2.0601799894158317

Epoch: 5| Step: 7
Training loss: 0.08625510977211232
Validation loss: 2.0653281176866845

Epoch: 5| Step: 8
Training loss: 0.08360461939798364
Validation loss: 2.0695968033227152

Epoch: 5| Step: 9
Training loss: 0.09964446777308231
Validation loss: 2.0800586838761896

Epoch: 5| Step: 10
Training loss: 0.10792064184277135
Validation loss: 2.0711302052764147

Epoch: 721| Step: 0
Training loss: 0.07422732002571172
Validation loss: 2.059659591172238

Epoch: 5| Step: 1
Training loss: 0.11215645502677028
Validation loss: 2.0509194016886845

Epoch: 5| Step: 2
Training loss: 0.09900823284545468
Validation loss: 2.091728482862764

Epoch: 5| Step: 3
Training loss: 0.07712610742470997
Validation loss: 2.057203928731694

Epoch: 5| Step: 4
Training loss: 0.06744925015590682
Validation loss: 2.071388999034705

Epoch: 5| Step: 5
Training loss: 0.10402936579034128
Validation loss: 2.09011880043887

Epoch: 5| Step: 6
Training loss: 0.10897074651789922
Validation loss: 2.063027792601564

Epoch: 5| Step: 7
Training loss: 0.06136708791046026
Validation loss: 2.075533305931857

Epoch: 5| Step: 8
Training loss: 0.0992871758160707
Validation loss: 2.091487085912002

Epoch: 5| Step: 9
Training loss: 0.08532181642651403
Validation loss: 2.073109461409475

Epoch: 5| Step: 10
Training loss: 0.09935236010929088
Validation loss: 2.0761305961070384

Epoch: 722| Step: 0
Training loss: 0.05771591730942767
Validation loss: 2.0912358735542784

Epoch: 5| Step: 1
Training loss: 0.09265024136750123
Validation loss: 2.0406426035248595

Epoch: 5| Step: 2
Training loss: 0.083005829394718
Validation loss: 2.0578367959409927

Epoch: 5| Step: 3
Training loss: 0.05301337040456139
Validation loss: 2.0840439454107798

Epoch: 5| Step: 4
Training loss: 0.10748242059148826
Validation loss: 2.0676514029379045

Epoch: 5| Step: 5
Training loss: 0.09798755713155925
Validation loss: 2.084336175022122

Epoch: 5| Step: 6
Training loss: 0.12143213154553645
Validation loss: 2.0869176802412683

Epoch: 5| Step: 7
Training loss: 0.09066009746199351
Validation loss: 2.0592791142281777

Epoch: 5| Step: 8
Training loss: 0.10411553816892628
Validation loss: 2.0748462716918805

Epoch: 5| Step: 9
Training loss: 0.07367825712066012
Validation loss: 2.0834127594563707

Epoch: 5| Step: 10
Training loss: 0.11600843384801317
Validation loss: 2.0680396697754553

Epoch: 723| Step: 0
Training loss: 0.06617128301556102
Validation loss: 2.078530468715547

Epoch: 5| Step: 1
Training loss: 0.06363797572564482
Validation loss: 2.0625202567012217

Epoch: 5| Step: 2
Training loss: 0.08356302768569908
Validation loss: 2.0803914823687135

Epoch: 5| Step: 3
Training loss: 0.06941072701773315
Validation loss: 2.0695378822300876

Epoch: 5| Step: 4
Training loss: 0.07918170119041185
Validation loss: 2.050024217144408

Epoch: 5| Step: 5
Training loss: 0.1454506960399768
Validation loss: 2.0321632007926893

Epoch: 5| Step: 6
Training loss: 0.09658368478561048
Validation loss: 2.0644791573380417

Epoch: 5| Step: 7
Training loss: 0.08770953702364957
Validation loss: 2.0574946961559872

Epoch: 5| Step: 8
Training loss: 0.10125742999089139
Validation loss: 2.067937464494656

Epoch: 5| Step: 9
Training loss: 0.07989369938446754
Validation loss: 2.0539525436021995

Epoch: 5| Step: 10
Training loss: 0.07465379663290875
Validation loss: 2.0504058641211915

Epoch: 724| Step: 0
Training loss: 0.07988664074610854
Validation loss: 2.0419444078788493

Epoch: 5| Step: 1
Training loss: 0.11158871268619473
Validation loss: 2.056013815494645

Epoch: 5| Step: 2
Training loss: 0.07422775289241264
Validation loss: 2.0731676773887635

Epoch: 5| Step: 3
Training loss: 0.11974739901519271
Validation loss: 2.0647275138141414

Epoch: 5| Step: 4
Training loss: 0.07198167767655607
Validation loss: 2.0640050232725105

Epoch: 5| Step: 5
Training loss: 0.06642511394382025
Validation loss: 2.062730880050604

Epoch: 5| Step: 6
Training loss: 0.11912038115191158
Validation loss: 2.0558846745207022

Epoch: 5| Step: 7
Training loss: 0.11502049689746653
Validation loss: 2.086308425628551

Epoch: 5| Step: 8
Training loss: 0.07405455521532404
Validation loss: 2.0907015401987827

Epoch: 5| Step: 9
Training loss: 0.06225801912937157
Validation loss: 2.088072409126988

Epoch: 5| Step: 10
Training loss: 0.12646646388131813
Validation loss: 2.088079085876371

Epoch: 725| Step: 0
Training loss: 0.07472772872541206
Validation loss: 2.1115036287648983

Epoch: 5| Step: 1
Training loss: 0.059071784273703604
Validation loss: 2.093660528101499

Epoch: 5| Step: 2
Training loss: 0.07151383407889014
Validation loss: 2.1152779394932777

Epoch: 5| Step: 3
Training loss: 0.09572847186380534
Validation loss: 2.1050819590984737

Epoch: 5| Step: 4
Training loss: 0.06945110883457536
Validation loss: 2.095783324733565

Epoch: 5| Step: 5
Training loss: 0.0829271878653244
Validation loss: 2.076130881967074

Epoch: 5| Step: 6
Training loss: 0.05275923531487869
Validation loss: 2.0660834060339046

Epoch: 5| Step: 7
Training loss: 0.083577729633043
Validation loss: 2.0831129039519314

Epoch: 5| Step: 8
Training loss: 0.08521726734230589
Validation loss: 2.10411610741082

Epoch: 5| Step: 9
Training loss: 0.1308908993910643
Validation loss: 2.0702350746702125

Epoch: 5| Step: 10
Training loss: 0.09884592676223161
Validation loss: 2.0786542771269927

Epoch: 726| Step: 0
Training loss: 0.06593050307736649
Validation loss: 2.0956815339216814

Epoch: 5| Step: 1
Training loss: 0.09575234334769872
Validation loss: 2.0677869819042365

Epoch: 5| Step: 2
Training loss: 0.10425675688545417
Validation loss: 2.0550084391553063

Epoch: 5| Step: 3
Training loss: 0.09454674219441453
Validation loss: 2.073727165498523

Epoch: 5| Step: 4
Training loss: 0.08479348210561473
Validation loss: 2.083812421861547

Epoch: 5| Step: 5
Training loss: 0.1190756323473036
Validation loss: 2.089976273234348

Epoch: 5| Step: 6
Training loss: 0.16961158176429114
Validation loss: 2.0682775782663443

Epoch: 5| Step: 7
Training loss: 0.09657394521901569
Validation loss: 2.0837204400220584

Epoch: 5| Step: 8
Training loss: 0.1100491498535718
Validation loss: 2.0933448363977556

Epoch: 5| Step: 9
Training loss: 0.07321679628845226
Validation loss: 2.0863652036818414

Epoch: 5| Step: 10
Training loss: 0.08417888506000173
Validation loss: 2.0941424344113275

Epoch: 727| Step: 0
Training loss: 0.0836851700781794
Validation loss: 2.0850838446124915

Epoch: 5| Step: 1
Training loss: 0.09595148305384157
Validation loss: 2.100601689669443

Epoch: 5| Step: 2
Training loss: 0.09934463568649918
Validation loss: 2.0922443141184828

Epoch: 5| Step: 3
Training loss: 0.09557414121215783
Validation loss: 2.088052732040506

Epoch: 5| Step: 4
Training loss: 0.11067570283440196
Validation loss: 2.0989519600748694

Epoch: 5| Step: 5
Training loss: 0.07149221267883171
Validation loss: 2.1043690196617106

Epoch: 5| Step: 6
Training loss: 0.09583752789681683
Validation loss: 2.0949049121265184

Epoch: 5| Step: 7
Training loss: 0.10881130104209628
Validation loss: 2.0823566321266243

Epoch: 5| Step: 8
Training loss: 0.11214320556251434
Validation loss: 2.0643414325042815

Epoch: 5| Step: 9
Training loss: 0.07456789586311241
Validation loss: 2.0900379800993556

Epoch: 5| Step: 10
Training loss: 0.06639033014542195
Validation loss: 2.067293200193587

Epoch: 728| Step: 0
Training loss: 0.07059010698662986
Validation loss: 2.0754239273335444

Epoch: 5| Step: 1
Training loss: 0.1015992831598172
Validation loss: 2.06530640953073

Epoch: 5| Step: 2
Training loss: 0.08583223333028123
Validation loss: 2.0822673096533415

Epoch: 5| Step: 3
Training loss: 0.09096827810395061
Validation loss: 2.0790048408732305

Epoch: 5| Step: 4
Training loss: 0.06863184510267338
Validation loss: 2.085092104473946

Epoch: 5| Step: 5
Training loss: 0.06729835593939194
Validation loss: 2.0963323726653647

Epoch: 5| Step: 6
Training loss: 0.09389826851755076
Validation loss: 2.0878153483623234

Epoch: 5| Step: 7
Training loss: 0.08107323606663354
Validation loss: 2.0807124845441876

Epoch: 5| Step: 8
Training loss: 0.09243298855547848
Validation loss: 2.093786902631265

Epoch: 5| Step: 9
Training loss: 0.1333377144200557
Validation loss: 2.098521087799324

Epoch: 5| Step: 10
Training loss: 0.14393833692152472
Validation loss: 2.097087083288337

Epoch: 729| Step: 0
Training loss: 0.04306999924651508
Validation loss: 2.0666281714742665

Epoch: 5| Step: 1
Training loss: 0.08733510782448482
Validation loss: 2.094168747725331

Epoch: 5| Step: 2
Training loss: 0.10489042989677742
Validation loss: 2.0948022088077214

Epoch: 5| Step: 3
Training loss: 0.09674664307778466
Validation loss: 2.0656679583328272

Epoch: 5| Step: 4
Training loss: 0.11349669473226699
Validation loss: 2.0654910745591346

Epoch: 5| Step: 5
Training loss: 0.08243507656930599
Validation loss: 2.050558378626586

Epoch: 5| Step: 6
Training loss: 0.09238067608353022
Validation loss: 2.0518396883697303

Epoch: 5| Step: 7
Training loss: 0.09753445659879828
Validation loss: 2.0732052332629785

Epoch: 5| Step: 8
Training loss: 0.10559630627796356
Validation loss: 2.0488804174792374

Epoch: 5| Step: 9
Training loss: 0.132138287027278
Validation loss: 2.039823581250249

Epoch: 5| Step: 10
Training loss: 0.09096877975882722
Validation loss: 2.0440148716838022

Epoch: 730| Step: 0
Training loss: 0.1115518380127167
Validation loss: 2.046451669173941

Epoch: 5| Step: 1
Training loss: 0.10143776716830549
Validation loss: 2.07237649146502

Epoch: 5| Step: 2
Training loss: 0.08496283934645957
Validation loss: 2.0430261414903073

Epoch: 5| Step: 3
Training loss: 0.08562031646087491
Validation loss: 2.0578682177390633

Epoch: 5| Step: 4
Training loss: 0.07143388369456496
Validation loss: 2.067440672030159

Epoch: 5| Step: 5
Training loss: 0.09762160163384904
Validation loss: 2.055094623036914

Epoch: 5| Step: 6
Training loss: 0.08011600714845829
Validation loss: 2.0601629003153423

Epoch: 5| Step: 7
Training loss: 0.09711852804674499
Validation loss: 2.062797287552631

Epoch: 5| Step: 8
Training loss: 0.0667173342867252
Validation loss: 2.0651823024205105

Epoch: 5| Step: 9
Training loss: 0.06947159257191941
Validation loss: 2.091465047420842

Epoch: 5| Step: 10
Training loss: 0.11589450389793979
Validation loss: 2.120440629234714

Epoch: 731| Step: 0
Training loss: 0.08024743835536398
Validation loss: 2.0952604144825613

Epoch: 5| Step: 1
Training loss: 0.09500602418376947
Validation loss: 2.073342324174326

Epoch: 5| Step: 2
Training loss: 0.11743346865176915
Validation loss: 2.0704460548296297

Epoch: 5| Step: 3
Training loss: 0.08653716813666042
Validation loss: 2.079433606791636

Epoch: 5| Step: 4
Training loss: 0.09186272592689367
Validation loss: 2.090477045749912

Epoch: 5| Step: 5
Training loss: 0.13579251022092462
Validation loss: 2.0910819028336016

Epoch: 5| Step: 6
Training loss: 0.08828548636441626
Validation loss: 2.098968480999974

Epoch: 5| Step: 7
Training loss: 0.06829380569202634
Validation loss: 2.0898004483864283

Epoch: 5| Step: 8
Training loss: 0.12807771985030772
Validation loss: 2.0721095255420914

Epoch: 5| Step: 9
Training loss: 0.09186013051134523
Validation loss: 2.0609542172667976

Epoch: 5| Step: 10
Training loss: 0.038838543232975774
Validation loss: 2.087288653377941

Epoch: 732| Step: 0
Training loss: 0.058797117803002834
Validation loss: 2.107966044162426

Epoch: 5| Step: 1
Training loss: 0.06969559433247977
Validation loss: 2.079223579293472

Epoch: 5| Step: 2
Training loss: 0.08964676097058512
Validation loss: 2.0733341071484137

Epoch: 5| Step: 3
Training loss: 0.10721440654563621
Validation loss: 2.061016110166934

Epoch: 5| Step: 4
Training loss: 0.09779273032922559
Validation loss: 2.0842826017791274

Epoch: 5| Step: 5
Training loss: 0.13697177089795037
Validation loss: 2.087005775526255

Epoch: 5| Step: 6
Training loss: 0.10871571425821035
Validation loss: 2.068743623994403

Epoch: 5| Step: 7
Training loss: 0.09288584274160616
Validation loss: 2.073658135363341

Epoch: 5| Step: 8
Training loss: 0.07013299665504424
Validation loss: 2.0970646867796563

Epoch: 5| Step: 9
Training loss: 0.06260128308291807
Validation loss: 2.0970700681737875

Epoch: 5| Step: 10
Training loss: 0.13938731342286423
Validation loss: 2.095520784102787

Epoch: 733| Step: 0
Training loss: 0.1027145972269788
Validation loss: 2.111963730395766

Epoch: 5| Step: 1
Training loss: 0.10243770039912947
Validation loss: 2.068794774888635

Epoch: 5| Step: 2
Training loss: 0.07034798892114784
Validation loss: 2.079630895572999

Epoch: 5| Step: 3
Training loss: 0.10424540246115425
Validation loss: 2.124345840390921

Epoch: 5| Step: 4
Training loss: 0.08234570891332177
Validation loss: 2.119604116076868

Epoch: 5| Step: 5
Training loss: 0.11878086711608067
Validation loss: 2.1117972627704256

Epoch: 5| Step: 6
Training loss: 0.08016930889717121
Validation loss: 2.088332979728816

Epoch: 5| Step: 7
Training loss: 0.12537659599281029
Validation loss: 2.064450758125309

Epoch: 5| Step: 8
Training loss: 0.06807011986867985
Validation loss: 2.062695690030992

Epoch: 5| Step: 9
Training loss: 0.0717032530243762
Validation loss: 2.085824399632397

Epoch: 5| Step: 10
Training loss: 0.05221765403693243
Validation loss: 2.0892567321241824

Epoch: 734| Step: 0
Training loss: 0.10088571302081242
Validation loss: 2.0372178503212486

Epoch: 5| Step: 1
Training loss: 0.06664263152626836
Validation loss: 2.041554765813645

Epoch: 5| Step: 2
Training loss: 0.08962286353757054
Validation loss: 2.045266614245823

Epoch: 5| Step: 3
Training loss: 0.1039410746089317
Validation loss: 2.0413347564214286

Epoch: 5| Step: 4
Training loss: 0.12477608085728627
Validation loss: 2.0396717710704606

Epoch: 5| Step: 5
Training loss: 0.112644291605481
Validation loss: 2.0519947624008568

Epoch: 5| Step: 6
Training loss: 0.10901640110414847
Validation loss: 2.067801745380346

Epoch: 5| Step: 7
Training loss: 0.08780414512280761
Validation loss: 2.051452248178461

Epoch: 5| Step: 8
Training loss: 0.1298502974575089
Validation loss: 2.0478661341961995

Epoch: 5| Step: 9
Training loss: 0.13049633996451376
Validation loss: 2.0857584880604967

Epoch: 5| Step: 10
Training loss: 0.04922747383309352
Validation loss: 2.062609186448866

Epoch: 735| Step: 0
Training loss: 0.08480211463567698
Validation loss: 2.0657395873663233

Epoch: 5| Step: 1
Training loss: 0.1310714739354509
Validation loss: 2.0907392458383343

Epoch: 5| Step: 2
Training loss: 0.08523234229019755
Validation loss: 2.1140611558378812

Epoch: 5| Step: 3
Training loss: 0.10527314485073992
Validation loss: 2.105920569523619

Epoch: 5| Step: 4
Training loss: 0.11260295319484136
Validation loss: 2.096402663842706

Epoch: 5| Step: 5
Training loss: 0.13617661481564808
Validation loss: 2.078008443219256

Epoch: 5| Step: 6
Training loss: 0.11671962320238588
Validation loss: 2.087279134684781

Epoch: 5| Step: 7
Training loss: 0.09050574224983052
Validation loss: 2.066596665157802

Epoch: 5| Step: 8
Training loss: 0.07192417294898054
Validation loss: 2.094474673193345

Epoch: 5| Step: 9
Training loss: 0.08387987710677539
Validation loss: 2.0505603567796986

Epoch: 5| Step: 10
Training loss: 0.13714505217787168
Validation loss: 2.060557811097431

Epoch: 736| Step: 0
Training loss: 0.07225870730823224
Validation loss: 2.0929344687633704

Epoch: 5| Step: 1
Training loss: 0.08579771637734136
Validation loss: 2.0710239116046685

Epoch: 5| Step: 2
Training loss: 0.06757513188475561
Validation loss: 2.0808253871990017

Epoch: 5| Step: 3
Training loss: 0.12715097562539
Validation loss: 2.0439754546750866

Epoch: 5| Step: 4
Training loss: 0.06613701347937445
Validation loss: 2.102791471031658

Epoch: 5| Step: 5
Training loss: 0.09184585441483606
Validation loss: 2.056556660291308

Epoch: 5| Step: 6
Training loss: 0.07868901449125408
Validation loss: 2.052471526649906

Epoch: 5| Step: 7
Training loss: 0.05720987654422004
Validation loss: 2.0740301062911644

Epoch: 5| Step: 8
Training loss: 0.11068293518602863
Validation loss: 2.0905702542786853

Epoch: 5| Step: 9
Training loss: 0.09286416787075803
Validation loss: 2.082978956374585

Epoch: 5| Step: 10
Training loss: 0.10390553276990432
Validation loss: 2.1028345895589737

Epoch: 737| Step: 0
Training loss: 0.0933028824321863
Validation loss: 2.1007295418520475

Epoch: 5| Step: 1
Training loss: 0.10124236784532652
Validation loss: 2.0856391835065917

Epoch: 5| Step: 2
Training loss: 0.10363985650243335
Validation loss: 2.0582460689425854

Epoch: 5| Step: 3
Training loss: 0.08125831694401002
Validation loss: 2.077952178299797

Epoch: 5| Step: 4
Training loss: 0.0567525280286184
Validation loss: 2.0775995841672805

Epoch: 5| Step: 5
Training loss: 0.07337162659971562
Validation loss: 2.0962579779371286

Epoch: 5| Step: 6
Training loss: 0.07185176637116038
Validation loss: 2.0977841142725633

Epoch: 5| Step: 7
Training loss: 0.09427834188036857
Validation loss: 2.0600849298843884

Epoch: 5| Step: 8
Training loss: 0.11531447600788322
Validation loss: 2.0546638764713574

Epoch: 5| Step: 9
Training loss: 0.10725086645463258
Validation loss: 2.0448956331808112

Epoch: 5| Step: 10
Training loss: 0.0957767534211729
Validation loss: 2.091135729436093

Epoch: 738| Step: 0
Training loss: 0.07423681114686176
Validation loss: 2.0541485761575413

Epoch: 5| Step: 1
Training loss: 0.1012195795036403
Validation loss: 2.0607592463687627

Epoch: 5| Step: 2
Training loss: 0.09789958201999589
Validation loss: 2.083706942457292

Epoch: 5| Step: 3
Training loss: 0.08206346424259713
Validation loss: 2.0533339335134806

Epoch: 5| Step: 4
Training loss: 0.07901274734180597
Validation loss: 2.082963011858465

Epoch: 5| Step: 5
Training loss: 0.09994691803363555
Validation loss: 2.0535613062104723

Epoch: 5| Step: 6
Training loss: 0.08200289031675832
Validation loss: 2.062212719553713

Epoch: 5| Step: 7
Training loss: 0.07740325432914874
Validation loss: 2.0649330086749087

Epoch: 5| Step: 8
Training loss: 0.06200202167715686
Validation loss: 2.0519663153399104

Epoch: 5| Step: 9
Training loss: 0.05666859117227774
Validation loss: 2.0936696602362956

Epoch: 5| Step: 10
Training loss: 0.10693852748550019
Validation loss: 2.0485236254264234

Epoch: 739| Step: 0
Training loss: 0.08180808751954584
Validation loss: 2.0638552352620096

Epoch: 5| Step: 1
Training loss: 0.06594084236862514
Validation loss: 2.0659670490675683

Epoch: 5| Step: 2
Training loss: 0.093518487859388
Validation loss: 2.079090413212636

Epoch: 5| Step: 3
Training loss: 0.10530140192178872
Validation loss: 2.094468484631426

Epoch: 5| Step: 4
Training loss: 0.08466958371110482
Validation loss: 2.0568900681459543

Epoch: 5| Step: 5
Training loss: 0.07304537396750191
Validation loss: 2.075212998027106

Epoch: 5| Step: 6
Training loss: 0.11770824522743753
Validation loss: 2.1100760397520792

Epoch: 5| Step: 7
Training loss: 0.1015732786987942
Validation loss: 2.0954195699342817

Epoch: 5| Step: 8
Training loss: 0.08544491075827816
Validation loss: 2.0865111936097027

Epoch: 5| Step: 9
Training loss: 0.11795985491482161
Validation loss: 2.075148904569835

Epoch: 5| Step: 10
Training loss: 0.06213649451580513
Validation loss: 2.078489703512044

Epoch: 740| Step: 0
Training loss: 0.08792560728919298
Validation loss: 2.0605071331811176

Epoch: 5| Step: 1
Training loss: 0.09997855753784934
Validation loss: 2.0732082260427913

Epoch: 5| Step: 2
Training loss: 0.042764819160955696
Validation loss: 2.0918233189272346

Epoch: 5| Step: 3
Training loss: 0.08606208635264037
Validation loss: 2.0525867533224926

Epoch: 5| Step: 4
Training loss: 0.07604008056780587
Validation loss: 2.048529399644048

Epoch: 5| Step: 5
Training loss: 0.12718716103510946
Validation loss: 2.0626814051775284

Epoch: 5| Step: 6
Training loss: 0.07619996347707307
Validation loss: 2.0441716407510118

Epoch: 5| Step: 7
Training loss: 0.07905918033796336
Validation loss: 2.082301704159172

Epoch: 5| Step: 8
Training loss: 0.11483473093598094
Validation loss: 2.064169119160463

Epoch: 5| Step: 9
Training loss: 0.05781219303526447
Validation loss: 2.0786920983131285

Epoch: 5| Step: 10
Training loss: 0.06447668439709608
Validation loss: 2.07087026997121

Epoch: 741| Step: 0
Training loss: 0.07158048713965047
Validation loss: 2.092047815960186

Epoch: 5| Step: 1
Training loss: 0.0873649133418506
Validation loss: 2.097650791892184

Epoch: 5| Step: 2
Training loss: 0.09334936567143613
Validation loss: 2.0602450717947254

Epoch: 5| Step: 3
Training loss: 0.11020869738002471
Validation loss: 2.073215165281252

Epoch: 5| Step: 4
Training loss: 0.058603127047117086
Validation loss: 2.087028018951639

Epoch: 5| Step: 5
Training loss: 0.12035500623957025
Validation loss: 2.0762882484246363

Epoch: 5| Step: 6
Training loss: 0.11277183731101305
Validation loss: 2.053125274566284

Epoch: 5| Step: 7
Training loss: 0.15236884912948986
Validation loss: 2.1172125533751656

Epoch: 5| Step: 8
Training loss: 0.07717824010189754
Validation loss: 2.0915569525043116

Epoch: 5| Step: 9
Training loss: 0.09390315817187744
Validation loss: 2.0948446213619465

Epoch: 5| Step: 10
Training loss: 0.09471093864978997
Validation loss: 2.107373706630912

Epoch: 742| Step: 0
Training loss: 0.07679319682388903
Validation loss: 2.1056352126774884

Epoch: 5| Step: 1
Training loss: 0.0904622865749739
Validation loss: 2.093384072375193

Epoch: 5| Step: 2
Training loss: 0.08849557794350302
Validation loss: 2.094637128031447

Epoch: 5| Step: 3
Training loss: 0.07308160025318494
Validation loss: 2.0978283588779942

Epoch: 5| Step: 4
Training loss: 0.09864442114925272
Validation loss: 2.0618386325361135

Epoch: 5| Step: 5
Training loss: 0.06628657875847885
Validation loss: 2.0717402167482755

Epoch: 5| Step: 6
Training loss: 0.08979516166750413
Validation loss: 2.080073964166165

Epoch: 5| Step: 7
Training loss: 0.07295231997678349
Validation loss: 2.0812667880492417

Epoch: 5| Step: 8
Training loss: 0.11947224927966674
Validation loss: 2.057298066542175

Epoch: 5| Step: 9
Training loss: 0.07871965059561783
Validation loss: 2.0737445217268067

Epoch: 5| Step: 10
Training loss: 0.0797014945261101
Validation loss: 2.0665280555704375

Epoch: 743| Step: 0
Training loss: 0.10003520133667573
Validation loss: 2.0794794105582133

Epoch: 5| Step: 1
Training loss: 0.11258088439402796
Validation loss: 2.0428106816657454

Epoch: 5| Step: 2
Training loss: 0.0648356164001997
Validation loss: 2.0835407211282355

Epoch: 5| Step: 3
Training loss: 0.06224004507226066
Validation loss: 2.0549111991755797

Epoch: 5| Step: 4
Training loss: 0.10488315330037987
Validation loss: 2.0829228626447374

Epoch: 5| Step: 5
Training loss: 0.07921368693738208
Validation loss: 2.043608133407795

Epoch: 5| Step: 6
Training loss: 0.10575623977995413
Validation loss: 2.0872149916855696

Epoch: 5| Step: 7
Training loss: 0.08057745077551243
Validation loss: 2.0802359569305517

Epoch: 5| Step: 8
Training loss: 0.07398795961076773
Validation loss: 2.06848343463737

Epoch: 5| Step: 9
Training loss: 0.045406146539017596
Validation loss: 2.1163551320850003

Epoch: 5| Step: 10
Training loss: 0.07022565869802114
Validation loss: 2.072220295819735

Epoch: 744| Step: 0
Training loss: 0.06589604825661576
Validation loss: 2.07364853926632

Epoch: 5| Step: 1
Training loss: 0.10026079235584501
Validation loss: 2.1069138839085526

Epoch: 5| Step: 2
Training loss: 0.08067582531894889
Validation loss: 2.0668079435439934

Epoch: 5| Step: 3
Training loss: 0.09256571050693868
Validation loss: 2.067553650309128

Epoch: 5| Step: 4
Training loss: 0.09800700615725638
Validation loss: 2.0809628304621475

Epoch: 5| Step: 5
Training loss: 0.09253237173159982
Validation loss: 2.093416584462101

Epoch: 5| Step: 6
Training loss: 0.08604105757046673
Validation loss: 2.0720810706872257

Epoch: 5| Step: 7
Training loss: 0.06332727630464437
Validation loss: 2.093802997357329

Epoch: 5| Step: 8
Training loss: 0.08929169573077306
Validation loss: 2.048182268158759

Epoch: 5| Step: 9
Training loss: 0.08366669409069591
Validation loss: 2.080329926227627

Epoch: 5| Step: 10
Training loss: 0.075804589059674
Validation loss: 2.087178057610125

Epoch: 745| Step: 0
Training loss: 0.12204364866871881
Validation loss: 2.0655896229269857

Epoch: 5| Step: 1
Training loss: 0.09963799514249068
Validation loss: 2.075353253892357

Epoch: 5| Step: 2
Training loss: 0.08714642164599608
Validation loss: 2.079243814859185

Epoch: 5| Step: 3
Training loss: 0.060174018926298485
Validation loss: 2.0529138246156258

Epoch: 5| Step: 4
Training loss: 0.05053659337466797
Validation loss: 2.0942103027336736

Epoch: 5| Step: 5
Training loss: 0.09365422104752906
Validation loss: 2.05818332608593

Epoch: 5| Step: 6
Training loss: 0.08117303194372542
Validation loss: 2.0768562957388608

Epoch: 5| Step: 7
Training loss: 0.0771501818592508
Validation loss: 2.0441398290717796

Epoch: 5| Step: 8
Training loss: 0.08975020493647361
Validation loss: 2.0674979570738814

Epoch: 5| Step: 9
Training loss: 0.0679978038636127
Validation loss: 2.0580045246718823

Epoch: 5| Step: 10
Training loss: 0.10265006460428411
Validation loss: 2.0683803551669278

Epoch: 746| Step: 0
Training loss: 0.09191308376473686
Validation loss: 2.085793979118444

Epoch: 5| Step: 1
Training loss: 0.08338053274366573
Validation loss: 2.063296725063859

Epoch: 5| Step: 2
Training loss: 0.10860841621186462
Validation loss: 2.060252378532804

Epoch: 5| Step: 3
Training loss: 0.09521896157774848
Validation loss: 2.06748145173389

Epoch: 5| Step: 4
Training loss: 0.05353478894321675
Validation loss: 2.066293388265355

Epoch: 5| Step: 5
Training loss: 0.0645290094210623
Validation loss: 2.055361463737576

Epoch: 5| Step: 6
Training loss: 0.1169743904880763
Validation loss: 2.0591058730160827

Epoch: 5| Step: 7
Training loss: 0.08256998720374788
Validation loss: 2.0510560460523686

Epoch: 5| Step: 8
Training loss: 0.09296166248713672
Validation loss: 2.0980222420207464

Epoch: 5| Step: 9
Training loss: 0.10724342001751887
Validation loss: 2.0709111919693632

Epoch: 5| Step: 10
Training loss: 0.08666724079981934
Validation loss: 2.0662097475756904

Epoch: 747| Step: 0
Training loss: 0.1086981727570882
Validation loss: 2.050577230545092

Epoch: 5| Step: 1
Training loss: 0.09021773453231159
Validation loss: 2.054932291068985

Epoch: 5| Step: 2
Training loss: 0.08824633302361079
Validation loss: 2.0600145503146634

Epoch: 5| Step: 3
Training loss: 0.07560124993779523
Validation loss: 2.049424409333545

Epoch: 5| Step: 4
Training loss: 0.08380472296970698
Validation loss: 2.0687390834658004

Epoch: 5| Step: 5
Training loss: 0.11361484079928401
Validation loss: 2.051437214579762

Epoch: 5| Step: 6
Training loss: 0.08354613271490167
Validation loss: 2.0327933406224097

Epoch: 5| Step: 7
Training loss: 0.10843732926605372
Validation loss: 2.089518447964737

Epoch: 5| Step: 8
Training loss: 0.0533308866691384
Validation loss: 2.0604011624480156

Epoch: 5| Step: 9
Training loss: 0.08241141307114909
Validation loss: 2.0632267041821892

Epoch: 5| Step: 10
Training loss: 0.08485981250429607
Validation loss: 2.061179108819202

Epoch: 748| Step: 0
Training loss: 0.13683076765447344
Validation loss: 2.0902655191902064

Epoch: 5| Step: 1
Training loss: 0.11394296777749766
Validation loss: 2.1089392582287654

Epoch: 5| Step: 2
Training loss: 0.06662897317814444
Validation loss: 2.1027985625724632

Epoch: 5| Step: 3
Training loss: 0.0753958678028502
Validation loss: 2.070591617033074

Epoch: 5| Step: 4
Training loss: 0.056297833168389266
Validation loss: 2.089260282615494

Epoch: 5| Step: 5
Training loss: 0.11226166854900282
Validation loss: 2.0657992104543395

Epoch: 5| Step: 6
Training loss: 0.09694476345932623
Validation loss: 2.0580486213996774

Epoch: 5| Step: 7
Training loss: 0.08875410514558425
Validation loss: 2.050591822566147

Epoch: 5| Step: 8
Training loss: 0.10098373122012277
Validation loss: 2.0619922061313476

Epoch: 5| Step: 9
Training loss: 0.07428486915561386
Validation loss: 2.0557843315841913

Epoch: 5| Step: 10
Training loss: 0.05717172811024852
Validation loss: 2.0399457393498026

Epoch: 749| Step: 0
Training loss: 0.09654728174656392
Validation loss: 2.062495010061682

Epoch: 5| Step: 1
Training loss: 0.06952442151732242
Validation loss: 2.0493399725798644

Epoch: 5| Step: 2
Training loss: 0.058163962053477375
Validation loss: 2.0737868927143563

Epoch: 5| Step: 3
Training loss: 0.08370994765319031
Validation loss: 2.058415345415601

Epoch: 5| Step: 4
Training loss: 0.11930052782897822
Validation loss: 2.0830882170259595

Epoch: 5| Step: 5
Training loss: 0.07166090428130109
Validation loss: 2.0541056765237973

Epoch: 5| Step: 6
Training loss: 0.06529510592113227
Validation loss: 2.0403419892985206

Epoch: 5| Step: 7
Training loss: 0.1044084355914235
Validation loss: 2.0672358707218064

Epoch: 5| Step: 8
Training loss: 0.07656372589959386
Validation loss: 2.0760078819580188

Epoch: 5| Step: 9
Training loss: 0.11971639820284237
Validation loss: 2.0431204940083743

Epoch: 5| Step: 10
Training loss: 0.05781589406270318
Validation loss: 2.0691386167975345

Epoch: 750| Step: 0
Training loss: 0.08274245201106739
Validation loss: 2.0840099333264868

Epoch: 5| Step: 1
Training loss: 0.11330750999599153
Validation loss: 2.09459098256487

Epoch: 5| Step: 2
Training loss: 0.09990479101798742
Validation loss: 2.0749434713369914

Epoch: 5| Step: 3
Training loss: 0.09915191659736546
Validation loss: 2.082038746090963

Epoch: 5| Step: 4
Training loss: 0.11133088560195177
Validation loss: 2.073201562534272

Epoch: 5| Step: 5
Training loss: 0.07774319934119411
Validation loss: 2.08009471032633

Epoch: 5| Step: 6
Training loss: 0.07244698860626206
Validation loss: 2.0714451476731646

Epoch: 5| Step: 7
Training loss: 0.09049920773422823
Validation loss: 2.046095071304068

Epoch: 5| Step: 8
Training loss: 0.06684237207844554
Validation loss: 2.094873415003031

Epoch: 5| Step: 9
Training loss: 0.06977393266931202
Validation loss: 2.0765337462112603

Epoch: 5| Step: 10
Training loss: 0.08345813334474077
Validation loss: 2.044073270697641

Epoch: 751| Step: 0
Training loss: 0.08181445675164424
Validation loss: 2.0135120618739175

Epoch: 5| Step: 1
Training loss: 0.050918645404318674
Validation loss: 2.040686270471386

Epoch: 5| Step: 2
Training loss: 0.09109510361040346
Validation loss: 2.023594257128032

Epoch: 5| Step: 3
Training loss: 0.09578604900852117
Validation loss: 2.052011041246004

Epoch: 5| Step: 4
Training loss: 0.05587888556983029
Validation loss: 2.024544649949194

Epoch: 5| Step: 5
Training loss: 0.08741438372494423
Validation loss: 2.0404606486931227

Epoch: 5| Step: 6
Training loss: 0.11912991913393861
Validation loss: 2.0182196465994466

Epoch: 5| Step: 7
Training loss: 0.10194294995655907
Validation loss: 2.062895266188426

Epoch: 5| Step: 8
Training loss: 0.08687894358106091
Validation loss: 2.0415210214134905

Epoch: 5| Step: 9
Training loss: 0.08879974446987532
Validation loss: 2.0383285014199957

Epoch: 5| Step: 10
Training loss: 0.06952127347588115
Validation loss: 2.0396498935464162

Epoch: 752| Step: 0
Training loss: 0.0783928244148961
Validation loss: 2.0593957868238997

Epoch: 5| Step: 1
Training loss: 0.08836393334868316
Validation loss: 2.054101489912868

Epoch: 5| Step: 2
Training loss: 0.05515288409561378
Validation loss: 2.0265750597809067

Epoch: 5| Step: 3
Training loss: 0.07673163028127832
Validation loss: 2.035757562720785

Epoch: 5| Step: 4
Training loss: 0.10147348042244554
Validation loss: 2.087589521811458

Epoch: 5| Step: 5
Training loss: 0.06535462799794611
Validation loss: 2.0588372392358227

Epoch: 5| Step: 6
Training loss: 0.11788934899708288
Validation loss: 2.054889959851189

Epoch: 5| Step: 7
Training loss: 0.03883834390421308
Validation loss: 2.081053885536272

Epoch: 5| Step: 8
Training loss: 0.08931653680714688
Validation loss: 2.041162722056454

Epoch: 5| Step: 9
Training loss: 0.099579016416179
Validation loss: 2.0854395361539626

Epoch: 5| Step: 10
Training loss: 0.08118018236322412
Validation loss: 2.0665579651224832

Epoch: 753| Step: 0
Training loss: 0.07784244582547346
Validation loss: 2.088747649956837

Epoch: 5| Step: 1
Training loss: 0.08396234334242748
Validation loss: 2.0435929621313096

Epoch: 5| Step: 2
Training loss: 0.09830068625012194
Validation loss: 2.079888969963093

Epoch: 5| Step: 3
Training loss: 0.0511816202049746
Validation loss: 2.0582160410949877

Epoch: 5| Step: 4
Training loss: 0.09566038014033175
Validation loss: 2.0611469980600967

Epoch: 5| Step: 5
Training loss: 0.10126088362054624
Validation loss: 2.059232488281638

Epoch: 5| Step: 6
Training loss: 0.0743557769312082
Validation loss: 2.0814279748398152

Epoch: 5| Step: 7
Training loss: 0.08782865140730356
Validation loss: 2.043254757846008

Epoch: 5| Step: 8
Training loss: 0.08850902126186212
Validation loss: 2.0692353560607204

Epoch: 5| Step: 9
Training loss: 0.06828801995002995
Validation loss: 2.0380911456908293

Epoch: 5| Step: 10
Training loss: 0.07085220179688433
Validation loss: 2.051361315093482

Epoch: 754| Step: 0
Training loss: 0.07717546762089045
Validation loss: 2.0609575590270977

Epoch: 5| Step: 1
Training loss: 0.0674111714326169
Validation loss: 2.0525872891350163

Epoch: 5| Step: 2
Training loss: 0.0938172099476956
Validation loss: 2.0451709273501293

Epoch: 5| Step: 3
Training loss: 0.10230502713712557
Validation loss: 2.0387870097365854

Epoch: 5| Step: 4
Training loss: 0.0651309574158604
Validation loss: 2.0855440219778454

Epoch: 5| Step: 5
Training loss: 0.08825151736113991
Validation loss: 2.0622660136565

Epoch: 5| Step: 6
Training loss: 0.11759785885770432
Validation loss: 2.0811399131709467

Epoch: 5| Step: 7
Training loss: 0.09195086063167118
Validation loss: 2.044707974049426

Epoch: 5| Step: 8
Training loss: 0.08143555539276705
Validation loss: 2.069104209778212

Epoch: 5| Step: 9
Training loss: 0.13690439290770468
Validation loss: 2.0655302072675292

Epoch: 5| Step: 10
Training loss: 0.05623190053844095
Validation loss: 2.0507702642674905

Epoch: 755| Step: 0
Training loss: 0.06455715049911849
Validation loss: 2.0575419745011776

Epoch: 5| Step: 1
Training loss: 0.08199921902224318
Validation loss: 2.074417196534479

Epoch: 5| Step: 2
Training loss: 0.08284865435829514
Validation loss: 2.0463247391668875

Epoch: 5| Step: 3
Training loss: 0.09759075829766377
Validation loss: 2.0597854760385075

Epoch: 5| Step: 4
Training loss: 0.08336825930328517
Validation loss: 2.056801443285835

Epoch: 5| Step: 5
Training loss: 0.0905663929721871
Validation loss: 2.075269238385177

Epoch: 5| Step: 6
Training loss: 0.1185242467697604
Validation loss: 2.07884327628709

Epoch: 5| Step: 7
Training loss: 0.09249365933053794
Validation loss: 2.032253510345862

Epoch: 5| Step: 8
Training loss: 0.08276729519544974
Validation loss: 2.081654989530871

Epoch: 5| Step: 9
Training loss: 0.06898312733862266
Validation loss: 2.049280212137921

Epoch: 5| Step: 10
Training loss: 0.08759884349737146
Validation loss: 2.0542110198041508

Epoch: 756| Step: 0
Training loss: 0.09795049208234605
Validation loss: 2.0980493232206787

Epoch: 5| Step: 1
Training loss: 0.10441509415430478
Validation loss: 2.090635198080861

Epoch: 5| Step: 2
Training loss: 0.07899179318604756
Validation loss: 2.0932030646817843

Epoch: 5| Step: 3
Training loss: 0.0725163896662551
Validation loss: 2.0834546228193194

Epoch: 5| Step: 4
Training loss: 0.060912990378876306
Validation loss: 2.0744710038519902

Epoch: 5| Step: 5
Training loss: 0.10646616442765208
Validation loss: 2.0514065834377004

Epoch: 5| Step: 6
Training loss: 0.09505598068956626
Validation loss: 2.0860858093461716

Epoch: 5| Step: 7
Training loss: 0.09046472649200389
Validation loss: 2.0886951748440334

Epoch: 5| Step: 8
Training loss: 0.08797457182813355
Validation loss: 2.0732148920029996

Epoch: 5| Step: 9
Training loss: 0.06628829985400742
Validation loss: 2.0877285729099055

Epoch: 5| Step: 10
Training loss: 0.06725674390591996
Validation loss: 2.075323580421748

Epoch: 757| Step: 0
Training loss: 0.09324528015019563
Validation loss: 2.0611343125741377

Epoch: 5| Step: 1
Training loss: 0.06178683331378
Validation loss: 2.059073597950529

Epoch: 5| Step: 2
Training loss: 0.09327083563057291
Validation loss: 2.0789956097949633

Epoch: 5| Step: 3
Training loss: 0.07734041832963286
Validation loss: 2.052385670741928

Epoch: 5| Step: 4
Training loss: 0.0703480087793369
Validation loss: 2.063758264921855

Epoch: 5| Step: 5
Training loss: 0.07963359542936346
Validation loss: 2.087784148269997

Epoch: 5| Step: 6
Training loss: 0.10545358725449443
Validation loss: 2.0698467025509304

Epoch: 5| Step: 7
Training loss: 0.06727176652068398
Validation loss: 2.0975318520896926

Epoch: 5| Step: 8
Training loss: 0.08636002274931696
Validation loss: 2.0885047202506524

Epoch: 5| Step: 9
Training loss: 0.08566070543104704
Validation loss: 2.105497707011278

Epoch: 5| Step: 10
Training loss: 0.07649634103521266
Validation loss: 2.082160292956065

Epoch: 758| Step: 0
Training loss: 0.06557693566213403
Validation loss: 2.076365922154311

Epoch: 5| Step: 1
Training loss: 0.08190253922994092
Validation loss: 2.0894083266583023

Epoch: 5| Step: 2
Training loss: 0.06275977596705146
Validation loss: 2.0699181628287757

Epoch: 5| Step: 3
Training loss: 0.08571635315450998
Validation loss: 2.082313594025421

Epoch: 5| Step: 4
Training loss: 0.07719058985741968
Validation loss: 2.0529254863277684

Epoch: 5| Step: 5
Training loss: 0.0746841925573034
Validation loss: 2.0854630470885844

Epoch: 5| Step: 6
Training loss: 0.07502635639232354
Validation loss: 2.0748110252088403

Epoch: 5| Step: 7
Training loss: 0.1270873680477446
Validation loss: 2.0685365080015097

Epoch: 5| Step: 8
Training loss: 0.10188421774480777
Validation loss: 2.0666985484842

Epoch: 5| Step: 9
Training loss: 0.07583133060283145
Validation loss: 2.054013728870567

Epoch: 5| Step: 10
Training loss: 0.09549165249649452
Validation loss: 2.0856115100207777

Epoch: 759| Step: 0
Training loss: 0.0995534244176731
Validation loss: 2.0652373188902073

Epoch: 5| Step: 1
Training loss: 0.10616923323313758
Validation loss: 2.065653468157336

Epoch: 5| Step: 2
Training loss: 0.09378978262660195
Validation loss: 2.0472027102114305

Epoch: 5| Step: 3
Training loss: 0.07383059341098666
Validation loss: 2.0670888447050952

Epoch: 5| Step: 4
Training loss: 0.08491505282687317
Validation loss: 2.0958061801889465

Epoch: 5| Step: 5
Training loss: 0.10552190394892437
Validation loss: 2.078676763466151

Epoch: 5| Step: 6
Training loss: 0.09108587631758812
Validation loss: 2.097963551803108

Epoch: 5| Step: 7
Training loss: 0.06194570737499516
Validation loss: 2.099915450943576

Epoch: 5| Step: 8
Training loss: 0.06282289364449112
Validation loss: 2.0844912143649514

Epoch: 5| Step: 9
Training loss: 0.06334867799867237
Validation loss: 2.0749665853748156

Epoch: 5| Step: 10
Training loss: 0.10280859807909212
Validation loss: 2.0986136403792273

Epoch: 760| Step: 0
Training loss: 0.10093888607343066
Validation loss: 2.0911690083630163

Epoch: 5| Step: 1
Training loss: 0.08609463133075264
Validation loss: 2.0692235446746055

Epoch: 5| Step: 2
Training loss: 0.09147130778391828
Validation loss: 2.0491958057229884

Epoch: 5| Step: 3
Training loss: 0.08983638463720572
Validation loss: 2.0872453098109687

Epoch: 5| Step: 4
Training loss: 0.10962145150856248
Validation loss: 2.049931433921882

Epoch: 5| Step: 5
Training loss: 0.106073157667438
Validation loss: 2.0880669421585245

Epoch: 5| Step: 6
Training loss: 0.08844940787778113
Validation loss: 2.0729759984072453

Epoch: 5| Step: 7
Training loss: 0.11028980957878558
Validation loss: 2.0731933288750968

Epoch: 5| Step: 8
Training loss: 0.07037222167060589
Validation loss: 2.077412467942707

Epoch: 5| Step: 9
Training loss: 0.09471605183601077
Validation loss: 2.0275366950932265

Epoch: 5| Step: 10
Training loss: 0.06014081707450738
Validation loss: 2.0744156084838767

Epoch: 761| Step: 0
Training loss: 0.08048745245855111
Validation loss: 2.0621661590041334

Epoch: 5| Step: 1
Training loss: 0.0971443876090321
Validation loss: 2.05144742944095

Epoch: 5| Step: 2
Training loss: 0.08844276355271202
Validation loss: 2.0866651210401113

Epoch: 5| Step: 3
Training loss: 0.08850620648946232
Validation loss: 2.0848288332621387

Epoch: 5| Step: 4
Training loss: 0.08209854158859867
Validation loss: 2.0502247526337953

Epoch: 5| Step: 5
Training loss: 0.09351694424813276
Validation loss: 2.0717171551915055

Epoch: 5| Step: 6
Training loss: 0.10164406600540157
Validation loss: 2.0584768283215955

Epoch: 5| Step: 7
Training loss: 0.09277850187432535
Validation loss: 2.0457869544161693

Epoch: 5| Step: 8
Training loss: 0.1116234225933802
Validation loss: 2.0460192129657067

Epoch: 5| Step: 9
Training loss: 0.10916908072742944
Validation loss: 2.0609705876734306

Epoch: 5| Step: 10
Training loss: 0.08063202699822522
Validation loss: 2.0725808175835727

Epoch: 762| Step: 0
Training loss: 0.09656553561491446
Validation loss: 2.053974715617123

Epoch: 5| Step: 1
Training loss: 0.11264490755628617
Validation loss: 2.057865576383072

Epoch: 5| Step: 2
Training loss: 0.07037429610649072
Validation loss: 2.057762405124993

Epoch: 5| Step: 3
Training loss: 0.07104339139148469
Validation loss: 2.063296841858603

Epoch: 5| Step: 4
Training loss: 0.07806026637880487
Validation loss: 2.0584181557576238

Epoch: 5| Step: 5
Training loss: 0.0626462700023239
Validation loss: 2.1173243808925672

Epoch: 5| Step: 6
Training loss: 0.09260947646271779
Validation loss: 2.072963228865807

Epoch: 5| Step: 7
Training loss: 0.07064438679864662
Validation loss: 2.071975574357832

Epoch: 5| Step: 8
Training loss: 0.06761022560557838
Validation loss: 2.071480906240775

Epoch: 5| Step: 9
Training loss: 0.07463129106159005
Validation loss: 2.082658139816805

Epoch: 5| Step: 10
Training loss: 0.053437054866476055
Validation loss: 2.0625474196595164

Epoch: 763| Step: 0
Training loss: 0.09238439098888741
Validation loss: 2.0726544004085055

Epoch: 5| Step: 1
Training loss: 0.10876996148315982
Validation loss: 2.078465907097834

Epoch: 5| Step: 2
Training loss: 0.06827530800675018
Validation loss: 2.06151601464066

Epoch: 5| Step: 3
Training loss: 0.10413976759103322
Validation loss: 2.049487523219036

Epoch: 5| Step: 4
Training loss: 0.05860940008968873
Validation loss: 2.086340087076302

Epoch: 5| Step: 5
Training loss: 0.04902744618778136
Validation loss: 2.0526749094623344

Epoch: 5| Step: 6
Training loss: 0.09015756202814092
Validation loss: 2.056783602560615

Epoch: 5| Step: 7
Training loss: 0.0614247211310236
Validation loss: 2.0830219056538675

Epoch: 5| Step: 8
Training loss: 0.07115516760660012
Validation loss: 2.0549879936356747

Epoch: 5| Step: 9
Training loss: 0.10448874262897884
Validation loss: 2.05415780407635

Epoch: 5| Step: 10
Training loss: 0.12015679722054909
Validation loss: 2.041692417385032

Epoch: 764| Step: 0
Training loss: 0.05989585514517401
Validation loss: 2.038733298667734

Epoch: 5| Step: 1
Training loss: 0.08235373573088343
Validation loss: 2.0624126019299034

Epoch: 5| Step: 2
Training loss: 0.08124518987740768
Validation loss: 2.0623040732369478

Epoch: 5| Step: 3
Training loss: 0.08311486353593706
Validation loss: 2.0697739844760585

Epoch: 5| Step: 4
Training loss: 0.07973007415895124
Validation loss: 2.0624402063328042

Epoch: 5| Step: 5
Training loss: 0.0875450493017788
Validation loss: 2.029576066036352

Epoch: 5| Step: 6
Training loss: 0.0934075319113497
Validation loss: 2.037037770585125

Epoch: 5| Step: 7
Training loss: 0.10268591401401393
Validation loss: 2.062394341739087

Epoch: 5| Step: 8
Training loss: 0.10228251652846897
Validation loss: 2.047423795706124

Epoch: 5| Step: 9
Training loss: 0.07997707061628526
Validation loss: 2.053855598760757

Epoch: 5| Step: 10
Training loss: 0.07701710495675143
Validation loss: 2.0658052174681827

Epoch: 765| Step: 0
Training loss: 0.11011877656908503
Validation loss: 2.082160011001911

Epoch: 5| Step: 1
Training loss: 0.0666364438622452
Validation loss: 2.051918888223202

Epoch: 5| Step: 2
Training loss: 0.04653276741488315
Validation loss: 2.06405724051589

Epoch: 5| Step: 3
Training loss: 0.08845844167442772
Validation loss: 2.0392843070893507

Epoch: 5| Step: 4
Training loss: 0.08568264277469363
Validation loss: 2.0813937426439546

Epoch: 5| Step: 5
Training loss: 0.09693521869903092
Validation loss: 2.075844004399145

Epoch: 5| Step: 6
Training loss: 0.08472463752895434
Validation loss: 2.0865861493222475

Epoch: 5| Step: 7
Training loss: 0.06821200288974522
Validation loss: 2.0861004261154132

Epoch: 5| Step: 8
Training loss: 0.08811450101827753
Validation loss: 2.105702866416114

Epoch: 5| Step: 9
Training loss: 0.09037186028077326
Validation loss: 2.0889261474014207

Epoch: 5| Step: 10
Training loss: 0.06987304247650197
Validation loss: 2.0818414258154507

Epoch: 766| Step: 0
Training loss: 0.07725670918805072
Validation loss: 2.1110713164668637

Epoch: 5| Step: 1
Training loss: 0.09329365887366886
Validation loss: 2.1017300502806036

Epoch: 5| Step: 2
Training loss: 0.0699006509269475
Validation loss: 2.078878580189875

Epoch: 5| Step: 3
Training loss: 0.06912254350300075
Validation loss: 2.1166790439197647

Epoch: 5| Step: 4
Training loss: 0.08132876168733794
Validation loss: 2.0873396525683487

Epoch: 5| Step: 5
Training loss: 0.11739829496066706
Validation loss: 2.0902326116085073

Epoch: 5| Step: 6
Training loss: 0.08465509613809584
Validation loss: 2.071441596349048

Epoch: 5| Step: 7
Training loss: 0.07119999508008847
Validation loss: 2.061603462533425

Epoch: 5| Step: 8
Training loss: 0.08442592430711551
Validation loss: 2.0788960383081263

Epoch: 5| Step: 9
Training loss: 0.057763441396529155
Validation loss: 2.0730785983322395

Epoch: 5| Step: 10
Training loss: 0.07903100033641823
Validation loss: 2.077432453825328

Epoch: 767| Step: 0
Training loss: 0.08717511918495598
Validation loss: 2.082414622215933

Epoch: 5| Step: 1
Training loss: 0.07431816357152748
Validation loss: 2.0641989784398205

Epoch: 5| Step: 2
Training loss: 0.08463894457677966
Validation loss: 2.0430564007479046

Epoch: 5| Step: 3
Training loss: 0.08136386961634705
Validation loss: 2.0727409386834013

Epoch: 5| Step: 4
Training loss: 0.10609847617261778
Validation loss: 2.060976907296019

Epoch: 5| Step: 5
Training loss: 0.0676010509146701
Validation loss: 2.070120191320125

Epoch: 5| Step: 6
Training loss: 0.07881177992684643
Validation loss: 2.081113403709712

Epoch: 5| Step: 7
Training loss: 0.05682707386444942
Validation loss: 2.0870578607361128

Epoch: 5| Step: 8
Training loss: 0.07808354589245227
Validation loss: 2.0754646755526345

Epoch: 5| Step: 9
Training loss: 0.09706896142000151
Validation loss: 2.0541566527728112

Epoch: 5| Step: 10
Training loss: 0.11468161942713911
Validation loss: 2.0826714696932105

Epoch: 768| Step: 0
Training loss: 0.07653717332505783
Validation loss: 2.063572903792725

Epoch: 5| Step: 1
Training loss: 0.09813006849623003
Validation loss: 2.1022447255695957

Epoch: 5| Step: 2
Training loss: 0.0992832314101736
Validation loss: 2.0648932767812322

Epoch: 5| Step: 3
Training loss: 0.055059449600923946
Validation loss: 2.093434651208764

Epoch: 5| Step: 4
Training loss: 0.0868003481720265
Validation loss: 2.0851768937238155

Epoch: 5| Step: 5
Training loss: 0.10325592230381204
Validation loss: 2.059980503632768

Epoch: 5| Step: 6
Training loss: 0.09159715210763145
Validation loss: 2.0720883387814686

Epoch: 5| Step: 7
Training loss: 0.047641414342091896
Validation loss: 2.0720566593790823

Epoch: 5| Step: 8
Training loss: 0.08195124709920636
Validation loss: 2.0933142930955797

Epoch: 5| Step: 9
Training loss: 0.09249656923800868
Validation loss: 2.0593800891946104

Epoch: 5| Step: 10
Training loss: 0.09238480934743176
Validation loss: 2.087779718528823

Epoch: 769| Step: 0
Training loss: 0.08267888928218849
Validation loss: 2.074934940032296

Epoch: 5| Step: 1
Training loss: 0.06414099818061872
Validation loss: 2.0567627938984705

Epoch: 5| Step: 2
Training loss: 0.10679038138275986
Validation loss: 2.0924839090931298

Epoch: 5| Step: 3
Training loss: 0.08547346860929231
Validation loss: 2.082586263613534

Epoch: 5| Step: 4
Training loss: 0.06695770148991198
Validation loss: 2.0992971173495647

Epoch: 5| Step: 5
Training loss: 0.06314604983640859
Validation loss: 2.075538992038394

Epoch: 5| Step: 6
Training loss: 0.05430498842985508
Validation loss: 2.0519003575449637

Epoch: 5| Step: 7
Training loss: 0.12418441012900928
Validation loss: 2.0790983997188497

Epoch: 5| Step: 8
Training loss: 0.07547443467700357
Validation loss: 2.0635762642954045

Epoch: 5| Step: 9
Training loss: 0.07593543084194426
Validation loss: 2.072533181255379

Epoch: 5| Step: 10
Training loss: 0.0832831025230677
Validation loss: 2.061926945154097

Epoch: 770| Step: 0
Training loss: 0.1263514492723376
Validation loss: 2.0994387309238123

Epoch: 5| Step: 1
Training loss: 0.07308247637033333
Validation loss: 2.0844820174219123

Epoch: 5| Step: 2
Training loss: 0.0647840457691131
Validation loss: 2.107133049015815

Epoch: 5| Step: 3
Training loss: 0.08730812695361254
Validation loss: 2.0893307463800084

Epoch: 5| Step: 4
Training loss: 0.09517043618689869
Validation loss: 2.0703642829584123

Epoch: 5| Step: 5
Training loss: 0.08324071243336104
Validation loss: 2.0979237055495195

Epoch: 5| Step: 6
Training loss: 0.07847627405689904
Validation loss: 2.0884343077924736

Epoch: 5| Step: 7
Training loss: 0.09015406010908487
Validation loss: 2.0761072881944553

Epoch: 5| Step: 8
Training loss: 0.12001751043668571
Validation loss: 2.1104470309347447

Epoch: 5| Step: 9
Training loss: 0.06689194862225233
Validation loss: 2.1233677479568134

Epoch: 5| Step: 10
Training loss: 0.10019165835493288
Validation loss: 2.082955485709072

Epoch: 771| Step: 0
Training loss: 0.08893036954300353
Validation loss: 2.081292178355948

Epoch: 5| Step: 1
Training loss: 0.06508423937367044
Validation loss: 2.0683276477792525

Epoch: 5| Step: 2
Training loss: 0.0881540668307483
Validation loss: 2.0670775636520764

Epoch: 5| Step: 3
Training loss: 0.09135843640349796
Validation loss: 2.0731252906540387

Epoch: 5| Step: 4
Training loss: 0.060312880307317865
Validation loss: 2.0553237813840894

Epoch: 5| Step: 5
Training loss: 0.10723850465154529
Validation loss: 2.1055916836621886

Epoch: 5| Step: 6
Training loss: 0.07792635936848646
Validation loss: 2.0602339554738

Epoch: 5| Step: 7
Training loss: 0.10945074404891193
Validation loss: 2.05196420204968

Epoch: 5| Step: 8
Training loss: 0.07347228147273317
Validation loss: 2.0736431805401514

Epoch: 5| Step: 9
Training loss: 0.1121384634434418
Validation loss: 2.0424778900212965

Epoch: 5| Step: 10
Training loss: 0.09443516005091875
Validation loss: 2.041061566807221

Epoch: 772| Step: 0
Training loss: 0.14044011731206563
Validation loss: 2.0616372878058113

Epoch: 5| Step: 1
Training loss: 0.13500785481375183
Validation loss: 2.067131888500421

Epoch: 5| Step: 2
Training loss: 0.05039594579668403
Validation loss: 2.0419517261165194

Epoch: 5| Step: 3
Training loss: 0.09349919586741075
Validation loss: 2.073069742773258

Epoch: 5| Step: 4
Training loss: 0.08845578848719017
Validation loss: 2.064750760839759

Epoch: 5| Step: 5
Training loss: 0.08958088213964098
Validation loss: 2.0847428035227296

Epoch: 5| Step: 6
Training loss: 0.0974852829686207
Validation loss: 2.0916362654182703

Epoch: 5| Step: 7
Training loss: 0.09928334397565321
Validation loss: 2.0809612523345367

Epoch: 5| Step: 8
Training loss: 0.08426861292324929
Validation loss: 2.0557189969920477

Epoch: 5| Step: 9
Training loss: 0.08337447863073347
Validation loss: 2.079223311736842

Epoch: 5| Step: 10
Training loss: 0.11270120942473619
Validation loss: 2.087824175758665

Epoch: 773| Step: 0
Training loss: 0.07480336193075561
Validation loss: 2.072072807212312

Epoch: 5| Step: 1
Training loss: 0.0680144257920643
Validation loss: 2.0848161978031707

Epoch: 5| Step: 2
Training loss: 0.054789035918140806
Validation loss: 2.1060947473337914

Epoch: 5| Step: 3
Training loss: 0.059888929594611465
Validation loss: 2.096817628388509

Epoch: 5| Step: 4
Training loss: 0.09873720347963261
Validation loss: 2.088836460903596

Epoch: 5| Step: 5
Training loss: 0.11119106706774916
Validation loss: 2.0990220323861077

Epoch: 5| Step: 6
Training loss: 0.10418421825916734
Validation loss: 2.080774901666981

Epoch: 5| Step: 7
Training loss: 0.09532549370856182
Validation loss: 2.0915729001461414

Epoch: 5| Step: 8
Training loss: 0.09024283154812354
Validation loss: 2.0804071027877415

Epoch: 5| Step: 9
Training loss: 0.09319488767178029
Validation loss: 2.0987707300688094

Epoch: 5| Step: 10
Training loss: 0.10197892922113043
Validation loss: 2.0758186474884606

Epoch: 774| Step: 0
Training loss: 0.08480062926609724
Validation loss: 2.091392383536136

Epoch: 5| Step: 1
Training loss: 0.09280413069703716
Validation loss: 2.0724029877450016

Epoch: 5| Step: 2
Training loss: 0.05321955234331006
Validation loss: 2.067264151996583

Epoch: 5| Step: 3
Training loss: 0.08165411312987661
Validation loss: 2.076323558729716

Epoch: 5| Step: 4
Training loss: 0.1107205871089925
Validation loss: 2.0334887060753246

Epoch: 5| Step: 5
Training loss: 0.10091555392250089
Validation loss: 2.0995547793426157

Epoch: 5| Step: 6
Training loss: 0.1233194639414175
Validation loss: 2.0623763759898903

Epoch: 5| Step: 7
Training loss: 0.08640920081282294
Validation loss: 2.1112069388126327

Epoch: 5| Step: 8
Training loss: 0.06319176534081537
Validation loss: 2.0832881672382966

Epoch: 5| Step: 9
Training loss: 0.07083545361996561
Validation loss: 2.092464072332571

Epoch: 5| Step: 10
Training loss: 0.08207623065960633
Validation loss: 2.0806642880283612

Epoch: 775| Step: 0
Training loss: 0.09193707980015185
Validation loss: 2.0665742340746935

Epoch: 5| Step: 1
Training loss: 0.07804528282019245
Validation loss: 2.099920711495212

Epoch: 5| Step: 2
Training loss: 0.06521286909730328
Validation loss: 2.1039851071849744

Epoch: 5| Step: 3
Training loss: 0.06714847493129039
Validation loss: 2.083287836829102

Epoch: 5| Step: 4
Training loss: 0.1077867812426568
Validation loss: 2.0973433929258802

Epoch: 5| Step: 5
Training loss: 0.08510965452696319
Validation loss: 2.0694195348380116

Epoch: 5| Step: 6
Training loss: 0.0761439871477243
Validation loss: 2.1028944446106226

Epoch: 5| Step: 7
Training loss: 0.1028253373795782
Validation loss: 2.0723521052854825

Epoch: 5| Step: 8
Training loss: 0.08948117153814145
Validation loss: 2.0997303325422347

Epoch: 5| Step: 9
Training loss: 0.06822265167411048
Validation loss: 2.1044661457940266

Epoch: 5| Step: 10
Training loss: 0.08173161801942828
Validation loss: 2.0886545914595747

Epoch: 776| Step: 0
Training loss: 0.10997652786881945
Validation loss: 2.0939969284677082

Epoch: 5| Step: 1
Training loss: 0.10072172129346714
Validation loss: 2.1066712340029836

Epoch: 5| Step: 2
Training loss: 0.09948403288721162
Validation loss: 2.086061367136229

Epoch: 5| Step: 3
Training loss: 0.07777057061403064
Validation loss: 2.0895413013992323

Epoch: 5| Step: 4
Training loss: 0.09420552944627043
Validation loss: 2.0732719464036777

Epoch: 5| Step: 5
Training loss: 0.05502221375840086
Validation loss: 2.0908760723604156

Epoch: 5| Step: 6
Training loss: 0.06270119574088609
Validation loss: 2.082698731111244

Epoch: 5| Step: 7
Training loss: 0.0807652822075062
Validation loss: 2.0857723782623196

Epoch: 5| Step: 8
Training loss: 0.05956556543603209
Validation loss: 2.064678514849745

Epoch: 5| Step: 9
Training loss: 0.05271756381055411
Validation loss: 2.0443344468945996

Epoch: 5| Step: 10
Training loss: 0.07496285114559123
Validation loss: 2.077426095564144

Epoch: 777| Step: 0
Training loss: 0.09594556695341995
Validation loss: 2.075433097095907

Epoch: 5| Step: 1
Training loss: 0.08786027967271154
Validation loss: 2.0696922842155216

Epoch: 5| Step: 2
Training loss: 0.05671863486604065
Validation loss: 2.071380266824271

Epoch: 5| Step: 3
Training loss: 0.06472814290955273
Validation loss: 2.049964403803347

Epoch: 5| Step: 4
Training loss: 0.08054345121793727
Validation loss: 2.0537983008087926

Epoch: 5| Step: 5
Training loss: 0.09972430592339859
Validation loss: 2.042432903892183

Epoch: 5| Step: 6
Training loss: 0.05942950256888555
Validation loss: 2.065670590642779

Epoch: 5| Step: 7
Training loss: 0.08980941634734535
Validation loss: 2.078377811864033

Epoch: 5| Step: 8
Training loss: 0.12099669012210604
Validation loss: 2.069269671078359

Epoch: 5| Step: 9
Training loss: 0.056121187273862165
Validation loss: 2.0907723649301895

Epoch: 5| Step: 10
Training loss: 0.10756530722756824
Validation loss: 2.0729821571429996

Epoch: 778| Step: 0
Training loss: 0.06113882416121034
Validation loss: 2.0679788517646447

Epoch: 5| Step: 1
Training loss: 0.1007420245432192
Validation loss: 2.076875709441066

Epoch: 5| Step: 2
Training loss: 0.09389257021168304
Validation loss: 2.0503799112957646

Epoch: 5| Step: 3
Training loss: 0.06419073505476676
Validation loss: 2.0760497788711096

Epoch: 5| Step: 4
Training loss: 0.09043831629605503
Validation loss: 2.096508209453093

Epoch: 5| Step: 5
Training loss: 0.04873070057448781
Validation loss: 2.042541450436052

Epoch: 5| Step: 6
Training loss: 0.07729013323333804
Validation loss: 2.09316875071119

Epoch: 5| Step: 7
Training loss: 0.07871781383039507
Validation loss: 2.0623003880774444

Epoch: 5| Step: 8
Training loss: 0.1284921743569559
Validation loss: 2.0337973512374448

Epoch: 5| Step: 9
Training loss: 0.08223927891094902
Validation loss: 2.087857915125805

Epoch: 5| Step: 10
Training loss: 0.12757433247345798
Validation loss: 2.080314565251419

Epoch: 779| Step: 0
Training loss: 0.11602358983375145
Validation loss: 2.0560766800409773

Epoch: 5| Step: 1
Training loss: 0.07375376693250163
Validation loss: 2.067226716373998

Epoch: 5| Step: 2
Training loss: 0.08353689936651415
Validation loss: 2.0602315140685925

Epoch: 5| Step: 3
Training loss: 0.07674121519515698
Validation loss: 2.063647914376549

Epoch: 5| Step: 4
Training loss: 0.09325889263564557
Validation loss: 2.0712165324546077

Epoch: 5| Step: 5
Training loss: 0.10735816366689027
Validation loss: 2.0618833376349133

Epoch: 5| Step: 6
Training loss: 0.08359136221496882
Validation loss: 2.079541421503093

Epoch: 5| Step: 7
Training loss: 0.11087127273567164
Validation loss: 2.0738134259849477

Epoch: 5| Step: 8
Training loss: 0.06307249575573448
Validation loss: 2.083377446558716

Epoch: 5| Step: 9
Training loss: 0.04845043017481341
Validation loss: 2.0699434229644096

Epoch: 5| Step: 10
Training loss: 0.06505334141789591
Validation loss: 2.0552153629637453

Epoch: 780| Step: 0
Training loss: 0.08558732180518348
Validation loss: 2.0792678156715163

Epoch: 5| Step: 1
Training loss: 0.08404080579856898
Validation loss: 2.068684346014437

Epoch: 5| Step: 2
Training loss: 0.09113667873548299
Validation loss: 2.0794274129176444

Epoch: 5| Step: 3
Training loss: 0.09544110923492613
Validation loss: 2.076695842920493

Epoch: 5| Step: 4
Training loss: 0.09761372594050095
Validation loss: 2.0803952161968033

Epoch: 5| Step: 5
Training loss: 0.10554509578591607
Validation loss: 2.065918680417972

Epoch: 5| Step: 6
Training loss: 0.07969835116331087
Validation loss: 2.0441176265703116

Epoch: 5| Step: 7
Training loss: 0.11357270762126238
Validation loss: 2.0615204933551854

Epoch: 5| Step: 8
Training loss: 0.0734956203174777
Validation loss: 2.08021698928759

Epoch: 5| Step: 9
Training loss: 0.09832937474671218
Validation loss: 2.061754485349401

Epoch: 5| Step: 10
Training loss: 0.0776793764590217
Validation loss: 2.043313275192282

Epoch: 781| Step: 0
Training loss: 0.08813670201168908
Validation loss: 2.0995279077405686

Epoch: 5| Step: 1
Training loss: 0.05468001058929694
Validation loss: 2.037439359012515

Epoch: 5| Step: 2
Training loss: 0.08701684318035015
Validation loss: 2.0515145252184404

Epoch: 5| Step: 3
Training loss: 0.07679306341939954
Validation loss: 2.029612574902366

Epoch: 5| Step: 4
Training loss: 0.06436163014625924
Validation loss: 2.051418750782934

Epoch: 5| Step: 5
Training loss: 0.09342917043978406
Validation loss: 2.0605307332638976

Epoch: 5| Step: 6
Training loss: 0.08706887526799896
Validation loss: 2.0260924168891594

Epoch: 5| Step: 7
Training loss: 0.0938036238771364
Validation loss: 2.0623840176365813

Epoch: 5| Step: 8
Training loss: 0.08969921427662236
Validation loss: 2.059122152913524

Epoch: 5| Step: 9
Training loss: 0.07811470559960934
Validation loss: 2.0437685117660584

Epoch: 5| Step: 10
Training loss: 0.05916979080641503
Validation loss: 2.0439487642230127

Epoch: 782| Step: 0
Training loss: 0.090444278569773
Validation loss: 2.0655333318698204

Epoch: 5| Step: 1
Training loss: 0.09067339961249063
Validation loss: 2.080287719932508

Epoch: 5| Step: 2
Training loss: 0.06288381163492571
Validation loss: 2.080214963235847

Epoch: 5| Step: 3
Training loss: 0.09009784033603746
Validation loss: 2.07080897985445

Epoch: 5| Step: 4
Training loss: 0.05719964220952752
Validation loss: 2.088245288473298

Epoch: 5| Step: 5
Training loss: 0.05560434006984869
Validation loss: 2.087838051296731

Epoch: 5| Step: 6
Training loss: 0.09011547834398517
Validation loss: 2.085306448378648

Epoch: 5| Step: 7
Training loss: 0.09509531000595853
Validation loss: 2.127877116023927

Epoch: 5| Step: 8
Training loss: 0.08287950304058059
Validation loss: 2.0771087134036446

Epoch: 5| Step: 9
Training loss: 0.07790508909810348
Validation loss: 2.075691850878124

Epoch: 5| Step: 10
Training loss: 0.07656074869819303
Validation loss: 2.066902377591278

Epoch: 783| Step: 0
Training loss: 0.07548138153897488
Validation loss: 2.0549040973847377

Epoch: 5| Step: 1
Training loss: 0.05641429586828459
Validation loss: 2.065247827340925

Epoch: 5| Step: 2
Training loss: 0.08468674943123304
Validation loss: 2.0563273865667657

Epoch: 5| Step: 3
Training loss: 0.06596238441308061
Validation loss: 2.0827781844092637

Epoch: 5| Step: 4
Training loss: 0.07328963332426122
Validation loss: 2.0661648829687627

Epoch: 5| Step: 5
Training loss: 0.07924374705629113
Validation loss: 2.068817297139508

Epoch: 5| Step: 6
Training loss: 0.09103001206600965
Validation loss: 2.0192625789337195

Epoch: 5| Step: 7
Training loss: 0.1057123355983057
Validation loss: 2.0677320239750823

Epoch: 5| Step: 8
Training loss: 0.07272740335784636
Validation loss: 2.0538375770430135

Epoch: 5| Step: 9
Training loss: 0.05201228133243644
Validation loss: 2.0221866008787424

Epoch: 5| Step: 10
Training loss: 0.09099888934221381
Validation loss: 2.0551255169943694

Epoch: 784| Step: 0
Training loss: 0.054009494268194846
Validation loss: 2.0798537842846008

Epoch: 5| Step: 1
Training loss: 0.0953922819185812
Validation loss: 2.07034343279226

Epoch: 5| Step: 2
Training loss: 0.07715976909520432
Validation loss: 2.0868152097460135

Epoch: 5| Step: 3
Training loss: 0.06459564289074869
Validation loss: 2.082830049164373

Epoch: 5| Step: 4
Training loss: 0.09332181582032398
Validation loss: 2.0537809501491187

Epoch: 5| Step: 5
Training loss: 0.06557774517021131
Validation loss: 2.071416785796005

Epoch: 5| Step: 6
Training loss: 0.07821674324575048
Validation loss: 2.0665467512621456

Epoch: 5| Step: 7
Training loss: 0.07996191920547635
Validation loss: 2.07608376392242

Epoch: 5| Step: 8
Training loss: 0.06701819273791605
Validation loss: 2.0809234422073857

Epoch: 5| Step: 9
Training loss: 0.08456232570614725
Validation loss: 2.101896748675561

Epoch: 5| Step: 10
Training loss: 0.13982429635474306
Validation loss: 2.0842317996193405

Epoch: 785| Step: 0
Training loss: 0.0797938353815038
Validation loss: 2.0766210203234152

Epoch: 5| Step: 1
Training loss: 0.05793616127501395
Validation loss: 2.0809249575331155

Epoch: 5| Step: 2
Training loss: 0.07267003377276866
Validation loss: 2.0905081602777082

Epoch: 5| Step: 3
Training loss: 0.06501925971724194
Validation loss: 2.039683309905589

Epoch: 5| Step: 4
Training loss: 0.07791903585524726
Validation loss: 2.0677485700888036

Epoch: 5| Step: 5
Training loss: 0.09251465593522103
Validation loss: 2.0966510122036834

Epoch: 5| Step: 6
Training loss: 0.0890272292350276
Validation loss: 2.0668251451521527

Epoch: 5| Step: 7
Training loss: 0.07082643044310957
Validation loss: 2.047869737983509

Epoch: 5| Step: 8
Training loss: 0.0833975952695535
Validation loss: 2.0854721899192175

Epoch: 5| Step: 9
Training loss: 0.06248769974370919
Validation loss: 2.0963708064563393

Epoch: 5| Step: 10
Training loss: 0.06755062988225466
Validation loss: 2.067577513419582

Epoch: 786| Step: 0
Training loss: 0.0741291571994459
Validation loss: 2.0667038842821883

Epoch: 5| Step: 1
Training loss: 0.07771117760427598
Validation loss: 2.083204353605833

Epoch: 5| Step: 2
Training loss: 0.06271563895667921
Validation loss: 2.0887515768842966

Epoch: 5| Step: 3
Training loss: 0.06976481892161729
Validation loss: 2.0652107542615625

Epoch: 5| Step: 4
Training loss: 0.10059248338158479
Validation loss: 2.079998147041136

Epoch: 5| Step: 5
Training loss: 0.0730141650620669
Validation loss: 2.0753967093231664

Epoch: 5| Step: 6
Training loss: 0.06321322396371856
Validation loss: 2.11052829414131

Epoch: 5| Step: 7
Training loss: 0.0724294776691273
Validation loss: 2.0791215979594586

Epoch: 5| Step: 8
Training loss: 0.09622096561205211
Validation loss: 2.072472052883303

Epoch: 5| Step: 9
Training loss: 0.09559471938866007
Validation loss: 2.091194545079553

Epoch: 5| Step: 10
Training loss: 0.07531349691447427
Validation loss: 2.0918601887557275

Epoch: 787| Step: 0
Training loss: 0.09705976950881749
Validation loss: 2.0670845696694906

Epoch: 5| Step: 1
Training loss: 0.09482382176136395
Validation loss: 2.0709237247227517

Epoch: 5| Step: 2
Training loss: 0.0580400250642994
Validation loss: 2.0780096251042663

Epoch: 5| Step: 3
Training loss: 0.09499434346060653
Validation loss: 2.0820594795996157

Epoch: 5| Step: 4
Training loss: 0.1098636627190643
Validation loss: 2.063043505968343

Epoch: 5| Step: 5
Training loss: 0.12105647020852191
Validation loss: 2.055891613623526

Epoch: 5| Step: 6
Training loss: 0.060884641071880276
Validation loss: 2.0606542160705676

Epoch: 5| Step: 7
Training loss: 0.08047477250570675
Validation loss: 2.0641966081688277

Epoch: 5| Step: 8
Training loss: 0.058557334153621014
Validation loss: 2.090929609083571

Epoch: 5| Step: 9
Training loss: 0.09213571710503421
Validation loss: 2.090355852015125

Epoch: 5| Step: 10
Training loss: 0.04953999868530151
Validation loss: 2.0716218370797757

Epoch: 788| Step: 0
Training loss: 0.08137416213145526
Validation loss: 2.0658019598706523

Epoch: 5| Step: 1
Training loss: 0.06652835530971342
Validation loss: 2.092669416154248

Epoch: 5| Step: 2
Training loss: 0.04744903430885601
Validation loss: 2.086126271272024

Epoch: 5| Step: 3
Training loss: 0.07106499535826975
Validation loss: 2.0645714180891646

Epoch: 5| Step: 4
Training loss: 0.09250578166316568
Validation loss: 2.0704472026471277

Epoch: 5| Step: 5
Training loss: 0.10068278603733911
Validation loss: 2.0686400218069405

Epoch: 5| Step: 6
Training loss: 0.07825166447761302
Validation loss: 2.035254758179255

Epoch: 5| Step: 7
Training loss: 0.07156374347743341
Validation loss: 2.0936526748990185

Epoch: 5| Step: 8
Training loss: 0.05043913609422608
Validation loss: 2.0608976235808254

Epoch: 5| Step: 9
Training loss: 0.07530093206604355
Validation loss: 2.074942115658803

Epoch: 5| Step: 10
Training loss: 0.08593387487741713
Validation loss: 2.0434639470034868

Epoch: 789| Step: 0
Training loss: 0.11318612626593892
Validation loss: 2.0766745424665287

Epoch: 5| Step: 1
Training loss: 0.06361671161508754
Validation loss: 2.052439994127212

Epoch: 5| Step: 2
Training loss: 0.06122926934450128
Validation loss: 2.0467838773379787

Epoch: 5| Step: 3
Training loss: 0.07437954600249208
Validation loss: 2.059033844504076

Epoch: 5| Step: 4
Training loss: 0.08655059820855587
Validation loss: 2.0446814812307688

Epoch: 5| Step: 5
Training loss: 0.058801067669509904
Validation loss: 2.0641535329716563

Epoch: 5| Step: 6
Training loss: 0.05915758330731309
Validation loss: 2.0290240053070376

Epoch: 5| Step: 7
Training loss: 0.0494803075073294
Validation loss: 2.064572805101308

Epoch: 5| Step: 8
Training loss: 0.0774340473349006
Validation loss: 2.076410997859529

Epoch: 5| Step: 9
Training loss: 0.12085040313768282
Validation loss: 2.0718775858680676

Epoch: 5| Step: 10
Training loss: 0.04732963507400878
Validation loss: 2.0482366948911808

Epoch: 790| Step: 0
Training loss: 0.07595485865123684
Validation loss: 2.0804617437568527

Epoch: 5| Step: 1
Training loss: 0.05730100938451353
Validation loss: 2.067346549646237

Epoch: 5| Step: 2
Training loss: 0.058593950668627125
Validation loss: 2.067907620145278

Epoch: 5| Step: 3
Training loss: 0.06603657683429986
Validation loss: 2.0775874705079973

Epoch: 5| Step: 4
Training loss: 0.1303337915325383
Validation loss: 2.0446521813784537

Epoch: 5| Step: 5
Training loss: 0.08229745518067229
Validation loss: 2.056233151952773

Epoch: 5| Step: 6
Training loss: 0.08292578683538938
Validation loss: 2.070539598011185

Epoch: 5| Step: 7
Training loss: 0.05946765911549546
Validation loss: 2.058849895916325

Epoch: 5| Step: 8
Training loss: 0.05931057744658677
Validation loss: 2.0574325378296545

Epoch: 5| Step: 9
Training loss: 0.08410878724933332
Validation loss: 2.0732687889494135

Epoch: 5| Step: 10
Training loss: 0.06959458584705329
Validation loss: 2.0890061185774647

Epoch: 791| Step: 0
Training loss: 0.10069075465521485
Validation loss: 2.053823346040293

Epoch: 5| Step: 1
Training loss: 0.07919698422780437
Validation loss: 2.0718517323319023

Epoch: 5| Step: 2
Training loss: 0.07253167755731496
Validation loss: 2.088266107523263

Epoch: 5| Step: 3
Training loss: 0.08081703217635687
Validation loss: 2.0605705038649282

Epoch: 5| Step: 4
Training loss: 0.09311306175253752
Validation loss: 2.0795003420246396

Epoch: 5| Step: 5
Training loss: 0.07767815353918497
Validation loss: 2.0815743664586295

Epoch: 5| Step: 6
Training loss: 0.12153433434836199
Validation loss: 2.069813206825217

Epoch: 5| Step: 7
Training loss: 0.10027634558121998
Validation loss: 2.0708461216948306

Epoch: 5| Step: 8
Training loss: 0.07224872107883577
Validation loss: 2.0675383649032324

Epoch: 5| Step: 9
Training loss: 0.10813523893167475
Validation loss: 2.0910727045343593

Epoch: 5| Step: 10
Training loss: 0.06757114531464374
Validation loss: 2.0684312095292543

Epoch: 792| Step: 0
Training loss: 0.0596726683375114
Validation loss: 2.0746095078895497

Epoch: 5| Step: 1
Training loss: 0.06911428038536221
Validation loss: 2.087346496007646

Epoch: 5| Step: 2
Training loss: 0.08348515366386218
Validation loss: 2.070198445691153

Epoch: 5| Step: 3
Training loss: 0.07324857683923043
Validation loss: 2.076384891023225

Epoch: 5| Step: 4
Training loss: 0.08742154832119282
Validation loss: 2.051527358286322

Epoch: 5| Step: 5
Training loss: 0.084784541128933
Validation loss: 2.0976248724080078

Epoch: 5| Step: 6
Training loss: 0.05428586083129435
Validation loss: 2.0369038149802394

Epoch: 5| Step: 7
Training loss: 0.06126653302766787
Validation loss: 2.0659720901825174

Epoch: 5| Step: 8
Training loss: 0.10105283944143596
Validation loss: 2.046652972138916

Epoch: 5| Step: 9
Training loss: 0.059147865092861344
Validation loss: 2.0269059306684687

Epoch: 5| Step: 10
Training loss: 0.07002417071519434
Validation loss: 2.0239072979561383

Epoch: 793| Step: 0
Training loss: 0.10406891488015288
Validation loss: 2.0525921089434847

Epoch: 5| Step: 1
Training loss: 0.08706889933487126
Validation loss: 2.0571174241455763

Epoch: 5| Step: 2
Training loss: 0.07344124130093341
Validation loss: 2.0325388950165646

Epoch: 5| Step: 3
Training loss: 0.07215867634415578
Validation loss: 2.049408324474634

Epoch: 5| Step: 4
Training loss: 0.08726886061097432
Validation loss: 2.0650184931273734

Epoch: 5| Step: 5
Training loss: 0.10012821568398385
Validation loss: 2.0515451291317506

Epoch: 5| Step: 6
Training loss: 0.06593699004215628
Validation loss: 2.033176832801491

Epoch: 5| Step: 7
Training loss: 0.09304756021767806
Validation loss: 2.0294677980747995

Epoch: 5| Step: 8
Training loss: 0.07147731159833778
Validation loss: 2.032314298741768

Epoch: 5| Step: 9
Training loss: 0.07271962350182187
Validation loss: 2.036688401668642

Epoch: 5| Step: 10
Training loss: 0.06507559944280487
Validation loss: 2.066379552141801

Epoch: 794| Step: 0
Training loss: 0.06381227775146459
Validation loss: 2.0177205378797067

Epoch: 5| Step: 1
Training loss: 0.07074771734159398
Validation loss: 2.068693416148657

Epoch: 5| Step: 2
Training loss: 0.08883900772001255
Validation loss: 2.040199109787493

Epoch: 5| Step: 3
Training loss: 0.06023409253362188
Validation loss: 2.037867410422017

Epoch: 5| Step: 4
Training loss: 0.08089818840688451
Validation loss: 2.096642197210155

Epoch: 5| Step: 5
Training loss: 0.08657467672537307
Validation loss: 2.050507274790826

Epoch: 5| Step: 6
Training loss: 0.08733110081637335
Validation loss: 2.059826944337851

Epoch: 5| Step: 7
Training loss: 0.0876027106843733
Validation loss: 2.0497720733738345

Epoch: 5| Step: 8
Training loss: 0.07732272078991928
Validation loss: 2.0679863493608814

Epoch: 5| Step: 9
Training loss: 0.0954527060158745
Validation loss: 2.0877452313062896

Epoch: 5| Step: 10
Training loss: 0.07305079885643417
Validation loss: 2.0679603704705345

Epoch: 795| Step: 0
Training loss: 0.08341418816625867
Validation loss: 2.0596269899563713

Epoch: 5| Step: 1
Training loss: 0.08633224360967748
Validation loss: 2.056877352666887

Epoch: 5| Step: 2
Training loss: 0.06691342107996522
Validation loss: 2.0806551437849126

Epoch: 5| Step: 3
Training loss: 0.0811590103596927
Validation loss: 2.0719075728622873

Epoch: 5| Step: 4
Training loss: 0.06563613121679217
Validation loss: 2.0821284639077273

Epoch: 5| Step: 5
Training loss: 0.07567048113041527
Validation loss: 2.0389816129208524

Epoch: 5| Step: 6
Training loss: 0.09412062420622035
Validation loss: 2.083176151827072

Epoch: 5| Step: 7
Training loss: 0.09866523681837079
Validation loss: 2.063042540429209

Epoch: 5| Step: 8
Training loss: 0.07399093019836835
Validation loss: 2.0666001522377284

Epoch: 5| Step: 9
Training loss: 0.10962903800071576
Validation loss: 2.0618438758459647

Epoch: 5| Step: 10
Training loss: 0.06034098890572074
Validation loss: 2.078225188207646

Epoch: 796| Step: 0
Training loss: 0.052954033059708576
Validation loss: 2.063780735928073

Epoch: 5| Step: 1
Training loss: 0.061530124210106056
Validation loss: 2.0989423261800693

Epoch: 5| Step: 2
Training loss: 0.07815154042042965
Validation loss: 2.094573655874807

Epoch: 5| Step: 3
Training loss: 0.07106285262209083
Validation loss: 2.105326315815087

Epoch: 5| Step: 4
Training loss: 0.05410758855978752
Validation loss: 2.0855549708175536

Epoch: 5| Step: 5
Training loss: 0.11734171098596022
Validation loss: 2.1007533685830633

Epoch: 5| Step: 6
Training loss: 0.06772974788256415
Validation loss: 2.096130210751955

Epoch: 5| Step: 7
Training loss: 0.11491134594024809
Validation loss: 2.0804835962924253

Epoch: 5| Step: 8
Training loss: 0.0848698401687513
Validation loss: 2.07790789355623

Epoch: 5| Step: 9
Training loss: 0.06192426071051991
Validation loss: 2.0761589565648286

Epoch: 5| Step: 10
Training loss: 0.07339652331009691
Validation loss: 2.051625971352

Epoch: 797| Step: 0
Training loss: 0.077309964488045
Validation loss: 2.0639196825409343

Epoch: 5| Step: 1
Training loss: 0.0917027731745866
Validation loss: 2.056476180195064

Epoch: 5| Step: 2
Training loss: 0.0879658324281237
Validation loss: 2.069082187498749

Epoch: 5| Step: 3
Training loss: 0.06265896831119068
Validation loss: 2.0591952297158103

Epoch: 5| Step: 4
Training loss: 0.11134821727205191
Validation loss: 2.02156274140415

Epoch: 5| Step: 5
Training loss: 0.07163815724460425
Validation loss: 2.0463478820555783

Epoch: 5| Step: 6
Training loss: 0.05497969538752864
Validation loss: 2.0366055359039406

Epoch: 5| Step: 7
Training loss: 0.08372556096298674
Validation loss: 2.0525476473734723

Epoch: 5| Step: 8
Training loss: 0.09837009832029052
Validation loss: 2.041553344955171

Epoch: 5| Step: 9
Training loss: 0.06123745390185988
Validation loss: 2.044727942486841

Epoch: 5| Step: 10
Training loss: 0.07235857746213584
Validation loss: 2.0592659497647667

Epoch: 798| Step: 0
Training loss: 0.07523746052373537
Validation loss: 2.0628142877183584

Epoch: 5| Step: 1
Training loss: 0.06330037975801886
Validation loss: 2.039032230821237

Epoch: 5| Step: 2
Training loss: 0.07562474454686866
Validation loss: 2.0547332814718136

Epoch: 5| Step: 3
Training loss: 0.0946824865933904
Validation loss: 2.0607488537390024

Epoch: 5| Step: 4
Training loss: 0.056160524021219946
Validation loss: 2.046922142264341

Epoch: 5| Step: 5
Training loss: 0.07953065297702722
Validation loss: 2.0525475724332187

Epoch: 5| Step: 6
Training loss: 0.06844330131642164
Validation loss: 2.082873736313245

Epoch: 5| Step: 7
Training loss: 0.0655533419227639
Validation loss: 2.074334060142403

Epoch: 5| Step: 8
Training loss: 0.08417175979192117
Validation loss: 2.076152802930975

Epoch: 5| Step: 9
Training loss: 0.0931155372298646
Validation loss: 2.0883080500631666

Epoch: 5| Step: 10
Training loss: 0.079483932985067
Validation loss: 2.066814053678775

Epoch: 799| Step: 0
Training loss: 0.06577995829095501
Validation loss: 2.096302514626824

Epoch: 5| Step: 1
Training loss: 0.0498285166450497
Validation loss: 2.0959091440776416

Epoch: 5| Step: 2
Training loss: 0.0663397470026659
Validation loss: 2.084373238170091

Epoch: 5| Step: 3
Training loss: 0.07636272534458782
Validation loss: 2.1107335645815803

Epoch: 5| Step: 4
Training loss: 0.07293242755354096
Validation loss: 2.091577533286525

Epoch: 5| Step: 5
Training loss: 0.09165301108335815
Validation loss: 2.0891158386416544

Epoch: 5| Step: 6
Training loss: 0.0768945960329697
Validation loss: 2.0864589743401543

Epoch: 5| Step: 7
Training loss: 0.05469568651096257
Validation loss: 2.0639401960885544

Epoch: 5| Step: 8
Training loss: 0.07952955806259
Validation loss: 2.079395027002681

Epoch: 5| Step: 9
Training loss: 0.09339749603403248
Validation loss: 2.0800155008592736

Epoch: 5| Step: 10
Training loss: 0.06700129933574105
Validation loss: 2.075392857799801

Epoch: 800| Step: 0
Training loss: 0.07199403595375393
Validation loss: 2.0721660641630715

Epoch: 5| Step: 1
Training loss: 0.04959727791227811
Validation loss: 2.082330533351051

Epoch: 5| Step: 2
Training loss: 0.08426600465047099
Validation loss: 2.0525408877516025

Epoch: 5| Step: 3
Training loss: 0.051154038363683936
Validation loss: 2.0685193057525564

Epoch: 5| Step: 4
Training loss: 0.07300453093446868
Validation loss: 2.088594679985249

Epoch: 5| Step: 5
Training loss: 0.06465528313617708
Validation loss: 2.07192011443662

Epoch: 5| Step: 6
Training loss: 0.06637473270058016
Validation loss: 2.0700035262458027

Epoch: 5| Step: 7
Training loss: 0.10426183962199502
Validation loss: 2.0552494580232397

Epoch: 5| Step: 8
Training loss: 0.08265272091054236
Validation loss: 2.0970631910625923

Epoch: 5| Step: 9
Training loss: 0.07301136520501787
Validation loss: 2.0751195642109015

Epoch: 5| Step: 10
Training loss: 0.08829457912420312
Validation loss: 2.076292234106314

Testing loss: 2.75263495354351
