Epoch: 1| Step: 0
Training loss: 6.9623035670295685
Validation loss: 5.735248681631799

Epoch: 6| Step: 1
Training loss: 5.906249354125295
Validation loss: 5.721580398025969

Epoch: 6| Step: 2
Training loss: 5.368337183258814
Validation loss: 5.708744905797985

Epoch: 6| Step: 3
Training loss: 6.183991024825084
Validation loss: 5.694881153076803

Epoch: 6| Step: 4
Training loss: 5.638996935447676
Validation loss: 5.679723445188819

Epoch: 6| Step: 5
Training loss: 5.53798029002894
Validation loss: 5.662140422348619

Epoch: 6| Step: 6
Training loss: 6.841935426712297
Validation loss: 5.6424155530635325

Epoch: 6| Step: 7
Training loss: 5.6498123542885805
Validation loss: 5.620373574125303

Epoch: 6| Step: 8
Training loss: 4.631439674601479
Validation loss: 5.595880984865468

Epoch: 6| Step: 9
Training loss: 5.30029870397116
Validation loss: 5.568205967681311

Epoch: 6| Step: 10
Training loss: 4.709715828715769
Validation loss: 5.537566263170028

Epoch: 6| Step: 11
Training loss: 5.981561621955914
Validation loss: 5.504195845550362

Epoch: 6| Step: 12
Training loss: 5.226940557608574
Validation loss: 5.467846143714842

Epoch: 6| Step: 13
Training loss: 3.960611484210162
Validation loss: 5.429504090200236

Epoch: 2| Step: 0
Training loss: 4.643444091249991
Validation loss: 5.38831454724346

Epoch: 6| Step: 1
Training loss: 4.520465935517037
Validation loss: 5.346389280890731

Epoch: 6| Step: 2
Training loss: 5.6447066230325404
Validation loss: 5.302910661529046

Epoch: 6| Step: 3
Training loss: 4.525018445393603
Validation loss: 5.259604985270231

Epoch: 6| Step: 4
Training loss: 4.94263046841109
Validation loss: 5.215821263084997

Epoch: 6| Step: 5
Training loss: 4.535136903759339
Validation loss: 5.172987991133428

Epoch: 6| Step: 6
Training loss: 5.620545212713726
Validation loss: 5.131264664148369

Epoch: 6| Step: 7
Training loss: 5.5829626311415215
Validation loss: 5.091312117219224

Epoch: 6| Step: 8
Training loss: 6.256090172432417
Validation loss: 5.050224567977141

Epoch: 6| Step: 9
Training loss: 5.130582420794203
Validation loss: 5.008900477096871

Epoch: 6| Step: 10
Training loss: 4.568179840957027
Validation loss: 4.965084730857305

Epoch: 6| Step: 11
Training loss: 6.320530683714723
Validation loss: 4.921801117633706

Epoch: 6| Step: 12
Training loss: 5.020489481736862
Validation loss: 4.873027727544563

Epoch: 6| Step: 13
Training loss: 4.091560302304912
Validation loss: 4.826640561063874

Epoch: 3| Step: 0
Training loss: 5.306529920403971
Validation loss: 4.784348877363635

Epoch: 6| Step: 1
Training loss: 3.9960617705526356
Validation loss: 4.745156236916085

Epoch: 6| Step: 2
Training loss: 4.96254549173792
Validation loss: 4.707449648328628

Epoch: 6| Step: 3
Training loss: 4.28363037761618
Validation loss: 4.672774130100305

Epoch: 6| Step: 4
Training loss: 4.159614291283038
Validation loss: 4.638560346574149

Epoch: 6| Step: 5
Training loss: 5.163892041969716
Validation loss: 4.602433654642423

Epoch: 6| Step: 6
Training loss: 3.812206069371965
Validation loss: 4.563385847521743

Epoch: 6| Step: 7
Training loss: 6.044450456173719
Validation loss: 4.526199378665974

Epoch: 6| Step: 8
Training loss: 4.9365824559095675
Validation loss: 4.489513428173821

Epoch: 6| Step: 9
Training loss: 4.659810797652827
Validation loss: 4.459792018793816

Epoch: 6| Step: 10
Training loss: 4.574788098039927
Validation loss: 4.4192833202668895

Epoch: 6| Step: 11
Training loss: 3.971249731806481
Validation loss: 4.379645548246893

Epoch: 6| Step: 12
Training loss: 4.481980166144959
Validation loss: 4.350914035184606

Epoch: 6| Step: 13
Training loss: 4.074548548867125
Validation loss: 4.3234730573607605

Epoch: 4| Step: 0
Training loss: 4.743551595406258
Validation loss: 4.303996710938002

Epoch: 6| Step: 1
Training loss: 4.235786230973753
Validation loss: 4.277598299813282

Epoch: 6| Step: 2
Training loss: 4.388127930312434
Validation loss: 4.2481489668589125

Epoch: 6| Step: 3
Training loss: 5.356913454502807
Validation loss: 4.22422243081701

Epoch: 6| Step: 4
Training loss: 4.249686734490978
Validation loss: 4.198749585510257

Epoch: 6| Step: 5
Training loss: 3.049649115218364
Validation loss: 4.17974503739854

Epoch: 6| Step: 6
Training loss: 5.272001395889584
Validation loss: 4.154733079241913

Epoch: 6| Step: 7
Training loss: 5.050804474460816
Validation loss: 4.127649778087746

Epoch: 6| Step: 8
Training loss: 4.1962039504764475
Validation loss: 4.10127433268492

Epoch: 6| Step: 9
Training loss: 4.161510608839698
Validation loss: 4.075227875021852

Epoch: 6| Step: 10
Training loss: 3.526002749402494
Validation loss: 4.0456816116947545

Epoch: 6| Step: 11
Training loss: 3.586953278993691
Validation loss: 4.006648818730411

Epoch: 6| Step: 12
Training loss: 3.8024321652994812
Validation loss: 4.000785588983602

Epoch: 6| Step: 13
Training loss: 3.2734437637451257
Validation loss: 3.997711018930335

Epoch: 5| Step: 0
Training loss: 3.9963130648364644
Validation loss: 3.978692185217425

Epoch: 6| Step: 1
Training loss: 3.6226142398783283
Validation loss: 3.9603329429112724

Epoch: 6| Step: 2
Training loss: 4.323914831658406
Validation loss: 3.9512188279855462

Epoch: 6| Step: 3
Training loss: 4.5296388063580135
Validation loss: 3.940176623587164

Epoch: 6| Step: 4
Training loss: 4.101555989578166
Validation loss: 3.9277884849401663

Epoch: 6| Step: 5
Training loss: 5.691822463547416
Validation loss: 3.9141103160166755

Epoch: 6| Step: 6
Training loss: 4.297990355951664
Validation loss: 3.9037715407806384

Epoch: 6| Step: 7
Training loss: 3.7563070029505097
Validation loss: 3.889719085053011

Epoch: 6| Step: 8
Training loss: 4.243259694873125
Validation loss: 3.8866210080934955

Epoch: 6| Step: 9
Training loss: 3.097018432375111
Validation loss: 3.8786719962504317

Epoch: 6| Step: 10
Training loss: 3.5974545168569527
Validation loss: 3.8951990834037926

Epoch: 6| Step: 11
Training loss: 3.321734960695824
Validation loss: 3.8954178581611405

Epoch: 6| Step: 12
Training loss: 3.9994163087314223
Validation loss: 3.8679132577071913

Epoch: 6| Step: 13
Training loss: 3.618589455003132
Validation loss: 3.8551903178718385

Epoch: 6| Step: 0
Training loss: 4.212101876210519
Validation loss: 3.842409639373619

Epoch: 6| Step: 1
Training loss: 3.664457059979499
Validation loss: 3.8268555448917287

Epoch: 6| Step: 2
Training loss: 2.149329315969027
Validation loss: 3.8234140137930615

Epoch: 6| Step: 3
Training loss: 4.259860996611183
Validation loss: 3.822587940994333

Epoch: 6| Step: 4
Training loss: 3.3743712228046268
Validation loss: 3.802475067784206

Epoch: 6| Step: 5
Training loss: 4.111039553411861
Validation loss: 3.7978899617163835

Epoch: 6| Step: 6
Training loss: 2.8942576084700913
Validation loss: 3.7912260680991845

Epoch: 6| Step: 7
Training loss: 5.100679329899582
Validation loss: 3.789308248351901

Epoch: 6| Step: 8
Training loss: 4.552729766594622
Validation loss: 3.779149853234954

Epoch: 6| Step: 9
Training loss: 4.742313188524326
Validation loss: 3.7713979337931223

Epoch: 6| Step: 10
Training loss: 3.6304419874235494
Validation loss: 3.7608640598534055

Epoch: 6| Step: 11
Training loss: 3.991224437790662
Validation loss: 3.7518031006865757

Epoch: 6| Step: 12
Training loss: 4.384297981047946
Validation loss: 3.7459119670760144

Epoch: 6| Step: 13
Training loss: 2.9977740930971817
Validation loss: 3.7425117983273037

Epoch: 7| Step: 0
Training loss: 2.83239844736941
Validation loss: 3.7370988513734464

Epoch: 6| Step: 1
Training loss: 3.9109221326683827
Validation loss: 3.7313397821392513

Epoch: 6| Step: 2
Training loss: 4.268060121879668
Validation loss: 3.7237920417490527

Epoch: 6| Step: 3
Training loss: 3.373753918097455
Validation loss: 3.722959204924473

Epoch: 6| Step: 4
Training loss: 4.2455879197901405
Validation loss: 3.718324228249497

Epoch: 6| Step: 5
Training loss: 4.490120108512375
Validation loss: 3.7091003160347524

Epoch: 6| Step: 6
Training loss: 4.424977861769303
Validation loss: 3.6986476930707317

Epoch: 6| Step: 7
Training loss: 3.451658187651953
Validation loss: 3.6957486018089356

Epoch: 6| Step: 8
Training loss: 3.309965495595271
Validation loss: 3.6921938136180983

Epoch: 6| Step: 9
Training loss: 4.043033617761616
Validation loss: 3.6815535115639464

Epoch: 6| Step: 10
Training loss: 4.250042185854508
Validation loss: 3.6734565716676792

Epoch: 6| Step: 11
Training loss: 3.287005508422878
Validation loss: 3.6674519468929185

Epoch: 6| Step: 12
Training loss: 4.202249996049363
Validation loss: 3.662365282837267

Epoch: 6| Step: 13
Training loss: 3.848331852963971
Validation loss: 3.6567728506478274

Epoch: 8| Step: 0
Training loss: 3.4554195461784816
Validation loss: 3.6518604203772256

Epoch: 6| Step: 1
Training loss: 4.306759980984949
Validation loss: 3.6452239218393183

Epoch: 6| Step: 2
Training loss: 3.6963867174599914
Validation loss: 3.6411222649672887

Epoch: 6| Step: 3
Training loss: 3.600631361804938
Validation loss: 3.6327876172739075

Epoch: 6| Step: 4
Training loss: 3.2303339827447695
Validation loss: 3.628421091324359

Epoch: 6| Step: 5
Training loss: 4.445606617508103
Validation loss: 3.621609168030703

Epoch: 6| Step: 6
Training loss: 3.06602228761499
Validation loss: 3.615919749768697

Epoch: 6| Step: 7
Training loss: 3.991808371261824
Validation loss: 3.610565578712698

Epoch: 6| Step: 8
Training loss: 4.099828037284336
Validation loss: 3.6044479654876738

Epoch: 6| Step: 9
Training loss: 4.569626768134223
Validation loss: 3.6006957229584193

Epoch: 6| Step: 10
Training loss: 3.622086241834412
Validation loss: 3.5966449906374396

Epoch: 6| Step: 11
Training loss: 3.876839970011165
Validation loss: 3.5960793228392722

Epoch: 6| Step: 12
Training loss: 2.749230710713894
Validation loss: 3.587879961400214

Epoch: 6| Step: 13
Training loss: 4.459546622253186
Validation loss: 3.5868194951684877

Epoch: 9| Step: 0
Training loss: 3.4689471214577092
Validation loss: 3.584079267487274

Epoch: 6| Step: 1
Training loss: 3.9293086512057602
Validation loss: 3.5806996945000753

Epoch: 6| Step: 2
Training loss: 3.5911188196056503
Validation loss: 3.575696259275976

Epoch: 6| Step: 3
Training loss: 3.1119020247641083
Validation loss: 3.571523575551947

Epoch: 6| Step: 4
Training loss: 3.8560299605001016
Validation loss: 3.569000595498332

Epoch: 6| Step: 5
Training loss: 3.3790044693094563
Validation loss: 3.56649139586235

Epoch: 6| Step: 6
Training loss: 3.7870665651590167
Validation loss: 3.5637889344496467

Epoch: 6| Step: 7
Training loss: 3.513565477474691
Validation loss: 3.566376510431606

Epoch: 6| Step: 8
Training loss: 4.25851014747499
Validation loss: 3.5641258917770022

Epoch: 6| Step: 9
Training loss: 4.002785189855064
Validation loss: 3.554864094415779

Epoch: 6| Step: 10
Training loss: 4.917124753829881
Validation loss: 3.549302261950921

Epoch: 6| Step: 11
Training loss: 3.215504611980516
Validation loss: 3.550577431188765

Epoch: 6| Step: 12
Training loss: 3.5863996885219134
Validation loss: 3.5489744812390023

Epoch: 6| Step: 13
Training loss: 3.7425361104585133
Validation loss: 3.547627133524117

Epoch: 10| Step: 0
Training loss: 3.837141232696634
Validation loss: 3.5441971431753636

Epoch: 6| Step: 1
Training loss: 4.045420027946993
Validation loss: 3.539996219498813

Epoch: 6| Step: 2
Training loss: 3.614967406404273
Validation loss: 3.535718562678133

Epoch: 6| Step: 3
Training loss: 2.893842731085831
Validation loss: 3.533051197209387

Epoch: 6| Step: 4
Training loss: 4.141643816285577
Validation loss: 3.5311356842793606

Epoch: 6| Step: 5
Training loss: 4.088551722552655
Validation loss: 3.5274829509298073

Epoch: 6| Step: 6
Training loss: 3.1462667474009227
Validation loss: 3.524060904790469

Epoch: 6| Step: 7
Training loss: 3.1583057922397133
Validation loss: 3.521754148363726

Epoch: 6| Step: 8
Training loss: 4.067755718012194
Validation loss: 3.517910791374536

Epoch: 6| Step: 9
Training loss: 3.649797271951248
Validation loss: 3.5159125841437002

Epoch: 6| Step: 10
Training loss: 4.055783162341957
Validation loss: 3.5153903721549535

Epoch: 6| Step: 11
Training loss: 3.6264378557065156
Validation loss: 3.5126346083406506

Epoch: 6| Step: 12
Training loss: 3.671040801392804
Validation loss: 3.509260872763648

Epoch: 6| Step: 13
Training loss: 4.235061646140047
Validation loss: 3.5070070217617872

Epoch: 11| Step: 0
Training loss: 3.7501844996523976
Validation loss: 3.5055069281130486

Epoch: 6| Step: 1
Training loss: 3.9857021141159383
Validation loss: 3.5053141795431006

Epoch: 6| Step: 2
Training loss: 3.7762897839639775
Validation loss: 3.5023773194312513

Epoch: 6| Step: 3
Training loss: 3.907115626744613
Validation loss: 3.4994179348587657

Epoch: 6| Step: 4
Training loss: 2.226953411921958
Validation loss: 3.497518500611523

Epoch: 6| Step: 5
Training loss: 3.996018096714836
Validation loss: 3.495953340289372

Epoch: 6| Step: 6
Training loss: 3.388947383883016
Validation loss: 3.496190095271603

Epoch: 6| Step: 7
Training loss: 3.934257383156494
Validation loss: 3.494365566337322

Epoch: 6| Step: 8
Training loss: 4.574651552699208
Validation loss: 3.4923710381736632

Epoch: 6| Step: 9
Training loss: 4.004421651278805
Validation loss: 3.4912231123838393

Epoch: 6| Step: 10
Training loss: 2.543404115597688
Validation loss: 3.4891659605343324

Epoch: 6| Step: 11
Training loss: 3.767668490119643
Validation loss: 3.487076913104051

Epoch: 6| Step: 12
Training loss: 3.6774499006249486
Validation loss: 3.4855821577502697

Epoch: 6| Step: 13
Training loss: 3.8088646738575216
Validation loss: 3.484381042001405

Epoch: 12| Step: 0
Training loss: 2.9318538539939536
Validation loss: 3.482849726073172

Epoch: 6| Step: 1
Training loss: 3.4848501112460437
Validation loss: 3.4830477704104648

Epoch: 6| Step: 2
Training loss: 3.7723895211092144
Validation loss: 3.4813026918957766

Epoch: 6| Step: 3
Training loss: 3.6229005192811217
Validation loss: 3.480041074721388

Epoch: 6| Step: 4
Training loss: 3.221232965769968
Validation loss: 3.4776024832089596

Epoch: 6| Step: 5
Training loss: 3.628833716645943
Validation loss: 3.476004835667225

Epoch: 6| Step: 6
Training loss: 3.9754014634183954
Validation loss: 3.475646365259072

Epoch: 6| Step: 7
Training loss: 4.225612456042569
Validation loss: 3.474117623656188

Epoch: 6| Step: 8
Training loss: 3.3238743246124502
Validation loss: 3.47272095580216

Epoch: 6| Step: 9
Training loss: 3.973718371797913
Validation loss: 3.471505776655377

Epoch: 6| Step: 10
Training loss: 4.06794256821323
Validation loss: 3.4713947044004327

Epoch: 6| Step: 11
Training loss: 3.366351172013679
Validation loss: 3.469534100502135

Epoch: 6| Step: 12
Training loss: 4.41924798255577
Validation loss: 3.4684407633006127

Epoch: 6| Step: 13
Training loss: 3.101981262071733
Validation loss: 3.4668895887785296

Epoch: 13| Step: 0
Training loss: 4.026378911917504
Validation loss: 3.465303588545723

Epoch: 6| Step: 1
Training loss: 2.549245936032204
Validation loss: 3.463882612825586

Epoch: 6| Step: 2
Training loss: 4.601868390989499
Validation loss: 3.4637612110953215

Epoch: 6| Step: 3
Training loss: 3.792959698431527
Validation loss: 3.462458333677326

Epoch: 6| Step: 4
Training loss: 4.092556612046159
Validation loss: 3.4597762312908626

Epoch: 6| Step: 5
Training loss: 4.21108380065311
Validation loss: 3.45941616521148

Epoch: 6| Step: 6
Training loss: 2.982778711462306
Validation loss: 3.4588202306596068

Epoch: 6| Step: 7
Training loss: 4.0723176143264075
Validation loss: 3.4567634116783528

Epoch: 6| Step: 8
Training loss: 3.560948485775548
Validation loss: 3.4556661096348753

Epoch: 6| Step: 9
Training loss: 3.0460745518077688
Validation loss: 3.4554965282968446

Epoch: 6| Step: 10
Training loss: 3.573404988690171
Validation loss: 3.454131707639569

Epoch: 6| Step: 11
Training loss: 3.2018293039641623
Validation loss: 3.4525065260051564

Epoch: 6| Step: 12
Training loss: 3.5323866643630373
Validation loss: 3.4517245957430855

Epoch: 6| Step: 13
Training loss: 3.760231175519288
Validation loss: 3.4505531326549876

Epoch: 14| Step: 0
Training loss: 4.280163480898572
Validation loss: 3.4492951986237035

Epoch: 6| Step: 1
Training loss: 3.1213977651332283
Validation loss: 3.4476463291944395

Epoch: 6| Step: 2
Training loss: 2.7958691029503724
Validation loss: 3.4463003992794503

Epoch: 6| Step: 3
Training loss: 3.159671251121093
Validation loss: 3.445358691634732

Epoch: 6| Step: 4
Training loss: 4.260106132152361
Validation loss: 3.444517257629597

Epoch: 6| Step: 5
Training loss: 3.8607980675956104
Validation loss: 3.443374506536421

Epoch: 6| Step: 6
Training loss: 3.9084379858607003
Validation loss: 3.4428403686107605

Epoch: 6| Step: 7
Training loss: 2.73253739871497
Validation loss: 3.441381890380883

Epoch: 6| Step: 8
Training loss: 3.5087799573271092
Validation loss: 3.440004911626699

Epoch: 6| Step: 9
Training loss: 3.6101406325741507
Validation loss: 3.439238692326577

Epoch: 6| Step: 10
Training loss: 2.9302278147589003
Validation loss: 3.4381675482221885

Epoch: 6| Step: 11
Training loss: 4.228258508349239
Validation loss: 3.4369041858748455

Epoch: 6| Step: 12
Training loss: 4.1977986334148065
Validation loss: 3.4358228781671842

Epoch: 6| Step: 13
Training loss: 4.442860119616695
Validation loss: 3.434849184039746

Epoch: 15| Step: 0
Training loss: 3.1278603242679943
Validation loss: 3.4337554419082905

Epoch: 6| Step: 1
Training loss: 3.7666239699472848
Validation loss: 3.4325852267708807

Epoch: 6| Step: 2
Training loss: 4.3000991100156085
Validation loss: 3.4313003657380046

Epoch: 6| Step: 3
Training loss: 3.8721210490843654
Validation loss: 3.4302757353545434

Epoch: 6| Step: 4
Training loss: 3.418777806031231
Validation loss: 3.4303220562296084

Epoch: 6| Step: 5
Training loss: 3.4048495432232104
Validation loss: 3.4286045967324963

Epoch: 6| Step: 6
Training loss: 4.030276868600127
Validation loss: 3.427642056096324

Epoch: 6| Step: 7
Training loss: 3.4243968571778036
Validation loss: 3.426117787791491

Epoch: 6| Step: 8
Training loss: 2.8356356709754342
Validation loss: 3.425156606613745

Epoch: 6| Step: 9
Training loss: 4.20625228541682
Validation loss: 3.4236326859216417

Epoch: 6| Step: 10
Training loss: 3.5877748656560517
Validation loss: 3.4231871451311973

Epoch: 6| Step: 11
Training loss: 4.240505158903305
Validation loss: 3.421945474247011

Epoch: 6| Step: 12
Training loss: 2.848087900776898
Validation loss: 3.420857101533122

Epoch: 6| Step: 13
Training loss: 3.6697467236343435
Validation loss: 3.4200260690447406

Epoch: 16| Step: 0
Training loss: 3.287030459911311
Validation loss: 3.418506730595

Epoch: 6| Step: 1
Training loss: 3.3280125272129943
Validation loss: 3.417685455629649

Epoch: 6| Step: 2
Training loss: 3.480629040658708
Validation loss: 3.4163773206821197

Epoch: 6| Step: 3
Training loss: 3.151302425639951
Validation loss: 3.4157228251668017

Epoch: 6| Step: 4
Training loss: 3.4435200083065327
Validation loss: 3.41495471977236

Epoch: 6| Step: 5
Training loss: 4.730232062746144
Validation loss: 3.413877847176391

Epoch: 6| Step: 6
Training loss: 3.2793199948466563
Validation loss: 3.413331165200873

Epoch: 6| Step: 7
Training loss: 4.038752944269881
Validation loss: 3.4123001849680112

Epoch: 6| Step: 8
Training loss: 4.205068599762783
Validation loss: 3.410419494875096

Epoch: 6| Step: 9
Training loss: 4.072350400046847
Validation loss: 3.409351750099785

Epoch: 6| Step: 10
Training loss: 3.9089124227507774
Validation loss: 3.4085969511631466

Epoch: 6| Step: 11
Training loss: 3.245642748923192
Validation loss: 3.407967423398632

Epoch: 6| Step: 12
Training loss: 3.1232897847117336
Validation loss: 3.4062506261868073

Epoch: 6| Step: 13
Training loss: 2.8715540925593133
Validation loss: 3.404606206045626

Epoch: 17| Step: 0
Training loss: 4.078473423364175
Validation loss: 3.4043143339039292

Epoch: 6| Step: 1
Training loss: 3.2171042966528134
Validation loss: 3.402998652826073

Epoch: 6| Step: 2
Training loss: 3.7909215397585676
Validation loss: 3.4015094078839376

Epoch: 6| Step: 3
Training loss: 2.636234041096047
Validation loss: 3.4003686208640254

Epoch: 6| Step: 4
Training loss: 4.070541170400058
Validation loss: 3.3988821019599778

Epoch: 6| Step: 5
Training loss: 3.8148698789071647
Validation loss: 3.3974613510073244

Epoch: 6| Step: 6
Training loss: 3.6555083737199827
Validation loss: 3.3964319814353705

Epoch: 6| Step: 7
Training loss: 4.56965014230802
Validation loss: 3.3948993048836678

Epoch: 6| Step: 8
Training loss: 3.8830728424415413
Validation loss: 3.393818000144382

Epoch: 6| Step: 9
Training loss: 2.8375848026459107
Validation loss: 3.3925268257763492

Epoch: 6| Step: 10
Training loss: 2.6653011720112256
Validation loss: 3.391386461218981

Epoch: 6| Step: 11
Training loss: 3.604473005443744
Validation loss: 3.3911644759867037

Epoch: 6| Step: 12
Training loss: 3.678302091031701
Validation loss: 3.390278868447441

Epoch: 6| Step: 13
Training loss: 3.7598347446974425
Validation loss: 3.389655348695859

Epoch: 18| Step: 0
Training loss: 3.3964363608056796
Validation loss: 3.3878355930043837

Epoch: 6| Step: 1
Training loss: 3.822876863333036
Validation loss: 3.3864513371645333

Epoch: 6| Step: 2
Training loss: 3.736150726398255
Validation loss: 3.3850079103984725

Epoch: 6| Step: 3
Training loss: 3.7248113904477336
Validation loss: 3.383778322401651

Epoch: 6| Step: 4
Training loss: 4.489089454811608
Validation loss: 3.3827846324839173

Epoch: 6| Step: 5
Training loss: 3.6938713763799704
Validation loss: 3.381771589570043

Epoch: 6| Step: 6
Training loss: 3.424901451308034
Validation loss: 3.3810097341826366

Epoch: 6| Step: 7
Training loss: 3.8109455379136996
Validation loss: 3.3791733768411127

Epoch: 6| Step: 8
Training loss: 3.151469926131693
Validation loss: 3.378500718389611

Epoch: 6| Step: 9
Training loss: 2.784990345854266
Validation loss: 3.377141494150449

Epoch: 6| Step: 10
Training loss: 3.7270379552891617
Validation loss: 3.376599657767132

Epoch: 6| Step: 11
Training loss: 3.0603390290185466
Validation loss: 3.376222723966543

Epoch: 6| Step: 12
Training loss: 3.6271363901767377
Validation loss: 3.3745400234199376

Epoch: 6| Step: 13
Training loss: 3.9839011714657717
Validation loss: 3.3760991298782543

Epoch: 19| Step: 0
Training loss: 3.125594578446001
Validation loss: 3.371923575111817

Epoch: 6| Step: 1
Training loss: 4.0350168061881355
Validation loss: 3.3717995907798897

Epoch: 6| Step: 2
Training loss: 2.8016810547933693
Validation loss: 3.372657313749288

Epoch: 6| Step: 3
Training loss: 3.0242089364265343
Validation loss: 3.373237751387221

Epoch: 6| Step: 4
Training loss: 2.8413437944228903
Validation loss: 3.370216193903509

Epoch: 6| Step: 5
Training loss: 4.051390731707066
Validation loss: 3.368571408532127

Epoch: 6| Step: 6
Training loss: 4.67284819504189
Validation loss: 3.367005570485203

Epoch: 6| Step: 7
Training loss: 3.603393618784855
Validation loss: 3.366190114301347

Epoch: 6| Step: 8
Training loss: 3.674858796397749
Validation loss: 3.365424260858494

Epoch: 6| Step: 9
Training loss: 3.6571785815444025
Validation loss: 3.3649533392581326

Epoch: 6| Step: 10
Training loss: 3.7264708821612578
Validation loss: 3.3650405305459246

Epoch: 6| Step: 11
Training loss: 3.2521264382307242
Validation loss: 3.3622345979096875

Epoch: 6| Step: 12
Training loss: 3.439203291164118
Validation loss: 3.3616776919507605

Epoch: 6| Step: 13
Training loss: 4.29248488444098
Validation loss: 3.3599276149905406

Epoch: 20| Step: 0
Training loss: 3.6210215868955644
Validation loss: 3.358932191969589

Epoch: 6| Step: 1
Training loss: 3.8602501498584805
Validation loss: 3.358175064075006

Epoch: 6| Step: 2
Training loss: 3.406681418439823
Validation loss: 3.35639275297113

Epoch: 6| Step: 3
Training loss: 4.197410357337693
Validation loss: 3.3560796098050334

Epoch: 6| Step: 4
Training loss: 3.770365789663678
Validation loss: 3.355047801284114

Epoch: 6| Step: 5
Training loss: 3.109918441438994
Validation loss: 3.354611174664406

Epoch: 6| Step: 6
Training loss: 3.384626576098366
Validation loss: 3.3569943653620617

Epoch: 6| Step: 7
Training loss: 3.382408769932171
Validation loss: 3.368108395386566

Epoch: 6| Step: 8
Training loss: 3.519728778880538
Validation loss: 3.3574757264003314

Epoch: 6| Step: 9
Training loss: 3.3447586392166264
Validation loss: 3.351479810777068

Epoch: 6| Step: 10
Training loss: 3.804837515691437
Validation loss: 3.3536626273643377

Epoch: 6| Step: 11
Training loss: 3.447798820087446
Validation loss: 3.354591032981238

Epoch: 6| Step: 12
Training loss: 3.732666390882008
Validation loss: 3.356672896234107

Epoch: 6| Step: 13
Training loss: 3.571669573145574
Validation loss: 3.354270892675777

Epoch: 21| Step: 0
Training loss: 3.331196401998682
Validation loss: 3.351363620794514

Epoch: 6| Step: 1
Training loss: 3.9623647672760005
Validation loss: 3.349670347224877

Epoch: 6| Step: 2
Training loss: 3.551965765624846
Validation loss: 3.3473142607474684

Epoch: 6| Step: 3
Training loss: 3.3136203238872897
Validation loss: 3.3444465262131127

Epoch: 6| Step: 4
Training loss: 2.9361150195591885
Validation loss: 3.3414051987664344

Epoch: 6| Step: 5
Training loss: 4.044601921420548
Validation loss: 3.3449011480954263

Epoch: 6| Step: 6
Training loss: 4.360974309008037
Validation loss: 3.3424627866201346

Epoch: 6| Step: 7
Training loss: 4.018081566734144
Validation loss: 3.3344387672307656

Epoch: 6| Step: 8
Training loss: 3.2614313238815114
Validation loss: 3.331529140322726

Epoch: 6| Step: 9
Training loss: 3.4878738695140155
Validation loss: 3.332190778225872

Epoch: 6| Step: 10
Training loss: 3.98239505416422
Validation loss: 3.3343656438585594

Epoch: 6| Step: 11
Training loss: 3.361412672346047
Validation loss: 3.334400821822652

Epoch: 6| Step: 12
Training loss: 3.2754963156583767
Validation loss: 3.3316987034042858

Epoch: 6| Step: 13
Training loss: 2.131782478644311
Validation loss: 3.3275628199314453

Epoch: 22| Step: 0
Training loss: 3.7128133108566628
Validation loss: 3.3263087894151617

Epoch: 6| Step: 1
Training loss: 2.874661135398672
Validation loss: 3.323844030104919

Epoch: 6| Step: 2
Training loss: 3.674506749897393
Validation loss: 3.321651158483371

Epoch: 6| Step: 3
Training loss: 3.181040483031849
Validation loss: 3.3186619971824007

Epoch: 6| Step: 4
Training loss: 2.66884740432838
Validation loss: 3.3138724123337187

Epoch: 6| Step: 5
Training loss: 3.4514189082852216
Validation loss: 3.3148057636074193

Epoch: 6| Step: 6
Training loss: 4.473348319137039
Validation loss: 3.3103461821790177

Epoch: 6| Step: 7
Training loss: 4.4922762389333055
Validation loss: 3.307467589068993

Epoch: 6| Step: 8
Training loss: 3.482121718346008
Validation loss: 3.3000235410977394

Epoch: 6| Step: 9
Training loss: 3.8215872855134867
Validation loss: 3.2985987653143254

Epoch: 6| Step: 10
Training loss: 3.57423289145085
Validation loss: 3.2984321609312173

Epoch: 6| Step: 11
Training loss: 2.898967190691381
Validation loss: 3.296277037320235

Epoch: 6| Step: 12
Training loss: 3.0675953108601104
Validation loss: 3.299858425704425

Epoch: 6| Step: 13
Training loss: 3.9542533862322604
Validation loss: 3.2946666885170934

Epoch: 23| Step: 0
Training loss: 3.068225102488573
Validation loss: 3.291451607705504

Epoch: 6| Step: 1
Training loss: 3.1975711963115
Validation loss: 3.2898252629301687

Epoch: 6| Step: 2
Training loss: 2.870220357696147
Validation loss: 3.288915293995048

Epoch: 6| Step: 3
Training loss: 3.5400154902232432
Validation loss: 3.287070302971291

Epoch: 6| Step: 4
Training loss: 3.9077833904416104
Validation loss: 3.2862607044521233

Epoch: 6| Step: 5
Training loss: 3.5959224602950077
Validation loss: 3.2880042716958817

Epoch: 6| Step: 6
Training loss: 3.838776386733
Validation loss: 3.285324275184618

Epoch: 6| Step: 7
Training loss: 3.267868220647756
Validation loss: 3.285316749663076

Epoch: 6| Step: 8
Training loss: 3.7841895161162684
Validation loss: 3.2840626402337794

Epoch: 6| Step: 9
Training loss: 3.3419849336148704
Validation loss: 3.2821828849124013

Epoch: 6| Step: 10
Training loss: 4.129421523178382
Validation loss: 3.2798882638968814

Epoch: 6| Step: 11
Training loss: 4.171960494061955
Validation loss: 3.2797063131081594

Epoch: 6| Step: 12
Training loss: 2.6749129842705517
Validation loss: 3.280843897317963

Epoch: 6| Step: 13
Training loss: 3.7555960544556926
Validation loss: 3.2787128270824724

Epoch: 24| Step: 0
Training loss: 4.442123797990092
Validation loss: 3.275728970861367

Epoch: 6| Step: 1
Training loss: 2.937697383661011
Validation loss: 3.291434316559109

Epoch: 6| Step: 2
Training loss: 4.046128841232508
Validation loss: 3.2760105771635706

Epoch: 6| Step: 3
Training loss: 4.013407647932905
Validation loss: 3.271172698639698

Epoch: 6| Step: 4
Training loss: 3.645132262625889
Validation loss: 3.271298890259119

Epoch: 6| Step: 5
Training loss: 4.3004521686655774
Validation loss: 3.269977524764097

Epoch: 6| Step: 6
Training loss: 3.563845999236557
Validation loss: 3.271584766153451

Epoch: 6| Step: 7
Training loss: 2.3849163835690783
Validation loss: 3.2773963718369075

Epoch: 6| Step: 8
Training loss: 3.524585207078701
Validation loss: 3.2940000459810848

Epoch: 6| Step: 9
Training loss: 3.508560882461979
Validation loss: 3.264705097604379

Epoch: 6| Step: 10
Training loss: 2.573156667370404
Validation loss: 3.268777947002559

Epoch: 6| Step: 11
Training loss: 3.0800960832941913
Validation loss: 3.3493585602723916

Epoch: 6| Step: 12
Training loss: 3.589779725609018
Validation loss: 3.2772690085180955

Epoch: 6| Step: 13
Training loss: 2.7533244066193756
Validation loss: 3.269080480401559

Epoch: 25| Step: 0
Training loss: 3.0070416143827945
Validation loss: 3.2758717781030806

Epoch: 6| Step: 1
Training loss: 3.6096862394555087
Validation loss: 3.2838707087225547

Epoch: 6| Step: 2
Training loss: 3.758864796708778
Validation loss: 3.2825519031849484

Epoch: 6| Step: 3
Training loss: 3.0794255176671936
Validation loss: 3.2888121548251856

Epoch: 6| Step: 4
Training loss: 3.2399850741384055
Validation loss: 3.2896203881857566

Epoch: 6| Step: 5
Training loss: 3.9074478143976807
Validation loss: 3.290220799521662

Epoch: 6| Step: 6
Training loss: 3.161968828910241
Validation loss: 3.2735474325466587

Epoch: 6| Step: 7
Training loss: 4.198883071612291
Validation loss: 3.264562646855915

Epoch: 6| Step: 8
Training loss: 3.7754623635191504
Validation loss: 3.2696250239220777

Epoch: 6| Step: 9
Training loss: 4.113862463017453
Validation loss: 3.275234902029847

Epoch: 6| Step: 10
Training loss: 4.131403259112368
Validation loss: 3.2909651559527573

Epoch: 6| Step: 11
Training loss: 3.096376171413522
Validation loss: 3.266532401736238

Epoch: 6| Step: 12
Training loss: 2.5636857243538285
Validation loss: 3.270149807468355

Epoch: 6| Step: 13
Training loss: 2.919910606949412
Validation loss: 3.352162535829386

Epoch: 26| Step: 0
Training loss: 4.104771809897369
Validation loss: 3.5316644248073947

Epoch: 6| Step: 1
Training loss: 4.187129217784636
Validation loss: 3.5537009057226205

Epoch: 6| Step: 2
Training loss: 3.222635239041355
Validation loss: 3.462794722864329

Epoch: 6| Step: 3
Training loss: 3.487355005675205
Validation loss: 3.347478507316328

Epoch: 6| Step: 4
Training loss: 3.2829034907982018
Validation loss: 3.272490245085997

Epoch: 6| Step: 5
Training loss: 3.2932515413215104
Validation loss: 3.3000929244187507

Epoch: 6| Step: 6
Training loss: 3.5298283508756496
Validation loss: 3.326690287555385

Epoch: 6| Step: 7
Training loss: 3.0438925206462355
Validation loss: 3.3682204243627853

Epoch: 6| Step: 8
Training loss: 4.228703265178539
Validation loss: 3.3819333561348013

Epoch: 6| Step: 9
Training loss: 3.6838376236543287
Validation loss: 3.263430535999761

Epoch: 6| Step: 10
Training loss: 3.600592824020401
Validation loss: 3.2515085992781856

Epoch: 6| Step: 11
Training loss: 3.2547574069188423
Validation loss: 3.2684713791198026

Epoch: 6| Step: 12
Training loss: 3.7353297333920987
Validation loss: 3.3448130777210574

Epoch: 6| Step: 13
Training loss: 3.3243695055691544
Validation loss: 3.412345051950378

Epoch: 27| Step: 0
Training loss: 3.8335886054804234
Validation loss: 3.42379165398902

Epoch: 6| Step: 1
Training loss: 3.747088764573736
Validation loss: 3.3358646646254266

Epoch: 6| Step: 2
Training loss: 3.511397333255613
Validation loss: 3.3087075151392513

Epoch: 6| Step: 3
Training loss: 2.8430243603833065
Validation loss: 3.278606305706788

Epoch: 6| Step: 4
Training loss: 3.2731467324992787
Validation loss: 3.285246517393756

Epoch: 6| Step: 5
Training loss: 4.0740183765444495
Validation loss: 3.292933820755446

Epoch: 6| Step: 6
Training loss: 3.894185103450282
Validation loss: 3.2945757540164435

Epoch: 6| Step: 7
Training loss: 3.6166000383512613
Validation loss: 3.2937890447529288

Epoch: 6| Step: 8
Training loss: 3.740966852640332
Validation loss: 3.2893400125119197

Epoch: 6| Step: 9
Training loss: 3.3251647678938525
Validation loss: 3.290491383153654

Epoch: 6| Step: 10
Training loss: 3.313266305635656
Validation loss: 3.2916120060195575

Epoch: 6| Step: 11
Training loss: 3.453321770632716
Validation loss: 3.2806125847972916

Epoch: 6| Step: 12
Training loss: 3.7381774186370564
Validation loss: 3.27515053308018

Epoch: 6| Step: 13
Training loss: 2.729848024379023
Validation loss: 3.2724516479486856

Epoch: 28| Step: 0
Training loss: 3.927789976996422
Validation loss: 3.2711886893563293

Epoch: 6| Step: 1
Training loss: 2.8531870773598227
Validation loss: 3.269697857672674

Epoch: 6| Step: 2
Training loss: 4.189135787078061
Validation loss: 3.2706114207296735

Epoch: 6| Step: 3
Training loss: 3.0424868553460693
Validation loss: 3.2757689341635943

Epoch: 6| Step: 4
Training loss: 3.4428077641073926
Validation loss: 3.269830022496363

Epoch: 6| Step: 5
Training loss: 3.202414829333599
Validation loss: 3.2668990883966087

Epoch: 6| Step: 6
Training loss: 3.1847932580174616
Validation loss: 3.263302237952782

Epoch: 6| Step: 7
Training loss: 3.610240221563859
Validation loss: 3.2611449604160088

Epoch: 6| Step: 8
Training loss: 4.046066851543989
Validation loss: 3.260228544991776

Epoch: 6| Step: 9
Training loss: 3.941284903708397
Validation loss: 3.2566697754757286

Epoch: 6| Step: 10
Training loss: 3.564653782879464
Validation loss: 3.25197514953319

Epoch: 6| Step: 11
Training loss: 2.350845988159664
Validation loss: 3.249643986262691

Epoch: 6| Step: 12
Training loss: 3.51017290999065
Validation loss: 3.2479524654510996

Epoch: 6| Step: 13
Training loss: 3.9035303032159234
Validation loss: 3.246302665267355

Epoch: 29| Step: 0
Training loss: 3.1050003946153573
Validation loss: 3.243414307795803

Epoch: 6| Step: 1
Training loss: 4.1179295835620815
Validation loss: 3.241882107413177

Epoch: 6| Step: 2
Training loss: 3.458482961213684
Validation loss: 3.235371855389198

Epoch: 6| Step: 3
Training loss: 3.406927758779167
Validation loss: 3.2287381031026063

Epoch: 6| Step: 4
Training loss: 4.370399890471891
Validation loss: 3.218291829377831

Epoch: 6| Step: 5
Training loss: 2.8013792796094386
Validation loss: 3.2098772153518276

Epoch: 6| Step: 6
Training loss: 3.737334543093448
Validation loss: 3.2104133976834808

Epoch: 6| Step: 7
Training loss: 2.735953175289056
Validation loss: 3.2101694267319423

Epoch: 6| Step: 8
Training loss: 3.018998704857563
Validation loss: 3.2142027671191453

Epoch: 6| Step: 9
Training loss: 3.3217971175386207
Validation loss: 3.2061118233768235

Epoch: 6| Step: 10
Training loss: 3.5989428610499017
Validation loss: 3.2030298170368514

Epoch: 6| Step: 11
Training loss: 2.9116641240872174
Validation loss: 3.2012728935229973

Epoch: 6| Step: 12
Training loss: 4.102117242991007
Validation loss: 3.199289830682651

Epoch: 6| Step: 13
Training loss: 3.34683356308419
Validation loss: 3.1982068088568956

Epoch: 30| Step: 0
Training loss: 2.883733007995256
Validation loss: 3.196365142540722

Epoch: 6| Step: 1
Training loss: 2.5115854752987095
Validation loss: 3.1957948430302126

Epoch: 6| Step: 2
Training loss: 3.685298715231019
Validation loss: 3.1940987374200014

Epoch: 6| Step: 3
Training loss: 2.852295496544735
Validation loss: 3.192511305825178

Epoch: 6| Step: 4
Training loss: 4.092316354628794
Validation loss: 3.190706694581149

Epoch: 6| Step: 5
Training loss: 3.340753371196114
Validation loss: 3.18945331790885

Epoch: 6| Step: 6
Training loss: 3.3238895311510293
Validation loss: 3.1872296702253538

Epoch: 6| Step: 7
Training loss: 3.368435727890572
Validation loss: 3.1872553979848477

Epoch: 6| Step: 8
Training loss: 3.5188612220762465
Validation loss: 3.1854583101608713

Epoch: 6| Step: 9
Training loss: 3.16529501939621
Validation loss: 3.185960752286085

Epoch: 6| Step: 10
Training loss: 3.4430544280559467
Validation loss: 3.1843712362694094

Epoch: 6| Step: 11
Training loss: 3.795297805299105
Validation loss: 3.1845929189723763

Epoch: 6| Step: 12
Training loss: 4.102218372039623
Validation loss: 3.18247752614189

Epoch: 6| Step: 13
Training loss: 3.9366224007267094
Validation loss: 3.180901864654653

Epoch: 31| Step: 0
Training loss: 3.61008172320486
Validation loss: 3.1813316652724946

Epoch: 6| Step: 1
Training loss: 3.254498376355665
Validation loss: 3.1789993340044984

Epoch: 6| Step: 2
Training loss: 3.7501555092674446
Validation loss: 3.1787779152745355

Epoch: 6| Step: 3
Training loss: 3.3382960252459415
Validation loss: 3.1771705657156497

Epoch: 6| Step: 4
Training loss: 4.180971208751991
Validation loss: 3.176523452936126

Epoch: 6| Step: 5
Training loss: 2.616540082878544
Validation loss: 3.174150726406095

Epoch: 6| Step: 6
Training loss: 4.046772016592047
Validation loss: 3.174238550347114

Epoch: 6| Step: 7
Training loss: 3.038909202180796
Validation loss: 3.173351743223678

Epoch: 6| Step: 8
Training loss: 3.2103873939508114
Validation loss: 3.172392996784371

Epoch: 6| Step: 9
Training loss: 2.7567276590496625
Validation loss: 3.170335103372882

Epoch: 6| Step: 10
Training loss: 3.362870070502871
Validation loss: 3.170370771207671

Epoch: 6| Step: 11
Training loss: 3.5740482477262665
Validation loss: 3.1798432067058835

Epoch: 6| Step: 12
Training loss: 3.884712107631618
Validation loss: 3.190245361150098

Epoch: 6| Step: 13
Training loss: 2.6649487942469463
Validation loss: 3.2029005610812638

Epoch: 32| Step: 0
Training loss: 3.1370612274605714
Validation loss: 3.2006947091446025

Epoch: 6| Step: 1
Training loss: 3.3587237059426798
Validation loss: 3.183724976706391

Epoch: 6| Step: 2
Training loss: 3.707579175292748
Validation loss: 3.1666331578172713

Epoch: 6| Step: 3
Training loss: 3.9076823545776267
Validation loss: 3.166228342295022

Epoch: 6| Step: 4
Training loss: 3.3710040702693407
Validation loss: 3.1650317256288485

Epoch: 6| Step: 5
Training loss: 3.3913656383895723
Validation loss: 3.1653691425482076

Epoch: 6| Step: 6
Training loss: 4.012721336653564
Validation loss: 3.164996887813582

Epoch: 6| Step: 7
Training loss: 3.2176178357673773
Validation loss: 3.1656509874369636

Epoch: 6| Step: 8
Training loss: 3.285236806709627
Validation loss: 3.164108872766946

Epoch: 6| Step: 9
Training loss: 2.887938534682229
Validation loss: 3.1636122678578724

Epoch: 6| Step: 10
Training loss: 3.4257296098320684
Validation loss: 3.1658363068572895

Epoch: 6| Step: 11
Training loss: 3.5222807548090542
Validation loss: 3.16179582294255

Epoch: 6| Step: 12
Training loss: 2.8931367426180907
Validation loss: 3.1599891474726842

Epoch: 6| Step: 13
Training loss: 3.904526108867331
Validation loss: 3.157624086811362

Epoch: 33| Step: 0
Training loss: 3.289516245516444
Validation loss: 3.1576521780498976

Epoch: 6| Step: 1
Training loss: 3.141982359333404
Validation loss: 3.1560009322311475

Epoch: 6| Step: 2
Training loss: 3.1625070021480197
Validation loss: 3.155286945995796

Epoch: 6| Step: 3
Training loss: 3.390214886451648
Validation loss: 3.1537510187663593

Epoch: 6| Step: 4
Training loss: 2.8987245648885613
Validation loss: 3.152416060025319

Epoch: 6| Step: 5
Training loss: 2.8389127063021693
Validation loss: 3.1518627155067787

Epoch: 6| Step: 6
Training loss: 3.6503494774717424
Validation loss: 3.150748368053146

Epoch: 6| Step: 7
Training loss: 3.843357717453779
Validation loss: 3.1500087123293956

Epoch: 6| Step: 8
Training loss: 3.3571017358458675
Validation loss: 3.1491330926832775

Epoch: 6| Step: 9
Training loss: 3.5344742090684877
Validation loss: 3.147862477068673

Epoch: 6| Step: 10
Training loss: 4.010557071490398
Validation loss: 3.1465380153128453

Epoch: 6| Step: 11
Training loss: 3.9520557751831755
Validation loss: 3.146662508220681

Epoch: 6| Step: 12
Training loss: 3.791482494758039
Validation loss: 3.145912563567922

Epoch: 6| Step: 13
Training loss: 1.6792682213123362
Validation loss: 3.1472706978879095

Epoch: 34| Step: 0
Training loss: 3.2142609337956527
Validation loss: 3.149839475415153

Epoch: 6| Step: 1
Training loss: 3.0538875381158004
Validation loss: 3.1477725897057813

Epoch: 6| Step: 2
Training loss: 3.4575095670158107
Validation loss: 3.1449556099398577

Epoch: 6| Step: 3
Training loss: 3.0144125917524014
Validation loss: 3.144430145164873

Epoch: 6| Step: 4
Training loss: 3.660854081731072
Validation loss: 3.1442488475069905

Epoch: 6| Step: 5
Training loss: 3.824180969114
Validation loss: 3.1427738758382584

Epoch: 6| Step: 6
Training loss: 4.165918791727997
Validation loss: 3.1404531578086115

Epoch: 6| Step: 7
Training loss: 3.558286350008558
Validation loss: 3.1390927737645438

Epoch: 6| Step: 8
Training loss: 3.618486010684784
Validation loss: 3.1390558105185784

Epoch: 6| Step: 9
Training loss: 3.0730518031174734
Validation loss: 3.138045374201148

Epoch: 6| Step: 10
Training loss: 3.38331483983089
Validation loss: 3.135865841839234

Epoch: 6| Step: 11
Training loss: 3.1835760759670446
Validation loss: 3.1348756674945606

Epoch: 6| Step: 12
Training loss: 2.6755604450980983
Validation loss: 3.1343322967580174

Epoch: 6| Step: 13
Training loss: 3.5434349283299382
Validation loss: 3.134904167020383

Epoch: 35| Step: 0
Training loss: 2.965917098972268
Validation loss: 3.1332361708504153

Epoch: 6| Step: 1
Training loss: 3.5647934340972975
Validation loss: 3.13261527559016

Epoch: 6| Step: 2
Training loss: 2.986080620977201
Validation loss: 3.1333803178811754

Epoch: 6| Step: 3
Training loss: 3.6404304943598547
Validation loss: 3.130879837487276

Epoch: 6| Step: 4
Training loss: 3.1056014122607456
Validation loss: 3.135550442178432

Epoch: 6| Step: 5
Training loss: 3.7861382280477778
Validation loss: 3.1333785751766463

Epoch: 6| Step: 6
Training loss: 3.304168876913389
Validation loss: 3.1353946012233522

Epoch: 6| Step: 7
Training loss: 3.0762788299858865
Validation loss: 3.133193803725068

Epoch: 6| Step: 8
Training loss: 3.799721612269708
Validation loss: 3.130316227626286

Epoch: 6| Step: 9
Training loss: 2.524027091199814
Validation loss: 3.127269718008656

Epoch: 6| Step: 10
Training loss: 4.302846303653689
Validation loss: 3.1252671273203836

Epoch: 6| Step: 11
Training loss: 3.090154851594971
Validation loss: 3.126257309192376

Epoch: 6| Step: 12
Training loss: 3.2716674389079565
Validation loss: 3.1257973750906407

Epoch: 6| Step: 13
Training loss: 3.861028155038689
Validation loss: 3.1247571264249334

Epoch: 36| Step: 0
Training loss: 2.90499834569467
Validation loss: 3.121821316429288

Epoch: 6| Step: 1
Training loss: 3.24490646885826
Validation loss: 3.1228299422316597

Epoch: 6| Step: 2
Training loss: 3.0318458207518644
Validation loss: 3.1218900862706636

Epoch: 6| Step: 3
Training loss: 2.664054982462817
Validation loss: 3.121766633864072

Epoch: 6| Step: 4
Training loss: 3.4946059487007024
Validation loss: 3.1199689322361244

Epoch: 6| Step: 5
Training loss: 2.25080581646336
Validation loss: 3.119035088830459

Epoch: 6| Step: 6
Training loss: 3.708330704477357
Validation loss: 3.1195070848173883

Epoch: 6| Step: 7
Training loss: 4.1519006903647595
Validation loss: 3.1180910617495528

Epoch: 6| Step: 8
Training loss: 3.6360964135038962
Validation loss: 3.1180554865218704

Epoch: 6| Step: 9
Training loss: 3.2149463882841056
Validation loss: 3.1175680356679916

Epoch: 6| Step: 10
Training loss: 3.1070069156467857
Validation loss: 3.1172503767452726

Epoch: 6| Step: 11
Training loss: 3.259757725892916
Validation loss: 3.1155642481619195

Epoch: 6| Step: 12
Training loss: 4.226998861918715
Validation loss: 3.1152999936339403

Epoch: 6| Step: 13
Training loss: 4.16801222373649
Validation loss: 3.114531074821097

Epoch: 37| Step: 0
Training loss: 2.5946602200894904
Validation loss: 3.1143825091884234

Epoch: 6| Step: 1
Training loss: 3.6231834858847125
Validation loss: 3.111602323499061

Epoch: 6| Step: 2
Training loss: 3.4449966528091447
Validation loss: 3.1112449820331807

Epoch: 6| Step: 3
Training loss: 2.6184099217833814
Validation loss: 3.110884786087437

Epoch: 6| Step: 4
Training loss: 3.1026337356699525
Validation loss: 3.1095491351162545

Epoch: 6| Step: 5
Training loss: 3.8461210799655503
Validation loss: 3.1108540128673763

Epoch: 6| Step: 6
Training loss: 3.0095862769001105
Validation loss: 3.108404677525521

Epoch: 6| Step: 7
Training loss: 3.957313218760546
Validation loss: 3.109361125494395

Epoch: 6| Step: 8
Training loss: 3.15665954350034
Validation loss: 3.1064810347160208

Epoch: 6| Step: 9
Training loss: 3.9866787103536954
Validation loss: 3.1037106297022983

Epoch: 6| Step: 10
Training loss: 4.0234273077085705
Validation loss: 3.104947522902449

Epoch: 6| Step: 11
Training loss: 2.905653041114323
Validation loss: 3.1061513623016457

Epoch: 6| Step: 12
Training loss: 3.3110456332901816
Validation loss: 3.106799953197592

Epoch: 6| Step: 13
Training loss: 3.0018262073142172
Validation loss: 3.1047310083207864

Epoch: 38| Step: 0
Training loss: 3.1731432554340873
Validation loss: 3.1047925519768405

Epoch: 6| Step: 1
Training loss: 3.0998785794997845
Validation loss: 3.103411929131212

Epoch: 6| Step: 2
Training loss: 3.8014877619297374
Validation loss: 3.1012020887873915

Epoch: 6| Step: 3
Training loss: 2.999107069006498
Validation loss: 3.1001934099348247

Epoch: 6| Step: 4
Training loss: 3.327898331207918
Validation loss: 3.0986511273983646

Epoch: 6| Step: 5
Training loss: 3.250800694354999
Validation loss: 3.096904390748867

Epoch: 6| Step: 6
Training loss: 3.539191439471317
Validation loss: 3.0963973138394234

Epoch: 6| Step: 7
Training loss: 2.4832781403657167
Validation loss: 3.0968867815779793

Epoch: 6| Step: 8
Training loss: 3.0379272537210906
Validation loss: 3.097592569986238

Epoch: 6| Step: 9
Training loss: 3.819359034344315
Validation loss: 3.0971997367206625

Epoch: 6| Step: 10
Training loss: 3.696686761341108
Validation loss: 3.0947650890237886

Epoch: 6| Step: 11
Training loss: 3.4341455912311667
Validation loss: 3.0941554077659807

Epoch: 6| Step: 12
Training loss: 3.894408198242523
Validation loss: 3.093603424647184

Epoch: 6| Step: 13
Training loss: 3.1673499089715076
Validation loss: 3.091739225242342

Epoch: 39| Step: 0
Training loss: 4.166959116527134
Validation loss: 3.0903976332077887

Epoch: 6| Step: 1
Training loss: 2.691317840585756
Validation loss: 3.089575524842646

Epoch: 6| Step: 2
Training loss: 2.9505429560254774
Validation loss: 3.0883999917765106

Epoch: 6| Step: 3
Training loss: 3.7896549351607054
Validation loss: 3.087319281785383

Epoch: 6| Step: 4
Training loss: 3.379330717558258
Validation loss: 3.0866790740280847

Epoch: 6| Step: 5
Training loss: 3.4008112893156994
Validation loss: 3.084088842115822

Epoch: 6| Step: 6
Training loss: 3.35288537867742
Validation loss: 3.08407371254594

Epoch: 6| Step: 7
Training loss: 3.1522047350175852
Validation loss: 3.0835483634574916

Epoch: 6| Step: 8
Training loss: 3.1566445887705594
Validation loss: 3.0842716396252685

Epoch: 6| Step: 9
Training loss: 3.2323947317591486
Validation loss: 3.0839368589267013

Epoch: 6| Step: 10
Training loss: 3.5815020620640228
Validation loss: 3.0822808787287785

Epoch: 6| Step: 11
Training loss: 3.1471747428931693
Validation loss: 3.081184438793252

Epoch: 6| Step: 12
Training loss: 3.8343803523864946
Validation loss: 3.081182475199722

Epoch: 6| Step: 13
Training loss: 2.2369513963271594
Validation loss: 3.078903940037797

Epoch: 40| Step: 0
Training loss: 3.5801361961670493
Validation loss: 3.0796227703483265

Epoch: 6| Step: 1
Training loss: 2.5162414364164483
Validation loss: 3.0828663977673583

Epoch: 6| Step: 2
Training loss: 3.2161155215339456
Validation loss: 3.0793880363478845

Epoch: 6| Step: 3
Training loss: 3.024207202019172
Validation loss: 3.0757241887734827

Epoch: 6| Step: 4
Training loss: 3.352415176445004
Validation loss: 3.077819175221415

Epoch: 6| Step: 5
Training loss: 2.2210413961181055
Validation loss: 3.0833765621087186

Epoch: 6| Step: 6
Training loss: 2.9406669265077015
Validation loss: 3.1147687226242833

Epoch: 6| Step: 7
Training loss: 4.14737873251915
Validation loss: 3.094043975018669

Epoch: 6| Step: 8
Training loss: 3.538869823069759
Validation loss: 3.0806829154859066

Epoch: 6| Step: 9
Training loss: 3.307726605669151
Validation loss: 3.079747039726666

Epoch: 6| Step: 10
Training loss: 4.226566110211027
Validation loss: 3.078317052699519

Epoch: 6| Step: 11
Training loss: 3.807512867455584
Validation loss: 3.077493124999049

Epoch: 6| Step: 12
Training loss: 3.4849792777585136
Validation loss: 3.0805582053457057

Epoch: 6| Step: 13
Training loss: 2.7120085697376255
Validation loss: 3.082340393778027

Epoch: 41| Step: 0
Training loss: 4.192335838056481
Validation loss: 3.082519906749219

Epoch: 6| Step: 1
Training loss: 2.918022349323655
Validation loss: 3.0989964873785683

Epoch: 6| Step: 2
Training loss: 3.6126205582615003
Validation loss: 3.0707070197036033

Epoch: 6| Step: 3
Training loss: 2.8589277073945745
Validation loss: 3.0691605949893646

Epoch: 6| Step: 4
Training loss: 3.080953779548052
Validation loss: 3.079695031399361

Epoch: 6| Step: 5
Training loss: 2.575369084397015
Validation loss: 3.119510419718658

Epoch: 6| Step: 6
Training loss: 3.7298851954815135
Validation loss: 3.155583362727873

Epoch: 6| Step: 7
Training loss: 3.8519407013144518
Validation loss: 3.1023878336023447

Epoch: 6| Step: 8
Training loss: 3.639274379381534
Validation loss: 3.069041710804181

Epoch: 6| Step: 9
Training loss: 2.381258097957749
Validation loss: 3.0666490366599723

Epoch: 6| Step: 10
Training loss: 3.90958085528222
Validation loss: 3.06610253478982

Epoch: 6| Step: 11
Training loss: 3.432670390990605
Validation loss: 3.064869827450197

Epoch: 6| Step: 12
Training loss: 3.3360628555651854
Validation loss: 3.0656304046702636

Epoch: 6| Step: 13
Training loss: 2.5844386617621886
Validation loss: 3.0680682917211746

Epoch: 42| Step: 0
Training loss: 3.2138200059207644
Validation loss: 3.075722801815902

Epoch: 6| Step: 1
Training loss: 3.504546618340534
Validation loss: 3.1036022105561867

Epoch: 6| Step: 2
Training loss: 3.6978258291916766
Validation loss: 3.0874319329011035

Epoch: 6| Step: 3
Training loss: 3.8210688117349667
Validation loss: 3.077695446900709

Epoch: 6| Step: 4
Training loss: 4.015311499800443
Validation loss: 3.0673410101128895

Epoch: 6| Step: 5
Training loss: 3.025036293001228
Validation loss: 3.0605924993093305

Epoch: 6| Step: 6
Training loss: 3.035501546377719
Validation loss: 3.0620005026352923

Epoch: 6| Step: 7
Training loss: 3.469473960865611
Validation loss: 3.058259695891762

Epoch: 6| Step: 8
Training loss: 3.1301803376040254
Validation loss: 3.0584400614944762

Epoch: 6| Step: 9
Training loss: 3.713889142758204
Validation loss: 3.058080937602938

Epoch: 6| Step: 10
Training loss: 2.8666276515109574
Validation loss: 3.057533632064843

Epoch: 6| Step: 11
Training loss: 2.293745958704078
Validation loss: 3.0571778062693244

Epoch: 6| Step: 12
Training loss: 2.945436510465404
Validation loss: 3.055008916785286

Epoch: 6| Step: 13
Training loss: 3.6628893700591725
Validation loss: 3.0537919195432512

Epoch: 43| Step: 0
Training loss: 3.4962343667164646
Validation loss: 3.0540772091639865

Epoch: 6| Step: 1
Training loss: 4.318369533711479
Validation loss: 3.051645695185107

Epoch: 6| Step: 2
Training loss: 2.8106811576188613
Validation loss: 3.0522608338795028

Epoch: 6| Step: 3
Training loss: 2.448257574056656
Validation loss: 3.0520829085914234

Epoch: 6| Step: 4
Training loss: 3.3559355405543707
Validation loss: 3.050736224338935

Epoch: 6| Step: 5
Training loss: 3.303383716567277
Validation loss: 3.0496702747590634

Epoch: 6| Step: 6
Training loss: 2.727193152827348
Validation loss: 3.04923260948349

Epoch: 6| Step: 7
Training loss: 3.162546204240741
Validation loss: 3.0489794459519843

Epoch: 6| Step: 8
Training loss: 4.268127154686155
Validation loss: 3.047128067466193

Epoch: 6| Step: 9
Training loss: 3.489111448047972
Validation loss: 3.0469099313623054

Epoch: 6| Step: 10
Training loss: 3.02927672664157
Validation loss: 3.0464862955223593

Epoch: 6| Step: 11
Training loss: 3.1206231556204496
Validation loss: 3.0460107949752073

Epoch: 6| Step: 12
Training loss: 3.546160520944817
Validation loss: 3.043535600381447

Epoch: 6| Step: 13
Training loss: 2.439076525142602
Validation loss: 3.0415724628631007

Epoch: 44| Step: 0
Training loss: 2.6653714809629747
Validation loss: 3.039039342420693

Epoch: 6| Step: 1
Training loss: 3.222007510460045
Validation loss: 3.038317088630914

Epoch: 6| Step: 2
Training loss: 3.367149264302196
Validation loss: 3.0431603188911853

Epoch: 6| Step: 3
Training loss: 3.6040931797069637
Validation loss: 3.042204275141383

Epoch: 6| Step: 4
Training loss: 3.5793177852916984
Validation loss: 3.0443803046887075

Epoch: 6| Step: 5
Training loss: 3.2444566254699203
Validation loss: 3.0393418532889473

Epoch: 6| Step: 6
Training loss: 3.2087512218917347
Validation loss: 3.036614511616352

Epoch: 6| Step: 7
Training loss: 2.8068590178764112
Validation loss: 3.0338798712339896

Epoch: 6| Step: 8
Training loss: 2.9338944404194938
Validation loss: 3.0310592346076315

Epoch: 6| Step: 9
Training loss: 3.5700031705783473
Validation loss: 3.029886798258172

Epoch: 6| Step: 10
Training loss: 4.199638423796149
Validation loss: 3.031459190931996

Epoch: 6| Step: 11
Training loss: 2.889904530410175
Validation loss: 3.028070300852388

Epoch: 6| Step: 12
Training loss: 2.950932087172707
Validation loss: 3.029492959056599

Epoch: 6| Step: 13
Training loss: 4.016397958423045
Validation loss: 3.0277028161230843

Epoch: 45| Step: 0
Training loss: 3.3083745350101776
Validation loss: 3.0264152347241366

Epoch: 6| Step: 1
Training loss: 2.9709228594872545
Validation loss: 3.0262190274890752

Epoch: 6| Step: 2
Training loss: 4.078971921008166
Validation loss: 3.0354697758328397

Epoch: 6| Step: 3
Training loss: 4.281121690595526
Validation loss: 3.035852172531348

Epoch: 6| Step: 4
Training loss: 2.65137546039225
Validation loss: 3.0378741766930615

Epoch: 6| Step: 5
Training loss: 3.706918310730189
Validation loss: 3.028496717636497

Epoch: 6| Step: 6
Training loss: 3.4245920759764688
Validation loss: 3.0249972758784716

Epoch: 6| Step: 7
Training loss: 2.3392474858811787
Validation loss: 3.020200580074276

Epoch: 6| Step: 8
Training loss: 3.367243011795894
Validation loss: 3.020133121003746

Epoch: 6| Step: 9
Training loss: 3.4962818286962203
Validation loss: 3.022024142443925

Epoch: 6| Step: 10
Training loss: 3.3428914046249294
Validation loss: 3.0212017905336563

Epoch: 6| Step: 11
Training loss: 3.0668462935651815
Validation loss: 3.020927618391967

Epoch: 6| Step: 12
Training loss: 2.618190288590206
Validation loss: 3.021271338584356

Epoch: 6| Step: 13
Training loss: 2.641687664666542
Validation loss: 3.019691021037482

Epoch: 46| Step: 0
Training loss: 3.4618920243480487
Validation loss: 3.020030102785199

Epoch: 6| Step: 1
Training loss: 3.110251911668977
Validation loss: 3.019583082190016

Epoch: 6| Step: 2
Training loss: 2.9153480455486904
Validation loss: 3.0180998222749937

Epoch: 6| Step: 3
Training loss: 3.2365360135685908
Validation loss: 3.0167260722695755

Epoch: 6| Step: 4
Training loss: 3.103366893855907
Validation loss: 3.0155045926671615

Epoch: 6| Step: 5
Training loss: 4.02335501280735
Validation loss: 3.0151527949384502

Epoch: 6| Step: 6
Training loss: 3.135010972924019
Validation loss: 3.0121881741525476

Epoch: 6| Step: 7
Training loss: 2.606534039504698
Validation loss: 3.0105573335530895

Epoch: 6| Step: 8
Training loss: 3.1566158875755432
Validation loss: 3.010606573187952

Epoch: 6| Step: 9
Training loss: 3.459014702894995
Validation loss: 3.0111573185999267

Epoch: 6| Step: 10
Training loss: 2.770450842899907
Validation loss: 3.0069227910248344

Epoch: 6| Step: 11
Training loss: 3.3867094574375107
Validation loss: 3.009064699331913

Epoch: 6| Step: 12
Training loss: 3.5643921227656734
Validation loss: 3.0080989382166887

Epoch: 6| Step: 13
Training loss: 4.190232026224055
Validation loss: 3.0060422024131226

Epoch: 47| Step: 0
Training loss: 4.016392972071273
Validation loss: 3.0052469610447052

Epoch: 6| Step: 1
Training loss: 3.3157896585233377
Validation loss: 3.0049673610018512

Epoch: 6| Step: 2
Training loss: 3.3543183349690544
Validation loss: 3.0040211560829513

Epoch: 6| Step: 3
Training loss: 3.3483336218502617
Validation loss: 3.003310973429368

Epoch: 6| Step: 4
Training loss: 3.2291694066846155
Validation loss: 3.0026456095414815

Epoch: 6| Step: 5
Training loss: 3.317468623549785
Validation loss: 3.0078376239461924

Epoch: 6| Step: 6
Training loss: 3.307632757104631
Validation loss: 3.001199593543688

Epoch: 6| Step: 7
Training loss: 2.736868979827887
Validation loss: 3.002450128762558

Epoch: 6| Step: 8
Training loss: 3.083682856638657
Validation loss: 2.9985568034415078

Epoch: 6| Step: 9
Training loss: 3.212818643523072
Validation loss: 2.9991638272760524

Epoch: 6| Step: 10
Training loss: 3.5003236893429985
Validation loss: 3.0009752157449405

Epoch: 6| Step: 11
Training loss: 2.899027720607983
Validation loss: 2.9982013574543007

Epoch: 6| Step: 12
Training loss: 3.3145613104765768
Validation loss: 2.9993437686788202

Epoch: 6| Step: 13
Training loss: 2.9585099145189018
Validation loss: 2.9987563218115425

Epoch: 48| Step: 0
Training loss: 3.5051748983631663
Validation loss: 2.9982053916224363

Epoch: 6| Step: 1
Training loss: 3.2941731595522943
Validation loss: 2.9979881356490052

Epoch: 6| Step: 2
Training loss: 3.185085054995573
Validation loss: 2.9975667437759164

Epoch: 6| Step: 3
Training loss: 3.6021508255580246
Validation loss: 2.997978704511935

Epoch: 6| Step: 4
Training loss: 3.445467506433724
Validation loss: 2.996166300619515

Epoch: 6| Step: 5
Training loss: 3.131232493460137
Validation loss: 2.992981536240304

Epoch: 6| Step: 6
Training loss: 2.5682145574666446
Validation loss: 2.9936542101835

Epoch: 6| Step: 7
Training loss: 3.391127307442645
Validation loss: 2.992724408355251

Epoch: 6| Step: 8
Training loss: 2.9272405145510842
Validation loss: 2.991360522055278

Epoch: 6| Step: 9
Training loss: 3.3625198193501347
Validation loss: 2.9922421919283515

Epoch: 6| Step: 10
Training loss: 2.529347210828764
Validation loss: 2.989498390333609

Epoch: 6| Step: 11
Training loss: 3.0232244214422432
Validation loss: 2.9880978703825027

Epoch: 6| Step: 12
Training loss: 3.9154000500044317
Validation loss: 2.987281662482293

Epoch: 6| Step: 13
Training loss: 3.874690012684495
Validation loss: 2.988795529349579

Epoch: 49| Step: 0
Training loss: 2.9985241438615766
Validation loss: 2.9914699754289553

Epoch: 6| Step: 1
Training loss: 3.903045682811286
Validation loss: 2.9913500330311313

Epoch: 6| Step: 2
Training loss: 2.9908146111501197
Validation loss: 2.9859159829547273

Epoch: 6| Step: 3
Training loss: 3.333315245261389
Validation loss: 2.9838511608500715

Epoch: 6| Step: 4
Training loss: 3.2809055692552502
Validation loss: 2.9836641450878867

Epoch: 6| Step: 5
Training loss: 1.9248662481039038
Validation loss: 2.9814006559338337

Epoch: 6| Step: 6
Training loss: 3.1838378812644974
Validation loss: 2.9826637880884244

Epoch: 6| Step: 7
Training loss: 3.4927595723928655
Validation loss: 2.982058144130085

Epoch: 6| Step: 8
Training loss: 3.12344474238233
Validation loss: 2.9831827362743986

Epoch: 6| Step: 9
Training loss: 3.9888151672644137
Validation loss: 2.9831701293740123

Epoch: 6| Step: 10
Training loss: 3.5670279120873656
Validation loss: 2.982417222070882

Epoch: 6| Step: 11
Training loss: 3.217987118284476
Validation loss: 2.98247024852878

Epoch: 6| Step: 12
Training loss: 3.328951021227768
Validation loss: 2.981798319518174

Epoch: 6| Step: 13
Training loss: 2.6944241593985776
Validation loss: 2.98102047450015

Epoch: 50| Step: 0
Training loss: 2.5669150116734563
Validation loss: 2.9801286104863163

Epoch: 6| Step: 1
Training loss: 3.560982364172732
Validation loss: 2.979721350433785

Epoch: 6| Step: 2
Training loss: 3.722709535295453
Validation loss: 2.980028267243418

Epoch: 6| Step: 3
Training loss: 3.2995143648642165
Validation loss: 2.978535080443907

Epoch: 6| Step: 4
Training loss: 3.4942743607372146
Validation loss: 2.980245977417615

Epoch: 6| Step: 5
Training loss: 3.0662137305209747
Validation loss: 2.9787108519165266

Epoch: 6| Step: 6
Training loss: 3.3833092023117346
Validation loss: 2.9822161558200078

Epoch: 6| Step: 7
Training loss: 3.2423744239696317
Validation loss: 2.98448891087566

Epoch: 6| Step: 8
Training loss: 2.2518703316442426
Validation loss: 2.9845116121283923

Epoch: 6| Step: 9
Training loss: 4.21097826539869
Validation loss: 2.9862049713480827

Epoch: 6| Step: 10
Training loss: 3.374633910492543
Validation loss: 2.9875917859007273

Epoch: 6| Step: 11
Training loss: 3.274745779872161
Validation loss: 2.9882257923822224

Epoch: 6| Step: 12
Training loss: 2.7343595667812233
Validation loss: 2.9743545107716742

Epoch: 6| Step: 13
Training loss: 2.9040317068024186
Validation loss: 2.973367897538931

Epoch: 51| Step: 0
Training loss: 3.6813135786022717
Validation loss: 2.972576766025228

Epoch: 6| Step: 1
Training loss: 3.2257016860192604
Validation loss: 2.97197308622442

Epoch: 6| Step: 2
Training loss: 3.380443844969068
Validation loss: 2.9708815913671853

Epoch: 6| Step: 3
Training loss: 3.2589252867560807
Validation loss: 2.970266327755309

Epoch: 6| Step: 4
Training loss: 3.730997385646259
Validation loss: 2.9686769935253627

Epoch: 6| Step: 5
Training loss: 3.3272649522359847
Validation loss: 2.967452076731443

Epoch: 6| Step: 6
Training loss: 3.235376470201059
Validation loss: 2.9679499516921055

Epoch: 6| Step: 7
Training loss: 2.756172535471625
Validation loss: 2.9655392964313143

Epoch: 6| Step: 8
Training loss: 3.545207030541982
Validation loss: 2.984480149183576

Epoch: 6| Step: 9
Training loss: 3.332185229626501
Validation loss: 2.9884505119217644

Epoch: 6| Step: 10
Training loss: 2.5299352363167866
Validation loss: 2.9788001210970556

Epoch: 6| Step: 11
Training loss: 3.4316094993608344
Validation loss: 2.9717434034317654

Epoch: 6| Step: 12
Training loss: 3.1371328192219488
Validation loss: 2.968278622296448

Epoch: 6| Step: 13
Training loss: 2.2867975584368425
Validation loss: 2.961813307305446

Epoch: 52| Step: 0
Training loss: 3.718330167264344
Validation loss: 2.9616873182416645

Epoch: 6| Step: 1
Training loss: 3.3785102391671433
Validation loss: 2.9616612479445013

Epoch: 6| Step: 2
Training loss: 3.26330717778334
Validation loss: 2.9593281610670528

Epoch: 6| Step: 3
Training loss: 3.1908273720521616
Validation loss: 2.957364717698895

Epoch: 6| Step: 4
Training loss: 3.389049814568957
Validation loss: 2.95809939122545

Epoch: 6| Step: 5
Training loss: 3.0715501925953164
Validation loss: 2.9566980464289454

Epoch: 6| Step: 6
Training loss: 3.076028952533004
Validation loss: 2.9570751041988053

Epoch: 6| Step: 7
Training loss: 2.809430884971264
Validation loss: 2.954219106940631

Epoch: 6| Step: 8
Training loss: 3.533318378008975
Validation loss: 2.9552891945037185

Epoch: 6| Step: 9
Training loss: 2.902077253179669
Validation loss: 2.956089757177674

Epoch: 6| Step: 10
Training loss: 3.240004500868697
Validation loss: 2.952197980943142

Epoch: 6| Step: 11
Training loss: 2.9733853743008902
Validation loss: 2.954784044702795

Epoch: 6| Step: 12
Training loss: 3.396549515979703
Validation loss: 2.9512022614673286

Epoch: 6| Step: 13
Training loss: 3.3891734870546246
Validation loss: 2.95138781018914

Epoch: 53| Step: 0
Training loss: 3.060573984304794
Validation loss: 2.9510638545695365

Epoch: 6| Step: 1
Training loss: 3.0597219517860132
Validation loss: 2.9496811883762515

Epoch: 6| Step: 2
Training loss: 3.5482613295139935
Validation loss: 2.948306566455654

Epoch: 6| Step: 3
Training loss: 2.1540727542006106
Validation loss: 2.9503009542863476

Epoch: 6| Step: 4
Training loss: 2.945651492738882
Validation loss: 2.948520938643823

Epoch: 6| Step: 5
Training loss: 3.358928704002843
Validation loss: 2.9678633233081646

Epoch: 6| Step: 6
Training loss: 3.292660156850127
Validation loss: 2.974049384121945

Epoch: 6| Step: 7
Training loss: 2.651427614988192
Validation loss: 2.97066336491612

Epoch: 6| Step: 8
Training loss: 4.072944244265385
Validation loss: 2.957965473237709

Epoch: 6| Step: 9
Training loss: 2.681025668632111
Validation loss: 2.9436267885607905

Epoch: 6| Step: 10
Training loss: 3.3670567887640694
Validation loss: 2.944430327102686

Epoch: 6| Step: 11
Training loss: 2.7447195508098194
Validation loss: 2.9450936576555224

Epoch: 6| Step: 12
Training loss: 4.274596899112517
Validation loss: 2.946458236103924

Epoch: 6| Step: 13
Training loss: 3.7504357402683657
Validation loss: 2.9455884622110053

Epoch: 54| Step: 0
Training loss: 3.7422026631918137
Validation loss: 2.9461211966267533

Epoch: 6| Step: 1
Training loss: 3.0671709212769915
Validation loss: 2.9458622272941026

Epoch: 6| Step: 2
Training loss: 2.9453500598566644
Validation loss: 2.9434620665759166

Epoch: 6| Step: 3
Training loss: 3.153742785844327
Validation loss: 2.9416440656169605

Epoch: 6| Step: 4
Training loss: 3.4654175843343147
Validation loss: 2.939863278450444

Epoch: 6| Step: 5
Training loss: 3.306802131687768
Validation loss: 2.938084221568367

Epoch: 6| Step: 6
Training loss: 3.44051991370655
Validation loss: 2.938515202555418

Epoch: 6| Step: 7
Training loss: 3.2837401614061723
Validation loss: 2.9365877503564386

Epoch: 6| Step: 8
Training loss: 3.51727934166241
Validation loss: 2.936661420142844

Epoch: 6| Step: 9
Training loss: 3.007200183716789
Validation loss: 2.9366177063201504

Epoch: 6| Step: 10
Training loss: 3.365991650004918
Validation loss: 2.932532149356166

Epoch: 6| Step: 11
Training loss: 2.1441080756348176
Validation loss: 2.9337213789773378

Epoch: 6| Step: 12
Training loss: 3.291837631485707
Validation loss: 2.93552694251893

Epoch: 6| Step: 13
Training loss: 3.157564097378347
Validation loss: 2.934382975230009

Epoch: 55| Step: 0
Training loss: 2.942418465080217
Validation loss: 2.9341996048789865

Epoch: 6| Step: 1
Training loss: 2.8934839904985625
Validation loss: 2.933784085110119

Epoch: 6| Step: 2
Training loss: 2.527381012301381
Validation loss: 2.9338821302816287

Epoch: 6| Step: 3
Training loss: 3.8823250478024676
Validation loss: 2.9340050091464476

Epoch: 6| Step: 4
Training loss: 3.6510319439826113
Validation loss: 2.93187283036583

Epoch: 6| Step: 5
Training loss: 3.3451282833572615
Validation loss: 2.9301084530755444

Epoch: 6| Step: 6
Training loss: 3.1093559839635225
Validation loss: 2.929100712685537

Epoch: 6| Step: 7
Training loss: 3.201973908307946
Validation loss: 2.9263856666761177

Epoch: 6| Step: 8
Training loss: 3.4687211319005677
Validation loss: 2.9263030073166347

Epoch: 6| Step: 9
Training loss: 2.7643496918905135
Validation loss: 2.9279488297121614

Epoch: 6| Step: 10
Training loss: 3.1339053105386516
Validation loss: 2.9283883715841705

Epoch: 6| Step: 11
Training loss: 3.5039987881453696
Validation loss: 2.9269231881568323

Epoch: 6| Step: 12
Training loss: 3.5080313497467013
Validation loss: 2.9262635647140534

Epoch: 6| Step: 13
Training loss: 2.7183308771599064
Validation loss: 2.927354218460512

Epoch: 56| Step: 0
Training loss: 2.6734510090328896
Validation loss: 2.923200250495392

Epoch: 6| Step: 1
Training loss: 3.1220987203508956
Validation loss: 2.924043016127206

Epoch: 6| Step: 2
Training loss: 3.527260205873182
Validation loss: 2.9222898949301426

Epoch: 6| Step: 3
Training loss: 3.097826189380123
Validation loss: 2.9214671316774727

Epoch: 6| Step: 4
Training loss: 3.4054024018004796
Validation loss: 2.921186723068677

Epoch: 6| Step: 5
Training loss: 3.0665906717034015
Validation loss: 2.9209122048983187

Epoch: 6| Step: 6
Training loss: 3.673152360514032
Validation loss: 2.9231105366131307

Epoch: 6| Step: 7
Training loss: 3.1336413117144404
Validation loss: 2.924509298671417

Epoch: 6| Step: 8
Training loss: 3.623375232551371
Validation loss: 2.9226915781200704

Epoch: 6| Step: 9
Training loss: 3.3441324460936954
Validation loss: 2.9232315723094735

Epoch: 6| Step: 10
Training loss: 3.1832407000846312
Validation loss: 2.926401098138636

Epoch: 6| Step: 11
Training loss: 2.808911895771743
Validation loss: 2.9224367407299443

Epoch: 6| Step: 12
Training loss: 3.0275800059021845
Validation loss: 2.9177760916264184

Epoch: 6| Step: 13
Training loss: 3.006071939568209
Validation loss: 2.9180629277004444

Epoch: 57| Step: 0
Training loss: 2.8541632510719372
Validation loss: 2.915257024205937

Epoch: 6| Step: 1
Training loss: 3.4470310206997
Validation loss: 2.9153484052069336

Epoch: 6| Step: 2
Training loss: 3.3641607217938545
Validation loss: 2.91270007296976

Epoch: 6| Step: 3
Training loss: 3.711169811807365
Validation loss: 2.912944862324934

Epoch: 6| Step: 4
Training loss: 3.542938064055371
Validation loss: 2.9149362024691494

Epoch: 6| Step: 5
Training loss: 2.6768400227650524
Validation loss: 2.914896350124483

Epoch: 6| Step: 6
Training loss: 2.939550779627857
Validation loss: 2.9143319490744135

Epoch: 6| Step: 7
Training loss: 3.1027858829269106
Validation loss: 2.9133861029131083

Epoch: 6| Step: 8
Training loss: 2.761728936895551
Validation loss: 2.9139840782086908

Epoch: 6| Step: 9
Training loss: 3.5615111199917244
Validation loss: 2.9128512091575534

Epoch: 6| Step: 10
Training loss: 3.397736996769872
Validation loss: 2.9124852040282185

Epoch: 6| Step: 11
Training loss: 3.1987125429417764
Validation loss: 2.9132925545682142

Epoch: 6| Step: 12
Training loss: 3.257157001369044
Validation loss: 2.9115703522397016

Epoch: 6| Step: 13
Training loss: 2.538083119407343
Validation loss: 2.9119515234717004

Epoch: 58| Step: 0
Training loss: 3.105010223126129
Validation loss: 2.9103679506478617

Epoch: 6| Step: 1
Training loss: 3.560997227715621
Validation loss: 2.9093991499651097

Epoch: 6| Step: 2
Training loss: 2.7774738007690982
Validation loss: 2.9087785766508714

Epoch: 6| Step: 3
Training loss: 2.6580264266101845
Validation loss: 2.908710783600698

Epoch: 6| Step: 4
Training loss: 3.769798403745592
Validation loss: 2.9108239289369835

Epoch: 6| Step: 5
Training loss: 3.592841522824223
Validation loss: 2.908276364325936

Epoch: 6| Step: 6
Training loss: 2.9577511675763595
Validation loss: 2.9103046756808775

Epoch: 6| Step: 7
Training loss: 3.1417017367266533
Validation loss: 2.9113280212331265

Epoch: 6| Step: 8
Training loss: 2.711245736399737
Validation loss: 2.913756585888435

Epoch: 6| Step: 9
Training loss: 3.607996293347267
Validation loss: 2.911832088771469

Epoch: 6| Step: 10
Training loss: 3.106529275478391
Validation loss: 2.909845364169873

Epoch: 6| Step: 11
Training loss: 3.219483523442051
Validation loss: 2.9094006602697062

Epoch: 6| Step: 12
Training loss: 3.394942106222439
Validation loss: 2.9083020493096243

Epoch: 6| Step: 13
Training loss: 2.8364349853660484
Validation loss: 2.9031961878766297

Epoch: 59| Step: 0
Training loss: 2.877718925201587
Validation loss: 2.903275435290124

Epoch: 6| Step: 1
Training loss: 3.5984948720594674
Validation loss: 2.903116478223047

Epoch: 6| Step: 2
Training loss: 3.0932945147358697
Validation loss: 2.9007657231113066

Epoch: 6| Step: 3
Training loss: 3.5717377937510433
Validation loss: 2.9001767463557173

Epoch: 6| Step: 4
Training loss: 2.4507417217808656
Validation loss: 2.8991408712333775

Epoch: 6| Step: 5
Training loss: 3.220435136572707
Validation loss: 2.89966907455374

Epoch: 6| Step: 6
Training loss: 3.0301263043860445
Validation loss: 2.8972833443520694

Epoch: 6| Step: 7
Training loss: 3.20074672331192
Validation loss: 2.897874642229879

Epoch: 6| Step: 8
Training loss: 3.6379429183768353
Validation loss: 2.9034442075437505

Epoch: 6| Step: 9
Training loss: 2.8726508453044413
Validation loss: 2.895628897945488

Epoch: 6| Step: 10
Training loss: 3.0287186582976977
Validation loss: 2.894360328270951

Epoch: 6| Step: 11
Training loss: 3.217082508332275
Validation loss: 2.891911278502187

Epoch: 6| Step: 12
Training loss: 3.342740771139322
Validation loss: 2.892383212559339

Epoch: 6| Step: 13
Training loss: 3.448666002302132
Validation loss: 2.8920457855339237

Epoch: 60| Step: 0
Training loss: 2.9061576254325683
Validation loss: 2.8906739820273053

Epoch: 6| Step: 1
Training loss: 3.7805376879434673
Validation loss: 2.8916836002746864

Epoch: 6| Step: 2
Training loss: 3.1311033538163944
Validation loss: 2.893008304163255

Epoch: 6| Step: 3
Training loss: 2.9507527183100684
Validation loss: 2.8892804203378724

Epoch: 6| Step: 4
Training loss: 2.8463635853119746
Validation loss: 2.8894830161291227

Epoch: 6| Step: 5
Training loss: 3.120991539266229
Validation loss: 2.889694018716053

Epoch: 6| Step: 6
Training loss: 3.679005164766743
Validation loss: 2.890428549164202

Epoch: 6| Step: 7
Training loss: 2.8589590635194275
Validation loss: 2.890573657998049

Epoch: 6| Step: 8
Training loss: 2.613511148099475
Validation loss: 2.8873159565750677

Epoch: 6| Step: 9
Training loss: 4.106179042534032
Validation loss: 2.8873721643795522

Epoch: 6| Step: 10
Training loss: 3.177198030663151
Validation loss: 2.8888156681494572

Epoch: 6| Step: 11
Training loss: 3.271309463607724
Validation loss: 2.890292605351636

Epoch: 6| Step: 12
Training loss: 2.784009271957041
Validation loss: 2.887499436540588

Epoch: 6| Step: 13
Training loss: 2.922368951344228
Validation loss: 2.8850316407203227

Epoch: 61| Step: 0
Training loss: 2.4420676838385806
Validation loss: 2.880650937128415

Epoch: 6| Step: 1
Training loss: 3.0444406027510538
Validation loss: 2.8813765071513133

Epoch: 6| Step: 2
Training loss: 2.7630930371906826
Validation loss: 2.88227200175965

Epoch: 6| Step: 3
Training loss: 2.7970555423026684
Validation loss: 2.8810956072982945

Epoch: 6| Step: 4
Training loss: 3.6757314356348263
Validation loss: 2.8805138955227383

Epoch: 6| Step: 5
Training loss: 3.218598889998141
Validation loss: 2.8807820872372494

Epoch: 6| Step: 6
Training loss: 3.2631683600408485
Validation loss: 2.8815330157989107

Epoch: 6| Step: 7
Training loss: 3.7935481311564874
Validation loss: 2.879334506115488

Epoch: 6| Step: 8
Training loss: 3.1264163050293727
Validation loss: 2.8777591899466266

Epoch: 6| Step: 9
Training loss: 3.1709554307031595
Validation loss: 2.880523636492694

Epoch: 6| Step: 10
Training loss: 2.6856376050014545
Validation loss: 2.8779751977725563

Epoch: 6| Step: 11
Training loss: 2.938639967467678
Validation loss: 2.8830910887190297

Epoch: 6| Step: 12
Training loss: 3.9612926196053286
Validation loss: 2.8846139318011854

Epoch: 6| Step: 13
Training loss: 3.340446765737566
Validation loss: 2.886600382335456

Epoch: 62| Step: 0
Training loss: 2.0433996851085707
Validation loss: 2.8826398179993724

Epoch: 6| Step: 1
Training loss: 3.5008731842739125
Validation loss: 2.877226658780513

Epoch: 6| Step: 2
Training loss: 3.091552107780108
Validation loss: 2.8757740225418087

Epoch: 6| Step: 3
Training loss: 3.283676703324425
Validation loss: 2.877443937867723

Epoch: 6| Step: 4
Training loss: 3.289108892190634
Validation loss: 2.8754349513744755

Epoch: 6| Step: 5
Training loss: 3.3444589594134913
Validation loss: 2.873083079247371

Epoch: 6| Step: 6
Training loss: 2.973067667458251
Validation loss: 2.8704137902561753

Epoch: 6| Step: 7
Training loss: 3.5989889685527183
Validation loss: 2.8701024833058884

Epoch: 6| Step: 8
Training loss: 3.205187621910828
Validation loss: 2.869501549497338

Epoch: 6| Step: 9
Training loss: 3.2196757642622242
Validation loss: 2.871280404093205

Epoch: 6| Step: 10
Training loss: 3.4580005041312916
Validation loss: 2.870989252124863

Epoch: 6| Step: 11
Training loss: 2.91951587112537
Validation loss: 2.866364442660306

Epoch: 6| Step: 12
Training loss: 3.0548279868989376
Validation loss: 2.867404659157586

Epoch: 6| Step: 13
Training loss: 3.0885601246857455
Validation loss: 2.8648836833450644

Epoch: 63| Step: 0
Training loss: 3.2400568935909217
Validation loss: 2.8673608220157147

Epoch: 6| Step: 1
Training loss: 2.33953845240639
Validation loss: 2.866824077177363

Epoch: 6| Step: 2
Training loss: 3.035318848956653
Validation loss: 2.8683641760897154

Epoch: 6| Step: 3
Training loss: 3.88309273581591
Validation loss: 2.868256286020837

Epoch: 6| Step: 4
Training loss: 3.207234049807426
Validation loss: 2.87039779968717

Epoch: 6| Step: 5
Training loss: 3.9175046605981345
Validation loss: 2.868855353878899

Epoch: 6| Step: 6
Training loss: 3.564710901423842
Validation loss: 2.868513509441404

Epoch: 6| Step: 7
Training loss: 2.7790424286745847
Validation loss: 2.8664111856550507

Epoch: 6| Step: 8
Training loss: 2.790850667169716
Validation loss: 2.862327963715923

Epoch: 6| Step: 9
Training loss: 3.045172582536839
Validation loss: 2.8639112353428207

Epoch: 6| Step: 10
Training loss: 3.038184031635182
Validation loss: 2.8608491135934857

Epoch: 6| Step: 11
Training loss: 3.0893705562719345
Validation loss: 2.860787416527206

Epoch: 6| Step: 12
Training loss: 2.1759299427773966
Validation loss: 2.857585188799697

Epoch: 6| Step: 13
Training loss: 3.927060289930873
Validation loss: 2.8594278238456945

Epoch: 64| Step: 0
Training loss: 3.4881407227782963
Validation loss: 2.8585817557048805

Epoch: 6| Step: 1
Training loss: 2.7510075890711305
Validation loss: 2.8564584966466944

Epoch: 6| Step: 2
Training loss: 3.265195681446177
Validation loss: 2.8578921639475494

Epoch: 6| Step: 3
Training loss: 2.7457533906250404
Validation loss: 2.8576838612169535

Epoch: 6| Step: 4
Training loss: 3.132004174571952
Validation loss: 2.8584005864238775

Epoch: 6| Step: 5
Training loss: 3.6287288560819633
Validation loss: 2.8589605915029974

Epoch: 6| Step: 6
Training loss: 3.5335950238708183
Validation loss: 2.857006861963056

Epoch: 6| Step: 7
Training loss: 3.192371161840166
Validation loss: 2.8550707157239508

Epoch: 6| Step: 8
Training loss: 3.0345145667809637
Validation loss: 2.855190234282103

Epoch: 6| Step: 9
Training loss: 3.1819890570892975
Validation loss: 2.851875961994755

Epoch: 6| Step: 10
Training loss: 3.091906528130941
Validation loss: 2.8501392696040004

Epoch: 6| Step: 11
Training loss: 3.139416210550364
Validation loss: 2.8513646957201484

Epoch: 6| Step: 12
Training loss: 2.6483673716574914
Validation loss: 2.852040303480054

Epoch: 6| Step: 13
Training loss: 3.1535096311045634
Validation loss: 2.852112347764104

Epoch: 65| Step: 0
Training loss: 3.4752558277833994
Validation loss: 2.84820818940018

Epoch: 6| Step: 1
Training loss: 3.0837419256345067
Validation loss: 2.847763116459861

Epoch: 6| Step: 2
Training loss: 2.565784861036677
Validation loss: 2.849343114026512

Epoch: 6| Step: 3
Training loss: 2.867995145796282
Validation loss: 2.85171143483791

Epoch: 6| Step: 4
Training loss: 2.520344069319244
Validation loss: 2.8497235324356454

Epoch: 6| Step: 5
Training loss: 3.4670612245165064
Validation loss: 2.85188050339219

Epoch: 6| Step: 6
Training loss: 3.3883957808094416
Validation loss: 2.8514435333550034

Epoch: 6| Step: 7
Training loss: 3.145690780003406
Validation loss: 2.849455359481848

Epoch: 6| Step: 8
Training loss: 3.4399799071323964
Validation loss: 2.846117729003646

Epoch: 6| Step: 9
Training loss: 2.973782420035781
Validation loss: 2.845673218287443

Epoch: 6| Step: 10
Training loss: 3.197388811482268
Validation loss: 2.851042532674645

Epoch: 6| Step: 11
Training loss: 3.2084103034228435
Validation loss: 2.8730413819511478

Epoch: 6| Step: 12
Training loss: 3.3943590267552204
Validation loss: 2.8907522220657182

Epoch: 6| Step: 13
Training loss: 3.3506626441689558
Validation loss: 2.8670548365332382

Epoch: 66| Step: 0
Training loss: 3.5254999117409644
Validation loss: 2.8465290664143317

Epoch: 6| Step: 1
Training loss: 3.004765222806842
Validation loss: 2.8448232027284237

Epoch: 6| Step: 2
Training loss: 2.9016261901603237
Validation loss: 2.8418938006844394

Epoch: 6| Step: 3
Training loss: 2.7538966401926745
Validation loss: 2.8426927748896054

Epoch: 6| Step: 4
Training loss: 3.0221761590900464
Validation loss: 2.839590906538111

Epoch: 6| Step: 5
Training loss: 3.121512947052003
Validation loss: 2.8421424235306296

Epoch: 6| Step: 6
Training loss: 3.934067213701228
Validation loss: 2.843481786592886

Epoch: 6| Step: 7
Training loss: 2.9993428464208582
Validation loss: 2.84112475431099

Epoch: 6| Step: 8
Training loss: 3.1292444015444314
Validation loss: 2.8410376886700055

Epoch: 6| Step: 9
Training loss: 3.279772762009948
Validation loss: 2.84099964308524

Epoch: 6| Step: 10
Training loss: 2.6440407595356654
Validation loss: 2.8356205655716393

Epoch: 6| Step: 11
Training loss: 2.8958931420459777
Validation loss: 2.8388714968540554

Epoch: 6| Step: 12
Training loss: 2.8528668490525195
Validation loss: 2.8513558828017658

Epoch: 6| Step: 13
Training loss: 4.0674928941060875
Validation loss: 2.8398204113660714

Epoch: 67| Step: 0
Training loss: 3.239457122862826
Validation loss: 2.836484395236649

Epoch: 6| Step: 1
Training loss: 2.2411160451044276
Validation loss: 2.836290519734152

Epoch: 6| Step: 2
Training loss: 3.461709653256568
Validation loss: 2.8354560083747886

Epoch: 6| Step: 3
Training loss: 3.2240361629000844
Validation loss: 2.836857993598515

Epoch: 6| Step: 4
Training loss: 3.183730945088308
Validation loss: 2.8383974756513997

Epoch: 6| Step: 5
Training loss: 3.0179349126654405
Validation loss: 2.834254246066795

Epoch: 6| Step: 6
Training loss: 2.964223522906125
Validation loss: 2.8323961773451143

Epoch: 6| Step: 7
Training loss: 2.904958130211389
Validation loss: 2.8318045431845373

Epoch: 6| Step: 8
Training loss: 3.2862969231402412
Validation loss: 2.838975905482634

Epoch: 6| Step: 9
Training loss: 3.8157092485804194
Validation loss: 2.8395019728206443

Epoch: 6| Step: 10
Training loss: 3.379973385271553
Validation loss: 2.8333608407622193

Epoch: 6| Step: 11
Training loss: 2.644143824181613
Validation loss: 2.8416337941621554

Epoch: 6| Step: 12
Training loss: 2.8077838775245794
Validation loss: 2.833691454615262

Epoch: 6| Step: 13
Training loss: 3.624819126220637
Validation loss: 2.829872505639316

Epoch: 68| Step: 0
Training loss: 3.109840549907601
Validation loss: 2.828556435572558

Epoch: 6| Step: 1
Training loss: 3.445832712772287
Validation loss: 2.830382863604667

Epoch: 6| Step: 2
Training loss: 2.9603610723234137
Validation loss: 2.828181978987762

Epoch: 6| Step: 3
Training loss: 2.919289163786581
Validation loss: 2.829088626019432

Epoch: 6| Step: 4
Training loss: 2.5365185949124096
Validation loss: 2.82956032891593

Epoch: 6| Step: 5
Training loss: 2.9071061708780648
Validation loss: 2.827589119443081

Epoch: 6| Step: 6
Training loss: 3.398871172715768
Validation loss: 2.8264982514390393

Epoch: 6| Step: 7
Training loss: 3.391415270986908
Validation loss: 2.823854902966691

Epoch: 6| Step: 8
Training loss: 3.793049961717478
Validation loss: 2.825136200684034

Epoch: 6| Step: 9
Training loss: 3.0369727787811365
Validation loss: 2.8228174558525123

Epoch: 6| Step: 10
Training loss: 2.7630939000589922
Validation loss: 2.82427501082043

Epoch: 6| Step: 11
Training loss: 3.086554897693318
Validation loss: 2.825558156745699

Epoch: 6| Step: 12
Training loss: 3.719540552048729
Validation loss: 2.823117422521117

Epoch: 6| Step: 13
Training loss: 2.040503916864952
Validation loss: 2.8245044613033756

Epoch: 69| Step: 0
Training loss: 2.8758832155373035
Validation loss: 2.8250965053646397

Epoch: 6| Step: 1
Training loss: 3.519452397927043
Validation loss: 2.844877963887077

Epoch: 6| Step: 2
Training loss: 3.721516197455328
Validation loss: 2.865613785973148

Epoch: 6| Step: 3
Training loss: 3.172583590128484
Validation loss: 2.8793062540037853

Epoch: 6| Step: 4
Training loss: 3.149502330400665
Validation loss: 2.844188755052589

Epoch: 6| Step: 5
Training loss: 2.458723737676295
Validation loss: 2.820540069615105

Epoch: 6| Step: 6
Training loss: 3.1077115770833514
Validation loss: 2.8197405389711343

Epoch: 6| Step: 7
Training loss: 3.1149958886965936
Validation loss: 2.8197989247450193

Epoch: 6| Step: 8
Training loss: 3.065275841601767
Validation loss: 2.820559244091511

Epoch: 6| Step: 9
Training loss: 2.9914419176551132
Validation loss: 2.82251753541678

Epoch: 6| Step: 10
Training loss: 2.962318118664745
Validation loss: 2.83311224538721

Epoch: 6| Step: 11
Training loss: 2.858740564221488
Validation loss: 2.8323214338782985

Epoch: 6| Step: 12
Training loss: 3.611406555479452
Validation loss: 2.822449455259532

Epoch: 6| Step: 13
Training loss: 2.93566528812447
Validation loss: 2.8217771488724925

Epoch: 70| Step: 0
Training loss: 3.786207747880116
Validation loss: 2.8201925659948532

Epoch: 6| Step: 1
Training loss: 2.9225229778969144
Validation loss: 2.818682595058629

Epoch: 6| Step: 2
Training loss: 3.330313236293405
Validation loss: 2.8171209841840845

Epoch: 6| Step: 3
Training loss: 2.955031652393996
Validation loss: 2.8156119609555113

Epoch: 6| Step: 4
Training loss: 2.973840304747733
Validation loss: 2.8153414119962097

Epoch: 6| Step: 5
Training loss: 2.949962557538883
Validation loss: 2.8141898034115003

Epoch: 6| Step: 6
Training loss: 3.295152259284119
Validation loss: 2.809798624405333

Epoch: 6| Step: 7
Training loss: 2.8232247910545833
Validation loss: 2.8110319163977393

Epoch: 6| Step: 8
Training loss: 2.87344650092901
Validation loss: 2.810577833204162

Epoch: 6| Step: 9
Training loss: 3.251723492737009
Validation loss: 2.816595907451726

Epoch: 6| Step: 10
Training loss: 3.52952709196571
Validation loss: 2.810603343821606

Epoch: 6| Step: 11
Training loss: 3.234660850093022
Validation loss: 2.809386539254165

Epoch: 6| Step: 12
Training loss: 2.9797487201612713
Validation loss: 2.808626050516765

Epoch: 6| Step: 13
Training loss: 2.2410732783840235
Validation loss: 2.8110441626092704

Epoch: 71| Step: 0
Training loss: 3.090208241874553
Validation loss: 2.8091553830444167

Epoch: 6| Step: 1
Training loss: 2.96662746646428
Validation loss: 2.8074279507944793

Epoch: 6| Step: 2
Training loss: 3.1791670839668558
Validation loss: 2.807047902049601

Epoch: 6| Step: 3
Training loss: 2.9259060882704233
Validation loss: 2.8046012584315103

Epoch: 6| Step: 4
Training loss: 2.9370534029798585
Validation loss: 2.8125844689814

Epoch: 6| Step: 5
Training loss: 3.3044081405267853
Validation loss: 2.8101347098191134

Epoch: 6| Step: 6
Training loss: 3.659048981644444
Validation loss: 2.806155911728823

Epoch: 6| Step: 7
Training loss: 3.0054944903206287
Validation loss: 2.808788998755568

Epoch: 6| Step: 8
Training loss: 3.211554920395083
Validation loss: 2.8076796749343025

Epoch: 6| Step: 9
Training loss: 2.851894746001849
Validation loss: 2.8040080384751627

Epoch: 6| Step: 10
Training loss: 3.371711541740059
Validation loss: 2.8075161272134235

Epoch: 6| Step: 11
Training loss: 2.7265757912910282
Validation loss: 2.806228783197921

Epoch: 6| Step: 12
Training loss: 3.290278918841005
Validation loss: 2.805247323362938

Epoch: 6| Step: 13
Training loss: 2.751437765020367
Validation loss: 2.801576892413707

Epoch: 72| Step: 0
Training loss: 2.6282049323410526
Validation loss: 2.8037458992896998

Epoch: 6| Step: 1
Training loss: 3.2595005556174264
Validation loss: 2.79604587947917

Epoch: 6| Step: 2
Training loss: 3.7545162979444853
Validation loss: 2.796152987436582

Epoch: 6| Step: 3
Training loss: 3.5376198630363214
Validation loss: 2.799953022502699

Epoch: 6| Step: 4
Training loss: 3.3935850380837027
Validation loss: 2.80584022191641

Epoch: 6| Step: 5
Training loss: 2.6078991399581266
Validation loss: 2.8110549888068044

Epoch: 6| Step: 6
Training loss: 3.2361209598185834
Validation loss: 2.809086488054384

Epoch: 6| Step: 7
Training loss: 2.8797794917249258
Validation loss: 2.814925060034962

Epoch: 6| Step: 8
Training loss: 3.2003857320522067
Validation loss: 2.805038661877888

Epoch: 6| Step: 9
Training loss: 2.9778992061940204
Validation loss: 2.8002483268056264

Epoch: 6| Step: 10
Training loss: 2.93493979059228
Validation loss: 2.7999952845086913

Epoch: 6| Step: 11
Training loss: 2.7978945104687964
Validation loss: 2.803159168167914

Epoch: 6| Step: 12
Training loss: 2.8352325656234756
Validation loss: 2.8014172693571555

Epoch: 6| Step: 13
Training loss: 3.281748125322332
Validation loss: 2.7951502736296545

Epoch: 73| Step: 0
Training loss: 3.6368152511364165
Validation loss: 2.807095145993669

Epoch: 6| Step: 1
Training loss: 3.222855995230195
Validation loss: 2.794342340722768

Epoch: 6| Step: 2
Training loss: 2.61130986460519
Validation loss: 2.7940974396432368

Epoch: 6| Step: 3
Training loss: 3.0855032699832208
Validation loss: 2.7916435739085226

Epoch: 6| Step: 4
Training loss: 2.8441212170785763
Validation loss: 2.7887940746841062

Epoch: 6| Step: 5
Training loss: 2.9032787598460206
Validation loss: 2.788670103535034

Epoch: 6| Step: 6
Training loss: 3.210288174727453
Validation loss: 2.7870333682670876

Epoch: 6| Step: 7
Training loss: 3.068370719514754
Validation loss: 2.7896348565830626

Epoch: 6| Step: 8
Training loss: 2.5689294682758566
Validation loss: 2.788999259022405

Epoch: 6| Step: 9
Training loss: 3.3595924484493254
Validation loss: 2.788201604324913

Epoch: 6| Step: 10
Training loss: 2.6600538057607475
Validation loss: 2.7925269488471063

Epoch: 6| Step: 11
Training loss: 3.3365332185454157
Validation loss: 2.8147204495041875

Epoch: 6| Step: 12
Training loss: 3.0885269310499464
Validation loss: 2.8209616189864173

Epoch: 6| Step: 13
Training loss: 4.000886342076815
Validation loss: 2.7940776358186503

Epoch: 74| Step: 0
Training loss: 2.7746716829199896
Validation loss: 2.7923458328058484

Epoch: 6| Step: 1
Training loss: 3.035298897669447
Validation loss: 2.7845336400405514

Epoch: 6| Step: 2
Training loss: 3.1504207451191113
Validation loss: 2.783251829269901

Epoch: 6| Step: 3
Training loss: 2.265709921462072
Validation loss: 2.7814549509661837

Epoch: 6| Step: 4
Training loss: 3.5152665019037657
Validation loss: 2.7860651609241938

Epoch: 6| Step: 5
Training loss: 3.317468623549785
Validation loss: 2.7860916284347206

Epoch: 6| Step: 6
Training loss: 2.9973121364031785
Validation loss: 2.789957515706094

Epoch: 6| Step: 7
Training loss: 3.094425166275665
Validation loss: 2.7888055746648743

Epoch: 6| Step: 8
Training loss: 2.924594368481518
Validation loss: 2.7942684454814475

Epoch: 6| Step: 9
Training loss: 3.3718116676527385
Validation loss: 2.784011710353169

Epoch: 6| Step: 10
Training loss: 3.4858890545469676
Validation loss: 2.784297512786333

Epoch: 6| Step: 11
Training loss: 2.682246196077472
Validation loss: 2.7790363531445723

Epoch: 6| Step: 12
Training loss: 3.34187249923564
Validation loss: 2.7810040897885737

Epoch: 6| Step: 13
Training loss: 3.31595316421509
Validation loss: 2.7809150321717895

Epoch: 75| Step: 0
Training loss: 3.592415072420122
Validation loss: 2.788875581958011

Epoch: 6| Step: 1
Training loss: 3.6723480569193967
Validation loss: 2.7986159225918255

Epoch: 6| Step: 2
Training loss: 2.92019017240408
Validation loss: 2.7919476667196554

Epoch: 6| Step: 3
Training loss: 2.228451860804458
Validation loss: 2.7899037982893065

Epoch: 6| Step: 4
Training loss: 2.4113902885004164
Validation loss: 2.7835033985469395

Epoch: 6| Step: 5
Training loss: 3.0015366115774182
Validation loss: 2.7801948971175614

Epoch: 6| Step: 6
Training loss: 3.217810188048859
Validation loss: 2.782796385828975

Epoch: 6| Step: 7
Training loss: 3.516195835817845
Validation loss: 2.7880269354200897

Epoch: 6| Step: 8
Training loss: 3.524169845766041
Validation loss: 2.781914308471121

Epoch: 6| Step: 9
Training loss: 3.102770361174763
Validation loss: 2.7782818786672094

Epoch: 6| Step: 10
Training loss: 2.941797400172988
Validation loss: 2.7747452546636375

Epoch: 6| Step: 11
Training loss: 2.9049118406801995
Validation loss: 2.775019581378383

Epoch: 6| Step: 12
Training loss: 3.031541947925387
Validation loss: 2.774402767139533

Epoch: 6| Step: 13
Training loss: 2.708759411283655
Validation loss: 2.7758164625671418

Epoch: 76| Step: 0
Training loss: 2.917983620642747
Validation loss: 2.7756887530689984

Epoch: 6| Step: 1
Training loss: 2.8839823512411633
Validation loss: 2.7738791955635045

Epoch: 6| Step: 2
Training loss: 3.043658470955206
Validation loss: 2.7739924391995046

Epoch: 6| Step: 3
Training loss: 2.909756749529188
Validation loss: 2.772959421246316

Epoch: 6| Step: 4
Training loss: 3.0262915573197477
Validation loss: 2.7694801652034013

Epoch: 6| Step: 5
Training loss: 2.9409599218870692
Validation loss: 2.7752281554133207

Epoch: 6| Step: 6
Training loss: 3.0439996699208947
Validation loss: 2.7829528679962623

Epoch: 6| Step: 7
Training loss: 3.236611740033873
Validation loss: 2.792362072034948

Epoch: 6| Step: 8
Training loss: 3.504460353692915
Validation loss: 2.778489922703707

Epoch: 6| Step: 9
Training loss: 2.9269042769178895
Validation loss: 2.7691220295716246

Epoch: 6| Step: 10
Training loss: 3.5239285890182974
Validation loss: 2.7659909003001317

Epoch: 6| Step: 11
Training loss: 3.142443685459483
Validation loss: 2.7683486629454617

Epoch: 6| Step: 12
Training loss: 3.1941859117646887
Validation loss: 2.772243769622622

Epoch: 6| Step: 13
Training loss: 2.6273152268444107
Validation loss: 2.7712292270798695

Epoch: 77| Step: 0
Training loss: 2.990872485086233
Validation loss: 2.7745661092476173

Epoch: 6| Step: 1
Training loss: 3.31077919654039
Validation loss: 2.7722622331787634

Epoch: 6| Step: 2
Training loss: 2.9835379659987007
Validation loss: 2.771542350091386

Epoch: 6| Step: 3
Training loss: 3.3121490292582854
Validation loss: 2.7716948586764247

Epoch: 6| Step: 4
Training loss: 3.5845588244500024
Validation loss: 2.7717770722523234

Epoch: 6| Step: 5
Training loss: 3.0981937437605405
Validation loss: 2.7688960920047796

Epoch: 6| Step: 6
Training loss: 3.5518115136337607
Validation loss: 2.7702743561054315

Epoch: 6| Step: 7
Training loss: 3.3766627983932205
Validation loss: 2.7673478009228294

Epoch: 6| Step: 8
Training loss: 2.3718982318449084
Validation loss: 2.7675139512180644

Epoch: 6| Step: 9
Training loss: 3.214649440228214
Validation loss: 2.765781680642606

Epoch: 6| Step: 10
Training loss: 2.2612256713368186
Validation loss: 2.7642946004430415

Epoch: 6| Step: 11
Training loss: 2.801669566485621
Validation loss: 2.7637777484097383

Epoch: 6| Step: 12
Training loss: 3.183898536742801
Validation loss: 2.764555948622582

Epoch: 6| Step: 13
Training loss: 2.8738732825305586
Validation loss: 2.765770932131694

Epoch: 78| Step: 0
Training loss: 2.810481046180084
Validation loss: 2.7690022373786443

Epoch: 6| Step: 1
Training loss: 3.454431071053264
Validation loss: 2.7668996915770374

Epoch: 6| Step: 2
Training loss: 3.03987201019696
Validation loss: 2.7663580940949326

Epoch: 6| Step: 3
Training loss: 3.1255184506457723
Validation loss: 2.7695384729052455

Epoch: 6| Step: 4
Training loss: 3.2531283068021737
Validation loss: 2.7682905061369745

Epoch: 6| Step: 5
Training loss: 3.1056084751388884
Validation loss: 2.7751851171704573

Epoch: 6| Step: 6
Training loss: 3.0626281400069453
Validation loss: 2.782778465689916

Epoch: 6| Step: 7
Training loss: 3.1952193789914975
Validation loss: 2.7703472839610717

Epoch: 6| Step: 8
Training loss: 2.9101872180084674
Validation loss: 2.766822883202606

Epoch: 6| Step: 9
Training loss: 2.7243772127510497
Validation loss: 2.7552376228446045

Epoch: 6| Step: 10
Training loss: 2.92610653544725
Validation loss: 2.7509578051120473

Epoch: 6| Step: 11
Training loss: 3.209551509768906
Validation loss: 2.7504546609050826

Epoch: 6| Step: 12
Training loss: 3.1669251855096348
Validation loss: 2.751857042918752

Epoch: 6| Step: 13
Training loss: 2.9999623296279925
Validation loss: 2.7490810880096808

Epoch: 79| Step: 0
Training loss: 2.621208722795083
Validation loss: 2.7496795309089204

Epoch: 6| Step: 1
Training loss: 3.8308820488679713
Validation loss: 2.753458468849629

Epoch: 6| Step: 2
Training loss: 2.563858881460559
Validation loss: 2.753495348900769

Epoch: 6| Step: 3
Training loss: 2.3869430012092305
Validation loss: 2.7545165916446814

Epoch: 6| Step: 4
Training loss: 3.047200190478875
Validation loss: 2.7565974004904903

Epoch: 6| Step: 5
Training loss: 2.724094705954714
Validation loss: 2.7478601962645293

Epoch: 6| Step: 6
Training loss: 2.5251902820160272
Validation loss: 2.7486375340302693

Epoch: 6| Step: 7
Training loss: 3.2954853618460516
Validation loss: 2.7493634703829355

Epoch: 6| Step: 8
Training loss: 3.6114453739754926
Validation loss: 2.749431608233778

Epoch: 6| Step: 9
Training loss: 3.0591717754817718
Validation loss: 2.750382526376455

Epoch: 6| Step: 10
Training loss: 3.645429854092101
Validation loss: 2.747801979012248

Epoch: 6| Step: 11
Training loss: 2.720527681607751
Validation loss: 2.7486459245421764

Epoch: 6| Step: 12
Training loss: 2.852552602618926
Validation loss: 2.761684971641529

Epoch: 6| Step: 13
Training loss: 4.158659731197985
Validation loss: 2.8079089211891173

Epoch: 80| Step: 0
Training loss: 2.3748020290382152
Validation loss: 2.814688544083365

Epoch: 6| Step: 1
Training loss: 3.5894385971554135
Validation loss: 2.8573101766730544

Epoch: 6| Step: 2
Training loss: 2.418213469858115
Validation loss: 2.7993793056312164

Epoch: 6| Step: 3
Training loss: 2.5268629698711127
Validation loss: 2.7527947911613206

Epoch: 6| Step: 4
Training loss: 3.4279939471695475
Validation loss: 2.751981930897935

Epoch: 6| Step: 5
Training loss: 2.6180646195214026
Validation loss: 2.7469732056976377

Epoch: 6| Step: 6
Training loss: 3.6329206553120548
Validation loss: 2.7492409653292595

Epoch: 6| Step: 7
Training loss: 2.850146132621084
Validation loss: 2.7500520945487534

Epoch: 6| Step: 8
Training loss: 3.6243290773585017
Validation loss: 2.7534825841817017

Epoch: 6| Step: 9
Training loss: 2.9282589290446612
Validation loss: 2.7546652918527488

Epoch: 6| Step: 10
Training loss: 3.7893083944857944
Validation loss: 2.7524902054413833

Epoch: 6| Step: 11
Training loss: 2.7625284046766847
Validation loss: 2.754573589252143

Epoch: 6| Step: 12
Training loss: 2.510300587441002
Validation loss: 2.7458959329179087

Epoch: 6| Step: 13
Training loss: 3.6676159121262732
Validation loss: 2.7451679230023727

Epoch: 81| Step: 0
Training loss: 2.68157625503133
Validation loss: 2.743156966406555

Epoch: 6| Step: 1
Training loss: 3.1834223976125275
Validation loss: 2.7407846142852095

Epoch: 6| Step: 2
Training loss: 3.0395946674166114
Validation loss: 2.7383985954916485

Epoch: 6| Step: 3
Training loss: 3.21394908595513
Validation loss: 2.743904541239475

Epoch: 6| Step: 4
Training loss: 3.5407357881187136
Validation loss: 2.7483780460173977

Epoch: 6| Step: 5
Training loss: 3.4869977035580537
Validation loss: 2.756584222333016

Epoch: 6| Step: 6
Training loss: 3.3025596748406816
Validation loss: 2.7635204589532667

Epoch: 6| Step: 7
Training loss: 3.1463672277521195
Validation loss: 2.7755638982301956

Epoch: 6| Step: 8
Training loss: 2.3685500249268654
Validation loss: 2.8210715022858515

Epoch: 6| Step: 9
Training loss: 3.3979257483315193
Validation loss: 2.8296628034538434

Epoch: 6| Step: 10
Training loss: 2.501725745607978
Validation loss: 2.775293631568125

Epoch: 6| Step: 11
Training loss: 3.2911255951118448
Validation loss: 2.74689363898429

Epoch: 6| Step: 12
Training loss: 2.799229829315396
Validation loss: 2.731701170396162

Epoch: 6| Step: 13
Training loss: 2.7868327997352873
Validation loss: 2.7341895171510036

Epoch: 82| Step: 0
Training loss: 2.5036803811688513
Validation loss: 2.7371825531183207

Epoch: 6| Step: 1
Training loss: 3.4041472778017177
Validation loss: 2.7458399521148538

Epoch: 6| Step: 2
Training loss: 2.7902573876284404
Validation loss: 2.7469547261511806

Epoch: 6| Step: 3
Training loss: 2.945072073192163
Validation loss: 2.7452146186341997

Epoch: 6| Step: 4
Training loss: 2.5920987675651923
Validation loss: 2.7434257191796565

Epoch: 6| Step: 5
Training loss: 3.412157448144463
Validation loss: 2.7406748252059936

Epoch: 6| Step: 6
Training loss: 3.176562824239869
Validation loss: 2.740528080570567

Epoch: 6| Step: 7
Training loss: 3.3317653464937593
Validation loss: 2.7395854616026276

Epoch: 6| Step: 8
Training loss: 2.822977260112894
Validation loss: 2.7364212765925187

Epoch: 6| Step: 9
Training loss: 3.0341308118347823
Validation loss: 2.7367348365446382

Epoch: 6| Step: 10
Training loss: 3.3348113756726807
Validation loss: 2.736100610349513

Epoch: 6| Step: 11
Training loss: 2.892977030858389
Validation loss: 2.7325281181187586

Epoch: 6| Step: 12
Training loss: 3.486538476234652
Validation loss: 2.7296998919069138

Epoch: 6| Step: 13
Training loss: 3.134613052410502
Validation loss: 2.7295039396803293

Epoch: 83| Step: 0
Training loss: 2.7291598914453017
Validation loss: 2.7342928778860673

Epoch: 6| Step: 1
Training loss: 2.650200811011136
Validation loss: 2.731399553288961

Epoch: 6| Step: 2
Training loss: 3.4357740751071253
Validation loss: 2.7539272624348508

Epoch: 6| Step: 3
Training loss: 3.1235943493907623
Validation loss: 2.756042701817408

Epoch: 6| Step: 4
Training loss: 2.953299381012145
Validation loss: 2.7641680094839

Epoch: 6| Step: 5
Training loss: 3.4283190106389596
Validation loss: 2.7743897493274

Epoch: 6| Step: 6
Training loss: 2.8999820511361136
Validation loss: 2.793084449588901

Epoch: 6| Step: 7
Training loss: 2.9930332671769175
Validation loss: 2.7411900370802065

Epoch: 6| Step: 8
Training loss: 2.5018234278871385
Validation loss: 2.7205477013801183

Epoch: 6| Step: 9
Training loss: 3.339967388519246
Validation loss: 2.7192707319795217

Epoch: 6| Step: 10
Training loss: 3.2178287113518933
Validation loss: 2.7230467016206585

Epoch: 6| Step: 11
Training loss: 3.382634887261346
Validation loss: 2.7248199702591243

Epoch: 6| Step: 12
Training loss: 3.054473791427435
Validation loss: 2.725786435209768

Epoch: 6| Step: 13
Training loss: 2.7547623406173702
Validation loss: 2.7289915976647685

Epoch: 84| Step: 0
Training loss: 2.700164585042163
Validation loss: 2.729942123936691

Epoch: 6| Step: 1
Training loss: 2.7898473837344633
Validation loss: 2.731171546410556

Epoch: 6| Step: 2
Training loss: 3.0906865529409924
Validation loss: 2.7436615470064356

Epoch: 6| Step: 3
Training loss: 3.6363967113724636
Validation loss: 2.7364511060174084

Epoch: 6| Step: 4
Training loss: 2.754595990751752
Validation loss: 2.734779620960629

Epoch: 6| Step: 5
Training loss: 2.580540028764788
Validation loss: 2.7290149738306777

Epoch: 6| Step: 6
Training loss: 3.286819816977703
Validation loss: 2.7281206796330912

Epoch: 6| Step: 7
Training loss: 2.993355864062684
Validation loss: 2.7229222198228094

Epoch: 6| Step: 8
Training loss: 2.367145600908072
Validation loss: 2.7243905476381447

Epoch: 6| Step: 9
Training loss: 3.6151987627399147
Validation loss: 2.72400970934439

Epoch: 6| Step: 10
Training loss: 2.894397150760933
Validation loss: 2.720023616322401

Epoch: 6| Step: 11
Training loss: 3.6836271476647435
Validation loss: 2.7196584005959425

Epoch: 6| Step: 12
Training loss: 3.0066280262135345
Validation loss: 2.721929913756355

Epoch: 6| Step: 13
Training loss: 3.3007211532990692
Validation loss: 2.726859344083009

Epoch: 85| Step: 0
Training loss: 3.170197743406522
Validation loss: 2.7293105404925937

Epoch: 6| Step: 1
Training loss: 3.584183141201472
Validation loss: 2.7351120947075596

Epoch: 6| Step: 2
Training loss: 2.8803271820399403
Validation loss: 2.7310097476632684

Epoch: 6| Step: 3
Training loss: 2.2657672705869176
Validation loss: 2.731518078522484

Epoch: 6| Step: 4
Training loss: 3.204850044015549
Validation loss: 2.73049077841324

Epoch: 6| Step: 5
Training loss: 2.621662743289224
Validation loss: 2.730376897619518

Epoch: 6| Step: 6
Training loss: 2.878905256211667
Validation loss: 2.7306787929180745

Epoch: 6| Step: 7
Training loss: 3.3460106738935504
Validation loss: 2.724226798119338

Epoch: 6| Step: 8
Training loss: 3.773840335802106
Validation loss: 2.7202577956078726

Epoch: 6| Step: 9
Training loss: 2.6694473927728906
Validation loss: 2.7192140823634006

Epoch: 6| Step: 10
Training loss: 2.4354203962999628
Validation loss: 2.7162525255662953

Epoch: 6| Step: 11
Training loss: 2.3312822477754005
Validation loss: 2.7186414871182367

Epoch: 6| Step: 12
Training loss: 3.4750270924781335
Validation loss: 2.72013529825271

Epoch: 6| Step: 13
Training loss: 3.7736293199012745
Validation loss: 2.7139885848717973

Epoch: 86| Step: 0
Training loss: 3.169279643380618
Validation loss: 2.717501994966958

Epoch: 6| Step: 1
Training loss: 2.4222035831158126
Validation loss: 2.708430911468469

Epoch: 6| Step: 2
Training loss: 3.0759781064964535
Validation loss: 2.7115631048353745

Epoch: 6| Step: 3
Training loss: 3.2944196624710074
Validation loss: 2.7111123990138157

Epoch: 6| Step: 4
Training loss: 3.0576432311350925
Validation loss: 2.7114097716016756

Epoch: 6| Step: 5
Training loss: 2.8498724122516927
Validation loss: 2.7135916555649664

Epoch: 6| Step: 6
Training loss: 3.631543272062889
Validation loss: 2.71374052656409

Epoch: 6| Step: 7
Training loss: 2.762164348389177
Validation loss: 2.715716479503675

Epoch: 6| Step: 8
Training loss: 2.687562808700107
Validation loss: 2.7193205728231815

Epoch: 6| Step: 9
Training loss: 3.0553469519259293
Validation loss: 2.722740226775

Epoch: 6| Step: 10
Training loss: 3.3023812112517703
Validation loss: 2.7187098885701824

Epoch: 6| Step: 11
Training loss: 3.186273974825669
Validation loss: 2.718933972414333

Epoch: 6| Step: 12
Training loss: 3.203173678888871
Validation loss: 2.718788852963299

Epoch: 6| Step: 13
Training loss: 2.4157534112393995
Validation loss: 2.716286600859395

Epoch: 87| Step: 0
Training loss: 3.1184223377514013
Validation loss: 2.730801232260575

Epoch: 6| Step: 1
Training loss: 2.695192549980377
Validation loss: 2.717010234653958

Epoch: 6| Step: 2
Training loss: 3.0978946858600884
Validation loss: 2.7140134485871723

Epoch: 6| Step: 3
Training loss: 2.9526352249174534
Validation loss: 2.7056504306937823

Epoch: 6| Step: 4
Training loss: 3.1373817816723752
Validation loss: 2.7030063868441236

Epoch: 6| Step: 5
Training loss: 2.532608138823052
Validation loss: 2.6970750417144482

Epoch: 6| Step: 6
Training loss: 3.829180638090982
Validation loss: 2.7050556242786543

Epoch: 6| Step: 7
Training loss: 2.6717300821902046
Validation loss: 2.7024875666742227

Epoch: 6| Step: 8
Training loss: 3.5946257477883004
Validation loss: 2.6992881099607544

Epoch: 6| Step: 9
Training loss: 2.6802557073133326
Validation loss: 2.6992828588047892

Epoch: 6| Step: 10
Training loss: 3.0799115413496962
Validation loss: 2.7008855988302463

Epoch: 6| Step: 11
Training loss: 2.050624761514554
Validation loss: 2.7032704890035517

Epoch: 6| Step: 12
Training loss: 3.6140917059826982
Validation loss: 2.6988048810490763

Epoch: 6| Step: 13
Training loss: 3.012520887373695
Validation loss: 2.7010326985974675

Epoch: 88| Step: 0
Training loss: 3.324900896703598
Validation loss: 2.699355262882663

Epoch: 6| Step: 1
Training loss: 3.12319054669724
Validation loss: 2.700084269882317

Epoch: 6| Step: 2
Training loss: 3.291387103478016
Validation loss: 2.7017457473276534

Epoch: 6| Step: 3
Training loss: 2.64852950124818
Validation loss: 2.7019089094765163

Epoch: 6| Step: 4
Training loss: 3.266149159395648
Validation loss: 2.7067199905950465

Epoch: 6| Step: 5
Training loss: 2.9006160147588793
Validation loss: 2.7016231175466654

Epoch: 6| Step: 6
Training loss: 3.2455475458974044
Validation loss: 2.7123270001453763

Epoch: 6| Step: 7
Training loss: 2.549355171053553
Validation loss: 2.7183456082430726

Epoch: 6| Step: 8
Training loss: 3.247032277737765
Validation loss: 2.7310574471259836

Epoch: 6| Step: 9
Training loss: 3.2977536734528075
Validation loss: 2.7116890336311044

Epoch: 6| Step: 10
Training loss: 2.3734854838359514
Validation loss: 2.6997535180219083

Epoch: 6| Step: 11
Training loss: 3.1621567249581797
Validation loss: 2.696283267347439

Epoch: 6| Step: 12
Training loss: 3.1243834841071796
Validation loss: 2.6929473482079977

Epoch: 6| Step: 13
Training loss: 2.3469883227258967
Validation loss: 2.694880037358577

Epoch: 89| Step: 0
Training loss: 2.512487694249929
Validation loss: 2.692605119917112

Epoch: 6| Step: 1
Training loss: 3.075388665176246
Validation loss: 2.698620548109735

Epoch: 6| Step: 2
Training loss: 3.5041030267174773
Validation loss: 2.697162649345875

Epoch: 6| Step: 3
Training loss: 3.176653790229353
Validation loss: 2.6969776794539784

Epoch: 6| Step: 4
Training loss: 2.7855555607916136
Validation loss: 2.6940607451335357

Epoch: 6| Step: 5
Training loss: 2.429573473447226
Validation loss: 2.6961964165328616

Epoch: 6| Step: 6
Training loss: 2.9672253357703227
Validation loss: 2.691632865993997

Epoch: 6| Step: 7
Training loss: 3.7336007436849257
Validation loss: 2.690283419262887

Epoch: 6| Step: 8
Training loss: 2.6801268103474984
Validation loss: 2.6879133892420057

Epoch: 6| Step: 9
Training loss: 3.2542970566914935
Validation loss: 2.6886962647330526

Epoch: 6| Step: 10
Training loss: 2.671566951014869
Validation loss: 2.689758145744192

Epoch: 6| Step: 11
Training loss: 3.192594757466157
Validation loss: 2.68785062116294

Epoch: 6| Step: 12
Training loss: 3.1931645045185943
Validation loss: 2.68913767264113

Epoch: 6| Step: 13
Training loss: 2.949097323917938
Validation loss: 2.6918060497770364

Epoch: 90| Step: 0
Training loss: 2.8770283717035037
Validation loss: 2.6904956103307063

Epoch: 6| Step: 1
Training loss: 3.166599641057133
Validation loss: 2.7071011238353435

Epoch: 6| Step: 2
Training loss: 3.2476528201659782
Validation loss: 2.701160763094617

Epoch: 6| Step: 3
Training loss: 2.9066148754487044
Validation loss: 2.690923311016379

Epoch: 6| Step: 4
Training loss: 2.6877725152531045
Validation loss: 2.687557499340331

Epoch: 6| Step: 5
Training loss: 3.0854748342844944
Validation loss: 2.691639235959418

Epoch: 6| Step: 6
Training loss: 2.670790245752032
Validation loss: 2.6946473249473035

Epoch: 6| Step: 7
Training loss: 3.0850907721372898
Validation loss: 2.706801947204448

Epoch: 6| Step: 8
Training loss: 3.3518384984333713
Validation loss: 2.7006320576647553

Epoch: 6| Step: 9
Training loss: 2.900328150631865
Validation loss: 2.702792962241667

Epoch: 6| Step: 10
Training loss: 2.7839038488785897
Validation loss: 2.6973520944811993

Epoch: 6| Step: 11
Training loss: 3.0903738075985108
Validation loss: 2.697922566953374

Epoch: 6| Step: 12
Training loss: 3.059390610995028
Validation loss: 2.6980904080451844

Epoch: 6| Step: 13
Training loss: 3.624902658142127
Validation loss: 2.698724341134484

Epoch: 91| Step: 0
Training loss: 2.621729038981548
Validation loss: 2.6905061393103797

Epoch: 6| Step: 1
Training loss: 3.5555551664696585
Validation loss: 2.6897335610621607

Epoch: 6| Step: 2
Training loss: 3.606282283962404
Validation loss: 2.6856084750541513

Epoch: 6| Step: 3
Training loss: 3.236308676201368
Validation loss: 2.6861970666363666

Epoch: 6| Step: 4
Training loss: 2.8770290346613083
Validation loss: 2.6897064065173955

Epoch: 6| Step: 5
Training loss: 2.986022494477296
Validation loss: 2.6895916395574706

Epoch: 6| Step: 6
Training loss: 3.0349813874882168
Validation loss: 2.689804969820585

Epoch: 6| Step: 7
Training loss: 2.8521960247134337
Validation loss: 2.690914574750023

Epoch: 6| Step: 8
Training loss: 2.4706090373945284
Validation loss: 2.6855406910516533

Epoch: 6| Step: 9
Training loss: 2.6955865250761963
Validation loss: 2.6943562042155964

Epoch: 6| Step: 10
Training loss: 3.17648536599738
Validation loss: 2.6962922077556013

Epoch: 6| Step: 11
Training loss: 3.1224931962097173
Validation loss: 2.6851238803452624

Epoch: 6| Step: 12
Training loss: 2.810474005119665
Validation loss: 2.6852330393053854

Epoch: 6| Step: 13
Training loss: 2.9059881276927158
Validation loss: 2.682879943724245

Epoch: 92| Step: 0
Training loss: 3.3425387746748845
Validation loss: 2.6895805675008506

Epoch: 6| Step: 1
Training loss: 2.801624633985109
Validation loss: 2.688051529172337

Epoch: 6| Step: 2
Training loss: 3.639975297445798
Validation loss: 2.6876233323709355

Epoch: 6| Step: 3
Training loss: 3.172018414341703
Validation loss: 2.691162288823792

Epoch: 6| Step: 4
Training loss: 3.0567162842573152
Validation loss: 2.6866329480020226

Epoch: 6| Step: 5
Training loss: 2.7357634588686315
Validation loss: 2.6903398499874323

Epoch: 6| Step: 6
Training loss: 2.9386480806851063
Validation loss: 2.6883866683024595

Epoch: 6| Step: 7
Training loss: 3.429475052147308
Validation loss: 2.686039637786488

Epoch: 6| Step: 8
Training loss: 2.8537031108197204
Validation loss: 2.6810003727648968

Epoch: 6| Step: 9
Training loss: 2.497868582989454
Validation loss: 2.6872644676560786

Epoch: 6| Step: 10
Training loss: 3.2033011039147268
Validation loss: 2.688746706655454

Epoch: 6| Step: 11
Training loss: 2.5541195486015495
Validation loss: 2.7040629440972057

Epoch: 6| Step: 12
Training loss: 3.106220120875379
Validation loss: 2.7266355881357836

Epoch: 6| Step: 13
Training loss: 2.7186988738065065
Validation loss: 2.705545398665327

Epoch: 93| Step: 0
Training loss: 3.4928607334404917
Validation loss: 2.6833171072288224

Epoch: 6| Step: 1
Training loss: 3.1055809912401022
Validation loss: 2.6760979165845775

Epoch: 6| Step: 2
Training loss: 2.7980400514606
Validation loss: 2.66990813844178

Epoch: 6| Step: 3
Training loss: 3.165279201588895
Validation loss: 2.6727025711907677

Epoch: 6| Step: 4
Training loss: 2.6448744490595093
Validation loss: 2.671845550173316

Epoch: 6| Step: 5
Training loss: 2.365986132048258
Validation loss: 2.6805421716000764

Epoch: 6| Step: 6
Training loss: 3.403244932809402
Validation loss: 2.684508583576329

Epoch: 6| Step: 7
Training loss: 2.9873255978039825
Validation loss: 2.6882486166405

Epoch: 6| Step: 8
Training loss: 2.7242323747911725
Validation loss: 2.689813275080728

Epoch: 6| Step: 9
Training loss: 3.3154442136555855
Validation loss: 2.696155690017408

Epoch: 6| Step: 10
Training loss: 3.4508120700599
Validation loss: 2.6933698509038932

Epoch: 6| Step: 11
Training loss: 2.955376952215656
Validation loss: 2.6717496356915293

Epoch: 6| Step: 12
Training loss: 2.0753184706101293
Validation loss: 2.6713304006011955

Epoch: 6| Step: 13
Training loss: 3.4757861009813866
Validation loss: 2.6695421444250145

Epoch: 94| Step: 0
Training loss: 2.6762898873604377
Validation loss: 2.6671918984984395

Epoch: 6| Step: 1
Training loss: 3.1335361624737574
Validation loss: 2.671724567689307

Epoch: 6| Step: 2
Training loss: 3.2138452288637565
Validation loss: 2.674774775369094

Epoch: 6| Step: 3
Training loss: 3.6020606765931755
Validation loss: 2.673484788891889

Epoch: 6| Step: 4
Training loss: 3.567892844819168
Validation loss: 2.6707865948424043

Epoch: 6| Step: 5
Training loss: 2.289194148838018
Validation loss: 2.667598181607994

Epoch: 6| Step: 6
Training loss: 3.0562298483467
Validation loss: 2.667822925234597

Epoch: 6| Step: 7
Training loss: 2.593611564159087
Validation loss: 2.672966527423836

Epoch: 6| Step: 8
Training loss: 3.627586625771744
Validation loss: 2.6707578937290894

Epoch: 6| Step: 9
Training loss: 3.040355417154723
Validation loss: 2.6771717640280714

Epoch: 6| Step: 10
Training loss: 3.1113253663476472
Validation loss: 2.6871136919267626

Epoch: 6| Step: 11
Training loss: 2.1220903110395675
Validation loss: 2.6723583556378774

Epoch: 6| Step: 12
Training loss: 3.1247439470294314
Validation loss: 2.674874403539655

Epoch: 6| Step: 13
Training loss: 2.1483410622887074
Validation loss: 2.667634310307614

Epoch: 95| Step: 0
Training loss: 3.282143462110025
Validation loss: 2.673464110801374

Epoch: 6| Step: 1
Training loss: 3.248945945593009
Validation loss: 2.6739804877880986

Epoch: 6| Step: 2
Training loss: 2.853946055404377
Validation loss: 2.667565777417378

Epoch: 6| Step: 3
Training loss: 3.29264263379979
Validation loss: 2.6680361252585625

Epoch: 6| Step: 4
Training loss: 3.008691594849003
Validation loss: 2.666407567429434

Epoch: 6| Step: 5
Training loss: 2.553198517542831
Validation loss: 2.6708401130207684

Epoch: 6| Step: 6
Training loss: 2.2585832276918936
Validation loss: 2.66580695924914

Epoch: 6| Step: 7
Training loss: 2.7616783473662396
Validation loss: 2.661198726039828

Epoch: 6| Step: 8
Training loss: 2.64253229184662
Validation loss: 2.663456228910876

Epoch: 6| Step: 9
Training loss: 3.2368649835720675
Validation loss: 2.6683143869040347

Epoch: 6| Step: 10
Training loss: 3.171605892698308
Validation loss: 2.6655427258725264

Epoch: 6| Step: 11
Training loss: 3.849544592340815
Validation loss: 2.6616670812298953

Epoch: 6| Step: 12
Training loss: 2.794520916491763
Validation loss: 2.668087039446935

Epoch: 6| Step: 13
Training loss: 2.3892742654419
Validation loss: 2.6603632052228163

Epoch: 96| Step: 0
Training loss: 2.8258221771760983
Validation loss: 2.6604249085019784

Epoch: 6| Step: 1
Training loss: 2.7062876286875
Validation loss: 2.6595928393034685

Epoch: 6| Step: 2
Training loss: 3.08035677639345
Validation loss: 2.6625265071322977

Epoch: 6| Step: 3
Training loss: 2.475148949813119
Validation loss: 2.6631238929040095

Epoch: 6| Step: 4
Training loss: 3.2886953987162006
Validation loss: 2.6645874472393625

Epoch: 6| Step: 5
Training loss: 2.9264780597551923
Validation loss: 2.657451388354038

Epoch: 6| Step: 6
Training loss: 3.0663938096881407
Validation loss: 2.659855858501673

Epoch: 6| Step: 7
Training loss: 3.5758225141681783
Validation loss: 2.658229754601776

Epoch: 6| Step: 8
Training loss: 3.133131814793637
Validation loss: 2.660193821247184

Epoch: 6| Step: 9
Training loss: 3.025744600317836
Validation loss: 2.663522003141157

Epoch: 6| Step: 10
Training loss: 2.6940208104214123
Validation loss: 2.672366174065586

Epoch: 6| Step: 11
Training loss: 3.010657928901249
Validation loss: 2.6612714591838476

Epoch: 6| Step: 12
Training loss: 2.7859209249520074
Validation loss: 2.6932751312986016

Epoch: 6| Step: 13
Training loss: 3.4804487473997323
Validation loss: 2.7145310952612025

Epoch: 97| Step: 0
Training loss: 3.0511075869795574
Validation loss: 2.677305072960233

Epoch: 6| Step: 1
Training loss: 3.173995939073086
Validation loss: 2.6503580510496705

Epoch: 6| Step: 2
Training loss: 2.620147761771856
Validation loss: 2.649644739217725

Epoch: 6| Step: 3
Training loss: 3.8075953969945857
Validation loss: 2.6503592736924055

Epoch: 6| Step: 4
Training loss: 2.438491032946652
Validation loss: 2.6543260781432405

Epoch: 6| Step: 5
Training loss: 3.6155680580238214
Validation loss: 2.654217153882843

Epoch: 6| Step: 6
Training loss: 2.796686347267762
Validation loss: 2.6531984775588335

Epoch: 6| Step: 7
Training loss: 2.9081455734840214
Validation loss: 2.653785404745094

Epoch: 6| Step: 8
Training loss: 2.5554840059446025
Validation loss: 2.6561109078150693

Epoch: 6| Step: 9
Training loss: 3.0056839185918145
Validation loss: 2.6491522023550425

Epoch: 6| Step: 10
Training loss: 2.499934577085863
Validation loss: 2.6479834018668265

Epoch: 6| Step: 11
Training loss: 2.949198216246812
Validation loss: 2.6469464029869227

Epoch: 6| Step: 12
Training loss: 3.2774144598115504
Validation loss: 2.6434970543968017

Epoch: 6| Step: 13
Training loss: 3.0429964860036507
Validation loss: 2.6566828201973594

Epoch: 98| Step: 0
Training loss: 2.8261708626682704
Validation loss: 2.6661993506205253

Epoch: 6| Step: 1
Training loss: 3.131622621213996
Validation loss: 2.6742833985248367

Epoch: 6| Step: 2
Training loss: 2.366084581528784
Validation loss: 2.698486943150042

Epoch: 6| Step: 3
Training loss: 1.8983022382610377
Validation loss: 2.7072869720915107

Epoch: 6| Step: 4
Training loss: 3.2712282723917654
Validation loss: 2.714023529274896

Epoch: 6| Step: 5
Training loss: 2.7312123346241277
Validation loss: 2.6762609689067047

Epoch: 6| Step: 6
Training loss: 3.370353608638955
Validation loss: 2.6462293571861215

Epoch: 6| Step: 7
Training loss: 2.9554398763417433
Validation loss: 2.643889689885354

Epoch: 6| Step: 8
Training loss: 3.089182555085176
Validation loss: 2.6511622791754865

Epoch: 6| Step: 9
Training loss: 3.157584333222334
Validation loss: 2.655390782523978

Epoch: 6| Step: 10
Training loss: 2.7398097497088387
Validation loss: 2.659501739382008

Epoch: 6| Step: 11
Training loss: 3.525596887361119
Validation loss: 2.668263923821041

Epoch: 6| Step: 12
Training loss: 3.120689165344607
Validation loss: 2.666072266484937

Epoch: 6| Step: 13
Training loss: 3.99194048511121
Validation loss: 2.6603071100031572

Epoch: 99| Step: 0
Training loss: 3.3560976587028835
Validation loss: 2.6577500018625706

Epoch: 6| Step: 1
Training loss: 2.8253928628704585
Validation loss: 2.655931423513658

Epoch: 6| Step: 2
Training loss: 2.4325639679859408
Validation loss: 2.6542171220089843

Epoch: 6| Step: 3
Training loss: 2.4586364645409673
Validation loss: 2.6518247839305107

Epoch: 6| Step: 4
Training loss: 3.37510907032236
Validation loss: 2.651227570330706

Epoch: 6| Step: 5
Training loss: 2.572445804481056
Validation loss: 2.648107441026609

Epoch: 6| Step: 6
Training loss: 2.8256400978243605
Validation loss: 2.648125917207026

Epoch: 6| Step: 7
Training loss: 3.4058678088875105
Validation loss: 2.6425458835491873

Epoch: 6| Step: 8
Training loss: 3.1361308419802927
Validation loss: 2.6428192540159916

Epoch: 6| Step: 9
Training loss: 3.3731401758592976
Validation loss: 2.642546835256791

Epoch: 6| Step: 10
Training loss: 2.514362468569727
Validation loss: 2.657454345154757

Epoch: 6| Step: 11
Training loss: 3.782340404827186
Validation loss: 2.6835346238397295

Epoch: 6| Step: 12
Training loss: 2.7248713541724405
Validation loss: 2.703209354967708

Epoch: 6| Step: 13
Training loss: 2.5838814943438764
Validation loss: 2.679900480295045

Epoch: 100| Step: 0
Training loss: 3.1808989745247827
Validation loss: 2.6856830041714153

Epoch: 6| Step: 1
Training loss: 3.060489539587389
Validation loss: 2.6772266067260966

Epoch: 6| Step: 2
Training loss: 2.714831455120541
Validation loss: 2.6576229728569842

Epoch: 6| Step: 3
Training loss: 2.697795398790077
Validation loss: 2.6442408951315115

Epoch: 6| Step: 4
Training loss: 2.939508765825132
Validation loss: 2.6397540559091817

Epoch: 6| Step: 5
Training loss: 2.7471761076266477
Validation loss: 2.6438897509731363

Epoch: 6| Step: 6
Training loss: 2.5991551713932872
Validation loss: 2.6405436729066785

Epoch: 6| Step: 7
Training loss: 3.319200899632558
Validation loss: 2.6440400623989615

Epoch: 6| Step: 8
Training loss: 3.5795315972042068
Validation loss: 2.6391971264191425

Epoch: 6| Step: 9
Training loss: 3.1063521370319824
Validation loss: 2.6421985388006637

Epoch: 6| Step: 10
Training loss: 3.2384645711549
Validation loss: 2.642816678558289

Epoch: 6| Step: 11
Training loss: 3.1634979121088405
Validation loss: 2.6489205652658807

Epoch: 6| Step: 12
Training loss: 2.48282723827561
Validation loss: 2.6480874389759403

Epoch: 6| Step: 13
Training loss: 2.7037426898802805
Validation loss: 2.6432379270188475

Epoch: 101| Step: 0
Training loss: 3.1291982297833574
Validation loss: 2.642249958622121

Epoch: 6| Step: 1
Training loss: 2.253766298494314
Validation loss: 2.6403150838364295

Epoch: 6| Step: 2
Training loss: 3.2735114988279763
Validation loss: 2.641634871353387

Epoch: 6| Step: 3
Training loss: 2.846244975116166
Validation loss: 2.6375130761969405

Epoch: 6| Step: 4
Training loss: 2.2526052015592515
Validation loss: 2.6397313402276463

Epoch: 6| Step: 5
Training loss: 3.04905333288984
Validation loss: 2.6418365147783844

Epoch: 6| Step: 6
Training loss: 2.457732520527011
Validation loss: 2.6484153166566156

Epoch: 6| Step: 7
Training loss: 2.23596369676685
Validation loss: 2.650364032707807

Epoch: 6| Step: 8
Training loss: 4.123274239867308
Validation loss: 2.6707256584225565

Epoch: 6| Step: 9
Training loss: 2.8522520302888923
Validation loss: 2.6583655101171053

Epoch: 6| Step: 10
Training loss: 3.1421672014200146
Validation loss: 2.641912200115502

Epoch: 6| Step: 11
Training loss: 3.6768143567199227
Validation loss: 2.641512051973933

Epoch: 6| Step: 12
Training loss: 2.7474715139562815
Validation loss: 2.6426133317027527

Epoch: 6| Step: 13
Training loss: 3.1771566080283917
Validation loss: 2.6371466973845035

Epoch: 102| Step: 0
Training loss: 2.6599963528027306
Validation loss: 2.6342053810484507

Epoch: 6| Step: 1
Training loss: 2.682265751290665
Validation loss: 2.635755220906584

Epoch: 6| Step: 2
Training loss: 3.224819497668281
Validation loss: 2.6360998114983434

Epoch: 6| Step: 3
Training loss: 3.007905240301188
Validation loss: 2.6397004829094195

Epoch: 6| Step: 4
Training loss: 2.322220348689993
Validation loss: 2.6318819393927626

Epoch: 6| Step: 5
Training loss: 2.9996289977504733
Validation loss: 2.6304119718839254

Epoch: 6| Step: 6
Training loss: 3.3504675296951474
Validation loss: 2.629875293766316

Epoch: 6| Step: 7
Training loss: 2.70565395354713
Validation loss: 2.628427683755628

Epoch: 6| Step: 8
Training loss: 3.304607850325602
Validation loss: 2.627836382631393

Epoch: 6| Step: 9
Training loss: 3.098975959962782
Validation loss: 2.6275631315099064

Epoch: 6| Step: 10
Training loss: 2.678374744641906
Validation loss: 2.631437842305226

Epoch: 6| Step: 11
Training loss: 3.2345016380986413
Validation loss: 2.628258240247822

Epoch: 6| Step: 12
Training loss: 2.9814702622400215
Validation loss: 2.630030386083364

Epoch: 6| Step: 13
Training loss: 3.4090568806655006
Validation loss: 2.6288693179564415

Epoch: 103| Step: 0
Training loss: 3.4021360419341184
Validation loss: 2.629733228258768

Epoch: 6| Step: 1
Training loss: 2.6153401245889905
Validation loss: 2.6304869611531543

Epoch: 6| Step: 2
Training loss: 2.914931753154663
Validation loss: 2.6249197455901077

Epoch: 6| Step: 3
Training loss: 3.3965570969608385
Validation loss: 2.6244267239573995

Epoch: 6| Step: 4
Training loss: 2.689084672587082
Validation loss: 2.6263655886595507

Epoch: 6| Step: 5
Training loss: 3.3270584331640447
Validation loss: 2.625027288714019

Epoch: 6| Step: 6
Training loss: 2.5276359849037155
Validation loss: 2.6214225199371888

Epoch: 6| Step: 7
Training loss: 2.443454219157413
Validation loss: 2.6326146117607787

Epoch: 6| Step: 8
Training loss: 2.8153668521322333
Validation loss: 2.6342153700788358

Epoch: 6| Step: 9
Training loss: 2.8493138474455773
Validation loss: 2.653675040098889

Epoch: 6| Step: 10
Training loss: 3.4127302210914188
Validation loss: 2.67704241500182

Epoch: 6| Step: 11
Training loss: 2.931564340227926
Validation loss: 2.6732492463482336

Epoch: 6| Step: 12
Training loss: 2.888440270518
Validation loss: 2.6503380330965154

Epoch: 6| Step: 13
Training loss: 3.4011397919609903
Validation loss: 2.6372589357691565

Epoch: 104| Step: 0
Training loss: 3.074784533387309
Validation loss: 2.626057799893788

Epoch: 6| Step: 1
Training loss: 3.509388592932338
Validation loss: 2.6241704447446415

Epoch: 6| Step: 2
Training loss: 2.7372019949576156
Validation loss: 2.621225712230824

Epoch: 6| Step: 3
Training loss: 2.937004209843373
Validation loss: 2.617841236036924

Epoch: 6| Step: 4
Training loss: 2.584195844167145
Validation loss: 2.621676673962632

Epoch: 6| Step: 5
Training loss: 2.518664117678875
Validation loss: 2.6152657542938935

Epoch: 6| Step: 6
Training loss: 3.1511300739255197
Validation loss: 2.62091343661734

Epoch: 6| Step: 7
Training loss: 3.6226820276201703
Validation loss: 2.619511154665008

Epoch: 6| Step: 8
Training loss: 2.6152770400039227
Validation loss: 2.622847172841645

Epoch: 6| Step: 9
Training loss: 3.2187337041646042
Validation loss: 2.6450508067652807

Epoch: 6| Step: 10
Training loss: 2.850453952976106
Validation loss: 2.6301356080262726

Epoch: 6| Step: 11
Training loss: 3.1257700162159887
Validation loss: 2.6191446899941417

Epoch: 6| Step: 12
Training loss: 2.836004755573025
Validation loss: 2.616389413439806

Epoch: 6| Step: 13
Training loss: 2.455761312933045
Validation loss: 2.6182752523074795

Epoch: 105| Step: 0
Training loss: 3.26257444567167
Validation loss: 2.620265079205947

Epoch: 6| Step: 1
Training loss: 3.2605800079932696
Validation loss: 2.6184332571435665

Epoch: 6| Step: 2
Training loss: 3.4307680274419132
Validation loss: 2.619851304077196

Epoch: 6| Step: 3
Training loss: 3.161930976910562
Validation loss: 2.6188859987325697

Epoch: 6| Step: 4
Training loss: 2.973423221010611
Validation loss: 2.6166267677145916

Epoch: 6| Step: 5
Training loss: 2.7222339625548733
Validation loss: 2.6164825964380745

Epoch: 6| Step: 6
Training loss: 3.0828471101112505
Validation loss: 2.6196741042560454

Epoch: 6| Step: 7
Training loss: 2.285589193429258
Validation loss: 2.618221439564351

Epoch: 6| Step: 8
Training loss: 2.8637348559947817
Validation loss: 2.6174512847464384

Epoch: 6| Step: 9
Training loss: 2.7699481343670933
Validation loss: 2.6170166430034336

Epoch: 6| Step: 10
Training loss: 3.0716638284864333
Validation loss: 2.617859015089775

Epoch: 6| Step: 11
Training loss: 3.1530797163071687
Validation loss: 2.6184786828585405

Epoch: 6| Step: 12
Training loss: 2.6769290884584542
Validation loss: 2.6243595781616973

Epoch: 6| Step: 13
Training loss: 2.2060017302878987
Validation loss: 2.6377558403461427

Epoch: 106| Step: 0
Training loss: 2.383590821270939
Validation loss: 2.646836143508985

Epoch: 6| Step: 1
Training loss: 2.2199308449911155
Validation loss: 2.6691776360009665

Epoch: 6| Step: 2
Training loss: 2.739434232147573
Validation loss: 2.6821349398762258

Epoch: 6| Step: 3
Training loss: 2.5616408978144203
Validation loss: 2.7038501357498874

Epoch: 6| Step: 4
Training loss: 3.211583724509023
Validation loss: 2.7292218917022377

Epoch: 6| Step: 5
Training loss: 3.249156255503983
Validation loss: 2.671391582815783

Epoch: 6| Step: 6
Training loss: 3.6367178321779856
Validation loss: 2.629928186670547

Epoch: 6| Step: 7
Training loss: 2.8383355208735868
Validation loss: 2.6207567091828556

Epoch: 6| Step: 8
Training loss: 3.291324951848369
Validation loss: 2.612330748664094

Epoch: 6| Step: 9
Training loss: 2.7705311335542517
Validation loss: 2.6193650183120454

Epoch: 6| Step: 10
Training loss: 2.439763705271688
Validation loss: 2.6204251261708333

Epoch: 6| Step: 11
Training loss: 3.332690049723991
Validation loss: 2.616885256162405

Epoch: 6| Step: 12
Training loss: 3.096277610831264
Validation loss: 2.6198758908666266

Epoch: 6| Step: 13
Training loss: 3.6368354426263454
Validation loss: 2.6166922249873994

Epoch: 107| Step: 0
Training loss: 3.1041653182946334
Validation loss: 2.6095632095059913

Epoch: 6| Step: 1
Training loss: 2.368038012109272
Validation loss: 2.6121876386951692

Epoch: 6| Step: 2
Training loss: 2.3012778712816995
Validation loss: 2.6156235169129505

Epoch: 6| Step: 3
Training loss: 3.646862662195617
Validation loss: 2.6207356052758946

Epoch: 6| Step: 4
Training loss: 2.236905352463015
Validation loss: 2.627146472731486

Epoch: 6| Step: 5
Training loss: 2.7110983501283394
Validation loss: 2.6297155987014595

Epoch: 6| Step: 6
Training loss: 2.731419562831121
Validation loss: 2.642601970653575

Epoch: 6| Step: 7
Training loss: 3.290971577969332
Validation loss: 2.6581048703400927

Epoch: 6| Step: 8
Training loss: 2.9288216493954162
Validation loss: 2.6573837119296644

Epoch: 6| Step: 9
Training loss: 3.4548256945219116
Validation loss: 2.644136783269953

Epoch: 6| Step: 10
Training loss: 2.865273650250585
Validation loss: 2.6253582133296742

Epoch: 6| Step: 11
Training loss: 3.234665862195239
Validation loss: 2.614713953750425

Epoch: 6| Step: 12
Training loss: 3.5078062469494657
Validation loss: 2.611692178225192

Epoch: 6| Step: 13
Training loss: 2.230962748696575
Validation loss: 2.6128893730900815

Epoch: 108| Step: 0
Training loss: 2.5872469349823732
Validation loss: 2.612160213885053

Epoch: 6| Step: 1
Training loss: 2.4426117141149137
Validation loss: 2.6138788292301314

Epoch: 6| Step: 2
Training loss: 2.994250510153369
Validation loss: 2.61044434281332

Epoch: 6| Step: 3
Training loss: 2.846660926717768
Validation loss: 2.6080569423131257

Epoch: 6| Step: 4
Training loss: 3.3924833909304932
Validation loss: 2.6098368216815895

Epoch: 6| Step: 5
Training loss: 2.91492635486677
Validation loss: 2.6076442034868816

Epoch: 6| Step: 6
Training loss: 2.718285356476733
Validation loss: 2.6088356628352014

Epoch: 6| Step: 7
Training loss: 2.879708125371233
Validation loss: 2.6064442433511754

Epoch: 6| Step: 8
Training loss: 3.2301946336902048
Validation loss: 2.6107856661419064

Epoch: 6| Step: 9
Training loss: 3.4408300742308455
Validation loss: 2.6077171021819563

Epoch: 6| Step: 10
Training loss: 2.941839543378737
Validation loss: 2.613123453606998

Epoch: 6| Step: 11
Training loss: 2.861513099289819
Validation loss: 2.619537669674914

Epoch: 6| Step: 12
Training loss: 2.8835871619658553
Validation loss: 2.611134118466268

Epoch: 6| Step: 13
Training loss: 3.1783718977217017
Validation loss: 2.6103722318105937

Epoch: 109| Step: 0
Training loss: 2.9776801466554685
Validation loss: 2.6075894536548563

Epoch: 6| Step: 1
Training loss: 2.409703538317136
Validation loss: 2.6130368644688633

Epoch: 6| Step: 2
Training loss: 2.397295254267361
Validation loss: 2.6099977880529903

Epoch: 6| Step: 3
Training loss: 2.778912022337711
Validation loss: 2.622538051277752

Epoch: 6| Step: 4
Training loss: 3.104416310216178
Validation loss: 2.6151969548150062

Epoch: 6| Step: 5
Training loss: 3.122853571937483
Validation loss: 2.6205331442999156

Epoch: 6| Step: 6
Training loss: 3.0594566949958106
Validation loss: 2.6190676086828493

Epoch: 6| Step: 7
Training loss: 2.8553595358944963
Validation loss: 2.651438113466353

Epoch: 6| Step: 8
Training loss: 2.8249380796955124
Validation loss: 2.689293210910273

Epoch: 6| Step: 9
Training loss: 2.708100607238546
Validation loss: 2.6538072224797316

Epoch: 6| Step: 10
Training loss: 3.393171628560321
Validation loss: 2.6275613528586517

Epoch: 6| Step: 11
Training loss: 3.6916766032364348
Validation loss: 2.6156767734776585

Epoch: 6| Step: 12
Training loss: 2.963318041435523
Validation loss: 2.603495241957786

Epoch: 6| Step: 13
Training loss: 2.9425963974090013
Validation loss: 2.6102396727503994

Epoch: 110| Step: 0
Training loss: 2.996455960219206
Validation loss: 2.6106112457771493

Epoch: 6| Step: 1
Training loss: 2.752543486928121
Validation loss: 2.609934793383112

Epoch: 6| Step: 2
Training loss: 2.8468083295332858
Validation loss: 2.6076027305135954

Epoch: 6| Step: 3
Training loss: 2.9236679695824397
Validation loss: 2.606191732934144

Epoch: 6| Step: 4
Training loss: 3.283238997935715
Validation loss: 2.606243380177187

Epoch: 6| Step: 5
Training loss: 3.2865705677501826
Validation loss: 2.6053867486152607

Epoch: 6| Step: 6
Training loss: 2.8311377227280397
Validation loss: 2.6069524959728825

Epoch: 6| Step: 7
Training loss: 2.6204152714337443
Validation loss: 2.604202022845716

Epoch: 6| Step: 8
Training loss: 2.888549059255288
Validation loss: 2.6131307693889725

Epoch: 6| Step: 9
Training loss: 2.854272678012172
Validation loss: 2.6179117629830815

Epoch: 6| Step: 10
Training loss: 2.876687591170161
Validation loss: 2.6287039697069865

Epoch: 6| Step: 11
Training loss: 3.082649120674666
Validation loss: 2.648533758283055

Epoch: 6| Step: 12
Training loss: 3.369273661322691
Validation loss: 2.6663954732135746

Epoch: 6| Step: 13
Training loss: 2.3810488318026386
Validation loss: 2.624433838261362

Epoch: 111| Step: 0
Training loss: 3.089381977978666
Validation loss: 2.6038679625134065

Epoch: 6| Step: 1
Training loss: 2.6991284765227235
Validation loss: 2.6029399632386636

Epoch: 6| Step: 2
Training loss: 3.01708695942015
Validation loss: 2.603315704773614

Epoch: 6| Step: 3
Training loss: 2.9006858803841817
Validation loss: 2.6158402853401856

Epoch: 6| Step: 4
Training loss: 2.789960615092021
Validation loss: 2.609438697863241

Epoch: 6| Step: 5
Training loss: 3.3391198160038944
Validation loss: 2.611616352344576

Epoch: 6| Step: 6
Training loss: 2.5231750162802347
Validation loss: 2.607802830822955

Epoch: 6| Step: 7
Training loss: 2.605807852803975
Validation loss: 2.6059366195910947

Epoch: 6| Step: 8
Training loss: 2.836836911332589
Validation loss: 2.6033643553918555

Epoch: 6| Step: 9
Training loss: 2.7757881626136487
Validation loss: 2.5978250699572376

Epoch: 6| Step: 10
Training loss: 3.642487274755113
Validation loss: 2.598623967217609

Epoch: 6| Step: 11
Training loss: 2.930824811798483
Validation loss: 2.606185656778478

Epoch: 6| Step: 12
Training loss: 2.916809914113918
Validation loss: 2.6047109236137262

Epoch: 6| Step: 13
Training loss: 3.092698968702053
Validation loss: 2.617932534181931

Epoch: 112| Step: 0
Training loss: 3.0750064446606595
Validation loss: 2.6342280460882903

Epoch: 6| Step: 1
Training loss: 2.9147766710843155
Validation loss: 2.632776740606551

Epoch: 6| Step: 2
Training loss: 3.1126595023470314
Validation loss: 2.612048152318116

Epoch: 6| Step: 3
Training loss: 3.107538188721154
Validation loss: 2.605574420709035

Epoch: 6| Step: 4
Training loss: 3.045105718772499
Validation loss: 2.6018520387370914

Epoch: 6| Step: 5
Training loss: 2.424462492844842
Validation loss: 2.5994363329973975

Epoch: 6| Step: 6
Training loss: 3.1584572203267656
Validation loss: 2.5983069387719704

Epoch: 6| Step: 7
Training loss: 2.902103871101465
Validation loss: 2.598794280472822

Epoch: 6| Step: 8
Training loss: 2.9643568762479156
Validation loss: 2.5994587065021575

Epoch: 6| Step: 9
Training loss: 2.7307591536264684
Validation loss: 2.603252575981643

Epoch: 6| Step: 10
Training loss: 2.8522633984505403
Validation loss: 2.598303795277303

Epoch: 6| Step: 11
Training loss: 2.853681388494696
Validation loss: 2.59888338508693

Epoch: 6| Step: 12
Training loss: 3.4770842085727316
Validation loss: 2.60146523886047

Epoch: 6| Step: 13
Training loss: 2.0782686341633196
Validation loss: 2.6029283029584063

Epoch: 113| Step: 0
Training loss: 3.5326166799703844
Validation loss: 2.6020006877936126

Epoch: 6| Step: 1
Training loss: 3.1412658037667796
Validation loss: 2.5992613917052796

Epoch: 6| Step: 2
Training loss: 2.5227467444790777
Validation loss: 2.5943426410672474

Epoch: 6| Step: 3
Training loss: 2.884865791994037
Validation loss: 2.600418773100247

Epoch: 6| Step: 4
Training loss: 3.368124280580156
Validation loss: 2.597890004772504

Epoch: 6| Step: 5
Training loss: 2.904661831632064
Validation loss: 2.5972835717851943

Epoch: 6| Step: 6
Training loss: 3.1205733418023334
Validation loss: 2.598643848836781

Epoch: 6| Step: 7
Training loss: 2.695927911796424
Validation loss: 2.6065522497562585

Epoch: 6| Step: 8
Training loss: 2.7491819725601125
Validation loss: 2.6156981769460503

Epoch: 6| Step: 9
Training loss: 2.895798131788257
Validation loss: 2.6351898113879737

Epoch: 6| Step: 10
Training loss: 2.593351218579488
Validation loss: 2.61616478156331

Epoch: 6| Step: 11
Training loss: 3.1313620846117187
Validation loss: 2.5993567963212696

Epoch: 6| Step: 12
Training loss: 2.883725401695316
Validation loss: 2.595477118614705

Epoch: 6| Step: 13
Training loss: 2.7475460547769015
Validation loss: 2.5991905372207174

Epoch: 114| Step: 0
Training loss: 3.2249673590375934
Validation loss: 2.617810599571338

Epoch: 6| Step: 1
Training loss: 3.065521773565091
Validation loss: 2.654523460404747

Epoch: 6| Step: 2
Training loss: 2.207576718061116
Validation loss: 2.6938538054266328

Epoch: 6| Step: 3
Training loss: 3.2132862717069623
Validation loss: 2.7077865452500016

Epoch: 6| Step: 4
Training loss: 3.002477258854995
Validation loss: 2.624522179840523

Epoch: 6| Step: 5
Training loss: 3.3696877386387922
Validation loss: 2.5893762021974074

Epoch: 6| Step: 6
Training loss: 2.306643415767522
Validation loss: 2.5881365846198916

Epoch: 6| Step: 7
Training loss: 3.278213694693525
Validation loss: 2.62607810933768

Epoch: 6| Step: 8
Training loss: 3.081579448427812
Validation loss: 2.6846514403296395

Epoch: 6| Step: 9
Training loss: 3.1327452236191182
Validation loss: 2.6650436500468917

Epoch: 6| Step: 10
Training loss: 3.056387737891496
Validation loss: 2.6120958727999324

Epoch: 6| Step: 11
Training loss: 2.7665190033017817
Validation loss: 2.597159515784088

Epoch: 6| Step: 12
Training loss: 3.0432533062555205
Validation loss: 2.59543631402042

Epoch: 6| Step: 13
Training loss: 3.3212082316593747
Validation loss: 2.5981002128458472

Epoch: 115| Step: 0
Training loss: 2.60354419643925
Validation loss: 2.6369255215152725

Epoch: 6| Step: 1
Training loss: 2.545794766930518
Validation loss: 2.712830059297661

Epoch: 6| Step: 2
Training loss: 3.3640575332711244
Validation loss: 2.6769191314441376

Epoch: 6| Step: 3
Training loss: 3.2717650882364
Validation loss: 2.638092144682732

Epoch: 6| Step: 4
Training loss: 2.941103571381044
Validation loss: 2.6007996349431397

Epoch: 6| Step: 5
Training loss: 2.7422885278420437
Validation loss: 2.585281271456256

Epoch: 6| Step: 6
Training loss: 3.4339081465134456
Validation loss: 2.5802427462002595

Epoch: 6| Step: 7
Training loss: 2.444180845247025
Validation loss: 2.5821462951272296

Epoch: 6| Step: 8
Training loss: 2.934940927876074
Validation loss: 2.582651596804907

Epoch: 6| Step: 9
Training loss: 3.2071760658343567
Validation loss: 2.581653464260056

Epoch: 6| Step: 10
Training loss: 2.747885584757882
Validation loss: 2.5821186674092553

Epoch: 6| Step: 11
Training loss: 3.0779000601899957
Validation loss: 2.5998659108800166

Epoch: 6| Step: 12
Training loss: 2.9261014836952084
Validation loss: 2.631340537743407

Epoch: 6| Step: 13
Training loss: 2.9187541757427136
Validation loss: 2.6511433812725183

Epoch: 116| Step: 0
Training loss: 3.1647769074360252
Validation loss: 2.6426726118968555

Epoch: 6| Step: 1
Training loss: 2.857884586649347
Validation loss: 2.5907059820798937

Epoch: 6| Step: 2
Training loss: 2.9154805269253403
Validation loss: 2.5798045544763264

Epoch: 6| Step: 3
Training loss: 2.9834316819956266
Validation loss: 2.5751681647150177

Epoch: 6| Step: 4
Training loss: 2.4826933729570304
Validation loss: 2.573949306619931

Epoch: 6| Step: 5
Training loss: 2.7376486228417294
Validation loss: 2.576258693157235

Epoch: 6| Step: 6
Training loss: 2.8515317314264683
Validation loss: 2.580549990080928

Epoch: 6| Step: 7
Training loss: 3.526420328758755
Validation loss: 2.606729310895919

Epoch: 6| Step: 8
Training loss: 3.571800272536197
Validation loss: 2.6075646487681885

Epoch: 6| Step: 9
Training loss: 3.2415929777764103
Validation loss: 2.585503513793625

Epoch: 6| Step: 10
Training loss: 2.9858398038251224
Validation loss: 2.5730182016050422

Epoch: 6| Step: 11
Training loss: 2.947130689319148
Validation loss: 2.564774216129203

Epoch: 6| Step: 12
Training loss: 2.48081494416057
Validation loss: 2.564140119092218

Epoch: 6| Step: 13
Training loss: 2.008986193118162
Validation loss: 2.5630423979495687

Epoch: 117| Step: 0
Training loss: 3.121268218586541
Validation loss: 2.571858500383356

Epoch: 6| Step: 1
Training loss: 2.983172429041614
Validation loss: 2.583564180016103

Epoch: 6| Step: 2
Training loss: 3.290299497845517
Validation loss: 2.636993573267292

Epoch: 6| Step: 3
Training loss: 2.713898199068271
Validation loss: 2.6277755238644334

Epoch: 6| Step: 4
Training loss: 3.2305159836329262
Validation loss: 2.6197253643521434

Epoch: 6| Step: 5
Training loss: 3.2330222134167728
Validation loss: 2.609877266555673

Epoch: 6| Step: 6
Training loss: 2.571062714798874
Validation loss: 2.593883742734001

Epoch: 6| Step: 7
Training loss: 2.4823139206217846
Validation loss: 2.587270862542965

Epoch: 6| Step: 8
Training loss: 2.9051743024052716
Validation loss: 2.576525373703861

Epoch: 6| Step: 9
Training loss: 3.1746734150805866
Validation loss: 2.5731524201322986

Epoch: 6| Step: 10
Training loss: 2.912103480250573
Validation loss: 2.5731439654873256

Epoch: 6| Step: 11
Training loss: 2.5720591074794847
Validation loss: 2.575443974686124

Epoch: 6| Step: 12
Training loss: 3.0196386320653867
Validation loss: 2.573583849114618

Epoch: 6| Step: 13
Training loss: 2.7885663956372273
Validation loss: 2.5755602686158436

Epoch: 118| Step: 0
Training loss: 2.3860073996186926
Validation loss: 2.5723395312879234

Epoch: 6| Step: 1
Training loss: 3.0299273879412176
Validation loss: 2.575818298919987

Epoch: 6| Step: 2
Training loss: 3.363991054373333
Validation loss: 2.578254676060942

Epoch: 6| Step: 3
Training loss: 3.1606674252439224
Validation loss: 2.577843397564957

Epoch: 6| Step: 4
Training loss: 3.289346062041685
Validation loss: 2.57793329992277

Epoch: 6| Step: 5
Training loss: 3.154698056434325
Validation loss: 2.578445741770362

Epoch: 6| Step: 6
Training loss: 3.0072612306811832
Validation loss: 2.581233489714166

Epoch: 6| Step: 7
Training loss: 2.6958159487918945
Validation loss: 2.5715500944417995

Epoch: 6| Step: 8
Training loss: 2.6037125967253827
Validation loss: 2.5714861050660893

Epoch: 6| Step: 9
Training loss: 3.0925540346376037
Validation loss: 2.5658288978261465

Epoch: 6| Step: 10
Training loss: 3.0110294725894406
Validation loss: 2.5668520073706707

Epoch: 6| Step: 11
Training loss: 2.461737414948778
Validation loss: 2.5633458988076887

Epoch: 6| Step: 12
Training loss: 2.905264246308991
Validation loss: 2.5610215729089933

Epoch: 6| Step: 13
Training loss: 2.238866919143369
Validation loss: 2.5623850963011057

Epoch: 119| Step: 0
Training loss: 2.9318663772589573
Validation loss: 2.5623503160315924

Epoch: 6| Step: 1
Training loss: 3.1567769130104244
Validation loss: 2.5633092733353053

Epoch: 6| Step: 2
Training loss: 2.7674446800650703
Validation loss: 2.5670323890676414

Epoch: 6| Step: 3
Training loss: 2.2426470242447882
Validation loss: 2.569304257683128

Epoch: 6| Step: 4
Training loss: 3.3994560030898118
Validation loss: 2.577741098269681

Epoch: 6| Step: 5
Training loss: 2.707296955670519
Validation loss: 2.5806744302735685

Epoch: 6| Step: 6
Training loss: 2.552170379607406
Validation loss: 2.5768709764254707

Epoch: 6| Step: 7
Training loss: 2.8273664268560323
Validation loss: 2.5704658553066206

Epoch: 6| Step: 8
Training loss: 2.2301559629769527
Validation loss: 2.5708387783440485

Epoch: 6| Step: 9
Training loss: 3.161706419275745
Validation loss: 2.5639973609315234

Epoch: 6| Step: 10
Training loss: 3.0110299476798956
Validation loss: 2.56397225230238

Epoch: 6| Step: 11
Training loss: 3.225237188562316
Validation loss: 2.5563492598714395

Epoch: 6| Step: 12
Training loss: 3.3996972566344166
Validation loss: 2.55830235378498

Epoch: 6| Step: 13
Training loss: 2.8172135591491823
Validation loss: 2.561453468761078

Epoch: 120| Step: 0
Training loss: 3.077401942806681
Validation loss: 2.5631466511577585

Epoch: 6| Step: 1
Training loss: 2.491549514857241
Validation loss: 2.5620035420415452

Epoch: 6| Step: 2
Training loss: 3.309053175193739
Validation loss: 2.561663411276927

Epoch: 6| Step: 3
Training loss: 2.564510487178572
Validation loss: 2.5604935420839325

Epoch: 6| Step: 4
Training loss: 3.2357650939311133
Validation loss: 2.5650870996863877

Epoch: 6| Step: 5
Training loss: 2.329212523562295
Validation loss: 2.5576854058760694

Epoch: 6| Step: 6
Training loss: 2.553194408803989
Validation loss: 2.5570292707364475

Epoch: 6| Step: 7
Training loss: 2.9247526797859402
Validation loss: 2.554736324045832

Epoch: 6| Step: 8
Training loss: 3.01594012101328
Validation loss: 2.5552491609915045

Epoch: 6| Step: 9
Training loss: 3.006392344318771
Validation loss: 2.552951065689418

Epoch: 6| Step: 10
Training loss: 3.600573886057605
Validation loss: 2.5597988191188876

Epoch: 6| Step: 11
Training loss: 3.2849254549762583
Validation loss: 2.553260902889252

Epoch: 6| Step: 12
Training loss: 2.4824577947219333
Validation loss: 2.55428646557941

Epoch: 6| Step: 13
Training loss: 2.425247600538897
Validation loss: 2.5537821081760512

Epoch: 121| Step: 0
Training loss: 3.561906597842702
Validation loss: 2.557117174925218

Epoch: 6| Step: 1
Training loss: 2.851676207065137
Validation loss: 2.5628175396165993

Epoch: 6| Step: 2
Training loss: 2.7510516150016744
Validation loss: 2.5594575850428587

Epoch: 6| Step: 3
Training loss: 2.6498184429808997
Validation loss: 2.5607191871526673

Epoch: 6| Step: 4
Training loss: 2.735723980164701
Validation loss: 2.560565613544893

Epoch: 6| Step: 5
Training loss: 2.571907638398327
Validation loss: 2.5687498625140073

Epoch: 6| Step: 6
Training loss: 3.0128268369284696
Validation loss: 2.571733139169281

Epoch: 6| Step: 7
Training loss: 3.1201266627399162
Validation loss: 2.5765780563818663

Epoch: 6| Step: 8
Training loss: 2.230899054445424
Validation loss: 2.579116784652321

Epoch: 6| Step: 9
Training loss: 2.5262246816084617
Validation loss: 2.581071939255882

Epoch: 6| Step: 10
Training loss: 3.2246086356279435
Validation loss: 2.603230627030593

Epoch: 6| Step: 11
Training loss: 3.0864764165504126
Validation loss: 2.583089777976577

Epoch: 6| Step: 12
Training loss: 3.282633462532913
Validation loss: 2.5632394553603075

Epoch: 6| Step: 13
Training loss: 3.023214011594267
Validation loss: 2.548507453128027

Epoch: 122| Step: 0
Training loss: 2.5400872143467903
Validation loss: 2.5458066279694656

Epoch: 6| Step: 1
Training loss: 3.1886782992745832
Validation loss: 2.5523348070164364

Epoch: 6| Step: 2
Training loss: 2.616819259017098
Validation loss: 2.5576159004757257

Epoch: 6| Step: 3
Training loss: 2.146053364654596
Validation loss: 2.551984354543726

Epoch: 6| Step: 4
Training loss: 3.6385629732847944
Validation loss: 2.5530208115588664

Epoch: 6| Step: 5
Training loss: 3.3317226969167755
Validation loss: 2.550449965852567

Epoch: 6| Step: 6
Training loss: 3.044732225542395
Validation loss: 2.5577628636370444

Epoch: 6| Step: 7
Training loss: 2.8463944097514418
Validation loss: 2.553697679112268

Epoch: 6| Step: 8
Training loss: 2.779151381908595
Validation loss: 2.5467001364680315

Epoch: 6| Step: 9
Training loss: 3.1921361977912257
Validation loss: 2.548387368455184

Epoch: 6| Step: 10
Training loss: 2.4276005162526246
Validation loss: 2.551682101451018

Epoch: 6| Step: 11
Training loss: 3.246956794303285
Validation loss: 2.561520590146915

Epoch: 6| Step: 12
Training loss: 2.924656161452099
Validation loss: 2.5658033714877346

Epoch: 6| Step: 13
Training loss: 2.3240982152634326
Validation loss: 2.583317899178225

Epoch: 123| Step: 0
Training loss: 2.4099801615931327
Validation loss: 2.582640179446172

Epoch: 6| Step: 1
Training loss: 2.79476439900745
Validation loss: 2.591673061839219

Epoch: 6| Step: 2
Training loss: 3.122060690427384
Validation loss: 2.602079395867338

Epoch: 6| Step: 3
Training loss: 2.8677346022003545
Validation loss: 2.584254547810636

Epoch: 6| Step: 4
Training loss: 2.6183193207707194
Validation loss: 2.5746485226448024

Epoch: 6| Step: 5
Training loss: 3.5309441358046634
Validation loss: 2.555246839391241

Epoch: 6| Step: 6
Training loss: 3.2578987091879656
Validation loss: 2.547005269624383

Epoch: 6| Step: 7
Training loss: 3.1486136337499766
Validation loss: 2.544947552358027

Epoch: 6| Step: 8
Training loss: 2.364354418010304
Validation loss: 2.5493634541966195

Epoch: 6| Step: 9
Training loss: 2.974959134374166
Validation loss: 2.5483618947640845

Epoch: 6| Step: 10
Training loss: 2.518803643727374
Validation loss: 2.545283042672646

Epoch: 6| Step: 11
Training loss: 3.2584615742324647
Validation loss: 2.5503790942179685

Epoch: 6| Step: 12
Training loss: 2.711220586326112
Validation loss: 2.5552665779426325

Epoch: 6| Step: 13
Training loss: 3.0199882289833915
Validation loss: 2.5539284286785997

Epoch: 124| Step: 0
Training loss: 3.6858224447355314
Validation loss: 2.5482608093239203

Epoch: 6| Step: 1
Training loss: 2.7776139740860475
Validation loss: 2.5475690389125463

Epoch: 6| Step: 2
Training loss: 2.9597835657533333
Validation loss: 2.5497656826946558

Epoch: 6| Step: 3
Training loss: 2.170275751163913
Validation loss: 2.547639555011827

Epoch: 6| Step: 4
Training loss: 2.30729832587275
Validation loss: 2.5637413907704127

Epoch: 6| Step: 5
Training loss: 2.6610435764854716
Validation loss: 2.59381657819008

Epoch: 6| Step: 6
Training loss: 2.5551574461439674
Validation loss: 2.611764555599751

Epoch: 6| Step: 7
Training loss: 3.326373145150924
Validation loss: 2.618391215356805

Epoch: 6| Step: 8
Training loss: 2.7301188450749985
Validation loss: 2.608459781775493

Epoch: 6| Step: 9
Training loss: 2.816208831174658
Validation loss: 2.5782529588493364

Epoch: 6| Step: 10
Training loss: 3.228071178715097
Validation loss: 2.5529745896690375

Epoch: 6| Step: 11
Training loss: 3.004421155276251
Validation loss: 2.5615271025241624

Epoch: 6| Step: 12
Training loss: 3.189352058449235
Validation loss: 2.570389291001631

Epoch: 6| Step: 13
Training loss: 3.1352572141807227
Validation loss: 2.554705171654732

Epoch: 125| Step: 0
Training loss: 3.400457654332889
Validation loss: 2.5530604830903454

Epoch: 6| Step: 1
Training loss: 2.770529756670893
Validation loss: 2.556794601809001

Epoch: 6| Step: 2
Training loss: 2.2904826371110047
Validation loss: 2.557774886173453

Epoch: 6| Step: 3
Training loss: 2.676753893421064
Validation loss: 2.556499313254185

Epoch: 6| Step: 4
Training loss: 2.9130086757479647
Validation loss: 2.556556952166193

Epoch: 6| Step: 5
Training loss: 3.1920843629611717
Validation loss: 2.557331167521288

Epoch: 6| Step: 6
Training loss: 3.1926043163155438
Validation loss: 2.5620199744823333

Epoch: 6| Step: 7
Training loss: 2.6964036584892406
Validation loss: 2.5694853132996593

Epoch: 6| Step: 8
Training loss: 3.3449975654353703
Validation loss: 2.564444750640391

Epoch: 6| Step: 9
Training loss: 2.1587598263904
Validation loss: 2.5737153756083124

Epoch: 6| Step: 10
Training loss: 2.933638936798294
Validation loss: 2.5725267571600483

Epoch: 6| Step: 11
Training loss: 2.991750500991128
Validation loss: 2.5828870211796087

Epoch: 6| Step: 12
Training loss: 2.873437041987372
Validation loss: 2.5706374008587947

Epoch: 6| Step: 13
Training loss: 3.0707591268268235
Validation loss: 2.5775000805787798

Epoch: 126| Step: 0
Training loss: 3.1321836682345396
Validation loss: 2.5818088418268976

Epoch: 6| Step: 1
Training loss: 2.621478034102607
Validation loss: 2.5918362996988575

Epoch: 6| Step: 2
Training loss: 2.557361288476101
Validation loss: 2.587272611422163

Epoch: 6| Step: 3
Training loss: 2.67932375560579
Validation loss: 2.588916707736261

Epoch: 6| Step: 4
Training loss: 2.394070305571923
Validation loss: 2.593623576695167

Epoch: 6| Step: 5
Training loss: 3.386621317622419
Validation loss: 2.5893085801417066

Epoch: 6| Step: 6
Training loss: 3.2576324632694633
Validation loss: 2.5857094403690524

Epoch: 6| Step: 7
Training loss: 2.9502827525005375
Validation loss: 2.560270927139153

Epoch: 6| Step: 8
Training loss: 2.963451113711332
Validation loss: 2.549680014609914

Epoch: 6| Step: 9
Training loss: 3.007573264379904
Validation loss: 2.546669070999659

Epoch: 6| Step: 10
Training loss: 3.1644778132137796
Validation loss: 2.545213968116362

Epoch: 6| Step: 11
Training loss: 2.95330906854425
Validation loss: 2.5400172415172304

Epoch: 6| Step: 12
Training loss: 2.0284163443579204
Validation loss: 2.537874861780821

Epoch: 6| Step: 13
Training loss: 3.3994524963713566
Validation loss: 2.5384192887146813

Epoch: 127| Step: 0
Training loss: 2.9864890714477683
Validation loss: 2.537778753042041

Epoch: 6| Step: 1
Training loss: 2.628028847912017
Validation loss: 2.5395876327691322

Epoch: 6| Step: 2
Training loss: 3.0858585395851454
Validation loss: 2.5401627502190096

Epoch: 6| Step: 3
Training loss: 2.81448074104902
Validation loss: 2.540647358470482

Epoch: 6| Step: 4
Training loss: 3.3535807474930515
Validation loss: 2.5438758660327307

Epoch: 6| Step: 5
Training loss: 2.6726298911036217
Validation loss: 2.5521495216999845

Epoch: 6| Step: 6
Training loss: 2.4508782077880573
Validation loss: 2.5781785827020536

Epoch: 6| Step: 7
Training loss: 3.2966337432091595
Validation loss: 2.5873643471488843

Epoch: 6| Step: 8
Training loss: 2.6072321333408817
Validation loss: 2.569635410708333

Epoch: 6| Step: 9
Training loss: 3.0441957871862737
Validation loss: 2.5521438969819044

Epoch: 6| Step: 10
Training loss: 2.494579733578419
Validation loss: 2.542214508228814

Epoch: 6| Step: 11
Training loss: 3.4056071103459753
Validation loss: 2.5411744295865337

Epoch: 6| Step: 12
Training loss: 2.5693049441664497
Validation loss: 2.53683696332311

Epoch: 6| Step: 13
Training loss: 2.9362176571652556
Validation loss: 2.5332628706500557

Epoch: 128| Step: 0
Training loss: 2.8637032191411413
Validation loss: 2.5364088747801468

Epoch: 6| Step: 1
Training loss: 2.418349129826566
Validation loss: 2.5357274731712205

Epoch: 6| Step: 2
Training loss: 3.031310090718016
Validation loss: 2.5387673200572074

Epoch: 6| Step: 3
Training loss: 3.230559378924467
Validation loss: 2.540198198611196

Epoch: 6| Step: 4
Training loss: 2.778370599006692
Validation loss: 2.540062990677643

Epoch: 6| Step: 5
Training loss: 2.991246167510049
Validation loss: 2.540236359275842

Epoch: 6| Step: 6
Training loss: 2.2675925294614085
Validation loss: 2.546802600501182

Epoch: 6| Step: 7
Training loss: 3.1158990706917633
Validation loss: 2.559243230322306

Epoch: 6| Step: 8
Training loss: 2.712267634551492
Validation loss: 2.5487131309947664

Epoch: 6| Step: 9
Training loss: 3.0369542514644965
Validation loss: 2.5578832107373684

Epoch: 6| Step: 10
Training loss: 3.0295879093856644
Validation loss: 2.552529554468851

Epoch: 6| Step: 11
Training loss: 3.0223901003916276
Validation loss: 2.543230885323208

Epoch: 6| Step: 12
Training loss: 3.3021926300219806
Validation loss: 2.5433262346486054

Epoch: 6| Step: 13
Training loss: 1.9996678553392926
Validation loss: 2.5336396880404792

Epoch: 129| Step: 0
Training loss: 3.000040371941079
Validation loss: 2.5362684927565544

Epoch: 6| Step: 1
Training loss: 2.945373048842979
Validation loss: 2.5374084941506045

Epoch: 6| Step: 2
Training loss: 3.1118706124284947
Validation loss: 2.537685142999407

Epoch: 6| Step: 3
Training loss: 2.887899897903752
Validation loss: 2.5366476186727325

Epoch: 6| Step: 4
Training loss: 2.9785028175954156
Validation loss: 2.5345453353911798

Epoch: 6| Step: 5
Training loss: 2.989214264067383
Validation loss: 2.5297542068448426

Epoch: 6| Step: 6
Training loss: 2.652677399853837
Validation loss: 2.531374803811365

Epoch: 6| Step: 7
Training loss: 3.2312819577081107
Validation loss: 2.534509944488046

Epoch: 6| Step: 8
Training loss: 2.398752396877059
Validation loss: 2.535440868572559

Epoch: 6| Step: 9
Training loss: 2.2688075370953924
Validation loss: 2.534687963136105

Epoch: 6| Step: 10
Training loss: 2.9932524775379554
Validation loss: 2.5363792974300305

Epoch: 6| Step: 11
Training loss: 2.6745411916125583
Validation loss: 2.541173356179616

Epoch: 6| Step: 12
Training loss: 3.3126577663638574
Validation loss: 2.5374294656531795

Epoch: 6| Step: 13
Training loss: 2.6538681121861845
Validation loss: 2.5414870158477627

Epoch: 130| Step: 0
Training loss: 3.3758798088265194
Validation loss: 2.543543450675628

Epoch: 6| Step: 1
Training loss: 2.223559901500088
Validation loss: 2.5490008189955153

Epoch: 6| Step: 2
Training loss: 2.420284511928889
Validation loss: 2.5499647624255157

Epoch: 6| Step: 3
Training loss: 2.3754109478836885
Validation loss: 2.54866919679934

Epoch: 6| Step: 4
Training loss: 3.102506633201228
Validation loss: 2.5592322073910068

Epoch: 6| Step: 5
Training loss: 2.9376699520213765
Validation loss: 2.559668987268113

Epoch: 6| Step: 6
Training loss: 2.681411677823459
Validation loss: 2.562006264778789

Epoch: 6| Step: 7
Training loss: 2.9986863439052
Validation loss: 2.565531392507125

Epoch: 6| Step: 8
Training loss: 3.136068350319549
Validation loss: 2.5673581483838626

Epoch: 6| Step: 9
Training loss: 2.770617101353858
Validation loss: 2.556243054607949

Epoch: 6| Step: 10
Training loss: 3.0409914774049294
Validation loss: 2.558221522194645

Epoch: 6| Step: 11
Training loss: 3.1195230936258573
Validation loss: 2.5451602162004674

Epoch: 6| Step: 12
Training loss: 2.576437010291396
Validation loss: 2.5357789450855868

Epoch: 6| Step: 13
Training loss: 3.6017248154347055
Validation loss: 2.532811455884149

Epoch: 131| Step: 0
Training loss: 3.646043666040336
Validation loss: 2.5372867151695817

Epoch: 6| Step: 1
Training loss: 3.001871478944199
Validation loss: 2.5305228881010913

Epoch: 6| Step: 2
Training loss: 2.4680518599738757
Validation loss: 2.53102981559733

Epoch: 6| Step: 3
Training loss: 3.0280760832970084
Validation loss: 2.5298977299281473

Epoch: 6| Step: 4
Training loss: 2.4897913400324603
Validation loss: 2.5277084992952035

Epoch: 6| Step: 5
Training loss: 2.4242946228093594
Validation loss: 2.528530390725973

Epoch: 6| Step: 6
Training loss: 2.2327852796065906
Validation loss: 2.5312253625972936

Epoch: 6| Step: 7
Training loss: 3.400863728485963
Validation loss: 2.53684989752161

Epoch: 6| Step: 8
Training loss: 2.6398434357023435
Validation loss: 2.549010104001258

Epoch: 6| Step: 9
Training loss: 3.063864267833839
Validation loss: 2.561890988696307

Epoch: 6| Step: 10
Training loss: 2.5645318698341932
Validation loss: 2.5683076676531553

Epoch: 6| Step: 11
Training loss: 2.531096182965131
Validation loss: 2.5900188463508624

Epoch: 6| Step: 12
Training loss: 3.555538402621962
Validation loss: 2.578797527062938

Epoch: 6| Step: 13
Training loss: 2.6768640707943168
Validation loss: 2.571075064016509

Epoch: 132| Step: 0
Training loss: 2.785267960072337
Validation loss: 2.545837883709996

Epoch: 6| Step: 1
Training loss: 2.4755007035068166
Validation loss: 2.5402298124999203

Epoch: 6| Step: 2
Training loss: 2.2676714895184884
Validation loss: 2.534942850050126

Epoch: 6| Step: 3
Training loss: 3.1153023356615206
Validation loss: 2.527353469594865

Epoch: 6| Step: 4
Training loss: 2.7078264397880334
Validation loss: 2.5308164688400914

Epoch: 6| Step: 5
Training loss: 2.583022396284444
Validation loss: 2.5329515750646667

Epoch: 6| Step: 6
Training loss: 3.2403041287134786
Validation loss: 2.5282100586164313

Epoch: 6| Step: 7
Training loss: 2.909948477272555
Validation loss: 2.530833180760565

Epoch: 6| Step: 8
Training loss: 2.609517624663408
Validation loss: 2.5315420553740546

Epoch: 6| Step: 9
Training loss: 3.0402431205105165
Validation loss: 2.532013579827974

Epoch: 6| Step: 10
Training loss: 3.244132981816704
Validation loss: 2.5314859462342256

Epoch: 6| Step: 11
Training loss: 3.34638559447892
Validation loss: 2.536325330991676

Epoch: 6| Step: 12
Training loss: 2.6996841139915118
Validation loss: 2.5325050832793385

Epoch: 6| Step: 13
Training loss: 3.244692062555482
Validation loss: 2.538187697840478

Epoch: 133| Step: 0
Training loss: 2.7297953592530813
Validation loss: 2.5443914123760774

Epoch: 6| Step: 1
Training loss: 2.936291385130003
Validation loss: 2.5394290600786382

Epoch: 6| Step: 2
Training loss: 2.5076890956665467
Validation loss: 2.555922792462731

Epoch: 6| Step: 3
Training loss: 2.8549836003622513
Validation loss: 2.5779834229894893

Epoch: 6| Step: 4
Training loss: 2.921683402077908
Validation loss: 2.60265454959915

Epoch: 6| Step: 5
Training loss: 2.5642022782279548
Validation loss: 2.6306593479131006

Epoch: 6| Step: 6
Training loss: 3.6450987738895546
Validation loss: 2.681052728462636

Epoch: 6| Step: 7
Training loss: 3.366131751996906
Validation loss: 2.6753077504317955

Epoch: 6| Step: 8
Training loss: 2.4079518430716687
Validation loss: 2.595775549194816

Epoch: 6| Step: 9
Training loss: 2.795089833926276
Validation loss: 2.5369563911974495

Epoch: 6| Step: 10
Training loss: 2.9693063315077532
Validation loss: 2.5270545648084792

Epoch: 6| Step: 11
Training loss: 3.240773087799268
Validation loss: 2.5361330267994204

Epoch: 6| Step: 12
Training loss: 2.7674479538073467
Validation loss: 2.5556988826036378

Epoch: 6| Step: 13
Training loss: 2.3267726170518688
Validation loss: 2.5747895616648324

Epoch: 134| Step: 0
Training loss: 3.060545628589408
Validation loss: 2.5848555101102284

Epoch: 6| Step: 1
Training loss: 3.287290843503616
Validation loss: 2.5971866923145495

Epoch: 6| Step: 2
Training loss: 2.838634039166195
Validation loss: 2.588654226220913

Epoch: 6| Step: 3
Training loss: 3.042303480260215
Validation loss: 2.577123219250719

Epoch: 6| Step: 4
Training loss: 2.7403582696510544
Validation loss: 2.574358523953242

Epoch: 6| Step: 5
Training loss: 3.236856733949354
Validation loss: 2.5686665272431926

Epoch: 6| Step: 6
Training loss: 2.842764882920399
Validation loss: 2.5573812402681146

Epoch: 6| Step: 7
Training loss: 2.985224897388517
Validation loss: 2.554393367914013

Epoch: 6| Step: 8
Training loss: 3.1566740449888315
Validation loss: 2.5414299056960683

Epoch: 6| Step: 9
Training loss: 2.2715685526239393
Validation loss: 2.538010259010114

Epoch: 6| Step: 10
Training loss: 2.940218702213443
Validation loss: 2.5437680686866684

Epoch: 6| Step: 11
Training loss: 2.544924498151948
Validation loss: 2.5633688693456564

Epoch: 6| Step: 12
Training loss: 3.404301217142598
Validation loss: 2.61526571998479

Epoch: 6| Step: 13
Training loss: 2.76371026433695
Validation loss: 2.6708333008642846

Epoch: 135| Step: 0
Training loss: 2.733449027086329
Validation loss: 2.6455724340636326

Epoch: 6| Step: 1
Training loss: 2.558555917241762
Validation loss: 2.641582464212372

Epoch: 6| Step: 2
Training loss: 3.5531136518446473
Validation loss: 2.6142780665194465

Epoch: 6| Step: 3
Training loss: 2.6016168445489942
Validation loss: 2.596710260309035

Epoch: 6| Step: 4
Training loss: 1.9499852693441506
Validation loss: 2.5667766886131003

Epoch: 6| Step: 5
Training loss: 3.1022373493424507
Validation loss: 2.576105844908963

Epoch: 6| Step: 6
Training loss: 2.8446109013562375
Validation loss: 2.5696798703590966

Epoch: 6| Step: 7
Training loss: 2.3071929244590335
Validation loss: 2.550924446282488

Epoch: 6| Step: 8
Training loss: 3.609102445277808
Validation loss: 2.538489302561691

Epoch: 6| Step: 9
Training loss: 2.6407526651253614
Validation loss: 2.5236679495633836

Epoch: 6| Step: 10
Training loss: 2.749683535313211
Validation loss: 2.516450622527818

Epoch: 6| Step: 11
Training loss: 2.721647625786666
Validation loss: 2.512510893035949

Epoch: 6| Step: 12
Training loss: 3.3835981130736994
Validation loss: 2.516442013034797

Epoch: 6| Step: 13
Training loss: 3.0155166843707333
Validation loss: 2.520020463614285

Epoch: 136| Step: 0
Training loss: 3.0965657377134685
Validation loss: 2.5229803456226945

Epoch: 6| Step: 1
Training loss: 3.0215489208623696
Validation loss: 2.5209641822233086

Epoch: 6| Step: 2
Training loss: 2.5550658152962726
Validation loss: 2.5210288072089946

Epoch: 6| Step: 3
Training loss: 2.692305770286461
Validation loss: 2.515693096507221

Epoch: 6| Step: 4
Training loss: 3.440878161853343
Validation loss: 2.5198689776145855

Epoch: 6| Step: 5
Training loss: 2.9541866271327017
Validation loss: 2.516869563927634

Epoch: 6| Step: 6
Training loss: 2.8088283732624775
Validation loss: 2.509130682018935

Epoch: 6| Step: 7
Training loss: 3.2346577543789494
Validation loss: 2.509953427804582

Epoch: 6| Step: 8
Training loss: 2.8796529849587325
Validation loss: 2.5160295592602893

Epoch: 6| Step: 9
Training loss: 2.5906465646837877
Validation loss: 2.528228923771284

Epoch: 6| Step: 10
Training loss: 2.653485733508539
Validation loss: 2.537807513009882

Epoch: 6| Step: 11
Training loss: 2.9520022563977393
Validation loss: 2.526713829991071

Epoch: 6| Step: 12
Training loss: 2.6612716778561665
Validation loss: 2.5158415069179374

Epoch: 6| Step: 13
Training loss: 2.5868306533540384
Validation loss: 2.5195370192579762

Epoch: 137| Step: 0
Training loss: 2.9659531117370936
Validation loss: 2.5108354930798216

Epoch: 6| Step: 1
Training loss: 3.013366802446059
Validation loss: 2.510656803249923

Epoch: 6| Step: 2
Training loss: 2.943456414033664
Validation loss: 2.5111351681874985

Epoch: 6| Step: 3
Training loss: 3.034955777846908
Validation loss: 2.502582361765007

Epoch: 6| Step: 4
Training loss: 2.552425304519242
Validation loss: 2.5053305504111014

Epoch: 6| Step: 5
Training loss: 3.2637545691012217
Validation loss: 2.5047739470266923

Epoch: 6| Step: 6
Training loss: 3.338216034734071
Validation loss: 2.5027101029976238

Epoch: 6| Step: 7
Training loss: 2.3383696789498725
Validation loss: 2.502421086598758

Epoch: 6| Step: 8
Training loss: 2.3853744991745542
Validation loss: 2.504971356368043

Epoch: 6| Step: 9
Training loss: 2.416257286475217
Validation loss: 2.510011034545254

Epoch: 6| Step: 10
Training loss: 2.312200681543394
Validation loss: 2.5140662434313237

Epoch: 6| Step: 11
Training loss: 3.267037556152446
Validation loss: 2.511967621357514

Epoch: 6| Step: 12
Training loss: 3.211413123181398
Validation loss: 2.511848546506751

Epoch: 6| Step: 13
Training loss: 2.775094410432987
Validation loss: 2.5187000355708493

Epoch: 138| Step: 0
Training loss: 2.6216771120452225
Validation loss: 2.5200295532578405

Epoch: 6| Step: 1
Training loss: 2.615891411817006
Validation loss: 2.533457292067177

Epoch: 6| Step: 2
Training loss: 3.3027408719351383
Validation loss: 2.535559907221001

Epoch: 6| Step: 3
Training loss: 2.7190916350995527
Validation loss: 2.547233008296423

Epoch: 6| Step: 4
Training loss: 3.235037767994612
Validation loss: 2.5538621266397277

Epoch: 6| Step: 5
Training loss: 2.836162127381467
Validation loss: 2.5336118126781226

Epoch: 6| Step: 6
Training loss: 3.007290881616754
Validation loss: 2.529849994180833

Epoch: 6| Step: 7
Training loss: 3.1236883844142977
Validation loss: 2.513740970838508

Epoch: 6| Step: 8
Training loss: 3.2026706280245754
Validation loss: 2.5198574345012212

Epoch: 6| Step: 9
Training loss: 2.4198006883623546
Validation loss: 2.520345397754448

Epoch: 6| Step: 10
Training loss: 2.8871666918187553
Validation loss: 2.537490778797723

Epoch: 6| Step: 11
Training loss: 2.9779459624297027
Validation loss: 2.546590065759473

Epoch: 6| Step: 12
Training loss: 2.889461798794775
Validation loss: 2.548884795813053

Epoch: 6| Step: 13
Training loss: 1.550370707327496
Validation loss: 2.549296783031025

Epoch: 139| Step: 0
Training loss: 2.816851830650637
Validation loss: 2.553743458255724

Epoch: 6| Step: 1
Training loss: 2.2844291377925696
Validation loss: 2.554009847837552

Epoch: 6| Step: 2
Training loss: 2.427803216573481
Validation loss: 2.5336070478617274

Epoch: 6| Step: 3
Training loss: 3.0916663965874593
Validation loss: 2.5351084150639593

Epoch: 6| Step: 4
Training loss: 2.6092597798932373
Validation loss: 2.539995087274954

Epoch: 6| Step: 5
Training loss: 2.883964163802266
Validation loss: 2.545044441001941

Epoch: 6| Step: 6
Training loss: 3.3335698679606516
Validation loss: 2.551671668764766

Epoch: 6| Step: 7
Training loss: 3.5028527758928263
Validation loss: 2.5609250354669353

Epoch: 6| Step: 8
Training loss: 3.0305662662150943
Validation loss: 2.5736001936693094

Epoch: 6| Step: 9
Training loss: 2.4646303595352927
Validation loss: 2.577472748196242

Epoch: 6| Step: 10
Training loss: 3.162965183950467
Validation loss: 2.5616118975290614

Epoch: 6| Step: 11
Training loss: 2.5762850582545207
Validation loss: 2.5732482717057263

Epoch: 6| Step: 12
Training loss: 2.909087569874234
Validation loss: 2.5736476070333802

Epoch: 6| Step: 13
Training loss: 2.9967369771763384
Validation loss: 2.5781607209307373

Epoch: 140| Step: 0
Training loss: 3.191132812739081
Validation loss: 2.56606154418863

Epoch: 6| Step: 1
Training loss: 3.2131375759956793
Validation loss: 2.5609749908967463

Epoch: 6| Step: 2
Training loss: 2.356047247705965
Validation loss: 2.5616208841248564

Epoch: 6| Step: 3
Training loss: 2.8132284280764686
Validation loss: 2.5698076840788344

Epoch: 6| Step: 4
Training loss: 3.0457492411459954
Validation loss: 2.5635219590034395

Epoch: 6| Step: 5
Training loss: 2.6215425155483625
Validation loss: 2.537030908747537

Epoch: 6| Step: 6
Training loss: 3.020618474926838
Validation loss: 2.530718295981426

Epoch: 6| Step: 7
Training loss: 2.9197933513206897
Validation loss: 2.5200622146656215

Epoch: 6| Step: 8
Training loss: 2.346955205814151
Validation loss: 2.5128470126355995

Epoch: 6| Step: 9
Training loss: 2.614922753500551
Validation loss: 2.5053033122332073

Epoch: 6| Step: 10
Training loss: 3.175000084103561
Validation loss: 2.512583838333218

Epoch: 6| Step: 11
Training loss: 2.5390757398993746
Validation loss: 2.5126625859405447

Epoch: 6| Step: 12
Training loss: 3.491056049885883
Validation loss: 2.5050792123997803

Epoch: 6| Step: 13
Training loss: 2.714951503454008
Validation loss: 2.506153548423895

Epoch: 141| Step: 0
Training loss: 2.57789916003025
Validation loss: 2.504266601073222

Epoch: 6| Step: 1
Training loss: 2.82024571558956
Validation loss: 2.503746873476027

Epoch: 6| Step: 2
Training loss: 2.9631568019651318
Validation loss: 2.5008107234675507

Epoch: 6| Step: 3
Training loss: 2.7444079503075307
Validation loss: 2.5036339610415626

Epoch: 6| Step: 4
Training loss: 3.227853290537594
Validation loss: 2.5018934821523326

Epoch: 6| Step: 5
Training loss: 3.142900999184325
Validation loss: 2.4994554849570685

Epoch: 6| Step: 6
Training loss: 2.6379559814274254
Validation loss: 2.496270461920966

Epoch: 6| Step: 7
Training loss: 2.7599411656839914
Validation loss: 2.499049694171456

Epoch: 6| Step: 8
Training loss: 2.5425218696366345
Validation loss: 2.509228054574366

Epoch: 6| Step: 9
Training loss: 2.7729558822033207
Validation loss: 2.530415792374907

Epoch: 6| Step: 10
Training loss: 3.7302346999958624
Validation loss: 2.53739084247117

Epoch: 6| Step: 11
Training loss: 3.0882513329011965
Validation loss: 2.5479500074171173

Epoch: 6| Step: 12
Training loss: 2.36735790885703
Validation loss: 2.544668979979983

Epoch: 6| Step: 13
Training loss: 2.3435336203827974
Validation loss: 2.5357193643689886

Epoch: 142| Step: 0
Training loss: 2.1535300085679636
Validation loss: 2.5209961145967728

Epoch: 6| Step: 1
Training loss: 2.7237024035065636
Validation loss: 2.507597930359818

Epoch: 6| Step: 2
Training loss: 2.5757653737757615
Validation loss: 2.4904053911025783

Epoch: 6| Step: 3
Training loss: 2.9094489755045463
Validation loss: 2.4907387494402875

Epoch: 6| Step: 4
Training loss: 2.69326076091903
Validation loss: 2.491431803027173

Epoch: 6| Step: 5
Training loss: 2.520850399579584
Validation loss: 2.49200398350683

Epoch: 6| Step: 6
Training loss: 2.9590035516602193
Validation loss: 2.4946146221915813

Epoch: 6| Step: 7
Training loss: 3.6777198535958666
Validation loss: 2.4905570191608315

Epoch: 6| Step: 8
Training loss: 2.678494112624619
Validation loss: 2.4972191900971854

Epoch: 6| Step: 9
Training loss: 3.3025902841313615
Validation loss: 2.4930026037837862

Epoch: 6| Step: 10
Training loss: 2.748295862865079
Validation loss: 2.4952783573359203

Epoch: 6| Step: 11
Training loss: 2.9964623255609037
Validation loss: 2.490900981682417

Epoch: 6| Step: 12
Training loss: 2.5117742790384474
Validation loss: 2.4951899698637345

Epoch: 6| Step: 13
Training loss: 3.673219475224886
Validation loss: 2.4974088602507836

Epoch: 143| Step: 0
Training loss: 2.370034598729737
Validation loss: 2.502014058485661

Epoch: 6| Step: 1
Training loss: 3.1115883468745142
Validation loss: 2.518380506312614

Epoch: 6| Step: 2
Training loss: 2.6362823351219564
Validation loss: 2.5373223815678037

Epoch: 6| Step: 3
Training loss: 2.8232354316115984
Validation loss: 2.5491993842237357

Epoch: 6| Step: 4
Training loss: 2.616796663622827
Validation loss: 2.5445190641778814

Epoch: 6| Step: 5
Training loss: 3.0903958720717584
Validation loss: 2.5199863713093373

Epoch: 6| Step: 6
Training loss: 2.9727260265607556
Validation loss: 2.5133047030371287

Epoch: 6| Step: 7
Training loss: 2.6366865594099806
Validation loss: 2.503354703296034

Epoch: 6| Step: 8
Training loss: 3.0492905651552182
Validation loss: 2.4953116817512706

Epoch: 6| Step: 9
Training loss: 3.375845909073256
Validation loss: 2.4895945393567596

Epoch: 6| Step: 10
Training loss: 2.5371446144528726
Validation loss: 2.4877139656533944

Epoch: 6| Step: 11
Training loss: 2.7965195072938958
Validation loss: 2.4833288442809662

Epoch: 6| Step: 12
Training loss: 2.8583025145653336
Validation loss: 2.486357078496117

Epoch: 6| Step: 13
Training loss: 2.7972935198280098
Validation loss: 2.4806374392139974

Epoch: 144| Step: 0
Training loss: 2.947488886300215
Validation loss: 2.490573136581503

Epoch: 6| Step: 1
Training loss: 3.135715271849994
Validation loss: 2.4911436732219827

Epoch: 6| Step: 2
Training loss: 3.1565896030943397
Validation loss: 2.4906796028137403

Epoch: 6| Step: 3
Training loss: 2.0413910296953413
Validation loss: 2.4930952128422055

Epoch: 6| Step: 4
Training loss: 3.163137493791009
Validation loss: 2.485944392953985

Epoch: 6| Step: 5
Training loss: 2.7266405854069813
Validation loss: 2.4862479756584097

Epoch: 6| Step: 6
Training loss: 2.833155084126686
Validation loss: 2.48967854739983

Epoch: 6| Step: 7
Training loss: 2.7494856613515077
Validation loss: 2.493664888700881

Epoch: 6| Step: 8
Training loss: 3.2041225461729073
Validation loss: 2.5025074023596567

Epoch: 6| Step: 9
Training loss: 2.7193768534986087
Validation loss: 2.5017560533970262

Epoch: 6| Step: 10
Training loss: 2.9818200164247948
Validation loss: 2.5107181606139504

Epoch: 6| Step: 11
Training loss: 2.2974505060321184
Validation loss: 2.522440753200625

Epoch: 6| Step: 12
Training loss: 2.6906498924459648
Validation loss: 2.5357889508084286

Epoch: 6| Step: 13
Training loss: 3.361318904103782
Validation loss: 2.542261591806645

Epoch: 145| Step: 0
Training loss: 3.1592528911051194
Validation loss: 2.522932771132228

Epoch: 6| Step: 1
Training loss: 2.5747594887713903
Validation loss: 2.513233619355474

Epoch: 6| Step: 2
Training loss: 2.6083871033542594
Validation loss: 2.5074445027501175

Epoch: 6| Step: 3
Training loss: 3.087286777315276
Validation loss: 2.5025822234712587

Epoch: 6| Step: 4
Training loss: 2.8618553535168623
Validation loss: 2.4946364251432493

Epoch: 6| Step: 5
Training loss: 3.0589580684305733
Validation loss: 2.4886645650645147

Epoch: 6| Step: 6
Training loss: 2.970905525289849
Validation loss: 2.487759314332186

Epoch: 6| Step: 7
Training loss: 2.8393740678802915
Validation loss: 2.484241714457101

Epoch: 6| Step: 8
Training loss: 2.7684194811010565
Validation loss: 2.4910933588938997

Epoch: 6| Step: 9
Training loss: 2.614907435863137
Validation loss: 2.4862802136755375

Epoch: 6| Step: 10
Training loss: 2.6510268974767155
Validation loss: 2.4867360515124752

Epoch: 6| Step: 11
Training loss: 3.1433210804586853
Validation loss: 2.486291885869088

Epoch: 6| Step: 12
Training loss: 2.5103015372019
Validation loss: 2.48673180615594

Epoch: 6| Step: 13
Training loss: 2.721224743748217
Validation loss: 2.491814490436502

Epoch: 146| Step: 0
Training loss: 2.8730121872374883
Validation loss: 2.494239226170521

Epoch: 6| Step: 1
Training loss: 2.3730012614571954
Validation loss: 2.5094781127973187

Epoch: 6| Step: 2
Training loss: 2.8467043108390464
Validation loss: 2.5335347063450127

Epoch: 6| Step: 3
Training loss: 2.8352066653644754
Validation loss: 2.538247287782743

Epoch: 6| Step: 4
Training loss: 3.0130021939021194
Validation loss: 2.5355431809560067

Epoch: 6| Step: 5
Training loss: 2.713609593298437
Validation loss: 2.5062001714754247

Epoch: 6| Step: 6
Training loss: 3.0064922655476516
Validation loss: 2.5059423927728206

Epoch: 6| Step: 7
Training loss: 3.3014173989426143
Validation loss: 2.488084240238351

Epoch: 6| Step: 8
Training loss: 2.4304601293329418
Validation loss: 2.480447139812189

Epoch: 6| Step: 9
Training loss: 2.7726199382297056
Validation loss: 2.481830569648489

Epoch: 6| Step: 10
Training loss: 3.005620618512789
Validation loss: 2.488309983472503

Epoch: 6| Step: 11
Training loss: 2.3960461950418264
Validation loss: 2.4862201484433912

Epoch: 6| Step: 12
Training loss: 3.4133849006224546
Validation loss: 2.486762543074565

Epoch: 6| Step: 13
Training loss: 2.638476970937168
Validation loss: 2.4840888876794676

Epoch: 147| Step: 0
Training loss: 2.195993663959361
Validation loss: 2.4840919589825328

Epoch: 6| Step: 1
Training loss: 3.0489374467407795
Validation loss: 2.4857450940566

Epoch: 6| Step: 2
Training loss: 2.71672851125458
Validation loss: 2.4870123542040643

Epoch: 6| Step: 3
Training loss: 3.001272090781313
Validation loss: 2.4927785124219954

Epoch: 6| Step: 4
Training loss: 2.6803254460825694
Validation loss: 2.510623338399456

Epoch: 6| Step: 5
Training loss: 2.8750515808785764
Validation loss: 2.5177416071723036

Epoch: 6| Step: 6
Training loss: 3.0443423969525525
Validation loss: 2.5176053683533564

Epoch: 6| Step: 7
Training loss: 3.255800499523918
Validation loss: 2.5050083967754264

Epoch: 6| Step: 8
Training loss: 2.7066690662291966
Validation loss: 2.49469102006567

Epoch: 6| Step: 9
Training loss: 2.4858457422495577
Validation loss: 2.493769108304333

Epoch: 6| Step: 10
Training loss: 3.061053031544254
Validation loss: 2.4889833813202733

Epoch: 6| Step: 11
Training loss: 2.948573404403354
Validation loss: 2.491428712989712

Epoch: 6| Step: 12
Training loss: 2.2594180618762256
Validation loss: 2.490610189887004

Epoch: 6| Step: 13
Training loss: 3.5007546837379064
Validation loss: 2.4990279676803158

Epoch: 148| Step: 0
Training loss: 2.6191151366675527
Validation loss: 2.497592907513898

Epoch: 6| Step: 1
Training loss: 3.250024061847526
Validation loss: 2.4927370232761783

Epoch: 6| Step: 2
Training loss: 3.0141004750819373
Validation loss: 2.490553737609087

Epoch: 6| Step: 3
Training loss: 2.9636398504761132
Validation loss: 2.4925726334107074

Epoch: 6| Step: 4
Training loss: 2.7638114543485033
Validation loss: 2.5026600437410482

Epoch: 6| Step: 5
Training loss: 2.3058324006738995
Validation loss: 2.508299115798299

Epoch: 6| Step: 6
Training loss: 2.9473612411490446
Validation loss: 2.507656696345587

Epoch: 6| Step: 7
Training loss: 2.094865871678831
Validation loss: 2.5105371199106363

Epoch: 6| Step: 8
Training loss: 3.081714995854391
Validation loss: 2.5081560524871147

Epoch: 6| Step: 9
Training loss: 2.8316421136208842
Validation loss: 2.511268993547945

Epoch: 6| Step: 10
Training loss: 2.775007636257353
Validation loss: 2.4997584985148236

Epoch: 6| Step: 11
Training loss: 2.7431343378484763
Validation loss: 2.497809464582367

Epoch: 6| Step: 12
Training loss: 2.86860010756962
Validation loss: 2.4914896723514453

Epoch: 6| Step: 13
Training loss: 3.406501550747714
Validation loss: 2.490578680587777

Epoch: 149| Step: 0
Training loss: 2.8627261343175983
Validation loss: 2.498268627200156

Epoch: 6| Step: 1
Training loss: 3.44508855874741
Validation loss: 2.5031320016262804

Epoch: 6| Step: 2
Training loss: 2.68979901296799
Validation loss: 2.493366721758132

Epoch: 6| Step: 3
Training loss: 3.209518973177222
Validation loss: 2.4866488625176264

Epoch: 6| Step: 4
Training loss: 2.326517151543698
Validation loss: 2.487467636348859

Epoch: 6| Step: 5
Training loss: 2.58834201546822
Validation loss: 2.485256522380337

Epoch: 6| Step: 6
Training loss: 2.0904773928047824
Validation loss: 2.4880743157207443

Epoch: 6| Step: 7
Training loss: 2.7137759077679546
Validation loss: 2.491567753679029

Epoch: 6| Step: 8
Training loss: 2.7576560173270166
Validation loss: 2.498234114915743

Epoch: 6| Step: 9
Training loss: 3.3067466146535858
Validation loss: 2.5086957850415446

Epoch: 6| Step: 10
Training loss: 3.2177451333637554
Validation loss: 2.5248505967973447

Epoch: 6| Step: 11
Training loss: 2.5633170523289737
Validation loss: 2.5256798408420216

Epoch: 6| Step: 12
Training loss: 2.9382574849789234
Validation loss: 2.528344242075848

Epoch: 6| Step: 13
Training loss: 2.1188828553263503
Validation loss: 2.53630095919708

Epoch: 150| Step: 0
Training loss: 1.879548532068929
Validation loss: 2.5502999053562503

Epoch: 6| Step: 1
Training loss: 2.861726721383588
Validation loss: 2.5581039990764007

Epoch: 6| Step: 2
Training loss: 2.598424720388654
Validation loss: 2.5636448557468623

Epoch: 6| Step: 3
Training loss: 2.7146778522547046
Validation loss: 2.575222943813007

Epoch: 6| Step: 4
Training loss: 3.001564094983878
Validation loss: 2.575019463046326

Epoch: 6| Step: 5
Training loss: 2.7225156115600124
Validation loss: 2.56517341353313

Epoch: 6| Step: 6
Training loss: 2.861819697002139
Validation loss: 2.5616344387679804

Epoch: 6| Step: 7
Training loss: 3.365076381275594
Validation loss: 2.53512940458237

Epoch: 6| Step: 8
Training loss: 3.229458227633663
Validation loss: 2.528837372605161

Epoch: 6| Step: 9
Training loss: 2.819939586046378
Validation loss: 2.5262956686712745

Epoch: 6| Step: 10
Training loss: 2.4563750101751145
Validation loss: 2.5127392257798378

Epoch: 6| Step: 11
Training loss: 3.0554956796347463
Validation loss: 2.5120753770276893

Epoch: 6| Step: 12
Training loss: 3.1893744847355
Validation loss: 2.5100480159031213

Epoch: 6| Step: 13
Training loss: 2.5502019577833788
Validation loss: 2.5031574573209694

Epoch: 151| Step: 0
Training loss: 2.5191820479300007
Validation loss: 2.5080280479027537

Epoch: 6| Step: 1
Training loss: 2.92478333021209
Validation loss: 2.5214952843694114

Epoch: 6| Step: 2
Training loss: 2.7988225027747964
Validation loss: 2.538440149863826

Epoch: 6| Step: 3
Training loss: 3.4757955669606377
Validation loss: 2.5554600275413684

Epoch: 6| Step: 4
Training loss: 2.9260322249248776
Validation loss: 2.5410209701673683

Epoch: 6| Step: 5
Training loss: 2.2996950030240084
Validation loss: 2.5382125656179624

Epoch: 6| Step: 6
Training loss: 3.092662427455954
Validation loss: 2.544433494506456

Epoch: 6| Step: 7
Training loss: 2.9283090832798435
Validation loss: 2.5282912113970615

Epoch: 6| Step: 8
Training loss: 2.9874488219661917
Validation loss: 2.528508697028967

Epoch: 6| Step: 9
Training loss: 2.577011607803059
Validation loss: 2.510492624849229

Epoch: 6| Step: 10
Training loss: 2.563850791136533
Validation loss: 2.501759098911924

Epoch: 6| Step: 11
Training loss: 2.8481699371643536
Validation loss: 2.5087387750582963

Epoch: 6| Step: 12
Training loss: 2.993133315757659
Validation loss: 2.4992183652926356

Epoch: 6| Step: 13
Training loss: 1.851478800109096
Validation loss: 2.498970036970239

Epoch: 152| Step: 0
Training loss: 2.9663016412598564
Validation loss: 2.501614535339068

Epoch: 6| Step: 1
Training loss: 2.441085721146605
Validation loss: 2.4975187108937407

Epoch: 6| Step: 2
Training loss: 2.45878715421127
Validation loss: 2.5059707211860327

Epoch: 6| Step: 3
Training loss: 2.9361984940871566
Validation loss: 2.510555051280157

Epoch: 6| Step: 4
Training loss: 2.7717099249196244
Validation loss: 2.521015885395111

Epoch: 6| Step: 5
Training loss: 3.307421263711264
Validation loss: 2.5225342104342556

Epoch: 6| Step: 6
Training loss: 2.973150264880434
Validation loss: 2.5372465691590373

Epoch: 6| Step: 7
Training loss: 3.3356967812373806
Validation loss: 2.540190712142515

Epoch: 6| Step: 8
Training loss: 3.074511580716673
Validation loss: 2.5177892609146895

Epoch: 6| Step: 9
Training loss: 2.442087600236528
Validation loss: 2.505654860337146

Epoch: 6| Step: 10
Training loss: 2.2857306386158296
Validation loss: 2.501704869336857

Epoch: 6| Step: 11
Training loss: 3.2791770563280123
Validation loss: 2.4837445886964424

Epoch: 6| Step: 12
Training loss: 2.4504317545468197
Validation loss: 2.494306782116245

Epoch: 6| Step: 13
Training loss: 2.463075320815574
Validation loss: 2.4871746305761113

Epoch: 153| Step: 0
Training loss: 2.9593272800485337
Validation loss: 2.4958939478197815

Epoch: 6| Step: 1
Training loss: 2.692253167784523
Validation loss: 2.5276594888940935

Epoch: 6| Step: 2
Training loss: 3.2120078871405693
Validation loss: 2.5550600871304043

Epoch: 6| Step: 3
Training loss: 2.892582411057763
Validation loss: 2.5694820666993166

Epoch: 6| Step: 4
Training loss: 2.721114084461866
Validation loss: 2.5962251036694344

Epoch: 6| Step: 5
Training loss: 3.3304466781940745
Validation loss: 2.6199133910006163

Epoch: 6| Step: 6
Training loss: 2.413192641686758
Validation loss: 2.5710705540910985

Epoch: 6| Step: 7
Training loss: 2.8202389525231037
Validation loss: 2.5633637708001005

Epoch: 6| Step: 8
Training loss: 2.7580698557825216
Validation loss: 2.5559640804277204

Epoch: 6| Step: 9
Training loss: 2.7545895858214373
Validation loss: 2.569403496522853

Epoch: 6| Step: 10
Training loss: 2.7942950747464375
Validation loss: 2.5786284570724516

Epoch: 6| Step: 11
Training loss: 2.7024567941322597
Validation loss: 2.582639619595254

Epoch: 6| Step: 12
Training loss: 3.028204262781642
Validation loss: 2.583924571869498

Epoch: 6| Step: 13
Training loss: 3.266764902726779
Validation loss: 2.5695843505979745

Epoch: 154| Step: 0
Training loss: 2.4778504497360863
Validation loss: 2.556479272349556

Epoch: 6| Step: 1
Training loss: 2.9596553230651126
Validation loss: 2.5464437051487736

Epoch: 6| Step: 2
Training loss: 2.4479907301932955
Validation loss: 2.5362810740569715

Epoch: 6| Step: 3
Training loss: 3.0608431947131938
Validation loss: 2.5145697831778566

Epoch: 6| Step: 4
Training loss: 2.7689304749373216
Validation loss: 2.4957587679980264

Epoch: 6| Step: 5
Training loss: 2.7063988941983075
Validation loss: 2.486603676070913

Epoch: 6| Step: 6
Training loss: 3.10880170741562
Validation loss: 2.4840447496627784

Epoch: 6| Step: 7
Training loss: 2.818726661737762
Validation loss: 2.4883309628498878

Epoch: 6| Step: 8
Training loss: 3.0239919701121454
Validation loss: 2.4885207531157456

Epoch: 6| Step: 9
Training loss: 2.986026646407671
Validation loss: 2.4926725688239215

Epoch: 6| Step: 10
Training loss: 2.972179479875955
Validation loss: 2.5047205954038354

Epoch: 6| Step: 11
Training loss: 2.7388027418343217
Validation loss: 2.5238536269502037

Epoch: 6| Step: 12
Training loss: 2.8276213308082636
Validation loss: 2.5237098139780634

Epoch: 6| Step: 13
Training loss: 2.5991790208913277
Validation loss: 2.513176220113006

Epoch: 155| Step: 0
Training loss: 2.5557256333335974
Validation loss: 2.4938640933434737

Epoch: 6| Step: 1
Training loss: 2.241746918991931
Validation loss: 2.4864196041326054

Epoch: 6| Step: 2
Training loss: 2.8748261772351396
Validation loss: 2.4851073438601325

Epoch: 6| Step: 3
Training loss: 2.960278923450705
Validation loss: 2.4852220449915707

Epoch: 6| Step: 4
Training loss: 2.9031186205380157
Validation loss: 2.4872631503369824

Epoch: 6| Step: 5
Training loss: 2.731769999360623
Validation loss: 2.4861607468612523

Epoch: 6| Step: 6
Training loss: 3.0604216081974513
Validation loss: 2.4907199168308654

Epoch: 6| Step: 7
Training loss: 2.701671496211855
Validation loss: 2.4907078773491134

Epoch: 6| Step: 8
Training loss: 2.923339802971542
Validation loss: 2.4971981457727517

Epoch: 6| Step: 9
Training loss: 3.590023729463747
Validation loss: 2.49055778705155

Epoch: 6| Step: 10
Training loss: 2.3801914495513454
Validation loss: 2.4874103258516365

Epoch: 6| Step: 11
Training loss: 2.720365460892012
Validation loss: 2.4920618277139224

Epoch: 6| Step: 12
Training loss: 2.937362343017914
Validation loss: 2.4930968519460026

Epoch: 6| Step: 13
Training loss: 2.9264568776196556
Validation loss: 2.500938190265249

Epoch: 156| Step: 0
Training loss: 2.6311293295692777
Validation loss: 2.499877580085959

Epoch: 6| Step: 1
Training loss: 2.8716756425637193
Validation loss: 2.504651983583233

Epoch: 6| Step: 2
Training loss: 3.0503301348008898
Validation loss: 2.5018163522624466

Epoch: 6| Step: 3
Training loss: 2.7741012423741664
Validation loss: 2.5023991414564546

Epoch: 6| Step: 4
Training loss: 3.9153759364919303
Validation loss: 2.5118513828056646

Epoch: 6| Step: 5
Training loss: 1.9583445271381759
Validation loss: 2.5212524843243105

Epoch: 6| Step: 6
Training loss: 2.945347631432139
Validation loss: 2.5306615840581563

Epoch: 6| Step: 7
Training loss: 2.7550879141459084
Validation loss: 2.509760187729783

Epoch: 6| Step: 8
Training loss: 2.8704057556851623
Validation loss: 2.5093891558434773

Epoch: 6| Step: 9
Training loss: 2.6204472979708773
Validation loss: 2.5280980151812673

Epoch: 6| Step: 10
Training loss: 2.8196322394740325
Validation loss: 2.5448498521036096

Epoch: 6| Step: 11
Training loss: 2.5582193115206917
Validation loss: 2.54008888469253

Epoch: 6| Step: 12
Training loss: 2.664832398259866
Validation loss: 2.514375949667236

Epoch: 6| Step: 13
Training loss: 2.3035524838535633
Validation loss: 2.503535686872173

Epoch: 157| Step: 0
Training loss: 2.740035644633534
Validation loss: 2.4897991870653344

Epoch: 6| Step: 1
Training loss: 2.3128373183563173
Validation loss: 2.488113900214602

Epoch: 6| Step: 2
Training loss: 2.897534335100017
Validation loss: 2.484688626898759

Epoch: 6| Step: 3
Training loss: 2.354962903518232
Validation loss: 2.48606904268224

Epoch: 6| Step: 4
Training loss: 2.787492411650178
Validation loss: 2.4922611538018677

Epoch: 6| Step: 5
Training loss: 2.507466800428078
Validation loss: 2.4886824583066898

Epoch: 6| Step: 6
Training loss: 3.29583043911337
Validation loss: 2.4953178285757907

Epoch: 6| Step: 7
Training loss: 2.3784686407973403
Validation loss: 2.4910571252796077

Epoch: 6| Step: 8
Training loss: 2.820045775589843
Validation loss: 2.4929575448429295

Epoch: 6| Step: 9
Training loss: 3.1170755237171655
Validation loss: 2.5001980436493976

Epoch: 6| Step: 10
Training loss: 3.100130379919135
Validation loss: 2.4997319036727053

Epoch: 6| Step: 11
Training loss: 3.1162646464444714
Validation loss: 2.513967893707361

Epoch: 6| Step: 12
Training loss: 2.8757351474439763
Validation loss: 2.511732238142346

Epoch: 6| Step: 13
Training loss: 2.4276632726665577
Validation loss: 2.5098086130348527

Epoch: 158| Step: 0
Training loss: 2.7027148337994067
Validation loss: 2.5311003498588915

Epoch: 6| Step: 1
Training loss: 2.397326283451248
Validation loss: 2.515917305055105

Epoch: 6| Step: 2
Training loss: 3.6507468256438615
Validation loss: 2.5245277099136927

Epoch: 6| Step: 3
Training loss: 2.3005389618686496
Validation loss: 2.5140182876377954

Epoch: 6| Step: 4
Training loss: 2.9669810596423374
Validation loss: 2.5102513750373197

Epoch: 6| Step: 5
Training loss: 2.8495069646179583
Validation loss: 2.503456976281979

Epoch: 6| Step: 6
Training loss: 2.891268766732338
Validation loss: 2.513590755591603

Epoch: 6| Step: 7
Training loss: 2.9610275214609407
Validation loss: 2.5225685203432797

Epoch: 6| Step: 8
Training loss: 2.8612841293545954
Validation loss: 2.502929916933323

Epoch: 6| Step: 9
Training loss: 2.146393292397601
Validation loss: 2.505585099500622

Epoch: 6| Step: 10
Training loss: 2.7867046401829945
Validation loss: 2.5013970460610473

Epoch: 6| Step: 11
Training loss: 2.8844007959999822
Validation loss: 2.4913216839922567

Epoch: 6| Step: 12
Training loss: 2.7165184070252106
Validation loss: 2.4923206938858464

Epoch: 6| Step: 13
Training loss: 2.639208441900447
Validation loss: 2.493319409406506

Epoch: 159| Step: 0
Training loss: 2.4053071391772103
Validation loss: 2.4920876768101468

Epoch: 6| Step: 1
Training loss: 3.0318683111635627
Validation loss: 2.5050075442780795

Epoch: 6| Step: 2
Training loss: 2.916289023519646
Validation loss: 2.528891887605827

Epoch: 6| Step: 3
Training loss: 2.271076562670119
Validation loss: 2.517868521281562

Epoch: 6| Step: 4
Training loss: 3.23273179334712
Validation loss: 2.5132645880841924

Epoch: 6| Step: 5
Training loss: 2.727879859074298
Validation loss: 2.5094968475413593

Epoch: 6| Step: 6
Training loss: 3.4497938011579494
Validation loss: 2.4993963610055268

Epoch: 6| Step: 7
Training loss: 3.200668658491565
Validation loss: 2.5049052343024867

Epoch: 6| Step: 8
Training loss: 2.831687074991484
Validation loss: 2.5118550733574985

Epoch: 6| Step: 9
Training loss: 2.426421887118126
Validation loss: 2.4998826891539774

Epoch: 6| Step: 10
Training loss: 2.535248412351165
Validation loss: 2.4834279407859143

Epoch: 6| Step: 11
Training loss: 2.384955471270914
Validation loss: 2.4911359539168267

Epoch: 6| Step: 12
Training loss: 2.112808710599
Validation loss: 2.495841747853662

Epoch: 6| Step: 13
Training loss: 3.286573904738951
Validation loss: 2.494454932575802

Epoch: 160| Step: 0
Training loss: 2.842651322630551
Validation loss: 2.494825274345381

Epoch: 6| Step: 1
Training loss: 2.6556006142674313
Validation loss: 2.4962098283070104

Epoch: 6| Step: 2
Training loss: 2.4248576840198774
Validation loss: 2.490877935681355

Epoch: 6| Step: 3
Training loss: 2.820172589073127
Validation loss: 2.485944618798648

Epoch: 6| Step: 4
Training loss: 2.8459933309041294
Validation loss: 2.490309844863008

Epoch: 6| Step: 5
Training loss: 3.0666517803273114
Validation loss: 2.485935009554166

Epoch: 6| Step: 6
Training loss: 3.24240398373645
Validation loss: 2.4900608556438573

Epoch: 6| Step: 7
Training loss: 2.713802264117496
Validation loss: 2.4886149134765247

Epoch: 6| Step: 8
Training loss: 2.567056187471363
Validation loss: 2.5083940779962273

Epoch: 6| Step: 9
Training loss: 2.824630517343689
Validation loss: 2.5149668384979256

Epoch: 6| Step: 10
Training loss: 3.006634370019965
Validation loss: 2.5284570771138384

Epoch: 6| Step: 11
Training loss: 2.8533274583964015
Validation loss: 2.543996086068192

Epoch: 6| Step: 12
Training loss: 2.4698702045268437
Validation loss: 2.5710149616059423

Epoch: 6| Step: 13
Training loss: 2.456670543593406
Validation loss: 2.581019114887428

Epoch: 161| Step: 0
Training loss: 3.209310523168279
Validation loss: 2.580942059077484

Epoch: 6| Step: 1
Training loss: 2.387772797183442
Validation loss: 2.5637164416295533

Epoch: 6| Step: 2
Training loss: 3.2415822394849463
Validation loss: 2.527806888435086

Epoch: 6| Step: 3
Training loss: 2.5667410389747594
Validation loss: 2.533494439153915

Epoch: 6| Step: 4
Training loss: 2.680049593737052
Validation loss: 2.510567744079914

Epoch: 6| Step: 5
Training loss: 2.3316294261620616
Validation loss: 2.5088117252922064

Epoch: 6| Step: 6
Training loss: 2.5502054169139066
Validation loss: 2.500754065257463

Epoch: 6| Step: 7
Training loss: 3.2116650873116646
Validation loss: 2.5047176323012668

Epoch: 6| Step: 8
Training loss: 2.7301374460910095
Validation loss: 2.495856664295416

Epoch: 6| Step: 9
Training loss: 2.983131828819785
Validation loss: 2.507878874572928

Epoch: 6| Step: 10
Training loss: 3.1848342818859776
Validation loss: 2.502948670987866

Epoch: 6| Step: 11
Training loss: 2.9691189185353934
Validation loss: 2.5070304132837986

Epoch: 6| Step: 12
Training loss: 1.910862142803462
Validation loss: 2.4945283478023144

Epoch: 6| Step: 13
Training loss: 2.7361115091477397
Validation loss: 2.4893416104895576

Epoch: 162| Step: 0
Training loss: 2.748367084861153
Validation loss: 2.4883551028751727

Epoch: 6| Step: 1
Training loss: 2.8510440720945356
Validation loss: 2.4887346456798443

Epoch: 6| Step: 2
Training loss: 2.309477506228654
Validation loss: 2.481764731807319

Epoch: 6| Step: 3
Training loss: 2.113872114068453
Validation loss: 2.4763409138990116

Epoch: 6| Step: 4
Training loss: 3.234338585100337
Validation loss: 2.483427919623781

Epoch: 6| Step: 5
Training loss: 2.9720771215400577
Validation loss: 2.4740695208621193

Epoch: 6| Step: 6
Training loss: 2.376606849392038
Validation loss: 2.4770004968443273

Epoch: 6| Step: 7
Training loss: 2.755055635447829
Validation loss: 2.4714466381395757

Epoch: 6| Step: 8
Training loss: 2.8616050820527077
Validation loss: 2.4683307018004133

Epoch: 6| Step: 9
Training loss: 2.898353760530139
Validation loss: 2.499327433777643

Epoch: 6| Step: 10
Training loss: 2.959319545786204
Validation loss: 2.5037359686866836

Epoch: 6| Step: 11
Training loss: 3.264455193343996
Validation loss: 2.522175247550677

Epoch: 6| Step: 12
Training loss: 2.6176714549342863
Validation loss: 2.5511571359112306

Epoch: 6| Step: 13
Training loss: 2.9775188841969604
Validation loss: 2.5854262842484657

Epoch: 163| Step: 0
Training loss: 3.099086897718322
Validation loss: 2.580285757300009

Epoch: 6| Step: 1
Training loss: 2.165535766172319
Validation loss: 2.564417120158109

Epoch: 6| Step: 2
Training loss: 2.493059059738015
Validation loss: 2.5736839100702644

Epoch: 6| Step: 3
Training loss: 2.857154526005486
Validation loss: 2.5364074850172917

Epoch: 6| Step: 4
Training loss: 2.6424781571769382
Validation loss: 2.5009730045286425

Epoch: 6| Step: 5
Training loss: 2.564113481143795
Validation loss: 2.477320622749659

Epoch: 6| Step: 6
Training loss: 2.744319337068814
Validation loss: 2.4706085030019755

Epoch: 6| Step: 7
Training loss: 3.433061265504879
Validation loss: 2.476335879456051

Epoch: 6| Step: 8
Training loss: 3.3600380886280514
Validation loss: 2.478149138724374

Epoch: 6| Step: 9
Training loss: 2.2925045446852104
Validation loss: 2.475355534370338

Epoch: 6| Step: 10
Training loss: 2.466010299766298
Validation loss: 2.477181950793628

Epoch: 6| Step: 11
Training loss: 3.064141903810829
Validation loss: 2.4707761357580336

Epoch: 6| Step: 12
Training loss: 2.888995396859637
Validation loss: 2.4861398955970118

Epoch: 6| Step: 13
Training loss: 2.68342929652697
Validation loss: 2.492375302504481

Epoch: 164| Step: 0
Training loss: 2.5697874327151693
Validation loss: 2.508139082143732

Epoch: 6| Step: 1
Training loss: 3.439447024944903
Validation loss: 2.534885664265903

Epoch: 6| Step: 2
Training loss: 2.3498146430429223
Validation loss: 2.537319515139539

Epoch: 6| Step: 3
Training loss: 2.8521585755957255
Validation loss: 2.53191391636509

Epoch: 6| Step: 4
Training loss: 2.719027537945453
Validation loss: 2.5381411926953916

Epoch: 6| Step: 5
Training loss: 3.176248175910627
Validation loss: 2.537935267171278

Epoch: 6| Step: 6
Training loss: 2.725904237701034
Validation loss: 2.531364770513225

Epoch: 6| Step: 7
Training loss: 2.3432541386266488
Validation loss: 2.5125263094576793

Epoch: 6| Step: 8
Training loss: 2.634360200924105
Validation loss: 2.5022563022650886

Epoch: 6| Step: 9
Training loss: 2.9658220810519094
Validation loss: 2.497110820043571

Epoch: 6| Step: 10
Training loss: 2.9814824171659353
Validation loss: 2.5016643962150362

Epoch: 6| Step: 11
Training loss: 2.826303221966167
Validation loss: 2.5062834142462824

Epoch: 6| Step: 12
Training loss: 2.6770053263380764
Validation loss: 2.5054522751543105

Epoch: 6| Step: 13
Training loss: 2.9272620168066714
Validation loss: 2.501352047120007

Epoch: 165| Step: 0
Training loss: 3.964587815015421
Validation loss: 2.5010338686153477

Epoch: 6| Step: 1
Training loss: 1.920626723403232
Validation loss: 2.5079026148376284

Epoch: 6| Step: 2
Training loss: 2.960273930014359
Validation loss: 2.514825022019192

Epoch: 6| Step: 3
Training loss: 2.9131291508067036
Validation loss: 2.5145779107352046

Epoch: 6| Step: 4
Training loss: 2.5530858983532294
Validation loss: 2.523932291597326

Epoch: 6| Step: 5
Training loss: 2.9973892932138866
Validation loss: 2.518982861913377

Epoch: 6| Step: 6
Training loss: 2.2132996789640997
Validation loss: 2.5081435421978204

Epoch: 6| Step: 7
Training loss: 2.7742955559486795
Validation loss: 2.5156512138373106

Epoch: 6| Step: 8
Training loss: 2.8803326451732247
Validation loss: 2.508206333214098

Epoch: 6| Step: 9
Training loss: 2.6872638332483962
Validation loss: 2.5154299758832197

Epoch: 6| Step: 10
Training loss: 2.636171637392837
Validation loss: 2.5157238199407206

Epoch: 6| Step: 11
Training loss: 3.1545819699915087
Validation loss: 2.52182475762233

Epoch: 6| Step: 12
Training loss: 2.3429571209320335
Validation loss: 2.512511733804256

Epoch: 6| Step: 13
Training loss: 1.9608453979747897
Validation loss: 2.5101996554255654

Epoch: 166| Step: 0
Training loss: 2.9982784417898802
Validation loss: 2.5214327210876455

Epoch: 6| Step: 1
Training loss: 2.33334165526223
Validation loss: 2.516755490228588

Epoch: 6| Step: 2
Training loss: 3.13989932658149
Validation loss: 2.507114564118451

Epoch: 6| Step: 3
Training loss: 2.7600242671728994
Validation loss: 2.4946949168679673

Epoch: 6| Step: 4
Training loss: 2.9541622540253116
Validation loss: 2.488177254907534

Epoch: 6| Step: 5
Training loss: 2.7803307203442085
Validation loss: 2.482844321739065

Epoch: 6| Step: 6
Training loss: 1.9844066587310643
Validation loss: 2.4849228443550873

Epoch: 6| Step: 7
Training loss: 2.9993204300803478
Validation loss: 2.48975771314176

Epoch: 6| Step: 8
Training loss: 3.015083857393399
Validation loss: 2.4816730118744257

Epoch: 6| Step: 9
Training loss: 3.0116193188434126
Validation loss: 2.4782994064004984

Epoch: 6| Step: 10
Training loss: 2.4328914014581624
Validation loss: 2.4944912946311115

Epoch: 6| Step: 11
Training loss: 2.8809902976076938
Validation loss: 2.530535343472419

Epoch: 6| Step: 12
Training loss: 2.7335903240748216
Validation loss: 2.5588545571690613

Epoch: 6| Step: 13
Training loss: 2.9762741309625227
Validation loss: 2.5831426393967134

Epoch: 167| Step: 0
Training loss: 2.7593122084181396
Validation loss: 2.6276676863789814

Epoch: 6| Step: 1
Training loss: 3.1968043046370536
Validation loss: 2.6338745849387406

Epoch: 6| Step: 2
Training loss: 3.085153214469338
Validation loss: 2.5988197737719596

Epoch: 6| Step: 3
Training loss: 2.78022061275335
Validation loss: 2.5631899191298753

Epoch: 6| Step: 4
Training loss: 2.932171960875093
Validation loss: 2.5314489944974947

Epoch: 6| Step: 5
Training loss: 2.6441139782275647
Validation loss: 2.510607490610729

Epoch: 6| Step: 6
Training loss: 2.590690462875172
Validation loss: 2.497292888491874

Epoch: 6| Step: 7
Training loss: 3.0392807438406164
Validation loss: 2.4876028524345073

Epoch: 6| Step: 8
Training loss: 3.0225141036822323
Validation loss: 2.480151002670102

Epoch: 6| Step: 9
Training loss: 2.8878388045068286
Validation loss: 2.4776802153254653

Epoch: 6| Step: 10
Training loss: 2.569803761511891
Validation loss: 2.478325732641577

Epoch: 6| Step: 11
Training loss: 2.6074804863789343
Validation loss: 2.4741986067477235

Epoch: 6| Step: 12
Training loss: 2.6682335204168917
Validation loss: 2.475941631014678

Epoch: 6| Step: 13
Training loss: 2.3533503937395537
Validation loss: 2.4739343257099717

Epoch: 168| Step: 0
Training loss: 2.9755109396316586
Validation loss: 2.4756236464309263

Epoch: 6| Step: 1
Training loss: 2.7013685219679844
Validation loss: 2.4721265759903814

Epoch: 6| Step: 2
Training loss: 3.0766647670598086
Validation loss: 2.4688396486905924

Epoch: 6| Step: 3
Training loss: 2.4098497687403566
Validation loss: 2.471531631265154

Epoch: 6| Step: 4
Training loss: 2.7349225177285215
Validation loss: 2.477117299620009

Epoch: 6| Step: 5
Training loss: 2.383915880229676
Validation loss: 2.4718161831328005

Epoch: 6| Step: 6
Training loss: 2.656926865449474
Validation loss: 2.471488862261537

Epoch: 6| Step: 7
Training loss: 3.26748472856661
Validation loss: 2.47485080305349

Epoch: 6| Step: 8
Training loss: 2.1056748326497354
Validation loss: 2.4746100836087854

Epoch: 6| Step: 9
Training loss: 2.7470230114739898
Validation loss: 2.4774250963375897

Epoch: 6| Step: 10
Training loss: 2.6797328756066214
Validation loss: 2.4750244907158923

Epoch: 6| Step: 11
Training loss: 3.106687064479067
Validation loss: 2.485735590268913

Epoch: 6| Step: 12
Training loss: 2.8112397655336387
Validation loss: 2.483957990497112

Epoch: 6| Step: 13
Training loss: 3.1244182808173844
Validation loss: 2.5012529945329987

Epoch: 169| Step: 0
Training loss: 2.5021154036889834
Validation loss: 2.49259208455202

Epoch: 6| Step: 1
Training loss: 2.8360276221045244
Validation loss: 2.4905836378618074

Epoch: 6| Step: 2
Training loss: 2.3801719167470834
Validation loss: 2.4728488429480215

Epoch: 6| Step: 3
Training loss: 3.003556368806103
Validation loss: 2.475343539779847

Epoch: 6| Step: 4
Training loss: 3.365950142430533
Validation loss: 2.478029472333591

Epoch: 6| Step: 5
Training loss: 2.2037305067458464
Validation loss: 2.470017674295562

Epoch: 6| Step: 6
Training loss: 3.126604202503305
Validation loss: 2.4729406434350985

Epoch: 6| Step: 7
Training loss: 2.680123518901434
Validation loss: 2.468659862047762

Epoch: 6| Step: 8
Training loss: 2.80561205573101
Validation loss: 2.4710452364521407

Epoch: 6| Step: 9
Training loss: 3.0105277352264785
Validation loss: 2.4743486947251734

Epoch: 6| Step: 10
Training loss: 2.604113545193874
Validation loss: 2.4810357607579485

Epoch: 6| Step: 11
Training loss: 3.01714938676528
Validation loss: 2.482464798501131

Epoch: 6| Step: 12
Training loss: 2.4521851895767357
Validation loss: 2.491116720897964

Epoch: 6| Step: 13
Training loss: 2.5131642882096807
Validation loss: 2.4979887347541623

Epoch: 170| Step: 0
Training loss: 2.0359510747730725
Validation loss: 2.536964285353437

Epoch: 6| Step: 1
Training loss: 3.5572523316889053
Validation loss: 2.5644376478584205

Epoch: 6| Step: 2
Training loss: 2.7946958950342764
Validation loss: 2.5539501308040102

Epoch: 6| Step: 3
Training loss: 2.8553114402846687
Validation loss: 2.5166676049318

Epoch: 6| Step: 4
Training loss: 2.6697941758621178
Validation loss: 2.4956626881276693

Epoch: 6| Step: 5
Training loss: 2.404564403335373
Validation loss: 2.469706597025262

Epoch: 6| Step: 6
Training loss: 3.3008114424007458
Validation loss: 2.4563526066900554

Epoch: 6| Step: 7
Training loss: 2.528444595789002
Validation loss: 2.4538984644965414

Epoch: 6| Step: 8
Training loss: 2.926271282967626
Validation loss: 2.4560126677515077

Epoch: 6| Step: 9
Training loss: 2.979563404333651
Validation loss: 2.4713552240641983

Epoch: 6| Step: 10
Training loss: 2.5702810546435617
Validation loss: 2.466300603891913

Epoch: 6| Step: 11
Training loss: 3.1222644276630382
Validation loss: 2.4592993791549884

Epoch: 6| Step: 12
Training loss: 2.8025551343219472
Validation loss: 2.465899307998356

Epoch: 6| Step: 13
Training loss: 2.931134896367051
Validation loss: 2.459874063643586

Epoch: 171| Step: 0
Training loss: 2.5559955945999318
Validation loss: 2.462197274868152

Epoch: 6| Step: 1
Training loss: 3.074811827321714
Validation loss: 2.4713461556035674

Epoch: 6| Step: 2
Training loss: 2.4456759539199036
Validation loss: 2.4993888846385

Epoch: 6| Step: 3
Training loss: 2.8644614083901097
Validation loss: 2.525241006294173

Epoch: 6| Step: 4
Training loss: 2.426726177170561
Validation loss: 2.6466280549726333

Epoch: 6| Step: 5
Training loss: 2.9156192170276922
Validation loss: 2.8598437280067057

Epoch: 6| Step: 6
Training loss: 3.290167905934766
Validation loss: 3.069546247764019

Epoch: 6| Step: 7
Training loss: 3.6155366693915365
Validation loss: 3.1797130194976777

Epoch: 6| Step: 8
Training loss: 3.650204608355719
Validation loss: 3.1558176355924052

Epoch: 6| Step: 9
Training loss: 3.6904814999918676
Validation loss: 3.046622066343231

Epoch: 6| Step: 10
Training loss: 2.718979047575988
Validation loss: 2.8981417515091503

Epoch: 6| Step: 11
Training loss: 3.302853627818222
Validation loss: 2.7476444503781474

Epoch: 6| Step: 12
Training loss: 2.7762913594606684
Validation loss: 2.5923431926307745

Epoch: 6| Step: 13
Training loss: 2.176247894268562
Validation loss: 2.5037429887142646

Epoch: 172| Step: 0
Training loss: 2.4012734610877446
Validation loss: 2.4770298734812704

Epoch: 6| Step: 1
Training loss: 2.351360223631342
Validation loss: 2.481959628896664

Epoch: 6| Step: 2
Training loss: 3.0411815169306977
Validation loss: 2.499666631683104

Epoch: 6| Step: 3
Training loss: 3.297125494963911
Validation loss: 2.511052824396544

Epoch: 6| Step: 4
Training loss: 2.5706451108049837
Validation loss: 2.507862155358693

Epoch: 6| Step: 5
Training loss: 3.317903106737115
Validation loss: 2.5079065514228374

Epoch: 6| Step: 6
Training loss: 3.106157180965144
Validation loss: 2.500491516443243

Epoch: 6| Step: 7
Training loss: 2.8666755572632128
Validation loss: 2.47935583630865

Epoch: 6| Step: 8
Training loss: 2.3142586284310527
Validation loss: 2.4737290733511936

Epoch: 6| Step: 9
Training loss: 2.43164160548424
Validation loss: 2.4631340249627076

Epoch: 6| Step: 10
Training loss: 3.2520998993247408
Validation loss: 2.4697450891203716

Epoch: 6| Step: 11
Training loss: 3.0445049751680884
Validation loss: 2.49668057656167

Epoch: 6| Step: 12
Training loss: 3.1824186625428736
Validation loss: 2.5087898891876494

Epoch: 6| Step: 13
Training loss: 2.3282642706875345
Validation loss: 2.5269720138836975

Epoch: 173| Step: 0
Training loss: 2.549055324673886
Validation loss: 2.5553643715172645

Epoch: 6| Step: 1
Training loss: 2.3475209735099996
Validation loss: 2.5570293970622258

Epoch: 6| Step: 2
Training loss: 3.267667286916745
Validation loss: 2.5612193203047227

Epoch: 6| Step: 3
Training loss: 3.164227215282443
Validation loss: 2.5236442316400973

Epoch: 6| Step: 4
Training loss: 2.396694581404653
Validation loss: 2.4933907256343613

Epoch: 6| Step: 5
Training loss: 2.203106927459396
Validation loss: 2.4669346431086616

Epoch: 6| Step: 6
Training loss: 3.1938734474884534
Validation loss: 2.464626230047149

Epoch: 6| Step: 7
Training loss: 3.523167906468264
Validation loss: 2.4612254755405942

Epoch: 6| Step: 8
Training loss: 2.8354295007628716
Validation loss: 2.456822759409242

Epoch: 6| Step: 9
Training loss: 2.812931112520643
Validation loss: 2.465720790112395

Epoch: 6| Step: 10
Training loss: 3.0567150362847557
Validation loss: 2.4623637967368013

Epoch: 6| Step: 11
Training loss: 2.136109204147451
Validation loss: 2.461995249246121

Epoch: 6| Step: 12
Training loss: 2.5324392468469896
Validation loss: 2.464870219955284

Epoch: 6| Step: 13
Training loss: 2.781213995882653
Validation loss: 2.4699256001367544

Epoch: 174| Step: 0
Training loss: 3.4608878999690735
Validation loss: 2.4624912443994895

Epoch: 6| Step: 1
Training loss: 2.658485100538492
Validation loss: 2.4807217764191414

Epoch: 6| Step: 2
Training loss: 2.847057221963457
Validation loss: 2.491171789155761

Epoch: 6| Step: 3
Training loss: 2.9867520277847097
Validation loss: 2.500585771456016

Epoch: 6| Step: 4
Training loss: 3.004099270456589
Validation loss: 2.505986324131796

Epoch: 6| Step: 5
Training loss: 2.50080972909725
Validation loss: 2.5100591772045786

Epoch: 6| Step: 6
Training loss: 2.315694303929802
Validation loss: 2.5374787975577022

Epoch: 6| Step: 7
Training loss: 3.221822808894689
Validation loss: 2.5502001231656033

Epoch: 6| Step: 8
Training loss: 2.499094417588103
Validation loss: 2.5741598672861046

Epoch: 6| Step: 9
Training loss: 2.5022995863014668
Validation loss: 2.5664373202935846

Epoch: 6| Step: 10
Training loss: 2.811482054553899
Validation loss: 2.540630708079154

Epoch: 6| Step: 11
Training loss: 3.117482412819402
Validation loss: 2.517252743012352

Epoch: 6| Step: 12
Training loss: 2.185408327894663
Validation loss: 2.498019867848

Epoch: 6| Step: 13
Training loss: 2.6067480695393015
Validation loss: 2.487259640775672

Epoch: 175| Step: 0
Training loss: 3.003305838992162
Validation loss: 2.4768001449752806

Epoch: 6| Step: 1
Training loss: 2.9211232243306053
Validation loss: 2.4796301306068678

Epoch: 6| Step: 2
Training loss: 2.79250416126129
Validation loss: 2.4724454904148696

Epoch: 6| Step: 3
Training loss: 3.1469480716286604
Validation loss: 2.4669801498147805

Epoch: 6| Step: 4
Training loss: 2.9987831826896434
Validation loss: 2.4713218089769495

Epoch: 6| Step: 5
Training loss: 3.0199620185131004
Validation loss: 2.4618810795057255

Epoch: 6| Step: 6
Training loss: 1.9845740150917939
Validation loss: 2.474029107541394

Epoch: 6| Step: 7
Training loss: 2.383169078724396
Validation loss: 2.4786691212057494

Epoch: 6| Step: 8
Training loss: 2.9729616507049834
Validation loss: 2.5391637214318243

Epoch: 6| Step: 9
Training loss: 2.5721602363981453
Validation loss: 2.528131650281674

Epoch: 6| Step: 10
Training loss: 2.943242405501787
Validation loss: 2.5166264347488987

Epoch: 6| Step: 11
Training loss: 2.8925787843939155
Validation loss: 2.5037720679654396

Epoch: 6| Step: 12
Training loss: 2.7074934219463604
Validation loss: 2.5038879085678682

Epoch: 6| Step: 13
Training loss: 2.3414117975331554
Validation loss: 2.4982829976004464

Epoch: 176| Step: 0
Training loss: 2.554286166989904
Validation loss: 2.506302422453017

Epoch: 6| Step: 1
Training loss: 2.8492939325386324
Validation loss: 2.499842233704532

Epoch: 6| Step: 2
Training loss: 2.6142145836568766
Validation loss: 2.4916654812801102

Epoch: 6| Step: 3
Training loss: 3.0839126317652594
Validation loss: 2.481978238764298

Epoch: 6| Step: 4
Training loss: 2.1874901907564666
Validation loss: 2.4798497015436585

Epoch: 6| Step: 5
Training loss: 2.9915307023827014
Validation loss: 2.481602699813315

Epoch: 6| Step: 6
Training loss: 3.350699644902772
Validation loss: 2.479303428770635

Epoch: 6| Step: 7
Training loss: 2.3655788885785185
Validation loss: 2.474259049813766

Epoch: 6| Step: 8
Training loss: 2.7938538329352753
Validation loss: 2.470029572795627

Epoch: 6| Step: 9
Training loss: 2.5470704547796332
Validation loss: 2.4686782865958836

Epoch: 6| Step: 10
Training loss: 2.5606283470245526
Validation loss: 2.4682252979753074

Epoch: 6| Step: 11
Training loss: 2.824313129204061
Validation loss: 2.456635741197529

Epoch: 6| Step: 12
Training loss: 2.651996932578866
Validation loss: 2.4535007799037483

Epoch: 6| Step: 13
Training loss: 3.2363819032665946
Validation loss: 2.456146763411568

Epoch: 177| Step: 0
Training loss: 2.8092965425901526
Validation loss: 2.46156723890194

Epoch: 6| Step: 1
Training loss: 2.7836994143593152
Validation loss: 2.464654216815474

Epoch: 6| Step: 2
Training loss: 2.9079109285925404
Validation loss: 2.4561921151147743

Epoch: 6| Step: 3
Training loss: 2.3369660935625354
Validation loss: 2.452147708809289

Epoch: 6| Step: 4
Training loss: 3.4763120411010995
Validation loss: 2.449795832214436

Epoch: 6| Step: 5
Training loss: 3.037451780587961
Validation loss: 2.4542898444866594

Epoch: 6| Step: 6
Training loss: 2.7482390400950725
Validation loss: 2.4622313218838143

Epoch: 6| Step: 7
Training loss: 2.7319365173269654
Validation loss: 2.4973550833582263

Epoch: 6| Step: 8
Training loss: 2.6539756462629853
Validation loss: 2.525553396413375

Epoch: 6| Step: 9
Training loss: 2.5301272881192545
Validation loss: 2.536286384727754

Epoch: 6| Step: 10
Training loss: 2.320180561668664
Validation loss: 2.52768412454136

Epoch: 6| Step: 11
Training loss: 2.8743857681261833
Validation loss: 2.513651662960838

Epoch: 6| Step: 12
Training loss: 2.6630369656812345
Validation loss: 2.516661230628908

Epoch: 6| Step: 13
Training loss: 2.641454081199584
Validation loss: 2.5140461406143504

Epoch: 178| Step: 0
Training loss: 2.494073327694279
Validation loss: 2.494073572332813

Epoch: 6| Step: 1
Training loss: 2.757541459464442
Validation loss: 2.4819414341223442

Epoch: 6| Step: 2
Training loss: 2.236013705209893
Validation loss: 2.473620858784644

Epoch: 6| Step: 3
Training loss: 3.1388607098900243
Validation loss: 2.4606750087857288

Epoch: 6| Step: 4
Training loss: 2.8946243250576287
Validation loss: 2.477467196836686

Epoch: 6| Step: 5
Training loss: 3.0140882934922124
Validation loss: 2.475099922003559

Epoch: 6| Step: 6
Training loss: 3.0503388888836813
Validation loss: 2.4762292582549446

Epoch: 6| Step: 7
Training loss: 2.157226120416433
Validation loss: 2.489642674192023

Epoch: 6| Step: 8
Training loss: 2.8766746619309775
Validation loss: 2.488236283803805

Epoch: 6| Step: 9
Training loss: 2.044654398770755
Validation loss: 2.4924773728744722

Epoch: 6| Step: 10
Training loss: 2.7824672649750903
Validation loss: 2.4896966135521064

Epoch: 6| Step: 11
Training loss: 2.7768400569814755
Validation loss: 2.486695099705215

Epoch: 6| Step: 12
Training loss: 3.199881646828666
Validation loss: 2.4771841644480865

Epoch: 6| Step: 13
Training loss: 2.3320078377371147
Validation loss: 2.478282540908365

Epoch: 179| Step: 0
Training loss: 3.152267814392874
Validation loss: 2.480435566207434

Epoch: 6| Step: 1
Training loss: 2.967605852201157
Validation loss: 2.4719577011163594

Epoch: 6| Step: 2
Training loss: 2.90554193874821
Validation loss: 2.473020292118084

Epoch: 6| Step: 3
Training loss: 2.460763301436325
Validation loss: 2.464001734351954

Epoch: 6| Step: 4
Training loss: 2.759504798609893
Validation loss: 2.4738106511352167

Epoch: 6| Step: 5
Training loss: 2.7072652520220304
Validation loss: 2.4727541459892763

Epoch: 6| Step: 6
Training loss: 3.130673712962386
Validation loss: 2.4751188610327515

Epoch: 6| Step: 7
Training loss: 2.7331671962799944
Validation loss: 2.4872736367323767

Epoch: 6| Step: 8
Training loss: 2.8313671096261355
Validation loss: 2.521912562312465

Epoch: 6| Step: 9
Training loss: 2.878469281309492
Validation loss: 2.5122989135115312

Epoch: 6| Step: 10
Training loss: 2.187480817438214
Validation loss: 2.5191444414841926

Epoch: 6| Step: 11
Training loss: 2.1171796172160677
Validation loss: 2.5314851016406976

Epoch: 6| Step: 12
Training loss: 2.216594885139515
Validation loss: 2.527936995731636

Epoch: 6| Step: 13
Training loss: 3.3979183107360815
Validation loss: 2.524841243253294

Epoch: 180| Step: 0
Training loss: 3.1404652720964994
Validation loss: 2.5404226411332105

Epoch: 6| Step: 1
Training loss: 2.4111840330348304
Validation loss: 2.548835927067852

Epoch: 6| Step: 2
Training loss: 3.214832329063477
Validation loss: 2.5560315094501496

Epoch: 6| Step: 3
Training loss: 2.742010301043348
Validation loss: 2.546285019774299

Epoch: 6| Step: 4
Training loss: 2.855028194147981
Validation loss: 2.5424361077123145

Epoch: 6| Step: 5
Training loss: 2.7394481572402998
Validation loss: 2.520810082319142

Epoch: 6| Step: 6
Training loss: 2.994625363362591
Validation loss: 2.51397138943776

Epoch: 6| Step: 7
Training loss: 2.150963979677511
Validation loss: 2.5141798202059245

Epoch: 6| Step: 8
Training loss: 2.7178446698354612
Validation loss: 2.500139914463393

Epoch: 6| Step: 9
Training loss: 2.9134429191155156
Validation loss: 2.4949009382622016

Epoch: 6| Step: 10
Training loss: 3.2423897186089934
Validation loss: 2.50115366435272

Epoch: 6| Step: 11
Training loss: 2.4522197049144383
Validation loss: 2.4894338583424696

Epoch: 6| Step: 12
Training loss: 2.640511143503944
Validation loss: 2.4957040372138732

Epoch: 6| Step: 13
Training loss: 2.3044668318285257
Validation loss: 2.476126204399663

Epoch: 181| Step: 0
Training loss: 2.686266682654225
Validation loss: 2.474196579001541

Epoch: 6| Step: 1
Training loss: 2.9625986718593746
Validation loss: 2.4563391285982266

Epoch: 6| Step: 2
Training loss: 2.158096407500124
Validation loss: 2.455265471727886

Epoch: 6| Step: 3
Training loss: 2.4760759038059983
Validation loss: 2.4570018205008872

Epoch: 6| Step: 4
Training loss: 2.8196565071202824
Validation loss: 2.453642744078141

Epoch: 6| Step: 5
Training loss: 2.961334765514501
Validation loss: 2.4649225973866233

Epoch: 6| Step: 6
Training loss: 2.9289658942042363
Validation loss: 2.4709762933904877

Epoch: 6| Step: 7
Training loss: 2.5917380009326783
Validation loss: 2.4733121190964704

Epoch: 6| Step: 8
Training loss: 2.612381259829852
Validation loss: 2.474223788170566

Epoch: 6| Step: 9
Training loss: 2.8222347059833166
Validation loss: 2.475220768855093

Epoch: 6| Step: 10
Training loss: 2.887034562816062
Validation loss: 2.477442184973491

Epoch: 6| Step: 11
Training loss: 2.826178455147402
Validation loss: 2.467420036740024

Epoch: 6| Step: 12
Training loss: 2.612922130593806
Validation loss: 2.4724498276993168

Epoch: 6| Step: 13
Training loss: 3.050609158828643
Validation loss: 2.4631232526140128

Epoch: 182| Step: 0
Training loss: 2.7474478236095825
Validation loss: 2.4499621322866294

Epoch: 6| Step: 1
Training loss: 2.933046251756253
Validation loss: 2.4564858045427016

Epoch: 6| Step: 2
Training loss: 2.393104215119732
Validation loss: 2.4599048433042014

Epoch: 6| Step: 3
Training loss: 2.9598038649659513
Validation loss: 2.4792383779396987

Epoch: 6| Step: 4
Training loss: 3.280334780983427
Validation loss: 2.5029741090865425

Epoch: 6| Step: 5
Training loss: 2.3810912872848427
Validation loss: 2.495939560780689

Epoch: 6| Step: 6
Training loss: 2.7461819587095455
Validation loss: 2.4693259474312694

Epoch: 6| Step: 7
Training loss: 2.8817924204080505
Validation loss: 2.4459362930814765

Epoch: 6| Step: 8
Training loss: 2.6785537501160475
Validation loss: 2.447060627037754

Epoch: 6| Step: 9
Training loss: 2.3636706323073495
Validation loss: 2.443004328281145

Epoch: 6| Step: 10
Training loss: 2.9094288166448643
Validation loss: 2.4493870082788063

Epoch: 6| Step: 11
Training loss: 2.6358639384046794
Validation loss: 2.453935725252863

Epoch: 6| Step: 12
Training loss: 2.751102226618217
Validation loss: 2.460686944126962

Epoch: 6| Step: 13
Training loss: 2.171865559289846
Validation loss: 2.4679206160072815

Epoch: 183| Step: 0
Training loss: 3.200978522893948
Validation loss: 2.471867152755509

Epoch: 6| Step: 1
Training loss: 3.049227075665597
Validation loss: 2.456156189115554

Epoch: 6| Step: 2
Training loss: 3.1359237480527287
Validation loss: 2.4656611733187703

Epoch: 6| Step: 3
Training loss: 2.895088337817112
Validation loss: 2.4699718078645776

Epoch: 6| Step: 4
Training loss: 2.189953545203954
Validation loss: 2.4861311935118136

Epoch: 6| Step: 5
Training loss: 2.5851201266741817
Validation loss: 2.4831031654523095

Epoch: 6| Step: 6
Training loss: 2.581940203517226
Validation loss: 2.4609192716825494

Epoch: 6| Step: 7
Training loss: 2.4788062103407906
Validation loss: 2.448254368270211

Epoch: 6| Step: 8
Training loss: 2.4091498006227883
Validation loss: 2.4373766539491233

Epoch: 6| Step: 9
Training loss: 2.503151623683124
Validation loss: 2.438067337326122

Epoch: 6| Step: 10
Training loss: 2.9263985444846896
Validation loss: 2.4411556427997096

Epoch: 6| Step: 11
Training loss: 2.231411121866071
Validation loss: 2.4390641382489164

Epoch: 6| Step: 12
Training loss: 2.9587542453827274
Validation loss: 2.4389706264705966

Epoch: 6| Step: 13
Training loss: 3.117645000643374
Validation loss: 2.438527738546258

Epoch: 184| Step: 0
Training loss: 2.572196942153227
Validation loss: 2.440952170264214

Epoch: 6| Step: 1
Training loss: 3.1850438846457267
Validation loss: 2.440853107490923

Epoch: 6| Step: 2
Training loss: 2.4722209625621927
Validation loss: 2.447882885897293

Epoch: 6| Step: 3
Training loss: 2.9585875997386233
Validation loss: 2.4511640507317796

Epoch: 6| Step: 4
Training loss: 2.3149255970477634
Validation loss: 2.450606988800706

Epoch: 6| Step: 5
Training loss: 2.732687991028437
Validation loss: 2.45543262761458

Epoch: 6| Step: 6
Training loss: 2.7945977002338536
Validation loss: 2.4624553249319536

Epoch: 6| Step: 7
Training loss: 2.276315028158861
Validation loss: 2.4546514981300867

Epoch: 6| Step: 8
Training loss: 2.690451310031079
Validation loss: 2.465387701445226

Epoch: 6| Step: 9
Training loss: 2.4325317220785543
Validation loss: 2.468802653372044

Epoch: 6| Step: 10
Training loss: 3.1901259731663276
Validation loss: 2.4685416745749604

Epoch: 6| Step: 11
Training loss: 3.1895308663213777
Validation loss: 2.4886978276440055

Epoch: 6| Step: 12
Training loss: 1.9412930185006072
Validation loss: 2.5020062651317527

Epoch: 6| Step: 13
Training loss: 3.0808016375382556
Validation loss: 2.5133789926030015

Epoch: 185| Step: 0
Training loss: 2.857753272926286
Validation loss: 2.5259672210822792

Epoch: 6| Step: 1
Training loss: 2.2272167649961756
Validation loss: 2.527890153941437

Epoch: 6| Step: 2
Training loss: 2.7327068362956917
Validation loss: 2.509409012981125

Epoch: 6| Step: 3
Training loss: 3.0899838730474563
Validation loss: 2.48706078537435

Epoch: 6| Step: 4
Training loss: 2.9854092228954836
Validation loss: 2.470666241632954

Epoch: 6| Step: 5
Training loss: 2.4939293588944658
Validation loss: 2.4600742516898957

Epoch: 6| Step: 6
Training loss: 3.0332550024741045
Validation loss: 2.464875949181072

Epoch: 6| Step: 7
Training loss: 2.115906049578887
Validation loss: 2.452182467219571

Epoch: 6| Step: 8
Training loss: 3.4733126763323225
Validation loss: 2.4531091799675613

Epoch: 6| Step: 9
Training loss: 1.94491327930887
Validation loss: 2.4516143400784975

Epoch: 6| Step: 10
Training loss: 2.9714059293062447
Validation loss: 2.447078591916827

Epoch: 6| Step: 11
Training loss: 2.24737883583852
Validation loss: 2.445643287586271

Epoch: 6| Step: 12
Training loss: 3.1634695745566304
Validation loss: 2.450560645035857

Epoch: 6| Step: 13
Training loss: 2.0505323277129404
Validation loss: 2.4473415242812213

Epoch: 186| Step: 0
Training loss: 2.275554601957615
Validation loss: 2.45711429405461

Epoch: 6| Step: 1
Training loss: 3.1340783051991723
Validation loss: 2.463003981351315

Epoch: 6| Step: 2
Training loss: 3.373294257991878
Validation loss: 2.468136060105864

Epoch: 6| Step: 3
Training loss: 2.227565392284657
Validation loss: 2.4848391428960266

Epoch: 6| Step: 4
Training loss: 2.605966774899224
Validation loss: 2.495017711684961

Epoch: 6| Step: 5
Training loss: 2.636032716018417
Validation loss: 2.479526220362239

Epoch: 6| Step: 6
Training loss: 2.95463240969018
Validation loss: 2.471799289999061

Epoch: 6| Step: 7
Training loss: 2.5605235968025593
Validation loss: 2.467105602875337

Epoch: 6| Step: 8
Training loss: 2.7633566309273117
Validation loss: 2.4617245099501246

Epoch: 6| Step: 9
Training loss: 2.119611977749291
Validation loss: 2.457987471274906

Epoch: 6| Step: 10
Training loss: 2.9129921427763845
Validation loss: 2.4495164498250412

Epoch: 6| Step: 11
Training loss: 2.58902208461308
Validation loss: 2.43680575664823

Epoch: 6| Step: 12
Training loss: 3.0246555920468845
Validation loss: 2.4443637276243977

Epoch: 6| Step: 13
Training loss: 2.6554632480314067
Validation loss: 2.442978794626045

Epoch: 187| Step: 0
Training loss: 1.9017349929749017
Validation loss: 2.4409101236914013

Epoch: 6| Step: 1
Training loss: 2.0895457402882656
Validation loss: 2.4433975602989717

Epoch: 6| Step: 2
Training loss: 2.5689047810870673
Validation loss: 2.450510242319791

Epoch: 6| Step: 3
Training loss: 2.4724954127933545
Validation loss: 2.4604852951395286

Epoch: 6| Step: 4
Training loss: 3.2052724199373044
Validation loss: 2.4692856267419967

Epoch: 6| Step: 5
Training loss: 2.2502784556698217
Validation loss: 2.4712698866863825

Epoch: 6| Step: 6
Training loss: 2.6080497985719244
Validation loss: 2.478433370439461

Epoch: 6| Step: 7
Training loss: 2.0742753015772517
Validation loss: 2.473682626971017

Epoch: 6| Step: 8
Training loss: 3.0733621220540166
Validation loss: 2.487805909068571

Epoch: 6| Step: 9
Training loss: 2.5743369276505805
Validation loss: 2.492033957916365

Epoch: 6| Step: 10
Training loss: 3.320739000640667
Validation loss: 2.4804075259855813

Epoch: 6| Step: 11
Training loss: 2.9910969552128193
Validation loss: 2.4991764845197033

Epoch: 6| Step: 12
Training loss: 3.4721309921147574
Validation loss: 2.4998554095632475

Epoch: 6| Step: 13
Training loss: 2.904348592291296
Validation loss: 2.477542020856666

Epoch: 188| Step: 0
Training loss: 2.4473773659832476
Validation loss: 2.460688327168391

Epoch: 6| Step: 1
Training loss: 2.4602845309632624
Validation loss: 2.4444211244480685

Epoch: 6| Step: 2
Training loss: 2.3888116079836643
Validation loss: 2.42691197521652

Epoch: 6| Step: 3
Training loss: 2.4576478314878525
Validation loss: 2.4283133667004866

Epoch: 6| Step: 4
Training loss: 2.6871507994426573
Validation loss: 2.423085769918538

Epoch: 6| Step: 5
Training loss: 1.7422421023446693
Validation loss: 2.4369437027536383

Epoch: 6| Step: 6
Training loss: 2.8416780741920347
Validation loss: 2.448528860633986

Epoch: 6| Step: 7
Training loss: 3.2740550767370746
Validation loss: 2.4369920001922543

Epoch: 6| Step: 8
Training loss: 2.879403101206617
Validation loss: 2.4506094534693887

Epoch: 6| Step: 9
Training loss: 2.5466846792805686
Validation loss: 2.45247003556122

Epoch: 6| Step: 10
Training loss: 2.46230779372127
Validation loss: 2.462496685056869

Epoch: 6| Step: 11
Training loss: 3.241293174847425
Validation loss: 2.4726626812385444

Epoch: 6| Step: 12
Training loss: 3.072738969912947
Validation loss: 2.4782211335755355

Epoch: 6| Step: 13
Training loss: 3.226154144530298
Validation loss: 2.486495074306285

Epoch: 189| Step: 0
Training loss: 2.810778620896437
Validation loss: 2.4875385638231484

Epoch: 6| Step: 1
Training loss: 2.3638225345385977
Validation loss: 2.488794875812464

Epoch: 6| Step: 2
Training loss: 2.716564483905148
Validation loss: 2.473431853063136

Epoch: 6| Step: 3
Training loss: 3.068925927862712
Validation loss: 2.4717433068137757

Epoch: 6| Step: 4
Training loss: 2.504644085846358
Validation loss: 2.4590821590003196

Epoch: 6| Step: 5
Training loss: 2.7192869861889966
Validation loss: 2.4485931180968006

Epoch: 6| Step: 6
Training loss: 2.730355583760022
Validation loss: 2.450085353264437

Epoch: 6| Step: 7
Training loss: 2.8345432689982424
Validation loss: 2.447991268476029

Epoch: 6| Step: 8
Training loss: 2.5119399096475568
Validation loss: 2.4490107206749605

Epoch: 6| Step: 9
Training loss: 2.6975463455928046
Validation loss: 2.443508547559623

Epoch: 6| Step: 10
Training loss: 2.572823176570903
Validation loss: 2.448410355830091

Epoch: 6| Step: 11
Training loss: 2.7955614127337145
Validation loss: 2.44326633295138

Epoch: 6| Step: 12
Training loss: 2.3997814873720875
Validation loss: 2.4628866195857575

Epoch: 6| Step: 13
Training loss: 3.108536343596917
Validation loss: 2.4725040498525312

Epoch: 190| Step: 0
Training loss: 2.763772807620249
Validation loss: 2.4886300277559497

Epoch: 6| Step: 1
Training loss: 2.284714145768515
Validation loss: 2.5192090235994162

Epoch: 6| Step: 2
Training loss: 2.545250216401723
Validation loss: 2.5298423068446456

Epoch: 6| Step: 3
Training loss: 3.010906421637577
Validation loss: 2.5303329027838264

Epoch: 6| Step: 4
Training loss: 2.806463332871324
Validation loss: 2.520278518411356

Epoch: 6| Step: 5
Training loss: 3.1783831496219555
Validation loss: 2.488244013134939

Epoch: 6| Step: 6
Training loss: 2.5161503782226684
Validation loss: 2.4471544917609362

Epoch: 6| Step: 7
Training loss: 2.9422659662432427
Validation loss: 2.4416428312791356

Epoch: 6| Step: 8
Training loss: 2.2730672738037896
Validation loss: 2.4343988918392747

Epoch: 6| Step: 9
Training loss: 2.0609205729705504
Validation loss: 2.4345439395802484

Epoch: 6| Step: 10
Training loss: 3.3055537105380624
Validation loss: 2.4288459340950967

Epoch: 6| Step: 11
Training loss: 3.00237148648309
Validation loss: 2.4306856079778822

Epoch: 6| Step: 12
Training loss: 2.431854459253767
Validation loss: 2.4350965023128124

Epoch: 6| Step: 13
Training loss: 2.6024223487548728
Validation loss: 2.4349284904851527

Epoch: 191| Step: 0
Training loss: 2.4183033848736812
Validation loss: 2.4458576606264155

Epoch: 6| Step: 1
Training loss: 2.4082808408549354
Validation loss: 2.4759659757009724

Epoch: 6| Step: 2
Training loss: 2.7779369552357385
Validation loss: 2.49960037441948

Epoch: 6| Step: 3
Training loss: 2.065549503395298
Validation loss: 2.513243007429205

Epoch: 6| Step: 4
Training loss: 3.0769892887180714
Validation loss: 2.538056753423274

Epoch: 6| Step: 5
Training loss: 3.588635329457708
Validation loss: 2.546631359065401

Epoch: 6| Step: 6
Training loss: 2.18702703540001
Validation loss: 2.5652511198955077

Epoch: 6| Step: 7
Training loss: 2.8802028515690563
Validation loss: 2.5908297712015482

Epoch: 6| Step: 8
Training loss: 2.9915311805697913
Validation loss: 2.579357037042461

Epoch: 6| Step: 9
Training loss: 2.710627293496704
Validation loss: 2.546008001418196

Epoch: 6| Step: 10
Training loss: 2.777928801775592
Validation loss: 2.518236418445314

Epoch: 6| Step: 11
Training loss: 2.5241595200791878
Validation loss: 2.461273347537254

Epoch: 6| Step: 12
Training loss: 2.970957527578654
Validation loss: 2.4470237141822113

Epoch: 6| Step: 13
Training loss: 1.840089105335152
Validation loss: 2.4366912088944974

Epoch: 192| Step: 0
Training loss: 3.1592713049408494
Validation loss: 2.4425496020660584

Epoch: 6| Step: 1
Training loss: 3.1630682996285797
Validation loss: 2.4405121199549993

Epoch: 6| Step: 2
Training loss: 3.038896492393167
Validation loss: 2.449677242711364

Epoch: 6| Step: 3
Training loss: 2.6741700605127425
Validation loss: 2.4622820958338987

Epoch: 6| Step: 4
Training loss: 2.683463769510707
Validation loss: 2.4855518836282124

Epoch: 6| Step: 5
Training loss: 2.46546417988255
Validation loss: 2.477839428909231

Epoch: 6| Step: 6
Training loss: 3.2193568870465907
Validation loss: 2.501893224957597

Epoch: 6| Step: 7
Training loss: 1.9771944626452995
Validation loss: 2.489057953906876

Epoch: 6| Step: 8
Training loss: 2.250587810451685
Validation loss: 2.4792717690515236

Epoch: 6| Step: 9
Training loss: 2.5106793235882505
Validation loss: 2.4584628328809344

Epoch: 6| Step: 10
Training loss: 3.0931628662307467
Validation loss: 2.467161621676253

Epoch: 6| Step: 11
Training loss: 2.329304850601598
Validation loss: 2.4548264269863584

Epoch: 6| Step: 12
Training loss: 2.2152019661819917
Validation loss: 2.4532904144944

Epoch: 6| Step: 13
Training loss: 2.4200144850872745
Validation loss: 2.444550973665971

Epoch: 193| Step: 0
Training loss: 2.1291716523930155
Validation loss: 2.4405527035647747

Epoch: 6| Step: 1
Training loss: 2.6901740144793482
Validation loss: 2.4442617730187512

Epoch: 6| Step: 2
Training loss: 2.9105443913243496
Validation loss: 2.454164747485364

Epoch: 6| Step: 3
Training loss: 2.89732648012299
Validation loss: 2.486334361055074

Epoch: 6| Step: 4
Training loss: 2.5949413826556746
Validation loss: 2.482682772215417

Epoch: 6| Step: 5
Training loss: 2.333467229906886
Validation loss: 2.535051817532968

Epoch: 6| Step: 6
Training loss: 3.3553625940443763
Validation loss: 2.5488749943790814

Epoch: 6| Step: 7
Training loss: 2.8071582505342447
Validation loss: 2.5587194654059706

Epoch: 6| Step: 8
Training loss: 2.568735398299769
Validation loss: 2.548818547644919

Epoch: 6| Step: 9
Training loss: 2.656210685887832
Validation loss: 2.5228518946242766

Epoch: 6| Step: 10
Training loss: 2.630201182339959
Validation loss: 2.5098774158518307

Epoch: 6| Step: 11
Training loss: 2.5323492418400164
Validation loss: 2.490510114588096

Epoch: 6| Step: 12
Training loss: 2.7072154941584397
Validation loss: 2.4895443698097597

Epoch: 6| Step: 13
Training loss: 3.122702707837889
Validation loss: 2.492113107471106

Epoch: 194| Step: 0
Training loss: 2.0966837811441175
Validation loss: 2.4736105362997267

Epoch: 6| Step: 1
Training loss: 2.6926021493503787
Validation loss: 2.4807119671268403

Epoch: 6| Step: 2
Training loss: 3.4620825119896
Validation loss: 2.4725200526985223

Epoch: 6| Step: 3
Training loss: 3.1048501988147637
Validation loss: 2.46812848177536

Epoch: 6| Step: 4
Training loss: 2.703185064276905
Validation loss: 2.464330911057342

Epoch: 6| Step: 5
Training loss: 2.7545521945796514
Validation loss: 2.446593110370694

Epoch: 6| Step: 6
Training loss: 2.7634053779140557
Validation loss: 2.4543925847623007

Epoch: 6| Step: 7
Training loss: 2.956004197464829
Validation loss: 2.4466313929430776

Epoch: 6| Step: 8
Training loss: 2.5476606596505267
Validation loss: 2.444803876890163

Epoch: 6| Step: 9
Training loss: 2.4285896985785285
Validation loss: 2.4352624592275336

Epoch: 6| Step: 10
Training loss: 2.459796750115725
Validation loss: 2.4424031598290337

Epoch: 6| Step: 11
Training loss: 2.829552053309445
Validation loss: 2.458654574231936

Epoch: 6| Step: 12
Training loss: 2.413711275395564
Validation loss: 2.468125902686358

Epoch: 6| Step: 13
Training loss: 1.7979867564213257
Validation loss: 2.475486810828224

Epoch: 195| Step: 0
Training loss: 2.984258998993098
Validation loss: 2.5117942806229534

Epoch: 6| Step: 1
Training loss: 2.4429957716191253
Validation loss: 2.5256401147956606

Epoch: 6| Step: 2
Training loss: 2.759209643687591
Validation loss: 2.514942605286768

Epoch: 6| Step: 3
Training loss: 2.7442375844747744
Validation loss: 2.517988949621625

Epoch: 6| Step: 4
Training loss: 2.4627004938754085
Validation loss: 2.5029136967649612

Epoch: 6| Step: 5
Training loss: 2.4591102234599993
Validation loss: 2.5038655042760585

Epoch: 6| Step: 6
Training loss: 2.5601270900412514
Validation loss: 2.522552136302018

Epoch: 6| Step: 7
Training loss: 2.5288956607459023
Validation loss: 2.524633902877997

Epoch: 6| Step: 8
Training loss: 2.3018561088538787
Validation loss: 2.552135062347446

Epoch: 6| Step: 9
Training loss: 2.5601989835653827
Validation loss: 2.600903607787762

Epoch: 6| Step: 10
Training loss: 3.36044337117573
Validation loss: 2.62312483624912

Epoch: 6| Step: 11
Training loss: 3.1018616654560818
Validation loss: 2.626203405682998

Epoch: 6| Step: 12
Training loss: 2.377607620643427
Validation loss: 2.569584662873954

Epoch: 6| Step: 13
Training loss: 3.6107795921802905
Validation loss: 2.5095593845529116

Epoch: 196| Step: 0
Training loss: 2.2292396913730514
Validation loss: 2.4949257041993875

Epoch: 6| Step: 1
Training loss: 2.1585424648381983
Validation loss: 2.4780157914320013

Epoch: 6| Step: 2
Training loss: 3.1758599265700242
Validation loss: 2.463384804415268

Epoch: 6| Step: 3
Training loss: 2.3879681952002296
Validation loss: 2.439617876578381

Epoch: 6| Step: 4
Training loss: 2.8974986239439073
Validation loss: 2.434491706771931

Epoch: 6| Step: 5
Training loss: 2.630782796740679
Validation loss: 2.4491053062010164

Epoch: 6| Step: 6
Training loss: 3.077007420007427
Validation loss: 2.4449262867378696

Epoch: 6| Step: 7
Training loss: 2.540241613235497
Validation loss: 2.4707574072750362

Epoch: 6| Step: 8
Training loss: 2.9797237560064818
Validation loss: 2.5170771588858396

Epoch: 6| Step: 9
Training loss: 3.0186821655486624
Validation loss: 2.5606790420902286

Epoch: 6| Step: 10
Training loss: 3.1002197433851992
Validation loss: 2.5462351617551873

Epoch: 6| Step: 11
Training loss: 1.8337365776252066
Validation loss: 2.498709255205327

Epoch: 6| Step: 12
Training loss: 2.8967243900261654
Validation loss: 2.441893579554233

Epoch: 6| Step: 13
Training loss: 2.618984231966202
Validation loss: 2.4301980900648257

Epoch: 197| Step: 0
Training loss: 2.8541565683747754
Validation loss: 2.4215820148513014

Epoch: 6| Step: 1
Training loss: 2.587397690376666
Validation loss: 2.42913962960748

Epoch: 6| Step: 2
Training loss: 3.0363514239606055
Validation loss: 2.432765485475883

Epoch: 6| Step: 3
Training loss: 2.880447699664149
Validation loss: 2.4312710301873413

Epoch: 6| Step: 4
Training loss: 3.3991668970759945
Validation loss: 2.4335712294938174

Epoch: 6| Step: 5
Training loss: 2.001843437353321
Validation loss: 2.435405012852148

Epoch: 6| Step: 6
Training loss: 2.595387872362783
Validation loss: 2.4561949958519778

Epoch: 6| Step: 7
Training loss: 2.4648278866119875
Validation loss: 2.473032953650488

Epoch: 6| Step: 8
Training loss: 2.6344599337931163
Validation loss: 2.482554294774101

Epoch: 6| Step: 9
Training loss: 2.750941895526155
Validation loss: 2.507306349650789

Epoch: 6| Step: 10
Training loss: 2.595732149833021
Validation loss: 2.5342955665445164

Epoch: 6| Step: 11
Training loss: 2.533171689581842
Validation loss: 2.5098608544826813

Epoch: 6| Step: 12
Training loss: 2.6197252410496277
Validation loss: 2.515916081273566

Epoch: 6| Step: 13
Training loss: 2.4826920285054572
Validation loss: 2.509113405617569

Epoch: 198| Step: 0
Training loss: 2.9176289923622494
Validation loss: 2.5030309889730322

Epoch: 6| Step: 1
Training loss: 2.43513579520629
Validation loss: 2.4886077652721874

Epoch: 6| Step: 2
Training loss: 2.572125940143528
Validation loss: 2.452621810698021

Epoch: 6| Step: 3
Training loss: 2.427760301299617
Validation loss: 2.4369761564319465

Epoch: 6| Step: 4
Training loss: 1.8606142674586015
Validation loss: 2.4264920918626096

Epoch: 6| Step: 5
Training loss: 2.7754356385996037
Validation loss: 2.4266130922328246

Epoch: 6| Step: 6
Training loss: 3.0673742625139515
Validation loss: 2.4271136588340543

Epoch: 6| Step: 7
Training loss: 1.9144031455087864
Validation loss: 2.4258175434160276

Epoch: 6| Step: 8
Training loss: 3.1244909253317523
Validation loss: 2.4355439898397035

Epoch: 6| Step: 9
Training loss: 2.7984583118544495
Validation loss: 2.4324891078613087

Epoch: 6| Step: 10
Training loss: 2.6940872724708553
Validation loss: 2.4400894776237267

Epoch: 6| Step: 11
Training loss: 2.761387310076444
Validation loss: 2.4578138521781097

Epoch: 6| Step: 12
Training loss: 2.8746299505501742
Validation loss: 2.482332886199181

Epoch: 6| Step: 13
Training loss: 2.9631820666135082
Validation loss: 2.48024467558816

Epoch: 199| Step: 0
Training loss: 3.18586928597201
Validation loss: 2.4911506093589924

Epoch: 6| Step: 1
Training loss: 2.2924242559169126
Validation loss: 2.504140149326358

Epoch: 6| Step: 2
Training loss: 2.9291425274378375
Validation loss: 2.5150328841023137

Epoch: 6| Step: 3
Training loss: 2.369211269750009
Validation loss: 2.523345477243115

Epoch: 6| Step: 4
Training loss: 2.691222606755173
Validation loss: 2.524352223548964

Epoch: 6| Step: 5
Training loss: 1.9441798332848768
Validation loss: 2.501629719672017

Epoch: 6| Step: 6
Training loss: 3.4678967775428933
Validation loss: 2.4879417538773803

Epoch: 6| Step: 7
Training loss: 2.6045366761878057
Validation loss: 2.4706310864342425

Epoch: 6| Step: 8
Training loss: 2.6006499285100215
Validation loss: 2.455192990642986

Epoch: 6| Step: 9
Training loss: 3.134941766371433
Validation loss: 2.4380587822642967

Epoch: 6| Step: 10
Training loss: 2.3338923352341254
Validation loss: 2.4357976066901617

Epoch: 6| Step: 11
Training loss: 2.438841817233103
Validation loss: 2.4478568857643674

Epoch: 6| Step: 12
Training loss: 2.584632290598839
Validation loss: 2.452892146369549

Epoch: 6| Step: 13
Training loss: 2.049990546972298
Validation loss: 2.4497469191418473

Epoch: 200| Step: 0
Training loss: 2.1595735229567685
Validation loss: 2.429532041925554

Epoch: 6| Step: 1
Training loss: 3.121188318684234
Validation loss: 2.4198931060386366

Epoch: 6| Step: 2
Training loss: 2.566882038575863
Validation loss: 2.4131881670898356

Epoch: 6| Step: 3
Training loss: 2.975539144179986
Validation loss: 2.410358611324256

Epoch: 6| Step: 4
Training loss: 2.853356202232958
Validation loss: 2.4084906765713967

Epoch: 6| Step: 5
Training loss: 2.714480061492798
Validation loss: 2.4120413944130137

Epoch: 6| Step: 6
Training loss: 3.149687639522767
Validation loss: 2.4055656575446775

Epoch: 6| Step: 7
Training loss: 2.6926287129557505
Validation loss: 2.4265803636700882

Epoch: 6| Step: 8
Training loss: 2.432436746086557
Validation loss: 2.4318914263109614

Epoch: 6| Step: 9
Training loss: 1.9895050539392098
Validation loss: 2.4410289621529584

Epoch: 6| Step: 10
Training loss: 2.343296057927828
Validation loss: 2.445670614210188

Epoch: 6| Step: 11
Training loss: 2.0021810560031943
Validation loss: 2.465185954962317

Epoch: 6| Step: 12
Training loss: 3.249457534120464
Validation loss: 2.4658819122076596

Epoch: 6| Step: 13
Training loss: 2.345595383532094
Validation loss: 2.475263726088514

Epoch: 201| Step: 0
Training loss: 2.3865202526205835
Validation loss: 2.4817942100964543

Epoch: 6| Step: 1
Training loss: 2.357167404839647
Validation loss: 2.4626299472184217

Epoch: 6| Step: 2
Training loss: 2.4501237915839464
Validation loss: 2.453290077488167

Epoch: 6| Step: 3
Training loss: 2.9993635138204087
Validation loss: 2.4544585290933747

Epoch: 6| Step: 4
Training loss: 2.3731800936757925
Validation loss: 2.438928352327763

Epoch: 6| Step: 5
Training loss: 2.722485836612231
Validation loss: 2.4210229280473

Epoch: 6| Step: 6
Training loss: 2.28052519688887
Validation loss: 2.4156729425252874

Epoch: 6| Step: 7
Training loss: 2.9881631665803363
Validation loss: 2.421704260675576

Epoch: 6| Step: 8
Training loss: 2.108220328316818
Validation loss: 2.4329365823481957

Epoch: 6| Step: 9
Training loss: 2.8819006327984695
Validation loss: 2.444496027651429

Epoch: 6| Step: 10
Training loss: 2.5237470029574127
Validation loss: 2.447937319181233

Epoch: 6| Step: 11
Training loss: 3.122076879929361
Validation loss: 2.4653135510170188

Epoch: 6| Step: 12
Training loss: 2.475342266422464
Validation loss: 2.4780798025866178

Epoch: 6| Step: 13
Training loss: 3.3509927901210648
Validation loss: 2.498033937957922

Epoch: 202| Step: 0
Training loss: 2.805722611450748
Validation loss: 2.516024528831921

Epoch: 6| Step: 1
Training loss: 2.6584962210980803
Validation loss: 2.524929588795741

Epoch: 6| Step: 2
Training loss: 2.3163394500209566
Validation loss: 2.500085042717077

Epoch: 6| Step: 3
Training loss: 2.4745470383883457
Validation loss: 2.4776197615614275

Epoch: 6| Step: 4
Training loss: 2.8054267950275054
Validation loss: 2.4663721224134414

Epoch: 6| Step: 5
Training loss: 2.3904345068737674
Validation loss: 2.4531695083166047

Epoch: 6| Step: 6
Training loss: 3.3162708052619903
Validation loss: 2.4306594892821605

Epoch: 6| Step: 7
Training loss: 2.431879067124667
Validation loss: 2.4345400739148597

Epoch: 6| Step: 8
Training loss: 1.7767384598822724
Validation loss: 2.4256498379699742

Epoch: 6| Step: 9
Training loss: 2.803342363824561
Validation loss: 2.426921884179899

Epoch: 6| Step: 10
Training loss: 3.149210113309138
Validation loss: 2.421230939477242

Epoch: 6| Step: 11
Training loss: 2.4178788225401786
Validation loss: 2.4211454257833913

Epoch: 6| Step: 12
Training loss: 2.4761695911152013
Validation loss: 2.4296347180392344

Epoch: 6| Step: 13
Training loss: 2.9016017042232334
Validation loss: 2.4341162308665374

Epoch: 203| Step: 0
Training loss: 2.8088780287121553
Validation loss: 2.458856381696358

Epoch: 6| Step: 1
Training loss: 2.623230201296745
Validation loss: 2.457487548640353

Epoch: 6| Step: 2
Training loss: 2.4798969721158923
Validation loss: 2.425082403376498

Epoch: 6| Step: 3
Training loss: 2.383906379135137
Validation loss: 2.4231267831956678

Epoch: 6| Step: 4
Training loss: 2.232924303868777
Validation loss: 2.4311991898146115

Epoch: 6| Step: 5
Training loss: 1.966327023946716
Validation loss: 2.4289469515422044

Epoch: 6| Step: 6
Training loss: 2.864993053381256
Validation loss: 2.436802289090127

Epoch: 6| Step: 7
Training loss: 2.739073982802246
Validation loss: 2.443178116268928

Epoch: 6| Step: 8
Training loss: 3.2135723654559984
Validation loss: 2.4365976770672786

Epoch: 6| Step: 9
Training loss: 3.0332413257715998
Validation loss: 2.441973020989782

Epoch: 6| Step: 10
Training loss: 2.661014726451105
Validation loss: 2.4549779713356235

Epoch: 6| Step: 11
Training loss: 2.3964595031691207
Validation loss: 2.4611158580770205

Epoch: 6| Step: 12
Training loss: 2.5372502359075733
Validation loss: 2.4749243616466585

Epoch: 6| Step: 13
Training loss: 2.9681326776446584
Validation loss: 2.4998607114731017

Epoch: 204| Step: 0
Training loss: 2.5334275851368004
Validation loss: 2.514680351184639

Epoch: 6| Step: 1
Training loss: 2.146495926663639
Validation loss: 2.529381472918494

Epoch: 6| Step: 2
Training loss: 2.4718105804498407
Validation loss: 2.536795250866864

Epoch: 6| Step: 3
Training loss: 2.5616670510815656
Validation loss: 2.5353188727289013

Epoch: 6| Step: 4
Training loss: 3.0147627946908115
Validation loss: 2.502137011159143

Epoch: 6| Step: 5
Training loss: 2.724068186619337
Validation loss: 2.481054835301315

Epoch: 6| Step: 6
Training loss: 2.297133969609678
Validation loss: 2.466671186942981

Epoch: 6| Step: 7
Training loss: 2.5618668681208994
Validation loss: 2.467465947487613

Epoch: 6| Step: 8
Training loss: 2.661045368402755
Validation loss: 2.4652998505044774

Epoch: 6| Step: 9
Training loss: 3.2944095305947374
Validation loss: 2.464988762344996

Epoch: 6| Step: 10
Training loss: 2.9295680314182855
Validation loss: 2.464316927320401

Epoch: 6| Step: 11
Training loss: 2.5698635091791444
Validation loss: 2.4676442752304117

Epoch: 6| Step: 12
Training loss: 2.5189526270538134
Validation loss: 2.464716428143229

Epoch: 6| Step: 13
Training loss: 2.0309467969694235
Validation loss: 2.4504765764648515

Epoch: 205| Step: 0
Training loss: 2.7342061889855196
Validation loss: 2.4524125584599847

Epoch: 6| Step: 1
Training loss: 2.0815313429734865
Validation loss: 2.457401553378153

Epoch: 6| Step: 2
Training loss: 2.50556345832896
Validation loss: 2.4575994382291473

Epoch: 6| Step: 3
Training loss: 2.633877864100161
Validation loss: 2.455851484827114

Epoch: 6| Step: 4
Training loss: 2.7985792881303015
Validation loss: 2.436862920147355

Epoch: 6| Step: 5
Training loss: 2.418010754443817
Validation loss: 2.4293435585992795

Epoch: 6| Step: 6
Training loss: 3.003339498205205
Validation loss: 2.4414183918968906

Epoch: 6| Step: 7
Training loss: 2.4832887974101547
Validation loss: 2.4607676624369073

Epoch: 6| Step: 8
Training loss: 2.698465554114175
Validation loss: 2.4918192600638784

Epoch: 6| Step: 9
Training loss: 1.8885686110439848
Validation loss: 2.5047726226150173

Epoch: 6| Step: 10
Training loss: 2.7980071605402603
Validation loss: 2.531603275157751

Epoch: 6| Step: 11
Training loss: 2.547290417077155
Validation loss: 2.5605073930497886

Epoch: 6| Step: 12
Training loss: 3.26675322541238
Validation loss: 2.5536976098436117

Epoch: 6| Step: 13
Training loss: 2.6054476118016683
Validation loss: 2.5403983147018336

Epoch: 206| Step: 0
Training loss: 2.516186669240116
Validation loss: 2.4883108169638852

Epoch: 6| Step: 1
Training loss: 2.4355515737725324
Validation loss: 2.4470276575586163

Epoch: 6| Step: 2
Training loss: 2.7682865934734315
Validation loss: 2.41859298971873

Epoch: 6| Step: 3
Training loss: 2.4718284245671356
Validation loss: 2.40128506071964

Epoch: 6| Step: 4
Training loss: 2.1255266995400843
Validation loss: 2.3932658491093224

Epoch: 6| Step: 5
Training loss: 2.129466803710034
Validation loss: 2.405744230176262

Epoch: 6| Step: 6
Training loss: 2.537852213050564
Validation loss: 2.3996250432233084

Epoch: 6| Step: 7
Training loss: 3.1593229234820024
Validation loss: 2.4050642175385306

Epoch: 6| Step: 8
Training loss: 2.4422332583660067
Validation loss: 2.404452420236496

Epoch: 6| Step: 9
Training loss: 2.9563921259130432
Validation loss: 2.400605446620255

Epoch: 6| Step: 10
Training loss: 2.8013548536307735
Validation loss: 2.4102472292879615

Epoch: 6| Step: 11
Training loss: 2.9516486458755096
Validation loss: 2.432504307925895

Epoch: 6| Step: 12
Training loss: 2.780563183965729
Validation loss: 2.4612503678451403

Epoch: 6| Step: 13
Training loss: 2.4568768621072286
Validation loss: 2.493065153502934

Epoch: 207| Step: 0
Training loss: 3.148865171403149
Validation loss: 2.5475508478070186

Epoch: 6| Step: 1
Training loss: 2.1980946786636895
Validation loss: 2.564278708344325

Epoch: 6| Step: 2
Training loss: 2.6663420201413737
Validation loss: 2.556578843561591

Epoch: 6| Step: 3
Training loss: 2.551276773688883
Validation loss: 2.5167943964702175

Epoch: 6| Step: 4
Training loss: 3.1093878817650875
Validation loss: 2.477751605072853

Epoch: 6| Step: 5
Training loss: 2.2745596616731114
Validation loss: 2.4449598329403144

Epoch: 6| Step: 6
Training loss: 2.2773309775987243
Validation loss: 2.4261220033114492

Epoch: 6| Step: 7
Training loss: 2.9343834435094673
Validation loss: 2.4163556027809396

Epoch: 6| Step: 8
Training loss: 2.8447585780145737
Validation loss: 2.424303412558811

Epoch: 6| Step: 9
Training loss: 3.0513716943235454
Validation loss: 2.4130666327170243

Epoch: 6| Step: 10
Training loss: 1.347329008757685
Validation loss: 2.4275096825333837

Epoch: 6| Step: 11
Training loss: 3.10272256598494
Validation loss: 2.434115138685358

Epoch: 6| Step: 12
Training loss: 2.3679449802012407
Validation loss: 2.460115134973651

Epoch: 6| Step: 13
Training loss: 1.8343465851592697
Validation loss: 2.464571403935213

Epoch: 208| Step: 0
Training loss: 2.7366644293914955
Validation loss: 2.486900384951513

Epoch: 6| Step: 1
Training loss: 2.432111506082984
Validation loss: 2.485694443554146

Epoch: 6| Step: 2
Training loss: 2.898817340813807
Validation loss: 2.507610161715327

Epoch: 6| Step: 3
Training loss: 2.7776098539669842
Validation loss: 2.5035300937340903

Epoch: 6| Step: 4
Training loss: 2.100098734759808
Validation loss: 2.5237138843746223

Epoch: 6| Step: 5
Training loss: 2.7734436894737273
Validation loss: 2.496373450294265

Epoch: 6| Step: 6
Training loss: 3.0517468749803998
Validation loss: 2.4694399499767123

Epoch: 6| Step: 7
Training loss: 2.4282593286147165
Validation loss: 2.452017845766505

Epoch: 6| Step: 8
Training loss: 2.0316463377229934
Validation loss: 2.4294132969130398

Epoch: 6| Step: 9
Training loss: 2.86741766148745
Validation loss: 2.398372975153165

Epoch: 6| Step: 10
Training loss: 2.5959460601904296
Validation loss: 2.3942436783375056

Epoch: 6| Step: 11
Training loss: 2.3613792142555305
Validation loss: 2.4026027494141258

Epoch: 6| Step: 12
Training loss: 2.796278479699233
Validation loss: 2.4061713566078917

Epoch: 6| Step: 13
Training loss: 2.562411143925564
Validation loss: 2.4189244340046434

Epoch: 209| Step: 0
Training loss: 2.4622872662512325
Validation loss: 2.4208959701161428

Epoch: 6| Step: 1
Training loss: 2.5422394112396374
Validation loss: 2.4241626363208844

Epoch: 6| Step: 2
Training loss: 2.3596948065863756
Validation loss: 2.4557002203997484

Epoch: 6| Step: 3
Training loss: 3.093755856903389
Validation loss: 2.4819168856846496

Epoch: 6| Step: 4
Training loss: 2.8303347221817075
Validation loss: 2.5141708297352685

Epoch: 6| Step: 5
Training loss: 2.653319593646388
Validation loss: 2.5177609493996047

Epoch: 6| Step: 6
Training loss: 2.528828816941607
Validation loss: 2.5209019942370925

Epoch: 6| Step: 7
Training loss: 2.296845520245554
Validation loss: 2.5457205854695175

Epoch: 6| Step: 8
Training loss: 2.32765520719464
Validation loss: 2.562897159943513

Epoch: 6| Step: 9
Training loss: 2.2984889581600543
Validation loss: 2.570366041100403

Epoch: 6| Step: 10
Training loss: 3.346892261905838
Validation loss: 2.5723023362276565

Epoch: 6| Step: 11
Training loss: 2.640203679348399
Validation loss: 2.583105486753307

Epoch: 6| Step: 12
Training loss: 2.9380901636632006
Validation loss: 2.5756839674942715

Epoch: 6| Step: 13
Training loss: 2.1049569663317684
Validation loss: 2.5584035805715253

Epoch: 210| Step: 0
Training loss: 2.792779065073182
Validation loss: 2.562888237340362

Epoch: 6| Step: 1
Training loss: 2.214129728105573
Validation loss: 2.5394618949681473

Epoch: 6| Step: 2
Training loss: 3.0248693579844956
Validation loss: 2.522894990944983

Epoch: 6| Step: 3
Training loss: 3.1518458997845644
Validation loss: 2.5127752385653124

Epoch: 6| Step: 4
Training loss: 2.401513627696085
Validation loss: 2.4607508221185452

Epoch: 6| Step: 5
Training loss: 2.4056235154291787
Validation loss: 2.447648424380922

Epoch: 6| Step: 6
Training loss: 2.340920125896575
Validation loss: 2.447918397112575

Epoch: 6| Step: 7
Training loss: 1.9636728123210538
Validation loss: 2.4296148161562354

Epoch: 6| Step: 8
Training loss: 2.3165484894540196
Validation loss: 2.4263842239205275

Epoch: 6| Step: 9
Training loss: 2.577255009756493
Validation loss: 2.429156328666625

Epoch: 6| Step: 10
Training loss: 2.6155125966411394
Validation loss: 2.4240152048948365

Epoch: 6| Step: 11
Training loss: 3.5037426692410993
Validation loss: 2.423938095045162

Epoch: 6| Step: 12
Training loss: 2.1998372537931687
Validation loss: 2.425925107372076

Epoch: 6| Step: 13
Training loss: 2.672117344980695
Validation loss: 2.4303966023337162

Epoch: 211| Step: 0
Training loss: 2.7788188466935475
Validation loss: 2.4738222743877096

Epoch: 6| Step: 1
Training loss: 2.529538553246105
Validation loss: 2.5143020270535494

Epoch: 6| Step: 2
Training loss: 2.404824763712533
Validation loss: 2.543737834139315

Epoch: 6| Step: 3
Training loss: 2.413376695320655
Validation loss: 2.609527862435479

Epoch: 6| Step: 4
Training loss: 2.6255053079261224
Validation loss: 2.5511909021114163

Epoch: 6| Step: 5
Training loss: 2.2445689457437625
Validation loss: 2.516796460180231

Epoch: 6| Step: 6
Training loss: 2.18074802863983
Validation loss: 2.484136987296484

Epoch: 6| Step: 7
Training loss: 2.5326531371260423
Validation loss: 2.4381896821512417

Epoch: 6| Step: 8
Training loss: 2.538086876863524
Validation loss: 2.4025671926292764

Epoch: 6| Step: 9
Training loss: 2.6918011335517216
Validation loss: 2.381629335674379

Epoch: 6| Step: 10
Training loss: 2.460241697734837
Validation loss: 2.3766944358839637

Epoch: 6| Step: 11
Training loss: 3.0937772807450123
Validation loss: 2.381754953618721

Epoch: 6| Step: 12
Training loss: 3.2049242874224584
Validation loss: 2.403457925606178

Epoch: 6| Step: 13
Training loss: 2.4305773513058893
Validation loss: 2.4198234498560827

Epoch: 212| Step: 0
Training loss: 2.8830007269385693
Validation loss: 2.4768405006618908

Epoch: 6| Step: 1
Training loss: 3.2702052653338125
Validation loss: 2.5219302572701148

Epoch: 6| Step: 2
Training loss: 2.7371386703245304
Validation loss: 2.4832351958225587

Epoch: 6| Step: 3
Training loss: 2.6101168189086117
Validation loss: 2.4775449626537935

Epoch: 6| Step: 4
Training loss: 2.4345641428735
Validation loss: 2.476905471635724

Epoch: 6| Step: 5
Training loss: 2.733771731722411
Validation loss: 2.488168824743175

Epoch: 6| Step: 6
Training loss: 1.552593872623129
Validation loss: 2.5075286192406807

Epoch: 6| Step: 7
Training loss: 3.145926636244839
Validation loss: 2.516132433746748

Epoch: 6| Step: 8
Training loss: 3.0998096653742873
Validation loss: 2.509500188091202

Epoch: 6| Step: 9
Training loss: 2.011728349681283
Validation loss: 2.4807242731734

Epoch: 6| Step: 10
Training loss: 2.1492678615515195
Validation loss: 2.430942872786461

Epoch: 6| Step: 11
Training loss: 1.60468230279157
Validation loss: 2.4234130929233673

Epoch: 6| Step: 12
Training loss: 2.838826875036275
Validation loss: 2.411868207783174

Epoch: 6| Step: 13
Training loss: 2.3620437787074393
Validation loss: 2.4382527390451463

Epoch: 213| Step: 0
Training loss: 2.77569711537811
Validation loss: 2.443140552936005

Epoch: 6| Step: 1
Training loss: 2.4837630375912063
Validation loss: 2.4237959765266512

Epoch: 6| Step: 2
Training loss: 2.9044206665993366
Validation loss: 2.419104339251229

Epoch: 6| Step: 3
Training loss: 2.63854212127774
Validation loss: 2.422862494855782

Epoch: 6| Step: 4
Training loss: 3.074439616430631
Validation loss: 2.4402008091784984

Epoch: 6| Step: 5
Training loss: 2.852504125353064
Validation loss: 2.425040327962499

Epoch: 6| Step: 6
Training loss: 2.1750173546109663
Validation loss: 2.442721433600244

Epoch: 6| Step: 7
Training loss: 2.418416365449673
Validation loss: 2.450494423191798

Epoch: 6| Step: 8
Training loss: 2.1875786903396692
Validation loss: 2.4990012737616714

Epoch: 6| Step: 9
Training loss: 2.327392155559105
Validation loss: 2.5146580134829803

Epoch: 6| Step: 10
Training loss: 2.8728165005784994
Validation loss: 2.508687450396953

Epoch: 6| Step: 11
Training loss: 2.424931818210056
Validation loss: 2.507667795705727

Epoch: 6| Step: 12
Training loss: 2.3568520098171626
Validation loss: 2.5093249513511324

Epoch: 6| Step: 13
Training loss: 2.12228770224373
Validation loss: 2.4954548963634773

Epoch: 214| Step: 0
Training loss: 2.446486413727346
Validation loss: 2.5150405030495757

Epoch: 6| Step: 1
Training loss: 2.0147774267207863
Validation loss: 2.5362581007797407

Epoch: 6| Step: 2
Training loss: 3.0771114016634287
Validation loss: 2.5419412246418776

Epoch: 6| Step: 3
Training loss: 2.7031382301315503
Validation loss: 2.509936994611538

Epoch: 6| Step: 4
Training loss: 2.540998548234797
Validation loss: 2.463975951127012

Epoch: 6| Step: 5
Training loss: 2.704523948339133
Validation loss: 2.427966187598828

Epoch: 6| Step: 6
Training loss: 2.765307650704647
Validation loss: 2.4028445595796093

Epoch: 6| Step: 7
Training loss: 2.991151475953635
Validation loss: 2.38733937760935

Epoch: 6| Step: 8
Training loss: 1.7423721694578473
Validation loss: 2.3922916570174655

Epoch: 6| Step: 9
Training loss: 2.6928129686184965
Validation loss: 2.399224132571433

Epoch: 6| Step: 10
Training loss: 2.777979610316107
Validation loss: 2.429054818081096

Epoch: 6| Step: 11
Training loss: 2.5491251922189835
Validation loss: 2.4784072439447002

Epoch: 6| Step: 12
Training loss: 2.218591818745198
Validation loss: 2.5417115099773944

Epoch: 6| Step: 13
Training loss: 2.1384842463714246
Validation loss: 2.6229641056456625

Epoch: 215| Step: 0
Training loss: 2.517502457315407
Validation loss: 2.8091095253355354

Epoch: 6| Step: 1
Training loss: 2.7376232798787674
Validation loss: 2.8526568816693896

Epoch: 6| Step: 2
Training loss: 3.086302607703256
Validation loss: 2.8520986239851567

Epoch: 6| Step: 3
Training loss: 2.609298065330558
Validation loss: 2.759074086195869

Epoch: 6| Step: 4
Training loss: 3.1469044325057314
Validation loss: 2.6659475543899074

Epoch: 6| Step: 5
Training loss: 2.836379003705452
Validation loss: 2.5716370985365087

Epoch: 6| Step: 6
Training loss: 2.6206354459722236
Validation loss: 2.48574768683621

Epoch: 6| Step: 7
Training loss: 2.1877182987825194
Validation loss: 2.487623933617374

Epoch: 6| Step: 8
Training loss: 2.5496958457715744
Validation loss: 2.5020532667001727

Epoch: 6| Step: 9
Training loss: 2.830177026340799
Validation loss: 2.5443203175714033

Epoch: 6| Step: 10
Training loss: 2.8639846083584426
Validation loss: 2.54922119298195

Epoch: 6| Step: 11
Training loss: 2.741444718054858
Validation loss: 2.5682991641194843

Epoch: 6| Step: 12
Training loss: 2.1426365443622424
Validation loss: 2.5938168786533877

Epoch: 6| Step: 13
Training loss: 2.6073121465675473
Validation loss: 2.6013218351641103

Epoch: 216| Step: 0
Training loss: 2.6670884653129563
Validation loss: 2.5964531376626643

Epoch: 6| Step: 1
Training loss: 2.8640012577416414
Validation loss: 2.5645268535731587

Epoch: 6| Step: 2
Training loss: 2.422610361992604
Validation loss: 2.4883251490569394

Epoch: 6| Step: 3
Training loss: 2.3185235007984892
Validation loss: 2.450224991680867

Epoch: 6| Step: 4
Training loss: 3.1070056878741665
Validation loss: 2.439390283049046

Epoch: 6| Step: 5
Training loss: 2.7019147864965634
Validation loss: 2.4416380791308447

Epoch: 6| Step: 6
Training loss: 2.3070692266586756
Validation loss: 2.4248712123412632

Epoch: 6| Step: 7
Training loss: 2.6045872971655046
Validation loss: 2.4207728423498316

Epoch: 6| Step: 8
Training loss: 2.008750844692962
Validation loss: 2.4148066968833333

Epoch: 6| Step: 9
Training loss: 2.9402524349285923
Validation loss: 2.4242679350651275

Epoch: 6| Step: 10
Training loss: 2.545013121625428
Validation loss: 2.4239153663724844

Epoch: 6| Step: 11
Training loss: 2.255485100681934
Validation loss: 2.4317074931192453

Epoch: 6| Step: 12
Training loss: 2.01100385981739
Validation loss: 2.442319148459464

Epoch: 6| Step: 13
Training loss: 3.299455979327726
Validation loss: 2.4549245071407597

Epoch: 217| Step: 0
Training loss: 2.9806752864525587
Validation loss: 2.4401075741996054

Epoch: 6| Step: 1
Training loss: 1.873460073708904
Validation loss: 2.434372320659044

Epoch: 6| Step: 2
Training loss: 2.8159948040524143
Validation loss: 2.4285345635055235

Epoch: 6| Step: 3
Training loss: 2.851820006566599
Validation loss: 2.4284834196712044

Epoch: 6| Step: 4
Training loss: 2.333783129072297
Validation loss: 2.4256182600594736

Epoch: 6| Step: 5
Training loss: 2.6520922264874973
Validation loss: 2.417675597656832

Epoch: 6| Step: 6
Training loss: 2.4768588974780856
Validation loss: 2.42304303348276

Epoch: 6| Step: 7
Training loss: 2.328976878541573
Validation loss: 2.426052898462579

Epoch: 6| Step: 8
Training loss: 2.365584230260627
Validation loss: 2.4244381311508496

Epoch: 6| Step: 9
Training loss: 2.1421052590018332
Validation loss: 2.443972531855995

Epoch: 6| Step: 10
Training loss: 2.775456255271691
Validation loss: 2.452395763736218

Epoch: 6| Step: 11
Training loss: 2.8485278560434115
Validation loss: 2.4792813069230997

Epoch: 6| Step: 12
Training loss: 2.203190795781697
Validation loss: 2.4781765072556197

Epoch: 6| Step: 13
Training loss: 2.8221476916319936
Validation loss: 2.46502670410737

Epoch: 218| Step: 0
Training loss: 2.884846948963725
Validation loss: 2.461864705514414

Epoch: 6| Step: 1
Training loss: 2.7530271168518894
Validation loss: 2.461160572917035

Epoch: 6| Step: 2
Training loss: 2.6799067193494
Validation loss: 2.4532261724322706

Epoch: 6| Step: 3
Training loss: 2.7997534234603116
Validation loss: 2.4561163442506957

Epoch: 6| Step: 4
Training loss: 2.184678137705564
Validation loss: 2.4755884560030985

Epoch: 6| Step: 5
Training loss: 2.511556617167001
Validation loss: 2.499981262793107

Epoch: 6| Step: 6
Training loss: 2.5233868573188403
Validation loss: 2.4920697123467788

Epoch: 6| Step: 7
Training loss: 2.6532949727926
Validation loss: 2.5318555220322163

Epoch: 6| Step: 8
Training loss: 2.359464833147263
Validation loss: 2.567040267632019

Epoch: 6| Step: 9
Training loss: 1.9932167535944736
Validation loss: 2.576053341658287

Epoch: 6| Step: 10
Training loss: 2.941705169281673
Validation loss: 2.5584478586412516

Epoch: 6| Step: 11
Training loss: 2.647557295196396
Validation loss: 2.5523554158198163

Epoch: 6| Step: 12
Training loss: 2.22720231350088
Validation loss: 2.4956936889638723

Epoch: 6| Step: 13
Training loss: 2.079077022151437
Validation loss: 2.4572672314640824

Epoch: 219| Step: 0
Training loss: 2.535709361910117
Validation loss: 2.4421521583989416

Epoch: 6| Step: 1
Training loss: 2.5573542963401215
Validation loss: 2.412093329537135

Epoch: 6| Step: 2
Training loss: 2.1693104484271664
Validation loss: 2.411135215447245

Epoch: 6| Step: 3
Training loss: 2.665389102636035
Validation loss: 2.402941022062373

Epoch: 6| Step: 4
Training loss: 2.686499653429797
Validation loss: 2.406922678790683

Epoch: 6| Step: 5
Training loss: 1.859868921665443
Validation loss: 2.4431412056140758

Epoch: 6| Step: 6
Training loss: 2.6924047735547947
Validation loss: 2.457369988096205

Epoch: 6| Step: 7
Training loss: 2.662861752000301
Validation loss: 2.4775850878797914

Epoch: 6| Step: 8
Training loss: 2.832494574168733
Validation loss: 2.4849132053673144

Epoch: 6| Step: 9
Training loss: 2.787835543156381
Validation loss: 2.489712388506331

Epoch: 6| Step: 10
Training loss: 2.508396734236944
Validation loss: 2.5289823805916605

Epoch: 6| Step: 11
Training loss: 2.287156180302719
Validation loss: 2.5558296824641227

Epoch: 6| Step: 12
Training loss: 2.105790094259526
Validation loss: 2.56394478370839

Epoch: 6| Step: 13
Training loss: 3.2477532470254653
Validation loss: 2.522546318551998

Epoch: 220| Step: 0
Training loss: 2.442730109816534
Validation loss: 2.4931768068200815

Epoch: 6| Step: 1
Training loss: 2.927766785750806
Validation loss: 2.467089194976057

Epoch: 6| Step: 2
Training loss: 2.6021342980855997
Validation loss: 2.4257781196647885

Epoch: 6| Step: 3
Training loss: 3.0050868776174857
Validation loss: 2.404962089263141

Epoch: 6| Step: 4
Training loss: 2.488974482146878
Validation loss: 2.401210681178088

Epoch: 6| Step: 5
Training loss: 2.5738345425297515
Validation loss: 2.4019128999510517

Epoch: 6| Step: 6
Training loss: 2.2806869229968325
Validation loss: 2.396116944192929

Epoch: 6| Step: 7
Training loss: 2.3718561144090753
Validation loss: 2.3896676761385094

Epoch: 6| Step: 8
Training loss: 2.3819223210747307
Validation loss: 2.395206161382002

Epoch: 6| Step: 9
Training loss: 3.0166012463580283
Validation loss: 2.416448241332071

Epoch: 6| Step: 10
Training loss: 2.299346631998323
Validation loss: 2.4545545517757112

Epoch: 6| Step: 11
Training loss: 2.588053687374532
Validation loss: 2.487085019159892

Epoch: 6| Step: 12
Training loss: 2.3230018315006284
Validation loss: 2.535453756303801

Epoch: 6| Step: 13
Training loss: 1.9270931209281288
Validation loss: 2.6199154184956317

Epoch: 221| Step: 0
Training loss: 2.175749143298512
Validation loss: 2.6500707617669104

Epoch: 6| Step: 1
Training loss: 3.0198571743570297
Validation loss: 2.642209075889901

Epoch: 6| Step: 2
Training loss: 2.4972687106484144
Validation loss: 2.6491876219222736

Epoch: 6| Step: 3
Training loss: 3.167626151904991
Validation loss: 2.6379767396011435

Epoch: 6| Step: 4
Training loss: 2.357301824336826
Validation loss: 2.5768493280561637

Epoch: 6| Step: 5
Training loss: 2.5434551096202425
Validation loss: 2.5094186472681135

Epoch: 6| Step: 6
Training loss: 2.8149923513522
Validation loss: 2.4570247997575736

Epoch: 6| Step: 7
Training loss: 2.710951395576329
Validation loss: 2.4462035046300143

Epoch: 6| Step: 8
Training loss: 2.083903832206459
Validation loss: 2.4396973385244407

Epoch: 6| Step: 9
Training loss: 2.4359160925785206
Validation loss: 2.436760678008009

Epoch: 6| Step: 10
Training loss: 2.3548762397076413
Validation loss: 2.458900055409749

Epoch: 6| Step: 11
Training loss: 1.849300112946885
Validation loss: 2.4686745252659823

Epoch: 6| Step: 12
Training loss: 2.4119431164235183
Validation loss: 2.507804007035528

Epoch: 6| Step: 13
Training loss: 2.8183388183859206
Validation loss: 2.489442558151132

Epoch: 222| Step: 0
Training loss: 2.901426845618982
Validation loss: 2.5079390967586703

Epoch: 6| Step: 1
Training loss: 2.2217833509469194
Validation loss: 2.4872802569295454

Epoch: 6| Step: 2
Training loss: 2.6959830956424313
Validation loss: 2.4555852719952016

Epoch: 6| Step: 3
Training loss: 2.088375424232104
Validation loss: 2.4363652025958995

Epoch: 6| Step: 4
Training loss: 2.7095828670677484
Validation loss: 2.4348594228932825

Epoch: 6| Step: 5
Training loss: 2.614068749437996
Validation loss: 2.43000678512819

Epoch: 6| Step: 6
Training loss: 2.0148484264377196
Validation loss: 2.4344423203485976

Epoch: 6| Step: 7
Training loss: 2.482857006483123
Validation loss: 2.420526427163702

Epoch: 6| Step: 8
Training loss: 2.196134040215946
Validation loss: 2.424493937773791

Epoch: 6| Step: 9
Training loss: 2.5080632830093403
Validation loss: 2.410437979052546

Epoch: 6| Step: 10
Training loss: 2.662276220095996
Validation loss: 2.41019549955869

Epoch: 6| Step: 11
Training loss: 2.6750410629400676
Validation loss: 2.4387374988600334

Epoch: 6| Step: 12
Training loss: 2.283961944182868
Validation loss: 2.4562550521907593

Epoch: 6| Step: 13
Training loss: 2.4703848532034463
Validation loss: 2.472546662359043

Epoch: 223| Step: 0
Training loss: 2.425478512459819
Validation loss: 2.488819127735204

Epoch: 6| Step: 1
Training loss: 2.598102915516057
Validation loss: 2.4768040906268256

Epoch: 6| Step: 2
Training loss: 2.267906986542741
Validation loss: 2.498339476864709

Epoch: 6| Step: 3
Training loss: 2.6755848610640034
Validation loss: 2.498905436540847

Epoch: 6| Step: 4
Training loss: 2.341885346307595
Validation loss: 2.5065405084119177

Epoch: 6| Step: 5
Training loss: 2.0788853910561613
Validation loss: 2.5219254378537843

Epoch: 6| Step: 6
Training loss: 2.586708161457111
Validation loss: 2.5245737245361455

Epoch: 6| Step: 7
Training loss: 2.1512122529179893
Validation loss: 2.5226089934437916

Epoch: 6| Step: 8
Training loss: 2.298708436972912
Validation loss: 2.500273676218143

Epoch: 6| Step: 9
Training loss: 2.6058444505760785
Validation loss: 2.480101187876515

Epoch: 6| Step: 10
Training loss: 2.794518868896427
Validation loss: 2.4460979721485603

Epoch: 6| Step: 11
Training loss: 2.420971215721049
Validation loss: 2.43258701316172

Epoch: 6| Step: 12
Training loss: 2.8413783653386693
Validation loss: 2.4361798087628896

Epoch: 6| Step: 13
Training loss: 2.181901798307728
Validation loss: 2.437665961552535

Epoch: 224| Step: 0
Training loss: 2.197171113418763
Validation loss: 2.4628108704383265

Epoch: 6| Step: 1
Training loss: 1.9980474119661118
Validation loss: 2.4766688263384276

Epoch: 6| Step: 2
Training loss: 2.249609383478577
Validation loss: 2.469598361911065

Epoch: 6| Step: 3
Training loss: 2.02795553807232
Validation loss: 2.485223537649699

Epoch: 6| Step: 4
Training loss: 3.1380569814707826
Validation loss: 2.492674988814241

Epoch: 6| Step: 5
Training loss: 1.9844797662427685
Validation loss: 2.5014880627741736

Epoch: 6| Step: 6
Training loss: 2.736023847174869
Validation loss: 2.492833750679023

Epoch: 6| Step: 7
Training loss: 1.988166011326149
Validation loss: 2.4953164744880527

Epoch: 6| Step: 8
Training loss: 2.6999931935825034
Validation loss: 2.494239836698306

Epoch: 6| Step: 9
Training loss: 2.451317771429955
Validation loss: 2.4664630237395526

Epoch: 6| Step: 10
Training loss: 3.049920540696992
Validation loss: 2.462825547661691

Epoch: 6| Step: 11
Training loss: 2.6967106385608823
Validation loss: 2.425658893370973

Epoch: 6| Step: 12
Training loss: 1.993930189068051
Validation loss: 2.421444969886944

Epoch: 6| Step: 13
Training loss: 2.189432652809061
Validation loss: 2.4044689165129514

Epoch: 225| Step: 0
Training loss: 2.628817643235357
Validation loss: 2.408425303393237

Epoch: 6| Step: 1
Training loss: 2.583006612564702
Validation loss: 2.3995412553035016

Epoch: 6| Step: 2
Training loss: 2.5484867729695466
Validation loss: 2.417634003063777

Epoch: 6| Step: 3
Training loss: 2.546024765667325
Validation loss: 2.4340899172735266

Epoch: 6| Step: 4
Training loss: 1.958814345461083
Validation loss: 2.460763409784259

Epoch: 6| Step: 5
Training loss: 2.344454443289038
Validation loss: 2.5036132471106303

Epoch: 6| Step: 6
Training loss: 2.060835079629942
Validation loss: 2.5491309749545583

Epoch: 6| Step: 7
Training loss: 2.1749926906769805
Validation loss: 2.59305747995157

Epoch: 6| Step: 8
Training loss: 2.4800255086571363
Validation loss: 2.6372014226875327

Epoch: 6| Step: 9
Training loss: 2.599278636044126
Validation loss: 2.726880893980174

Epoch: 6| Step: 10
Training loss: 2.5338994982991077
Validation loss: 2.764748777185776

Epoch: 6| Step: 11
Training loss: 2.864880540630789
Validation loss: 2.7409953846816264

Epoch: 6| Step: 12
Training loss: 3.175477335934734
Validation loss: 2.668107082774607

Epoch: 6| Step: 13
Training loss: 1.951513861851057
Validation loss: 2.541826854024034

Epoch: 226| Step: 0
Training loss: 2.308722942629534
Validation loss: 2.493906272004964

Epoch: 6| Step: 1
Training loss: 2.4623039206268142
Validation loss: 2.447344007951278

Epoch: 6| Step: 2
Training loss: 2.5148920922611717
Validation loss: 2.4032150944015918

Epoch: 6| Step: 3
Training loss: 2.1213094415468134
Validation loss: 2.3979600107267274

Epoch: 6| Step: 4
Training loss: 2.183983837899292
Validation loss: 2.4012824205138266

Epoch: 6| Step: 5
Training loss: 2.9244834965543323
Validation loss: 2.395452399731392

Epoch: 6| Step: 6
Training loss: 2.529200536594337
Validation loss: 2.3953634495939458

Epoch: 6| Step: 7
Training loss: 2.309321203366609
Validation loss: 2.410343686408758

Epoch: 6| Step: 8
Training loss: 2.30227420987935
Validation loss: 2.427302103553259

Epoch: 6| Step: 9
Training loss: 2.5172877532676843
Validation loss: 2.4406359724465396

Epoch: 6| Step: 10
Training loss: 2.8313617204261505
Validation loss: 2.4363163687057665

Epoch: 6| Step: 11
Training loss: 2.482504758494139
Validation loss: 2.4543944351132603

Epoch: 6| Step: 12
Training loss: 2.5305494116010547
Validation loss: 2.469311626534708

Epoch: 6| Step: 13
Training loss: 2.088925511070704
Validation loss: 2.459459795134181

Epoch: 227| Step: 0
Training loss: 2.009943087706792
Validation loss: 2.462316867358217

Epoch: 6| Step: 1
Training loss: 2.5712809028307677
Validation loss: 2.472046027388456

Epoch: 6| Step: 2
Training loss: 2.4581598985776125
Validation loss: 2.4829034970390698

Epoch: 6| Step: 3
Training loss: 2.6081236619943624
Validation loss: 2.488831646060036

Epoch: 6| Step: 4
Training loss: 2.5285011718940393
Validation loss: 2.4933143825127777

Epoch: 6| Step: 5
Training loss: 2.2695401793942778
Validation loss: 2.515328810415373

Epoch: 6| Step: 6
Training loss: 2.572407897397783
Validation loss: 2.5282955826677345

Epoch: 6| Step: 7
Training loss: 2.472818040903036
Validation loss: 2.5418906460306485

Epoch: 6| Step: 8
Training loss: 2.7537722291192064
Validation loss: 2.5653382796599145

Epoch: 6| Step: 9
Training loss: 2.4389054574695703
Validation loss: 2.544806375060128

Epoch: 6| Step: 10
Training loss: 2.401017680568968
Validation loss: 2.5423356982334613

Epoch: 6| Step: 11
Training loss: 2.4469688582658247
Validation loss: 2.5364699942812705

Epoch: 6| Step: 12
Training loss: 2.367275626679259
Validation loss: 2.532491244165206

Epoch: 6| Step: 13
Training loss: 1.9575100311178177
Validation loss: 2.5363227100646517

Epoch: 228| Step: 0
Training loss: 1.915703019860525
Validation loss: 2.5419618027383697

Epoch: 6| Step: 1
Training loss: 2.293971711547225
Validation loss: 2.52888218000624

Epoch: 6| Step: 2
Training loss: 2.7794689519266305
Validation loss: 2.524442419232945

Epoch: 6| Step: 3
Training loss: 2.4026757980000983
Validation loss: 2.500895090759742

Epoch: 6| Step: 4
Training loss: 1.8663697307426188
Validation loss: 2.509540976152628

Epoch: 6| Step: 5
Training loss: 2.777495089027877
Validation loss: 2.5123605440378465

Epoch: 6| Step: 6
Training loss: 2.7618357243780682
Validation loss: 2.511855155006814

Epoch: 6| Step: 7
Training loss: 3.0191699128884126
Validation loss: 2.493783879343583

Epoch: 6| Step: 8
Training loss: 2.417452607661736
Validation loss: 2.5295020544719837

Epoch: 6| Step: 9
Training loss: 2.2481427474669577
Validation loss: 2.5204574628817005

Epoch: 6| Step: 10
Training loss: 2.0517949968370157
Validation loss: 2.4990073530366548

Epoch: 6| Step: 11
Training loss: 2.3976491819235894
Validation loss: 2.479249937486416

Epoch: 6| Step: 12
Training loss: 2.210543324409865
Validation loss: 2.4700186955926524

Epoch: 6| Step: 13
Training loss: 2.0693314441093853
Validation loss: 2.476983673222329

Epoch: 229| Step: 0
Training loss: 2.2315560010840243
Validation loss: 2.4716263237200695

Epoch: 6| Step: 1
Training loss: 2.2329105299618375
Validation loss: 2.4729657816873933

Epoch: 6| Step: 2
Training loss: 2.4380674435281513
Validation loss: 2.4659635375071174

Epoch: 6| Step: 3
Training loss: 2.872589925581826
Validation loss: 2.4992326440672317

Epoch: 6| Step: 4
Training loss: 2.0596559740957754
Validation loss: 2.49422956665547

Epoch: 6| Step: 5
Training loss: 2.7075119142279016
Validation loss: 2.505358191970195

Epoch: 6| Step: 6
Training loss: 2.69476896693506
Validation loss: 2.4948338669816263

Epoch: 6| Step: 7
Training loss: 2.2790554412351693
Validation loss: 2.4816022380361455

Epoch: 6| Step: 8
Training loss: 2.607726530071673
Validation loss: 2.5125315754464985

Epoch: 6| Step: 9
Training loss: 1.8911579736480832
Validation loss: 2.4930316273283277

Epoch: 6| Step: 10
Training loss: 2.221177183899427
Validation loss: 2.508306369371515

Epoch: 6| Step: 11
Training loss: 2.2082948021556223
Validation loss: 2.5050285219736694

Epoch: 6| Step: 12
Training loss: 2.794256934954708
Validation loss: 2.5063590258151036

Epoch: 6| Step: 13
Training loss: 2.389671185271786
Validation loss: 2.517879443263079

Epoch: 230| Step: 0
Training loss: 2.0756978941043207
Validation loss: 2.532903747074909

Epoch: 6| Step: 1
Training loss: 2.032251668588913
Validation loss: 2.546543708018692

Epoch: 6| Step: 2
Training loss: 2.173275502884526
Validation loss: 2.5545524156790447

Epoch: 6| Step: 3
Training loss: 2.620387247892658
Validation loss: 2.5477151426813975

Epoch: 6| Step: 4
Training loss: 2.6056588030676906
Validation loss: 2.550172432842777

Epoch: 6| Step: 5
Training loss: 2.333946783170071
Validation loss: 2.5308524239475014

Epoch: 6| Step: 6
Training loss: 2.3703510560412213
Validation loss: 2.532361883106152

Epoch: 6| Step: 7
Training loss: 2.2242811863520027
Validation loss: 2.5338389633099143

Epoch: 6| Step: 8
Training loss: 2.370443993518917
Validation loss: 2.527439816339585

Epoch: 6| Step: 9
Training loss: 2.0399090993487814
Validation loss: 2.5365870330402016

Epoch: 6| Step: 10
Training loss: 2.5223333346427084
Validation loss: 2.580672365988625

Epoch: 6| Step: 11
Training loss: 2.8504117969355542
Validation loss: 2.6479757321848667

Epoch: 6| Step: 12
Training loss: 2.7109876292758006
Validation loss: 2.606145339547987

Epoch: 6| Step: 13
Training loss: 2.468984472028959
Validation loss: 2.540761574327514

Epoch: 231| Step: 0
Training loss: 2.4005256037555376
Validation loss: 2.459174407718733

Epoch: 6| Step: 1
Training loss: 2.7230604356103316
Validation loss: 2.4341102928495477

Epoch: 6| Step: 2
Training loss: 2.0756904280681714
Validation loss: 2.4274246984138252

Epoch: 6| Step: 3
Training loss: 2.412257633981121
Validation loss: 2.4159231672328563

Epoch: 6| Step: 4
Training loss: 2.3501023736934523
Validation loss: 2.415148574001294

Epoch: 6| Step: 5
Training loss: 2.48123892293999
Validation loss: 2.4353611272805487

Epoch: 6| Step: 6
Training loss: 2.500630680641257
Validation loss: 2.4592252489526794

Epoch: 6| Step: 7
Training loss: 2.388468449087741
Validation loss: 2.4404189830099248

Epoch: 6| Step: 8
Training loss: 1.7679256203009859
Validation loss: 2.4406333485493987

Epoch: 6| Step: 9
Training loss: 2.6502242011469925
Validation loss: 2.4379399746305612

Epoch: 6| Step: 10
Training loss: 2.558348479417664
Validation loss: 2.4518026248565175

Epoch: 6| Step: 11
Training loss: 1.6348846282850464
Validation loss: 2.4579047769286824

Epoch: 6| Step: 12
Training loss: 2.8138635508919636
Validation loss: 2.473292531876344

Epoch: 6| Step: 13
Training loss: 1.502666804849866
Validation loss: 2.525328286134221

Epoch: 232| Step: 0
Training loss: 2.17234610518398
Validation loss: 2.4989016940350663

Epoch: 6| Step: 1
Training loss: 2.3199856203554376
Validation loss: 2.4721524836841926

Epoch: 6| Step: 2
Training loss: 2.439458011716983
Validation loss: 2.442817435943909

Epoch: 6| Step: 3
Training loss: 2.4063276798541033
Validation loss: 2.419857177197922

Epoch: 6| Step: 4
Training loss: 2.2710504223942563
Validation loss: 2.417360170919059

Epoch: 6| Step: 5
Training loss: 1.5746871213615372
Validation loss: 2.4101624980619563

Epoch: 6| Step: 6
Training loss: 2.793450331350666
Validation loss: 2.4044033380269445

Epoch: 6| Step: 7
Training loss: 2.4165504252222014
Validation loss: 2.4335837728662937

Epoch: 6| Step: 8
Training loss: 2.7623935937886177
Validation loss: 2.46067806972286

Epoch: 6| Step: 9
Training loss: 2.4247678153975167
Validation loss: 2.5128137514124798

Epoch: 6| Step: 10
Training loss: 2.0014852730759336
Validation loss: 2.5552614090533954

Epoch: 6| Step: 11
Training loss: 1.9292531625074938
Validation loss: 2.5893468932529693

Epoch: 6| Step: 12
Training loss: 2.737972835308489
Validation loss: 2.5980009284698093

Epoch: 6| Step: 13
Training loss: 2.289865190294328
Validation loss: 2.5620437684137634

Epoch: 233| Step: 0
Training loss: 1.9508708916456674
Validation loss: 2.572801637629383

Epoch: 6| Step: 1
Training loss: 2.578110296034063
Validation loss: 2.548618700407479

Epoch: 6| Step: 2
Training loss: 2.0623691401727564
Validation loss: 2.5302499152368485

Epoch: 6| Step: 3
Training loss: 2.1230638322617987
Validation loss: 2.5134818001422863

Epoch: 6| Step: 4
Training loss: 2.291576060035587
Validation loss: 2.4877395626243572

Epoch: 6| Step: 5
Training loss: 2.585473425214232
Validation loss: 2.46808523311908

Epoch: 6| Step: 6
Training loss: 2.2349707602822027
Validation loss: 2.474846304236274

Epoch: 6| Step: 7
Training loss: 2.7172226397373787
Validation loss: 2.4536673016499826

Epoch: 6| Step: 8
Training loss: 2.2226785615092814
Validation loss: 2.4918798467059653

Epoch: 6| Step: 9
Training loss: 2.376930957650075
Validation loss: 2.4938866193518816

Epoch: 6| Step: 10
Training loss: 1.7408876231219266
Validation loss: 2.5429152883552297

Epoch: 6| Step: 11
Training loss: 2.0981110660475513
Validation loss: 2.573709569419228

Epoch: 6| Step: 12
Training loss: 2.3280559759980797
Validation loss: 2.5951398636207768

Epoch: 6| Step: 13
Training loss: 3.0520742023492002
Validation loss: 2.621648438994128

Epoch: 234| Step: 0
Training loss: 1.5833109636566969
Validation loss: 2.6200837195740587

Epoch: 6| Step: 1
Training loss: 2.7553874043548565
Validation loss: 2.58129996467129

Epoch: 6| Step: 2
Training loss: 2.3682201386724215
Validation loss: 2.583082675847273

Epoch: 6| Step: 3
Training loss: 2.424210634257937
Validation loss: 2.5576965607641378

Epoch: 6| Step: 4
Training loss: 2.618352192455276
Validation loss: 2.547790340713309

Epoch: 6| Step: 5
Training loss: 1.959587453126345
Validation loss: 2.537090788075498

Epoch: 6| Step: 6
Training loss: 2.3284537064117963
Validation loss: 2.5255017617730386

Epoch: 6| Step: 7
Training loss: 2.054916195053966
Validation loss: 2.520361745790991

Epoch: 6| Step: 8
Training loss: 2.5635626845652344
Validation loss: 2.518791666217812

Epoch: 6| Step: 9
Training loss: 2.1703171666138408
Validation loss: 2.5127400736135432

Epoch: 6| Step: 10
Training loss: 2.348441146675167
Validation loss: 2.5202220791612193

Epoch: 6| Step: 11
Training loss: 2.469258026774299
Validation loss: 2.5340418457387988

Epoch: 6| Step: 12
Training loss: 2.2042640284744843
Validation loss: 2.5355337576595307

Epoch: 6| Step: 13
Training loss: 2.5918230919277367
Validation loss: 2.5200484608321747

Epoch: 235| Step: 0
Training loss: 1.6890110032720906
Validation loss: 2.500224559706976

Epoch: 6| Step: 1
Training loss: 1.6849318848830526
Validation loss: 2.4890332294929642

Epoch: 6| Step: 2
Training loss: 2.3752606901348434
Validation loss: 2.5076651100678737

Epoch: 6| Step: 3
Training loss: 2.6148616647690766
Validation loss: 2.4981007283352774

Epoch: 6| Step: 4
Training loss: 2.5409317413253563
Validation loss: 2.494864015474059

Epoch: 6| Step: 5
Training loss: 2.4590556382085826
Validation loss: 2.4898930761670908

Epoch: 6| Step: 6
Training loss: 2.339616309115012
Validation loss: 2.4705442930795423

Epoch: 6| Step: 7
Training loss: 2.003554285382629
Validation loss: 2.465863798414527

Epoch: 6| Step: 8
Training loss: 2.1567039564742263
Validation loss: 2.4501821793006453

Epoch: 6| Step: 9
Training loss: 2.2677203781889785
Validation loss: 2.4406095810387476

Epoch: 6| Step: 10
Training loss: 2.7487181363550977
Validation loss: 2.4097878500362833

Epoch: 6| Step: 11
Training loss: 2.4782067264968335
Validation loss: 2.4017508103766176

Epoch: 6| Step: 12
Training loss: 2.1279178109610055
Validation loss: 2.399257279181508

Epoch: 6| Step: 13
Training loss: 1.8669475576823218
Validation loss: 2.411730160397152

Epoch: 236| Step: 0
Training loss: 2.444015012454612
Validation loss: 2.4469230260219206

Epoch: 6| Step: 1
Training loss: 2.7175348131183625
Validation loss: 2.5215207193859692

Epoch: 6| Step: 2
Training loss: 1.8796743619210758
Validation loss: 2.5969452038938936

Epoch: 6| Step: 3
Training loss: 1.9974569603934569
Validation loss: 2.6647223631914785

Epoch: 6| Step: 4
Training loss: 2.05668873381974
Validation loss: 2.6607169360503726

Epoch: 6| Step: 5
Training loss: 1.9371519699075241
Validation loss: 2.64077619913526

Epoch: 6| Step: 6
Training loss: 2.76111670680495
Validation loss: 2.650764880889571

Epoch: 6| Step: 7
Training loss: 2.36934249030501
Validation loss: 2.6324009376923496

Epoch: 6| Step: 8
Training loss: 2.3309863639442514
Validation loss: 2.591217277153278

Epoch: 6| Step: 9
Training loss: 2.4793509299992476
Validation loss: 2.516785207541466

Epoch: 6| Step: 10
Training loss: 2.278805821206397
Validation loss: 2.508901612137858

Epoch: 6| Step: 11
Training loss: 2.348932259042044
Validation loss: 2.494410713851082

Epoch: 6| Step: 12
Training loss: 2.2407710156819816
Validation loss: 2.495440492726163

Epoch: 6| Step: 13
Training loss: 2.5396592597991936
Validation loss: 2.5140889514469276

Epoch: 237| Step: 0
Training loss: 2.0340577893445078
Validation loss: 2.4890802391429543

Epoch: 6| Step: 1
Training loss: 1.7441785579712852
Validation loss: 2.5065235874749967

Epoch: 6| Step: 2
Training loss: 2.2792824399044833
Validation loss: 2.512128765838276

Epoch: 6| Step: 3
Training loss: 1.7966139894075228
Validation loss: 2.5072425059328833

Epoch: 6| Step: 4
Training loss: 2.3774809678335784
Validation loss: 2.501954149655532

Epoch: 6| Step: 5
Training loss: 2.120613507442886
Validation loss: 2.534969305054999

Epoch: 6| Step: 6
Training loss: 2.6344735992550996
Validation loss: 2.559059262161441

Epoch: 6| Step: 7
Training loss: 2.653914378425788
Validation loss: 2.590091060298773

Epoch: 6| Step: 8
Training loss: 1.6084469091341418
Validation loss: 2.585100907629121

Epoch: 6| Step: 9
Training loss: 2.749522427792255
Validation loss: 2.5874791858690585

Epoch: 6| Step: 10
Training loss: 2.544028440790324
Validation loss: 2.6125743229915477

Epoch: 6| Step: 11
Training loss: 1.9623595776706688
Validation loss: 2.6420213871559763

Epoch: 6| Step: 12
Training loss: 2.244225190829414
Validation loss: 2.6835295147708735

Epoch: 6| Step: 13
Training loss: 2.9198542660442017
Validation loss: 2.6372894765681743

Epoch: 238| Step: 0
Training loss: 1.626697314096148
Validation loss: 2.5678925028318527

Epoch: 6| Step: 1
Training loss: 2.371702414605345
Validation loss: 2.5116575722253107

Epoch: 6| Step: 2
Training loss: 2.0338296795167494
Validation loss: 2.4809374274036378

Epoch: 6| Step: 3
Training loss: 2.5049178390582254
Validation loss: 2.4581391404004536

Epoch: 6| Step: 4
Training loss: 2.54978224628673
Validation loss: 2.4395600388772833

Epoch: 6| Step: 5
Training loss: 2.162077837182474
Validation loss: 2.413197430728593

Epoch: 6| Step: 6
Training loss: 1.8415089581427297
Validation loss: 2.4097998943267886

Epoch: 6| Step: 7
Training loss: 2.6350466703447624
Validation loss: 2.407693985525907

Epoch: 6| Step: 8
Training loss: 2.00960546806284
Validation loss: 2.3998910328010736

Epoch: 6| Step: 9
Training loss: 2.664786500519933
Validation loss: 2.4028840320594975

Epoch: 6| Step: 10
Training loss: 1.9879180036785635
Validation loss: 2.4022398679349277

Epoch: 6| Step: 11
Training loss: 2.262867163271963
Validation loss: 2.401790241058151

Epoch: 6| Step: 12
Training loss: 2.147396542918103
Validation loss: 2.429087170829139

Epoch: 6| Step: 13
Training loss: 2.4836160712185547
Validation loss: 2.5078904063752856

Epoch: 239| Step: 0
Training loss: 1.5757912479928857
Validation loss: 2.538204542021486

Epoch: 6| Step: 1
Training loss: 1.42645899719933
Validation loss: 2.6041932565295536

Epoch: 6| Step: 2
Training loss: 1.978611844915512
Validation loss: 2.6446692935906744

Epoch: 6| Step: 3
Training loss: 2.261326362159768
Validation loss: 2.686583536093986

Epoch: 6| Step: 4
Training loss: 2.347311137344278
Validation loss: 2.689726244898

Epoch: 6| Step: 5
Training loss: 1.5419928059688437
Validation loss: 2.678335621284406

Epoch: 6| Step: 6
Training loss: 2.346779353279148
Validation loss: 2.6598569302769737

Epoch: 6| Step: 7
Training loss: 2.208764615919958
Validation loss: 2.6344351970149735

Epoch: 6| Step: 8
Training loss: 2.9921473408287427
Validation loss: 2.5966860208705347

Epoch: 6| Step: 9
Training loss: 2.1043077427873946
Validation loss: 2.5734383443332702

Epoch: 6| Step: 10
Training loss: 2.8217141850168046
Validation loss: 2.5532764799105636

Epoch: 6| Step: 11
Training loss: 2.7454445995492853
Validation loss: 2.535142418279659

Epoch: 6| Step: 12
Training loss: 2.4444805838581782
Validation loss: 2.516501152149882

Epoch: 6| Step: 13
Training loss: 2.00865755220952
Validation loss: 2.5222546602750846

Epoch: 240| Step: 0
Training loss: 1.976653085675901
Validation loss: 2.5300489812520444

Epoch: 6| Step: 1
Training loss: 2.700422667163299
Validation loss: 2.5132098254017095

Epoch: 6| Step: 2
Training loss: 2.0280735708807582
Validation loss: 2.517652270139183

Epoch: 6| Step: 3
Training loss: 1.3546835964195039
Validation loss: 2.5284715476677517

Epoch: 6| Step: 4
Training loss: 2.719137229966635
Validation loss: 2.5392210733703577

Epoch: 6| Step: 5
Training loss: 2.012681097566251
Validation loss: 2.5365266774084496

Epoch: 6| Step: 6
Training loss: 2.1211101608625045
Validation loss: 2.5439211124675785

Epoch: 6| Step: 7
Training loss: 2.245458682298272
Validation loss: 2.5268679959699667

Epoch: 6| Step: 8
Training loss: 2.130867430954066
Validation loss: 2.52496834471833

Epoch: 6| Step: 9
Training loss: 2.06103960988843
Validation loss: 2.521151122365593

Epoch: 6| Step: 10
Training loss: 2.27900794648764
Validation loss: 2.529209165501055

Epoch: 6| Step: 11
Training loss: 1.920604316756468
Validation loss: 2.528185169010937

Epoch: 6| Step: 12
Training loss: 2.086126768976477
Validation loss: 2.544598925600887

Epoch: 6| Step: 13
Training loss: 2.6262516489073686
Validation loss: 2.5577000648864248

Epoch: 241| Step: 0
Training loss: 2.5388848345293114
Validation loss: 2.555103390200789

Epoch: 6| Step: 1
Training loss: 1.819292167264006
Validation loss: 2.559926368088037

Epoch: 6| Step: 2
Training loss: 1.6616124128529117
Validation loss: 2.567956700554386

Epoch: 6| Step: 3
Training loss: 2.7762409494141718
Validation loss: 2.5770771272413984

Epoch: 6| Step: 4
Training loss: 2.2105382552099346
Validation loss: 2.5794795132761745

Epoch: 6| Step: 5
Training loss: 1.6464544725700652
Validation loss: 2.55373440328215

Epoch: 6| Step: 6
Training loss: 2.291655962369946
Validation loss: 2.509475959299047

Epoch: 6| Step: 7
Training loss: 2.1508298558716104
Validation loss: 2.481608125430357

Epoch: 6| Step: 8
Training loss: 1.868907886074177
Validation loss: 2.4833263305308755

Epoch: 6| Step: 9
Training loss: 1.7585466674304557
Validation loss: 2.460199353522284

Epoch: 6| Step: 10
Training loss: 2.4364371305480637
Validation loss: 2.450441132661774

Epoch: 6| Step: 11
Training loss: 1.9330305415946094
Validation loss: 2.4651719136789936

Epoch: 6| Step: 12
Training loss: 2.485728536918891
Validation loss: 2.456058244782744

Epoch: 6| Step: 13
Training loss: 2.0184995277372106
Validation loss: 2.4702427023387066

Epoch: 242| Step: 0
Training loss: 2.248412950075538
Validation loss: 2.510316218621426

Epoch: 6| Step: 1
Training loss: 2.313991375022647
Validation loss: 2.5746402700668476

Epoch: 6| Step: 2
Training loss: 2.138211748626434
Validation loss: 2.62606356648758

Epoch: 6| Step: 3
Training loss: 2.3337751606022676
Validation loss: 2.659859132619649

Epoch: 6| Step: 4
Training loss: 1.8136433908270324
Validation loss: 2.6955962333887427

Epoch: 6| Step: 5
Training loss: 2.60280636672535
Validation loss: 2.6985745552948193

Epoch: 6| Step: 6
Training loss: 2.3864398300095186
Validation loss: 2.6835795073749154

Epoch: 6| Step: 7
Training loss: 2.0725493241389383
Validation loss: 2.616244316802971

Epoch: 6| Step: 8
Training loss: 1.3132830963031015
Validation loss: 2.589647704298133

Epoch: 6| Step: 9
Training loss: 1.872066428151128
Validation loss: 2.536489668724564

Epoch: 6| Step: 10
Training loss: 2.599451256578424
Validation loss: 2.492954749777619

Epoch: 6| Step: 11
Training loss: 2.0349350587572506
Validation loss: 2.484985072339365

Epoch: 6| Step: 12
Training loss: 2.1410098878435266
Validation loss: 2.474523586254615

Epoch: 6| Step: 13
Training loss: 1.986249503921245
Validation loss: 2.4755115783698876

Epoch: 243| Step: 0
Training loss: 2.4612506001221335
Validation loss: 2.468353781753119

Epoch: 6| Step: 1
Training loss: 2.2094812348763018
Validation loss: 2.466310526633787

Epoch: 6| Step: 2
Training loss: 2.3457670560410033
Validation loss: 2.4919429297342104

Epoch: 6| Step: 3
Training loss: 1.762678743321537
Validation loss: 2.516780319192901

Epoch: 6| Step: 4
Training loss: 2.2580242123720566
Validation loss: 2.532247083880625

Epoch: 6| Step: 5
Training loss: 1.7226494683026232
Validation loss: 2.53521254183561

Epoch: 6| Step: 6
Training loss: 2.3336441877474217
Validation loss: 2.5479728808104807

Epoch: 6| Step: 7
Training loss: 2.1100170147467416
Validation loss: 2.554315612263666

Epoch: 6| Step: 8
Training loss: 2.4345910736679963
Validation loss: 2.594239773934035

Epoch: 6| Step: 9
Training loss: 2.1379052029068575
Validation loss: 2.628122731226441

Epoch: 6| Step: 10
Training loss: 2.183403102352115
Validation loss: 2.6404691745939783

Epoch: 6| Step: 11
Training loss: 2.4171857166838526
Validation loss: 2.6141143873116106

Epoch: 6| Step: 12
Training loss: 1.9626369331356177
Validation loss: 2.5939739964281476

Epoch: 6| Step: 13
Training loss: 2.2468267952917
Validation loss: 2.553059119964358

Epoch: 244| Step: 0
Training loss: 2.1725219202197823
Validation loss: 2.505815480803824

Epoch: 6| Step: 1
Training loss: 1.8212330336556104
Validation loss: 2.4861683104411543

Epoch: 6| Step: 2
Training loss: 1.781088369966934
Validation loss: 2.4725235883658296

Epoch: 6| Step: 3
Training loss: 2.3101495705934676
Validation loss: 2.4765486552020115

Epoch: 6| Step: 4
Training loss: 1.6458011173362708
Validation loss: 2.483846941485344

Epoch: 6| Step: 5
Training loss: 2.2774492766073915
Validation loss: 2.4942686752294136

Epoch: 6| Step: 6
Training loss: 2.545181366579156
Validation loss: 2.4978694451075723

Epoch: 6| Step: 7
Training loss: 2.564750613457089
Validation loss: 2.4772476672359014

Epoch: 6| Step: 8
Training loss: 2.23336000663809
Validation loss: 2.4852389933652996

Epoch: 6| Step: 9
Training loss: 2.5032916333839372
Validation loss: 2.478832186806472

Epoch: 6| Step: 10
Training loss: 2.1837056631163048
Validation loss: 2.460842906711495

Epoch: 6| Step: 11
Training loss: 2.0999647682504263
Validation loss: 2.468305636822881

Epoch: 6| Step: 12
Training loss: 1.9976402905676656
Validation loss: 2.44837091892022

Epoch: 6| Step: 13
Training loss: 1.8786157712618978
Validation loss: 2.4510804212258477

Epoch: 245| Step: 0
Training loss: 2.329072490646655
Validation loss: 2.43868776898861

Epoch: 6| Step: 1
Training loss: 1.921582827805617
Validation loss: 2.465161345745847

Epoch: 6| Step: 2
Training loss: 1.9203429900217204
Validation loss: 2.477676690120798

Epoch: 6| Step: 3
Training loss: 2.035093456624846
Validation loss: 2.489392313453394

Epoch: 6| Step: 4
Training loss: 2.03223817703763
Validation loss: 2.4993693776669494

Epoch: 6| Step: 5
Training loss: 2.07503135841298
Validation loss: 2.527995095220714

Epoch: 6| Step: 6
Training loss: 2.011716142671247
Validation loss: 2.5135540211632663

Epoch: 6| Step: 7
Training loss: 1.969274662891516
Validation loss: 2.4991670379634567

Epoch: 6| Step: 8
Training loss: 2.502035266203823
Validation loss: 2.511058462034893

Epoch: 6| Step: 9
Training loss: 2.2330371612859654
Validation loss: 2.5349885613417875

Epoch: 6| Step: 10
Training loss: 2.5661878333201034
Validation loss: 2.516739872557212

Epoch: 6| Step: 11
Training loss: 1.3096374904120318
Validation loss: 2.5385474483583326

Epoch: 6| Step: 12
Training loss: 1.9811170972658894
Validation loss: 2.5369867894241747

Epoch: 6| Step: 13
Training loss: 2.221538027763934
Validation loss: 2.489924846395842

Epoch: 246| Step: 0
Training loss: 1.8453917871507655
Validation loss: 2.4530817731763013

Epoch: 6| Step: 1
Training loss: 2.689738472488454
Validation loss: 2.438778615788183

Epoch: 6| Step: 2
Training loss: 2.2600369698530463
Validation loss: 2.440507934950973

Epoch: 6| Step: 3
Training loss: 2.1492375774106622
Validation loss: 2.4417237591755954

Epoch: 6| Step: 4
Training loss: 1.6643593393549503
Validation loss: 2.4388885045615583

Epoch: 6| Step: 5
Training loss: 1.62426286264088
Validation loss: 2.459672243787625

Epoch: 6| Step: 6
Training loss: 1.9945711125156906
Validation loss: 2.5212755063757717

Epoch: 6| Step: 7
Training loss: 2.2746981242346167
Validation loss: 2.527985221920716

Epoch: 6| Step: 8
Training loss: 1.9108253976374576
Validation loss: 2.5459960350862394

Epoch: 6| Step: 9
Training loss: 2.323542956669938
Validation loss: 2.528664454789964

Epoch: 6| Step: 10
Training loss: 2.1208651087490873
Validation loss: 2.491609964011226

Epoch: 6| Step: 11
Training loss: 1.7531774829209659
Validation loss: 2.4772697637793533

Epoch: 6| Step: 12
Training loss: 2.5142493425717176
Validation loss: 2.463974354037702

Epoch: 6| Step: 13
Training loss: 1.425850895264983
Validation loss: 2.4587865880553004

Epoch: 247| Step: 0
Training loss: 1.7374501502481066
Validation loss: 2.4548433497190745

Epoch: 6| Step: 1
Training loss: 2.5006765403861113
Validation loss: 2.481823695266222

Epoch: 6| Step: 2
Training loss: 1.8717692197228417
Validation loss: 2.480713068762317

Epoch: 6| Step: 3
Training loss: 2.4736835099547143
Validation loss: 2.535228675692442

Epoch: 6| Step: 4
Training loss: 2.2940725240110353
Validation loss: 2.5438410725510927

Epoch: 6| Step: 5
Training loss: 2.233275029384549
Validation loss: 2.548444465538207

Epoch: 6| Step: 6
Training loss: 1.9727130541790456
Validation loss: 2.5606217272377285

Epoch: 6| Step: 7
Training loss: 2.1292061410766996
Validation loss: 2.566495811817705

Epoch: 6| Step: 8
Training loss: 2.042195803005907
Validation loss: 2.573496227462363

Epoch: 6| Step: 9
Training loss: 2.0553288492274895
Validation loss: 2.581836484775682

Epoch: 6| Step: 10
Training loss: 1.4070075643643813
Validation loss: 2.6008130957978133

Epoch: 6| Step: 11
Training loss: 1.9411520839543102
Validation loss: 2.6066244905329286

Epoch: 6| Step: 12
Training loss: 1.2170612176655171
Validation loss: 2.600429635248229

Epoch: 6| Step: 13
Training loss: 2.286775142702861
Validation loss: 2.619652919209863

Epoch: 248| Step: 0
Training loss: 2.2432009436930525
Validation loss: 2.6414482424158554

Epoch: 6| Step: 1
Training loss: 1.8964728090854839
Validation loss: 2.63537253325399

Epoch: 6| Step: 2
Training loss: 1.922169112364232
Validation loss: 2.633528962377268

Epoch: 6| Step: 3
Training loss: 2.3859994057129392
Validation loss: 2.6059207867587006

Epoch: 6| Step: 4
Training loss: 1.7037902372762732
Validation loss: 2.5332781749521356

Epoch: 6| Step: 5
Training loss: 1.3741736963638622
Validation loss: 2.501357288463179

Epoch: 6| Step: 6
Training loss: 2.2750273189371595
Validation loss: 2.4907976517605652

Epoch: 6| Step: 7
Training loss: 2.182184354803601
Validation loss: 2.4944422451450863

Epoch: 6| Step: 8
Training loss: 1.9478433836617308
Validation loss: 2.4865943642349344

Epoch: 6| Step: 9
Training loss: 2.163694935786116
Validation loss: 2.5096210159566383

Epoch: 6| Step: 10
Training loss: 2.2076150577753926
Validation loss: 2.5214362440880898

Epoch: 6| Step: 11
Training loss: 1.704592221514383
Validation loss: 2.547277068911352

Epoch: 6| Step: 12
Training loss: 2.0630535192162696
Validation loss: 2.546910635802489

Epoch: 6| Step: 13
Training loss: 2.1602086755830348
Validation loss: 2.559214677186188

Epoch: 249| Step: 0
Training loss: 2.2847054843875667
Validation loss: 2.574227321617394

Epoch: 6| Step: 1
Training loss: 1.3792250915706539
Validation loss: 2.6200261102969264

Epoch: 6| Step: 2
Training loss: 2.2006612217529633
Validation loss: 2.667578215183688

Epoch: 6| Step: 3
Training loss: 2.0573154367610837
Validation loss: 2.684825015245828

Epoch: 6| Step: 4
Training loss: 1.8965110266214324
Validation loss: 2.661119913982687

Epoch: 6| Step: 5
Training loss: 1.8594582162395243
Validation loss: 2.602709580538421

Epoch: 6| Step: 6
Training loss: 1.9787798721073246
Validation loss: 2.5861456164918244

Epoch: 6| Step: 7
Training loss: 2.3824130364445
Validation loss: 2.5605936299968297

Epoch: 6| Step: 8
Training loss: 1.2976235676691301
Validation loss: 2.5340658740476276

Epoch: 6| Step: 9
Training loss: 2.247723169162615
Validation loss: 2.5119596700783524

Epoch: 6| Step: 10
Training loss: 2.2696825197005803
Validation loss: 2.5051466991152833

Epoch: 6| Step: 11
Training loss: 1.8464270085509729
Validation loss: 2.5097463968474973

Epoch: 6| Step: 12
Training loss: 1.9774013744504961
Validation loss: 2.510970488115

Epoch: 6| Step: 13
Training loss: 2.547594027445173
Validation loss: 2.5264362953457464

Epoch: 250| Step: 0
Training loss: 2.374360550577651
Validation loss: 2.537526304928106

Epoch: 6| Step: 1
Training loss: 2.335157997944938
Validation loss: 2.567194280769659

Epoch: 6| Step: 2
Training loss: 1.6628713866992249
Validation loss: 2.6014578439560974

Epoch: 6| Step: 3
Training loss: 1.7619262031836316
Validation loss: 2.6241957647910477

Epoch: 6| Step: 4
Training loss: 2.0465684035049034
Validation loss: 2.6253812515984425

Epoch: 6| Step: 5
Training loss: 2.388145307640742
Validation loss: 2.6295623489612074

Epoch: 6| Step: 6
Training loss: 2.09264674940269
Validation loss: 2.636358408428168

Epoch: 6| Step: 7
Training loss: 1.9119054979808046
Validation loss: 2.6161868101447143

Epoch: 6| Step: 8
Training loss: 1.5260777214226378
Validation loss: 2.5844774869910787

Epoch: 6| Step: 9
Training loss: 1.8302666924221767
Validation loss: 2.553744721632799

Epoch: 6| Step: 10
Training loss: 1.9449235764814183
Validation loss: 2.575978612395333

Epoch: 6| Step: 11
Training loss: 1.8301853405009878
Validation loss: 2.6032166380229746

Epoch: 6| Step: 12
Training loss: 2.0835548537420956
Validation loss: 2.5766499047918208

Epoch: 6| Step: 13
Training loss: 1.6509071399584003
Validation loss: 2.5382095668724487

Epoch: 251| Step: 0
Training loss: 2.2149005862416473
Validation loss: 2.5085918054046115

Epoch: 6| Step: 1
Training loss: 1.6578236427615778
Validation loss: 2.510935886999548

Epoch: 6| Step: 2
Training loss: 2.2944341652644797
Validation loss: 2.5047765692369235

Epoch: 6| Step: 3
Training loss: 2.2580122809806795
Validation loss: 2.498061019874219

Epoch: 6| Step: 4
Training loss: 2.16746501397185
Validation loss: 2.4858082265431216

Epoch: 6| Step: 5
Training loss: 1.6270474959499948
Validation loss: 2.4882442294981684

Epoch: 6| Step: 6
Training loss: 1.8266313760137514
Validation loss: 2.507043213914927

Epoch: 6| Step: 7
Training loss: 2.019776792374748
Validation loss: 2.508007836378173

Epoch: 6| Step: 8
Training loss: 1.9833398356718441
Validation loss: 2.529617196164365

Epoch: 6| Step: 9
Training loss: 1.9714039670700154
Validation loss: 2.55780851088812

Epoch: 6| Step: 10
Training loss: 1.3384626293473052
Validation loss: 2.5714116269085774

Epoch: 6| Step: 11
Training loss: 2.010991411294148
Validation loss: 2.562574656129567

Epoch: 6| Step: 12
Training loss: 1.9674786292421724
Validation loss: 2.589554592190836

Epoch: 6| Step: 13
Training loss: 1.93669782460285
Validation loss: 2.6123229394688536

Epoch: 252| Step: 0
Training loss: 2.3430497204156997
Validation loss: 2.615047240290449

Epoch: 6| Step: 1
Training loss: 1.916547073558436
Validation loss: 2.619690850185728

Epoch: 6| Step: 2
Training loss: 1.6859665013489011
Validation loss: 2.59054319848122

Epoch: 6| Step: 3
Training loss: 1.9359554163709518
Validation loss: 2.561617170196166

Epoch: 6| Step: 4
Training loss: 1.4646179025114556
Validation loss: 2.5458043445840413

Epoch: 6| Step: 5
Training loss: 2.225547800243669
Validation loss: 2.5177287321271415

Epoch: 6| Step: 6
Training loss: 0.8657256856263974
Validation loss: 2.524572631885179

Epoch: 6| Step: 7
Training loss: 2.1593578994890907
Validation loss: 2.554268492436297

Epoch: 6| Step: 8
Training loss: 2.272373120718066
Validation loss: 2.5511821315039676

Epoch: 6| Step: 9
Training loss: 2.1149789474557785
Validation loss: 2.554712631645368

Epoch: 6| Step: 10
Training loss: 1.9546488806113542
Validation loss: 2.5388740180572085

Epoch: 6| Step: 11
Training loss: 2.085786163898109
Validation loss: 2.523055632088453

Epoch: 6| Step: 12
Training loss: 1.73971450524315
Validation loss: 2.4950170664123763

Epoch: 6| Step: 13
Training loss: 2.226012794498988
Validation loss: 2.524387273965456

Epoch: 253| Step: 0
Training loss: 2.200508674422461
Validation loss: 2.5343791782541

Epoch: 6| Step: 1
Training loss: 1.7520973716049462
Validation loss: 2.5340634455305326

Epoch: 6| Step: 2
Training loss: 2.0937863247125925
Validation loss: 2.5760461325533943

Epoch: 6| Step: 3
Training loss: 1.9799020772860156
Validation loss: 2.587072931323061

Epoch: 6| Step: 4
Training loss: 1.6974483694502944
Validation loss: 2.5874984645298977

Epoch: 6| Step: 5
Training loss: 2.3958685720312416
Validation loss: 2.576465388484991

Epoch: 6| Step: 6
Training loss: 2.0005521012252583
Validation loss: 2.5272183007784026

Epoch: 6| Step: 7
Training loss: 2.1896456413465555
Validation loss: 2.5144406007314566

Epoch: 6| Step: 8
Training loss: 2.10327101678118
Validation loss: 2.4999459435145956

Epoch: 6| Step: 9
Training loss: 1.6687068690751776
Validation loss: 2.494024864121978

Epoch: 6| Step: 10
Training loss: 2.0970866248594278
Validation loss: 2.495472127095306

Epoch: 6| Step: 11
Training loss: 1.6128580863850444
Validation loss: 2.496489895035022

Epoch: 6| Step: 12
Training loss: 1.9270938632436836
Validation loss: 2.52204382245791

Epoch: 6| Step: 13
Training loss: 1.6302453992568406
Validation loss: 2.541204311277567

Epoch: 254| Step: 0
Training loss: 2.096219670184918
Validation loss: 2.581636823131094

Epoch: 6| Step: 1
Training loss: 1.9963876168261567
Validation loss: 2.5845785371801497

Epoch: 6| Step: 2
Training loss: 1.821356085395475
Validation loss: 2.6026212649149945

Epoch: 6| Step: 3
Training loss: 1.8925648975205327
Validation loss: 2.600497459059347

Epoch: 6| Step: 4
Training loss: 1.3929263157139005
Validation loss: 2.5798792126645553

Epoch: 6| Step: 5
Training loss: 1.9117443761133
Validation loss: 2.6184152969435215

Epoch: 6| Step: 6
Training loss: 1.1394159885719648
Validation loss: 2.644703426043433

Epoch: 6| Step: 7
Training loss: 1.9699604007207137
Validation loss: 2.6348091568927163

Epoch: 6| Step: 8
Training loss: 1.8267168669984173
Validation loss: 2.6313671517890165

Epoch: 6| Step: 9
Training loss: 1.9655354004832828
Validation loss: 2.6257823241238647

Epoch: 6| Step: 10
Training loss: 2.396579084569034
Validation loss: 2.619270227962943

Epoch: 6| Step: 11
Training loss: 1.9183159725597874
Validation loss: 2.575300617214569

Epoch: 6| Step: 12
Training loss: 2.065377742032957
Validation loss: 2.535722894312079

Epoch: 6| Step: 13
Training loss: 2.028634250462527
Validation loss: 2.5150733989616847

Epoch: 255| Step: 0
Training loss: 1.931203640378288
Validation loss: 2.49122801389697

Epoch: 6| Step: 1
Training loss: 1.657725486665025
Validation loss: 2.4657986914175063

Epoch: 6| Step: 2
Training loss: 1.5533525879666614
Validation loss: 2.4608253631852213

Epoch: 6| Step: 3
Training loss: 1.808654125021564
Validation loss: 2.4737522418065736

Epoch: 6| Step: 4
Training loss: 1.9611412641580408
Validation loss: 2.4769512935089013

Epoch: 6| Step: 5
Training loss: 2.3027414155161665
Validation loss: 2.494271998145159

Epoch: 6| Step: 6
Training loss: 2.2013330409055376
Validation loss: 2.4964514415140346

Epoch: 6| Step: 7
Training loss: 1.9323236783264457
Validation loss: 2.507667136308805

Epoch: 6| Step: 8
Training loss: 2.0878627621796144
Validation loss: 2.5516328683220397

Epoch: 6| Step: 9
Training loss: 1.6315610917835481
Validation loss: 2.6063632572495474

Epoch: 6| Step: 10
Training loss: 2.1123654113873354
Validation loss: 2.6823130817715324

Epoch: 6| Step: 11
Training loss: 2.434309215905526
Validation loss: 2.7577188726859885

Epoch: 6| Step: 12
Training loss: 2.0626625228195796
Validation loss: 2.7177147351662554

Epoch: 6| Step: 13
Training loss: 2.0797338926212245
Validation loss: 2.668368002223528

Epoch: 256| Step: 0
Training loss: 2.600813840992478
Validation loss: 2.606172636818782

Epoch: 6| Step: 1
Training loss: 1.7676803643601502
Validation loss: 2.5858171399870535

Epoch: 6| Step: 2
Training loss: 1.6933871116258552
Validation loss: 2.5381852778122442

Epoch: 6| Step: 3
Training loss: 1.8667082231300942
Validation loss: 2.5173847736457753

Epoch: 6| Step: 4
Training loss: 2.0720023689992906
Validation loss: 2.526997726531475

Epoch: 6| Step: 5
Training loss: 1.9897052933892032
Validation loss: 2.5373047414138497

Epoch: 6| Step: 6
Training loss: 1.3808852305278059
Validation loss: 2.534019687310511

Epoch: 6| Step: 7
Training loss: 2.1011454228617055
Validation loss: 2.5760707289132325

Epoch: 6| Step: 8
Training loss: 1.9637902167443597
Validation loss: 2.5740049413032877

Epoch: 6| Step: 9
Training loss: 2.0601527411120335
Validation loss: 2.5981799281013926

Epoch: 6| Step: 10
Training loss: 1.6430496464366247
Validation loss: 2.6150527105930745

Epoch: 6| Step: 11
Training loss: 1.5078888710722889
Validation loss: 2.648573961661738

Epoch: 6| Step: 12
Training loss: 2.1976500314786596
Validation loss: 2.683776820565317

Epoch: 6| Step: 13
Training loss: 2.1442369491893376
Validation loss: 2.7053335815892967

Epoch: 257| Step: 0
Training loss: 1.5451001089803988
Validation loss: 2.676494388206838

Epoch: 6| Step: 1
Training loss: 2.2580329760972444
Validation loss: 2.608509411635288

Epoch: 6| Step: 2
Training loss: 1.449575950835485
Validation loss: 2.5820211613523947

Epoch: 6| Step: 3
Training loss: 2.0679452858037917
Validation loss: 2.5383377573042365

Epoch: 6| Step: 4
Training loss: 2.497791650065359
Validation loss: 2.521926880325067

Epoch: 6| Step: 5
Training loss: 1.4308360338194832
Validation loss: 2.506978046384939

Epoch: 6| Step: 6
Training loss: 1.8442328515855337
Validation loss: 2.512230060169327

Epoch: 6| Step: 7
Training loss: 1.7471737519161525
Validation loss: 2.5251525112388316

Epoch: 6| Step: 8
Training loss: 1.7232691221738246
Validation loss: 2.512226603344745

Epoch: 6| Step: 9
Training loss: 1.9887016166781337
Validation loss: 2.5247606406062784

Epoch: 6| Step: 10
Training loss: 1.9372307374956272
Validation loss: 2.547067645620999

Epoch: 6| Step: 11
Training loss: 1.7655491095243117
Validation loss: 2.5367869650882264

Epoch: 6| Step: 12
Training loss: 1.9474511091684223
Validation loss: 2.552330450801533

Epoch: 6| Step: 13
Training loss: 2.065688125638419
Validation loss: 2.5619344249729483

Epoch: 258| Step: 0
Training loss: 1.863073693317298
Validation loss: 2.5721055545360874

Epoch: 6| Step: 1
Training loss: 1.7086820324075263
Validation loss: 2.5725963988213807

Epoch: 6| Step: 2
Training loss: 1.2090161739968166
Validation loss: 2.5887043863152415

Epoch: 6| Step: 3
Training loss: 1.9792421293093743
Validation loss: 2.6203654189862027

Epoch: 6| Step: 4
Training loss: 1.9134814567694118
Validation loss: 2.634528974644258

Epoch: 6| Step: 5
Training loss: 1.8751619269068396
Validation loss: 2.634450703751804

Epoch: 6| Step: 6
Training loss: 2.062825841885101
Validation loss: 2.6322061039916185

Epoch: 6| Step: 7
Training loss: 1.4534022569207614
Validation loss: 2.5883604349255305

Epoch: 6| Step: 8
Training loss: 1.8986332168476643
Validation loss: 2.571005185707727

Epoch: 6| Step: 9
Training loss: 1.462655184736945
Validation loss: 2.5726034950218555

Epoch: 6| Step: 10
Training loss: 2.2799949851733823
Validation loss: 2.5784798784029457

Epoch: 6| Step: 11
Training loss: 2.0264823715380653
Validation loss: 2.574666574071141

Epoch: 6| Step: 12
Training loss: 1.955095929380094
Validation loss: 2.5671997911254394

Epoch: 6| Step: 13
Training loss: 1.9646092420900994
Validation loss: 2.580539558862319

Epoch: 259| Step: 0
Training loss: 1.1993202390190976
Validation loss: 2.5918417863492125

Epoch: 6| Step: 1
Training loss: 1.9207556961930394
Validation loss: 2.616483310715238

Epoch: 6| Step: 2
Training loss: 1.8045771841706162
Validation loss: 2.593897671380793

Epoch: 6| Step: 3
Training loss: 1.6238730264034615
Validation loss: 2.5711654054391473

Epoch: 6| Step: 4
Training loss: 2.3007536855707698
Validation loss: 2.58208224070435

Epoch: 6| Step: 5
Training loss: 1.7777480116312567
Validation loss: 2.5743153645278327

Epoch: 6| Step: 6
Training loss: 1.4907105811161372
Validation loss: 2.5733908504053886

Epoch: 6| Step: 7
Training loss: 1.1017385572060407
Validation loss: 2.559747357483082

Epoch: 6| Step: 8
Training loss: 1.7305397036367114
Validation loss: 2.5879803229598592

Epoch: 6| Step: 9
Training loss: 1.7846263541446066
Validation loss: 2.5681486112764165

Epoch: 6| Step: 10
Training loss: 2.1746560274180027
Validation loss: 2.5713391854719334

Epoch: 6| Step: 11
Training loss: 1.8583267847581557
Validation loss: 2.554116279458217

Epoch: 6| Step: 12
Training loss: 2.301544011204273
Validation loss: 2.5571071564124543

Epoch: 6| Step: 13
Training loss: 2.216183104390307
Validation loss: 2.544254608023631

Epoch: 260| Step: 0
Training loss: 1.723358495566707
Validation loss: 2.55759685965776

Epoch: 6| Step: 1
Training loss: 1.9729583811017328
Validation loss: 2.5630246137378543

Epoch: 6| Step: 2
Training loss: 1.4217542659936329
Validation loss: 2.5854268028414444

Epoch: 6| Step: 3
Training loss: 1.2849758682508399
Validation loss: 2.626374682639739

Epoch: 6| Step: 4
Training loss: 1.6605010269285918
Validation loss: 2.645547279847809

Epoch: 6| Step: 5
Training loss: 1.3333907810391998
Validation loss: 2.6564071097288733

Epoch: 6| Step: 6
Training loss: 1.6300456135458266
Validation loss: 2.6426558631722377

Epoch: 6| Step: 7
Training loss: 1.8206800490862602
Validation loss: 2.6134603821471285

Epoch: 6| Step: 8
Training loss: 1.7659669393077972
Validation loss: 2.5949723562961813

Epoch: 6| Step: 9
Training loss: 2.4166198813634256
Validation loss: 2.568312379570918

Epoch: 6| Step: 10
Training loss: 2.2512255615737957
Validation loss: 2.5803756351684335

Epoch: 6| Step: 11
Training loss: 2.111628141445686
Validation loss: 2.5408010674776285

Epoch: 6| Step: 12
Training loss: 1.458168465513834
Validation loss: 2.5449185184898004

Epoch: 6| Step: 13
Training loss: 1.2625732362863924
Validation loss: 2.5419793288842514

Epoch: 261| Step: 0
Training loss: 1.6470787631659098
Validation loss: 2.525868495379571

Epoch: 6| Step: 1
Training loss: 2.1375802097552286
Validation loss: 2.5472322846649873

Epoch: 6| Step: 2
Training loss: 1.2926359641540943
Validation loss: 2.554786213842982

Epoch: 6| Step: 3
Training loss: 2.099973396859372
Validation loss: 2.569945249463088

Epoch: 6| Step: 4
Training loss: 0.9053954008343312
Validation loss: 2.5737211837764646

Epoch: 6| Step: 5
Training loss: 2.021900668563517
Validation loss: 2.59169946845699

Epoch: 6| Step: 6
Training loss: 1.877965743283614
Validation loss: 2.5863912137462863

Epoch: 6| Step: 7
Training loss: 1.8494628719327113
Validation loss: 2.5564591410349986

Epoch: 6| Step: 8
Training loss: 1.388209956908698
Validation loss: 2.570069830062177

Epoch: 6| Step: 9
Training loss: 1.6259880729932294
Validation loss: 2.5637352420046953

Epoch: 6| Step: 10
Training loss: 1.2374374450902457
Validation loss: 2.549881913122919

Epoch: 6| Step: 11
Training loss: 1.678479847250402
Validation loss: 2.556087500024004

Epoch: 6| Step: 12
Training loss: 2.052078737618453
Validation loss: 2.568009075841978

Epoch: 6| Step: 13
Training loss: 2.639085851535509
Validation loss: 2.535920578446982

Epoch: 262| Step: 0
Training loss: 1.516456533204628
Validation loss: 2.560474594754408

Epoch: 6| Step: 1
Training loss: 1.8837994406628327
Validation loss: 2.580512095745702

Epoch: 6| Step: 2
Training loss: 1.774398341762707
Validation loss: 2.609615227183983

Epoch: 6| Step: 3
Training loss: 1.867951942920259
Validation loss: 2.6112541745211777

Epoch: 6| Step: 4
Training loss: 2.048052150814836
Validation loss: 2.585839342827564

Epoch: 6| Step: 5
Training loss: 1.5565116570437831
Validation loss: 2.6062241555806844

Epoch: 6| Step: 6
Training loss: 1.825686793236532
Validation loss: 2.612158280476109

Epoch: 6| Step: 7
Training loss: 1.691224896793751
Validation loss: 2.614183106427333

Epoch: 6| Step: 8
Training loss: 1.7353630344610609
Validation loss: 2.614392950734308

Epoch: 6| Step: 9
Training loss: 2.0135791657322892
Validation loss: 2.615409535871298

Epoch: 6| Step: 10
Training loss: 1.7518639855475775
Validation loss: 2.607184631608265

Epoch: 6| Step: 11
Training loss: 1.3335655526754095
Validation loss: 2.5950504714164486

Epoch: 6| Step: 12
Training loss: 1.4124393315072328
Validation loss: 2.6024344624748226

Epoch: 6| Step: 13
Training loss: 1.457831932339043
Validation loss: 2.6090766491046926

Epoch: 263| Step: 0
Training loss: 1.8237874666879557
Validation loss: 2.6006988576904377

Epoch: 6| Step: 1
Training loss: 1.4933253239235211
Validation loss: 2.578469610814753

Epoch: 6| Step: 2
Training loss: 1.274762266098173
Validation loss: 2.580336935501027

Epoch: 6| Step: 3
Training loss: 1.4110882075562798
Validation loss: 2.5595926418553407

Epoch: 6| Step: 4
Training loss: 1.5066811858521303
Validation loss: 2.549468942501652

Epoch: 6| Step: 5
Training loss: 2.505558795696606
Validation loss: 2.521012929242498

Epoch: 6| Step: 6
Training loss: 1.6455372974685896
Validation loss: 2.5486755981748246

Epoch: 6| Step: 7
Training loss: 1.77647361834988
Validation loss: 2.5595279258518047

Epoch: 6| Step: 8
Training loss: 1.8563290819989458
Validation loss: 2.5750918567018712

Epoch: 6| Step: 9
Training loss: 2.109009209458568
Validation loss: 2.55965874037292

Epoch: 6| Step: 10
Training loss: 1.5929962320468782
Validation loss: 2.555449006850524

Epoch: 6| Step: 11
Training loss: 1.5917128464688641
Validation loss: 2.5631281465253424

Epoch: 6| Step: 12
Training loss: 1.221554585858401
Validation loss: 2.597572059694968

Epoch: 6| Step: 13
Training loss: 1.6310813524316077
Validation loss: 2.617156442510893

Epoch: 264| Step: 0
Training loss: 1.675112433005023
Validation loss: 2.5843169398647396

Epoch: 6| Step: 1
Training loss: 0.6828648414016812
Validation loss: 2.5631936947908978

Epoch: 6| Step: 2
Training loss: 1.6206017172627187
Validation loss: 2.5670884642656335

Epoch: 6| Step: 3
Training loss: 2.060312208941992
Validation loss: 2.565953881096808

Epoch: 6| Step: 4
Training loss: 1.5792880918309051
Validation loss: 2.55666443891319

Epoch: 6| Step: 5
Training loss: 1.3605943231799815
Validation loss: 2.551814371032599

Epoch: 6| Step: 6
Training loss: 2.132174218214841
Validation loss: 2.5559710262167536

Epoch: 6| Step: 7
Training loss: 1.811092882838242
Validation loss: 2.5764300311183366

Epoch: 6| Step: 8
Training loss: 1.6859414709572964
Validation loss: 2.5918094172192294

Epoch: 6| Step: 9
Training loss: 1.932603000397965
Validation loss: 2.6301869283800365

Epoch: 6| Step: 10
Training loss: 1.7165849400790942
Validation loss: 2.637332295109955

Epoch: 6| Step: 11
Training loss: 1.4553560746746506
Validation loss: 2.6343253208739377

Epoch: 6| Step: 12
Training loss: 2.1587330991683116
Validation loss: 2.6500194748325208

Epoch: 6| Step: 13
Training loss: 1.445748917958044
Validation loss: 2.625822856318242

Epoch: 265| Step: 0
Training loss: 1.2963440049313295
Validation loss: 2.610326770110935

Epoch: 6| Step: 1
Training loss: 1.5520891876451655
Validation loss: 2.594580600238787

Epoch: 6| Step: 2
Training loss: 1.6161681570055604
Validation loss: 2.6057262694041263

Epoch: 6| Step: 3
Training loss: 1.9422418956550682
Validation loss: 2.594002521753736

Epoch: 6| Step: 4
Training loss: 1.9210865295200001
Validation loss: 2.604852264395952

Epoch: 6| Step: 5
Training loss: 1.9284518219931073
Validation loss: 2.607804866750526

Epoch: 6| Step: 6
Training loss: 1.617560007435591
Validation loss: 2.60611117870113

Epoch: 6| Step: 7
Training loss: 0.9061705455808099
Validation loss: 2.6206722954700448

Epoch: 6| Step: 8
Training loss: 1.6054533055066127
Validation loss: 2.6205384534728466

Epoch: 6| Step: 9
Training loss: 1.4975588325572438
Validation loss: 2.621049608856212

Epoch: 6| Step: 10
Training loss: 1.5143852275734453
Validation loss: 2.598769348232238

Epoch: 6| Step: 11
Training loss: 1.7915501519693733
Validation loss: 2.5726364844736893

Epoch: 6| Step: 12
Training loss: 1.8456099875227434
Validation loss: 2.560185237074054

Epoch: 6| Step: 13
Training loss: 2.3447064292008375
Validation loss: 2.5541940983875335

Epoch: 266| Step: 0
Training loss: 1.69608110153423
Validation loss: 2.563459897379266

Epoch: 6| Step: 1
Training loss: 1.8699642586989853
Validation loss: 2.5909047281369473

Epoch: 6| Step: 2
Training loss: 1.8714142526871282
Validation loss: 2.587292863654433

Epoch: 6| Step: 3
Training loss: 1.5786875864529775
Validation loss: 2.6105717825129733

Epoch: 6| Step: 4
Training loss: 1.4564960713881923
Validation loss: 2.5828013543868398

Epoch: 6| Step: 5
Training loss: 2.0245073354959846
Validation loss: 2.5756600975182247

Epoch: 6| Step: 6
Training loss: 1.4646209140403814
Validation loss: 2.590628671115945

Epoch: 6| Step: 7
Training loss: 1.675668423640282
Validation loss: 2.5994654670379798

Epoch: 6| Step: 8
Training loss: 1.6342555336113762
Validation loss: 2.624205867634347

Epoch: 6| Step: 9
Training loss: 1.7510284399122682
Validation loss: 2.6267026408009744

Epoch: 6| Step: 10
Training loss: 1.7979975635397487
Validation loss: 2.5979260519411302

Epoch: 6| Step: 11
Training loss: 1.7612896923306112
Validation loss: 2.605059945421751

Epoch: 6| Step: 12
Training loss: 1.4494560438151516
Validation loss: 2.613377658399764

Epoch: 6| Step: 13
Training loss: 1.8455906102031325
Validation loss: 2.617453712781002

Epoch: 267| Step: 0
Training loss: 2.043522776066788
Validation loss: 2.608601729232745

Epoch: 6| Step: 1
Training loss: 1.4740446714674034
Validation loss: 2.587367206685383

Epoch: 6| Step: 2
Training loss: 1.5319989766598066
Validation loss: 2.5970924823509858

Epoch: 6| Step: 3
Training loss: 1.2915434111987347
Validation loss: 2.6364449609025704

Epoch: 6| Step: 4
Training loss: 1.979808750067509
Validation loss: 2.6537753116274487

Epoch: 6| Step: 5
Training loss: 1.8942036453622826
Validation loss: 2.6861415891707607

Epoch: 6| Step: 6
Training loss: 1.8689874887267084
Validation loss: 2.7361293264155795

Epoch: 6| Step: 7
Training loss: 1.3761031320701889
Validation loss: 2.717509797662704

Epoch: 6| Step: 8
Training loss: 1.4454494926894326
Validation loss: 2.6179511606493504

Epoch: 6| Step: 9
Training loss: 2.0452439893376124
Validation loss: 2.6108751548930775

Epoch: 6| Step: 10
Training loss: 1.787444469949849
Validation loss: 2.5588077673899137

Epoch: 6| Step: 11
Training loss: 1.3291806681661862
Validation loss: 2.516088680559569

Epoch: 6| Step: 12
Training loss: 1.5998110242347185
Validation loss: 2.5276259438642406

Epoch: 6| Step: 13
Training loss: 1.2664345401002082
Validation loss: 2.522928680168852

Epoch: 268| Step: 0
Training loss: 1.8832751453604235
Validation loss: 2.5382654587047826

Epoch: 6| Step: 1
Training loss: 1.6616610539889012
Validation loss: 2.535599972764138

Epoch: 6| Step: 2
Training loss: 2.082166141341494
Validation loss: 2.537353560459727

Epoch: 6| Step: 3
Training loss: 1.3285470628481757
Validation loss: 2.5610562020528844

Epoch: 6| Step: 4
Training loss: 1.871370681306196
Validation loss: 2.567919929197777

Epoch: 6| Step: 5
Training loss: 1.6499073291532773
Validation loss: 2.5898248115015012

Epoch: 6| Step: 6
Training loss: 2.076161999109272
Validation loss: 2.623439150931525

Epoch: 6| Step: 7
Training loss: 1.4921458772776
Validation loss: 2.673067571432968

Epoch: 6| Step: 8
Training loss: 1.5521587720454681
Validation loss: 2.734963849910795

Epoch: 6| Step: 9
Training loss: 1.5145175466544274
Validation loss: 2.7352358333486366

Epoch: 6| Step: 10
Training loss: 1.7265024994656135
Validation loss: 2.7643231182221872

Epoch: 6| Step: 11
Training loss: 1.4441786158720937
Validation loss: 2.716193465683132

Epoch: 6| Step: 12
Training loss: 1.4155370284950257
Validation loss: 2.6516717359101314

Epoch: 6| Step: 13
Training loss: 1.2233159537124585
Validation loss: 2.614999719741026

Epoch: 269| Step: 0
Training loss: 1.666285288409153
Validation loss: 2.5815525562807347

Epoch: 6| Step: 1
Training loss: 1.1724818375081547
Validation loss: 2.592923851803358

Epoch: 6| Step: 2
Training loss: 1.3634152934023167
Validation loss: 2.5615507989506052

Epoch: 6| Step: 3
Training loss: 1.3506589747034448
Validation loss: 2.5606039131982663

Epoch: 6| Step: 4
Training loss: 1.272112385109555
Validation loss: 2.564321556321678

Epoch: 6| Step: 5
Training loss: 2.080764814762944
Validation loss: 2.574264463967085

Epoch: 6| Step: 6
Training loss: 1.7199377637515227
Validation loss: 2.571960135572548

Epoch: 6| Step: 7
Training loss: 1.7103977135720596
Validation loss: 2.5938495152845804

Epoch: 6| Step: 8
Training loss: 1.8496235541794155
Validation loss: 2.5870051479830876

Epoch: 6| Step: 9
Training loss: 1.5274313196703198
Validation loss: 2.601634830059519

Epoch: 6| Step: 10
Training loss: 1.8133247077727397
Validation loss: 2.620879906475424

Epoch: 6| Step: 11
Training loss: 1.4517031039991077
Validation loss: 2.642314134969245

Epoch: 6| Step: 12
Training loss: 1.9137085879359466
Validation loss: 2.6803010053908882

Epoch: 6| Step: 13
Training loss: 1.5902108183437011
Validation loss: 2.710768383217408

Epoch: 270| Step: 0
Training loss: 2.0242339816416632
Validation loss: 2.708249120294376

Epoch: 6| Step: 1
Training loss: 1.074422144274333
Validation loss: 2.6185991364432266

Epoch: 6| Step: 2
Training loss: 1.4973206432095776
Validation loss: 2.5960509621343157

Epoch: 6| Step: 3
Training loss: 1.2617432205142018
Validation loss: 2.5826467785308247

Epoch: 6| Step: 4
Training loss: 1.535709038912406
Validation loss: 2.5567984881843646

Epoch: 6| Step: 5
Training loss: 1.6774720241072867
Validation loss: 2.550721202092605

Epoch: 6| Step: 6
Training loss: 2.190063173785103
Validation loss: 2.5459230205138983

Epoch: 6| Step: 7
Training loss: 1.8098709507244894
Validation loss: 2.5438487125450697

Epoch: 6| Step: 8
Training loss: 1.378455761166075
Validation loss: 2.5542804982991507

Epoch: 6| Step: 9
Training loss: 1.82717929734512
Validation loss: 2.573022970157672

Epoch: 6| Step: 10
Training loss: 1.4245628690332937
Validation loss: 2.5689067680063835

Epoch: 6| Step: 11
Training loss: 1.1589275494032965
Validation loss: 2.6185308631548523

Epoch: 6| Step: 12
Training loss: 1.5055615319809452
Validation loss: 2.6472166054892776

Epoch: 6| Step: 13
Training loss: 2.2761808537596955
Validation loss: 2.6867602742798393

Epoch: 271| Step: 0
Training loss: 1.2137577317499368
Validation loss: 2.7149164510715824

Epoch: 6| Step: 1
Training loss: 1.5760410259251407
Validation loss: 2.7312532630233175

Epoch: 6| Step: 2
Training loss: 1.6428882791400015
Validation loss: 2.720193830544246

Epoch: 6| Step: 3
Training loss: 1.581417162355981
Validation loss: 2.6927084012474953

Epoch: 6| Step: 4
Training loss: 1.6372322242134154
Validation loss: 2.620948739199855

Epoch: 6| Step: 5
Training loss: 1.6108385116696524
Validation loss: 2.5634291850300612

Epoch: 6| Step: 6
Training loss: 1.0762152965945166
Validation loss: 2.553961625226905

Epoch: 6| Step: 7
Training loss: 1.4816719741783442
Validation loss: 2.5310890433200837

Epoch: 6| Step: 8
Training loss: 2.2033154560850874
Validation loss: 2.523604500470021

Epoch: 6| Step: 9
Training loss: 1.645710646808855
Validation loss: 2.5309405383910994

Epoch: 6| Step: 10
Training loss: 1.4989654629210611
Validation loss: 2.542863781438287

Epoch: 6| Step: 11
Training loss: 1.9615303754280244
Validation loss: 2.565624161408967

Epoch: 6| Step: 12
Training loss: 1.8202673124672293
Validation loss: 2.596272488953538

Epoch: 6| Step: 13
Training loss: 1.3952368225558072
Validation loss: 2.6060607840683154

Epoch: 272| Step: 0
Training loss: 1.525633417752495
Validation loss: 2.6201084587773638

Epoch: 6| Step: 1
Training loss: 1.6011527677104627
Validation loss: 2.610952551705384

Epoch: 6| Step: 2
Training loss: 1.6509503199902558
Validation loss: 2.613503184993444

Epoch: 6| Step: 3
Training loss: 1.1890787371655929
Validation loss: 2.5655937807349205

Epoch: 6| Step: 4
Training loss: 1.4525153409111642
Validation loss: 2.548981688679374

Epoch: 6| Step: 5
Training loss: 1.8414488834823832
Validation loss: 2.5674891630528887

Epoch: 6| Step: 6
Training loss: 1.3543641264320103
Validation loss: 2.57180346820081

Epoch: 6| Step: 7
Training loss: 1.8824489764914287
Validation loss: 2.6013411989755646

Epoch: 6| Step: 8
Training loss: 1.8301897045469129
Validation loss: 2.611884604270069

Epoch: 6| Step: 9
Training loss: 1.7838719128099574
Validation loss: 2.6180079489643933

Epoch: 6| Step: 10
Training loss: 1.5317280081640678
Validation loss: 2.627405483500037

Epoch: 6| Step: 11
Training loss: 1.8323933908382888
Validation loss: 2.6405516797093997

Epoch: 6| Step: 12
Training loss: 0.9659455838169072
Validation loss: 2.6170322362974887

Epoch: 6| Step: 13
Training loss: 1.0735515395088735
Validation loss: 2.59216928579562

Epoch: 273| Step: 0
Training loss: 1.2614863981888793
Validation loss: 2.5875038721991808

Epoch: 6| Step: 1
Training loss: 1.3128682028783267
Validation loss: 2.5986176306779303

Epoch: 6| Step: 2
Training loss: 1.6387597516291308
Validation loss: 2.615233818205531

Epoch: 6| Step: 3
Training loss: 1.1409288811547489
Validation loss: 2.600167517317844

Epoch: 6| Step: 4
Training loss: 1.9330826517345008
Validation loss: 2.5871197390616874

Epoch: 6| Step: 5
Training loss: 1.5649529086209502
Validation loss: 2.590428763792222

Epoch: 6| Step: 6
Training loss: 1.5963084311309657
Validation loss: 2.587329753046348

Epoch: 6| Step: 7
Training loss: 1.7966617623558887
Validation loss: 2.5801418853897697

Epoch: 6| Step: 8
Training loss: 1.7714306740155026
Validation loss: 2.5650795429389386

Epoch: 6| Step: 9
Training loss: 1.539677763208007
Validation loss: 2.5468320386826364

Epoch: 6| Step: 10
Training loss: 1.7169281059858819
Validation loss: 2.5481386284231564

Epoch: 6| Step: 11
Training loss: 1.5501047960356187
Validation loss: 2.5533556979452507

Epoch: 6| Step: 12
Training loss: 1.2266360704262003
Validation loss: 2.5507868186767912

Epoch: 6| Step: 13
Training loss: 1.0279787951000516
Validation loss: 2.576481616253329

Epoch: 274| Step: 0
Training loss: 1.4434598028322707
Validation loss: 2.601405662177686

Epoch: 6| Step: 1
Training loss: 1.7624182824203432
Validation loss: 2.5839615361357997

Epoch: 6| Step: 2
Training loss: 1.5715636777389825
Validation loss: 2.5763513772970423

Epoch: 6| Step: 3
Training loss: 1.2765948698872756
Validation loss: 2.587954208759991

Epoch: 6| Step: 4
Training loss: 1.2726457158654394
Validation loss: 2.5824464359884662

Epoch: 6| Step: 5
Training loss: 1.9611746959926606
Validation loss: 2.574493406995347

Epoch: 6| Step: 6
Training loss: 1.852456243309697
Validation loss: 2.5752747462506655

Epoch: 6| Step: 7
Training loss: 1.0273324944057254
Validation loss: 2.548836783010673

Epoch: 6| Step: 8
Training loss: 1.0634341901424442
Validation loss: 2.548163305523659

Epoch: 6| Step: 9
Training loss: 1.3608616559238198
Validation loss: 2.5874465768831665

Epoch: 6| Step: 10
Training loss: 1.8522162591057247
Validation loss: 2.585701304393748

Epoch: 6| Step: 11
Training loss: 1.5565247534460254
Validation loss: 2.567380674619798

Epoch: 6| Step: 12
Training loss: 1.4892313970505664
Validation loss: 2.60296203775238

Epoch: 6| Step: 13
Training loss: 1.6604134394073076
Validation loss: 2.5914500150670885

Epoch: 275| Step: 0
Training loss: 1.4565555726700732
Validation loss: 2.577108671717179

Epoch: 6| Step: 1
Training loss: 1.73582645201849
Validation loss: 2.5674610680750156

Epoch: 6| Step: 2
Training loss: 1.524550750097885
Validation loss: 2.5416964016981667

Epoch: 6| Step: 3
Training loss: 1.6985875853875019
Validation loss: 2.546636758886518

Epoch: 6| Step: 4
Training loss: 1.663734582819538
Validation loss: 2.564838295493993

Epoch: 6| Step: 5
Training loss: 1.5060775341526726
Validation loss: 2.6058130493253993

Epoch: 6| Step: 6
Training loss: 1.354611436232995
Validation loss: 2.5920799938967742

Epoch: 6| Step: 7
Training loss: 1.6370289947794252
Validation loss: 2.628340012832421

Epoch: 6| Step: 8
Training loss: 1.1425127059597275
Validation loss: 2.6063205387892854

Epoch: 6| Step: 9
Training loss: 1.4162349136505215
Validation loss: 2.604086831786705

Epoch: 6| Step: 10
Training loss: 1.4780287148727949
Validation loss: 2.5809983356620156

Epoch: 6| Step: 11
Training loss: 1.5495612969523649
Validation loss: 2.5668155657606384

Epoch: 6| Step: 12
Training loss: 1.4454530389864069
Validation loss: 2.5784805604549015

Epoch: 6| Step: 13
Training loss: 1.4297872206299984
Validation loss: 2.5868957060788653

Epoch: 276| Step: 0
Training loss: 0.9834554706843156
Validation loss: 2.5961460137013184

Epoch: 6| Step: 1
Training loss: 1.944487431217534
Validation loss: 2.586911241111777

Epoch: 6| Step: 2
Training loss: 1.4953215276910004
Validation loss: 2.6127565659377154

Epoch: 6| Step: 3
Training loss: 1.520465475386015
Validation loss: 2.585910290505934

Epoch: 6| Step: 4
Training loss: 1.4596756161937139
Validation loss: 2.596453135194258

Epoch: 6| Step: 5
Training loss: 1.6490530157548426
Validation loss: 2.585505786411598

Epoch: 6| Step: 6
Training loss: 1.0739127538254583
Validation loss: 2.5905986890685444

Epoch: 6| Step: 7
Training loss: 1.9475896292201356
Validation loss: 2.60664995249283

Epoch: 6| Step: 8
Training loss: 1.5517498229813202
Validation loss: 2.606996865972452

Epoch: 6| Step: 9
Training loss: 1.7128816471712769
Validation loss: 2.6134709478008715

Epoch: 6| Step: 10
Training loss: 1.3536866535501322
Validation loss: 2.6377629420257676

Epoch: 6| Step: 11
Training loss: 1.3646750771158218
Validation loss: 2.605562370782841

Epoch: 6| Step: 12
Training loss: 1.12505001380798
Validation loss: 2.6039005863887956

Epoch: 6| Step: 13
Training loss: 0.6291171839710011
Validation loss: 2.6101344565947238

Epoch: 277| Step: 0
Training loss: 1.3121068456454483
Validation loss: 2.6176960905991655

Epoch: 6| Step: 1
Training loss: 2.0171373002050252
Validation loss: 2.612317197990343

Epoch: 6| Step: 2
Training loss: 1.0108363600641292
Validation loss: 2.5963351150389524

Epoch: 6| Step: 3
Training loss: 1.559138076305337
Validation loss: 2.5796799321987613

Epoch: 6| Step: 4
Training loss: 1.3820341689195963
Validation loss: 2.582173177932544

Epoch: 6| Step: 5
Training loss: 1.542093303860859
Validation loss: 2.571733809054603

Epoch: 6| Step: 6
Training loss: 1.1282310182414574
Validation loss: 2.578596647841532

Epoch: 6| Step: 7
Training loss: 1.3824797838881757
Validation loss: 2.5967388157990974

Epoch: 6| Step: 8
Training loss: 1.5804025060071414
Validation loss: 2.606665766143874

Epoch: 6| Step: 9
Training loss: 1.5959990844437117
Validation loss: 2.6124052942679956

Epoch: 6| Step: 10
Training loss: 1.2986747020081848
Validation loss: 2.608564322007232

Epoch: 6| Step: 11
Training loss: 1.4868398179088635
Validation loss: 2.610677436192551

Epoch: 6| Step: 12
Training loss: 1.459347435897178
Validation loss: 2.608066383227363

Epoch: 6| Step: 13
Training loss: 1.4807974015261018
Validation loss: 2.5902501192696197

Epoch: 278| Step: 0
Training loss: 1.1873915271405977
Validation loss: 2.579616968355868

Epoch: 6| Step: 1
Training loss: 1.8982648103764976
Validation loss: 2.55591681245293

Epoch: 6| Step: 2
Training loss: 1.931492629133672
Validation loss: 2.556913158665928

Epoch: 6| Step: 3
Training loss: 1.234479972142312
Validation loss: 2.568311610472337

Epoch: 6| Step: 4
Training loss: 1.2253546143123837
Validation loss: 2.5900093084717524

Epoch: 6| Step: 5
Training loss: 1.045146939291353
Validation loss: 2.5976424806612184

Epoch: 6| Step: 6
Training loss: 1.3235995214879315
Validation loss: 2.60682577770433

Epoch: 6| Step: 7
Training loss: 1.7040072614488215
Validation loss: 2.6124456949620485

Epoch: 6| Step: 8
Training loss: 1.2975678489012188
Validation loss: 2.6535610972118535

Epoch: 6| Step: 9
Training loss: 1.5680934732855352
Validation loss: 2.670660197916913

Epoch: 6| Step: 10
Training loss: 1.2895045591749315
Validation loss: 2.651166515544093

Epoch: 6| Step: 11
Training loss: 1.16352903700178
Validation loss: 2.6679139264734397

Epoch: 6| Step: 12
Training loss: 1.6511539296713054
Validation loss: 2.6140807228862246

Epoch: 6| Step: 13
Training loss: 1.2078982205587285
Validation loss: 2.6357287494067454

Epoch: 279| Step: 0
Training loss: 1.211078069588087
Validation loss: 2.577490429734598

Epoch: 6| Step: 1
Training loss: 1.2989048067560052
Validation loss: 2.595970724270202

Epoch: 6| Step: 2
Training loss: 1.6776851340407481
Validation loss: 2.581536173692026

Epoch: 6| Step: 3
Training loss: 1.364601173963717
Validation loss: 2.589003002465792

Epoch: 6| Step: 4
Training loss: 1.2719033952772218
Validation loss: 2.5860672978178783

Epoch: 6| Step: 5
Training loss: 1.1935469609495655
Validation loss: 2.5968591730870916

Epoch: 6| Step: 6
Training loss: 1.5316428634210801
Validation loss: 2.631779783631806

Epoch: 6| Step: 7
Training loss: 1.3366405131967458
Validation loss: 2.613859131166107

Epoch: 6| Step: 8
Training loss: 1.6656800051655043
Validation loss: 2.6024945307980882

Epoch: 6| Step: 9
Training loss: 1.1828792417132334
Validation loss: 2.6056508464643744

Epoch: 6| Step: 10
Training loss: 1.2970522104547326
Validation loss: 2.569383493410227

Epoch: 6| Step: 11
Training loss: 1.2242461765627664
Validation loss: 2.5387883651575653

Epoch: 6| Step: 12
Training loss: 1.9288451174646861
Validation loss: 2.568929280662898

Epoch: 6| Step: 13
Training loss: 1.8528272598664386
Validation loss: 2.5676250694283507

Epoch: 280| Step: 0
Training loss: 1.4645257630118744
Validation loss: 2.569637310265735

Epoch: 6| Step: 1
Training loss: 1.387884847863561
Validation loss: 2.5862122992484

Epoch: 6| Step: 2
Training loss: 1.0011512566689702
Validation loss: 2.6038370848439225

Epoch: 6| Step: 3
Training loss: 0.917660665555048
Validation loss: 2.603519945790575

Epoch: 6| Step: 4
Training loss: 0.9583856768756571
Validation loss: 2.634935953783496

Epoch: 6| Step: 5
Training loss: 1.7328924767738967
Validation loss: 2.6456098858620893

Epoch: 6| Step: 6
Training loss: 1.4133422872121755
Validation loss: 2.6605158602186694

Epoch: 6| Step: 7
Training loss: 1.4793029059767393
Validation loss: 2.654233257859333

Epoch: 6| Step: 8
Training loss: 1.6704186486968058
Validation loss: 2.635920805699242

Epoch: 6| Step: 9
Training loss: 1.7827701439870212
Validation loss: 2.603707114412894

Epoch: 6| Step: 10
Training loss: 1.5568300751736164
Validation loss: 2.593965333909664

Epoch: 6| Step: 11
Training loss: 1.082090190287474
Validation loss: 2.5762004153341542

Epoch: 6| Step: 12
Training loss: 1.323347181821055
Validation loss: 2.575537382920608

Epoch: 6| Step: 13
Training loss: 1.866678974701404
Validation loss: 2.5718159992702767

Epoch: 281| Step: 0
Training loss: 1.3203780028216876
Validation loss: 2.5726228841612904

Epoch: 6| Step: 1
Training loss: 1.4006466172680883
Validation loss: 2.5796517086228734

Epoch: 6| Step: 2
Training loss: 1.3427332202784117
Validation loss: 2.597779615163562

Epoch: 6| Step: 3
Training loss: 1.1098019490243967
Validation loss: 2.5969455345976593

Epoch: 6| Step: 4
Training loss: 1.3549246891671947
Validation loss: 2.606239838038233

Epoch: 6| Step: 5
Training loss: 1.2057163026369255
Validation loss: 2.6136834367777517

Epoch: 6| Step: 6
Training loss: 1.5060265592991555
Validation loss: 2.6013532110494375

Epoch: 6| Step: 7
Training loss: 1.3575499988712847
Validation loss: 2.592372791075303

Epoch: 6| Step: 8
Training loss: 1.1416724634139388
Validation loss: 2.5894171923823808

Epoch: 6| Step: 9
Training loss: 1.2564266934609674
Validation loss: 2.590041452646965

Epoch: 6| Step: 10
Training loss: 1.1873679840590623
Validation loss: 2.587455204750359

Epoch: 6| Step: 11
Training loss: 1.2870012854426678
Validation loss: 2.6151406024743333

Epoch: 6| Step: 12
Training loss: 2.02436224231192
Validation loss: 2.613628748716829

Epoch: 6| Step: 13
Training loss: 1.9617101963089165
Validation loss: 2.614995707125234

Epoch: 282| Step: 0
Training loss: 1.0470749962916657
Validation loss: 2.6104925310996605

Epoch: 6| Step: 1
Training loss: 1.2548422484020187
Validation loss: 2.621150703007645

Epoch: 6| Step: 2
Training loss: 1.407425156292252
Validation loss: 2.6121123748425776

Epoch: 6| Step: 3
Training loss: 1.5279543697524256
Validation loss: 2.6189909724446228

Epoch: 6| Step: 4
Training loss: 1.589962816583355
Validation loss: 2.5958183760083613

Epoch: 6| Step: 5
Training loss: 1.4539070076097484
Validation loss: 2.6223878520739805

Epoch: 6| Step: 6
Training loss: 1.3471649601271225
Validation loss: 2.6042684391603164

Epoch: 6| Step: 7
Training loss: 1.5859301336709313
Validation loss: 2.625134377231201

Epoch: 6| Step: 8
Training loss: 1.1464013974577218
Validation loss: 2.6251738198230417

Epoch: 6| Step: 9
Training loss: 1.136749739077026
Validation loss: 2.6057075486621137

Epoch: 6| Step: 10
Training loss: 1.4610797996373104
Validation loss: 2.659825431276126

Epoch: 6| Step: 11
Training loss: 1.4535267592395538
Validation loss: 2.658589102761989

Epoch: 6| Step: 12
Training loss: 1.5799617842386382
Validation loss: 2.615983785442106

Epoch: 6| Step: 13
Training loss: 1.126335464012281
Validation loss: 2.6061011242484673

Epoch: 283| Step: 0
Training loss: 1.557068348398121
Validation loss: 2.5714335792718668

Epoch: 6| Step: 1
Training loss: 0.43002482958011234
Validation loss: 2.5528193410552684

Epoch: 6| Step: 2
Training loss: 1.4935986302504876
Validation loss: 2.5657998704388953

Epoch: 6| Step: 3
Training loss: 1.4394125447447323
Validation loss: 2.559312790695302

Epoch: 6| Step: 4
Training loss: 0.9054922355917187
Validation loss: 2.547094053200236

Epoch: 6| Step: 5
Training loss: 1.1206696668532146
Validation loss: 2.5745755081184365

Epoch: 6| Step: 6
Training loss: 0.9150726409906714
Validation loss: 2.5713705351379743

Epoch: 6| Step: 7
Training loss: 1.3460595443727852
Validation loss: 2.599208603630875

Epoch: 6| Step: 8
Training loss: 1.5026679948266655
Validation loss: 2.6174782505932566

Epoch: 6| Step: 9
Training loss: 1.5241997792418864
Validation loss: 2.6278771660552898

Epoch: 6| Step: 10
Training loss: 1.7360242270875461
Validation loss: 2.646065284600625

Epoch: 6| Step: 11
Training loss: 1.4924667656295698
Validation loss: 2.607209929788329

Epoch: 6| Step: 12
Training loss: 1.647626198087129
Validation loss: 2.59781924216039

Epoch: 6| Step: 13
Training loss: 1.450681621559161
Validation loss: 2.607836617577531

Epoch: 284| Step: 0
Training loss: 1.5643193143656327
Validation loss: 2.5767378261247953

Epoch: 6| Step: 1
Training loss: 1.1031959273146268
Validation loss: 2.565367156375106

Epoch: 6| Step: 2
Training loss: 1.0153510677941233
Validation loss: 2.5713924639244214

Epoch: 6| Step: 3
Training loss: 1.3245364457901871
Validation loss: 2.570778115953075

Epoch: 6| Step: 4
Training loss: 1.3631603985317517
Validation loss: 2.5670697663441975

Epoch: 6| Step: 5
Training loss: 1.301260965687686
Validation loss: 2.595934166045546

Epoch: 6| Step: 6
Training loss: 1.7895648367669375
Validation loss: 2.5882227874899737

Epoch: 6| Step: 7
Training loss: 1.0970417080777215
Validation loss: 2.5900487841355373

Epoch: 6| Step: 8
Training loss: 1.1467381575018456
Validation loss: 2.599216379733381

Epoch: 6| Step: 9
Training loss: 1.3050317823990318
Validation loss: 2.602321719064919

Epoch: 6| Step: 10
Training loss: 1.8639621090455458
Validation loss: 2.610179864186971

Epoch: 6| Step: 11
Training loss: 1.2141940719419566
Validation loss: 2.6305071735402423

Epoch: 6| Step: 12
Training loss: 1.0930808609022318
Validation loss: 2.6271880289742673

Epoch: 6| Step: 13
Training loss: 1.1148971341670337
Validation loss: 2.5973563338875922

Epoch: 285| Step: 0
Training loss: 1.770382303880179
Validation loss: 2.6081412821967573

Epoch: 6| Step: 1
Training loss: 1.2059565330440707
Validation loss: 2.5845952198740867

Epoch: 6| Step: 2
Training loss: 1.1609061543685577
Validation loss: 2.57797295254704

Epoch: 6| Step: 3
Training loss: 1.0253349943056613
Validation loss: 2.595311945490491

Epoch: 6| Step: 4
Training loss: 1.2727202285224872
Validation loss: 2.5875163876703797

Epoch: 6| Step: 5
Training loss: 1.2254693086003465
Validation loss: 2.6071471401349835

Epoch: 6| Step: 6
Training loss: 1.3338313315136323
Validation loss: 2.613466215774433

Epoch: 6| Step: 7
Training loss: 1.0382832064298018
Validation loss: 2.61810627389488

Epoch: 6| Step: 8
Training loss: 1.4189083464730616
Validation loss: 2.620249016931315

Epoch: 6| Step: 9
Training loss: 0.9569378242823493
Validation loss: 2.6152771429307857

Epoch: 6| Step: 10
Training loss: 1.2293808745033927
Validation loss: 2.6270000116436867

Epoch: 6| Step: 11
Training loss: 1.2353101157974329
Validation loss: 2.634410584566008

Epoch: 6| Step: 12
Training loss: 1.982606715713097
Validation loss: 2.630494980537065

Epoch: 6| Step: 13
Training loss: 1.161933539415362
Validation loss: 2.634582262602003

Epoch: 286| Step: 0
Training loss: 1.2869658556560748
Validation loss: 2.6215802040463725

Epoch: 6| Step: 1
Training loss: 1.0616447147832677
Validation loss: 2.6311212395295063

Epoch: 6| Step: 2
Training loss: 1.165468889679589
Validation loss: 2.6151878469630807

Epoch: 6| Step: 3
Training loss: 1.1877139049417857
Validation loss: 2.5860254118926984

Epoch: 6| Step: 4
Training loss: 0.8607517658252092
Validation loss: 2.595976292542635

Epoch: 6| Step: 5
Training loss: 1.4265642916113477
Validation loss: 2.5744148115122463

Epoch: 6| Step: 6
Training loss: 1.6714539042149519
Validation loss: 2.5944461533209826

Epoch: 6| Step: 7
Training loss: 1.5260064790420678
Validation loss: 2.5748184603255875

Epoch: 6| Step: 8
Training loss: 1.0527642693459554
Validation loss: 2.5863981353127175

Epoch: 6| Step: 9
Training loss: 1.1934734982926996
Validation loss: 2.584644035402889

Epoch: 6| Step: 10
Training loss: 1.0860839305922776
Validation loss: 2.59227797399003

Epoch: 6| Step: 11
Training loss: 1.601067368800153
Validation loss: 2.580516665666727

Epoch: 6| Step: 12
Training loss: 1.473458473808711
Validation loss: 2.602497177681224

Epoch: 6| Step: 13
Training loss: 1.365285673255551
Validation loss: 2.591302530678217

Epoch: 287| Step: 0
Training loss: 1.4921950095422132
Validation loss: 2.59568801295611

Epoch: 6| Step: 1
Training loss: 1.2991688216955986
Validation loss: 2.6124492237800894

Epoch: 6| Step: 2
Training loss: 1.4978495123413078
Validation loss: 2.61874878593783

Epoch: 6| Step: 3
Training loss: 0.931373861895562
Validation loss: 2.6247849627819337

Epoch: 6| Step: 4
Training loss: 0.8610238642913159
Validation loss: 2.6349585084352594

Epoch: 6| Step: 5
Training loss: 1.932468402796697
Validation loss: 2.632179553944466

Epoch: 6| Step: 6
Training loss: 1.4347565220420202
Validation loss: 2.657476925742651

Epoch: 6| Step: 7
Training loss: 0.9797224570917215
Validation loss: 2.6464531362850003

Epoch: 6| Step: 8
Training loss: 1.5361650952186312
Validation loss: 2.615594257047581

Epoch: 6| Step: 9
Training loss: 1.400484856024854
Validation loss: 2.63852220314531

Epoch: 6| Step: 10
Training loss: 1.125305240335435
Validation loss: 2.6181346361693754

Epoch: 6| Step: 11
Training loss: 1.0366925050105593
Validation loss: 2.5984959528994116

Epoch: 6| Step: 12
Training loss: 0.9238703841046488
Validation loss: 2.596232754415261

Epoch: 6| Step: 13
Training loss: 0.9270016959317855
Validation loss: 2.605792375333443

Epoch: 288| Step: 0
Training loss: 1.1328800575895195
Validation loss: 2.6031606664684763

Epoch: 6| Step: 1
Training loss: 1.2949781218635883
Validation loss: 2.594139412860703

Epoch: 6| Step: 2
Training loss: 1.2672668921345134
Validation loss: 2.6078443532071733

Epoch: 6| Step: 3
Training loss: 1.3494375646733487
Validation loss: 2.6059942678387347

Epoch: 6| Step: 4
Training loss: 1.415265914814032
Validation loss: 2.6150726780808817

Epoch: 6| Step: 5
Training loss: 1.1021121121683066
Validation loss: 2.6233608545478386

Epoch: 6| Step: 6
Training loss: 0.9582656062423056
Validation loss: 2.6235356062368846

Epoch: 6| Step: 7
Training loss: 1.0910493478777183
Validation loss: 2.6130619146790153

Epoch: 6| Step: 8
Training loss: 1.0611387396228609
Validation loss: 2.608709146106716

Epoch: 6| Step: 9
Training loss: 1.1688047243249966
Validation loss: 2.6420685196924865

Epoch: 6| Step: 10
Training loss: 1.7734305091753733
Validation loss: 2.6403707979109265

Epoch: 6| Step: 11
Training loss: 1.5136411602226487
Validation loss: 2.6109436293516466

Epoch: 6| Step: 12
Training loss: 1.1532323482344233
Validation loss: 2.6174220756765076

Epoch: 6| Step: 13
Training loss: 1.2061177472760234
Validation loss: 2.6089350016432054

Epoch: 289| Step: 0
Training loss: 1.1574655278059394
Validation loss: 2.6275118633316343

Epoch: 6| Step: 1
Training loss: 0.8653233742848625
Validation loss: 2.6247629174804703

Epoch: 6| Step: 2
Training loss: 1.8711305746066422
Validation loss: 2.617060486293958

Epoch: 6| Step: 3
Training loss: 1.105624292437045
Validation loss: 2.6240259620369843

Epoch: 6| Step: 4
Training loss: 1.1926927468337831
Validation loss: 2.6296754599193424

Epoch: 6| Step: 5
Training loss: 1.2759842944060569
Validation loss: 2.6514068074192276

Epoch: 6| Step: 6
Training loss: 0.7471068529156066
Validation loss: 2.6557603533147707

Epoch: 6| Step: 7
Training loss: 1.249935529953656
Validation loss: 2.6673053859699873

Epoch: 6| Step: 8
Training loss: 1.6581322393104754
Validation loss: 2.6744867894203157

Epoch: 6| Step: 9
Training loss: 1.0055291383714415
Validation loss: 2.6543438479962878

Epoch: 6| Step: 10
Training loss: 1.1602297159175505
Validation loss: 2.64974850114951

Epoch: 6| Step: 11
Training loss: 1.3819072799328547
Validation loss: 2.648007183354938

Epoch: 6| Step: 12
Training loss: 1.1219934448791882
Validation loss: 2.6391788169759134

Epoch: 6| Step: 13
Training loss: 1.1223214900037035
Validation loss: 2.6372872043441276

Epoch: 290| Step: 0
Training loss: 1.347351039657506
Validation loss: 2.6339927898510775

Epoch: 6| Step: 1
Training loss: 1.5201378717133962
Validation loss: 2.6411902884529956

Epoch: 6| Step: 2
Training loss: 1.2811865907190656
Validation loss: 2.6561114309457428

Epoch: 6| Step: 3
Training loss: 0.7435852140709022
Validation loss: 2.655591639195225

Epoch: 6| Step: 4
Training loss: 1.184716828068007
Validation loss: 2.6540807727647624

Epoch: 6| Step: 5
Training loss: 1.426577996026701
Validation loss: 2.645342961542326

Epoch: 6| Step: 6
Training loss: 0.9498703215582113
Validation loss: 2.6387208180929873

Epoch: 6| Step: 7
Training loss: 1.2528436739766617
Validation loss: 2.64692671952741

Epoch: 6| Step: 8
Training loss: 1.5945550717747592
Validation loss: 2.6345668325396447

Epoch: 6| Step: 9
Training loss: 1.1996017987463257
Validation loss: 2.609112263652203

Epoch: 6| Step: 10
Training loss: 0.9202292671842349
Validation loss: 2.5923275101639303

Epoch: 6| Step: 11
Training loss: 1.3028386887818524
Validation loss: 2.5980456190950063

Epoch: 6| Step: 12
Training loss: 0.8171212382831793
Validation loss: 2.601817550556017

Epoch: 6| Step: 13
Training loss: 1.1945353456156285
Validation loss: 2.5770843294830654

Epoch: 291| Step: 0
Training loss: 1.2669957590912835
Validation loss: 2.5881154574063516

Epoch: 6| Step: 1
Training loss: 0.8487960605735756
Validation loss: 2.598053947313774

Epoch: 6| Step: 2
Training loss: 1.1246527029782503
Validation loss: 2.6042368033203713

Epoch: 6| Step: 3
Training loss: 1.3144321751731785
Validation loss: 2.616801963232142

Epoch: 6| Step: 4
Training loss: 0.9029964051877407
Validation loss: 2.629670199415179

Epoch: 6| Step: 5
Training loss: 1.6243282543588058
Validation loss: 2.632061727330651

Epoch: 6| Step: 6
Training loss: 1.321562451867522
Validation loss: 2.641136194222703

Epoch: 6| Step: 7
Training loss: 1.5610660076224896
Validation loss: 2.6485485726723637

Epoch: 6| Step: 8
Training loss: 1.3140734369319496
Validation loss: 2.650496801923664

Epoch: 6| Step: 9
Training loss: 1.2040792866894785
Validation loss: 2.650356061352179

Epoch: 6| Step: 10
Training loss: 1.3108454675389682
Validation loss: 2.6364577020379163

Epoch: 6| Step: 11
Training loss: 0.8832422746352327
Validation loss: 2.6190102599448886

Epoch: 6| Step: 12
Training loss: 0.911677354201367
Validation loss: 2.6189500751131027

Epoch: 6| Step: 13
Training loss: 0.6578141373276438
Validation loss: 2.5932999803779966

Epoch: 292| Step: 0
Training loss: 1.7263004570174219
Validation loss: 2.596968021367763

Epoch: 6| Step: 1
Training loss: 1.294378060006172
Validation loss: 2.598310477912231

Epoch: 6| Step: 2
Training loss: 0.7358060245551384
Validation loss: 2.608561489638384

Epoch: 6| Step: 3
Training loss: 1.2169973046077824
Validation loss: 2.6022278615017065

Epoch: 6| Step: 4
Training loss: 0.9337276538284037
Validation loss: 2.5894335300603846

Epoch: 6| Step: 5
Training loss: 1.1600032410083088
Validation loss: 2.6163320422519374

Epoch: 6| Step: 6
Training loss: 1.308547016277208
Validation loss: 2.6223554000249

Epoch: 6| Step: 7
Training loss: 1.2172398136047238
Validation loss: 2.6146027487842174

Epoch: 6| Step: 8
Training loss: 1.3067130167113619
Validation loss: 2.6139235553675406

Epoch: 6| Step: 9
Training loss: 1.0155430100431482
Validation loss: 2.614539233603331

Epoch: 6| Step: 10
Training loss: 0.9228498832243319
Validation loss: 2.594685232323994

Epoch: 6| Step: 11
Training loss: 0.938360518665298
Validation loss: 2.603995667452606

Epoch: 6| Step: 12
Training loss: 1.3381423156558694
Validation loss: 2.5997086876860127

Epoch: 6| Step: 13
Training loss: 1.1288802728007092
Validation loss: 2.609058919273407

Epoch: 293| Step: 0
Training loss: 0.7819050141084604
Validation loss: 2.6338030010637525

Epoch: 6| Step: 1
Training loss: 1.2760075571081542
Validation loss: 2.6465071455706175

Epoch: 6| Step: 2
Training loss: 1.3055226742321502
Validation loss: 2.628700857198303

Epoch: 6| Step: 3
Training loss: 1.070356047920821
Validation loss: 2.62301450196329

Epoch: 6| Step: 4
Training loss: 1.2448735017358579
Validation loss: 2.6365198101800167

Epoch: 6| Step: 5
Training loss: 1.324444596827866
Validation loss: 2.6075951401639985

Epoch: 6| Step: 6
Training loss: 1.142251514149107
Validation loss: 2.591439279499881

Epoch: 6| Step: 7
Training loss: 1.5993658865594094
Validation loss: 2.5977057487489783

Epoch: 6| Step: 8
Training loss: 0.5797393014799941
Validation loss: 2.58801313373818

Epoch: 6| Step: 9
Training loss: 0.9581309636994835
Validation loss: 2.5920841834175383

Epoch: 6| Step: 10
Training loss: 1.722478325407084
Validation loss: 2.593121730890262

Epoch: 6| Step: 11
Training loss: 0.9731697657290208
Validation loss: 2.6117952085089553

Epoch: 6| Step: 12
Training loss: 0.8691222456799682
Validation loss: 2.6237105842116994

Epoch: 6| Step: 13
Training loss: 1.3735407108068456
Validation loss: 2.6357570300161357

Epoch: 294| Step: 0
Training loss: 1.1915854397458177
Validation loss: 2.6319945016380193

Epoch: 6| Step: 1
Training loss: 0.9655291636293472
Validation loss: 2.6279601338095513

Epoch: 6| Step: 2
Training loss: 1.2346896000030587
Validation loss: 2.632902718156357

Epoch: 6| Step: 3
Training loss: 1.0615717254857677
Validation loss: 2.6318905267912442

Epoch: 6| Step: 4
Training loss: 1.5349035467604035
Validation loss: 2.632082881654895

Epoch: 6| Step: 5
Training loss: 1.0851687447780873
Validation loss: 2.6345213718608465

Epoch: 6| Step: 6
Training loss: 1.5213715458806354
Validation loss: 2.6317514846362053

Epoch: 6| Step: 7
Training loss: 1.0401445648696828
Validation loss: 2.6343109646631064

Epoch: 6| Step: 8
Training loss: 1.046097993735266
Validation loss: 2.6435867483942497

Epoch: 6| Step: 9
Training loss: 1.2945174424258685
Validation loss: 2.6175809586207226

Epoch: 6| Step: 10
Training loss: 0.9948476738999902
Validation loss: 2.635410184478148

Epoch: 6| Step: 11
Training loss: 1.0899194397159824
Validation loss: 2.6367785321761614

Epoch: 6| Step: 12
Training loss: 1.1228220308208814
Validation loss: 2.6157434286608567

Epoch: 6| Step: 13
Training loss: 0.5728536195454698
Validation loss: 2.596770282353379

Epoch: 295| Step: 0
Training loss: 0.9825901016387454
Validation loss: 2.6064216494881265

Epoch: 6| Step: 1
Training loss: 1.6485192879730628
Validation loss: 2.6096108614719826

Epoch: 6| Step: 2
Training loss: 0.8860834677605329
Validation loss: 2.60606447499253

Epoch: 6| Step: 3
Training loss: 1.1922365390995968
Validation loss: 2.6511928358026173

Epoch: 6| Step: 4
Training loss: 1.2405566660320912
Validation loss: 2.6390806612741247

Epoch: 6| Step: 5
Training loss: 1.3157381801896983
Validation loss: 2.6383537912684956

Epoch: 6| Step: 6
Training loss: 1.113733514306262
Validation loss: 2.645782848752106

Epoch: 6| Step: 7
Training loss: 1.0926244121044129
Validation loss: 2.6373726507718223

Epoch: 6| Step: 8
Training loss: 1.0743141825507052
Validation loss: 2.6554229568354915

Epoch: 6| Step: 9
Training loss: 1.2475009733207743
Validation loss: 2.6371179203338273

Epoch: 6| Step: 10
Training loss: 0.8850013132678272
Validation loss: 2.641409985251943

Epoch: 6| Step: 11
Training loss: 1.0191909982288239
Validation loss: 2.6514650445123533

Epoch: 6| Step: 12
Training loss: 1.1609326985030146
Validation loss: 2.650173112102711

Epoch: 6| Step: 13
Training loss: 1.1911764454824296
Validation loss: 2.630752181379124

Epoch: 296| Step: 0
Training loss: 1.320585730456717
Validation loss: 2.643244423310271

Epoch: 6| Step: 1
Training loss: 0.859957826822318
Validation loss: 2.62758831251634

Epoch: 6| Step: 2
Training loss: 0.7045373718645488
Validation loss: 2.623693007011627

Epoch: 6| Step: 3
Training loss: 1.10171621345874
Validation loss: 2.612267035940474

Epoch: 6| Step: 4
Training loss: 1.3020757242616214
Validation loss: 2.6258472221974323

Epoch: 6| Step: 5
Training loss: 0.8745822590504361
Validation loss: 2.6234027204366734

Epoch: 6| Step: 6
Training loss: 1.7111701981277168
Validation loss: 2.6179130428877517

Epoch: 6| Step: 7
Training loss: 1.4446297347402224
Validation loss: 2.6092314120330546

Epoch: 6| Step: 8
Training loss: 1.258958708915463
Validation loss: 2.6253345821229757

Epoch: 6| Step: 9
Training loss: 1.2072904240643236
Validation loss: 2.6083775884129277

Epoch: 6| Step: 10
Training loss: 1.141939842416723
Validation loss: 2.585967736841474

Epoch: 6| Step: 11
Training loss: 0.9230084644127892
Validation loss: 2.5795289523512457

Epoch: 6| Step: 12
Training loss: 0.7591146705762618
Validation loss: 2.595566452666363

Epoch: 6| Step: 13
Training loss: 0.9631856037062065
Validation loss: 2.5955301030813938

Epoch: 297| Step: 0
Training loss: 1.2384623205608043
Validation loss: 2.59294462839826

Epoch: 6| Step: 1
Training loss: 0.8511589213869726
Validation loss: 2.578794841936677

Epoch: 6| Step: 2
Training loss: 1.1991397694974786
Validation loss: 2.575489483752456

Epoch: 6| Step: 3
Training loss: 1.0271706671013014
Validation loss: 2.612054672689989

Epoch: 6| Step: 4
Training loss: 1.1640193342359735
Validation loss: 2.6147999804670454

Epoch: 6| Step: 5
Training loss: 1.0090990947232048
Validation loss: 2.6361305067390646

Epoch: 6| Step: 6
Training loss: 1.119322650479778
Validation loss: 2.6336217998214373

Epoch: 6| Step: 7
Training loss: 1.822282110305255
Validation loss: 2.6674415128559654

Epoch: 6| Step: 8
Training loss: 0.6617231564786042
Validation loss: 2.6687177776740985

Epoch: 6| Step: 9
Training loss: 1.2818045927787134
Validation loss: 2.6629301325420145

Epoch: 6| Step: 10
Training loss: 1.2815755104980262
Validation loss: 2.6673212696401585

Epoch: 6| Step: 11
Training loss: 0.6879443120070708
Validation loss: 2.6656326133610553

Epoch: 6| Step: 12
Training loss: 1.0507682033707366
Validation loss: 2.6438761060607106

Epoch: 6| Step: 13
Training loss: 0.7795558489574876
Validation loss: 2.649519686395309

Epoch: 298| Step: 0
Training loss: 0.7502513305438713
Validation loss: 2.646982548190003

Epoch: 6| Step: 1
Training loss: 1.1819577130565189
Validation loss: 2.654144012029432

Epoch: 6| Step: 2
Training loss: 0.7211740500725514
Validation loss: 2.643794996307821

Epoch: 6| Step: 3
Training loss: 1.4725308554611118
Validation loss: 2.653402377441916

Epoch: 6| Step: 4
Training loss: 1.081133859383526
Validation loss: 2.652292667952798

Epoch: 6| Step: 5
Training loss: 0.9416125059728226
Validation loss: 2.61860604238654

Epoch: 6| Step: 6
Training loss: 1.771393526517288
Validation loss: 2.6406307503155317

Epoch: 6| Step: 7
Training loss: 1.1313150966735244
Validation loss: 2.649918431864581

Epoch: 6| Step: 8
Training loss: 0.9977656078221834
Validation loss: 2.629613599585216

Epoch: 6| Step: 9
Training loss: 1.23321589843012
Validation loss: 2.610701276664875

Epoch: 6| Step: 10
Training loss: 0.7718989163913625
Validation loss: 2.6286645805719786

Epoch: 6| Step: 11
Training loss: 1.31561418469983
Validation loss: 2.6178481420210096

Epoch: 6| Step: 12
Training loss: 0.8503666451629847
Validation loss: 2.5904747523338503

Epoch: 6| Step: 13
Training loss: 1.0084426447568955
Validation loss: 2.6086244300063868

Epoch: 299| Step: 0
Training loss: 0.8840881853090653
Validation loss: 2.606771821049332

Epoch: 6| Step: 1
Training loss: 1.0424366711745245
Validation loss: 2.6094439451184757

Epoch: 6| Step: 2
Training loss: 1.265107319768895
Validation loss: 2.6218641734671846

Epoch: 6| Step: 3
Training loss: 1.723838832743306
Validation loss: 2.626886995307141

Epoch: 6| Step: 4
Training loss: 1.0097734166920127
Validation loss: 2.6337649968899055

Epoch: 6| Step: 5
Training loss: 1.2775829219593928
Validation loss: 2.6522376972780943

Epoch: 6| Step: 6
Training loss: 1.143486301061509
Validation loss: 2.647568369667449

Epoch: 6| Step: 7
Training loss: 0.8998986346064363
Validation loss: 2.6439723616956585

Epoch: 6| Step: 8
Training loss: 0.9975634932806136
Validation loss: 2.6491225270195407

Epoch: 6| Step: 9
Training loss: 0.9597026985974781
Validation loss: 2.6265338336647917

Epoch: 6| Step: 10
Training loss: 1.087448495982589
Validation loss: 2.6340378693697803

Epoch: 6| Step: 11
Training loss: 0.9532689470498585
Validation loss: 2.623408618927728

Epoch: 6| Step: 12
Training loss: 0.9891255809078875
Validation loss: 2.6314644816708164

Epoch: 6| Step: 13
Training loss: 1.0133233619709643
Validation loss: 2.609789141424925

Epoch: 300| Step: 0
Training loss: 1.3640815986965467
Validation loss: 2.6000063338017205

Epoch: 6| Step: 1
Training loss: 0.9723398697530619
Validation loss: 2.618332539794302

Epoch: 6| Step: 2
Training loss: 1.4156301670948572
Validation loss: 2.60710123279872

Epoch: 6| Step: 3
Training loss: 0.8415292194867083
Validation loss: 2.610828846693312

Epoch: 6| Step: 4
Training loss: 0.8742648851427214
Validation loss: 2.605497679820593

Epoch: 6| Step: 5
Training loss: 0.8982921648648
Validation loss: 2.6025853379395514

Epoch: 6| Step: 6
Training loss: 0.6716789136894896
Validation loss: 2.590659511269047

Epoch: 6| Step: 7
Training loss: 1.0787543519287024
Validation loss: 2.5881974245636954

Epoch: 6| Step: 8
Training loss: 0.7995053803726285
Validation loss: 2.5898219051840172

Epoch: 6| Step: 9
Training loss: 1.0841533907156402
Validation loss: 2.604787504619347

Epoch: 6| Step: 10
Training loss: 0.9805667417882978
Validation loss: 2.6200421436054326

Epoch: 6| Step: 11
Training loss: 1.5587054143309282
Validation loss: 2.611570565780918

Epoch: 6| Step: 12
Training loss: 1.2462599592662245
Validation loss: 2.633556479086708

Epoch: 6| Step: 13
Training loss: 1.1410456887541633
Validation loss: 2.632828620974972

Epoch: 301| Step: 0
Training loss: 1.1666483991191856
Validation loss: 2.6443396317248204

Epoch: 6| Step: 1
Training loss: 1.1202834121567036
Validation loss: 2.672138543892072

Epoch: 6| Step: 2
Training loss: 0.8303513380219852
Validation loss: 2.6422441448831377

Epoch: 6| Step: 3
Training loss: 0.8391831749886803
Validation loss: 2.640387020805832

Epoch: 6| Step: 4
Training loss: 0.7719537779727395
Validation loss: 2.6230158829786303

Epoch: 6| Step: 5
Training loss: 1.1701686898098878
Validation loss: 2.607373021837114

Epoch: 6| Step: 6
Training loss: 1.250995430368544
Validation loss: 2.624430085255963

Epoch: 6| Step: 7
Training loss: 1.5355605352624313
Validation loss: 2.5826122626896457

Epoch: 6| Step: 8
Training loss: 0.9349843924540615
Validation loss: 2.5839121402007157

Epoch: 6| Step: 9
Training loss: 0.9243351712264195
Validation loss: 2.591122857075062

Epoch: 6| Step: 10
Training loss: 1.17093422320406
Validation loss: 2.6140497795158195

Epoch: 6| Step: 11
Training loss: 0.9821315814275116
Validation loss: 2.6104099696250667

Epoch: 6| Step: 12
Training loss: 1.1957960958143712
Validation loss: 2.601050620713502

Epoch: 6| Step: 13
Training loss: 1.0419951048276581
Validation loss: 2.60955255312198

Epoch: 302| Step: 0
Training loss: 1.2090414646948384
Validation loss: 2.590018468241338

Epoch: 6| Step: 1
Training loss: 0.9572760444060985
Validation loss: 2.6201152648548143

Epoch: 6| Step: 2
Training loss: 1.2449782589465703
Validation loss: 2.5937050752372888

Epoch: 6| Step: 3
Training loss: 0.6811613130149841
Validation loss: 2.6492450613144065

Epoch: 6| Step: 4
Training loss: 1.1628944630122255
Validation loss: 2.6631150654425264

Epoch: 6| Step: 5
Training loss: 1.0357445538612653
Validation loss: 2.6716068106598914

Epoch: 6| Step: 6
Training loss: 1.887708763552212
Validation loss: 2.6667239704691834

Epoch: 6| Step: 7
Training loss: 0.7943455812062512
Validation loss: 2.6720955635380976

Epoch: 6| Step: 8
Training loss: 1.0020552614738492
Validation loss: 2.683262493154101

Epoch: 6| Step: 9
Training loss: 0.9686636732461686
Validation loss: 2.6355633714076587

Epoch: 6| Step: 10
Training loss: 0.6514971144547167
Validation loss: 2.654261196428229

Epoch: 6| Step: 11
Training loss: 0.5443723635604206
Validation loss: 2.6362594942254036

Epoch: 6| Step: 12
Training loss: 1.0845471270264249
Validation loss: 2.606847847832717

Epoch: 6| Step: 13
Training loss: 1.0937740323287493
Validation loss: 2.59834057767611

Epoch: 303| Step: 0
Training loss: 1.0788369523208747
Validation loss: 2.583482281191388

Epoch: 6| Step: 1
Training loss: 1.3041313950681568
Validation loss: 2.6398182919627944

Epoch: 6| Step: 2
Training loss: 0.6677875830822062
Validation loss: 2.6415403900393737

Epoch: 6| Step: 3
Training loss: 0.9156330017156828
Validation loss: 2.669789422674566

Epoch: 6| Step: 4
Training loss: 0.4842554067822878
Validation loss: 2.687177302453082

Epoch: 6| Step: 5
Training loss: 1.2619138395577596
Validation loss: 2.6690196364743946

Epoch: 6| Step: 6
Training loss: 1.0071603601996713
Validation loss: 2.634737937505253

Epoch: 6| Step: 7
Training loss: 1.7023997031089695
Validation loss: 2.6093600978061042

Epoch: 6| Step: 8
Training loss: 0.9073817322645885
Validation loss: 2.576637192270363

Epoch: 6| Step: 9
Training loss: 1.2405400898124022
Validation loss: 2.570566510355154

Epoch: 6| Step: 10
Training loss: 0.834025969350271
Validation loss: 2.555758247820334

Epoch: 6| Step: 11
Training loss: 1.110206399921765
Validation loss: 2.565413747574218

Epoch: 6| Step: 12
Training loss: 1.1849955198951727
Validation loss: 2.595151006682733

Epoch: 6| Step: 13
Training loss: 0.9386181521113205
Validation loss: 2.6375655107362346

Epoch: 304| Step: 0
Training loss: 1.094271018046249
Validation loss: 2.6399117297887322

Epoch: 6| Step: 1
Training loss: 0.9637003312627593
Validation loss: 2.6459471113142006

Epoch: 6| Step: 2
Training loss: 1.0481369611117897
Validation loss: 2.643172167899912

Epoch: 6| Step: 3
Training loss: 0.8918739061676354
Validation loss: 2.6419797731256387

Epoch: 6| Step: 4
Training loss: 1.1025157618531276
Validation loss: 2.63230116089897

Epoch: 6| Step: 5
Training loss: 0.9235925353882337
Validation loss: 2.6228034600042776

Epoch: 6| Step: 6
Training loss: 1.0576001674025803
Validation loss: 2.602976425038235

Epoch: 6| Step: 7
Training loss: 1.1232903523433844
Validation loss: 2.5995763802155856

Epoch: 6| Step: 8
Training loss: 1.0647481806879024
Validation loss: 2.615595679225941

Epoch: 6| Step: 9
Training loss: 0.855811342243472
Validation loss: 2.6356352527738642

Epoch: 6| Step: 10
Training loss: 0.574792173393923
Validation loss: 2.636831378483447

Epoch: 6| Step: 11
Training loss: 1.3244229949708455
Validation loss: 2.6264657461360974

Epoch: 6| Step: 12
Training loss: 1.0345142604975195
Validation loss: 2.66644934824944

Epoch: 6| Step: 13
Training loss: 2.0354250915207217
Validation loss: 2.70846620774868

Epoch: 305| Step: 0
Training loss: 0.7634151251532046
Validation loss: 2.70706621508015

Epoch: 6| Step: 1
Training loss: 1.6320896282501534
Validation loss: 2.6965265722205367

Epoch: 6| Step: 2
Training loss: 0.506326996870157
Validation loss: 2.72173603713234

Epoch: 6| Step: 3
Training loss: 0.880135147543337
Validation loss: 2.6884690302692826

Epoch: 6| Step: 4
Training loss: 0.727280129048222
Validation loss: 2.6689352651860307

Epoch: 6| Step: 5
Training loss: 0.9786705457901106
Validation loss: 2.6292231102347685

Epoch: 6| Step: 6
Training loss: 1.0625837517435035
Validation loss: 2.611732395105517

Epoch: 6| Step: 7
Training loss: 1.2122146762320105
Validation loss: 2.5919317471631147

Epoch: 6| Step: 8
Training loss: 1.2281855638630574
Validation loss: 2.5640314619596314

Epoch: 6| Step: 9
Training loss: 1.0977265685014783
Validation loss: 2.549909249688929

Epoch: 6| Step: 10
Training loss: 1.1671762488868491
Validation loss: 2.5702885557031174

Epoch: 6| Step: 11
Training loss: 1.0784766687903462
Validation loss: 2.5634831169111036

Epoch: 6| Step: 12
Training loss: 0.7791467966684243
Validation loss: 2.5977914702664746

Epoch: 6| Step: 13
Training loss: 1.1517954928383305
Validation loss: 2.5985870704439074

Epoch: 306| Step: 0
Training loss: 0.6448501260496295
Validation loss: 2.6048495579025714

Epoch: 6| Step: 1
Training loss: 0.9877641553914467
Validation loss: 2.603822771233361

Epoch: 6| Step: 2
Training loss: 0.8407835559143421
Validation loss: 2.6386486583860997

Epoch: 6| Step: 3
Training loss: 1.0579587150732195
Validation loss: 2.61722225875682

Epoch: 6| Step: 4
Training loss: 0.8446580451122884
Validation loss: 2.6107582334783834

Epoch: 6| Step: 5
Training loss: 1.1217908121042537
Validation loss: 2.5949784241305207

Epoch: 6| Step: 6
Training loss: 1.2763039092392214
Validation loss: 2.605748738445903

Epoch: 6| Step: 7
Training loss: 1.0361339630206854
Validation loss: 2.6079200675797782

Epoch: 6| Step: 8
Training loss: 0.6966651874356179
Validation loss: 2.6046426573507153

Epoch: 6| Step: 9
Training loss: 1.0799259126824092
Validation loss: 2.6160079391694318

Epoch: 6| Step: 10
Training loss: 1.1634397441013444
Validation loss: 2.640451924496006

Epoch: 6| Step: 11
Training loss: 0.7747606461597611
Validation loss: 2.6531153424407536

Epoch: 6| Step: 12
Training loss: 1.5560808695001416
Validation loss: 2.66679791222379

Epoch: 6| Step: 13
Training loss: 0.6710216292506718
Validation loss: 2.6728392260042475

Epoch: 307| Step: 0
Training loss: 0.7941687012760109
Validation loss: 2.688159290365508

Epoch: 6| Step: 1
Training loss: 0.9710672413283703
Validation loss: 2.664301104384557

Epoch: 6| Step: 2
Training loss: 0.6599481243279431
Validation loss: 2.637962694809718

Epoch: 6| Step: 3
Training loss: 0.8529903095942643
Validation loss: 2.6131147250684377

Epoch: 6| Step: 4
Training loss: 1.2070736183211848
Validation loss: 2.61481312365139

Epoch: 6| Step: 5
Training loss: 0.892760410518404
Validation loss: 2.583640178262992

Epoch: 6| Step: 6
Training loss: 0.9995455603374962
Validation loss: 2.6009641352951576

Epoch: 6| Step: 7
Training loss: 1.6366698046082497
Validation loss: 2.61462472385194

Epoch: 6| Step: 8
Training loss: 0.8574525310623368
Validation loss: 2.60778566841138

Epoch: 6| Step: 9
Training loss: 1.0436672771817175
Validation loss: 2.641023576051551

Epoch: 6| Step: 10
Training loss: 0.8958608748763655
Validation loss: 2.6366737872946033

Epoch: 6| Step: 11
Training loss: 1.2072008131114227
Validation loss: 2.6564704914496717

Epoch: 6| Step: 12
Training loss: 0.9994595378454408
Validation loss: 2.6253972487854154

Epoch: 6| Step: 13
Training loss: 0.8454738949400783
Validation loss: 2.62099755206324

Epoch: 308| Step: 0
Training loss: 1.1989393871853102
Validation loss: 2.5709184793222026

Epoch: 6| Step: 1
Training loss: 0.976546935911129
Validation loss: 2.55297287854934

Epoch: 6| Step: 2
Training loss: 0.8986782912295809
Validation loss: 2.5187999613209975

Epoch: 6| Step: 3
Training loss: 0.7965185078579722
Validation loss: 2.5191665053437697

Epoch: 6| Step: 4
Training loss: 0.8350877453619864
Validation loss: 2.503941895309576

Epoch: 6| Step: 5
Training loss: 0.9163573711397486
Validation loss: 2.5278731015862195

Epoch: 6| Step: 6
Training loss: 0.9790227189004502
Validation loss: 2.570243327089002

Epoch: 6| Step: 7
Training loss: 0.8266864734117527
Validation loss: 2.6174553660763418

Epoch: 6| Step: 8
Training loss: 0.9688972545809694
Validation loss: 2.668213961325344

Epoch: 6| Step: 9
Training loss: 0.9976673935138651
Validation loss: 2.6815868572726016

Epoch: 6| Step: 10
Training loss: 0.9993542135723827
Validation loss: 2.6388312961904816

Epoch: 6| Step: 11
Training loss: 1.6835863861135358
Validation loss: 2.63398246710989

Epoch: 6| Step: 12
Training loss: 0.8975881127376123
Validation loss: 2.609839375658273

Epoch: 6| Step: 13
Training loss: 1.1526862718401556
Validation loss: 2.6115160779093505

Epoch: 309| Step: 0
Training loss: 0.9669275677131216
Validation loss: 2.604351956246334

Epoch: 6| Step: 1
Training loss: 0.7750745076080767
Validation loss: 2.601985746321059

Epoch: 6| Step: 2
Training loss: 1.7153628178501459
Validation loss: 2.606506092938715

Epoch: 6| Step: 3
Training loss: 0.6398687783959919
Validation loss: 2.6153091740638743

Epoch: 6| Step: 4
Training loss: 0.79462316650928
Validation loss: 2.6060019686036564

Epoch: 6| Step: 5
Training loss: 1.0824163419540105
Validation loss: 2.656740734654369

Epoch: 6| Step: 6
Training loss: 1.243433585245854
Validation loss: 2.6616422370802892

Epoch: 6| Step: 7
Training loss: 0.9462344505211636
Validation loss: 2.629637231334681

Epoch: 6| Step: 8
Training loss: 1.1053739581225588
Validation loss: 2.6182681623932473

Epoch: 6| Step: 9
Training loss: 1.0398206311299083
Validation loss: 2.630838743865979

Epoch: 6| Step: 10
Training loss: 0.9331121439472939
Validation loss: 2.6042132787327104

Epoch: 6| Step: 11
Training loss: 0.6000669144034082
Validation loss: 2.5780977513081176

Epoch: 6| Step: 12
Training loss: 0.9026490392755154
Validation loss: 2.566415517985093

Epoch: 6| Step: 13
Training loss: 0.3995208597454579
Validation loss: 2.5721021996115616

Epoch: 310| Step: 0
Training loss: 0.7770310352784625
Validation loss: 2.5760904178735378

Epoch: 6| Step: 1
Training loss: 0.8319515852780028
Validation loss: 2.626589333499529

Epoch: 6| Step: 2
Training loss: 1.9229945821740317
Validation loss: 2.6280411069847247

Epoch: 6| Step: 3
Training loss: 0.8536505341570125
Validation loss: 2.6421146907925945

Epoch: 6| Step: 4
Training loss: 0.7465559641127634
Validation loss: 2.6366987033630362

Epoch: 6| Step: 5
Training loss: 0.546390755018883
Validation loss: 2.682983492406784

Epoch: 6| Step: 6
Training loss: 0.7180037148546904
Validation loss: 2.6536221017341624

Epoch: 6| Step: 7
Training loss: 0.9022615403546893
Validation loss: 2.635457792248594

Epoch: 6| Step: 8
Training loss: 1.103407376811883
Validation loss: 2.649603734501426

Epoch: 6| Step: 9
Training loss: 0.7216473108857219
Validation loss: 2.640915393243713

Epoch: 6| Step: 10
Training loss: 0.947403541828579
Validation loss: 2.6316462191698045

Epoch: 6| Step: 11
Training loss: 1.0793627944901178
Validation loss: 2.6324922781897255

Epoch: 6| Step: 12
Training loss: 1.0103093054190246
Validation loss: 2.635226456879473

Epoch: 6| Step: 13
Training loss: 0.7142518307959806
Validation loss: 2.6133215993841095

Epoch: 311| Step: 0
Training loss: 0.9573680051654395
Validation loss: 2.6415956988095286

Epoch: 6| Step: 1
Training loss: 0.5308163499835141
Validation loss: 2.661456256412357

Epoch: 6| Step: 2
Training loss: 1.191886229839741
Validation loss: 2.644167160277632

Epoch: 6| Step: 3
Training loss: 0.9704355527340252
Validation loss: 2.642718292254685

Epoch: 6| Step: 4
Training loss: 1.7882934649888975
Validation loss: 2.638343356841735

Epoch: 6| Step: 5
Training loss: 0.7898464274526129
Validation loss: 2.627595412406232

Epoch: 6| Step: 6
Training loss: 1.0202552300309553
Validation loss: 2.6147914168461313

Epoch: 6| Step: 7
Training loss: 0.5491390230093326
Validation loss: 2.6280389301670057

Epoch: 6| Step: 8
Training loss: 0.301665307344005
Validation loss: 2.62237020784045

Epoch: 6| Step: 9
Training loss: 0.9631545380277949
Validation loss: 2.6344883598790254

Epoch: 6| Step: 10
Training loss: 0.7366736939326648
Validation loss: 2.630275673229127

Epoch: 6| Step: 11
Training loss: 1.1013920428912518
Validation loss: 2.6536687364728753

Epoch: 6| Step: 12
Training loss: 0.8587887585040577
Validation loss: 2.6450281821264126

Epoch: 6| Step: 13
Training loss: 0.9755883813470392
Validation loss: 2.650875019992721

Epoch: 312| Step: 0
Training loss: 1.1984214493175287
Validation loss: 2.6213147105848185

Epoch: 6| Step: 1
Training loss: 1.0092091899536557
Validation loss: 2.6170410183825603

Epoch: 6| Step: 2
Training loss: 0.8182100510301811
Validation loss: 2.6427926582929344

Epoch: 6| Step: 3
Training loss: 0.7145383422152569
Validation loss: 2.607936925846841

Epoch: 6| Step: 4
Training loss: 0.7959337846828776
Validation loss: 2.602577317270359

Epoch: 6| Step: 5
Training loss: 0.8356420404812345
Validation loss: 2.5921082621513305

Epoch: 6| Step: 6
Training loss: 0.5525357324170179
Validation loss: 2.616282466226062

Epoch: 6| Step: 7
Training loss: 0.7298040782915919
Validation loss: 2.5907006958828718

Epoch: 6| Step: 8
Training loss: 1.0080206604308608
Validation loss: 2.5759361732898096

Epoch: 6| Step: 9
Training loss: 0.8503073094723723
Validation loss: 2.59601451465537

Epoch: 6| Step: 10
Training loss: 1.6333213633792851
Validation loss: 2.583982841171221

Epoch: 6| Step: 11
Training loss: 1.0008622267017468
Validation loss: 2.6059679406521807

Epoch: 6| Step: 12
Training loss: 0.9303808111470326
Validation loss: 2.6144012582570735

Epoch: 6| Step: 13
Training loss: 0.9013834215150869
Validation loss: 2.6140757114816076

Epoch: 313| Step: 0
Training loss: 1.1674830214513603
Validation loss: 2.5909262867721115

Epoch: 6| Step: 1
Training loss: 0.6418864228923165
Validation loss: 2.6195645856635554

Epoch: 6| Step: 2
Training loss: 1.0958279081338433
Validation loss: 2.631804676872118

Epoch: 6| Step: 3
Training loss: 0.5660756428807955
Validation loss: 2.618092935245474

Epoch: 6| Step: 4
Training loss: 0.5005016194868992
Validation loss: 2.6346468037915884

Epoch: 6| Step: 5
Training loss: 1.0074480565881934
Validation loss: 2.6216589276447197

Epoch: 6| Step: 6
Training loss: 1.0295812224908483
Validation loss: 2.641919056763207

Epoch: 6| Step: 7
Training loss: 0.5713771915114191
Validation loss: 2.6516896941901513

Epoch: 6| Step: 8
Training loss: 0.81694976382783
Validation loss: 2.638287680604344

Epoch: 6| Step: 9
Training loss: 1.631704949555579
Validation loss: 2.625510962466941

Epoch: 6| Step: 10
Training loss: 1.0061788403482994
Validation loss: 2.618453633558035

Epoch: 6| Step: 11
Training loss: 0.9245945531626482
Validation loss: 2.621489625565468

Epoch: 6| Step: 12
Training loss: 0.8418273920249697
Validation loss: 2.617761198935383

Epoch: 6| Step: 13
Training loss: 0.8039546332892408
Validation loss: 2.605406583548115

Epoch: 314| Step: 0
Training loss: 0.9042688616704141
Validation loss: 2.60545070141544

Epoch: 6| Step: 1
Training loss: 0.7969362945918493
Validation loss: 2.582863422238693

Epoch: 6| Step: 2
Training loss: 0.9669724430232778
Validation loss: 2.5790654053035778

Epoch: 6| Step: 3
Training loss: 0.8042261226857887
Validation loss: 2.5963347714211373

Epoch: 6| Step: 4
Training loss: 0.8787409648186587
Validation loss: 2.605231335636691

Epoch: 6| Step: 5
Training loss: 0.6254584061860589
Validation loss: 2.592981741405076

Epoch: 6| Step: 6
Training loss: 1.15923393398963
Validation loss: 2.5966218601014073

Epoch: 6| Step: 7
Training loss: 0.7957202173568643
Validation loss: 2.5937549103246735

Epoch: 6| Step: 8
Training loss: 0.8850400722181541
Validation loss: 2.588337328622974

Epoch: 6| Step: 9
Training loss: 0.9147288184287397
Validation loss: 2.6046903452034096

Epoch: 6| Step: 10
Training loss: 1.639807579219539
Validation loss: 2.6350860180758318

Epoch: 6| Step: 11
Training loss: 0.65879295024522
Validation loss: 2.6388922982948557

Epoch: 6| Step: 12
Training loss: 0.8295034057059801
Validation loss: 2.6621843135359424

Epoch: 6| Step: 13
Training loss: 0.8495159930945965
Validation loss: 2.652403380079055

Epoch: 315| Step: 0
Training loss: 0.6915831689723698
Validation loss: 2.6330529197479344

Epoch: 6| Step: 1
Training loss: 0.4490736685620313
Validation loss: 2.609828359160217

Epoch: 6| Step: 2
Training loss: 0.846657723006622
Validation loss: 2.5729867325229607

Epoch: 6| Step: 3
Training loss: 0.9485803663063336
Validation loss: 2.554306159863945

Epoch: 6| Step: 4
Training loss: 1.7705154208373826
Validation loss: 2.562093582958787

Epoch: 6| Step: 5
Training loss: 0.6654624543493428
Validation loss: 2.5116648058925195

Epoch: 6| Step: 6
Training loss: 0.7722225472413743
Validation loss: 2.55412226267991

Epoch: 6| Step: 7
Training loss: 1.0286056832634387
Validation loss: 2.5935096397080866

Epoch: 6| Step: 8
Training loss: 0.7526338344829052
Validation loss: 2.6248050232495714

Epoch: 6| Step: 9
Training loss: 0.521876155829149
Validation loss: 2.653000674935446

Epoch: 6| Step: 10
Training loss: 1.2707509915717423
Validation loss: 2.682381367858595

Epoch: 6| Step: 11
Training loss: 1.028933437396625
Validation loss: 2.6672547471292387

Epoch: 6| Step: 12
Training loss: 0.9848149239995124
Validation loss: 2.6602107342065966

Epoch: 6| Step: 13
Training loss: 1.1979860313346262
Validation loss: 2.6589831136695268

Epoch: 316| Step: 0
Training loss: 0.8304838019484589
Validation loss: 2.631630592646289

Epoch: 6| Step: 1
Training loss: 0.6787692916264225
Validation loss: 2.6058476272778055

Epoch: 6| Step: 2
Training loss: 0.6550137819776684
Validation loss: 2.605158095290292

Epoch: 6| Step: 3
Training loss: 0.5839311454269586
Validation loss: 2.5978121918952417

Epoch: 6| Step: 4
Training loss: 0.895538961852607
Validation loss: 2.602905912985868

Epoch: 6| Step: 5
Training loss: 1.2086359609717787
Validation loss: 2.592311916606804

Epoch: 6| Step: 6
Training loss: 1.0425949283988007
Validation loss: 2.6079118485268262

Epoch: 6| Step: 7
Training loss: 0.895049066051066
Validation loss: 2.6105023830314393

Epoch: 6| Step: 8
Training loss: 0.7483219607054736
Validation loss: 2.6121108555676433

Epoch: 6| Step: 9
Training loss: 1.597010400335739
Validation loss: 2.603117122356811

Epoch: 6| Step: 10
Training loss: 1.020043547673076
Validation loss: 2.620730047057237

Epoch: 6| Step: 11
Training loss: 0.40763039085452174
Validation loss: 2.614564147834378

Epoch: 6| Step: 12
Training loss: 0.9852968773539463
Validation loss: 2.6174681692854667

Epoch: 6| Step: 13
Training loss: 0.7076575945510607
Validation loss: 2.608511480426519

Epoch: 317| Step: 0
Training loss: 0.7329383758256035
Validation loss: 2.607316729493499

Epoch: 6| Step: 1
Training loss: 0.9991335095038789
Validation loss: 2.610563354780936

Epoch: 6| Step: 2
Training loss: 0.5926463510947289
Validation loss: 2.624050550743859

Epoch: 6| Step: 3
Training loss: 1.190744685367607
Validation loss: 2.5887405306904743

Epoch: 6| Step: 4
Training loss: 0.9573382449657215
Validation loss: 2.6041227833321634

Epoch: 6| Step: 5
Training loss: 0.8187883659284486
Validation loss: 2.605248569980899

Epoch: 6| Step: 6
Training loss: 0.69159885460906
Validation loss: 2.5918775180362577

Epoch: 6| Step: 7
Training loss: 0.7653919176583521
Validation loss: 2.6053002064008313

Epoch: 6| Step: 8
Training loss: 1.693248705563965
Validation loss: 2.619027340971219

Epoch: 6| Step: 9
Training loss: 1.0061457846560204
Validation loss: 2.628813935496787

Epoch: 6| Step: 10
Training loss: 0.38395605749296463
Validation loss: 2.6438705441290757

Epoch: 6| Step: 11
Training loss: 0.7891674160844682
Validation loss: 2.678139441678068

Epoch: 6| Step: 12
Training loss: 0.9047934567296673
Validation loss: 2.7203507190715843

Epoch: 6| Step: 13
Training loss: 0.8248944879742398
Validation loss: 2.685598884325013

Epoch: 318| Step: 0
Training loss: 0.7981652678485858
Validation loss: 2.6604189937912635

Epoch: 6| Step: 1
Training loss: 0.42988193621063003
Validation loss: 2.635266711026725

Epoch: 6| Step: 2
Training loss: 1.6977591724330534
Validation loss: 2.6010414367147647

Epoch: 6| Step: 3
Training loss: 0.7417711395090189
Validation loss: 2.5973440661966745

Epoch: 6| Step: 4
Training loss: 0.9916111030292465
Validation loss: 2.5732184223968138

Epoch: 6| Step: 5
Training loss: 0.7912866198847639
Validation loss: 2.5975261696681136

Epoch: 6| Step: 6
Training loss: 0.7756245834263399
Validation loss: 2.578488937947148

Epoch: 6| Step: 7
Training loss: 0.8644996089305622
Validation loss: 2.608270961887617

Epoch: 6| Step: 8
Training loss: 0.8716399528854363
Validation loss: 2.6067887973800543

Epoch: 6| Step: 9
Training loss: 0.37657625007059764
Validation loss: 2.6199821683916715

Epoch: 6| Step: 10
Training loss: 0.7363028281644931
Validation loss: 2.6179258693194303

Epoch: 6| Step: 11
Training loss: 1.1601867671767574
Validation loss: 2.6243157161432262

Epoch: 6| Step: 12
Training loss: 0.9180217321811265
Validation loss: 2.6247699009706884

Epoch: 6| Step: 13
Training loss: 1.0415736665536295
Validation loss: 2.606911323241929

Epoch: 319| Step: 0
Training loss: 0.8657463401829436
Validation loss: 2.606511911640276

Epoch: 6| Step: 1
Training loss: 0.5960681484819155
Validation loss: 2.6042000421825895

Epoch: 6| Step: 2
Training loss: 0.750387409606431
Validation loss: 2.576643167969172

Epoch: 6| Step: 3
Training loss: 0.9450156005701943
Validation loss: 2.5795445446694996

Epoch: 6| Step: 4
Training loss: 0.9984609562322907
Validation loss: 2.5611408259664663

Epoch: 6| Step: 5
Training loss: 0.8288783119951241
Validation loss: 2.560226352161253

Epoch: 6| Step: 6
Training loss: 0.8495450751867245
Validation loss: 2.5937947697981913

Epoch: 6| Step: 7
Training loss: 0.5927489776843847
Validation loss: 2.5809431546832573

Epoch: 6| Step: 8
Training loss: 1.7658841103344216
Validation loss: 2.5936269779141115

Epoch: 6| Step: 9
Training loss: 0.7091287933468707
Validation loss: 2.611850394813776

Epoch: 6| Step: 10
Training loss: 0.751773882223632
Validation loss: 2.6191281030556888

Epoch: 6| Step: 11
Training loss: 0.779965145237099
Validation loss: 2.6204265980679744

Epoch: 6| Step: 12
Training loss: 0.4495086397989206
Validation loss: 2.6216549222876715

Epoch: 6| Step: 13
Training loss: 1.1190492283114812
Validation loss: 2.5876399628094364

Epoch: 320| Step: 0
Training loss: 0.6756820164846907
Validation loss: 2.5937008725201345

Epoch: 6| Step: 1
Training loss: 0.9152764630215788
Validation loss: 2.5591535759707895

Epoch: 6| Step: 2
Training loss: 0.6729125727439409
Validation loss: 2.577028004233097

Epoch: 6| Step: 3
Training loss: 0.6017378019072012
Validation loss: 2.5870943891039495

Epoch: 6| Step: 4
Training loss: 0.9320543438207909
Validation loss: 2.596205968806577

Epoch: 6| Step: 5
Training loss: 0.797661561415845
Validation loss: 2.6089532020146957

Epoch: 6| Step: 6
Training loss: 0.8059979480972865
Validation loss: 2.606626746211594

Epoch: 6| Step: 7
Training loss: 1.7389329695810367
Validation loss: 2.610073025464916

Epoch: 6| Step: 8
Training loss: 0.9440816953210872
Validation loss: 2.61876466553991

Epoch: 6| Step: 9
Training loss: 0.7734780349127917
Validation loss: 2.6512658183012

Epoch: 6| Step: 10
Training loss: 0.6499606478222932
Validation loss: 2.6582646874666973

Epoch: 6| Step: 11
Training loss: 1.293041077403138
Validation loss: 2.6439115698873046

Epoch: 6| Step: 12
Training loss: 0.5255621591077632
Validation loss: 2.6263514222323607

Epoch: 6| Step: 13
Training loss: 0.31370184578235505
Validation loss: 2.612850361229373

Epoch: 321| Step: 0
Training loss: 0.885591100826021
Validation loss: 2.623324080439948

Epoch: 6| Step: 1
Training loss: 0.8657683023208507
Validation loss: 2.623054259862832

Epoch: 6| Step: 2
Training loss: 0.8018068026816679
Validation loss: 2.612593143681105

Epoch: 6| Step: 3
Training loss: 0.8906231595739791
Validation loss: 2.63126497019624

Epoch: 6| Step: 4
Training loss: 0.689987969362724
Validation loss: 2.6072982866334793

Epoch: 6| Step: 5
Training loss: 0.7029062566643998
Validation loss: 2.627835211458298

Epoch: 6| Step: 6
Training loss: 0.6046304621643952
Validation loss: 2.60988838205755

Epoch: 6| Step: 7
Training loss: 1.0788455158793002
Validation loss: 2.594904921567717

Epoch: 6| Step: 8
Training loss: 0.5499191029616024
Validation loss: 2.592812186865562

Epoch: 6| Step: 9
Training loss: 1.6462226922182392
Validation loss: 2.6085521984248827

Epoch: 6| Step: 10
Training loss: 0.7442697728342803
Validation loss: 2.608112267186125

Epoch: 6| Step: 11
Training loss: 0.6105527988568684
Validation loss: 2.5836103438345437

Epoch: 6| Step: 12
Training loss: 0.8173961569951244
Validation loss: 2.5766547011978314

Epoch: 6| Step: 13
Training loss: 1.1404328902993859
Validation loss: 2.607171964726721

Epoch: 322| Step: 0
Training loss: 0.907665035857371
Validation loss: 2.5956001443716485

Epoch: 6| Step: 1
Training loss: 0.6176957560690658
Validation loss: 2.599332296530692

Epoch: 6| Step: 2
Training loss: 0.9795731485362809
Validation loss: 2.6178420371006745

Epoch: 6| Step: 3
Training loss: 0.6908029197636689
Validation loss: 2.6177289201636067

Epoch: 6| Step: 4
Training loss: 0.4783478111752114
Validation loss: 2.5939705165996125

Epoch: 6| Step: 5
Training loss: 0.5720376090993811
Validation loss: 2.5790032475374187

Epoch: 6| Step: 6
Training loss: 0.8312644469647783
Validation loss: 2.581817233343516

Epoch: 6| Step: 7
Training loss: 0.6058494847447773
Validation loss: 2.6184000002270267

Epoch: 6| Step: 8
Training loss: 0.7867484957423344
Validation loss: 2.5858530357234466

Epoch: 6| Step: 9
Training loss: 0.7254777008694139
Validation loss: 2.569104628932619

Epoch: 6| Step: 10
Training loss: 0.8972877775388005
Validation loss: 2.5792906914158986

Epoch: 6| Step: 11
Training loss: 1.8783602168955489
Validation loss: 2.5996927755062793

Epoch: 6| Step: 12
Training loss: 0.6997063923611223
Validation loss: 2.5841851052490385

Epoch: 6| Step: 13
Training loss: 0.7546454644985056
Validation loss: 2.58156303007987

Epoch: 323| Step: 0
Training loss: 0.7288791271204741
Validation loss: 2.580588034861479

Epoch: 6| Step: 1
Training loss: 0.6071136281246546
Validation loss: 2.56977070177606

Epoch: 6| Step: 2
Training loss: 0.87388406846453
Validation loss: 2.5770908244155075

Epoch: 6| Step: 3
Training loss: 0.7662571224360796
Validation loss: 2.5728949559639918

Epoch: 6| Step: 4
Training loss: 0.7411922809328583
Validation loss: 2.572405399439205

Epoch: 6| Step: 5
Training loss: 0.7682706315224392
Validation loss: 2.60622110426298

Epoch: 6| Step: 6
Training loss: 1.1209785854189613
Validation loss: 2.596548710131802

Epoch: 6| Step: 7
Training loss: 1.6578709569578436
Validation loss: 2.618531541627944

Epoch: 6| Step: 8
Training loss: 0.7331418986864815
Validation loss: 2.663880535384393

Epoch: 6| Step: 9
Training loss: 0.8841979034819185
Validation loss: 2.6894586870332255

Epoch: 6| Step: 10
Training loss: 0.7770121264794038
Validation loss: 2.6680677790700207

Epoch: 6| Step: 11
Training loss: 0.7610106086467724
Validation loss: 2.637459586955126

Epoch: 6| Step: 12
Training loss: 0.7177901285527449
Validation loss: 2.594487033762703

Epoch: 6| Step: 13
Training loss: 0.4574530195909784
Validation loss: 2.5772999656213833

Epoch: 324| Step: 0
Training loss: 0.9653303332547819
Validation loss: 2.5397551197211294

Epoch: 6| Step: 1
Training loss: 0.6639798281202327
Validation loss: 2.558824440767648

Epoch: 6| Step: 2
Training loss: 0.769956906710514
Validation loss: 2.560472241847539

Epoch: 6| Step: 3
Training loss: 0.6427024558698671
Validation loss: 2.5695961462230756

Epoch: 6| Step: 4
Training loss: 0.8606023520354856
Validation loss: 2.575574708437306

Epoch: 6| Step: 5
Training loss: 0.4906194929554926
Validation loss: 2.6141634616510956

Epoch: 6| Step: 6
Training loss: 0.7825336210809737
Validation loss: 2.618445994868865

Epoch: 6| Step: 7
Training loss: 1.0412708992938617
Validation loss: 2.603772318525414

Epoch: 6| Step: 8
Training loss: 0.5640724244657991
Validation loss: 2.6284843656913845

Epoch: 6| Step: 9
Training loss: 0.6208183349700771
Validation loss: 2.618216360690321

Epoch: 6| Step: 10
Training loss: 1.7918655226010756
Validation loss: 2.6386208168341776

Epoch: 6| Step: 11
Training loss: 0.9875637661590387
Validation loss: 2.6276074954439403

Epoch: 6| Step: 12
Training loss: 0.4367022222895647
Validation loss: 2.6185576093512895

Epoch: 6| Step: 13
Training loss: 0.4557023412892943
Validation loss: 2.6275611025985186

Epoch: 325| Step: 0
Training loss: 0.7314030185588146
Validation loss: 2.6412194062302823

Epoch: 6| Step: 1
Training loss: 0.9963466547622839
Validation loss: 2.6445502135718253

Epoch: 6| Step: 2
Training loss: 0.8643280173198413
Validation loss: 2.6545730470446753

Epoch: 6| Step: 3
Training loss: 1.5768666302023773
Validation loss: 2.674153297674997

Epoch: 6| Step: 4
Training loss: 0.680029618550839
Validation loss: 2.6792801776699853

Epoch: 6| Step: 5
Training loss: 1.005702626875623
Validation loss: 2.6645330063450414

Epoch: 6| Step: 6
Training loss: 0.7925063039125811
Validation loss: 2.68635877687774

Epoch: 6| Step: 7
Training loss: 0.7014724384774587
Validation loss: 2.6479434673845184

Epoch: 6| Step: 8
Training loss: 0.6475675331157968
Validation loss: 2.641506990706575

Epoch: 6| Step: 9
Training loss: 0.717701603415448
Validation loss: 2.646306066806951

Epoch: 6| Step: 10
Training loss: 0.610574226962629
Validation loss: 2.6305441371645375

Epoch: 6| Step: 11
Training loss: 0.6055190526924177
Validation loss: 2.6133777596847385

Epoch: 6| Step: 12
Training loss: 0.7615450147422408
Validation loss: 2.5914523715042885

Epoch: 6| Step: 13
Training loss: 0.5310903197018085
Validation loss: 2.5658322030027962

Epoch: 326| Step: 0
Training loss: 0.4127463710412811
Validation loss: 2.5889783215182014

Epoch: 6| Step: 1
Training loss: 0.7475937549138365
Validation loss: 2.570144737113098

Epoch: 6| Step: 2
Training loss: 0.7931391340338555
Validation loss: 2.576505289567123

Epoch: 6| Step: 3
Training loss: 1.8378454804830127
Validation loss: 2.607742314583198

Epoch: 6| Step: 4
Training loss: 0.9967524725254489
Validation loss: 2.582946491023379

Epoch: 6| Step: 5
Training loss: 0.6038322729125448
Validation loss: 2.6088932185262217

Epoch: 6| Step: 6
Training loss: 0.6540002862363883
Validation loss: 2.60658726934019

Epoch: 6| Step: 7
Training loss: 0.3589122737168112
Validation loss: 2.5965379354183553

Epoch: 6| Step: 8
Training loss: 0.7587496674865296
Validation loss: 2.6273177774912835

Epoch: 6| Step: 9
Training loss: 0.8758752396415687
Validation loss: 2.629915761905151

Epoch: 6| Step: 10
Training loss: 0.7030283119692032
Validation loss: 2.5892006366322273

Epoch: 6| Step: 11
Training loss: 0.5978329964377939
Validation loss: 2.5998430261483563

Epoch: 6| Step: 12
Training loss: 0.5956561210723844
Validation loss: 2.5860536759454775

Epoch: 6| Step: 13
Training loss: 1.037169258989391
Validation loss: 2.5748234132254804

Epoch: 327| Step: 0
Training loss: 0.49254971754305893
Validation loss: 2.562520522048694

Epoch: 6| Step: 1
Training loss: 0.6413883685315529
Validation loss: 2.5834007132003243

Epoch: 6| Step: 2
Training loss: 1.6214273500167826
Validation loss: 2.5770901758183027

Epoch: 6| Step: 3
Training loss: 0.7654276223628128
Validation loss: 2.617936431639944

Epoch: 6| Step: 4
Training loss: 0.4586793575933796
Validation loss: 2.611475419867213

Epoch: 6| Step: 5
Training loss: 0.7720234206975591
Validation loss: 2.638174449131684

Epoch: 6| Step: 6
Training loss: 1.0341033763305447
Validation loss: 2.6472411037176964

Epoch: 6| Step: 7
Training loss: 1.0310928340560375
Validation loss: 2.628960681690589

Epoch: 6| Step: 8
Training loss: 0.8707321511278431
Validation loss: 2.6312421247180158

Epoch: 6| Step: 9
Training loss: 0.436153075537158
Validation loss: 2.6236765797614967

Epoch: 6| Step: 10
Training loss: 0.5552794025112824
Validation loss: 2.6104888228669036

Epoch: 6| Step: 11
Training loss: 0.5134303174064988
Validation loss: 2.5901886856876173

Epoch: 6| Step: 12
Training loss: 0.7164461280764451
Validation loss: 2.568614639441581

Epoch: 6| Step: 13
Training loss: 1.1291765991468528
Validation loss: 2.560095804472555

Epoch: 328| Step: 0
Training loss: 0.6610715941988092
Validation loss: 2.576333187419425

Epoch: 6| Step: 1
Training loss: 0.7531050936652149
Validation loss: 2.5607506728394682

Epoch: 6| Step: 2
Training loss: 0.7935692528813426
Validation loss: 2.5641034009831927

Epoch: 6| Step: 3
Training loss: 0.9545165987524818
Validation loss: 2.560865585804098

Epoch: 6| Step: 4
Training loss: 0.6019658804599689
Validation loss: 2.5547631370353634

Epoch: 6| Step: 5
Training loss: 0.8020324608328988
Validation loss: 2.5856472232033743

Epoch: 6| Step: 6
Training loss: 0.8692473613906322
Validation loss: 2.606304357624858

Epoch: 6| Step: 7
Training loss: 0.7621635898720124
Validation loss: 2.6026124991845587

Epoch: 6| Step: 8
Training loss: 0.7543046126124369
Validation loss: 2.612102453411689

Epoch: 6| Step: 9
Training loss: 0.8448061866939213
Validation loss: 2.618959816919331

Epoch: 6| Step: 10
Training loss: 0.2938676902708889
Validation loss: 2.6430693893276507

Epoch: 6| Step: 11
Training loss: 0.8004824569395325
Validation loss: 2.61690757355219

Epoch: 6| Step: 12
Training loss: 1.5904636533554148
Validation loss: 2.6234848165947553

Epoch: 6| Step: 13
Training loss: 0.392379919471538
Validation loss: 2.6114398346030954

Epoch: 329| Step: 0
Training loss: 0.5351568625787724
Validation loss: 2.6260674411394755

Epoch: 6| Step: 1
Training loss: 0.7274189485055345
Validation loss: 2.588895635411075

Epoch: 6| Step: 2
Training loss: 0.42288616646714294
Validation loss: 2.5795090923578226

Epoch: 6| Step: 3
Training loss: 0.7636263704523355
Validation loss: 2.5708203909060163

Epoch: 6| Step: 4
Training loss: 0.8216057528561818
Validation loss: 2.5683929669492334

Epoch: 6| Step: 5
Training loss: 1.730879827372958
Validation loss: 2.587590430028291

Epoch: 6| Step: 6
Training loss: 0.6056277158694002
Validation loss: 2.5615634517337167

Epoch: 6| Step: 7
Training loss: 0.5682626491184357
Validation loss: 2.5684011288062534

Epoch: 6| Step: 8
Training loss: 0.6540886163213475
Validation loss: 2.599750772249704

Epoch: 6| Step: 9
Training loss: 0.4958911692389796
Validation loss: 2.601656148522606

Epoch: 6| Step: 10
Training loss: 0.7863102114475615
Validation loss: 2.6291495558316784

Epoch: 6| Step: 11
Training loss: 0.9534769815367994
Validation loss: 2.630141330589684

Epoch: 6| Step: 12
Training loss: 0.8334266530873338
Validation loss: 2.640118042460922

Epoch: 6| Step: 13
Training loss: 0.6538092774892569
Validation loss: 2.6273526471422217

Epoch: 330| Step: 0
Training loss: 1.5325473816658268
Validation loss: 2.633102256449029

Epoch: 6| Step: 1
Training loss: 0.5878707020574285
Validation loss: 2.6636192215937515

Epoch: 6| Step: 2
Training loss: 0.9632692656502451
Validation loss: 2.6594926569802353

Epoch: 6| Step: 3
Training loss: 0.8362893050554833
Validation loss: 2.657866264316911

Epoch: 6| Step: 4
Training loss: 0.5031095905195091
Validation loss: 2.67363226859597

Epoch: 6| Step: 5
Training loss: 0.7514569119139546
Validation loss: 2.6482008506650425

Epoch: 6| Step: 6
Training loss: 0.850674332275003
Validation loss: 2.62210350966588

Epoch: 6| Step: 7
Training loss: 0.42889136338933875
Validation loss: 2.593334941170212

Epoch: 6| Step: 8
Training loss: 0.6563091705531336
Validation loss: 2.575160600715733

Epoch: 6| Step: 9
Training loss: 0.680765918789325
Validation loss: 2.5768573586673207

Epoch: 6| Step: 10
Training loss: 0.6503971775400732
Validation loss: 2.587001788597659

Epoch: 6| Step: 11
Training loss: 1.0291961678563697
Validation loss: 2.5872425315261256

Epoch: 6| Step: 12
Training loss: 0.6068974282376001
Validation loss: 2.6288930168575164

Epoch: 6| Step: 13
Training loss: 0.5794143732512819
Validation loss: 2.638057800357243

Epoch: 331| Step: 0
Training loss: 0.7798855119214724
Validation loss: 2.633323497398183

Epoch: 6| Step: 1
Training loss: 0.9595444979962087
Validation loss: 2.6216205381578632

Epoch: 6| Step: 2
Training loss: 0.35029633655742376
Validation loss: 2.62977498709433

Epoch: 6| Step: 3
Training loss: 0.8450811975731315
Validation loss: 2.607149919466569

Epoch: 6| Step: 4
Training loss: 0.8302384524623528
Validation loss: 2.617394552916125

Epoch: 6| Step: 5
Training loss: 0.9341381831821942
Validation loss: 2.6126324103368086

Epoch: 6| Step: 6
Training loss: 0.660852685631352
Validation loss: 2.619548581727785

Epoch: 6| Step: 7
Training loss: 0.7645335299896229
Validation loss: 2.595611147675846

Epoch: 6| Step: 8
Training loss: 0.6336524475227381
Validation loss: 2.5704720677595847

Epoch: 6| Step: 9
Training loss: 0.4901107389014139
Validation loss: 2.573341810448492

Epoch: 6| Step: 10
Training loss: 0.520025863967089
Validation loss: 2.5867244082179885

Epoch: 6| Step: 11
Training loss: 0.5641333390238079
Validation loss: 2.566049563973848

Epoch: 6| Step: 12
Training loss: 0.36530588847264184
Validation loss: 2.566990248474234

Epoch: 6| Step: 13
Training loss: 2.055790014327293
Validation loss: 2.5907061790009145

Epoch: 332| Step: 0
Training loss: 0.5810339659514179
Validation loss: 2.5824699161403206

Epoch: 6| Step: 1
Training loss: 0.565225541283703
Validation loss: 2.5964694937657535

Epoch: 6| Step: 2
Training loss: 0.7457318052168904
Validation loss: 2.6270580242289374

Epoch: 6| Step: 3
Training loss: 0.7054231597262076
Validation loss: 2.6467530172814833

Epoch: 6| Step: 4
Training loss: 0.8643999403129603
Validation loss: 2.6585638441307338

Epoch: 6| Step: 5
Training loss: 0.6456713447665553
Validation loss: 2.639494644597994

Epoch: 6| Step: 6
Training loss: 0.7240105388306372
Validation loss: 2.6474507118165875

Epoch: 6| Step: 7
Training loss: 0.8166241514726169
Validation loss: 2.609488670639391

Epoch: 6| Step: 8
Training loss: 0.5192315807702985
Validation loss: 2.628549031250296

Epoch: 6| Step: 9
Training loss: 0.51822667784229
Validation loss: 2.6096678676255753

Epoch: 6| Step: 10
Training loss: 0.5019980681370801
Validation loss: 2.6449768599313632

Epoch: 6| Step: 11
Training loss: 0.9700308914771333
Validation loss: 2.623951324013352

Epoch: 6| Step: 12
Training loss: 0.48991928005002716
Validation loss: 2.616466037694708

Epoch: 6| Step: 13
Training loss: 2.095102471187653
Validation loss: 2.6235276960327383

Epoch: 333| Step: 0
Training loss: 0.908171359911566
Validation loss: 2.6307858322386997

Epoch: 6| Step: 1
Training loss: 0.8819444828250372
Validation loss: 2.6524459227413515

Epoch: 6| Step: 2
Training loss: 0.5983876508862032
Validation loss: 2.639917538953196

Epoch: 6| Step: 3
Training loss: 0.5985641813530419
Validation loss: 2.6507116073159693

Epoch: 6| Step: 4
Training loss: 0.6349614237534426
Validation loss: 2.672160932277355

Epoch: 6| Step: 5
Training loss: 0.2813607765959805
Validation loss: 2.649529831524911

Epoch: 6| Step: 6
Training loss: 0.7160442673302324
Validation loss: 2.6184054082068715

Epoch: 6| Step: 7
Training loss: 1.6883399427133312
Validation loss: 2.625162145018228

Epoch: 6| Step: 8
Training loss: 0.614530566477256
Validation loss: 2.584638171438481

Epoch: 6| Step: 9
Training loss: 0.5963398766506042
Validation loss: 2.5821707911852148

Epoch: 6| Step: 10
Training loss: 0.5970062261397333
Validation loss: 2.5871256925299337

Epoch: 6| Step: 11
Training loss: 0.656120741693912
Validation loss: 2.570322015219022

Epoch: 6| Step: 12
Training loss: 0.7775713333451112
Validation loss: 2.57139134929455

Epoch: 6| Step: 13
Training loss: 0.35746108293452206
Validation loss: 2.576611004895354

Epoch: 334| Step: 0
Training loss: 0.7981585095450028
Validation loss: 2.6021242381186145

Epoch: 6| Step: 1
Training loss: 0.8031179806294928
Validation loss: 2.6075407560220643

Epoch: 6| Step: 2
Training loss: 0.5201473455105209
Validation loss: 2.628134240707815

Epoch: 6| Step: 3
Training loss: 0.531281470320318
Validation loss: 2.624366886066091

Epoch: 6| Step: 4
Training loss: 0.7061938812105298
Validation loss: 2.619850567233213

Epoch: 6| Step: 5
Training loss: 0.7578098257745179
Validation loss: 2.64678192058307

Epoch: 6| Step: 6
Training loss: 0.6349894202469891
Validation loss: 2.626259981392094

Epoch: 6| Step: 7
Training loss: 0.4643865629068372
Validation loss: 2.6312925544243773

Epoch: 6| Step: 8
Training loss: 0.6578667570739677
Validation loss: 2.629477349243391

Epoch: 6| Step: 9
Training loss: 1.6383404038445823
Validation loss: 2.6039844312996183

Epoch: 6| Step: 10
Training loss: 0.5460441817897996
Validation loss: 2.601778261337409

Epoch: 6| Step: 11
Training loss: 0.6758390192466089
Validation loss: 2.586658427478852

Epoch: 6| Step: 12
Training loss: 0.6078006998206225
Validation loss: 2.596410049296387

Epoch: 6| Step: 13
Training loss: 0.8346540634444846
Validation loss: 2.5663174142953618

Epoch: 335| Step: 0
Training loss: 0.3092271605702438
Validation loss: 2.594699999457759

Epoch: 6| Step: 1
Training loss: 0.9259573853411254
Validation loss: 2.583549730272752

Epoch: 6| Step: 2
Training loss: 1.6166928774226283
Validation loss: 2.5916858104068274

Epoch: 6| Step: 3
Training loss: 0.8987494880664201
Validation loss: 2.627629595419584

Epoch: 6| Step: 4
Training loss: 0.7709665999469725
Validation loss: 2.633306196109805

Epoch: 6| Step: 5
Training loss: 0.51266377669939
Validation loss: 2.663582921011337

Epoch: 6| Step: 6
Training loss: 0.7131833664247207
Validation loss: 2.673520140921876

Epoch: 6| Step: 7
Training loss: 0.9023103253668052
Validation loss: 2.6636466136918977

Epoch: 6| Step: 8
Training loss: 0.5868384999715238
Validation loss: 2.654629854454714

Epoch: 6| Step: 9
Training loss: 0.3713321722971014
Validation loss: 2.6169213394886808

Epoch: 6| Step: 10
Training loss: 0.2577262069319024
Validation loss: 2.616174206447932

Epoch: 6| Step: 11
Training loss: 0.6538122175599139
Validation loss: 2.6227289641126896

Epoch: 6| Step: 12
Training loss: 0.6359567353434858
Validation loss: 2.630149851542483

Epoch: 6| Step: 13
Training loss: 0.7461229887820359
Validation loss: 2.6023818500824385

Epoch: 336| Step: 0
Training loss: 0.35770984159820735
Validation loss: 2.604160622046234

Epoch: 6| Step: 1
Training loss: 0.6714349015025919
Validation loss: 2.6190018123818137

Epoch: 6| Step: 2
Training loss: 0.5824101130259223
Validation loss: 2.612160069615501

Epoch: 6| Step: 3
Training loss: 0.977301630687534
Validation loss: 2.625241520460419

Epoch: 6| Step: 4
Training loss: 0.7112664520157632
Validation loss: 2.639594226204135

Epoch: 6| Step: 5
Training loss: 0.5639781075110988
Validation loss: 2.6700927723849555

Epoch: 6| Step: 6
Training loss: 1.5929540254624233
Validation loss: 2.6727039476339995

Epoch: 6| Step: 7
Training loss: 0.7175251849336712
Validation loss: 2.6547584095303915

Epoch: 6| Step: 8
Training loss: 0.7117908093752231
Validation loss: 2.64862286599636

Epoch: 6| Step: 9
Training loss: 0.5943279715865095
Validation loss: 2.623039202774005

Epoch: 6| Step: 10
Training loss: 0.4959160794473816
Validation loss: 2.6247572525376928

Epoch: 6| Step: 11
Training loss: 0.602737270504022
Validation loss: 2.6118275532520174

Epoch: 6| Step: 12
Training loss: 0.7434385897935895
Validation loss: 2.5923919126972708

Epoch: 6| Step: 13
Training loss: 0.7172190075437938
Validation loss: 2.605187404960641

Epoch: 337| Step: 0
Training loss: 0.6464051258574391
Validation loss: 2.5886423827509804

Epoch: 6| Step: 1
Training loss: 0.5219860449876802
Validation loss: 2.560470057146545

Epoch: 6| Step: 2
Training loss: 0.6574156263919194
Validation loss: 2.612145353097909

Epoch: 6| Step: 3
Training loss: 0.6967974033689458
Validation loss: 2.6058492357951653

Epoch: 6| Step: 4
Training loss: 1.6713036960372634
Validation loss: 2.632007070973391

Epoch: 6| Step: 5
Training loss: 0.7317025276062222
Validation loss: 2.633684452782154

Epoch: 6| Step: 6
Training loss: 0.7234325466439578
Validation loss: 2.66423018117882

Epoch: 6| Step: 7
Training loss: 0.9243713781712721
Validation loss: 2.6594062926052047

Epoch: 6| Step: 8
Training loss: 0.5191551223693956
Validation loss: 2.6462704413150626

Epoch: 6| Step: 9
Training loss: 0.3879737526751214
Validation loss: 2.61073282926105

Epoch: 6| Step: 10
Training loss: 0.7510581102480219
Validation loss: 2.5937192786312737

Epoch: 6| Step: 11
Training loss: 0.5663944111606223
Validation loss: 2.5916968318134774

Epoch: 6| Step: 12
Training loss: 0.3415090166188981
Validation loss: 2.594657677848878

Epoch: 6| Step: 13
Training loss: 0.6432073926650868
Validation loss: 2.5891765467004

Epoch: 338| Step: 0
Training loss: 0.4829857499960524
Validation loss: 2.5754885968514554

Epoch: 6| Step: 1
Training loss: 1.6157765153270114
Validation loss: 2.592638113726129

Epoch: 6| Step: 2
Training loss: 0.5124489037698438
Validation loss: 2.5833490032497495

Epoch: 6| Step: 3
Training loss: 0.7227670120723062
Validation loss: 2.594909516526838

Epoch: 6| Step: 4
Training loss: 0.7812129202626377
Validation loss: 2.599617629177824

Epoch: 6| Step: 5
Training loss: 0.7447139103632846
Validation loss: 2.646188787823569

Epoch: 6| Step: 6
Training loss: 0.3300820299628596
Validation loss: 2.638553160716425

Epoch: 6| Step: 7
Training loss: 0.8736362046999521
Validation loss: 2.6263723521669498

Epoch: 6| Step: 8
Training loss: 0.6135463020352536
Validation loss: 2.646828900063722

Epoch: 6| Step: 9
Training loss: 0.5830341122316705
Validation loss: 2.6230434298312306

Epoch: 6| Step: 10
Training loss: 0.7368816854935618
Validation loss: 2.625628391765183

Epoch: 6| Step: 11
Training loss: 0.8342012217284763
Validation loss: 2.603423938457338

Epoch: 6| Step: 12
Training loss: 0.3334411084266766
Validation loss: 2.5816130667852923

Epoch: 6| Step: 13
Training loss: 0.7645575809212933
Validation loss: 2.5872171272818387

Epoch: 339| Step: 0
Training loss: 0.8163433141953633
Validation loss: 2.5884724013488434

Epoch: 6| Step: 1
Training loss: 0.7205599924428209
Validation loss: 2.6247636060631985

Epoch: 6| Step: 2
Training loss: 0.8880708443588381
Validation loss: 2.592819216861911

Epoch: 6| Step: 3
Training loss: 0.4400717555945823
Validation loss: 2.6245288123232102

Epoch: 6| Step: 4
Training loss: 0.8921720219487086
Validation loss: 2.6257042679870772

Epoch: 6| Step: 5
Training loss: 1.6647078288107962
Validation loss: 2.6287318480240014

Epoch: 6| Step: 6
Training loss: 0.4104104298958456
Validation loss: 2.6411729605599796

Epoch: 6| Step: 7
Training loss: 0.6727958179962489
Validation loss: 2.644345122140115

Epoch: 6| Step: 8
Training loss: 0.44167147744755647
Validation loss: 2.636042081537788

Epoch: 6| Step: 9
Training loss: 0.2995441062289491
Validation loss: 2.6200799711005933

Epoch: 6| Step: 10
Training loss: 0.39773100504424425
Validation loss: 2.615303494034935

Epoch: 6| Step: 11
Training loss: 0.7906922232655879
Validation loss: 2.6159171804840664

Epoch: 6| Step: 12
Training loss: 0.37236193744968193
Validation loss: 2.5829952801457896

Epoch: 6| Step: 13
Training loss: 0.7159437877124163
Validation loss: 2.592881795843115

Epoch: 340| Step: 0
Training loss: 1.5518352472419614
Validation loss: 2.6027758645376315

Epoch: 6| Step: 1
Training loss: 0.9681252341519511
Validation loss: 2.5823988049474753

Epoch: 6| Step: 2
Training loss: 0.7532984996720452
Validation loss: 2.587630301237305

Epoch: 6| Step: 3
Training loss: 0.4869428372899109
Validation loss: 2.601771892080813

Epoch: 6| Step: 4
Training loss: 0.6006660221948811
Validation loss: 2.606811262180717

Epoch: 6| Step: 5
Training loss: 0.6988113324539671
Validation loss: 2.6021390428376496

Epoch: 6| Step: 6
Training loss: 0.7625138656731303
Validation loss: 2.637735608180996

Epoch: 6| Step: 7
Training loss: 0.2557705149789322
Validation loss: 2.642084471634876

Epoch: 6| Step: 8
Training loss: 0.5646351451490167
Validation loss: 2.6549265180493262

Epoch: 6| Step: 9
Training loss: 0.5910141555959484
Validation loss: 2.6475362474492012

Epoch: 6| Step: 10
Training loss: 0.5766298187570525
Validation loss: 2.6179114584303096

Epoch: 6| Step: 11
Training loss: 0.6501464385356021
Validation loss: 2.6432950158582504

Epoch: 6| Step: 12
Training loss: 0.5183437802140022
Validation loss: 2.6546720852437193

Epoch: 6| Step: 13
Training loss: 0.632157257307075
Validation loss: 2.6399870944989514

Epoch: 341| Step: 0
Training loss: 0.7355600089482272
Validation loss: 2.609425799257453

Epoch: 6| Step: 1
Training loss: 0.6696288688651869
Validation loss: 2.5933329235393656

Epoch: 6| Step: 2
Training loss: 0.5029843495116453
Validation loss: 2.598179597554744

Epoch: 6| Step: 3
Training loss: 0.4692387893467593
Validation loss: 2.5857422249372473

Epoch: 6| Step: 4
Training loss: 0.9926092197752501
Validation loss: 2.5866780046295506

Epoch: 6| Step: 5
Training loss: 0.5563373207818303
Validation loss: 2.605611807889702

Epoch: 6| Step: 6
Training loss: 0.6909156394892274
Validation loss: 2.602366762537938

Epoch: 6| Step: 7
Training loss: 0.8184327886969448
Validation loss: 2.5990929081797436

Epoch: 6| Step: 8
Training loss: 0.5244107095337701
Validation loss: 2.587703187159859

Epoch: 6| Step: 9
Training loss: 0.48865112028864943
Validation loss: 2.605705301534366

Epoch: 6| Step: 10
Training loss: 0.4824590630039718
Validation loss: 2.6340356785290417

Epoch: 6| Step: 11
Training loss: 0.551640050693543
Validation loss: 2.6581699003111106

Epoch: 6| Step: 12
Training loss: 1.576118931596104
Validation loss: 2.623461708659225

Epoch: 6| Step: 13
Training loss: 0.7640371400333905
Validation loss: 2.644354303103095

Epoch: 342| Step: 0
Training loss: 0.4971620666117603
Validation loss: 2.6289493679334606

Epoch: 6| Step: 1
Training loss: 0.7436163549800797
Validation loss: 2.6043533323923853

Epoch: 6| Step: 2
Training loss: 0.611791611737587
Validation loss: 2.5855835043812525

Epoch: 6| Step: 3
Training loss: 0.5834433815102376
Validation loss: 2.6090847279093836

Epoch: 6| Step: 4
Training loss: 0.5332336975946455
Validation loss: 2.585945350707674

Epoch: 6| Step: 5
Training loss: 0.6135607040206458
Validation loss: 2.5929686630546556

Epoch: 6| Step: 6
Training loss: 0.5826530463411167
Validation loss: 2.607342284983732

Epoch: 6| Step: 7
Training loss: 0.3731073260634256
Validation loss: 2.5998103533286057

Epoch: 6| Step: 8
Training loss: 0.6324915130709269
Validation loss: 2.588737078487711

Epoch: 6| Step: 9
Training loss: 0.49462714387931805
Validation loss: 2.6204276957534405

Epoch: 6| Step: 10
Training loss: 0.7185967323422158
Validation loss: 2.6205602535461194

Epoch: 6| Step: 11
Training loss: 0.8616214520884831
Validation loss: 2.646565057485548

Epoch: 6| Step: 12
Training loss: 1.5885327531741686
Validation loss: 2.635567481107072

Epoch: 6| Step: 13
Training loss: 0.6552457618838298
Validation loss: 2.648023726872875

Epoch: 343| Step: 0
Training loss: 0.41910043258863117
Validation loss: 2.6337076021892827

Epoch: 6| Step: 1
Training loss: 0.5935606152513699
Validation loss: 2.6346723899927773

Epoch: 6| Step: 2
Training loss: 0.6490284169063754
Validation loss: 2.611370341365857

Epoch: 6| Step: 3
Training loss: 0.5288889252432687
Validation loss: 2.573830329279605

Epoch: 6| Step: 4
Training loss: 1.609067720874074
Validation loss: 2.557431418291912

Epoch: 6| Step: 5
Training loss: 0.6440907215522683
Validation loss: 2.5611314688252285

Epoch: 6| Step: 6
Training loss: 0.44945191676114854
Validation loss: 2.565457555900396

Epoch: 6| Step: 7
Training loss: 0.6696728168325077
Validation loss: 2.5717490658449456

Epoch: 6| Step: 8
Training loss: 0.7710394626665984
Validation loss: 2.5765744048069505

Epoch: 6| Step: 9
Training loss: 0.425485368166642
Validation loss: 2.599067435314331

Epoch: 6| Step: 10
Training loss: 0.3383910492098523
Validation loss: 2.5863227434594527

Epoch: 6| Step: 11
Training loss: 0.4921335614636705
Validation loss: 2.613664248269631

Epoch: 6| Step: 12
Training loss: 0.8401612147531643
Validation loss: 2.610309271712335

Epoch: 6| Step: 13
Training loss: 0.9027197908868314
Validation loss: 2.629134395675571

Epoch: 344| Step: 0
Training loss: 0.6794005478842983
Validation loss: 2.6353959441003587

Epoch: 6| Step: 1
Training loss: 0.6700781592642264
Validation loss: 2.6029159911073583

Epoch: 6| Step: 2
Training loss: 0.4282312337958013
Validation loss: 2.61259005760757

Epoch: 6| Step: 3
Training loss: 0.7062324521745773
Validation loss: 2.617276066086757

Epoch: 6| Step: 4
Training loss: 0.3709037294256372
Validation loss: 2.6015394606982487

Epoch: 6| Step: 5
Training loss: 0.6756564559812706
Validation loss: 2.6178079769854787

Epoch: 6| Step: 6
Training loss: 0.34124938713270214
Validation loss: 2.5849980942199897

Epoch: 6| Step: 7
Training loss: 0.6404393089807194
Validation loss: 2.6002117270343645

Epoch: 6| Step: 8
Training loss: 0.529302223994968
Validation loss: 2.625749931113646

Epoch: 6| Step: 9
Training loss: 0.5197074992723861
Validation loss: 2.624748352692554

Epoch: 6| Step: 10
Training loss: 0.4410903610547934
Validation loss: 2.5724699833215516

Epoch: 6| Step: 11
Training loss: 0.721171611909402
Validation loss: 2.603391225891509

Epoch: 6| Step: 12
Training loss: 1.6665516893146004
Validation loss: 2.5887763358817297

Epoch: 6| Step: 13
Training loss: 0.6699885343524258
Validation loss: 2.599291902587277

Epoch: 345| Step: 0
Training loss: 0.577045773639213
Validation loss: 2.6132160280836985

Epoch: 6| Step: 1
Training loss: 0.4217477182599061
Validation loss: 2.6276114014792498

Epoch: 6| Step: 2
Training loss: 0.6011522058116019
Validation loss: 2.6360676415533115

Epoch: 6| Step: 3
Training loss: 0.7248304086498844
Validation loss: 2.606597105543229

Epoch: 6| Step: 4
Training loss: 0.6048453290125921
Validation loss: 2.6265320338193487

Epoch: 6| Step: 5
Training loss: 0.5986892648685421
Validation loss: 2.604658460550842

Epoch: 6| Step: 6
Training loss: 0.5561257909476344
Validation loss: 2.5937524136510914

Epoch: 6| Step: 7
Training loss: 1.526783950345734
Validation loss: 2.604383945055638

Epoch: 6| Step: 8
Training loss: 0.6377974424028598
Validation loss: 2.6241850762404098

Epoch: 6| Step: 9
Training loss: 0.6379740224261156
Validation loss: 2.6501424885784863

Epoch: 6| Step: 10
Training loss: 0.4612475338536525
Validation loss: 2.64086101234776

Epoch: 6| Step: 11
Training loss: 0.6196788770698037
Validation loss: 2.61452901349333

Epoch: 6| Step: 12
Training loss: 0.6139830685946391
Validation loss: 2.6420517292958015

Epoch: 6| Step: 13
Training loss: 0.6694725019749308
Validation loss: 2.6034646611870267

Epoch: 346| Step: 0
Training loss: 0.7165870879222384
Validation loss: 2.57941261173935

Epoch: 6| Step: 1
Training loss: 0.699333991245267
Validation loss: 2.575175792405406

Epoch: 6| Step: 2
Training loss: 0.7157639381098854
Validation loss: 2.5621209073022966

Epoch: 6| Step: 3
Training loss: 0.3952279313288525
Validation loss: 2.588810901741183

Epoch: 6| Step: 4
Training loss: 0.7645542286488051
Validation loss: 2.574915689051257

Epoch: 6| Step: 5
Training loss: 0.5340911959309794
Validation loss: 2.5672069471805514

Epoch: 6| Step: 6
Training loss: 0.6112097726156082
Validation loss: 2.5931791845467163

Epoch: 6| Step: 7
Training loss: 0.769454487491377
Validation loss: 2.6045898454626437

Epoch: 6| Step: 8
Training loss: 0.28656074109468443
Validation loss: 2.620830916816026

Epoch: 6| Step: 9
Training loss: 1.6204028024404866
Validation loss: 2.617894504283942

Epoch: 6| Step: 10
Training loss: 0.36797167863915503
Validation loss: 2.6247261698534743

Epoch: 6| Step: 11
Training loss: 0.3216977404477716
Validation loss: 2.637890763644476

Epoch: 6| Step: 12
Training loss: 0.5666216210618625
Validation loss: 2.650864696263059

Epoch: 6| Step: 13
Training loss: 0.27104686914348197
Validation loss: 2.6346820094449535

Epoch: 347| Step: 0
Training loss: 0.5238358419534053
Validation loss: 2.6209603070831236

Epoch: 6| Step: 1
Training loss: 0.5329715659123908
Validation loss: 2.613458489918492

Epoch: 6| Step: 2
Training loss: 0.7499520763344821
Validation loss: 2.589341091422788

Epoch: 6| Step: 3
Training loss: 0.602575613239424
Validation loss: 2.5746114635033224

Epoch: 6| Step: 4
Training loss: 0.5107399993324452
Validation loss: 2.5983389647571316

Epoch: 6| Step: 5
Training loss: 0.7102092744107296
Validation loss: 2.586655337223026

Epoch: 6| Step: 6
Training loss: 0.3813456048067721
Validation loss: 2.598936601954382

Epoch: 6| Step: 7
Training loss: 0.8299281444813694
Validation loss: 2.607629652210728

Epoch: 6| Step: 8
Training loss: 0.5758018210474695
Validation loss: 2.6125847646640574

Epoch: 6| Step: 9
Training loss: 0.5064105709354151
Validation loss: 2.6380178473002114

Epoch: 6| Step: 10
Training loss: 0.45521422221595986
Validation loss: 2.6529938594902793

Epoch: 6| Step: 11
Training loss: 0.6456080833500981
Validation loss: 2.6502326846150623

Epoch: 6| Step: 12
Training loss: 0.42290022572222496
Validation loss: 2.6783674347797257

Epoch: 6| Step: 13
Training loss: 2.1309626455483475
Validation loss: 2.652986360837625

Epoch: 348| Step: 0
Training loss: 0.4354788038491372
Validation loss: 2.6613810811208314

Epoch: 6| Step: 1
Training loss: 0.7538248522206401
Validation loss: 2.6634182512918088

Epoch: 6| Step: 2
Training loss: 0.5019342441199116
Validation loss: 2.6544264689826518

Epoch: 6| Step: 3
Training loss: 0.7587872165181254
Validation loss: 2.6419675389456883

Epoch: 6| Step: 4
Training loss: 0.5833535758548031
Validation loss: 2.6059325034967857

Epoch: 6| Step: 5
Training loss: 0.4516860707039901
Validation loss: 2.6068507538534353

Epoch: 6| Step: 6
Training loss: 0.706381799839647
Validation loss: 2.5900117661913664

Epoch: 6| Step: 7
Training loss: 0.28745588814216627
Validation loss: 2.5721954102655378

Epoch: 6| Step: 8
Training loss: 0.5229531509721734
Validation loss: 2.59091032857071

Epoch: 6| Step: 9
Training loss: 0.565326081635229
Validation loss: 2.6079594136883086

Epoch: 6| Step: 10
Training loss: 0.6760126941352422
Validation loss: 2.5835760239426917

Epoch: 6| Step: 11
Training loss: 0.6118840136852843
Validation loss: 2.6282978866378746

Epoch: 6| Step: 12
Training loss: 1.6583878736616644
Validation loss: 2.6279733794537217

Epoch: 6| Step: 13
Training loss: 0.5960955218567519
Validation loss: 2.652579256550545

Epoch: 349| Step: 0
Training loss: 0.46351992809742143
Validation loss: 2.6221328083527675

Epoch: 6| Step: 1
Training loss: 0.8577064962848457
Validation loss: 2.6072379022414625

Epoch: 6| Step: 2
Training loss: 0.6764107787328069
Validation loss: 2.5987902349435132

Epoch: 6| Step: 3
Training loss: 0.5643318336344465
Validation loss: 2.583505103453796

Epoch: 6| Step: 4
Training loss: 0.5465074939213979
Validation loss: 2.6058030242208226

Epoch: 6| Step: 5
Training loss: 0.46810983814086843
Validation loss: 2.591875047249226

Epoch: 6| Step: 6
Training loss: 0.513692122956
Validation loss: 2.5858977573474666

Epoch: 6| Step: 7
Training loss: 0.587441104615264
Validation loss: 2.5531879509817634

Epoch: 6| Step: 8
Training loss: 0.8140513941031063
Validation loss: 2.5667587035508004

Epoch: 6| Step: 9
Training loss: 1.5059125720175612
Validation loss: 2.5837371707676353

Epoch: 6| Step: 10
Training loss: 0.5996616601669598
Validation loss: 2.600897916505248

Epoch: 6| Step: 11
Training loss: 0.1506547219088748
Validation loss: 2.622517014493282

Epoch: 6| Step: 12
Training loss: 0.48689482123362365
Validation loss: 2.6376060688848457

Epoch: 6| Step: 13
Training loss: 0.6615726242047565
Validation loss: 2.6322992111180983

Epoch: 350| Step: 0
Training loss: 0.6649288136520566
Validation loss: 2.61941171487051

Epoch: 6| Step: 1
Training loss: 0.688108889835545
Validation loss: 2.586633868862146

Epoch: 6| Step: 2
Training loss: 0.616890509892579
Validation loss: 2.6020618021046373

Epoch: 6| Step: 3
Training loss: 0.824664750040161
Validation loss: 2.625226458827248

Epoch: 6| Step: 4
Training loss: 0.39525051460256744
Validation loss: 2.6259252203894294

Epoch: 6| Step: 5
Training loss: 0.4837650026661348
Validation loss: 2.6306838176093406

Epoch: 6| Step: 6
Training loss: 0.4620121212644886
Validation loss: 2.615518079692799

Epoch: 6| Step: 7
Training loss: 0.46095728427648397
Validation loss: 2.6054388575481005

Epoch: 6| Step: 8
Training loss: 0.6146638434957943
Validation loss: 2.61328404978531

Epoch: 6| Step: 9
Training loss: 0.5578584967276342
Validation loss: 2.6066613477924823

Epoch: 6| Step: 10
Training loss: 1.5900419144533984
Validation loss: 2.6224819808342947

Epoch: 6| Step: 11
Training loss: 0.5968486840004069
Validation loss: 2.60403692763179

Epoch: 6| Step: 12
Training loss: 0.473468272150199
Validation loss: 2.642395325105021

Epoch: 6| Step: 13
Training loss: 0.5234208460193892
Validation loss: 2.6111054121135773

Epoch: 351| Step: 0
Training loss: 0.3816668631242194
Validation loss: 2.6280392998798443

Epoch: 6| Step: 1
Training loss: 0.2412686607081413
Validation loss: 2.633615604919727

Epoch: 6| Step: 2
Training loss: 0.31243250833298514
Validation loss: 2.6010479758079823

Epoch: 6| Step: 3
Training loss: 0.6474702584126517
Validation loss: 2.6328579648688524

Epoch: 6| Step: 4
Training loss: 0.42987690999105077
Validation loss: 2.6227314630152647

Epoch: 6| Step: 5
Training loss: 0.5793714746658081
Validation loss: 2.618048934454501

Epoch: 6| Step: 6
Training loss: 0.7650640339947798
Validation loss: 2.612883801124103

Epoch: 6| Step: 7
Training loss: 0.7073454606541332
Validation loss: 2.6110507976958464

Epoch: 6| Step: 8
Training loss: 0.49261267024370775
Validation loss: 2.6237609642370456

Epoch: 6| Step: 9
Training loss: 0.2638714211870425
Validation loss: 2.6154837491701968

Epoch: 6| Step: 10
Training loss: 0.6998152931936451
Validation loss: 2.600475889567821

Epoch: 6| Step: 11
Training loss: 0.6599385506388288
Validation loss: 2.611419109931788

Epoch: 6| Step: 12
Training loss: 1.5795815421922503
Validation loss: 2.585883423749424

Epoch: 6| Step: 13
Training loss: 0.6908278335709758
Validation loss: 2.595730164682262

Epoch: 352| Step: 0
Training loss: 0.5362248576212298
Validation loss: 2.60183978633154

Epoch: 6| Step: 1
Training loss: 0.5510090566503528
Validation loss: 2.6175787902435803

Epoch: 6| Step: 2
Training loss: 0.6195685896137916
Validation loss: 2.5967090686801484

Epoch: 6| Step: 3
Training loss: 0.3974224887405975
Validation loss: 2.612786678837913

Epoch: 6| Step: 4
Training loss: 0.6639550290376114
Validation loss: 2.6064047160113186

Epoch: 6| Step: 5
Training loss: 0.37987412391277886
Validation loss: 2.623824634309781

Epoch: 6| Step: 6
Training loss: 0.5764059593425379
Validation loss: 2.618311523072302

Epoch: 6| Step: 7
Training loss: 0.44927286568469504
Validation loss: 2.593214155370523

Epoch: 6| Step: 8
Training loss: 0.8155672791032798
Validation loss: 2.6151647688908075

Epoch: 6| Step: 9
Training loss: 0.4555180105852758
Validation loss: 2.616047503682655

Epoch: 6| Step: 10
Training loss: 0.25044174208164927
Validation loss: 2.6060824445640756

Epoch: 6| Step: 11
Training loss: 0.647740782592279
Validation loss: 2.608846979309423

Epoch: 6| Step: 12
Training loss: 0.5669032054306494
Validation loss: 2.5982728169502085

Epoch: 6| Step: 13
Training loss: 1.9972801788414585
Validation loss: 2.5893875453025164

Epoch: 353| Step: 0
Training loss: 0.6487334162185601
Validation loss: 2.618869577549476

Epoch: 6| Step: 1
Training loss: 0.6553128226392658
Validation loss: 2.5726854825704755

Epoch: 6| Step: 2
Training loss: 0.30668175779835977
Validation loss: 2.5959827298397746

Epoch: 6| Step: 3
Training loss: 0.43716419479608354
Validation loss: 2.6105729746882056

Epoch: 6| Step: 4
Training loss: 0.5569053957143638
Validation loss: 2.606699486007562

Epoch: 6| Step: 5
Training loss: 0.8069815296318886
Validation loss: 2.6393631101176527

Epoch: 6| Step: 6
Training loss: 0.36897411324897006
Validation loss: 2.635806289841257

Epoch: 6| Step: 7
Training loss: 0.6230281480228932
Validation loss: 2.6449232861001244

Epoch: 6| Step: 8
Training loss: 0.5016306869408809
Validation loss: 2.64027243018504

Epoch: 6| Step: 9
Training loss: 1.5734039545508225
Validation loss: 2.6571871480258595

Epoch: 6| Step: 10
Training loss: 0.42962720621345546
Validation loss: 2.66680535281415

Epoch: 6| Step: 11
Training loss: 0.4194062904646103
Validation loss: 2.6649215247200173

Epoch: 6| Step: 12
Training loss: 0.38194183676243704
Validation loss: 2.640762113897295

Epoch: 6| Step: 13
Training loss: 0.4698862292182716
Validation loss: 2.614329739348874

Epoch: 354| Step: 0
Training loss: 0.42731737686594756
Validation loss: 2.586258868802156

Epoch: 6| Step: 1
Training loss: 0.5842461653074696
Validation loss: 2.556659434289689

Epoch: 6| Step: 2
Training loss: 0.5231678965856786
Validation loss: 2.5619536697088954

Epoch: 6| Step: 3
Training loss: 0.3452241024950157
Validation loss: 2.5758848817771507

Epoch: 6| Step: 4
Training loss: 0.5401704431798255
Validation loss: 2.5765675523688834

Epoch: 6| Step: 5
Training loss: 0.4040739762637649
Validation loss: 2.603913340070575

Epoch: 6| Step: 6
Training loss: 0.5064205459323531
Validation loss: 2.593288085465366

Epoch: 6| Step: 7
Training loss: 0.6886320763662511
Validation loss: 2.5939403621728085

Epoch: 6| Step: 8
Training loss: 0.5797685252935574
Validation loss: 2.6286053545901997

Epoch: 6| Step: 9
Training loss: 0.4784379545741597
Validation loss: 2.620737256500849

Epoch: 6| Step: 10
Training loss: 0.40062159877529496
Validation loss: 2.6227917736708597

Epoch: 6| Step: 11
Training loss: 1.588281712341992
Validation loss: 2.6216636683523813

Epoch: 6| Step: 12
Training loss: 0.7291653269800867
Validation loss: 2.624128489013033

Epoch: 6| Step: 13
Training loss: 0.4413269613165901
Validation loss: 2.6235821137485273

Epoch: 355| Step: 0
Training loss: 0.601308793902933
Validation loss: 2.597842922345414

Epoch: 6| Step: 1
Training loss: 0.4595974338244052
Validation loss: 2.5983867157627434

Epoch: 6| Step: 2
Training loss: 0.6832525873355052
Validation loss: 2.5755585993764196

Epoch: 6| Step: 3
Training loss: 0.604582032658628
Validation loss: 2.589320788875108

Epoch: 6| Step: 4
Training loss: 0.6689808634200634
Validation loss: 2.6133795163530613

Epoch: 6| Step: 5
Training loss: 0.4400300033049948
Validation loss: 2.586976270008575

Epoch: 6| Step: 6
Training loss: 0.6110077771208511
Validation loss: 2.6086265439131298

Epoch: 6| Step: 7
Training loss: 0.1828869342064907
Validation loss: 2.6002278835066015

Epoch: 6| Step: 8
Training loss: 0.5001888216633503
Validation loss: 2.620548179102345

Epoch: 6| Step: 9
Training loss: 0.5067838373766796
Validation loss: 2.6335265365085965

Epoch: 6| Step: 10
Training loss: 0.2310099954341668
Validation loss: 2.6342838901177386

Epoch: 6| Step: 11
Training loss: 0.5130777149971917
Validation loss: 2.6364254897850583

Epoch: 6| Step: 12
Training loss: 1.5549445778393445
Validation loss: 2.6362419360268494

Epoch: 6| Step: 13
Training loss: 0.44256793395090804
Validation loss: 2.6348627626963212

Epoch: 356| Step: 0
Training loss: 0.617868482362026
Validation loss: 2.627340161409271

Epoch: 6| Step: 1
Training loss: 0.32879224554739367
Validation loss: 2.638325092001527

Epoch: 6| Step: 2
Training loss: 0.7034848246167861
Validation loss: 2.6156174469855413

Epoch: 6| Step: 3
Training loss: 0.2278197689492721
Validation loss: 2.615405109256365

Epoch: 6| Step: 4
Training loss: 0.6830622323282007
Validation loss: 2.6033433428952644

Epoch: 6| Step: 5
Training loss: 0.3723424481982655
Validation loss: 2.6105717127893637

Epoch: 6| Step: 6
Training loss: 0.37199022527511855
Validation loss: 2.6074649765595845

Epoch: 6| Step: 7
Training loss: 1.604767063623631
Validation loss: 2.6344149442131375

Epoch: 6| Step: 8
Training loss: 0.5769738515799726
Validation loss: 2.6150380760373975

Epoch: 6| Step: 9
Training loss: 0.6249788280715753
Validation loss: 2.617216470233878

Epoch: 6| Step: 10
Training loss: 0.2514058164186218
Validation loss: 2.6105273112382115

Epoch: 6| Step: 11
Training loss: 0.5846103388130821
Validation loss: 2.5902075740179438

Epoch: 6| Step: 12
Training loss: 0.27590946264596855
Validation loss: 2.6014949887504404

Epoch: 6| Step: 13
Training loss: 0.4529966633023285
Validation loss: 2.6108513454660134

Epoch: 357| Step: 0
Training loss: 0.5891132757832107
Validation loss: 2.5886073254058757

Epoch: 6| Step: 1
Training loss: 0.34968755689659714
Validation loss: 2.5776583938242563

Epoch: 6| Step: 2
Training loss: 1.581477993899181
Validation loss: 2.5554297783373365

Epoch: 6| Step: 3
Training loss: 0.45939046872622447
Validation loss: 2.5634227234889666

Epoch: 6| Step: 4
Training loss: 0.3668137941531011
Validation loss: 2.5984581540349896

Epoch: 6| Step: 5
Training loss: 0.44083823732534066
Validation loss: 2.5759051354631812

Epoch: 6| Step: 6
Training loss: 0.3716975069009107
Validation loss: 2.6038750571777745

Epoch: 6| Step: 7
Training loss: 0.5295868814601136
Validation loss: 2.6147286254168174

Epoch: 6| Step: 8
Training loss: 0.5488771301328973
Validation loss: 2.6046231994796387

Epoch: 6| Step: 9
Training loss: 0.45781064212148687
Validation loss: 2.6278764812150754

Epoch: 6| Step: 10
Training loss: 0.4567741257633338
Validation loss: 2.621850550818657

Epoch: 6| Step: 11
Training loss: 0.5694542789643793
Validation loss: 2.603932075680947

Epoch: 6| Step: 12
Training loss: 0.602371316123158
Validation loss: 2.6484377342517074

Epoch: 6| Step: 13
Training loss: 0.6451975759369637
Validation loss: 2.6264744595876337

Epoch: 358| Step: 0
Training loss: 0.6149818265369709
Validation loss: 2.645598846798769

Epoch: 6| Step: 1
Training loss: 0.32735467359939413
Validation loss: 2.6170166562280914

Epoch: 6| Step: 2
Training loss: 0.4452734812992415
Validation loss: 2.6115093642762273

Epoch: 6| Step: 3
Training loss: 0.4384971732752043
Validation loss: 2.5886503025018652

Epoch: 6| Step: 4
Training loss: 0.38837492444148464
Validation loss: 2.5896010462005545

Epoch: 6| Step: 5
Training loss: 0.44347002102380284
Validation loss: 2.5840609204318934

Epoch: 6| Step: 6
Training loss: 0.42720361116915384
Validation loss: 2.589312090987652

Epoch: 6| Step: 7
Training loss: 0.5319444941340004
Validation loss: 2.599177619320179

Epoch: 6| Step: 8
Training loss: 0.2533889636307356
Validation loss: 2.614635734848452

Epoch: 6| Step: 9
Training loss: 0.5807999765878205
Validation loss: 2.6229339571150976

Epoch: 6| Step: 10
Training loss: 0.39716556830673855
Validation loss: 2.60082178676517

Epoch: 6| Step: 11
Training loss: 0.4515521441001452
Validation loss: 2.593012009307433

Epoch: 6| Step: 12
Training loss: 0.7865549411342277
Validation loss: 2.599389359451042

Epoch: 6| Step: 13
Training loss: 2.088124246971088
Validation loss: 2.570508740274619

Epoch: 359| Step: 0
Training loss: 0.5446787739687804
Validation loss: 2.5784940423778093

Epoch: 6| Step: 1
Training loss: 0.5768571819062349
Validation loss: 2.5880356926714403

Epoch: 6| Step: 2
Training loss: 0.3719156299161781
Validation loss: 2.598354376861262

Epoch: 6| Step: 3
Training loss: 0.40838367174584433
Validation loss: 2.5909812660207607

Epoch: 6| Step: 4
Training loss: 0.6526367306227671
Validation loss: 2.6038945925109056

Epoch: 6| Step: 5
Training loss: 0.5412874055583662
Validation loss: 2.5823349920723553

Epoch: 6| Step: 6
Training loss: 0.6746141355133404
Validation loss: 2.5988070365250993

Epoch: 6| Step: 7
Training loss: 0.40415030508580857
Validation loss: 2.5673102953285465

Epoch: 6| Step: 8
Training loss: 0.34894609667071663
Validation loss: 2.588967450934332

Epoch: 6| Step: 9
Training loss: 0.5236432823947167
Validation loss: 2.5589318513048003

Epoch: 6| Step: 10
Training loss: 0.3997306035759342
Validation loss: 2.5527790466533014

Epoch: 6| Step: 11
Training loss: 1.5509357519560754
Validation loss: 2.5651062967830742

Epoch: 6| Step: 12
Training loss: 0.3077240531218816
Validation loss: 2.563920125515231

Epoch: 6| Step: 13
Training loss: 0.4064444296743401
Validation loss: 2.5839730230580655

Epoch: 360| Step: 0
Training loss: 0.7462032697094249
Validation loss: 2.613070660562942

Epoch: 6| Step: 1
Training loss: 0.4766297058495435
Validation loss: 2.611906224321151

Epoch: 6| Step: 2
Training loss: 0.19491284489021032
Validation loss: 2.6246292391519375

Epoch: 6| Step: 3
Training loss: 0.49042331048791404
Validation loss: 2.6150154672132824

Epoch: 6| Step: 4
Training loss: 0.44392847515085865
Validation loss: 2.567002080986751

Epoch: 6| Step: 5
Training loss: 0.6208474972621859
Validation loss: 2.5637624618556907

Epoch: 6| Step: 6
Training loss: 0.4311620207896177
Validation loss: 2.5769047698031398

Epoch: 6| Step: 7
Training loss: 0.6637414941763556
Validation loss: 2.5741572231343293

Epoch: 6| Step: 8
Training loss: 0.32065901969915783
Validation loss: 2.5787394472873504

Epoch: 6| Step: 9
Training loss: 0.6075342203242968
Validation loss: 2.5731418682608163

Epoch: 6| Step: 10
Training loss: 0.2853269980299563
Validation loss: 2.600366759759018

Epoch: 6| Step: 11
Training loss: 0.35176417606068733
Validation loss: 2.617103565763736

Epoch: 6| Step: 12
Training loss: 1.4827265369833817
Validation loss: 2.6404651045635723

Epoch: 6| Step: 13
Training loss: 0.6200072183496448
Validation loss: 2.6773747238924646

Epoch: 361| Step: 0
Training loss: 0.6306189914640185
Validation loss: 2.6852373393523488

Epoch: 6| Step: 1
Training loss: 0.29276203492133657
Validation loss: 2.6462130921202123

Epoch: 6| Step: 2
Training loss: 0.40920488739712035
Validation loss: 2.630083217384328

Epoch: 6| Step: 3
Training loss: 0.44451830129418807
Validation loss: 2.5691717829249927

Epoch: 6| Step: 4
Training loss: 1.5053447234807151
Validation loss: 2.5611974815854035

Epoch: 6| Step: 5
Training loss: 0.29922581059265363
Validation loss: 2.5506235481067083

Epoch: 6| Step: 6
Training loss: 0.6423248905131163
Validation loss: 2.5865918840788997

Epoch: 6| Step: 7
Training loss: 0.47086013454631065
Validation loss: 2.5491605139689164

Epoch: 6| Step: 8
Training loss: 0.31626930334337044
Validation loss: 2.5371411759121822

Epoch: 6| Step: 9
Training loss: 0.5485582332908027
Validation loss: 2.5401366974951314

Epoch: 6| Step: 10
Training loss: 0.43127747185597815
Validation loss: 2.539553521497922

Epoch: 6| Step: 11
Training loss: 0.8452755593850092
Validation loss: 2.5634649357295216

Epoch: 6| Step: 12
Training loss: 0.4101414632402468
Validation loss: 2.505076094167894

Epoch: 6| Step: 13
Training loss: 0.6546900692254322
Validation loss: 2.5152490113596673

Epoch: 362| Step: 0
Training loss: 0.6792946041654917
Validation loss: 2.5137178619339533

Epoch: 6| Step: 1
Training loss: 0.6648415427613965
Validation loss: 2.5068307280649624

Epoch: 6| Step: 2
Training loss: 0.6956134530588864
Validation loss: 2.5134616283931632

Epoch: 6| Step: 3
Training loss: 0.5535266172492683
Validation loss: 2.5359934877618877

Epoch: 6| Step: 4
Training loss: 0.44739217508735163
Validation loss: 2.5509867264485213

Epoch: 6| Step: 5
Training loss: 0.41356654424651457
Validation loss: 2.542720015263817

Epoch: 6| Step: 6
Training loss: 0.2999769082719008
Validation loss: 2.5491436818413424

Epoch: 6| Step: 7
Training loss: 0.5016263499276243
Validation loss: 2.552903541086365

Epoch: 6| Step: 8
Training loss: 0.48118163155761323
Validation loss: 2.5585420036077386

Epoch: 6| Step: 9
Training loss: 0.23732994478921768
Validation loss: 2.5349357505676022

Epoch: 6| Step: 10
Training loss: 0.5637931000755191
Validation loss: 2.5363339851865483

Epoch: 6| Step: 11
Training loss: 0.45898836824019223
Validation loss: 2.575851516416875

Epoch: 6| Step: 12
Training loss: 1.3718276274198653
Validation loss: 2.572164310854499

Epoch: 6| Step: 13
Training loss: 0.2249165963192472
Validation loss: 2.562321776508358

Epoch: 363| Step: 0
Training loss: 0.4000399100241871
Validation loss: 2.585963767904424

Epoch: 6| Step: 1
Training loss: 0.5907944602669783
Validation loss: 2.600529574147559

Epoch: 6| Step: 2
Training loss: 0.626940528053818
Validation loss: 2.6134834379945113

Epoch: 6| Step: 3
Training loss: 0.5227177354259204
Validation loss: 2.547968629826963

Epoch: 6| Step: 4
Training loss: 0.5998001043802331
Validation loss: 2.5362633528725564

Epoch: 6| Step: 5
Training loss: 0.31680273010638094
Validation loss: 2.5279074632649823

Epoch: 6| Step: 6
Training loss: 0.6616387058743265
Validation loss: 2.5281732744805194

Epoch: 6| Step: 7
Training loss: 0.6810166528012878
Validation loss: 2.509903301582018

Epoch: 6| Step: 8
Training loss: 0.6795050058145394
Validation loss: 2.5230433475829734

Epoch: 6| Step: 9
Training loss: 0.3862813344609249
Validation loss: 2.5473399062281277

Epoch: 6| Step: 10
Training loss: 0.26437628572119787
Validation loss: 2.5803523545346505

Epoch: 6| Step: 11
Training loss: 1.4707088799636323
Validation loss: 2.6107304548756645

Epoch: 6| Step: 12
Training loss: 0.6661855978551641
Validation loss: 2.656823921332185

Epoch: 6| Step: 13
Training loss: 0.5890131780481123
Validation loss: 2.6714280987738857

Epoch: 364| Step: 0
Training loss: 0.6925249908771709
Validation loss: 2.644753110044689

Epoch: 6| Step: 1
Training loss: 0.5908242217636035
Validation loss: 2.6088773486079373

Epoch: 6| Step: 2
Training loss: 0.5554641605407575
Validation loss: 2.538743646256616

Epoch: 6| Step: 3
Training loss: 0.3617741898632594
Validation loss: 2.4940407823322404

Epoch: 6| Step: 4
Training loss: 0.7638169563025493
Validation loss: 2.5051764630588336

Epoch: 6| Step: 5
Training loss: 0.4376484074242309
Validation loss: 2.4710659360099507

Epoch: 6| Step: 6
Training loss: 1.508923847387792
Validation loss: 2.4605387171695674

Epoch: 6| Step: 7
Training loss: 0.7588384703036322
Validation loss: 2.474952905255941

Epoch: 6| Step: 8
Training loss: 0.3224597923956259
Validation loss: 2.5065853569335332

Epoch: 6| Step: 9
Training loss: 0.8100966340572743
Validation loss: 2.5524450920085364

Epoch: 6| Step: 10
Training loss: 0.8482295264402164
Validation loss: 2.6179756840066624

Epoch: 6| Step: 11
Training loss: 0.5590332809582796
Validation loss: 2.5936965235112055

Epoch: 6| Step: 12
Training loss: 0.6307507589746143
Validation loss: 2.532011287547604

Epoch: 6| Step: 13
Training loss: 0.612852152971767
Validation loss: 2.472480452879254

Epoch: 365| Step: 0
Training loss: 0.5794983094974905
Validation loss: 2.470196354382249

Epoch: 6| Step: 1
Training loss: 0.6356912759532406
Validation loss: 2.4641138805943283

Epoch: 6| Step: 2
Training loss: 1.3204944191828831
Validation loss: 2.4454649457996718

Epoch: 6| Step: 3
Training loss: 0.41938978683622713
Validation loss: 2.4321736691425957

Epoch: 6| Step: 4
Training loss: 0.5668315737492388
Validation loss: 2.4259009067300075

Epoch: 6| Step: 5
Training loss: 0.49994608469194024
Validation loss: 2.450366510580975

Epoch: 6| Step: 6
Training loss: 0.6697354516089967
Validation loss: 2.464562317014489

Epoch: 6| Step: 7
Training loss: 0.8789531780006439
Validation loss: 2.512419298623088

Epoch: 6| Step: 8
Training loss: 0.5199526175130715
Validation loss: 2.521344232682724

Epoch: 6| Step: 9
Training loss: 0.30487130807484414
Validation loss: 2.513285364255904

Epoch: 6| Step: 10
Training loss: 0.570518717650156
Validation loss: 2.4609135535592617

Epoch: 6| Step: 11
Training loss: 0.471197509726095
Validation loss: 2.4387368407985344

Epoch: 6| Step: 12
Training loss: 0.7504318106854936
Validation loss: 2.4136130425642075

Epoch: 6| Step: 13
Training loss: 0.781376141855043
Validation loss: 2.4207973902494078

Epoch: 366| Step: 0
Training loss: 0.4980837939173408
Validation loss: 2.442255838608327

Epoch: 6| Step: 1
Training loss: 0.7138184245058841
Validation loss: 2.439937426729508

Epoch: 6| Step: 2
Training loss: 0.5831267524684728
Validation loss: 2.4750724645558986

Epoch: 6| Step: 3
Training loss: 0.476431484661338
Validation loss: 2.4958035591172814

Epoch: 6| Step: 4
Training loss: 0.37674709480826063
Validation loss: 2.499310146027299

Epoch: 6| Step: 5
Training loss: 0.4787922740678246
Validation loss: 2.5378070331746656

Epoch: 6| Step: 6
Training loss: 0.5242683876061903
Validation loss: 2.582037932056676

Epoch: 6| Step: 7
Training loss: 0.677662804422132
Validation loss: 2.623465707348991

Epoch: 6| Step: 8
Training loss: 0.5671399855875605
Validation loss: 2.613869399992154

Epoch: 6| Step: 9
Training loss: 0.3814093897595348
Validation loss: 2.593777521617263

Epoch: 6| Step: 10
Training loss: 0.44482922682052356
Validation loss: 2.550374346654746

Epoch: 6| Step: 11
Training loss: 0.5477709651418708
Validation loss: 2.496342968298108

Epoch: 6| Step: 12
Training loss: 0.5822523580350254
Validation loss: 2.468232926902611

Epoch: 6| Step: 13
Training loss: 1.7755915797685968
Validation loss: 2.469725804221816

Epoch: 367| Step: 0
Training loss: 0.4665890953471027
Validation loss: 2.4527808573003336

Epoch: 6| Step: 1
Training loss: 0.7629455468506642
Validation loss: 2.4612195867832187

Epoch: 6| Step: 2
Training loss: 0.4989984136529449
Validation loss: 2.461124348615451

Epoch: 6| Step: 3
Training loss: 0.5825930962231759
Validation loss: 2.4523173917163454

Epoch: 6| Step: 4
Training loss: 0.6949931922414513
Validation loss: 2.481281773917633

Epoch: 6| Step: 5
Training loss: 0.6058905824043
Validation loss: 2.4663914413304076

Epoch: 6| Step: 6
Training loss: 0.5116063642484018
Validation loss: 2.454025087751186

Epoch: 6| Step: 7
Training loss: 0.34485567608957757
Validation loss: 2.472030306665001

Epoch: 6| Step: 8
Training loss: 0.7277891817202439
Validation loss: 2.4495604255930408

Epoch: 6| Step: 9
Training loss: 0.5949231153388816
Validation loss: 2.4586173881187072

Epoch: 6| Step: 10
Training loss: 0.3319439043832497
Validation loss: 2.447448421422776

Epoch: 6| Step: 11
Training loss: 0.4674248880081708
Validation loss: 2.446076302506065

Epoch: 6| Step: 12
Training loss: 1.2574506440534872
Validation loss: 2.505985859686741

Epoch: 6| Step: 13
Training loss: 0.8706218313582597
Validation loss: 2.5173399780050216

Epoch: 368| Step: 0
Training loss: 0.43750425745391147
Validation loss: 2.51172056271256

Epoch: 6| Step: 1
Training loss: 0.5357209171157207
Validation loss: 2.470892490930144

Epoch: 6| Step: 2
Training loss: 0.5791591467700783
Validation loss: 2.488131481100114

Epoch: 6| Step: 3
Training loss: 0.605420879809673
Validation loss: 2.4684819981674884

Epoch: 6| Step: 4
Training loss: 1.0452864251640908
Validation loss: 2.4788540923766282

Epoch: 6| Step: 5
Training loss: 0.49314901498933855
Validation loss: 2.476548880350753

Epoch: 6| Step: 6
Training loss: 0.33088328557724506
Validation loss: 2.4795352464986955

Epoch: 6| Step: 7
Training loss: 0.41794202843927164
Validation loss: 2.492242030273887

Epoch: 6| Step: 8
Training loss: 0.4512946387056818
Validation loss: 2.505723093768824

Epoch: 6| Step: 9
Training loss: 0.4783689312974815
Validation loss: 2.4969292670788894

Epoch: 6| Step: 10
Training loss: 0.586951687792132
Validation loss: 2.4635658870872144

Epoch: 6| Step: 11
Training loss: 0.5253638221682516
Validation loss: 2.4435342771164126

Epoch: 6| Step: 12
Training loss: 0.5899726524723048
Validation loss: 2.428207851693134

Epoch: 6| Step: 13
Training loss: 0.7323042711572252
Validation loss: 2.416763913323523

Epoch: 369| Step: 0
Training loss: 0.29919594212151107
Validation loss: 2.423343996515745

Epoch: 6| Step: 1
Training loss: 0.4198307736957195
Validation loss: 2.451475340279282

Epoch: 6| Step: 2
Training loss: 0.6749889602464771
Validation loss: 2.444175244247121

Epoch: 6| Step: 3
Training loss: 0.5287853175964328
Validation loss: 2.4332894105805933

Epoch: 6| Step: 4
Training loss: 0.528300314928474
Validation loss: 2.4726931306398363

Epoch: 6| Step: 5
Training loss: 0.43042831715636476
Validation loss: 2.4451844070026216

Epoch: 6| Step: 6
Training loss: 0.3176505969173588
Validation loss: 2.4749198049556695

Epoch: 6| Step: 7
Training loss: 0.483118581198706
Validation loss: 2.4800286935323315

Epoch: 6| Step: 8
Training loss: 1.1812176412358548
Validation loss: 2.4959144659491206

Epoch: 6| Step: 9
Training loss: 0.5149771926977649
Validation loss: 2.50342874781411

Epoch: 6| Step: 10
Training loss: 0.32649445714670794
Validation loss: 2.4833072393675732

Epoch: 6| Step: 11
Training loss: 0.39115823589764676
Validation loss: 2.4679114320858524

Epoch: 6| Step: 12
Training loss: 0.510483714650034
Validation loss: 2.487406779394655

Epoch: 6| Step: 13
Training loss: 0.610595776337898
Validation loss: 2.4631987756733524

Epoch: 370| Step: 0
Training loss: 0.40343128367982356
Validation loss: 2.458261504113728

Epoch: 6| Step: 1
Training loss: 0.354585052180504
Validation loss: 2.452846382474867

Epoch: 6| Step: 2
Training loss: 0.5427257076223143
Validation loss: 2.4366888237846633

Epoch: 6| Step: 3
Training loss: 0.4249334732046656
Validation loss: 2.4148096407923254

Epoch: 6| Step: 4
Training loss: 0.4251597707224813
Validation loss: 2.42045265055245

Epoch: 6| Step: 5
Training loss: 0.26257409344352944
Validation loss: 2.40473840821621

Epoch: 6| Step: 6
Training loss: 0.41103610172104077
Validation loss: 2.409523083313357

Epoch: 6| Step: 7
Training loss: 0.692709024089574
Validation loss: 2.419646194938497

Epoch: 6| Step: 8
Training loss: 0.3326481641769496
Validation loss: 2.4242338170047235

Epoch: 6| Step: 9
Training loss: 0.513247470528027
Validation loss: 2.42620935028362

Epoch: 6| Step: 10
Training loss: 0.5568022911479552
Validation loss: 2.4278176577130344

Epoch: 6| Step: 11
Training loss: 0.4744757161885605
Validation loss: 2.418972983382462

Epoch: 6| Step: 12
Training loss: 1.1698432093492055
Validation loss: 2.425982685235389

Epoch: 6| Step: 13
Training loss: 0.435869670362738
Validation loss: 2.4672588259808776

Epoch: 371| Step: 0
Training loss: 0.3329092310531441
Validation loss: 2.497836625908269

Epoch: 6| Step: 1
Training loss: 0.47516351696153747
Validation loss: 2.5006759304046366

Epoch: 6| Step: 2
Training loss: 0.5685126238942009
Validation loss: 2.4900529538397502

Epoch: 6| Step: 3
Training loss: 0.6175115676136175
Validation loss: 2.4708993739363256

Epoch: 6| Step: 4
Training loss: 0.24636019557541133
Validation loss: 2.465363949530013

Epoch: 6| Step: 5
Training loss: 0.5089358302963508
Validation loss: 2.461328098169208

Epoch: 6| Step: 6
Training loss: 0.2649042364270985
Validation loss: 2.4376436511448842

Epoch: 6| Step: 7
Training loss: 0.5202017451449538
Validation loss: 2.4392028720691883

Epoch: 6| Step: 8
Training loss: 0.30863902810059773
Validation loss: 2.4443744274250148

Epoch: 6| Step: 9
Training loss: 0.6448687045697153
Validation loss: 2.43265159424094

Epoch: 6| Step: 10
Training loss: 0.352808418824722
Validation loss: 2.428050172943312

Epoch: 6| Step: 11
Training loss: 0.25713539796277596
Validation loss: 2.4279879787499072

Epoch: 6| Step: 12
Training loss: 0.6294563683318201
Validation loss: 2.475630705788806

Epoch: 6| Step: 13
Training loss: 1.2835440219155199
Validation loss: 2.4411066799994967

Epoch: 372| Step: 0
Training loss: 0.4291902959978903
Validation loss: 2.465191721411972

Epoch: 6| Step: 1
Training loss: 0.4915388465132812
Validation loss: 2.5146963608871706

Epoch: 6| Step: 2
Training loss: 0.5277550117981139
Validation loss: 2.51537910777607

Epoch: 6| Step: 3
Training loss: 0.534835942328677
Validation loss: 2.4872079976010695

Epoch: 6| Step: 4
Training loss: 0.6142505833332302
Validation loss: 2.4845602222259995

Epoch: 6| Step: 5
Training loss: 0.38275155730650146
Validation loss: 2.4517813287313492

Epoch: 6| Step: 6
Training loss: 0.39836067506226774
Validation loss: 2.4613998319966113

Epoch: 6| Step: 7
Training loss: 0.47695528322023667
Validation loss: 2.4484436909575558

Epoch: 6| Step: 8
Training loss: 0.6022009001083767
Validation loss: 2.4516943705092937

Epoch: 6| Step: 9
Training loss: 0.4839122930980206
Validation loss: 2.45380966782555

Epoch: 6| Step: 10
Training loss: 0.4923228728608572
Validation loss: 2.4274983835238717

Epoch: 6| Step: 11
Training loss: 0.9819899229398911
Validation loss: 2.46271955012038

Epoch: 6| Step: 12
Training loss: 0.1998195098271408
Validation loss: 2.4747314702718612

Epoch: 6| Step: 13
Training loss: 0.3412050409358867
Validation loss: 2.4880622057361172

Epoch: 373| Step: 0
Training loss: 0.42625726111931117
Validation loss: 2.4911490765155397

Epoch: 6| Step: 1
Training loss: 0.542115975754955
Validation loss: 2.525520656801741

Epoch: 6| Step: 2
Training loss: 0.3389006386552209
Validation loss: 2.479350998243028

Epoch: 6| Step: 3
Training loss: 0.5631438385313506
Validation loss: 2.468228163629595

Epoch: 6| Step: 4
Training loss: 1.0789505934942523
Validation loss: 2.439039065764321

Epoch: 6| Step: 5
Training loss: 0.5053242684753223
Validation loss: 2.424716605857123

Epoch: 6| Step: 6
Training loss: 0.2590803845838894
Validation loss: 2.419661875113859

Epoch: 6| Step: 7
Training loss: 0.47343484733014657
Validation loss: 2.422846777462612

Epoch: 6| Step: 8
Training loss: 0.5234637467365734
Validation loss: 2.4401602420415016

Epoch: 6| Step: 9
Training loss: 0.39669373345124176
Validation loss: 2.4571970755162007

Epoch: 6| Step: 10
Training loss: 0.45940983309346534
Validation loss: 2.4440435163566083

Epoch: 6| Step: 11
Training loss: 0.5607239712606683
Validation loss: 2.475892242001311

Epoch: 6| Step: 12
Training loss: 0.3521209414088767
Validation loss: 2.465899095392541

Epoch: 6| Step: 13
Training loss: 0.30403696205810815
Validation loss: 2.485383291243644

Epoch: 374| Step: 0
Training loss: 0.48776448179045584
Validation loss: 2.5069946083913925

Epoch: 6| Step: 1
Training loss: 0.4405793233964
Validation loss: 2.4959970349237555

Epoch: 6| Step: 2
Training loss: 0.2925855419201792
Validation loss: 2.4880078290869503

Epoch: 6| Step: 3
Training loss: 0.4578932108380574
Validation loss: 2.4806320290427446

Epoch: 6| Step: 4
Training loss: 0.37598609416818946
Validation loss: 2.4990974171069156

Epoch: 6| Step: 5
Training loss: 0.5618276816738016
Validation loss: 2.4602990471592077

Epoch: 6| Step: 6
Training loss: 0.5275508615190451
Validation loss: 2.4817301542586514

Epoch: 6| Step: 7
Training loss: 1.097977126385294
Validation loss: 2.4649952375086466

Epoch: 6| Step: 8
Training loss: 0.29200261075097056
Validation loss: 2.486773237763062

Epoch: 6| Step: 9
Training loss: 0.26601325438755336
Validation loss: 2.485201650054594

Epoch: 6| Step: 10
Training loss: 0.28513134886827995
Validation loss: 2.495132225403414

Epoch: 6| Step: 11
Training loss: 0.37409824987663404
Validation loss: 2.5047367685597517

Epoch: 6| Step: 12
Training loss: 0.562255514842966
Validation loss: 2.477174798575357

Epoch: 6| Step: 13
Training loss: 0.31644189892792324
Validation loss: 2.464687948010992

Epoch: 375| Step: 0
Training loss: 0.4483455297815386
Validation loss: 2.452730324612013

Epoch: 6| Step: 1
Training loss: 0.3325969925112785
Validation loss: 2.434842323889653

Epoch: 6| Step: 2
Training loss: 0.3412044295250967
Validation loss: 2.423764225326034

Epoch: 6| Step: 3
Training loss: 0.333854895584493
Validation loss: 2.4414933084696258

Epoch: 6| Step: 4
Training loss: 0.6236450767565598
Validation loss: 2.4301947270089355

Epoch: 6| Step: 5
Training loss: 0.28984407491742864
Validation loss: 2.4683145700088187

Epoch: 6| Step: 6
Training loss: 0.32328014784745357
Validation loss: 2.4398585442016905

Epoch: 6| Step: 7
Training loss: 0.49145806468467385
Validation loss: 2.455506204129806

Epoch: 6| Step: 8
Training loss: 0.546570311545576
Validation loss: 2.4646958354418733

Epoch: 6| Step: 9
Training loss: 0.4966580343082995
Validation loss: 2.440355452628377

Epoch: 6| Step: 10
Training loss: 0.39787814201818567
Validation loss: 2.487850246216694

Epoch: 6| Step: 11
Training loss: 0.22593478687920873
Validation loss: 2.4885005974340633

Epoch: 6| Step: 12
Training loss: 0.3367366489512222
Validation loss: 2.4994926737732794

Epoch: 6| Step: 13
Training loss: 1.2924015149312185
Validation loss: 2.498020764807044

Epoch: 376| Step: 0
Training loss: 0.206770841100454
Validation loss: 2.480918022837682

Epoch: 6| Step: 1
Training loss: 0.9234869167576311
Validation loss: 2.528476154867087

Epoch: 6| Step: 2
Training loss: 0.4785860593690351
Validation loss: 2.570542656686723

Epoch: 6| Step: 3
Training loss: 0.5289502011495724
Validation loss: 2.566204403802349

Epoch: 6| Step: 4
Training loss: 0.6263116900578976
Validation loss: 2.5623029297434066

Epoch: 6| Step: 5
Training loss: 0.5619824995967916
Validation loss: 2.487032422474437

Epoch: 6| Step: 6
Training loss: 0.5910872935971797
Validation loss: 2.4435899182974703

Epoch: 6| Step: 7
Training loss: 0.6291181787749761
Validation loss: 2.4362056251916444

Epoch: 6| Step: 8
Training loss: 0.5182090512561828
Validation loss: 2.422420814661161

Epoch: 6| Step: 9
Training loss: 0.270287255117142
Validation loss: 2.4239412393905893

Epoch: 6| Step: 10
Training loss: 0.4846063338348345
Validation loss: 2.4024635592536017

Epoch: 6| Step: 11
Training loss: 0.45347157740031896
Validation loss: 2.4459814069982015

Epoch: 6| Step: 12
Training loss: 0.2503924865177366
Validation loss: 2.4485715668596106

Epoch: 6| Step: 13
Training loss: 0.3058959032951624
Validation loss: 2.4632579514612774

Epoch: 377| Step: 0
Training loss: 0.5476236940467167
Validation loss: 2.487507827217978

Epoch: 6| Step: 1
Training loss: 0.5803318945664011
Validation loss: 2.505698595181865

Epoch: 6| Step: 2
Training loss: 0.43529131794676945
Validation loss: 2.5003941737931874

Epoch: 6| Step: 3
Training loss: 0.276653209185675
Validation loss: 2.5245346203352255

Epoch: 6| Step: 4
Training loss: 0.23377405849869326
Validation loss: 2.5279105685458987

Epoch: 6| Step: 5
Training loss: 0.9016740634060126
Validation loss: 2.4481254715491936

Epoch: 6| Step: 6
Training loss: 0.4230928503469714
Validation loss: 2.4811493957528703

Epoch: 6| Step: 7
Training loss: 0.352763572067476
Validation loss: 2.4575726281288763

Epoch: 6| Step: 8
Training loss: 0.4635703974474507
Validation loss: 2.4339284306406572

Epoch: 6| Step: 9
Training loss: 0.41902643587617355
Validation loss: 2.4498900447227605

Epoch: 6| Step: 10
Training loss: 0.24718422958679748
Validation loss: 2.425406709797966

Epoch: 6| Step: 11
Training loss: 0.5243142599543983
Validation loss: 2.4242996849560114

Epoch: 6| Step: 12
Training loss: 0.3005259656660703
Validation loss: 2.430154385799172

Epoch: 6| Step: 13
Training loss: 0.6485238075268619
Validation loss: 2.4252191732930237

Epoch: 378| Step: 0
Training loss: 0.24992196534117306
Validation loss: 2.421887255692873

Epoch: 6| Step: 1
Training loss: 0.27148824455741905
Validation loss: 2.4475920427684823

Epoch: 6| Step: 2
Training loss: 0.5387700711293063
Validation loss: 2.419942061059416

Epoch: 6| Step: 3
Training loss: 0.3237163143602134
Validation loss: 2.4280931738947684

Epoch: 6| Step: 4
Training loss: 0.5042308974007088
Validation loss: 2.447596300500137

Epoch: 6| Step: 5
Training loss: 0.28955255671916924
Validation loss: 2.4494501400934836

Epoch: 6| Step: 6
Training loss: 0.49062119379207253
Validation loss: 2.4379754939720852

Epoch: 6| Step: 7
Training loss: 0.2898307334671056
Validation loss: 2.4483201611828935

Epoch: 6| Step: 8
Training loss: 0.5119147180278704
Validation loss: 2.4678368406741114

Epoch: 6| Step: 9
Training loss: 0.1958799321114191
Validation loss: 2.4622306013830375

Epoch: 6| Step: 10
Training loss: 0.4904241308628985
Validation loss: 2.453873310606585

Epoch: 6| Step: 11
Training loss: 0.9710941256386605
Validation loss: 2.456090912463794

Epoch: 6| Step: 12
Training loss: 0.3575587401449944
Validation loss: 2.4717791753202576

Epoch: 6| Step: 13
Training loss: 0.681861907106009
Validation loss: 2.4664929904868536

Epoch: 379| Step: 0
Training loss: 0.7898900442017333
Validation loss: 2.45489441170926

Epoch: 6| Step: 1
Training loss: 0.3633555674676377
Validation loss: 2.4566354771774694

Epoch: 6| Step: 2
Training loss: 0.35349794206600266
Validation loss: 2.4518434306725605

Epoch: 6| Step: 3
Training loss: 0.36732914404346606
Validation loss: 2.4162595198719146

Epoch: 6| Step: 4
Training loss: 0.36607903711872164
Validation loss: 2.4292411772790334

Epoch: 6| Step: 5
Training loss: 0.29757094374825105
Validation loss: 2.399289032009896

Epoch: 6| Step: 6
Training loss: 0.44581346608694594
Validation loss: 2.409130842066843

Epoch: 6| Step: 7
Training loss: 0.49218277701882
Validation loss: 2.391514171429227

Epoch: 6| Step: 8
Training loss: 0.6043649024869392
Validation loss: 2.4182638418032085

Epoch: 6| Step: 9
Training loss: 0.43541807998841564
Validation loss: 2.422332806143786

Epoch: 6| Step: 10
Training loss: 0.3380567550185138
Validation loss: 2.424251909799094

Epoch: 6| Step: 11
Training loss: 0.45100127128096257
Validation loss: 2.407814674195192

Epoch: 6| Step: 12
Training loss: 0.47763887388140547
Validation loss: 2.419810211675757

Epoch: 6| Step: 13
Training loss: 0.6248134573070278
Validation loss: 2.444627187940447

Epoch: 380| Step: 0
Training loss: 0.2726048735387255
Validation loss: 2.4424469692520527

Epoch: 6| Step: 1
Training loss: 0.3369863681328338
Validation loss: 2.4844001123293347

Epoch: 6| Step: 2
Training loss: 0.9107932288952261
Validation loss: 2.4924054257069828

Epoch: 6| Step: 3
Training loss: 0.36328598757700287
Validation loss: 2.504802554762048

Epoch: 6| Step: 4
Training loss: 0.3442422853061125
Validation loss: 2.539779446256765

Epoch: 6| Step: 5
Training loss: 0.4095524294200288
Validation loss: 2.5266130077601536

Epoch: 6| Step: 6
Training loss: 0.28284692396710215
Validation loss: 2.5370556160822946

Epoch: 6| Step: 7
Training loss: 0.4392024024355693
Validation loss: 2.5036097143898943

Epoch: 6| Step: 8
Training loss: 0.47965675839506483
Validation loss: 2.4725460018904952

Epoch: 6| Step: 9
Training loss: 0.2759794743972145
Validation loss: 2.474462216178908

Epoch: 6| Step: 10
Training loss: 0.4715024405797534
Validation loss: 2.442702978040695

Epoch: 6| Step: 11
Training loss: 0.5485685827642305
Validation loss: 2.439693500464433

Epoch: 6| Step: 12
Training loss: 0.5939502880185332
Validation loss: 2.4020196975739916

Epoch: 6| Step: 13
Training loss: 0.21465706083350347
Validation loss: 2.4293755381585385

Epoch: 381| Step: 0
Training loss: 0.4263424106446285
Validation loss: 2.4049434985062677

Epoch: 6| Step: 1
Training loss: 0.3624459785460404
Validation loss: 2.4172172679407535

Epoch: 6| Step: 2
Training loss: 0.25035475356409975
Validation loss: 2.4419561166734622

Epoch: 6| Step: 3
Training loss: 0.20918089993621478
Validation loss: 2.4481940481261275

Epoch: 6| Step: 4
Training loss: 0.21508567367259857
Validation loss: 2.477566748192885

Epoch: 6| Step: 5
Training loss: 0.5395675173273984
Validation loss: 2.4817413520118583

Epoch: 6| Step: 6
Training loss: 0.49069242621536224
Validation loss: 2.4869159828118232

Epoch: 6| Step: 7
Training loss: 0.5716837245223875
Validation loss: 2.473806237476798

Epoch: 6| Step: 8
Training loss: 0.9380460420504586
Validation loss: 2.4651232583808476

Epoch: 6| Step: 9
Training loss: 0.4346564561137298
Validation loss: 2.4347534181908537

Epoch: 6| Step: 10
Training loss: 0.3157093355605884
Validation loss: 2.4542784624671223

Epoch: 6| Step: 11
Training loss: 0.2852840137362443
Validation loss: 2.430296485872158

Epoch: 6| Step: 12
Training loss: 0.42953550945125263
Validation loss: 2.4584492266245657

Epoch: 6| Step: 13
Training loss: 0.3806713129001929
Validation loss: 2.4854385638931564

Epoch: 382| Step: 0
Training loss: 0.33829707577800605
Validation loss: 2.4666297107756185

Epoch: 6| Step: 1
Training loss: 0.4505080586939385
Validation loss: 2.4551989935731235

Epoch: 6| Step: 2
Training loss: 0.7890033133187002
Validation loss: 2.5052468400496624

Epoch: 6| Step: 3
Training loss: 0.4135396283129111
Validation loss: 2.5051536783491883

Epoch: 6| Step: 4
Training loss: 0.35634643019227197
Validation loss: 2.475547950457872

Epoch: 6| Step: 5
Training loss: 0.5612372954699973
Validation loss: 2.515770287032544

Epoch: 6| Step: 6
Training loss: 0.34000659198190875
Validation loss: 2.4879998939720416

Epoch: 6| Step: 7
Training loss: 0.36856593451954356
Validation loss: 2.4795674570275485

Epoch: 6| Step: 8
Training loss: 0.32043817427288773
Validation loss: 2.507673171062079

Epoch: 6| Step: 9
Training loss: 0.2523710348300522
Validation loss: 2.467499771155556

Epoch: 6| Step: 10
Training loss: 0.45074482312776154
Validation loss: 2.4566737869220066

Epoch: 6| Step: 11
Training loss: 0.6392054763941295
Validation loss: 2.4742707310547827

Epoch: 6| Step: 12
Training loss: 0.3561134361057952
Validation loss: 2.441888023701271

Epoch: 6| Step: 13
Training loss: 0.44894996562986944
Validation loss: 2.442646837019042

Epoch: 383| Step: 0
Training loss: 0.2117999072615913
Validation loss: 2.453180182250222

Epoch: 6| Step: 1
Training loss: 0.6967535623022035
Validation loss: 2.447205584806449

Epoch: 6| Step: 2
Training loss: 0.8510121308099762
Validation loss: 2.4403417401607137

Epoch: 6| Step: 3
Training loss: 0.45710729308722675
Validation loss: 2.4522161671538734

Epoch: 6| Step: 4
Training loss: 0.40080675040278674
Validation loss: 2.4508949878068114

Epoch: 6| Step: 5
Training loss: 0.27484390423603944
Validation loss: 2.4839465003361205

Epoch: 6| Step: 6
Training loss: 0.275674903184025
Validation loss: 2.4573893563976346

Epoch: 6| Step: 7
Training loss: 0.5090796872510719
Validation loss: 2.4827470161872682

Epoch: 6| Step: 8
Training loss: 0.2635011190701922
Validation loss: 2.4815228883081133

Epoch: 6| Step: 9
Training loss: 0.30180459755485417
Validation loss: 2.4575424117803086

Epoch: 6| Step: 10
Training loss: 0.4864918077157447
Validation loss: 2.4794231753288547

Epoch: 6| Step: 11
Training loss: 0.23179824895551207
Validation loss: 2.484501458884523

Epoch: 6| Step: 12
Training loss: 0.33802441059721633
Validation loss: 2.4701028389286788

Epoch: 6| Step: 13
Training loss: 0.5068061834579838
Validation loss: 2.4358364914934985

Epoch: 384| Step: 0
Training loss: 0.41950368240113334
Validation loss: 2.4160884298712304

Epoch: 6| Step: 1
Training loss: 0.4726530027672061
Validation loss: 2.419201292579914

Epoch: 6| Step: 2
Training loss: 0.42482585635002684
Validation loss: 2.4401998174251793

Epoch: 6| Step: 3
Training loss: 0.3898194781374999
Validation loss: 2.4074271457335534

Epoch: 6| Step: 4
Training loss: 0.38193095164115454
Validation loss: 2.4172033722448236

Epoch: 6| Step: 5
Training loss: 0.1648160680696387
Validation loss: 2.406540824192485

Epoch: 6| Step: 6
Training loss: 0.6202127698390032
Validation loss: 2.4123314157324476

Epoch: 6| Step: 7
Training loss: 0.3696070958181939
Validation loss: 2.424471102227357

Epoch: 6| Step: 8
Training loss: 0.35260387469476345
Validation loss: 2.4037264399981972

Epoch: 6| Step: 9
Training loss: 0.3563493991515424
Validation loss: 2.4381229119003627

Epoch: 6| Step: 10
Training loss: 0.19785519113630565
Validation loss: 2.4312375291967987

Epoch: 6| Step: 11
Training loss: 0.7853878685472081
Validation loss: 2.4442437056262607

Epoch: 6| Step: 12
Training loss: 0.3603349593971597
Validation loss: 2.433018812428549

Epoch: 6| Step: 13
Training loss: 0.23656929730737047
Validation loss: 2.4423942373598093

Epoch: 385| Step: 0
Training loss: 0.691036362495878
Validation loss: 2.477287787963544

Epoch: 6| Step: 1
Training loss: 0.4777207604228278
Validation loss: 2.4762765151167447

Epoch: 6| Step: 2
Training loss: 0.3202165599519903
Validation loss: 2.4555476228374298

Epoch: 6| Step: 3
Training loss: 0.28214922838708884
Validation loss: 2.436065216579804

Epoch: 6| Step: 4
Training loss: 0.4366436991068913
Validation loss: 2.4445230750294087

Epoch: 6| Step: 5
Training loss: 0.5427276020937083
Validation loss: 2.4145223586620608

Epoch: 6| Step: 6
Training loss: 0.3010943381002371
Validation loss: 2.423455785808756

Epoch: 6| Step: 7
Training loss: 0.3127957137002591
Validation loss: 2.428261141340926

Epoch: 6| Step: 8
Training loss: 0.7880829500238643
Validation loss: 2.4475209757868543

Epoch: 6| Step: 9
Training loss: 0.29272850358550495
Validation loss: 2.4324387859851804

Epoch: 6| Step: 10
Training loss: 0.33977005696689927
Validation loss: 2.455444882863755

Epoch: 6| Step: 11
Training loss: 0.18730465329103288
Validation loss: 2.4831146987479973

Epoch: 6| Step: 12
Training loss: 0.30513432335586355
Validation loss: 2.491596549055808

Epoch: 6| Step: 13
Training loss: 0.4612084901424418
Validation loss: 2.508880339075776

Epoch: 386| Step: 0
Training loss: 0.35491522985774965
Validation loss: 2.4873913155051217

Epoch: 6| Step: 1
Training loss: 0.3756616636082438
Validation loss: 2.4950509306675785

Epoch: 6| Step: 2
Training loss: 0.5459262247127648
Validation loss: 2.4381576052788385

Epoch: 6| Step: 3
Training loss: 0.40920496022694386
Validation loss: 2.4539613298112433

Epoch: 6| Step: 4
Training loss: 0.3326623304715307
Validation loss: 2.4719375376866193

Epoch: 6| Step: 5
Training loss: 0.3404488383611581
Validation loss: 2.4556996070760824

Epoch: 6| Step: 6
Training loss: 0.2566482815696296
Validation loss: 2.457194446350668

Epoch: 6| Step: 7
Training loss: 0.7365018199579629
Validation loss: 2.476798475420413

Epoch: 6| Step: 8
Training loss: 0.37911800484472197
Validation loss: 2.4993005522692284

Epoch: 6| Step: 9
Training loss: 0.44619115510943086
Validation loss: 2.486084638540074

Epoch: 6| Step: 10
Training loss: 0.25148171673804004
Validation loss: 2.493870364009248

Epoch: 6| Step: 11
Training loss: 0.30288843726272535
Validation loss: 2.510767414921312

Epoch: 6| Step: 12
Training loss: 0.5642273659313689
Validation loss: 2.504394950949276

Epoch: 6| Step: 13
Training loss: 0.5088977075362859
Validation loss: 2.4718798196759955

Epoch: 387| Step: 0
Training loss: 0.28307701459981544
Validation loss: 2.4751044742198682

Epoch: 6| Step: 1
Training loss: 0.6905794965848342
Validation loss: 2.4454108988366485

Epoch: 6| Step: 2
Training loss: 0.37484376354781995
Validation loss: 2.434336991487099

Epoch: 6| Step: 3
Training loss: 0.3564159851550821
Validation loss: 2.4113738087420495

Epoch: 6| Step: 4
Training loss: 0.4775282657705539
Validation loss: 2.411767670832073

Epoch: 6| Step: 5
Training loss: 0.4278843063882554
Validation loss: 2.406495785848683

Epoch: 6| Step: 6
Training loss: 0.32851746339771193
Validation loss: 2.4055170126201024

Epoch: 6| Step: 7
Training loss: 0.7293060351196461
Validation loss: 2.4069174299162848

Epoch: 6| Step: 8
Training loss: 0.44899531903195133
Validation loss: 2.445987709233876

Epoch: 6| Step: 9
Training loss: 0.4235518825360377
Validation loss: 2.480104260499965

Epoch: 6| Step: 10
Training loss: 0.1667083201412751
Validation loss: 2.470580066925521

Epoch: 6| Step: 11
Training loss: 0.4177096624503866
Validation loss: 2.502283284183649

Epoch: 6| Step: 12
Training loss: 0.19431102535501737
Validation loss: 2.4729765168634215

Epoch: 6| Step: 13
Training loss: 0.3482341035855616
Validation loss: 2.4873806203821225

Epoch: 388| Step: 0
Training loss: 0.4437089289879948
Validation loss: 2.458278699893152

Epoch: 6| Step: 1
Training loss: 0.47664954219193095
Validation loss: 2.4315763454883705

Epoch: 6| Step: 2
Training loss: 0.4856996266823666
Validation loss: 2.456936260069482

Epoch: 6| Step: 3
Training loss: 0.33722367365755346
Validation loss: 2.4391934460162235

Epoch: 6| Step: 4
Training loss: 0.40917486219815763
Validation loss: 2.422611420206552

Epoch: 6| Step: 5
Training loss: 0.26691496596706143
Validation loss: 2.4362040882941467

Epoch: 6| Step: 6
Training loss: 0.27555774460701954
Validation loss: 2.4388596397781512

Epoch: 6| Step: 7
Training loss: 0.4013401959850076
Validation loss: 2.4571432094040895

Epoch: 6| Step: 8
Training loss: 0.2811499921164392
Validation loss: 2.425903842459722

Epoch: 6| Step: 9
Training loss: 0.18879498874006484
Validation loss: 2.4367903340776285

Epoch: 6| Step: 10
Training loss: 0.4675670479057523
Validation loss: 2.4360101783507875

Epoch: 6| Step: 11
Training loss: 0.47674191333931715
Validation loss: 2.4555431554721237

Epoch: 6| Step: 12
Training loss: 0.7311960363446534
Validation loss: 2.4679196748672614

Epoch: 6| Step: 13
Training loss: 0.32817541597967226
Validation loss: 2.519674081546426

Epoch: 389| Step: 0
Training loss: 0.727390719658044
Validation loss: 2.545119640381994

Epoch: 6| Step: 1
Training loss: 0.6559887093395202
Validation loss: 2.5655644913821067

Epoch: 6| Step: 2
Training loss: 0.5394541658229856
Validation loss: 2.554394425729424

Epoch: 6| Step: 3
Training loss: 0.33095053775886013
Validation loss: 2.542796213951705

Epoch: 6| Step: 4
Training loss: 0.24622538996696675
Validation loss: 2.4916011328671517

Epoch: 6| Step: 5
Training loss: 0.42868785752580335
Validation loss: 2.4801290889150445

Epoch: 6| Step: 6
Training loss: 0.25449180573722446
Validation loss: 2.4373969925833094

Epoch: 6| Step: 7
Training loss: 0.3438796969141173
Validation loss: 2.407840170832419

Epoch: 6| Step: 8
Training loss: 0.2743426192603929
Validation loss: 2.3978149326481835

Epoch: 6| Step: 9
Training loss: 0.316875451311471
Validation loss: 2.3807732016006553

Epoch: 6| Step: 10
Training loss: 0.5194375663558078
Validation loss: 2.384944250135814

Epoch: 6| Step: 11
Training loss: 0.36138729951209125
Validation loss: 2.407961957283445

Epoch: 6| Step: 12
Training loss: 0.33510099546864636
Validation loss: 2.4242322920812884

Epoch: 6| Step: 13
Training loss: 0.46679055437094363
Validation loss: 2.4473151737589416

Epoch: 390| Step: 0
Training loss: 0.4083944173621387
Validation loss: 2.4665514906483987

Epoch: 6| Step: 1
Training loss: 0.5018015829426994
Validation loss: 2.4669900848914548

Epoch: 6| Step: 2
Training loss: 0.4767654643368709
Validation loss: 2.524628133081941

Epoch: 6| Step: 3
Training loss: 0.2947995014070645
Validation loss: 2.4991633686811934

Epoch: 6| Step: 4
Training loss: 0.33024526348442584
Validation loss: 2.439097380388222

Epoch: 6| Step: 5
Training loss: 0.7046996815510357
Validation loss: 2.4301583465273375

Epoch: 6| Step: 6
Training loss: 0.2744451484856689
Validation loss: 2.4429207856863524

Epoch: 6| Step: 7
Training loss: 0.23833878401017633
Validation loss: 2.432106409072731

Epoch: 6| Step: 8
Training loss: 0.6089253355994225
Validation loss: 2.4265919627680157

Epoch: 6| Step: 9
Training loss: 0.5062936222450016
Validation loss: 2.42931151582898

Epoch: 6| Step: 10
Training loss: 0.3997963752124746
Validation loss: 2.444032464761731

Epoch: 6| Step: 11
Training loss: 0.29171728506675637
Validation loss: 2.436948528227423

Epoch: 6| Step: 12
Training loss: 0.5510389117608916
Validation loss: 2.4578324383455366

Epoch: 6| Step: 13
Training loss: 0.39619728556034833
Validation loss: 2.474605901363647

Epoch: 391| Step: 0
Training loss: 0.3631069216274143
Validation loss: 2.4476939089310505

Epoch: 6| Step: 1
Training loss: 0.17497515225266896
Validation loss: 2.4594984131983657

Epoch: 6| Step: 2
Training loss: 0.23567765149773384
Validation loss: 2.4682112646343795

Epoch: 6| Step: 3
Training loss: 0.404711819069002
Validation loss: 2.45612336625833

Epoch: 6| Step: 4
Training loss: 0.3467276311685025
Validation loss: 2.414551105613508

Epoch: 6| Step: 5
Training loss: 0.616550164773616
Validation loss: 2.437857642386411

Epoch: 6| Step: 6
Training loss: 0.7656851375083481
Validation loss: 2.4352043543811313

Epoch: 6| Step: 7
Training loss: 0.20990443689274008
Validation loss: 2.4083266974087105

Epoch: 6| Step: 8
Training loss: 0.41378062028320556
Validation loss: 2.433632471446825

Epoch: 6| Step: 9
Training loss: 0.3622211863903403
Validation loss: 2.4252910613139065

Epoch: 6| Step: 10
Training loss: 0.37288590398453736
Validation loss: 2.413635725923627

Epoch: 6| Step: 11
Training loss: 0.43554949225079836
Validation loss: 2.3980751780696967

Epoch: 6| Step: 12
Training loss: 0.37425999344458144
Validation loss: 2.4209336601893403

Epoch: 6| Step: 13
Training loss: 0.243967131959053
Validation loss: 2.423951279481395

Epoch: 392| Step: 0
Training loss: 0.2547338934926993
Validation loss: 2.403124658049653

Epoch: 6| Step: 1
Training loss: 0.45186208798861616
Validation loss: 2.4068844761391377

Epoch: 6| Step: 2
Training loss: 0.2956832506160306
Validation loss: 2.4079001406867278

Epoch: 6| Step: 3
Training loss: 0.270252603168107
Validation loss: 2.4120324999279257

Epoch: 6| Step: 4
Training loss: 0.39086002908698064
Validation loss: 2.424858979130498

Epoch: 6| Step: 5
Training loss: 0.31938630619677705
Validation loss: 2.4287216650929118

Epoch: 6| Step: 6
Training loss: 0.4486979575515997
Validation loss: 2.42944877419019

Epoch: 6| Step: 7
Training loss: 0.30970320872509743
Validation loss: 2.469113297352305

Epoch: 6| Step: 8
Training loss: 0.4644350451005541
Validation loss: 2.4708021209039686

Epoch: 6| Step: 9
Training loss: 0.4028435537828857
Validation loss: 2.4523648981920574

Epoch: 6| Step: 10
Training loss: 0.30353814757058534
Validation loss: 2.4738791955143635

Epoch: 6| Step: 11
Training loss: 0.7287695393633753
Validation loss: 2.4776768380822336

Epoch: 6| Step: 12
Training loss: 0.46474168762952744
Validation loss: 2.5075542306865857

Epoch: 6| Step: 13
Training loss: 0.22320641759220392
Validation loss: 2.5206301865012843

Epoch: 393| Step: 0
Training loss: 0.4138448611075097
Validation loss: 2.516862839233463

Epoch: 6| Step: 1
Training loss: 0.44460657282757143
Validation loss: 2.5143984948111306

Epoch: 6| Step: 2
Training loss: 0.4518687163637596
Validation loss: 2.4640981363148193

Epoch: 6| Step: 3
Training loss: 0.4295246682715685
Validation loss: 2.4283709349158253

Epoch: 6| Step: 4
Training loss: 0.35782946084149087
Validation loss: 2.451183252880564

Epoch: 6| Step: 5
Training loss: 0.3082165646251722
Validation loss: 2.437497168687344

Epoch: 6| Step: 6
Training loss: 0.48381520810125156
Validation loss: 2.3987815882410124

Epoch: 6| Step: 7
Training loss: 0.30489828692405696
Validation loss: 2.4376386703453123

Epoch: 6| Step: 8
Training loss: 0.26939125848371187
Validation loss: 2.4311559221798404

Epoch: 6| Step: 9
Training loss: 0.2737178999661912
Validation loss: 2.431178593706649

Epoch: 6| Step: 10
Training loss: 0.3956451930938667
Validation loss: 2.438911222330176

Epoch: 6| Step: 11
Training loss: 0.825861807280017
Validation loss: 2.4494604011229835

Epoch: 6| Step: 12
Training loss: 0.2792209975670353
Validation loss: 2.4439130286154835

Epoch: 6| Step: 13
Training loss: 0.1692673695038692
Validation loss: 2.462101103561923

Epoch: 394| Step: 0
Training loss: 0.4632297030457889
Validation loss: 2.502789149491978

Epoch: 6| Step: 1
Training loss: 0.49058441188601465
Validation loss: 2.49707938199241

Epoch: 6| Step: 2
Training loss: 0.4755665111294881
Validation loss: 2.4572947605849107

Epoch: 6| Step: 3
Training loss: 0.2689933800387955
Validation loss: 2.4382566556012706

Epoch: 6| Step: 4
Training loss: 0.27551028851027
Validation loss: 2.424880835207272

Epoch: 6| Step: 5
Training loss: 0.26267392663515826
Validation loss: 2.419839174438181

Epoch: 6| Step: 6
Training loss: 0.3373262620485994
Validation loss: 2.414031642397083

Epoch: 6| Step: 7
Training loss: 0.35037153695974416
Validation loss: 2.4072270736888486

Epoch: 6| Step: 8
Training loss: 0.4130761255853023
Validation loss: 2.4261990115240066

Epoch: 6| Step: 9
Training loss: 0.7675687289451545
Validation loss: 2.4153205958900292

Epoch: 6| Step: 10
Training loss: 0.17531501078890147
Validation loss: 2.415889719765117

Epoch: 6| Step: 11
Training loss: 0.27148356540476887
Validation loss: 2.4379571507542828

Epoch: 6| Step: 12
Training loss: 0.4959859355405283
Validation loss: 2.4529073333996054

Epoch: 6| Step: 13
Training loss: 0.2513030633594332
Validation loss: 2.4533613509248706

Epoch: 395| Step: 0
Training loss: 0.220927698101396
Validation loss: 2.4799006647360433

Epoch: 6| Step: 1
Training loss: 0.40033053435679333
Validation loss: 2.465888732266329

Epoch: 6| Step: 2
Training loss: 0.28794953301278114
Validation loss: 2.4612402788779986

Epoch: 6| Step: 3
Training loss: 0.2492539479623113
Validation loss: 2.469210756025706

Epoch: 6| Step: 4
Training loss: 0.2835117894215692
Validation loss: 2.4480673138603954

Epoch: 6| Step: 5
Training loss: 0.5352706786842297
Validation loss: 2.4471606105267814

Epoch: 6| Step: 6
Training loss: 0.37519672320059494
Validation loss: 2.445872590516388

Epoch: 6| Step: 7
Training loss: 0.2497899693141619
Validation loss: 2.4452537789833313

Epoch: 6| Step: 8
Training loss: 0.36095072651858806
Validation loss: 2.4415406444024104

Epoch: 6| Step: 9
Training loss: 0.5317064456149386
Validation loss: 2.4421879083034486

Epoch: 6| Step: 10
Training loss: 0.332089867746942
Validation loss: 2.4306372052691696

Epoch: 6| Step: 11
Training loss: 0.6561765856777584
Validation loss: 2.4213613769319995

Epoch: 6| Step: 12
Training loss: 0.27595193622104747
Validation loss: 2.443228072151558

Epoch: 6| Step: 13
Training loss: 0.265776268577652
Validation loss: 2.431445167587516

Epoch: 396| Step: 0
Training loss: 0.46384127895882066
Validation loss: 2.4611322464252963

Epoch: 6| Step: 1
Training loss: 0.3595264778997572
Validation loss: 2.4590683090922845

Epoch: 6| Step: 2
Training loss: 0.321231802154054
Validation loss: 2.4532387522046504

Epoch: 6| Step: 3
Training loss: 0.21595937469030665
Validation loss: 2.454430362353998

Epoch: 6| Step: 4
Training loss: 0.31062462271316305
Validation loss: 2.4639625501109976

Epoch: 6| Step: 5
Training loss: 0.17361993859948918
Validation loss: 2.4896472646899026

Epoch: 6| Step: 6
Training loss: 0.3427928690822983
Validation loss: 2.449339923418092

Epoch: 6| Step: 7
Training loss: 0.6820365171458518
Validation loss: 2.443373168110017

Epoch: 6| Step: 8
Training loss: 0.37504730323627516
Validation loss: 2.4807432581377546

Epoch: 6| Step: 9
Training loss: 0.4052414111616269
Validation loss: 2.4506529027860813

Epoch: 6| Step: 10
Training loss: 0.37175687468533614
Validation loss: 2.432655238965288

Epoch: 6| Step: 11
Training loss: 0.2539605889495327
Validation loss: 2.421274984807682

Epoch: 6| Step: 12
Training loss: 0.3267756715444126
Validation loss: 2.4479857599739816

Epoch: 6| Step: 13
Training loss: 0.2878824064616348
Validation loss: 2.4446341553848874

Epoch: 397| Step: 0
Training loss: 0.24625545820005945
Validation loss: 2.442688080204109

Epoch: 6| Step: 1
Training loss: 0.3205457861312606
Validation loss: 2.415709645157691

Epoch: 6| Step: 2
Training loss: 0.29740301659098894
Validation loss: 2.429111343421075

Epoch: 6| Step: 3
Training loss: 0.22769009403381457
Validation loss: 2.4337399154288897

Epoch: 6| Step: 4
Training loss: 0.7051479907305482
Validation loss: 2.436179184737074

Epoch: 6| Step: 5
Training loss: 0.39183642415026076
Validation loss: 2.4365723251083256

Epoch: 6| Step: 6
Training loss: 0.39688824533902733
Validation loss: 2.453776964549914

Epoch: 6| Step: 7
Training loss: 0.2720347800948774
Validation loss: 2.492936967412344

Epoch: 6| Step: 8
Training loss: 0.2493336036210733
Validation loss: 2.4763945881063156

Epoch: 6| Step: 9
Training loss: 0.33196243246150847
Validation loss: 2.493952735450122

Epoch: 6| Step: 10
Training loss: 0.41342066556835166
Validation loss: 2.4892761196066937

Epoch: 6| Step: 11
Training loss: 0.5479198284082121
Validation loss: 2.451017830320877

Epoch: 6| Step: 12
Training loss: 0.4233199558184393
Validation loss: 2.4463422862854496

Epoch: 6| Step: 13
Training loss: 0.1991371193237143
Validation loss: 2.4242542674889016

Epoch: 398| Step: 0
Training loss: 0.3568011663123279
Validation loss: 2.413601201587462

Epoch: 6| Step: 1
Training loss: 0.22043798775452658
Validation loss: 2.41544031470524

Epoch: 6| Step: 2
Training loss: 0.3437761275158867
Validation loss: 2.388354250946658

Epoch: 6| Step: 3
Training loss: 0.23704535045690486
Validation loss: 2.3635100266579334

Epoch: 6| Step: 4
Training loss: 0.4246022235229515
Validation loss: 2.4019276760621224

Epoch: 6| Step: 5
Training loss: 0.3667551295175922
Validation loss: 2.3978013500391033

Epoch: 6| Step: 6
Training loss: 0.1620417419354784
Validation loss: 2.383227635234216

Epoch: 6| Step: 7
Training loss: 0.2455597108719926
Validation loss: 2.4182079465314392

Epoch: 6| Step: 8
Training loss: 0.42439464203403277
Validation loss: 2.4365924826490835

Epoch: 6| Step: 9
Training loss: 0.3226853613848159
Validation loss: 2.450960620404673

Epoch: 6| Step: 10
Training loss: 0.3782320808873399
Validation loss: 2.434839955920879

Epoch: 6| Step: 11
Training loss: 0.6320048700398513
Validation loss: 2.4502145256411634

Epoch: 6| Step: 12
Training loss: 0.5367387082138576
Validation loss: 2.4862142688770956

Epoch: 6| Step: 13
Training loss: 0.3312597849138434
Validation loss: 2.440490709550106

Epoch: 399| Step: 0
Training loss: 0.3406508278460279
Validation loss: 2.4253653006427554

Epoch: 6| Step: 1
Training loss: 0.18149922106972421
Validation loss: 2.428510934634768

Epoch: 6| Step: 2
Training loss: 0.2902829849588843
Validation loss: 2.440380931791797

Epoch: 6| Step: 3
Training loss: 0.6925751455278419
Validation loss: 2.423569521578639

Epoch: 6| Step: 4
Training loss: 0.3408117867089283
Validation loss: 2.422621189615888

Epoch: 6| Step: 5
Training loss: 0.422128283444129
Validation loss: 2.4157739934718743

Epoch: 6| Step: 6
Training loss: 0.13277226427619912
Validation loss: 2.406948664171732

Epoch: 6| Step: 7
Training loss: 0.33718180314873725
Validation loss: 2.406932657798125

Epoch: 6| Step: 8
Training loss: 0.2776700504675143
Validation loss: 2.418299736010689

Epoch: 6| Step: 9
Training loss: 0.4004068138757497
Validation loss: 2.3908259295079843

Epoch: 6| Step: 10
Training loss: 0.23354997862697546
Validation loss: 2.4524910037471424

Epoch: 6| Step: 11
Training loss: 0.4995827125670601
Validation loss: 2.4287414597682813

Epoch: 6| Step: 12
Training loss: 0.4252935994227887
Validation loss: 2.4454563940782146

Epoch: 6| Step: 13
Training loss: 0.27326436692394906
Validation loss: 2.450257687957988

Epoch: 400| Step: 0
Training loss: 0.33793810692717324
Validation loss: 2.430012099123131

Epoch: 6| Step: 1
Training loss: 0.3296724682133671
Validation loss: 2.441290907893661

Epoch: 6| Step: 2
Training loss: 0.39255155407009185
Validation loss: 2.487139030480781

Epoch: 6| Step: 3
Training loss: 0.24075507512492073
Validation loss: 2.4725927599320014

Epoch: 6| Step: 4
Training loss: 0.4544209003483286
Validation loss: 2.4785263640653366

Epoch: 6| Step: 5
Training loss: 0.4879075260457186
Validation loss: 2.470768255286227

Epoch: 6| Step: 6
Training loss: 0.21852699902105338
Validation loss: 2.4906268509568577

Epoch: 6| Step: 7
Training loss: 0.585606825026427
Validation loss: 2.484957224792035

Epoch: 6| Step: 8
Training loss: 0.38485279160912333
Validation loss: 2.473710782802994

Epoch: 6| Step: 9
Training loss: 0.3247503954390893
Validation loss: 2.491112432580346

Epoch: 6| Step: 10
Training loss: 0.4497950299013432
Validation loss: 2.481307250236741

Epoch: 6| Step: 11
Training loss: 0.23623811568285882
Validation loss: 2.4592226063185794

Epoch: 6| Step: 12
Training loss: 0.1991930552349211
Validation loss: 2.4495900271716224

Epoch: 6| Step: 13
Training loss: 0.41451032281613687
Validation loss: 2.4383110687949294

Epoch: 401| Step: 0
Training loss: 0.5595730553471581
Validation loss: 2.4140963784475047

Epoch: 6| Step: 1
Training loss: 0.48992779632819927
Validation loss: 2.4160436931248412

Epoch: 6| Step: 2
Training loss: 0.3193926512959654
Validation loss: 2.429020993645212

Epoch: 6| Step: 3
Training loss: 0.23599806507174076
Validation loss: 2.432707322570374

Epoch: 6| Step: 4
Training loss: 0.3883033807538083
Validation loss: 2.425845416754434

Epoch: 6| Step: 5
Training loss: 0.16476286964952408
Validation loss: 2.4088764652371952

Epoch: 6| Step: 6
Training loss: 0.1841920478370661
Validation loss: 2.419185917265634

Epoch: 6| Step: 7
Training loss: 0.5027410653476101
Validation loss: 2.443862571669563

Epoch: 6| Step: 8
Training loss: 0.2570744266595246
Validation loss: 2.446833156878084

Epoch: 6| Step: 9
Training loss: 0.296113417684336
Validation loss: 2.4199730493442675

Epoch: 6| Step: 10
Training loss: 0.3092697682249376
Validation loss: 2.4505900933046094

Epoch: 6| Step: 11
Training loss: 0.46660951820767077
Validation loss: 2.4117081521896133

Epoch: 6| Step: 12
Training loss: 0.31123828094128897
Validation loss: 2.4365381352400153

Epoch: 6| Step: 13
Training loss: 0.11865178645752691
Validation loss: 2.4430396081923726

Epoch: 402| Step: 0
Training loss: 0.441255138491572
Validation loss: 2.427862219216758

Epoch: 6| Step: 1
Training loss: 0.34898173078223116
Validation loss: 2.439337022132565

Epoch: 6| Step: 2
Training loss: 0.2081045633168351
Validation loss: 2.4431819504288157

Epoch: 6| Step: 3
Training loss: 0.46333581304000965
Validation loss: 2.4088935921105232

Epoch: 6| Step: 4
Training loss: 0.211442501825341
Validation loss: 2.444808874025957

Epoch: 6| Step: 5
Training loss: 0.20029477695669978
Validation loss: 2.4397756998291347

Epoch: 6| Step: 6
Training loss: 0.28194061894214856
Validation loss: 2.4359479211285464

Epoch: 6| Step: 7
Training loss: 0.4060527799633995
Validation loss: 2.4304675076226774

Epoch: 6| Step: 8
Training loss: 0.5560138586910569
Validation loss: 2.438013462858761

Epoch: 6| Step: 9
Training loss: 0.28764684803696405
Validation loss: 2.41580971774098

Epoch: 6| Step: 10
Training loss: 0.4170205064220792
Validation loss: 2.436591639357339

Epoch: 6| Step: 11
Training loss: 0.170552071663865
Validation loss: 2.4452869925436005

Epoch: 6| Step: 12
Training loss: 0.3095604446715668
Validation loss: 2.4092366009384336

Epoch: 6| Step: 13
Training loss: 0.3402446486874207
Validation loss: 2.4432746515321604

Epoch: 403| Step: 0
Training loss: 0.4941389965889979
Validation loss: 2.436430028128184

Epoch: 6| Step: 1
Training loss: 0.47330956193955787
Validation loss: 2.456484949034083

Epoch: 6| Step: 2
Training loss: 0.19203385786640031
Validation loss: 2.449901895000786

Epoch: 6| Step: 3
Training loss: 0.23899251281161477
Validation loss: 2.4402715005058764

Epoch: 6| Step: 4
Training loss: 0.31432569776988695
Validation loss: 2.4161438940526425

Epoch: 6| Step: 5
Training loss: 0.19487595409039857
Validation loss: 2.446485415091093

Epoch: 6| Step: 6
Training loss: 0.6100879557703268
Validation loss: 2.4442171517918894

Epoch: 6| Step: 7
Training loss: 0.2484110764180852
Validation loss: 2.426461789585332

Epoch: 6| Step: 8
Training loss: 0.2771602345832997
Validation loss: 2.4403343413001073

Epoch: 6| Step: 9
Training loss: 0.2772038335191744
Validation loss: 2.4082809824348494

Epoch: 6| Step: 10
Training loss: 0.1698227516536507
Validation loss: 2.4309558151703805

Epoch: 6| Step: 11
Training loss: 0.380205816321555
Validation loss: 2.4256394244284127

Epoch: 6| Step: 12
Training loss: 0.31449275033673246
Validation loss: 2.399612938781516

Epoch: 6| Step: 13
Training loss: 0.3399859602217247
Validation loss: 2.3872737849724914

Epoch: 404| Step: 0
Training loss: 0.2383533196819474
Validation loss: 2.4421983268625396

Epoch: 6| Step: 1
Training loss: 0.2747184043181736
Validation loss: 2.3768115331981736

Epoch: 6| Step: 2
Training loss: 0.430192910241985
Validation loss: 2.391389882212259

Epoch: 6| Step: 3
Training loss: 0.2286190874681506
Validation loss: 2.4027129419077546

Epoch: 6| Step: 4
Training loss: 0.2584902351617649
Validation loss: 2.3963447000102622

Epoch: 6| Step: 5
Training loss: 0.2564344422708728
Validation loss: 2.4410778650748304

Epoch: 6| Step: 6
Training loss: 0.24683442748136564
Validation loss: 2.401398726674154

Epoch: 6| Step: 7
Training loss: 0.3070600763043192
Validation loss: 2.410182530256251

Epoch: 6| Step: 8
Training loss: 0.23728354089023662
Validation loss: 2.447017901776285

Epoch: 6| Step: 9
Training loss: 0.570596049640872
Validation loss: 2.45429132357604

Epoch: 6| Step: 10
Training loss: 0.535506141053934
Validation loss: 2.4244008876018377

Epoch: 6| Step: 11
Training loss: 0.13129218252436387
Validation loss: 2.4720900384526665

Epoch: 6| Step: 12
Training loss: 0.46503447779126195
Validation loss: 2.4640158715206217

Epoch: 6| Step: 13
Training loss: 0.22207501321747686
Validation loss: 2.4973711692242886

Epoch: 405| Step: 0
Training loss: 0.19171972296296125
Validation loss: 2.4989804978354986

Epoch: 6| Step: 1
Training loss: 0.4485796819305959
Validation loss: 2.4879463166008873

Epoch: 6| Step: 2
Training loss: 0.1552906146834824
Validation loss: 2.482909680260789

Epoch: 6| Step: 3
Training loss: 0.18706613252007936
Validation loss: 2.434386687024475

Epoch: 6| Step: 4
Training loss: 0.5604057001319552
Validation loss: 2.423665364407041

Epoch: 6| Step: 5
Training loss: 0.09556815302702718
Validation loss: 2.414730708180177

Epoch: 6| Step: 6
Training loss: 0.39570443246367476
Validation loss: 2.419599503447969

Epoch: 6| Step: 7
Training loss: 0.2211738562621508
Validation loss: 2.423713628691944

Epoch: 6| Step: 8
Training loss: 0.34077321030386987
Validation loss: 2.3924829029038945

Epoch: 6| Step: 9
Training loss: 0.4308158451339504
Validation loss: 2.4243664362015838

Epoch: 6| Step: 10
Training loss: 0.3043516459895396
Validation loss: 2.4237220313042265

Epoch: 6| Step: 11
Training loss: 0.45527991540228674
Validation loss: 2.3969544762642316

Epoch: 6| Step: 12
Training loss: 0.29749387933140864
Validation loss: 2.4188911446197743

Epoch: 6| Step: 13
Training loss: 0.285127886576509
Validation loss: 2.396790926664307

Epoch: 406| Step: 0
Training loss: 0.14958048260140913
Validation loss: 2.4327135738347865

Epoch: 6| Step: 1
Training loss: 0.22922442622265318
Validation loss: 2.4528073084956605

Epoch: 6| Step: 2
Training loss: 0.3955405139355104
Validation loss: 2.432075027255182

Epoch: 6| Step: 3
Training loss: 0.2654001602692325
Validation loss: 2.4164281358917945

Epoch: 6| Step: 4
Training loss: 0.32058031237345397
Validation loss: 2.417484847384175

Epoch: 6| Step: 5
Training loss: 0.5020817098419829
Validation loss: 2.435080142457078

Epoch: 6| Step: 6
Training loss: 0.2517286379936274
Validation loss: 2.4303863663001852

Epoch: 6| Step: 7
Training loss: 0.24959177722296944
Validation loss: 2.4012185796029857

Epoch: 6| Step: 8
Training loss: 0.38282281511383665
Validation loss: 2.4185409222779906

Epoch: 6| Step: 9
Training loss: 0.3948006795829018
Validation loss: 2.4202579769850447

Epoch: 6| Step: 10
Training loss: 0.14930721277110723
Validation loss: 2.428563634402007

Epoch: 6| Step: 11
Training loss: 0.26706230956146
Validation loss: 2.4150634937949667

Epoch: 6| Step: 12
Training loss: 0.49202598464779684
Validation loss: 2.4169808043204304

Epoch: 6| Step: 13
Training loss: 0.3990133275839287
Validation loss: 2.3744363132049235

Epoch: 407| Step: 0
Training loss: 0.5437638204287102
Validation loss: 2.4071675822928276

Epoch: 6| Step: 1
Training loss: 0.30077697701329564
Validation loss: 2.413779313568227

Epoch: 6| Step: 2
Training loss: 0.434604154833504
Validation loss: 2.4193043700460923

Epoch: 6| Step: 3
Training loss: 0.2695136824701555
Validation loss: 2.435129704917752

Epoch: 6| Step: 4
Training loss: 0.1880667287459497
Validation loss: 2.401266317651029

Epoch: 6| Step: 5
Training loss: 0.27293784948701805
Validation loss: 2.430121076183822

Epoch: 6| Step: 6
Training loss: 0.1912617235081069
Validation loss: 2.3981415261111696

Epoch: 6| Step: 7
Training loss: 0.24953217245276588
Validation loss: 2.4060751616136913

Epoch: 6| Step: 8
Training loss: 0.4878660954829046
Validation loss: 2.399481435524172

Epoch: 6| Step: 9
Training loss: 0.2849124754811005
Validation loss: 2.3999341911262726

Epoch: 6| Step: 10
Training loss: 0.45047081318679527
Validation loss: 2.411407165757019

Epoch: 6| Step: 11
Training loss: 0.20877219507582667
Validation loss: 2.417518689006488

Epoch: 6| Step: 12
Training loss: 0.1892416550517343
Validation loss: 2.3994925117511987

Epoch: 6| Step: 13
Training loss: 0.3349905974043613
Validation loss: 2.4029126184488865

Epoch: 408| Step: 0
Training loss: 0.1589269621093655
Validation loss: 2.3942775845226962

Epoch: 6| Step: 1
Training loss: 0.2144735441232063
Validation loss: 2.3887170519326557

Epoch: 6| Step: 2
Training loss: 0.25141924102012275
Validation loss: 2.358405546639923

Epoch: 6| Step: 3
Training loss: 0.17290411974492484
Validation loss: 2.3820040919267704

Epoch: 6| Step: 4
Training loss: 0.3207069155135667
Validation loss: 2.383097056600866

Epoch: 6| Step: 5
Training loss: 0.4780042445959987
Validation loss: 2.3584134895022544

Epoch: 6| Step: 6
Training loss: 0.6179275180646661
Validation loss: 2.3874691615501917

Epoch: 6| Step: 7
Training loss: 0.439880451548021
Validation loss: 2.3859060157844163

Epoch: 6| Step: 8
Training loss: 0.2119382941108255
Validation loss: 2.3756913008561087

Epoch: 6| Step: 9
Training loss: 0.1622517087292441
Validation loss: 2.413245305751747

Epoch: 6| Step: 10
Training loss: 0.37351405264885124
Validation loss: 2.4194382247432635

Epoch: 6| Step: 11
Training loss: 0.40716793818411257
Validation loss: 2.402091091504815

Epoch: 6| Step: 12
Training loss: 0.4430896257719345
Validation loss: 2.3996964923732724

Epoch: 6| Step: 13
Training loss: 0.28557446264339803
Validation loss: 2.3901987829224836

Epoch: 409| Step: 0
Training loss: 0.42716820579104675
Validation loss: 2.390484001639122

Epoch: 6| Step: 1
Training loss: 0.4013620826415119
Validation loss: 2.3595941218127927

Epoch: 6| Step: 2
Training loss: 0.28897739136923584
Validation loss: 2.400607615553007

Epoch: 6| Step: 3
Training loss: 0.3836239758176733
Validation loss: 2.38347624583976

Epoch: 6| Step: 4
Training loss: 0.218184216284758
Validation loss: 2.395353410616539

Epoch: 6| Step: 5
Training loss: 0.6717422709103783
Validation loss: 2.39105025548012

Epoch: 6| Step: 6
Training loss: 0.19188695994575666
Validation loss: 2.4058519824490316

Epoch: 6| Step: 7
Training loss: 0.28532033928320333
Validation loss: 2.394722346469184

Epoch: 6| Step: 8
Training loss: 0.3050217506790584
Validation loss: 2.404440353957444

Epoch: 6| Step: 9
Training loss: 0.18324990234528524
Validation loss: 2.410371525436315

Epoch: 6| Step: 10
Training loss: 0.3683527657653176
Validation loss: 2.4154785444244236

Epoch: 6| Step: 11
Training loss: 0.1506747249977358
Validation loss: 2.4574918246961275

Epoch: 6| Step: 12
Training loss: 0.1944177637405144
Validation loss: 2.45535343841627

Epoch: 6| Step: 13
Training loss: 0.10618042578800853
Validation loss: 2.457764922395512

Epoch: 410| Step: 0
Training loss: 0.22400659865373515
Validation loss: 2.4497451128959313

Epoch: 6| Step: 1
Training loss: 0.2763387712623074
Validation loss: 2.452361908418108

Epoch: 6| Step: 2
Training loss: 0.3031453941799417
Validation loss: 2.458167591073024

Epoch: 6| Step: 3
Training loss: 0.3524486394083422
Validation loss: 2.4269072428152785

Epoch: 6| Step: 4
Training loss: 0.2139794999730582
Validation loss: 2.4360432190647643

Epoch: 6| Step: 5
Training loss: 0.19617362922118078
Validation loss: 2.397029368085259

Epoch: 6| Step: 6
Training loss: 0.4070759227056037
Validation loss: 2.4370194417074886

Epoch: 6| Step: 7
Training loss: 0.26537736400839634
Validation loss: 2.4237967772028055

Epoch: 6| Step: 8
Training loss: 0.295451238628702
Validation loss: 2.44215947302147

Epoch: 6| Step: 9
Training loss: 0.5627815019034108
Validation loss: 2.4310628296198984

Epoch: 6| Step: 10
Training loss: 0.28150352336667206
Validation loss: 2.4371988369715587

Epoch: 6| Step: 11
Training loss: 0.22195612270609483
Validation loss: 2.4175942093920404

Epoch: 6| Step: 12
Training loss: 0.3330811226882535
Validation loss: 2.425485825574623

Epoch: 6| Step: 13
Training loss: 0.5144909322716239
Validation loss: 2.4217998343456273

Epoch: 411| Step: 0
Training loss: 0.1968386154764809
Validation loss: 2.4275241866713304

Epoch: 6| Step: 1
Training loss: 0.4486517271539401
Validation loss: 2.439834274243067

Epoch: 6| Step: 2
Training loss: 0.29596409840272003
Validation loss: 2.454780629180822

Epoch: 6| Step: 3
Training loss: 0.3428988213818681
Validation loss: 2.456366565318863

Epoch: 6| Step: 4
Training loss: 0.5136068614821504
Validation loss: 2.453168872937067

Epoch: 6| Step: 5
Training loss: 0.2822530529433197
Validation loss: 2.45017442615995

Epoch: 6| Step: 6
Training loss: 0.2486662303584731
Validation loss: 2.4285088444606737

Epoch: 6| Step: 7
Training loss: 0.3462476052535386
Validation loss: 2.4428964726909608

Epoch: 6| Step: 8
Training loss: 0.22808275223494087
Validation loss: 2.4430418286480298

Epoch: 6| Step: 9
Training loss: 0.13773057364391084
Validation loss: 2.4385399016091966

Epoch: 6| Step: 10
Training loss: 0.46288890274950734
Validation loss: 2.462785613959061

Epoch: 6| Step: 11
Training loss: 0.3641526221193888
Validation loss: 2.489455619134917

Epoch: 6| Step: 12
Training loss: 0.18373619803020497
Validation loss: 2.4912640978713614

Epoch: 6| Step: 13
Training loss: 0.3210722008781019
Validation loss: 2.5136239606376893

Epoch: 412| Step: 0
Training loss: 0.23236237894424766
Validation loss: 2.5030392374709254

Epoch: 6| Step: 1
Training loss: 0.33258128888070443
Validation loss: 2.491645942651465

Epoch: 6| Step: 2
Training loss: 0.26851427641178377
Validation loss: 2.4794069978353805

Epoch: 6| Step: 3
Training loss: 0.46270700023698974
Validation loss: 2.469957466840368

Epoch: 6| Step: 4
Training loss: 0.21218487360119592
Validation loss: 2.4267256806533872

Epoch: 6| Step: 5
Training loss: 0.5202132316494198
Validation loss: 2.458771760561291

Epoch: 6| Step: 6
Training loss: 0.3189919044676676
Validation loss: 2.443067208438755

Epoch: 6| Step: 7
Training loss: 0.34090689185184636
Validation loss: 2.4678905086977996

Epoch: 6| Step: 8
Training loss: 0.28051721956314796
Validation loss: 2.4268941626426392

Epoch: 6| Step: 9
Training loss: 0.29185472397555107
Validation loss: 2.4676310863339537

Epoch: 6| Step: 10
Training loss: 0.2502756982769407
Validation loss: 2.471748012491125

Epoch: 6| Step: 11
Training loss: 0.15958430346782546
Validation loss: 2.445686136967689

Epoch: 6| Step: 12
Training loss: 0.44586131091288295
Validation loss: 2.473545906822884

Epoch: 6| Step: 13
Training loss: 0.3803275282938065
Validation loss: 2.500245235064251

Epoch: 413| Step: 0
Training loss: 0.22979928430005067
Validation loss: 2.4774608820661266

Epoch: 6| Step: 1
Training loss: 0.20733344317635952
Validation loss: 2.481505606561273

Epoch: 6| Step: 2
Training loss: 0.21759286587431576
Validation loss: 2.4576813031429374

Epoch: 6| Step: 3
Training loss: 0.17285939646064483
Validation loss: 2.4704714134856265

Epoch: 6| Step: 4
Training loss: 0.24868028222055147
Validation loss: 2.447615527758445

Epoch: 6| Step: 5
Training loss: 0.42883934930618417
Validation loss: 2.4645377689244876

Epoch: 6| Step: 6
Training loss: 0.30502484060189045
Validation loss: 2.483856157312771

Epoch: 6| Step: 7
Training loss: 0.1698324253058313
Validation loss: 2.484310812574663

Epoch: 6| Step: 8
Training loss: 0.3045351185364544
Validation loss: 2.4749014248011854

Epoch: 6| Step: 9
Training loss: 0.5030711151079205
Validation loss: 2.4832751310302505

Epoch: 6| Step: 10
Training loss: 0.4144415829531741
Validation loss: 2.454544802931794

Epoch: 6| Step: 11
Training loss: 0.34626874611302016
Validation loss: 2.446330175115099

Epoch: 6| Step: 12
Training loss: 0.42735519324120036
Validation loss: 2.4648359264876722

Epoch: 6| Step: 13
Training loss: 0.0788750289298789
Validation loss: 2.456338443941751

Epoch: 414| Step: 0
Training loss: 0.2199890349240231
Validation loss: 2.476706596414452

Epoch: 6| Step: 1
Training loss: 0.3652708677940473
Validation loss: 2.4601267343562307

Epoch: 6| Step: 2
Training loss: 0.3076234604937656
Validation loss: 2.4455677182218767

Epoch: 6| Step: 3
Training loss: 0.34972652411868105
Validation loss: 2.4541813911714816

Epoch: 6| Step: 4
Training loss: 0.43364452374080587
Validation loss: 2.428025451301194

Epoch: 6| Step: 5
Training loss: 0.2609607623347255
Validation loss: 2.4579805635847793

Epoch: 6| Step: 6
Training loss: 0.37380692313249636
Validation loss: 2.436943089443336

Epoch: 6| Step: 7
Training loss: 0.23731854873174102
Validation loss: 2.4465328587697868

Epoch: 6| Step: 8
Training loss: 0.2768178709090048
Validation loss: 2.42941596986217

Epoch: 6| Step: 9
Training loss: 0.17320707905118446
Validation loss: 2.4112507901291713

Epoch: 6| Step: 10
Training loss: 0.550929056450183
Validation loss: 2.4439686800549993

Epoch: 6| Step: 11
Training loss: 0.26987443719640003
Validation loss: 2.4415566716933395

Epoch: 6| Step: 12
Training loss: 0.12879323339954288
Validation loss: 2.428064329649717

Epoch: 6| Step: 13
Training loss: 0.14212314307283896
Validation loss: 2.4405641278004997

Epoch: 415| Step: 0
Training loss: 0.20557999735866261
Validation loss: 2.467814117399821

Epoch: 6| Step: 1
Training loss: 0.25785648086404
Validation loss: 2.466105746352423

Epoch: 6| Step: 2
Training loss: 0.29133033377192935
Validation loss: 2.450698790805202

Epoch: 6| Step: 3
Training loss: 0.4789374535804635
Validation loss: 2.489024354187291

Epoch: 6| Step: 4
Training loss: 0.31218274224582276
Validation loss: 2.472641369855981

Epoch: 6| Step: 5
Training loss: 0.29788603036029826
Validation loss: 2.450844456506628

Epoch: 6| Step: 6
Training loss: 0.3838394559045333
Validation loss: 2.45754591840213

Epoch: 6| Step: 7
Training loss: 0.34010029021892596
Validation loss: 2.4277250443366376

Epoch: 6| Step: 8
Training loss: 0.28313142592356716
Validation loss: 2.420922746920851

Epoch: 6| Step: 9
Training loss: 0.2540926175958436
Validation loss: 2.3944446548263425

Epoch: 6| Step: 10
Training loss: 0.373309776777767
Validation loss: 2.4166243623362456

Epoch: 6| Step: 11
Training loss: 0.2502470732726406
Validation loss: 2.384388360020596

Epoch: 6| Step: 12
Training loss: 0.2195464858608966
Validation loss: 2.381500446676801

Epoch: 6| Step: 13
Training loss: 0.19649129859147202
Validation loss: 2.3761611969983134

Epoch: 416| Step: 0
Training loss: 0.22209759949696953
Validation loss: 2.414216252744562

Epoch: 6| Step: 1
Training loss: 0.2867481008781063
Validation loss: 2.420138916234389

Epoch: 6| Step: 2
Training loss: 0.1881278770645
Validation loss: 2.415783921590459

Epoch: 6| Step: 3
Training loss: 0.37910835539103654
Validation loss: 2.4062411331164677

Epoch: 6| Step: 4
Training loss: 0.39821382864071153
Validation loss: 2.423046977797565

Epoch: 6| Step: 5
Training loss: 0.15954295055698545
Validation loss: 2.3896903110840033

Epoch: 6| Step: 6
Training loss: 0.2832138585654535
Validation loss: 2.3810628555893407

Epoch: 6| Step: 7
Training loss: 0.445526707310009
Validation loss: 2.4037785118452577

Epoch: 6| Step: 8
Training loss: 0.13545850572053908
Validation loss: 2.387280609456995

Epoch: 6| Step: 9
Training loss: 0.5300043593083448
Validation loss: 2.393828676273224

Epoch: 6| Step: 10
Training loss: 0.2619989802235129
Validation loss: 2.421883961544863

Epoch: 6| Step: 11
Training loss: 0.2921643339755074
Validation loss: 2.42528598379522

Epoch: 6| Step: 12
Training loss: 0.36289645909936274
Validation loss: 2.444147437295201

Epoch: 6| Step: 13
Training loss: 0.22780242707964438
Validation loss: 2.4817039586531187

Epoch: 417| Step: 0
Training loss: 0.41524132680591125
Validation loss: 2.454558645986167

Epoch: 6| Step: 1
Training loss: 0.42342186719464425
Validation loss: 2.4604696985178474

Epoch: 6| Step: 2
Training loss: 0.2838678123390604
Validation loss: 2.4692527619395266

Epoch: 6| Step: 3
Training loss: 0.24134435323116
Validation loss: 2.4549134815558453

Epoch: 6| Step: 4
Training loss: 0.12594163395649366
Validation loss: 2.4197897824326646

Epoch: 6| Step: 5
Training loss: 0.3274553140700967
Validation loss: 2.450361318148782

Epoch: 6| Step: 6
Training loss: 0.2787264888410591
Validation loss: 2.41915696469757

Epoch: 6| Step: 7
Training loss: 0.5790736173992288
Validation loss: 2.404191952891578

Epoch: 6| Step: 8
Training loss: 0.2012089074872419
Validation loss: 2.406989795845884

Epoch: 6| Step: 9
Training loss: 0.14782481739023878
Validation loss: 2.4225483043436635

Epoch: 6| Step: 10
Training loss: 0.22275761756330548
Validation loss: 2.4366425004275873

Epoch: 6| Step: 11
Training loss: 0.3534099568462607
Validation loss: 2.456129325685553

Epoch: 6| Step: 12
Training loss: 0.2688047042883483
Validation loss: 2.430403308895376

Epoch: 6| Step: 13
Training loss: 0.2502327372115957
Validation loss: 2.4245905719656053

Epoch: 418| Step: 0
Training loss: 0.27482595788425607
Validation loss: 2.403484760155838

Epoch: 6| Step: 1
Training loss: 0.24573492199209937
Validation loss: 2.379038869015376

Epoch: 6| Step: 2
Training loss: 0.2867091237045132
Validation loss: 2.3891789862435817

Epoch: 6| Step: 3
Training loss: 0.4179306547683374
Validation loss: 2.38375254539121

Epoch: 6| Step: 4
Training loss: 0.3298496155102108
Validation loss: 2.3759700594546844

Epoch: 6| Step: 5
Training loss: 0.2131856658736985
Validation loss: 2.3775637637513074

Epoch: 6| Step: 6
Training loss: 0.2568117717789226
Validation loss: 2.3802694057623914

Epoch: 6| Step: 7
Training loss: 0.4612407333456291
Validation loss: 2.4089734162288785

Epoch: 6| Step: 8
Training loss: 0.1765085433278234
Validation loss: 2.409987898307613

Epoch: 6| Step: 9
Training loss: 0.23748311058022564
Validation loss: 2.460115194372299

Epoch: 6| Step: 10
Training loss: 0.25110100655553375
Validation loss: 2.4519935372402313

Epoch: 6| Step: 11
Training loss: 0.3511619829560435
Validation loss: 2.461103482109074

Epoch: 6| Step: 12
Training loss: 0.46205264506698007
Validation loss: 2.4825065130220554

Epoch: 6| Step: 13
Training loss: 0.2634518305635448
Validation loss: 2.4601770182091984

Epoch: 419| Step: 0
Training loss: 0.36922673830615893
Validation loss: 2.4296148129907453

Epoch: 6| Step: 1
Training loss: 0.30068762672150473
Validation loss: 2.4521719980344803

Epoch: 6| Step: 2
Training loss: 0.1848502685029523
Validation loss: 2.438363899503275

Epoch: 6| Step: 3
Training loss: 0.1803891952015222
Validation loss: 2.4541557131746607

Epoch: 6| Step: 4
Training loss: 0.44278952658103093
Validation loss: 2.4133815126783023

Epoch: 6| Step: 5
Training loss: 0.2872661888940758
Validation loss: 2.4379072919206255

Epoch: 6| Step: 6
Training loss: 0.24457033107083026
Validation loss: 2.42756142243294

Epoch: 6| Step: 7
Training loss: 0.4134623839083099
Validation loss: 2.428539253677332

Epoch: 6| Step: 8
Training loss: 0.20103990985583717
Validation loss: 2.4204619663545226

Epoch: 6| Step: 9
Training loss: 0.2124762044935089
Validation loss: 2.428904167828819

Epoch: 6| Step: 10
Training loss: 0.1054014812629715
Validation loss: 2.434757701006122

Epoch: 6| Step: 11
Training loss: 0.29317617067344187
Validation loss: 2.4437116498801648

Epoch: 6| Step: 12
Training loss: 0.357148508895705
Validation loss: 2.4528442006822178

Epoch: 6| Step: 13
Training loss: 0.13480640568352598
Validation loss: 2.44453750811063

Epoch: 420| Step: 0
Training loss: 0.24508080079427094
Validation loss: 2.4551775379118554

Epoch: 6| Step: 1
Training loss: 0.2592505748313851
Validation loss: 2.4560098160275023

Epoch: 6| Step: 2
Training loss: 0.3757305578987431
Validation loss: 2.455549514861803

Epoch: 6| Step: 3
Training loss: 0.3096069651184319
Validation loss: 2.477874878095222

Epoch: 6| Step: 4
Training loss: 0.23354181969121796
Validation loss: 2.4757606857119283

Epoch: 6| Step: 5
Training loss: 0.21991552069311093
Validation loss: 2.476578766464766

Epoch: 6| Step: 6
Training loss: 0.20218105329468428
Validation loss: 2.4879005509098535

Epoch: 6| Step: 7
Training loss: 0.19555288780316646
Validation loss: 2.482148760918298

Epoch: 6| Step: 8
Training loss: 0.43361447258995206
Validation loss: 2.452302975152559

Epoch: 6| Step: 9
Training loss: 0.23200806877629984
Validation loss: 2.4757867676513365

Epoch: 6| Step: 10
Training loss: 0.18150706148991738
Validation loss: 2.483533137070784

Epoch: 6| Step: 11
Training loss: 0.2648942376010087
Validation loss: 2.4550376162558427

Epoch: 6| Step: 12
Training loss: 0.35480319585489767
Validation loss: 2.4546268198533006

Epoch: 6| Step: 13
Training loss: 0.5630053263695174
Validation loss: 2.441904443456946

Epoch: 421| Step: 0
Training loss: 0.5505982764662244
Validation loss: 2.4602654933702377

Epoch: 6| Step: 1
Training loss: 0.20849226115007422
Validation loss: 2.485913726358218

Epoch: 6| Step: 2
Training loss: 0.35029295471208394
Validation loss: 2.484232621831836

Epoch: 6| Step: 3
Training loss: 0.3509245276155314
Validation loss: 2.5287758957759343

Epoch: 6| Step: 4
Training loss: 0.3626987956285004
Validation loss: 2.48409148837989

Epoch: 6| Step: 5
Training loss: 0.1339905884750583
Validation loss: 2.4879962267678075

Epoch: 6| Step: 6
Training loss: 0.24575742567287626
Validation loss: 2.48101628204664

Epoch: 6| Step: 7
Training loss: 0.32444401464386635
Validation loss: 2.45986376163621

Epoch: 6| Step: 8
Training loss: 0.1944554407174207
Validation loss: 2.4467816851485242

Epoch: 6| Step: 9
Training loss: 0.18496037194106132
Validation loss: 2.4605493851827878

Epoch: 6| Step: 10
Training loss: 0.24326673890718267
Validation loss: 2.4268965581707476

Epoch: 6| Step: 11
Training loss: 0.3196270167280058
Validation loss: 2.4214279000281733

Epoch: 6| Step: 12
Training loss: 0.1953412702351463
Validation loss: 2.440166871339921

Epoch: 6| Step: 13
Training loss: 0.3379312722337953
Validation loss: 2.4379137958989485

Epoch: 422| Step: 0
Training loss: 0.3118389051034069
Validation loss: 2.4305147281465977

Epoch: 6| Step: 1
Training loss: 0.34619481740113
Validation loss: 2.446635464786204

Epoch: 6| Step: 2
Training loss: 0.16897318174668183
Validation loss: 2.4285197038455655

Epoch: 6| Step: 3
Training loss: 0.4027826452326532
Validation loss: 2.3997520069123466

Epoch: 6| Step: 4
Training loss: 0.22369585439658804
Validation loss: 2.443394831298532

Epoch: 6| Step: 5
Training loss: 0.23697968192970237
Validation loss: 2.422178827202928

Epoch: 6| Step: 6
Training loss: 0.1590600295334022
Validation loss: 2.391538994998663

Epoch: 6| Step: 7
Training loss: 0.3715898710970238
Validation loss: 2.436424419306268

Epoch: 6| Step: 8
Training loss: 0.3164317273843984
Validation loss: 2.414583996165515

Epoch: 6| Step: 9
Training loss: 0.360795427409767
Validation loss: 2.3904852582654468

Epoch: 6| Step: 10
Training loss: 0.28966343764333324
Validation loss: 2.37766078070237

Epoch: 6| Step: 11
Training loss: 0.20634089836612401
Validation loss: 2.3894551070289216

Epoch: 6| Step: 12
Training loss: 0.3115191444412078
Validation loss: 2.3856670171066487

Epoch: 6| Step: 13
Training loss: 0.28755356040943264
Validation loss: 2.374885770061655

Epoch: 423| Step: 0
Training loss: 0.366035683976887
Validation loss: 2.4122181522824544

Epoch: 6| Step: 1
Training loss: 0.2692422284711052
Validation loss: 2.4111997719614116

Epoch: 6| Step: 2
Training loss: 0.3916189708312581
Validation loss: 2.426277016850355

Epoch: 6| Step: 3
Training loss: 0.3875074339738065
Validation loss: 2.4429078998709097

Epoch: 6| Step: 4
Training loss: 0.4590684529665753
Validation loss: 2.429397663320243

Epoch: 6| Step: 5
Training loss: 0.16027112655591338
Validation loss: 2.4396662251078705

Epoch: 6| Step: 6
Training loss: 0.23723046197674677
Validation loss: 2.4572840241914435

Epoch: 6| Step: 7
Training loss: 0.3365259561206443
Validation loss: 2.4308678952435256

Epoch: 6| Step: 8
Training loss: 0.25652201218061665
Validation loss: 2.438836212381046

Epoch: 6| Step: 9
Training loss: 0.21666148829843745
Validation loss: 2.415246348462243

Epoch: 6| Step: 10
Training loss: 0.18331079796079924
Validation loss: 2.4163551911309944

Epoch: 6| Step: 11
Training loss: 0.24276974123583075
Validation loss: 2.4191392025849563

Epoch: 6| Step: 12
Training loss: 0.2319374325083226
Validation loss: 2.395332539469253

Epoch: 6| Step: 13
Training loss: 0.3051484851073869
Validation loss: 2.4126085938939488

Epoch: 424| Step: 0
Training loss: 0.23014752583177642
Validation loss: 2.42270734538087

Epoch: 6| Step: 1
Training loss: 0.3117075050448212
Validation loss: 2.4404361017676304

Epoch: 6| Step: 2
Training loss: 0.3227096042439747
Validation loss: 2.428167596778254

Epoch: 6| Step: 3
Training loss: 0.38790534261420506
Validation loss: 2.4346434043779825

Epoch: 6| Step: 4
Training loss: 0.19142336671550184
Validation loss: 2.422525629830613

Epoch: 6| Step: 5
Training loss: 0.18006379697320005
Validation loss: 2.4598938817288563

Epoch: 6| Step: 6
Training loss: 0.4511991220148655
Validation loss: 2.4626370157164525

Epoch: 6| Step: 7
Training loss: 0.21125106111519568
Validation loss: 2.4637686246725288

Epoch: 6| Step: 8
Training loss: 0.3553795755060269
Validation loss: 2.435749332404938

Epoch: 6| Step: 9
Training loss: 0.18130634681651472
Validation loss: 2.4209602684711853

Epoch: 6| Step: 10
Training loss: 0.17193844556219137
Validation loss: 2.416477164821996

Epoch: 6| Step: 11
Training loss: 0.23505794048020445
Validation loss: 2.415715838529316

Epoch: 6| Step: 12
Training loss: 0.24456346135154022
Validation loss: 2.397947066121956

Epoch: 6| Step: 13
Training loss: 0.4009978179574993
Validation loss: 2.3998926105793656

Epoch: 425| Step: 0
Training loss: 0.246936837431285
Validation loss: 2.398053160000618

Epoch: 6| Step: 1
Training loss: 0.15502723632404306
Validation loss: 2.4047875159683922

Epoch: 6| Step: 2
Training loss: 0.4179131479802937
Validation loss: 2.382306851900906

Epoch: 6| Step: 3
Training loss: 0.2757885675296992
Validation loss: 2.4329341429787976

Epoch: 6| Step: 4
Training loss: 0.3054227272350052
Validation loss: 2.4575552657181077

Epoch: 6| Step: 5
Training loss: 0.18499563550311385
Validation loss: 2.4618247885078848

Epoch: 6| Step: 6
Training loss: 0.37847750287741827
Validation loss: 2.4676412447513427

Epoch: 6| Step: 7
Training loss: 0.37271542828997845
Validation loss: 2.454997291676227

Epoch: 6| Step: 8
Training loss: 0.48657019844898475
Validation loss: 2.4967241071737414

Epoch: 6| Step: 9
Training loss: 0.2728974049204012
Validation loss: 2.453687127029121

Epoch: 6| Step: 10
Training loss: 0.24974942315572463
Validation loss: 2.478256173088941

Epoch: 6| Step: 11
Training loss: 0.3182217118950396
Validation loss: 2.477171461521871

Epoch: 6| Step: 12
Training loss: 0.1823517405206442
Validation loss: 2.4743185257585814

Epoch: 6| Step: 13
Training loss: 0.3656179280697533
Validation loss: 2.4988484196577114

Epoch: 426| Step: 0
Training loss: 0.356248336085399
Validation loss: 2.488500333704154

Epoch: 6| Step: 1
Training loss: 0.2507699791582956
Validation loss: 2.4998819364336526

Epoch: 6| Step: 2
Training loss: 0.4724556836281214
Validation loss: 2.4624648675556498

Epoch: 6| Step: 3
Training loss: 0.3128180792403398
Validation loss: 2.4352934731067752

Epoch: 6| Step: 4
Training loss: 0.3720865521428796
Validation loss: 2.436323800813691

Epoch: 6| Step: 5
Training loss: 0.2675261342571352
Validation loss: 2.4471071533725146

Epoch: 6| Step: 6
Training loss: 0.24930773942992066
Validation loss: 2.4343412950441796

Epoch: 6| Step: 7
Training loss: 0.13548208606639914
Validation loss: 2.3997021069156284

Epoch: 6| Step: 8
Training loss: 0.21506093058668943
Validation loss: 2.41113682201816

Epoch: 6| Step: 9
Training loss: 0.23309793639908158
Validation loss: 2.385009433884788

Epoch: 6| Step: 10
Training loss: 0.2855024718112467
Validation loss: 2.405633961266106

Epoch: 6| Step: 11
Training loss: 0.22925661048697543
Validation loss: 2.4090079036610863

Epoch: 6| Step: 12
Training loss: 0.28527166042952273
Validation loss: 2.3880470279720485

Epoch: 6| Step: 13
Training loss: 0.09311050619074218
Validation loss: 2.3949066356606723

Epoch: 427| Step: 0
Training loss: 0.23123462761226488
Validation loss: 2.3706893250281964

Epoch: 6| Step: 1
Training loss: 0.2726434486029137
Validation loss: 2.3799123371085806

Epoch: 6| Step: 2
Training loss: 0.19616108608316035
Validation loss: 2.3767551085473664

Epoch: 6| Step: 3
Training loss: 0.32030090450605175
Validation loss: 2.3887666818232653

Epoch: 6| Step: 4
Training loss: 0.28429001701618467
Validation loss: 2.3758605861559268

Epoch: 6| Step: 5
Training loss: 0.36672687045299146
Validation loss: 2.3784438996205175

Epoch: 6| Step: 6
Training loss: 0.4683631254146228
Validation loss: 2.3919962184274013

Epoch: 6| Step: 7
Training loss: 0.3569704550771091
Validation loss: 2.3844368349790885

Epoch: 6| Step: 8
Training loss: 0.16021589006089038
Validation loss: 2.4176251105970596

Epoch: 6| Step: 9
Training loss: 0.2627641665616743
Validation loss: 2.434286539308512

Epoch: 6| Step: 10
Training loss: 0.2203037733689905
Validation loss: 2.4600255268318847

Epoch: 6| Step: 11
Training loss: 0.2646991075945295
Validation loss: 2.4730090839021823

Epoch: 6| Step: 12
Training loss: 0.1077338716330605
Validation loss: 2.465435941310676

Epoch: 6| Step: 13
Training loss: 0.3005914956533867
Validation loss: 2.4979812818838556

Epoch: 428| Step: 0
Training loss: 0.27900214750478636
Validation loss: 2.501290970416266

Epoch: 6| Step: 1
Training loss: 0.24946884264652175
Validation loss: 2.47230475524809

Epoch: 6| Step: 2
Training loss: 0.2676079169624715
Validation loss: 2.483556145938356

Epoch: 6| Step: 3
Training loss: 0.3544508854789183
Validation loss: 2.468736319596837

Epoch: 6| Step: 4
Training loss: 0.21755496643204142
Validation loss: 2.4582151471805127

Epoch: 6| Step: 5
Training loss: 0.17631098082914629
Validation loss: 2.425915808322019

Epoch: 6| Step: 6
Training loss: 0.31145670304568107
Validation loss: 2.422902932081085

Epoch: 6| Step: 7
Training loss: 0.28971730633407755
Validation loss: 2.408161032522184

Epoch: 6| Step: 8
Training loss: 0.3167238995736117
Validation loss: 2.4255112738584774

Epoch: 6| Step: 9
Training loss: 0.2604363894941265
Validation loss: 2.413643651666028

Epoch: 6| Step: 10
Training loss: 0.23324549623927035
Validation loss: 2.411282775742395

Epoch: 6| Step: 11
Training loss: 0.13179716317100656
Validation loss: 2.4190521418672235

Epoch: 6| Step: 12
Training loss: 0.4127009335887453
Validation loss: 2.401287714801491

Epoch: 6| Step: 13
Training loss: 0.16053500978568194
Validation loss: 2.421447736329806

Epoch: 429| Step: 0
Training loss: 0.16523023965408856
Validation loss: 2.4162471401439434

Epoch: 6| Step: 1
Training loss: 0.3631534967057969
Validation loss: 2.4424756279022235

Epoch: 6| Step: 2
Training loss: 0.32937629846031014
Validation loss: 2.4425256002517055

Epoch: 6| Step: 3
Training loss: 0.33616271343154214
Validation loss: 2.4461144841698896

Epoch: 6| Step: 4
Training loss: 0.20770933559128724
Validation loss: 2.3973216525186243

Epoch: 6| Step: 5
Training loss: 0.22163624274755833
Validation loss: 2.4025443001963844

Epoch: 6| Step: 6
Training loss: 0.40880277841215434
Validation loss: 2.428520724120653

Epoch: 6| Step: 7
Training loss: 0.36560072859059195
Validation loss: 2.387665858899575

Epoch: 6| Step: 8
Training loss: 0.13616263502137566
Validation loss: 2.386436297862367

Epoch: 6| Step: 9
Training loss: 0.1594236645544361
Validation loss: 2.401599690972798

Epoch: 6| Step: 10
Training loss: 0.1878477785265197
Validation loss: 2.400114629000827

Epoch: 6| Step: 11
Training loss: 0.2064711172962115
Validation loss: 2.391928154407358

Epoch: 6| Step: 12
Training loss: 0.1893395742323289
Validation loss: 2.369441377014681

Epoch: 6| Step: 13
Training loss: 0.1422593852041116
Validation loss: 2.4014998194101054

Epoch: 430| Step: 0
Training loss: 0.18717365872852912
Validation loss: 2.3865846789899834

Epoch: 6| Step: 1
Training loss: 0.2937156692693983
Validation loss: 2.4101028291535758

Epoch: 6| Step: 2
Training loss: 0.26534143907859054
Validation loss: 2.4229474697024815

Epoch: 6| Step: 3
Training loss: 0.13993710912587692
Validation loss: 2.3902327840249566

Epoch: 6| Step: 4
Training loss: 0.23536965391658649
Validation loss: 2.411388686350926

Epoch: 6| Step: 5
Training loss: 0.32792764359746596
Validation loss: 2.405909202636481

Epoch: 6| Step: 6
Training loss: 0.23585612870692982
Validation loss: 2.4048176617401187

Epoch: 6| Step: 7
Training loss: 0.12355486520349807
Validation loss: 2.3997353345243466

Epoch: 6| Step: 8
Training loss: 0.18571296084895575
Validation loss: 2.3982895357934395

Epoch: 6| Step: 9
Training loss: 0.2977527767271323
Validation loss: 2.378042916332348

Epoch: 6| Step: 10
Training loss: 0.19456261684513473
Validation loss: 2.3863973794423163

Epoch: 6| Step: 11
Training loss: 0.2739906166307689
Validation loss: 2.3624925461257775

Epoch: 6| Step: 12
Training loss: 0.44495000641451266
Validation loss: 2.3843357875636313

Epoch: 6| Step: 13
Training loss: 0.3741283020743045
Validation loss: 2.4013966353204212

Epoch: 431| Step: 0
Training loss: 0.17003069604875615
Validation loss: 2.3842270198825175

Epoch: 6| Step: 1
Training loss: 0.19850396034592352
Validation loss: 2.3975387139249507

Epoch: 6| Step: 2
Training loss: 0.3908749734227702
Validation loss: 2.3929855999539447

Epoch: 6| Step: 3
Training loss: 0.1685859408085812
Validation loss: 2.4160297630906364

Epoch: 6| Step: 4
Training loss: 0.20231631582737333
Validation loss: 2.406359745820929

Epoch: 6| Step: 5
Training loss: 0.2562319249081883
Validation loss: 2.4317882524821957

Epoch: 6| Step: 6
Training loss: 0.3300570983509725
Validation loss: 2.4103161916698945

Epoch: 6| Step: 7
Training loss: 0.20250893665833336
Validation loss: 2.4062148231307767

Epoch: 6| Step: 8
Training loss: 0.3552753215653855
Validation loss: 2.4049603367919654

Epoch: 6| Step: 9
Training loss: 0.39518102638339536
Validation loss: 2.3935682224466976

Epoch: 6| Step: 10
Training loss: 0.1511443189400071
Validation loss: 2.389906498930187

Epoch: 6| Step: 11
Training loss: 0.16073810321907672
Validation loss: 2.3873331578711583

Epoch: 6| Step: 12
Training loss: 0.09488288526033617
Validation loss: 2.4197403883594837

Epoch: 6| Step: 13
Training loss: 0.3361171641190074
Validation loss: 2.4313835536945487

Epoch: 432| Step: 0
Training loss: 0.23299018716460296
Validation loss: 2.397860001469083

Epoch: 6| Step: 1
Training loss: 0.1582683852485401
Validation loss: 2.4234330028934576

Epoch: 6| Step: 2
Training loss: 0.17527550421716936
Validation loss: 2.4383755508395053

Epoch: 6| Step: 3
Training loss: 0.419891374056938
Validation loss: 2.451062728333712

Epoch: 6| Step: 4
Training loss: 0.1219515107932043
Validation loss: 2.414008851780507

Epoch: 6| Step: 5
Training loss: 0.26952172690996773
Validation loss: 2.4271143506782002

Epoch: 6| Step: 6
Training loss: 0.08403868083844142
Validation loss: 2.4246578100290948

Epoch: 6| Step: 7
Training loss: 0.2527379373243346
Validation loss: 2.4341997217696405

Epoch: 6| Step: 8
Training loss: 0.4334331249299536
Validation loss: 2.4145813832421177

Epoch: 6| Step: 9
Training loss: 0.19426005046329337
Validation loss: 2.425047188352481

Epoch: 6| Step: 10
Training loss: 0.2981337914280224
Validation loss: 2.402665266746341

Epoch: 6| Step: 11
Training loss: 0.1580135127525867
Validation loss: 2.4117625140853938

Epoch: 6| Step: 12
Training loss: 0.2222416011652244
Validation loss: 2.4196779042917815

Epoch: 6| Step: 13
Training loss: 0.2237110334302571
Validation loss: 2.413484706986627

Epoch: 433| Step: 0
Training loss: 0.2388621659581516
Validation loss: 2.4174222822161835

Epoch: 6| Step: 1
Training loss: 0.278203303854718
Validation loss: 2.4371387728333533

Epoch: 6| Step: 2
Training loss: 0.4315946563132257
Validation loss: 2.4260664972587533

Epoch: 6| Step: 3
Training loss: 0.3017292935125893
Validation loss: 2.4231028788821884

Epoch: 6| Step: 4
Training loss: 0.24635032115835598
Validation loss: 2.4156253984447753

Epoch: 6| Step: 5
Training loss: 0.11457082470617763
Validation loss: 2.4042905533162853

Epoch: 6| Step: 6
Training loss: 0.3059243139361368
Validation loss: 2.4254026889889935

Epoch: 6| Step: 7
Training loss: 0.13353916134867175
Validation loss: 2.42221512061836

Epoch: 6| Step: 8
Training loss: 0.20078495927642448
Validation loss: 2.4051546582383234

Epoch: 6| Step: 9
Training loss: 0.11441321686223475
Validation loss: 2.4289452005441663

Epoch: 6| Step: 10
Training loss: 0.18238107441465942
Validation loss: 2.4208726389183752

Epoch: 6| Step: 11
Training loss: 0.2201518710955125
Validation loss: 2.4197825670535824

Epoch: 6| Step: 12
Training loss: 0.2572963055232371
Validation loss: 2.4168959384389272

Epoch: 6| Step: 13
Training loss: 0.1200580334964487
Validation loss: 2.4000980889108043

Epoch: 434| Step: 0
Training loss: 0.1371070796415772
Validation loss: 2.4169612718388414

Epoch: 6| Step: 1
Training loss: 0.1714888591657996
Validation loss: 2.4226039629630116

Epoch: 6| Step: 2
Training loss: 0.3155059249914039
Validation loss: 2.392926629781335

Epoch: 6| Step: 3
Training loss: 0.3031487244239269
Validation loss: 2.368198588620376

Epoch: 6| Step: 4
Training loss: 0.20366979862057555
Validation loss: 2.3911858783463917

Epoch: 6| Step: 5
Training loss: 0.3146107438547665
Validation loss: 2.4006513899851587

Epoch: 6| Step: 6
Training loss: 0.1704359827446208
Validation loss: 2.4226922065984606

Epoch: 6| Step: 7
Training loss: 0.32450688439165376
Validation loss: 2.4183767054990857

Epoch: 6| Step: 8
Training loss: 0.12431914453120238
Validation loss: 2.4523636604678996

Epoch: 6| Step: 9
Training loss: 0.14622547794842103
Validation loss: 2.4245850340891004

Epoch: 6| Step: 10
Training loss: 0.3225128497106926
Validation loss: 2.435389084028501

Epoch: 6| Step: 11
Training loss: 0.22487323852589208
Validation loss: 2.4408950132571303

Epoch: 6| Step: 12
Training loss: 0.2793685847704342
Validation loss: 2.4412194411476733

Epoch: 6| Step: 13
Training loss: 0.23602753430813966
Validation loss: 2.466854790140765

Epoch: 435| Step: 0
Training loss: 0.13692513283720847
Validation loss: 2.4379731647990748

Epoch: 6| Step: 1
Training loss: 0.20660551851018866
Validation loss: 2.415882034846861

Epoch: 6| Step: 2
Training loss: 0.24743554482551144
Validation loss: 2.4472047551239164

Epoch: 6| Step: 3
Training loss: 0.15355968013071622
Validation loss: 2.447223764421033

Epoch: 6| Step: 4
Training loss: 0.2144784075177174
Validation loss: 2.407407620930178

Epoch: 6| Step: 5
Training loss: 0.15069719748855953
Validation loss: 2.389986263195681

Epoch: 6| Step: 6
Training loss: 0.39365696110592663
Validation loss: 2.4089450603299296

Epoch: 6| Step: 7
Training loss: 0.4393055138102334
Validation loss: 2.385299024857261

Epoch: 6| Step: 8
Training loss: 0.2470396950187269
Validation loss: 2.397337921430403

Epoch: 6| Step: 9
Training loss: 0.2960196394760138
Validation loss: 2.388654087434987

Epoch: 6| Step: 10
Training loss: 0.1289313826480453
Validation loss: 2.3658429563241294

Epoch: 6| Step: 11
Training loss: 0.17100442596997217
Validation loss: 2.394508070896201

Epoch: 6| Step: 12
Training loss: 0.22073888910894363
Validation loss: 2.3992191115482666

Epoch: 6| Step: 13
Training loss: 0.24431764669894032
Validation loss: 2.397378972044611

Epoch: 436| Step: 0
Training loss: 0.16805226445478447
Validation loss: 2.416476464627891

Epoch: 6| Step: 1
Training loss: 0.252889224906772
Validation loss: 2.435191310352892

Epoch: 6| Step: 2
Training loss: 0.22517243175611143
Validation loss: 2.4696937274400854

Epoch: 6| Step: 3
Training loss: 0.1715603462459266
Validation loss: 2.431284788541696

Epoch: 6| Step: 4
Training loss: 0.16759417041353825
Validation loss: 2.4225403400066456

Epoch: 6| Step: 5
Training loss: 0.18115408143395115
Validation loss: 2.418912577694594

Epoch: 6| Step: 6
Training loss: 0.39386969518161136
Validation loss: 2.4349407604934123

Epoch: 6| Step: 7
Training loss: 0.3935330860655816
Validation loss: 2.4242110170785645

Epoch: 6| Step: 8
Training loss: 0.156792705510863
Validation loss: 2.4063042372349646

Epoch: 6| Step: 9
Training loss: 0.30410721123752765
Validation loss: 2.3905087525250486

Epoch: 6| Step: 10
Training loss: 0.2517151854941694
Validation loss: 2.4046711530283513

Epoch: 6| Step: 11
Training loss: 0.15060868493436633
Validation loss: 2.40580342749684

Epoch: 6| Step: 12
Training loss: 0.22421581784766825
Validation loss: 2.4230654063807466

Epoch: 6| Step: 13
Training loss: 0.16526351428282227
Validation loss: 2.4319911577123894

Epoch: 437| Step: 0
Training loss: 0.16741888287460974
Validation loss: 2.4296942929292715

Epoch: 6| Step: 1
Training loss: 0.3152791540964944
Validation loss: 2.3937755470151756

Epoch: 6| Step: 2
Training loss: 0.10082202352722085
Validation loss: 2.4541433376244775

Epoch: 6| Step: 3
Training loss: 0.16567924304031387
Validation loss: 2.411474208495594

Epoch: 6| Step: 4
Training loss: 0.24227280806318552
Validation loss: 2.4181014822096203

Epoch: 6| Step: 5
Training loss: 0.22656588716276987
Validation loss: 2.441365912385179

Epoch: 6| Step: 6
Training loss: 0.29855064524113034
Validation loss: 2.422205252199253

Epoch: 6| Step: 7
Training loss: 0.287278625011537
Validation loss: 2.4320375396220375

Epoch: 6| Step: 8
Training loss: 0.3862729248169387
Validation loss: 2.4203627910192784

Epoch: 6| Step: 9
Training loss: 0.137643716492688
Validation loss: 2.398660491563727

Epoch: 6| Step: 10
Training loss: 0.1720392028016707
Validation loss: 2.3908575916539

Epoch: 6| Step: 11
Training loss: 0.11297253356364508
Validation loss: 2.40830744282949

Epoch: 6| Step: 12
Training loss: 0.2343656855957591
Validation loss: 2.417261912440616

Epoch: 6| Step: 13
Training loss: 0.37725006030330593
Validation loss: 2.4241955075071746

Epoch: 438| Step: 0
Training loss: 0.2996735301456125
Validation loss: 2.4157344509163186

Epoch: 6| Step: 1
Training loss: 0.2289538135522116
Validation loss: 2.4090063797414074

Epoch: 6| Step: 2
Training loss: 0.36727806759976744
Validation loss: 2.43429722706012

Epoch: 6| Step: 3
Training loss: 0.18467632660090436
Validation loss: 2.4110217788398667

Epoch: 6| Step: 4
Training loss: 0.369261686465564
Validation loss: 2.4244240410364037

Epoch: 6| Step: 5
Training loss: 0.215506796295995
Validation loss: 2.4291231330659255

Epoch: 6| Step: 6
Training loss: 0.1268885154642714
Validation loss: 2.4073927953914884

Epoch: 6| Step: 7
Training loss: 0.11631868480399532
Validation loss: 2.429672512861163

Epoch: 6| Step: 8
Training loss: 0.170972448399292
Validation loss: 2.3922034038185087

Epoch: 6| Step: 9
Training loss: 0.15498562896156623
Validation loss: 2.3909329977279725

Epoch: 6| Step: 10
Training loss: 0.22229220930251936
Validation loss: 2.3953108322556975

Epoch: 6| Step: 11
Training loss: 0.21680422074528624
Validation loss: 2.3715755583130016

Epoch: 6| Step: 12
Training loss: 0.28897380756941027
Validation loss: 2.3837971520044126

Epoch: 6| Step: 13
Training loss: 0.22533482037590608
Validation loss: 2.393009048775077

Epoch: 439| Step: 0
Training loss: 0.33110462363490456
Validation loss: 2.412563440626942

Epoch: 6| Step: 1
Training loss: 0.29287120466748534
Validation loss: 2.418682190010078

Epoch: 6| Step: 2
Training loss: 0.259782532450056
Validation loss: 2.4037937241508955

Epoch: 6| Step: 3
Training loss: 0.21296081785681958
Validation loss: 2.4047492207628665

Epoch: 6| Step: 4
Training loss: 0.08663926455441795
Validation loss: 2.3820885085397085

Epoch: 6| Step: 5
Training loss: 0.28617298768556454
Validation loss: 2.4275792517597314

Epoch: 6| Step: 6
Training loss: 0.18152924681254512
Validation loss: 2.4159818445602768

Epoch: 6| Step: 7
Training loss: 0.30763974788226284
Validation loss: 2.414353098802839

Epoch: 6| Step: 8
Training loss: 0.1343261283339191
Validation loss: 2.4011152382219807

Epoch: 6| Step: 9
Training loss: 0.18400330213312543
Validation loss: 2.3990551195187395

Epoch: 6| Step: 10
Training loss: 0.14010234238336194
Validation loss: 2.367246900178915

Epoch: 6| Step: 11
Training loss: 0.25197292220531337
Validation loss: 2.373923283229995

Epoch: 6| Step: 12
Training loss: 0.2095023180894816
Validation loss: 2.3731051638171294

Epoch: 6| Step: 13
Training loss: 0.3791092397707423
Validation loss: 2.377835546141336

Epoch: 440| Step: 0
Training loss: 0.3553419620642376
Validation loss: 2.3953234012614892

Epoch: 6| Step: 1
Training loss: 0.19864874056679227
Validation loss: 2.3890111404566663

Epoch: 6| Step: 2
Training loss: 0.2977717808668985
Validation loss: 2.411828086194446

Epoch: 6| Step: 3
Training loss: 0.2362502419001234
Validation loss: 2.412519090668213

Epoch: 6| Step: 4
Training loss: 0.22217652021445788
Validation loss: 2.4345830686981427

Epoch: 6| Step: 5
Training loss: 0.23443230881990756
Validation loss: 2.4701491949966097

Epoch: 6| Step: 6
Training loss: 0.2934464184560521
Validation loss: 2.468119223840853

Epoch: 6| Step: 7
Training loss: 0.2772042366832514
Validation loss: 2.4761187499167985

Epoch: 6| Step: 8
Training loss: 0.095763362689129
Validation loss: 2.4235209555906874

Epoch: 6| Step: 9
Training loss: 0.3157899765326445
Validation loss: 2.427203944413117

Epoch: 6| Step: 10
Training loss: 0.13792962233359007
Validation loss: 2.398967225204324

Epoch: 6| Step: 11
Training loss: 0.2709586452693709
Validation loss: 2.3868409460797007

Epoch: 6| Step: 12
Training loss: 0.2873232557363464
Validation loss: 2.405042617347258

Epoch: 6| Step: 13
Training loss: 0.31415970659683295
Validation loss: 2.3623719381597885

Epoch: 441| Step: 0
Training loss: 0.197219427761315
Validation loss: 2.41819837344208

Epoch: 6| Step: 1
Training loss: 0.16608763984070804
Validation loss: 2.409582926700369

Epoch: 6| Step: 2
Training loss: 0.23033865796925979
Validation loss: 2.4260261719406024

Epoch: 6| Step: 3
Training loss: 0.35575274765846165
Validation loss: 2.468286752495248

Epoch: 6| Step: 4
Training loss: 0.13476852054525995
Validation loss: 2.476408839056311

Epoch: 6| Step: 5
Training loss: 0.1414249370935916
Validation loss: 2.4686784589813793

Epoch: 6| Step: 6
Training loss: 0.3883667711602288
Validation loss: 2.463136626972237

Epoch: 6| Step: 7
Training loss: 0.23826695227329914
Validation loss: 2.4366731958391727

Epoch: 6| Step: 8
Training loss: 0.2747783754029849
Validation loss: 2.404602247309021

Epoch: 6| Step: 9
Training loss: 0.27676153187214386
Validation loss: 2.409643459078017

Epoch: 6| Step: 10
Training loss: 0.36799516522299913
Validation loss: 2.3846688669982767

Epoch: 6| Step: 11
Training loss: 0.17433208106594403
Validation loss: 2.4119130894721077

Epoch: 6| Step: 12
Training loss: 0.17439266214513
Validation loss: 2.3626959972093418

Epoch: 6| Step: 13
Training loss: 0.2108915950133589
Validation loss: 2.3686040777233597

Epoch: 442| Step: 0
Training loss: 0.20876534294233276
Validation loss: 2.396365499758621

Epoch: 6| Step: 1
Training loss: 0.30676441973904744
Validation loss: 2.3614846473549775

Epoch: 6| Step: 2
Training loss: 0.13019009144475152
Validation loss: 2.3944169668144966

Epoch: 6| Step: 3
Training loss: 0.23209563367106714
Validation loss: 2.3918110050762103

Epoch: 6| Step: 4
Training loss: 0.23171423728237273
Validation loss: 2.4101403712977487

Epoch: 6| Step: 5
Training loss: 0.26307664725956936
Validation loss: 2.4011515051558097

Epoch: 6| Step: 6
Training loss: 0.154510416674682
Validation loss: 2.382345403476486

Epoch: 6| Step: 7
Training loss: 0.20016352703555437
Validation loss: 2.3696979910316283

Epoch: 6| Step: 8
Training loss: 0.35455435215682596
Validation loss: 2.3919728121940076

Epoch: 6| Step: 9
Training loss: 0.15847236187684755
Validation loss: 2.3844695603409196

Epoch: 6| Step: 10
Training loss: 0.28025860365048605
Validation loss: 2.381373223645112

Epoch: 6| Step: 11
Training loss: 0.22673378421984347
Validation loss: 2.390327201824015

Epoch: 6| Step: 12
Training loss: 0.24520821419963898
Validation loss: 2.3717002235623474

Epoch: 6| Step: 13
Training loss: 0.2269461277787501
Validation loss: 2.3723131173066525

Epoch: 443| Step: 0
Training loss: 0.1698596994058127
Validation loss: 2.4019949444290205

Epoch: 6| Step: 1
Training loss: 0.11214462566773703
Validation loss: 2.402830318301923

Epoch: 6| Step: 2
Training loss: 0.34397354226747867
Validation loss: 2.3561934091063037

Epoch: 6| Step: 3
Training loss: 0.10562160241711945
Validation loss: 2.37544216580066

Epoch: 6| Step: 4
Training loss: 0.13789283842520225
Validation loss: 2.390501178513595

Epoch: 6| Step: 5
Training loss: 0.2525119793524114
Validation loss: 2.432919954546319

Epoch: 6| Step: 6
Training loss: 0.2244648758852523
Validation loss: 2.407293175882212

Epoch: 6| Step: 7
Training loss: 0.30899485342437183
Validation loss: 2.3882395621484904

Epoch: 6| Step: 8
Training loss: 0.2189036323695816
Validation loss: 2.3903557346074575

Epoch: 6| Step: 9
Training loss: 0.32238987925900864
Validation loss: 2.370585303805199

Epoch: 6| Step: 10
Training loss: 0.2837513189033071
Validation loss: 2.351765551467737

Epoch: 6| Step: 11
Training loss: 0.32654078972668577
Validation loss: 2.3796590810076435

Epoch: 6| Step: 12
Training loss: 0.23420682277428712
Validation loss: 2.3859868109592393

Epoch: 6| Step: 13
Training loss: 0.17948284104081022
Validation loss: 2.4003493471355473

Epoch: 444| Step: 0
Training loss: 0.18559487374513572
Validation loss: 2.3944366671400017

Epoch: 6| Step: 1
Training loss: 0.13503179663591858
Validation loss: 2.392074117339705

Epoch: 6| Step: 2
Training loss: 0.1960858199047288
Validation loss: 2.3823921794472604

Epoch: 6| Step: 3
Training loss: 0.32722743205127663
Validation loss: 2.361758582919668

Epoch: 6| Step: 4
Training loss: 0.402201877505958
Validation loss: 2.3733965594259177

Epoch: 6| Step: 5
Training loss: 0.20032568617400565
Validation loss: 2.420714369055214

Epoch: 6| Step: 6
Training loss: 0.21284337350568125
Validation loss: 2.4073213478361817

Epoch: 6| Step: 7
Training loss: 0.14109815364652922
Validation loss: 2.4299964598878008

Epoch: 6| Step: 8
Training loss: 0.354528630172579
Validation loss: 2.443884807471185

Epoch: 6| Step: 9
Training loss: 0.20302843586241262
Validation loss: 2.4468923198450687

Epoch: 6| Step: 10
Training loss: 0.2589182261457974
Validation loss: 2.4315080883577367

Epoch: 6| Step: 11
Training loss: 0.16996320682203878
Validation loss: 2.455694464742601

Epoch: 6| Step: 12
Training loss: 0.22202006017204234
Validation loss: 2.4501344787861328

Epoch: 6| Step: 13
Training loss: 0.17966793824568925
Validation loss: 2.429312958417008

Epoch: 445| Step: 0
Training loss: 0.2829973986324138
Validation loss: 2.389107314837484

Epoch: 6| Step: 1
Training loss: 0.26893214662415665
Validation loss: 2.363657841567641

Epoch: 6| Step: 2
Training loss: 0.18419222986227574
Validation loss: 2.361357737751729

Epoch: 6| Step: 3
Training loss: 0.13198737171528857
Validation loss: 2.3684146158489168

Epoch: 6| Step: 4
Training loss: 0.26696796879458157
Validation loss: 2.3699023423194943

Epoch: 6| Step: 5
Training loss: 0.21997026280434218
Validation loss: 2.391716211740562

Epoch: 6| Step: 6
Training loss: 0.2926649298452539
Validation loss: 2.387061764132775

Epoch: 6| Step: 7
Training loss: 0.13098466625679522
Validation loss: 2.4044253981699266

Epoch: 6| Step: 8
Training loss: 0.25002151635085723
Validation loss: 2.40979142614843

Epoch: 6| Step: 9
Training loss: 0.17567874250769805
Validation loss: 2.3934157220020427

Epoch: 6| Step: 10
Training loss: 0.250041347303114
Validation loss: 2.4150438961799736

Epoch: 6| Step: 11
Training loss: 0.1780869267581173
Validation loss: 2.4010609328881665

Epoch: 6| Step: 12
Training loss: 0.26414709711142326
Validation loss: 2.4087775041553052

Epoch: 6| Step: 13
Training loss: 0.42107529254724924
Validation loss: 2.4289822171550117

Epoch: 446| Step: 0
Training loss: 0.24068395678830165
Validation loss: 2.397170004182088

Epoch: 6| Step: 1
Training loss: 0.23911011477242974
Validation loss: 2.385497749592369

Epoch: 6| Step: 2
Training loss: 0.1307542079395204
Validation loss: 2.395643833650404

Epoch: 6| Step: 3
Training loss: 0.1379347066147029
Validation loss: 2.3788326035217198

Epoch: 6| Step: 4
Training loss: 0.1403689570149533
Validation loss: 2.376203578514893

Epoch: 6| Step: 5
Training loss: 0.38931187217467034
Validation loss: 2.3817174629491644

Epoch: 6| Step: 6
Training loss: 0.14251190110753215
Validation loss: 2.3859197155379044

Epoch: 6| Step: 7
Training loss: 0.3827560538891421
Validation loss: 2.362075711614696

Epoch: 6| Step: 8
Training loss: 0.2818150936251858
Validation loss: 2.3962507359601584

Epoch: 6| Step: 9
Training loss: 0.1503200117522261
Validation loss: 2.38253602902396

Epoch: 6| Step: 10
Training loss: 0.21996506356684942
Validation loss: 2.3943052136504557

Epoch: 6| Step: 11
Training loss: 0.2713322247415956
Validation loss: 2.392595129599299

Epoch: 6| Step: 12
Training loss: 0.16764712035962404
Validation loss: 2.389279229036675

Epoch: 6| Step: 13
Training loss: 0.23536747763865257
Validation loss: 2.3930254696694564

Epoch: 447| Step: 0
Training loss: 0.3188411484152033
Validation loss: 2.3718581356134463

Epoch: 6| Step: 1
Training loss: 0.171625769418963
Validation loss: 2.3878204776595924

Epoch: 6| Step: 2
Training loss: 0.31314342539745554
Validation loss: 2.366448226488864

Epoch: 6| Step: 3
Training loss: 0.30609458853123356
Validation loss: 2.394398610033789

Epoch: 6| Step: 4
Training loss: 0.27774105359080686
Validation loss: 2.3846196280793612

Epoch: 6| Step: 5
Training loss: 0.16155114633890785
Validation loss: 2.3800265008321846

Epoch: 6| Step: 6
Training loss: 0.14233864961441128
Validation loss: 2.3844060842552515

Epoch: 6| Step: 7
Training loss: 0.11062763081671333
Validation loss: 2.401011225059604

Epoch: 6| Step: 8
Training loss: 0.2581533865987459
Validation loss: 2.4014785928185947

Epoch: 6| Step: 9
Training loss: 0.30627494924474963
Validation loss: 2.4000582036998592

Epoch: 6| Step: 10
Training loss: 0.2311648266753334
Validation loss: 2.3971589225710135

Epoch: 6| Step: 11
Training loss: 0.13694703253399726
Validation loss: 2.4174342221899505

Epoch: 6| Step: 12
Training loss: 0.203687430220525
Validation loss: 2.4304689199903815

Epoch: 6| Step: 13
Training loss: 0.2461384475322074
Validation loss: 2.4162282521302907

Epoch: 448| Step: 0
Training loss: 0.18151521968279113
Validation loss: 2.407858382550858

Epoch: 6| Step: 1
Training loss: 0.159518273785115
Validation loss: 2.417460410601613

Epoch: 6| Step: 2
Training loss: 0.14146486458520816
Validation loss: 2.42585866902745

Epoch: 6| Step: 3
Training loss: 0.2333568392278354
Validation loss: 2.396583267124996

Epoch: 6| Step: 4
Training loss: 0.2294922767801314
Validation loss: 2.4046689451163936

Epoch: 6| Step: 5
Training loss: 0.24127891293152115
Validation loss: 2.408695443779496

Epoch: 6| Step: 6
Training loss: 0.37895296732979816
Validation loss: 2.383127695126216

Epoch: 6| Step: 7
Training loss: 0.2742552110825446
Validation loss: 2.4038079698525854

Epoch: 6| Step: 8
Training loss: 0.1721879050687951
Validation loss: 2.380283689397687

Epoch: 6| Step: 9
Training loss: 0.1754316137628971
Validation loss: 2.398069181276828

Epoch: 6| Step: 10
Training loss: 0.23340064011815345
Validation loss: 2.386999951872309

Epoch: 6| Step: 11
Training loss: 0.3097734356505198
Validation loss: 2.3604476284435143

Epoch: 6| Step: 12
Training loss: 0.1537134936167429
Validation loss: 2.368981142298569

Epoch: 6| Step: 13
Training loss: 0.19812326669686908
Validation loss: 2.364822974743653

Epoch: 449| Step: 0
Training loss: 0.2241872303437057
Validation loss: 2.3788994456754824

Epoch: 6| Step: 1
Training loss: 0.16227835155787784
Validation loss: 2.3591761503556636

Epoch: 6| Step: 2
Training loss: 0.15443267158145169
Validation loss: 2.371153956728723

Epoch: 6| Step: 3
Training loss: 0.20964681503552285
Validation loss: 2.402755919376875

Epoch: 6| Step: 4
Training loss: 0.2678123896541835
Validation loss: 2.3797642202464235

Epoch: 6| Step: 5
Training loss: 0.32153921621343845
Validation loss: 2.3998492442657655

Epoch: 6| Step: 6
Training loss: 0.16826508685265137
Validation loss: 2.399091681536527

Epoch: 6| Step: 7
Training loss: 0.3059799341614785
Validation loss: 2.3914316955555464

Epoch: 6| Step: 8
Training loss: 0.18036265619408534
Validation loss: 2.403900778945707

Epoch: 6| Step: 9
Training loss: 0.14737305959487
Validation loss: 2.3950305842254656

Epoch: 6| Step: 10
Training loss: 0.33363477914684103
Validation loss: 2.4135000208975366

Epoch: 6| Step: 11
Training loss: 0.2633074325763873
Validation loss: 2.4155124868559588

Epoch: 6| Step: 12
Training loss: 0.12866173297168315
Validation loss: 2.391984997632661

Epoch: 6| Step: 13
Training loss: 0.21822615468140022
Validation loss: 2.399685600839416

Epoch: 450| Step: 0
Training loss: 0.22624806255754498
Validation loss: 2.417891661497097

Epoch: 6| Step: 1
Training loss: 0.30326528449193946
Validation loss: 2.4110888955591294

Epoch: 6| Step: 2
Training loss: 0.1923511885778078
Validation loss: 2.4017367622193593

Epoch: 6| Step: 3
Training loss: 0.32830204047667877
Validation loss: 2.4090922104613837

Epoch: 6| Step: 4
Training loss: 0.25175127919126844
Validation loss: 2.4288931903662108

Epoch: 6| Step: 5
Training loss: 0.29473494611966994
Validation loss: 2.3957813515893602

Epoch: 6| Step: 6
Training loss: 0.2682218535207171
Validation loss: 2.4260446154068225

Epoch: 6| Step: 7
Training loss: 0.1571024647828646
Validation loss: 2.4026043520872897

Epoch: 6| Step: 8
Training loss: 0.2519764261042814
Validation loss: 2.403660713268576

Epoch: 6| Step: 9
Training loss: 0.19658960516372415
Validation loss: 2.405441375241903

Epoch: 6| Step: 10
Training loss: 0.16865434010378302
Validation loss: 2.4081161011307133

Epoch: 6| Step: 11
Training loss: 0.18239786369882793
Validation loss: 2.4060008603626555

Epoch: 6| Step: 12
Training loss: 0.2016508455874995
Validation loss: 2.397919744095439

Epoch: 6| Step: 13
Training loss: 0.17392837119811314
Validation loss: 2.3931914640366463

Epoch: 451| Step: 0
Training loss: 0.14555548200686835
Validation loss: 2.4073162324157216

Epoch: 6| Step: 1
Training loss: 0.126426617357214
Validation loss: 2.3808577899923717

Epoch: 6| Step: 2
Training loss: 0.2901970789320676
Validation loss: 2.372445032390728

Epoch: 6| Step: 3
Training loss: 0.3961140072550096
Validation loss: 2.375428954949756

Epoch: 6| Step: 4
Training loss: 0.18714965434545688
Validation loss: 2.368190140829558

Epoch: 6| Step: 5
Training loss: 0.14104606585166468
Validation loss: 2.3758105377511214

Epoch: 6| Step: 6
Training loss: 0.1805424358163868
Validation loss: 2.349509126576561

Epoch: 6| Step: 7
Training loss: 0.32490961165879956
Validation loss: 2.3803265494824113

Epoch: 6| Step: 8
Training loss: 0.208225762888225
Validation loss: 2.3694848865519824

Epoch: 6| Step: 9
Training loss: 0.24890460002421738
Validation loss: 2.347877721178428

Epoch: 6| Step: 10
Training loss: 0.14287302142372724
Validation loss: 2.376175279300592

Epoch: 6| Step: 11
Training loss: 0.22658777096001337
Validation loss: 2.3727620639101854

Epoch: 6| Step: 12
Training loss: 0.18378316969145397
Validation loss: 2.3433806294435975

Epoch: 6| Step: 13
Training loss: 0.1616169678314113
Validation loss: 2.3450831771927945

Epoch: 452| Step: 0
Training loss: 0.24042033929570503
Validation loss: 2.3574628137807907

Epoch: 6| Step: 1
Training loss: 0.28444567420461014
Validation loss: 2.368714896169876

Epoch: 6| Step: 2
Training loss: 0.26592160942843945
Validation loss: 2.3535532266912123

Epoch: 6| Step: 3
Training loss: 0.2609542669973984
Validation loss: 2.3699454766876196

Epoch: 6| Step: 4
Training loss: 0.23058570706709627
Validation loss: 2.3727944997496855

Epoch: 6| Step: 5
Training loss: 0.2387049066814559
Validation loss: 2.334114496777181

Epoch: 6| Step: 6
Training loss: 0.24390327360156516
Validation loss: 2.3402431183574643

Epoch: 6| Step: 7
Training loss: 0.18412720507928373
Validation loss: 2.387792716593854

Epoch: 6| Step: 8
Training loss: 0.14160044439466296
Validation loss: 2.391972361515395

Epoch: 6| Step: 9
Training loss: 0.19195236421713008
Validation loss: 2.3736522954739177

Epoch: 6| Step: 10
Training loss: 0.28952080248178114
Validation loss: 2.40482518373246

Epoch: 6| Step: 11
Training loss: 0.2932263703944131
Validation loss: 2.408663505230177

Epoch: 6| Step: 12
Training loss: 0.19433088631511106
Validation loss: 2.402903313026481

Epoch: 6| Step: 13
Training loss: 0.11964919249134189
Validation loss: 2.3988884296220574

Epoch: 453| Step: 0
Training loss: 0.25945713971669376
Validation loss: 2.36926987799474

Epoch: 6| Step: 1
Training loss: 0.135067187716447
Validation loss: 2.3537246455380463

Epoch: 6| Step: 2
Training loss: 0.11587365676560171
Validation loss: 2.3657349573922906

Epoch: 6| Step: 3
Training loss: 0.31233982511175473
Validation loss: 2.3695013060175403

Epoch: 6| Step: 4
Training loss: 0.17934578039519206
Validation loss: 2.376588100471215

Epoch: 6| Step: 5
Training loss: 0.12320057034792026
Validation loss: 2.363236570736805

Epoch: 6| Step: 6
Training loss: 0.13222079440542173
Validation loss: 2.37299864812099

Epoch: 6| Step: 7
Training loss: 0.13592316206592278
Validation loss: 2.388391381974977

Epoch: 6| Step: 8
Training loss: 0.21808797419582793
Validation loss: 2.3767802432025182

Epoch: 6| Step: 9
Training loss: 0.2264566503097849
Validation loss: 2.4241679800472746

Epoch: 6| Step: 10
Training loss: 0.3292897419366228
Validation loss: 2.3919803992297735

Epoch: 6| Step: 11
Training loss: 0.28141113804411505
Validation loss: 2.398287155250789

Epoch: 6| Step: 12
Training loss: 0.22979244313032493
Validation loss: 2.423965192548072

Epoch: 6| Step: 13
Training loss: 0.3546223467168557
Validation loss: 2.467049859216951

Epoch: 454| Step: 0
Training loss: 0.2123242552582393
Validation loss: 2.4462992833423645

Epoch: 6| Step: 1
Training loss: 0.3460066158235483
Validation loss: 2.4427045439087665

Epoch: 6| Step: 2
Training loss: 0.17952348645840138
Validation loss: 2.4437085078938177

Epoch: 6| Step: 3
Training loss: 0.31949486700227
Validation loss: 2.423240346094274

Epoch: 6| Step: 4
Training loss: 0.1909431382390999
Validation loss: 2.4149884332741514

Epoch: 6| Step: 5
Training loss: 0.24367105721755056
Validation loss: 2.405333580061324

Epoch: 6| Step: 6
Training loss: 0.1753213057286948
Validation loss: 2.3973231608744077

Epoch: 6| Step: 7
Training loss: 0.21574437630872811
Validation loss: 2.3735893385376654

Epoch: 6| Step: 8
Training loss: 0.2030483889991175
Validation loss: 2.370026390858494

Epoch: 6| Step: 9
Training loss: 0.21526013685740972
Validation loss: 2.380645595106911

Epoch: 6| Step: 10
Training loss: 0.15001440053598433
Validation loss: 2.3808253988597747

Epoch: 6| Step: 11
Training loss: 0.13697665276293533
Validation loss: 2.3816310967017844

Epoch: 6| Step: 12
Training loss: 0.2749031297255777
Validation loss: 2.380272995527388

Epoch: 6| Step: 13
Training loss: 0.3264352797057142
Validation loss: 2.362942441815564

Epoch: 455| Step: 0
Training loss: 0.18817555400974117
Validation loss: 2.3730564141715824

Epoch: 6| Step: 1
Training loss: 0.16635524008226843
Validation loss: 2.384024886852448

Epoch: 6| Step: 2
Training loss: 0.14023858863641958
Validation loss: 2.4057224485374857

Epoch: 6| Step: 3
Training loss: 0.12200328512586028
Validation loss: 2.3619637925965864

Epoch: 6| Step: 4
Training loss: 0.3086953780471755
Validation loss: 2.3649747650198787

Epoch: 6| Step: 5
Training loss: 0.20184823564434415
Validation loss: 2.392072914330435

Epoch: 6| Step: 6
Training loss: 0.26831111612858316
Validation loss: 2.421752093501411

Epoch: 6| Step: 7
Training loss: 0.2785277814740094
Validation loss: 2.441213144454793

Epoch: 6| Step: 8
Training loss: 0.2765130106510351
Validation loss: 2.4110972028802804

Epoch: 6| Step: 9
Training loss: 0.195706142470802
Validation loss: 2.4249896305641876

Epoch: 6| Step: 10
Training loss: 0.17891178414060252
Validation loss: 2.4227259130506047

Epoch: 6| Step: 11
Training loss: 0.18668061269948732
Validation loss: 2.448928718752305

Epoch: 6| Step: 12
Training loss: 0.33114538385113335
Validation loss: 2.437787449465509

Epoch: 6| Step: 13
Training loss: 0.2609512119916321
Validation loss: 2.4453666780869026

Epoch: 456| Step: 0
Training loss: 0.18664572736329263
Validation loss: 2.438223690093713

Epoch: 6| Step: 1
Training loss: 0.3101631408809928
Validation loss: 2.427062874822694

Epoch: 6| Step: 2
Training loss: 0.1985878022246415
Validation loss: 2.4013899793268347

Epoch: 6| Step: 3
Training loss: 0.18183072714710927
Validation loss: 2.3955288966907697

Epoch: 6| Step: 4
Training loss: 0.12304063433004596
Validation loss: 2.3790322773569983

Epoch: 6| Step: 5
Training loss: 0.1778615664109429
Validation loss: 2.387611367921954

Epoch: 6| Step: 6
Training loss: 0.22664887327473357
Validation loss: 2.3386859611303064

Epoch: 6| Step: 7
Training loss: 0.2904486669869024
Validation loss: 2.3681637825271684

Epoch: 6| Step: 8
Training loss: 0.2808929667326686
Validation loss: 2.399226118966078

Epoch: 6| Step: 9
Training loss: 0.2991732430775694
Validation loss: 2.3903275203583214

Epoch: 6| Step: 10
Training loss: 0.3656111421159669
Validation loss: 2.4161436659276685

Epoch: 6| Step: 11
Training loss: 0.18350140298468157
Validation loss: 2.4138445566146918

Epoch: 6| Step: 12
Training loss: 0.193620313033578
Validation loss: 2.4538950440757654

Epoch: 6| Step: 13
Training loss: 0.2127213461280235
Validation loss: 2.434793619499323

Epoch: 457| Step: 0
Training loss: 0.2856229985916168
Validation loss: 2.440584280733087

Epoch: 6| Step: 1
Training loss: 0.15893401161307866
Validation loss: 2.4149034883521114

Epoch: 6| Step: 2
Training loss: 0.15634950211416412
Validation loss: 2.369017893593351

Epoch: 6| Step: 3
Training loss: 0.3360209915736587
Validation loss: 2.369015313738374

Epoch: 6| Step: 4
Training loss: 0.2355364631135635
Validation loss: 2.3902840523669417

Epoch: 6| Step: 5
Training loss: 0.29095200989021286
Validation loss: 2.3720697710387717

Epoch: 6| Step: 6
Training loss: 0.16959717299446134
Validation loss: 2.364891080646479

Epoch: 6| Step: 7
Training loss: 0.19235531373206857
Validation loss: 2.3916713899849698

Epoch: 6| Step: 8
Training loss: 0.23632684029474302
Validation loss: 2.392759569732837

Epoch: 6| Step: 9
Training loss: 0.1568673217649753
Validation loss: 2.3640715038927125

Epoch: 6| Step: 10
Training loss: 0.37980121432447234
Validation loss: 2.403787952258059

Epoch: 6| Step: 11
Training loss: 0.24428115614827883
Validation loss: 2.3641621594619537

Epoch: 6| Step: 12
Training loss: 0.2798525078413212
Validation loss: 2.393110629825558

Epoch: 6| Step: 13
Training loss: 0.19428889026194743
Validation loss: 2.368459369535015

Epoch: 458| Step: 0
Training loss: 0.2196106329372643
Validation loss: 2.384095077115397

Epoch: 6| Step: 1
Training loss: 0.21538492880820692
Validation loss: 2.396877623711951

Epoch: 6| Step: 2
Training loss: 0.24040795854789204
Validation loss: 2.3929082626391156

Epoch: 6| Step: 3
Training loss: 0.3402979216592587
Validation loss: 2.4335212502492576

Epoch: 6| Step: 4
Training loss: 0.2972396693884885
Validation loss: 2.428844605223472

Epoch: 6| Step: 5
Training loss: 0.28883394020341124
Validation loss: 2.4334202517603574

Epoch: 6| Step: 6
Training loss: 0.3300248729478724
Validation loss: 2.4314369656365096

Epoch: 6| Step: 7
Training loss: 0.20548994404664164
Validation loss: 2.3654568047166875

Epoch: 6| Step: 8
Training loss: 0.33420701441908635
Validation loss: 2.374171469251308

Epoch: 6| Step: 9
Training loss: 0.16439217414267443
Validation loss: 2.3752150834881767

Epoch: 6| Step: 10
Training loss: 0.3127688324447422
Validation loss: 2.3748306393213703

Epoch: 6| Step: 11
Training loss: 0.22108309453891906
Validation loss: 2.3786300374087164

Epoch: 6| Step: 12
Training loss: 0.2263336011904207
Validation loss: 2.3949012930120306

Epoch: 6| Step: 13
Training loss: 0.1594267489996712
Validation loss: 2.402389823391062

Epoch: 459| Step: 0
Training loss: 0.37316008043475596
Validation loss: 2.398545561281409

Epoch: 6| Step: 1
Training loss: 0.2485279989055094
Validation loss: 2.4389315162392

Epoch: 6| Step: 2
Training loss: 0.21863838311385
Validation loss: 2.4470786097265904

Epoch: 6| Step: 3
Training loss: 0.32820646092263867
Validation loss: 2.457845286072869

Epoch: 6| Step: 4
Training loss: 0.1471138716145691
Validation loss: 2.4421738817560126

Epoch: 6| Step: 5
Training loss: 0.22456441512221534
Validation loss: 2.3958312888402005

Epoch: 6| Step: 6
Training loss: 0.28409398153117493
Validation loss: 2.406985229836569

Epoch: 6| Step: 7
Training loss: 0.2901923805136968
Validation loss: 2.3726968894483287

Epoch: 6| Step: 8
Training loss: 0.28834792040757456
Validation loss: 2.37453810038133

Epoch: 6| Step: 9
Training loss: 0.21643765218246358
Validation loss: 2.3923561787160157

Epoch: 6| Step: 10
Training loss: 0.23280744067077594
Validation loss: 2.3931684267494617

Epoch: 6| Step: 11
Training loss: 0.3114282229337674
Validation loss: 2.40084710664305

Epoch: 6| Step: 12
Training loss: 0.16209853951883457
Validation loss: 2.4438899675077526

Epoch: 6| Step: 13
Training loss: 0.11711551124040376
Validation loss: 2.4463242688411992

Epoch: 460| Step: 0
Training loss: 0.3141317087277546
Validation loss: 2.432940775107421

Epoch: 6| Step: 1
Training loss: 0.14511869232095756
Validation loss: 2.43177890838227

Epoch: 6| Step: 2
Training loss: 0.2363387255222196
Validation loss: 2.4228003230380217

Epoch: 6| Step: 3
Training loss: 0.12921876305392105
Validation loss: 2.4165397465029055

Epoch: 6| Step: 4
Training loss: 0.16727284499171205
Validation loss: 2.3938892975230255

Epoch: 6| Step: 5
Training loss: 0.15140696587408084
Validation loss: 2.4152742694969516

Epoch: 6| Step: 6
Training loss: 0.30430454249387257
Validation loss: 2.4253853245986132

Epoch: 6| Step: 7
Training loss: 0.14638330151499196
Validation loss: 2.404060216505411

Epoch: 6| Step: 8
Training loss: 0.20663467247218975
Validation loss: 2.3483635039413837

Epoch: 6| Step: 9
Training loss: 0.29488582264410745
Validation loss: 2.4010150197822293

Epoch: 6| Step: 10
Training loss: 0.22726977052445047
Validation loss: 2.3667311836240565

Epoch: 6| Step: 11
Training loss: 0.213350211162856
Validation loss: 2.3821839432683367

Epoch: 6| Step: 12
Training loss: 0.31621319567962014
Validation loss: 2.413778242985544

Epoch: 6| Step: 13
Training loss: 0.3904871125042296
Validation loss: 2.3955513922469818

Epoch: 461| Step: 0
Training loss: 0.29409322470708354
Validation loss: 2.399242671478481

Epoch: 6| Step: 1
Training loss: 0.23468007260085916
Validation loss: 2.3851630758569935

Epoch: 6| Step: 2
Training loss: 0.31173604329261106
Validation loss: 2.36556034215159

Epoch: 6| Step: 3
Training loss: 0.17665406865585545
Validation loss: 2.330241520026239

Epoch: 6| Step: 4
Training loss: 0.1949091752373925
Validation loss: 2.3804956613093045

Epoch: 6| Step: 5
Training loss: 0.3372231213100108
Validation loss: 2.373559652111212

Epoch: 6| Step: 6
Training loss: 0.2762936605499383
Validation loss: 2.354074478703854

Epoch: 6| Step: 7
Training loss: 0.2852584838499893
Validation loss: 2.3861578272525534

Epoch: 6| Step: 8
Training loss: 0.21373648982825239
Validation loss: 2.427360341055823

Epoch: 6| Step: 9
Training loss: 0.22265413350220334
Validation loss: 2.445518292351196

Epoch: 6| Step: 10
Training loss: 0.20137530291065092
Validation loss: 2.481915260888887

Epoch: 6| Step: 11
Training loss: 0.3597552941047438
Validation loss: 2.4863375600174016

Epoch: 6| Step: 12
Training loss: 0.22924070986380818
Validation loss: 2.5002286047652835

Epoch: 6| Step: 13
Training loss: 0.13854203391444736
Validation loss: 2.4476924876498436

Epoch: 462| Step: 0
Training loss: 0.1960320569445486
Validation loss: 2.467551816412517

Epoch: 6| Step: 1
Training loss: 0.17962981417634813
Validation loss: 2.445522334598662

Epoch: 6| Step: 2
Training loss: 0.09234443657840896
Validation loss: 2.450021494891878

Epoch: 6| Step: 3
Training loss: 0.24506818425912752
Validation loss: 2.4102964679728043

Epoch: 6| Step: 4
Training loss: 0.26346899633946946
Validation loss: 2.3902975859918465

Epoch: 6| Step: 5
Training loss: 0.22345585047454322
Validation loss: 2.3747959119437403

Epoch: 6| Step: 6
Training loss: 0.38008083095547823
Validation loss: 2.373961266314592

Epoch: 6| Step: 7
Training loss: 0.223222355867004
Validation loss: 2.3676915262504954

Epoch: 6| Step: 8
Training loss: 0.2414908773113904
Validation loss: 2.36112099634796

Epoch: 6| Step: 9
Training loss: 0.3402733991734791
Validation loss: 2.3673596025310215

Epoch: 6| Step: 10
Training loss: 0.21182797700646477
Validation loss: 2.41851656665641

Epoch: 6| Step: 11
Training loss: 0.2796458884670663
Validation loss: 2.3948606045675365

Epoch: 6| Step: 12
Training loss: 0.16612224521032035
Validation loss: 2.4433085204966947

Epoch: 6| Step: 13
Training loss: 0.1275202335636888
Validation loss: 2.439313517344776

Epoch: 463| Step: 0
Training loss: 0.1951118487600475
Validation loss: 2.4720795312050683

Epoch: 6| Step: 1
Training loss: 0.20432850208147035
Validation loss: 2.516370988432654

Epoch: 6| Step: 2
Training loss: 0.33427275092546815
Validation loss: 2.5078140241917115

Epoch: 6| Step: 3
Training loss: 0.22162093841878097
Validation loss: 2.4268183226605546

Epoch: 6| Step: 4
Training loss: 0.26248976312840056
Validation loss: 2.422980863652351

Epoch: 6| Step: 5
Training loss: 0.2483092144773489
Validation loss: 2.430414400313691

Epoch: 6| Step: 6
Training loss: 0.31426093347112793
Validation loss: 2.3975078008355597

Epoch: 6| Step: 7
Training loss: 0.2180421480044371
Validation loss: 2.4032868400413827

Epoch: 6| Step: 8
Training loss: 0.28317307937669894
Validation loss: 2.4227277235680322

Epoch: 6| Step: 9
Training loss: 0.2078305147006529
Validation loss: 2.45605745879906

Epoch: 6| Step: 10
Training loss: 0.3104170161870401
Validation loss: 2.449303952909468

Epoch: 6| Step: 11
Training loss: 0.2262715740877214
Validation loss: 2.464236148412269

Epoch: 6| Step: 12
Training loss: 0.3752300629615228
Validation loss: 2.467751780548017

Epoch: 6| Step: 13
Training loss: 0.2211216696644209
Validation loss: 2.450575647748762

Epoch: 464| Step: 0
Training loss: 0.17227673181206687
Validation loss: 2.4081249552552952

Epoch: 6| Step: 1
Training loss: 0.3911254347533324
Validation loss: 2.4308763480039612

Epoch: 6| Step: 2
Training loss: 0.12077594399980501
Validation loss: 2.4048475731402923

Epoch: 6| Step: 3
Training loss: 0.256944901591974
Validation loss: 2.383255971184655

Epoch: 6| Step: 4
Training loss: 0.20548277397306527
Validation loss: 2.338764831658522

Epoch: 6| Step: 5
Training loss: 0.19340151510638792
Validation loss: 2.3253040576246313

Epoch: 6| Step: 6
Training loss: 0.313177042917291
Validation loss: 2.3156286170872216

Epoch: 6| Step: 7
Training loss: 0.11078800552065173
Validation loss: 2.3281511160908144

Epoch: 6| Step: 8
Training loss: 0.18539962949237407
Validation loss: 2.312207997030449

Epoch: 6| Step: 9
Training loss: 0.35498756286164906
Validation loss: 2.334039568779417

Epoch: 6| Step: 10
Training loss: 0.15462510892930506
Validation loss: 2.34920749898487

Epoch: 6| Step: 11
Training loss: 0.2343508787458331
Validation loss: 2.3599937087896863

Epoch: 6| Step: 12
Training loss: 0.1540513801817461
Validation loss: 2.318419943270573

Epoch: 6| Step: 13
Training loss: 0.28475435232029706
Validation loss: 2.3474302519051746

Epoch: 465| Step: 0
Training loss: 0.12471533936597334
Validation loss: 2.3465089607036824

Epoch: 6| Step: 1
Training loss: 0.3202718848553609
Validation loss: 2.37059446248452

Epoch: 6| Step: 2
Training loss: 0.20307665029379057
Validation loss: 2.381458859689107

Epoch: 6| Step: 3
Training loss: 0.1492635118044806
Validation loss: 2.38852876578573

Epoch: 6| Step: 4
Training loss: 0.13099116478629552
Validation loss: 2.416671227467455

Epoch: 6| Step: 5
Training loss: 0.33446768875331506
Validation loss: 2.3669656802380077

Epoch: 6| Step: 6
Training loss: 0.23434854993979953
Validation loss: 2.426804074174758

Epoch: 6| Step: 7
Training loss: 0.20698655743707137
Validation loss: 2.4109608977384314

Epoch: 6| Step: 8
Training loss: 0.2255728911883747
Validation loss: 2.4699624841843555

Epoch: 6| Step: 9
Training loss: 0.3257854822739237
Validation loss: 2.456444273286415

Epoch: 6| Step: 10
Training loss: 0.17555183168517446
Validation loss: 2.4522327435671083

Epoch: 6| Step: 11
Training loss: 0.2714992628886647
Validation loss: 2.420061694528069

Epoch: 6| Step: 12
Training loss: 0.20858928732795207
Validation loss: 2.4081574374881427

Epoch: 6| Step: 13
Training loss: 0.16188954764800084
Validation loss: 2.3824662845821676

Epoch: 466| Step: 0
Training loss: 0.165223926637701
Validation loss: 2.396922374316579

Epoch: 6| Step: 1
Training loss: 0.29176061116381796
Validation loss: 2.375672891107887

Epoch: 6| Step: 2
Training loss: 0.3060491896125174
Validation loss: 2.3837194004281588

Epoch: 6| Step: 3
Training loss: 0.2794657776708749
Validation loss: 2.3775575022659163

Epoch: 6| Step: 4
Training loss: 0.21673074349438443
Validation loss: 2.37008589836267

Epoch: 6| Step: 5
Training loss: 0.14149026772093606
Validation loss: 2.3819635313476692

Epoch: 6| Step: 6
Training loss: 0.25945297585804417
Validation loss: 2.383068360528461

Epoch: 6| Step: 7
Training loss: 0.20488606496725767
Validation loss: 2.3646156150179496

Epoch: 6| Step: 8
Training loss: 0.20170387736245263
Validation loss: 2.3990499474683147

Epoch: 6| Step: 9
Training loss: 0.16021189653326556
Validation loss: 2.3927811163451773

Epoch: 6| Step: 10
Training loss: 0.138181929022261
Validation loss: 2.3992628023254023

Epoch: 6| Step: 11
Training loss: 0.20393684347703472
Validation loss: 2.394243805756962

Epoch: 6| Step: 12
Training loss: 0.2344979678866094
Validation loss: 2.403916426386372

Epoch: 6| Step: 13
Training loss: 0.16675559232068893
Validation loss: 2.3946517081360224

Epoch: 467| Step: 0
Training loss: 0.16188506613367115
Validation loss: 2.417279203677123

Epoch: 6| Step: 1
Training loss: 0.3266441557975543
Validation loss: 2.4002287439708425

Epoch: 6| Step: 2
Training loss: 0.3026129940712952
Validation loss: 2.3792854121553653

Epoch: 6| Step: 3
Training loss: 0.28835341111234775
Validation loss: 2.3338685516906303

Epoch: 6| Step: 4
Training loss: 0.22334180663413436
Validation loss: 2.3504665585796443

Epoch: 6| Step: 5
Training loss: 0.2360738379301091
Validation loss: 2.3362552433440866

Epoch: 6| Step: 6
Training loss: 0.34714242919035454
Validation loss: 2.3489202251598638

Epoch: 6| Step: 7
Training loss: 0.13020741621330253
Validation loss: 2.362210837235897

Epoch: 6| Step: 8
Training loss: 0.13272831155849504
Validation loss: 2.3633706737886166

Epoch: 6| Step: 9
Training loss: 0.3156218047027499
Validation loss: 2.3863879559069696

Epoch: 6| Step: 10
Training loss: 0.17694476025749634
Validation loss: 2.366996372688651

Epoch: 6| Step: 11
Training loss: 0.1452218003392851
Validation loss: 2.4019460884379553

Epoch: 6| Step: 12
Training loss: 0.15305439552301478
Validation loss: 2.426377222032353

Epoch: 6| Step: 13
Training loss: 0.18349429744310194
Validation loss: 2.3984280478801048

Epoch: 468| Step: 0
Training loss: 0.20268186502919458
Validation loss: 2.4498217583997226

Epoch: 6| Step: 1
Training loss: 0.1534804400922431
Validation loss: 2.398789848411281

Epoch: 6| Step: 2
Training loss: 0.24498431339210833
Validation loss: 2.3842471796637237

Epoch: 6| Step: 3
Training loss: 0.24493276641819378
Validation loss: 2.383387796370729

Epoch: 6| Step: 4
Training loss: 0.12394432863962465
Validation loss: 2.3736411742707344

Epoch: 6| Step: 5
Training loss: 0.1708861428334221
Validation loss: 2.350170809102482

Epoch: 6| Step: 6
Training loss: 0.234296849254926
Validation loss: 2.392694568190416

Epoch: 6| Step: 7
Training loss: 0.2841833579753832
Validation loss: 2.342234739019183

Epoch: 6| Step: 8
Training loss: 0.27669403375046364
Validation loss: 2.3652957730025643

Epoch: 6| Step: 9
Training loss: 0.342454375966391
Validation loss: 2.3375069691877286

Epoch: 6| Step: 10
Training loss: 0.18111785395829183
Validation loss: 2.3636083384858217

Epoch: 6| Step: 11
Training loss: 0.2851356342127033
Validation loss: 2.351242938214176

Epoch: 6| Step: 12
Training loss: 0.18146382207668071
Validation loss: 2.3427335190674334

Epoch: 6| Step: 13
Training loss: 0.12530649874769673
Validation loss: 2.363643308869265

Epoch: 469| Step: 0
Training loss: 0.21261281076440297
Validation loss: 2.3824635186072105

Epoch: 6| Step: 1
Training loss: 0.2611566029156323
Validation loss: 2.368907995125721

Epoch: 6| Step: 2
Training loss: 0.24153468378996892
Validation loss: 2.3696198623044555

Epoch: 6| Step: 3
Training loss: 0.14545205347221934
Validation loss: 2.347194509174143

Epoch: 6| Step: 4
Training loss: 0.2521054893929498
Validation loss: 2.3233065479155344

Epoch: 6| Step: 5
Training loss: 0.19460096450573502
Validation loss: 2.326817345339526

Epoch: 6| Step: 6
Training loss: 0.13255507400851146
Validation loss: 2.3457953723769274

Epoch: 6| Step: 7
Training loss: 0.13504265217400377
Validation loss: 2.336416998304613

Epoch: 6| Step: 8
Training loss: 0.22377302946353086
Validation loss: 2.336861725300703

Epoch: 6| Step: 9
Training loss: 0.18958952015084504
Validation loss: 2.3529296341555046

Epoch: 6| Step: 10
Training loss: 0.30331715510309964
Validation loss: 2.3786577221906056

Epoch: 6| Step: 11
Training loss: 0.1808796601423414
Validation loss: 2.3490176003191556

Epoch: 6| Step: 12
Training loss: 0.1166604348700974
Validation loss: 2.375450583754089

Epoch: 6| Step: 13
Training loss: 0.3175983577350104
Validation loss: 2.3901616150809213

Epoch: 470| Step: 0
Training loss: 0.2850528947783917
Validation loss: 2.385017517637603

Epoch: 6| Step: 1
Training loss: 0.10787939263171421
Validation loss: 2.371537620255639

Epoch: 6| Step: 2
Training loss: 0.28995551244919715
Validation loss: 2.393859860160512

Epoch: 6| Step: 3
Training loss: 0.1831652530982107
Validation loss: 2.392648091669193

Epoch: 6| Step: 4
Training loss: 0.17037489124470945
Validation loss: 2.389000295713991

Epoch: 6| Step: 5
Training loss: 0.18299837159320823
Validation loss: 2.3884953103635533

Epoch: 6| Step: 6
Training loss: 0.10261786929319001
Validation loss: 2.3991975110914816

Epoch: 6| Step: 7
Training loss: 0.15896012076684893
Validation loss: 2.386668721979732

Epoch: 6| Step: 8
Training loss: 0.13392160630279848
Validation loss: 2.3711087635780843

Epoch: 6| Step: 9
Training loss: 0.3062670187211231
Validation loss: 2.4113589230677426

Epoch: 6| Step: 10
Training loss: 0.2176937676003078
Validation loss: 2.4110646900758197

Epoch: 6| Step: 11
Training loss: 0.12308418374369362
Validation loss: 2.375094046509018

Epoch: 6| Step: 12
Training loss: 0.17594571896457772
Validation loss: 2.3797120422640856

Epoch: 6| Step: 13
Training loss: 0.2537470538574343
Validation loss: 2.4021924704637905

Epoch: 471| Step: 0
Training loss: 0.19123326483914724
Validation loss: 2.4076400745459434

Epoch: 6| Step: 1
Training loss: 0.1362081598316444
Validation loss: 2.352239099678207

Epoch: 6| Step: 2
Training loss: 0.28401604099372285
Validation loss: 2.3797104715743496

Epoch: 6| Step: 3
Training loss: 0.1824793780119801
Validation loss: 2.368325983281309

Epoch: 6| Step: 4
Training loss: 0.19018133548094168
Validation loss: 2.3467074875696037

Epoch: 6| Step: 5
Training loss: 0.10898541993491365
Validation loss: 2.349041565255237

Epoch: 6| Step: 6
Training loss: 0.15484083840782506
Validation loss: 2.3279194515027357

Epoch: 6| Step: 7
Training loss: 0.11246597484133651
Validation loss: 2.321993354388058

Epoch: 6| Step: 8
Training loss: 0.30442392735385876
Validation loss: 2.3413036790142403

Epoch: 6| Step: 9
Training loss: 0.27413570635544826
Validation loss: 2.358510640925132

Epoch: 6| Step: 10
Training loss: 0.17076016963468563
Validation loss: 2.374516669748007

Epoch: 6| Step: 11
Training loss: 0.17442250161937067
Validation loss: 2.3690055992173082

Epoch: 6| Step: 12
Training loss: 0.17327878172022015
Validation loss: 2.38175042480344

Epoch: 6| Step: 13
Training loss: 0.3725370748362275
Validation loss: 2.377770918291339

Epoch: 472| Step: 0
Training loss: 0.2592641105076557
Validation loss: 2.385344628933918

Epoch: 6| Step: 1
Training loss: 0.34793074625997034
Validation loss: 2.3645583312224465

Epoch: 6| Step: 2
Training loss: 0.19027739083543896
Validation loss: 2.3614887965354145

Epoch: 6| Step: 3
Training loss: 0.16406257379621028
Validation loss: 2.381889382049052

Epoch: 6| Step: 4
Training loss: 0.0819127413207015
Validation loss: 2.3772143655525766

Epoch: 6| Step: 5
Training loss: 0.20660183115144898
Validation loss: 2.352923648145824

Epoch: 6| Step: 6
Training loss: 0.14962071109383485
Validation loss: 2.3775143367090554

Epoch: 6| Step: 7
Training loss: 0.19721899331237552
Validation loss: 2.380090839085998

Epoch: 6| Step: 8
Training loss: 0.23942472902481599
Validation loss: 2.375125487163801

Epoch: 6| Step: 9
Training loss: 0.19974269408614123
Validation loss: 2.3613261946647515

Epoch: 6| Step: 10
Training loss: 0.10843111954559749
Validation loss: 2.3653310240809544

Epoch: 6| Step: 11
Training loss: 0.1706703789682188
Validation loss: 2.350062685566578

Epoch: 6| Step: 12
Training loss: 0.10574483939299106
Validation loss: 2.369558581753579

Epoch: 6| Step: 13
Training loss: 0.07003756587487349
Validation loss: 2.3745669610784854

Epoch: 473| Step: 0
Training loss: 0.30201011899548974
Validation loss: 2.3686052704643905

Epoch: 6| Step: 1
Training loss: 0.1993350643114165
Validation loss: 2.3603919573751355

Epoch: 6| Step: 2
Training loss: 0.2343851087297562
Validation loss: 2.363887351775656

Epoch: 6| Step: 3
Training loss: 0.2772509728647677
Validation loss: 2.3711055199785984

Epoch: 6| Step: 4
Training loss: 0.14465953314593455
Validation loss: 2.3799883027055113

Epoch: 6| Step: 5
Training loss: 0.1129513903690597
Validation loss: 2.363782319216241

Epoch: 6| Step: 6
Training loss: 0.23935986891849392
Validation loss: 2.3769489898714427

Epoch: 6| Step: 7
Training loss: 0.1374101323439689
Validation loss: 2.3659584496061563

Epoch: 6| Step: 8
Training loss: 0.24041956454921068
Validation loss: 2.380457225165758

Epoch: 6| Step: 9
Training loss: 0.06914731346258059
Validation loss: 2.379789012870653

Epoch: 6| Step: 10
Training loss: 0.1344239284460966
Validation loss: 2.3721223408356313

Epoch: 6| Step: 11
Training loss: 0.18709421952575622
Validation loss: 2.365412140535349

Epoch: 6| Step: 12
Training loss: 0.1453381964307999
Validation loss: 2.3636846821929973

Epoch: 6| Step: 13
Training loss: 0.11973663850860278
Validation loss: 2.3669943300035077

Epoch: 474| Step: 0
Training loss: 0.1653401545755706
Validation loss: 2.3660703855356946

Epoch: 6| Step: 1
Training loss: 0.2370418694442706
Validation loss: 2.3835236196828378

Epoch: 6| Step: 2
Training loss: 0.24003512175190891
Validation loss: 2.38170625777382

Epoch: 6| Step: 3
Training loss: 0.24641466409399287
Validation loss: 2.4109280938668602

Epoch: 6| Step: 4
Training loss: 0.13411997503411527
Validation loss: 2.4098403932974706

Epoch: 6| Step: 5
Training loss: 0.13851104731991265
Validation loss: 2.388148515214858

Epoch: 6| Step: 6
Training loss: 0.1342576376586699
Validation loss: 2.425949263388901

Epoch: 6| Step: 7
Training loss: 0.10759514359611203
Validation loss: 2.395669565225765

Epoch: 6| Step: 8
Training loss: 0.2315540862903688
Validation loss: 2.405015372731439

Epoch: 6| Step: 9
Training loss: 0.17872121395727814
Validation loss: 2.4057630193453687

Epoch: 6| Step: 10
Training loss: 0.14586544889523662
Validation loss: 2.364019688769775

Epoch: 6| Step: 11
Training loss: 0.21356761976250385
Validation loss: 2.3604896100424804

Epoch: 6| Step: 12
Training loss: 0.21309220980495855
Validation loss: 2.376782148582446

Epoch: 6| Step: 13
Training loss: 0.0959709322717598
Validation loss: 2.359502507897178

Epoch: 475| Step: 0
Training loss: 0.12887218776690734
Validation loss: 2.343220327269051

Epoch: 6| Step: 1
Training loss: 0.13755946526176177
Validation loss: 2.3495849911433395

Epoch: 6| Step: 2
Training loss: 0.23338225240732452
Validation loss: 2.356825592559711

Epoch: 6| Step: 3
Training loss: 0.18153946633574528
Validation loss: 2.3337226321712534

Epoch: 6| Step: 4
Training loss: 0.19318860151753747
Validation loss: 2.3458285854405716

Epoch: 6| Step: 5
Training loss: 0.20720969912616272
Validation loss: 2.366296347365335

Epoch: 6| Step: 6
Training loss: 0.200022348258005
Validation loss: 2.353547224839309

Epoch: 6| Step: 7
Training loss: 0.1837247117637868
Validation loss: 2.3706825684914596

Epoch: 6| Step: 8
Training loss: 0.3285742817334281
Validation loss: 2.3599667789315486

Epoch: 6| Step: 9
Training loss: 0.14439060481896623
Validation loss: 2.363600956482159

Epoch: 6| Step: 10
Training loss: 0.17288037507175155
Validation loss: 2.370792693962638

Epoch: 6| Step: 11
Training loss: 0.1308647268538885
Validation loss: 2.376466204608228

Epoch: 6| Step: 12
Training loss: 0.17717924512576402
Validation loss: 2.3808087947541288

Epoch: 6| Step: 13
Training loss: 0.35391027856685453
Validation loss: 2.415067410538932

Epoch: 476| Step: 0
Training loss: 0.19117734806908024
Validation loss: 2.43150205224339

Epoch: 6| Step: 1
Training loss: 0.1625784556189809
Validation loss: 2.4291308468040227

Epoch: 6| Step: 2
Training loss: 0.20351428545842315
Validation loss: 2.4270624058375003

Epoch: 6| Step: 3
Training loss: 0.2241253571946276
Validation loss: 2.4116127143522292

Epoch: 6| Step: 4
Training loss: 0.29047295838704007
Validation loss: 2.35993563602854

Epoch: 6| Step: 5
Training loss: 0.31456125662982554
Validation loss: 2.3638497745660922

Epoch: 6| Step: 6
Training loss: 0.14093227062758312
Validation loss: 2.3583804588351898

Epoch: 6| Step: 7
Training loss: 0.21333389331202723
Validation loss: 2.337214979748991

Epoch: 6| Step: 8
Training loss: 0.28049359331107265
Validation loss: 2.3105463157925454

Epoch: 6| Step: 9
Training loss: 0.2050956082838932
Validation loss: 2.350569572405225

Epoch: 6| Step: 10
Training loss: 0.21728969954980631
Validation loss: 2.3631019073374384

Epoch: 6| Step: 11
Training loss: 0.10941186351806723
Validation loss: 2.3590757281650445

Epoch: 6| Step: 12
Training loss: 0.23562779183340107
Validation loss: 2.3547231016776

Epoch: 6| Step: 13
Training loss: 0.2148267392446688
Validation loss: 2.4002744013633066

Epoch: 477| Step: 0
Training loss: 0.26813935501511876
Validation loss: 2.3657251838871987

Epoch: 6| Step: 1
Training loss: 0.1351530132567639
Validation loss: 2.4021747579361654

Epoch: 6| Step: 2
Training loss: 0.15705931398505188
Validation loss: 2.356948961293122

Epoch: 6| Step: 3
Training loss: 0.17829894431901366
Validation loss: 2.363130644627814

Epoch: 6| Step: 4
Training loss: 0.24537973666999827
Validation loss: 2.3622515128700323

Epoch: 6| Step: 5
Training loss: 0.17691723078448968
Validation loss: 2.339558341989025

Epoch: 6| Step: 6
Training loss: 0.16980636441403374
Validation loss: 2.3028499362712314

Epoch: 6| Step: 7
Training loss: 0.20544050987157914
Validation loss: 2.3094509891489627

Epoch: 6| Step: 8
Training loss: 0.16710383603554305
Validation loss: 2.3284402047406343

Epoch: 6| Step: 9
Training loss: 0.26982957114655476
Validation loss: 2.3438363423731126

Epoch: 6| Step: 10
Training loss: 0.27820989191855533
Validation loss: 2.3100671783830227

Epoch: 6| Step: 11
Training loss: 0.21460279477546915
Validation loss: 2.3126391951227996

Epoch: 6| Step: 12
Training loss: 0.10965800286764874
Validation loss: 2.3431183869760774

Epoch: 6| Step: 13
Training loss: 0.19235743437553404
Validation loss: 2.338304076526985

Epoch: 478| Step: 0
Training loss: 0.19267082923368387
Validation loss: 2.332765330634417

Epoch: 6| Step: 1
Training loss: 0.19549246126588785
Validation loss: 2.3510801762109574

Epoch: 6| Step: 2
Training loss: 0.1986083234096355
Validation loss: 2.315901997954272

Epoch: 6| Step: 3
Training loss: 0.22380907699994854
Validation loss: 2.321575792765546

Epoch: 6| Step: 4
Training loss: 0.18864578595855078
Validation loss: 2.3127503197240737

Epoch: 6| Step: 5
Training loss: 0.29563685774460613
Validation loss: 2.3239347084919104

Epoch: 6| Step: 6
Training loss: 0.09987531018417851
Validation loss: 2.3258677676498984

Epoch: 6| Step: 7
Training loss: 0.24370536150929936
Validation loss: 2.358467593086007

Epoch: 6| Step: 8
Training loss: 0.19565265598661008
Validation loss: 2.3536443952270525

Epoch: 6| Step: 9
Training loss: 0.28231502585287166
Validation loss: 2.3687154492209053

Epoch: 6| Step: 10
Training loss: 0.1571808801948274
Validation loss: 2.364489660611697

Epoch: 6| Step: 11
Training loss: 0.1665650867812381
Validation loss: 2.374244598953165

Epoch: 6| Step: 12
Training loss: 0.287566696599009
Validation loss: 2.379973492714754

Epoch: 6| Step: 13
Training loss: 0.09859023260954834
Validation loss: 2.379838225160236

Epoch: 479| Step: 0
Training loss: 0.21165040310069483
Validation loss: 2.3948698309818135

Epoch: 6| Step: 1
Training loss: 0.15450408156722595
Validation loss: 2.4039247217014914

Epoch: 6| Step: 2
Training loss: 0.18748665801898856
Validation loss: 2.3989047343954555

Epoch: 6| Step: 3
Training loss: 0.25755362084331274
Validation loss: 2.3738099151327963

Epoch: 6| Step: 4
Training loss: 0.15428801402470171
Validation loss: 2.3714693863286436

Epoch: 6| Step: 5
Training loss: 0.22627240550817357
Validation loss: 2.352454029057912

Epoch: 6| Step: 6
Training loss: 0.12572055501398294
Validation loss: 2.3672985342052666

Epoch: 6| Step: 7
Training loss: 0.11332232454098887
Validation loss: 2.3410851711636957

Epoch: 6| Step: 8
Training loss: 0.17847115945767614
Validation loss: 2.323560550344584

Epoch: 6| Step: 9
Training loss: 0.23720509986515187
Validation loss: 2.3572657696639534

Epoch: 6| Step: 10
Training loss: 0.16901607905592528
Validation loss: 2.31133330407756

Epoch: 6| Step: 11
Training loss: 0.3116506000107256
Validation loss: 2.3269126209095328

Epoch: 6| Step: 12
Training loss: 0.14083043298847883
Validation loss: 2.3352053365249525

Epoch: 6| Step: 13
Training loss: 0.2141450531344083
Validation loss: 2.346859052924045

Epoch: 480| Step: 0
Training loss: 0.27620614148134087
Validation loss: 2.3516552315774786

Epoch: 6| Step: 1
Training loss: 0.10178766599794101
Validation loss: 2.367388180389642

Epoch: 6| Step: 2
Training loss: 0.161867737211322
Validation loss: 2.3719401312880466

Epoch: 6| Step: 3
Training loss: 0.24427329464114997
Validation loss: 2.3516705245997014

Epoch: 6| Step: 4
Training loss: 0.2695412841255971
Validation loss: 2.3240886273681274

Epoch: 6| Step: 5
Training loss: 0.12474278719324204
Validation loss: 2.3275427796750168

Epoch: 6| Step: 6
Training loss: 0.177467376202564
Validation loss: 2.3538387675337447

Epoch: 6| Step: 7
Training loss: 0.14698239544508393
Validation loss: 2.3211095203494536

Epoch: 6| Step: 8
Training loss: 0.18850217655048448
Validation loss: 2.3306746373294533

Epoch: 6| Step: 9
Training loss: 0.12538181790947314
Validation loss: 2.336417094862878

Epoch: 6| Step: 10
Training loss: 0.13946383619445357
Validation loss: 2.327416061460323

Epoch: 6| Step: 11
Training loss: 0.21055426044993342
Validation loss: 2.322666514159077

Epoch: 6| Step: 12
Training loss: 0.24651934138415862
Validation loss: 2.346884635565897

Epoch: 6| Step: 13
Training loss: 0.15697276914829106
Validation loss: 2.3399103785764948

Epoch: 481| Step: 0
Training loss: 0.11321669004973808
Validation loss: 2.3402753805012306

Epoch: 6| Step: 1
Training loss: 0.2714187625115602
Validation loss: 2.3681140636176545

Epoch: 6| Step: 2
Training loss: 0.1636863722560264
Validation loss: 2.374759226858359

Epoch: 6| Step: 3
Training loss: 0.2804470122900296
Validation loss: 2.385212401364642

Epoch: 6| Step: 4
Training loss: 0.16365151927433919
Validation loss: 2.36532946009916

Epoch: 6| Step: 5
Training loss: 0.08151315669501011
Validation loss: 2.367897958354644

Epoch: 6| Step: 6
Training loss: 0.1408040707939852
Validation loss: 2.3835212749444477

Epoch: 6| Step: 7
Training loss: 0.0940746557026543
Validation loss: 2.352779153411

Epoch: 6| Step: 8
Training loss: 0.2683665639700113
Validation loss: 2.373279997914302

Epoch: 6| Step: 9
Training loss: 0.10743797788436044
Validation loss: 2.364850717091975

Epoch: 6| Step: 10
Training loss: 0.26660138084768736
Validation loss: 2.373648735657728

Epoch: 6| Step: 11
Training loss: 0.20494978385633772
Validation loss: 2.348273845463435

Epoch: 6| Step: 12
Training loss: 0.0983368332372686
Validation loss: 2.3341523050204387

Epoch: 6| Step: 13
Training loss: 0.15930430676989707
Validation loss: 2.3762352179698603

Epoch: 482| Step: 0
Training loss: 0.15718141938387395
Validation loss: 2.384681201026432

Epoch: 6| Step: 1
Training loss: 0.3418412533968893
Validation loss: 2.3522946846971204

Epoch: 6| Step: 2
Training loss: 0.10304938889532358
Validation loss: 2.341121462708198

Epoch: 6| Step: 3
Training loss: 0.15387940366294345
Validation loss: 2.3713010578506584

Epoch: 6| Step: 4
Training loss: 0.16704009857862676
Validation loss: 2.36153949693404

Epoch: 6| Step: 5
Training loss: 0.23514878175605652
Validation loss: 2.361432530661193

Epoch: 6| Step: 6
Training loss: 0.13992399758284352
Validation loss: 2.400191894331859

Epoch: 6| Step: 7
Training loss: 0.10609195398712225
Validation loss: 2.3876747104790983

Epoch: 6| Step: 8
Training loss: 0.17900359574627622
Validation loss: 2.3917139296999546

Epoch: 6| Step: 9
Training loss: 0.17600767070238463
Validation loss: 2.3797588996204784

Epoch: 6| Step: 10
Training loss: 0.23160742060162207
Validation loss: 2.349620445741675

Epoch: 6| Step: 11
Training loss: 0.09498652936773584
Validation loss: 2.3303460412199626

Epoch: 6| Step: 12
Training loss: 0.1466941094959407
Validation loss: 2.3634266117673515

Epoch: 6| Step: 13
Training loss: 0.1763739659558216
Validation loss: 2.318043972893572

Epoch: 483| Step: 0
Training loss: 0.13219916145705127
Validation loss: 2.299281774844157

Epoch: 6| Step: 1
Training loss: 0.23278841399723296
Validation loss: 2.3206427416384487

Epoch: 6| Step: 2
Training loss: 0.21801966274243087
Validation loss: 2.329308810568952

Epoch: 6| Step: 3
Training loss: 0.14807900631159213
Validation loss: 2.3159685797536453

Epoch: 6| Step: 4
Training loss: 0.15251177300676283
Validation loss: 2.33736076789196

Epoch: 6| Step: 5
Training loss: 0.23304093086368188
Validation loss: 2.3345293423888465

Epoch: 6| Step: 6
Training loss: 0.2010014747475379
Validation loss: 2.3024705850575167

Epoch: 6| Step: 7
Training loss: 0.2601647143662356
Validation loss: 2.324754356369199

Epoch: 6| Step: 8
Training loss: 0.1511798930444464
Validation loss: 2.341124834085143

Epoch: 6| Step: 9
Training loss: 0.11703502351638684
Validation loss: 2.309950324534195

Epoch: 6| Step: 10
Training loss: 0.10675406518159615
Validation loss: 2.3211393027124294

Epoch: 6| Step: 11
Training loss: 0.1555058700969154
Validation loss: 2.3138746251760107

Epoch: 6| Step: 12
Training loss: 0.16481201648351912
Validation loss: 2.3087405204324054

Epoch: 6| Step: 13
Training loss: 0.11199115441347786
Validation loss: 2.3073665158888392

Epoch: 484| Step: 0
Training loss: 0.24910631483646486
Validation loss: 2.3051213415956417

Epoch: 6| Step: 1
Training loss: 0.10513132478702145
Validation loss: 2.325461995974232

Epoch: 6| Step: 2
Training loss: 0.2720425582717663
Validation loss: 2.311313711775561

Epoch: 6| Step: 3
Training loss: 0.1494325863195087
Validation loss: 2.3235378868512213

Epoch: 6| Step: 4
Training loss: 0.2846297537800782
Validation loss: 2.3415965999440496

Epoch: 6| Step: 5
Training loss: 0.2363697362159367
Validation loss: 2.3284269782457634

Epoch: 6| Step: 6
Training loss: 0.09565048813843638
Validation loss: 2.340587835045447

Epoch: 6| Step: 7
Training loss: 0.14625492563470882
Validation loss: 2.3180519202363494

Epoch: 6| Step: 8
Training loss: 0.12325071299305096
Validation loss: 2.3022294713377205

Epoch: 6| Step: 9
Training loss: 0.10750242594404627
Validation loss: 2.307688970786223

Epoch: 6| Step: 10
Training loss: 0.18512175194352684
Validation loss: 2.3076151789067585

Epoch: 6| Step: 11
Training loss: 0.11249267766223012
Validation loss: 2.328126670460757

Epoch: 6| Step: 12
Training loss: 0.12237134056006752
Validation loss: 2.3290008716467057

Epoch: 6| Step: 13
Training loss: 0.2191382691907817
Validation loss: 2.323580877901125

Epoch: 485| Step: 0
Training loss: 0.19099861646570548
Validation loss: 2.3837660015618845

Epoch: 6| Step: 1
Training loss: 0.1376584862777455
Validation loss: 2.359541506488787

Epoch: 6| Step: 2
Training loss: 0.1309912145549711
Validation loss: 2.3543161302476756

Epoch: 6| Step: 3
Training loss: 0.20121185127751393
Validation loss: 2.349424741839896

Epoch: 6| Step: 4
Training loss: 0.37286943939339123
Validation loss: 2.342993095440051

Epoch: 6| Step: 5
Training loss: 0.09528007718012202
Validation loss: 2.322398464858188

Epoch: 6| Step: 6
Training loss: 0.15631267959343417
Validation loss: 2.318682338845308

Epoch: 6| Step: 7
Training loss: 0.15888307000995766
Validation loss: 2.3045905803186972

Epoch: 6| Step: 8
Training loss: 0.10190387811652409
Validation loss: 2.3005065703863963

Epoch: 6| Step: 9
Training loss: 0.08323209419441104
Validation loss: 2.335475052609438

Epoch: 6| Step: 10
Training loss: 0.20407401816208903
Validation loss: 2.3466281099743376

Epoch: 6| Step: 11
Training loss: 0.14944958108826994
Validation loss: 2.300473738261355

Epoch: 6| Step: 12
Training loss: 0.24401398998454565
Validation loss: 2.3440564464548435

Epoch: 6| Step: 13
Training loss: 0.10635337008564955
Validation loss: 2.3400895595301194

Epoch: 486| Step: 0
Training loss: 0.2489619459637618
Validation loss: 2.3440258856390543

Epoch: 6| Step: 1
Training loss: 0.1757960737123843
Validation loss: 2.3797882787209645

Epoch: 6| Step: 2
Training loss: 0.16852001173864728
Validation loss: 2.3567718300992637

Epoch: 6| Step: 3
Training loss: 0.11802024601551435
Validation loss: 2.3702815819989174

Epoch: 6| Step: 4
Training loss: 0.299063608472438
Validation loss: 2.3696913971907794

Epoch: 6| Step: 5
Training loss: 0.12325012359820894
Validation loss: 2.383197394932485

Epoch: 6| Step: 6
Training loss: 0.2442208577880887
Validation loss: 2.386709666085059

Epoch: 6| Step: 7
Training loss: 0.27438454791685374
Validation loss: 2.3686191590344277

Epoch: 6| Step: 8
Training loss: 0.1491000422299528
Validation loss: 2.3531961138291284

Epoch: 6| Step: 9
Training loss: 0.17106554852780795
Validation loss: 2.362667493888494

Epoch: 6| Step: 10
Training loss: 0.1482135438449106
Validation loss: 2.3591658932764887

Epoch: 6| Step: 11
Training loss: 0.11062537883569755
Validation loss: 2.351171738311567

Epoch: 6| Step: 12
Training loss: 0.10682637138707254
Validation loss: 2.366006237047709

Epoch: 6| Step: 13
Training loss: 0.08210265083528165
Validation loss: 2.3428995176769516

Epoch: 487| Step: 0
Training loss: 0.16344919693484955
Validation loss: 2.3631037233965606

Epoch: 6| Step: 1
Training loss: 0.26250422451616295
Validation loss: 2.3562073403725274

Epoch: 6| Step: 2
Training loss: 0.31895775522511466
Validation loss: 2.3549659113509844

Epoch: 6| Step: 3
Training loss: 0.12253885756169342
Validation loss: 2.355811498866166

Epoch: 6| Step: 4
Training loss: 0.16601091827003553
Validation loss: 2.343331139986113

Epoch: 6| Step: 5
Training loss: 0.20379651467501225
Validation loss: 2.3479298657783687

Epoch: 6| Step: 6
Training loss: 0.13192140140288042
Validation loss: 2.360315777072321

Epoch: 6| Step: 7
Training loss: 0.17837588895056278
Validation loss: 2.34547176874715

Epoch: 6| Step: 8
Training loss: 0.1641549292826613
Validation loss: 2.3657197319898327

Epoch: 6| Step: 9
Training loss: 0.1790760666932222
Validation loss: 2.3421310263993234

Epoch: 6| Step: 10
Training loss: 0.19333158158428115
Validation loss: 2.3639519286515718

Epoch: 6| Step: 11
Training loss: 0.09895173059152952
Validation loss: 2.362016600339678

Epoch: 6| Step: 12
Training loss: 0.1130073582362866
Validation loss: 2.3538625224673972

Epoch: 6| Step: 13
Training loss: 0.21349753043881628
Validation loss: 2.367626851597279

Epoch: 488| Step: 0
Training loss: 0.18578693520755846
Validation loss: 2.384759578075847

Epoch: 6| Step: 1
Training loss: 0.11922846745150968
Validation loss: 2.3773656299370827

Epoch: 6| Step: 2
Training loss: 0.2679667191942852
Validation loss: 2.407117814189348

Epoch: 6| Step: 3
Training loss: 0.1280319300338566
Validation loss: 2.37204666641635

Epoch: 6| Step: 4
Training loss: 0.09441349068035658
Validation loss: 2.4021193185987846

Epoch: 6| Step: 5
Training loss: 0.24134367406464305
Validation loss: 2.3883937959951074

Epoch: 6| Step: 6
Training loss: 0.2491840293519159
Validation loss: 2.3618531328084544

Epoch: 6| Step: 7
Training loss: 0.13122486912731185
Validation loss: 2.3567948734405966

Epoch: 6| Step: 8
Training loss: 0.06654277959359495
Validation loss: 2.3230663817660004

Epoch: 6| Step: 9
Training loss: 0.0854205764722748
Validation loss: 2.337720400123769

Epoch: 6| Step: 10
Training loss: 0.16785628412684328
Validation loss: 2.310221994830379

Epoch: 6| Step: 11
Training loss: 0.22132721998714397
Validation loss: 2.327863673202472

Epoch: 6| Step: 12
Training loss: 0.16648721471447434
Validation loss: 2.3104067360418896

Epoch: 6| Step: 13
Training loss: 0.21929143418485725
Validation loss: 2.3070070146736663

Epoch: 489| Step: 0
Training loss: 0.1692472747156491
Validation loss: 2.352560910465568

Epoch: 6| Step: 1
Training loss: 0.2050955628746967
Validation loss: 2.342978481615035

Epoch: 6| Step: 2
Training loss: 0.17016817745548576
Validation loss: 2.3591942943772883

Epoch: 6| Step: 3
Training loss: 0.1442880582052103
Validation loss: 2.356068554996798

Epoch: 6| Step: 4
Training loss: 0.20125127355101516
Validation loss: 2.3596780852999144

Epoch: 6| Step: 5
Training loss: 0.15451516030058762
Validation loss: 2.3790025343862213

Epoch: 6| Step: 6
Training loss: 0.23927978103364148
Validation loss: 2.4079004193664315

Epoch: 6| Step: 7
Training loss: 0.08832505730086702
Validation loss: 2.3839636410722207

Epoch: 6| Step: 8
Training loss: 0.14465557370261595
Validation loss: 2.403019546069809

Epoch: 6| Step: 9
Training loss: 0.08035018111150967
Validation loss: 2.3851003555799464

Epoch: 6| Step: 10
Training loss: 0.2307327423435762
Validation loss: 2.3939917889382762

Epoch: 6| Step: 11
Training loss: 0.28363232153264367
Validation loss: 2.3784989832563324

Epoch: 6| Step: 12
Training loss: 0.1896094139642915
Validation loss: 2.368322970225548

Epoch: 6| Step: 13
Training loss: 0.3157952260355653
Validation loss: 2.3733016581851025

Epoch: 490| Step: 0
Training loss: 0.16346051263810965
Validation loss: 2.3589632951414097

Epoch: 6| Step: 1
Training loss: 0.22932765825544707
Validation loss: 2.3321786263207716

Epoch: 6| Step: 2
Training loss: 0.14819248582560507
Validation loss: 2.3603090446048705

Epoch: 6| Step: 3
Training loss: 0.17928462890491592
Validation loss: 2.3535100958014623

Epoch: 6| Step: 4
Training loss: 0.21623244139879552
Validation loss: 2.3747798826309667

Epoch: 6| Step: 5
Training loss: 0.20511032941544893
Validation loss: 2.3692596353985143

Epoch: 6| Step: 6
Training loss: 0.2187595450498665
Validation loss: 2.3899239837939326

Epoch: 6| Step: 7
Training loss: 0.2409206605164785
Validation loss: 2.395272244260042

Epoch: 6| Step: 8
Training loss: 0.10071968704471852
Validation loss: 2.351503618314206

Epoch: 6| Step: 9
Training loss: 0.2478986507502735
Validation loss: 2.3819347199103245

Epoch: 6| Step: 10
Training loss: 0.12655102065502596
Validation loss: 2.3579271026298567

Epoch: 6| Step: 11
Training loss: 0.22129069241010182
Validation loss: 2.3503663952549863

Epoch: 6| Step: 12
Training loss: 0.2126692925012549
Validation loss: 2.351760732711449

Epoch: 6| Step: 13
Training loss: 0.12932391849067817
Validation loss: 2.3029732807284677

Epoch: 491| Step: 0
Training loss: 0.11091475958866072
Validation loss: 2.3413994556488977

Epoch: 6| Step: 1
Training loss: 0.2587353056729599
Validation loss: 2.334790811412094

Epoch: 6| Step: 2
Training loss: 0.0979255967261525
Validation loss: 2.329370196355804

Epoch: 6| Step: 3
Training loss: 0.12608195487235568
Validation loss: 2.353672949001674

Epoch: 6| Step: 4
Training loss: 0.07406777473269063
Validation loss: 2.3399678286288474

Epoch: 6| Step: 5
Training loss: 0.23125002867466518
Validation loss: 2.336428543572491

Epoch: 6| Step: 6
Training loss: 0.252185492596206
Validation loss: 2.3398035953222145

Epoch: 6| Step: 7
Training loss: 0.20560521101588927
Validation loss: 2.3522176334521063

Epoch: 6| Step: 8
Training loss: 0.19599747707180987
Validation loss: 2.355302600227945

Epoch: 6| Step: 9
Training loss: 0.17869232164157434
Validation loss: 2.383764233507988

Epoch: 6| Step: 10
Training loss: 0.2251751780710737
Validation loss: 2.4134862514473316

Epoch: 6| Step: 11
Training loss: 0.20682933245694965
Validation loss: 2.4047351069676814

Epoch: 6| Step: 12
Training loss: 0.19420568615593958
Validation loss: 2.412383603380352

Epoch: 6| Step: 13
Training loss: 0.0636123964495874
Validation loss: 2.3946777988386296

Epoch: 492| Step: 0
Training loss: 0.14832541349740117
Validation loss: 2.3843081724743884

Epoch: 6| Step: 1
Training loss: 0.19552810213061755
Validation loss: 2.4154684638092916

Epoch: 6| Step: 2
Training loss: 0.18170009172843504
Validation loss: 2.378942814020326

Epoch: 6| Step: 3
Training loss: 0.11673028285079373
Validation loss: 2.3886784132263426

Epoch: 6| Step: 4
Training loss: 0.2972772909273931
Validation loss: 2.3912406974098515

Epoch: 6| Step: 5
Training loss: 0.21705617090098722
Validation loss: 2.3931790560338158

Epoch: 6| Step: 6
Training loss: 0.17556537512016945
Validation loss: 2.4152119968144463

Epoch: 6| Step: 7
Training loss: 0.17236412415555008
Validation loss: 2.393860969636939

Epoch: 6| Step: 8
Training loss: 0.168756611129393
Validation loss: 2.3767266627326595

Epoch: 6| Step: 9
Training loss: 0.23870858192686148
Validation loss: 2.373377357399288

Epoch: 6| Step: 10
Training loss: 0.18123390438697215
Validation loss: 2.34861335124662

Epoch: 6| Step: 11
Training loss: 0.11970757214036093
Validation loss: 2.3636743004266654

Epoch: 6| Step: 12
Training loss: 0.19254761622492933
Validation loss: 2.3627505338490415

Epoch: 6| Step: 13
Training loss: 0.13618904085456193
Validation loss: 2.366447099827032

Epoch: 493| Step: 0
Training loss: 0.12471530202803564
Validation loss: 2.3408998328219184

Epoch: 6| Step: 1
Training loss: 0.1379459345822389
Validation loss: 2.391836730189052

Epoch: 6| Step: 2
Training loss: 0.08829788582958513
Validation loss: 2.3664036124370225

Epoch: 6| Step: 3
Training loss: 0.21830377024296882
Validation loss: 2.3572245539378347

Epoch: 6| Step: 4
Training loss: 0.27968166760804725
Validation loss: 2.3437856713865304

Epoch: 6| Step: 5
Training loss: 0.18627432720309595
Validation loss: 2.3277272530699693

Epoch: 6| Step: 6
Training loss: 0.17083400601646134
Validation loss: 2.354935629277806

Epoch: 6| Step: 7
Training loss: 0.15616028117224423
Validation loss: 2.3511897947237017

Epoch: 6| Step: 8
Training loss: 0.15447844915637093
Validation loss: 2.3712038893499856

Epoch: 6| Step: 9
Training loss: 0.24193419007018196
Validation loss: 2.3491388161591042

Epoch: 6| Step: 10
Training loss: 0.21983651694929723
Validation loss: 2.3603710624650334

Epoch: 6| Step: 11
Training loss: 0.07915873874738259
Validation loss: 2.3543014930610617

Epoch: 6| Step: 12
Training loss: 0.11511039125504717
Validation loss: 2.374087206844739

Epoch: 6| Step: 13
Training loss: 0.11328575519942602
Validation loss: 2.3851486096998165

Epoch: 494| Step: 0
Training loss: 0.20669895171020525
Validation loss: 2.367303926153938

Epoch: 6| Step: 1
Training loss: 0.1717839379099448
Validation loss: 2.3891876208327165

Epoch: 6| Step: 2
Training loss: 0.11005913125882567
Validation loss: 2.4063933220210583

Epoch: 6| Step: 3
Training loss: 0.2659367667119712
Validation loss: 2.3416134957839962

Epoch: 6| Step: 4
Training loss: 0.14168527693617786
Validation loss: 2.399314750670111

Epoch: 6| Step: 5
Training loss: 0.1509736266843881
Validation loss: 2.3924904127787503

Epoch: 6| Step: 6
Training loss: 0.18461969512234694
Validation loss: 2.3905843856892863

Epoch: 6| Step: 7
Training loss: 0.22152200207676553
Validation loss: 2.3717670613530832

Epoch: 6| Step: 8
Training loss: 0.13844977982051682
Validation loss: 2.3819335704376554

Epoch: 6| Step: 9
Training loss: 0.15464091273744812
Validation loss: 2.4026391854228795

Epoch: 6| Step: 10
Training loss: 0.1319659616224085
Validation loss: 2.3894760209301973

Epoch: 6| Step: 11
Training loss: 0.08362443997854191
Validation loss: 2.3918287847054174

Epoch: 6| Step: 12
Training loss: 0.21245608472042507
Validation loss: 2.382569515400903

Epoch: 6| Step: 13
Training loss: 0.13186741205957173
Validation loss: 2.3699670095031045

Epoch: 495| Step: 0
Training loss: 0.11589413022560781
Validation loss: 2.3256916544293245

Epoch: 6| Step: 1
Training loss: 0.21200347807062211
Validation loss: 2.33998011232908

Epoch: 6| Step: 2
Training loss: 0.12443960756982005
Validation loss: 2.3388279751627676

Epoch: 6| Step: 3
Training loss: 0.14831204508620438
Validation loss: 2.334183369080513

Epoch: 6| Step: 4
Training loss: 0.16517743962684445
Validation loss: 2.3312804905024307

Epoch: 6| Step: 5
Training loss: 0.11647364630308595
Validation loss: 2.3279122966165158

Epoch: 6| Step: 6
Training loss: 0.2644332066843119
Validation loss: 2.3297857995409665

Epoch: 6| Step: 7
Training loss: 0.20162708667117601
Validation loss: 2.39093936464743

Epoch: 6| Step: 8
Training loss: 0.2699406596601885
Validation loss: 2.382608708314899

Epoch: 6| Step: 9
Training loss: 0.2083114056173626
Validation loss: 2.339400587670915

Epoch: 6| Step: 10
Training loss: 0.15619636449544005
Validation loss: 2.386756013346026

Epoch: 6| Step: 11
Training loss: 0.09862055088537014
Validation loss: 2.359910270366175

Epoch: 6| Step: 12
Training loss: 0.16572490369164117
Validation loss: 2.323448119437951

Epoch: 6| Step: 13
Training loss: 0.09300874683178383
Validation loss: 2.3292081627950383

Epoch: 496| Step: 0
Training loss: 0.27645169101852657
Validation loss: 2.341356048313508

Epoch: 6| Step: 1
Training loss: 0.22037433507270487
Validation loss: 2.342000191895276

Epoch: 6| Step: 2
Training loss: 0.13731886083778913
Validation loss: 2.3514328842082524

Epoch: 6| Step: 3
Training loss: 0.11678658491116244
Validation loss: 2.3538026527355926

Epoch: 6| Step: 4
Training loss: 0.12558344190381265
Validation loss: 2.363449491788596

Epoch: 6| Step: 5
Training loss: 0.12953638901771988
Validation loss: 2.3599328887286384

Epoch: 6| Step: 6
Training loss: 0.24134642159014272
Validation loss: 2.3645378680509164

Epoch: 6| Step: 7
Training loss: 0.1607131579526055
Validation loss: 2.380488121670899

Epoch: 6| Step: 8
Training loss: 0.15601523166734896
Validation loss: 2.3606230470413494

Epoch: 6| Step: 9
Training loss: 0.30906571138755873
Validation loss: 2.346103909216482

Epoch: 6| Step: 10
Training loss: 0.16089650946876838
Validation loss: 2.318476963842434

Epoch: 6| Step: 11
Training loss: 0.08651295269026571
Validation loss: 2.337190938792939

Epoch: 6| Step: 12
Training loss: 0.24683426146640786
Validation loss: 2.3311820734039426

Epoch: 6| Step: 13
Training loss: 0.1719245243248011
Validation loss: 2.340615026749928

Epoch: 497| Step: 0
Training loss: 0.2550618065700999
Validation loss: 2.3356179451506267

Epoch: 6| Step: 1
Training loss: 0.23493953109476193
Validation loss: 2.3185922535246064

Epoch: 6| Step: 2
Training loss: 0.13811475703937737
Validation loss: 2.287042136307473

Epoch: 6| Step: 3
Training loss: 0.1914570021003653
Validation loss: 2.3161223957241934

Epoch: 6| Step: 4
Training loss: 0.10593499336821782
Validation loss: 2.3002223957288144

Epoch: 6| Step: 5
Training loss: 0.1143485385609359
Validation loss: 2.335207359810687

Epoch: 6| Step: 6
Training loss: 0.20258093376286807
Validation loss: 2.3394072608621017

Epoch: 6| Step: 7
Training loss: 0.20647340870262626
Validation loss: 2.359514309076891

Epoch: 6| Step: 8
Training loss: 0.1877236820180777
Validation loss: 2.3380163862453704

Epoch: 6| Step: 9
Training loss: 0.16851394908038062
Validation loss: 2.335003530489945

Epoch: 6| Step: 10
Training loss: 0.27408432070033406
Validation loss: 2.3444961284486454

Epoch: 6| Step: 11
Training loss: 0.12521076315343274
Validation loss: 2.349318183707517

Epoch: 6| Step: 12
Training loss: 0.19729719759134615
Validation loss: 2.348350194249273

Epoch: 6| Step: 13
Training loss: 0.16972161144238868
Validation loss: 2.3368111510151572

Epoch: 498| Step: 0
Training loss: 0.14879352763179338
Validation loss: 2.351640609443126

Epoch: 6| Step: 1
Training loss: 0.17029383933353073
Validation loss: 2.3732935734138505

Epoch: 6| Step: 2
Training loss: 0.1811755903191238
Validation loss: 2.3458481779878126

Epoch: 6| Step: 3
Training loss: 0.19258277686267164
Validation loss: 2.3763078252520984

Epoch: 6| Step: 4
Training loss: 0.1363462140999243
Validation loss: 2.380056296173343

Epoch: 6| Step: 5
Training loss: 0.16690568747155138
Validation loss: 2.3807972574168152

Epoch: 6| Step: 6
Training loss: 0.1677219995909189
Validation loss: 2.386254036056607

Epoch: 6| Step: 7
Training loss: 0.19669583622722217
Validation loss: 2.3725861916204267

Epoch: 6| Step: 8
Training loss: 0.21390070717863216
Validation loss: 2.380563490057763

Epoch: 6| Step: 9
Training loss: 0.13031503279257703
Validation loss: 2.375866652492199

Epoch: 6| Step: 10
Training loss: 0.23176798479422808
Validation loss: 2.335115049868612

Epoch: 6| Step: 11
Training loss: 0.14361107944775733
Validation loss: 2.373096344317109

Epoch: 6| Step: 12
Training loss: 0.231323773627564
Validation loss: 2.3583833136574976

Epoch: 6| Step: 13
Training loss: 0.10241813795428639
Validation loss: 2.3277564711311927

Epoch: 499| Step: 0
Training loss: 0.12072818705786979
Validation loss: 2.3374530966299982

Epoch: 6| Step: 1
Training loss: 0.1845847331070047
Validation loss: 2.344982361930418

Epoch: 6| Step: 2
Training loss: 0.1492325172264748
Validation loss: 2.350244599430782

Epoch: 6| Step: 3
Training loss: 0.21685617512235134
Validation loss: 2.353377417283637

Epoch: 6| Step: 4
Training loss: 0.14388720609008396
Validation loss: 2.324145648399912

Epoch: 6| Step: 5
Training loss: 0.19128258271758786
Validation loss: 2.3426650546197685

Epoch: 6| Step: 6
Training loss: 0.10857174739642943
Validation loss: 2.3173840360293103

Epoch: 6| Step: 7
Training loss: 0.1221775575651326
Validation loss: 2.319634590268351

Epoch: 6| Step: 8
Training loss: 0.22125581725603458
Validation loss: 2.3393877557375946

Epoch: 6| Step: 9
Training loss: 0.1249846732160709
Validation loss: 2.3832332191921863

Epoch: 6| Step: 10
Training loss: 0.2118466177640892
Validation loss: 2.3549503202196878

Epoch: 6| Step: 11
Training loss: 0.16152167936242337
Validation loss: 2.3750832105393487

Epoch: 6| Step: 12
Training loss: 0.15066213992778504
Validation loss: 2.3332188493210286

Epoch: 6| Step: 13
Training loss: 0.27605268018572193
Validation loss: 2.347761302417999

Epoch: 500| Step: 0
Training loss: 0.12944902676004308
Validation loss: 2.342531307678962

Epoch: 6| Step: 1
Training loss: 0.15445289690910635
Validation loss: 2.3356906114121583

Epoch: 6| Step: 2
Training loss: 0.0937843408869704
Validation loss: 2.3487102902451715

Epoch: 6| Step: 3
Training loss: 0.2508740642551064
Validation loss: 2.3330114612499218

Epoch: 6| Step: 4
Training loss: 0.3005809116748937
Validation loss: 2.345678464466127

Epoch: 6| Step: 5
Training loss: 0.08921731368142992
Validation loss: 2.3440186060186923

Epoch: 6| Step: 6
Training loss: 0.16681366574647238
Validation loss: 2.320565679001479

Epoch: 6| Step: 7
Training loss: 0.07938065565978665
Validation loss: 2.333208701178942

Epoch: 6| Step: 8
Training loss: 0.19511992497476044
Validation loss: 2.3031280330555006

Epoch: 6| Step: 9
Training loss: 0.1984647431783759
Validation loss: 2.29953957483917

Epoch: 6| Step: 10
Training loss: 0.19842657900217187
Validation loss: 2.365472503795665

Epoch: 6| Step: 11
Training loss: 0.1459987984601314
Validation loss: 2.3241723734074724

Epoch: 6| Step: 12
Training loss: 0.14837541034532478
Validation loss: 2.34583256778549

Epoch: 6| Step: 13
Training loss: 0.24466964626094992
Validation loss: 2.3492884693944625

Epoch: 501| Step: 0
Training loss: 0.24389657601936154
Validation loss: 2.3319562699067653

Epoch: 6| Step: 1
Training loss: 0.14080936214711356
Validation loss: 2.3461111577802893

Epoch: 6| Step: 2
Training loss: 0.1582063392030076
Validation loss: 2.3546883635442426

Epoch: 6| Step: 3
Training loss: 0.29597658441046837
Validation loss: 2.354759948122422

Epoch: 6| Step: 4
Training loss: 0.14145284933402344
Validation loss: 2.3672422943330997

Epoch: 6| Step: 5
Training loss: 0.1859766950889264
Validation loss: 2.4039670061948915

Epoch: 6| Step: 6
Training loss: 0.0855184220327601
Validation loss: 2.4076984128360333

Epoch: 6| Step: 7
Training loss: 0.17730159258447248
Validation loss: 2.4256694706453006

Epoch: 6| Step: 8
Training loss: 0.2949053652354861
Validation loss: 2.3744258197340087

Epoch: 6| Step: 9
Training loss: 0.26604343162544636
Validation loss: 2.3390458322664496

Epoch: 6| Step: 10
Training loss: 0.17008543364171744
Validation loss: 2.3339795750016723

Epoch: 6| Step: 11
Training loss: 0.14052920257420562
Validation loss: 2.320606921645207

Epoch: 6| Step: 12
Training loss: 0.24103535118555716
Validation loss: 2.279346597434272

Epoch: 6| Step: 13
Training loss: 0.07188349290096036
Validation loss: 2.299156545298538

Epoch: 502| Step: 0
Training loss: 0.27954830509992906
Validation loss: 2.299096882332308

Epoch: 6| Step: 1
Training loss: 0.16900684360749618
Validation loss: 2.2966030976438727

Epoch: 6| Step: 2
Training loss: 0.1133273869317789
Validation loss: 2.301917962225229

Epoch: 6| Step: 3
Training loss: 0.30544385198799184
Validation loss: 2.285208115551357

Epoch: 6| Step: 4
Training loss: 0.2875958168994264
Validation loss: 2.3192904702497277

Epoch: 6| Step: 5
Training loss: 0.17752312063020922
Validation loss: 2.3899571124328225

Epoch: 6| Step: 6
Training loss: 0.1653584938480013
Validation loss: 2.400439544688953

Epoch: 6| Step: 7
Training loss: 0.2599095684287782
Validation loss: 2.401106313405896

Epoch: 6| Step: 8
Training loss: 0.20603571257523823
Validation loss: 2.399055084254797

Epoch: 6| Step: 9
Training loss: 0.15309793904637806
Validation loss: 2.4157126129053457

Epoch: 6| Step: 10
Training loss: 0.14957646662877555
Validation loss: 2.3857929129865743

Epoch: 6| Step: 11
Training loss: 0.14186634432230505
Validation loss: 2.3705724616961397

Epoch: 6| Step: 12
Training loss: 0.14689091535331986
Validation loss: 2.341000198046196

Epoch: 6| Step: 13
Training loss: 0.20559876067281108
Validation loss: 2.346826651885854

Epoch: 503| Step: 0
Training loss: 0.18063984270390854
Validation loss: 2.2989179343249497

Epoch: 6| Step: 1
Training loss: 0.16267020522944198
Validation loss: 2.2951117494572415

Epoch: 6| Step: 2
Training loss: 0.2570017725265546
Validation loss: 2.3045259697539033

Epoch: 6| Step: 3
Training loss: 0.20547953784021727
Validation loss: 2.31457826570204

Epoch: 6| Step: 4
Training loss: 0.18022563420378726
Validation loss: 2.3080315130224696

Epoch: 6| Step: 5
Training loss: 0.2784982881861527
Validation loss: 2.3509048579639544

Epoch: 6| Step: 6
Training loss: 0.16004553899307014
Validation loss: 2.340811922789702

Epoch: 6| Step: 7
Training loss: 0.15935853845066486
Validation loss: 2.364510166484868

Epoch: 6| Step: 8
Training loss: 0.2818962725205825
Validation loss: 2.3907134219160358

Epoch: 6| Step: 9
Training loss: 0.10585795222096964
Validation loss: 2.3807586990780223

Epoch: 6| Step: 10
Training loss: 0.1406288610034299
Validation loss: 2.380524787932627

Epoch: 6| Step: 11
Training loss: 0.26778185529993254
Validation loss: 2.344125121802725

Epoch: 6| Step: 12
Training loss: 0.25746211893640847
Validation loss: 2.377570752507029

Epoch: 6| Step: 13
Training loss: 0.14777863617640652
Validation loss: 2.36923429381759

Epoch: 504| Step: 0
Training loss: 0.250153196603319
Validation loss: 2.351288417250161

Epoch: 6| Step: 1
Training loss: 0.06985559292156
Validation loss: 2.3415624876571908

Epoch: 6| Step: 2
Training loss: 0.18430104873931147
Validation loss: 2.369340478856693

Epoch: 6| Step: 3
Training loss: 0.12796084919900896
Validation loss: 2.35328809580979

Epoch: 6| Step: 4
Training loss: 0.16382215697296973
Validation loss: 2.3702598097658627

Epoch: 6| Step: 5
Training loss: 0.23310893151692186
Validation loss: 2.3915566062092735

Epoch: 6| Step: 6
Training loss: 0.13492491885994407
Validation loss: 2.4040573841996755

Epoch: 6| Step: 7
Training loss: 0.13231575857897077
Validation loss: 2.381753876714049

Epoch: 6| Step: 8
Training loss: 0.18571044337737405
Validation loss: 2.4316287221006503

Epoch: 6| Step: 9
Training loss: 0.11980851372826863
Validation loss: 2.397064851938976

Epoch: 6| Step: 10
Training loss: 0.15550394762032838
Validation loss: 2.3885360889938454

Epoch: 6| Step: 11
Training loss: 0.2739393533482522
Validation loss: 2.4385341157645746

Epoch: 6| Step: 12
Training loss: 0.24282692514133797
Validation loss: 2.357140265955533

Epoch: 6| Step: 13
Training loss: 0.21737719525999524
Validation loss: 2.373927762182445

Epoch: 505| Step: 0
Training loss: 0.15027422549519837
Validation loss: 2.3341258645211376

Epoch: 6| Step: 1
Training loss: 0.18303073629561517
Validation loss: 2.3723046347277723

Epoch: 6| Step: 2
Training loss: 0.1654134150116608
Validation loss: 2.3294918614614617

Epoch: 6| Step: 3
Training loss: 0.17041375230202993
Validation loss: 2.3329434329100676

Epoch: 6| Step: 4
Training loss: 0.20872912461012322
Validation loss: 2.323365470019684

Epoch: 6| Step: 5
Training loss: 0.23043560339289695
Validation loss: 2.3245011093766648

Epoch: 6| Step: 6
Training loss: 0.29589129901999983
Validation loss: 2.343865473920878

Epoch: 6| Step: 7
Training loss: 0.13988806432661813
Validation loss: 2.386222463773672

Epoch: 6| Step: 8
Training loss: 0.17092814595991795
Validation loss: 2.3935402260044643

Epoch: 6| Step: 9
Training loss: 0.22926007159041872
Validation loss: 2.4197668029036916

Epoch: 6| Step: 10
Training loss: 0.10226757803932394
Validation loss: 2.444251617075505

Epoch: 6| Step: 11
Training loss: 0.18203369802048605
Validation loss: 2.423720233957869

Epoch: 6| Step: 12
Training loss: 0.15363929756186218
Validation loss: 2.4447478265830025

Epoch: 6| Step: 13
Training loss: 0.3460535224113827
Validation loss: 2.418867180430365

Epoch: 506| Step: 0
Training loss: 0.1706250920225601
Validation loss: 2.409323553478237

Epoch: 6| Step: 1
Training loss: 0.1270352318152583
Validation loss: 2.3968098181086783

Epoch: 6| Step: 2
Training loss: 0.21319626383017187
Validation loss: 2.3823654672666907

Epoch: 6| Step: 3
Training loss: 0.1255336338127404
Validation loss: 2.3772068936929434

Epoch: 6| Step: 4
Training loss: 0.24735432912453378
Validation loss: 2.376499520849901

Epoch: 6| Step: 5
Training loss: 0.2479523456101377
Validation loss: 2.3734887414648282

Epoch: 6| Step: 6
Training loss: 0.19950065115294158
Validation loss: 2.3708074423571133

Epoch: 6| Step: 7
Training loss: 0.2047318577932282
Validation loss: 2.3668002289649595

Epoch: 6| Step: 8
Training loss: 0.24944542677912349
Validation loss: 2.3985756102171143

Epoch: 6| Step: 9
Training loss: 0.2479391990701488
Validation loss: 2.4046556165772963

Epoch: 6| Step: 10
Training loss: 0.13281774510516892
Validation loss: 2.433343326426153

Epoch: 6| Step: 11
Training loss: 0.17553022792947134
Validation loss: 2.449002584880394

Epoch: 6| Step: 12
Training loss: 0.20811203687122437
Validation loss: 2.4181674679009126

Epoch: 6| Step: 13
Training loss: 0.2983884131920951
Validation loss: 2.406458310423623

Epoch: 507| Step: 0
Training loss: 0.26958297841246726
Validation loss: 2.374394830307815

Epoch: 6| Step: 1
Training loss: 0.24338011737433668
Validation loss: 2.343675936824198

Epoch: 6| Step: 2
Training loss: 0.15392664662865602
Validation loss: 2.3525231790356953

Epoch: 6| Step: 3
Training loss: 0.1274249698373004
Validation loss: 2.3397769255912717

Epoch: 6| Step: 4
Training loss: 0.19651553625465895
Validation loss: 2.333326442623365

Epoch: 6| Step: 5
Training loss: 0.1597721681444166
Validation loss: 2.3228814068904904

Epoch: 6| Step: 6
Training loss: 0.16150769637875037
Validation loss: 2.307831273740685

Epoch: 6| Step: 7
Training loss: 0.2696125350231951
Validation loss: 2.307678897564705

Epoch: 6| Step: 8
Training loss: 0.29330397183050244
Validation loss: 2.313161857667918

Epoch: 6| Step: 9
Training loss: 0.2160946668631631
Validation loss: 2.3666408274038853

Epoch: 6| Step: 10
Training loss: 0.14342509797860734
Validation loss: 2.359067461517115

Epoch: 6| Step: 11
Training loss: 0.16997235195167829
Validation loss: 2.379916187555463

Epoch: 6| Step: 12
Training loss: 0.23627077935939161
Validation loss: 2.4090275602229916

Epoch: 6| Step: 13
Training loss: 0.1436386122581728
Validation loss: 2.428592094809302

Epoch: 508| Step: 0
Training loss: 0.2582193689820175
Validation loss: 2.4308689118964915

Epoch: 6| Step: 1
Training loss: 0.1528139865447993
Validation loss: 2.369282728246164

Epoch: 6| Step: 2
Training loss: 0.11967349486544068
Validation loss: 2.347926101544051

Epoch: 6| Step: 3
Training loss: 0.15859371993341773
Validation loss: 2.3662700572135433

Epoch: 6| Step: 4
Training loss: 0.24760290648402228
Validation loss: 2.3268180725141616

Epoch: 6| Step: 5
Training loss: 0.08317526028358488
Validation loss: 2.3362760683610784

Epoch: 6| Step: 6
Training loss: 0.19213750855846212
Validation loss: 2.3294198035799227

Epoch: 6| Step: 7
Training loss: 0.22596886571438843
Validation loss: 2.3127872595706163

Epoch: 6| Step: 8
Training loss: 0.2517780612470444
Validation loss: 2.2944878635265855

Epoch: 6| Step: 9
Training loss: 0.1891040634150649
Validation loss: 2.3430832289725974

Epoch: 6| Step: 10
Training loss: 0.27593152379944286
Validation loss: 2.3357566702868424

Epoch: 6| Step: 11
Training loss: 0.2137496573043887
Validation loss: 2.365212590991063

Epoch: 6| Step: 12
Training loss: 0.24534291819877366
Validation loss: 2.375132102077346

Epoch: 6| Step: 13
Training loss: 0.28185818399989415
Validation loss: 2.432585707411265

Epoch: 509| Step: 0
Training loss: 0.16148679748991807
Validation loss: 2.4062577678851755

Epoch: 6| Step: 1
Training loss: 0.19545166779546022
Validation loss: 2.4205812315084336

Epoch: 6| Step: 2
Training loss: 0.29989918266476295
Validation loss: 2.4066458617379105

Epoch: 6| Step: 3
Training loss: 0.30195097928685083
Validation loss: 2.3844177573416574

Epoch: 6| Step: 4
Training loss: 0.14612144014005055
Validation loss: 2.375790936556705

Epoch: 6| Step: 5
Training loss: 0.18969468319974947
Validation loss: 2.377757504204771

Epoch: 6| Step: 6
Training loss: 0.1406542893213536
Validation loss: 2.3583910848440564

Epoch: 6| Step: 7
Training loss: 0.13584838116361875
Validation loss: 2.351549764412066

Epoch: 6| Step: 8
Training loss: 0.1944867224843925
Validation loss: 2.338178160809212

Epoch: 6| Step: 9
Training loss: 0.12390634310647898
Validation loss: 2.370505204677385

Epoch: 6| Step: 10
Training loss: 0.11054372934644373
Validation loss: 2.339443476249376

Epoch: 6| Step: 11
Training loss: 0.24732819770360295
Validation loss: 2.3655979209075366

Epoch: 6| Step: 12
Training loss: 0.17901362649235392
Validation loss: 2.374985426602774

Epoch: 6| Step: 13
Training loss: 0.125258469087313
Validation loss: 2.3861294688196364

Epoch: 510| Step: 0
Training loss: 0.2989953265191681
Validation loss: 2.377683626989313

Epoch: 6| Step: 1
Training loss: 0.2187009824601665
Validation loss: 2.366802125590158

Epoch: 6| Step: 2
Training loss: 0.14558873070774514
Validation loss: 2.3348600963719055

Epoch: 6| Step: 3
Training loss: 0.12064806768870402
Validation loss: 2.3215991871062367

Epoch: 6| Step: 4
Training loss: 0.23218534759971676
Validation loss: 2.3259484384459053

Epoch: 6| Step: 5
Training loss: 0.15337753442956928
Validation loss: 2.297903465044383

Epoch: 6| Step: 6
Training loss: 0.22430457290306882
Validation loss: 2.304207192148601

Epoch: 6| Step: 7
Training loss: 0.16672685524813036
Validation loss: 2.3059777459593924

Epoch: 6| Step: 8
Training loss: 0.1368915419620229
Validation loss: 2.3203925585091043

Epoch: 6| Step: 9
Training loss: 0.1248614094267346
Validation loss: 2.344059458439382

Epoch: 6| Step: 10
Training loss: 0.16750356109057646
Validation loss: 2.3236370436570826

Epoch: 6| Step: 11
Training loss: 0.1940490291668482
Validation loss: 2.356328248639918

Epoch: 6| Step: 12
Training loss: 0.1684111546506356
Validation loss: 2.3639337593310588

Epoch: 6| Step: 13
Training loss: 0.07899542740636675
Validation loss: 2.3727406666665094

Epoch: 511| Step: 0
Training loss: 0.19485080508909342
Validation loss: 2.326278186915689

Epoch: 6| Step: 1
Training loss: 0.22720864663229862
Validation loss: 2.3677405076208284

Epoch: 6| Step: 2
Training loss: 0.14129592532912655
Validation loss: 2.3362176101428456

Epoch: 6| Step: 3
Training loss: 0.0914049558058842
Validation loss: 2.3383279147244065

Epoch: 6| Step: 4
Training loss: 0.21438878176349743
Validation loss: 2.3345400053063217

Epoch: 6| Step: 5
Training loss: 0.14955234984608645
Validation loss: 2.3232766973338013

Epoch: 6| Step: 6
Training loss: 0.13517867933059521
Validation loss: 2.3082411954420827

Epoch: 6| Step: 7
Training loss: 0.15895784751906178
Validation loss: 2.3299292206245203

Epoch: 6| Step: 8
Training loss: 0.21334396879375767
Validation loss: 2.3159695787677057

Epoch: 6| Step: 9
Training loss: 0.1524948507850604
Validation loss: 2.2988360328310735

Epoch: 6| Step: 10
Training loss: 0.1309229710468505
Validation loss: 2.318692068505073

Epoch: 6| Step: 11
Training loss: 0.18243646093701882
Validation loss: 2.3227872363182764

Epoch: 6| Step: 12
Training loss: 0.17603571804612592
Validation loss: 2.324039879280108

Epoch: 6| Step: 13
Training loss: 0.08136160892293705
Validation loss: 2.3199525699463064

Epoch: 512| Step: 0
Training loss: 0.14400087161677871
Validation loss: 2.3217500081645355

Epoch: 6| Step: 1
Training loss: 0.12177719783085919
Validation loss: 2.3354009575314696

Epoch: 6| Step: 2
Training loss: 0.16247303514319703
Validation loss: 2.3542091052903413

Epoch: 6| Step: 3
Training loss: 0.11755142922727196
Validation loss: 2.338163587061969

Epoch: 6| Step: 4
Training loss: 0.24814750852754136
Validation loss: 2.335502882319592

Epoch: 6| Step: 5
Training loss: 0.17222476180466156
Validation loss: 2.3532647610320523

Epoch: 6| Step: 6
Training loss: 0.21538325974106892
Validation loss: 2.3691548880813644

Epoch: 6| Step: 7
Training loss: 0.095466213489182
Validation loss: 2.3388158735342994

Epoch: 6| Step: 8
Training loss: 0.148570979486595
Validation loss: 2.3374426471622485

Epoch: 6| Step: 9
Training loss: 0.1490622973490683
Validation loss: 2.312678231840346

Epoch: 6| Step: 10
Training loss: 0.09544847142703856
Validation loss: 2.2929592779091466

Epoch: 6| Step: 11
Training loss: 0.12599444447249408
Validation loss: 2.3257640157566555

Epoch: 6| Step: 12
Training loss: 0.1967239496757381
Validation loss: 2.3384158825097847

Epoch: 6| Step: 13
Training loss: 0.0735759410499605
Validation loss: 2.329631000364445

Epoch: 513| Step: 0
Training loss: 0.18698144772306174
Validation loss: 2.2893987499180035

Epoch: 6| Step: 1
Training loss: 0.17402146335085728
Validation loss: 2.3157262205994846

Epoch: 6| Step: 2
Training loss: 0.08842823064234062
Validation loss: 2.2965670355385517

Epoch: 6| Step: 3
Training loss: 0.1813208112840072
Validation loss: 2.2864867420792323

Epoch: 6| Step: 4
Training loss: 0.13276135637986608
Validation loss: 2.332960273288786

Epoch: 6| Step: 5
Training loss: 0.14222051897333934
Validation loss: 2.326545526966324

Epoch: 6| Step: 6
Training loss: 0.07430037602540293
Validation loss: 2.330548806062792

Epoch: 6| Step: 7
Training loss: 0.20029481415477363
Validation loss: 2.3085407452060958

Epoch: 6| Step: 8
Training loss: 0.07818889389350751
Validation loss: 2.334782619090861

Epoch: 6| Step: 9
Training loss: 0.10306282697964647
Validation loss: 2.3245739615843384

Epoch: 6| Step: 10
Training loss: 0.09958424438158914
Validation loss: 2.3601570422427254

Epoch: 6| Step: 11
Training loss: 0.23343611058047647
Validation loss: 2.333183548187812

Epoch: 6| Step: 12
Training loss: 0.16606114829234375
Validation loss: 2.3430294621978947

Epoch: 6| Step: 13
Training loss: 0.1524098143017061
Validation loss: 2.3646601050604703

Epoch: 514| Step: 0
Training loss: 0.12119931956729095
Validation loss: 2.3363423455019316

Epoch: 6| Step: 1
Training loss: 0.16737788536983494
Validation loss: 2.3502914176239145

Epoch: 6| Step: 2
Training loss: 0.16826420680867213
Validation loss: 2.340402219620771

Epoch: 6| Step: 3
Training loss: 0.19551376463283096
Validation loss: 2.382561082787674

Epoch: 6| Step: 4
Training loss: 0.07432200439561998
Validation loss: 2.35758880976539

Epoch: 6| Step: 5
Training loss: 0.16108075081134363
Validation loss: 2.360996722595826

Epoch: 6| Step: 6
Training loss: 0.16090391257635514
Validation loss: 2.3755712515680467

Epoch: 6| Step: 7
Training loss: 0.2540066153892584
Validation loss: 2.365981777296953

Epoch: 6| Step: 8
Training loss: 0.09823242920176692
Validation loss: 2.361135415364917

Epoch: 6| Step: 9
Training loss: 0.14736949535941601
Validation loss: 2.3596838931112205

Epoch: 6| Step: 10
Training loss: 0.13054882036696672
Validation loss: 2.3668243813063876

Epoch: 6| Step: 11
Training loss: 0.14433205900027066
Validation loss: 2.359046399745137

Epoch: 6| Step: 12
Training loss: 0.07938810829279577
Validation loss: 2.364426604452492

Epoch: 6| Step: 13
Training loss: 0.1192005038266367
Validation loss: 2.346704968944386

Epoch: 515| Step: 0
Training loss: 0.08124992113843171
Validation loss: 2.3531671397356093

Epoch: 6| Step: 1
Training loss: 0.17103396899813286
Validation loss: 2.3383364575174066

Epoch: 6| Step: 2
Training loss: 0.19123337198102405
Validation loss: 2.3257973914204415

Epoch: 6| Step: 3
Training loss: 0.1319375670743236
Validation loss: 2.329649448222258

Epoch: 6| Step: 4
Training loss: 0.11406739580412267
Validation loss: 2.3391160807401206

Epoch: 6| Step: 5
Training loss: 0.13820587356016528
Validation loss: 2.3223807829002263

Epoch: 6| Step: 6
Training loss: 0.12042133081441148
Validation loss: 2.31675469160518

Epoch: 6| Step: 7
Training loss: 0.10752626895149116
Validation loss: 2.349744917483638

Epoch: 6| Step: 8
Training loss: 0.12902578678007634
Validation loss: 2.3702686025057154

Epoch: 6| Step: 9
Training loss: 0.14782732483958044
Validation loss: 2.384994719567764

Epoch: 6| Step: 10
Training loss: 0.2372810838679417
Validation loss: 2.3986696130502736

Epoch: 6| Step: 11
Training loss: 0.16643857373354312
Validation loss: 2.3990043239438186

Epoch: 6| Step: 12
Training loss: 0.1477371937539851
Validation loss: 2.387523853346272

Epoch: 6| Step: 13
Training loss: 0.22763835394168497
Validation loss: 2.369896790774641

Epoch: 516| Step: 0
Training loss: 0.12271521162517997
Validation loss: 2.345557658640418

Epoch: 6| Step: 1
Training loss: 0.10011081143904577
Validation loss: 2.330024463571438

Epoch: 6| Step: 2
Training loss: 0.11515780103019371
Validation loss: 2.3080785032798605

Epoch: 6| Step: 3
Training loss: 0.1850082308800458
Validation loss: 2.2959428360202785

Epoch: 6| Step: 4
Training loss: 0.16625032664209557
Validation loss: 2.288581894847131

Epoch: 6| Step: 5
Training loss: 0.1250882507766946
Validation loss: 2.2809619359266957

Epoch: 6| Step: 6
Training loss: 0.14186436830714363
Validation loss: 2.3066357292009485

Epoch: 6| Step: 7
Training loss: 0.1062442034654866
Validation loss: 2.294819848649352

Epoch: 6| Step: 8
Training loss: 0.14912200882486648
Validation loss: 2.288876963435444

Epoch: 6| Step: 9
Training loss: 0.18563879647344528
Validation loss: 2.3247874043335024

Epoch: 6| Step: 10
Training loss: 0.25137915771722186
Validation loss: 2.332375622870867

Epoch: 6| Step: 11
Training loss: 0.12973253978959756
Validation loss: 2.322943254985711

Epoch: 6| Step: 12
Training loss: 0.18105717752960387
Validation loss: 2.332693279906832

Epoch: 6| Step: 13
Training loss: 0.08625239150819429
Validation loss: 2.326201329154522

Epoch: 517| Step: 0
Training loss: 0.09718299634501383
Validation loss: 2.3093708999031017

Epoch: 6| Step: 1
Training loss: 0.19683125327763806
Validation loss: 2.3260346932524314

Epoch: 6| Step: 2
Training loss: 0.134741241902968
Validation loss: 2.331439871862089

Epoch: 6| Step: 3
Training loss: 0.11895861559108957
Validation loss: 2.3327672043786256

Epoch: 6| Step: 4
Training loss: 0.21710333771494444
Validation loss: 2.3174388862068134

Epoch: 6| Step: 5
Training loss: 0.1790816625690524
Validation loss: 2.3429770974766884

Epoch: 6| Step: 6
Training loss: 0.11512504256353306
Validation loss: 2.34078757159615

Epoch: 6| Step: 7
Training loss: 0.12690613684030394
Validation loss: 2.347294025310322

Epoch: 6| Step: 8
Training loss: 0.07769727744220839
Validation loss: 2.349987858610222

Epoch: 6| Step: 9
Training loss: 0.11709906499597907
Validation loss: 2.3469373549516854

Epoch: 6| Step: 10
Training loss: 0.13707555125442397
Validation loss: 2.372507403231949

Epoch: 6| Step: 11
Training loss: 0.13999068729472397
Validation loss: 2.3738988159593832

Epoch: 6| Step: 12
Training loss: 0.1967719671305243
Validation loss: 2.3580887951832725

Epoch: 6| Step: 13
Training loss: 0.0814260312454218
Validation loss: 2.3650873902891805

Epoch: 518| Step: 0
Training loss: 0.10085696215295707
Validation loss: 2.336678336193948

Epoch: 6| Step: 1
Training loss: 0.20521938363609588
Validation loss: 2.3485960216555806

Epoch: 6| Step: 2
Training loss: 0.1269764511980083
Validation loss: 2.3300273468098904

Epoch: 6| Step: 3
Training loss: 0.10170492859151171
Validation loss: 2.378240698360982

Epoch: 6| Step: 4
Training loss: 0.140925972777977
Validation loss: 2.3362935826075164

Epoch: 6| Step: 5
Training loss: 0.09112624457442145
Validation loss: 2.3583510296416117

Epoch: 6| Step: 6
Training loss: 0.1798054059511724
Validation loss: 2.3634093525574404

Epoch: 6| Step: 7
Training loss: 0.12159065231337249
Validation loss: 2.363917834219973

Epoch: 6| Step: 8
Training loss: 0.18067599076767013
Validation loss: 2.37327013395677

Epoch: 6| Step: 9
Training loss: 0.09005902766146148
Validation loss: 2.3434356489582626

Epoch: 6| Step: 10
Training loss: 0.1562134461560365
Validation loss: 2.355819174067665

Epoch: 6| Step: 11
Training loss: 0.0986781771362077
Validation loss: 2.337800877402057

Epoch: 6| Step: 12
Training loss: 0.2155303387937218
Validation loss: 2.349672897533503

Epoch: 6| Step: 13
Training loss: 0.18975470813431247
Validation loss: 2.3337596080564738

Epoch: 519| Step: 0
Training loss: 0.11366768809600847
Validation loss: 2.2979160985545346

Epoch: 6| Step: 1
Training loss: 0.10853662360453788
Validation loss: 2.3248482219629656

Epoch: 6| Step: 2
Training loss: 0.15298389774793916
Validation loss: 2.288079479331085

Epoch: 6| Step: 3
Training loss: 0.16622342400094178
Validation loss: 2.2760399966507063

Epoch: 6| Step: 4
Training loss: 0.21869689433025516
Validation loss: 2.3063291686883463

Epoch: 6| Step: 5
Training loss: 0.1462981247991639
Validation loss: 2.3104519653494004

Epoch: 6| Step: 6
Training loss: 0.1394365410333621
Validation loss: 2.323331108261095

Epoch: 6| Step: 7
Training loss: 0.19993317351887646
Validation loss: 2.3326821733399448

Epoch: 6| Step: 8
Training loss: 0.1624470892835483
Validation loss: 2.3446482675522597

Epoch: 6| Step: 9
Training loss: 0.15944277780725488
Validation loss: 2.3655459853280614

Epoch: 6| Step: 10
Training loss: 0.09069810869866837
Validation loss: 2.389756246115959

Epoch: 6| Step: 11
Training loss: 0.20615858017068747
Validation loss: 2.385961105507446

Epoch: 6| Step: 12
Training loss: 0.15305494924903285
Validation loss: 2.365840970074262

Epoch: 6| Step: 13
Training loss: 0.08414177228806004
Validation loss: 2.345032951304859

Epoch: 520| Step: 0
Training loss: 0.11777235555705375
Validation loss: 2.348130465624269

Epoch: 6| Step: 1
Training loss: 0.16383346965477874
Validation loss: 2.3257440886730656

Epoch: 6| Step: 2
Training loss: 0.09805334419398383
Validation loss: 2.3528991580819447

Epoch: 6| Step: 3
Training loss: 0.24344066223617478
Validation loss: 2.3206559147328867

Epoch: 6| Step: 4
Training loss: 0.246883789340625
Validation loss: 2.3441861813931424

Epoch: 6| Step: 5
Training loss: 0.0914589566917002
Validation loss: 2.313555628682843

Epoch: 6| Step: 6
Training loss: 0.13491562774190255
Validation loss: 2.323126857111404

Epoch: 6| Step: 7
Training loss: 0.135388111502797
Validation loss: 2.330030238846861

Epoch: 6| Step: 8
Training loss: 0.11288647264545967
Validation loss: 2.349047898931316

Epoch: 6| Step: 9
Training loss: 0.1839077577391393
Validation loss: 2.357450827793673

Epoch: 6| Step: 10
Training loss: 0.0989353337246541
Validation loss: 2.3440718934979747

Epoch: 6| Step: 11
Training loss: 0.08638497914255949
Validation loss: 2.348986622476967

Epoch: 6| Step: 12
Training loss: 0.12386817675495933
Validation loss: 2.348357129665016

Epoch: 6| Step: 13
Training loss: 0.08293810329598729
Validation loss: 2.3719218296902187

Epoch: 521| Step: 0
Training loss: 0.15084267462099527
Validation loss: 2.3310093267509036

Epoch: 6| Step: 1
Training loss: 0.08702247533875046
Validation loss: 2.342264222124365

Epoch: 6| Step: 2
Training loss: 0.07750931969296039
Validation loss: 2.297409517776835

Epoch: 6| Step: 3
Training loss: 0.0982334673445053
Validation loss: 2.343179373238571

Epoch: 6| Step: 4
Training loss: 0.10468249949568706
Validation loss: 2.323699414994874

Epoch: 6| Step: 5
Training loss: 0.16882287809452673
Validation loss: 2.320281798810561

Epoch: 6| Step: 6
Training loss: 0.20536771037769874
Validation loss: 2.3131491413191023

Epoch: 6| Step: 7
Training loss: 0.11943268935452986
Validation loss: 2.3217062930841403

Epoch: 6| Step: 8
Training loss: 0.10838258472716489
Validation loss: 2.321281829747755

Epoch: 6| Step: 9
Training loss: 0.07903657115329103
Validation loss: 2.3180085855426387

Epoch: 6| Step: 10
Training loss: 0.1493821515182955
Validation loss: 2.33189215701934

Epoch: 6| Step: 11
Training loss: 0.08510757540384212
Validation loss: 2.350402615752613

Epoch: 6| Step: 12
Training loss: 0.21002643362072962
Validation loss: 2.3523943632353004

Epoch: 6| Step: 13
Training loss: 0.2931569321570264
Validation loss: 2.3376846477004714

Epoch: 522| Step: 0
Training loss: 0.12463928120885658
Validation loss: 2.340898214187017

Epoch: 6| Step: 1
Training loss: 0.0871503062370608
Validation loss: 2.312309606508377

Epoch: 6| Step: 2
Training loss: 0.11920876977425746
Validation loss: 2.292879729584996

Epoch: 6| Step: 3
Training loss: 0.10102888832287703
Validation loss: 2.310510783650897

Epoch: 6| Step: 4
Training loss: 0.2376500508981526
Validation loss: 2.317001942668409

Epoch: 6| Step: 5
Training loss: 0.17138795770702686
Validation loss: 2.332454754041349

Epoch: 6| Step: 6
Training loss: 0.20862694951147095
Validation loss: 2.339358001863159

Epoch: 6| Step: 7
Training loss: 0.08051631988967296
Validation loss: 2.3645894354677863

Epoch: 6| Step: 8
Training loss: 0.0690597992526466
Validation loss: 2.341090818407536

Epoch: 6| Step: 9
Training loss: 0.08090524224876268
Validation loss: 2.36732142093396

Epoch: 6| Step: 10
Training loss: 0.19408500227641226
Validation loss: 2.397300768029545

Epoch: 6| Step: 11
Training loss: 0.11012464164519703
Validation loss: 2.3839769670078255

Epoch: 6| Step: 12
Training loss: 0.21311088856491656
Validation loss: 2.3513623529468948

Epoch: 6| Step: 13
Training loss: 0.20074664236968645
Validation loss: 2.3459575841872984

Epoch: 523| Step: 0
Training loss: 0.13320254803977255
Validation loss: 2.3259190979226925

Epoch: 6| Step: 1
Training loss: 0.14126387483676972
Validation loss: 2.326858399500838

Epoch: 6| Step: 2
Training loss: 0.17228784071903766
Validation loss: 2.307764495495419

Epoch: 6| Step: 3
Training loss: 0.09444193009324611
Validation loss: 2.3401289840718116

Epoch: 6| Step: 4
Training loss: 0.09885804737333699
Validation loss: 2.350630179944262

Epoch: 6| Step: 5
Training loss: 0.22664533120403693
Validation loss: 2.41183227100533

Epoch: 6| Step: 6
Training loss: 0.1809067101873863
Validation loss: 2.403425844923792

Epoch: 6| Step: 7
Training loss: 0.17873906607298937
Validation loss: 2.3881997112932805

Epoch: 6| Step: 8
Training loss: 0.29812122082664133
Validation loss: 2.4050778134931177

Epoch: 6| Step: 9
Training loss: 0.19945226335171296
Validation loss: 2.3755786538400776

Epoch: 6| Step: 10
Training loss: 0.12800800314159475
Validation loss: 2.340397470028166

Epoch: 6| Step: 11
Training loss: 0.14382755530149735
Validation loss: 2.322236009979525

Epoch: 6| Step: 12
Training loss: 0.16864825466303546
Validation loss: 2.31280698459737

Epoch: 6| Step: 13
Training loss: 0.2757538233402906
Validation loss: 2.324095800644193

Epoch: 524| Step: 0
Training loss: 0.1953098296936599
Validation loss: 2.3057527349897358

Epoch: 6| Step: 1
Training loss: 0.12741587006658991
Validation loss: 2.3423227209701976

Epoch: 6| Step: 2
Training loss: 0.09743019643575244
Validation loss: 2.3603936006559976

Epoch: 6| Step: 3
Training loss: 0.19603314964131718
Validation loss: 2.3926658350772843

Epoch: 6| Step: 4
Training loss: 0.0992741460170726
Validation loss: 2.3862552801383505

Epoch: 6| Step: 5
Training loss: 0.17711402239126695
Validation loss: 2.3648744047736403

Epoch: 6| Step: 6
Training loss: 0.12925918265959843
Validation loss: 2.3424329285181837

Epoch: 6| Step: 7
Training loss: 0.13781661243747126
Validation loss: 2.3428119064552853

Epoch: 6| Step: 8
Training loss: 0.18071099779961597
Validation loss: 2.3487459812576237

Epoch: 6| Step: 9
Training loss: 0.2061139604551326
Validation loss: 2.333505313954647

Epoch: 6| Step: 10
Training loss: 0.19190874119918086
Validation loss: 2.324930050658067

Epoch: 6| Step: 11
Training loss: 0.26325882949222856
Validation loss: 2.2912213882004213

Epoch: 6| Step: 12
Training loss: 0.2034059379048956
Validation loss: 2.2929856681838974

Epoch: 6| Step: 13
Training loss: 0.18910416191345938
Validation loss: 2.3164238204086316

Epoch: 525| Step: 0
Training loss: 0.13550755922761737
Validation loss: 2.3512617082428555

Epoch: 6| Step: 1
Training loss: 0.10112247144534454
Validation loss: 2.3682665013767306

Epoch: 6| Step: 2
Training loss: 0.16441414250983433
Validation loss: 2.3810985827641997

Epoch: 6| Step: 3
Training loss: 0.2872377614608817
Validation loss: 2.4174635665538338

Epoch: 6| Step: 4
Training loss: 0.11979813186848923
Validation loss: 2.3832221244110086

Epoch: 6| Step: 5
Training loss: 0.14710004488246084
Validation loss: 2.4088794185220586

Epoch: 6| Step: 6
Training loss: 0.1297358563478827
Validation loss: 2.3915018383383693

Epoch: 6| Step: 7
Training loss: 0.22475546356769643
Validation loss: 2.3735977463211255

Epoch: 6| Step: 8
Training loss: 0.18202574725695153
Validation loss: 2.345408511171827

Epoch: 6| Step: 9
Training loss: 0.2223449840229932
Validation loss: 2.358862328090645

Epoch: 6| Step: 10
Training loss: 0.14538864401892887
Validation loss: 2.3428910473273343

Epoch: 6| Step: 11
Training loss: 0.10242969038655411
Validation loss: 2.370603855257928

Epoch: 6| Step: 12
Training loss: 0.18518536133614305
Validation loss: 2.387613504635931

Epoch: 6| Step: 13
Training loss: 0.10174578396072705
Validation loss: 2.40272411100221

Epoch: 526| Step: 0
Training loss: 0.23708997832496445
Validation loss: 2.387438155124198

Epoch: 6| Step: 1
Training loss: 0.1747889911274821
Validation loss: 2.384322381917721

Epoch: 6| Step: 2
Training loss: 0.1382656056234575
Validation loss: 2.3723681336508453

Epoch: 6| Step: 3
Training loss: 0.14215838034570885
Validation loss: 2.333277103593281

Epoch: 6| Step: 4
Training loss: 0.09545829167809834
Validation loss: 2.3628117831929227

Epoch: 6| Step: 5
Training loss: 0.1106613166648863
Validation loss: 2.3460213875439915

Epoch: 6| Step: 6
Training loss: 0.1577236657288305
Validation loss: 2.337668342806216

Epoch: 6| Step: 7
Training loss: 0.2317938132448681
Validation loss: 2.343742180267743

Epoch: 6| Step: 8
Training loss: 0.1438264350750392
Validation loss: 2.382441521970793

Epoch: 6| Step: 9
Training loss: 0.1366859669209111
Validation loss: 2.3802455979872694

Epoch: 6| Step: 10
Training loss: 0.1699629876397363
Validation loss: 2.371708247288136

Epoch: 6| Step: 11
Training loss: 0.12823363589062994
Validation loss: 2.3693794902621845

Epoch: 6| Step: 12
Training loss: 0.1852203105412174
Validation loss: 2.3743558818709527

Epoch: 6| Step: 13
Training loss: 0.17836029799394232
Validation loss: 2.3838648825130164

Epoch: 527| Step: 0
Training loss: 0.2010823948936154
Validation loss: 2.380738602363837

Epoch: 6| Step: 1
Training loss: 0.1508346912571425
Validation loss: 2.3412688797401175

Epoch: 6| Step: 2
Training loss: 0.20536324798500707
Validation loss: 2.378526426513586

Epoch: 6| Step: 3
Training loss: 0.14792032872511313
Validation loss: 2.3556439331802816

Epoch: 6| Step: 4
Training loss: 0.14154446864922426
Validation loss: 2.381003984201188

Epoch: 6| Step: 5
Training loss: 0.09859913543768017
Validation loss: 2.3807365905832762

Epoch: 6| Step: 6
Training loss: 0.16654603598530332
Validation loss: 2.3880028399861124

Epoch: 6| Step: 7
Training loss: 0.08649784252061554
Validation loss: 2.368966668228836

Epoch: 6| Step: 8
Training loss: 0.11584722277059226
Validation loss: 2.3607508475196193

Epoch: 6| Step: 9
Training loss: 0.17287756837376775
Validation loss: 2.410574913841258

Epoch: 6| Step: 10
Training loss: 0.22093856541485982
Validation loss: 2.400162803433063

Epoch: 6| Step: 11
Training loss: 0.09790687349311482
Validation loss: 2.3961463912730543

Epoch: 6| Step: 12
Training loss: 0.10656971617566018
Validation loss: 2.4044609456013597

Epoch: 6| Step: 13
Training loss: 0.11036288785629739
Validation loss: 2.37489629280505

Epoch: 528| Step: 0
Training loss: 0.15442248555222604
Validation loss: 2.3774591342901594

Epoch: 6| Step: 1
Training loss: 0.09343808160396719
Validation loss: 2.3828097392684353

Epoch: 6| Step: 2
Training loss: 0.13358180845998188
Validation loss: 2.3533620792517893

Epoch: 6| Step: 3
Training loss: 0.18742924587103438
Validation loss: 2.3450325861688217

Epoch: 6| Step: 4
Training loss: 0.14795460706913824
Validation loss: 2.351904247404096

Epoch: 6| Step: 5
Training loss: 0.16362583996999397
Validation loss: 2.327107785046758

Epoch: 6| Step: 6
Training loss: 0.18651956284577928
Validation loss: 2.3228508643681045

Epoch: 6| Step: 7
Training loss: 0.1731445071526439
Validation loss: 2.314236890221819

Epoch: 6| Step: 8
Training loss: 0.09810003059377738
Validation loss: 2.3218279302692943

Epoch: 6| Step: 9
Training loss: 0.09748169557521306
Validation loss: 2.295703499054026

Epoch: 6| Step: 10
Training loss: 0.21554805446964337
Validation loss: 2.318673285802487

Epoch: 6| Step: 11
Training loss: 0.1915929331571519
Validation loss: 2.2950844967208135

Epoch: 6| Step: 12
Training loss: 0.15113112592902261
Validation loss: 2.32272265566893

Epoch: 6| Step: 13
Training loss: 0.1528322323441325
Validation loss: 2.311268737807879

Epoch: 529| Step: 0
Training loss: 0.12074957666707911
Validation loss: 2.319337296507631

Epoch: 6| Step: 1
Training loss: 0.120364899031031
Validation loss: 2.34522700759813

Epoch: 6| Step: 2
Training loss: 0.10996368906159427
Validation loss: 2.3402233430461212

Epoch: 6| Step: 3
Training loss: 0.15449283324828872
Validation loss: 2.401750190214278

Epoch: 6| Step: 4
Training loss: 0.20595399828107
Validation loss: 2.393567359712607

Epoch: 6| Step: 5
Training loss: 0.13499859009995505
Validation loss: 2.3950081983113365

Epoch: 6| Step: 6
Training loss: 0.1542872051637353
Validation loss: 2.4000253421375226

Epoch: 6| Step: 7
Training loss: 0.17960655420916552
Validation loss: 2.4067068711680957

Epoch: 6| Step: 8
Training loss: 0.19851434751517677
Validation loss: 2.402472702048332

Epoch: 6| Step: 9
Training loss: 0.06076392370556031
Validation loss: 2.3441493885652345

Epoch: 6| Step: 10
Training loss: 0.08457147738423128
Validation loss: 2.3287733785176967

Epoch: 6| Step: 11
Training loss: 0.11312247939357617
Validation loss: 2.360484872630536

Epoch: 6| Step: 12
Training loss: 0.20097336650713168
Validation loss: 2.3296149271475746

Epoch: 6| Step: 13
Training loss: 0.18872665455108442
Validation loss: 2.3207850815544178

Epoch: 530| Step: 0
Training loss: 0.12717498320537612
Validation loss: 2.343921046424653

Epoch: 6| Step: 1
Training loss: 0.17883254952746314
Validation loss: 2.3371230200420436

Epoch: 6| Step: 2
Training loss: 0.15681319065861743
Validation loss: 2.326896006138406

Epoch: 6| Step: 3
Training loss: 0.149879143127908
Validation loss: 2.331657860314367

Epoch: 6| Step: 4
Training loss: 0.13508420413156466
Validation loss: 2.3176265896167707

Epoch: 6| Step: 5
Training loss: 0.12085699193734326
Validation loss: 2.3363969365926716

Epoch: 6| Step: 6
Training loss: 0.15164852453898178
Validation loss: 2.3498167421201384

Epoch: 6| Step: 7
Training loss: 0.11262778369594334
Validation loss: 2.3575691402594576

Epoch: 6| Step: 8
Training loss: 0.15428441637176973
Validation loss: 2.3802706529720856

Epoch: 6| Step: 9
Training loss: 0.13297239663920798
Validation loss: 2.3495756960134098

Epoch: 6| Step: 10
Training loss: 0.17864220761956326
Validation loss: 2.376185321622309

Epoch: 6| Step: 11
Training loss: 0.17236589640505695
Validation loss: 2.3325972622951805

Epoch: 6| Step: 12
Training loss: 0.18128175046312797
Validation loss: 2.3422136988200686

Epoch: 6| Step: 13
Training loss: 0.07946046892338714
Validation loss: 2.340730049663858

Epoch: 531| Step: 0
Training loss: 0.17377146858403655
Validation loss: 2.3294871551044944

Epoch: 6| Step: 1
Training loss: 0.1305338811200527
Validation loss: 2.306858154702652

Epoch: 6| Step: 2
Training loss: 0.20331565455836967
Validation loss: 2.28881361964675

Epoch: 6| Step: 3
Training loss: 0.24383424990171654
Validation loss: 2.3168743879080407

Epoch: 6| Step: 4
Training loss: 0.08029878267262751
Validation loss: 2.299582583102503

Epoch: 6| Step: 5
Training loss: 0.13220336011787465
Validation loss: 2.3340731006971334

Epoch: 6| Step: 6
Training loss: 0.11449442515404007
Validation loss: 2.3190006444913216

Epoch: 6| Step: 7
Training loss: 0.13837913723147652
Validation loss: 2.3582555033689547

Epoch: 6| Step: 8
Training loss: 0.1364940977427414
Validation loss: 2.3464483357595127

Epoch: 6| Step: 9
Training loss: 0.12474463873343608
Validation loss: 2.3774533534571862

Epoch: 6| Step: 10
Training loss: 0.11833226236454233
Validation loss: 2.3587356697562485

Epoch: 6| Step: 11
Training loss: 0.1295791316833362
Validation loss: 2.3541627238294414

Epoch: 6| Step: 12
Training loss: 0.09345459591075181
Validation loss: 2.337962213463748

Epoch: 6| Step: 13
Training loss: 0.12990695327474822
Validation loss: 2.35047421415094

Epoch: 532| Step: 0
Training loss: 0.057292347826304095
Validation loss: 2.328523657478396

Epoch: 6| Step: 1
Training loss: 0.21363183575670386
Validation loss: 2.2857329098238277

Epoch: 6| Step: 2
Training loss: 0.14315202253853532
Validation loss: 2.2964432922936986

Epoch: 6| Step: 3
Training loss: 0.09097349927437005
Validation loss: 2.2852653893147274

Epoch: 6| Step: 4
Training loss: 0.150054227196198
Validation loss: 2.294150288843068

Epoch: 6| Step: 5
Training loss: 0.10380496218798518
Validation loss: 2.313231912495378

Epoch: 6| Step: 6
Training loss: 0.1707762472112751
Validation loss: 2.275371810467016

Epoch: 6| Step: 7
Training loss: 0.11090568233956313
Validation loss: 2.2995975234306405

Epoch: 6| Step: 8
Training loss: 0.10593943295923722
Validation loss: 2.2826575655153545

Epoch: 6| Step: 9
Training loss: 0.1667641259144539
Validation loss: 2.296572889369139

Epoch: 6| Step: 10
Training loss: 0.11979136043661477
Validation loss: 2.313917249557227

Epoch: 6| Step: 11
Training loss: 0.19995322127450574
Validation loss: 2.301570429468496

Epoch: 6| Step: 12
Training loss: 0.12745213372108216
Validation loss: 2.3219833757919495

Epoch: 6| Step: 13
Training loss: 0.21059932798489422
Validation loss: 2.3170374239500275

Epoch: 533| Step: 0
Training loss: 0.10154107674818795
Validation loss: 2.3418885794750097

Epoch: 6| Step: 1
Training loss: 0.1264063357363529
Validation loss: 2.315530669565668

Epoch: 6| Step: 2
Training loss: 0.21583626114272184
Validation loss: 2.3157679053439164

Epoch: 6| Step: 3
Training loss: 0.17186269932859558
Validation loss: 2.3025751749890504

Epoch: 6| Step: 4
Training loss: 0.27842862882514285
Validation loss: 2.3273554100700085

Epoch: 6| Step: 5
Training loss: 0.12019394538754018
Validation loss: 2.3233065197776908

Epoch: 6| Step: 6
Training loss: 0.14121391245767118
Validation loss: 2.3302672999542824

Epoch: 6| Step: 7
Training loss: 0.17267536622804305
Validation loss: 2.3342787201534185

Epoch: 6| Step: 8
Training loss: 0.10934279171964473
Validation loss: 2.3770755060173516

Epoch: 6| Step: 9
Training loss: 0.09097956978793262
Validation loss: 2.3662457632447658

Epoch: 6| Step: 10
Training loss: 0.08046874571772443
Validation loss: 2.3464230941604254

Epoch: 6| Step: 11
Training loss: 0.09617027786502916
Validation loss: 2.39002705071185

Epoch: 6| Step: 12
Training loss: 0.15791316598679153
Validation loss: 2.380647588388414

Epoch: 6| Step: 13
Training loss: 0.1322154058711073
Validation loss: 2.3931587427849

Epoch: 534| Step: 0
Training loss: 0.17680676451570457
Validation loss: 2.383448467518501

Epoch: 6| Step: 1
Training loss: 0.13044299596733336
Validation loss: 2.3526970772691764

Epoch: 6| Step: 2
Training loss: 0.10587882746496684
Validation loss: 2.3122022382206624

Epoch: 6| Step: 3
Training loss: 0.10378723229778387
Validation loss: 2.340094979115659

Epoch: 6| Step: 4
Training loss: 0.11415853833699177
Validation loss: 2.3128899364973803

Epoch: 6| Step: 5
Training loss: 0.14265584786850405
Validation loss: 2.3120616596064503

Epoch: 6| Step: 6
Training loss: 0.08798190780741144
Validation loss: 2.342022768679614

Epoch: 6| Step: 7
Training loss: 0.14700904978577967
Validation loss: 2.32765975149781

Epoch: 6| Step: 8
Training loss: 0.2577239664825785
Validation loss: 2.341498315359171

Epoch: 6| Step: 9
Training loss: 0.09477600301852278
Validation loss: 2.3489734440079144

Epoch: 6| Step: 10
Training loss: 0.06830705616057549
Validation loss: 2.3652049256775842

Epoch: 6| Step: 11
Training loss: 0.18101983995267862
Validation loss: 2.3523407270007

Epoch: 6| Step: 12
Training loss: 0.12935816415716989
Validation loss: 2.357132078440984

Epoch: 6| Step: 13
Training loss: 0.14742166741522814
Validation loss: 2.3695919274975865

Epoch: 535| Step: 0
Training loss: 0.2024235350858399
Validation loss: 2.359949366505361

Epoch: 6| Step: 1
Training loss: 0.14283072291708324
Validation loss: 2.345050001126688

Epoch: 6| Step: 2
Training loss: 0.14128452852719256
Validation loss: 2.3250854299187598

Epoch: 6| Step: 3
Training loss: 0.18084640580015737
Validation loss: 2.3583408961589165

Epoch: 6| Step: 4
Training loss: 0.10992283372657496
Validation loss: 2.3001967170770246

Epoch: 6| Step: 5
Training loss: 0.1274660094032719
Validation loss: 2.338213079541526

Epoch: 6| Step: 6
Training loss: 0.10857503270000077
Validation loss: 2.295795771147844

Epoch: 6| Step: 7
Training loss: 0.10469425129827642
Validation loss: 2.328105939924874

Epoch: 6| Step: 8
Training loss: 0.15549318490587508
Validation loss: 2.316155764218731

Epoch: 6| Step: 9
Training loss: 0.14859049842638303
Validation loss: 2.3114102896567523

Epoch: 6| Step: 10
Training loss: 0.10194441166179431
Validation loss: 2.331566076161496

Epoch: 6| Step: 11
Training loss: 0.20634017620258843
Validation loss: 2.3418334617617718

Epoch: 6| Step: 12
Training loss: 0.12154030754195608
Validation loss: 2.3441664305963448

Epoch: 6| Step: 13
Training loss: 0.14010675621712135
Validation loss: 2.350214161078375

Epoch: 536| Step: 0
Training loss: 0.2652890380801846
Validation loss: 2.349214401041116

Epoch: 6| Step: 1
Training loss: 0.09178471484704995
Validation loss: 2.3399376317010465

Epoch: 6| Step: 2
Training loss: 0.10536224674563713
Validation loss: 2.30959514046189

Epoch: 6| Step: 3
Training loss: 0.14792400560731406
Validation loss: 2.327031852002964

Epoch: 6| Step: 4
Training loss: 0.13066292008155714
Validation loss: 2.3572489512115973

Epoch: 6| Step: 5
Training loss: 0.12459358067401739
Validation loss: 2.3111819918250114

Epoch: 6| Step: 6
Training loss: 0.2312529444507064
Validation loss: 2.3217906517402307

Epoch: 6| Step: 7
Training loss: 0.11315584640778609
Validation loss: 2.303278274969131

Epoch: 6| Step: 8
Training loss: 0.09632408847534721
Validation loss: 2.295951755930266

Epoch: 6| Step: 9
Training loss: 0.18035102736749178
Validation loss: 2.3228210896023658

Epoch: 6| Step: 10
Training loss: 0.11353453732631419
Validation loss: 2.308410059775192

Epoch: 6| Step: 11
Training loss: 0.09788857005764089
Validation loss: 2.3110701051641738

Epoch: 6| Step: 12
Training loss: 0.12018874990717905
Validation loss: 2.320825178669949

Epoch: 6| Step: 13
Training loss: 0.19690508045006
Validation loss: 2.359645547385854

Epoch: 537| Step: 0
Training loss: 0.25780406128915306
Validation loss: 2.3453981845919976

Epoch: 6| Step: 1
Training loss: 0.18402023694844968
Validation loss: 2.322273048980931

Epoch: 6| Step: 2
Training loss: 0.16031909432707525
Validation loss: 2.3269841334171946

Epoch: 6| Step: 3
Training loss: 0.1683961398880038
Validation loss: 2.2993543189605976

Epoch: 6| Step: 4
Training loss: 0.09134353132479499
Validation loss: 2.3118239159726395

Epoch: 6| Step: 5
Training loss: 0.11796679463565982
Validation loss: 2.2920008314114324

Epoch: 6| Step: 6
Training loss: 0.1600804382090061
Validation loss: 2.2814070416747336

Epoch: 6| Step: 7
Training loss: 0.09610336166476491
Validation loss: 2.2932737383503388

Epoch: 6| Step: 8
Training loss: 0.13020887533710843
Validation loss: 2.2901367622845115

Epoch: 6| Step: 9
Training loss: 0.18173289262837583
Validation loss: 2.3084216351706623

Epoch: 6| Step: 10
Training loss: 0.1200897138856881
Validation loss: 2.3036231846636257

Epoch: 6| Step: 11
Training loss: 0.11926858315434426
Validation loss: 2.3228055420741223

Epoch: 6| Step: 12
Training loss: 0.0913243611639482
Validation loss: 2.3228484639035076

Epoch: 6| Step: 13
Training loss: 0.12066156804626779
Validation loss: 2.304833278978127

Epoch: 538| Step: 0
Training loss: 0.10904094226121822
Validation loss: 2.2986654770400783

Epoch: 6| Step: 1
Training loss: 0.11847563327861341
Validation loss: 2.309019484345592

Epoch: 6| Step: 2
Training loss: 0.07824983755565576
Validation loss: 2.3078595700976625

Epoch: 6| Step: 3
Training loss: 0.19128320592694473
Validation loss: 2.2987842193706167

Epoch: 6| Step: 4
Training loss: 0.10767524489378687
Validation loss: 2.3319412746981723

Epoch: 6| Step: 5
Training loss: 0.08304936547012555
Validation loss: 2.3322746688616958

Epoch: 6| Step: 6
Training loss: 0.154494985321213
Validation loss: 2.3211222484492793

Epoch: 6| Step: 7
Training loss: 0.11576177442899124
Validation loss: 2.327207029895478

Epoch: 6| Step: 8
Training loss: 0.14352704774671196
Validation loss: 2.326257495560249

Epoch: 6| Step: 9
Training loss: 0.14511550912618104
Validation loss: 2.354723262808563

Epoch: 6| Step: 10
Training loss: 0.12148269747222881
Validation loss: 2.3180181919507246

Epoch: 6| Step: 11
Training loss: 0.1991646917712753
Validation loss: 2.348018780206132

Epoch: 6| Step: 12
Training loss: 0.26779269226429425
Validation loss: 2.3100180983334937

Epoch: 6| Step: 13
Training loss: 0.07249089518876292
Validation loss: 2.335658028001336

Epoch: 539| Step: 0
Training loss: 0.21297143574824257
Validation loss: 2.307780955566979

Epoch: 6| Step: 1
Training loss: 0.14025678375908882
Validation loss: 2.314817266971105

Epoch: 6| Step: 2
Training loss: 0.1048198802399165
Validation loss: 2.3209298571661594

Epoch: 6| Step: 3
Training loss: 0.09088354575609761
Validation loss: 2.3224924182855298

Epoch: 6| Step: 4
Training loss: 0.15486049924312859
Validation loss: 2.338607914496001

Epoch: 6| Step: 5
Training loss: 0.16081165328397798
Validation loss: 2.315219526675245

Epoch: 6| Step: 6
Training loss: 0.096221251142082
Validation loss: 2.318650106844398

Epoch: 6| Step: 7
Training loss: 0.17231607195860438
Validation loss: 2.316123542438653

Epoch: 6| Step: 8
Training loss: 0.13185139318221262
Validation loss: 2.3124541699658088

Epoch: 6| Step: 9
Training loss: 0.09298173709525641
Validation loss: 2.273432359040166

Epoch: 6| Step: 10
Training loss: 0.0945167528417202
Validation loss: 2.3088639765753483

Epoch: 6| Step: 11
Training loss: 0.13281911945676675
Validation loss: 2.314709831149598

Epoch: 6| Step: 12
Training loss: 0.19124025815573908
Validation loss: 2.3345246335587055

Epoch: 6| Step: 13
Training loss: 0.11398678203156484
Validation loss: 2.300408851590988

Epoch: 540| Step: 0
Training loss: 0.12061842180879777
Validation loss: 2.3195960168271372

Epoch: 6| Step: 1
Training loss: 0.17855582254199662
Validation loss: 2.337684534744692

Epoch: 6| Step: 2
Training loss: 0.12075220286169577
Validation loss: 2.3332956841356873

Epoch: 6| Step: 3
Training loss: 0.1211865515585738
Validation loss: 2.3254362553787757

Epoch: 6| Step: 4
Training loss: 0.17115015837551717
Validation loss: 2.3341885909563644

Epoch: 6| Step: 5
Training loss: 0.13857320848329238
Validation loss: 2.3174943147414275

Epoch: 6| Step: 6
Training loss: 0.10598818589053924
Validation loss: 2.3294109287358804

Epoch: 6| Step: 7
Training loss: 0.21284659394058614
Validation loss: 2.332258287398964

Epoch: 6| Step: 8
Training loss: 0.1301217427024681
Validation loss: 2.323533367035066

Epoch: 6| Step: 9
Training loss: 0.14128632808335287
Validation loss: 2.3694037626495112

Epoch: 6| Step: 10
Training loss: 0.08149505395303203
Validation loss: 2.3544719014295277

Epoch: 6| Step: 11
Training loss: 0.19277584766245603
Validation loss: 2.3523856502638876

Epoch: 6| Step: 12
Training loss: 0.08025405039418083
Validation loss: 2.336600202340929

Epoch: 6| Step: 13
Training loss: 0.09598669547471479
Validation loss: 2.358527379727658

Epoch: 541| Step: 0
Training loss: 0.1717647990319058
Validation loss: 2.349235587245218

Epoch: 6| Step: 1
Training loss: 0.12084493917053231
Validation loss: 2.3303901371247644

Epoch: 6| Step: 2
Training loss: 0.1349408972583292
Validation loss: 2.3389678120260577

Epoch: 6| Step: 3
Training loss: 0.09597498369606795
Validation loss: 2.3015290495382024

Epoch: 6| Step: 4
Training loss: 0.1623085705491181
Validation loss: 2.3153455392883546

Epoch: 6| Step: 5
Training loss: 0.15538193253091473
Validation loss: 2.3258267059227635

Epoch: 6| Step: 6
Training loss: 0.07775166836747074
Validation loss: 2.3302953513780325

Epoch: 6| Step: 7
Training loss: 0.08326360056104248
Validation loss: 2.3251554660552998

Epoch: 6| Step: 8
Training loss: 0.13243906730968413
Validation loss: 2.3292459609763085

Epoch: 6| Step: 9
Training loss: 0.10753350093495523
Validation loss: 2.308928905435205

Epoch: 6| Step: 10
Training loss: 0.1014434960885343
Validation loss: 2.328764568912958

Epoch: 6| Step: 11
Training loss: 0.08776957334900862
Validation loss: 2.325527561602754

Epoch: 6| Step: 12
Training loss: 0.20355727891548048
Validation loss: 2.340235681273773

Epoch: 6| Step: 13
Training loss: 0.23255011282524204
Validation loss: 2.3271700953107146

Epoch: 542| Step: 0
Training loss: 0.11400125913829158
Validation loss: 2.332314438744827

Epoch: 6| Step: 1
Training loss: 0.19686026518040858
Validation loss: 2.360288871525795

Epoch: 6| Step: 2
Training loss: 0.1603942475093315
Validation loss: 2.3048137348657596

Epoch: 6| Step: 3
Training loss: 0.1065963801797868
Validation loss: 2.310340263042636

Epoch: 6| Step: 4
Training loss: 0.11447876571417868
Validation loss: 2.2927549710827866

Epoch: 6| Step: 5
Training loss: 0.177413472573364
Validation loss: 2.2751429764954145

Epoch: 6| Step: 6
Training loss: 0.13904302251691245
Validation loss: 2.3059523148367327

Epoch: 6| Step: 7
Training loss: 0.08908134374037499
Validation loss: 2.302173098446096

Epoch: 6| Step: 8
Training loss: 0.07728271930256518
Validation loss: 2.325405091557833

Epoch: 6| Step: 9
Training loss: 0.13215595540834482
Validation loss: 2.3115898432042825

Epoch: 6| Step: 10
Training loss: 0.08155163987249447
Validation loss: 2.3217398744881295

Epoch: 6| Step: 11
Training loss: 0.2107623043835185
Validation loss: 2.315897075240775

Epoch: 6| Step: 12
Training loss: 0.14683315715912734
Validation loss: 2.348733274057589

Epoch: 6| Step: 13
Training loss: 0.0699648873999543
Validation loss: 2.3570018139560793

Epoch: 543| Step: 0
Training loss: 0.22176495563237003
Validation loss: 2.3354137114773375

Epoch: 6| Step: 1
Training loss: 0.2045756041458087
Validation loss: 2.358531311826283

Epoch: 6| Step: 2
Training loss: 0.10447236345428042
Validation loss: 2.360654366036536

Epoch: 6| Step: 3
Training loss: 0.12676826369309804
Validation loss: 2.344045379511098

Epoch: 6| Step: 4
Training loss: 0.10781765766522523
Validation loss: 2.3539899004115274

Epoch: 6| Step: 5
Training loss: 0.11894465573134229
Validation loss: 2.358385845356141

Epoch: 6| Step: 6
Training loss: 0.16551998988557431
Validation loss: 2.3811398207515917

Epoch: 6| Step: 7
Training loss: 0.12014452305330586
Validation loss: 2.372247659800237

Epoch: 6| Step: 8
Training loss: 0.12331260643179622
Validation loss: 2.3685729060569622

Epoch: 6| Step: 9
Training loss: 0.11527876483883719
Validation loss: 2.390888302291006

Epoch: 6| Step: 10
Training loss: 0.12714462508947885
Validation loss: 2.3360024105476227

Epoch: 6| Step: 11
Training loss: 0.0768132897449708
Validation loss: 2.379862738013011

Epoch: 6| Step: 12
Training loss: 0.06951226728072309
Validation loss: 2.3920183394063725

Epoch: 6| Step: 13
Training loss: 0.11216259965595651
Validation loss: 2.3772541978195276

Epoch: 544| Step: 0
Training loss: 0.07028349304563454
Validation loss: 2.3948120333705685

Epoch: 6| Step: 1
Training loss: 0.13890635451794567
Validation loss: 2.38828705619133

Epoch: 6| Step: 2
Training loss: 0.11853985890092235
Validation loss: 2.40756383834982

Epoch: 6| Step: 3
Training loss: 0.10004497165052008
Validation loss: 2.391719512066927

Epoch: 6| Step: 4
Training loss: 0.12119100879539464
Validation loss: 2.3782948521360896

Epoch: 6| Step: 5
Training loss: 0.13366434451751327
Validation loss: 2.371551370040697

Epoch: 6| Step: 6
Training loss: 0.18050355740724208
Validation loss: 2.366568257047022

Epoch: 6| Step: 7
Training loss: 0.2004288776316662
Validation loss: 2.3612470864751502

Epoch: 6| Step: 8
Training loss: 0.1299845075087314
Validation loss: 2.339615352522804

Epoch: 6| Step: 9
Training loss: 0.07519512981541228
Validation loss: 2.3751729633450758

Epoch: 6| Step: 10
Training loss: 0.08957331320905579
Validation loss: 2.344368850878801

Epoch: 6| Step: 11
Training loss: 0.21884420614318942
Validation loss: 2.3463044671354885

Epoch: 6| Step: 12
Training loss: 0.0724302491651904
Validation loss: 2.346687289878109

Epoch: 6| Step: 13
Training loss: 0.05927385173799676
Validation loss: 2.3263296254967805

Epoch: 545| Step: 0
Training loss: 0.07904361438982399
Validation loss: 2.3339544017595584

Epoch: 6| Step: 1
Training loss: 0.14279379275562545
Validation loss: 2.341842551164257

Epoch: 6| Step: 2
Training loss: 0.060567171786383774
Validation loss: 2.3371648310272533

Epoch: 6| Step: 3
Training loss: 0.13047103051802256
Validation loss: 2.3443436186026023

Epoch: 6| Step: 4
Training loss: 0.08481144633478467
Validation loss: 2.337053936546377

Epoch: 6| Step: 5
Training loss: 0.08874466068197634
Validation loss: 2.3437834881540134

Epoch: 6| Step: 6
Training loss: 0.09608839299226321
Validation loss: 2.3522085383657676

Epoch: 6| Step: 7
Training loss: 0.08024092442767554
Validation loss: 2.3308695436653166

Epoch: 6| Step: 8
Training loss: 0.10815975614594482
Validation loss: 2.3632805215700037

Epoch: 6| Step: 9
Training loss: 0.08350586136911725
Validation loss: 2.378222194083268

Epoch: 6| Step: 10
Training loss: 0.17102723853775403
Validation loss: 2.347211615380367

Epoch: 6| Step: 11
Training loss: 0.24858055374634597
Validation loss: 2.320293803336677

Epoch: 6| Step: 12
Training loss: 0.1978146589230666
Validation loss: 2.3391457434381087

Epoch: 6| Step: 13
Training loss: 0.15057478812734984
Validation loss: 2.329404433261879

Epoch: 546| Step: 0
Training loss: 0.17502670999607586
Validation loss: 2.3559486453875005

Epoch: 6| Step: 1
Training loss: 0.08751582126122079
Validation loss: 2.337631847406773

Epoch: 6| Step: 2
Training loss: 0.13041776186155152
Validation loss: 2.3194538669969127

Epoch: 6| Step: 3
Training loss: 0.1323435160512106
Validation loss: 2.326670995717009

Epoch: 6| Step: 4
Training loss: 0.2000628149214235
Validation loss: 2.351091935159783

Epoch: 6| Step: 5
Training loss: 0.06224044721228651
Validation loss: 2.35743517479876

Epoch: 6| Step: 6
Training loss: 0.14774806130213625
Validation loss: 2.3702389501998975

Epoch: 6| Step: 7
Training loss: 0.1256072078270653
Validation loss: 2.351220002921993

Epoch: 6| Step: 8
Training loss: 0.14350581472525303
Validation loss: 2.3548988748504227

Epoch: 6| Step: 9
Training loss: 0.1370967272280209
Validation loss: 2.364075554188804

Epoch: 6| Step: 10
Training loss: 0.1284395497105159
Validation loss: 2.3543094176464985

Epoch: 6| Step: 11
Training loss: 0.10908792491758836
Validation loss: 2.3369170836901496

Epoch: 6| Step: 12
Training loss: 0.13093849181753267
Validation loss: 2.320192691575187

Epoch: 6| Step: 13
Training loss: 0.1469348909644554
Validation loss: 2.329355400212958

Epoch: 547| Step: 0
Training loss: 0.13947390607191876
Validation loss: 2.288396792634011

Epoch: 6| Step: 1
Training loss: 0.07698343232036232
Validation loss: 2.331339654229773

Epoch: 6| Step: 2
Training loss: 0.15419680935968624
Validation loss: 2.3305870109502815

Epoch: 6| Step: 3
Training loss: 0.14785714006674872
Validation loss: 2.326723562146061

Epoch: 6| Step: 4
Training loss: 0.22162696446679295
Validation loss: 2.31719066834373

Epoch: 6| Step: 5
Training loss: 0.0868313749644556
Validation loss: 2.332287155761308

Epoch: 6| Step: 6
Training loss: 0.11771074938896746
Validation loss: 2.3786939241346063

Epoch: 6| Step: 7
Training loss: 0.09091096885933295
Validation loss: 2.3603455073363953

Epoch: 6| Step: 8
Training loss: 0.11359619065854343
Validation loss: 2.345472689067326

Epoch: 6| Step: 9
Training loss: 0.10800861165197702
Validation loss: 2.3741252564155833

Epoch: 6| Step: 10
Training loss: 0.14500594797965738
Validation loss: 2.4025768450738263

Epoch: 6| Step: 11
Training loss: 0.2057038525004549
Validation loss: 2.3964404591953463

Epoch: 6| Step: 12
Training loss: 0.20951247114763163
Validation loss: 2.3893811650013568

Epoch: 6| Step: 13
Training loss: 0.1187653807667802
Validation loss: 2.3749603501331036

Epoch: 548| Step: 0
Training loss: 0.27184673524141195
Validation loss: 2.3624281355403673

Epoch: 6| Step: 1
Training loss: 0.13433363688174724
Validation loss: 2.3356740245086285

Epoch: 6| Step: 2
Training loss: 0.1043535096635938
Validation loss: 2.326092837585092

Epoch: 6| Step: 3
Training loss: 0.17061653865542536
Validation loss: 2.3002498389137607

Epoch: 6| Step: 4
Training loss: 0.1309592520620085
Validation loss: 2.331229989782099

Epoch: 6| Step: 5
Training loss: 0.20136409205842704
Validation loss: 2.293672441962541

Epoch: 6| Step: 6
Training loss: 0.17060160335011498
Validation loss: 2.300804497550368

Epoch: 6| Step: 7
Training loss: 0.1150261525227061
Validation loss: 2.3195726293611383

Epoch: 6| Step: 8
Training loss: 0.07877154442531702
Validation loss: 2.3321289480662517

Epoch: 6| Step: 9
Training loss: 0.14527311534799714
Validation loss: 2.3495860009595013

Epoch: 6| Step: 10
Training loss: 0.17679236269328438
Validation loss: 2.3325471439852468

Epoch: 6| Step: 11
Training loss: 0.1521836931665066
Validation loss: 2.367340234581904

Epoch: 6| Step: 12
Training loss: 0.11427861211839245
Validation loss: 2.3430183586726367

Epoch: 6| Step: 13
Training loss: 0.06306341037740569
Validation loss: 2.340328550010633

Epoch: 549| Step: 0
Training loss: 0.10847714719659406
Validation loss: 2.3366245015835796

Epoch: 6| Step: 1
Training loss: 0.18642373940662024
Validation loss: 2.3422981966824357

Epoch: 6| Step: 2
Training loss: 0.09838709581499532
Validation loss: 2.322588946357258

Epoch: 6| Step: 3
Training loss: 0.16790009359620686
Validation loss: 2.3113353826442395

Epoch: 6| Step: 4
Training loss: 0.09571979338624931
Validation loss: 2.299550479156659

Epoch: 6| Step: 5
Training loss: 0.2175418580406992
Validation loss: 2.322116431622479

Epoch: 6| Step: 6
Training loss: 0.13502952748369512
Validation loss: 2.313389033819938

Epoch: 6| Step: 7
Training loss: 0.118792800029148
Validation loss: 2.2923990367726708

Epoch: 6| Step: 8
Training loss: 0.15018050886004083
Validation loss: 2.3196399054049044

Epoch: 6| Step: 9
Training loss: 0.1226758320174699
Validation loss: 2.33536975708066

Epoch: 6| Step: 10
Training loss: 0.10251396871233771
Validation loss: 2.3572840017987353

Epoch: 6| Step: 11
Training loss: 0.14618999146698722
Validation loss: 2.338224476149422

Epoch: 6| Step: 12
Training loss: 0.1840542233456918
Validation loss: 2.335534818075813

Epoch: 6| Step: 13
Training loss: 0.06528104794239531
Validation loss: 2.3407725289166272

Epoch: 550| Step: 0
Training loss: 0.16171471687484595
Validation loss: 2.3434013101849667

Epoch: 6| Step: 1
Training loss: 0.10125183311321807
Validation loss: 2.297265894937873

Epoch: 6| Step: 2
Training loss: 0.11795812584234323
Validation loss: 2.3000872307438316

Epoch: 6| Step: 3
Training loss: 0.13174926593248476
Validation loss: 2.3060686342215124

Epoch: 6| Step: 4
Training loss: 0.11938171538842467
Validation loss: 2.2814357073448908

Epoch: 6| Step: 5
Training loss: 0.11300612616179091
Validation loss: 2.276943636770052

Epoch: 6| Step: 6
Training loss: 0.07951862565703753
Validation loss: 2.301986360064214

Epoch: 6| Step: 7
Training loss: 0.11215099100615986
Validation loss: 2.3111080114177134

Epoch: 6| Step: 8
Training loss: 0.09959652761746055
Validation loss: 2.3142563597396757

Epoch: 6| Step: 9
Training loss: 0.17450220159997232
Validation loss: 2.3404197095619166

Epoch: 6| Step: 10
Training loss: 0.2222796735698264
Validation loss: 2.320996986176616

Epoch: 6| Step: 11
Training loss: 0.15899873757685917
Validation loss: 2.3026924899409957

Epoch: 6| Step: 12
Training loss: 0.10473901349517635
Validation loss: 2.324044216100592

Epoch: 6| Step: 13
Training loss: 0.06427799620944875
Validation loss: 2.314827175677076

Epoch: 551| Step: 0
Training loss: 0.18306989197020768
Validation loss: 2.3321886668223413

Epoch: 6| Step: 1
Training loss: 0.08893330179239357
Validation loss: 2.333152548280496

Epoch: 6| Step: 2
Training loss: 0.1377977233866658
Validation loss: 2.3290648902101965

Epoch: 6| Step: 3
Training loss: 0.18224457859222612
Validation loss: 2.3096213756158512

Epoch: 6| Step: 4
Training loss: 0.15723862809034994
Validation loss: 2.309504659056416

Epoch: 6| Step: 5
Training loss: 0.09599472890913957
Validation loss: 2.3465437603823545

Epoch: 6| Step: 6
Training loss: 0.09523096192700589
Validation loss: 2.3285614307145757

Epoch: 6| Step: 7
Training loss: 0.06026743616387259
Validation loss: 2.3042078755576414

Epoch: 6| Step: 8
Training loss: 0.16060484885933826
Validation loss: 2.3243424406545294

Epoch: 6| Step: 9
Training loss: 0.13987726523855118
Validation loss: 2.317400214543971

Epoch: 6| Step: 10
Training loss: 0.15027404576796485
Validation loss: 2.313925803809875

Epoch: 6| Step: 11
Training loss: 0.1395394827217706
Validation loss: 2.3319708945396855

Epoch: 6| Step: 12
Training loss: 0.13800078522330944
Validation loss: 2.3362106567952674

Epoch: 6| Step: 13
Training loss: 0.14935468603412694
Validation loss: 2.3426775671164597

Epoch: 552| Step: 0
Training loss: 0.11995201850312202
Validation loss: 2.3684178663809368

Epoch: 6| Step: 1
Training loss: 0.11965627162666155
Validation loss: 2.360435427362251

Epoch: 6| Step: 2
Training loss: 0.20296263624620056
Validation loss: 2.39060649721236

Epoch: 6| Step: 3
Training loss: 0.10241438688435908
Validation loss: 2.380369227860621

Epoch: 6| Step: 4
Training loss: 0.05896182086925274
Validation loss: 2.338213992302827

Epoch: 6| Step: 5
Training loss: 0.1688070006705289
Validation loss: 2.3388823208047533

Epoch: 6| Step: 6
Training loss: 0.19798231709154146
Validation loss: 2.3104231048881605

Epoch: 6| Step: 7
Training loss: 0.13299717405461228
Validation loss: 2.30743748258653

Epoch: 6| Step: 8
Training loss: 0.14903768493820357
Validation loss: 2.2913361752015393

Epoch: 6| Step: 9
Training loss: 0.10563169801653254
Validation loss: 2.28778895603929

Epoch: 6| Step: 10
Training loss: 0.11930775254927242
Validation loss: 2.2929082722298055

Epoch: 6| Step: 11
Training loss: 0.07586055494426001
Validation loss: 2.2770668398539717

Epoch: 6| Step: 12
Training loss: 0.10901998054493549
Validation loss: 2.300615333622201

Epoch: 6| Step: 13
Training loss: 0.1391884557492485
Validation loss: 2.283132336438104

Epoch: 553| Step: 0
Training loss: 0.1266901961492781
Validation loss: 2.260775770690399

Epoch: 6| Step: 1
Training loss: 0.11350223756361681
Validation loss: 2.331585468595756

Epoch: 6| Step: 2
Training loss: 0.14699032192582176
Validation loss: 2.3051129679252558

Epoch: 6| Step: 3
Training loss: 0.13462211043852784
Validation loss: 2.316350981364213

Epoch: 6| Step: 4
Training loss: 0.10226232332476173
Validation loss: 2.328243970807751

Epoch: 6| Step: 5
Training loss: 0.10482606400382637
Validation loss: 2.3463383886546048

Epoch: 6| Step: 6
Training loss: 0.12723519460823318
Validation loss: 2.3643743758693456

Epoch: 6| Step: 7
Training loss: 0.11276641549664122
Validation loss: 2.3636119741629606

Epoch: 6| Step: 8
Training loss: 0.22242988825232232
Validation loss: 2.3722087604041833

Epoch: 6| Step: 9
Training loss: 0.12769321250880825
Validation loss: 2.3866145369330027

Epoch: 6| Step: 10
Training loss: 0.10647552831316734
Validation loss: 2.363773353764841

Epoch: 6| Step: 11
Training loss: 0.1459447585471574
Validation loss: 2.3639036821508403

Epoch: 6| Step: 12
Training loss: 0.07308458219440842
Validation loss: 2.3619574713044957

Epoch: 6| Step: 13
Training loss: 0.13333341178171512
Validation loss: 2.3471095977657193

Epoch: 554| Step: 0
Training loss: 0.09985038174139335
Validation loss: 2.3399911042798016

Epoch: 6| Step: 1
Training loss: 0.10416194388491656
Validation loss: 2.324684198627442

Epoch: 6| Step: 2
Training loss: 0.14769865920566252
Validation loss: 2.3147430317275526

Epoch: 6| Step: 3
Training loss: 0.1688465480205467
Validation loss: 2.34102631943609

Epoch: 6| Step: 4
Training loss: 0.09164874319751196
Validation loss: 2.359089729346752

Epoch: 6| Step: 5
Training loss: 0.2146152321398456
Validation loss: 2.370255358493096

Epoch: 6| Step: 6
Training loss: 0.14023366093785822
Validation loss: 2.3606528543417453

Epoch: 6| Step: 7
Training loss: 0.0732372631960747
Validation loss: 2.3681697447640646

Epoch: 6| Step: 8
Training loss: 0.11566470904493265
Validation loss: 2.399553683826751

Epoch: 6| Step: 9
Training loss: 0.12163825056665556
Validation loss: 2.3910847060423657

Epoch: 6| Step: 10
Training loss: 0.12283405564323643
Validation loss: 2.3756994891554934

Epoch: 6| Step: 11
Training loss: 0.15892778251656503
Validation loss: 2.342116764576657

Epoch: 6| Step: 12
Training loss: 0.12852417068128552
Validation loss: 2.3200313115579454

Epoch: 6| Step: 13
Training loss: 0.18823904181688147
Validation loss: 2.353545033233674

Epoch: 555| Step: 0
Training loss: 0.10965114457662196
Validation loss: 2.3392786105022103

Epoch: 6| Step: 1
Training loss: 0.13521193806888643
Validation loss: 2.3388392640952866

Epoch: 6| Step: 2
Training loss: 0.18510471665023934
Validation loss: 2.3289833421853565

Epoch: 6| Step: 3
Training loss: 0.09445571028971005
Validation loss: 2.3194094410395776

Epoch: 6| Step: 4
Training loss: 0.17957714050402815
Validation loss: 2.317173666889897

Epoch: 6| Step: 5
Training loss: 0.15444129510706622
Validation loss: 2.350209526761146

Epoch: 6| Step: 6
Training loss: 0.12802807467999064
Validation loss: 2.332496878418508

Epoch: 6| Step: 7
Training loss: 0.08570884499461275
Validation loss: 2.3370020939259017

Epoch: 6| Step: 8
Training loss: 0.11593051945295083
Validation loss: 2.347162437158963

Epoch: 6| Step: 9
Training loss: 0.13267813224624445
Validation loss: 2.35283347699331

Epoch: 6| Step: 10
Training loss: 0.17162396239399774
Validation loss: 2.370528587119533

Epoch: 6| Step: 11
Training loss: 0.14699922365880505
Validation loss: 2.3494861088902277

Epoch: 6| Step: 12
Training loss: 0.15556772402715896
Validation loss: 2.3522671070541805

Epoch: 6| Step: 13
Training loss: 0.22236224054051965
Validation loss: 2.330747885579317

Epoch: 556| Step: 0
Training loss: 0.10323406109560793
Validation loss: 2.343598272409796

Epoch: 6| Step: 1
Training loss: 0.1610934353889183
Validation loss: 2.33133038752231

Epoch: 6| Step: 2
Training loss: 0.14967116506678768
Validation loss: 2.3110461261316164

Epoch: 6| Step: 3
Training loss: 0.16552022057794552
Validation loss: 2.3352652977146637

Epoch: 6| Step: 4
Training loss: 0.12077381184536767
Validation loss: 2.36670430930655

Epoch: 6| Step: 5
Training loss: 0.09822894968445088
Validation loss: 2.334168733597783

Epoch: 6| Step: 6
Training loss: 0.16747244990867763
Validation loss: 2.3662460416839775

Epoch: 6| Step: 7
Training loss: 0.14935199221184886
Validation loss: 2.379497688473628

Epoch: 6| Step: 8
Training loss: 0.1595212221216452
Validation loss: 2.378056768110364

Epoch: 6| Step: 9
Training loss: 0.17819931713553
Validation loss: 2.3342473460019213

Epoch: 6| Step: 10
Training loss: 0.1142622588180982
Validation loss: 2.334987555739433

Epoch: 6| Step: 11
Training loss: 0.1782697850451717
Validation loss: 2.3523037113352205

Epoch: 6| Step: 12
Training loss: 0.08674452351418266
Validation loss: 2.34293543070002

Epoch: 6| Step: 13
Training loss: 0.14205266197299146
Validation loss: 2.321385048673855

Epoch: 557| Step: 0
Training loss: 0.18023340601137675
Validation loss: 2.3226702575204916

Epoch: 6| Step: 1
Training loss: 0.08980371785812277
Validation loss: 2.3014051108061975

Epoch: 6| Step: 2
Training loss: 0.07848221948360845
Validation loss: 2.3048624641436493

Epoch: 6| Step: 3
Training loss: 0.12108845853011685
Validation loss: 2.3197575453760346

Epoch: 6| Step: 4
Training loss: 0.14918778307879488
Validation loss: 2.306143140914201

Epoch: 6| Step: 5
Training loss: 0.1089465186639424
Validation loss: 2.313793489105272

Epoch: 6| Step: 6
Training loss: 0.144838431979824
Validation loss: 2.3298873359094263

Epoch: 6| Step: 7
Training loss: 0.1428109254165925
Validation loss: 2.3435246042685933

Epoch: 6| Step: 8
Training loss: 0.16232205423108326
Validation loss: 2.3625189095112735

Epoch: 6| Step: 9
Training loss: 0.09736077430734562
Validation loss: 2.371232287897085

Epoch: 6| Step: 10
Training loss: 0.10434422311192887
Validation loss: 2.374874099779506

Epoch: 6| Step: 11
Training loss: 0.14435570598258157
Validation loss: 2.3644535274274228

Epoch: 6| Step: 12
Training loss: 0.07990923376968588
Validation loss: 2.382917700209869

Epoch: 6| Step: 13
Training loss: 0.07149033677927259
Validation loss: 2.383658483432371

Epoch: 558| Step: 0
Training loss: 0.09725862615751957
Validation loss: 2.351195582341433

Epoch: 6| Step: 1
Training loss: 0.2521284809089753
Validation loss: 2.353295371811978

Epoch: 6| Step: 2
Training loss: 0.13348704030411168
Validation loss: 2.342836846103402

Epoch: 6| Step: 3
Training loss: 0.1316800219843624
Validation loss: 2.3011721027581573

Epoch: 6| Step: 4
Training loss: 0.22295480922485497
Validation loss: 2.3194540593152246

Epoch: 6| Step: 5
Training loss: 0.12648205290247969
Validation loss: 2.3072043404002183

Epoch: 6| Step: 6
Training loss: 0.16297359366090303
Validation loss: 2.315002730049092

Epoch: 6| Step: 7
Training loss: 0.1293489555851436
Validation loss: 2.3609778051929937

Epoch: 6| Step: 8
Training loss: 0.20764012142777405
Validation loss: 2.359475929901016

Epoch: 6| Step: 9
Training loss: 0.13311642344925093
Validation loss: 2.3677996611439696

Epoch: 6| Step: 10
Training loss: 0.20948300636170486
Validation loss: 2.3615827026327207

Epoch: 6| Step: 11
Training loss: 0.13138145947750657
Validation loss: 2.37004773580767

Epoch: 6| Step: 12
Training loss: 0.09948373799863776
Validation loss: 2.3904958850026357

Epoch: 6| Step: 13
Training loss: 0.1536222327959314
Validation loss: 2.3348316056913836

Epoch: 559| Step: 0
Training loss: 0.0930841212909868
Validation loss: 2.3113317512517133

Epoch: 6| Step: 1
Training loss: 0.11960857763591476
Validation loss: 2.3192385450379738

Epoch: 6| Step: 2
Training loss: 0.10362125351676685
Validation loss: 2.31257648225138

Epoch: 6| Step: 3
Training loss: 0.15790378248648618
Validation loss: 2.2884779626190506

Epoch: 6| Step: 4
Training loss: 0.12158013920671466
Validation loss: 2.276557394429873

Epoch: 6| Step: 5
Training loss: 0.2003451554167736
Validation loss: 2.276143727546589

Epoch: 6| Step: 6
Training loss: 0.21442487805109425
Validation loss: 2.292288165869558

Epoch: 6| Step: 7
Training loss: 0.2386968225030517
Validation loss: 2.2644571804439457

Epoch: 6| Step: 8
Training loss: 0.24575975247684664
Validation loss: 2.3204216562494113

Epoch: 6| Step: 9
Training loss: 0.1296001024936047
Validation loss: 2.3565086211173525

Epoch: 6| Step: 10
Training loss: 0.0936311723726991
Validation loss: 2.33893768562588

Epoch: 6| Step: 11
Training loss: 0.09090677882906516
Validation loss: 2.3753097561020784

Epoch: 6| Step: 12
Training loss: 0.14960773855564355
Validation loss: 2.327374994554916

Epoch: 6| Step: 13
Training loss: 0.19015032499638163
Validation loss: 2.3222714085315737

Epoch: 560| Step: 0
Training loss: 0.18626047741778898
Validation loss: 2.339087059922364

Epoch: 6| Step: 1
Training loss: 0.11627941758558115
Validation loss: 2.309379850094936

Epoch: 6| Step: 2
Training loss: 0.2142702771910437
Validation loss: 2.32370846445335

Epoch: 6| Step: 3
Training loss: 0.08692063885357865
Validation loss: 2.3463893902327815

Epoch: 6| Step: 4
Training loss: 0.24690501145338398
Validation loss: 2.3612175722227113

Epoch: 6| Step: 5
Training loss: 0.17557935776650735
Validation loss: 2.3097959260682788

Epoch: 6| Step: 6
Training loss: 0.09320651912344678
Validation loss: 2.3270915539416626

Epoch: 6| Step: 7
Training loss: 0.13774842394552003
Validation loss: 2.3555146236024207

Epoch: 6| Step: 8
Training loss: 0.13350810880805036
Validation loss: 2.298878785500574

Epoch: 6| Step: 9
Training loss: 0.11038042636230552
Validation loss: 2.284435783030845

Epoch: 6| Step: 10
Training loss: 0.10593479995606293
Validation loss: 2.2666551374628403

Epoch: 6| Step: 11
Training loss: 0.13546452150488297
Validation loss: 2.272767806479442

Epoch: 6| Step: 12
Training loss: 0.22403414500288651
Validation loss: 2.257681377452744

Epoch: 6| Step: 13
Training loss: 0.21117272330624262
Validation loss: 2.2840443636002026

Epoch: 561| Step: 0
Training loss: 0.09495688487435558
Validation loss: 2.314621990802524

Epoch: 6| Step: 1
Training loss: 0.22611788993198878
Validation loss: 2.2921414531376842

Epoch: 6| Step: 2
Training loss: 0.17123711950005194
Validation loss: 2.330578799452076

Epoch: 6| Step: 3
Training loss: 0.06610440627106856
Validation loss: 2.3406110618147062

Epoch: 6| Step: 4
Training loss: 0.14592152225220145
Validation loss: 2.3490315520424825

Epoch: 6| Step: 5
Training loss: 0.23563735672754804
Validation loss: 2.3790289966073543

Epoch: 6| Step: 6
Training loss: 0.19261581330668862
Validation loss: 2.3752635082094056

Epoch: 6| Step: 7
Training loss: 0.25263094841995787
Validation loss: 2.389399472349395

Epoch: 6| Step: 8
Training loss: 0.21522843859840524
Validation loss: 2.352873085695272

Epoch: 6| Step: 9
Training loss: 0.1503175706662418
Validation loss: 2.347030794661497

Epoch: 6| Step: 10
Training loss: 0.10620416220477981
Validation loss: 2.338269750926711

Epoch: 6| Step: 11
Training loss: 0.08413656993576343
Validation loss: 2.315988856057127

Epoch: 6| Step: 12
Training loss: 0.1696314357465751
Validation loss: 2.294308045384056

Epoch: 6| Step: 13
Training loss: 0.17713469690701758
Validation loss: 2.294773254958194

Epoch: 562| Step: 0
Training loss: 0.16792362183545845
Validation loss: 2.2879029392772567

Epoch: 6| Step: 1
Training loss: 0.2024440998904767
Validation loss: 2.2981984534401962

Epoch: 6| Step: 2
Training loss: 0.15076031391286404
Validation loss: 2.283642775855953

Epoch: 6| Step: 3
Training loss: 0.19261426605874593
Validation loss: 2.332278617191406

Epoch: 6| Step: 4
Training loss: 0.1427659013170806
Validation loss: 2.31669049000289

Epoch: 6| Step: 5
Training loss: 0.13479513729757833
Validation loss: 2.3337099420354455

Epoch: 6| Step: 6
Training loss: 0.17027553389033875
Validation loss: 2.348820332608269

Epoch: 6| Step: 7
Training loss: 0.16472276591430043
Validation loss: 2.337989642398285

Epoch: 6| Step: 8
Training loss: 0.20497788295414313
Validation loss: 2.3400946022538403

Epoch: 6| Step: 9
Training loss: 0.15608825060079765
Validation loss: 2.339891234819334

Epoch: 6| Step: 10
Training loss: 0.1899509868804296
Validation loss: 2.3330939392772114

Epoch: 6| Step: 11
Training loss: 0.25456640547545883
Validation loss: 2.3302935735583907

Epoch: 6| Step: 12
Training loss: 0.20173770069426933
Validation loss: 2.321118215977445

Epoch: 6| Step: 13
Training loss: 0.14223368072927006
Validation loss: 2.3362018313416657

Epoch: 563| Step: 0
Training loss: 0.1849606539151073
Validation loss: 2.3188652197680724

Epoch: 6| Step: 1
Training loss: 0.10075188345692718
Validation loss: 2.3197347176362886

Epoch: 6| Step: 2
Training loss: 0.18565450859248378
Validation loss: 2.304952281927505

Epoch: 6| Step: 3
Training loss: 0.1931674370697524
Validation loss: 2.314555389095904

Epoch: 6| Step: 4
Training loss: 0.13614703942805406
Validation loss: 2.290383814585731

Epoch: 6| Step: 5
Training loss: 0.11073301435420237
Validation loss: 2.319392438717384

Epoch: 6| Step: 6
Training loss: 0.20193756087811993
Validation loss: 2.330948140856152

Epoch: 6| Step: 7
Training loss: 0.26921440242770517
Validation loss: 2.334434282139002

Epoch: 6| Step: 8
Training loss: 0.21341822805290286
Validation loss: 2.338916691396999

Epoch: 6| Step: 9
Training loss: 0.13613346707201737
Validation loss: 2.3361580991771382

Epoch: 6| Step: 10
Training loss: 0.11359231268433864
Validation loss: 2.323068229122904

Epoch: 6| Step: 11
Training loss: 0.3555210200854233
Validation loss: 2.3213933534327342

Epoch: 6| Step: 12
Training loss: 0.13660137724107066
Validation loss: 2.3611514200448975

Epoch: 6| Step: 13
Training loss: 0.1290599383661091
Validation loss: 2.3434229020232484

Epoch: 564| Step: 0
Training loss: 0.1260234021189203
Validation loss: 2.3534811424575355

Epoch: 6| Step: 1
Training loss: 0.1757938062633783
Validation loss: 2.3863475069032654

Epoch: 6| Step: 2
Training loss: 0.38097923544622025
Validation loss: 2.387515841968775

Epoch: 6| Step: 3
Training loss: 0.2055409612787241
Validation loss: 2.4058661823975482

Epoch: 6| Step: 4
Training loss: 0.3354201547172787
Validation loss: 2.4216111837680154

Epoch: 6| Step: 5
Training loss: 0.2635573809666869
Validation loss: 2.41914790827246

Epoch: 6| Step: 6
Training loss: 0.2770450084516476
Validation loss: 2.415931683953815

Epoch: 6| Step: 7
Training loss: 0.17180074366489334
Validation loss: 2.3803752137793475

Epoch: 6| Step: 8
Training loss: 0.24971227927543102
Validation loss: 2.3491289506884687

Epoch: 6| Step: 9
Training loss: 0.2237620001377374
Validation loss: 2.3457323153314475

Epoch: 6| Step: 10
Training loss: 0.16306236804892485
Validation loss: 2.3503572706447087

Epoch: 6| Step: 11
Training loss: 0.298748005616941
Validation loss: 2.3373728080925913

Epoch: 6| Step: 12
Training loss: 0.17494359171674423
Validation loss: 2.355958303844056

Epoch: 6| Step: 13
Training loss: 0.18362654737972237
Validation loss: 2.385292290357841

Epoch: 565| Step: 0
Training loss: 0.25609020565855
Validation loss: 2.3953301763229167

Epoch: 6| Step: 1
Training loss: 0.3035073656016363
Validation loss: 2.374444524186711

Epoch: 6| Step: 2
Training loss: 0.2416006715799741
Validation loss: 2.367002134654211

Epoch: 6| Step: 3
Training loss: 0.22198837902608845
Validation loss: 2.3402440944113247

Epoch: 6| Step: 4
Training loss: 0.23157705106847196
Validation loss: 2.3199568558404016

Epoch: 6| Step: 5
Training loss: 0.19611211174034068
Validation loss: 2.302514654765839

Epoch: 6| Step: 6
Training loss: 0.1793086058491958
Validation loss: 2.315017075301246

Epoch: 6| Step: 7
Training loss: 0.31255201860446363
Validation loss: 2.3264560590791428

Epoch: 6| Step: 8
Training loss: 0.2612408217045301
Validation loss: 2.3070778607517637

Epoch: 6| Step: 9
Training loss: 0.44574037708800374
Validation loss: 2.35156547947659

Epoch: 6| Step: 10
Training loss: 0.22303457075877606
Validation loss: 2.3560738486023913

Epoch: 6| Step: 11
Training loss: 0.23646035711679964
Validation loss: 2.3705166044713644

Epoch: 6| Step: 12
Training loss: 0.2682935520166501
Validation loss: 2.3716253712590265

Epoch: 6| Step: 13
Training loss: 0.1942254236260885
Validation loss: 2.3937711475026893

Epoch: 566| Step: 0
Training loss: 0.288880019970057
Validation loss: 2.36578990239993

Epoch: 6| Step: 1
Training loss: 0.23172509710116632
Validation loss: 2.3379860524055274

Epoch: 6| Step: 2
Training loss: 0.15980551275367968
Validation loss: 2.309079439387805

Epoch: 6| Step: 3
Training loss: 0.2477517512449158
Validation loss: 2.320640401858393

Epoch: 6| Step: 4
Training loss: 0.3786484932926293
Validation loss: 2.313048151707155

Epoch: 6| Step: 5
Training loss: 0.24738111284865666
Validation loss: 2.29582191553629

Epoch: 6| Step: 6
Training loss: 0.1737355189154967
Validation loss: 2.323520412166045

Epoch: 6| Step: 7
Training loss: 0.2173544955254008
Validation loss: 2.3465185351051656

Epoch: 6| Step: 8
Training loss: 0.2024327365989669
Validation loss: 2.3573619760393414

Epoch: 6| Step: 9
Training loss: 0.23592452588314153
Validation loss: 2.371131144293605

Epoch: 6| Step: 10
Training loss: 0.25292294172916435
Validation loss: 2.3996857033984744

Epoch: 6| Step: 11
Training loss: 0.2371565116773311
Validation loss: 2.3468226422795273

Epoch: 6| Step: 12
Training loss: 0.16161761323344728
Validation loss: 2.3263271404608434

Epoch: 6| Step: 13
Training loss: 0.14201261119013858
Validation loss: 2.3173630235384

Epoch: 567| Step: 0
Training loss: 0.22313427223312293
Validation loss: 2.269942363325145

Epoch: 6| Step: 1
Training loss: 0.19658231891548497
Validation loss: 2.2851356400944414

Epoch: 6| Step: 2
Training loss: 0.26057049817194256
Validation loss: 2.2909991879875364

Epoch: 6| Step: 3
Training loss: 0.20863394903528007
Validation loss: 2.3072349994896655

Epoch: 6| Step: 4
Training loss: 0.19769663982326416
Validation loss: 2.325953859017465

Epoch: 6| Step: 5
Training loss: 0.21424946520948934
Validation loss: 2.35578384051026

Epoch: 6| Step: 6
Training loss: 0.18869136764893976
Validation loss: 2.374799443592107

Epoch: 6| Step: 7
Training loss: 0.310269453783622
Validation loss: 2.3796511164100727

Epoch: 6| Step: 8
Training loss: 0.23880956271296264
Validation loss: 2.3797961631428257

Epoch: 6| Step: 9
Training loss: 0.2776941047585314
Validation loss: 2.3542943432163956

Epoch: 6| Step: 10
Training loss: 0.25730806187788147
Validation loss: 2.307190524370773

Epoch: 6| Step: 11
Training loss: 0.22842568477859052
Validation loss: 2.2716249458015403

Epoch: 6| Step: 12
Training loss: 0.2109148755126232
Validation loss: 2.2724313057369887

Epoch: 6| Step: 13
Training loss: 0.3949457200998869
Validation loss: 2.2474886313347793

Epoch: 568| Step: 0
Training loss: 0.3515446764348537
Validation loss: 2.2546858151072335

Epoch: 6| Step: 1
Training loss: 0.24515465529818492
Validation loss: 2.285321877935562

Epoch: 6| Step: 2
Training loss: 0.2924400518191475
Validation loss: 2.3548761645906544

Epoch: 6| Step: 3
Training loss: 0.335841630962527
Validation loss: 2.3748661126575947

Epoch: 6| Step: 4
Training loss: 0.32497004132473245
Validation loss: 2.3962754821115704

Epoch: 6| Step: 5
Training loss: 0.4038726128566967
Validation loss: 2.4026295028188644

Epoch: 6| Step: 6
Training loss: 0.5458304647802247
Validation loss: 2.3896951987193327

Epoch: 6| Step: 7
Training loss: 0.5331952160818118
Validation loss: 2.393032579320406

Epoch: 6| Step: 8
Training loss: 0.297833476533697
Validation loss: 2.3873098916971505

Epoch: 6| Step: 9
Training loss: 0.48617071645366633
Validation loss: 2.410689749969667

Epoch: 6| Step: 10
Training loss: 0.44155725917419253
Validation loss: 2.4492284823619093

Epoch: 6| Step: 11
Training loss: 0.533571193100999
Validation loss: 2.45391356694496

Epoch: 6| Step: 12
Training loss: 0.496004411958484
Validation loss: 2.4255361838941027

Epoch: 6| Step: 13
Training loss: 0.3633601195336577
Validation loss: 2.3736427003746345

Epoch: 569| Step: 0
Training loss: 0.298770761905661
Validation loss: 2.3788145376212784

Epoch: 6| Step: 1
Training loss: 0.31693287574826373
Validation loss: 2.310495227626247

Epoch: 6| Step: 2
Training loss: 0.3595327984553965
Validation loss: 2.2863731558086102

Epoch: 6| Step: 3
Training loss: 0.3693176127809529
Validation loss: 2.308519653332745

Epoch: 6| Step: 4
Training loss: 0.22572135988955602
Validation loss: 2.3579448170197237

Epoch: 6| Step: 5
Training loss: 0.36780082936922026
Validation loss: 2.375049863636196

Epoch: 6| Step: 6
Training loss: 0.37020762201790786
Validation loss: 2.398727491384617

Epoch: 6| Step: 7
Training loss: 0.534864304259309
Validation loss: 2.3502883192736546

Epoch: 6| Step: 8
Training loss: 0.38305335350401076
Validation loss: 2.317780118030845

Epoch: 6| Step: 9
Training loss: 0.3803667256761888
Validation loss: 2.281964022734926

Epoch: 6| Step: 10
Training loss: 0.3553011782208723
Validation loss: 2.25779451889007

Epoch: 6| Step: 11
Training loss: 0.34755700012682006
Validation loss: 2.2940499458014343

Epoch: 6| Step: 12
Training loss: 0.18494629283318575
Validation loss: 2.3224321902421736

Epoch: 6| Step: 13
Training loss: 0.28417946464818233
Validation loss: 2.3369381726733867

Epoch: 570| Step: 0
Training loss: 0.20483025603146468
Validation loss: 2.353302301368832

Epoch: 6| Step: 1
Training loss: 0.33585148087084604
Validation loss: 2.395040394956182

Epoch: 6| Step: 2
Training loss: 0.3067984205361981
Validation loss: 2.358806504402176

Epoch: 6| Step: 3
Training loss: 0.2807252810509501
Validation loss: 2.3646604471090207

Epoch: 6| Step: 4
Training loss: 0.28898838742727656
Validation loss: 2.3734356272987633

Epoch: 6| Step: 5
Training loss: 0.3309705509183257
Validation loss: 2.332684516427723

Epoch: 6| Step: 6
Training loss: 0.31715826454165524
Validation loss: 2.3054593525732456

Epoch: 6| Step: 7
Training loss: 0.3779627270512379
Validation loss: 2.3276139875586663

Epoch: 6| Step: 8
Training loss: 0.199588796596242
Validation loss: 2.3076114633379383

Epoch: 6| Step: 9
Training loss: 0.2739106716401894
Validation loss: 2.2964946573389984

Epoch: 6| Step: 10
Training loss: 0.40149131767414925
Validation loss: 2.3241024278800295

Epoch: 6| Step: 11
Training loss: 0.30616460894241165
Validation loss: 2.319830904050357

Epoch: 6| Step: 12
Training loss: 0.32329474768063854
Validation loss: 2.306572878666052

Epoch: 6| Step: 13
Training loss: 0.26418026549679224
Validation loss: 2.3382513220160486

Epoch: 571| Step: 0
Training loss: 0.3089979156729389
Validation loss: 2.350538594566646

Epoch: 6| Step: 1
Training loss: 0.3402090082884099
Validation loss: 2.286306185881723

Epoch: 6| Step: 2
Training loss: 0.17666045822024962
Validation loss: 2.283430042543682

Epoch: 6| Step: 3
Training loss: 0.45194061644445965
Validation loss: 2.3080664929785315

Epoch: 6| Step: 4
Training loss: 0.3399631685054229
Validation loss: 2.2824611873274194

Epoch: 6| Step: 5
Training loss: 0.510945529466351
Validation loss: 2.337293750744128

Epoch: 6| Step: 6
Training loss: 0.24084556181154268
Validation loss: 2.3324768351970455

Epoch: 6| Step: 7
Training loss: 0.29587445303524307
Validation loss: 2.4085583608914454

Epoch: 6| Step: 8
Training loss: 0.38574122175264786
Validation loss: 2.425487112951128

Epoch: 6| Step: 9
Training loss: 0.29351823774631425
Validation loss: 2.4099952743848854

Epoch: 6| Step: 10
Training loss: 0.4345162004363242
Validation loss: 2.40942560754084

Epoch: 6| Step: 11
Training loss: 0.33166429774398426
Validation loss: 2.3500379475095747

Epoch: 6| Step: 12
Training loss: 0.3630600943148294
Validation loss: 2.272092068636513

Epoch: 6| Step: 13
Training loss: 0.2732571143108064
Validation loss: 2.2706293624290876

Epoch: 572| Step: 0
Training loss: 0.4075458107690057
Validation loss: 2.274891579915883

Epoch: 6| Step: 1
Training loss: 0.4556617596139283
Validation loss: 2.2799336991486694

Epoch: 6| Step: 2
Training loss: 0.35012893856220756
Validation loss: 2.3211338742108127

Epoch: 6| Step: 3
Training loss: 0.35549561954433845
Validation loss: 2.404643855162289

Epoch: 6| Step: 4
Training loss: 0.33104838587521973
Validation loss: 2.4616484376072427

Epoch: 6| Step: 5
Training loss: 0.2384458036214257
Validation loss: 2.4804621560652875

Epoch: 6| Step: 6
Training loss: 0.24434759903483988
Validation loss: 2.485624051348459

Epoch: 6| Step: 7
Training loss: 0.24867733858597937
Validation loss: 2.447113203375821

Epoch: 6| Step: 8
Training loss: 0.27197220423881735
Validation loss: 2.4121453969251125

Epoch: 6| Step: 9
Training loss: 0.22393842080033693
Validation loss: 2.3567373984632574

Epoch: 6| Step: 10
Training loss: 0.30986343609805705
Validation loss: 2.3162396996795382

Epoch: 6| Step: 11
Training loss: 0.2711171472660047
Validation loss: 2.310448208294772

Epoch: 6| Step: 12
Training loss: 0.35311561420086557
Validation loss: 2.312245657341472

Epoch: 6| Step: 13
Training loss: 0.32409195546300845
Validation loss: 2.312884203770721

Epoch: 573| Step: 0
Training loss: 0.27185458731479295
Validation loss: 2.305126873422965

Epoch: 6| Step: 1
Training loss: 0.38810078439404727
Validation loss: 2.290172591780027

Epoch: 6| Step: 2
Training loss: 0.21014000996518023
Validation loss: 2.368448879349471

Epoch: 6| Step: 3
Training loss: 0.26199861053651635
Validation loss: 2.392602912886599

Epoch: 6| Step: 4
Training loss: 0.3178369998959606
Validation loss: 2.4160465511699947

Epoch: 6| Step: 5
Training loss: 0.22865600838465305
Validation loss: 2.409280685716057

Epoch: 6| Step: 6
Training loss: 0.3011410777850061
Validation loss: 2.4036012743907524

Epoch: 6| Step: 7
Training loss: 0.26661724002560516
Validation loss: 2.3553549633058974

Epoch: 6| Step: 8
Training loss: 0.2598914508539271
Validation loss: 2.3383397065552947

Epoch: 6| Step: 9
Training loss: 0.23759789268898948
Validation loss: 2.2878991631222796

Epoch: 6| Step: 10
Training loss: 0.29525492979935775
Validation loss: 2.297785225566184

Epoch: 6| Step: 11
Training loss: 0.3400808690996883
Validation loss: 2.30618715016923

Epoch: 6| Step: 12
Training loss: 0.282749483559168
Validation loss: 2.309913627878845

Epoch: 6| Step: 13
Training loss: 0.1655958759594687
Validation loss: 2.3558284957093596

Epoch: 574| Step: 0
Training loss: 0.28607398460192646
Validation loss: 2.3724976789671315

Epoch: 6| Step: 1
Training loss: 0.45915615032820406
Validation loss: 2.4026251387253956

Epoch: 6| Step: 2
Training loss: 0.27572565463925114
Validation loss: 2.4193828800586257

Epoch: 6| Step: 3
Training loss: 0.23626954164368597
Validation loss: 2.419345002376564

Epoch: 6| Step: 4
Training loss: 0.19453951461884683
Validation loss: 2.4018572859270066

Epoch: 6| Step: 5
Training loss: 0.16265180906010326
Validation loss: 2.425732435545383

Epoch: 6| Step: 6
Training loss: 0.1828928106732232
Validation loss: 2.4182686621466924

Epoch: 6| Step: 7
Training loss: 0.27470184657590974
Validation loss: 2.425341304762311

Epoch: 6| Step: 8
Training loss: 0.2841284400901189
Validation loss: 2.432470397081095

Epoch: 6| Step: 9
Training loss: 0.18810053854862183
Validation loss: 2.401973533299856

Epoch: 6| Step: 10
Training loss: 0.13854917954627347
Validation loss: 2.38511957769882

Epoch: 6| Step: 11
Training loss: 0.24010955855520866
Validation loss: 2.3898838338510866

Epoch: 6| Step: 12
Training loss: 0.22651217164720555
Validation loss: 2.387671209685467

Epoch: 6| Step: 13
Training loss: 0.19507215016373464
Validation loss: 2.380317108375105

Epoch: 575| Step: 0
Training loss: 0.16538169101520628
Validation loss: 2.4011626665660155

Epoch: 6| Step: 1
Training loss: 0.23843958550037353
Validation loss: 2.4014653949594242

Epoch: 6| Step: 2
Training loss: 0.29224071324117046
Validation loss: 2.378942335009914

Epoch: 6| Step: 3
Training loss: 0.28987887804563556
Validation loss: 2.369930827857458

Epoch: 6| Step: 4
Training loss: 0.17604385469608036
Validation loss: 2.318536755593734

Epoch: 6| Step: 5
Training loss: 0.2554177265368237
Validation loss: 2.3153767627994357

Epoch: 6| Step: 6
Training loss: 0.4228465231932148
Validation loss: 2.2486717172764927

Epoch: 6| Step: 7
Training loss: 0.3099838527196452
Validation loss: 2.289939982373833

Epoch: 6| Step: 8
Training loss: 0.23145933149026976
Validation loss: 2.3112089704462684

Epoch: 6| Step: 9
Training loss: 0.28125895379966753
Validation loss: 2.29476627657567

Epoch: 6| Step: 10
Training loss: 0.18735920070028958
Validation loss: 2.3334227389538666

Epoch: 6| Step: 11
Training loss: 0.27323641876609894
Validation loss: 2.342800667304565

Epoch: 6| Step: 12
Training loss: 0.47551530944133863
Validation loss: 2.359886189572671

Epoch: 6| Step: 13
Training loss: 0.187312012052871
Validation loss: 2.337264221392433

Epoch: 576| Step: 0
Training loss: 0.4027135131346253
Validation loss: 2.3431368364151948

Epoch: 6| Step: 1
Training loss: 0.4678046707843644
Validation loss: 2.321620617310237

Epoch: 6| Step: 2
Training loss: 0.6360129909088315
Validation loss: 2.282892824325728

Epoch: 6| Step: 3
Training loss: 0.4852069969480965
Validation loss: 2.2829506362356264

Epoch: 6| Step: 4
Training loss: 0.2850942805639764
Validation loss: 2.283209435836789

Epoch: 6| Step: 5
Training loss: 0.4334379208266368
Validation loss: 2.315107696171361

Epoch: 6| Step: 6
Training loss: 0.32725632440096225
Validation loss: 2.34043172909685

Epoch: 6| Step: 7
Training loss: 0.4816915721817698
Validation loss: 2.3548401582392877

Epoch: 6| Step: 8
Training loss: 0.49525734085870027
Validation loss: 2.3601410682943422

Epoch: 6| Step: 9
Training loss: 0.5252532779458776
Validation loss: 2.46024926284619

Epoch: 6| Step: 10
Training loss: 0.46247764868468316
Validation loss: 2.4580134383005743

Epoch: 6| Step: 11
Training loss: 0.43079246285020567
Validation loss: 2.44970939583611

Epoch: 6| Step: 12
Training loss: 0.43472371340642485
Validation loss: 2.3893165747673555

Epoch: 6| Step: 13
Training loss: 0.4619242080316259
Validation loss: 2.325196521444131

Epoch: 577| Step: 0
Training loss: 0.4081292701602953
Validation loss: 2.291264985046066

Epoch: 6| Step: 1
Training loss: 0.5265249323814845
Validation loss: 2.311829290374129

Epoch: 6| Step: 2
Training loss: 0.5554092976319046
Validation loss: 2.3489590627486665

Epoch: 6| Step: 3
Training loss: 0.5684137744366731
Validation loss: 2.359160242029524

Epoch: 6| Step: 4
Training loss: 0.6085804625641125
Validation loss: 2.3893918653162265

Epoch: 6| Step: 5
Training loss: 0.4027762819496236
Validation loss: 2.4445173264182336

Epoch: 6| Step: 6
Training loss: 0.3161970553729113
Validation loss: 2.474008982754647

Epoch: 6| Step: 7
Training loss: 0.5196246586629423
Validation loss: 2.5614271261515733

Epoch: 6| Step: 8
Training loss: 0.5148778762273984
Validation loss: 2.532764729548599

Epoch: 6| Step: 9
Training loss: 0.4780637826561973
Validation loss: 2.484582113408038

Epoch: 6| Step: 10
Training loss: 0.4784493225251523
Validation loss: 2.4258629733586043

Epoch: 6| Step: 11
Training loss: 0.46983223596843693
Validation loss: 2.376773739659583

Epoch: 6| Step: 12
Training loss: 0.5229640356648599
Validation loss: 2.352763337490138

Epoch: 6| Step: 13
Training loss: 0.43173382473560884
Validation loss: 2.3335526706807035

Epoch: 578| Step: 0
Training loss: 0.6151070114789183
Validation loss: 2.3305021797743746

Epoch: 6| Step: 1
Training loss: 0.5431453499970792
Validation loss: 2.3207518558431612

Epoch: 6| Step: 2
Training loss: 0.38333829465364466
Validation loss: 2.3381902916411934

Epoch: 6| Step: 3
Training loss: 0.2605879109336067
Validation loss: 2.425649570577251

Epoch: 6| Step: 4
Training loss: 0.6420174329416997
Validation loss: 2.478798001692075

Epoch: 6| Step: 5
Training loss: 0.6467663245203433
Validation loss: 2.473287265264421

Epoch: 6| Step: 6
Training loss: 0.35847594958732343
Validation loss: 2.361416297731453

Epoch: 6| Step: 7
Training loss: 0.31645174052687564
Validation loss: 2.331720241393304

Epoch: 6| Step: 8
Training loss: 0.3864910727083077
Validation loss: 2.288517552057838

Epoch: 6| Step: 9
Training loss: 0.5689552827453219
Validation loss: 2.2975909677226953

Epoch: 6| Step: 10
Training loss: 0.4108493217171117
Validation loss: 2.310792245834151

Epoch: 6| Step: 11
Training loss: 0.5412062436536632
Validation loss: 2.347885598110159

Epoch: 6| Step: 12
Training loss: 0.49311302600822776
Validation loss: 2.3992135338085725

Epoch: 6| Step: 13
Training loss: 0.36226962349145025
Validation loss: 2.460384710873557

Epoch: 579| Step: 0
Training loss: 0.4740989357733394
Validation loss: 2.5295557985892514

Epoch: 6| Step: 1
Training loss: 0.4030384251684282
Validation loss: 2.5627885841564866

Epoch: 6| Step: 2
Training loss: 0.38762623822587394
Validation loss: 2.6178639105510966

Epoch: 6| Step: 3
Training loss: 0.3954318126608925
Validation loss: 2.5935046142547704

Epoch: 6| Step: 4
Training loss: 0.478535601140555
Validation loss: 2.531753742100679

Epoch: 6| Step: 5
Training loss: 0.27275890887979226
Validation loss: 2.4918298949831614

Epoch: 6| Step: 6
Training loss: 0.3717400394098084
Validation loss: 2.423015685492573

Epoch: 6| Step: 7
Training loss: 0.22707383233647604
Validation loss: 2.394721296271436

Epoch: 6| Step: 8
Training loss: 0.5173818540006222
Validation loss: 2.379141793285251

Epoch: 6| Step: 9
Training loss: 0.2511797575952156
Validation loss: 2.3616522447783983

Epoch: 6| Step: 10
Training loss: 0.3388697159642588
Validation loss: 2.3585222878268284

Epoch: 6| Step: 11
Training loss: 0.3376652291060353
Validation loss: 2.3624559765466584

Epoch: 6| Step: 12
Training loss: 0.24710226040878813
Validation loss: 2.3444380386745323

Epoch: 6| Step: 13
Training loss: 0.20895876682999723
Validation loss: 2.32907063924646

Epoch: 580| Step: 0
Training loss: 0.3020609101929079
Validation loss: 2.34513504723247

Epoch: 6| Step: 1
Training loss: 0.21253547442477833
Validation loss: 2.332019939104202

Epoch: 6| Step: 2
Training loss: 0.27028412642433053
Validation loss: 2.3453827517493115

Epoch: 6| Step: 3
Training loss: 0.16333267825669992
Validation loss: 2.3452809366020917

Epoch: 6| Step: 4
Training loss: 0.4121096281077977
Validation loss: 2.326992212210681

Epoch: 6| Step: 5
Training loss: 0.22284757190979512
Validation loss: 2.275486435981805

Epoch: 6| Step: 6
Training loss: 0.33623057156842934
Validation loss: 2.2184769865279423

Epoch: 6| Step: 7
Training loss: 0.37095934793072954
Validation loss: 2.201612735621924

Epoch: 6| Step: 8
Training loss: 0.37650802503192
Validation loss: 2.2105217625437725

Epoch: 6| Step: 9
Training loss: 0.4167139165631598
Validation loss: 2.2207505033513804

Epoch: 6| Step: 10
Training loss: 0.23709304225419292
Validation loss: 2.2274704503007725

Epoch: 6| Step: 11
Training loss: 0.3756155683758313
Validation loss: 2.272094754312019

Epoch: 6| Step: 12
Training loss: 0.28427733221810836
Validation loss: 2.3325522041139193

Epoch: 6| Step: 13
Training loss: 0.22143954238735702
Validation loss: 2.403321071995867

Epoch: 581| Step: 0
Training loss: 0.24060786297697936
Validation loss: 2.455119798405316

Epoch: 6| Step: 1
Training loss: 0.448271075213358
Validation loss: 2.479683094692881

Epoch: 6| Step: 2
Training loss: 0.28039577352920586
Validation loss: 2.4546262480379024

Epoch: 6| Step: 3
Training loss: 0.4056884479126694
Validation loss: 2.4274577963171353

Epoch: 6| Step: 4
Training loss: 0.28345787166496367
Validation loss: 2.326207253884395

Epoch: 6| Step: 5
Training loss: 0.19946017315996661
Validation loss: 2.273228663254587

Epoch: 6| Step: 6
Training loss: 0.334065867961039
Validation loss: 2.220625966924051

Epoch: 6| Step: 7
Training loss: 0.2270341190253993
Validation loss: 2.2075859294080784

Epoch: 6| Step: 8
Training loss: 0.35581115328937446
Validation loss: 2.219297545720299

Epoch: 6| Step: 9
Training loss: 0.34236612056207905
Validation loss: 2.2316791949580304

Epoch: 6| Step: 10
Training loss: 0.4429427218317112
Validation loss: 2.2085182900347085

Epoch: 6| Step: 11
Training loss: 0.2875613592846935
Validation loss: 2.242702524882485

Epoch: 6| Step: 12
Training loss: 0.35018404821777677
Validation loss: 2.255572986220555

Epoch: 6| Step: 13
Training loss: 0.44350076513106135
Validation loss: 2.298069824868991

Epoch: 582| Step: 0
Training loss: 0.33618943060643103
Validation loss: 2.3631762302339254

Epoch: 6| Step: 1
Training loss: 0.2840597941959041
Validation loss: 2.418004589215117

Epoch: 6| Step: 2
Training loss: 0.7624002000503237
Validation loss: 2.446992424145204

Epoch: 6| Step: 3
Training loss: 0.31554110894598225
Validation loss: 2.3447733716976744

Epoch: 6| Step: 4
Training loss: 0.4025006590121069
Validation loss: 2.2566909056546387

Epoch: 6| Step: 5
Training loss: 0.4915960633641342
Validation loss: 2.2032851643359352

Epoch: 6| Step: 6
Training loss: 0.4179677161088082
Validation loss: 2.227777501540474

Epoch: 6| Step: 7
Training loss: 0.34944140272395185
Validation loss: 2.200519319783653

Epoch: 6| Step: 8
Training loss: 0.6021493303587434
Validation loss: 2.210266479902573

Epoch: 6| Step: 9
Training loss: 0.42086328063138323
Validation loss: 2.2373764894482457

Epoch: 6| Step: 10
Training loss: 0.41047503480721176
Validation loss: 2.2631606988841417

Epoch: 6| Step: 11
Training loss: 0.2911891164094103
Validation loss: 2.3057439886410913

Epoch: 6| Step: 12
Training loss: 0.5261753277569761
Validation loss: 2.3208207855736704

Epoch: 6| Step: 13
Training loss: 0.34835619597985273
Validation loss: 2.3940359097522275

Epoch: 583| Step: 0
Training loss: 0.5521392314131269
Validation loss: 2.4261319752035986

Epoch: 6| Step: 1
Training loss: 0.34777295371909644
Validation loss: 2.4361593031698776

Epoch: 6| Step: 2
Training loss: 0.7111826882582183
Validation loss: 2.4324209769959193

Epoch: 6| Step: 3
Training loss: 0.2936673418381695
Validation loss: 2.422608135508948

Epoch: 6| Step: 4
Training loss: 0.16664221268803805
Validation loss: 2.413447746918607

Epoch: 6| Step: 5
Training loss: 0.2409816996286086
Validation loss: 2.3985851333660277

Epoch: 6| Step: 6
Training loss: 0.4299619318501011
Validation loss: 2.362005304961025

Epoch: 6| Step: 7
Training loss: 0.30507282198742974
Validation loss: 2.358589178951119

Epoch: 6| Step: 8
Training loss: 0.27303730425344536
Validation loss: 2.3525107129120824

Epoch: 6| Step: 9
Training loss: 0.4231314140521113
Validation loss: 2.3250646435989655

Epoch: 6| Step: 10
Training loss: 0.3687390762262825
Validation loss: 2.307248938032041

Epoch: 6| Step: 11
Training loss: 0.2691365406407463
Validation loss: 2.30183298831005

Epoch: 6| Step: 12
Training loss: 0.2692179171637319
Validation loss: 2.2950208227103164

Epoch: 6| Step: 13
Training loss: 0.27586884606847434
Validation loss: 2.3053942487120325

Epoch: 584| Step: 0
Training loss: 0.28824273707643355
Validation loss: 2.306114169833838

Epoch: 6| Step: 1
Training loss: 0.30226645455008716
Validation loss: 2.2818340509644615

Epoch: 6| Step: 2
Training loss: 0.27735465659603986
Validation loss: 2.2824752266143746

Epoch: 6| Step: 3
Training loss: 0.22311428708182474
Validation loss: 2.2744257072150247

Epoch: 6| Step: 4
Training loss: 0.23423917331428679
Validation loss: 2.289243148445047

Epoch: 6| Step: 5
Training loss: 0.30015003555354197
Validation loss: 2.2655879664408847

Epoch: 6| Step: 6
Training loss: 0.4309651366923171
Validation loss: 2.2550192648091985

Epoch: 6| Step: 7
Training loss: 0.2618450031079807
Validation loss: 2.2676391384199888

Epoch: 6| Step: 8
Training loss: 0.31048943330227446
Validation loss: 2.266184967396435

Epoch: 6| Step: 9
Training loss: 0.23421638207641474
Validation loss: 2.261099464479766

Epoch: 6| Step: 10
Training loss: 0.2326396034516009
Validation loss: 2.2311075352314345

Epoch: 6| Step: 11
Training loss: 0.2425927110178255
Validation loss: 2.2355816617145816

Epoch: 6| Step: 12
Training loss: 0.24641411228735166
Validation loss: 2.269590063054749

Epoch: 6| Step: 13
Training loss: 0.24897625045998606
Validation loss: 2.2664625272567487

Epoch: 585| Step: 0
Training loss: 0.23506736216021187
Validation loss: 2.2892367232172166

Epoch: 6| Step: 1
Training loss: 0.20070748291392446
Validation loss: 2.266959016369841

Epoch: 6| Step: 2
Training loss: 0.2994073726456624
Validation loss: 2.344494724977042

Epoch: 6| Step: 3
Training loss: 0.16399966467155797
Validation loss: 2.3445833979102146

Epoch: 6| Step: 4
Training loss: 0.2860826832471025
Validation loss: 2.3604790795512884

Epoch: 6| Step: 5
Training loss: 0.24181278527687422
Validation loss: 2.3717959611734694

Epoch: 6| Step: 6
Training loss: 0.290801244537171
Validation loss: 2.356428649750142

Epoch: 6| Step: 7
Training loss: 0.2012105367601359
Validation loss: 2.3789053770991466

Epoch: 6| Step: 8
Training loss: 0.18132862860179494
Validation loss: 2.382491306798292

Epoch: 6| Step: 9
Training loss: 0.23128091631245337
Validation loss: 2.3892656193630812

Epoch: 6| Step: 10
Training loss: 0.2516941691496179
Validation loss: 2.371804793615547

Epoch: 6| Step: 11
Training loss: 0.31805930008180905
Validation loss: 2.3915490006777196

Epoch: 6| Step: 12
Training loss: 0.1935823484300751
Validation loss: 2.384864903761513

Epoch: 6| Step: 13
Training loss: 0.21337243775224374
Validation loss: 2.3745631022275298

Epoch: 586| Step: 0
Training loss: 0.18622670362374127
Validation loss: 2.379418448549078

Epoch: 6| Step: 1
Training loss: 0.2469648958060136
Validation loss: 2.352662772333075

Epoch: 6| Step: 2
Training loss: 0.32524999668523036
Validation loss: 2.3644564082575767

Epoch: 6| Step: 3
Training loss: 0.18117900354031666
Validation loss: 2.366360171916056

Epoch: 6| Step: 4
Training loss: 0.1973233846574871
Validation loss: 2.392399123634038

Epoch: 6| Step: 5
Training loss: 0.2531239709715472
Validation loss: 2.40850599189994

Epoch: 6| Step: 6
Training loss: 0.19196671542977753
Validation loss: 2.393592836210355

Epoch: 6| Step: 7
Training loss: 0.2254699392280754
Validation loss: 2.353422202021604

Epoch: 6| Step: 8
Training loss: 0.17903364468299873
Validation loss: 2.3480026636275033

Epoch: 6| Step: 9
Training loss: 0.21132275932396286
Validation loss: 2.3691092645310547

Epoch: 6| Step: 10
Training loss: 0.20269577820276505
Validation loss: 2.3315699971032666

Epoch: 6| Step: 11
Training loss: 0.15493255961206012
Validation loss: 2.3236513378111554

Epoch: 6| Step: 12
Training loss: 0.1968755264123812
Validation loss: 2.3161314941572777

Epoch: 6| Step: 13
Training loss: 0.1363520267924331
Validation loss: 2.295736076674629

Epoch: 587| Step: 0
Training loss: 0.26735313033430697
Validation loss: 2.319704681841361

Epoch: 6| Step: 1
Training loss: 0.23687953304241122
Validation loss: 2.290113332840059

Epoch: 6| Step: 2
Training loss: 0.12748439838284376
Validation loss: 2.290864004780766

Epoch: 6| Step: 3
Training loss: 0.22998326293802923
Validation loss: 2.3286700043351907

Epoch: 6| Step: 4
Training loss: 0.1349747527872716
Validation loss: 2.30403243416015

Epoch: 6| Step: 5
Training loss: 0.13647781668563935
Validation loss: 2.3142210684523645

Epoch: 6| Step: 6
Training loss: 0.17885598305246625
Validation loss: 2.3169913152173387

Epoch: 6| Step: 7
Training loss: 0.16404344811399565
Validation loss: 2.3170046866561864

Epoch: 6| Step: 8
Training loss: 0.144054793826139
Validation loss: 2.357425733363082

Epoch: 6| Step: 9
Training loss: 0.1366909748201727
Validation loss: 2.3650998372744696

Epoch: 6| Step: 10
Training loss: 0.18905848270278142
Validation loss: 2.3854652543490267

Epoch: 6| Step: 11
Training loss: 0.2316530317615324
Validation loss: 2.3898000187118633

Epoch: 6| Step: 12
Training loss: 0.15501377298321356
Validation loss: 2.360264567586183

Epoch: 6| Step: 13
Training loss: 0.16249204762880717
Validation loss: 2.3532952266516514

Epoch: 588| Step: 0
Training loss: 0.1162915351010242
Validation loss: 2.3143946084899354

Epoch: 6| Step: 1
Training loss: 0.22771263869445166
Validation loss: 2.2914960922643903

Epoch: 6| Step: 2
Training loss: 0.19447035430008613
Validation loss: 2.325902029106933

Epoch: 6| Step: 3
Training loss: 0.18005139365563919
Validation loss: 2.3033540316714682

Epoch: 6| Step: 4
Training loss: 0.142182067882609
Validation loss: 2.3378842265554285

Epoch: 6| Step: 5
Training loss: 0.1883175826730397
Validation loss: 2.3368510913526768

Epoch: 6| Step: 6
Training loss: 0.17303239124556255
Validation loss: 2.3709786679723

Epoch: 6| Step: 7
Training loss: 0.14721289988558436
Validation loss: 2.3843547078036034

Epoch: 6| Step: 8
Training loss: 0.18627753700634936
Validation loss: 2.3668831807965183

Epoch: 6| Step: 9
Training loss: 0.21713314954367602
Validation loss: 2.360341207346208

Epoch: 6| Step: 10
Training loss: 0.12880747073756227
Validation loss: 2.32894388665524

Epoch: 6| Step: 11
Training loss: 0.18034348785190965
Validation loss: 2.3257279004098828

Epoch: 6| Step: 12
Training loss: 0.12567912333140063
Validation loss: 2.2982620382980525

Epoch: 6| Step: 13
Training loss: 0.1775005500240938
Validation loss: 2.3058012643082586

Epoch: 589| Step: 0
Training loss: 0.1758251135458133
Validation loss: 2.2821448842770855

Epoch: 6| Step: 1
Training loss: 0.2691477382921339
Validation loss: 2.272711994384543

Epoch: 6| Step: 2
Training loss: 0.2643162518241993
Validation loss: 2.290869764634575

Epoch: 6| Step: 3
Training loss: 0.17277236244717586
Validation loss: 2.2788390330082207

Epoch: 6| Step: 4
Training loss: 0.16088702789994921
Validation loss: 2.2766329502573512

Epoch: 6| Step: 5
Training loss: 0.14171127804339276
Validation loss: 2.331782026009625

Epoch: 6| Step: 6
Training loss: 0.11077667318340444
Validation loss: 2.3281696365128597

Epoch: 6| Step: 7
Training loss: 0.17942033477257646
Validation loss: 2.3550927441229614

Epoch: 6| Step: 8
Training loss: 0.19135917357129456
Validation loss: 2.3701555760798696

Epoch: 6| Step: 9
Training loss: 0.21758440820192765
Validation loss: 2.3686853526672156

Epoch: 6| Step: 10
Training loss: 0.2398852004972988
Validation loss: 2.3534672179290577

Epoch: 6| Step: 11
Training loss: 0.17458518327910366
Validation loss: 2.3451674137045972

Epoch: 6| Step: 12
Training loss: 0.27043280267305647
Validation loss: 2.34253120261761

Epoch: 6| Step: 13
Training loss: 0.20162124812637505
Validation loss: 2.315998298715628

Epoch: 590| Step: 0
Training loss: 0.1787154713039941
Validation loss: 2.3047574741258927

Epoch: 6| Step: 1
Training loss: 0.1822648142156051
Validation loss: 2.3038229623465862

Epoch: 6| Step: 2
Training loss: 0.21062288840732424
Validation loss: 2.2910377664954913

Epoch: 6| Step: 3
Training loss: 0.12725512457161137
Validation loss: 2.3017976051143236

Epoch: 6| Step: 4
Training loss: 0.1663386848003882
Validation loss: 2.2705649885039225

Epoch: 6| Step: 5
Training loss: 0.253442428672646
Validation loss: 2.2976288598102337

Epoch: 6| Step: 6
Training loss: 0.15428798384339854
Validation loss: 2.2769453155058432

Epoch: 6| Step: 7
Training loss: 0.1461555860078976
Validation loss: 2.27478952408955

Epoch: 6| Step: 8
Training loss: 0.20788961284839763
Validation loss: 2.3052141703285924

Epoch: 6| Step: 9
Training loss: 0.14012855745269537
Validation loss: 2.294316397871381

Epoch: 6| Step: 10
Training loss: 0.11112926524422534
Validation loss: 2.3115882661519183

Epoch: 6| Step: 11
Training loss: 0.1284472501028674
Validation loss: 2.3596072909426624

Epoch: 6| Step: 12
Training loss: 0.21030445828870462
Validation loss: 2.355231709998845

Epoch: 6| Step: 13
Training loss: 0.19164066168516097
Validation loss: 2.3680775922172277

Epoch: 591| Step: 0
Training loss: 0.1440038530936092
Validation loss: 2.3591047356436725

Epoch: 6| Step: 1
Training loss: 0.24956080482035192
Validation loss: 2.334600455770179

Epoch: 6| Step: 2
Training loss: 0.1457784810677207
Validation loss: 2.3612976267671155

Epoch: 6| Step: 3
Training loss: 0.15517901902755074
Validation loss: 2.335013362318145

Epoch: 6| Step: 4
Training loss: 0.18224197232589417
Validation loss: 2.3248877086817323

Epoch: 6| Step: 5
Training loss: 0.16062583350733453
Validation loss: 2.3450871438589957

Epoch: 6| Step: 6
Training loss: 0.09186845383062076
Validation loss: 2.3199615516949073

Epoch: 6| Step: 7
Training loss: 0.16390045428506947
Validation loss: 2.276039711118403

Epoch: 6| Step: 8
Training loss: 0.1339044491013596
Validation loss: 2.3021230438538787

Epoch: 6| Step: 9
Training loss: 0.16928315973639457
Validation loss: 2.30450266629963

Epoch: 6| Step: 10
Training loss: 0.18087665318786106
Validation loss: 2.2649468583482903

Epoch: 6| Step: 11
Training loss: 0.1659864680547787
Validation loss: 2.27857654003253

Epoch: 6| Step: 12
Training loss: 0.2204454910018571
Validation loss: 2.286198919576914

Epoch: 6| Step: 13
Training loss: 0.19222347806654747
Validation loss: 2.286306284556333

Epoch: 592| Step: 0
Training loss: 0.1316702967746408
Validation loss: 2.2613590665811647

Epoch: 6| Step: 1
Training loss: 0.14752777429109243
Validation loss: 2.261253541880727

Epoch: 6| Step: 2
Training loss: 0.14967290112256876
Validation loss: 2.274531006276121

Epoch: 6| Step: 3
Training loss: 0.1092221008790904
Validation loss: 2.2960160232565947

Epoch: 6| Step: 4
Training loss: 0.1458734871443463
Validation loss: 2.291925475719372

Epoch: 6| Step: 5
Training loss: 0.152958808211531
Validation loss: 2.282695452800956

Epoch: 6| Step: 6
Training loss: 0.19223204383407128
Validation loss: 2.23613510377133

Epoch: 6| Step: 7
Training loss: 0.1538392899173002
Validation loss: 2.266605715713315

Epoch: 6| Step: 8
Training loss: 0.0992706091962661
Validation loss: 2.26173641654094

Epoch: 6| Step: 9
Training loss: 0.1641747964552054
Validation loss: 2.2445153929880526

Epoch: 6| Step: 10
Training loss: 0.1297636704639312
Validation loss: 2.267129745613375

Epoch: 6| Step: 11
Training loss: 0.10875566576032454
Validation loss: 2.2817100626260434

Epoch: 6| Step: 12
Training loss: 0.21196933324408257
Validation loss: 2.2509415990906065

Epoch: 6| Step: 13
Training loss: 0.13369546526033743
Validation loss: 2.289993023643

Epoch: 593| Step: 0
Training loss: 0.17394910310101186
Validation loss: 2.292160706017781

Epoch: 6| Step: 1
Training loss: 0.09391098307267035
Validation loss: 2.2801338411828493

Epoch: 6| Step: 2
Training loss: 0.09413068687248234
Validation loss: 2.274273580675867

Epoch: 6| Step: 3
Training loss: 0.13033111187784824
Validation loss: 2.300183152079758

Epoch: 6| Step: 4
Training loss: 0.1509430079412801
Validation loss: 2.286167593188448

Epoch: 6| Step: 5
Training loss: 0.1813149968711403
Validation loss: 2.2954614444572616

Epoch: 6| Step: 6
Training loss: 0.12444184156347037
Validation loss: 2.2845780071446704

Epoch: 6| Step: 7
Training loss: 0.16477819287195022
Validation loss: 2.2592801743000326

Epoch: 6| Step: 8
Training loss: 0.12028048820184987
Validation loss: 2.270802135729264

Epoch: 6| Step: 9
Training loss: 0.13085195890450066
Validation loss: 2.2669272245058476

Epoch: 6| Step: 10
Training loss: 0.15472826829878641
Validation loss: 2.2728219624945893

Epoch: 6| Step: 11
Training loss: 0.1571823200032114
Validation loss: 2.2805407055383675

Epoch: 6| Step: 12
Training loss: 0.20724576956339208
Validation loss: 2.2763177738913374

Epoch: 6| Step: 13
Training loss: 0.12669382022972206
Validation loss: 2.286183917479555

Epoch: 594| Step: 0
Training loss: 0.18981020006966332
Validation loss: 2.2673618288780295

Epoch: 6| Step: 1
Training loss: 0.1587646139450775
Validation loss: 2.256520098941124

Epoch: 6| Step: 2
Training loss: 0.1406888154721202
Validation loss: 2.2504767923371976

Epoch: 6| Step: 3
Training loss: 0.14621894949002404
Validation loss: 2.2499644175260167

Epoch: 6| Step: 4
Training loss: 0.10525255650815618
Validation loss: 2.2417753450424884

Epoch: 6| Step: 5
Training loss: 0.17923534559256946
Validation loss: 2.2329825926052336

Epoch: 6| Step: 6
Training loss: 0.20442356827421024
Validation loss: 2.2459088632213167

Epoch: 6| Step: 7
Training loss: 0.1645957704162587
Validation loss: 2.2247568399049675

Epoch: 6| Step: 8
Training loss: 0.13977220026182613
Validation loss: 2.2687890476369597

Epoch: 6| Step: 9
Training loss: 0.1789202480586985
Validation loss: 2.261899572188069

Epoch: 6| Step: 10
Training loss: 0.14268479211069926
Validation loss: 2.285183302532782

Epoch: 6| Step: 11
Training loss: 0.11495191903601075
Validation loss: 2.302361241930416

Epoch: 6| Step: 12
Training loss: 0.0960584680403552
Validation loss: 2.2721128521448843

Epoch: 6| Step: 13
Training loss: 0.1498132123846655
Validation loss: 2.2919349118149652

Epoch: 595| Step: 0
Training loss: 0.11246831831937992
Validation loss: 2.3081756152611024

Epoch: 6| Step: 1
Training loss: 0.18690483684353168
Validation loss: 2.3226287518424877

Epoch: 6| Step: 2
Training loss: 0.0920721755164997
Validation loss: 2.294464502255448

Epoch: 6| Step: 3
Training loss: 0.10440766846915793
Validation loss: 2.2866686955163162

Epoch: 6| Step: 4
Training loss: 0.14240213532537857
Validation loss: 2.2769477542304823

Epoch: 6| Step: 5
Training loss: 0.1571634710973649
Validation loss: 2.2733246634642823

Epoch: 6| Step: 6
Training loss: 0.13677643512672966
Validation loss: 2.276614942126886

Epoch: 6| Step: 7
Training loss: 0.21079288046203928
Validation loss: 2.252385525842447

Epoch: 6| Step: 8
Training loss: 0.1394709078886576
Validation loss: 2.2524412725160956

Epoch: 6| Step: 9
Training loss: 0.1686676201807164
Validation loss: 2.274013074161755

Epoch: 6| Step: 10
Training loss: 0.09836948766223955
Validation loss: 2.282325059216968

Epoch: 6| Step: 11
Training loss: 0.15570864475761992
Validation loss: 2.2685925357107544

Epoch: 6| Step: 12
Training loss: 0.14856437230244315
Validation loss: 2.2868593401407553

Epoch: 6| Step: 13
Training loss: 0.16553318384721405
Validation loss: 2.264305720165832

Epoch: 596| Step: 0
Training loss: 0.15331180816195708
Validation loss: 2.2919464440222366

Epoch: 6| Step: 1
Training loss: 0.14774329581678822
Validation loss: 2.286100771432669

Epoch: 6| Step: 2
Training loss: 0.10851694622567455
Validation loss: 2.295525674696381

Epoch: 6| Step: 3
Training loss: 0.10035488293931778
Validation loss: 2.295585439413548

Epoch: 6| Step: 4
Training loss: 0.17348035033878792
Validation loss: 2.297827873388358

Epoch: 6| Step: 5
Training loss: 0.15287008207938504
Validation loss: 2.2978296877622655

Epoch: 6| Step: 6
Training loss: 0.17286758564104845
Validation loss: 2.3056321193989318

Epoch: 6| Step: 7
Training loss: 0.247156241329751
Validation loss: 2.2778862058575537

Epoch: 6| Step: 8
Training loss: 0.1128763699688685
Validation loss: 2.2763173369169074

Epoch: 6| Step: 9
Training loss: 0.190892239761361
Validation loss: 2.2925677249902288

Epoch: 6| Step: 10
Training loss: 0.11934196157281604
Validation loss: 2.28760381488026

Epoch: 6| Step: 11
Training loss: 0.12433899511663848
Validation loss: 2.276175710830364

Epoch: 6| Step: 12
Training loss: 0.13404255540804336
Validation loss: 2.298074858281707

Epoch: 6| Step: 13
Training loss: 0.13092932326202833
Validation loss: 2.2618259491876667

Epoch: 597| Step: 0
Training loss: 0.07977850616643746
Validation loss: 2.2827122663108614

Epoch: 6| Step: 1
Training loss: 0.12980872027147713
Validation loss: 2.311402384361895

Epoch: 6| Step: 2
Training loss: 0.2706782083204765
Validation loss: 2.306748316058201

Epoch: 6| Step: 3
Training loss: 0.1785832141495184
Validation loss: 2.2697712955907505

Epoch: 6| Step: 4
Training loss: 0.17617371509546811
Validation loss: 2.2947390990562493

Epoch: 6| Step: 5
Training loss: 0.15190240925640247
Validation loss: 2.275051417868981

Epoch: 6| Step: 6
Training loss: 0.10826910740749818
Validation loss: 2.291614660715199

Epoch: 6| Step: 7
Training loss: 0.15420018558790985
Validation loss: 2.2858444233609325

Epoch: 6| Step: 8
Training loss: 0.14328306802243113
Validation loss: 2.3291240716934625

Epoch: 6| Step: 9
Training loss: 0.11656261573202815
Validation loss: 2.2824360950949973

Epoch: 6| Step: 10
Training loss: 0.157848024382914
Validation loss: 2.2786912490373767

Epoch: 6| Step: 11
Training loss: 0.20314937225257013
Validation loss: 2.3080372916800114

Epoch: 6| Step: 12
Training loss: 0.13167864281651018
Validation loss: 2.2892177447526914

Epoch: 6| Step: 13
Training loss: 0.08300392197860088
Validation loss: 2.3010355518828596

Epoch: 598| Step: 0
Training loss: 0.09322964780921314
Validation loss: 2.2611018522669517

Epoch: 6| Step: 1
Training loss: 0.12970058306229887
Validation loss: 2.2628206327602327

Epoch: 6| Step: 2
Training loss: 0.1428692471429853
Validation loss: 2.2399401652091186

Epoch: 6| Step: 3
Training loss: 0.16609413870930156
Validation loss: 2.2510230975352186

Epoch: 6| Step: 4
Training loss: 0.14235259207639023
Validation loss: 2.287386229400386

Epoch: 6| Step: 5
Training loss: 0.12250839208301964
Validation loss: 2.266776588055976

Epoch: 6| Step: 6
Training loss: 0.10790825751519938
Validation loss: 2.258579819086648

Epoch: 6| Step: 7
Training loss: 0.16186903752020435
Validation loss: 2.2835647620965336

Epoch: 6| Step: 8
Training loss: 0.14579947254490386
Validation loss: 2.2789217319140027

Epoch: 6| Step: 9
Training loss: 0.12955214060474657
Validation loss: 2.3183008243887704

Epoch: 6| Step: 10
Training loss: 0.15424958240678174
Validation loss: 2.303301434987063

Epoch: 6| Step: 11
Training loss: 0.17283734300822431
Validation loss: 2.296541365131972

Epoch: 6| Step: 12
Training loss: 0.09271315573712056
Validation loss: 2.3152760718772547

Epoch: 6| Step: 13
Training loss: 0.1429453001958964
Validation loss: 2.3102453404652574

Epoch: 599| Step: 0
Training loss: 0.1929741885696848
Validation loss: 2.2917121554546345

Epoch: 6| Step: 1
Training loss: 0.21126441876733126
Validation loss: 2.3135252644500506

Epoch: 6| Step: 2
Training loss: 0.11467096019774495
Validation loss: 2.2868466906701395

Epoch: 6| Step: 3
Training loss: 0.1132366733978375
Validation loss: 2.283993415873063

Epoch: 6| Step: 4
Training loss: 0.12481896881394539
Validation loss: 2.27460064635597

Epoch: 6| Step: 5
Training loss: 0.15129302884671164
Validation loss: 2.2882298914487063

Epoch: 6| Step: 6
Training loss: 0.18397921820214966
Validation loss: 2.2579773436330797

Epoch: 6| Step: 7
Training loss: 0.07779001899354161
Validation loss: 2.2831431203712667

Epoch: 6| Step: 8
Training loss: 0.09487683872217809
Validation loss: 2.2829057879581653

Epoch: 6| Step: 9
Training loss: 0.1268960310859227
Validation loss: 2.2654768836318575

Epoch: 6| Step: 10
Training loss: 0.07302387125227829
Validation loss: 2.252917978332671

Epoch: 6| Step: 11
Training loss: 0.1325972018119609
Validation loss: 2.243264166368418

Epoch: 6| Step: 12
Training loss: 0.1142682453837293
Validation loss: 2.252972809483038

Epoch: 6| Step: 13
Training loss: 0.22535138507584102
Validation loss: 2.2535079388280512

Epoch: 600| Step: 0
Training loss: 0.1282045454728809
Validation loss: 2.2634479177240383

Epoch: 6| Step: 1
Training loss: 0.13184827111090408
Validation loss: 2.254706140526027

Epoch: 6| Step: 2
Training loss: 0.08130218453108758
Validation loss: 2.259811226907436

Epoch: 6| Step: 3
Training loss: 0.12300685579952125
Validation loss: 2.305544809407895

Epoch: 6| Step: 4
Training loss: 0.08574482603075714
Validation loss: 2.2726708634033175

Epoch: 6| Step: 5
Training loss: 0.09836525082175726
Validation loss: 2.272416407355186

Epoch: 6| Step: 6
Training loss: 0.1269020417949872
Validation loss: 2.2670325422177324

Epoch: 6| Step: 7
Training loss: 0.11661535306111147
Validation loss: 2.2974937810339093

Epoch: 6| Step: 8
Training loss: 0.14333993717600668
Validation loss: 2.3025909359392362

Epoch: 6| Step: 9
Training loss: 0.08751515614854445
Validation loss: 2.290389412228829

Epoch: 6| Step: 10
Training loss: 0.16759428155371256
Validation loss: 2.2712858252946395

Epoch: 6| Step: 11
Training loss: 0.11353608357923423
Validation loss: 2.2907266503024957

Epoch: 6| Step: 12
Training loss: 0.15800753618176117
Validation loss: 2.2596933568489765

Epoch: 6| Step: 13
Training loss: 0.24140589476377158
Validation loss: 2.28759631648937

Epoch: 601| Step: 0
Training loss: 0.12259188044228835
Validation loss: 2.2715987001084965

Epoch: 6| Step: 1
Training loss: 0.10962434004451226
Validation loss: 2.267453599641767

Epoch: 6| Step: 2
Training loss: 0.0792134811880116
Validation loss: 2.27528711328488

Epoch: 6| Step: 3
Training loss: 0.13624492691596024
Validation loss: 2.266168823151215

Epoch: 6| Step: 4
Training loss: 0.159607989743533
Validation loss: 2.2806791287159243

Epoch: 6| Step: 5
Training loss: 0.15796361854512192
Validation loss: 2.2857783346314355

Epoch: 6| Step: 6
Training loss: 0.1369607554658591
Validation loss: 2.2913580193472067

Epoch: 6| Step: 7
Training loss: 0.12517870109915602
Validation loss: 2.281178074207293

Epoch: 6| Step: 8
Training loss: 0.1343749922375344
Validation loss: 2.2670845329095934

Epoch: 6| Step: 9
Training loss: 0.10160674451895499
Validation loss: 2.3120876344795387

Epoch: 6| Step: 10
Training loss: 0.1374400051317114
Validation loss: 2.3098650447000835

Epoch: 6| Step: 11
Training loss: 0.11444374996495921
Validation loss: 2.294032750497396

Epoch: 6| Step: 12
Training loss: 0.15393134169160919
Validation loss: 2.2801751523518967

Epoch: 6| Step: 13
Training loss: 0.13054911285664741
Validation loss: 2.3326078018845213

Epoch: 602| Step: 0
Training loss: 0.13556735354027843
Validation loss: 2.3013209161260284

Epoch: 6| Step: 1
Training loss: 0.14069086095514308
Validation loss: 2.3188899620302976

Epoch: 6| Step: 2
Training loss: 0.10221283197662774
Validation loss: 2.304066490126413

Epoch: 6| Step: 3
Training loss: 0.09062738333231855
Validation loss: 2.2835223098702184

Epoch: 6| Step: 4
Training loss: 0.1077902675939255
Validation loss: 2.29913933020458

Epoch: 6| Step: 5
Training loss: 0.11416741406005823
Validation loss: 2.277463122819562

Epoch: 6| Step: 6
Training loss: 0.1402404813048017
Validation loss: 2.2690143448040283

Epoch: 6| Step: 7
Training loss: 0.11216685087805034
Validation loss: 2.273537405294291

Epoch: 6| Step: 8
Training loss: 0.15259199213237648
Validation loss: 2.2594372532044207

Epoch: 6| Step: 9
Training loss: 0.14011745785723537
Validation loss: 2.264464957539161

Epoch: 6| Step: 10
Training loss: 0.13454751318480204
Validation loss: 2.245666939308584

Epoch: 6| Step: 11
Training loss: 0.07754648110671872
Validation loss: 2.249617989673585

Epoch: 6| Step: 12
Training loss: 0.11073697563972602
Validation loss: 2.268627742387576

Epoch: 6| Step: 13
Training loss: 0.0968449653704324
Validation loss: 2.2614207998756997

Epoch: 603| Step: 0
Training loss: 0.17492216307840824
Validation loss: 2.257291286080873

Epoch: 6| Step: 1
Training loss: 0.12202411158779906
Validation loss: 2.26632807158264

Epoch: 6| Step: 2
Training loss: 0.09211984087183404
Validation loss: 2.2645356039718143

Epoch: 6| Step: 3
Training loss: 0.13596493811317356
Validation loss: 2.257256379595986

Epoch: 6| Step: 4
Training loss: 0.10382766297282801
Validation loss: 2.2351227551835873

Epoch: 6| Step: 5
Training loss: 0.11742102878390002
Validation loss: 2.2617650277474217

Epoch: 6| Step: 6
Training loss: 0.11750515165601387
Validation loss: 2.2609798371957286

Epoch: 6| Step: 7
Training loss: 0.08374659288916776
Validation loss: 2.257997600820855

Epoch: 6| Step: 8
Training loss: 0.10582456790708342
Validation loss: 2.278060366654478

Epoch: 6| Step: 9
Training loss: 0.08690611127851239
Validation loss: 2.2773273099948503

Epoch: 6| Step: 10
Training loss: 0.17091398440897737
Validation loss: 2.277422567842168

Epoch: 6| Step: 11
Training loss: 0.07066713412912033
Validation loss: 2.2703114956426567

Epoch: 6| Step: 12
Training loss: 0.1022789608104509
Validation loss: 2.267088591946515

Epoch: 6| Step: 13
Training loss: 0.1599320260960022
Validation loss: 2.2714959139723003

Epoch: 604| Step: 0
Training loss: 0.1009366485984963
Validation loss: 2.256574941404352

Epoch: 6| Step: 1
Training loss: 0.08105642535173554
Validation loss: 2.2817564270267483

Epoch: 6| Step: 2
Training loss: 0.14122972007345172
Validation loss: 2.280768585990341

Epoch: 6| Step: 3
Training loss: 0.09504852440672937
Validation loss: 2.258523223910107

Epoch: 6| Step: 4
Training loss: 0.13545256530103955
Validation loss: 2.259712214565537

Epoch: 6| Step: 5
Training loss: 0.08147919325203065
Validation loss: 2.2659197905839616

Epoch: 6| Step: 6
Training loss: 0.1648178423730654
Validation loss: 2.261103856827087

Epoch: 6| Step: 7
Training loss: 0.14092658737590288
Validation loss: 2.271423982918119

Epoch: 6| Step: 8
Training loss: 0.1225868663625016
Validation loss: 2.3087542727767794

Epoch: 6| Step: 9
Training loss: 0.2007530537707933
Validation loss: 2.2894896188891662

Epoch: 6| Step: 10
Training loss: 0.10884542922570906
Validation loss: 2.308403216737911

Epoch: 6| Step: 11
Training loss: 0.10574530617688135
Validation loss: 2.274038720422374

Epoch: 6| Step: 12
Training loss: 0.10661337210804701
Validation loss: 2.297578953925951

Epoch: 6| Step: 13
Training loss: 0.09154287157975288
Validation loss: 2.2966693414705603

Epoch: 605| Step: 0
Training loss: 0.0971177992385281
Validation loss: 2.2670916502131604

Epoch: 6| Step: 1
Training loss: 0.11429023690154541
Validation loss: 2.2608412998781

Epoch: 6| Step: 2
Training loss: 0.10016058362699513
Validation loss: 2.2448054434269302

Epoch: 6| Step: 3
Training loss: 0.1268969705073315
Validation loss: 2.2696041503322184

Epoch: 6| Step: 4
Training loss: 0.15382216862915798
Validation loss: 2.2591429432916983

Epoch: 6| Step: 5
Training loss: 0.124144142465951
Validation loss: 2.278087702638177

Epoch: 6| Step: 6
Training loss: 0.05258025943708831
Validation loss: 2.28782294508794

Epoch: 6| Step: 7
Training loss: 0.11328740349860923
Validation loss: 2.282635829598407

Epoch: 6| Step: 8
Training loss: 0.14480500457127993
Validation loss: 2.2830826930834207

Epoch: 6| Step: 9
Training loss: 0.18463698701679437
Validation loss: 2.2889405182734435

Epoch: 6| Step: 10
Training loss: 0.0899026718978976
Validation loss: 2.294827500503709

Epoch: 6| Step: 11
Training loss: 0.07800289088384055
Validation loss: 2.3108165459015906

Epoch: 6| Step: 12
Training loss: 0.08871636324961021
Validation loss: 2.3004320970540255

Epoch: 6| Step: 13
Training loss: 0.16162259196252574
Validation loss: 2.3204703317537807

Epoch: 606| Step: 0
Training loss: 0.12625621096988707
Validation loss: 2.315450323376573

Epoch: 6| Step: 1
Training loss: 0.13525645394800576
Validation loss: 2.3523148413257595

Epoch: 6| Step: 2
Training loss: 0.1359034616232974
Validation loss: 2.334477690790794

Epoch: 6| Step: 3
Training loss: 0.10639915865600448
Validation loss: 2.340705703642385

Epoch: 6| Step: 4
Training loss: 0.16258592534634583
Validation loss: 2.3224367486287045

Epoch: 6| Step: 5
Training loss: 0.14812616902103345
Validation loss: 2.294681865680211

Epoch: 6| Step: 6
Training loss: 0.09650336669388104
Validation loss: 2.3074110209469034

Epoch: 6| Step: 7
Training loss: 0.12771255324264497
Validation loss: 2.2621072075014093

Epoch: 6| Step: 8
Training loss: 0.07798130111639921
Validation loss: 2.2537459677276814

Epoch: 6| Step: 9
Training loss: 0.09352685279336546
Validation loss: 2.2676439315917563

Epoch: 6| Step: 10
Training loss: 0.17868990331383194
Validation loss: 2.2559428197063323

Epoch: 6| Step: 11
Training loss: 0.18715055008669051
Validation loss: 2.2598710614944935

Epoch: 6| Step: 12
Training loss: 0.08341698775253863
Validation loss: 2.2747773628237486

Epoch: 6| Step: 13
Training loss: 0.14547311766036475
Validation loss: 2.2856897968637226

Epoch: 607| Step: 0
Training loss: 0.11936040446420122
Validation loss: 2.28461552930909

Epoch: 6| Step: 1
Training loss: 0.09764160046370236
Validation loss: 2.286008160158708

Epoch: 6| Step: 2
Training loss: 0.10510171054774935
Validation loss: 2.299825959622916

Epoch: 6| Step: 3
Training loss: 0.1955243392346163
Validation loss: 2.2813042636901226

Epoch: 6| Step: 4
Training loss: 0.10530608490158869
Validation loss: 2.3007845063871315

Epoch: 6| Step: 5
Training loss: 0.10772866742269173
Validation loss: 2.2713989436998103

Epoch: 6| Step: 6
Training loss: 0.1586334944472958
Validation loss: 2.2268852398649877

Epoch: 6| Step: 7
Training loss: 0.14202023141336195
Validation loss: 2.2468017877456736

Epoch: 6| Step: 8
Training loss: 0.08072579252462274
Validation loss: 2.2351380225794713

Epoch: 6| Step: 9
Training loss: 0.13752034074794023
Validation loss: 2.228149072163572

Epoch: 6| Step: 10
Training loss: 0.16766396304801678
Validation loss: 2.252358479461774

Epoch: 6| Step: 11
Training loss: 0.14024234738440944
Validation loss: 2.2551425368267166

Epoch: 6| Step: 12
Training loss: 0.16914318051951513
Validation loss: 2.2565677210617756

Epoch: 6| Step: 13
Training loss: 0.06712562434254198
Validation loss: 2.2534355837575957

Epoch: 608| Step: 0
Training loss: 0.09522935805589773
Validation loss: 2.245314563139966

Epoch: 6| Step: 1
Training loss: 0.16773727458016519
Validation loss: 2.2540975868261426

Epoch: 6| Step: 2
Training loss: 0.12085496524540812
Validation loss: 2.2696429490537953

Epoch: 6| Step: 3
Training loss: 0.10805886150410088
Validation loss: 2.2553977289031426

Epoch: 6| Step: 4
Training loss: 0.13248384707885902
Validation loss: 2.2682104965516627

Epoch: 6| Step: 5
Training loss: 0.12923545415771562
Validation loss: 2.2924719658737542

Epoch: 6| Step: 6
Training loss: 0.18823027454937533
Validation loss: 2.2471677850076257

Epoch: 6| Step: 7
Training loss: 0.13976792911999295
Validation loss: 2.301206939107768

Epoch: 6| Step: 8
Training loss: 0.123773819239776
Validation loss: 2.2542727336965194

Epoch: 6| Step: 9
Training loss: 0.09309597166201342
Validation loss: 2.2675613892095314

Epoch: 6| Step: 10
Training loss: 0.11632836843968546
Validation loss: 2.2516508802577366

Epoch: 6| Step: 11
Training loss: 0.1256430743628297
Validation loss: 2.250892557833965

Epoch: 6| Step: 12
Training loss: 0.10465842241736066
Validation loss: 2.2674532256873845

Epoch: 6| Step: 13
Training loss: 0.19676627797706284
Validation loss: 2.2563375856035646

Epoch: 609| Step: 0
Training loss: 0.15156515158467265
Validation loss: 2.257510182352909

Epoch: 6| Step: 1
Training loss: 0.1473041357587963
Validation loss: 2.2789204468151087

Epoch: 6| Step: 2
Training loss: 0.10982846874118686
Validation loss: 2.277887021806622

Epoch: 6| Step: 3
Training loss: 0.08641566201145325
Validation loss: 2.3117534648582065

Epoch: 6| Step: 4
Training loss: 0.17399805314109415
Validation loss: 2.291287326087003

Epoch: 6| Step: 5
Training loss: 0.1381379041857938
Validation loss: 2.308546972896606

Epoch: 6| Step: 6
Training loss: 0.13132279455020351
Validation loss: 2.2950229579400916

Epoch: 6| Step: 7
Training loss: 0.09660075076664935
Validation loss: 2.3146516301415843

Epoch: 6| Step: 8
Training loss: 0.09781946847547106
Validation loss: 2.316391608997738

Epoch: 6| Step: 9
Training loss: 0.09795633938618017
Validation loss: 2.3420554452476625

Epoch: 6| Step: 10
Training loss: 0.10602707898665861
Validation loss: 2.3245484002950434

Epoch: 6| Step: 11
Training loss: 0.14382468025189216
Validation loss: 2.3247990669032936

Epoch: 6| Step: 12
Training loss: 0.10552926446754227
Validation loss: 2.2880075424554276

Epoch: 6| Step: 13
Training loss: 0.09064100366726041
Validation loss: 2.302174129058815

Epoch: 610| Step: 0
Training loss: 0.08359987100580264
Validation loss: 2.2577623090002694

Epoch: 6| Step: 1
Training loss: 0.10439804328170896
Validation loss: 2.3107352447622502

Epoch: 6| Step: 2
Training loss: 0.06595502447634284
Validation loss: 2.282589188239124

Epoch: 6| Step: 3
Training loss: 0.13902226358868264
Validation loss: 2.263117534270133

Epoch: 6| Step: 4
Training loss: 0.1300981715223196
Validation loss: 2.272743298687557

Epoch: 6| Step: 5
Training loss: 0.1528020104121535
Validation loss: 2.2748290694483755

Epoch: 6| Step: 6
Training loss: 0.156099819489203
Validation loss: 2.26181250600026

Epoch: 6| Step: 7
Training loss: 0.06800233378463898
Validation loss: 2.2768807255072923

Epoch: 6| Step: 8
Training loss: 0.1248631398680382
Validation loss: 2.276672143798797

Epoch: 6| Step: 9
Training loss: 0.13493531366161057
Validation loss: 2.2914541038719083

Epoch: 6| Step: 10
Training loss: 0.09578320986623513
Validation loss: 2.295683386975044

Epoch: 6| Step: 11
Training loss: 0.11036596794964082
Validation loss: 2.2758897037133234

Epoch: 6| Step: 12
Training loss: 0.09351924969684272
Validation loss: 2.2926511050299054

Epoch: 6| Step: 13
Training loss: 0.12348585313469583
Validation loss: 2.2907560521233257

Epoch: 611| Step: 0
Training loss: 0.12310074580636382
Validation loss: 2.3066798554794494

Epoch: 6| Step: 1
Training loss: 0.06482005074029681
Validation loss: 2.2718750997979082

Epoch: 6| Step: 2
Training loss: 0.09065306040002696
Validation loss: 2.2845220448076504

Epoch: 6| Step: 3
Training loss: 0.09784889293691548
Validation loss: 2.258341484326047

Epoch: 6| Step: 4
Training loss: 0.14116215766897997
Validation loss: 2.289373448174369

Epoch: 6| Step: 5
Training loss: 0.12779187649308624
Validation loss: 2.2897469874959833

Epoch: 6| Step: 6
Training loss: 0.1416514736214349
Validation loss: 2.286222104595747

Epoch: 6| Step: 7
Training loss: 0.11334097866112662
Validation loss: 2.2989566520416655

Epoch: 6| Step: 8
Training loss: 0.09111967279027246
Validation loss: 2.255642359764094

Epoch: 6| Step: 9
Training loss: 0.12461823040340063
Validation loss: 2.2955929362773935

Epoch: 6| Step: 10
Training loss: 0.11104122638466002
Validation loss: 2.328495160005699

Epoch: 6| Step: 11
Training loss: 0.07512956073003663
Validation loss: 2.313452875473371

Epoch: 6| Step: 12
Training loss: 0.12672025891309927
Validation loss: 2.319689018381403

Epoch: 6| Step: 13
Training loss: 0.11460735780829902
Validation loss: 2.30872201432239

Epoch: 612| Step: 0
Training loss: 0.12096659845021934
Validation loss: 2.320378308360642

Epoch: 6| Step: 1
Training loss: 0.11948303359685336
Validation loss: 2.2969830624098337

Epoch: 6| Step: 2
Training loss: 0.09427134274859687
Validation loss: 2.3196229009037737

Epoch: 6| Step: 3
Training loss: 0.1362136570664732
Validation loss: 2.2937748501743025

Epoch: 6| Step: 4
Training loss: 0.09858897150735181
Validation loss: 2.3049393711075825

Epoch: 6| Step: 5
Training loss: 0.16678805450773831
Validation loss: 2.295221633970514

Epoch: 6| Step: 6
Training loss: 0.10330723533728202
Validation loss: 2.277451753064887

Epoch: 6| Step: 7
Training loss: 0.15254569118618305
Validation loss: 2.3150022870879075

Epoch: 6| Step: 8
Training loss: 0.11712958971300912
Validation loss: 2.28798465172741

Epoch: 6| Step: 9
Training loss: 0.112973296112246
Validation loss: 2.294019613944769

Epoch: 6| Step: 10
Training loss: 0.16856358793061046
Validation loss: 2.305538151067433

Epoch: 6| Step: 11
Training loss: 0.0939867933299893
Validation loss: 2.310214743520305

Epoch: 6| Step: 12
Training loss: 0.09404408502758001
Validation loss: 2.291137559746185

Epoch: 6| Step: 13
Training loss: 0.14742874274052967
Validation loss: 2.3437914584194974

Epoch: 613| Step: 0
Training loss: 0.08748706781665103
Validation loss: 2.309816288189131

Epoch: 6| Step: 1
Training loss: 0.08788010216344448
Validation loss: 2.3107108889215704

Epoch: 6| Step: 2
Training loss: 0.07335088611172697
Validation loss: 2.300046617170155

Epoch: 6| Step: 3
Training loss: 0.11363377473331321
Validation loss: 2.3142917623708716

Epoch: 6| Step: 4
Training loss: 0.1573214037576467
Validation loss: 2.3188051645120487

Epoch: 6| Step: 5
Training loss: 0.12350083428460155
Validation loss: 2.3246820829220916

Epoch: 6| Step: 6
Training loss: 0.10491116032317169
Validation loss: 2.301841790727569

Epoch: 6| Step: 7
Training loss: 0.12075627122956534
Validation loss: 2.3403997528132687

Epoch: 6| Step: 8
Training loss: 0.150738067076379
Validation loss: 2.334366642848778

Epoch: 6| Step: 9
Training loss: 0.1349916152756526
Validation loss: 2.30443173382015

Epoch: 6| Step: 10
Training loss: 0.09185501043362314
Validation loss: 2.30513619542281

Epoch: 6| Step: 11
Training loss: 0.0796777906299593
Validation loss: 2.3260650209339953

Epoch: 6| Step: 12
Training loss: 0.08528228256932617
Validation loss: 2.298702083369885

Epoch: 6| Step: 13
Training loss: 0.09676625008229492
Validation loss: 2.293005794980509

Epoch: 614| Step: 0
Training loss: 0.14021926203396823
Validation loss: 2.2987346842937666

Epoch: 6| Step: 1
Training loss: 0.1173816106420548
Validation loss: 2.3199138247065445

Epoch: 6| Step: 2
Training loss: 0.06991179516131951
Validation loss: 2.30117346302334

Epoch: 6| Step: 3
Training loss: 0.09487399200424168
Validation loss: 2.295380862069559

Epoch: 6| Step: 4
Training loss: 0.1516344848246566
Validation loss: 2.2903996723003806

Epoch: 6| Step: 5
Training loss: 0.08426243748569871
Validation loss: 2.2854861985800174

Epoch: 6| Step: 6
Training loss: 0.12154608505351287
Validation loss: 2.2955475822782083

Epoch: 6| Step: 7
Training loss: 0.13806536843690537
Validation loss: 2.2560879235048916

Epoch: 6| Step: 8
Training loss: 0.09763889158471074
Validation loss: 2.270023271080805

Epoch: 6| Step: 9
Training loss: 0.0992716036466804
Validation loss: 2.255902942708555

Epoch: 6| Step: 10
Training loss: 0.10161597421373011
Validation loss: 2.272323959843882

Epoch: 6| Step: 11
Training loss: 0.08888275408384541
Validation loss: 2.2692922979945775

Epoch: 6| Step: 12
Training loss: 0.08668884285723509
Validation loss: 2.270930244595879

Epoch: 6| Step: 13
Training loss: 0.12673238490417177
Validation loss: 2.2747872537886793

Epoch: 615| Step: 0
Training loss: 0.08585146639779742
Validation loss: 2.293353191963095

Epoch: 6| Step: 1
Training loss: 0.10347186819180608
Validation loss: 2.2912098232523026

Epoch: 6| Step: 2
Training loss: 0.07528285095868792
Validation loss: 2.274909102462924

Epoch: 6| Step: 3
Training loss: 0.1318892900805869
Validation loss: 2.27045318124962

Epoch: 6| Step: 4
Training loss: 0.11082894948111904
Validation loss: 2.279620577745381

Epoch: 6| Step: 5
Training loss: 0.0791846562978044
Validation loss: 2.2888181122591713

Epoch: 6| Step: 6
Training loss: 0.10223255669027563
Validation loss: 2.318140411935741

Epoch: 6| Step: 7
Training loss: 0.12774006425512505
Validation loss: 2.3053358909200927

Epoch: 6| Step: 8
Training loss: 0.11465350128506557
Validation loss: 2.319554608660943

Epoch: 6| Step: 9
Training loss: 0.11199590692773655
Validation loss: 2.3061312706080295

Epoch: 6| Step: 10
Training loss: 0.07694477953413004
Validation loss: 2.301639175126406

Epoch: 6| Step: 11
Training loss: 0.09521621800922561
Validation loss: 2.3149231385302023

Epoch: 6| Step: 12
Training loss: 0.14145562116198057
Validation loss: 2.30689759651818

Epoch: 6| Step: 13
Training loss: 0.1462449787879608
Validation loss: 2.3049788785669696

Epoch: 616| Step: 0
Training loss: 0.0750675788542058
Validation loss: 2.292201643295078

Epoch: 6| Step: 1
Training loss: 0.11399604285319787
Validation loss: 2.3077133779612975

Epoch: 6| Step: 2
Training loss: 0.15607388823484603
Validation loss: 2.2818092652955824

Epoch: 6| Step: 3
Training loss: 0.14309149252032832
Validation loss: 2.309634999507926

Epoch: 6| Step: 4
Training loss: 0.07815877065326927
Validation loss: 2.295571424746571

Epoch: 6| Step: 5
Training loss: 0.11691964054279329
Validation loss: 2.287841225814744

Epoch: 6| Step: 6
Training loss: 0.06533261827738286
Validation loss: 2.319739175782433

Epoch: 6| Step: 7
Training loss: 0.12124077270240811
Validation loss: 2.315162740909711

Epoch: 6| Step: 8
Training loss: 0.08389513131214937
Validation loss: 2.291978519136666

Epoch: 6| Step: 9
Training loss: 0.08807329163207385
Validation loss: 2.314427161167375

Epoch: 6| Step: 10
Training loss: 0.07817333931326312
Validation loss: 2.294709886522693

Epoch: 6| Step: 11
Training loss: 0.1082206806511303
Validation loss: 2.3192282627674823

Epoch: 6| Step: 12
Training loss: 0.06343362896834469
Validation loss: 2.3141519498962166

Epoch: 6| Step: 13
Training loss: 0.16117498250601456
Validation loss: 2.3103608667034155

Epoch: 617| Step: 0
Training loss: 0.1184585935988079
Validation loss: 2.3168512617700983

Epoch: 6| Step: 1
Training loss: 0.0996277595832436
Validation loss: 2.3010359930762143

Epoch: 6| Step: 2
Training loss: 0.14125571273121593
Validation loss: 2.2935379539657323

Epoch: 6| Step: 3
Training loss: 0.1773828656587771
Validation loss: 2.2935182085297834

Epoch: 6| Step: 4
Training loss: 0.0748934290379091
Validation loss: 2.313746044846306

Epoch: 6| Step: 5
Training loss: 0.09000646327904495
Validation loss: 2.30764140046514

Epoch: 6| Step: 6
Training loss: 0.11683917332220595
Validation loss: 2.301792479604021

Epoch: 6| Step: 7
Training loss: 0.12425293302144373
Validation loss: 2.3049845542120604

Epoch: 6| Step: 8
Training loss: 0.07493984497169891
Validation loss: 2.2776824939016618

Epoch: 6| Step: 9
Training loss: 0.06676938539775963
Validation loss: 2.276633981734248

Epoch: 6| Step: 10
Training loss: 0.11830311073678793
Validation loss: 2.2659403506886413

Epoch: 6| Step: 11
Training loss: 0.11729025309570827
Validation loss: 2.2744175476924733

Epoch: 6| Step: 12
Training loss: 0.07578716574516055
Validation loss: 2.2991543620584456

Epoch: 6| Step: 13
Training loss: 0.07891320537845263
Validation loss: 2.277232688163278

Epoch: 618| Step: 0
Training loss: 0.17176903362461038
Validation loss: 2.2578492929286833

Epoch: 6| Step: 1
Training loss: 0.10972626937631502
Validation loss: 2.278617807992379

Epoch: 6| Step: 2
Training loss: 0.11166769241489372
Validation loss: 2.289998370355088

Epoch: 6| Step: 3
Training loss: 0.14478541270364165
Validation loss: 2.2774687516215897

Epoch: 6| Step: 4
Training loss: 0.06763169034485449
Validation loss: 2.279219757416775

Epoch: 6| Step: 5
Training loss: 0.1350852038137592
Validation loss: 2.31456414589845

Epoch: 6| Step: 6
Training loss: 0.08253833172858745
Validation loss: 2.3100289831521583

Epoch: 6| Step: 7
Training loss: 0.12670232501749443
Validation loss: 2.29138414388431

Epoch: 6| Step: 8
Training loss: 0.06759700387410104
Validation loss: 2.261187086454624

Epoch: 6| Step: 9
Training loss: 0.06224011053709309
Validation loss: 2.274820584553136

Epoch: 6| Step: 10
Training loss: 0.101279161523227
Validation loss: 2.2564938726889063

Epoch: 6| Step: 11
Training loss: 0.11141709068970655
Validation loss: 2.2507802494563087

Epoch: 6| Step: 12
Training loss: 0.08886456747699191
Validation loss: 2.2657734076549896

Epoch: 6| Step: 13
Training loss: 0.1736186243789209
Validation loss: 2.2432962198732658

Epoch: 619| Step: 0
Training loss: 0.08127321807907247
Validation loss: 2.268012250280667

Epoch: 6| Step: 1
Training loss: 0.06817460634393666
Validation loss: 2.2613247273797583

Epoch: 6| Step: 2
Training loss: 0.07808228457476234
Validation loss: 2.2404692614381063

Epoch: 6| Step: 3
Training loss: 0.1244378338176555
Validation loss: 2.267638101721089

Epoch: 6| Step: 4
Training loss: 0.10331522689302561
Validation loss: 2.2658830958914455

Epoch: 6| Step: 5
Training loss: 0.11732702691019892
Validation loss: 2.2729498678516

Epoch: 6| Step: 6
Training loss: 0.08137499474673393
Validation loss: 2.2598882637585076

Epoch: 6| Step: 7
Training loss: 0.06463047394590456
Validation loss: 2.2523859059975715

Epoch: 6| Step: 8
Training loss: 0.08808809984010228
Validation loss: 2.2467408759714735

Epoch: 6| Step: 9
Training loss: 0.08987111732130097
Validation loss: 2.252309938574758

Epoch: 6| Step: 10
Training loss: 0.10724306830711915
Validation loss: 2.2940536213130818

Epoch: 6| Step: 11
Training loss: 0.16248874625338391
Validation loss: 2.2569675158091065

Epoch: 6| Step: 12
Training loss: 0.1434868113624444
Validation loss: 2.251230933171674

Epoch: 6| Step: 13
Training loss: 0.07585003302278913
Validation loss: 2.2768884956349233

Epoch: 620| Step: 0
Training loss: 0.09240340674705477
Validation loss: 2.2485938817171762

Epoch: 6| Step: 1
Training loss: 0.08193836175551253
Validation loss: 2.270209826638131

Epoch: 6| Step: 2
Training loss: 0.08193357078906569
Validation loss: 2.2737039039871965

Epoch: 6| Step: 3
Training loss: 0.1338914980268379
Validation loss: 2.2628912580220404

Epoch: 6| Step: 4
Training loss: 0.14473205870000352
Validation loss: 2.254573139650941

Epoch: 6| Step: 5
Training loss: 0.10552633885525219
Validation loss: 2.2840275495139273

Epoch: 6| Step: 6
Training loss: 0.05576871562491463
Validation loss: 2.293099078956007

Epoch: 6| Step: 7
Training loss: 0.07999002739562029
Validation loss: 2.2859495255884865

Epoch: 6| Step: 8
Training loss: 0.0916921850559883
Validation loss: 2.2740269711361876

Epoch: 6| Step: 9
Training loss: 0.09118028284904339
Validation loss: 2.27153576270328

Epoch: 6| Step: 10
Training loss: 0.0764433443238107
Validation loss: 2.302836028435263

Epoch: 6| Step: 11
Training loss: 0.07970559590231377
Validation loss: 2.2811808028481697

Epoch: 6| Step: 12
Training loss: 0.15930613076942152
Validation loss: 2.30160124603092

Epoch: 6| Step: 13
Training loss: 0.06720767549950406
Validation loss: 2.289005928274256

Epoch: 621| Step: 0
Training loss: 0.0708777995324053
Validation loss: 2.297063934009203

Epoch: 6| Step: 1
Training loss: 0.13993810741638593
Validation loss: 2.3074145229623997

Epoch: 6| Step: 2
Training loss: 0.1656293076728751
Validation loss: 2.303722792456703

Epoch: 6| Step: 3
Training loss: 0.08928613109150738
Validation loss: 2.2912890759908136

Epoch: 6| Step: 4
Training loss: 0.11136276141322372
Validation loss: 2.2764976053993142

Epoch: 6| Step: 5
Training loss: 0.07851288883224239
Validation loss: 2.27777669271141

Epoch: 6| Step: 6
Training loss: 0.07795568238186817
Validation loss: 2.2908461029239127

Epoch: 6| Step: 7
Training loss: 0.06570603244032103
Validation loss: 2.2849878145834834

Epoch: 6| Step: 8
Training loss: 0.07247053555776482
Validation loss: 2.292144031717707

Epoch: 6| Step: 9
Training loss: 0.10165564227457562
Validation loss: 2.272937265885921

Epoch: 6| Step: 10
Training loss: 0.11901938413673314
Validation loss: 2.2827967200084394

Epoch: 6| Step: 11
Training loss: 0.0404649823461951
Validation loss: 2.296253603858399

Epoch: 6| Step: 12
Training loss: 0.08314923972735923
Validation loss: 2.2830193805478616

Epoch: 6| Step: 13
Training loss: 0.10366180732528517
Validation loss: 2.2624135629924664

Epoch: 622| Step: 0
Training loss: 0.09132933253623121
Validation loss: 2.301862010488764

Epoch: 6| Step: 1
Training loss: 0.07748761043420717
Validation loss: 2.313083919735093

Epoch: 6| Step: 2
Training loss: 0.13733876512223742
Validation loss: 2.2806619967164306

Epoch: 6| Step: 3
Training loss: 0.05709169471929685
Validation loss: 2.312707497583952

Epoch: 6| Step: 4
Training loss: 0.11694513530617115
Validation loss: 2.3051341813313093

Epoch: 6| Step: 5
Training loss: 0.116261270986758
Validation loss: 2.2920601097797366

Epoch: 6| Step: 6
Training loss: 0.09419918731809152
Validation loss: 2.3023858714910155

Epoch: 6| Step: 7
Training loss: 0.16633045413499456
Validation loss: 2.3005074607765814

Epoch: 6| Step: 8
Training loss: 0.09001475107318023
Validation loss: 2.312935704694166

Epoch: 6| Step: 9
Training loss: 0.05819303661960464
Validation loss: 2.2961435242180506

Epoch: 6| Step: 10
Training loss: 0.1150648478380351
Validation loss: 2.300887290527314

Epoch: 6| Step: 11
Training loss: 0.1267086903710161
Validation loss: 2.316738202615132

Epoch: 6| Step: 12
Training loss: 0.09069055599128394
Validation loss: 2.311171662618991

Epoch: 6| Step: 13
Training loss: 0.08231642517631246
Validation loss: 2.294089293250181

Epoch: 623| Step: 0
Training loss: 0.11385357498932523
Validation loss: 2.308628511004897

Epoch: 6| Step: 1
Training loss: 0.11084606136410462
Validation loss: 2.2996766649154585

Epoch: 6| Step: 2
Training loss: 0.1480173703085431
Validation loss: 2.2919956767225718

Epoch: 6| Step: 3
Training loss: 0.07903683038851267
Validation loss: 2.300920382483391

Epoch: 6| Step: 4
Training loss: 0.10928239478334427
Validation loss: 2.2918497495334864

Epoch: 6| Step: 5
Training loss: 0.11501912849395916
Validation loss: 2.302638407411889

Epoch: 6| Step: 6
Training loss: 0.08722984084013137
Validation loss: 2.27053956269713

Epoch: 6| Step: 7
Training loss: 0.10375718955039744
Validation loss: 2.2678303266484336

Epoch: 6| Step: 8
Training loss: 0.0859853329619875
Validation loss: 2.2432065962185845

Epoch: 6| Step: 9
Training loss: 0.11071206175887635
Validation loss: 2.2743290416493576

Epoch: 6| Step: 10
Training loss: 0.07340542721926678
Validation loss: 2.269804950185752

Epoch: 6| Step: 11
Training loss: 0.09503032705328604
Validation loss: 2.251675284030138

Epoch: 6| Step: 12
Training loss: 0.16186521136023357
Validation loss: 2.24727844240444

Epoch: 6| Step: 13
Training loss: 0.08661036527096101
Validation loss: 2.2794841585339984

Epoch: 624| Step: 0
Training loss: 0.1200652436623547
Validation loss: 2.2853725076146953

Epoch: 6| Step: 1
Training loss: 0.12873587764673733
Validation loss: 2.2883121165334246

Epoch: 6| Step: 2
Training loss: 0.09075190931733934
Validation loss: 2.2980482888330385

Epoch: 6| Step: 3
Training loss: 0.14349238023149433
Validation loss: 2.268166550949035

Epoch: 6| Step: 4
Training loss: 0.07453226703573675
Validation loss: 2.3070385459197613

Epoch: 6| Step: 5
Training loss: 0.08935372814713612
Validation loss: 2.30640554711965

Epoch: 6| Step: 6
Training loss: 0.09883146770387942
Validation loss: 2.3189089071501656

Epoch: 6| Step: 7
Training loss: 0.14710994024466956
Validation loss: 2.3049390379923453

Epoch: 6| Step: 8
Training loss: 0.07640819692373987
Validation loss: 2.3254123026658924

Epoch: 6| Step: 9
Training loss: 0.0946836472662263
Validation loss: 2.284880332671951

Epoch: 6| Step: 10
Training loss: 0.12086030161403143
Validation loss: 2.3250091419355594

Epoch: 6| Step: 11
Training loss: 0.11810305888646219
Validation loss: 2.3173628996356035

Epoch: 6| Step: 12
Training loss: 0.177918611133575
Validation loss: 2.3512582279212326

Epoch: 6| Step: 13
Training loss: 0.1274279298635992
Validation loss: 2.2943177856663293

Epoch: 625| Step: 0
Training loss: 0.10129099097072942
Validation loss: 2.303927967131902

Epoch: 6| Step: 1
Training loss: 0.10006058169163633
Validation loss: 2.302652617322258

Epoch: 6| Step: 2
Training loss: 0.1532907639719099
Validation loss: 2.3007573013456253

Epoch: 6| Step: 3
Training loss: 0.13121802729639043
Validation loss: 2.3181843048479243

Epoch: 6| Step: 4
Training loss: 0.12810933988514622
Validation loss: 2.2958375218511793

Epoch: 6| Step: 5
Training loss: 0.07360168603559354
Validation loss: 2.2820640276968627

Epoch: 6| Step: 6
Training loss: 0.06901483326700263
Validation loss: 2.2775656694500634

Epoch: 6| Step: 7
Training loss: 0.11013434983743436
Validation loss: 2.285099886723337

Epoch: 6| Step: 8
Training loss: 0.0827763415516215
Validation loss: 2.2578725487842637

Epoch: 6| Step: 9
Training loss: 0.13761430751960682
Validation loss: 2.2954649378994296

Epoch: 6| Step: 10
Training loss: 0.09843882756624715
Validation loss: 2.3385798745348305

Epoch: 6| Step: 11
Training loss: 0.08104785350347134
Validation loss: 2.3263040055304858

Epoch: 6| Step: 12
Training loss: 0.1340415410017603
Validation loss: 2.3092395204165386

Epoch: 6| Step: 13
Training loss: 0.06857308632641666
Validation loss: 2.3150468928537573

Epoch: 626| Step: 0
Training loss: 0.1350936146399486
Validation loss: 2.2843598540142214

Epoch: 6| Step: 1
Training loss: 0.07014239450518363
Validation loss: 2.2896626809907583

Epoch: 6| Step: 2
Training loss: 0.10385569009202389
Validation loss: 2.313673699342571

Epoch: 6| Step: 3
Training loss: 0.1279016201883204
Validation loss: 2.302002581645095

Epoch: 6| Step: 4
Training loss: 0.1425892289945819
Validation loss: 2.3039566730593624

Epoch: 6| Step: 5
Training loss: 0.08665198556908282
Validation loss: 2.307179930618036

Epoch: 6| Step: 6
Training loss: 0.11869297587737998
Validation loss: 2.3115473611189783

Epoch: 6| Step: 7
Training loss: 0.11762826997202742
Validation loss: 2.317801589075974

Epoch: 6| Step: 8
Training loss: 0.0728168567236098
Validation loss: 2.3100960810225883

Epoch: 6| Step: 9
Training loss: 0.08920132521148223
Validation loss: 2.317197198884632

Epoch: 6| Step: 10
Training loss: 0.10646942285583189
Validation loss: 2.2847614587818588

Epoch: 6| Step: 11
Training loss: 0.06973955049483134
Validation loss: 2.3100459417483665

Epoch: 6| Step: 12
Training loss: 0.09014237573133242
Validation loss: 2.3077980970338614

Epoch: 6| Step: 13
Training loss: 0.12928878493800466
Validation loss: 2.309209245419242

Epoch: 627| Step: 0
Training loss: 0.06061069908524944
Validation loss: 2.3084357536762408

Epoch: 6| Step: 1
Training loss: 0.059157829292428785
Validation loss: 2.341352032076028

Epoch: 6| Step: 2
Training loss: 0.1065720757044314
Validation loss: 2.3237099621201587

Epoch: 6| Step: 3
Training loss: 0.14956677181330036
Validation loss: 2.282585176982687

Epoch: 6| Step: 4
Training loss: 0.10230682504087873
Validation loss: 2.292008227589531

Epoch: 6| Step: 5
Training loss: 0.08906637651807624
Validation loss: 2.2983202293612752

Epoch: 6| Step: 6
Training loss: 0.09470691673821001
Validation loss: 2.323933663536074

Epoch: 6| Step: 7
Training loss: 0.12089007692285521
Validation loss: 2.2659341162080415

Epoch: 6| Step: 8
Training loss: 0.07069081942288423
Validation loss: 2.2668227354038235

Epoch: 6| Step: 9
Training loss: 0.11973875801987835
Validation loss: 2.2767931186078463

Epoch: 6| Step: 10
Training loss: 0.11400818249967799
Validation loss: 2.273291320916282

Epoch: 6| Step: 11
Training loss: 0.09361786272221996
Validation loss: 2.242999139428461

Epoch: 6| Step: 12
Training loss: 0.17252193961874981
Validation loss: 2.2351885025392755

Epoch: 6| Step: 13
Training loss: 0.14206777971562412
Validation loss: 2.261866329274321

Epoch: 628| Step: 0
Training loss: 0.14076930165790139
Validation loss: 2.272946884576858

Epoch: 6| Step: 1
Training loss: 0.1422691786572027
Validation loss: 2.2742424597608104

Epoch: 6| Step: 2
Training loss: 0.13600842007086025
Validation loss: 2.2623887804281626

Epoch: 6| Step: 3
Training loss: 0.11105122764449646
Validation loss: 2.2610001865374967

Epoch: 6| Step: 4
Training loss: 0.12801901050394554
Validation loss: 2.2723727111895315

Epoch: 6| Step: 5
Training loss: 0.08899679269797894
Validation loss: 2.2758880374345085

Epoch: 6| Step: 6
Training loss: 0.10521853754709275
Validation loss: 2.286670213518585

Epoch: 6| Step: 7
Training loss: 0.1060291651229325
Validation loss: 2.264551217030791

Epoch: 6| Step: 8
Training loss: 0.0871263761138058
Validation loss: 2.29201205122249

Epoch: 6| Step: 9
Training loss: 0.09685787003331489
Validation loss: 2.3145459953780207

Epoch: 6| Step: 10
Training loss: 0.08838757846498628
Validation loss: 2.321001792589869

Epoch: 6| Step: 11
Training loss: 0.16167388007901445
Validation loss: 2.33711377187805

Epoch: 6| Step: 12
Training loss: 0.13823572260649375
Validation loss: 2.3084148374231472

Epoch: 6| Step: 13
Training loss: 0.13375070119388774
Validation loss: 2.3169860827979614

Epoch: 629| Step: 0
Training loss: 0.14842762412295465
Validation loss: 2.2789018710859574

Epoch: 6| Step: 1
Training loss: 0.08955035297952826
Validation loss: 2.2873180046912993

Epoch: 6| Step: 2
Training loss: 0.10463235491590832
Validation loss: 2.2554370266174217

Epoch: 6| Step: 3
Training loss: 0.09848739271671307
Validation loss: 2.256596444948443

Epoch: 6| Step: 4
Training loss: 0.10016580448312477
Validation loss: 2.2593994535981623

Epoch: 6| Step: 5
Training loss: 0.08846875360482821
Validation loss: 2.2515491612468184

Epoch: 6| Step: 6
Training loss: 0.10958538512734353
Validation loss: 2.254362076900668

Epoch: 6| Step: 7
Training loss: 0.11754495621798243
Validation loss: 2.2373752473742217

Epoch: 6| Step: 8
Training loss: 0.1629017229210382
Validation loss: 2.2576966955552873

Epoch: 6| Step: 9
Training loss: 0.1893096754348878
Validation loss: 2.2221431480545073

Epoch: 6| Step: 10
Training loss: 0.08975534650821897
Validation loss: 2.2707378375462417

Epoch: 6| Step: 11
Training loss: 0.12663205702012265
Validation loss: 2.257320762247747

Epoch: 6| Step: 12
Training loss: 0.058210858368912606
Validation loss: 2.2461548596558503

Epoch: 6| Step: 13
Training loss: 0.11187825304102202
Validation loss: 2.3019975935712593

Epoch: 630| Step: 0
Training loss: 0.12035298657093245
Validation loss: 2.2851530582870914

Epoch: 6| Step: 1
Training loss: 0.10961598432113168
Validation loss: 2.264006543326966

Epoch: 6| Step: 2
Training loss: 0.06869945401970078
Validation loss: 2.271620099805879

Epoch: 6| Step: 3
Training loss: 0.13888584338928753
Validation loss: 2.270081595381461

Epoch: 6| Step: 4
Training loss: 0.08115848536381842
Validation loss: 2.2698789937336548

Epoch: 6| Step: 5
Training loss: 0.11311227017510089
Validation loss: 2.2617791847314295

Epoch: 6| Step: 6
Training loss: 0.13348215640132233
Validation loss: 2.282306011484346

Epoch: 6| Step: 7
Training loss: 0.13312921906891148
Validation loss: 2.2566028267855405

Epoch: 6| Step: 8
Training loss: 0.12218953985818869
Validation loss: 2.276239242157526

Epoch: 6| Step: 9
Training loss: 0.12390892870149361
Validation loss: 2.2822575880231555

Epoch: 6| Step: 10
Training loss: 0.1779381977143994
Validation loss: 2.2762166864066025

Epoch: 6| Step: 11
Training loss: 0.10413603829072424
Validation loss: 2.294811072361594

Epoch: 6| Step: 12
Training loss: 0.1526587481962951
Validation loss: 2.2793233604743612

Epoch: 6| Step: 13
Training loss: 0.1009240762963947
Validation loss: 2.3056638618041734

Epoch: 631| Step: 0
Training loss: 0.12099852201597534
Validation loss: 2.2856913020568617

Epoch: 6| Step: 1
Training loss: 0.1261465419221229
Validation loss: 2.313495305392305

Epoch: 6| Step: 2
Training loss: 0.08859074742243041
Validation loss: 2.296750929277909

Epoch: 6| Step: 3
Training loss: 0.180737372293631
Validation loss: 2.2825913025272695

Epoch: 6| Step: 4
Training loss: 0.12188085731467345
Validation loss: 2.298283021852084

Epoch: 6| Step: 5
Training loss: 0.08514180607745721
Validation loss: 2.298727019237166

Epoch: 6| Step: 6
Training loss: 0.11545904531721682
Validation loss: 2.295377939778926

Epoch: 6| Step: 7
Training loss: 0.10710293064583411
Validation loss: 2.2936353205670765

Epoch: 6| Step: 8
Training loss: 0.10078164847243438
Validation loss: 2.281248977352986

Epoch: 6| Step: 9
Training loss: 0.0802782860101483
Validation loss: 2.2917938350024185

Epoch: 6| Step: 10
Training loss: 0.08025123911120821
Validation loss: 2.313254678067007

Epoch: 6| Step: 11
Training loss: 0.07135664662636577
Validation loss: 2.292902083403523

Epoch: 6| Step: 12
Training loss: 0.09213893649776365
Validation loss: 2.2898096398703576

Epoch: 6| Step: 13
Training loss: 0.1441847410636691
Validation loss: 2.2767632606010175

Epoch: 632| Step: 0
Training loss: 0.07468530550928972
Validation loss: 2.274864046627

Epoch: 6| Step: 1
Training loss: 0.08879727453577903
Validation loss: 2.283058974248094

Epoch: 6| Step: 2
Training loss: 0.10634220011212524
Validation loss: 2.2842618692687195

Epoch: 6| Step: 3
Training loss: 0.09297983400002942
Validation loss: 2.293424454231781

Epoch: 6| Step: 4
Training loss: 0.12855847001053128
Validation loss: 2.289391959515122

Epoch: 6| Step: 5
Training loss: 0.12971464183315035
Validation loss: 2.2841428882740513

Epoch: 6| Step: 6
Training loss: 0.07850682709874852
Validation loss: 2.283677301471154

Epoch: 6| Step: 7
Training loss: 0.09392020054461972
Validation loss: 2.279625233547095

Epoch: 6| Step: 8
Training loss: 0.10205813659736117
Validation loss: 2.2941538490948816

Epoch: 6| Step: 9
Training loss: 0.11476526303166072
Validation loss: 2.278510446396784

Epoch: 6| Step: 10
Training loss: 0.08663192775885846
Validation loss: 2.2901188595004056

Epoch: 6| Step: 11
Training loss: 0.09855326192235297
Validation loss: 2.2537483584713254

Epoch: 6| Step: 12
Training loss: 0.11602777584421722
Validation loss: 2.2852890224289637

Epoch: 6| Step: 13
Training loss: 0.04396506633769985
Validation loss: 2.290004810798028

Epoch: 633| Step: 0
Training loss: 0.09035252519054267
Validation loss: 2.2937019211444913

Epoch: 6| Step: 1
Training loss: 0.08131065798083398
Validation loss: 2.2899559215280467

Epoch: 6| Step: 2
Training loss: 0.0990227977649256
Validation loss: 2.3069024228614254

Epoch: 6| Step: 3
Training loss: 0.16359439554606303
Validation loss: 2.3000623163107075

Epoch: 6| Step: 4
Training loss: 0.06729498958847188
Validation loss: 2.2866683221817783

Epoch: 6| Step: 5
Training loss: 0.08007871813670743
Validation loss: 2.3022068144429553

Epoch: 6| Step: 6
Training loss: 0.08779886011675468
Validation loss: 2.289785145979249

Epoch: 6| Step: 7
Training loss: 0.12536476973881774
Validation loss: 2.2871063945020116

Epoch: 6| Step: 8
Training loss: 0.10342173546981794
Validation loss: 2.291803042324369

Epoch: 6| Step: 9
Training loss: 0.07524551845826294
Validation loss: 2.317296434233741

Epoch: 6| Step: 10
Training loss: 0.06657248264885639
Validation loss: 2.294063177168801

Epoch: 6| Step: 11
Training loss: 0.12518663926811865
Validation loss: 2.3056666087225435

Epoch: 6| Step: 12
Training loss: 0.06564364750206805
Validation loss: 2.281174111603569

Epoch: 6| Step: 13
Training loss: 0.1481536485233997
Validation loss: 2.2980529491345423

Epoch: 634| Step: 0
Training loss: 0.11677082211355155
Validation loss: 2.307159054093611

Epoch: 6| Step: 1
Training loss: 0.061781286143377724
Validation loss: 2.3193446331454846

Epoch: 6| Step: 2
Training loss: 0.07829740693530751
Validation loss: 2.3001171225803336

Epoch: 6| Step: 3
Training loss: 0.08717709825364213
Validation loss: 2.337525529268536

Epoch: 6| Step: 4
Training loss: 0.09448535924480549
Validation loss: 2.3303545060130424

Epoch: 6| Step: 5
Training loss: 0.052607533886912215
Validation loss: 2.311029234222795

Epoch: 6| Step: 6
Training loss: 0.10225835251212022
Validation loss: 2.2760874587176882

Epoch: 6| Step: 7
Training loss: 0.06577870528266784
Validation loss: 2.334603269667158

Epoch: 6| Step: 8
Training loss: 0.14984899683727287
Validation loss: 2.3258537285072705

Epoch: 6| Step: 9
Training loss: 0.12862779423910334
Validation loss: 2.307127555607608

Epoch: 6| Step: 10
Training loss: 0.15052244057396724
Validation loss: 2.3331965268662307

Epoch: 6| Step: 11
Training loss: 0.13826239936920828
Validation loss: 2.3232113663996277

Epoch: 6| Step: 12
Training loss: 0.1395902846038377
Validation loss: 2.322415336442346

Epoch: 6| Step: 13
Training loss: 0.05610240291092946
Validation loss: 2.28555437253215

Epoch: 635| Step: 0
Training loss: 0.08685216414021975
Validation loss: 2.295362101379223

Epoch: 6| Step: 1
Training loss: 0.140875084022744
Validation loss: 2.2695418788556605

Epoch: 6| Step: 2
Training loss: 0.15051846210851524
Validation loss: 2.3059317496083738

Epoch: 6| Step: 3
Training loss: 0.08323453625924236
Validation loss: 2.2740758686008418

Epoch: 6| Step: 4
Training loss: 0.10454392711962836
Validation loss: 2.264032375407859

Epoch: 6| Step: 5
Training loss: 0.13822976678786508
Validation loss: 2.2782777287937654

Epoch: 6| Step: 6
Training loss: 0.12371661312621454
Validation loss: 2.262646498520848

Epoch: 6| Step: 7
Training loss: 0.13611849760213163
Validation loss: 2.282392201557688

Epoch: 6| Step: 8
Training loss: 0.10216118804097873
Validation loss: 2.295147521114794

Epoch: 6| Step: 9
Training loss: 0.08771790381262282
Validation loss: 2.262152441488962

Epoch: 6| Step: 10
Training loss: 0.05950529427525653
Validation loss: 2.259553393910708

Epoch: 6| Step: 11
Training loss: 0.10235602982210813
Validation loss: 2.2955875009697886

Epoch: 6| Step: 12
Training loss: 0.11276627096641537
Validation loss: 2.2697670013383138

Epoch: 6| Step: 13
Training loss: 0.10406057398964039
Validation loss: 2.283505000487711

Epoch: 636| Step: 0
Training loss: 0.0952233188476369
Validation loss: 2.2779090680770953

Epoch: 6| Step: 1
Training loss: 0.14252189938518692
Validation loss: 2.2842855402615396

Epoch: 6| Step: 2
Training loss: 0.07435601804133084
Validation loss: 2.268423228657222

Epoch: 6| Step: 3
Training loss: 0.06716709922300912
Validation loss: 2.3036901408229227

Epoch: 6| Step: 4
Training loss: 0.09551200954990052
Validation loss: 2.282535321806159

Epoch: 6| Step: 5
Training loss: 0.07351525266575347
Validation loss: 2.2691413914910847

Epoch: 6| Step: 6
Training loss: 0.10735900946743523
Validation loss: 2.2752455082956016

Epoch: 6| Step: 7
Training loss: 0.06889527615164323
Validation loss: 2.28873718900088

Epoch: 6| Step: 8
Training loss: 0.09113286187194716
Validation loss: 2.279236551575031

Epoch: 6| Step: 9
Training loss: 0.12431698699360039
Validation loss: 2.29511999178805

Epoch: 6| Step: 10
Training loss: 0.07554875329097932
Validation loss: 2.2939736471524834

Epoch: 6| Step: 11
Training loss: 0.0928863440666918
Validation loss: 2.290044808196338

Epoch: 6| Step: 12
Training loss: 0.13127149621587972
Validation loss: 2.2879481697340296

Epoch: 6| Step: 13
Training loss: 0.04541013830451201
Validation loss: 2.296861811618083

Epoch: 637| Step: 0
Training loss: 0.11596588937504704
Validation loss: 2.298500176414767

Epoch: 6| Step: 1
Training loss: 0.1002390026368197
Validation loss: 2.287604276594753

Epoch: 6| Step: 2
Training loss: 0.09750433549961864
Validation loss: 2.2858002509567137

Epoch: 6| Step: 3
Training loss: 0.07227672672054739
Validation loss: 2.3048171496193257

Epoch: 6| Step: 4
Training loss: 0.09558776792917954
Validation loss: 2.2954337882247233

Epoch: 6| Step: 5
Training loss: 0.1488046184508992
Validation loss: 2.299198640839658

Epoch: 6| Step: 6
Training loss: 0.10186262901060178
Validation loss: 2.3047901718159522

Epoch: 6| Step: 7
Training loss: 0.085599149230943
Validation loss: 2.271722939005207

Epoch: 6| Step: 8
Training loss: 0.07550061163433486
Validation loss: 2.2802267348893333

Epoch: 6| Step: 9
Training loss: 0.1077067110133461
Validation loss: 2.289058596963175

Epoch: 6| Step: 10
Training loss: 0.1113120703247148
Validation loss: 2.310152308293996

Epoch: 6| Step: 11
Training loss: 0.09416596202284283
Validation loss: 2.290200570126672

Epoch: 6| Step: 12
Training loss: 0.11973133373243632
Validation loss: 2.3202282787506245

Epoch: 6| Step: 13
Training loss: 0.06185136171322566
Validation loss: 2.2973286516473266

Epoch: 638| Step: 0
Training loss: 0.10698754765372112
Validation loss: 2.2987786042518703

Epoch: 6| Step: 1
Training loss: 0.09904236791267111
Validation loss: 2.318449635232868

Epoch: 6| Step: 2
Training loss: 0.09428957793186322
Validation loss: 2.3205522374918366

Epoch: 6| Step: 3
Training loss: 0.06747387523982179
Validation loss: 2.3134770927417683

Epoch: 6| Step: 4
Training loss: 0.1004771876166281
Validation loss: 2.31503206330381

Epoch: 6| Step: 5
Training loss: 0.05916857095685049
Validation loss: 2.305239293203917

Epoch: 6| Step: 6
Training loss: 0.1188201345833294
Validation loss: 2.2901680542496905

Epoch: 6| Step: 7
Training loss: 0.054609526240394515
Validation loss: 2.2974706852148823

Epoch: 6| Step: 8
Training loss: 0.10620781011771808
Validation loss: 2.2954777590546644

Epoch: 6| Step: 9
Training loss: 0.1309876524920067
Validation loss: 2.2844283634580504

Epoch: 6| Step: 10
Training loss: 0.09702459617351081
Validation loss: 2.2637685375567047

Epoch: 6| Step: 11
Training loss: 0.13344811761321
Validation loss: 2.2409928840978925

Epoch: 6| Step: 12
Training loss: 0.11276575891498164
Validation loss: 2.279149941275065

Epoch: 6| Step: 13
Training loss: 0.0738621098645737
Validation loss: 2.2715544182782375

Epoch: 639| Step: 0
Training loss: 0.12512888075739245
Validation loss: 2.272672479869557

Epoch: 6| Step: 1
Training loss: 0.0857813999647209
Validation loss: 2.28710694262698

Epoch: 6| Step: 2
Training loss: 0.0740247122420812
Validation loss: 2.284084854002558

Epoch: 6| Step: 3
Training loss: 0.06899893488226017
Validation loss: 2.3020458172905913

Epoch: 6| Step: 4
Training loss: 0.08084695693041354
Validation loss: 2.3004627012487

Epoch: 6| Step: 5
Training loss: 0.1281500512730633
Validation loss: 2.3127955918769554

Epoch: 6| Step: 6
Training loss: 0.08720123340090931
Validation loss: 2.2847192983713236

Epoch: 6| Step: 7
Training loss: 0.08181765541039171
Validation loss: 2.2943689172797495

Epoch: 6| Step: 8
Training loss: 0.10749044830558825
Validation loss: 2.3118624641216465

Epoch: 6| Step: 9
Training loss: 0.11195464937778808
Validation loss: 2.299405855897533

Epoch: 6| Step: 10
Training loss: 0.10528744903344926
Validation loss: 2.333887673450221

Epoch: 6| Step: 11
Training loss: 0.1159018887017883
Validation loss: 2.3333184385337007

Epoch: 6| Step: 12
Training loss: 0.0565783347244716
Validation loss: 2.3151996976306353

Epoch: 6| Step: 13
Training loss: 0.09914781651818297
Validation loss: 2.3094640423660175

Epoch: 640| Step: 0
Training loss: 0.07446936907492915
Validation loss: 2.28393373226723

Epoch: 6| Step: 1
Training loss: 0.07341558910754313
Validation loss: 2.283731975596435

Epoch: 6| Step: 2
Training loss: 0.07251129405661708
Validation loss: 2.327828111346751

Epoch: 6| Step: 3
Training loss: 0.06200198600264672
Validation loss: 2.2997944175522784

Epoch: 6| Step: 4
Training loss: 0.0972186967327839
Validation loss: 2.310942555794714

Epoch: 6| Step: 5
Training loss: 0.09568573346055277
Validation loss: 2.309427113748244

Epoch: 6| Step: 6
Training loss: 0.12643385842632937
Validation loss: 2.3111755560429184

Epoch: 6| Step: 7
Training loss: 0.050150572471795565
Validation loss: 2.316992262893638

Epoch: 6| Step: 8
Training loss: 0.12568900831010835
Validation loss: 2.300092522783008

Epoch: 6| Step: 9
Training loss: 0.07832038408499702
Validation loss: 2.2982671828364825

Epoch: 6| Step: 10
Training loss: 0.08173274610548399
Validation loss: 2.270793200572207

Epoch: 6| Step: 11
Training loss: 0.13298560529894318
Validation loss: 2.283687980675404

Epoch: 6| Step: 12
Training loss: 0.10364369800738621
Validation loss: 2.275426885830067

Epoch: 6| Step: 13
Training loss: 0.15041020501233449
Validation loss: 2.2848869322790395

Epoch: 641| Step: 0
Training loss: 0.09050298957833015
Validation loss: 2.280263087456508

Epoch: 6| Step: 1
Training loss: 0.12959160821514043
Validation loss: 2.274925779127872

Epoch: 6| Step: 2
Training loss: 0.07363756908160317
Validation loss: 2.2897463560316664

Epoch: 6| Step: 3
Training loss: 0.10935073821867798
Validation loss: 2.279837528565523

Epoch: 6| Step: 4
Training loss: 0.15079193324453474
Validation loss: 2.29979777412916

Epoch: 6| Step: 5
Training loss: 0.07143351538292911
Validation loss: 2.2927457899466988

Epoch: 6| Step: 6
Training loss: 0.06322679531441533
Validation loss: 2.321469327345075

Epoch: 6| Step: 7
Training loss: 0.08281065864585135
Validation loss: 2.3251664950109254

Epoch: 6| Step: 8
Training loss: 0.07147873832804909
Validation loss: 2.3411305327003706

Epoch: 6| Step: 9
Training loss: 0.050098071645014675
Validation loss: 2.331267594629537

Epoch: 6| Step: 10
Training loss: 0.08395004679810343
Validation loss: 2.3200449693499023

Epoch: 6| Step: 11
Training loss: 0.09714558597577927
Validation loss: 2.3187889991167037

Epoch: 6| Step: 12
Training loss: 0.12141670722061838
Validation loss: 2.354958201254445

Epoch: 6| Step: 13
Training loss: 0.16269734622925253
Validation loss: 2.3133989331289015

Epoch: 642| Step: 0
Training loss: 0.1204625646015068
Validation loss: 2.334228648654376

Epoch: 6| Step: 1
Training loss: 0.08132132943388196
Validation loss: 2.3311284967738146

Epoch: 6| Step: 2
Training loss: 0.12332492777441242
Validation loss: 2.3082580749900243

Epoch: 6| Step: 3
Training loss: 0.08845165588427077
Validation loss: 2.2965656870567748

Epoch: 6| Step: 4
Training loss: 0.08639102172139522
Validation loss: 2.294151249307025

Epoch: 6| Step: 5
Training loss: 0.10222425273083142
Validation loss: 2.2780081290416625

Epoch: 6| Step: 6
Training loss: 0.07414277479594306
Validation loss: 2.322370902559118

Epoch: 6| Step: 7
Training loss: 0.0823446457748984
Validation loss: 2.3303369405292527

Epoch: 6| Step: 8
Training loss: 0.08880029508276134
Validation loss: 2.3259419228316327

Epoch: 6| Step: 9
Training loss: 0.09062595490248512
Validation loss: 2.327734475707064

Epoch: 6| Step: 10
Training loss: 0.08061497120435931
Validation loss: 2.328398998450952

Epoch: 6| Step: 11
Training loss: 0.09910316023179574
Validation loss: 2.2946449957910153

Epoch: 6| Step: 12
Training loss: 0.08783551713720238
Validation loss: 2.354130842578969

Epoch: 6| Step: 13
Training loss: 0.06895515490512655
Validation loss: 2.3488451347872257

Epoch: 643| Step: 0
Training loss: 0.06750006425708785
Validation loss: 2.312635001532491

Epoch: 6| Step: 1
Training loss: 0.08257988973877425
Validation loss: 2.3400772742133316

Epoch: 6| Step: 2
Training loss: 0.11658675868182215
Validation loss: 2.31897872410561

Epoch: 6| Step: 3
Training loss: 0.10976822025312641
Validation loss: 2.3188737845122223

Epoch: 6| Step: 4
Training loss: 0.09573507748696765
Validation loss: 2.3277665576897233

Epoch: 6| Step: 5
Training loss: 0.08646463878409971
Validation loss: 2.3300106332194686

Epoch: 6| Step: 6
Training loss: 0.14266615592975235
Validation loss: 2.2941282103533402

Epoch: 6| Step: 7
Training loss: 0.09812721650086409
Validation loss: 2.325831725560222

Epoch: 6| Step: 8
Training loss: 0.10400063773736833
Validation loss: 2.3073732100626154

Epoch: 6| Step: 9
Training loss: 0.06826856917141948
Validation loss: 2.307020981818717

Epoch: 6| Step: 10
Training loss: 0.06650696157867572
Validation loss: 2.311430665284023

Epoch: 6| Step: 11
Training loss: 0.07176628806158585
Validation loss: 2.3099288892745515

Epoch: 6| Step: 12
Training loss: 0.09489595860027387
Validation loss: 2.304854367880531

Epoch: 6| Step: 13
Training loss: 0.0646819618406722
Validation loss: 2.3100875980399285

Epoch: 644| Step: 0
Training loss: 0.11700002456169604
Validation loss: 2.2803674986464104

Epoch: 6| Step: 1
Training loss: 0.12931691126860928
Validation loss: 2.2972525634463494

Epoch: 6| Step: 2
Training loss: 0.12645756763161498
Validation loss: 2.301047312553558

Epoch: 6| Step: 3
Training loss: 0.07955738002326833
Validation loss: 2.2823958669196625

Epoch: 6| Step: 4
Training loss: 0.13684430488008742
Validation loss: 2.3023163942862537

Epoch: 6| Step: 5
Training loss: 0.07496628003267373
Validation loss: 2.288876288889444

Epoch: 6| Step: 6
Training loss: 0.1108345416981333
Validation loss: 2.2811486040035454

Epoch: 6| Step: 7
Training loss: 0.05662312525038864
Validation loss: 2.2859392573187307

Epoch: 6| Step: 8
Training loss: 0.05945580843610432
Validation loss: 2.3040044894215477

Epoch: 6| Step: 9
Training loss: 0.09275615932790976
Validation loss: 2.2836324287344514

Epoch: 6| Step: 10
Training loss: 0.11036778643014819
Validation loss: 2.305287212240076

Epoch: 6| Step: 11
Training loss: 0.06578027684857854
Validation loss: 2.2670367229123247

Epoch: 6| Step: 12
Training loss: 0.1438166764327231
Validation loss: 2.283515127020061

Epoch: 6| Step: 13
Training loss: 0.08909534154177573
Validation loss: 2.26147946733345

Epoch: 645| Step: 0
Training loss: 0.11267931277512903
Validation loss: 2.2882253629501754

Epoch: 6| Step: 1
Training loss: 0.08172853564429543
Validation loss: 2.274982528006411

Epoch: 6| Step: 2
Training loss: 0.10425352756646294
Validation loss: 2.2551096319799733

Epoch: 6| Step: 3
Training loss: 0.1296328167931149
Validation loss: 2.2659612425224758

Epoch: 6| Step: 4
Training loss: 0.0838267738334715
Validation loss: 2.247731164403817

Epoch: 6| Step: 5
Training loss: 0.09249807450023781
Validation loss: 2.241033731653706

Epoch: 6| Step: 6
Training loss: 0.09705312450065137
Validation loss: 2.263599019752724

Epoch: 6| Step: 7
Training loss: 0.12129868194347689
Validation loss: 2.2865898891857435

Epoch: 6| Step: 8
Training loss: 0.15220120681589394
Validation loss: 2.29233637073407

Epoch: 6| Step: 9
Training loss: 0.06237328805095917
Validation loss: 2.284836850187056

Epoch: 6| Step: 10
Training loss: 0.11206682972966127
Validation loss: 2.290961705473511

Epoch: 6| Step: 11
Training loss: 0.13006103449174095
Validation loss: 2.279126099679904

Epoch: 6| Step: 12
Training loss: 0.055163956109227835
Validation loss: 2.2850314321927776

Epoch: 6| Step: 13
Training loss: 0.06618768120417587
Validation loss: 2.2948316272103964

Epoch: 646| Step: 0
Training loss: 0.0808291572277763
Validation loss: 2.2904759786364717

Epoch: 6| Step: 1
Training loss: 0.08568028950803651
Validation loss: 2.2671882076735406

Epoch: 6| Step: 2
Training loss: 0.08175528747042152
Validation loss: 2.2568219340992846

Epoch: 6| Step: 3
Training loss: 0.10665445168256366
Validation loss: 2.2584048915944916

Epoch: 6| Step: 4
Training loss: 0.15003346477177693
Validation loss: 2.2323234606104454

Epoch: 6| Step: 5
Training loss: 0.0710469012951472
Validation loss: 2.2383857056550283

Epoch: 6| Step: 6
Training loss: 0.10231813517916993
Validation loss: 2.257087388687852

Epoch: 6| Step: 7
Training loss: 0.09483586720068758
Validation loss: 2.248606130437755

Epoch: 6| Step: 8
Training loss: 0.11381039683647025
Validation loss: 2.245017870824053

Epoch: 6| Step: 9
Training loss: 0.07259816262697431
Validation loss: 2.2717310585523105

Epoch: 6| Step: 10
Training loss: 0.17719371011067592
Validation loss: 2.2539656567236883

Epoch: 6| Step: 11
Training loss: 0.10052758904059
Validation loss: 2.2578237296051302

Epoch: 6| Step: 12
Training loss: 0.10419802839319646
Validation loss: 2.260995469706321

Epoch: 6| Step: 13
Training loss: 0.08674934938486378
Validation loss: 2.264569520336973

Epoch: 647| Step: 0
Training loss: 0.07541131911607533
Validation loss: 2.244339066590257

Epoch: 6| Step: 1
Training loss: 0.05775072899194202
Validation loss: 2.2765056876464187

Epoch: 6| Step: 2
Training loss: 0.1022218702855234
Validation loss: 2.2778432482585997

Epoch: 6| Step: 3
Training loss: 0.15217262217863786
Validation loss: 2.273530510010219

Epoch: 6| Step: 4
Training loss: 0.08265439135980242
Validation loss: 2.2808311129512777

Epoch: 6| Step: 5
Training loss: 0.07734380201858158
Validation loss: 2.269692920251618

Epoch: 6| Step: 6
Training loss: 0.06062617031668694
Validation loss: 2.287027228856759

Epoch: 6| Step: 7
Training loss: 0.08079010800045819
Validation loss: 2.247215378868573

Epoch: 6| Step: 8
Training loss: 0.08767427466107844
Validation loss: 2.266177068371337

Epoch: 6| Step: 9
Training loss: 0.09985668671662834
Validation loss: 2.251431611587724

Epoch: 6| Step: 10
Training loss: 0.10831391415715651
Validation loss: 2.2774976210735236

Epoch: 6| Step: 11
Training loss: 0.07863438660590062
Validation loss: 2.2786137633051866

Epoch: 6| Step: 12
Training loss: 0.1067076041278193
Validation loss: 2.2858960282495437

Epoch: 6| Step: 13
Training loss: 0.059615200359283665
Validation loss: 2.305563296542973

Epoch: 648| Step: 0
Training loss: 0.08882718705593852
Validation loss: 2.2854216057036063

Epoch: 6| Step: 1
Training loss: 0.10583552412083432
Validation loss: 2.306243535825964

Epoch: 6| Step: 2
Training loss: 0.08414856806801514
Validation loss: 2.2938267787433335

Epoch: 6| Step: 3
Training loss: 0.0801350344825602
Validation loss: 2.2659159760969207

Epoch: 6| Step: 4
Training loss: 0.1222566174732663
Validation loss: 2.296077647632792

Epoch: 6| Step: 5
Training loss: 0.07174890305057718
Validation loss: 2.2994500584827704

Epoch: 6| Step: 6
Training loss: 0.09097043827158462
Validation loss: 2.298814243016115

Epoch: 6| Step: 7
Training loss: 0.07490372787052174
Validation loss: 2.3010903505698015

Epoch: 6| Step: 8
Training loss: 0.0727940103227607
Validation loss: 2.289895019646941

Epoch: 6| Step: 9
Training loss: 0.0666124354573705
Validation loss: 2.305538738176383

Epoch: 6| Step: 10
Training loss: 0.051613300036795984
Validation loss: 2.293192678866305

Epoch: 6| Step: 11
Training loss: 0.1470863434868073
Validation loss: 2.3303830492292783

Epoch: 6| Step: 12
Training loss: 0.13129635344273133
Validation loss: 2.317076790409114

Epoch: 6| Step: 13
Training loss: 0.09154408731951212
Validation loss: 2.3284629251136715

Epoch: 649| Step: 0
Training loss: 0.1111930563204719
Validation loss: 2.311378564056013

Epoch: 6| Step: 1
Training loss: 0.08180212196237623
Validation loss: 2.312868767901271

Epoch: 6| Step: 2
Training loss: 0.06653879765593003
Validation loss: 2.308255802622225

Epoch: 6| Step: 3
Training loss: 0.09469305507649652
Validation loss: 2.3095774920180983

Epoch: 6| Step: 4
Training loss: 0.07946951376420075
Validation loss: 2.302644746256851

Epoch: 6| Step: 5
Training loss: 0.1108662998034089
Validation loss: 2.295277620529117

Epoch: 6| Step: 6
Training loss: 0.07872471700604146
Validation loss: 2.3027434083212297

Epoch: 6| Step: 7
Training loss: 0.1021886286979426
Validation loss: 2.282474005712573

Epoch: 6| Step: 8
Training loss: 0.09965251474626381
Validation loss: 2.339250122128139

Epoch: 6| Step: 9
Training loss: 0.129081361491549
Validation loss: 2.302263589050312

Epoch: 6| Step: 10
Training loss: 0.061000741793126464
Validation loss: 2.3074707955783302

Epoch: 6| Step: 11
Training loss: 0.09562133680757101
Validation loss: 2.2983456936230025

Epoch: 6| Step: 12
Training loss: 0.06981260029624216
Validation loss: 2.299828176781456

Epoch: 6| Step: 13
Training loss: 0.06094563021893052
Validation loss: 2.3071830929705475

Epoch: 650| Step: 0
Training loss: 0.12495895546345623
Validation loss: 2.3046522629680575

Epoch: 6| Step: 1
Training loss: 0.06227970414628619
Validation loss: 2.307729728696783

Epoch: 6| Step: 2
Training loss: 0.1370808438560088
Validation loss: 2.2830597159216044

Epoch: 6| Step: 3
Training loss: 0.08917269749092487
Validation loss: 2.2865348685566502

Epoch: 6| Step: 4
Training loss: 0.08547397799777663
Validation loss: 2.29764312971246

Epoch: 6| Step: 5
Training loss: 0.06642490713906608
Validation loss: 2.2965521441478693

Epoch: 6| Step: 6
Training loss: 0.09183435993632562
Validation loss: 2.2853369015368954

Epoch: 6| Step: 7
Training loss: 0.08020190232781317
Validation loss: 2.277236735303451

Epoch: 6| Step: 8
Training loss: 0.10846751821341111
Validation loss: 2.2809468386923855

Epoch: 6| Step: 9
Training loss: 0.1333613694661418
Validation loss: 2.2896578474192473

Epoch: 6| Step: 10
Training loss: 0.09203722614612582
Validation loss: 2.294699514172575

Epoch: 6| Step: 11
Training loss: 0.07541848789478399
Validation loss: 2.2709340083269827

Epoch: 6| Step: 12
Training loss: 0.0850924701436822
Validation loss: 2.2886633758291617

Epoch: 6| Step: 13
Training loss: 0.053274525294237506
Validation loss: 2.2821228036614087

Testing loss: 2.6798063824588225
