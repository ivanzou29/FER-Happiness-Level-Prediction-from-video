Epoch: 1| Step: 0
Training loss: 5.721801610670804
Validation loss: 5.812419667186672

Epoch: 6| Step: 1
Training loss: 4.87596238247112
Validation loss: 5.789701542573011

Epoch: 6| Step: 2
Training loss: 4.847994415267396
Validation loss: 5.77114314815111

Epoch: 6| Step: 3
Training loss: 6.337447018373673
Validation loss: 5.753178866740936

Epoch: 6| Step: 4
Training loss: 7.0784828482941
Validation loss: 5.733851573403554

Epoch: 6| Step: 5
Training loss: 4.695301531939145
Validation loss: 5.712870077750592

Epoch: 6| Step: 6
Training loss: 5.827734558281383
Validation loss: 5.689124766755436

Epoch: 6| Step: 7
Training loss: 6.824366322817658
Validation loss: 5.662308074727256

Epoch: 6| Step: 8
Training loss: 4.562478679450399
Validation loss: 5.632084425769793

Epoch: 6| Step: 9
Training loss: 4.304047414057616
Validation loss: 5.598313774750234

Epoch: 6| Step: 10
Training loss: 6.45732013589247
Validation loss: 5.56249639407985

Epoch: 6| Step: 11
Training loss: 5.467684047899645
Validation loss: 5.524039375160387

Epoch: 6| Step: 12
Training loss: 6.479158881899296
Validation loss: 5.482235461521469

Epoch: 6| Step: 13
Training loss: 4.9814094163760085
Validation loss: 5.437785807655813

Epoch: 2| Step: 0
Training loss: 6.129631004491274
Validation loss: 5.394107756328749

Epoch: 6| Step: 1
Training loss: 5.11453667623937
Validation loss: 5.348111280216877

Epoch: 6| Step: 2
Training loss: 4.0436022865638375
Validation loss: 5.302623967889609

Epoch: 6| Step: 3
Training loss: 5.73811172847794
Validation loss: 5.257917328193777

Epoch: 6| Step: 4
Training loss: 4.618896374686574
Validation loss: 5.213141063356593

Epoch: 6| Step: 5
Training loss: 4.5761908393626465
Validation loss: 5.169005932546059

Epoch: 6| Step: 6
Training loss: 5.033687972318222
Validation loss: 5.127433469241745

Epoch: 6| Step: 7
Training loss: 6.081133649444184
Validation loss: 5.084488501268492

Epoch: 6| Step: 8
Training loss: 5.6109246368813155
Validation loss: 5.040811939988126

Epoch: 6| Step: 9
Training loss: 5.042784932019753
Validation loss: 4.993804536746234

Epoch: 6| Step: 10
Training loss: 5.016980519832318
Validation loss: 4.946945864435241

Epoch: 6| Step: 11
Training loss: 4.825868146996184
Validation loss: 4.8923797022895785

Epoch: 6| Step: 12
Training loss: 4.92641043823068
Validation loss: 4.8400922044395145

Epoch: 6| Step: 13
Training loss: 5.111315997251088
Validation loss: 4.786416125144641

Epoch: 3| Step: 0
Training loss: 4.588295533430645
Validation loss: 4.732990935606768

Epoch: 6| Step: 1
Training loss: 5.056973867386954
Validation loss: 4.680752877011918

Epoch: 6| Step: 2
Training loss: 4.943898750700477
Validation loss: 4.631327432863581

Epoch: 6| Step: 3
Training loss: 4.302107964076484
Validation loss: 4.586188073714532

Epoch: 6| Step: 4
Training loss: 4.749695215987589
Validation loss: 4.540582628904057

Epoch: 6| Step: 5
Training loss: 5.214328560401179
Validation loss: 4.497260770819346

Epoch: 6| Step: 6
Training loss: 4.4447928662950735
Validation loss: 4.460999156540971

Epoch: 6| Step: 7
Training loss: 4.651820591387111
Validation loss: 4.423348824487303

Epoch: 6| Step: 8
Training loss: 4.333654293987341
Validation loss: 4.38952600075976

Epoch: 6| Step: 9
Training loss: 3.6129782389838847
Validation loss: 4.358573031498051

Epoch: 6| Step: 10
Training loss: 4.34135513701185
Validation loss: 4.339717449462487

Epoch: 6| Step: 11
Training loss: 4.776414208423478
Validation loss: 4.335675230688691

Epoch: 6| Step: 12
Training loss: 4.415618676183104
Validation loss: 4.301939610929456

Epoch: 6| Step: 13
Training loss: 4.545699868951313
Validation loss: 4.28010425426661

Epoch: 4| Step: 0
Training loss: 4.888287165246341
Validation loss: 4.251501895331055

Epoch: 6| Step: 1
Training loss: 4.350812042560274
Validation loss: 4.231491598327092

Epoch: 6| Step: 2
Training loss: 4.2275876760386355
Validation loss: 4.216558172501799

Epoch: 6| Step: 3
Training loss: 4.047197365900839
Validation loss: 4.20571778333759

Epoch: 6| Step: 4
Training loss: 3.8230523579948805
Validation loss: 4.185101773268349

Epoch: 6| Step: 5
Training loss: 4.304627461369538
Validation loss: 4.1737435389446995

Epoch: 6| Step: 6
Training loss: 4.723829150580286
Validation loss: 4.152289463245123

Epoch: 6| Step: 7
Training loss: 3.849238005695063
Validation loss: 4.1352028975787665

Epoch: 6| Step: 8
Training loss: 4.358402485538956
Validation loss: 4.12219611340785

Epoch: 6| Step: 9
Training loss: 4.020451950934187
Validation loss: 4.110458130839899

Epoch: 6| Step: 10
Training loss: 3.9863788427689824
Validation loss: 4.099053288179635

Epoch: 6| Step: 11
Training loss: 5.098327452219855
Validation loss: 4.087723081161714

Epoch: 6| Step: 12
Training loss: 3.834915055946888
Validation loss: 4.075240169725005

Epoch: 6| Step: 13
Training loss: 4.460530865469562
Validation loss: 4.060123549326855

Epoch: 5| Step: 0
Training loss: 4.3765378156658405
Validation loss: 4.042968034736768

Epoch: 6| Step: 1
Training loss: 3.8316967552787973
Validation loss: 4.0278346405051275

Epoch: 6| Step: 2
Training loss: 3.660888338104874
Validation loss: 4.019799227606011

Epoch: 6| Step: 3
Training loss: 3.2130210780411965
Validation loss: 4.011010592519956

Epoch: 6| Step: 4
Training loss: 4.538804905421957
Validation loss: 4.003417900551343

Epoch: 6| Step: 5
Training loss: 4.591537461767832
Validation loss: 3.990867289690498

Epoch: 6| Step: 6
Training loss: 4.7083901370962735
Validation loss: 3.977680049505848

Epoch: 6| Step: 7
Training loss: 3.4775002575674723
Validation loss: 3.9645737080044987

Epoch: 6| Step: 8
Training loss: 4.620365811022016
Validation loss: 3.9559856937763214

Epoch: 6| Step: 9
Training loss: 3.7888709580291433
Validation loss: 3.9486573227179185

Epoch: 6| Step: 10
Training loss: 4.073860598921294
Validation loss: 3.940754623709718

Epoch: 6| Step: 11
Training loss: 5.225821449648696
Validation loss: 3.9220476885875395

Epoch: 6| Step: 12
Training loss: 3.336357429749974
Validation loss: 3.9095236343026483

Epoch: 6| Step: 13
Training loss: 3.6021538701973346
Validation loss: 3.899819555912093

Epoch: 6| Step: 0
Training loss: 4.1522486649802275
Validation loss: 3.88989169985602

Epoch: 6| Step: 1
Training loss: 4.798932656192612
Validation loss: 3.877553502708726

Epoch: 6| Step: 2
Training loss: 4.10987392631277
Validation loss: 3.8666360587272472

Epoch: 6| Step: 3
Training loss: 3.0865422296123968
Validation loss: 3.854787252539826

Epoch: 6| Step: 4
Training loss: 3.8447636454031437
Validation loss: 3.849262901161885

Epoch: 6| Step: 5
Training loss: 3.638712499353872
Validation loss: 3.840502752161108

Epoch: 6| Step: 6
Training loss: 3.3767523278394784
Validation loss: 3.8250254951435405

Epoch: 6| Step: 7
Training loss: 4.796451711461895
Validation loss: 3.808809651160113

Epoch: 6| Step: 8
Training loss: 3.548716600562575
Validation loss: 3.797914696962133

Epoch: 6| Step: 9
Training loss: 4.612800385739843
Validation loss: 3.7860171503132594

Epoch: 6| Step: 10
Training loss: 4.35070244390157
Validation loss: 3.7756526492320495

Epoch: 6| Step: 11
Training loss: 3.6576298123397084
Validation loss: 3.7627255948119367

Epoch: 6| Step: 12
Training loss: 3.4734546271419706
Validation loss: 3.7450063606448167

Epoch: 6| Step: 13
Training loss: 3.905304328889762
Validation loss: 3.7343542402454757

Epoch: 7| Step: 0
Training loss: 3.308836008185498
Validation loss: 3.7258431785693547

Epoch: 6| Step: 1
Training loss: 4.184122118099557
Validation loss: 3.7163066949780132

Epoch: 6| Step: 2
Training loss: 3.7871811433536213
Validation loss: 3.706698582856274

Epoch: 6| Step: 3
Training loss: 3.6537279086728986
Validation loss: 3.6968137952989184

Epoch: 6| Step: 4
Training loss: 3.3242835857734185
Validation loss: 3.6900042857310207

Epoch: 6| Step: 5
Training loss: 4.212786946017928
Validation loss: 3.6859731424370628

Epoch: 6| Step: 6
Training loss: 4.575215218906801
Validation loss: 3.67737631699745

Epoch: 6| Step: 7
Training loss: 3.708397439695447
Validation loss: 3.670047264797311

Epoch: 6| Step: 8
Training loss: 4.149051484328013
Validation loss: 3.6655546797355307

Epoch: 6| Step: 9
Training loss: 3.9947031235943298
Validation loss: 3.644123766255291

Epoch: 6| Step: 10
Training loss: 3.756734269037945
Validation loss: 3.630465989420401

Epoch: 6| Step: 11
Training loss: 3.8328800486270223
Validation loss: 3.627111827565509

Epoch: 6| Step: 12
Training loss: 4.221497721724645
Validation loss: 3.6183828907382165

Epoch: 6| Step: 13
Training loss: 2.217722265206638
Validation loss: 3.607107548959256

Epoch: 8| Step: 0
Training loss: 4.022988303580694
Validation loss: 3.6020432452270748

Epoch: 6| Step: 1
Training loss: 2.9217512951127724
Validation loss: 3.597253643991471

Epoch: 6| Step: 2
Training loss: 4.156741005712795
Validation loss: 3.5893443506052227

Epoch: 6| Step: 3
Training loss: 3.3823674638246146
Validation loss: 3.5765266593959

Epoch: 6| Step: 4
Training loss: 3.7990593298054502
Validation loss: 3.5767561744681813

Epoch: 6| Step: 5
Training loss: 3.663317509050934
Validation loss: 3.57685670085215

Epoch: 6| Step: 6
Training loss: 4.736637393253363
Validation loss: 3.554053727943986

Epoch: 6| Step: 7
Training loss: 3.8216194772336993
Validation loss: 3.558048510398078

Epoch: 6| Step: 8
Training loss: 3.7332624110796804
Validation loss: 3.554759888992018

Epoch: 6| Step: 9
Training loss: 3.5951670630928754
Validation loss: 3.5342369851900415

Epoch: 6| Step: 10
Training loss: 3.398095966584834
Validation loss: 3.5200467984429715

Epoch: 6| Step: 11
Training loss: 4.289070059903401
Validation loss: 3.5127432169281634

Epoch: 6| Step: 12
Training loss: 3.129933087544736
Validation loss: 3.5080804059973913

Epoch: 6| Step: 13
Training loss: 3.530581790864279
Validation loss: 3.501925665312842

Epoch: 9| Step: 0
Training loss: 3.3871974232803943
Validation loss: 3.4921294918208257

Epoch: 6| Step: 1
Training loss: 3.3885073751048758
Validation loss: 3.4848315830389094

Epoch: 6| Step: 2
Training loss: 3.2378530184660104
Validation loss: 3.4787023665686605

Epoch: 6| Step: 3
Training loss: 3.5293967185915203
Validation loss: 3.4724716712740347

Epoch: 6| Step: 4
Training loss: 3.1024485362639
Validation loss: 3.4613554468444745

Epoch: 6| Step: 5
Training loss: 3.8032755336888555
Validation loss: 3.4548850621683753

Epoch: 6| Step: 6
Training loss: 3.9754981394597766
Validation loss: 3.4494724365506033

Epoch: 6| Step: 7
Training loss: 4.142459563735368
Validation loss: 3.439018674741381

Epoch: 6| Step: 8
Training loss: 4.088631728166446
Validation loss: 3.4350094495816097

Epoch: 6| Step: 9
Training loss: 4.162810461248422
Validation loss: 3.4234714804206527

Epoch: 6| Step: 10
Training loss: 2.874631111694214
Validation loss: 3.4168530890276094

Epoch: 6| Step: 11
Training loss: 4.352934862353623
Validation loss: 3.4128869184242094

Epoch: 6| Step: 12
Training loss: 3.6466397220190303
Validation loss: 3.4012087881231508

Epoch: 6| Step: 13
Training loss: 2.926655168995905
Validation loss: 3.39455793960667

Epoch: 10| Step: 0
Training loss: 4.0162808962457826
Validation loss: 3.3885053868401855

Epoch: 6| Step: 1
Training loss: 4.469265141172496
Validation loss: 3.3797159930262692

Epoch: 6| Step: 2
Training loss: 3.6440609938272712
Validation loss: 3.3780448096668474

Epoch: 6| Step: 3
Training loss: 3.1462900870144677
Validation loss: 3.3773658159740774

Epoch: 6| Step: 4
Training loss: 3.197130203874616
Validation loss: 3.368810011098432

Epoch: 6| Step: 5
Training loss: 3.9511576344435664
Validation loss: 3.3601089961552515

Epoch: 6| Step: 6
Training loss: 3.109991117998301
Validation loss: 3.355388013652086

Epoch: 6| Step: 7
Training loss: 3.508428778599736
Validation loss: 3.3525212987905766

Epoch: 6| Step: 8
Training loss: 3.525453519392224
Validation loss: 3.3533232101068755

Epoch: 6| Step: 9
Training loss: 3.310073827744207
Validation loss: 3.3496260688839543

Epoch: 6| Step: 10
Training loss: 3.4173047625145734
Validation loss: 3.3441785373505017

Epoch: 6| Step: 11
Training loss: 3.544323377292177
Validation loss: 3.335450491174188

Epoch: 6| Step: 12
Training loss: 4.17449114776561
Validation loss: 3.325385830248824

Epoch: 6| Step: 13
Training loss: 2.2944705340749705
Validation loss: 3.3160519686732566

Epoch: 11| Step: 0
Training loss: 3.8024498471094548
Validation loss: 3.3116489926246766

Epoch: 6| Step: 1
Training loss: 3.8224291720168537
Validation loss: 3.307304034388818

Epoch: 6| Step: 2
Training loss: 3.994989594981903
Validation loss: 3.301804787221934

Epoch: 6| Step: 3
Training loss: 3.402930365707259
Validation loss: 3.2959148605101585

Epoch: 6| Step: 4
Training loss: 3.6755726478401676
Validation loss: 3.294577956929581

Epoch: 6| Step: 5
Training loss: 3.839166280720082
Validation loss: 3.2873867139383655

Epoch: 6| Step: 6
Training loss: 3.2735534501764456
Validation loss: 3.2784828014464193

Epoch: 6| Step: 7
Training loss: 2.907078778627522
Validation loss: 3.2741307967330573

Epoch: 6| Step: 8
Training loss: 3.79926868227842
Validation loss: 3.272544172520582

Epoch: 6| Step: 9
Training loss: 3.961818860353282
Validation loss: 3.2715896182518005

Epoch: 6| Step: 10
Training loss: 3.138357682041626
Validation loss: 3.2592384143406496

Epoch: 6| Step: 11
Training loss: 2.9809664289496625
Validation loss: 3.2521755960432577

Epoch: 6| Step: 12
Training loss: 3.024855643366805
Validation loss: 3.2510551446811133

Epoch: 6| Step: 13
Training loss: 3.5006325013990076
Validation loss: 3.25374164339017

Epoch: 12| Step: 0
Training loss: 3.2343135219757313
Validation loss: 3.2586676117988795

Epoch: 6| Step: 1
Training loss: 3.47945175982513
Validation loss: 3.253539331356407

Epoch: 6| Step: 2
Training loss: 3.7178863035304084
Validation loss: 3.2595340821487127

Epoch: 6| Step: 3
Training loss: 3.4243951862128035
Validation loss: 3.2648812548230954

Epoch: 6| Step: 4
Training loss: 3.249007587033023
Validation loss: 3.2665188855346705

Epoch: 6| Step: 5
Training loss: 3.617483831341825
Validation loss: 3.2616409796494956

Epoch: 6| Step: 6
Training loss: 3.2838646053881386
Validation loss: 3.2561028388130375

Epoch: 6| Step: 7
Training loss: 4.1999054671048475
Validation loss: 3.2490808861151943

Epoch: 6| Step: 8
Training loss: 2.5967252281875273
Validation loss: 3.2355184342554537

Epoch: 6| Step: 9
Training loss: 3.8328452145050798
Validation loss: 3.2311556234509378

Epoch: 6| Step: 10
Training loss: 3.164811561362399
Validation loss: 3.228178571089708

Epoch: 6| Step: 11
Training loss: 3.2166379647300345
Validation loss: 3.2248151499644493

Epoch: 6| Step: 12
Training loss: 4.150399356608462
Validation loss: 3.219299282282052

Epoch: 6| Step: 13
Training loss: 3.4890887616916384
Validation loss: 3.2146898725569173

Epoch: 13| Step: 0
Training loss: 2.4783292900245724
Validation loss: 3.2097962984257107

Epoch: 6| Step: 1
Training loss: 4.022955115575922
Validation loss: 3.2014474321034547

Epoch: 6| Step: 2
Training loss: 3.1839990275970966
Validation loss: 3.1958575625881633

Epoch: 6| Step: 3
Training loss: 2.891353865826388
Validation loss: 3.1954190702558494

Epoch: 6| Step: 4
Training loss: 3.539575535386005
Validation loss: 3.1941826195144576

Epoch: 6| Step: 5
Training loss: 3.2270135079388687
Validation loss: 3.191584258417415

Epoch: 6| Step: 6
Training loss: 3.887741675024985
Validation loss: 3.1857351395333176

Epoch: 6| Step: 7
Training loss: 3.2397111742772404
Validation loss: 3.1818437636526578

Epoch: 6| Step: 8
Training loss: 3.736962607033577
Validation loss: 3.1795053406949667

Epoch: 6| Step: 9
Training loss: 3.5601239227842973
Validation loss: 3.171622783098279

Epoch: 6| Step: 10
Training loss: 3.31049574190784
Validation loss: 3.169446439697088

Epoch: 6| Step: 11
Training loss: 4.060367435308878
Validation loss: 3.1656459778216957

Epoch: 6| Step: 12
Training loss: 3.4992010022015876
Validation loss: 3.160076814143379

Epoch: 6| Step: 13
Training loss: 3.0711018176228775
Validation loss: 3.157532455675957

Epoch: 14| Step: 0
Training loss: 4.406834773225094
Validation loss: 3.155785970692464

Epoch: 6| Step: 1
Training loss: 3.546894896867375
Validation loss: 3.1570504691466588

Epoch: 6| Step: 2
Training loss: 3.6499778224323567
Validation loss: 3.149099314768978

Epoch: 6| Step: 3
Training loss: 3.6669211877281023
Validation loss: 3.1543297715158904

Epoch: 6| Step: 4
Training loss: 3.6409175902576885
Validation loss: 3.1576771205869782

Epoch: 6| Step: 5
Training loss: 3.1674661296427593
Validation loss: 3.154136360178804

Epoch: 6| Step: 6
Training loss: 3.156072479392421
Validation loss: 3.154192379391123

Epoch: 6| Step: 7
Training loss: 3.2841521008728387
Validation loss: 3.152966703924213

Epoch: 6| Step: 8
Training loss: 3.158731523708083
Validation loss: 3.152390339068675

Epoch: 6| Step: 9
Training loss: 2.9571565427654334
Validation loss: 3.1510220895781282

Epoch: 6| Step: 10
Training loss: 3.497546016889383
Validation loss: 3.1491452647571703

Epoch: 6| Step: 11
Training loss: 2.8255397719819406
Validation loss: 3.1392032746140717

Epoch: 6| Step: 12
Training loss: 3.067139206290872
Validation loss: 3.1343727394887346

Epoch: 6| Step: 13
Training loss: 3.696144187839512
Validation loss: 3.1346331419927638

Epoch: 15| Step: 0
Training loss: 3.037375955442814
Validation loss: 3.133573711153445

Epoch: 6| Step: 1
Training loss: 3.00733527819295
Validation loss: 3.1302114204158236

Epoch: 6| Step: 2
Training loss: 3.7296823042093052
Validation loss: 3.1257268851912547

Epoch: 6| Step: 3
Training loss: 3.537424007179148
Validation loss: 3.1207736897961307

Epoch: 6| Step: 4
Training loss: 3.601071272509388
Validation loss: 3.1174016313501327

Epoch: 6| Step: 5
Training loss: 3.486629697434715
Validation loss: 3.111757538576405

Epoch: 6| Step: 6
Training loss: 3.632849908451549
Validation loss: 3.1095657772431804

Epoch: 6| Step: 7
Training loss: 3.0503907875728284
Validation loss: 3.1057754089672884

Epoch: 6| Step: 8
Training loss: 3.8296422326141353
Validation loss: 3.10217012554647

Epoch: 6| Step: 9
Training loss: 4.193351642546434
Validation loss: 3.102830729993281

Epoch: 6| Step: 10
Training loss: 3.7369108009952186
Validation loss: 3.1001831270524507

Epoch: 6| Step: 11
Training loss: 2.740327992542839
Validation loss: 3.102436795770982

Epoch: 6| Step: 12
Training loss: 2.112387872011215
Validation loss: 3.099487759679713

Epoch: 6| Step: 13
Training loss: 3.0288820751328425
Validation loss: 3.09731423263869

Epoch: 16| Step: 0
Training loss: 3.0510302257659783
Validation loss: 3.098452123197143

Epoch: 6| Step: 1
Training loss: 3.7906012802451143
Validation loss: 3.1028252950713218

Epoch: 6| Step: 2
Training loss: 3.411802473497559
Validation loss: 3.113707752122385

Epoch: 6| Step: 3
Training loss: 3.834934080072112
Validation loss: 3.1437465448098965

Epoch: 6| Step: 4
Training loss: 4.096681433439735
Validation loss: 3.0899317848005325

Epoch: 6| Step: 5
Training loss: 2.7728893329315447
Validation loss: 3.117524579006994

Epoch: 6| Step: 6
Training loss: 3.441738913626766
Validation loss: 3.1283481914404243

Epoch: 6| Step: 7
Training loss: 3.3018973184813656
Validation loss: 3.094676868639791

Epoch: 6| Step: 8
Training loss: 3.3370845350349945
Validation loss: 3.086883063603079

Epoch: 6| Step: 9
Training loss: 2.908675299563534
Validation loss: 3.089413462967584

Epoch: 6| Step: 10
Training loss: 3.0262085195075437
Validation loss: 3.1101676469406265

Epoch: 6| Step: 11
Training loss: 3.622054119799003
Validation loss: 3.127020899839874

Epoch: 6| Step: 12
Training loss: 3.5489229851968327
Validation loss: 3.0836804190996285

Epoch: 6| Step: 13
Training loss: 2.4179099819948373
Validation loss: 3.0815085210786965

Epoch: 17| Step: 0
Training loss: 2.857386830676251
Validation loss: 3.1205560403594443

Epoch: 6| Step: 1
Training loss: 3.0896588642733693
Validation loss: 3.11238348767059

Epoch: 6| Step: 2
Training loss: 3.2937461143629982
Validation loss: 3.093594183902493

Epoch: 6| Step: 3
Training loss: 3.7888888289773837
Validation loss: 3.089453760165127

Epoch: 6| Step: 4
Training loss: 3.145011306038868
Validation loss: 3.089413388284262

Epoch: 6| Step: 5
Training loss: 3.7008950001567267
Validation loss: 3.0921265639307385

Epoch: 6| Step: 6
Training loss: 3.442780202018302
Validation loss: 3.0903933966909216

Epoch: 6| Step: 7
Training loss: 3.289167751340749
Validation loss: 3.080538567026766

Epoch: 6| Step: 8
Training loss: 4.154268868176633
Validation loss: 3.0683786969109703

Epoch: 6| Step: 9
Training loss: 2.9664718721137393
Validation loss: 3.0642081129094536

Epoch: 6| Step: 10
Training loss: 3.0054948076308983
Validation loss: 3.0825252676921058

Epoch: 6| Step: 11
Training loss: 3.351936799602987
Validation loss: 3.0972770257370428

Epoch: 6| Step: 12
Training loss: 3.9584859450518266
Validation loss: 3.1348281622571332

Epoch: 6| Step: 13
Training loss: 2.3767517054655904
Validation loss: 3.073893625596757

Epoch: 18| Step: 0
Training loss: 2.927760433923388
Validation loss: 3.0981277975688446

Epoch: 6| Step: 1
Training loss: 3.4170143756871063
Validation loss: 3.100205502924705

Epoch: 6| Step: 2
Training loss: 3.413200636261224
Validation loss: 3.0840134711675935

Epoch: 6| Step: 3
Training loss: 2.710621488330089
Validation loss: 3.0675739899815215

Epoch: 6| Step: 4
Training loss: 3.144075690020849
Validation loss: 3.0573248684888665

Epoch: 6| Step: 5
Training loss: 3.629845898932901
Validation loss: 3.055314599011339

Epoch: 6| Step: 6
Training loss: 3.571476385613945
Validation loss: 3.05809055643481

Epoch: 6| Step: 7
Training loss: 3.0643211710755702
Validation loss: 3.064674872565189

Epoch: 6| Step: 8
Training loss: 2.6898451043667624
Validation loss: 3.072846468204828

Epoch: 6| Step: 9
Training loss: 3.6766281206376283
Validation loss: 3.086692243197353

Epoch: 6| Step: 10
Training loss: 4.275532043543949
Validation loss: 3.11434605937171

Epoch: 6| Step: 11
Training loss: 3.828677764221117
Validation loss: 3.067824295375705

Epoch: 6| Step: 12
Training loss: 2.922721536167706
Validation loss: 3.0479263599450688

Epoch: 6| Step: 13
Training loss: 3.275594433134368
Validation loss: 3.046137162724911

Epoch: 19| Step: 0
Training loss: 3.3640435005214897
Validation loss: 3.048728449390617

Epoch: 6| Step: 1
Training loss: 3.2806073240595026
Validation loss: 3.0607075706002274

Epoch: 6| Step: 2
Training loss: 3.1420539907263922
Validation loss: 3.0814665376016266

Epoch: 6| Step: 3
Training loss: 3.3984533550725695
Validation loss: 3.1223933039533724

Epoch: 6| Step: 4
Training loss: 3.4299014639533305
Validation loss: 3.095654167299795

Epoch: 6| Step: 5
Training loss: 2.9800617145061987
Validation loss: 3.04548392059952

Epoch: 6| Step: 6
Training loss: 3.1474113969398587
Validation loss: 3.0401942327016798

Epoch: 6| Step: 7
Training loss: 3.883902383349596
Validation loss: 3.047000219623792

Epoch: 6| Step: 8
Training loss: 3.6955870834823474
Validation loss: 3.083904880762498

Epoch: 6| Step: 9
Training loss: 3.3031290767070693
Validation loss: 3.0952135197771455

Epoch: 6| Step: 10
Training loss: 2.7605847481471892
Validation loss: 3.081453741279484

Epoch: 6| Step: 11
Training loss: 3.602058161391467
Validation loss: 3.0804483180292395

Epoch: 6| Step: 12
Training loss: 2.9345771370552924
Validation loss: 3.048350714020262

Epoch: 6| Step: 13
Training loss: 4.049071904971061
Validation loss: 3.034293412513687

Epoch: 20| Step: 0
Training loss: 3.623278505061975
Validation loss: 3.0303234481030437

Epoch: 6| Step: 1
Training loss: 3.577988267976345
Validation loss: 3.029727805199538

Epoch: 6| Step: 2
Training loss: 3.028813592272294
Validation loss: 3.0306329635143863

Epoch: 6| Step: 3
Training loss: 3.304276533252495
Validation loss: 3.034328893412995

Epoch: 6| Step: 4
Training loss: 2.606379817226942
Validation loss: 3.0351664820565247

Epoch: 6| Step: 5
Training loss: 3.454100320053848
Validation loss: 3.0372978106357884

Epoch: 6| Step: 6
Training loss: 3.6206291419172967
Validation loss: 3.0331093933901188

Epoch: 6| Step: 7
Training loss: 2.9955533770048004
Validation loss: 3.0301200232987586

Epoch: 6| Step: 8
Training loss: 3.1423031702665463
Validation loss: 3.033316889162418

Epoch: 6| Step: 9
Training loss: 3.0020882967595286
Validation loss: 3.0326247536281725

Epoch: 6| Step: 10
Training loss: 3.0515113963014806
Validation loss: 3.026863089307975

Epoch: 6| Step: 11
Training loss: 3.735301904285932
Validation loss: 3.032288488777831

Epoch: 6| Step: 12
Training loss: 3.5299123745597867
Validation loss: 3.039542972366707

Epoch: 6| Step: 13
Training loss: 3.838032385462362
Validation loss: 3.0155206936741017

Epoch: 21| Step: 0
Training loss: 2.762017262255004
Validation loss: 3.0125135994424967

Epoch: 6| Step: 1
Training loss: 3.1464146630623233
Validation loss: 3.011866112465334

Epoch: 6| Step: 2
Training loss: 3.4716816104073436
Validation loss: 3.0111020234826307

Epoch: 6| Step: 3
Training loss: 3.6506999350630203
Validation loss: 3.012516567719265

Epoch: 6| Step: 4
Training loss: 3.796944825586082
Validation loss: 3.0107185191714745

Epoch: 6| Step: 5
Training loss: 3.140639879181949
Validation loss: 3.011217864767139

Epoch: 6| Step: 6
Training loss: 2.8208637913947654
Validation loss: 3.013744429483061

Epoch: 6| Step: 7
Training loss: 3.042781486184714
Validation loss: 3.008293129009736

Epoch: 6| Step: 8
Training loss: 3.824304659602261
Validation loss: 3.0061910071955094

Epoch: 6| Step: 9
Training loss: 2.4545035406830413
Validation loss: 3.008268627563597

Epoch: 6| Step: 10
Training loss: 3.541872639370036
Validation loss: 3.0044753770600034

Epoch: 6| Step: 11
Training loss: 3.4878167230768327
Validation loss: 3.004047203536074

Epoch: 6| Step: 12
Training loss: 3.223115349637346
Validation loss: 3.0010217495620433

Epoch: 6| Step: 13
Training loss: 3.8334445660803467
Validation loss: 3.0005546094771494

Epoch: 22| Step: 0
Training loss: 3.375029104601793
Validation loss: 3.005063177543497

Epoch: 6| Step: 1
Training loss: 3.7564470185517105
Validation loss: 3.019870432881933

Epoch: 6| Step: 2
Training loss: 3.198684815506241
Validation loss: 3.0618022385824286

Epoch: 6| Step: 3
Training loss: 3.2347425169085406
Validation loss: 3.009621373586451

Epoch: 6| Step: 4
Training loss: 2.5313282707263527
Validation loss: 2.997420466704831

Epoch: 6| Step: 5
Training loss: 3.3440950875155604
Validation loss: 2.9969118239484853

Epoch: 6| Step: 6
Training loss: 3.1898587045498856
Validation loss: 2.996867169447557

Epoch: 6| Step: 7
Training loss: 2.827008611881186
Validation loss: 2.998624482876328

Epoch: 6| Step: 8
Training loss: 3.5314961575483568
Validation loss: 3.002246647816408

Epoch: 6| Step: 9
Training loss: 3.378933627508307
Validation loss: 3.0017540821593895

Epoch: 6| Step: 10
Training loss: 3.5405654242302025
Validation loss: 2.9988353837500314

Epoch: 6| Step: 11
Training loss: 3.0546845340958266
Validation loss: 2.9941617529899807

Epoch: 6| Step: 12
Training loss: 3.0962960911794157
Validation loss: 2.9936822437976085

Epoch: 6| Step: 13
Training loss: 4.394462673076037
Validation loss: 2.989220667128119

Epoch: 23| Step: 0
Training loss: 3.2650364979782207
Validation loss: 2.988589614978028

Epoch: 6| Step: 1
Training loss: 3.577004602921457
Validation loss: 2.9862340054919656

Epoch: 6| Step: 2
Training loss: 3.111810545030668
Validation loss: 2.986230348338583

Epoch: 6| Step: 3
Training loss: 3.42974297341776
Validation loss: 2.9877484100626504

Epoch: 6| Step: 4
Training loss: 3.5197398878573156
Validation loss: 2.9923581978804146

Epoch: 6| Step: 5
Training loss: 3.3345557037839666
Validation loss: 2.992022205808882

Epoch: 6| Step: 6
Training loss: 3.0960493694380986
Validation loss: 2.985272258530263

Epoch: 6| Step: 7
Training loss: 2.4911377229478107
Validation loss: 2.9807821882129097

Epoch: 6| Step: 8
Training loss: 3.193405962962916
Validation loss: 2.980709819613334

Epoch: 6| Step: 9
Training loss: 2.598363427295184
Validation loss: 2.978126198472972

Epoch: 6| Step: 10
Training loss: 3.885444347838657
Validation loss: 2.978504192156193

Epoch: 6| Step: 11
Training loss: 3.398851110785969
Validation loss: 2.9806073456708257

Epoch: 6| Step: 12
Training loss: 3.6015304597103825
Validation loss: 2.9815163777800566

Epoch: 6| Step: 13
Training loss: 3.00411069891051
Validation loss: 2.9841105163476116

Epoch: 24| Step: 0
Training loss: 3.531848957949303
Validation loss: 2.9794451715831802

Epoch: 6| Step: 1
Training loss: 2.6718189612864207
Validation loss: 2.97264653927724

Epoch: 6| Step: 2
Training loss: 2.4781999920613904
Validation loss: 2.9765671870580928

Epoch: 6| Step: 3
Training loss: 3.932012700507607
Validation loss: 2.9746632413051217

Epoch: 6| Step: 4
Training loss: 3.6148584501166687
Validation loss: 2.9760696820944244

Epoch: 6| Step: 5
Training loss: 3.3877503475008584
Validation loss: 2.973049862881879

Epoch: 6| Step: 6
Training loss: 3.077519546062459
Validation loss: 2.9739949912109673

Epoch: 6| Step: 7
Training loss: 3.70161658360658
Validation loss: 2.9758859324707627

Epoch: 6| Step: 8
Training loss: 3.1684166606906654
Validation loss: 2.974846223638297

Epoch: 6| Step: 9
Training loss: 3.9330368178075186
Validation loss: 2.9769037040538144

Epoch: 6| Step: 10
Training loss: 3.2172345788372523
Validation loss: 2.977322196266244

Epoch: 6| Step: 11
Training loss: 2.607416937319763
Validation loss: 2.9717553893761495

Epoch: 6| Step: 12
Training loss: 2.8416914982610377
Validation loss: 2.9718552493751846

Epoch: 6| Step: 13
Training loss: 3.1648484749100745
Validation loss: 2.97307732161926

Epoch: 25| Step: 0
Training loss: 3.33180713682486
Validation loss: 2.970786873755429

Epoch: 6| Step: 1
Training loss: 3.008689693009773
Validation loss: 2.9707944866908793

Epoch: 6| Step: 2
Training loss: 3.6526126864555266
Validation loss: 2.972926997360908

Epoch: 6| Step: 3
Training loss: 3.96424995072384
Validation loss: 2.9744610406905014

Epoch: 6| Step: 4
Training loss: 1.8388748371372354
Validation loss: 2.9604519235854068

Epoch: 6| Step: 5
Training loss: 2.9778207437379334
Validation loss: 2.957481000363161

Epoch: 6| Step: 6
Training loss: 3.52125146553678
Validation loss: 2.95998526978867

Epoch: 6| Step: 7
Training loss: 4.047425221629501
Validation loss: 2.965238193301128

Epoch: 6| Step: 8
Training loss: 3.3111776915590205
Validation loss: 2.961223350720842

Epoch: 6| Step: 9
Training loss: 3.3482910409031477
Validation loss: 2.9552000201585176

Epoch: 6| Step: 10
Training loss: 3.0549928166231655
Validation loss: 2.9534575312069964

Epoch: 6| Step: 11
Training loss: 2.984676964946627
Validation loss: 2.9546449474693177

Epoch: 6| Step: 12
Training loss: 2.6391314735230216
Validation loss: 2.9657331041219352

Epoch: 6| Step: 13
Training loss: 3.491221454311083
Validation loss: 2.9836942874291426

Epoch: 26| Step: 0
Training loss: 3.460121489139434
Validation loss: 2.985014371240459

Epoch: 6| Step: 1
Training loss: 3.863870450440605
Validation loss: 2.969566862355718

Epoch: 6| Step: 2
Training loss: 3.4846027111691655
Validation loss: 2.9521575660886414

Epoch: 6| Step: 3
Training loss: 2.563168322241934
Validation loss: 2.9486180190838427

Epoch: 6| Step: 4
Training loss: 2.618213418326751
Validation loss: 2.9501388095840797

Epoch: 6| Step: 5
Training loss: 2.632585193092364
Validation loss: 2.9499308512491367

Epoch: 6| Step: 6
Training loss: 3.5286061339825525
Validation loss: 2.948158438320609

Epoch: 6| Step: 7
Training loss: 2.980192759123269
Validation loss: 2.948433012517415

Epoch: 6| Step: 8
Training loss: 2.464981486345758
Validation loss: 2.9464293999260813

Epoch: 6| Step: 9
Training loss: 3.3158149686389318
Validation loss: 2.9419627434347886

Epoch: 6| Step: 10
Training loss: 3.4673023124069466
Validation loss: 2.9422599088547368

Epoch: 6| Step: 11
Training loss: 3.9394933105597874
Validation loss: 2.9474369326753034

Epoch: 6| Step: 12
Training loss: 3.476451537686708
Validation loss: 2.9380050186662428

Epoch: 6| Step: 13
Training loss: 3.2563363442715687
Validation loss: 2.9396399525317216

Epoch: 27| Step: 0
Training loss: 3.251059726191095
Validation loss: 2.9588680301182655

Epoch: 6| Step: 1
Training loss: 3.2346416861011638
Validation loss: 2.963792789218315

Epoch: 6| Step: 2
Training loss: 3.7318183095520356
Validation loss: 2.954307892632225

Epoch: 6| Step: 3
Training loss: 2.837364993475667
Validation loss: 2.935274939188088

Epoch: 6| Step: 4
Training loss: 3.045102586944264
Validation loss: 2.943059618505604

Epoch: 6| Step: 5
Training loss: 3.0208917195608045
Validation loss: 2.9793222238889565

Epoch: 6| Step: 6
Training loss: 3.483339438060418
Validation loss: 2.9936745332097345

Epoch: 6| Step: 7
Training loss: 3.34208309657891
Validation loss: 2.9365154432545078

Epoch: 6| Step: 8
Training loss: 2.785843645313138
Validation loss: 2.934266605467804

Epoch: 6| Step: 9
Training loss: 2.6555902896012338
Validation loss: 2.9316147072540213

Epoch: 6| Step: 10
Training loss: 3.968012703721415
Validation loss: 2.9323134582778754

Epoch: 6| Step: 11
Training loss: 3.7758742021279534
Validation loss: 2.9334417712070486

Epoch: 6| Step: 12
Training loss: 2.9648546864505145
Validation loss: 2.943285794470727

Epoch: 6| Step: 13
Training loss: 2.9838809258478585
Validation loss: 2.941900442555995

Epoch: 28| Step: 0
Training loss: 3.626378027658907
Validation loss: 2.930046640348499

Epoch: 6| Step: 1
Training loss: 3.722233911435829
Validation loss: 2.9267796704238984

Epoch: 6| Step: 2
Training loss: 2.7658780946602626
Validation loss: 2.9251737321616478

Epoch: 6| Step: 3
Training loss: 3.8394519377048857
Validation loss: 2.9248145640753593

Epoch: 6| Step: 4
Training loss: 2.904726511019721
Validation loss: 2.920723500052653

Epoch: 6| Step: 5
Training loss: 3.325448119290361
Validation loss: 2.917065332710541

Epoch: 6| Step: 6
Training loss: 2.799240390737587
Validation loss: 2.9158357787412075

Epoch: 6| Step: 7
Training loss: 3.350906272258146
Validation loss: 2.915614351976938

Epoch: 6| Step: 8
Training loss: 2.991170924632394
Validation loss: 2.923832551131626

Epoch: 6| Step: 9
Training loss: 3.11217491566404
Validation loss: 2.9277687489127646

Epoch: 6| Step: 10
Training loss: 3.4013645238917936
Validation loss: 2.9284319858897714

Epoch: 6| Step: 11
Training loss: 3.0022973165462674
Validation loss: 2.9059590610722132

Epoch: 6| Step: 12
Training loss: 2.739266864401265
Validation loss: 2.9082647796523657

Epoch: 6| Step: 13
Training loss: 3.531694232376435
Validation loss: 2.9170683541690736

Epoch: 29| Step: 0
Training loss: 3.064060669878501
Validation loss: 2.920819200411309

Epoch: 6| Step: 1
Training loss: 2.865142841606264
Validation loss: 2.9067774979880316

Epoch: 6| Step: 2
Training loss: 3.324170409230991
Validation loss: 2.907483417273701

Epoch: 6| Step: 3
Training loss: 3.1125153445436267
Validation loss: 2.908275334735754

Epoch: 6| Step: 4
Training loss: 2.981295129846275
Validation loss: 2.909223751919964

Epoch: 6| Step: 5
Training loss: 3.6445612114004917
Validation loss: 2.9103223074003157

Epoch: 6| Step: 6
Training loss: 2.853867192579371
Validation loss: 2.9123853144466754

Epoch: 6| Step: 7
Training loss: 3.5597361501149294
Validation loss: 2.915936564698993

Epoch: 6| Step: 8
Training loss: 3.040719254886273
Validation loss: 2.9212148465815257

Epoch: 6| Step: 9
Training loss: 3.5987948625742234
Validation loss: 2.9184184914911913

Epoch: 6| Step: 10
Training loss: 2.9415150251197715
Validation loss: 2.9210715933996654

Epoch: 6| Step: 11
Training loss: 2.4942396558012
Validation loss: 2.919464889677027

Epoch: 6| Step: 12
Training loss: 3.6889430956196283
Validation loss: 2.9225864146441256

Epoch: 6| Step: 13
Training loss: 3.9260138447498476
Validation loss: 2.910847344726152

Epoch: 30| Step: 0
Training loss: 2.353484524723197
Validation loss: 2.906695501677084

Epoch: 6| Step: 1
Training loss: 3.195938011819163
Validation loss: 2.904553483105207

Epoch: 6| Step: 2
Training loss: 3.3987384531344778
Validation loss: 2.911623734765555

Epoch: 6| Step: 3
Training loss: 3.0031594487813478
Validation loss: 2.928814534828915

Epoch: 6| Step: 4
Training loss: 3.204289815360838
Validation loss: 2.9454529100660096

Epoch: 6| Step: 5
Training loss: 3.3203802842345627
Validation loss: 2.907811329747544

Epoch: 6| Step: 6
Training loss: 2.662726819759906
Validation loss: 2.897480165663772

Epoch: 6| Step: 7
Training loss: 3.217484901469861
Validation loss: 2.9016017625359507

Epoch: 6| Step: 8
Training loss: 3.779556273397619
Validation loss: 2.908879105655862

Epoch: 6| Step: 9
Training loss: 3.7337267963517258
Validation loss: 2.908522691235176

Epoch: 6| Step: 10
Training loss: 3.178035072397207
Validation loss: 2.9040897803463626

Epoch: 6| Step: 11
Training loss: 3.388358910259704
Validation loss: 2.901790403344045

Epoch: 6| Step: 12
Training loss: 2.913452411839721
Validation loss: 2.8989282693439966

Epoch: 6| Step: 13
Training loss: 3.524714811435547
Validation loss: 2.8903328670071553

Epoch: 31| Step: 0
Training loss: 3.0210396181026007
Validation loss: 2.8855825959698893

Epoch: 6| Step: 1
Training loss: 2.8998315959572736
Validation loss: 2.887668856509104

Epoch: 6| Step: 2
Training loss: 3.131866845078624
Validation loss: 2.8838738133770487

Epoch: 6| Step: 3
Training loss: 3.111932210953717
Validation loss: 2.8831510627641843

Epoch: 6| Step: 4
Training loss: 3.0029852637133585
Validation loss: 2.8874798595782774

Epoch: 6| Step: 5
Training loss: 3.399767946290312
Validation loss: 2.881831313428747

Epoch: 6| Step: 6
Training loss: 3.3039887683852998
Validation loss: 2.8799267038352308

Epoch: 6| Step: 7
Training loss: 2.622691274527823
Validation loss: 2.8757233951295857

Epoch: 6| Step: 8
Training loss: 3.541108001328849
Validation loss: 2.8750461826119573

Epoch: 6| Step: 9
Training loss: 3.4612644290864405
Validation loss: 2.876797963227929

Epoch: 6| Step: 10
Training loss: 3.603444168498838
Validation loss: 2.8756958956138368

Epoch: 6| Step: 11
Training loss: 3.1998734508763835
Validation loss: 2.8704098149504516

Epoch: 6| Step: 12
Training loss: 3.1577534635632194
Validation loss: 2.8724274345416894

Epoch: 6| Step: 13
Training loss: 2.87545673225444
Validation loss: 2.870723570302918

Epoch: 32| Step: 0
Training loss: 3.655625249191226
Validation loss: 2.870505802174677

Epoch: 6| Step: 1
Training loss: 3.583252277492512
Validation loss: 2.8723947420914824

Epoch: 6| Step: 2
Training loss: 2.9838289889814127
Validation loss: 2.8696799346491813

Epoch: 6| Step: 3
Training loss: 3.036875273584203
Validation loss: 2.8899921295365987

Epoch: 6| Step: 4
Training loss: 3.2938834986695595
Validation loss: 2.8734365334412404

Epoch: 6| Step: 5
Training loss: 2.9709169209310144
Validation loss: 2.8699794374575203

Epoch: 6| Step: 6
Training loss: 2.730259528487266
Validation loss: 2.8665797306489837

Epoch: 6| Step: 7
Training loss: 3.1066474644909308
Validation loss: 2.8646160436349337

Epoch: 6| Step: 8
Training loss: 2.834343580515543
Validation loss: 2.8653088146356627

Epoch: 6| Step: 9
Training loss: 3.004346718509215
Validation loss: 2.8663332221045064

Epoch: 6| Step: 10
Training loss: 3.3913373770110096
Validation loss: 2.8663000934378315

Epoch: 6| Step: 11
Training loss: 3.2366192536526803
Validation loss: 2.8631157226420787

Epoch: 6| Step: 12
Training loss: 3.3705267755395307
Validation loss: 2.864065913718899

Epoch: 6| Step: 13
Training loss: 3.099715982777964
Validation loss: 2.8657036511156546

Epoch: 33| Step: 0
Training loss: 3.135316528208223
Validation loss: 2.8684809993905005

Epoch: 6| Step: 1
Training loss: 2.712201178479197
Validation loss: 2.87716958717718

Epoch: 6| Step: 2
Training loss: 3.553075403892328
Validation loss: 2.887241887215093

Epoch: 6| Step: 3
Training loss: 3.112929263253899
Validation loss: 2.9121613400100337

Epoch: 6| Step: 4
Training loss: 2.6222349772259834
Validation loss: 2.895854363520398

Epoch: 6| Step: 5
Training loss: 3.629679323434344
Validation loss: 2.88667750010996

Epoch: 6| Step: 6
Training loss: 3.3649149791298534
Validation loss: 2.8625095149285684

Epoch: 6| Step: 7
Training loss: 3.409916575465702
Validation loss: 2.861665066530663

Epoch: 6| Step: 8
Training loss: 3.2292723279504325
Validation loss: 2.8628236149486637

Epoch: 6| Step: 9
Training loss: 3.460937775553742
Validation loss: 2.8639969503943656

Epoch: 6| Step: 10
Training loss: 3.557052194662282
Validation loss: 2.8659749578284375

Epoch: 6| Step: 11
Training loss: 3.18048190753926
Validation loss: 2.864800076306833

Epoch: 6| Step: 12
Training loss: 2.95800990812694
Validation loss: 2.868878821794389

Epoch: 6| Step: 13
Training loss: 0.9691458785357878
Validation loss: 2.862062878801635

Epoch: 34| Step: 0
Training loss: 3.305498893814929
Validation loss: 2.8608084343093187

Epoch: 6| Step: 1
Training loss: 3.2349599410676633
Validation loss: 2.86140397611879

Epoch: 6| Step: 2
Training loss: 2.7484381315177466
Validation loss: 2.860649989726624

Epoch: 6| Step: 3
Training loss: 3.4052028621342956
Validation loss: 2.8592727842798946

Epoch: 6| Step: 4
Training loss: 2.8285137773393703
Validation loss: 2.8587014915657796

Epoch: 6| Step: 5
Training loss: 3.5231714253922126
Validation loss: 2.8592482091052083

Epoch: 6| Step: 6
Training loss: 2.508250545854869
Validation loss: 2.8632486581566776

Epoch: 6| Step: 7
Training loss: 3.037435140034999
Validation loss: 2.8604765192019244

Epoch: 6| Step: 8
Training loss: 2.908653004155701
Validation loss: 2.861481001562151

Epoch: 6| Step: 9
Training loss: 2.9228241546701943
Validation loss: 2.8615790710978892

Epoch: 6| Step: 10
Training loss: 3.455313562940027
Validation loss: 2.8582574731748087

Epoch: 6| Step: 11
Training loss: 3.5683668582297012
Validation loss: 2.8590419303415717

Epoch: 6| Step: 12
Training loss: 3.3491156478328117
Validation loss: 2.8583443622943774

Epoch: 6| Step: 13
Training loss: 3.460943975507133
Validation loss: 2.8567118340473123

Epoch: 35| Step: 0
Training loss: 3.190972474967237
Validation loss: 2.8585187729556187

Epoch: 6| Step: 1
Training loss: 3.709874179485378
Validation loss: 2.855540910683298

Epoch: 6| Step: 2
Training loss: 3.2672421772348232
Validation loss: 2.85477903937658

Epoch: 6| Step: 3
Training loss: 3.0122196557752345
Validation loss: 2.852853899921925

Epoch: 6| Step: 4
Training loss: 2.9282809123379026
Validation loss: 2.850744387481959

Epoch: 6| Step: 5
Training loss: 3.7358438962715734
Validation loss: 2.850183172839539

Epoch: 6| Step: 6
Training loss: 2.703139994144198
Validation loss: 2.8483476367630356

Epoch: 6| Step: 7
Training loss: 3.215983859576816
Validation loss: 2.847601501756896

Epoch: 6| Step: 8
Training loss: 3.4663220405452133
Validation loss: 2.8556375583963645

Epoch: 6| Step: 9
Training loss: 3.0201767481940576
Validation loss: 2.849188206830675

Epoch: 6| Step: 10
Training loss: 2.7454051732166076
Validation loss: 2.8521142677216256

Epoch: 6| Step: 11
Training loss: 2.575820355151764
Validation loss: 2.8458561571895014

Epoch: 6| Step: 12
Training loss: 2.4272681453779783
Validation loss: 2.8432182816480367

Epoch: 6| Step: 13
Training loss: 4.241900411484474
Validation loss: 2.8443793486471876

Epoch: 36| Step: 0
Training loss: 3.809459036321832
Validation loss: 2.841689587500248

Epoch: 6| Step: 1
Training loss: 2.3845430687382185
Validation loss: 2.841133061176485

Epoch: 6| Step: 2
Training loss: 3.398431045701486
Validation loss: 2.8395804274822396

Epoch: 6| Step: 3
Training loss: 3.4886980138860237
Validation loss: 2.8382051968232576

Epoch: 6| Step: 4
Training loss: 3.26898400251384
Validation loss: 2.8361589790546478

Epoch: 6| Step: 5
Training loss: 2.8917755311670112
Validation loss: 2.8365101699497406

Epoch: 6| Step: 6
Training loss: 3.4361369811920515
Validation loss: 2.836914179977396

Epoch: 6| Step: 7
Training loss: 2.7673056285938347
Validation loss: 2.835389275047192

Epoch: 6| Step: 8
Training loss: 2.6847102745208233
Validation loss: 2.837340681221896

Epoch: 6| Step: 9
Training loss: 2.88016543548995
Validation loss: 2.8495012984360626

Epoch: 6| Step: 10
Training loss: 3.508992224018551
Validation loss: 2.8877732337505644

Epoch: 6| Step: 11
Training loss: 2.9487110231418145
Validation loss: 2.917121402315431

Epoch: 6| Step: 12
Training loss: 3.255825983069619
Validation loss: 2.84181139096927

Epoch: 6| Step: 13
Training loss: 3.0568335914030036
Validation loss: 2.832109417372301

Epoch: 37| Step: 0
Training loss: 3.6777195942845573
Validation loss: 2.8401036017596284

Epoch: 6| Step: 1
Training loss: 3.387512184487139
Validation loss: 2.8453973062231377

Epoch: 6| Step: 2
Training loss: 3.044737080465267
Validation loss: 2.8524674496060674

Epoch: 6| Step: 3
Training loss: 2.534722195513535
Validation loss: 2.8648702757789053

Epoch: 6| Step: 4
Training loss: 3.1188183488408563
Validation loss: 2.8814250405015835

Epoch: 6| Step: 5
Training loss: 2.8737161506428106
Validation loss: 2.8459388542427675

Epoch: 6| Step: 6
Training loss: 4.032764239135145
Validation loss: 2.8339588559362476

Epoch: 6| Step: 7
Training loss: 3.2918095296125576
Validation loss: 2.82965131369029

Epoch: 6| Step: 8
Training loss: 3.002346869255389
Validation loss: 2.832740715080267

Epoch: 6| Step: 9
Training loss: 3.6503959806759134
Validation loss: 2.852959263341018

Epoch: 6| Step: 10
Training loss: 2.538658039450345
Validation loss: 2.8746651806287677

Epoch: 6| Step: 11
Training loss: 2.7930681117596667
Validation loss: 2.906995910692

Epoch: 6| Step: 12
Training loss: 3.3317309978839442
Validation loss: 2.9587708068426872

Epoch: 6| Step: 13
Training loss: 1.7948344710594952
Validation loss: 2.9579544705810887

Epoch: 38| Step: 0
Training loss: 3.4097747764154316
Validation loss: 3.0308754878520374

Epoch: 6| Step: 1
Training loss: 3.6530405940346515
Validation loss: 2.9442505551757256

Epoch: 6| Step: 2
Training loss: 3.2666630167519037
Validation loss: 2.834670493855361

Epoch: 6| Step: 3
Training loss: 2.9687862996341634
Validation loss: 2.8273498845373095

Epoch: 6| Step: 4
Training loss: 3.1209858862580075
Validation loss: 2.828935127208219

Epoch: 6| Step: 5
Training loss: 2.9488174266472047
Validation loss: 2.8279333761859116

Epoch: 6| Step: 6
Training loss: 3.2941365371691402
Validation loss: 2.832041659224648

Epoch: 6| Step: 7
Training loss: 3.1903501745333567
Validation loss: 2.8349350957998385

Epoch: 6| Step: 8
Training loss: 3.4571879378332904
Validation loss: 2.833952919848844

Epoch: 6| Step: 9
Training loss: 2.945507903156288
Validation loss: 2.8313837063418927

Epoch: 6| Step: 10
Training loss: 2.1066852516046657
Validation loss: 2.8290789100275604

Epoch: 6| Step: 11
Training loss: 3.3105507639634237
Validation loss: 2.827380933494053

Epoch: 6| Step: 12
Training loss: 2.9938431185772485
Validation loss: 2.826888480414539

Epoch: 6| Step: 13
Training loss: 3.6249412005687165
Validation loss: 2.823667334637427

Epoch: 39| Step: 0
Training loss: 2.9985147614337557
Validation loss: 2.823082299253296

Epoch: 6| Step: 1
Training loss: 3.124901426667984
Validation loss: 2.821331984442853

Epoch: 6| Step: 2
Training loss: 2.8948554347810274
Validation loss: 2.8197165884440767

Epoch: 6| Step: 3
Training loss: 3.662503234028609
Validation loss: 2.8181725861960483

Epoch: 6| Step: 4
Training loss: 2.753227767152108
Validation loss: 2.8186042972632666

Epoch: 6| Step: 5
Training loss: 3.044227897835101
Validation loss: 2.81721374478746

Epoch: 6| Step: 6
Training loss: 3.109922581288622
Validation loss: 2.8306480361598534

Epoch: 6| Step: 7
Training loss: 3.076232483281901
Validation loss: 2.825742512212423

Epoch: 6| Step: 8
Training loss: 2.8222972194922717
Validation loss: 2.8233413246708925

Epoch: 6| Step: 9
Training loss: 3.432717620552435
Validation loss: 2.8135895454215234

Epoch: 6| Step: 10
Training loss: 3.0777931615427403
Validation loss: 2.810481231350887

Epoch: 6| Step: 11
Training loss: 3.2974482756542574
Validation loss: 2.8086369700100517

Epoch: 6| Step: 12
Training loss: 3.3435375110455325
Validation loss: 2.809623858299928

Epoch: 6| Step: 13
Training loss: 2.983910329703775
Validation loss: 2.807917152848597

Epoch: 40| Step: 0
Training loss: 2.7589647517342906
Validation loss: 2.8096051776537414

Epoch: 6| Step: 1
Training loss: 3.0647464220402787
Validation loss: 2.807611082493947

Epoch: 6| Step: 2
Training loss: 3.4644179227655405
Validation loss: 2.80656073252857

Epoch: 6| Step: 3
Training loss: 3.103087542750548
Validation loss: 2.8056806339954545

Epoch: 6| Step: 4
Training loss: 2.766382146093098
Validation loss: 2.8083639891107466

Epoch: 6| Step: 5
Training loss: 2.760616271281763
Validation loss: 2.8049996011263696

Epoch: 6| Step: 6
Training loss: 3.2936921145367135
Validation loss: 2.798040740463432

Epoch: 6| Step: 7
Training loss: 3.646166076008196
Validation loss: 2.799120175733276

Epoch: 6| Step: 8
Training loss: 3.1156941520033903
Validation loss: 2.796324792610783

Epoch: 6| Step: 9
Training loss: 2.530474697104871
Validation loss: 2.8110809282830713

Epoch: 6| Step: 10
Training loss: 2.984119983582432
Validation loss: 2.8251146643364784

Epoch: 6| Step: 11
Training loss: 3.430526595995151
Validation loss: 2.8011120181136926

Epoch: 6| Step: 12
Training loss: 3.1214182354399593
Validation loss: 2.7862147003440265

Epoch: 6| Step: 13
Training loss: 3.5640549863261985
Validation loss: 2.7854804798774437

Epoch: 41| Step: 0
Training loss: 2.927508629868425
Validation loss: 2.7846536819625967

Epoch: 6| Step: 1
Training loss: 2.579413721909146
Validation loss: 2.787041232016809

Epoch: 6| Step: 2
Training loss: 3.2968418788602136
Validation loss: 2.7845753774474526

Epoch: 6| Step: 3
Training loss: 3.0977683125221627
Validation loss: 2.781588405785531

Epoch: 6| Step: 4
Training loss: 3.067305706309606
Validation loss: 2.7815520364635025

Epoch: 6| Step: 5
Training loss: 3.553501073684412
Validation loss: 2.779096650300612

Epoch: 6| Step: 6
Training loss: 2.8595941178210516
Validation loss: 2.779574176129848

Epoch: 6| Step: 7
Training loss: 3.6061113142455796
Validation loss: 2.7764942153013816

Epoch: 6| Step: 8
Training loss: 3.0287386529310827
Validation loss: 2.7754173282431154

Epoch: 6| Step: 9
Training loss: 3.1277478153592204
Validation loss: 2.7739731738844626

Epoch: 6| Step: 10
Training loss: 2.983948362522414
Validation loss: 2.7741041783455955

Epoch: 6| Step: 11
Training loss: 2.63594299207295
Validation loss: 2.7732861438419043

Epoch: 6| Step: 12
Training loss: 2.7706828446979133
Validation loss: 2.7727916722979553

Epoch: 6| Step: 13
Training loss: 3.9150155557491484
Validation loss: 2.777011464527273

Epoch: 42| Step: 0
Training loss: 2.9933958477240985
Validation loss: 2.7792248987131627

Epoch: 6| Step: 1
Training loss: 3.4470315740305137
Validation loss: 2.77915375999522

Epoch: 6| Step: 2
Training loss: 3.5747883660690483
Validation loss: 2.791771837315685

Epoch: 6| Step: 3
Training loss: 3.031313551403719
Validation loss: 2.7845414252274847

Epoch: 6| Step: 4
Training loss: 2.9581259713009116
Validation loss: 2.7737123137447366

Epoch: 6| Step: 5
Training loss: 2.7289229616646717
Validation loss: 2.7666974892760607

Epoch: 6| Step: 6
Training loss: 2.473732471529256
Validation loss: 2.7654684078174343

Epoch: 6| Step: 7
Training loss: 3.2297362450776927
Validation loss: 2.7639140199076038

Epoch: 6| Step: 8
Training loss: 3.1009880706252573
Validation loss: 2.761857872974157

Epoch: 6| Step: 9
Training loss: 3.16091121525002
Validation loss: 2.7631244723298973

Epoch: 6| Step: 10
Training loss: 3.0943396420617066
Validation loss: 2.7664954065639793

Epoch: 6| Step: 11
Training loss: 3.147020347594891
Validation loss: 2.769831843194435

Epoch: 6| Step: 12
Training loss: 3.4208648444771517
Validation loss: 2.764107026809211

Epoch: 6| Step: 13
Training loss: 2.3610716523507245
Validation loss: 2.764283579981477

Epoch: 43| Step: 0
Training loss: 2.8756417926446423
Validation loss: 2.7656850296735

Epoch: 6| Step: 1
Training loss: 3.4815914513945816
Validation loss: 2.7635446339806413

Epoch: 6| Step: 2
Training loss: 3.073813580153668
Validation loss: 2.7623698504437013

Epoch: 6| Step: 3
Training loss: 3.3329472954054036
Validation loss: 2.762254061590719

Epoch: 6| Step: 4
Training loss: 2.846533450628479
Validation loss: 2.7604289157724904

Epoch: 6| Step: 5
Training loss: 3.0992906066395736
Validation loss: 2.7613321873785917

Epoch: 6| Step: 6
Training loss: 3.039143303824155
Validation loss: 2.7569649759480725

Epoch: 6| Step: 7
Training loss: 2.527397143405762
Validation loss: 2.759834920762453

Epoch: 6| Step: 8
Training loss: 3.6231147862570587
Validation loss: 2.758952762655725

Epoch: 6| Step: 9
Training loss: 3.336002965637645
Validation loss: 2.7563885997310575

Epoch: 6| Step: 10
Training loss: 2.490514498644114
Validation loss: 2.7526233397019713

Epoch: 6| Step: 11
Training loss: 3.0972355175635777
Validation loss: 2.753726272095362

Epoch: 6| Step: 12
Training loss: 3.452387804422328
Validation loss: 2.7547815895220262

Epoch: 6| Step: 13
Training loss: 2.124536239282622
Validation loss: 2.7523131900952835

Epoch: 44| Step: 0
Training loss: 3.376994073728739
Validation loss: 2.753703939860836

Epoch: 6| Step: 1
Training loss: 3.0901708996372426
Validation loss: 2.7542276635174088

Epoch: 6| Step: 2
Training loss: 3.234638295536937
Validation loss: 2.756688494524905

Epoch: 6| Step: 3
Training loss: 2.6761337159509453
Validation loss: 2.7549899928330306

Epoch: 6| Step: 4
Training loss: 3.3425802876567006
Validation loss: 2.7515539717684905

Epoch: 6| Step: 5
Training loss: 3.5501374016619005
Validation loss: 2.7530158231391573

Epoch: 6| Step: 6
Training loss: 2.443801754454662
Validation loss: 2.75405372091541

Epoch: 6| Step: 7
Training loss: 2.768122176037345
Validation loss: 2.7511602510311706

Epoch: 6| Step: 8
Training loss: 3.1095717478091656
Validation loss: 2.7538168508726946

Epoch: 6| Step: 9
Training loss: 3.0094232383022974
Validation loss: 2.7533949073042927

Epoch: 6| Step: 10
Training loss: 2.7436898400873653
Validation loss: 2.7557464216221828

Epoch: 6| Step: 11
Training loss: 3.429283865636632
Validation loss: 2.7535605886327232

Epoch: 6| Step: 12
Training loss: 3.163358030661621
Validation loss: 2.752510492893968

Epoch: 6| Step: 13
Training loss: 2.8363225165856614
Validation loss: 2.7459445296035807

Epoch: 45| Step: 0
Training loss: 2.938169687106157
Validation loss: 2.7480931788793392

Epoch: 6| Step: 1
Training loss: 2.8905492824225933
Validation loss: 2.7441242349341204

Epoch: 6| Step: 2
Training loss: 2.9051043805855183
Validation loss: 2.746509871083888

Epoch: 6| Step: 3
Training loss: 3.1678748252106055
Validation loss: 2.7490034600387334

Epoch: 6| Step: 4
Training loss: 2.814987438980183
Validation loss: 2.755934487084484

Epoch: 6| Step: 5
Training loss: 3.3180708195611266
Validation loss: 2.792645370242961

Epoch: 6| Step: 6
Training loss: 3.2194981862818572
Validation loss: 2.880238122071536

Epoch: 6| Step: 7
Training loss: 3.5834517496340825
Validation loss: 2.8204404776728613

Epoch: 6| Step: 8
Training loss: 3.3251439744568505
Validation loss: 2.751561438454003

Epoch: 6| Step: 9
Training loss: 2.7193927224418375
Validation loss: 2.7378034502059942

Epoch: 6| Step: 10
Training loss: 3.171847338626306
Validation loss: 2.742843631235244

Epoch: 6| Step: 11
Training loss: 2.872676905935646
Validation loss: 2.7483014951721767

Epoch: 6| Step: 12
Training loss: 2.7193401178548275
Validation loss: 2.7493809397554774

Epoch: 6| Step: 13
Training loss: 3.375763135745342
Validation loss: 2.75415223587478

Epoch: 46| Step: 0
Training loss: 3.2908443598797175
Validation loss: 2.762803689261732

Epoch: 6| Step: 1
Training loss: 2.358344250800897
Validation loss: 2.7562090527299965

Epoch: 6| Step: 2
Training loss: 3.1796818013807964
Validation loss: 2.7540027688476214

Epoch: 6| Step: 3
Training loss: 2.8883425387503445
Validation loss: 2.7507059863503733

Epoch: 6| Step: 4
Training loss: 3.1031726722090283
Validation loss: 2.749250850641555

Epoch: 6| Step: 5
Training loss: 3.207708438276115
Validation loss: 2.743082271736761

Epoch: 6| Step: 6
Training loss: 2.9307286561421235
Validation loss: 2.743663863349885

Epoch: 6| Step: 7
Training loss: 2.640885379752264
Validation loss: 2.742934400683993

Epoch: 6| Step: 8
Training loss: 3.4405955854747132
Validation loss: 2.741002741706118

Epoch: 6| Step: 9
Training loss: 3.4324156179704266
Validation loss: 2.7387143450663802

Epoch: 6| Step: 10
Training loss: 3.138494727518765
Validation loss: 2.7394640764917826

Epoch: 6| Step: 11
Training loss: 2.7788077786608145
Validation loss: 2.738107109878465

Epoch: 6| Step: 12
Training loss: 3.196172845570879
Validation loss: 2.7381530725165595

Epoch: 6| Step: 13
Training loss: 3.3446316136158165
Validation loss: 2.7374409437212686

Epoch: 47| Step: 0
Training loss: 3.219054272538116
Validation loss: 2.747643246766398

Epoch: 6| Step: 1
Training loss: 2.6172926241130963
Validation loss: 2.7705384343557906

Epoch: 6| Step: 2
Training loss: 3.500817748315583
Validation loss: 2.795955206754978

Epoch: 6| Step: 3
Training loss: 3.318927215614833
Validation loss: 2.7655618293193562

Epoch: 6| Step: 4
Training loss: 2.001617969277375
Validation loss: 2.7376877291868724

Epoch: 6| Step: 5
Training loss: 3.1334255313159645
Validation loss: 2.7349757337115137

Epoch: 6| Step: 6
Training loss: 2.607458267243693
Validation loss: 2.7312604660727606

Epoch: 6| Step: 7
Training loss: 2.704379722145001
Validation loss: 2.7326470756746035

Epoch: 6| Step: 8
Training loss: 2.962764287177519
Validation loss: 2.7342121437902493

Epoch: 6| Step: 9
Training loss: 3.090756596154075
Validation loss: 2.731545776592447

Epoch: 6| Step: 10
Training loss: 3.3580254261356095
Validation loss: 2.7315691947198237

Epoch: 6| Step: 11
Training loss: 3.769429417949334
Validation loss: 2.730729400969035

Epoch: 6| Step: 12
Training loss: 3.324217889339636
Validation loss: 2.730678207088671

Epoch: 6| Step: 13
Training loss: 2.6004836219546164
Validation loss: 2.731267902821234

Epoch: 48| Step: 0
Training loss: 3.553559981722719
Validation loss: 2.7299110251063863

Epoch: 6| Step: 1
Training loss: 3.0669305632560357
Validation loss: 2.7296935140248815

Epoch: 6| Step: 2
Training loss: 2.758248961926392
Validation loss: 2.7275272431089292

Epoch: 6| Step: 3
Training loss: 2.4461757123502266
Validation loss: 2.7268024530216532

Epoch: 6| Step: 4
Training loss: 3.3931703638040123
Validation loss: 2.726542555419946

Epoch: 6| Step: 5
Training loss: 3.2137349883077233
Validation loss: 2.72377695478816

Epoch: 6| Step: 6
Training loss: 3.0594401741294353
Validation loss: 2.7232055081788498

Epoch: 6| Step: 7
Training loss: 3.5083740056837334
Validation loss: 2.7198269617763122

Epoch: 6| Step: 8
Training loss: 2.170089646522487
Validation loss: 2.720084821080043

Epoch: 6| Step: 9
Training loss: 2.9894072761045387
Validation loss: 2.722476721382847

Epoch: 6| Step: 10
Training loss: 2.8150056485920634
Validation loss: 2.7186276006721593

Epoch: 6| Step: 11
Training loss: 2.870454927336112
Validation loss: 2.7242685212477222

Epoch: 6| Step: 12
Training loss: 3.5071520619053786
Validation loss: 2.730329467952221

Epoch: 6| Step: 13
Training loss: 2.948202885368627
Validation loss: 2.7580838838413095

Epoch: 49| Step: 0
Training loss: 2.331263430150187
Validation loss: 2.763114327691664

Epoch: 6| Step: 1
Training loss: 3.302066710677962
Validation loss: 2.7779232516872763

Epoch: 6| Step: 2
Training loss: 3.970245560130917
Validation loss: 2.781397082947161

Epoch: 6| Step: 3
Training loss: 3.051332470358733
Validation loss: 2.717561382059285

Epoch: 6| Step: 4
Training loss: 3.0583352555798164
Validation loss: 2.714809956889524

Epoch: 6| Step: 5
Training loss: 3.862023931009357
Validation loss: 2.726239191202862

Epoch: 6| Step: 6
Training loss: 2.8648870318711173
Validation loss: 2.732350097572916

Epoch: 6| Step: 7
Training loss: 3.66417389722719
Validation loss: 2.748698927063927

Epoch: 6| Step: 8
Training loss: 2.592481187919557
Validation loss: 2.7572999431608727

Epoch: 6| Step: 9
Training loss: 2.112060758533143
Validation loss: 2.738597034634846

Epoch: 6| Step: 10
Training loss: 2.9406993568740636
Validation loss: 2.7424711324913584

Epoch: 6| Step: 11
Training loss: 3.2234868129521437
Validation loss: 2.735984586803134

Epoch: 6| Step: 12
Training loss: 2.7011474255209014
Validation loss: 2.7269803755442847

Epoch: 6| Step: 13
Training loss: 2.5776852319353782
Validation loss: 2.7205280604252393

Epoch: 50| Step: 0
Training loss: 3.382880582410658
Validation loss: 2.7203360987406775

Epoch: 6| Step: 1
Training loss: 2.517176179487463
Validation loss: 2.717986863863016

Epoch: 6| Step: 2
Training loss: 3.1544608909079956
Validation loss: 2.716929042672177

Epoch: 6| Step: 3
Training loss: 3.411059842119601
Validation loss: 2.714285208824401

Epoch: 6| Step: 4
Training loss: 2.8007101691043403
Validation loss: 2.711986439410877

Epoch: 6| Step: 5
Training loss: 3.062623313445288
Validation loss: 2.7140064255221996

Epoch: 6| Step: 6
Training loss: 2.730906089936452
Validation loss: 2.7115758551107656

Epoch: 6| Step: 7
Training loss: 3.332468842620458
Validation loss: 2.711921043717431

Epoch: 6| Step: 8
Training loss: 3.0507115393964153
Validation loss: 2.7133176640786796

Epoch: 6| Step: 9
Training loss: 2.9014745054937623
Validation loss: 2.727077044554617

Epoch: 6| Step: 10
Training loss: 3.1747243326016035
Validation loss: 2.7910829664523633

Epoch: 6| Step: 11
Training loss: 3.1047098252098992
Validation loss: 2.731543592629727

Epoch: 6| Step: 12
Training loss: 2.6562371646346596
Validation loss: 2.712215343585585

Epoch: 6| Step: 13
Training loss: 3.4439414966323922
Validation loss: 2.7096682433675183

Epoch: 51| Step: 0
Training loss: 2.654255915108908
Validation loss: 2.7102487257735137

Epoch: 6| Step: 1
Training loss: 2.69296790715872
Validation loss: 2.7090038100692295

Epoch: 6| Step: 2
Training loss: 2.517364090373297
Validation loss: 2.7070366111332587

Epoch: 6| Step: 3
Training loss: 2.7421821094253462
Validation loss: 2.7080082593370713

Epoch: 6| Step: 4
Training loss: 3.3248507014435473
Validation loss: 2.7109026727995236

Epoch: 6| Step: 5
Training loss: 3.0398861276481037
Validation loss: 2.7121156380394336

Epoch: 6| Step: 6
Training loss: 3.1741700536967388
Validation loss: 2.712956132451308

Epoch: 6| Step: 7
Training loss: 3.2474474052651536
Validation loss: 2.7151686696978032

Epoch: 6| Step: 8
Training loss: 3.5418575609409575
Validation loss: 2.713184343476639

Epoch: 6| Step: 9
Training loss: 3.231849753466193
Validation loss: 2.7144308495514773

Epoch: 6| Step: 10
Training loss: 2.5635496641362665
Validation loss: 2.7104217917298095

Epoch: 6| Step: 11
Training loss: 2.973159887731835
Validation loss: 2.7072214562488983

Epoch: 6| Step: 12
Training loss: 3.2954659727849114
Validation loss: 2.7091143053981037

Epoch: 6| Step: 13
Training loss: 3.7058650313790893
Validation loss: 2.707469666801511

Epoch: 52| Step: 0
Training loss: 2.775299392908066
Validation loss: 2.704268113805137

Epoch: 6| Step: 1
Training loss: 3.0985212429193165
Validation loss: 2.7013177871221936

Epoch: 6| Step: 2
Training loss: 3.248687772664941
Validation loss: 2.698615080958448

Epoch: 6| Step: 3
Training loss: 3.235485826004101
Validation loss: 2.7001699873427136

Epoch: 6| Step: 4
Training loss: 3.121776291333952
Validation loss: 2.698167036149796

Epoch: 6| Step: 5
Training loss: 3.0584824348158595
Validation loss: 2.6976229948539374

Epoch: 6| Step: 6
Training loss: 3.1202026164458907
Validation loss: 2.696128828360644

Epoch: 6| Step: 7
Training loss: 3.231827917012393
Validation loss: 2.7036116991318466

Epoch: 6| Step: 8
Training loss: 2.473604186291872
Validation loss: 2.700204216219716

Epoch: 6| Step: 9
Training loss: 2.9187313038392606
Validation loss: 2.698973253334684

Epoch: 6| Step: 10
Training loss: 3.0485766231948697
Validation loss: 2.699658754600624

Epoch: 6| Step: 11
Training loss: 3.123225814722031
Validation loss: 2.7030326585173423

Epoch: 6| Step: 12
Training loss: 3.071917010279085
Validation loss: 2.7318923259848615

Epoch: 6| Step: 13
Training loss: 2.809031063832888
Validation loss: 2.760605816543368

Epoch: 53| Step: 0
Training loss: 3.974316275472161
Validation loss: 2.8042751501238743

Epoch: 6| Step: 1
Training loss: 2.5837726116990374
Validation loss: 2.763496845888521

Epoch: 6| Step: 2
Training loss: 3.5962767632966655
Validation loss: 2.739707212822321

Epoch: 6| Step: 3
Training loss: 2.6246553830592267
Validation loss: 2.702306709528652

Epoch: 6| Step: 4
Training loss: 2.173449048821312
Validation loss: 2.6936066910223566

Epoch: 6| Step: 5
Training loss: 3.1742085108590703
Validation loss: 2.6939435485951164

Epoch: 6| Step: 6
Training loss: 3.1870766152831296
Validation loss: 2.691273125161724

Epoch: 6| Step: 7
Training loss: 3.257409965108189
Validation loss: 2.6926629939008677

Epoch: 6| Step: 8
Training loss: 2.4687683491085304
Validation loss: 2.695997153877588

Epoch: 6| Step: 9
Training loss: 2.5350661533609933
Validation loss: 2.700090334120583

Epoch: 6| Step: 10
Training loss: 3.0299264436864455
Validation loss: 2.7022994596602534

Epoch: 6| Step: 11
Training loss: 3.2537520831200712
Validation loss: 2.7062220592847286

Epoch: 6| Step: 12
Training loss: 2.9319746931370827
Validation loss: 2.705859241372995

Epoch: 6| Step: 13
Training loss: 3.614245146981996
Validation loss: 2.6962697915491187

Epoch: 54| Step: 0
Training loss: 3.0307242340626392
Validation loss: 2.6949795729420645

Epoch: 6| Step: 1
Training loss: 3.284803518983319
Validation loss: 2.6923359589849087

Epoch: 6| Step: 2
Training loss: 3.2113621934392844
Validation loss: 2.692549900163778

Epoch: 6| Step: 3
Training loss: 3.4410073160605354
Validation loss: 2.6901014309504996

Epoch: 6| Step: 4
Training loss: 2.7465021255737723
Validation loss: 2.687536138743245

Epoch: 6| Step: 5
Training loss: 3.0668251480394932
Validation loss: 2.687034419702649

Epoch: 6| Step: 6
Training loss: 2.5786076874140473
Validation loss: 2.687738632631047

Epoch: 6| Step: 7
Training loss: 2.5029460714446206
Validation loss: 2.6891982104398746

Epoch: 6| Step: 8
Training loss: 3.0855131605996107
Validation loss: 2.704225226037671

Epoch: 6| Step: 9
Training loss: 3.527242090866195
Validation loss: 2.73816401370349

Epoch: 6| Step: 10
Training loss: 2.602972982851875
Validation loss: 2.7011292123611197

Epoch: 6| Step: 11
Training loss: 3.195935176998841
Validation loss: 2.688398343179634

Epoch: 6| Step: 12
Training loss: 3.2118086549669496
Validation loss: 2.6896391203963916

Epoch: 6| Step: 13
Training loss: 2.2412631691558014
Validation loss: 2.684394133021146

Epoch: 55| Step: 0
Training loss: 2.801631697285767
Validation loss: 2.6832785298182698

Epoch: 6| Step: 1
Training loss: 3.619625975112212
Validation loss: 2.6859188956798867

Epoch: 6| Step: 2
Training loss: 2.9659473240008087
Validation loss: 2.6833236077612077

Epoch: 6| Step: 3
Training loss: 3.5531896097151767
Validation loss: 2.6828862890829144

Epoch: 6| Step: 4
Training loss: 3.3983521900211984
Validation loss: 2.6854259350822924

Epoch: 6| Step: 5
Training loss: 3.0241162230747785
Validation loss: 2.6838653207801166

Epoch: 6| Step: 6
Training loss: 3.1167799604363062
Validation loss: 2.685517541689752

Epoch: 6| Step: 7
Training loss: 2.105101148118787
Validation loss: 2.700399382406538

Epoch: 6| Step: 8
Training loss: 3.228528917565648
Validation loss: 2.708932184378067

Epoch: 6| Step: 9
Training loss: 2.7831218292677433
Validation loss: 2.7381303473649434

Epoch: 6| Step: 10
Training loss: 2.926066447110399
Validation loss: 2.719095557268712

Epoch: 6| Step: 11
Training loss: 2.954714876932677
Validation loss: 2.684382940204667

Epoch: 6| Step: 12
Training loss: 3.0654488204742982
Validation loss: 2.682551203898083

Epoch: 6| Step: 13
Training loss: 1.886565397676445
Validation loss: 2.6844441190733237

Epoch: 56| Step: 0
Training loss: 2.622713637327814
Validation loss: 2.695482350627736

Epoch: 6| Step: 1
Training loss: 3.069523600789416
Validation loss: 2.7028287191371265

Epoch: 6| Step: 2
Training loss: 2.3159086519585155
Validation loss: 2.7070514747036833

Epoch: 6| Step: 3
Training loss: 3.2922171281333212
Validation loss: 2.696687394953365

Epoch: 6| Step: 4
Training loss: 3.5997116397234037
Validation loss: 2.6926249893062884

Epoch: 6| Step: 5
Training loss: 3.088352928806261
Validation loss: 2.6879987127556872

Epoch: 6| Step: 6
Training loss: 3.05058962016192
Validation loss: 2.6832589151066286

Epoch: 6| Step: 7
Training loss: 3.479579482266943
Validation loss: 2.6803767026149585

Epoch: 6| Step: 8
Training loss: 3.659706242763918
Validation loss: 2.6834903213548165

Epoch: 6| Step: 9
Training loss: 3.753689794422803
Validation loss: 2.677727457836114

Epoch: 6| Step: 10
Training loss: 2.339664917290811
Validation loss: 2.681774390512654

Epoch: 6| Step: 11
Training loss: 2.06864188104784
Validation loss: 2.6820375734128286

Epoch: 6| Step: 12
Training loss: 2.7107461207663843
Validation loss: 2.6808569188621543

Epoch: 6| Step: 13
Training loss: 2.591873685249122
Validation loss: 2.6827761626583926

Epoch: 57| Step: 0
Training loss: 3.2703729455340196
Validation loss: 2.6808020308944807

Epoch: 6| Step: 1
Training loss: 2.6910158270034126
Validation loss: 2.6782767513946193

Epoch: 6| Step: 2
Training loss: 3.0531960673343495
Validation loss: 2.6791244446734104

Epoch: 6| Step: 3
Training loss: 1.9837593264922402
Validation loss: 2.6854864410431944

Epoch: 6| Step: 4
Training loss: 2.8547452539741425
Validation loss: 2.695172638643187

Epoch: 6| Step: 5
Training loss: 3.3421654199813395
Validation loss: 2.7113120456942474

Epoch: 6| Step: 6
Training loss: 3.047852344751181
Validation loss: 2.70107378627444

Epoch: 6| Step: 7
Training loss: 2.7597981077794667
Validation loss: 2.695415743217297

Epoch: 6| Step: 8
Training loss: 3.1493401759743813
Validation loss: 2.6904448991383485

Epoch: 6| Step: 9
Training loss: 3.62620682194595
Validation loss: 2.681577668028575

Epoch: 6| Step: 10
Training loss: 2.5013666232333245
Validation loss: 2.66978702399206

Epoch: 6| Step: 11
Training loss: 2.7032800530742502
Validation loss: 2.673906025582104

Epoch: 6| Step: 12
Training loss: 3.287754550840477
Validation loss: 2.671756140379873

Epoch: 6| Step: 13
Training loss: 3.7615855224087382
Validation loss: 2.6724737034257546

Epoch: 58| Step: 0
Training loss: 2.720744749518946
Validation loss: 2.677079121058975

Epoch: 6| Step: 1
Training loss: 2.4324229257415024
Validation loss: 2.675611059927559

Epoch: 6| Step: 2
Training loss: 3.1405870425839018
Validation loss: 2.676187936182613

Epoch: 6| Step: 3
Training loss: 3.170148407744348
Validation loss: 2.6764276971397756

Epoch: 6| Step: 4
Training loss: 3.0722620552367212
Validation loss: 2.6750477580040486

Epoch: 6| Step: 5
Training loss: 3.1365527421435218
Validation loss: 2.675708592219335

Epoch: 6| Step: 6
Training loss: 2.7836067415673535
Validation loss: 2.6735503763318773

Epoch: 6| Step: 7
Training loss: 3.6323191974378015
Validation loss: 2.6742320079475483

Epoch: 6| Step: 8
Training loss: 3.3168098195171236
Validation loss: 2.6754556307907373

Epoch: 6| Step: 9
Training loss: 2.5977153570578024
Validation loss: 2.6737837767428214

Epoch: 6| Step: 10
Training loss: 2.9707788862791706
Validation loss: 2.6726771581804916

Epoch: 6| Step: 11
Training loss: 3.2718834294863655
Validation loss: 2.671945265497465

Epoch: 6| Step: 12
Training loss: 3.0092887129252417
Validation loss: 2.6702840103235506

Epoch: 6| Step: 13
Training loss: 2.644019027981987
Validation loss: 2.6708554919016705

Epoch: 59| Step: 0
Training loss: 2.801236976140466
Validation loss: 2.6710712073207348

Epoch: 6| Step: 1
Training loss: 2.789608429123287
Validation loss: 2.667681459283341

Epoch: 6| Step: 2
Training loss: 2.8984457257506255
Validation loss: 2.6694550046054975

Epoch: 6| Step: 3
Training loss: 3.0622938437068834
Validation loss: 2.669678809289257

Epoch: 6| Step: 4
Training loss: 3.2476268320079553
Validation loss: 2.6649106801306295

Epoch: 6| Step: 5
Training loss: 2.7957464743783587
Validation loss: 2.672113795662456

Epoch: 6| Step: 6
Training loss: 2.9985583338162405
Validation loss: 2.6742599235604954

Epoch: 6| Step: 7
Training loss: 3.394411003695887
Validation loss: 2.6794556543420995

Epoch: 6| Step: 8
Training loss: 3.5345299266045247
Validation loss: 2.6948524200132344

Epoch: 6| Step: 9
Training loss: 2.791018529400606
Validation loss: 2.690431170171615

Epoch: 6| Step: 10
Training loss: 3.0302251282706587
Validation loss: 2.678402423732362

Epoch: 6| Step: 11
Training loss: 2.905281315640579
Validation loss: 2.677420234445288

Epoch: 6| Step: 12
Training loss: 2.708012566766923
Validation loss: 2.6649737181984934

Epoch: 6| Step: 13
Training loss: 2.9976944011043067
Validation loss: 2.6635315954015315

Epoch: 60| Step: 0
Training loss: 2.8912313289344573
Validation loss: 2.6594740486596473

Epoch: 6| Step: 1
Training loss: 2.951571262683856
Validation loss: 2.6560430688620356

Epoch: 6| Step: 2
Training loss: 3.2674142416781486
Validation loss: 2.657076292707894

Epoch: 6| Step: 3
Training loss: 3.4854274922119375
Validation loss: 2.6584784756252633

Epoch: 6| Step: 4
Training loss: 3.14504830036766
Validation loss: 2.657481255266527

Epoch: 6| Step: 5
Training loss: 2.3702660613266713
Validation loss: 2.6521597092851517

Epoch: 6| Step: 6
Training loss: 3.0246131838814323
Validation loss: 2.6537770707771515

Epoch: 6| Step: 7
Training loss: 2.88253989649455
Validation loss: 2.653808321814459

Epoch: 6| Step: 8
Training loss: 3.1443736919475422
Validation loss: 2.6573867672073757

Epoch: 6| Step: 9
Training loss: 3.2940975982993557
Validation loss: 2.6557332800016025

Epoch: 6| Step: 10
Training loss: 2.0408187844300554
Validation loss: 2.657090615647271

Epoch: 6| Step: 11
Training loss: 2.8916376762879086
Validation loss: 2.6554809557288452

Epoch: 6| Step: 12
Training loss: 3.424441276698456
Validation loss: 2.6568754903802274

Epoch: 6| Step: 13
Training loss: 2.5556387807129806
Validation loss: 2.664786033928776

Epoch: 61| Step: 0
Training loss: 2.8550355428697913
Validation loss: 2.6588067284161996

Epoch: 6| Step: 1
Training loss: 2.4954500756410836
Validation loss: 2.6587941261980106

Epoch: 6| Step: 2
Training loss: 2.4273735385880357
Validation loss: 2.678293785632639

Epoch: 6| Step: 3
Training loss: 2.9397480255932638
Validation loss: 2.6764214940370303

Epoch: 6| Step: 4
Training loss: 3.342611529045283
Validation loss: 2.6839566329705367

Epoch: 6| Step: 5
Training loss: 3.2649146954782755
Validation loss: 2.6743756762981636

Epoch: 6| Step: 6
Training loss: 2.5745381691111526
Validation loss: 2.658152291539846

Epoch: 6| Step: 7
Training loss: 3.471183679185467
Validation loss: 2.6468069972020083

Epoch: 6| Step: 8
Training loss: 3.4115254558142967
Validation loss: 2.6473423394168867

Epoch: 6| Step: 9
Training loss: 2.434433597745787
Validation loss: 2.6496064610735166

Epoch: 6| Step: 10
Training loss: 3.235028924119934
Validation loss: 2.648892058393221

Epoch: 6| Step: 11
Training loss: 2.5412497152393065
Validation loss: 2.6543141964162946

Epoch: 6| Step: 12
Training loss: 3.596382835249977
Validation loss: 2.652123101056813

Epoch: 6| Step: 13
Training loss: 2.959463593104523
Validation loss: 2.6543145161090425

Epoch: 62| Step: 0
Training loss: 2.912000320203994
Validation loss: 2.6544188353017204

Epoch: 6| Step: 1
Training loss: 2.3137850928053965
Validation loss: 2.656611013279486

Epoch: 6| Step: 2
Training loss: 3.013568394306505
Validation loss: 2.6555413861465276

Epoch: 6| Step: 3
Training loss: 3.035911986380747
Validation loss: 2.6507705313546714

Epoch: 6| Step: 4
Training loss: 2.8159798181580054
Validation loss: 2.6542333679683545

Epoch: 6| Step: 5
Training loss: 3.081890455929385
Validation loss: 2.648927220857873

Epoch: 6| Step: 6
Training loss: 3.427551855895621
Validation loss: 2.6423162956606197

Epoch: 6| Step: 7
Training loss: 2.765420938495898
Validation loss: 2.6467167318852436

Epoch: 6| Step: 8
Training loss: 3.086678485998782
Validation loss: 2.647684390776213

Epoch: 6| Step: 9
Training loss: 3.2899786246396703
Validation loss: 2.681776962015323

Epoch: 6| Step: 10
Training loss: 2.54685197129399
Validation loss: 2.6788257610171335

Epoch: 6| Step: 11
Training loss: 2.995794845850238
Validation loss: 2.677280873768443

Epoch: 6| Step: 12
Training loss: 3.3484891302744892
Validation loss: 2.6855756982354757

Epoch: 6| Step: 13
Training loss: 3.285417072406583
Validation loss: 2.6567494375875227

Epoch: 63| Step: 0
Training loss: 2.470074069190557
Validation loss: 2.642611291548685

Epoch: 6| Step: 1
Training loss: 3.252034944072068
Validation loss: 2.646684578626534

Epoch: 6| Step: 2
Training loss: 3.3252906729626486
Validation loss: 2.639154181739685

Epoch: 6| Step: 3
Training loss: 3.236509788815437
Validation loss: 2.6427476728180794

Epoch: 6| Step: 4
Training loss: 2.427951597406873
Validation loss: 2.637761591085037

Epoch: 6| Step: 5
Training loss: 3.0100048447883623
Validation loss: 2.6426316619749977

Epoch: 6| Step: 6
Training loss: 2.8017111794655225
Validation loss: 2.65336611389504

Epoch: 6| Step: 7
Training loss: 3.6447226585505055
Validation loss: 2.6636993610101745

Epoch: 6| Step: 8
Training loss: 2.5706213675672007
Validation loss: 2.6517519540976737

Epoch: 6| Step: 9
Training loss: 3.5469310604824194
Validation loss: 2.6526640852435954

Epoch: 6| Step: 10
Training loss: 3.3396123080901425
Validation loss: 2.6578735572573087

Epoch: 6| Step: 11
Training loss: 2.5915366231136323
Validation loss: 2.6496701467296533

Epoch: 6| Step: 12
Training loss: 2.4575586768719386
Validation loss: 2.657501679565231

Epoch: 6| Step: 13
Training loss: 2.5835720895344276
Validation loss: 2.6514113112275095

Epoch: 64| Step: 0
Training loss: 3.1621840187202124
Validation loss: 2.6440416544688836

Epoch: 6| Step: 1
Training loss: 2.762135950326696
Validation loss: 2.645980777238241

Epoch: 6| Step: 2
Training loss: 2.8198982420614143
Validation loss: 2.6473464192102383

Epoch: 6| Step: 3
Training loss: 2.0806367079364425
Validation loss: 2.647294121264245

Epoch: 6| Step: 4
Training loss: 3.5264061307909196
Validation loss: 2.6464013118307053

Epoch: 6| Step: 5
Training loss: 2.426258967686176
Validation loss: 2.651638022355135

Epoch: 6| Step: 6
Training loss: 3.2220773627798387
Validation loss: 2.6522901809533326

Epoch: 6| Step: 7
Training loss: 3.136985681940734
Validation loss: 2.6419656681048007

Epoch: 6| Step: 8
Training loss: 3.0200281758288767
Validation loss: 2.6365663477865646

Epoch: 6| Step: 9
Training loss: 3.2198931691709936
Validation loss: 2.6323996380501775

Epoch: 6| Step: 10
Training loss: 2.8972647625913
Validation loss: 2.6307424929857013

Epoch: 6| Step: 11
Training loss: 2.9147357725389553
Validation loss: 2.6329485952799723

Epoch: 6| Step: 12
Training loss: 3.145470065601285
Validation loss: 2.6272747752445165

Epoch: 6| Step: 13
Training loss: 3.2512370469577045
Validation loss: 2.6374492330699764

Epoch: 65| Step: 0
Training loss: 2.7246286261640678
Validation loss: 2.6285165933353127

Epoch: 6| Step: 1
Training loss: 3.1723097329466503
Validation loss: 2.6324773198810676

Epoch: 6| Step: 2
Training loss: 3.0919196368947923
Validation loss: 2.6290214808432077

Epoch: 6| Step: 3
Training loss: 2.747520976659031
Validation loss: 2.6344229706160385

Epoch: 6| Step: 4
Training loss: 3.18352844545751
Validation loss: 2.6353125022475647

Epoch: 6| Step: 5
Training loss: 2.6494365596976097
Validation loss: 2.6385396630968465

Epoch: 6| Step: 6
Training loss: 3.337510321097542
Validation loss: 2.6564567220065314

Epoch: 6| Step: 7
Training loss: 3.296454090892858
Validation loss: 2.65846700301086

Epoch: 6| Step: 8
Training loss: 3.200830596178456
Validation loss: 2.63366290151551

Epoch: 6| Step: 9
Training loss: 2.850024166339342
Validation loss: 2.626867614371729

Epoch: 6| Step: 10
Training loss: 2.523058222089459
Validation loss: 2.629219712648793

Epoch: 6| Step: 11
Training loss: 2.7959127635635412
Validation loss: 2.6286686405908193

Epoch: 6| Step: 12
Training loss: 2.809451506764241
Validation loss: 2.630829923061591

Epoch: 6| Step: 13
Training loss: 3.3361356082312943
Validation loss: 2.6309453775673655

Epoch: 66| Step: 0
Training loss: 2.9509083335442594
Validation loss: 2.629280298129139

Epoch: 6| Step: 1
Training loss: 2.7167293010894458
Validation loss: 2.6309362774615614

Epoch: 6| Step: 2
Training loss: 3.23967128687419
Validation loss: 2.6307378699859614

Epoch: 6| Step: 3
Training loss: 3.2169682283975902
Validation loss: 2.630825845914438

Epoch: 6| Step: 4
Training loss: 3.5553358890970848
Validation loss: 2.628750687614798

Epoch: 6| Step: 5
Training loss: 3.1352204085020396
Validation loss: 2.6292045719109467

Epoch: 6| Step: 6
Training loss: 3.1298006948568413
Validation loss: 2.6278451042205297

Epoch: 6| Step: 7
Training loss: 3.3576498170604907
Validation loss: 2.6274896096687517

Epoch: 6| Step: 8
Training loss: 2.4175272647933648
Validation loss: 2.6218457156023143

Epoch: 6| Step: 9
Training loss: 2.2642497130734225
Validation loss: 2.621308603957976

Epoch: 6| Step: 10
Training loss: 3.256721734785566
Validation loss: 2.6237526736475236

Epoch: 6| Step: 11
Training loss: 3.0983985886893395
Validation loss: 2.6339233164193714

Epoch: 6| Step: 12
Training loss: 1.6803722316631455
Validation loss: 2.6458113493977824

Epoch: 6| Step: 13
Training loss: 2.985478541675142
Validation loss: 2.657830726258311

Epoch: 67| Step: 0
Training loss: 3.240129447282013
Validation loss: 2.680271383199553

Epoch: 6| Step: 1
Training loss: 3.3307380268534827
Validation loss: 2.6578823413609105

Epoch: 6| Step: 2
Training loss: 2.8482804314209695
Validation loss: 2.6253034667254

Epoch: 6| Step: 3
Training loss: 3.2222259419153017
Validation loss: 2.6222452816874227

Epoch: 6| Step: 4
Training loss: 2.62003820231301
Validation loss: 2.6170328710771855

Epoch: 6| Step: 5
Training loss: 2.7762525429471396
Validation loss: 2.6135140467111304

Epoch: 6| Step: 6
Training loss: 3.8191075833438233
Validation loss: 2.6163114200248723

Epoch: 6| Step: 7
Training loss: 2.3589877385511704
Validation loss: 2.611801413449899

Epoch: 6| Step: 8
Training loss: 2.9985678751293614
Validation loss: 2.614178225647818

Epoch: 6| Step: 9
Training loss: 2.466822584052985
Validation loss: 2.611380947872616

Epoch: 6| Step: 10
Training loss: 2.6263544130699037
Validation loss: 2.6117447581552087

Epoch: 6| Step: 11
Training loss: 3.58745109179185
Validation loss: 2.6133531674304606

Epoch: 6| Step: 12
Training loss: 2.29601442992431
Validation loss: 2.6180473912064817

Epoch: 6| Step: 13
Training loss: 2.94974643458049
Validation loss: 2.6198423210248585

Epoch: 68| Step: 0
Training loss: 2.5676219273099345
Validation loss: 2.6208384106313285

Epoch: 6| Step: 1
Training loss: 2.796132932283442
Validation loss: 2.6206282973894157

Epoch: 6| Step: 2
Training loss: 2.6795542158339067
Validation loss: 2.618826999462791

Epoch: 6| Step: 3
Training loss: 2.511260232558036
Validation loss: 2.6156187172314866

Epoch: 6| Step: 4
Training loss: 2.7685998122424844
Validation loss: 2.6137319513049895

Epoch: 6| Step: 5
Training loss: 2.9560406536151014
Validation loss: 2.6114864996072065

Epoch: 6| Step: 6
Training loss: 3.272960254776355
Validation loss: 2.614155925164961

Epoch: 6| Step: 7
Training loss: 3.5607884629024316
Validation loss: 2.613160008766858

Epoch: 6| Step: 8
Training loss: 2.7189651930258742
Validation loss: 2.61887360185013

Epoch: 6| Step: 9
Training loss: 3.4366111299730706
Validation loss: 2.6348574186569014

Epoch: 6| Step: 10
Training loss: 3.1782673281567293
Validation loss: 2.6321013290920257

Epoch: 6| Step: 11
Training loss: 3.530736024974362
Validation loss: 2.635404743785478

Epoch: 6| Step: 12
Training loss: 2.6325382802993027
Validation loss: 2.633718058389135

Epoch: 6| Step: 13
Training loss: 2.491385495280927
Validation loss: 2.6340262961429404

Epoch: 69| Step: 0
Training loss: 3.088863945668944
Validation loss: 2.6529597858671417

Epoch: 6| Step: 1
Training loss: 2.956353254712703
Validation loss: 2.6600018916176156

Epoch: 6| Step: 2
Training loss: 2.950126296103926
Validation loss: 2.642152145029954

Epoch: 6| Step: 3
Training loss: 3.100582861711073
Validation loss: 2.6188932553453856

Epoch: 6| Step: 4
Training loss: 3.5699605622236947
Validation loss: 2.6101218457717934

Epoch: 6| Step: 5
Training loss: 2.4918571420627176
Validation loss: 2.608203146584802

Epoch: 6| Step: 6
Training loss: 3.115269886161237
Validation loss: 2.6047606189971866

Epoch: 6| Step: 7
Training loss: 2.4932459195091297
Validation loss: 2.6059049676030495

Epoch: 6| Step: 8
Training loss: 3.213270690143799
Validation loss: 2.605255510329519

Epoch: 6| Step: 9
Training loss: 3.325583477022714
Validation loss: 2.607827950971178

Epoch: 6| Step: 10
Training loss: 3.040691968566543
Validation loss: 2.608601541524758

Epoch: 6| Step: 11
Training loss: 2.882914058064604
Validation loss: 2.608529004644053

Epoch: 6| Step: 12
Training loss: 2.285231368957631
Validation loss: 2.6048580218361526

Epoch: 6| Step: 13
Training loss: 2.456724211365209
Validation loss: 2.6006640348292143

Epoch: 70| Step: 0
Training loss: 3.2418118546504435
Validation loss: 2.6111029889758535

Epoch: 6| Step: 1
Training loss: 3.1174944963077764
Validation loss: 2.608535696464104

Epoch: 6| Step: 2
Training loss: 3.0784286116921984
Validation loss: 2.609318012010448

Epoch: 6| Step: 3
Training loss: 2.6895278554602537
Validation loss: 2.616805649292927

Epoch: 6| Step: 4
Training loss: 3.0474748069967346
Validation loss: 2.6241509528903575

Epoch: 6| Step: 5
Training loss: 4.092363661520658
Validation loss: 2.6187103909900786

Epoch: 6| Step: 6
Training loss: 2.993297560236645
Validation loss: 2.6076603473352287

Epoch: 6| Step: 7
Training loss: 2.797067134800234
Validation loss: 2.61179976639116

Epoch: 6| Step: 8
Training loss: 3.069483521348435
Validation loss: 2.6055404334180423

Epoch: 6| Step: 9
Training loss: 2.2966111219727314
Validation loss: 2.6161508744559065

Epoch: 6| Step: 10
Training loss: 2.549655449721095
Validation loss: 2.6165025451755257

Epoch: 6| Step: 11
Training loss: 2.9407593521090094
Validation loss: 2.6223683924284638

Epoch: 6| Step: 12
Training loss: 2.4658309483062704
Validation loss: 2.608973685878819

Epoch: 6| Step: 13
Training loss: 2.3843990859668747
Validation loss: 2.6062006272909093

Epoch: 71| Step: 0
Training loss: 3.1762181505860556
Validation loss: 2.603143158307312

Epoch: 6| Step: 1
Training loss: 3.2455829535217426
Validation loss: 2.5987596796986967

Epoch: 6| Step: 2
Training loss: 3.033027992670244
Validation loss: 2.5994072725983175

Epoch: 6| Step: 3
Training loss: 3.051874841506082
Validation loss: 2.5979935878451696

Epoch: 6| Step: 4
Training loss: 2.7123562401150436
Validation loss: 2.595681394680834

Epoch: 6| Step: 5
Training loss: 3.3333256880354627
Validation loss: 2.600082590946404

Epoch: 6| Step: 6
Training loss: 2.3797904440040614
Validation loss: 2.6005960487639657

Epoch: 6| Step: 7
Training loss: 2.9408104281687844
Validation loss: 2.595745644867394

Epoch: 6| Step: 8
Training loss: 2.4952654829952348
Validation loss: 2.5953135773301645

Epoch: 6| Step: 9
Training loss: 2.8581500321790863
Validation loss: 2.600193114480384

Epoch: 6| Step: 10
Training loss: 2.8488825497959263
Validation loss: 2.6035677398730552

Epoch: 6| Step: 11
Training loss: 3.1284569502239115
Validation loss: 2.6150934120302463

Epoch: 6| Step: 12
Training loss: 2.8132223261346065
Validation loss: 2.6207028427230132

Epoch: 6| Step: 13
Training loss: 3.3733662076964053
Validation loss: 2.6207906801099035

Epoch: 72| Step: 0
Training loss: 1.8785001510201729
Validation loss: 2.6351905322686644

Epoch: 6| Step: 1
Training loss: 3.1771229892611337
Validation loss: 2.6634064755788303

Epoch: 6| Step: 2
Training loss: 3.171626339641173
Validation loss: 2.6435232686974035

Epoch: 6| Step: 3
Training loss: 3.2607945394868962
Validation loss: 2.6071299163745714

Epoch: 6| Step: 4
Training loss: 2.6956815162923595
Validation loss: 2.5956646913866566

Epoch: 6| Step: 5
Training loss: 1.8499178120682742
Validation loss: 2.596774938182384

Epoch: 6| Step: 6
Training loss: 3.105860578661256
Validation loss: 2.602389006919782

Epoch: 6| Step: 7
Training loss: 2.8755167621090165
Validation loss: 2.6043133067201345

Epoch: 6| Step: 8
Training loss: 2.9077933530674196
Validation loss: 2.608722021722522

Epoch: 6| Step: 9
Training loss: 3.0226806955145182
Validation loss: 2.614598210986205

Epoch: 6| Step: 10
Training loss: 3.0601423881164216
Validation loss: 2.6123078141468326

Epoch: 6| Step: 11
Training loss: 3.491680748546188
Validation loss: 2.6116652606135484

Epoch: 6| Step: 12
Training loss: 3.2279559583247535
Validation loss: 2.6129822016297037

Epoch: 6| Step: 13
Training loss: 3.428206347714823
Validation loss: 2.607614613217804

Epoch: 73| Step: 0
Training loss: 3.306547178242488
Validation loss: 2.6022882823513953

Epoch: 6| Step: 1
Training loss: 2.423919897317075
Validation loss: 2.594555022799186

Epoch: 6| Step: 2
Training loss: 2.6877970863967433
Validation loss: 2.6059880446439165

Epoch: 6| Step: 3
Training loss: 2.847721554356651
Validation loss: 2.6770681543032815

Epoch: 6| Step: 4
Training loss: 3.2541238590669725
Validation loss: 2.7703918455662713

Epoch: 6| Step: 5
Training loss: 2.2720311589992286
Validation loss: 2.7249381184125387

Epoch: 6| Step: 6
Training loss: 3.0835342513598065
Validation loss: 2.7175332848586407

Epoch: 6| Step: 7
Training loss: 3.352033390853014
Validation loss: 2.697129494912776

Epoch: 6| Step: 8
Training loss: 3.1023311095027046
Validation loss: 2.66083306308664

Epoch: 6| Step: 9
Training loss: 2.5902537485962065
Validation loss: 2.6091227024761685

Epoch: 6| Step: 10
Training loss: 3.5642329234208954
Validation loss: 2.596466200930247

Epoch: 6| Step: 11
Training loss: 3.15802646914328
Validation loss: 2.589549152174189

Epoch: 6| Step: 12
Training loss: 2.6735415252833743
Validation loss: 2.586821935201327

Epoch: 6| Step: 13
Training loss: 2.6981006299390216
Validation loss: 2.589188083756137

Epoch: 74| Step: 0
Training loss: 3.0437894407376307
Validation loss: 2.5897297437295195

Epoch: 6| Step: 1
Training loss: 2.6343431862282385
Validation loss: 2.5937293840466955

Epoch: 6| Step: 2
Training loss: 2.6096154747443907
Validation loss: 2.5994834960337596

Epoch: 6| Step: 3
Training loss: 2.706506631501631
Validation loss: 2.600176130581162

Epoch: 6| Step: 4
Training loss: 2.788357856704971
Validation loss: 2.601607737439977

Epoch: 6| Step: 5
Training loss: 3.262138294031945
Validation loss: 2.59905453209075

Epoch: 6| Step: 6
Training loss: 3.6057302064006533
Validation loss: 2.599671819127417

Epoch: 6| Step: 7
Training loss: 2.702923629404431
Validation loss: 2.5971341463566895

Epoch: 6| Step: 8
Training loss: 2.1969002517399305
Validation loss: 2.5960095839164326

Epoch: 6| Step: 9
Training loss: 2.4863726184157158
Validation loss: 2.590477404076185

Epoch: 6| Step: 10
Training loss: 3.806301894562336
Validation loss: 2.5901143578201675

Epoch: 6| Step: 11
Training loss: 3.114634603803464
Validation loss: 2.5897609212591406

Epoch: 6| Step: 12
Training loss: 2.8743210695785097
Validation loss: 2.591128236403035

Epoch: 6| Step: 13
Training loss: 3.5950675870991002
Validation loss: 2.592380251451832

Epoch: 75| Step: 0
Training loss: 3.062502491229854
Validation loss: 2.595763405387159

Epoch: 6| Step: 1
Training loss: 2.9119829627576164
Validation loss: 2.588287974597235

Epoch: 6| Step: 2
Training loss: 3.013893064934513
Validation loss: 2.5846179430396705

Epoch: 6| Step: 3
Training loss: 3.008880187935632
Validation loss: 2.58752357967952

Epoch: 6| Step: 4
Training loss: 3.624168037442945
Validation loss: 2.588465413524322

Epoch: 6| Step: 5
Training loss: 3.5658911910730344
Validation loss: 2.5847257357463103

Epoch: 6| Step: 6
Training loss: 2.4323752890567616
Validation loss: 2.587855322688561

Epoch: 6| Step: 7
Training loss: 2.6324884685035563
Validation loss: 2.594019180406699

Epoch: 6| Step: 8
Training loss: 3.3791523573666926
Validation loss: 2.6059905020501586

Epoch: 6| Step: 9
Training loss: 2.389036061930899
Validation loss: 2.624456200865505

Epoch: 6| Step: 10
Training loss: 2.6517664150399978
Validation loss: 2.6711225603341178

Epoch: 6| Step: 11
Training loss: 2.5391267269520954
Validation loss: 2.736053633146451

Epoch: 6| Step: 12
Training loss: 3.2850830940873617
Validation loss: 2.81094372531857

Epoch: 6| Step: 13
Training loss: 2.65558687796358
Validation loss: 2.7241296345906285

Epoch: 76| Step: 0
Training loss: 3.1240235901355855
Validation loss: 2.6122013470666148

Epoch: 6| Step: 1
Training loss: 2.8130595180481515
Validation loss: 2.586365442320737

Epoch: 6| Step: 2
Training loss: 2.909656947781297
Validation loss: 2.584474363873366

Epoch: 6| Step: 3
Training loss: 3.0917891636629986
Validation loss: 2.5881271111229918

Epoch: 6| Step: 4
Training loss: 3.3887287234064405
Validation loss: 2.6011534915051575

Epoch: 6| Step: 5
Training loss: 2.944903519868352
Validation loss: 2.596594687532375

Epoch: 6| Step: 6
Training loss: 3.2285103079584165
Validation loss: 2.594625988062235

Epoch: 6| Step: 7
Training loss: 2.9940195874100293
Validation loss: 2.590565629989304

Epoch: 6| Step: 8
Training loss: 2.2649274080951094
Validation loss: 2.5874989222700218

Epoch: 6| Step: 9
Training loss: 3.4470066740559595
Validation loss: 2.5826407790026944

Epoch: 6| Step: 10
Training loss: 2.606085617040846
Validation loss: 2.5840046272088455

Epoch: 6| Step: 11
Training loss: 2.2778523892947433
Validation loss: 2.5823156212533687

Epoch: 6| Step: 12
Training loss: 2.9329220425650036
Validation loss: 2.577925918564276

Epoch: 6| Step: 13
Training loss: 3.0412575607738908
Validation loss: 2.5759495182509906

Epoch: 77| Step: 0
Training loss: 3.068770858786989
Validation loss: 2.5771696894356344

Epoch: 6| Step: 1
Training loss: 2.5046360898230002
Validation loss: 2.5846485385059035

Epoch: 6| Step: 2
Training loss: 2.6819803199188255
Validation loss: 2.5975573523143733

Epoch: 6| Step: 3
Training loss: 2.9547970191189674
Validation loss: 2.604855116544842

Epoch: 6| Step: 4
Training loss: 3.37710420922509
Validation loss: 2.6159832758467227

Epoch: 6| Step: 5
Training loss: 2.947278568145867
Validation loss: 2.6144618723683726

Epoch: 6| Step: 6
Training loss: 2.833824526526573
Validation loss: 2.6121367243416005

Epoch: 6| Step: 7
Training loss: 2.8565890388520447
Validation loss: 2.6208423477858536

Epoch: 6| Step: 8
Training loss: 2.602567278224159
Validation loss: 2.6095707631855674

Epoch: 6| Step: 9
Training loss: 3.2013104020705763
Validation loss: 2.593017968031998

Epoch: 6| Step: 10
Training loss: 2.966026261319497
Validation loss: 2.58038648929163

Epoch: 6| Step: 11
Training loss: 2.8924347032514395
Validation loss: 2.57159741600644

Epoch: 6| Step: 12
Training loss: 3.0706192135188553
Validation loss: 2.5709135198965725

Epoch: 6| Step: 13
Training loss: 3.025462495111478
Validation loss: 2.5733106382190534

Epoch: 78| Step: 0
Training loss: 3.2401557899037323
Validation loss: 2.5759382732174365

Epoch: 6| Step: 1
Training loss: 2.422116765906538
Validation loss: 2.5756321245152134

Epoch: 6| Step: 2
Training loss: 2.6841729440016615
Validation loss: 2.577617781566776

Epoch: 6| Step: 3
Training loss: 3.5413160412329825
Validation loss: 2.5763889218730163

Epoch: 6| Step: 4
Training loss: 3.1449339804216776
Validation loss: 2.57642373253275

Epoch: 6| Step: 5
Training loss: 2.886049680899502
Validation loss: 2.5761858944337774

Epoch: 6| Step: 6
Training loss: 2.627169847589047
Validation loss: 2.576148638476308

Epoch: 6| Step: 7
Training loss: 3.2707988145954623
Validation loss: 2.57213456857008

Epoch: 6| Step: 8
Training loss: 2.36679174558339
Validation loss: 2.573634920522796

Epoch: 6| Step: 9
Training loss: 2.7669252259491315
Validation loss: 2.5766915570876594

Epoch: 6| Step: 10
Training loss: 2.5852141967808597
Validation loss: 2.575670037894149

Epoch: 6| Step: 11
Training loss: 3.6244131468245326
Validation loss: 2.588850561052457

Epoch: 6| Step: 12
Training loss: 3.1105830467235505
Validation loss: 2.579687114254508

Epoch: 6| Step: 13
Training loss: 2.0902447182148665
Validation loss: 2.5784347512175954

Epoch: 79| Step: 0
Training loss: 3.685264038812769
Validation loss: 2.573437521477923

Epoch: 6| Step: 1
Training loss: 3.1438609291360278
Validation loss: 2.571995695925828

Epoch: 6| Step: 2
Training loss: 3.099275682800032
Validation loss: 2.5667527517828224

Epoch: 6| Step: 3
Training loss: 3.0229830930226327
Validation loss: 2.5683700862620458

Epoch: 6| Step: 4
Training loss: 2.5912867419908454
Validation loss: 2.568056199110893

Epoch: 6| Step: 5
Training loss: 2.746125960398531
Validation loss: 2.5668301596453627

Epoch: 6| Step: 6
Training loss: 2.4152777615937704
Validation loss: 2.569795892417528

Epoch: 6| Step: 7
Training loss: 2.646105975023428
Validation loss: 2.564265439612485

Epoch: 6| Step: 8
Training loss: 3.252299742225684
Validation loss: 2.568115120947974

Epoch: 6| Step: 9
Training loss: 2.806149582457424
Validation loss: 2.5630150714271562

Epoch: 6| Step: 10
Training loss: 2.5498018823591426
Validation loss: 2.5654282255198346

Epoch: 6| Step: 11
Training loss: 2.9036873624879567
Validation loss: 2.562603800082165

Epoch: 6| Step: 12
Training loss: 2.6473195464941517
Validation loss: 2.564797958520943

Epoch: 6| Step: 13
Training loss: 3.4604382983746307
Validation loss: 2.56850894133926

Epoch: 80| Step: 0
Training loss: 3.4103254383323764
Validation loss: 2.5758012100376906

Epoch: 6| Step: 1
Training loss: 2.865927603915317
Validation loss: 2.5768333364003873

Epoch: 6| Step: 2
Training loss: 3.154248651189033
Validation loss: 2.578779214267408

Epoch: 6| Step: 3
Training loss: 3.113319080845668
Validation loss: 2.5729200756629487

Epoch: 6| Step: 4
Training loss: 2.6309123894122624
Validation loss: 2.563736853944703

Epoch: 6| Step: 5
Training loss: 2.8522737634996123
Validation loss: 2.567529051861637

Epoch: 6| Step: 6
Training loss: 3.038675239424799
Validation loss: 2.5694861713433177

Epoch: 6| Step: 7
Training loss: 3.330068674381751
Validation loss: 2.562567717234936

Epoch: 6| Step: 8
Training loss: 2.610880251975381
Validation loss: 2.561996545564177

Epoch: 6| Step: 9
Training loss: 2.2703355949471615
Validation loss: 2.564502861754563

Epoch: 6| Step: 10
Training loss: 3.095570038543045
Validation loss: 2.5649561592220107

Epoch: 6| Step: 11
Training loss: 3.1343500259941006
Validation loss: 2.565163959168378

Epoch: 6| Step: 12
Training loss: 2.6056480975098384
Validation loss: 2.576705924904055

Epoch: 6| Step: 13
Training loss: 2.4188224012790696
Validation loss: 2.5730891939385327

Epoch: 81| Step: 0
Training loss: 3.0929592162291497
Validation loss: 2.6072056564111814

Epoch: 6| Step: 1
Training loss: 2.3379803658632614
Validation loss: 2.6818702724359285

Epoch: 6| Step: 2
Training loss: 3.0829525961657405
Validation loss: 2.7953644265955724

Epoch: 6| Step: 3
Training loss: 2.9782139959977743
Validation loss: 2.9192507856221694

Epoch: 6| Step: 4
Training loss: 3.253247032844857
Validation loss: 2.9052923227649274

Epoch: 6| Step: 5
Training loss: 3.290016887586668
Validation loss: 2.6371476510405936

Epoch: 6| Step: 6
Training loss: 2.9022151050834113
Validation loss: 2.560675211662344

Epoch: 6| Step: 7
Training loss: 2.7409668729854637
Validation loss: 2.6312640329197747

Epoch: 6| Step: 8
Training loss: 3.1332505221955786
Validation loss: 2.8309264398404212

Epoch: 6| Step: 9
Training loss: 3.1575429553132666
Validation loss: 3.0230844544925635

Epoch: 6| Step: 10
Training loss: 3.499279765546544
Validation loss: 3.064721723631998

Epoch: 6| Step: 11
Training loss: 3.7376306619418527
Validation loss: 3.0044496447666686

Epoch: 6| Step: 12
Training loss: 2.929848302878642
Validation loss: 2.83737693629257

Epoch: 6| Step: 13
Training loss: 3.554302756479363
Validation loss: 2.684752561157449

Epoch: 82| Step: 0
Training loss: 2.888425743032051
Validation loss: 2.602588639778624

Epoch: 6| Step: 1
Training loss: 2.8622377167190844
Validation loss: 2.5765752694446395

Epoch: 6| Step: 2
Training loss: 3.0142357348803506
Validation loss: 2.6910900910958633

Epoch: 6| Step: 3
Training loss: 2.9259460158358097
Validation loss: 2.7951859900119684

Epoch: 6| Step: 4
Training loss: 3.3407025577117104
Validation loss: 2.80025808515372

Epoch: 6| Step: 5
Training loss: 3.06746629020244
Validation loss: 2.6953429489234906

Epoch: 6| Step: 6
Training loss: 2.873641315012824
Validation loss: 2.586318773580345

Epoch: 6| Step: 7
Training loss: 2.566147139430012
Validation loss: 2.5792876902352138

Epoch: 6| Step: 8
Training loss: 3.278355366164619
Validation loss: 2.5734519971187693

Epoch: 6| Step: 9
Training loss: 3.020298947828332
Validation loss: 2.578520006811708

Epoch: 6| Step: 10
Training loss: 3.1513537207742166
Validation loss: 2.582094282056341

Epoch: 6| Step: 11
Training loss: 2.991521457417277
Validation loss: 2.5867172209244145

Epoch: 6| Step: 12
Training loss: 2.962545074248756
Validation loss: 2.5900504727406033

Epoch: 6| Step: 13
Training loss: 2.3509738730370615
Validation loss: 2.591330330564409

Epoch: 83| Step: 0
Training loss: 2.600086423464586
Validation loss: 2.594859128616073

Epoch: 6| Step: 1
Training loss: 2.904168480790902
Validation loss: 2.5940057653370534

Epoch: 6| Step: 2
Training loss: 2.8610608076922275
Validation loss: 2.5900991240877516

Epoch: 6| Step: 3
Training loss: 2.8601356703583916
Validation loss: 2.587377204139154

Epoch: 6| Step: 4
Training loss: 3.006571248549986
Validation loss: 2.5850769956848287

Epoch: 6| Step: 5
Training loss: 3.5747963693952696
Validation loss: 2.5816639882937626

Epoch: 6| Step: 6
Training loss: 2.813412242870522
Validation loss: 2.5802689136068535

Epoch: 6| Step: 7
Training loss: 3.1404279201029763
Validation loss: 2.5777750771548096

Epoch: 6| Step: 8
Training loss: 2.7724632593718264
Validation loss: 2.5764792859246177

Epoch: 6| Step: 9
Training loss: 2.435341490625977
Validation loss: 2.5759564638932666

Epoch: 6| Step: 10
Training loss: 3.098578182379676
Validation loss: 2.5715834114342284

Epoch: 6| Step: 11
Training loss: 2.9402529214553064
Validation loss: 2.5717982189095907

Epoch: 6| Step: 12
Training loss: 3.180183840541857
Validation loss: 2.5699857635090964

Epoch: 6| Step: 13
Training loss: 3.306756276126523
Validation loss: 2.570212732702707

Epoch: 84| Step: 0
Training loss: 2.3710129046915513
Validation loss: 2.5677465337698826

Epoch: 6| Step: 1
Training loss: 3.0614636283033505
Validation loss: 2.565385642858463

Epoch: 6| Step: 2
Training loss: 2.816450354115706
Validation loss: 2.5658302636599397

Epoch: 6| Step: 3
Training loss: 3.096186747515124
Validation loss: 2.558172771680579

Epoch: 6| Step: 4
Training loss: 3.0988954852914556
Validation loss: 2.554496229882206

Epoch: 6| Step: 5
Training loss: 3.0314434815627322
Validation loss: 2.547353488554417

Epoch: 6| Step: 6
Training loss: 2.8020977506774827
Validation loss: 2.568842819569239

Epoch: 6| Step: 7
Training loss: 2.6677208445974454
Validation loss: 2.6168599515917825

Epoch: 6| Step: 8
Training loss: 3.3387926377316393
Validation loss: 2.5979039997659394

Epoch: 6| Step: 9
Training loss: 3.2495527693335884
Validation loss: 2.5821037369802933

Epoch: 6| Step: 10
Training loss: 3.23797348271728
Validation loss: 2.5612747600671866

Epoch: 6| Step: 11
Training loss: 2.858673009532088
Validation loss: 2.549051037278036

Epoch: 6| Step: 12
Training loss: 2.314180227681108
Validation loss: 2.5527034552745973

Epoch: 6| Step: 13
Training loss: 3.0776534130739703
Validation loss: 2.5545046810131287

Epoch: 85| Step: 0
Training loss: 2.646200940484194
Validation loss: 2.5529760206221286

Epoch: 6| Step: 1
Training loss: 3.1347271402914147
Validation loss: 2.5441467924646264

Epoch: 6| Step: 2
Training loss: 2.634376853498755
Validation loss: 2.5455418508699807

Epoch: 6| Step: 3
Training loss: 2.9200936665600943
Validation loss: 2.5487483045612627

Epoch: 6| Step: 4
Training loss: 2.6901209271559092
Validation loss: 2.5588205083770292

Epoch: 6| Step: 5
Training loss: 3.4837853997727706
Validation loss: 2.61600971195623

Epoch: 6| Step: 6
Training loss: 2.75286196124345
Validation loss: 2.6291335707499526

Epoch: 6| Step: 7
Training loss: 2.6704992131937537
Validation loss: 2.643355671520395

Epoch: 6| Step: 8
Training loss: 3.0793375638029916
Validation loss: 2.6171181495868363

Epoch: 6| Step: 9
Training loss: 3.060189757603123
Validation loss: 2.5865990509071373

Epoch: 6| Step: 10
Training loss: 2.779142974645772
Validation loss: 2.5577121508640466

Epoch: 6| Step: 11
Training loss: 3.0815096608409256
Validation loss: 2.5458601119739015

Epoch: 6| Step: 12
Training loss: 2.912442245238203
Validation loss: 2.5402631315484903

Epoch: 6| Step: 13
Training loss: 3.237806186410304
Validation loss: 2.549917331966528

Epoch: 86| Step: 0
Training loss: 3.368712042486759
Validation loss: 2.553558779634526

Epoch: 6| Step: 1
Training loss: 2.6670672791286925
Validation loss: 2.566469496989983

Epoch: 6| Step: 2
Training loss: 2.6581173784158825
Validation loss: 2.5841492294986335

Epoch: 6| Step: 3
Training loss: 2.668022367460866
Validation loss: 2.612610767102736

Epoch: 6| Step: 4
Training loss: 3.0374054693889048
Validation loss: 2.6376031986931956

Epoch: 6| Step: 5
Training loss: 3.3465886411145473
Validation loss: 2.665820493832575

Epoch: 6| Step: 6
Training loss: 3.150785039534821
Validation loss: 2.6614535761753086

Epoch: 6| Step: 7
Training loss: 2.951917613422764
Validation loss: 2.6302396015626366

Epoch: 6| Step: 8
Training loss: 2.6017751062713472
Validation loss: 2.594075885833453

Epoch: 6| Step: 9
Training loss: 2.832102975923607
Validation loss: 2.5953113202150897

Epoch: 6| Step: 10
Training loss: 2.9559380590533286
Validation loss: 2.540768764485577

Epoch: 6| Step: 11
Training loss: 3.171174672051223
Validation loss: 2.543085627778302

Epoch: 6| Step: 12
Training loss: 2.434226454388313
Validation loss: 2.5500764226510433

Epoch: 6| Step: 13
Training loss: 2.7886713004709454
Validation loss: 2.5575596035558883

Epoch: 87| Step: 0
Training loss: 2.3316099978094034
Validation loss: 2.562548707208501

Epoch: 6| Step: 1
Training loss: 3.2141278606587957
Validation loss: 2.5639417320686175

Epoch: 6| Step: 2
Training loss: 3.0429413271489794
Validation loss: 2.573659761560318

Epoch: 6| Step: 3
Training loss: 3.0060927193276696
Validation loss: 2.571158091895349

Epoch: 6| Step: 4
Training loss: 2.6855195311107942
Validation loss: 2.56700085159843

Epoch: 6| Step: 5
Training loss: 2.4881278429396025
Validation loss: 2.5608265932995655

Epoch: 6| Step: 6
Training loss: 3.269707860700055
Validation loss: 2.5596425576865895

Epoch: 6| Step: 7
Training loss: 2.8518166624744983
Validation loss: 2.5585855538516324

Epoch: 6| Step: 8
Training loss: 3.143152235470277
Validation loss: 2.557575413007632

Epoch: 6| Step: 9
Training loss: 2.8806892163730757
Validation loss: 2.555340789277678

Epoch: 6| Step: 10
Training loss: 2.79177135062489
Validation loss: 2.5557643265031627

Epoch: 6| Step: 11
Training loss: 3.382246080159297
Validation loss: 2.5537832666306484

Epoch: 6| Step: 12
Training loss: 3.121807451252449
Validation loss: 2.554471457400045

Epoch: 6| Step: 13
Training loss: 2.9558880509792442
Validation loss: 2.554412250957196

Epoch: 88| Step: 0
Training loss: 2.4837613097549145
Validation loss: 2.551861832536704

Epoch: 6| Step: 1
Training loss: 2.7517210170092534
Validation loss: 2.5506959024706553

Epoch: 6| Step: 2
Training loss: 2.5592643965412814
Validation loss: 2.5461433125124358

Epoch: 6| Step: 3
Training loss: 2.8665601163475998
Validation loss: 2.550856423975303

Epoch: 6| Step: 4
Training loss: 2.978747269424679
Validation loss: 2.546109207512629

Epoch: 6| Step: 5
Training loss: 3.7889708832351703
Validation loss: 2.5424559820207695

Epoch: 6| Step: 6
Training loss: 3.0272678291891446
Validation loss: 2.542658687060722

Epoch: 6| Step: 7
Training loss: 2.774195092115667
Validation loss: 2.5436070766702463

Epoch: 6| Step: 8
Training loss: 2.7631846722999973
Validation loss: 2.5419899102691037

Epoch: 6| Step: 9
Training loss: 3.4408631951725526
Validation loss: 2.5421210595097183

Epoch: 6| Step: 10
Training loss: 2.9068358456376386
Validation loss: 2.5414598156538486

Epoch: 6| Step: 11
Training loss: 2.80704766642152
Validation loss: 2.5410376977041857

Epoch: 6| Step: 12
Training loss: 2.895162783774975
Validation loss: 2.5441898132322263

Epoch: 6| Step: 13
Training loss: 2.21163853830342
Validation loss: 2.558373577104287

Epoch: 89| Step: 0
Training loss: 2.9295120390165943
Validation loss: 2.558381192739472

Epoch: 6| Step: 1
Training loss: 3.1893568427368706
Validation loss: 2.5777191160812394

Epoch: 6| Step: 2
Training loss: 2.873659567785203
Validation loss: 2.594819696493781

Epoch: 6| Step: 3
Training loss: 2.8804195572636115
Validation loss: 2.581054549437812

Epoch: 6| Step: 4
Training loss: 3.5771296420216694
Validation loss: 2.585942163436249

Epoch: 6| Step: 5
Training loss: 2.8877633441216806
Validation loss: 2.5453355380414515

Epoch: 6| Step: 6
Training loss: 2.8426055282020477
Validation loss: 2.530428896166871

Epoch: 6| Step: 7
Training loss: 2.8398595334628447
Validation loss: 2.5349084011928955

Epoch: 6| Step: 8
Training loss: 2.545633024919066
Validation loss: 2.531708055436962

Epoch: 6| Step: 9
Training loss: 2.9989604738383964
Validation loss: 2.5317411950076103

Epoch: 6| Step: 10
Training loss: 2.558540634885224
Validation loss: 2.532439023124108

Epoch: 6| Step: 11
Training loss: 2.861987978522793
Validation loss: 2.5343821896241834

Epoch: 6| Step: 12
Training loss: 2.5993241311975464
Validation loss: 2.53109618802942

Epoch: 6| Step: 13
Training loss: 3.2603272902128464
Validation loss: 2.5309066853608155

Epoch: 90| Step: 0
Training loss: 2.8722444680600847
Validation loss: 2.5332573724939627

Epoch: 6| Step: 1
Training loss: 3.3079333226081338
Validation loss: 2.5326091156471797

Epoch: 6| Step: 2
Training loss: 2.7711290665369166
Validation loss: 2.5337843721199333

Epoch: 6| Step: 3
Training loss: 3.359063848235612
Validation loss: 2.5372541491883305

Epoch: 6| Step: 4
Training loss: 3.217202416376603
Validation loss: 2.549194081346599

Epoch: 6| Step: 5
Training loss: 2.4580263387946544
Validation loss: 2.5483573587262724

Epoch: 6| Step: 6
Training loss: 2.9723752023023136
Validation loss: 2.547789360653679

Epoch: 6| Step: 7
Training loss: 2.6679700010863647
Validation loss: 2.5422356084915467

Epoch: 6| Step: 8
Training loss: 2.4520762929326456
Validation loss: 2.5290856881409205

Epoch: 6| Step: 9
Training loss: 2.8731813068693652
Validation loss: 2.530450474623062

Epoch: 6| Step: 10
Training loss: 3.3191740350611947
Validation loss: 2.527531233600303

Epoch: 6| Step: 11
Training loss: 2.898171466638339
Validation loss: 2.5254860560737407

Epoch: 6| Step: 12
Training loss: 2.5385601779250817
Validation loss: 2.523714652334904

Epoch: 6| Step: 13
Training loss: 2.6006693638632186
Validation loss: 2.5206660224744337

Epoch: 91| Step: 0
Training loss: 3.6465377272476194
Validation loss: 2.5213585722245453

Epoch: 6| Step: 1
Training loss: 2.286264630036761
Validation loss: 2.5204959051328957

Epoch: 6| Step: 2
Training loss: 3.3098185500459865
Validation loss: 2.516009207207998

Epoch: 6| Step: 3
Training loss: 2.7471065905332064
Validation loss: 2.5194754559131924

Epoch: 6| Step: 4
Training loss: 3.331657004050561
Validation loss: 2.5176690317660864

Epoch: 6| Step: 5
Training loss: 2.881256096889309
Validation loss: 2.5203481105675016

Epoch: 6| Step: 6
Training loss: 2.426368040410027
Validation loss: 2.5312697393229295

Epoch: 6| Step: 7
Training loss: 3.0352817740191553
Validation loss: 2.5321991150199916

Epoch: 6| Step: 8
Training loss: 2.656800605703329
Validation loss: 2.5332461616023614

Epoch: 6| Step: 9
Training loss: 2.790769935936524
Validation loss: 2.5310046331399105

Epoch: 6| Step: 10
Training loss: 3.1708077575480904
Validation loss: 2.530044591225301

Epoch: 6| Step: 11
Training loss: 2.405289297171627
Validation loss: 2.5257494130803906

Epoch: 6| Step: 12
Training loss: 3.3020737865482475
Validation loss: 2.5286216869443106

Epoch: 6| Step: 13
Training loss: 1.8342612548083528
Validation loss: 2.527365818356218

Epoch: 92| Step: 0
Training loss: 2.9640132660665435
Validation loss: 2.5268187369293047

Epoch: 6| Step: 1
Training loss: 3.209563543767204
Validation loss: 2.5345472066275545

Epoch: 6| Step: 2
Training loss: 2.9800049107146283
Validation loss: 2.533617060138093

Epoch: 6| Step: 3
Training loss: 2.5574790331744564
Validation loss: 2.536053646831317

Epoch: 6| Step: 4
Training loss: 2.84710964404171
Validation loss: 2.5371750538730087

Epoch: 6| Step: 5
Training loss: 2.780522454930995
Validation loss: 2.5451452462433966

Epoch: 6| Step: 6
Training loss: 3.174644125871077
Validation loss: 2.543072603316417

Epoch: 6| Step: 7
Training loss: 2.5512422901506198
Validation loss: 2.542095564373023

Epoch: 6| Step: 8
Training loss: 3.040648686315759
Validation loss: 2.5509861073928413

Epoch: 6| Step: 9
Training loss: 3.1152308544748917
Validation loss: 2.5498911245428504

Epoch: 6| Step: 10
Training loss: 2.997010330788261
Validation loss: 2.5442793651150635

Epoch: 6| Step: 11
Training loss: 2.536284914034922
Validation loss: 2.5324915721503523

Epoch: 6| Step: 12
Training loss: 2.563059954986466
Validation loss: 2.5279854064876885

Epoch: 6| Step: 13
Training loss: 3.1861499096312254
Validation loss: 2.522031030873845

Epoch: 93| Step: 0
Training loss: 2.7076342242811857
Validation loss: 2.530504151994946

Epoch: 6| Step: 1
Training loss: 2.674345068214698
Validation loss: 2.5242667228036098

Epoch: 6| Step: 2
Training loss: 2.821125536781553
Validation loss: 2.5238683534593407

Epoch: 6| Step: 3
Training loss: 2.877529689923988
Validation loss: 2.5286942703959143

Epoch: 6| Step: 4
Training loss: 2.8566653227237255
Validation loss: 2.529516541344704

Epoch: 6| Step: 5
Training loss: 2.422606720674877
Validation loss: 2.5246678928221375

Epoch: 6| Step: 6
Training loss: 2.8339143793044483
Validation loss: 2.5285306365932265

Epoch: 6| Step: 7
Training loss: 2.5179066232845733
Validation loss: 2.525985148467525

Epoch: 6| Step: 8
Training loss: 3.111055772909859
Validation loss: 2.5261062869217468

Epoch: 6| Step: 9
Training loss: 3.014022638621928
Validation loss: 2.5247178183086567

Epoch: 6| Step: 10
Training loss: 3.0753889752750245
Validation loss: 2.5250275724796687

Epoch: 6| Step: 11
Training loss: 3.5886834296068204
Validation loss: 2.5243614062597795

Epoch: 6| Step: 12
Training loss: 2.752062370996297
Validation loss: 2.525860116919416

Epoch: 6| Step: 13
Training loss: 3.1029320294788008
Validation loss: 2.5489926362544453

Epoch: 94| Step: 0
Training loss: 3.1575390289141656
Validation loss: 2.5610592861601504

Epoch: 6| Step: 1
Training loss: 3.151700508451065
Validation loss: 2.574401090142133

Epoch: 6| Step: 2
Training loss: 2.6485392233068814
Validation loss: 2.5492869932373563

Epoch: 6| Step: 3
Training loss: 2.5061147296578437
Validation loss: 2.5258892612555015

Epoch: 6| Step: 4
Training loss: 2.802204701419878
Validation loss: 2.5196142904287817

Epoch: 6| Step: 5
Training loss: 3.276258759616056
Validation loss: 2.519448299430411

Epoch: 6| Step: 6
Training loss: 2.8560069108019226
Validation loss: 2.5214041495247153

Epoch: 6| Step: 7
Training loss: 2.796891707897896
Validation loss: 2.5182543092438734

Epoch: 6| Step: 8
Training loss: 3.2302560424889886
Validation loss: 2.517420994931884

Epoch: 6| Step: 9
Training loss: 2.6286049566736938
Validation loss: 2.522416570449214

Epoch: 6| Step: 10
Training loss: 2.389722965576422
Validation loss: 2.5217507321138246

Epoch: 6| Step: 11
Training loss: 2.709402479760577
Validation loss: 2.526364192959841

Epoch: 6| Step: 12
Training loss: 3.063416947090884
Validation loss: 2.5354398220608307

Epoch: 6| Step: 13
Training loss: 3.43227863839918
Validation loss: 2.543358209821875

Epoch: 95| Step: 0
Training loss: 3.643009567277499
Validation loss: 2.5634017096166426

Epoch: 6| Step: 1
Training loss: 2.619506446272696
Validation loss: 2.550886571134114

Epoch: 6| Step: 2
Training loss: 2.5946644469418625
Validation loss: 2.5353766958767348

Epoch: 6| Step: 3
Training loss: 3.016062018002207
Validation loss: 2.532341682561509

Epoch: 6| Step: 4
Training loss: 2.7664285128327046
Validation loss: 2.5251822343010315

Epoch: 6| Step: 5
Training loss: 3.4948451364503974
Validation loss: 2.5215744699292486

Epoch: 6| Step: 6
Training loss: 2.7858516044447352
Validation loss: 2.5223385791406283

Epoch: 6| Step: 7
Training loss: 2.9012703842505436
Validation loss: 2.5219455561366972

Epoch: 6| Step: 8
Training loss: 2.862657840824721
Validation loss: 2.516056430156765

Epoch: 6| Step: 9
Training loss: 2.730875271508231
Validation loss: 2.52029508151063

Epoch: 6| Step: 10
Training loss: 2.753409612798214
Validation loss: 2.521546847531118

Epoch: 6| Step: 11
Training loss: 2.910627943893035
Validation loss: 2.5380641764911207

Epoch: 6| Step: 12
Training loss: 2.2112051326670055
Validation loss: 2.564734008592712

Epoch: 6| Step: 13
Training loss: 3.099836277483795
Validation loss: 2.5731241408997563

Epoch: 96| Step: 0
Training loss: 2.499811356102911
Validation loss: 2.5683593510440943

Epoch: 6| Step: 1
Training loss: 3.140078672650507
Validation loss: 2.554943742081538

Epoch: 6| Step: 2
Training loss: 2.720857702110097
Validation loss: 2.5355909308492746

Epoch: 6| Step: 3
Training loss: 3.2332567133788457
Validation loss: 2.548576110493405

Epoch: 6| Step: 4
Training loss: 3.468450034978391
Validation loss: 2.5387233116953456

Epoch: 6| Step: 5
Training loss: 2.740432046950823
Validation loss: 2.556536003195782

Epoch: 6| Step: 6
Training loss: 3.033404813350456
Validation loss: 2.5673866508941767

Epoch: 6| Step: 7
Training loss: 3.3055200993393203
Validation loss: 2.5675372883556573

Epoch: 6| Step: 8
Training loss: 2.3892358471270727
Validation loss: 2.5605057760730343

Epoch: 6| Step: 9
Training loss: 2.5447374981176685
Validation loss: 2.5710779606148835

Epoch: 6| Step: 10
Training loss: 3.1064448520020878
Validation loss: 2.564813483465396

Epoch: 6| Step: 11
Training loss: 2.4897893291040334
Validation loss: 2.554173218363513

Epoch: 6| Step: 12
Training loss: 2.4529278912899506
Validation loss: 2.5355042985102485

Epoch: 6| Step: 13
Training loss: 3.22743416527723
Validation loss: 2.527658156188997

Epoch: 97| Step: 0
Training loss: 3.054159523685389
Validation loss: 2.5311116229230883

Epoch: 6| Step: 1
Training loss: 2.192097437579426
Validation loss: 2.5281596651627076

Epoch: 6| Step: 2
Training loss: 2.866164687659219
Validation loss: 2.5270045601980784

Epoch: 6| Step: 3
Training loss: 3.175929742886402
Validation loss: 2.5317740728971354

Epoch: 6| Step: 4
Training loss: 2.8851515628664033
Validation loss: 2.5301133204885056

Epoch: 6| Step: 5
Training loss: 3.024839091159195
Validation loss: 2.528232841889476

Epoch: 6| Step: 6
Training loss: 2.876701183384595
Validation loss: 2.532279863074957

Epoch: 6| Step: 7
Training loss: 2.9179579646512526
Validation loss: 2.5302042156042726

Epoch: 6| Step: 8
Training loss: 2.6251375071522483
Validation loss: 2.531774535649194

Epoch: 6| Step: 9
Training loss: 2.920525387045446
Validation loss: 2.5375259361717712

Epoch: 6| Step: 10
Training loss: 3.2697355691926906
Validation loss: 2.546617409474521

Epoch: 6| Step: 11
Training loss: 2.870672368896935
Validation loss: 2.5596639754988715

Epoch: 6| Step: 12
Training loss: 2.952334828097048
Validation loss: 2.579311167833344

Epoch: 6| Step: 13
Training loss: 2.7111439035426637
Validation loss: 2.6046540491290635

Epoch: 98| Step: 0
Training loss: 2.8284141434870596
Validation loss: 2.6359823137812524

Epoch: 6| Step: 1
Training loss: 2.7819691274809872
Validation loss: 2.6568155689125743

Epoch: 6| Step: 2
Training loss: 2.984616254871432
Validation loss: 2.660568334765815

Epoch: 6| Step: 3
Training loss: 3.0121656746760754
Validation loss: 2.6179018086916606

Epoch: 6| Step: 4
Training loss: 3.108478666151647
Validation loss: 2.5976333033642818

Epoch: 6| Step: 5
Training loss: 2.8354468223281803
Validation loss: 2.5833315076897634

Epoch: 6| Step: 6
Training loss: 2.9511495774927017
Validation loss: 2.567225767929693

Epoch: 6| Step: 7
Training loss: 2.9652358287153926
Validation loss: 2.5592596824898695

Epoch: 6| Step: 8
Training loss: 3.167948580488352
Validation loss: 2.559600688548457

Epoch: 6| Step: 9
Training loss: 2.6446260917031337
Validation loss: 2.561635522615925

Epoch: 6| Step: 10
Training loss: 3.0911364063782294
Validation loss: 2.5616958300751542

Epoch: 6| Step: 11
Training loss: 2.8690930928031766
Validation loss: 2.556268441738753

Epoch: 6| Step: 12
Training loss: 2.9656077570358677
Validation loss: 2.5527239546484797

Epoch: 6| Step: 13
Training loss: 2.700780921607181
Validation loss: 2.5543214113507897

Epoch: 99| Step: 0
Training loss: 2.661141682181319
Validation loss: 2.5535519909280517

Epoch: 6| Step: 1
Training loss: 2.995429690301713
Validation loss: 2.5562980467020253

Epoch: 6| Step: 2
Training loss: 2.5913683516198263
Validation loss: 2.5536714673170855

Epoch: 6| Step: 3
Training loss: 2.751930339602487
Validation loss: 2.5580149011052606

Epoch: 6| Step: 4
Training loss: 2.8005507200061825
Validation loss: 2.5538815978348732

Epoch: 6| Step: 5
Training loss: 3.172055244022457
Validation loss: 2.552650631369396

Epoch: 6| Step: 6
Training loss: 2.7910961782844974
Validation loss: 2.548679145881812

Epoch: 6| Step: 7
Training loss: 2.663127656839975
Validation loss: 2.5500603173875676

Epoch: 6| Step: 8
Training loss: 3.0242475661508976
Validation loss: 2.5481607692100545

Epoch: 6| Step: 9
Training loss: 2.9287773651394575
Validation loss: 2.541708249081947

Epoch: 6| Step: 10
Training loss: 2.8236798501725993
Validation loss: 2.549518797613759

Epoch: 6| Step: 11
Training loss: 3.348777342909321
Validation loss: 2.548245891787038

Epoch: 6| Step: 12
Training loss: 3.054597897203269
Validation loss: 2.551370315111555

Epoch: 6| Step: 13
Training loss: 2.917473399899909
Validation loss: 2.5507570113025566

Epoch: 100| Step: 0
Training loss: 1.4767939471952525
Validation loss: 2.5571185474173053

Epoch: 6| Step: 1
Training loss: 2.949818369559576
Validation loss: 2.570422392649498

Epoch: 6| Step: 2
Training loss: 2.9813111240990526
Validation loss: 2.5652319738515983

Epoch: 6| Step: 3
Training loss: 2.470838894336569
Validation loss: 2.568226794604537

Epoch: 6| Step: 4
Training loss: 3.5782126869884627
Validation loss: 2.5931214313350393

Epoch: 6| Step: 5
Training loss: 3.2673802381427035
Validation loss: 2.5898346064405278

Epoch: 6| Step: 6
Training loss: 3.384766188509763
Validation loss: 2.5975334977963493

Epoch: 6| Step: 7
Training loss: 2.923794855146385
Validation loss: 2.591320643178849

Epoch: 6| Step: 8
Training loss: 2.4271805270357483
Validation loss: 2.5644072611252904

Epoch: 6| Step: 9
Training loss: 2.2236791311875472
Validation loss: 2.5459985091128656

Epoch: 6| Step: 10
Training loss: 2.768845229739286
Validation loss: 2.549198565612283

Epoch: 6| Step: 11
Training loss: 3.4555561604010356
Validation loss: 2.5355358354387483

Epoch: 6| Step: 12
Training loss: 2.9042924420464655
Validation loss: 2.531591770358509

Epoch: 6| Step: 13
Training loss: 3.0833834738563715
Validation loss: 2.5261097414979856

Epoch: 101| Step: 0
Training loss: 2.778235355412402
Validation loss: 2.5172880027790576

Epoch: 6| Step: 1
Training loss: 2.50692657318743
Validation loss: 2.520407491655763

Epoch: 6| Step: 2
Training loss: 2.607843737817982
Validation loss: 2.5126761098276615

Epoch: 6| Step: 3
Training loss: 3.5255857968395077
Validation loss: 2.514763584417722

Epoch: 6| Step: 4
Training loss: 2.8949565703670794
Validation loss: 2.5138118535462404

Epoch: 6| Step: 5
Training loss: 2.8756504152398192
Validation loss: 2.5020102550532863

Epoch: 6| Step: 6
Training loss: 3.226208387991101
Validation loss: 2.50327511754201

Epoch: 6| Step: 7
Training loss: 2.336794488687621
Validation loss: 2.502833294964528

Epoch: 6| Step: 8
Training loss: 2.872954594668587
Validation loss: 2.503810032262612

Epoch: 6| Step: 9
Training loss: 2.2491897607639815
Validation loss: 2.50199001848263

Epoch: 6| Step: 10
Training loss: 3.0280121489952596
Validation loss: 2.5001242463196105

Epoch: 6| Step: 11
Training loss: 3.1845533925589304
Validation loss: 2.5015768492649273

Epoch: 6| Step: 12
Training loss: 2.946064577284462
Validation loss: 2.496395126975528

Epoch: 6| Step: 13
Training loss: 3.203130359179968
Validation loss: 2.4991610380635505

Epoch: 102| Step: 0
Training loss: 3.1332447391186733
Validation loss: 2.498654258674215

Epoch: 6| Step: 1
Training loss: 2.7788463020883114
Validation loss: 2.5034186277300634

Epoch: 6| Step: 2
Training loss: 2.6926791830839996
Validation loss: 2.5087989204003676

Epoch: 6| Step: 3
Training loss: 2.874515160852895
Validation loss: 2.509446232048451

Epoch: 6| Step: 4
Training loss: 2.703600450278272
Validation loss: 2.5059213112168583

Epoch: 6| Step: 5
Training loss: 2.790127590912605
Validation loss: 2.512992305212197

Epoch: 6| Step: 6
Training loss: 2.6531561392494525
Validation loss: 2.5050179471820586

Epoch: 6| Step: 7
Training loss: 3.2527495271053355
Validation loss: 2.516258351096479

Epoch: 6| Step: 8
Training loss: 3.2112778531979216
Validation loss: 2.503195561006225

Epoch: 6| Step: 9
Training loss: 2.510455868574531
Validation loss: 2.5013663465113902

Epoch: 6| Step: 10
Training loss: 3.321320791297651
Validation loss: 2.4961395626642027

Epoch: 6| Step: 11
Training loss: 3.029211086138159
Validation loss: 2.4985336556405144

Epoch: 6| Step: 12
Training loss: 2.4103582411938507
Validation loss: 2.4944343387208336

Epoch: 6| Step: 13
Training loss: 2.4494910081245567
Validation loss: 2.49764629540383

Epoch: 103| Step: 0
Training loss: 2.8624957621847043
Validation loss: 2.4980681410281353

Epoch: 6| Step: 1
Training loss: 3.011074447486828
Validation loss: 2.498694753877567

Epoch: 6| Step: 2
Training loss: 2.6267390167451095
Validation loss: 2.4927435569728584

Epoch: 6| Step: 3
Training loss: 2.632027075909424
Validation loss: 2.5001618404712205

Epoch: 6| Step: 4
Training loss: 3.0838144459695385
Validation loss: 2.505572258678562

Epoch: 6| Step: 5
Training loss: 2.970445490091837
Validation loss: 2.5035405027772852

Epoch: 6| Step: 6
Training loss: 2.9224053375863726
Validation loss: 2.5044775776184345

Epoch: 6| Step: 7
Training loss: 2.8367427807049825
Validation loss: 2.503739974282429

Epoch: 6| Step: 8
Training loss: 3.0169009340766753
Validation loss: 2.5014620023358116

Epoch: 6| Step: 9
Training loss: 2.808394593458319
Validation loss: 2.4957826266325975

Epoch: 6| Step: 10
Training loss: 2.5737014273848855
Validation loss: 2.4942383360741887

Epoch: 6| Step: 11
Training loss: 2.929585935739522
Validation loss: 2.505495747501478

Epoch: 6| Step: 12
Training loss: 2.802914199642772
Validation loss: 2.5122079022239587

Epoch: 6| Step: 13
Training loss: 3.002731351427839
Validation loss: 2.505266838489804

Epoch: 104| Step: 0
Training loss: 2.7665942374097785
Validation loss: 2.533409602140288

Epoch: 6| Step: 1
Training loss: 2.7209078238680426
Validation loss: 2.5799298464407614

Epoch: 6| Step: 2
Training loss: 2.831711660307953
Validation loss: 2.555616287406267

Epoch: 6| Step: 3
Training loss: 2.785465089600094
Validation loss: 2.528013304340483

Epoch: 6| Step: 4
Training loss: 3.21155744447725
Validation loss: 2.5180336145981

Epoch: 6| Step: 5
Training loss: 2.93298577359245
Validation loss: 2.5067850330630583

Epoch: 6| Step: 6
Training loss: 2.675194267990734
Validation loss: 2.505002078258784

Epoch: 6| Step: 7
Training loss: 3.3325619917739133
Validation loss: 2.5048737323702515

Epoch: 6| Step: 8
Training loss: 2.6511288811527858
Validation loss: 2.4945201127841243

Epoch: 6| Step: 9
Training loss: 2.8180228367483218
Validation loss: 2.5012224818070172

Epoch: 6| Step: 10
Training loss: 3.1685233612571833
Validation loss: 2.500049645946147

Epoch: 6| Step: 11
Training loss: 2.956803709923287
Validation loss: 2.495504597288633

Epoch: 6| Step: 12
Training loss: 2.4669033821895225
Validation loss: 2.4953616788408466

Epoch: 6| Step: 13
Training loss: 2.4601078633177274
Validation loss: 2.4951219754730696

Epoch: 105| Step: 0
Training loss: 2.7781369220833985
Validation loss: 2.492459231222082

Epoch: 6| Step: 1
Training loss: 2.338883701337839
Validation loss: 2.490608374676448

Epoch: 6| Step: 2
Training loss: 3.506615789307868
Validation loss: 2.5059618127729597

Epoch: 6| Step: 3
Training loss: 2.8059684357285075
Validation loss: 2.5019680828798077

Epoch: 6| Step: 4
Training loss: 2.718710800414469
Validation loss: 2.5007968565792265

Epoch: 6| Step: 5
Training loss: 2.9309590339622025
Validation loss: 2.5090743496204357

Epoch: 6| Step: 6
Training loss: 3.2672167827328344
Validation loss: 2.5225117491833022

Epoch: 6| Step: 7
Training loss: 2.555470011380478
Validation loss: 2.5298626540153673

Epoch: 6| Step: 8
Training loss: 2.512370403230739
Validation loss: 2.534087847443725

Epoch: 6| Step: 9
Training loss: 2.8595130762000345
Validation loss: 2.5494964373444975

Epoch: 6| Step: 10
Training loss: 3.072630960577183
Validation loss: 2.5539496951572382

Epoch: 6| Step: 11
Training loss: 2.756641517564419
Validation loss: 2.5647624832903353

Epoch: 6| Step: 12
Training loss: 3.103410837890361
Validation loss: 2.555175993450654

Epoch: 6| Step: 13
Training loss: 2.5813971821570463
Validation loss: 2.528757605974912

Epoch: 106| Step: 0
Training loss: 2.692786406830757
Validation loss: 2.517733410405546

Epoch: 6| Step: 1
Training loss: 2.8595200798875804
Validation loss: 2.5015293637366938

Epoch: 6| Step: 2
Training loss: 3.397909890797071
Validation loss: 2.4936265920913163

Epoch: 6| Step: 3
Training loss: 2.0693446938229085
Validation loss: 2.4997402733047323

Epoch: 6| Step: 4
Training loss: 3.0860867621141015
Validation loss: 2.4974424446862558

Epoch: 6| Step: 5
Training loss: 2.9506778972645864
Validation loss: 2.497684128028371

Epoch: 6| Step: 6
Training loss: 2.873539595167026
Validation loss: 2.49963635701958

Epoch: 6| Step: 7
Training loss: 3.0231889331769515
Validation loss: 2.501430227470149

Epoch: 6| Step: 8
Training loss: 3.039523445220953
Validation loss: 2.5211079880998857

Epoch: 6| Step: 9
Training loss: 2.4237992056720588
Validation loss: 2.5220528722814795

Epoch: 6| Step: 10
Training loss: 2.633125807234366
Validation loss: 2.552684480251826

Epoch: 6| Step: 11
Training loss: 3.0579532425214198
Validation loss: 2.551614801636318

Epoch: 6| Step: 12
Training loss: 2.7915411014691163
Validation loss: 2.538360800636068

Epoch: 6| Step: 13
Training loss: 2.842062648654486
Validation loss: 2.510314963514557

Epoch: 107| Step: 0
Training loss: 2.9957579184542675
Validation loss: 2.50651801941444

Epoch: 6| Step: 1
Training loss: 2.6880957364562916
Validation loss: 2.4974426274043866

Epoch: 6| Step: 2
Training loss: 3.123695864351443
Validation loss: 2.500757086363974

Epoch: 6| Step: 3
Training loss: 3.388939223063345
Validation loss: 2.4983675148972933

Epoch: 6| Step: 4
Training loss: 2.8854249111750914
Validation loss: 2.496800276217896

Epoch: 6| Step: 5
Training loss: 2.3241754607969685
Validation loss: 2.4954547705162877

Epoch: 6| Step: 6
Training loss: 3.1864421809571577
Validation loss: 2.499609758826692

Epoch: 6| Step: 7
Training loss: 2.320271398520649
Validation loss: 2.496940288865467

Epoch: 6| Step: 8
Training loss: 2.91180856380423
Validation loss: 2.5067043811214287

Epoch: 6| Step: 9
Training loss: 2.758550183241979
Validation loss: 2.502913814555146

Epoch: 6| Step: 10
Training loss: 2.456267075806878
Validation loss: 2.510061614136601

Epoch: 6| Step: 11
Training loss: 3.0405077010892936
Validation loss: 2.5188656331466728

Epoch: 6| Step: 12
Training loss: 2.6909386570522313
Validation loss: 2.5290617544301175

Epoch: 6| Step: 13
Training loss: 2.887188822835468
Validation loss: 2.5666344286898757

Epoch: 108| Step: 0
Training loss: 2.2748123678446373
Validation loss: 2.6016773919221348

Epoch: 6| Step: 1
Training loss: 1.9674369429646879
Validation loss: 2.67273211132935

Epoch: 6| Step: 2
Training loss: 3.505307668985427
Validation loss: 2.7501074563936787

Epoch: 6| Step: 3
Training loss: 1.7755780178837997
Validation loss: 2.665633692431065

Epoch: 6| Step: 4
Training loss: 1.8722547142813997
Validation loss: 2.6112037613308337

Epoch: 6| Step: 5
Training loss: 3.122457461773649
Validation loss: 2.5602339923251187

Epoch: 6| Step: 6
Training loss: 3.1006617547324864
Validation loss: 2.5061594282667703

Epoch: 6| Step: 7
Training loss: 2.819807097147695
Validation loss: 2.510271663475187

Epoch: 6| Step: 8
Training loss: 2.7582186218872295
Validation loss: 2.5040982003743695

Epoch: 6| Step: 9
Training loss: 3.077678512490399
Validation loss: 2.4987800277411605

Epoch: 6| Step: 10
Training loss: 2.6351563296189395
Validation loss: 2.49866751107852

Epoch: 6| Step: 11
Training loss: 3.6386426513939862
Validation loss: 2.4984128600334903

Epoch: 6| Step: 12
Training loss: 3.575043663345137
Validation loss: 2.5034416115353517

Epoch: 6| Step: 13
Training loss: 3.1407153368051777
Validation loss: 2.5058317246464257

Epoch: 109| Step: 0
Training loss: 3.142514699387142
Validation loss: 2.506794894753509

Epoch: 6| Step: 1
Training loss: 1.986252864885995
Validation loss: 2.4991989487978854

Epoch: 6| Step: 2
Training loss: 2.8441554189244074
Validation loss: 2.4977111316258735

Epoch: 6| Step: 3
Training loss: 2.572893325349722
Validation loss: 2.505346242275004

Epoch: 6| Step: 4
Training loss: 2.5797477470215844
Validation loss: 2.5065889631902896

Epoch: 6| Step: 5
Training loss: 2.698921154084642
Validation loss: 2.5190726606042024

Epoch: 6| Step: 6
Training loss: 3.3452571431354468
Validation loss: 2.537696950517027

Epoch: 6| Step: 7
Training loss: 2.7948179725511326
Validation loss: 2.561294039787128

Epoch: 6| Step: 8
Training loss: 3.2549049337775884
Validation loss: 2.586012835672823

Epoch: 6| Step: 9
Training loss: 2.760105638555584
Validation loss: 2.5653050854262522

Epoch: 6| Step: 10
Training loss: 3.2474918957991643
Validation loss: 2.5514691693504195

Epoch: 6| Step: 11
Training loss: 2.5014669882597436
Validation loss: 2.5540847054610745

Epoch: 6| Step: 12
Training loss: 2.628516067638635
Validation loss: 2.5386649356442588

Epoch: 6| Step: 13
Training loss: 3.436605996139953
Validation loss: 2.538908448448414

Epoch: 110| Step: 0
Training loss: 2.4892568547099962
Validation loss: 2.508463879266112

Epoch: 6| Step: 1
Training loss: 2.5674374162127953
Validation loss: 2.499561933878808

Epoch: 6| Step: 2
Training loss: 2.2032037815590666
Validation loss: 2.493874104813666

Epoch: 6| Step: 3
Training loss: 2.7473850822539694
Validation loss: 2.48764224759539

Epoch: 6| Step: 4
Training loss: 3.0697163786952504
Validation loss: 2.4950629666599515

Epoch: 6| Step: 5
Training loss: 3.3317639153087537
Validation loss: 2.50596089001178

Epoch: 6| Step: 6
Training loss: 3.0867795157624496
Validation loss: 2.507181512396242

Epoch: 6| Step: 7
Training loss: 3.115683132842193
Validation loss: 2.5193654662033858

Epoch: 6| Step: 8
Training loss: 2.67301345574631
Validation loss: 2.510512313957563

Epoch: 6| Step: 9
Training loss: 3.0429356858461207
Validation loss: 2.4923562374540174

Epoch: 6| Step: 10
Training loss: 2.8267487607436865
Validation loss: 2.4908310762625434

Epoch: 6| Step: 11
Training loss: 2.854046969908749
Validation loss: 2.501236728129283

Epoch: 6| Step: 12
Training loss: 3.019875490767182
Validation loss: 2.5260952046417597

Epoch: 6| Step: 13
Training loss: 3.1842226121133006
Validation loss: 2.5708192725378844

Epoch: 111| Step: 0
Training loss: 2.9610354122993234
Validation loss: 2.5785777579734606

Epoch: 6| Step: 1
Training loss: 3.397977951373437
Validation loss: 2.560853234404393

Epoch: 6| Step: 2
Training loss: 2.5554437013924467
Validation loss: 2.5628104423280824

Epoch: 6| Step: 3
Training loss: 2.5972983665886806
Validation loss: 2.54477353558854

Epoch: 6| Step: 4
Training loss: 2.6782818101802564
Validation loss: 2.5423847867094733

Epoch: 6| Step: 5
Training loss: 3.168979168492105
Validation loss: 2.542410900089686

Epoch: 6| Step: 6
Training loss: 2.5434398302685546
Validation loss: 2.503119524093459

Epoch: 6| Step: 7
Training loss: 2.7770664597094297
Validation loss: 2.48515362417039

Epoch: 6| Step: 8
Training loss: 2.876361027198961
Validation loss: 2.480301351650107

Epoch: 6| Step: 9
Training loss: 2.885885776620108
Validation loss: 2.4749428307128998

Epoch: 6| Step: 10
Training loss: 2.8536046906552746
Validation loss: 2.4767251743314422

Epoch: 6| Step: 11
Training loss: 2.761603152001882
Validation loss: 2.481109250158479

Epoch: 6| Step: 12
Training loss: 2.9494182594976266
Validation loss: 2.478965743552269

Epoch: 6| Step: 13
Training loss: 2.8058729296493214
Validation loss: 2.4814919390130097

Epoch: 112| Step: 0
Training loss: 2.702268431673443
Validation loss: 2.4743156184611683

Epoch: 6| Step: 1
Training loss: 2.813725013977853
Validation loss: 2.484539351338481

Epoch: 6| Step: 2
Training loss: 3.0410698779882743
Validation loss: 2.500942383829523

Epoch: 6| Step: 3
Training loss: 2.8761673920666544
Validation loss: 2.528766520254526

Epoch: 6| Step: 4
Training loss: 2.356675782930187
Validation loss: 2.5447451092272826

Epoch: 6| Step: 5
Training loss: 2.2280970589061533
Validation loss: 2.6019140634994784

Epoch: 6| Step: 6
Training loss: 2.5887865120869997
Validation loss: 2.665739012178466

Epoch: 6| Step: 7
Training loss: 3.4588652665122366
Validation loss: 2.68923467336236

Epoch: 6| Step: 8
Training loss: 2.845196701785412
Validation loss: 2.614073528428373

Epoch: 6| Step: 9
Training loss: 2.81658503246701
Validation loss: 2.5462555289544873

Epoch: 6| Step: 10
Training loss: 3.455040861956351
Validation loss: 2.4921600394803542

Epoch: 6| Step: 11
Training loss: 3.064309033518857
Validation loss: 2.4782323875281267

Epoch: 6| Step: 12
Training loss: 2.8344769881130767
Validation loss: 2.4876952595720616

Epoch: 6| Step: 13
Training loss: 3.3264849566393724
Validation loss: 2.497559291228559

Epoch: 113| Step: 0
Training loss: 3.083928403050499
Validation loss: 2.511346779426051

Epoch: 6| Step: 1
Training loss: 2.4016717730787085
Validation loss: 2.5014485192818756

Epoch: 6| Step: 2
Training loss: 2.9270666988529133
Validation loss: 2.493356401850481

Epoch: 6| Step: 3
Training loss: 3.158516551585669
Validation loss: 2.481140137840796

Epoch: 6| Step: 4
Training loss: 2.7364279751254768
Validation loss: 2.4771245705033276

Epoch: 6| Step: 5
Training loss: 2.084632036411675
Validation loss: 2.4761234721272296

Epoch: 6| Step: 6
Training loss: 3.3679552375736534
Validation loss: 2.4795011444867665

Epoch: 6| Step: 7
Training loss: 2.8945412989556503
Validation loss: 2.49572563855955

Epoch: 6| Step: 8
Training loss: 2.496705172878023
Validation loss: 2.518453402226691

Epoch: 6| Step: 9
Training loss: 2.7556083883925604
Validation loss: 2.5439848217275656

Epoch: 6| Step: 10
Training loss: 2.8845346987272698
Validation loss: 2.546947654112102

Epoch: 6| Step: 11
Training loss: 3.255980637551362
Validation loss: 2.506503217559222

Epoch: 6| Step: 12
Training loss: 2.720827558510354
Validation loss: 2.487518995870753

Epoch: 6| Step: 13
Training loss: 2.994723766497015
Validation loss: 2.4826616418470278

Epoch: 114| Step: 0
Training loss: 3.2418677482575355
Validation loss: 2.478503446590191

Epoch: 6| Step: 1
Training loss: 2.317401125546583
Validation loss: 2.475055822557267

Epoch: 6| Step: 2
Training loss: 2.1874250126656127
Validation loss: 2.4744908024160974

Epoch: 6| Step: 3
Training loss: 2.7294311298235665
Validation loss: 2.478270762718769

Epoch: 6| Step: 4
Training loss: 2.955036009231856
Validation loss: 2.4807717306615498

Epoch: 6| Step: 5
Training loss: 3.159402009903245
Validation loss: 2.481470786107006

Epoch: 6| Step: 6
Training loss: 2.6442736636864153
Validation loss: 2.485135342400598

Epoch: 6| Step: 7
Training loss: 2.927063440728158
Validation loss: 2.494621970021336

Epoch: 6| Step: 8
Training loss: 2.7706575457423113
Validation loss: 2.499846735737542

Epoch: 6| Step: 9
Training loss: 2.7557558165949723
Validation loss: 2.4948621139600786

Epoch: 6| Step: 10
Training loss: 2.678416314856314
Validation loss: 2.4997881112493885

Epoch: 6| Step: 11
Training loss: 2.871926696776949
Validation loss: 2.4999723022731413

Epoch: 6| Step: 12
Training loss: 3.0424299632328036
Validation loss: 2.5002279751926335

Epoch: 6| Step: 13
Training loss: 3.3742455946218124
Validation loss: 2.4991308157465624

Epoch: 115| Step: 0
Training loss: 2.888584055671513
Validation loss: 2.5104473835315133

Epoch: 6| Step: 1
Training loss: 3.1194347417296866
Validation loss: 2.5404256100196547

Epoch: 6| Step: 2
Training loss: 2.1774523359966134
Validation loss: 2.5588634617776718

Epoch: 6| Step: 3
Training loss: 2.768445489469067
Validation loss: 2.572149032606586

Epoch: 6| Step: 4
Training loss: 3.078180922566642
Validation loss: 2.594504277226817

Epoch: 6| Step: 5
Training loss: 2.6964466307296067
Validation loss: 2.5626678892011934

Epoch: 6| Step: 6
Training loss: 2.4625653408308437
Validation loss: 2.56981021698447

Epoch: 6| Step: 7
Training loss: 3.2441950086689397
Validation loss: 2.5602023040208977

Epoch: 6| Step: 8
Training loss: 2.3426992476985253
Validation loss: 2.526996314346286

Epoch: 6| Step: 9
Training loss: 2.7467288589226415
Validation loss: 2.5203870671360327

Epoch: 6| Step: 10
Training loss: 3.1400358492025764
Validation loss: 2.506800463221749

Epoch: 6| Step: 11
Training loss: 2.994810702498378
Validation loss: 2.482084817516266

Epoch: 6| Step: 12
Training loss: 3.077945762101879
Validation loss: 2.497045621220061

Epoch: 6| Step: 13
Training loss: 2.4959395813231784
Validation loss: 2.4991695368062197

Epoch: 116| Step: 0
Training loss: 2.1337383342797223
Validation loss: 2.4921590622320866

Epoch: 6| Step: 1
Training loss: 2.6420838428740065
Validation loss: 2.4764233062850924

Epoch: 6| Step: 2
Training loss: 2.7022979000157785
Validation loss: 2.4898159333600933

Epoch: 6| Step: 3
Training loss: 2.335219767355296
Validation loss: 2.475554384539897

Epoch: 6| Step: 4
Training loss: 3.11549656640569
Validation loss: 2.484952268673768

Epoch: 6| Step: 5
Training loss: 2.85102149325337
Validation loss: 2.4884235263295764

Epoch: 6| Step: 6
Training loss: 2.2040006371928156
Validation loss: 2.5334729281124266

Epoch: 6| Step: 7
Training loss: 2.726277071378086
Validation loss: 2.5642414153550495

Epoch: 6| Step: 8
Training loss: 2.9734007696307643
Validation loss: 2.5869232312472232

Epoch: 6| Step: 9
Training loss: 2.888363174956421
Validation loss: 2.6213217521612107

Epoch: 6| Step: 10
Training loss: 3.1672847211583
Validation loss: 2.664707724344446

Epoch: 6| Step: 11
Training loss: 2.7461568681346438
Validation loss: 2.6632846380740247

Epoch: 6| Step: 12
Training loss: 3.811671057463534
Validation loss: 2.6497324666674507

Epoch: 6| Step: 13
Training loss: 2.754482084633231
Validation loss: 2.57254298685312

Epoch: 117| Step: 0
Training loss: 2.902665583760882
Validation loss: 2.5258724547124896

Epoch: 6| Step: 1
Training loss: 2.2961167102352364
Validation loss: 2.4996764978684305

Epoch: 6| Step: 2
Training loss: 3.1766844118575994
Validation loss: 2.489691264254792

Epoch: 6| Step: 3
Training loss: 3.179775677332333
Validation loss: 2.491205720088886

Epoch: 6| Step: 4
Training loss: 2.5794459802332375
Validation loss: 2.491796667011292

Epoch: 6| Step: 5
Training loss: 3.002355445602789
Validation loss: 2.4925295790161335

Epoch: 6| Step: 6
Training loss: 2.6478458069915134
Validation loss: 2.493811204276249

Epoch: 6| Step: 7
Training loss: 2.466097795340169
Validation loss: 2.491957160694008

Epoch: 6| Step: 8
Training loss: 3.275166130220266
Validation loss: 2.484366747836695

Epoch: 6| Step: 9
Training loss: 1.9713012271627848
Validation loss: 2.4768216172343815

Epoch: 6| Step: 10
Training loss: 3.238453822490046
Validation loss: 2.489971167922179

Epoch: 6| Step: 11
Training loss: 2.8810528602927907
Validation loss: 2.5118172893416255

Epoch: 6| Step: 12
Training loss: 2.847573194090562
Validation loss: 2.534581977993964

Epoch: 6| Step: 13
Training loss: 2.850688141849276
Validation loss: 2.5540242880441757

Epoch: 118| Step: 0
Training loss: 2.6915329237583725
Validation loss: 2.5467294721499356

Epoch: 6| Step: 1
Training loss: 2.9363857347369238
Validation loss: 2.539957479123118

Epoch: 6| Step: 2
Training loss: 2.772466269202781
Validation loss: 2.5180525738113175

Epoch: 6| Step: 3
Training loss: 2.5068417390430042
Validation loss: 2.5189474650676424

Epoch: 6| Step: 4
Training loss: 2.807068135852357
Validation loss: 2.5144885143158757

Epoch: 6| Step: 5
Training loss: 2.8221522536160824
Validation loss: 2.530655590954988

Epoch: 6| Step: 6
Training loss: 2.626395989653924
Validation loss: 2.5568381126325543

Epoch: 6| Step: 7
Training loss: 3.149380450402033
Validation loss: 2.5459340205125534

Epoch: 6| Step: 8
Training loss: 2.487408782973414
Validation loss: 2.562908581230333

Epoch: 6| Step: 9
Training loss: 3.1411384428520637
Validation loss: 2.5375455013996335

Epoch: 6| Step: 10
Training loss: 2.768396917352061
Validation loss: 2.531416341262803

Epoch: 6| Step: 11
Training loss: 2.8288421564603055
Validation loss: 2.525729487498079

Epoch: 6| Step: 12
Training loss: 3.0028196435629595
Validation loss: 2.5078602376330075

Epoch: 6| Step: 13
Training loss: 2.512508570718144
Validation loss: 2.496869565830593

Epoch: 119| Step: 0
Training loss: 2.87127925766556
Validation loss: 2.492510417948921

Epoch: 6| Step: 1
Training loss: 2.862780934503211
Validation loss: 2.4835113295462374

Epoch: 6| Step: 2
Training loss: 2.490125227387428
Validation loss: 2.4881023849403054

Epoch: 6| Step: 3
Training loss: 2.3148305335747414
Validation loss: 2.486869043584624

Epoch: 6| Step: 4
Training loss: 2.9973639987257026
Validation loss: 2.4876852118997923

Epoch: 6| Step: 5
Training loss: 2.951425699241316
Validation loss: 2.479871550571891

Epoch: 6| Step: 6
Training loss: 2.9115430970838743
Validation loss: 2.489595103655438

Epoch: 6| Step: 7
Training loss: 2.634937730375529
Validation loss: 2.504038944426678

Epoch: 6| Step: 8
Training loss: 2.8117321237732007
Validation loss: 2.522046698115802

Epoch: 6| Step: 9
Training loss: 2.499233319024529
Validation loss: 2.547848413101398

Epoch: 6| Step: 10
Training loss: 3.3095188761586467
Validation loss: 2.615267506018082

Epoch: 6| Step: 11
Training loss: 2.9594924339510937
Validation loss: 2.6293873206811447

Epoch: 6| Step: 12
Training loss: 2.9269244783313884
Validation loss: 2.6436597338334487

Epoch: 6| Step: 13
Training loss: 2.7736461292293955
Validation loss: 2.606979641219211

Epoch: 120| Step: 0
Training loss: 2.8060398082560374
Validation loss: 2.584622221030907

Epoch: 6| Step: 1
Training loss: 3.1026209795508417
Validation loss: 2.581502773624208

Epoch: 6| Step: 2
Training loss: 2.3980463063061817
Validation loss: 2.5290971496027126

Epoch: 6| Step: 3
Training loss: 2.878553930538399
Validation loss: 2.5019807567388086

Epoch: 6| Step: 4
Training loss: 3.774781045184861
Validation loss: 2.4983895159746026

Epoch: 6| Step: 5
Training loss: 2.854338833333575
Validation loss: 2.496848241336733

Epoch: 6| Step: 6
Training loss: 2.7699254969964686
Validation loss: 2.491634914936545

Epoch: 6| Step: 7
Training loss: 2.5195218817958103
Validation loss: 2.495077510672634

Epoch: 6| Step: 8
Training loss: 2.6214681207354453
Validation loss: 2.4891599090069287

Epoch: 6| Step: 9
Training loss: 2.8559549859610773
Validation loss: 2.50871577029464

Epoch: 6| Step: 10
Training loss: 2.2540211243337698
Validation loss: 2.52301964004565

Epoch: 6| Step: 11
Training loss: 2.4603904479393175
Validation loss: 2.527962666112675

Epoch: 6| Step: 12
Training loss: 2.3670681460667287
Validation loss: 2.535583349892115

Epoch: 6| Step: 13
Training loss: 3.5453075020537574
Validation loss: 2.5475923972407077

Epoch: 121| Step: 0
Training loss: 2.4122554595819063
Validation loss: 2.531124844654262

Epoch: 6| Step: 1
Training loss: 2.5408224256695706
Validation loss: 2.541776971089442

Epoch: 6| Step: 2
Training loss: 2.8418946973605883
Validation loss: 2.5294129341571066

Epoch: 6| Step: 3
Training loss: 2.7550442988716384
Validation loss: 2.5305045876256793

Epoch: 6| Step: 4
Training loss: 2.957405338787807
Validation loss: 2.5265928383666623

Epoch: 6| Step: 5
Training loss: 2.8866031195126354
Validation loss: 2.5192793637309734

Epoch: 6| Step: 6
Training loss: 2.110230336023876
Validation loss: 2.51146682228319

Epoch: 6| Step: 7
Training loss: 2.8591665389986454
Validation loss: 2.5119053371946802

Epoch: 6| Step: 8
Training loss: 2.767245491406697
Validation loss: 2.4972183801111028

Epoch: 6| Step: 9
Training loss: 2.7631766478779327
Validation loss: 2.4970023631517066

Epoch: 6| Step: 10
Training loss: 2.6973012470210658
Validation loss: 2.498376585837394

Epoch: 6| Step: 11
Training loss: 3.456723508769057
Validation loss: 2.5006653853904446

Epoch: 6| Step: 12
Training loss: 2.9209485548713587
Validation loss: 2.5087759570629915

Epoch: 6| Step: 13
Training loss: 2.8235098765669813
Validation loss: 2.518008332710091

Epoch: 122| Step: 0
Training loss: 2.749026212809434
Validation loss: 2.504335917507923

Epoch: 6| Step: 1
Training loss: 2.835492059703587
Validation loss: 2.494561862082974

Epoch: 6| Step: 2
Training loss: 2.265321698111564
Validation loss: 2.496764245557574

Epoch: 6| Step: 3
Training loss: 2.9324869437549026
Validation loss: 2.4902590216024816

Epoch: 6| Step: 4
Training loss: 2.462485174918691
Validation loss: 2.4986172051266617

Epoch: 6| Step: 5
Training loss: 2.785441979174606
Validation loss: 2.487193453954072

Epoch: 6| Step: 6
Training loss: 2.2893559915439248
Validation loss: 2.491418760635217

Epoch: 6| Step: 7
Training loss: 2.827433970630679
Validation loss: 2.4966140516251705

Epoch: 6| Step: 8
Training loss: 3.0115792604593374
Validation loss: 2.5114307749133875

Epoch: 6| Step: 9
Training loss: 2.84509932815583
Validation loss: 2.5369916923950515

Epoch: 6| Step: 10
Training loss: 2.697441874276459
Validation loss: 2.5476678393940655

Epoch: 6| Step: 11
Training loss: 3.0219752992318583
Validation loss: 2.564825399985974

Epoch: 6| Step: 12
Training loss: 3.099877964201871
Validation loss: 2.5646833826844024

Epoch: 6| Step: 13
Training loss: 2.8828875937670375
Validation loss: 2.556804455102638

Epoch: 123| Step: 0
Training loss: 2.619746810094255
Validation loss: 2.560572487781149

Epoch: 6| Step: 1
Training loss: 2.7792332227097063
Validation loss: 2.512593303317908

Epoch: 6| Step: 2
Training loss: 2.526404936058339
Validation loss: 2.487630743535024

Epoch: 6| Step: 3
Training loss: 3.174658695409071
Validation loss: 2.488781981324083

Epoch: 6| Step: 4
Training loss: 2.9997087973088896
Validation loss: 2.489668771337774

Epoch: 6| Step: 5
Training loss: 3.1717380437739107
Validation loss: 2.49608973624224

Epoch: 6| Step: 6
Training loss: 2.969835103142253
Validation loss: 2.488230520274667

Epoch: 6| Step: 7
Training loss: 2.4582625125662387
Validation loss: 2.4925627421920606

Epoch: 6| Step: 8
Training loss: 3.372426782807228
Validation loss: 2.497887925153684

Epoch: 6| Step: 9
Training loss: 2.028382140141574
Validation loss: 2.5122907551112506

Epoch: 6| Step: 10
Training loss: 2.694720305471282
Validation loss: 2.5352721228342223

Epoch: 6| Step: 11
Training loss: 3.014771019383795
Validation loss: 2.5469569385503132

Epoch: 6| Step: 12
Training loss: 2.403902965167767
Validation loss: 2.528239353820927

Epoch: 6| Step: 13
Training loss: 2.678471147385749
Validation loss: 2.5293196723022406

Epoch: 124| Step: 0
Training loss: 2.2976632355159343
Validation loss: 2.505910162176515

Epoch: 6| Step: 1
Training loss: 2.4942576262200804
Validation loss: 2.5041903909095833

Epoch: 6| Step: 2
Training loss: 2.5372323820558846
Validation loss: 2.494585245043679

Epoch: 6| Step: 3
Training loss: 2.8763842360146112
Validation loss: 2.489467022080816

Epoch: 6| Step: 4
Training loss: 2.8485107814215835
Validation loss: 2.4940394532488313

Epoch: 6| Step: 5
Training loss: 2.844956529818193
Validation loss: 2.5037521502507016

Epoch: 6| Step: 6
Training loss: 3.029856568016695
Validation loss: 2.5222194186112183

Epoch: 6| Step: 7
Training loss: 2.433303840232029
Validation loss: 2.5241489360590967

Epoch: 6| Step: 8
Training loss: 2.0619366194255524
Validation loss: 2.5118858416935037

Epoch: 6| Step: 9
Training loss: 2.601392402472304
Validation loss: 2.4903862656772846

Epoch: 6| Step: 10
Training loss: 3.034393725352157
Validation loss: 2.472145408171981

Epoch: 6| Step: 11
Training loss: 2.904474023420104
Validation loss: 2.4754048408839906

Epoch: 6| Step: 12
Training loss: 3.757992682627994
Validation loss: 2.481909871062904

Epoch: 6| Step: 13
Training loss: 2.7570934709125536
Validation loss: 2.479381025324024

Epoch: 125| Step: 0
Training loss: 2.933472815000619
Validation loss: 2.4788092023487387

Epoch: 6| Step: 1
Training loss: 3.0416186254879225
Validation loss: 2.471662467748466

Epoch: 6| Step: 2
Training loss: 2.557169324094007
Validation loss: 2.4666649988723655

Epoch: 6| Step: 3
Training loss: 3.080562652619464
Validation loss: 2.4661099913518685

Epoch: 6| Step: 4
Training loss: 2.864503191202563
Validation loss: 2.459633133367014

Epoch: 6| Step: 5
Training loss: 2.4510700341455722
Validation loss: 2.4710127156358572

Epoch: 6| Step: 6
Training loss: 2.867284289812993
Validation loss: 2.4744666929016046

Epoch: 6| Step: 7
Training loss: 2.5410496843593138
Validation loss: 2.4735572235031156

Epoch: 6| Step: 8
Training loss: 2.916327774704716
Validation loss: 2.486019427940819

Epoch: 6| Step: 9
Training loss: 2.66764416263076
Validation loss: 2.4929458874048587

Epoch: 6| Step: 10
Training loss: 3.33203225174919
Validation loss: 2.5183762155573226

Epoch: 6| Step: 11
Training loss: 2.8475006856406764
Validation loss: 2.494539592931131

Epoch: 6| Step: 12
Training loss: 2.1125796240974815
Validation loss: 2.474318709148218

Epoch: 6| Step: 13
Training loss: 2.1024061587117187
Validation loss: 2.462642896399869

Epoch: 126| Step: 0
Training loss: 2.4708832807033057
Validation loss: 2.465505099606122

Epoch: 6| Step: 1
Training loss: 2.8198507253218468
Validation loss: 2.4652638263722624

Epoch: 6| Step: 2
Training loss: 2.849418942296099
Validation loss: 2.4611926083134574

Epoch: 6| Step: 3
Training loss: 2.677125467842112
Validation loss: 2.4543706394830966

Epoch: 6| Step: 4
Training loss: 2.7042572648948044
Validation loss: 2.450059626583874

Epoch: 6| Step: 5
Training loss: 2.6018744387638644
Validation loss: 2.4671952759881015

Epoch: 6| Step: 6
Training loss: 2.8636805735996997
Validation loss: 2.460901251579824

Epoch: 6| Step: 7
Training loss: 2.637060705545833
Validation loss: 2.4692314657707874

Epoch: 6| Step: 8
Training loss: 2.674313508833673
Validation loss: 2.4702601042623

Epoch: 6| Step: 9
Training loss: 2.7428625422521082
Validation loss: 2.4844959869612877

Epoch: 6| Step: 10
Training loss: 1.9840742469015664
Validation loss: 2.490622336375312

Epoch: 6| Step: 11
Training loss: 2.9858679108068618
Validation loss: 2.506109510539985

Epoch: 6| Step: 12
Training loss: 3.043928707445886
Validation loss: 2.509475816277275

Epoch: 6| Step: 13
Training loss: 3.603695053967828
Validation loss: 2.5045600137330832

Epoch: 127| Step: 0
Training loss: 3.435874415881492
Validation loss: 2.54159388311042

Epoch: 6| Step: 1
Training loss: 2.8121721712422283
Validation loss: 2.563344306624144

Epoch: 6| Step: 2
Training loss: 2.486433795562302
Validation loss: 2.5693584164629035

Epoch: 6| Step: 3
Training loss: 2.871833550254724
Validation loss: 2.5540102192327394

Epoch: 6| Step: 4
Training loss: 2.4898515713739133
Validation loss: 2.4997774353221436

Epoch: 6| Step: 5
Training loss: 2.84508910456939
Validation loss: 2.4692128096693877

Epoch: 6| Step: 6
Training loss: 2.0663078299089697
Validation loss: 2.464314604318772

Epoch: 6| Step: 7
Training loss: 2.6635370267654324
Validation loss: 2.4614283793369456

Epoch: 6| Step: 8
Training loss: 2.210787602927144
Validation loss: 2.47401802720664

Epoch: 6| Step: 9
Training loss: 3.186040806089339
Validation loss: 2.4705466994641414

Epoch: 6| Step: 10
Training loss: 2.6353483128384507
Validation loss: 2.475945744736769

Epoch: 6| Step: 11
Training loss: 2.8154211345202635
Validation loss: 2.4685221772418346

Epoch: 6| Step: 12
Training loss: 3.355028187936087
Validation loss: 2.4601286163459477

Epoch: 6| Step: 13
Training loss: 2.8165099485991276
Validation loss: 2.4592691683859242

Epoch: 128| Step: 0
Training loss: 3.005719454894006
Validation loss: 2.4677834748255787

Epoch: 6| Step: 1
Training loss: 3.030082556478002
Validation loss: 2.4849693602247336

Epoch: 6| Step: 2
Training loss: 2.4471103287094484
Validation loss: 2.5180213442804837

Epoch: 6| Step: 3
Training loss: 2.7266425965357404
Validation loss: 2.544722865179175

Epoch: 6| Step: 4
Training loss: 2.4114887628358734
Validation loss: 2.5837487916445343

Epoch: 6| Step: 5
Training loss: 2.8977870982585134
Validation loss: 2.6001683553769976

Epoch: 6| Step: 6
Training loss: 3.2175696718012974
Validation loss: 2.6223072669590755

Epoch: 6| Step: 7
Training loss: 2.776062059357385
Validation loss: 2.5977183255996037

Epoch: 6| Step: 8
Training loss: 2.5378679018205546
Validation loss: 2.5599442789752165

Epoch: 6| Step: 9
Training loss: 2.308918628327722
Validation loss: 2.5241044544546343

Epoch: 6| Step: 10
Training loss: 2.7692036724191307
Validation loss: 2.5027412777441818

Epoch: 6| Step: 11
Training loss: 2.902262259118415
Validation loss: 2.466628451108134

Epoch: 6| Step: 12
Training loss: 2.990940242403778
Validation loss: 2.458943635558

Epoch: 6| Step: 13
Training loss: 2.2948809421216567
Validation loss: 2.4462860946435865

Epoch: 129| Step: 0
Training loss: 3.326036397848348
Validation loss: 2.444305079257589

Epoch: 6| Step: 1
Training loss: 2.153923991520773
Validation loss: 2.4559218206563376

Epoch: 6| Step: 2
Training loss: 2.98569878582637
Validation loss: 2.4564205982253915

Epoch: 6| Step: 3
Training loss: 3.167232630163016
Validation loss: 2.44851481073123

Epoch: 6| Step: 4
Training loss: 2.7978777233451892
Validation loss: 2.4467045981157147

Epoch: 6| Step: 5
Training loss: 2.4932495532860197
Validation loss: 2.4488703775709677

Epoch: 6| Step: 6
Training loss: 2.664982522187884
Validation loss: 2.454432767825174

Epoch: 6| Step: 7
Training loss: 3.183105730904365
Validation loss: 2.447810243812339

Epoch: 6| Step: 8
Training loss: 2.910037126599253
Validation loss: 2.4498669823236847

Epoch: 6| Step: 9
Training loss: 3.229559958513662
Validation loss: 2.5006843993946286

Epoch: 6| Step: 10
Training loss: 2.637881055306433
Validation loss: 2.552065048169011

Epoch: 6| Step: 11
Training loss: 2.2359218978070907
Validation loss: 2.564579875695772

Epoch: 6| Step: 12
Training loss: 2.77973227933911
Validation loss: 2.567403682950201

Epoch: 6| Step: 13
Training loss: 1.7816284848372286
Validation loss: 2.5386268811241033

Epoch: 130| Step: 0
Training loss: 3.033806106557817
Validation loss: 2.5398024532924466

Epoch: 6| Step: 1
Training loss: 2.9297395828703787
Validation loss: 2.526090321116135

Epoch: 6| Step: 2
Training loss: 2.779891721826033
Validation loss: 2.520065805705931

Epoch: 6| Step: 3
Training loss: 2.42957209960071
Validation loss: 2.49920946358426

Epoch: 6| Step: 4
Training loss: 2.8928558813829044
Validation loss: 2.4729499278966935

Epoch: 6| Step: 5
Training loss: 2.7614000020485037
Validation loss: 2.46739741456682

Epoch: 6| Step: 6
Training loss: 2.659688900129335
Validation loss: 2.448097043972509

Epoch: 6| Step: 7
Training loss: 2.966652540823349
Validation loss: 2.464349251457982

Epoch: 6| Step: 8
Training loss: 2.7105015121030713
Validation loss: 2.4695907735347014

Epoch: 6| Step: 9
Training loss: 1.8726361951203716
Validation loss: 2.46400004259945

Epoch: 6| Step: 10
Training loss: 3.1050538367673486
Validation loss: 2.4668317574787353

Epoch: 6| Step: 11
Training loss: 2.8028294776438885
Validation loss: 2.4681289076415895

Epoch: 6| Step: 12
Training loss: 2.1734320458810634
Validation loss: 2.4538579592625824

Epoch: 6| Step: 13
Training loss: 3.2949470559759484
Validation loss: 2.458278414149483

Epoch: 131| Step: 0
Training loss: 2.756769604481151
Validation loss: 2.4554500666340804

Epoch: 6| Step: 1
Training loss: 2.656259514286729
Validation loss: 2.4648322539422787

Epoch: 6| Step: 2
Training loss: 2.9508836101768816
Validation loss: 2.465511631642556

Epoch: 6| Step: 3
Training loss: 2.597424122470369
Validation loss: 2.4811593438368504

Epoch: 6| Step: 4
Training loss: 2.8562578397346936
Validation loss: 2.4773814170250144

Epoch: 6| Step: 5
Training loss: 2.526177209317905
Validation loss: 2.490061797166597

Epoch: 6| Step: 6
Training loss: 3.1803169845844805
Validation loss: 2.5019063982125203

Epoch: 6| Step: 7
Training loss: 3.0149143152413256
Validation loss: 2.5260653857601922

Epoch: 6| Step: 8
Training loss: 3.0698400235819685
Validation loss: 2.542685472141531

Epoch: 6| Step: 9
Training loss: 1.7008591724746245
Validation loss: 2.532572045666572

Epoch: 6| Step: 10
Training loss: 2.6484133738991447
Validation loss: 2.524056690397701

Epoch: 6| Step: 11
Training loss: 2.643573536856746
Validation loss: 2.527830854310388

Epoch: 6| Step: 12
Training loss: 3.1021315967775425
Validation loss: 2.514720617879796

Epoch: 6| Step: 13
Training loss: 2.161995130930454
Validation loss: 2.5133825075124037

Epoch: 132| Step: 0
Training loss: 2.8501591822022156
Validation loss: 2.5133931327904793

Epoch: 6| Step: 1
Training loss: 3.191078720188128
Validation loss: 2.512607758101484

Epoch: 6| Step: 2
Training loss: 2.219161734189339
Validation loss: 2.4888946085812633

Epoch: 6| Step: 3
Training loss: 2.6996792567441106
Validation loss: 2.4931862750447507

Epoch: 6| Step: 4
Training loss: 2.3994772580200405
Validation loss: 2.5172307428349106

Epoch: 6| Step: 5
Training loss: 2.836399513631275
Validation loss: 2.53727683558964

Epoch: 6| Step: 6
Training loss: 2.680758693115688
Validation loss: 2.57124012603117

Epoch: 6| Step: 7
Training loss: 2.7848465200214685
Validation loss: 2.614425370712009

Epoch: 6| Step: 8
Training loss: 3.2059998055860777
Validation loss: 2.623106167355819

Epoch: 6| Step: 9
Training loss: 2.9132019899674972
Validation loss: 2.5839902374717227

Epoch: 6| Step: 10
Training loss: 2.3237293914324306
Validation loss: 2.514190102564846

Epoch: 6| Step: 11
Training loss: 2.723360383807169
Validation loss: 2.479699281757472

Epoch: 6| Step: 12
Training loss: 2.7534700521679976
Validation loss: 2.462482406689119

Epoch: 6| Step: 13
Training loss: 2.9173146935773495
Validation loss: 2.4630216738143966

Epoch: 133| Step: 0
Training loss: 2.758531168808783
Validation loss: 2.458937354017287

Epoch: 6| Step: 1
Training loss: 2.9090819968282124
Validation loss: 2.4573270435556

Epoch: 6| Step: 2
Training loss: 2.3835141008911043
Validation loss: 2.4583544479083494

Epoch: 6| Step: 3
Training loss: 2.6798891041714277
Validation loss: 2.455129788264091

Epoch: 6| Step: 4
Training loss: 1.603682886802163
Validation loss: 2.44870082851313

Epoch: 6| Step: 5
Training loss: 2.565145104302665
Validation loss: 2.451867282719957

Epoch: 6| Step: 6
Training loss: 2.8544497569973393
Validation loss: 2.466743412863734

Epoch: 6| Step: 7
Training loss: 3.07851535239023
Validation loss: 2.476241059613753

Epoch: 6| Step: 8
Training loss: 2.9261138686201784
Validation loss: 2.496877926575996

Epoch: 6| Step: 9
Training loss: 2.691518750766931
Validation loss: 2.502354503740376

Epoch: 6| Step: 10
Training loss: 3.3742443227715238
Validation loss: 2.5329340846289177

Epoch: 6| Step: 11
Training loss: 2.679253634815646
Validation loss: 2.556474136999146

Epoch: 6| Step: 12
Training loss: 2.62325001467566
Validation loss: 2.565335084773579

Epoch: 6| Step: 13
Training loss: 3.0122543234783423
Validation loss: 2.5752726995380772

Epoch: 134| Step: 0
Training loss: 2.341880154182783
Validation loss: 2.6027397732349815

Epoch: 6| Step: 1
Training loss: 2.7212285111664825
Validation loss: 2.6123983125620125

Epoch: 6| Step: 2
Training loss: 2.686508350614217
Validation loss: 2.6042012953558067

Epoch: 6| Step: 3
Training loss: 2.759867737130284
Validation loss: 2.59072888122251

Epoch: 6| Step: 4
Training loss: 3.067686399285356
Validation loss: 2.578758275825693

Epoch: 6| Step: 5
Training loss: 3.1116012194765337
Validation loss: 2.5598431010964577

Epoch: 6| Step: 6
Training loss: 2.4922198350297515
Validation loss: 2.5303784025289624

Epoch: 6| Step: 7
Training loss: 2.226763157419469
Validation loss: 2.483210735539122

Epoch: 6| Step: 8
Training loss: 2.6004844470960835
Validation loss: 2.4781662999543355

Epoch: 6| Step: 9
Training loss: 3.1106052744345183
Validation loss: 2.4708593621742194

Epoch: 6| Step: 10
Training loss: 2.7244640243207683
Validation loss: 2.4672879196105444

Epoch: 6| Step: 11
Training loss: 2.2405591627847
Validation loss: 2.4601908118572604

Epoch: 6| Step: 12
Training loss: 2.8689165852368164
Validation loss: 2.468354034133733

Epoch: 6| Step: 13
Training loss: 3.506829818682005
Validation loss: 2.4620005743758244

Epoch: 135| Step: 0
Training loss: 2.7742577427858035
Validation loss: 2.460049076536209

Epoch: 6| Step: 1
Training loss: 2.622841628872022
Validation loss: 2.4628138215040924

Epoch: 6| Step: 2
Training loss: 2.9096889043785543
Validation loss: 2.4707187317301744

Epoch: 6| Step: 3
Training loss: 3.0620963940039307
Validation loss: 2.485764168559351

Epoch: 6| Step: 4
Training loss: 2.737443520995392
Validation loss: 2.501274905658973

Epoch: 6| Step: 5
Training loss: 2.552946751697809
Validation loss: 2.540619516605784

Epoch: 6| Step: 6
Training loss: 3.1229436593716153
Validation loss: 2.5394770377410936

Epoch: 6| Step: 7
Training loss: 2.5228825481532278
Validation loss: 2.5115009587833104

Epoch: 6| Step: 8
Training loss: 2.8303955405588854
Validation loss: 2.503925708316766

Epoch: 6| Step: 9
Training loss: 3.006438340217586
Validation loss: 2.4982855342692063

Epoch: 6| Step: 10
Training loss: 2.552875214290979
Validation loss: 2.4921527805739423

Epoch: 6| Step: 11
Training loss: 1.9240246667529826
Validation loss: 2.487463288147847

Epoch: 6| Step: 12
Training loss: 2.7259635376706193
Validation loss: 2.4868489652333508

Epoch: 6| Step: 13
Training loss: 2.6334515710031288
Validation loss: 2.4821762289115665

Epoch: 136| Step: 0
Training loss: 2.8910446274808588
Validation loss: 2.4696696821667348

Epoch: 6| Step: 1
Training loss: 2.4774156899835287
Validation loss: 2.4624257619280145

Epoch: 6| Step: 2
Training loss: 2.5057969594720975
Validation loss: 2.4580364200941

Epoch: 6| Step: 3
Training loss: 2.000823804945728
Validation loss: 2.4565239726039168

Epoch: 6| Step: 4
Training loss: 2.265958353708688
Validation loss: 2.4623769440903978

Epoch: 6| Step: 5
Training loss: 2.7799944668996073
Validation loss: 2.468782741692447

Epoch: 6| Step: 6
Training loss: 2.8304066595668735
Validation loss: 2.4822429646954896

Epoch: 6| Step: 7
Training loss: 2.4301070559431586
Validation loss: 2.513315978398999

Epoch: 6| Step: 8
Training loss: 3.1899321010143824
Validation loss: 2.534343172025266

Epoch: 6| Step: 9
Training loss: 3.1048755391065654
Validation loss: 2.5376564402386013

Epoch: 6| Step: 10
Training loss: 2.9428522575538922
Validation loss: 2.550861726411696

Epoch: 6| Step: 11
Training loss: 3.052779516470864
Validation loss: 2.5272768773219667

Epoch: 6| Step: 12
Training loss: 2.606111415773658
Validation loss: 2.52399995778897

Epoch: 6| Step: 13
Training loss: 2.6622961011010298
Validation loss: 2.499921276534801

Epoch: 137| Step: 0
Training loss: 3.030930492433533
Validation loss: 2.4899844490374825

Epoch: 6| Step: 1
Training loss: 2.778492535715475
Validation loss: 2.4782031823860846

Epoch: 6| Step: 2
Training loss: 2.875513777228728
Validation loss: 2.4745207739935

Epoch: 6| Step: 3
Training loss: 2.8448866364699374
Validation loss: 2.485094137261752

Epoch: 6| Step: 4
Training loss: 2.634406176254766
Validation loss: 2.4759369353784155

Epoch: 6| Step: 5
Training loss: 2.4890546569892225
Validation loss: 2.4831048823897937

Epoch: 6| Step: 6
Training loss: 2.950446634911227
Validation loss: 2.493324372541588

Epoch: 6| Step: 7
Training loss: 2.629394304564173
Validation loss: 2.4958754571183985

Epoch: 6| Step: 8
Training loss: 2.5837618154579487
Validation loss: 2.4893461057670327

Epoch: 6| Step: 9
Training loss: 2.229572817680737
Validation loss: 2.4815159637432322

Epoch: 6| Step: 10
Training loss: 2.5822667001551136
Validation loss: 2.4851110596862065

Epoch: 6| Step: 11
Training loss: 3.0023536985710466
Validation loss: 2.486574111489873

Epoch: 6| Step: 12
Training loss: 2.33050282549651
Validation loss: 2.474868739196023

Epoch: 6| Step: 13
Training loss: 2.9085531645347817
Validation loss: 2.48389494618941

Epoch: 138| Step: 0
Training loss: 2.8307518324987133
Validation loss: 2.486502837918627

Epoch: 6| Step: 1
Training loss: 2.8436877904103
Validation loss: 2.470081162052738

Epoch: 6| Step: 2
Training loss: 2.812100784790976
Validation loss: 2.468536899435385

Epoch: 6| Step: 3
Training loss: 2.7940816729329034
Validation loss: 2.4691399582628866

Epoch: 6| Step: 4
Training loss: 3.22128492366761
Validation loss: 2.4695558075315236

Epoch: 6| Step: 5
Training loss: 3.0660165332564904
Validation loss: 2.4820710133335364

Epoch: 6| Step: 6
Training loss: 2.424882461216236
Validation loss: 2.4802323237495774

Epoch: 6| Step: 7
Training loss: 2.4002064695556053
Validation loss: 2.4724870826167016

Epoch: 6| Step: 8
Training loss: 2.544014289491936
Validation loss: 2.4719278846220285

Epoch: 6| Step: 9
Training loss: 2.2353976383685152
Validation loss: 2.4686572627443963

Epoch: 6| Step: 10
Training loss: 2.800106632382053
Validation loss: 2.4563176578472885

Epoch: 6| Step: 11
Training loss: 2.9108076557024676
Validation loss: 2.4608160173518447

Epoch: 6| Step: 12
Training loss: 2.548214612764694
Validation loss: 2.4573747087783935

Epoch: 6| Step: 13
Training loss: 1.9589680664357296
Validation loss: 2.4684501768070612

Epoch: 139| Step: 0
Training loss: 2.7874318546467314
Validation loss: 2.4867160030154185

Epoch: 6| Step: 1
Training loss: 2.605608751919331
Validation loss: 2.480161861277458

Epoch: 6| Step: 2
Training loss: 3.384629252878867
Validation loss: 2.483737124049304

Epoch: 6| Step: 3
Training loss: 2.7887713282995095
Validation loss: 2.4831165777688065

Epoch: 6| Step: 4
Training loss: 2.3278287148599053
Validation loss: 2.4917975723834593

Epoch: 6| Step: 5
Training loss: 2.5578806108973287
Validation loss: 2.497153126604889

Epoch: 6| Step: 6
Training loss: 1.7724939600703067
Validation loss: 2.500554156669222

Epoch: 6| Step: 7
Training loss: 2.5719563059973853
Validation loss: 2.4987226309485995

Epoch: 6| Step: 8
Training loss: 2.489299476008482
Validation loss: 2.5045079329719826

Epoch: 6| Step: 9
Training loss: 2.8643998150850343
Validation loss: 2.5205141867375516

Epoch: 6| Step: 10
Training loss: 2.5562140427277935
Validation loss: 2.5017280000544804

Epoch: 6| Step: 11
Training loss: 3.0003692081870543
Validation loss: 2.514597201854332

Epoch: 6| Step: 12
Training loss: 3.0532615045430536
Validation loss: 2.528120261510513

Epoch: 6| Step: 13
Training loss: 2.7226061604296663
Validation loss: 2.5106041724672994

Epoch: 140| Step: 0
Training loss: 2.8205494450923374
Validation loss: 2.511475452914555

Epoch: 6| Step: 1
Training loss: 2.7553386020451582
Validation loss: 2.5050480831225177

Epoch: 6| Step: 2
Training loss: 2.5104760971526896
Validation loss: 2.49495647272356

Epoch: 6| Step: 3
Training loss: 2.5976316522566596
Validation loss: 2.501084562101728

Epoch: 6| Step: 4
Training loss: 2.449834572792929
Validation loss: 2.5052762282769616

Epoch: 6| Step: 5
Training loss: 2.6033775252899014
Validation loss: 2.5068677982672924

Epoch: 6| Step: 6
Training loss: 2.919601616791072
Validation loss: 2.4957514964464926

Epoch: 6| Step: 7
Training loss: 2.2859484220544997
Validation loss: 2.496378307743942

Epoch: 6| Step: 8
Training loss: 2.7514194813114
Validation loss: 2.4878803829904115

Epoch: 6| Step: 9
Training loss: 2.722541182725834
Validation loss: 2.479929599718719

Epoch: 6| Step: 10
Training loss: 2.9329184657826257
Validation loss: 2.492696495050839

Epoch: 6| Step: 11
Training loss: 2.698177683415104
Validation loss: 2.4918769424079343

Epoch: 6| Step: 12
Training loss: 2.8261187270939887
Validation loss: 2.482655960377319

Epoch: 6| Step: 13
Training loss: 3.0002627257700314
Validation loss: 2.479013375347886

Epoch: 141| Step: 0
Training loss: 2.23718810225211
Validation loss: 2.4841501602834395

Epoch: 6| Step: 1
Training loss: 2.9118910975685752
Validation loss: 2.486935297798089

Epoch: 6| Step: 2
Training loss: 2.4589995004250857
Validation loss: 2.4880161052374894

Epoch: 6| Step: 3
Training loss: 2.679576459980721
Validation loss: 2.4880873282472264

Epoch: 6| Step: 4
Training loss: 2.6951083340925495
Validation loss: 2.4793037720640867

Epoch: 6| Step: 5
Training loss: 2.4654313972380786
Validation loss: 2.481039545712859

Epoch: 6| Step: 6
Training loss: 2.56155899261685
Validation loss: 2.4797679533536336

Epoch: 6| Step: 7
Training loss: 2.5192641952098063
Validation loss: 2.4737973883736597

Epoch: 6| Step: 8
Training loss: 3.1996694394084484
Validation loss: 2.4727057446006424

Epoch: 6| Step: 9
Training loss: 2.689447717377234
Validation loss: 2.4758483461567993

Epoch: 6| Step: 10
Training loss: 3.130218421213119
Validation loss: 2.4669903441662324

Epoch: 6| Step: 11
Training loss: 2.568491374637913
Validation loss: 2.461304525288881

Epoch: 6| Step: 12
Training loss: 2.829646086113288
Validation loss: 2.461804445497705

Epoch: 6| Step: 13
Training loss: 2.3917184959227566
Validation loss: 2.4571609252868667

Epoch: 142| Step: 0
Training loss: 2.488449881452307
Validation loss: 2.463158452519939

Epoch: 6| Step: 1
Training loss: 2.8583368803693676
Validation loss: 2.475230249836236

Epoch: 6| Step: 2
Training loss: 3.004201807529949
Validation loss: 2.515206037825298

Epoch: 6| Step: 3
Training loss: 2.5541253360891263
Validation loss: 2.5451014418422395

Epoch: 6| Step: 4
Training loss: 2.8286806688228125
Validation loss: 2.6147037774640682

Epoch: 6| Step: 5
Training loss: 2.613572815736952
Validation loss: 2.6173569726170705

Epoch: 6| Step: 6
Training loss: 2.837110208634395
Validation loss: 2.5823933726895745

Epoch: 6| Step: 7
Training loss: 2.770067343323597
Validation loss: 2.5039133166474423

Epoch: 6| Step: 8
Training loss: 2.8523018492497245
Validation loss: 2.461376904000419

Epoch: 6| Step: 9
Training loss: 2.713343714976152
Validation loss: 2.4578322777159247

Epoch: 6| Step: 10
Training loss: 2.542374642581653
Validation loss: 2.460591206599262

Epoch: 6| Step: 11
Training loss: 2.5502119612020695
Validation loss: 2.4472538819018332

Epoch: 6| Step: 12
Training loss: 2.9541685490855545
Validation loss: 2.4546563598122235

Epoch: 6| Step: 13
Training loss: 2.144408175579554
Validation loss: 2.462749782062278

Epoch: 143| Step: 0
Training loss: 2.8512384099862738
Validation loss: 2.471140540956644

Epoch: 6| Step: 1
Training loss: 2.1677061179603596
Validation loss: 2.4848471541338975

Epoch: 6| Step: 2
Training loss: 2.6445450437290283
Validation loss: 2.566649754746453

Epoch: 6| Step: 3
Training loss: 2.5998777140690277
Validation loss: 2.639259697538196

Epoch: 6| Step: 4
Training loss: 2.968035160134056
Validation loss: 2.731941370711188

Epoch: 6| Step: 5
Training loss: 2.400260406512903
Validation loss: 2.7534601838653567

Epoch: 6| Step: 6
Training loss: 2.519036580103718
Validation loss: 2.699746076127966

Epoch: 6| Step: 7
Training loss: 3.065675918202904
Validation loss: 2.631724290973678

Epoch: 6| Step: 8
Training loss: 2.772990273965864
Validation loss: 2.5349948132070255

Epoch: 6| Step: 9
Training loss: 2.5534696796888605
Validation loss: 2.475970915638512

Epoch: 6| Step: 10
Training loss: 3.178779191135505
Validation loss: 2.452824951699819

Epoch: 6| Step: 11
Training loss: 2.748284064646119
Validation loss: 2.4770742141143316

Epoch: 6| Step: 12
Training loss: 2.8792353407034588
Validation loss: 2.5043629415119777

Epoch: 6| Step: 13
Training loss: 2.725387188763152
Validation loss: 2.533266973260504

Epoch: 144| Step: 0
Training loss: 3.0581515834205693
Validation loss: 2.568794974211399

Epoch: 6| Step: 1
Training loss: 2.3405122900438253
Validation loss: 2.5463832750709003

Epoch: 6| Step: 2
Training loss: 2.7984828483106376
Validation loss: 2.5208135197456665

Epoch: 6| Step: 3
Training loss: 2.9041931092761026
Validation loss: 2.4536822649937844

Epoch: 6| Step: 4
Training loss: 2.9118948639345477
Validation loss: 2.449656638703532

Epoch: 6| Step: 5
Training loss: 3.017245000827664
Validation loss: 2.490310808424701

Epoch: 6| Step: 6
Training loss: 2.9820891408920147
Validation loss: 2.56252260195661

Epoch: 6| Step: 7
Training loss: 2.864999710801994
Validation loss: 2.5992616851282686

Epoch: 6| Step: 8
Training loss: 2.2410364685631903
Validation loss: 2.617949340214474

Epoch: 6| Step: 9
Training loss: 2.6145485398205244
Validation loss: 2.593945682288718

Epoch: 6| Step: 10
Training loss: 3.053238547018559
Validation loss: 2.611176118046584

Epoch: 6| Step: 11
Training loss: 2.446564375257486
Validation loss: 2.585806370127968

Epoch: 6| Step: 12
Training loss: 2.454632144257678
Validation loss: 2.5424763210114096

Epoch: 6| Step: 13
Training loss: 2.7661213402491827
Validation loss: 2.493452772105842

Epoch: 145| Step: 0
Training loss: 2.9450217186947847
Validation loss: 2.444478611165078

Epoch: 6| Step: 1
Training loss: 2.808843482193071
Validation loss: 2.432238060932162

Epoch: 6| Step: 2
Training loss: 2.4619128035436586
Validation loss: 2.4222438524758156

Epoch: 6| Step: 3
Training loss: 2.1132365731471983
Validation loss: 2.424154391751778

Epoch: 6| Step: 4
Training loss: 2.3905123017119636
Validation loss: 2.425724460525652

Epoch: 6| Step: 5
Training loss: 2.9660224029250557
Validation loss: 2.4311226647764497

Epoch: 6| Step: 6
Training loss: 3.252178489047239
Validation loss: 2.426533907559754

Epoch: 6| Step: 7
Training loss: 2.5124418603044156
Validation loss: 2.444294841685831

Epoch: 6| Step: 8
Training loss: 3.1256069356895573
Validation loss: 2.451248501515221

Epoch: 6| Step: 9
Training loss: 2.638034610894324
Validation loss: 2.4684142755055998

Epoch: 6| Step: 10
Training loss: 2.4931343217294377
Validation loss: 2.5031932996882644

Epoch: 6| Step: 11
Training loss: 2.983975368725363
Validation loss: 2.5068866864847674

Epoch: 6| Step: 12
Training loss: 2.3042936344127174
Validation loss: 2.50369157597655

Epoch: 6| Step: 13
Training loss: 2.3589559018620783
Validation loss: 2.5087125635904166

Epoch: 146| Step: 0
Training loss: 3.0092318270049696
Validation loss: 2.528200743358783

Epoch: 6| Step: 1
Training loss: 3.2018663864421977
Validation loss: 2.5741362082556045

Epoch: 6| Step: 2
Training loss: 2.8417389853961965
Validation loss: 2.607405808332348

Epoch: 6| Step: 3
Training loss: 2.6755550985064844
Validation loss: 2.6423622431642664

Epoch: 6| Step: 4
Training loss: 3.296023579800156
Validation loss: 2.6412867273794682

Epoch: 6| Step: 5
Training loss: 2.191846833843502
Validation loss: 2.581360299353133

Epoch: 6| Step: 6
Training loss: 2.2293702742620356
Validation loss: 2.545396507656225

Epoch: 6| Step: 7
Training loss: 2.5332187484459423
Validation loss: 2.510109138944787

Epoch: 6| Step: 8
Training loss: 2.582059135805828
Validation loss: 2.4893827648895006

Epoch: 6| Step: 9
Training loss: 1.9651770489163685
Validation loss: 2.4647869078006157

Epoch: 6| Step: 10
Training loss: 2.885552982640416
Validation loss: 2.458142522585263

Epoch: 6| Step: 11
Training loss: 2.778661916746423
Validation loss: 2.4676549146031177

Epoch: 6| Step: 12
Training loss: 2.270039014102911
Validation loss: 2.461069451782612

Epoch: 6| Step: 13
Training loss: 2.676230466683171
Validation loss: 2.4643806836536273

Epoch: 147| Step: 0
Training loss: 1.9163938687558668
Validation loss: 2.4512877488505658

Epoch: 6| Step: 1
Training loss: 2.8878369881968666
Validation loss: 2.4603934050340976

Epoch: 6| Step: 2
Training loss: 2.512881471133063
Validation loss: 2.474096279648482

Epoch: 6| Step: 3
Training loss: 2.8690099926651866
Validation loss: 2.4683441621896636

Epoch: 6| Step: 4
Training loss: 3.3053283791432473
Validation loss: 2.469311907887035

Epoch: 6| Step: 5
Training loss: 2.740960871125269
Validation loss: 2.4686380269836388

Epoch: 6| Step: 6
Training loss: 2.6936788279608144
Validation loss: 2.456473062938563

Epoch: 6| Step: 7
Training loss: 2.6058567107147974
Validation loss: 2.4653863345581652

Epoch: 6| Step: 8
Training loss: 2.8600776517770172
Validation loss: 2.4776066474961023

Epoch: 6| Step: 9
Training loss: 2.371704827236438
Validation loss: 2.478430357290187

Epoch: 6| Step: 10
Training loss: 2.5848197249927645
Validation loss: 2.4852712228083678

Epoch: 6| Step: 11
Training loss: 2.329105042908825
Validation loss: 2.5003911727541026

Epoch: 6| Step: 12
Training loss: 2.558812442198405
Validation loss: 2.5052212234345217

Epoch: 6| Step: 13
Training loss: 2.8087315213894732
Validation loss: 2.5129787901678426

Epoch: 148| Step: 0
Training loss: 2.9916118336985815
Validation loss: 2.5186005262418454

Epoch: 6| Step: 1
Training loss: 2.775800187496968
Validation loss: 2.5344603383325426

Epoch: 6| Step: 2
Training loss: 3.040967800031371
Validation loss: 2.5087437485639996

Epoch: 6| Step: 3
Training loss: 1.4673091232703563
Validation loss: 2.505608232254555

Epoch: 6| Step: 4
Training loss: 2.445013643472436
Validation loss: 2.50658614036922

Epoch: 6| Step: 5
Training loss: 3.100831529397567
Validation loss: 2.498507530013194

Epoch: 6| Step: 6
Training loss: 2.6744230735614187
Validation loss: 2.498569261654161

Epoch: 6| Step: 7
Training loss: 2.1374282914118394
Validation loss: 2.4869095358592817

Epoch: 6| Step: 8
Training loss: 3.0761442831103833
Validation loss: 2.4912245191828544

Epoch: 6| Step: 9
Training loss: 2.515506149232916
Validation loss: 2.4962299006872977

Epoch: 6| Step: 10
Training loss: 1.727517394711133
Validation loss: 2.5038441072837583

Epoch: 6| Step: 11
Training loss: 3.0938085685349432
Validation loss: 2.491548717433068

Epoch: 6| Step: 12
Training loss: 2.7272626529854325
Validation loss: 2.4952739498003815

Epoch: 6| Step: 13
Training loss: 2.726644869983856
Validation loss: 2.5007263620428963

Epoch: 149| Step: 0
Training loss: 3.0183188310173312
Validation loss: 2.4996596761016034

Epoch: 6| Step: 1
Training loss: 2.411416983747696
Validation loss: 2.517391127785883

Epoch: 6| Step: 2
Training loss: 2.6397730790495064
Validation loss: 2.5324598444522213

Epoch: 6| Step: 3
Training loss: 2.9368027204446396
Validation loss: 2.5197713712227543

Epoch: 6| Step: 4
Training loss: 2.872186694078163
Validation loss: 2.4911863589731205

Epoch: 6| Step: 5
Training loss: 2.9929438897407064
Validation loss: 2.4604015417152394

Epoch: 6| Step: 6
Training loss: 2.4932829264103082
Validation loss: 2.455384715873257

Epoch: 6| Step: 7
Training loss: 2.3610066209996736
Validation loss: 2.4584734838325693

Epoch: 6| Step: 8
Training loss: 2.6117491742871572
Validation loss: 2.473157894433408

Epoch: 6| Step: 9
Training loss: 2.922811592662307
Validation loss: 2.4762555350697903

Epoch: 6| Step: 10
Training loss: 2.5868647546558394
Validation loss: 2.488720988602798

Epoch: 6| Step: 11
Training loss: 2.396474127836945
Validation loss: 2.5171988441711366

Epoch: 6| Step: 12
Training loss: 2.432972150499759
Validation loss: 2.5126950875293153

Epoch: 6| Step: 13
Training loss: 1.9305224137545114
Validation loss: 2.5332584998547527

Epoch: 150| Step: 0
Training loss: 3.556195218111808
Validation loss: 2.5280198837674073

Epoch: 6| Step: 1
Training loss: 2.682022012038507
Validation loss: 2.5146624991858775

Epoch: 6| Step: 2
Training loss: 3.121045624286738
Validation loss: 2.5135069409099624

Epoch: 6| Step: 3
Training loss: 2.4950485787411676
Validation loss: 2.508025110173446

Epoch: 6| Step: 4
Training loss: 2.840758374464439
Validation loss: 2.479766350927784

Epoch: 6| Step: 5
Training loss: 1.9707605298757973
Validation loss: 2.487236361075629

Epoch: 6| Step: 6
Training loss: 2.643594460387219
Validation loss: 2.49178656694516

Epoch: 6| Step: 7
Training loss: 2.392344535791132
Validation loss: 2.4859315496808048

Epoch: 6| Step: 8
Training loss: 2.3425442455106995
Validation loss: 2.49392754969761

Epoch: 6| Step: 9
Training loss: 2.2527113578444697
Validation loss: 2.504912893776753

Epoch: 6| Step: 10
Training loss: 2.523342449653851
Validation loss: 2.527324836141465

Epoch: 6| Step: 11
Training loss: 2.48546782635723
Validation loss: 2.563424152610045

Epoch: 6| Step: 12
Training loss: 2.6030278475103854
Validation loss: 2.589604966499107

Epoch: 6| Step: 13
Training loss: 2.720118035952962
Validation loss: 2.5874911168981183

Epoch: 151| Step: 0
Training loss: 2.5074713644292363
Validation loss: 2.570316839702269

Epoch: 6| Step: 1
Training loss: 2.2860885935225874
Validation loss: 2.5653465421751576

Epoch: 6| Step: 2
Training loss: 2.825946875357017
Validation loss: 2.539758259977064

Epoch: 6| Step: 3
Training loss: 2.8252631613439423
Validation loss: 2.5130760340254947

Epoch: 6| Step: 4
Training loss: 3.0533316254368077
Validation loss: 2.5018002888293402

Epoch: 6| Step: 5
Training loss: 1.967343812145238
Validation loss: 2.4938601500118067

Epoch: 6| Step: 6
Training loss: 2.879580621914495
Validation loss: 2.4879109789749343

Epoch: 6| Step: 7
Training loss: 2.674005205798449
Validation loss: 2.4852163373969707

Epoch: 6| Step: 8
Training loss: 2.6363094662090667
Validation loss: 2.501737423618865

Epoch: 6| Step: 9
Training loss: 2.929613768603452
Validation loss: 2.5133012859417176

Epoch: 6| Step: 10
Training loss: 3.097698427853615
Validation loss: 2.519491543512207

Epoch: 6| Step: 11
Training loss: 2.6282259782222948
Validation loss: 2.5186696420932626

Epoch: 6| Step: 12
Training loss: 2.0042919360352567
Validation loss: 2.5257197246057217

Epoch: 6| Step: 13
Training loss: 2.411708931366928
Validation loss: 2.5453265337324016

Epoch: 152| Step: 0
Training loss: 2.8333472831233073
Validation loss: 2.565024782089973

Epoch: 6| Step: 1
Training loss: 2.123279099103655
Validation loss: 2.560658841674526

Epoch: 6| Step: 2
Training loss: 2.533820460148583
Validation loss: 2.5688096786052466

Epoch: 6| Step: 3
Training loss: 2.9226752016727167
Validation loss: 2.5373830062217677

Epoch: 6| Step: 4
Training loss: 1.7795467599039971
Validation loss: 2.5234917542435613

Epoch: 6| Step: 5
Training loss: 2.7218272015549614
Validation loss: 2.5184046474009536

Epoch: 6| Step: 6
Training loss: 3.3155900469779342
Validation loss: 2.506084386606115

Epoch: 6| Step: 7
Training loss: 2.389067797159094
Validation loss: 2.5026285893514517

Epoch: 6| Step: 8
Training loss: 2.6172937172359383
Validation loss: 2.4960059244656407

Epoch: 6| Step: 9
Training loss: 2.8102392647311403
Validation loss: 2.4959634063888205

Epoch: 6| Step: 10
Training loss: 2.631057290022189
Validation loss: 2.492121858619892

Epoch: 6| Step: 11
Training loss: 2.5813743690658786
Validation loss: 2.4835877520742886

Epoch: 6| Step: 12
Training loss: 2.5637837427560775
Validation loss: 2.5016330051408517

Epoch: 6| Step: 13
Training loss: 2.7465630641706205
Validation loss: 2.56062716063026

Epoch: 153| Step: 0
Training loss: 1.7545584844374038
Validation loss: 2.571171540424465

Epoch: 6| Step: 1
Training loss: 2.8407224531421815
Validation loss: 2.593485052061113

Epoch: 6| Step: 2
Training loss: 3.39749307773494
Validation loss: 2.6332875638634086

Epoch: 6| Step: 3
Training loss: 2.4583841307828327
Validation loss: 2.594767698368928

Epoch: 6| Step: 4
Training loss: 2.2899079828223887
Validation loss: 2.58698687545021

Epoch: 6| Step: 5
Training loss: 2.490903996213678
Validation loss: 2.5641834942743302

Epoch: 6| Step: 6
Training loss: 2.809786526047922
Validation loss: 2.5461485673724447

Epoch: 6| Step: 7
Training loss: 2.706016978039312
Validation loss: 2.5386614880545633

Epoch: 6| Step: 8
Training loss: 2.672349675717353
Validation loss: 2.5244250140475515

Epoch: 6| Step: 9
Training loss: 2.781137785630175
Validation loss: 2.5168629991514213

Epoch: 6| Step: 10
Training loss: 2.950384735622763
Validation loss: 2.5287621274944856

Epoch: 6| Step: 11
Training loss: 1.9404434487748068
Validation loss: 2.5267408977332626

Epoch: 6| Step: 12
Training loss: 2.4530905945910346
Validation loss: 2.5370914999477665

Epoch: 6| Step: 13
Training loss: 2.9149466392906938
Validation loss: 2.560324271701475

Epoch: 154| Step: 0
Training loss: 2.3242080816456836
Validation loss: 2.6054121990560484

Epoch: 6| Step: 1
Training loss: 2.9608978832483253
Validation loss: 2.6113608618376123

Epoch: 6| Step: 2
Training loss: 2.6902731848197052
Validation loss: 2.6278208251566193

Epoch: 6| Step: 3
Training loss: 2.4556404386303523
Validation loss: 2.63335268488085

Epoch: 6| Step: 4
Training loss: 2.9398988708956897
Validation loss: 2.5805659994358523

Epoch: 6| Step: 5
Training loss: 2.526392762209893
Validation loss: 2.5602955834293812

Epoch: 6| Step: 6
Training loss: 2.6405408495975884
Validation loss: 2.5670300142085325

Epoch: 6| Step: 7
Training loss: 3.0805050705798496
Validation loss: 2.5622918249248694

Epoch: 6| Step: 8
Training loss: 2.3562894944339057
Validation loss: 2.5457956243993376

Epoch: 6| Step: 9
Training loss: 2.423793893921255
Validation loss: 2.5270327706889413

Epoch: 6| Step: 10
Training loss: 2.5051102860285446
Validation loss: 2.478874986310499

Epoch: 6| Step: 11
Training loss: 1.919015136690858
Validation loss: 2.4583062385441097

Epoch: 6| Step: 12
Training loss: 2.948509525132962
Validation loss: 2.4460368824648935

Epoch: 6| Step: 13
Training loss: 2.6874583928635625
Validation loss: 2.4501031055314724

Epoch: 155| Step: 0
Training loss: 3.019391647605666
Validation loss: 2.4589785679296723

Epoch: 6| Step: 1
Training loss: 2.132202061079686
Validation loss: 2.4637792349981127

Epoch: 6| Step: 2
Training loss: 2.2714400807831976
Validation loss: 2.493050588495686

Epoch: 6| Step: 3
Training loss: 2.7520591655847273
Validation loss: 2.5510377678764966

Epoch: 6| Step: 4
Training loss: 2.6682266401142045
Validation loss: 2.5445853577886344

Epoch: 6| Step: 5
Training loss: 2.623737303987984
Validation loss: 2.5198052708421597

Epoch: 6| Step: 6
Training loss: 2.784820151146382
Validation loss: 2.5077045279297416

Epoch: 6| Step: 7
Training loss: 2.5396105365584467
Validation loss: 2.495235368634812

Epoch: 6| Step: 8
Training loss: 2.2909958522297855
Validation loss: 2.4832729114494394

Epoch: 6| Step: 9
Training loss: 2.9993903812269225
Validation loss: 2.480763617389662

Epoch: 6| Step: 10
Training loss: 2.252380383498261
Validation loss: 2.4894164586339347

Epoch: 6| Step: 11
Training loss: 2.600249087799766
Validation loss: 2.5030510404521116

Epoch: 6| Step: 12
Training loss: 3.1217020561573445
Validation loss: 2.5135171658449638

Epoch: 6| Step: 13
Training loss: 1.9894457331770443
Validation loss: 2.579051063554099

Epoch: 156| Step: 0
Training loss: 3.0176335894477937
Validation loss: 2.638052501661892

Epoch: 6| Step: 1
Training loss: 2.620620889549025
Validation loss: 2.73269374368951

Epoch: 6| Step: 2
Training loss: 2.4483691723898753
Validation loss: 2.717757658147515

Epoch: 6| Step: 3
Training loss: 2.375598430530128
Validation loss: 2.641340771938879

Epoch: 6| Step: 4
Training loss: 2.5469418382358002
Validation loss: 2.5518089188755964

Epoch: 6| Step: 5
Training loss: 2.7712518380743596
Validation loss: 2.5193639398420182

Epoch: 6| Step: 6
Training loss: 2.614550910738544
Validation loss: 2.519507551133451

Epoch: 6| Step: 7
Training loss: 2.181825962919752
Validation loss: 2.5183383598865734

Epoch: 6| Step: 8
Training loss: 2.663334005767139
Validation loss: 2.5281890800987816

Epoch: 6| Step: 9
Training loss: 2.8942992906382474
Validation loss: 2.556042382699917

Epoch: 6| Step: 10
Training loss: 2.6316246726430377
Validation loss: 2.6012185132402936

Epoch: 6| Step: 11
Training loss: 2.916367669901613
Validation loss: 2.598660897009243

Epoch: 6| Step: 12
Training loss: 2.7394874952448283
Validation loss: 2.5850580673874464

Epoch: 6| Step: 13
Training loss: 2.2007600251766495
Validation loss: 2.5593051507865017

Epoch: 157| Step: 0
Training loss: 2.4553424507791464
Validation loss: 2.5623102505529465

Epoch: 6| Step: 1
Training loss: 2.555422056092814
Validation loss: 2.5595253006389735

Epoch: 6| Step: 2
Training loss: 2.4532816648570996
Validation loss: 2.5429288005568766

Epoch: 6| Step: 3
Training loss: 2.3985957488001413
Validation loss: 2.532829961355768

Epoch: 6| Step: 4
Training loss: 2.679221421350162
Validation loss: 2.565505261646195

Epoch: 6| Step: 5
Training loss: 2.789668426089515
Validation loss: 2.657462320300359

Epoch: 6| Step: 6
Training loss: 1.5883825086898127
Validation loss: 2.728818177160633

Epoch: 6| Step: 7
Training loss: 3.1106731829399905
Validation loss: 2.788800933311437

Epoch: 6| Step: 8
Training loss: 2.7913937696236095
Validation loss: 2.709775038956475

Epoch: 6| Step: 9
Training loss: 3.276845682738051
Validation loss: 2.6240336255159558

Epoch: 6| Step: 10
Training loss: 2.954636767116754
Validation loss: 2.5464432178801237

Epoch: 6| Step: 11
Training loss: 2.2338501640622535
Validation loss: 2.4532946226272507

Epoch: 6| Step: 12
Training loss: 2.266415583036734
Validation loss: 2.4438355196039594

Epoch: 6| Step: 13
Training loss: 3.0951251432049736
Validation loss: 2.4600005460578958

Epoch: 158| Step: 0
Training loss: 2.0158109357372025
Validation loss: 2.459266406960724

Epoch: 6| Step: 1
Training loss: 3.079069196081474
Validation loss: 2.470566116484298

Epoch: 6| Step: 2
Training loss: 2.571788422064733
Validation loss: 2.4713230206085215

Epoch: 6| Step: 3
Training loss: 2.5105288996215442
Validation loss: 2.490968740342493

Epoch: 6| Step: 4
Training loss: 2.6592701515839314
Validation loss: 2.5134386433970035

Epoch: 6| Step: 5
Training loss: 2.3883626368078827
Validation loss: 2.5567754897001302

Epoch: 6| Step: 6
Training loss: 2.8535553957486868
Validation loss: 2.602545074275559

Epoch: 6| Step: 7
Training loss: 1.8072189477660958
Validation loss: 2.631111589520592

Epoch: 6| Step: 8
Training loss: 2.7578249490689273
Validation loss: 2.6518773772840794

Epoch: 6| Step: 9
Training loss: 2.8544425738183214
Validation loss: 2.706462755252056

Epoch: 6| Step: 10
Training loss: 2.388689441881439
Validation loss: 2.6951638914196505

Epoch: 6| Step: 11
Training loss: 2.2222836790593643
Validation loss: 2.6657370233825683

Epoch: 6| Step: 12
Training loss: 2.527330825984875
Validation loss: 2.657885078731284

Epoch: 6| Step: 13
Training loss: 2.9915131688032957
Validation loss: 2.667854265427303

Epoch: 159| Step: 0
Training loss: 2.656707455008052
Validation loss: 2.6393120488113553

Epoch: 6| Step: 1
Training loss: 2.171530936452712
Validation loss: 2.6195388939801503

Epoch: 6| Step: 2
Training loss: 2.4367626737822916
Validation loss: 2.570580907419936

Epoch: 6| Step: 3
Training loss: 2.4066720567609425
Validation loss: 2.505067984904737

Epoch: 6| Step: 4
Training loss: 2.6546644078463353
Validation loss: 2.4881448405529785

Epoch: 6| Step: 5
Training loss: 2.510867340873826
Validation loss: 2.4726285310978846

Epoch: 6| Step: 6
Training loss: 2.2218930186038675
Validation loss: 2.4800650903388073

Epoch: 6| Step: 7
Training loss: 2.565493719015572
Validation loss: 2.473313483158095

Epoch: 6| Step: 8
Training loss: 2.5055625067720415
Validation loss: 2.473329739895407

Epoch: 6| Step: 9
Training loss: 2.666135099200245
Validation loss: 2.4964494226005307

Epoch: 6| Step: 10
Training loss: 2.7496875238619087
Validation loss: 2.517598964348716

Epoch: 6| Step: 11
Training loss: 2.7560799751692273
Validation loss: 2.5331214570748557

Epoch: 6| Step: 12
Training loss: 2.7026685208014873
Validation loss: 2.5909798867302025

Epoch: 6| Step: 13
Training loss: 2.784008843764147
Validation loss: 2.665842242881409

Epoch: 160| Step: 0
Training loss: 2.5254416051263826
Validation loss: 2.7167217330087667

Epoch: 6| Step: 1
Training loss: 2.8174952757287213
Validation loss: 2.728819531874886

Epoch: 6| Step: 2
Training loss: 2.2907735529214057
Validation loss: 2.6974374891411874

Epoch: 6| Step: 3
Training loss: 2.5385450569498564
Validation loss: 2.612143019253758

Epoch: 6| Step: 4
Training loss: 1.1658084755665834
Validation loss: 2.5756771714115327

Epoch: 6| Step: 5
Training loss: 2.679418166613485
Validation loss: 2.5415336524321392

Epoch: 6| Step: 6
Training loss: 2.1979499802317126
Validation loss: 2.520481709183186

Epoch: 6| Step: 7
Training loss: 2.6651404205315568
Validation loss: 2.4981316393954116

Epoch: 6| Step: 8
Training loss: 2.696899919626821
Validation loss: 2.4975117036520045

Epoch: 6| Step: 9
Training loss: 3.056965400577368
Validation loss: 2.4765163231126324

Epoch: 6| Step: 10
Training loss: 2.609821852381072
Validation loss: 2.4932831310258616

Epoch: 6| Step: 11
Training loss: 2.263644069339579
Validation loss: 2.4911165243373707

Epoch: 6| Step: 12
Training loss: 3.010701800683954
Validation loss: 2.508683220727955

Epoch: 6| Step: 13
Training loss: 2.5493896801173546
Validation loss: 2.492043199018821

Epoch: 161| Step: 0
Training loss: 2.456281247316351
Validation loss: 2.473828183406153

Epoch: 6| Step: 1
Training loss: 2.1183280547181558
Validation loss: 2.456784560511107

Epoch: 6| Step: 2
Training loss: 2.0198424226844
Validation loss: 2.4819556573549777

Epoch: 6| Step: 3
Training loss: 3.0349981986076626
Validation loss: 2.501327124454692

Epoch: 6| Step: 4
Training loss: 2.56028726456138
Validation loss: 2.5222167189915417

Epoch: 6| Step: 5
Training loss: 2.5647039472373994
Validation loss: 2.5472301731495537

Epoch: 6| Step: 6
Training loss: 2.805738586859394
Validation loss: 2.546408743386481

Epoch: 6| Step: 7
Training loss: 2.774722207401503
Validation loss: 2.506590345962349

Epoch: 6| Step: 8
Training loss: 2.41460691566131
Validation loss: 2.5083968630119133

Epoch: 6| Step: 9
Training loss: 2.4591823555749563
Validation loss: 2.5126479896514677

Epoch: 6| Step: 10
Training loss: 2.083233970815723
Validation loss: 2.5175315945362273

Epoch: 6| Step: 11
Training loss: 2.440666587172445
Validation loss: 2.511049843242573

Epoch: 6| Step: 12
Training loss: 2.4729169614727957
Validation loss: 2.525936164509159

Epoch: 6| Step: 13
Training loss: 2.980923719165323
Validation loss: 2.5478296112113705

Epoch: 162| Step: 0
Training loss: 2.5248730240423223
Validation loss: 2.6252080324150215

Epoch: 6| Step: 1
Training loss: 2.264293832063843
Validation loss: 2.7064067251158113

Epoch: 6| Step: 2
Training loss: 2.804459161415854
Validation loss: 2.767883372410552

Epoch: 6| Step: 3
Training loss: 2.2922222735491817
Validation loss: 2.7170724791275855

Epoch: 6| Step: 4
Training loss: 2.369313912214212
Validation loss: 2.665322082717067

Epoch: 6| Step: 5
Training loss: 2.378040575892434
Validation loss: 2.6367571180097493

Epoch: 6| Step: 6
Training loss: 2.338604785319432
Validation loss: 2.5971377700117175

Epoch: 6| Step: 7
Training loss: 2.9684745259219194
Validation loss: 2.5461177035989424

Epoch: 6| Step: 8
Training loss: 2.0141217444253927
Validation loss: 2.5258746267099674

Epoch: 6| Step: 9
Training loss: 3.1919094328687834
Validation loss: 2.5146783805487734

Epoch: 6| Step: 10
Training loss: 2.1088195069350033
Validation loss: 2.519579751038436

Epoch: 6| Step: 11
Training loss: 2.6952519949051217
Validation loss: 2.5076417049240316

Epoch: 6| Step: 12
Training loss: 2.617726922313924
Validation loss: 2.4655922585474377

Epoch: 6| Step: 13
Training loss: 2.702809309854432
Validation loss: 2.453418485006168

Epoch: 163| Step: 0
Training loss: 2.7034447100548378
Validation loss: 2.452378159781795

Epoch: 6| Step: 1
Training loss: 2.683395089649178
Validation loss: 2.451779269897443

Epoch: 6| Step: 2
Training loss: 1.7710032288076563
Validation loss: 2.4649166701394294

Epoch: 6| Step: 3
Training loss: 1.926135976437903
Validation loss: 2.4969618723293396

Epoch: 6| Step: 4
Training loss: 2.4233790495739247
Validation loss: 2.5663173923183087

Epoch: 6| Step: 5
Training loss: 2.8096774030794
Validation loss: 2.6067256179626463

Epoch: 6| Step: 6
Training loss: 2.3509393924703996
Validation loss: 2.630916841580339

Epoch: 6| Step: 7
Training loss: 2.6950633942856985
Validation loss: 2.647063828542075

Epoch: 6| Step: 8
Training loss: 3.039139381358033
Validation loss: 2.656419504199491

Epoch: 6| Step: 9
Training loss: 2.648297781620624
Validation loss: 2.6428687925292227

Epoch: 6| Step: 10
Training loss: 2.1792306728943576
Validation loss: 2.6600056397320206

Epoch: 6| Step: 11
Training loss: 2.2340996846060466
Validation loss: 2.649093607158662

Epoch: 6| Step: 12
Training loss: 2.692297623164872
Validation loss: 2.6618438172470036

Epoch: 6| Step: 13
Training loss: 2.4029391411588605
Validation loss: 2.598068875875124

Epoch: 164| Step: 0
Training loss: 2.8134448689532996
Validation loss: 2.5516801403021585

Epoch: 6| Step: 1
Training loss: 2.1741262061888245
Validation loss: 2.5130782405453873

Epoch: 6| Step: 2
Training loss: 2.900072320496737
Validation loss: 2.4980462582188547

Epoch: 6| Step: 3
Training loss: 2.445087556577939
Validation loss: 2.4605959502740875

Epoch: 6| Step: 4
Training loss: 2.5398594001844037
Validation loss: 2.4631572233418715

Epoch: 6| Step: 5
Training loss: 2.5399512041466075
Validation loss: 2.493601802970744

Epoch: 6| Step: 6
Training loss: 1.9835329446866947
Validation loss: 2.5590952151594113

Epoch: 6| Step: 7
Training loss: 2.277565894571169
Validation loss: 2.590991774924213

Epoch: 6| Step: 8
Training loss: 2.1885653490119394
Validation loss: 2.661406352508393

Epoch: 6| Step: 9
Training loss: 2.2346369449752657
Validation loss: 2.7065219990559184

Epoch: 6| Step: 10
Training loss: 2.4883780228557213
Validation loss: 2.7278860908302827

Epoch: 6| Step: 11
Training loss: 2.0687164488316188
Validation loss: 2.6774006629916043

Epoch: 6| Step: 12
Training loss: 3.002547136456083
Validation loss: 2.668353009642118

Epoch: 6| Step: 13
Training loss: 2.4895377587226335
Validation loss: 2.6487167772095552

Epoch: 165| Step: 0
Training loss: 2.473675317470631
Validation loss: 2.6185349584666717

Epoch: 6| Step: 1
Training loss: 2.775781119443513
Validation loss: 2.5882869989768533

Epoch: 6| Step: 2
Training loss: 2.1188056645915925
Validation loss: 2.5919962614030716

Epoch: 6| Step: 3
Training loss: 2.3048972858704757
Validation loss: 2.6102535155930706

Epoch: 6| Step: 4
Training loss: 1.6763583525614065
Validation loss: 2.622829509705799

Epoch: 6| Step: 5
Training loss: 2.303563972368139
Validation loss: 2.615057355439618

Epoch: 6| Step: 6
Training loss: 2.5279147934255666
Validation loss: 2.6157227557290175

Epoch: 6| Step: 7
Training loss: 2.773609252769456
Validation loss: 2.6012413602467706

Epoch: 6| Step: 8
Training loss: 1.9971401510175486
Validation loss: 2.585012567602689

Epoch: 6| Step: 9
Training loss: 2.7473063715008488
Validation loss: 2.5645508021825685

Epoch: 6| Step: 10
Training loss: 2.315062057289515
Validation loss: 2.576208627089995

Epoch: 6| Step: 11
Training loss: 2.921308656363971
Validation loss: 2.53185030231056

Epoch: 6| Step: 12
Training loss: 2.3026062959702736
Validation loss: 2.518308196693196

Epoch: 6| Step: 13
Training loss: 2.381645842564145
Validation loss: 2.531743332604892

Epoch: 166| Step: 0
Training loss: 2.351563311098282
Validation loss: 2.5213985548451596

Epoch: 6| Step: 1
Training loss: 2.380178728204721
Validation loss: 2.5165778686427247

Epoch: 6| Step: 2
Training loss: 2.221785819065276
Validation loss: 2.5280221674979035

Epoch: 6| Step: 3
Training loss: 2.6131980437986866
Validation loss: 2.5525443575843307

Epoch: 6| Step: 4
Training loss: 2.2715431527218968
Validation loss: 2.5522529346464133

Epoch: 6| Step: 5
Training loss: 1.9522749004458904
Validation loss: 2.568136801016696

Epoch: 6| Step: 6
Training loss: 2.8173276370247144
Validation loss: 2.546469118495832

Epoch: 6| Step: 7
Training loss: 2.637441849632494
Validation loss: 2.527003180480657

Epoch: 6| Step: 8
Training loss: 2.292392534838429
Validation loss: 2.5680488817038065

Epoch: 6| Step: 9
Training loss: 2.4210663460642046
Validation loss: 2.5385495776996674

Epoch: 6| Step: 10
Training loss: 2.16223441902128
Validation loss: 2.5271659930953922

Epoch: 6| Step: 11
Training loss: 2.684009147821747
Validation loss: 2.5367293701446787

Epoch: 6| Step: 12
Training loss: 2.876310630268726
Validation loss: 2.508857639861817

Epoch: 6| Step: 13
Training loss: 1.9795832413074064
Validation loss: 2.5168580478015103

Epoch: 167| Step: 0
Training loss: 2.2700976191969353
Validation loss: 2.499119439455582

Epoch: 6| Step: 1
Training loss: 2.7226695603602193
Validation loss: 2.5115333289274013

Epoch: 6| Step: 2
Training loss: 1.7199500316192589
Validation loss: 2.55345534578062

Epoch: 6| Step: 3
Training loss: 2.5120021725420454
Validation loss: 2.5974043065269776

Epoch: 6| Step: 4
Training loss: 2.5035885804239677
Validation loss: 2.62241112808587

Epoch: 6| Step: 5
Training loss: 2.5232249072962745
Validation loss: 2.6219300123373137

Epoch: 6| Step: 6
Training loss: 2.2507765807315545
Validation loss: 2.6157147611322755

Epoch: 6| Step: 7
Training loss: 2.470755040524228
Validation loss: 2.599026932697671

Epoch: 6| Step: 8
Training loss: 2.2206831556242643
Validation loss: 2.581024345425176

Epoch: 6| Step: 9
Training loss: 2.0870650883437722
Validation loss: 2.6035340926862043

Epoch: 6| Step: 10
Training loss: 2.671093921376859
Validation loss: 2.5981068969911467

Epoch: 6| Step: 11
Training loss: 2.8821660172390717
Validation loss: 2.599512636449166

Epoch: 6| Step: 12
Training loss: 2.1744882792816793
Validation loss: 2.5574806891539987

Epoch: 6| Step: 13
Training loss: 2.402034584558736
Validation loss: 2.5654960483308082

Epoch: 168| Step: 0
Training loss: 2.4487915639966924
Validation loss: 2.520921980349128

Epoch: 6| Step: 1
Training loss: 2.781315149122845
Validation loss: 2.504959181720603

Epoch: 6| Step: 2
Training loss: 2.9983948546016355
Validation loss: 2.518093889170747

Epoch: 6| Step: 3
Training loss: 1.944093989019273
Validation loss: 2.5372500156401063

Epoch: 6| Step: 4
Training loss: 1.777980547838252
Validation loss: 2.5767441438409064

Epoch: 6| Step: 5
Training loss: 1.8952591274511166
Validation loss: 2.5721905086174717

Epoch: 6| Step: 6
Training loss: 2.6610769059494395
Validation loss: 2.557288206428232

Epoch: 6| Step: 7
Training loss: 2.229002997073336
Validation loss: 2.541923890865075

Epoch: 6| Step: 8
Training loss: 2.470789778927546
Validation loss: 2.5142766780738173

Epoch: 6| Step: 9
Training loss: 2.772085800670552
Validation loss: 2.500640162676116

Epoch: 6| Step: 10
Training loss: 2.0000585309047025
Validation loss: 2.4671556930540293

Epoch: 6| Step: 11
Training loss: 2.488500468659697
Validation loss: 2.4703831959169458

Epoch: 6| Step: 12
Training loss: 2.2914116688666533
Validation loss: 2.514194344382534

Epoch: 6| Step: 13
Training loss: 2.343252612424351
Validation loss: 2.5345547239264623

Epoch: 169| Step: 0
Training loss: 2.423436996292662
Validation loss: 2.572381471633688

Epoch: 6| Step: 1
Training loss: 2.8928985727293672
Validation loss: 2.5952810430738236

Epoch: 6| Step: 2
Training loss: 2.4879412695769685
Validation loss: 2.6408267894597226

Epoch: 6| Step: 3
Training loss: 2.659979502089835
Validation loss: 2.650448137222267

Epoch: 6| Step: 4
Training loss: 2.6874917495955755
Validation loss: 2.625831025166259

Epoch: 6| Step: 5
Training loss: 1.6022879841445206
Validation loss: 2.5594730933005216

Epoch: 6| Step: 6
Training loss: 2.3239130412130566
Validation loss: 2.518203056357797

Epoch: 6| Step: 7
Training loss: 2.2544816206679723
Validation loss: 2.503697624408029

Epoch: 6| Step: 8
Training loss: 2.463602034384954
Validation loss: 2.534584568354177

Epoch: 6| Step: 9
Training loss: 1.6298532637562662
Validation loss: 2.550088946886131

Epoch: 6| Step: 10
Training loss: 2.3181240666177514
Validation loss: 2.56899389056218

Epoch: 6| Step: 11
Training loss: 2.362412474287552
Validation loss: 2.6029299713892424

Epoch: 6| Step: 12
Training loss: 2.687769055759968
Validation loss: 2.6035073772722854

Epoch: 6| Step: 13
Training loss: 1.9680860096039325
Validation loss: 2.651190902816291

Epoch: 170| Step: 0
Training loss: 1.7017983685576097
Validation loss: 2.607842507039164

Epoch: 6| Step: 1
Training loss: 2.4313746050208276
Validation loss: 2.561129998385612

Epoch: 6| Step: 2
Training loss: 2.100421014090243
Validation loss: 2.4962490090695364

Epoch: 6| Step: 3
Training loss: 2.4917729430567617
Validation loss: 2.494188730688485

Epoch: 6| Step: 4
Training loss: 2.605706931784418
Validation loss: 2.467141491007789

Epoch: 6| Step: 5
Training loss: 1.5770908404246777
Validation loss: 2.4713761772469596

Epoch: 6| Step: 6
Training loss: 1.4734515969177517
Validation loss: 2.4566947693179606

Epoch: 6| Step: 7
Training loss: 2.386160277912447
Validation loss: 2.480522840273631

Epoch: 6| Step: 8
Training loss: 3.178197413156878
Validation loss: 2.503290826386814

Epoch: 6| Step: 9
Training loss: 2.3781741163517753
Validation loss: 2.5368683422072107

Epoch: 6| Step: 10
Training loss: 2.2226508866230326
Validation loss: 2.593434929073854

Epoch: 6| Step: 11
Training loss: 2.5081198435658374
Validation loss: 2.648114496551537

Epoch: 6| Step: 12
Training loss: 3.1053873687253364
Validation loss: 2.665698997473477

Epoch: 6| Step: 13
Training loss: 2.280966545157327
Validation loss: 2.614441198128124

Epoch: 171| Step: 0
Training loss: 1.5836291120558441
Validation loss: 2.610669245460219

Epoch: 6| Step: 1
Training loss: 2.3001281122103974
Validation loss: 2.620620032595784

Epoch: 6| Step: 2
Training loss: 2.7328168516740563
Validation loss: 2.607936223482661

Epoch: 6| Step: 3
Training loss: 1.765638300752757
Validation loss: 2.63671844567495

Epoch: 6| Step: 4
Training loss: 2.9110595939614026
Validation loss: 2.639263641209679

Epoch: 6| Step: 5
Training loss: 2.3912121419507093
Validation loss: 2.574847546341569

Epoch: 6| Step: 6
Training loss: 1.6849133482253122
Validation loss: 2.5526927666517767

Epoch: 6| Step: 7
Training loss: 2.425712252755158
Validation loss: 2.5228276700859062

Epoch: 6| Step: 8
Training loss: 2.472269760227226
Validation loss: 2.523229441778255

Epoch: 6| Step: 9
Training loss: 2.342387808084548
Validation loss: 2.554262787574147

Epoch: 6| Step: 10
Training loss: 2.383534406525285
Validation loss: 2.523184971396797

Epoch: 6| Step: 11
Training loss: 2.3184465811315444
Validation loss: 2.5414810371762906

Epoch: 6| Step: 12
Training loss: 2.396071568682738
Validation loss: 2.55509303318972

Epoch: 6| Step: 13
Training loss: 2.613328873409955
Validation loss: 2.5823502338820514

Epoch: 172| Step: 0
Training loss: 2.901226501238195
Validation loss: 2.5644517074488697

Epoch: 6| Step: 1
Training loss: 2.4872425732085235
Validation loss: 2.5582166589098505

Epoch: 6| Step: 2
Training loss: 2.046603235738406
Validation loss: 2.5706293458301674

Epoch: 6| Step: 3
Training loss: 2.3658542214609484
Validation loss: 2.6173289986079507

Epoch: 6| Step: 4
Training loss: 2.5384202350243936
Validation loss: 2.625147693774287

Epoch: 6| Step: 5
Training loss: 1.9565855573298745
Validation loss: 2.6079730548315996

Epoch: 6| Step: 6
Training loss: 2.380164604425277
Validation loss: 2.6345852363111453

Epoch: 6| Step: 7
Training loss: 2.5396985944503485
Validation loss: 2.5674858310527093

Epoch: 6| Step: 8
Training loss: 1.9742769438813181
Validation loss: 2.5521634224703025

Epoch: 6| Step: 9
Training loss: 2.3042057891706755
Validation loss: 2.5167246765066085

Epoch: 6| Step: 10
Training loss: 1.7297075030954363
Validation loss: 2.521789344753809

Epoch: 6| Step: 11
Training loss: 2.007724151448736
Validation loss: 2.5413521105180816

Epoch: 6| Step: 12
Training loss: 2.807632727538515
Validation loss: 2.5694183660542023

Epoch: 6| Step: 13
Training loss: 1.36800896080607
Validation loss: 2.5582954964968434

Epoch: 173| Step: 0
Training loss: 2.6176411249833507
Validation loss: 2.526008541971266

Epoch: 6| Step: 1
Training loss: 2.2590762498811543
Validation loss: 2.5555303289099585

Epoch: 6| Step: 2
Training loss: 2.055769254842696
Validation loss: 2.5571350172648897

Epoch: 6| Step: 3
Training loss: 2.022639172343051
Validation loss: 2.5617221298915767

Epoch: 6| Step: 4
Training loss: 1.498500233153464
Validation loss: 2.5917892161055236

Epoch: 6| Step: 5
Training loss: 1.9737573553217649
Validation loss: 2.5939009714302634

Epoch: 6| Step: 6
Training loss: 2.0984997749319403
Validation loss: 2.61987001084234

Epoch: 6| Step: 7
Training loss: 2.359256564571896
Validation loss: 2.5487277108485262

Epoch: 6| Step: 8
Training loss: 2.297616021648215
Validation loss: 2.519541087238287

Epoch: 6| Step: 9
Training loss: 2.0404780944007332
Validation loss: 2.449441761895435

Epoch: 6| Step: 10
Training loss: 2.397738177707368
Validation loss: 2.450916834503606

Epoch: 6| Step: 11
Training loss: 2.928752129326444
Validation loss: 2.40287232385365

Epoch: 6| Step: 12
Training loss: 2.575752785282134
Validation loss: 2.4478637413808855

Epoch: 6| Step: 13
Training loss: 2.9048589843560633
Validation loss: 2.493008805661561

Epoch: 174| Step: 0
Training loss: 2.3018642913958716
Validation loss: 2.5380361628567827

Epoch: 6| Step: 1
Training loss: 1.7716674037200935
Validation loss: 2.5678797988702398

Epoch: 6| Step: 2
Training loss: 2.2255046272238297
Validation loss: 2.616339787058508

Epoch: 6| Step: 3
Training loss: 2.558552189846145
Validation loss: 2.6658397233243503

Epoch: 6| Step: 4
Training loss: 2.0299077220670454
Validation loss: 2.6767758792647696

Epoch: 6| Step: 5
Training loss: 2.204336928754584
Validation loss: 2.64144131757833

Epoch: 6| Step: 6
Training loss: 2.603907722314784
Validation loss: 2.6422728437884566

Epoch: 6| Step: 7
Training loss: 2.4014902971442194
Validation loss: 2.6128297929599587

Epoch: 6| Step: 8
Training loss: 2.1920624156892394
Validation loss: 2.596386651271915

Epoch: 6| Step: 9
Training loss: 1.9872444612342124
Validation loss: 2.593745536419828

Epoch: 6| Step: 10
Training loss: 1.8811346151762847
Validation loss: 2.570188696209492

Epoch: 6| Step: 11
Training loss: 2.1631159175405474
Validation loss: 2.597896933201678

Epoch: 6| Step: 12
Training loss: 2.9693704057231183
Validation loss: 2.560353550409657

Epoch: 6| Step: 13
Training loss: 1.7178399884732933
Validation loss: 2.5649455296545014

Epoch: 175| Step: 0
Training loss: 2.2331975221855553
Validation loss: 2.545987554704851

Epoch: 6| Step: 1
Training loss: 2.7564809897030376
Validation loss: 2.5493594398370907

Epoch: 6| Step: 2
Training loss: 2.323961567473943
Validation loss: 2.520926222025855

Epoch: 6| Step: 3
Training loss: 2.213991892785147
Validation loss: 2.5242226322556927

Epoch: 6| Step: 4
Training loss: 2.2432501531014433
Validation loss: 2.5069789227546564

Epoch: 6| Step: 5
Training loss: 1.5270840553327087
Validation loss: 2.528051813215361

Epoch: 6| Step: 6
Training loss: 2.2481251428735054
Validation loss: 2.5715277482877643

Epoch: 6| Step: 7
Training loss: 2.2379823388569546
Validation loss: 2.642275023918395

Epoch: 6| Step: 8
Training loss: 1.9690437703224886
Validation loss: 2.711717142225926

Epoch: 6| Step: 9
Training loss: 2.564795326707691
Validation loss: 2.71932725974375

Epoch: 6| Step: 10
Training loss: 2.057710925168158
Validation loss: 2.704832681505627

Epoch: 6| Step: 11
Training loss: 2.5540449635155564
Validation loss: 2.6887301839145934

Epoch: 6| Step: 12
Training loss: 2.1434414566477367
Validation loss: 2.691230790471807

Epoch: 6| Step: 13
Training loss: 1.9219542696352303
Validation loss: 2.6354836944988898

Epoch: 176| Step: 0
Training loss: 1.6904662870415077
Validation loss: 2.5871735402588634

Epoch: 6| Step: 1
Training loss: 2.424603506492616
Validation loss: 2.549629049566903

Epoch: 6| Step: 2
Training loss: 2.348723259530509
Validation loss: 2.4984050236368116

Epoch: 6| Step: 3
Training loss: 1.6896163949738137
Validation loss: 2.4937694064296636

Epoch: 6| Step: 4
Training loss: 2.011734630929428
Validation loss: 2.5000031717341824

Epoch: 6| Step: 5
Training loss: 2.8021510138486185
Validation loss: 2.492809235459767

Epoch: 6| Step: 6
Training loss: 2.1570521535002167
Validation loss: 2.5735936490861873

Epoch: 6| Step: 7
Training loss: 1.8272251620716355
Validation loss: 2.651827169858224

Epoch: 6| Step: 8
Training loss: 3.2594724675323707
Validation loss: 2.67887493130992

Epoch: 6| Step: 9
Training loss: 1.9850830256781324
Validation loss: 2.6885647344687653

Epoch: 6| Step: 10
Training loss: 2.289968890516037
Validation loss: 2.649274897846994

Epoch: 6| Step: 11
Training loss: 2.0169909676239413
Validation loss: 2.562404709331534

Epoch: 6| Step: 12
Training loss: 2.2210845485500683
Validation loss: 2.521828612496793

Epoch: 6| Step: 13
Training loss: 2.3332956742471995
Validation loss: 2.489601112192744

Epoch: 177| Step: 0
Training loss: 1.7594392158348435
Validation loss: 2.478644434861424

Epoch: 6| Step: 1
Training loss: 1.9739366058791101
Validation loss: 2.4637781601285313

Epoch: 6| Step: 2
Training loss: 2.566656695590117
Validation loss: 2.478795919791588

Epoch: 6| Step: 3
Training loss: 1.9487412351321858
Validation loss: 2.499520434764401

Epoch: 6| Step: 4
Training loss: 2.046010074892717
Validation loss: 2.5517440275679037

Epoch: 6| Step: 5
Training loss: 1.9716334949238572
Validation loss: 2.5779289382360884

Epoch: 6| Step: 6
Training loss: 2.749963066546641
Validation loss: 2.6175531681950064

Epoch: 6| Step: 7
Training loss: 1.8781178301326849
Validation loss: 2.6553027583117497

Epoch: 6| Step: 8
Training loss: 2.226349187972792
Validation loss: 2.6175800556201616

Epoch: 6| Step: 9
Training loss: 2.2577799758416504
Validation loss: 2.5977829833090986

Epoch: 6| Step: 10
Training loss: 2.0161403026881066
Validation loss: 2.57941800952552

Epoch: 6| Step: 11
Training loss: 2.5535557657803745
Validation loss: 2.5953564018890583

Epoch: 6| Step: 12
Training loss: 2.9006761814920825
Validation loss: 2.6141968867104253

Epoch: 6| Step: 13
Training loss: 2.147707395475368
Validation loss: 2.6413147679492615

Epoch: 178| Step: 0
Training loss: 1.540825545623283
Validation loss: 2.676736906848374

Epoch: 6| Step: 1
Training loss: 1.8395997227780738
Validation loss: 2.715096133064068

Epoch: 6| Step: 2
Training loss: 2.117341433626498
Validation loss: 2.6666178397610203

Epoch: 6| Step: 3
Training loss: 1.843249818877151
Validation loss: 2.6257581031175654

Epoch: 6| Step: 4
Training loss: 2.3426364542200364
Validation loss: 2.602224152328496

Epoch: 6| Step: 5
Training loss: 2.6863296089428976
Validation loss: 2.586937261785606

Epoch: 6| Step: 6
Training loss: 2.0511220884919097
Validation loss: 2.5636926352229668

Epoch: 6| Step: 7
Training loss: 2.0389656833157486
Validation loss: 2.5584269682416316

Epoch: 6| Step: 8
Training loss: 1.987825412621348
Validation loss: 2.554381323440289

Epoch: 6| Step: 9
Training loss: 1.908996479580702
Validation loss: 2.5333177392260517

Epoch: 6| Step: 10
Training loss: 2.375610875321298
Validation loss: 2.5731197192526483

Epoch: 6| Step: 11
Training loss: 2.746621050070065
Validation loss: 2.581396366804295

Epoch: 6| Step: 12
Training loss: 2.5368924771364982
Validation loss: 2.5667584268872816

Epoch: 6| Step: 13
Training loss: 2.241635244591256
Validation loss: 2.570752231886724

Epoch: 179| Step: 0
Training loss: 1.2805671733201394
Validation loss: 2.572426604354577

Epoch: 6| Step: 1
Training loss: 1.637661318804359
Validation loss: 2.574243677024725

Epoch: 6| Step: 2
Training loss: 2.235936826096706
Validation loss: 2.6261282457743906

Epoch: 6| Step: 3
Training loss: 2.139588487935257
Validation loss: 2.615751073282083

Epoch: 6| Step: 4
Training loss: 2.335039763673632
Validation loss: 2.604275404762097

Epoch: 6| Step: 5
Training loss: 2.071697189503118
Validation loss: 2.5840796600954956

Epoch: 6| Step: 6
Training loss: 2.448228748529629
Validation loss: 2.5615818620845543

Epoch: 6| Step: 7
Training loss: 1.920102985024177
Validation loss: 2.588864379133151

Epoch: 6| Step: 8
Training loss: 2.023719561738481
Validation loss: 2.559053198317832

Epoch: 6| Step: 9
Training loss: 2.3162685308317315
Validation loss: 2.574734441283345

Epoch: 6| Step: 10
Training loss: 2.544404311698831
Validation loss: 2.5887442037261685

Epoch: 6| Step: 11
Training loss: 2.4357182764405
Validation loss: 2.5759067790994705

Epoch: 6| Step: 12
Training loss: 2.3098104146469094
Validation loss: 2.6071525778479963

Epoch: 6| Step: 13
Training loss: 2.1512983660051472
Validation loss: 2.604775376253005

Epoch: 180| Step: 0
Training loss: 2.74222818980228
Validation loss: 2.620283837806499

Epoch: 6| Step: 1
Training loss: 1.8770513756925078
Validation loss: 2.62770099624699

Epoch: 6| Step: 2
Training loss: 2.1049357856143875
Validation loss: 2.6335638773109795

Epoch: 6| Step: 3
Training loss: 1.689653223789603
Validation loss: 2.641393871034331

Epoch: 6| Step: 4
Training loss: 2.150435860389339
Validation loss: 2.659983694538674

Epoch: 6| Step: 5
Training loss: 2.6250989986098507
Validation loss: 2.6478256548289134

Epoch: 6| Step: 6
Training loss: 2.5806092286684685
Validation loss: 2.694308342171063

Epoch: 6| Step: 7
Training loss: 2.031425233765003
Validation loss: 2.717079113082124

Epoch: 6| Step: 8
Training loss: 2.513754202347424
Validation loss: 2.708192424721349

Epoch: 6| Step: 9
Training loss: 1.4488938782335614
Validation loss: 2.6929643191590387

Epoch: 6| Step: 10
Training loss: 1.930797798028405
Validation loss: 2.622633395064159

Epoch: 6| Step: 11
Training loss: 1.4807487766480436
Validation loss: 2.5791947766450236

Epoch: 6| Step: 12
Training loss: 2.095214217894191
Validation loss: 2.5332429232059503

Epoch: 6| Step: 13
Training loss: 2.3172966980878806
Validation loss: 2.5329527481067564

Epoch: 181| Step: 0
Training loss: 2.1282320687448157
Validation loss: 2.5016776260124227

Epoch: 6| Step: 1
Training loss: 1.891467387532107
Validation loss: 2.5483605145378645

Epoch: 6| Step: 2
Training loss: 1.749177194351324
Validation loss: 2.5876610334714423

Epoch: 6| Step: 3
Training loss: 2.1280488973893847
Validation loss: 2.6305679924992766

Epoch: 6| Step: 4
Training loss: 2.3795379651802944
Validation loss: 2.6291423055875125

Epoch: 6| Step: 5
Training loss: 2.4617002243754094
Validation loss: 2.646422951167917

Epoch: 6| Step: 6
Training loss: 2.2999085615475003
Validation loss: 2.591627959617955

Epoch: 6| Step: 7
Training loss: 2.5657454616874844
Validation loss: 2.567464018676222

Epoch: 6| Step: 8
Training loss: 1.629080929983952
Validation loss: 2.573460103083451

Epoch: 6| Step: 9
Training loss: 2.3923040739093886
Validation loss: 2.6062583582272354

Epoch: 6| Step: 10
Training loss: 1.7135229911675436
Validation loss: 2.6419530263091446

Epoch: 6| Step: 11
Training loss: 1.7206391096385307
Validation loss: 2.6536200700438486

Epoch: 6| Step: 12
Training loss: 2.435492838464309
Validation loss: 2.6972295643410145

Epoch: 6| Step: 13
Training loss: 2.0817825140174815
Validation loss: 2.6707150495408514

Epoch: 182| Step: 0
Training loss: 1.6983244548611707
Validation loss: 2.6726346248512214

Epoch: 6| Step: 1
Training loss: 2.3250638563349515
Validation loss: 2.63403799102903

Epoch: 6| Step: 2
Training loss: 1.2978424691943011
Validation loss: 2.610197572653923

Epoch: 6| Step: 3
Training loss: 1.9684492820075863
Validation loss: 2.6168235715567354

Epoch: 6| Step: 4
Training loss: 2.129138058982212
Validation loss: 2.5972805376013253

Epoch: 6| Step: 5
Training loss: 1.8307226261403733
Validation loss: 2.6144205129380405

Epoch: 6| Step: 6
Training loss: 2.590566128750942
Validation loss: 2.6444602900198912

Epoch: 6| Step: 7
Training loss: 1.9261734197545013
Validation loss: 2.672265476722709

Epoch: 6| Step: 8
Training loss: 2.2226367272456535
Validation loss: 2.6862090688356863

Epoch: 6| Step: 9
Training loss: 2.4889457450155197
Validation loss: 2.704131180565974

Epoch: 6| Step: 10
Training loss: 2.352155946388413
Validation loss: 2.7428670482385225

Epoch: 6| Step: 11
Training loss: 2.2937436719594038
Validation loss: 2.710881345788557

Epoch: 6| Step: 12
Training loss: 1.7260038412765246
Validation loss: 2.6605579734903424

Epoch: 6| Step: 13
Training loss: 2.359173292417754
Validation loss: 2.5852868404403586

Epoch: 183| Step: 0
Training loss: 2.0511899704317504
Validation loss: 2.5164595732723165

Epoch: 6| Step: 1
Training loss: 1.981267643798822
Validation loss: 2.4677454320861507

Epoch: 6| Step: 2
Training loss: 2.079234923909497
Validation loss: 2.469090717169487

Epoch: 6| Step: 3
Training loss: 1.0257006367300132
Validation loss: 2.482677087696229

Epoch: 6| Step: 4
Training loss: 3.002339881102357
Validation loss: 2.558230735152764

Epoch: 6| Step: 5
Training loss: 2.393696924323365
Validation loss: 2.5919474616968743

Epoch: 6| Step: 6
Training loss: 2.0836429620172603
Validation loss: 2.6526041570729224

Epoch: 6| Step: 7
Training loss: 2.4646704079301482
Validation loss: 2.7123069282019956

Epoch: 6| Step: 8
Training loss: 2.0061866916638347
Validation loss: 2.7451162704187415

Epoch: 6| Step: 9
Training loss: 2.099594158738467
Validation loss: 2.7810653509086976

Epoch: 6| Step: 10
Training loss: 1.7855619474553897
Validation loss: 2.7951673146804557

Epoch: 6| Step: 11
Training loss: 2.0997205412067985
Validation loss: 2.741177843536346

Epoch: 6| Step: 12
Training loss: 2.158072323524968
Validation loss: 2.699227202951777

Epoch: 6| Step: 13
Training loss: 1.8409587615790628
Validation loss: 2.6372478704990083

Epoch: 184| Step: 0
Training loss: 1.9320122927280559
Validation loss: 2.627761503573308

Epoch: 6| Step: 1
Training loss: 2.1363985982944937
Validation loss: 2.628347068750367

Epoch: 6| Step: 2
Training loss: 1.8108880339902769
Validation loss: 2.626084488954167

Epoch: 6| Step: 3
Training loss: 2.1366501261903568
Validation loss: 2.6283786904225677

Epoch: 6| Step: 4
Training loss: 1.970935153817649
Validation loss: 2.6319434790362783

Epoch: 6| Step: 5
Training loss: 2.1928638635659308
Validation loss: 2.679999116302979

Epoch: 6| Step: 6
Training loss: 2.271750122164344
Validation loss: 2.7185308443291447

Epoch: 6| Step: 7
Training loss: 1.5348532185907577
Validation loss: 2.754801303596313

Epoch: 6| Step: 8
Training loss: 2.0424881145453653
Validation loss: 2.7517685689413987

Epoch: 6| Step: 9
Training loss: 2.0042562495121468
Validation loss: 2.7504170960064784

Epoch: 6| Step: 10
Training loss: 2.4514352603761393
Validation loss: 2.7008538635858486

Epoch: 6| Step: 11
Training loss: 2.2838080708554287
Validation loss: 2.66693992970727

Epoch: 6| Step: 12
Training loss: 2.4162046933650423
Validation loss: 2.618954497694015

Epoch: 6| Step: 13
Training loss: 2.310349779275878
Validation loss: 2.573103566925137

Epoch: 185| Step: 0
Training loss: 1.693570978479842
Validation loss: 2.558831200457858

Epoch: 6| Step: 1
Training loss: 2.3617048065652217
Validation loss: 2.5325094361413845

Epoch: 6| Step: 2
Training loss: 2.428340918957398
Validation loss: 2.520019107540421

Epoch: 6| Step: 3
Training loss: 2.212299695619313
Validation loss: 2.5548806342176995

Epoch: 6| Step: 4
Training loss: 1.9681256227561956
Validation loss: 2.546383002234263

Epoch: 6| Step: 5
Training loss: 2.5365195348563763
Validation loss: 2.5716407940069983

Epoch: 6| Step: 6
Training loss: 2.324453954255778
Validation loss: 2.6128803592346213

Epoch: 6| Step: 7
Training loss: 1.7338925627145603
Validation loss: 2.6454458039288133

Epoch: 6| Step: 8
Training loss: 1.678241621969681
Validation loss: 2.66663560990225

Epoch: 6| Step: 9
Training loss: 2.0929868075797518
Validation loss: 2.701574081820916

Epoch: 6| Step: 10
Training loss: 1.7725374735972146
Validation loss: 2.6739312236575286

Epoch: 6| Step: 11
Training loss: 1.9060156005829352
Validation loss: 2.6767295273863607

Epoch: 6| Step: 12
Training loss: 1.8449916214998217
Validation loss: 2.6378981395084313

Epoch: 6| Step: 13
Training loss: 2.3193466282648347
Validation loss: 2.623264744634595

Epoch: 186| Step: 0
Training loss: 1.938294955185544
Validation loss: 2.6306001059328867

Epoch: 6| Step: 1
Training loss: 1.715443916700457
Validation loss: 2.67703170187116

Epoch: 6| Step: 2
Training loss: 2.490333944087855
Validation loss: 2.727081652769043

Epoch: 6| Step: 3
Training loss: 2.4632547761248835
Validation loss: 2.7438076821161888

Epoch: 6| Step: 4
Training loss: 2.7495017900865175
Validation loss: 2.7060632308878563

Epoch: 6| Step: 5
Training loss: 1.0308342297816613
Validation loss: 2.660344327387588

Epoch: 6| Step: 6
Training loss: 1.9044931789845896
Validation loss: 2.5756999085576466

Epoch: 6| Step: 7
Training loss: 1.3055044117958563
Validation loss: 2.5164829188157616

Epoch: 6| Step: 8
Training loss: 2.0158063230351586
Validation loss: 2.544957561319996

Epoch: 6| Step: 9
Training loss: 2.4932239254833366
Validation loss: 2.545533141367862

Epoch: 6| Step: 10
Training loss: 2.296292289464912
Validation loss: 2.5830610854924703

Epoch: 6| Step: 11
Training loss: 2.606313039625605
Validation loss: 2.5771344093756943

Epoch: 6| Step: 12
Training loss: 1.1152136378189135
Validation loss: 2.635916767549064

Epoch: 6| Step: 13
Training loss: 1.8774360091152917
Validation loss: 2.696115520093431

Epoch: 187| Step: 0
Training loss: 2.399095972982187
Validation loss: 2.7131500922116287

Epoch: 6| Step: 1
Training loss: 2.0583857335307516
Validation loss: 2.7029693784438122

Epoch: 6| Step: 2
Training loss: 2.55814605756416
Validation loss: 2.633643460447437

Epoch: 6| Step: 3
Training loss: 2.0308236481638198
Validation loss: 2.5849414534633137

Epoch: 6| Step: 4
Training loss: 1.9095700852646702
Validation loss: 2.5155095725054206

Epoch: 6| Step: 5
Training loss: 1.8523317179777798
Validation loss: 2.5090100553304353

Epoch: 6| Step: 6
Training loss: 1.9563126453448232
Validation loss: 2.5182824390964207

Epoch: 6| Step: 7
Training loss: 2.43238215036516
Validation loss: 2.5551445915754587

Epoch: 6| Step: 8
Training loss: 2.214832985396019
Validation loss: 2.586105955351309

Epoch: 6| Step: 9
Training loss: 2.23943476221104
Validation loss: 2.6054714784809154

Epoch: 6| Step: 10
Training loss: 1.811373525004885
Validation loss: 2.6371466614158168

Epoch: 6| Step: 11
Training loss: 1.5758361080608554
Validation loss: 2.6644923895037285

Epoch: 6| Step: 12
Training loss: 1.3622489452921536
Validation loss: 2.675444021128079

Epoch: 6| Step: 13
Training loss: 1.9986373908770425
Validation loss: 2.6914689303952777

Epoch: 188| Step: 0
Training loss: 1.681030800863428
Validation loss: 2.70399816170618

Epoch: 6| Step: 1
Training loss: 1.7127288080768885
Validation loss: 2.7003365599343474

Epoch: 6| Step: 2
Training loss: 2.3361052896208117
Validation loss: 2.690356896466537

Epoch: 6| Step: 3
Training loss: 2.24422922781193
Validation loss: 2.6693167061494347

Epoch: 6| Step: 4
Training loss: 1.9057687871177849
Validation loss: 2.6267970829162963

Epoch: 6| Step: 5
Training loss: 1.977105469440738
Validation loss: 2.62831861087089

Epoch: 6| Step: 6
Training loss: 1.9915899240666792
Validation loss: 2.6220115413202603

Epoch: 6| Step: 7
Training loss: 1.9461912445431213
Validation loss: 2.619504280468111

Epoch: 6| Step: 8
Training loss: 1.5905052514707565
Validation loss: 2.6329472272638874

Epoch: 6| Step: 9
Training loss: 1.8974006238805872
Validation loss: 2.684796543938498

Epoch: 6| Step: 10
Training loss: 2.32906941965504
Validation loss: 2.687695564085743

Epoch: 6| Step: 11
Training loss: 1.463802689956714
Validation loss: 2.694366814208587

Epoch: 6| Step: 12
Training loss: 2.0823633097361642
Validation loss: 2.667273784624217

Epoch: 6| Step: 13
Training loss: 3.018897144214455
Validation loss: 2.6953547097078885

Epoch: 189| Step: 0
Training loss: 2.4457952735794692
Validation loss: 2.706879307034447

Epoch: 6| Step: 1
Training loss: 1.866905350695423
Validation loss: 2.6953332083110024

Epoch: 6| Step: 2
Training loss: 2.0746488251021082
Validation loss: 2.623927326453392

Epoch: 6| Step: 3
Training loss: 1.749960830795083
Validation loss: 2.6022622959721047

Epoch: 6| Step: 4
Training loss: 2.0751829043746692
Validation loss: 2.5783850077916126

Epoch: 6| Step: 5
Training loss: 2.3137996217753565
Validation loss: 2.578792189613731

Epoch: 6| Step: 6
Training loss: 1.713754712188052
Validation loss: 2.5832078693526617

Epoch: 6| Step: 7
Training loss: 2.0107087497978595
Validation loss: 2.6405962705642128

Epoch: 6| Step: 8
Training loss: 1.705637137767172
Validation loss: 2.6404944936927985

Epoch: 6| Step: 9
Training loss: 2.0379898933332248
Validation loss: 2.6429739679721638

Epoch: 6| Step: 10
Training loss: 1.7532450017810237
Validation loss: 2.681996178810748

Epoch: 6| Step: 11
Training loss: 1.9176154345365886
Validation loss: 2.7061767972154795

Epoch: 6| Step: 12
Training loss: 1.8234638228555398
Validation loss: 2.727298963258351

Epoch: 6| Step: 13
Training loss: 2.0537956826161206
Validation loss: 2.694936185381061

Epoch: 190| Step: 0
Training loss: 1.7585848319574453
Validation loss: 2.6781704735277696

Epoch: 6| Step: 1
Training loss: 2.148905311284151
Validation loss: 2.619893999575441

Epoch: 6| Step: 2
Training loss: 2.1661664189648215
Validation loss: 2.5999617370270003

Epoch: 6| Step: 3
Training loss: 2.500592161619412
Validation loss: 2.574929461940224

Epoch: 6| Step: 4
Training loss: 1.6800417504345315
Validation loss: 2.5694211068756903

Epoch: 6| Step: 5
Training loss: 1.869957182490916
Validation loss: 2.600090310206096

Epoch: 6| Step: 6
Training loss: 2.1465490190874315
Validation loss: 2.62689265663301

Epoch: 6| Step: 7
Training loss: 1.2859640162759673
Validation loss: 2.6995286359546773

Epoch: 6| Step: 8
Training loss: 2.734052540975386
Validation loss: 2.685823748175603

Epoch: 6| Step: 9
Training loss: 1.8762120461993272
Validation loss: 2.70008751800662

Epoch: 6| Step: 10
Training loss: 1.5285182641872022
Validation loss: 2.7155964833963377

Epoch: 6| Step: 11
Training loss: 1.4194682785956187
Validation loss: 2.7411318876601833

Epoch: 6| Step: 12
Training loss: 1.9703549700401795
Validation loss: 2.7388617157330883

Epoch: 6| Step: 13
Training loss: 2.157464500833601
Validation loss: 2.6533527109528197

Epoch: 191| Step: 0
Training loss: 1.9961147717826513
Validation loss: 2.5887830411300827

Epoch: 6| Step: 1
Training loss: 2.292039309172882
Validation loss: 2.5501668444779577

Epoch: 6| Step: 2
Training loss: 2.0190783348814616
Validation loss: 2.5396597054681305

Epoch: 6| Step: 3
Training loss: 1.5871339991821305
Validation loss: 2.5319185740021446

Epoch: 6| Step: 4
Training loss: 1.7883761226207655
Validation loss: 2.5452416841811645

Epoch: 6| Step: 5
Training loss: 1.5476709495127503
Validation loss: 2.5926274236202085

Epoch: 6| Step: 6
Training loss: 2.6632896935711527
Validation loss: 2.6818552391929456

Epoch: 6| Step: 7
Training loss: 1.8666352289254589
Validation loss: 2.749602676916127

Epoch: 6| Step: 8
Training loss: 2.1905377684896106
Validation loss: 2.806503873615946

Epoch: 6| Step: 9
Training loss: 1.6188019143988939
Validation loss: 2.7363320599385146

Epoch: 6| Step: 10
Training loss: 1.531030600263787
Validation loss: 2.6982518900579175

Epoch: 6| Step: 11
Training loss: 2.58489471339188
Validation loss: 2.6593536717354276

Epoch: 6| Step: 12
Training loss: 2.0126782545674535
Validation loss: 2.59047989203051

Epoch: 6| Step: 13
Training loss: 1.7139497481672423
Validation loss: 2.585394959254813

Epoch: 192| Step: 0
Training loss: 1.879226118050963
Validation loss: 2.5479340884364055

Epoch: 6| Step: 1
Training loss: 1.3507255211757876
Validation loss: 2.5737608445187936

Epoch: 6| Step: 2
Training loss: 2.8800066600828518
Validation loss: 2.6021682382415676

Epoch: 6| Step: 3
Training loss: 1.9994681962601544
Validation loss: 2.5850347872709034

Epoch: 6| Step: 4
Training loss: 1.5516247509226517
Validation loss: 2.6081347849698537

Epoch: 6| Step: 5
Training loss: 1.507003962703322
Validation loss: 2.6215984843374205

Epoch: 6| Step: 6
Training loss: 1.8668544583999194
Validation loss: 2.6612324148088478

Epoch: 6| Step: 7
Training loss: 1.9371090156076372
Validation loss: 2.662782331594572

Epoch: 6| Step: 8
Training loss: 2.255025549361134
Validation loss: 2.6717845817733337

Epoch: 6| Step: 9
Training loss: 1.810288757558359
Validation loss: 2.6430141191562813

Epoch: 6| Step: 10
Training loss: 2.4722225055861102
Validation loss: 2.6438599021509113

Epoch: 6| Step: 11
Training loss: 1.3782004908777696
Validation loss: 2.6196903833914527

Epoch: 6| Step: 12
Training loss: 1.8651663722878655
Validation loss: 2.637560873452279

Epoch: 6| Step: 13
Training loss: 2.316634631678702
Validation loss: 2.656161885546339

Epoch: 193| Step: 0
Training loss: 2.151273319310836
Validation loss: 2.634142244127951

Epoch: 6| Step: 1
Training loss: 1.8994802115329148
Validation loss: 2.645991008602355

Epoch: 6| Step: 2
Training loss: 1.8156722359741995
Validation loss: 2.649193505339785

Epoch: 6| Step: 3
Training loss: 2.0860405942893223
Validation loss: 2.648148059410724

Epoch: 6| Step: 4
Training loss: 2.3478459489446037
Validation loss: 2.637248938825016

Epoch: 6| Step: 5
Training loss: 1.9946462978319213
Validation loss: 2.653231057218803

Epoch: 6| Step: 6
Training loss: 1.9610703867837498
Validation loss: 2.635679333478235

Epoch: 6| Step: 7
Training loss: 1.694985213088631
Validation loss: 2.6439635788899905

Epoch: 6| Step: 8
Training loss: 2.157865499609347
Validation loss: 2.6215835973536743

Epoch: 6| Step: 9
Training loss: 1.8006454714478985
Validation loss: 2.6358859229579865

Epoch: 6| Step: 10
Training loss: 1.79561511113026
Validation loss: 2.662995051419634

Epoch: 6| Step: 11
Training loss: 2.0121754544545256
Validation loss: 2.635175210836211

Epoch: 6| Step: 12
Training loss: 1.7961056596478104
Validation loss: 2.58901163603841

Epoch: 6| Step: 13
Training loss: 1.2053843005718652
Validation loss: 2.5767170581406655

Epoch: 194| Step: 0
Training loss: 1.5424750588501204
Validation loss: 2.524064588333777

Epoch: 6| Step: 1
Training loss: 1.8294385445847794
Validation loss: 2.5302482637258357

Epoch: 6| Step: 2
Training loss: 2.346365727866449
Validation loss: 2.5849077730861243

Epoch: 6| Step: 3
Training loss: 1.873373661433018
Validation loss: 2.573880502365839

Epoch: 6| Step: 4
Training loss: 1.4805412979266512
Validation loss: 2.6368955428186682

Epoch: 6| Step: 5
Training loss: 1.5646455148801268
Validation loss: 2.6943083773766485

Epoch: 6| Step: 6
Training loss: 2.241263701040129
Validation loss: 2.765538683277124

Epoch: 6| Step: 7
Training loss: 2.119479694576057
Validation loss: 2.741514958490832

Epoch: 6| Step: 8
Training loss: 2.4254863762505354
Validation loss: 2.6918120593312365

Epoch: 6| Step: 9
Training loss: 2.278791278375264
Validation loss: 2.5991573235778174

Epoch: 6| Step: 10
Training loss: 2.0236162379204323
Validation loss: 2.557097370454106

Epoch: 6| Step: 11
Training loss: 2.0376589098786413
Validation loss: 2.51455854708222

Epoch: 6| Step: 12
Training loss: 1.3156361124108524
Validation loss: 2.4863188647180636

Epoch: 6| Step: 13
Training loss: 1.323326237673117
Validation loss: 2.514135061272426

Epoch: 195| Step: 0
Training loss: 2.513425635642185
Validation loss: 2.503130369093716

Epoch: 6| Step: 1
Training loss: 1.839903488323231
Validation loss: 2.536115663433432

Epoch: 6| Step: 2
Training loss: 2.045038112481096
Validation loss: 2.549930569795144

Epoch: 6| Step: 3
Training loss: 1.7940934254529612
Validation loss: 2.6024155515708975

Epoch: 6| Step: 4
Training loss: 1.8842336269505957
Validation loss: 2.629406173125298

Epoch: 6| Step: 5
Training loss: 1.6217112640463889
Validation loss: 2.677717702929229

Epoch: 6| Step: 6
Training loss: 1.4640033396489975
Validation loss: 2.7085014108103302

Epoch: 6| Step: 7
Training loss: 1.98779308869135
Validation loss: 2.7692452474301006

Epoch: 6| Step: 8
Training loss: 2.150532536756975
Validation loss: 2.764828581583335

Epoch: 6| Step: 9
Training loss: 1.7682265298980095
Validation loss: 2.7323553649303705

Epoch: 6| Step: 10
Training loss: 1.4464912350517942
Validation loss: 2.7029162019295363

Epoch: 6| Step: 11
Training loss: 1.3552282818150228
Validation loss: 2.6568044355286937

Epoch: 6| Step: 12
Training loss: 2.5457526232157
Validation loss: 2.622862624444785

Epoch: 6| Step: 13
Training loss: 1.9580006282988525
Validation loss: 2.563091416919733

Epoch: 196| Step: 0
Training loss: 1.5255622327645626
Validation loss: 2.5566384570795853

Epoch: 6| Step: 1
Training loss: 1.9731716577996448
Validation loss: 2.540487447240285

Epoch: 6| Step: 2
Training loss: 2.0811479423175325
Validation loss: 2.5501912154492485

Epoch: 6| Step: 3
Training loss: 1.801349012524529
Validation loss: 2.590821219879813

Epoch: 6| Step: 4
Training loss: 1.9423052358502837
Validation loss: 2.631259759636358

Epoch: 6| Step: 5
Training loss: 1.405519168409568
Validation loss: 2.633426058608553

Epoch: 6| Step: 6
Training loss: 1.8582804688032089
Validation loss: 2.6622698540215906

Epoch: 6| Step: 7
Training loss: 1.7196282657082897
Validation loss: 2.672834863808792

Epoch: 6| Step: 8
Training loss: 2.143093940730071
Validation loss: 2.699704347205482

Epoch: 6| Step: 9
Training loss: 1.585192575879824
Validation loss: 2.6978657988057657

Epoch: 6| Step: 10
Training loss: 2.056311947895281
Validation loss: 2.6774632624151575

Epoch: 6| Step: 11
Training loss: 1.963262691630197
Validation loss: 2.6316002063372874

Epoch: 6| Step: 12
Training loss: 1.8045680679501215
Validation loss: 2.596202419885246

Epoch: 6| Step: 13
Training loss: 2.448808407517774
Validation loss: 2.5993079010546793

Epoch: 197| Step: 0
Training loss: 1.5523273438353211
Validation loss: 2.559220136605706

Epoch: 6| Step: 1
Training loss: 1.7115748363675045
Validation loss: 2.5403136154071295

Epoch: 6| Step: 2
Training loss: 1.4953140338503186
Validation loss: 2.5624591074796355

Epoch: 6| Step: 3
Training loss: 2.4418823754477734
Validation loss: 2.588364752291868

Epoch: 6| Step: 4
Training loss: 2.290542696818216
Validation loss: 2.633549169426027

Epoch: 6| Step: 5
Training loss: 1.9982114781866824
Validation loss: 2.638153278545713

Epoch: 6| Step: 6
Training loss: 2.0638684443605997
Validation loss: 2.678790192858206

Epoch: 6| Step: 7
Training loss: 1.6429378374196395
Validation loss: 2.6859540468304575

Epoch: 6| Step: 8
Training loss: 1.4998593264419802
Validation loss: 2.6888133906010214

Epoch: 6| Step: 9
Training loss: 1.716978790401038
Validation loss: 2.661605888344321

Epoch: 6| Step: 10
Training loss: 2.001666804982524
Validation loss: 2.653185955956069

Epoch: 6| Step: 11
Training loss: 1.7312215368912618
Validation loss: 2.6230131893627564

Epoch: 6| Step: 12
Training loss: 1.684057468357947
Validation loss: 2.6092285641766315

Epoch: 6| Step: 13
Training loss: 1.5000499081256182
Validation loss: 2.607345608329453

Epoch: 198| Step: 0
Training loss: 1.546155203378157
Validation loss: 2.605876087558512

Epoch: 6| Step: 1
Training loss: 1.5189450268268745
Validation loss: 2.6194485669029355

Epoch: 6| Step: 2
Training loss: 1.9625614934143438
Validation loss: 2.6316555194449407

Epoch: 6| Step: 3
Training loss: 1.8097084515583508
Validation loss: 2.5998618867395846

Epoch: 6| Step: 4
Training loss: 1.8185531562124366
Validation loss: 2.6034128248966377

Epoch: 6| Step: 5
Training loss: 1.717082792913174
Validation loss: 2.599723428257431

Epoch: 6| Step: 6
Training loss: 1.7393273109974137
Validation loss: 2.5490570736235822

Epoch: 6| Step: 7
Training loss: 2.2266515881300055
Validation loss: 2.5249710231203877

Epoch: 6| Step: 8
Training loss: 2.0183326218863926
Validation loss: 2.549809870467193

Epoch: 6| Step: 9
Training loss: 1.773158988425187
Validation loss: 2.560821577789263

Epoch: 6| Step: 10
Training loss: 1.7524765746636595
Validation loss: 2.5741646167933387

Epoch: 6| Step: 11
Training loss: 1.7524462359965836
Validation loss: 2.606744061923935

Epoch: 6| Step: 12
Training loss: 1.9107051754926554
Validation loss: 2.6673098494773204

Epoch: 6| Step: 13
Training loss: 1.8678936760150056
Validation loss: 2.726698670608501

Epoch: 199| Step: 0
Training loss: 2.291257671503605
Validation loss: 2.7310983234026054

Epoch: 6| Step: 1
Training loss: 1.8345996283746748
Validation loss: 2.763344084318497

Epoch: 6| Step: 2
Training loss: 2.1310459967830995
Validation loss: 2.794237934132911

Epoch: 6| Step: 3
Training loss: 1.6929886179956561
Validation loss: 2.7877123083005158

Epoch: 6| Step: 4
Training loss: 2.126284043063652
Validation loss: 2.7825211950567197

Epoch: 6| Step: 5
Training loss: 1.16027800566515
Validation loss: 2.7500891554504547

Epoch: 6| Step: 6
Training loss: 1.789939565437532
Validation loss: 2.714106578283482

Epoch: 6| Step: 7
Training loss: 1.2842028945740518
Validation loss: 2.670278616684679

Epoch: 6| Step: 8
Training loss: 1.4039440321893246
Validation loss: 2.6312827491568545

Epoch: 6| Step: 9
Training loss: 1.663530148167903
Validation loss: 2.5753969746496503

Epoch: 6| Step: 10
Training loss: 1.5109774721335743
Validation loss: 2.5619418248872226

Epoch: 6| Step: 11
Training loss: 2.402119646241802
Validation loss: 2.5375739144568743

Epoch: 6| Step: 12
Training loss: 1.4809389198169234
Validation loss: 2.5075271132782917

Epoch: 6| Step: 13
Training loss: 1.7054047331806834
Validation loss: 2.545343836279719

Epoch: 200| Step: 0
Training loss: 1.9104595294610394
Validation loss: 2.5025085194990053

Epoch: 6| Step: 1
Training loss: 1.8501479785606398
Validation loss: 2.534734899789128

Epoch: 6| Step: 2
Training loss: 1.526058973750204
Validation loss: 2.5497577638238607

Epoch: 6| Step: 3
Training loss: 1.627145084995346
Validation loss: 2.5510918893666745

Epoch: 6| Step: 4
Training loss: 1.632484220513206
Validation loss: 2.6301413120700814

Epoch: 6| Step: 5
Training loss: 1.9135699202753775
Validation loss: 2.6882858939723664

Epoch: 6| Step: 6
Training loss: 1.8172295786085007
Validation loss: 2.722052072296129

Epoch: 6| Step: 7
Training loss: 1.7449627996376142
Validation loss: 2.705619895947546

Epoch: 6| Step: 8
Training loss: 1.740374935137816
Validation loss: 2.7383373619232056

Epoch: 6| Step: 9
Training loss: 1.809801065356063
Validation loss: 2.7109383019244033

Epoch: 6| Step: 10
Training loss: 2.1209524539652467
Validation loss: 2.696025178841933

Epoch: 6| Step: 11
Training loss: 1.8828340901130198
Validation loss: 2.6865111866880174

Epoch: 6| Step: 12
Training loss: 1.4377620292350055
Validation loss: 2.656304896328487

Epoch: 6| Step: 13
Training loss: 2.167568960357777
Validation loss: 2.624677840473524

Epoch: 201| Step: 0
Training loss: 1.4236107596213468
Validation loss: 2.633582937377239

Epoch: 6| Step: 1
Training loss: 1.7783790339872405
Validation loss: 2.6208159633575843

Epoch: 6| Step: 2
Training loss: 2.2074663391657423
Validation loss: 2.638119533139482

Epoch: 6| Step: 3
Training loss: 1.7877103535050567
Validation loss: 2.6506855811319094

Epoch: 6| Step: 4
Training loss: 1.7820043472339766
Validation loss: 2.6323033833747065

Epoch: 6| Step: 5
Training loss: 1.8204857739670894
Validation loss: 2.6607061234632545

Epoch: 6| Step: 6
Training loss: 1.7124704260952521
Validation loss: 2.662049916110263

Epoch: 6| Step: 7
Training loss: 2.2179743525859914
Validation loss: 2.666552570681149

Epoch: 6| Step: 8
Training loss: 1.1881087399272596
Validation loss: 2.6473366598460086

Epoch: 6| Step: 9
Training loss: 1.7928856392008625
Validation loss: 2.618016114778377

Epoch: 6| Step: 10
Training loss: 1.9679557166854855
Validation loss: 2.58361960964097

Epoch: 6| Step: 11
Training loss: 1.565467458020633
Validation loss: 2.573478455721971

Epoch: 6| Step: 12
Training loss: 1.5664301463751584
Validation loss: 2.571757418413354

Epoch: 6| Step: 13
Training loss: 1.8533309024456375
Validation loss: 2.565099668563931

Epoch: 202| Step: 0
Training loss: 1.838919048823912
Validation loss: 2.561857420566786

Epoch: 6| Step: 1
Training loss: 2.016506741490482
Validation loss: 2.5716940851514845

Epoch: 6| Step: 2
Training loss: 1.5121656442360771
Validation loss: 2.547614797366303

Epoch: 6| Step: 3
Training loss: 1.4767328396186477
Validation loss: 2.610569423693488

Epoch: 6| Step: 4
Training loss: 1.7677900155714346
Validation loss: 2.6245863725824337

Epoch: 6| Step: 5
Training loss: 1.4486234115577394
Validation loss: 2.642614654940212

Epoch: 6| Step: 6
Training loss: 1.4960331917002863
Validation loss: 2.674017968340057

Epoch: 6| Step: 7
Training loss: 1.0299014319319808
Validation loss: 2.6529216666844753

Epoch: 6| Step: 8
Training loss: 1.7956731342751304
Validation loss: 2.6855432484472703

Epoch: 6| Step: 9
Training loss: 1.9223706606451263
Validation loss: 2.661228390019951

Epoch: 6| Step: 10
Training loss: 1.7794530404291795
Validation loss: 2.6650487955162805

Epoch: 6| Step: 11
Training loss: 2.146588226666228
Validation loss: 2.6541676001955135

Epoch: 6| Step: 12
Training loss: 1.7382036170339825
Validation loss: 2.6376963874482517

Epoch: 6| Step: 13
Training loss: 2.3111821105129993
Validation loss: 2.6456965000180244

Epoch: 203| Step: 0
Training loss: 1.9302467431578367
Validation loss: 2.6184238638881507

Epoch: 6| Step: 1
Training loss: 2.020067272954533
Validation loss: 2.600235653603134

Epoch: 6| Step: 2
Training loss: 1.5003117396347385
Validation loss: 2.6175490233562724

Epoch: 6| Step: 3
Training loss: 1.620517931783933
Validation loss: 2.6174913690658235

Epoch: 6| Step: 4
Training loss: 1.5616782507098683
Validation loss: 2.6418979603364927

Epoch: 6| Step: 5
Training loss: 1.6281313436607912
Validation loss: 2.6704292101304943

Epoch: 6| Step: 6
Training loss: 1.8427850816901588
Validation loss: 2.698804268352542

Epoch: 6| Step: 7
Training loss: 1.5946791689126425
Validation loss: 2.7029962688623015

Epoch: 6| Step: 8
Training loss: 1.454992427478499
Validation loss: 2.714732422651953

Epoch: 6| Step: 9
Training loss: 1.6815800849747948
Validation loss: 2.7381460982594934

Epoch: 6| Step: 10
Training loss: 1.86201296333283
Validation loss: 2.683948258008033

Epoch: 6| Step: 11
Training loss: 1.4908510784431463
Validation loss: 2.6568859547877772

Epoch: 6| Step: 12
Training loss: 2.479403337567197
Validation loss: 2.5806660688166048

Epoch: 6| Step: 13
Training loss: 1.4826244271154014
Validation loss: 2.5775484764860774

Epoch: 204| Step: 0
Training loss: 1.7900420593136739
Validation loss: 2.563017104922551

Epoch: 6| Step: 1
Training loss: 2.0681356249594267
Validation loss: 2.571735350188923

Epoch: 6| Step: 2
Training loss: 1.9759539847325072
Validation loss: 2.6347816814827705

Epoch: 6| Step: 3
Training loss: 1.9259374218615297
Validation loss: 2.6081878966220864

Epoch: 6| Step: 4
Training loss: 1.0710498469708822
Validation loss: 2.623399680304643

Epoch: 6| Step: 5
Training loss: 1.217228893903235
Validation loss: 2.6234003135436206

Epoch: 6| Step: 6
Training loss: 1.5734700961936718
Validation loss: 2.668420294496855

Epoch: 6| Step: 7
Training loss: 1.9183838933031525
Validation loss: 2.6791403951077513

Epoch: 6| Step: 8
Training loss: 2.1074331882516075
Validation loss: 2.6856276010441635

Epoch: 6| Step: 9
Training loss: 1.4088458368286656
Validation loss: 2.7245779339622898

Epoch: 6| Step: 10
Training loss: 1.166911945217869
Validation loss: 2.6898033609951364

Epoch: 6| Step: 11
Training loss: 1.7691022677147363
Validation loss: 2.664025838814569

Epoch: 6| Step: 12
Training loss: 1.6727717481324516
Validation loss: 2.652211283961931

Epoch: 6| Step: 13
Training loss: 1.8304245660572185
Validation loss: 2.633262131658951

Epoch: 205| Step: 0
Training loss: 1.5499737460466347
Validation loss: 2.6256601950771583

Epoch: 6| Step: 1
Training loss: 1.811245517027515
Validation loss: 2.581661263448993

Epoch: 6| Step: 2
Training loss: 1.274434641237108
Validation loss: 2.581841859621222

Epoch: 6| Step: 3
Training loss: 1.402098227767091
Validation loss: 2.610740567110762

Epoch: 6| Step: 4
Training loss: 1.6360869360351895
Validation loss: 2.607962866495789

Epoch: 6| Step: 5
Training loss: 2.197770992230435
Validation loss: 2.6212197403652655

Epoch: 6| Step: 6
Training loss: 1.881691753444349
Validation loss: 2.5915618029976986

Epoch: 6| Step: 7
Training loss: 1.9903639881280049
Validation loss: 2.6564253853521906

Epoch: 6| Step: 8
Training loss: 1.7940243873342006
Validation loss: 2.644197599956074

Epoch: 6| Step: 9
Training loss: 2.0262311701337974
Validation loss: 2.64562845506738

Epoch: 6| Step: 10
Training loss: 1.3281647620139385
Validation loss: 2.6199107861760496

Epoch: 6| Step: 11
Training loss: 1.386557642214822
Validation loss: 2.6197124009201795

Epoch: 6| Step: 12
Training loss: 1.003908149925245
Validation loss: 2.64419184285431

Epoch: 6| Step: 13
Training loss: 1.8694339151386654
Validation loss: 2.6317167326909496

Epoch: 206| Step: 0
Training loss: 1.4930628261339853
Validation loss: 2.623164956035062

Epoch: 6| Step: 1
Training loss: 1.7707918573645984
Validation loss: 2.6375034374243236

Epoch: 6| Step: 2
Training loss: 1.6246173848355758
Validation loss: 2.629649794876737

Epoch: 6| Step: 3
Training loss: 1.550643799501397
Validation loss: 2.6414561542752764

Epoch: 6| Step: 4
Training loss: 1.8473457575563448
Validation loss: 2.639298518162106

Epoch: 6| Step: 5
Training loss: 1.128777730945422
Validation loss: 2.6148771395395403

Epoch: 6| Step: 6
Training loss: 2.074300358490517
Validation loss: 2.6287196848206675

Epoch: 6| Step: 7
Training loss: 2.0329356315318754
Validation loss: 2.6082655648389594

Epoch: 6| Step: 8
Training loss: 1.4339010548526079
Validation loss: 2.6301593598483235

Epoch: 6| Step: 9
Training loss: 1.2050040298014644
Validation loss: 2.5886718640667516

Epoch: 6| Step: 10
Training loss: 1.960633577298247
Validation loss: 2.545692403319163

Epoch: 6| Step: 11
Training loss: 1.0044426579644719
Validation loss: 2.5409768162052897

Epoch: 6| Step: 12
Training loss: 1.453720462987736
Validation loss: 2.558543199986848

Epoch: 6| Step: 13
Training loss: 2.765880594457952
Validation loss: 2.592446418336099

Epoch: 207| Step: 0
Training loss: 1.5895122960500914
Validation loss: 2.5686599241796713

Epoch: 6| Step: 1
Training loss: 1.492215780419592
Validation loss: 2.5471139374627114

Epoch: 6| Step: 2
Training loss: 1.4965386189920946
Validation loss: 2.5382895975195927

Epoch: 6| Step: 3
Training loss: 1.743660684574702
Validation loss: 2.5699928958463136

Epoch: 6| Step: 4
Training loss: 1.2542977360687104
Validation loss: 2.5441630822801184

Epoch: 6| Step: 5
Training loss: 1.9547989042814122
Validation loss: 2.5816027590272226

Epoch: 6| Step: 6
Training loss: 1.2946515613883427
Validation loss: 2.6065589958279576

Epoch: 6| Step: 7
Training loss: 1.9958618984952317
Validation loss: 2.602622075588427

Epoch: 6| Step: 8
Training loss: 1.5405555879690946
Validation loss: 2.6091902875449255

Epoch: 6| Step: 9
Training loss: 1.6978264377077374
Validation loss: 2.6620151330745117

Epoch: 6| Step: 10
Training loss: 1.8519262286544176
Validation loss: 2.670082909894216

Epoch: 6| Step: 11
Training loss: 1.7786317287647275
Validation loss: 2.690366225339721

Epoch: 6| Step: 12
Training loss: 1.7411164553901812
Validation loss: 2.6691865855602135

Epoch: 6| Step: 13
Training loss: 1.4657090543219642
Validation loss: 2.643308711293461

Epoch: 208| Step: 0
Training loss: 1.512577256680788
Validation loss: 2.5939769504737575

Epoch: 6| Step: 1
Training loss: 1.7499888283509204
Validation loss: 2.580765070423904

Epoch: 6| Step: 2
Training loss: 1.221268423794607
Validation loss: 2.601519612540796

Epoch: 6| Step: 3
Training loss: 1.8454138796588555
Validation loss: 2.557859699828756

Epoch: 6| Step: 4
Training loss: 1.6519132012616653
Validation loss: 2.6157587237614193

Epoch: 6| Step: 5
Training loss: 1.2102549444332824
Validation loss: 2.597223283249345

Epoch: 6| Step: 6
Training loss: 1.510679375613277
Validation loss: 2.6533721167911986

Epoch: 6| Step: 7
Training loss: 1.591071926800049
Validation loss: 2.686598868749618

Epoch: 6| Step: 8
Training loss: 2.060679933129888
Validation loss: 2.7107523077411693

Epoch: 6| Step: 9
Training loss: 1.7003905016116714
Validation loss: 2.7014845394702367

Epoch: 6| Step: 10
Training loss: 1.7711785671822318
Validation loss: 2.68854722274104

Epoch: 6| Step: 11
Training loss: 1.5375571077487247
Validation loss: 2.627865835926579

Epoch: 6| Step: 12
Training loss: 1.5614298398211295
Validation loss: 2.5927658774006126

Epoch: 6| Step: 13
Training loss: 1.8943288793333042
Validation loss: 2.5736806339028284

Epoch: 209| Step: 0
Training loss: 1.9704532219097455
Validation loss: 2.5665663103328082

Epoch: 6| Step: 1
Training loss: 1.4394464169142798
Validation loss: 2.5852333495349646

Epoch: 6| Step: 2
Training loss: 1.5670693532693225
Validation loss: 2.5780006913202866

Epoch: 6| Step: 3
Training loss: 2.2081790606275447
Validation loss: 2.6017467105046204

Epoch: 6| Step: 4
Training loss: 1.5684361421222361
Validation loss: 2.6282439640455557

Epoch: 6| Step: 5
Training loss: 1.0613135838416303
Validation loss: 2.648423903685646

Epoch: 6| Step: 6
Training loss: 1.4267947422603393
Validation loss: 2.6403727193997475

Epoch: 6| Step: 7
Training loss: 1.31845476723752
Validation loss: 2.6811767790715777

Epoch: 6| Step: 8
Training loss: 1.8405738240561114
Validation loss: 2.6598146054264746

Epoch: 6| Step: 9
Training loss: 1.570387957074263
Validation loss: 2.641211003735844

Epoch: 6| Step: 10
Training loss: 0.9951003562694299
Validation loss: 2.6360256359359977

Epoch: 6| Step: 11
Training loss: 1.7167542401293778
Validation loss: 2.614568158170926

Epoch: 6| Step: 12
Training loss: 1.7642322549834322
Validation loss: 2.573107906901706

Epoch: 6| Step: 13
Training loss: 1.9154026244686548
Validation loss: 2.5435100274425206

Epoch: 210| Step: 0
Training loss: 1.7352446017041891
Validation loss: 2.587189752884024

Epoch: 6| Step: 1
Training loss: 1.5671380443129002
Validation loss: 2.604399041093577

Epoch: 6| Step: 2
Training loss: 1.6502343098126142
Validation loss: 2.660098446526126

Epoch: 6| Step: 3
Training loss: 1.1475131927928615
Validation loss: 2.67806768166126

Epoch: 6| Step: 4
Training loss: 1.1177924592330792
Validation loss: 2.7002424910566627

Epoch: 6| Step: 5
Training loss: 1.75949396032764
Validation loss: 2.659196394814987

Epoch: 6| Step: 6
Training loss: 1.7554155070876536
Validation loss: 2.5866225860327527

Epoch: 6| Step: 7
Training loss: 1.5967550184112187
Validation loss: 2.5684784420753712

Epoch: 6| Step: 8
Training loss: 1.4662759925249007
Validation loss: 2.549350014313282

Epoch: 6| Step: 9
Training loss: 1.3370179386062504
Validation loss: 2.565064608277889

Epoch: 6| Step: 10
Training loss: 1.6903592364408297
Validation loss: 2.5462635926248867

Epoch: 6| Step: 11
Training loss: 1.5016447427795483
Validation loss: 2.5812325293047476

Epoch: 6| Step: 12
Training loss: 2.1339759866995465
Validation loss: 2.603540373934425

Epoch: 6| Step: 13
Training loss: 2.1550635791790356
Validation loss: 2.6425095505696614

Epoch: 211| Step: 0
Training loss: 1.7911346296170967
Validation loss: 2.6956648677263915

Epoch: 6| Step: 1
Training loss: 1.66887181155349
Validation loss: 2.7027959500633947

Epoch: 6| Step: 2
Training loss: 1.5631794024628323
Validation loss: 2.6771927754487206

Epoch: 6| Step: 3
Training loss: 1.5421392214869858
Validation loss: 2.6093901477256396

Epoch: 6| Step: 4
Training loss: 0.7107245576982941
Validation loss: 2.5761809207677495

Epoch: 6| Step: 5
Training loss: 1.8478097347843325
Validation loss: 2.578355636547412

Epoch: 6| Step: 6
Training loss: 1.5215696181191327
Validation loss: 2.538437710887626

Epoch: 6| Step: 7
Training loss: 1.8345840984790232
Validation loss: 2.539698346131265

Epoch: 6| Step: 8
Training loss: 1.7458098519991112
Validation loss: 2.588594164542629

Epoch: 6| Step: 9
Training loss: 1.5949854830377217
Validation loss: 2.577029310909282

Epoch: 6| Step: 10
Training loss: 1.2712160170072402
Validation loss: 2.588888404632898

Epoch: 6| Step: 11
Training loss: 1.6464551242026562
Validation loss: 2.6024625089137565

Epoch: 6| Step: 12
Training loss: 1.6878835454155365
Validation loss: 2.5842287664853982

Epoch: 6| Step: 13
Training loss: 1.5817377265561323
Validation loss: 2.593802403991674

Epoch: 212| Step: 0
Training loss: 1.6446246122919495
Validation loss: 2.597202988028139

Epoch: 6| Step: 1
Training loss: 1.617930366064496
Validation loss: 2.6521043221310046

Epoch: 6| Step: 2
Training loss: 1.5577394826108808
Validation loss: 2.6429795851395377

Epoch: 6| Step: 3
Training loss: 1.506190717488164
Validation loss: 2.635929984881764

Epoch: 6| Step: 4
Training loss: 1.573634794228537
Validation loss: 2.6292153580379916

Epoch: 6| Step: 5
Training loss: 1.5207302197899686
Validation loss: 2.600001891808338

Epoch: 6| Step: 6
Training loss: 1.3053711795928145
Validation loss: 2.5762138823213627

Epoch: 6| Step: 7
Training loss: 1.9426198194314555
Validation loss: 2.546943271571726

Epoch: 6| Step: 8
Training loss: 1.4963802531440702
Validation loss: 2.5346440063296893

Epoch: 6| Step: 9
Training loss: 1.6786382902447174
Validation loss: 2.531057807516031

Epoch: 6| Step: 10
Training loss: 1.3550135483011643
Validation loss: 2.55037182560763

Epoch: 6| Step: 11
Training loss: 1.9695032283449503
Validation loss: 2.5748360704824043

Epoch: 6| Step: 12
Training loss: 1.395729896166948
Validation loss: 2.5988633139295496

Epoch: 6| Step: 13
Training loss: 1.0144150789608244
Validation loss: 2.6059624601331093

Epoch: 213| Step: 0
Training loss: 1.5129630711921755
Validation loss: 2.6629982966480887

Epoch: 6| Step: 1
Training loss: 1.642671525728689
Validation loss: 2.6711997235655067

Epoch: 6| Step: 2
Training loss: 1.6891244204707985
Validation loss: 2.6758726177001124

Epoch: 6| Step: 3
Training loss: 1.4588047718791146
Validation loss: 2.658569971256047

Epoch: 6| Step: 4
Training loss: 1.5886718029644071
Validation loss: 2.629461706905681

Epoch: 6| Step: 5
Training loss: 1.3804375895948644
Validation loss: 2.6509701027955734

Epoch: 6| Step: 6
Training loss: 1.812630221194224
Validation loss: 2.5926395316871034

Epoch: 6| Step: 7
Training loss: 1.2724818288708561
Validation loss: 2.613676133332134

Epoch: 6| Step: 8
Training loss: 1.6374705188223107
Validation loss: 2.5706754711734696

Epoch: 6| Step: 9
Training loss: 1.5770605293079896
Validation loss: 2.5461365186339524

Epoch: 6| Step: 10
Training loss: 1.721953994960521
Validation loss: 2.5174451472581763

Epoch: 6| Step: 11
Training loss: 1.6343496287840142
Validation loss: 2.527026703545134

Epoch: 6| Step: 12
Training loss: 1.499848517080386
Validation loss: 2.5821419614065624

Epoch: 6| Step: 13
Training loss: 0.7970397255377147
Validation loss: 2.582101054299309

Epoch: 214| Step: 0
Training loss: 1.4671986279862872
Validation loss: 2.6072113909552543

Epoch: 6| Step: 1
Training loss: 1.7088670439633658
Validation loss: 2.6441860246590756

Epoch: 6| Step: 2
Training loss: 1.5205202782033564
Validation loss: 2.644962216964653

Epoch: 6| Step: 3
Training loss: 1.7250833518857485
Validation loss: 2.628025239537159

Epoch: 6| Step: 4
Training loss: 1.439403766008385
Validation loss: 2.642900488775104

Epoch: 6| Step: 5
Training loss: 1.19650946630359
Validation loss: 2.6516145625108125

Epoch: 6| Step: 6
Training loss: 1.3352825500143417
Validation loss: 2.666918336685214

Epoch: 6| Step: 7
Training loss: 1.1981290656604349
Validation loss: 2.643253824379756

Epoch: 6| Step: 8
Training loss: 1.7569508793260278
Validation loss: 2.660473722190299

Epoch: 6| Step: 9
Training loss: 1.5724252939596934
Validation loss: 2.6287224264712967

Epoch: 6| Step: 10
Training loss: 1.5640605762633728
Validation loss: 2.6314754728635337

Epoch: 6| Step: 11
Training loss: 1.672082763311823
Validation loss: 2.604970056136823

Epoch: 6| Step: 12
Training loss: 1.1907876331662315
Validation loss: 2.5484371622369446

Epoch: 6| Step: 13
Training loss: 2.1749691226565213
Validation loss: 2.563928799054963

Epoch: 215| Step: 0
Training loss: 1.6409377753614036
Validation loss: 2.537726191262526

Epoch: 6| Step: 1
Training loss: 1.0129606070508208
Validation loss: 2.5505656816320417

Epoch: 6| Step: 2
Training loss: 1.358715993811882
Validation loss: 2.5418102305222963

Epoch: 6| Step: 3
Training loss: 0.9677338346660125
Validation loss: 2.5825424905725356

Epoch: 6| Step: 4
Training loss: 1.220441182833329
Validation loss: 2.5851881776055134

Epoch: 6| Step: 5
Training loss: 1.5291158634793152
Validation loss: 2.656892118589183

Epoch: 6| Step: 6
Training loss: 1.2876466778655267
Validation loss: 2.7044132180627987

Epoch: 6| Step: 7
Training loss: 1.8087222751899503
Validation loss: 2.670729012325541

Epoch: 6| Step: 8
Training loss: 1.6515104027563974
Validation loss: 2.6836480258505873

Epoch: 6| Step: 9
Training loss: 1.7910833813945308
Validation loss: 2.588972059402041

Epoch: 6| Step: 10
Training loss: 1.5819718714744047
Validation loss: 2.5613982570627565

Epoch: 6| Step: 11
Training loss: 1.6115365188395032
Validation loss: 2.5078670493348394

Epoch: 6| Step: 12
Training loss: 2.209518570396557
Validation loss: 2.4803273279610196

Epoch: 6| Step: 13
Training loss: 1.6444135247723126
Validation loss: 2.508389059850067

Epoch: 216| Step: 0
Training loss: 1.582771260062261
Validation loss: 2.55042685081483

Epoch: 6| Step: 1
Training loss: 1.3686647118599211
Validation loss: 2.5556008410115965

Epoch: 6| Step: 2
Training loss: 1.8362838093843712
Validation loss: 2.632014986375491

Epoch: 6| Step: 3
Training loss: 1.0855271915876394
Validation loss: 2.7052448777349896

Epoch: 6| Step: 4
Training loss: 1.327158497708375
Validation loss: 2.7320955531353

Epoch: 6| Step: 5
Training loss: 1.5880900090073562
Validation loss: 2.753159873169517

Epoch: 6| Step: 6
Training loss: 1.8521843360962675
Validation loss: 2.763721071880356

Epoch: 6| Step: 7
Training loss: 1.806594633599568
Validation loss: 2.6582937274360883

Epoch: 6| Step: 8
Training loss: 1.247591177259182
Validation loss: 2.4933854223049132

Epoch: 6| Step: 9
Training loss: 1.6252890109767124
Validation loss: 2.4369113380634735

Epoch: 6| Step: 10
Training loss: 1.7474401006951792
Validation loss: 2.4195448977836294

Epoch: 6| Step: 11
Training loss: 1.730119588169464
Validation loss: 2.4456516976653524

Epoch: 6| Step: 12
Training loss: 1.6395571185112277
Validation loss: 2.4252603539760864

Epoch: 6| Step: 13
Training loss: 2.3791511797915894
Validation loss: 2.4583165564641556

Epoch: 217| Step: 0
Training loss: 1.2650560583728319
Validation loss: 2.511249420625419

Epoch: 6| Step: 1
Training loss: 0.9708994430877506
Validation loss: 2.6099946232782254

Epoch: 6| Step: 2
Training loss: 1.785833184507325
Validation loss: 2.761156843759419

Epoch: 6| Step: 3
Training loss: 1.3206966225103807
Validation loss: 2.7980903665457117

Epoch: 6| Step: 4
Training loss: 1.6897715362201338
Validation loss: 2.830666225631818

Epoch: 6| Step: 5
Training loss: 2.217083802328602
Validation loss: 2.717254702715239

Epoch: 6| Step: 6
Training loss: 1.464950191445268
Validation loss: 2.599729696031941

Epoch: 6| Step: 7
Training loss: 1.5403429310927588
Validation loss: 2.4884254059776847

Epoch: 6| Step: 8
Training loss: 1.4814755682474028
Validation loss: 2.406382833670368

Epoch: 6| Step: 9
Training loss: 1.9885050529624884
Validation loss: 2.373531525511873

Epoch: 6| Step: 10
Training loss: 1.8899652259897375
Validation loss: 2.381808294503414

Epoch: 6| Step: 11
Training loss: 1.9046555401418435
Validation loss: 2.4016921984571935

Epoch: 6| Step: 12
Training loss: 1.539438347018363
Validation loss: 2.413708118785646

Epoch: 6| Step: 13
Training loss: 1.0826240320486549
Validation loss: 2.4678721572175797

Epoch: 218| Step: 0
Training loss: 1.5276175251153512
Validation loss: 2.529818159377395

Epoch: 6| Step: 1
Training loss: 1.4732844381432422
Validation loss: 2.548884019343722

Epoch: 6| Step: 2
Training loss: 1.3453424022864788
Validation loss: 2.627149913007556

Epoch: 6| Step: 3
Training loss: 1.3372514743393868
Validation loss: 2.6556581410858926

Epoch: 6| Step: 4
Training loss: 1.9950603041939874
Validation loss: 2.713392414706435

Epoch: 6| Step: 5
Training loss: 1.6268182265831483
Validation loss: 2.640195908415285

Epoch: 6| Step: 6
Training loss: 1.449705468880726
Validation loss: 2.5740009165713453

Epoch: 6| Step: 7
Training loss: 1.2057973239603874
Validation loss: 2.5522249220613658

Epoch: 6| Step: 8
Training loss: 1.4894118132465837
Validation loss: 2.5294961082829857

Epoch: 6| Step: 9
Training loss: 1.4669208905941298
Validation loss: 2.5084710730872812

Epoch: 6| Step: 10
Training loss: 1.8002660846073764
Validation loss: 2.4783280388897277

Epoch: 6| Step: 11
Training loss: 1.6478945303425625
Validation loss: 2.501189426787956

Epoch: 6| Step: 12
Training loss: 1.3899263491431768
Validation loss: 2.4957605558370535

Epoch: 6| Step: 13
Training loss: 1.4629613556206982
Validation loss: 2.5217875636772145

Epoch: 219| Step: 0
Training loss: 1.6160918131372919
Validation loss: 2.541695444504609

Epoch: 6| Step: 1
Training loss: 1.818977685159182
Validation loss: 2.6031359922178474

Epoch: 6| Step: 2
Training loss: 1.8413961223312456
Validation loss: 2.6801139774154987

Epoch: 6| Step: 3
Training loss: 1.8049211227005273
Validation loss: 2.7127795312472323

Epoch: 6| Step: 4
Training loss: 1.7941805332827414
Validation loss: 2.7444599165401504

Epoch: 6| Step: 5
Training loss: 1.3397452092982858
Validation loss: 2.716155175882472

Epoch: 6| Step: 6
Training loss: 1.4464033804151395
Validation loss: 2.670573224173531

Epoch: 6| Step: 7
Training loss: 0.9657281073671868
Validation loss: 2.7128079262222573

Epoch: 6| Step: 8
Training loss: 1.4322821414515183
Validation loss: 2.7105650126219607

Epoch: 6| Step: 9
Training loss: 0.7875578480620896
Validation loss: 2.6395189085517465

Epoch: 6| Step: 10
Training loss: 1.1889707592576149
Validation loss: 2.5792953392881834

Epoch: 6| Step: 11
Training loss: 0.9863846262243474
Validation loss: 2.5854534076124276

Epoch: 6| Step: 12
Training loss: 1.440929633842777
Validation loss: 2.5856279763483547

Epoch: 6| Step: 13
Training loss: 2.1145429810931677
Validation loss: 2.5689364039580482

Epoch: 220| Step: 0
Training loss: 2.2084664598560426
Validation loss: 2.583231194217279

Epoch: 6| Step: 1
Training loss: 1.220087051569015
Validation loss: 2.5671291012910062

Epoch: 6| Step: 2
Training loss: 1.428195863130094
Validation loss: 2.614823668642543

Epoch: 6| Step: 3
Training loss: 1.7645146752533882
Validation loss: 2.5935817455876813

Epoch: 6| Step: 4
Training loss: 1.05634544889324
Validation loss: 2.6149722342288704

Epoch: 6| Step: 5
Training loss: 1.7532607082125333
Validation loss: 2.6111483448713195

Epoch: 6| Step: 6
Training loss: 1.3822221088324198
Validation loss: 2.635833804174043

Epoch: 6| Step: 7
Training loss: 1.3507301987222673
Validation loss: 2.6526810684390645

Epoch: 6| Step: 8
Training loss: 0.9166771425746756
Validation loss: 2.6303183593609885

Epoch: 6| Step: 9
Training loss: 1.4580887543988348
Validation loss: 2.616881548171519

Epoch: 6| Step: 10
Training loss: 1.4794834854323289
Validation loss: 2.635695603243685

Epoch: 6| Step: 11
Training loss: 1.202816812255297
Validation loss: 2.5883726233699824

Epoch: 6| Step: 12
Training loss: 1.3564529583511566
Validation loss: 2.6236150953800235

Epoch: 6| Step: 13
Training loss: 1.1153927772385246
Validation loss: 2.6122592476546163

Epoch: 221| Step: 0
Training loss: 1.654883198606927
Validation loss: 2.6136686533114797

Epoch: 6| Step: 1
Training loss: 1.5601447092086922
Validation loss: 2.63927108754474

Epoch: 6| Step: 2
Training loss: 2.076625196717405
Validation loss: 2.6229815333047797

Epoch: 6| Step: 3
Training loss: 1.541835088379526
Validation loss: 2.6188270777769556

Epoch: 6| Step: 4
Training loss: 1.6609193730912744
Validation loss: 2.617599984241242

Epoch: 6| Step: 5
Training loss: 1.0874258037994688
Validation loss: 2.658619327175095

Epoch: 6| Step: 6
Training loss: 1.359117944024599
Validation loss: 2.6486266176305366

Epoch: 6| Step: 7
Training loss: 1.3175766719535282
Validation loss: 2.636540549518232

Epoch: 6| Step: 8
Training loss: 1.3399067410712084
Validation loss: 2.607798269395683

Epoch: 6| Step: 9
Training loss: 1.2516998177585772
Validation loss: 2.5979991937199514

Epoch: 6| Step: 10
Training loss: 1.2258381253547974
Validation loss: 2.586843151270712

Epoch: 6| Step: 11
Training loss: 1.359217755222713
Validation loss: 2.5825579872677626

Epoch: 6| Step: 12
Training loss: 1.1026182053359546
Validation loss: 2.581864845325276

Epoch: 6| Step: 13
Training loss: 1.7295910953992988
Validation loss: 2.5946189214627027

Epoch: 222| Step: 0
Training loss: 1.7224324398882087
Validation loss: 2.601716487561715

Epoch: 6| Step: 1
Training loss: 1.2434861694076036
Validation loss: 2.653884712870419

Epoch: 6| Step: 2
Training loss: 1.6613191010144643
Validation loss: 2.671149123041615

Epoch: 6| Step: 3
Training loss: 1.715336270521199
Validation loss: 2.662812405397212

Epoch: 6| Step: 4
Training loss: 0.8554577761429598
Validation loss: 2.648393869290193

Epoch: 6| Step: 5
Training loss: 1.405084678161628
Validation loss: 2.644828804003297

Epoch: 6| Step: 6
Training loss: 1.7655837467741848
Validation loss: 2.622113120476883

Epoch: 6| Step: 7
Training loss: 1.5054759367378814
Validation loss: 2.604394639075902

Epoch: 6| Step: 8
Training loss: 1.775894681007234
Validation loss: 2.5766585449326143

Epoch: 6| Step: 9
Training loss: 0.6905879765939033
Validation loss: 2.5396675533673125

Epoch: 6| Step: 10
Training loss: 1.4697094482236535
Validation loss: 2.545899969099288

Epoch: 6| Step: 11
Training loss: 1.0555737762942068
Validation loss: 2.535627658435785

Epoch: 6| Step: 12
Training loss: 1.3342646783253997
Validation loss: 2.5333026026449708

Epoch: 6| Step: 13
Training loss: 1.1684333617143992
Validation loss: 2.50126889749113

Epoch: 223| Step: 0
Training loss: 1.030970506651389
Validation loss: 2.5282906648609482

Epoch: 6| Step: 1
Training loss: 1.5119344867863767
Validation loss: 2.5581313159264436

Epoch: 6| Step: 2
Training loss: 1.4326712735295652
Validation loss: 2.5785781616215617

Epoch: 6| Step: 3
Training loss: 2.0296650498391537
Validation loss: 2.583182607045186

Epoch: 6| Step: 4
Training loss: 1.730079348734468
Validation loss: 2.596212355667802

Epoch: 6| Step: 5
Training loss: 0.8489761272664114
Validation loss: 2.6104098674883773

Epoch: 6| Step: 6
Training loss: 1.478530541046168
Validation loss: 2.613096646884213

Epoch: 6| Step: 7
Training loss: 1.3428283014359845
Validation loss: 2.6165425646668767

Epoch: 6| Step: 8
Training loss: 1.2365523823441553
Validation loss: 2.6318404572659038

Epoch: 6| Step: 9
Training loss: 0.9977210421870264
Validation loss: 2.6416786976414115

Epoch: 6| Step: 10
Training loss: 1.6048147535522579
Validation loss: 2.6552167838582683

Epoch: 6| Step: 11
Training loss: 1.1838791506282371
Validation loss: 2.664275938394972

Epoch: 6| Step: 12
Training loss: 1.6220600235788976
Validation loss: 2.652199925362487

Epoch: 6| Step: 13
Training loss: 1.411618391395286
Validation loss: 2.650021765161569

Epoch: 224| Step: 0
Training loss: 1.0182151045482724
Validation loss: 2.6072828307929266

Epoch: 6| Step: 1
Training loss: 1.6400989960820849
Validation loss: 2.6178797984585196

Epoch: 6| Step: 2
Training loss: 1.447571756827675
Validation loss: 2.6070810115239125

Epoch: 6| Step: 3
Training loss: 1.6942110482835657
Validation loss: 2.6053277506543306

Epoch: 6| Step: 4
Training loss: 1.837781653584016
Validation loss: 2.632543550166608

Epoch: 6| Step: 5
Training loss: 1.2042456027935224
Validation loss: 2.623662691951898

Epoch: 6| Step: 6
Training loss: 1.5016815773452636
Validation loss: 2.6422982862876605

Epoch: 6| Step: 7
Training loss: 1.211944407560391
Validation loss: 2.6232111314867357

Epoch: 6| Step: 8
Training loss: 1.5309922916210825
Validation loss: 2.6037567866175904

Epoch: 6| Step: 9
Training loss: 1.2907196028723011
Validation loss: 2.624191852206271

Epoch: 6| Step: 10
Training loss: 0.913117564260507
Validation loss: 2.615394275976701

Epoch: 6| Step: 11
Training loss: 1.1600772304147398
Validation loss: 2.579852167828927

Epoch: 6| Step: 12
Training loss: 1.4764258911880441
Validation loss: 2.5739921579520453

Epoch: 6| Step: 13
Training loss: 1.420180096555656
Validation loss: 2.546724891932245

Epoch: 225| Step: 0
Training loss: 1.442092525376096
Validation loss: 2.567468134534576

Epoch: 6| Step: 1
Training loss: 1.2720158604406813
Validation loss: 2.586196898795966

Epoch: 6| Step: 2
Training loss: 0.9643326614193818
Validation loss: 2.5561686177340026

Epoch: 6| Step: 3
Training loss: 1.481581458497663
Validation loss: 2.589991533239686

Epoch: 6| Step: 4
Training loss: 1.8959751565166718
Validation loss: 2.612433718926685

Epoch: 6| Step: 5
Training loss: 1.2867193948156967
Validation loss: 2.6333981978606813

Epoch: 6| Step: 6
Training loss: 1.656471525528427
Validation loss: 2.624995688197066

Epoch: 6| Step: 7
Training loss: 1.2075252077776755
Validation loss: 2.6663586095052243

Epoch: 6| Step: 8
Training loss: 1.1633795968851566
Validation loss: 2.6291324123433277

Epoch: 6| Step: 9
Training loss: 1.48401814236823
Validation loss: 2.6504376909233796

Epoch: 6| Step: 10
Training loss: 1.5833458230713915
Validation loss: 2.5852994955551423

Epoch: 6| Step: 11
Training loss: 1.2289677259585599
Validation loss: 2.6206674962311256

Epoch: 6| Step: 12
Training loss: 1.2741767750088144
Validation loss: 2.599142094516069

Epoch: 6| Step: 13
Training loss: 0.8245100979877732
Validation loss: 2.541834779448488

Epoch: 226| Step: 0
Training loss: 1.5278556726808226
Validation loss: 2.5455114128026834

Epoch: 6| Step: 1
Training loss: 1.3688773039400528
Validation loss: 2.5105672886515236

Epoch: 6| Step: 2
Training loss: 0.9824622811412947
Validation loss: 2.514791596834989

Epoch: 6| Step: 3
Training loss: 1.2588424730474588
Validation loss: 2.5431810274077153

Epoch: 6| Step: 4
Training loss: 1.7533167334714779
Validation loss: 2.553622231381678

Epoch: 6| Step: 5
Training loss: 1.359909040410537
Validation loss: 2.556198103504016

Epoch: 6| Step: 6
Training loss: 1.146259968255648
Validation loss: 2.579373281404915

Epoch: 6| Step: 7
Training loss: 1.550369323291949
Validation loss: 2.6330822621157863

Epoch: 6| Step: 8
Training loss: 1.4402485982566597
Validation loss: 2.6472813712741257

Epoch: 6| Step: 9
Training loss: 1.405502332505632
Validation loss: 2.6569192698290633

Epoch: 6| Step: 10
Training loss: 1.707423114972525
Validation loss: 2.6653073211608413

Epoch: 6| Step: 11
Training loss: 1.3058916576889923
Validation loss: 2.6570377791036077

Epoch: 6| Step: 12
Training loss: 1.409486817789835
Validation loss: 2.609631187905548

Epoch: 6| Step: 13
Training loss: 1.037277179368359
Validation loss: 2.575002964223957

Epoch: 227| Step: 0
Training loss: 1.4183929901636176
Validation loss: 2.4935404223122637

Epoch: 6| Step: 1
Training loss: 1.2770768099561718
Validation loss: 2.4986424893024073

Epoch: 6| Step: 2
Training loss: 1.429792723405416
Validation loss: 2.490836743202151

Epoch: 6| Step: 3
Training loss: 1.0885081430532737
Validation loss: 2.505137789818647

Epoch: 6| Step: 4
Training loss: 1.337914593335714
Validation loss: 2.512646720404932

Epoch: 6| Step: 5
Training loss: 1.281225436835812
Validation loss: 2.528129394029331

Epoch: 6| Step: 6
Training loss: 1.4083790239374976
Validation loss: 2.5730355789812727

Epoch: 6| Step: 7
Training loss: 1.787661141021362
Validation loss: 2.629437973399863

Epoch: 6| Step: 8
Training loss: 1.5603987488611326
Validation loss: 2.6688563117690616

Epoch: 6| Step: 9
Training loss: 1.246383633273893
Validation loss: 2.6588955603073305

Epoch: 6| Step: 10
Training loss: 1.599305139098852
Validation loss: 2.668283868780974

Epoch: 6| Step: 11
Training loss: 1.2511253060050755
Validation loss: 2.683248710240619

Epoch: 6| Step: 12
Training loss: 1.478319606108011
Validation loss: 2.6939069961941207

Epoch: 6| Step: 13
Training loss: 1.0608685815193812
Validation loss: 2.5700552426036527

Epoch: 228| Step: 0
Training loss: 1.162763754343993
Validation loss: 2.542238467359974

Epoch: 6| Step: 1
Training loss: 1.4704827983307958
Validation loss: 2.4976464119027937

Epoch: 6| Step: 2
Training loss: 1.145841245912917
Validation loss: 2.5196564358613935

Epoch: 6| Step: 3
Training loss: 1.5301967813442265
Validation loss: 2.5458763042266224

Epoch: 6| Step: 4
Training loss: 0.8903464835507462
Validation loss: 2.5485377477784903

Epoch: 6| Step: 5
Training loss: 1.500664881534156
Validation loss: 2.598231948712841

Epoch: 6| Step: 6
Training loss: 2.0264697827943583
Validation loss: 2.6197334543545145

Epoch: 6| Step: 7
Training loss: 1.2838821356501449
Validation loss: 2.6455585090573046

Epoch: 6| Step: 8
Training loss: 1.4823835968584054
Validation loss: 2.6747358370541696

Epoch: 6| Step: 9
Training loss: 1.5376504529826867
Validation loss: 2.6769513659108446

Epoch: 6| Step: 10
Training loss: 1.205265568478961
Validation loss: 2.697670326732996

Epoch: 6| Step: 11
Training loss: 1.266042240266773
Validation loss: 2.674016827460286

Epoch: 6| Step: 12
Training loss: 1.2302229862917826
Validation loss: 2.6762805046309506

Epoch: 6| Step: 13
Training loss: 1.2812656308593036
Validation loss: 2.6442117337913444

Epoch: 229| Step: 0
Training loss: 1.7748850825544773
Validation loss: 2.606080193824726

Epoch: 6| Step: 1
Training loss: 1.4463287904422895
Validation loss: 2.6053399226970124

Epoch: 6| Step: 2
Training loss: 1.709543784001192
Validation loss: 2.5997670341414003

Epoch: 6| Step: 3
Training loss: 1.2768948667439943
Validation loss: 2.5576748884228926

Epoch: 6| Step: 4
Training loss: 1.1353102934585158
Validation loss: 2.5358646531293747

Epoch: 6| Step: 5
Training loss: 1.406870217774854
Validation loss: 2.540981975813522

Epoch: 6| Step: 6
Training loss: 1.1603942010555128
Validation loss: 2.590672574558359

Epoch: 6| Step: 7
Training loss: 1.2391270297205192
Validation loss: 2.598731216455669

Epoch: 6| Step: 8
Training loss: 1.4208376107846008
Validation loss: 2.603111820985054

Epoch: 6| Step: 9
Training loss: 1.133526807053256
Validation loss: 2.5574169687539614

Epoch: 6| Step: 10
Training loss: 1.1631197600167222
Validation loss: 2.558837507281813

Epoch: 6| Step: 11
Training loss: 1.3752693432652632
Validation loss: 2.5628249559870104

Epoch: 6| Step: 12
Training loss: 1.6509939321201956
Validation loss: 2.601559677499417

Epoch: 6| Step: 13
Training loss: 0.8974905579901766
Validation loss: 2.543542550619648

Epoch: 230| Step: 0
Training loss: 1.1207185443018208
Validation loss: 2.53156606589013

Epoch: 6| Step: 1
Training loss: 1.2420518429174725
Validation loss: 2.5570943326989424

Epoch: 6| Step: 2
Training loss: 1.7500343319386242
Validation loss: 2.567123693643741

Epoch: 6| Step: 3
Training loss: 1.956264383671443
Validation loss: 2.584651380217754

Epoch: 6| Step: 4
Training loss: 1.4433121318596143
Validation loss: 2.5872026305597897

Epoch: 6| Step: 5
Training loss: 1.4230768343515032
Validation loss: 2.6110400818448425

Epoch: 6| Step: 6
Training loss: 1.3609743465862003
Validation loss: 2.5828638579714283

Epoch: 6| Step: 7
Training loss: 1.2561059594014736
Validation loss: 2.5673160850344776

Epoch: 6| Step: 8
Training loss: 1.0864902982950122
Validation loss: 2.5401493862970446

Epoch: 6| Step: 9
Training loss: 1.3569923654452551
Validation loss: 2.530918778747189

Epoch: 6| Step: 10
Training loss: 1.098497984348231
Validation loss: 2.564104012872667

Epoch: 6| Step: 11
Training loss: 1.0811883831658955
Validation loss: 2.58648156930943

Epoch: 6| Step: 12
Training loss: 1.2760019516765533
Validation loss: 2.57370518961756

Epoch: 6| Step: 13
Training loss: 1.2490599912494644
Validation loss: 2.5985557719009855

Epoch: 231| Step: 0
Training loss: 1.5818400703109596
Validation loss: 2.6430488151894127

Epoch: 6| Step: 1
Training loss: 1.1895085464369346
Validation loss: 2.67297197030748

Epoch: 6| Step: 2
Training loss: 0.9378170431014967
Validation loss: 2.6657404874255284

Epoch: 6| Step: 3
Training loss: 0.8648015784756479
Validation loss: 2.6913797295762474

Epoch: 6| Step: 4
Training loss: 1.2957067628153305
Validation loss: 2.6632506518315644

Epoch: 6| Step: 5
Training loss: 1.3257436608744373
Validation loss: 2.6688762782373514

Epoch: 6| Step: 6
Training loss: 1.0227649021932588
Validation loss: 2.644694878794766

Epoch: 6| Step: 7
Training loss: 1.271196745935792
Validation loss: 2.6592960175935674

Epoch: 6| Step: 8
Training loss: 1.2829793563662666
Validation loss: 2.5974990164287597

Epoch: 6| Step: 9
Training loss: 1.1941936966542672
Validation loss: 2.617933123697309

Epoch: 6| Step: 10
Training loss: 1.8041390250234457
Validation loss: 2.5945903386892644

Epoch: 6| Step: 11
Training loss: 1.6005811708669109
Validation loss: 2.5644351126453415

Epoch: 6| Step: 12
Training loss: 1.296143704785899
Validation loss: 2.5774281603818703

Epoch: 6| Step: 13
Training loss: 1.8854166596414415
Validation loss: 2.58605893198829

Epoch: 232| Step: 0
Training loss: 1.46850040019377
Validation loss: 2.604923747281151

Epoch: 6| Step: 1
Training loss: 2.1053692116501805
Validation loss: 2.6524840361964217

Epoch: 6| Step: 2
Training loss: 1.3910186724695013
Validation loss: 2.6504952659616112

Epoch: 6| Step: 3
Training loss: 1.6059006158854279
Validation loss: 2.6706369262888865

Epoch: 6| Step: 4
Training loss: 1.3381781721530734
Validation loss: 2.690656788775061

Epoch: 6| Step: 5
Training loss: 1.0102526672562182
Validation loss: 2.673602538957843

Epoch: 6| Step: 6
Training loss: 0.6237744713762716
Validation loss: 2.6570525817779918

Epoch: 6| Step: 7
Training loss: 1.0869849662583393
Validation loss: 2.6227934881127952

Epoch: 6| Step: 8
Training loss: 1.043684010504012
Validation loss: 2.635632349310077

Epoch: 6| Step: 9
Training loss: 1.0812592765101465
Validation loss: 2.59090563746615

Epoch: 6| Step: 10
Training loss: 1.0934977104222348
Validation loss: 2.607617277515871

Epoch: 6| Step: 11
Training loss: 1.2280429725335005
Validation loss: 2.5827782951286484

Epoch: 6| Step: 12
Training loss: 1.607203379505681
Validation loss: 2.593620078604539

Epoch: 6| Step: 13
Training loss: 1.185638926921444
Validation loss: 2.5640641337706316

Epoch: 233| Step: 0
Training loss: 1.1094545147835198
Validation loss: 2.5938961009155244

Epoch: 6| Step: 1
Training loss: 1.1330778140107831
Validation loss: 2.5689486506305776

Epoch: 6| Step: 2
Training loss: 1.5114408331220937
Validation loss: 2.57921450686177

Epoch: 6| Step: 3
Training loss: 1.2373868678620468
Validation loss: 2.58810895349034

Epoch: 6| Step: 4
Training loss: 1.1760653029106016
Validation loss: 2.567330775930288

Epoch: 6| Step: 5
Training loss: 1.0703042023051703
Validation loss: 2.6488593305185564

Epoch: 6| Step: 6
Training loss: 1.5348155490506161
Validation loss: 2.64824505812615

Epoch: 6| Step: 7
Training loss: 1.4030589880421211
Validation loss: 2.623000500938515

Epoch: 6| Step: 8
Training loss: 0.9053534315005773
Validation loss: 2.604425515056809

Epoch: 6| Step: 9
Training loss: 1.7506697599224375
Validation loss: 2.6072572171985846

Epoch: 6| Step: 10
Training loss: 1.3883356687992474
Validation loss: 2.645211342806489

Epoch: 6| Step: 11
Training loss: 1.2120439458282681
Validation loss: 2.613025121701614

Epoch: 6| Step: 12
Training loss: 1.134427202352956
Validation loss: 2.580334019490558

Epoch: 6| Step: 13
Training loss: 1.4160952631161403
Validation loss: 2.5838152872178792

Epoch: 234| Step: 0
Training loss: 1.2468556433683393
Validation loss: 2.591373788806764

Epoch: 6| Step: 1
Training loss: 1.2855839351017067
Validation loss: 2.609837568228879

Epoch: 6| Step: 2
Training loss: 1.06176609048851
Validation loss: 2.5743708409297046

Epoch: 6| Step: 3
Training loss: 1.1022230832505024
Validation loss: 2.61656307729705

Epoch: 6| Step: 4
Training loss: 1.2150664784647065
Validation loss: 2.6264802965200698

Epoch: 6| Step: 5
Training loss: 2.007377369556754
Validation loss: 2.6169443991313743

Epoch: 6| Step: 6
Training loss: 0.9688395797166763
Validation loss: 2.6398926746296025

Epoch: 6| Step: 7
Training loss: 1.3464396859708025
Validation loss: 2.679299597610537

Epoch: 6| Step: 8
Training loss: 1.4228666431724828
Validation loss: 2.656940388340352

Epoch: 6| Step: 9
Training loss: 1.3708451526599972
Validation loss: 2.6668303565064018

Epoch: 6| Step: 10
Training loss: 0.7242000688532281
Validation loss: 2.687435502320274

Epoch: 6| Step: 11
Training loss: 1.146703124095147
Validation loss: 2.604639711464553

Epoch: 6| Step: 12
Training loss: 1.3896814638611057
Validation loss: 2.6663280132305602

Epoch: 6| Step: 13
Training loss: 1.3005441902129724
Validation loss: 2.6159080947401505

Epoch: 235| Step: 0
Training loss: 1.0574812445093358
Validation loss: 2.636488559387069

Epoch: 6| Step: 1
Training loss: 1.2351926196231142
Validation loss: 2.6219858775244855

Epoch: 6| Step: 2
Training loss: 1.2004434004806592
Validation loss: 2.6211690474223506

Epoch: 6| Step: 3
Training loss: 0.9064699103468674
Validation loss: 2.6169379071067174

Epoch: 6| Step: 4
Training loss: 1.0553366464750424
Validation loss: 2.6121530219891125

Epoch: 6| Step: 5
Training loss: 1.7486441673337074
Validation loss: 2.6270540954139583

Epoch: 6| Step: 6
Training loss: 0.9605980870702989
Validation loss: 2.5993441307444254

Epoch: 6| Step: 7
Training loss: 0.9115916054793171
Validation loss: 2.568733004056767

Epoch: 6| Step: 8
Training loss: 1.3045769376221308
Validation loss: 2.5679304945400694

Epoch: 6| Step: 9
Training loss: 1.2062621397682416
Validation loss: 2.579225891674841

Epoch: 6| Step: 10
Training loss: 1.2706712035688228
Validation loss: 2.542230629918291

Epoch: 6| Step: 11
Training loss: 1.5178677983270619
Validation loss: 2.5493713984265534

Epoch: 6| Step: 12
Training loss: 1.6648655059839328
Validation loss: 2.5403451037315894

Epoch: 6| Step: 13
Training loss: 1.4743351359231653
Validation loss: 2.5503883802371057

Epoch: 236| Step: 0
Training loss: 0.8593609201838429
Validation loss: 2.5493234671929845

Epoch: 6| Step: 1
Training loss: 0.9136067419823005
Validation loss: 2.5768090373301993

Epoch: 6| Step: 2
Training loss: 1.3099709622608253
Validation loss: 2.6189495337918185

Epoch: 6| Step: 3
Training loss: 1.4224878185266865
Validation loss: 2.6279600401591563

Epoch: 6| Step: 4
Training loss: 1.450261237190532
Validation loss: 2.5946597784334107

Epoch: 6| Step: 5
Training loss: 1.459309941216005
Validation loss: 2.555866993873777

Epoch: 6| Step: 6
Training loss: 1.07463870076108
Validation loss: 2.585165367226538

Epoch: 6| Step: 7
Training loss: 1.4081108920173278
Validation loss: 2.5344376034550264

Epoch: 6| Step: 8
Training loss: 1.6513482018839505
Validation loss: 2.5738002984670816

Epoch: 6| Step: 9
Training loss: 1.3270319760544154
Validation loss: 2.602684133219943

Epoch: 6| Step: 10
Training loss: 1.1221117455225649
Validation loss: 2.5748505531953962

Epoch: 6| Step: 11
Training loss: 1.2795624202574898
Validation loss: 2.6223694951667507

Epoch: 6| Step: 12
Training loss: 1.3611874829273074
Validation loss: 2.6253680709953815

Epoch: 6| Step: 13
Training loss: 0.7975857500834093
Validation loss: 2.6558426044517653

Epoch: 237| Step: 0
Training loss: 1.0955264243103882
Validation loss: 2.675831068326828

Epoch: 6| Step: 1
Training loss: 1.1415691909573067
Validation loss: 2.6931124360743843

Epoch: 6| Step: 2
Training loss: 1.6143524825253293
Validation loss: 2.6592306276116173

Epoch: 6| Step: 3
Training loss: 1.136388881576324
Validation loss: 2.6529968734401876

Epoch: 6| Step: 4
Training loss: 0.5782732644569489
Validation loss: 2.645199798113105

Epoch: 6| Step: 5
Training loss: 1.0674963888067053
Validation loss: 2.6143186613623506

Epoch: 6| Step: 6
Training loss: 1.393496174643159
Validation loss: 2.6316082924691973

Epoch: 6| Step: 7
Training loss: 1.5624785612542889
Validation loss: 2.657043396449405

Epoch: 6| Step: 8
Training loss: 1.4198744397327263
Validation loss: 2.6094216876845104

Epoch: 6| Step: 9
Training loss: 0.938550995763773
Validation loss: 2.611172417657194

Epoch: 6| Step: 10
Training loss: 1.6737003522465148
Validation loss: 2.623344702265693

Epoch: 6| Step: 11
Training loss: 1.1327751416590448
Validation loss: 2.6390071222458444

Epoch: 6| Step: 12
Training loss: 1.4430481364785916
Validation loss: 2.6345683758418703

Epoch: 6| Step: 13
Training loss: 0.8534015081660066
Validation loss: 2.59587049134878

Epoch: 238| Step: 0
Training loss: 1.1149634785508435
Validation loss: 2.621284811547382

Epoch: 6| Step: 1
Training loss: 1.0220390258176002
Validation loss: 2.6296405499016346

Epoch: 6| Step: 2
Training loss: 1.4705896422435538
Validation loss: 2.6358268947372965

Epoch: 6| Step: 3
Training loss: 1.6026504914889812
Validation loss: 2.6322307019914715

Epoch: 6| Step: 4
Training loss: 1.4579780509144307
Validation loss: 2.620026288380106

Epoch: 6| Step: 5
Training loss: 0.9875966893918158
Validation loss: 2.683670472972988

Epoch: 6| Step: 6
Training loss: 0.6910047712492559
Validation loss: 2.6605834116840974

Epoch: 6| Step: 7
Training loss: 1.4330803474161065
Validation loss: 2.6787057828632848

Epoch: 6| Step: 8
Training loss: 1.3006885025821946
Validation loss: 2.6963506833600674

Epoch: 6| Step: 9
Training loss: 1.435842968773167
Validation loss: 2.6429668230654504

Epoch: 6| Step: 10
Training loss: 1.0037058470671716
Validation loss: 2.6393159788060268

Epoch: 6| Step: 11
Training loss: 1.4666317213114652
Validation loss: 2.6117161350784945

Epoch: 6| Step: 12
Training loss: 1.1018223016506214
Validation loss: 2.575460844957664

Epoch: 6| Step: 13
Training loss: 0.5386396767756179
Validation loss: 2.561884087977381

Epoch: 239| Step: 0
Training loss: 1.3585214675706607
Validation loss: 2.51571575824754

Epoch: 6| Step: 1
Training loss: 1.5809716714761628
Validation loss: 2.493360596856452

Epoch: 6| Step: 2
Training loss: 1.06992984809147
Validation loss: 2.559926843777183

Epoch: 6| Step: 3
Training loss: 1.6668937131090908
Validation loss: 2.5903267185576975

Epoch: 6| Step: 4
Training loss: 1.1937133963200781
Validation loss: 2.589570635965917

Epoch: 6| Step: 5
Training loss: 0.5311387450463488
Validation loss: 2.580044500373066

Epoch: 6| Step: 6
Training loss: 1.108070681338478
Validation loss: 2.5954446822197603

Epoch: 6| Step: 7
Training loss: 1.1744533403465303
Validation loss: 2.6027709594120814

Epoch: 6| Step: 8
Training loss: 1.2690996111168782
Validation loss: 2.5901866621418597

Epoch: 6| Step: 9
Training loss: 1.1775899263938456
Validation loss: 2.602952633971361

Epoch: 6| Step: 10
Training loss: 1.2673474588341072
Validation loss: 2.5445770339045453

Epoch: 6| Step: 11
Training loss: 1.4689002264585287
Validation loss: 2.5384127261430613

Epoch: 6| Step: 12
Training loss: 0.846514552643046
Validation loss: 2.5760499739618803

Epoch: 6| Step: 13
Training loss: 1.1005071901245111
Validation loss: 2.564359299518985

Epoch: 240| Step: 0
Training loss: 1.0712571256705492
Validation loss: 2.5742736070614356

Epoch: 6| Step: 1
Training loss: 1.1692762424312728
Validation loss: 2.564340401247071

Epoch: 6| Step: 2
Training loss: 1.3422428816892398
Validation loss: 2.596904034401227

Epoch: 6| Step: 3
Training loss: 1.6212286100248585
Validation loss: 2.6136680579299494

Epoch: 6| Step: 4
Training loss: 1.1091305638051967
Validation loss: 2.6537200480365244

Epoch: 6| Step: 5
Training loss: 1.1447256919077797
Validation loss: 2.6316980916266073

Epoch: 6| Step: 6
Training loss: 0.6789768274493696
Validation loss: 2.6790181004354485

Epoch: 6| Step: 7
Training loss: 0.9986581442156927
Validation loss: 2.6448710643094953

Epoch: 6| Step: 8
Training loss: 1.5550756688734606
Validation loss: 2.6763246821999442

Epoch: 6| Step: 9
Training loss: 1.1818410656120668
Validation loss: 2.637262663713635

Epoch: 6| Step: 10
Training loss: 0.9738383023693832
Validation loss: 2.6374655181616724

Epoch: 6| Step: 11
Training loss: 1.2483286173943202
Validation loss: 2.6033838266105565

Epoch: 6| Step: 12
Training loss: 1.5425522640530547
Validation loss: 2.6529387767542087

Epoch: 6| Step: 13
Training loss: 0.721005797472646
Validation loss: 2.6584331509398176

Epoch: 241| Step: 0
Training loss: 1.0115612599692583
Validation loss: 2.641503651138278

Epoch: 6| Step: 1
Training loss: 0.6174290341359574
Validation loss: 2.625521932690558

Epoch: 6| Step: 2
Training loss: 1.4384525294474881
Validation loss: 2.6319684637491063

Epoch: 6| Step: 3
Training loss: 1.3680551010406479
Validation loss: 2.600439241379414

Epoch: 6| Step: 4
Training loss: 1.1407149815013418
Validation loss: 2.6118906514635953

Epoch: 6| Step: 5
Training loss: 1.3809312858364033
Validation loss: 2.597513204011992

Epoch: 6| Step: 6
Training loss: 1.601349160476423
Validation loss: 2.6252911333484423

Epoch: 6| Step: 7
Training loss: 1.021682865850354
Validation loss: 2.5695833020288323

Epoch: 6| Step: 8
Training loss: 1.118590267861759
Validation loss: 2.6121089613799557

Epoch: 6| Step: 9
Training loss: 0.9444721048798687
Validation loss: 2.5896454798631368

Epoch: 6| Step: 10
Training loss: 1.4321932487197622
Validation loss: 2.5710914215283647

Epoch: 6| Step: 11
Training loss: 1.2760761749376364
Validation loss: 2.578911216382061

Epoch: 6| Step: 12
Training loss: 0.7942080280091296
Validation loss: 2.5639063339816976

Epoch: 6| Step: 13
Training loss: 1.5131001629498613
Validation loss: 2.58634135076166

Epoch: 242| Step: 0
Training loss: 1.1412574895673593
Validation loss: 2.5948935897373864

Epoch: 6| Step: 1
Training loss: 0.987062811347653
Validation loss: 2.6007134585883414

Epoch: 6| Step: 2
Training loss: 1.311139627908046
Validation loss: 2.608892206391901

Epoch: 6| Step: 3
Training loss: 1.1934669059093317
Validation loss: 2.6191907141361725

Epoch: 6| Step: 4
Training loss: 1.3184507437233188
Validation loss: 2.6455293961576545

Epoch: 6| Step: 5
Training loss: 0.967404569507885
Validation loss: 2.6599676687468667

Epoch: 6| Step: 6
Training loss: 1.2091332561172006
Validation loss: 2.629269900334042

Epoch: 6| Step: 7
Training loss: 0.8320099733882798
Validation loss: 2.61781829593491

Epoch: 6| Step: 8
Training loss: 1.738570834266211
Validation loss: 2.5554937479217386

Epoch: 6| Step: 9
Training loss: 0.9492471949706931
Validation loss: 2.5617988101286064

Epoch: 6| Step: 10
Training loss: 1.5200847019889066
Validation loss: 2.5253751185945577

Epoch: 6| Step: 11
Training loss: 0.8844340463074458
Validation loss: 2.513354344239221

Epoch: 6| Step: 12
Training loss: 1.3515408905595014
Validation loss: 2.4947779444400346

Epoch: 6| Step: 13
Training loss: 0.9378015351154977
Validation loss: 2.499392486918833

Epoch: 243| Step: 0
Training loss: 1.12781670074653
Validation loss: 2.5158198276152604

Epoch: 6| Step: 1
Training loss: 1.5255589508299163
Validation loss: 2.5925266886398526

Epoch: 6| Step: 2
Training loss: 1.2777217573979098
Validation loss: 2.58518488130895

Epoch: 6| Step: 3
Training loss: 0.9064350596930791
Validation loss: 2.596641449015283

Epoch: 6| Step: 4
Training loss: 1.1370968009754108
Validation loss: 2.6072158452477594

Epoch: 6| Step: 5
Training loss: 0.7886069465199684
Validation loss: 2.619750953412924

Epoch: 6| Step: 6
Training loss: 0.8411319877185728
Validation loss: 2.6074303512309496

Epoch: 6| Step: 7
Training loss: 1.0243322523413219
Validation loss: 2.6006231716386057

Epoch: 6| Step: 8
Training loss: 1.2107817518917732
Validation loss: 2.581758984673614

Epoch: 6| Step: 9
Training loss: 1.3539818955567624
Validation loss: 2.569421830244543

Epoch: 6| Step: 10
Training loss: 1.6786643527204115
Validation loss: 2.5670149820384314

Epoch: 6| Step: 11
Training loss: 1.1933163199641568
Validation loss: 2.5651425877782486

Epoch: 6| Step: 12
Training loss: 1.4591982683426636
Validation loss: 2.5312202185495885

Epoch: 6| Step: 13
Training loss: 0.5697199212002032
Validation loss: 2.521252370441326

Epoch: 244| Step: 0
Training loss: 1.1551303081574185
Validation loss: 2.511204075540657

Epoch: 6| Step: 1
Training loss: 1.047174667056645
Validation loss: 2.580837379399496

Epoch: 6| Step: 2
Training loss: 1.071344031677129
Validation loss: 2.5641064004400027

Epoch: 6| Step: 3
Training loss: 1.1028130109033998
Validation loss: 2.6068926749316406

Epoch: 6| Step: 4
Training loss: 1.3908801326950126
Validation loss: 2.634813194794458

Epoch: 6| Step: 5
Training loss: 1.3448119292245817
Validation loss: 2.664022902780025

Epoch: 6| Step: 6
Training loss: 1.5973485076663287
Validation loss: 2.6104528215060543

Epoch: 6| Step: 7
Training loss: 1.1776092614670075
Validation loss: 2.5699749058592847

Epoch: 6| Step: 8
Training loss: 0.780331796843678
Validation loss: 2.529886264493258

Epoch: 6| Step: 9
Training loss: 1.1554333664001026
Validation loss: 2.5351185650083936

Epoch: 6| Step: 10
Training loss: 1.2163508349311458
Validation loss: 2.523386733372659

Epoch: 6| Step: 11
Training loss: 1.3590782981756053
Validation loss: 2.516472381970704

Epoch: 6| Step: 12
Training loss: 1.1602052620447358
Validation loss: 2.5401796842453193

Epoch: 6| Step: 13
Training loss: 1.02781619968137
Validation loss: 2.590923769562348

Epoch: 245| Step: 0
Training loss: 0.9717766028144472
Validation loss: 2.6181923311278714

Epoch: 6| Step: 1
Training loss: 1.4198918188552947
Validation loss: 2.6424983821357175

Epoch: 6| Step: 2
Training loss: 1.0096757800863327
Validation loss: 2.693088439846012

Epoch: 6| Step: 3
Training loss: 1.2489919412443031
Validation loss: 2.7182323503789307

Epoch: 6| Step: 4
Training loss: 1.008415514904634
Validation loss: 2.741991313559571

Epoch: 6| Step: 5
Training loss: 1.8863085188234812
Validation loss: 2.6960665368127095

Epoch: 6| Step: 6
Training loss: 1.2544502195453038
Validation loss: 2.6463039040450056

Epoch: 6| Step: 7
Training loss: 1.31560648273113
Validation loss: 2.6344517887820595

Epoch: 6| Step: 8
Training loss: 1.0681786532511945
Validation loss: 2.5905515201411298

Epoch: 6| Step: 9
Training loss: 0.8772502302428775
Validation loss: 2.55718461865593

Epoch: 6| Step: 10
Training loss: 1.3569713256465716
Validation loss: 2.5229321807576444

Epoch: 6| Step: 11
Training loss: 0.9394764094332176
Validation loss: 2.505845831715496

Epoch: 6| Step: 12
Training loss: 1.273956567488055
Validation loss: 2.5066322082071295

Epoch: 6| Step: 13
Training loss: 0.7575346053751683
Validation loss: 2.5461170692630675

Epoch: 246| Step: 0
Training loss: 1.1925296677391763
Validation loss: 2.6361036869587404

Epoch: 6| Step: 1
Training loss: 0.8988204471636543
Validation loss: 2.715094534503774

Epoch: 6| Step: 2
Training loss: 1.4349156243908887
Validation loss: 2.7690447727133938

Epoch: 6| Step: 3
Training loss: 1.7122532910473955
Validation loss: 2.742316917355053

Epoch: 6| Step: 4
Training loss: 1.1213368541032522
Validation loss: 2.779111570333109

Epoch: 6| Step: 5
Training loss: 1.0559113360231702
Validation loss: 2.7397935105830786

Epoch: 6| Step: 6
Training loss: 0.8768695205223627
Validation loss: 2.7244030459184834

Epoch: 6| Step: 7
Training loss: 0.9185112506736013
Validation loss: 2.645112816842673

Epoch: 6| Step: 8
Training loss: 1.694905808006246
Validation loss: 2.5936510294754482

Epoch: 6| Step: 9
Training loss: 1.2761559052485447
Validation loss: 2.5422046699848915

Epoch: 6| Step: 10
Training loss: 1.289961114415627
Validation loss: 2.5288975969870116

Epoch: 6| Step: 11
Training loss: 0.9705693787937697
Validation loss: 2.4872451943178477

Epoch: 6| Step: 12
Training loss: 1.1312001296373804
Validation loss: 2.5512704712860654

Epoch: 6| Step: 13
Training loss: 0.8290513453648032
Validation loss: 2.652992862248004

Epoch: 247| Step: 0
Training loss: 1.2128875781526243
Validation loss: 2.6621716425636186

Epoch: 6| Step: 1
Training loss: 1.7031073613084604
Validation loss: 2.7259519945258384

Epoch: 6| Step: 2
Training loss: 0.9883111640112033
Validation loss: 2.682491055102779

Epoch: 6| Step: 3
Training loss: 1.281119968049716
Validation loss: 2.6555922652405597

Epoch: 6| Step: 4
Training loss: 0.8016655110280146
Validation loss: 2.6298104200343344

Epoch: 6| Step: 5
Training loss: 1.0549652864069423
Validation loss: 2.5571136690016196

Epoch: 6| Step: 6
Training loss: 1.057509933767714
Validation loss: 2.5406199969188807

Epoch: 6| Step: 7
Training loss: 1.5266665935655157
Validation loss: 2.509835591391767

Epoch: 6| Step: 8
Training loss: 1.6429317424849024
Validation loss: 2.532537443086692

Epoch: 6| Step: 9
Training loss: 0.9866649996629585
Validation loss: 2.5287493394807807

Epoch: 6| Step: 10
Training loss: 1.1590265495873318
Validation loss: 2.5199905413137427

Epoch: 6| Step: 11
Training loss: 0.8638005830607794
Validation loss: 2.538901463553586

Epoch: 6| Step: 12
Training loss: 0.9563449812448229
Validation loss: 2.5706598664466003

Epoch: 6| Step: 13
Training loss: 0.7785384232723411
Validation loss: 2.575142621444269

Epoch: 248| Step: 0
Training loss: 1.0271725820230444
Validation loss: 2.627577775822893

Epoch: 6| Step: 1
Training loss: 1.5716300485308845
Validation loss: 2.599039686621714

Epoch: 6| Step: 2
Training loss: 0.9578537501153855
Validation loss: 2.658894526711526

Epoch: 6| Step: 3
Training loss: 0.7523789426310832
Validation loss: 2.638803460451604

Epoch: 6| Step: 4
Training loss: 1.7614479279694868
Validation loss: 2.6480996448820466

Epoch: 6| Step: 5
Training loss: 0.9283887623231302
Validation loss: 2.683964759562911

Epoch: 6| Step: 6
Training loss: 1.0295076389705569
Validation loss: 2.6699832018307332

Epoch: 6| Step: 7
Training loss: 0.8434871334752098
Validation loss: 2.6189855201565644

Epoch: 6| Step: 8
Training loss: 1.4276273298512578
Validation loss: 2.652555908444023

Epoch: 6| Step: 9
Training loss: 1.1491237328807757
Validation loss: 2.623671536852574

Epoch: 6| Step: 10
Training loss: 0.8891482910169001
Validation loss: 2.649729634766402

Epoch: 6| Step: 11
Training loss: 0.9307539457165296
Validation loss: 2.60668264088256

Epoch: 6| Step: 12
Training loss: 1.1993760990457831
Validation loss: 2.6487524278704697

Epoch: 6| Step: 13
Training loss: 1.369892387409975
Validation loss: 2.597837903301054

Epoch: 249| Step: 0
Training loss: 1.3031033703955175
Validation loss: 2.60176431674419

Epoch: 6| Step: 1
Training loss: 1.1568545230349538
Validation loss: 2.59672796783011

Epoch: 6| Step: 2
Training loss: 0.9958744480844479
Validation loss: 2.555914305899877

Epoch: 6| Step: 3
Training loss: 0.8994979570756818
Validation loss: 2.5822932148759805

Epoch: 6| Step: 4
Training loss: 1.1100453782471613
Validation loss: 2.5827958222283716

Epoch: 6| Step: 5
Training loss: 1.353739490133614
Validation loss: 2.59764721190584

Epoch: 6| Step: 6
Training loss: 1.0904745921831005
Validation loss: 2.6114992628714537

Epoch: 6| Step: 7
Training loss: 1.1600175254418683
Validation loss: 2.6064123840886793

Epoch: 6| Step: 8
Training loss: 1.5530640833860918
Validation loss: 2.5958708577424856

Epoch: 6| Step: 9
Training loss: 0.901011685146383
Validation loss: 2.5928563262257858

Epoch: 6| Step: 10
Training loss: 0.7534587500481625
Validation loss: 2.561479658971443

Epoch: 6| Step: 11
Training loss: 0.5360084486729642
Validation loss: 2.5060869440213214

Epoch: 6| Step: 12
Training loss: 1.2121703732159075
Validation loss: 2.504877025865662

Epoch: 6| Step: 13
Training loss: 1.5369774496425896
Validation loss: 2.533274480696583

Epoch: 250| Step: 0
Training loss: 0.9912013462147565
Validation loss: 2.523241551639889

Epoch: 6| Step: 1
Training loss: 1.0051714572500325
Validation loss: 2.501076497297624

Epoch: 6| Step: 2
Training loss: 0.7283303687459405
Validation loss: 2.5396188908532085

Epoch: 6| Step: 3
Training loss: 0.7757819891212531
Validation loss: 2.5238409735414993

Epoch: 6| Step: 4
Training loss: 1.199880460904548
Validation loss: 2.563388196321617

Epoch: 6| Step: 5
Training loss: 1.016281619923165
Validation loss: 2.5921289384703536

Epoch: 6| Step: 6
Training loss: 0.9443824228011437
Validation loss: 2.6029952831157734

Epoch: 6| Step: 7
Training loss: 1.5526526855476972
Validation loss: 2.6569031676595127

Epoch: 6| Step: 8
Training loss: 1.281519791645605
Validation loss: 2.637099224123432

Epoch: 6| Step: 9
Training loss: 1.3150349614532537
Validation loss: 2.641526907683878

Epoch: 6| Step: 10
Training loss: 1.4018153308103554
Validation loss: 2.613666383602579

Epoch: 6| Step: 11
Training loss: 1.0417455007603786
Validation loss: 2.5459055205096286

Epoch: 6| Step: 12
Training loss: 1.1149189999158196
Validation loss: 2.550238745863597

Epoch: 6| Step: 13
Training loss: 1.1737141228535908
Validation loss: 2.578311994675249

Epoch: 251| Step: 0
Training loss: 1.0102182698221682
Validation loss: 2.5317590248021595

Epoch: 6| Step: 1
Training loss: 1.1172534416318147
Validation loss: 2.5795944704616085

Epoch: 6| Step: 2
Training loss: 1.1009519251133664
Validation loss: 2.533713156247823

Epoch: 6| Step: 3
Training loss: 0.9580481284521483
Validation loss: 2.560762442079783

Epoch: 6| Step: 4
Training loss: 1.392560447805384
Validation loss: 2.5670633029814565

Epoch: 6| Step: 5
Training loss: 1.127075823314041
Validation loss: 2.538332000478475

Epoch: 6| Step: 6
Training loss: 0.95001011893254
Validation loss: 2.5281239293271094

Epoch: 6| Step: 7
Training loss: 1.0375313627719172
Validation loss: 2.473412035656299

Epoch: 6| Step: 8
Training loss: 1.080873937753416
Validation loss: 2.491357134795628

Epoch: 6| Step: 9
Training loss: 0.7275263228357127
Validation loss: 2.4951208925288917

Epoch: 6| Step: 10
Training loss: 1.5228723504767423
Validation loss: 2.516682221200857

Epoch: 6| Step: 11
Training loss: 1.1222856412935551
Validation loss: 2.531315536187412

Epoch: 6| Step: 12
Training loss: 0.8232121399886068
Validation loss: 2.5563698493482967

Epoch: 6| Step: 13
Training loss: 1.1869382533473325
Validation loss: 2.5450033687420417

Epoch: 252| Step: 0
Training loss: 1.049356508620325
Validation loss: 2.5266498029427864

Epoch: 6| Step: 1
Training loss: 1.0159796462385675
Validation loss: 2.523415021390823

Epoch: 6| Step: 2
Training loss: 1.1470744029809579
Validation loss: 2.50567862269659

Epoch: 6| Step: 3
Training loss: 1.3415916763498985
Validation loss: 2.548702097726779

Epoch: 6| Step: 4
Training loss: 1.1493508994898298
Validation loss: 2.510865803220316

Epoch: 6| Step: 5
Training loss: 1.224686907636456
Validation loss: 2.4828184874079136

Epoch: 6| Step: 6
Training loss: 0.8100163573509027
Validation loss: 2.503204666682101

Epoch: 6| Step: 7
Training loss: 0.8368242498255715
Validation loss: 2.5423498790427597

Epoch: 6| Step: 8
Training loss: 1.3393108765191157
Validation loss: 2.514757105893329

Epoch: 6| Step: 9
Training loss: 1.1257968835320966
Validation loss: 2.540864388827838

Epoch: 6| Step: 10
Training loss: 0.7981848703391413
Validation loss: 2.5009585337528732

Epoch: 6| Step: 11
Training loss: 0.7036060806742505
Validation loss: 2.5104618762004773

Epoch: 6| Step: 12
Training loss: 1.3643583398589028
Validation loss: 2.530761967439452

Epoch: 6| Step: 13
Training loss: 1.1038448416549502
Validation loss: 2.556646856006165

Epoch: 253| Step: 0
Training loss: 0.9052039719547138
Validation loss: 2.5261755145510922

Epoch: 6| Step: 1
Training loss: 1.7104081680638088
Validation loss: 2.5598823799795687

Epoch: 6| Step: 2
Training loss: 0.9284416313682937
Validation loss: 2.5345855697031787

Epoch: 6| Step: 3
Training loss: 0.9588893990965314
Validation loss: 2.533905524199298

Epoch: 6| Step: 4
Training loss: 0.968454838979428
Validation loss: 2.5847427229756605

Epoch: 6| Step: 5
Training loss: 0.8839196883136435
Validation loss: 2.5498424610854538

Epoch: 6| Step: 6
Training loss: 0.9789253640953626
Validation loss: 2.5496177040327455

Epoch: 6| Step: 7
Training loss: 1.073372247259036
Validation loss: 2.539683487319153

Epoch: 6| Step: 8
Training loss: 1.00516013127056
Validation loss: 2.555847309610274

Epoch: 6| Step: 9
Training loss: 1.2880121749338047
Validation loss: 2.549271365692207

Epoch: 6| Step: 10
Training loss: 1.4540159713938356
Validation loss: 2.5657163993837813

Epoch: 6| Step: 11
Training loss: 0.9280259166193943
Validation loss: 2.5428258336118077

Epoch: 6| Step: 12
Training loss: 0.6718080176742379
Validation loss: 2.5477671331220213

Epoch: 6| Step: 13
Training loss: 0.7518483274680337
Validation loss: 2.5454134919686857

Epoch: 254| Step: 0
Training loss: 0.8137317637262088
Validation loss: 2.5247173522323485

Epoch: 6| Step: 1
Training loss: 1.268451877389397
Validation loss: 2.517007670321339

Epoch: 6| Step: 2
Training loss: 1.3652258614859953
Validation loss: 2.5201669066499868

Epoch: 6| Step: 3
Training loss: 0.5273477624811179
Validation loss: 2.4605600906579084

Epoch: 6| Step: 4
Training loss: 0.6751274076947521
Validation loss: 2.4656545673370673

Epoch: 6| Step: 5
Training loss: 1.1917600012732286
Validation loss: 2.4559056986945467

Epoch: 6| Step: 6
Training loss: 0.8574203456439237
Validation loss: 2.423573278864905

Epoch: 6| Step: 7
Training loss: 1.1074711218485358
Validation loss: 2.4618781616859424

Epoch: 6| Step: 8
Training loss: 1.1540990876245358
Validation loss: 2.4723316668993145

Epoch: 6| Step: 9
Training loss: 1.2854446968637228
Validation loss: 2.498285710768717

Epoch: 6| Step: 10
Training loss: 1.3645296692912763
Validation loss: 2.524806105216235

Epoch: 6| Step: 11
Training loss: 0.8468857176830962
Validation loss: 2.592499796508334

Epoch: 6| Step: 12
Training loss: 1.1804552422084549
Validation loss: 2.580788762060625

Epoch: 6| Step: 13
Training loss: 1.2759856490730292
Validation loss: 2.645979602954147

Epoch: 255| Step: 0
Training loss: 0.7747217940310364
Validation loss: 2.645312002024344

Epoch: 6| Step: 1
Training loss: 1.2236021240477817
Validation loss: 2.6060273795892175

Epoch: 6| Step: 2
Training loss: 0.8390137585454147
Validation loss: 2.5811439237912004

Epoch: 6| Step: 3
Training loss: 0.7545057690035211
Validation loss: 2.5506043766906488

Epoch: 6| Step: 4
Training loss: 0.8746626067222404
Validation loss: 2.533640754520719

Epoch: 6| Step: 5
Training loss: 0.6558192746943033
Validation loss: 2.502858229263291

Epoch: 6| Step: 6
Training loss: 1.5300896588402804
Validation loss: 2.4833391738572956

Epoch: 6| Step: 7
Training loss: 1.4135705503109783
Validation loss: 2.46657859395024

Epoch: 6| Step: 8
Training loss: 1.0284040078267922
Validation loss: 2.484688658883796

Epoch: 6| Step: 9
Training loss: 0.9378337583893994
Validation loss: 2.5030410871955353

Epoch: 6| Step: 10
Training loss: 0.9673284129099339
Validation loss: 2.5085343193674654

Epoch: 6| Step: 11
Training loss: 1.0560017062556324
Validation loss: 2.541318912678092

Epoch: 6| Step: 12
Training loss: 1.2610833425214105
Validation loss: 2.5382949506999246

Epoch: 6| Step: 13
Training loss: 1.0557144816424433
Validation loss: 2.519017556038829

Epoch: 256| Step: 0
Training loss: 1.5092946412234687
Validation loss: 2.5705345983692505

Epoch: 6| Step: 1
Training loss: 0.9212005540370725
Validation loss: 2.560015151181877

Epoch: 6| Step: 2
Training loss: 0.8424963644837857
Validation loss: 2.57168579518029

Epoch: 6| Step: 3
Training loss: 0.9438731372154586
Validation loss: 2.6051449525989003

Epoch: 6| Step: 4
Training loss: 0.7221995379683888
Validation loss: 2.6107488410856017

Epoch: 6| Step: 5
Training loss: 1.0140234423905246
Validation loss: 2.6151649316202605

Epoch: 6| Step: 6
Training loss: 0.9141746517401789
Validation loss: 2.63787350105862

Epoch: 6| Step: 7
Training loss: 1.1522950242942585
Validation loss: 2.600816636456275

Epoch: 6| Step: 8
Training loss: 1.112575052708601
Validation loss: 2.583093460039841

Epoch: 6| Step: 9
Training loss: 1.1217469229948225
Validation loss: 2.5247704092380543

Epoch: 6| Step: 10
Training loss: 1.255724957571276
Validation loss: 2.522375851351248

Epoch: 6| Step: 11
Training loss: 0.8315848285669124
Validation loss: 2.4946583342663473

Epoch: 6| Step: 12
Training loss: 1.337475744366186
Validation loss: 2.5161908628622314

Epoch: 6| Step: 13
Training loss: 0.3557588211180312
Validation loss: 2.492760096312338

Epoch: 257| Step: 0
Training loss: 1.2460849486611196
Validation loss: 2.564036508185369

Epoch: 6| Step: 1
Training loss: 0.6060304312933805
Validation loss: 2.5739771813810153

Epoch: 6| Step: 2
Training loss: 1.2177386856320962
Validation loss: 2.5946740709590754

Epoch: 6| Step: 3
Training loss: 0.8087236972641154
Validation loss: 2.5943033088063068

Epoch: 6| Step: 4
Training loss: 1.2687300281174188
Validation loss: 2.561614423026371

Epoch: 6| Step: 5
Training loss: 1.0278118503066294
Validation loss: 2.5674115134442284

Epoch: 6| Step: 6
Training loss: 0.720105510106915
Validation loss: 2.530331644434596

Epoch: 6| Step: 7
Training loss: 0.9429092439018536
Validation loss: 2.52358120353817

Epoch: 6| Step: 8
Training loss: 1.101032156468621
Validation loss: 2.5385195248883665

Epoch: 6| Step: 9
Training loss: 1.1250491661348418
Validation loss: 2.5653077866710396

Epoch: 6| Step: 10
Training loss: 1.2190592935769813
Validation loss: 2.534651207773107

Epoch: 6| Step: 11
Training loss: 0.9593859917324764
Validation loss: 2.572785787220782

Epoch: 6| Step: 12
Training loss: 0.9091985682115806
Validation loss: 2.5524305780844383

Epoch: 6| Step: 13
Training loss: 0.32043797663740076
Validation loss: 2.505927069863984

Epoch: 258| Step: 0
Training loss: 1.052857910155231
Validation loss: 2.5287468171504797

Epoch: 6| Step: 1
Training loss: 0.537034962441224
Validation loss: 2.57451617949041

Epoch: 6| Step: 2
Training loss: 1.3151526212421256
Validation loss: 2.5650644343744777

Epoch: 6| Step: 3
Training loss: 0.7985651380786909
Validation loss: 2.5667729971261686

Epoch: 6| Step: 4
Training loss: 0.7310342894390541
Validation loss: 2.5813187586423987

Epoch: 6| Step: 5
Training loss: 1.0120217005962482
Validation loss: 2.58335635075419

Epoch: 6| Step: 6
Training loss: 1.1574395221210734
Validation loss: 2.576420963339301

Epoch: 6| Step: 7
Training loss: 0.8634861491494518
Validation loss: 2.6189937485064974

Epoch: 6| Step: 8
Training loss: 1.1626834252965903
Validation loss: 2.618424615819781

Epoch: 6| Step: 9
Training loss: 1.3157227776589002
Validation loss: 2.5994292834198105

Epoch: 6| Step: 10
Training loss: 0.6683297548134843
Validation loss: 2.62715653153763

Epoch: 6| Step: 11
Training loss: 1.1501884347532205
Validation loss: 2.5997455547356414

Epoch: 6| Step: 12
Training loss: 0.9554347209219991
Validation loss: 2.5720219611911865

Epoch: 6| Step: 13
Training loss: 1.0948558121946743
Validation loss: 2.5906805939861166

Epoch: 259| Step: 0
Training loss: 0.9516722128874063
Validation loss: 2.6083332448492342

Epoch: 6| Step: 1
Training loss: 1.1617982079141265
Validation loss: 2.567935681854647

Epoch: 6| Step: 2
Training loss: 0.71295027809868
Validation loss: 2.5585155117832645

Epoch: 6| Step: 3
Training loss: 1.2592780064037128
Validation loss: 2.5504583027346714

Epoch: 6| Step: 4
Training loss: 1.2113506965785417
Validation loss: 2.5391363156224385

Epoch: 6| Step: 5
Training loss: 0.7492577535681852
Validation loss: 2.5478482239361187

Epoch: 6| Step: 6
Training loss: 1.1198744040980575
Validation loss: 2.5261180120631215

Epoch: 6| Step: 7
Training loss: 1.0707965508067367
Validation loss: 2.4976119171946762

Epoch: 6| Step: 8
Training loss: 0.659029365636344
Validation loss: 2.4796132297087166

Epoch: 6| Step: 9
Training loss: 0.9610481818740689
Validation loss: 2.5190543471662266

Epoch: 6| Step: 10
Training loss: 0.9772564063009825
Validation loss: 2.5150111927326595

Epoch: 6| Step: 11
Training loss: 0.8759569657088901
Validation loss: 2.5300341681110963

Epoch: 6| Step: 12
Training loss: 0.8928123851184551
Validation loss: 2.5487437078546176

Epoch: 6| Step: 13
Training loss: 1.3319813112087662
Validation loss: 2.5619231844672776

Epoch: 260| Step: 0
Training loss: 0.7780329653686583
Validation loss: 2.5110607479190556

Epoch: 6| Step: 1
Training loss: 0.9295963274704289
Validation loss: 2.5154892029972302

Epoch: 6| Step: 2
Training loss: 1.1400745579113414
Validation loss: 2.4917334897405974

Epoch: 6| Step: 3
Training loss: 0.9029964711953596
Validation loss: 2.504326538526725

Epoch: 6| Step: 4
Training loss: 1.0259524014494912
Validation loss: 2.5014132319942752

Epoch: 6| Step: 5
Training loss: 0.9627204419642887
Validation loss: 2.5009468285284453

Epoch: 6| Step: 6
Training loss: 0.9794170316575774
Validation loss: 2.508559633120101

Epoch: 6| Step: 7
Training loss: 1.062719883325347
Validation loss: 2.5547541037385124

Epoch: 6| Step: 8
Training loss: 1.2227334677593114
Validation loss: 2.555956768522554

Epoch: 6| Step: 9
Training loss: 0.9721303230327284
Validation loss: 2.5665537835979486

Epoch: 6| Step: 10
Training loss: 1.030380981039218
Validation loss: 2.617669481524744

Epoch: 6| Step: 11
Training loss: 0.9617025229900212
Validation loss: 2.5841242323487843

Epoch: 6| Step: 12
Training loss: 0.7162164734188748
Validation loss: 2.558596137198423

Epoch: 6| Step: 13
Training loss: 1.1274613898659358
Validation loss: 2.56108805246377

Epoch: 261| Step: 0
Training loss: 0.7553177502173075
Validation loss: 2.5730602026250424

Epoch: 6| Step: 1
Training loss: 1.0767344477274103
Validation loss: 2.523756297577116

Epoch: 6| Step: 2
Training loss: 0.7023183434020855
Validation loss: 2.551268299807254

Epoch: 6| Step: 3
Training loss: 1.0755237767115382
Validation loss: 2.5293359663889703

Epoch: 6| Step: 4
Training loss: 1.289562983601393
Validation loss: 2.5437442267604022

Epoch: 6| Step: 5
Training loss: 1.2535345649655436
Validation loss: 2.5814201350754735

Epoch: 6| Step: 6
Training loss: 1.1101522812044207
Validation loss: 2.5515046967787818

Epoch: 6| Step: 7
Training loss: 0.702258742028508
Validation loss: 2.5425568616551715

Epoch: 6| Step: 8
Training loss: 0.7954209843900206
Validation loss: 2.5517676932797166

Epoch: 6| Step: 9
Training loss: 0.8855753513329562
Validation loss: 2.5289679190429544

Epoch: 6| Step: 10
Training loss: 0.6622390845073501
Validation loss: 2.4809842649582348

Epoch: 6| Step: 11
Training loss: 1.1634549597271047
Validation loss: 2.4641223368736807

Epoch: 6| Step: 12
Training loss: 0.7419295816501068
Validation loss: 2.4850426275562336

Epoch: 6| Step: 13
Training loss: 1.161418087294788
Validation loss: 2.4744814636461685

Epoch: 262| Step: 0
Training loss: 0.9344096429328891
Validation loss: 2.5226160585120554

Epoch: 6| Step: 1
Training loss: 1.2871580447544926
Validation loss: 2.4642429459770314

Epoch: 6| Step: 2
Training loss: 0.9175742742425983
Validation loss: 2.4783671775434755

Epoch: 6| Step: 3
Training loss: 1.1875482348634343
Validation loss: 2.5039603714923944

Epoch: 6| Step: 4
Training loss: 0.766004234902351
Validation loss: 2.535851255941397

Epoch: 6| Step: 5
Training loss: 1.0195583179139998
Validation loss: 2.553269142235685

Epoch: 6| Step: 6
Training loss: 1.1058036916842615
Validation loss: 2.569651516995062

Epoch: 6| Step: 7
Training loss: 0.5692224667574649
Validation loss: 2.530519253141198

Epoch: 6| Step: 8
Training loss: 1.0235577578178832
Validation loss: 2.5353017666932836

Epoch: 6| Step: 9
Training loss: 1.0771494335401672
Validation loss: 2.499236188616778

Epoch: 6| Step: 10
Training loss: 1.087654786768607
Validation loss: 2.441104487189123

Epoch: 6| Step: 11
Training loss: 0.7791360866101184
Validation loss: 2.468858863151016

Epoch: 6| Step: 12
Training loss: 0.5407714017088678
Validation loss: 2.479109428312371

Epoch: 6| Step: 13
Training loss: 1.1535598803232778
Validation loss: 2.518057714215649

Epoch: 263| Step: 0
Training loss: 0.8546898836594281
Validation loss: 2.4923126799266666

Epoch: 6| Step: 1
Training loss: 0.9264466031493334
Validation loss: 2.5710053332837823

Epoch: 6| Step: 2
Training loss: 1.2748841102140689
Validation loss: 2.5782803286996594

Epoch: 6| Step: 3
Training loss: 0.8128961917626095
Validation loss: 2.5569723523178602

Epoch: 6| Step: 4
Training loss: 1.238190127127673
Validation loss: 2.558415648195099

Epoch: 6| Step: 5
Training loss: 1.1414101393657532
Validation loss: 2.602709329366182

Epoch: 6| Step: 6
Training loss: 0.8957326558930865
Validation loss: 2.538160722879432

Epoch: 6| Step: 7
Training loss: 0.7083068637016086
Validation loss: 2.5444196668706542

Epoch: 6| Step: 8
Training loss: 0.8895042461703475
Validation loss: 2.538202344214199

Epoch: 6| Step: 9
Training loss: 1.0507618501708824
Validation loss: 2.5403349696239936

Epoch: 6| Step: 10
Training loss: 0.9241326054131492
Validation loss: 2.5575231849111

Epoch: 6| Step: 11
Training loss: 0.9002456382808941
Validation loss: 2.532329872852032

Epoch: 6| Step: 12
Training loss: 0.768438308609905
Validation loss: 2.5458217647238555

Epoch: 6| Step: 13
Training loss: 1.2849632048626731
Validation loss: 2.5588606455282314

Epoch: 264| Step: 0
Training loss: 0.7408357054933803
Validation loss: 2.5144021031165438

Epoch: 6| Step: 1
Training loss: 0.908442541580199
Validation loss: 2.5401909770657856

Epoch: 6| Step: 2
Training loss: 0.6770120338655128
Validation loss: 2.5563639125038335

Epoch: 6| Step: 3
Training loss: 0.8743479887994128
Validation loss: 2.4967083323689114

Epoch: 6| Step: 4
Training loss: 1.1304757055399466
Validation loss: 2.5156911378743394

Epoch: 6| Step: 5
Training loss: 0.8397370736438089
Validation loss: 2.478353667115356

Epoch: 6| Step: 6
Training loss: 1.20110200508172
Validation loss: 2.5480049616727567

Epoch: 6| Step: 7
Training loss: 1.2376917449673415
Validation loss: 2.535754504346713

Epoch: 6| Step: 8
Training loss: 0.6393108379727646
Validation loss: 2.541952790512732

Epoch: 6| Step: 9
Training loss: 0.6905911916337314
Validation loss: 2.5279774548840974

Epoch: 6| Step: 10
Training loss: 0.7610809394636996
Validation loss: 2.5269159229828992

Epoch: 6| Step: 11
Training loss: 1.129970062500696
Validation loss: 2.536400512944581

Epoch: 6| Step: 12
Training loss: 0.845445589316895
Validation loss: 2.5526397657669024

Epoch: 6| Step: 13
Training loss: 1.5872396000232858
Validation loss: 2.548794788165687

Epoch: 265| Step: 0
Training loss: 0.9272169095509302
Validation loss: 2.5688812093805296

Epoch: 6| Step: 1
Training loss: 0.5785434600294939
Validation loss: 2.603067001655693

Epoch: 6| Step: 2
Training loss: 1.0815147516776245
Validation loss: 2.550739949501378

Epoch: 6| Step: 3
Training loss: 0.6019412248092395
Validation loss: 2.5908646836933324

Epoch: 6| Step: 4
Training loss: 0.5388017936203038
Validation loss: 2.5565689472822473

Epoch: 6| Step: 5
Training loss: 1.1132039361174804
Validation loss: 2.5740528690924482

Epoch: 6| Step: 6
Training loss: 0.8910827129816945
Validation loss: 2.5853772276587623

Epoch: 6| Step: 7
Training loss: 1.189259781180369
Validation loss: 2.611986634185883

Epoch: 6| Step: 8
Training loss: 0.8176293223572534
Validation loss: 2.5772702776300296

Epoch: 6| Step: 9
Training loss: 1.0939624035179039
Validation loss: 2.5749666529024506

Epoch: 6| Step: 10
Training loss: 1.0068450542521896
Validation loss: 2.5346675606377373

Epoch: 6| Step: 11
Training loss: 1.0120517374202729
Validation loss: 2.5209207183192635

Epoch: 6| Step: 12
Training loss: 1.2042636684871881
Validation loss: 2.511155439275907

Epoch: 6| Step: 13
Training loss: 0.8239754412611542
Validation loss: 2.498705656043957

Epoch: 266| Step: 0
Training loss: 1.0526450266104568
Validation loss: 2.510467711232551

Epoch: 6| Step: 1
Training loss: 0.9727554883466297
Validation loss: 2.5403249777701027

Epoch: 6| Step: 2
Training loss: 0.9463930496068624
Validation loss: 2.542182854481018

Epoch: 6| Step: 3
Training loss: 0.5338591846757463
Validation loss: 2.5522003213982902

Epoch: 6| Step: 4
Training loss: 0.8188286576088708
Validation loss: 2.5688630105179047

Epoch: 6| Step: 5
Training loss: 0.9199037003392239
Validation loss: 2.5773146811732377

Epoch: 6| Step: 6
Training loss: 0.8588939707646688
Validation loss: 2.5783128139863147

Epoch: 6| Step: 7
Training loss: 0.6510742764253363
Validation loss: 2.5601800731086115

Epoch: 6| Step: 8
Training loss: 0.9121861558246281
Validation loss: 2.5486350712821544

Epoch: 6| Step: 9
Training loss: 1.1300157420994532
Validation loss: 2.568027024195178

Epoch: 6| Step: 10
Training loss: 0.9195572764327967
Validation loss: 2.5820275902510796

Epoch: 6| Step: 11
Training loss: 1.2537817016731578
Validation loss: 2.552154139896159

Epoch: 6| Step: 12
Training loss: 1.19788915630209
Validation loss: 2.5229755642844403

Epoch: 6| Step: 13
Training loss: 0.9367778539901765
Validation loss: 2.508432261569387

Epoch: 267| Step: 0
Training loss: 1.0245525895561312
Validation loss: 2.511962619535374

Epoch: 6| Step: 1
Training loss: 0.6981841803510986
Validation loss: 2.4882385267753366

Epoch: 6| Step: 2
Training loss: 1.146013361342
Validation loss: 2.5020291881381276

Epoch: 6| Step: 3
Training loss: 0.8773286351084885
Validation loss: 2.549776062853204

Epoch: 6| Step: 4
Training loss: 1.0569910959538207
Validation loss: 2.546089805760546

Epoch: 6| Step: 5
Training loss: 1.1512320635762072
Validation loss: 2.5575495316452312

Epoch: 6| Step: 6
Training loss: 1.124817992428283
Validation loss: 2.556392993884447

Epoch: 6| Step: 7
Training loss: 1.0374852880331036
Validation loss: 2.549898902245012

Epoch: 6| Step: 8
Training loss: 0.6587657617858497
Validation loss: 2.5507498533199877

Epoch: 6| Step: 9
Training loss: 0.8982493327918947
Validation loss: 2.5121682034649866

Epoch: 6| Step: 10
Training loss: 0.6042040999643724
Validation loss: 2.505346835258739

Epoch: 6| Step: 11
Training loss: 0.3016335438270381
Validation loss: 2.4928368893665875

Epoch: 6| Step: 12
Training loss: 1.3487722889611435
Validation loss: 2.5324902804555167

Epoch: 6| Step: 13
Training loss: 0.3711338824606142
Validation loss: 2.5263953650256314

Epoch: 268| Step: 0
Training loss: 0.7126883860047897
Validation loss: 2.533191058711358

Epoch: 6| Step: 1
Training loss: 0.6980629430799011
Validation loss: 2.565915556391811

Epoch: 6| Step: 2
Training loss: 1.1437218313448476
Validation loss: 2.5312965790860886

Epoch: 6| Step: 3
Training loss: 1.085542456036908
Validation loss: 2.550133202443929

Epoch: 6| Step: 4
Training loss: 1.1111423223138481
Validation loss: 2.5642675386000655

Epoch: 6| Step: 5
Training loss: 0.6408578403021575
Validation loss: 2.589872114923608

Epoch: 6| Step: 6
Training loss: 0.7358663714916943
Validation loss: 2.5763070686003116

Epoch: 6| Step: 7
Training loss: 1.121596858151208
Validation loss: 2.490524843709317

Epoch: 6| Step: 8
Training loss: 0.9383045876528355
Validation loss: 2.5140371935140577

Epoch: 6| Step: 9
Training loss: 0.843428727196562
Validation loss: 2.488654611957254

Epoch: 6| Step: 10
Training loss: 0.9814885827390085
Validation loss: 2.490234317349251

Epoch: 6| Step: 11
Training loss: 0.9194424426705914
Validation loss: 2.5056648451596804

Epoch: 6| Step: 12
Training loss: 1.1271887785732715
Validation loss: 2.513179982164991

Epoch: 6| Step: 13
Training loss: 0.6293670671980204
Validation loss: 2.5451503974012577

Epoch: 269| Step: 0
Training loss: 0.7817350026525954
Validation loss: 2.5606959245377428

Epoch: 6| Step: 1
Training loss: 0.976784947809221
Validation loss: 2.5484046728552987

Epoch: 6| Step: 2
Training loss: 1.1400548476694357
Validation loss: 2.5801749622721686

Epoch: 6| Step: 3
Training loss: 0.9775798533767399
Validation loss: 2.559373125840906

Epoch: 6| Step: 4
Training loss: 0.9303532628824943
Validation loss: 2.5157933526280285

Epoch: 6| Step: 5
Training loss: 0.35171052147803344
Validation loss: 2.520123542420907

Epoch: 6| Step: 6
Training loss: 1.1630162395153667
Validation loss: 2.5213938360880634

Epoch: 6| Step: 7
Training loss: 0.8675587177467605
Validation loss: 2.491456309162571

Epoch: 6| Step: 8
Training loss: 0.6788878944294825
Validation loss: 2.48342652808408

Epoch: 6| Step: 9
Training loss: 0.6695241609462914
Validation loss: 2.534496693887003

Epoch: 6| Step: 10
Training loss: 0.9547527359620853
Validation loss: 2.5053567819132216

Epoch: 6| Step: 11
Training loss: 0.8212750555016545
Validation loss: 2.520744593363571

Epoch: 6| Step: 12
Training loss: 1.081729888263572
Validation loss: 2.5332846809981926

Epoch: 6| Step: 13
Training loss: 1.01292177057543
Validation loss: 2.5178294381806348

Epoch: 270| Step: 0
Training loss: 0.8752612337068699
Validation loss: 2.5497881240537055

Epoch: 6| Step: 1
Training loss: 0.680228314147635
Validation loss: 2.547509182973792

Epoch: 6| Step: 2
Training loss: 0.8508456301259788
Validation loss: 2.519376429012341

Epoch: 6| Step: 3
Training loss: 0.627506570363697
Validation loss: 2.4895957904932557

Epoch: 6| Step: 4
Training loss: 0.916715309990969
Validation loss: 2.519830751658766

Epoch: 6| Step: 5
Training loss: 1.0545615226954952
Validation loss: 2.5124655217406078

Epoch: 6| Step: 6
Training loss: 1.0141969471164283
Validation loss: 2.541331939066287

Epoch: 6| Step: 7
Training loss: 1.1231743516305768
Validation loss: 2.517202196905614

Epoch: 6| Step: 8
Training loss: 1.0813467566797261
Validation loss: 2.4813605019038825

Epoch: 6| Step: 9
Training loss: 0.9971984123414733
Validation loss: 2.5342625402921963

Epoch: 6| Step: 10
Training loss: 0.6836007690069339
Validation loss: 2.541854456744434

Epoch: 6| Step: 11
Training loss: 0.48958538609608676
Validation loss: 2.5473850710073664

Epoch: 6| Step: 12
Training loss: 0.9898183275915838
Validation loss: 2.548362454097529

Epoch: 6| Step: 13
Training loss: 0.9519286229639692
Validation loss: 2.5463014665648305

Epoch: 271| Step: 0
Training loss: 1.039486504570357
Validation loss: 2.552069839800149

Epoch: 6| Step: 1
Training loss: 1.2126369241698973
Validation loss: 2.587929118592416

Epoch: 6| Step: 2
Training loss: 0.8789058430988641
Validation loss: 2.561225219869974

Epoch: 6| Step: 3
Training loss: 0.6080028784944131
Validation loss: 2.5125127051769987

Epoch: 6| Step: 4
Training loss: 0.8407712561001527
Validation loss: 2.4971937015878938

Epoch: 6| Step: 5
Training loss: 0.7363295011229266
Validation loss: 2.488275948144044

Epoch: 6| Step: 6
Training loss: 0.9220461605684857
Validation loss: 2.472375727835256

Epoch: 6| Step: 7
Training loss: 1.1843537764044199
Validation loss: 2.4843493652672253

Epoch: 6| Step: 8
Training loss: 0.6635944512141012
Validation loss: 2.499772102469172

Epoch: 6| Step: 9
Training loss: 1.3243616527768713
Validation loss: 2.556599183007845

Epoch: 6| Step: 10
Training loss: 0.6896713170934501
Validation loss: 2.529832447847397

Epoch: 6| Step: 11
Training loss: 0.7808675974517454
Validation loss: 2.585121622143936

Epoch: 6| Step: 12
Training loss: 0.6808359375168089
Validation loss: 2.5910496389278643

Epoch: 6| Step: 13
Training loss: 0.5557049298803483
Validation loss: 2.6287113391649135

Epoch: 272| Step: 0
Training loss: 0.37783893215082054
Validation loss: 2.568235058308078

Epoch: 6| Step: 1
Training loss: 0.9932342174436948
Validation loss: 2.6103919876137125

Epoch: 6| Step: 2
Training loss: 0.6838992716742837
Validation loss: 2.626196922880319

Epoch: 6| Step: 3
Training loss: 0.7183242034184396
Validation loss: 2.5733047544059304

Epoch: 6| Step: 4
Training loss: 0.8908315051077581
Validation loss: 2.610648074738322

Epoch: 6| Step: 5
Training loss: 1.2638991091155463
Validation loss: 2.5521472590570466

Epoch: 6| Step: 6
Training loss: 1.138357024069627
Validation loss: 2.519762915513909

Epoch: 6| Step: 7
Training loss: 1.1277924953767753
Validation loss: 2.5163153596180927

Epoch: 6| Step: 8
Training loss: 0.8383244456230239
Validation loss: 2.5073839149222734

Epoch: 6| Step: 9
Training loss: 1.0410325727103105
Validation loss: 2.508062318090615

Epoch: 6| Step: 10
Training loss: 0.8540635085422718
Validation loss: 2.523783425481231

Epoch: 6| Step: 11
Training loss: 0.5812173054841927
Validation loss: 2.5477222920839555

Epoch: 6| Step: 12
Training loss: 1.0362556808923369
Validation loss: 2.5568711741468384

Epoch: 6| Step: 13
Training loss: 0.6154323198897159
Validation loss: 2.5929146548392947

Epoch: 273| Step: 0
Training loss: 1.03541682580426
Validation loss: 2.576610378066627

Epoch: 6| Step: 1
Training loss: 0.6546498954734407
Validation loss: 2.597181360082958

Epoch: 6| Step: 2
Training loss: 1.0899363926168175
Validation loss: 2.6092951689129777

Epoch: 6| Step: 3
Training loss: 0.6869210493151658
Validation loss: 2.597757105812788

Epoch: 6| Step: 4
Training loss: 0.8472794429202766
Validation loss: 2.628193790909483

Epoch: 6| Step: 5
Training loss: 1.032865415016896
Validation loss: 2.5604295016688408

Epoch: 6| Step: 6
Training loss: 0.7760123347599869
Validation loss: 2.5153712956987877

Epoch: 6| Step: 7
Training loss: 0.8170898349963024
Validation loss: 2.5273634640422347

Epoch: 6| Step: 8
Training loss: 0.7542161057708205
Validation loss: 2.5645793109026327

Epoch: 6| Step: 9
Training loss: 1.2240756147751886
Validation loss: 2.546640499695478

Epoch: 6| Step: 10
Training loss: 0.8773704844042148
Validation loss: 2.559166499557963

Epoch: 6| Step: 11
Training loss: 0.58063783198242
Validation loss: 2.5887456366939245

Epoch: 6| Step: 12
Training loss: 0.7965281984734045
Validation loss: 2.608272531560754

Epoch: 6| Step: 13
Training loss: 0.9490842684703975
Validation loss: 2.562825576184265

Epoch: 274| Step: 0
Training loss: 0.809288095352418
Validation loss: 2.5878317482508617

Epoch: 6| Step: 1
Training loss: 0.9167774668111389
Validation loss: 2.6120507855943638

Epoch: 6| Step: 2
Training loss: 0.8349696822572954
Validation loss: 2.595603433861266

Epoch: 6| Step: 3
Training loss: 0.6418850996565644
Validation loss: 2.5803509819816064

Epoch: 6| Step: 4
Training loss: 0.6480841075831605
Validation loss: 2.5650348966090455

Epoch: 6| Step: 5
Training loss: 0.8395930426125321
Validation loss: 2.5504792322696623

Epoch: 6| Step: 6
Training loss: 0.9533815507654986
Validation loss: 2.503089869860039

Epoch: 6| Step: 7
Training loss: 1.069787168013571
Validation loss: 2.538815041623954

Epoch: 6| Step: 8
Training loss: 0.7714432331172884
Validation loss: 2.5148325483203555

Epoch: 6| Step: 9
Training loss: 0.8392044117863405
Validation loss: 2.4953153906009042

Epoch: 6| Step: 10
Training loss: 1.1302482785433505
Validation loss: 2.513454936399774

Epoch: 6| Step: 11
Training loss: 0.8684280045777121
Validation loss: 2.557448571780807

Epoch: 6| Step: 12
Training loss: 0.738845286799769
Validation loss: 2.537210975455524

Epoch: 6| Step: 13
Training loss: 0.9112402228104303
Validation loss: 2.5490833358849314

Epoch: 275| Step: 0
Training loss: 0.9415705367339436
Validation loss: 2.5387183858134685

Epoch: 6| Step: 1
Training loss: 1.164517512136154
Validation loss: 2.5800842417733225

Epoch: 6| Step: 2
Training loss: 0.5166254452699541
Validation loss: 2.5899508421681463

Epoch: 6| Step: 3
Training loss: 0.7233307036631844
Validation loss: 2.5638747030648243

Epoch: 6| Step: 4
Training loss: 0.7989082576040838
Validation loss: 2.571830773114415

Epoch: 6| Step: 5
Training loss: 0.9666970249593914
Validation loss: 2.5719702955812602

Epoch: 6| Step: 6
Training loss: 0.5125364220865689
Validation loss: 2.578820563760654

Epoch: 6| Step: 7
Training loss: 1.0555073695031696
Validation loss: 2.613396218254071

Epoch: 6| Step: 8
Training loss: 0.6339850453333857
Validation loss: 2.6130212100504098

Epoch: 6| Step: 9
Training loss: 0.8225438967762577
Validation loss: 2.576374521441991

Epoch: 6| Step: 10
Training loss: 0.8646513134684707
Validation loss: 2.5547576971922408

Epoch: 6| Step: 11
Training loss: 1.151218602086784
Validation loss: 2.571898115090564

Epoch: 6| Step: 12
Training loss: 0.8870747393587042
Validation loss: 2.570950686188772

Epoch: 6| Step: 13
Training loss: 0.39388236893831047
Validation loss: 2.5497301692425363

Epoch: 276| Step: 0
Training loss: 0.9798801372659596
Validation loss: 2.545518885637218

Epoch: 6| Step: 1
Training loss: 0.6086050696048702
Validation loss: 2.552535324470134

Epoch: 6| Step: 2
Training loss: 1.1256019253565868
Validation loss: 2.5677335904670584

Epoch: 6| Step: 3
Training loss: 0.793943886092853
Validation loss: 2.5286541400433897

Epoch: 6| Step: 4
Training loss: 0.8054632503051664
Validation loss: 2.505931466846609

Epoch: 6| Step: 5
Training loss: 0.8692547326780586
Validation loss: 2.517648054512886

Epoch: 6| Step: 6
Training loss: 0.6141040652041919
Validation loss: 2.505839910214124

Epoch: 6| Step: 7
Training loss: 0.820316859642433
Validation loss: 2.556491052228818

Epoch: 6| Step: 8
Training loss: 0.7329163369992548
Validation loss: 2.507032222228207

Epoch: 6| Step: 9
Training loss: 0.6345835263140713
Validation loss: 2.506138153154082

Epoch: 6| Step: 10
Training loss: 0.6072764084492983
Validation loss: 2.5694029766913404

Epoch: 6| Step: 11
Training loss: 0.9701323337344088
Validation loss: 2.5450258369841925

Epoch: 6| Step: 12
Training loss: 0.8127154284762967
Validation loss: 2.5137859106703924

Epoch: 6| Step: 13
Training loss: 1.222844898429324
Validation loss: 2.5386420707864925

Epoch: 277| Step: 0
Training loss: 0.6448277571709765
Validation loss: 2.538678237197178

Epoch: 6| Step: 1
Training loss: 1.1275121931782761
Validation loss: 2.510218767765139

Epoch: 6| Step: 2
Training loss: 0.9338600385445475
Validation loss: 2.4944593420723544

Epoch: 6| Step: 3
Training loss: 0.5381736614630802
Validation loss: 2.5073982555745014

Epoch: 6| Step: 4
Training loss: 0.8920214229542918
Validation loss: 2.5348919310493656

Epoch: 6| Step: 5
Training loss: 0.876643680614439
Validation loss: 2.5286095714194197

Epoch: 6| Step: 6
Training loss: 0.807003798484135
Validation loss: 2.5823619026958142

Epoch: 6| Step: 7
Training loss: 1.050576796370461
Validation loss: 2.538210694053731

Epoch: 6| Step: 8
Training loss: 0.49059379745688253
Validation loss: 2.543593378590061

Epoch: 6| Step: 9
Training loss: 0.9507007724677371
Validation loss: 2.5531642979325078

Epoch: 6| Step: 10
Training loss: 0.9410599194177326
Validation loss: 2.5467362448171738

Epoch: 6| Step: 11
Training loss: 0.6264797336774164
Validation loss: 2.5688380622185236

Epoch: 6| Step: 12
Training loss: 0.82481290545334
Validation loss: 2.5589904703034634

Epoch: 6| Step: 13
Training loss: 0.598871653269392
Validation loss: 2.586100920467322

Epoch: 278| Step: 0
Training loss: 1.3290375659791382
Validation loss: 2.5619257812055864

Epoch: 6| Step: 1
Training loss: 1.2247340186050317
Validation loss: 2.5594002268107108

Epoch: 6| Step: 2
Training loss: 0.6167856429214619
Validation loss: 2.5577786126972337

Epoch: 6| Step: 3
Training loss: 0.7881391429312802
Validation loss: 2.5291971794926376

Epoch: 6| Step: 4
Training loss: 0.9833668587244465
Validation loss: 2.5366077718085176

Epoch: 6| Step: 5
Training loss: 0.742120639399484
Validation loss: 2.5486517563895372

Epoch: 6| Step: 6
Training loss: 0.7729034892258747
Validation loss: 2.5580497774016804

Epoch: 6| Step: 7
Training loss: 0.77978213697218
Validation loss: 2.523078678838029

Epoch: 6| Step: 8
Training loss: 0.7621936198196496
Validation loss: 2.5621835136509383

Epoch: 6| Step: 9
Training loss: 0.8410865282503046
Validation loss: 2.5016962818549113

Epoch: 6| Step: 10
Training loss: 0.5111338643466621
Validation loss: 2.522183874064987

Epoch: 6| Step: 11
Training loss: 0.33530480664858464
Validation loss: 2.496712003205595

Epoch: 6| Step: 12
Training loss: 0.7434516981708513
Validation loss: 2.459265800259868

Epoch: 6| Step: 13
Training loss: 0.5067197339392139
Validation loss: 2.484551776693435

Epoch: 279| Step: 0
Training loss: 0.8543239929332597
Validation loss: 2.4803289424275152

Epoch: 6| Step: 1
Training loss: 1.0768713919058301
Validation loss: 2.501999379581938

Epoch: 6| Step: 2
Training loss: 0.9427547057041181
Validation loss: 2.507991229953326

Epoch: 6| Step: 3
Training loss: 0.8120592462390371
Validation loss: 2.5502889267017763

Epoch: 6| Step: 4
Training loss: 0.9421973802038998
Validation loss: 2.5730503428338447

Epoch: 6| Step: 5
Training loss: 0.5507982129670534
Validation loss: 2.545976571048501

Epoch: 6| Step: 6
Training loss: 0.7557992048735321
Validation loss: 2.5833295487353984

Epoch: 6| Step: 7
Training loss: 0.6078474755508606
Validation loss: 2.556564074837195

Epoch: 6| Step: 8
Training loss: 1.0269355107854012
Validation loss: 2.574749766917939

Epoch: 6| Step: 9
Training loss: 0.6857858442394686
Validation loss: 2.5189689352781617

Epoch: 6| Step: 10
Training loss: 0.937365554070153
Validation loss: 2.5001381805133076

Epoch: 6| Step: 11
Training loss: 0.5082423518271983
Validation loss: 2.501359435627381

Epoch: 6| Step: 12
Training loss: 0.8780104416484854
Validation loss: 2.511813848279109

Epoch: 6| Step: 13
Training loss: 0.5505940815951501
Validation loss: 2.513801007715859

Epoch: 280| Step: 0
Training loss: 0.9508188834222139
Validation loss: 2.5214381342037595

Epoch: 6| Step: 1
Training loss: 0.7777432895764522
Validation loss: 2.5269776119486065

Epoch: 6| Step: 2
Training loss: 0.4221691942517055
Validation loss: 2.512423906687713

Epoch: 6| Step: 3
Training loss: 0.8491667548214833
Validation loss: 2.549471340757986

Epoch: 6| Step: 4
Training loss: 0.9841853064974513
Validation loss: 2.5385732265483942

Epoch: 6| Step: 5
Training loss: 0.7985119182148686
Validation loss: 2.52764353391349

Epoch: 6| Step: 6
Training loss: 0.9584796766137336
Validation loss: 2.542706322487181

Epoch: 6| Step: 7
Training loss: 0.7306562376890724
Validation loss: 2.493090261590503

Epoch: 6| Step: 8
Training loss: 0.6578804153213702
Validation loss: 2.484877327329335

Epoch: 6| Step: 9
Training loss: 0.8625902197824015
Validation loss: 2.50298371897903

Epoch: 6| Step: 10
Training loss: 0.8237738108920043
Validation loss: 2.477181355724888

Epoch: 6| Step: 11
Training loss: 0.9693984045945425
Validation loss: 2.470456192262471

Epoch: 6| Step: 12
Training loss: 0.6777565812312354
Validation loss: 2.5071807577771352

Epoch: 6| Step: 13
Training loss: 0.9324943421629397
Validation loss: 2.5091056731403594

Epoch: 281| Step: 0
Training loss: 0.7679563565966538
Validation loss: 2.5088269447474665

Epoch: 6| Step: 1
Training loss: 0.8817561082836594
Validation loss: 2.559090073537989

Epoch: 6| Step: 2
Training loss: 0.6341462855211542
Validation loss: 2.5430337432484267

Epoch: 6| Step: 3
Training loss: 1.0221708190359253
Validation loss: 2.552733800556132

Epoch: 6| Step: 4
Training loss: 0.7870695421159346
Validation loss: 2.5690840267601

Epoch: 6| Step: 5
Training loss: 0.44184333968418343
Validation loss: 2.532433687175679

Epoch: 6| Step: 6
Training loss: 0.6679950508159904
Validation loss: 2.554273764705207

Epoch: 6| Step: 7
Training loss: 0.7993968254372765
Validation loss: 2.5526308233785135

Epoch: 6| Step: 8
Training loss: 0.9323051529802182
Validation loss: 2.5516590347487225

Epoch: 6| Step: 9
Training loss: 0.8299331717991258
Validation loss: 2.5699277185159968

Epoch: 6| Step: 10
Training loss: 1.029854031932391
Validation loss: 2.5467702689430864

Epoch: 6| Step: 11
Training loss: 0.9140727702810943
Validation loss: 2.5283263425716656

Epoch: 6| Step: 12
Training loss: 0.7446410731587958
Validation loss: 2.5261994745918783

Epoch: 6| Step: 13
Training loss: 0.7481808853628179
Validation loss: 2.5313653609466282

Epoch: 282| Step: 0
Training loss: 1.1344644537510402
Validation loss: 2.5117901245686998

Epoch: 6| Step: 1
Training loss: 0.6566529399345624
Validation loss: 2.5349406595281523

Epoch: 6| Step: 2
Training loss: 1.0362982442597828
Validation loss: 2.5194102492343204

Epoch: 6| Step: 3
Training loss: 0.6724887971760352
Validation loss: 2.5246211300021875

Epoch: 6| Step: 4
Training loss: 0.9314271694343306
Validation loss: 2.5268635035268145

Epoch: 6| Step: 5
Training loss: 0.4850526806643938
Validation loss: 2.5762033748332773

Epoch: 6| Step: 6
Training loss: 0.48925513230615686
Validation loss: 2.546617968184436

Epoch: 6| Step: 7
Training loss: 0.908665430680589
Validation loss: 2.5622755883308788

Epoch: 6| Step: 8
Training loss: 1.1616588584787082
Validation loss: 2.4852900729808876

Epoch: 6| Step: 9
Training loss: 0.5002846503622633
Validation loss: 2.54038316833806

Epoch: 6| Step: 10
Training loss: 0.39220112400783835
Validation loss: 2.5634470904443805

Epoch: 6| Step: 11
Training loss: 0.8688523746794121
Validation loss: 2.545312648501673

Epoch: 6| Step: 12
Training loss: 0.703834366594472
Validation loss: 2.561417027412187

Epoch: 6| Step: 13
Training loss: 0.6666175158581441
Validation loss: 2.5252139894789956

Epoch: 283| Step: 0
Training loss: 0.7191504316681805
Validation loss: 2.5296388002932275

Epoch: 6| Step: 1
Training loss: 0.9663483783537192
Validation loss: 2.505702006275313

Epoch: 6| Step: 2
Training loss: 0.8447164369538549
Validation loss: 2.5176524564819216

Epoch: 6| Step: 3
Training loss: 1.031798823575678
Validation loss: 2.5383881249329403

Epoch: 6| Step: 4
Training loss: 0.4544709538777043
Validation loss: 2.5285460486202638

Epoch: 6| Step: 5
Training loss: 0.857344778153109
Validation loss: 2.5224699106192965

Epoch: 6| Step: 6
Training loss: 0.8410491454748125
Validation loss: 2.55274802603801

Epoch: 6| Step: 7
Training loss: 0.6675889792768049
Validation loss: 2.530034895648192

Epoch: 6| Step: 8
Training loss: 1.0406220284267762
Validation loss: 2.571608305186527

Epoch: 6| Step: 9
Training loss: 0.5340862297022821
Validation loss: 2.584412283624185

Epoch: 6| Step: 10
Training loss: 0.7705199962276381
Validation loss: 2.6259017758752576

Epoch: 6| Step: 11
Training loss: 0.6244438558038733
Validation loss: 2.609024449715474

Epoch: 6| Step: 12
Training loss: 0.7225530189807456
Validation loss: 2.6463545993982724

Epoch: 6| Step: 13
Training loss: 1.0434262418867928
Validation loss: 2.600138403961118

Epoch: 284| Step: 0
Training loss: 0.8689253979915539
Validation loss: 2.589543784415898

Epoch: 6| Step: 1
Training loss: 0.7540309190203569
Validation loss: 2.559393103518481

Epoch: 6| Step: 2
Training loss: 0.655354979397539
Validation loss: 2.5405881436896087

Epoch: 6| Step: 3
Training loss: 0.6948031799605451
Validation loss: 2.5227566159243446

Epoch: 6| Step: 4
Training loss: 1.0516358484588055
Validation loss: 2.5291285363274523

Epoch: 6| Step: 5
Training loss: 0.7197171214505443
Validation loss: 2.459104341626145

Epoch: 6| Step: 6
Training loss: 0.49818431977278843
Validation loss: 2.5084104088753048

Epoch: 6| Step: 7
Training loss: 0.6870957182914449
Validation loss: 2.4897866066770926

Epoch: 6| Step: 8
Training loss: 0.9565355223696411
Validation loss: 2.4912656229261567

Epoch: 6| Step: 9
Training loss: 0.8850296333976817
Validation loss: 2.5406782059557984

Epoch: 6| Step: 10
Training loss: 0.7443221864453606
Validation loss: 2.535826152704148

Epoch: 6| Step: 11
Training loss: 0.833500062634718
Validation loss: 2.554884128154156

Epoch: 6| Step: 12
Training loss: 0.7063828756865081
Validation loss: 2.5756463758148147

Epoch: 6| Step: 13
Training loss: 0.5935475857690482
Validation loss: 2.5625138823890765

Epoch: 285| Step: 0
Training loss: 0.7392755503775208
Validation loss: 2.536106940766164

Epoch: 6| Step: 1
Training loss: 0.6422928289831259
Validation loss: 2.5988226818644877

Epoch: 6| Step: 2
Training loss: 1.0249952153350061
Validation loss: 2.559819972731961

Epoch: 6| Step: 3
Training loss: 0.6457416843686721
Validation loss: 2.5424497041357577

Epoch: 6| Step: 4
Training loss: 0.8031181290625765
Validation loss: 2.5431170641390763

Epoch: 6| Step: 5
Training loss: 0.8332489845184996
Validation loss: 2.506685993686364

Epoch: 6| Step: 6
Training loss: 0.8271673891672974
Validation loss: 2.5358251002856087

Epoch: 6| Step: 7
Training loss: 0.9787373853043496
Validation loss: 2.490056584039774

Epoch: 6| Step: 8
Training loss: 0.522036913350364
Validation loss: 2.5016345085027254

Epoch: 6| Step: 9
Training loss: 0.9191930844259281
Validation loss: 2.5125493885080337

Epoch: 6| Step: 10
Training loss: 0.507003550661885
Validation loss: 2.498101701206716

Epoch: 6| Step: 11
Training loss: 0.39465603885015194
Validation loss: 2.512977365003811

Epoch: 6| Step: 12
Training loss: 0.9080720540290471
Validation loss: 2.527519254849161

Epoch: 6| Step: 13
Training loss: 0.9405146448535453
Validation loss: 2.523843175728773

Epoch: 286| Step: 0
Training loss: 0.7476832848327792
Validation loss: 2.529567604527705

Epoch: 6| Step: 1
Training loss: 0.5265902186492597
Validation loss: 2.5309828836696235

Epoch: 6| Step: 2
Training loss: 0.8084287244676571
Validation loss: 2.542301224510465

Epoch: 6| Step: 3
Training loss: 0.7005547488108195
Validation loss: 2.575505364802902

Epoch: 6| Step: 4
Training loss: 0.954902492358628
Validation loss: 2.5058060516026104

Epoch: 6| Step: 5
Training loss: 0.6630840947570814
Validation loss: 2.5234043864986253

Epoch: 6| Step: 6
Training loss: 0.7816144093354657
Validation loss: 2.5636599036779266

Epoch: 6| Step: 7
Training loss: 0.7885205891327357
Validation loss: 2.5464939094280665

Epoch: 6| Step: 8
Training loss: 0.3368677743267753
Validation loss: 2.524481218177494

Epoch: 6| Step: 9
Training loss: 0.723141481546363
Validation loss: 2.5446970772536712

Epoch: 6| Step: 10
Training loss: 0.7879275100085602
Validation loss: 2.51445087947506

Epoch: 6| Step: 11
Training loss: 0.923524447767567
Validation loss: 2.507469810379596

Epoch: 6| Step: 12
Training loss: 0.9887047866534111
Validation loss: 2.5306275581176316

Epoch: 6| Step: 13
Training loss: 0.7470578660115144
Validation loss: 2.5641546742150707

Epoch: 287| Step: 0
Training loss: 1.2429525070999317
Validation loss: 2.5232246807243643

Epoch: 6| Step: 1
Training loss: 0.5667599330144397
Validation loss: 2.539861222084343

Epoch: 6| Step: 2
Training loss: 0.8008909569001016
Validation loss: 2.5550176407101266

Epoch: 6| Step: 3
Training loss: 0.625216756427298
Validation loss: 2.5533570192457677

Epoch: 6| Step: 4
Training loss: 0.5419023319025967
Validation loss: 2.5312094341447238

Epoch: 6| Step: 5
Training loss: 0.5302461789257423
Validation loss: 2.5549951720366204

Epoch: 6| Step: 6
Training loss: 0.8659155512946265
Validation loss: 2.5452847831350733

Epoch: 6| Step: 7
Training loss: 0.9248393937459605
Validation loss: 2.5213263861788233

Epoch: 6| Step: 8
Training loss: 0.7184145600786893
Validation loss: 2.533325573882874

Epoch: 6| Step: 9
Training loss: 0.4209156077128757
Validation loss: 2.505538118142572

Epoch: 6| Step: 10
Training loss: 1.0563863000451565
Validation loss: 2.5553368294546006

Epoch: 6| Step: 11
Training loss: 0.6567052442898622
Validation loss: 2.5629929089233996

Epoch: 6| Step: 12
Training loss: 0.6924325470487708
Validation loss: 2.5398870999879106

Epoch: 6| Step: 13
Training loss: 0.7926402797552715
Validation loss: 2.5798421531386304

Epoch: 288| Step: 0
Training loss: 0.668939899506213
Validation loss: 2.5743037209838797

Epoch: 6| Step: 1
Training loss: 0.3618354740858482
Validation loss: 2.5364171274289777

Epoch: 6| Step: 2
Training loss: 0.37655614792147574
Validation loss: 2.5342470760325373

Epoch: 6| Step: 3
Training loss: 1.2431186568844903
Validation loss: 2.547179940103955

Epoch: 6| Step: 4
Training loss: 0.5335128499443623
Validation loss: 2.4858667702685455

Epoch: 6| Step: 5
Training loss: 0.8331041179767211
Validation loss: 2.460922596917747

Epoch: 6| Step: 6
Training loss: 0.9828146420502479
Validation loss: 2.486155049671013

Epoch: 6| Step: 7
Training loss: 0.2912521169446378
Validation loss: 2.5025817297112947

Epoch: 6| Step: 8
Training loss: 0.7604458859895907
Validation loss: 2.474197703224847

Epoch: 6| Step: 9
Training loss: 0.9823346867180407
Validation loss: 2.529170215073936

Epoch: 6| Step: 10
Training loss: 1.0002714623110587
Validation loss: 2.560588791741774

Epoch: 6| Step: 11
Training loss: 0.6152692028057589
Validation loss: 2.534649523729534

Epoch: 6| Step: 12
Training loss: 0.5411849325066065
Validation loss: 2.547780429415282

Epoch: 6| Step: 13
Training loss: 0.8089594728034639
Validation loss: 2.547332084482172

Epoch: 289| Step: 0
Training loss: 0.42788986097333426
Validation loss: 2.565039797938724

Epoch: 6| Step: 1
Training loss: 1.0068479550196656
Validation loss: 2.5669840016286547

Epoch: 6| Step: 2
Training loss: 1.0297225274711352
Validation loss: 2.537149613110678

Epoch: 6| Step: 3
Training loss: 0.8669344558623873
Validation loss: 2.5142894061261156

Epoch: 6| Step: 4
Training loss: 0.743391085022024
Validation loss: 2.543760144246558

Epoch: 6| Step: 5
Training loss: 0.7222826017506493
Validation loss: 2.5330160996696107

Epoch: 6| Step: 6
Training loss: 0.9599477431359738
Validation loss: 2.552526393768102

Epoch: 6| Step: 7
Training loss: 0.8419275735526639
Validation loss: 2.5547970773408206

Epoch: 6| Step: 8
Training loss: 0.4984216065698018
Validation loss: 2.5258005930212994

Epoch: 6| Step: 9
Training loss: 0.8181151615189464
Validation loss: 2.5634709511347316

Epoch: 6| Step: 10
Training loss: 0.482282610726524
Validation loss: 2.51884786068191

Epoch: 6| Step: 11
Training loss: 0.5458546520272879
Validation loss: 2.560833462830869

Epoch: 6| Step: 12
Training loss: 0.41698400413470105
Validation loss: 2.5728932227201304

Epoch: 6| Step: 13
Training loss: 0.8679137067397897
Validation loss: 2.5701265591671305

Epoch: 290| Step: 0
Training loss: 0.3718591927125972
Validation loss: 2.5455442800181247

Epoch: 6| Step: 1
Training loss: 0.48804396395046395
Validation loss: 2.5662371208748804

Epoch: 6| Step: 2
Training loss: 0.3102865867705192
Validation loss: 2.6303583012025658

Epoch: 6| Step: 3
Training loss: 0.7811952190266545
Validation loss: 2.604687641494505

Epoch: 6| Step: 4
Training loss: 0.5583217198554252
Validation loss: 2.5492644760664245

Epoch: 6| Step: 5
Training loss: 1.1257795176337186
Validation loss: 2.572946580089622

Epoch: 6| Step: 6
Training loss: 0.7423575758564861
Validation loss: 2.5745170896292335

Epoch: 6| Step: 7
Training loss: 0.899744062325149
Validation loss: 2.6275315478311807

Epoch: 6| Step: 8
Training loss: 0.6145961054320724
Validation loss: 2.5587095433403513

Epoch: 6| Step: 9
Training loss: 1.0851982399689646
Validation loss: 2.5398564770668672

Epoch: 6| Step: 10
Training loss: 0.6811047390398943
Validation loss: 2.5428099284245085

Epoch: 6| Step: 11
Training loss: 0.7138594641313349
Validation loss: 2.5371062102458284

Epoch: 6| Step: 12
Training loss: 0.7477113454323512
Validation loss: 2.5368917758190936

Epoch: 6| Step: 13
Training loss: 0.953101329822231
Validation loss: 2.5057043615026924

Epoch: 291| Step: 0
Training loss: 0.8462180316696181
Validation loss: 2.51144270943835

Epoch: 6| Step: 1
Training loss: 0.632873438032115
Validation loss: 2.5791961284430274

Epoch: 6| Step: 2
Training loss: 0.4778877186870022
Validation loss: 2.5095335494179483

Epoch: 6| Step: 3
Training loss: 0.5701338605804849
Validation loss: 2.536650211976769

Epoch: 6| Step: 4
Training loss: 0.7097131855665776
Validation loss: 2.5343044481941686

Epoch: 6| Step: 5
Training loss: 0.4596060904710207
Validation loss: 2.5300482233206774

Epoch: 6| Step: 6
Training loss: 0.7068571434834907
Validation loss: 2.559127290829983

Epoch: 6| Step: 7
Training loss: 0.6547072532787489
Validation loss: 2.5372922773420177

Epoch: 6| Step: 8
Training loss: 0.6617190805769886
Validation loss: 2.5709131295040613

Epoch: 6| Step: 9
Training loss: 0.8800244487270571
Validation loss: 2.508744143010506

Epoch: 6| Step: 10
Training loss: 1.0072291260443127
Validation loss: 2.5455682712564265

Epoch: 6| Step: 11
Training loss: 0.828444653123662
Validation loss: 2.5146453770110044

Epoch: 6| Step: 12
Training loss: 0.9168413097014051
Validation loss: 2.512272666736166

Epoch: 6| Step: 13
Training loss: 1.1587384741250035
Validation loss: 2.516149846879731

Epoch: 292| Step: 0
Training loss: 0.8314963398805257
Validation loss: 2.5708770146995703

Epoch: 6| Step: 1
Training loss: 0.7970143364654322
Validation loss: 2.5961532282155866

Epoch: 6| Step: 2
Training loss: 0.71860486099336
Validation loss: 2.5705907886504873

Epoch: 6| Step: 3
Training loss: 0.8800988138597209
Validation loss: 2.574263459130969

Epoch: 6| Step: 4
Training loss: 0.4731608448030955
Validation loss: 2.5976503009282372

Epoch: 6| Step: 5
Training loss: 0.575817503493033
Validation loss: 2.632574781083685

Epoch: 6| Step: 6
Training loss: 0.779333892937365
Validation loss: 2.625126747239545

Epoch: 6| Step: 7
Training loss: 0.70592542971508
Validation loss: 2.5950711806029556

Epoch: 6| Step: 8
Training loss: 0.7475056495580591
Validation loss: 2.5773299626189257

Epoch: 6| Step: 9
Training loss: 0.9581240895485331
Validation loss: 2.5635977473915905

Epoch: 6| Step: 10
Training loss: 0.8366422089260638
Validation loss: 2.4841760591968947

Epoch: 6| Step: 11
Training loss: 0.7730003817139112
Validation loss: 2.470790105765043

Epoch: 6| Step: 12
Training loss: 0.8142460621594227
Validation loss: 2.4358562178265406

Epoch: 6| Step: 13
Training loss: 0.4943246913250111
Validation loss: 2.469226803575565

Epoch: 293| Step: 0
Training loss: 0.6817195813814174
Validation loss: 2.504820532301268

Epoch: 6| Step: 1
Training loss: 0.869184582916651
Validation loss: 2.568072003840424

Epoch: 6| Step: 2
Training loss: 0.7283333967224839
Validation loss: 2.583960053884553

Epoch: 6| Step: 3
Training loss: 1.0320101739433676
Validation loss: 2.581176215118394

Epoch: 6| Step: 4
Training loss: 0.7439191994424342
Validation loss: 2.5620113830366686

Epoch: 6| Step: 5
Training loss: 0.7775612148338376
Validation loss: 2.5679557960769763

Epoch: 6| Step: 6
Training loss: 0.8859548765493394
Validation loss: 2.5697554282519506

Epoch: 6| Step: 7
Training loss: 1.07518012289878
Validation loss: 2.585711817901238

Epoch: 6| Step: 8
Training loss: 0.6871515821686707
Validation loss: 2.577809461349529

Epoch: 6| Step: 9
Training loss: 0.5162000628281045
Validation loss: 2.5451425860500474

Epoch: 6| Step: 10
Training loss: 0.8024647949197343
Validation loss: 2.5720608358034394

Epoch: 6| Step: 11
Training loss: 0.7926997964192968
Validation loss: 2.5615412781717484

Epoch: 6| Step: 12
Training loss: 0.8364302706890243
Validation loss: 2.5589304417153396

Epoch: 6| Step: 13
Training loss: 0.46300571153776043
Validation loss: 2.561992617041764

Epoch: 294| Step: 0
Training loss: 0.7972457621603221
Validation loss: 2.620438695573444

Epoch: 6| Step: 1
Training loss: 0.7809555261675427
Validation loss: 2.588426037515878

Epoch: 6| Step: 2
Training loss: 0.8511738021289565
Validation loss: 2.5918136249817056

Epoch: 6| Step: 3
Training loss: 0.552762681216042
Validation loss: 2.5985995833429687

Epoch: 6| Step: 4
Training loss: 0.898957209993429
Validation loss: 2.598955249153655

Epoch: 6| Step: 5
Training loss: 0.5989516686331324
Validation loss: 2.580992584594449

Epoch: 6| Step: 6
Training loss: 0.9935708502266023
Validation loss: 2.567911894596745

Epoch: 6| Step: 7
Training loss: 0.8177698602226884
Validation loss: 2.5696453808748716

Epoch: 6| Step: 8
Training loss: 0.6046598383764348
Validation loss: 2.558591020625391

Epoch: 6| Step: 9
Training loss: 0.4636713518044943
Validation loss: 2.5619962343645826

Epoch: 6| Step: 10
Training loss: 0.8178678871205796
Validation loss: 2.5770427521767

Epoch: 6| Step: 11
Training loss: 0.7312184123202269
Validation loss: 2.599522224272647

Epoch: 6| Step: 12
Training loss: 0.8028984551838095
Validation loss: 2.5801259668026737

Epoch: 6| Step: 13
Training loss: 0.8062407677883331
Validation loss: 2.6263293676286885

Epoch: 295| Step: 0
Training loss: 0.7101313453394851
Validation loss: 2.631582650660752

Epoch: 6| Step: 1
Training loss: 0.8289396489611732
Validation loss: 2.6199792857424846

Epoch: 6| Step: 2
Training loss: 0.868158844630692
Validation loss: 2.6352479287205814

Epoch: 6| Step: 3
Training loss: 0.5526131001528473
Validation loss: 2.611348354619484

Epoch: 6| Step: 4
Training loss: 0.7018056146662908
Validation loss: 2.565449771405656

Epoch: 6| Step: 5
Training loss: 0.5472353156965881
Validation loss: 2.6171701131018765

Epoch: 6| Step: 6
Training loss: 0.6508213484226786
Validation loss: 2.53644781107751

Epoch: 6| Step: 7
Training loss: 0.4574457554891198
Validation loss: 2.5064843080415637

Epoch: 6| Step: 8
Training loss: 0.8733125150240048
Validation loss: 2.526516471634944

Epoch: 6| Step: 9
Training loss: 0.5430503070422654
Validation loss: 2.540214239239692

Epoch: 6| Step: 10
Training loss: 0.8472126797797059
Validation loss: 2.5198631022924713

Epoch: 6| Step: 11
Training loss: 0.7412444698905831
Validation loss: 2.532699974839767

Epoch: 6| Step: 12
Training loss: 0.6325918919828522
Validation loss: 2.536642276417636

Epoch: 6| Step: 13
Training loss: 0.8762523680476734
Validation loss: 2.574138071626267

Epoch: 296| Step: 0
Training loss: 0.9512652404205918
Validation loss: 2.599211512767838

Epoch: 6| Step: 1
Training loss: 0.7477077183402497
Validation loss: 2.5765642002693387

Epoch: 6| Step: 2
Training loss: 0.3932189076919076
Validation loss: 2.578678355863353

Epoch: 6| Step: 3
Training loss: 0.7572424799614054
Validation loss: 2.6045047079562558

Epoch: 6| Step: 4
Training loss: 0.7766630940361969
Validation loss: 2.623927668411858

Epoch: 6| Step: 5
Training loss: 0.6014756474404918
Validation loss: 2.563737782909669

Epoch: 6| Step: 6
Training loss: 0.4436105025333781
Validation loss: 2.5305961008360027

Epoch: 6| Step: 7
Training loss: 0.7531275705633971
Validation loss: 2.5362512111819115

Epoch: 6| Step: 8
Training loss: 0.8943805151128901
Validation loss: 2.5333620418574516

Epoch: 6| Step: 9
Training loss: 0.677066947054038
Validation loss: 2.504114207092166

Epoch: 6| Step: 10
Training loss: 0.6334165821658386
Validation loss: 2.5016399132195457

Epoch: 6| Step: 11
Training loss: 0.6589438687703938
Validation loss: 2.5137104526391605

Epoch: 6| Step: 12
Training loss: 0.6972659669335646
Validation loss: 2.517730797616894

Epoch: 6| Step: 13
Training loss: 0.3215337129095
Validation loss: 2.541405352858963

Epoch: 297| Step: 0
Training loss: 0.6390951777826445
Validation loss: 2.574443602351728

Epoch: 6| Step: 1
Training loss: 0.5811949232115341
Validation loss: 2.5763980444924837

Epoch: 6| Step: 2
Training loss: 0.6187685260503853
Validation loss: 2.6228633922087563

Epoch: 6| Step: 3
Training loss: 0.7772330200460806
Validation loss: 2.6691009699539987

Epoch: 6| Step: 4
Training loss: 0.7349281257078902
Validation loss: 2.6093312176858117

Epoch: 6| Step: 5
Training loss: 0.4178627271855468
Validation loss: 2.6426844567170837

Epoch: 6| Step: 6
Training loss: 0.7756814867548377
Validation loss: 2.657042067854606

Epoch: 6| Step: 7
Training loss: 0.9079378458441119
Validation loss: 2.594126746516682

Epoch: 6| Step: 8
Training loss: 0.673084611770186
Validation loss: 2.5852985297148403

Epoch: 6| Step: 9
Training loss: 0.4757112185296688
Validation loss: 2.5542855748291

Epoch: 6| Step: 10
Training loss: 0.7569025613316841
Validation loss: 2.5332294322043563

Epoch: 6| Step: 11
Training loss: 0.6492327673692164
Validation loss: 2.538757855208547

Epoch: 6| Step: 12
Training loss: 0.7242894867524429
Validation loss: 2.5270017743855098

Epoch: 6| Step: 13
Training loss: 0.7609894219764868
Validation loss: 2.541059095271549

Epoch: 298| Step: 0
Training loss: 0.4059614844280989
Validation loss: 2.5535781989299244

Epoch: 6| Step: 1
Training loss: 0.8746395049670389
Validation loss: 2.5652298581640043

Epoch: 6| Step: 2
Training loss: 0.746966505630033
Validation loss: 2.558607908834549

Epoch: 6| Step: 3
Training loss: 0.6662505062881464
Validation loss: 2.6005379506027295

Epoch: 6| Step: 4
Training loss: 0.8712989325991541
Validation loss: 2.575393090458824

Epoch: 6| Step: 5
Training loss: 0.7237221357684025
Validation loss: 2.623920740324638

Epoch: 6| Step: 6
Training loss: 0.4326303622131986
Validation loss: 2.5791699680439306

Epoch: 6| Step: 7
Training loss: 0.7375247450087858
Validation loss: 2.569465682978397

Epoch: 6| Step: 8
Training loss: 0.4655920785107992
Validation loss: 2.5588183102431814

Epoch: 6| Step: 9
Training loss: 0.5644734784848855
Validation loss: 2.5452285619710016

Epoch: 6| Step: 10
Training loss: 0.767946926361794
Validation loss: 2.5589371510336347

Epoch: 6| Step: 11
Training loss: 0.47407463938309047
Validation loss: 2.544866651181205

Epoch: 6| Step: 12
Training loss: 0.6712000361908594
Validation loss: 2.5435384605516207

Epoch: 6| Step: 13
Training loss: 0.8472063479126268
Validation loss: 2.5606674706964982

Epoch: 299| Step: 0
Training loss: 0.6595274509446135
Validation loss: 2.5622479014390898

Epoch: 6| Step: 1
Training loss: 0.5837263730268861
Validation loss: 2.5864264973850295

Epoch: 6| Step: 2
Training loss: 0.8519959003076732
Validation loss: 2.5482087011865358

Epoch: 6| Step: 3
Training loss: 0.761790189082875
Validation loss: 2.563273901519317

Epoch: 6| Step: 4
Training loss: 0.5179938895682561
Validation loss: 2.612851320809806

Epoch: 6| Step: 5
Training loss: 0.7127990663860556
Validation loss: 2.626751738593206

Epoch: 6| Step: 6
Training loss: 0.5230453502584373
Validation loss: 2.6125944575917526

Epoch: 6| Step: 7
Training loss: 0.7370820170279898
Validation loss: 2.5814905661505825

Epoch: 6| Step: 8
Training loss: 0.6742513902881109
Validation loss: 2.5866261104355543

Epoch: 6| Step: 9
Training loss: 0.7347828564405453
Validation loss: 2.5927751732743505

Epoch: 6| Step: 10
Training loss: 0.38080788288732736
Validation loss: 2.5871398626805364

Epoch: 6| Step: 11
Training loss: 0.5506144061243948
Validation loss: 2.609767248430741

Epoch: 6| Step: 12
Training loss: 0.4089513974889852
Validation loss: 2.582700610867147

Epoch: 6| Step: 13
Training loss: 0.9527797386314844
Validation loss: 2.5991039543991294

Epoch: 300| Step: 0
Training loss: 0.7721692871761777
Validation loss: 2.5824631016817086

Epoch: 6| Step: 1
Training loss: 0.8981660515754856
Validation loss: 2.5972264033750703

Epoch: 6| Step: 2
Training loss: 0.8144420010106637
Validation loss: 2.6148957622808275

Epoch: 6| Step: 3
Training loss: 0.3085681566659091
Validation loss: 2.5553838312657917

Epoch: 6| Step: 4
Training loss: 0.7662310634345371
Validation loss: 2.536025648896458

Epoch: 6| Step: 5
Training loss: 0.46612401374882373
Validation loss: 2.516187231650485

Epoch: 6| Step: 6
Training loss: 0.5681615793351573
Validation loss: 2.5405153581622244

Epoch: 6| Step: 7
Training loss: 0.4958494140384201
Validation loss: 2.514936264837956

Epoch: 6| Step: 8
Training loss: 0.39347832935261867
Validation loss: 2.494326473598228

Epoch: 6| Step: 9
Training loss: 0.9395251970145321
Validation loss: 2.504528683518222

Epoch: 6| Step: 10
Training loss: 0.590728702220982
Validation loss: 2.543189560997403

Epoch: 6| Step: 11
Training loss: 0.5851761258140429
Validation loss: 2.554501085196323

Epoch: 6| Step: 12
Training loss: 0.6949547265078491
Validation loss: 2.567515736023927

Epoch: 6| Step: 13
Training loss: 0.5655751938783847
Validation loss: 2.5656983269532145

Epoch: 301| Step: 0
Training loss: 0.41538287115545947
Validation loss: 2.6158284542127603

Epoch: 6| Step: 1
Training loss: 0.5219320882764038
Validation loss: 2.609498538150275

Epoch: 6| Step: 2
Training loss: 0.7893957812789714
Validation loss: 2.5963376704481758

Epoch: 6| Step: 3
Training loss: 0.703607690221107
Validation loss: 2.597771806141303

Epoch: 6| Step: 4
Training loss: 0.4639603852459475
Validation loss: 2.543841845520792

Epoch: 6| Step: 5
Training loss: 0.5882173561769132
Validation loss: 2.524844488364339

Epoch: 6| Step: 6
Training loss: 0.7541581360631311
Validation loss: 2.5091835424296733

Epoch: 6| Step: 7
Training loss: 0.4127063314661152
Validation loss: 2.5092088141289004

Epoch: 6| Step: 8
Training loss: 0.9926593289416873
Validation loss: 2.5271414913758354

Epoch: 6| Step: 9
Training loss: 0.8505391612806424
Validation loss: 2.496238688753772

Epoch: 6| Step: 10
Training loss: 0.6920150404216218
Validation loss: 2.5061535924102447

Epoch: 6| Step: 11
Training loss: 0.6860886739579114
Validation loss: 2.5504024941574954

Epoch: 6| Step: 12
Training loss: 0.5091794030437838
Validation loss: 2.528667605270565

Epoch: 6| Step: 13
Training loss: 0.7183254895663412
Validation loss: 2.5898701693304136

Epoch: 302| Step: 0
Training loss: 0.6821445034594987
Validation loss: 2.605532140935845

Epoch: 6| Step: 1
Training loss: 0.4939913166022358
Validation loss: 2.6254777292934754

Epoch: 6| Step: 2
Training loss: 0.6481940490374156
Validation loss: 2.6449113776414106

Epoch: 6| Step: 3
Training loss: 0.7493555956341361
Validation loss: 2.567573562962763

Epoch: 6| Step: 4
Training loss: 0.4156047242460597
Validation loss: 2.5834634042227576

Epoch: 6| Step: 5
Training loss: 0.7827082566467795
Validation loss: 2.534502094273914

Epoch: 6| Step: 6
Training loss: 0.6230115252664084
Validation loss: 2.506131237015707

Epoch: 6| Step: 7
Training loss: 0.7797750664657188
Validation loss: 2.5276554360079206

Epoch: 6| Step: 8
Training loss: 0.6609018167372923
Validation loss: 2.5151479252518034

Epoch: 6| Step: 9
Training loss: 0.4149254856660008
Validation loss: 2.5553329498854773

Epoch: 6| Step: 10
Training loss: 0.807579178013705
Validation loss: 2.5611739590604827

Epoch: 6| Step: 11
Training loss: 0.7926861489625898
Validation loss: 2.5631630242603842

Epoch: 6| Step: 12
Training loss: 0.6792107587282362
Validation loss: 2.582898273677429

Epoch: 6| Step: 13
Training loss: 0.846157982414313
Validation loss: 2.5588925207624635

Epoch: 303| Step: 0
Training loss: 0.7560065074519481
Validation loss: 2.579558496081967

Epoch: 6| Step: 1
Training loss: 0.6369817693682627
Validation loss: 2.600524291160487

Epoch: 6| Step: 2
Training loss: 0.7381024017879955
Validation loss: 2.557419103435369

Epoch: 6| Step: 3
Training loss: 0.40689384352357144
Validation loss: 2.562759369280169

Epoch: 6| Step: 4
Training loss: 0.5620858999391195
Validation loss: 2.5648024274995844

Epoch: 6| Step: 5
Training loss: 0.9661822590640456
Validation loss: 2.5467643358930228

Epoch: 6| Step: 6
Training loss: 0.34097071392328276
Validation loss: 2.5842008817708106

Epoch: 6| Step: 7
Training loss: 0.301944551432539
Validation loss: 2.6052629751443606

Epoch: 6| Step: 8
Training loss: 0.7178653995483721
Validation loss: 2.596860413020278

Epoch: 6| Step: 9
Training loss: 0.7321486306710501
Validation loss: 2.623215760910128

Epoch: 6| Step: 10
Training loss: 0.761728100841543
Validation loss: 2.668913186897171

Epoch: 6| Step: 11
Training loss: 0.5494433989491859
Validation loss: 2.5984519636015193

Epoch: 6| Step: 12
Training loss: 0.8057541305597087
Validation loss: 2.61837838533011

Epoch: 6| Step: 13
Training loss: 0.48203898691061253
Validation loss: 2.5595435508705586

Epoch: 304| Step: 0
Training loss: 0.7532285500405513
Validation loss: 2.5714828310833173

Epoch: 6| Step: 1
Training loss: 0.3650632243071693
Validation loss: 2.5732050154502426

Epoch: 6| Step: 2
Training loss: 0.9440551150909767
Validation loss: 2.5278482248895395

Epoch: 6| Step: 3
Training loss: 0.3145603802604053
Validation loss: 2.5297093616853252

Epoch: 6| Step: 4
Training loss: 0.7706712518008934
Validation loss: 2.5595725039785

Epoch: 6| Step: 5
Training loss: 0.5707756931087691
Validation loss: 2.5249279459887823

Epoch: 6| Step: 6
Training loss: 0.5683581689775918
Validation loss: 2.495282611781838

Epoch: 6| Step: 7
Training loss: 0.5870345970953933
Validation loss: 2.4936274217494754

Epoch: 6| Step: 8
Training loss: 0.5769281112011093
Validation loss: 2.51686073279724

Epoch: 6| Step: 9
Training loss: 0.4743354697713279
Validation loss: 2.554886184175989

Epoch: 6| Step: 10
Training loss: 0.6867109886312369
Validation loss: 2.5988609227811863

Epoch: 6| Step: 11
Training loss: 0.760640873363308
Validation loss: 2.597885311962558

Epoch: 6| Step: 12
Training loss: 0.7071392756601219
Validation loss: 2.579170008797067

Epoch: 6| Step: 13
Training loss: 0.5456784373155507
Validation loss: 2.6018785455130513

Epoch: 305| Step: 0
Training loss: 0.7822903382094913
Validation loss: 2.6198095228368334

Epoch: 6| Step: 1
Training loss: 0.6254945943783302
Validation loss: 2.5814032997772682

Epoch: 6| Step: 2
Training loss: 0.7373069106314787
Validation loss: 2.5399447616059385

Epoch: 6| Step: 3
Training loss: 0.7094662712634229
Validation loss: 2.529757670627083

Epoch: 6| Step: 4
Training loss: 0.27273075867361307
Validation loss: 2.518467179022176

Epoch: 6| Step: 5
Training loss: 0.8340970037018912
Validation loss: 2.494251952663246

Epoch: 6| Step: 6
Training loss: 0.6692326506374063
Validation loss: 2.4992660439770615

Epoch: 6| Step: 7
Training loss: 0.515804375167934
Validation loss: 2.5222950515103206

Epoch: 6| Step: 8
Training loss: 0.4923793328058988
Validation loss: 2.5224254329453344

Epoch: 6| Step: 9
Training loss: 0.6542607083929265
Validation loss: 2.559664966035177

Epoch: 6| Step: 10
Training loss: 0.5055868231998382
Validation loss: 2.553467804247572

Epoch: 6| Step: 11
Training loss: 0.6642423498411628
Validation loss: 2.606140332558096

Epoch: 6| Step: 12
Training loss: 0.5769919297812575
Validation loss: 2.6043498664323055

Epoch: 6| Step: 13
Training loss: 0.6005740528946703
Validation loss: 2.6514860744876976

Epoch: 306| Step: 0
Training loss: 0.8445159120252012
Validation loss: 2.6565451026788622

Epoch: 6| Step: 1
Training loss: 0.7441055810240992
Validation loss: 2.6226588619118405

Epoch: 6| Step: 2
Training loss: 0.611713519506394
Validation loss: 2.6366784601692057

Epoch: 6| Step: 3
Training loss: 0.5760904028236318
Validation loss: 2.610091468362748

Epoch: 6| Step: 4
Training loss: 0.40258405971612915
Validation loss: 2.626240687100792

Epoch: 6| Step: 5
Training loss: 0.6262760963256445
Validation loss: 2.5761643816171835

Epoch: 6| Step: 6
Training loss: 0.6638856989049242
Validation loss: 2.592909356337018

Epoch: 6| Step: 7
Training loss: 0.3431809874406276
Validation loss: 2.5106945582707025

Epoch: 6| Step: 8
Training loss: 0.441871785795616
Validation loss: 2.5324035177486564

Epoch: 6| Step: 9
Training loss: 0.6387552796013131
Validation loss: 2.5464811671707275

Epoch: 6| Step: 10
Training loss: 0.6568976113286856
Validation loss: 2.5475948043076744

Epoch: 6| Step: 11
Training loss: 0.8952947964340978
Validation loss: 2.5434996116327593

Epoch: 6| Step: 12
Training loss: 0.7104826090199018
Validation loss: 2.574017865022602

Epoch: 6| Step: 13
Training loss: 0.6803176633317357
Validation loss: 2.5731171487557942

Epoch: 307| Step: 0
Training loss: 0.577654930982046
Validation loss: 2.575359953155446

Epoch: 6| Step: 1
Training loss: 0.28426061048306195
Validation loss: 2.625487310176885

Epoch: 6| Step: 2
Training loss: 0.7929704036601446
Validation loss: 2.5957260304280965

Epoch: 6| Step: 3
Training loss: 0.6410462227445484
Validation loss: 2.6053104066252586

Epoch: 6| Step: 4
Training loss: 0.7352633277673485
Validation loss: 2.6436488466332877

Epoch: 6| Step: 5
Training loss: 0.5634810581391555
Validation loss: 2.5830569964649834

Epoch: 6| Step: 6
Training loss: 0.4473200435932431
Validation loss: 2.573244516775154

Epoch: 6| Step: 7
Training loss: 0.37947170106069705
Validation loss: 2.5590778453032326

Epoch: 6| Step: 8
Training loss: 0.6488158719205128
Validation loss: 2.5917209932792424

Epoch: 6| Step: 9
Training loss: 0.7177326631966786
Validation loss: 2.560593643012299

Epoch: 6| Step: 10
Training loss: 0.6897810461420503
Validation loss: 2.594662101326179

Epoch: 6| Step: 11
Training loss: 0.6720268610172594
Validation loss: 2.6030831276031683

Epoch: 6| Step: 12
Training loss: 0.7893579892872545
Validation loss: 2.586913012036181

Epoch: 6| Step: 13
Training loss: 0.6264575175855235
Validation loss: 2.5891895946986963

Epoch: 308| Step: 0
Training loss: 0.589771493692289
Validation loss: 2.6206444028279288

Epoch: 6| Step: 1
Training loss: 0.5773878294928937
Validation loss: 2.621046691191378

Epoch: 6| Step: 2
Training loss: 0.4647412387428383
Validation loss: 2.6471364464606073

Epoch: 6| Step: 3
Training loss: 0.3935303787031565
Validation loss: 2.587585043840949

Epoch: 6| Step: 4
Training loss: 0.5617482937615851
Validation loss: 2.582772513283786

Epoch: 6| Step: 5
Training loss: 0.8956952580049505
Validation loss: 2.6142405081040225

Epoch: 6| Step: 6
Training loss: 0.5822294269070295
Validation loss: 2.59340095864859

Epoch: 6| Step: 7
Training loss: 0.6763984199294546
Validation loss: 2.5819661819485065

Epoch: 6| Step: 8
Training loss: 0.3990050742488771
Validation loss: 2.580441439762949

Epoch: 6| Step: 9
Training loss: 0.6030623329297574
Validation loss: 2.526768634816667

Epoch: 6| Step: 10
Training loss: 0.8433480894986572
Validation loss: 2.546010878203011

Epoch: 6| Step: 11
Training loss: 0.5886042626325405
Validation loss: 2.537078950959371

Epoch: 6| Step: 12
Training loss: 0.6316465539129087
Validation loss: 2.5613074660415207

Epoch: 6| Step: 13
Training loss: 0.5157068938909453
Validation loss: 2.5772830646158966

Epoch: 309| Step: 0
Training loss: 0.5683134394694246
Validation loss: 2.588406649883142

Epoch: 6| Step: 1
Training loss: 0.5535046497621764
Validation loss: 2.622974254771531

Epoch: 6| Step: 2
Training loss: 0.4237637976422801
Validation loss: 2.631773937996607

Epoch: 6| Step: 3
Training loss: 0.7520521222627555
Validation loss: 2.6391664153619403

Epoch: 6| Step: 4
Training loss: 0.5045068399780376
Validation loss: 2.584660611544257

Epoch: 6| Step: 5
Training loss: 0.6428509860462971
Validation loss: 2.6199182542461634

Epoch: 6| Step: 6
Training loss: 0.7422012729370706
Validation loss: 2.5583029390035166

Epoch: 6| Step: 7
Training loss: 0.7353073046006661
Validation loss: 2.5459723862106047

Epoch: 6| Step: 8
Training loss: 0.8666464002391548
Validation loss: 2.552416792265984

Epoch: 6| Step: 9
Training loss: 0.5411933579441185
Validation loss: 2.5502532853300264

Epoch: 6| Step: 10
Training loss: 0.40119193304595674
Validation loss: 2.5841315250692674

Epoch: 6| Step: 11
Training loss: 0.4453220701025864
Validation loss: 2.600346189363235

Epoch: 6| Step: 12
Training loss: 0.560164902964733
Validation loss: 2.606526614721278

Epoch: 6| Step: 13
Training loss: 0.5896464895877713
Validation loss: 2.624288067861103

Epoch: 310| Step: 0
Training loss: 0.7692673128874403
Validation loss: 2.6725247182107488

Epoch: 6| Step: 1
Training loss: 0.4439497390707637
Validation loss: 2.6574264777803025

Epoch: 6| Step: 2
Training loss: 0.5484350840197436
Validation loss: 2.6176702483634675

Epoch: 6| Step: 3
Training loss: 0.4210512985601311
Validation loss: 2.602014396630049

Epoch: 6| Step: 4
Training loss: 0.8234863643154269
Validation loss: 2.5598930115432235

Epoch: 6| Step: 5
Training loss: 0.8157367059791722
Validation loss: 2.5016349245659066

Epoch: 6| Step: 6
Training loss: 0.545912849904783
Validation loss: 2.552720156471995

Epoch: 6| Step: 7
Training loss: 0.6793594006920677
Validation loss: 2.5261822459146024

Epoch: 6| Step: 8
Training loss: 0.6449386465108835
Validation loss: 2.504471144140158

Epoch: 6| Step: 9
Training loss: 0.6801434007373437
Validation loss: 2.5276435290958434

Epoch: 6| Step: 10
Training loss: 0.3406291414586551
Validation loss: 2.5693769221222666

Epoch: 6| Step: 11
Training loss: 0.6161097036836167
Validation loss: 2.549342586899545

Epoch: 6| Step: 12
Training loss: 0.6583755674777999
Validation loss: 2.5728965875736303

Epoch: 6| Step: 13
Training loss: 0.5323623623965814
Validation loss: 2.598136808676059

Epoch: 311| Step: 0
Training loss: 0.6120656838370764
Validation loss: 2.6076202367514925

Epoch: 6| Step: 1
Training loss: 1.0086685212045359
Validation loss: 2.6176650788084155

Epoch: 6| Step: 2
Training loss: 0.5367296020654511
Validation loss: 2.587028369243952

Epoch: 6| Step: 3
Training loss: 0.43077492530449735
Validation loss: 2.597721931662774

Epoch: 6| Step: 4
Training loss: 0.5360721908232441
Validation loss: 2.6028956151884897

Epoch: 6| Step: 5
Training loss: 0.7642217349265361
Validation loss: 2.5886174864299285

Epoch: 6| Step: 6
Training loss: 0.6550960385916269
Validation loss: 2.614699882050783

Epoch: 6| Step: 7
Training loss: 0.3917893603926838
Validation loss: 2.61161484161576

Epoch: 6| Step: 8
Training loss: 0.5563245980464742
Validation loss: 2.606100216286494

Epoch: 6| Step: 9
Training loss: 0.7363821966013543
Validation loss: 2.5699324000307557

Epoch: 6| Step: 10
Training loss: 0.38615611598886224
Validation loss: 2.5399116937445774

Epoch: 6| Step: 11
Training loss: 0.470048124203339
Validation loss: 2.586269723015704

Epoch: 6| Step: 12
Training loss: 0.39178300872941074
Validation loss: 2.6052232793239765

Epoch: 6| Step: 13
Training loss: 0.4325210085490689
Validation loss: 2.6051222382347494

Epoch: 312| Step: 0
Training loss: 0.7096113895000021
Validation loss: 2.594990204105749

Epoch: 6| Step: 1
Training loss: 0.6860038777344656
Validation loss: 2.5612222420626085

Epoch: 6| Step: 2
Training loss: 0.4990015342369651
Validation loss: 2.5745361048849422

Epoch: 6| Step: 3
Training loss: 0.5669307516455669
Validation loss: 2.559698531869013

Epoch: 6| Step: 4
Training loss: 0.5743972085803909
Validation loss: 2.563327042070417

Epoch: 6| Step: 5
Training loss: 0.2742666615638406
Validation loss: 2.541006914108588

Epoch: 6| Step: 6
Training loss: 0.7602056881234908
Validation loss: 2.5778924234888736

Epoch: 6| Step: 7
Training loss: 0.6588795522591541
Validation loss: 2.5922121108728295

Epoch: 6| Step: 8
Training loss: 0.5720632149570914
Validation loss: 2.6038720946703995

Epoch: 6| Step: 9
Training loss: 0.4837585649052494
Validation loss: 2.5831321521533175

Epoch: 6| Step: 10
Training loss: 0.4600843519118815
Validation loss: 2.640044759557067

Epoch: 6| Step: 11
Training loss: 0.6954695706350866
Validation loss: 2.569131061459613

Epoch: 6| Step: 12
Training loss: 0.8305896215317223
Validation loss: 2.6081424106091

Epoch: 6| Step: 13
Training loss: 0.23501742850007867
Validation loss: 2.612515526597985

Epoch: 313| Step: 0
Training loss: 0.4547631151699895
Validation loss: 2.5762899939060824

Epoch: 6| Step: 1
Training loss: 0.5291501506971376
Validation loss: 2.5531987344262226

Epoch: 6| Step: 2
Training loss: 0.47245349160643274
Validation loss: 2.5255332195727123

Epoch: 6| Step: 3
Training loss: 0.4589395704112314
Validation loss: 2.5249830337591206

Epoch: 6| Step: 4
Training loss: 0.8494755782085306
Validation loss: 2.508809428162163

Epoch: 6| Step: 5
Training loss: 0.2795634298208915
Validation loss: 2.5350838323510496

Epoch: 6| Step: 6
Training loss: 0.5345364064734797
Validation loss: 2.585208740689183

Epoch: 6| Step: 7
Training loss: 0.711613930647443
Validation loss: 2.557241270696822

Epoch: 6| Step: 8
Training loss: 0.4102155551723513
Validation loss: 2.567648996129596

Epoch: 6| Step: 9
Training loss: 0.6308556429631531
Validation loss: 2.540979118558165

Epoch: 6| Step: 10
Training loss: 0.5292889077125364
Validation loss: 2.5720200773493493

Epoch: 6| Step: 11
Training loss: 0.5998649425295418
Validation loss: 2.5781843847928694

Epoch: 6| Step: 12
Training loss: 0.5910282998449832
Validation loss: 2.6190170884533646

Epoch: 6| Step: 13
Training loss: 0.9674937501355557
Validation loss: 2.63068481405066

Epoch: 314| Step: 0
Training loss: 0.6617652201183042
Validation loss: 2.6086988333824914

Epoch: 6| Step: 1
Training loss: 0.6811798637053813
Validation loss: 2.5534955762999543

Epoch: 6| Step: 2
Training loss: 0.6346337518890631
Validation loss: 2.5961193170592303

Epoch: 6| Step: 3
Training loss: 0.647359618577826
Validation loss: 2.592124194186533

Epoch: 6| Step: 4
Training loss: 0.758272247858415
Validation loss: 2.591005893753432

Epoch: 6| Step: 5
Training loss: 0.686239669562236
Validation loss: 2.5790978498875132

Epoch: 6| Step: 6
Training loss: 0.6742788383079036
Validation loss: 2.5803522030223163

Epoch: 6| Step: 7
Training loss: 0.5698870548229232
Validation loss: 2.5716017206425117

Epoch: 6| Step: 8
Training loss: 0.3615161097447005
Validation loss: 2.5890526894259573

Epoch: 6| Step: 9
Training loss: 0.5205680712089066
Validation loss: 2.5739319672846013

Epoch: 6| Step: 10
Training loss: 0.3682946699478696
Validation loss: 2.6029592662603322

Epoch: 6| Step: 11
Training loss: 0.4057540433779743
Validation loss: 2.5656475706899893

Epoch: 6| Step: 12
Training loss: 0.6024538100411587
Validation loss: 2.6117885932590736

Epoch: 6| Step: 13
Training loss: 0.18180515672076394
Validation loss: 2.559188070112739

Epoch: 315| Step: 0
Training loss: 0.883667624544881
Validation loss: 2.563792771236193

Epoch: 6| Step: 1
Training loss: 0.7121344749726987
Validation loss: 2.5815221277018274

Epoch: 6| Step: 2
Training loss: 0.5884363423405471
Validation loss: 2.5647454796747198

Epoch: 6| Step: 3
Training loss: 0.3446147402335115
Validation loss: 2.5764580263041337

Epoch: 6| Step: 4
Training loss: 0.6922506144318724
Validation loss: 2.520437616503114

Epoch: 6| Step: 5
Training loss: 0.3447751667457959
Validation loss: 2.5269437200309905

Epoch: 6| Step: 6
Training loss: 0.6452006245358798
Validation loss: 2.513237835246022

Epoch: 6| Step: 7
Training loss: 0.6013456672170449
Validation loss: 2.5245242511416017

Epoch: 6| Step: 8
Training loss: 0.4764760986550037
Validation loss: 2.5383718960226895

Epoch: 6| Step: 9
Training loss: 0.5299243937402565
Validation loss: 2.5576820731320784

Epoch: 6| Step: 10
Training loss: 0.4818074410079295
Validation loss: 2.565805129004458

Epoch: 6| Step: 11
Training loss: 0.49467228570267563
Validation loss: 2.5215294721769954

Epoch: 6| Step: 12
Training loss: 0.44310780248373366
Validation loss: 2.5183213757015745

Epoch: 6| Step: 13
Training loss: 0.5742472946442055
Validation loss: 2.590107219524638

Epoch: 316| Step: 0
Training loss: 0.6614433697387158
Validation loss: 2.5875708419473247

Epoch: 6| Step: 1
Training loss: 0.5597751635253199
Validation loss: 2.5994979232824194

Epoch: 6| Step: 2
Training loss: 0.5034022213149896
Validation loss: 2.5824311123504984

Epoch: 6| Step: 3
Training loss: 0.49944836763872685
Validation loss: 2.6054055661234448

Epoch: 6| Step: 4
Training loss: 0.5233248119612135
Validation loss: 2.5677959860906325

Epoch: 6| Step: 5
Training loss: 0.5164069979340509
Validation loss: 2.5756855839002974

Epoch: 6| Step: 6
Training loss: 0.5637840608765982
Validation loss: 2.607762716532306

Epoch: 6| Step: 7
Training loss: 0.7933867156343393
Validation loss: 2.615456506930487

Epoch: 6| Step: 8
Training loss: 0.5436749702515701
Validation loss: 2.5933135488651584

Epoch: 6| Step: 9
Training loss: 0.42814571163449305
Validation loss: 2.5768641814835487

Epoch: 6| Step: 10
Training loss: 0.6119122867698485
Validation loss: 2.6122616343898466

Epoch: 6| Step: 11
Training loss: 0.6603762694517574
Validation loss: 2.6251686626028254

Epoch: 6| Step: 12
Training loss: 0.4163920530722517
Validation loss: 2.5996628126942545

Epoch: 6| Step: 13
Training loss: 0.6132009660204341
Validation loss: 2.585102924743038

Epoch: 317| Step: 0
Training loss: 0.8986237374377909
Validation loss: 2.6156044533926286

Epoch: 6| Step: 1
Training loss: 0.4501689977671435
Validation loss: 2.6238499576932437

Epoch: 6| Step: 2
Training loss: 0.5606553773506968
Validation loss: 2.598835392400316

Epoch: 6| Step: 3
Training loss: 0.3621861760112797
Validation loss: 2.5759420809491376

Epoch: 6| Step: 4
Training loss: 0.6253027659454007
Validation loss: 2.576581151759166

Epoch: 6| Step: 5
Training loss: 0.6397523053117653
Validation loss: 2.5880366733394253

Epoch: 6| Step: 6
Training loss: 0.4429562790610456
Validation loss: 2.5448917488529497

Epoch: 6| Step: 7
Training loss: 0.5300105727238813
Validation loss: 2.5677306581469477

Epoch: 6| Step: 8
Training loss: 0.537825976817451
Validation loss: 2.571892128366795

Epoch: 6| Step: 9
Training loss: 0.43612960356417163
Validation loss: 2.5702139725240265

Epoch: 6| Step: 10
Training loss: 0.5750892424781717
Validation loss: 2.5635251021470156

Epoch: 6| Step: 11
Training loss: 0.6777965506140858
Validation loss: 2.5534501159974683

Epoch: 6| Step: 12
Training loss: 0.2213438910548897
Validation loss: 2.5845218916923685

Epoch: 6| Step: 13
Training loss: 0.7346441709007429
Validation loss: 2.586308849351534

Epoch: 318| Step: 0
Training loss: 0.4096777895453885
Validation loss: 2.5999671592010865

Epoch: 6| Step: 1
Training loss: 0.4223706195171762
Validation loss: 2.5933685486786633

Epoch: 6| Step: 2
Training loss: 0.7895828646320439
Validation loss: 2.5864174547408925

Epoch: 6| Step: 3
Training loss: 0.6280112680742412
Validation loss: 2.618167256566702

Epoch: 6| Step: 4
Training loss: 0.460408602366299
Validation loss: 2.612306113431992

Epoch: 6| Step: 5
Training loss: 0.4023133423805159
Validation loss: 2.5648557737690583

Epoch: 6| Step: 6
Training loss: 0.5872945202986705
Validation loss: 2.539980870104521

Epoch: 6| Step: 7
Training loss: 0.744040575084949
Validation loss: 2.545155545526905

Epoch: 6| Step: 8
Training loss: 0.526777684194401
Validation loss: 2.536582171735183

Epoch: 6| Step: 9
Training loss: 0.7071757300691622
Validation loss: 2.492838080256838

Epoch: 6| Step: 10
Training loss: 0.5308396774354049
Validation loss: 2.557030351523458

Epoch: 6| Step: 11
Training loss: 0.7132976885235245
Validation loss: 2.529204304205883

Epoch: 6| Step: 12
Training loss: 0.21011295581704414
Validation loss: 2.571109247657771

Epoch: 6| Step: 13
Training loss: 0.25727452878722606
Validation loss: 2.5905861612743957

Epoch: 319| Step: 0
Training loss: 0.5067549624282413
Validation loss: 2.6284357840365686

Epoch: 6| Step: 1
Training loss: 0.715489247201964
Validation loss: 2.642017567922384

Epoch: 6| Step: 2
Training loss: 0.4671374080429932
Validation loss: 2.6633296640997077

Epoch: 6| Step: 3
Training loss: 0.5354808741661534
Validation loss: 2.6851562951021735

Epoch: 6| Step: 4
Training loss: 0.80973403802811
Validation loss: 2.6723579968530387

Epoch: 6| Step: 5
Training loss: 0.5419997206155824
Validation loss: 2.6426582040226676

Epoch: 6| Step: 6
Training loss: 0.5645781381891206
Validation loss: 2.6426699024231457

Epoch: 6| Step: 7
Training loss: 0.6021923879396333
Validation loss: 2.619494536772013

Epoch: 6| Step: 8
Training loss: 0.6327391923428303
Validation loss: 2.6415874641941004

Epoch: 6| Step: 9
Training loss: 0.5673814993496799
Validation loss: 2.6417958779561106

Epoch: 6| Step: 10
Training loss: 0.6845868553524543
Validation loss: 2.585047849232649

Epoch: 6| Step: 11
Training loss: 0.6130207018553647
Validation loss: 2.604535283405549

Epoch: 6| Step: 12
Training loss: 0.6341166303681238
Validation loss: 2.567635414329338

Epoch: 6| Step: 13
Training loss: 0.5915206163655625
Validation loss: 2.605506636074501

Epoch: 320| Step: 0
Training loss: 0.5753086153362353
Validation loss: 2.6000747119338565

Epoch: 6| Step: 1
Training loss: 0.4366438526765265
Validation loss: 2.6172055293567076

Epoch: 6| Step: 2
Training loss: 0.4088649768574603
Validation loss: 2.578860059592167

Epoch: 6| Step: 3
Training loss: 0.30678597425305154
Validation loss: 2.60521170651066

Epoch: 6| Step: 4
Training loss: 0.5186466343859404
Validation loss: 2.5846167934461044

Epoch: 6| Step: 5
Training loss: 0.6587792882977415
Validation loss: 2.5868612870665193

Epoch: 6| Step: 6
Training loss: 0.713669442943653
Validation loss: 2.5838673192223367

Epoch: 6| Step: 7
Training loss: 0.49568610075687114
Validation loss: 2.598426621591971

Epoch: 6| Step: 8
Training loss: 0.6261819154501969
Validation loss: 2.586295981102819

Epoch: 6| Step: 9
Training loss: 0.7630065204896701
Validation loss: 2.584261938373396

Epoch: 6| Step: 10
Training loss: 0.3322590887708091
Validation loss: 2.548317206039502

Epoch: 6| Step: 11
Training loss: 0.612741390656494
Validation loss: 2.5400887408712634

Epoch: 6| Step: 12
Training loss: 0.6216996554356713
Validation loss: 2.511407066469094

Epoch: 6| Step: 13
Training loss: 0.8483790818365353
Validation loss: 2.5357497622600387

Epoch: 321| Step: 0
Training loss: 0.2055310198484028
Validation loss: 2.568492035387604

Epoch: 6| Step: 1
Training loss: 0.4100482980262797
Validation loss: 2.5312212678186836

Epoch: 6| Step: 2
Training loss: 0.34078581452318957
Validation loss: 2.507457465874749

Epoch: 6| Step: 3
Training loss: 0.7196546334875442
Validation loss: 2.542879319316899

Epoch: 6| Step: 4
Training loss: 0.4754718275468896
Validation loss: 2.571786492197529

Epoch: 6| Step: 5
Training loss: 0.41855765237973025
Validation loss: 2.5858216033731147

Epoch: 6| Step: 6
Training loss: 0.7322470494474939
Validation loss: 2.5928589364775774

Epoch: 6| Step: 7
Training loss: 0.6558011654530809
Validation loss: 2.6206362422688483

Epoch: 6| Step: 8
Training loss: 0.4940978321951256
Validation loss: 2.5819671142837706

Epoch: 6| Step: 9
Training loss: 0.6964434737403162
Validation loss: 2.6167882353654037

Epoch: 6| Step: 10
Training loss: 0.7315843600233954
Validation loss: 2.6265053473545366

Epoch: 6| Step: 11
Training loss: 0.7383089817227766
Validation loss: 2.6306670739279223

Epoch: 6| Step: 12
Training loss: 0.5730128438735063
Validation loss: 2.625471062102857

Epoch: 6| Step: 13
Training loss: 0.8402600343440457
Validation loss: 2.62346655262354

Epoch: 322| Step: 0
Training loss: 0.33356476240157423
Validation loss: 2.5570292797597176

Epoch: 6| Step: 1
Training loss: 0.6857329548056948
Validation loss: 2.5624892632004137

Epoch: 6| Step: 2
Training loss: 0.5958317852222453
Validation loss: 2.5051621455050976

Epoch: 6| Step: 3
Training loss: 0.5750879728357396
Validation loss: 2.5185385180825075

Epoch: 6| Step: 4
Training loss: 0.5191836807847083
Validation loss: 2.4757700253517534

Epoch: 6| Step: 5
Training loss: 0.7391286759861706
Validation loss: 2.5465348509354757

Epoch: 6| Step: 6
Training loss: 0.30945546519861594
Validation loss: 2.56483283853752

Epoch: 6| Step: 7
Training loss: 0.6600083631289082
Validation loss: 2.5872490168118016

Epoch: 6| Step: 8
Training loss: 0.5452040621869957
Validation loss: 2.583829598554414

Epoch: 6| Step: 9
Training loss: 0.6518589434013199
Validation loss: 2.6543616882353724

Epoch: 6| Step: 10
Training loss: 0.7009876827485657
Validation loss: 2.6746282702001696

Epoch: 6| Step: 11
Training loss: 0.6830598762790616
Validation loss: 2.6879442958543676

Epoch: 6| Step: 12
Training loss: 0.4944176180249737
Validation loss: 2.575594205601389

Epoch: 6| Step: 13
Training loss: 0.6379861679520955
Validation loss: 2.5538314133057067

Epoch: 323| Step: 0
Training loss: 0.36913186522086183
Validation loss: 2.5131127172945935

Epoch: 6| Step: 1
Training loss: 0.5171705260473425
Validation loss: 2.488296118008784

Epoch: 6| Step: 2
Training loss: 0.6018914648479808
Validation loss: 2.4784597966256827

Epoch: 6| Step: 3
Training loss: 0.559893210353178
Validation loss: 2.507233563183655

Epoch: 6| Step: 4
Training loss: 0.6294828816056542
Validation loss: 2.4850451540129854

Epoch: 6| Step: 5
Training loss: 0.6498982624983376
Validation loss: 2.520019899007476

Epoch: 6| Step: 6
Training loss: 0.5845533170310175
Validation loss: 2.5266904744706205

Epoch: 6| Step: 7
Training loss: 0.6794121283077785
Validation loss: 2.5551845506907123

Epoch: 6| Step: 8
Training loss: 0.7417483184815965
Validation loss: 2.588970102735189

Epoch: 6| Step: 9
Training loss: 0.8375919405446524
Validation loss: 2.6686018150652813

Epoch: 6| Step: 10
Training loss: 0.46303272882835433
Validation loss: 2.626693411804871

Epoch: 6| Step: 11
Training loss: 0.6956165806071446
Validation loss: 2.6539956812131162

Epoch: 6| Step: 12
Training loss: 0.6801183365486828
Validation loss: 2.6031829124372403

Epoch: 6| Step: 13
Training loss: 0.44078808938406133
Validation loss: 2.579559488917177

Epoch: 324| Step: 0
Training loss: 0.6396467136039509
Validation loss: 2.5760756595019894

Epoch: 6| Step: 1
Training loss: 0.3760459538617817
Validation loss: 2.5817553453914006

Epoch: 6| Step: 2
Training loss: 0.5415468327918959
Validation loss: 2.5506523733068813

Epoch: 6| Step: 3
Training loss: 0.7828477162493693
Validation loss: 2.580503591200477

Epoch: 6| Step: 4
Training loss: 0.3208484933520541
Validation loss: 2.5580138016924385

Epoch: 6| Step: 5
Training loss: 0.36486303862528985
Validation loss: 2.54487494792628

Epoch: 6| Step: 6
Training loss: 0.8012260876210267
Validation loss: 2.5827844888845797

Epoch: 6| Step: 7
Training loss: 0.4053316373285043
Validation loss: 2.573355980786786

Epoch: 6| Step: 8
Training loss: 0.40453887920471626
Validation loss: 2.5554977240542422

Epoch: 6| Step: 9
Training loss: 0.5925228085533972
Validation loss: 2.5664279255251574

Epoch: 6| Step: 10
Training loss: 0.783379285222092
Validation loss: 2.543786035396209

Epoch: 6| Step: 11
Training loss: 0.3664312285020471
Validation loss: 2.542522685356242

Epoch: 6| Step: 12
Training loss: 0.7623999264193696
Validation loss: 2.5891428897298128

Epoch: 6| Step: 13
Training loss: 0.4099568018311657
Validation loss: 2.5226484293205074

Epoch: 325| Step: 0
Training loss: 0.642253875086681
Validation loss: 2.550158961032613

Epoch: 6| Step: 1
Training loss: 0.6364956330286666
Validation loss: 2.524185322314328

Epoch: 6| Step: 2
Training loss: 0.4375667180551527
Validation loss: 2.5653516647613506

Epoch: 6| Step: 3
Training loss: 0.44890371139344987
Validation loss: 2.582644326706817

Epoch: 6| Step: 4
Training loss: 0.49859322892475305
Validation loss: 2.5463036025103967

Epoch: 6| Step: 5
Training loss: 0.6828026253621291
Validation loss: 2.591273782709994

Epoch: 6| Step: 6
Training loss: 0.5197940821263437
Validation loss: 2.5855817231268547

Epoch: 6| Step: 7
Training loss: 0.8457455172937249
Validation loss: 2.578581689065829

Epoch: 6| Step: 8
Training loss: 0.28507369949865796
Validation loss: 2.623995654731885

Epoch: 6| Step: 9
Training loss: 0.6573562154093484
Validation loss: 2.5792846199725727

Epoch: 6| Step: 10
Training loss: 0.4356480297092666
Validation loss: 2.5886783061584726

Epoch: 6| Step: 11
Training loss: 0.4070077395101616
Validation loss: 2.6006776900873305

Epoch: 6| Step: 12
Training loss: 0.4673249198872283
Validation loss: 2.605381232434362

Epoch: 6| Step: 13
Training loss: 0.1758097678469567
Validation loss: 2.6114135161762966

Epoch: 326| Step: 0
Training loss: 0.6336254502349596
Validation loss: 2.578289661388269

Epoch: 6| Step: 1
Training loss: 0.21168041093262355
Validation loss: 2.5649801787839284

Epoch: 6| Step: 2
Training loss: 0.5809431465863579
Validation loss: 2.54779450847808

Epoch: 6| Step: 3
Training loss: 0.6276038289893628
Validation loss: 2.5354846103542097

Epoch: 6| Step: 4
Training loss: 0.5665942439146089
Validation loss: 2.5428250406736335

Epoch: 6| Step: 5
Training loss: 0.5552265610365784
Validation loss: 2.540480905652436

Epoch: 6| Step: 6
Training loss: 0.4792335574135742
Validation loss: 2.5197117329939824

Epoch: 6| Step: 7
Training loss: 0.25573227907036156
Validation loss: 2.581810484187166

Epoch: 6| Step: 8
Training loss: 0.43518951535419104
Validation loss: 2.5718664748085764

Epoch: 6| Step: 9
Training loss: 0.40409029414385367
Validation loss: 2.5909872526675763

Epoch: 6| Step: 10
Training loss: 0.6321116204198913
Validation loss: 2.6232516310905196

Epoch: 6| Step: 11
Training loss: 0.6363386880408878
Validation loss: 2.6027190255820143

Epoch: 6| Step: 12
Training loss: 0.674595757696552
Validation loss: 2.6346119061284394

Epoch: 6| Step: 13
Training loss: 0.5623859978758057
Validation loss: 2.6460495882134776

Epoch: 327| Step: 0
Training loss: 0.7133722220126617
Validation loss: 2.6190900768140817

Epoch: 6| Step: 1
Training loss: 0.48211675717085084
Validation loss: 2.547023359947972

Epoch: 6| Step: 2
Training loss: 0.7738614702429938
Validation loss: 2.5572569558020297

Epoch: 6| Step: 3
Training loss: 0.5348334348164755
Validation loss: 2.513246643404878

Epoch: 6| Step: 4
Training loss: 0.5217445096182642
Validation loss: 2.4620352483523815

Epoch: 6| Step: 5
Training loss: 0.4602435432366585
Validation loss: 2.505338428588381

Epoch: 6| Step: 6
Training loss: 0.5207796514184991
Validation loss: 2.494687761421734

Epoch: 6| Step: 7
Training loss: 0.6623530431816759
Validation loss: 2.4670221116151105

Epoch: 6| Step: 8
Training loss: 0.5530377690987831
Validation loss: 2.5174815540310242

Epoch: 6| Step: 9
Training loss: 0.5790931482330979
Validation loss: 2.510761075160525

Epoch: 6| Step: 10
Training loss: 0.4721294020451842
Validation loss: 2.5972542671851753

Epoch: 6| Step: 11
Training loss: 0.4602641181614219
Validation loss: 2.5606564118472206

Epoch: 6| Step: 12
Training loss: 0.2925456488681976
Validation loss: 2.585619511930376

Epoch: 6| Step: 13
Training loss: 0.24661503939131582
Validation loss: 2.5699790331581887

Epoch: 328| Step: 0
Training loss: 0.6235656969780516
Validation loss: 2.5937762653846024

Epoch: 6| Step: 1
Training loss: 0.6184566100851119
Validation loss: 2.5363836416217795

Epoch: 6| Step: 2
Training loss: 0.4859626653110166
Validation loss: 2.5674607775080127

Epoch: 6| Step: 3
Training loss: 0.636204306942147
Validation loss: 2.5657199974679097

Epoch: 6| Step: 4
Training loss: 0.3749803696898552
Validation loss: 2.5606253424924543

Epoch: 6| Step: 5
Training loss: 0.5594450592409932
Validation loss: 2.5799657639714275

Epoch: 6| Step: 6
Training loss: 0.4571750936174216
Validation loss: 2.5375261382300436

Epoch: 6| Step: 7
Training loss: 0.3976221718266344
Validation loss: 2.584788101053613

Epoch: 6| Step: 8
Training loss: 0.5609159151987609
Validation loss: 2.5855137544403335

Epoch: 6| Step: 9
Training loss: 0.6167180170983153
Validation loss: 2.5639834963232646

Epoch: 6| Step: 10
Training loss: 0.5733294444959552
Validation loss: 2.6000582882915904

Epoch: 6| Step: 11
Training loss: 0.5621485141809499
Validation loss: 2.6049730346178728

Epoch: 6| Step: 12
Training loss: 0.28573447873504837
Validation loss: 2.6019980167592185

Epoch: 6| Step: 13
Training loss: 0.23515803345925926
Validation loss: 2.5940582807782193

Epoch: 329| Step: 0
Training loss: 0.4575847306506631
Validation loss: 2.5842637755945765

Epoch: 6| Step: 1
Training loss: 0.3410709738193382
Validation loss: 2.5927290673315273

Epoch: 6| Step: 2
Training loss: 0.648277079030243
Validation loss: 2.5431581915603068

Epoch: 6| Step: 3
Training loss: 0.6098587365817206
Validation loss: 2.588047619153837

Epoch: 6| Step: 4
Training loss: 0.564384403467256
Validation loss: 2.5595363884138664

Epoch: 6| Step: 5
Training loss: 0.4650840458748563
Validation loss: 2.5434550743424733

Epoch: 6| Step: 6
Training loss: 0.2724638907980062
Validation loss: 2.5947932796401054

Epoch: 6| Step: 7
Training loss: 0.6371590197953542
Validation loss: 2.5967744741794436

Epoch: 6| Step: 8
Training loss: 0.49833437531446306
Validation loss: 2.6032648906723566

Epoch: 6| Step: 9
Training loss: 0.47239343571781717
Validation loss: 2.6015343531983786

Epoch: 6| Step: 10
Training loss: 0.6191286633416062
Validation loss: 2.625043891113991

Epoch: 6| Step: 11
Training loss: 0.4974575670155836
Validation loss: 2.601734420159429

Epoch: 6| Step: 12
Training loss: 0.6495143956284227
Validation loss: 2.5910188568477444

Epoch: 6| Step: 13
Training loss: 0.5718426492014296
Validation loss: 2.5667824475618186

Epoch: 330| Step: 0
Training loss: 0.47411208925035037
Validation loss: 2.5480567409522727

Epoch: 6| Step: 1
Training loss: 0.36817968522576794
Validation loss: 2.557297545552579

Epoch: 6| Step: 2
Training loss: 0.6612588151008876
Validation loss: 2.54938309852265

Epoch: 6| Step: 3
Training loss: 0.29089456638891814
Validation loss: 2.5211355237889514

Epoch: 6| Step: 4
Training loss: 0.5144101483374773
Validation loss: 2.5655190186033643

Epoch: 6| Step: 5
Training loss: 0.5390647390567884
Validation loss: 2.5827947770376865

Epoch: 6| Step: 6
Training loss: 0.6543506657139162
Validation loss: 2.562801907550027

Epoch: 6| Step: 7
Training loss: 0.4305868101141434
Validation loss: 2.5880439500823815

Epoch: 6| Step: 8
Training loss: 0.35706532522319445
Validation loss: 2.6232130176576915

Epoch: 6| Step: 9
Training loss: 0.48948825426981923
Validation loss: 2.618594349068942

Epoch: 6| Step: 10
Training loss: 0.6227519374635038
Validation loss: 2.637506303350563

Epoch: 6| Step: 11
Training loss: 0.5544911157826772
Validation loss: 2.631880915156602

Epoch: 6| Step: 12
Training loss: 0.6098893757865657
Validation loss: 2.615836768937126

Epoch: 6| Step: 13
Training loss: 0.5821357223656926
Validation loss: 2.65025608220816

Epoch: 331| Step: 0
Training loss: 0.6575768091569996
Validation loss: 2.5974562084427535

Epoch: 6| Step: 1
Training loss: 0.5942636827667772
Validation loss: 2.617163507029853

Epoch: 6| Step: 2
Training loss: 0.48603988439748497
Validation loss: 2.6010914643760534

Epoch: 6| Step: 3
Training loss: 0.22803273490724452
Validation loss: 2.5905706413518694

Epoch: 6| Step: 4
Training loss: 0.6221941430940925
Validation loss: 2.577678321782505

Epoch: 6| Step: 5
Training loss: 0.6276202826323605
Validation loss: 2.565275660361679

Epoch: 6| Step: 6
Training loss: 0.490627571876734
Validation loss: 2.5596936283241547

Epoch: 6| Step: 7
Training loss: 0.45220297696636524
Validation loss: 2.6109150141844655

Epoch: 6| Step: 8
Training loss: 0.5798289987450133
Validation loss: 2.589842721512027

Epoch: 6| Step: 9
Training loss: 0.35207103401160095
Validation loss: 2.6105850594255204

Epoch: 6| Step: 10
Training loss: 0.3406138847007381
Validation loss: 2.5817411427083568

Epoch: 6| Step: 11
Training loss: 0.3785564735188607
Validation loss: 2.5809072527411954

Epoch: 6| Step: 12
Training loss: 0.32892696831840473
Validation loss: 2.627906688157059

Epoch: 6| Step: 13
Training loss: 0.8000009596342054
Validation loss: 2.611775060385432

Epoch: 332| Step: 0
Training loss: 0.4656924346121741
Validation loss: 2.6486514006898116

Epoch: 6| Step: 1
Training loss: 0.45371257569850276
Validation loss: 2.6202391400070892

Epoch: 6| Step: 2
Training loss: 0.2864821322987627
Validation loss: 2.6019412613102113

Epoch: 6| Step: 3
Training loss: 0.4317877333232233
Validation loss: 2.6168207829060077

Epoch: 6| Step: 4
Training loss: 0.2721163987932491
Validation loss: 2.6174372806531903

Epoch: 6| Step: 5
Training loss: 0.537178062901979
Validation loss: 2.6039749888768373

Epoch: 6| Step: 6
Training loss: 0.4925352563437929
Validation loss: 2.6144705179647567

Epoch: 6| Step: 7
Training loss: 0.7666196007033849
Validation loss: 2.589304410882202

Epoch: 6| Step: 8
Training loss: 0.6275247600123507
Validation loss: 2.6126882989333984

Epoch: 6| Step: 9
Training loss: 0.48616423392294733
Validation loss: 2.624210526320077

Epoch: 6| Step: 10
Training loss: 0.6118323589659417
Validation loss: 2.6225534348083492

Epoch: 6| Step: 11
Training loss: 0.6238381553994855
Validation loss: 2.590935869759387

Epoch: 6| Step: 12
Training loss: 0.3339733768905421
Validation loss: 2.6026791919689893

Epoch: 6| Step: 13
Training loss: 0.5359812871545282
Validation loss: 2.5934691590293024

Epoch: 333| Step: 0
Training loss: 0.4381675735989995
Validation loss: 2.559457462843465

Epoch: 6| Step: 1
Training loss: 0.5851569253385388
Validation loss: 2.598593848045627

Epoch: 6| Step: 2
Training loss: 0.4534259323022195
Validation loss: 2.5676007211550376

Epoch: 6| Step: 3
Training loss: 0.25244412153248363
Validation loss: 2.5278904744104214

Epoch: 6| Step: 4
Training loss: 0.4792230787103485
Validation loss: 2.5499473977338636

Epoch: 6| Step: 5
Training loss: 0.7294559903847964
Validation loss: 2.571371289862215

Epoch: 6| Step: 6
Training loss: 0.524703019022267
Validation loss: 2.5669305273093634

Epoch: 6| Step: 7
Training loss: 0.574628203891986
Validation loss: 2.5723230730807636

Epoch: 6| Step: 8
Training loss: 0.5418730733764612
Validation loss: 2.5677184216398223

Epoch: 6| Step: 9
Training loss: 0.2931292920520245
Validation loss: 2.629874111316031

Epoch: 6| Step: 10
Training loss: 0.5095731291395181
Validation loss: 2.6137212542930137

Epoch: 6| Step: 11
Training loss: 0.5995269619348683
Validation loss: 2.5978345608844977

Epoch: 6| Step: 12
Training loss: 0.4393425866023495
Validation loss: 2.598203954289945

Epoch: 6| Step: 13
Training loss: 0.5988390568819697
Validation loss: 2.538970292328372

Epoch: 334| Step: 0
Training loss: 0.786620790657918
Validation loss: 2.5728990098270086

Epoch: 6| Step: 1
Training loss: 0.4022086203601213
Validation loss: 2.567556864525754

Epoch: 6| Step: 2
Training loss: 0.4218037333163172
Validation loss: 2.606315295082008

Epoch: 6| Step: 3
Training loss: 0.3396248386426198
Validation loss: 2.584375382347598

Epoch: 6| Step: 4
Training loss: 0.3567655196339461
Validation loss: 2.625517080801137

Epoch: 6| Step: 5
Training loss: 0.5015681530880464
Validation loss: 2.5818155383606394

Epoch: 6| Step: 6
Training loss: 0.21913452071937428
Validation loss: 2.568409627011622

Epoch: 6| Step: 7
Training loss: 0.4606792728795415
Validation loss: 2.5678090039571977

Epoch: 6| Step: 8
Training loss: 0.6147745503087835
Validation loss: 2.5695939303696953

Epoch: 6| Step: 9
Training loss: 0.5015423054655277
Validation loss: 2.5622727578221713

Epoch: 6| Step: 10
Training loss: 0.5413701792669476
Validation loss: 2.541141038247444

Epoch: 6| Step: 11
Training loss: 0.4385235257900723
Validation loss: 2.541372114355218

Epoch: 6| Step: 12
Training loss: 0.463566475822245
Validation loss: 2.5895818960508086

Epoch: 6| Step: 13
Training loss: 0.7370137632267588
Validation loss: 2.5440402380135203

Epoch: 335| Step: 0
Training loss: 0.24302598947504694
Validation loss: 2.5999710392187003

Epoch: 6| Step: 1
Training loss: 0.5940491023351384
Validation loss: 2.549070397382681

Epoch: 6| Step: 2
Training loss: 0.3191852272270978
Validation loss: 2.5752257053351997

Epoch: 6| Step: 3
Training loss: 0.2737510110017754
Validation loss: 2.590860589170991

Epoch: 6| Step: 4
Training loss: 0.5374080313136019
Validation loss: 2.5688819862922547

Epoch: 6| Step: 5
Training loss: 0.4737969025768273
Validation loss: 2.5786534190158252

Epoch: 6| Step: 6
Training loss: 0.710280607475055
Validation loss: 2.554461597114551

Epoch: 6| Step: 7
Training loss: 0.4285671366607246
Validation loss: 2.6029339208582107

Epoch: 6| Step: 8
Training loss: 0.7364375592169972
Validation loss: 2.5998695149505147

Epoch: 6| Step: 9
Training loss: 0.4388089014385821
Validation loss: 2.5725947894430408

Epoch: 6| Step: 10
Training loss: 0.3407007898654353
Validation loss: 2.5582796985096827

Epoch: 6| Step: 11
Training loss: 0.46069756421554187
Validation loss: 2.5819473842502534

Epoch: 6| Step: 12
Training loss: 0.5937723858277427
Validation loss: 2.5616516221573864

Epoch: 6| Step: 13
Training loss: 0.1783913323658269
Validation loss: 2.5488017303579937

Epoch: 336| Step: 0
Training loss: 0.37591455121601886
Validation loss: 2.5673423033116967

Epoch: 6| Step: 1
Training loss: 0.3913413346114079
Validation loss: 2.577081401336551

Epoch: 6| Step: 2
Training loss: 0.6803429611038176
Validation loss: 2.539982705038416

Epoch: 6| Step: 3
Training loss: 0.21964691413949491
Validation loss: 2.556296281646076

Epoch: 6| Step: 4
Training loss: 0.426871016303669
Validation loss: 2.548628248336844

Epoch: 6| Step: 5
Training loss: 0.5443729931414432
Validation loss: 2.604727973414139

Epoch: 6| Step: 6
Training loss: 0.8069386889839173
Validation loss: 2.540049212927502

Epoch: 6| Step: 7
Training loss: 0.44163169842371175
Validation loss: 2.579016743626603

Epoch: 6| Step: 8
Training loss: 0.375758734680855
Validation loss: 2.5674759089156867

Epoch: 6| Step: 9
Training loss: 0.3292010578566979
Validation loss: 2.592435133609604

Epoch: 6| Step: 10
Training loss: 0.4578678592371883
Validation loss: 2.582000961102476

Epoch: 6| Step: 11
Training loss: 0.22544152727963762
Validation loss: 2.5701314128828

Epoch: 6| Step: 12
Training loss: 0.46786681260658564
Validation loss: 2.603107728984423

Epoch: 6| Step: 13
Training loss: 0.5927668512974564
Validation loss: 2.5734835292475946

Epoch: 337| Step: 0
Training loss: 0.24654962307818598
Validation loss: 2.6373120703882993

Epoch: 6| Step: 1
Training loss: 0.37699814759818806
Validation loss: 2.644146935479071

Epoch: 6| Step: 2
Training loss: 0.519764611171397
Validation loss: 2.618011870790933

Epoch: 6| Step: 3
Training loss: 0.6502839651084562
Validation loss: 2.5763527484981474

Epoch: 6| Step: 4
Training loss: 0.36197567213096055
Validation loss: 2.564610629244144

Epoch: 6| Step: 5
Training loss: 0.29066619119683657
Validation loss: 2.5924198591252408

Epoch: 6| Step: 6
Training loss: 0.5717502916616373
Validation loss: 2.555048592632357

Epoch: 6| Step: 7
Training loss: 0.7813722133412861
Validation loss: 2.5374036798846933

Epoch: 6| Step: 8
Training loss: 0.366605825506106
Validation loss: 2.599611850269936

Epoch: 6| Step: 9
Training loss: 0.49011946467470063
Validation loss: 2.566681590181372

Epoch: 6| Step: 10
Training loss: 0.473536153152307
Validation loss: 2.574127954035185

Epoch: 6| Step: 11
Training loss: 0.4863625786155228
Validation loss: 2.6139672136870926

Epoch: 6| Step: 12
Training loss: 0.40621330022101826
Validation loss: 2.6041332854725874

Epoch: 6| Step: 13
Training loss: 0.5106301120889699
Validation loss: 2.629309266263027

Epoch: 338| Step: 0
Training loss: 0.3994918038741344
Validation loss: 2.6531117169722025

Epoch: 6| Step: 1
Training loss: 0.44667245436175884
Validation loss: 2.6805094533379603

Epoch: 6| Step: 2
Training loss: 0.5447478204397337
Validation loss: 2.6446824090194636

Epoch: 6| Step: 3
Training loss: 0.4018331639715244
Validation loss: 2.6419245568181613

Epoch: 6| Step: 4
Training loss: 0.3857749828449122
Validation loss: 2.6342779344735603

Epoch: 6| Step: 5
Training loss: 0.4176528663940602
Validation loss: 2.5770630758487125

Epoch: 6| Step: 6
Training loss: 0.1946363092632887
Validation loss: 2.611023513132135

Epoch: 6| Step: 7
Training loss: 0.6374694751462539
Validation loss: 2.5867015350724656

Epoch: 6| Step: 8
Training loss: 0.6294108907321013
Validation loss: 2.601048811119407

Epoch: 6| Step: 9
Training loss: 0.4928197281814754
Validation loss: 2.54141970832839

Epoch: 6| Step: 10
Training loss: 0.6408559801476106
Validation loss: 2.524661999727907

Epoch: 6| Step: 11
Training loss: 0.31277553808717723
Validation loss: 2.5056875556484406

Epoch: 6| Step: 12
Training loss: 0.6174705918448367
Validation loss: 2.5543844025595486

Epoch: 6| Step: 13
Training loss: 0.27487712358206945
Validation loss: 2.5507058175160715

Epoch: 339| Step: 0
Training loss: 0.4245481396047273
Validation loss: 2.5817845357160953

Epoch: 6| Step: 1
Training loss: 0.48418727436407566
Validation loss: 2.5647169508109764

Epoch: 6| Step: 2
Training loss: 0.5741187287496206
Validation loss: 2.59353941462728

Epoch: 6| Step: 3
Training loss: 0.37517992312768267
Validation loss: 2.5794395702440576

Epoch: 6| Step: 4
Training loss: 0.7079839873415869
Validation loss: 2.6283267709867046

Epoch: 6| Step: 5
Training loss: 0.2965022557914184
Validation loss: 2.5738604110372547

Epoch: 6| Step: 6
Training loss: 0.3453821750617643
Validation loss: 2.609765816199926

Epoch: 6| Step: 7
Training loss: 0.24005881927357978
Validation loss: 2.6091654153427446

Epoch: 6| Step: 8
Training loss: 0.3670180924202034
Validation loss: 2.61791554491841

Epoch: 6| Step: 9
Training loss: 0.4355108819296181
Validation loss: 2.586886983190322

Epoch: 6| Step: 10
Training loss: 0.5385790605923987
Validation loss: 2.620498476417798

Epoch: 6| Step: 11
Training loss: 0.4969464880421095
Validation loss: 2.604443229182137

Epoch: 6| Step: 12
Training loss: 0.6494126398744992
Validation loss: 2.6107002740692833

Epoch: 6| Step: 13
Training loss: 0.6930510144179425
Validation loss: 2.62416824224661

Epoch: 340| Step: 0
Training loss: 0.6620643397856381
Validation loss: 2.61005750944253

Epoch: 6| Step: 1
Training loss: 0.3541457319617241
Validation loss: 2.6027886719935567

Epoch: 6| Step: 2
Training loss: 0.37474744955064043
Validation loss: 2.6509558425266824

Epoch: 6| Step: 3
Training loss: 0.4281931467882466
Validation loss: 2.6308358711635993

Epoch: 6| Step: 4
Training loss: 0.48679390781644966
Validation loss: 2.630984052909484

Epoch: 6| Step: 5
Training loss: 0.5789833655842064
Validation loss: 2.6160767717080344

Epoch: 6| Step: 6
Training loss: 0.372506534243884
Validation loss: 2.6161549813327594

Epoch: 6| Step: 7
Training loss: 0.4385409913167337
Validation loss: 2.6191407933552884

Epoch: 6| Step: 8
Training loss: 0.3238710584352809
Validation loss: 2.6406417130637165

Epoch: 6| Step: 9
Training loss: 0.3947079706508812
Validation loss: 2.671027863305744

Epoch: 6| Step: 10
Training loss: 0.38059722485856073
Validation loss: 2.6258065898176954

Epoch: 6| Step: 11
Training loss: 0.7723592698507579
Validation loss: 2.6420224748990866

Epoch: 6| Step: 12
Training loss: 0.5276808050088543
Validation loss: 2.622622884895488

Epoch: 6| Step: 13
Training loss: 0.29910315529253606
Validation loss: 2.6186433267253526

Epoch: 341| Step: 0
Training loss: 0.5014000900047079
Validation loss: 2.6518432883484855

Epoch: 6| Step: 1
Training loss: 0.5161203259408645
Validation loss: 2.6032026784842595

Epoch: 6| Step: 2
Training loss: 0.427686401185159
Validation loss: 2.6285179534164893

Epoch: 6| Step: 3
Training loss: 0.6676639731594547
Validation loss: 2.6024493767439667

Epoch: 6| Step: 4
Training loss: 0.3730034128805095
Validation loss: 2.5940069710555953

Epoch: 6| Step: 5
Training loss: 0.2823606522340033
Validation loss: 2.6177525798763237

Epoch: 6| Step: 6
Training loss: 0.4856002139979493
Validation loss: 2.5970207829234186

Epoch: 6| Step: 7
Training loss: 0.5206131819520557
Validation loss: 2.6093198468183103

Epoch: 6| Step: 8
Training loss: 0.36542098230200787
Validation loss: 2.5796525762042957

Epoch: 6| Step: 9
Training loss: 0.47722604552190473
Validation loss: 2.5913190948954266

Epoch: 6| Step: 10
Training loss: 0.4323752008488926
Validation loss: 2.5916761738091343

Epoch: 6| Step: 11
Training loss: 0.38828045098512287
Validation loss: 2.5769155166768862

Epoch: 6| Step: 12
Training loss: 0.4723178661092588
Validation loss: 2.597259486742702

Epoch: 6| Step: 13
Training loss: 0.4069603065564482
Validation loss: 2.6017711166148754

Epoch: 342| Step: 0
Training loss: 0.4759854434456282
Validation loss: 2.574255786910468

Epoch: 6| Step: 1
Training loss: 0.3587396852492458
Validation loss: 2.5657680600339594

Epoch: 6| Step: 2
Training loss: 0.47766988323647797
Validation loss: 2.597387329067374

Epoch: 6| Step: 3
Training loss: 0.5640528226323426
Validation loss: 2.6070223095450857

Epoch: 6| Step: 4
Training loss: 0.1613346454143207
Validation loss: 2.6284781674595594

Epoch: 6| Step: 5
Training loss: 0.4656281464745631
Validation loss: 2.6311590568172147

Epoch: 6| Step: 6
Training loss: 0.17361587252975252
Validation loss: 2.5837975785159113

Epoch: 6| Step: 7
Training loss: 0.3672258275907962
Validation loss: 2.632342461437517

Epoch: 6| Step: 8
Training loss: 0.6280939056519279
Validation loss: 2.6166824669011803

Epoch: 6| Step: 9
Training loss: 0.4945708802842648
Validation loss: 2.5743643381391093

Epoch: 6| Step: 10
Training loss: 0.4799752531030205
Validation loss: 2.5852110928987844

Epoch: 6| Step: 11
Training loss: 0.6260281688824018
Validation loss: 2.5558428224656753

Epoch: 6| Step: 12
Training loss: 0.4345383364453833
Validation loss: 2.5486876987825497

Epoch: 6| Step: 13
Training loss: 0.39992987942011493
Validation loss: 2.5880441581022304

Epoch: 343| Step: 0
Training loss: 0.397879228112241
Validation loss: 2.5731240741466905

Epoch: 6| Step: 1
Training loss: 0.2986894547589473
Validation loss: 2.5557326289222826

Epoch: 6| Step: 2
Training loss: 0.6621031634284129
Validation loss: 2.577616951094434

Epoch: 6| Step: 3
Training loss: 0.6715985993791599
Validation loss: 2.622156232792383

Epoch: 6| Step: 4
Training loss: 0.19709039213417825
Validation loss: 2.569662273751492

Epoch: 6| Step: 5
Training loss: 0.24575670564764035
Validation loss: 2.5860893161078895

Epoch: 6| Step: 6
Training loss: 0.4889765557283927
Validation loss: 2.62938673080884

Epoch: 6| Step: 7
Training loss: 0.6555336266511972
Validation loss: 2.5896374621797085

Epoch: 6| Step: 8
Training loss: 0.5238827761503261
Validation loss: 2.579605340791232

Epoch: 6| Step: 9
Training loss: 0.4374020500889018
Validation loss: 2.605525151143926

Epoch: 6| Step: 10
Training loss: 0.32023193928000954
Validation loss: 2.643412592947116

Epoch: 6| Step: 11
Training loss: 0.5029606189289778
Validation loss: 2.6014937687642923

Epoch: 6| Step: 12
Training loss: 0.3037150097540243
Validation loss: 2.5833253708186446

Epoch: 6| Step: 13
Training loss: 0.14169064054807284
Validation loss: 2.592932086726621

Epoch: 344| Step: 0
Training loss: 0.42547564957285194
Validation loss: 2.5880594286946264

Epoch: 6| Step: 1
Training loss: 0.4970612590692284
Validation loss: 2.5804773019892195

Epoch: 6| Step: 2
Training loss: 0.3308897479639636
Validation loss: 2.5837823065481667

Epoch: 6| Step: 3
Training loss: 0.33126797177487644
Validation loss: 2.5811208750531347

Epoch: 6| Step: 4
Training loss: 0.4843908738027091
Validation loss: 2.570292867019576

Epoch: 6| Step: 5
Training loss: 0.6152222889515375
Validation loss: 2.5385564565153045

Epoch: 6| Step: 6
Training loss: 0.5424216828310886
Validation loss: 2.5514148528953053

Epoch: 6| Step: 7
Training loss: 0.4740515676607079
Validation loss: 2.5598620551030606

Epoch: 6| Step: 8
Training loss: 0.4353450084961359
Validation loss: 2.5559781595475193

Epoch: 6| Step: 9
Training loss: 0.6099340368782934
Validation loss: 2.551604502302274

Epoch: 6| Step: 10
Training loss: 0.3158629073163212
Validation loss: 2.575927118203134

Epoch: 6| Step: 11
Training loss: 0.23882472486636858
Validation loss: 2.571458699787556

Epoch: 6| Step: 12
Training loss: 0.43454901825242326
Validation loss: 2.5948062949486763

Epoch: 6| Step: 13
Training loss: 0.42169233182154786
Validation loss: 2.5899668290476807

Epoch: 345| Step: 0
Training loss: 0.6005112020001976
Validation loss: 2.6017593515759754

Epoch: 6| Step: 1
Training loss: 0.5067565502991127
Validation loss: 2.594724907566684

Epoch: 6| Step: 2
Training loss: 0.18644996514180667
Validation loss: 2.571318763716625

Epoch: 6| Step: 3
Training loss: 0.48480062857872747
Validation loss: 2.6068946614162245

Epoch: 6| Step: 4
Training loss: 0.6079624383344355
Validation loss: 2.536093151127311

Epoch: 6| Step: 5
Training loss: 0.46545350929860857
Validation loss: 2.5544956166949175

Epoch: 6| Step: 6
Training loss: 0.4879517473427787
Validation loss: 2.581626620729386

Epoch: 6| Step: 7
Training loss: 0.4498693316209339
Validation loss: 2.6141246492508303

Epoch: 6| Step: 8
Training loss: 0.31450403879389405
Validation loss: 2.611683270177514

Epoch: 6| Step: 9
Training loss: 0.44739953580959285
Validation loss: 2.6297183926880647

Epoch: 6| Step: 10
Training loss: 0.3092147156662805
Validation loss: 2.611385626738154

Epoch: 6| Step: 11
Training loss: 0.5316080121219451
Validation loss: 2.641978655284137

Epoch: 6| Step: 12
Training loss: 0.20263057837317452
Validation loss: 2.6690289323486267

Epoch: 6| Step: 13
Training loss: 0.6633603366750042
Validation loss: 2.622562422259778

Epoch: 346| Step: 0
Training loss: 0.6225428201509708
Validation loss: 2.6390619527402297

Epoch: 6| Step: 1
Training loss: 0.5787443503481006
Validation loss: 2.6078193560993412

Epoch: 6| Step: 2
Training loss: 0.23355920593617374
Validation loss: 2.6551752684978362

Epoch: 6| Step: 3
Training loss: 0.4952241078636556
Validation loss: 2.600979996328672

Epoch: 6| Step: 4
Training loss: 0.4031353357749554
Validation loss: 2.6396724980312234

Epoch: 6| Step: 5
Training loss: 0.7315003968952847
Validation loss: 2.58711054425583

Epoch: 6| Step: 6
Training loss: 0.3979643274727256
Validation loss: 2.6032676076762415

Epoch: 6| Step: 7
Training loss: 0.1575643571428694
Validation loss: 2.623593923102238

Epoch: 6| Step: 8
Training loss: 0.3931732222148128
Validation loss: 2.5953558111966686

Epoch: 6| Step: 9
Training loss: 0.30413298398602245
Validation loss: 2.5930638221690843

Epoch: 6| Step: 10
Training loss: 0.3858955947426831
Validation loss: 2.6232467837975078

Epoch: 6| Step: 11
Training loss: 0.46574989922277205
Validation loss: 2.6522477836814327

Epoch: 6| Step: 12
Training loss: 0.41093443662712753
Validation loss: 2.635855806971838

Epoch: 6| Step: 13
Training loss: 0.4323986870838386
Validation loss: 2.628023450955895

Epoch: 347| Step: 0
Training loss: 0.34736020631370235
Validation loss: 2.609553491565344

Epoch: 6| Step: 1
Training loss: 0.41492153523251113
Validation loss: 2.5623451384203935

Epoch: 6| Step: 2
Training loss: 0.5540837507911395
Validation loss: 2.6182705225995297

Epoch: 6| Step: 3
Training loss: 0.41562729383136804
Validation loss: 2.572968951285192

Epoch: 6| Step: 4
Training loss: 0.51253805019272
Validation loss: 2.5875047143599246

Epoch: 6| Step: 5
Training loss: 0.5064202811119644
Validation loss: 2.6035816039118083

Epoch: 6| Step: 6
Training loss: 0.3863898911582355
Validation loss: 2.5903152038931365

Epoch: 6| Step: 7
Training loss: 0.43760656012764604
Validation loss: 2.578393622232549

Epoch: 6| Step: 8
Training loss: 0.5571343089852245
Validation loss: 2.5630840283261986

Epoch: 6| Step: 9
Training loss: 0.44019319736054807
Validation loss: 2.5894059098001776

Epoch: 6| Step: 10
Training loss: 0.37465284093377627
Validation loss: 2.5842503922218354

Epoch: 6| Step: 11
Training loss: 0.3704716738710577
Validation loss: 2.6302400966997794

Epoch: 6| Step: 12
Training loss: 0.4987252794798379
Validation loss: 2.6054873297866568

Epoch: 6| Step: 13
Training loss: 0.1947139437459893
Validation loss: 2.693619621469178

Epoch: 348| Step: 0
Training loss: 0.44777167731142714
Validation loss: 2.6692875709679225

Epoch: 6| Step: 1
Training loss: 0.40248712744179493
Validation loss: 2.640167366085622

Epoch: 6| Step: 2
Training loss: 0.40350858344316265
Validation loss: 2.651771043917029

Epoch: 6| Step: 3
Training loss: 0.62260890383421
Validation loss: 2.6005598158134404

Epoch: 6| Step: 4
Training loss: 0.35639334521914795
Validation loss: 2.5822581244473533

Epoch: 6| Step: 5
Training loss: 0.4244972256366485
Validation loss: 2.52976337400073

Epoch: 6| Step: 6
Training loss: 0.49673276580879155
Validation loss: 2.576586989783859

Epoch: 6| Step: 7
Training loss: 0.3800040985501263
Validation loss: 2.5548169207159117

Epoch: 6| Step: 8
Training loss: 0.5506382479248454
Validation loss: 2.5604963295042196

Epoch: 6| Step: 9
Training loss: 0.536191120694412
Validation loss: 2.553833989160369

Epoch: 6| Step: 10
Training loss: 0.2512191016143377
Validation loss: 2.6038506914636375

Epoch: 6| Step: 11
Training loss: 0.5449152026571227
Validation loss: 2.576015826525605

Epoch: 6| Step: 12
Training loss: 0.46958845174121644
Validation loss: 2.600152532774584

Epoch: 6| Step: 13
Training loss: 0.2824128272162449
Validation loss: 2.5916223458969307

Epoch: 349| Step: 0
Training loss: 0.567480449843911
Validation loss: 2.613171016124713

Epoch: 6| Step: 1
Training loss: 0.4999619111812304
Validation loss: 2.64238662243508

Epoch: 6| Step: 2
Training loss: 0.5878868483108419
Validation loss: 2.625228973418495

Epoch: 6| Step: 3
Training loss: 0.39433132431558976
Validation loss: 2.6132931299373507

Epoch: 6| Step: 4
Training loss: 0.37257873160756205
Validation loss: 2.57266445417506

Epoch: 6| Step: 5
Training loss: 0.40020963718586494
Validation loss: 2.601929801247199

Epoch: 6| Step: 6
Training loss: 0.4606386120828146
Validation loss: 2.6215511896227603

Epoch: 6| Step: 7
Training loss: 0.6189533516002755
Validation loss: 2.6268478741481682

Epoch: 6| Step: 8
Training loss: 0.5023529004439734
Validation loss: 2.6389140912539837

Epoch: 6| Step: 9
Training loss: 0.3677131664221455
Validation loss: 2.6215739210378284

Epoch: 6| Step: 10
Training loss: 0.5301354441226721
Validation loss: 2.6316622820209292

Epoch: 6| Step: 11
Training loss: 0.34627997767821694
Validation loss: 2.612736103881718

Epoch: 6| Step: 12
Training loss: 0.2916470021476208
Validation loss: 2.5923772055955037

Epoch: 6| Step: 13
Training loss: 0.37186923062633537
Validation loss: 2.6300878698021104

Epoch: 350| Step: 0
Training loss: 0.3387657695351379
Validation loss: 2.5948872411245025

Epoch: 6| Step: 1
Training loss: 0.49344276635595136
Validation loss: 2.607634766451355

Epoch: 6| Step: 2
Training loss: 0.2709596626606568
Validation loss: 2.6149738042911417

Epoch: 6| Step: 3
Training loss: 0.5979054747895312
Validation loss: 2.5819051812709124

Epoch: 6| Step: 4
Training loss: 0.4727161779322996
Validation loss: 2.6073725125252634

Epoch: 6| Step: 5
Training loss: 0.6470106351249553
Validation loss: 2.5833084883935764

Epoch: 6| Step: 6
Training loss: 0.40155819248605457
Validation loss: 2.5614794407875197

Epoch: 6| Step: 7
Training loss: 0.30401962391592235
Validation loss: 2.5718108237695505

Epoch: 6| Step: 8
Training loss: 0.5372716485157751
Validation loss: 2.558649821771934

Epoch: 6| Step: 9
Training loss: 0.41947778684346365
Validation loss: 2.6246064443356563

Epoch: 6| Step: 10
Training loss: 0.4081117628150289
Validation loss: 2.577956371690535

Epoch: 6| Step: 11
Training loss: 0.24808658071803055
Validation loss: 2.6323612021454093

Epoch: 6| Step: 12
Training loss: 0.441560853197789
Validation loss: 2.558241983865584

Epoch: 6| Step: 13
Training loss: 0.2621785153701204
Validation loss: 2.637785247026301

Epoch: 351| Step: 0
Training loss: 0.13604425535421427
Validation loss: 2.6435050144323995

Epoch: 6| Step: 1
Training loss: 0.2599344780322749
Validation loss: 2.5984427275006414

Epoch: 6| Step: 2
Training loss: 0.5375152718791876
Validation loss: 2.565070594945608

Epoch: 6| Step: 3
Training loss: 0.45944577015810173
Validation loss: 2.598179236420149

Epoch: 6| Step: 4
Training loss: 0.34652629198780627
Validation loss: 2.631136237701098

Epoch: 6| Step: 5
Training loss: 0.4033184651847449
Validation loss: 2.6349439455193924

Epoch: 6| Step: 6
Training loss: 0.3445187663716619
Validation loss: 2.6202945109627165

Epoch: 6| Step: 7
Training loss: 0.5922324211374808
Validation loss: 2.6364053485402086

Epoch: 6| Step: 8
Training loss: 0.7299556868311192
Validation loss: 2.6332912166255014

Epoch: 6| Step: 9
Training loss: 0.4359527886010222
Validation loss: 2.6109868465653157

Epoch: 6| Step: 10
Training loss: 0.591856119444873
Validation loss: 2.6177771031353023

Epoch: 6| Step: 11
Training loss: 0.2992403142145557
Validation loss: 2.6086362201003714

Epoch: 6| Step: 12
Training loss: 0.4253303870504652
Validation loss: 2.5934423349925457

Epoch: 6| Step: 13
Training loss: 0.1363449777608636
Validation loss: 2.597680851458005

Epoch: 352| Step: 0
Training loss: 0.611657684513149
Validation loss: 2.59167614017693

Epoch: 6| Step: 1
Training loss: 0.46938643166022076
Validation loss: 2.542792892947166

Epoch: 6| Step: 2
Training loss: 0.3882551787007072
Validation loss: 2.5794031698104

Epoch: 6| Step: 3
Training loss: 0.4885746493996234
Validation loss: 2.6226254107806426

Epoch: 6| Step: 4
Training loss: 0.41924515244713095
Validation loss: 2.6091024241577165

Epoch: 6| Step: 5
Training loss: 0.4943649325690032
Validation loss: 2.62756460087202

Epoch: 6| Step: 6
Training loss: 0.4581071790583164
Validation loss: 2.647332100686349

Epoch: 6| Step: 7
Training loss: 0.5692989016701379
Validation loss: 2.677850716625416

Epoch: 6| Step: 8
Training loss: 0.3053294778981969
Validation loss: 2.6152083114022115

Epoch: 6| Step: 9
Training loss: 0.38285967477782756
Validation loss: 2.613442261230521

Epoch: 6| Step: 10
Training loss: 0.4263049413561535
Validation loss: 2.6389855046729926

Epoch: 6| Step: 11
Training loss: 0.42500319830308125
Validation loss: 2.610011121908249

Epoch: 6| Step: 12
Training loss: 0.19314014645472366
Validation loss: 2.59169191066525

Epoch: 6| Step: 13
Training loss: 0.20367974859074853
Validation loss: 2.5842297203251077

Epoch: 353| Step: 0
Training loss: 0.6046874881714812
Validation loss: 2.58931083605384

Epoch: 6| Step: 1
Training loss: 0.3546915045692806
Validation loss: 2.576151683617257

Epoch: 6| Step: 2
Training loss: 0.41084843312164676
Validation loss: 2.5483870948271248

Epoch: 6| Step: 3
Training loss: 0.4803700229348231
Validation loss: 2.5543376443086703

Epoch: 6| Step: 4
Training loss: 0.6153928038047739
Validation loss: 2.5915659072936337

Epoch: 6| Step: 5
Training loss: 0.44745605279594897
Validation loss: 2.6142998874168013

Epoch: 6| Step: 6
Training loss: 0.35220337839558746
Validation loss: 2.5728198654287335

Epoch: 6| Step: 7
Training loss: 0.25934489316742365
Validation loss: 2.6175701191655425

Epoch: 6| Step: 8
Training loss: 0.5561491285437132
Validation loss: 2.644935829373108

Epoch: 6| Step: 9
Training loss: 0.46313486214869515
Validation loss: 2.647899694441525

Epoch: 6| Step: 10
Training loss: 0.1754352024411725
Validation loss: 2.6718968379311967

Epoch: 6| Step: 11
Training loss: 0.3815693815143463
Validation loss: 2.637896338670238

Epoch: 6| Step: 12
Training loss: 0.18467608453678222
Validation loss: 2.6304188414532614

Epoch: 6| Step: 13
Training loss: 0.3821115889062976
Validation loss: 2.672125296510973

Epoch: 354| Step: 0
Training loss: 0.37431168965016115
Validation loss: 2.6503625740511487

Epoch: 6| Step: 1
Training loss: 0.6006235002385845
Validation loss: 2.634792388344911

Epoch: 6| Step: 2
Training loss: 0.5739086637334543
Validation loss: 2.56791969458938

Epoch: 6| Step: 3
Training loss: 0.3535112096184087
Validation loss: 2.6621284695138083

Epoch: 6| Step: 4
Training loss: 0.464087231294936
Validation loss: 2.6164347208072787

Epoch: 6| Step: 5
Training loss: 0.6573859555727323
Validation loss: 2.5734093953070643

Epoch: 6| Step: 6
Training loss: 0.4256189719514077
Validation loss: 2.583070260968696

Epoch: 6| Step: 7
Training loss: 0.3655312703293975
Validation loss: 2.564079164243625

Epoch: 6| Step: 8
Training loss: 0.38089824380362114
Validation loss: 2.5916795271355335

Epoch: 6| Step: 9
Training loss: 0.1819031264491249
Validation loss: 2.6008595458571038

Epoch: 6| Step: 10
Training loss: 0.18122426376466869
Validation loss: 2.5708360330507625

Epoch: 6| Step: 11
Training loss: 0.38522872552421294
Validation loss: 2.5614024627379486

Epoch: 6| Step: 12
Training loss: 0.29723995764622846
Validation loss: 2.5891002356834028

Epoch: 6| Step: 13
Training loss: 0.15317580830124333
Validation loss: 2.573337207861195

Epoch: 355| Step: 0
Training loss: 0.4501614671674279
Validation loss: 2.573252415174095

Epoch: 6| Step: 1
Training loss: 0.7320937171753981
Validation loss: 2.561490792832361

Epoch: 6| Step: 2
Training loss: 0.4277664242238249
Validation loss: 2.5895944301883014

Epoch: 6| Step: 3
Training loss: 0.27806221221099525
Validation loss: 2.5922636934718475

Epoch: 6| Step: 4
Training loss: 0.19701620896094268
Validation loss: 2.592273264592382

Epoch: 6| Step: 5
Training loss: 0.3637435186929501
Validation loss: 2.5976030483529593

Epoch: 6| Step: 6
Training loss: 0.5295992898775653
Validation loss: 2.6027301618048386

Epoch: 6| Step: 7
Training loss: 0.4208860815938537
Validation loss: 2.6164960853677166

Epoch: 6| Step: 8
Training loss: 0.5885365128643144
Validation loss: 2.626743743404419

Epoch: 6| Step: 9
Training loss: 0.2568742411664906
Validation loss: 2.6049404394279176

Epoch: 6| Step: 10
Training loss: 0.2998428071977782
Validation loss: 2.605987033348761

Epoch: 6| Step: 11
Training loss: 0.32699554058848923
Validation loss: 2.6188324050924803

Epoch: 6| Step: 12
Training loss: 0.5224327578922093
Validation loss: 2.612549274975119

Epoch: 6| Step: 13
Training loss: 0.3160706966024518
Validation loss: 2.6207940450936817

Epoch: 356| Step: 0
Training loss: 0.2776208218891764
Validation loss: 2.5729959987250277

Epoch: 6| Step: 1
Training loss: 0.6460616467029169
Validation loss: 2.6209450149497355

Epoch: 6| Step: 2
Training loss: 0.3195971665793303
Validation loss: 2.5733040928995163

Epoch: 6| Step: 3
Training loss: 0.32443085591981735
Validation loss: 2.5574207744901982

Epoch: 6| Step: 4
Training loss: 0.38811362733626537
Validation loss: 2.6037563081053614

Epoch: 6| Step: 5
Training loss: 0.33320939347697676
Validation loss: 2.5941056720419313

Epoch: 6| Step: 6
Training loss: 0.30824752893872853
Validation loss: 2.573214974276706

Epoch: 6| Step: 7
Training loss: 0.2893144695011396
Validation loss: 2.6402274707097733

Epoch: 6| Step: 8
Training loss: 0.40075404723652785
Validation loss: 2.58524266703971

Epoch: 6| Step: 9
Training loss: 0.3842735435753568
Validation loss: 2.632292026523468

Epoch: 6| Step: 10
Training loss: 0.5517615664194064
Validation loss: 2.612778511398077

Epoch: 6| Step: 11
Training loss: 0.6026131755932448
Validation loss: 2.615514172750123

Epoch: 6| Step: 12
Training loss: 0.2868656109746531
Validation loss: 2.620439346648638

Epoch: 6| Step: 13
Training loss: 0.5742829215594237
Validation loss: 2.6302523825039463

Epoch: 357| Step: 0
Training loss: 0.25997595052265643
Validation loss: 2.629376247634669

Epoch: 6| Step: 1
Training loss: 0.4369995967952605
Validation loss: 2.5929835482252144

Epoch: 6| Step: 2
Training loss: 0.43914584118918343
Validation loss: 2.6218095431099706

Epoch: 6| Step: 3
Training loss: 0.46184881285787105
Validation loss: 2.603306417487437

Epoch: 6| Step: 4
Training loss: 0.19765631068835626
Validation loss: 2.626275036609959

Epoch: 6| Step: 5
Training loss: 0.4308329486783719
Validation loss: 2.6608177679098683

Epoch: 6| Step: 6
Training loss: 0.4685019631594032
Validation loss: 2.6134917837216673

Epoch: 6| Step: 7
Training loss: 0.5534144016229665
Validation loss: 2.6487168788369786

Epoch: 6| Step: 8
Training loss: 0.6442360172922954
Validation loss: 2.6616599691654765

Epoch: 6| Step: 9
Training loss: 0.3294183807831865
Validation loss: 2.63662049007505

Epoch: 6| Step: 10
Training loss: 0.49099672170348735
Validation loss: 2.635939434407325

Epoch: 6| Step: 11
Training loss: 0.2582159642246204
Validation loss: 2.6354459810959208

Epoch: 6| Step: 12
Training loss: 0.3133699110909026
Validation loss: 2.594061949249117

Epoch: 6| Step: 13
Training loss: 0.4918995120667474
Validation loss: 2.6313600328480318

Epoch: 358| Step: 0
Training loss: 0.25935859628304564
Validation loss: 2.588781564610337

Epoch: 6| Step: 1
Training loss: 0.24594508327828368
Validation loss: 2.608831749815761

Epoch: 6| Step: 2
Training loss: 0.3515652126631456
Validation loss: 2.6179736510924307

Epoch: 6| Step: 3
Training loss: 0.4056165598504059
Validation loss: 2.61768883948181

Epoch: 6| Step: 4
Training loss: 0.4231677381999745
Validation loss: 2.6406444518019736

Epoch: 6| Step: 5
Training loss: 0.5625715740020034
Validation loss: 2.5959059216771

Epoch: 6| Step: 6
Training loss: 0.41580336264291407
Validation loss: 2.605316710158996

Epoch: 6| Step: 7
Training loss: 0.5329032865350289
Validation loss: 2.5965496540155013

Epoch: 6| Step: 8
Training loss: 0.31658032420779153
Validation loss: 2.533509089386113

Epoch: 6| Step: 9
Training loss: 0.5262607332344704
Validation loss: 2.5015208632754606

Epoch: 6| Step: 10
Training loss: 0.48427816161301834
Validation loss: 2.4813888227045124

Epoch: 6| Step: 11
Training loss: 0.5639209548584588
Validation loss: 2.5361142684556315

Epoch: 6| Step: 12
Training loss: 0.5076624428514303
Validation loss: 2.5354972460992897

Epoch: 6| Step: 13
Training loss: 0.3918702685300176
Validation loss: 2.582096505053755

Epoch: 359| Step: 0
Training loss: 0.36994608041589633
Validation loss: 2.6454394060748423

Epoch: 6| Step: 1
Training loss: 0.5615594205522458
Validation loss: 2.650603631317069

Epoch: 6| Step: 2
Training loss: 0.5392266175705611
Validation loss: 2.664587930221253

Epoch: 6| Step: 3
Training loss: 0.4987517959399861
Validation loss: 2.662682602404772

Epoch: 6| Step: 4
Training loss: 0.42002477050578807
Validation loss: 2.6146825492051744

Epoch: 6| Step: 5
Training loss: 0.421023321543267
Validation loss: 2.604867661337244

Epoch: 6| Step: 6
Training loss: 0.41373643092237433
Validation loss: 2.620981686967553

Epoch: 6| Step: 7
Training loss: 0.4154616414897005
Validation loss: 2.570356504849883

Epoch: 6| Step: 8
Training loss: 0.5602540105108463
Validation loss: 2.527279799773585

Epoch: 6| Step: 9
Training loss: 0.4124660665831006
Validation loss: 2.5618512462646352

Epoch: 6| Step: 10
Training loss: 0.39238971725016786
Validation loss: 2.5151674403159854

Epoch: 6| Step: 11
Training loss: 0.47604683039206724
Validation loss: 2.6001500580193624

Epoch: 6| Step: 12
Training loss: 0.47929067320102914
Validation loss: 2.6451880236757175

Epoch: 6| Step: 13
Training loss: 0.41690323392318773
Validation loss: 2.6492225992630196

Epoch: 360| Step: 0
Training loss: 0.6017823251141257
Validation loss: 2.6410556361246806

Epoch: 6| Step: 1
Training loss: 0.34233598971048185
Validation loss: 2.6343367098323425

Epoch: 6| Step: 2
Training loss: 0.49527844694029016
Validation loss: 2.6258733285943476

Epoch: 6| Step: 3
Training loss: 0.38462871691172684
Validation loss: 2.5560478970376703

Epoch: 6| Step: 4
Training loss: 0.38869474334150683
Validation loss: 2.606450733972846

Epoch: 6| Step: 5
Training loss: 0.41969994291491936
Validation loss: 2.606144255028891

Epoch: 6| Step: 6
Training loss: 0.4775546642789417
Validation loss: 2.6284192323221123

Epoch: 6| Step: 7
Training loss: 0.293372740358542
Validation loss: 2.602956246571607

Epoch: 6| Step: 8
Training loss: 0.575354769354171
Validation loss: 2.560823166535805

Epoch: 6| Step: 9
Training loss: 0.39479273449527724
Validation loss: 2.5486451150509133

Epoch: 6| Step: 10
Training loss: 0.2926889991257549
Validation loss: 2.5757466950487533

Epoch: 6| Step: 11
Training loss: 0.5148528704609632
Validation loss: 2.6336750808257188

Epoch: 6| Step: 12
Training loss: 0.46787300722562564
Validation loss: 2.6391159768039145

Epoch: 6| Step: 13
Training loss: 0.25333504615589475
Validation loss: 2.626341932352569

Epoch: 361| Step: 0
Training loss: 0.4713408554333244
Validation loss: 2.6495411386784236

Epoch: 6| Step: 1
Training loss: 0.4624277689951773
Validation loss: 2.6797001292861684

Epoch: 6| Step: 2
Training loss: 0.21821401702050672
Validation loss: 2.6844488854675883

Epoch: 6| Step: 3
Training loss: 0.5151070391886979
Validation loss: 2.7161001007848915

Epoch: 6| Step: 4
Training loss: 0.48748376953787764
Validation loss: 2.7067263998784967

Epoch: 6| Step: 5
Training loss: 0.45256716822447757
Validation loss: 2.666862518734992

Epoch: 6| Step: 6
Training loss: 0.4946830697261878
Validation loss: 2.6876000654970764

Epoch: 6| Step: 7
Training loss: 0.5410848910614172
Validation loss: 2.672187007851563

Epoch: 6| Step: 8
Training loss: 0.19196369778584274
Validation loss: 2.666041956362875

Epoch: 6| Step: 9
Training loss: 0.47176862553457305
Validation loss: 2.6164285371425224

Epoch: 6| Step: 10
Training loss: 0.37400389538103107
Validation loss: 2.601506652498659

Epoch: 6| Step: 11
Training loss: 0.5115488658525938
Validation loss: 2.627720475426426

Epoch: 6| Step: 12
Training loss: 0.2998088997908418
Validation loss: 2.6079427133401443

Epoch: 6| Step: 13
Training loss: 0.31607891151646794
Validation loss: 2.6135677582371852

Epoch: 362| Step: 0
Training loss: 0.5014865354249852
Validation loss: 2.589694477377994

Epoch: 6| Step: 1
Training loss: 0.42342294055640367
Validation loss: 2.5968855852142076

Epoch: 6| Step: 2
Training loss: 0.26579778324936515
Validation loss: 2.5882653470430776

Epoch: 6| Step: 3
Training loss: 0.29939677169253176
Validation loss: 2.610583054144685

Epoch: 6| Step: 4
Training loss: 0.4493789055645277
Validation loss: 2.616212266252116

Epoch: 6| Step: 5
Training loss: 0.2674491181512209
Validation loss: 2.6644105833913407

Epoch: 6| Step: 6
Training loss: 0.5077771688054665
Validation loss: 2.613798490326676

Epoch: 6| Step: 7
Training loss: 0.541364151279824
Validation loss: 2.6538285164544155

Epoch: 6| Step: 8
Training loss: 0.6247461995745375
Validation loss: 2.6520386929603084

Epoch: 6| Step: 9
Training loss: 0.4949509983180231
Validation loss: 2.596338636131532

Epoch: 6| Step: 10
Training loss: 0.2305785822612098
Validation loss: 2.6061091473526528

Epoch: 6| Step: 11
Training loss: 0.37408462701172834
Validation loss: 2.635203666660861

Epoch: 6| Step: 12
Training loss: 0.3052788644260678
Validation loss: 2.6235307174501576

Epoch: 6| Step: 13
Training loss: 0.2624445288948532
Validation loss: 2.5867546566735653

Epoch: 363| Step: 0
Training loss: 0.21029561891867277
Validation loss: 2.6115055926970134

Epoch: 6| Step: 1
Training loss: 0.4747250576869619
Validation loss: 2.621277422188531

Epoch: 6| Step: 2
Training loss: 0.17301021450233106
Validation loss: 2.6106079462288183

Epoch: 6| Step: 3
Training loss: 0.5357554067996604
Validation loss: 2.636571897414982

Epoch: 6| Step: 4
Training loss: 0.39016337775096627
Validation loss: 2.617200719842535

Epoch: 6| Step: 5
Training loss: 0.5558216159887577
Validation loss: 2.5897070109705953

Epoch: 6| Step: 6
Training loss: 0.3894222243436445
Validation loss: 2.611943437440727

Epoch: 6| Step: 7
Training loss: 0.45426111187147944
Validation loss: 2.6416824853398304

Epoch: 6| Step: 8
Training loss: 0.2421130635096582
Validation loss: 2.6216670732860514

Epoch: 6| Step: 9
Training loss: 0.4096540737410027
Validation loss: 2.6175445033982347

Epoch: 6| Step: 10
Training loss: 0.42210470233359393
Validation loss: 2.6307114532456004

Epoch: 6| Step: 11
Training loss: 0.4683763922494273
Validation loss: 2.6295834970693956

Epoch: 6| Step: 12
Training loss: 0.2566597628026179
Validation loss: 2.6365361467130137

Epoch: 6| Step: 13
Training loss: 0.5373065655868582
Validation loss: 2.6014989266016646

Epoch: 364| Step: 0
Training loss: 0.5172401332292126
Validation loss: 2.6022312051715115

Epoch: 6| Step: 1
Training loss: 0.33833688141969953
Validation loss: 2.6069567746819375

Epoch: 6| Step: 2
Training loss: 0.4157983275084921
Validation loss: 2.5979160013354328

Epoch: 6| Step: 3
Training loss: 0.2032330024135012
Validation loss: 2.6323566199704103

Epoch: 6| Step: 4
Training loss: 0.48685962481333
Validation loss: 2.643402220676642

Epoch: 6| Step: 5
Training loss: 0.3412611659637072
Validation loss: 2.6173347129308913

Epoch: 6| Step: 6
Training loss: 0.29830228128919645
Validation loss: 2.6034765544081377

Epoch: 6| Step: 7
Training loss: 0.2563461739633484
Validation loss: 2.6516251762670384

Epoch: 6| Step: 8
Training loss: 0.5111661941653417
Validation loss: 2.6036650445664957

Epoch: 6| Step: 9
Training loss: 0.4980877279842237
Validation loss: 2.6173683678262605

Epoch: 6| Step: 10
Training loss: 0.2780211061743356
Validation loss: 2.580200531236364

Epoch: 6| Step: 11
Training loss: 0.5574930457036387
Validation loss: 2.5684437692714113

Epoch: 6| Step: 12
Training loss: 0.2795291548299126
Validation loss: 2.5902597265323752

Epoch: 6| Step: 13
Training loss: 0.30924402604928525
Validation loss: 2.5392048104084473

Epoch: 365| Step: 0
Training loss: 0.3508044228832804
Validation loss: 2.5409604787220026

Epoch: 6| Step: 1
Training loss: 0.5096586560964349
Validation loss: 2.553113699662956

Epoch: 6| Step: 2
Training loss: 0.41723836381570756
Validation loss: 2.5602261058331792

Epoch: 6| Step: 3
Training loss: 0.3578205907315054
Validation loss: 2.6125622562872937

Epoch: 6| Step: 4
Training loss: 0.4131474370245142
Validation loss: 2.5877124838831573

Epoch: 6| Step: 5
Training loss: 0.23936004011752912
Validation loss: 2.6398788857249245

Epoch: 6| Step: 6
Training loss: 0.2109505508058965
Validation loss: 2.619229024719561

Epoch: 6| Step: 7
Training loss: 0.5326900598790552
Validation loss: 2.6377858593177734

Epoch: 6| Step: 8
Training loss: 0.2047535826028432
Validation loss: 2.6370977347981435

Epoch: 6| Step: 9
Training loss: 0.5898528950973851
Validation loss: 2.615357655003118

Epoch: 6| Step: 10
Training loss: 0.22219518138521768
Validation loss: 2.593819679681362

Epoch: 6| Step: 11
Training loss: 0.27083207399124404
Validation loss: 2.6535340217488366

Epoch: 6| Step: 12
Training loss: 0.5235129914006167
Validation loss: 2.616669371805804

Epoch: 6| Step: 13
Training loss: 0.26760804224876805
Validation loss: 2.6019682568563582

Epoch: 366| Step: 0
Training loss: 0.3229668011765724
Validation loss: 2.626899430494387

Epoch: 6| Step: 1
Training loss: 0.25304475030245543
Validation loss: 2.606463856801837

Epoch: 6| Step: 2
Training loss: 0.41121471613106986
Validation loss: 2.5951314450452547

Epoch: 6| Step: 3
Training loss: 0.24391911184988962
Validation loss: 2.597406505564264

Epoch: 6| Step: 4
Training loss: 0.29219749657976957
Validation loss: 2.6077221317048416

Epoch: 6| Step: 5
Training loss: 0.5157707470757948
Validation loss: 2.5849295364518694

Epoch: 6| Step: 6
Training loss: 0.3563118880875062
Validation loss: 2.6170962699034126

Epoch: 6| Step: 7
Training loss: 0.15118664464830817
Validation loss: 2.591315006037699

Epoch: 6| Step: 8
Training loss: 0.7431736067009918
Validation loss: 2.646673986708377

Epoch: 6| Step: 9
Training loss: 0.2411834222335679
Validation loss: 2.6203106189419962

Epoch: 6| Step: 10
Training loss: 0.4673099013007961
Validation loss: 2.597252434217799

Epoch: 6| Step: 11
Training loss: 0.368339557458467
Validation loss: 2.649711929269299

Epoch: 6| Step: 12
Training loss: 0.4878776102643723
Validation loss: 2.629768270113777

Epoch: 6| Step: 13
Training loss: 0.361101646584597
Validation loss: 2.6294020888955307

Epoch: 367| Step: 0
Training loss: 0.5025280283707287
Validation loss: 2.611826327785933

Epoch: 6| Step: 1
Training loss: 0.2899729078479656
Validation loss: 2.581553419995891

Epoch: 6| Step: 2
Training loss: 0.5399032891173488
Validation loss: 2.5994802819683467

Epoch: 6| Step: 3
Training loss: 0.3449592885412218
Validation loss: 2.5772134914060985

Epoch: 6| Step: 4
Training loss: 0.45131334341023477
Validation loss: 2.5545356893288256

Epoch: 6| Step: 5
Training loss: 0.5054361052783389
Validation loss: 2.5833754031605873

Epoch: 6| Step: 6
Training loss: 0.2816963627404725
Validation loss: 2.5788031657195734

Epoch: 6| Step: 7
Training loss: 0.28869097263207355
Validation loss: 2.5900774496904266

Epoch: 6| Step: 8
Training loss: 0.4394783690937283
Validation loss: 2.600442405953037

Epoch: 6| Step: 9
Training loss: 0.4240499873834767
Validation loss: 2.5381383312320356

Epoch: 6| Step: 10
Training loss: 0.34427946669487275
Validation loss: 2.574544000317207

Epoch: 6| Step: 11
Training loss: 0.30631590007661014
Validation loss: 2.6123725131099196

Epoch: 6| Step: 12
Training loss: 0.20362842970009334
Validation loss: 2.565307465879632

Epoch: 6| Step: 13
Training loss: 0.36516664254347914
Validation loss: 2.6598450539801424

Epoch: 368| Step: 0
Training loss: 0.3691820595713199
Validation loss: 2.591186927440276

Epoch: 6| Step: 1
Training loss: 0.3416758840856644
Validation loss: 2.5581216155617965

Epoch: 6| Step: 2
Training loss: 0.39948318741361105
Validation loss: 2.5675829824947836

Epoch: 6| Step: 3
Training loss: 0.5863174224019031
Validation loss: 2.5147686469320116

Epoch: 6| Step: 4
Training loss: 0.6007855339542434
Validation loss: 2.5551760697024215

Epoch: 6| Step: 5
Training loss: 0.32344722871384846
Validation loss: 2.5440396323830816

Epoch: 6| Step: 6
Training loss: 0.5096702047906736
Validation loss: 2.593213939856628

Epoch: 6| Step: 7
Training loss: 0.3123972366168355
Validation loss: 2.5754960354628422

Epoch: 6| Step: 8
Training loss: 0.45054931954821525
Validation loss: 2.591633072792214

Epoch: 6| Step: 9
Training loss: 0.3672895086913492
Validation loss: 2.616407523253207

Epoch: 6| Step: 10
Training loss: 0.3616384050355103
Validation loss: 2.650493158364877

Epoch: 6| Step: 11
Training loss: 0.27242430574007115
Validation loss: 2.6101989879510605

Epoch: 6| Step: 12
Training loss: 0.4458290918392077
Validation loss: 2.5979018287805005

Epoch: 6| Step: 13
Training loss: 0.4617834087867871
Validation loss: 2.6222356390982053

Epoch: 369| Step: 0
Training loss: 0.30169825290177865
Validation loss: 2.5859007786155157

Epoch: 6| Step: 1
Training loss: 0.4453075308271526
Validation loss: 2.5656847388236383

Epoch: 6| Step: 2
Training loss: 0.2950008614980112
Validation loss: 2.5445786065988445

Epoch: 6| Step: 3
Training loss: 0.20927697491846947
Validation loss: 2.542741847331708

Epoch: 6| Step: 4
Training loss: 0.45034253077864445
Validation loss: 2.553208320452908

Epoch: 6| Step: 5
Training loss: 0.3517790974855034
Validation loss: 2.5539966381790067

Epoch: 6| Step: 6
Training loss: 0.5625093777192743
Validation loss: 2.550741130443814

Epoch: 6| Step: 7
Training loss: 0.34854755374218005
Validation loss: 2.6544891234436965

Epoch: 6| Step: 8
Training loss: 0.5441268809623641
Validation loss: 2.6353645447633536

Epoch: 6| Step: 9
Training loss: 0.5591207032800793
Validation loss: 2.6558686862797036

Epoch: 6| Step: 10
Training loss: 0.5001581955037389
Validation loss: 2.6598006007674946

Epoch: 6| Step: 11
Training loss: 0.3584082079810708
Validation loss: 2.6900367564376793

Epoch: 6| Step: 12
Training loss: 0.41942920615906704
Validation loss: 2.63309869202433

Epoch: 6| Step: 13
Training loss: 0.6800461623006208
Validation loss: 2.6437703614197625

Epoch: 370| Step: 0
Training loss: 0.3904190474220135
Validation loss: 2.5915533322405615

Epoch: 6| Step: 1
Training loss: 0.44905674542461044
Validation loss: 2.56647737828122

Epoch: 6| Step: 2
Training loss: 0.5331962780635107
Validation loss: 2.5194403086723383

Epoch: 6| Step: 3
Training loss: 0.409441825275521
Validation loss: 2.509950173654816

Epoch: 6| Step: 4
Training loss: 0.29826941025557374
Validation loss: 2.5244837401999565

Epoch: 6| Step: 5
Training loss: 0.5347017460435162
Validation loss: 2.5583281493694754

Epoch: 6| Step: 6
Training loss: 0.5151524545878584
Validation loss: 2.6033466752848944

Epoch: 6| Step: 7
Training loss: 0.5062441743115204
Validation loss: 2.590514706316534

Epoch: 6| Step: 8
Training loss: 0.2457665432836381
Validation loss: 2.6018308721406345

Epoch: 6| Step: 9
Training loss: 0.29039978304367525
Validation loss: 2.650041226348633

Epoch: 6| Step: 10
Training loss: 0.3661322140319941
Validation loss: 2.649566598465009

Epoch: 6| Step: 11
Training loss: 0.38407339963663345
Validation loss: 2.639797592943132

Epoch: 6| Step: 12
Training loss: 0.38166762444877106
Validation loss: 2.616082635269348

Epoch: 6| Step: 13
Training loss: 0.6292009314833898
Validation loss: 2.585712465327264

Epoch: 371| Step: 0
Training loss: 0.37200989320248706
Validation loss: 2.6054620817892147

Epoch: 6| Step: 1
Training loss: 0.5402279570026596
Validation loss: 2.5374017390206585

Epoch: 6| Step: 2
Training loss: 0.4107946060406452
Validation loss: 2.549186428208431

Epoch: 6| Step: 3
Training loss: 0.45075834404515863
Validation loss: 2.5228336086200436

Epoch: 6| Step: 4
Training loss: 0.4907776910846533
Validation loss: 2.517686540169725

Epoch: 6| Step: 5
Training loss: 0.2262825057879012
Validation loss: 2.5033344315096246

Epoch: 6| Step: 6
Training loss: 0.38272885946398144
Validation loss: 2.475184137167901

Epoch: 6| Step: 7
Training loss: 0.39500723349309863
Validation loss: 2.5281563147911355

Epoch: 6| Step: 8
Training loss: 0.4768638283557135
Validation loss: 2.5238621766245783

Epoch: 6| Step: 9
Training loss: 0.30805269929012513
Validation loss: 2.563524323111789

Epoch: 6| Step: 10
Training loss: 0.45082521538232967
Validation loss: 2.5505841190996064

Epoch: 6| Step: 11
Training loss: 0.38004870090109516
Validation loss: 2.5947236577208237

Epoch: 6| Step: 12
Training loss: 0.6638040825170316
Validation loss: 2.622456458502437

Epoch: 6| Step: 13
Training loss: 0.22390313447806556
Validation loss: 2.614521682013049

Epoch: 372| Step: 0
Training loss: 0.3135198640477372
Validation loss: 2.6086974673906145

Epoch: 6| Step: 1
Training loss: 0.39025506622476547
Validation loss: 2.6535548957234134

Epoch: 6| Step: 2
Training loss: 0.4565776301807166
Validation loss: 2.61410891553579

Epoch: 6| Step: 3
Training loss: 0.40529141673456887
Validation loss: 2.61707278743938

Epoch: 6| Step: 4
Training loss: 0.40490062065359583
Validation loss: 2.5883382170640705

Epoch: 6| Step: 5
Training loss: 0.257418389072462
Validation loss: 2.5568431098877102

Epoch: 6| Step: 6
Training loss: 0.4472312247694422
Validation loss: 2.6000551222644557

Epoch: 6| Step: 7
Training loss: 0.3931724263195582
Validation loss: 2.6028634342475323

Epoch: 6| Step: 8
Training loss: 0.462726644451095
Validation loss: 2.569579612578536

Epoch: 6| Step: 9
Training loss: 0.37397588522195746
Validation loss: 2.527351428706203

Epoch: 6| Step: 10
Training loss: 0.6514804404199728
Validation loss: 2.532356433611559

Epoch: 6| Step: 11
Training loss: 0.4487492305249601
Validation loss: 2.517954570692962

Epoch: 6| Step: 12
Training loss: 0.3419925347658112
Validation loss: 2.5116985099955684

Epoch: 6| Step: 13
Training loss: 0.36481976562997515
Validation loss: 2.59365272463112

Epoch: 373| Step: 0
Training loss: 0.3306947625155261
Validation loss: 2.5484116186252677

Epoch: 6| Step: 1
Training loss: 0.5701570690982336
Validation loss: 2.5984144132180718

Epoch: 6| Step: 2
Training loss: 0.43565481926699723
Validation loss: 2.588492966568887

Epoch: 6| Step: 3
Training loss: 0.5562283243820919
Validation loss: 2.582275192440568

Epoch: 6| Step: 4
Training loss: 0.44713900577065224
Validation loss: 2.5584623599733805

Epoch: 6| Step: 5
Training loss: 0.280033952961986
Validation loss: 2.5761668883701163

Epoch: 6| Step: 6
Training loss: 0.5747531298717683
Validation loss: 2.592154407322745

Epoch: 6| Step: 7
Training loss: 0.3996741979680551
Validation loss: 2.5870328939615947

Epoch: 6| Step: 8
Training loss: 0.39019669894083736
Validation loss: 2.607116891297274

Epoch: 6| Step: 9
Training loss: 0.30143788732796056
Validation loss: 2.59882243623536

Epoch: 6| Step: 10
Training loss: 0.31935198915601776
Validation loss: 2.6167596821515997

Epoch: 6| Step: 11
Training loss: 0.35874273824486463
Validation loss: 2.595505691622559

Epoch: 6| Step: 12
Training loss: 0.23689522758769652
Validation loss: 2.562747924320351

Epoch: 6| Step: 13
Training loss: 0.5538897620842234
Validation loss: 2.607262469335801

Epoch: 374| Step: 0
Training loss: 0.34308894490849373
Validation loss: 2.5801892600182796

Epoch: 6| Step: 1
Training loss: 0.26306747111170753
Validation loss: 2.591718102936442

Epoch: 6| Step: 2
Training loss: 0.3853000859769106
Validation loss: 2.6254485245688004

Epoch: 6| Step: 3
Training loss: 0.3436207203083372
Validation loss: 2.5714058803213797

Epoch: 6| Step: 4
Training loss: 0.4933244652074549
Validation loss: 2.6173717117436266

Epoch: 6| Step: 5
Training loss: 0.3740579175867595
Validation loss: 2.5963659101198755

Epoch: 6| Step: 6
Training loss: 0.3999950781161765
Validation loss: 2.617260223979827

Epoch: 6| Step: 7
Training loss: 0.4645892175663884
Validation loss: 2.5702797021464834

Epoch: 6| Step: 8
Training loss: 0.40806975307670545
Validation loss: 2.5815515483230436

Epoch: 6| Step: 9
Training loss: 0.3530208856142301
Validation loss: 2.6160740234194457

Epoch: 6| Step: 10
Training loss: 0.4149055176349419
Validation loss: 2.6003828728755907

Epoch: 6| Step: 11
Training loss: 0.5586256004803158
Validation loss: 2.621430880485203

Epoch: 6| Step: 12
Training loss: 0.3519938895171993
Validation loss: 2.635268979642408

Epoch: 6| Step: 13
Training loss: 0.20783436846577286
Validation loss: 2.6269448644908686

Epoch: 375| Step: 0
Training loss: 0.36514338211545894
Validation loss: 2.6012174222320743

Epoch: 6| Step: 1
Training loss: 0.5810925639654059
Validation loss: 2.6116167086761966

Epoch: 6| Step: 2
Training loss: 0.5400289634601879
Validation loss: 2.6357270054453528

Epoch: 6| Step: 3
Training loss: 0.3245154138079756
Validation loss: 2.645065150238306

Epoch: 6| Step: 4
Training loss: 0.3828012892969436
Validation loss: 2.6013833546925134

Epoch: 6| Step: 5
Training loss: 0.34576609409798126
Validation loss: 2.619947648801717

Epoch: 6| Step: 6
Training loss: 0.4072170485155866
Validation loss: 2.6225449228990154

Epoch: 6| Step: 7
Training loss: 0.21334068602008296
Validation loss: 2.6155080035718568

Epoch: 6| Step: 8
Training loss: 0.5256058773141103
Validation loss: 2.567396081097332

Epoch: 6| Step: 9
Training loss: 0.3831043687775958
Validation loss: 2.6069610927192817

Epoch: 6| Step: 10
Training loss: 0.41015050974870826
Validation loss: 2.566975676472371

Epoch: 6| Step: 11
Training loss: 0.34769976268595093
Validation loss: 2.558500913557535

Epoch: 6| Step: 12
Training loss: 0.44927480596667974
Validation loss: 2.5812073449976456

Epoch: 6| Step: 13
Training loss: 0.20252778215916556
Validation loss: 2.568935062728305

Epoch: 376| Step: 0
Training loss: 0.40313714696636804
Validation loss: 2.5902137465447845

Epoch: 6| Step: 1
Training loss: 0.4169271092253023
Validation loss: 2.5625410324281033

Epoch: 6| Step: 2
Training loss: 0.39786252440687075
Validation loss: 2.5645599429210457

Epoch: 6| Step: 3
Training loss: 0.502022259771523
Validation loss: 2.6127355534233128

Epoch: 6| Step: 4
Training loss: 0.3341130572031697
Validation loss: 2.5796000159454175

Epoch: 6| Step: 5
Training loss: 0.27820686571348185
Validation loss: 2.5790180110247367

Epoch: 6| Step: 6
Training loss: 0.5191620109751437
Validation loss: 2.6065522064806292

Epoch: 6| Step: 7
Training loss: 0.36985397037877715
Validation loss: 2.5844508806053614

Epoch: 6| Step: 8
Training loss: 0.3124861952593566
Validation loss: 2.574804510112475

Epoch: 6| Step: 9
Training loss: 0.3393069225688339
Validation loss: 2.5594413114378325

Epoch: 6| Step: 10
Training loss: 0.29945992394145154
Validation loss: 2.5908584063466242

Epoch: 6| Step: 11
Training loss: 0.26075930307055256
Validation loss: 2.59380691689248

Epoch: 6| Step: 12
Training loss: 0.6626113294232184
Validation loss: 2.5468715886885174

Epoch: 6| Step: 13
Training loss: 0.20464587297924297
Validation loss: 2.5659680892370282

Epoch: 377| Step: 0
Training loss: 0.42585732716537045
Validation loss: 2.533443421219493

Epoch: 6| Step: 1
Training loss: 0.5449877189862403
Validation loss: 2.613959415755661

Epoch: 6| Step: 2
Training loss: 0.20359685085977033
Validation loss: 2.619360344891247

Epoch: 6| Step: 3
Training loss: 0.1923454945575796
Validation loss: 2.6414057439116614

Epoch: 6| Step: 4
Training loss: 0.5499041181131608
Validation loss: 2.6331754434099888

Epoch: 6| Step: 5
Training loss: 0.3125620541949832
Validation loss: 2.6462819077110695

Epoch: 6| Step: 6
Training loss: 0.39921814980060527
Validation loss: 2.679401185449908

Epoch: 6| Step: 7
Training loss: 0.21589224466739335
Validation loss: 2.7102341682404854

Epoch: 6| Step: 8
Training loss: 0.44243131460108975
Validation loss: 2.6769748029084024

Epoch: 6| Step: 9
Training loss: 0.38197125234832063
Validation loss: 2.6384949529533412

Epoch: 6| Step: 10
Training loss: 0.2359632639049555
Validation loss: 2.6543964276557817

Epoch: 6| Step: 11
Training loss: 0.4140742858073077
Validation loss: 2.6657319205948173

Epoch: 6| Step: 12
Training loss: 0.39489793261539646
Validation loss: 2.6336328657252506

Epoch: 6| Step: 13
Training loss: 0.18641535638403572
Validation loss: 2.6421944782260525

Epoch: 378| Step: 0
Training loss: 0.18121972077766338
Validation loss: 2.6316951468017424

Epoch: 6| Step: 1
Training loss: 0.18211122278677733
Validation loss: 2.6286783888040643

Epoch: 6| Step: 2
Training loss: 0.4055438323137358
Validation loss: 2.630614400046529

Epoch: 6| Step: 3
Training loss: 0.36162320022319744
Validation loss: 2.6339479110354587

Epoch: 6| Step: 4
Training loss: 0.37298663386923797
Validation loss: 2.6705469662876182

Epoch: 6| Step: 5
Training loss: 0.3702541892904882
Validation loss: 2.640398284097739

Epoch: 6| Step: 6
Training loss: 0.47088856823205544
Validation loss: 2.6656907469144047

Epoch: 6| Step: 7
Training loss: 0.4072465228487886
Validation loss: 2.644878759472285

Epoch: 6| Step: 8
Training loss: 0.34637379650428635
Validation loss: 2.648864184656214

Epoch: 6| Step: 9
Training loss: 0.38692243587208464
Validation loss: 2.620205753868631

Epoch: 6| Step: 10
Training loss: 0.38732385015669707
Validation loss: 2.6191595839887207

Epoch: 6| Step: 11
Training loss: 0.24853734463251004
Validation loss: 2.5974530214782674

Epoch: 6| Step: 12
Training loss: 0.5062319293152495
Validation loss: 2.607422563246204

Epoch: 6| Step: 13
Training loss: 0.24168536984619904
Validation loss: 2.5802356148727457

Epoch: 379| Step: 0
Training loss: 0.2277914947276295
Validation loss: 2.5892088190389657

Epoch: 6| Step: 1
Training loss: 0.44581545484946855
Validation loss: 2.615235468002883

Epoch: 6| Step: 2
Training loss: 0.5024401013178511
Validation loss: 2.6221267495828524

Epoch: 6| Step: 3
Training loss: 0.2436134980145018
Validation loss: 2.6208185526097503

Epoch: 6| Step: 4
Training loss: 0.4448566445885901
Validation loss: 2.578976112003447

Epoch: 6| Step: 5
Training loss: 0.5073949123910143
Validation loss: 2.5862074836430433

Epoch: 6| Step: 6
Training loss: 0.29601347295523
Validation loss: 2.588663149143906

Epoch: 6| Step: 7
Training loss: 0.2556512583184792
Validation loss: 2.616293967532289

Epoch: 6| Step: 8
Training loss: 0.18225784442120863
Validation loss: 2.6126169784473947

Epoch: 6| Step: 9
Training loss: 0.4585168933314638
Validation loss: 2.6359882590098866

Epoch: 6| Step: 10
Training loss: 0.32201313184385416
Validation loss: 2.631577452663635

Epoch: 6| Step: 11
Training loss: 0.22044404613962432
Validation loss: 2.6077739786780207

Epoch: 6| Step: 12
Training loss: 0.31184810354265624
Validation loss: 2.593020829243142

Epoch: 6| Step: 13
Training loss: 0.419541190827018
Validation loss: 2.639100892356043

Epoch: 380| Step: 0
Training loss: 0.3705089378038208
Validation loss: 2.651431975661549

Epoch: 6| Step: 1
Training loss: 0.4723538463849817
Validation loss: 2.6172622030852666

Epoch: 6| Step: 2
Training loss: 0.2544457792182776
Validation loss: 2.609796533351022

Epoch: 6| Step: 3
Training loss: 0.4291438738625129
Validation loss: 2.5801192629029184

Epoch: 6| Step: 4
Training loss: 0.4194934522483793
Validation loss: 2.6160042358149145

Epoch: 6| Step: 5
Training loss: 0.3871023029254948
Validation loss: 2.5955896872139994

Epoch: 6| Step: 6
Training loss: 0.5648487117227561
Validation loss: 2.5971693005819345

Epoch: 6| Step: 7
Training loss: 0.28814802632202835
Validation loss: 2.6069399248274046

Epoch: 6| Step: 8
Training loss: 0.25226080390432193
Validation loss: 2.598404721658174

Epoch: 6| Step: 9
Training loss: 0.2955949063740736
Validation loss: 2.631224797564901

Epoch: 6| Step: 10
Training loss: 0.2270959296509695
Validation loss: 2.6166109652756733

Epoch: 6| Step: 11
Training loss: 0.30904145901049707
Validation loss: 2.6129396448530615

Epoch: 6| Step: 12
Training loss: 0.20226885945138268
Validation loss: 2.6247356318781905

Epoch: 6| Step: 13
Training loss: 0.2106522114378908
Validation loss: 2.6259745748301997

Epoch: 381| Step: 0
Training loss: 0.6211472734145337
Validation loss: 2.5795173889897947

Epoch: 6| Step: 1
Training loss: 0.34527302512057834
Validation loss: 2.615264862257062

Epoch: 6| Step: 2
Training loss: 0.3058666739926577
Validation loss: 2.6074312046534414

Epoch: 6| Step: 3
Training loss: 0.27863275491320005
Validation loss: 2.634490485631712

Epoch: 6| Step: 4
Training loss: 0.36556367767452125
Validation loss: 2.625129161338881

Epoch: 6| Step: 5
Training loss: 0.4408978598097356
Validation loss: 2.669983242157918

Epoch: 6| Step: 6
Training loss: 0.4031757160192
Validation loss: 2.595578123301733

Epoch: 6| Step: 7
Training loss: 0.45211366721608004
Validation loss: 2.650341058772195

Epoch: 6| Step: 8
Training loss: 0.3629468999453071
Validation loss: 2.648946608307513

Epoch: 6| Step: 9
Training loss: 0.2561369402286526
Validation loss: 2.6555913833709517

Epoch: 6| Step: 10
Training loss: 0.25018720770043806
Validation loss: 2.6142371219362923

Epoch: 6| Step: 11
Training loss: 0.32345575152145667
Validation loss: 2.5627677891607243

Epoch: 6| Step: 12
Training loss: 0.2455427571314608
Validation loss: 2.5674207258770405

Epoch: 6| Step: 13
Training loss: 0.5326106094496902
Validation loss: 2.5712277287508902

Epoch: 382| Step: 0
Training loss: 0.28518237686655246
Validation loss: 2.5820964017971066

Epoch: 6| Step: 1
Training loss: 0.4884311293408016
Validation loss: 2.614569364212254

Epoch: 6| Step: 2
Training loss: 0.32830278938728225
Validation loss: 2.625040782566739

Epoch: 6| Step: 3
Training loss: 0.3834931686519063
Validation loss: 2.680801607255257

Epoch: 6| Step: 4
Training loss: 0.2507515429195426
Validation loss: 2.6738883862127567

Epoch: 6| Step: 5
Training loss: 0.32971049043304973
Validation loss: 2.6367120300474713

Epoch: 6| Step: 6
Training loss: 0.48582529017441184
Validation loss: 2.642610700747712

Epoch: 6| Step: 7
Training loss: 0.4618500227620589
Validation loss: 2.6516973676318547

Epoch: 6| Step: 8
Training loss: 0.5800421090296187
Validation loss: 2.6440516111864993

Epoch: 6| Step: 9
Training loss: 0.19407338948803313
Validation loss: 2.6317228882266233

Epoch: 6| Step: 10
Training loss: 0.33835687606899884
Validation loss: 2.6556408549827855

Epoch: 6| Step: 11
Training loss: 0.17484571199279347
Validation loss: 2.5866706645781603

Epoch: 6| Step: 12
Training loss: 0.33837985304222473
Validation loss: 2.560579807530926

Epoch: 6| Step: 13
Training loss: 0.5380550313336632
Validation loss: 2.574625146910118

Epoch: 383| Step: 0
Training loss: 0.35287210472883956
Validation loss: 2.552704172333664

Epoch: 6| Step: 1
Training loss: 0.4778965429139482
Validation loss: 2.5737781481526985

Epoch: 6| Step: 2
Training loss: 0.24909408165686248
Validation loss: 2.580667646339607

Epoch: 6| Step: 3
Training loss: 0.33193003289786577
Validation loss: 2.609709152078084

Epoch: 6| Step: 4
Training loss: 0.5144348859631358
Validation loss: 2.575988112656035

Epoch: 6| Step: 5
Training loss: 0.36991989795837266
Validation loss: 2.609057339264861

Epoch: 6| Step: 6
Training loss: 0.43114759155281135
Validation loss: 2.5713813215919226

Epoch: 6| Step: 7
Training loss: 0.40304267693300333
Validation loss: 2.6077545264759268

Epoch: 6| Step: 8
Training loss: 0.2658102147120497
Validation loss: 2.595045930053403

Epoch: 6| Step: 9
Training loss: 0.36363613063631395
Validation loss: 2.6072281618677318

Epoch: 6| Step: 10
Training loss: 0.20681149137440635
Validation loss: 2.5841987119219523

Epoch: 6| Step: 11
Training loss: 0.30196880630497375
Validation loss: 2.6380303573246167

Epoch: 6| Step: 12
Training loss: 0.40385490253425066
Validation loss: 2.5644314157883388

Epoch: 6| Step: 13
Training loss: 0.37786379690721605
Validation loss: 2.5926127514744772

Epoch: 384| Step: 0
Training loss: 0.4999727301313695
Validation loss: 2.601514893758644

Epoch: 6| Step: 1
Training loss: 0.3713885892810404
Validation loss: 2.5982170388489183

Epoch: 6| Step: 2
Training loss: 0.4015440910661741
Validation loss: 2.5988424633179776

Epoch: 6| Step: 3
Training loss: 0.2361686736106623
Validation loss: 2.5836423364257657

Epoch: 6| Step: 4
Training loss: 0.2646565031392077
Validation loss: 2.5982487095039764

Epoch: 6| Step: 5
Training loss: 0.32555454333917955
Validation loss: 2.589324853159686

Epoch: 6| Step: 6
Training loss: 0.310549406125292
Validation loss: 2.5444830719680955

Epoch: 6| Step: 7
Training loss: 0.20910386208064882
Validation loss: 2.6271052749413735

Epoch: 6| Step: 8
Training loss: 0.22977490967659642
Validation loss: 2.603348099230226

Epoch: 6| Step: 9
Training loss: 0.28403839059374564
Validation loss: 2.6239456231227822

Epoch: 6| Step: 10
Training loss: 0.5096573696434096
Validation loss: 2.6129151468348124

Epoch: 6| Step: 11
Training loss: 0.35937522805248157
Validation loss: 2.608585017763786

Epoch: 6| Step: 12
Training loss: 0.31771066018591787
Validation loss: 2.641780308558072

Epoch: 6| Step: 13
Training loss: 0.5070736718909548
Validation loss: 2.668284737328277

Epoch: 385| Step: 0
Training loss: 0.27631056781844787
Validation loss: 2.5949788449859743

Epoch: 6| Step: 1
Training loss: 0.2988107713634579
Validation loss: 2.582028234629386

Epoch: 6| Step: 2
Training loss: 0.30420446008664276
Validation loss: 2.6031136577052667

Epoch: 6| Step: 3
Training loss: 0.35578640169711884
Validation loss: 2.5543787651992025

Epoch: 6| Step: 4
Training loss: 0.3434707634517757
Validation loss: 2.50711206194649

Epoch: 6| Step: 5
Training loss: 0.16851344062510676
Validation loss: 2.527312781348375

Epoch: 6| Step: 6
Training loss: 0.32982575062513325
Validation loss: 2.5418521516544184

Epoch: 6| Step: 7
Training loss: 0.5149853814003914
Validation loss: 2.5653372233591796

Epoch: 6| Step: 8
Training loss: 0.29593996820357105
Validation loss: 2.543042867574766

Epoch: 6| Step: 9
Training loss: 0.3387554985036503
Validation loss: 2.5612729874306823

Epoch: 6| Step: 10
Training loss: 0.27088920616037526
Validation loss: 2.5855639516635

Epoch: 6| Step: 11
Training loss: 0.36540458915148355
Validation loss: 2.554308793451753

Epoch: 6| Step: 12
Training loss: 0.5725699387021229
Validation loss: 2.5792969586491505

Epoch: 6| Step: 13
Training loss: 0.24696429243364573
Validation loss: 2.6263102505280775

Epoch: 386| Step: 0
Training loss: 0.32020192447437856
Validation loss: 2.616031116620526

Epoch: 6| Step: 1
Training loss: 0.48452093633151544
Validation loss: 2.5956144722142156

Epoch: 6| Step: 2
Training loss: 0.4068453168222795
Validation loss: 2.635857558142528

Epoch: 6| Step: 3
Training loss: 0.3583627002163439
Validation loss: 2.585582178727526

Epoch: 6| Step: 4
Training loss: 0.1488665353464953
Validation loss: 2.586729302146945

Epoch: 6| Step: 5
Training loss: 0.24760766079183436
Validation loss: 2.6062020152485115

Epoch: 6| Step: 6
Training loss: 0.4801104535484186
Validation loss: 2.63426830040779

Epoch: 6| Step: 7
Training loss: 0.1706357626612131
Validation loss: 2.6010141053053832

Epoch: 6| Step: 8
Training loss: 0.38786588899199637
Validation loss: 2.58184569637831

Epoch: 6| Step: 9
Training loss: 0.33920047431397565
Validation loss: 2.5680093393928742

Epoch: 6| Step: 10
Training loss: 0.40696155149040736
Validation loss: 2.585553108368458

Epoch: 6| Step: 11
Training loss: 0.28862670317882916
Validation loss: 2.6037963846766736

Epoch: 6| Step: 12
Training loss: 0.4086294913478324
Validation loss: 2.630225183089185

Epoch: 6| Step: 13
Training loss: 0.29410470082035745
Validation loss: 2.5778259039213727

Epoch: 387| Step: 0
Training loss: 0.31302643779914635
Validation loss: 2.633069531908751

Epoch: 6| Step: 1
Training loss: 0.4310339552366383
Validation loss: 2.5941568711063345

Epoch: 6| Step: 2
Training loss: 0.3228066844176302
Validation loss: 2.5908591346146137

Epoch: 6| Step: 3
Training loss: 0.3334466498209073
Validation loss: 2.6315910851156024

Epoch: 6| Step: 4
Training loss: 0.29666379894833267
Validation loss: 2.599256704823336

Epoch: 6| Step: 5
Training loss: 0.43204976019775954
Validation loss: 2.6282458475800983

Epoch: 6| Step: 6
Training loss: 0.2857975867614342
Validation loss: 2.6210916559288537

Epoch: 6| Step: 7
Training loss: 0.5314558415770079
Validation loss: 2.651475841122677

Epoch: 6| Step: 8
Training loss: 0.2414854857889111
Validation loss: 2.616945669712858

Epoch: 6| Step: 9
Training loss: 0.30952461699648565
Validation loss: 2.651373690946919

Epoch: 6| Step: 10
Training loss: 0.36344581896247524
Validation loss: 2.581351914047929

Epoch: 6| Step: 11
Training loss: 0.41794332979567944
Validation loss: 2.5749231243396062

Epoch: 6| Step: 12
Training loss: 0.3239992731705802
Validation loss: 2.601056752231846

Epoch: 6| Step: 13
Training loss: 0.2664504408891595
Validation loss: 2.610672385849541

Epoch: 388| Step: 0
Training loss: 0.30418318802673655
Validation loss: 2.6100976601654464

Epoch: 6| Step: 1
Training loss: 0.19344017960598237
Validation loss: 2.6064060822212123

Epoch: 6| Step: 2
Training loss: 0.4633598685499131
Validation loss: 2.6227732412053157

Epoch: 6| Step: 3
Training loss: 0.3415582205145699
Validation loss: 2.6117553798282573

Epoch: 6| Step: 4
Training loss: 0.5278736136940149
Validation loss: 2.5812592508005814

Epoch: 6| Step: 5
Training loss: 0.17129259703935695
Validation loss: 2.56161380954142

Epoch: 6| Step: 6
Training loss: 0.44255892719539236
Validation loss: 2.589564580209845

Epoch: 6| Step: 7
Training loss: 0.36495181490677725
Validation loss: 2.58341803363901

Epoch: 6| Step: 8
Training loss: 0.38869560590978336
Validation loss: 2.601868036242245

Epoch: 6| Step: 9
Training loss: 0.2735019880271364
Validation loss: 2.616768103643108

Epoch: 6| Step: 10
Training loss: 0.20634427444712575
Validation loss: 2.6213322636347764

Epoch: 6| Step: 11
Training loss: 0.19695257142173386
Validation loss: 2.628403319364596

Epoch: 6| Step: 12
Training loss: 0.5212449799440003
Validation loss: 2.616231339062104

Epoch: 6| Step: 13
Training loss: 0.39687005437938383
Validation loss: 2.646876932012148

Epoch: 389| Step: 0
Training loss: 0.29182037350818874
Validation loss: 2.6176392847454353

Epoch: 6| Step: 1
Training loss: 0.22394508315227163
Validation loss: 2.5545666159804146

Epoch: 6| Step: 2
Training loss: 0.6081688265479427
Validation loss: 2.523341689708056

Epoch: 6| Step: 3
Training loss: 0.4359002155507328
Validation loss: 2.5672078693974782

Epoch: 6| Step: 4
Training loss: 0.20557128103098596
Validation loss: 2.571477892186681

Epoch: 6| Step: 5
Training loss: 0.291688703941965
Validation loss: 2.590644680531155

Epoch: 6| Step: 6
Training loss: 0.36849762151822696
Validation loss: 2.556222478150433

Epoch: 6| Step: 7
Training loss: 0.20031784773545416
Validation loss: 2.598555378262064

Epoch: 6| Step: 8
Training loss: 0.36600209702740455
Validation loss: 2.5825807273655306

Epoch: 6| Step: 9
Training loss: 0.41341435789358
Validation loss: 2.64591579891717

Epoch: 6| Step: 10
Training loss: 0.4320329290153892
Validation loss: 2.64476194935744

Epoch: 6| Step: 11
Training loss: 0.4542590452730714
Validation loss: 2.638931944243461

Epoch: 6| Step: 12
Training loss: 0.255427950479657
Validation loss: 2.6263644573394678

Epoch: 6| Step: 13
Training loss: 0.34667086522871743
Validation loss: 2.624228568727402

Epoch: 390| Step: 0
Training loss: 0.32938527858483485
Validation loss: 2.63315041903551

Epoch: 6| Step: 1
Training loss: 0.3106519173562807
Validation loss: 2.5792916600028586

Epoch: 6| Step: 2
Training loss: 0.2619500632580708
Validation loss: 2.61279748368185

Epoch: 6| Step: 3
Training loss: 0.5249293120797422
Validation loss: 2.611770607979093

Epoch: 6| Step: 4
Training loss: 0.43884504845550776
Validation loss: 2.61132669951571

Epoch: 6| Step: 5
Training loss: 0.1950061398083652
Validation loss: 2.5936401488230443

Epoch: 6| Step: 6
Training loss: 0.2877553044666251
Validation loss: 2.617592087440452

Epoch: 6| Step: 7
Training loss: 0.35812533832953486
Validation loss: 2.6062452687913797

Epoch: 6| Step: 8
Training loss: 0.44613107100930854
Validation loss: 2.6304178975403145

Epoch: 6| Step: 9
Training loss: 0.3683194305671525
Validation loss: 2.616400914765826

Epoch: 6| Step: 10
Training loss: 0.38041665192458146
Validation loss: 2.5878455440335095

Epoch: 6| Step: 11
Training loss: 0.4185180619556771
Validation loss: 2.631215200548966

Epoch: 6| Step: 12
Training loss: 0.23999985047921849
Validation loss: 2.6098321056588447

Epoch: 6| Step: 13
Training loss: 0.300659105345035
Validation loss: 2.6251289435622116

Epoch: 391| Step: 0
Training loss: 0.39328531365460545
Validation loss: 2.5926919423030594

Epoch: 6| Step: 1
Training loss: 0.2413836258715487
Validation loss: 2.6042921837532074

Epoch: 6| Step: 2
Training loss: 0.242280327019618
Validation loss: 2.632199342812803

Epoch: 6| Step: 3
Training loss: 0.2818770438794724
Validation loss: 2.5659891770053345

Epoch: 6| Step: 4
Training loss: 0.3990515297118935
Validation loss: 2.601491404669958

Epoch: 6| Step: 5
Training loss: 0.32467799236119727
Validation loss: 2.5600229021315037

Epoch: 6| Step: 6
Training loss: 0.2844759520874397
Validation loss: 2.57465410566607

Epoch: 6| Step: 7
Training loss: 0.29635519397380994
Validation loss: 2.5870681133559192

Epoch: 6| Step: 8
Training loss: 0.46515577726945573
Validation loss: 2.5996184950267387

Epoch: 6| Step: 9
Training loss: 0.5142487162572613
Validation loss: 2.603381602095442

Epoch: 6| Step: 10
Training loss: 0.27460587066541536
Validation loss: 2.620172521895822

Epoch: 6| Step: 11
Training loss: 0.3781883084287436
Validation loss: 2.6166864279439803

Epoch: 6| Step: 12
Training loss: 0.20803493448300744
Validation loss: 2.6307492481637986

Epoch: 6| Step: 13
Training loss: 0.1741917268468103
Validation loss: 2.6164478072788913

Epoch: 392| Step: 0
Training loss: 0.31068761503408937
Validation loss: 2.627625751365038

Epoch: 6| Step: 1
Training loss: 0.3406211686575062
Validation loss: 2.62931008333333

Epoch: 6| Step: 2
Training loss: 0.20772678572272474
Validation loss: 2.600299540840493

Epoch: 6| Step: 3
Training loss: 0.3308752243046996
Validation loss: 2.6008335097173227

Epoch: 6| Step: 4
Training loss: 0.42622674157013213
Validation loss: 2.5600484350356294

Epoch: 6| Step: 5
Training loss: 0.5291247211061748
Validation loss: 2.5706945612177794

Epoch: 6| Step: 6
Training loss: 0.4438087773684667
Validation loss: 2.5465713240412913

Epoch: 6| Step: 7
Training loss: 0.47255016744298073
Validation loss: 2.493006963404171

Epoch: 6| Step: 8
Training loss: 0.2943486333082121
Validation loss: 2.544592140192575

Epoch: 6| Step: 9
Training loss: 0.21047771641493643
Validation loss: 2.5192266907356453

Epoch: 6| Step: 10
Training loss: 0.3958862754485579
Validation loss: 2.528446956193744

Epoch: 6| Step: 11
Training loss: 0.19138135553516972
Validation loss: 2.558487873380736

Epoch: 6| Step: 12
Training loss: 0.23864349596090811
Validation loss: 2.574437535908036

Epoch: 6| Step: 13
Training loss: 0.43997468303866466
Validation loss: 2.5765948227156814

Epoch: 393| Step: 0
Training loss: 0.371620045946797
Validation loss: 2.617343555708411

Epoch: 6| Step: 1
Training loss: 0.38339484937468654
Validation loss: 2.6288461708027953

Epoch: 6| Step: 2
Training loss: 0.4311152752227151
Validation loss: 2.563233619440411

Epoch: 6| Step: 3
Training loss: 0.35269765905701717
Validation loss: 2.5617265311815127

Epoch: 6| Step: 4
Training loss: 0.37205679561061883
Validation loss: 2.5297583050114967

Epoch: 6| Step: 5
Training loss: 0.31545163010372407
Validation loss: 2.517189093513957

Epoch: 6| Step: 6
Training loss: 0.32445007712248203
Validation loss: 2.493737940646413

Epoch: 6| Step: 7
Training loss: 0.264543491402495
Validation loss: 2.442642748031586

Epoch: 6| Step: 8
Training loss: 0.48939095092345564
Validation loss: 2.501409304150477

Epoch: 6| Step: 9
Training loss: 0.3562107097977652
Validation loss: 2.4788858639518447

Epoch: 6| Step: 10
Training loss: 0.3246646824805637
Validation loss: 2.552720262925458

Epoch: 6| Step: 11
Training loss: 0.26917111482920897
Validation loss: 2.591865589394956

Epoch: 6| Step: 12
Training loss: 0.47448016005020194
Validation loss: 2.629685982845869

Epoch: 6| Step: 13
Training loss: 0.4205515553941946
Validation loss: 2.659227456837714

Epoch: 394| Step: 0
Training loss: 0.3806174463546713
Validation loss: 2.6441844840616597

Epoch: 6| Step: 1
Training loss: 0.41063698343241756
Validation loss: 2.614770418232847

Epoch: 6| Step: 2
Training loss: 0.4016149642455077
Validation loss: 2.660412557746206

Epoch: 6| Step: 3
Training loss: 0.48674593829638535
Validation loss: 2.6316123864262733

Epoch: 6| Step: 4
Training loss: 0.31669918675500436
Validation loss: 2.5978264954488632

Epoch: 6| Step: 5
Training loss: 0.33455060064589415
Validation loss: 2.5757968507123508

Epoch: 6| Step: 6
Training loss: 0.35087007574642526
Validation loss: 2.579742349925348

Epoch: 6| Step: 7
Training loss: 0.5430168569645957
Validation loss: 2.5867638775209696

Epoch: 6| Step: 8
Training loss: 0.33749454635169834
Validation loss: 2.5764948479431715

Epoch: 6| Step: 9
Training loss: 0.4223866715321515
Validation loss: 2.5675210589724364

Epoch: 6| Step: 10
Training loss: 0.27906707166150113
Validation loss: 2.5908416590948695

Epoch: 6| Step: 11
Training loss: 0.305670339014127
Validation loss: 2.6248855263106132

Epoch: 6| Step: 12
Training loss: 0.4863956818135627
Validation loss: 2.624686084187343

Epoch: 6| Step: 13
Training loss: 0.4529093196182917
Validation loss: 2.5973113797079677

Epoch: 395| Step: 0
Training loss: 0.3833535516458686
Validation loss: 2.5868416746347456

Epoch: 6| Step: 1
Training loss: 0.23844925632716793
Validation loss: 2.581661108537906

Epoch: 6| Step: 2
Training loss: 0.5253947374828157
Validation loss: 2.573244589502702

Epoch: 6| Step: 3
Training loss: 0.36986531164560094
Validation loss: 2.54610219152427

Epoch: 6| Step: 4
Training loss: 0.416590870479939
Validation loss: 2.5764786331933967

Epoch: 6| Step: 5
Training loss: 0.26157436373568627
Validation loss: 2.571110410270487

Epoch: 6| Step: 6
Training loss: 0.3946284372713493
Validation loss: 2.5951647833135776

Epoch: 6| Step: 7
Training loss: 0.14869905316597182
Validation loss: 2.615210172956342

Epoch: 6| Step: 8
Training loss: 0.4531002695635531
Validation loss: 2.6220821975912534

Epoch: 6| Step: 9
Training loss: 0.2412201651842888
Validation loss: 2.6456628430735383

Epoch: 6| Step: 10
Training loss: 0.3121315572253815
Validation loss: 2.636575129952686

Epoch: 6| Step: 11
Training loss: 0.4681375635292149
Validation loss: 2.618069953774053

Epoch: 6| Step: 12
Training loss: 0.3955791267809957
Validation loss: 2.619966357814456

Epoch: 6| Step: 13
Training loss: 0.3898708693373269
Validation loss: 2.6027490379187386

Epoch: 396| Step: 0
Training loss: 0.34264003842295043
Validation loss: 2.571614037364789

Epoch: 6| Step: 1
Training loss: 0.20088886983638343
Validation loss: 2.5855794768507727

Epoch: 6| Step: 2
Training loss: 0.2561909078290866
Validation loss: 2.56804136661518

Epoch: 6| Step: 3
Training loss: 0.3331940653062361
Validation loss: 2.5768197373461454

Epoch: 6| Step: 4
Training loss: 0.28179424662219577
Validation loss: 2.492970321069185

Epoch: 6| Step: 5
Training loss: 0.3069426270338102
Validation loss: 2.5034741596179173

Epoch: 6| Step: 6
Training loss: 0.2983798860190625
Validation loss: 2.5670292522158467

Epoch: 6| Step: 7
Training loss: 0.39245018843423823
Validation loss: 2.591575391961326

Epoch: 6| Step: 8
Training loss: 0.40872285236534295
Validation loss: 2.604882034161287

Epoch: 6| Step: 9
Training loss: 0.5568605758049071
Validation loss: 2.6293869531078395

Epoch: 6| Step: 10
Training loss: 0.33391395183315153
Validation loss: 2.6205073408032264

Epoch: 6| Step: 11
Training loss: 0.3786822177803766
Validation loss: 2.622584207463982

Epoch: 6| Step: 12
Training loss: 0.23752077099671282
Validation loss: 2.6298290910512314

Epoch: 6| Step: 13
Training loss: 0.13421115284203042
Validation loss: 2.5710063922414435

Epoch: 397| Step: 0
Training loss: 0.3440762835313421
Validation loss: 2.616148753889911

Epoch: 6| Step: 1
Training loss: 0.3049999982020894
Validation loss: 2.5603218115177646

Epoch: 6| Step: 2
Training loss: 0.38681969144062234
Validation loss: 2.6180515616950704

Epoch: 6| Step: 3
Training loss: 0.3973844862384922
Validation loss: 2.5728672483342407

Epoch: 6| Step: 4
Training loss: 0.43297894166083606
Validation loss: 2.6122902456012214

Epoch: 6| Step: 5
Training loss: 0.2610420331751957
Validation loss: 2.6008909182017446

Epoch: 6| Step: 6
Training loss: 0.3092996153838957
Validation loss: 2.590807757576357

Epoch: 6| Step: 7
Training loss: 0.46446132155389347
Validation loss: 2.5697562273458283

Epoch: 6| Step: 8
Training loss: 0.38720100850331574
Validation loss: 2.6030979790653017

Epoch: 6| Step: 9
Training loss: 0.3144676726393965
Validation loss: 2.594333352292229

Epoch: 6| Step: 10
Training loss: 0.211474159819804
Validation loss: 2.5616284270564207

Epoch: 6| Step: 11
Training loss: 0.33757393389207696
Validation loss: 2.595827703911469

Epoch: 6| Step: 12
Training loss: 0.2619014785326501
Validation loss: 2.580303018171083

Epoch: 6| Step: 13
Training loss: 0.1441131485489741
Validation loss: 2.5673800585185407

Epoch: 398| Step: 0
Training loss: 0.25754923817316955
Validation loss: 2.5403425989698603

Epoch: 6| Step: 1
Training loss: 0.3807597298972547
Validation loss: 2.589992133074097

Epoch: 6| Step: 2
Training loss: 0.3213302098973381
Validation loss: 2.565309880308679

Epoch: 6| Step: 3
Training loss: 0.40250238050621684
Validation loss: 2.560713787994262

Epoch: 6| Step: 4
Training loss: 0.30218298134487576
Validation loss: 2.5311743379215605

Epoch: 6| Step: 5
Training loss: 0.28352848962486804
Validation loss: 2.5422283024798498

Epoch: 6| Step: 6
Training loss: 0.36074198013902786
Validation loss: 2.4968116312460054

Epoch: 6| Step: 7
Training loss: 0.21859424870497537
Validation loss: 2.540026390809655

Epoch: 6| Step: 8
Training loss: 0.5345468322926945
Validation loss: 2.5224503605813915

Epoch: 6| Step: 9
Training loss: 0.3146563400516955
Validation loss: 2.5450495800243473

Epoch: 6| Step: 10
Training loss: 0.4140379556542873
Validation loss: 2.563128315059028

Epoch: 6| Step: 11
Training loss: 0.21285580866585024
Validation loss: 2.549034628845653

Epoch: 6| Step: 12
Training loss: 0.2526931540408363
Validation loss: 2.569693305673971

Epoch: 6| Step: 13
Training loss: 0.24634930042651804
Validation loss: 2.554944422389324

Epoch: 399| Step: 0
Training loss: 0.35890311897848526
Validation loss: 2.546721672688596

Epoch: 6| Step: 1
Training loss: 0.4307803388439971
Validation loss: 2.540523983956546

Epoch: 6| Step: 2
Training loss: 0.38029841657906244
Validation loss: 2.5836223272109526

Epoch: 6| Step: 3
Training loss: 0.3564611562055641
Validation loss: 2.495072611132511

Epoch: 6| Step: 4
Training loss: 0.38938564148225746
Validation loss: 2.552750177177046

Epoch: 6| Step: 5
Training loss: 0.5061008068698616
Validation loss: 2.5450151785704462

Epoch: 6| Step: 6
Training loss: 0.21704256896073526
Validation loss: 2.548952383946856

Epoch: 6| Step: 7
Training loss: 0.20485557105948154
Validation loss: 2.5826701779470502

Epoch: 6| Step: 8
Training loss: 0.4063354915749862
Validation loss: 2.5344272848931007

Epoch: 6| Step: 9
Training loss: 0.29964892786548064
Validation loss: 2.583799096579498

Epoch: 6| Step: 10
Training loss: 0.1842378720623007
Validation loss: 2.544371171818946

Epoch: 6| Step: 11
Training loss: 0.336443508882559
Validation loss: 2.569686005898106

Epoch: 6| Step: 12
Training loss: 0.22267630971928337
Validation loss: 2.5857137666233405

Epoch: 6| Step: 13
Training loss: 0.4381986897271823
Validation loss: 2.5948114655850834

Epoch: 400| Step: 0
Training loss: 0.25317674155108566
Validation loss: 2.600884369349693

Epoch: 6| Step: 1
Training loss: 0.5174475163184814
Validation loss: 2.58766179830511

Epoch: 6| Step: 2
Training loss: 0.41975241502018257
Validation loss: 2.5734179810765885

Epoch: 6| Step: 3
Training loss: 0.26519662310290054
Validation loss: 2.5927465518828727

Epoch: 6| Step: 4
Training loss: 0.3244076373929848
Validation loss: 2.5914346407951294

Epoch: 6| Step: 5
Training loss: 0.40924024475206294
Validation loss: 2.580244000079842

Epoch: 6| Step: 6
Training loss: 0.29584948446394255
Validation loss: 2.6134523315827334

Epoch: 6| Step: 7
Training loss: 0.35529763431368117
Validation loss: 2.5779233364511924

Epoch: 6| Step: 8
Training loss: 0.3397683465549975
Validation loss: 2.6061460143596413

Epoch: 6| Step: 9
Training loss: 0.3416186930928832
Validation loss: 2.6092386714246127

Epoch: 6| Step: 10
Training loss: 0.450640890261915
Validation loss: 2.5720367687380206

Epoch: 6| Step: 11
Training loss: 0.291768693392904
Validation loss: 2.5528096802582105

Epoch: 6| Step: 12
Training loss: 0.24422931586050606
Validation loss: 2.5632422027887762

Epoch: 6| Step: 13
Training loss: 0.35044542434833126
Validation loss: 2.5754685743082

Epoch: 401| Step: 0
Training loss: 0.4190913659379884
Validation loss: 2.604491122963148

Epoch: 6| Step: 1
Training loss: 0.16816012990431572
Validation loss: 2.53163187237255

Epoch: 6| Step: 2
Training loss: 0.4031303087520725
Validation loss: 2.5528082933985843

Epoch: 6| Step: 3
Training loss: 0.21453858290084887
Validation loss: 2.606948611595215

Epoch: 6| Step: 4
Training loss: 0.44134860379702745
Validation loss: 2.610621149307141

Epoch: 6| Step: 5
Training loss: 0.36883968620385404
Validation loss: 2.616784787834871

Epoch: 6| Step: 6
Training loss: 0.3053522439036258
Validation loss: 2.5904617390137323

Epoch: 6| Step: 7
Training loss: 0.22272145002657245
Validation loss: 2.584420458376022

Epoch: 6| Step: 8
Training loss: 0.39751947520189157
Validation loss: 2.590555925889603

Epoch: 6| Step: 9
Training loss: 0.28765514945462545
Validation loss: 2.6124733640648774

Epoch: 6| Step: 10
Training loss: 0.28612033960022537
Validation loss: 2.6087544787629713

Epoch: 6| Step: 11
Training loss: 0.20298882651643496
Validation loss: 2.61916306411963

Epoch: 6| Step: 12
Training loss: 0.4084119308336949
Validation loss: 2.5543733862606364

Epoch: 6| Step: 13
Training loss: 0.19211736267660165
Validation loss: 2.5975733634387534

Epoch: 402| Step: 0
Training loss: 0.1594160116011559
Validation loss: 2.613867622811392

Epoch: 6| Step: 1
Training loss: 0.3373532073129539
Validation loss: 2.5931988597711184

Epoch: 6| Step: 2
Training loss: 0.14910520157884155
Validation loss: 2.615045791344575

Epoch: 6| Step: 3
Training loss: 0.29302989321680667
Validation loss: 2.628634913376339

Epoch: 6| Step: 4
Training loss: 0.4441281514022426
Validation loss: 2.6067591133152117

Epoch: 6| Step: 5
Training loss: 0.4105813321390709
Validation loss: 2.5968153485714747

Epoch: 6| Step: 6
Training loss: 0.30719109953190754
Validation loss: 2.572018223408417

Epoch: 6| Step: 7
Training loss: 0.2949461137524635
Validation loss: 2.633248772424558

Epoch: 6| Step: 8
Training loss: 0.25987111007784647
Validation loss: 2.6306661578779056

Epoch: 6| Step: 9
Training loss: 0.2643988301424413
Validation loss: 2.6220988347708647

Epoch: 6| Step: 10
Training loss: 0.38371478034068646
Validation loss: 2.6062098904921793

Epoch: 6| Step: 11
Training loss: 0.3219635906337413
Validation loss: 2.6298936036438016

Epoch: 6| Step: 12
Training loss: 0.4061064283058516
Validation loss: 2.605287689275564

Epoch: 6| Step: 13
Training loss: 0.1954983494590149
Validation loss: 2.628901294161811

Epoch: 403| Step: 0
Training loss: 0.35941244013266443
Validation loss: 2.6075302115650523

Epoch: 6| Step: 1
Training loss: 0.2935317161846327
Validation loss: 2.587989393823324

Epoch: 6| Step: 2
Training loss: 0.27842919077179074
Validation loss: 2.572489906128674

Epoch: 6| Step: 3
Training loss: 0.28384710297267796
Validation loss: 2.6023899555809837

Epoch: 6| Step: 4
Training loss: 0.1974705113656726
Validation loss: 2.545227485741291

Epoch: 6| Step: 5
Training loss: 0.3168609554330928
Validation loss: 2.5519203095459484

Epoch: 6| Step: 6
Training loss: 0.2571377304655061
Validation loss: 2.572300035001711

Epoch: 6| Step: 7
Training loss: 0.3707148977164885
Validation loss: 2.6055838652068264

Epoch: 6| Step: 8
Training loss: 0.2328043763452323
Validation loss: 2.564437111025261

Epoch: 6| Step: 9
Training loss: 0.31184436446956104
Validation loss: 2.601456787539471

Epoch: 6| Step: 10
Training loss: 0.2356607614137735
Validation loss: 2.6012468260740653

Epoch: 6| Step: 11
Training loss: 0.23225274864763015
Validation loss: 2.5798545070355665

Epoch: 6| Step: 12
Training loss: 0.4489321582300604
Validation loss: 2.6007254905656088

Epoch: 6| Step: 13
Training loss: 0.6685244161944585
Validation loss: 2.5726399333691496

Epoch: 404| Step: 0
Training loss: 0.19278026325234865
Validation loss: 2.560743546796458

Epoch: 6| Step: 1
Training loss: 0.2662723730653772
Validation loss: 2.6165758789936313

Epoch: 6| Step: 2
Training loss: 0.36885657306020125
Validation loss: 2.593141953259348

Epoch: 6| Step: 3
Training loss: 0.40563823413860617
Validation loss: 2.6184546204570354

Epoch: 6| Step: 4
Training loss: 0.3645033839530482
Validation loss: 2.6283064335627335

Epoch: 6| Step: 5
Training loss: 0.23188870447331394
Validation loss: 2.621979692285302

Epoch: 6| Step: 6
Training loss: 0.2811911309409087
Validation loss: 2.588493221101397

Epoch: 6| Step: 7
Training loss: 0.3442000564022118
Validation loss: 2.5980747766246126

Epoch: 6| Step: 8
Training loss: 0.45514847043922446
Validation loss: 2.589780748171082

Epoch: 6| Step: 9
Training loss: 0.2794250514278619
Validation loss: 2.5974159827225067

Epoch: 6| Step: 10
Training loss: 0.235781534067113
Validation loss: 2.5770717986638734

Epoch: 6| Step: 11
Training loss: 0.3707003465715161
Validation loss: 2.5882440178292954

Epoch: 6| Step: 12
Training loss: 0.34190003064594204
Validation loss: 2.5669133867483556

Epoch: 6| Step: 13
Training loss: 0.2053296499477998
Validation loss: 2.5848536614081112

Epoch: 405| Step: 0
Training loss: 0.4913726752717954
Validation loss: 2.5847232601064376

Epoch: 6| Step: 1
Training loss: 0.36244869197925705
Validation loss: 2.594064455507502

Epoch: 6| Step: 2
Training loss: 0.2529404243929839
Validation loss: 2.5327060309236837

Epoch: 6| Step: 3
Training loss: 0.3235857886233439
Validation loss: 2.5711902793089667

Epoch: 6| Step: 4
Training loss: 0.3105060742524299
Validation loss: 2.5711203727231617

Epoch: 6| Step: 5
Training loss: 0.3034806927348233
Validation loss: 2.5983191525841125

Epoch: 6| Step: 6
Training loss: 0.3431618600860422
Validation loss: 2.612676061039999

Epoch: 6| Step: 7
Training loss: 0.2365169873921329
Validation loss: 2.5752781527891195

Epoch: 6| Step: 8
Training loss: 0.19981044898950784
Validation loss: 2.5712640490038363

Epoch: 6| Step: 9
Training loss: 0.2623971005119285
Validation loss: 2.5809310164528463

Epoch: 6| Step: 10
Training loss: 0.2844238412226727
Validation loss: 2.604309040894758

Epoch: 6| Step: 11
Training loss: 0.24389575885592243
Validation loss: 2.609000868561287

Epoch: 6| Step: 12
Training loss: 0.16284295214653566
Validation loss: 2.5927951301464587

Epoch: 6| Step: 13
Training loss: 0.33491118703899525
Validation loss: 2.604326715945032

Epoch: 406| Step: 0
Training loss: 0.31460957159846614
Validation loss: 2.5705518289760048

Epoch: 6| Step: 1
Training loss: 0.24458429839730697
Validation loss: 2.5723737733696717

Epoch: 6| Step: 2
Training loss: 0.20242981056314754
Validation loss: 2.56802863843271

Epoch: 6| Step: 3
Training loss: 0.2782052722559878
Validation loss: 2.5605601209507816

Epoch: 6| Step: 4
Training loss: 0.27829437134965707
Validation loss: 2.537068242992583

Epoch: 6| Step: 5
Training loss: 0.2124221967867974
Validation loss: 2.5453501513427828

Epoch: 6| Step: 6
Training loss: 0.18191802469615426
Validation loss: 2.5964990915782833

Epoch: 6| Step: 7
Training loss: 0.4455293495494624
Validation loss: 2.5594431354249316

Epoch: 6| Step: 8
Training loss: 0.3619361915966554
Validation loss: 2.5711868872958337

Epoch: 6| Step: 9
Training loss: 0.28430492879262903
Validation loss: 2.5596681915352226

Epoch: 6| Step: 10
Training loss: 0.15475883019333347
Validation loss: 2.5792707053453903

Epoch: 6| Step: 11
Training loss: 0.30890621590505596
Validation loss: 2.5761640492408673

Epoch: 6| Step: 12
Training loss: 0.3595168207050795
Validation loss: 2.5674788669886257

Epoch: 6| Step: 13
Training loss: 0.2853734743659819
Validation loss: 2.529097990939066

Epoch: 407| Step: 0
Training loss: 0.3530404496035575
Validation loss: 2.598589521037312

Epoch: 6| Step: 1
Training loss: 0.23806236719962512
Validation loss: 2.539914561284796

Epoch: 6| Step: 2
Training loss: 0.173795964984317
Validation loss: 2.5703734396804343

Epoch: 6| Step: 3
Training loss: 0.3597629774826665
Validation loss: 2.591837773489259

Epoch: 6| Step: 4
Training loss: 0.428867719826966
Validation loss: 2.599244255745286

Epoch: 6| Step: 5
Training loss: 0.3716572147858197
Validation loss: 2.5480156568806436

Epoch: 6| Step: 6
Training loss: 0.20084139149540683
Validation loss: 2.5756473412932177

Epoch: 6| Step: 7
Training loss: 0.17855644844436983
Validation loss: 2.628820472308534

Epoch: 6| Step: 8
Training loss: 0.22935061856598704
Validation loss: 2.5903221278404183

Epoch: 6| Step: 9
Training loss: 0.3587059551874615
Validation loss: 2.572675780781252

Epoch: 6| Step: 10
Training loss: 0.26560915170401317
Validation loss: 2.611671823659744

Epoch: 6| Step: 11
Training loss: 0.283321408530408
Validation loss: 2.6108612628139647

Epoch: 6| Step: 12
Training loss: 0.27033307873666473
Validation loss: 2.614113243824681

Epoch: 6| Step: 13
Training loss: 0.14308367550098422
Validation loss: 2.5872244375426856

Epoch: 408| Step: 0
Training loss: 0.3231436933758486
Validation loss: 2.5875935791073363

Epoch: 6| Step: 1
Training loss: 0.257121750224583
Validation loss: 2.5794231131115195

Epoch: 6| Step: 2
Training loss: 0.31280166847309643
Validation loss: 2.5586545309352577

Epoch: 6| Step: 3
Training loss: 0.3150030268039301
Validation loss: 2.541666336167138

Epoch: 6| Step: 4
Training loss: 0.339147907698233
Validation loss: 2.569882603758653

Epoch: 6| Step: 5
Training loss: 0.3377123676712506
Validation loss: 2.5379377339037714

Epoch: 6| Step: 6
Training loss: 0.27311882795522485
Validation loss: 2.540357414569313

Epoch: 6| Step: 7
Training loss: 0.29435769489877395
Validation loss: 2.540210481902615

Epoch: 6| Step: 8
Training loss: 0.1710046274788791
Validation loss: 2.5642478228454704

Epoch: 6| Step: 9
Training loss: 0.4601705927791284
Validation loss: 2.5990290228462007

Epoch: 6| Step: 10
Training loss: 0.37825865314466733
Validation loss: 2.598231990153678

Epoch: 6| Step: 11
Training loss: 0.21091432797348508
Validation loss: 2.5980991935467137

Epoch: 6| Step: 12
Training loss: 0.21242365236931227
Validation loss: 2.5840542505511253

Epoch: 6| Step: 13
Training loss: 0.4790076703809321
Validation loss: 2.6118958879037475

Epoch: 409| Step: 0
Training loss: 0.3239158686356609
Validation loss: 2.599554941147345

Epoch: 6| Step: 1
Training loss: 0.2942456710095102
Validation loss: 2.5967553749566896

Epoch: 6| Step: 2
Training loss: 0.31035947843602824
Validation loss: 2.556362629361398

Epoch: 6| Step: 3
Training loss: 0.14528931463533232
Validation loss: 2.5675062393611277

Epoch: 6| Step: 4
Training loss: 0.22573841606035377
Validation loss: 2.617308636945791

Epoch: 6| Step: 5
Training loss: 0.24347877818457664
Validation loss: 2.596841024188367

Epoch: 6| Step: 6
Training loss: 0.22285136658294652
Validation loss: 2.6123757662690203

Epoch: 6| Step: 7
Training loss: 0.3047974828142131
Validation loss: 2.5958144586741025

Epoch: 6| Step: 8
Training loss: 0.27155034203743994
Validation loss: 2.6206328790389506

Epoch: 6| Step: 9
Training loss: 0.23630514111949683
Validation loss: 2.5506992895710923

Epoch: 6| Step: 10
Training loss: 0.4395493126611388
Validation loss: 2.5640457352439388

Epoch: 6| Step: 11
Training loss: 0.43224668460278287
Validation loss: 2.5798273585934783

Epoch: 6| Step: 12
Training loss: 0.2366390232499207
Validation loss: 2.5548108859378944

Epoch: 6| Step: 13
Training loss: 0.1611225702903095
Validation loss: 2.573088217536974

Epoch: 410| Step: 0
Training loss: 0.3333093279400251
Validation loss: 2.580870627159967

Epoch: 6| Step: 1
Training loss: 0.368414876888794
Validation loss: 2.584854118624799

Epoch: 6| Step: 2
Training loss: 0.29299941856079215
Validation loss: 2.6052509001609745

Epoch: 6| Step: 3
Training loss: 0.41397057718498764
Validation loss: 2.5797420831012032

Epoch: 6| Step: 4
Training loss: 0.4796881343327904
Validation loss: 2.5655834305994216

Epoch: 6| Step: 5
Training loss: 0.2492383964113224
Validation loss: 2.589622670632046

Epoch: 6| Step: 6
Training loss: 0.24982769064615287
Validation loss: 2.574324292337829

Epoch: 6| Step: 7
Training loss: 0.25251357266328694
Validation loss: 2.573767050014514

Epoch: 6| Step: 8
Training loss: 0.19906471880001095
Validation loss: 2.5737699321285055

Epoch: 6| Step: 9
Training loss: 0.31334296020639585
Validation loss: 2.534205348260933

Epoch: 6| Step: 10
Training loss: 0.22014764069075538
Validation loss: 2.5403995559549055

Epoch: 6| Step: 11
Training loss: 0.2939401036811706
Validation loss: 2.5978272040003114

Epoch: 6| Step: 12
Training loss: 0.26356081566330075
Validation loss: 2.572784612411354

Epoch: 6| Step: 13
Training loss: 0.14356333518418476
Validation loss: 2.5997175943618513

Epoch: 411| Step: 0
Training loss: 0.23594677319524035
Validation loss: 2.617095484284587

Epoch: 6| Step: 1
Training loss: 0.35756326182377113
Validation loss: 2.588589164209148

Epoch: 6| Step: 2
Training loss: 0.30629438545730453
Validation loss: 2.598570869980397

Epoch: 6| Step: 3
Training loss: 0.45226096942434174
Validation loss: 2.578097224777324

Epoch: 6| Step: 4
Training loss: 0.3237519753333258
Validation loss: 2.5867448887236963

Epoch: 6| Step: 5
Training loss: 0.2003515052906891
Validation loss: 2.5130103588231316

Epoch: 6| Step: 6
Training loss: 0.1958247048847795
Validation loss: 2.5414004856393766

Epoch: 6| Step: 7
Training loss: 0.15480769381418333
Validation loss: 2.511685822654963

Epoch: 6| Step: 8
Training loss: 0.370312742241245
Validation loss: 2.490870772357844

Epoch: 6| Step: 9
Training loss: 0.2416228125439146
Validation loss: 2.520223768776473

Epoch: 6| Step: 10
Training loss: 0.35555310348858965
Validation loss: 2.5138010719649215

Epoch: 6| Step: 11
Training loss: 0.2621493711243194
Validation loss: 2.5215125816726442

Epoch: 6| Step: 12
Training loss: 0.36357547781308985
Validation loss: 2.592830189451735

Epoch: 6| Step: 13
Training loss: 0.17598304821260397
Validation loss: 2.56976558001787

Epoch: 412| Step: 0
Training loss: 0.28737887235789394
Validation loss: 2.5912517421871626

Epoch: 6| Step: 1
Training loss: 0.2808791072742084
Validation loss: 2.580920412076743

Epoch: 6| Step: 2
Training loss: 0.2878788349113167
Validation loss: 2.5702948997441797

Epoch: 6| Step: 3
Training loss: 0.24594189484824713
Validation loss: 2.6341934474942548

Epoch: 6| Step: 4
Training loss: 0.25706815193820653
Validation loss: 2.617190529716402

Epoch: 6| Step: 5
Training loss: 0.3327987775525695
Validation loss: 2.611950815908798

Epoch: 6| Step: 6
Training loss: 0.41276138939326695
Validation loss: 2.5563719673543357

Epoch: 6| Step: 7
Training loss: 0.30982164355051084
Validation loss: 2.5895543951822435

Epoch: 6| Step: 8
Training loss: 0.15291080942963348
Validation loss: 2.6126715169519334

Epoch: 6| Step: 9
Training loss: 0.4045220821280332
Validation loss: 2.605697534957952

Epoch: 6| Step: 10
Training loss: 0.2391288098142941
Validation loss: 2.6158319676868533

Epoch: 6| Step: 11
Training loss: 0.35091811570721637
Validation loss: 2.636560073264886

Epoch: 6| Step: 12
Training loss: 0.3494205177866545
Validation loss: 2.566885666486257

Epoch: 6| Step: 13
Training loss: 0.427542813399213
Validation loss: 2.5729318031867834

Epoch: 413| Step: 0
Training loss: 0.2561531273396847
Validation loss: 2.5471288933332064

Epoch: 6| Step: 1
Training loss: 0.2437759727921029
Validation loss: 2.5550025759945796

Epoch: 6| Step: 2
Training loss: 0.23710129895353207
Validation loss: 2.5381049368172235

Epoch: 6| Step: 3
Training loss: 0.31591088170588116
Validation loss: 2.5396115975029128

Epoch: 6| Step: 4
Training loss: 0.3629761511926231
Validation loss: 2.5398428919954656

Epoch: 6| Step: 5
Training loss: 0.39985721692165527
Validation loss: 2.550947613089982

Epoch: 6| Step: 6
Training loss: 0.12603669616524604
Validation loss: 2.5553947062682147

Epoch: 6| Step: 7
Training loss: 0.32767436327186633
Validation loss: 2.5524893669771584

Epoch: 6| Step: 8
Training loss: 0.2995701471980643
Validation loss: 2.5518030969998597

Epoch: 6| Step: 9
Training loss: 0.28695022947126414
Validation loss: 2.565111995518711

Epoch: 6| Step: 10
Training loss: 0.12615637551169853
Validation loss: 2.556145850274594

Epoch: 6| Step: 11
Training loss: 0.3415297199863868
Validation loss: 2.5838379636645676

Epoch: 6| Step: 12
Training loss: 0.2624118793261245
Validation loss: 2.60964722220729

Epoch: 6| Step: 13
Training loss: 0.2944104009954572
Validation loss: 2.6120372913750556

Epoch: 414| Step: 0
Training loss: 0.23082656078496783
Validation loss: 2.602002857329675

Epoch: 6| Step: 1
Training loss: 0.20028221291203294
Validation loss: 2.644381775029701

Epoch: 6| Step: 2
Training loss: 0.2113812159555414
Validation loss: 2.6318984362124263

Epoch: 6| Step: 3
Training loss: 0.31930998017158146
Validation loss: 2.62858059392581

Epoch: 6| Step: 4
Training loss: 0.25480469423697866
Validation loss: 2.598230296012268

Epoch: 6| Step: 5
Training loss: 0.2495039548617791
Validation loss: 2.6219373436354494

Epoch: 6| Step: 6
Training loss: 0.3529518331600074
Validation loss: 2.6239776905932493

Epoch: 6| Step: 7
Training loss: 0.26896109607399443
Validation loss: 2.602665141389622

Epoch: 6| Step: 8
Training loss: 0.24214401162304736
Validation loss: 2.5644130473884488

Epoch: 6| Step: 9
Training loss: 0.36550827771583555
Validation loss: 2.5181946411949103

Epoch: 6| Step: 10
Training loss: 0.39293661877299874
Validation loss: 2.578063562381454

Epoch: 6| Step: 11
Training loss: 0.23684665447426723
Validation loss: 2.5915199757066008

Epoch: 6| Step: 12
Training loss: 0.24233982464226372
Validation loss: 2.5684110368885222

Epoch: 6| Step: 13
Training loss: 0.37160480845515464
Validation loss: 2.5703748499762336

Epoch: 415| Step: 0
Training loss: 0.14309312616484285
Validation loss: 2.5926073623719295

Epoch: 6| Step: 1
Training loss: 0.15253740619927567
Validation loss: 2.559001923051921

Epoch: 6| Step: 2
Training loss: 0.2224753632192822
Validation loss: 2.60471797685893

Epoch: 6| Step: 3
Training loss: 0.13848683274765403
Validation loss: 2.586124192473565

Epoch: 6| Step: 4
Training loss: 0.2537289073474086
Validation loss: 2.6147264134948367

Epoch: 6| Step: 5
Training loss: 0.25985571367497595
Validation loss: 2.5863372758413283

Epoch: 6| Step: 6
Training loss: 0.2262341734714481
Validation loss: 2.5897736000468288

Epoch: 6| Step: 7
Training loss: 0.1468031466526381
Validation loss: 2.603184029211572

Epoch: 6| Step: 8
Training loss: 0.4666772313994092
Validation loss: 2.577554938173054

Epoch: 6| Step: 9
Training loss: 0.29147761751928897
Validation loss: 2.6125437081714766

Epoch: 6| Step: 10
Training loss: 0.456167676762285
Validation loss: 2.602646024324044

Epoch: 6| Step: 11
Training loss: 0.3758778628312275
Validation loss: 2.6448225015873343

Epoch: 6| Step: 12
Training loss: 0.25829854578446204
Validation loss: 2.6159856645742248

Epoch: 6| Step: 13
Training loss: 0.20534712088753726
Validation loss: 2.5842849323126122

Epoch: 416| Step: 0
Training loss: 0.3486013104393907
Validation loss: 2.6002335456919172

Epoch: 6| Step: 1
Training loss: 0.1986121310379795
Validation loss: 2.601003832051171

Epoch: 6| Step: 2
Training loss: 0.2667448615872565
Validation loss: 2.5680765809246413

Epoch: 6| Step: 3
Training loss: 0.3089216156506425
Validation loss: 2.5735522594421796

Epoch: 6| Step: 4
Training loss: 0.41983996634842286
Validation loss: 2.5655941434585485

Epoch: 6| Step: 5
Training loss: 0.25000536436047704
Validation loss: 2.5711443152560713

Epoch: 6| Step: 6
Training loss: 0.19975435027468832
Validation loss: 2.571805415998131

Epoch: 6| Step: 7
Training loss: 0.3913988459147581
Validation loss: 2.5800202295588655

Epoch: 6| Step: 8
Training loss: 0.3380858017487587
Validation loss: 2.567788602048635

Epoch: 6| Step: 9
Training loss: 0.3350497870314923
Validation loss: 2.597756592641923

Epoch: 6| Step: 10
Training loss: 0.12102506597052598
Validation loss: 2.6186171227945336

Epoch: 6| Step: 11
Training loss: 0.2018838800626678
Validation loss: 2.6083984964704525

Epoch: 6| Step: 12
Training loss: 0.2620663114325604
Validation loss: 2.619504159112537

Epoch: 6| Step: 13
Training loss: 0.16888453101334513
Validation loss: 2.646594066970412

Epoch: 417| Step: 0
Training loss: 0.25901547010810283
Validation loss: 2.6241472893590796

Epoch: 6| Step: 1
Training loss: 0.32038057580799806
Validation loss: 2.6114199178740707

Epoch: 6| Step: 2
Training loss: 0.3275088701794136
Validation loss: 2.6231040563219348

Epoch: 6| Step: 3
Training loss: 0.24262405857471517
Validation loss: 2.571790216361455

Epoch: 6| Step: 4
Training loss: 0.19480243838373265
Validation loss: 2.555425677700491

Epoch: 6| Step: 5
Training loss: 0.2180237208544407
Validation loss: 2.533833704168333

Epoch: 6| Step: 6
Training loss: 0.38136189882299265
Validation loss: 2.552533329828868

Epoch: 6| Step: 7
Training loss: 0.2518669690823073
Validation loss: 2.5275208249715106

Epoch: 6| Step: 8
Training loss: 0.2997699555896225
Validation loss: 2.5633225670191075

Epoch: 6| Step: 9
Training loss: 0.3107927177005017
Validation loss: 2.6254797661617495

Epoch: 6| Step: 10
Training loss: 0.17984995547077454
Validation loss: 2.6224890798852063

Epoch: 6| Step: 11
Training loss: 0.3704495309247252
Validation loss: 2.5948558920272857

Epoch: 6| Step: 12
Training loss: 0.20596566469303568
Validation loss: 2.6429944757647137

Epoch: 6| Step: 13
Training loss: 0.5241840504562022
Validation loss: 2.577327934448149

Epoch: 418| Step: 0
Training loss: 0.35882459868416156
Validation loss: 2.6541409964844678

Epoch: 6| Step: 1
Training loss: 0.29985262211112246
Validation loss: 2.602913582506352

Epoch: 6| Step: 2
Training loss: 0.28959367251063256
Validation loss: 2.630935215342011

Epoch: 6| Step: 3
Training loss: 0.15073270411537568
Validation loss: 2.641036576599837

Epoch: 6| Step: 4
Training loss: 0.35931198977508655
Validation loss: 2.5981731286990324

Epoch: 6| Step: 5
Training loss: 0.2818055097474843
Validation loss: 2.5978902721997525

Epoch: 6| Step: 6
Training loss: 0.2667988476882769
Validation loss: 2.619008039892713

Epoch: 6| Step: 7
Training loss: 0.1918712145590378
Validation loss: 2.6082917164875314

Epoch: 6| Step: 8
Training loss: 0.31511286127164395
Validation loss: 2.6148698276630844

Epoch: 6| Step: 9
Training loss: 0.2688967104720881
Validation loss: 2.5863325239071506

Epoch: 6| Step: 10
Training loss: 0.32029990427326627
Validation loss: 2.587067464287262

Epoch: 6| Step: 11
Training loss: 0.2030517923039284
Validation loss: 2.5863603422738644

Epoch: 6| Step: 12
Training loss: 0.1720067624568877
Validation loss: 2.6027074066665117

Epoch: 6| Step: 13
Training loss: 0.4389755536259112
Validation loss: 2.6189522668268874

Epoch: 419| Step: 0
Training loss: 0.19785546414744956
Validation loss: 2.619685620519323

Epoch: 6| Step: 1
Training loss: 0.35990120883281806
Validation loss: 2.5758279620007456

Epoch: 6| Step: 2
Training loss: 0.4187942801734829
Validation loss: 2.596226077294252

Epoch: 6| Step: 3
Training loss: 0.37285135547917947
Validation loss: 2.5890763210686925

Epoch: 6| Step: 4
Training loss: 0.12390071323767156
Validation loss: 2.6000583075184642

Epoch: 6| Step: 5
Training loss: 0.1981778345749627
Validation loss: 2.6065639184133604

Epoch: 6| Step: 6
Training loss: 0.25259262071682936
Validation loss: 2.5564255808034755

Epoch: 6| Step: 7
Training loss: 0.28902842346584484
Validation loss: 2.539462618794749

Epoch: 6| Step: 8
Training loss: 0.2656314933207589
Validation loss: 2.5234272817363346

Epoch: 6| Step: 9
Training loss: 0.37166934297151166
Validation loss: 2.5820568621399937

Epoch: 6| Step: 10
Training loss: 0.26540351497238496
Validation loss: 2.5217583099240906

Epoch: 6| Step: 11
Training loss: 0.15192659435731884
Validation loss: 2.543691645135299

Epoch: 6| Step: 12
Training loss: 0.24826799884290024
Validation loss: 2.579979080140183

Epoch: 6| Step: 13
Training loss: 0.4785554518960937
Validation loss: 2.5675476695555424

Epoch: 420| Step: 0
Training loss: 0.2931294445563056
Validation loss: 2.601894952739029

Epoch: 6| Step: 1
Training loss: 0.29706983697917133
Validation loss: 2.6009451121781013

Epoch: 6| Step: 2
Training loss: 0.24199595875607052
Validation loss: 2.588464773719731

Epoch: 6| Step: 3
Training loss: 0.40924643470595357
Validation loss: 2.631855414323803

Epoch: 6| Step: 4
Training loss: 0.14760062567699736
Validation loss: 2.6215690970461076

Epoch: 6| Step: 5
Training loss: 0.19908328218833338
Validation loss: 2.6511492267468393

Epoch: 6| Step: 6
Training loss: 0.27684093618852246
Validation loss: 2.6372886921043075

Epoch: 6| Step: 7
Training loss: 0.34051298697039695
Validation loss: 2.626072197318114

Epoch: 6| Step: 8
Training loss: 0.16529624132488716
Validation loss: 2.6053731116423355

Epoch: 6| Step: 9
Training loss: 0.22143239247221352
Validation loss: 2.6292237513342274

Epoch: 6| Step: 10
Training loss: 0.3523666932614436
Validation loss: 2.6193365930187187

Epoch: 6| Step: 11
Training loss: 0.35903995901324937
Validation loss: 2.5982068897125354

Epoch: 6| Step: 12
Training loss: 0.3367561744373104
Validation loss: 2.573663835634932

Epoch: 6| Step: 13
Training loss: 0.31417966289394483
Validation loss: 2.572139123474584

Epoch: 421| Step: 0
Training loss: 0.26608865606480037
Validation loss: 2.5580077012956597

Epoch: 6| Step: 1
Training loss: 0.2804148513306292
Validation loss: 2.5486362753294305

Epoch: 6| Step: 2
Training loss: 0.3316999577802287
Validation loss: 2.565914872998149

Epoch: 6| Step: 3
Training loss: 0.19953493197037867
Validation loss: 2.5679163361927935

Epoch: 6| Step: 4
Training loss: 0.28496549052313197
Validation loss: 2.5913136170315734

Epoch: 6| Step: 5
Training loss: 0.2875324298356407
Validation loss: 2.5525008629563444

Epoch: 6| Step: 6
Training loss: 0.5527818747016654
Validation loss: 2.588253480993389

Epoch: 6| Step: 7
Training loss: 0.309590588696836
Validation loss: 2.5981867620205903

Epoch: 6| Step: 8
Training loss: 0.2675946641251742
Validation loss: 2.559771610199801

Epoch: 6| Step: 9
Training loss: 0.2288565578489147
Validation loss: 2.553715903730792

Epoch: 6| Step: 10
Training loss: 0.21920013095802202
Validation loss: 2.5497891435623696

Epoch: 6| Step: 11
Training loss: 0.255445917958251
Validation loss: 2.530242259511685

Epoch: 6| Step: 12
Training loss: 0.3434037610594829
Validation loss: 2.528502595405517

Epoch: 6| Step: 13
Training loss: 0.1856555720722873
Validation loss: 2.560136936517229

Epoch: 422| Step: 0
Training loss: 0.23195800652768458
Validation loss: 2.5445244412787282

Epoch: 6| Step: 1
Training loss: 0.22881330354200916
Validation loss: 2.540591741034742

Epoch: 6| Step: 2
Training loss: 0.24672136052920632
Validation loss: 2.5730140358396514

Epoch: 6| Step: 3
Training loss: 0.3520788427589457
Validation loss: 2.564677480078461

Epoch: 6| Step: 4
Training loss: 0.22779578759857336
Validation loss: 2.588442772665022

Epoch: 6| Step: 5
Training loss: 0.1599353103696507
Validation loss: 2.5851541612888695

Epoch: 6| Step: 6
Training loss: 0.3335617581645685
Validation loss: 2.6131350860537226

Epoch: 6| Step: 7
Training loss: 0.40330015783313944
Validation loss: 2.590099305218356

Epoch: 6| Step: 8
Training loss: 0.3493724531684815
Validation loss: 2.609569887867595

Epoch: 6| Step: 9
Training loss: 0.20724264184983443
Validation loss: 2.580048250375334

Epoch: 6| Step: 10
Training loss: 0.3472676409050322
Validation loss: 2.5546853816009296

Epoch: 6| Step: 11
Training loss: 0.2786364449794107
Validation loss: 2.562917431742342

Epoch: 6| Step: 12
Training loss: 0.24259926800568274
Validation loss: 2.572474928285998

Epoch: 6| Step: 13
Training loss: 0.2658550023995293
Validation loss: 2.563489675305684

Epoch: 423| Step: 0
Training loss: 0.2278641273857278
Validation loss: 2.538591697087732

Epoch: 6| Step: 1
Training loss: 0.22588426094618566
Validation loss: 2.5548991153012452

Epoch: 6| Step: 2
Training loss: 0.1730988022025112
Validation loss: 2.587660009564877

Epoch: 6| Step: 3
Training loss: 0.15148426573318075
Validation loss: 2.5764810829246554

Epoch: 6| Step: 4
Training loss: 0.40942239050251666
Validation loss: 2.6415207728108476

Epoch: 6| Step: 5
Training loss: 0.22241370057124105
Validation loss: 2.5857921282266525

Epoch: 6| Step: 6
Training loss: 0.2923069663789264
Validation loss: 2.5646765744445776

Epoch: 6| Step: 7
Training loss: 0.26291501242444176
Validation loss: 2.60755251267267

Epoch: 6| Step: 8
Training loss: 0.3693802272923763
Validation loss: 2.6073387394214675

Epoch: 6| Step: 9
Training loss: 0.31602931234662923
Validation loss: 2.5880645796265918

Epoch: 6| Step: 10
Training loss: 0.23255007277698564
Validation loss: 2.5931748208223144

Epoch: 6| Step: 11
Training loss: 0.23331044345933416
Validation loss: 2.578581193951339

Epoch: 6| Step: 12
Training loss: 0.31515722642481575
Validation loss: 2.6320345427175793

Epoch: 6| Step: 13
Training loss: 0.20812143437306796
Validation loss: 2.614263033901985

Epoch: 424| Step: 0
Training loss: 0.5255512431646362
Validation loss: 2.6109450638820197

Epoch: 6| Step: 1
Training loss: 0.17324989564040646
Validation loss: 2.5622070909433803

Epoch: 6| Step: 2
Training loss: 0.19787172175262474
Validation loss: 2.5647248754716494

Epoch: 6| Step: 3
Training loss: 0.35159947942585645
Validation loss: 2.5778455794760764

Epoch: 6| Step: 4
Training loss: 0.09658122587880687
Validation loss: 2.5655990836893063

Epoch: 6| Step: 5
Training loss: 0.2214633289140352
Validation loss: 2.565100608029085

Epoch: 6| Step: 6
Training loss: 0.12965829704288737
Validation loss: 2.593725784293486

Epoch: 6| Step: 7
Training loss: 0.29465822725748214
Validation loss: 2.5977432106889506

Epoch: 6| Step: 8
Training loss: 0.19818656592087305
Validation loss: 2.5811081895183445

Epoch: 6| Step: 9
Training loss: 0.21145078233726136
Validation loss: 2.5895744325623467

Epoch: 6| Step: 10
Training loss: 0.22971864443753084
Validation loss: 2.571822798578495

Epoch: 6| Step: 11
Training loss: 0.2714243898056169
Validation loss: 2.607342892625367

Epoch: 6| Step: 12
Training loss: 0.3136945186627082
Validation loss: 2.562728881618575

Epoch: 6| Step: 13
Training loss: 0.13188625364512796
Validation loss: 2.573965777336521

Epoch: 425| Step: 0
Training loss: 0.20932981871873382
Validation loss: 2.6026957591343036

Epoch: 6| Step: 1
Training loss: 0.22595965817593178
Validation loss: 2.576741616756321

Epoch: 6| Step: 2
Training loss: 0.17333659854053984
Validation loss: 2.5867265311020384

Epoch: 6| Step: 3
Training loss: 0.3269278166716472
Validation loss: 2.5728348427579864

Epoch: 6| Step: 4
Training loss: 0.3114628389068779
Validation loss: 2.545600518379451

Epoch: 6| Step: 5
Training loss: 0.22423118596696337
Validation loss: 2.5720619361890202

Epoch: 6| Step: 6
Training loss: 0.4199886002866812
Validation loss: 2.512484640312151

Epoch: 6| Step: 7
Training loss: 0.21481626508208446
Validation loss: 2.589694472923267

Epoch: 6| Step: 8
Training loss: 0.29494764202809515
Validation loss: 2.5816642216531482

Epoch: 6| Step: 9
Training loss: 0.22556234624460528
Validation loss: 2.545194893946082

Epoch: 6| Step: 10
Training loss: 0.25429528583082794
Validation loss: 2.563284000944167

Epoch: 6| Step: 11
Training loss: 0.2768504497200963
Validation loss: 2.5941329245418574

Epoch: 6| Step: 12
Training loss: 0.2909713429804658
Validation loss: 2.5831083778009356

Epoch: 6| Step: 13
Training loss: 0.18426584431277687
Validation loss: 2.6222129388386715

Epoch: 426| Step: 0
Training loss: 0.18647857446043423
Validation loss: 2.565640291877843

Epoch: 6| Step: 1
Training loss: 0.1861360731769933
Validation loss: 2.5515054483364468

Epoch: 6| Step: 2
Training loss: 0.31586236479139373
Validation loss: 2.590877297710371

Epoch: 6| Step: 3
Training loss: 0.2423024443147896
Validation loss: 2.5179078776617003

Epoch: 6| Step: 4
Training loss: 0.2889575896749757
Validation loss: 2.5330305502515036

Epoch: 6| Step: 5
Training loss: 0.19021500443803216
Validation loss: 2.589764065224149

Epoch: 6| Step: 6
Training loss: 0.21235298372448977
Validation loss: 2.5354717687852997

Epoch: 6| Step: 7
Training loss: 0.30783792477863164
Validation loss: 2.586362431012027

Epoch: 6| Step: 8
Training loss: 0.23107764258228913
Validation loss: 2.5976667447294117

Epoch: 6| Step: 9
Training loss: 0.3532708094866567
Validation loss: 2.604872634851168

Epoch: 6| Step: 10
Training loss: 0.3202293916208894
Validation loss: 2.608374381375506

Epoch: 6| Step: 11
Training loss: 0.27117424684991254
Validation loss: 2.614985001557738

Epoch: 6| Step: 12
Training loss: 0.30331672523868003
Validation loss: 2.6118581764664777

Epoch: 6| Step: 13
Training loss: 0.48945816110515
Validation loss: 2.595263502499279

Epoch: 427| Step: 0
Training loss: 0.32782944356370347
Validation loss: 2.6105721380051508

Epoch: 6| Step: 1
Training loss: 0.3093870806021177
Validation loss: 2.5782471559185054

Epoch: 6| Step: 2
Training loss: 0.2479183735241088
Validation loss: 2.5616343001595077

Epoch: 6| Step: 3
Training loss: 0.3643082693708041
Validation loss: 2.5417269290744384

Epoch: 6| Step: 4
Training loss: 0.3436988012159195
Validation loss: 2.5501847253927763

Epoch: 6| Step: 5
Training loss: 0.3223438052511607
Validation loss: 2.5533267561718773

Epoch: 6| Step: 6
Training loss: 0.33151320266252177
Validation loss: 2.552858775206103

Epoch: 6| Step: 7
Training loss: 0.19479635703887827
Validation loss: 2.5928124192215827

Epoch: 6| Step: 8
Training loss: 0.23584947902038822
Validation loss: 2.5859471094056836

Epoch: 6| Step: 9
Training loss: 0.19064688400600435
Validation loss: 2.5784568903626455

Epoch: 6| Step: 10
Training loss: 0.18622243270778988
Validation loss: 2.5258782257259758

Epoch: 6| Step: 11
Training loss: 0.3092586741761286
Validation loss: 2.5356878484270196

Epoch: 6| Step: 12
Training loss: 0.2846647363809637
Validation loss: 2.595929381313141

Epoch: 6| Step: 13
Training loss: 0.3578552786895737
Validation loss: 2.5662428570587883

Epoch: 428| Step: 0
Training loss: 0.3617504229592551
Validation loss: 2.614885554348725

Epoch: 6| Step: 1
Training loss: 0.2241149934757093
Validation loss: 2.622576716682107

Epoch: 6| Step: 2
Training loss: 0.29514892629621664
Validation loss: 2.5634608084433346

Epoch: 6| Step: 3
Training loss: 0.37755220866910555
Validation loss: 2.628405539284035

Epoch: 6| Step: 4
Training loss: 0.3348129434872813
Validation loss: 2.609840318664417

Epoch: 6| Step: 5
Training loss: 0.29851076315320274
Validation loss: 2.6206743800939143

Epoch: 6| Step: 6
Training loss: 0.35578533369626514
Validation loss: 2.601256210397711

Epoch: 6| Step: 7
Training loss: 0.2633367598789545
Validation loss: 2.6357414794145724

Epoch: 6| Step: 8
Training loss: 0.15824494574409292
Validation loss: 2.569768282559644

Epoch: 6| Step: 9
Training loss: 0.23382517377199868
Validation loss: 2.565588034106628

Epoch: 6| Step: 10
Training loss: 0.3924700080443797
Validation loss: 2.6366575012020763

Epoch: 6| Step: 11
Training loss: 0.1757086762975687
Validation loss: 2.5890913578342456

Epoch: 6| Step: 12
Training loss: 0.2551749298396836
Validation loss: 2.572284126687049

Epoch: 6| Step: 13
Training loss: 0.23585807145407015
Validation loss: 2.5975021421450566

Epoch: 429| Step: 0
Training loss: 0.28719930473033617
Validation loss: 2.564812070111606

Epoch: 6| Step: 1
Training loss: 0.11911189014176808
Validation loss: 2.5574819341451764

Epoch: 6| Step: 2
Training loss: 0.30878586161219385
Validation loss: 2.5221722256717722

Epoch: 6| Step: 3
Training loss: 0.30755476545326627
Validation loss: 2.5449423343046753

Epoch: 6| Step: 4
Training loss: 0.21457193693125645
Validation loss: 2.5315102403299585

Epoch: 6| Step: 5
Training loss: 0.2319516144828912
Validation loss: 2.52241249795919

Epoch: 6| Step: 6
Training loss: 0.17401207609583308
Validation loss: 2.523177331828815

Epoch: 6| Step: 7
Training loss: 0.17272515173536973
Validation loss: 2.567572145137482

Epoch: 6| Step: 8
Training loss: 0.3674571690609971
Validation loss: 2.5518725859212306

Epoch: 6| Step: 9
Training loss: 0.23932572004456382
Validation loss: 2.539372237807119

Epoch: 6| Step: 10
Training loss: 0.2527309948136519
Validation loss: 2.5849930750294994

Epoch: 6| Step: 11
Training loss: 0.3590795712442506
Validation loss: 2.558998138200727

Epoch: 6| Step: 12
Training loss: 0.3412599324258584
Validation loss: 2.528611957016484

Epoch: 6| Step: 13
Training loss: 0.16846112232492666
Validation loss: 2.5303767693384347

Epoch: 430| Step: 0
Training loss: 0.14817697475297523
Validation loss: 2.54444118007626

Epoch: 6| Step: 1
Training loss: 0.30327675746791827
Validation loss: 2.582830624454475

Epoch: 6| Step: 2
Training loss: 0.28094335899990297
Validation loss: 2.611296510874345

Epoch: 6| Step: 3
Training loss: 0.3885824014243619
Validation loss: 2.5852592234765734

Epoch: 6| Step: 4
Training loss: 0.2104345790081366
Validation loss: 2.573642422764528

Epoch: 6| Step: 5
Training loss: 0.2612045988303841
Validation loss: 2.547140741114304

Epoch: 6| Step: 6
Training loss: 0.3211136428908003
Validation loss: 2.549656067088889

Epoch: 6| Step: 7
Training loss: 0.2576221283387522
Validation loss: 2.5611996211234946

Epoch: 6| Step: 8
Training loss: 0.19575490437864174
Validation loss: 2.533686578344393

Epoch: 6| Step: 9
Training loss: 0.3242316990300227
Validation loss: 2.573784144434336

Epoch: 6| Step: 10
Training loss: 0.25200543119428503
Validation loss: 2.5605928210352134

Epoch: 6| Step: 11
Training loss: 0.32346161370065873
Validation loss: 2.5134019404050982

Epoch: 6| Step: 12
Training loss: 0.2995829927449596
Validation loss: 2.5338029423220054

Epoch: 6| Step: 13
Training loss: 0.14369983860425242
Validation loss: 2.552608912185057

Epoch: 431| Step: 0
Training loss: 0.19859390815530478
Validation loss: 2.5631176454045907

Epoch: 6| Step: 1
Training loss: 0.20570745635262638
Validation loss: 2.563054389719858

Epoch: 6| Step: 2
Training loss: 0.21117938266495204
Validation loss: 2.570543685915551

Epoch: 6| Step: 3
Training loss: 0.20285909928502385
Validation loss: 2.5664799754061107

Epoch: 6| Step: 4
Training loss: 0.20630001993230077
Validation loss: 2.5633439705852794

Epoch: 6| Step: 5
Training loss: 0.2613248280315806
Validation loss: 2.5891384251382146

Epoch: 6| Step: 6
Training loss: 0.25800945965849714
Validation loss: 2.596269403228992

Epoch: 6| Step: 7
Training loss: 0.18314167936223516
Validation loss: 2.6211530249192263

Epoch: 6| Step: 8
Training loss: 0.3289240123274691
Validation loss: 2.573386381398329

Epoch: 6| Step: 9
Training loss: 0.2114474437443422
Validation loss: 2.5790423091631083

Epoch: 6| Step: 10
Training loss: 0.4191170720489148
Validation loss: 2.5819683176808663

Epoch: 6| Step: 11
Training loss: 0.22299897436154148
Validation loss: 2.6126062572451336

Epoch: 6| Step: 12
Training loss: 0.16587559460337184
Validation loss: 2.5579743056999993

Epoch: 6| Step: 13
Training loss: 0.40560943279753087
Validation loss: 2.576818014203855

Epoch: 432| Step: 0
Training loss: 0.1718576812688425
Validation loss: 2.592766889897545

Epoch: 6| Step: 1
Training loss: 0.37596572265852024
Validation loss: 2.557939530601897

Epoch: 6| Step: 2
Training loss: 0.1982791189736035
Validation loss: 2.544700106133239

Epoch: 6| Step: 3
Training loss: 0.2331949088791456
Validation loss: 2.5904942135556523

Epoch: 6| Step: 4
Training loss: 0.4015852621136003
Validation loss: 2.5721911743969765

Epoch: 6| Step: 5
Training loss: 0.28194538880619646
Validation loss: 2.5909117098772465

Epoch: 6| Step: 6
Training loss: 0.2017508849942344
Validation loss: 2.6425711342440104

Epoch: 6| Step: 7
Training loss: 0.12138855335079864
Validation loss: 2.6089624377555536

Epoch: 6| Step: 8
Training loss: 0.18637776303433903
Validation loss: 2.5908018452232575

Epoch: 6| Step: 9
Training loss: 0.24049521451182113
Validation loss: 2.6025089866677913

Epoch: 6| Step: 10
Training loss: 0.16468391353024453
Validation loss: 2.6688790480375095

Epoch: 6| Step: 11
Training loss: 0.27326170856365933
Validation loss: 2.6339523794853186

Epoch: 6| Step: 12
Training loss: 0.30059947676774895
Validation loss: 2.651065659413936

Epoch: 6| Step: 13
Training loss: 0.3502516786792398
Validation loss: 2.656949889541174

Epoch: 433| Step: 0
Training loss: 0.17258391699131231
Validation loss: 2.576122205307469

Epoch: 6| Step: 1
Training loss: 0.2842579894322826
Validation loss: 2.618698645273778

Epoch: 6| Step: 2
Training loss: 0.14950966114145736
Validation loss: 2.6747582612068865

Epoch: 6| Step: 3
Training loss: 0.36066140187828466
Validation loss: 2.6145853937233507

Epoch: 6| Step: 4
Training loss: 0.17621188925213563
Validation loss: 2.5809962120395946

Epoch: 6| Step: 5
Training loss: 0.3319300665672214
Validation loss: 2.5974025486776102

Epoch: 6| Step: 6
Training loss: 0.20581835712713806
Validation loss: 2.595320267170644

Epoch: 6| Step: 7
Training loss: 0.2545167479297391
Validation loss: 2.5657317958711077

Epoch: 6| Step: 8
Training loss: 0.16881140876390488
Validation loss: 2.5568539044870007

Epoch: 6| Step: 9
Training loss: 0.28100343333637945
Validation loss: 2.5411893563522834

Epoch: 6| Step: 10
Training loss: 0.3209958695334594
Validation loss: 2.5817602532080226

Epoch: 6| Step: 11
Training loss: 0.20213691936610276
Validation loss: 2.5478259398157372

Epoch: 6| Step: 12
Training loss: 0.24599876538651103
Validation loss: 2.571537529177921

Epoch: 6| Step: 13
Training loss: 0.14187983432171214
Validation loss: 2.5900799251616395

Epoch: 434| Step: 0
Training loss: 0.2568996770983323
Validation loss: 2.576753416429258

Epoch: 6| Step: 1
Training loss: 0.19551874715159187
Validation loss: 2.583338959443327

Epoch: 6| Step: 2
Training loss: 0.1631430052086833
Validation loss: 2.5789541393478097

Epoch: 6| Step: 3
Training loss: 0.12337665793740726
Validation loss: 2.5441745594535665

Epoch: 6| Step: 4
Training loss: 0.4067490703347056
Validation loss: 2.5740668930955626

Epoch: 6| Step: 5
Training loss: 0.24915429211484436
Validation loss: 2.516046424418898

Epoch: 6| Step: 6
Training loss: 0.254309993469981
Validation loss: 2.548422844788439

Epoch: 6| Step: 7
Training loss: 0.3822533552772258
Validation loss: 2.542005405080676

Epoch: 6| Step: 8
Training loss: 0.19273601582311542
Validation loss: 2.539462362376423

Epoch: 6| Step: 9
Training loss: 0.26267372808448913
Validation loss: 2.5190283743204933

Epoch: 6| Step: 10
Training loss: 0.18446679214519054
Validation loss: 2.537083388937077

Epoch: 6| Step: 11
Training loss: 0.14786646829550018
Validation loss: 2.547492439562875

Epoch: 6| Step: 12
Training loss: 0.27411173392401056
Validation loss: 2.5388184173109605

Epoch: 6| Step: 13
Training loss: 0.2764714182641612
Validation loss: 2.5382251110217915

Epoch: 435| Step: 0
Training loss: 0.18253507144874334
Validation loss: 2.616075678566672

Epoch: 6| Step: 1
Training loss: 0.25187599125139354
Validation loss: 2.583933820674782

Epoch: 6| Step: 2
Training loss: 0.3078521194714349
Validation loss: 2.5853469581293007

Epoch: 6| Step: 3
Training loss: 0.16965873117858218
Validation loss: 2.6217750881599295

Epoch: 6| Step: 4
Training loss: 0.18429945189973546
Validation loss: 2.636145208001891

Epoch: 6| Step: 5
Training loss: 0.3590860449074112
Validation loss: 2.5802136941762583

Epoch: 6| Step: 6
Training loss: 0.3345018360190189
Validation loss: 2.5606263016203785

Epoch: 6| Step: 7
Training loss: 0.23042127152532887
Validation loss: 2.547033787517281

Epoch: 6| Step: 8
Training loss: 0.15164586532279917
Validation loss: 2.5475081484640336

Epoch: 6| Step: 9
Training loss: 0.3290442351718057
Validation loss: 2.509974718583051

Epoch: 6| Step: 10
Training loss: 0.23733618413432112
Validation loss: 2.546114214749674

Epoch: 6| Step: 11
Training loss: 0.21914473749065624
Validation loss: 2.5654672709966406

Epoch: 6| Step: 12
Training loss: 0.2029114480950077
Validation loss: 2.546709772122182

Epoch: 6| Step: 13
Training loss: 0.20313670051327712
Validation loss: 2.575627311025903

Epoch: 436| Step: 0
Training loss: 0.3001159021880563
Validation loss: 2.563733421071247

Epoch: 6| Step: 1
Training loss: 0.17761906876416125
Validation loss: 2.575102210433114

Epoch: 6| Step: 2
Training loss: 0.27394585357399354
Validation loss: 2.57307747510271

Epoch: 6| Step: 3
Training loss: 0.1691394638479783
Validation loss: 2.596820983644788

Epoch: 6| Step: 4
Training loss: 0.24456122979366304
Validation loss: 2.6140244288631145

Epoch: 6| Step: 5
Training loss: 0.2053718824457614
Validation loss: 2.609452891266429

Epoch: 6| Step: 6
Training loss: 0.2873999105253923
Validation loss: 2.5907647420546893

Epoch: 6| Step: 7
Training loss: 0.2484558593516049
Validation loss: 2.6037844712556257

Epoch: 6| Step: 8
Training loss: 0.24063265744943027
Validation loss: 2.546067273403728

Epoch: 6| Step: 9
Training loss: 0.32923179109993345
Validation loss: 2.549229579136967

Epoch: 6| Step: 10
Training loss: 0.17298695816476434
Validation loss: 2.614321650275793

Epoch: 6| Step: 11
Training loss: 0.328362379039934
Validation loss: 2.5762857677550146

Epoch: 6| Step: 12
Training loss: 0.13488159165878016
Validation loss: 2.575020169908789

Epoch: 6| Step: 13
Training loss: 0.26745579004383446
Validation loss: 2.59662784904666

Epoch: 437| Step: 0
Training loss: 0.17681004084552052
Validation loss: 2.6224714793456787

Epoch: 6| Step: 1
Training loss: 0.315603249810775
Validation loss: 2.6098690408966405

Epoch: 6| Step: 2
Training loss: 0.21066285727007789
Validation loss: 2.6166275480855203

Epoch: 6| Step: 3
Training loss: 0.28208286098476365
Validation loss: 2.6035803868727263

Epoch: 6| Step: 4
Training loss: 0.24560975361114196
Validation loss: 2.608937265641909

Epoch: 6| Step: 5
Training loss: 0.16937583576502943
Validation loss: 2.6161444020205784

Epoch: 6| Step: 6
Training loss: 0.3758551661704334
Validation loss: 2.5466301726937726

Epoch: 6| Step: 7
Training loss: 0.16345961812210738
Validation loss: 2.595583807482675

Epoch: 6| Step: 8
Training loss: 0.22199840572521454
Validation loss: 2.590691496963948

Epoch: 6| Step: 9
Training loss: 0.1935693871914435
Validation loss: 2.593981281223067

Epoch: 6| Step: 10
Training loss: 0.15652409592659688
Validation loss: 2.575592954434938

Epoch: 6| Step: 11
Training loss: 0.2919842900767876
Validation loss: 2.5814352601347244

Epoch: 6| Step: 12
Training loss: 0.23404532133962336
Validation loss: 2.573038373737838

Epoch: 6| Step: 13
Training loss: 0.2112099865538699
Validation loss: 2.5931035083788925

Epoch: 438| Step: 0
Training loss: 0.1826829434902302
Validation loss: 2.555349535579113

Epoch: 6| Step: 1
Training loss: 0.31653985393444156
Validation loss: 2.5633948629694068

Epoch: 6| Step: 2
Training loss: 0.2510958436357609
Validation loss: 2.54983097624536

Epoch: 6| Step: 3
Training loss: 0.3000124854231547
Validation loss: 2.5767479752545808

Epoch: 6| Step: 4
Training loss: 0.36359640008200783
Validation loss: 2.5794820431447016

Epoch: 6| Step: 5
Training loss: 0.19514167945046065
Validation loss: 2.5525559878977626

Epoch: 6| Step: 6
Training loss: 0.18906250236448177
Validation loss: 2.606098877460082

Epoch: 6| Step: 7
Training loss: 0.2144068523854994
Validation loss: 2.5848613834994896

Epoch: 6| Step: 8
Training loss: 0.2517887140905053
Validation loss: 2.583166946870827

Epoch: 6| Step: 9
Training loss: 0.18652549462906642
Validation loss: 2.619952525193512

Epoch: 6| Step: 10
Training loss: 0.19190550911056406
Validation loss: 2.607135884131342

Epoch: 6| Step: 11
Training loss: 0.3115337812565962
Validation loss: 2.596128819653554

Epoch: 6| Step: 12
Training loss: 0.26472878731981386
Validation loss: 2.613465065137356

Epoch: 6| Step: 13
Training loss: 0.2428742639007251
Validation loss: 2.5857063772358515

Epoch: 439| Step: 0
Training loss: 0.2265964515502894
Validation loss: 2.6351240732445484

Epoch: 6| Step: 1
Training loss: 0.2665003490105754
Validation loss: 2.6048255172286714

Epoch: 6| Step: 2
Training loss: 0.20862427998836236
Validation loss: 2.61374333877834

Epoch: 6| Step: 3
Training loss: 0.22810153448574583
Validation loss: 2.602681042292009

Epoch: 6| Step: 4
Training loss: 0.16174846136667292
Validation loss: 2.560842956208489

Epoch: 6| Step: 5
Training loss: 0.3091158373817174
Validation loss: 2.549690307641221

Epoch: 6| Step: 6
Training loss: 0.3848401108886044
Validation loss: 2.5894471004917956

Epoch: 6| Step: 7
Training loss: 0.23331409191229227
Validation loss: 2.5569989944783216

Epoch: 6| Step: 8
Training loss: 0.18703568108328208
Validation loss: 2.5946431189530874

Epoch: 6| Step: 9
Training loss: 0.21928678795827697
Validation loss: 2.5482457288083404

Epoch: 6| Step: 10
Training loss: 0.22455394724392178
Validation loss: 2.5498365844491477

Epoch: 6| Step: 11
Training loss: 0.25153096635205097
Validation loss: 2.5654256912856677

Epoch: 6| Step: 12
Training loss: 0.373288740272149
Validation loss: 2.5492792096457624

Epoch: 6| Step: 13
Training loss: 0.36575313181393493
Validation loss: 2.5366969981219567

Epoch: 440| Step: 0
Training loss: 0.29243396268296257
Validation loss: 2.512272119776615

Epoch: 6| Step: 1
Training loss: 0.3701519710733054
Validation loss: 2.5370603249086203

Epoch: 6| Step: 2
Training loss: 0.19174707003024788
Validation loss: 2.4997180615669143

Epoch: 6| Step: 3
Training loss: 0.24197476796161646
Validation loss: 2.5742071707522345

Epoch: 6| Step: 4
Training loss: 0.161251174918781
Validation loss: 2.588490984779892

Epoch: 6| Step: 5
Training loss: 0.22789535133082314
Validation loss: 2.6343212510829614

Epoch: 6| Step: 6
Training loss: 0.18145973673831461
Validation loss: 2.587968059858723

Epoch: 6| Step: 7
Training loss: 0.3043523314335796
Validation loss: 2.5960186296870855

Epoch: 6| Step: 8
Training loss: 0.19071508686536245
Validation loss: 2.6273154054092873

Epoch: 6| Step: 9
Training loss: 0.19300225542287372
Validation loss: 2.6086040446243928

Epoch: 6| Step: 10
Training loss: 0.2503790961362343
Validation loss: 2.582079678136954

Epoch: 6| Step: 11
Training loss: 0.23451222535090796
Validation loss: 2.601151205947898

Epoch: 6| Step: 12
Training loss: 0.37665749851324665
Validation loss: 2.596617799339869

Epoch: 6| Step: 13
Training loss: 0.4288434147623941
Validation loss: 2.547363652104645

Epoch: 441| Step: 0
Training loss: 0.2207181469691536
Validation loss: 2.5645779174124796

Epoch: 6| Step: 1
Training loss: 0.18694733589604892
Validation loss: 2.5698993160130783

Epoch: 6| Step: 2
Training loss: 0.18872954630396854
Validation loss: 2.545379356543095

Epoch: 6| Step: 3
Training loss: 0.29076038919158836
Validation loss: 2.5847369822230726

Epoch: 6| Step: 4
Training loss: 0.2023259457005296
Validation loss: 2.5865773233935383

Epoch: 6| Step: 5
Training loss: 0.1972300809054167
Validation loss: 2.5632026043286893

Epoch: 6| Step: 6
Training loss: 0.1555099185991672
Validation loss: 2.6003840475399675

Epoch: 6| Step: 7
Training loss: 0.22703260943799297
Validation loss: 2.60399728597446

Epoch: 6| Step: 8
Training loss: 0.3933944754675153
Validation loss: 2.572393474680716

Epoch: 6| Step: 9
Training loss: 0.2380535726478258
Validation loss: 2.62573527318913

Epoch: 6| Step: 10
Training loss: 0.35603800455705914
Validation loss: 2.5697763472705826

Epoch: 6| Step: 11
Training loss: 0.14609709088182526
Validation loss: 2.6049126794854565

Epoch: 6| Step: 12
Training loss: 0.3045337729351979
Validation loss: 2.5736026800088547

Epoch: 6| Step: 13
Training loss: 0.13820148662201953
Validation loss: 2.602295648296988

Epoch: 442| Step: 0
Training loss: 0.16644961906829542
Validation loss: 2.550418659581633

Epoch: 6| Step: 1
Training loss: 0.18732308942756465
Validation loss: 2.5427637165159322

Epoch: 6| Step: 2
Training loss: 0.17522030442679265
Validation loss: 2.5475725931920454

Epoch: 6| Step: 3
Training loss: 0.20568875728780453
Validation loss: 2.562582939560492

Epoch: 6| Step: 4
Training loss: 0.3309448757736528
Validation loss: 2.5628862302505193

Epoch: 6| Step: 5
Training loss: 0.2671650391892211
Validation loss: 2.558117730695491

Epoch: 6| Step: 6
Training loss: 0.3590046383988428
Validation loss: 2.5659473090185565

Epoch: 6| Step: 7
Training loss: 0.252944695458268
Validation loss: 2.62802618089523

Epoch: 6| Step: 8
Training loss: 0.2157365886839617
Validation loss: 2.63593719554585

Epoch: 6| Step: 9
Training loss: 0.2723782595088857
Validation loss: 2.622863143943919

Epoch: 6| Step: 10
Training loss: 0.32305259561143934
Validation loss: 2.603676005418601

Epoch: 6| Step: 11
Training loss: 0.23667381162223192
Validation loss: 2.6350842999570276

Epoch: 6| Step: 12
Training loss: 0.24043284335881326
Validation loss: 2.591443444830053

Epoch: 6| Step: 13
Training loss: 0.1796664142676169
Validation loss: 2.5934189823549225

Epoch: 443| Step: 0
Training loss: 0.1663322458791478
Validation loss: 2.5774708792792946

Epoch: 6| Step: 1
Training loss: 0.17646427439443152
Validation loss: 2.604577854959739

Epoch: 6| Step: 2
Training loss: 0.2591753829219135
Validation loss: 2.577945992130472

Epoch: 6| Step: 3
Training loss: 0.20021929713532133
Validation loss: 2.5516012319460697

Epoch: 6| Step: 4
Training loss: 0.18680509302687867
Validation loss: 2.550051857559545

Epoch: 6| Step: 5
Training loss: 0.197044739892905
Validation loss: 2.525902439277077

Epoch: 6| Step: 6
Training loss: 0.24191756741328346
Validation loss: 2.5633201177140545

Epoch: 6| Step: 7
Training loss: 0.34601195598077333
Validation loss: 2.535784211819127

Epoch: 6| Step: 8
Training loss: 0.24146169686189553
Validation loss: 2.553625187431868

Epoch: 6| Step: 9
Training loss: 0.3612309918138152
Validation loss: 2.562063063860097

Epoch: 6| Step: 10
Training loss: 0.16722219365665528
Validation loss: 2.6158575889537152

Epoch: 6| Step: 11
Training loss: 0.21239499484974464
Validation loss: 2.5984166508651647

Epoch: 6| Step: 12
Training loss: 0.17954083344899247
Validation loss: 2.5636713865659053

Epoch: 6| Step: 13
Training loss: 0.15513622771320723
Validation loss: 2.571180266775241

Epoch: 444| Step: 0
Training loss: 0.3328075757804107
Validation loss: 2.601417372643896

Epoch: 6| Step: 1
Training loss: 0.2179039534099419
Validation loss: 2.579966575801607

Epoch: 6| Step: 2
Training loss: 0.13894443858088737
Validation loss: 2.6167007368304827

Epoch: 6| Step: 3
Training loss: 0.16515402768028467
Validation loss: 2.5788113860874207

Epoch: 6| Step: 4
Training loss: 0.21599035339426698
Validation loss: 2.591054690909936

Epoch: 6| Step: 5
Training loss: 0.16399881852701326
Validation loss: 2.5844648402505217

Epoch: 6| Step: 6
Training loss: 0.25966665347233525
Validation loss: 2.6227719402134957

Epoch: 6| Step: 7
Training loss: 0.28274455597912573
Validation loss: 2.590569171788615

Epoch: 6| Step: 8
Training loss: 0.32564708041781926
Validation loss: 2.5780265026101934

Epoch: 6| Step: 9
Training loss: 0.23071375448075293
Validation loss: 2.629593534854328

Epoch: 6| Step: 10
Training loss: 0.23528419416837418
Validation loss: 2.5972032456553538

Epoch: 6| Step: 11
Training loss: 0.12810520333194123
Validation loss: 2.591258454880838

Epoch: 6| Step: 12
Training loss: 0.19055888366082865
Validation loss: 2.5671867392124565

Epoch: 6| Step: 13
Training loss: 0.32177953183901936
Validation loss: 2.5637249088651966

Epoch: 445| Step: 0
Training loss: 0.13714785674343505
Validation loss: 2.5983623336082067

Epoch: 6| Step: 1
Training loss: 0.17761096232847548
Validation loss: 2.611411254324412

Epoch: 6| Step: 2
Training loss: 0.2217646112654695
Validation loss: 2.591226640417159

Epoch: 6| Step: 3
Training loss: 0.18507602579352214
Validation loss: 2.618914598265301

Epoch: 6| Step: 4
Training loss: 0.30010604623225606
Validation loss: 2.597131313367625

Epoch: 6| Step: 5
Training loss: 0.23835279610055893
Validation loss: 2.609714581996916

Epoch: 6| Step: 6
Training loss: 0.47268344075831753
Validation loss: 2.567517624169184

Epoch: 6| Step: 7
Training loss: 0.1573883314341441
Validation loss: 2.565923590250146

Epoch: 6| Step: 8
Training loss: 0.2493028606436202
Validation loss: 2.5884084821815936

Epoch: 6| Step: 9
Training loss: 0.20190190748579082
Validation loss: 2.6150796482353935

Epoch: 6| Step: 10
Training loss: 0.20550092981817297
Validation loss: 2.5998121756177692

Epoch: 6| Step: 11
Training loss: 0.20144571721108617
Validation loss: 2.5963429984880655

Epoch: 6| Step: 12
Training loss: 0.12110103692925753
Validation loss: 2.5689350278004377

Epoch: 6| Step: 13
Training loss: 0.19907440304164253
Validation loss: 2.5591340437096797

Epoch: 446| Step: 0
Training loss: 0.24916691106419608
Validation loss: 2.562676882597868

Epoch: 6| Step: 1
Training loss: 0.20206034855710486
Validation loss: 2.580216606348409

Epoch: 6| Step: 2
Training loss: 0.18162831910809632
Validation loss: 2.596340403587869

Epoch: 6| Step: 3
Training loss: 0.3163595636091877
Validation loss: 2.5916647249859546

Epoch: 6| Step: 4
Training loss: 0.16025486677905934
Validation loss: 2.5530177117159627

Epoch: 6| Step: 5
Training loss: 0.2507718212220943
Validation loss: 2.6040732008045473

Epoch: 6| Step: 6
Training loss: 0.1676592637081843
Validation loss: 2.6017379664615756

Epoch: 6| Step: 7
Training loss: 0.24743447587568573
Validation loss: 2.5596259552407963

Epoch: 6| Step: 8
Training loss: 0.22887346989918655
Validation loss: 2.6113025810282164

Epoch: 6| Step: 9
Training loss: 0.29261515577835917
Validation loss: 2.5961935934776452

Epoch: 6| Step: 10
Training loss: 0.2764674298089019
Validation loss: 2.5620645222571268

Epoch: 6| Step: 11
Training loss: 0.24082793589558382
Validation loss: 2.536697416519241

Epoch: 6| Step: 12
Training loss: 0.18815719150053598
Validation loss: 2.5455888985856343

Epoch: 6| Step: 13
Training loss: 0.3379417005975974
Validation loss: 2.5496301073479906

Epoch: 447| Step: 0
Training loss: 0.11128690860119403
Validation loss: 2.5667124923394167

Epoch: 6| Step: 1
Training loss: 0.3386676211678453
Validation loss: 2.605684353173169

Epoch: 6| Step: 2
Training loss: 0.24596034324401425
Validation loss: 2.5581338674083645

Epoch: 6| Step: 3
Training loss: 0.23794798136081513
Validation loss: 2.5993201979417946

Epoch: 6| Step: 4
Training loss: 0.2658764266319721
Validation loss: 2.545360145628272

Epoch: 6| Step: 5
Training loss: 0.3863873458538665
Validation loss: 2.549081219365679

Epoch: 6| Step: 6
Training loss: 0.276669407779738
Validation loss: 2.6333783829546586

Epoch: 6| Step: 7
Training loss: 0.20197360453259922
Validation loss: 2.570975107935463

Epoch: 6| Step: 8
Training loss: 0.1803766903424648
Validation loss: 2.57263983072945

Epoch: 6| Step: 9
Training loss: 0.3002978192689748
Validation loss: 2.547738082582837

Epoch: 6| Step: 10
Training loss: 0.23499653579055768
Validation loss: 2.545742004097944

Epoch: 6| Step: 11
Training loss: 0.15780792796244422
Validation loss: 2.5627815738169457

Epoch: 6| Step: 12
Training loss: 0.16749203477965788
Validation loss: 2.5281713174040834

Epoch: 6| Step: 13
Training loss: 0.2289806671389008
Validation loss: 2.5600852363378612

Epoch: 448| Step: 0
Training loss: 0.40234926831062867
Validation loss: 2.5184011669859223

Epoch: 6| Step: 1
Training loss: 0.2231403408867442
Validation loss: 2.567390855746559

Epoch: 6| Step: 2
Training loss: 0.25638860466290286
Validation loss: 2.5605814885373923

Epoch: 6| Step: 3
Training loss: 0.2554533700075584
Validation loss: 2.5514027350778323

Epoch: 6| Step: 4
Training loss: 0.2904192042046073
Validation loss: 2.593043483517358

Epoch: 6| Step: 5
Training loss: 0.12180011600589083
Validation loss: 2.5698343058996276

Epoch: 6| Step: 6
Training loss: 0.23647520516962664
Validation loss: 2.5774395103156262

Epoch: 6| Step: 7
Training loss: 0.17037719801340656
Validation loss: 2.592496372055458

Epoch: 6| Step: 8
Training loss: 0.2195617905683211
Validation loss: 2.525253586699585

Epoch: 6| Step: 9
Training loss: 0.18628574625152322
Validation loss: 2.5759340539535325

Epoch: 6| Step: 10
Training loss: 0.43585560210516894
Validation loss: 2.5788038954037873

Epoch: 6| Step: 11
Training loss: 0.20654768521309932
Validation loss: 2.606098835160633

Epoch: 6| Step: 12
Training loss: 0.19934992118285655
Validation loss: 2.5620146381032716

Epoch: 6| Step: 13
Training loss: 0.41153177579698
Validation loss: 2.5642148964325036

Epoch: 449| Step: 0
Training loss: 0.23465145019609035
Validation loss: 2.5464179678736487

Epoch: 6| Step: 1
Training loss: 0.2508612787298616
Validation loss: 2.5759523108413243

Epoch: 6| Step: 2
Training loss: 0.21843214443228537
Validation loss: 2.586793799459759

Epoch: 6| Step: 3
Training loss: 0.19694052241677673
Validation loss: 2.605010510635358

Epoch: 6| Step: 4
Training loss: 0.3275278425029415
Validation loss: 2.58044107018495

Epoch: 6| Step: 5
Training loss: 0.28835290726379603
Validation loss: 2.565754240464813

Epoch: 6| Step: 6
Training loss: 0.25190221286894326
Validation loss: 2.584090746681984

Epoch: 6| Step: 7
Training loss: 0.3962850398446551
Validation loss: 2.5879149468196703

Epoch: 6| Step: 8
Training loss: 0.35953122350766425
Validation loss: 2.5970199606300426

Epoch: 6| Step: 9
Training loss: 0.30234943650686635
Validation loss: 2.562328442929215

Epoch: 6| Step: 10
Training loss: 0.36582541963726173
Validation loss: 2.618696675575238

Epoch: 6| Step: 11
Training loss: 0.24799151816639953
Validation loss: 2.5750995443512985

Epoch: 6| Step: 12
Training loss: 0.1881322928374306
Validation loss: 2.6062287295995645

Epoch: 6| Step: 13
Training loss: 0.20281341386480412
Validation loss: 2.6257835396594498

Epoch: 450| Step: 0
Training loss: 0.2089991519730534
Validation loss: 2.584084056044339

Epoch: 6| Step: 1
Training loss: 0.1854990546190844
Validation loss: 2.618454533320135

Epoch: 6| Step: 2
Training loss: 0.2147111136486368
Validation loss: 2.562648206657303

Epoch: 6| Step: 3
Training loss: 0.13640650105753688
Validation loss: 2.5790501758898285

Epoch: 6| Step: 4
Training loss: 0.24481875273145606
Validation loss: 2.569483053450746

Epoch: 6| Step: 5
Training loss: 0.20170676775683744
Validation loss: 2.587741682549794

Epoch: 6| Step: 6
Training loss: 0.19514662374512387
Validation loss: 2.607736096543072

Epoch: 6| Step: 7
Training loss: 0.33267493964604855
Validation loss: 2.575506449283611

Epoch: 6| Step: 8
Training loss: 0.28940443486570333
Validation loss: 2.5766155757656213

Epoch: 6| Step: 9
Training loss: 0.35920022778174604
Validation loss: 2.6020885564981424

Epoch: 6| Step: 10
Training loss: 0.24881410963509934
Validation loss: 2.5628251190388838

Epoch: 6| Step: 11
Training loss: 0.2785474018090444
Validation loss: 2.576913286722922

Epoch: 6| Step: 12
Training loss: 0.26564323138332735
Validation loss: 2.5469236678146547

Epoch: 6| Step: 13
Training loss: 0.14914893019797992
Validation loss: 2.5900316188977643

Epoch: 451| Step: 0
Training loss: 0.14053479586439818
Validation loss: 2.5750672584588243

Epoch: 6| Step: 1
Training loss: 0.29236604365982405
Validation loss: 2.588184892575394

Epoch: 6| Step: 2
Training loss: 0.31833971583041254
Validation loss: 2.5173146759114453

Epoch: 6| Step: 3
Training loss: 0.22248124054252544
Validation loss: 2.5732137259385266

Epoch: 6| Step: 4
Training loss: 0.27742741894265127
Validation loss: 2.533683315721217

Epoch: 6| Step: 5
Training loss: 0.23482288639744325
Validation loss: 2.532464365435598

Epoch: 6| Step: 6
Training loss: 0.21184230064023465
Validation loss: 2.5513391095629143

Epoch: 6| Step: 7
Training loss: 0.21291118487550628
Validation loss: 2.5780040813291447

Epoch: 6| Step: 8
Training loss: 0.20985132949331606
Validation loss: 2.5941350270336727

Epoch: 6| Step: 9
Training loss: 0.2247697672165571
Validation loss: 2.6213426039183623

Epoch: 6| Step: 10
Training loss: 0.2570983938157347
Validation loss: 2.612733302528023

Epoch: 6| Step: 11
Training loss: 0.33621172469091154
Validation loss: 2.6507420443771004

Epoch: 6| Step: 12
Training loss: 0.30556772926070974
Validation loss: 2.604459073457607

Epoch: 6| Step: 13
Training loss: 0.10056858005570961
Validation loss: 2.613184587878049

Epoch: 452| Step: 0
Training loss: 0.2673522385587873
Validation loss: 2.5943647363601365

Epoch: 6| Step: 1
Training loss: 0.3313427912104506
Validation loss: 2.5887608303616485

Epoch: 6| Step: 2
Training loss: 0.17969784499533617
Validation loss: 2.5570709178016484

Epoch: 6| Step: 3
Training loss: 0.20301904115494232
Validation loss: 2.539808400586859

Epoch: 6| Step: 4
Training loss: 0.1779752712712804
Validation loss: 2.572137093453316

Epoch: 6| Step: 5
Training loss: 0.2146628571961106
Validation loss: 2.535865800561064

Epoch: 6| Step: 6
Training loss: 0.29324952975769586
Validation loss: 2.580334408954498

Epoch: 6| Step: 7
Training loss: 0.3148782001323657
Validation loss: 2.5591249406914365

Epoch: 6| Step: 8
Training loss: 0.24448781313245918
Validation loss: 2.5700506473475433

Epoch: 6| Step: 9
Training loss: 0.23336086210141632
Validation loss: 2.6000635525056883

Epoch: 6| Step: 10
Training loss: 0.30714558372641804
Validation loss: 2.547863935674643

Epoch: 6| Step: 11
Training loss: 0.26542421774600267
Validation loss: 2.5805174584478547

Epoch: 6| Step: 12
Training loss: 0.20546087242661254
Validation loss: 2.563729820199044

Epoch: 6| Step: 13
Training loss: 0.19351905433163427
Validation loss: 2.6141518563360235

Epoch: 453| Step: 0
Training loss: 0.29512158636100577
Validation loss: 2.607232667262163

Epoch: 6| Step: 1
Training loss: 0.14087823742562713
Validation loss: 2.5871018349737622

Epoch: 6| Step: 2
Training loss: 0.21071431043650132
Validation loss: 2.565625670241118

Epoch: 6| Step: 3
Training loss: 0.24264007244235114
Validation loss: 2.5401035195992723

Epoch: 6| Step: 4
Training loss: 0.16286709658988507
Validation loss: 2.565578791111151

Epoch: 6| Step: 5
Training loss: 0.2562966141520636
Validation loss: 2.5676557745223305

Epoch: 6| Step: 6
Training loss: 0.20582642952123612
Validation loss: 2.584039832319275

Epoch: 6| Step: 7
Training loss: 0.20323697085103737
Validation loss: 2.615777769496275

Epoch: 6| Step: 8
Training loss: 0.23180243548135349
Validation loss: 2.633392048188058

Epoch: 6| Step: 9
Training loss: 0.23600388975999073
Validation loss: 2.609963121183892

Epoch: 6| Step: 10
Training loss: 0.29780983554412715
Validation loss: 2.626864480656522

Epoch: 6| Step: 11
Training loss: 0.16517821771259802
Validation loss: 2.6269573935782713

Epoch: 6| Step: 12
Training loss: 0.28871048293595986
Validation loss: 2.6291825100383175

Epoch: 6| Step: 13
Training loss: 0.20854335669106785
Validation loss: 2.650329612839588

Epoch: 454| Step: 0
Training loss: 0.20677207522816055
Validation loss: 2.6447293051118868

Epoch: 6| Step: 1
Training loss: 0.26940169883612225
Validation loss: 2.6543520077848677

Epoch: 6| Step: 2
Training loss: 0.2560939732492997
Validation loss: 2.655741185020558

Epoch: 6| Step: 3
Training loss: 0.25095054105646
Validation loss: 2.6168417366559016

Epoch: 6| Step: 4
Training loss: 0.256149011576449
Validation loss: 2.633191544638379

Epoch: 6| Step: 5
Training loss: 0.2157527766131933
Validation loss: 2.6194656460498393

Epoch: 6| Step: 6
Training loss: 0.14750988255344316
Validation loss: 2.608941298384733

Epoch: 6| Step: 7
Training loss: 0.2856126033839035
Validation loss: 2.6154169217145657

Epoch: 6| Step: 8
Training loss: 0.29636296235201764
Validation loss: 2.562617369534265

Epoch: 6| Step: 9
Training loss: 0.18523406715319218
Validation loss: 2.547489136756598

Epoch: 6| Step: 10
Training loss: 0.31069888587076017
Validation loss: 2.566657680431286

Epoch: 6| Step: 11
Training loss: 0.2825175965998128
Validation loss: 2.5741663944950925

Epoch: 6| Step: 12
Training loss: 0.2374848517807103
Validation loss: 2.6065612343514633

Epoch: 6| Step: 13
Training loss: 0.22965405214145357
Validation loss: 2.5915579944743254

Epoch: 455| Step: 0
Training loss: 0.20061434179736132
Validation loss: 2.5531396049053368

Epoch: 6| Step: 1
Training loss: 0.19696446838155515
Validation loss: 2.597171193573676

Epoch: 6| Step: 2
Training loss: 0.24779124115848095
Validation loss: 2.579843536396441

Epoch: 6| Step: 3
Training loss: 0.3282461850859089
Validation loss: 2.5917752820623976

Epoch: 6| Step: 4
Training loss: 0.2747944947218438
Validation loss: 2.5952573355618997

Epoch: 6| Step: 5
Training loss: 0.1498657082388873
Validation loss: 2.605663707676278

Epoch: 6| Step: 6
Training loss: 0.12792751805453426
Validation loss: 2.620159973573295

Epoch: 6| Step: 7
Training loss: 0.22350865878223258
Validation loss: 2.596691325488403

Epoch: 6| Step: 8
Training loss: 0.23894600304838523
Validation loss: 2.6162577275901775

Epoch: 6| Step: 9
Training loss: 0.24352485057940576
Validation loss: 2.59203502436504

Epoch: 6| Step: 10
Training loss: 0.29442135862926594
Validation loss: 2.6155698495628212

Epoch: 6| Step: 11
Training loss: 0.31964579257013
Validation loss: 2.604243043497339

Epoch: 6| Step: 12
Training loss: 0.21173379851628657
Validation loss: 2.6228028578993787

Epoch: 6| Step: 13
Training loss: 0.2518828242201279
Validation loss: 2.6379306165833016

Epoch: 456| Step: 0
Training loss: 0.3616976935764779
Validation loss: 2.6309508333283094

Epoch: 6| Step: 1
Training loss: 0.2009426959598489
Validation loss: 2.6127692253686705

Epoch: 6| Step: 2
Training loss: 0.27502782745884435
Validation loss: 2.6249488536502645

Epoch: 6| Step: 3
Training loss: 0.14085040306677543
Validation loss: 2.6143372076719773

Epoch: 6| Step: 4
Training loss: 0.2856718914263785
Validation loss: 2.595975164273447

Epoch: 6| Step: 5
Training loss: 0.21432260248308727
Validation loss: 2.6401559483876453

Epoch: 6| Step: 6
Training loss: 0.25112724975652917
Validation loss: 2.5809903765386784

Epoch: 6| Step: 7
Training loss: 0.2979241579732274
Validation loss: 2.6069811448003435

Epoch: 6| Step: 8
Training loss: 0.19740901117113313
Validation loss: 2.5870807557935667

Epoch: 6| Step: 9
Training loss: 0.14085091881274592
Validation loss: 2.603516253228428

Epoch: 6| Step: 10
Training loss: 0.2934929798722858
Validation loss: 2.6085937408209534

Epoch: 6| Step: 11
Training loss: 0.2310068346969344
Validation loss: 2.6079364613722995

Epoch: 6| Step: 12
Training loss: 0.2056110994950962
Validation loss: 2.5681490594882295

Epoch: 6| Step: 13
Training loss: 0.08408980073377068
Validation loss: 2.5979568903315986

Epoch: 457| Step: 0
Training loss: 0.21349958067100136
Validation loss: 2.5955179146657468

Epoch: 6| Step: 1
Training loss: 0.20425163118161652
Validation loss: 2.5518487825445053

Epoch: 6| Step: 2
Training loss: 0.2026214869645913
Validation loss: 2.5239610295598323

Epoch: 6| Step: 3
Training loss: 0.3125326377991175
Validation loss: 2.563890795545028

Epoch: 6| Step: 4
Training loss: 0.3028970957869952
Validation loss: 2.536104372178046

Epoch: 6| Step: 5
Training loss: 0.20798364239170256
Validation loss: 2.5450974358695646

Epoch: 6| Step: 6
Training loss: 0.17113691312417487
Validation loss: 2.5316433820527466

Epoch: 6| Step: 7
Training loss: 0.23197167334910818
Validation loss: 2.5611636761458745

Epoch: 6| Step: 8
Training loss: 0.2257350082298803
Validation loss: 2.5494507966278377

Epoch: 6| Step: 9
Training loss: 0.31914813384207186
Validation loss: 2.567609225004937

Epoch: 6| Step: 10
Training loss: 0.17658906859121581
Validation loss: 2.5479772645983636

Epoch: 6| Step: 11
Training loss: 0.2656867853001162
Validation loss: 2.609152641153229

Epoch: 6| Step: 12
Training loss: 0.24899370352557115
Validation loss: 2.552441510364822

Epoch: 6| Step: 13
Training loss: 0.18415558860617315
Validation loss: 2.5667448513613187

Epoch: 458| Step: 0
Training loss: 0.3067654519615682
Validation loss: 2.583327890470436

Epoch: 6| Step: 1
Training loss: 0.26711217309200846
Validation loss: 2.5399205587836504

Epoch: 6| Step: 2
Training loss: 0.1706382187239746
Validation loss: 2.5442271623348067

Epoch: 6| Step: 3
Training loss: 0.1765202670098584
Validation loss: 2.555870957890668

Epoch: 6| Step: 4
Training loss: 0.2235183839517698
Validation loss: 2.4901220688095496

Epoch: 6| Step: 5
Training loss: 0.3004475265601089
Validation loss: 2.5603316001712186

Epoch: 6| Step: 6
Training loss: 0.3784408857728055
Validation loss: 2.5515209677518005

Epoch: 6| Step: 7
Training loss: 0.19034253595917272
Validation loss: 2.546080624891354

Epoch: 6| Step: 8
Training loss: 0.318450680610623
Validation loss: 2.5834346739619836

Epoch: 6| Step: 9
Training loss: 0.1854287323526325
Validation loss: 2.6210208465348814

Epoch: 6| Step: 10
Training loss: 0.19088162322566363
Validation loss: 2.6020030632483078

Epoch: 6| Step: 11
Training loss: 0.21930668874484338
Validation loss: 2.616848058457028

Epoch: 6| Step: 12
Training loss: 0.20144514393424925
Validation loss: 2.668961634021568

Epoch: 6| Step: 13
Training loss: 0.3580725328847967
Validation loss: 2.6720197295755588

Epoch: 459| Step: 0
Training loss: 0.1885361947711039
Validation loss: 2.61805612778003

Epoch: 6| Step: 1
Training loss: 0.1944670881604629
Validation loss: 2.627464672619315

Epoch: 6| Step: 2
Training loss: 0.1776470242153905
Validation loss: 2.587894877768683

Epoch: 6| Step: 3
Training loss: 0.36961211515357123
Validation loss: 2.6505688392851363

Epoch: 6| Step: 4
Training loss: 0.2256653220795431
Validation loss: 2.541133232226611

Epoch: 6| Step: 5
Training loss: 0.2455430757360347
Validation loss: 2.5447817641332664

Epoch: 6| Step: 6
Training loss: 0.43789294171635007
Validation loss: 2.534058024481165

Epoch: 6| Step: 7
Training loss: 0.4904429839172653
Validation loss: 2.571073333035682

Epoch: 6| Step: 8
Training loss: 0.5368756982356939
Validation loss: 2.580049448705593

Epoch: 6| Step: 9
Training loss: 0.3218120735656082
Validation loss: 2.579614454023683

Epoch: 6| Step: 10
Training loss: 0.275006574313734
Validation loss: 2.6054816268698877

Epoch: 6| Step: 11
Training loss: 0.23931294798541336
Validation loss: 2.6157681011055187

Epoch: 6| Step: 12
Training loss: 0.4086720451773215
Validation loss: 2.65389988765002

Epoch: 6| Step: 13
Training loss: 0.2802452977106712
Validation loss: 2.5910675424509515

Epoch: 460| Step: 0
Training loss: 0.2897451176384252
Validation loss: 2.611850908650917

Epoch: 6| Step: 1
Training loss: 0.21039095468137617
Validation loss: 2.5274246562207945

Epoch: 6| Step: 2
Training loss: 0.20977471543261972
Validation loss: 2.539867467002362

Epoch: 6| Step: 3
Training loss: 0.31740364593206816
Validation loss: 2.516801294511081

Epoch: 6| Step: 4
Training loss: 0.42747259621040534
Validation loss: 2.5365192518625306

Epoch: 6| Step: 5
Training loss: 0.318918451041227
Validation loss: 2.529643801114772

Epoch: 6| Step: 6
Training loss: 0.26317268023395746
Validation loss: 2.5303530899836386

Epoch: 6| Step: 7
Training loss: 0.2145748970462828
Validation loss: 2.5774925781272366

Epoch: 6| Step: 8
Training loss: 0.34911398713674985
Validation loss: 2.577508756659838

Epoch: 6| Step: 9
Training loss: 0.2786371134644378
Validation loss: 2.5932035645220366

Epoch: 6| Step: 10
Training loss: 0.26146958005255244
Validation loss: 2.6116368045229548

Epoch: 6| Step: 11
Training loss: 0.27588854747568353
Validation loss: 2.572098195823357

Epoch: 6| Step: 12
Training loss: 0.23649892073560438
Validation loss: 2.608335570307859

Epoch: 6| Step: 13
Training loss: 0.1474130565389231
Validation loss: 2.581324251261008

Epoch: 461| Step: 0
Training loss: 0.4024921624978459
Validation loss: 2.5367724904279236

Epoch: 6| Step: 1
Training loss: 0.25936975646176574
Validation loss: 2.5414497162531484

Epoch: 6| Step: 2
Training loss: 0.22371539627515583
Validation loss: 2.549896532541734

Epoch: 6| Step: 3
Training loss: 0.20170901170858302
Validation loss: 2.5176976497892087

Epoch: 6| Step: 4
Training loss: 0.3001689623831931
Validation loss: 2.4885220882371697

Epoch: 6| Step: 5
Training loss: 0.2521440684370689
Validation loss: 2.527268318404389

Epoch: 6| Step: 6
Training loss: 0.29970536466143216
Validation loss: 2.5403544698231655

Epoch: 6| Step: 7
Training loss: 0.22913277259791714
Validation loss: 2.550647426238603

Epoch: 6| Step: 8
Training loss: 0.2578999919975667
Validation loss: 2.569050548625801

Epoch: 6| Step: 9
Training loss: 0.25955395212848065
Validation loss: 2.6021963949348534

Epoch: 6| Step: 10
Training loss: 0.29497300266934934
Validation loss: 2.62095148433316

Epoch: 6| Step: 11
Training loss: 0.3087186681239744
Validation loss: 2.5851168283074615

Epoch: 6| Step: 12
Training loss: 0.2904975555279321
Validation loss: 2.5939364612746445

Epoch: 6| Step: 13
Training loss: 0.24602455347067345
Validation loss: 2.5916526845757883

Epoch: 462| Step: 0
Training loss: 0.2065783350901397
Validation loss: 2.558438177012367

Epoch: 6| Step: 1
Training loss: 0.29271097923024175
Validation loss: 2.558093392146913

Epoch: 6| Step: 2
Training loss: 0.2398723883414612
Validation loss: 2.543179004764842

Epoch: 6| Step: 3
Training loss: 0.29601293180543825
Validation loss: 2.544165801941616

Epoch: 6| Step: 4
Training loss: 0.25164663909859747
Validation loss: 2.511783005574721

Epoch: 6| Step: 5
Training loss: 0.32609833670709304
Validation loss: 2.5221275846886893

Epoch: 6| Step: 6
Training loss: 0.21154431198689685
Validation loss: 2.5555862467010595

Epoch: 6| Step: 7
Training loss: 0.22076702036967746
Validation loss: 2.5421729576248078

Epoch: 6| Step: 8
Training loss: 0.23033393537545732
Validation loss: 2.5598672818014254

Epoch: 6| Step: 9
Training loss: 0.2813380686309081
Validation loss: 2.5731186621610362

Epoch: 6| Step: 10
Training loss: 0.3887572075031544
Validation loss: 2.5754348053863905

Epoch: 6| Step: 11
Training loss: 0.31309127898249656
Validation loss: 2.541449647659399

Epoch: 6| Step: 12
Training loss: 0.16026336297975977
Validation loss: 2.582624249456339

Epoch: 6| Step: 13
Training loss: 0.11377773746479067
Validation loss: 2.582782048109777

Epoch: 463| Step: 0
Training loss: 0.2757134000182838
Validation loss: 2.555383227320574

Epoch: 6| Step: 1
Training loss: 0.24737344021423496
Validation loss: 2.5300299994613615

Epoch: 6| Step: 2
Training loss: 0.2435876381983952
Validation loss: 2.5525049949075576

Epoch: 6| Step: 3
Training loss: 0.2504457880157175
Validation loss: 2.473819260803595

Epoch: 6| Step: 4
Training loss: 0.24502542001361108
Validation loss: 2.4653690027388517

Epoch: 6| Step: 5
Training loss: 0.331882903674853
Validation loss: 2.4801903053316856

Epoch: 6| Step: 6
Training loss: 0.27168534065250216
Validation loss: 2.4432772547552672

Epoch: 6| Step: 7
Training loss: 0.1862527570904449
Validation loss: 2.472358328359622

Epoch: 6| Step: 8
Training loss: 0.21490899742481473
Validation loss: 2.5083538477164407

Epoch: 6| Step: 9
Training loss: 0.2829229613340323
Validation loss: 2.51283129823676

Epoch: 6| Step: 10
Training loss: 0.2882713755542107
Validation loss: 2.521102006859821

Epoch: 6| Step: 11
Training loss: 0.2701006279515082
Validation loss: 2.5297486919424435

Epoch: 6| Step: 12
Training loss: 0.24323790934096123
Validation loss: 2.5225304348929574

Epoch: 6| Step: 13
Training loss: 0.20448064507351438
Validation loss: 2.551182945459411

Epoch: 464| Step: 0
Training loss: 0.31388413740156135
Validation loss: 2.5532138589850732

Epoch: 6| Step: 1
Training loss: 0.20124445226379675
Validation loss: 2.560769649161026

Epoch: 6| Step: 2
Training loss: 0.13031580463399878
Validation loss: 2.553145838431152

Epoch: 6| Step: 3
Training loss: 0.27372915517360497
Validation loss: 2.5171730680934155

Epoch: 6| Step: 4
Training loss: 0.2650582353689143
Validation loss: 2.534803081651236

Epoch: 6| Step: 5
Training loss: 0.25854327928059123
Validation loss: 2.5295923188840344

Epoch: 6| Step: 6
Training loss: 0.19604338268849195
Validation loss: 2.547129288377554

Epoch: 6| Step: 7
Training loss: 0.25519161591304235
Validation loss: 2.535004501443952

Epoch: 6| Step: 8
Training loss: 0.21272057557503013
Validation loss: 2.574649293335457

Epoch: 6| Step: 9
Training loss: 0.37117878792824305
Validation loss: 2.527622229683775

Epoch: 6| Step: 10
Training loss: 0.1944874024669266
Validation loss: 2.5330579034551355

Epoch: 6| Step: 11
Training loss: 0.15265309885964204
Validation loss: 2.5867496785519375

Epoch: 6| Step: 12
Training loss: 0.20946997082818464
Validation loss: 2.57040111185657

Epoch: 6| Step: 13
Training loss: 0.2576037052724747
Validation loss: 2.58837948417317

Epoch: 465| Step: 0
Training loss: 0.3843700098473634
Validation loss: 2.5977738923653946

Epoch: 6| Step: 1
Training loss: 0.2629265883901665
Validation loss: 2.5399067176815335

Epoch: 6| Step: 2
Training loss: 0.2588507236939973
Validation loss: 2.5314642631809163

Epoch: 6| Step: 3
Training loss: 0.18218831583956022
Validation loss: 2.538288834978954

Epoch: 6| Step: 4
Training loss: 0.20427074447609153
Validation loss: 2.4691635954662594

Epoch: 6| Step: 5
Training loss: 0.3438293625510943
Validation loss: 2.5095188899803094

Epoch: 6| Step: 6
Training loss: 0.22993246820786542
Validation loss: 2.4927355793402715

Epoch: 6| Step: 7
Training loss: 0.2427721810711168
Validation loss: 2.495982916869318

Epoch: 6| Step: 8
Training loss: 0.15530844959450088
Validation loss: 2.519773996139233

Epoch: 6| Step: 9
Training loss: 0.35944888143308346
Validation loss: 2.5145509129111083

Epoch: 6| Step: 10
Training loss: 0.23657983978397795
Validation loss: 2.5200409785931788

Epoch: 6| Step: 11
Training loss: 0.3368178520492355
Validation loss: 2.5255311467604105

Epoch: 6| Step: 12
Training loss: 0.19306516902606272
Validation loss: 2.5398740530678463

Epoch: 6| Step: 13
Training loss: 0.2699510097651524
Validation loss: 2.526221953794978

Epoch: 466| Step: 0
Training loss: 0.3150933187629906
Validation loss: 2.495800967026057

Epoch: 6| Step: 1
Training loss: 0.13490459629695037
Validation loss: 2.474907545664679

Epoch: 6| Step: 2
Training loss: 0.2550219452054157
Validation loss: 2.5241191469993236

Epoch: 6| Step: 3
Training loss: 0.23078826803230326
Validation loss: 2.476994957636709

Epoch: 6| Step: 4
Training loss: 0.22750582472712022
Validation loss: 2.4816970100592637

Epoch: 6| Step: 5
Training loss: 0.2024843677326763
Validation loss: 2.4567715136674844

Epoch: 6| Step: 6
Training loss: 0.2538906386051037
Validation loss: 2.4411499655470394

Epoch: 6| Step: 7
Training loss: 0.3243182385860096
Validation loss: 2.4509652875354013

Epoch: 6| Step: 8
Training loss: 0.21181270267243874
Validation loss: 2.472572742430906

Epoch: 6| Step: 9
Training loss: 0.18865353670897253
Validation loss: 2.4978891526360765

Epoch: 6| Step: 10
Training loss: 0.2867507511335278
Validation loss: 2.49585176885273

Epoch: 6| Step: 11
Training loss: 0.22124639673854984
Validation loss: 2.502928757475421

Epoch: 6| Step: 12
Training loss: 0.16512048281685893
Validation loss: 2.493517324624834

Epoch: 6| Step: 13
Training loss: 0.17427729854478413
Validation loss: 2.5066533410574054

Epoch: 467| Step: 0
Training loss: 0.18475717843812445
Validation loss: 2.515672975099386

Epoch: 6| Step: 1
Training loss: 0.13342558080563957
Validation loss: 2.525912094387415

Epoch: 6| Step: 2
Training loss: 0.141190497843598
Validation loss: 2.5396736261478243

Epoch: 6| Step: 3
Training loss: 0.2137829950169693
Validation loss: 2.5182336371853684

Epoch: 6| Step: 4
Training loss: 0.253350662378063
Validation loss: 2.4974164123484552

Epoch: 6| Step: 5
Training loss: 0.25686799056056614
Validation loss: 2.517836687207496

Epoch: 6| Step: 6
Training loss: 0.13314915511776082
Validation loss: 2.5563233430290797

Epoch: 6| Step: 7
Training loss: 0.19117360671194036
Validation loss: 2.522414149518827

Epoch: 6| Step: 8
Training loss: 0.20272179162107723
Validation loss: 2.551451006051691

Epoch: 6| Step: 9
Training loss: 0.14253218446311075
Validation loss: 2.5364690401689725

Epoch: 6| Step: 10
Training loss: 0.29642564244596026
Validation loss: 2.538756467488919

Epoch: 6| Step: 11
Training loss: 0.2401143681447702
Validation loss: 2.5644213258808146

Epoch: 6| Step: 12
Training loss: 0.20551197844653113
Validation loss: 2.5622893816382164

Epoch: 6| Step: 13
Training loss: 0.3292440903827722
Validation loss: 2.5899510376618204

Epoch: 468| Step: 0
Training loss: 0.294082862886777
Validation loss: 2.568009065858989

Epoch: 6| Step: 1
Training loss: 0.3032201253935871
Validation loss: 2.569008630740165

Epoch: 6| Step: 2
Training loss: 0.2203917543422211
Validation loss: 2.5973374195693166

Epoch: 6| Step: 3
Training loss: 0.20578709623740565
Validation loss: 2.5533819380824125

Epoch: 6| Step: 4
Training loss: 0.1756431566980178
Validation loss: 2.5686161834454233

Epoch: 6| Step: 5
Training loss: 0.27583777196968157
Validation loss: 2.556405203372689

Epoch: 6| Step: 6
Training loss: 0.14967856338678576
Validation loss: 2.59203559998947

Epoch: 6| Step: 7
Training loss: 0.24689679592830005
Validation loss: 2.564697937223106

Epoch: 6| Step: 8
Training loss: 0.19986259911401286
Validation loss: 2.5689881789824276

Epoch: 6| Step: 9
Training loss: 0.11261108315073312
Validation loss: 2.5788354416221133

Epoch: 6| Step: 10
Training loss: 0.17469494320975548
Validation loss: 2.577198488294187

Epoch: 6| Step: 11
Training loss: 0.13082771487634737
Validation loss: 2.5381826840565505

Epoch: 6| Step: 12
Training loss: 0.16799120420253225
Validation loss: 2.564913382815703

Epoch: 6| Step: 13
Training loss: 0.2549204743721234
Validation loss: 2.5360571798471865

Epoch: 469| Step: 0
Training loss: 0.2158571876334976
Validation loss: 2.5556102705661377

Epoch: 6| Step: 1
Training loss: 0.2382261493949372
Validation loss: 2.5325722268624666

Epoch: 6| Step: 2
Training loss: 0.11619995770556227
Validation loss: 2.5488980591198755

Epoch: 6| Step: 3
Training loss: 0.18202753799975935
Validation loss: 2.560322270612055

Epoch: 6| Step: 4
Training loss: 0.22968506519817694
Validation loss: 2.539296872260385

Epoch: 6| Step: 5
Training loss: 0.15967057018902242
Validation loss: 2.5630666474936246

Epoch: 6| Step: 6
Training loss: 0.2633847121071565
Validation loss: 2.556538816992128

Epoch: 6| Step: 7
Training loss: 0.36981257079592633
Validation loss: 2.5427178546310367

Epoch: 6| Step: 8
Training loss: 0.12478035016431635
Validation loss: 2.534955109252198

Epoch: 6| Step: 9
Training loss: 0.23059586882428793
Validation loss: 2.528076761428597

Epoch: 6| Step: 10
Training loss: 0.178585008121914
Validation loss: 2.5527324452898856

Epoch: 6| Step: 11
Training loss: 0.20598492639215066
Validation loss: 2.5610562110619663

Epoch: 6| Step: 12
Training loss: 0.13405493610447286
Validation loss: 2.5384200512161317

Epoch: 6| Step: 13
Training loss: 0.14720105645342266
Validation loss: 2.575365571465984

Epoch: 470| Step: 0
Training loss: 0.12579369394575277
Validation loss: 2.548311151845136

Epoch: 6| Step: 1
Training loss: 0.24840805461015447
Validation loss: 2.5281802266527493

Epoch: 6| Step: 2
Training loss: 0.28963618442292105
Validation loss: 2.5738269696309874

Epoch: 6| Step: 3
Training loss: 0.15119669757272264
Validation loss: 2.5656315067152744

Epoch: 6| Step: 4
Training loss: 0.22092717537773182
Validation loss: 2.56628122982136

Epoch: 6| Step: 5
Training loss: 0.24300741029162495
Validation loss: 2.5384346871598424

Epoch: 6| Step: 6
Training loss: 0.13914050582546506
Validation loss: 2.5402463383585836

Epoch: 6| Step: 7
Training loss: 0.2237998388635202
Validation loss: 2.5017595308377776

Epoch: 6| Step: 8
Training loss: 0.1932352226178893
Validation loss: 2.5062267969015997

Epoch: 6| Step: 9
Training loss: 0.36576453912588386
Validation loss: 2.511191472732558

Epoch: 6| Step: 10
Training loss: 0.1454019737631452
Validation loss: 2.540523318960108

Epoch: 6| Step: 11
Training loss: 0.2730118708623415
Validation loss: 2.549477130752869

Epoch: 6| Step: 12
Training loss: 0.19456081701887099
Validation loss: 2.5958214780707007

Epoch: 6| Step: 13
Training loss: 0.16077371522173295
Validation loss: 2.5928860500654682

Epoch: 471| Step: 0
Training loss: 0.1687986420797835
Validation loss: 2.561249511642152

Epoch: 6| Step: 1
Training loss: 0.15444184989082993
Validation loss: 2.59023413809748

Epoch: 6| Step: 2
Training loss: 0.19593870865298477
Validation loss: 2.592381434192481

Epoch: 6| Step: 3
Training loss: 0.1887741704016507
Validation loss: 2.5627934337637144

Epoch: 6| Step: 4
Training loss: 0.31260262234814906
Validation loss: 2.6172018854893477

Epoch: 6| Step: 5
Training loss: 0.17350784541951686
Validation loss: 2.5893326183511918

Epoch: 6| Step: 6
Training loss: 0.14680556370559608
Validation loss: 2.570525914706043

Epoch: 6| Step: 7
Training loss: 0.18921176046980578
Validation loss: 2.5559929396813157

Epoch: 6| Step: 8
Training loss: 0.254205527357384
Validation loss: 2.5594593729595494

Epoch: 6| Step: 9
Training loss: 0.14611733547093672
Validation loss: 2.580311961528133

Epoch: 6| Step: 10
Training loss: 0.11602899991269931
Validation loss: 2.5321238376832373

Epoch: 6| Step: 11
Training loss: 0.29077394421975894
Validation loss: 2.53676983661334

Epoch: 6| Step: 12
Training loss: 0.28559661202458114
Validation loss: 2.5334951565902455

Epoch: 6| Step: 13
Training loss: 0.17819948437695876
Validation loss: 2.5451075620940755

Epoch: 472| Step: 0
Training loss: 0.280847950836986
Validation loss: 2.5410738764270837

Epoch: 6| Step: 1
Training loss: 0.2713519534986647
Validation loss: 2.505423045547223

Epoch: 6| Step: 2
Training loss: 0.11503027362637108
Validation loss: 2.547610944276964

Epoch: 6| Step: 3
Training loss: 0.1383732683517943
Validation loss: 2.506771653807289

Epoch: 6| Step: 4
Training loss: 0.2624976538371643
Validation loss: 2.5045512297867725

Epoch: 6| Step: 5
Training loss: 0.196822499662309
Validation loss: 2.509632833440903

Epoch: 6| Step: 6
Training loss: 0.10916914470998948
Validation loss: 2.511948601929339

Epoch: 6| Step: 7
Training loss: 0.13925514994426003
Validation loss: 2.5137284215436018

Epoch: 6| Step: 8
Training loss: 0.26498490232069566
Validation loss: 2.5019752144309715

Epoch: 6| Step: 9
Training loss: 0.1629013284418743
Validation loss: 2.5030577320950034

Epoch: 6| Step: 10
Training loss: 0.18357028202462988
Validation loss: 2.5317712832193684

Epoch: 6| Step: 11
Training loss: 0.22050156293042628
Validation loss: 2.521226220941619

Epoch: 6| Step: 12
Training loss: 0.23202610780817085
Validation loss: 2.49399294670445

Epoch: 6| Step: 13
Training loss: 0.2454504505963443
Validation loss: 2.5232658920929207

Epoch: 473| Step: 0
Training loss: 0.14640200524298766
Validation loss: 2.498962654734762

Epoch: 6| Step: 1
Training loss: 0.2969300068540344
Validation loss: 2.518801361816705

Epoch: 6| Step: 2
Training loss: 0.2107546331568344
Validation loss: 2.4957839157545476

Epoch: 6| Step: 3
Training loss: 0.209842195867264
Validation loss: 2.4793478704011775

Epoch: 6| Step: 4
Training loss: 0.16995817651700118
Validation loss: 2.5283055835306687

Epoch: 6| Step: 5
Training loss: 0.2261102865956114
Validation loss: 2.5202100412555173

Epoch: 6| Step: 6
Training loss: 0.17158363311141425
Validation loss: 2.56793267489066

Epoch: 6| Step: 7
Training loss: 0.17476051987314148
Validation loss: 2.5540915584964963

Epoch: 6| Step: 8
Training loss: 0.20892178855005794
Validation loss: 2.5563228034890364

Epoch: 6| Step: 9
Training loss: 0.195807107266715
Validation loss: 2.5276128052559805

Epoch: 6| Step: 10
Training loss: 0.20155607035828005
Validation loss: 2.5521059701169686

Epoch: 6| Step: 11
Training loss: 0.1411677192832085
Validation loss: 2.5223784496729476

Epoch: 6| Step: 12
Training loss: 0.2571735845998353
Validation loss: 2.504533380311716

Epoch: 6| Step: 13
Training loss: 0.17403744834901053
Validation loss: 2.5818337293314073

Epoch: 474| Step: 0
Training loss: 0.18582062854944456
Validation loss: 2.5681131114544833

Epoch: 6| Step: 1
Training loss: 0.09822100416649855
Validation loss: 2.598036665243295

Epoch: 6| Step: 2
Training loss: 0.17762516145611593
Validation loss: 2.579649991347445

Epoch: 6| Step: 3
Training loss: 0.17125978143455606
Validation loss: 2.5410994816926835

Epoch: 6| Step: 4
Training loss: 0.17353940946726074
Validation loss: 2.582498283135103

Epoch: 6| Step: 5
Training loss: 0.27883609028194506
Validation loss: 2.5632107972154587

Epoch: 6| Step: 6
Training loss: 0.19654228236865073
Validation loss: 2.5673396191859292

Epoch: 6| Step: 7
Training loss: 0.3180804756948303
Validation loss: 2.525018928267633

Epoch: 6| Step: 8
Training loss: 0.15586165806525107
Validation loss: 2.566368147820874

Epoch: 6| Step: 9
Training loss: 0.19000687243242118
Validation loss: 2.5608389338157305

Epoch: 6| Step: 10
Training loss: 0.19129771444592497
Validation loss: 2.5345786998341944

Epoch: 6| Step: 11
Training loss: 0.2852295036808956
Validation loss: 2.48434792677547

Epoch: 6| Step: 12
Training loss: 0.20026350023122133
Validation loss: 2.533905191338496

Epoch: 6| Step: 13
Training loss: 0.18721116190269957
Validation loss: 2.5222288398140273

Epoch: 475| Step: 0
Training loss: 0.21195890242298543
Validation loss: 2.534273461419832

Epoch: 6| Step: 1
Training loss: 0.10593305043916358
Validation loss: 2.527831149939821

Epoch: 6| Step: 2
Training loss: 0.10418469650476167
Validation loss: 2.534358360555857

Epoch: 6| Step: 3
Training loss: 0.22699485828441365
Validation loss: 2.5449301060871554

Epoch: 6| Step: 4
Training loss: 0.14712296843969455
Validation loss: 2.5401088732462065

Epoch: 6| Step: 5
Training loss: 0.1483044404405229
Validation loss: 2.572923706518012

Epoch: 6| Step: 6
Training loss: 0.1706421865551262
Validation loss: 2.556508919996896

Epoch: 6| Step: 7
Training loss: 0.22882697910322775
Validation loss: 2.56424684107781

Epoch: 6| Step: 8
Training loss: 0.16639726193650076
Validation loss: 2.5675201353702697

Epoch: 6| Step: 9
Training loss: 0.3126796444476647
Validation loss: 2.5490191259731936

Epoch: 6| Step: 10
Training loss: 0.1970201891699363
Validation loss: 2.546398720999927

Epoch: 6| Step: 11
Training loss: 0.31846522110436326
Validation loss: 2.567472591376665

Epoch: 6| Step: 12
Training loss: 0.2215819458438041
Validation loss: 2.5477184109821995

Epoch: 6| Step: 13
Training loss: 0.22745335483244605
Validation loss: 2.5315765986473586

Epoch: 476| Step: 0
Training loss: 0.14335492566347632
Validation loss: 2.528330878044039

Epoch: 6| Step: 1
Training loss: 0.19439539167638611
Validation loss: 2.531752760896142

Epoch: 6| Step: 2
Training loss: 0.11384834375728516
Validation loss: 2.5382801985589905

Epoch: 6| Step: 3
Training loss: 0.3228382456318274
Validation loss: 2.533994130392064

Epoch: 6| Step: 4
Training loss: 0.22699842772327933
Validation loss: 2.533609277987144

Epoch: 6| Step: 5
Training loss: 0.183856259019813
Validation loss: 2.5142070392028066

Epoch: 6| Step: 6
Training loss: 0.19230475996606156
Validation loss: 2.48561873660494

Epoch: 6| Step: 7
Training loss: 0.15027527286686904
Validation loss: 2.532966265884768

Epoch: 6| Step: 8
Training loss: 0.2554832343565445
Validation loss: 2.48909762575257

Epoch: 6| Step: 9
Training loss: 0.20272788329563188
Validation loss: 2.5646836635701384

Epoch: 6| Step: 10
Training loss: 0.1578947759249706
Validation loss: 2.5206384694517716

Epoch: 6| Step: 11
Training loss: 0.1876285132429301
Validation loss: 2.567120024625981

Epoch: 6| Step: 12
Training loss: 0.13578747604459102
Validation loss: 2.5382353828343245

Epoch: 6| Step: 13
Training loss: 0.36244308008357456
Validation loss: 2.5378460985355495

Epoch: 477| Step: 0
Training loss: 0.26450239705764506
Validation loss: 2.5585101650887996

Epoch: 6| Step: 1
Training loss: 0.14238062989036382
Validation loss: 2.5779447958057973

Epoch: 6| Step: 2
Training loss: 0.20187165481937325
Validation loss: 2.5478432472743036

Epoch: 6| Step: 3
Training loss: 0.2219031547762434
Validation loss: 2.5663814736086485

Epoch: 6| Step: 4
Training loss: 0.23288617920367155
Validation loss: 2.5781199763781397

Epoch: 6| Step: 5
Training loss: 0.1210265357613514
Validation loss: 2.6157749625794167

Epoch: 6| Step: 6
Training loss: 0.2846667517084766
Validation loss: 2.5563246181683397

Epoch: 6| Step: 7
Training loss: 0.12865535566349437
Validation loss: 2.57196801299671

Epoch: 6| Step: 8
Training loss: 0.2423018370194253
Validation loss: 2.577499953267044

Epoch: 6| Step: 9
Training loss: 0.2443379787051825
Validation loss: 2.5787381355128387

Epoch: 6| Step: 10
Training loss: 0.16872276686867746
Validation loss: 2.535888920693502

Epoch: 6| Step: 11
Training loss: 0.14270845100532562
Validation loss: 2.5576118629841584

Epoch: 6| Step: 12
Training loss: 0.1460680895724609
Validation loss: 2.5775468672159203

Epoch: 6| Step: 13
Training loss: 0.1559012574256486
Validation loss: 2.577988284784618

Epoch: 478| Step: 0
Training loss: 0.15519209596539746
Validation loss: 2.568786063112161

Epoch: 6| Step: 1
Training loss: 0.31432863697492525
Validation loss: 2.5364697193675942

Epoch: 6| Step: 2
Training loss: 0.24155322202652935
Validation loss: 2.555752166615331

Epoch: 6| Step: 3
Training loss: 0.2936392042533359
Validation loss: 2.5797486861211385

Epoch: 6| Step: 4
Training loss: 0.1948447539327373
Validation loss: 2.5706449332899908

Epoch: 6| Step: 5
Training loss: 0.1502584830533793
Validation loss: 2.588126120583881

Epoch: 6| Step: 6
Training loss: 0.12904135530830654
Validation loss: 2.577665471116485

Epoch: 6| Step: 7
Training loss: 0.19830658529101122
Validation loss: 2.613091048871161

Epoch: 6| Step: 8
Training loss: 0.24801320125260937
Validation loss: 2.619141049803439

Epoch: 6| Step: 9
Training loss: 0.15915717217286632
Validation loss: 2.665322771882662

Epoch: 6| Step: 10
Training loss: 0.21837385228570014
Validation loss: 2.6190755166961277

Epoch: 6| Step: 11
Training loss: 0.12787297862889346
Validation loss: 2.6313399512317743

Epoch: 6| Step: 12
Training loss: 0.24526328789880106
Validation loss: 2.588445896937109

Epoch: 6| Step: 13
Training loss: 0.1331790186304162
Validation loss: 2.5733708150270314

Epoch: 479| Step: 0
Training loss: 0.1350112418288913
Validation loss: 2.587908718288121

Epoch: 6| Step: 1
Training loss: 0.1501362308629747
Validation loss: 2.5980524148840547

Epoch: 6| Step: 2
Training loss: 0.24394949488723386
Validation loss: 2.5506839591366957

Epoch: 6| Step: 3
Training loss: 0.14266779444466388
Validation loss: 2.5972817398255468

Epoch: 6| Step: 4
Training loss: 0.2438510092495981
Validation loss: 2.588246984605287

Epoch: 6| Step: 5
Training loss: 0.2296823971369652
Validation loss: 2.5878892500059747

Epoch: 6| Step: 6
Training loss: 0.31584423684663615
Validation loss: 2.5968147784490627

Epoch: 6| Step: 7
Training loss: 0.36759234491099346
Validation loss: 2.572090984603339

Epoch: 6| Step: 8
Training loss: 0.13225150837966498
Validation loss: 2.569548868616219

Epoch: 6| Step: 9
Training loss: 0.16623174400409652
Validation loss: 2.623498260482961

Epoch: 6| Step: 10
Training loss: 0.10089200868111159
Validation loss: 2.5697501378651166

Epoch: 6| Step: 11
Training loss: 0.1587232059015512
Validation loss: 2.564627072969665

Epoch: 6| Step: 12
Training loss: 0.17387468807348797
Validation loss: 2.5700521877455382

Epoch: 6| Step: 13
Training loss: 0.1678102599426025
Validation loss: 2.5606157006337984

Epoch: 480| Step: 0
Training loss: 0.17443651714786126
Validation loss: 2.5819574801364737

Epoch: 6| Step: 1
Training loss: 0.22806582238528578
Validation loss: 2.5678160794430007

Epoch: 6| Step: 2
Training loss: 0.19550417078305893
Validation loss: 2.5488112011595425

Epoch: 6| Step: 3
Training loss: 0.14345206920125975
Validation loss: 2.5749561433116783

Epoch: 6| Step: 4
Training loss: 0.1370512869179867
Validation loss: 2.5331713333479673

Epoch: 6| Step: 5
Training loss: 0.25145570312479215
Validation loss: 2.5675044166089296

Epoch: 6| Step: 6
Training loss: 0.15310867548554158
Validation loss: 2.5306728145036663

Epoch: 6| Step: 7
Training loss: 0.34591849132716124
Validation loss: 2.5340499867184323

Epoch: 6| Step: 8
Training loss: 0.13927909720513607
Validation loss: 2.58265013861784

Epoch: 6| Step: 9
Training loss: 0.14713702721403543
Validation loss: 2.5670507826665157

Epoch: 6| Step: 10
Training loss: 0.30216316971374635
Validation loss: 2.578221375673615

Epoch: 6| Step: 11
Training loss: 0.24463798216774732
Validation loss: 2.6190869142165187

Epoch: 6| Step: 12
Training loss: 0.14991163169094407
Validation loss: 2.6413964750550756

Epoch: 6| Step: 13
Training loss: 0.12620806307930074
Validation loss: 2.609923690848363

Epoch: 481| Step: 0
Training loss: 0.3054295575690124
Validation loss: 2.62157578589501

Epoch: 6| Step: 1
Training loss: 0.30744716244608883
Validation loss: 2.6191405447375913

Epoch: 6| Step: 2
Training loss: 0.225348872345413
Validation loss: 2.644025024950685

Epoch: 6| Step: 3
Training loss: 0.2924674004133235
Validation loss: 2.6324109179879245

Epoch: 6| Step: 4
Training loss: 0.24317264924725496
Validation loss: 2.6103471985105475

Epoch: 6| Step: 5
Training loss: 0.22741472342440092
Validation loss: 2.616220536640969

Epoch: 6| Step: 6
Training loss: 0.17987011876087336
Validation loss: 2.570430287253259

Epoch: 6| Step: 7
Training loss: 0.22459613097576722
Validation loss: 2.612439035727922

Epoch: 6| Step: 8
Training loss: 0.12803526882198454
Validation loss: 2.5911129314584342

Epoch: 6| Step: 9
Training loss: 0.22895746634570552
Validation loss: 2.584574817556558

Epoch: 6| Step: 10
Training loss: 0.389431656501138
Validation loss: 2.5541918721834205

Epoch: 6| Step: 11
Training loss: 0.2396335842811743
Validation loss: 2.562369937832453

Epoch: 6| Step: 12
Training loss: 0.12332298695198997
Validation loss: 2.5631565830522827

Epoch: 6| Step: 13
Training loss: 0.16319159551482998
Validation loss: 2.5604604580068533

Epoch: 482| Step: 0
Training loss: 0.34167265678403896
Validation loss: 2.580116428122815

Epoch: 6| Step: 1
Training loss: 0.16133905563086265
Validation loss: 2.578945051118806

Epoch: 6| Step: 2
Training loss: 0.322191958243959
Validation loss: 2.5867831416917553

Epoch: 6| Step: 3
Training loss: 0.17557695490993852
Validation loss: 2.5563531729979676

Epoch: 6| Step: 4
Training loss: 0.12915369328853293
Validation loss: 2.5649873040509603

Epoch: 6| Step: 5
Training loss: 0.2402887360389859
Validation loss: 2.5732840732838382

Epoch: 6| Step: 6
Training loss: 0.13638585297540406
Validation loss: 2.567305638989519

Epoch: 6| Step: 7
Training loss: 0.15533193649889632
Validation loss: 2.554089124428899

Epoch: 6| Step: 8
Training loss: 0.16404948864159244
Validation loss: 2.5991567820796773

Epoch: 6| Step: 9
Training loss: 0.2213248887988537
Validation loss: 2.588362377196527

Epoch: 6| Step: 10
Training loss: 0.16440375350350253
Validation loss: 2.5645056948001623

Epoch: 6| Step: 11
Training loss: 0.21729993448471507
Validation loss: 2.55600012009142

Epoch: 6| Step: 12
Training loss: 0.14067113967121983
Validation loss: 2.5412780894031504

Epoch: 6| Step: 13
Training loss: 0.09167530755566713
Validation loss: 2.5614443659788906

Epoch: 483| Step: 0
Training loss: 0.2013198900592503
Validation loss: 2.512418217012363

Epoch: 6| Step: 1
Training loss: 0.21595658017891367
Validation loss: 2.51642542966846

Epoch: 6| Step: 2
Training loss: 0.21817130791390235
Validation loss: 2.516967268590102

Epoch: 6| Step: 3
Training loss: 0.3160925829229905
Validation loss: 2.491601506362519

Epoch: 6| Step: 4
Training loss: 0.1589483909280696
Validation loss: 2.5212647480681034

Epoch: 6| Step: 5
Training loss: 0.21675528737431313
Validation loss: 2.5412270340406504

Epoch: 6| Step: 6
Training loss: 0.18889699501481727
Validation loss: 2.545704061915322

Epoch: 6| Step: 7
Training loss: 0.2073189697463642
Validation loss: 2.5659083118102646

Epoch: 6| Step: 8
Training loss: 0.18441227802753762
Validation loss: 2.5509297465675216

Epoch: 6| Step: 9
Training loss: 0.2290871637605094
Validation loss: 2.6114361826905736

Epoch: 6| Step: 10
Training loss: 0.1994949371106571
Validation loss: 2.6039323631627256

Epoch: 6| Step: 11
Training loss: 0.15980678904775655
Validation loss: 2.574421614910673

Epoch: 6| Step: 12
Training loss: 0.29418137408674555
Validation loss: 2.6048830084870804

Epoch: 6| Step: 13
Training loss: 0.11003662844705672
Validation loss: 2.5598848726325456

Epoch: 484| Step: 0
Training loss: 0.15526507013196247
Validation loss: 2.5441162097320698

Epoch: 6| Step: 1
Training loss: 0.21209520956548641
Validation loss: 2.571840663498239

Epoch: 6| Step: 2
Training loss: 0.29261744735353845
Validation loss: 2.562516033083432

Epoch: 6| Step: 3
Training loss: 0.2840692364488791
Validation loss: 2.5680653153929813

Epoch: 6| Step: 4
Training loss: 0.20237084836924898
Validation loss: 2.55578764854973

Epoch: 6| Step: 5
Training loss: 0.32446163914929244
Validation loss: 2.535837469966975

Epoch: 6| Step: 6
Training loss: 0.21500317120708407
Validation loss: 2.526393980916543

Epoch: 6| Step: 7
Training loss: 0.14077065130510577
Validation loss: 2.567712565947335

Epoch: 6| Step: 8
Training loss: 0.21758152327289307
Validation loss: 2.56313956278211

Epoch: 6| Step: 9
Training loss: 0.238508421060956
Validation loss: 2.6178507802353055

Epoch: 6| Step: 10
Training loss: 0.16111810790504125
Validation loss: 2.6064817518198264

Epoch: 6| Step: 11
Training loss: 0.23304074702964392
Validation loss: 2.6120477538422393

Epoch: 6| Step: 12
Training loss: 0.14017208331012565
Validation loss: 2.599970790739982

Epoch: 6| Step: 13
Training loss: 0.10576825531179608
Validation loss: 2.5995290073257484

Epoch: 485| Step: 0
Training loss: 0.3020708256905455
Validation loss: 2.622320615455869

Epoch: 6| Step: 1
Training loss: 0.23529454882162396
Validation loss: 2.641091955131812

Epoch: 6| Step: 2
Training loss: 0.23487922154378943
Validation loss: 2.5688544728956213

Epoch: 6| Step: 3
Training loss: 0.33268009068108756
Validation loss: 2.6025837672989396

Epoch: 6| Step: 4
Training loss: 0.16692701819285186
Validation loss: 2.5429084349407236

Epoch: 6| Step: 5
Training loss: 0.28813159386874193
Validation loss: 2.5503610940410666

Epoch: 6| Step: 6
Training loss: 0.19484234488928154
Validation loss: 2.5324123533928478

Epoch: 6| Step: 7
Training loss: 0.25445544196418834
Validation loss: 2.508364621028161

Epoch: 6| Step: 8
Training loss: 0.22360016030560037
Validation loss: 2.534341473615154

Epoch: 6| Step: 9
Training loss: 0.18918480503266105
Validation loss: 2.498997669891541

Epoch: 6| Step: 10
Training loss: 0.14820440713089555
Validation loss: 2.527768842356886

Epoch: 6| Step: 11
Training loss: 0.11871271991301668
Validation loss: 2.5719377172263123

Epoch: 6| Step: 12
Training loss: 0.176760784145266
Validation loss: 2.599647123103515

Epoch: 6| Step: 13
Training loss: 0.12631879938415405
Validation loss: 2.5519790243028124

Epoch: 486| Step: 0
Training loss: 0.15072664275118053
Validation loss: 2.6228592714003898

Epoch: 6| Step: 1
Training loss: 0.2746703556339282
Validation loss: 2.640148983261761

Epoch: 6| Step: 2
Training loss: 0.20786368162844826
Validation loss: 2.6184861594188393

Epoch: 6| Step: 3
Training loss: 0.2691876391137452
Validation loss: 2.5984426530118454

Epoch: 6| Step: 4
Training loss: 0.17277652383247416
Validation loss: 2.5928639839456524

Epoch: 6| Step: 5
Training loss: 0.2842503882483496
Validation loss: 2.568412963802213

Epoch: 6| Step: 6
Training loss: 0.3062115479677453
Validation loss: 2.583348097214867

Epoch: 6| Step: 7
Training loss: 0.20112607490129028
Validation loss: 2.555679063129432

Epoch: 6| Step: 8
Training loss: 0.27513859085092757
Validation loss: 2.528733994590014

Epoch: 6| Step: 9
Training loss: 0.22928642626063178
Validation loss: 2.5108095056667445

Epoch: 6| Step: 10
Training loss: 0.20957828517228827
Validation loss: 2.5066212771057232

Epoch: 6| Step: 11
Training loss: 0.18842839826361632
Validation loss: 2.4672197604895745

Epoch: 6| Step: 12
Training loss: 0.5277152554248413
Validation loss: 2.491609380619591

Epoch: 6| Step: 13
Training loss: 0.15683279426246768
Validation loss: 2.5316982320586305

Epoch: 487| Step: 0
Training loss: 0.21570129910490354
Validation loss: 2.554136139163438

Epoch: 6| Step: 1
Training loss: 0.22105698364057555
Validation loss: 2.567269384562819

Epoch: 6| Step: 2
Training loss: 0.3580571558402535
Validation loss: 2.5631340917069307

Epoch: 6| Step: 3
Training loss: 0.31404791366334783
Validation loss: 2.5856775358171826

Epoch: 6| Step: 4
Training loss: 0.28994655739463515
Validation loss: 2.5938627967469237

Epoch: 6| Step: 5
Training loss: 0.2694779771872684
Validation loss: 2.543115625118398

Epoch: 6| Step: 6
Training loss: 0.21374638076138597
Validation loss: 2.545795102264806

Epoch: 6| Step: 7
Training loss: 0.18071973819122775
Validation loss: 2.5498684387724406

Epoch: 6| Step: 8
Training loss: 0.24353162722103744
Validation loss: 2.5233647846430287

Epoch: 6| Step: 9
Training loss: 0.34678817985618454
Validation loss: 2.4970871434969997

Epoch: 6| Step: 10
Training loss: 0.284034403470044
Validation loss: 2.5055471927950217

Epoch: 6| Step: 11
Training loss: 0.2804593257330149
Validation loss: 2.529158015004156

Epoch: 6| Step: 12
Training loss: 0.367884360191419
Validation loss: 2.5025898408844145

Epoch: 6| Step: 13
Training loss: 0.26805983293878194
Validation loss: 2.511856704302074

Epoch: 488| Step: 0
Training loss: 0.2990984597704674
Validation loss: 2.49242454438128

Epoch: 6| Step: 1
Training loss: 0.2419204470104422
Validation loss: 2.517122222990359

Epoch: 6| Step: 2
Training loss: 0.14811120434792432
Validation loss: 2.5346244055558347

Epoch: 6| Step: 3
Training loss: 0.23356832123459542
Validation loss: 2.5481911152670933

Epoch: 6| Step: 4
Training loss: 0.2543886004615094
Validation loss: 2.56606843916826

Epoch: 6| Step: 5
Training loss: 0.31428589727966133
Validation loss: 2.5902853315396235

Epoch: 6| Step: 6
Training loss: 0.3338374322137926
Validation loss: 2.569975732317131

Epoch: 6| Step: 7
Training loss: 0.2756021377268103
Validation loss: 2.572218504098248

Epoch: 6| Step: 8
Training loss: 0.29387534693442324
Validation loss: 2.6010256627910744

Epoch: 6| Step: 9
Training loss: 0.2748451105575327
Validation loss: 2.5528028544110546

Epoch: 6| Step: 10
Training loss: 0.28801982573642815
Validation loss: 2.5788940972964425

Epoch: 6| Step: 11
Training loss: 0.2386164262109566
Validation loss: 2.5430628414788243

Epoch: 6| Step: 12
Training loss: 0.23132884640309023
Validation loss: 2.531723029914576

Epoch: 6| Step: 13
Training loss: 0.2860135685988239
Validation loss: 2.5610084584775046

Epoch: 489| Step: 0
Training loss: 0.3603596259974985
Validation loss: 2.557110706457342

Epoch: 6| Step: 1
Training loss: 0.17654812214130075
Validation loss: 2.5936030220091513

Epoch: 6| Step: 2
Training loss: 0.22908693610004496
Validation loss: 2.5823472655434405

Epoch: 6| Step: 3
Training loss: 0.29389384126401585
Validation loss: 2.551868583545737

Epoch: 6| Step: 4
Training loss: 0.23640487149852124
Validation loss: 2.5397139316396853

Epoch: 6| Step: 5
Training loss: 0.23044002483258363
Validation loss: 2.524311713401097

Epoch: 6| Step: 6
Training loss: 0.11221045811718126
Validation loss: 2.551451037199794

Epoch: 6| Step: 7
Training loss: 0.2715188834673233
Validation loss: 2.521002627933689

Epoch: 6| Step: 8
Training loss: 0.17692543217297754
Validation loss: 2.5243392943736267

Epoch: 6| Step: 9
Training loss: 0.17543534577443112
Validation loss: 2.537028858970724

Epoch: 6| Step: 10
Training loss: 0.2112437338859028
Validation loss: 2.5293816208959843

Epoch: 6| Step: 11
Training loss: 0.26349402186725973
Validation loss: 2.497418616279681

Epoch: 6| Step: 12
Training loss: 0.4095094576454954
Validation loss: 2.5077283270935307

Epoch: 6| Step: 13
Training loss: 0.2333117288070388
Validation loss: 2.502982329605435

Epoch: 490| Step: 0
Training loss: 0.252132617977196
Validation loss: 2.53939216234293

Epoch: 6| Step: 1
Training loss: 0.17627960662366565
Validation loss: 2.590293440250504

Epoch: 6| Step: 2
Training loss: 0.3106178346571185
Validation loss: 2.576353154484982

Epoch: 6| Step: 3
Training loss: 0.20319554131071962
Validation loss: 2.563312918803907

Epoch: 6| Step: 4
Training loss: 0.2617630280574389
Validation loss: 2.5503105869189513

Epoch: 6| Step: 5
Training loss: 0.23521000415663576
Validation loss: 2.537634764448481

Epoch: 6| Step: 6
Training loss: 0.13614735409364728
Validation loss: 2.5473354805841604

Epoch: 6| Step: 7
Training loss: 0.2510413001019557
Validation loss: 2.5568185957710146

Epoch: 6| Step: 8
Training loss: 0.15484194511031452
Validation loss: 2.535392871156918

Epoch: 6| Step: 9
Training loss: 0.3482543322744865
Validation loss: 2.543659412111125

Epoch: 6| Step: 10
Training loss: 0.16605973499194251
Validation loss: 2.495276603569215

Epoch: 6| Step: 11
Training loss: 0.32456003174411646
Validation loss: 2.5220989300233505

Epoch: 6| Step: 12
Training loss: 0.385614784544384
Validation loss: 2.483389333528658

Epoch: 6| Step: 13
Training loss: 0.14781932983386328
Validation loss: 2.5126546649186148

Epoch: 491| Step: 0
Training loss: 0.20685307014838852
Validation loss: 2.503204838738193

Epoch: 6| Step: 1
Training loss: 0.2410209540793473
Validation loss: 2.5343376134959805

Epoch: 6| Step: 2
Training loss: 0.1506520636965396
Validation loss: 2.5782357647949152

Epoch: 6| Step: 3
Training loss: 0.2913395403883475
Validation loss: 2.612358212900665

Epoch: 6| Step: 4
Training loss: 0.24536352204058404
Validation loss: 2.599409398931889

Epoch: 6| Step: 5
Training loss: 0.2878861850101116
Validation loss: 2.6128104353065846

Epoch: 6| Step: 6
Training loss: 0.22826363453143111
Validation loss: 2.6388541682588866

Epoch: 6| Step: 7
Training loss: 0.2219630207835268
Validation loss: 2.605913247093507

Epoch: 6| Step: 8
Training loss: 0.2102507166215248
Validation loss: 2.6221322931085576

Epoch: 6| Step: 9
Training loss: 0.21365176634514768
Validation loss: 2.607279742366957

Epoch: 6| Step: 10
Training loss: 0.2635105345862308
Validation loss: 2.6140381315250645

Epoch: 6| Step: 11
Training loss: 0.15766483139864523
Validation loss: 2.6120090817636235

Epoch: 6| Step: 12
Training loss: 0.23348031942004066
Validation loss: 2.588927196303361

Epoch: 6| Step: 13
Training loss: 0.1669818083008219
Validation loss: 2.5914057884389146

Epoch: 492| Step: 0
Training loss: 0.15075555098136603
Validation loss: 2.5907788032444143

Epoch: 6| Step: 1
Training loss: 0.17501024062983733
Validation loss: 2.5948154036992603

Epoch: 6| Step: 2
Training loss: 0.1651629485194737
Validation loss: 2.609934734447372

Epoch: 6| Step: 3
Training loss: 0.2696492862701873
Validation loss: 2.587618988076999

Epoch: 6| Step: 4
Training loss: 0.22553276492235472
Validation loss: 2.5893545692721376

Epoch: 6| Step: 5
Training loss: 0.1641896924209008
Validation loss: 2.6221269940066314

Epoch: 6| Step: 6
Training loss: 0.16137687232957626
Validation loss: 2.6095445771993675

Epoch: 6| Step: 7
Training loss: 0.18249613783943266
Validation loss: 2.5673908647334125

Epoch: 6| Step: 8
Training loss: 0.21844166073636195
Validation loss: 2.6345225230324565

Epoch: 6| Step: 9
Training loss: 0.2921341515863541
Validation loss: 2.5705407498198203

Epoch: 6| Step: 10
Training loss: 0.20930776797686793
Validation loss: 2.5759621137449358

Epoch: 6| Step: 11
Training loss: 0.22046568428411523
Validation loss: 2.603235275244574

Epoch: 6| Step: 12
Training loss: 0.18064857622736918
Validation loss: 2.5951060399856933

Epoch: 6| Step: 13
Training loss: 0.24359645470077435
Validation loss: 2.560508844323102

Epoch: 493| Step: 0
Training loss: 0.24628366983244035
Validation loss: 2.5389284462954653

Epoch: 6| Step: 1
Training loss: 0.19391085269577216
Validation loss: 2.5305176666436884

Epoch: 6| Step: 2
Training loss: 0.1696526927445075
Validation loss: 2.5573840010072595

Epoch: 6| Step: 3
Training loss: 0.15519326017354002
Validation loss: 2.5824697826209824

Epoch: 6| Step: 4
Training loss: 0.18398473581655317
Validation loss: 2.58852579412329

Epoch: 6| Step: 5
Training loss: 0.20929245211152436
Validation loss: 2.540105976656656

Epoch: 6| Step: 6
Training loss: 0.21911991721926405
Validation loss: 2.564291250192065

Epoch: 6| Step: 7
Training loss: 0.26432318601297017
Validation loss: 2.5702272750061073

Epoch: 6| Step: 8
Training loss: 0.1428579628177936
Validation loss: 2.5414244927943517

Epoch: 6| Step: 9
Training loss: 0.24053384367089714
Validation loss: 2.542874559767881

Epoch: 6| Step: 10
Training loss: 0.22405572740010282
Validation loss: 2.576142913900125

Epoch: 6| Step: 11
Training loss: 0.19920650145331983
Validation loss: 2.57012578911522

Epoch: 6| Step: 12
Training loss: 0.1328694067380686
Validation loss: 2.5576879948889304

Epoch: 6| Step: 13
Training loss: 0.0948792485493974
Validation loss: 2.5476905085342096

Epoch: 494| Step: 0
Training loss: 0.2477889033624743
Validation loss: 2.6095637891232246

Epoch: 6| Step: 1
Training loss: 0.1546964120224238
Validation loss: 2.5504161003812804

Epoch: 6| Step: 2
Training loss: 0.3055022911525914
Validation loss: 2.5964876195903113

Epoch: 6| Step: 3
Training loss: 0.16260393949631685
Validation loss: 2.5739393177667105

Epoch: 6| Step: 4
Training loss: 0.12604995186690185
Validation loss: 2.584783948306253

Epoch: 6| Step: 5
Training loss: 0.18408296215520173
Validation loss: 2.5786171461744436

Epoch: 6| Step: 6
Training loss: 0.1725051393382561
Validation loss: 2.5913372038176887

Epoch: 6| Step: 7
Training loss: 0.1684072116768427
Validation loss: 2.6114880992521354

Epoch: 6| Step: 8
Training loss: 0.09086635919461848
Validation loss: 2.611547324201094

Epoch: 6| Step: 9
Training loss: 0.19163103917093088
Validation loss: 2.6165148851963314

Epoch: 6| Step: 10
Training loss: 0.25011658930137265
Validation loss: 2.579160134591514

Epoch: 6| Step: 11
Training loss: 0.12356260997302304
Validation loss: 2.589305542553161

Epoch: 6| Step: 12
Training loss: 0.13156584163463186
Validation loss: 2.6091243296083704

Epoch: 6| Step: 13
Training loss: 0.2148635334963185
Validation loss: 2.6478339261996897

Epoch: 495| Step: 0
Training loss: 0.2675017366174674
Validation loss: 2.609694651609891

Epoch: 6| Step: 1
Training loss: 0.18382881213058536
Validation loss: 2.6106452485581815

Epoch: 6| Step: 2
Training loss: 0.12817948101838741
Validation loss: 2.5975854089739627

Epoch: 6| Step: 3
Training loss: 0.11466587184287579
Validation loss: 2.5902597730493744

Epoch: 6| Step: 4
Training loss: 0.17211250671155645
Validation loss: 2.599508308997814

Epoch: 6| Step: 5
Training loss: 0.15899251687386562
Validation loss: 2.6078629991358917

Epoch: 6| Step: 6
Training loss: 0.1869190474496187
Validation loss: 2.5996739171396395

Epoch: 6| Step: 7
Training loss: 0.17817218013470676
Validation loss: 2.6087446664176186

Epoch: 6| Step: 8
Training loss: 0.19104302254684113
Validation loss: 2.572703058001894

Epoch: 6| Step: 9
Training loss: 0.1965918980494394
Validation loss: 2.5900449842752105

Epoch: 6| Step: 10
Training loss: 0.24415138220929952
Validation loss: 2.571316348449236

Epoch: 6| Step: 11
Training loss: 0.193627220136155
Validation loss: 2.67519949599529

Epoch: 6| Step: 12
Training loss: 0.17479471359355608
Validation loss: 2.642768145019407

Epoch: 6| Step: 13
Training loss: 0.22842893830991964
Validation loss: 2.6300574266794152

Epoch: 496| Step: 0
Training loss: 0.25960280399461316
Validation loss: 2.630341719676169

Epoch: 6| Step: 1
Training loss: 0.19993701181355125
Validation loss: 2.6328487175269157

Epoch: 6| Step: 2
Training loss: 0.1570857525180929
Validation loss: 2.5836446077040893

Epoch: 6| Step: 3
Training loss: 0.1746555310035058
Validation loss: 2.640181918153418

Epoch: 6| Step: 4
Training loss: 0.1706023785333638
Validation loss: 2.5895704062889795

Epoch: 6| Step: 5
Training loss: 0.293173387901413
Validation loss: 2.586317429470083

Epoch: 6| Step: 6
Training loss: 0.2617633553825922
Validation loss: 2.5883969634405846

Epoch: 6| Step: 7
Training loss: 0.16493837682404927
Validation loss: 2.6052045165897395

Epoch: 6| Step: 8
Training loss: 0.0959105870461677
Validation loss: 2.5659208756660803

Epoch: 6| Step: 9
Training loss: 0.15794334746941935
Validation loss: 2.546295963841285

Epoch: 6| Step: 10
Training loss: 0.15207454542240717
Validation loss: 2.57483522816069

Epoch: 6| Step: 11
Training loss: 0.20302519730630098
Validation loss: 2.549578821553493

Epoch: 6| Step: 12
Training loss: 0.18269682998793696
Validation loss: 2.555967380306741

Epoch: 6| Step: 13
Training loss: 0.22552215202832868
Validation loss: 2.56486853568828

Epoch: 497| Step: 0
Training loss: 0.18643720740686334
Validation loss: 2.558155235217936

Epoch: 6| Step: 1
Training loss: 0.16577650689001225
Validation loss: 2.5559471876007516

Epoch: 6| Step: 2
Training loss: 0.1776464894749635
Validation loss: 2.512235858949992

Epoch: 6| Step: 3
Training loss: 0.25419878613394503
Validation loss: 2.58859459534928

Epoch: 6| Step: 4
Training loss: 0.14745726170284748
Validation loss: 2.613567387458113

Epoch: 6| Step: 5
Training loss: 0.23816806418829953
Validation loss: 2.606944285670085

Epoch: 6| Step: 6
Training loss: 0.09631243222906957
Validation loss: 2.594051062414086

Epoch: 6| Step: 7
Training loss: 0.22319116251249674
Validation loss: 2.602926250412746

Epoch: 6| Step: 8
Training loss: 0.20000386271620904
Validation loss: 2.6237008619992963

Epoch: 6| Step: 9
Training loss: 0.2230270543953869
Validation loss: 2.6095207752803944

Epoch: 6| Step: 10
Training loss: 0.2623695424017972
Validation loss: 2.5857737222004022

Epoch: 6| Step: 11
Training loss: 0.16865153486436674
Validation loss: 2.5940718991596907

Epoch: 6| Step: 12
Training loss: 0.1892543812097239
Validation loss: 2.576017148145548

Epoch: 6| Step: 13
Training loss: 0.25474509541635365
Validation loss: 2.5554214722209574

Epoch: 498| Step: 0
Training loss: 0.212484400891916
Validation loss: 2.5882818643351997

Epoch: 6| Step: 1
Training loss: 0.25452923274543443
Validation loss: 2.55515525388877

Epoch: 6| Step: 2
Training loss: 0.21511729772234853
Validation loss: 2.551796477425616

Epoch: 6| Step: 3
Training loss: 0.15873952282852002
Validation loss: 2.5503735103267924

Epoch: 6| Step: 4
Training loss: 0.17136358990793954
Validation loss: 2.574352932822152

Epoch: 6| Step: 5
Training loss: 0.15613989526919217
Validation loss: 2.6154553944161965

Epoch: 6| Step: 6
Training loss: 0.2206276283431796
Validation loss: 2.569313787611795

Epoch: 6| Step: 7
Training loss: 0.20335732525302846
Validation loss: 2.5817344459816467

Epoch: 6| Step: 8
Training loss: 0.1561998644503092
Validation loss: 2.5704042435960694

Epoch: 6| Step: 9
Training loss: 0.1704221136494203
Validation loss: 2.6052043827595037

Epoch: 6| Step: 10
Training loss: 0.29306337735709215
Validation loss: 2.5677767142555035

Epoch: 6| Step: 11
Training loss: 0.13843031112183382
Validation loss: 2.5733250099688085

Epoch: 6| Step: 12
Training loss: 0.250535376808006
Validation loss: 2.5306191949074193

Epoch: 6| Step: 13
Training loss: 0.11768722082860596
Validation loss: 2.526708509854036

Epoch: 499| Step: 0
Training loss: 0.13810266611942607
Validation loss: 2.556663715945744

Epoch: 6| Step: 1
Training loss: 0.25737575181477934
Validation loss: 2.5620892123175576

Epoch: 6| Step: 2
Training loss: 0.18005929711938226
Validation loss: 2.6105511246026474

Epoch: 6| Step: 3
Training loss: 0.22554289006623113
Validation loss: 2.579330433497485

Epoch: 6| Step: 4
Training loss: 0.15342566642656896
Validation loss: 2.611702819744028

Epoch: 6| Step: 5
Training loss: 0.19622361339867003
Validation loss: 2.5621197676264424

Epoch: 6| Step: 6
Training loss: 0.13470501158578704
Validation loss: 2.5809058889263903

Epoch: 6| Step: 7
Training loss: 0.1645078291711157
Validation loss: 2.602269719622858

Epoch: 6| Step: 8
Training loss: 0.2137750313836785
Validation loss: 2.6080295138772387

Epoch: 6| Step: 9
Training loss: 0.23680835198932368
Validation loss: 2.595755676222998

Epoch: 6| Step: 10
Training loss: 0.19852583188265877
Validation loss: 2.6074079104452803

Epoch: 6| Step: 11
Training loss: 0.20616275430375794
Validation loss: 2.6166717133696418

Epoch: 6| Step: 12
Training loss: 0.19064535008916955
Validation loss: 2.618292079639267

Epoch: 6| Step: 13
Training loss: 0.2240750799544742
Validation loss: 2.5888038133266607

Epoch: 500| Step: 0
Training loss: 0.3166571670077734
Validation loss: 2.597349825474669

Epoch: 6| Step: 1
Training loss: 0.2570654854975576
Validation loss: 2.587652906604405

Epoch: 6| Step: 2
Training loss: 0.31233895443645504
Validation loss: 2.598341951086067

Epoch: 6| Step: 3
Training loss: 0.16485594008331608
Validation loss: 2.557324349732718

Epoch: 6| Step: 4
Training loss: 0.1251557542074339
Validation loss: 2.5977046947540234

Epoch: 6| Step: 5
Training loss: 0.18728154092120344
Validation loss: 2.5795196827831925

Epoch: 6| Step: 6
Training loss: 0.2067657874057789
Validation loss: 2.524468357194692

Epoch: 6| Step: 7
Training loss: 0.16450331708026147
Validation loss: 2.5495673425644414

Epoch: 6| Step: 8
Training loss: 0.16575396617974356
Validation loss: 2.574807035115611

Epoch: 6| Step: 9
Training loss: 0.21118522155900926
Validation loss: 2.5655545633132926

Epoch: 6| Step: 10
Training loss: 0.2554783349761785
Validation loss: 2.565288688019868

Epoch: 6| Step: 11
Training loss: 0.16841653530603967
Validation loss: 2.601803078035308

Epoch: 6| Step: 12
Training loss: 0.13259781989586036
Validation loss: 2.647842745545732

Epoch: 6| Step: 13
Training loss: 0.17831360051202902
Validation loss: 2.6181495755667017

Epoch: 501| Step: 0
Training loss: 0.2014467712964964
Validation loss: 2.6518033994258294

Epoch: 6| Step: 1
Training loss: 0.17574211320708044
Validation loss: 2.645559823553902

Epoch: 6| Step: 2
Training loss: 0.2587493002232474
Validation loss: 2.5966717873020393

Epoch: 6| Step: 3
Training loss: 0.1711464091047685
Validation loss: 2.5967568424999032

Epoch: 6| Step: 4
Training loss: 0.15515806602344911
Validation loss: 2.6154217403901847

Epoch: 6| Step: 5
Training loss: 0.27347591675234095
Validation loss: 2.5933332863373844

Epoch: 6| Step: 6
Training loss: 0.22418114017774327
Validation loss: 2.5894126505450266

Epoch: 6| Step: 7
Training loss: 0.16372244652224607
Validation loss: 2.5790972842976188

Epoch: 6| Step: 8
Training loss: 0.23780601825979028
Validation loss: 2.6130454667065117

Epoch: 6| Step: 9
Training loss: 0.1291254087923564
Validation loss: 2.5659460783755503

Epoch: 6| Step: 10
Training loss: 0.20867035348581017
Validation loss: 2.589047614723852

Epoch: 6| Step: 11
Training loss: 0.16853433576758364
Validation loss: 2.6050083977307636

Epoch: 6| Step: 12
Training loss: 0.11597443404899387
Validation loss: 2.5918710779615246

Epoch: 6| Step: 13
Training loss: 0.19303126384333022
Validation loss: 2.5895649677905377

Epoch: 502| Step: 0
Training loss: 0.22252742487144742
Validation loss: 2.6120128771528526

Epoch: 6| Step: 1
Training loss: 0.17017633196127493
Validation loss: 2.6011401694081253

Epoch: 6| Step: 2
Training loss: 0.21725431930662126
Validation loss: 2.584985899781751

Epoch: 6| Step: 3
Training loss: 0.24956455156594579
Validation loss: 2.5782895082632438

Epoch: 6| Step: 4
Training loss: 0.20897983831312222
Validation loss: 2.56208759533851

Epoch: 6| Step: 5
Training loss: 0.19372573977526186
Validation loss: 2.545120946316371

Epoch: 6| Step: 6
Training loss: 0.154058417020475
Validation loss: 2.536655483470488

Epoch: 6| Step: 7
Training loss: 0.1733961094620276
Validation loss: 2.553445917304146

Epoch: 6| Step: 8
Training loss: 0.1293425545573837
Validation loss: 2.5634256567366176

Epoch: 6| Step: 9
Training loss: 0.16960894061419063
Validation loss: 2.5923993126954734

Epoch: 6| Step: 10
Training loss: 0.27568180841725226
Validation loss: 2.576266100687195

Epoch: 6| Step: 11
Training loss: 0.16589004030077012
Validation loss: 2.62244300365239

Epoch: 6| Step: 12
Training loss: 0.17457942727160666
Validation loss: 2.5643713581102463

Epoch: 6| Step: 13
Training loss: 0.2857617911903905
Validation loss: 2.617415644583392

Epoch: 503| Step: 0
Training loss: 0.17001034636778758
Validation loss: 2.6294350404247098

Epoch: 6| Step: 1
Training loss: 0.16640791825008983
Validation loss: 2.6139976916951326

Epoch: 6| Step: 2
Training loss: 0.1942787853144148
Validation loss: 2.5890884912904575

Epoch: 6| Step: 3
Training loss: 0.14285340580990985
Validation loss: 2.5988676355497846

Epoch: 6| Step: 4
Training loss: 0.1866349590905748
Validation loss: 2.6112809805231803

Epoch: 6| Step: 5
Training loss: 0.24761379913019319
Validation loss: 2.5841241073475465

Epoch: 6| Step: 6
Training loss: 0.15193276109527343
Validation loss: 2.5591661439372992

Epoch: 6| Step: 7
Training loss: 0.33714178378200427
Validation loss: 2.563561569531088

Epoch: 6| Step: 8
Training loss: 0.27666776507276397
Validation loss: 2.5541117004423133

Epoch: 6| Step: 9
Training loss: 0.1577253308662624
Validation loss: 2.5344969583939534

Epoch: 6| Step: 10
Training loss: 0.1681870716139839
Validation loss: 2.5396744478294444

Epoch: 6| Step: 11
Training loss: 0.27222770361155524
Validation loss: 2.5843565257902426

Epoch: 6| Step: 12
Training loss: 0.219828247277431
Validation loss: 2.586570172363261

Epoch: 6| Step: 13
Training loss: 0.15871497346035707
Validation loss: 2.5934318785251143

Epoch: 504| Step: 0
Training loss: 0.20494491246956967
Validation loss: 2.590598386747593

Epoch: 6| Step: 1
Training loss: 0.26316548923934074
Validation loss: 2.6267534524024794

Epoch: 6| Step: 2
Training loss: 0.22573555282609745
Validation loss: 2.591386024414248

Epoch: 6| Step: 3
Training loss: 0.192245938170127
Validation loss: 2.5986940962801865

Epoch: 6| Step: 4
Training loss: 0.16812413812792212
Validation loss: 2.613283780990354

Epoch: 6| Step: 5
Training loss: 0.20385338328124408
Validation loss: 2.5705687124051986

Epoch: 6| Step: 6
Training loss: 0.17564208031641831
Validation loss: 2.555035780661014

Epoch: 6| Step: 7
Training loss: 0.21735416987964626
Validation loss: 2.5550853335061374

Epoch: 6| Step: 8
Training loss: 0.20260411195500933
Validation loss: 2.5559572238873547

Epoch: 6| Step: 9
Training loss: 0.20255879202146926
Validation loss: 2.5660499386217825

Epoch: 6| Step: 10
Training loss: 0.31764975252650735
Validation loss: 2.563031365351321

Epoch: 6| Step: 11
Training loss: 0.1780168782399931
Validation loss: 2.5111004223282825

Epoch: 6| Step: 12
Training loss: 0.19731989199083852
Validation loss: 2.5727646545193488

Epoch: 6| Step: 13
Training loss: 0.19708339848090528
Validation loss: 2.5914380913828627

Epoch: 505| Step: 0
Training loss: 0.21468024534492197
Validation loss: 2.602626912043148

Epoch: 6| Step: 1
Training loss: 0.3075152758161253
Validation loss: 2.6128965443174152

Epoch: 6| Step: 2
Training loss: 0.20054109066451756
Validation loss: 2.6379090067099007

Epoch: 6| Step: 3
Training loss: 0.2686352418249132
Validation loss: 2.6261263641377637

Epoch: 6| Step: 4
Training loss: 0.11721767593330028
Validation loss: 2.6138102408987685

Epoch: 6| Step: 5
Training loss: 0.2955179065258664
Validation loss: 2.5620189258191837

Epoch: 6| Step: 6
Training loss: 0.22345160759891503
Validation loss: 2.54445444135751

Epoch: 6| Step: 7
Training loss: 0.15638279040574146
Validation loss: 2.532681018990942

Epoch: 6| Step: 8
Training loss: 0.1761987707918149
Validation loss: 2.5524638629132714

Epoch: 6| Step: 9
Training loss: 0.20012627318332885
Validation loss: 2.520348542867775

Epoch: 6| Step: 10
Training loss: 0.16012222812570245
Validation loss: 2.5552817193569073

Epoch: 6| Step: 11
Training loss: 0.17346169930108538
Validation loss: 2.568691672823195

Epoch: 6| Step: 12
Training loss: 0.20335334084491008
Validation loss: 2.5303177751961843

Epoch: 6| Step: 13
Training loss: 0.2689803893597003
Validation loss: 2.5816883101863843

Epoch: 506| Step: 0
Training loss: 0.2507612291704609
Validation loss: 2.591611359784973

Epoch: 6| Step: 1
Training loss: 0.27303705866335753
Validation loss: 2.6135466718104468

Epoch: 6| Step: 2
Training loss: 0.18968670004309912
Validation loss: 2.6434065907097244

Epoch: 6| Step: 3
Training loss: 0.20581138855025571
Validation loss: 2.618661657377245

Epoch: 6| Step: 4
Training loss: 0.15372072767903697
Validation loss: 2.5706930982427765

Epoch: 6| Step: 5
Training loss: 0.27419060130612083
Validation loss: 2.4989770806448472

Epoch: 6| Step: 6
Training loss: 0.19774565502895972
Validation loss: 2.513767428687495

Epoch: 6| Step: 7
Training loss: 0.1421127431972616
Validation loss: 2.5231862861438947

Epoch: 6| Step: 8
Training loss: 0.14002890875914398
Validation loss: 2.5349571854830746

Epoch: 6| Step: 9
Training loss: 0.22541669797250763
Validation loss: 2.4863282281095036

Epoch: 6| Step: 10
Training loss: 0.2318103824404598
Validation loss: 2.5266449681772793

Epoch: 6| Step: 11
Training loss: 0.16541646659111908
Validation loss: 2.510530927635739

Epoch: 6| Step: 12
Training loss: 0.14807315708878416
Validation loss: 2.5281930256572873

Epoch: 6| Step: 13
Training loss: 0.30223410094199
Validation loss: 2.5603589493264316

Epoch: 507| Step: 0
Training loss: 0.17475861736124032
Validation loss: 2.5439531164423776

Epoch: 6| Step: 1
Training loss: 0.15964532394117173
Validation loss: 2.5855602552710306

Epoch: 6| Step: 2
Training loss: 0.1579701273789242
Validation loss: 2.582873843079572

Epoch: 6| Step: 3
Training loss: 0.18004042754232058
Validation loss: 2.5548088519315164

Epoch: 6| Step: 4
Training loss: 0.17542773833261194
Validation loss: 2.5619006432672293

Epoch: 6| Step: 5
Training loss: 0.2564171687747212
Validation loss: 2.53674504867877

Epoch: 6| Step: 6
Training loss: 0.2528334032996158
Validation loss: 2.5300853191336152

Epoch: 6| Step: 7
Training loss: 0.14429677811450525
Validation loss: 2.5321141212128113

Epoch: 6| Step: 8
Training loss: 0.24280558440033176
Validation loss: 2.522920981904831

Epoch: 6| Step: 9
Training loss: 0.17793956900835123
Validation loss: 2.5244311773187667

Epoch: 6| Step: 10
Training loss: 0.2522603018049302
Validation loss: 2.551724773145197

Epoch: 6| Step: 11
Training loss: 0.150648564675777
Validation loss: 2.5088187740348773

Epoch: 6| Step: 12
Training loss: 0.18327316742788552
Validation loss: 2.534077327147701

Epoch: 6| Step: 13
Training loss: 0.11001994089747505
Validation loss: 2.581903742520821

Epoch: 508| Step: 0
Training loss: 0.23114420623057624
Validation loss: 2.530209923037421

Epoch: 6| Step: 1
Training loss: 0.2044842795926123
Validation loss: 2.5612743001427

Epoch: 6| Step: 2
Training loss: 0.2466341624532497
Validation loss: 2.5635350375755146

Epoch: 6| Step: 3
Training loss: 0.11621463994130796
Validation loss: 2.5329036610434295

Epoch: 6| Step: 4
Training loss: 0.2208835741838893
Validation loss: 2.548172116703782

Epoch: 6| Step: 5
Training loss: 0.15738550291320563
Validation loss: 2.5374511674447415

Epoch: 6| Step: 6
Training loss: 0.16968498488928002
Validation loss: 2.5684058370590486

Epoch: 6| Step: 7
Training loss: 0.16663558988122398
Validation loss: 2.5688068343385355

Epoch: 6| Step: 8
Training loss: 0.2708111105873778
Validation loss: 2.5604662984952835

Epoch: 6| Step: 9
Training loss: 0.14769186165689552
Validation loss: 2.586909695144323

Epoch: 6| Step: 10
Training loss: 0.2057988083140169
Validation loss: 2.574590331846911

Epoch: 6| Step: 11
Training loss: 0.17560477405029257
Validation loss: 2.5714197233535834

Epoch: 6| Step: 12
Training loss: 0.24280817730073984
Validation loss: 2.5541970823812568

Epoch: 6| Step: 13
Training loss: 0.14317045236563686
Validation loss: 2.5613551079577492

Epoch: 509| Step: 0
Training loss: 0.10895707974736944
Validation loss: 2.600610187906296

Epoch: 6| Step: 1
Training loss: 0.25692915584569403
Validation loss: 2.5396408636478323

Epoch: 6| Step: 2
Training loss: 0.18504919264776265
Validation loss: 2.5295964426494195

Epoch: 6| Step: 3
Training loss: 0.19477598888795922
Validation loss: 2.565706815126179

Epoch: 6| Step: 4
Training loss: 0.17515696825736038
Validation loss: 2.5690548255967713

Epoch: 6| Step: 5
Training loss: 0.16244548974563894
Validation loss: 2.568753286687488

Epoch: 6| Step: 6
Training loss: 0.14931990580078522
Validation loss: 2.571872923110089

Epoch: 6| Step: 7
Training loss: 0.20472102181925808
Validation loss: 2.5616427932922647

Epoch: 6| Step: 8
Training loss: 0.15371197284509755
Validation loss: 2.5761375401012585

Epoch: 6| Step: 9
Training loss: 0.30503685802787184
Validation loss: 2.589443025508701

Epoch: 6| Step: 10
Training loss: 0.1643604116892167
Validation loss: 2.6215730487496933

Epoch: 6| Step: 11
Training loss: 0.1830650793670719
Validation loss: 2.6009922636264413

Epoch: 6| Step: 12
Training loss: 0.2057709752025336
Validation loss: 2.5993156147247882

Epoch: 6| Step: 13
Training loss: 0.32101912594276666
Validation loss: 2.595197386200532

Epoch: 510| Step: 0
Training loss: 0.16462580162105167
Validation loss: 2.592117488679895

Epoch: 6| Step: 1
Training loss: 0.16081869545680258
Validation loss: 2.5985533725771104

Epoch: 6| Step: 2
Training loss: 0.2663312107130107
Validation loss: 2.6281443054879996

Epoch: 6| Step: 3
Training loss: 0.2810407761026406
Validation loss: 2.5797451543100345

Epoch: 6| Step: 4
Training loss: 0.1421684362396214
Validation loss: 2.574237922817274

Epoch: 6| Step: 5
Training loss: 0.13165046926755972
Validation loss: 2.5293902562797275

Epoch: 6| Step: 6
Training loss: 0.14754595421533354
Validation loss: 2.5852021531025904

Epoch: 6| Step: 7
Training loss: 0.11495963578389683
Validation loss: 2.558787495093275

Epoch: 6| Step: 8
Training loss: 0.19221845858196307
Validation loss: 2.5316756060435694

Epoch: 6| Step: 9
Training loss: 0.1930112402001087
Validation loss: 2.5536253565927285

Epoch: 6| Step: 10
Training loss: 0.24931030206196772
Validation loss: 2.5187097284689517

Epoch: 6| Step: 11
Training loss: 0.11651476244295768
Validation loss: 2.5263080895785452

Epoch: 6| Step: 12
Training loss: 0.14275224713671258
Validation loss: 2.5108874364687823

Epoch: 6| Step: 13
Training loss: 0.24201294545944954
Validation loss: 2.5727345494866554

Epoch: 511| Step: 0
Training loss: 0.17138818593497596
Validation loss: 2.5622069753787557

Epoch: 6| Step: 1
Training loss: 0.164733004770819
Validation loss: 2.5215674293931083

Epoch: 6| Step: 2
Training loss: 0.17545400464136962
Validation loss: 2.5288655494715138

Epoch: 6| Step: 3
Training loss: 0.14750111266298405
Validation loss: 2.5399077139042663

Epoch: 6| Step: 4
Training loss: 0.1759280174860819
Validation loss: 2.569237318691542

Epoch: 6| Step: 5
Training loss: 0.22792791122358924
Validation loss: 2.538810728351779

Epoch: 6| Step: 6
Training loss: 0.2261784850688075
Validation loss: 2.583397690993168

Epoch: 6| Step: 7
Training loss: 0.23018825563560003
Validation loss: 2.558163354578005

Epoch: 6| Step: 8
Training loss: 0.14434429268405644
Validation loss: 2.587556250112725

Epoch: 6| Step: 9
Training loss: 0.09489507041611218
Validation loss: 2.5977232767802936

Epoch: 6| Step: 10
Training loss: 0.09818893111537892
Validation loss: 2.5992669978046528

Epoch: 6| Step: 11
Training loss: 0.2123974152793424
Validation loss: 2.583932857300449

Epoch: 6| Step: 12
Training loss: 0.2162430106257304
Validation loss: 2.5561287040905083

Epoch: 6| Step: 13
Training loss: 0.13959306672900212
Validation loss: 2.5532776807650355

Epoch: 512| Step: 0
Training loss: 0.1212994689285677
Validation loss: 2.5740754970889146

Epoch: 6| Step: 1
Training loss: 0.1722756506149867
Validation loss: 2.5662743359129365

Epoch: 6| Step: 2
Training loss: 0.24838188406576647
Validation loss: 2.561866434821065

Epoch: 6| Step: 3
Training loss: 0.1315792410386096
Validation loss: 2.532642277843618

Epoch: 6| Step: 4
Training loss: 0.13577631651691904
Validation loss: 2.50964599007584

Epoch: 6| Step: 5
Training loss: 0.18749445668609369
Validation loss: 2.5174707235013685

Epoch: 6| Step: 6
Training loss: 0.18135324940968964
Validation loss: 2.5285945876284712

Epoch: 6| Step: 7
Training loss: 0.18598188303319788
Validation loss: 2.538552271058902

Epoch: 6| Step: 8
Training loss: 0.2499721630811018
Validation loss: 2.5523305035341766

Epoch: 6| Step: 9
Training loss: 0.1733442923821202
Validation loss: 2.5586727843719523

Epoch: 6| Step: 10
Training loss: 0.30025599802586733
Validation loss: 2.5782725754628646

Epoch: 6| Step: 11
Training loss: 0.16612456057478206
Validation loss: 2.5499105104414688

Epoch: 6| Step: 12
Training loss: 0.10652307417289678
Validation loss: 2.560350306247959

Epoch: 6| Step: 13
Training loss: 0.2633349915620245
Validation loss: 2.588662178121425

Epoch: 513| Step: 0
Training loss: 0.16400755802444256
Validation loss: 2.5893384860403805

Epoch: 6| Step: 1
Training loss: 0.17953251291267408
Validation loss: 2.586176738101126

Epoch: 6| Step: 2
Training loss: 0.21237119248936054
Validation loss: 2.5553519002255527

Epoch: 6| Step: 3
Training loss: 0.13992182108091575
Validation loss: 2.5523290345529834

Epoch: 6| Step: 4
Training loss: 0.12110139453507889
Validation loss: 2.566929155569335

Epoch: 6| Step: 5
Training loss: 0.2176480295692372
Validation loss: 2.5657627764131017

Epoch: 6| Step: 6
Training loss: 0.26910158823771524
Validation loss: 2.5260137626004058

Epoch: 6| Step: 7
Training loss: 0.18898309821540832
Validation loss: 2.547122414093925

Epoch: 6| Step: 8
Training loss: 0.1605191480635597
Validation loss: 2.521948220468027

Epoch: 6| Step: 9
Training loss: 0.24447338315339565
Validation loss: 2.5143061901715584

Epoch: 6| Step: 10
Training loss: 0.19799526226752587
Validation loss: 2.4903387741991843

Epoch: 6| Step: 11
Training loss: 0.1384631318545511
Validation loss: 2.5449077125518964

Epoch: 6| Step: 12
Training loss: 0.28324258463648505
Validation loss: 2.5110285258466525

Epoch: 6| Step: 13
Training loss: 0.19330446831612477
Validation loss: 2.544236414380325

Epoch: 514| Step: 0
Training loss: 0.20195051077178147
Validation loss: 2.5316444200074333

Epoch: 6| Step: 1
Training loss: 0.14270646707214799
Validation loss: 2.5537026207734996

Epoch: 6| Step: 2
Training loss: 0.266501914604352
Validation loss: 2.5940307354560135

Epoch: 6| Step: 3
Training loss: 0.178186439074138
Validation loss: 2.5653704521533975

Epoch: 6| Step: 4
Training loss: 0.19652856856858383
Validation loss: 2.5386909774686846

Epoch: 6| Step: 5
Training loss: 0.18211645947999336
Validation loss: 2.55406317963352

Epoch: 6| Step: 6
Training loss: 0.24465835607218842
Validation loss: 2.589892954604781

Epoch: 6| Step: 7
Training loss: 0.15580338186958295
Validation loss: 2.5263057403675147

Epoch: 6| Step: 8
Training loss: 0.19173902660861106
Validation loss: 2.560680571857004

Epoch: 6| Step: 9
Training loss: 0.2355516461700493
Validation loss: 2.506294886902325

Epoch: 6| Step: 10
Training loss: 0.13747771635252556
Validation loss: 2.5196349420026882

Epoch: 6| Step: 11
Training loss: 0.175833143415695
Validation loss: 2.5404545241886054

Epoch: 6| Step: 12
Training loss: 0.17549002152451984
Validation loss: 2.5471676662663745

Epoch: 6| Step: 13
Training loss: 0.2830589716803651
Validation loss: 2.5481652884945762

Epoch: 515| Step: 0
Training loss: 0.12425680807092034
Validation loss: 2.5547237362937985

Epoch: 6| Step: 1
Training loss: 0.19194289318756885
Validation loss: 2.583062383658095

Epoch: 6| Step: 2
Training loss: 0.16712444488929654
Validation loss: 2.609007336609561

Epoch: 6| Step: 3
Training loss: 0.15087858527189513
Validation loss: 2.5823490832789613

Epoch: 6| Step: 4
Training loss: 0.1390565720912734
Validation loss: 2.564478404863462

Epoch: 6| Step: 5
Training loss: 0.23866911104540428
Validation loss: 2.5630550738762174

Epoch: 6| Step: 6
Training loss: 0.2302025210968736
Validation loss: 2.5973644511210137

Epoch: 6| Step: 7
Training loss: 0.23007881993446255
Validation loss: 2.56193147000459

Epoch: 6| Step: 8
Training loss: 0.15056360502181954
Validation loss: 2.5676098570264716

Epoch: 6| Step: 9
Training loss: 0.14943595177372146
Validation loss: 2.5636747535233075

Epoch: 6| Step: 10
Training loss: 0.15499701576859493
Validation loss: 2.5414590984484304

Epoch: 6| Step: 11
Training loss: 0.15916381944070374
Validation loss: 2.5734628565354734

Epoch: 6| Step: 12
Training loss: 0.17598656214205327
Validation loss: 2.5492898934739348

Epoch: 6| Step: 13
Training loss: 0.254330266351152
Validation loss: 2.5436288497232162

Epoch: 516| Step: 0
Training loss: 0.1599432529087115
Validation loss: 2.582684128605326

Epoch: 6| Step: 1
Training loss: 0.19708403170027067
Validation loss: 2.5884069301753674

Epoch: 6| Step: 2
Training loss: 0.29347160417421775
Validation loss: 2.617944013060494

Epoch: 6| Step: 3
Training loss: 0.14632382177287193
Validation loss: 2.619994838409393

Epoch: 6| Step: 4
Training loss: 0.1115261374846545
Validation loss: 2.621337913485502

Epoch: 6| Step: 5
Training loss: 0.22060356595256017
Validation loss: 2.5805346909458713

Epoch: 6| Step: 6
Training loss: 0.1274368606867523
Validation loss: 2.6104657003062703

Epoch: 6| Step: 7
Training loss: 0.1873715874906419
Validation loss: 2.596638869222717

Epoch: 6| Step: 8
Training loss: 0.17697400102566474
Validation loss: 2.6109476894338584

Epoch: 6| Step: 9
Training loss: 0.14346907781265622
Validation loss: 2.6100440550110435

Epoch: 6| Step: 10
Training loss: 0.17786123129244524
Validation loss: 2.571670814149653

Epoch: 6| Step: 11
Training loss: 0.17185932326348569
Validation loss: 2.606260961942002

Epoch: 6| Step: 12
Training loss: 0.13394369809125348
Validation loss: 2.5919194973172863

Epoch: 6| Step: 13
Training loss: 0.1539857358983644
Validation loss: 2.5966187328318084

Epoch: 517| Step: 0
Training loss: 0.10721793322417453
Validation loss: 2.5680033166491665

Epoch: 6| Step: 1
Training loss: 0.19012220941560976
Validation loss: 2.5536250915573104

Epoch: 6| Step: 2
Training loss: 0.1690960415674473
Validation loss: 2.5765479660562036

Epoch: 6| Step: 3
Training loss: 0.15667363791626182
Validation loss: 2.560168362273847

Epoch: 6| Step: 4
Training loss: 0.32856242224170096
Validation loss: 2.5818211287217387

Epoch: 6| Step: 5
Training loss: 0.07409504569701388
Validation loss: 2.619000062176462

Epoch: 6| Step: 6
Training loss: 0.1744740038198069
Validation loss: 2.6268115104469514

Epoch: 6| Step: 7
Training loss: 0.16589137645018398
Validation loss: 2.6088893517779375

Epoch: 6| Step: 8
Training loss: 0.2510412259051832
Validation loss: 2.6113404595299143

Epoch: 6| Step: 9
Training loss: 0.140126483822605
Validation loss: 2.629742045917694

Epoch: 6| Step: 10
Training loss: 0.17500727118985743
Validation loss: 2.615355787182491

Epoch: 6| Step: 11
Training loss: 0.11130897457648703
Validation loss: 2.5967422089886836

Epoch: 6| Step: 12
Training loss: 0.1289500032211376
Validation loss: 2.567387935017482

Epoch: 6| Step: 13
Training loss: 0.11197470824289223
Validation loss: 2.575868875674195

Epoch: 518| Step: 0
Training loss: 0.1384173865378047
Validation loss: 2.5732719727727855

Epoch: 6| Step: 1
Training loss: 0.22322474233794234
Validation loss: 2.5718025311841735

Epoch: 6| Step: 2
Training loss: 0.14701980012139892
Validation loss: 2.55219668717791

Epoch: 6| Step: 3
Training loss: 0.18127280083654534
Validation loss: 2.520320770221825

Epoch: 6| Step: 4
Training loss: 0.18164005074358988
Validation loss: 2.519131128378814

Epoch: 6| Step: 5
Training loss: 0.19672637355052003
Validation loss: 2.556855639078401

Epoch: 6| Step: 6
Training loss: 0.1875393150755364
Validation loss: 2.5327720324932046

Epoch: 6| Step: 7
Training loss: 0.15296792274617682
Validation loss: 2.51835620007982

Epoch: 6| Step: 8
Training loss: 0.2843270198462824
Validation loss: 2.5535291228336963

Epoch: 6| Step: 9
Training loss: 0.20438106691180732
Validation loss: 2.5756622653535537

Epoch: 6| Step: 10
Training loss: 0.16804292061452397
Validation loss: 2.55897408853638

Epoch: 6| Step: 11
Training loss: 0.16348970421912892
Validation loss: 2.5492791141105755

Epoch: 6| Step: 12
Training loss: 0.14275597884364222
Validation loss: 2.546904084038118

Epoch: 6| Step: 13
Training loss: 0.1729044967892037
Validation loss: 2.574026978117973

Epoch: 519| Step: 0
Training loss: 0.12995048423579997
Validation loss: 2.558660615762607

Epoch: 6| Step: 1
Training loss: 0.18404963888821027
Validation loss: 2.575953889260608

Epoch: 6| Step: 2
Training loss: 0.21463064548663568
Validation loss: 2.5837786790456794

Epoch: 6| Step: 3
Training loss: 0.1129012640721382
Validation loss: 2.5769519253890665

Epoch: 6| Step: 4
Training loss: 0.20588529774644465
Validation loss: 2.5810940398888373

Epoch: 6| Step: 5
Training loss: 0.20376083004433723
Validation loss: 2.5679087268725054

Epoch: 6| Step: 6
Training loss: 0.20837707159743746
Validation loss: 2.5591968383264954

Epoch: 6| Step: 7
Training loss: 0.24601780764161835
Validation loss: 2.5495643652183535

Epoch: 6| Step: 8
Training loss: 0.18790099854889156
Validation loss: 2.5464150688965344

Epoch: 6| Step: 9
Training loss: 0.19537514635569922
Validation loss: 2.5863899990258217

Epoch: 6| Step: 10
Training loss: 0.12169766576465142
Validation loss: 2.501464100217041

Epoch: 6| Step: 11
Training loss: 0.2385557266669957
Validation loss: 2.5511377112503792

Epoch: 6| Step: 12
Training loss: 0.0934301722405761
Validation loss: 2.5622197129703324

Epoch: 6| Step: 13
Training loss: 0.1271012908789145
Validation loss: 2.5530863964036996

Epoch: 520| Step: 0
Training loss: 0.1138337981146269
Validation loss: 2.6191469079728744

Epoch: 6| Step: 1
Training loss: 0.16523963545593806
Validation loss: 2.580985766731946

Epoch: 6| Step: 2
Training loss: 0.14708966131709345
Validation loss: 2.5816869785605

Epoch: 6| Step: 3
Training loss: 0.13952323663091423
Validation loss: 2.566928829986957

Epoch: 6| Step: 4
Training loss: 0.15641719694061237
Validation loss: 2.6237367734253385

Epoch: 6| Step: 5
Training loss: 0.19606831222227028
Validation loss: 2.5933843484166075

Epoch: 6| Step: 6
Training loss: 0.23438889144420158
Validation loss: 2.6202325808087057

Epoch: 6| Step: 7
Training loss: 0.17494725961061156
Validation loss: 2.5759584652777567

Epoch: 6| Step: 8
Training loss: 0.2680739521569639
Validation loss: 2.559942748768448

Epoch: 6| Step: 9
Training loss: 0.1599954868216568
Validation loss: 2.601463725193056

Epoch: 6| Step: 10
Training loss: 0.18723332793000225
Validation loss: 2.5352105072736384

Epoch: 6| Step: 11
Training loss: 0.10022208690767806
Validation loss: 2.5498351467071507

Epoch: 6| Step: 12
Training loss: 0.11167372216287144
Validation loss: 2.5993456870692166

Epoch: 6| Step: 13
Training loss: 0.1942911527778079
Validation loss: 2.550364340857371

Epoch: 521| Step: 0
Training loss: 0.24235782479120027
Validation loss: 2.563637726748686

Epoch: 6| Step: 1
Training loss: 0.2075489696490895
Validation loss: 2.55737931356314

Epoch: 6| Step: 2
Training loss: 0.09843799973164216
Validation loss: 2.5919834550184926

Epoch: 6| Step: 3
Training loss: 0.22821002479630065
Validation loss: 2.550303926277255

Epoch: 6| Step: 4
Training loss: 0.11400917093349526
Validation loss: 2.5890375019268546

Epoch: 6| Step: 5
Training loss: 0.10224313722578769
Validation loss: 2.5819038388346893

Epoch: 6| Step: 6
Training loss: 0.14780490748884448
Validation loss: 2.5684987666406323

Epoch: 6| Step: 7
Training loss: 0.1031901487917959
Validation loss: 2.56214103915743

Epoch: 6| Step: 8
Training loss: 0.19701639804632456
Validation loss: 2.554302247616069

Epoch: 6| Step: 9
Training loss: 0.09197055841800827
Validation loss: 2.5863579883836234

Epoch: 6| Step: 10
Training loss: 0.2328455613490389
Validation loss: 2.5589270464749942

Epoch: 6| Step: 11
Training loss: 0.10353322599231174
Validation loss: 2.588665378879516

Epoch: 6| Step: 12
Training loss: 0.1119383434432142
Validation loss: 2.5226026539712776

Epoch: 6| Step: 13
Training loss: 0.17448444441504202
Validation loss: 2.5503408762340265

Epoch: 522| Step: 0
Training loss: 0.15180719473054555
Validation loss: 2.5746535620016098

Epoch: 6| Step: 1
Training loss: 0.19403107850995982
Validation loss: 2.5440189814073237

Epoch: 6| Step: 2
Training loss: 0.22782906482529633
Validation loss: 2.4964645140934976

Epoch: 6| Step: 3
Training loss: 0.23665177433300605
Validation loss: 2.5129797011706256

Epoch: 6| Step: 4
Training loss: 0.1619127183773265
Validation loss: 2.5156012143978894

Epoch: 6| Step: 5
Training loss: 0.11727807994779559
Validation loss: 2.5195218817958103

Epoch: 6| Step: 6
Training loss: 0.12679230701164906
Validation loss: 2.482415053374854

Epoch: 6| Step: 7
Training loss: 0.13858705935622773
Validation loss: 2.5153491241473076

Epoch: 6| Step: 8
Training loss: 0.14033374825145942
Validation loss: 2.557607410509653

Epoch: 6| Step: 9
Training loss: 0.19972240137025277
Validation loss: 2.519057240484566

Epoch: 6| Step: 10
Training loss: 0.168126004926876
Validation loss: 2.546617961137645

Epoch: 6| Step: 11
Training loss: 0.16477837373511856
Validation loss: 2.5704948948297806

Epoch: 6| Step: 12
Training loss: 0.16312224161074024
Validation loss: 2.593354075468791

Epoch: 6| Step: 13
Training loss: 0.13217326911680774
Validation loss: 2.567677833878361

Epoch: 523| Step: 0
Training loss: 0.09754314548500405
Validation loss: 2.565088370968786

Epoch: 6| Step: 1
Training loss: 0.15953041124076675
Validation loss: 2.570051615676195

Epoch: 6| Step: 2
Training loss: 0.17003655126615874
Validation loss: 2.584941917110909

Epoch: 6| Step: 3
Training loss: 0.2263260956298946
Validation loss: 2.5594710199291395

Epoch: 6| Step: 4
Training loss: 0.20266148978807236
Validation loss: 2.5414777941420987

Epoch: 6| Step: 5
Training loss: 0.20665860377306228
Validation loss: 2.5373197960233824

Epoch: 6| Step: 6
Training loss: 0.16211809571490518
Validation loss: 2.552758077726755

Epoch: 6| Step: 7
Training loss: 0.14930839791537193
Validation loss: 2.547294414568978

Epoch: 6| Step: 8
Training loss: 0.1756807039711285
Validation loss: 2.5155457178614826

Epoch: 6| Step: 9
Training loss: 0.20549301685873195
Validation loss: 2.542570239642889

Epoch: 6| Step: 10
Training loss: 0.27300099545426587
Validation loss: 2.5492109458253562

Epoch: 6| Step: 11
Training loss: 0.2510077609252972
Validation loss: 2.581503479207964

Epoch: 6| Step: 12
Training loss: 0.1446130044503308
Validation loss: 2.597183621988903

Epoch: 6| Step: 13
Training loss: 0.2529786699504783
Validation loss: 2.6052807012878403

Epoch: 524| Step: 0
Training loss: 0.12353970213958305
Validation loss: 2.603088311836712

Epoch: 6| Step: 1
Training loss: 0.1484855272998433
Validation loss: 2.5973071793715614

Epoch: 6| Step: 2
Training loss: 0.19055520835943848
Validation loss: 2.5991721609774836

Epoch: 6| Step: 3
Training loss: 0.17686172718620946
Validation loss: 2.60236577692631

Epoch: 6| Step: 4
Training loss: 0.2126496902732199
Validation loss: 2.5903321376422923

Epoch: 6| Step: 5
Training loss: 0.19281593209957204
Validation loss: 2.567096732132884

Epoch: 6| Step: 6
Training loss: 0.1503209782626253
Validation loss: 2.5855199743640664

Epoch: 6| Step: 7
Training loss: 0.14334621992742205
Validation loss: 2.5736940667604697

Epoch: 6| Step: 8
Training loss: 0.13310916808732795
Validation loss: 2.5620609010282562

Epoch: 6| Step: 9
Training loss: 0.2396491761884054
Validation loss: 2.570357508969234

Epoch: 6| Step: 10
Training loss: 0.1805525358163555
Validation loss: 2.5512957109490833

Epoch: 6| Step: 11
Training loss: 0.21481402798448562
Validation loss: 2.5336609113175577

Epoch: 6| Step: 12
Training loss: 0.16611134630586707
Validation loss: 2.5357727163843884

Epoch: 6| Step: 13
Training loss: 0.281496641837767
Validation loss: 2.556102447018066

Epoch: 525| Step: 0
Training loss: 0.15490815242794256
Validation loss: 2.5752568981852124

Epoch: 6| Step: 1
Training loss: 0.2701460005810986
Validation loss: 2.5922924185948046

Epoch: 6| Step: 2
Training loss: 0.20420208878326848
Validation loss: 2.598614158054271

Epoch: 6| Step: 3
Training loss: 0.14146457491444533
Validation loss: 2.6107496816398506

Epoch: 6| Step: 4
Training loss: 0.20948907925620353
Validation loss: 2.601844262629216

Epoch: 6| Step: 5
Training loss: 0.16581855184386418
Validation loss: 2.6080772842977553

Epoch: 6| Step: 6
Training loss: 0.18545928694727623
Validation loss: 2.57487883437554

Epoch: 6| Step: 7
Training loss: 0.18470907293471808
Validation loss: 2.6159656516252983

Epoch: 6| Step: 8
Training loss: 0.25096618690269645
Validation loss: 2.572129257162497

Epoch: 6| Step: 9
Training loss: 0.15901811860235843
Validation loss: 2.556671424914025

Epoch: 6| Step: 10
Training loss: 0.14616922173265925
Validation loss: 2.56385320293769

Epoch: 6| Step: 11
Training loss: 0.19431253033475496
Validation loss: 2.530270909596697

Epoch: 6| Step: 12
Training loss: 0.14609334252040562
Validation loss: 2.522045841212786

Epoch: 6| Step: 13
Training loss: 0.11997719104008774
Validation loss: 2.5374282714430607

Epoch: 526| Step: 0
Training loss: 0.12261083712847827
Validation loss: 2.555675929395478

Epoch: 6| Step: 1
Training loss: 0.16407619146710453
Validation loss: 2.529080973589822

Epoch: 6| Step: 2
Training loss: 0.11712170184192942
Validation loss: 2.554376734863241

Epoch: 6| Step: 3
Training loss: 0.19436495770335674
Validation loss: 2.5293248019709975

Epoch: 6| Step: 4
Training loss: 0.17153443928660533
Validation loss: 2.534866765215812

Epoch: 6| Step: 5
Training loss: 0.11730394935439184
Validation loss: 2.5285158956684746

Epoch: 6| Step: 6
Training loss: 0.17130608577368978
Validation loss: 2.568852960471088

Epoch: 6| Step: 7
Training loss: 0.3555698460614477
Validation loss: 2.5361693917336265

Epoch: 6| Step: 8
Training loss: 0.24555538721043463
Validation loss: 2.519403977521038

Epoch: 6| Step: 9
Training loss: 0.1883860751340828
Validation loss: 2.5452755288570703

Epoch: 6| Step: 10
Training loss: 0.11743559404408035
Validation loss: 2.529657020383453

Epoch: 6| Step: 11
Training loss: 0.2559219167434376
Validation loss: 2.5053206717004914

Epoch: 6| Step: 12
Training loss: 0.1515789028022329
Validation loss: 2.500933710698479

Epoch: 6| Step: 13
Training loss: 0.20083979632503102
Validation loss: 2.5387190785477416

Epoch: 527| Step: 0
Training loss: 0.23462747644388735
Validation loss: 2.5668855071878904

Epoch: 6| Step: 1
Training loss: 0.2869911729040004
Validation loss: 2.6346979827567036

Epoch: 6| Step: 2
Training loss: 0.2334600550825047
Validation loss: 2.5906958391427426

Epoch: 6| Step: 3
Training loss: 0.33552986741400653
Validation loss: 2.613895280785656

Epoch: 6| Step: 4
Training loss: 0.22286488980453992
Validation loss: 2.582237337818263

Epoch: 6| Step: 5
Training loss: 0.13684226995784124
Validation loss: 2.594258378802274

Epoch: 6| Step: 6
Training loss: 0.17513028514723292
Validation loss: 2.594503487731422

Epoch: 6| Step: 7
Training loss: 0.24984903545884335
Validation loss: 2.5318550967594673

Epoch: 6| Step: 8
Training loss: 0.1649355817887796
Validation loss: 2.550655803684026

Epoch: 6| Step: 9
Training loss: 0.22177605907852546
Validation loss: 2.491555531028547

Epoch: 6| Step: 10
Training loss: 0.19255434899256468
Validation loss: 2.535517108065014

Epoch: 6| Step: 11
Training loss: 0.30861372822664646
Validation loss: 2.5282897847246213

Epoch: 6| Step: 12
Training loss: 0.18433174983799397
Validation loss: 2.5024770258127504

Epoch: 6| Step: 13
Training loss: 0.28599388733913905
Validation loss: 2.537796644467442

Epoch: 528| Step: 0
Training loss: 0.18218763084799516
Validation loss: 2.4918969658434302

Epoch: 6| Step: 1
Training loss: 0.20765998126567756
Validation loss: 2.521238548872694

Epoch: 6| Step: 2
Training loss: 0.193281736103455
Validation loss: 2.5415901631165827

Epoch: 6| Step: 3
Training loss: 0.11968675110186747
Validation loss: 2.5472306099455495

Epoch: 6| Step: 4
Training loss: 0.13861999750226559
Validation loss: 2.5224283406910044

Epoch: 6| Step: 5
Training loss: 0.1509033603047909
Validation loss: 2.5407682408135113

Epoch: 6| Step: 6
Training loss: 0.12092214391983834
Validation loss: 2.55041060100687

Epoch: 6| Step: 7
Training loss: 0.26275324980253184
Validation loss: 2.5272417356163617

Epoch: 6| Step: 8
Training loss: 0.21979078413950356
Validation loss: 2.540354832113914

Epoch: 6| Step: 9
Training loss: 0.1383820042771508
Validation loss: 2.5722704966055754

Epoch: 6| Step: 10
Training loss: 0.2705349133959421
Validation loss: 2.589795118602972

Epoch: 6| Step: 11
Training loss: 0.165284848451525
Validation loss: 2.5608184823835916

Epoch: 6| Step: 12
Training loss: 0.15072846551120006
Validation loss: 2.589056596692254

Epoch: 6| Step: 13
Training loss: 0.33381403098070456
Validation loss: 2.5403558907292036

Epoch: 529| Step: 0
Training loss: 0.2792594190970995
Validation loss: 2.5846757216082668

Epoch: 6| Step: 1
Training loss: 0.2279668560302371
Validation loss: 2.55650145221161

Epoch: 6| Step: 2
Training loss: 0.14590584635275317
Validation loss: 2.54119859575037

Epoch: 6| Step: 3
Training loss: 0.1318449794353009
Validation loss: 2.5470987998321704

Epoch: 6| Step: 4
Training loss: 0.1163610802770477
Validation loss: 2.5393709082204006

Epoch: 6| Step: 5
Training loss: 0.2766710370122669
Validation loss: 2.543388133137686

Epoch: 6| Step: 6
Training loss: 0.21584639240645095
Validation loss: 2.497421021405949

Epoch: 6| Step: 7
Training loss: 0.18458831537841205
Validation loss: 2.509423616872343

Epoch: 6| Step: 8
Training loss: 0.1644771309227938
Validation loss: 2.50623945127042

Epoch: 6| Step: 9
Training loss: 0.19790617178814943
Validation loss: 2.48721115678742

Epoch: 6| Step: 10
Training loss: 0.14509868067411724
Validation loss: 2.539388180678836

Epoch: 6| Step: 11
Training loss: 0.13657991308105125
Validation loss: 2.5450488227828583

Epoch: 6| Step: 12
Training loss: 0.164526295184295
Validation loss: 2.5671637808663212

Epoch: 6| Step: 13
Training loss: 0.2587064215225485
Validation loss: 2.5766063225805733

Epoch: 530| Step: 0
Training loss: 0.11437586855688861
Validation loss: 2.5565044555735623

Epoch: 6| Step: 1
Training loss: 0.20871725569394448
Validation loss: 2.5719219133260522

Epoch: 6| Step: 2
Training loss: 0.19415539353379926
Validation loss: 2.6044214871337483

Epoch: 6| Step: 3
Training loss: 0.17270663484233614
Validation loss: 2.6099039835609665

Epoch: 6| Step: 4
Training loss: 0.14502658891040887
Validation loss: 2.5674213180038805

Epoch: 6| Step: 5
Training loss: 0.18734412866956607
Validation loss: 2.586037719398497

Epoch: 6| Step: 6
Training loss: 0.1541451782853325
Validation loss: 2.5888089652532247

Epoch: 6| Step: 7
Training loss: 0.14853776506870434
Validation loss: 2.552663436230241

Epoch: 6| Step: 8
Training loss: 0.2536263022974533
Validation loss: 2.5759483493629407

Epoch: 6| Step: 9
Training loss: 0.23314260083965496
Validation loss: 2.5557846458500513

Epoch: 6| Step: 10
Training loss: 0.17591357548698747
Validation loss: 2.5553930549562516

Epoch: 6| Step: 11
Training loss: 0.23083454134059234
Validation loss: 2.5354365187209766

Epoch: 6| Step: 12
Training loss: 0.1506436683830873
Validation loss: 2.587140537494863

Epoch: 6| Step: 13
Training loss: 0.24570491135134348
Validation loss: 2.569484936159449

Epoch: 531| Step: 0
Training loss: 0.25204454286430605
Validation loss: 2.5762204411455487

Epoch: 6| Step: 1
Training loss: 0.36444866100001977
Validation loss: 2.5778788061541786

Epoch: 6| Step: 2
Training loss: 0.1439900187784958
Validation loss: 2.573209403575356

Epoch: 6| Step: 3
Training loss: 0.18512613880597958
Validation loss: 2.582201847519964

Epoch: 6| Step: 4
Training loss: 0.13172892006317027
Validation loss: 2.585864410641406

Epoch: 6| Step: 5
Training loss: 0.14927638323977838
Validation loss: 2.5480067153679644

Epoch: 6| Step: 6
Training loss: 0.2198818251627788
Validation loss: 2.517593570471778

Epoch: 6| Step: 7
Training loss: 0.12109181187216951
Validation loss: 2.572839251941158

Epoch: 6| Step: 8
Training loss: 0.178733271886458
Validation loss: 2.5107722547343623

Epoch: 6| Step: 9
Training loss: 0.24521165524395702
Validation loss: 2.510696112366491

Epoch: 6| Step: 10
Training loss: 0.19353972799653077
Validation loss: 2.506091838906748

Epoch: 6| Step: 11
Training loss: 0.07112536513397405
Validation loss: 2.535867131985554

Epoch: 6| Step: 12
Training loss: 0.09676724139624739
Validation loss: 2.5575842438850684

Epoch: 6| Step: 13
Training loss: 0.1871614479283265
Validation loss: 2.5703065634429922

Epoch: 532| Step: 0
Training loss: 0.2887283662230341
Validation loss: 2.579188661738143

Epoch: 6| Step: 1
Training loss: 0.15491083981122947
Validation loss: 2.5925695434116407

Epoch: 6| Step: 2
Training loss: 0.21118934925982302
Validation loss: 2.588309490647459

Epoch: 6| Step: 3
Training loss: 0.21384000387705443
Validation loss: 2.555706887388698

Epoch: 6| Step: 4
Training loss: 0.16151218259777408
Validation loss: 2.5744241542307127

Epoch: 6| Step: 5
Training loss: 0.2822489086135091
Validation loss: 2.587584084302857

Epoch: 6| Step: 6
Training loss: 0.15008591461419749
Validation loss: 2.5997826303152647

Epoch: 6| Step: 7
Training loss: 0.1272642065640081
Validation loss: 2.5839888276620866

Epoch: 6| Step: 8
Training loss: 0.18786488235727627
Validation loss: 2.645437658824241

Epoch: 6| Step: 9
Training loss: 0.09960210998071112
Validation loss: 2.5899941800327233

Epoch: 6| Step: 10
Training loss: 0.16135317444008845
Validation loss: 2.5926622723527633

Epoch: 6| Step: 11
Training loss: 0.18522680684641146
Validation loss: 2.6032064335336735

Epoch: 6| Step: 12
Training loss: 0.1865024255231777
Validation loss: 2.624067016197195

Epoch: 6| Step: 13
Training loss: 0.16449870861881433
Validation loss: 2.5699727716316683

Epoch: 533| Step: 0
Training loss: 0.09856801690171327
Validation loss: 2.562929959245746

Epoch: 6| Step: 1
Training loss: 0.13661972274255968
Validation loss: 2.5634745143681013

Epoch: 6| Step: 2
Training loss: 0.26057754633469205
Validation loss: 2.538268189735347

Epoch: 6| Step: 3
Training loss: 0.09373436241067153
Validation loss: 2.5433596330817014

Epoch: 6| Step: 4
Training loss: 0.1361166297236887
Validation loss: 2.5324232784501444

Epoch: 6| Step: 5
Training loss: 0.18963081835883747
Validation loss: 2.5337646417634727

Epoch: 6| Step: 6
Training loss: 0.14459717381185078
Validation loss: 2.509457656532308

Epoch: 6| Step: 7
Training loss: 0.11204438934526784
Validation loss: 2.544911855824086

Epoch: 6| Step: 8
Training loss: 0.22639110264414114
Validation loss: 2.514109880899321

Epoch: 6| Step: 9
Training loss: 0.20330357038329316
Validation loss: 2.506921782194354

Epoch: 6| Step: 10
Training loss: 0.07821086694693076
Validation loss: 2.538347156051711

Epoch: 6| Step: 11
Training loss: 0.1929332488141235
Validation loss: 2.559095964487886

Epoch: 6| Step: 12
Training loss: 0.09324067562429324
Validation loss: 2.556848808491296

Epoch: 6| Step: 13
Training loss: 0.09107855516320025
Validation loss: 2.6055508235815514

Epoch: 534| Step: 0
Training loss: 0.09650098777330926
Validation loss: 2.569107245354795

Epoch: 6| Step: 1
Training loss: 0.15174326784010253
Validation loss: 2.5646421281325344

Epoch: 6| Step: 2
Training loss: 0.16127135360887473
Validation loss: 2.5900965110546714

Epoch: 6| Step: 3
Training loss: 0.17040968624367156
Validation loss: 2.5745285370371156

Epoch: 6| Step: 4
Training loss: 0.21917707612666587
Validation loss: 2.5788356195674176

Epoch: 6| Step: 5
Training loss: 0.12837157481117653
Validation loss: 2.5964794902358497

Epoch: 6| Step: 6
Training loss: 0.23531455227791545
Validation loss: 2.5903387745333024

Epoch: 6| Step: 7
Training loss: 0.11651021823587632
Validation loss: 2.6003091829446183

Epoch: 6| Step: 8
Training loss: 0.13133836734641813
Validation loss: 2.5724767320695348

Epoch: 6| Step: 9
Training loss: 0.20752093146356657
Validation loss: 2.5547094064113036

Epoch: 6| Step: 10
Training loss: 0.1810158886535068
Validation loss: 2.55092895263095

Epoch: 6| Step: 11
Training loss: 0.1453074862015122
Validation loss: 2.577516663873242

Epoch: 6| Step: 12
Training loss: 0.20598728650464723
Validation loss: 2.5731040611009837

Epoch: 6| Step: 13
Training loss: 0.13068839190227546
Validation loss: 2.5098859401034366

Epoch: 535| Step: 0
Training loss: 0.13923901114002946
Validation loss: 2.544459967710581

Epoch: 6| Step: 1
Training loss: 0.2744721592123849
Validation loss: 2.4839656402541546

Epoch: 6| Step: 2
Training loss: 0.1341358410243798
Validation loss: 2.514874866142492

Epoch: 6| Step: 3
Training loss: 0.10508718611069237
Validation loss: 2.522348688997611

Epoch: 6| Step: 4
Training loss: 0.19924341310911597
Validation loss: 2.493811722388744

Epoch: 6| Step: 5
Training loss: 0.19102276123696005
Validation loss: 2.536907768637234

Epoch: 6| Step: 6
Training loss: 0.10911324378066126
Validation loss: 2.553617378412255

Epoch: 6| Step: 7
Training loss: 0.17442297149152258
Validation loss: 2.5015891244073845

Epoch: 6| Step: 8
Training loss: 0.15177345514378382
Validation loss: 2.497389312150165

Epoch: 6| Step: 9
Training loss: 0.2812200901233981
Validation loss: 2.5426248801473523

Epoch: 6| Step: 10
Training loss: 0.19815704321240032
Validation loss: 2.5354708400806762

Epoch: 6| Step: 11
Training loss: 0.20375566512698157
Validation loss: 2.5266575233287973

Epoch: 6| Step: 12
Training loss: 0.13509179463671186
Validation loss: 2.5530080968569684

Epoch: 6| Step: 13
Training loss: 0.23943723840582212
Validation loss: 2.5790066198267625

Epoch: 536| Step: 0
Training loss: 0.14396515376950747
Validation loss: 2.5864769415367146

Epoch: 6| Step: 1
Training loss: 0.16140468664972418
Validation loss: 2.584803203925571

Epoch: 6| Step: 2
Training loss: 0.18273528253363372
Validation loss: 2.6026286299181813

Epoch: 6| Step: 3
Training loss: 0.18306882364428456
Validation loss: 2.5162661604197827

Epoch: 6| Step: 4
Training loss: 0.16651683209047866
Validation loss: 2.5477170847448796

Epoch: 6| Step: 5
Training loss: 0.18313006426608086
Validation loss: 2.5689940202912833

Epoch: 6| Step: 6
Training loss: 0.19649132703005978
Validation loss: 2.5726482800556996

Epoch: 6| Step: 7
Training loss: 0.1930066561823511
Validation loss: 2.574468714906529

Epoch: 6| Step: 8
Training loss: 0.14699483938508903
Validation loss: 2.5400765145199156

Epoch: 6| Step: 9
Training loss: 0.21643908076049165
Validation loss: 2.5630401874327813

Epoch: 6| Step: 10
Training loss: 0.2311869035807494
Validation loss: 2.5183410850415315

Epoch: 6| Step: 11
Training loss: 0.13191687607186292
Validation loss: 2.515622272921815

Epoch: 6| Step: 12
Training loss: 0.1905972452751684
Validation loss: 2.543252150532377

Epoch: 6| Step: 13
Training loss: 0.32277380439029263
Validation loss: 2.558759804523658

Epoch: 537| Step: 0
Training loss: 0.18373733343854787
Validation loss: 2.558241794967786

Epoch: 6| Step: 1
Training loss: 0.2009133001174284
Validation loss: 2.5617404285200864

Epoch: 6| Step: 2
Training loss: 0.18775257344647361
Validation loss: 2.6006259397055644

Epoch: 6| Step: 3
Training loss: 0.20938305839289853
Validation loss: 2.556559927385397

Epoch: 6| Step: 4
Training loss: 0.16047747891911304
Validation loss: 2.584822386007851

Epoch: 6| Step: 5
Training loss: 0.21977269006378075
Validation loss: 2.5907825901541766

Epoch: 6| Step: 6
Training loss: 0.14618589509349678
Validation loss: 2.5440256630386466

Epoch: 6| Step: 7
Training loss: 0.23438003852514663
Validation loss: 2.57820743094651

Epoch: 6| Step: 8
Training loss: 0.2438455171380499
Validation loss: 2.585412639167152

Epoch: 6| Step: 9
Training loss: 0.2346982157784051
Validation loss: 2.5596808280848204

Epoch: 6| Step: 10
Training loss: 0.17225464160877366
Validation loss: 2.5448887851767363

Epoch: 6| Step: 11
Training loss: 0.20662040250940047
Validation loss: 2.5541658461275554

Epoch: 6| Step: 12
Training loss: 0.1809746418189646
Validation loss: 2.546922729697214

Epoch: 6| Step: 13
Training loss: 0.14820971705043953
Validation loss: 2.5343069513368452

Epoch: 538| Step: 0
Training loss: 0.21467877035702707
Validation loss: 2.52141788884593

Epoch: 6| Step: 1
Training loss: 0.1586729655188421
Validation loss: 2.5335721325841662

Epoch: 6| Step: 2
Training loss: 0.18792151714635652
Validation loss: 2.5032249712675703

Epoch: 6| Step: 3
Training loss: 0.2586152554700206
Validation loss: 2.518246621122955

Epoch: 6| Step: 4
Training loss: 0.24131746295112397
Validation loss: 2.5406574116173832

Epoch: 6| Step: 5
Training loss: 0.1279879430087932
Validation loss: 2.564216711025389

Epoch: 6| Step: 6
Training loss: 0.2702758014441599
Validation loss: 2.5503126345651888

Epoch: 6| Step: 7
Training loss: 0.13835790847698998
Validation loss: 2.5591961811873305

Epoch: 6| Step: 8
Training loss: 0.2659581423367374
Validation loss: 2.570297642623211

Epoch: 6| Step: 9
Training loss: 0.464745182518207
Validation loss: 2.612507970638513

Epoch: 6| Step: 10
Training loss: 0.42979890939610543
Validation loss: 2.613638018941106

Epoch: 6| Step: 11
Training loss: 0.3109769302555742
Validation loss: 2.5722998904898353

Epoch: 6| Step: 12
Training loss: 0.21641458708750944
Validation loss: 2.5082586734469627

Epoch: 6| Step: 13
Training loss: 0.43873140197853006
Validation loss: 2.420972968780114

Epoch: 539| Step: 0
Training loss: 0.42885840797072067
Validation loss: 2.487364280264409

Epoch: 6| Step: 1
Training loss: 0.38185716652942736
Validation loss: 2.5083534562746825

Epoch: 6| Step: 2
Training loss: 0.40504202612889817
Validation loss: 2.516016857332876

Epoch: 6| Step: 3
Training loss: 0.49470873355177253
Validation loss: 2.5760552563867867

Epoch: 6| Step: 4
Training loss: 0.4702029914986334
Validation loss: 2.5719453943681705

Epoch: 6| Step: 5
Training loss: 0.2996146130756718
Validation loss: 2.5951275632251525

Epoch: 6| Step: 6
Training loss: 0.5784680920738776
Validation loss: 2.5784281552726247

Epoch: 6| Step: 7
Training loss: 0.5123720148822742
Validation loss: 2.5709784922508394

Epoch: 6| Step: 8
Training loss: 0.339695514489656
Validation loss: 2.51315528594539

Epoch: 6| Step: 9
Training loss: 0.3150402298472299
Validation loss: 2.5251999215752905

Epoch: 6| Step: 10
Training loss: 0.2735240118227668
Validation loss: 2.554393869724035

Epoch: 6| Step: 11
Training loss: 0.27632876826700276
Validation loss: 2.565676963011842

Epoch: 6| Step: 12
Training loss: 0.3145103165643181
Validation loss: 2.610841251334563

Epoch: 6| Step: 13
Training loss: 0.20372193911169123
Validation loss: 2.564845920670387

Epoch: 540| Step: 0
Training loss: 0.28173862503533237
Validation loss: 2.6180306636517368

Epoch: 6| Step: 1
Training loss: 0.2810439838759745
Validation loss: 2.5729390857827945

Epoch: 6| Step: 2
Training loss: 0.19415788784837473
Validation loss: 2.583924557979399

Epoch: 6| Step: 3
Training loss: 0.2270609781580189
Validation loss: 2.606897132718943

Epoch: 6| Step: 4
Training loss: 0.13361537406987578
Validation loss: 2.6023886187862315

Epoch: 6| Step: 5
Training loss: 0.3711713207885484
Validation loss: 2.560219727329674

Epoch: 6| Step: 6
Training loss: 0.3045407455318367
Validation loss: 2.5886064073464747

Epoch: 6| Step: 7
Training loss: 0.30261263706916874
Validation loss: 2.6357996487764797

Epoch: 6| Step: 8
Training loss: 0.33892694215757624
Validation loss: 2.6232442575333854

Epoch: 6| Step: 9
Training loss: 0.3675641907534853
Validation loss: 2.551162266891105

Epoch: 6| Step: 10
Training loss: 0.3148123543280605
Validation loss: 2.5649316606763026

Epoch: 6| Step: 11
Training loss: 0.25110352863292
Validation loss: 2.53086215336544

Epoch: 6| Step: 12
Training loss: 0.2441042911195732
Validation loss: 2.5139923372046082

Epoch: 6| Step: 13
Training loss: 0.3274234469864577
Validation loss: 2.5138058488271247

Epoch: 541| Step: 0
Training loss: 0.38690385338044303
Validation loss: 2.4850975374362676

Epoch: 6| Step: 1
Training loss: 0.23038578964907838
Validation loss: 2.4378098553058467

Epoch: 6| Step: 2
Training loss: 0.34954426334935523
Validation loss: 2.4721474925621174

Epoch: 6| Step: 3
Training loss: 0.4247168088319457
Validation loss: 2.411788991822978

Epoch: 6| Step: 4
Training loss: 0.17063587182030873
Validation loss: 2.488113343822832

Epoch: 6| Step: 5
Training loss: 0.19368565129151458
Validation loss: 2.5231477167268532

Epoch: 6| Step: 6
Training loss: 0.3526925257531407
Validation loss: 2.5616141708270286

Epoch: 6| Step: 7
Training loss: 0.21270280830058763
Validation loss: 2.607585743259944

Epoch: 6| Step: 8
Training loss: 0.41389584336351454
Validation loss: 2.6275195146921755

Epoch: 6| Step: 9
Training loss: 0.2747759621687411
Validation loss: 2.606540155173448

Epoch: 6| Step: 10
Training loss: 0.31796952231123576
Validation loss: 2.6568474307050103

Epoch: 6| Step: 11
Training loss: 0.2988202960416189
Validation loss: 2.6385612784928183

Epoch: 6| Step: 12
Training loss: 0.36123936568186654
Validation loss: 2.589013239172535

Epoch: 6| Step: 13
Training loss: 0.24643023511446435
Validation loss: 2.5959425119013337

Epoch: 542| Step: 0
Training loss: 0.23846490223814332
Validation loss: 2.551833196808176

Epoch: 6| Step: 1
Training loss: 0.281196748142649
Validation loss: 2.5351650618930237

Epoch: 6| Step: 2
Training loss: 0.3876888553264222
Validation loss: 2.5455770481137883

Epoch: 6| Step: 3
Training loss: 0.3120708379718378
Validation loss: 2.5343205928899044

Epoch: 6| Step: 4
Training loss: 0.26552323187014976
Validation loss: 2.5420053304508547

Epoch: 6| Step: 5
Training loss: 0.1858129901898767
Validation loss: 2.5426023019605

Epoch: 6| Step: 6
Training loss: 0.20819137425569775
Validation loss: 2.582124576809081

Epoch: 6| Step: 7
Training loss: 0.267996787670263
Validation loss: 2.617195790815989

Epoch: 6| Step: 8
Training loss: 0.29439619089297936
Validation loss: 2.5512364905961036

Epoch: 6| Step: 9
Training loss: 0.31162713456522606
Validation loss: 2.5740085268052857

Epoch: 6| Step: 10
Training loss: 0.22153404257541529
Validation loss: 2.5621784157483245

Epoch: 6| Step: 11
Training loss: 0.19961095051600905
Validation loss: 2.5115994142945013

Epoch: 6| Step: 12
Training loss: 0.19519861715869546
Validation loss: 2.519463310651643

Epoch: 6| Step: 13
Training loss: 0.3088422933272212
Validation loss: 2.4928547814556783

Epoch: 543| Step: 0
Training loss: 0.2617739434189686
Validation loss: 2.481109593718704

Epoch: 6| Step: 1
Training loss: 0.22739765373726872
Validation loss: 2.4970565285332453

Epoch: 6| Step: 2
Training loss: 0.34518538245456937
Validation loss: 2.456025062587377

Epoch: 6| Step: 3
Training loss: 0.2873889185018402
Validation loss: 2.42689388640807

Epoch: 6| Step: 4
Training loss: 0.30741502688777056
Validation loss: 2.4975270976940287

Epoch: 6| Step: 5
Training loss: 0.3650224039961916
Validation loss: 2.4569320404355417

Epoch: 6| Step: 6
Training loss: 0.1943276370015481
Validation loss: 2.508140460994806

Epoch: 6| Step: 7
Training loss: 0.2129020337888763
Validation loss: 2.5787168308890753

Epoch: 6| Step: 8
Training loss: 0.2772283179539452
Validation loss: 2.5903638007840115

Epoch: 6| Step: 9
Training loss: 0.3977256287194
Validation loss: 2.612989449619727

Epoch: 6| Step: 10
Training loss: 0.30565918744864373
Validation loss: 2.6154363678981047

Epoch: 6| Step: 11
Training loss: 0.26032832872641387
Validation loss: 2.539526166331943

Epoch: 6| Step: 12
Training loss: 0.3836514563575226
Validation loss: 2.6158174051145218

Epoch: 6| Step: 13
Training loss: 0.33671479897714585
Validation loss: 2.55599386343684

Epoch: 544| Step: 0
Training loss: 0.1606828243913706
Validation loss: 2.578403381054865

Epoch: 6| Step: 1
Training loss: 0.2757445962122204
Validation loss: 2.534580567000075

Epoch: 6| Step: 2
Training loss: 0.2572158498423269
Validation loss: 2.538286965490936

Epoch: 6| Step: 3
Training loss: 0.27543344908718054
Validation loss: 2.5107256839099534

Epoch: 6| Step: 4
Training loss: 0.23306966314051755
Validation loss: 2.5080044764634666

Epoch: 6| Step: 5
Training loss: 0.20563414447533182
Validation loss: 2.47793275054588

Epoch: 6| Step: 6
Training loss: 0.17289595384138134
Validation loss: 2.527247387861434

Epoch: 6| Step: 7
Training loss: 0.20284210275578568
Validation loss: 2.50706592930123

Epoch: 6| Step: 8
Training loss: 0.2520592044810686
Validation loss: 2.54094897996841

Epoch: 6| Step: 9
Training loss: 0.22551112565223946
Validation loss: 2.5519845755485746

Epoch: 6| Step: 10
Training loss: 0.24113929703974085
Validation loss: 2.5747690980765356

Epoch: 6| Step: 11
Training loss: 0.31417922417733274
Validation loss: 2.5435377681220057

Epoch: 6| Step: 12
Training loss: 0.27068914952608986
Validation loss: 2.5386514189249882

Epoch: 6| Step: 13
Training loss: 0.3225152638246081
Validation loss: 2.549124991582966

Epoch: 545| Step: 0
Training loss: 0.2957843774709788
Validation loss: 2.5490773237386923

Epoch: 6| Step: 1
Training loss: 0.36506936736881385
Validation loss: 2.5414418753703356

Epoch: 6| Step: 2
Training loss: 0.3678344748843279
Validation loss: 2.550999573829896

Epoch: 6| Step: 3
Training loss: 0.3182083661054956
Validation loss: 2.5235781660729586

Epoch: 6| Step: 4
Training loss: 0.2489436751137779
Validation loss: 2.4872644711882166

Epoch: 6| Step: 5
Training loss: 0.4216320786626931
Validation loss: 2.49739615395146

Epoch: 6| Step: 6
Training loss: 0.6434980028858035
Validation loss: 2.490447518196583

Epoch: 6| Step: 7
Training loss: 0.2923142051345262
Validation loss: 2.480794960452232

Epoch: 6| Step: 8
Training loss: 0.24277264141464755
Validation loss: 2.493855602991085

Epoch: 6| Step: 9
Training loss: 0.2553753533381904
Validation loss: 2.4512471921094505

Epoch: 6| Step: 10
Training loss: 0.4685099463908254
Validation loss: 2.40712606865141

Epoch: 6| Step: 11
Training loss: 0.439071828939899
Validation loss: 2.4386647704263575

Epoch: 6| Step: 12
Training loss: 0.4025550583683294
Validation loss: 2.448937374023957

Epoch: 6| Step: 13
Training loss: 0.3553209731233256
Validation loss: 2.486836045191966

Epoch: 546| Step: 0
Training loss: 0.32229897297643184
Validation loss: 2.49383543928418

Epoch: 6| Step: 1
Training loss: 0.40781321909172413
Validation loss: 2.505517351399656

Epoch: 6| Step: 2
Training loss: 0.3808530758067817
Validation loss: 2.512368949150179

Epoch: 6| Step: 3
Training loss: 0.20294660290297079
Validation loss: 2.48803924266119

Epoch: 6| Step: 4
Training loss: 0.2957538339530815
Validation loss: 2.5219660493567435

Epoch: 6| Step: 5
Training loss: 0.29349861548582984
Validation loss: 2.4910303263914724

Epoch: 6| Step: 6
Training loss: 0.260689190682796
Validation loss: 2.5222980478323014

Epoch: 6| Step: 7
Training loss: 0.25328901534322595
Validation loss: 2.5215552606569296

Epoch: 6| Step: 8
Training loss: 0.21274711426448714
Validation loss: 2.505195618837395

Epoch: 6| Step: 9
Training loss: 0.1924551232467966
Validation loss: 2.527200601762611

Epoch: 6| Step: 10
Training loss: 0.2243924295674131
Validation loss: 2.5302443203589844

Epoch: 6| Step: 11
Training loss: 0.23493945974104463
Validation loss: 2.5522602501313862

Epoch: 6| Step: 12
Training loss: 0.3019669928086562
Validation loss: 2.525117917649342

Epoch: 6| Step: 13
Training loss: 0.20195788003425838
Validation loss: 2.5525963942881407

Epoch: 547| Step: 0
Training loss: 0.30348282861445736
Validation loss: 2.5812353549136504

Epoch: 6| Step: 1
Training loss: 0.1914413381061644
Validation loss: 2.5510446125156325

Epoch: 6| Step: 2
Training loss: 0.2525808661159041
Validation loss: 2.577128011045449

Epoch: 6| Step: 3
Training loss: 0.22230786959566434
Validation loss: 2.595089782474269

Epoch: 6| Step: 4
Training loss: 0.34164372964177175
Validation loss: 2.564774097181796

Epoch: 6| Step: 5
Training loss: 0.14380653503179497
Validation loss: 2.627964268080969

Epoch: 6| Step: 6
Training loss: 0.2678623221668684
Validation loss: 2.5931964653768502

Epoch: 6| Step: 7
Training loss: 0.2589133486007702
Validation loss: 2.5922784961570713

Epoch: 6| Step: 8
Training loss: 0.3336260027336182
Validation loss: 2.548967498500383

Epoch: 6| Step: 9
Training loss: 0.22551219114581952
Validation loss: 2.561982388445977

Epoch: 6| Step: 10
Training loss: 0.20084556484634056
Validation loss: 2.5772698727823777

Epoch: 6| Step: 11
Training loss: 0.1891787203303837
Validation loss: 2.54730930748556

Epoch: 6| Step: 12
Training loss: 0.2257354042999867
Validation loss: 2.578516720881144

Epoch: 6| Step: 13
Training loss: 0.1937777972277491
Validation loss: 2.55062353705057

Epoch: 548| Step: 0
Training loss: 0.13069789089341366
Validation loss: 2.5453972277808847

Epoch: 6| Step: 1
Training loss: 0.13829068728210592
Validation loss: 2.5276889258783326

Epoch: 6| Step: 2
Training loss: 0.19614690880793773
Validation loss: 2.546388031585361

Epoch: 6| Step: 3
Training loss: 0.2186255952762637
Validation loss: 2.5143563825778843

Epoch: 6| Step: 4
Training loss: 0.19383076322728926
Validation loss: 2.5663770433413053

Epoch: 6| Step: 5
Training loss: 0.2571714841924394
Validation loss: 2.5642231495704984

Epoch: 6| Step: 6
Training loss: 0.16653074120994837
Validation loss: 2.5398766804237636

Epoch: 6| Step: 7
Training loss: 0.2018750871888436
Validation loss: 2.5322888641686796

Epoch: 6| Step: 8
Training loss: 0.15411350363529042
Validation loss: 2.5283063359005884

Epoch: 6| Step: 9
Training loss: 0.2636382611359276
Validation loss: 2.5493451622616736

Epoch: 6| Step: 10
Training loss: 0.2767997295373494
Validation loss: 2.5841988758573335

Epoch: 6| Step: 11
Training loss: 0.15439731009079974
Validation loss: 2.579799217123125

Epoch: 6| Step: 12
Training loss: 0.13859982700851442
Validation loss: 2.561147564528391

Epoch: 6| Step: 13
Training loss: 0.19272953101582002
Validation loss: 2.5445189291708936

Epoch: 549| Step: 0
Training loss: 0.1838400689916745
Validation loss: 2.551855316590512

Epoch: 6| Step: 1
Training loss: 0.13839549070920065
Validation loss: 2.530941367972555

Epoch: 6| Step: 2
Training loss: 0.26991340248512813
Validation loss: 2.553841975196766

Epoch: 6| Step: 3
Training loss: 0.2825110430584579
Validation loss: 2.5876153560456956

Epoch: 6| Step: 4
Training loss: 0.19007104210566741
Validation loss: 2.5073766584248856

Epoch: 6| Step: 5
Training loss: 0.16109042910715085
Validation loss: 2.59458423931704

Epoch: 6| Step: 6
Training loss: 0.23437872724748288
Validation loss: 2.5660308944487134

Epoch: 6| Step: 7
Training loss: 0.11590164763836296
Validation loss: 2.56437058483054

Epoch: 6| Step: 8
Training loss: 0.19190947884541
Validation loss: 2.5519199750165416

Epoch: 6| Step: 9
Training loss: 0.17511576672159967
Validation loss: 2.538248441207374

Epoch: 6| Step: 10
Training loss: 0.2418057447787932
Validation loss: 2.565198256559334

Epoch: 6| Step: 11
Training loss: 0.14783622657123896
Validation loss: 2.5364547961595445

Epoch: 6| Step: 12
Training loss: 0.1741929672390605
Validation loss: 2.5277879851412104

Epoch: 6| Step: 13
Training loss: 0.29873458794618596
Validation loss: 2.537174657783978

Epoch: 550| Step: 0
Training loss: 0.1652613051994026
Validation loss: 2.5532932697326194

Epoch: 6| Step: 1
Training loss: 0.23911007582290011
Validation loss: 2.538206474949001

Epoch: 6| Step: 2
Training loss: 0.11041000388469133
Validation loss: 2.528749411460427

Epoch: 6| Step: 3
Training loss: 0.18409642939834733
Validation loss: 2.5314001385476974

Epoch: 6| Step: 4
Training loss: 0.1712595747877947
Validation loss: 2.562083162649378

Epoch: 6| Step: 5
Training loss: 0.17351768933836875
Validation loss: 2.5184949339363483

Epoch: 6| Step: 6
Training loss: 0.2643692120128151
Validation loss: 2.5245420587913427

Epoch: 6| Step: 7
Training loss: 0.11538105858500262
Validation loss: 2.544208694417792

Epoch: 6| Step: 8
Training loss: 0.18182547198047744
Validation loss: 2.4674577351391367

Epoch: 6| Step: 9
Training loss: 0.1872253393097048
Validation loss: 2.530035363784765

Epoch: 6| Step: 10
Training loss: 0.1677175351001684
Validation loss: 2.4891214653252702

Epoch: 6| Step: 11
Training loss: 0.27068842012614097
Validation loss: 2.4878409261657004

Epoch: 6| Step: 12
Training loss: 0.15281464474778006
Validation loss: 2.536265154107426

Epoch: 6| Step: 13
Training loss: 0.12279010654691744
Validation loss: 2.5295878616830207

Epoch: 551| Step: 0
Training loss: 0.21972633361804486
Validation loss: 2.5326785947131842

Epoch: 6| Step: 1
Training loss: 0.210030318041452
Validation loss: 2.542011454627236

Epoch: 6| Step: 2
Training loss: 0.18225028158618747
Validation loss: 2.5594403949364106

Epoch: 6| Step: 3
Training loss: 0.18796507456825617
Validation loss: 2.493688202968495

Epoch: 6| Step: 4
Training loss: 0.151971919557173
Validation loss: 2.543963122262708

Epoch: 6| Step: 5
Training loss: 0.12214941894800597
Validation loss: 2.5492718825893763

Epoch: 6| Step: 6
Training loss: 0.09530899576874463
Validation loss: 2.5159001506609013

Epoch: 6| Step: 7
Training loss: 0.15061452844040393
Validation loss: 2.5551252604381394

Epoch: 6| Step: 8
Training loss: 0.24677881377023472
Validation loss: 2.5282464781913707

Epoch: 6| Step: 9
Training loss: 0.1400692208987089
Validation loss: 2.498730831597091

Epoch: 6| Step: 10
Training loss: 0.24681690474110668
Validation loss: 2.5454280166964196

Epoch: 6| Step: 11
Training loss: 0.15126212380818532
Validation loss: 2.5659407698938907

Epoch: 6| Step: 12
Training loss: 0.1576053960045847
Validation loss: 2.5334455938095886

Epoch: 6| Step: 13
Training loss: 0.15280426553176152
Validation loss: 2.5130372186469083

Epoch: 552| Step: 0
Training loss: 0.24539869033495867
Validation loss: 2.5277304437764068

Epoch: 6| Step: 1
Training loss: 0.24989501417650425
Validation loss: 2.5562135212169794

Epoch: 6| Step: 2
Training loss: 0.22264288142710864
Validation loss: 2.508343280811622

Epoch: 6| Step: 3
Training loss: 0.22019044017696557
Validation loss: 2.50796153212525

Epoch: 6| Step: 4
Training loss: 0.21524442244269362
Validation loss: 2.506849928471302

Epoch: 6| Step: 5
Training loss: 0.1260621792742385
Validation loss: 2.4933348848547436

Epoch: 6| Step: 6
Training loss: 0.21430668025821467
Validation loss: 2.466374251181322

Epoch: 6| Step: 7
Training loss: 0.11193879688013271
Validation loss: 2.440843648424243

Epoch: 6| Step: 8
Training loss: 0.1874267912041417
Validation loss: 2.493489999042019

Epoch: 6| Step: 9
Training loss: 0.21002903211103982
Validation loss: 2.48113448801766

Epoch: 6| Step: 10
Training loss: 0.19855542170966534
Validation loss: 2.520961792439911

Epoch: 6| Step: 11
Training loss: 0.15930031377495948
Validation loss: 2.4776086734861105

Epoch: 6| Step: 12
Training loss: 0.146279414155438
Validation loss: 2.4739424074930856

Epoch: 6| Step: 13
Training loss: 0.14958512729730783
Validation loss: 2.4796273778991567

Epoch: 553| Step: 0
Training loss: 0.18121872377206316
Validation loss: 2.470656032357455

Epoch: 6| Step: 1
Training loss: 0.1213387924866961
Validation loss: 2.459484856449632

Epoch: 6| Step: 2
Training loss: 0.3230646458342539
Validation loss: 2.5012991175476733

Epoch: 6| Step: 3
Training loss: 0.19297330055585618
Validation loss: 2.517322109223439

Epoch: 6| Step: 4
Training loss: 0.1742260321989696
Validation loss: 2.5053285990260457

Epoch: 6| Step: 5
Training loss: 0.16872944574214854
Validation loss: 2.505614608074242

Epoch: 6| Step: 6
Training loss: 0.24187956737917662
Validation loss: 2.4976544533974305

Epoch: 6| Step: 7
Training loss: 0.18192176186566994
Validation loss: 2.5475551337023488

Epoch: 6| Step: 8
Training loss: 0.19698902604900037
Validation loss: 2.5391253447347575

Epoch: 6| Step: 9
Training loss: 0.14580758469198954
Validation loss: 2.5592039636676107

Epoch: 6| Step: 10
Training loss: 0.15301500890275313
Validation loss: 2.6246698116183516

Epoch: 6| Step: 11
Training loss: 0.17532499228047335
Validation loss: 2.591431070500405

Epoch: 6| Step: 12
Training loss: 0.2470450935007601
Validation loss: 2.580104964768916

Epoch: 6| Step: 13
Training loss: 0.30162402153014517
Validation loss: 2.5765642952903267

Epoch: 554| Step: 0
Training loss: 0.15784734586744514
Validation loss: 2.5720626727693223

Epoch: 6| Step: 1
Training loss: 0.21813792359834136
Validation loss: 2.52611050061105

Epoch: 6| Step: 2
Training loss: 0.25251004671183763
Validation loss: 2.5076275742208165

Epoch: 6| Step: 3
Training loss: 0.15846406350928846
Validation loss: 2.522527883985678

Epoch: 6| Step: 4
Training loss: 0.31709500688367853
Validation loss: 2.521894179023957

Epoch: 6| Step: 5
Training loss: 0.2422305576442227
Validation loss: 2.5178368493545333

Epoch: 6| Step: 6
Training loss: 0.2051432460751411
Validation loss: 2.5667585856941426

Epoch: 6| Step: 7
Training loss: 0.163771518884015
Validation loss: 2.5351027055127457

Epoch: 6| Step: 8
Training loss: 0.18969530180671876
Validation loss: 2.5494363531419606

Epoch: 6| Step: 9
Training loss: 0.15429728544156496
Validation loss: 2.5238735957833156

Epoch: 6| Step: 10
Training loss: 0.17033700547961506
Validation loss: 2.5471984692595133

Epoch: 6| Step: 11
Training loss: 0.1643933865014567
Validation loss: 2.5314828823027637

Epoch: 6| Step: 12
Training loss: 0.24451684574200552
Validation loss: 2.545704499980216

Epoch: 6| Step: 13
Training loss: 0.12975049987735265
Validation loss: 2.5288227835061523

Epoch: 555| Step: 0
Training loss: 0.16931708999867123
Validation loss: 2.5693868538801747

Epoch: 6| Step: 1
Training loss: 0.14823778419840525
Validation loss: 2.529331432718872

Epoch: 6| Step: 2
Training loss: 0.22625240941108313
Validation loss: 2.552778213121673

Epoch: 6| Step: 3
Training loss: 0.10476033395809022
Validation loss: 2.519960263608445

Epoch: 6| Step: 4
Training loss: 0.2195133870551283
Validation loss: 2.5256423037411886

Epoch: 6| Step: 5
Training loss: 0.16276325350514415
Validation loss: 2.518145005312592

Epoch: 6| Step: 6
Training loss: 0.24341085082424843
Validation loss: 2.4669704599459528

Epoch: 6| Step: 7
Training loss: 0.18278945101012603
Validation loss: 2.514941518390227

Epoch: 6| Step: 8
Training loss: 0.18865856218461322
Validation loss: 2.5080937605530713

Epoch: 6| Step: 9
Training loss: 0.15634040005564456
Validation loss: 2.4915162533066053

Epoch: 6| Step: 10
Training loss: 0.19869018071332045
Validation loss: 2.539095215440727

Epoch: 6| Step: 11
Training loss: 0.14688517099023637
Validation loss: 2.5522449642294025

Epoch: 6| Step: 12
Training loss: 0.2299347526321874
Validation loss: 2.556762392594075

Epoch: 6| Step: 13
Training loss: 0.24848468320470393
Validation loss: 2.544657310596735

Epoch: 556| Step: 0
Training loss: 0.15441010340530212
Validation loss: 2.5040522369275475

Epoch: 6| Step: 1
Training loss: 0.2155577931502703
Validation loss: 2.4933229690457206

Epoch: 6| Step: 2
Training loss: 0.17081438449890649
Validation loss: 2.49112819342342

Epoch: 6| Step: 3
Training loss: 0.25818529053007916
Validation loss: 2.469586493514055

Epoch: 6| Step: 4
Training loss: 0.1990898594252339
Validation loss: 2.4609628004475157

Epoch: 6| Step: 5
Training loss: 0.24051133914534725
Validation loss: 2.4865708298368188

Epoch: 6| Step: 6
Training loss: 0.1967810921513138
Validation loss: 2.444341945068473

Epoch: 6| Step: 7
Training loss: 0.10161437488774373
Validation loss: 2.4803424255589746

Epoch: 6| Step: 8
Training loss: 0.25291280800600746
Validation loss: 2.483748168251022

Epoch: 6| Step: 9
Training loss: 0.23224662937894608
Validation loss: 2.52759142266907

Epoch: 6| Step: 10
Training loss: 0.16495713339088378
Validation loss: 2.519208807860336

Epoch: 6| Step: 11
Training loss: 0.14901560591571275
Validation loss: 2.5526007123870045

Epoch: 6| Step: 12
Training loss: 0.13270111181361863
Validation loss: 2.5471843614890957

Epoch: 6| Step: 13
Training loss: 0.1994850865391199
Validation loss: 2.5466185802484906

Epoch: 557| Step: 0
Training loss: 0.14579466891906562
Validation loss: 2.5236123378537267

Epoch: 6| Step: 1
Training loss: 0.1580143025389217
Validation loss: 2.5415142984644614

Epoch: 6| Step: 2
Training loss: 0.3156505319447343
Validation loss: 2.513636323813664

Epoch: 6| Step: 3
Training loss: 0.18207548242581267
Validation loss: 2.552718721358362

Epoch: 6| Step: 4
Training loss: 0.206560310014551
Validation loss: 2.516081015369535

Epoch: 6| Step: 5
Training loss: 0.2789265237914139
Validation loss: 2.5466717728849937

Epoch: 6| Step: 6
Training loss: 0.20085886334621528
Validation loss: 2.527264539284357

Epoch: 6| Step: 7
Training loss: 0.20221217159700394
Validation loss: 2.554088998459564

Epoch: 6| Step: 8
Training loss: 0.1869049165694407
Validation loss: 2.5304703336509506

Epoch: 6| Step: 9
Training loss: 0.13473503484324384
Validation loss: 2.5416676746395326

Epoch: 6| Step: 10
Training loss: 0.16345680919608888
Validation loss: 2.5418803698264867

Epoch: 6| Step: 11
Training loss: 0.1523344452779652
Validation loss: 2.561088064976228

Epoch: 6| Step: 12
Training loss: 0.13144882730259821
Validation loss: 2.5282592058809126

Epoch: 6| Step: 13
Training loss: 0.18824354403597338
Validation loss: 2.603879346850974

Epoch: 558| Step: 0
Training loss: 0.12530035947080623
Validation loss: 2.5838965127244053

Epoch: 6| Step: 1
Training loss: 0.16511661355266535
Validation loss: 2.521943997791277

Epoch: 6| Step: 2
Training loss: 0.16821806170262335
Validation loss: 2.503943114704986

Epoch: 6| Step: 3
Training loss: 0.1445134641683972
Validation loss: 2.531803809354752

Epoch: 6| Step: 4
Training loss: 0.14945126986511295
Validation loss: 2.5318962694118365

Epoch: 6| Step: 5
Training loss: 0.19410027059615295
Validation loss: 2.5346421988855523

Epoch: 6| Step: 6
Training loss: 0.11104389347535852
Validation loss: 2.50001597758284

Epoch: 6| Step: 7
Training loss: 0.11611077054889003
Validation loss: 2.568721358163503

Epoch: 6| Step: 8
Training loss: 0.2255275865531864
Validation loss: 2.526543013348978

Epoch: 6| Step: 9
Training loss: 0.1207229335666317
Validation loss: 2.521312019000664

Epoch: 6| Step: 10
Training loss: 0.2559008237156537
Validation loss: 2.5556391729371946

Epoch: 6| Step: 11
Training loss: 0.15363553923265902
Validation loss: 2.5454892429287725

Epoch: 6| Step: 12
Training loss: 0.2269284400712603
Validation loss: 2.523007608375082

Epoch: 6| Step: 13
Training loss: 0.1340278040731346
Validation loss: 2.558318959308966

Epoch: 559| Step: 0
Training loss: 0.19078638952457305
Validation loss: 2.5207885555831884

Epoch: 6| Step: 1
Training loss: 0.17279864433300962
Validation loss: 2.5176500075502948

Epoch: 6| Step: 2
Training loss: 0.0817227409201532
Validation loss: 2.5537751313369945

Epoch: 6| Step: 3
Training loss: 0.1380516608617049
Validation loss: 2.525774942280976

Epoch: 6| Step: 4
Training loss: 0.13461759979395668
Validation loss: 2.556437960615058

Epoch: 6| Step: 5
Training loss: 0.15415297207922865
Validation loss: 2.527662154555737

Epoch: 6| Step: 6
Training loss: 0.21837635144894751
Validation loss: 2.5301401198304627

Epoch: 6| Step: 7
Training loss: 0.14861103630200204
Validation loss: 2.5541894281744164

Epoch: 6| Step: 8
Training loss: 0.199754751235473
Validation loss: 2.5512468733117255

Epoch: 6| Step: 9
Training loss: 0.12501312723371472
Validation loss: 2.522430008501671

Epoch: 6| Step: 10
Training loss: 0.13596799990623096
Validation loss: 2.556264532995503

Epoch: 6| Step: 11
Training loss: 0.1185714815050348
Validation loss: 2.582343617162715

Epoch: 6| Step: 12
Training loss: 0.1759913248862372
Validation loss: 2.5537655333838014

Epoch: 6| Step: 13
Training loss: 0.1776536611537811
Validation loss: 2.6230163540679143

Epoch: 560| Step: 0
Training loss: 0.2646607681160816
Validation loss: 2.600983371171944

Epoch: 6| Step: 1
Training loss: 0.1781674652343401
Validation loss: 2.5760560545216347

Epoch: 6| Step: 2
Training loss: 0.14352256389532905
Validation loss: 2.5307705636716404

Epoch: 6| Step: 3
Training loss: 0.14172204252495874
Validation loss: 2.5869070402403653

Epoch: 6| Step: 4
Training loss: 0.16182178242051296
Validation loss: 2.579500452820388

Epoch: 6| Step: 5
Training loss: 0.17721918915983598
Validation loss: 2.5405362676910066

Epoch: 6| Step: 6
Training loss: 0.13873832077840792
Validation loss: 2.5515807094860743

Epoch: 6| Step: 7
Training loss: 0.19255484233266015
Validation loss: 2.559473578589378

Epoch: 6| Step: 8
Training loss: 0.23435253194562727
Validation loss: 2.5715123167169827

Epoch: 6| Step: 9
Training loss: 0.15958578578676394
Validation loss: 2.582233984640094

Epoch: 6| Step: 10
Training loss: 0.12290531295600539
Validation loss: 2.606120469763936

Epoch: 6| Step: 11
Training loss: 0.12967598731864033
Validation loss: 2.611040354798163

Epoch: 6| Step: 12
Training loss: 0.14635454782479318
Validation loss: 2.579989521574183

Epoch: 6| Step: 13
Training loss: 0.16890232553607457
Validation loss: 2.5759944879422827

Epoch: 561| Step: 0
Training loss: 0.08643860910335735
Validation loss: 2.6030045454127966

Epoch: 6| Step: 1
Training loss: 0.15946806780164427
Validation loss: 2.576423353423079

Epoch: 6| Step: 2
Training loss: 0.16367587446547557
Validation loss: 2.5774436579873004

Epoch: 6| Step: 3
Training loss: 0.27736336007435086
Validation loss: 2.59233278414322

Epoch: 6| Step: 4
Training loss: 0.13484664913875616
Validation loss: 2.6128459008437153

Epoch: 6| Step: 5
Training loss: 0.1656729696191411
Validation loss: 2.5700984401530698

Epoch: 6| Step: 6
Training loss: 0.11732425657309514
Validation loss: 2.5807658432614393

Epoch: 6| Step: 7
Training loss: 0.12726837776958416
Validation loss: 2.5817867244744512

Epoch: 6| Step: 8
Training loss: 0.17320532616269227
Validation loss: 2.54566010700693

Epoch: 6| Step: 9
Training loss: 0.15042454473262704
Validation loss: 2.556494554995079

Epoch: 6| Step: 10
Training loss: 0.20768775853024146
Validation loss: 2.5505028092022046

Epoch: 6| Step: 11
Training loss: 0.19355017948386213
Validation loss: 2.512999532997075

Epoch: 6| Step: 12
Training loss: 0.14321596055848754
Validation loss: 2.5509775069251717

Epoch: 6| Step: 13
Training loss: 0.08584420059656589
Validation loss: 2.5476446236429093

Epoch: 562| Step: 0
Training loss: 0.14534175280976763
Validation loss: 2.5342457174553377

Epoch: 6| Step: 1
Training loss: 0.13682257933103723
Validation loss: 2.5220571994741974

Epoch: 6| Step: 2
Training loss: 0.15789047005262138
Validation loss: 2.542144226875307

Epoch: 6| Step: 3
Training loss: 0.13757486689368936
Validation loss: 2.5512823968017235

Epoch: 6| Step: 4
Training loss: 0.15084551469494908
Validation loss: 2.570548081077043

Epoch: 6| Step: 5
Training loss: 0.18806026121070268
Validation loss: 2.519293728763441

Epoch: 6| Step: 6
Training loss: 0.1615357476171192
Validation loss: 2.5575759973901344

Epoch: 6| Step: 7
Training loss: 0.11685723814915024
Validation loss: 2.544419208937245

Epoch: 6| Step: 8
Training loss: 0.10109575935854952
Validation loss: 2.520906499338002

Epoch: 6| Step: 9
Training loss: 0.0723712059654708
Validation loss: 2.584317122888607

Epoch: 6| Step: 10
Training loss: 0.20597016829388823
Validation loss: 2.5558307136056184

Epoch: 6| Step: 11
Training loss: 0.28688858261864825
Validation loss: 2.5668239433717317

Epoch: 6| Step: 12
Training loss: 0.19691558979564364
Validation loss: 2.58354499404963

Epoch: 6| Step: 13
Training loss: 0.09324083543811187
Validation loss: 2.5549056987410523

Epoch: 563| Step: 0
Training loss: 0.2270125572269843
Validation loss: 2.5464832642061634

Epoch: 6| Step: 1
Training loss: 0.10924628892887193
Validation loss: 2.5565890140570136

Epoch: 6| Step: 2
Training loss: 0.10601005458042145
Validation loss: 2.5289454439737113

Epoch: 6| Step: 3
Training loss: 0.10756531155667108
Validation loss: 2.5429822296576194

Epoch: 6| Step: 4
Training loss: 0.14537826634170964
Validation loss: 2.48145439364309

Epoch: 6| Step: 5
Training loss: 0.15057262950629244
Validation loss: 2.5017913307255863

Epoch: 6| Step: 6
Training loss: 0.13211805041053196
Validation loss: 2.493589350744864

Epoch: 6| Step: 7
Training loss: 0.16020454283406577
Validation loss: 2.528200638914944

Epoch: 6| Step: 8
Training loss: 0.14630196976603518
Validation loss: 2.5142071401493133

Epoch: 6| Step: 9
Training loss: 0.10529566178144395
Validation loss: 2.4955386295673025

Epoch: 6| Step: 10
Training loss: 0.2499649276569918
Validation loss: 2.5149901591626893

Epoch: 6| Step: 11
Training loss: 0.1621074044441044
Validation loss: 2.505622930942431

Epoch: 6| Step: 12
Training loss: 0.15435241351554566
Validation loss: 2.583201017639863

Epoch: 6| Step: 13
Training loss: 0.1536814997111771
Validation loss: 2.5240554929075505

Epoch: 564| Step: 0
Training loss: 0.12256613552400251
Validation loss: 2.580387437100312

Epoch: 6| Step: 1
Training loss: 0.17805019029089195
Validation loss: 2.5159493758671827

Epoch: 6| Step: 2
Training loss: 0.12565282876386005
Validation loss: 2.546048042506759

Epoch: 6| Step: 3
Training loss: 0.11593559246858899
Validation loss: 2.5580606490879014

Epoch: 6| Step: 4
Training loss: 0.10389223954387233
Validation loss: 2.5577909619051997

Epoch: 6| Step: 5
Training loss: 0.0871543990301444
Validation loss: 2.5494958380379145

Epoch: 6| Step: 6
Training loss: 0.11887306907110444
Validation loss: 2.5494997491141573

Epoch: 6| Step: 7
Training loss: 0.14314306373171853
Validation loss: 2.5532160057153033

Epoch: 6| Step: 8
Training loss: 0.24761006800148416
Validation loss: 2.518799107893544

Epoch: 6| Step: 9
Training loss: 0.12796747217483556
Validation loss: 2.5238833409309387

Epoch: 6| Step: 10
Training loss: 0.13361487221631463
Validation loss: 2.554904670236485

Epoch: 6| Step: 11
Training loss: 0.14122759666682527
Validation loss: 2.5411525558045365

Epoch: 6| Step: 12
Training loss: 0.18803284352232613
Validation loss: 2.548782352119328

Epoch: 6| Step: 13
Training loss: 0.1921082876142868
Validation loss: 2.5734633536308755

Epoch: 565| Step: 0
Training loss: 0.11949438589392661
Validation loss: 2.558688155111462

Epoch: 6| Step: 1
Training loss: 0.14278020647026207
Validation loss: 2.5152336625882543

Epoch: 6| Step: 2
Training loss: 0.1109172198066609
Validation loss: 2.5231853422490227

Epoch: 6| Step: 3
Training loss: 0.11639139445451638
Validation loss: 2.539709442740428

Epoch: 6| Step: 4
Training loss: 0.18971635287961344
Validation loss: 2.5455475032685406

Epoch: 6| Step: 5
Training loss: 0.11732547505320345
Validation loss: 2.5016565351613145

Epoch: 6| Step: 6
Training loss: 0.1934282969933986
Validation loss: 2.5356213798214924

Epoch: 6| Step: 7
Training loss: 0.12431121839320095
Validation loss: 2.5140074620731143

Epoch: 6| Step: 8
Training loss: 0.14062684110919751
Validation loss: 2.527511091820091

Epoch: 6| Step: 9
Training loss: 0.11055786967784242
Validation loss: 2.5492756411527044

Epoch: 6| Step: 10
Training loss: 0.16084823331741643
Validation loss: 2.5449812155964193

Epoch: 6| Step: 11
Training loss: 0.15592175815148604
Validation loss: 2.541110066741289

Epoch: 6| Step: 12
Training loss: 0.12993256612660978
Validation loss: 2.5511630024713927

Epoch: 6| Step: 13
Training loss: 0.11709038763739199
Validation loss: 2.5819704524185583

Epoch: 566| Step: 0
Training loss: 0.107554397334898
Validation loss: 2.543908734224251

Epoch: 6| Step: 1
Training loss: 0.15378414141334582
Validation loss: 2.5715383656013135

Epoch: 6| Step: 2
Training loss: 0.17364467627519894
Validation loss: 2.572972850095631

Epoch: 6| Step: 3
Training loss: 0.13757208457263417
Validation loss: 2.538166757853675

Epoch: 6| Step: 4
Training loss: 0.15291621171959843
Validation loss: 2.5507497347236456

Epoch: 6| Step: 5
Training loss: 0.1158769520514915
Validation loss: 2.5790436610410272

Epoch: 6| Step: 6
Training loss: 0.15774251264087374
Validation loss: 2.5696688562815857

Epoch: 6| Step: 7
Training loss: 0.15042896525155872
Validation loss: 2.5798381941552813

Epoch: 6| Step: 8
Training loss: 0.08294192111162241
Validation loss: 2.585441215817495

Epoch: 6| Step: 9
Training loss: 0.09006944069435072
Validation loss: 2.562106119993721

Epoch: 6| Step: 10
Training loss: 0.07464527245184041
Validation loss: 2.5703113470004175

Epoch: 6| Step: 11
Training loss: 0.2785119451036289
Validation loss: 2.5399706881150137

Epoch: 6| Step: 12
Training loss: 0.11696915152957535
Validation loss: 2.539061736681802

Epoch: 6| Step: 13
Training loss: 0.08626027072865282
Validation loss: 2.574179762573773

Epoch: 567| Step: 0
Training loss: 0.09688799024978823
Validation loss: 2.559116924558981

Epoch: 6| Step: 1
Training loss: 0.1536248941754814
Validation loss: 2.5398286881043464

Epoch: 6| Step: 2
Training loss: 0.11009598564760419
Validation loss: 2.5534855696813734

Epoch: 6| Step: 3
Training loss: 0.09704368636771105
Validation loss: 2.5623321338157283

Epoch: 6| Step: 4
Training loss: 0.08853499712320667
Validation loss: 2.5993025179428626

Epoch: 6| Step: 5
Training loss: 0.13016014319982167
Validation loss: 2.562028065584531

Epoch: 6| Step: 6
Training loss: 0.11123985003127942
Validation loss: 2.5715406515580166

Epoch: 6| Step: 7
Training loss: 0.176717627156651
Validation loss: 2.566848103258226

Epoch: 6| Step: 8
Training loss: 0.16276467254160784
Validation loss: 2.5554247647749397

Epoch: 6| Step: 9
Training loss: 0.08207997509860823
Validation loss: 2.560687782172131

Epoch: 6| Step: 10
Training loss: 0.16529500178227563
Validation loss: 2.587885261726665

Epoch: 6| Step: 11
Training loss: 0.13051058418324474
Validation loss: 2.5617323255012074

Epoch: 6| Step: 12
Training loss: 0.17542327882744072
Validation loss: 2.5721878185874485

Epoch: 6| Step: 13
Training loss: 0.17739011099727545
Validation loss: 2.584125771054003

Epoch: 568| Step: 0
Training loss: 0.1444464318667781
Validation loss: 2.5756023048240877

Epoch: 6| Step: 1
Training loss: 0.18562345430263624
Validation loss: 2.589270427850085

Epoch: 6| Step: 2
Training loss: 0.20160045155598103
Validation loss: 2.520120753070943

Epoch: 6| Step: 3
Training loss: 0.09551894702248327
Validation loss: 2.5192263966405606

Epoch: 6| Step: 4
Training loss: 0.12138967349322377
Validation loss: 2.550074416535911

Epoch: 6| Step: 5
Training loss: 0.13470492170644724
Validation loss: 2.524069959241209

Epoch: 6| Step: 6
Training loss: 0.11289106784720497
Validation loss: 2.502048917206858

Epoch: 6| Step: 7
Training loss: 0.1008029374732957
Validation loss: 2.512052821239664

Epoch: 6| Step: 8
Training loss: 0.12917047211081445
Validation loss: 2.547139535353602

Epoch: 6| Step: 9
Training loss: 0.20841865084006284
Validation loss: 2.595073655756083

Epoch: 6| Step: 10
Training loss: 0.1567002603875926
Validation loss: 2.573004843433227

Epoch: 6| Step: 11
Training loss: 0.1366598070332916
Validation loss: 2.5955412820009505

Epoch: 6| Step: 12
Training loss: 0.10978952263084393
Validation loss: 2.5761129344277394

Epoch: 6| Step: 13
Training loss: 0.29479347364368347
Validation loss: 2.5398691667640394

Epoch: 569| Step: 0
Training loss: 0.12763354553621123
Validation loss: 2.5697223279889747

Epoch: 6| Step: 1
Training loss: 0.09544276809517038
Validation loss: 2.552040330442084

Epoch: 6| Step: 2
Training loss: 0.1362294296170326
Validation loss: 2.550158302569804

Epoch: 6| Step: 3
Training loss: 0.12155478528384943
Validation loss: 2.509891893426448

Epoch: 6| Step: 4
Training loss: 0.14111999970912528
Validation loss: 2.5190396138858366

Epoch: 6| Step: 5
Training loss: 0.09667622916461462
Validation loss: 2.5087556636824098

Epoch: 6| Step: 6
Training loss: 0.16923487110081073
Validation loss: 2.535486963193965

Epoch: 6| Step: 7
Training loss: 0.19849279376733253
Validation loss: 2.5447228279041125

Epoch: 6| Step: 8
Training loss: 0.14753949681127979
Validation loss: 2.5055231288811606

Epoch: 6| Step: 9
Training loss: 0.3013775846575386
Validation loss: 2.5578181377706093

Epoch: 6| Step: 10
Training loss: 0.1548554233900934
Validation loss: 2.5566932842450263

Epoch: 6| Step: 11
Training loss: 0.1525486888119285
Validation loss: 2.57537601368671

Epoch: 6| Step: 12
Training loss: 0.18632132879694455
Validation loss: 2.576546506404791

Epoch: 6| Step: 13
Training loss: 0.1675389023875892
Validation loss: 2.5807755374853607

Epoch: 570| Step: 0
Training loss: 0.14257995395271178
Validation loss: 2.5634497206416014

Epoch: 6| Step: 1
Training loss: 0.09421901802480352
Validation loss: 2.561915638400861

Epoch: 6| Step: 2
Training loss: 0.2262712201157106
Validation loss: 2.5408484441201007

Epoch: 6| Step: 3
Training loss: 0.20242927687909792
Validation loss: 2.511313302332386

Epoch: 6| Step: 4
Training loss: 0.15777755529815402
Validation loss: 2.5503517737454184

Epoch: 6| Step: 5
Training loss: 0.163889350801785
Validation loss: 2.5458258239346403

Epoch: 6| Step: 6
Training loss: 0.12253447975536938
Validation loss: 2.54682861020139

Epoch: 6| Step: 7
Training loss: 0.13869096060497144
Validation loss: 2.5585362952484574

Epoch: 6| Step: 8
Training loss: 0.15282083049838688
Validation loss: 2.574249042826522

Epoch: 6| Step: 9
Training loss: 0.11034987878780898
Validation loss: 2.5530401074189175

Epoch: 6| Step: 10
Training loss: 0.14601546576844868
Validation loss: 2.5373229266636828

Epoch: 6| Step: 11
Training loss: 0.10225343887339453
Validation loss: 2.530692775114765

Epoch: 6| Step: 12
Training loss: 0.20780295371594343
Validation loss: 2.584078899162043

Epoch: 6| Step: 13
Training loss: 0.1558076736916903
Validation loss: 2.542380460838842

Epoch: 571| Step: 0
Training loss: 0.2780659500400203
Validation loss: 2.572563088968854

Epoch: 6| Step: 1
Training loss: 0.20435535585855513
Validation loss: 2.5559569340185813

Epoch: 6| Step: 2
Training loss: 0.11305857839684084
Validation loss: 2.5818171688011304

Epoch: 6| Step: 3
Training loss: 0.08459582747806813
Validation loss: 2.572681753225362

Epoch: 6| Step: 4
Training loss: 0.22023328209125786
Validation loss: 2.582041331658072

Epoch: 6| Step: 5
Training loss: 0.1647530905295494
Validation loss: 2.5645150476271406

Epoch: 6| Step: 6
Training loss: 0.11820139177089166
Validation loss: 2.593634663011691

Epoch: 6| Step: 7
Training loss: 0.12940899750078114
Validation loss: 2.5563442917365102

Epoch: 6| Step: 8
Training loss: 0.1708576589706615
Validation loss: 2.619214070924735

Epoch: 6| Step: 9
Training loss: 0.2053233995984636
Validation loss: 2.595659602944554

Epoch: 6| Step: 10
Training loss: 0.1837044747229931
Validation loss: 2.5587646838085245

Epoch: 6| Step: 11
Training loss: 0.17021144112859016
Validation loss: 2.559815948731727

Epoch: 6| Step: 12
Training loss: 0.10889613534212729
Validation loss: 2.5041291039462408

Epoch: 6| Step: 13
Training loss: 0.1323853242556507
Validation loss: 2.5087546499798554

Epoch: 572| Step: 0
Training loss: 0.08817912541387163
Validation loss: 2.5067261198272264

Epoch: 6| Step: 1
Training loss: 0.12981998386767304
Validation loss: 2.4873450201429974

Epoch: 6| Step: 2
Training loss: 0.155180699466766
Validation loss: 2.4941373430238944

Epoch: 6| Step: 3
Training loss: 0.24285525127258248
Validation loss: 2.4772162865352985

Epoch: 6| Step: 4
Training loss: 0.13461820860143334
Validation loss: 2.5172969566565464

Epoch: 6| Step: 5
Training loss: 0.15708473869811482
Validation loss: 2.4759313068156943

Epoch: 6| Step: 6
Training loss: 0.12031314728921931
Validation loss: 2.54260250159881

Epoch: 6| Step: 7
Training loss: 0.16731768112083442
Validation loss: 2.468851057034906

Epoch: 6| Step: 8
Training loss: 0.10790047235319213
Validation loss: 2.5242512541806605

Epoch: 6| Step: 9
Training loss: 0.17837430172190763
Validation loss: 2.5098426939486025

Epoch: 6| Step: 10
Training loss: 0.12058730896051545
Validation loss: 2.5332883352656057

Epoch: 6| Step: 11
Training loss: 0.11040278739638953
Validation loss: 2.5491679660494104

Epoch: 6| Step: 12
Training loss: 0.14405032640189783
Validation loss: 2.575085485154261

Epoch: 6| Step: 13
Training loss: 0.11800798243763269
Validation loss: 2.549441287979509

Epoch: 573| Step: 0
Training loss: 0.19416043969089444
Validation loss: 2.577857769900847

Epoch: 6| Step: 1
Training loss: 0.13223330341100092
Validation loss: 2.5568336788638835

Epoch: 6| Step: 2
Training loss: 0.20363558274314253
Validation loss: 2.5419306924728566

Epoch: 6| Step: 3
Training loss: 0.12066306541996628
Validation loss: 2.5661726893222405

Epoch: 6| Step: 4
Training loss: 0.12518419165770084
Validation loss: 2.5502617796734777

Epoch: 6| Step: 5
Training loss: 0.08913830910431682
Validation loss: 2.555397413976105

Epoch: 6| Step: 6
Training loss: 0.0709106021092295
Validation loss: 2.5170865759102212

Epoch: 6| Step: 7
Training loss: 0.1301105052293742
Validation loss: 2.546065558648773

Epoch: 6| Step: 8
Training loss: 0.08798364908640068
Validation loss: 2.5304971200940654

Epoch: 6| Step: 9
Training loss: 0.1420362574677663
Validation loss: 2.4871917934373013

Epoch: 6| Step: 10
Training loss: 0.2249518561513242
Validation loss: 2.526392173658594

Epoch: 6| Step: 11
Training loss: 0.2475969258564173
Validation loss: 2.4843590905434754

Epoch: 6| Step: 12
Training loss: 0.11021095365006471
Validation loss: 2.569778115039069

Epoch: 6| Step: 13
Training loss: 0.06484836711302047
Validation loss: 2.5255023718489684

Epoch: 574| Step: 0
Training loss: 0.2169311039167735
Validation loss: 2.5287720707539347

Epoch: 6| Step: 1
Training loss: 0.16607575169223346
Validation loss: 2.574789914629811

Epoch: 6| Step: 2
Training loss: 0.3555729262737211
Validation loss: 2.540031274792417

Epoch: 6| Step: 3
Training loss: 0.14519719758656066
Validation loss: 2.5046124137879633

Epoch: 6| Step: 4
Training loss: 0.15404234184600926
Validation loss: 2.49966811776694

Epoch: 6| Step: 5
Training loss: 0.11242489393845098
Validation loss: 2.481518522717131

Epoch: 6| Step: 6
Training loss: 0.1749996930358102
Validation loss: 2.5006549366994295

Epoch: 6| Step: 7
Training loss: 0.19922752922011747
Validation loss: 2.486751050923817

Epoch: 6| Step: 8
Training loss: 0.20944873522064486
Validation loss: 2.4551480177981344

Epoch: 6| Step: 9
Training loss: 0.13966620272230845
Validation loss: 2.450143399226476

Epoch: 6| Step: 10
Training loss: 0.134202707528724
Validation loss: 2.467321404914578

Epoch: 6| Step: 11
Training loss: 0.2691310454547582
Validation loss: 2.4820084561324744

Epoch: 6| Step: 12
Training loss: 0.22509011775238216
Validation loss: 2.5357661439304526

Epoch: 6| Step: 13
Training loss: 0.21533722125176144
Validation loss: 2.521404970042781

Epoch: 575| Step: 0
Training loss: 0.17266845703125
Validation loss: 2.4965983598135097

Epoch: 6| Step: 1
Training loss: 0.2258239992715425
Validation loss: 2.535679492301963

Epoch: 6| Step: 2
Training loss: 0.2171855483893661
Validation loss: 2.5184385936653104

Epoch: 6| Step: 3
Training loss: 0.2135061936261795
Validation loss: 2.527855926403079

Epoch: 6| Step: 4
Training loss: 0.17305961846129037
Validation loss: 2.512679008449898

Epoch: 6| Step: 5
Training loss: 0.16279718110985447
Validation loss: 2.49985550801274

Epoch: 6| Step: 6
Training loss: 0.16801674844569675
Validation loss: 2.568346657377021

Epoch: 6| Step: 7
Training loss: 0.2784594271810227
Validation loss: 2.569140484261933

Epoch: 6| Step: 8
Training loss: 0.2840918310107098
Validation loss: 2.5684597003740395

Epoch: 6| Step: 9
Training loss: 0.1306667760957816
Validation loss: 2.5553801955535524

Epoch: 6| Step: 10
Training loss: 0.15711532828093203
Validation loss: 2.5201783107634013

Epoch: 6| Step: 11
Training loss: 0.13317125616004793
Validation loss: 2.539476074663423

Epoch: 6| Step: 12
Training loss: 0.14896303555151516
Validation loss: 2.528750357840513

Epoch: 6| Step: 13
Training loss: 0.10804307096546757
Validation loss: 2.5483041781358273

Epoch: 576| Step: 0
Training loss: 0.2551501833912248
Validation loss: 2.5292967026916693

Epoch: 6| Step: 1
Training loss: 0.21919998650109204
Validation loss: 2.524307853178346

Epoch: 6| Step: 2
Training loss: 0.15013466765262057
Validation loss: 2.524692424640118

Epoch: 6| Step: 3
Training loss: 0.1424063863194851
Validation loss: 2.4924771445360916

Epoch: 6| Step: 4
Training loss: 0.1845388436107614
Validation loss: 2.512861828133468

Epoch: 6| Step: 5
Training loss: 0.24059673056569095
Validation loss: 2.509889093727019

Epoch: 6| Step: 6
Training loss: 0.1990835348031515
Validation loss: 2.53152453798419

Epoch: 6| Step: 7
Training loss: 0.23364771216480792
Validation loss: 2.5225600638477226

Epoch: 6| Step: 8
Training loss: 0.12645893745916983
Validation loss: 2.5496007416938453

Epoch: 6| Step: 9
Training loss: 0.10474883851782145
Validation loss: 2.548612984910523

Epoch: 6| Step: 10
Training loss: 0.14085866799920282
Validation loss: 2.5413661596237898

Epoch: 6| Step: 11
Training loss: 0.10042356143756272
Validation loss: 2.5591102567845874

Epoch: 6| Step: 12
Training loss: 0.13854857456820727
Validation loss: 2.567799883770004

Epoch: 6| Step: 13
Training loss: 0.19246040754514324
Validation loss: 2.558730093285241

Epoch: 577| Step: 0
Training loss: 0.19924836780066238
Validation loss: 2.5389841875063404

Epoch: 6| Step: 1
Training loss: 0.16479593912446452
Validation loss: 2.598970964622065

Epoch: 6| Step: 2
Training loss: 0.12269269210533663
Validation loss: 2.594946139571738

Epoch: 6| Step: 3
Training loss: 0.20078938426895931
Validation loss: 2.5812159758424014

Epoch: 6| Step: 4
Training loss: 0.1312600095088337
Validation loss: 2.5512671432252354

Epoch: 6| Step: 5
Training loss: 0.24120427327081362
Validation loss: 2.537945454296322

Epoch: 6| Step: 6
Training loss: 0.20228455977588125
Validation loss: 2.5600113167563894

Epoch: 6| Step: 7
Training loss: 0.17600580812855732
Validation loss: 2.537901910995233

Epoch: 6| Step: 8
Training loss: 0.16191074542799574
Validation loss: 2.530190553377546

Epoch: 6| Step: 9
Training loss: 0.18568192636630612
Validation loss: 2.518849489134249

Epoch: 6| Step: 10
Training loss: 0.19196051513891202
Validation loss: 2.5308759851804883

Epoch: 6| Step: 11
Training loss: 0.16399831310973276
Validation loss: 2.541747276672627

Epoch: 6| Step: 12
Training loss: 0.22060284826200724
Validation loss: 2.5569883448661797

Epoch: 6| Step: 13
Training loss: 0.2710767059025171
Validation loss: 2.560503288029409

Epoch: 578| Step: 0
Training loss: 0.18315276488779816
Validation loss: 2.550684091807211

Epoch: 6| Step: 1
Training loss: 0.15184503010384712
Validation loss: 2.6029645708974702

Epoch: 6| Step: 2
Training loss: 0.16499874367380135
Validation loss: 2.60437211011807

Epoch: 6| Step: 3
Training loss: 0.19112525477495296
Validation loss: 2.568677771674377

Epoch: 6| Step: 4
Training loss: 0.13263977262969254
Validation loss: 2.530534250862893

Epoch: 6| Step: 5
Training loss: 0.06969848396034957
Validation loss: 2.5916823512462885

Epoch: 6| Step: 6
Training loss: 0.16575684855014927
Validation loss: 2.598697365575997

Epoch: 6| Step: 7
Training loss: 0.06564343114156389
Validation loss: 2.544401486498331

Epoch: 6| Step: 8
Training loss: 0.17377175799505185
Validation loss: 2.574415843176279

Epoch: 6| Step: 9
Training loss: 0.20022692547059406
Validation loss: 2.547676161229864

Epoch: 6| Step: 10
Training loss: 0.16517471065943362
Validation loss: 2.545502510835446

Epoch: 6| Step: 11
Training loss: 0.14823001238616748
Validation loss: 2.5494314464509173

Epoch: 6| Step: 12
Training loss: 0.16403451749040335
Validation loss: 2.566921704116886

Epoch: 6| Step: 13
Training loss: 0.13533220882131605
Validation loss: 2.5512703245781614

Epoch: 579| Step: 0
Training loss: 0.09649404369203061
Validation loss: 2.5692289659128833

Epoch: 6| Step: 1
Training loss: 0.19126955328198866
Validation loss: 2.555701254450146

Epoch: 6| Step: 2
Training loss: 0.1620666321166251
Validation loss: 2.548396777419809

Epoch: 6| Step: 3
Training loss: 0.15090292211707482
Validation loss: 2.5561974867133306

Epoch: 6| Step: 4
Training loss: 0.11310824798399814
Validation loss: 2.527213498547311

Epoch: 6| Step: 5
Training loss: 0.1748636082493104
Validation loss: 2.5129799868153277

Epoch: 6| Step: 6
Training loss: 0.15740175733919745
Validation loss: 2.511537262884063

Epoch: 6| Step: 7
Training loss: 0.14345393245666305
Validation loss: 2.5325478531144974

Epoch: 6| Step: 8
Training loss: 0.18725536202137139
Validation loss: 2.489633497289776

Epoch: 6| Step: 9
Training loss: 0.13884004952777407
Validation loss: 2.508382672174953

Epoch: 6| Step: 10
Training loss: 0.09177547570645384
Validation loss: 2.520824562192414

Epoch: 6| Step: 11
Training loss: 0.15829484541328687
Validation loss: 2.5085464950591323

Epoch: 6| Step: 12
Training loss: 0.20787422833726693
Validation loss: 2.5156021030499645

Epoch: 6| Step: 13
Training loss: 0.21253266118594524
Validation loss: 2.5286549531397426

Epoch: 580| Step: 0
Training loss: 0.15520184143835242
Validation loss: 2.541200326399844

Epoch: 6| Step: 1
Training loss: 0.14905418113871616
Validation loss: 2.523247293110316

Epoch: 6| Step: 2
Training loss: 0.1687535482051247
Validation loss: 2.5405555675550455

Epoch: 6| Step: 3
Training loss: 0.19902734350203083
Validation loss: 2.5595153546536906

Epoch: 6| Step: 4
Training loss: 0.20113478013033945
Validation loss: 2.596152382935456

Epoch: 6| Step: 5
Training loss: 0.16922741969011987
Validation loss: 2.5471712296609015

Epoch: 6| Step: 6
Training loss: 0.1485628489725735
Validation loss: 2.542724996407662

Epoch: 6| Step: 7
Training loss: 0.1374904379987777
Validation loss: 2.5731395657930696

Epoch: 6| Step: 8
Training loss: 0.12004681983905773
Validation loss: 2.5570002311819593

Epoch: 6| Step: 9
Training loss: 0.10905246350963667
Validation loss: 2.560239989787713

Epoch: 6| Step: 10
Training loss: 0.1403524353441871
Validation loss: 2.602360808965165

Epoch: 6| Step: 11
Training loss: 0.21942170929652924
Validation loss: 2.5359503350253307

Epoch: 6| Step: 12
Training loss: 0.20529802431028304
Validation loss: 2.561220063006084

Epoch: 6| Step: 13
Training loss: 0.08591307217033343
Validation loss: 2.521008886009232

Epoch: 581| Step: 0
Training loss: 0.1296301801238721
Validation loss: 2.539785624755952

Epoch: 6| Step: 1
Training loss: 0.20541263727900708
Validation loss: 2.492998068824429

Epoch: 6| Step: 2
Training loss: 0.1255962189637905
Validation loss: 2.4702876183131073

Epoch: 6| Step: 3
Training loss: 0.20830310761216309
Validation loss: 2.462897299288056

Epoch: 6| Step: 4
Training loss: 0.10768678252954746
Validation loss: 2.4619719560937483

Epoch: 6| Step: 5
Training loss: 0.12020634234540938
Validation loss: 2.4441625989462055

Epoch: 6| Step: 6
Training loss: 0.14873038434071942
Validation loss: 2.496000646207674

Epoch: 6| Step: 7
Training loss: 0.14603215030700395
Validation loss: 2.4797370056751626

Epoch: 6| Step: 8
Training loss: 0.18106554116120258
Validation loss: 2.4803392354019107

Epoch: 6| Step: 9
Training loss: 0.13731693468238257
Validation loss: 2.5082800276702586

Epoch: 6| Step: 10
Training loss: 0.08938756480960793
Validation loss: 2.4884204706749773

Epoch: 6| Step: 11
Training loss: 0.09753566927005124
Validation loss: 2.5402738714618605

Epoch: 6| Step: 12
Training loss: 0.1609807250390252
Validation loss: 2.5003518872105697

Epoch: 6| Step: 13
Training loss: 0.06583862120795538
Validation loss: 2.523899604090691

Epoch: 582| Step: 0
Training loss: 0.1896893709520959
Validation loss: 2.5095179935554737

Epoch: 6| Step: 1
Training loss: 0.11867163152085843
Validation loss: 2.4992937608140378

Epoch: 6| Step: 2
Training loss: 0.2171005665082494
Validation loss: 2.521500278974092

Epoch: 6| Step: 3
Training loss: 0.11336038554849946
Validation loss: 2.507076075692848

Epoch: 6| Step: 4
Training loss: 0.11696405964216455
Validation loss: 2.5480494506253657

Epoch: 6| Step: 5
Training loss: 0.16860530795976633
Validation loss: 2.518860352919978

Epoch: 6| Step: 6
Training loss: 0.12906056617414888
Validation loss: 2.5351590349417297

Epoch: 6| Step: 7
Training loss: 0.10199797327176188
Validation loss: 2.5043918579686903

Epoch: 6| Step: 8
Training loss: 0.10197448616307526
Validation loss: 2.517175205331279

Epoch: 6| Step: 9
Training loss: 0.1661017587153806
Validation loss: 2.5345831836598043

Epoch: 6| Step: 10
Training loss: 0.1832107038089361
Validation loss: 2.502739359167622

Epoch: 6| Step: 11
Training loss: 0.16495217061758127
Validation loss: 2.5179035270474475

Epoch: 6| Step: 12
Training loss: 0.13099357499043995
Validation loss: 2.494308064806375

Epoch: 6| Step: 13
Training loss: 0.14709359322898782
Validation loss: 2.4562218713494843

Epoch: 583| Step: 0
Training loss: 0.07939538134111575
Validation loss: 2.5150512171391863

Epoch: 6| Step: 1
Training loss: 0.10551807345195065
Validation loss: 2.503666002837878

Epoch: 6| Step: 2
Training loss: 0.1117629585628
Validation loss: 2.491082120849052

Epoch: 6| Step: 3
Training loss: 0.05908264207130136
Validation loss: 2.492131968642792

Epoch: 6| Step: 4
Training loss: 0.1310550593045414
Validation loss: 2.5231178777439642

Epoch: 6| Step: 5
Training loss: 0.19574013624637118
Validation loss: 2.4928689815002767

Epoch: 6| Step: 6
Training loss: 0.09618153497227469
Validation loss: 2.5049940557460295

Epoch: 6| Step: 7
Training loss: 0.11738243182306242
Validation loss: 2.480491514443022

Epoch: 6| Step: 8
Training loss: 0.1382279476518308
Validation loss: 2.5291962084460855

Epoch: 6| Step: 9
Training loss: 0.12447976843104559
Validation loss: 2.524236883337745

Epoch: 6| Step: 10
Training loss: 0.11750882917062898
Validation loss: 2.537090073171635

Epoch: 6| Step: 11
Training loss: 0.09825729420814815
Validation loss: 2.5141295039508957

Epoch: 6| Step: 12
Training loss: 0.21408886503482796
Validation loss: 2.510807812779412

Epoch: 6| Step: 13
Training loss: 0.17912495708864368
Validation loss: 2.536357997845224

Epoch: 584| Step: 0
Training loss: 0.11987955732205138
Validation loss: 2.5209274525277174

Epoch: 6| Step: 1
Training loss: 0.12276291628283323
Validation loss: 2.5146989870232446

Epoch: 6| Step: 2
Training loss: 0.1890703148448385
Validation loss: 2.5332880134555054

Epoch: 6| Step: 3
Training loss: 0.10840338618349227
Validation loss: 2.560895803335413

Epoch: 6| Step: 4
Training loss: 0.07548649873393215
Validation loss: 2.5416069015329708

Epoch: 6| Step: 5
Training loss: 0.12181777007767806
Validation loss: 2.4954035825444927

Epoch: 6| Step: 6
Training loss: 0.18504577028640048
Validation loss: 2.540657913113281

Epoch: 6| Step: 7
Training loss: 0.10371302730085567
Validation loss: 2.5139101838802866

Epoch: 6| Step: 8
Training loss: 0.12979792208494328
Validation loss: 2.5408983856415603

Epoch: 6| Step: 9
Training loss: 0.10932358316591206
Validation loss: 2.5131759232697277

Epoch: 6| Step: 10
Training loss: 0.11238804916045711
Validation loss: 2.522409443841444

Epoch: 6| Step: 11
Training loss: 0.1675359450566318
Validation loss: 2.5196918207125614

Epoch: 6| Step: 12
Training loss: 0.08716535672448184
Validation loss: 2.497093031341863

Epoch: 6| Step: 13
Training loss: 0.18788223247858102
Validation loss: 2.5091841043663226

Epoch: 585| Step: 0
Training loss: 0.10576199014616547
Validation loss: 2.5457213135588157

Epoch: 6| Step: 1
Training loss: 0.09527218876888774
Validation loss: 2.526009887725455

Epoch: 6| Step: 2
Training loss: 0.08978735148725478
Validation loss: 2.4902924955415093

Epoch: 6| Step: 3
Training loss: 0.17848824347386538
Validation loss: 2.515431499535886

Epoch: 6| Step: 4
Training loss: 0.10135490953180384
Validation loss: 2.520094518584999

Epoch: 6| Step: 5
Training loss: 0.10716300463420252
Validation loss: 2.5406567345473117

Epoch: 6| Step: 6
Training loss: 0.10202535285089483
Validation loss: 2.522327532141896

Epoch: 6| Step: 7
Training loss: 0.10611875120093651
Validation loss: 2.512716539235239

Epoch: 6| Step: 8
Training loss: 0.18914967253331702
Validation loss: 2.5583109115906577

Epoch: 6| Step: 9
Training loss: 0.1616977728723638
Validation loss: 2.5327876788419603

Epoch: 6| Step: 10
Training loss: 0.07764003854527413
Validation loss: 2.5149492494891263

Epoch: 6| Step: 11
Training loss: 0.08548579114547317
Validation loss: 2.5510446059835385

Epoch: 6| Step: 12
Training loss: 0.11259773830070054
Validation loss: 2.559554399184849

Epoch: 6| Step: 13
Training loss: 0.07268080142735067
Validation loss: 2.5464516957372787

Epoch: 586| Step: 0
Training loss: 0.13790115229807776
Validation loss: 2.5096752603915276

Epoch: 6| Step: 1
Training loss: 0.10180914713383464
Validation loss: 2.5346058899222026

Epoch: 6| Step: 2
Training loss: 0.09534523667508332
Validation loss: 2.5390197482741867

Epoch: 6| Step: 3
Training loss: 0.1089154962393725
Validation loss: 2.507103080897588

Epoch: 6| Step: 4
Training loss: 0.14400286358645076
Validation loss: 2.533576584799574

Epoch: 6| Step: 5
Training loss: 0.08907113409855419
Validation loss: 2.508380148783294

Epoch: 6| Step: 6
Training loss: 0.0979065215362402
Validation loss: 2.493922409926654

Epoch: 6| Step: 7
Training loss: 0.18814031224968905
Validation loss: 2.5050356908648808

Epoch: 6| Step: 8
Training loss: 0.07231126774399038
Validation loss: 2.497843290466746

Epoch: 6| Step: 9
Training loss: 0.1055595395715967
Validation loss: 2.5128083768504763

Epoch: 6| Step: 10
Training loss: 0.22394450093216614
Validation loss: 2.5236466066931693

Epoch: 6| Step: 11
Training loss: 0.09133389576284251
Validation loss: 2.4806457523557697

Epoch: 6| Step: 12
Training loss: 0.09644408369305109
Validation loss: 2.5071890989641963

Epoch: 6| Step: 13
Training loss: 0.11632998163344124
Validation loss: 2.5216753278995814

Epoch: 587| Step: 0
Training loss: 0.14230763238859254
Validation loss: 2.5186683875865907

Epoch: 6| Step: 1
Training loss: 0.17994505626504706
Validation loss: 2.547841287698469

Epoch: 6| Step: 2
Training loss: 0.1335136823362177
Validation loss: 2.5262278549205153

Epoch: 6| Step: 3
Training loss: 0.0803420323685709
Validation loss: 2.5523484933375045

Epoch: 6| Step: 4
Training loss: 0.11543367414480402
Validation loss: 2.536497404642334

Epoch: 6| Step: 5
Training loss: 0.11043474556208668
Validation loss: 2.55355769135449

Epoch: 6| Step: 6
Training loss: 0.15968873825078395
Validation loss: 2.563504198119726

Epoch: 6| Step: 7
Training loss: 0.18243635883869588
Validation loss: 2.55977403786246

Epoch: 6| Step: 8
Training loss: 0.13234213676054876
Validation loss: 2.572218187158699

Epoch: 6| Step: 9
Training loss: 0.1183253598199262
Validation loss: 2.5741638549207826

Epoch: 6| Step: 10
Training loss: 0.1193454888450123
Validation loss: 2.56468215818217

Epoch: 6| Step: 11
Training loss: 0.12633419284154923
Validation loss: 2.5745320192456482

Epoch: 6| Step: 12
Training loss: 0.0940342062237904
Validation loss: 2.5656930162103513

Epoch: 6| Step: 13
Training loss: 0.1922775600283259
Validation loss: 2.612890881119683

Epoch: 588| Step: 0
Training loss: 0.10398876276940427
Validation loss: 2.5961040277138676

Epoch: 6| Step: 1
Training loss: 0.0919854884533034
Validation loss: 2.5832515793592035

Epoch: 6| Step: 2
Training loss: 0.10609622900458499
Validation loss: 2.571751766302361

Epoch: 6| Step: 3
Training loss: 0.10979445102709104
Validation loss: 2.5831114326016085

Epoch: 6| Step: 4
Training loss: 0.1927874033467317
Validation loss: 2.572327372516

Epoch: 6| Step: 5
Training loss: 0.16726953218610235
Validation loss: 2.587462029345188

Epoch: 6| Step: 6
Training loss: 0.1398988359526251
Validation loss: 2.572807732841296

Epoch: 6| Step: 7
Training loss: 0.12106166691461447
Validation loss: 2.5654916904810605

Epoch: 6| Step: 8
Training loss: 0.15792459529240901
Validation loss: 2.54685485517823

Epoch: 6| Step: 9
Training loss: 0.18263263943012029
Validation loss: 2.552146056666176

Epoch: 6| Step: 10
Training loss: 0.10953817797312475
Validation loss: 2.5608096005907908

Epoch: 6| Step: 11
Training loss: 0.10640959184078988
Validation loss: 2.55078980489764

Epoch: 6| Step: 12
Training loss: 0.16754239886380107
Validation loss: 2.605881026190804

Epoch: 6| Step: 13
Training loss: 0.10131132262279431
Validation loss: 2.5598838511358375

Epoch: 589| Step: 0
Training loss: 0.1626514197007027
Validation loss: 2.6022466368317603

Epoch: 6| Step: 1
Training loss: 0.23517347855680518
Validation loss: 2.5635804940448947

Epoch: 6| Step: 2
Training loss: 0.1015204562681134
Validation loss: 2.579319824901456

Epoch: 6| Step: 3
Training loss: 0.17501449248215933
Validation loss: 2.5688575616120435

Epoch: 6| Step: 4
Training loss: 0.12029680143463822
Validation loss: 2.551665788303689

Epoch: 6| Step: 5
Training loss: 0.1442741349481717
Validation loss: 2.566750093508441

Epoch: 6| Step: 6
Training loss: 0.12769749368535885
Validation loss: 2.5770417742886846

Epoch: 6| Step: 7
Training loss: 0.14946277298123534
Validation loss: 2.578971859438396

Epoch: 6| Step: 8
Training loss: 0.13442859800545376
Validation loss: 2.5595017577381647

Epoch: 6| Step: 9
Training loss: 0.09926643896317103
Validation loss: 2.5673670125147394

Epoch: 6| Step: 10
Training loss: 0.13899912300793738
Validation loss: 2.5888727032186885

Epoch: 6| Step: 11
Training loss: 0.10312890294665504
Validation loss: 2.582546065214027

Epoch: 6| Step: 12
Training loss: 0.12677921708103557
Validation loss: 2.563972530266409

Epoch: 6| Step: 13
Training loss: 0.10002979211033854
Validation loss: 2.5505061855024245

Epoch: 590| Step: 0
Training loss: 0.14816194606710606
Validation loss: 2.5726338716408232

Epoch: 6| Step: 1
Training loss: 0.17418107621879167
Validation loss: 2.545832521467236

Epoch: 6| Step: 2
Training loss: 0.10981580768189095
Validation loss: 2.575698123951747

Epoch: 6| Step: 3
Training loss: 0.22294836791883307
Validation loss: 2.5269793021194453

Epoch: 6| Step: 4
Training loss: 0.10581249275759533
Validation loss: 2.540637709914486

Epoch: 6| Step: 5
Training loss: 0.13250590446200042
Validation loss: 2.5265719565128455

Epoch: 6| Step: 6
Training loss: 0.10617898731254839
Validation loss: 2.5656793231360835

Epoch: 6| Step: 7
Training loss: 0.1462007255870991
Validation loss: 2.5610943887649107

Epoch: 6| Step: 8
Training loss: 0.1650928319435798
Validation loss: 2.5418503659772553

Epoch: 6| Step: 9
Training loss: 0.0836536638403777
Validation loss: 2.548854527917986

Epoch: 6| Step: 10
Training loss: 0.1656152834831186
Validation loss: 2.536591114103624

Epoch: 6| Step: 11
Training loss: 0.07398060815238981
Validation loss: 2.5321832797610972

Epoch: 6| Step: 12
Training loss: 0.14046592457086368
Validation loss: 2.486203949183798

Epoch: 6| Step: 13
Training loss: 0.14163235954285042
Validation loss: 2.5469769577534036

Epoch: 591| Step: 0
Training loss: 0.12937194339163705
Validation loss: 2.5429511691769617

Epoch: 6| Step: 1
Training loss: 0.13358628436192502
Validation loss: 2.532405344000281

Epoch: 6| Step: 2
Training loss: 0.09484065941640893
Validation loss: 2.5183875476145308

Epoch: 6| Step: 3
Training loss: 0.10606309530746376
Validation loss: 2.493360351119777

Epoch: 6| Step: 4
Training loss: 0.17477547811768265
Validation loss: 2.5033893641374036

Epoch: 6| Step: 5
Training loss: 0.1549864762409234
Validation loss: 2.489699529660836

Epoch: 6| Step: 6
Training loss: 0.07537646271799113
Validation loss: 2.4901022071517604

Epoch: 6| Step: 7
Training loss: 0.1095543438363957
Validation loss: 2.466757337117109

Epoch: 6| Step: 8
Training loss: 0.1760838447262634
Validation loss: 2.5194881205624546

Epoch: 6| Step: 9
Training loss: 0.09361270944956737
Validation loss: 2.513680656141062

Epoch: 6| Step: 10
Training loss: 0.17516993612098203
Validation loss: 2.475281096855683

Epoch: 6| Step: 11
Training loss: 0.1595257525286092
Validation loss: 2.5030352645528153

Epoch: 6| Step: 12
Training loss: 0.17614751380924903
Validation loss: 2.505818793522958

Epoch: 6| Step: 13
Training loss: 0.14047164635011347
Validation loss: 2.5398398447063024

Epoch: 592| Step: 0
Training loss: 0.061446774114308565
Validation loss: 2.5088643390085923

Epoch: 6| Step: 1
Training loss: 0.10653623582385777
Validation loss: 2.5211653938601346

Epoch: 6| Step: 2
Training loss: 0.16605430040334568
Validation loss: 2.5501361600252697

Epoch: 6| Step: 3
Training loss: 0.10083152825372643
Validation loss: 2.540679680159762

Epoch: 6| Step: 4
Training loss: 0.08321556571400508
Validation loss: 2.552901746067802

Epoch: 6| Step: 5
Training loss: 0.10603240184681087
Validation loss: 2.5140028762862277

Epoch: 6| Step: 6
Training loss: 0.12261619202281741
Validation loss: 2.576560583499281

Epoch: 6| Step: 7
Training loss: 0.12670235441940053
Validation loss: 2.4919917959160083

Epoch: 6| Step: 8
Training loss: 0.14033348279187693
Validation loss: 2.5414772211888157

Epoch: 6| Step: 9
Training loss: 0.09417602973394766
Validation loss: 2.5458421110626177

Epoch: 6| Step: 10
Training loss: 0.07351442604627738
Validation loss: 2.5211725148328643

Epoch: 6| Step: 11
Training loss: 0.1950969842144387
Validation loss: 2.5123963581720528

Epoch: 6| Step: 12
Training loss: 0.09658335211364595
Validation loss: 2.501448746801327

Epoch: 6| Step: 13
Training loss: 0.1825677937501163
Validation loss: 2.5051163699223977

Epoch: 593| Step: 0
Training loss: 0.06902858282102596
Validation loss: 2.520070222780223

Epoch: 6| Step: 1
Training loss: 0.11332549677985448
Validation loss: 2.5144029830161743

Epoch: 6| Step: 2
Training loss: 0.11049376667817065
Validation loss: 2.4768368334958004

Epoch: 6| Step: 3
Training loss: 0.17734266440441582
Validation loss: 2.5435951131534806

Epoch: 6| Step: 4
Training loss: 0.08075999208516496
Validation loss: 2.481128602599336

Epoch: 6| Step: 5
Training loss: 0.11062241120191918
Validation loss: 2.501172246205207

Epoch: 6| Step: 6
Training loss: 0.06756421563434245
Validation loss: 2.5334134464706235

Epoch: 6| Step: 7
Training loss: 0.10991483538385241
Validation loss: 2.5539992489991565

Epoch: 6| Step: 8
Training loss: 0.09031050657593477
Validation loss: 2.514058393623677

Epoch: 6| Step: 9
Training loss: 0.09524636358230631
Validation loss: 2.4940263998235603

Epoch: 6| Step: 10
Training loss: 0.09866076724791384
Validation loss: 2.508454721141149

Epoch: 6| Step: 11
Training loss: 0.11701412090853294
Validation loss: 2.529217216620525

Epoch: 6| Step: 12
Training loss: 0.1833935417033706
Validation loss: 2.5178631503820643

Epoch: 6| Step: 13
Training loss: 0.19916822690399166
Validation loss: 2.5205087568890128

Epoch: 594| Step: 0
Training loss: 0.11413020156222953
Validation loss: 2.4950752296674197

Epoch: 6| Step: 1
Training loss: 0.10350947091864855
Validation loss: 2.539108395599468

Epoch: 6| Step: 2
Training loss: 0.10066606052593297
Validation loss: 2.522841626228658

Epoch: 6| Step: 3
Training loss: 0.07746065917857191
Validation loss: 2.500109450702857

Epoch: 6| Step: 4
Training loss: 0.13439136172641422
Validation loss: 2.4864585107686197

Epoch: 6| Step: 5
Training loss: 0.09082387076349718
Validation loss: 2.4913092208842524

Epoch: 6| Step: 6
Training loss: 0.15289444913257919
Validation loss: 2.50390130886376

Epoch: 6| Step: 7
Training loss: 0.13132026982458508
Validation loss: 2.473604096125167

Epoch: 6| Step: 8
Training loss: 0.13406501628719492
Validation loss: 2.4933506604387117

Epoch: 6| Step: 9
Training loss: 0.16493036426287705
Validation loss: 2.5092871798097347

Epoch: 6| Step: 10
Training loss: 0.13062992191624245
Validation loss: 2.4999158916886453

Epoch: 6| Step: 11
Training loss: 0.05128841052545255
Validation loss: 2.517627674813169

Epoch: 6| Step: 12
Training loss: 0.11256412311153649
Validation loss: 2.5243973781565674

Epoch: 6| Step: 13
Training loss: 0.24792156658753264
Validation loss: 2.5286593227677847

Epoch: 595| Step: 0
Training loss: 0.10532637540804068
Validation loss: 2.5000604519662097

Epoch: 6| Step: 1
Training loss: 0.17569821833861704
Validation loss: 2.518404006084711

Epoch: 6| Step: 2
Training loss: 0.12803442504061374
Validation loss: 2.5212704157461414

Epoch: 6| Step: 3
Training loss: 0.10048040390650242
Validation loss: 2.510073670072287

Epoch: 6| Step: 4
Training loss: 0.09796038475553019
Validation loss: 2.526902738072267

Epoch: 6| Step: 5
Training loss: 0.15064326653381782
Validation loss: 2.4887018450824816

Epoch: 6| Step: 6
Training loss: 0.12185113303310666
Validation loss: 2.5357305668536614

Epoch: 6| Step: 7
Training loss: 0.1891851791665439
Validation loss: 2.5201858050558923

Epoch: 6| Step: 8
Training loss: 0.14355665971088916
Validation loss: 2.512436184955049

Epoch: 6| Step: 9
Training loss: 0.10224472671658814
Validation loss: 2.485468599946072

Epoch: 6| Step: 10
Training loss: 0.07774482254287013
Validation loss: 2.49399110466006

Epoch: 6| Step: 11
Training loss: 0.10152763905478042
Validation loss: 2.502702139720541

Epoch: 6| Step: 12
Training loss: 0.06775529849573056
Validation loss: 2.514074389441832

Epoch: 6| Step: 13
Training loss: 0.2348980154258947
Validation loss: 2.5210151420354237

Epoch: 596| Step: 0
Training loss: 0.12291059819155228
Validation loss: 2.524701990958943

Epoch: 6| Step: 1
Training loss: 0.101625514655552
Validation loss: 2.5256656902701082

Epoch: 6| Step: 2
Training loss: 0.07074635485502509
Validation loss: 2.526860366522479

Epoch: 6| Step: 3
Training loss: 0.07325870645524185
Validation loss: 2.515490030540378

Epoch: 6| Step: 4
Training loss: 0.16627225114768118
Validation loss: 2.5176314852002624

Epoch: 6| Step: 5
Training loss: 0.13843977672263372
Validation loss: 2.544863747918465

Epoch: 6| Step: 6
Training loss: 0.1438990504382617
Validation loss: 2.491660234983021

Epoch: 6| Step: 7
Training loss: 0.11684801678851701
Validation loss: 2.504379650817885

Epoch: 6| Step: 8
Training loss: 0.14009247722809146
Validation loss: 2.4902465413371626

Epoch: 6| Step: 9
Training loss: 0.1469307392963217
Validation loss: 2.5110342094823097

Epoch: 6| Step: 10
Training loss: 0.11243141322070269
Validation loss: 2.538950875402511

Epoch: 6| Step: 11
Training loss: 0.07690859585811011
Validation loss: 2.488366504682688

Epoch: 6| Step: 12
Training loss: 0.14135519497028148
Validation loss: 2.5082873446669005

Epoch: 6| Step: 13
Training loss: 0.2253326546414959
Validation loss: 2.4909575634861514

Epoch: 597| Step: 0
Training loss: 0.13200142681595162
Validation loss: 2.540661222781916

Epoch: 6| Step: 1
Training loss: 0.0859325743477389
Validation loss: 2.4847012506388753

Epoch: 6| Step: 2
Training loss: 0.14115115914613732
Validation loss: 2.499551267241932

Epoch: 6| Step: 3
Training loss: 0.09117748414855867
Validation loss: 2.5213715695562775

Epoch: 6| Step: 4
Training loss: 0.143571372587109
Validation loss: 2.525063633368227

Epoch: 6| Step: 5
Training loss: 0.12985877481468064
Validation loss: 2.534575798441796

Epoch: 6| Step: 6
Training loss: 0.16729663401976738
Validation loss: 2.5303965509331596

Epoch: 6| Step: 7
Training loss: 0.1249802767571347
Validation loss: 2.5266487938828375

Epoch: 6| Step: 8
Training loss: 0.09743753259222722
Validation loss: 2.51434803508949

Epoch: 6| Step: 9
Training loss: 0.08118458186713198
Validation loss: 2.521801148420843

Epoch: 6| Step: 10
Training loss: 0.13927711791717104
Validation loss: 2.5329242224840103

Epoch: 6| Step: 11
Training loss: 0.1114507886154243
Validation loss: 2.5516435985586496

Epoch: 6| Step: 12
Training loss: 0.22313281973858862
Validation loss: 2.5064672292124492

Epoch: 6| Step: 13
Training loss: 0.08029107528862843
Validation loss: 2.550630081271041

Epoch: 598| Step: 0
Training loss: 0.20627736538628966
Validation loss: 2.4935217290966514

Epoch: 6| Step: 1
Training loss: 0.09046291457678558
Validation loss: 2.463262762853067

Epoch: 6| Step: 2
Training loss: 0.15692088818109257
Validation loss: 2.489223109370186

Epoch: 6| Step: 3
Training loss: 0.12544399622986663
Validation loss: 2.4962570042296

Epoch: 6| Step: 4
Training loss: 0.08999094101229424
Validation loss: 2.5345020861819396

Epoch: 6| Step: 5
Training loss: 0.10460243469872983
Validation loss: 2.4690267808288486

Epoch: 6| Step: 6
Training loss: 0.0985296106053909
Validation loss: 2.5007528863380855

Epoch: 6| Step: 7
Training loss: 0.11122821624725751
Validation loss: 2.529846231584323

Epoch: 6| Step: 8
Training loss: 0.09523358282897289
Validation loss: 2.5245845527730535

Epoch: 6| Step: 9
Training loss: 0.23507721925803762
Validation loss: 2.511799455268319

Epoch: 6| Step: 10
Training loss: 0.14805579045408096
Validation loss: 2.5192247358676734

Epoch: 6| Step: 11
Training loss: 0.11409850711643033
Validation loss: 2.5184487013640533

Epoch: 6| Step: 12
Training loss: 0.11807473013715983
Validation loss: 2.5186234071296547

Epoch: 6| Step: 13
Training loss: 0.11681474769000376
Validation loss: 2.4987040349832657

Epoch: 599| Step: 0
Training loss: 0.20637508089132128
Validation loss: 2.525383083467799

Epoch: 6| Step: 1
Training loss: 0.11980341425251134
Validation loss: 2.5006925833580707

Epoch: 6| Step: 2
Training loss: 0.0754451101459777
Validation loss: 2.493880491615166

Epoch: 6| Step: 3
Training loss: 0.18838307923341696
Validation loss: 2.544402109674959

Epoch: 6| Step: 4
Training loss: 0.15887981674124402
Validation loss: 2.5256016711623035

Epoch: 6| Step: 5
Training loss: 0.09608027045757397
Validation loss: 2.5131951404844215

Epoch: 6| Step: 6
Training loss: 0.06349653516678752
Validation loss: 2.5209086613767986

Epoch: 6| Step: 7
Training loss: 0.07616983313146815
Validation loss: 2.4781180725509806

Epoch: 6| Step: 8
Training loss: 0.09168706575731603
Validation loss: 2.4937279296576036

Epoch: 6| Step: 9
Training loss: 0.13595010764751542
Validation loss: 2.521204674371644

Epoch: 6| Step: 10
Training loss: 0.20755612219052116
Validation loss: 2.5164505563088975

Epoch: 6| Step: 11
Training loss: 0.1748878558200447
Validation loss: 2.4983498469920407

Epoch: 6| Step: 12
Training loss: 0.09656092545234839
Validation loss: 2.5005140073540626

Epoch: 6| Step: 13
Training loss: 0.11971210389321182
Validation loss: 2.497774953138195

Epoch: 600| Step: 0
Training loss: 0.14114927868902008
Validation loss: 2.4646502433919184

Epoch: 6| Step: 1
Training loss: 0.1363698526590239
Validation loss: 2.459298945505223

Epoch: 6| Step: 2
Training loss: 0.19462130312082124
Validation loss: 2.478482685025212

Epoch: 6| Step: 3
Training loss: 0.06423069401973945
Validation loss: 2.4757507159350114

Epoch: 6| Step: 4
Training loss: 0.10502243977272613
Validation loss: 2.465149012966738

Epoch: 6| Step: 5
Training loss: 0.1636911572043797
Validation loss: 2.498053442016427

Epoch: 6| Step: 6
Training loss: 0.12040481014093735
Validation loss: 2.5112454831552484

Epoch: 6| Step: 7
Training loss: 0.10094700054064887
Validation loss: 2.5424241114601753

Epoch: 6| Step: 8
Training loss: 0.15504779855456355
Validation loss: 2.5569927944082607

Epoch: 6| Step: 9
Training loss: 0.1637615213272182
Validation loss: 2.5471066545022256

Epoch: 6| Step: 10
Training loss: 0.16577692823502455
Validation loss: 2.564074254078841

Epoch: 6| Step: 11
Training loss: 0.07587835110396238
Validation loss: 2.517864689871395

Epoch: 6| Step: 12
Training loss: 0.09556911778847317
Validation loss: 2.535685405792465

Epoch: 6| Step: 13
Training loss: 0.08130387413700854
Validation loss: 2.5365849450047175

Epoch: 601| Step: 0
Training loss: 0.13597976011238605
Validation loss: 2.50338553002433

Epoch: 6| Step: 1
Training loss: 0.10102258736439519
Validation loss: 2.5026021458874577

Epoch: 6| Step: 2
Training loss: 0.1994069650192127
Validation loss: 2.528212838027539

Epoch: 6| Step: 3
Training loss: 0.11993863628563828
Validation loss: 2.5057664335305327

Epoch: 6| Step: 4
Training loss: 0.09800453069550975
Validation loss: 2.521858079930293

Epoch: 6| Step: 5
Training loss: 0.065939804275304
Validation loss: 2.528255787703534

Epoch: 6| Step: 6
Training loss: 0.1090600127261709
Validation loss: 2.5297854009819223

Epoch: 6| Step: 7
Training loss: 0.09035794170040379
Validation loss: 2.5336664136571074

Epoch: 6| Step: 8
Training loss: 0.14171386737676933
Validation loss: 2.509877344352384

Epoch: 6| Step: 9
Training loss: 0.093904358230679
Validation loss: 2.520958918086793

Epoch: 6| Step: 10
Training loss: 0.08274267712436416
Validation loss: 2.535606375791358

Epoch: 6| Step: 11
Training loss: 0.1312719360821458
Validation loss: 2.4852099448341938

Epoch: 6| Step: 12
Training loss: 0.17766586492416003
Validation loss: 2.45818466131851

Epoch: 6| Step: 13
Training loss: 0.04667257270700152
Validation loss: 2.474557063778767

Epoch: 602| Step: 0
Training loss: 0.1302155270178769
Validation loss: 2.4610445357727366

Epoch: 6| Step: 1
Training loss: 0.11763788934891889
Validation loss: 2.4685311563779453

Epoch: 6| Step: 2
Training loss: 0.16305106469745206
Validation loss: 2.456123522302716

Epoch: 6| Step: 3
Training loss: 0.12048957832047628
Validation loss: 2.4948048438517745

Epoch: 6| Step: 4
Training loss: 0.08602660609701018
Validation loss: 2.4837467036069083

Epoch: 6| Step: 5
Training loss: 0.1779137743503363
Validation loss: 2.530572087195133

Epoch: 6| Step: 6
Training loss: 0.07867629031715573
Validation loss: 2.513435869067741

Epoch: 6| Step: 7
Training loss: 0.10058768743085364
Validation loss: 2.5340473472512013

Epoch: 6| Step: 8
Training loss: 0.051655970549880456
Validation loss: 2.500898098369749

Epoch: 6| Step: 9
Training loss: 0.08027391804832057
Validation loss: 2.5552228758184223

Epoch: 6| Step: 10
Training loss: 0.09404876409877862
Validation loss: 2.5199279711935096

Epoch: 6| Step: 11
Training loss: 0.0813774610691476
Validation loss: 2.508819550642021

Epoch: 6| Step: 12
Training loss: 0.1425802805489415
Validation loss: 2.5191339432485744

Epoch: 6| Step: 13
Training loss: 0.08069165349064572
Validation loss: 2.5504884706818434

Epoch: 603| Step: 0
Training loss: 0.111530663478332
Validation loss: 2.55510564922262

Epoch: 6| Step: 1
Training loss: 0.07729038627653041
Validation loss: 2.534608928332191

Epoch: 6| Step: 2
Training loss: 0.06117867952017453
Validation loss: 2.563095412772666

Epoch: 6| Step: 3
Training loss: 0.11051567500040635
Validation loss: 2.5311787285209553

Epoch: 6| Step: 4
Training loss: 0.08760744144387175
Validation loss: 2.512617811202915

Epoch: 6| Step: 5
Training loss: 0.11984889764187294
Validation loss: 2.535339610747825

Epoch: 6| Step: 6
Training loss: 0.13991443935895
Validation loss: 2.5447439690734304

Epoch: 6| Step: 7
Training loss: 0.06456695244430184
Validation loss: 2.533682418233503

Epoch: 6| Step: 8
Training loss: 0.07345052017793935
Validation loss: 2.5227757906441775

Epoch: 6| Step: 9
Training loss: 0.0758322824131978
Validation loss: 2.5016081283161027

Epoch: 6| Step: 10
Training loss: 0.06556725274483581
Validation loss: 2.538825906816479

Epoch: 6| Step: 11
Training loss: 0.09681857373102933
Validation loss: 2.5002236932741178

Epoch: 6| Step: 12
Training loss: 0.2522272496526467
Validation loss: 2.508896160733314

Epoch: 6| Step: 13
Training loss: 0.06478384810154257
Validation loss: 2.5210234023661204

Epoch: 604| Step: 0
Training loss: 0.10401837601991268
Validation loss: 2.5355280702989487

Epoch: 6| Step: 1
Training loss: 0.10815987238925424
Validation loss: 2.495271359727497

Epoch: 6| Step: 2
Training loss: 0.10358805641506147
Validation loss: 2.534612520003216

Epoch: 6| Step: 3
Training loss: 0.10798982553245462
Validation loss: 2.514282479781526

Epoch: 6| Step: 4
Training loss: 0.06352123742450995
Validation loss: 2.527097391638381

Epoch: 6| Step: 5
Training loss: 0.1103168956350908
Validation loss: 2.477937108228654

Epoch: 6| Step: 6
Training loss: 0.1639089547035042
Validation loss: 2.50784816747886

Epoch: 6| Step: 7
Training loss: 0.0957447856611243
Validation loss: 2.542123792448955

Epoch: 6| Step: 8
Training loss: 0.08021380978111325
Validation loss: 2.5286614700671506

Epoch: 6| Step: 9
Training loss: 0.14497345214786445
Validation loss: 2.4911755257797097

Epoch: 6| Step: 10
Training loss: 0.11990874122246745
Validation loss: 2.5496201690148363

Epoch: 6| Step: 11
Training loss: 0.10540235160078608
Validation loss: 2.5268453642425297

Epoch: 6| Step: 12
Training loss: 0.22036737881279336
Validation loss: 2.531025162402084

Epoch: 6| Step: 13
Training loss: 0.15522407250853001
Validation loss: 2.574538810385142

Epoch: 605| Step: 0
Training loss: 0.11490966420162799
Validation loss: 2.519728194006493

Epoch: 6| Step: 1
Training loss: 0.11899207970012786
Validation loss: 2.5242141559111757

Epoch: 6| Step: 2
Training loss: 0.06249828261757719
Validation loss: 2.523406065855522

Epoch: 6| Step: 3
Training loss: 0.0828186179096469
Validation loss: 2.5492712661341796

Epoch: 6| Step: 4
Training loss: 0.08527419557815476
Validation loss: 2.5145304744652526

Epoch: 6| Step: 5
Training loss: 0.1622127410232824
Validation loss: 2.53092859502159

Epoch: 6| Step: 6
Training loss: 0.11229923898499763
Validation loss: 2.557028951914218

Epoch: 6| Step: 7
Training loss: 0.1751980325238917
Validation loss: 2.527526454278119

Epoch: 6| Step: 8
Training loss: 0.10030214310446621
Validation loss: 2.5363133975645695

Epoch: 6| Step: 9
Training loss: 0.18703846951782613
Validation loss: 2.5101022327264255

Epoch: 6| Step: 10
Training loss: 0.11048437666943581
Validation loss: 2.511745587402375

Epoch: 6| Step: 11
Training loss: 0.1533307843367891
Validation loss: 2.529507019584831

Epoch: 6| Step: 12
Training loss: 0.1417762862251592
Validation loss: 2.518614628971195

Epoch: 6| Step: 13
Training loss: 0.09584152665651802
Validation loss: 2.5497135660991304

Epoch: 606| Step: 0
Training loss: 0.0716644814080945
Validation loss: 2.5363807549284174

Epoch: 6| Step: 1
Training loss: 0.07932331649711231
Validation loss: 2.532914283378762

Epoch: 6| Step: 2
Training loss: 0.08607474118968557
Validation loss: 2.52957305192257

Epoch: 6| Step: 3
Training loss: 0.16380315673144888
Validation loss: 2.5586031304495664

Epoch: 6| Step: 4
Training loss: 0.09183710312519376
Validation loss: 2.5496480171641975

Epoch: 6| Step: 5
Training loss: 0.13102029755687467
Validation loss: 2.548149381422618

Epoch: 6| Step: 6
Training loss: 0.13292753623098255
Validation loss: 2.534752714593932

Epoch: 6| Step: 7
Training loss: 0.12238794962538682
Validation loss: 2.530946301900113

Epoch: 6| Step: 8
Training loss: 0.0744916891472424
Validation loss: 2.516511289023749

Epoch: 6| Step: 9
Training loss: 0.1318060099223543
Validation loss: 2.511195300031879

Epoch: 6| Step: 10
Training loss: 0.15828769683888913
Validation loss: 2.530041074638661

Epoch: 6| Step: 11
Training loss: 0.0862131898531333
Validation loss: 2.5481277858364932

Epoch: 6| Step: 12
Training loss: 0.10029957572175995
Validation loss: 2.4958096477220018

Epoch: 6| Step: 13
Training loss: 0.20478339133095586
Validation loss: 2.5155480251460194

Epoch: 607| Step: 0
Training loss: 0.12530305008680867
Validation loss: 2.5187218234190696

Epoch: 6| Step: 1
Training loss: 0.10421285548977127
Validation loss: 2.5282468655391455

Epoch: 6| Step: 2
Training loss: 0.11242717200253678
Validation loss: 2.5113933571074503

Epoch: 6| Step: 3
Training loss: 0.09876124357997809
Validation loss: 2.5178958103649216

Epoch: 6| Step: 4
Training loss: 0.18226272943700847
Validation loss: 2.551421813078374

Epoch: 6| Step: 5
Training loss: 0.11194687107770782
Validation loss: 2.528207448035795

Epoch: 6| Step: 6
Training loss: 0.19085177081243238
Validation loss: 2.510326876281477

Epoch: 6| Step: 7
Training loss: 0.10315280886148076
Validation loss: 2.54261707716962

Epoch: 6| Step: 8
Training loss: 0.07686729146332161
Validation loss: 2.5541394835603453

Epoch: 6| Step: 9
Training loss: 0.1481200764437359
Validation loss: 2.5274297395264798

Epoch: 6| Step: 10
Training loss: 0.07287080065878658
Validation loss: 2.495501005832973

Epoch: 6| Step: 11
Training loss: 0.05256426713617384
Validation loss: 2.5119271554020295

Epoch: 6| Step: 12
Training loss: 0.13891813414019208
Validation loss: 2.5266755767034415

Epoch: 6| Step: 13
Training loss: 0.07388813642633668
Validation loss: 2.517625865335504

Epoch: 608| Step: 0
Training loss: 0.12655316954234053
Validation loss: 2.4827821934357197

Epoch: 6| Step: 1
Training loss: 0.20902201055169053
Validation loss: 2.5061168359196953

Epoch: 6| Step: 2
Training loss: 0.11811401946888687
Validation loss: 2.4812150164140054

Epoch: 6| Step: 3
Training loss: 0.10484596329696523
Validation loss: 2.487399356657225

Epoch: 6| Step: 4
Training loss: 0.07016087448833962
Validation loss: 2.506431420366142

Epoch: 6| Step: 5
Training loss: 0.07482981098081463
Validation loss: 2.5086529107868802

Epoch: 6| Step: 6
Training loss: 0.08074689069373743
Validation loss: 2.507131280649075

Epoch: 6| Step: 7
Training loss: 0.09650253673230998
Validation loss: 2.5098330612893665

Epoch: 6| Step: 8
Training loss: 0.0691753663857266
Validation loss: 2.4961604279660667

Epoch: 6| Step: 9
Training loss: 0.09780343884401482
Validation loss: 2.5319179958480977

Epoch: 6| Step: 10
Training loss: 0.12322984821072529
Validation loss: 2.4912628527179685

Epoch: 6| Step: 11
Training loss: 0.06491455440814624
Validation loss: 2.4793398393260295

Epoch: 6| Step: 12
Training loss: 0.14379556389877984
Validation loss: 2.5155756940514724

Epoch: 6| Step: 13
Training loss: 0.04384803867385719
Validation loss: 2.535338053556917

Epoch: 609| Step: 0
Training loss: 0.11155778219094194
Validation loss: 2.474392041119334

Epoch: 6| Step: 1
Training loss: 0.1756439255379789
Validation loss: 2.480609266922691

Epoch: 6| Step: 2
Training loss: 0.13153067675098765
Validation loss: 2.4726400354908646

Epoch: 6| Step: 3
Training loss: 0.09463032031503608
Validation loss: 2.4911865421501096

Epoch: 6| Step: 4
Training loss: 0.09480593983467885
Validation loss: 2.530140626450701

Epoch: 6| Step: 5
Training loss: 0.06701774109807876
Validation loss: 2.512991232009339

Epoch: 6| Step: 6
Training loss: 0.14038986840572285
Validation loss: 2.5255722930859204

Epoch: 6| Step: 7
Training loss: 0.09052495716656786
Validation loss: 2.502610459822963

Epoch: 6| Step: 8
Training loss: 0.08238197181077365
Validation loss: 2.5072345611412445

Epoch: 6| Step: 9
Training loss: 0.16854205542799724
Validation loss: 2.527708790374978

Epoch: 6| Step: 10
Training loss: 0.1626909234781825
Validation loss: 2.532343049246719

Epoch: 6| Step: 11
Training loss: 0.13389562970870028
Validation loss: 2.54945149700435

Epoch: 6| Step: 12
Training loss: 0.069074072434643
Validation loss: 2.5373808652927927

Epoch: 6| Step: 13
Training loss: 0.06518013892439811
Validation loss: 2.5623432006904583

Epoch: 610| Step: 0
Training loss: 0.10634300144682039
Validation loss: 2.544820173395016

Epoch: 6| Step: 1
Training loss: 0.05830016095903344
Validation loss: 2.5110129149252374

Epoch: 6| Step: 2
Training loss: 0.15284033073339717
Validation loss: 2.52447276707359

Epoch: 6| Step: 3
Training loss: 0.1434089543729126
Validation loss: 2.545046712477818

Epoch: 6| Step: 4
Training loss: 0.08011523410381696
Validation loss: 2.533626716458007

Epoch: 6| Step: 5
Training loss: 0.09437378347320138
Validation loss: 2.50932660539471

Epoch: 6| Step: 6
Training loss: 0.10697085023295376
Validation loss: 2.4905762400325067

Epoch: 6| Step: 7
Training loss: 0.09270182405436929
Validation loss: 2.5210826150165686

Epoch: 6| Step: 8
Training loss: 0.09748062554149824
Validation loss: 2.5114223304230903

Epoch: 6| Step: 9
Training loss: 0.16571559722378765
Validation loss: 2.486724701249996

Epoch: 6| Step: 10
Training loss: 0.09329680337106143
Validation loss: 2.528154592958013

Epoch: 6| Step: 11
Training loss: 0.07070969938303345
Validation loss: 2.5111455651038073

Epoch: 6| Step: 12
Training loss: 0.1050974172303396
Validation loss: 2.522963880933759

Epoch: 6| Step: 13
Training loss: 0.14158825647384923
Validation loss: 2.520197469242422

Epoch: 611| Step: 0
Training loss: 0.0823691877672022
Validation loss: 2.5138518965381973

Epoch: 6| Step: 1
Training loss: 0.064821807182029
Validation loss: 2.536792743610688

Epoch: 6| Step: 2
Training loss: 0.0898661896422152
Validation loss: 2.5286763348440147

Epoch: 6| Step: 3
Training loss: 0.1523147518729545
Validation loss: 2.5479990979028506

Epoch: 6| Step: 4
Training loss: 0.10583094376944546
Validation loss: 2.51899500491164

Epoch: 6| Step: 5
Training loss: 0.15729258318080364
Validation loss: 2.5251343028096906

Epoch: 6| Step: 6
Training loss: 0.09491925942384792
Validation loss: 2.488918510869814

Epoch: 6| Step: 7
Training loss: 0.11255890641838412
Validation loss: 2.4889102104242915

Epoch: 6| Step: 8
Training loss: 0.06876625158847471
Validation loss: 2.499381114896017

Epoch: 6| Step: 9
Training loss: 0.0726206794953895
Validation loss: 2.504470304767072

Epoch: 6| Step: 10
Training loss: 0.09940567412145138
Validation loss: 2.5366634417275904

Epoch: 6| Step: 11
Training loss: 0.11091231610994326
Validation loss: 2.5347577402193573

Epoch: 6| Step: 12
Training loss: 0.15855781213764567
Validation loss: 2.503756676482735

Epoch: 6| Step: 13
Training loss: 0.07509387903424661
Validation loss: 2.502936397647826

Epoch: 612| Step: 0
Training loss: 0.10886369555881541
Validation loss: 2.509792748865633

Epoch: 6| Step: 1
Training loss: 0.14349833829263228
Validation loss: 2.5139999608349783

Epoch: 6| Step: 2
Training loss: 0.10781184417414569
Validation loss: 2.5169027308098393

Epoch: 6| Step: 3
Training loss: 0.1544150973960113
Validation loss: 2.5271457094257164

Epoch: 6| Step: 4
Training loss: 0.07281522279159011
Validation loss: 2.5121697035837305

Epoch: 6| Step: 5
Training loss: 0.09390420946389172
Validation loss: 2.522694497529933

Epoch: 6| Step: 6
Training loss: 0.06541606063711385
Validation loss: 2.5134376632023456

Epoch: 6| Step: 7
Training loss: 0.15441379463139757
Validation loss: 2.5271152293426864

Epoch: 6| Step: 8
Training loss: 0.10354880035254387
Validation loss: 2.5305928448654824

Epoch: 6| Step: 9
Training loss: 0.1738354220626765
Validation loss: 2.4905476706384846

Epoch: 6| Step: 10
Training loss: 0.09423641835481372
Validation loss: 2.5665014175683427

Epoch: 6| Step: 11
Training loss: 0.1232079707797103
Validation loss: 2.548692173377598

Epoch: 6| Step: 12
Training loss: 0.12079351645406775
Validation loss: 2.535597132698412

Epoch: 6| Step: 13
Training loss: 0.14915526797276843
Validation loss: 2.5394509941347656

Epoch: 613| Step: 0
Training loss: 0.08619122006179888
Validation loss: 2.541586307954534

Epoch: 6| Step: 1
Training loss: 0.09091121472308125
Validation loss: 2.5326361163340882

Epoch: 6| Step: 2
Training loss: 0.07278197662270063
Validation loss: 2.57357946112989

Epoch: 6| Step: 3
Training loss: 0.18800424285105888
Validation loss: 2.531083934445526

Epoch: 6| Step: 4
Training loss: 0.14271020650214394
Validation loss: 2.5521672264978057

Epoch: 6| Step: 5
Training loss: 0.09040022672927009
Validation loss: 2.532818523870808

Epoch: 6| Step: 6
Training loss: 0.14338085133228703
Validation loss: 2.5262436118222253

Epoch: 6| Step: 7
Training loss: 0.09279498301836814
Validation loss: 2.5207587054548855

Epoch: 6| Step: 8
Training loss: 0.09112432827885095
Validation loss: 2.5314427774221273

Epoch: 6| Step: 9
Training loss: 0.15085697940641069
Validation loss: 2.5336357712007573

Epoch: 6| Step: 10
Training loss: 0.09323462247424097
Validation loss: 2.537747948098183

Epoch: 6| Step: 11
Training loss: 0.14953027207703534
Validation loss: 2.5239038143538703

Epoch: 6| Step: 12
Training loss: 0.10034343040603119
Validation loss: 2.4979603979237797

Epoch: 6| Step: 13
Training loss: 0.09734328187949347
Validation loss: 2.488759452376776

Epoch: 614| Step: 0
Training loss: 0.2012332896586835
Validation loss: 2.4705614059616035

Epoch: 6| Step: 1
Training loss: 0.15618915565303165
Validation loss: 2.4848516642482714

Epoch: 6| Step: 2
Training loss: 0.09159748255381216
Validation loss: 2.486507098100385

Epoch: 6| Step: 3
Training loss: 0.08157163104834944
Validation loss: 2.4919832963555013

Epoch: 6| Step: 4
Training loss: 0.11306287006456787
Validation loss: 2.518227825238033

Epoch: 6| Step: 5
Training loss: 0.15186605385934607
Validation loss: 2.512735427869024

Epoch: 6| Step: 6
Training loss: 0.20590018857682824
Validation loss: 2.548611008323323

Epoch: 6| Step: 7
Training loss: 0.12278200964354075
Validation loss: 2.5395455516030543

Epoch: 6| Step: 8
Training loss: 0.15460196644524324
Validation loss: 2.5184154912195207

Epoch: 6| Step: 9
Training loss: 0.11041958155773145
Validation loss: 2.5308823647061813

Epoch: 6| Step: 10
Training loss: 0.10089615787880168
Validation loss: 2.5259726133170024

Epoch: 6| Step: 11
Training loss: 0.2220555366827621
Validation loss: 2.521756405815872

Epoch: 6| Step: 12
Training loss: 0.13586172151211778
Validation loss: 2.5457268804642985

Epoch: 6| Step: 13
Training loss: 0.1279027051352887
Validation loss: 2.520840810508558

Epoch: 615| Step: 0
Training loss: 0.199601936201722
Validation loss: 2.5425448145496214

Epoch: 6| Step: 1
Training loss: 0.19276968305926126
Validation loss: 2.5103510539693863

Epoch: 6| Step: 2
Training loss: 0.15441079702478144
Validation loss: 2.4890677364878195

Epoch: 6| Step: 3
Training loss: 0.11445624083616485
Validation loss: 2.516095637593395

Epoch: 6| Step: 4
Training loss: 0.2113570438560176
Validation loss: 2.490530718246119

Epoch: 6| Step: 5
Training loss: 0.194444980412456
Validation loss: 2.4911541515152797

Epoch: 6| Step: 6
Training loss: 0.1263002185749419
Validation loss: 2.4709047981550016

Epoch: 6| Step: 7
Training loss: 0.16229318056963393
Validation loss: 2.4925742728581497

Epoch: 6| Step: 8
Training loss: 0.2600700201145032
Validation loss: 2.508569174350076

Epoch: 6| Step: 9
Training loss: 0.11921338689247578
Validation loss: 2.4992101836821523

Epoch: 6| Step: 10
Training loss: 0.14603712468582702
Validation loss: 2.5348416330130155

Epoch: 6| Step: 11
Training loss: 0.14036802150240546
Validation loss: 2.590622758848925

Epoch: 6| Step: 12
Training loss: 0.13355065425864646
Validation loss: 2.6077154535266245

Epoch: 6| Step: 13
Training loss: 0.10866708800483683
Validation loss: 2.593519739020992

Epoch: 616| Step: 0
Training loss: 0.2141765899545531
Validation loss: 2.567987061260275

Epoch: 6| Step: 1
Training loss: 0.17567292160350786
Validation loss: 2.5597750293576857

Epoch: 6| Step: 2
Training loss: 0.1467508054740415
Validation loss: 2.577861616565584

Epoch: 6| Step: 3
Training loss: 0.14116120102285654
Validation loss: 2.5671661875577376

Epoch: 6| Step: 4
Training loss: 0.1033810964958085
Validation loss: 2.5539195550459897

Epoch: 6| Step: 5
Training loss: 0.11085353884345624
Validation loss: 2.4894683144731773

Epoch: 6| Step: 6
Training loss: 0.1738142586653046
Validation loss: 2.497364182612612

Epoch: 6| Step: 7
Training loss: 0.29938544866370304
Validation loss: 2.4748042109462918

Epoch: 6| Step: 8
Training loss: 0.2281341302690664
Validation loss: 2.507573724081944

Epoch: 6| Step: 9
Training loss: 0.17104837652055963
Validation loss: 2.5283476449242572

Epoch: 6| Step: 10
Training loss: 0.18494957604000015
Validation loss: 2.5191889445212254

Epoch: 6| Step: 11
Training loss: 0.26386739757650896
Validation loss: 2.560887480410735

Epoch: 6| Step: 12
Training loss: 0.11971598978328327
Validation loss: 2.5783267551605498

Epoch: 6| Step: 13
Training loss: 0.16303473942425953
Validation loss: 2.547393793298944

Epoch: 617| Step: 0
Training loss: 0.14689895454830645
Validation loss: 2.5565625997650465

Epoch: 6| Step: 1
Training loss: 0.1527753731027803
Validation loss: 2.559441079057175

Epoch: 6| Step: 2
Training loss: 0.18290744500459885
Validation loss: 2.5185370818138373

Epoch: 6| Step: 3
Training loss: 0.11320486453071017
Validation loss: 2.5510156138715967

Epoch: 6| Step: 4
Training loss: 0.23351582563844078
Validation loss: 2.5694240632080767

Epoch: 6| Step: 5
Training loss: 0.1669853722146428
Validation loss: 2.5230727439289473

Epoch: 6| Step: 6
Training loss: 0.16197992809664566
Validation loss: 2.5646852539226033

Epoch: 6| Step: 7
Training loss: 0.09369783639065052
Validation loss: 2.5470731894538368

Epoch: 6| Step: 8
Training loss: 0.24501918642180207
Validation loss: 2.5764440292467743

Epoch: 6| Step: 9
Training loss: 0.14934489575297957
Validation loss: 2.5617957038950783

Epoch: 6| Step: 10
Training loss: 0.2027104530847661
Validation loss: 2.602849022698647

Epoch: 6| Step: 11
Training loss: 0.13962241243732723
Validation loss: 2.5530365928840792

Epoch: 6| Step: 12
Training loss: 0.1642690391650175
Validation loss: 2.585594090747921

Epoch: 6| Step: 13
Training loss: 0.1197512332085242
Validation loss: 2.551946457956611

Epoch: 618| Step: 0
Training loss: 0.21974999196917244
Validation loss: 2.5504464256346817

Epoch: 6| Step: 1
Training loss: 0.16245377965312557
Validation loss: 2.5423154650069524

Epoch: 6| Step: 2
Training loss: 0.1166253953727182
Validation loss: 2.5438383737058947

Epoch: 6| Step: 3
Training loss: 0.12044444512498273
Validation loss: 2.5368857004215926

Epoch: 6| Step: 4
Training loss: 0.12399530091606219
Validation loss: 2.5292161563839235

Epoch: 6| Step: 5
Training loss: 0.21523897924189062
Validation loss: 2.5345725865252295

Epoch: 6| Step: 6
Training loss: 0.2727032749317902
Validation loss: 2.5218488083033193

Epoch: 6| Step: 7
Training loss: 0.12671925938570908
Validation loss: 2.52615128332065

Epoch: 6| Step: 8
Training loss: 0.14028320896720942
Validation loss: 2.537869841317932

Epoch: 6| Step: 9
Training loss: 0.11497542008464022
Validation loss: 2.570029060980245

Epoch: 6| Step: 10
Training loss: 0.11130599588340202
Validation loss: 2.538532824173545

Epoch: 6| Step: 11
Training loss: 0.19731690901578067
Validation loss: 2.5456017349399933

Epoch: 6| Step: 12
Training loss: 0.1372870215477691
Validation loss: 2.5491898243541833

Epoch: 6| Step: 13
Training loss: 0.13115593769662542
Validation loss: 2.5872222224194013

Epoch: 619| Step: 0
Training loss: 0.2380998890570102
Validation loss: 2.567105212686049

Epoch: 6| Step: 1
Training loss: 0.23937193815050983
Validation loss: 2.548604567555518

Epoch: 6| Step: 2
Training loss: 0.1322620569593946
Validation loss: 2.5511846095452877

Epoch: 6| Step: 3
Training loss: 0.12182011713489217
Validation loss: 2.5506968869414095

Epoch: 6| Step: 4
Training loss: 0.12631585023184724
Validation loss: 2.561698616187215

Epoch: 6| Step: 5
Training loss: 0.21858553153152038
Validation loss: 2.5218632420581413

Epoch: 6| Step: 6
Training loss: 0.16381504493237076
Validation loss: 2.5551815788865913

Epoch: 6| Step: 7
Training loss: 0.09410293030209912
Validation loss: 2.5677331761285327

Epoch: 6| Step: 8
Training loss: 0.17124203609479177
Validation loss: 2.5697660738380077

Epoch: 6| Step: 9
Training loss: 0.1903297944815797
Validation loss: 2.5803578800095353

Epoch: 6| Step: 10
Training loss: 0.10488470722241684
Validation loss: 2.5736617657269245

Epoch: 6| Step: 11
Training loss: 0.21383196396982648
Validation loss: 2.6280044320234377

Epoch: 6| Step: 12
Training loss: 0.15605904712722385
Validation loss: 2.5642478688345776

Epoch: 6| Step: 13
Training loss: 0.3186421571880947
Validation loss: 2.597232134289052

Epoch: 620| Step: 0
Training loss: 0.13117947500181115
Validation loss: 2.5944647952459294

Epoch: 6| Step: 1
Training loss: 0.25742915581694614
Validation loss: 2.5504640804373166

Epoch: 6| Step: 2
Training loss: 0.12858677781440775
Validation loss: 2.5403178877786345

Epoch: 6| Step: 3
Training loss: 0.14718182149895434
Validation loss: 2.524387063238893

Epoch: 6| Step: 4
Training loss: 0.1940770749440758
Validation loss: 2.520570661147557

Epoch: 6| Step: 5
Training loss: 0.18603388467989912
Validation loss: 2.5471857443655495

Epoch: 6| Step: 6
Training loss: 0.22669628731350755
Validation loss: 2.5376884605860535

Epoch: 6| Step: 7
Training loss: 0.25081754166350356
Validation loss: 2.5714839511567598

Epoch: 6| Step: 8
Training loss: 0.14614872943385918
Validation loss: 2.509820618092199

Epoch: 6| Step: 9
Training loss: 0.13408214599648918
Validation loss: 2.507923274941078

Epoch: 6| Step: 10
Training loss: 0.20251573374930512
Validation loss: 2.4393319328633845

Epoch: 6| Step: 11
Training loss: 0.39697321930454765
Validation loss: 2.4359726970773234

Epoch: 6| Step: 12
Training loss: 0.13789947740706135
Validation loss: 2.497052476283053

Epoch: 6| Step: 13
Training loss: 0.20927740213639892
Validation loss: 2.5383394404158284

Epoch: 621| Step: 0
Training loss: 0.1842879299889243
Validation loss: 2.5817757084251327

Epoch: 6| Step: 1
Training loss: 0.1770475762861464
Validation loss: 2.5649488899419115

Epoch: 6| Step: 2
Training loss: 0.28268105629478674
Validation loss: 2.6418575093192853

Epoch: 6| Step: 3
Training loss: 0.2742959851125843
Validation loss: 2.6396226742104476

Epoch: 6| Step: 4
Training loss: 0.36264770392555307
Validation loss: 2.609505643049383

Epoch: 6| Step: 5
Training loss: 0.18953519203822672
Validation loss: 2.578918881711304

Epoch: 6| Step: 6
Training loss: 0.1959068220479782
Validation loss: 2.545204119307206

Epoch: 6| Step: 7
Training loss: 0.26644296085542984
Validation loss: 2.500243987718764

Epoch: 6| Step: 8
Training loss: 0.18030271736661058
Validation loss: 2.481156927080191

Epoch: 6| Step: 9
Training loss: 0.32730580430887973
Validation loss: 2.513654485496506

Epoch: 6| Step: 10
Training loss: 0.39166797636029566
Validation loss: 2.457666917522055

Epoch: 6| Step: 11
Training loss: 0.26100451242813916
Validation loss: 2.4958540717457645

Epoch: 6| Step: 12
Training loss: 0.2700516059133098
Validation loss: 2.5697745026846746

Epoch: 6| Step: 13
Training loss: 0.14717079190265625
Validation loss: 2.5808787922700147

Epoch: 622| Step: 0
Training loss: 0.30143651554232437
Validation loss: 2.5837452117214976

Epoch: 6| Step: 1
Training loss: 0.3811430828074818
Validation loss: 2.6446378085412214

Epoch: 6| Step: 2
Training loss: 0.3066450713983336
Validation loss: 2.596957057870037

Epoch: 6| Step: 3
Training loss: 0.2660134084331911
Validation loss: 2.572012895314282

Epoch: 6| Step: 4
Training loss: 0.215825067873387
Validation loss: 2.5633358136283784

Epoch: 6| Step: 5
Training loss: 0.21613139177052273
Validation loss: 2.5396021004695006

Epoch: 6| Step: 6
Training loss: 0.2718180245956176
Validation loss: 2.5623328451787146

Epoch: 6| Step: 7
Training loss: 0.28624933884057063
Validation loss: 2.570250546485183

Epoch: 6| Step: 8
Training loss: 0.30683523429338383
Validation loss: 2.558183035551341

Epoch: 6| Step: 9
Training loss: 0.25725332944919355
Validation loss: 2.583815928173776

Epoch: 6| Step: 10
Training loss: 0.30277165829358815
Validation loss: 2.5555105602939534

Epoch: 6| Step: 11
Training loss: 0.2799267768270974
Validation loss: 2.5673046733697955

Epoch: 6| Step: 12
Training loss: 0.20428213317957952
Validation loss: 2.5662143318545785

Epoch: 6| Step: 13
Training loss: 0.28101475467075177
Validation loss: 2.5586131421027254

Epoch: 623| Step: 0
Training loss: 0.11780897493173324
Validation loss: 2.5912924380585545

Epoch: 6| Step: 1
Training loss: 0.2907462953920261
Validation loss: 2.5979009919638107

Epoch: 6| Step: 2
Training loss: 0.3481568472076189
Validation loss: 2.607939231507071

Epoch: 6| Step: 3
Training loss: 0.31868285145037273
Validation loss: 2.587649684779517

Epoch: 6| Step: 4
Training loss: 0.2164659810176177
Validation loss: 2.6194661823710264

Epoch: 6| Step: 5
Training loss: 0.18291477700591946
Validation loss: 2.549096240127516

Epoch: 6| Step: 6
Training loss: 0.2635316263831948
Validation loss: 2.53311180110599

Epoch: 6| Step: 7
Training loss: 0.13945966245784158
Validation loss: 2.5181415708608177

Epoch: 6| Step: 8
Training loss: 0.19419586462649938
Validation loss: 2.5038969369841526

Epoch: 6| Step: 9
Training loss: 0.3390324104599348
Validation loss: 2.469571319779347

Epoch: 6| Step: 10
Training loss: 0.3747239089914817
Validation loss: 2.427547755974681

Epoch: 6| Step: 11
Training loss: 0.2792406092168684
Validation loss: 2.4266569986723248

Epoch: 6| Step: 12
Training loss: 0.22326296411787155
Validation loss: 2.4743607112335804

Epoch: 6| Step: 13
Training loss: 0.25423700357376755
Validation loss: 2.532021473194503

Epoch: 624| Step: 0
Training loss: 0.24106408873111906
Validation loss: 2.49210939179831

Epoch: 6| Step: 1
Training loss: 0.29752185270447656
Validation loss: 2.5223837342231397

Epoch: 6| Step: 2
Training loss: 0.48300216307461763
Validation loss: 2.6048920573974557

Epoch: 6| Step: 3
Training loss: 0.15978495660425968
Validation loss: 2.539936519409607

Epoch: 6| Step: 4
Training loss: 0.22466648868370742
Validation loss: 2.4844464863002407

Epoch: 6| Step: 5
Training loss: 0.2599086654466452
Validation loss: 2.442186020886175

Epoch: 6| Step: 6
Training loss: 0.5915153513647097
Validation loss: 2.442840850871717

Epoch: 6| Step: 7
Training loss: 0.33123283881592347
Validation loss: 2.483595962440076

Epoch: 6| Step: 8
Training loss: 0.4229669391493263
Validation loss: 2.500630104480125

Epoch: 6| Step: 9
Training loss: 0.6740015663615514
Validation loss: 2.491477267191276

Epoch: 6| Step: 10
Training loss: 0.3837103144102679
Validation loss: 2.4871214374260346

Epoch: 6| Step: 11
Training loss: 0.4129290271465422
Validation loss: 2.508137359345421

Epoch: 6| Step: 12
Training loss: 0.2971120941655574
Validation loss: 2.4422621074201296

Epoch: 6| Step: 13
Training loss: 0.45051978410661125
Validation loss: 2.479926724326384

Epoch: 625| Step: 0
Training loss: 0.3917183452188708
Validation loss: 2.5072340110376223

Epoch: 6| Step: 1
Training loss: 0.49420343535119643
Validation loss: 2.4947027304931577

Epoch: 6| Step: 2
Training loss: 0.43282335591387083
Validation loss: 2.5042327119761922

Epoch: 6| Step: 3
Training loss: 0.492804760869131
Validation loss: 2.558104440028677

Epoch: 6| Step: 4
Training loss: 0.5363859263569372
Validation loss: 2.606989434640199

Epoch: 6| Step: 5
Training loss: 0.8104001199623351
Validation loss: 2.601986424182008

Epoch: 6| Step: 6
Training loss: 0.43274082457954205
Validation loss: 2.5755086172482673

Epoch: 6| Step: 7
Training loss: 0.3604600944521586
Validation loss: 2.5919667813037144

Epoch: 6| Step: 8
Training loss: 0.3693919663316764
Validation loss: 2.5822076266713707

Epoch: 6| Step: 9
Training loss: 0.6006799639779933
Validation loss: 2.545375523234877

Epoch: 6| Step: 10
Training loss: 0.5866768813147087
Validation loss: 2.5412851979004643

Epoch: 6| Step: 11
Training loss: 0.5452576836521665
Validation loss: 2.5311033428471386

Epoch: 6| Step: 12
Training loss: 0.30418048145763243
Validation loss: 2.583534280210545

Epoch: 6| Step: 13
Training loss: 0.21394062087936241
Validation loss: 2.6283729123267885

Epoch: 626| Step: 0
Training loss: 0.37858361341231106
Validation loss: 2.634563544504964

Epoch: 6| Step: 1
Training loss: 0.8069952677029024
Validation loss: 2.6660475547369265

Epoch: 6| Step: 2
Training loss: 0.3945424106643392
Validation loss: 2.6414005150188165

Epoch: 6| Step: 3
Training loss: 0.5617256662847581
Validation loss: 2.6208993331557604

Epoch: 6| Step: 4
Training loss: 0.323714737776053
Validation loss: 2.5849603077372914

Epoch: 6| Step: 5
Training loss: 0.29200808376560217
Validation loss: 2.5577498066675046

Epoch: 6| Step: 6
Training loss: 0.46579854342538773
Validation loss: 2.5851551856920914

Epoch: 6| Step: 7
Training loss: 0.35992222048372546
Validation loss: 2.6119245168627327

Epoch: 6| Step: 8
Training loss: 0.4378413503590759
Validation loss: 2.6287669329719376

Epoch: 6| Step: 9
Training loss: 0.6450053927469664
Validation loss: 2.6473848055647013

Epoch: 6| Step: 10
Training loss: 0.38576837764630734
Validation loss: 2.6382513365967526

Epoch: 6| Step: 11
Training loss: 0.433424083059256
Validation loss: 2.5984641061901996

Epoch: 6| Step: 12
Training loss: 0.5335365342927703
Validation loss: 2.5570480029765252

Epoch: 6| Step: 13
Training loss: 0.35279549441985486
Validation loss: 2.561533287615854

Epoch: 627| Step: 0
Training loss: 0.4413808629660182
Validation loss: 2.5355414024631404

Epoch: 6| Step: 1
Training loss: 0.6602295603478973
Validation loss: 2.5538401768224497

Epoch: 6| Step: 2
Training loss: 0.4713512090375922
Validation loss: 2.4610137422402163

Epoch: 6| Step: 3
Training loss: 0.5440122881598912
Validation loss: 2.528673088567506

Epoch: 6| Step: 4
Training loss: 0.5053891975735307
Validation loss: 2.503850080603576

Epoch: 6| Step: 5
Training loss: 0.2655141262455953
Validation loss: 2.5340891352892525

Epoch: 6| Step: 6
Training loss: 0.5876144571614295
Validation loss: 2.529990282443346

Epoch: 6| Step: 7
Training loss: 0.41118266331230996
Validation loss: 2.572276317006032

Epoch: 6| Step: 8
Training loss: 0.24611141504737058
Validation loss: 2.606161777949522

Epoch: 6| Step: 9
Training loss: 0.40776383339777406
Validation loss: 2.7054146619773762

Epoch: 6| Step: 10
Training loss: 0.9905863179738218
Validation loss: 2.763455001639577

Epoch: 6| Step: 11
Training loss: 0.25012579375698224
Validation loss: 2.5418586705504875

Epoch: 6| Step: 12
Training loss: 0.4409734917002483
Validation loss: 2.458394846729712

Epoch: 6| Step: 13
Training loss: 0.7619300744770737
Validation loss: 2.4356918927948707

Epoch: 628| Step: 0
Training loss: 0.9533014603157347
Validation loss: 2.4164889089565094

Epoch: 6| Step: 1
Training loss: 0.3731587027659293
Validation loss: 2.391012661273115

Epoch: 6| Step: 2
Training loss: 0.7516864254110333
Validation loss: 2.4421344071214253

Epoch: 6| Step: 3
Training loss: 0.5872769114830826
Validation loss: 2.4813510174835436

Epoch: 6| Step: 4
Training loss: 0.6098767684532463
Validation loss: 2.565891026042168

Epoch: 6| Step: 5
Training loss: 0.9292026826410081
Validation loss: 2.5972460351083035

Epoch: 6| Step: 6
Training loss: 0.49935722758688056
Validation loss: 2.615668408259129

Epoch: 6| Step: 7
Training loss: 0.8758203883958157
Validation loss: 2.573367158402971

Epoch: 6| Step: 8
Training loss: 0.5318148078881829
Validation loss: 2.5667885001370765

Epoch: 6| Step: 9
Training loss: 0.5214752310762003
Validation loss: 2.4894780727861905

Epoch: 6| Step: 10
Training loss: 0.5338953855155422
Validation loss: 2.5355322420423754

Epoch: 6| Step: 11
Training loss: 0.5513002642164699
Validation loss: 2.509159987975558

Epoch: 6| Step: 12
Training loss: 0.43150058045243245
Validation loss: 2.517632611411912

Epoch: 6| Step: 13
Training loss: 0.6489218316341901
Validation loss: 2.501292053763864

Epoch: 629| Step: 0
Training loss: 0.7574169266978318
Validation loss: 2.511824917021903

Epoch: 6| Step: 1
Training loss: 0.45859368111449056
Validation loss: 2.4557980756641764

Epoch: 6| Step: 2
Training loss: 0.6612700146709032
Validation loss: 2.460307529054458

Epoch: 6| Step: 3
Training loss: 0.47426173346849565
Validation loss: 2.4163310193052

Epoch: 6| Step: 4
Training loss: 0.3180176240442759
Validation loss: 2.437051728170137

Epoch: 6| Step: 5
Training loss: 0.5141103635263176
Validation loss: 2.4525767609148916

Epoch: 6| Step: 6
Training loss: 0.4983963432181306
Validation loss: 2.4409911956078507

Epoch: 6| Step: 7
Training loss: 0.3783915652015978
Validation loss: 2.501083756442497

Epoch: 6| Step: 8
Training loss: 0.4112097697596087
Validation loss: 2.4875880748372174

Epoch: 6| Step: 9
Training loss: 0.6057744884728574
Validation loss: 2.4996764917148964

Epoch: 6| Step: 10
Training loss: 0.42518461929774193
Validation loss: 2.531561286083912

Epoch: 6| Step: 11
Training loss: 0.29292776456884145
Validation loss: 2.5634043348599658

Epoch: 6| Step: 12
Training loss: 0.3238143006837776
Validation loss: 2.613524668059973

Epoch: 6| Step: 13
Training loss: 0.38890105348627285
Validation loss: 2.5712497614504484

Epoch: 630| Step: 0
Training loss: 0.30101521792707286
Validation loss: 2.595305281805241

Epoch: 6| Step: 1
Training loss: 0.40286718966482055
Validation loss: 2.5826617365921383

Epoch: 6| Step: 2
Training loss: 0.28033717690061954
Validation loss: 2.60409308265994

Epoch: 6| Step: 3
Training loss: 0.4107214530177285
Validation loss: 2.567681436452528

Epoch: 6| Step: 4
Training loss: 0.3387624925160934
Validation loss: 2.5530820289195058

Epoch: 6| Step: 5
Training loss: 0.29143855705863064
Validation loss: 2.5634952656287755

Epoch: 6| Step: 6
Training loss: 0.3569394383819534
Validation loss: 2.5689259106129048

Epoch: 6| Step: 7
Training loss: 0.266825040835736
Validation loss: 2.567937187331973

Epoch: 6| Step: 8
Training loss: 0.3608995112124352
Validation loss: 2.599749804875463

Epoch: 6| Step: 9
Training loss: 0.3376643796027726
Validation loss: 2.576800098231209

Epoch: 6| Step: 10
Training loss: 0.407306727287824
Validation loss: 2.6134406034345505

Epoch: 6| Step: 11
Training loss: 0.31282720125390745
Validation loss: 2.5794316237038437

Epoch: 6| Step: 12
Training loss: 0.3597735392707508
Validation loss: 2.5625023520454118

Epoch: 6| Step: 13
Training loss: 0.22756240790453533
Validation loss: 2.5947819186702605

Epoch: 631| Step: 0
Training loss: 0.23587906947615525
Validation loss: 2.614732101150369

Epoch: 6| Step: 1
Training loss: 0.21199903234955988
Validation loss: 2.603897274398842

Epoch: 6| Step: 2
Training loss: 0.4099123638395391
Validation loss: 2.614825285364218

Epoch: 6| Step: 3
Training loss: 0.22496091450185868
Validation loss: 2.646744671824845

Epoch: 6| Step: 4
Training loss: 0.2822476283464559
Validation loss: 2.587799227914103

Epoch: 6| Step: 5
Training loss: 0.22263945131342555
Validation loss: 2.6070300564411695

Epoch: 6| Step: 6
Training loss: 0.43858633387770973
Validation loss: 2.638297834915143

Epoch: 6| Step: 7
Training loss: 0.44441004543831
Validation loss: 2.5821049403137155

Epoch: 6| Step: 8
Training loss: 0.2444349117449266
Validation loss: 2.5968961980661915

Epoch: 6| Step: 9
Training loss: 0.20711368143330755
Validation loss: 2.59423334071171

Epoch: 6| Step: 10
Training loss: 0.19164964226254666
Validation loss: 2.5535398631732504

Epoch: 6| Step: 11
Training loss: 0.20231183216407814
Validation loss: 2.554324524666275

Epoch: 6| Step: 12
Training loss: 0.23620649628511692
Validation loss: 2.563015221463763

Epoch: 6| Step: 13
Training loss: 0.31875473467732435
Validation loss: 2.5512490639010585

Epoch: 632| Step: 0
Training loss: 0.16709594960652843
Validation loss: 2.5568310528900757

Epoch: 6| Step: 1
Training loss: 0.2454012254758982
Validation loss: 2.5710851607167053

Epoch: 6| Step: 2
Training loss: 0.26405400031139836
Validation loss: 2.552187583774664

Epoch: 6| Step: 3
Training loss: 0.1779927691493811
Validation loss: 2.609542995520054

Epoch: 6| Step: 4
Training loss: 0.20381833004326405
Validation loss: 2.5493688301301156

Epoch: 6| Step: 5
Training loss: 0.1936662819944584
Validation loss: 2.584466969950292

Epoch: 6| Step: 6
Training loss: 0.1362506619052383
Validation loss: 2.539088341618523

Epoch: 6| Step: 7
Training loss: 0.2768038477868623
Validation loss: 2.5825885783506917

Epoch: 6| Step: 8
Training loss: 0.25217026217894056
Validation loss: 2.577269538559207

Epoch: 6| Step: 9
Training loss: 0.20625469029035293
Validation loss: 2.5536154709538126

Epoch: 6| Step: 10
Training loss: 0.2213280699810979
Validation loss: 2.6016687087398735

Epoch: 6| Step: 11
Training loss: 0.11814566539964808
Validation loss: 2.60547292389572

Epoch: 6| Step: 12
Training loss: 0.188224871492665
Validation loss: 2.6076126990506863

Epoch: 6| Step: 13
Training loss: 0.30356049568059645
Validation loss: 2.5841913234104767

Epoch: 633| Step: 0
Training loss: 0.23648371973315552
Validation loss: 2.5632995960662095

Epoch: 6| Step: 1
Training loss: 0.18025579975839487
Validation loss: 2.588584315391699

Epoch: 6| Step: 2
Training loss: 0.145754132022897
Validation loss: 2.5749132637168834

Epoch: 6| Step: 3
Training loss: 0.24912406533808112
Validation loss: 2.5754837582088577

Epoch: 6| Step: 4
Training loss: 0.2058788833205595
Validation loss: 2.561483420139095

Epoch: 6| Step: 5
Training loss: 0.19307761422688852
Validation loss: 2.5762778667146433

Epoch: 6| Step: 6
Training loss: 0.21116832183998616
Validation loss: 2.5629449593600993

Epoch: 6| Step: 7
Training loss: 0.21612265282542814
Validation loss: 2.5521045421918647

Epoch: 6| Step: 8
Training loss: 0.24893749474389687
Validation loss: 2.5685930262845615

Epoch: 6| Step: 9
Training loss: 0.17829716836204662
Validation loss: 2.570236940529718

Epoch: 6| Step: 10
Training loss: 0.23885042969255962
Validation loss: 2.5516138006907667

Epoch: 6| Step: 11
Training loss: 0.14434173118102853
Validation loss: 2.5695171175938336

Epoch: 6| Step: 12
Training loss: 0.2527158120131847
Validation loss: 2.5415133190107797

Epoch: 6| Step: 13
Training loss: 0.12870692969002737
Validation loss: 2.549861671911088

Epoch: 634| Step: 0
Training loss: 0.20580417537216406
Validation loss: 2.5434608770249945

Epoch: 6| Step: 1
Training loss: 0.16396337307423225
Validation loss: 2.5518055804659916

Epoch: 6| Step: 2
Training loss: 0.18756367675033309
Validation loss: 2.5414010011111565

Epoch: 6| Step: 3
Training loss: 0.2116784574730223
Validation loss: 2.5608446550618704

Epoch: 6| Step: 4
Training loss: 0.20349575099445727
Validation loss: 2.564888670965067

Epoch: 6| Step: 5
Training loss: 0.26696505237757234
Validation loss: 2.5739995027844045

Epoch: 6| Step: 6
Training loss: 0.2525759546839752
Validation loss: 2.5776765663938583

Epoch: 6| Step: 7
Training loss: 0.14345254962482912
Validation loss: 2.5291848852859644

Epoch: 6| Step: 8
Training loss: 0.12527685500343386
Validation loss: 2.5394115355129605

Epoch: 6| Step: 9
Training loss: 0.17121669562907615
Validation loss: 2.565013308259184

Epoch: 6| Step: 10
Training loss: 0.15616607200104085
Validation loss: 2.572215519084282

Epoch: 6| Step: 11
Training loss: 0.17344024329550464
Validation loss: 2.5175223135945815

Epoch: 6| Step: 12
Training loss: 0.1545529594446262
Validation loss: 2.5945018968826496

Epoch: 6| Step: 13
Training loss: 0.21024866128590566
Validation loss: 2.5781003113699055

Epoch: 635| Step: 0
Training loss: 0.18019990837013336
Validation loss: 2.5896572751875717

Epoch: 6| Step: 1
Training loss: 0.23773805270075352
Validation loss: 2.5744651997511228

Epoch: 6| Step: 2
Training loss: 0.315420947824817
Validation loss: 2.555138613757677

Epoch: 6| Step: 3
Training loss: 0.14361227917383207
Validation loss: 2.5987361844499803

Epoch: 6| Step: 4
Training loss: 0.18208810589607638
Validation loss: 2.5766253045086462

Epoch: 6| Step: 5
Training loss: 0.17089563639933789
Validation loss: 2.56732640122357

Epoch: 6| Step: 6
Training loss: 0.16751488646145293
Validation loss: 2.5762150993522073

Epoch: 6| Step: 7
Training loss: 0.14459352182782936
Validation loss: 2.581501235341713

Epoch: 6| Step: 8
Training loss: 0.13656860690352704
Validation loss: 2.6036876269040805

Epoch: 6| Step: 9
Training loss: 0.16579904453582656
Validation loss: 2.5814963672525284

Epoch: 6| Step: 10
Training loss: 0.2001411736950101
Validation loss: 2.584480531742033

Epoch: 6| Step: 11
Training loss: 0.15481989377476194
Validation loss: 2.5858299263480915

Epoch: 6| Step: 12
Training loss: 0.22899896091741842
Validation loss: 2.5926607179488865

Epoch: 6| Step: 13
Training loss: 0.203909642275366
Validation loss: 2.583904365664605

Epoch: 636| Step: 0
Training loss: 0.17057331221051739
Validation loss: 2.5447876393462763

Epoch: 6| Step: 1
Training loss: 0.21978775867645883
Validation loss: 2.596440517163659

Epoch: 6| Step: 2
Training loss: 0.17455395239264743
Validation loss: 2.568924905684497

Epoch: 6| Step: 3
Training loss: 0.11752834422696529
Validation loss: 2.571923502193074

Epoch: 6| Step: 4
Training loss: 0.11928330148747154
Validation loss: 2.5405584192322386

Epoch: 6| Step: 5
Training loss: 0.14739665468164578
Validation loss: 2.554010034538923

Epoch: 6| Step: 6
Training loss: 0.11286255725159282
Validation loss: 2.5678472724486663

Epoch: 6| Step: 7
Training loss: 0.13094231126681402
Validation loss: 2.587869807829262

Epoch: 6| Step: 8
Training loss: 0.17184140137078366
Validation loss: 2.5416078108481046

Epoch: 6| Step: 9
Training loss: 0.1915683643694247
Validation loss: 2.577403644115664

Epoch: 6| Step: 10
Training loss: 0.09882014019942283
Validation loss: 2.5782406778197378

Epoch: 6| Step: 11
Training loss: 0.14697591961757722
Validation loss: 2.5997692203330187

Epoch: 6| Step: 12
Training loss: 0.1548865314244013
Validation loss: 2.570593359679016

Epoch: 6| Step: 13
Training loss: 0.18608517112143308
Validation loss: 2.5928927765722234

Epoch: 637| Step: 0
Training loss: 0.18678598749523193
Validation loss: 2.5810554920349063

Epoch: 6| Step: 1
Training loss: 0.1676030058274295
Validation loss: 2.594364493273412

Epoch: 6| Step: 2
Training loss: 0.1726680255343782
Validation loss: 2.607417540027947

Epoch: 6| Step: 3
Training loss: 0.21680334442383578
Validation loss: 2.601900001398606

Epoch: 6| Step: 4
Training loss: 0.17273279193651375
Validation loss: 2.5883768951555965

Epoch: 6| Step: 5
Training loss: 0.12323787790492602
Validation loss: 2.5601178894150105

Epoch: 6| Step: 6
Training loss: 0.13533542256091338
Validation loss: 2.6143602803016908

Epoch: 6| Step: 7
Training loss: 0.15004987011841578
Validation loss: 2.5721859996511407

Epoch: 6| Step: 8
Training loss: 0.1320354506146049
Validation loss: 2.5881297697280896

Epoch: 6| Step: 9
Training loss: 0.16423798440286497
Validation loss: 2.590033113016367

Epoch: 6| Step: 10
Training loss: 0.15921740874828952
Validation loss: 2.582392951768529

Epoch: 6| Step: 11
Training loss: 0.21338857807787412
Validation loss: 2.622869100338682

Epoch: 6| Step: 12
Training loss: 0.19361492570732658
Validation loss: 2.6173846250622086

Epoch: 6| Step: 13
Training loss: 0.1177968395762878
Validation loss: 2.5725207136011803

Epoch: 638| Step: 0
Training loss: 0.18958105113853127
Validation loss: 2.5757945635565163

Epoch: 6| Step: 1
Training loss: 0.16663009023653752
Validation loss: 2.585732779351872

Epoch: 6| Step: 2
Training loss: 0.1560928985450288
Validation loss: 2.5857931712143603

Epoch: 6| Step: 3
Training loss: 0.21424115376142572
Validation loss: 2.61057004629634

Epoch: 6| Step: 4
Training loss: 0.20062056245382348
Validation loss: 2.6142347693659764

Epoch: 6| Step: 5
Training loss: 0.11742208366603928
Validation loss: 2.662422960102604

Epoch: 6| Step: 6
Training loss: 0.09549374935155888
Validation loss: 2.6081845906906778

Epoch: 6| Step: 7
Training loss: 0.1418062572160136
Validation loss: 2.5941839506229307

Epoch: 6| Step: 8
Training loss: 0.09018159660440891
Validation loss: 2.61605808265172

Epoch: 6| Step: 9
Training loss: 0.11722695957867832
Validation loss: 2.6030721061483466

Epoch: 6| Step: 10
Training loss: 0.12515024751801804
Validation loss: 2.5827441517824576

Epoch: 6| Step: 11
Training loss: 0.10077262885900956
Validation loss: 2.5707684428658513

Epoch: 6| Step: 12
Training loss: 0.14165805479011226
Validation loss: 2.595859593828251

Epoch: 6| Step: 13
Training loss: 0.0883950803509469
Validation loss: 2.5614662516349016

Epoch: 639| Step: 0
Training loss: 0.1578548919753288
Validation loss: 2.5645207946604884

Epoch: 6| Step: 1
Training loss: 0.1410539825873983
Validation loss: 2.5576109187635128

Epoch: 6| Step: 2
Training loss: 0.1661596458895886
Validation loss: 2.602788481896425

Epoch: 6| Step: 3
Training loss: 0.13286590203792578
Validation loss: 2.5589065897810657

Epoch: 6| Step: 4
Training loss: 0.12368508238884938
Validation loss: 2.5751740900645603

Epoch: 6| Step: 5
Training loss: 0.1313519246708932
Validation loss: 2.5469553643049334

Epoch: 6| Step: 6
Training loss: 0.17876848221976102
Validation loss: 2.532517249003845

Epoch: 6| Step: 7
Training loss: 0.18698099944793495
Validation loss: 2.565213701128974

Epoch: 6| Step: 8
Training loss: 0.1436689856022442
Validation loss: 2.551559772910353

Epoch: 6| Step: 9
Training loss: 0.15951956989224247
Validation loss: 2.5673145632158323

Epoch: 6| Step: 10
Training loss: 0.14838079574082877
Validation loss: 2.595436594047357

Epoch: 6| Step: 11
Training loss: 0.1570196804605168
Validation loss: 2.5622465827223393

Epoch: 6| Step: 12
Training loss: 0.16755708437879097
Validation loss: 2.5939709366302854

Epoch: 6| Step: 13
Training loss: 0.11545061980216803
Validation loss: 2.5650710406969357

Epoch: 640| Step: 0
Training loss: 0.15517644431931008
Validation loss: 2.540298112294688

Epoch: 6| Step: 1
Training loss: 0.1758857945984212
Validation loss: 2.5890187456682914

Epoch: 6| Step: 2
Training loss: 0.08761236860379981
Validation loss: 2.5834396190260485

Epoch: 6| Step: 3
Training loss: 0.11720596803736921
Validation loss: 2.59189863139896

Epoch: 6| Step: 4
Training loss: 0.1538235974941177
Validation loss: 2.5754821765152407

Epoch: 6| Step: 5
Training loss: 0.14966410241004766
Validation loss: 2.5833411307586056

Epoch: 6| Step: 6
Training loss: 0.09053687505328605
Validation loss: 2.6070524729455484

Epoch: 6| Step: 7
Training loss: 0.10617118499789889
Validation loss: 2.553574222318412

Epoch: 6| Step: 8
Training loss: 0.18163895349861486
Validation loss: 2.600393458145078

Epoch: 6| Step: 9
Training loss: 0.17989043510597297
Validation loss: 2.6166949682179363

Epoch: 6| Step: 10
Training loss: 0.13985778881976682
Validation loss: 2.5761579166911077

Epoch: 6| Step: 11
Training loss: 0.151087126522592
Validation loss: 2.6014278344615756

Epoch: 6| Step: 12
Training loss: 0.15213860858318703
Validation loss: 2.580322443840345

Epoch: 6| Step: 13
Training loss: 0.11763868894895316
Validation loss: 2.5670204688106932

Epoch: 641| Step: 0
Training loss: 0.14196344370647973
Validation loss: 2.5558387550907344

Epoch: 6| Step: 1
Training loss: 0.15624449243375624
Validation loss: 2.5769822686569777

Epoch: 6| Step: 2
Training loss: 0.13405677018447706
Validation loss: 2.582038651890873

Epoch: 6| Step: 3
Training loss: 0.100579729166375
Validation loss: 2.572717289653764

Epoch: 6| Step: 4
Training loss: 0.10766118875699578
Validation loss: 2.557756739588855

Epoch: 6| Step: 5
Training loss: 0.16574784167856577
Validation loss: 2.57473212430869

Epoch: 6| Step: 6
Training loss: 0.10454931212871214
Validation loss: 2.5535047345253132

Epoch: 6| Step: 7
Training loss: 0.08815958936242727
Validation loss: 2.553450541689567

Epoch: 6| Step: 8
Training loss: 0.10623019906970814
Validation loss: 2.57757684393472

Epoch: 6| Step: 9
Training loss: 0.12404232932556479
Validation loss: 2.6119366090879534

Epoch: 6| Step: 10
Training loss: 0.10274162266915166
Validation loss: 2.54884992486519

Epoch: 6| Step: 11
Training loss: 0.18080635653138627
Validation loss: 2.5763181040526084

Epoch: 6| Step: 12
Training loss: 0.09197023943862531
Validation loss: 2.573039654044199

Epoch: 6| Step: 13
Training loss: 0.06484973144519761
Validation loss: 2.5689038979004386

Epoch: 642| Step: 0
Training loss: 0.14673669065529615
Validation loss: 2.5745255258241095

Epoch: 6| Step: 1
Training loss: 0.09288214789226668
Validation loss: 2.5694797769157236

Epoch: 6| Step: 2
Training loss: 0.1405028899165411
Validation loss: 2.5252289973900295

Epoch: 6| Step: 3
Training loss: 0.15648267230832527
Validation loss: 2.53308827483805

Epoch: 6| Step: 4
Training loss: 0.16191205114350854
Validation loss: 2.5686781943438657

Epoch: 6| Step: 5
Training loss: 0.08995842870940159
Validation loss: 2.583108940527647

Epoch: 6| Step: 6
Training loss: 0.11123566803741278
Validation loss: 2.532313366702728

Epoch: 6| Step: 7
Training loss: 0.17587511947088244
Validation loss: 2.5555256480975164

Epoch: 6| Step: 8
Training loss: 0.15102993711330698
Validation loss: 2.5639104915474316

Epoch: 6| Step: 9
Training loss: 0.07985695674647986
Validation loss: 2.57091970883149

Epoch: 6| Step: 10
Training loss: 0.10043219510912756
Validation loss: 2.535676527968829

Epoch: 6| Step: 11
Training loss: 0.1877118443761562
Validation loss: 2.571220710511759

Epoch: 6| Step: 12
Training loss: 0.12102836720347501
Validation loss: 2.5455229231744037

Epoch: 6| Step: 13
Training loss: 0.1640393604127428
Validation loss: 2.581900290113087

Epoch: 643| Step: 0
Training loss: 0.2158817100360084
Validation loss: 2.585394972145427

Epoch: 6| Step: 1
Training loss: 0.10350339745333396
Validation loss: 2.5593965607442053

Epoch: 6| Step: 2
Training loss: 0.12498557484362381
Validation loss: 2.5915132167012107

Epoch: 6| Step: 3
Training loss: 0.17271011297745506
Validation loss: 2.570992939857038

Epoch: 6| Step: 4
Training loss: 0.19457334844230667
Validation loss: 2.587240964948187

Epoch: 6| Step: 5
Training loss: 0.10736664739518854
Validation loss: 2.5936711587597485

Epoch: 6| Step: 6
Training loss: 0.179981819930156
Validation loss: 2.5966869795134273

Epoch: 6| Step: 7
Training loss: 0.11158380511353055
Validation loss: 2.5887931073874637

Epoch: 6| Step: 8
Training loss: 0.10572487584773388
Validation loss: 2.606493647994701

Epoch: 6| Step: 9
Training loss: 0.1668047829390494
Validation loss: 2.599098557055903

Epoch: 6| Step: 10
Training loss: 0.0858817976629039
Validation loss: 2.5916288469309845

Epoch: 6| Step: 11
Training loss: 0.15364123730870624
Validation loss: 2.5533227385051025

Epoch: 6| Step: 12
Training loss: 0.16782800743973297
Validation loss: 2.552497545539044

Epoch: 6| Step: 13
Training loss: 0.12012612689489002
Validation loss: 2.59033650219675

Epoch: 644| Step: 0
Training loss: 0.12685952771089892
Validation loss: 2.5427473592589918

Epoch: 6| Step: 1
Training loss: 0.17260861969657645
Validation loss: 2.549939879565861

Epoch: 6| Step: 2
Training loss: 0.20376915762651418
Validation loss: 2.533898871021904

Epoch: 6| Step: 3
Training loss: 0.12117826296768501
Validation loss: 2.531917428831741

Epoch: 6| Step: 4
Training loss: 0.10626596688461107
Validation loss: 2.5330140785247814

Epoch: 6| Step: 5
Training loss: 0.07380198490245737
Validation loss: 2.5434001044317505

Epoch: 6| Step: 6
Training loss: 0.17223703121139777
Validation loss: 2.5138854040726306

Epoch: 6| Step: 7
Training loss: 0.20542672819046878
Validation loss: 2.554594013808771

Epoch: 6| Step: 8
Training loss: 0.13012080509054944
Validation loss: 2.5628310139073154

Epoch: 6| Step: 9
Training loss: 0.15590569589416617
Validation loss: 2.5685941341441807

Epoch: 6| Step: 10
Training loss: 0.11226499104702425
Validation loss: 2.5777571151242022

Epoch: 6| Step: 11
Training loss: 0.18953929003513215
Validation loss: 2.564080670485529

Epoch: 6| Step: 12
Training loss: 0.11094483264007815
Validation loss: 2.5645822075903757

Epoch: 6| Step: 13
Training loss: 0.19739683905037472
Validation loss: 2.5547124710862077

Epoch: 645| Step: 0
Training loss: 0.0876511437072846
Validation loss: 2.5463931978476952

Epoch: 6| Step: 1
Training loss: 0.17441358982718433
Validation loss: 2.550816460375699

Epoch: 6| Step: 2
Training loss: 0.07219629570603474
Validation loss: 2.5554879846002394

Epoch: 6| Step: 3
Training loss: 0.11249650661687201
Validation loss: 2.549614616643085

Epoch: 6| Step: 4
Training loss: 0.16123620964009805
Validation loss: 2.5518798371969873

Epoch: 6| Step: 5
Training loss: 0.14776710279874758
Validation loss: 2.561962260347445

Epoch: 6| Step: 6
Training loss: 0.14409408955315828
Validation loss: 2.547343358174764

Epoch: 6| Step: 7
Training loss: 0.1012967695650196
Validation loss: 2.5496753964570344

Epoch: 6| Step: 8
Training loss: 0.13365399023076235
Validation loss: 2.5676408548459104

Epoch: 6| Step: 9
Training loss: 0.12138032842680774
Validation loss: 2.524936676815239

Epoch: 6| Step: 10
Training loss: 0.11660124844200485
Validation loss: 2.5430276603460125

Epoch: 6| Step: 11
Training loss: 0.15861548148034726
Validation loss: 2.505395112054724

Epoch: 6| Step: 12
Training loss: 0.10449556541330697
Validation loss: 2.5701893435559557

Epoch: 6| Step: 13
Training loss: 0.1266921074419451
Validation loss: 2.548606321844036

Epoch: 646| Step: 0
Training loss: 0.09100187263225673
Validation loss: 2.58882657778317

Epoch: 6| Step: 1
Training loss: 0.14090274826405877
Validation loss: 2.5302512202337453

Epoch: 6| Step: 2
Training loss: 0.147079910228581
Validation loss: 2.5582114097987643

Epoch: 6| Step: 3
Training loss: 0.09457319172537926
Validation loss: 2.5861738866655513

Epoch: 6| Step: 4
Training loss: 0.0962748770488161
Validation loss: 2.5418925047998178

Epoch: 6| Step: 5
Training loss: 0.18688637938029207
Validation loss: 2.5480206472915405

Epoch: 6| Step: 6
Training loss: 0.12275191937449333
Validation loss: 2.604847012073914

Epoch: 6| Step: 7
Training loss: 0.11093464548844224
Validation loss: 2.5545568398591416

Epoch: 6| Step: 8
Training loss: 0.0719750755917923
Validation loss: 2.5444745671492117

Epoch: 6| Step: 9
Training loss: 0.13500598536574462
Validation loss: 2.5500480910923238

Epoch: 6| Step: 10
Training loss: 0.1182167156598045
Validation loss: 2.53825734286048

Epoch: 6| Step: 11
Training loss: 0.15045594369852927
Validation loss: 2.5624311924622103

Epoch: 6| Step: 12
Training loss: 0.17418828364272287
Validation loss: 2.5511559079313595

Epoch: 6| Step: 13
Training loss: 0.1503134318816549
Validation loss: 2.525765772829196

Epoch: 647| Step: 0
Training loss: 0.16284543423686668
Validation loss: 2.521164419720076

Epoch: 6| Step: 1
Training loss: 0.09585684478392671
Validation loss: 2.5196590965085464

Epoch: 6| Step: 2
Training loss: 0.11178073980547189
Validation loss: 2.521522982568441

Epoch: 6| Step: 3
Training loss: 0.12970572424001625
Validation loss: 2.5313419683357004

Epoch: 6| Step: 4
Training loss: 0.09083968642948481
Validation loss: 2.5285365566639313

Epoch: 6| Step: 5
Training loss: 0.11288947563510264
Validation loss: 2.559051497774276

Epoch: 6| Step: 6
Training loss: 0.1392734936075156
Validation loss: 2.533327927715879

Epoch: 6| Step: 7
Training loss: 0.09702074216684507
Validation loss: 2.524465330952097

Epoch: 6| Step: 8
Training loss: 0.09019964156535556
Validation loss: 2.562125127800737

Epoch: 6| Step: 9
Training loss: 0.07041818239705795
Validation loss: 2.5446671423805767

Epoch: 6| Step: 10
Training loss: 0.09076433610189799
Validation loss: 2.572800207738606

Epoch: 6| Step: 11
Training loss: 0.11796172607429128
Validation loss: 2.5385410588087796

Epoch: 6| Step: 12
Training loss: 0.15100620047955007
Validation loss: 2.578674428895029

Epoch: 6| Step: 13
Training loss: 0.12367707419898101
Validation loss: 2.5744328625857062

Epoch: 648| Step: 0
Training loss: 0.0787624164757182
Validation loss: 2.5219285586327587

Epoch: 6| Step: 1
Training loss: 0.10460868918555176
Validation loss: 2.5409731538254703

Epoch: 6| Step: 2
Training loss: 0.1573571142924965
Validation loss: 2.5539847795413215

Epoch: 6| Step: 3
Training loss: 0.09750472711450102
Validation loss: 2.526262542908934

Epoch: 6| Step: 4
Training loss: 0.11888725667938017
Validation loss: 2.5142623827720305

Epoch: 6| Step: 5
Training loss: 0.07936090177076423
Validation loss: 2.55036409357677

Epoch: 6| Step: 6
Training loss: 0.08651834315766009
Validation loss: 2.5810041622054833

Epoch: 6| Step: 7
Training loss: 0.1885131049432376
Validation loss: 2.5549918036751533

Epoch: 6| Step: 8
Training loss: 0.13437199811022
Validation loss: 2.520663174735872

Epoch: 6| Step: 9
Training loss: 0.09456749469509337
Validation loss: 2.529184594376071

Epoch: 6| Step: 10
Training loss: 0.11710326028018497
Validation loss: 2.4990771472037796

Epoch: 6| Step: 11
Training loss: 0.13366312517817083
Validation loss: 2.489804570624234

Epoch: 6| Step: 12
Training loss: 0.1580367803249011
Validation loss: 2.5238871479681735

Epoch: 6| Step: 13
Training loss: 0.15394273993417193
Validation loss: 2.5612753365991785

Epoch: 649| Step: 0
Training loss: 0.08363313749696533
Validation loss: 2.546464650816987

Epoch: 6| Step: 1
Training loss: 0.135536538920029
Validation loss: 2.551472510209731

Epoch: 6| Step: 2
Training loss: 0.12541846919850255
Validation loss: 2.5684170042775087

Epoch: 6| Step: 3
Training loss: 0.10003692366232508
Validation loss: 2.5402315957840114

Epoch: 6| Step: 4
Training loss: 0.11306122261061709
Validation loss: 2.539806232430224

Epoch: 6| Step: 5
Training loss: 0.10504756823538948
Validation loss: 2.5868025682506466

Epoch: 6| Step: 6
Training loss: 0.1183296651030993
Validation loss: 2.570776039732679

Epoch: 6| Step: 7
Training loss: 0.18284737262517617
Validation loss: 2.562806400015859

Epoch: 6| Step: 8
Training loss: 0.10324205380509402
Validation loss: 2.5806134954235063

Epoch: 6| Step: 9
Training loss: 0.12960115166365085
Validation loss: 2.5646063998409163

Epoch: 6| Step: 10
Training loss: 0.09367963514564343
Validation loss: 2.576555644386111

Epoch: 6| Step: 11
Training loss: 0.14741724516447074
Validation loss: 2.544041492605235

Epoch: 6| Step: 12
Training loss: 0.18093681366614062
Validation loss: 2.556978371968501

Epoch: 6| Step: 13
Training loss: 0.15314193845990728
Validation loss: 2.56915036404752

Epoch: 650| Step: 0
Training loss: 0.11513498837219847
Validation loss: 2.5705257922848315

Epoch: 6| Step: 1
Training loss: 0.17522042136010055
Validation loss: 2.588230021118195

Epoch: 6| Step: 2
Training loss: 0.1743558149910146
Validation loss: 2.572709136507283

Epoch: 6| Step: 3
Training loss: 0.1047905157092702
Validation loss: 2.5532886711677687

Epoch: 6| Step: 4
Training loss: 0.17339092630238312
Validation loss: 2.5730894131306683

Epoch: 6| Step: 5
Training loss: 0.14229997519754595
Validation loss: 2.5805930521886418

Epoch: 6| Step: 6
Training loss: 0.07093043130891566
Validation loss: 2.563321421876775

Epoch: 6| Step: 7
Training loss: 0.13368200627141177
Validation loss: 2.581990665814772

Epoch: 6| Step: 8
Training loss: 0.10782164832015251
Validation loss: 2.522539821396497

Epoch: 6| Step: 9
Training loss: 0.1269960844274526
Validation loss: 2.544246633710164

Epoch: 6| Step: 10
Training loss: 0.14645831830018763
Validation loss: 2.5703894904765154

Epoch: 6| Step: 11
Training loss: 0.08741981182612628
Validation loss: 2.582871952264343

Epoch: 6| Step: 12
Training loss: 0.1283281323911209
Validation loss: 2.5629800546434254

Epoch: 6| Step: 13
Training loss: 0.1739932625979594
Validation loss: 2.556433710671108

Epoch: 651| Step: 0
Training loss: 0.1633405126138084
Validation loss: 2.5378655491678406

Epoch: 6| Step: 1
Training loss: 0.11013805783657309
Validation loss: 2.565739498576443

Epoch: 6| Step: 2
Training loss: 0.10862217829483137
Validation loss: 2.5471591948181076

Epoch: 6| Step: 3
Training loss: 0.12274844446527117
Validation loss: 2.5615462001976548

Epoch: 6| Step: 4
Training loss: 0.10518417555127875
Validation loss: 2.560830078122397

Epoch: 6| Step: 5
Training loss: 0.10324758338755638
Validation loss: 2.5574717446464255

Epoch: 6| Step: 6
Training loss: 0.15837392887861246
Validation loss: 2.5767591137815056

Epoch: 6| Step: 7
Training loss: 0.10080813891975281
Validation loss: 2.5701837169227697

Epoch: 6| Step: 8
Training loss: 0.09697804027873644
Validation loss: 2.5654465641669666

Epoch: 6| Step: 9
Training loss: 0.13221954062227048
Validation loss: 2.558020693810412

Epoch: 6| Step: 10
Training loss: 0.1289679061939688
Validation loss: 2.596156035116384

Epoch: 6| Step: 11
Training loss: 0.1416527819900081
Validation loss: 2.5750624200200796

Epoch: 6| Step: 12
Training loss: 0.12565739439353288
Validation loss: 2.5650153681554078

Epoch: 6| Step: 13
Training loss: 0.07273599544977724
Validation loss: 2.5886325426966197

Epoch: 652| Step: 0
Training loss: 0.12709868962368753
Validation loss: 2.545989407462161

Epoch: 6| Step: 1
Training loss: 0.1502180037701147
Validation loss: 2.5702855280525

Epoch: 6| Step: 2
Training loss: 0.15199195150034986
Validation loss: 2.5816808060038063

Epoch: 6| Step: 3
Training loss: 0.09827151078939628
Validation loss: 2.5615244923709546

Epoch: 6| Step: 4
Training loss: 0.10240312375548834
Validation loss: 2.58993441619251

Epoch: 6| Step: 5
Training loss: 0.08802478934695913
Validation loss: 2.5551160749110857

Epoch: 6| Step: 6
Training loss: 0.11437550213708768
Validation loss: 2.581303636376562

Epoch: 6| Step: 7
Training loss: 0.1274857937036873
Validation loss: 2.5776638002566656

Epoch: 6| Step: 8
Training loss: 0.1613303505326061
Validation loss: 2.562286935347649

Epoch: 6| Step: 9
Training loss: 0.09006867552735588
Validation loss: 2.603593669897951

Epoch: 6| Step: 10
Training loss: 0.11263388607510767
Validation loss: 2.578051329175732

Epoch: 6| Step: 11
Training loss: 0.0956868332989749
Validation loss: 2.568426611360365

Epoch: 6| Step: 12
Training loss: 0.16106568296408544
Validation loss: 2.570911259807305

Epoch: 6| Step: 13
Training loss: 0.10225675867927717
Validation loss: 2.6026813131669746

Epoch: 653| Step: 0
Training loss: 0.12361783815309232
Validation loss: 2.5376801090281944

Epoch: 6| Step: 1
Training loss: 0.11172952149889229
Validation loss: 2.5814246378436767

Epoch: 6| Step: 2
Training loss: 0.12927571725751483
Validation loss: 2.562069656408436

Epoch: 6| Step: 3
Training loss: 0.07586665932246883
Validation loss: 2.574365406669228

Epoch: 6| Step: 4
Training loss: 0.12067849732043796
Validation loss: 2.6061026844077384

Epoch: 6| Step: 5
Training loss: 0.11169494045073135
Validation loss: 2.5617193197870893

Epoch: 6| Step: 6
Training loss: 0.127792532394063
Validation loss: 2.573994415834127

Epoch: 6| Step: 7
Training loss: 0.1053177184855161
Validation loss: 2.543012235274181

Epoch: 6| Step: 8
Training loss: 0.1026233871323928
Validation loss: 2.563613889610819

Epoch: 6| Step: 9
Training loss: 0.10475698680809746
Validation loss: 2.565721132546999

Epoch: 6| Step: 10
Training loss: 0.17431707943057054
Validation loss: 2.549250448364729

Epoch: 6| Step: 11
Training loss: 0.10832559010758504
Validation loss: 2.5484445817269217

Epoch: 6| Step: 12
Training loss: 0.19639082780557882
Validation loss: 2.5660229388539193

Epoch: 6| Step: 13
Training loss: 0.15204458328188397
Validation loss: 2.5641656149979752

Epoch: 654| Step: 0
Training loss: 0.08329668269746128
Validation loss: 2.5685294083910093

Epoch: 6| Step: 1
Training loss: 0.14454628247622162
Validation loss: 2.5771074570978705

Epoch: 6| Step: 2
Training loss: 0.08633928226850494
Validation loss: 2.5711162662011566

Epoch: 6| Step: 3
Training loss: 0.12011114741079991
Validation loss: 2.6034952124170294

Epoch: 6| Step: 4
Training loss: 0.13971125250366312
Validation loss: 2.6060663725898583

Epoch: 6| Step: 5
Training loss: 0.06629230035035022
Validation loss: 2.569438237193188

Epoch: 6| Step: 6
Training loss: 0.19585990488766605
Validation loss: 2.5984954990696516

Epoch: 6| Step: 7
Training loss: 0.1296529528551918
Validation loss: 2.5732203830709657

Epoch: 6| Step: 8
Training loss: 0.11084665790063515
Validation loss: 2.5715920725852666

Epoch: 6| Step: 9
Training loss: 0.07746280829016787
Validation loss: 2.567560253346736

Epoch: 6| Step: 10
Training loss: 0.11228742052105373
Validation loss: 2.573439751455153

Epoch: 6| Step: 11
Training loss: 0.14187554129316612
Validation loss: 2.5474554150808544

Epoch: 6| Step: 12
Training loss: 0.1503391982991015
Validation loss: 2.545874088874744

Epoch: 6| Step: 13
Training loss: 0.153637460841496
Validation loss: 2.556628814724887

Epoch: 655| Step: 0
Training loss: 0.12575775187622967
Validation loss: 2.570921347179124

Epoch: 6| Step: 1
Training loss: 0.15267212030697336
Validation loss: 2.5776788449179278

Epoch: 6| Step: 2
Training loss: 0.13708629930204658
Validation loss: 2.5742251356435535

Epoch: 6| Step: 3
Training loss: 0.07087221159739636
Validation loss: 2.583691941920354

Epoch: 6| Step: 4
Training loss: 0.11317038866347136
Validation loss: 2.5373181218339718

Epoch: 6| Step: 5
Training loss: 0.11290195698604706
Validation loss: 2.5654430481413812

Epoch: 6| Step: 6
Training loss: 0.0961537941143922
Validation loss: 2.5477689624481563

Epoch: 6| Step: 7
Training loss: 0.12162737785878874
Validation loss: 2.5986476903825397

Epoch: 6| Step: 8
Training loss: 0.1491572285697385
Validation loss: 2.5822876915566892

Epoch: 6| Step: 9
Training loss: 0.09919554634304023
Validation loss: 2.5757205613245864

Epoch: 6| Step: 10
Training loss: 0.12943717685642547
Validation loss: 2.5968514758134518

Epoch: 6| Step: 11
Training loss: 0.08934567090291476
Validation loss: 2.5645624090355246

Epoch: 6| Step: 12
Training loss: 0.12053386786790023
Validation loss: 2.5956711931606424

Epoch: 6| Step: 13
Training loss: 0.11675726671879391
Validation loss: 2.5995582182361754

Epoch: 656| Step: 0
Training loss: 0.0653708392577949
Validation loss: 2.5916301872973593

Epoch: 6| Step: 1
Training loss: 0.08795850834337039
Validation loss: 2.6070066519534922

Epoch: 6| Step: 2
Training loss: 0.0904515738397897
Validation loss: 2.6056363873639303

Epoch: 6| Step: 3
Training loss: 0.15986835376146505
Validation loss: 2.596930092167635

Epoch: 6| Step: 4
Training loss: 0.07225975450951345
Validation loss: 2.5565630093959766

Epoch: 6| Step: 5
Training loss: 0.11376579016563604
Validation loss: 2.5877812136094884

Epoch: 6| Step: 6
Training loss: 0.09083186865677068
Validation loss: 2.5567343592273337

Epoch: 6| Step: 7
Training loss: 0.14863718555248115
Validation loss: 2.6055148759976916

Epoch: 6| Step: 8
Training loss: 0.10430870703400447
Validation loss: 2.552073663053258

Epoch: 6| Step: 9
Training loss: 0.11750510806409438
Validation loss: 2.571219582845751

Epoch: 6| Step: 10
Training loss: 0.09195616273877809
Validation loss: 2.6025795153843685

Epoch: 6| Step: 11
Training loss: 0.12308262502461748
Validation loss: 2.631166358502841

Epoch: 6| Step: 12
Training loss: 0.1356486540264644
Validation loss: 2.5972901514313356

Epoch: 6| Step: 13
Training loss: 0.1699063798262995
Validation loss: 2.6125052706043186

Epoch: 657| Step: 0
Training loss: 0.11579692244152352
Validation loss: 2.550145345394533

Epoch: 6| Step: 1
Training loss: 0.1472478046310251
Validation loss: 2.6006078732837823

Epoch: 6| Step: 2
Training loss: 0.09683403064039818
Validation loss: 2.594071494957671

Epoch: 6| Step: 3
Training loss: 0.14579331467679962
Validation loss: 2.5829301530070428

Epoch: 6| Step: 4
Training loss: 0.09776150276628773
Validation loss: 2.585926834737274

Epoch: 6| Step: 5
Training loss: 0.10701034787311767
Validation loss: 2.551066984338257

Epoch: 6| Step: 6
Training loss: 0.10000059492709097
Validation loss: 2.5650839724489387

Epoch: 6| Step: 7
Training loss: 0.10803291622308114
Validation loss: 2.576766742234383

Epoch: 6| Step: 8
Training loss: 0.14527302559622138
Validation loss: 2.5431540776888495

Epoch: 6| Step: 9
Training loss: 0.08830457269586361
Validation loss: 2.5800538435720863

Epoch: 6| Step: 10
Training loss: 0.06584182155765167
Validation loss: 2.5989601496438324

Epoch: 6| Step: 11
Training loss: 0.09186070840318446
Validation loss: 2.6061618497584806

Epoch: 6| Step: 12
Training loss: 0.14177677232727265
Validation loss: 2.598069456083193

Epoch: 6| Step: 13
Training loss: 0.12906712550309826
Validation loss: 2.576491394257783

Epoch: 658| Step: 0
Training loss: 0.09342258619811995
Validation loss: 2.5761756923377668

Epoch: 6| Step: 1
Training loss: 0.1147244372120676
Validation loss: 2.5896925568948177

Epoch: 6| Step: 2
Training loss: 0.06716144868996828
Validation loss: 2.5869816797603993

Epoch: 6| Step: 3
Training loss: 0.10900021099586364
Validation loss: 2.596292508057882

Epoch: 6| Step: 4
Training loss: 0.09315887492710004
Validation loss: 2.5860702648605485

Epoch: 6| Step: 5
Training loss: 0.16283201105319686
Validation loss: 2.576098514540987

Epoch: 6| Step: 6
Training loss: 0.13239809908705177
Validation loss: 2.573817841882806

Epoch: 6| Step: 7
Training loss: 0.16247345359085105
Validation loss: 2.545428576674556

Epoch: 6| Step: 8
Training loss: 0.09672565523373278
Validation loss: 2.5458469687835947

Epoch: 6| Step: 9
Training loss: 0.15629060336885808
Validation loss: 2.56525341045555

Epoch: 6| Step: 10
Training loss: 0.14137711988912113
Validation loss: 2.5132510780742163

Epoch: 6| Step: 11
Training loss: 0.15276292451147627
Validation loss: 2.565942436398138

Epoch: 6| Step: 12
Training loss: 0.12201342973994825
Validation loss: 2.5781299788649763

Epoch: 6| Step: 13
Training loss: 0.1183519288669974
Validation loss: 2.5237238393971912

Epoch: 659| Step: 0
Training loss: 0.12800000711437295
Validation loss: 2.561989379958784

Epoch: 6| Step: 1
Training loss: 0.1010264408136268
Validation loss: 2.552398241481909

Epoch: 6| Step: 2
Training loss: 0.12572576264459015
Validation loss: 2.557769288359238

Epoch: 6| Step: 3
Training loss: 0.12434711796129329
Validation loss: 2.5628180697867635

Epoch: 6| Step: 4
Training loss: 0.165984880181066
Validation loss: 2.5506058903874362

Epoch: 6| Step: 5
Training loss: 0.16904501095600957
Validation loss: 2.562501735771706

Epoch: 6| Step: 6
Training loss: 0.09728963701076548
Validation loss: 2.572007204393203

Epoch: 6| Step: 7
Training loss: 0.06972906658473914
Validation loss: 2.5667338246893867

Epoch: 6| Step: 8
Training loss: 0.08831207108714055
Validation loss: 2.5965442355654957

Epoch: 6| Step: 9
Training loss: 0.09704578807512641
Validation loss: 2.5949692062922485

Epoch: 6| Step: 10
Training loss: 0.13073072229906144
Validation loss: 2.595120083580098

Epoch: 6| Step: 11
Training loss: 0.09879262648519362
Validation loss: 2.5808745031071543

Epoch: 6| Step: 12
Training loss: 0.16479353162391006
Validation loss: 2.586062761497479

Epoch: 6| Step: 13
Training loss: 0.15710670333290339
Validation loss: 2.5770231595276414

Epoch: 660| Step: 0
Training loss: 0.08883356674052888
Validation loss: 2.580155946842598

Epoch: 6| Step: 1
Training loss: 0.11487456900792842
Validation loss: 2.5689303509547234

Epoch: 6| Step: 2
Training loss: 0.10582679004213012
Validation loss: 2.5718671685824015

Epoch: 6| Step: 3
Training loss: 0.10977651772804063
Validation loss: 2.584227046299322

Epoch: 6| Step: 4
Training loss: 0.09021062166748894
Validation loss: 2.58981391279412

Epoch: 6| Step: 5
Training loss: 0.09506008580457269
Validation loss: 2.6031187621064316

Epoch: 6| Step: 6
Training loss: 0.15782793318945756
Validation loss: 2.56464833894874

Epoch: 6| Step: 7
Training loss: 0.06932965438205613
Validation loss: 2.5657967110979145

Epoch: 6| Step: 8
Training loss: 0.0878384594285936
Validation loss: 2.58675903420163

Epoch: 6| Step: 9
Training loss: 0.12339329018382778
Validation loss: 2.610669024513361

Epoch: 6| Step: 10
Training loss: 0.13881014257178576
Validation loss: 2.584241875674372

Epoch: 6| Step: 11
Training loss: 0.080989127474705
Validation loss: 2.582333712899906

Epoch: 6| Step: 12
Training loss: 0.14253671907112145
Validation loss: 2.605980760949031

Epoch: 6| Step: 13
Training loss: 0.08825511851558954
Validation loss: 2.59309944013038

Epoch: 661| Step: 0
Training loss: 0.10691803771138672
Validation loss: 2.5919834411715796

Epoch: 6| Step: 1
Training loss: 0.1273250267680792
Validation loss: 2.6158613875794243

Epoch: 6| Step: 2
Training loss: 0.13533913856723623
Validation loss: 2.6013996063785965

Epoch: 6| Step: 3
Training loss: 0.09766127096620016
Validation loss: 2.5705688001680236

Epoch: 6| Step: 4
Training loss: 0.08972865486279527
Validation loss: 2.60437438398948

Epoch: 6| Step: 5
Training loss: 0.19599515822509955
Validation loss: 2.5995163534361545

Epoch: 6| Step: 6
Training loss: 0.08917560610661449
Validation loss: 2.6073361357997404

Epoch: 6| Step: 7
Training loss: 0.06837998488228417
Validation loss: 2.5635927393029165

Epoch: 6| Step: 8
Training loss: 0.0819774348984089
Validation loss: 2.578125208820174

Epoch: 6| Step: 9
Training loss: 0.11790114701514308
Validation loss: 2.569135262958023

Epoch: 6| Step: 10
Training loss: 0.16441625535172844
Validation loss: 2.578940880513086

Epoch: 6| Step: 11
Training loss: 0.13834259402083163
Validation loss: 2.5699953298142044

Epoch: 6| Step: 12
Training loss: 0.1100665987381804
Validation loss: 2.5478147434728102

Epoch: 6| Step: 13
Training loss: 0.15838049141366603
Validation loss: 2.5809753750193423

Epoch: 662| Step: 0
Training loss: 0.141526893133417
Validation loss: 2.536448793497966

Epoch: 6| Step: 1
Training loss: 0.11161066475488428
Validation loss: 2.5774907241440657

Epoch: 6| Step: 2
Training loss: 0.10711989438760897
Validation loss: 2.571738632821883

Epoch: 6| Step: 3
Training loss: 0.12709178687990771
Validation loss: 2.585776569615777

Epoch: 6| Step: 4
Training loss: 0.08158537624260687
Validation loss: 2.5876841834597886

Epoch: 6| Step: 5
Training loss: 0.10279769976450727
Validation loss: 2.5677408768237435

Epoch: 6| Step: 6
Training loss: 0.16248346735226368
Validation loss: 2.5691856509666815

Epoch: 6| Step: 7
Training loss: 0.0825191108422038
Validation loss: 2.554765991919805

Epoch: 6| Step: 8
Training loss: 0.14162139753657102
Validation loss: 2.5983966224738553

Epoch: 6| Step: 9
Training loss: 0.10527538304840132
Validation loss: 2.571039168859359

Epoch: 6| Step: 10
Training loss: 0.17464103710354267
Validation loss: 2.588361223323316

Epoch: 6| Step: 11
Training loss: 0.07255468999801669
Validation loss: 2.5654894570926867

Epoch: 6| Step: 12
Training loss: 0.11480690988036076
Validation loss: 2.56696235676538

Epoch: 6| Step: 13
Training loss: 0.1243966898923267
Validation loss: 2.559353543168236

Epoch: 663| Step: 0
Training loss: 0.09553596924046212
Validation loss: 2.5699321217137947

Epoch: 6| Step: 1
Training loss: 0.12616070145772865
Validation loss: 2.5425549136336034

Epoch: 6| Step: 2
Training loss: 0.09042759557162262
Validation loss: 2.5648168639166338

Epoch: 6| Step: 3
Training loss: 0.1471840614881003
Validation loss: 2.566456014831484

Epoch: 6| Step: 4
Training loss: 0.13313351431559167
Validation loss: 2.57984900880351

Epoch: 6| Step: 5
Training loss: 0.14635877947025902
Validation loss: 2.5713564804771187

Epoch: 6| Step: 6
Training loss: 0.1245752920278146
Validation loss: 2.5592622523802144

Epoch: 6| Step: 7
Training loss: 0.14506271952243088
Validation loss: 2.532107379801059

Epoch: 6| Step: 8
Training loss: 0.19294855035240754
Validation loss: 2.533975314734608

Epoch: 6| Step: 9
Training loss: 0.08009109450193763
Validation loss: 2.5982776447272973

Epoch: 6| Step: 10
Training loss: 0.09030856265820715
Validation loss: 2.5766688097881594

Epoch: 6| Step: 11
Training loss: 0.06454223195305171
Validation loss: 2.566468151474346

Epoch: 6| Step: 12
Training loss: 0.09779431596806629
Validation loss: 2.5337639552630855

Epoch: 6| Step: 13
Training loss: 0.12280408809211502
Validation loss: 2.599699283970346

Epoch: 664| Step: 0
Training loss: 0.087005010446877
Validation loss: 2.609839657577854

Epoch: 6| Step: 1
Training loss: 0.14827874126261642
Validation loss: 2.612939170965905

Epoch: 6| Step: 2
Training loss: 0.16373142260810905
Validation loss: 2.5904840029887857

Epoch: 6| Step: 3
Training loss: 0.09987665295396798
Validation loss: 2.6060998414938648

Epoch: 6| Step: 4
Training loss: 0.10300710217111991
Validation loss: 2.6241910677347637

Epoch: 6| Step: 5
Training loss: 0.07891813840160083
Validation loss: 2.6167399646260767

Epoch: 6| Step: 6
Training loss: 0.15827479917028156
Validation loss: 2.5814378005003964

Epoch: 6| Step: 7
Training loss: 0.11295444522607997
Validation loss: 2.6184826255192672

Epoch: 6| Step: 8
Training loss: 0.09207585735237792
Validation loss: 2.5970546280164815

Epoch: 6| Step: 9
Training loss: 0.15054220759506381
Validation loss: 2.605392607207729

Epoch: 6| Step: 10
Training loss: 0.13866951094210686
Validation loss: 2.5974624096386902

Epoch: 6| Step: 11
Training loss: 0.10796038291573945
Validation loss: 2.5580599866459535

Epoch: 6| Step: 12
Training loss: 0.08564263932194735
Validation loss: 2.537637051649092

Epoch: 6| Step: 13
Training loss: 0.053139536372982056
Validation loss: 2.5531219078546594

Epoch: 665| Step: 0
Training loss: 0.12594096841603214
Validation loss: 2.530142645837961

Epoch: 6| Step: 1
Training loss: 0.13540354689596823
Validation loss: 2.523067394268583

Epoch: 6| Step: 2
Training loss: 0.08545004163073368
Validation loss: 2.5288423202684696

Epoch: 6| Step: 3
Training loss: 0.08996286995551836
Validation loss: 2.5189361996474453

Epoch: 6| Step: 4
Training loss: 0.1507340695878386
Validation loss: 2.5468791904008583

Epoch: 6| Step: 5
Training loss: 0.15502648538758482
Validation loss: 2.5127607296517525

Epoch: 6| Step: 6
Training loss: 0.1351379834218068
Validation loss: 2.535678687524279

Epoch: 6| Step: 7
Training loss: 0.10923956677427094
Validation loss: 2.579227066532209

Epoch: 6| Step: 8
Training loss: 0.1536885353059713
Validation loss: 2.530998575010743

Epoch: 6| Step: 9
Training loss: 0.14628484488138355
Validation loss: 2.5916199718086097

Epoch: 6| Step: 10
Training loss: 0.09981220295449224
Validation loss: 2.578851237947958

Epoch: 6| Step: 11
Training loss: 0.126587730706725
Validation loss: 2.5975888533649942

Epoch: 6| Step: 12
Training loss: 0.12733185835470032
Validation loss: 2.577474643966918

Epoch: 6| Step: 13
Training loss: 0.14944755577722196
Validation loss: 2.5886692396896636

Epoch: 666| Step: 0
Training loss: 0.09840731763578561
Validation loss: 2.5746378823107148

Epoch: 6| Step: 1
Training loss: 0.182879764050261
Validation loss: 2.570822238730317

Epoch: 6| Step: 2
Training loss: 0.09287703903213843
Validation loss: 2.575225650582625

Epoch: 6| Step: 3
Training loss: 0.1388514323357631
Validation loss: 2.599027367693327

Epoch: 6| Step: 4
Training loss: 0.13451719190668843
Validation loss: 2.5587496251232236

Epoch: 6| Step: 5
Training loss: 0.09421323038099998
Validation loss: 2.5819400357150126

Epoch: 6| Step: 6
Training loss: 0.24533273710615938
Validation loss: 2.5785362604242095

Epoch: 6| Step: 7
Training loss: 0.16692820656250243
Validation loss: 2.5739395707504094

Epoch: 6| Step: 8
Training loss: 0.11530779261659503
Validation loss: 2.5737190003609913

Epoch: 6| Step: 9
Training loss: 0.12088383276733244
Validation loss: 2.5851648178392215

Epoch: 6| Step: 10
Training loss: 0.10118079900966834
Validation loss: 2.521352655635558

Epoch: 6| Step: 11
Training loss: 0.1407143918005721
Validation loss: 2.544788200472735

Epoch: 6| Step: 12
Training loss: 0.1457798610020055
Validation loss: 2.5510635002477935

Epoch: 6| Step: 13
Training loss: 0.18581884428883289
Validation loss: 2.5471389815388643

Epoch: 667| Step: 0
Training loss: 0.1246187909075563
Validation loss: 2.5532761084086477

Epoch: 6| Step: 1
Training loss: 0.14033489635837126
Validation loss: 2.5378840127358178

Epoch: 6| Step: 2
Training loss: 0.1405105721311661
Validation loss: 2.5273735030814706

Epoch: 6| Step: 3
Training loss: 0.10127806724101297
Validation loss: 2.557410612815979

Epoch: 6| Step: 4
Training loss: 0.06634390232223224
Validation loss: 2.553824254905627

Epoch: 6| Step: 5
Training loss: 0.18674894751082388
Validation loss: 2.5658134569596007

Epoch: 6| Step: 6
Training loss: 0.1112602386625271
Validation loss: 2.559117293209462

Epoch: 6| Step: 7
Training loss: 0.22191257259417346
Validation loss: 2.5936286256404877

Epoch: 6| Step: 8
Training loss: 0.18672255428381093
Validation loss: 2.584578878889302

Epoch: 6| Step: 9
Training loss: 0.15525427286169813
Validation loss: 2.5427931843165905

Epoch: 6| Step: 10
Training loss: 0.16382040599562184
Validation loss: 2.5494623294363876

Epoch: 6| Step: 11
Training loss: 0.08570957845455855
Validation loss: 2.558117820889797

Epoch: 6| Step: 12
Training loss: 0.15197638698891897
Validation loss: 2.55108939113689

Epoch: 6| Step: 13
Training loss: 0.06536255068043852
Validation loss: 2.523383965409013

Epoch: 668| Step: 0
Training loss: 0.09835566400067472
Validation loss: 2.52943496064269

Epoch: 6| Step: 1
Training loss: 0.18149343289824096
Validation loss: 2.521983308869581

Epoch: 6| Step: 2
Training loss: 0.1437849676061581
Validation loss: 2.5315903982044192

Epoch: 6| Step: 3
Training loss: 0.12660352548256198
Validation loss: 2.5345970204548998

Epoch: 6| Step: 4
Training loss: 0.11557001597904683
Validation loss: 2.499430243879028

Epoch: 6| Step: 5
Training loss: 0.2237402478815354
Validation loss: 2.5356366850540177

Epoch: 6| Step: 6
Training loss: 0.1061665971972589
Validation loss: 2.52894886426009

Epoch: 6| Step: 7
Training loss: 0.21115615779179728
Validation loss: 2.4976914591300745

Epoch: 6| Step: 8
Training loss: 0.16743751175165936
Validation loss: 2.5165611017855136

Epoch: 6| Step: 9
Training loss: 0.12135506322294866
Validation loss: 2.525066413196863

Epoch: 6| Step: 10
Training loss: 0.18219015610265302
Validation loss: 2.523591660923883

Epoch: 6| Step: 11
Training loss: 0.092889487313313
Validation loss: 2.5119127222167568

Epoch: 6| Step: 12
Training loss: 0.12604501623899528
Validation loss: 2.5411975208404125

Epoch: 6| Step: 13
Training loss: 0.12064035196894715
Validation loss: 2.550687305044779

Epoch: 669| Step: 0
Training loss: 0.09516231359383132
Validation loss: 2.5369052761450703

Epoch: 6| Step: 1
Training loss: 0.14928299010390372
Validation loss: 2.5578642400628326

Epoch: 6| Step: 2
Training loss: 0.10564680434503984
Validation loss: 2.5789464090120986

Epoch: 6| Step: 3
Training loss: 0.10551250397901706
Validation loss: 2.583736607185528

Epoch: 6| Step: 4
Training loss: 0.13681441093912183
Validation loss: 2.570023044465947

Epoch: 6| Step: 5
Training loss: 0.15634233011755752
Validation loss: 2.567151654502591

Epoch: 6| Step: 6
Training loss: 0.12894389296486725
Validation loss: 2.609707649086343

Epoch: 6| Step: 7
Training loss: 0.1128168287265679
Validation loss: 2.5452849120581686

Epoch: 6| Step: 8
Training loss: 0.13260578449198304
Validation loss: 2.5719758136462856

Epoch: 6| Step: 9
Training loss: 0.1324779771438064
Validation loss: 2.5617818318745065

Epoch: 6| Step: 10
Training loss: 0.12334063447410364
Validation loss: 2.5750108283572177

Epoch: 6| Step: 11
Training loss: 0.14360759045767665
Validation loss: 2.6072793392292635

Epoch: 6| Step: 12
Training loss: 0.11782068614319956
Validation loss: 2.582080547881152

Epoch: 6| Step: 13
Training loss: 0.06871702096801333
Validation loss: 2.5920220124494837

Epoch: 670| Step: 0
Training loss: 0.10146254425820954
Validation loss: 2.5897904918018213

Epoch: 6| Step: 1
Training loss: 0.10462177120545306
Validation loss: 2.5831758564940097

Epoch: 6| Step: 2
Training loss: 0.14408923553703282
Validation loss: 2.569732290336067

Epoch: 6| Step: 3
Training loss: 0.06820353728537902
Validation loss: 2.579895678315181

Epoch: 6| Step: 4
Training loss: 0.12092006440611833
Validation loss: 2.551350704172962

Epoch: 6| Step: 5
Training loss: 0.06829150440963588
Validation loss: 2.6079820453450537

Epoch: 6| Step: 6
Training loss: 0.17150788765123995
Validation loss: 2.5779672623523884

Epoch: 6| Step: 7
Training loss: 0.16810065457477863
Validation loss: 2.5674424108108735

Epoch: 6| Step: 8
Training loss: 0.18271954365755766
Validation loss: 2.5682989789559483

Epoch: 6| Step: 9
Training loss: 0.10957117879324502
Validation loss: 2.5777171747415593

Epoch: 6| Step: 10
Training loss: 0.15118422371553905
Validation loss: 2.6085226046967

Epoch: 6| Step: 11
Training loss: 0.10543514528737406
Validation loss: 2.5756896965741096

Epoch: 6| Step: 12
Training loss: 0.1479723002744013
Validation loss: 2.5503944284952973

Epoch: 6| Step: 13
Training loss: 0.10080158394455317
Validation loss: 2.581145787068971

Epoch: 671| Step: 0
Training loss: 0.15071264692712086
Validation loss: 2.5739477249793876

Epoch: 6| Step: 1
Training loss: 0.1656149910655614
Validation loss: 2.5529067906943834

Epoch: 6| Step: 2
Training loss: 0.06566925458333918
Validation loss: 2.550576185180204

Epoch: 6| Step: 3
Training loss: 0.09347824605277748
Validation loss: 2.5866339828398797

Epoch: 6| Step: 4
Training loss: 0.08972659454378346
Validation loss: 2.57613783367019

Epoch: 6| Step: 5
Training loss: 0.13371090798986424
Validation loss: 2.5549122139315856

Epoch: 6| Step: 6
Training loss: 0.10580240560703308
Validation loss: 2.5594968427985134

Epoch: 6| Step: 7
Training loss: 0.0734132580870883
Validation loss: 2.5914263556065675

Epoch: 6| Step: 8
Training loss: 0.0913883564625579
Validation loss: 2.56644824035759

Epoch: 6| Step: 9
Training loss: 0.08823742791621567
Validation loss: 2.572603954415707

Epoch: 6| Step: 10
Training loss: 0.1744309110716028
Validation loss: 2.5728669125427412

Epoch: 6| Step: 11
Training loss: 0.07166398107594134
Validation loss: 2.5831915945202275

Epoch: 6| Step: 12
Training loss: 0.13202854497948796
Validation loss: 2.5399522972472175

Epoch: 6| Step: 13
Training loss: 0.09254201333625683
Validation loss: 2.563361010500511

Epoch: 672| Step: 0
Training loss: 0.06601196933533764
Validation loss: 2.5897107578704355

Epoch: 6| Step: 1
Training loss: 0.14102742444282196
Validation loss: 2.5600227198743015

Epoch: 6| Step: 2
Training loss: 0.12155300391354193
Validation loss: 2.5355322501310615

Epoch: 6| Step: 3
Training loss: 0.08985825089899244
Validation loss: 2.5555578187290755

Epoch: 6| Step: 4
Training loss: 0.07867371268148038
Validation loss: 2.573397518037918

Epoch: 6| Step: 5
Training loss: 0.06026151924325295
Validation loss: 2.561693197076381

Epoch: 6| Step: 6
Training loss: 0.1226670670447195
Validation loss: 2.5667188097618445

Epoch: 6| Step: 7
Training loss: 0.12998573269635388
Validation loss: 2.543845587416419

Epoch: 6| Step: 8
Training loss: 0.18189259966678004
Validation loss: 2.5565196799069887

Epoch: 6| Step: 9
Training loss: 0.16966483526804357
Validation loss: 2.554200849254329

Epoch: 6| Step: 10
Training loss: 0.08838626398893518
Validation loss: 2.52533481875267

Epoch: 6| Step: 11
Training loss: 0.08806817347178322
Validation loss: 2.577179841838442

Epoch: 6| Step: 12
Training loss: 0.13390172266345232
Validation loss: 2.5611023271371316

Epoch: 6| Step: 13
Training loss: 0.06551589197754452
Validation loss: 2.51872079337088

Epoch: 673| Step: 0
Training loss: 0.1227672100824173
Validation loss: 2.5451874755590493

Epoch: 6| Step: 1
Training loss: 0.11025979437702764
Validation loss: 2.554115050893598

Epoch: 6| Step: 2
Training loss: 0.1277673798247332
Validation loss: 2.558883417886881

Epoch: 6| Step: 3
Training loss: 0.1469451587085405
Validation loss: 2.4974618491744707

Epoch: 6| Step: 4
Training loss: 0.09829985251500523
Validation loss: 2.5356622643419775

Epoch: 6| Step: 5
Training loss: 0.10553316515776658
Validation loss: 2.54666858377413

Epoch: 6| Step: 6
Training loss: 0.10690096352961942
Validation loss: 2.5622416370282064

Epoch: 6| Step: 7
Training loss: 0.17345516505792946
Validation loss: 2.551526974140098

Epoch: 6| Step: 8
Training loss: 0.14575844499453133
Validation loss: 2.551500058819093

Epoch: 6| Step: 9
Training loss: 0.1127357668139748
Validation loss: 2.544195414725688

Epoch: 6| Step: 10
Training loss: 0.10824771230991553
Validation loss: 2.589640878533591

Epoch: 6| Step: 11
Training loss: 0.10072945106404396
Validation loss: 2.585148506734449

Epoch: 6| Step: 12
Training loss: 0.08802697678246785
Validation loss: 2.564752541621528

Epoch: 6| Step: 13
Training loss: 0.08454742320109834
Validation loss: 2.544640846630989

Epoch: 674| Step: 0
Training loss: 0.12041650091751642
Validation loss: 2.5517081337508993

Epoch: 6| Step: 1
Training loss: 0.11075124686725436
Validation loss: 2.5735974274145166

Epoch: 6| Step: 2
Training loss: 0.09399940178749287
Validation loss: 2.5453881370733744

Epoch: 6| Step: 3
Training loss: 0.1383465523811865
Validation loss: 2.5464463050878763

Epoch: 6| Step: 4
Training loss: 0.10522549887721529
Validation loss: 2.5233902587247874

Epoch: 6| Step: 5
Training loss: 0.1088734862493883
Validation loss: 2.5073236436157544

Epoch: 6| Step: 6
Training loss: 0.08699545906383145
Validation loss: 2.5949996930522756

Epoch: 6| Step: 7
Training loss: 0.08316734354974666
Validation loss: 2.5805945646866006

Epoch: 6| Step: 8
Training loss: 0.13648073049613157
Validation loss: 2.575343557553176

Epoch: 6| Step: 9
Training loss: 0.13769499460819423
Validation loss: 2.5937892299531446

Epoch: 6| Step: 10
Training loss: 0.1395590702956003
Validation loss: 2.559440545683388

Epoch: 6| Step: 11
Training loss: 0.12922460086127668
Validation loss: 2.568795024111073

Epoch: 6| Step: 12
Training loss: 0.11787284084943693
Validation loss: 2.5875734020488754

Epoch: 6| Step: 13
Training loss: 0.070422335112393
Validation loss: 2.6289056678211455

Epoch: 675| Step: 0
Training loss: 0.1454364806583356
Validation loss: 2.5487924928727934

Epoch: 6| Step: 1
Training loss: 0.112131391416996
Validation loss: 2.5953930541876233

Epoch: 6| Step: 2
Training loss: 0.09785896242832251
Validation loss: 2.591341280274012

Epoch: 6| Step: 3
Training loss: 0.11832732751905756
Validation loss: 2.588449513441998

Epoch: 6| Step: 4
Training loss: 0.10509754572226103
Validation loss: 2.597327617391517

Epoch: 6| Step: 5
Training loss: 0.06226348082321859
Validation loss: 2.5697117510586747

Epoch: 6| Step: 6
Training loss: 0.07090344056691357
Validation loss: 2.5853824711945173

Epoch: 6| Step: 7
Training loss: 0.08966746865849518
Validation loss: 2.582027250686484

Epoch: 6| Step: 8
Training loss: 0.09103519388953893
Validation loss: 2.5749790530891468

Epoch: 6| Step: 9
Training loss: 0.11484021729595688
Validation loss: 2.5498738910569947

Epoch: 6| Step: 10
Training loss: 0.09445427073532382
Validation loss: 2.564513636108196

Epoch: 6| Step: 11
Training loss: 0.14308900622077214
Validation loss: 2.589467370368298

Epoch: 6| Step: 12
Training loss: 0.12133912636570897
Validation loss: 2.568271495248758

Epoch: 6| Step: 13
Training loss: 0.10663280248771183
Validation loss: 2.569302583381466

Epoch: 676| Step: 0
Training loss: 0.0965621310600467
Validation loss: 2.5560473082939192

Epoch: 6| Step: 1
Training loss: 0.09497220839849567
Validation loss: 2.5343767222196862

Epoch: 6| Step: 2
Training loss: 0.07795193696354458
Validation loss: 2.5535191675487265

Epoch: 6| Step: 3
Training loss: 0.1138039851920855
Validation loss: 2.546572678056278

Epoch: 6| Step: 4
Training loss: 0.09275557697435731
Validation loss: 2.581002915648108

Epoch: 6| Step: 5
Training loss: 0.10487816283505884
Validation loss: 2.561970754894618

Epoch: 6| Step: 6
Training loss: 0.10303522595088921
Validation loss: 2.546309368497328

Epoch: 6| Step: 7
Training loss: 0.07153803317587697
Validation loss: 2.5702235798721755

Epoch: 6| Step: 8
Training loss: 0.10525013200339332
Validation loss: 2.5483742181793403

Epoch: 6| Step: 9
Training loss: 0.08506698950184687
Validation loss: 2.573205093160322

Epoch: 6| Step: 10
Training loss: 0.18269491326543558
Validation loss: 2.539927101310006

Epoch: 6| Step: 11
Training loss: 0.1422843192134159
Validation loss: 2.6163644636779657

Epoch: 6| Step: 12
Training loss: 0.11951907039747604
Validation loss: 2.615766581013665

Epoch: 6| Step: 13
Training loss: 0.07782223566844323
Validation loss: 2.5822249233430647

Epoch: 677| Step: 0
Training loss: 0.11177944422002599
Validation loss: 2.5878816974321057

Epoch: 6| Step: 1
Training loss: 0.088022784370416
Validation loss: 2.5720112332416893

Epoch: 6| Step: 2
Training loss: 0.11471588873509851
Validation loss: 2.5938376728041144

Epoch: 6| Step: 3
Training loss: 0.14474257922380773
Validation loss: 2.5994809693585528

Epoch: 6| Step: 4
Training loss: 0.1640939682345373
Validation loss: 2.571752557798017

Epoch: 6| Step: 5
Training loss: 0.10296687842247018
Validation loss: 2.586888068350178

Epoch: 6| Step: 6
Training loss: 0.08483368288295952
Validation loss: 2.6001083930417486

Epoch: 6| Step: 7
Training loss: 0.11985295004887223
Validation loss: 2.5782580493293965

Epoch: 6| Step: 8
Training loss: 0.11671928009872884
Validation loss: 2.623451601484387

Epoch: 6| Step: 9
Training loss: 0.1146001618302515
Validation loss: 2.5949857673568477

Epoch: 6| Step: 10
Training loss: 0.07692046222633063
Validation loss: 2.5708750701875998

Epoch: 6| Step: 11
Training loss: 0.06412882932793237
Validation loss: 2.572144976066517

Epoch: 6| Step: 12
Training loss: 0.09463212132774283
Validation loss: 2.570108726221852

Epoch: 6| Step: 13
Training loss: 0.08714553195943588
Validation loss: 2.546634867843084

Epoch: 678| Step: 0
Training loss: 0.16944079974678672
Validation loss: 2.573788043005966

Epoch: 6| Step: 1
Training loss: 0.07589927213468085
Validation loss: 2.584533456965314

Epoch: 6| Step: 2
Training loss: 0.13178474704000356
Validation loss: 2.56853272606218

Epoch: 6| Step: 3
Training loss: 0.12646275964146395
Validation loss: 2.5951373840854117

Epoch: 6| Step: 4
Training loss: 0.07690684601933724
Validation loss: 2.5854152004141966

Epoch: 6| Step: 5
Training loss: 0.1086371474033845
Validation loss: 2.579264057368327

Epoch: 6| Step: 6
Training loss: 0.08542357468680285
Validation loss: 2.5892084185333326

Epoch: 6| Step: 7
Training loss: 0.1121175159927733
Validation loss: 2.560107066520225

Epoch: 6| Step: 8
Training loss: 0.08205373773694363
Validation loss: 2.5858324673534585

Epoch: 6| Step: 9
Training loss: 0.09207789039096433
Validation loss: 2.5930100932586955

Epoch: 6| Step: 10
Training loss: 0.12993775546519903
Validation loss: 2.592666704178547

Epoch: 6| Step: 11
Training loss: 0.15306720372749538
Validation loss: 2.6006896771318275

Epoch: 6| Step: 12
Training loss: 0.07892605065722459
Validation loss: 2.5756569512672867

Epoch: 6| Step: 13
Training loss: 0.12755118132843843
Validation loss: 2.556921666979229

Epoch: 679| Step: 0
Training loss: 0.13171304697200303
Validation loss: 2.5622820127435997

Epoch: 6| Step: 1
Training loss: 0.1276210600186888
Validation loss: 2.550560297164792

Epoch: 6| Step: 2
Training loss: 0.1448496456036892
Validation loss: 2.5504888435949606

Epoch: 6| Step: 3
Training loss: 0.10096957368848267
Validation loss: 2.5644295483636843

Epoch: 6| Step: 4
Training loss: 0.09732725515725572
Validation loss: 2.579649617680881

Epoch: 6| Step: 5
Training loss: 0.14240195220278146
Validation loss: 2.546742272556399

Epoch: 6| Step: 6
Training loss: 0.1209356136815624
Validation loss: 2.5390287825220663

Epoch: 6| Step: 7
Training loss: 0.08381256838627897
Validation loss: 2.5384714038992393

Epoch: 6| Step: 8
Training loss: 0.08345490828549512
Validation loss: 2.5644672944701403

Epoch: 6| Step: 9
Training loss: 0.08257809372362683
Validation loss: 2.5493915977766637

Epoch: 6| Step: 10
Training loss: 0.13522278603273347
Validation loss: 2.5859268258148385

Epoch: 6| Step: 11
Training loss: 0.09367902373714296
Validation loss: 2.544962670549497

Epoch: 6| Step: 12
Training loss: 0.09306121163216163
Validation loss: 2.553866113343133

Epoch: 6| Step: 13
Training loss: 0.08281771265574515
Validation loss: 2.544379144230744

Epoch: 680| Step: 0
Training loss: 0.08408824740392132
Validation loss: 2.5392750994178406

Epoch: 6| Step: 1
Training loss: 0.07975544697372443
Validation loss: 2.537475203881882

Epoch: 6| Step: 2
Training loss: 0.10565703856978667
Validation loss: 2.56648744112664

Epoch: 6| Step: 3
Training loss: 0.09765307898141451
Validation loss: 2.5481816985006107

Epoch: 6| Step: 4
Training loss: 0.06781326547313699
Validation loss: 2.5215564517092703

Epoch: 6| Step: 5
Training loss: 0.1225323401976373
Validation loss: 2.515493759576875

Epoch: 6| Step: 6
Training loss: 0.10368250045714464
Validation loss: 2.5585764338522576

Epoch: 6| Step: 7
Training loss: 0.09389869004950445
Validation loss: 2.573846727549013

Epoch: 6| Step: 8
Training loss: 0.11685398644730238
Validation loss: 2.530327322273777

Epoch: 6| Step: 9
Training loss: 0.1034958793593283
Validation loss: 2.5443101292692436

Epoch: 6| Step: 10
Training loss: 0.1331697036116773
Validation loss: 2.55560353947278

Epoch: 6| Step: 11
Training loss: 0.07344815222609931
Validation loss: 2.5819657381210583

Epoch: 6| Step: 12
Training loss: 0.1925189316097711
Validation loss: 2.5606190956374415

Epoch: 6| Step: 13
Training loss: 0.08599989966453199
Validation loss: 2.565629684629622

Epoch: 681| Step: 0
Training loss: 0.1741542649778014
Validation loss: 2.5587438030089626

Epoch: 6| Step: 1
Training loss: 0.0789042029965088
Validation loss: 2.5730623865995494

Epoch: 6| Step: 2
Training loss: 0.12060727955929824
Validation loss: 2.5347762072085716

Epoch: 6| Step: 3
Training loss: 0.13322286459572763
Validation loss: 2.5673324085797096

Epoch: 6| Step: 4
Training loss: 0.15343929339252327
Validation loss: 2.556726035791041

Epoch: 6| Step: 5
Training loss: 0.08208529077392955
Validation loss: 2.571666157730883

Epoch: 6| Step: 6
Training loss: 0.09050815527056251
Validation loss: 2.5589206587223163

Epoch: 6| Step: 7
Training loss: 0.09252553242697971
Validation loss: 2.54705461635852

Epoch: 6| Step: 8
Training loss: 0.16015722111663408
Validation loss: 2.5467207425498986

Epoch: 6| Step: 9
Training loss: 0.10376577472115911
Validation loss: 2.5772240524701893

Epoch: 6| Step: 10
Training loss: 0.11392411793044414
Validation loss: 2.577964655916845

Epoch: 6| Step: 11
Training loss: 0.0725980856561777
Validation loss: 2.5558840114190278

Epoch: 6| Step: 12
Training loss: 0.11975984219738496
Validation loss: 2.5945921389548197

Epoch: 6| Step: 13
Training loss: 0.0550652278348668
Validation loss: 2.6132149057863128

Epoch: 682| Step: 0
Training loss: 0.10752027946163327
Validation loss: 2.568586276315134

Epoch: 6| Step: 1
Training loss: 0.14703517357256146
Validation loss: 2.6089404857443195

Epoch: 6| Step: 2
Training loss: 0.07746623772798134
Validation loss: 2.561538221666964

Epoch: 6| Step: 3
Training loss: 0.14832410747745625
Validation loss: 2.6152053186007187

Epoch: 6| Step: 4
Training loss: 0.053338039511550646
Validation loss: 2.606285867025943

Epoch: 6| Step: 5
Training loss: 0.10206724335252992
Validation loss: 2.6039812651235086

Epoch: 6| Step: 6
Training loss: 0.1077078523900284
Validation loss: 2.585465722798912

Epoch: 6| Step: 7
Training loss: 0.09963620983754597
Validation loss: 2.5672861427873297

Epoch: 6| Step: 8
Training loss: 0.13541021851324006
Validation loss: 2.578054638570879

Epoch: 6| Step: 9
Training loss: 0.06265274397156566
Validation loss: 2.606450273659552

Epoch: 6| Step: 10
Training loss: 0.07159643015388441
Validation loss: 2.5868590830290508

Epoch: 6| Step: 11
Training loss: 0.0935603548216819
Validation loss: 2.5449675158463894

Epoch: 6| Step: 12
Training loss: 0.09071957733875587
Validation loss: 2.5658588281036607

Epoch: 6| Step: 13
Training loss: 0.07671823852488989
Validation loss: 2.5694349326641586

Epoch: 683| Step: 0
Training loss: 0.1064376259574548
Validation loss: 2.5740380054182137

Epoch: 6| Step: 1
Training loss: 0.19139391995634122
Validation loss: 2.568370557392852

Epoch: 6| Step: 2
Training loss: 0.07682567089068268
Validation loss: 2.589949013930387

Epoch: 6| Step: 3
Training loss: 0.11065062365546859
Validation loss: 2.592782164315017

Epoch: 6| Step: 4
Training loss: 0.049545201147888435
Validation loss: 2.5651537012431485

Epoch: 6| Step: 5
Training loss: 0.06754765526499355
Validation loss: 2.590144150984597

Epoch: 6| Step: 6
Training loss: 0.09441316515804274
Validation loss: 2.5876611999119485

Epoch: 6| Step: 7
Training loss: 0.15348499710856334
Validation loss: 2.5605461661444666

Epoch: 6| Step: 8
Training loss: 0.1356028864341457
Validation loss: 2.5722950229264705

Epoch: 6| Step: 9
Training loss: 0.08558599696642621
Validation loss: 2.5897847503597182

Epoch: 6| Step: 10
Training loss: 0.0692857372532499
Validation loss: 2.5625500337731797

Epoch: 6| Step: 11
Training loss: 0.1181094066858533
Validation loss: 2.5544068901542096

Epoch: 6| Step: 12
Training loss: 0.1003367476109455
Validation loss: 2.5371629559523465

Epoch: 6| Step: 13
Training loss: 0.09287487808523738
Validation loss: 2.5470777589801834

Epoch: 684| Step: 0
Training loss: 0.13396728089614662
Validation loss: 2.5613689712796432

Epoch: 6| Step: 1
Training loss: 0.15375022991868792
Validation loss: 2.5446636006659156

Epoch: 6| Step: 2
Training loss: 0.10073814172449234
Validation loss: 2.5904755603757934

Epoch: 6| Step: 3
Training loss: 0.09841474182961601
Validation loss: 2.5620283747790005

Epoch: 6| Step: 4
Training loss: 0.07724502408411917
Validation loss: 2.6120844653854953

Epoch: 6| Step: 5
Training loss: 0.11187645911218898
Validation loss: 2.577124460721332

Epoch: 6| Step: 6
Training loss: 0.08783842231922578
Validation loss: 2.5686663555797247

Epoch: 6| Step: 7
Training loss: 0.0656270140384246
Validation loss: 2.5833363693436464

Epoch: 6| Step: 8
Training loss: 0.09211536713151336
Validation loss: 2.5726300789427796

Epoch: 6| Step: 9
Training loss: 0.1426302148432298
Validation loss: 2.6113147281658318

Epoch: 6| Step: 10
Training loss: 0.09086827068127663
Validation loss: 2.581173067645517

Epoch: 6| Step: 11
Training loss: 0.09214660295032376
Validation loss: 2.589306951448161

Epoch: 6| Step: 12
Training loss: 0.08005383169543764
Validation loss: 2.6090129424021966

Epoch: 6| Step: 13
Training loss: 0.042201616378108424
Validation loss: 2.5756178880670038

Epoch: 685| Step: 0
Training loss: 0.088940176490928
Validation loss: 2.6031563706868814

Epoch: 6| Step: 1
Training loss: 0.06710254737707723
Validation loss: 2.558413750326327

Epoch: 6| Step: 2
Training loss: 0.10640772322056391
Validation loss: 2.6074756043598515

Epoch: 6| Step: 3
Training loss: 0.06855769001398412
Validation loss: 2.5903206304245714

Epoch: 6| Step: 4
Training loss: 0.10822140353361928
Validation loss: 2.5859481017708306

Epoch: 6| Step: 5
Training loss: 0.08654300907506844
Validation loss: 2.570880439031434

Epoch: 6| Step: 6
Training loss: 0.10495048804560403
Validation loss: 2.553893520192113

Epoch: 6| Step: 7
Training loss: 0.07403030124638472
Validation loss: 2.5705999173857936

Epoch: 6| Step: 8
Training loss: 0.08038656797264696
Validation loss: 2.5651053923000173

Epoch: 6| Step: 9
Training loss: 0.14473199435193926
Validation loss: 2.56957581038395

Epoch: 6| Step: 10
Training loss: 0.09609389809077568
Validation loss: 2.581981903518573

Epoch: 6| Step: 11
Training loss: 0.1258183232161723
Validation loss: 2.577886424829595

Epoch: 6| Step: 12
Training loss: 0.13633946532818353
Validation loss: 2.5625988195630125

Epoch: 6| Step: 13
Training loss: 0.10606426315213334
Validation loss: 2.5814623797498544

Epoch: 686| Step: 0
Training loss: 0.10596235323430363
Validation loss: 2.5606583481003984

Epoch: 6| Step: 1
Training loss: 0.17052002564831042
Validation loss: 2.5805622531662915

Epoch: 6| Step: 2
Training loss: 0.11694555738450088
Validation loss: 2.585865189886144

Epoch: 6| Step: 3
Training loss: 0.07727201137917913
Validation loss: 2.545966829911354

Epoch: 6| Step: 4
Training loss: 0.10025884164671228
Validation loss: 2.6041362555584238

Epoch: 6| Step: 5
Training loss: 0.12870273998129272
Validation loss: 2.5643759942845907

Epoch: 6| Step: 6
Training loss: 0.131304021060914
Validation loss: 2.572294946185533

Epoch: 6| Step: 7
Training loss: 0.16601540060589154
Validation loss: 2.576365475358924

Epoch: 6| Step: 8
Training loss: 0.13480831935017112
Validation loss: 2.5691791869398712

Epoch: 6| Step: 9
Training loss: 0.09431063389685741
Validation loss: 2.556864194457008

Epoch: 6| Step: 10
Training loss: 0.13999230390282336
Validation loss: 2.5729700213911753

Epoch: 6| Step: 11
Training loss: 0.11312550493254123
Validation loss: 2.5240659930181217

Epoch: 6| Step: 12
Training loss: 0.0978743882501175
Validation loss: 2.539483811578961

Epoch: 6| Step: 13
Training loss: 0.11397452979288926
Validation loss: 2.5630236415040497

Epoch: 687| Step: 0
Training loss: 0.12407164500327872
Validation loss: 2.554479792196929

Epoch: 6| Step: 1
Training loss: 0.11699814200174156
Validation loss: 2.549711042387736

Epoch: 6| Step: 2
Training loss: 0.15184958100020876
Validation loss: 2.533525423313595

Epoch: 6| Step: 3
Training loss: 0.10403355995059019
Validation loss: 2.55766199839461

Epoch: 6| Step: 4
Training loss: 0.07313767924383793
Validation loss: 2.579510457904977

Epoch: 6| Step: 5
Training loss: 0.1449334695193125
Validation loss: 2.5817433769327094

Epoch: 6| Step: 6
Training loss: 0.1438996329220364
Validation loss: 2.579592912158636

Epoch: 6| Step: 7
Training loss: 0.14101508132533888
Validation loss: 2.572973189360609

Epoch: 6| Step: 8
Training loss: 0.143740928923461
Validation loss: 2.6023087329706445

Epoch: 6| Step: 9
Training loss: 0.06420907502838813
Validation loss: 2.5818920885162386

Epoch: 6| Step: 10
Training loss: 0.10509081076159481
Validation loss: 2.583578560714982

Epoch: 6| Step: 11
Training loss: 0.14504285425746327
Validation loss: 2.6036965952919435

Epoch: 6| Step: 12
Training loss: 0.12654165932292413
Validation loss: 2.5796179860137314

Epoch: 6| Step: 13
Training loss: 0.09680062734706253
Validation loss: 2.5976303909794787

Epoch: 688| Step: 0
Training loss: 0.09226156871836269
Validation loss: 2.6109081792144546

Epoch: 6| Step: 1
Training loss: 0.13196687906742507
Validation loss: 2.572140066847123

Epoch: 6| Step: 2
Training loss: 0.10044941386827495
Validation loss: 2.571857745802089

Epoch: 6| Step: 3
Training loss: 0.13559701415469744
Validation loss: 2.624555080306493

Epoch: 6| Step: 4
Training loss: 0.07957337507460117
Validation loss: 2.5688055908441

Epoch: 6| Step: 5
Training loss: 0.12526613455058874
Validation loss: 2.582958059876405

Epoch: 6| Step: 6
Training loss: 0.18930273871130904
Validation loss: 2.587535794853533

Epoch: 6| Step: 7
Training loss: 0.1362490077376325
Validation loss: 2.5897330688885973

Epoch: 6| Step: 8
Training loss: 0.1017712135789393
Validation loss: 2.569492013016655

Epoch: 6| Step: 9
Training loss: 0.12639831943649096
Validation loss: 2.5709722580871803

Epoch: 6| Step: 10
Training loss: 0.12927239609843674
Validation loss: 2.5751594369449844

Epoch: 6| Step: 11
Training loss: 0.1414088615155255
Validation loss: 2.5991657162913904

Epoch: 6| Step: 12
Training loss: 0.09482837396822529
Validation loss: 2.5732726392687413

Epoch: 6| Step: 13
Training loss: 0.10680654895642858
Validation loss: 2.584032605811283

Epoch: 689| Step: 0
Training loss: 0.08361163148631381
Validation loss: 2.5574705487685043

Epoch: 6| Step: 1
Training loss: 0.08275506303963223
Validation loss: 2.5423694610947827

Epoch: 6| Step: 2
Training loss: 0.0868252906286929
Validation loss: 2.5638665245485

Epoch: 6| Step: 3
Training loss: 0.1294667312433376
Validation loss: 2.5574954164987367

Epoch: 6| Step: 4
Training loss: 0.16520087080557427
Validation loss: 2.559456956016409

Epoch: 6| Step: 5
Training loss: 0.10683688489364862
Validation loss: 2.541466684070729

Epoch: 6| Step: 6
Training loss: 0.18470327442273834
Validation loss: 2.5308099767083587

Epoch: 6| Step: 7
Training loss: 0.11000146440864189
Validation loss: 2.579990744773288

Epoch: 6| Step: 8
Training loss: 0.13159828665447398
Validation loss: 2.557979668547714

Epoch: 6| Step: 9
Training loss: 0.08552353488292466
Validation loss: 2.5647531898402995

Epoch: 6| Step: 10
Training loss: 0.09298165696571656
Validation loss: 2.5697988233786653

Epoch: 6| Step: 11
Training loss: 0.1421939429196279
Validation loss: 2.5623562049888307

Epoch: 6| Step: 12
Training loss: 0.08481573434409935
Validation loss: 2.5791173084899714

Epoch: 6| Step: 13
Training loss: 0.08698821922504568
Validation loss: 2.5424192834997412

Epoch: 690| Step: 0
Training loss: 0.09539342907370041
Validation loss: 2.540335665449543

Epoch: 6| Step: 1
Training loss: 0.10160866476781866
Validation loss: 2.555271346514599

Epoch: 6| Step: 2
Training loss: 0.13907397094306762
Validation loss: 2.564905983478506

Epoch: 6| Step: 3
Training loss: 0.09716941602386273
Validation loss: 2.547047810316346

Epoch: 6| Step: 4
Training loss: 0.09071642563759715
Validation loss: 2.5667217821911126

Epoch: 6| Step: 5
Training loss: 0.10457333862833741
Validation loss: 2.5598099988482113

Epoch: 6| Step: 6
Training loss: 0.10026714583104449
Validation loss: 2.5541120587741917

Epoch: 6| Step: 7
Training loss: 0.09692868045220106
Validation loss: 2.5692908552568774

Epoch: 6| Step: 8
Training loss: 0.12924064986877623
Validation loss: 2.537482062878071

Epoch: 6| Step: 9
Training loss: 0.11554555580103124
Validation loss: 2.5896247688659653

Epoch: 6| Step: 10
Training loss: 0.08526353279201168
Validation loss: 2.5635722788390085

Epoch: 6| Step: 11
Training loss: 0.09461151097010422
Validation loss: 2.5707989289228066

Epoch: 6| Step: 12
Training loss: 0.1439563749557845
Validation loss: 2.598344120223806

Epoch: 6| Step: 13
Training loss: 0.1858906422403659
Validation loss: 2.5731158684879927

Epoch: 691| Step: 0
Training loss: 0.1227805115630716
Validation loss: 2.5798460107566226

Epoch: 6| Step: 1
Training loss: 0.08899404044571069
Validation loss: 2.554089124428899

Epoch: 6| Step: 2
Training loss: 0.08235492031998798
Validation loss: 2.5684469243582266

Epoch: 6| Step: 3
Training loss: 0.1228795275979419
Validation loss: 2.577817654056675

Epoch: 6| Step: 4
Training loss: 0.1665691236821492
Validation loss: 2.5616706768702664

Epoch: 6| Step: 5
Training loss: 0.08775973109855734
Validation loss: 2.5708430882391817

Epoch: 6| Step: 6
Training loss: 0.1189654031081852
Validation loss: 2.550115958530374

Epoch: 6| Step: 7
Training loss: 0.12703559837547063
Validation loss: 2.5287293275389984

Epoch: 6| Step: 8
Training loss: 0.06100447837423052
Validation loss: 2.555574565976209

Epoch: 6| Step: 9
Training loss: 0.09719547285022728
Validation loss: 2.5434084800454606

Epoch: 6| Step: 10
Training loss: 0.07285687820943065
Validation loss: 2.533435462966597

Epoch: 6| Step: 11
Training loss: 0.11951632749371235
Validation loss: 2.5476522532369326

Epoch: 6| Step: 12
Training loss: 0.12324597886385352
Validation loss: 2.5420329483777673

Epoch: 6| Step: 13
Training loss: 0.06335574536563333
Validation loss: 2.5498433287553297

Epoch: 692| Step: 0
Training loss: 0.07068126061144536
Validation loss: 2.5178234695161215

Epoch: 6| Step: 1
Training loss: 0.08973885715601869
Validation loss: 2.54000408928855

Epoch: 6| Step: 2
Training loss: 0.07029312250894794
Validation loss: 2.585491512116541

Epoch: 6| Step: 3
Training loss: 0.148424122860106
Validation loss: 2.5656384033502113

Epoch: 6| Step: 4
Training loss: 0.06903577022444592
Validation loss: 2.567473017240078

Epoch: 6| Step: 5
Training loss: 0.12426217822500521
Validation loss: 2.546873568638819

Epoch: 6| Step: 6
Training loss: 0.08056648138794141
Validation loss: 2.574085464498897

Epoch: 6| Step: 7
Training loss: 0.08809316398260598
Validation loss: 2.5658971506586

Epoch: 6| Step: 8
Training loss: 0.14532897507169049
Validation loss: 2.6071327365322166

Epoch: 6| Step: 9
Training loss: 0.13647888122314844
Validation loss: 2.5672987018974616

Epoch: 6| Step: 10
Training loss: 0.06040342511423655
Validation loss: 2.5774407436767253

Epoch: 6| Step: 11
Training loss: 0.1443238058398951
Validation loss: 2.581333957291862

Epoch: 6| Step: 12
Training loss: 0.12130117724448623
Validation loss: 2.571183049589513

Epoch: 6| Step: 13
Training loss: 0.06068556229891754
Validation loss: 2.545428272513785

Epoch: 693| Step: 0
Training loss: 0.10883679121993027
Validation loss: 2.5738902436256326

Epoch: 6| Step: 1
Training loss: 0.05796860958028376
Validation loss: 2.570898921768963

Epoch: 6| Step: 2
Training loss: 0.1256086536585584
Validation loss: 2.5419662135334415

Epoch: 6| Step: 3
Training loss: 0.12599595977724043
Validation loss: 2.6147858464822042

Epoch: 6| Step: 4
Training loss: 0.1143989628497936
Validation loss: 2.5559409259896015

Epoch: 6| Step: 5
Training loss: 0.07331587263818873
Validation loss: 2.5573829745018397

Epoch: 6| Step: 6
Training loss: 0.1650175159542136
Validation loss: 2.5681635060417847

Epoch: 6| Step: 7
Training loss: 0.07979481870863765
Validation loss: 2.5380747822790597

Epoch: 6| Step: 8
Training loss: 0.12498823870521554
Validation loss: 2.544717125820532

Epoch: 6| Step: 9
Training loss: 0.09094731362307877
Validation loss: 2.542368265675811

Epoch: 6| Step: 10
Training loss: 0.07731384339742031
Validation loss: 2.5093679193512175

Epoch: 6| Step: 11
Training loss: 0.12146340370091327
Validation loss: 2.560971138888578

Epoch: 6| Step: 12
Training loss: 0.11004479566324171
Validation loss: 2.5746577460244064

Epoch: 6| Step: 13
Training loss: 0.03153499459665033
Validation loss: 2.550418717882318

Epoch: 694| Step: 0
Training loss: 0.1379581810044915
Validation loss: 2.570839051576856

Epoch: 6| Step: 1
Training loss: 0.12034788695024812
Validation loss: 2.5302980537762396

Epoch: 6| Step: 2
Training loss: 0.1842936910343726
Validation loss: 2.551364115430605

Epoch: 6| Step: 3
Training loss: 0.12578599399600304
Validation loss: 2.569086304921855

Epoch: 6| Step: 4
Training loss: 0.10098593998498623
Validation loss: 2.5831006370707104

Epoch: 6| Step: 5
Training loss: 0.08055297277181415
Validation loss: 2.54533975011334

Epoch: 6| Step: 6
Training loss: 0.13103418630461888
Validation loss: 2.5659117714976527

Epoch: 6| Step: 7
Training loss: 0.08074466751342696
Validation loss: 2.5588428883579213

Epoch: 6| Step: 8
Training loss: 0.10863708310750096
Validation loss: 2.5987424792678926

Epoch: 6| Step: 9
Training loss: 0.08370712170557508
Validation loss: 2.5957371354188803

Epoch: 6| Step: 10
Training loss: 0.11660502634702213
Validation loss: 2.6088277896218526

Epoch: 6| Step: 11
Training loss: 0.09332466996735189
Validation loss: 2.5949200895452855

Epoch: 6| Step: 12
Training loss: 0.11031635532990547
Validation loss: 2.5741758307345495

Epoch: 6| Step: 13
Training loss: 0.07249010827866668
Validation loss: 2.5868657536061157

Epoch: 695| Step: 0
Training loss: 0.12834181177270076
Validation loss: 2.6021415669318713

Epoch: 6| Step: 1
Training loss: 0.08838660907371872
Validation loss: 2.5665006224554907

Epoch: 6| Step: 2
Training loss: 0.11383314359882055
Validation loss: 2.584383486786022

Epoch: 6| Step: 3
Training loss: 0.10070240351948968
Validation loss: 2.5736588894684473

Epoch: 6| Step: 4
Training loss: 0.1290489187553348
Validation loss: 2.563178046014956

Epoch: 6| Step: 5
Training loss: 0.06450759146893778
Validation loss: 2.613850029931687

Epoch: 6| Step: 6
Training loss: 0.0805430725293467
Validation loss: 2.5675601934383305

Epoch: 6| Step: 7
Training loss: 0.06052421715001438
Validation loss: 2.5674673277389894

Epoch: 6| Step: 8
Training loss: 0.10726731191365838
Validation loss: 2.555736501866143

Epoch: 6| Step: 9
Training loss: 0.06249676450162819
Validation loss: 2.589778117493387

Epoch: 6| Step: 10
Training loss: 0.1493835293357771
Validation loss: 2.5859052423529083

Epoch: 6| Step: 11
Training loss: 0.10628173228050398
Validation loss: 2.60736257207521

Epoch: 6| Step: 12
Training loss: 0.09873265227215296
Validation loss: 2.5774166432960803

Epoch: 6| Step: 13
Training loss: 0.13071619570418594
Validation loss: 2.565802303388581

Epoch: 696| Step: 0
Training loss: 0.09852940265655057
Validation loss: 2.5803547265708544

Epoch: 6| Step: 1
Training loss: 0.16293511297740385
Validation loss: 2.578778637672201

Epoch: 6| Step: 2
Training loss: 0.044213981038478324
Validation loss: 2.5440341131785797

Epoch: 6| Step: 3
Training loss: 0.09524396793283721
Validation loss: 2.5726914320729777

Epoch: 6| Step: 4
Training loss: 0.09667130636242496
Validation loss: 2.585957032048648

Epoch: 6| Step: 5
Training loss: 0.13176520534101596
Validation loss: 2.5725138189738948

Epoch: 6| Step: 6
Training loss: 0.05407276953885585
Validation loss: 2.594619267283877

Epoch: 6| Step: 7
Training loss: 0.08974391635748118
Validation loss: 2.5756817683244693

Epoch: 6| Step: 8
Training loss: 0.08856321579833018
Validation loss: 2.5687733036895697

Epoch: 6| Step: 9
Training loss: 0.08202161902702644
Validation loss: 2.5822929334237594

Epoch: 6| Step: 10
Training loss: 0.1460714942891259
Validation loss: 2.5519651190120487

Epoch: 6| Step: 11
Training loss: 0.09054632286285234
Validation loss: 2.6059899826306174

Epoch: 6| Step: 12
Training loss: 0.1369280983427881
Validation loss: 2.568150642703495

Epoch: 6| Step: 13
Training loss: 0.05315310632289442
Validation loss: 2.5693381994738735

Epoch: 697| Step: 0
Training loss: 0.07717727170581323
Validation loss: 2.5703039811561035

Epoch: 6| Step: 1
Training loss: 0.09462002534400546
Validation loss: 2.6065780704257873

Epoch: 6| Step: 2
Training loss: 0.08194965607489935
Validation loss: 2.540381314519461

Epoch: 6| Step: 3
Training loss: 0.08939365967452143
Validation loss: 2.5789997395565876

Epoch: 6| Step: 4
Training loss: 0.09694464337507437
Validation loss: 2.5769682257005115

Epoch: 6| Step: 5
Training loss: 0.1144591253419821
Validation loss: 2.557005856245966

Epoch: 6| Step: 6
Training loss: 0.09922612080266612
Validation loss: 2.5617882485189543

Epoch: 6| Step: 7
Training loss: 0.12819317626242607
Validation loss: 2.545601831620276

Epoch: 6| Step: 8
Training loss: 0.12477314375793302
Validation loss: 2.554501977376851

Epoch: 6| Step: 9
Training loss: 0.12141872453609291
Validation loss: 2.5300149217404124

Epoch: 6| Step: 10
Training loss: 0.10743672961784918
Validation loss: 2.5548688840402263

Epoch: 6| Step: 11
Training loss: 0.058469716558770465
Validation loss: 2.5500698920895495

Epoch: 6| Step: 12
Training loss: 0.07965929418080642
Validation loss: 2.567708991622083

Epoch: 6| Step: 13
Training loss: 0.06754184352583226
Validation loss: 2.5505143292126364

Epoch: 698| Step: 0
Training loss: 0.12941033608701794
Validation loss: 2.5534073677158386

Epoch: 6| Step: 1
Training loss: 0.15975842844417004
Validation loss: 2.5553011295716876

Epoch: 6| Step: 2
Training loss: 0.09027845495023008
Validation loss: 2.555345413243706

Epoch: 6| Step: 3
Training loss: 0.06504885668511273
Validation loss: 2.5690582593426936

Epoch: 6| Step: 4
Training loss: 0.06892872832438457
Validation loss: 2.5471074164160106

Epoch: 6| Step: 5
Training loss: 0.1516900955979343
Validation loss: 2.552095981656128

Epoch: 6| Step: 6
Training loss: 0.08049880572915483
Validation loss: 2.565669250126668

Epoch: 6| Step: 7
Training loss: 0.05483459589507651
Validation loss: 2.546024665982345

Epoch: 6| Step: 8
Training loss: 0.10678060465582227
Validation loss: 2.5807002327026556

Epoch: 6| Step: 9
Training loss: 0.0883611376693662
Validation loss: 2.563936847637635

Epoch: 6| Step: 10
Training loss: 0.10041072547749766
Validation loss: 2.5698615140213303

Epoch: 6| Step: 11
Training loss: 0.08576623420842977
Validation loss: 2.5656776554617284

Epoch: 6| Step: 12
Training loss: 0.09485031185357784
Validation loss: 2.542308246954759

Epoch: 6| Step: 13
Training loss: 0.07943491102429688
Validation loss: 2.546344515363699

Epoch: 699| Step: 0
Training loss: 0.09128624341641282
Validation loss: 2.588632681344988

Epoch: 6| Step: 1
Training loss: 0.0852211196576596
Validation loss: 2.597090444935536

Epoch: 6| Step: 2
Training loss: 0.05809908519268221
Validation loss: 2.590659282678215

Epoch: 6| Step: 3
Training loss: 0.13170052390970124
Validation loss: 2.5621753890201875

Epoch: 6| Step: 4
Training loss: 0.07717322904886076
Validation loss: 2.586030511360927

Epoch: 6| Step: 5
Training loss: 0.05870343115277197
Validation loss: 2.6112041049555543

Epoch: 6| Step: 6
Training loss: 0.10725669298540098
Validation loss: 2.5598980869576264

Epoch: 6| Step: 7
Training loss: 0.15638497006813243
Validation loss: 2.6024730601125112

Epoch: 6| Step: 8
Training loss: 0.08018070721565593
Validation loss: 2.5871478073446545

Epoch: 6| Step: 9
Training loss: 0.1286319501878626
Validation loss: 2.5883572427044044

Epoch: 6| Step: 10
Training loss: 0.12768970431676505
Validation loss: 2.609399190339503

Epoch: 6| Step: 11
Training loss: 0.07834435900028079
Validation loss: 2.5823224172386205

Epoch: 6| Step: 12
Training loss: 0.08253534154272217
Validation loss: 2.5895912266186105

Epoch: 6| Step: 13
Training loss: 0.12089719509786709
Validation loss: 2.572405624170866

Epoch: 700| Step: 0
Training loss: 0.07948215196326744
Validation loss: 2.5640637568328715

Epoch: 6| Step: 1
Training loss: 0.08686761472205688
Validation loss: 2.562944860333225

Epoch: 6| Step: 2
Training loss: 0.14436090586346367
Validation loss: 2.571179982268206

Epoch: 6| Step: 3
Training loss: 0.10058326625054663
Validation loss: 2.5450136887460864

Epoch: 6| Step: 4
Training loss: 0.13397754145731783
Validation loss: 2.5794741424529732

Epoch: 6| Step: 5
Training loss: 0.12189129482056395
Validation loss: 2.559758951814619

Epoch: 6| Step: 6
Training loss: 0.08536152836036742
Validation loss: 2.568307031810609

Epoch: 6| Step: 7
Training loss: 0.0740678533196743
Validation loss: 2.5524523798244245

Epoch: 6| Step: 8
Training loss: 0.13524560179848297
Validation loss: 2.567704728384062

Epoch: 6| Step: 9
Training loss: 0.05951013222104815
Validation loss: 2.5719840907216254

Epoch: 6| Step: 10
Training loss: 0.06473167512048192
Validation loss: 2.5649566249829645

Epoch: 6| Step: 11
Training loss: 0.07820423399818187
Validation loss: 2.568666369552333

Epoch: 6| Step: 12
Training loss: 0.04475109924449431
Validation loss: 2.5698620497213556

Epoch: 6| Step: 13
Training loss: 0.08733825891530005
Validation loss: 2.575809564395361

Testing loss: 2.4061940680714815
