Epoch: 1| Step: 0
Training loss: 6.399699514010709
Validation loss: 5.750924687448341

Epoch: 6| Step: 1
Training loss: 5.995240230885281
Validation loss: 5.734996880741106

Epoch: 6| Step: 2
Training loss: 6.450021657981292
Validation loss: 5.721119383168518

Epoch: 6| Step: 3
Training loss: 5.101331065888473
Validation loss: 5.706684075794647

Epoch: 6| Step: 4
Training loss: 6.380992092857609
Validation loss: 5.691078098141984

Epoch: 6| Step: 5
Training loss: 6.591273127341105
Validation loss: 5.67311493453527

Epoch: 6| Step: 6
Training loss: 4.685295909220463
Validation loss: 5.653541345602331

Epoch: 6| Step: 7
Training loss: 5.632261717556608
Validation loss: 5.631162283741884

Epoch: 6| Step: 8
Training loss: 5.169335609113461
Validation loss: 5.605878244787854

Epoch: 6| Step: 9
Training loss: 4.9021820892792425
Validation loss: 5.578627586731455

Epoch: 6| Step: 10
Training loss: 5.25041560389955
Validation loss: 5.547426426105662

Epoch: 6| Step: 11
Training loss: 6.026460791815787
Validation loss: 5.512987216943832

Epoch: 6| Step: 12
Training loss: 5.256572968384273
Validation loss: 5.476540918155413

Epoch: 6| Step: 13
Training loss: 4.602917716130155
Validation loss: 5.436939986238714

Epoch: 2| Step: 0
Training loss: 5.541966461256368
Validation loss: 5.395034734108976

Epoch: 6| Step: 1
Training loss: 4.953762266156866
Validation loss: 5.35109180583764

Epoch: 6| Step: 2
Training loss: 4.999002357135911
Validation loss: 5.3054742884019275

Epoch: 6| Step: 3
Training loss: 4.015834936450502
Validation loss: 5.260153950316449

Epoch: 6| Step: 4
Training loss: 5.301547260077013
Validation loss: 5.213670394032902

Epoch: 6| Step: 5
Training loss: 5.290842948340454
Validation loss: 5.166022552659897

Epoch: 6| Step: 6
Training loss: 5.439082474467775
Validation loss: 5.116043229658557

Epoch: 6| Step: 7
Training loss: 4.750468582330482
Validation loss: 5.066040980225723

Epoch: 6| Step: 8
Training loss: 4.898330808995598
Validation loss: 5.01273373605674

Epoch: 6| Step: 9
Training loss: 5.68910211488027
Validation loss: 4.961266162215068

Epoch: 6| Step: 10
Training loss: 6.123092665797678
Validation loss: 4.910901858057292

Epoch: 6| Step: 11
Training loss: 4.793692362412726
Validation loss: 4.862790681513512

Epoch: 6| Step: 12
Training loss: 4.867170453233089
Validation loss: 4.822460072771217

Epoch: 6| Step: 13
Training loss: 5.300044638967565
Validation loss: 4.793191712934837

Epoch: 3| Step: 0
Training loss: 5.2547611264309255
Validation loss: 4.766008549584951

Epoch: 6| Step: 1
Training loss: 4.5428220113473765
Validation loss: 4.73710316706997

Epoch: 6| Step: 2
Training loss: 5.064165006386943
Validation loss: 4.704254310246553

Epoch: 6| Step: 3
Training loss: 3.562517668027734
Validation loss: 4.669157351636631

Epoch: 6| Step: 4
Training loss: 4.63591776793176
Validation loss: 4.636744267359025

Epoch: 6| Step: 5
Training loss: 5.25803378179413
Validation loss: 4.606306828214395

Epoch: 6| Step: 6
Training loss: 4.957855564895791
Validation loss: 4.582233564747917

Epoch: 6| Step: 7
Training loss: 4.82329982391788
Validation loss: 4.5601767798740065

Epoch: 6| Step: 8
Training loss: 4.6365143008579786
Validation loss: 4.5390807654394685

Epoch: 6| Step: 9
Training loss: 4.5941406914271745
Validation loss: 4.519205063940005

Epoch: 6| Step: 10
Training loss: 4.988795314459714
Validation loss: 4.500129324126893

Epoch: 6| Step: 11
Training loss: 4.484945971993877
Validation loss: 4.482529820151295

Epoch: 6| Step: 12
Training loss: 4.11210953270459
Validation loss: 4.465922769226854

Epoch: 6| Step: 13
Training loss: 4.33145024881212
Validation loss: 4.4520190912496

Epoch: 4| Step: 0
Training loss: 4.736500480111419
Validation loss: 4.436098803331348

Epoch: 6| Step: 1
Training loss: 4.427257483553853
Validation loss: 4.418356211057537

Epoch: 6| Step: 2
Training loss: 5.450940938094606
Validation loss: 4.399578500417255

Epoch: 6| Step: 3
Training loss: 5.370642736745921
Validation loss: 4.387827650990513

Epoch: 6| Step: 4
Training loss: 4.098929586475329
Validation loss: 4.3749878609250095

Epoch: 6| Step: 5
Training loss: 4.875337051086246
Validation loss: 4.3611256602427595

Epoch: 6| Step: 6
Training loss: 4.553033911344342
Validation loss: 4.347271460705178

Epoch: 6| Step: 7
Training loss: 3.459642844095849
Validation loss: 4.33407878064474

Epoch: 6| Step: 8
Training loss: 3.9948800221021923
Validation loss: 4.322984851705154

Epoch: 6| Step: 9
Training loss: 5.173216493080233
Validation loss: 4.310093071730672

Epoch: 6| Step: 10
Training loss: 2.8262324455218835
Validation loss: 4.2962284476507335

Epoch: 6| Step: 11
Training loss: 4.317545937987892
Validation loss: 4.282860450853158

Epoch: 6| Step: 12
Training loss: 4.800328704387442
Validation loss: 4.2718705417249625

Epoch: 6| Step: 13
Training loss: 3.0753672682850204
Validation loss: 4.258264686466706

Epoch: 5| Step: 0
Training loss: 4.452365101008202
Validation loss: 4.245176926410229

Epoch: 6| Step: 1
Training loss: 4.010531152189278
Validation loss: 4.233095674252385

Epoch: 6| Step: 2
Training loss: 4.363030545127977
Validation loss: 4.2221397791421555

Epoch: 6| Step: 3
Training loss: 3.8232850911545464
Validation loss: 4.209971044780524

Epoch: 6| Step: 4
Training loss: 4.21782080695934
Validation loss: 4.201284815507963

Epoch: 6| Step: 5
Training loss: 5.218057369479722
Validation loss: 4.190387663800432

Epoch: 6| Step: 6
Training loss: 3.7711531080241434
Validation loss: 4.179128314075075

Epoch: 6| Step: 7
Training loss: 3.6035878740216534
Validation loss: 4.168340857720914

Epoch: 6| Step: 8
Training loss: 4.4751617743377885
Validation loss: 4.154758079199674

Epoch: 6| Step: 9
Training loss: 4.765819908283711
Validation loss: 4.145256987269436

Epoch: 6| Step: 10
Training loss: 3.251718213643732
Validation loss: 4.133527305178572

Epoch: 6| Step: 11
Training loss: 3.7934557428258366
Validation loss: 4.124092547903344

Epoch: 6| Step: 12
Training loss: 6.034491265953344
Validation loss: 4.11321845241045

Epoch: 6| Step: 13
Training loss: 3.3496470991407046
Validation loss: 4.101813910885503

Epoch: 6| Step: 0
Training loss: 5.007694808362544
Validation loss: 4.0908735487309515

Epoch: 6| Step: 1
Training loss: 4.144563004266902
Validation loss: 4.0832977511019415

Epoch: 6| Step: 2
Training loss: 2.7133582133090517
Validation loss: 4.070861715109369

Epoch: 6| Step: 3
Training loss: 4.193357328175444
Validation loss: 4.061201063668715

Epoch: 6| Step: 4
Training loss: 4.135564280965425
Validation loss: 4.049126496705961

Epoch: 6| Step: 5
Training loss: 4.651173941798483
Validation loss: 4.037030789379869

Epoch: 6| Step: 6
Training loss: 4.424141346872237
Validation loss: 4.033806354938945

Epoch: 6| Step: 7
Training loss: 3.4072085090611566
Validation loss: 4.022923347108736

Epoch: 6| Step: 8
Training loss: 3.975804584574871
Validation loss: 4.00581926899014

Epoch: 6| Step: 9
Training loss: 4.117395732326096
Validation loss: 3.9958370270100834

Epoch: 6| Step: 10
Training loss: 4.174665682079094
Validation loss: 3.9887597655102107

Epoch: 6| Step: 11
Training loss: 4.350675263006954
Validation loss: 3.9758276493803937

Epoch: 6| Step: 12
Training loss: 4.453006782970321
Validation loss: 3.9684810171006086

Epoch: 6| Step: 13
Training loss: 4.344157028338782
Validation loss: 3.958567968041017

Epoch: 7| Step: 0
Training loss: 4.033648346718557
Validation loss: 3.947826034557985

Epoch: 6| Step: 1
Training loss: 3.800448772633712
Validation loss: 3.9475323166938514

Epoch: 6| Step: 2
Training loss: 4.072321595463683
Validation loss: 3.9429081167351354

Epoch: 6| Step: 3
Training loss: 4.012396200863654
Validation loss: 3.927466904220395

Epoch: 6| Step: 4
Training loss: 4.304658034651311
Validation loss: 3.9120245430144984

Epoch: 6| Step: 5
Training loss: 3.971844285415516
Validation loss: 3.9074224577174466

Epoch: 6| Step: 6
Training loss: 4.398644776144036
Validation loss: 3.89861366636265

Epoch: 6| Step: 7
Training loss: 3.909531824517363
Validation loss: 3.8914752045575742

Epoch: 6| Step: 8
Training loss: 4.729775589827382
Validation loss: 3.889062053489377

Epoch: 6| Step: 9
Training loss: 4.490850684242804
Validation loss: 3.8711561151187013

Epoch: 6| Step: 10
Training loss: 4.403527900234044
Validation loss: 3.888463490937246

Epoch: 6| Step: 11
Training loss: 3.5335901658864204
Validation loss: 3.8699465219819174

Epoch: 6| Step: 12
Training loss: 3.9217163297008226
Validation loss: 3.84392425224836

Epoch: 6| Step: 13
Training loss: 1.959515789516383
Validation loss: 3.8365785942582713

Epoch: 8| Step: 0
Training loss: 3.6461973317409235
Validation loss: 3.8342169928668874

Epoch: 6| Step: 1
Training loss: 2.778731502414763
Validation loss: 3.833461410679856

Epoch: 6| Step: 2
Training loss: 4.1484604886957195
Validation loss: 3.822671344176572

Epoch: 6| Step: 3
Training loss: 4.058443362228191
Validation loss: 3.801173450909801

Epoch: 6| Step: 4
Training loss: 4.2782689317632006
Validation loss: 3.806524874747089

Epoch: 6| Step: 5
Training loss: 4.348655071839786
Validation loss: 3.794177135119401

Epoch: 6| Step: 6
Training loss: 4.1711934993896636
Validation loss: 3.779782687078765

Epoch: 6| Step: 7
Training loss: 3.3883217578495697
Validation loss: 3.772318290934034

Epoch: 6| Step: 8
Training loss: 4.988144743507123
Validation loss: 3.7677238319355792

Epoch: 6| Step: 9
Training loss: 3.8728746307592523
Validation loss: 3.76080127410746

Epoch: 6| Step: 10
Training loss: 4.514375612802053
Validation loss: 3.750933863807011

Epoch: 6| Step: 11
Training loss: 3.0919464711321702
Validation loss: 3.7437716467813926

Epoch: 6| Step: 12
Training loss: 4.14671068476857
Validation loss: 3.7373376971099086

Epoch: 6| Step: 13
Training loss: 2.8713554833931165
Validation loss: 3.7241558086557753

Epoch: 9| Step: 0
Training loss: 4.120836179376795
Validation loss: 3.7211172514902464

Epoch: 6| Step: 1
Training loss: 3.4816906086883863
Validation loss: 3.7136431806734147

Epoch: 6| Step: 2
Training loss: 3.3278729697063922
Validation loss: 3.7133309642627848

Epoch: 6| Step: 3
Training loss: 3.1921072181917136
Validation loss: 3.696616465057723

Epoch: 6| Step: 4
Training loss: 3.3268991997838557
Validation loss: 3.6919458187119556

Epoch: 6| Step: 5
Training loss: 4.131896063399387
Validation loss: 3.6864402768027187

Epoch: 6| Step: 6
Training loss: 3.9161375107668097
Validation loss: 3.681405421930485

Epoch: 6| Step: 7
Training loss: 4.162975405559696
Validation loss: 3.6754501598351483

Epoch: 6| Step: 8
Training loss: 4.1534306421611475
Validation loss: 3.6671805054361766

Epoch: 6| Step: 9
Training loss: 4.184321777369932
Validation loss: 3.65999208786686

Epoch: 6| Step: 10
Training loss: 3.441998953553683
Validation loss: 3.652376824159516

Epoch: 6| Step: 11
Training loss: 4.603121171316508
Validation loss: 3.6467530293252883

Epoch: 6| Step: 12
Training loss: 3.738205864125271
Validation loss: 3.635380539398878

Epoch: 6| Step: 13
Training loss: 4.189173349851083
Validation loss: 3.629868038925559

Epoch: 10| Step: 0
Training loss: 3.5609012161689457
Validation loss: 3.629117653228274

Epoch: 6| Step: 1
Training loss: 3.5265850210083394
Validation loss: 3.629878532562544

Epoch: 6| Step: 2
Training loss: 4.4147883805809425
Validation loss: 3.6125244369727763

Epoch: 6| Step: 3
Training loss: 4.405790697332452
Validation loss: 3.6095764646578803

Epoch: 6| Step: 4
Training loss: 3.877955755310899
Validation loss: 3.613820456171076

Epoch: 6| Step: 5
Training loss: 3.325047749341412
Validation loss: 3.604266703337232

Epoch: 6| Step: 6
Training loss: 3.462230707706907
Validation loss: 3.5888372197426675

Epoch: 6| Step: 7
Training loss: 4.050494015551625
Validation loss: 3.5758441168584643

Epoch: 6| Step: 8
Training loss: 3.6066288264810944
Validation loss: 3.57799831477243

Epoch: 6| Step: 9
Training loss: 4.157832941336918
Validation loss: 3.567901250181698

Epoch: 6| Step: 10
Training loss: 3.1161821699353753
Validation loss: 3.557926537453783

Epoch: 6| Step: 11
Training loss: 4.282924797871047
Validation loss: 3.566131778554081

Epoch: 6| Step: 12
Training loss: 3.263371324197902
Validation loss: 3.5475350526925635

Epoch: 6| Step: 13
Training loss: 3.6534121985404067
Validation loss: 3.540988614481058

Epoch: 11| Step: 0
Training loss: 3.3666201509592266
Validation loss: 3.543639897319507

Epoch: 6| Step: 1
Training loss: 3.0552247494502462
Validation loss: 3.5339152980210655

Epoch: 6| Step: 2
Training loss: 3.49613030270696
Validation loss: 3.529208510186485

Epoch: 6| Step: 3
Training loss: 4.248930179358962
Validation loss: 3.5220892954138785

Epoch: 6| Step: 4
Training loss: 1.8985103389125928
Validation loss: 3.515811361571322

Epoch: 6| Step: 5
Training loss: 4.385631613398178
Validation loss: 3.514065842622854

Epoch: 6| Step: 6
Training loss: 3.8991113970864757
Validation loss: 3.5066828293297063

Epoch: 6| Step: 7
Training loss: 4.416514460022285
Validation loss: 3.497832642417802

Epoch: 6| Step: 8
Training loss: 3.674427719711304
Validation loss: 3.4959086516898235

Epoch: 6| Step: 9
Training loss: 3.808134237103237
Validation loss: 3.4862902488407803

Epoch: 6| Step: 10
Training loss: 4.206729293655305
Validation loss: 3.488741088568458

Epoch: 6| Step: 11
Training loss: 3.989157525322962
Validation loss: 3.481162019940731

Epoch: 6| Step: 12
Training loss: 3.4253576662746825
Validation loss: 3.474591686428306

Epoch: 6| Step: 13
Training loss: 3.109322858977083
Validation loss: 3.469668988607828

Epoch: 12| Step: 0
Training loss: 3.735028453141471
Validation loss: 3.477172823062124

Epoch: 6| Step: 1
Training loss: 4.297576292202931
Validation loss: 3.4624836126816136

Epoch: 6| Step: 2
Training loss: 3.9549141555516982
Validation loss: 3.4676373297369043

Epoch: 6| Step: 3
Training loss: 3.6986151810106103
Validation loss: 3.4728380359119897

Epoch: 6| Step: 4
Training loss: 2.947057717929878
Validation loss: 3.459276979177485

Epoch: 6| Step: 5
Training loss: 3.682255134599141
Validation loss: 3.458725921926428

Epoch: 6| Step: 6
Training loss: 3.3376660480697438
Validation loss: 3.452859099442298

Epoch: 6| Step: 7
Training loss: 3.6190083413155762
Validation loss: 3.4523083663083716

Epoch: 6| Step: 8
Training loss: 3.8000060934720623
Validation loss: 3.4465412702492317

Epoch: 6| Step: 9
Training loss: 3.2779175320877076
Validation loss: 3.4410541510694

Epoch: 6| Step: 10
Training loss: 3.0857295099014053
Validation loss: 3.4374192124882876

Epoch: 6| Step: 11
Training loss: 3.2704359327443715
Validation loss: 3.437896499811373

Epoch: 6| Step: 12
Training loss: 4.018824627362837
Validation loss: 3.4363235026480883

Epoch: 6| Step: 13
Training loss: 4.858705137147264
Validation loss: 3.4338330485724486

Epoch: 13| Step: 0
Training loss: 4.595244702951616
Validation loss: 3.420199278491328

Epoch: 6| Step: 1
Training loss: 3.204879354744387
Validation loss: 3.420642032235196

Epoch: 6| Step: 2
Training loss: 3.6741178115454103
Validation loss: 3.427846024344428

Epoch: 6| Step: 3
Training loss: 2.982705493124626
Validation loss: 3.4282624119287686

Epoch: 6| Step: 4
Training loss: 3.300229070400153
Validation loss: 3.4278289590220017

Epoch: 6| Step: 5
Training loss: 2.7005324086033466
Validation loss: 3.4238078244392156

Epoch: 6| Step: 6
Training loss: 4.229698611224785
Validation loss: 3.421685160024643

Epoch: 6| Step: 7
Training loss: 4.20973225120447
Validation loss: 3.403744832563016

Epoch: 6| Step: 8
Training loss: 3.5939001964197854
Validation loss: 3.3956534892119157

Epoch: 6| Step: 9
Training loss: 3.686369253812165
Validation loss: 3.4048326005699816

Epoch: 6| Step: 10
Training loss: 3.9162508696486027
Validation loss: 3.3788203664611816

Epoch: 6| Step: 11
Training loss: 3.4414974204899904
Validation loss: 3.3770691663641994

Epoch: 6| Step: 12
Training loss: 3.3802900887326777
Validation loss: 3.3801599630531665

Epoch: 6| Step: 13
Training loss: 3.417347320740356
Validation loss: 3.3805833070662517

Epoch: 14| Step: 0
Training loss: 3.148970414488787
Validation loss: 3.381111393868423

Epoch: 6| Step: 1
Training loss: 2.76619382709021
Validation loss: 3.3655521561618644

Epoch: 6| Step: 2
Training loss: 3.676692707756925
Validation loss: 3.3627966795088913

Epoch: 6| Step: 3
Training loss: 3.811638781722573
Validation loss: 3.3652782209621948

Epoch: 6| Step: 4
Training loss: 4.167717737506508
Validation loss: 3.3738144463788835

Epoch: 6| Step: 5
Training loss: 3.492597654010942
Validation loss: 3.3660142368320733

Epoch: 6| Step: 6
Training loss: 4.05465221940937
Validation loss: 3.3939396278591087

Epoch: 6| Step: 7
Training loss: 3.430827236014146
Validation loss: 3.3998107074496606

Epoch: 6| Step: 8
Training loss: 4.557434196059885
Validation loss: 3.400053406126448

Epoch: 6| Step: 9
Training loss: 3.9905792400989597
Validation loss: 3.383297781760268

Epoch: 6| Step: 10
Training loss: 3.009164798482102
Validation loss: 3.365625851168573

Epoch: 6| Step: 11
Training loss: 3.7136084651779866
Validation loss: 3.3542301113635444

Epoch: 6| Step: 12
Training loss: 2.711227797210238
Validation loss: 3.351279783794056

Epoch: 6| Step: 13
Training loss: 3.2973308519271027
Validation loss: 3.3529441734048366

Epoch: 15| Step: 0
Training loss: 3.07849335765881
Validation loss: 3.412146390870308

Epoch: 6| Step: 1
Training loss: 3.810150172760814
Validation loss: 3.334169686411448

Epoch: 6| Step: 2
Training loss: 4.07301776627174
Validation loss: 3.3303687622970064

Epoch: 6| Step: 3
Training loss: 3.1685093654778886
Validation loss: 3.3376914933845288

Epoch: 6| Step: 4
Training loss: 3.7939856567594306
Validation loss: 3.3472435248663555

Epoch: 6| Step: 5
Training loss: 3.634568575478856
Validation loss: 3.3311064162225548

Epoch: 6| Step: 6
Training loss: 3.0590419319124624
Validation loss: 3.3261471462262033

Epoch: 6| Step: 7
Training loss: 3.736696678764788
Validation loss: 3.331014380806693

Epoch: 6| Step: 8
Training loss: 4.233744782004507
Validation loss: 3.3302209649494414

Epoch: 6| Step: 9
Training loss: 3.431631176175096
Validation loss: 3.326429338061051

Epoch: 6| Step: 10
Training loss: 3.6794506085835503
Validation loss: 3.3312073223998233

Epoch: 6| Step: 11
Training loss: 3.544437865115297
Validation loss: 3.3293501533179257

Epoch: 6| Step: 12
Training loss: 2.9029139578561933
Validation loss: 3.32411855714834

Epoch: 6| Step: 13
Training loss: 3.689199540898198
Validation loss: 3.326727827715271

Epoch: 16| Step: 0
Training loss: 4.027011742952938
Validation loss: 3.31455261381647

Epoch: 6| Step: 1
Training loss: 3.4594252061517397
Validation loss: 3.3137496615627486

Epoch: 6| Step: 2
Training loss: 3.870833956934314
Validation loss: 3.313172912664103

Epoch: 6| Step: 3
Training loss: 4.126867391812401
Validation loss: 3.312605435347113

Epoch: 6| Step: 4
Training loss: 3.2549620675075595
Validation loss: 3.307575912346667

Epoch: 6| Step: 5
Training loss: 3.3466422148744677
Validation loss: 3.3031992873213984

Epoch: 6| Step: 6
Training loss: 3.2182750166263916
Validation loss: 3.29815393969633

Epoch: 6| Step: 7
Training loss: 2.8734826769448514
Validation loss: 3.2944313436608064

Epoch: 6| Step: 8
Training loss: 4.266786074954289
Validation loss: 3.290861965733123

Epoch: 6| Step: 9
Training loss: 4.200456757913079
Validation loss: 3.2902449272047822

Epoch: 6| Step: 10
Training loss: 1.714726958935787
Validation loss: 3.2882412709554507

Epoch: 6| Step: 11
Training loss: 3.0778088092578484
Validation loss: 3.291714333162762

Epoch: 6| Step: 12
Training loss: 3.5067168225906595
Validation loss: 3.301030084801056

Epoch: 6| Step: 13
Training loss: 4.1150378527470455
Validation loss: 3.2840137427140905

Epoch: 17| Step: 0
Training loss: 3.5616201016838196
Validation loss: 3.2874843205727213

Epoch: 6| Step: 1
Training loss: 2.9759032152599048
Validation loss: 3.2911570008929347

Epoch: 6| Step: 2
Training loss: 3.824105406222212
Validation loss: 3.293036281209658

Epoch: 6| Step: 3
Training loss: 3.377349883159334
Validation loss: 3.290648235210226

Epoch: 6| Step: 4
Training loss: 2.8717437216025172
Validation loss: 3.2909311932166405

Epoch: 6| Step: 5
Training loss: 3.403351276535971
Validation loss: 3.285700264003182

Epoch: 6| Step: 6
Training loss: 4.1335148638168135
Validation loss: 3.285809160544412

Epoch: 6| Step: 7
Training loss: 3.535092044479104
Validation loss: 3.2802301418711792

Epoch: 6| Step: 8
Training loss: 2.9899642294080455
Validation loss: 3.274789760191077

Epoch: 6| Step: 9
Training loss: 3.101165207945661
Validation loss: 3.2703835312830116

Epoch: 6| Step: 10
Training loss: 4.1506973691793885
Validation loss: 3.2681835459484754

Epoch: 6| Step: 11
Training loss: 3.725052693653555
Validation loss: 3.2654521033023225

Epoch: 6| Step: 12
Training loss: 4.160823972602235
Validation loss: 3.262801150391589

Epoch: 6| Step: 13
Training loss: 2.954101885330561
Validation loss: 3.267914778786069

Epoch: 18| Step: 0
Training loss: 3.1978806152962465
Validation loss: 3.2681508039391476

Epoch: 6| Step: 1
Training loss: 2.4347645008482988
Validation loss: 3.264351505950972

Epoch: 6| Step: 2
Training loss: 3.1753858857430957
Validation loss: 3.2614659066533727

Epoch: 6| Step: 3
Training loss: 3.9609545946222586
Validation loss: 3.260493657406357

Epoch: 6| Step: 4
Training loss: 3.770781346308736
Validation loss: 3.253539236801877

Epoch: 6| Step: 5
Training loss: 3.6160014043146966
Validation loss: 3.2531109648405674

Epoch: 6| Step: 6
Training loss: 3.5331774827185867
Validation loss: 3.251696018652426

Epoch: 6| Step: 7
Training loss: 3.3668192863492976
Validation loss: 3.2518842565749466

Epoch: 6| Step: 8
Training loss: 3.5829012114916865
Validation loss: 3.250197493718729

Epoch: 6| Step: 9
Training loss: 3.771255525730979
Validation loss: 3.252705605023811

Epoch: 6| Step: 10
Training loss: 3.8128411812630167
Validation loss: 3.247106223020765

Epoch: 6| Step: 11
Training loss: 3.1103514091934814
Validation loss: 3.246057237530069

Epoch: 6| Step: 12
Training loss: 3.703681871738373
Validation loss: 3.2413488733418014

Epoch: 6| Step: 13
Training loss: 3.9177264274592476
Validation loss: 3.2386317416286

Epoch: 19| Step: 0
Training loss: 3.6339379976953032
Validation loss: 3.236136257870761

Epoch: 6| Step: 1
Training loss: 4.161296333657779
Validation loss: 3.234169096890012

Epoch: 6| Step: 2
Training loss: 3.654291655528074
Validation loss: 3.2314453013932147

Epoch: 6| Step: 3
Training loss: 3.9509758818171963
Validation loss: 3.2301851178250693

Epoch: 6| Step: 4
Training loss: 3.9064976728123093
Validation loss: 3.2267501114259427

Epoch: 6| Step: 5
Training loss: 3.4961901773974997
Validation loss: 3.22505178642873

Epoch: 6| Step: 6
Training loss: 3.1954988830975113
Validation loss: 3.2240307525930536

Epoch: 6| Step: 7
Training loss: 2.3497628964872717
Validation loss: 3.2230502278382773

Epoch: 6| Step: 8
Training loss: 3.6944628135842743
Validation loss: 3.2210239168132078

Epoch: 6| Step: 9
Training loss: 2.925423655028681
Validation loss: 3.219208169918447

Epoch: 6| Step: 10
Training loss: 4.323865867489308
Validation loss: 3.219281802681747

Epoch: 6| Step: 11
Training loss: 3.2722598486224683
Validation loss: 3.218900363817699

Epoch: 6| Step: 12
Training loss: 2.9005165560834603
Validation loss: 3.21676188691476

Epoch: 6| Step: 13
Training loss: 1.8071587226920813
Validation loss: 3.2157716799581624

Epoch: 20| Step: 0
Training loss: 2.8550856472870874
Validation loss: 3.2179672049171315

Epoch: 6| Step: 1
Training loss: 3.1797093945998345
Validation loss: 3.21427142359325

Epoch: 6| Step: 2
Training loss: 3.8940135493108903
Validation loss: 3.2134021377660495

Epoch: 6| Step: 3
Training loss: 2.9859951874067563
Validation loss: 3.213430859903436

Epoch: 6| Step: 4
Training loss: 2.3936494133833954
Validation loss: 3.2150018877626616

Epoch: 6| Step: 5
Training loss: 3.810487059451721
Validation loss: 3.2379661353402196

Epoch: 6| Step: 6
Training loss: 3.07795521224306
Validation loss: 3.2102009792546484

Epoch: 6| Step: 7
Training loss: 3.361030773817584
Validation loss: 3.209435025426144

Epoch: 6| Step: 8
Training loss: 3.1692506052383598
Validation loss: 3.211576198617032

Epoch: 6| Step: 9
Training loss: 3.6061774287863573
Validation loss: 3.2127666380768893

Epoch: 6| Step: 10
Training loss: 3.754707687520506
Validation loss: 3.212311411255807

Epoch: 6| Step: 11
Training loss: 4.372422685326769
Validation loss: 3.2123923965065493

Epoch: 6| Step: 12
Training loss: 4.219459304521109
Validation loss: 3.2093571208178617

Epoch: 6| Step: 13
Training loss: 3.2933413112662153
Validation loss: 3.206242317152602

Epoch: 21| Step: 0
Training loss: 3.605896169139814
Validation loss: 3.202733762044503

Epoch: 6| Step: 1
Training loss: 2.8967179701300094
Validation loss: 3.2017611173306784

Epoch: 6| Step: 2
Training loss: 3.268368531354824
Validation loss: 3.200705278645615

Epoch: 6| Step: 3
Training loss: 3.4835169809167645
Validation loss: 3.2014500506382357

Epoch: 6| Step: 4
Training loss: 3.6191174361777354
Validation loss: 3.2049896607363317

Epoch: 6| Step: 5
Training loss: 3.989000335938159
Validation loss: 3.2012271880454097

Epoch: 6| Step: 6
Training loss: 3.4247789297666262
Validation loss: 3.1979633720834997

Epoch: 6| Step: 7
Training loss: 3.4269871258589846
Validation loss: 3.194230486026837

Epoch: 6| Step: 8
Training loss: 3.292273759187126
Validation loss: 3.1933262399092914

Epoch: 6| Step: 9
Training loss: 3.045675031633452
Validation loss: 3.1914344391031166

Epoch: 6| Step: 10
Training loss: 3.5532783146428364
Validation loss: 3.191328024175655

Epoch: 6| Step: 11
Training loss: 3.9187818997436934
Validation loss: 3.1902262083930513

Epoch: 6| Step: 12
Training loss: 3.5635425313758784
Validation loss: 3.1873954258750423

Epoch: 6| Step: 13
Training loss: 2.920537305805569
Validation loss: 3.1873405170535727

Epoch: 22| Step: 0
Training loss: 4.020720458875854
Validation loss: 3.18623262512521

Epoch: 6| Step: 1
Training loss: 3.3880552055067703
Validation loss: 3.1857820111994912

Epoch: 6| Step: 2
Training loss: 3.2499665478672024
Validation loss: 3.1843690223271035

Epoch: 6| Step: 3
Training loss: 2.233892001786786
Validation loss: 3.187237509387727

Epoch: 6| Step: 4
Training loss: 2.369239547186376
Validation loss: 3.1952045012340298

Epoch: 6| Step: 5
Training loss: 3.70032598245125
Validation loss: 3.1855339084785186

Epoch: 6| Step: 6
Training loss: 4.164822335546851
Validation loss: 3.18071632685245

Epoch: 6| Step: 7
Training loss: 2.763480696788642
Validation loss: 3.1797480572763175

Epoch: 6| Step: 8
Training loss: 3.6339334050712426
Validation loss: 3.177400867578487

Epoch: 6| Step: 9
Training loss: 4.059945110081539
Validation loss: 3.177568526046052

Epoch: 6| Step: 10
Training loss: 3.264999110643812
Validation loss: 3.175856058334746

Epoch: 6| Step: 11
Training loss: 3.683189847288879
Validation loss: 3.1748384091422874

Epoch: 6| Step: 12
Training loss: 3.7053998567151334
Validation loss: 3.1731206069783995

Epoch: 6| Step: 13
Training loss: 3.1942829441396827
Validation loss: 3.1732151076461794

Epoch: 23| Step: 0
Training loss: 3.4672263983478064
Validation loss: 3.1789639968491357

Epoch: 6| Step: 1
Training loss: 3.1588577224363403
Validation loss: 3.2044288940693915

Epoch: 6| Step: 2
Training loss: 3.1222092946857
Validation loss: 3.19720526480974

Epoch: 6| Step: 3
Training loss: 4.249046891993126
Validation loss: 3.16980573951584

Epoch: 6| Step: 4
Training loss: 2.2445719199076013
Validation loss: 3.1659609413549856

Epoch: 6| Step: 5
Training loss: 2.528318520814593
Validation loss: 3.1662750687447283

Epoch: 6| Step: 6
Training loss: 3.8762064870626642
Validation loss: 3.166816408074362

Epoch: 6| Step: 7
Training loss: 3.1737827520795214
Validation loss: 3.1671782929253625

Epoch: 6| Step: 8
Training loss: 3.293037097081341
Validation loss: 3.169643669386638

Epoch: 6| Step: 9
Training loss: 3.7696987292781747
Validation loss: 3.1700468656323983

Epoch: 6| Step: 10
Training loss: 3.707256475104547
Validation loss: 3.1632145186793603

Epoch: 6| Step: 11
Training loss: 4.008234132000474
Validation loss: 3.1612452799308985

Epoch: 6| Step: 12
Training loss: 3.748392396300129
Validation loss: 3.1622794663948777

Epoch: 6| Step: 13
Training loss: 3.0310701926475323
Validation loss: 3.1594358188578706

Epoch: 24| Step: 0
Training loss: 3.5487755880209306
Validation loss: 3.1601015217497297

Epoch: 6| Step: 1
Training loss: 3.1902382252869503
Validation loss: 3.1569998756108353

Epoch: 6| Step: 2
Training loss: 2.7687404348238327
Validation loss: 3.156187905068612

Epoch: 6| Step: 3
Training loss: 3.0565568516375548
Validation loss: 3.163972342019548

Epoch: 6| Step: 4
Training loss: 3.7534470292166446
Validation loss: 3.1702372450236798

Epoch: 6| Step: 5
Training loss: 3.273532765898209
Validation loss: 3.1800025142319983

Epoch: 6| Step: 6
Training loss: 3.7829448590133388
Validation loss: 3.1627532133876564

Epoch: 6| Step: 7
Training loss: 3.4773266584687246
Validation loss: 3.157813584976167

Epoch: 6| Step: 8
Training loss: 3.534226504983147
Validation loss: 3.152807981822155

Epoch: 6| Step: 9
Training loss: 3.7292396637717764
Validation loss: 3.156780906138029

Epoch: 6| Step: 10
Training loss: 3.591172330489779
Validation loss: 3.1504607241807827

Epoch: 6| Step: 11
Training loss: 3.586850384635899
Validation loss: 3.1525987160446536

Epoch: 6| Step: 12
Training loss: 3.133437401145811
Validation loss: 3.1551537142424273

Epoch: 6| Step: 13
Training loss: 3.300984068288091
Validation loss: 3.1530634526410077

Epoch: 25| Step: 0
Training loss: 3.2898360042802426
Validation loss: 3.1507364365076627

Epoch: 6| Step: 1
Training loss: 3.715193514398176
Validation loss: 3.152508540858574

Epoch: 6| Step: 2
Training loss: 3.43101819754533
Validation loss: 3.1521780087346203

Epoch: 6| Step: 3
Training loss: 3.1755370999900294
Validation loss: 3.1467114690954636

Epoch: 6| Step: 4
Training loss: 2.8816272811301458
Validation loss: 3.1471123287886793

Epoch: 6| Step: 5
Training loss: 2.6702960072427153
Validation loss: 3.1434305445314976

Epoch: 6| Step: 6
Training loss: 4.255173171359976
Validation loss: 3.146667543170064

Epoch: 6| Step: 7
Training loss: 3.5264407466884773
Validation loss: 3.146002043663427

Epoch: 6| Step: 8
Training loss: 3.060958162776417
Validation loss: 3.1525028858150623

Epoch: 6| Step: 9
Training loss: 3.3858952736609
Validation loss: 3.14350883765624

Epoch: 6| Step: 10
Training loss: 4.2685018486849176
Validation loss: 3.144465240191275

Epoch: 6| Step: 11
Training loss: 2.989065428920334
Validation loss: 3.1378307822980918

Epoch: 6| Step: 12
Training loss: 2.9250816659856778
Validation loss: 3.138895246469231

Epoch: 6| Step: 13
Training loss: 3.8766211533327946
Validation loss: 3.1388871705988297

Epoch: 26| Step: 0
Training loss: 3.0226810110206412
Validation loss: 3.135355898562213

Epoch: 6| Step: 1
Training loss: 3.7763620104777678
Validation loss: 3.1371284407028033

Epoch: 6| Step: 2
Training loss: 2.8397020307227687
Validation loss: 3.140422671882085

Epoch: 6| Step: 3
Training loss: 2.9946180387281407
Validation loss: 3.1391254310753878

Epoch: 6| Step: 4
Training loss: 3.216899006281324
Validation loss: 3.1399309026701157

Epoch: 6| Step: 5
Training loss: 3.6038207547813434
Validation loss: 3.1324889542482843

Epoch: 6| Step: 6
Training loss: 2.6699754532389313
Validation loss: 3.130216917533598

Epoch: 6| Step: 7
Training loss: 3.9650677998195096
Validation loss: 3.136219552397139

Epoch: 6| Step: 8
Training loss: 4.094344933064165
Validation loss: 3.1417112284688122

Epoch: 6| Step: 9
Training loss: 3.0568312515438336
Validation loss: 3.129222481553442

Epoch: 6| Step: 10
Training loss: 3.570053658816777
Validation loss: 3.1286928634307043

Epoch: 6| Step: 11
Training loss: 3.3452937760379204
Validation loss: 3.1331093001363066

Epoch: 6| Step: 12
Training loss: 3.6379767351292664
Validation loss: 3.131592154926857

Epoch: 6| Step: 13
Training loss: 3.550756943286923
Validation loss: 3.127934147741689

Epoch: 27| Step: 0
Training loss: 3.5033570946910855
Validation loss: 3.1242015466667037

Epoch: 6| Step: 1
Training loss: 3.912733632872486
Validation loss: 3.1230147538766335

Epoch: 6| Step: 2
Training loss: 4.0574100005392095
Validation loss: 3.1222522542513884

Epoch: 6| Step: 3
Training loss: 2.8668222636496705
Validation loss: 3.1222349440479524

Epoch: 6| Step: 4
Training loss: 3.7205424116373127
Validation loss: 3.1215340670539615

Epoch: 6| Step: 5
Training loss: 3.2326306048072104
Validation loss: 3.1247234213885604

Epoch: 6| Step: 6
Training loss: 3.182885963067801
Validation loss: 3.1189248162307974

Epoch: 6| Step: 7
Training loss: 2.9492974883425465
Validation loss: 3.1164646758602

Epoch: 6| Step: 8
Training loss: 2.7606922707836965
Validation loss: 3.117264452988353

Epoch: 6| Step: 9
Training loss: 3.8081389952865266
Validation loss: 3.1153770607233437

Epoch: 6| Step: 10
Training loss: 3.9171193990733393
Validation loss: 3.113819257553561

Epoch: 6| Step: 11
Training loss: 2.4819530461532358
Validation loss: 3.115951980365193

Epoch: 6| Step: 12
Training loss: 3.07365829225475
Validation loss: 3.1179146755429255

Epoch: 6| Step: 13
Training loss: 3.4116259507018705
Validation loss: 3.112306007085272

Epoch: 28| Step: 0
Training loss: 3.3734050796880353
Validation loss: 3.1109021866420545

Epoch: 6| Step: 1
Training loss: 3.599368273090714
Validation loss: 3.115512064252216

Epoch: 6| Step: 2
Training loss: 3.4971768028239523
Validation loss: 3.115826038267068

Epoch: 6| Step: 3
Training loss: 3.4018677686214596
Validation loss: 3.1121979771625936

Epoch: 6| Step: 4
Training loss: 3.651627708051971
Validation loss: 3.110744023847913

Epoch: 6| Step: 5
Training loss: 3.186242846738703
Validation loss: 3.1126819013662024

Epoch: 6| Step: 6
Training loss: 4.169959382149819
Validation loss: 3.1109254331037395

Epoch: 6| Step: 7
Training loss: 3.97062398566148
Validation loss: 3.113625814701694

Epoch: 6| Step: 8
Training loss: 1.9435701955568168
Validation loss: 3.1107112367025356

Epoch: 6| Step: 9
Training loss: 2.974752681934543
Validation loss: 3.1122508607939268

Epoch: 6| Step: 10
Training loss: 3.6808901236876297
Validation loss: 3.1090426511386764

Epoch: 6| Step: 11
Training loss: 3.0242399979172356
Validation loss: 3.103552293705077

Epoch: 6| Step: 12
Training loss: 3.1739702492216804
Validation loss: 3.1013948087272345

Epoch: 6| Step: 13
Training loss: 2.812935180904497
Validation loss: 3.10315247313403

Epoch: 29| Step: 0
Training loss: 3.5988448143964074
Validation loss: 3.100195471468779

Epoch: 6| Step: 1
Training loss: 3.6678874988920813
Validation loss: 3.0998876220493896

Epoch: 6| Step: 2
Training loss: 2.458792778228684
Validation loss: 3.1007220182625246

Epoch: 6| Step: 3
Training loss: 3.5373810064029643
Validation loss: 3.1104236058369166

Epoch: 6| Step: 4
Training loss: 3.2957669244595147
Validation loss: 3.1241137841531015

Epoch: 6| Step: 5
Training loss: 4.132744195442169
Validation loss: 3.105060100026947

Epoch: 6| Step: 6
Training loss: 3.0031178485257266
Validation loss: 3.101136396704569

Epoch: 6| Step: 7
Training loss: 3.6021818013335194
Validation loss: 3.0978758658231467

Epoch: 6| Step: 8
Training loss: 2.8642113646400134
Validation loss: 3.097610789238029

Epoch: 6| Step: 9
Training loss: 3.7531305597345113
Validation loss: 3.091476294354642

Epoch: 6| Step: 10
Training loss: 3.012274110801259
Validation loss: 3.093678226344814

Epoch: 6| Step: 11
Training loss: 3.0006317427181424
Validation loss: 3.0936404685606504

Epoch: 6| Step: 12
Training loss: 3.3506849869686306
Validation loss: 3.094028280981732

Epoch: 6| Step: 13
Training loss: 3.407377423931586
Validation loss: 3.0904356164287163

Epoch: 30| Step: 0
Training loss: 3.717419554629475
Validation loss: 3.0936243730504898

Epoch: 6| Step: 1
Training loss: 4.463309437405522
Validation loss: 3.0932608845804785

Epoch: 6| Step: 2
Training loss: 2.885370210532966
Validation loss: 3.0881232233940588

Epoch: 6| Step: 3
Training loss: 2.6351858246515247
Validation loss: 3.0851947389508756

Epoch: 6| Step: 4
Training loss: 3.2026444237429232
Validation loss: 3.0917405867727594

Epoch: 6| Step: 5
Training loss: 3.222210255596989
Validation loss: 3.093457588206231

Epoch: 6| Step: 6
Training loss: 4.0468698155432525
Validation loss: 3.0975543600253777

Epoch: 6| Step: 7
Training loss: 3.0719772368422196
Validation loss: 3.0833635525496073

Epoch: 6| Step: 8
Training loss: 3.3506156811106944
Validation loss: 3.082397415895559

Epoch: 6| Step: 9
Training loss: 3.1794304521215633
Validation loss: 3.081705916619241

Epoch: 6| Step: 10
Training loss: 3.517931101286442
Validation loss: 3.080655907408858

Epoch: 6| Step: 11
Training loss: 3.451453585479916
Validation loss: 3.0797593062318964

Epoch: 6| Step: 12
Training loss: 2.946508999341954
Validation loss: 3.079192956621852

Epoch: 6| Step: 13
Training loss: 2.323860102318228
Validation loss: 3.0826019773890496

Epoch: 31| Step: 0
Training loss: 3.637278053879762
Validation loss: 3.140936759144121

Epoch: 6| Step: 1
Training loss: 3.64264475579977
Validation loss: 3.2003523236560456

Epoch: 6| Step: 2
Training loss: 3.294327605993422
Validation loss: 3.0854591149403623

Epoch: 6| Step: 3
Training loss: 2.9388161815101763
Validation loss: 3.0763603046221095

Epoch: 6| Step: 4
Training loss: 3.533009858589227
Validation loss: 3.0758809826299256

Epoch: 6| Step: 5
Training loss: 4.122516231100078
Validation loss: 3.0875089491396093

Epoch: 6| Step: 6
Training loss: 3.3674535801101664
Validation loss: 3.1013028355478127

Epoch: 6| Step: 7
Training loss: 3.8081147034463774
Validation loss: 3.0835449996394333

Epoch: 6| Step: 8
Training loss: 2.490309339404748
Validation loss: 3.073087893485297

Epoch: 6| Step: 9
Training loss: 2.613684379377828
Validation loss: 3.071608252988434

Epoch: 6| Step: 10
Training loss: 3.756513406718192
Validation loss: 3.0706182642445716

Epoch: 6| Step: 11
Training loss: 3.196490604562853
Validation loss: 3.071576390184177

Epoch: 6| Step: 12
Training loss: 3.0263430805852547
Validation loss: 3.071566109151187

Epoch: 6| Step: 13
Training loss: 3.1183269206119935
Validation loss: 3.0695387043589673

Epoch: 32| Step: 0
Training loss: 3.4178641167020167
Validation loss: 3.073004857141835

Epoch: 6| Step: 1
Training loss: 3.046319685973616
Validation loss: 3.077223033523312

Epoch: 6| Step: 2
Training loss: 3.922761976393355
Validation loss: 3.088212960875034

Epoch: 6| Step: 3
Training loss: 3.6027501727670552
Validation loss: 3.0676891186255504

Epoch: 6| Step: 4
Training loss: 3.5522707594182306
Validation loss: 3.0639801876617203

Epoch: 6| Step: 5
Training loss: 3.539699606569537
Validation loss: 3.0915761133740736

Epoch: 6| Step: 6
Training loss: 3.6342135445180164
Validation loss: 3.1209976555434533

Epoch: 6| Step: 7
Training loss: 2.411506558973491
Validation loss: 3.074151642367878

Epoch: 6| Step: 8
Training loss: 3.495650176993131
Validation loss: 3.0660805613833366

Epoch: 6| Step: 9
Training loss: 3.1387595334776095
Validation loss: 3.0620476566747366

Epoch: 6| Step: 10
Training loss: 2.329942441892447
Validation loss: 3.0634255064480467

Epoch: 6| Step: 11
Training loss: 2.8770804134264765
Validation loss: 3.067712258826111

Epoch: 6| Step: 12
Training loss: 3.7668617085509863
Validation loss: 3.082895192232136

Epoch: 6| Step: 13
Training loss: 3.970434477162287
Validation loss: 3.0681898071868967

Epoch: 33| Step: 0
Training loss: 3.611206778864821
Validation loss: 3.0638108594482034

Epoch: 6| Step: 1
Training loss: 2.682637717630533
Validation loss: 3.06090327567154

Epoch: 6| Step: 2
Training loss: 3.440705070984441
Validation loss: 3.0645293643516642

Epoch: 6| Step: 3
Training loss: 2.5894651754792015
Validation loss: 3.060442607816075

Epoch: 6| Step: 4
Training loss: 3.4129662052049525
Validation loss: 3.0597643274635993

Epoch: 6| Step: 5
Training loss: 3.213276774382216
Validation loss: 3.05923064064315

Epoch: 6| Step: 6
Training loss: 3.6118565075360167
Validation loss: 3.0567975246651073

Epoch: 6| Step: 7
Training loss: 3.5398542516414104
Validation loss: 3.0579447064113774

Epoch: 6| Step: 8
Training loss: 3.3519165990191024
Validation loss: 3.0593658023118486

Epoch: 6| Step: 9
Training loss: 3.0691081783933836
Validation loss: 3.058767625558701

Epoch: 6| Step: 10
Training loss: 4.032580725281045
Validation loss: 3.059402253560409

Epoch: 6| Step: 11
Training loss: 3.6942857279581016
Validation loss: 3.05460861973251

Epoch: 6| Step: 12
Training loss: 3.2089863067268225
Validation loss: 3.0547924914881497

Epoch: 6| Step: 13
Training loss: 2.25384933955177
Validation loss: 3.049760820063856

Epoch: 34| Step: 0
Training loss: 3.3747585351537763
Validation loss: 3.0489802077341372

Epoch: 6| Step: 1
Training loss: 3.3429493168290327
Validation loss: 3.0455747056861537

Epoch: 6| Step: 2
Training loss: 2.7536836574768935
Validation loss: 3.0453345726128043

Epoch: 6| Step: 3
Training loss: 2.8820880920479697
Validation loss: 3.0425428397601606

Epoch: 6| Step: 4
Training loss: 2.8813373544156837
Validation loss: 3.043960861337995

Epoch: 6| Step: 5
Training loss: 3.0887657628878693
Validation loss: 3.0435634019738917

Epoch: 6| Step: 6
Training loss: 3.437971048158858
Validation loss: 3.0442286507006955

Epoch: 6| Step: 7
Training loss: 2.3632262672774993
Validation loss: 3.0474261243732608

Epoch: 6| Step: 8
Training loss: 3.7825804332342647
Validation loss: 3.044577444927054

Epoch: 6| Step: 9
Training loss: 3.506758431683191
Validation loss: 3.045432788506629

Epoch: 6| Step: 10
Training loss: 4.162886290625383
Validation loss: 3.0430860782575

Epoch: 6| Step: 11
Training loss: 3.779333464373913
Validation loss: 3.0418216875404878

Epoch: 6| Step: 12
Training loss: 2.8213619065643636
Validation loss: 3.0393271091274916

Epoch: 6| Step: 13
Training loss: 4.070501341438705
Validation loss: 3.0364026127304817

Epoch: 35| Step: 0
Training loss: 3.5822643341474105
Validation loss: 3.0399494867035655

Epoch: 6| Step: 1
Training loss: 3.2530042994201374
Validation loss: 3.0372596946466923

Epoch: 6| Step: 2
Training loss: 3.9743145957564154
Validation loss: 3.0365264338406703

Epoch: 6| Step: 3
Training loss: 3.874590452147814
Validation loss: 3.0352830637440342

Epoch: 6| Step: 4
Training loss: 2.7076027006922825
Validation loss: 3.0343683101399126

Epoch: 6| Step: 5
Training loss: 3.7193249169889375
Validation loss: 3.0331577242980643

Epoch: 6| Step: 6
Training loss: 3.1580174096021993
Validation loss: 3.0336704796212373

Epoch: 6| Step: 7
Training loss: 3.2814947127869685
Validation loss: 3.030729150335496

Epoch: 6| Step: 8
Training loss: 2.817836699790641
Validation loss: 3.030484900391211

Epoch: 6| Step: 9
Training loss: 3.8446785650340938
Validation loss: 3.0321105642101425

Epoch: 6| Step: 10
Training loss: 2.969046166353675
Validation loss: 3.0331871313795125

Epoch: 6| Step: 11
Training loss: 2.9517321657495135
Validation loss: 3.032330721966711

Epoch: 6| Step: 12
Training loss: 2.4669441668466816
Validation loss: 3.031828762156297

Epoch: 6| Step: 13
Training loss: 3.167496237929473
Validation loss: 3.0338608704144807

Epoch: 36| Step: 0
Training loss: 3.5862797592486673
Validation loss: 3.029472334726688

Epoch: 6| Step: 1
Training loss: 3.9575362490489736
Validation loss: 3.025691090979241

Epoch: 6| Step: 2
Training loss: 3.477172797994695
Validation loss: 3.0263493491809

Epoch: 6| Step: 3
Training loss: 3.4088665073405506
Validation loss: 3.0248210099088753

Epoch: 6| Step: 4
Training loss: 3.121119875076439
Validation loss: 3.0231018176830604

Epoch: 6| Step: 5
Training loss: 3.3942934222911383
Validation loss: 3.020846523359369

Epoch: 6| Step: 6
Training loss: 2.895601020843794
Validation loss: 3.01833319366834

Epoch: 6| Step: 7
Training loss: 2.957930595672163
Validation loss: 3.018783150852684

Epoch: 6| Step: 8
Training loss: 2.9279395827433516
Validation loss: 3.0204227110438726

Epoch: 6| Step: 9
Training loss: 2.4663181157476797
Validation loss: 3.017174576559776

Epoch: 6| Step: 10
Training loss: 2.591628344417065
Validation loss: 3.020543176947195

Epoch: 6| Step: 11
Training loss: 3.8616684496901117
Validation loss: 3.0192305700882636

Epoch: 6| Step: 12
Training loss: 3.402206961228439
Validation loss: 3.0170324213176807

Epoch: 6| Step: 13
Training loss: 4.049809043997838
Validation loss: 3.0132538990215134

Epoch: 37| Step: 0
Training loss: 4.065952184062909
Validation loss: 3.0165982702026795

Epoch: 6| Step: 1
Training loss: 2.7305444535005696
Validation loss: 3.0172587551366465

Epoch: 6| Step: 2
Training loss: 2.90846807683273
Validation loss: 3.0189352440798887

Epoch: 6| Step: 3
Training loss: 2.9342380024512833
Validation loss: 3.015703669002281

Epoch: 6| Step: 4
Training loss: 3.743964997551802
Validation loss: 3.01253332038704

Epoch: 6| Step: 5
Training loss: 2.4907394555188467
Validation loss: 3.0145033090724263

Epoch: 6| Step: 6
Training loss: 3.4493318325354525
Validation loss: 3.012627861095009

Epoch: 6| Step: 7
Training loss: 3.15633671707529
Validation loss: 3.0116350396854816

Epoch: 6| Step: 8
Training loss: 3.5553077240508046
Validation loss: 3.010323521153492

Epoch: 6| Step: 9
Training loss: 3.8300695346267126
Validation loss: 3.0072763767177184

Epoch: 6| Step: 10
Training loss: 4.1770905885451075
Validation loss: 3.005966068531445

Epoch: 6| Step: 11
Training loss: 3.154273141116205
Validation loss: 3.0053346307768294

Epoch: 6| Step: 12
Training loss: 2.578402417602731
Validation loss: 3.0053188522392813

Epoch: 6| Step: 13
Training loss: 1.8529044008746154
Validation loss: 3.005911442087026

Epoch: 38| Step: 0
Training loss: 2.89690298912576
Validation loss: 3.005402116635472

Epoch: 6| Step: 1
Training loss: 2.489902513120003
Validation loss: 3.001619083248102

Epoch: 6| Step: 2
Training loss: 3.228994418236571
Validation loss: 3.003834195272088

Epoch: 6| Step: 3
Training loss: 3.4677308106011457
Validation loss: 3.00634020796077

Epoch: 6| Step: 4
Training loss: 3.651668710596327
Validation loss: 3.008656168635578

Epoch: 6| Step: 5
Training loss: 3.377501655538677
Validation loss: 3.0166427728521046

Epoch: 6| Step: 6
Training loss: 3.771141980994658
Validation loss: 3.0015571323397237

Epoch: 6| Step: 7
Training loss: 3.2790902432200846
Validation loss: 3.0013807171894453

Epoch: 6| Step: 8
Training loss: 3.205639405882907
Validation loss: 3.00796100072478

Epoch: 6| Step: 9
Training loss: 3.0527887321216234
Validation loss: 3.0120226583005127

Epoch: 6| Step: 10
Training loss: 3.118519281021606
Validation loss: 3.004939652779288

Epoch: 6| Step: 11
Training loss: 3.524998625626533
Validation loss: 3.0064637561886287

Epoch: 6| Step: 12
Training loss: 2.9923549834307415
Validation loss: 2.9971387251885595

Epoch: 6| Step: 13
Training loss: 3.8670755389411458
Validation loss: 2.9936682013327403

Epoch: 39| Step: 0
Training loss: 3.524471833180237
Validation loss: 2.9976033375852738

Epoch: 6| Step: 1
Training loss: 3.2616380510226617
Validation loss: 2.9911927712479196

Epoch: 6| Step: 2
Training loss: 3.2985787712430357
Validation loss: 2.996971851257677

Epoch: 6| Step: 3
Training loss: 2.9000522608816426
Validation loss: 2.995644210159879

Epoch: 6| Step: 4
Training loss: 3.0281630065863374
Validation loss: 2.994306101908527

Epoch: 6| Step: 5
Training loss: 2.941885089779974
Validation loss: 2.9906685035797067

Epoch: 6| Step: 6
Training loss: 2.773048481052104
Validation loss: 2.9916192770956855

Epoch: 6| Step: 7
Training loss: 3.5468985266892497
Validation loss: 2.9909973587872702

Epoch: 6| Step: 8
Training loss: 3.535591090314342
Validation loss: 2.992254847995926

Epoch: 6| Step: 9
Training loss: 3.5110264521129038
Validation loss: 2.990921152224161

Epoch: 6| Step: 10
Training loss: 3.586927755087192
Validation loss: 2.9906305365071275

Epoch: 6| Step: 11
Training loss: 3.3428621628599005
Validation loss: 2.995728613770213

Epoch: 6| Step: 12
Training loss: 3.1998017726536347
Validation loss: 3.0003390616227374

Epoch: 6| Step: 13
Training loss: 3.2299872227466233
Validation loss: 2.999168166162223

Epoch: 40| Step: 0
Training loss: 3.639071415472186
Validation loss: 3.004316680122418

Epoch: 6| Step: 1
Training loss: 3.430456262164842
Validation loss: 2.992603129303875

Epoch: 6| Step: 2
Training loss: 3.420008598896839
Validation loss: 2.9955148770469506

Epoch: 6| Step: 3
Training loss: 3.66921056296794
Validation loss: 2.9906276433743164

Epoch: 6| Step: 4
Training loss: 2.9760472610166473
Validation loss: 2.989272364522994

Epoch: 6| Step: 5
Training loss: 2.2897374326609077
Validation loss: 2.9881842253036375

Epoch: 6| Step: 6
Training loss: 2.863269759047116
Validation loss: 2.9808280804662255

Epoch: 6| Step: 7
Training loss: 2.13967986020685
Validation loss: 2.982929927236206

Epoch: 6| Step: 8
Training loss: 3.048719581367796
Validation loss: 2.985284312958747

Epoch: 6| Step: 9
Training loss: 3.703969609640531
Validation loss: 2.980988740788901

Epoch: 6| Step: 10
Training loss: 4.132131942355917
Validation loss: 2.9796609609750115

Epoch: 6| Step: 11
Training loss: 3.3353516825902507
Validation loss: 2.9774773011012607

Epoch: 6| Step: 12
Training loss: 3.230523806636717
Validation loss: 2.9771616945775485

Epoch: 6| Step: 13
Training loss: 3.16419119867502
Validation loss: 2.980392976985558

Epoch: 41| Step: 0
Training loss: 3.208744237439131
Validation loss: 2.976406841036902

Epoch: 6| Step: 1
Training loss: 3.462633393400151
Validation loss: 2.9769858281927455

Epoch: 6| Step: 2
Training loss: 3.3449234374083994
Validation loss: 2.9809248733059155

Epoch: 6| Step: 3
Training loss: 2.5441194383186225
Validation loss: 2.988185127841546

Epoch: 6| Step: 4
Training loss: 3.252714344089878
Validation loss: 2.984790300858886

Epoch: 6| Step: 5
Training loss: 3.491009882759698
Validation loss: 2.99272415308118

Epoch: 6| Step: 6
Training loss: 3.208271042520471
Validation loss: 2.9715454825681227

Epoch: 6| Step: 7
Training loss: 3.6360135321706286
Validation loss: 2.9725256941817504

Epoch: 6| Step: 8
Training loss: 3.274114789065518
Validation loss: 2.975014498916499

Epoch: 6| Step: 9
Training loss: 2.80954485455098
Validation loss: 2.9797595365201657

Epoch: 6| Step: 10
Training loss: 3.477074060414366
Validation loss: 3.019158991474102

Epoch: 6| Step: 11
Training loss: 3.765021184732481
Validation loss: 2.9971814673572927

Epoch: 6| Step: 12
Training loss: 3.117422147633781
Validation loss: 2.9787545384140994

Epoch: 6| Step: 13
Training loss: 2.627444446096202
Validation loss: 2.965869700168957

Epoch: 42| Step: 0
Training loss: 4.27131870892159
Validation loss: 2.9663694594283996

Epoch: 6| Step: 1
Training loss: 3.690045528802954
Validation loss: 2.967105394833703

Epoch: 6| Step: 2
Training loss: 3.129715375542827
Validation loss: 2.975857726901823

Epoch: 6| Step: 3
Training loss: 2.7738519922993556
Validation loss: 2.9819039859892773

Epoch: 6| Step: 4
Training loss: 3.303758422979384
Validation loss: 2.98368366748903

Epoch: 6| Step: 5
Training loss: 3.1250004577636386
Validation loss: 2.976870393545839

Epoch: 6| Step: 6
Training loss: 3.352695229213027
Validation loss: 2.983100508590308

Epoch: 6| Step: 7
Training loss: 3.4446793923866132
Validation loss: 2.985035331941445

Epoch: 6| Step: 8
Training loss: 3.302539172232611
Validation loss: 2.9640091425474715

Epoch: 6| Step: 9
Training loss: 2.584174993264386
Validation loss: 2.967822606083543

Epoch: 6| Step: 10
Training loss: 3.098813931389245
Validation loss: 2.9716075794798917

Epoch: 6| Step: 11
Training loss: 3.5173524130717553
Validation loss: 2.961941894516468

Epoch: 6| Step: 12
Training loss: 1.7847071109763653
Validation loss: 2.9583764224024707

Epoch: 6| Step: 13
Training loss: 3.6988583220992517
Validation loss: 2.9590147904041375

Epoch: 43| Step: 0
Training loss: 3.139104522530134
Validation loss: 2.9600807487478757

Epoch: 6| Step: 1
Training loss: 3.531011657773384
Validation loss: 2.9647635446713942

Epoch: 6| Step: 2
Training loss: 3.423413771142733
Validation loss: 2.9717985742621615

Epoch: 6| Step: 3
Training loss: 2.9900568853982494
Validation loss: 2.9605656153635858

Epoch: 6| Step: 4
Training loss: 3.4046865252300407
Validation loss: 2.957286185479073

Epoch: 6| Step: 5
Training loss: 3.3650313198224815
Validation loss: 2.954614933065262

Epoch: 6| Step: 6
Training loss: 3.2413287760572933
Validation loss: 2.9552416217706354

Epoch: 6| Step: 7
Training loss: 3.309662809455441
Validation loss: 2.953835552011656

Epoch: 6| Step: 8
Training loss: 3.3593931685555205
Validation loss: 2.9522733192157657

Epoch: 6| Step: 9
Training loss: 2.6566799040320594
Validation loss: 2.952298572798354

Epoch: 6| Step: 10
Training loss: 3.041324352354274
Validation loss: 2.9508951978150866

Epoch: 6| Step: 11
Training loss: 3.291806922210103
Validation loss: 2.9477240647614087

Epoch: 6| Step: 12
Training loss: 3.3888846294883543
Validation loss: 2.9500570712679135

Epoch: 6| Step: 13
Training loss: 3.0008686715372064
Validation loss: 2.9468989746042746

Epoch: 44| Step: 0
Training loss: 3.5091721378435654
Validation loss: 2.9477309197422517

Epoch: 6| Step: 1
Training loss: 2.8380025275812595
Validation loss: 2.94433941160089

Epoch: 6| Step: 2
Training loss: 2.3319726677825603
Validation loss: 2.9511499640607077

Epoch: 6| Step: 3
Training loss: 2.864073348454035
Validation loss: 2.9436455113728415

Epoch: 6| Step: 4
Training loss: 3.3686130984202007
Validation loss: 2.9426173344266053

Epoch: 6| Step: 5
Training loss: 3.2633977714413605
Validation loss: 2.940795276307159

Epoch: 6| Step: 6
Training loss: 2.8115254727111423
Validation loss: 2.940699175543977

Epoch: 6| Step: 7
Training loss: 3.662095312473
Validation loss: 2.9386668456860496

Epoch: 6| Step: 8
Training loss: 3.7728511125643593
Validation loss: 2.9406584091183103

Epoch: 6| Step: 9
Training loss: 3.887609454512244
Validation loss: 2.9410417909990616

Epoch: 6| Step: 10
Training loss: 2.9598183643183003
Validation loss: 2.937196849015872

Epoch: 6| Step: 11
Training loss: 3.3021614394391956
Validation loss: 2.9432547966914635

Epoch: 6| Step: 12
Training loss: 3.073866633761673
Validation loss: 2.943282228540725

Epoch: 6| Step: 13
Training loss: 3.1928281943062538
Validation loss: 2.9525331771303707

Epoch: 45| Step: 0
Training loss: 3.17038981426604
Validation loss: 2.9535914418024527

Epoch: 6| Step: 1
Training loss: 2.9590662375227215
Validation loss: 2.96964307217841

Epoch: 6| Step: 2
Training loss: 3.3260157532264407
Validation loss: 2.9978457649932477

Epoch: 6| Step: 3
Training loss: 3.490086548614703
Validation loss: 2.9435343502247724

Epoch: 6| Step: 4
Training loss: 2.7570532599262694
Validation loss: 2.9334936423511992

Epoch: 6| Step: 5
Training loss: 3.1751209806686616
Validation loss: 2.9308377278329245

Epoch: 6| Step: 6
Training loss: 2.7941779233495465
Validation loss: 2.9286282098383625

Epoch: 6| Step: 7
Training loss: 3.439888141942576
Validation loss: 2.9308194891441333

Epoch: 6| Step: 8
Training loss: 3.778976765957161
Validation loss: 2.929351720018954

Epoch: 6| Step: 9
Training loss: 2.7991527467612283
Validation loss: 2.9281871858436155

Epoch: 6| Step: 10
Training loss: 3.671995250274977
Validation loss: 2.927632101991866

Epoch: 6| Step: 11
Training loss: 3.1965202902918604
Validation loss: 2.9281579385990457

Epoch: 6| Step: 12
Training loss: 2.926539324145754
Validation loss: 2.926129207771222

Epoch: 6| Step: 13
Training loss: 3.6513105103918977
Validation loss: 2.9240812209258062

Epoch: 46| Step: 0
Training loss: 3.8308462007937285
Validation loss: 2.9241315800776064

Epoch: 6| Step: 1
Training loss: 3.3762077713620164
Validation loss: 2.922273775466821

Epoch: 6| Step: 2
Training loss: 2.799374960209275
Validation loss: 2.923209312501193

Epoch: 6| Step: 3
Training loss: 3.133806865162505
Validation loss: 2.921535830016114

Epoch: 6| Step: 4
Training loss: 3.504996139807215
Validation loss: 2.9215523163942256

Epoch: 6| Step: 5
Training loss: 3.4124863956166265
Validation loss: 2.921652973595191

Epoch: 6| Step: 6
Training loss: 3.648040684556799
Validation loss: 2.918245892377967

Epoch: 6| Step: 7
Training loss: 2.5052874916772705
Validation loss: 2.92090073704446

Epoch: 6| Step: 8
Training loss: 3.5036996633810893
Validation loss: 2.917548717487062

Epoch: 6| Step: 9
Training loss: 3.544680819972162
Validation loss: 2.917655276855834

Epoch: 6| Step: 10
Training loss: 2.5003824895086657
Validation loss: 2.9196394160877466

Epoch: 6| Step: 11
Training loss: 2.8340686704059697
Validation loss: 2.9189473501004213

Epoch: 6| Step: 12
Training loss: 2.4597030207624457
Validation loss: 2.9147168077326993

Epoch: 6| Step: 13
Training loss: 3.4587880643756677
Validation loss: 2.9257440847101535

Epoch: 47| Step: 0
Training loss: 3.444940317686133
Validation loss: 2.939158227962851

Epoch: 6| Step: 1
Training loss: 2.72374293178921
Validation loss: 2.943192679949912

Epoch: 6| Step: 2
Training loss: 3.3560752098558497
Validation loss: 2.9381155740541636

Epoch: 6| Step: 3
Training loss: 3.007463866006452
Validation loss: 2.9211408521834823

Epoch: 6| Step: 4
Training loss: 3.6460736150126354
Validation loss: 2.9125054491198

Epoch: 6| Step: 5
Training loss: 3.5721308045054943
Validation loss: 2.9125564432411744

Epoch: 6| Step: 6
Training loss: 3.2766889570479885
Validation loss: 2.9082330621631773

Epoch: 6| Step: 7
Training loss: 3.135176910324711
Validation loss: 2.907986123583924

Epoch: 6| Step: 8
Training loss: 2.5872580852848497
Validation loss: 2.9108709496801666

Epoch: 6| Step: 9
Training loss: 3.55844769141464
Validation loss: 2.93261095282862

Epoch: 6| Step: 10
Training loss: 3.1755377006280923
Validation loss: 2.9494092310812765

Epoch: 6| Step: 11
Training loss: 2.7294740188348796
Validation loss: 2.9269561106409796

Epoch: 6| Step: 12
Training loss: 3.315548196059449
Validation loss: 2.9180313360401846

Epoch: 6| Step: 13
Training loss: 3.5054095561447647
Validation loss: 2.91560094380932

Epoch: 48| Step: 0
Training loss: 3.579869673716955
Validation loss: 2.905216512710933

Epoch: 6| Step: 1
Training loss: 3.962579691473636
Validation loss: 2.9031241838382593

Epoch: 6| Step: 2
Training loss: 3.163475000916065
Validation loss: 2.901243968103286

Epoch: 6| Step: 3
Training loss: 3.424126150213821
Validation loss: 2.902402290126284

Epoch: 6| Step: 4
Training loss: 2.8189792176150754
Validation loss: 2.901896786912947

Epoch: 6| Step: 5
Training loss: 2.552449310427105
Validation loss: 2.9014172181232034

Epoch: 6| Step: 6
Training loss: 2.913577778364781
Validation loss: 2.8987566561573566

Epoch: 6| Step: 7
Training loss: 3.578534764976854
Validation loss: 2.9021621378094546

Epoch: 6| Step: 8
Training loss: 3.1994530448776635
Validation loss: 2.905705643014497

Epoch: 6| Step: 9
Training loss: 3.3265004379338685
Validation loss: 2.9010664457078614

Epoch: 6| Step: 10
Training loss: 2.438705732998683
Validation loss: 2.898242350044936

Epoch: 6| Step: 11
Training loss: 2.7678812597252493
Validation loss: 2.8982413151211035

Epoch: 6| Step: 12
Training loss: 3.3996585450095207
Validation loss: 2.8985709842430407

Epoch: 6| Step: 13
Training loss: 3.2468064096235034
Validation loss: 2.8999514939576505

Epoch: 49| Step: 0
Training loss: 3.795204705709528
Validation loss: 2.8995331926349945

Epoch: 6| Step: 1
Training loss: 2.25700865694954
Validation loss: 2.8993371473286014

Epoch: 6| Step: 2
Training loss: 2.9449329890608027
Validation loss: 2.901714222615687

Epoch: 6| Step: 3
Training loss: 3.5065630278362994
Validation loss: 2.897891622389572

Epoch: 6| Step: 4
Training loss: 3.411849013615847
Validation loss: 2.898912160146655

Epoch: 6| Step: 5
Training loss: 2.6145819148532214
Validation loss: 2.89750439268532

Epoch: 6| Step: 6
Training loss: 3.76189075999675
Validation loss: 2.8966855978479593

Epoch: 6| Step: 7
Training loss: 3.5045234876496805
Validation loss: 2.896166439614665

Epoch: 6| Step: 8
Training loss: 2.836555854913136
Validation loss: 2.8958926206232607

Epoch: 6| Step: 9
Training loss: 3.2157077671146435
Validation loss: 2.8934564489090167

Epoch: 6| Step: 10
Training loss: 3.5736459742133424
Validation loss: 2.8918403728876485

Epoch: 6| Step: 11
Training loss: 2.7625205509577864
Validation loss: 2.8921353860453007

Epoch: 6| Step: 12
Training loss: 3.287216429573568
Validation loss: 2.8890714994566222

Epoch: 6| Step: 13
Training loss: 2.328833964907846
Validation loss: 2.8904561080748357

Epoch: 50| Step: 0
Training loss: 3.7067467084882764
Validation loss: 2.8895217612732655

Epoch: 6| Step: 1
Training loss: 3.187279637517225
Validation loss: 2.8883213556424034

Epoch: 6| Step: 2
Training loss: 2.5928376213218582
Validation loss: 2.8887980010084213

Epoch: 6| Step: 3
Training loss: 3.839675107960618
Validation loss: 2.887295501119876

Epoch: 6| Step: 4
Training loss: 3.4560989760778393
Validation loss: 2.8876490711757534

Epoch: 6| Step: 5
Training loss: 3.5555284783868792
Validation loss: 2.8892539850724246

Epoch: 6| Step: 6
Training loss: 3.210127159761111
Validation loss: 2.886378820460719

Epoch: 6| Step: 7
Training loss: 3.203518429296648
Validation loss: 2.8860266182099705

Epoch: 6| Step: 8
Training loss: 2.2456855734754524
Validation loss: 2.8853460664346304

Epoch: 6| Step: 9
Training loss: 2.6389436504192147
Validation loss: 2.8840146652191754

Epoch: 6| Step: 10
Training loss: 2.74087423411404
Validation loss: 2.882157120606103

Epoch: 6| Step: 11
Training loss: 2.5911434818940857
Validation loss: 2.8824094044822033

Epoch: 6| Step: 12
Training loss: 3.1867625561523147
Validation loss: 2.882233393087633

Epoch: 6| Step: 13
Training loss: 4.214389157815251
Validation loss: 2.8825119755197184

Epoch: 51| Step: 0
Training loss: 3.722161787564148
Validation loss: 2.8798601054638486

Epoch: 6| Step: 1
Training loss: 2.965300312497596
Validation loss: 2.8791757748170386

Epoch: 6| Step: 2
Training loss: 3.8570707909850346
Validation loss: 2.8790149671254155

Epoch: 6| Step: 3
Training loss: 3.4479361511478976
Validation loss: 2.878799755970607

Epoch: 6| Step: 4
Training loss: 3.3208199864928587
Validation loss: 2.8765423139058033

Epoch: 6| Step: 5
Training loss: 3.1031600719671193
Validation loss: 2.8764121701249556

Epoch: 6| Step: 6
Training loss: 2.988261144233833
Validation loss: 2.8793370391849815

Epoch: 6| Step: 7
Training loss: 2.8407328603009736
Validation loss: 2.875595452884725

Epoch: 6| Step: 8
Training loss: 3.4484337056964005
Validation loss: 2.8744093656983196

Epoch: 6| Step: 9
Training loss: 3.2449210168192857
Validation loss: 2.874292846677543

Epoch: 6| Step: 10
Training loss: 3.460868886435411
Validation loss: 2.8763721699494162

Epoch: 6| Step: 11
Training loss: 2.4562639697116855
Validation loss: 2.881067263897739

Epoch: 6| Step: 12
Training loss: 2.4413304675738385
Validation loss: 2.8861727166965467

Epoch: 6| Step: 13
Training loss: 2.462510928986594
Validation loss: 2.896186331404629

Epoch: 52| Step: 0
Training loss: 3.2331174902955024
Validation loss: 2.8910110007491947

Epoch: 6| Step: 1
Training loss: 2.9205480816290175
Validation loss: 2.884438530428231

Epoch: 6| Step: 2
Training loss: 2.7353925283102507
Validation loss: 2.8794373852296533

Epoch: 6| Step: 3
Training loss: 2.8977354284161527
Validation loss: 2.8692880184112606

Epoch: 6| Step: 4
Training loss: 3.208648236826597
Validation loss: 2.8678932525067102

Epoch: 6| Step: 5
Training loss: 2.7393693925024243
Validation loss: 2.869765620331828

Epoch: 6| Step: 6
Training loss: 3.244436637514845
Validation loss: 2.870311872074605

Epoch: 6| Step: 7
Training loss: 3.2619276516654545
Validation loss: 2.8698309959758563

Epoch: 6| Step: 8
Training loss: 3.1183182044777666
Validation loss: 2.867552033622167

Epoch: 6| Step: 9
Training loss: 4.120713752474683
Validation loss: 2.8683553939512207

Epoch: 6| Step: 10
Training loss: 3.1970439966901396
Validation loss: 2.8693626870350144

Epoch: 6| Step: 11
Training loss: 3.313785519461714
Validation loss: 2.8674399270469344

Epoch: 6| Step: 12
Training loss: 3.1906193448277196
Validation loss: 2.8675266505755057

Epoch: 6| Step: 13
Training loss: 2.657569647205607
Validation loss: 2.8677357536208774

Epoch: 53| Step: 0
Training loss: 3.566953853085159
Validation loss: 2.8653928702796887

Epoch: 6| Step: 1
Training loss: 3.5423265777329154
Validation loss: 2.8647677854217526

Epoch: 6| Step: 2
Training loss: 2.9878987385393665
Validation loss: 2.8632104985200666

Epoch: 6| Step: 3
Training loss: 3.6765875261446372
Validation loss: 2.8628199478994363

Epoch: 6| Step: 4
Training loss: 3.6614121732158007
Validation loss: 2.8644798136303193

Epoch: 6| Step: 5
Training loss: 3.598038743154555
Validation loss: 2.861379309046682

Epoch: 6| Step: 6
Training loss: 2.360872311452673
Validation loss: 2.861464354537347

Epoch: 6| Step: 7
Training loss: 2.7924930620918387
Validation loss: 2.861963564610483

Epoch: 6| Step: 8
Training loss: 3.4195942005536213
Validation loss: 2.863934570113468

Epoch: 6| Step: 9
Training loss: 2.536961833842699
Validation loss: 2.8629567028217657

Epoch: 6| Step: 10
Training loss: 3.3424383425107975
Validation loss: 2.860379221186627

Epoch: 6| Step: 11
Training loss: 3.045456150007925
Validation loss: 2.8689074259051734

Epoch: 6| Step: 12
Training loss: 2.3151030452855714
Validation loss: 2.8627152169608148

Epoch: 6| Step: 13
Training loss: 2.8881533391404592
Validation loss: 2.8603448028412317

Epoch: 54| Step: 0
Training loss: 2.166814383337525
Validation loss: 2.8611259431856424

Epoch: 6| Step: 1
Training loss: 3.4807317871984997
Validation loss: 2.8577110029803032

Epoch: 6| Step: 2
Training loss: 3.4940779857874036
Validation loss: 2.857053692549988

Epoch: 6| Step: 3
Training loss: 2.817548586300391
Validation loss: 2.856259974113134

Epoch: 6| Step: 4
Training loss: 3.0638477707339584
Validation loss: 2.8545180483862307

Epoch: 6| Step: 5
Training loss: 3.22304270883563
Validation loss: 2.854218189614885

Epoch: 6| Step: 6
Training loss: 3.2446553225622354
Validation loss: 2.852348779104919

Epoch: 6| Step: 7
Training loss: 3.2791953783987795
Validation loss: 2.8491659839942924

Epoch: 6| Step: 8
Training loss: 2.81872192504164
Validation loss: 2.850345678186072

Epoch: 6| Step: 9
Training loss: 3.004252122429892
Validation loss: 2.8514112665335616

Epoch: 6| Step: 10
Training loss: 3.8160543914053506
Validation loss: 2.854960932350738

Epoch: 6| Step: 11
Training loss: 2.8575653853657705
Validation loss: 2.861693756184377

Epoch: 6| Step: 12
Training loss: 3.4768965999927315
Validation loss: 2.8752405325492023

Epoch: 6| Step: 13
Training loss: 2.976460773001272
Validation loss: 2.8687138256430544

Epoch: 55| Step: 0
Training loss: 3.2728329193518517
Validation loss: 2.85310009227994

Epoch: 6| Step: 1
Training loss: 2.405713306371142
Validation loss: 2.858547005412734

Epoch: 6| Step: 2
Training loss: 2.448886295126072
Validation loss: 2.849503813041835

Epoch: 6| Step: 3
Training loss: 3.80208014222451
Validation loss: 2.855460443539753

Epoch: 6| Step: 4
Training loss: 2.4487142575641108
Validation loss: 2.857398753510416

Epoch: 6| Step: 5
Training loss: 3.686302766574258
Validation loss: 2.8529436961255623

Epoch: 6| Step: 6
Training loss: 3.644219846188415
Validation loss: 2.8434299999782913

Epoch: 6| Step: 7
Training loss: 2.8697240767276377
Validation loss: 2.844617829081066

Epoch: 6| Step: 8
Training loss: 3.476976142878253
Validation loss: 2.845688008172196

Epoch: 6| Step: 9
Training loss: 2.6671233282878237
Validation loss: 2.846069244819454

Epoch: 6| Step: 10
Training loss: 3.289047422397151
Validation loss: 2.844638659017678

Epoch: 6| Step: 11
Training loss: 3.3417540680703666
Validation loss: 2.844683564572528

Epoch: 6| Step: 12
Training loss: 3.271266317359655
Validation loss: 2.8472723716269743

Epoch: 6| Step: 13
Training loss: 2.8322743699524335
Validation loss: 2.8424596860052516

Epoch: 56| Step: 0
Training loss: 3.2529431734747467
Validation loss: 2.8443451594084266

Epoch: 6| Step: 1
Training loss: 3.2237712618898406
Validation loss: 2.8467708680760566

Epoch: 6| Step: 2
Training loss: 2.9694346391376993
Validation loss: 2.8432404265425095

Epoch: 6| Step: 3
Training loss: 2.924357782269588
Validation loss: 2.844457138832839

Epoch: 6| Step: 4
Training loss: 3.1878403126677823
Validation loss: 2.844250582332559

Epoch: 6| Step: 5
Training loss: 3.530713065857656
Validation loss: 2.8434254009055313

Epoch: 6| Step: 6
Training loss: 3.030026218313464
Validation loss: 2.840287744225621

Epoch: 6| Step: 7
Training loss: 3.417979213153628
Validation loss: 2.8406163786276

Epoch: 6| Step: 8
Training loss: 2.952722269682654
Validation loss: 2.838724790914637

Epoch: 6| Step: 9
Training loss: 3.1090626008561615
Validation loss: 2.837304431109242

Epoch: 6| Step: 10
Training loss: 2.6645952961652903
Validation loss: 2.8350492640298697

Epoch: 6| Step: 11
Training loss: 3.447597723247353
Validation loss: 2.833744191801139

Epoch: 6| Step: 12
Training loss: 3.4321363739093074
Validation loss: 2.8335869408401524

Epoch: 6| Step: 13
Training loss: 2.5238814302998955
Validation loss: 2.8306564326389556

Epoch: 57| Step: 0
Training loss: 2.6513008235824365
Validation loss: 2.8318464086039277

Epoch: 6| Step: 1
Training loss: 2.7992347693404134
Validation loss: 2.830980743547412

Epoch: 6| Step: 2
Training loss: 2.9722645084149892
Validation loss: 2.833861752938533

Epoch: 6| Step: 3
Training loss: 3.409484167825012
Validation loss: 2.8317430190419275

Epoch: 6| Step: 4
Training loss: 3.37635903016817
Validation loss: 2.8475880119191337

Epoch: 6| Step: 5
Training loss: 3.808659980393687
Validation loss: 2.8448609466599173

Epoch: 6| Step: 6
Training loss: 2.6184439760267586
Validation loss: 2.842657599488702

Epoch: 6| Step: 7
Training loss: 2.8691215124980336
Validation loss: 2.8436094454639163

Epoch: 6| Step: 8
Training loss: 3.251908108969583
Validation loss: 2.848215436006863

Epoch: 6| Step: 9
Training loss: 3.455461220988576
Validation loss: 2.838839251493124

Epoch: 6| Step: 10
Training loss: 3.0813600222615976
Validation loss: 2.824803214225488

Epoch: 6| Step: 11
Training loss: 2.4893181525273045
Validation loss: 2.8264669723819584

Epoch: 6| Step: 12
Training loss: 2.9957518699580947
Validation loss: 2.826400202781367

Epoch: 6| Step: 13
Training loss: 4.085328970354836
Validation loss: 2.8294383197066355

Epoch: 58| Step: 0
Training loss: 3.726309649768391
Validation loss: 2.842184969215683

Epoch: 6| Step: 1
Training loss: 2.6765316544429485
Validation loss: 2.8484042112206795

Epoch: 6| Step: 2
Training loss: 3.4591671654659444
Validation loss: 2.8488187235858007

Epoch: 6| Step: 3
Training loss: 3.480750829224069
Validation loss: 2.826721541162691

Epoch: 6| Step: 4
Training loss: 3.4312826631030164
Validation loss: 2.8242041118364276

Epoch: 6| Step: 5
Training loss: 3.2703569069301985
Validation loss: 2.821703179848478

Epoch: 6| Step: 6
Training loss: 3.643390571049232
Validation loss: 2.8269086928207265

Epoch: 6| Step: 7
Training loss: 3.1651945373144774
Validation loss: 2.8459254339937057

Epoch: 6| Step: 8
Training loss: 2.7848065385449674
Validation loss: 2.9312588821781373

Epoch: 6| Step: 9
Training loss: 3.38314641489425
Validation loss: 3.01060174327046

Epoch: 6| Step: 10
Training loss: 3.1375586880366115
Validation loss: 2.979053226384739

Epoch: 6| Step: 11
Training loss: 2.615398467359497
Validation loss: 2.8247137105589486

Epoch: 6| Step: 12
Training loss: 2.339647491834478
Validation loss: 2.814662212503054

Epoch: 6| Step: 13
Training loss: 2.2973442376834248
Validation loss: 2.812567867066378

Epoch: 59| Step: 0
Training loss: 2.4420598734421057
Validation loss: 2.8135319210172747

Epoch: 6| Step: 1
Training loss: 3.0008262450150287
Validation loss: 2.8173591877087256

Epoch: 6| Step: 2
Training loss: 3.1944361000136334
Validation loss: 2.8418140061994035

Epoch: 6| Step: 3
Training loss: 3.451997736942261
Validation loss: 2.8504461805254917

Epoch: 6| Step: 4
Training loss: 3.5854092875878876
Validation loss: 2.8313477430463307

Epoch: 6| Step: 5
Training loss: 3.5175268835627844
Validation loss: 2.81936893104047

Epoch: 6| Step: 6
Training loss: 2.837428518058697
Validation loss: 2.81116260009241

Epoch: 6| Step: 7
Training loss: 2.5427971707308963
Validation loss: 2.8127890052110707

Epoch: 6| Step: 8
Training loss: 2.733277193128706
Validation loss: 2.8155974565063615

Epoch: 6| Step: 9
Training loss: 3.70152202952826
Validation loss: 2.8174097483239096

Epoch: 6| Step: 10
Training loss: 3.089084845516596
Validation loss: 2.8175905197837507

Epoch: 6| Step: 11
Training loss: 3.2516123366855925
Validation loss: 2.8242841569556747

Epoch: 6| Step: 12
Training loss: 3.201620055426484
Validation loss: 2.8242741040116397

Epoch: 6| Step: 13
Training loss: 2.755969244742457
Validation loss: 2.8150000668735897

Epoch: 60| Step: 0
Training loss: 3.4280626623420054
Validation loss: 2.810408188275828

Epoch: 6| Step: 1
Training loss: 2.845937202162898
Validation loss: 2.809685039215598

Epoch: 6| Step: 2
Training loss: 3.0055301875158147
Validation loss: 2.809120466677425

Epoch: 6| Step: 3
Training loss: 3.150046569237779
Validation loss: 2.812765493133286

Epoch: 6| Step: 4
Training loss: 3.249540149727709
Validation loss: 2.8184500100606353

Epoch: 6| Step: 5
Training loss: 3.3784005729358646
Validation loss: 2.8267957053572865

Epoch: 6| Step: 6
Training loss: 3.4434769426983274
Validation loss: 2.8373675314865823

Epoch: 6| Step: 7
Training loss: 3.3296871906711787
Validation loss: 2.8472972185362475

Epoch: 6| Step: 8
Training loss: 3.01526003195458
Validation loss: 2.8214270762647438

Epoch: 6| Step: 9
Training loss: 2.738378852269333
Validation loss: 2.815869569558547

Epoch: 6| Step: 10
Training loss: 3.212224920347859
Validation loss: 2.813482905358009

Epoch: 6| Step: 11
Training loss: 3.2916787223756105
Validation loss: 2.810656883622979

Epoch: 6| Step: 12
Training loss: 2.381755156513749
Validation loss: 2.804292810393

Epoch: 6| Step: 13
Training loss: 2.858172387873711
Validation loss: 2.8068075821811074

Epoch: 61| Step: 0
Training loss: 3.1649164248455794
Validation loss: 2.8033231630363113

Epoch: 6| Step: 1
Training loss: 2.783259662254706
Validation loss: 2.8020621132465533

Epoch: 6| Step: 2
Training loss: 3.099143980647037
Validation loss: 2.7972828649065367

Epoch: 6| Step: 3
Training loss: 3.2826516200520532
Validation loss: 2.79818524589595

Epoch: 6| Step: 4
Training loss: 3.30960762856102
Validation loss: 2.798462262949311

Epoch: 6| Step: 5
Training loss: 3.1621033431072796
Validation loss: 2.8002520922741185

Epoch: 6| Step: 6
Training loss: 2.745765460212124
Validation loss: 2.8012084131760195

Epoch: 6| Step: 7
Training loss: 2.0363295206240424
Validation loss: 2.802425907186664

Epoch: 6| Step: 8
Training loss: 3.016908362666255
Validation loss: 2.798129464652569

Epoch: 6| Step: 9
Training loss: 3.124511527985324
Validation loss: 2.799277914968829

Epoch: 6| Step: 10
Training loss: 3.3861453793044913
Validation loss: 2.7958753509638266

Epoch: 6| Step: 11
Training loss: 3.234882701887458
Validation loss: 2.797230718809223

Epoch: 6| Step: 12
Training loss: 3.9105657311658315
Validation loss: 2.7956781457747235

Epoch: 6| Step: 13
Training loss: 2.8067065438936
Validation loss: 2.7942072407893654

Epoch: 62| Step: 0
Training loss: 3.0914247039406084
Validation loss: 2.7940629388384473

Epoch: 6| Step: 1
Training loss: 3.0457902591301824
Validation loss: 2.7913524877606655

Epoch: 6| Step: 2
Training loss: 2.716367620457326
Validation loss: 2.790671167555707

Epoch: 6| Step: 3
Training loss: 3.6931383378463774
Validation loss: 2.791518650223597

Epoch: 6| Step: 4
Training loss: 3.1053575795746107
Validation loss: 2.793375645267444

Epoch: 6| Step: 5
Training loss: 3.0097519999894393
Validation loss: 2.7875225746980363

Epoch: 6| Step: 6
Training loss: 3.212057915931444
Validation loss: 2.789061671821874

Epoch: 6| Step: 7
Training loss: 2.4865176000564775
Validation loss: 2.79260633672915

Epoch: 6| Step: 8
Training loss: 3.5188213822220233
Validation loss: 2.7913359349847715

Epoch: 6| Step: 9
Training loss: 2.4610889206577893
Validation loss: 2.793849762458141

Epoch: 6| Step: 10
Training loss: 3.6726513630295474
Validation loss: 2.81181500569202

Epoch: 6| Step: 11
Training loss: 3.256399749416974
Validation loss: 2.7895262613469933

Epoch: 6| Step: 12
Training loss: 3.1987183567284236
Validation loss: 2.7865462131268517

Epoch: 6| Step: 13
Training loss: 2.3962891739343033
Validation loss: 2.786371983288567

Epoch: 63| Step: 0
Training loss: 3.2815322028013774
Validation loss: 2.785811884019774

Epoch: 6| Step: 1
Training loss: 2.991731853005153
Validation loss: 2.7871824519495147

Epoch: 6| Step: 2
Training loss: 3.5546398788448212
Validation loss: 2.787208119672167

Epoch: 6| Step: 3
Training loss: 2.6034464844825784
Validation loss: 2.785752644200225

Epoch: 6| Step: 4
Training loss: 3.0332537448488623
Validation loss: 2.7871783864460653

Epoch: 6| Step: 5
Training loss: 2.898929358851696
Validation loss: 2.7864705820459386

Epoch: 6| Step: 6
Training loss: 2.811944101285383
Validation loss: 2.786253668822985

Epoch: 6| Step: 7
Training loss: 2.9903498252941443
Validation loss: 2.785006582867589

Epoch: 6| Step: 8
Training loss: 2.807182031494712
Validation loss: 2.785061127456185

Epoch: 6| Step: 9
Training loss: 3.232125352241546
Validation loss: 2.7835798636149467

Epoch: 6| Step: 10
Training loss: 3.1944234119404737
Validation loss: 2.7841710274706983

Epoch: 6| Step: 11
Training loss: 3.788229561718808
Validation loss: 2.7844890368340525

Epoch: 6| Step: 12
Training loss: 2.598999777382536
Validation loss: 2.781902786453658

Epoch: 6| Step: 13
Training loss: 3.681840983233506
Validation loss: 2.782849422389371

Epoch: 64| Step: 0
Training loss: 3.463241464707752
Validation loss: 2.7808166568199555

Epoch: 6| Step: 1
Training loss: 3.4638995375304282
Validation loss: 2.781766676879746

Epoch: 6| Step: 2
Training loss: 3.1887177777727804
Validation loss: 2.7808587948005647

Epoch: 6| Step: 3
Training loss: 3.707579046681289
Validation loss: 2.778729268814119

Epoch: 6| Step: 4
Training loss: 2.8379702678303147
Validation loss: 2.7776436767886463

Epoch: 6| Step: 5
Training loss: 2.729511316877287
Validation loss: 2.777372493779479

Epoch: 6| Step: 6
Training loss: 2.7149578262622365
Validation loss: 2.778353167967369

Epoch: 6| Step: 7
Training loss: 2.928268536578306
Validation loss: 2.779263911696992

Epoch: 6| Step: 8
Training loss: 3.3346999863591082
Validation loss: 2.7783460334910637

Epoch: 6| Step: 9
Training loss: 3.209884285192943
Validation loss: 2.7772535637686526

Epoch: 6| Step: 10
Training loss: 3.117906071724215
Validation loss: 2.7754201593685326

Epoch: 6| Step: 11
Training loss: 2.7720957774560473
Validation loss: 2.7756421106132443

Epoch: 6| Step: 12
Training loss: 2.6641110055037114
Validation loss: 2.7743974169813774

Epoch: 6| Step: 13
Training loss: 3.0023571926335153
Validation loss: 2.774964596442046

Epoch: 65| Step: 0
Training loss: 2.9238628622372853
Validation loss: 2.7724511280092954

Epoch: 6| Step: 1
Training loss: 3.0081823344565444
Validation loss: 2.773847406331761

Epoch: 6| Step: 2
Training loss: 3.421933526361652
Validation loss: 2.7720560023472585

Epoch: 6| Step: 3
Training loss: 2.618560339858336
Validation loss: 2.7686400184981053

Epoch: 6| Step: 4
Training loss: 3.08985748480868
Validation loss: 2.771559369799873

Epoch: 6| Step: 5
Training loss: 2.7406299656265145
Validation loss: 2.767390340379973

Epoch: 6| Step: 6
Training loss: 2.789335178755131
Validation loss: 2.7763084137706606

Epoch: 6| Step: 7
Training loss: 3.6444710647830663
Validation loss: 2.7783149154446014

Epoch: 6| Step: 8
Training loss: 3.166084302925685
Validation loss: 2.7923098748981223

Epoch: 6| Step: 9
Training loss: 2.730191501845478
Validation loss: 2.771778522508733

Epoch: 6| Step: 10
Training loss: 2.7945022321287047
Validation loss: 2.766115864710693

Epoch: 6| Step: 11
Training loss: 3.3650369879629682
Validation loss: 2.7633247930077425

Epoch: 6| Step: 12
Training loss: 3.1794135048276084
Validation loss: 2.7647779736636404

Epoch: 6| Step: 13
Training loss: 3.914848203091286
Validation loss: 2.766019125320662

Epoch: 66| Step: 0
Training loss: 2.885846781892547
Validation loss: 2.7670576536386586

Epoch: 6| Step: 1
Training loss: 3.552181626616477
Validation loss: 2.7654529339797707

Epoch: 6| Step: 2
Training loss: 3.1632279413940925
Validation loss: 2.7662404759410846

Epoch: 6| Step: 3
Training loss: 2.803608721414771
Validation loss: 2.7661942154091124

Epoch: 6| Step: 4
Training loss: 2.86257088919071
Validation loss: 2.768540149494363

Epoch: 6| Step: 5
Training loss: 2.4292441205806155
Validation loss: 2.775629971439241

Epoch: 6| Step: 6
Training loss: 2.90605507473828
Validation loss: 2.7763335578137527

Epoch: 6| Step: 7
Training loss: 2.8352914289685667
Validation loss: 2.7722710589481965

Epoch: 6| Step: 8
Training loss: 3.4201884533452955
Validation loss: 2.7673985758395703

Epoch: 6| Step: 9
Training loss: 2.368517914124271
Validation loss: 2.7631753851589154

Epoch: 6| Step: 10
Training loss: 3.0058276476558183
Validation loss: 2.761923282744461

Epoch: 6| Step: 11
Training loss: 3.2227198738984617
Validation loss: 2.759871131328128

Epoch: 6| Step: 12
Training loss: 3.8129955032286103
Validation loss: 2.7600560800039613

Epoch: 6| Step: 13
Training loss: 3.895213535121264
Validation loss: 2.7609264185597224

Epoch: 67| Step: 0
Training loss: 3.324011180955281
Validation loss: 2.760593417161163

Epoch: 6| Step: 1
Training loss: 3.435384203262197
Validation loss: 2.7609384422449903

Epoch: 6| Step: 2
Training loss: 3.005341860197484
Validation loss: 2.7703635929162087

Epoch: 6| Step: 3
Training loss: 2.961768041395253
Validation loss: 2.785242571771123

Epoch: 6| Step: 4
Training loss: 3.2307125862102413
Validation loss: 2.7914517784766453

Epoch: 6| Step: 5
Training loss: 3.4576252744849785
Validation loss: 2.795429166987201

Epoch: 6| Step: 6
Training loss: 3.288522417755068
Validation loss: 2.77423556011743

Epoch: 6| Step: 7
Training loss: 3.019946860546944
Validation loss: 2.7609808724638336

Epoch: 6| Step: 8
Training loss: 2.8131670690584762
Validation loss: 2.755387516004082

Epoch: 6| Step: 9
Training loss: 2.4969644236873703
Validation loss: 2.7557877605652625

Epoch: 6| Step: 10
Training loss: 3.4912812766078556
Validation loss: 2.759034272031138

Epoch: 6| Step: 11
Training loss: 2.9595998998822144
Validation loss: 2.764197686020357

Epoch: 6| Step: 12
Training loss: 2.6798447988180123
Validation loss: 2.7762414074312076

Epoch: 6| Step: 13
Training loss: 2.5015793579982213
Validation loss: 2.7957538817244143

Epoch: 68| Step: 0
Training loss: 3.3209250928453713
Validation loss: 2.7876650972833126

Epoch: 6| Step: 1
Training loss: 2.6998714204477747
Validation loss: 2.784102913858801

Epoch: 6| Step: 2
Training loss: 3.622792328069515
Validation loss: 2.766508659830353

Epoch: 6| Step: 3
Training loss: 3.143592002341439
Validation loss: 2.762261548541781

Epoch: 6| Step: 4
Training loss: 2.7000513848960543
Validation loss: 2.7549389008164877

Epoch: 6| Step: 5
Training loss: 3.097159616458173
Validation loss: 2.7532021197111654

Epoch: 6| Step: 6
Training loss: 3.553144384111524
Validation loss: 2.751109342287852

Epoch: 6| Step: 7
Training loss: 2.620601056292284
Validation loss: 2.749007154882163

Epoch: 6| Step: 8
Training loss: 3.5654958877122502
Validation loss: 2.7505236320115456

Epoch: 6| Step: 9
Training loss: 2.405994847629069
Validation loss: 2.7854077871738863

Epoch: 6| Step: 10
Training loss: 2.730263720060592
Validation loss: 2.8118639811347292

Epoch: 6| Step: 11
Training loss: 2.580092910158242
Validation loss: 2.878471523905808

Epoch: 6| Step: 12
Training loss: 3.297055352507379
Validation loss: 2.932025775333959

Epoch: 6| Step: 13
Training loss: 3.9590686851222503
Validation loss: 2.8283784587664353

Epoch: 69| Step: 0
Training loss: 2.8090654382956615
Validation loss: 2.7533765453448735

Epoch: 6| Step: 1
Training loss: 2.986788906876943
Validation loss: 2.748050837937338

Epoch: 6| Step: 2
Training loss: 2.660749327299934
Validation loss: 2.7505428695694634

Epoch: 6| Step: 3
Training loss: 3.135450512945216
Validation loss: 2.759946153738789

Epoch: 6| Step: 4
Training loss: 3.136287445781384
Validation loss: 2.76751333057461

Epoch: 6| Step: 5
Training loss: 2.915109891046971
Validation loss: 2.7683532265363153

Epoch: 6| Step: 6
Training loss: 3.69749208976926
Validation loss: 2.7626675165727566

Epoch: 6| Step: 7
Training loss: 2.690605409841076
Validation loss: 2.7611789049552287

Epoch: 6| Step: 8
Training loss: 3.302071909278017
Validation loss: 2.758441951635397

Epoch: 6| Step: 9
Training loss: 3.5043915037280535
Validation loss: 2.7501947682637087

Epoch: 6| Step: 10
Training loss: 3.306109039243884
Validation loss: 2.749286134790143

Epoch: 6| Step: 11
Training loss: 3.0913326182356022
Validation loss: 2.7477959790198714

Epoch: 6| Step: 12
Training loss: 2.834639491281427
Validation loss: 2.7457173178637677

Epoch: 6| Step: 13
Training loss: 2.912974791239947
Validation loss: 2.7442114578451564

Epoch: 70| Step: 0
Training loss: 2.6477053370108505
Validation loss: 2.741275603594136

Epoch: 6| Step: 1
Training loss: 3.097710742447085
Validation loss: 2.743564739107307

Epoch: 6| Step: 2
Training loss: 2.909584347643114
Validation loss: 2.7411076141022575

Epoch: 6| Step: 3
Training loss: 2.8777376492066007
Validation loss: 2.7435724770250105

Epoch: 6| Step: 4
Training loss: 2.639448998778131
Validation loss: 2.744429262457566

Epoch: 6| Step: 5
Training loss: 2.8179969475257862
Validation loss: 2.744347728927492

Epoch: 6| Step: 6
Training loss: 3.3807465409391853
Validation loss: 2.75085319547535

Epoch: 6| Step: 7
Training loss: 2.7877939796238795
Validation loss: 2.769896548213947

Epoch: 6| Step: 8
Training loss: 3.401621482383309
Validation loss: 2.797136010549459

Epoch: 6| Step: 9
Training loss: 3.378244324163828
Validation loss: 2.799361972440094

Epoch: 6| Step: 10
Training loss: 2.9539664548132754
Validation loss: 2.7426850233026876

Epoch: 6| Step: 11
Training loss: 3.171770967929123
Validation loss: 2.7359125823794748

Epoch: 6| Step: 12
Training loss: 3.401817727841189
Validation loss: 2.7378043219811583

Epoch: 6| Step: 13
Training loss: 3.425304070778961
Validation loss: 2.742193526287181

Epoch: 71| Step: 0
Training loss: 3.060166384592773
Validation loss: 2.7467283315836966

Epoch: 6| Step: 1
Training loss: 3.7187010176822675
Validation loss: 2.7799868248271498

Epoch: 6| Step: 2
Training loss: 3.0680581861048846
Validation loss: 2.7588618915980483

Epoch: 6| Step: 3
Training loss: 3.57404637989419
Validation loss: 2.7471786729681256

Epoch: 6| Step: 4
Training loss: 3.1227637872987843
Validation loss: 2.7415305178790286

Epoch: 6| Step: 5
Training loss: 3.01113383232575
Validation loss: 2.740130612474602

Epoch: 6| Step: 6
Training loss: 2.5559232097188467
Validation loss: 2.7358620411585837

Epoch: 6| Step: 7
Training loss: 2.647375203218042
Validation loss: 2.733677480773416

Epoch: 6| Step: 8
Training loss: 3.3848453606988795
Validation loss: 2.731596582561993

Epoch: 6| Step: 9
Training loss: 3.3558096484919435
Validation loss: 2.7272095064627213

Epoch: 6| Step: 10
Training loss: 2.611394591758815
Validation loss: 2.7502417043328453

Epoch: 6| Step: 11
Training loss: 2.780167787003
Validation loss: 2.8014423188998077

Epoch: 6| Step: 12
Training loss: 2.1810535812477605
Validation loss: 2.8312316322396383

Epoch: 6| Step: 13
Training loss: 4.223595443295668
Validation loss: 2.93060010602619

Epoch: 72| Step: 0
Training loss: 2.7808822217223277
Validation loss: 2.858091853094913

Epoch: 6| Step: 1
Training loss: 3.0780837932481364
Validation loss: 2.811339735389788

Epoch: 6| Step: 2
Training loss: 2.944129767087249
Validation loss: 2.793735986735794

Epoch: 6| Step: 3
Training loss: 3.0638153988080994
Validation loss: 2.7928448585977943

Epoch: 6| Step: 4
Training loss: 3.1488595684352254
Validation loss: 2.7929919922780417

Epoch: 6| Step: 5
Training loss: 3.5669894122925605
Validation loss: 2.7844883233021545

Epoch: 6| Step: 6
Training loss: 2.9757365685331045
Validation loss: 2.778712962829206

Epoch: 6| Step: 7
Training loss: 2.9163518099911525
Validation loss: 2.7666977755975393

Epoch: 6| Step: 8
Training loss: 2.1700578950814586
Validation loss: 2.773464933794385

Epoch: 6| Step: 9
Training loss: 3.8346658684946786
Validation loss: 2.786621918513544

Epoch: 6| Step: 10
Training loss: 2.9441738204228503
Validation loss: 2.796836119011632

Epoch: 6| Step: 11
Training loss: 3.6009709002657253
Validation loss: 2.8006688314226413

Epoch: 6| Step: 12
Training loss: 3.4613871745118314
Validation loss: 2.8021437890073817

Epoch: 6| Step: 13
Training loss: 2.3217362168577518
Validation loss: 2.7972369234557464

Epoch: 73| Step: 0
Training loss: 2.5972176776739695
Validation loss: 2.788131787912084

Epoch: 6| Step: 1
Training loss: 3.01288697855672
Validation loss: 2.789775125529269

Epoch: 6| Step: 2
Training loss: 2.630217861246408
Validation loss: 2.787262669926191

Epoch: 6| Step: 3
Training loss: 2.8863340129164974
Validation loss: 2.7905568598530195

Epoch: 6| Step: 4
Training loss: 3.170216695316532
Validation loss: 2.7937994040358833

Epoch: 6| Step: 5
Training loss: 3.130758244623704
Validation loss: 2.8037631953209474

Epoch: 6| Step: 6
Training loss: 3.4606153626709935
Validation loss: 2.802351983589151

Epoch: 6| Step: 7
Training loss: 3.414627133255911
Validation loss: 2.7842840532371227

Epoch: 6| Step: 8
Training loss: 2.5066201295827697
Validation loss: 2.7765059956751634

Epoch: 6| Step: 9
Training loss: 3.3815412357156336
Validation loss: 2.776401082708973

Epoch: 6| Step: 10
Training loss: 3.3089174294705077
Validation loss: 2.7741307294777386

Epoch: 6| Step: 11
Training loss: 3.122232661412693
Validation loss: 2.7751748438736956

Epoch: 6| Step: 12
Training loss: 3.6051000073829327
Validation loss: 2.773500889688203

Epoch: 6| Step: 13
Training loss: 2.6349974488566317
Validation loss: 2.7692211490156278

Epoch: 74| Step: 0
Training loss: 2.1908487028867216
Validation loss: 2.770441606026584

Epoch: 6| Step: 1
Training loss: 2.8024790790467775
Validation loss: 2.77914317205162

Epoch: 6| Step: 2
Training loss: 3.250332448535223
Validation loss: 2.778310494631112

Epoch: 6| Step: 3
Training loss: 2.221361799029483
Validation loss: 2.7407925349650832

Epoch: 6| Step: 4
Training loss: 4.082589114093129
Validation loss: 2.7284811715663744

Epoch: 6| Step: 5
Training loss: 3.1801142675634697
Validation loss: 2.715816043884727

Epoch: 6| Step: 6
Training loss: 2.877494724775926
Validation loss: 2.715669269102523

Epoch: 6| Step: 7
Training loss: 3.260174012015777
Validation loss: 2.7164644151576867

Epoch: 6| Step: 8
Training loss: 3.5629938686766693
Validation loss: 2.7170547350358887

Epoch: 6| Step: 9
Training loss: 2.8166169446209453
Validation loss: 2.715969820245849

Epoch: 6| Step: 10
Training loss: 2.888673690785011
Validation loss: 2.714813008919687

Epoch: 6| Step: 11
Training loss: 2.5343616339428676
Validation loss: 2.7143758518587258

Epoch: 6| Step: 12
Training loss: 3.497437492722769
Validation loss: 2.7135694002156856

Epoch: 6| Step: 13
Training loss: 3.0757779695717677
Validation loss: 2.7136975570478987

Epoch: 75| Step: 0
Training loss: 2.865422758164633
Validation loss: 2.7118803699561442

Epoch: 6| Step: 1
Training loss: 3.183215234639578
Validation loss: 2.710043963433787

Epoch: 6| Step: 2
Training loss: 2.9429551462740573
Validation loss: 2.708955725123787

Epoch: 6| Step: 3
Training loss: 3.004251170105225
Validation loss: 2.7081380055860658

Epoch: 6| Step: 4
Training loss: 2.883020739800636
Validation loss: 2.7065850928257156

Epoch: 6| Step: 5
Training loss: 2.992288692346908
Validation loss: 2.7046330399546057

Epoch: 6| Step: 6
Training loss: 3.276464987828694
Validation loss: 2.7043881712888482

Epoch: 6| Step: 7
Training loss: 2.6906955262266217
Validation loss: 2.705864912745891

Epoch: 6| Step: 8
Training loss: 3.3853569768876537
Validation loss: 2.706429718536519

Epoch: 6| Step: 9
Training loss: 2.621199172240717
Validation loss: 2.7068550407531173

Epoch: 6| Step: 10
Training loss: 3.3302593998498202
Validation loss: 2.706836876415545

Epoch: 6| Step: 11
Training loss: 3.3728202562570786
Validation loss: 2.7115160967767946

Epoch: 6| Step: 12
Training loss: 2.6433874724890245
Validation loss: 2.7093908953910955

Epoch: 6| Step: 13
Training loss: 3.523045012611771
Validation loss: 2.7033157020554186

Epoch: 76| Step: 0
Training loss: 2.842129423734057
Validation loss: 2.700236959780976

Epoch: 6| Step: 1
Training loss: 2.913519514697716
Validation loss: 2.7028948455728816

Epoch: 6| Step: 2
Training loss: 3.148285589978599
Validation loss: 2.7018100438241888

Epoch: 6| Step: 3
Training loss: 3.1433530886835985
Validation loss: 2.7007461219556825

Epoch: 6| Step: 4
Training loss: 3.0673919842767208
Validation loss: 2.7023493412453776

Epoch: 6| Step: 5
Training loss: 3.4687450512000173
Validation loss: 2.702383609873084

Epoch: 6| Step: 6
Training loss: 3.1773231957781203
Validation loss: 2.701104844119156

Epoch: 6| Step: 7
Training loss: 2.830850036529892
Validation loss: 2.7000739064312387

Epoch: 6| Step: 8
Training loss: 2.9033132502331696
Validation loss: 2.7031255254129105

Epoch: 6| Step: 9
Training loss: 2.7896052668542266
Validation loss: 2.7209864578409655

Epoch: 6| Step: 10
Training loss: 3.420479128330736
Validation loss: 2.7826520872932226

Epoch: 6| Step: 11
Training loss: 3.420707886812233
Validation loss: 2.756667258553009

Epoch: 6| Step: 12
Training loss: 2.8413360746463825
Validation loss: 2.742510672981769

Epoch: 6| Step: 13
Training loss: 2.197390404443092
Validation loss: 2.727403298552782

Epoch: 77| Step: 0
Training loss: 2.772874715952499
Validation loss: 2.7100614431498107

Epoch: 6| Step: 1
Training loss: 3.0324531605649754
Validation loss: 2.710538974269372

Epoch: 6| Step: 2
Training loss: 3.1558272579091993
Validation loss: 2.709249401799433

Epoch: 6| Step: 3
Training loss: 3.3518487412368208
Validation loss: 2.7081973500028673

Epoch: 6| Step: 4
Training loss: 2.3712222521681188
Validation loss: 2.703067898199051

Epoch: 6| Step: 5
Training loss: 2.685340723621663
Validation loss: 2.70268848789535

Epoch: 6| Step: 6
Training loss: 3.258523182000815
Validation loss: 2.6947844841918362

Epoch: 6| Step: 7
Training loss: 3.521122004546056
Validation loss: 2.692946889352056

Epoch: 6| Step: 8
Training loss: 3.434140592564182
Validation loss: 2.6925709420158386

Epoch: 6| Step: 9
Training loss: 3.0241551693357627
Validation loss: 2.690886542290102

Epoch: 6| Step: 10
Training loss: 2.7968881276424633
Validation loss: 2.694147666698535

Epoch: 6| Step: 11
Training loss: 2.673028172827951
Validation loss: 2.692565368321352

Epoch: 6| Step: 12
Training loss: 3.1226846891687208
Validation loss: 2.6931538083141677

Epoch: 6| Step: 13
Training loss: 3.167509485484962
Validation loss: 2.6920509753843986

Epoch: 78| Step: 0
Training loss: 2.784381261062861
Validation loss: 2.6930736220110956

Epoch: 6| Step: 1
Training loss: 2.4348460690449913
Validation loss: 2.7024882439906355

Epoch: 6| Step: 2
Training loss: 3.186125664722565
Validation loss: 2.704528145673726

Epoch: 6| Step: 3
Training loss: 3.661636558018835
Validation loss: 2.699579339849256

Epoch: 6| Step: 4
Training loss: 3.1224791468220996
Validation loss: 2.701307546084035

Epoch: 6| Step: 5
Training loss: 2.9677543175079224
Validation loss: 2.708205231570609

Epoch: 6| Step: 6
Training loss: 3.1272811193434236
Validation loss: 2.714113358337605

Epoch: 6| Step: 7
Training loss: 3.4537013336740165
Validation loss: 2.704782143385354

Epoch: 6| Step: 8
Training loss: 2.9458768187626654
Validation loss: 2.697559062332423

Epoch: 6| Step: 9
Training loss: 2.7136188186152674
Validation loss: 2.68386523958772

Epoch: 6| Step: 10
Training loss: 3.6045706344332005
Validation loss: 2.685734131729095

Epoch: 6| Step: 11
Training loss: 2.4325379948721424
Validation loss: 2.684737406071668

Epoch: 6| Step: 12
Training loss: 3.171124900482548
Validation loss: 2.6841800021457467

Epoch: 6| Step: 13
Training loss: 1.7385608233963399
Validation loss: 2.686170643666659

Epoch: 79| Step: 0
Training loss: 3.407404292799345
Validation loss: 2.687802987596384

Epoch: 6| Step: 1
Training loss: 2.6615552990314226
Validation loss: 2.685456322359897

Epoch: 6| Step: 2
Training loss: 2.5661830950236304
Validation loss: 2.685777119093592

Epoch: 6| Step: 3
Training loss: 3.2686744579098104
Validation loss: 2.682894546483367

Epoch: 6| Step: 4
Training loss: 2.9825932641487847
Validation loss: 2.6886868633212266

Epoch: 6| Step: 5
Training loss: 3.038058941438239
Validation loss: 2.6916991127070395

Epoch: 6| Step: 6
Training loss: 2.869249314546981
Validation loss: 2.700626793933572

Epoch: 6| Step: 7
Training loss: 2.9833950810639878
Validation loss: 2.7019689941452594

Epoch: 6| Step: 8
Training loss: 2.8800609658993963
Validation loss: 2.713495899676024

Epoch: 6| Step: 9
Training loss: 2.6925258217992836
Validation loss: 2.718804763998632

Epoch: 6| Step: 10
Training loss: 3.1350099082193967
Validation loss: 2.7235923804709956

Epoch: 6| Step: 11
Training loss: 3.6577072499942034
Validation loss: 2.726243418108469

Epoch: 6| Step: 12
Training loss: 3.012491604488593
Validation loss: 2.730681247016164

Epoch: 6| Step: 13
Training loss: 3.2917940300231714
Validation loss: 2.736062452970052

Epoch: 80| Step: 0
Training loss: 3.0137161775745587
Validation loss: 2.7347869328369034

Epoch: 6| Step: 1
Training loss: 2.9987752321683607
Validation loss: 2.7252201906557123

Epoch: 6| Step: 2
Training loss: 3.1410904724441004
Validation loss: 2.7203983547574375

Epoch: 6| Step: 3
Training loss: 2.9732206713568194
Validation loss: 2.7116926838320343

Epoch: 6| Step: 4
Training loss: 3.0826683014576064
Validation loss: 2.7143677672021718

Epoch: 6| Step: 5
Training loss: 2.8166630769364396
Validation loss: 2.7191079214928258

Epoch: 6| Step: 6
Training loss: 3.0665238084551483
Validation loss: 2.7204818612645667

Epoch: 6| Step: 7
Training loss: 2.9190813877093746
Validation loss: 2.7076753263465756

Epoch: 6| Step: 8
Training loss: 3.5576238891303884
Validation loss: 2.703951084706632

Epoch: 6| Step: 9
Training loss: 2.8716203479127227
Validation loss: 2.7003605306778717

Epoch: 6| Step: 10
Training loss: 2.646356986382873
Validation loss: 2.6911011026415474

Epoch: 6| Step: 11
Training loss: 2.464224808692559
Validation loss: 2.690783393013383

Epoch: 6| Step: 12
Training loss: 3.2893888261791857
Validation loss: 2.690639517429587

Epoch: 6| Step: 13
Training loss: 3.5264711705366283
Validation loss: 2.6936504426225087

Epoch: 81| Step: 0
Training loss: 3.031375843070787
Validation loss: 2.6824785058553684

Epoch: 6| Step: 1
Training loss: 2.858667505005576
Validation loss: 2.674670581086781

Epoch: 6| Step: 2
Training loss: 2.8494313258289337
Validation loss: 2.6731106445306354

Epoch: 6| Step: 3
Training loss: 3.1212732600031736
Validation loss: 2.6751744598411906

Epoch: 6| Step: 4
Training loss: 2.8700299634266533
Validation loss: 2.6746277363136506

Epoch: 6| Step: 5
Training loss: 2.8402144703005594
Validation loss: 2.6738450591017466

Epoch: 6| Step: 6
Training loss: 2.9669180588523734
Validation loss: 2.675127965216091

Epoch: 6| Step: 7
Training loss: 3.136286381510098
Validation loss: 2.673239623745153

Epoch: 6| Step: 8
Training loss: 2.930145634752125
Validation loss: 2.674649698898472

Epoch: 6| Step: 9
Training loss: 3.449833470623853
Validation loss: 2.675802450542926

Epoch: 6| Step: 10
Training loss: 2.6508538579960677
Validation loss: 2.6772824767131254

Epoch: 6| Step: 11
Training loss: 3.7146573666768568
Validation loss: 2.670996128437423

Epoch: 6| Step: 12
Training loss: 2.864057198960247
Validation loss: 2.6728765489567756

Epoch: 6| Step: 13
Training loss: 2.6542858266705767
Validation loss: 2.6712901481527225

Epoch: 82| Step: 0
Training loss: 2.969467879384173
Validation loss: 2.6716107353700904

Epoch: 6| Step: 1
Training loss: 2.208162972938676
Validation loss: 2.677596190613356

Epoch: 6| Step: 2
Training loss: 2.5696440874042064
Validation loss: 2.691163759660417

Epoch: 6| Step: 3
Training loss: 3.084624423963809
Validation loss: 2.698629824666899

Epoch: 6| Step: 4
Training loss: 2.737572593249009
Validation loss: 2.6963715415262834

Epoch: 6| Step: 5
Training loss: 3.4390199942000645
Validation loss: 2.680277741907419

Epoch: 6| Step: 6
Training loss: 3.041365273231699
Validation loss: 2.662665208336491

Epoch: 6| Step: 7
Training loss: 2.742075947723235
Validation loss: 2.663550716294315

Epoch: 6| Step: 8
Training loss: 2.9718027581420645
Validation loss: 2.6640970417136596

Epoch: 6| Step: 9
Training loss: 3.152316824834671
Validation loss: 2.6647217926858677

Epoch: 6| Step: 10
Training loss: 3.0977658496531566
Validation loss: 2.6659971641392084

Epoch: 6| Step: 11
Training loss: 3.3620254351886554
Validation loss: 2.6612832250777014

Epoch: 6| Step: 12
Training loss: 3.113884957052337
Validation loss: 2.6584888218616944

Epoch: 6| Step: 13
Training loss: 3.742929022794546
Validation loss: 2.6622005031720595

Epoch: 83| Step: 0
Training loss: 2.796929556032159
Validation loss: 2.658609682477231

Epoch: 6| Step: 1
Training loss: 2.269388374913251
Validation loss: 2.6598674696990345

Epoch: 6| Step: 2
Training loss: 3.1047546717341894
Validation loss: 2.6574945573179263

Epoch: 6| Step: 3
Training loss: 3.3792522628109447
Validation loss: 2.6607307046438664

Epoch: 6| Step: 4
Training loss: 3.090265643111465
Validation loss: 2.6786375696050957

Epoch: 6| Step: 5
Training loss: 3.5194257070485353
Validation loss: 2.688609151670296

Epoch: 6| Step: 6
Training loss: 2.8919415749099895
Validation loss: 2.71258084126764

Epoch: 6| Step: 7
Training loss: 2.9512503996626225
Validation loss: 2.7014095846081556

Epoch: 6| Step: 8
Training loss: 3.0958660865033427
Validation loss: 2.6719459208126626

Epoch: 6| Step: 9
Training loss: 2.9611167350208283
Validation loss: 2.6695662188219806

Epoch: 6| Step: 10
Training loss: 3.1900068410961495
Validation loss: 2.6617740478924103

Epoch: 6| Step: 11
Training loss: 2.714073983158818
Validation loss: 2.6587088682606415

Epoch: 6| Step: 12
Training loss: 2.767966448475793
Validation loss: 2.6612331079235068

Epoch: 6| Step: 13
Training loss: 3.0476539594206016
Validation loss: 2.6605502465908297

Epoch: 84| Step: 0
Training loss: 3.2876211165828053
Validation loss: 2.6601570624142052

Epoch: 6| Step: 1
Training loss: 3.0787631694900783
Validation loss: 2.6606596062912025

Epoch: 6| Step: 2
Training loss: 2.837265502381802
Validation loss: 2.6635001725831695

Epoch: 6| Step: 3
Training loss: 3.139740472990074
Validation loss: 2.665617841983552

Epoch: 6| Step: 4
Training loss: 2.7920161830301935
Validation loss: 2.665835551625024

Epoch: 6| Step: 5
Training loss: 3.0427313382694843
Validation loss: 2.6683091756738837

Epoch: 6| Step: 6
Training loss: 3.1338540341212022
Validation loss: 2.6646788880049734

Epoch: 6| Step: 7
Training loss: 2.937057461782707
Validation loss: 2.666761562622678

Epoch: 6| Step: 8
Training loss: 2.921663164425753
Validation loss: 2.6704735132971367

Epoch: 6| Step: 9
Training loss: 3.3484518203037514
Validation loss: 2.6776390745354246

Epoch: 6| Step: 10
Training loss: 2.5370826866619782
Validation loss: 2.6800371717600395

Epoch: 6| Step: 11
Training loss: 2.6387914126501775
Validation loss: 2.67490738049107

Epoch: 6| Step: 12
Training loss: 3.3964546118951837
Validation loss: 2.6911961788293706

Epoch: 6| Step: 13
Training loss: 2.670114394462642
Validation loss: 2.6866729572217105

Epoch: 85| Step: 0
Training loss: 2.803933725039096
Validation loss: 2.680740907573549

Epoch: 6| Step: 1
Training loss: 2.9251524143775596
Validation loss: 2.68653718739061

Epoch: 6| Step: 2
Training loss: 2.618565802821937
Validation loss: 2.670574830184351

Epoch: 6| Step: 3
Training loss: 2.7360757824402193
Validation loss: 2.6561650570842428

Epoch: 6| Step: 4
Training loss: 3.1074430511731315
Validation loss: 2.653901971289537

Epoch: 6| Step: 5
Training loss: 3.042482467011561
Validation loss: 2.6537196616143284

Epoch: 6| Step: 6
Training loss: 2.83302178259439
Validation loss: 2.6511701523755633

Epoch: 6| Step: 7
Training loss: 3.7069005591425155
Validation loss: 2.654371167760344

Epoch: 6| Step: 8
Training loss: 3.328932400045436
Validation loss: 2.6567677002415837

Epoch: 6| Step: 9
Training loss: 2.9430042399389826
Validation loss: 2.6503549015812937

Epoch: 6| Step: 10
Training loss: 2.6187378803418833
Validation loss: 2.6539294767234116

Epoch: 6| Step: 11
Training loss: 3.0479768765791406
Validation loss: 2.650821189158428

Epoch: 6| Step: 12
Training loss: 3.1297007491411706
Validation loss: 2.6521158377355496

Epoch: 6| Step: 13
Training loss: 2.7951399893327418
Validation loss: 2.6544665821471587

Epoch: 86| Step: 0
Training loss: 3.24720732206246
Validation loss: 2.6679648641335407

Epoch: 6| Step: 1
Training loss: 3.307789746522918
Validation loss: 2.6842424367823234

Epoch: 6| Step: 2
Training loss: 3.0237095436900105
Validation loss: 2.703257846549396

Epoch: 6| Step: 3
Training loss: 2.833136907014329
Validation loss: 2.694356659025587

Epoch: 6| Step: 4
Training loss: 1.7960453937885512
Validation loss: 2.660287040673168

Epoch: 6| Step: 5
Training loss: 3.3319493917626626
Validation loss: 2.6472174209061494

Epoch: 6| Step: 6
Training loss: 3.2103603614723215
Validation loss: 2.6499320272828397

Epoch: 6| Step: 7
Training loss: 2.8510082803670844
Validation loss: 2.658861948954275

Epoch: 6| Step: 8
Training loss: 3.2351627588379346
Validation loss: 2.6622890542714184

Epoch: 6| Step: 9
Training loss: 2.9794523373379795
Validation loss: 2.6683475813557287

Epoch: 6| Step: 10
Training loss: 2.624406838384044
Validation loss: 2.661238308445177

Epoch: 6| Step: 11
Training loss: 3.131422690618719
Validation loss: 2.656675107116524

Epoch: 6| Step: 12
Training loss: 3.3010794059126516
Validation loss: 2.654509916509382

Epoch: 6| Step: 13
Training loss: 2.3051548370851385
Validation loss: 2.653140733143358

Epoch: 87| Step: 0
Training loss: 2.9188173992862207
Validation loss: 2.65133291602437

Epoch: 6| Step: 1
Training loss: 2.6172009823579967
Validation loss: 2.6507863554942492

Epoch: 6| Step: 2
Training loss: 3.183225271045187
Validation loss: 2.647967346046702

Epoch: 6| Step: 3
Training loss: 2.7100961572401885
Validation loss: 2.649290444489449

Epoch: 6| Step: 4
Training loss: 2.5642226406860775
Validation loss: 2.6491448892761613

Epoch: 6| Step: 5
Training loss: 3.31519107549858
Validation loss: 2.6473232399351554

Epoch: 6| Step: 6
Training loss: 2.8721979833383986
Validation loss: 2.6481554129977565

Epoch: 6| Step: 7
Training loss: 3.1336842225471004
Validation loss: 2.6455016444623967

Epoch: 6| Step: 8
Training loss: 3.1493500175174107
Validation loss: 2.6451096746977245

Epoch: 6| Step: 9
Training loss: 2.8850143831578783
Validation loss: 2.644552967650464

Epoch: 6| Step: 10
Training loss: 3.287860134110727
Validation loss: 2.641801497628415

Epoch: 6| Step: 11
Training loss: 3.4065156885522394
Validation loss: 2.643935510173902

Epoch: 6| Step: 12
Training loss: 3.347552837612926
Validation loss: 2.6442606092485024

Epoch: 6| Step: 13
Training loss: 1.9929937788028345
Validation loss: 2.641761640492074

Epoch: 88| Step: 0
Training loss: 3.0949606019995937
Validation loss: 2.639281477021742

Epoch: 6| Step: 1
Training loss: 3.1855868413629453
Validation loss: 2.640464504544246

Epoch: 6| Step: 2
Training loss: 3.6379136889150634
Validation loss: 2.6389159557578594

Epoch: 6| Step: 3
Training loss: 2.932711655311214
Validation loss: 2.6410224830435296

Epoch: 6| Step: 4
Training loss: 2.67025439989913
Validation loss: 2.636157222676181

Epoch: 6| Step: 5
Training loss: 2.4139475378421342
Validation loss: 2.6401796255999663

Epoch: 6| Step: 6
Training loss: 2.6020064791306234
Validation loss: 2.636017233662413

Epoch: 6| Step: 7
Training loss: 2.958934740714078
Validation loss: 2.63613451733183

Epoch: 6| Step: 8
Training loss: 2.829882670959431
Validation loss: 2.6442421302978736

Epoch: 6| Step: 9
Training loss: 3.4077190066267202
Validation loss: 2.6396827820107056

Epoch: 6| Step: 10
Training loss: 2.7903127566087647
Validation loss: 2.638534775876647

Epoch: 6| Step: 11
Training loss: 3.0214499710185776
Validation loss: 2.634564028125593

Epoch: 6| Step: 12
Training loss: 3.0245539060440643
Validation loss: 2.638271237339895

Epoch: 6| Step: 13
Training loss: 3.2667516197783857
Validation loss: 2.633825797075387

Epoch: 89| Step: 0
Training loss: 3.0877482449583167
Validation loss: 2.6337797454244924

Epoch: 6| Step: 1
Training loss: 2.8542999087973135
Validation loss: 2.6393293860077787

Epoch: 6| Step: 2
Training loss: 2.7722173021417693
Validation loss: 2.6422683205224735

Epoch: 6| Step: 3
Training loss: 2.581259192203291
Validation loss: 2.63337286894427

Epoch: 6| Step: 4
Training loss: 3.079071364177557
Validation loss: 2.6305988273283116

Epoch: 6| Step: 5
Training loss: 2.863488245789889
Validation loss: 2.6338636563178652

Epoch: 6| Step: 6
Training loss: 3.438686374199098
Validation loss: 2.631286549871506

Epoch: 6| Step: 7
Training loss: 2.79460025965559
Validation loss: 2.631338943834413

Epoch: 6| Step: 8
Training loss: 2.518193988626664
Validation loss: 2.6298061668102037

Epoch: 6| Step: 9
Training loss: 3.2406549347512965
Validation loss: 2.6299619455515337

Epoch: 6| Step: 10
Training loss: 3.2206581163471197
Validation loss: 2.63294710458056

Epoch: 6| Step: 11
Training loss: 3.459782599305981
Validation loss: 2.6352387452166295

Epoch: 6| Step: 12
Training loss: 2.6275588687940505
Validation loss: 2.6386972162022317

Epoch: 6| Step: 13
Training loss: 2.8933023786280625
Validation loss: 2.632880927776182

Epoch: 90| Step: 0
Training loss: 3.2288222262537154
Validation loss: 2.628337336377529

Epoch: 6| Step: 1
Training loss: 3.0421280881059825
Validation loss: 2.6346469137461317

Epoch: 6| Step: 2
Training loss: 2.4829299850947404
Validation loss: 2.629052221671734

Epoch: 6| Step: 3
Training loss: 3.1751454597854094
Validation loss: 2.625366092629779

Epoch: 6| Step: 4
Training loss: 2.3846745454108653
Validation loss: 2.6266122160302343

Epoch: 6| Step: 5
Training loss: 3.5510181310218205
Validation loss: 2.6368476075984244

Epoch: 6| Step: 6
Training loss: 3.1906731462722364
Validation loss: 2.6442312309528053

Epoch: 6| Step: 7
Training loss: 3.080686945664869
Validation loss: 2.625574056981683

Epoch: 6| Step: 8
Training loss: 2.4476589851838972
Validation loss: 2.6220078278682504

Epoch: 6| Step: 9
Training loss: 2.848380207400024
Validation loss: 2.6265726637610225

Epoch: 6| Step: 10
Training loss: 2.6385532355302774
Validation loss: 2.6295756138326496

Epoch: 6| Step: 11
Training loss: 3.2034499585068774
Validation loss: 2.6236183722187327

Epoch: 6| Step: 12
Training loss: 3.4174449933528956
Validation loss: 2.6237565800475946

Epoch: 6| Step: 13
Training loss: 2.2363762063267365
Validation loss: 2.625351631767031

Epoch: 91| Step: 0
Training loss: 2.925237994822811
Validation loss: 2.625147581468728

Epoch: 6| Step: 1
Training loss: 3.1838768207166983
Validation loss: 2.6227757405544314

Epoch: 6| Step: 2
Training loss: 3.7637129238485407
Validation loss: 2.6267199118977618

Epoch: 6| Step: 3
Training loss: 2.4492671298613367
Validation loss: 2.623056640196335

Epoch: 6| Step: 4
Training loss: 1.9613925968066626
Validation loss: 2.6210874120308207

Epoch: 6| Step: 5
Training loss: 3.0294523906325668
Validation loss: 2.623649744065728

Epoch: 6| Step: 6
Training loss: 3.27510629146566
Validation loss: 2.6274676826795123

Epoch: 6| Step: 7
Training loss: 2.9030952969480044
Validation loss: 2.628084304469326

Epoch: 6| Step: 8
Training loss: 2.966743192507246
Validation loss: 2.637354852597412

Epoch: 6| Step: 9
Training loss: 2.9352325453905728
Validation loss: 2.646331650717718

Epoch: 6| Step: 10
Training loss: 2.9045152306324002
Validation loss: 2.6380077784027085

Epoch: 6| Step: 11
Training loss: 3.080581536817435
Validation loss: 2.6266352027954154

Epoch: 6| Step: 12
Training loss: 3.287888269739711
Validation loss: 2.6252335621751097

Epoch: 6| Step: 13
Training loss: 2.533527527025134
Validation loss: 2.617778804213034

Epoch: 92| Step: 0
Training loss: 2.956667758062678
Validation loss: 2.615467600681463

Epoch: 6| Step: 1
Training loss: 3.241290821034644
Validation loss: 2.6168561044527068

Epoch: 6| Step: 2
Training loss: 2.752342959990484
Validation loss: 2.617481267240522

Epoch: 6| Step: 3
Training loss: 2.964294623986936
Validation loss: 2.616872054319387

Epoch: 6| Step: 4
Training loss: 2.9525401025643965
Validation loss: 2.6122581828481053

Epoch: 6| Step: 5
Training loss: 2.907801060395284
Validation loss: 2.6144444134127056

Epoch: 6| Step: 6
Training loss: 2.902647677664207
Validation loss: 2.618637752317732

Epoch: 6| Step: 7
Training loss: 2.7129287662118133
Validation loss: 2.6360780086451894

Epoch: 6| Step: 8
Training loss: 3.376422723492253
Validation loss: 2.6482425915268593

Epoch: 6| Step: 9
Training loss: 2.5538606851410055
Validation loss: 2.647889485943437

Epoch: 6| Step: 10
Training loss: 2.8342286733521633
Validation loss: 2.6340047836848295

Epoch: 6| Step: 11
Training loss: 3.476347430145342
Validation loss: 2.6270329327988273

Epoch: 6| Step: 12
Training loss: 3.0616801195951417
Validation loss: 2.615264477014688

Epoch: 6| Step: 13
Training loss: 2.5394377915254367
Validation loss: 2.6101199825530212

Epoch: 93| Step: 0
Training loss: 2.799853395983701
Validation loss: 2.607158485571088

Epoch: 6| Step: 1
Training loss: 3.2093002711791896
Validation loss: 2.611958945204492

Epoch: 6| Step: 2
Training loss: 3.175419072406096
Validation loss: 2.6129724105566385

Epoch: 6| Step: 3
Training loss: 3.683842930704042
Validation loss: 2.610344077863228

Epoch: 6| Step: 4
Training loss: 2.849010924993518
Validation loss: 2.6100774149591004

Epoch: 6| Step: 5
Training loss: 2.1202493184514406
Validation loss: 2.606493023434576

Epoch: 6| Step: 6
Training loss: 3.3116105522952486
Validation loss: 2.610169259674788

Epoch: 6| Step: 7
Training loss: 3.243418411623589
Validation loss: 2.613687801572333

Epoch: 6| Step: 8
Training loss: 2.538444936915888
Validation loss: 2.625308855113709

Epoch: 6| Step: 9
Training loss: 2.104570922794831
Validation loss: 2.63613326086162

Epoch: 6| Step: 10
Training loss: 3.390689972285756
Validation loss: 2.646116419046371

Epoch: 6| Step: 11
Training loss: 3.0021403942381357
Validation loss: 2.6476483161556206

Epoch: 6| Step: 12
Training loss: 2.4611409421117023
Validation loss: 2.6477945306965243

Epoch: 6| Step: 13
Training loss: 3.2261763149923284
Validation loss: 2.628220383171314

Epoch: 94| Step: 0
Training loss: 2.5360639031779537
Validation loss: 2.6142208578752233

Epoch: 6| Step: 1
Training loss: 3.4668571187547306
Validation loss: 2.605327557790464

Epoch: 6| Step: 2
Training loss: 2.800840326641159
Validation loss: 2.6110135198156477

Epoch: 6| Step: 3
Training loss: 2.6748646746479423
Validation loss: 2.6178883221087568

Epoch: 6| Step: 4
Training loss: 3.5115441267241203
Validation loss: 2.6145251805740783

Epoch: 6| Step: 5
Training loss: 2.0669719880692363
Validation loss: 2.6170485406827493

Epoch: 6| Step: 6
Training loss: 2.9668399488726322
Validation loss: 2.6093699284691465

Epoch: 6| Step: 7
Training loss: 2.682235885089475
Validation loss: 2.6076394402411114

Epoch: 6| Step: 8
Training loss: 2.881614705005766
Validation loss: 2.608605790011645

Epoch: 6| Step: 9
Training loss: 3.7921567886548693
Validation loss: 2.6083066778607495

Epoch: 6| Step: 10
Training loss: 3.334416706142566
Validation loss: 2.620852155921232

Epoch: 6| Step: 11
Training loss: 2.709872957468242
Validation loss: 2.644870423610337

Epoch: 6| Step: 12
Training loss: 2.993705344613703
Validation loss: 2.6836912520126583

Epoch: 6| Step: 13
Training loss: 2.483860946350593
Validation loss: 2.7111715648544954

Epoch: 95| Step: 0
Training loss: 2.544161421662851
Validation loss: 2.7426303884152117

Epoch: 6| Step: 1
Training loss: 2.385605472827572
Validation loss: 2.720789942613452

Epoch: 6| Step: 2
Training loss: 2.9012546061652227
Validation loss: 2.7124276666971134

Epoch: 6| Step: 3
Training loss: 3.1086274595079475
Validation loss: 2.7390502048490224

Epoch: 6| Step: 4
Training loss: 3.6054527472474627
Validation loss: 2.7199115443052153

Epoch: 6| Step: 5
Training loss: 2.9507897241302565
Validation loss: 2.65642502634554

Epoch: 6| Step: 6
Training loss: 3.247137716640623
Validation loss: 2.6317033256720626

Epoch: 6| Step: 7
Training loss: 2.9353379754555298
Validation loss: 2.632184006891095

Epoch: 6| Step: 8
Training loss: 3.241833770942812
Validation loss: 2.633665207042229

Epoch: 6| Step: 9
Training loss: 3.1495492642975607
Validation loss: 2.633580508637956

Epoch: 6| Step: 10
Training loss: 3.051662967276158
Validation loss: 2.634270102752992

Epoch: 6| Step: 11
Training loss: 2.9452244267335765
Validation loss: 2.6406857140790394

Epoch: 6| Step: 12
Training loss: 2.776613807526178
Validation loss: 2.642047182363498

Epoch: 6| Step: 13
Training loss: 2.928165294650876
Validation loss: 2.6454635089060266

Epoch: 96| Step: 0
Training loss: 3.0797825721686096
Validation loss: 2.6526839097529042

Epoch: 6| Step: 1
Training loss: 3.114854747637031
Validation loss: 2.656411831852389

Epoch: 6| Step: 2
Training loss: 2.5503695799838177
Validation loss: 2.638534688431273

Epoch: 6| Step: 3
Training loss: 2.928752780575965
Validation loss: 2.624014898606905

Epoch: 6| Step: 4
Training loss: 3.1547409831516067
Validation loss: 2.619493527755209

Epoch: 6| Step: 5
Training loss: 3.306034183489321
Validation loss: 2.618673814432902

Epoch: 6| Step: 6
Training loss: 3.3997283939258764
Validation loss: 2.606552831026573

Epoch: 6| Step: 7
Training loss: 2.611114835623752
Validation loss: 2.607525481538827

Epoch: 6| Step: 8
Training loss: 2.9213168177147253
Validation loss: 2.604553840322412

Epoch: 6| Step: 9
Training loss: 3.0618905220019847
Validation loss: 2.6065097084823217

Epoch: 6| Step: 10
Training loss: 2.515177432223016
Validation loss: 2.6041680580053406

Epoch: 6| Step: 11
Training loss: 3.3989204151323285
Validation loss: 2.595692735911374

Epoch: 6| Step: 12
Training loss: 2.313596517046342
Validation loss: 2.597210018971663

Epoch: 6| Step: 13
Training loss: 3.3061316831363197
Validation loss: 2.6123174403878617

Epoch: 97| Step: 0
Training loss: 2.301265231718745
Validation loss: 2.6349266271421445

Epoch: 6| Step: 1
Training loss: 2.9192883470856685
Validation loss: 2.6320782415294497

Epoch: 6| Step: 2
Training loss: 3.1328225456704586
Validation loss: 2.6223303447407345

Epoch: 6| Step: 3
Training loss: 3.196980010962021
Validation loss: 2.6152698645212076

Epoch: 6| Step: 4
Training loss: 3.489434370970327
Validation loss: 2.612597210031257

Epoch: 6| Step: 5
Training loss: 3.417296948487659
Validation loss: 2.6029863743593107

Epoch: 6| Step: 6
Training loss: 2.691681735662869
Validation loss: 2.603606489085389

Epoch: 6| Step: 7
Training loss: 2.4809858128650584
Validation loss: 2.6003844256210873

Epoch: 6| Step: 8
Training loss: 3.0793141812790665
Validation loss: 2.5996015823220464

Epoch: 6| Step: 9
Training loss: 2.7020328498385147
Validation loss: 2.5999657600268593

Epoch: 6| Step: 10
Training loss: 3.4094925591806766
Validation loss: 2.60604486935708

Epoch: 6| Step: 11
Training loss: 2.96536399086649
Validation loss: 2.6230073564434306

Epoch: 6| Step: 12
Training loss: 2.681338232762764
Validation loss: 2.6260465048697625

Epoch: 6| Step: 13
Training loss: 2.2144485470893875
Validation loss: 2.6144773249912663

Epoch: 98| Step: 0
Training loss: 2.975051776852156
Validation loss: 2.613306411662988

Epoch: 6| Step: 1
Training loss: 2.9231261160413866
Validation loss: 2.60926063271737

Epoch: 6| Step: 2
Training loss: 2.9081306525347026
Validation loss: 2.6036085558645206

Epoch: 6| Step: 3
Training loss: 3.210602605948415
Validation loss: 2.5982837512160635

Epoch: 6| Step: 4
Training loss: 2.7402452508081128
Validation loss: 2.5934493731658304

Epoch: 6| Step: 5
Training loss: 2.9208293818629842
Validation loss: 2.5902017162154998

Epoch: 6| Step: 6
Training loss: 2.6313117303199065
Validation loss: 2.584713482495977

Epoch: 6| Step: 7
Training loss: 2.296755521612152
Validation loss: 2.59252330179915

Epoch: 6| Step: 8
Training loss: 3.5828477101648346
Validation loss: 2.594844533801513

Epoch: 6| Step: 9
Training loss: 3.03160612236358
Validation loss: 2.597338498388962

Epoch: 6| Step: 10
Training loss: 2.8084330506171202
Validation loss: 2.596247715172262

Epoch: 6| Step: 11
Training loss: 3.433821218201282
Validation loss: 2.5938338201811364

Epoch: 6| Step: 12
Training loss: 2.8324728575413562
Validation loss: 2.5942004633366316

Epoch: 6| Step: 13
Training loss: 2.9035359497262196
Validation loss: 2.5859708071003262

Epoch: 99| Step: 0
Training loss: 2.8398266231644826
Validation loss: 2.593269308543978

Epoch: 6| Step: 1
Training loss: 3.028165053662716
Validation loss: 2.695949936212567

Epoch: 6| Step: 2
Training loss: 2.675887457974296
Validation loss: 2.837105672509489

Epoch: 6| Step: 3
Training loss: 3.568926853267263
Validation loss: 2.9274136692573736

Epoch: 6| Step: 4
Training loss: 2.6910597712450257
Validation loss: 2.806684047719788

Epoch: 6| Step: 5
Training loss: 3.396863972102902
Validation loss: 2.6410058393681637

Epoch: 6| Step: 6
Training loss: 2.5664865141558315
Validation loss: 2.6081384002215566

Epoch: 6| Step: 7
Training loss: 3.021413357176862
Validation loss: 2.608138586979937

Epoch: 6| Step: 8
Training loss: 3.7345817221401463
Validation loss: 2.6116198577425096

Epoch: 6| Step: 9
Training loss: 2.8394289828859147
Validation loss: 2.6399835694734923

Epoch: 6| Step: 10
Training loss: 3.229551394934661
Validation loss: 2.6804772004491793

Epoch: 6| Step: 11
Training loss: 3.303563280721507
Validation loss: 2.6708958027322693

Epoch: 6| Step: 12
Training loss: 2.3732256033196064
Validation loss: 2.6282244741145724

Epoch: 6| Step: 13
Training loss: 2.215841724465464
Validation loss: 2.6099281306892124

Epoch: 100| Step: 0
Training loss: 2.284799505573775
Validation loss: 2.6090080853594233

Epoch: 6| Step: 1
Training loss: 2.1793304479063917
Validation loss: 2.604783625870985

Epoch: 6| Step: 2
Training loss: 3.6193826494644954
Validation loss: 2.6001535325355873

Epoch: 6| Step: 3
Training loss: 3.288668719932564
Validation loss: 2.5962974264104446

Epoch: 6| Step: 4
Training loss: 3.7106316691411454
Validation loss: 2.5890318885301746

Epoch: 6| Step: 5
Training loss: 3.1735223710897533
Validation loss: 2.5867611971952735

Epoch: 6| Step: 6
Training loss: 2.3332727855819293
Validation loss: 2.5971463548261293

Epoch: 6| Step: 7
Training loss: 3.1239547507297436
Validation loss: 2.5991791619360956

Epoch: 6| Step: 8
Training loss: 2.8187616792085857
Validation loss: 2.634651044336045

Epoch: 6| Step: 9
Training loss: 2.8064073480277174
Validation loss: 2.680388823651633

Epoch: 6| Step: 10
Training loss: 2.8750396394070155
Validation loss: 2.6502079102971017

Epoch: 6| Step: 11
Training loss: 3.2901734131907374
Validation loss: 2.6179360908574147

Epoch: 6| Step: 12
Training loss: 2.6897898832318257
Validation loss: 2.5928007915075018

Epoch: 6| Step: 13
Training loss: 2.6457091374922452
Validation loss: 2.580786862764266

Testing loss: 2.815017694162064
