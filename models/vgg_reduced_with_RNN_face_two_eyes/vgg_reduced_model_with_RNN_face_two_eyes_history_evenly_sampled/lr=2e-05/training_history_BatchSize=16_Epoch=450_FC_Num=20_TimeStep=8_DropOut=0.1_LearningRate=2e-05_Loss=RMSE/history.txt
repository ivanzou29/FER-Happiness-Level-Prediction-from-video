Epoch: 1| Step: 0
Training loss: 5.544648403237788
Validation loss: 5.810160243275577

Epoch: 6| Step: 1
Training loss: 6.20198167694741
Validation loss: 5.795324438096714

Epoch: 6| Step: 2
Training loss: 5.690873371802145
Validation loss: 5.780842822102605

Epoch: 6| Step: 3
Training loss: 5.083221413469464
Validation loss: 5.7638851812991305

Epoch: 6| Step: 4
Training loss: 6.0647368089848595
Validation loss: 5.744641511282163

Epoch: 6| Step: 5
Training loss: 5.3342525564218795
Validation loss: 5.722258321619875

Epoch: 6| Step: 6
Training loss: 6.168166038445466
Validation loss: 5.695802549890566

Epoch: 6| Step: 7
Training loss: 5.0334947210716
Validation loss: 5.665359698624214

Epoch: 6| Step: 8
Training loss: 4.868538119562263
Validation loss: 5.6313970361881065

Epoch: 6| Step: 9
Training loss: 5.889720897959374
Validation loss: 5.5928525311855735

Epoch: 6| Step: 10
Training loss: 6.449221707487208
Validation loss: 5.550938582347074

Epoch: 6| Step: 11
Training loss: 6.329799402321752
Validation loss: 5.504268202002322

Epoch: 6| Step: 12
Training loss: 4.7601885695732165
Validation loss: 5.454463987217518

Epoch: 6| Step: 13
Training loss: 6.1616645664537915
Validation loss: 5.399345587390421

Epoch: 2| Step: 0
Training loss: 3.989746183386748
Validation loss: 5.3402564730659465

Epoch: 6| Step: 1
Training loss: 6.146341317945147
Validation loss: 5.277392450430993

Epoch: 6| Step: 2
Training loss: 4.993883588052051
Validation loss: 5.212294578443998

Epoch: 6| Step: 3
Training loss: 5.285373680452178
Validation loss: 5.140330769291978

Epoch: 6| Step: 4
Training loss: 4.9561552291218005
Validation loss: 5.068412776402279

Epoch: 6| Step: 5
Training loss: 4.383494822110407
Validation loss: 4.993878047909876

Epoch: 6| Step: 6
Training loss: 5.482735500191804
Validation loss: 4.919711402681135

Epoch: 6| Step: 7
Training loss: 4.139384764138982
Validation loss: 4.847835790398092

Epoch: 6| Step: 8
Training loss: 5.693893360464507
Validation loss: 4.780520289162224

Epoch: 6| Step: 9
Training loss: 5.058602799219705
Validation loss: 4.718651203114661

Epoch: 6| Step: 10
Training loss: 4.968751535475391
Validation loss: 4.6632099020583375

Epoch: 6| Step: 11
Training loss: 5.016183031834296
Validation loss: 4.613873508568635

Epoch: 6| Step: 12
Training loss: 4.657089669728782
Validation loss: 4.567489112325414

Epoch: 6| Step: 13
Training loss: 4.2496710257270855
Validation loss: 4.523573290331305

Epoch: 3| Step: 0
Training loss: 4.286238611027629
Validation loss: 4.479586174053083

Epoch: 6| Step: 1
Training loss: 5.037223918155291
Validation loss: 4.437552373641454

Epoch: 6| Step: 2
Training loss: 4.4156674868300545
Validation loss: 4.401534851405106

Epoch: 6| Step: 3
Training loss: 4.630545307451419
Validation loss: 4.367060682350168

Epoch: 6| Step: 4
Training loss: 4.499546875922402
Validation loss: 4.33641822675419

Epoch: 6| Step: 5
Training loss: 3.9346237576647507
Validation loss: 4.302772927737247

Epoch: 6| Step: 6
Training loss: 4.220364410069844
Validation loss: 4.274861884187298

Epoch: 6| Step: 7
Training loss: 4.7742194051965265
Validation loss: 4.240228235899291

Epoch: 6| Step: 8
Training loss: 3.8649070720678673
Validation loss: 4.204072559324247

Epoch: 6| Step: 9
Training loss: 5.113119357397037
Validation loss: 4.190020864477184

Epoch: 6| Step: 10
Training loss: 5.200644695224976
Validation loss: 4.1752364442113095

Epoch: 6| Step: 11
Training loss: 3.6365270512882173
Validation loss: 4.155408302932325

Epoch: 6| Step: 12
Training loss: 3.971213469801075
Validation loss: 4.134754603495807

Epoch: 6| Step: 13
Training loss: 3.0513580988231155
Validation loss: 4.116025073899854

Epoch: 4| Step: 0
Training loss: 4.126786509814023
Validation loss: 4.100597548491014

Epoch: 6| Step: 1
Training loss: 4.216648510880014
Validation loss: 4.082954875559131

Epoch: 6| Step: 2
Training loss: 4.666436030728573
Validation loss: 4.064284056122355

Epoch: 6| Step: 3
Training loss: 3.885481778469418
Validation loss: 4.046251747003518

Epoch: 6| Step: 4
Training loss: 4.740873302376837
Validation loss: 4.0310301985091295

Epoch: 6| Step: 5
Training loss: 5.168356260273228
Validation loss: 4.011499738038458

Epoch: 6| Step: 6
Training loss: 3.2462773644105907
Validation loss: 3.994952774548018

Epoch: 6| Step: 7
Training loss: 4.546872063599782
Validation loss: 3.9807205520670217

Epoch: 6| Step: 8
Training loss: 3.7624941905030678
Validation loss: 3.9723410676211524

Epoch: 6| Step: 9
Training loss: 4.204037024947438
Validation loss: 3.956704826825803

Epoch: 6| Step: 10
Training loss: 4.394353946075982
Validation loss: 3.9429986247877213

Epoch: 6| Step: 11
Training loss: 3.9091962765854604
Validation loss: 3.921260888777178

Epoch: 6| Step: 12
Training loss: 3.6181446893459075
Validation loss: 3.907424593962431

Epoch: 6| Step: 13
Training loss: 2.1471129617313034
Validation loss: 3.91511366004077

Epoch: 5| Step: 0
Training loss: 4.698500276278741
Validation loss: 3.884961903154161

Epoch: 6| Step: 1
Training loss: 4.6112832467505935
Validation loss: 3.871531039616327

Epoch: 6| Step: 2
Training loss: 4.944163208486682
Validation loss: 3.8667829828797684

Epoch: 6| Step: 3
Training loss: 4.405757146015096
Validation loss: 3.8595768005293345

Epoch: 6| Step: 4
Training loss: 3.581366657267734
Validation loss: 3.845022949014141

Epoch: 6| Step: 5
Training loss: 3.5561266993381446
Validation loss: 3.829217175269502

Epoch: 6| Step: 6
Training loss: 3.240462614164278
Validation loss: 3.815902735355023

Epoch: 6| Step: 7
Training loss: 3.792908908674443
Validation loss: 3.8044776155322504

Epoch: 6| Step: 8
Training loss: 4.033421367808954
Validation loss: 3.8001211153557177

Epoch: 6| Step: 9
Training loss: 3.551091985251822
Validation loss: 3.790799386678758

Epoch: 6| Step: 10
Training loss: 2.5661591246838613
Validation loss: 3.779284086950628

Epoch: 6| Step: 11
Training loss: 3.8467957129779133
Validation loss: 3.7666865919368213

Epoch: 6| Step: 12
Training loss: 4.28525239181118
Validation loss: 3.760403284921641

Epoch: 6| Step: 13
Training loss: 4.358521955698476
Validation loss: 3.7593516398055034

Epoch: 6| Step: 0
Training loss: 2.4137530576033663
Validation loss: 3.7478636231227136

Epoch: 6| Step: 1
Training loss: 3.806495565877096
Validation loss: 3.7477953880529027

Epoch: 6| Step: 2
Training loss: 4.151448164899175
Validation loss: 3.7203403201167324

Epoch: 6| Step: 3
Training loss: 4.280602176408803
Validation loss: 3.707058492587846

Epoch: 6| Step: 4
Training loss: 4.388277668515985
Validation loss: 3.7006132580451214

Epoch: 6| Step: 5
Training loss: 3.6058025432906295
Validation loss: 3.689039717785446

Epoch: 6| Step: 6
Training loss: 2.6044608801900693
Validation loss: 3.6752921020642986

Epoch: 6| Step: 7
Training loss: 3.4618114461607425
Validation loss: 3.6664022777321166

Epoch: 6| Step: 8
Training loss: 4.5906203631539295
Validation loss: 3.6596462959011693

Epoch: 6| Step: 9
Training loss: 3.456359315216135
Validation loss: 3.648887961140553

Epoch: 6| Step: 10
Training loss: 4.021756370946775
Validation loss: 3.6417161374190634

Epoch: 6| Step: 11
Training loss: 4.59951026631547
Validation loss: 3.6313835616076373

Epoch: 6| Step: 12
Training loss: 3.8388770003133934
Validation loss: 3.620693225477615

Epoch: 6| Step: 13
Training loss: 4.312453781101397
Validation loss: 3.6100923751944127

Epoch: 7| Step: 0
Training loss: 2.6953607969517974
Validation loss: 3.601274258115434

Epoch: 6| Step: 1
Training loss: 3.274972924273439
Validation loss: 3.5987598854855847

Epoch: 6| Step: 2
Training loss: 3.199050768493206
Validation loss: 3.5926818958190374

Epoch: 6| Step: 3
Training loss: 4.276772043699492
Validation loss: 3.580512196639303

Epoch: 6| Step: 4
Training loss: 4.141246820938544
Validation loss: 3.5697844675746877

Epoch: 6| Step: 5
Training loss: 3.973307958389602
Validation loss: 3.560530303138359

Epoch: 6| Step: 6
Training loss: 4.316816961158703
Validation loss: 3.5553081451581066

Epoch: 6| Step: 7
Training loss: 4.524257341845097
Validation loss: 3.5464795215441924

Epoch: 6| Step: 8
Training loss: 3.6369516070725356
Validation loss: 3.536379542860903

Epoch: 6| Step: 9
Training loss: 3.9616459019274175
Validation loss: 3.533653503437871

Epoch: 6| Step: 10
Training loss: 3.9694439138689894
Validation loss: 3.5278740929126693

Epoch: 6| Step: 11
Training loss: 3.9128352694933897
Validation loss: 3.521326567271447

Epoch: 6| Step: 12
Training loss: 2.7778620283277737
Validation loss: 3.515897102718464

Epoch: 6| Step: 13
Training loss: 3.132963638274859
Validation loss: 3.5116752008499623

Epoch: 8| Step: 0
Training loss: 3.0062388080856506
Validation loss: 3.507786533250376

Epoch: 6| Step: 1
Training loss: 2.8935853388099813
Validation loss: 3.503523210612177

Epoch: 6| Step: 2
Training loss: 3.8460413608241293
Validation loss: 3.4966921403024

Epoch: 6| Step: 3
Training loss: 3.0140213729718237
Validation loss: 3.488326321462393

Epoch: 6| Step: 4
Training loss: 4.292193383545067
Validation loss: 3.482724498227568

Epoch: 6| Step: 5
Training loss: 4.092765398502305
Validation loss: 3.477826562908616

Epoch: 6| Step: 6
Training loss: 3.5779480203229355
Validation loss: 3.4721889135479014

Epoch: 6| Step: 7
Training loss: 3.709782792182494
Validation loss: 3.4622365528870245

Epoch: 6| Step: 8
Training loss: 3.9135546935433863
Validation loss: 3.4564642547182074

Epoch: 6| Step: 9
Training loss: 3.4890396985249823
Validation loss: 3.4489219089150236

Epoch: 6| Step: 10
Training loss: 3.7727013416798822
Validation loss: 3.43945640012287

Epoch: 6| Step: 11
Training loss: 4.568228065329089
Validation loss: 3.435291085463711

Epoch: 6| Step: 12
Training loss: 3.530392973209652
Validation loss: 3.4291796628185702

Epoch: 6| Step: 13
Training loss: 3.2772043628173306
Validation loss: 3.424394368697372

Epoch: 9| Step: 0
Training loss: 3.8785478900816397
Validation loss: 3.419700781030951

Epoch: 6| Step: 1
Training loss: 4.185758313896481
Validation loss: 3.42260431891714

Epoch: 6| Step: 2
Training loss: 3.938343744854773
Validation loss: 3.4325944922313716

Epoch: 6| Step: 3
Training loss: 3.154865225499253
Validation loss: 3.3979760953997444

Epoch: 6| Step: 4
Training loss: 3.944838451950511
Validation loss: 3.3935887382134613

Epoch: 6| Step: 5
Training loss: 3.399804973618719
Validation loss: 3.3812119116789368

Epoch: 6| Step: 6
Training loss: 3.593346481888966
Validation loss: 3.4058482759317434

Epoch: 6| Step: 7
Training loss: 2.9922464628859236
Validation loss: 3.4115052443623592

Epoch: 6| Step: 8
Training loss: 3.2075730120584236
Validation loss: 3.3848293828078

Epoch: 6| Step: 9
Training loss: 4.130266468974651
Validation loss: 3.3724319960957647

Epoch: 6| Step: 10
Training loss: 3.3734426790792225
Validation loss: 3.374560176701638

Epoch: 6| Step: 11
Training loss: 3.384354801417103
Validation loss: 3.367705959699104

Epoch: 6| Step: 12
Training loss: 3.2503826209566755
Validation loss: 3.361283507525312

Epoch: 6| Step: 13
Training loss: 4.240745791216759
Validation loss: 3.3642513368253337

Epoch: 10| Step: 0
Training loss: 4.600418544469814
Validation loss: 3.359992483499795

Epoch: 6| Step: 1
Training loss: 3.1076228893775073
Validation loss: 3.34753923499642

Epoch: 6| Step: 2
Training loss: 2.9989208823742306
Validation loss: 3.3444337035644547

Epoch: 6| Step: 3
Training loss: 2.9377240034687806
Validation loss: 3.3420201755921433

Epoch: 6| Step: 4
Training loss: 2.995199176871358
Validation loss: 3.374424043988787

Epoch: 6| Step: 5
Training loss: 3.6963542090939976
Validation loss: 3.3434469511018414

Epoch: 6| Step: 6
Training loss: 4.181875522506879
Validation loss: 3.334672926836643

Epoch: 6| Step: 7
Training loss: 4.18802058841341
Validation loss: 3.335562977549257

Epoch: 6| Step: 8
Training loss: 3.8694748404365527
Validation loss: 3.3357667321388265

Epoch: 6| Step: 9
Training loss: 3.760596499101271
Validation loss: 3.333859302698728

Epoch: 6| Step: 10
Training loss: 2.3335924912900436
Validation loss: 3.331406219814446

Epoch: 6| Step: 11
Training loss: 3.502187862496635
Validation loss: 3.333009823102728

Epoch: 6| Step: 12
Training loss: 3.8728304296081726
Validation loss: 3.341960693129203

Epoch: 6| Step: 13
Training loss: 3.188215287677583
Validation loss: 3.335635550514858

Epoch: 11| Step: 0
Training loss: 3.910371117114023
Validation loss: 3.331190167580258

Epoch: 6| Step: 1
Training loss: 4.228295046931594
Validation loss: 3.324334818342842

Epoch: 6| Step: 2
Training loss: 3.9512785568581115
Validation loss: 3.3290516816238966

Epoch: 6| Step: 3
Training loss: 3.1136822029490925
Validation loss: 3.327966993179273

Epoch: 6| Step: 4
Training loss: 3.787638162541638
Validation loss: 3.3292910512677354

Epoch: 6| Step: 5
Training loss: 3.0367598648369567
Validation loss: 3.319247669203319

Epoch: 6| Step: 6
Training loss: 4.1980285377204885
Validation loss: 3.320605170171192

Epoch: 6| Step: 7
Training loss: 3.5889203333649973
Validation loss: 3.3132899250516283

Epoch: 6| Step: 8
Training loss: 2.501524269817375
Validation loss: 3.316911489877016

Epoch: 6| Step: 9
Training loss: 3.079667377841654
Validation loss: 3.339510343161863

Epoch: 6| Step: 10
Training loss: 3.255890276876073
Validation loss: 3.329237101269751

Epoch: 6| Step: 11
Training loss: 3.496103706558797
Validation loss: 3.310393360288506

Epoch: 6| Step: 12
Training loss: 3.0121731149437028
Validation loss: 3.307859951214501

Epoch: 6| Step: 13
Training loss: 4.631932192660245
Validation loss: 3.3260835121817047

Epoch: 12| Step: 0
Training loss: 4.238079857326333
Validation loss: 3.3120377895883766

Epoch: 6| Step: 1
Training loss: 3.5126745431777566
Validation loss: 3.299872134749738

Epoch: 6| Step: 2
Training loss: 3.441210322263907
Validation loss: 3.3028774319150886

Epoch: 6| Step: 3
Training loss: 2.9932859311956075
Validation loss: 3.313846148213183

Epoch: 6| Step: 4
Training loss: 3.8381907881984354
Validation loss: 3.327706481232658

Epoch: 6| Step: 5
Training loss: 3.4696366835037837
Validation loss: 3.318560129384929

Epoch: 6| Step: 6
Training loss: 3.5821188413670417
Validation loss: 3.309975933035414

Epoch: 6| Step: 7
Training loss: 3.821202211589686
Validation loss: 3.3063546305814024

Epoch: 6| Step: 8
Training loss: 3.322554246676333
Validation loss: 3.307029651084384

Epoch: 6| Step: 9
Training loss: 3.702449946300206
Validation loss: 3.3073225184480783

Epoch: 6| Step: 10
Training loss: 3.360485088663232
Validation loss: 3.3047343182675846

Epoch: 6| Step: 11
Training loss: 3.067308349094178
Validation loss: 3.3003497202852166

Epoch: 6| Step: 12
Training loss: 2.9984730967386106
Validation loss: 3.3035149170706153

Epoch: 6| Step: 13
Training loss: 4.449660496137182
Validation loss: 3.306604163959874

Epoch: 13| Step: 0
Training loss: 2.768476406383377
Validation loss: 3.2963218114054698

Epoch: 6| Step: 1
Training loss: 2.8870081362898694
Validation loss: 3.2876001418343965

Epoch: 6| Step: 2
Training loss: 2.551246121677888
Validation loss: 3.283693317059468

Epoch: 6| Step: 3
Training loss: 3.9323546684557065
Validation loss: 3.278525968452171

Epoch: 6| Step: 4
Training loss: 3.2574884267207653
Validation loss: 3.2754844612804184

Epoch: 6| Step: 5
Training loss: 4.108183597417814
Validation loss: 3.2736119452844994

Epoch: 6| Step: 6
Training loss: 3.94197639447426
Validation loss: 3.2729060420296783

Epoch: 6| Step: 7
Training loss: 3.552720953280035
Validation loss: 3.2707153407715386

Epoch: 6| Step: 8
Training loss: 3.679716527220966
Validation loss: 3.2679361795545327

Epoch: 6| Step: 9
Training loss: 3.268899398511354
Validation loss: 3.264932403465227

Epoch: 6| Step: 10
Training loss: 3.3044814458145204
Validation loss: 3.262728321404598

Epoch: 6| Step: 11
Training loss: 4.069260356907004
Validation loss: 3.2623960956288385

Epoch: 6| Step: 12
Training loss: 3.534219354226138
Validation loss: 3.2607046990361948

Epoch: 6| Step: 13
Training loss: 4.264374378466515
Validation loss: 3.2606930975107558

Epoch: 14| Step: 0
Training loss: 3.44307921812123
Validation loss: 3.258118246903145

Epoch: 6| Step: 1
Training loss: 2.8827208631057153
Validation loss: 3.2559777983169838

Epoch: 6| Step: 2
Training loss: 4.152326983958979
Validation loss: 3.2542763146166696

Epoch: 6| Step: 3
Training loss: 3.5627532333585274
Validation loss: 3.2521935751936026

Epoch: 6| Step: 4
Training loss: 3.6067852290815297
Validation loss: 3.2504409091821618

Epoch: 6| Step: 5
Training loss: 4.36416089813937
Validation loss: 3.24973167435031

Epoch: 6| Step: 6
Training loss: 2.6054145773041393
Validation loss: 3.2482142657956454

Epoch: 6| Step: 7
Training loss: 3.3813233654926242
Validation loss: 3.248135015043457

Epoch: 6| Step: 8
Training loss: 3.8363596262452724
Validation loss: 3.2461330767371868

Epoch: 6| Step: 9
Training loss: 2.965254804138558
Validation loss: 3.2451563277843

Epoch: 6| Step: 10
Training loss: 3.1814438376738554
Validation loss: 3.243819755439438

Epoch: 6| Step: 11
Training loss: 3.5003392191397467
Validation loss: 3.2469607357435613

Epoch: 6| Step: 12
Training loss: 3.5527049813672043
Validation loss: 3.2429089835247518

Epoch: 6| Step: 13
Training loss: 3.6074539951449696
Validation loss: 3.243427996159554

Epoch: 15| Step: 0
Training loss: 3.6423249430275417
Validation loss: 3.2422354168692427

Epoch: 6| Step: 1
Training loss: 4.2534513484243694
Validation loss: 3.239438048972924

Epoch: 6| Step: 2
Training loss: 3.5346825045136434
Validation loss: 3.2378545624206057

Epoch: 6| Step: 3
Training loss: 3.7494048600010133
Validation loss: 3.2377440102435133

Epoch: 6| Step: 4
Training loss: 3.4770585638451204
Validation loss: 3.2365634721814134

Epoch: 6| Step: 5
Training loss: 3.521601907183119
Validation loss: 3.234427244543104

Epoch: 6| Step: 6
Training loss: 3.4122032846979553
Validation loss: 3.2353675083952194

Epoch: 6| Step: 7
Training loss: 3.2058837919443013
Validation loss: 3.2325466259696674

Epoch: 6| Step: 8
Training loss: 3.3582666742289566
Validation loss: 3.230827723367869

Epoch: 6| Step: 9
Training loss: 3.260426449177034
Validation loss: 3.229636318470535

Epoch: 6| Step: 10
Training loss: 3.4219909369629034
Validation loss: 3.2288852363922236

Epoch: 6| Step: 11
Training loss: 3.1806351282937086
Validation loss: 3.2300398922446125

Epoch: 6| Step: 12
Training loss: 3.4565968730898025
Validation loss: 3.228304931319851

Epoch: 6| Step: 13
Training loss: 2.9883827341836247
Validation loss: 3.228894849776514

Epoch: 16| Step: 0
Training loss: 3.2755592043491273
Validation loss: 3.225557476197787

Epoch: 6| Step: 1
Training loss: 2.6490974616744842
Validation loss: 3.2269321730342266

Epoch: 6| Step: 2
Training loss: 3.078621761301267
Validation loss: 3.227848977894888

Epoch: 6| Step: 3
Training loss: 3.9492274434251495
Validation loss: 3.2254959286671525

Epoch: 6| Step: 4
Training loss: 2.9180661431621355
Validation loss: 3.222542619588122

Epoch: 6| Step: 5
Training loss: 3.8899100385918186
Validation loss: 3.2229735034392593

Epoch: 6| Step: 6
Training loss: 1.970864628656917
Validation loss: 3.2222808832079495

Epoch: 6| Step: 7
Training loss: 2.997321681683294
Validation loss: 3.220348383019098

Epoch: 6| Step: 8
Training loss: 4.11148539262747
Validation loss: 3.218916945524034

Epoch: 6| Step: 9
Training loss: 3.975067877039988
Validation loss: 3.218226735039619

Epoch: 6| Step: 10
Training loss: 4.061063541864921
Validation loss: 3.2177893031955644

Epoch: 6| Step: 11
Training loss: 3.626988753316863
Validation loss: 3.217270438302921

Epoch: 6| Step: 12
Training loss: 3.487745767226189
Validation loss: 3.2156330711059122

Epoch: 6| Step: 13
Training loss: 4.193965191159579
Validation loss: 3.2120261948855613

Epoch: 17| Step: 0
Training loss: 3.685026858890533
Validation loss: 3.2135592136544533

Epoch: 6| Step: 1
Training loss: 4.20112375030549
Validation loss: 3.21039835157444

Epoch: 6| Step: 2
Training loss: 2.5010946738205115
Validation loss: 3.210885478457268

Epoch: 6| Step: 3
Training loss: 3.71486839502866
Validation loss: 3.2101984317453414

Epoch: 6| Step: 4
Training loss: 3.615342264817048
Validation loss: 3.2078658329200533

Epoch: 6| Step: 5
Training loss: 3.715395015082922
Validation loss: 3.208058798691303

Epoch: 6| Step: 6
Training loss: 1.866603488647706
Validation loss: 3.206167947545648

Epoch: 6| Step: 7
Training loss: 4.147485196280891
Validation loss: 3.2032503613247094

Epoch: 6| Step: 8
Training loss: 3.6002200059422096
Validation loss: 3.207060691076141

Epoch: 6| Step: 9
Training loss: 2.9716167863249234
Validation loss: 3.202567362573072

Epoch: 6| Step: 10
Training loss: 2.9270906459585775
Validation loss: 3.1994278751391896

Epoch: 6| Step: 11
Training loss: 3.794910566359244
Validation loss: 3.207343538659069

Epoch: 6| Step: 12
Training loss: 3.5534618905759885
Validation loss: 3.1946956382980725

Epoch: 6| Step: 13
Training loss: 3.3011784963436437
Validation loss: 3.188947173357923

Epoch: 18| Step: 0
Training loss: 3.8421585385975128
Validation loss: 3.1837375109396775

Epoch: 6| Step: 1
Training loss: 3.1127943091296135
Validation loss: 3.183026421579766

Epoch: 6| Step: 2
Training loss: 3.0779967305523597
Validation loss: 3.180071204493668

Epoch: 6| Step: 3
Training loss: 4.194171203291484
Validation loss: 3.1799096559510107

Epoch: 6| Step: 4
Training loss: 3.2191428528083543
Validation loss: 3.17788488859775

Epoch: 6| Step: 5
Training loss: 2.780936234166648
Validation loss: 3.1806948937680555

Epoch: 6| Step: 6
Training loss: 3.412578897647059
Validation loss: 3.192946033608791

Epoch: 6| Step: 7
Training loss: 3.9067238482130127
Validation loss: 3.185074451367297

Epoch: 6| Step: 8
Training loss: 3.4293354522833006
Validation loss: 3.1739479289449113

Epoch: 6| Step: 9
Training loss: 4.454949684415507
Validation loss: 3.173529000068731

Epoch: 6| Step: 10
Training loss: 3.127637284373778
Validation loss: 3.175796729735267

Epoch: 6| Step: 11
Training loss: 2.5957801870556176
Validation loss: 3.171724779932379

Epoch: 6| Step: 12
Training loss: 3.591666504991945
Validation loss: 3.1692376416094237

Epoch: 6| Step: 13
Training loss: 2.2869202676542773
Validation loss: 3.167400662556159

Epoch: 19| Step: 0
Training loss: 3.62092255781282
Validation loss: 3.167384482946235

Epoch: 6| Step: 1
Training loss: 3.8531385682943005
Validation loss: 3.166597717475787

Epoch: 6| Step: 2
Training loss: 3.757774305248655
Validation loss: 3.1659303933440164

Epoch: 6| Step: 3
Training loss: 2.850253538934046
Validation loss: 3.1643080206557337

Epoch: 6| Step: 4
Training loss: 3.031355393927276
Validation loss: 3.161701100155471

Epoch: 6| Step: 5
Training loss: 2.924710616444199
Validation loss: 3.1611485650907913

Epoch: 6| Step: 6
Training loss: 4.203702638775029
Validation loss: 3.161474356224087

Epoch: 6| Step: 7
Training loss: 3.1464649770506967
Validation loss: 3.1588681803364573

Epoch: 6| Step: 8
Training loss: 3.1800048069947575
Validation loss: 3.16443196434463

Epoch: 6| Step: 9
Training loss: 3.6665993308617963
Validation loss: 3.158981700619101

Epoch: 6| Step: 10
Training loss: 3.4499792900016706
Validation loss: 3.1625946833279053

Epoch: 6| Step: 11
Training loss: 3.0085657538946715
Validation loss: 3.159746228294827

Epoch: 6| Step: 12
Training loss: 3.2826292499741188
Validation loss: 3.1550906746887093

Epoch: 6| Step: 13
Training loss: 3.704094739686901
Validation loss: 3.149543377656379

Epoch: 20| Step: 0
Training loss: 3.770686376809705
Validation loss: 3.1502897977303372

Epoch: 6| Step: 1
Training loss: 3.5832136858696435
Validation loss: 3.1467329527851655

Epoch: 6| Step: 2
Training loss: 3.4818157838912303
Validation loss: 3.144917020049466

Epoch: 6| Step: 3
Training loss: 3.0391203965504565
Validation loss: 3.1466503640199757

Epoch: 6| Step: 4
Training loss: 3.029531719418835
Validation loss: 3.1419715482297836

Epoch: 6| Step: 5
Training loss: 3.5465953565422255
Validation loss: 3.1426841594412065

Epoch: 6| Step: 6
Training loss: 4.144129468478714
Validation loss: 3.136516724883124

Epoch: 6| Step: 7
Training loss: 1.893146882155841
Validation loss: 3.1376237188659797

Epoch: 6| Step: 8
Training loss: 3.1450325323463035
Validation loss: 3.136842030763271

Epoch: 6| Step: 9
Training loss: 3.4512489711783427
Validation loss: 3.133760237057354

Epoch: 6| Step: 10
Training loss: 3.982231251568246
Validation loss: 3.1349224883577835

Epoch: 6| Step: 11
Training loss: 3.5459085231628116
Validation loss: 3.134434937796867

Epoch: 6| Step: 12
Training loss: 3.0855898118016816
Validation loss: 3.139662044251147

Epoch: 6| Step: 13
Training loss: 3.3340600334213417
Validation loss: 3.163271267797477

Epoch: 21| Step: 0
Training loss: 3.598315846369912
Validation loss: 3.128019012422241

Epoch: 6| Step: 1
Training loss: 2.9411891740636804
Validation loss: 3.129783316641413

Epoch: 6| Step: 2
Training loss: 3.841730595275364
Validation loss: 3.1362515889586544

Epoch: 6| Step: 3
Training loss: 2.3862918653057847
Validation loss: 3.1400930988578395

Epoch: 6| Step: 4
Training loss: 3.4285973139194437
Validation loss: 3.1392637316905194

Epoch: 6| Step: 5
Training loss: 3.559945646363989
Validation loss: 3.129425061940205

Epoch: 6| Step: 6
Training loss: 2.2913419551263545
Validation loss: 3.127167902606869

Epoch: 6| Step: 7
Training loss: 4.061361534815571
Validation loss: 3.1243242973015906

Epoch: 6| Step: 8
Training loss: 3.5840971967936994
Validation loss: 3.1241781044017443

Epoch: 6| Step: 9
Training loss: 3.163049455640187
Validation loss: 3.126792221508923

Epoch: 6| Step: 10
Training loss: 3.143122955946638
Validation loss: 3.133271337256702

Epoch: 6| Step: 11
Training loss: 2.8307001182003875
Validation loss: 3.1279283925370542

Epoch: 6| Step: 12
Training loss: 3.6648087707424573
Validation loss: 3.130456198238783

Epoch: 6| Step: 13
Training loss: 5.00564485433344
Validation loss: 3.1265968098786563

Epoch: 22| Step: 0
Training loss: 2.9455610013598315
Validation loss: 3.1206497742557198

Epoch: 6| Step: 1
Training loss: 3.0100029437788955
Validation loss: 3.120438145642304

Epoch: 6| Step: 2
Training loss: 3.5142776280929278
Validation loss: 3.1205742290532292

Epoch: 6| Step: 3
Training loss: 3.7513238477445183
Validation loss: 3.1244041071617454

Epoch: 6| Step: 4
Training loss: 3.6652430602865893
Validation loss: 3.1211864968920167

Epoch: 6| Step: 5
Training loss: 3.440863333753229
Validation loss: 3.125294853984763

Epoch: 6| Step: 6
Training loss: 3.4857268170169466
Validation loss: 3.130029964246588

Epoch: 6| Step: 7
Training loss: 2.80570842045295
Validation loss: 3.1224592680457395

Epoch: 6| Step: 8
Training loss: 3.7398138940375274
Validation loss: 3.11495806504743

Epoch: 6| Step: 9
Training loss: 3.807806409002104
Validation loss: 3.1105571595229113

Epoch: 6| Step: 10
Training loss: 2.4429725444436072
Validation loss: 3.110260734481798

Epoch: 6| Step: 11
Training loss: 3.7428297793761947
Validation loss: 3.10888812843233

Epoch: 6| Step: 12
Training loss: 3.229641754313635
Validation loss: 3.1095130095388757

Epoch: 6| Step: 13
Training loss: 3.4639986506364764
Validation loss: 3.1053573550238913

Epoch: 23| Step: 0
Training loss: 2.9983306054666046
Validation loss: 3.1063642456598632

Epoch: 6| Step: 1
Training loss: 3.5230769545991105
Validation loss: 3.1101107284226823

Epoch: 6| Step: 2
Training loss: 3.2436646554998356
Validation loss: 3.1057310097207265

Epoch: 6| Step: 3
Training loss: 3.2379796678023727
Validation loss: 3.109711446877167

Epoch: 6| Step: 4
Training loss: 3.2446281346994
Validation loss: 3.113045572138469

Epoch: 6| Step: 5
Training loss: 3.2273604396960134
Validation loss: 3.102619470759091

Epoch: 6| Step: 6
Training loss: 3.313295376852547
Validation loss: 3.102790152923677

Epoch: 6| Step: 7
Training loss: 3.300220112251097
Validation loss: 3.101429633565815

Epoch: 6| Step: 8
Training loss: 3.6094632488873413
Validation loss: 3.100503880690179

Epoch: 6| Step: 9
Training loss: 3.8898424947276546
Validation loss: 3.099961450081056

Epoch: 6| Step: 10
Training loss: 3.3444253114791636
Validation loss: 3.0985347737890843

Epoch: 6| Step: 11
Training loss: 3.0720930299580442
Validation loss: 3.098748699131818

Epoch: 6| Step: 12
Training loss: 3.5243215192027146
Validation loss: 3.0981659872179215

Epoch: 6| Step: 13
Training loss: 3.658229715766946
Validation loss: 3.1001569735637506

Epoch: 24| Step: 0
Training loss: 3.060474582346577
Validation loss: 3.0999748952737582

Epoch: 6| Step: 1
Training loss: 3.4509736000362237
Validation loss: 3.098262329753074

Epoch: 6| Step: 2
Training loss: 3.286744957146824
Validation loss: 3.0971828278357636

Epoch: 6| Step: 3
Training loss: 4.366594359597595
Validation loss: 3.093425355419613

Epoch: 6| Step: 4
Training loss: 2.953364609781621
Validation loss: 3.092004332596812

Epoch: 6| Step: 5
Training loss: 3.9297465932357953
Validation loss: 3.0894484859273317

Epoch: 6| Step: 6
Training loss: 3.335371983499074
Validation loss: 3.08848534844157

Epoch: 6| Step: 7
Training loss: 2.4902599378283545
Validation loss: 3.08653970795043

Epoch: 6| Step: 8
Training loss: 3.4897058873457776
Validation loss: 3.0853857383854355

Epoch: 6| Step: 9
Training loss: 3.5789823212998355
Validation loss: 3.084963777898902

Epoch: 6| Step: 10
Training loss: 3.5128318711292996
Validation loss: 3.086082860270568

Epoch: 6| Step: 11
Training loss: 2.968011543385147
Validation loss: 3.100752719239872

Epoch: 6| Step: 12
Training loss: 3.2633150682987004
Validation loss: 3.0941123282041745

Epoch: 6| Step: 13
Training loss: 2.5643188720332386
Validation loss: 3.0860995217808873

Epoch: 25| Step: 0
Training loss: 3.7934331167692106
Validation loss: 3.078644760621592

Epoch: 6| Step: 1
Training loss: 3.605091277724815
Validation loss: 3.0811986481840523

Epoch: 6| Step: 2
Training loss: 4.083805498085261
Validation loss: 3.0800766617639637

Epoch: 6| Step: 3
Training loss: 2.5187052947589805
Validation loss: 3.077698338985471

Epoch: 6| Step: 4
Training loss: 3.319751647254759
Validation loss: 3.0776971228441687

Epoch: 6| Step: 5
Training loss: 3.331945670885909
Validation loss: 3.077270659096277

Epoch: 6| Step: 6
Training loss: 3.329087955338501
Validation loss: 3.0804519598643334

Epoch: 6| Step: 7
Training loss: 3.060096576139036
Validation loss: 3.0807883832750202

Epoch: 6| Step: 8
Training loss: 3.56881515523621
Validation loss: 3.076910900197573

Epoch: 6| Step: 9
Training loss: 3.602025993130531
Validation loss: 3.0750685281935226

Epoch: 6| Step: 10
Training loss: 2.983982080288177
Validation loss: 3.0747192540780013

Epoch: 6| Step: 11
Training loss: 3.5815195032142846
Validation loss: 3.0786847128875086

Epoch: 6| Step: 12
Training loss: 3.0414988501949667
Validation loss: 3.0765287571399376

Epoch: 6| Step: 13
Training loss: 2.054305472594435
Validation loss: 3.0772119299199456

Epoch: 26| Step: 0
Training loss: 3.6883203919314815
Validation loss: 3.077637341409968

Epoch: 6| Step: 1
Training loss: 3.277618287583092
Validation loss: 3.0834219118036743

Epoch: 6| Step: 2
Training loss: 2.9626508199552384
Validation loss: 3.0896122419978456

Epoch: 6| Step: 3
Training loss: 3.6646324641650097
Validation loss: 3.094517748978676

Epoch: 6| Step: 4
Training loss: 3.3197443217905422
Validation loss: 3.0995882214000785

Epoch: 6| Step: 5
Training loss: 2.8871833726754548
Validation loss: 3.1056380612915158

Epoch: 6| Step: 6
Training loss: 2.955289501589989
Validation loss: 3.1301730811906854

Epoch: 6| Step: 7
Training loss: 3.3119326411506385
Validation loss: 3.0865159680133583

Epoch: 6| Step: 8
Training loss: 3.897123004329792
Validation loss: 3.0694356847464315

Epoch: 6| Step: 9
Training loss: 3.3165313373605163
Validation loss: 3.0695200244964718

Epoch: 6| Step: 10
Training loss: 3.9542851008588786
Validation loss: 3.084890825853422

Epoch: 6| Step: 11
Training loss: 3.5284357250014216
Validation loss: 3.0907164403628213

Epoch: 6| Step: 12
Training loss: 2.4706525593886863
Validation loss: 3.068917524186406

Epoch: 6| Step: 13
Training loss: 3.282132130075647
Validation loss: 3.065413844457213

Epoch: 27| Step: 0
Training loss: 2.807110518141309
Validation loss: 3.0696586942500974

Epoch: 6| Step: 1
Training loss: 2.875235838131879
Validation loss: 3.0816756140415653

Epoch: 6| Step: 2
Training loss: 3.758240863708503
Validation loss: 3.087596911020035

Epoch: 6| Step: 3
Training loss: 3.258911532900588
Validation loss: 3.068308687616812

Epoch: 6| Step: 4
Training loss: 4.136039065680114
Validation loss: 3.0640715065486495

Epoch: 6| Step: 5
Training loss: 2.995451339823107
Validation loss: 3.0639229491289566

Epoch: 6| Step: 6
Training loss: 3.1780671811166026
Validation loss: 3.0701423670316528

Epoch: 6| Step: 7
Training loss: 3.0488967838901857
Validation loss: 3.08263129201992

Epoch: 6| Step: 8
Training loss: 3.4280749029569355
Validation loss: 3.053010517420436

Epoch: 6| Step: 9
Training loss: 3.1371094114797344
Validation loss: 3.055588246304575

Epoch: 6| Step: 10
Training loss: 3.86297081605541
Validation loss: 3.051893982177103

Epoch: 6| Step: 11
Training loss: 3.4346520850995534
Validation loss: 3.0511458828692524

Epoch: 6| Step: 12
Training loss: 2.678481472866348
Validation loss: 3.053686918839252

Epoch: 6| Step: 13
Training loss: 4.00329882968726
Validation loss: 3.0511250116773674

Epoch: 28| Step: 0
Training loss: 3.6061058927994623
Validation loss: 3.0503779256014507

Epoch: 6| Step: 1
Training loss: 2.7641746036790122
Validation loss: 3.0493394248300687

Epoch: 6| Step: 2
Training loss: 3.859557977578209
Validation loss: 3.059806475498591

Epoch: 6| Step: 3
Training loss: 2.4884889716574086
Validation loss: 3.0527068114512343

Epoch: 6| Step: 4
Training loss: 2.8743938968150924
Validation loss: 3.0484906553539677

Epoch: 6| Step: 5
Training loss: 3.374008174259977
Validation loss: 3.0477490993178793

Epoch: 6| Step: 6
Training loss: 3.6992318979933976
Validation loss: 3.045939291876618

Epoch: 6| Step: 7
Training loss: 3.4414170575702885
Validation loss: 3.0462075469214223

Epoch: 6| Step: 8
Training loss: 3.251397492650261
Validation loss: 3.049254873288363

Epoch: 6| Step: 9
Training loss: 3.181652914436824
Validation loss: 3.045601773175845

Epoch: 6| Step: 10
Training loss: 2.4833849967685824
Validation loss: 3.0439799389176168

Epoch: 6| Step: 11
Training loss: 3.735502958533221
Validation loss: 3.049677380585954

Epoch: 6| Step: 12
Training loss: 3.539179583164325
Validation loss: 3.048497917824698

Epoch: 6| Step: 13
Training loss: 4.134319528220549
Validation loss: 3.0452433560745145

Epoch: 29| Step: 0
Training loss: 3.0773199742433275
Validation loss: 3.0460450562116566

Epoch: 6| Step: 1
Training loss: 3.3807782758994205
Validation loss: 3.0394847869726336

Epoch: 6| Step: 2
Training loss: 3.227273266996175
Validation loss: 3.0395187388496816

Epoch: 6| Step: 3
Training loss: 3.6751917367339915
Validation loss: 3.0387141121377645

Epoch: 6| Step: 4
Training loss: 3.318666871604847
Validation loss: 3.0360546019198527

Epoch: 6| Step: 5
Training loss: 3.465094762609991
Validation loss: 3.03723447223068

Epoch: 6| Step: 6
Training loss: 3.2051965481245257
Validation loss: 3.0367323318878796

Epoch: 6| Step: 7
Training loss: 3.365595253022194
Validation loss: 3.0402431238834584

Epoch: 6| Step: 8
Training loss: 3.0138555682128105
Validation loss: 3.0789507960677955

Epoch: 6| Step: 9
Training loss: 3.555712608670243
Validation loss: 3.0856530565828764

Epoch: 6| Step: 10
Training loss: 3.437390273683761
Validation loss: 3.089399784272163

Epoch: 6| Step: 11
Training loss: 2.742334432550781
Validation loss: 3.087496640354385

Epoch: 6| Step: 12
Training loss: 3.142233365566861
Validation loss: 3.083317628292228

Epoch: 6| Step: 13
Training loss: 4.125929294292852
Validation loss: 3.0802026506649844

Epoch: 30| Step: 0
Training loss: 3.0412787272785553
Validation loss: 3.0769687544581172

Epoch: 6| Step: 1
Training loss: 3.4233420375674934
Validation loss: 3.0774746408658333

Epoch: 6| Step: 2
Training loss: 3.5318627290068694
Validation loss: 3.077628524199885

Epoch: 6| Step: 3
Training loss: 3.1740042018465955
Validation loss: 3.0751395707328584

Epoch: 6| Step: 4
Training loss: 2.7902048373484685
Validation loss: 3.074666394447899

Epoch: 6| Step: 5
Training loss: 3.4332751580899
Validation loss: 3.0774260062976535

Epoch: 6| Step: 6
Training loss: 3.622225258506745
Validation loss: 3.0726386565849073

Epoch: 6| Step: 7
Training loss: 3.22540218004243
Validation loss: 3.073031896589729

Epoch: 6| Step: 8
Training loss: 2.9158655065386125
Validation loss: 3.0708220709590037

Epoch: 6| Step: 9
Training loss: 3.2139570976484584
Validation loss: 3.069813682567705

Epoch: 6| Step: 10
Training loss: 3.407650161087744
Validation loss: 3.067408686300865

Epoch: 6| Step: 11
Training loss: 3.7117426912229745
Validation loss: 3.065595137196972

Epoch: 6| Step: 12
Training loss: 3.8961671628397845
Validation loss: 3.0625444977813014

Epoch: 6| Step: 13
Training loss: 2.966728084085622
Validation loss: 3.0590757220408222

Epoch: 31| Step: 0
Training loss: 3.183650066603117
Validation loss: 3.021094302374809

Epoch: 6| Step: 1
Training loss: 2.7671816480629645
Validation loss: 3.0172748977621535

Epoch: 6| Step: 2
Training loss: 2.493152778262262
Validation loss: 3.01498205263774

Epoch: 6| Step: 3
Training loss: 3.029827767440586
Validation loss: 3.0138103268894816

Epoch: 6| Step: 4
Training loss: 2.177720580463597
Validation loss: 3.0130269606099147

Epoch: 6| Step: 5
Training loss: 4.751440733202688
Validation loss: 3.014915770137754

Epoch: 6| Step: 6
Training loss: 2.8825837331423108
Validation loss: 3.0152053740829907

Epoch: 6| Step: 7
Training loss: 3.3949470221497013
Validation loss: 3.0154684753959056

Epoch: 6| Step: 8
Training loss: 3.801381266672278
Validation loss: 3.0159296707220564

Epoch: 6| Step: 9
Training loss: 3.283074298716237
Validation loss: 3.0177623314098985

Epoch: 6| Step: 10
Training loss: 3.3401752508179503
Validation loss: 3.0178767286093025

Epoch: 6| Step: 11
Training loss: 3.0701624709885635
Validation loss: 3.017427045772477

Epoch: 6| Step: 12
Training loss: 3.699429112286913
Validation loss: 3.0176214883860353

Epoch: 6| Step: 13
Training loss: 3.5521154467491187
Validation loss: 3.014638210637659

Epoch: 32| Step: 0
Training loss: 3.2468745535445436
Validation loss: 3.0205533948502676

Epoch: 6| Step: 1
Training loss: 3.8707362682599356
Validation loss: 3.0191729238700478

Epoch: 6| Step: 2
Training loss: 2.804022324934391
Validation loss: 3.008691129614249

Epoch: 6| Step: 3
Training loss: 3.330775392085815
Validation loss: 3.008207701604186

Epoch: 6| Step: 4
Training loss: 3.051683905355062
Validation loss: 3.0097795727698156

Epoch: 6| Step: 5
Training loss: 2.7391272529046513
Validation loss: 3.0064137221812937

Epoch: 6| Step: 6
Training loss: 2.8395357870112807
Validation loss: 3.004398772559406

Epoch: 6| Step: 7
Training loss: 3.9560062327321384
Validation loss: 3.0053482544882684

Epoch: 6| Step: 8
Training loss: 3.9137073591767084
Validation loss: 3.0053580966878117

Epoch: 6| Step: 9
Training loss: 3.106808470599023
Validation loss: 3.005553604986752

Epoch: 6| Step: 10
Training loss: 3.079654526594473
Validation loss: 3.0066179750046516

Epoch: 6| Step: 11
Training loss: 3.971667561490279
Validation loss: 3.013391149290015

Epoch: 6| Step: 12
Training loss: 2.5143846569781383
Validation loss: 3.0032829810370085

Epoch: 6| Step: 13
Training loss: 2.9470389489433892
Validation loss: 3.001988165749888

Epoch: 33| Step: 0
Training loss: 3.5521934395259955
Validation loss: 3.0063323968093023

Epoch: 6| Step: 1
Training loss: 3.182528189918585
Validation loss: 2.998629503928125

Epoch: 6| Step: 2
Training loss: 2.8045599863292185
Validation loss: 2.9945577664766083

Epoch: 6| Step: 3
Training loss: 2.867713318716626
Validation loss: 2.995086970097396

Epoch: 6| Step: 4
Training loss: 3.741577608426415
Validation loss: 2.9962650741077557

Epoch: 6| Step: 5
Training loss: 3.235227610674571
Validation loss: 2.9950149848071863

Epoch: 6| Step: 6
Training loss: 3.3559704939462436
Validation loss: 2.9953852422210216

Epoch: 6| Step: 7
Training loss: 3.354480531275236
Validation loss: 2.994321427345666

Epoch: 6| Step: 8
Training loss: 3.4001442317663475
Validation loss: 2.9937485005984694

Epoch: 6| Step: 9
Training loss: 2.8620419598055338
Validation loss: 2.9912529638905556

Epoch: 6| Step: 10
Training loss: 3.994586022499691
Validation loss: 2.9921866997691744

Epoch: 6| Step: 11
Training loss: 2.845529188339901
Validation loss: 2.992038490588195

Epoch: 6| Step: 12
Training loss: 3.4955369559238667
Validation loss: 2.9918196188632873

Epoch: 6| Step: 13
Training loss: 2.5447810639826636
Validation loss: 2.9905973274602635

Epoch: 34| Step: 0
Training loss: 2.998714171462313
Validation loss: 2.988828800445628

Epoch: 6| Step: 1
Training loss: 3.464982469742812
Validation loss: 2.9885635932128265

Epoch: 6| Step: 2
Training loss: 3.3368428987143948
Validation loss: 2.989328549692402

Epoch: 6| Step: 3
Training loss: 3.2808781004365764
Validation loss: 2.9884116322159655

Epoch: 6| Step: 4
Training loss: 3.6198354302191857
Validation loss: 2.9877351522865907

Epoch: 6| Step: 5
Training loss: 3.9155696928923973
Validation loss: 2.983866456645603

Epoch: 6| Step: 6
Training loss: 3.1323497554127595
Validation loss: 2.9855295568094857

Epoch: 6| Step: 7
Training loss: 3.14345745447054
Validation loss: 2.9806611586268716

Epoch: 6| Step: 8
Training loss: 2.9870831250583403
Validation loss: 2.982209243424271

Epoch: 6| Step: 9
Training loss: 2.493093869886849
Validation loss: 2.984679486775895

Epoch: 6| Step: 10
Training loss: 3.928470491375916
Validation loss: 2.9959790960747705

Epoch: 6| Step: 11
Training loss: 3.213549217738714
Validation loss: 3.000098466111787

Epoch: 6| Step: 12
Training loss: 2.4647961595296732
Validation loss: 3.0051105459400977

Epoch: 6| Step: 13
Training loss: 3.5728621112599153
Validation loss: 2.994081024702017

Epoch: 35| Step: 0
Training loss: 3.7381003723710924
Validation loss: 2.9789977682299615

Epoch: 6| Step: 1
Training loss: 2.2950299176694946
Validation loss: 2.9750770180407367

Epoch: 6| Step: 2
Training loss: 3.5451376268710684
Validation loss: 2.975832317453421

Epoch: 6| Step: 3
Training loss: 3.593186176686311
Validation loss: 2.9782118130132598

Epoch: 6| Step: 4
Training loss: 2.942371144289012
Validation loss: 2.982606043674498

Epoch: 6| Step: 5
Training loss: 3.5555676387210675
Validation loss: 2.9831889838460532

Epoch: 6| Step: 6
Training loss: 3.219007018855188
Validation loss: 2.976667885538649

Epoch: 6| Step: 7
Training loss: 3.5674843970788266
Validation loss: 2.9742211057546424

Epoch: 6| Step: 8
Training loss: 3.6552594791261006
Validation loss: 2.972955996475428

Epoch: 6| Step: 9
Training loss: 3.401941216500859
Validation loss: 2.9717888572861937

Epoch: 6| Step: 10
Training loss: 3.384633761135979
Validation loss: 2.9717177716026613

Epoch: 6| Step: 11
Training loss: 2.5737101351970213
Validation loss: 2.9705225895924907

Epoch: 6| Step: 12
Training loss: 2.9820379723344947
Validation loss: 2.9701908114760522

Epoch: 6| Step: 13
Training loss: 2.2650141451564467
Validation loss: 2.967392475169092

Epoch: 36| Step: 0
Training loss: 2.8813304037596734
Validation loss: 2.978149665286452

Epoch: 6| Step: 1
Training loss: 3.444367778772583
Validation loss: 3.053767369275886

Epoch: 6| Step: 2
Training loss: 3.742631539458423
Validation loss: 3.0156151420019404

Epoch: 6| Step: 3
Training loss: 3.2415725308620438
Validation loss: 2.9891452274639847

Epoch: 6| Step: 4
Training loss: 2.9776708586873366
Validation loss: 2.9801076471030052

Epoch: 6| Step: 5
Training loss: 3.5023472952925814
Validation loss: 2.9769432826188096

Epoch: 6| Step: 6
Training loss: 2.7138699109097075
Validation loss: 2.972181429228602

Epoch: 6| Step: 7
Training loss: 2.8283185523805896
Validation loss: 2.9719221575532666

Epoch: 6| Step: 8
Training loss: 3.6496957573747055
Validation loss: 2.974721850032706

Epoch: 6| Step: 9
Training loss: 3.36714586555249
Validation loss: 2.970146126388075

Epoch: 6| Step: 10
Training loss: 3.1010286654882258
Validation loss: 2.970659383959437

Epoch: 6| Step: 11
Training loss: 3.024381110825093
Validation loss: 2.972374917680961

Epoch: 6| Step: 12
Training loss: 3.087030531059715
Validation loss: 2.968325119831702

Epoch: 6| Step: 13
Training loss: 4.162366453668983
Validation loss: 2.971765077130907

Epoch: 37| Step: 0
Training loss: 3.6758023949561185
Validation loss: 2.969110211645982

Epoch: 6| Step: 1
Training loss: 2.515853492358692
Validation loss: 2.9576440349261475

Epoch: 6| Step: 2
Training loss: 3.3317109610313507
Validation loss: 2.9546197590604906

Epoch: 6| Step: 3
Training loss: 3.087199974154561
Validation loss: 2.9577977118632655

Epoch: 6| Step: 4
Training loss: 3.157621482269996
Validation loss: 2.9547258803734002

Epoch: 6| Step: 5
Training loss: 4.185766288214819
Validation loss: 2.9567037499575335

Epoch: 6| Step: 6
Training loss: 2.9916446681440245
Validation loss: 2.958336029559901

Epoch: 6| Step: 7
Training loss: 2.158541691663531
Validation loss: 2.9583412065160015

Epoch: 6| Step: 8
Training loss: 3.6760646860784307
Validation loss: 2.957310269307844

Epoch: 6| Step: 9
Training loss: 2.8762282360170275
Validation loss: 2.9624777526560107

Epoch: 6| Step: 10
Training loss: 3.4730763991125024
Validation loss: 2.9626266895469504

Epoch: 6| Step: 11
Training loss: 3.2971299782454473
Validation loss: 2.9577220133181017

Epoch: 6| Step: 12
Training loss: 3.2746439965961733
Validation loss: 2.951059847173267

Epoch: 6| Step: 13
Training loss: 3.188774452489561
Validation loss: 2.959161708016035

Epoch: 38| Step: 0
Training loss: 3.1299074930774182
Validation loss: 2.9560912332205653

Epoch: 6| Step: 1
Training loss: 3.4243343346818738
Validation loss: 2.953974210034263

Epoch: 6| Step: 2
Training loss: 3.739303465051688
Validation loss: 2.9577721169298417

Epoch: 6| Step: 3
Training loss: 3.136012395659102
Validation loss: 2.9535383395425585

Epoch: 6| Step: 4
Training loss: 3.094925474092316
Validation loss: 2.9564286483852804

Epoch: 6| Step: 5
Training loss: 2.9109826060397572
Validation loss: 2.9707662526298333

Epoch: 6| Step: 6
Training loss: 2.987602046995372
Validation loss: 2.976539276474285

Epoch: 6| Step: 7
Training loss: 3.3165166721899744
Validation loss: 2.9638456221204423

Epoch: 6| Step: 8
Training loss: 2.996475692734456
Validation loss: 2.942639677419479

Epoch: 6| Step: 9
Training loss: 2.429591333381236
Validation loss: 2.9444274364616647

Epoch: 6| Step: 10
Training loss: 3.814665507680305
Validation loss: 2.968662791328615

Epoch: 6| Step: 11
Training loss: 4.076725862270299
Validation loss: 2.946361012282003

Epoch: 6| Step: 12
Training loss: 3.3512807874392987
Validation loss: 2.935368833256433

Epoch: 6| Step: 13
Training loss: 1.6808934340593453
Validation loss: 2.928194424504681

Epoch: 39| Step: 0
Training loss: 3.384318168634967
Validation loss: 2.9306652364336103

Epoch: 6| Step: 1
Training loss: 3.288938107709352
Validation loss: 2.9351522139324224

Epoch: 6| Step: 2
Training loss: 3.2864993294860723
Validation loss: 2.963497580586683

Epoch: 6| Step: 3
Training loss: 2.958665121752264
Validation loss: 2.957221170645152

Epoch: 6| Step: 4
Training loss: 3.2786357819895735
Validation loss: 2.924806479099923

Epoch: 6| Step: 5
Training loss: 2.8590070977671616
Validation loss: 2.910002478042527

Epoch: 6| Step: 6
Training loss: 3.084031378283355
Validation loss: 2.90959174007964

Epoch: 6| Step: 7
Training loss: 2.876552494327978
Validation loss: 2.9119160375469217

Epoch: 6| Step: 8
Training loss: 3.545668611088493
Validation loss: 2.9121238142686

Epoch: 6| Step: 9
Training loss: 2.7796861345138755
Validation loss: 2.9203626135919207

Epoch: 6| Step: 10
Training loss: 3.579698641362995
Validation loss: 2.914043502659918

Epoch: 6| Step: 11
Training loss: 3.742670016150566
Validation loss: 2.9013402076101538

Epoch: 6| Step: 12
Training loss: 3.0834346617123765
Validation loss: 2.901039043264863

Epoch: 6| Step: 13
Training loss: 3.042025261908881
Validation loss: 2.8959252558386783

Epoch: 40| Step: 0
Training loss: 2.1481953432421017
Validation loss: 2.8967486162886096

Epoch: 6| Step: 1
Training loss: 4.097848951319708
Validation loss: 2.896527441242569

Epoch: 6| Step: 2
Training loss: 2.4915567873539177
Validation loss: 2.89680414547365

Epoch: 6| Step: 3
Training loss: 3.3230942506284062
Validation loss: 2.896931597941983

Epoch: 6| Step: 4
Training loss: 3.2377977919136334
Validation loss: 2.906511324785078

Epoch: 6| Step: 5
Training loss: 3.6674429909735498
Validation loss: 2.901428568598061

Epoch: 6| Step: 6
Training loss: 2.2307666372542143
Validation loss: 2.90475075350412

Epoch: 6| Step: 7
Training loss: 3.2768295302975226
Validation loss: 2.8982038833583394

Epoch: 6| Step: 8
Training loss: 2.9972897048752514
Validation loss: 2.8944467899211

Epoch: 6| Step: 9
Training loss: 3.482818666489466
Validation loss: 2.892062481684527

Epoch: 6| Step: 10
Training loss: 2.636932228771168
Validation loss: 2.890456879706361

Epoch: 6| Step: 11
Training loss: 3.2444786708658024
Validation loss: 2.899323169606524

Epoch: 6| Step: 12
Training loss: 3.199018870387179
Validation loss: 2.9044834042334475

Epoch: 6| Step: 13
Training loss: 4.424594864914519
Validation loss: 2.9126499184092447

Epoch: 41| Step: 0
Training loss: 3.3456170404497367
Validation loss: 2.888633306604793

Epoch: 6| Step: 1
Training loss: 3.1630144809001868
Validation loss: 2.887161783263416

Epoch: 6| Step: 2
Training loss: 3.1609359552640814
Validation loss: 2.8860571771444103

Epoch: 6| Step: 3
Training loss: 3.1325809840323355
Validation loss: 2.8936593538818656

Epoch: 6| Step: 4
Training loss: 2.927830791858019
Validation loss: 2.8933018664851113

Epoch: 6| Step: 5
Training loss: 3.3634301129403283
Validation loss: 2.885654902675025

Epoch: 6| Step: 6
Training loss: 3.339352862773603
Validation loss: 2.883171718344603

Epoch: 6| Step: 7
Training loss: 3.4191275937287373
Validation loss: 2.8809411011052135

Epoch: 6| Step: 8
Training loss: 3.41145165517993
Validation loss: 2.881619921933294

Epoch: 6| Step: 9
Training loss: 2.0854953482993723
Validation loss: 2.889438851177083

Epoch: 6| Step: 10
Training loss: 3.018048829337771
Validation loss: 2.902067793917813

Epoch: 6| Step: 11
Training loss: 3.7633014015575266
Validation loss: 2.8989103171695354

Epoch: 6| Step: 12
Training loss: 3.3868767196614304
Validation loss: 2.8955988694254824

Epoch: 6| Step: 13
Training loss: 2.4351666359409174
Validation loss: 2.881797743765585

Epoch: 42| Step: 0
Training loss: 2.7595931834174157
Validation loss: 2.87471438108678

Epoch: 6| Step: 1
Training loss: 3.1734939727942337
Validation loss: 2.877274968991978

Epoch: 6| Step: 2
Training loss: 3.274633949148443
Validation loss: 2.8758912544169126

Epoch: 6| Step: 3
Training loss: 3.6018111335510725
Validation loss: 2.9035188409967914

Epoch: 6| Step: 4
Training loss: 3.3357756885887992
Validation loss: 2.942028357746317

Epoch: 6| Step: 5
Training loss: 3.6312279968120347
Validation loss: 2.8760006212396445

Epoch: 6| Step: 6
Training loss: 3.5482822936905363
Validation loss: 2.874238370334566

Epoch: 6| Step: 7
Training loss: 2.54509537194002
Validation loss: 2.877927244052796

Epoch: 6| Step: 8
Training loss: 3.2830041465396125
Validation loss: 2.884865273021449

Epoch: 6| Step: 9
Training loss: 3.2330331276288686
Validation loss: 2.8969598064820445

Epoch: 6| Step: 10
Training loss: 3.1182978667364925
Validation loss: 2.9089672781861693

Epoch: 6| Step: 11
Training loss: 2.8149551695646835
Validation loss: 2.9667672816565975

Epoch: 6| Step: 12
Training loss: 3.1830959937277488
Validation loss: 2.992497880888846

Epoch: 6| Step: 13
Training loss: 3.0672439888694636
Validation loss: 2.9648865617194113

Epoch: 43| Step: 0
Training loss: 3.6005946780813356
Validation loss: 2.917135909930487

Epoch: 6| Step: 1
Training loss: 2.8686361784783894
Validation loss: 2.872094527586759

Epoch: 6| Step: 2
Training loss: 3.3165311935846495
Validation loss: 2.87492888595851

Epoch: 6| Step: 3
Training loss: 2.521923827652308
Validation loss: 2.8832550469484595

Epoch: 6| Step: 4
Training loss: 2.613830964755926
Validation loss: 2.924679952984255

Epoch: 6| Step: 5
Training loss: 3.10282307334387
Validation loss: 2.962424817474101

Epoch: 6| Step: 6
Training loss: 3.0563367211143526
Validation loss: 2.9865468712601944

Epoch: 6| Step: 7
Training loss: 3.4610780295608743
Validation loss: 2.9554024117525524

Epoch: 6| Step: 8
Training loss: 4.262419561706652
Validation loss: 2.9081865876286415

Epoch: 6| Step: 9
Training loss: 3.2917168207009464
Validation loss: 2.874338386884207

Epoch: 6| Step: 10
Training loss: 3.0145669771043804
Validation loss: 2.873242030250451

Epoch: 6| Step: 11
Training loss: 3.129247753922998
Validation loss: 2.868600275583428

Epoch: 6| Step: 12
Training loss: 3.2172348752639657
Validation loss: 2.872937452844062

Epoch: 6| Step: 13
Training loss: 2.5433848050943193
Validation loss: 2.8819197334949616

Epoch: 44| Step: 0
Training loss: 3.2636464527174143
Validation loss: 2.9603645726495795

Epoch: 6| Step: 1
Training loss: 2.759864108845215
Validation loss: 2.8861416313597927

Epoch: 6| Step: 2
Training loss: 3.155690511838312
Validation loss: 2.8760964726831495

Epoch: 6| Step: 3
Training loss: 3.2216070143269713
Validation loss: 2.8716169768846798

Epoch: 6| Step: 4
Training loss: 3.574276916364136
Validation loss: 2.871454930756074

Epoch: 6| Step: 5
Training loss: 2.669662005287026
Validation loss: 2.871739909718923

Epoch: 6| Step: 6
Training loss: 3.4451501509633955
Validation loss: 2.8659068079490653

Epoch: 6| Step: 7
Training loss: 3.862821700146356
Validation loss: 2.8669115454394616

Epoch: 6| Step: 8
Training loss: 2.5571909546039198
Validation loss: 2.865413506248651

Epoch: 6| Step: 9
Training loss: 3.1335150104636136
Validation loss: 2.8662373912004395

Epoch: 6| Step: 10
Training loss: 3.1691714636657453
Validation loss: 2.8696373213372284

Epoch: 6| Step: 11
Training loss: 3.352941838334277
Validation loss: 2.8829503624883475

Epoch: 6| Step: 12
Training loss: 3.144523819624373
Validation loss: 2.8914868950864254

Epoch: 6| Step: 13
Training loss: 2.5359797616987416
Validation loss: 2.8945246357027314

Epoch: 45| Step: 0
Training loss: 3.016190708050322
Validation loss: 3.023413841174282

Epoch: 6| Step: 1
Training loss: 2.8499515529329513
Validation loss: 3.1530669984087005

Epoch: 6| Step: 2
Training loss: 3.492941550957554
Validation loss: 3.181788394838093

Epoch: 6| Step: 3
Training loss: 3.4938719098653843
Validation loss: 3.1206836267986042

Epoch: 6| Step: 4
Training loss: 3.3149009496467974
Validation loss: 3.0489881316025484

Epoch: 6| Step: 5
Training loss: 4.140748450400264
Validation loss: 2.964720834941454

Epoch: 6| Step: 6
Training loss: 3.208472575018904
Validation loss: 2.8773553401682666

Epoch: 6| Step: 7
Training loss: 2.756437396471486
Validation loss: 2.852787906069737

Epoch: 6| Step: 8
Training loss: 3.05201983250165
Validation loss: 2.8802949397299753

Epoch: 6| Step: 9
Training loss: 2.992635588796936
Validation loss: 2.9875899856147248

Epoch: 6| Step: 10
Training loss: 4.258741252992077
Validation loss: 3.0649023848050225

Epoch: 6| Step: 11
Training loss: 3.5046207715849245
Validation loss: 2.9582025200638897

Epoch: 6| Step: 12
Training loss: 2.5339055201523584
Validation loss: 2.876808120466898

Epoch: 6| Step: 13
Training loss: 2.594978684942359
Validation loss: 2.8516266855345203

Epoch: 46| Step: 0
Training loss: 2.6954818008988766
Validation loss: 2.8481328149566023

Epoch: 6| Step: 1
Training loss: 3.561639514534583
Validation loss: 2.8487970355591776

Epoch: 6| Step: 2
Training loss: 4.001827537759189
Validation loss: 2.845793334216685

Epoch: 6| Step: 3
Training loss: 2.715180695845138
Validation loss: 2.858846324056151

Epoch: 6| Step: 4
Training loss: 3.318735838893987
Validation loss: 2.8590971131801806

Epoch: 6| Step: 5
Training loss: 2.8579276335452484
Validation loss: 2.8961280914129235

Epoch: 6| Step: 6
Training loss: 2.2360095467679257
Validation loss: 2.902308745487732

Epoch: 6| Step: 7
Training loss: 3.3531166154769063
Validation loss: 2.8941250467171735

Epoch: 6| Step: 8
Training loss: 3.2459118880501596
Validation loss: 2.8571835328208377

Epoch: 6| Step: 9
Training loss: 3.210587753962055
Validation loss: 2.8485884515849684

Epoch: 6| Step: 10
Training loss: 3.240618148987756
Validation loss: 2.8464314033215667

Epoch: 6| Step: 11
Training loss: 3.526936960685007
Validation loss: 2.8468841028491774

Epoch: 6| Step: 12
Training loss: 3.0583075027691606
Validation loss: 2.8467344156480805

Epoch: 6| Step: 13
Training loss: 2.277254341686707
Validation loss: 2.843641973005719

Epoch: 47| Step: 0
Training loss: 2.9395248252260293
Validation loss: 2.845650644578776

Epoch: 6| Step: 1
Training loss: 2.5176232972394774
Validation loss: 2.843486082642348

Epoch: 6| Step: 2
Training loss: 3.428236113341075
Validation loss: 2.840280812257497

Epoch: 6| Step: 3
Training loss: 2.961141695012154
Validation loss: 2.842121235238832

Epoch: 6| Step: 4
Training loss: 3.441798903270172
Validation loss: 2.844299411179258

Epoch: 6| Step: 5
Training loss: 3.5132074478537803
Validation loss: 2.8389628063024746

Epoch: 6| Step: 6
Training loss: 3.1186516939314535
Validation loss: 2.8378736200754684

Epoch: 6| Step: 7
Training loss: 2.459893577413651
Validation loss: 2.8351025664335507

Epoch: 6| Step: 8
Training loss: 3.4051576315177243
Validation loss: 2.8356057539163944

Epoch: 6| Step: 9
Training loss: 3.030499709566899
Validation loss: 2.8335191899772187

Epoch: 6| Step: 10
Training loss: 3.634626432005349
Validation loss: 2.8327714886566127

Epoch: 6| Step: 11
Training loss: 3.092676149746674
Validation loss: 2.8299051466868668

Epoch: 6| Step: 12
Training loss: 3.1334906626492693
Validation loss: 2.8303069854664744

Epoch: 6| Step: 13
Training loss: 3.0725457608793647
Validation loss: 2.8314646367997396

Epoch: 48| Step: 0
Training loss: 2.2582048649394353
Validation loss: 2.8291568390997264

Epoch: 6| Step: 1
Training loss: 3.046511584396538
Validation loss: 2.8332028645462586

Epoch: 6| Step: 2
Training loss: 2.9967681642966633
Validation loss: 2.830700500387207

Epoch: 6| Step: 3
Training loss: 3.396889660758884
Validation loss: 2.8346147052574384

Epoch: 6| Step: 4
Training loss: 2.7808865941973213
Validation loss: 2.8321732861321878

Epoch: 6| Step: 5
Training loss: 2.7341955507522533
Validation loss: 2.835906064704424

Epoch: 6| Step: 6
Training loss: 2.8249087091059626
Validation loss: 2.83711858508503

Epoch: 6| Step: 7
Training loss: 3.7837937051134864
Validation loss: 2.844815542858834

Epoch: 6| Step: 8
Training loss: 3.3631712289641205
Validation loss: 2.853345823146582

Epoch: 6| Step: 9
Training loss: 3.620892532502669
Validation loss: 2.8565209468521413

Epoch: 6| Step: 10
Training loss: 2.69234349468027
Validation loss: 2.8351276266988847

Epoch: 6| Step: 11
Training loss: 3.063442163149631
Validation loss: 2.825395046878462

Epoch: 6| Step: 12
Training loss: 3.209272635219384
Validation loss: 2.824060199743888

Epoch: 6| Step: 13
Training loss: 4.17918298831591
Validation loss: 2.8247061958247586

Epoch: 49| Step: 0
Training loss: 3.21358215867081
Validation loss: 2.8207841581663997

Epoch: 6| Step: 1
Training loss: 3.394321097134038
Validation loss: 2.8281058024872836

Epoch: 6| Step: 2
Training loss: 2.8937893430206327
Validation loss: 2.833055535679755

Epoch: 6| Step: 3
Training loss: 3.6713409684794924
Validation loss: 2.83315642605046

Epoch: 6| Step: 4
Training loss: 3.1735973473789985
Validation loss: 2.826697650692401

Epoch: 6| Step: 5
Training loss: 3.3037385051410415
Validation loss: 2.817361791058878

Epoch: 6| Step: 6
Training loss: 3.5958084182200243
Validation loss: 2.8136876578171495

Epoch: 6| Step: 7
Training loss: 2.799375811894191
Validation loss: 2.8165284651216926

Epoch: 6| Step: 8
Training loss: 2.9373782518195872
Validation loss: 2.8176217336055864

Epoch: 6| Step: 9
Training loss: 3.124118833286767
Validation loss: 2.8163222151521308

Epoch: 6| Step: 10
Training loss: 2.5530474236607783
Validation loss: 2.8198241110158304

Epoch: 6| Step: 11
Training loss: 3.2753133201689084
Validation loss: 2.821650132209067

Epoch: 6| Step: 12
Training loss: 2.4352276309103766
Validation loss: 2.8244949455620962

Epoch: 6| Step: 13
Training loss: 3.1950810355594275
Validation loss: 2.835253593812221

Epoch: 50| Step: 0
Training loss: 3.618408919683676
Validation loss: 2.855807864940124

Epoch: 6| Step: 1
Training loss: 3.345071549270474
Validation loss: 2.8580669699672496

Epoch: 6| Step: 2
Training loss: 3.12861668155239
Validation loss: 2.8317533858707615

Epoch: 6| Step: 3
Training loss: 2.175564493172436
Validation loss: 2.816371467219325

Epoch: 6| Step: 4
Training loss: 3.5058482220400595
Validation loss: 2.8110789009578774

Epoch: 6| Step: 5
Training loss: 3.3749513975811793
Validation loss: 2.8092284377045114

Epoch: 6| Step: 6
Training loss: 2.6851474312312
Validation loss: 2.8090254373873313

Epoch: 6| Step: 7
Training loss: 3.3654204154992406
Validation loss: 2.8080291981615995

Epoch: 6| Step: 8
Training loss: 3.1839430166924974
Validation loss: 2.807648778822384

Epoch: 6| Step: 9
Training loss: 3.578171908808236
Validation loss: 2.809322636097472

Epoch: 6| Step: 10
Training loss: 2.593186098869802
Validation loss: 2.806547887626732

Epoch: 6| Step: 11
Training loss: 3.03834144648398
Validation loss: 2.8051582978964293

Epoch: 6| Step: 12
Training loss: 3.0502869893115117
Validation loss: 2.8043303136415174

Epoch: 6| Step: 13
Training loss: 2.368907542764595
Validation loss: 2.803586396982982

Epoch: 51| Step: 0
Training loss: 3.069609505735248
Validation loss: 2.802876066462506

Epoch: 6| Step: 1
Training loss: 3.346581516879739
Validation loss: 2.802066335562883

Epoch: 6| Step: 2
Training loss: 2.6588959025894345
Validation loss: 2.8034861405906804

Epoch: 6| Step: 3
Training loss: 3.578586598568914
Validation loss: 2.801582672908696

Epoch: 6| Step: 4
Training loss: 2.6830324699322396
Validation loss: 2.7992297816918272

Epoch: 6| Step: 5
Training loss: 3.160142217164069
Validation loss: 2.8012325484882172

Epoch: 6| Step: 6
Training loss: 3.2493044769212127
Validation loss: 2.799869201611169

Epoch: 6| Step: 7
Training loss: 2.7493933095146743
Validation loss: 2.8055641069677537

Epoch: 6| Step: 8
Training loss: 2.5602323221051355
Validation loss: 2.8016618481098337

Epoch: 6| Step: 9
Training loss: 3.3345326809124605
Validation loss: 2.8010357122320944

Epoch: 6| Step: 10
Training loss: 3.0971891765418667
Validation loss: 2.8054014182746476

Epoch: 6| Step: 11
Training loss: 3.4053442914552954
Validation loss: 2.820838497168832

Epoch: 6| Step: 12
Training loss: 3.688855455494726
Validation loss: 2.814538676668182

Epoch: 6| Step: 13
Training loss: 2.384439582000085
Validation loss: 2.8106034377711775

Epoch: 52| Step: 0
Training loss: 3.203938599511307
Validation loss: 2.811123519101701

Epoch: 6| Step: 1
Training loss: 3.057764245355711
Validation loss: 2.8004673559545883

Epoch: 6| Step: 2
Training loss: 3.4561050467420995
Validation loss: 2.8003175957845423

Epoch: 6| Step: 3
Training loss: 3.115100745321637
Validation loss: 2.7984786480700885

Epoch: 6| Step: 4
Training loss: 3.6359025836312293
Validation loss: 2.794855032396624

Epoch: 6| Step: 5
Training loss: 3.367915028440288
Validation loss: 2.794833140711252

Epoch: 6| Step: 6
Training loss: 3.075510376544503
Validation loss: 2.792991302488676

Epoch: 6| Step: 7
Training loss: 2.700487117624306
Validation loss: 2.794704643536221

Epoch: 6| Step: 8
Training loss: 2.5022964420664215
Validation loss: 2.795762429766367

Epoch: 6| Step: 9
Training loss: 3.0620337929383927
Validation loss: 2.792052676812636

Epoch: 6| Step: 10
Training loss: 3.60329066455667
Validation loss: 2.794330563524352

Epoch: 6| Step: 11
Training loss: 2.963956476466003
Validation loss: 2.7948953847094904

Epoch: 6| Step: 12
Training loss: 2.5397011291205795
Validation loss: 2.789733833498317

Epoch: 6| Step: 13
Training loss: 3.0530234875392472
Validation loss: 2.79331985241402

Epoch: 53| Step: 0
Training loss: 3.0581518952672
Validation loss: 2.793416119902641

Epoch: 6| Step: 1
Training loss: 2.2910033450891056
Validation loss: 2.7987263919368632

Epoch: 6| Step: 2
Training loss: 3.4733454875281873
Validation loss: 2.8031377574607346

Epoch: 6| Step: 3
Training loss: 2.739989353354159
Validation loss: 2.799882474533542

Epoch: 6| Step: 4
Training loss: 3.313221978734762
Validation loss: 2.816867988669602

Epoch: 6| Step: 5
Training loss: 2.696415330029675
Validation loss: 2.8203531652682208

Epoch: 6| Step: 6
Training loss: 3.9230241649699265
Validation loss: 2.8085449238238285

Epoch: 6| Step: 7
Training loss: 2.4690499425312114
Validation loss: 2.7923860377622587

Epoch: 6| Step: 8
Training loss: 3.525108736133185
Validation loss: 2.785984391319289

Epoch: 6| Step: 9
Training loss: 3.042370719075037
Validation loss: 2.783487483410335

Epoch: 6| Step: 10
Training loss: 2.9999833106530405
Validation loss: 2.787510537844457

Epoch: 6| Step: 11
Training loss: 3.347594573299619
Validation loss: 2.7862140884668407

Epoch: 6| Step: 12
Training loss: 3.1590618034903155
Validation loss: 2.7882327113316747

Epoch: 6| Step: 13
Training loss: 3.0817508932610425
Validation loss: 2.7864090054991077

Epoch: 54| Step: 0
Training loss: 3.148991765534533
Validation loss: 2.7866057884310766

Epoch: 6| Step: 1
Training loss: 3.570654654437318
Validation loss: 2.7879350161383325

Epoch: 6| Step: 2
Training loss: 2.33152399984103
Validation loss: 2.787364432343066

Epoch: 6| Step: 3
Training loss: 3.231990211453109
Validation loss: 2.787358279299502

Epoch: 6| Step: 4
Training loss: 3.6749235443673927
Validation loss: 2.7848237110143312

Epoch: 6| Step: 5
Training loss: 3.155284620647158
Validation loss: 2.783572527023501

Epoch: 6| Step: 6
Training loss: 3.5742966606945688
Validation loss: 2.78258369235098

Epoch: 6| Step: 7
Training loss: 3.3098227279997476
Validation loss: 2.7813284543623

Epoch: 6| Step: 8
Training loss: 2.653355446232931
Validation loss: 2.7799379213368662

Epoch: 6| Step: 9
Training loss: 2.8855409193771457
Validation loss: 2.777819831967333

Epoch: 6| Step: 10
Training loss: 3.202308811314496
Validation loss: 2.7768803858079028

Epoch: 6| Step: 11
Training loss: 2.9181432710109494
Validation loss: 2.7766867424556594

Epoch: 6| Step: 12
Training loss: 2.3615599361505204
Validation loss: 2.7726078468495534

Epoch: 6| Step: 13
Training loss: 3.0956040808781276
Validation loss: 2.7780075155814004

Epoch: 55| Step: 0
Training loss: 2.8120961217174494
Validation loss: 2.777719557435726

Epoch: 6| Step: 1
Training loss: 2.670748824648771
Validation loss: 2.775505179536482

Epoch: 6| Step: 2
Training loss: 3.1424952769338823
Validation loss: 2.774356766530805

Epoch: 6| Step: 3
Training loss: 2.8644051421259014
Validation loss: 2.7730645614907363

Epoch: 6| Step: 4
Training loss: 3.4744155941255968
Validation loss: 2.7742958451822743

Epoch: 6| Step: 5
Training loss: 3.631691774162159
Validation loss: 2.7765876679271186

Epoch: 6| Step: 6
Training loss: 3.018652626504811
Validation loss: 2.7764586301159775

Epoch: 6| Step: 7
Training loss: 3.8960158905394544
Validation loss: 2.7774274513530894

Epoch: 6| Step: 8
Training loss: 2.4000930291265616
Validation loss: 2.7714832964423906

Epoch: 6| Step: 9
Training loss: 3.3793977413043743
Validation loss: 2.774063716744553

Epoch: 6| Step: 10
Training loss: 3.711926137838817
Validation loss: 2.774801599308802

Epoch: 6| Step: 11
Training loss: 2.4771186853896094
Validation loss: 2.7736693259232017

Epoch: 6| Step: 12
Training loss: 2.691251487324007
Validation loss: 2.773233248861547

Epoch: 6| Step: 13
Training loss: 2.1214717296377295
Validation loss: 2.7726115990017632

Epoch: 56| Step: 0
Training loss: 3.559176316715259
Validation loss: 2.773041952334123

Epoch: 6| Step: 1
Training loss: 3.3754255238474773
Validation loss: 2.770023221660883

Epoch: 6| Step: 2
Training loss: 3.076547441111492
Validation loss: 2.774276907248673

Epoch: 6| Step: 3
Training loss: 2.7573327357729935
Validation loss: 2.7693901834301196

Epoch: 6| Step: 4
Training loss: 3.0630059894698736
Validation loss: 2.776078841727321

Epoch: 6| Step: 5
Training loss: 2.6151155839397426
Validation loss: 2.769956176193173

Epoch: 6| Step: 6
Training loss: 2.80522911346441
Validation loss: 2.7661046578029285

Epoch: 6| Step: 7
Training loss: 3.2674768481204164
Validation loss: 2.7717884365818106

Epoch: 6| Step: 8
Training loss: 2.8395136204477005
Validation loss: 2.766488057099079

Epoch: 6| Step: 9
Training loss: 3.1116246658648055
Validation loss: 2.764586273824101

Epoch: 6| Step: 10
Training loss: 3.493913535451742
Validation loss: 2.7682323397718545

Epoch: 6| Step: 11
Training loss: 2.464979648622142
Validation loss: 2.762217677151234

Epoch: 6| Step: 12
Training loss: 3.0114096793422074
Validation loss: 2.7677416642447024

Epoch: 6| Step: 13
Training loss: 3.7744517098704606
Validation loss: 2.769655598343943

Epoch: 57| Step: 0
Training loss: 2.9125805888671144
Validation loss: 2.764592187301645

Epoch: 6| Step: 1
Training loss: 2.5415263736548943
Validation loss: 2.779835923022005

Epoch: 6| Step: 2
Training loss: 2.9057547854925896
Validation loss: 2.772784064923663

Epoch: 6| Step: 3
Training loss: 2.609418857228739
Validation loss: 2.766952258271186

Epoch: 6| Step: 4
Training loss: 2.588505878367389
Validation loss: 2.7690449291771895

Epoch: 6| Step: 5
Training loss: 3.419597547174748
Validation loss: 2.759799669299013

Epoch: 6| Step: 6
Training loss: 3.341133305958994
Validation loss: 2.76355706650447

Epoch: 6| Step: 7
Training loss: 3.3339303117870562
Validation loss: 2.765397806107103

Epoch: 6| Step: 8
Training loss: 2.7789333853738665
Validation loss: 2.763405996696999

Epoch: 6| Step: 9
Training loss: 3.3667933682561646
Validation loss: 2.7646441793647867

Epoch: 6| Step: 10
Training loss: 3.4634760723738585
Validation loss: 2.762980131795306

Epoch: 6| Step: 11
Training loss: 3.484324638789641
Validation loss: 2.7633983347257263

Epoch: 6| Step: 12
Training loss: 3.029476945002674
Validation loss: 2.7663323274393643

Epoch: 6| Step: 13
Training loss: 3.064417024962637
Validation loss: 2.7689501225324507

Epoch: 58| Step: 0
Training loss: 3.140618319528032
Validation loss: 2.7669484113514256

Epoch: 6| Step: 1
Training loss: 2.8037280298427536
Validation loss: 2.7591307573684962

Epoch: 6| Step: 2
Training loss: 3.4742371744156726
Validation loss: 2.7605538264301965

Epoch: 6| Step: 3
Training loss: 2.6442247942877
Validation loss: 2.7516827641297485

Epoch: 6| Step: 4
Training loss: 3.686852737776
Validation loss: 2.750561721127233

Epoch: 6| Step: 5
Training loss: 2.7256783087401963
Validation loss: 2.7478225847018907

Epoch: 6| Step: 6
Training loss: 2.7160295929118212
Validation loss: 2.751123701235661

Epoch: 6| Step: 7
Training loss: 2.671782464103682
Validation loss: 2.748603424227773

Epoch: 6| Step: 8
Training loss: 3.095115745487769
Validation loss: 2.7506883138291625

Epoch: 6| Step: 9
Training loss: 3.062529427523236
Validation loss: 2.7496370558942207

Epoch: 6| Step: 10
Training loss: 3.0337809585230233
Validation loss: 2.7482212299749484

Epoch: 6| Step: 11
Training loss: 3.168093677696286
Validation loss: 2.7476357087859378

Epoch: 6| Step: 12
Training loss: 3.5903930907891852
Validation loss: 2.7510491828026638

Epoch: 6| Step: 13
Training loss: 2.828806420950701
Validation loss: 2.7477438752853063

Epoch: 59| Step: 0
Training loss: 2.914235291458872
Validation loss: 2.7536013664043275

Epoch: 6| Step: 1
Training loss: 3.0868783796083
Validation loss: 2.7606841768991406

Epoch: 6| Step: 2
Training loss: 3.5251444469102298
Validation loss: 2.7759039078034786

Epoch: 6| Step: 3
Training loss: 3.418287931525444
Validation loss: 2.7666265788573483

Epoch: 6| Step: 4
Training loss: 2.502442883002613
Validation loss: 2.7533730826199747

Epoch: 6| Step: 5
Training loss: 2.2279117177186896
Validation loss: 2.7565532715502923

Epoch: 6| Step: 6
Training loss: 2.474795604704497
Validation loss: 2.7436504773058337

Epoch: 6| Step: 7
Training loss: 3.330339438290181
Validation loss: 2.7410889472402173

Epoch: 6| Step: 8
Training loss: 3.560293886505519
Validation loss: 2.741944757508599

Epoch: 6| Step: 9
Training loss: 3.424375970056699
Validation loss: 2.744248207134201

Epoch: 6| Step: 10
Training loss: 3.4620935304768317
Validation loss: 2.7408872502305512

Epoch: 6| Step: 11
Training loss: 3.244264383269311
Validation loss: 2.742227860726253

Epoch: 6| Step: 12
Training loss: 2.8188328123932527
Validation loss: 2.7410946317663036

Epoch: 6| Step: 13
Training loss: 2.2670629739247383
Validation loss: 2.741019962266458

Epoch: 60| Step: 0
Training loss: 3.091918094690165
Validation loss: 2.7375807273710167

Epoch: 6| Step: 1
Training loss: 2.5666215826591534
Validation loss: 2.746709239979026

Epoch: 6| Step: 2
Training loss: 3.1527562208367623
Validation loss: 2.7435440967665143

Epoch: 6| Step: 3
Training loss: 2.688666689267936
Validation loss: 2.7460591754234267

Epoch: 6| Step: 4
Training loss: 2.919631178046349
Validation loss: 2.748637726165444

Epoch: 6| Step: 5
Training loss: 2.827012828677702
Validation loss: 2.754476366307996

Epoch: 6| Step: 6
Training loss: 3.864090359375661
Validation loss: 2.7486613997277227

Epoch: 6| Step: 7
Training loss: 2.949929420790688
Validation loss: 2.750278727258231

Epoch: 6| Step: 8
Training loss: 2.6261514227412737
Validation loss: 2.7457898074338467

Epoch: 6| Step: 9
Training loss: 3.2555450672187574
Validation loss: 2.7427435463886383

Epoch: 6| Step: 10
Training loss: 3.264199415725479
Validation loss: 2.7466579463261587

Epoch: 6| Step: 11
Training loss: 3.409780789709877
Validation loss: 2.748665893409806

Epoch: 6| Step: 12
Training loss: 2.9827795107792188
Validation loss: 2.738974830040509

Epoch: 6| Step: 13
Training loss: 3.0392143780333316
Validation loss: 2.736873092899304

Epoch: 61| Step: 0
Training loss: 3.451886261260813
Validation loss: 2.7403362475878397

Epoch: 6| Step: 1
Training loss: 2.950967474876801
Validation loss: 2.7326668509269245

Epoch: 6| Step: 2
Training loss: 3.391502302031514
Validation loss: 2.7331933009185607

Epoch: 6| Step: 3
Training loss: 1.8155015887077774
Validation loss: 2.7281957820536746

Epoch: 6| Step: 4
Training loss: 3.1621116369568036
Validation loss: 2.730595190787146

Epoch: 6| Step: 5
Training loss: 3.1326076221777868
Validation loss: 2.7307917918024094

Epoch: 6| Step: 6
Training loss: 3.0360893081978855
Validation loss: 2.731018319997937

Epoch: 6| Step: 7
Training loss: 3.2868930793086544
Validation loss: 2.727627910724248

Epoch: 6| Step: 8
Training loss: 2.9209606351514723
Validation loss: 2.726790804838831

Epoch: 6| Step: 9
Training loss: 3.358922315748011
Validation loss: 2.7276894777538123

Epoch: 6| Step: 10
Training loss: 2.5553854825837155
Validation loss: 2.7266870271534476

Epoch: 6| Step: 11
Training loss: 3.0417490560442833
Validation loss: 2.729632451459923

Epoch: 6| Step: 12
Training loss: 3.139010645512627
Validation loss: 2.731924053511508

Epoch: 6| Step: 13
Training loss: 3.2403359147177877
Validation loss: 2.7412614006766542

Epoch: 62| Step: 0
Training loss: 2.841211212739297
Validation loss: 2.7556144569651204

Epoch: 6| Step: 1
Training loss: 3.7592463622753263
Validation loss: 2.7515451298598927

Epoch: 6| Step: 2
Training loss: 3.664189513390248
Validation loss: 2.7332353195677235

Epoch: 6| Step: 3
Training loss: 2.8381038409773542
Validation loss: 2.7249892526704227

Epoch: 6| Step: 4
Training loss: 2.3052888764521557
Validation loss: 2.724085740097369

Epoch: 6| Step: 5
Training loss: 2.6796640111488763
Validation loss: 2.723271085696201

Epoch: 6| Step: 6
Training loss: 2.870280829323948
Validation loss: 2.7236573650991076

Epoch: 6| Step: 7
Training loss: 3.4256236824154214
Validation loss: 2.7189883084180173

Epoch: 6| Step: 8
Training loss: 2.747871268598488
Validation loss: 2.7212646075548936

Epoch: 6| Step: 9
Training loss: 2.9651505986222295
Validation loss: 2.723806174433512

Epoch: 6| Step: 10
Training loss: 3.0425818298920664
Validation loss: 2.7255430973560086

Epoch: 6| Step: 11
Training loss: 3.0448705095090225
Validation loss: 2.7420929465119057

Epoch: 6| Step: 12
Training loss: 2.717697290525059
Validation loss: 2.7539134086935335

Epoch: 6| Step: 13
Training loss: 3.7372588829421334
Validation loss: 2.762402642265748

Epoch: 63| Step: 0
Training loss: 3.5339720370660332
Validation loss: 2.7516065362819777

Epoch: 6| Step: 1
Training loss: 2.532264882778647
Validation loss: 2.7347939522197344

Epoch: 6| Step: 2
Training loss: 2.969525687622224
Validation loss: 2.728859348148361

Epoch: 6| Step: 3
Training loss: 2.7573086978130323
Validation loss: 2.7205316318611574

Epoch: 6| Step: 4
Training loss: 3.181278215144554
Validation loss: 2.7237539703920444

Epoch: 6| Step: 5
Training loss: 2.9656818798467195
Validation loss: 2.719617202494522

Epoch: 6| Step: 6
Training loss: 2.8032025414738393
Validation loss: 2.720732806385956

Epoch: 6| Step: 7
Training loss: 2.6769808342653345
Validation loss: 2.7225598176228445

Epoch: 6| Step: 8
Training loss: 3.0466654387568273
Validation loss: 2.7153856769559845

Epoch: 6| Step: 9
Training loss: 3.7182591218494707
Validation loss: 2.7160961186018464

Epoch: 6| Step: 10
Training loss: 2.631478534840707
Validation loss: 2.718847776320718

Epoch: 6| Step: 11
Training loss: 3.3555950811583104
Validation loss: 2.7206763737845563

Epoch: 6| Step: 12
Training loss: 3.683656143841275
Validation loss: 2.7184333810210566

Epoch: 6| Step: 13
Training loss: 1.9762075957466656
Validation loss: 2.718441431896186

Epoch: 64| Step: 0
Training loss: 3.354528435257215
Validation loss: 2.716915978771952

Epoch: 6| Step: 1
Training loss: 2.391590397202398
Validation loss: 2.716112969454059

Epoch: 6| Step: 2
Training loss: 3.569795733893758
Validation loss: 2.717030911575378

Epoch: 6| Step: 3
Training loss: 2.646512662729354
Validation loss: 2.715318298296265

Epoch: 6| Step: 4
Training loss: 3.4167425255766615
Validation loss: 2.715642724131025

Epoch: 6| Step: 5
Training loss: 2.8284375771453076
Validation loss: 2.7205647508163966

Epoch: 6| Step: 6
Training loss: 3.1393296336488867
Validation loss: 2.724436144159253

Epoch: 6| Step: 7
Training loss: 2.9024520176117594
Validation loss: 2.7208925206049437

Epoch: 6| Step: 8
Training loss: 3.338435861197368
Validation loss: 2.7278902014695534

Epoch: 6| Step: 9
Training loss: 2.8643911586224964
Validation loss: 2.7271612001146335

Epoch: 6| Step: 10
Training loss: 2.7888133902122685
Validation loss: 2.7215847248411653

Epoch: 6| Step: 11
Training loss: 2.7630142561786015
Validation loss: 2.722353055402363

Epoch: 6| Step: 12
Training loss: 2.826009728578964
Validation loss: 2.731095839641348

Epoch: 6| Step: 13
Training loss: 3.709641400920754
Validation loss: 2.7348224401550207

Epoch: 65| Step: 0
Training loss: 3.3850232800538236
Validation loss: 2.718995391215435

Epoch: 6| Step: 1
Training loss: 2.89110779725508
Validation loss: 2.7189658756663113

Epoch: 6| Step: 2
Training loss: 3.1960951166143037
Validation loss: 2.713138211082006

Epoch: 6| Step: 3
Training loss: 2.9618607744856145
Validation loss: 2.711277947593999

Epoch: 6| Step: 4
Training loss: 3.1727702563932225
Validation loss: 2.7056420338150473

Epoch: 6| Step: 5
Training loss: 2.9503667958995674
Validation loss: 2.7118084950376637

Epoch: 6| Step: 6
Training loss: 2.6236809640846293
Validation loss: 2.711877396869902

Epoch: 6| Step: 7
Training loss: 2.982103052191792
Validation loss: 2.713656184370406

Epoch: 6| Step: 8
Training loss: 3.1794015066887766
Validation loss: 2.7154587723100407

Epoch: 6| Step: 9
Training loss: 3.553396539704482
Validation loss: 2.7130384969297032

Epoch: 6| Step: 10
Training loss: 2.9691054281992426
Validation loss: 2.716436619936125

Epoch: 6| Step: 11
Training loss: 3.0134378516657767
Validation loss: 2.715357660151972

Epoch: 6| Step: 12
Training loss: 2.810281684033777
Validation loss: 2.7052169170100755

Epoch: 6| Step: 13
Training loss: 2.128988225915979
Validation loss: 2.7023649050980993

Epoch: 66| Step: 0
Training loss: 2.9962255257445234
Validation loss: 2.69984113179511

Epoch: 6| Step: 1
Training loss: 3.132513093791609
Validation loss: 2.696677836021052

Epoch: 6| Step: 2
Training loss: 2.9185421136507235
Validation loss: 2.695744583239488

Epoch: 6| Step: 3
Training loss: 2.7901660434986604
Validation loss: 2.695988540554708

Epoch: 6| Step: 4
Training loss: 2.7843405022501653
Validation loss: 2.7035832521386243

Epoch: 6| Step: 5
Training loss: 3.5138387931968644
Validation loss: 2.700952596236582

Epoch: 6| Step: 6
Training loss: 3.3066722059459845
Validation loss: 2.7013655297204124

Epoch: 6| Step: 7
Training loss: 2.2309626418285493
Validation loss: 2.702802438842

Epoch: 6| Step: 8
Training loss: 2.931136360487095
Validation loss: 2.7030175253059996

Epoch: 6| Step: 9
Training loss: 2.9468980159245017
Validation loss: 2.713133681234092

Epoch: 6| Step: 10
Training loss: 2.8630505894366136
Validation loss: 2.719169102549761

Epoch: 6| Step: 11
Training loss: 2.8751194141301006
Validation loss: 2.720383991481622

Epoch: 6| Step: 12
Training loss: 3.831582014872491
Validation loss: 2.741086311666209

Epoch: 6| Step: 13
Training loss: 3.0643558717737913
Validation loss: 2.7312724654812013

Epoch: 67| Step: 0
Training loss: 2.816286208812721
Validation loss: 2.71405386746056

Epoch: 6| Step: 1
Training loss: 2.9533825312952042
Validation loss: 2.7112839555927604

Epoch: 6| Step: 2
Training loss: 2.8842237372943975
Validation loss: 2.6937871444246744

Epoch: 6| Step: 3
Training loss: 3.662382541895195
Validation loss: 2.6989636816012625

Epoch: 6| Step: 4
Training loss: 3.4966171810501976
Validation loss: 2.694552994660695

Epoch: 6| Step: 5
Training loss: 3.0644339858090186
Validation loss: 2.6955174265210937

Epoch: 6| Step: 6
Training loss: 3.5350407871337524
Validation loss: 2.6949825361319415

Epoch: 6| Step: 7
Training loss: 2.352567743021261
Validation loss: 2.696899997575034

Epoch: 6| Step: 8
Training loss: 2.29512756724474
Validation loss: 2.696782488085738

Epoch: 6| Step: 9
Training loss: 3.160145687656174
Validation loss: 2.6937023240373765

Epoch: 6| Step: 10
Training loss: 3.1081773761422467
Validation loss: 2.690604416058165

Epoch: 6| Step: 11
Training loss: 3.01463625812449
Validation loss: 2.6912385445465534

Epoch: 6| Step: 12
Training loss: 3.077185472890822
Validation loss: 2.695051359224182

Epoch: 6| Step: 13
Training loss: 2.0985380624405456
Validation loss: 2.6948289938973655

Epoch: 68| Step: 0
Training loss: 3.013208557628824
Validation loss: 2.6947281788891133

Epoch: 6| Step: 1
Training loss: 2.784695409284731
Validation loss: 2.699032706175552

Epoch: 6| Step: 2
Training loss: 2.3860336793951094
Validation loss: 2.7147506493697637

Epoch: 6| Step: 3
Training loss: 2.6218533502532853
Validation loss: 2.7183718721894023

Epoch: 6| Step: 4
Training loss: 2.051035954235124
Validation loss: 2.7171460461448342

Epoch: 6| Step: 5
Training loss: 2.6219442838078346
Validation loss: 2.704279322909699

Epoch: 6| Step: 6
Training loss: 3.232128745441898
Validation loss: 2.7113823557162346

Epoch: 6| Step: 7
Training loss: 3.385425148977755
Validation loss: 2.709964511510164

Epoch: 6| Step: 8
Training loss: 3.2524366781065503
Validation loss: 2.699181955607129

Epoch: 6| Step: 9
Training loss: 3.347679040179134
Validation loss: 2.687750983722746

Epoch: 6| Step: 10
Training loss: 2.9231773370800744
Validation loss: 2.6839355751626455

Epoch: 6| Step: 11
Training loss: 3.5015979933567585
Validation loss: 2.683119299695076

Epoch: 6| Step: 12
Training loss: 3.143890353457867
Validation loss: 2.6851553756821906

Epoch: 6| Step: 13
Training loss: 3.920247503952848
Validation loss: 2.6857818735769823

Epoch: 69| Step: 0
Training loss: 2.4507512556191715
Validation loss: 2.6868513249272956

Epoch: 6| Step: 1
Training loss: 3.076461419905028
Validation loss: 2.682580283901462

Epoch: 6| Step: 2
Training loss: 2.600816132760446
Validation loss: 2.6836733110905504

Epoch: 6| Step: 3
Training loss: 3.2130241946019726
Validation loss: 2.686183378948249

Epoch: 6| Step: 4
Training loss: 2.404195329395007
Validation loss: 2.698522819803675

Epoch: 6| Step: 5
Training loss: 2.7657162063990546
Validation loss: 2.7017185151969225

Epoch: 6| Step: 6
Training loss: 3.505494573203443
Validation loss: 2.7109512679121095

Epoch: 6| Step: 7
Training loss: 3.4217175312476424
Validation loss: 2.7087005372611848

Epoch: 6| Step: 8
Training loss: 2.3774111705274668
Validation loss: 2.6971351057501343

Epoch: 6| Step: 9
Training loss: 3.3290802207166466
Validation loss: 2.684991702451947

Epoch: 6| Step: 10
Training loss: 3.0009371565302474
Validation loss: 2.6822633838367116

Epoch: 6| Step: 11
Training loss: 2.8227292851454986
Validation loss: 2.682281597025761

Epoch: 6| Step: 12
Training loss: 3.463304386281069
Validation loss: 2.678119733806707

Epoch: 6| Step: 13
Training loss: 3.665371463784987
Validation loss: 2.675708811628012

Epoch: 70| Step: 0
Training loss: 3.121998833538182
Validation loss: 2.681310659511644

Epoch: 6| Step: 1
Training loss: 2.9575027231057174
Validation loss: 2.6792903077087646

Epoch: 6| Step: 2
Training loss: 3.166860741808489
Validation loss: 2.6758146076295297

Epoch: 6| Step: 3
Training loss: 3.3586609547278625
Validation loss: 2.677196212220409

Epoch: 6| Step: 4
Training loss: 2.53628143591879
Validation loss: 2.6786625662132453

Epoch: 6| Step: 5
Training loss: 2.7453708701097237
Validation loss: 2.6811449042497104

Epoch: 6| Step: 6
Training loss: 3.091858873450559
Validation loss: 2.6773299402937263

Epoch: 6| Step: 7
Training loss: 3.2591614343270696
Validation loss: 2.6797783097579275

Epoch: 6| Step: 8
Training loss: 2.9444710012553847
Validation loss: 2.676802614290109

Epoch: 6| Step: 9
Training loss: 2.956490027460046
Validation loss: 2.6720127448486077

Epoch: 6| Step: 10
Training loss: 3.110967180540624
Validation loss: 2.671541235480258

Epoch: 6| Step: 11
Training loss: 2.3628165300443618
Validation loss: 2.67385722796426

Epoch: 6| Step: 12
Training loss: 3.0388608733223816
Validation loss: 2.675821640875076

Epoch: 6| Step: 13
Training loss: 3.4424150873930257
Validation loss: 2.678204720333752

Epoch: 71| Step: 0
Training loss: 3.0415742590118517
Validation loss: 2.679161549931705

Epoch: 6| Step: 1
Training loss: 2.6007218019217686
Validation loss: 2.6869155618431955

Epoch: 6| Step: 2
Training loss: 3.3412788743221076
Validation loss: 2.710999985087332

Epoch: 6| Step: 3
Training loss: 3.5195808364812944
Validation loss: 2.733448710083679

Epoch: 6| Step: 4
Training loss: 2.844138653365097
Validation loss: 2.733230518661624

Epoch: 6| Step: 5
Training loss: 2.783650937109905
Validation loss: 2.737498071167613

Epoch: 6| Step: 6
Training loss: 2.9248169148847083
Validation loss: 2.7048550409649286

Epoch: 6| Step: 7
Training loss: 3.3454035298034945
Validation loss: 2.698227420770768

Epoch: 6| Step: 8
Training loss: 2.594974366724793
Validation loss: 2.6945873662446718

Epoch: 6| Step: 9
Training loss: 2.692191708340624
Validation loss: 2.6902305265931887

Epoch: 6| Step: 10
Training loss: 3.1017263835205613
Validation loss: 2.682968807001201

Epoch: 6| Step: 11
Training loss: 2.8098440557357827
Validation loss: 2.6732064152371913

Epoch: 6| Step: 12
Training loss: 3.1775834153794196
Validation loss: 2.665802797115309

Epoch: 6| Step: 13
Training loss: 3.1324704713639817
Validation loss: 2.6700074085939196

Epoch: 72| Step: 0
Training loss: 2.702383215230895
Validation loss: 2.6667206499829366

Epoch: 6| Step: 1
Training loss: 3.6005925591544754
Validation loss: 2.666251257552717

Epoch: 6| Step: 2
Training loss: 3.116483604100375
Validation loss: 2.6648689482998518

Epoch: 6| Step: 3
Training loss: 2.7053083301189056
Validation loss: 2.665732721692749

Epoch: 6| Step: 4
Training loss: 2.7151511038923366
Validation loss: 2.6667848421132523

Epoch: 6| Step: 5
Training loss: 2.71699212782937
Validation loss: 2.666694569505817

Epoch: 6| Step: 6
Training loss: 3.277492733502862
Validation loss: 2.6678494463224642

Epoch: 6| Step: 7
Training loss: 2.4597888990866816
Validation loss: 2.6609826563603716

Epoch: 6| Step: 8
Training loss: 2.508174311602041
Validation loss: 2.666778122459557

Epoch: 6| Step: 9
Training loss: 3.3600020422248082
Validation loss: 2.6715387347325494

Epoch: 6| Step: 10
Training loss: 2.9926507257603654
Validation loss: 2.678339062332679

Epoch: 6| Step: 11
Training loss: 3.085450416464497
Validation loss: 2.681250324168454

Epoch: 6| Step: 12
Training loss: 3.1483847942626295
Validation loss: 2.6807369751912753

Epoch: 6| Step: 13
Training loss: 3.6015143070596123
Validation loss: 2.6802544189195587

Epoch: 73| Step: 0
Training loss: 2.6804505087694044
Validation loss: 2.672770189685268

Epoch: 6| Step: 1
Training loss: 2.986484121835096
Validation loss: 2.6805861526931496

Epoch: 6| Step: 2
Training loss: 3.0770757600608887
Validation loss: 2.679786566690285

Epoch: 6| Step: 3
Training loss: 2.3366081780456818
Validation loss: 2.691361384590319

Epoch: 6| Step: 4
Training loss: 3.1385685655057562
Validation loss: 2.6976679385865627

Epoch: 6| Step: 5
Training loss: 3.3635959810274456
Validation loss: 2.70745686120728

Epoch: 6| Step: 6
Training loss: 2.5764043441359163
Validation loss: 2.7069583882957446

Epoch: 6| Step: 7
Training loss: 2.3809500998531496
Validation loss: 2.702411650191452

Epoch: 6| Step: 8
Training loss: 3.384002264883307
Validation loss: 2.6695597078373186

Epoch: 6| Step: 9
Training loss: 3.3402052298898046
Validation loss: 2.6617363747047964

Epoch: 6| Step: 10
Training loss: 2.8780746604667335
Validation loss: 2.6558563394329786

Epoch: 6| Step: 11
Training loss: 3.0276507215837727
Validation loss: 2.654164065026531

Epoch: 6| Step: 12
Training loss: 3.365745713699945
Validation loss: 2.660163231164507

Epoch: 6| Step: 13
Training loss: 2.983301738664062
Validation loss: 2.661811109929504

Epoch: 74| Step: 0
Training loss: 3.286376436223703
Validation loss: 2.663065255678018

Epoch: 6| Step: 1
Training loss: 3.259188208343419
Validation loss: 2.6623641947774206

Epoch: 6| Step: 2
Training loss: 2.4044919217632965
Validation loss: 2.670195805007081

Epoch: 6| Step: 3
Training loss: 2.952051361133395
Validation loss: 2.6661296774560785

Epoch: 6| Step: 4
Training loss: 3.1906726979306144
Validation loss: 2.6609876526454177

Epoch: 6| Step: 5
Training loss: 3.276000555818578
Validation loss: 2.6536860407357294

Epoch: 6| Step: 6
Training loss: 2.6960107755756955
Validation loss: 2.6561494445105116

Epoch: 6| Step: 7
Training loss: 3.164323207334174
Validation loss: 2.652080974676568

Epoch: 6| Step: 8
Training loss: 2.9542594224350687
Validation loss: 2.6554243644406514

Epoch: 6| Step: 9
Training loss: 2.5645991775514947
Validation loss: 2.66222831961054

Epoch: 6| Step: 10
Training loss: 3.0795479985290277
Validation loss: 2.667761037506708

Epoch: 6| Step: 11
Training loss: 3.0228307149609015
Validation loss: 2.679489730682989

Epoch: 6| Step: 12
Training loss: 3.01868453497816
Validation loss: 2.668871744346374

Epoch: 6| Step: 13
Training loss: 3.1320212261508655
Validation loss: 2.6685082827799445

Epoch: 75| Step: 0
Training loss: 2.6750736832497584
Validation loss: 2.664927687251548

Epoch: 6| Step: 1
Training loss: 3.2293733264054234
Validation loss: 2.6630201967826412

Epoch: 6| Step: 2
Training loss: 2.9746600301415747
Validation loss: 2.6603086615008036

Epoch: 6| Step: 3
Training loss: 2.6747540583698743
Validation loss: 2.66070649827208

Epoch: 6| Step: 4
Training loss: 2.9905183683417094
Validation loss: 2.6610531352904925

Epoch: 6| Step: 5
Training loss: 2.8393413198943476
Validation loss: 2.657811453289286

Epoch: 6| Step: 6
Training loss: 3.0317423312528313
Validation loss: 2.6530830850660987

Epoch: 6| Step: 7
Training loss: 3.332603485950267
Validation loss: 2.6504333179743704

Epoch: 6| Step: 8
Training loss: 3.5782797167782103
Validation loss: 2.652168078300609

Epoch: 6| Step: 9
Training loss: 3.2713412398724824
Validation loss: 2.6492489668972192

Epoch: 6| Step: 10
Training loss: 2.5159080772588958
Validation loss: 2.6526697456765413

Epoch: 6| Step: 11
Training loss: 2.923840193382742
Validation loss: 2.645083171787448

Epoch: 6| Step: 12
Training loss: 2.845299267306029
Validation loss: 2.644929559197951

Epoch: 6| Step: 13
Training loss: 2.259823652493409
Validation loss: 2.6401472752349164

Epoch: 76| Step: 0
Training loss: 3.204993768171182
Validation loss: 2.644367890288125

Epoch: 6| Step: 1
Training loss: 2.9490780828415324
Validation loss: 2.6373158235313428

Epoch: 6| Step: 2
Training loss: 3.4979382300531108
Validation loss: 2.6413883475513433

Epoch: 6| Step: 3
Training loss: 3.2004815335366
Validation loss: 2.649980256449573

Epoch: 6| Step: 4
Training loss: 2.7807299524222664
Validation loss: 2.648231354337438

Epoch: 6| Step: 5
Training loss: 2.7961404357917936
Validation loss: 2.656004045115194

Epoch: 6| Step: 6
Training loss: 3.257878218246397
Validation loss: 2.684923077906757

Epoch: 6| Step: 7
Training loss: 2.7230714675653047
Validation loss: 2.700489658966832

Epoch: 6| Step: 8
Training loss: 2.9966714195182655
Validation loss: 2.6831195442954456

Epoch: 6| Step: 9
Training loss: 2.416793217031184
Validation loss: 2.6662472470705456

Epoch: 6| Step: 10
Training loss: 3.113124714246154
Validation loss: 2.660297084993758

Epoch: 6| Step: 11
Training loss: 2.5207634803194363
Validation loss: 2.652639571380138

Epoch: 6| Step: 12
Training loss: 3.2067514127872596
Validation loss: 2.6487376291394122

Epoch: 6| Step: 13
Training loss: 2.658760769081993
Validation loss: 2.64411793501978

Epoch: 77| Step: 0
Training loss: 3.164175224650955
Validation loss: 2.6445236497980877

Epoch: 6| Step: 1
Training loss: 2.987213861656617
Validation loss: 2.6458887106213203

Epoch: 6| Step: 2
Training loss: 3.4418198232001536
Validation loss: 2.645840841923308

Epoch: 6| Step: 3
Training loss: 2.919096416035003
Validation loss: 2.643786200307026

Epoch: 6| Step: 4
Training loss: 3.049394553704889
Validation loss: 2.646256543232478

Epoch: 6| Step: 5
Training loss: 3.0907025982224785
Validation loss: 2.6405406379463727

Epoch: 6| Step: 6
Training loss: 2.7354066482984165
Validation loss: 2.6404039523781857

Epoch: 6| Step: 7
Training loss: 2.927196043475892
Validation loss: 2.640300422783479

Epoch: 6| Step: 8
Training loss: 2.737914579169403
Validation loss: 2.6444986310199434

Epoch: 6| Step: 9
Training loss: 2.468426453840588
Validation loss: 2.6475211839846

Epoch: 6| Step: 10
Training loss: 3.2141253385951996
Validation loss: 2.643545098394581

Epoch: 6| Step: 11
Training loss: 2.5693420618869425
Validation loss: 2.651567102702924

Epoch: 6| Step: 12
Training loss: 2.6993669615491385
Validation loss: 2.652934617623949

Epoch: 6| Step: 13
Training loss: 3.770171021242796
Validation loss: 2.6559693508529554

Epoch: 78| Step: 0
Training loss: 2.6254138620282195
Validation loss: 2.6515050879054285

Epoch: 6| Step: 1
Training loss: 2.8532788271763403
Validation loss: 2.651594637190929

Epoch: 6| Step: 2
Training loss: 3.0655591049656175
Validation loss: 2.6558290306026673

Epoch: 6| Step: 3
Training loss: 2.2515395513419976
Validation loss: 2.6746578139912716

Epoch: 6| Step: 4
Training loss: 3.069296632394294
Validation loss: 2.681806556105366

Epoch: 6| Step: 5
Training loss: 3.0817838504256962
Validation loss: 2.6546738370392062

Epoch: 6| Step: 6
Training loss: 2.388838755157939
Validation loss: 2.643780157221281

Epoch: 6| Step: 7
Training loss: 3.5914151775588543
Validation loss: 2.6436469828006364

Epoch: 6| Step: 8
Training loss: 3.6123692366748994
Validation loss: 2.6338451861836365

Epoch: 6| Step: 9
Training loss: 2.3853948889214402
Validation loss: 2.6298744875945803

Epoch: 6| Step: 10
Training loss: 3.1630847314948305
Validation loss: 2.631028738684377

Epoch: 6| Step: 11
Training loss: 2.7671349492998565
Validation loss: 2.628568954733483

Epoch: 6| Step: 12
Training loss: 3.3709411232920785
Validation loss: 2.6291745124906414

Epoch: 6| Step: 13
Training loss: 2.9777680606430446
Validation loss: 2.6255808449854765

Epoch: 79| Step: 0
Training loss: 3.1955675242533976
Validation loss: 2.6280789549379087

Epoch: 6| Step: 1
Training loss: 3.2928849070453956
Validation loss: 2.626694680598559

Epoch: 6| Step: 2
Training loss: 3.4127820579582973
Validation loss: 2.6270702322081814

Epoch: 6| Step: 3
Training loss: 3.123981157155669
Validation loss: 2.625848604651885

Epoch: 6| Step: 4
Training loss: 3.262496544847084
Validation loss: 2.627227671998491

Epoch: 6| Step: 5
Training loss: 2.9014017006109487
Validation loss: 2.631177841029922

Epoch: 6| Step: 6
Training loss: 2.9641340811154406
Validation loss: 2.628882227457562

Epoch: 6| Step: 7
Training loss: 2.4856758790423736
Validation loss: 2.635303030045043

Epoch: 6| Step: 8
Training loss: 3.1456583408079664
Validation loss: 2.6528576812353006

Epoch: 6| Step: 9
Training loss: 2.801454428584515
Validation loss: 2.646785827863307

Epoch: 6| Step: 10
Training loss: 3.0313807193846394
Validation loss: 2.653374441424305

Epoch: 6| Step: 11
Training loss: 2.9104896712835022
Validation loss: 2.6483123930760555

Epoch: 6| Step: 12
Training loss: 1.5367106947035634
Validation loss: 2.6385806337748816

Epoch: 6| Step: 13
Training loss: 2.781978211811892
Validation loss: 2.6285219312475734

Epoch: 80| Step: 0
Training loss: 2.8986230672571343
Validation loss: 2.62858264887087

Epoch: 6| Step: 1
Training loss: 3.0645660904728382
Validation loss: 2.6305544782711285

Epoch: 6| Step: 2
Training loss: 3.1593582409452883
Validation loss: 2.6240257148591284

Epoch: 6| Step: 3
Training loss: 2.6102196702556943
Validation loss: 2.621529532742571

Epoch: 6| Step: 4
Training loss: 2.778674529814379
Validation loss: 2.6202796043407077

Epoch: 6| Step: 5
Training loss: 3.5204990085274797
Validation loss: 2.6177517836818436

Epoch: 6| Step: 6
Training loss: 3.1160051211509687
Validation loss: 2.6245399868953077

Epoch: 6| Step: 7
Training loss: 2.9296722004808844
Validation loss: 2.624518634043934

Epoch: 6| Step: 8
Training loss: 3.4277861240751797
Validation loss: 2.626821953107251

Epoch: 6| Step: 9
Training loss: 2.497462892609894
Validation loss: 2.6194895415967623

Epoch: 6| Step: 10
Training loss: 2.7486407648840405
Validation loss: 2.624459002404893

Epoch: 6| Step: 11
Training loss: 2.2558830491182
Validation loss: 2.6224268418066035

Epoch: 6| Step: 12
Training loss: 3.32721249961257
Validation loss: 2.627193733562869

Epoch: 6| Step: 13
Training loss: 2.504559745552693
Validation loss: 2.6338784023533375

Epoch: 81| Step: 0
Training loss: 2.4422251556285532
Validation loss: 2.6545202096443785

Epoch: 6| Step: 1
Training loss: 2.994914353663358
Validation loss: 2.6783508690669287

Epoch: 6| Step: 2
Training loss: 2.151094659209501
Validation loss: 2.6712194335456423

Epoch: 6| Step: 3
Training loss: 3.132604273394807
Validation loss: 2.6649192649932862

Epoch: 6| Step: 4
Training loss: 3.356527709837465
Validation loss: 2.653997782164604

Epoch: 6| Step: 5
Training loss: 2.7236012990064657
Validation loss: 2.646522932721886

Epoch: 6| Step: 6
Training loss: 3.4435349634399812
Validation loss: 2.6298959451309463

Epoch: 6| Step: 7
Training loss: 3.017006355114579
Validation loss: 2.6295087109044752

Epoch: 6| Step: 8
Training loss: 3.2245422393261096
Validation loss: 2.6237751573528274

Epoch: 6| Step: 9
Training loss: 3.008657678535617
Validation loss: 2.6174379084785304

Epoch: 6| Step: 10
Training loss: 3.0336758060444096
Validation loss: 2.626309572600308

Epoch: 6| Step: 11
Training loss: 3.0824888636626886
Validation loss: 2.6203066017402024

Epoch: 6| Step: 12
Training loss: 2.539502290637926
Validation loss: 2.6207664305787004

Epoch: 6| Step: 13
Training loss: 2.9001953059233787
Validation loss: 2.615825972726959

Epoch: 82| Step: 0
Training loss: 3.703261618367612
Validation loss: 2.6163932269707852

Epoch: 6| Step: 1
Training loss: 2.447738273018225
Validation loss: 2.611585520149809

Epoch: 6| Step: 2
Training loss: 3.569795066016324
Validation loss: 2.615339983435548

Epoch: 6| Step: 3
Training loss: 2.5478758922276463
Validation loss: 2.622864917961824

Epoch: 6| Step: 4
Training loss: 3.161676859124512
Validation loss: 2.6147838522664837

Epoch: 6| Step: 5
Training loss: 2.800934301900352
Validation loss: 2.6168401662448546

Epoch: 6| Step: 6
Training loss: 3.3510030355095384
Validation loss: 2.617339095144043

Epoch: 6| Step: 7
Training loss: 2.7584035094247694
Validation loss: 2.6303792694276074

Epoch: 6| Step: 8
Training loss: 2.3404218313051404
Validation loss: 2.6330001246664394

Epoch: 6| Step: 9
Training loss: 2.969467237064095
Validation loss: 2.63615609896195

Epoch: 6| Step: 10
Training loss: 2.75009814000575
Validation loss: 2.634120714125144

Epoch: 6| Step: 11
Training loss: 2.6184425191698
Validation loss: 2.6288876260637974

Epoch: 6| Step: 12
Training loss: 3.3279218298277886
Validation loss: 2.6286716244032147

Epoch: 6| Step: 13
Training loss: 2.2692698658107973
Validation loss: 2.6161737988013063

Epoch: 83| Step: 0
Training loss: 3.277740199920712
Validation loss: 2.613718819848633

Epoch: 6| Step: 1
Training loss: 3.1609088015797444
Validation loss: 2.614814011430398

Epoch: 6| Step: 2
Training loss: 3.351514126799807
Validation loss: 2.611169111454491

Epoch: 6| Step: 3
Training loss: 2.8615034342626386
Validation loss: 2.607059380958253

Epoch: 6| Step: 4
Training loss: 2.9956047922396345
Validation loss: 2.6117361108976636

Epoch: 6| Step: 5
Training loss: 2.7211508837738463
Validation loss: 2.609610887013973

Epoch: 6| Step: 6
Training loss: 2.41559016707204
Validation loss: 2.614805759142784

Epoch: 6| Step: 7
Training loss: 3.2497583446159313
Validation loss: 2.6339357183871392

Epoch: 6| Step: 8
Training loss: 3.0348553796842026
Validation loss: 2.6308651359414577

Epoch: 6| Step: 9
Training loss: 2.311404613153129
Validation loss: 2.6443496903275796

Epoch: 6| Step: 10
Training loss: 2.9374892863626103
Validation loss: 2.637723762519843

Epoch: 6| Step: 11
Training loss: 2.7449879488654414
Validation loss: 2.6352894953496593

Epoch: 6| Step: 12
Training loss: 2.9492714580347994
Validation loss: 2.635549292355692

Epoch: 6| Step: 13
Training loss: 3.07473211594748
Validation loss: 2.6230831970657014

Epoch: 84| Step: 0
Training loss: 3.3370510985269144
Validation loss: 2.6258445100071333

Epoch: 6| Step: 1
Training loss: 3.32344578722668
Validation loss: 2.624808861668136

Epoch: 6| Step: 2
Training loss: 2.9838649453698523
Validation loss: 2.626083735310915

Epoch: 6| Step: 3
Training loss: 2.34205179362112
Validation loss: 2.629487258739028

Epoch: 6| Step: 4
Training loss: 3.3609328805066174
Validation loss: 2.6260581064304955

Epoch: 6| Step: 5
Training loss: 3.3847628074497793
Validation loss: 2.614111266748329

Epoch: 6| Step: 6
Training loss: 3.245510668666373
Validation loss: 2.6106204039659335

Epoch: 6| Step: 7
Training loss: 2.963155997354956
Validation loss: 2.6042618180806403

Epoch: 6| Step: 8
Training loss: 2.240337179896469
Validation loss: 2.600764500956214

Epoch: 6| Step: 9
Training loss: 1.88651655231234
Validation loss: 2.5993988293799903

Epoch: 6| Step: 10
Training loss: 3.0245302576464574
Validation loss: 2.598663053055956

Epoch: 6| Step: 11
Training loss: 2.70831567807434
Validation loss: 2.5995146798557776

Epoch: 6| Step: 12
Training loss: 2.4795684382045176
Validation loss: 2.602334499202

Epoch: 6| Step: 13
Training loss: 3.530994777402254
Validation loss: 2.601165728417498

Epoch: 85| Step: 0
Training loss: 3.432522308210437
Validation loss: 2.6024684056117517

Epoch: 6| Step: 1
Training loss: 2.7220910250476598
Validation loss: 2.5984606022834753

Epoch: 6| Step: 2
Training loss: 2.8728359204610197
Validation loss: 2.597517949309493

Epoch: 6| Step: 3
Training loss: 2.742624449084012
Validation loss: 2.5982783876891307

Epoch: 6| Step: 4
Training loss: 3.459173782134237
Validation loss: 2.597269265488374

Epoch: 6| Step: 5
Training loss: 3.193374904396491
Validation loss: 2.5990912392585077

Epoch: 6| Step: 6
Training loss: 2.9796592643052096
Validation loss: 2.5972653153020135

Epoch: 6| Step: 7
Training loss: 1.953125488281189
Validation loss: 2.5953856617374473

Epoch: 6| Step: 8
Training loss: 2.974860878905152
Validation loss: 2.5982221568166173

Epoch: 6| Step: 9
Training loss: 2.8552235969062174
Validation loss: 2.593800223148819

Epoch: 6| Step: 10
Training loss: 2.604970172264679
Validation loss: 2.5905870192563056

Epoch: 6| Step: 11
Training loss: 3.0091419799208987
Validation loss: 2.5912285449230534

Epoch: 6| Step: 12
Training loss: 3.1259243933088188
Validation loss: 2.5909518297823935

Epoch: 6| Step: 13
Training loss: 2.880750461394599
Validation loss: 2.5959539082815923

Epoch: 86| Step: 0
Training loss: 3.2271958438443686
Validation loss: 2.5953715563625526

Epoch: 6| Step: 1
Training loss: 2.946651245554391
Validation loss: 2.598399413631833

Epoch: 6| Step: 2
Training loss: 3.286941678171842
Validation loss: 2.602152467207607

Epoch: 6| Step: 3
Training loss: 2.660192906691499
Validation loss: 2.6079989675974278

Epoch: 6| Step: 4
Training loss: 2.983376221019981
Validation loss: 2.6279363299178353

Epoch: 6| Step: 5
Training loss: 2.8625307439627328
Validation loss: 2.619641926365938

Epoch: 6| Step: 6
Training loss: 2.5557233944201827
Validation loss: 2.6248209687653388

Epoch: 6| Step: 7
Training loss: 2.768385807652356
Validation loss: 2.6140728674316613

Epoch: 6| Step: 8
Training loss: 2.7374588497326298
Validation loss: 2.6020886274342847

Epoch: 6| Step: 9
Training loss: 2.9202014393759215
Validation loss: 2.5979055480721733

Epoch: 6| Step: 10
Training loss: 3.135739602391102
Validation loss: 2.5906107922683494

Epoch: 6| Step: 11
Training loss: 3.1515007924595304
Validation loss: 2.588059207303379

Epoch: 6| Step: 12
Training loss: 2.7655667228808736
Validation loss: 2.5885318592422446

Epoch: 6| Step: 13
Training loss: 3.1041325987582793
Validation loss: 2.58750100290593

Epoch: 87| Step: 0
Training loss: 2.437793420590557
Validation loss: 2.587795613967755

Epoch: 6| Step: 1
Training loss: 3.4073805026667645
Validation loss: 2.591313936582194

Epoch: 6| Step: 2
Training loss: 2.856487212566624
Validation loss: 2.5945212952900536

Epoch: 6| Step: 3
Training loss: 2.6776887874492883
Validation loss: 2.606924078912225

Epoch: 6| Step: 4
Training loss: 3.1109757639947304
Validation loss: 2.6097857376937754

Epoch: 6| Step: 5
Training loss: 3.0047014272826273
Validation loss: 2.620164609366036

Epoch: 6| Step: 6
Training loss: 3.1122132196023427
Validation loss: 2.6349741551128667

Epoch: 6| Step: 7
Training loss: 2.789262609489039
Validation loss: 2.659773055807386

Epoch: 6| Step: 8
Training loss: 2.8340430960168135
Validation loss: 2.656019226125463

Epoch: 6| Step: 9
Training loss: 3.125848731180408
Validation loss: 2.6379314718004094

Epoch: 6| Step: 10
Training loss: 3.1242021686622374
Validation loss: 2.6363597367499225

Epoch: 6| Step: 11
Training loss: 3.2187194822772023
Validation loss: 2.6036459978592608

Epoch: 6| Step: 12
Training loss: 2.6142000826822995
Validation loss: 2.592229579131613

Epoch: 6| Step: 13
Training loss: 2.0918980849114637
Validation loss: 2.5861844651634747

Epoch: 88| Step: 0
Training loss: 2.8567135624576867
Validation loss: 2.589523721058522

Epoch: 6| Step: 1
Training loss: 3.0078740101259256
Validation loss: 2.596476957181657

Epoch: 6| Step: 2
Training loss: 2.8173095270472865
Validation loss: 2.6151972018470353

Epoch: 6| Step: 3
Training loss: 2.9793028544706943
Validation loss: 2.6038903018782795

Epoch: 6| Step: 4
Training loss: 3.3074835453791906
Validation loss: 2.599534573400301

Epoch: 6| Step: 5
Training loss: 3.294104691287617
Validation loss: 2.587287976736631

Epoch: 6| Step: 6
Training loss: 2.746350554481898
Validation loss: 2.5874521253541163

Epoch: 6| Step: 7
Training loss: 2.592407614552587
Validation loss: 2.585364584823638

Epoch: 6| Step: 8
Training loss: 2.8207599992859684
Validation loss: 2.595371606739028

Epoch: 6| Step: 9
Training loss: 2.3857295956866844
Validation loss: 2.6022918791264167

Epoch: 6| Step: 10
Training loss: 3.2228545156814086
Validation loss: 2.6279770688678354

Epoch: 6| Step: 11
Training loss: 2.7898481528686205
Validation loss: 2.642453569192975

Epoch: 6| Step: 12
Training loss: 3.1665999422238036
Validation loss: 2.5991344661429174

Epoch: 6| Step: 13
Training loss: 3.2402664560083045
Validation loss: 2.5859639597340434

Epoch: 89| Step: 0
Training loss: 2.784810733630484
Validation loss: 2.5845916004557896

Epoch: 6| Step: 1
Training loss: 2.3840958938129977
Validation loss: 2.582756531502437

Epoch: 6| Step: 2
Training loss: 3.0927890094236177
Validation loss: 2.586987344677071

Epoch: 6| Step: 3
Training loss: 2.9548551143750252
Validation loss: 2.5852437449566215

Epoch: 6| Step: 4
Training loss: 3.221314232881184
Validation loss: 2.5811793357708934

Epoch: 6| Step: 5
Training loss: 2.7338427216303662
Validation loss: 2.585597431140658

Epoch: 6| Step: 6
Training loss: 2.538943056084759
Validation loss: 2.5901892048117205

Epoch: 6| Step: 7
Training loss: 3.082711612463955
Validation loss: 2.61176670622788

Epoch: 6| Step: 8
Training loss: 2.915800583633604
Validation loss: 2.6313668624332305

Epoch: 6| Step: 9
Training loss: 2.9920890134534286
Validation loss: 2.6646367782880787

Epoch: 6| Step: 10
Training loss: 3.253542949641005
Validation loss: 2.6849003605348734

Epoch: 6| Step: 11
Training loss: 3.209236678399304
Validation loss: 2.7226590823175285

Epoch: 6| Step: 12
Training loss: 2.944508086022578
Validation loss: 2.726056588265877

Epoch: 6| Step: 13
Training loss: 2.9781658029713176
Validation loss: 2.6545497227519466

Epoch: 90| Step: 0
Training loss: 2.7917915050625215
Validation loss: 2.594474148765991

Epoch: 6| Step: 1
Training loss: 3.590102758185489
Validation loss: 2.5787528050805233

Epoch: 6| Step: 2
Training loss: 2.8653338934446806
Validation loss: 2.5790555277154694

Epoch: 6| Step: 3
Training loss: 2.8499349887861682
Validation loss: 2.587999525574697

Epoch: 6| Step: 4
Training loss: 3.2514029189200944
Validation loss: 2.6253468469411017

Epoch: 6| Step: 5
Training loss: 3.1968411470860025
Validation loss: 2.627019592632425

Epoch: 6| Step: 6
Training loss: 2.7167031486573583
Validation loss: 2.5972821425409247

Epoch: 6| Step: 7
Training loss: 2.6454634720813477
Validation loss: 2.5955225060703704

Epoch: 6| Step: 8
Training loss: 2.931567105382269
Validation loss: 2.596001596751252

Epoch: 6| Step: 9
Training loss: 2.0637744087425505
Validation loss: 2.6021849648121944

Epoch: 6| Step: 10
Training loss: 2.8935360658466776
Validation loss: 2.6059006645399916

Epoch: 6| Step: 11
Training loss: 2.71943243823087
Validation loss: 2.598438301086549

Epoch: 6| Step: 12
Training loss: 3.5521550474264254
Validation loss: 2.60173321900737

Epoch: 6| Step: 13
Training loss: 2.5473430180123007
Validation loss: 2.6039439608600623

Epoch: 91| Step: 0
Training loss: 2.8797043169082177
Validation loss: 2.5940429713788244

Epoch: 6| Step: 1
Training loss: 2.368499492997125
Validation loss: 2.59776043056542

Epoch: 6| Step: 2
Training loss: 2.9975658714304267
Validation loss: 2.5876724524542167

Epoch: 6| Step: 3
Training loss: 2.303966034287854
Validation loss: 2.6034805463746302

Epoch: 6| Step: 4
Training loss: 2.939450853923541
Validation loss: 2.600834245049145

Epoch: 6| Step: 5
Training loss: 3.514984750728168
Validation loss: 2.6192854466799775

Epoch: 6| Step: 6
Training loss: 2.4664346001548108
Validation loss: 2.595718549050797

Epoch: 6| Step: 7
Training loss: 2.3162931314931186
Validation loss: 2.5776256287712638

Epoch: 6| Step: 8
Training loss: 3.2613579282085357
Validation loss: 2.57173972437367

Epoch: 6| Step: 9
Training loss: 3.587102696552642
Validation loss: 2.5712728887022767

Epoch: 6| Step: 10
Training loss: 3.144169264151232
Validation loss: 2.5677595998101617

Epoch: 6| Step: 11
Training loss: 2.7310284871725163
Validation loss: 2.5706499166697148

Epoch: 6| Step: 12
Training loss: 3.2448895696297275
Validation loss: 2.5806873563552224

Epoch: 6| Step: 13
Training loss: 2.4560821592337856
Validation loss: 2.5872702813995585

Epoch: 92| Step: 0
Training loss: 3.0942823164005038
Validation loss: 2.5994557152922946

Epoch: 6| Step: 1
Training loss: 2.734251531810668
Validation loss: 2.5973025249901527

Epoch: 6| Step: 2
Training loss: 2.732289505343371
Validation loss: 2.5858891183354444

Epoch: 6| Step: 3
Training loss: 3.2624285810699414
Validation loss: 2.606958105200697

Epoch: 6| Step: 4
Training loss: 2.436661111309574
Validation loss: 2.5979136774048692

Epoch: 6| Step: 5
Training loss: 3.297653901714545
Validation loss: 2.5997322589517466

Epoch: 6| Step: 6
Training loss: 2.836439356260014
Validation loss: 2.5884990302791655

Epoch: 6| Step: 7
Training loss: 2.0566243952647847
Validation loss: 2.587807469238336

Epoch: 6| Step: 8
Training loss: 3.2534720141395947
Validation loss: 2.5792797158938128

Epoch: 6| Step: 9
Training loss: 2.914834091673559
Validation loss: 2.573476046964305

Epoch: 6| Step: 10
Training loss: 3.0369534664062106
Validation loss: 2.580133588778702

Epoch: 6| Step: 11
Training loss: 2.4105966125510054
Validation loss: 2.573980861540049

Epoch: 6| Step: 12
Training loss: 3.653051819733228
Validation loss: 2.580952716133304

Epoch: 6| Step: 13
Training loss: 2.42044763649554
Validation loss: 2.5757159629879163

Epoch: 93| Step: 0
Training loss: 3.3069659375563885
Validation loss: 2.578355562969738

Epoch: 6| Step: 1
Training loss: 2.4533246196025402
Validation loss: 2.592840358150989

Epoch: 6| Step: 2
Training loss: 2.495856093195169
Validation loss: 2.6050042014400785

Epoch: 6| Step: 3
Training loss: 3.2079100061193797
Validation loss: 2.626669283136256

Epoch: 6| Step: 4
Training loss: 2.910476728368903
Validation loss: 2.6558307652251387

Epoch: 6| Step: 5
Training loss: 2.9927305520588656
Validation loss: 2.6238753902611918

Epoch: 6| Step: 6
Training loss: 2.299998540463192
Validation loss: 2.599854575035013

Epoch: 6| Step: 7
Training loss: 3.4547975382022407
Validation loss: 2.5733517478248094

Epoch: 6| Step: 8
Training loss: 2.6625848067124154
Validation loss: 2.554880521833679

Epoch: 6| Step: 9
Training loss: 2.8752091373173165
Validation loss: 2.5597677994458103

Epoch: 6| Step: 10
Training loss: 3.1458017377129868
Validation loss: 2.5656755161606837

Epoch: 6| Step: 11
Training loss: 3.1587958313455426
Validation loss: 2.563384451950178

Epoch: 6| Step: 12
Training loss: 2.9447234599352727
Validation loss: 2.556040311560529

Epoch: 6| Step: 13
Training loss: 2.738735710883287
Validation loss: 2.5603429447892547

Epoch: 94| Step: 0
Training loss: 2.8859059347048794
Validation loss: 2.5571530479570375

Epoch: 6| Step: 1
Training loss: 2.6828535855523743
Validation loss: 2.5758659322124444

Epoch: 6| Step: 2
Training loss: 3.083968294764918
Validation loss: 2.6253431562719607

Epoch: 6| Step: 3
Training loss: 3.6592290756358117
Validation loss: 2.687604052701142

Epoch: 6| Step: 4
Training loss: 2.6685432943656373
Validation loss: 2.6887481797669546

Epoch: 6| Step: 5
Training loss: 3.2612994444181465
Validation loss: 2.734023800283335

Epoch: 6| Step: 6
Training loss: 2.6221263233077274
Validation loss: 2.7565702898737405

Epoch: 6| Step: 7
Training loss: 2.298060934933829
Validation loss: 2.7774250311751394

Epoch: 6| Step: 8
Training loss: 3.3395976014922186
Validation loss: 2.741404499164247

Epoch: 6| Step: 9
Training loss: 2.7576189270381493
Validation loss: 2.6514306162151478

Epoch: 6| Step: 10
Training loss: 2.718241150690664
Validation loss: 2.606456021668446

Epoch: 6| Step: 11
Training loss: 3.414930010814243
Validation loss: 2.556912118435957

Epoch: 6| Step: 12
Training loss: 2.5295058469717957
Validation loss: 2.5459010626666574

Epoch: 6| Step: 13
Training loss: 2.8411622062978235
Validation loss: 2.5620541768759653

Epoch: 95| Step: 0
Training loss: 2.652627696595741
Validation loss: 2.603990461397388

Epoch: 6| Step: 1
Training loss: 2.9531989517236923
Validation loss: 2.609090708881368

Epoch: 6| Step: 2
Training loss: 3.4744271224686383
Validation loss: 2.5908995739461322

Epoch: 6| Step: 3
Training loss: 3.003325685271906
Validation loss: 2.589733963780338

Epoch: 6| Step: 4
Training loss: 3.032659930283411
Validation loss: 2.5847191132059706

Epoch: 6| Step: 5
Training loss: 3.05797273413888
Validation loss: 2.5740603108569

Epoch: 6| Step: 6
Training loss: 3.1580335657656398
Validation loss: 2.5803241775583214

Epoch: 6| Step: 7
Training loss: 2.308720154375732
Validation loss: 2.578128501216019

Epoch: 6| Step: 8
Training loss: 2.3667626330122227
Validation loss: 2.577452620714974

Epoch: 6| Step: 9
Training loss: 3.467917677539142
Validation loss: 2.5782706330484295

Epoch: 6| Step: 10
Training loss: 3.0745723768181112
Validation loss: 2.5784849947824577

Epoch: 6| Step: 11
Training loss: 3.2910698136302847
Validation loss: 2.5872503326936034

Epoch: 6| Step: 12
Training loss: 2.833579520207412
Validation loss: 2.5938688019459994

Epoch: 6| Step: 13
Training loss: 1.5668589254193046
Validation loss: 2.591710565477014

Epoch: 96| Step: 0
Training loss: 2.479341698459683
Validation loss: 2.614425187344443

Epoch: 6| Step: 1
Training loss: 2.934728085661017
Validation loss: 2.667372931762199

Epoch: 6| Step: 2
Training loss: 3.0006169638419844
Validation loss: 2.7222356614559695

Epoch: 6| Step: 3
Training loss: 3.0973382043339033
Validation loss: 2.7453008161098396

Epoch: 6| Step: 4
Training loss: 3.2754824858074794
Validation loss: 2.727578770579364

Epoch: 6| Step: 5
Training loss: 3.1560254914157175
Validation loss: 2.701240289846262

Epoch: 6| Step: 6
Training loss: 3.030815486636903
Validation loss: 2.6835078842335944

Epoch: 6| Step: 7
Training loss: 3.1284261613776954
Validation loss: 2.5942796140996514

Epoch: 6| Step: 8
Training loss: 2.5555653594930074
Validation loss: 2.546074548261436

Epoch: 6| Step: 9
Training loss: 3.1281560600941427
Validation loss: 2.547503215416589

Epoch: 6| Step: 10
Training loss: 3.117672837031206
Validation loss: 2.5511171192400517

Epoch: 6| Step: 11
Training loss: 2.86961972551758
Validation loss: 2.5660304059041708

Epoch: 6| Step: 12
Training loss: 2.4973836559732008
Validation loss: 2.5606132482389534

Epoch: 6| Step: 13
Training loss: 3.234352443450557
Validation loss: 2.5620289471388906

Epoch: 97| Step: 0
Training loss: 2.774477309755153
Validation loss: 2.5550627169310425

Epoch: 6| Step: 1
Training loss: 2.8045610064615896
Validation loss: 2.5583397844537936

Epoch: 6| Step: 2
Training loss: 3.24733962698932
Validation loss: 2.5508081618503096

Epoch: 6| Step: 3
Training loss: 3.2950470543889363
Validation loss: 2.561365230962587

Epoch: 6| Step: 4
Training loss: 2.8951929239612975
Validation loss: 2.5545057849469406

Epoch: 6| Step: 5
Training loss: 2.8989150484184214
Validation loss: 2.5641527995902686

Epoch: 6| Step: 6
Training loss: 2.596845319557654
Validation loss: 2.569049861076607

Epoch: 6| Step: 7
Training loss: 2.461736640150897
Validation loss: 2.569770104204877

Epoch: 6| Step: 8
Training loss: 3.3332784807142466
Validation loss: 2.5938341008752563

Epoch: 6| Step: 9
Training loss: 2.9803105183567093
Validation loss: 2.6326228530189724

Epoch: 6| Step: 10
Training loss: 2.5463230026334513
Validation loss: 2.605205611832516

Epoch: 6| Step: 11
Training loss: 3.1687715127128167
Validation loss: 2.5966666751641316

Epoch: 6| Step: 12
Training loss: 3.089506996602478
Validation loss: 2.570788151991905

Epoch: 6| Step: 13
Training loss: 1.6764951665747754
Validation loss: 2.552177574790037

Epoch: 98| Step: 0
Training loss: 2.820555277595993
Validation loss: 2.5503382375435626

Epoch: 6| Step: 1
Training loss: 2.797078301057608
Validation loss: 2.548053309088313

Epoch: 6| Step: 2
Training loss: 2.9043390698115954
Validation loss: 2.552451127358098

Epoch: 6| Step: 3
Training loss: 2.734264785725229
Validation loss: 2.5483556455122858

Epoch: 6| Step: 4
Training loss: 3.345495036034699
Validation loss: 2.549024695230939

Epoch: 6| Step: 5
Training loss: 2.853693252246548
Validation loss: 2.5450321477997586

Epoch: 6| Step: 6
Training loss: 3.390390976946833
Validation loss: 2.5571449083458937

Epoch: 6| Step: 7
Training loss: 1.8738260408715544
Validation loss: 2.558356632234664

Epoch: 6| Step: 8
Training loss: 3.1005599469875245
Validation loss: 2.560823207580914

Epoch: 6| Step: 9
Training loss: 2.6756872452978615
Validation loss: 2.5731398666781975

Epoch: 6| Step: 10
Training loss: 2.7572800768032315
Validation loss: 2.5817436802905784

Epoch: 6| Step: 11
Training loss: 3.016962733062911
Validation loss: 2.594497719170794

Epoch: 6| Step: 12
Training loss: 2.8071786342269793
Validation loss: 2.5910146962768947

Epoch: 6| Step: 13
Training loss: 3.237743153517495
Validation loss: 2.594619073624025

Epoch: 99| Step: 0
Training loss: 3.1103656666673936
Validation loss: 2.6047466982438636

Epoch: 6| Step: 1
Training loss: 2.4923110022482127
Validation loss: 2.6239131791040724

Epoch: 6| Step: 2
Training loss: 3.1083611603855745
Validation loss: 2.6235143771298692

Epoch: 6| Step: 3
Training loss: 3.4620995906298613
Validation loss: 2.6122928305460236

Epoch: 6| Step: 4
Training loss: 3.1922064050085694
Validation loss: 2.600462351550873

Epoch: 6| Step: 5
Training loss: 2.52627102049888
Validation loss: 2.5692738307221306

Epoch: 6| Step: 6
Training loss: 3.03262596755588
Validation loss: 2.564149630221486

Epoch: 6| Step: 7
Training loss: 2.937185717063774
Validation loss: 2.5631150098655784

Epoch: 6| Step: 8
Training loss: 2.9122298872616095
Validation loss: 2.5710464259056294

Epoch: 6| Step: 9
Training loss: 2.729033915855866
Validation loss: 2.577657358485189

Epoch: 6| Step: 10
Training loss: 2.8189213668936373
Validation loss: 2.5637546532148714

Epoch: 6| Step: 11
Training loss: 2.992554963259636
Validation loss: 2.558146848258711

Epoch: 6| Step: 12
Training loss: 2.3248444043670107
Validation loss: 2.555147752047486

Epoch: 6| Step: 13
Training loss: 2.730073957594249
Validation loss: 2.5583079654640652

Epoch: 100| Step: 0
Training loss: 3.053122663545837
Validation loss: 2.5464222058410253

Epoch: 6| Step: 1
Training loss: 3.3392858920523505
Validation loss: 2.543904835211253

Epoch: 6| Step: 2
Training loss: 3.154360214872953
Validation loss: 2.539301793991327

Epoch: 6| Step: 3
Training loss: 2.7494093520751544
Validation loss: 2.5450295207295137

Epoch: 6| Step: 4
Training loss: 2.9745255356393243
Validation loss: 2.540229456246638

Epoch: 6| Step: 5
Training loss: 2.854411502184594
Validation loss: 2.539191173388343

Epoch: 6| Step: 6
Training loss: 2.577649621774037
Validation loss: 2.543131088877653

Epoch: 6| Step: 7
Training loss: 3.0028958649009883
Validation loss: 2.543627426614027

Epoch: 6| Step: 8
Training loss: 3.202099743025227
Validation loss: 2.548613948559095

Epoch: 6| Step: 9
Training loss: 2.7632010662081217
Validation loss: 2.541359907292088

Epoch: 6| Step: 10
Training loss: 2.361217663423883
Validation loss: 2.543048124809028

Epoch: 6| Step: 11
Training loss: 2.7414892454240776
Validation loss: 2.5411474469852338

Epoch: 6| Step: 12
Training loss: 2.3103565901939334
Validation loss: 2.539184316989643

Epoch: 6| Step: 13
Training loss: 3.1298747379478526
Validation loss: 2.5402039905674463

Epoch: 101| Step: 0
Training loss: 2.8171168262928283
Validation loss: 2.5422310010174645

Epoch: 6| Step: 1
Training loss: 3.4574003378184694
Validation loss: 2.5464621427621914

Epoch: 6| Step: 2
Training loss: 2.3981160001210577
Validation loss: 2.5386022663364485

Epoch: 6| Step: 3
Training loss: 2.956679369853648
Validation loss: 2.544847915911118

Epoch: 6| Step: 4
Training loss: 2.260855554494217
Validation loss: 2.5493023753143684

Epoch: 6| Step: 5
Training loss: 3.1148031576060027
Validation loss: 2.558567977132953

Epoch: 6| Step: 6
Training loss: 3.024374015919887
Validation loss: 2.552783892178159

Epoch: 6| Step: 7
Training loss: 3.6591697837302593
Validation loss: 2.556673576762884

Epoch: 6| Step: 8
Training loss: 2.752821428620297
Validation loss: 2.5554810575621603

Epoch: 6| Step: 9
Training loss: 2.534992230345126
Validation loss: 2.542770908070018

Epoch: 6| Step: 10
Training loss: 2.6747289217203862
Validation loss: 2.5379308286629567

Epoch: 6| Step: 11
Training loss: 2.888819114950995
Validation loss: 2.5349271634034105

Epoch: 6| Step: 12
Training loss: 3.045380524158889
Validation loss: 2.5311982111441784

Epoch: 6| Step: 13
Training loss: 1.9238820954318934
Validation loss: 2.5264004082905998

Epoch: 102| Step: 0
Training loss: 2.765380934813525
Validation loss: 2.5239944719576104

Epoch: 6| Step: 1
Training loss: 2.6639695137330075
Validation loss: 2.5320779248302387

Epoch: 6| Step: 2
Training loss: 2.6413973068270944
Validation loss: 2.5332758271448204

Epoch: 6| Step: 3
Training loss: 2.9482659626090886
Validation loss: 2.5425711249187612

Epoch: 6| Step: 4
Training loss: 2.899954262734526
Validation loss: 2.5363735164495047

Epoch: 6| Step: 5
Training loss: 2.7147494292855376
Validation loss: 2.5413956738918864

Epoch: 6| Step: 6
Training loss: 2.780436364650098
Validation loss: 2.5379092269361925

Epoch: 6| Step: 7
Training loss: 2.530183543909244
Validation loss: 2.5339021328616655

Epoch: 6| Step: 8
Training loss: 2.919464259186768
Validation loss: 2.545656898501525

Epoch: 6| Step: 9
Training loss: 2.870340635175288
Validation loss: 2.542027919990996

Epoch: 6| Step: 10
Training loss: 3.412883214428403
Validation loss: 2.552261660391354

Epoch: 6| Step: 11
Training loss: 2.9626459914664043
Validation loss: 2.547490741868654

Epoch: 6| Step: 12
Training loss: 3.002797729570194
Validation loss: 2.5569662429194304

Epoch: 6| Step: 13
Training loss: 2.9657833334457906
Validation loss: 2.548638444021335

Epoch: 103| Step: 0
Training loss: 2.8840217018527814
Validation loss: 2.5517899050524724

Epoch: 6| Step: 1
Training loss: 2.712458379048211
Validation loss: 2.5496098354802488

Epoch: 6| Step: 2
Training loss: 3.1740154692303526
Validation loss: 2.5593398722703897

Epoch: 6| Step: 3
Training loss: 2.7627389795837614
Validation loss: 2.558472225882461

Epoch: 6| Step: 4
Training loss: 2.240646417534057
Validation loss: 2.5660597503819385

Epoch: 6| Step: 5
Training loss: 2.844511328430738
Validation loss: 2.56655558804686

Epoch: 6| Step: 6
Training loss: 2.2494352479642385
Validation loss: 2.5570610083881227

Epoch: 6| Step: 7
Training loss: 2.626857372935455
Validation loss: 2.5586582411486827

Epoch: 6| Step: 8
Training loss: 3.008143656942471
Validation loss: 2.556707213956075

Epoch: 6| Step: 9
Training loss: 3.4239030515368336
Validation loss: 2.5456971344376975

Epoch: 6| Step: 10
Training loss: 2.279433690061568
Validation loss: 2.5309466898476125

Epoch: 6| Step: 11
Training loss: 3.3131177793984348
Validation loss: 2.528710671921469

Epoch: 6| Step: 12
Training loss: 3.094821012433356
Validation loss: 2.5234774999693843

Epoch: 6| Step: 13
Training loss: 3.393039529243548
Validation loss: 2.519619490730199

Epoch: 104| Step: 0
Training loss: 2.6628862844003423
Validation loss: 2.50986158582459

Epoch: 6| Step: 1
Training loss: 3.073061733808777
Validation loss: 2.5101057399683526

Epoch: 6| Step: 2
Training loss: 2.915007328135471
Validation loss: 2.5115781658690746

Epoch: 6| Step: 3
Training loss: 2.6074995965125263
Validation loss: 2.513354331999129

Epoch: 6| Step: 4
Training loss: 2.8100049289646565
Validation loss: 2.5112683616388356

Epoch: 6| Step: 5
Training loss: 2.842998363385717
Validation loss: 2.5105113295568717

Epoch: 6| Step: 6
Training loss: 3.025825917381865
Validation loss: 2.510801181101817

Epoch: 6| Step: 7
Training loss: 3.0484367867238724
Validation loss: 2.515430016649858

Epoch: 6| Step: 8
Training loss: 2.4354933279310638
Validation loss: 2.515849998224447

Epoch: 6| Step: 9
Training loss: 3.1688801575062313
Validation loss: 2.5156550537140348

Epoch: 6| Step: 10
Training loss: 2.8433170198581514
Validation loss: 2.5229582404308637

Epoch: 6| Step: 11
Training loss: 2.8310289174512704
Validation loss: 2.5221109335018275

Epoch: 6| Step: 12
Training loss: 2.3184058579217526
Validation loss: 2.531687662340457

Epoch: 6| Step: 13
Training loss: 3.6444059066233887
Validation loss: 2.535698299357979

Epoch: 105| Step: 0
Training loss: 2.4713264252070704
Validation loss: 2.5473211388282366

Epoch: 6| Step: 1
Training loss: 3.6922377845675225
Validation loss: 2.567537674768293

Epoch: 6| Step: 2
Training loss: 2.4957984904901793
Validation loss: 2.567950566873521

Epoch: 6| Step: 3
Training loss: 3.3795096327227734
Validation loss: 2.5739491880965235

Epoch: 6| Step: 4
Training loss: 2.854011717068546
Validation loss: 2.568450158293236

Epoch: 6| Step: 5
Training loss: 3.069956673928374
Validation loss: 2.5482373937419216

Epoch: 6| Step: 6
Training loss: 3.2354077150933764
Validation loss: 2.523782681920907

Epoch: 6| Step: 7
Training loss: 2.2518676847476176
Validation loss: 2.5129736301928767

Epoch: 6| Step: 8
Training loss: 2.799976355589081
Validation loss: 2.5106119365790796

Epoch: 6| Step: 9
Training loss: 3.285800067895434
Validation loss: 2.508444255839684

Epoch: 6| Step: 10
Training loss: 2.496039686975654
Validation loss: 2.5044009214197795

Epoch: 6| Step: 11
Training loss: 2.505256276983794
Validation loss: 2.5065045083270245

Epoch: 6| Step: 12
Training loss: 2.5369088297014706
Validation loss: 2.5095545168619733

Epoch: 6| Step: 13
Training loss: 2.424162934546178
Validation loss: 2.508456395176532

Epoch: 106| Step: 0
Training loss: 2.64483397426073
Validation loss: 2.5125484324544956

Epoch: 6| Step: 1
Training loss: 2.2393087056062426
Validation loss: 2.5194837818346816

Epoch: 6| Step: 2
Training loss: 2.7689526899214867
Validation loss: 2.534482753370729

Epoch: 6| Step: 3
Training loss: 2.6599364785088664
Validation loss: 2.555349424218959

Epoch: 6| Step: 4
Training loss: 3.3994335600291903
Validation loss: 2.58118346948746

Epoch: 6| Step: 5
Training loss: 2.903223245886217
Validation loss: 2.577648103072515

Epoch: 6| Step: 6
Training loss: 2.8541829649374035
Validation loss: 2.590767437534269

Epoch: 6| Step: 7
Training loss: 2.507575098132101
Validation loss: 2.595053969554721

Epoch: 6| Step: 8
Training loss: 2.9524044388980983
Validation loss: 2.580678513142199

Epoch: 6| Step: 9
Training loss: 3.0073406691611484
Validation loss: 2.574981127911824

Epoch: 6| Step: 10
Training loss: 2.982068513672893
Validation loss: 2.5606606958304416

Epoch: 6| Step: 11
Training loss: 3.0986658978792287
Validation loss: 2.548640411534287

Epoch: 6| Step: 12
Training loss: 2.890577986051375
Validation loss: 2.5472350060817255

Epoch: 6| Step: 13
Training loss: 2.8654745114413798
Validation loss: 2.5419781973229516

Epoch: 107| Step: 0
Training loss: 3.363004205615465
Validation loss: 2.5226505532814247

Epoch: 6| Step: 1
Training loss: 2.920927659133752
Validation loss: 2.522705569343606

Epoch: 6| Step: 2
Training loss: 2.7308370317285253
Validation loss: 2.5297885607070536

Epoch: 6| Step: 3
Training loss: 1.884119616864029
Validation loss: 2.520358325040251

Epoch: 6| Step: 4
Training loss: 3.5046943790335967
Validation loss: 2.522810275100029

Epoch: 6| Step: 5
Training loss: 3.1818923991081083
Validation loss: 2.5151625824592587

Epoch: 6| Step: 6
Training loss: 3.199978506492911
Validation loss: 2.5068593685745486

Epoch: 6| Step: 7
Training loss: 3.107494916842685
Validation loss: 2.5134625300412683

Epoch: 6| Step: 8
Training loss: 1.9194477539782309
Validation loss: 2.5115163660930007

Epoch: 6| Step: 9
Training loss: 2.584142701711269
Validation loss: 2.5100897694155955

Epoch: 6| Step: 10
Training loss: 2.32490501209772
Validation loss: 2.5065894438877634

Epoch: 6| Step: 11
Training loss: 2.924914732122211
Validation loss: 2.5083591010020085

Epoch: 6| Step: 12
Training loss: 2.651099383632106
Validation loss: 2.5088398138723873

Epoch: 6| Step: 13
Training loss: 3.0474227021751386
Validation loss: 2.5115739186121706

Epoch: 108| Step: 0
Training loss: 2.1658163847583647
Validation loss: 2.5163691434126174

Epoch: 6| Step: 1
Training loss: 2.8263350243920096
Validation loss: 2.514055721950636

Epoch: 6| Step: 2
Training loss: 3.2653411303803934
Validation loss: 2.5099165053159247

Epoch: 6| Step: 3
Training loss: 2.951943297330058
Validation loss: 2.5141620095190236

Epoch: 6| Step: 4
Training loss: 2.9612096495353004
Validation loss: 2.5267555140717284

Epoch: 6| Step: 5
Training loss: 2.6415006551313915
Validation loss: 2.521353471086524

Epoch: 6| Step: 6
Training loss: 2.7679748896854535
Validation loss: 2.5446712789922845

Epoch: 6| Step: 7
Training loss: 2.3801069064131997
Validation loss: 2.5309928997429942

Epoch: 6| Step: 8
Training loss: 3.217274447985006
Validation loss: 2.5344360892054065

Epoch: 6| Step: 9
Training loss: 3.5215478807796345
Validation loss: 2.5305019566175297

Epoch: 6| Step: 10
Training loss: 2.5365407774971334
Validation loss: 2.5278210006522923

Epoch: 6| Step: 11
Training loss: 2.684217533204782
Validation loss: 2.5271037710655615

Epoch: 6| Step: 12
Training loss: 2.7371717700403924
Validation loss: 2.516421257831305

Epoch: 6| Step: 13
Training loss: 2.7729103124609256
Validation loss: 2.4943730792705177

Epoch: 109| Step: 0
Training loss: 3.068968189819189
Validation loss: 2.5048614999342225

Epoch: 6| Step: 1
Training loss: 3.04703337428936
Validation loss: 2.533142617899185

Epoch: 6| Step: 2
Training loss: 3.2654643772175733
Validation loss: 2.5637954640749756

Epoch: 6| Step: 3
Training loss: 2.787263776409303
Validation loss: 2.5898889575326796

Epoch: 6| Step: 4
Training loss: 3.4150900265624577
Validation loss: 2.656622319243973

Epoch: 6| Step: 5
Training loss: 2.5582064502908226
Validation loss: 2.6232269322800708

Epoch: 6| Step: 6
Training loss: 2.9618817034273426
Validation loss: 2.5796040945517076

Epoch: 6| Step: 7
Training loss: 2.6280544312354674
Validation loss: 2.556714944852796

Epoch: 6| Step: 8
Training loss: 2.8595864473133528
Validation loss: 2.532092881933604

Epoch: 6| Step: 9
Training loss: 2.464267669437913
Validation loss: 2.515167431142534

Epoch: 6| Step: 10
Training loss: 2.853546037975334
Validation loss: 2.523127370780183

Epoch: 6| Step: 11
Training loss: 2.8242766610482923
Validation loss: 2.6049815685155604

Epoch: 6| Step: 12
Training loss: 2.8019078328550884
Validation loss: 2.649561348426049

Epoch: 6| Step: 13
Training loss: 2.9826775162109715
Validation loss: 2.5801329926140046

Epoch: 110| Step: 0
Training loss: 3.401802729480758
Validation loss: 2.5439859403036102

Epoch: 6| Step: 1
Training loss: 2.3419516212424702
Validation loss: 2.538248077605971

Epoch: 6| Step: 2
Training loss: 2.3033975385595276
Validation loss: 2.5353228577502382

Epoch: 6| Step: 3
Training loss: 3.256694940491787
Validation loss: 2.5411334178563347

Epoch: 6| Step: 4
Training loss: 3.013374239748003
Validation loss: 2.5621567492989086

Epoch: 6| Step: 5
Training loss: 3.3201206286473286
Validation loss: 2.5791786852245187

Epoch: 6| Step: 6
Training loss: 2.252898786090634
Validation loss: 2.5943913927564144

Epoch: 6| Step: 7
Training loss: 3.294553979257467
Validation loss: 2.619735114039828

Epoch: 6| Step: 8
Training loss: 2.6345806580042814
Validation loss: 2.6552968891547963

Epoch: 6| Step: 9
Training loss: 2.8893413270922768
Validation loss: 2.705914779765199

Epoch: 6| Step: 10
Training loss: 2.7427405861941696
Validation loss: 2.687536326661532

Epoch: 6| Step: 11
Training loss: 2.6210102460268696
Validation loss: 2.6695003342229815

Epoch: 6| Step: 12
Training loss: 2.825253372307839
Validation loss: 2.6464345534919413

Epoch: 6| Step: 13
Training loss: 2.891156616813897
Validation loss: 2.6443289317686998

Epoch: 111| Step: 0
Training loss: 1.887352373021517
Validation loss: 2.631130735555828

Epoch: 6| Step: 1
Training loss: 3.2570287553023247
Validation loss: 2.6262545178387273

Epoch: 6| Step: 2
Training loss: 3.463482818486004
Validation loss: 2.604050783265683

Epoch: 6| Step: 3
Training loss: 2.619668086773051
Validation loss: 2.5681319684875303

Epoch: 6| Step: 4
Training loss: 2.616144410839956
Validation loss: 2.5485698295776467

Epoch: 6| Step: 5
Training loss: 3.0189326829307377
Validation loss: 2.550468540356451

Epoch: 6| Step: 6
Training loss: 2.3544611001226943
Validation loss: 2.551391827988098

Epoch: 6| Step: 7
Training loss: 2.9764848033146065
Validation loss: 2.5564432865730677

Epoch: 6| Step: 8
Training loss: 3.146738810466542
Validation loss: 2.5378404173671445

Epoch: 6| Step: 9
Training loss: 2.8275832189427046
Validation loss: 2.527988214540678

Epoch: 6| Step: 10
Training loss: 3.054803636299338
Validation loss: 2.5271284882138363

Epoch: 6| Step: 11
Training loss: 2.8747624838199948
Validation loss: 2.521638679728363

Epoch: 6| Step: 12
Training loss: 3.4564165678810554
Validation loss: 2.5191733236183764

Epoch: 6| Step: 13
Training loss: 2.2155967118753477
Validation loss: 2.5293530813511125

Epoch: 112| Step: 0
Training loss: 2.6440344474845374
Validation loss: 2.522002201796514

Epoch: 6| Step: 1
Training loss: 2.228849822251685
Validation loss: 2.5518005336624396

Epoch: 6| Step: 2
Training loss: 2.774337837329554
Validation loss: 2.5661797543345415

Epoch: 6| Step: 3
Training loss: 2.772341573469581
Validation loss: 2.5649457195578336

Epoch: 6| Step: 4
Training loss: 3.3063145593350605
Validation loss: 2.559604691853993

Epoch: 6| Step: 5
Training loss: 2.89782823600927
Validation loss: 2.528590828233197

Epoch: 6| Step: 6
Training loss: 3.0524597630203743
Validation loss: 2.512679807330412

Epoch: 6| Step: 7
Training loss: 2.630211153438051
Validation loss: 2.502067441180215

Epoch: 6| Step: 8
Training loss: 2.984526465601696
Validation loss: 2.501069368308946

Epoch: 6| Step: 9
Training loss: 2.7275039228066715
Validation loss: 2.5034403980399484

Epoch: 6| Step: 10
Training loss: 3.2484884414972166
Validation loss: 2.495820658018153

Epoch: 6| Step: 11
Training loss: 3.0524831950406965
Validation loss: 2.4943350772028383

Epoch: 6| Step: 12
Training loss: 2.653302251243966
Validation loss: 2.4974662718389857

Epoch: 6| Step: 13
Training loss: 2.848929414945258
Validation loss: 2.501363719701284

Epoch: 113| Step: 0
Training loss: 2.801947144858694
Validation loss: 2.4968902556211687

Epoch: 6| Step: 1
Training loss: 3.03756779096645
Validation loss: 2.507786737850916

Epoch: 6| Step: 2
Training loss: 2.8891713379267525
Validation loss: 2.5249740030677836

Epoch: 6| Step: 3
Training loss: 3.2433269658537482
Validation loss: 2.542867704227267

Epoch: 6| Step: 4
Training loss: 3.0517368749281757
Validation loss: 2.5272533910755772

Epoch: 6| Step: 5
Training loss: 1.895208682041724
Validation loss: 2.5364667438294277

Epoch: 6| Step: 6
Training loss: 2.9261461343627384
Validation loss: 2.517704981164246

Epoch: 6| Step: 7
Training loss: 2.5023833358353698
Validation loss: 2.5049145538040314

Epoch: 6| Step: 8
Training loss: 3.260039010077794
Validation loss: 2.50750941891926

Epoch: 6| Step: 9
Training loss: 2.4807854397675833
Validation loss: 2.4899983962172008

Epoch: 6| Step: 10
Training loss: 3.2419509985278108
Validation loss: 2.495967867143855

Epoch: 6| Step: 11
Training loss: 2.8907282630415247
Validation loss: 2.4978314397846275

Epoch: 6| Step: 12
Training loss: 2.302936677725588
Validation loss: 2.488852590138675

Epoch: 6| Step: 13
Training loss: 2.8401771989800997
Validation loss: 2.4916218478851686

Epoch: 114| Step: 0
Training loss: 3.289261836809485
Validation loss: 2.50281829104051

Epoch: 6| Step: 1
Training loss: 3.020859992249465
Validation loss: 2.5032739469787297

Epoch: 6| Step: 2
Training loss: 3.3373420135023455
Validation loss: 2.5097884853083707

Epoch: 6| Step: 3
Training loss: 2.8758581788028774
Validation loss: 2.5166887956165342

Epoch: 6| Step: 4
Training loss: 3.1550166675834683
Validation loss: 2.5216675973432094

Epoch: 6| Step: 5
Training loss: 2.764780206480965
Validation loss: 2.514945517606532

Epoch: 6| Step: 6
Training loss: 2.8925342749672565
Validation loss: 2.5265154620143973

Epoch: 6| Step: 7
Training loss: 2.647979066495179
Validation loss: 2.5470717622300514

Epoch: 6| Step: 8
Training loss: 2.094170143902775
Validation loss: 2.5449883051881033

Epoch: 6| Step: 9
Training loss: 2.5846547982028087
Validation loss: 2.5478541594931707

Epoch: 6| Step: 10
Training loss: 2.6773212985145687
Validation loss: 2.54494980478084

Epoch: 6| Step: 11
Training loss: 2.6929571945522404
Validation loss: 2.535212502398291

Epoch: 6| Step: 12
Training loss: 2.921887402839652
Validation loss: 2.5303596349583906

Epoch: 6| Step: 13
Training loss: 1.7935971424221242
Validation loss: 2.5247950537831425

Epoch: 115| Step: 0
Training loss: 2.62126293290149
Validation loss: 2.5117011249765713

Epoch: 6| Step: 1
Training loss: 2.500871220417897
Validation loss: 2.501990637365495

Epoch: 6| Step: 2
Training loss: 2.835193210591094
Validation loss: 2.494664802813498

Epoch: 6| Step: 3
Training loss: 2.8226571520971
Validation loss: 2.494586666327636

Epoch: 6| Step: 4
Training loss: 2.26884578786361
Validation loss: 2.4890475739058173

Epoch: 6| Step: 5
Training loss: 2.4310311775483586
Validation loss: 2.4896632407510126

Epoch: 6| Step: 6
Training loss: 2.2288996694035133
Validation loss: 2.492298348134367

Epoch: 6| Step: 7
Training loss: 2.9079361812929556
Validation loss: 2.4907126635055348

Epoch: 6| Step: 8
Training loss: 2.5658841001124664
Validation loss: 2.497690733975506

Epoch: 6| Step: 9
Training loss: 3.281728800399655
Validation loss: 2.5247783496187606

Epoch: 6| Step: 10
Training loss: 2.990152408963966
Validation loss: 2.5411687619121768

Epoch: 6| Step: 11
Training loss: 3.2533288193759975
Validation loss: 2.5687151295001436

Epoch: 6| Step: 12
Training loss: 3.673794638254482
Validation loss: 2.607719948248189

Epoch: 6| Step: 13
Training loss: 2.5827182427184643
Validation loss: 2.6404023513183605

Epoch: 116| Step: 0
Training loss: 3.0479440231990296
Validation loss: 2.6847767612772526

Epoch: 6| Step: 1
Training loss: 2.4036075896213287
Validation loss: 2.7620179621003023

Epoch: 6| Step: 2
Training loss: 2.9532160669242358
Validation loss: 2.7861649326670825

Epoch: 6| Step: 3
Training loss: 2.840145467605602
Validation loss: 2.6907588157932225

Epoch: 6| Step: 4
Training loss: 2.862004472911653
Validation loss: 2.6162298456966724

Epoch: 6| Step: 5
Training loss: 3.0173512000031013
Validation loss: 2.5271747902432478

Epoch: 6| Step: 6
Training loss: 3.0487386628050017
Validation loss: 2.52334325735

Epoch: 6| Step: 7
Training loss: 3.4213989484069462
Validation loss: 2.558878861427642

Epoch: 6| Step: 8
Training loss: 3.3403711092240735
Validation loss: 2.54136087570846

Epoch: 6| Step: 9
Training loss: 2.368602770253373
Validation loss: 2.5781316235688094

Epoch: 6| Step: 10
Training loss: 3.1620384995338338
Validation loss: 2.6031430017201216

Epoch: 6| Step: 11
Training loss: 2.313462546786375
Validation loss: 2.552392099037945

Epoch: 6| Step: 12
Training loss: 3.073611130340694
Validation loss: 2.544471651600581

Epoch: 6| Step: 13
Training loss: 3.0212760513186288
Validation loss: 2.5363407653970795

Epoch: 117| Step: 0
Training loss: 3.1338878127456917
Validation loss: 2.520414898554742

Epoch: 6| Step: 1
Training loss: 2.9767454396497506
Validation loss: 2.5263157389598434

Epoch: 6| Step: 2
Training loss: 2.9297565096038967
Validation loss: 2.5445192314253338

Epoch: 6| Step: 3
Training loss: 2.952046030724638
Validation loss: 2.5603462920928104

Epoch: 6| Step: 4
Training loss: 2.851283229582402
Validation loss: 2.573396280746589

Epoch: 6| Step: 5
Training loss: 2.8569776146652326
Validation loss: 2.5891344991824883

Epoch: 6| Step: 6
Training loss: 2.684875715139047
Validation loss: 2.6043886581473004

Epoch: 6| Step: 7
Training loss: 2.879731307211386
Validation loss: 2.6101913889455592

Epoch: 6| Step: 8
Training loss: 2.386968671384563
Validation loss: 2.5958670871438727

Epoch: 6| Step: 9
Training loss: 2.557879958431276
Validation loss: 2.590950636494551

Epoch: 6| Step: 10
Training loss: 2.29690946176847
Validation loss: 2.5816479480127583

Epoch: 6| Step: 11
Training loss: 2.6589664705765643
Validation loss: 2.568692525143761

Epoch: 6| Step: 12
Training loss: 3.6148610883222347
Validation loss: 2.5691068701548296

Epoch: 6| Step: 13
Training loss: 3.162239661074452
Validation loss: 2.55904461694777

Epoch: 118| Step: 0
Training loss: 3.0377566319439473
Validation loss: 2.5674587964592552

Epoch: 6| Step: 1
Training loss: 2.7509536823462786
Validation loss: 2.56101510729545

Epoch: 6| Step: 2
Training loss: 2.751363589599319
Validation loss: 2.5552247429484973

Epoch: 6| Step: 3
Training loss: 3.2732344316301543
Validation loss: 2.560647353286536

Epoch: 6| Step: 4
Training loss: 3.2277309712707454
Validation loss: 2.5450464898631986

Epoch: 6| Step: 5
Training loss: 3.2934866754712013
Validation loss: 2.549139788824033

Epoch: 6| Step: 6
Training loss: 2.2503502890983484
Validation loss: 2.5443518061850816

Epoch: 6| Step: 7
Training loss: 2.7098320457805336
Validation loss: 2.541217324129679

Epoch: 6| Step: 8
Training loss: 2.920555102219874
Validation loss: 2.547515722112328

Epoch: 6| Step: 9
Training loss: 2.3608858437381266
Validation loss: 2.5412293175036758

Epoch: 6| Step: 10
Training loss: 2.6509865166124453
Validation loss: 2.5388845285748434

Epoch: 6| Step: 11
Training loss: 2.8626726656482075
Validation loss: 2.550594733637035

Epoch: 6| Step: 12
Training loss: 2.5676981607871414
Validation loss: 2.550142482321398

Epoch: 6| Step: 13
Training loss: 3.1597860942342155
Validation loss: 2.5525343060583228

Epoch: 119| Step: 0
Training loss: 3.4701340122344284
Validation loss: 2.5528574235209875

Epoch: 6| Step: 1
Training loss: 3.315617372034846
Validation loss: 2.5534044129194946

Epoch: 6| Step: 2
Training loss: 2.503723804414925
Validation loss: 2.5411383814286994

Epoch: 6| Step: 3
Training loss: 3.1518514974437606
Validation loss: 2.531029811545792

Epoch: 6| Step: 4
Training loss: 2.805565231818539
Validation loss: 2.5216025596935783

Epoch: 6| Step: 5
Training loss: 2.484281718104295
Validation loss: 2.5275842700813618

Epoch: 6| Step: 6
Training loss: 2.7323294699629432
Validation loss: 2.5217581574328287

Epoch: 6| Step: 7
Training loss: 3.1722488558828266
Validation loss: 2.525607908706581

Epoch: 6| Step: 8
Training loss: 2.7757903099180616
Validation loss: 2.5263788124924775

Epoch: 6| Step: 9
Training loss: 2.804551910268183
Validation loss: 2.5373135812084877

Epoch: 6| Step: 10
Training loss: 1.9715814362863782
Validation loss: 2.532621191794137

Epoch: 6| Step: 11
Training loss: 2.7532572962380994
Validation loss: 2.5492243215771246

Epoch: 6| Step: 12
Training loss: 2.512108471478321
Validation loss: 2.5530351549358596

Epoch: 6| Step: 13
Training loss: 3.0081110025885085
Validation loss: 2.569502506045384

Epoch: 120| Step: 0
Training loss: 2.527216865384979
Validation loss: 2.567719987149209

Epoch: 6| Step: 1
Training loss: 3.2529521152315257
Validation loss: 2.5534970541477953

Epoch: 6| Step: 2
Training loss: 2.6034974929624606
Validation loss: 2.5504506292659337

Epoch: 6| Step: 3
Training loss: 3.0990056565889503
Validation loss: 2.541397718633495

Epoch: 6| Step: 4
Training loss: 3.1140148107510903
Validation loss: 2.534040761217107

Epoch: 6| Step: 5
Training loss: 2.5071258080119767
Validation loss: 2.5176909945113835

Epoch: 6| Step: 6
Training loss: 3.005482115193996
Validation loss: 2.5171121939900196

Epoch: 6| Step: 7
Training loss: 2.7498932731032038
Validation loss: 2.5116070339603627

Epoch: 6| Step: 8
Training loss: 2.885301461427459
Validation loss: 2.5159115387054114

Epoch: 6| Step: 9
Training loss: 2.938722721234483
Validation loss: 2.5071154046513406

Epoch: 6| Step: 10
Training loss: 2.5154000886635477
Validation loss: 2.520055777229844

Epoch: 6| Step: 11
Training loss: 2.804271784073833
Validation loss: 2.5137982618317736

Epoch: 6| Step: 12
Training loss: 2.9116687095851823
Validation loss: 2.5166937890642544

Epoch: 6| Step: 13
Training loss: 2.6075824359506488
Validation loss: 2.530675268054585

Epoch: 121| Step: 0
Training loss: 2.7673865274187253
Validation loss: 2.5313886753603434

Epoch: 6| Step: 1
Training loss: 2.8019688428062737
Validation loss: 2.524394685943762

Epoch: 6| Step: 2
Training loss: 3.2683543795527736
Validation loss: 2.5332318144628054

Epoch: 6| Step: 3
Training loss: 2.7035957764383878
Validation loss: 2.517731349499992

Epoch: 6| Step: 4
Training loss: 2.772897845136782
Validation loss: 2.522483659380325

Epoch: 6| Step: 5
Training loss: 3.0443400474927347
Validation loss: 2.495494664271213

Epoch: 6| Step: 6
Training loss: 2.604314225148914
Validation loss: 2.489366481166933

Epoch: 6| Step: 7
Training loss: 3.26412067717571
Validation loss: 2.4861446781733467

Epoch: 6| Step: 8
Training loss: 3.003387922354686
Validation loss: 2.4846731667278648

Epoch: 6| Step: 9
Training loss: 2.647108616703419
Validation loss: 2.4829228783443074

Epoch: 6| Step: 10
Training loss: 1.8021251769160034
Validation loss: 2.4749195791408036

Epoch: 6| Step: 11
Training loss: 2.8468041420586325
Validation loss: 2.4825828890330586

Epoch: 6| Step: 12
Training loss: 2.7281438837785195
Validation loss: 2.496078600803732

Epoch: 6| Step: 13
Training loss: 2.887766316340456
Validation loss: 2.5066797888298225

Epoch: 122| Step: 0
Training loss: 2.848064126525038
Validation loss: 2.5259436627781846

Epoch: 6| Step: 1
Training loss: 2.9533810782035594
Validation loss: 2.522691901058104

Epoch: 6| Step: 2
Training loss: 2.4266102429352276
Validation loss: 2.5194468219611985

Epoch: 6| Step: 3
Training loss: 2.5515470187762324
Validation loss: 2.521278752517433

Epoch: 6| Step: 4
Training loss: 3.6039578298288357
Validation loss: 2.5165213311154546

Epoch: 6| Step: 5
Training loss: 2.89648305799026
Validation loss: 2.504878213078608

Epoch: 6| Step: 6
Training loss: 2.5312762788891967
Validation loss: 2.491729943263578

Epoch: 6| Step: 7
Training loss: 2.6164567069436298
Validation loss: 2.4931361181342835

Epoch: 6| Step: 8
Training loss: 3.028387231957725
Validation loss: 2.4906666655885763

Epoch: 6| Step: 9
Training loss: 2.676144584992133
Validation loss: 2.5073055838221023

Epoch: 6| Step: 10
Training loss: 2.543528411736546
Validation loss: 2.5266642138374293

Epoch: 6| Step: 11
Training loss: 2.6793608619311597
Validation loss: 2.5120895265940724

Epoch: 6| Step: 12
Training loss: 2.99744879009927
Validation loss: 2.4993966784608688

Epoch: 6| Step: 13
Training loss: 2.730230885897311
Validation loss: 2.4985545399393114

Epoch: 123| Step: 0
Training loss: 2.7808030015729504
Validation loss: 2.492019171875408

Epoch: 6| Step: 1
Training loss: 3.0232405093186117
Validation loss: 2.4863430696468174

Epoch: 6| Step: 2
Training loss: 2.9705040819248882
Validation loss: 2.4876919773369166

Epoch: 6| Step: 3
Training loss: 2.8866127005004376
Validation loss: 2.4798625949229898

Epoch: 6| Step: 4
Training loss: 2.4197440339905705
Validation loss: 2.4827190175602074

Epoch: 6| Step: 5
Training loss: 2.852476375926666
Validation loss: 2.4800911962679386

Epoch: 6| Step: 6
Training loss: 2.341857756649701
Validation loss: 2.4913030049996694

Epoch: 6| Step: 7
Training loss: 2.2582123610224007
Validation loss: 2.491843746956624

Epoch: 6| Step: 8
Training loss: 2.714447651241513
Validation loss: 2.516776390375764

Epoch: 6| Step: 9
Training loss: 3.0153885980951065
Validation loss: 2.5177151391563775

Epoch: 6| Step: 10
Training loss: 2.7171660446013095
Validation loss: 2.5447245939355345

Epoch: 6| Step: 11
Training loss: 3.374719961345664
Validation loss: 2.57270297230483

Epoch: 6| Step: 12
Training loss: 3.2322609299527962
Validation loss: 2.600947078563747

Epoch: 6| Step: 13
Training loss: 2.5166943095964838
Validation loss: 2.612308746448208

Epoch: 124| Step: 0
Training loss: 3.1729635240614433
Validation loss: 2.5640124777834745

Epoch: 6| Step: 1
Training loss: 2.8416921694628234
Validation loss: 2.5273582634451506

Epoch: 6| Step: 2
Training loss: 2.6496320073115665
Validation loss: 2.5081587202232365

Epoch: 6| Step: 3
Training loss: 2.6115019575648866
Validation loss: 2.4938472447060254

Epoch: 6| Step: 4
Training loss: 3.3073444192038375
Validation loss: 2.4865286922225893

Epoch: 6| Step: 5
Training loss: 2.5979859107078176
Validation loss: 2.477082126271846

Epoch: 6| Step: 6
Training loss: 2.718827520558789
Validation loss: 2.4720905175621817

Epoch: 6| Step: 7
Training loss: 3.2202263566535096
Validation loss: 2.4736785623401207

Epoch: 6| Step: 8
Training loss: 2.5876993590876163
Validation loss: 2.4679434567214757

Epoch: 6| Step: 9
Training loss: 2.609571803546277
Validation loss: 2.470551793437434

Epoch: 6| Step: 10
Training loss: 2.6886815866929243
Validation loss: 2.478572608488386

Epoch: 6| Step: 11
Training loss: 2.5307260606841813
Validation loss: 2.478708117433742

Epoch: 6| Step: 12
Training loss: 3.1234755803315855
Validation loss: 2.4842712252713595

Epoch: 6| Step: 13
Training loss: 2.095257117032325
Validation loss: 2.4955505214422415

Epoch: 125| Step: 0
Training loss: 3.148979651483792
Validation loss: 2.5056369419878575

Epoch: 6| Step: 1
Training loss: 2.493526374140433
Validation loss: 2.510560038547184

Epoch: 6| Step: 2
Training loss: 3.317545664745385
Validation loss: 2.5284729499038257

Epoch: 6| Step: 3
Training loss: 3.0359900469510017
Validation loss: 2.536766823024639

Epoch: 6| Step: 4
Training loss: 2.1274717204884936
Validation loss: 2.550081504534231

Epoch: 6| Step: 5
Training loss: 3.0543008154689857
Validation loss: 2.5326001784515553

Epoch: 6| Step: 6
Training loss: 3.1209648019748664
Validation loss: 2.5227289627726766

Epoch: 6| Step: 7
Training loss: 2.6824860042551766
Validation loss: 2.5108043044760953

Epoch: 6| Step: 8
Training loss: 2.7955255929358396
Validation loss: 2.497983851700089

Epoch: 6| Step: 9
Training loss: 1.8384099017971365
Validation loss: 2.4937584292258834

Epoch: 6| Step: 10
Training loss: 3.13854608004758
Validation loss: 2.4865268956837294

Epoch: 6| Step: 11
Training loss: 2.400584995976292
Validation loss: 2.4840247960660786

Epoch: 6| Step: 12
Training loss: 2.743702005648715
Validation loss: 2.4823515913795

Epoch: 6| Step: 13
Training loss: 2.7159031838533827
Validation loss: 2.4837328054434256

Epoch: 126| Step: 0
Training loss: 2.3485316010871413
Validation loss: 2.4797072206898547

Epoch: 6| Step: 1
Training loss: 3.302876149658862
Validation loss: 2.482602542360915

Epoch: 6| Step: 2
Training loss: 2.418064688657335
Validation loss: 2.483892493906488

Epoch: 6| Step: 3
Training loss: 2.839145495850194
Validation loss: 2.482762027823428

Epoch: 6| Step: 4
Training loss: 2.8816011359679057
Validation loss: 2.4841586474292274

Epoch: 6| Step: 5
Training loss: 2.832678906277903
Validation loss: 2.479904713999917

Epoch: 6| Step: 6
Training loss: 2.7912824755435213
Validation loss: 2.4902885089791575

Epoch: 6| Step: 7
Training loss: 2.8087860168945573
Validation loss: 2.508708665058251

Epoch: 6| Step: 8
Training loss: 2.5558935462501533
Validation loss: 2.5236066794987826

Epoch: 6| Step: 9
Training loss: 2.5484639459356946
Validation loss: 2.5312456733305067

Epoch: 6| Step: 10
Training loss: 3.401190543701277
Validation loss: 2.531812752399241

Epoch: 6| Step: 11
Training loss: 3.1823722134067043
Validation loss: 2.528028505042042

Epoch: 6| Step: 12
Training loss: 2.5422106197269514
Validation loss: 2.508492266072864

Epoch: 6| Step: 13
Training loss: 2.1811644223102715
Validation loss: 2.4990532210282073

Epoch: 127| Step: 0
Training loss: 3.01260651839366
Validation loss: 2.4933379735580483

Epoch: 6| Step: 1
Training loss: 1.7747745934939998
Validation loss: 2.479558420669244

Epoch: 6| Step: 2
Training loss: 3.2418949592701054
Validation loss: 2.4704227452979257

Epoch: 6| Step: 3
Training loss: 2.8615107663552126
Validation loss: 2.475377760690521

Epoch: 6| Step: 4
Training loss: 2.9424020973583915
Validation loss: 2.4696998933894077

Epoch: 6| Step: 5
Training loss: 2.7117088605633914
Validation loss: 2.4703318848635822

Epoch: 6| Step: 6
Training loss: 2.524702859145515
Validation loss: 2.4680500255752076

Epoch: 6| Step: 7
Training loss: 3.4255183085290715
Validation loss: 2.4702747226966415

Epoch: 6| Step: 8
Training loss: 2.8904285261037264
Validation loss: 2.4673132879365682

Epoch: 6| Step: 9
Training loss: 3.001708656736079
Validation loss: 2.4700700671217843

Epoch: 6| Step: 10
Training loss: 2.604325393925707
Validation loss: 2.4846168689778882

Epoch: 6| Step: 11
Training loss: 2.843158702369664
Validation loss: 2.4918115377074717

Epoch: 6| Step: 12
Training loss: 2.7439781493826714
Validation loss: 2.496346897438245

Epoch: 6| Step: 13
Training loss: 1.5024445799954291
Validation loss: 2.5052724533329767

Epoch: 128| Step: 0
Training loss: 2.683041622662233
Validation loss: 2.504225715843408

Epoch: 6| Step: 1
Training loss: 3.2380775967419266
Validation loss: 2.5038295220437625

Epoch: 6| Step: 2
Training loss: 2.465332756563693
Validation loss: 2.5226298207041533

Epoch: 6| Step: 3
Training loss: 2.286498733430066
Validation loss: 2.5217352256919017

Epoch: 6| Step: 4
Training loss: 3.0924228171952906
Validation loss: 2.533542931928362

Epoch: 6| Step: 5
Training loss: 2.7619585637237662
Validation loss: 2.5153517434866823

Epoch: 6| Step: 6
Training loss: 2.5066086205735028
Validation loss: 2.5056024043226968

Epoch: 6| Step: 7
Training loss: 3.212542427465605
Validation loss: 2.4953668618785136

Epoch: 6| Step: 8
Training loss: 3.092732888459712
Validation loss: 2.4935344530826447

Epoch: 6| Step: 9
Training loss: 2.380229212518403
Validation loss: 2.4837516734845906

Epoch: 6| Step: 10
Training loss: 3.0848674222629815
Validation loss: 2.483968381445764

Epoch: 6| Step: 11
Training loss: 2.3244942638041715
Validation loss: 2.4759603047523493

Epoch: 6| Step: 12
Training loss: 2.4969473321055617
Validation loss: 2.4739706391231953

Epoch: 6| Step: 13
Training loss: 3.3425955517506165
Validation loss: 2.469757350162271

Epoch: 129| Step: 0
Training loss: 3.195111032863976
Validation loss: 2.472400598088869

Epoch: 6| Step: 1
Training loss: 2.352605138652793
Validation loss: 2.4708560855885024

Epoch: 6| Step: 2
Training loss: 2.7810584013018165
Validation loss: 2.471469640241125

Epoch: 6| Step: 3
Training loss: 2.5476906997237205
Validation loss: 2.4708645307251556

Epoch: 6| Step: 4
Training loss: 2.719574901797039
Validation loss: 2.4801306704330948

Epoch: 6| Step: 5
Training loss: 2.8916854975047843
Validation loss: 2.490811980866039

Epoch: 6| Step: 6
Training loss: 2.4581129546443807
Validation loss: 2.4951783146360196

Epoch: 6| Step: 7
Training loss: 2.8478615350602943
Validation loss: 2.5027432342195643

Epoch: 6| Step: 8
Training loss: 2.571662895939902
Validation loss: 2.5061969830338016

Epoch: 6| Step: 9
Training loss: 2.4958069924655906
Validation loss: 2.49698408599735

Epoch: 6| Step: 10
Training loss: 3.227099505573398
Validation loss: 2.492958063132841

Epoch: 6| Step: 11
Training loss: 2.916668501353822
Validation loss: 2.4933931922236443

Epoch: 6| Step: 12
Training loss: 3.0724869422231618
Validation loss: 2.492194451747913

Epoch: 6| Step: 13
Training loss: 2.5642867023422093
Validation loss: 2.5017360309912613

Epoch: 130| Step: 0
Training loss: 3.1697943115891927
Validation loss: 2.4847876103649855

Epoch: 6| Step: 1
Training loss: 3.247760881688938
Validation loss: 2.483922968974864

Epoch: 6| Step: 2
Training loss: 2.7567681342397066
Validation loss: 2.4822682369866786

Epoch: 6| Step: 3
Training loss: 2.5446364973940048
Validation loss: 2.471614023199697

Epoch: 6| Step: 4
Training loss: 2.8689082748200674
Validation loss: 2.473752312277479

Epoch: 6| Step: 5
Training loss: 2.51025851267266
Validation loss: 2.4893696829267666

Epoch: 6| Step: 6
Training loss: 3.140553639678248
Validation loss: 2.495302968501399

Epoch: 6| Step: 7
Training loss: 2.4549689682127744
Validation loss: 2.489729647139079

Epoch: 6| Step: 8
Training loss: 2.7216421945300575
Validation loss: 2.4966130355598626

Epoch: 6| Step: 9
Training loss: 2.153016139408043
Validation loss: 2.5092041184242944

Epoch: 6| Step: 10
Training loss: 3.036521025458134
Validation loss: 2.5090714074965645

Epoch: 6| Step: 11
Training loss: 2.701155016357595
Validation loss: 2.4890001269239432

Epoch: 6| Step: 12
Training loss: 2.6555050871277257
Validation loss: 2.4885216267137955

Epoch: 6| Step: 13
Training loss: 2.5696696953085354
Validation loss: 2.479060367143558

Epoch: 131| Step: 0
Training loss: 2.5330216600867725
Validation loss: 2.4732664433281317

Epoch: 6| Step: 1
Training loss: 2.2215145242522327
Validation loss: 2.47970747915187

Epoch: 6| Step: 2
Training loss: 2.4674194226930513
Validation loss: 2.4716295131948667

Epoch: 6| Step: 3
Training loss: 2.5908933788109096
Validation loss: 2.4810137111883788

Epoch: 6| Step: 4
Training loss: 3.0276004805455763
Validation loss: 2.4811544152626306

Epoch: 6| Step: 5
Training loss: 2.8350341030538795
Validation loss: 2.480778436414197

Epoch: 6| Step: 6
Training loss: 3.018336524842329
Validation loss: 2.4818612908287245

Epoch: 6| Step: 7
Training loss: 3.201791774272009
Validation loss: 2.481124862210351

Epoch: 6| Step: 8
Training loss: 2.562350198972672
Validation loss: 2.4762693706361345

Epoch: 6| Step: 9
Training loss: 2.68055377448445
Validation loss: 2.4756020550471063

Epoch: 6| Step: 10
Training loss: 3.068603972089656
Validation loss: 2.4812031653538926

Epoch: 6| Step: 11
Training loss: 2.881523691943456
Validation loss: 2.4861027854617634

Epoch: 6| Step: 12
Training loss: 2.8733308341892405
Validation loss: 2.4835704228902875

Epoch: 6| Step: 13
Training loss: 2.4726967469284435
Validation loss: 2.4891244948858784

Epoch: 132| Step: 0
Training loss: 2.7531998830910265
Validation loss: 2.4877261556524046

Epoch: 6| Step: 1
Training loss: 3.091787775620296
Validation loss: 2.4881257868768416

Epoch: 6| Step: 2
Training loss: 2.8333528368409517
Validation loss: 2.4979343915099372

Epoch: 6| Step: 3
Training loss: 2.4615605610075515
Validation loss: 2.5019441274817518

Epoch: 6| Step: 4
Training loss: 3.2108819590124944
Validation loss: 2.4884667542711227

Epoch: 6| Step: 5
Training loss: 2.808373794113269
Validation loss: 2.4909528580763816

Epoch: 6| Step: 6
Training loss: 2.3242921961872254
Validation loss: 2.494535153259204

Epoch: 6| Step: 7
Training loss: 2.925495373112148
Validation loss: 2.5003363136990657

Epoch: 6| Step: 8
Training loss: 3.072332363288955
Validation loss: 2.4904791696651554

Epoch: 6| Step: 9
Training loss: 2.297568806810274
Validation loss: 2.495719733621363

Epoch: 6| Step: 10
Training loss: 2.681395761933829
Validation loss: 2.4924127800496234

Epoch: 6| Step: 11
Training loss: 2.318765349221645
Validation loss: 2.4877680488507368

Epoch: 6| Step: 12
Training loss: 3.0981660401760265
Validation loss: 2.497833454502057

Epoch: 6| Step: 13
Training loss: 2.335683853514451
Validation loss: 2.5028954561197976

Epoch: 133| Step: 0
Training loss: 2.2625245024476586
Validation loss: 2.502308911409345

Epoch: 6| Step: 1
Training loss: 2.3725842688239545
Validation loss: 2.4927379663592215

Epoch: 6| Step: 2
Training loss: 2.645163704145457
Validation loss: 2.486274348686928

Epoch: 6| Step: 3
Training loss: 3.0577876367274497
Validation loss: 2.488247944760971

Epoch: 6| Step: 4
Training loss: 2.4940503850159175
Validation loss: 2.4694271579014364

Epoch: 6| Step: 5
Training loss: 2.950777604371259
Validation loss: 2.4815153872764024

Epoch: 6| Step: 6
Training loss: 2.5362388521102686
Validation loss: 2.47475330336864

Epoch: 6| Step: 7
Training loss: 2.848915857606311
Validation loss: 2.4714484648306403

Epoch: 6| Step: 8
Training loss: 3.1422855674884937
Validation loss: 2.47585352137786

Epoch: 6| Step: 9
Training loss: 2.861228633882501
Validation loss: 2.4689598020308874

Epoch: 6| Step: 10
Training loss: 2.5665144759631433
Validation loss: 2.465736521431632

Epoch: 6| Step: 11
Training loss: 3.2735228607046056
Validation loss: 2.4731337537845395

Epoch: 6| Step: 12
Training loss: 2.869138132072181
Validation loss: 2.4864167027361774

Epoch: 6| Step: 13
Training loss: 2.40387896353999
Validation loss: 2.496202776310384

Epoch: 134| Step: 0
Training loss: 2.7706885240235435
Validation loss: 2.502904991542852

Epoch: 6| Step: 1
Training loss: 2.7745393525366358
Validation loss: 2.543060832855246

Epoch: 6| Step: 2
Training loss: 2.6015606671117792
Validation loss: 2.5704626657961196

Epoch: 6| Step: 3
Training loss: 2.2522304923235006
Validation loss: 2.5772410200117384

Epoch: 6| Step: 4
Training loss: 3.030510409079397
Validation loss: 2.590695701594346

Epoch: 6| Step: 5
Training loss: 3.0608061173708414
Validation loss: 2.5565847668710675

Epoch: 6| Step: 6
Training loss: 3.248901181433309
Validation loss: 2.5105292805125528

Epoch: 6| Step: 7
Training loss: 2.7477052824685217
Validation loss: 2.4881632990650706

Epoch: 6| Step: 8
Training loss: 2.577986187521286
Validation loss: 2.4635615357228606

Epoch: 6| Step: 9
Training loss: 2.6117480788436986
Validation loss: 2.465237647660138

Epoch: 6| Step: 10
Training loss: 3.0634944624616516
Validation loss: 2.4656272869977314

Epoch: 6| Step: 11
Training loss: 2.871250527182146
Validation loss: 2.46562671305462

Epoch: 6| Step: 12
Training loss: 2.4173055549697575
Validation loss: 2.463823000417324

Epoch: 6| Step: 13
Training loss: 3.1822506932660852
Validation loss: 2.4639946520814178

Epoch: 135| Step: 0
Training loss: 2.8492030585494703
Validation loss: 2.478179500023834

Epoch: 6| Step: 1
Training loss: 3.377092631046989
Validation loss: 2.5046495751650752

Epoch: 6| Step: 2
Training loss: 2.3386722746288493
Validation loss: 2.5098656521225724

Epoch: 6| Step: 3
Training loss: 2.430081154680839
Validation loss: 2.5358132238991473

Epoch: 6| Step: 4
Training loss: 2.365825399681334
Validation loss: 2.5472772168556674

Epoch: 6| Step: 5
Training loss: 3.205285511362535
Validation loss: 2.552698039162285

Epoch: 6| Step: 6
Training loss: 2.702663316053068
Validation loss: 2.542800057197445

Epoch: 6| Step: 7
Training loss: 2.9269586900846267
Validation loss: 2.5239513101052973

Epoch: 6| Step: 8
Training loss: 2.8085193862938667
Validation loss: 2.4868034432571915

Epoch: 6| Step: 9
Training loss: 2.4988555195880933
Validation loss: 2.4733786131155844

Epoch: 6| Step: 10
Training loss: 3.4271656401392643
Validation loss: 2.476849669329644

Epoch: 6| Step: 11
Training loss: 2.6469743225846765
Validation loss: 2.476240533683704

Epoch: 6| Step: 12
Training loss: 2.4170180317431402
Validation loss: 2.470940262270655

Epoch: 6| Step: 13
Training loss: 2.5772576925081685
Validation loss: 2.4766713271785004

Epoch: 136| Step: 0
Training loss: 2.9685166116628454
Validation loss: 2.469868417149206

Epoch: 6| Step: 1
Training loss: 3.1714593022992013
Validation loss: 2.467374561005246

Epoch: 6| Step: 2
Training loss: 2.8927248364422975
Validation loss: 2.4623609492448093

Epoch: 6| Step: 3
Training loss: 2.3195095535348003
Validation loss: 2.46343490728973

Epoch: 6| Step: 4
Training loss: 2.818481188895573
Validation loss: 2.4726899850450437

Epoch: 6| Step: 5
Training loss: 2.4662733572053477
Validation loss: 2.489785894150337

Epoch: 6| Step: 6
Training loss: 3.2538836823009416
Validation loss: 2.515883787898975

Epoch: 6| Step: 7
Training loss: 2.476284841863309
Validation loss: 2.526777073168825

Epoch: 6| Step: 8
Training loss: 3.2268118034645323
Validation loss: 2.5387867818078758

Epoch: 6| Step: 9
Training loss: 2.288048425188659
Validation loss: 2.5490008240242323

Epoch: 6| Step: 10
Training loss: 2.6048675712854052
Validation loss: 2.5417877025891324

Epoch: 6| Step: 11
Training loss: 3.0691624008868574
Validation loss: 2.5231893596419717

Epoch: 6| Step: 12
Training loss: 2.643668322733122
Validation loss: 2.50960127950506

Epoch: 6| Step: 13
Training loss: 2.554625064191889
Validation loss: 2.4886081546690617

Epoch: 137| Step: 0
Training loss: 3.309986672504251
Validation loss: 2.4747219604456294

Epoch: 6| Step: 1
Training loss: 2.8152171255498675
Validation loss: 2.4653555567818377

Epoch: 6| Step: 2
Training loss: 2.6844110701849835
Validation loss: 2.4749840184094847

Epoch: 6| Step: 3
Training loss: 3.2439676200765293
Validation loss: 2.4733269423428297

Epoch: 6| Step: 4
Training loss: 2.567596670409072
Validation loss: 2.4784352064623687

Epoch: 6| Step: 5
Training loss: 2.740419518870112
Validation loss: 2.479387327449295

Epoch: 6| Step: 6
Training loss: 2.1640050997506513
Validation loss: 2.472953656806976

Epoch: 6| Step: 7
Training loss: 2.3717631317415275
Validation loss: 2.47230762706177

Epoch: 6| Step: 8
Training loss: 2.483990141610994
Validation loss: 2.477676420065288

Epoch: 6| Step: 9
Training loss: 2.818541840101125
Validation loss: 2.4699290512929983

Epoch: 6| Step: 10
Training loss: 2.4523922743163387
Validation loss: 2.4820135524043576

Epoch: 6| Step: 11
Training loss: 3.0401788146985362
Validation loss: 2.476618809006656

Epoch: 6| Step: 12
Training loss: 2.6119355755582294
Validation loss: 2.4830702636211757

Epoch: 6| Step: 13
Training loss: 3.365828733378893
Validation loss: 2.4835662691532123

Epoch: 138| Step: 0
Training loss: 2.8298543627033754
Validation loss: 2.4843658067354246

Epoch: 6| Step: 1
Training loss: 3.183296873140164
Validation loss: 2.484321534328394

Epoch: 6| Step: 2
Training loss: 2.7025431629725163
Validation loss: 2.4942948591304748

Epoch: 6| Step: 3
Training loss: 2.523892293756974
Validation loss: 2.501065284634675

Epoch: 6| Step: 4
Training loss: 2.4113120796118412
Validation loss: 2.490656465214888

Epoch: 6| Step: 5
Training loss: 2.850588781205759
Validation loss: 2.5119880908612964

Epoch: 6| Step: 6
Training loss: 2.747637167119456
Validation loss: 2.516457040661066

Epoch: 6| Step: 7
Training loss: 2.7449556382560454
Validation loss: 2.500581786438104

Epoch: 6| Step: 8
Training loss: 2.578358402668703
Validation loss: 2.486988557809525

Epoch: 6| Step: 9
Training loss: 2.727632241683989
Validation loss: 2.476509051478719

Epoch: 6| Step: 10
Training loss: 3.259424483160452
Validation loss: 2.463513905913544

Epoch: 6| Step: 11
Training loss: 2.703828929466836
Validation loss: 2.4584306597193044

Epoch: 6| Step: 12
Training loss: 2.247607760789748
Validation loss: 2.4595723162822343

Epoch: 6| Step: 13
Training loss: 3.2350840505444234
Validation loss: 2.462700312743562

Epoch: 139| Step: 0
Training loss: 1.8431308806006375
Validation loss: 2.468151812904274

Epoch: 6| Step: 1
Training loss: 2.4487954584627305
Validation loss: 2.463221738229302

Epoch: 6| Step: 2
Training loss: 2.7969910155374675
Validation loss: 2.472735458925173

Epoch: 6| Step: 3
Training loss: 2.691714154307804
Validation loss: 2.4761939905026296

Epoch: 6| Step: 4
Training loss: 2.449209891612021
Validation loss: 2.4796672259529977

Epoch: 6| Step: 5
Training loss: 3.0461988432435145
Validation loss: 2.487907949482271

Epoch: 6| Step: 6
Training loss: 2.8888508068737297
Validation loss: 2.489980860430382

Epoch: 6| Step: 7
Training loss: 3.0951089667887923
Validation loss: 2.488205162236366

Epoch: 6| Step: 8
Training loss: 2.7672231765592596
Validation loss: 2.478646318305357

Epoch: 6| Step: 9
Training loss: 2.7701207059595685
Validation loss: 2.467763506096485

Epoch: 6| Step: 10
Training loss: 2.788441564857729
Validation loss: 2.4648600355566246

Epoch: 6| Step: 11
Training loss: 2.795551349122576
Validation loss: 2.476338022434256

Epoch: 6| Step: 12
Training loss: 2.897219008479211
Validation loss: 2.4773000251270214

Epoch: 6| Step: 13
Training loss: 3.1518631465945406
Validation loss: 2.471518416435694

Epoch: 140| Step: 0
Training loss: 2.140542801441318
Validation loss: 2.480111236297222

Epoch: 6| Step: 1
Training loss: 2.9904309886475846
Validation loss: 2.4986546588175176

Epoch: 6| Step: 2
Training loss: 2.0059865523065374
Validation loss: 2.5129251536592427

Epoch: 6| Step: 3
Training loss: 2.7434432151483747
Validation loss: 2.5021856587900184

Epoch: 6| Step: 4
Training loss: 2.992870123464721
Validation loss: 2.4952733641831855

Epoch: 6| Step: 5
Training loss: 2.934653668481285
Validation loss: 2.4836309919281208

Epoch: 6| Step: 6
Training loss: 2.89096314797917
Validation loss: 2.4748007873065045

Epoch: 6| Step: 7
Training loss: 2.936035278056396
Validation loss: 2.471776589668792

Epoch: 6| Step: 8
Training loss: 2.301780289486404
Validation loss: 2.4603864509584827

Epoch: 6| Step: 9
Training loss: 2.7644399054279796
Validation loss: 2.463495571781685

Epoch: 6| Step: 10
Training loss: 3.0108966026834567
Validation loss: 2.4675238749763313

Epoch: 6| Step: 11
Training loss: 2.480543913415821
Validation loss: 2.4618399672935074

Epoch: 6| Step: 12
Training loss: 2.9048376445737905
Validation loss: 2.462864144177944

Epoch: 6| Step: 13
Training loss: 3.383390804485415
Validation loss: 2.4675263985911915

Epoch: 141| Step: 0
Training loss: 2.6777010747952192
Validation loss: 2.4689696590532466

Epoch: 6| Step: 1
Training loss: 2.5199712324771104
Validation loss: 2.4794381357457844

Epoch: 6| Step: 2
Training loss: 2.8775739343128133
Validation loss: 2.478178714849253

Epoch: 6| Step: 3
Training loss: 2.88711318030124
Validation loss: 2.4901114363768992

Epoch: 6| Step: 4
Training loss: 2.7867475032793503
Validation loss: 2.493218539539453

Epoch: 6| Step: 5
Training loss: 2.4771824009759715
Validation loss: 2.4887566731984627

Epoch: 6| Step: 6
Training loss: 2.8962588283517867
Validation loss: 2.486543203672534

Epoch: 6| Step: 7
Training loss: 3.032861969203868
Validation loss: 2.499583736753227

Epoch: 6| Step: 8
Training loss: 2.8346495843386377
Validation loss: 2.490883868050346

Epoch: 6| Step: 9
Training loss: 2.405806760712788
Validation loss: 2.4920759813553484

Epoch: 6| Step: 10
Training loss: 2.8217208600534085
Validation loss: 2.504520301739004

Epoch: 6| Step: 11
Training loss: 2.8904898946994892
Validation loss: 2.517124579753809

Epoch: 6| Step: 12
Training loss: 2.7715657540135687
Validation loss: 2.5112679512551286

Epoch: 6| Step: 13
Training loss: 2.83586872952731
Validation loss: 2.524350370144422

Epoch: 142| Step: 0
Training loss: 2.6225061832205987
Validation loss: 2.5087969431009736

Epoch: 6| Step: 1
Training loss: 3.372429045092657
Validation loss: 2.512333402996286

Epoch: 6| Step: 2
Training loss: 3.0440060924915193
Validation loss: 2.5067553843519774

Epoch: 6| Step: 3
Training loss: 2.2460042653709937
Validation loss: 2.5064973835259363

Epoch: 6| Step: 4
Training loss: 2.7181385273442205
Validation loss: 2.5062684064272114

Epoch: 6| Step: 5
Training loss: 2.8058253453360695
Validation loss: 2.5116852768434743

Epoch: 6| Step: 6
Training loss: 3.465930789703348
Validation loss: 2.500131086788963

Epoch: 6| Step: 7
Training loss: 2.188049465380447
Validation loss: 2.5270495801671258

Epoch: 6| Step: 8
Training loss: 3.399923205910879
Validation loss: 2.520773651411834

Epoch: 6| Step: 9
Training loss: 2.6355701346563296
Validation loss: 2.525308156223568

Epoch: 6| Step: 10
Training loss: 1.8733696525193497
Validation loss: 2.5053242429397113

Epoch: 6| Step: 11
Training loss: 2.7469626906353635
Validation loss: 2.5039981363613855

Epoch: 6| Step: 12
Training loss: 2.690791841976433
Validation loss: 2.496851377031348

Epoch: 6| Step: 13
Training loss: 2.5836231212717102
Validation loss: 2.4967618849772277

Epoch: 143| Step: 0
Training loss: 2.9202510788501375
Validation loss: 2.504068260831694

Epoch: 6| Step: 1
Training loss: 3.0364165960271174
Validation loss: 2.5006313880275184

Epoch: 6| Step: 2
Training loss: 2.109851472517434
Validation loss: 2.5141685527968587

Epoch: 6| Step: 3
Training loss: 2.895059349492677
Validation loss: 2.5162758362039614

Epoch: 6| Step: 4
Training loss: 2.917290175867811
Validation loss: 2.5325076960097572

Epoch: 6| Step: 5
Training loss: 2.924288482201479
Validation loss: 2.5383590377518157

Epoch: 6| Step: 6
Training loss: 2.2129623792012945
Validation loss: 2.5299572192424855

Epoch: 6| Step: 7
Training loss: 2.9735378807712114
Validation loss: 2.538996436787569

Epoch: 6| Step: 8
Training loss: 3.0415987155239357
Validation loss: 2.5322552782127903

Epoch: 6| Step: 9
Training loss: 2.2193619864621286
Validation loss: 2.5196336711884495

Epoch: 6| Step: 10
Training loss: 3.069002061114174
Validation loss: 2.5277945631262413

Epoch: 6| Step: 11
Training loss: 2.5607174511738098
Validation loss: 2.5265133950814262

Epoch: 6| Step: 12
Training loss: 2.833891663983611
Validation loss: 2.5179819830559786

Epoch: 6| Step: 13
Training loss: 2.935606000943151
Validation loss: 2.506366589812798

Epoch: 144| Step: 0
Training loss: 2.628122017186272
Validation loss: 2.5037379161933906

Epoch: 6| Step: 1
Training loss: 2.547841643390523
Validation loss: 2.48678557979291

Epoch: 6| Step: 2
Training loss: 2.6158090178044255
Validation loss: 2.4795469039172615

Epoch: 6| Step: 3
Training loss: 2.892460420777889
Validation loss: 2.4718100826173455

Epoch: 6| Step: 4
Training loss: 2.6334369043512735
Validation loss: 2.472216507697413

Epoch: 6| Step: 5
Training loss: 3.2309919715434487
Validation loss: 2.4704164182281967

Epoch: 6| Step: 6
Training loss: 2.9287591302512035
Validation loss: 2.476517391418357

Epoch: 6| Step: 7
Training loss: 2.9589892094638723
Validation loss: 2.478867966183477

Epoch: 6| Step: 8
Training loss: 3.0394796756868723
Validation loss: 2.4863215744444847

Epoch: 6| Step: 9
Training loss: 2.2736394733494905
Validation loss: 2.501118737804291

Epoch: 6| Step: 10
Training loss: 2.643133833846301
Validation loss: 2.523876098605725

Epoch: 6| Step: 11
Training loss: 2.394396132473255
Validation loss: 2.529960494777315

Epoch: 6| Step: 12
Training loss: 2.8986127034416347
Validation loss: 2.522146296114656

Epoch: 6| Step: 13
Training loss: 3.1167083601449246
Validation loss: 2.5274199619008866

Epoch: 145| Step: 0
Training loss: 3.239617416022649
Validation loss: 2.493302950893032

Epoch: 6| Step: 1
Training loss: 2.5792679536206986
Validation loss: 2.494534934358509

Epoch: 6| Step: 2
Training loss: 2.5167023620431896
Validation loss: 2.491950353340526

Epoch: 6| Step: 3
Training loss: 2.7604989861263824
Validation loss: 2.4852174401304388

Epoch: 6| Step: 4
Training loss: 2.8514382531258082
Validation loss: 2.4748095561656567

Epoch: 6| Step: 5
Training loss: 2.6698089999914876
Validation loss: 2.483417722035273

Epoch: 6| Step: 6
Training loss: 3.0417393366524146
Validation loss: 2.483035714061101

Epoch: 6| Step: 7
Training loss: 3.3481396534185883
Validation loss: 2.4838188004365866

Epoch: 6| Step: 8
Training loss: 2.504839694895712
Validation loss: 2.474822349424813

Epoch: 6| Step: 9
Training loss: 2.07531663248311
Validation loss: 2.4738349991750677

Epoch: 6| Step: 10
Training loss: 2.5919335680678346
Validation loss: 2.4742491237203144

Epoch: 6| Step: 11
Training loss: 2.8377111684054404
Validation loss: 2.475477646174347

Epoch: 6| Step: 12
Training loss: 2.6295736522815703
Validation loss: 2.4795987779898763

Epoch: 6| Step: 13
Training loss: 3.0745595042745077
Validation loss: 2.4853076800310583

Epoch: 146| Step: 0
Training loss: 2.667924246689133
Validation loss: 2.4889029580051654

Epoch: 6| Step: 1
Training loss: 2.521696263518006
Validation loss: 2.490658180033406

Epoch: 6| Step: 2
Training loss: 2.6627985397383
Validation loss: 2.482146374560708

Epoch: 6| Step: 3
Training loss: 2.778499657820879
Validation loss: 2.476775897504358

Epoch: 6| Step: 4
Training loss: 2.830760086484958
Validation loss: 2.4792258359928674

Epoch: 6| Step: 5
Training loss: 2.343548778797035
Validation loss: 2.4717439280840114

Epoch: 6| Step: 6
Training loss: 3.2920395523235286
Validation loss: 2.4606697453818676

Epoch: 6| Step: 7
Training loss: 2.28105350850053
Validation loss: 2.4678427131220104

Epoch: 6| Step: 8
Training loss: 2.9725691473051143
Validation loss: 2.465378389024685

Epoch: 6| Step: 9
Training loss: 2.516907738093066
Validation loss: 2.471998782989479

Epoch: 6| Step: 10
Training loss: 2.72482830521626
Validation loss: 2.479866868579634

Epoch: 6| Step: 11
Training loss: 3.3543189035938186
Validation loss: 2.4776373755230567

Epoch: 6| Step: 12
Training loss: 2.6351357009950536
Validation loss: 2.4895451761140444

Epoch: 6| Step: 13
Training loss: 2.6743880382985807
Validation loss: 2.4955025971278952

Epoch: 147| Step: 0
Training loss: 2.566816091109968
Validation loss: 2.486898294371036

Epoch: 6| Step: 1
Training loss: 2.1374365456961386
Validation loss: 2.4689539447002145

Epoch: 6| Step: 2
Training loss: 2.991293033939099
Validation loss: 2.4715338333841057

Epoch: 6| Step: 3
Training loss: 2.9135722139075764
Validation loss: 2.4666808847429444

Epoch: 6| Step: 4
Training loss: 2.5871513721548314
Validation loss: 2.464291984847191

Epoch: 6| Step: 5
Training loss: 2.779876112475898
Validation loss: 2.4487785703590825

Epoch: 6| Step: 6
Training loss: 3.0148017036173025
Validation loss: 2.4534387523061367

Epoch: 6| Step: 7
Training loss: 3.098896870150508
Validation loss: 2.4474509165065648

Epoch: 6| Step: 8
Training loss: 2.822955047984628
Validation loss: 2.4545191282145824

Epoch: 6| Step: 9
Training loss: 2.568974758441444
Validation loss: 2.4534482704395035

Epoch: 6| Step: 10
Training loss: 2.8229273459219604
Validation loss: 2.468396843951755

Epoch: 6| Step: 11
Training loss: 2.0926747763870437
Validation loss: 2.465522499615159

Epoch: 6| Step: 12
Training loss: 2.9874422778055836
Validation loss: 2.47019065254487

Epoch: 6| Step: 13
Training loss: 2.6963011766580904
Validation loss: 2.47350630788052

Epoch: 148| Step: 0
Training loss: 2.990473881553705
Validation loss: 2.476006033330024

Epoch: 6| Step: 1
Training loss: 2.7730463316245593
Validation loss: 2.482324404171396

Epoch: 6| Step: 2
Training loss: 2.670168147418031
Validation loss: 2.488600617047318

Epoch: 6| Step: 3
Training loss: 2.1372025132213213
Validation loss: 2.4871648982710526

Epoch: 6| Step: 4
Training loss: 2.5780163366363897
Validation loss: 2.475730502886433

Epoch: 6| Step: 5
Training loss: 2.8462493309452443
Validation loss: 2.468230258598384

Epoch: 6| Step: 6
Training loss: 2.531970639726016
Validation loss: 2.4650557533619613

Epoch: 6| Step: 7
Training loss: 2.9264381394488757
Validation loss: 2.4663827194599666

Epoch: 6| Step: 8
Training loss: 2.477897404613542
Validation loss: 2.458282921908418

Epoch: 6| Step: 9
Training loss: 2.6338636524245116
Validation loss: 2.451582651135158

Epoch: 6| Step: 10
Training loss: 2.7116014178803423
Validation loss: 2.4548944545254656

Epoch: 6| Step: 11
Training loss: 2.6388789617340573
Validation loss: 2.4556754644469927

Epoch: 6| Step: 12
Training loss: 3.2503271671826495
Validation loss: 2.463408564485954

Epoch: 6| Step: 13
Training loss: 3.033335175007132
Validation loss: 2.4648148605015914

Epoch: 149| Step: 0
Training loss: 2.5955128940885897
Validation loss: 2.45446722022248

Epoch: 6| Step: 1
Training loss: 2.5622300726913756
Validation loss: 2.452926681023396

Epoch: 6| Step: 2
Training loss: 2.280168459842656
Validation loss: 2.46500067159929

Epoch: 6| Step: 3
Training loss: 2.8525480892530917
Validation loss: 2.468058497452568

Epoch: 6| Step: 4
Training loss: 3.0428449534550066
Validation loss: 2.4736018595752673

Epoch: 6| Step: 5
Training loss: 2.618602404384082
Validation loss: 2.4736330384323333

Epoch: 6| Step: 6
Training loss: 2.47596998377094
Validation loss: 2.473943693487938

Epoch: 6| Step: 7
Training loss: 3.0297457708585314
Validation loss: 2.461385774322593

Epoch: 6| Step: 8
Training loss: 2.6328016331841764
Validation loss: 2.4636973687583077

Epoch: 6| Step: 9
Training loss: 3.2037332096917552
Validation loss: 2.47303639632383

Epoch: 6| Step: 10
Training loss: 3.113371308099888
Validation loss: 2.4658888611818903

Epoch: 6| Step: 11
Training loss: 2.3985289515850745
Validation loss: 2.4595649335784393

Epoch: 6| Step: 12
Training loss: 2.6359855932383263
Validation loss: 2.4722772366852284

Epoch: 6| Step: 13
Training loss: 2.3031973466418645
Validation loss: 2.461109227915921

Epoch: 150| Step: 0
Training loss: 2.2771984335337305
Validation loss: 2.4670888759613545

Epoch: 6| Step: 1
Training loss: 2.8046200034857907
Validation loss: 2.4669958996024093

Epoch: 6| Step: 2
Training loss: 2.687060120535011
Validation loss: 2.479071685537847

Epoch: 6| Step: 3
Training loss: 2.626635995321107
Validation loss: 2.4742682049936766

Epoch: 6| Step: 4
Training loss: 2.483759773899424
Validation loss: 2.475411477288226

Epoch: 6| Step: 5
Training loss: 2.666293197546587
Validation loss: 2.4679286136053986

Epoch: 6| Step: 6
Training loss: 3.083381927382241
Validation loss: 2.47395945282907

Epoch: 6| Step: 7
Training loss: 2.462585285084746
Validation loss: 2.470967580440844

Epoch: 6| Step: 8
Training loss: 2.4960952782663552
Validation loss: 2.4554721087594342

Epoch: 6| Step: 9
Training loss: 2.8924945456042086
Validation loss: 2.4615424341614123

Epoch: 6| Step: 10
Training loss: 3.1916605405690603
Validation loss: 2.455689003077164

Epoch: 6| Step: 11
Training loss: 2.7840173219711914
Validation loss: 2.4747627581710043

Epoch: 6| Step: 12
Training loss: 2.966239108303954
Validation loss: 2.4775599054392248

Epoch: 6| Step: 13
Training loss: 2.325773856881987
Validation loss: 2.4630135260127344

Epoch: 151| Step: 0
Training loss: 2.686941754225533
Validation loss: 2.4673214495932108

Epoch: 6| Step: 1
Training loss: 2.7276915040867955
Validation loss: 2.477086070439292

Epoch: 6| Step: 2
Training loss: 2.7278281173757186
Validation loss: 2.477695065207994

Epoch: 6| Step: 3
Training loss: 3.2187720733182
Validation loss: 2.491561048154574

Epoch: 6| Step: 4
Training loss: 2.4906567503318544
Validation loss: 2.4955301235957315

Epoch: 6| Step: 5
Training loss: 2.782761666606313
Validation loss: 2.5034093774159576

Epoch: 6| Step: 6
Training loss: 2.371919139506638
Validation loss: 2.510592488217526

Epoch: 6| Step: 7
Training loss: 2.321418267531112
Validation loss: 2.506774056607232

Epoch: 6| Step: 8
Training loss: 2.8107874424710473
Validation loss: 2.4981052909758974

Epoch: 6| Step: 9
Training loss: 3.2618393561628074
Validation loss: 2.4996614052556394

Epoch: 6| Step: 10
Training loss: 2.0567825138020868
Validation loss: 2.5097178720245634

Epoch: 6| Step: 11
Training loss: 3.442663303067283
Validation loss: 2.508040320091732

Epoch: 6| Step: 12
Training loss: 2.4273055688404632
Validation loss: 2.51331337631844

Epoch: 6| Step: 13
Training loss: 2.6714539670210673
Validation loss: 2.508775624955511

Epoch: 152| Step: 0
Training loss: 3.2858508597001754
Validation loss: 2.501677340101972

Epoch: 6| Step: 1
Training loss: 2.4537236157561697
Validation loss: 2.4949567249819666

Epoch: 6| Step: 2
Training loss: 1.9570540314526697
Validation loss: 2.497753729774493

Epoch: 6| Step: 3
Training loss: 2.6899594430808658
Validation loss: 2.4860943173272694

Epoch: 6| Step: 4
Training loss: 2.909801814878064
Validation loss: 2.4808019565252275

Epoch: 6| Step: 5
Training loss: 2.6900458586517013
Validation loss: 2.5026810390648815

Epoch: 6| Step: 6
Training loss: 2.777676805144524
Validation loss: 2.4948492302784104

Epoch: 6| Step: 7
Training loss: 3.2631879410064752
Validation loss: 2.517249648007807

Epoch: 6| Step: 8
Training loss: 2.314892330425941
Validation loss: 2.5175839628862513

Epoch: 6| Step: 9
Training loss: 3.047072027633964
Validation loss: 2.5222952070182996

Epoch: 6| Step: 10
Training loss: 2.8766759880094654
Validation loss: 2.5280091445275104

Epoch: 6| Step: 11
Training loss: 2.5568977150925605
Validation loss: 2.5174789572743643

Epoch: 6| Step: 12
Training loss: 2.5650961215801558
Validation loss: 2.50796380549911

Epoch: 6| Step: 13
Training loss: 2.8952736256476013
Validation loss: 2.4945901871620646

Epoch: 153| Step: 0
Training loss: 2.404726611359058
Validation loss: 2.48337226516996

Epoch: 6| Step: 1
Training loss: 2.6256387024367314
Validation loss: 2.4887305767893317

Epoch: 6| Step: 2
Training loss: 2.862059453521314
Validation loss: 2.4840932593314764

Epoch: 6| Step: 3
Training loss: 2.023589728678876
Validation loss: 2.4665225026634543

Epoch: 6| Step: 4
Training loss: 3.2080614709648656
Validation loss: 2.4749910345336708

Epoch: 6| Step: 5
Training loss: 2.906011428064925
Validation loss: 2.482201923268352

Epoch: 6| Step: 6
Training loss: 2.335303689456891
Validation loss: 2.4734962056801653

Epoch: 6| Step: 7
Training loss: 2.4309441852195683
Validation loss: 2.475558289718176

Epoch: 6| Step: 8
Training loss: 3.1544147859153786
Validation loss: 2.474589707917303

Epoch: 6| Step: 9
Training loss: 2.771690054554153
Validation loss: 2.47567535003977

Epoch: 6| Step: 10
Training loss: 3.726415603269584
Validation loss: 2.4675796089654316

Epoch: 6| Step: 11
Training loss: 1.7842359445239302
Validation loss: 2.47780511628763

Epoch: 6| Step: 12
Training loss: 2.6926321662052004
Validation loss: 2.484850178072862

Epoch: 6| Step: 13
Training loss: 2.992769428766567
Validation loss: 2.47420306011598

Epoch: 154| Step: 0
Training loss: 3.0302663563907757
Validation loss: 2.481838062755119

Epoch: 6| Step: 1
Training loss: 2.6352888737228657
Validation loss: 2.5032541630451504

Epoch: 6| Step: 2
Training loss: 2.8427268063420383
Validation loss: 2.4949541546166016

Epoch: 6| Step: 3
Training loss: 2.6702956501008934
Validation loss: 2.497882075617056

Epoch: 6| Step: 4
Training loss: 2.5508467708193416
Validation loss: 2.497344533560708

Epoch: 6| Step: 5
Training loss: 2.718275006773813
Validation loss: 2.4979687909383017

Epoch: 6| Step: 6
Training loss: 2.547990800263042
Validation loss: 2.4911334017349507

Epoch: 6| Step: 7
Training loss: 2.2702973692797372
Validation loss: 2.491366137620266

Epoch: 6| Step: 8
Training loss: 2.1371258726129927
Validation loss: 2.4909331213996815

Epoch: 6| Step: 9
Training loss: 2.9103746575445975
Validation loss: 2.4953502802295526

Epoch: 6| Step: 10
Training loss: 3.09560177032424
Validation loss: 2.478034948190534

Epoch: 6| Step: 11
Training loss: 2.8555529121488945
Validation loss: 2.470246928294208

Epoch: 6| Step: 12
Training loss: 2.5377713250985465
Validation loss: 2.467016903319503

Epoch: 6| Step: 13
Training loss: 3.784904290504748
Validation loss: 2.472177678689718

Epoch: 155| Step: 0
Training loss: 2.785001046884227
Validation loss: 2.4681256741725024

Epoch: 6| Step: 1
Training loss: 2.911011271993186
Validation loss: 2.459144784422866

Epoch: 6| Step: 2
Training loss: 2.8459326783056977
Validation loss: 2.4542236825281285

Epoch: 6| Step: 3
Training loss: 2.3045554947630102
Validation loss: 2.467494351919293

Epoch: 6| Step: 4
Training loss: 2.8152361805628057
Validation loss: 2.4684107838040656

Epoch: 6| Step: 5
Training loss: 3.2351228153552576
Validation loss: 2.472849610635704

Epoch: 6| Step: 6
Training loss: 2.683893223118119
Validation loss: 2.5009971229855603

Epoch: 6| Step: 7
Training loss: 2.0576696764855327
Validation loss: 2.4968113119218405

Epoch: 6| Step: 8
Training loss: 2.862346501794968
Validation loss: 2.4931645108247746

Epoch: 6| Step: 9
Training loss: 3.0579510594525274
Validation loss: 2.4888497914934073

Epoch: 6| Step: 10
Training loss: 2.3118813176828046
Validation loss: 2.4946494527680967

Epoch: 6| Step: 11
Training loss: 3.065074539149414
Validation loss: 2.49792582903906

Epoch: 6| Step: 12
Training loss: 2.6193559915066333
Validation loss: 2.5113411812262996

Epoch: 6| Step: 13
Training loss: 2.276605764591895
Validation loss: 2.504355312089563

Epoch: 156| Step: 0
Training loss: 3.1986059549805157
Validation loss: 2.5028267404896694

Epoch: 6| Step: 1
Training loss: 3.0729573047774132
Validation loss: 2.466277714699629

Epoch: 6| Step: 2
Training loss: 2.582172891999536
Validation loss: 2.485406844106942

Epoch: 6| Step: 3
Training loss: 2.3376144462760484
Validation loss: 2.4831139161663836

Epoch: 6| Step: 4
Training loss: 2.7498054435572334
Validation loss: 2.4900566108081037

Epoch: 6| Step: 5
Training loss: 2.932731003764562
Validation loss: 2.4953907684361973

Epoch: 6| Step: 6
Training loss: 2.4918202096672037
Validation loss: 2.50132430901935

Epoch: 6| Step: 7
Training loss: 2.562206902838188
Validation loss: 2.4958767965227673

Epoch: 6| Step: 8
Training loss: 2.883035294522155
Validation loss: 2.5146843678923814

Epoch: 6| Step: 9
Training loss: 2.4923396049169932
Validation loss: 2.506159998042043

Epoch: 6| Step: 10
Training loss: 2.599617629177824
Validation loss: 2.504437736874118

Epoch: 6| Step: 11
Training loss: 2.6238124522663524
Validation loss: 2.5009230048089184

Epoch: 6| Step: 12
Training loss: 2.9037361347657327
Validation loss: 2.491075237006982

Epoch: 6| Step: 13
Training loss: 2.7824582679271845
Validation loss: 2.4788216357423196

Epoch: 157| Step: 0
Training loss: 2.3174848698818615
Validation loss: 2.4707417566911776

Epoch: 6| Step: 1
Training loss: 2.212772537945891
Validation loss: 2.4774334109453533

Epoch: 6| Step: 2
Training loss: 3.187503590301287
Validation loss: 2.4723993600258756

Epoch: 6| Step: 3
Training loss: 2.3402031063715483
Validation loss: 2.4714612786000245

Epoch: 6| Step: 4
Training loss: 3.147394580242171
Validation loss: 2.4747219324754988

Epoch: 6| Step: 5
Training loss: 2.981357187067642
Validation loss: 2.4712861599790954

Epoch: 6| Step: 6
Training loss: 3.0447234553395206
Validation loss: 2.475520921538535

Epoch: 6| Step: 7
Training loss: 2.2238524960446044
Validation loss: 2.48516432062484

Epoch: 6| Step: 8
Training loss: 2.4908205307390814
Validation loss: 2.482528460522815

Epoch: 6| Step: 9
Training loss: 2.533006788423149
Validation loss: 2.4891356779133034

Epoch: 6| Step: 10
Training loss: 2.856397068235749
Validation loss: 2.4734489490766256

Epoch: 6| Step: 11
Training loss: 3.09507245399577
Validation loss: 2.4755214683333913

Epoch: 6| Step: 12
Training loss: 2.9725834239806312
Validation loss: 2.4729605164529342

Epoch: 6| Step: 13
Training loss: 2.5196921127184386
Validation loss: 2.4628313123514545

Epoch: 158| Step: 0
Training loss: 2.4032256701829255
Validation loss: 2.461408203862131

Epoch: 6| Step: 1
Training loss: 2.6640454960165734
Validation loss: 2.454045719850655

Epoch: 6| Step: 2
Training loss: 3.12162201460638
Validation loss: 2.461747821585394

Epoch: 6| Step: 3
Training loss: 3.1385972798093515
Validation loss: 2.460823506731121

Epoch: 6| Step: 4
Training loss: 2.4331058117129247
Validation loss: 2.4652333923192606

Epoch: 6| Step: 5
Training loss: 2.590647853110902
Validation loss: 2.4666296484158576

Epoch: 6| Step: 6
Training loss: 2.869989922535712
Validation loss: 2.4754437290481115

Epoch: 6| Step: 7
Training loss: 2.9372561739107397
Validation loss: 2.488972360348524

Epoch: 6| Step: 8
Training loss: 2.8339894226996742
Validation loss: 2.5067361770852714

Epoch: 6| Step: 9
Training loss: 2.7442462724325174
Validation loss: 2.5175976975982137

Epoch: 6| Step: 10
Training loss: 2.4606899560828546
Validation loss: 2.525432242604849

Epoch: 6| Step: 11
Training loss: 2.623492761862592
Validation loss: 2.5293357809069863

Epoch: 6| Step: 12
Training loss: 2.7469579169872578
Validation loss: 2.5195763780654663

Epoch: 6| Step: 13
Training loss: 2.554765799252836
Validation loss: 2.506033277650432

Epoch: 159| Step: 0
Training loss: 2.8980441173515152
Validation loss: 2.473117931650395

Epoch: 6| Step: 1
Training loss: 2.681086939408392
Validation loss: 2.4621641925875557

Epoch: 6| Step: 2
Training loss: 2.821603917886703
Validation loss: 2.453442869276907

Epoch: 6| Step: 3
Training loss: 2.962772012447414
Validation loss: 2.455905558816271

Epoch: 6| Step: 4
Training loss: 2.794751943864495
Validation loss: 2.4604813577025797

Epoch: 6| Step: 5
Training loss: 2.6589877213061524
Validation loss: 2.4695550030055395

Epoch: 6| Step: 6
Training loss: 2.8160875962895022
Validation loss: 2.4757328493481827

Epoch: 6| Step: 7
Training loss: 2.986463365305527
Validation loss: 2.4728240870955416

Epoch: 6| Step: 8
Training loss: 2.840646076858602
Validation loss: 2.450649443313891

Epoch: 6| Step: 9
Training loss: 2.7028350674589796
Validation loss: 2.458823726776586

Epoch: 6| Step: 10
Training loss: 2.273391460988142
Validation loss: 2.4688059119148016

Epoch: 6| Step: 11
Training loss: 2.950856785896941
Validation loss: 2.4799311854990083

Epoch: 6| Step: 12
Training loss: 2.666564661300286
Validation loss: 2.504797687038368

Epoch: 6| Step: 13
Training loss: 2.2639842439109965
Validation loss: 2.521339862578532

Epoch: 160| Step: 0
Training loss: 2.9662341249011392
Validation loss: 2.536119085169208

Epoch: 6| Step: 1
Training loss: 2.87168145425199
Validation loss: 2.54306233692886

Epoch: 6| Step: 2
Training loss: 3.163869291458264
Validation loss: 2.584659667286307

Epoch: 6| Step: 3
Training loss: 2.5865309112194277
Validation loss: 2.565369993462858

Epoch: 6| Step: 4
Training loss: 2.3947803560653296
Validation loss: 2.554465063523581

Epoch: 6| Step: 5
Training loss: 3.0380627083449783
Validation loss: 2.556423368576477

Epoch: 6| Step: 6
Training loss: 2.1112626283492677
Validation loss: 2.533027330809068

Epoch: 6| Step: 7
Training loss: 2.8649769090717223
Validation loss: 2.5230160664188905

Epoch: 6| Step: 8
Training loss: 2.772814183642546
Validation loss: 2.5227322817359625

Epoch: 6| Step: 9
Training loss: 2.5166765941230387
Validation loss: 2.489005982399687

Epoch: 6| Step: 10
Training loss: 2.922600803904696
Validation loss: 2.485414594614971

Epoch: 6| Step: 11
Training loss: 2.778142071254188
Validation loss: 2.4681429284671306

Epoch: 6| Step: 12
Training loss: 2.8150428297128403
Validation loss: 2.4511607028451805

Epoch: 6| Step: 13
Training loss: 2.3339320731587585
Validation loss: 2.451582490096055

Epoch: 161| Step: 0
Training loss: 3.009782418532805
Validation loss: 2.4758454064855964

Epoch: 6| Step: 1
Training loss: 2.6697313956548268
Validation loss: 2.4660073587633007

Epoch: 6| Step: 2
Training loss: 2.499282352440732
Validation loss: 2.452123423525415

Epoch: 6| Step: 3
Training loss: 3.250867727789235
Validation loss: 2.4579958203444896

Epoch: 6| Step: 4
Training loss: 2.1387354175063806
Validation loss: 2.4551565958027504

Epoch: 6| Step: 5
Training loss: 2.8116166316994002
Validation loss: 2.453051424173916

Epoch: 6| Step: 6
Training loss: 2.5273735598850546
Validation loss: 2.4640572598128294

Epoch: 6| Step: 7
Training loss: 2.9098409801962197
Validation loss: 2.462257703311853

Epoch: 6| Step: 8
Training loss: 2.1052726130524175
Validation loss: 2.473002029500514

Epoch: 6| Step: 9
Training loss: 2.8223705443841225
Validation loss: 2.466777787896985

Epoch: 6| Step: 10
Training loss: 3.188294853886225
Validation loss: 2.4891195491249944

Epoch: 6| Step: 11
Training loss: 2.1844014702367804
Validation loss: 2.4522391018714624

Epoch: 6| Step: 12
Training loss: 2.3833453473764226
Validation loss: 2.455673401048177

Epoch: 6| Step: 13
Training loss: 3.5689204400777808
Validation loss: 2.4518651580861865

Epoch: 162| Step: 0
Training loss: 2.9589189478121365
Validation loss: 2.453573190819394

Epoch: 6| Step: 1
Training loss: 2.9258998953747386
Validation loss: 2.4574700395800395

Epoch: 6| Step: 2
Training loss: 2.632130158067102
Validation loss: 2.468907952593902

Epoch: 6| Step: 3
Training loss: 2.9346981890295565
Validation loss: 2.484225843877744

Epoch: 6| Step: 4
Training loss: 2.7553161042354164
Validation loss: 2.5235914028929325

Epoch: 6| Step: 5
Training loss: 2.22536878208491
Validation loss: 2.5360329015097927

Epoch: 6| Step: 6
Training loss: 2.9398294505780993
Validation loss: 2.5204507930227726

Epoch: 6| Step: 7
Training loss: 3.0520432678995326
Validation loss: 2.518452504401287

Epoch: 6| Step: 8
Training loss: 2.0473674152750116
Validation loss: 2.4965237865486167

Epoch: 6| Step: 9
Training loss: 3.02185521873777
Validation loss: 2.4649954611126126

Epoch: 6| Step: 10
Training loss: 2.7543634995509745
Validation loss: 2.454338366718663

Epoch: 6| Step: 11
Training loss: 2.709690301801526
Validation loss: 2.4571580049920136

Epoch: 6| Step: 12
Training loss: 2.952323199218548
Validation loss: 2.44144641264008

Epoch: 6| Step: 13
Training loss: 2.290437669366848
Validation loss: 2.458641494560636

Epoch: 163| Step: 0
Training loss: 2.4911414555064457
Validation loss: 2.4620908962551606

Epoch: 6| Step: 1
Training loss: 3.3187634254083442
Validation loss: 2.4485466671129923

Epoch: 6| Step: 2
Training loss: 2.681748556811479
Validation loss: 2.4647153588830433

Epoch: 6| Step: 3
Training loss: 2.868146938523533
Validation loss: 2.454696742211596

Epoch: 6| Step: 4
Training loss: 3.2520661755405924
Validation loss: 2.4467618562050943

Epoch: 6| Step: 5
Training loss: 2.689457380170926
Validation loss: 2.4621448019767684

Epoch: 6| Step: 6
Training loss: 2.839809832048996
Validation loss: 2.50677792849027

Epoch: 6| Step: 7
Training loss: 2.6479616891158275
Validation loss: 2.5111982616163875

Epoch: 6| Step: 8
Training loss: 2.2409264610443143
Validation loss: 2.5740255718150875

Epoch: 6| Step: 9
Training loss: 2.383589620971104
Validation loss: 2.6615844523938135

Epoch: 6| Step: 10
Training loss: 2.5656769760015243
Validation loss: 2.671820356415569

Epoch: 6| Step: 11
Training loss: 3.3231731702446075
Validation loss: 2.814489205799285

Epoch: 6| Step: 12
Training loss: 2.6858192333482966
Validation loss: 2.667297979453182

Epoch: 6| Step: 13
Training loss: 2.8160641445256114
Validation loss: 2.630367089476385

Epoch: 164| Step: 0
Training loss: 3.1567089389225043
Validation loss: 2.590911045939884

Epoch: 6| Step: 1
Training loss: 3.365894184310188
Validation loss: 2.563537734685191

Epoch: 6| Step: 2
Training loss: 2.8357320243442614
Validation loss: 2.5276009993153616

Epoch: 6| Step: 3
Training loss: 2.6475365830902637
Validation loss: 2.532532027375227

Epoch: 6| Step: 4
Training loss: 2.6249311528941255
Validation loss: 2.533969904119644

Epoch: 6| Step: 5
Training loss: 2.4096724706296597
Validation loss: 2.5481174824690664

Epoch: 6| Step: 6
Training loss: 2.7871272534957847
Validation loss: 2.595020386837488

Epoch: 6| Step: 7
Training loss: 3.1575938470444656
Validation loss: 2.5540635128784617

Epoch: 6| Step: 8
Training loss: 3.135641974953897
Validation loss: 2.4724371631806816

Epoch: 6| Step: 9
Training loss: 2.4364058166123836
Validation loss: 2.4551753764639077

Epoch: 6| Step: 10
Training loss: 2.7158939662960573
Validation loss: 2.47964431436954

Epoch: 6| Step: 11
Training loss: 2.629457957176644
Validation loss: 2.496331478659945

Epoch: 6| Step: 12
Training loss: 2.1578442857791944
Validation loss: 2.484404976678706

Epoch: 6| Step: 13
Training loss: 2.8242000088524963
Validation loss: 2.5006835782288364

Epoch: 165| Step: 0
Training loss: 2.2359480222485097
Validation loss: 2.4575840861679086

Epoch: 6| Step: 1
Training loss: 2.6572592220521414
Validation loss: 2.4249934786814706

Epoch: 6| Step: 2
Training loss: 2.975105149149948
Validation loss: 2.4336473083159444

Epoch: 6| Step: 3
Training loss: 2.342759189983772
Validation loss: 2.431755318942912

Epoch: 6| Step: 4
Training loss: 2.6568102077569455
Validation loss: 2.4406643971178297

Epoch: 6| Step: 5
Training loss: 2.8087821971506215
Validation loss: 2.44709771324224

Epoch: 6| Step: 6
Training loss: 2.6687305530134364
Validation loss: 2.4486687752159333

Epoch: 6| Step: 7
Training loss: 3.485389732778168
Validation loss: 2.448658037644453

Epoch: 6| Step: 8
Training loss: 2.961423325753825
Validation loss: 2.449121623138064

Epoch: 6| Step: 9
Training loss: 1.9038880520695622
Validation loss: 2.445412507001331

Epoch: 6| Step: 10
Training loss: 2.7423556458308274
Validation loss: 2.455581156528323

Epoch: 6| Step: 11
Training loss: 3.3075178574637216
Validation loss: 2.4456169816617415

Epoch: 6| Step: 12
Training loss: 2.2305567201279066
Validation loss: 2.467146866337339

Epoch: 6| Step: 13
Training loss: 3.1143048182110276
Validation loss: 2.4808866043447915

Epoch: 166| Step: 0
Training loss: 2.684491802689756
Validation loss: 2.4687268998672427

Epoch: 6| Step: 1
Training loss: 2.4351102411588434
Validation loss: 2.4737850048613343

Epoch: 6| Step: 2
Training loss: 2.9841369214386853
Validation loss: 2.476857684414409

Epoch: 6| Step: 3
Training loss: 2.7478853244647405
Validation loss: 2.4606700068853735

Epoch: 6| Step: 4
Training loss: 2.457225312785331
Validation loss: 2.467352030368814

Epoch: 6| Step: 5
Training loss: 3.0135036775102293
Validation loss: 2.4626563493603

Epoch: 6| Step: 6
Training loss: 2.7203190101751598
Validation loss: 2.4527235536731973

Epoch: 6| Step: 7
Training loss: 2.5919160908904435
Validation loss: 2.4515429248730367

Epoch: 6| Step: 8
Training loss: 3.0738622902258426
Validation loss: 2.467123534017803

Epoch: 6| Step: 9
Training loss: 2.8397268824818074
Validation loss: 2.4598220466633136

Epoch: 6| Step: 10
Training loss: 2.624684905259714
Validation loss: 2.4601131612703706

Epoch: 6| Step: 11
Training loss: 2.767822082578746
Validation loss: 2.467740580607801

Epoch: 6| Step: 12
Training loss: 2.076507512520589
Validation loss: 2.466463570463672

Epoch: 6| Step: 13
Training loss: 3.4011689532744858
Validation loss: 2.471655466550275

Epoch: 167| Step: 0
Training loss: 2.497683978172935
Validation loss: 2.464705535813487

Epoch: 6| Step: 1
Training loss: 2.4905184235977917
Validation loss: 2.4601384816583027

Epoch: 6| Step: 2
Training loss: 2.882827386585039
Validation loss: 2.4660656656503286

Epoch: 6| Step: 3
Training loss: 3.358110340625283
Validation loss: 2.468329904145413

Epoch: 6| Step: 4
Training loss: 3.1404119770436303
Validation loss: 2.4713889270768163

Epoch: 6| Step: 5
Training loss: 2.7038020350033998
Validation loss: 2.468029816976419

Epoch: 6| Step: 6
Training loss: 2.599885233767015
Validation loss: 2.4629967046930985

Epoch: 6| Step: 7
Training loss: 2.9896624795004882
Validation loss: 2.457346787245902

Epoch: 6| Step: 8
Training loss: 2.9630887311716445
Validation loss: 2.458919913665436

Epoch: 6| Step: 9
Training loss: 2.3654598566461744
Validation loss: 2.461038865858255

Epoch: 6| Step: 10
Training loss: 2.7792215558245554
Validation loss: 2.4584403858544768

Epoch: 6| Step: 11
Training loss: 2.62301533467751
Validation loss: 2.4554812421095913

Epoch: 6| Step: 12
Training loss: 1.934120923243306
Validation loss: 2.4562803006729212

Epoch: 6| Step: 13
Training loss: 2.438935175229335
Validation loss: 2.4544702262325706

Epoch: 168| Step: 0
Training loss: 2.2454741842501305
Validation loss: 2.4509306112321494

Epoch: 6| Step: 1
Training loss: 2.6252849969103242
Validation loss: 2.451862058961579

Epoch: 6| Step: 2
Training loss: 2.9153287452901835
Validation loss: 2.4598921485907272

Epoch: 6| Step: 3
Training loss: 3.178294333538898
Validation loss: 2.4512615223252783

Epoch: 6| Step: 4
Training loss: 3.4355503448763747
Validation loss: 2.4598002071452587

Epoch: 6| Step: 5
Training loss: 2.5533425059871737
Validation loss: 2.4491114548979107

Epoch: 6| Step: 6
Training loss: 2.420707962895561
Validation loss: 2.4596131141025945

Epoch: 6| Step: 7
Training loss: 2.311259581410347
Validation loss: 2.451795136153273

Epoch: 6| Step: 8
Training loss: 2.6540148138166084
Validation loss: 2.4540112333296276

Epoch: 6| Step: 9
Training loss: 2.5153132654227526
Validation loss: 2.4546882701717037

Epoch: 6| Step: 10
Training loss: 3.1945477528844335
Validation loss: 2.456025926867675

Epoch: 6| Step: 11
Training loss: 2.628827166111745
Validation loss: 2.4639747514893404

Epoch: 6| Step: 12
Training loss: 2.5863902453400542
Validation loss: 2.467179695807062

Epoch: 6| Step: 13
Training loss: 2.376986124880058
Validation loss: 2.474275395661253

Epoch: 169| Step: 0
Training loss: 1.9481689439357155
Validation loss: 2.479023752378672

Epoch: 6| Step: 1
Training loss: 3.336946500107558
Validation loss: 2.4805594706334393

Epoch: 6| Step: 2
Training loss: 2.540978656473487
Validation loss: 2.4765044837285104

Epoch: 6| Step: 3
Training loss: 2.3848474037088936
Validation loss: 2.466588270287965

Epoch: 6| Step: 4
Training loss: 2.802909266102616
Validation loss: 2.4710767816292436

Epoch: 6| Step: 5
Training loss: 2.691284088329937
Validation loss: 2.465752751706068

Epoch: 6| Step: 6
Training loss: 3.2800783517829952
Validation loss: 2.4679666732577155

Epoch: 6| Step: 7
Training loss: 2.688011564315034
Validation loss: 2.4646685595730196

Epoch: 6| Step: 8
Training loss: 3.228635699190663
Validation loss: 2.469257722574923

Epoch: 6| Step: 9
Training loss: 1.8629000291768947
Validation loss: 2.468469350679817

Epoch: 6| Step: 10
Training loss: 2.858785933388412
Validation loss: 2.4637797209264143

Epoch: 6| Step: 11
Training loss: 2.602076757426284
Validation loss: 2.4648383561267035

Epoch: 6| Step: 12
Training loss: 2.2996688770276745
Validation loss: 2.4597950554711945

Epoch: 6| Step: 13
Training loss: 2.904901171002803
Validation loss: 2.461976204576247

Epoch: 170| Step: 0
Training loss: 2.6818568398814917
Validation loss: 2.4630339797749317

Epoch: 6| Step: 1
Training loss: 2.591390616709326
Validation loss: 2.474897313486677

Epoch: 6| Step: 2
Training loss: 2.750734057857223
Validation loss: 2.4707965864767685

Epoch: 6| Step: 3
Training loss: 1.8561735400755137
Validation loss: 2.4704022126160172

Epoch: 6| Step: 4
Training loss: 2.7980109949938883
Validation loss: 2.4578408766006494

Epoch: 6| Step: 5
Training loss: 1.885591347823687
Validation loss: 2.4498215611419925

Epoch: 6| Step: 6
Training loss: 2.685598365983645
Validation loss: 2.4565943836223925

Epoch: 6| Step: 7
Training loss: 2.928766131159228
Validation loss: 2.4498427110567644

Epoch: 6| Step: 8
Training loss: 2.683744956563929
Validation loss: 2.4429570280552215

Epoch: 6| Step: 9
Training loss: 3.2716438277372566
Validation loss: 2.44630585722979

Epoch: 6| Step: 10
Training loss: 2.7817223822802406
Validation loss: 2.4559921941368272

Epoch: 6| Step: 11
Training loss: 3.042526820244038
Validation loss: 2.4483277222938695

Epoch: 6| Step: 12
Training loss: 3.100121458812091
Validation loss: 2.4557662783766694

Epoch: 6| Step: 13
Training loss: 2.1181606857251785
Validation loss: 2.4690232796103038

Epoch: 171| Step: 0
Training loss: 3.0522004366510997
Validation loss: 2.4760666310658177

Epoch: 6| Step: 1
Training loss: 2.623634528190275
Validation loss: 2.4680941068574276

Epoch: 6| Step: 2
Training loss: 2.1974263179087345
Validation loss: 2.4640604674083115

Epoch: 6| Step: 3
Training loss: 3.3936970237685835
Validation loss: 2.456513150396502

Epoch: 6| Step: 4
Training loss: 3.3305666567974725
Validation loss: 2.4486403785504285

Epoch: 6| Step: 5
Training loss: 2.1165299749416873
Validation loss: 2.4410259469421907

Epoch: 6| Step: 6
Training loss: 2.6870818589081704
Validation loss: 2.438440783415829

Epoch: 6| Step: 7
Training loss: 2.445524163881173
Validation loss: 2.439061777006592

Epoch: 6| Step: 8
Training loss: 3.0974219523427045
Validation loss: 2.4424020881477873

Epoch: 6| Step: 9
Training loss: 2.74699246065364
Validation loss: 2.436351383490326

Epoch: 6| Step: 10
Training loss: 2.2841201911474407
Validation loss: 2.43789911696837

Epoch: 6| Step: 11
Training loss: 2.7109823525535783
Validation loss: 2.4342390286121516

Epoch: 6| Step: 12
Training loss: 2.30344763557296
Validation loss: 2.4463637974289454

Epoch: 6| Step: 13
Training loss: 2.133645366657538
Validation loss: 2.4439484438390138

Epoch: 172| Step: 0
Training loss: 2.261687757843034
Validation loss: 2.4534748967747637

Epoch: 6| Step: 1
Training loss: 2.5464898502755027
Validation loss: 2.454169154944582

Epoch: 6| Step: 2
Training loss: 2.4583788937587143
Validation loss: 2.4708755722866598

Epoch: 6| Step: 3
Training loss: 2.975606449408297
Validation loss: 2.474153498586845

Epoch: 6| Step: 4
Training loss: 3.2887388962689075
Validation loss: 2.473768509132809

Epoch: 6| Step: 5
Training loss: 2.9791419999673123
Validation loss: 2.4764893120086566

Epoch: 6| Step: 6
Training loss: 2.929502923873169
Validation loss: 2.5054541783515165

Epoch: 6| Step: 7
Training loss: 2.864307922070622
Validation loss: 2.5133080242454104

Epoch: 6| Step: 8
Training loss: 2.2369409512744243
Validation loss: 2.4744308954700935

Epoch: 6| Step: 9
Training loss: 2.23212089745755
Validation loss: 2.458186249654605

Epoch: 6| Step: 10
Training loss: 3.119474485106814
Validation loss: 2.4460218026533713

Epoch: 6| Step: 11
Training loss: 2.4921057038949987
Validation loss: 2.439805217852894

Epoch: 6| Step: 12
Training loss: 2.6246726422321385
Validation loss: 2.4378909167507485

Epoch: 6| Step: 13
Training loss: 2.278098869435508
Validation loss: 2.438395752875542

Epoch: 173| Step: 0
Training loss: 2.6205666661610487
Validation loss: 2.435930736099574

Epoch: 6| Step: 1
Training loss: 1.8035607722074158
Validation loss: 2.444407905688987

Epoch: 6| Step: 2
Training loss: 2.888382985575546
Validation loss: 2.4367827387452956

Epoch: 6| Step: 3
Training loss: 3.2861940466062993
Validation loss: 2.4398824766368366

Epoch: 6| Step: 4
Training loss: 3.222115248150395
Validation loss: 2.438422218183159

Epoch: 6| Step: 5
Training loss: 2.5212155412277566
Validation loss: 2.4283158159903335

Epoch: 6| Step: 6
Training loss: 2.661506030307885
Validation loss: 2.443781497449054

Epoch: 6| Step: 7
Training loss: 2.364224130736434
Validation loss: 2.4619333268467622

Epoch: 6| Step: 8
Training loss: 2.7510680812119825
Validation loss: 2.476604765258386

Epoch: 6| Step: 9
Training loss: 2.2688945461496997
Validation loss: 2.4822680552171335

Epoch: 6| Step: 10
Training loss: 2.944957276635105
Validation loss: 2.490003206387962

Epoch: 6| Step: 11
Training loss: 2.7384402328245985
Validation loss: 2.474756344821002

Epoch: 6| Step: 12
Training loss: 3.1178874135908314
Validation loss: 2.4605817494368107

Epoch: 6| Step: 13
Training loss: 2.381456333142096
Validation loss: 2.4572194681719597

Epoch: 174| Step: 0
Training loss: 2.848305543154225
Validation loss: 2.444741905999948

Epoch: 6| Step: 1
Training loss: 3.123096038641327
Validation loss: 2.433643996903567

Epoch: 6| Step: 2
Training loss: 2.677999426302517
Validation loss: 2.439058998484152

Epoch: 6| Step: 3
Training loss: 2.591601113556465
Validation loss: 2.449477780094172

Epoch: 6| Step: 4
Training loss: 2.849967447730763
Validation loss: 2.444230036998169

Epoch: 6| Step: 5
Training loss: 2.708083703690011
Validation loss: 2.4481264354829326

Epoch: 6| Step: 6
Training loss: 2.426916965354619
Validation loss: 2.452402040079909

Epoch: 6| Step: 7
Training loss: 2.5123505694993526
Validation loss: 2.454422724993501

Epoch: 6| Step: 8
Training loss: 2.685406956582361
Validation loss: 2.460951153440114

Epoch: 6| Step: 9
Training loss: 2.3660957664204556
Validation loss: 2.465091322944636

Epoch: 6| Step: 10
Training loss: 2.589393726219473
Validation loss: 2.466734239109443

Epoch: 6| Step: 11
Training loss: 2.945320594837185
Validation loss: 2.465865169715351

Epoch: 6| Step: 12
Training loss: 2.124950408356881
Validation loss: 2.453232884508581

Epoch: 6| Step: 13
Training loss: 3.175357203777558
Validation loss: 2.4483320740319625

Epoch: 175| Step: 0
Training loss: 2.569898206720981
Validation loss: 2.4481279926461403

Epoch: 6| Step: 1
Training loss: 3.1634538983548666
Validation loss: 2.450479565400514

Epoch: 6| Step: 2
Training loss: 2.4886522241121045
Validation loss: 2.4534743210337373

Epoch: 6| Step: 3
Training loss: 2.570845899339958
Validation loss: 2.4597308957456083

Epoch: 6| Step: 4
Training loss: 2.69785125142527
Validation loss: 2.452045787204917

Epoch: 6| Step: 5
Training loss: 2.6117947260708663
Validation loss: 2.45705605646041

Epoch: 6| Step: 6
Training loss: 2.7726717899302997
Validation loss: 2.494173339682646

Epoch: 6| Step: 7
Training loss: 3.080330769996607
Validation loss: 2.5041693212217204

Epoch: 6| Step: 8
Training loss: 2.43902442408771
Validation loss: 2.5123488245888046

Epoch: 6| Step: 9
Training loss: 2.3398832849591975
Validation loss: 2.5105481473095947

Epoch: 6| Step: 10
Training loss: 2.8856906324709457
Validation loss: 2.519775455103256

Epoch: 6| Step: 11
Training loss: 3.0649754387274366
Validation loss: 2.4826853940083455

Epoch: 6| Step: 12
Training loss: 2.3558578043385165
Validation loss: 2.5051164476979007

Epoch: 6| Step: 13
Training loss: 2.2872095517730604
Validation loss: 2.5309759721152725

Epoch: 176| Step: 0
Training loss: 2.8994451452421988
Validation loss: 2.538358150501959

Epoch: 6| Step: 1
Training loss: 2.94258489209198
Validation loss: 2.5415102575851494

Epoch: 6| Step: 2
Training loss: 2.5218844048420417
Validation loss: 2.515695597277685

Epoch: 6| Step: 3
Training loss: 2.674597173289405
Validation loss: 2.4810178433664145

Epoch: 6| Step: 4
Training loss: 2.4561366164267504
Validation loss: 2.4714339218013315

Epoch: 6| Step: 5
Training loss: 2.7915438345081505
Validation loss: 2.451745880786443

Epoch: 6| Step: 6
Training loss: 2.7616393254579816
Validation loss: 2.4573968598716247

Epoch: 6| Step: 7
Training loss: 3.0429397601214565
Validation loss: 2.458404589691477

Epoch: 6| Step: 8
Training loss: 2.9888454328526883
Validation loss: 2.466739064506375

Epoch: 6| Step: 9
Training loss: 2.556400576309428
Validation loss: 2.4584999858778427

Epoch: 6| Step: 10
Training loss: 2.5686549259606886
Validation loss: 2.466939870803116

Epoch: 6| Step: 11
Training loss: 2.715566766639095
Validation loss: 2.4659808188854964

Epoch: 6| Step: 12
Training loss: 2.322258130342984
Validation loss: 2.4726975530241653

Epoch: 6| Step: 13
Training loss: 2.4528422587544814
Validation loss: 2.4834666517035875

Epoch: 177| Step: 0
Training loss: 2.8625430707731283
Validation loss: 2.4940786768439662

Epoch: 6| Step: 1
Training loss: 2.8538564991471818
Validation loss: 2.497433688571374

Epoch: 6| Step: 2
Training loss: 2.7843483800503948
Validation loss: 2.492250394199532

Epoch: 6| Step: 3
Training loss: 2.896378683064079
Validation loss: 2.486038800422301

Epoch: 6| Step: 4
Training loss: 2.2580314978809226
Validation loss: 2.4718135384025155

Epoch: 6| Step: 5
Training loss: 3.0304610021914526
Validation loss: 2.459382514448559

Epoch: 6| Step: 6
Training loss: 2.785552907468314
Validation loss: 2.462635096085121

Epoch: 6| Step: 7
Training loss: 2.920389705676285
Validation loss: 2.4616717083059996

Epoch: 6| Step: 8
Training loss: 2.586079112436673
Validation loss: 2.4649461887084447

Epoch: 6| Step: 9
Training loss: 2.433894792431715
Validation loss: 2.4625311901631854

Epoch: 6| Step: 10
Training loss: 3.043795707093128
Validation loss: 2.457825831661795

Epoch: 6| Step: 11
Training loss: 2.3795882627017204
Validation loss: 2.4567995867827834

Epoch: 6| Step: 12
Training loss: 2.305118636845323
Validation loss: 2.453769954111115

Epoch: 6| Step: 13
Training loss: 2.3646586289930185
Validation loss: 2.4548729554745514

Epoch: 178| Step: 0
Training loss: 2.383498396415003
Validation loss: 2.445052071352457

Epoch: 6| Step: 1
Training loss: 2.2713852891114263
Validation loss: 2.445481726271185

Epoch: 6| Step: 2
Training loss: 2.786213763665814
Validation loss: 2.4425766956621424

Epoch: 6| Step: 3
Training loss: 2.908879229040048
Validation loss: 2.4530666875534877

Epoch: 6| Step: 4
Training loss: 2.8648815392841045
Validation loss: 2.462291643293587

Epoch: 6| Step: 5
Training loss: 2.6768679006457012
Validation loss: 2.4635570984992086

Epoch: 6| Step: 6
Training loss: 2.480326683000999
Validation loss: 2.471534594738011

Epoch: 6| Step: 7
Training loss: 2.3482391090883716
Validation loss: 2.4656830066720063

Epoch: 6| Step: 8
Training loss: 3.00724442306916
Validation loss: 2.4751757891108586

Epoch: 6| Step: 9
Training loss: 2.745831364431722
Validation loss: 2.4670115703126863

Epoch: 6| Step: 10
Training loss: 2.802107110093975
Validation loss: 2.4606936004299533

Epoch: 6| Step: 11
Training loss: 2.6009239352439835
Validation loss: 2.45686817115452

Epoch: 6| Step: 12
Training loss: 2.832782934995076
Validation loss: 2.4448407461898825

Epoch: 6| Step: 13
Training loss: 2.644024528516606
Validation loss: 2.441627284391091

Epoch: 179| Step: 0
Training loss: 2.43760739603401
Validation loss: 2.4373321349190693

Epoch: 6| Step: 1
Training loss: 2.7753320375039805
Validation loss: 2.4344818596847557

Epoch: 6| Step: 2
Training loss: 2.596746161945298
Validation loss: 2.442162008150314

Epoch: 6| Step: 3
Training loss: 2.438718833391796
Validation loss: 2.443164574941808

Epoch: 6| Step: 4
Training loss: 2.381890690836177
Validation loss: 2.4513108397157746

Epoch: 6| Step: 5
Training loss: 1.9540164591546036
Validation loss: 2.4450734145547637

Epoch: 6| Step: 6
Training loss: 2.6448114379127783
Validation loss: 2.452287150339832

Epoch: 6| Step: 7
Training loss: 3.188450540667169
Validation loss: 2.444898120280746

Epoch: 6| Step: 8
Training loss: 2.1905357005247454
Validation loss: 2.4406986436750238

Epoch: 6| Step: 9
Training loss: 2.4092124438832627
Validation loss: 2.436133364178795

Epoch: 6| Step: 10
Training loss: 2.760673443829305
Validation loss: 2.4362519389666395

Epoch: 6| Step: 11
Training loss: 3.46451674577253
Validation loss: 2.438068589668568

Epoch: 6| Step: 12
Training loss: 3.049424576806875
Validation loss: 2.441405266611865

Epoch: 6| Step: 13
Training loss: 2.935893491990722
Validation loss: 2.436059702420687

Epoch: 180| Step: 0
Training loss: 2.4365699167347863
Validation loss: 2.4400421187921038

Epoch: 6| Step: 1
Training loss: 3.056456851005043
Validation loss: 2.4437516298612008

Epoch: 6| Step: 2
Training loss: 2.35878518923825
Validation loss: 2.4400578465102924

Epoch: 6| Step: 3
Training loss: 2.6890873324340956
Validation loss: 2.4308550077593183

Epoch: 6| Step: 4
Training loss: 2.939327077602698
Validation loss: 2.423740722886932

Epoch: 6| Step: 5
Training loss: 3.309174505829842
Validation loss: 2.4309083659291773

Epoch: 6| Step: 6
Training loss: 2.748171024730931
Validation loss: 2.4401301993271702

Epoch: 6| Step: 7
Training loss: 2.396506460969438
Validation loss: 2.435407309743712

Epoch: 6| Step: 8
Training loss: 2.1458744921641166
Validation loss: 2.4455968078291703

Epoch: 6| Step: 9
Training loss: 1.812706771105767
Validation loss: 2.4512751768450465

Epoch: 6| Step: 10
Training loss: 2.8390255763456116
Validation loss: 2.4450759078681696

Epoch: 6| Step: 11
Training loss: 3.018098913393229
Validation loss: 2.4440300752778326

Epoch: 6| Step: 12
Training loss: 2.5270071380357426
Validation loss: 2.4440769016037662

Epoch: 6| Step: 13
Training loss: 2.9113287080809997
Validation loss: 2.4455919218475968

Epoch: 181| Step: 0
Training loss: 2.8177910097488748
Validation loss: 2.445523271778526

Epoch: 6| Step: 1
Training loss: 3.147597435131669
Validation loss: 2.4477973114707616

Epoch: 6| Step: 2
Training loss: 2.442558321925161
Validation loss: 2.4518021219158403

Epoch: 6| Step: 3
Training loss: 3.1748931506342597
Validation loss: 2.4507119547106293

Epoch: 6| Step: 4
Training loss: 2.3294031103928767
Validation loss: 2.440538015558278

Epoch: 6| Step: 5
Training loss: 2.9844564856144857
Validation loss: 2.434569441655903

Epoch: 6| Step: 6
Training loss: 2.4640316842135177
Validation loss: 2.441035937767355

Epoch: 6| Step: 7
Training loss: 2.7551870844021016
Validation loss: 2.439456002384217

Epoch: 6| Step: 8
Training loss: 2.1051192692473144
Validation loss: 2.427218782026434

Epoch: 6| Step: 9
Training loss: 2.7378558863796574
Validation loss: 2.4323085394258253

Epoch: 6| Step: 10
Training loss: 1.6572559828386255
Validation loss: 2.446402801416782

Epoch: 6| Step: 11
Training loss: 3.1846480232871204
Validation loss: 2.436950924654934

Epoch: 6| Step: 12
Training loss: 2.557582136906638
Validation loss: 2.440687653611818

Epoch: 6| Step: 13
Training loss: 2.4697812015135288
Validation loss: 2.448502226581915

Epoch: 182| Step: 0
Training loss: 2.353535277731743
Validation loss: 2.4508293482211756

Epoch: 6| Step: 1
Training loss: 3.3167944367556697
Validation loss: 2.470098651257577

Epoch: 6| Step: 2
Training loss: 2.3499115379403155
Validation loss: 2.482493162468862

Epoch: 6| Step: 3
Training loss: 2.2753736503524564
Validation loss: 2.5147259496157406

Epoch: 6| Step: 4
Training loss: 3.2064253017398063
Validation loss: 2.485436824844086

Epoch: 6| Step: 5
Training loss: 2.5893766002019367
Validation loss: 2.4562622256625626

Epoch: 6| Step: 6
Training loss: 2.7282321485034826
Validation loss: 2.4496396053122425

Epoch: 6| Step: 7
Training loss: 2.5704050714119235
Validation loss: 2.446923424147792

Epoch: 6| Step: 8
Training loss: 1.7838177159801403
Validation loss: 2.4553414964650155

Epoch: 6| Step: 9
Training loss: 2.932029662727721
Validation loss: 2.4548498208359635

Epoch: 6| Step: 10
Training loss: 2.631464038398032
Validation loss: 2.462564151957491

Epoch: 6| Step: 11
Training loss: 2.568276755741014
Validation loss: 2.465987146939797

Epoch: 6| Step: 12
Training loss: 3.0363757654985064
Validation loss: 2.473171543122471

Epoch: 6| Step: 13
Training loss: 3.007755110552339
Validation loss: 2.47075390124574

Epoch: 183| Step: 0
Training loss: 2.980834458539063
Validation loss: 2.4699435453181153

Epoch: 6| Step: 1
Training loss: 2.475998101167459
Validation loss: 2.460342736943151

Epoch: 6| Step: 2
Training loss: 2.0681747051501596
Validation loss: 2.4623846983724684

Epoch: 6| Step: 3
Training loss: 2.3445870494208596
Validation loss: 2.4669788653858604

Epoch: 6| Step: 4
Training loss: 3.4410476411128346
Validation loss: 2.4517109687494196

Epoch: 6| Step: 5
Training loss: 2.973372544798437
Validation loss: 2.4468995113358103

Epoch: 6| Step: 6
Training loss: 2.469957466840368
Validation loss: 2.427863979443247

Epoch: 6| Step: 7
Training loss: 3.0477002713471886
Validation loss: 2.4374227014595293

Epoch: 6| Step: 8
Training loss: 2.8708755098814898
Validation loss: 2.4329906419397602

Epoch: 6| Step: 9
Training loss: 2.7658940416067552
Validation loss: 2.4412587846089107

Epoch: 6| Step: 10
Training loss: 2.363262888939521
Validation loss: 2.434911189815854

Epoch: 6| Step: 11
Training loss: 2.870360570182158
Validation loss: 2.4356625101689886

Epoch: 6| Step: 12
Training loss: 2.047933173929655
Validation loss: 2.4433507492828492

Epoch: 6| Step: 13
Training loss: 2.3836148271407103
Validation loss: 2.444880989773981

Epoch: 184| Step: 0
Training loss: 2.775982959310244
Validation loss: 2.4400653081973096

Epoch: 6| Step: 1
Training loss: 2.5696848186973917
Validation loss: 2.450720884032803

Epoch: 6| Step: 2
Training loss: 2.4278904196443927
Validation loss: 2.446026273783164

Epoch: 6| Step: 3
Training loss: 2.371204756977288
Validation loss: 2.45123303123878

Epoch: 6| Step: 4
Training loss: 2.7459958141764544
Validation loss: 2.4647705905574138

Epoch: 6| Step: 5
Training loss: 3.1196808368100046
Validation loss: 2.473807053055972

Epoch: 6| Step: 6
Training loss: 2.89508767899478
Validation loss: 2.479483957341652

Epoch: 6| Step: 7
Training loss: 2.6352349521477665
Validation loss: 2.489904720613292

Epoch: 6| Step: 8
Training loss: 1.8522962572950983
Validation loss: 2.4925815341368693

Epoch: 6| Step: 9
Training loss: 3.31316815241496
Validation loss: 2.496164858585094

Epoch: 6| Step: 10
Training loss: 2.5655260594348683
Validation loss: 2.4799838816211257

Epoch: 6| Step: 11
Training loss: 2.113280234627471
Validation loss: 2.470326047390609

Epoch: 6| Step: 12
Training loss: 3.0650353349699344
Validation loss: 2.4718123394571876

Epoch: 6| Step: 13
Training loss: 2.7157832653779344
Validation loss: 2.467211003620753

Epoch: 185| Step: 0
Training loss: 2.804103949999419
Validation loss: 2.484398333341314

Epoch: 6| Step: 1
Training loss: 2.7045410504461906
Validation loss: 2.494045472665014

Epoch: 6| Step: 2
Training loss: 2.5824126684705333
Validation loss: 2.4982514244785947

Epoch: 6| Step: 3
Training loss: 3.184288052166437
Validation loss: 2.4955804152452448

Epoch: 6| Step: 4
Training loss: 2.5280462641768167
Validation loss: 2.4946628430854387

Epoch: 6| Step: 5
Training loss: 2.9077210343789055
Validation loss: 2.4865501737779394

Epoch: 6| Step: 6
Training loss: 2.620510531035474
Validation loss: 2.489342957528883

Epoch: 6| Step: 7
Training loss: 2.7939454831680304
Validation loss: 2.482560610529698

Epoch: 6| Step: 8
Training loss: 2.781868597951879
Validation loss: 2.4915091566422265

Epoch: 6| Step: 9
Training loss: 2.6120198260280723
Validation loss: 2.486401735848516

Epoch: 6| Step: 10
Training loss: 2.6039468189264388
Validation loss: 2.49190207944278

Epoch: 6| Step: 11
Training loss: 2.2477152138123646
Validation loss: 2.484555879255051

Epoch: 6| Step: 12
Training loss: 2.521820211465337
Validation loss: 2.4857885810278653

Epoch: 6| Step: 13
Training loss: 2.6753782094098417
Validation loss: 2.4893667489244264

Epoch: 186| Step: 0
Training loss: 3.191438373604775
Validation loss: 2.491855521690809

Epoch: 6| Step: 1
Training loss: 2.9960480727552175
Validation loss: 2.4944620814957825

Epoch: 6| Step: 2
Training loss: 2.2591664831409313
Validation loss: 2.484005889849201

Epoch: 6| Step: 3
Training loss: 2.907176208572578
Validation loss: 2.4871683986893314

Epoch: 6| Step: 4
Training loss: 2.7159724462119943
Validation loss: 2.48302777080009

Epoch: 6| Step: 5
Training loss: 2.556221877412064
Validation loss: 2.4643728763560073

Epoch: 6| Step: 6
Training loss: 2.4587813362486837
Validation loss: 2.4714752623682243

Epoch: 6| Step: 7
Training loss: 2.5935690023856117
Validation loss: 2.4654401006375197

Epoch: 6| Step: 8
Training loss: 2.7889053770627417
Validation loss: 2.4679561858507624

Epoch: 6| Step: 9
Training loss: 2.6676152052308275
Validation loss: 2.456963341098585

Epoch: 6| Step: 10
Training loss: 3.099426302584297
Validation loss: 2.4566689490596283

Epoch: 6| Step: 11
Training loss: 2.09876720482759
Validation loss: 2.4723503367954205

Epoch: 6| Step: 12
Training loss: 2.4841807547392354
Validation loss: 2.4817162468680656

Epoch: 6| Step: 13
Training loss: 1.4721363880319145
Validation loss: 2.484361234340297

Epoch: 187| Step: 0
Training loss: 2.6774891546975406
Validation loss: 2.469889394362754

Epoch: 6| Step: 1
Training loss: 2.4280539169609545
Validation loss: 2.482680015147791

Epoch: 6| Step: 2
Training loss: 2.59773995400855
Validation loss: 2.495316593664241

Epoch: 6| Step: 3
Training loss: 2.957389860190274
Validation loss: 2.4609747396015926

Epoch: 6| Step: 4
Training loss: 1.8642369664317082
Validation loss: 2.4565091930258207

Epoch: 6| Step: 5
Training loss: 2.466021998249328
Validation loss: 2.451957782880904

Epoch: 6| Step: 6
Training loss: 2.9164471316595364
Validation loss: 2.454590298598046

Epoch: 6| Step: 7
Training loss: 2.5794108565370677
Validation loss: 2.4455080263124924

Epoch: 6| Step: 8
Training loss: 2.5503009618538584
Validation loss: 2.45136235543752

Epoch: 6| Step: 9
Training loss: 2.883591461387435
Validation loss: 2.4410436590203903

Epoch: 6| Step: 10
Training loss: 2.8597231793650337
Validation loss: 2.4540607994551533

Epoch: 6| Step: 11
Training loss: 2.777377143154779
Validation loss: 2.4462778575656077

Epoch: 6| Step: 12
Training loss: 3.030008278007656
Validation loss: 2.446791035343295

Epoch: 6| Step: 13
Training loss: 2.6406084771175466
Validation loss: 2.4532416897049263

Epoch: 188| Step: 0
Training loss: 2.95459787282261
Validation loss: 2.468105257412821

Epoch: 6| Step: 1
Training loss: 3.0740240827918823
Validation loss: 2.4650370895776024

Epoch: 6| Step: 2
Training loss: 2.439942823115333
Validation loss: 2.4620686457832686

Epoch: 6| Step: 3
Training loss: 1.6871589739910928
Validation loss: 2.4747155713343347

Epoch: 6| Step: 4
Training loss: 3.0786690013420115
Validation loss: 2.476908034337855

Epoch: 6| Step: 5
Training loss: 2.2557676354452094
Validation loss: 2.479881044785622

Epoch: 6| Step: 6
Training loss: 2.5730570601694196
Validation loss: 2.4630384002466337

Epoch: 6| Step: 7
Training loss: 3.3003396003996786
Validation loss: 2.4597795149219177

Epoch: 6| Step: 8
Training loss: 2.254994359485144
Validation loss: 2.48164970146151

Epoch: 6| Step: 9
Training loss: 2.5680985118830315
Validation loss: 2.480235256153979

Epoch: 6| Step: 10
Training loss: 2.3858783946932243
Validation loss: 2.482437732327325

Epoch: 6| Step: 11
Training loss: 2.333476118986882
Validation loss: 2.473034974057677

Epoch: 6| Step: 12
Training loss: 2.687623309478079
Validation loss: 2.471134700206757

Epoch: 6| Step: 13
Training loss: 3.2309440069467916
Validation loss: 2.469095852044237

Epoch: 189| Step: 0
Training loss: 2.635489079582504
Validation loss: 2.45911235330172

Epoch: 6| Step: 1
Training loss: 2.7029450637817756
Validation loss: 2.469070072176037

Epoch: 6| Step: 2
Training loss: 2.2002412577038117
Validation loss: 2.460155967558916

Epoch: 6| Step: 3
Training loss: 2.6846180922335043
Validation loss: 2.4645899433027965

Epoch: 6| Step: 4
Training loss: 2.7227692108583392
Validation loss: 2.460446691523058

Epoch: 6| Step: 5
Training loss: 3.20348449178377
Validation loss: 2.4631412783176216

Epoch: 6| Step: 6
Training loss: 2.5534464303442785
Validation loss: 2.456304922676808

Epoch: 6| Step: 7
Training loss: 2.3709384923942665
Validation loss: 2.4559595846418403

Epoch: 6| Step: 8
Training loss: 2.7854461733031024
Validation loss: 2.450637399458641

Epoch: 6| Step: 9
Training loss: 2.4470559629363176
Validation loss: 2.453866623266209

Epoch: 6| Step: 10
Training loss: 2.0956816232223505
Validation loss: 2.449429329559609

Epoch: 6| Step: 11
Training loss: 2.2888966783475375
Validation loss: 2.4476776002818457

Epoch: 6| Step: 12
Training loss: 2.784169754015952
Validation loss: 2.456415985292958

Epoch: 6| Step: 13
Training loss: 3.352660241674655
Validation loss: 2.4563261889760284

Epoch: 190| Step: 0
Training loss: 2.876470438547542
Validation loss: 2.4662705422932123

Epoch: 6| Step: 1
Training loss: 3.199839325685757
Validation loss: 2.477265187600559

Epoch: 6| Step: 2
Training loss: 2.4313333217591913
Validation loss: 2.482373367782779

Epoch: 6| Step: 3
Training loss: 2.7922811448714104
Validation loss: 2.480698567645283

Epoch: 6| Step: 4
Training loss: 2.9253155855957815
Validation loss: 2.4953975622949627

Epoch: 6| Step: 5
Training loss: 2.6611308414556922
Validation loss: 2.496715732564777

Epoch: 6| Step: 6
Training loss: 2.5604002188228496
Validation loss: 2.494710372479577

Epoch: 6| Step: 7
Training loss: 2.445696523328766
Validation loss: 2.5039754985991993

Epoch: 6| Step: 8
Training loss: 2.012570336101963
Validation loss: 2.516207282720632

Epoch: 6| Step: 9
Training loss: 2.441895946982068
Validation loss: 2.502705921614489

Epoch: 6| Step: 10
Training loss: 2.4429205264805383
Validation loss: 2.4915397018919587

Epoch: 6| Step: 11
Training loss: 2.4683331487716957
Validation loss: 2.472371921321581

Epoch: 6| Step: 12
Training loss: 2.80902308550237
Validation loss: 2.481873258567977

Epoch: 6| Step: 13
Training loss: 3.121572674994288
Validation loss: 2.4807269456070853

Epoch: 191| Step: 0
Training loss: 3.1106328672340613
Validation loss: 2.4791660155449464

Epoch: 6| Step: 1
Training loss: 2.76261643384435
Validation loss: 2.4673183948197295

Epoch: 6| Step: 2
Training loss: 1.4232192340087202
Validation loss: 2.46313492629912

Epoch: 6| Step: 3
Training loss: 2.804737823799919
Validation loss: 2.4585158400437037

Epoch: 6| Step: 4
Training loss: 2.4598281539813183
Validation loss: 2.452131371234874

Epoch: 6| Step: 5
Training loss: 2.9133547007681355
Validation loss: 2.459754210641284

Epoch: 6| Step: 6
Training loss: 3.134112081406528
Validation loss: 2.4416503542700583

Epoch: 6| Step: 7
Training loss: 2.2109349119353228
Validation loss: 2.4411953621955567

Epoch: 6| Step: 8
Training loss: 3.2921803391518587
Validation loss: 2.448845502847065

Epoch: 6| Step: 9
Training loss: 2.571301858292791
Validation loss: 2.455422719381528

Epoch: 6| Step: 10
Training loss: 2.5599585234739135
Validation loss: 2.4496942486315723

Epoch: 6| Step: 11
Training loss: 2.2696917636331806
Validation loss: 2.451821937282229

Epoch: 6| Step: 12
Training loss: 2.3884474866499317
Validation loss: 2.45432655405171

Epoch: 6| Step: 13
Training loss: 2.5059890535120104
Validation loss: 2.451919863682413

Epoch: 192| Step: 0
Training loss: 2.3471476024476563
Validation loss: 2.4494030376068503

Epoch: 6| Step: 1
Training loss: 2.758360205881499
Validation loss: 2.451344769161272

Epoch: 6| Step: 2
Training loss: 1.7514199899077845
Validation loss: 2.454587242080225

Epoch: 6| Step: 3
Training loss: 2.3625395312357447
Validation loss: 2.474102422191497

Epoch: 6| Step: 4
Training loss: 3.1639701170444536
Validation loss: 2.476560811652017

Epoch: 6| Step: 5
Training loss: 2.802689459570416
Validation loss: 2.474253580106027

Epoch: 6| Step: 6
Training loss: 2.2746626970689547
Validation loss: 2.4596773373519585

Epoch: 6| Step: 7
Training loss: 3.1963658916541577
Validation loss: 2.4639232299856624

Epoch: 6| Step: 8
Training loss: 2.6846115203503382
Validation loss: 2.4541283217268774

Epoch: 6| Step: 9
Training loss: 2.936927252591
Validation loss: 2.4505441179887044

Epoch: 6| Step: 10
Training loss: 2.446295884783401
Validation loss: 2.4422378414026493

Epoch: 6| Step: 11
Training loss: 2.424473506758353
Validation loss: 2.456207993049107

Epoch: 6| Step: 12
Training loss: 2.8544938579793264
Validation loss: 2.4442784117671317

Epoch: 6| Step: 13
Training loss: 2.7098052988809025
Validation loss: 2.445427501461156

Epoch: 193| Step: 0
Training loss: 3.1558296754659874
Validation loss: 2.4536857886251684

Epoch: 6| Step: 1
Training loss: 3.014081016155379
Validation loss: 2.4623372186286323

Epoch: 6| Step: 2
Training loss: 2.3017281881181235
Validation loss: 2.4807164346380364

Epoch: 6| Step: 3
Training loss: 2.341518204169629
Validation loss: 2.4937273477894886

Epoch: 6| Step: 4
Training loss: 2.7398760582395254
Validation loss: 2.4830392218491113

Epoch: 6| Step: 5
Training loss: 3.355219484247727
Validation loss: 2.4605794666680145

Epoch: 6| Step: 6
Training loss: 2.6185219166923623
Validation loss: 2.4620035607751616

Epoch: 6| Step: 7
Training loss: 2.5108671509644793
Validation loss: 2.457624547723206

Epoch: 6| Step: 8
Training loss: 2.609008397829775
Validation loss: 2.4617474206500436

Epoch: 6| Step: 9
Training loss: 2.462179494225774
Validation loss: 2.4831017830225277

Epoch: 6| Step: 10
Training loss: 2.519018502513115
Validation loss: 2.4832495499829843

Epoch: 6| Step: 11
Training loss: 2.5563705453220655
Validation loss: 2.4932470156065083

Epoch: 6| Step: 12
Training loss: 2.4034377669643145
Validation loss: 2.4838964169387387

Epoch: 6| Step: 13
Training loss: 2.7788854255571644
Validation loss: 2.4743169550309663

Epoch: 194| Step: 0
Training loss: 2.5288895326850813
Validation loss: 2.4858250079742743

Epoch: 6| Step: 1
Training loss: 2.742475271748116
Validation loss: 2.482412295493528

Epoch: 6| Step: 2
Training loss: 2.455901597334925
Validation loss: 2.4728154055380958

Epoch: 6| Step: 3
Training loss: 2.5271896952118014
Validation loss: 2.4677057411032264

Epoch: 6| Step: 4
Training loss: 2.377560089025872
Validation loss: 2.4603787977015132

Epoch: 6| Step: 5
Training loss: 2.76881974177648
Validation loss: 2.48023459669922

Epoch: 6| Step: 6
Training loss: 3.058177934348688
Validation loss: 2.467014932020392

Epoch: 6| Step: 7
Training loss: 2.9785601303027445
Validation loss: 2.4711863338247233

Epoch: 6| Step: 8
Training loss: 2.325344601596571
Validation loss: 2.462226601142233

Epoch: 6| Step: 9
Training loss: 2.9071253617022337
Validation loss: 2.45422207282501

Epoch: 6| Step: 10
Training loss: 2.68796961030357
Validation loss: 2.460100282140236

Epoch: 6| Step: 11
Training loss: 2.481761109105233
Validation loss: 2.4557967979137842

Epoch: 6| Step: 12
Training loss: 2.415363640112406
Validation loss: 2.4635070865648503

Epoch: 6| Step: 13
Training loss: 2.8318726383385444
Validation loss: 2.4659437837962135

Epoch: 195| Step: 0
Training loss: 2.3992304283362187
Validation loss: 2.455354530025179

Epoch: 6| Step: 1
Training loss: 2.686581388102941
Validation loss: 2.460815422492672

Epoch: 6| Step: 2
Training loss: 2.8908211306456177
Validation loss: 2.464607263957762

Epoch: 6| Step: 3
Training loss: 2.8882010529507163
Validation loss: 2.469899109627417

Epoch: 6| Step: 4
Training loss: 2.8623549978519485
Validation loss: 2.476185962657563

Epoch: 6| Step: 5
Training loss: 2.8812084335671884
Validation loss: 2.470770667678225

Epoch: 6| Step: 6
Training loss: 2.0184143637727803
Validation loss: 2.4625087885504335

Epoch: 6| Step: 7
Training loss: 2.0583933781605914
Validation loss: 2.4458922348592806

Epoch: 6| Step: 8
Training loss: 3.01697569330354
Validation loss: 2.446377531682162

Epoch: 6| Step: 9
Training loss: 2.3069861376957306
Validation loss: 2.4452234334725227

Epoch: 6| Step: 10
Training loss: 2.7148505999801174
Validation loss: 2.4371169257019543

Epoch: 6| Step: 11
Training loss: 2.792347744280392
Validation loss: 2.4399223964292043

Epoch: 6| Step: 12
Training loss: 2.3703310398088386
Validation loss: 2.4315440643427837

Epoch: 6| Step: 13
Training loss: 2.8042611565807958
Validation loss: 2.4413552645045806

Epoch: 196| Step: 0
Training loss: 3.3953127471741165
Validation loss: 2.4258686451724527

Epoch: 6| Step: 1
Training loss: 2.8627236358038886
Validation loss: 2.438392394817763

Epoch: 6| Step: 2
Training loss: 2.22218636907689
Validation loss: 2.4312064683227126

Epoch: 6| Step: 3
Training loss: 1.8600796558387125
Validation loss: 2.4247424354353053

Epoch: 6| Step: 4
Training loss: 2.201588629302891
Validation loss: 2.42738737976082

Epoch: 6| Step: 5
Training loss: 2.569312182164033
Validation loss: 2.4284960727189286

Epoch: 6| Step: 6
Training loss: 2.844032692744136
Validation loss: 2.4259127045797797

Epoch: 6| Step: 7
Training loss: 2.90088807024148
Validation loss: 2.4278443037975967

Epoch: 6| Step: 8
Training loss: 2.719163534349872
Validation loss: 2.4447148615673524

Epoch: 6| Step: 9
Training loss: 2.5701509094461086
Validation loss: 2.462020361807124

Epoch: 6| Step: 10
Training loss: 2.2188828119636104
Validation loss: 2.482664454696357

Epoch: 6| Step: 11
Training loss: 2.967445809850521
Validation loss: 2.502475003564951

Epoch: 6| Step: 12
Training loss: 2.5022058292316443
Validation loss: 2.4799886016405135

Epoch: 6| Step: 13
Training loss: 2.4477396366685853
Validation loss: 2.4587723475736882

Epoch: 197| Step: 0
Training loss: 2.6787158327687224
Validation loss: 2.4462973959532794

Epoch: 6| Step: 1
Training loss: 2.513657078554936
Validation loss: 2.441071360600042

Epoch: 6| Step: 2
Training loss: 2.8783114063316444
Validation loss: 2.4596140615478963

Epoch: 6| Step: 3
Training loss: 2.1377302213130145
Validation loss: 2.4508515898527796

Epoch: 6| Step: 4
Training loss: 2.927045520977178
Validation loss: 2.454313476384349

Epoch: 6| Step: 5
Training loss: 2.597456524276742
Validation loss: 2.4382033573040998

Epoch: 6| Step: 6
Training loss: 2.382922160642609
Validation loss: 2.4284698534110594

Epoch: 6| Step: 7
Training loss: 2.6854882806107816
Validation loss: 2.42970019742335

Epoch: 6| Step: 8
Training loss: 2.879036930177296
Validation loss: 2.430562667094041

Epoch: 6| Step: 9
Training loss: 2.6285655919004287
Validation loss: 2.44187273454178

Epoch: 6| Step: 10
Training loss: 2.5189162812353567
Validation loss: 2.441515592099525

Epoch: 6| Step: 11
Training loss: 2.317003144269908
Validation loss: 2.440138233377022

Epoch: 6| Step: 12
Training loss: 2.1737350073764055
Validation loss: 2.4363825971113093

Epoch: 6| Step: 13
Training loss: 3.526792565558127
Validation loss: 2.4361860100765127

Epoch: 198| Step: 0
Training loss: 2.3513043537580294
Validation loss: 2.4429084497678346

Epoch: 6| Step: 1
Training loss: 3.0761652095661915
Validation loss: 2.448011574424991

Epoch: 6| Step: 2
Training loss: 2.2434965027657974
Validation loss: 2.436419576485101

Epoch: 6| Step: 3
Training loss: 2.791951027427018
Validation loss: 2.450807767484494

Epoch: 6| Step: 4
Training loss: 2.724152907551392
Validation loss: 2.4649295563456173

Epoch: 6| Step: 5
Training loss: 2.984715627035108
Validation loss: 2.46716882993896

Epoch: 6| Step: 6
Training loss: 2.3853063321867825
Validation loss: 2.479206878185713

Epoch: 6| Step: 7
Training loss: 2.631124164535315
Validation loss: 2.4844699851006444

Epoch: 6| Step: 8
Training loss: 2.26527538890649
Validation loss: 2.5022749261310797

Epoch: 6| Step: 9
Training loss: 2.599483908270153
Validation loss: 2.511270477870171

Epoch: 6| Step: 10
Training loss: 2.8401258241961087
Validation loss: 2.5023833747655937

Epoch: 6| Step: 11
Training loss: 2.12309415285589
Validation loss: 2.4709331298550103

Epoch: 6| Step: 12
Training loss: 2.6101920853009974
Validation loss: 2.4583874260770373

Epoch: 6| Step: 13
Training loss: 3.1324146046609416
Validation loss: 2.4338549454673215

Epoch: 199| Step: 0
Training loss: 2.232661196879197
Validation loss: 2.4440301759760596

Epoch: 6| Step: 1
Training loss: 2.9370766192564357
Validation loss: 2.479129317028052

Epoch: 6| Step: 2
Training loss: 2.4199224661394556
Validation loss: 2.4947382098087045

Epoch: 6| Step: 3
Training loss: 2.421736190263492
Validation loss: 2.51666673244527

Epoch: 6| Step: 4
Training loss: 2.433973451142033
Validation loss: 2.520010883592971

Epoch: 6| Step: 5
Training loss: 2.865943576488931
Validation loss: 2.568944679849001

Epoch: 6| Step: 6
Training loss: 2.703171569775868
Validation loss: 2.5268015418971914

Epoch: 6| Step: 7
Training loss: 3.2184688111969426
Validation loss: 2.490877627947047

Epoch: 6| Step: 8
Training loss: 2.332823447874407
Validation loss: 2.4527496401853246

Epoch: 6| Step: 9
Training loss: 2.8476013262021564
Validation loss: 2.4678268513515444

Epoch: 6| Step: 10
Training loss: 2.7857815975398887
Validation loss: 2.4749669987746903

Epoch: 6| Step: 11
Training loss: 2.6068098971666154
Validation loss: 2.5145927914783455

Epoch: 6| Step: 12
Training loss: 2.875485254883044
Validation loss: 2.546154309545641

Epoch: 6| Step: 13
Training loss: 2.5301418940140916
Validation loss: 2.5835975196972347

Epoch: 200| Step: 0
Training loss: 3.359598835429905
Validation loss: 2.581603848394351

Epoch: 6| Step: 1
Training loss: 2.6675070590754366
Validation loss: 2.513414497450001

Epoch: 6| Step: 2
Training loss: 1.9951908585310685
Validation loss: 2.4785535717303206

Epoch: 6| Step: 3
Training loss: 2.0397351788687055
Validation loss: 2.45816200525581

Epoch: 6| Step: 4
Training loss: 2.589004403603803
Validation loss: 2.4519954526562953

Epoch: 6| Step: 5
Training loss: 3.4676060895360505
Validation loss: 2.47329753519911

Epoch: 6| Step: 6
Training loss: 2.8456533580818997
Validation loss: 2.512896710828261

Epoch: 6| Step: 7
Training loss: 2.094551502373181
Validation loss: 2.5126503159215887

Epoch: 6| Step: 8
Training loss: 2.6988009227420355
Validation loss: 2.503263124107012

Epoch: 6| Step: 9
Training loss: 2.8150597685572
Validation loss: 2.5265716226858896

Epoch: 6| Step: 10
Training loss: 3.010442995442464
Validation loss: 2.499208232647212

Epoch: 6| Step: 11
Training loss: 2.532955960559189
Validation loss: 2.4736206411423343

Epoch: 6| Step: 12
Training loss: 2.176704252053876
Validation loss: 2.4726391573185578

Epoch: 6| Step: 13
Training loss: 3.0657354896847187
Validation loss: 2.463712069836166

Epoch: 201| Step: 0
Training loss: 2.813843300355853
Validation loss: 2.4494404096589104

Epoch: 6| Step: 1
Training loss: 2.4721759251273063
Validation loss: 2.4567019811599233

Epoch: 6| Step: 2
Training loss: 2.40226336088821
Validation loss: 2.456472102801902

Epoch: 6| Step: 3
Training loss: 2.3196175815837576
Validation loss: 2.4529237499392695

Epoch: 6| Step: 4
Training loss: 1.7731197929642024
Validation loss: 2.4482734243916426

Epoch: 6| Step: 5
Training loss: 2.5431555050951373
Validation loss: 2.439672115976016

Epoch: 6| Step: 6
Training loss: 2.4203823288854505
Validation loss: 2.4455883032168915

Epoch: 6| Step: 7
Training loss: 2.9476962776610676
Validation loss: 2.443432301540686

Epoch: 6| Step: 8
Training loss: 2.6006026229867465
Validation loss: 2.4556899541243706

Epoch: 6| Step: 9
Training loss: 3.0872856961521276
Validation loss: 2.45167974794541

Epoch: 6| Step: 10
Training loss: 2.849647359614469
Validation loss: 2.4690088043239986

Epoch: 6| Step: 11
Training loss: 2.902982289858471
Validation loss: 2.464971365848556

Epoch: 6| Step: 12
Training loss: 2.968732492495663
Validation loss: 2.454439069250213

Epoch: 6| Step: 13
Training loss: 2.4275540617119487
Validation loss: 2.4427529509866277

Epoch: 202| Step: 0
Training loss: 2.1976024047460685
Validation loss: 2.4406656323718976

Epoch: 6| Step: 1
Training loss: 2.689225995481404
Validation loss: 2.4204007459814783

Epoch: 6| Step: 2
Training loss: 2.946325800701096
Validation loss: 2.416108566256481

Epoch: 6| Step: 3
Training loss: 2.901518220414691
Validation loss: 2.4185590057205046

Epoch: 6| Step: 4
Training loss: 2.40749614204264
Validation loss: 2.419343044156547

Epoch: 6| Step: 5
Training loss: 2.313270543571929
Validation loss: 2.420896610789017

Epoch: 6| Step: 6
Training loss: 2.720553709638909
Validation loss: 2.417920894282754

Epoch: 6| Step: 7
Training loss: 2.4329731304473965
Validation loss: 2.4145069599234392

Epoch: 6| Step: 8
Training loss: 2.912685529177897
Validation loss: 2.411989230715597

Epoch: 6| Step: 9
Training loss: 2.3602477221676454
Validation loss: 2.4298655533042193

Epoch: 6| Step: 10
Training loss: 2.4406153015647374
Validation loss: 2.4371556116847053

Epoch: 6| Step: 11
Training loss: 2.948901835207711
Validation loss: 2.4374636533523604

Epoch: 6| Step: 12
Training loss: 3.0714281690476875
Validation loss: 2.4694713298339717

Epoch: 6| Step: 13
Training loss: 1.903512020252493
Validation loss: 2.468374093636283

Epoch: 203| Step: 0
Training loss: 2.1969728537589646
Validation loss: 2.477393672352652

Epoch: 6| Step: 1
Training loss: 2.6807327233920835
Validation loss: 2.4679961335332115

Epoch: 6| Step: 2
Training loss: 2.545467245082634
Validation loss: 2.4648060373632763

Epoch: 6| Step: 3
Training loss: 2.597295520947188
Validation loss: 2.452378178598441

Epoch: 6| Step: 4
Training loss: 2.345602397042386
Validation loss: 2.455026137978054

Epoch: 6| Step: 5
Training loss: 3.0804542984261887
Validation loss: 2.450872586529306

Epoch: 6| Step: 6
Training loss: 2.320851889444222
Validation loss: 2.4494605152039552

Epoch: 6| Step: 7
Training loss: 2.9230202455083774
Validation loss: 2.441748709600299

Epoch: 6| Step: 8
Training loss: 2.7096826468877278
Validation loss: 2.442746588980284

Epoch: 6| Step: 9
Training loss: 2.820656203357918
Validation loss: 2.437446000453135

Epoch: 6| Step: 10
Training loss: 2.6072634073743584
Validation loss: 2.449275261637079

Epoch: 6| Step: 11
Training loss: 2.5472292039452675
Validation loss: 2.44325213002146

Epoch: 6| Step: 12
Training loss: 2.5851010355582216
Validation loss: 2.449265169397011

Epoch: 6| Step: 13
Training loss: 2.3658032288426987
Validation loss: 2.446143144917452

Epoch: 204| Step: 0
Training loss: 2.7421537652616905
Validation loss: 2.458821098307767

Epoch: 6| Step: 1
Training loss: 2.8265834421675735
Validation loss: 2.4510991076094553

Epoch: 6| Step: 2
Training loss: 2.322244475631722
Validation loss: 2.456684484240909

Epoch: 6| Step: 3
Training loss: 2.5555133942798083
Validation loss: 2.44329112807242

Epoch: 6| Step: 4
Training loss: 2.1225501131178346
Validation loss: 2.442597787609784

Epoch: 6| Step: 5
Training loss: 2.598480690363767
Validation loss: 2.446812812336467

Epoch: 6| Step: 6
Training loss: 2.7860489494038188
Validation loss: 2.444438403955841

Epoch: 6| Step: 7
Training loss: 2.3838934775882485
Validation loss: 2.440807153056268

Epoch: 6| Step: 8
Training loss: 2.6378055847460558
Validation loss: 2.4402323149965524

Epoch: 6| Step: 9
Training loss: 2.883629825173115
Validation loss: 2.4507980518545147

Epoch: 6| Step: 10
Training loss: 2.797970179095537
Validation loss: 2.4477287473441747

Epoch: 6| Step: 11
Training loss: 1.8758352326708747
Validation loss: 2.4503306623823886

Epoch: 6| Step: 12
Training loss: 2.6811923147545254
Validation loss: 2.4490513134056657

Epoch: 6| Step: 13
Training loss: 2.8450260862418264
Validation loss: 2.470162287420734

Epoch: 205| Step: 0
Training loss: 2.2947231255360356
Validation loss: 2.4883218563196956

Epoch: 6| Step: 1
Training loss: 2.1619439617449814
Validation loss: 2.5086620620568385

Epoch: 6| Step: 2
Training loss: 3.551109710038468
Validation loss: 2.5550227579171234

Epoch: 6| Step: 3
Training loss: 2.6905248607826056
Validation loss: 2.5227319890657687

Epoch: 6| Step: 4
Training loss: 2.3628065404878615
Validation loss: 2.4661438440123686

Epoch: 6| Step: 5
Training loss: 2.5681414029416154
Validation loss: 2.4836823956925644

Epoch: 6| Step: 6
Training loss: 2.5986852916534837
Validation loss: 2.481806525238339

Epoch: 6| Step: 7
Training loss: 2.508599273761096
Validation loss: 2.4598541026183294

Epoch: 6| Step: 8
Training loss: 2.9704007026784547
Validation loss: 2.4730158967453533

Epoch: 6| Step: 9
Training loss: 2.5214329366364434
Validation loss: 2.4617371389791303

Epoch: 6| Step: 10
Training loss: 3.0216655417971685
Validation loss: 2.4458438982980564

Epoch: 6| Step: 11
Training loss: 1.4814053192473724
Validation loss: 2.455803934099456

Epoch: 6| Step: 12
Training loss: 2.730937693742439
Validation loss: 2.4388523226169077

Epoch: 6| Step: 13
Training loss: 2.6997959165796996
Validation loss: 2.4402787256906007

Epoch: 206| Step: 0
Training loss: 2.0237498392125066
Validation loss: 2.434320806084647

Epoch: 6| Step: 1
Training loss: 2.591702123892099
Validation loss: 2.43942669872604

Epoch: 6| Step: 2
Training loss: 2.7256195274040915
Validation loss: 2.44567075572208

Epoch: 6| Step: 3
Training loss: 2.5791098823109846
Validation loss: 2.4396637509600243

Epoch: 6| Step: 4
Training loss: 2.617916722977418
Validation loss: 2.4615767558074593

Epoch: 6| Step: 5
Training loss: 2.744499427443695
Validation loss: 2.4524210122276897

Epoch: 6| Step: 6
Training loss: 2.2339607334903753
Validation loss: 2.4845811950883836

Epoch: 6| Step: 7
Training loss: 2.8759367702043415
Validation loss: 2.4826268919491805

Epoch: 6| Step: 8
Training loss: 3.049584695025503
Validation loss: 2.486074662729564

Epoch: 6| Step: 9
Training loss: 2.7400401693030947
Validation loss: 2.4795949277681295

Epoch: 6| Step: 10
Training loss: 2.6301259446538316
Validation loss: 2.481646166916455

Epoch: 6| Step: 11
Training loss: 2.6370362945361925
Validation loss: 2.473805568017707

Epoch: 6| Step: 12
Training loss: 2.423428338806427
Validation loss: 2.4628149353093

Epoch: 6| Step: 13
Training loss: 1.433916019316215
Validation loss: 2.4723146455965272

Epoch: 207| Step: 0
Training loss: 2.6220641294154285
Validation loss: 2.4696690967064603

Epoch: 6| Step: 1
Training loss: 2.7004946220300607
Validation loss: 2.480686659345608

Epoch: 6| Step: 2
Training loss: 2.817818677695979
Validation loss: 2.4830645479831204

Epoch: 6| Step: 3
Training loss: 2.170524561541154
Validation loss: 2.4601003696756147

Epoch: 6| Step: 4
Training loss: 2.6786178366864224
Validation loss: 2.482213932743051

Epoch: 6| Step: 5
Training loss: 2.772729229819777
Validation loss: 2.4767920104130794

Epoch: 6| Step: 6
Training loss: 2.2833509829690617
Validation loss: 2.462397161601468

Epoch: 6| Step: 7
Training loss: 2.9580953439611855
Validation loss: 2.4925084585840596

Epoch: 6| Step: 8
Training loss: 2.6230003369847794
Validation loss: 2.4994600646125256

Epoch: 6| Step: 9
Training loss: 2.6718031667232984
Validation loss: 2.5234452495165782

Epoch: 6| Step: 10
Training loss: 3.0752773376941716
Validation loss: 2.491089408088857

Epoch: 6| Step: 11
Training loss: 1.8455698762458383
Validation loss: 2.467813449431703

Epoch: 6| Step: 12
Training loss: 2.183184481295641
Validation loss: 2.464739562742714

Epoch: 6| Step: 13
Training loss: 2.12769718659413
Validation loss: 2.461679075318692

Epoch: 208| Step: 0
Training loss: 2.604243824133664
Validation loss: 2.4417553209371508

Epoch: 6| Step: 1
Training loss: 2.346099286449199
Validation loss: 2.4364232623963615

Epoch: 6| Step: 2
Training loss: 2.3893978983714588
Validation loss: 2.4544982807566

Epoch: 6| Step: 3
Training loss: 3.0212481159145934
Validation loss: 2.4456071164739943

Epoch: 6| Step: 4
Training loss: 2.301134584299892
Validation loss: 2.438978129323854

Epoch: 6| Step: 5
Training loss: 2.659475724030769
Validation loss: 2.4313890977014054

Epoch: 6| Step: 6
Training loss: 2.2786243953604632
Validation loss: 2.451565569428509

Epoch: 6| Step: 7
Training loss: 2.5764892937859556
Validation loss: 2.4377903561580077

Epoch: 6| Step: 8
Training loss: 2.4608230806424123
Validation loss: 2.423561451644273

Epoch: 6| Step: 9
Training loss: 2.72747420231466
Validation loss: 2.426183304386537

Epoch: 6| Step: 10
Training loss: 2.072377452655383
Validation loss: 2.4201492930642714

Epoch: 6| Step: 11
Training loss: 2.311221207335698
Validation loss: 2.4433137163754886

Epoch: 6| Step: 12
Training loss: 3.296080724125793
Validation loss: 2.455923133311004

Epoch: 6| Step: 13
Training loss: 2.9441990860090694
Validation loss: 2.4960931152761985

Epoch: 209| Step: 0
Training loss: 2.5415817204856386
Validation loss: 2.5329227569238957

Epoch: 6| Step: 1
Training loss: 2.130951121564058
Validation loss: 2.55055822860967

Epoch: 6| Step: 2
Training loss: 2.664999520192631
Validation loss: 2.571421066278273

Epoch: 6| Step: 3
Training loss: 3.153781492096454
Validation loss: 2.6020145710196982

Epoch: 6| Step: 4
Training loss: 2.76219335036441
Validation loss: 2.609637272739166

Epoch: 6| Step: 5
Training loss: 2.1109392935563833
Validation loss: 2.5746205914251

Epoch: 6| Step: 6
Training loss: 3.0352300882870105
Validation loss: 2.5427855361101894

Epoch: 6| Step: 7
Training loss: 2.6518987582920577
Validation loss: 2.522342765075571

Epoch: 6| Step: 8
Training loss: 2.804443178719008
Validation loss: 2.4735418036195975

Epoch: 6| Step: 9
Training loss: 2.6614834559698783
Validation loss: 2.447838185103266

Epoch: 6| Step: 10
Training loss: 2.639465438590487
Validation loss: 2.4523214677085337

Epoch: 6| Step: 11
Training loss: 2.862030963700885
Validation loss: 2.440956648579592

Epoch: 6| Step: 12
Training loss: 2.489683226386245
Validation loss: 2.440243299756482

Epoch: 6| Step: 13
Training loss: 1.7828209625230518
Validation loss: 2.4604735833560025

Epoch: 210| Step: 0
Training loss: 2.436666492857016
Validation loss: 2.46198054364382

Epoch: 6| Step: 1
Training loss: 2.632169650688824
Validation loss: 2.458398983556576

Epoch: 6| Step: 2
Training loss: 2.4527223098586934
Validation loss: 2.455104384893424

Epoch: 6| Step: 3
Training loss: 2.467896519177844
Validation loss: 2.4491125864490617

Epoch: 6| Step: 4
Training loss: 2.302254844478995
Validation loss: 2.461436334496517

Epoch: 6| Step: 5
Training loss: 2.81008120477165
Validation loss: 2.4601465170598886

Epoch: 6| Step: 6
Training loss: 2.953238833216519
Validation loss: 2.4501575166947167

Epoch: 6| Step: 7
Training loss: 2.5855826972892366
Validation loss: 2.4690598126916936

Epoch: 6| Step: 8
Training loss: 2.3856398521082944
Validation loss: 2.4568432407111422

Epoch: 6| Step: 9
Training loss: 2.589380191150483
Validation loss: 2.4691374362971863

Epoch: 6| Step: 10
Training loss: 3.2100358054282427
Validation loss: 2.4630137289795058

Epoch: 6| Step: 11
Training loss: 1.6400493520196082
Validation loss: 2.4457203315509974

Epoch: 6| Step: 12
Training loss: 2.3879932553117795
Validation loss: 2.4470441014954423

Epoch: 6| Step: 13
Training loss: 3.8833235897438594
Validation loss: 2.4320519055488137

Epoch: 211| Step: 0
Training loss: 2.3824299489597673
Validation loss: 2.4358405119189994

Epoch: 6| Step: 1
Training loss: 2.3704551578408886
Validation loss: 2.439335794613371

Epoch: 6| Step: 2
Training loss: 2.3753007397224413
Validation loss: 2.4829265138064267

Epoch: 6| Step: 3
Training loss: 2.3980042504280097
Validation loss: 2.479967764640962

Epoch: 6| Step: 4
Training loss: 2.443201293222501
Validation loss: 2.505679218159495

Epoch: 6| Step: 5
Training loss: 2.6743745767905516
Validation loss: 2.514979761830342

Epoch: 6| Step: 6
Training loss: 2.633051739698296
Validation loss: 2.526116650636291

Epoch: 6| Step: 7
Training loss: 3.304299045394724
Validation loss: 2.537574607503578

Epoch: 6| Step: 8
Training loss: 2.7041499669794193
Validation loss: 2.5427231195948683

Epoch: 6| Step: 9
Training loss: 2.6213673478665553
Validation loss: 2.5278957469306906

Epoch: 6| Step: 10
Training loss: 2.075852607301687
Validation loss: 2.5133719178894283

Epoch: 6| Step: 11
Training loss: 3.3322782436115204
Validation loss: 2.530627818470289

Epoch: 6| Step: 12
Training loss: 2.5306491845186643
Validation loss: 2.5167292817813993

Epoch: 6| Step: 13
Training loss: 1.5307724655723234
Validation loss: 2.506716750811774

Epoch: 212| Step: 0
Training loss: 2.544512067985439
Validation loss: 2.4944117971035826

Epoch: 6| Step: 1
Training loss: 2.016034934770559
Validation loss: 2.4933187786033595

Epoch: 6| Step: 2
Training loss: 1.9530156219373285
Validation loss: 2.4804860161039963

Epoch: 6| Step: 3
Training loss: 2.722898540908348
Validation loss: 2.4863256544950203

Epoch: 6| Step: 4
Training loss: 2.823619478205701
Validation loss: 2.4992519797777986

Epoch: 6| Step: 5
Training loss: 2.6295692095384533
Validation loss: 2.5115632846170954

Epoch: 6| Step: 6
Training loss: 2.8168558087318347
Validation loss: 2.491187933471519

Epoch: 6| Step: 7
Training loss: 2.752693244601903
Validation loss: 2.461128335023034

Epoch: 6| Step: 8
Training loss: 2.420562486932182
Validation loss: 2.431569273151767

Epoch: 6| Step: 9
Training loss: 3.078495990839162
Validation loss: 2.43474155420043

Epoch: 6| Step: 10
Training loss: 2.354817517088711
Validation loss: 2.45360729115783

Epoch: 6| Step: 11
Training loss: 2.6614278255339037
Validation loss: 2.4862575517284413

Epoch: 6| Step: 12
Training loss: 3.387744435855647
Validation loss: 2.4956482430589833

Epoch: 6| Step: 13
Training loss: 2.406153392090943
Validation loss: 2.5096580377930087

Epoch: 213| Step: 0
Training loss: 2.383223301230464
Validation loss: 2.5359216520554386

Epoch: 6| Step: 1
Training loss: 2.8304489450922667
Validation loss: 2.543376769591634

Epoch: 6| Step: 2
Training loss: 2.5689565682249804
Validation loss: 2.5583689395721767

Epoch: 6| Step: 3
Training loss: 2.9378903718026916
Validation loss: 2.530213588838039

Epoch: 6| Step: 4
Training loss: 2.9705864295887334
Validation loss: 2.5156497820346435

Epoch: 6| Step: 5
Training loss: 2.6400208995454224
Validation loss: 2.4934458968649085

Epoch: 6| Step: 6
Training loss: 2.303576392319444
Validation loss: 2.46279917335733

Epoch: 6| Step: 7
Training loss: 2.8691394616339543
Validation loss: 2.4869016498137

Epoch: 6| Step: 8
Training loss: 2.476241707708502
Validation loss: 2.551060372903238

Epoch: 6| Step: 9
Training loss: 2.2029088773301697
Validation loss: 2.5985527165116027

Epoch: 6| Step: 10
Training loss: 2.2758206071734115
Validation loss: 2.593853767178497

Epoch: 6| Step: 11
Training loss: 3.3001718534168734
Validation loss: 2.609631125033444

Epoch: 6| Step: 12
Training loss: 2.9500519440813786
Validation loss: 2.5530371371352194

Epoch: 6| Step: 13
Training loss: 2.9392592660845964
Validation loss: 2.536413285629721

Epoch: 214| Step: 0
Training loss: 2.4377372821831726
Validation loss: 2.5256500728838005

Epoch: 6| Step: 1
Training loss: 2.4556115055854266
Validation loss: 2.5226568855198437

Epoch: 6| Step: 2
Training loss: 3.087705004600435
Validation loss: 2.5419380860741936

Epoch: 6| Step: 3
Training loss: 3.1354482317546997
Validation loss: 2.5753586899297907

Epoch: 6| Step: 4
Training loss: 2.861965819244685
Validation loss: 2.582764728369047

Epoch: 6| Step: 5
Training loss: 1.4151994549799292
Validation loss: 2.509579821600958

Epoch: 6| Step: 6
Training loss: 2.6491748604813252
Validation loss: 2.4650156935475334

Epoch: 6| Step: 7
Training loss: 2.577879368033503
Validation loss: 2.4535092518645305

Epoch: 6| Step: 8
Training loss: 2.3009619649953947
Validation loss: 2.4597874868784797

Epoch: 6| Step: 9
Training loss: 2.8701181843312322
Validation loss: 2.4479143326398467

Epoch: 6| Step: 10
Training loss: 3.281446469192478
Validation loss: 2.444638269355777

Epoch: 6| Step: 11
Training loss: 2.731719815069029
Validation loss: 2.4280223808755204

Epoch: 6| Step: 12
Training loss: 2.6541574650659356
Validation loss: 2.430244542589386

Epoch: 6| Step: 13
Training loss: 2.295190206221078
Validation loss: 2.4237025494477242

Epoch: 215| Step: 0
Training loss: 2.9141122440459353
Validation loss: 2.4178923231113303

Epoch: 6| Step: 1
Training loss: 3.1513832264466344
Validation loss: 2.4137628150716544

Epoch: 6| Step: 2
Training loss: 2.152671165971178
Validation loss: 2.4205433603988253

Epoch: 6| Step: 3
Training loss: 2.5652516175828115
Validation loss: 2.400527712955299

Epoch: 6| Step: 4
Training loss: 2.4920495452486735
Validation loss: 2.4100854045239912

Epoch: 6| Step: 5
Training loss: 2.954672433218625
Validation loss: 2.3971232871762336

Epoch: 6| Step: 6
Training loss: 2.592540229036449
Validation loss: 2.4068621104723555

Epoch: 6| Step: 7
Training loss: 2.296753549284272
Validation loss: 2.404807635578542

Epoch: 6| Step: 8
Training loss: 2.34826012586849
Validation loss: 2.396264745134436

Epoch: 6| Step: 9
Training loss: 2.559207382582152
Validation loss: 2.4096815499000726

Epoch: 6| Step: 10
Training loss: 2.640478367091857
Validation loss: 2.41533575725986

Epoch: 6| Step: 11
Training loss: 2.3074930991485996
Validation loss: 2.423085773092558

Epoch: 6| Step: 12
Training loss: 3.015499290257495
Validation loss: 2.4238997903926176

Epoch: 6| Step: 13
Training loss: 2.736379008939808
Validation loss: 2.434520785511253

Epoch: 216| Step: 0
Training loss: 3.1284459760164496
Validation loss: 2.4595176724921743

Epoch: 6| Step: 1
Training loss: 3.089205708558438
Validation loss: 2.485166210474867

Epoch: 6| Step: 2
Training loss: 2.813388090851252
Validation loss: 2.4982283056977743

Epoch: 6| Step: 3
Training loss: 2.664598696268953
Validation loss: 2.507026045838301

Epoch: 6| Step: 4
Training loss: 2.246192040987938
Validation loss: 2.4928110747780425

Epoch: 6| Step: 5
Training loss: 2.776908486297662
Validation loss: 2.4757047631112554

Epoch: 6| Step: 6
Training loss: 2.1477194956115273
Validation loss: 2.4736776715818967

Epoch: 6| Step: 7
Training loss: 2.2310956885567643
Validation loss: 2.442433683128819

Epoch: 6| Step: 8
Training loss: 2.598594278181035
Validation loss: 2.4290526634674414

Epoch: 6| Step: 9
Training loss: 2.7223183026733953
Validation loss: 2.429499514660197

Epoch: 6| Step: 10
Training loss: 2.2869918884280276
Validation loss: 2.4169655389809312

Epoch: 6| Step: 11
Training loss: 2.540635874444603
Validation loss: 2.416451323281508

Epoch: 6| Step: 12
Training loss: 2.278661748921352
Validation loss: 2.417680488097329

Epoch: 6| Step: 13
Training loss: 3.2846297523721693
Validation loss: 2.4151102822686075

Epoch: 217| Step: 0
Training loss: 2.8727622238004016
Validation loss: 2.4291290938277936

Epoch: 6| Step: 1
Training loss: 2.7088887941073425
Validation loss: 2.4375734957081514

Epoch: 6| Step: 2
Training loss: 2.475464875460747
Validation loss: 2.444365808436185

Epoch: 6| Step: 3
Training loss: 2.685783636580429
Validation loss: 2.4370557492207086

Epoch: 6| Step: 4
Training loss: 2.743074713746031
Validation loss: 2.440932923076954

Epoch: 6| Step: 5
Training loss: 2.895136266739568
Validation loss: 2.4538472036529986

Epoch: 6| Step: 6
Training loss: 2.288135744563
Validation loss: 2.441809123345562

Epoch: 6| Step: 7
Training loss: 2.180747809982206
Validation loss: 2.4547098763221458

Epoch: 6| Step: 8
Training loss: 2.14875463745966
Validation loss: 2.4897978093830955

Epoch: 6| Step: 9
Training loss: 2.7101928391767443
Validation loss: 2.4861869914053063

Epoch: 6| Step: 10
Training loss: 2.4215690173392344
Validation loss: 2.4813030673980943

Epoch: 6| Step: 11
Training loss: 2.477923864449639
Validation loss: 2.4843225827668913

Epoch: 6| Step: 12
Training loss: 2.3108897402189
Validation loss: 2.47896644160838

Epoch: 6| Step: 13
Training loss: 3.354191955723805
Validation loss: 2.4918654321775597

Epoch: 218| Step: 0
Training loss: 1.9379205554941457
Validation loss: 2.4829226966226874

Epoch: 6| Step: 1
Training loss: 2.5406431941170395
Validation loss: 2.4858021923368607

Epoch: 6| Step: 2
Training loss: 3.013205392647712
Validation loss: 2.4782097016425153

Epoch: 6| Step: 3
Training loss: 2.0354458242284763
Validation loss: 2.4739017454625984

Epoch: 6| Step: 4
Training loss: 2.8048314134658945
Validation loss: 2.473323304172277

Epoch: 6| Step: 5
Training loss: 2.6515757104637863
Validation loss: 2.465885603462792

Epoch: 6| Step: 6
Training loss: 2.563187111634749
Validation loss: 2.4610783008169332

Epoch: 6| Step: 7
Training loss: 2.593868850374968
Validation loss: 2.4681522844687582

Epoch: 6| Step: 8
Training loss: 2.725701051178935
Validation loss: 2.471343578835176

Epoch: 6| Step: 9
Training loss: 2.3807262855990268
Validation loss: 2.4730454098647296

Epoch: 6| Step: 10
Training loss: 2.4641863011117713
Validation loss: 2.493595982961087

Epoch: 6| Step: 11
Training loss: 2.8753797860777577
Validation loss: 2.4874164396388965

Epoch: 6| Step: 12
Training loss: 2.7374949067647574
Validation loss: 2.4886250099324942

Epoch: 6| Step: 13
Training loss: 2.8904846157317183
Validation loss: 2.472550365956484

Epoch: 219| Step: 0
Training loss: 2.7173212616227747
Validation loss: 2.4720580602752102

Epoch: 6| Step: 1
Training loss: 2.2542141550342087
Validation loss: 2.474176291086721

Epoch: 6| Step: 2
Training loss: 2.682497025316621
Validation loss: 2.4737759966060677

Epoch: 6| Step: 3
Training loss: 2.667576058616402
Validation loss: 2.4691882021713103

Epoch: 6| Step: 4
Training loss: 2.2073121018759196
Validation loss: 2.4826404823852477

Epoch: 6| Step: 5
Training loss: 2.9771127267342608
Validation loss: 2.4835789151139243

Epoch: 6| Step: 6
Training loss: 2.427601694791777
Validation loss: 2.467987409023694

Epoch: 6| Step: 7
Training loss: 2.528816843323216
Validation loss: 2.4548393536274795

Epoch: 6| Step: 8
Training loss: 2.555201860728867
Validation loss: 2.455237233324068

Epoch: 6| Step: 9
Training loss: 2.4283914819936543
Validation loss: 2.4579983391400515

Epoch: 6| Step: 10
Training loss: 2.9602803731564538
Validation loss: 2.4623324168809066

Epoch: 6| Step: 11
Training loss: 2.454787158946278
Validation loss: 2.4710377158050183

Epoch: 6| Step: 12
Training loss: 2.36254084314635
Validation loss: 2.470501322791409

Epoch: 6| Step: 13
Training loss: 2.184136011150372
Validation loss: 2.4731259694543875

Epoch: 220| Step: 0
Training loss: 2.4969014038675987
Validation loss: 2.4498505311734626

Epoch: 6| Step: 1
Training loss: 2.4605586653477043
Validation loss: 2.4545365497019747

Epoch: 6| Step: 2
Training loss: 2.551278268899511
Validation loss: 2.470937837075268

Epoch: 6| Step: 3
Training loss: 2.497897312915477
Validation loss: 2.4613572796074568

Epoch: 6| Step: 4
Training loss: 2.8738756054296086
Validation loss: 2.471219496062385

Epoch: 6| Step: 5
Training loss: 2.9654630433891
Validation loss: 2.4812145824616256

Epoch: 6| Step: 6
Training loss: 2.69887247914595
Validation loss: 2.508304991633704

Epoch: 6| Step: 7
Training loss: 1.9784500698665808
Validation loss: 2.505660599133851

Epoch: 6| Step: 8
Training loss: 2.618131279517807
Validation loss: 2.4957859249345224

Epoch: 6| Step: 9
Training loss: 2.5387622831827863
Validation loss: 2.495172122774152

Epoch: 6| Step: 10
Training loss: 2.484446686484171
Validation loss: 2.485933429666242

Epoch: 6| Step: 11
Training loss: 2.028808299958613
Validation loss: 2.45598192073125

Epoch: 6| Step: 12
Training loss: 2.3561571421653227
Validation loss: 2.469483509184833

Epoch: 6| Step: 13
Training loss: 2.692405127763888
Validation loss: 2.4666436429461087

Epoch: 221| Step: 0
Training loss: 2.5888301655335684
Validation loss: 2.473219864909263

Epoch: 6| Step: 1
Training loss: 2.7205888514677237
Validation loss: 2.4818207822990965

Epoch: 6| Step: 2
Training loss: 2.155942369713504
Validation loss: 2.4786181047652724

Epoch: 6| Step: 3
Training loss: 2.3857160044485255
Validation loss: 2.49418051613381

Epoch: 6| Step: 4
Training loss: 2.0809191512424428
Validation loss: 2.4912520301477614

Epoch: 6| Step: 5
Training loss: 1.9536728967839456
Validation loss: 2.4839968923425406

Epoch: 6| Step: 6
Training loss: 3.2602762470334037
Validation loss: 2.4739975108923513

Epoch: 6| Step: 7
Training loss: 2.6148015775946845
Validation loss: 2.4723600631280935

Epoch: 6| Step: 8
Training loss: 2.5759815900630483
Validation loss: 2.516657261897769

Epoch: 6| Step: 9
Training loss: 2.534135374883529
Validation loss: 2.551018028762943

Epoch: 6| Step: 10
Training loss: 2.7911054891717315
Validation loss: 2.4874844411106865

Epoch: 6| Step: 11
Training loss: 2.493721994802071
Validation loss: 2.478928825411331

Epoch: 6| Step: 12
Training loss: 2.9438207273632537
Validation loss: 2.46886494811433

Epoch: 6| Step: 13
Training loss: 2.57181706786235
Validation loss: 2.445722907013794

Epoch: 222| Step: 0
Training loss: 2.2545056265098564
Validation loss: 2.457249982701374

Epoch: 6| Step: 1
Training loss: 1.9088250574769496
Validation loss: 2.448153897748608

Epoch: 6| Step: 2
Training loss: 2.7515480712650953
Validation loss: 2.4870028202113414

Epoch: 6| Step: 3
Training loss: 2.4582489344015443
Validation loss: 2.5166191287550204

Epoch: 6| Step: 4
Training loss: 3.0564863367110715
Validation loss: 2.5222699871578595

Epoch: 6| Step: 5
Training loss: 2.4367555312804923
Validation loss: 2.5418504759116667

Epoch: 6| Step: 6
Training loss: 2.902921349616718
Validation loss: 2.4764658668810444

Epoch: 6| Step: 7
Training loss: 2.712798521429687
Validation loss: 2.4608386687737314

Epoch: 6| Step: 8
Training loss: 1.6662840006536552
Validation loss: 2.4398903906696376

Epoch: 6| Step: 9
Training loss: 2.1836348036726623
Validation loss: 2.41689566371342

Epoch: 6| Step: 10
Training loss: 3.2466132784559036
Validation loss: 2.413196802353304

Epoch: 6| Step: 11
Training loss: 2.823667775882483
Validation loss: 2.413237293183962

Epoch: 6| Step: 12
Training loss: 2.701792041035303
Validation loss: 2.415956136729623

Epoch: 6| Step: 13
Training loss: 2.4302815879336226
Validation loss: 2.412316687406233

Epoch: 223| Step: 0
Training loss: 2.79175538069175
Validation loss: 2.40490932695583

Epoch: 6| Step: 1
Training loss: 3.0977008907762253
Validation loss: 2.4154989719222306

Epoch: 6| Step: 2
Training loss: 2.4701292796414704
Validation loss: 2.4270841607399554

Epoch: 6| Step: 3
Training loss: 3.49288216664664
Validation loss: 2.425382413609388

Epoch: 6| Step: 4
Training loss: 1.9908673269191408
Validation loss: 2.4313499583030977

Epoch: 6| Step: 5
Training loss: 2.5849386170291537
Validation loss: 2.431122266699284

Epoch: 6| Step: 6
Training loss: 1.5228692193039406
Validation loss: 2.4237765835828764

Epoch: 6| Step: 7
Training loss: 2.614358677020859
Validation loss: 2.4373888359036817

Epoch: 6| Step: 8
Training loss: 2.1209291847417853
Validation loss: 2.43881363832004

Epoch: 6| Step: 9
Training loss: 2.746180830072692
Validation loss: 2.441949859674142

Epoch: 6| Step: 10
Training loss: 2.6481862356899497
Validation loss: 2.425656928622391

Epoch: 6| Step: 11
Training loss: 2.0623638223717067
Validation loss: 2.4329680768637365

Epoch: 6| Step: 12
Training loss: 2.820930899243309
Validation loss: 2.4417592665223786

Epoch: 6| Step: 13
Training loss: 2.502319023303137
Validation loss: 2.4513597733500334

Epoch: 224| Step: 0
Training loss: 2.3893964016430114
Validation loss: 2.4606337222269468

Epoch: 6| Step: 1
Training loss: 2.3174630596093238
Validation loss: 2.4660177712911886

Epoch: 6| Step: 2
Training loss: 2.608118177158656
Validation loss: 2.4570165590317594

Epoch: 6| Step: 3
Training loss: 3.0937603266379896
Validation loss: 2.446404095600775

Epoch: 6| Step: 4
Training loss: 2.2927786701187203
Validation loss: 2.456588702393187

Epoch: 6| Step: 5
Training loss: 2.6977108222662616
Validation loss: 2.4619715760208147

Epoch: 6| Step: 6
Training loss: 2.9806847250344526
Validation loss: 2.4730070925000174

Epoch: 6| Step: 7
Training loss: 1.8527216763496532
Validation loss: 2.521077160461782

Epoch: 6| Step: 8
Training loss: 2.910615001593306
Validation loss: 2.5452127584211564

Epoch: 6| Step: 9
Training loss: 2.632401703161324
Validation loss: 2.5989939319986224

Epoch: 6| Step: 10
Training loss: 1.9720341976365292
Validation loss: 2.5935227538811745

Epoch: 6| Step: 11
Training loss: 3.1372019774399953
Validation loss: 2.589824156194506

Epoch: 6| Step: 12
Training loss: 2.641160538219413
Validation loss: 2.5347046535765445

Epoch: 6| Step: 13
Training loss: 1.5539466204416832
Validation loss: 2.5388086810217336

Epoch: 225| Step: 0
Training loss: 2.3690830610535585
Validation loss: 2.5367277003659927

Epoch: 6| Step: 1
Training loss: 3.074408751921117
Validation loss: 2.5254830066880194

Epoch: 6| Step: 2
Training loss: 1.5663768737017056
Validation loss: 2.512669248415343

Epoch: 6| Step: 3
Training loss: 2.2372128265051363
Validation loss: 2.5070570498327562

Epoch: 6| Step: 4
Training loss: 3.2178343424148808
Validation loss: 2.491216454360103

Epoch: 6| Step: 5
Training loss: 2.975071811610725
Validation loss: 2.48301521598725

Epoch: 6| Step: 6
Training loss: 1.9863686946600543
Validation loss: 2.4945032521341775

Epoch: 6| Step: 7
Training loss: 2.413161124922587
Validation loss: 2.51398169304424

Epoch: 6| Step: 8
Training loss: 2.3539375148637776
Validation loss: 2.5231137677755364

Epoch: 6| Step: 9
Training loss: 2.4521441594446953
Validation loss: 2.5218517660175293

Epoch: 6| Step: 10
Training loss: 2.488664678378486
Validation loss: 2.5204629513257673

Epoch: 6| Step: 11
Training loss: 2.261417243639285
Validation loss: 2.5115161650044344

Epoch: 6| Step: 12
Training loss: 2.542003161142516
Validation loss: 2.4853011432902745

Epoch: 6| Step: 13
Training loss: 2.2526316617195428
Validation loss: 2.4704982558654653

Epoch: 226| Step: 0
Training loss: 1.9449742034535085
Validation loss: 2.4422408845090358

Epoch: 6| Step: 1
Training loss: 2.2026570140975035
Validation loss: 2.4183798475347706

Epoch: 6| Step: 2
Training loss: 2.6082238496302947
Validation loss: 2.4261920413292026

Epoch: 6| Step: 3
Training loss: 2.3712111920050147
Validation loss: 2.418121849913379

Epoch: 6| Step: 4
Training loss: 2.5460631591981806
Validation loss: 2.416763280041285

Epoch: 6| Step: 5
Training loss: 2.6306226548800504
Validation loss: 2.4147761789625926

Epoch: 6| Step: 6
Training loss: 2.0926475469236934
Validation loss: 2.4060937921059966

Epoch: 6| Step: 7
Training loss: 2.3636425908546848
Validation loss: 2.422400948228766

Epoch: 6| Step: 8
Training loss: 2.8372607966355505
Validation loss: 2.4146661781176726

Epoch: 6| Step: 9
Training loss: 2.595188615151444
Validation loss: 2.430814176552142

Epoch: 6| Step: 10
Training loss: 2.5183766166389097
Validation loss: 2.4353474624847693

Epoch: 6| Step: 11
Training loss: 2.91694723323872
Validation loss: 2.4355385752866745

Epoch: 6| Step: 12
Training loss: 2.5865624355506496
Validation loss: 2.439146934267547

Epoch: 6| Step: 13
Training loss: 2.9022261132367886
Validation loss: 2.4269475413461463

Epoch: 227| Step: 0
Training loss: 3.183737385323811
Validation loss: 2.4156872656866106

Epoch: 6| Step: 1
Training loss: 2.3621730759896016
Validation loss: 2.4173020795893345

Epoch: 6| Step: 2
Training loss: 3.2105476532557002
Validation loss: 2.41951313423855

Epoch: 6| Step: 3
Training loss: 2.367688821515569
Validation loss: 2.4190934545565184

Epoch: 6| Step: 4
Training loss: 2.50652786579086
Validation loss: 2.420255083132212

Epoch: 6| Step: 5
Training loss: 2.450659612495362
Validation loss: 2.4314797812240863

Epoch: 6| Step: 6
Training loss: 2.2535832800109845
Validation loss: 2.4473910568385495

Epoch: 6| Step: 7
Training loss: 2.079793618673943
Validation loss: 2.438361544416818

Epoch: 6| Step: 8
Training loss: 2.2587565524033133
Validation loss: 2.4520411022660293

Epoch: 6| Step: 9
Training loss: 2.1551658005448524
Validation loss: 2.4562516804534678

Epoch: 6| Step: 10
Training loss: 2.453410915550926
Validation loss: 2.437982652879082

Epoch: 6| Step: 11
Training loss: 2.8070468170643177
Validation loss: 2.451960872474598

Epoch: 6| Step: 12
Training loss: 1.9253266515646688
Validation loss: 2.4597027299729586

Epoch: 6| Step: 13
Training loss: 2.6115017749737253
Validation loss: 2.4532435654814555

Epoch: 228| Step: 0
Training loss: 2.6694238138167976
Validation loss: 2.4749658168944206

Epoch: 6| Step: 1
Training loss: 2.2082837896967416
Validation loss: 2.451840097306408

Epoch: 6| Step: 2
Training loss: 2.354493605155629
Validation loss: 2.4518792734827217

Epoch: 6| Step: 3
Training loss: 3.183461192361082
Validation loss: 2.45422803843588

Epoch: 6| Step: 4
Training loss: 2.114463940586947
Validation loss: 2.451117542832973

Epoch: 6| Step: 5
Training loss: 2.22608766009939
Validation loss: 2.4438358531933764

Epoch: 6| Step: 6
Training loss: 2.1746237944667435
Validation loss: 2.447687366003278

Epoch: 6| Step: 7
Training loss: 2.074828667059077
Validation loss: 2.453887436390958

Epoch: 6| Step: 8
Training loss: 2.832179077499579
Validation loss: 2.4559661900828367

Epoch: 6| Step: 9
Training loss: 2.4180451659913573
Validation loss: 2.4646364050102427

Epoch: 6| Step: 10
Training loss: 2.4665098045922913
Validation loss: 2.474559637718944

Epoch: 6| Step: 11
Training loss: 2.6995181678065943
Validation loss: 2.463905079942912

Epoch: 6| Step: 12
Training loss: 2.31805145352702
Validation loss: 2.460357958215374

Epoch: 6| Step: 13
Training loss: 2.130064706849299
Validation loss: 2.4567601374060932

Epoch: 229| Step: 0
Training loss: 2.4261339702111164
Validation loss: 2.4422294332138597

Epoch: 6| Step: 1
Training loss: 2.2206520202178144
Validation loss: 2.4601216656901643

Epoch: 6| Step: 2
Training loss: 1.8196175357838202
Validation loss: 2.472326155597839

Epoch: 6| Step: 3
Training loss: 2.43213660149543
Validation loss: 2.467081802553099

Epoch: 6| Step: 4
Training loss: 2.307040393887441
Validation loss: 2.4853705884483777

Epoch: 6| Step: 5
Training loss: 2.36225755446598
Validation loss: 2.488774948968707

Epoch: 6| Step: 6
Training loss: 2.836098070038908
Validation loss: 2.4802445815283662

Epoch: 6| Step: 7
Training loss: 2.6596092972605407
Validation loss: 2.449253756176846

Epoch: 6| Step: 8
Training loss: 2.8311205432254978
Validation loss: 2.4230933494656663

Epoch: 6| Step: 9
Training loss: 2.557070026517443
Validation loss: 2.4270473105922497

Epoch: 6| Step: 10
Training loss: 1.777127430925104
Validation loss: 2.4381558566897

Epoch: 6| Step: 11
Training loss: 2.65547716454219
Validation loss: 2.4410392911382743

Epoch: 6| Step: 12
Training loss: 2.5107978330934952
Validation loss: 2.452340752004448

Epoch: 6| Step: 13
Training loss: 2.8471565383736643
Validation loss: 2.4337904790074663

Epoch: 230| Step: 0
Training loss: 2.800068060865181
Validation loss: 2.4329566019444298

Epoch: 6| Step: 1
Training loss: 1.7706654936593165
Validation loss: 2.4571590045073988

Epoch: 6| Step: 2
Training loss: 2.0676351257227563
Validation loss: 2.4642411784455427

Epoch: 6| Step: 3
Training loss: 2.3497949591933005
Validation loss: 2.4685951294407453

Epoch: 6| Step: 4
Training loss: 2.2314675361311282
Validation loss: 2.4875487872879076

Epoch: 6| Step: 5
Training loss: 2.2128237169593166
Validation loss: 2.505183302012989

Epoch: 6| Step: 6
Training loss: 2.9683646504118966
Validation loss: 2.5653715404188597

Epoch: 6| Step: 7
Training loss: 2.615929691338132
Validation loss: 2.5597693838388285

Epoch: 6| Step: 8
Training loss: 2.180505742545505
Validation loss: 2.5309788659859334

Epoch: 6| Step: 9
Training loss: 2.8967352544334015
Validation loss: 2.5104397542187398

Epoch: 6| Step: 10
Training loss: 3.291874424297166
Validation loss: 2.5084850784443975

Epoch: 6| Step: 11
Training loss: 1.9289750857487011
Validation loss: 2.4723587420911253

Epoch: 6| Step: 12
Training loss: 2.6614969826795325
Validation loss: 2.4834995193797598

Epoch: 6| Step: 13
Training loss: 1.8488740355567979
Validation loss: 2.4646405875299147

Epoch: 231| Step: 0
Training loss: 2.1926211764908663
Validation loss: 2.4443431029500844

Epoch: 6| Step: 1
Training loss: 2.763622528821822
Validation loss: 2.4483851968637724

Epoch: 6| Step: 2
Training loss: 2.244438609765068
Validation loss: 2.442634118734259

Epoch: 6| Step: 3
Training loss: 2.423365177573226
Validation loss: 2.459244128848835

Epoch: 6| Step: 4
Training loss: 2.132876999546981
Validation loss: 2.46262692722508

Epoch: 6| Step: 5
Training loss: 2.5442925214412484
Validation loss: 2.452064654422309

Epoch: 6| Step: 6
Training loss: 2.1201207860690325
Validation loss: 2.4397221310381942

Epoch: 6| Step: 7
Training loss: 2.741145009171115
Validation loss: 2.4388494066784117

Epoch: 6| Step: 8
Training loss: 2.343196243989799
Validation loss: 2.4452706521154335

Epoch: 6| Step: 9
Training loss: 2.4859144131819035
Validation loss: 2.4449840247586514

Epoch: 6| Step: 10
Training loss: 2.4453249800001022
Validation loss: 2.4499447850042535

Epoch: 6| Step: 11
Training loss: 2.984072684908724
Validation loss: 2.4522075914087225

Epoch: 6| Step: 12
Training loss: 2.381542730485877
Validation loss: 2.4512916947799397

Epoch: 6| Step: 13
Training loss: 2.5145002421441363
Validation loss: 2.4411288747422875

Epoch: 232| Step: 0
Training loss: 2.3154961018588196
Validation loss: 2.431102082256164

Epoch: 6| Step: 1
Training loss: 2.1100065063086983
Validation loss: 2.4272425718714716

Epoch: 6| Step: 2
Training loss: 2.1271523066243736
Validation loss: 2.4267579033508833

Epoch: 6| Step: 3
Training loss: 2.5684135866426927
Validation loss: 2.417671201871919

Epoch: 6| Step: 4
Training loss: 2.8512280411733886
Validation loss: 2.429834102980492

Epoch: 6| Step: 5
Training loss: 2.206623951286249
Validation loss: 2.445847586777358

Epoch: 6| Step: 6
Training loss: 2.2825197840289673
Validation loss: 2.459883428688423

Epoch: 6| Step: 7
Training loss: 2.189101259812828
Validation loss: 2.4632100972195548

Epoch: 6| Step: 8
Training loss: 2.9999014520353544
Validation loss: 2.477213976664902

Epoch: 6| Step: 9
Training loss: 2.5202188189431536
Validation loss: 2.4621047728925016

Epoch: 6| Step: 10
Training loss: 2.0165120619893853
Validation loss: 2.4685531523193815

Epoch: 6| Step: 11
Training loss: 2.368719127926913
Validation loss: 2.46242697273135

Epoch: 6| Step: 12
Training loss: 2.8154265542332113
Validation loss: 2.479238226969325

Epoch: 6| Step: 13
Training loss: 2.768394247583333
Validation loss: 2.489448069661911

Epoch: 233| Step: 0
Training loss: 2.6773677828188487
Validation loss: 2.505979326756647

Epoch: 6| Step: 1
Training loss: 2.774738790916832
Validation loss: 2.4883244793829467

Epoch: 6| Step: 2
Training loss: 1.791075527641236
Validation loss: 2.512075879126901

Epoch: 6| Step: 3
Training loss: 2.506523585429422
Validation loss: 2.521156267637633

Epoch: 6| Step: 4
Training loss: 2.109221954445002
Validation loss: 2.5108410076616834

Epoch: 6| Step: 5
Training loss: 2.7268471992748986
Validation loss: 2.502874608554288

Epoch: 6| Step: 6
Training loss: 2.9346619552038358
Validation loss: 2.494864807214524

Epoch: 6| Step: 7
Training loss: 2.334916622135407
Validation loss: 2.49202744910639

Epoch: 6| Step: 8
Training loss: 2.2257089149876204
Validation loss: 2.4798631293889186

Epoch: 6| Step: 9
Training loss: 2.069744910403363
Validation loss: 2.477000439920545

Epoch: 6| Step: 10
Training loss: 2.34280681705587
Validation loss: 2.45723157783653

Epoch: 6| Step: 11
Training loss: 2.350346247549054
Validation loss: 2.4401221705039653

Epoch: 6| Step: 12
Training loss: 2.4277942800458083
Validation loss: 2.4390945519808755

Epoch: 6| Step: 13
Training loss: 1.8913431616388723
Validation loss: 2.446088107852613

Epoch: 234| Step: 0
Training loss: 1.9240818534102015
Validation loss: 2.4474190846191997

Epoch: 6| Step: 1
Training loss: 2.6160737813700004
Validation loss: 2.4505476299170894

Epoch: 6| Step: 2
Training loss: 1.7575186928939281
Validation loss: 2.459154236686562

Epoch: 6| Step: 3
Training loss: 2.3020010080476174
Validation loss: 2.471875211739206

Epoch: 6| Step: 4
Training loss: 1.708115431992232
Validation loss: 2.4868927359749464

Epoch: 6| Step: 5
Training loss: 2.3405974484542296
Validation loss: 2.4782288041444107

Epoch: 6| Step: 6
Training loss: 2.3411250355736963
Validation loss: 2.477137343009689

Epoch: 6| Step: 7
Training loss: 2.136475822963638
Validation loss: 2.5022861405452996

Epoch: 6| Step: 8
Training loss: 2.6618659397247817
Validation loss: 2.507750767923746

Epoch: 6| Step: 9
Training loss: 2.5236738820568863
Validation loss: 2.5092152262648613

Epoch: 6| Step: 10
Training loss: 2.6580684047533736
Validation loss: 2.5206867905276606

Epoch: 6| Step: 11
Training loss: 2.616793019186124
Validation loss: 2.5312468947646383

Epoch: 6| Step: 12
Training loss: 3.1080709051736437
Validation loss: 2.556794783293637

Epoch: 6| Step: 13
Training loss: 2.9145059120378725
Validation loss: 2.532790784212661

Epoch: 235| Step: 0
Training loss: 2.9462749820988536
Validation loss: 2.4997976426294826

Epoch: 6| Step: 1
Training loss: 2.6431459210195425
Validation loss: 2.517981749394436

Epoch: 6| Step: 2
Training loss: 1.7463177360225988
Validation loss: 2.5171571770084498

Epoch: 6| Step: 3
Training loss: 2.680948922563936
Validation loss: 2.5204693266939002

Epoch: 6| Step: 4
Training loss: 2.479500649232312
Validation loss: 2.5138570108588647

Epoch: 6| Step: 5
Training loss: 1.799956556961543
Validation loss: 2.507230044255236

Epoch: 6| Step: 6
Training loss: 3.301806481405204
Validation loss: 2.4928451638824245

Epoch: 6| Step: 7
Training loss: 2.400933076357189
Validation loss: 2.4723978046694777

Epoch: 6| Step: 8
Training loss: 1.09917792466081
Validation loss: 2.4787901229357643

Epoch: 6| Step: 9
Training loss: 2.016778896561233
Validation loss: 2.4607633993661886

Epoch: 6| Step: 10
Training loss: 2.1937025146561777
Validation loss: 2.467738203691587

Epoch: 6| Step: 11
Training loss: 2.8098569530852915
Validation loss: 2.4714854869307996

Epoch: 6| Step: 12
Training loss: 1.5888259216464384
Validation loss: 2.47048565605735

Epoch: 6| Step: 13
Training loss: 2.5732369062742295
Validation loss: 2.4659064341812007

Epoch: 236| Step: 0
Training loss: 2.0065377192503546
Validation loss: 2.4698382972541344

Epoch: 6| Step: 1
Training loss: 1.9371784927889826
Validation loss: 2.490669737014811

Epoch: 6| Step: 2
Training loss: 2.574131132032691
Validation loss: 2.509901912463869

Epoch: 6| Step: 3
Training loss: 2.8836098165382302
Validation loss: 2.502823518045822

Epoch: 6| Step: 4
Training loss: 1.7481034765190302
Validation loss: 2.479951801067364

Epoch: 6| Step: 5
Training loss: 2.6393401501843683
Validation loss: 2.4807478092991717

Epoch: 6| Step: 6
Training loss: 2.0557065112155253
Validation loss: 2.4740867508015745

Epoch: 6| Step: 7
Training loss: 2.2509437277296103
Validation loss: 2.4651140952367556

Epoch: 6| Step: 8
Training loss: 2.4763697600349444
Validation loss: 2.457839305773153

Epoch: 6| Step: 9
Training loss: 2.5993164264291853
Validation loss: 2.4909072068038176

Epoch: 6| Step: 10
Training loss: 3.2138211928872265
Validation loss: 2.494503264466768

Epoch: 6| Step: 11
Training loss: 2.2899518157020915
Validation loss: 2.470723174769032

Epoch: 6| Step: 12
Training loss: 2.2950178670083803
Validation loss: 2.4612971300739983

Epoch: 6| Step: 13
Training loss: 2.5168416179283764
Validation loss: 2.4516586259036215

Epoch: 237| Step: 0
Training loss: 2.6722645615016702
Validation loss: 2.4444019265996935

Epoch: 6| Step: 1
Training loss: 1.5233528309303994
Validation loss: 2.449180430935041

Epoch: 6| Step: 2
Training loss: 2.066092050818955
Validation loss: 2.4589372904198634

Epoch: 6| Step: 3
Training loss: 2.3334301406215032
Validation loss: 2.4503378333195496

Epoch: 6| Step: 4
Training loss: 2.5713621274750067
Validation loss: 2.4766601655039735

Epoch: 6| Step: 5
Training loss: 2.4670219650929783
Validation loss: 2.4805925566549334

Epoch: 6| Step: 6
Training loss: 2.269098394877306
Validation loss: 2.4957112565155444

Epoch: 6| Step: 7
Training loss: 1.7494148911115042
Validation loss: 2.502012705972656

Epoch: 6| Step: 8
Training loss: 3.12200143002484
Validation loss: 2.4951184410045673

Epoch: 6| Step: 9
Training loss: 2.7987836580011742
Validation loss: 2.498956702560706

Epoch: 6| Step: 10
Training loss: 1.7643199587488658
Validation loss: 2.5147530648352006

Epoch: 6| Step: 11
Training loss: 3.0625741132215247
Validation loss: 2.5280645297160858

Epoch: 6| Step: 12
Training loss: 1.2935955452978543
Validation loss: 2.512900421268912

Epoch: 6| Step: 13
Training loss: 2.424466623068272
Validation loss: 2.522756213506701

Epoch: 238| Step: 0
Training loss: 2.0728022737105576
Validation loss: 2.5150652337619515

Epoch: 6| Step: 1
Training loss: 3.0701012769265343
Validation loss: 2.5118518910733574

Epoch: 6| Step: 2
Training loss: 1.8642158003999472
Validation loss: 2.5046497010620445

Epoch: 6| Step: 3
Training loss: 1.8108898772066138
Validation loss: 2.525933793638739

Epoch: 6| Step: 4
Training loss: 2.295324308132599
Validation loss: 2.5266565888477923

Epoch: 6| Step: 5
Training loss: 2.362232826909285
Validation loss: 2.5347269683477296

Epoch: 6| Step: 6
Training loss: 2.8609858077016246
Validation loss: 2.524985252718247

Epoch: 6| Step: 7
Training loss: 2.430491814155974
Validation loss: 2.525541657992304

Epoch: 6| Step: 8
Training loss: 2.2906189922342453
Validation loss: 2.5177167571407146

Epoch: 6| Step: 9
Training loss: 2.0387852505852964
Validation loss: 2.5155431726102946

Epoch: 6| Step: 10
Training loss: 2.2332550656662518
Validation loss: 2.522905702163116

Epoch: 6| Step: 11
Training loss: 2.459192244490318
Validation loss: 2.528639437350763

Epoch: 6| Step: 12
Training loss: 2.218878728866345
Validation loss: 2.5213799985183556

Epoch: 6| Step: 13
Training loss: 2.4877924416553663
Validation loss: 2.5069741840144038

Epoch: 239| Step: 0
Training loss: 1.3590975072601386
Validation loss: 2.466636876681194

Epoch: 6| Step: 1
Training loss: 2.2787030777779727
Validation loss: 2.4586524804882104

Epoch: 6| Step: 2
Training loss: 2.0993672643838672
Validation loss: 2.438459851571482

Epoch: 6| Step: 3
Training loss: 2.3388846187698555
Validation loss: 2.433885669714815

Epoch: 6| Step: 4
Training loss: 2.445878910850946
Validation loss: 2.4255250426882196

Epoch: 6| Step: 5
Training loss: 2.6683985530103107
Validation loss: 2.4274605205281676

Epoch: 6| Step: 6
Training loss: 2.541454796220403
Validation loss: 2.443993652666675

Epoch: 6| Step: 7
Training loss: 2.289452008642664
Validation loss: 2.4370838721945636

Epoch: 6| Step: 8
Training loss: 2.5661457457922108
Validation loss: 2.4552479911975817

Epoch: 6| Step: 9
Training loss: 2.6617345399111105
Validation loss: 2.4565278777706236

Epoch: 6| Step: 10
Training loss: 2.4491747497792096
Validation loss: 2.4683706787340354

Epoch: 6| Step: 11
Training loss: 2.480006762156958
Validation loss: 2.549531107392735

Epoch: 6| Step: 12
Training loss: 1.997631816692214
Validation loss: 2.608654947341916

Epoch: 6| Step: 13
Training loss: 3.1839864476936266
Validation loss: 2.641707353196753

Epoch: 240| Step: 0
Training loss: 2.2006723806951687
Validation loss: 2.5545492364064106

Epoch: 6| Step: 1
Training loss: 1.8487020682104554
Validation loss: 2.5067770806854357

Epoch: 6| Step: 2
Training loss: 2.614570972266493
Validation loss: 2.504139382529368

Epoch: 6| Step: 3
Training loss: 1.947697537042336
Validation loss: 2.5372008197357805

Epoch: 6| Step: 4
Training loss: 2.604156117735796
Validation loss: 2.592745287240492

Epoch: 6| Step: 5
Training loss: 2.365379322754627
Validation loss: 2.593836719038312

Epoch: 6| Step: 6
Training loss: 2.614406280804657
Validation loss: 2.575443174370757

Epoch: 6| Step: 7
Training loss: 2.0764952270541137
Validation loss: 2.522077768023054

Epoch: 6| Step: 8
Training loss: 2.7111920943524543
Validation loss: 2.4879088057780203

Epoch: 6| Step: 9
Training loss: 3.249068933781246
Validation loss: 2.4443387231341442

Epoch: 6| Step: 10
Training loss: 2.22783766254069
Validation loss: 2.424775455766111

Epoch: 6| Step: 11
Training loss: 1.9862886348013389
Validation loss: 2.4023540574973246

Epoch: 6| Step: 12
Training loss: 2.5133820005742358
Validation loss: 2.3981457861178237

Epoch: 6| Step: 13
Training loss: 2.3060995657634464
Validation loss: 2.39932245446108

Epoch: 241| Step: 0
Training loss: 2.0514461347782165
Validation loss: 2.409515917519647

Epoch: 6| Step: 1
Training loss: 2.565686082751713
Validation loss: 2.409697868882369

Epoch: 6| Step: 2
Training loss: 1.8935370599360009
Validation loss: 2.4081157540764715

Epoch: 6| Step: 3
Training loss: 2.3402629088380027
Validation loss: 2.410790436086645

Epoch: 6| Step: 4
Training loss: 2.922344476038597
Validation loss: 2.4248563466192046

Epoch: 6| Step: 5
Training loss: 2.5172057309191995
Validation loss: 2.435977085094486

Epoch: 6| Step: 6
Training loss: 1.5886474157269672
Validation loss: 2.430652795029184

Epoch: 6| Step: 7
Training loss: 2.3836966453306196
Validation loss: 2.4448033709368038

Epoch: 6| Step: 8
Training loss: 2.3709487493632024
Validation loss: 2.4461748833664068

Epoch: 6| Step: 9
Training loss: 2.2508540122212004
Validation loss: 2.442472408754028

Epoch: 6| Step: 10
Training loss: 2.470162096457615
Validation loss: 2.4569924846436755

Epoch: 6| Step: 11
Training loss: 1.8412878115747442
Validation loss: 2.4403446968622604

Epoch: 6| Step: 12
Training loss: 2.560073634221148
Validation loss: 2.437198145360381

Epoch: 6| Step: 13
Training loss: 1.891708756985465
Validation loss: 2.4397895068945283

Epoch: 242| Step: 0
Training loss: 2.278002164482984
Validation loss: 2.440078622975821

Epoch: 6| Step: 1
Training loss: 2.3883356838742724
Validation loss: 2.4475082723556585

Epoch: 6| Step: 2
Training loss: 1.9450177195313083
Validation loss: 2.450076847491007

Epoch: 6| Step: 3
Training loss: 2.33418448001375
Validation loss: 2.4478541889652567

Epoch: 6| Step: 4
Training loss: 2.1024929100035012
Validation loss: 2.4639971969983683

Epoch: 6| Step: 5
Training loss: 2.6545140596507113
Validation loss: 2.476203120928262

Epoch: 6| Step: 6
Training loss: 2.290071128506843
Validation loss: 2.4525072176693916

Epoch: 6| Step: 7
Training loss: 2.39737531272122
Validation loss: 2.4520176178425177

Epoch: 6| Step: 8
Training loss: 2.0219314449396864
Validation loss: 2.46744702140802

Epoch: 6| Step: 9
Training loss: 2.0994248419997823
Validation loss: 2.461979508599358

Epoch: 6| Step: 10
Training loss: 2.4052085108789307
Validation loss: 2.4622286116753185

Epoch: 6| Step: 11
Training loss: 2.189543940815577
Validation loss: 2.473420727557319

Epoch: 6| Step: 12
Training loss: 2.5391886048912786
Validation loss: 2.476737804502766

Epoch: 6| Step: 13
Training loss: 2.066087319581094
Validation loss: 2.481586151194847

Epoch: 243| Step: 0
Training loss: 2.660470549043511
Validation loss: 2.496835245719527

Epoch: 6| Step: 1
Training loss: 2.2987279359672366
Validation loss: 2.4886340772382054

Epoch: 6| Step: 2
Training loss: 2.5509595823237605
Validation loss: 2.471021206405161

Epoch: 6| Step: 3
Training loss: 1.9628818189129271
Validation loss: 2.456283903552031

Epoch: 6| Step: 4
Training loss: 2.4598572312771734
Validation loss: 2.4467350551812035

Epoch: 6| Step: 5
Training loss: 2.7135540650146117
Validation loss: 2.436425110084864

Epoch: 6| Step: 6
Training loss: 2.4018714998861475
Validation loss: 2.433520530729421

Epoch: 6| Step: 7
Training loss: 2.2819833491233608
Validation loss: 2.4206289070117584

Epoch: 6| Step: 8
Training loss: 2.1035317196314405
Validation loss: 2.4343549907625026

Epoch: 6| Step: 9
Training loss: 2.2033359074926224
Validation loss: 2.4347734454863477

Epoch: 6| Step: 10
Training loss: 1.9749584097044313
Validation loss: 2.445561461028336

Epoch: 6| Step: 11
Training loss: 1.628237580197979
Validation loss: 2.432333560080501

Epoch: 6| Step: 12
Training loss: 2.0644152447447133
Validation loss: 2.434629024785537

Epoch: 6| Step: 13
Training loss: 2.0808076680588807
Validation loss: 2.4297837778174722

Epoch: 244| Step: 0
Training loss: 2.6662003784998958
Validation loss: 2.4454904010808987

Epoch: 6| Step: 1
Training loss: 1.9277529266299587
Validation loss: 2.4454037291769333

Epoch: 6| Step: 2
Training loss: 2.6215119575432952
Validation loss: 2.4547531287824693

Epoch: 6| Step: 3
Training loss: 2.582228752581374
Validation loss: 2.4865001098313155

Epoch: 6| Step: 4
Training loss: 2.4308136418481907
Validation loss: 2.482846213354989

Epoch: 6| Step: 5
Training loss: 2.632823276214732
Validation loss: 2.510282159965964

Epoch: 6| Step: 6
Training loss: 1.8211724210722526
Validation loss: 2.49396097645354

Epoch: 6| Step: 7
Training loss: 2.1947425835589827
Validation loss: 2.493136370576875

Epoch: 6| Step: 8
Training loss: 1.9791578058412531
Validation loss: 2.473378095905318

Epoch: 6| Step: 9
Training loss: 2.187411388237334
Validation loss: 2.454170994234489

Epoch: 6| Step: 10
Training loss: 2.2006659886866538
Validation loss: 2.45098448313517

Epoch: 6| Step: 11
Training loss: 1.477235509496979
Validation loss: 2.4367190788403565

Epoch: 6| Step: 12
Training loss: 2.5455718655921475
Validation loss: 2.435560722879778

Epoch: 6| Step: 13
Training loss: 1.8071854383340442
Validation loss: 2.437907597140045

Epoch: 245| Step: 0
Training loss: 1.8240650447156526
Validation loss: 2.4387758374687345

Epoch: 6| Step: 1
Training loss: 2.3830312159483102
Validation loss: 2.4417345692377306

Epoch: 6| Step: 2
Training loss: 2.791711398852837
Validation loss: 2.435166210626735

Epoch: 6| Step: 3
Training loss: 2.5837412378820512
Validation loss: 2.4389268092624903

Epoch: 6| Step: 4
Training loss: 2.0101518473037676
Validation loss: 2.445847187428205

Epoch: 6| Step: 5
Training loss: 2.476450150405339
Validation loss: 2.458539288463729

Epoch: 6| Step: 6
Training loss: 2.4259369288813253
Validation loss: 2.4578447974067332

Epoch: 6| Step: 7
Training loss: 1.8527463838178835
Validation loss: 2.4622186943483433

Epoch: 6| Step: 8
Training loss: 1.7748913288430563
Validation loss: 2.4624072666508647

Epoch: 6| Step: 9
Training loss: 2.520496272312307
Validation loss: 2.4772619153481235

Epoch: 6| Step: 10
Training loss: 2.1137728586432867
Validation loss: 2.4820212308777436

Epoch: 6| Step: 11
Training loss: 2.0559159584383844
Validation loss: 2.4912242207529762

Epoch: 6| Step: 12
Training loss: 2.4452550716786314
Validation loss: 2.4919577913274455

Epoch: 6| Step: 13
Training loss: 2.670476714877812
Validation loss: 2.488079038938795

Epoch: 246| Step: 0
Training loss: 2.0939601963490238
Validation loss: 2.4925523099325466

Epoch: 6| Step: 1
Training loss: 3.01563575228815
Validation loss: 2.488592721938371

Epoch: 6| Step: 2
Training loss: 2.0983091222786836
Validation loss: 2.464426503305786

Epoch: 6| Step: 3
Training loss: 2.546748152306316
Validation loss: 2.4901589543251506

Epoch: 6| Step: 4
Training loss: 2.2356689547770716
Validation loss: 2.457111182770274

Epoch: 6| Step: 5
Training loss: 1.8085690325701973
Validation loss: 2.4523496273084175

Epoch: 6| Step: 6
Training loss: 2.104009968679622
Validation loss: 2.430220555327576

Epoch: 6| Step: 7
Training loss: 2.155824370462046
Validation loss: 2.4358961983395644

Epoch: 6| Step: 8
Training loss: 2.644156177242267
Validation loss: 2.436223423877791

Epoch: 6| Step: 9
Training loss: 1.8185348016378642
Validation loss: 2.4081587926792776

Epoch: 6| Step: 10
Training loss: 2.549417268328301
Validation loss: 2.436376766158651

Epoch: 6| Step: 11
Training loss: 1.5168684744802596
Validation loss: 2.4535940377787813

Epoch: 6| Step: 12
Training loss: 1.7195628238259364
Validation loss: 2.4690137124949287

Epoch: 6| Step: 13
Training loss: 2.2552113052125398
Validation loss: 2.474403391228081

Epoch: 247| Step: 0
Training loss: 1.9534430893320842
Validation loss: 2.4314325699529604

Epoch: 6| Step: 1
Training loss: 1.8320755617683815
Validation loss: 2.4420557204845608

Epoch: 6| Step: 2
Training loss: 1.9191534109095376
Validation loss: 2.42991781697792

Epoch: 6| Step: 3
Training loss: 2.815938162032568
Validation loss: 2.4419638869834386

Epoch: 6| Step: 4
Training loss: 2.420463790745648
Validation loss: 2.456481854433326

Epoch: 6| Step: 5
Training loss: 2.9181174530173544
Validation loss: 2.461525824624958

Epoch: 6| Step: 6
Training loss: 2.5582524894673164
Validation loss: 2.4316665570936764

Epoch: 6| Step: 7
Training loss: 2.8649109994003066
Validation loss: 2.401550690301676

Epoch: 6| Step: 8
Training loss: 2.363097128513308
Validation loss: 2.431514291042685

Epoch: 6| Step: 9
Training loss: 2.152737285547672
Validation loss: 2.4991837514913957

Epoch: 6| Step: 10
Training loss: 2.4116807564528355
Validation loss: 2.576939177548475

Epoch: 6| Step: 11
Training loss: 2.310638503307852
Validation loss: 2.578409396408346

Epoch: 6| Step: 12
Training loss: 1.9241632005151739
Validation loss: 2.5739400826937238

Epoch: 6| Step: 13
Training loss: 3.1887659289157715
Validation loss: 2.549435988622252

Epoch: 248| Step: 0
Training loss: 2.3447999763991145
Validation loss: 2.510190431121549

Epoch: 6| Step: 1
Training loss: 2.3906768593741954
Validation loss: 2.480653922853095

Epoch: 6| Step: 2
Training loss: 2.8491781220861765
Validation loss: 2.433216436596757

Epoch: 6| Step: 3
Training loss: 1.7775311381728514
Validation loss: 2.4410295943910376

Epoch: 6| Step: 4
Training loss: 1.9766394558728164
Validation loss: 2.4548800431748887

Epoch: 6| Step: 5
Training loss: 2.7846624463632117
Validation loss: 2.4614777768375373

Epoch: 6| Step: 6
Training loss: 2.6298614172449417
Validation loss: 2.461582266180999

Epoch: 6| Step: 7
Training loss: 2.7228245512118714
Validation loss: 2.4569483085244284

Epoch: 6| Step: 8
Training loss: 2.1904951027138653
Validation loss: 2.453815073404561

Epoch: 6| Step: 9
Training loss: 2.2326175206811274
Validation loss: 2.4484502580403773

Epoch: 6| Step: 10
Training loss: 1.726994041953884
Validation loss: 2.4561064351226016

Epoch: 6| Step: 11
Training loss: 2.293761757968629
Validation loss: 2.4786469936970392

Epoch: 6| Step: 12
Training loss: 1.6815313819908313
Validation loss: 2.507747209340693

Epoch: 6| Step: 13
Training loss: 1.969505528392136
Validation loss: 2.535294550918874

Epoch: 249| Step: 0
Training loss: 2.469512435421448
Validation loss: 2.559014956602006

Epoch: 6| Step: 1
Training loss: 1.6606179706049988
Validation loss: 2.5880702515832765

Epoch: 6| Step: 2
Training loss: 2.4127274559200202
Validation loss: 2.6048930651810585

Epoch: 6| Step: 3
Training loss: 2.162782807131866
Validation loss: 2.588733711446731

Epoch: 6| Step: 4
Training loss: 1.7314121955333672
Validation loss: 2.5133312537101813

Epoch: 6| Step: 5
Training loss: 2.505469537918638
Validation loss: 2.4806186715015865

Epoch: 6| Step: 6
Training loss: 2.165836860014904
Validation loss: 2.4779176775807206

Epoch: 6| Step: 7
Training loss: 2.3370796396824
Validation loss: 2.483977131358681

Epoch: 6| Step: 8
Training loss: 2.145971151821068
Validation loss: 2.4793421611748783

Epoch: 6| Step: 9
Training loss: 2.345358029914125
Validation loss: 2.507382675729025

Epoch: 6| Step: 10
Training loss: 2.509533918201303
Validation loss: 2.5081935599832135

Epoch: 6| Step: 11
Training loss: 1.9535038695032223
Validation loss: 2.4992826032367668

Epoch: 6| Step: 12
Training loss: 2.206419409280488
Validation loss: 2.4867474937328646

Epoch: 6| Step: 13
Training loss: 2.512233746593253
Validation loss: 2.4785529459610016

Epoch: 250| Step: 0
Training loss: 2.1496790402391937
Validation loss: 2.454723062580953

Epoch: 6| Step: 1
Training loss: 1.963718099450348
Validation loss: 2.4366554540962526

Epoch: 6| Step: 2
Training loss: 1.9057999376652275
Validation loss: 2.4362195429881726

Epoch: 6| Step: 3
Training loss: 2.3621016151347445
Validation loss: 2.4522019690155807

Epoch: 6| Step: 4
Training loss: 2.0388510875795265
Validation loss: 2.4583754170025705

Epoch: 6| Step: 5
Training loss: 2.260757057355255
Validation loss: 2.453087582710078

Epoch: 6| Step: 6
Training loss: 1.907224062338351
Validation loss: 2.445351129713122

Epoch: 6| Step: 7
Training loss: 2.237023337967625
Validation loss: 2.4241914074900275

Epoch: 6| Step: 8
Training loss: 2.382790086984754
Validation loss: 2.4153559843007084

Epoch: 6| Step: 9
Training loss: 2.039073841750366
Validation loss: 2.4183742111608333

Epoch: 6| Step: 10
Training loss: 2.415734363365157
Validation loss: 2.4340817326601596

Epoch: 6| Step: 11
Training loss: 2.0707133354967207
Validation loss: 2.4390268069135748

Epoch: 6| Step: 12
Training loss: 2.010445023041871
Validation loss: 2.438342941256615

Epoch: 6| Step: 13
Training loss: 2.6663938819918074
Validation loss: 2.4734866631206063

Epoch: 251| Step: 0
Training loss: 1.9609691115791148
Validation loss: 2.459633488786439

Epoch: 6| Step: 1
Training loss: 1.9472160983507063
Validation loss: 2.4700545590440437

Epoch: 6| Step: 2
Training loss: 1.7327233775741986
Validation loss: 2.460791074814602

Epoch: 6| Step: 3
Training loss: 1.7796840141871797
Validation loss: 2.4389670390096287

Epoch: 6| Step: 4
Training loss: 2.3014229104778448
Validation loss: 2.441339639128263

Epoch: 6| Step: 5
Training loss: 1.8250785288180176
Validation loss: 2.4300323601387728

Epoch: 6| Step: 6
Training loss: 2.094015303926553
Validation loss: 2.4335842690376728

Epoch: 6| Step: 7
Training loss: 1.7867122354793172
Validation loss: 2.425241030880555

Epoch: 6| Step: 8
Training loss: 1.831080924291196
Validation loss: 2.4360822693779336

Epoch: 6| Step: 9
Training loss: 2.1811367672273727
Validation loss: 2.4315043201371926

Epoch: 6| Step: 10
Training loss: 1.8763740591044675
Validation loss: 2.427832991034297

Epoch: 6| Step: 11
Training loss: 2.890655517417033
Validation loss: 2.420734102123219

Epoch: 6| Step: 12
Training loss: 2.629276515965182
Validation loss: 2.4301504751737655

Epoch: 6| Step: 13
Training loss: 2.3422066248137745
Validation loss: 2.441601964181542

Epoch: 252| Step: 0
Training loss: 2.39875498108697
Validation loss: 2.430148603725769

Epoch: 6| Step: 1
Training loss: 2.231063202376949
Validation loss: 2.4504947239664623

Epoch: 6| Step: 2
Training loss: 1.7773000858518708
Validation loss: 2.441544386633056

Epoch: 6| Step: 3
Training loss: 1.8173446364290327
Validation loss: 2.450124875059524

Epoch: 6| Step: 4
Training loss: 2.0638605889692947
Validation loss: 2.464633857632809

Epoch: 6| Step: 5
Training loss: 2.0534278866849522
Validation loss: 2.4562082002313352

Epoch: 6| Step: 6
Training loss: 1.7619218730341097
Validation loss: 2.4629650778863357

Epoch: 6| Step: 7
Training loss: 1.5979081307406597
Validation loss: 2.4489138012130387

Epoch: 6| Step: 8
Training loss: 3.0141053793444197
Validation loss: 2.4583746724296796

Epoch: 6| Step: 9
Training loss: 1.9768528178511533
Validation loss: 2.4466560800907367

Epoch: 6| Step: 10
Training loss: 2.0324152025314506
Validation loss: 2.440799344928148

Epoch: 6| Step: 11
Training loss: 1.564647191044434
Validation loss: 2.4448129064360318

Epoch: 6| Step: 12
Training loss: 2.2259732721580052
Validation loss: 2.441581325102824

Epoch: 6| Step: 13
Training loss: 2.0727685718893714
Validation loss: 2.4326996918328896

Epoch: 253| Step: 0
Training loss: 2.73417096057924
Validation loss: 2.4240984789584425

Epoch: 6| Step: 1
Training loss: 1.874521448736632
Validation loss: 2.43470182639024

Epoch: 6| Step: 2
Training loss: 2.0379693034951547
Validation loss: 2.447557059959261

Epoch: 6| Step: 3
Training loss: 1.7507442526629702
Validation loss: 2.4483104681416337

Epoch: 6| Step: 4
Training loss: 1.374323374987328
Validation loss: 2.4632924698409493

Epoch: 6| Step: 5
Training loss: 2.4907976538190546
Validation loss: 2.4552357271344825

Epoch: 6| Step: 6
Training loss: 2.011422915141092
Validation loss: 2.459043947243165

Epoch: 6| Step: 7
Training loss: 2.4712524285929223
Validation loss: 2.432322890577149

Epoch: 6| Step: 8
Training loss: 1.4594504392023442
Validation loss: 2.4331992549286405

Epoch: 6| Step: 9
Training loss: 2.123254283329829
Validation loss: 2.443012754790489

Epoch: 6| Step: 10
Training loss: 1.6987941869247785
Validation loss: 2.4419590593472975

Epoch: 6| Step: 11
Training loss: 2.423102480016499
Validation loss: 2.450905717670067

Epoch: 6| Step: 12
Training loss: 1.979369812294004
Validation loss: 2.4230746417800066

Epoch: 6| Step: 13
Training loss: 2.458099763625759
Validation loss: 2.4272516746680535

Epoch: 254| Step: 0
Training loss: 1.7667521701970528
Validation loss: 2.450121268878451

Epoch: 6| Step: 1
Training loss: 1.9509187979094305
Validation loss: 2.4500968703840815

Epoch: 6| Step: 2
Training loss: 1.6012899027251686
Validation loss: 2.4312146199095754

Epoch: 6| Step: 3
Training loss: 2.0669093538145273
Validation loss: 2.4396538002262407

Epoch: 6| Step: 4
Training loss: 2.0357237626813607
Validation loss: 2.4274191622505223

Epoch: 6| Step: 5
Training loss: 1.8702207053594961
Validation loss: 2.41330613241071

Epoch: 6| Step: 6
Training loss: 2.288089271897912
Validation loss: 2.419264652594834

Epoch: 6| Step: 7
Training loss: 1.8932884308478204
Validation loss: 2.397234087657264

Epoch: 6| Step: 8
Training loss: 1.8442950978514756
Validation loss: 2.407446587317976

Epoch: 6| Step: 9
Training loss: 2.7253983862603586
Validation loss: 2.404138475759922

Epoch: 6| Step: 10
Training loss: 2.13269456250874
Validation loss: 2.429174378465386

Epoch: 6| Step: 11
Training loss: 1.9651994326386661
Validation loss: 2.420442661617233

Epoch: 6| Step: 12
Training loss: 2.207453918494475
Validation loss: 2.412124052514141

Epoch: 6| Step: 13
Training loss: 2.352171454680882
Validation loss: 2.436968215051544

Epoch: 255| Step: 0
Training loss: 1.8222590831708674
Validation loss: 2.4249418224836234

Epoch: 6| Step: 1
Training loss: 2.0945642510688156
Validation loss: 2.429964564988522

Epoch: 6| Step: 2
Training loss: 1.1578454016825337
Validation loss: 2.4296709407045194

Epoch: 6| Step: 3
Training loss: 1.814168753785577
Validation loss: 2.447688950677481

Epoch: 6| Step: 4
Training loss: 1.83009922988431
Validation loss: 2.4482097658844664

Epoch: 6| Step: 5
Training loss: 2.2916975770657446
Validation loss: 2.458864442139992

Epoch: 6| Step: 6
Training loss: 2.4746693014522756
Validation loss: 2.469617994001747

Epoch: 6| Step: 7
Training loss: 2.0163710049043417
Validation loss: 2.4658460650037908

Epoch: 6| Step: 8
Training loss: 2.1112970708068324
Validation loss: 2.435193871685285

Epoch: 6| Step: 9
Training loss: 1.90975074130255
Validation loss: 2.4234299218889124

Epoch: 6| Step: 10
Training loss: 2.2956629039648084
Validation loss: 2.4195153805233693

Epoch: 6| Step: 11
Training loss: 2.4448183187996766
Validation loss: 2.4258999630263602

Epoch: 6| Step: 12
Training loss: 1.6363790154938533
Validation loss: 2.4280410092615603

Epoch: 6| Step: 13
Training loss: 2.244432554853483
Validation loss: 2.433103154407524

Epoch: 256| Step: 0
Training loss: 2.076820480361195
Validation loss: 2.475601467883103

Epoch: 6| Step: 1
Training loss: 1.1300293506760266
Validation loss: 2.5296437524696813

Epoch: 6| Step: 2
Training loss: 1.6932473679120366
Validation loss: 2.5837298392295263

Epoch: 6| Step: 3
Training loss: 1.7088342567996213
Validation loss: 2.5867642283565178

Epoch: 6| Step: 4
Training loss: 2.414367853993963
Validation loss: 2.587046333297473

Epoch: 6| Step: 5
Training loss: 1.8630141860577425
Validation loss: 2.5507772820936574

Epoch: 6| Step: 6
Training loss: 2.165424125129559
Validation loss: 2.5190810524802285

Epoch: 6| Step: 7
Training loss: 2.4099346535082
Validation loss: 2.4953573146017725

Epoch: 6| Step: 8
Training loss: 1.7699795254099646
Validation loss: 2.457151347457975

Epoch: 6| Step: 9
Training loss: 2.0516643838794857
Validation loss: 2.4628507267030564

Epoch: 6| Step: 10
Training loss: 1.7012813983965591
Validation loss: 2.454859268750863

Epoch: 6| Step: 11
Training loss: 2.7216852938810217
Validation loss: 2.4846695358849398

Epoch: 6| Step: 12
Training loss: 1.409041622004653
Validation loss: 2.4681494883185597

Epoch: 6| Step: 13
Training loss: 2.469430467527656
Validation loss: 2.459740957552011

Epoch: 257| Step: 0
Training loss: 2.1312431178722964
Validation loss: 2.443312258970375

Epoch: 6| Step: 1
Training loss: 1.8581610812197542
Validation loss: 2.4586100317436044

Epoch: 6| Step: 2
Training loss: 1.9700623028967692
Validation loss: 2.4450868551405502

Epoch: 6| Step: 3
Training loss: 2.2387613843397296
Validation loss: 2.422761280856223

Epoch: 6| Step: 4
Training loss: 1.5971460250517937
Validation loss: 2.437494495134261

Epoch: 6| Step: 5
Training loss: 2.127026993630904
Validation loss: 2.4287916186456506

Epoch: 6| Step: 6
Training loss: 1.9505400985628787
Validation loss: 2.428145114633081

Epoch: 6| Step: 7
Training loss: 1.571156744545297
Validation loss: 2.4468923303221977

Epoch: 6| Step: 8
Training loss: 1.4959981305115795
Validation loss: 2.462749583237621

Epoch: 6| Step: 9
Training loss: 2.250859202472031
Validation loss: 2.481368905090677

Epoch: 6| Step: 10
Training loss: 2.525950217148335
Validation loss: 2.443444207269042

Epoch: 6| Step: 11
Training loss: 1.5052688568865202
Validation loss: 2.437420709381034

Epoch: 6| Step: 12
Training loss: 1.8670249453217966
Validation loss: 2.433016859945494

Epoch: 6| Step: 13
Training loss: 1.75876093391322
Validation loss: 2.420789186110665

Epoch: 258| Step: 0
Training loss: 1.790784515146225
Validation loss: 2.433374429030678

Epoch: 6| Step: 1
Training loss: 2.2933884712547563
Validation loss: 2.433437977320697

Epoch: 6| Step: 2
Training loss: 1.8649095502095125
Validation loss: 2.455923033100414

Epoch: 6| Step: 3
Training loss: 1.4200044841426915
Validation loss: 2.460236149450712

Epoch: 6| Step: 4
Training loss: 2.4212019446571413
Validation loss: 2.460098289667443

Epoch: 6| Step: 5
Training loss: 1.529674653884829
Validation loss: 2.4577532425013264

Epoch: 6| Step: 6
Training loss: 2.0871634434745667
Validation loss: 2.4593169836030118

Epoch: 6| Step: 7
Training loss: 1.9884886268135091
Validation loss: 2.455989640925026

Epoch: 6| Step: 8
Training loss: 1.6968302459154154
Validation loss: 2.4650465026072026

Epoch: 6| Step: 9
Training loss: 1.3016572585765163
Validation loss: 2.464207595886643

Epoch: 6| Step: 10
Training loss: 1.6806503020481858
Validation loss: 2.44055287924993

Epoch: 6| Step: 11
Training loss: 2.458930756557747
Validation loss: 2.445720478301087

Epoch: 6| Step: 12
Training loss: 2.045089525347732
Validation loss: 2.457650868030836

Epoch: 6| Step: 13
Training loss: 2.178277766426945
Validation loss: 2.432070359713474

Epoch: 259| Step: 0
Training loss: 1.9386871761569062
Validation loss: 2.43857336062657

Epoch: 6| Step: 1
Training loss: 1.8545915638279566
Validation loss: 2.4323517633699105

Epoch: 6| Step: 2
Training loss: 2.084985637295147
Validation loss: 2.4380521093793543

Epoch: 6| Step: 3
Training loss: 1.5687715931656327
Validation loss: 2.4362421253015016

Epoch: 6| Step: 4
Training loss: 2.4383913024491912
Validation loss: 2.434277690823578

Epoch: 6| Step: 5
Training loss: 1.7066483755671311
Validation loss: 2.44145594707483

Epoch: 6| Step: 6
Training loss: 1.5165290888893328
Validation loss: 2.4641188827867033

Epoch: 6| Step: 7
Training loss: 2.0282821100684396
Validation loss: 2.4760548444062462

Epoch: 6| Step: 8
Training loss: 1.649993957161675
Validation loss: 2.5017794234275192

Epoch: 6| Step: 9
Training loss: 1.5231952963766435
Validation loss: 2.516207522150636

Epoch: 6| Step: 10
Training loss: 2.029606315510344
Validation loss: 2.5053391776227802

Epoch: 6| Step: 11
Training loss: 1.709910742231572
Validation loss: 2.4670407946744315

Epoch: 6| Step: 12
Training loss: 1.9546332677305402
Validation loss: 2.4413985267434963

Epoch: 6| Step: 13
Training loss: 2.4494419513340833
Validation loss: 2.414548489469276

Epoch: 260| Step: 0
Training loss: 1.9993756034828698
Validation loss: 2.4161381527240757

Epoch: 6| Step: 1
Training loss: 2.2547677705874247
Validation loss: 2.417922184626797

Epoch: 6| Step: 2
Training loss: 1.7709850545475494
Validation loss: 2.4199230514521255

Epoch: 6| Step: 3
Training loss: 1.7288279450581228
Validation loss: 2.4063253328324894

Epoch: 6| Step: 4
Training loss: 1.886179465864134
Validation loss: 2.409485466648548

Epoch: 6| Step: 5
Training loss: 2.028364038707783
Validation loss: 2.402835304039022

Epoch: 6| Step: 6
Training loss: 2.3833003310828555
Validation loss: 2.4256661002538418

Epoch: 6| Step: 7
Training loss: 1.5867282793894284
Validation loss: 2.426520871332783

Epoch: 6| Step: 8
Training loss: 2.0239140601100587
Validation loss: 2.438520088175145

Epoch: 6| Step: 9
Training loss: 1.0687814049819224
Validation loss: 2.444602925474428

Epoch: 6| Step: 10
Training loss: 1.4907530435713068
Validation loss: 2.45857677398005

Epoch: 6| Step: 11
Training loss: 1.997423837424813
Validation loss: 2.4907939125112475

Epoch: 6| Step: 12
Training loss: 2.0474358874892533
Validation loss: 2.4758912127726243

Epoch: 6| Step: 13
Training loss: 1.7444885522013598
Validation loss: 2.468286108024252

Epoch: 261| Step: 0
Training loss: 1.5652044161544412
Validation loss: 2.4399761993283615

Epoch: 6| Step: 1
Training loss: 1.5291196055364304
Validation loss: 2.4409331026732586

Epoch: 6| Step: 2
Training loss: 2.0468181573094855
Validation loss: 2.4099011346265056

Epoch: 6| Step: 3
Training loss: 2.5015744020177704
Validation loss: 2.415470304177417

Epoch: 6| Step: 4
Training loss: 1.8977173746314997
Validation loss: 2.4256796621140952

Epoch: 6| Step: 5
Training loss: 1.56463225788098
Validation loss: 2.4495600969695026

Epoch: 6| Step: 6
Training loss: 1.9470714292428335
Validation loss: 2.462523118818343

Epoch: 6| Step: 7
Training loss: 1.9630617589033716
Validation loss: 2.466743202928875

Epoch: 6| Step: 8
Training loss: 1.9572946215152685
Validation loss: 2.4627059226196715

Epoch: 6| Step: 9
Training loss: 1.7621439147960183
Validation loss: 2.447233689612305

Epoch: 6| Step: 10
Training loss: 1.9493034512572993
Validation loss: 2.4305667394877855

Epoch: 6| Step: 11
Training loss: 2.066865404889421
Validation loss: 2.416818439680979

Epoch: 6| Step: 12
Training loss: 1.6233326353950228
Validation loss: 2.406151892466966

Epoch: 6| Step: 13
Training loss: 1.7248128595980392
Validation loss: 2.3981466445323014

Epoch: 262| Step: 0
Training loss: 2.1854830571488577
Validation loss: 2.410076683652217

Epoch: 6| Step: 1
Training loss: 1.483690847038827
Validation loss: 2.404120734915519

Epoch: 6| Step: 2
Training loss: 1.9550998316883146
Validation loss: 2.3688358629966935

Epoch: 6| Step: 3
Training loss: 2.081543369637687
Validation loss: 2.362952592994729

Epoch: 6| Step: 4
Training loss: 1.923427110112481
Validation loss: 2.366347279792943

Epoch: 6| Step: 5
Training loss: 2.2015488850894775
Validation loss: 2.380337443435468

Epoch: 6| Step: 6
Training loss: 1.5605719305325887
Validation loss: 2.410386000816526

Epoch: 6| Step: 7
Training loss: 1.6189670078528065
Validation loss: 2.4337251270531883

Epoch: 6| Step: 8
Training loss: 1.7122486960358347
Validation loss: 2.479015226453277

Epoch: 6| Step: 9
Training loss: 1.8033313362101122
Validation loss: 2.468146539477679

Epoch: 6| Step: 10
Training loss: 1.9410943561753524
Validation loss: 2.4428337329631

Epoch: 6| Step: 11
Training loss: 1.655387869961375
Validation loss: 2.426586974074527

Epoch: 6| Step: 12
Training loss: 1.661786954741741
Validation loss: 2.3948536282657322

Epoch: 6| Step: 13
Training loss: 1.721373965274067
Validation loss: 2.394630836225724

Epoch: 263| Step: 0
Training loss: 1.4355705414981563
Validation loss: 2.427649368121683

Epoch: 6| Step: 1
Training loss: 1.836401568260512
Validation loss: 2.4295803479440434

Epoch: 6| Step: 2
Training loss: 1.4000071235884222
Validation loss: 2.4252346176506525

Epoch: 6| Step: 3
Training loss: 2.0733691413379436
Validation loss: 2.4151607184047825

Epoch: 6| Step: 4
Training loss: 1.713429139064863
Validation loss: 2.421081175759887

Epoch: 6| Step: 5
Training loss: 1.5531544243157165
Validation loss: 2.481908073763021

Epoch: 6| Step: 6
Training loss: 1.9211854395446282
Validation loss: 2.5416452745505347

Epoch: 6| Step: 7
Training loss: 1.5449641592072172
Validation loss: 2.5523169954041465

Epoch: 6| Step: 8
Training loss: 2.3899204986309925
Validation loss: 2.5635521372228314

Epoch: 6| Step: 9
Training loss: 1.6368324404176318
Validation loss: 2.4579193781040396

Epoch: 6| Step: 10
Training loss: 2.048966598558717
Validation loss: 2.3998394013836286

Epoch: 6| Step: 11
Training loss: 2.5018591643534367
Validation loss: 2.414100682511885

Epoch: 6| Step: 12
Training loss: 2.227386536282587
Validation loss: 2.4029638605730903

Epoch: 6| Step: 13
Training loss: 2.2448671922716277
Validation loss: 2.4241494265956183

Epoch: 264| Step: 0
Training loss: 1.3262955575609305
Validation loss: 2.412244176267705

Epoch: 6| Step: 1
Training loss: 1.7736040616905633
Validation loss: 2.4498337560349848

Epoch: 6| Step: 2
Training loss: 1.291595744165029
Validation loss: 2.479083965601116

Epoch: 6| Step: 3
Training loss: 2.227419397199483
Validation loss: 2.4799877415763274

Epoch: 6| Step: 4
Training loss: 1.705637836680572
Validation loss: 2.5090793904070394

Epoch: 6| Step: 5
Training loss: 1.5479419766081532
Validation loss: 2.475558971130249

Epoch: 6| Step: 6
Training loss: 1.7973030575603943
Validation loss: 2.4049843564088733

Epoch: 6| Step: 7
Training loss: 1.8671550668110204
Validation loss: 2.393092811512896

Epoch: 6| Step: 8
Training loss: 1.9311978996681036
Validation loss: 2.388042357037522

Epoch: 6| Step: 9
Training loss: 2.548210495989795
Validation loss: 2.3977852066916743

Epoch: 6| Step: 10
Training loss: 1.7356237091839901
Validation loss: 2.385339028423672

Epoch: 6| Step: 11
Training loss: 1.947653101533318
Validation loss: 2.392884985319264

Epoch: 6| Step: 12
Training loss: 1.487828143173184
Validation loss: 2.40750163883145

Epoch: 6| Step: 13
Training loss: 2.6387244613907854
Validation loss: 2.415884986995926

Epoch: 265| Step: 0
Training loss: 1.6396648685615816
Validation loss: 2.428085447357656

Epoch: 6| Step: 1
Training loss: 1.721001831869406
Validation loss: 2.4184259419163134

Epoch: 6| Step: 2
Training loss: 2.171730969819567
Validation loss: 2.425130480364151

Epoch: 6| Step: 3
Training loss: 1.8782243343749003
Validation loss: 2.4133619085751628

Epoch: 6| Step: 4
Training loss: 1.6201585393023625
Validation loss: 2.415720919714055

Epoch: 6| Step: 5
Training loss: 1.9191178804801092
Validation loss: 2.4015657291082007

Epoch: 6| Step: 6
Training loss: 1.6490139066481058
Validation loss: 2.406605533776953

Epoch: 6| Step: 7
Training loss: 1.7526114597329414
Validation loss: 2.403218612555521

Epoch: 6| Step: 8
Training loss: 1.6613628714789432
Validation loss: 2.394472003122105

Epoch: 6| Step: 9
Training loss: 1.8281664721357596
Validation loss: 2.3942168542494953

Epoch: 6| Step: 10
Training loss: 1.5261572402396928
Validation loss: 2.3839967745744124

Epoch: 6| Step: 11
Training loss: 1.621075954109776
Validation loss: 2.3928327495336412

Epoch: 6| Step: 12
Training loss: 2.0145237006191925
Validation loss: 2.3842185899058634

Epoch: 6| Step: 13
Training loss: 1.6681194014042606
Validation loss: 2.3792229356126744

Epoch: 266| Step: 0
Training loss: 1.6215719597746932
Validation loss: 2.3693348967811168

Epoch: 6| Step: 1
Training loss: 1.210917811079856
Validation loss: 2.3753469814938684

Epoch: 6| Step: 2
Training loss: 1.4595720570606294
Validation loss: 2.3711027607531427

Epoch: 6| Step: 3
Training loss: 2.430987436586129
Validation loss: 2.3793838414642723

Epoch: 6| Step: 4
Training loss: 2.04288880755248
Validation loss: 2.4203803280779317

Epoch: 6| Step: 5
Training loss: 2.0176635605927706
Validation loss: 2.444200935319747

Epoch: 6| Step: 6
Training loss: 1.5985613732987798
Validation loss: 2.464797151787254

Epoch: 6| Step: 7
Training loss: 1.6764749722772836
Validation loss: 2.446040902893803

Epoch: 6| Step: 8
Training loss: 1.6290927844193506
Validation loss: 2.425767946575872

Epoch: 6| Step: 9
Training loss: 1.6977688621671922
Validation loss: 2.420047331048572

Epoch: 6| Step: 10
Training loss: 1.6159633112557306
Validation loss: 2.4031791231689725

Epoch: 6| Step: 11
Training loss: 1.9037100332752481
Validation loss: 2.394924754119493

Epoch: 6| Step: 12
Training loss: 1.93465275904106
Validation loss: 2.3911490217581486

Epoch: 6| Step: 13
Training loss: 1.4136808944798103
Validation loss: 2.3988978040520794

Epoch: 267| Step: 0
Training loss: 1.918170926068472
Validation loss: 2.404221132058564

Epoch: 6| Step: 1
Training loss: 1.7913573094107296
Validation loss: 2.423725301270657

Epoch: 6| Step: 2
Training loss: 1.7651920294109082
Validation loss: 2.416738738900774

Epoch: 6| Step: 3
Training loss: 2.1418524793871847
Validation loss: 2.4291495954441764

Epoch: 6| Step: 4
Training loss: 1.5423567318652576
Validation loss: 2.410997273892275

Epoch: 6| Step: 5
Training loss: 1.3971613170241202
Validation loss: 2.399108526698973

Epoch: 6| Step: 6
Training loss: 1.635714785218237
Validation loss: 2.4014266421754806

Epoch: 6| Step: 7
Training loss: 1.5604917972475003
Validation loss: 2.4034532504888335

Epoch: 6| Step: 8
Training loss: 1.4115864694387357
Validation loss: 2.3942373651767976

Epoch: 6| Step: 9
Training loss: 1.7010869422146373
Validation loss: 2.396839747619077

Epoch: 6| Step: 10
Training loss: 1.4849324835896418
Validation loss: 2.4099571715011106

Epoch: 6| Step: 11
Training loss: 1.7536230729516893
Validation loss: 2.398372733579891

Epoch: 6| Step: 12
Training loss: 1.6550711269019136
Validation loss: 2.397513179378198

Epoch: 6| Step: 13
Training loss: 2.444563973519589
Validation loss: 2.402519446283582

Epoch: 268| Step: 0
Training loss: 1.9511217754297532
Validation loss: 2.4041142824066752

Epoch: 6| Step: 1
Training loss: 1.7534070228398597
Validation loss: 2.3964357233179063

Epoch: 6| Step: 2
Training loss: 1.3618568477322461
Validation loss: 2.4009209203162785

Epoch: 6| Step: 3
Training loss: 1.7394582128546745
Validation loss: 2.406199046803247

Epoch: 6| Step: 4
Training loss: 1.9027324177640506
Validation loss: 2.433208695246974

Epoch: 6| Step: 5
Training loss: 1.5596328369295938
Validation loss: 2.4155524835695537

Epoch: 6| Step: 6
Training loss: 1.3886447479989328
Validation loss: 2.41149346064625

Epoch: 6| Step: 7
Training loss: 1.848989767604344
Validation loss: 2.4180887901432877

Epoch: 6| Step: 8
Training loss: 1.4407299078024056
Validation loss: 2.448705901974741

Epoch: 6| Step: 9
Training loss: 1.650922159228011
Validation loss: 2.4700201434673765

Epoch: 6| Step: 10
Training loss: 2.0573738435838984
Validation loss: 2.506530427867507

Epoch: 6| Step: 11
Training loss: 1.6572764113239782
Validation loss: 2.495884011216146

Epoch: 6| Step: 12
Training loss: 1.854909069577964
Validation loss: 2.4557221224789334

Epoch: 6| Step: 13
Training loss: 1.7211863502806946
Validation loss: 2.4264684246130286

Epoch: 269| Step: 0
Training loss: 1.6513441592911293
Validation loss: 2.4057598437814938

Epoch: 6| Step: 1
Training loss: 1.5291624046633554
Validation loss: 2.4011656613683243

Epoch: 6| Step: 2
Training loss: 1.8270781038123192
Validation loss: 2.4175869180031366

Epoch: 6| Step: 3
Training loss: 2.1621431177499097
Validation loss: 2.4102520539640957

Epoch: 6| Step: 4
Training loss: 1.3367504747060657
Validation loss: 2.4096953176855664

Epoch: 6| Step: 5
Training loss: 1.6398845636632822
Validation loss: 2.3928701244421653

Epoch: 6| Step: 6
Training loss: 1.670552452558697
Validation loss: 2.414334228888661

Epoch: 6| Step: 7
Training loss: 1.1127231202711052
Validation loss: 2.42803859981674

Epoch: 6| Step: 8
Training loss: 1.821011650496475
Validation loss: 2.4293250531173145

Epoch: 6| Step: 9
Training loss: 1.5371051870674366
Validation loss: 2.423298510886221

Epoch: 6| Step: 10
Training loss: 1.9857278852790983
Validation loss: 2.401544931165353

Epoch: 6| Step: 11
Training loss: 1.839498370042075
Validation loss: 2.4257446347595306

Epoch: 6| Step: 12
Training loss: 1.359026984906159
Validation loss: 2.422189493761956

Epoch: 6| Step: 13
Training loss: 1.98037274069628
Validation loss: 2.440480665020083

Epoch: 270| Step: 0
Training loss: 1.8911280947852873
Validation loss: 2.433384785239538

Epoch: 6| Step: 1
Training loss: 1.6366020652674986
Validation loss: 2.4304886941068458

Epoch: 6| Step: 2
Training loss: 1.3987615625416627
Validation loss: 2.41432047587647

Epoch: 6| Step: 3
Training loss: 1.9310478326848093
Validation loss: 2.4092905325894836

Epoch: 6| Step: 4
Training loss: 1.8782007871751067
Validation loss: 2.3971315584080783

Epoch: 6| Step: 5
Training loss: 1.1693161557029454
Validation loss: 2.4073522211673013

Epoch: 6| Step: 6
Training loss: 2.065195576271049
Validation loss: 2.4221807884223567

Epoch: 6| Step: 7
Training loss: 1.7110888270513773
Validation loss: 2.436623419102114

Epoch: 6| Step: 8
Training loss: 1.9527862255021635
Validation loss: 2.4044017973279086

Epoch: 6| Step: 9
Training loss: 1.5308304036624114
Validation loss: 2.4051014396790436

Epoch: 6| Step: 10
Training loss: 1.9125187467765774
Validation loss: 2.4106147279379906

Epoch: 6| Step: 11
Training loss: 1.6545633328888572
Validation loss: 2.4352250559279685

Epoch: 6| Step: 12
Training loss: 1.177802544134485
Validation loss: 2.457918181768411

Epoch: 6| Step: 13
Training loss: 1.2636207440510552
Validation loss: 2.469483304673556

Epoch: 271| Step: 0
Training loss: 1.4657529730326668
Validation loss: 2.468022143794076

Epoch: 6| Step: 1
Training loss: 1.4677251933500972
Validation loss: 2.45510151123021

Epoch: 6| Step: 2
Training loss: 1.889599040960477
Validation loss: 2.438175706204563

Epoch: 6| Step: 3
Training loss: 1.9308016877043124
Validation loss: 2.452456968900732

Epoch: 6| Step: 4
Training loss: 1.9903375750468644
Validation loss: 2.4274373918317744

Epoch: 6| Step: 5
Training loss: 1.789867902815062
Validation loss: 2.391801145192313

Epoch: 6| Step: 6
Training loss: 2.048728045845754
Validation loss: 2.394549257813992

Epoch: 6| Step: 7
Training loss: 0.9650760633504817
Validation loss: 2.3886251924883175

Epoch: 6| Step: 8
Training loss: 1.6727757389412745
Validation loss: 2.391137216422528

Epoch: 6| Step: 9
Training loss: 1.8463853009337987
Validation loss: 2.3782728406584197

Epoch: 6| Step: 10
Training loss: 1.372470870551388
Validation loss: 2.378659608822344

Epoch: 6| Step: 11
Training loss: 1.1456101055602608
Validation loss: 2.377543390950194

Epoch: 6| Step: 12
Training loss: 2.0564164114635015
Validation loss: 2.375728550484163

Epoch: 6| Step: 13
Training loss: 1.6145462360016996
Validation loss: 2.3888465099036806

Epoch: 272| Step: 0
Training loss: 1.636611243019798
Validation loss: 2.425770274786045

Epoch: 6| Step: 1
Training loss: 1.5170148002792714
Validation loss: 2.425912587806288

Epoch: 6| Step: 2
Training loss: 1.9116350624090532
Validation loss: 2.4792595591987987

Epoch: 6| Step: 3
Training loss: 1.8087838322257281
Validation loss: 2.481800224091344

Epoch: 6| Step: 4
Training loss: 2.1368336759969204
Validation loss: 2.504240579275123

Epoch: 6| Step: 5
Training loss: 1.8420387991050697
Validation loss: 2.4845500927426416

Epoch: 6| Step: 6
Training loss: 1.3068290540371088
Validation loss: 2.455753049176584

Epoch: 6| Step: 7
Training loss: 1.1444419852068834
Validation loss: 2.445572817052287

Epoch: 6| Step: 8
Training loss: 1.3360410505172726
Validation loss: 2.4437655886058027

Epoch: 6| Step: 9
Training loss: 1.5389707896216205
Validation loss: 2.442284054432864

Epoch: 6| Step: 10
Training loss: 1.4242602452664113
Validation loss: 2.424750587078872

Epoch: 6| Step: 11
Training loss: 1.783939005001481
Validation loss: 2.4267907594553892

Epoch: 6| Step: 12
Training loss: 1.8359961317723898
Validation loss: 2.408074245602601

Epoch: 6| Step: 13
Training loss: 1.7657629313648264
Validation loss: 2.4770055599507685

Epoch: 273| Step: 0
Training loss: 1.6205781783207993
Validation loss: 2.5348157663053748

Epoch: 6| Step: 1
Training loss: 2.301144116321181
Validation loss: 2.6000244379275514

Epoch: 6| Step: 2
Training loss: 1.5468922623721144
Validation loss: 2.562497003665096

Epoch: 6| Step: 3
Training loss: 2.328325403792091
Validation loss: 2.505845877753375

Epoch: 6| Step: 4
Training loss: 1.890271177365211
Validation loss: 2.4343360884394682

Epoch: 6| Step: 5
Training loss: 1.8274821267773855
Validation loss: 2.3928147288015733

Epoch: 6| Step: 6
Training loss: 1.9116384921981235
Validation loss: 2.4476756600156278

Epoch: 6| Step: 7
Training loss: 2.073283816336069
Validation loss: 2.469244917096864

Epoch: 6| Step: 8
Training loss: 1.8836488884189428
Validation loss: 2.478758929309885

Epoch: 6| Step: 9
Training loss: 1.8429737073209875
Validation loss: 2.466373725226147

Epoch: 6| Step: 10
Training loss: 1.7144259071927437
Validation loss: 2.38683467026482

Epoch: 6| Step: 11
Training loss: 1.163869854648259
Validation loss: 2.363286017604037

Epoch: 6| Step: 12
Training loss: 1.5575346826209484
Validation loss: 2.376821283227433

Epoch: 6| Step: 13
Training loss: 1.6198207774924636
Validation loss: 2.4116388684478154

Epoch: 274| Step: 0
Training loss: 1.782549601502754
Validation loss: 2.4283823333239436

Epoch: 6| Step: 1
Training loss: 1.8814018314975938
Validation loss: 2.480264817738933

Epoch: 6| Step: 2
Training loss: 2.1120005903243193
Validation loss: 2.5091790510187706

Epoch: 6| Step: 3
Training loss: 1.7312173365186756
Validation loss: 2.452634619869004

Epoch: 6| Step: 4
Training loss: 1.4488365306800683
Validation loss: 2.445026991069206

Epoch: 6| Step: 5
Training loss: 1.7308324427350612
Validation loss: 2.4189977898553643

Epoch: 6| Step: 6
Training loss: 1.5996210752252578
Validation loss: 2.414644727522997

Epoch: 6| Step: 7
Training loss: 1.1245773899184672
Validation loss: 2.4298934772717544

Epoch: 6| Step: 8
Training loss: 1.3666561729136826
Validation loss: 2.433669997716358

Epoch: 6| Step: 9
Training loss: 1.4952658810418749
Validation loss: 2.442905598487971

Epoch: 6| Step: 10
Training loss: 1.2839489863770017
Validation loss: 2.4383567958616945

Epoch: 6| Step: 11
Training loss: 1.9896173391049081
Validation loss: 2.451287959063237

Epoch: 6| Step: 12
Training loss: 1.387770176263404
Validation loss: 2.460168045054174

Epoch: 6| Step: 13
Training loss: 2.0009977712852347
Validation loss: 2.468042360765569

Epoch: 275| Step: 0
Training loss: 2.2951721314680578
Validation loss: 2.4565204493909993

Epoch: 6| Step: 1
Training loss: 1.4080377447233048
Validation loss: 2.478577919205811

Epoch: 6| Step: 2
Training loss: 1.4888809077363694
Validation loss: 2.470904874932304

Epoch: 6| Step: 3
Training loss: 2.080221853529066
Validation loss: 2.4503567492596923

Epoch: 6| Step: 4
Training loss: 1.0857241853284174
Validation loss: 2.44435163496842

Epoch: 6| Step: 5
Training loss: 1.413771963041659
Validation loss: 2.4523334719313707

Epoch: 6| Step: 6
Training loss: 1.0793209353515
Validation loss: 2.4623853990468607

Epoch: 6| Step: 7
Training loss: 1.6404732043569796
Validation loss: 2.4439737129898336

Epoch: 6| Step: 8
Training loss: 1.3553195838312107
Validation loss: 2.4567634995757857

Epoch: 6| Step: 9
Training loss: 1.8083286956282298
Validation loss: 2.423785294825684

Epoch: 6| Step: 10
Training loss: 1.5202414610713415
Validation loss: 2.4336111042791373

Epoch: 6| Step: 11
Training loss: 1.1721387947721464
Validation loss: 2.417575662222975

Epoch: 6| Step: 12
Training loss: 1.5248229940279807
Validation loss: 2.450905053461725

Epoch: 6| Step: 13
Training loss: 1.9934978887749164
Validation loss: 2.4388311719976503

Epoch: 276| Step: 0
Training loss: 1.8911475728316849
Validation loss: 2.416650479962288

Epoch: 6| Step: 1
Training loss: 1.9422506111920843
Validation loss: 2.421648715824248

Epoch: 6| Step: 2
Training loss: 1.5540725028358344
Validation loss: 2.4335048582072183

Epoch: 6| Step: 3
Training loss: 1.098456203252625
Validation loss: 2.428075563731502

Epoch: 6| Step: 4
Training loss: 1.468380577216448
Validation loss: 2.4077912066587506

Epoch: 6| Step: 5
Training loss: 1.827815624696797
Validation loss: 2.427075983133444

Epoch: 6| Step: 6
Training loss: 1.7312171299427117
Validation loss: 2.425587645644794

Epoch: 6| Step: 7
Training loss: 1.6202100436300648
Validation loss: 2.4450310435655105

Epoch: 6| Step: 8
Training loss: 1.5896087397806915
Validation loss: 2.4424224038273294

Epoch: 6| Step: 9
Training loss: 1.5407539793424578
Validation loss: 2.451232344110256

Epoch: 6| Step: 10
Training loss: 0.9793682837727643
Validation loss: 2.4448503439343225

Epoch: 6| Step: 11
Training loss: 1.3896820643331333
Validation loss: 2.437399427486251

Epoch: 6| Step: 12
Training loss: 1.6064079860072704
Validation loss: 2.4410146873918053

Epoch: 6| Step: 13
Training loss: 1.1463672896585424
Validation loss: 2.4262909762789726

Epoch: 277| Step: 0
Training loss: 1.5914825316299506
Validation loss: 2.411018147665964

Epoch: 6| Step: 1
Training loss: 1.4514148452279239
Validation loss: 2.3959419725209643

Epoch: 6| Step: 2
Training loss: 1.8808219169142892
Validation loss: 2.3977104320343745

Epoch: 6| Step: 3
Training loss: 1.6353704684914263
Validation loss: 2.391600456263163

Epoch: 6| Step: 4
Training loss: 1.5123606657053097
Validation loss: 2.3867218488562987

Epoch: 6| Step: 5
Training loss: 0.7964464044804322
Validation loss: 2.4210809915143146

Epoch: 6| Step: 6
Training loss: 1.990899720690487
Validation loss: 2.4227678064477587

Epoch: 6| Step: 7
Training loss: 1.4826542567881829
Validation loss: 2.4775572285546446

Epoch: 6| Step: 8
Training loss: 1.6064799667377316
Validation loss: 2.505780344533768

Epoch: 6| Step: 9
Training loss: 1.7669560639252015
Validation loss: 2.474319778402779

Epoch: 6| Step: 10
Training loss: 1.929030148129673
Validation loss: 2.4063373012338043

Epoch: 6| Step: 11
Training loss: 1.5883966932171552
Validation loss: 2.3975024762803216

Epoch: 6| Step: 12
Training loss: 1.2837877959247042
Validation loss: 2.404314933358434

Epoch: 6| Step: 13
Training loss: 1.0233383713100153
Validation loss: 2.4134831009164004

Epoch: 278| Step: 0
Training loss: 1.5083989401330817
Validation loss: 2.420999556775216

Epoch: 6| Step: 1
Training loss: 1.216060605490111
Validation loss: 2.3993699225169274

Epoch: 6| Step: 2
Training loss: 2.0940197443500344
Validation loss: 2.394388590566203

Epoch: 6| Step: 3
Training loss: 1.2815783010279354
Validation loss: 2.4209621819667757

Epoch: 6| Step: 4
Training loss: 1.727783737840148
Validation loss: 2.4560067085631303

Epoch: 6| Step: 5
Training loss: 2.0551968367484323
Validation loss: 2.5874883466690703

Epoch: 6| Step: 6
Training loss: 1.8735142861507
Validation loss: 2.5699937442439897

Epoch: 6| Step: 7
Training loss: 1.7168720042310532
Validation loss: 2.5063534246575436

Epoch: 6| Step: 8
Training loss: 1.6878253481848593
Validation loss: 2.4566143241737417

Epoch: 6| Step: 9
Training loss: 1.6201229267811996
Validation loss: 2.414587503063135

Epoch: 6| Step: 10
Training loss: 1.5831323629961802
Validation loss: 2.38924743438336

Epoch: 6| Step: 11
Training loss: 1.344488340288238
Validation loss: 2.384645857570847

Epoch: 6| Step: 12
Training loss: 1.5012102807577
Validation loss: 2.3896529990871387

Epoch: 6| Step: 13
Training loss: 1.5813137358233234
Validation loss: 2.3991408366162807

Epoch: 279| Step: 0
Training loss: 1.6108622669371806
Validation loss: 2.436289109732736

Epoch: 6| Step: 1
Training loss: 1.3894074070797973
Validation loss: 2.4529732972795735

Epoch: 6| Step: 2
Training loss: 1.5271830364464152
Validation loss: 2.4731260275039473

Epoch: 6| Step: 3
Training loss: 1.6544064752332115
Validation loss: 2.501474038226488

Epoch: 6| Step: 4
Training loss: 1.6200096090055343
Validation loss: 2.450606725177253

Epoch: 6| Step: 5
Training loss: 1.4223533077394497
Validation loss: 2.4409489937430835

Epoch: 6| Step: 6
Training loss: 1.5530197936870413
Validation loss: 2.433931766418417

Epoch: 6| Step: 7
Training loss: 1.6038633613036297
Validation loss: 2.417764520055662

Epoch: 6| Step: 8
Training loss: 1.684217580824433
Validation loss: 2.4084061230497613

Epoch: 6| Step: 9
Training loss: 1.2235033312316865
Validation loss: 2.3986124082675966

Epoch: 6| Step: 10
Training loss: 1.7505693871770092
Validation loss: 2.375182434613935

Epoch: 6| Step: 11
Training loss: 1.5247548985112518
Validation loss: 2.3899065847457814

Epoch: 6| Step: 12
Training loss: 1.477979031023038
Validation loss: 2.427576755260565

Epoch: 6| Step: 13
Training loss: 1.7627233783040945
Validation loss: 2.4292842763981186

Epoch: 280| Step: 0
Training loss: 1.8957314376556138
Validation loss: 2.42658663917034

Epoch: 6| Step: 1
Training loss: 1.5186206275876368
Validation loss: 2.4538519196201096

Epoch: 6| Step: 2
Training loss: 1.6350015084962564
Validation loss: 2.5086778659302045

Epoch: 6| Step: 3
Training loss: 1.1201543294640326
Validation loss: 2.5236612409529013

Epoch: 6| Step: 4
Training loss: 1.727025448972222
Validation loss: 2.4890895051158566

Epoch: 6| Step: 5
Training loss: 1.7582119636169404
Validation loss: 2.448209328176106

Epoch: 6| Step: 6
Training loss: 1.608785428692251
Validation loss: 2.413557409225005

Epoch: 6| Step: 7
Training loss: 1.273945619275875
Validation loss: 2.4138002912639487

Epoch: 6| Step: 8
Training loss: 1.7046771195162937
Validation loss: 2.41029808361174

Epoch: 6| Step: 9
Training loss: 1.6229963420984177
Validation loss: 2.4023020083988498

Epoch: 6| Step: 10
Training loss: 1.408397095081418
Validation loss: 2.3746388845725126

Epoch: 6| Step: 11
Training loss: 1.982615915207299
Validation loss: 2.3595570064395535

Epoch: 6| Step: 12
Training loss: 1.138438807823651
Validation loss: 2.3405610220024644

Epoch: 6| Step: 13
Training loss: 0.7972740595295245
Validation loss: 2.35249720873301

Epoch: 281| Step: 0
Training loss: 1.6882883279167489
Validation loss: 2.36579204852794

Epoch: 6| Step: 1
Training loss: 1.2081627341671421
Validation loss: 2.3692855902200876

Epoch: 6| Step: 2
Training loss: 1.197939211868207
Validation loss: 2.3869108596682893

Epoch: 6| Step: 3
Training loss: 1.7737838474133087
Validation loss: 2.3860147101509925

Epoch: 6| Step: 4
Training loss: 1.2241012273392915
Validation loss: 2.365798026359215

Epoch: 6| Step: 5
Training loss: 1.8361510456966537
Validation loss: 2.369588516833149

Epoch: 6| Step: 6
Training loss: 1.206953472112956
Validation loss: 2.3823329518969327

Epoch: 6| Step: 7
Training loss: 1.4205532428091239
Validation loss: 2.3868779594111045

Epoch: 6| Step: 8
Training loss: 1.3214931288160587
Validation loss: 2.390167375903609

Epoch: 6| Step: 9
Training loss: 1.7453259309612186
Validation loss: 2.3889934117557092

Epoch: 6| Step: 10
Training loss: 1.6709048584859822
Validation loss: 2.4168193052529845

Epoch: 6| Step: 11
Training loss: 1.4028452876918898
Validation loss: 2.4209773162128667

Epoch: 6| Step: 12
Training loss: 1.6796616663166
Validation loss: 2.43131467958463

Epoch: 6| Step: 13
Training loss: 1.3386497849711416
Validation loss: 2.4496115615994594

Epoch: 282| Step: 0
Training loss: 1.2123724526243767
Validation loss: 2.456385702533178

Epoch: 6| Step: 1
Training loss: 1.541625469104074
Validation loss: 2.4707830979446026

Epoch: 6| Step: 2
Training loss: 1.3201237379945254
Validation loss: 2.486257192897151

Epoch: 6| Step: 3
Training loss: 1.7150546489494312
Validation loss: 2.4422467156319274

Epoch: 6| Step: 4
Training loss: 1.219715127517205
Validation loss: 2.401793263897359

Epoch: 6| Step: 5
Training loss: 1.562737408721684
Validation loss: 2.3779846418194874

Epoch: 6| Step: 6
Training loss: 1.8276105629682289
Validation loss: 2.3897701898408976

Epoch: 6| Step: 7
Training loss: 1.6778129585877941
Validation loss: 2.3726921850537463

Epoch: 6| Step: 8
Training loss: 1.556034597174028
Validation loss: 2.352263397169543

Epoch: 6| Step: 9
Training loss: 1.587451982147422
Validation loss: 2.3507023237927234

Epoch: 6| Step: 10
Training loss: 1.2308654145795077
Validation loss: 2.3324174079454703

Epoch: 6| Step: 11
Training loss: 1.9009600547795722
Validation loss: 2.3603891465259057

Epoch: 6| Step: 12
Training loss: 1.1972166365640442
Validation loss: 2.377375741636694

Epoch: 6| Step: 13
Training loss: 1.5634388963783459
Validation loss: 2.395063534655893

Epoch: 283| Step: 0
Training loss: 1.6159549752468807
Validation loss: 2.433331763724533

Epoch: 6| Step: 1
Training loss: 0.9632897159300305
Validation loss: 2.442508587453242

Epoch: 6| Step: 2
Training loss: 1.3519196672330835
Validation loss: 2.4706583390202996

Epoch: 6| Step: 3
Training loss: 1.5983504673447504
Validation loss: 2.4851597156567484

Epoch: 6| Step: 4
Training loss: 1.5903651626691633
Validation loss: 2.495734548585089

Epoch: 6| Step: 5
Training loss: 1.1321713968301055
Validation loss: 2.4673915379420754

Epoch: 6| Step: 6
Training loss: 1.7307950437691249
Validation loss: 2.4618824769756458

Epoch: 6| Step: 7
Training loss: 1.9035669424371708
Validation loss: 2.4863293984020673

Epoch: 6| Step: 8
Training loss: 1.2912446019520518
Validation loss: 2.4743418042186645

Epoch: 6| Step: 9
Training loss: 1.4078126066929717
Validation loss: 2.4668242468493538

Epoch: 6| Step: 10
Training loss: 1.5416990053376445
Validation loss: 2.4577242759156057

Epoch: 6| Step: 11
Training loss: 1.564562085342215
Validation loss: 2.43907428425992

Epoch: 6| Step: 12
Training loss: 1.4686504898450214
Validation loss: 2.4550455482657965

Epoch: 6| Step: 13
Training loss: 1.224400601394416
Validation loss: 2.4102286473873162

Epoch: 284| Step: 0
Training loss: 1.1593392831899398
Validation loss: 2.4119111783635736

Epoch: 6| Step: 1
Training loss: 1.6328198008396886
Validation loss: 2.4181522662413477

Epoch: 6| Step: 2
Training loss: 1.5814393996846283
Validation loss: 2.3976906762779935

Epoch: 6| Step: 3
Training loss: 1.1630425817446641
Validation loss: 2.3721979036898886

Epoch: 6| Step: 4
Training loss: 1.7383303517468132
Validation loss: 2.3821091976171216

Epoch: 6| Step: 5
Training loss: 1.6602807570499107
Validation loss: 2.376917029205052

Epoch: 6| Step: 6
Training loss: 1.6020120873584576
Validation loss: 2.3741033034647248

Epoch: 6| Step: 7
Training loss: 1.1889527619862281
Validation loss: 2.3942537540903785

Epoch: 6| Step: 8
Training loss: 1.3874151066421083
Validation loss: 2.434724283791271

Epoch: 6| Step: 9
Training loss: 1.6429633052951569
Validation loss: 2.4280023828911617

Epoch: 6| Step: 10
Training loss: 1.0576889281452313
Validation loss: 2.415528085079927

Epoch: 6| Step: 11
Training loss: 1.2718167903242332
Validation loss: 2.409434537717357

Epoch: 6| Step: 12
Training loss: 1.456450400254708
Validation loss: 2.4235999277160096

Epoch: 6| Step: 13
Training loss: 1.4113979631677098
Validation loss: 2.4108515953119585

Epoch: 285| Step: 0
Training loss: 1.4480973092149458
Validation loss: 2.4115856268793903

Epoch: 6| Step: 1
Training loss: 1.5048367086647219
Validation loss: 2.3886352699391646

Epoch: 6| Step: 2
Training loss: 1.5347402848705036
Validation loss: 2.3836182537653063

Epoch: 6| Step: 3
Training loss: 1.325873542230279
Validation loss: 2.4007367815229617

Epoch: 6| Step: 4
Training loss: 0.6880051534301681
Validation loss: 2.3686708237567395

Epoch: 6| Step: 5
Training loss: 1.0687830222755828
Validation loss: 2.391315410643466

Epoch: 6| Step: 6
Training loss: 1.619536237621586
Validation loss: 2.3767208650170706

Epoch: 6| Step: 7
Training loss: 1.2020728725108207
Validation loss: 2.366886764868816

Epoch: 6| Step: 8
Training loss: 1.3120397033091995
Validation loss: 2.366479599472157

Epoch: 6| Step: 9
Training loss: 1.308056530352064
Validation loss: 2.3786030787368793

Epoch: 6| Step: 10
Training loss: 1.9654171905074784
Validation loss: 2.3744037875049604

Epoch: 6| Step: 11
Training loss: 1.6717601986267787
Validation loss: 2.4146001864595985

Epoch: 6| Step: 12
Training loss: 1.3598116907712683
Validation loss: 2.427703850630101

Epoch: 6| Step: 13
Training loss: 0.9958387160588013
Validation loss: 2.437447488711907

Epoch: 286| Step: 0
Training loss: 1.3881068200059203
Validation loss: 2.4669842150902563

Epoch: 6| Step: 1
Training loss: 1.6921225918396718
Validation loss: 2.4260019189415996

Epoch: 6| Step: 2
Training loss: 1.291695697006993
Validation loss: 2.3873551545383087

Epoch: 6| Step: 3
Training loss: 1.1855366186361336
Validation loss: 2.3860322047311557

Epoch: 6| Step: 4
Training loss: 1.6457326673150978
Validation loss: 2.389865072701172

Epoch: 6| Step: 5
Training loss: 1.3886537617764283
Validation loss: 2.378885458707817

Epoch: 6| Step: 6
Training loss: 1.4138039621296281
Validation loss: 2.3470913756158946

Epoch: 6| Step: 7
Training loss: 1.0698794860353582
Validation loss: 2.3456518582528196

Epoch: 6| Step: 8
Training loss: 1.4389907736200815
Validation loss: 2.395456236436442

Epoch: 6| Step: 9
Training loss: 1.4222295130519618
Validation loss: 2.4003363118167704

Epoch: 6| Step: 10
Training loss: 1.9167213501247509
Validation loss: 2.4174040089260465

Epoch: 6| Step: 11
Training loss: 1.6238512233461364
Validation loss: 2.4200068503448717

Epoch: 6| Step: 12
Training loss: 1.7311591499811554
Validation loss: 2.44142116510901

Epoch: 6| Step: 13
Training loss: 1.2481847934602825
Validation loss: 2.390692015911031

Epoch: 287| Step: 0
Training loss: 1.0866455404494206
Validation loss: 2.391117672250905

Epoch: 6| Step: 1
Training loss: 1.2433034814177581
Validation loss: 2.3587888953865415

Epoch: 6| Step: 2
Training loss: 1.4092408059256583
Validation loss: 2.3691358908196527

Epoch: 6| Step: 3
Training loss: 1.9139886335794776
Validation loss: 2.3648982461515065

Epoch: 6| Step: 4
Training loss: 1.4358190576895686
Validation loss: 2.3798895213729283

Epoch: 6| Step: 5
Training loss: 1.4858988920344625
Validation loss: 2.359763499399505

Epoch: 6| Step: 6
Training loss: 1.5822532215516567
Validation loss: 2.361531452770693

Epoch: 6| Step: 7
Training loss: 1.45773012310798
Validation loss: 2.3942194106966017

Epoch: 6| Step: 8
Training loss: 1.154932250640944
Validation loss: 2.408612380638029

Epoch: 6| Step: 9
Training loss: 1.306135732955125
Validation loss: 2.4107393922250964

Epoch: 6| Step: 10
Training loss: 1.4776915416716307
Validation loss: 2.4150141089443022

Epoch: 6| Step: 11
Training loss: 1.4920229196910149
Validation loss: 2.430538494169374

Epoch: 6| Step: 12
Training loss: 0.9551814984816532
Validation loss: 2.4209684000227996

Epoch: 6| Step: 13
Training loss: 1.299424755764001
Validation loss: 2.4033762681421176

Epoch: 288| Step: 0
Training loss: 1.198281036468459
Validation loss: 2.4042054039616114

Epoch: 6| Step: 1
Training loss: 1.5782518996782138
Validation loss: 2.4035387184745547

Epoch: 6| Step: 2
Training loss: 1.2424929741060187
Validation loss: 2.426899610742495

Epoch: 6| Step: 3
Training loss: 1.409323364462252
Validation loss: 2.411933415899011

Epoch: 6| Step: 4
Training loss: 1.201008607266573
Validation loss: 2.39373770965837

Epoch: 6| Step: 5
Training loss: 1.5123013105801846
Validation loss: 2.3664188280227236

Epoch: 6| Step: 6
Training loss: 1.9641788032468601
Validation loss: 2.3514947216113393

Epoch: 6| Step: 7
Training loss: 0.7379032761966978
Validation loss: 2.3512437859488795

Epoch: 6| Step: 8
Training loss: 1.468890650081749
Validation loss: 2.347544638394439

Epoch: 6| Step: 9
Training loss: 1.6481396736009692
Validation loss: 2.3411079352660384

Epoch: 6| Step: 10
Training loss: 1.0847840255039367
Validation loss: 2.3311889730184037

Epoch: 6| Step: 11
Training loss: 1.2679899748637529
Validation loss: 2.315567314845764

Epoch: 6| Step: 12
Training loss: 1.4106752069451516
Validation loss: 2.331215483667737

Epoch: 6| Step: 13
Training loss: 1.253451588755261
Validation loss: 2.323572610198691

Epoch: 289| Step: 0
Training loss: 1.5910451787483852
Validation loss: 2.3268345517729636

Epoch: 6| Step: 1
Training loss: 1.2668587593351226
Validation loss: 2.3230059329877135

Epoch: 6| Step: 2
Training loss: 0.9845865718601565
Validation loss: 2.3268445833833558

Epoch: 6| Step: 3
Training loss: 1.4070622111911433
Validation loss: 2.340878483288047

Epoch: 6| Step: 4
Training loss: 1.377722775329611
Validation loss: 2.349178151037407

Epoch: 6| Step: 5
Training loss: 1.2625370737807657
Validation loss: 2.3742136460338528

Epoch: 6| Step: 6
Training loss: 1.25898867756401
Validation loss: 2.373181755108032

Epoch: 6| Step: 7
Training loss: 1.464800617854573
Validation loss: 2.376571665244693

Epoch: 6| Step: 8
Training loss: 1.6314517104741435
Validation loss: 2.3613026450990704

Epoch: 6| Step: 9
Training loss: 1.4387824101778839
Validation loss: 2.3730447338126153

Epoch: 6| Step: 10
Training loss: 1.0473498505840504
Validation loss: 2.3560815229492564

Epoch: 6| Step: 11
Training loss: 1.2280974290388331
Validation loss: 2.373362978190936

Epoch: 6| Step: 12
Training loss: 1.5777155278839938
Validation loss: 2.345245410388405

Epoch: 6| Step: 13
Training loss: 1.2734552861943287
Validation loss: 2.356704150946952

Epoch: 290| Step: 0
Training loss: 1.2147783954863458
Validation loss: 2.3408343494952066

Epoch: 6| Step: 1
Training loss: 1.0112622973020908
Validation loss: 2.334539623155229

Epoch: 6| Step: 2
Training loss: 1.4175926529409784
Validation loss: 2.3282975213232473

Epoch: 6| Step: 3
Training loss: 1.1977828683628984
Validation loss: 2.3339834067631458

Epoch: 6| Step: 4
Training loss: 1.5596216010615924
Validation loss: 2.35159369437676

Epoch: 6| Step: 5
Training loss: 1.5297803248607078
Validation loss: 2.3597915043822835

Epoch: 6| Step: 6
Training loss: 1.4097494875437993
Validation loss: 2.3705022284580353

Epoch: 6| Step: 7
Training loss: 1.0107358185940645
Validation loss: 2.3814574806921143

Epoch: 6| Step: 8
Training loss: 1.3398073597406495
Validation loss: 2.3574748845282216

Epoch: 6| Step: 9
Training loss: 1.3714029338475389
Validation loss: 2.3337434446355245

Epoch: 6| Step: 10
Training loss: 1.7898922790848446
Validation loss: 2.343920751114785

Epoch: 6| Step: 11
Training loss: 1.2735300791033486
Validation loss: 2.3242010471451913

Epoch: 6| Step: 12
Training loss: 1.1046760871437944
Validation loss: 2.3491251321727287

Epoch: 6| Step: 13
Training loss: 1.3560456469175541
Validation loss: 2.35220440442215

Epoch: 291| Step: 0
Training loss: 1.4655035948746684
Validation loss: 2.3518135749771374

Epoch: 6| Step: 1
Training loss: 1.6641834197190446
Validation loss: 2.35210037988956

Epoch: 6| Step: 2
Training loss: 1.1265579138885988
Validation loss: 2.3582186240288414

Epoch: 6| Step: 3
Training loss: 1.2326560304312475
Validation loss: 2.3581036447755594

Epoch: 6| Step: 4
Training loss: 1.165020644369292
Validation loss: 2.3685639333033395

Epoch: 6| Step: 5
Training loss: 1.3934169559542717
Validation loss: 2.3626241051172645

Epoch: 6| Step: 6
Training loss: 1.254794225274765
Validation loss: 2.3416825350849715

Epoch: 6| Step: 7
Training loss: 1.0396587984040722
Validation loss: 2.339471995143529

Epoch: 6| Step: 8
Training loss: 1.563642236913292
Validation loss: 2.332007164948512

Epoch: 6| Step: 9
Training loss: 1.1294068807082602
Validation loss: 2.3218414615581686

Epoch: 6| Step: 10
Training loss: 1.5357314723501065
Validation loss: 2.3170253682530646

Epoch: 6| Step: 11
Training loss: 1.5606402964791428
Validation loss: 2.338203843912092

Epoch: 6| Step: 12
Training loss: 0.9376990424894245
Validation loss: 2.354680179480294

Epoch: 6| Step: 13
Training loss: 1.6273485232176532
Validation loss: 2.35325564929412

Epoch: 292| Step: 0
Training loss: 1.3385613980552127
Validation loss: 2.374767930610096

Epoch: 6| Step: 1
Training loss: 1.0651709699627872
Validation loss: 2.378274746459449

Epoch: 6| Step: 2
Training loss: 1.3550718754360067
Validation loss: 2.385690710870812

Epoch: 6| Step: 3
Training loss: 0.8627605680417013
Validation loss: 2.3893790030448248

Epoch: 6| Step: 4
Training loss: 1.1718093345046325
Validation loss: 2.384043065429338

Epoch: 6| Step: 5
Training loss: 1.3439791284427818
Validation loss: 2.3817408752448137

Epoch: 6| Step: 6
Training loss: 1.2752167610962308
Validation loss: 2.386112469176918

Epoch: 6| Step: 7
Training loss: 1.6961071771189502
Validation loss: 2.3832940303474106

Epoch: 6| Step: 8
Training loss: 1.2177141629425685
Validation loss: 2.373589546450969

Epoch: 6| Step: 9
Training loss: 1.354952491265216
Validation loss: 2.3618290484869195

Epoch: 6| Step: 10
Training loss: 1.3461522652543396
Validation loss: 2.362473459480462

Epoch: 6| Step: 11
Training loss: 1.1431413876050784
Validation loss: 2.3493895532676214

Epoch: 6| Step: 12
Training loss: 1.5551332381102099
Validation loss: 2.3920376629429847

Epoch: 6| Step: 13
Training loss: 1.6939588495410975
Validation loss: 2.4197740008487796

Epoch: 293| Step: 0
Training loss: 1.323108579076932
Validation loss: 2.4259663764632133

Epoch: 6| Step: 1
Training loss: 1.557688820844988
Validation loss: 2.3514119781003773

Epoch: 6| Step: 2
Training loss: 1.0327011648584326
Validation loss: 2.3775548901638555

Epoch: 6| Step: 3
Training loss: 1.3049828657582003
Validation loss: 2.37484456381058

Epoch: 6| Step: 4
Training loss: 1.3610441111382061
Validation loss: 2.377114756081882

Epoch: 6| Step: 5
Training loss: 1.6653086692922052
Validation loss: 2.3935489530379983

Epoch: 6| Step: 6
Training loss: 1.5800099965274228
Validation loss: 2.4071976758937708

Epoch: 6| Step: 7
Training loss: 1.6480470891076686
Validation loss: 2.4166478883680615

Epoch: 6| Step: 8
Training loss: 1.457458678849033
Validation loss: 2.448009149030146

Epoch: 6| Step: 9
Training loss: 1.0851079942425115
Validation loss: 2.48859933450588

Epoch: 6| Step: 10
Training loss: 1.4402079576429005
Validation loss: 2.4871687852193163

Epoch: 6| Step: 11
Training loss: 1.2369838620816174
Validation loss: 2.492116259925036

Epoch: 6| Step: 12
Training loss: 1.3742533303703273
Validation loss: 2.424180187134239

Epoch: 6| Step: 13
Training loss: 1.5112619424479021
Validation loss: 2.377318598160707

Epoch: 294| Step: 0
Training loss: 1.4256656965695864
Validation loss: 2.3361296221318626

Epoch: 6| Step: 1
Training loss: 1.2204113420808984
Validation loss: 2.3390284845371165

Epoch: 6| Step: 2
Training loss: 1.8784304073785592
Validation loss: 2.365187470521506

Epoch: 6| Step: 3
Training loss: 1.1278462961259113
Validation loss: 2.294023028002899

Epoch: 6| Step: 4
Training loss: 1.1215127301592709
Validation loss: 2.2963103470277977

Epoch: 6| Step: 5
Training loss: 1.1040976280845454
Validation loss: 2.300710795027658

Epoch: 6| Step: 6
Training loss: 1.1923165267777955
Validation loss: 2.2973403587600028

Epoch: 6| Step: 7
Training loss: 1.58747856546184
Validation loss: 2.31680616845677

Epoch: 6| Step: 8
Training loss: 1.7566392840447544
Validation loss: 2.298095784978479

Epoch: 6| Step: 9
Training loss: 1.1586883197651685
Validation loss: 2.285833285990825

Epoch: 6| Step: 10
Training loss: 1.2789575490759093
Validation loss: 2.2931830489529506

Epoch: 6| Step: 11
Training loss: 1.33672572746663
Validation loss: 2.3115626366820994

Epoch: 6| Step: 12
Training loss: 1.3685632377957357
Validation loss: 2.298594954985885

Epoch: 6| Step: 13
Training loss: 1.5144286792544375
Validation loss: 2.311743422100457

Epoch: 295| Step: 0
Training loss: 1.4288702958695072
Validation loss: 2.324733838025326

Epoch: 6| Step: 1
Training loss: 1.3946108755251394
Validation loss: 2.341288029752361

Epoch: 6| Step: 2
Training loss: 0.8047573837007904
Validation loss: 2.325005750222295

Epoch: 6| Step: 3
Training loss: 1.4153546072974763
Validation loss: 2.3643704177068527

Epoch: 6| Step: 4
Training loss: 1.6684679628839645
Validation loss: 2.338281014870715

Epoch: 6| Step: 5
Training loss: 0.9570189183277578
Validation loss: 2.350084702185572

Epoch: 6| Step: 6
Training loss: 1.4018513444596028
Validation loss: 2.3144862683395764

Epoch: 6| Step: 7
Training loss: 0.9454685113969917
Validation loss: 2.335693517839981

Epoch: 6| Step: 8
Training loss: 1.042253513333005
Validation loss: 2.3261917080487517

Epoch: 6| Step: 9
Training loss: 1.130304862733013
Validation loss: 2.360769816694089

Epoch: 6| Step: 10
Training loss: 0.9514496258718032
Validation loss: 2.330860177200524

Epoch: 6| Step: 11
Training loss: 1.6189350508443936
Validation loss: 2.3463744675624856

Epoch: 6| Step: 12
Training loss: 1.6730163101158262
Validation loss: 2.3478911885973774

Epoch: 6| Step: 13
Training loss: 1.4993236924456987
Validation loss: 2.357562865360571

Epoch: 296| Step: 0
Training loss: 0.6855677414025239
Validation loss: 2.366666489768235

Epoch: 6| Step: 1
Training loss: 1.4843472929928527
Validation loss: 2.3845098466034744

Epoch: 6| Step: 2
Training loss: 1.601298091740973
Validation loss: 2.392955571885988

Epoch: 6| Step: 3
Training loss: 1.5123382008921031
Validation loss: 2.336470629222782

Epoch: 6| Step: 4
Training loss: 1.2920474547360545
Validation loss: 2.324912319587576

Epoch: 6| Step: 5
Training loss: 1.1595083154904091
Validation loss: 2.290050278488866

Epoch: 6| Step: 6
Training loss: 1.217478749365865
Validation loss: 2.2665845067611126

Epoch: 6| Step: 7
Training loss: 1.1267818538952872
Validation loss: 2.278866097535057

Epoch: 6| Step: 8
Training loss: 1.1298906726613214
Validation loss: 2.291839244828984

Epoch: 6| Step: 9
Training loss: 1.349684408175051
Validation loss: 2.256431256161913

Epoch: 6| Step: 10
Training loss: 1.0588804187638259
Validation loss: 2.2627593783821167

Epoch: 6| Step: 11
Training loss: 1.0611159903451297
Validation loss: 2.2889633333622954

Epoch: 6| Step: 12
Training loss: 1.2281915816490196
Validation loss: 2.3142968125659658

Epoch: 6| Step: 13
Training loss: 1.6417502767633212
Validation loss: 2.3172512627366233

Epoch: 297| Step: 0
Training loss: 1.455790873830736
Validation loss: 2.3574504308696316

Epoch: 6| Step: 1
Training loss: 1.3910251427495965
Validation loss: 2.3531487269934104

Epoch: 6| Step: 2
Training loss: 1.1145367419525893
Validation loss: 2.3594112913647445

Epoch: 6| Step: 3
Training loss: 1.400158723280478
Validation loss: 2.3507660278149833

Epoch: 6| Step: 4
Training loss: 0.9460759193510496
Validation loss: 2.331410961669516

Epoch: 6| Step: 5
Training loss: 1.3468233492477695
Validation loss: 2.3296734938238286

Epoch: 6| Step: 6
Training loss: 0.8695584782178585
Validation loss: 2.33751855184482

Epoch: 6| Step: 7
Training loss: 1.4143404186975452
Validation loss: 2.3604604897963073

Epoch: 6| Step: 8
Training loss: 1.5601190355319996
Validation loss: 2.3784413968174496

Epoch: 6| Step: 9
Training loss: 0.9554387447358802
Validation loss: 2.3620054753635062

Epoch: 6| Step: 10
Training loss: 1.5999838887834013
Validation loss: 2.387920043148069

Epoch: 6| Step: 11
Training loss: 1.1516518794949233
Validation loss: 2.386663182580829

Epoch: 6| Step: 12
Training loss: 1.2663841325639376
Validation loss: 2.39207606948219

Epoch: 6| Step: 13
Training loss: 0.900788324862618
Validation loss: 2.4220665111368844

Epoch: 298| Step: 0
Training loss: 1.2759755123921803
Validation loss: 2.446885513892639

Epoch: 6| Step: 1
Training loss: 0.8845587145313929
Validation loss: 2.4247021806104896

Epoch: 6| Step: 2
Training loss: 0.8787315025390491
Validation loss: 2.426883339822633

Epoch: 6| Step: 3
Training loss: 0.968942746091926
Validation loss: 2.4131576658829874

Epoch: 6| Step: 4
Training loss: 1.5009358983187178
Validation loss: 2.392907775175126

Epoch: 6| Step: 5
Training loss: 1.401947092897326
Validation loss: 2.36155991009682

Epoch: 6| Step: 6
Training loss: 1.3232894832703135
Validation loss: 2.3522399508684515

Epoch: 6| Step: 7
Training loss: 1.8158491039014362
Validation loss: 2.347544952905372

Epoch: 6| Step: 8
Training loss: 1.1875834686658968
Validation loss: 2.3424982371969163

Epoch: 6| Step: 9
Training loss: 0.896518847897674
Validation loss: 2.3649814359672616

Epoch: 6| Step: 10
Training loss: 0.8976766266929533
Validation loss: 2.3583863839803834

Epoch: 6| Step: 11
Training loss: 1.3187085402782834
Validation loss: 2.3629809995736384

Epoch: 6| Step: 12
Training loss: 1.3774214144408403
Validation loss: 2.3444994028479624

Epoch: 6| Step: 13
Training loss: 1.2106926947451668
Validation loss: 2.353127667263317

Epoch: 299| Step: 0
Training loss: 1.2877852614590068
Validation loss: 2.3392750197477996

Epoch: 6| Step: 1
Training loss: 1.2526780051861388
Validation loss: 2.3196561516271235

Epoch: 6| Step: 2
Training loss: 1.1649306983145438
Validation loss: 2.3049780221584037

Epoch: 6| Step: 3
Training loss: 1.4116109598931479
Validation loss: 2.2941172249474273

Epoch: 6| Step: 4
Training loss: 1.0899142991068531
Validation loss: 2.292681196691143

Epoch: 6| Step: 5
Training loss: 0.8117051638364818
Validation loss: 2.280954059414462

Epoch: 6| Step: 6
Training loss: 1.1871294648157906
Validation loss: 2.2986544135005773

Epoch: 6| Step: 7
Training loss: 1.3827731455574663
Validation loss: 2.309803016093445

Epoch: 6| Step: 8
Training loss: 1.1561107036091456
Validation loss: 2.3080110018647746

Epoch: 6| Step: 9
Training loss: 1.1350347360681516
Validation loss: 2.3106883301671455

Epoch: 6| Step: 10
Training loss: 1.1351205923908325
Validation loss: 2.3160072897112833

Epoch: 6| Step: 11
Training loss: 1.3510217191134855
Validation loss: 2.3068742442310044

Epoch: 6| Step: 12
Training loss: 1.188179022751286
Validation loss: 2.3379601075811

Epoch: 6| Step: 13
Training loss: 1.791574305733842
Validation loss: 2.378496572127697

Epoch: 300| Step: 0
Training loss: 1.2308595067166106
Validation loss: 2.4405510346864725

Epoch: 6| Step: 1
Training loss: 1.0128921126278605
Validation loss: 2.4472192682421894

Epoch: 6| Step: 2
Training loss: 1.3149147526773253
Validation loss: 2.4574295222765263

Epoch: 6| Step: 3
Training loss: 1.4880178623973157
Validation loss: 2.438739241776053

Epoch: 6| Step: 4
Training loss: 0.9286813500602056
Validation loss: 2.3933332805934606

Epoch: 6| Step: 5
Training loss: 1.4619032987454446
Validation loss: 2.3615419742268693

Epoch: 6| Step: 6
Training loss: 1.3508552067699902
Validation loss: 2.356840075110972

Epoch: 6| Step: 7
Training loss: 1.4415909150054311
Validation loss: 2.364430445963739

Epoch: 6| Step: 8
Training loss: 1.3914034090007756
Validation loss: 2.3458611565395584

Epoch: 6| Step: 9
Training loss: 0.859803110472791
Validation loss: 2.325200382012539

Epoch: 6| Step: 10
Training loss: 1.2087718178990141
Validation loss: 2.3301598035916236

Epoch: 6| Step: 11
Training loss: 1.3023729638002197
Validation loss: 2.3665535919160066

Epoch: 6| Step: 12
Training loss: 1.425329769191324
Validation loss: 2.365175123717261

Epoch: 6| Step: 13
Training loss: 1.2301912509508495
Validation loss: 2.3509266578688517

Epoch: 301| Step: 0
Training loss: 0.8281582519765003
Validation loss: 2.332889480792712

Epoch: 6| Step: 1
Training loss: 1.4029990872511338
Validation loss: 2.2979184815543148

Epoch: 6| Step: 2
Training loss: 0.9115085297340803
Validation loss: 2.3274484430290365

Epoch: 6| Step: 3
Training loss: 0.9011176229813399
Validation loss: 2.3355739682539522

Epoch: 6| Step: 4
Training loss: 1.0366415631810864
Validation loss: 2.34552241533142

Epoch: 6| Step: 5
Training loss: 1.2388376135305463
Validation loss: 2.313933302188466

Epoch: 6| Step: 6
Training loss: 1.2151190148449378
Validation loss: 2.327598337673228

Epoch: 6| Step: 7
Training loss: 1.4724031832979005
Validation loss: 2.3255871296394837

Epoch: 6| Step: 8
Training loss: 1.1825745478029916
Validation loss: 2.3736818333180376

Epoch: 6| Step: 9
Training loss: 1.4396056634005614
Validation loss: 2.3592671494178963

Epoch: 6| Step: 10
Training loss: 1.6172906962469649
Validation loss: 2.3882553717745036

Epoch: 6| Step: 11
Training loss: 1.3970817515319431
Validation loss: 2.3384667548140325

Epoch: 6| Step: 12
Training loss: 1.0712936248264862
Validation loss: 2.293301084708554

Epoch: 6| Step: 13
Training loss: 0.9392103488199245
Validation loss: 2.269974008494229

Epoch: 302| Step: 0
Training loss: 1.1974878400531654
Validation loss: 2.270991169085255

Epoch: 6| Step: 1
Training loss: 1.4817381879253002
Validation loss: 2.2849838204402406

Epoch: 6| Step: 2
Training loss: 1.3025147397311083
Validation loss: 2.2718642369887774

Epoch: 6| Step: 3
Training loss: 0.8580067232308701
Validation loss: 2.269574699277521

Epoch: 6| Step: 4
Training loss: 0.7568557835099569
Validation loss: 2.282907898022695

Epoch: 6| Step: 5
Training loss: 1.2077379842771243
Validation loss: 2.2844746962558946

Epoch: 6| Step: 6
Training loss: 0.9515740956068169
Validation loss: 2.321659002797678

Epoch: 6| Step: 7
Training loss: 0.9872397260867879
Validation loss: 2.3249010854289036

Epoch: 6| Step: 8
Training loss: 1.1510234445823997
Validation loss: 2.326751462374527

Epoch: 6| Step: 9
Training loss: 1.1025551185756546
Validation loss: 2.3334142166246754

Epoch: 6| Step: 10
Training loss: 1.0944058767828788
Validation loss: 2.3189520895935867

Epoch: 6| Step: 11
Training loss: 1.5572892085877819
Validation loss: 2.3168376637145203

Epoch: 6| Step: 12
Training loss: 1.367571008571664
Validation loss: 2.3185978798133715

Epoch: 6| Step: 13
Training loss: 1.8992304774510338
Validation loss: 2.3119910294505326

Epoch: 303| Step: 0
Training loss: 0.6889086077886194
Validation loss: 2.329714682523012

Epoch: 6| Step: 1
Training loss: 1.3554775886357406
Validation loss: 2.3336198370108767

Epoch: 6| Step: 2
Training loss: 1.0987458709187872
Validation loss: 2.3161880182022205

Epoch: 6| Step: 3
Training loss: 1.005682653809814
Validation loss: 2.3110772212310216

Epoch: 6| Step: 4
Training loss: 1.4302240417610619
Validation loss: 2.296157596521116

Epoch: 6| Step: 5
Training loss: 1.0703125
Validation loss: 2.322316129680623

Epoch: 6| Step: 6
Training loss: 1.258060880979961
Validation loss: 2.3017419322392385

Epoch: 6| Step: 7
Training loss: 1.0212358278110614
Validation loss: 2.306889753549958

Epoch: 6| Step: 8
Training loss: 0.7450219089691625
Validation loss: 2.302151008368114

Epoch: 6| Step: 9
Training loss: 1.1721423034985465
Validation loss: 2.308418937618947

Epoch: 6| Step: 10
Training loss: 1.5648141889593883
Validation loss: 2.318949343488077

Epoch: 6| Step: 11
Training loss: 1.1932453906475549
Validation loss: 2.3237868873882674

Epoch: 6| Step: 12
Training loss: 1.3924260852311088
Validation loss: 2.3078482096069077

Epoch: 6| Step: 13
Training loss: 1.2671906947461367
Validation loss: 2.3255292273149464

Epoch: 304| Step: 0
Training loss: 1.3743349114053607
Validation loss: 2.310282960641636

Epoch: 6| Step: 1
Training loss: 1.0346580602109319
Validation loss: 2.3350195062290764

Epoch: 6| Step: 2
Training loss: 1.0847153407122934
Validation loss: 2.335619993324361

Epoch: 6| Step: 3
Training loss: 0.9135127248206624
Validation loss: 2.3407570195773557

Epoch: 6| Step: 4
Training loss: 0.9905056252741051
Validation loss: 2.351715988826049

Epoch: 6| Step: 5
Training loss: 1.2490441959615644
Validation loss: 2.382026639334352

Epoch: 6| Step: 6
Training loss: 1.0107049170362679
Validation loss: 2.392815453597608

Epoch: 6| Step: 7
Training loss: 1.2198877159415145
Validation loss: 2.3815827078020972

Epoch: 6| Step: 8
Training loss: 1.4587518182398327
Validation loss: 2.3644595720707655

Epoch: 6| Step: 9
Training loss: 1.5139101689949694
Validation loss: 2.3331945935839227

Epoch: 6| Step: 10
Training loss: 1.3750439116662112
Validation loss: 2.3276246931695646

Epoch: 6| Step: 11
Training loss: 0.8361410089352589
Validation loss: 2.3258096463492666

Epoch: 6| Step: 12
Training loss: 1.1947326250906236
Validation loss: 2.3348230566626307

Epoch: 6| Step: 13
Training loss: 1.0139537852927083
Validation loss: 2.3323657656345045

Epoch: 305| Step: 0
Training loss: 0.9167557514136134
Validation loss: 2.3115013358530963

Epoch: 6| Step: 1
Training loss: 1.3635614320368163
Validation loss: 2.32096167643434

Epoch: 6| Step: 2
Training loss: 0.889076761087772
Validation loss: 2.310866099341346

Epoch: 6| Step: 3
Training loss: 1.193032077789719
Validation loss: 2.2929565297432637

Epoch: 6| Step: 4
Training loss: 0.7720332257651437
Validation loss: 2.309354712317657

Epoch: 6| Step: 5
Training loss: 1.5435375855135716
Validation loss: 2.3164128018434424

Epoch: 6| Step: 6
Training loss: 1.619310248201882
Validation loss: 2.3566740772267547

Epoch: 6| Step: 7
Training loss: 1.0171678415206566
Validation loss: 2.341696907387996

Epoch: 6| Step: 8
Training loss: 1.2129595210215554
Validation loss: 2.315711932325834

Epoch: 6| Step: 9
Training loss: 1.235200436964106
Validation loss: 2.3057288012808463

Epoch: 6| Step: 10
Training loss: 1.1106347466912159
Validation loss: 2.3161571345005645

Epoch: 6| Step: 11
Training loss: 0.6839750915629346
Validation loss: 2.321975974622515

Epoch: 6| Step: 12
Training loss: 0.9560055588596525
Validation loss: 2.3548898521724135

Epoch: 6| Step: 13
Training loss: 1.129723487375768
Validation loss: 2.347427264995726

Epoch: 306| Step: 0
Training loss: 1.1921007477280452
Validation loss: 2.3481608810385963

Epoch: 6| Step: 1
Training loss: 1.0507176036065478
Validation loss: 2.352063275970182

Epoch: 6| Step: 2
Training loss: 0.7114018192065307
Validation loss: 2.345264248093596

Epoch: 6| Step: 3
Training loss: 1.0665886132670208
Validation loss: 2.361453686226993

Epoch: 6| Step: 4
Training loss: 0.884899912363178
Validation loss: 2.3576997550584577

Epoch: 6| Step: 5
Training loss: 0.8967147232021085
Validation loss: 2.359269370480057

Epoch: 6| Step: 6
Training loss: 1.3425393972174726
Validation loss: 2.3635665397279104

Epoch: 6| Step: 7
Training loss: 0.9728083051228966
Validation loss: 2.362565999352478

Epoch: 6| Step: 8
Training loss: 1.2117026588065096
Validation loss: 2.3343768200015638

Epoch: 6| Step: 9
Training loss: 1.208542306960463
Validation loss: 2.339452333307229

Epoch: 6| Step: 10
Training loss: 1.048089248420536
Validation loss: 2.3205662855081326

Epoch: 6| Step: 11
Training loss: 0.9904441235151659
Validation loss: 2.312296582659291

Epoch: 6| Step: 12
Training loss: 1.6492244053557998
Validation loss: 2.317609115713093

Epoch: 6| Step: 13
Training loss: 1.4366067515991405
Validation loss: 2.314907885142287

Epoch: 307| Step: 0
Training loss: 0.956218202847663
Validation loss: 2.3162304788149406

Epoch: 6| Step: 1
Training loss: 1.34865398238442
Validation loss: 2.3206972132166244

Epoch: 6| Step: 2
Training loss: 1.1519500577154294
Validation loss: 2.32954684969305

Epoch: 6| Step: 3
Training loss: 1.1108680671208566
Validation loss: 2.3236957400386147

Epoch: 6| Step: 4
Training loss: 1.1406527999207476
Validation loss: 2.3345002777299255

Epoch: 6| Step: 5
Training loss: 0.952987160643222
Validation loss: 2.3363017619493545

Epoch: 6| Step: 6
Training loss: 0.9998149700645786
Validation loss: 2.38758154928831

Epoch: 6| Step: 7
Training loss: 1.0263361758293625
Validation loss: 2.3858497535640497

Epoch: 6| Step: 8
Training loss: 1.282298566157695
Validation loss: 2.4031850032008686

Epoch: 6| Step: 9
Training loss: 0.9003755646809379
Validation loss: 2.387826167902768

Epoch: 6| Step: 10
Training loss: 0.7756683083000346
Validation loss: 2.371679620416936

Epoch: 6| Step: 11
Training loss: 1.4367696316428082
Validation loss: 2.3281211481353616

Epoch: 6| Step: 12
Training loss: 1.1639083145743967
Validation loss: 2.335514943623724

Epoch: 6| Step: 13
Training loss: 1.6045921884254597
Validation loss: 2.3084346364594848

Epoch: 308| Step: 0
Training loss: 1.4715863700092402
Validation loss: 2.314220247035649

Epoch: 6| Step: 1
Training loss: 0.920302456086925
Validation loss: 2.3166897696087245

Epoch: 6| Step: 2
Training loss: 0.8351355654489664
Validation loss: 2.3256389191674196

Epoch: 6| Step: 3
Training loss: 1.4745302292760736
Validation loss: 2.341797441523887

Epoch: 6| Step: 4
Training loss: 0.9734034904306886
Validation loss: 2.3324437606473643

Epoch: 6| Step: 5
Training loss: 0.9701138402068158
Validation loss: 2.3193140551015685

Epoch: 6| Step: 6
Training loss: 1.1929949064953413
Validation loss: 2.323840914594486

Epoch: 6| Step: 7
Training loss: 0.8733908639102866
Validation loss: 2.3128640759351864

Epoch: 6| Step: 8
Training loss: 0.7157225912924013
Validation loss: 2.311845633068843

Epoch: 6| Step: 9
Training loss: 1.1171450840294008
Validation loss: 2.287237362370775

Epoch: 6| Step: 10
Training loss: 1.038878460410731
Validation loss: 2.3187795506858566

Epoch: 6| Step: 11
Training loss: 1.2005775532042628
Validation loss: 2.308817588024309

Epoch: 6| Step: 12
Training loss: 1.213841751826478
Validation loss: 2.305555604151474

Epoch: 6| Step: 13
Training loss: 1.2959597011823412
Validation loss: 2.3067667941036865

Epoch: 309| Step: 0
Training loss: 1.307949032601282
Validation loss: 2.3040757090452604

Epoch: 6| Step: 1
Training loss: 0.8964359710856921
Validation loss: 2.277766277298539

Epoch: 6| Step: 2
Training loss: 1.3775678844998291
Validation loss: 2.2837598397680314

Epoch: 6| Step: 3
Training loss: 1.0208449979362202
Validation loss: 2.2797135328499336

Epoch: 6| Step: 4
Training loss: 0.849692013985645
Validation loss: 2.282861244815654

Epoch: 6| Step: 5
Training loss: 1.3252684447223446
Validation loss: 2.2829335611474297

Epoch: 6| Step: 6
Training loss: 0.7765016835152085
Validation loss: 2.2530673265325802

Epoch: 6| Step: 7
Training loss: 1.1956104580383218
Validation loss: 2.281865588515994

Epoch: 6| Step: 8
Training loss: 1.0834198452567645
Validation loss: 2.2805447990802947

Epoch: 6| Step: 9
Training loss: 0.8725639902384535
Validation loss: 2.2716316871804993

Epoch: 6| Step: 10
Training loss: 0.9843885027246965
Validation loss: 2.277263449344028

Epoch: 6| Step: 11
Training loss: 1.035323795218991
Validation loss: 2.3137416239048068

Epoch: 6| Step: 12
Training loss: 1.2411828927053947
Validation loss: 2.349049995419628

Epoch: 6| Step: 13
Training loss: 0.8142812350814401
Validation loss: 2.3356409645004197

Epoch: 310| Step: 0
Training loss: 1.2377692767703032
Validation loss: 2.3044645601721556

Epoch: 6| Step: 1
Training loss: 1.538459156107892
Validation loss: 2.2959632294394376

Epoch: 6| Step: 2
Training loss: 0.9254105546060426
Validation loss: 2.3092184832183293

Epoch: 6| Step: 3
Training loss: 1.2806949808967936
Validation loss: 2.298494463566107

Epoch: 6| Step: 4
Training loss: 0.5694452511257051
Validation loss: 2.298144306426821

Epoch: 6| Step: 5
Training loss: 1.0958517861112003
Validation loss: 2.309759241388818

Epoch: 6| Step: 6
Training loss: 1.1703858132311515
Validation loss: 2.314480746697911

Epoch: 6| Step: 7
Training loss: 1.102611394085785
Validation loss: 2.3716826086704974

Epoch: 6| Step: 8
Training loss: 1.2407031517492402
Validation loss: 2.423785702040615

Epoch: 6| Step: 9
Training loss: 0.9596901217654311
Validation loss: 2.366915669579887

Epoch: 6| Step: 10
Training loss: 0.7867763751990654
Validation loss: 2.3351213900292698

Epoch: 6| Step: 11
Training loss: 0.8750642344194204
Validation loss: 2.2943132920905147

Epoch: 6| Step: 12
Training loss: 1.0884187193922428
Validation loss: 2.2917027341031084

Epoch: 6| Step: 13
Training loss: 1.0071255612361727
Validation loss: 2.278308630303617

Epoch: 311| Step: 0
Training loss: 1.1601392956660466
Validation loss: 2.2868606363326953

Epoch: 6| Step: 1
Training loss: 0.9285705652861722
Validation loss: 2.2746873633787366

Epoch: 6| Step: 2
Training loss: 1.2824798821847532
Validation loss: 2.270810710714894

Epoch: 6| Step: 3
Training loss: 1.175425681659178
Validation loss: 2.2717471734257204

Epoch: 6| Step: 4
Training loss: 0.82504195193351
Validation loss: 2.317380161886367

Epoch: 6| Step: 5
Training loss: 0.9955769713001005
Validation loss: 2.373972625754912

Epoch: 6| Step: 6
Training loss: 1.058316803350042
Validation loss: 2.385454178546653

Epoch: 6| Step: 7
Training loss: 1.106656033415056
Validation loss: 2.3344125335826025

Epoch: 6| Step: 8
Training loss: 1.0441735556076617
Validation loss: 2.341910896254405

Epoch: 6| Step: 9
Training loss: 0.8948020691686996
Validation loss: 2.3148707271873934

Epoch: 6| Step: 10
Training loss: 1.373922576130515
Validation loss: 2.299113380763077

Epoch: 6| Step: 11
Training loss: 1.1733010325718023
Validation loss: 2.309513287374769

Epoch: 6| Step: 12
Training loss: 0.9855529760775904
Validation loss: 2.3128585116257203

Epoch: 6| Step: 13
Training loss: 1.3571424018170732
Validation loss: 2.3130579161499356

Epoch: 312| Step: 0
Training loss: 0.8915132476755154
Validation loss: 2.313631077676778

Epoch: 6| Step: 1
Training loss: 1.191375832091207
Validation loss: 2.3818690007718826

Epoch: 6| Step: 2
Training loss: 1.169927886794602
Validation loss: 2.390722586055359

Epoch: 6| Step: 3
Training loss: 0.949523657033497
Validation loss: 2.422446006231515

Epoch: 6| Step: 4
Training loss: 1.2501307895901284
Validation loss: 2.395155643815423

Epoch: 6| Step: 5
Training loss: 1.0376123045841008
Validation loss: 2.345493121831056

Epoch: 6| Step: 6
Training loss: 0.9455839035473088
Validation loss: 2.3152744497230366

Epoch: 6| Step: 7
Training loss: 1.347775617095279
Validation loss: 2.329590237167516

Epoch: 6| Step: 8
Training loss: 1.300960173344003
Validation loss: 2.3403675044333934

Epoch: 6| Step: 9
Training loss: 1.2748133242212125
Validation loss: 2.3166768843640244

Epoch: 6| Step: 10
Training loss: 0.7807116370155557
Validation loss: 2.309650700072536

Epoch: 6| Step: 11
Training loss: 1.249338594930053
Validation loss: 2.3477399721474925

Epoch: 6| Step: 12
Training loss: 0.5973740453718451
Validation loss: 2.3630566193185434

Epoch: 6| Step: 13
Training loss: 0.5792820924093337
Validation loss: 2.426060176031253

Epoch: 313| Step: 0
Training loss: 1.0603847766170549
Validation loss: 2.4384612098972203

Epoch: 6| Step: 1
Training loss: 1.5149243495170053
Validation loss: 2.4249357383086427

Epoch: 6| Step: 2
Training loss: 0.8295069984890407
Validation loss: 2.377295090550679

Epoch: 6| Step: 3
Training loss: 1.0428382134632526
Validation loss: 2.337217728524654

Epoch: 6| Step: 4
Training loss: 0.9267848566609411
Validation loss: 2.296093578234152

Epoch: 6| Step: 5
Training loss: 0.864989028486229
Validation loss: 2.300685353043127

Epoch: 6| Step: 6
Training loss: 1.0495840293172236
Validation loss: 2.3083761128691087

Epoch: 6| Step: 7
Training loss: 1.1071321623149395
Validation loss: 2.3062982418931672

Epoch: 6| Step: 8
Training loss: 1.1881536893074809
Validation loss: 2.3097683515681218

Epoch: 6| Step: 9
Training loss: 1.1234238497736437
Validation loss: 2.317760319188403

Epoch: 6| Step: 10
Training loss: 0.7330343305190715
Validation loss: 2.3351737278096167

Epoch: 6| Step: 11
Training loss: 1.4296378872293798
Validation loss: 2.349093100703536

Epoch: 6| Step: 12
Training loss: 1.0590311533278292
Validation loss: 2.333407434555496

Epoch: 6| Step: 13
Training loss: 0.4700632138048394
Validation loss: 2.3306764170583345

Epoch: 314| Step: 0
Training loss: 0.9506698630918113
Validation loss: 2.3189011114397466

Epoch: 6| Step: 1
Training loss: 0.9099976233566605
Validation loss: 2.3058270673294867

Epoch: 6| Step: 2
Training loss: 1.4213689385589239
Validation loss: 2.3172700370517125

Epoch: 6| Step: 3
Training loss: 0.9980682549920746
Validation loss: 2.308307386819417

Epoch: 6| Step: 4
Training loss: 1.1324734410588508
Validation loss: 2.2837944029022488

Epoch: 6| Step: 5
Training loss: 1.004691206716104
Validation loss: 2.2952491497918888

Epoch: 6| Step: 6
Training loss: 1.006614327670094
Validation loss: 2.3055063618968443

Epoch: 6| Step: 7
Training loss: 1.0989071922997902
Validation loss: 2.3085793892646764

Epoch: 6| Step: 8
Training loss: 1.132077735172864
Validation loss: 2.323421376169193

Epoch: 6| Step: 9
Training loss: 0.5572056629688664
Validation loss: 2.338377285321936

Epoch: 6| Step: 10
Training loss: 1.19437556228345
Validation loss: 2.3358898382276534

Epoch: 6| Step: 11
Training loss: 0.8861445782027266
Validation loss: 2.352207875714604

Epoch: 6| Step: 12
Training loss: 0.9159779164700675
Validation loss: 2.3382159565200817

Epoch: 6| Step: 13
Training loss: 0.9718349006942002
Validation loss: 2.366585467221066

Epoch: 315| Step: 0
Training loss: 1.4142531798557774
Validation loss: 2.3644777492773277

Epoch: 6| Step: 1
Training loss: 0.8732825863511103
Validation loss: 2.3821908781132533

Epoch: 6| Step: 2
Training loss: 0.9471142834765354
Validation loss: 2.3413693205716553

Epoch: 6| Step: 3
Training loss: 0.9836510918031752
Validation loss: 2.3605775007767824

Epoch: 6| Step: 4
Training loss: 0.9408317490782012
Validation loss: 2.3543554646496654

Epoch: 6| Step: 5
Training loss: 1.101601674350527
Validation loss: 2.325583231681515

Epoch: 6| Step: 6
Training loss: 1.2135659516923898
Validation loss: 2.339530421354604

Epoch: 6| Step: 7
Training loss: 1.1562768056700639
Validation loss: 2.348346322066643

Epoch: 6| Step: 8
Training loss: 0.6622020915333384
Validation loss: 2.340530175670048

Epoch: 6| Step: 9
Training loss: 0.9670015985304077
Validation loss: 2.351527738070645

Epoch: 6| Step: 10
Training loss: 0.7293584616779223
Validation loss: 2.365331840212416

Epoch: 6| Step: 11
Training loss: 0.9001931327649421
Validation loss: 2.4000231363606703

Epoch: 6| Step: 12
Training loss: 0.6962320911699869
Validation loss: 2.360156373133498

Epoch: 6| Step: 13
Training loss: 1.3917486387465083
Validation loss: 2.365119163953644

Epoch: 316| Step: 0
Training loss: 1.2822914542914101
Validation loss: 2.333820498900393

Epoch: 6| Step: 1
Training loss: 0.886190114008904
Validation loss: 2.32667142213262

Epoch: 6| Step: 2
Training loss: 0.6832999551769986
Validation loss: 2.312739241534761

Epoch: 6| Step: 3
Training loss: 1.0782043870086946
Validation loss: 2.3212894402060944

Epoch: 6| Step: 4
Training loss: 1.0593680615043162
Validation loss: 2.2983435832310266

Epoch: 6| Step: 5
Training loss: 1.176000885077552
Validation loss: 2.30323502739755

Epoch: 6| Step: 6
Training loss: 0.6582112750445902
Validation loss: 2.3202371865082445

Epoch: 6| Step: 7
Training loss: 0.9854740183931218
Validation loss: 2.33721090484217

Epoch: 6| Step: 8
Training loss: 0.8765767060622949
Validation loss: 2.334704799938918

Epoch: 6| Step: 9
Training loss: 0.5857248047389184
Validation loss: 2.352111678146739

Epoch: 6| Step: 10
Training loss: 1.045874045948657
Validation loss: 2.352852527432642

Epoch: 6| Step: 11
Training loss: 1.3568347127548408
Validation loss: 2.3563068936498226

Epoch: 6| Step: 12
Training loss: 1.1201765182732404
Validation loss: 2.359016167878638

Epoch: 6| Step: 13
Training loss: 0.4898223513320401
Validation loss: 2.374205704200799

Epoch: 317| Step: 0
Training loss: 0.8428119106948371
Validation loss: 2.339904242029489

Epoch: 6| Step: 1
Training loss: 1.056808712153364
Validation loss: 2.3328580313628677

Epoch: 6| Step: 2
Training loss: 0.7878797750714148
Validation loss: 2.3414052838906727

Epoch: 6| Step: 3
Training loss: 1.0952090749193255
Validation loss: 2.3593056004463477

Epoch: 6| Step: 4
Training loss: 1.0478856915749073
Validation loss: 2.3980827212109794

Epoch: 6| Step: 5
Training loss: 1.1545598848720395
Validation loss: 2.4131817016438246

Epoch: 6| Step: 6
Training loss: 0.8886694268832179
Validation loss: 2.393389327264054

Epoch: 6| Step: 7
Training loss: 0.8430505962075827
Validation loss: 2.355747673912363

Epoch: 6| Step: 8
Training loss: 1.150474972700962
Validation loss: 2.3256504881781233

Epoch: 6| Step: 9
Training loss: 0.7819514368202721
Validation loss: 2.307198091307233

Epoch: 6| Step: 10
Training loss: 1.2097055382690647
Validation loss: 2.278032519985288

Epoch: 6| Step: 11
Training loss: 1.0884522883516503
Validation loss: 2.2919947958887166

Epoch: 6| Step: 12
Training loss: 0.9420669896123778
Validation loss: 2.328503557210987

Epoch: 6| Step: 13
Training loss: 0.8525951318994254
Validation loss: 2.300654597757007

Epoch: 318| Step: 0
Training loss: 1.0924992085155003
Validation loss: 2.2902436977975387

Epoch: 6| Step: 1
Training loss: 1.1410074507313752
Validation loss: 2.3280277335112687

Epoch: 6| Step: 2
Training loss: 0.8331313047292124
Validation loss: 2.313582126419354

Epoch: 6| Step: 3
Training loss: 0.9061154232732048
Validation loss: 2.3420920531458735

Epoch: 6| Step: 4
Training loss: 1.0537542664791089
Validation loss: 2.3486266812783936

Epoch: 6| Step: 5
Training loss: 1.0381748165003226
Validation loss: 2.3628398334203733

Epoch: 6| Step: 6
Training loss: 0.6707284148329978
Validation loss: 2.383852676537787

Epoch: 6| Step: 7
Training loss: 0.9843894715229347
Validation loss: 2.400592758164202

Epoch: 6| Step: 8
Training loss: 1.2057202574343777
Validation loss: 2.3599408916293263

Epoch: 6| Step: 9
Training loss: 0.9591755103546764
Validation loss: 2.329803258868192

Epoch: 6| Step: 10
Training loss: 0.8910384306106748
Validation loss: 2.283813030182867

Epoch: 6| Step: 11
Training loss: 0.7817113277213321
Validation loss: 2.294985196530113

Epoch: 6| Step: 12
Training loss: 0.9126685182869823
Validation loss: 2.2941820616043334

Epoch: 6| Step: 13
Training loss: 1.0305763124864429
Validation loss: 2.2844889403134863

Epoch: 319| Step: 0
Training loss: 0.9435744267528775
Validation loss: 2.2816017639353094

Epoch: 6| Step: 1
Training loss: 1.0424539388456777
Validation loss: 2.2877168537029497

Epoch: 6| Step: 2
Training loss: 0.936095011453506
Validation loss: 2.3015292990486187

Epoch: 6| Step: 3
Training loss: 0.7649237866553598
Validation loss: 2.3266479338984176

Epoch: 6| Step: 4
Training loss: 0.725788483516917
Validation loss: 2.3511736748029852

Epoch: 6| Step: 5
Training loss: 0.7704947389525778
Validation loss: 2.3771529577843844

Epoch: 6| Step: 6
Training loss: 1.1463937024941144
Validation loss: 2.3642955686421994

Epoch: 6| Step: 7
Training loss: 1.2418781591105488
Validation loss: 2.3398916982681754

Epoch: 6| Step: 8
Training loss: 1.154515589407654
Validation loss: 2.330275879998515

Epoch: 6| Step: 9
Training loss: 1.140934262089561
Validation loss: 2.3030214650937793

Epoch: 6| Step: 10
Training loss: 1.2523352743470013
Validation loss: 2.290341571582963

Epoch: 6| Step: 11
Training loss: 0.976191763123828
Validation loss: 2.3018919316227686

Epoch: 6| Step: 12
Training loss: 0.859006213040248
Validation loss: 2.2907919404780266

Epoch: 6| Step: 13
Training loss: 0.8401179376188124
Validation loss: 2.299744883054219

Epoch: 320| Step: 0
Training loss: 1.1043941815215756
Validation loss: 2.3157754176844647

Epoch: 6| Step: 1
Training loss: 0.7082431165425996
Validation loss: 2.3803908860882763

Epoch: 6| Step: 2
Training loss: 1.3232635383713376
Validation loss: 2.3725570080593874

Epoch: 6| Step: 3
Training loss: 0.9378569876959478
Validation loss: 2.4093132481323156

Epoch: 6| Step: 4
Training loss: 0.8873833673697684
Validation loss: 2.387297868711391

Epoch: 6| Step: 5
Training loss: 1.187804835494759
Validation loss: 2.337242672473983

Epoch: 6| Step: 6
Training loss: 0.89619577453952
Validation loss: 2.307440042406587

Epoch: 6| Step: 7
Training loss: 1.092998028159217
Validation loss: 2.2980112403548962

Epoch: 6| Step: 8
Training loss: 0.5272047636758983
Validation loss: 2.3020412742088623

Epoch: 6| Step: 9
Training loss: 1.0693604627609936
Validation loss: 2.307747653440011

Epoch: 6| Step: 10
Training loss: 0.7490620310960558
Validation loss: 2.3243303699047657

Epoch: 6| Step: 11
Training loss: 0.7185471289885993
Validation loss: 2.331671351049922

Epoch: 6| Step: 12
Training loss: 1.0175542846932877
Validation loss: 2.312871683056128

Epoch: 6| Step: 13
Training loss: 0.885947946961181
Validation loss: 2.3237182684992517

Epoch: 321| Step: 0
Training loss: 0.9247361412546475
Validation loss: 2.2733122665643584

Epoch: 6| Step: 1
Training loss: 0.7861069953422805
Validation loss: 2.2590283004701814

Epoch: 6| Step: 2
Training loss: 0.8551023560877079
Validation loss: 2.278899566071255

Epoch: 6| Step: 3
Training loss: 0.8746321109135375
Validation loss: 2.284764103757494

Epoch: 6| Step: 4
Training loss: 1.2120246191262636
Validation loss: 2.282898711535394

Epoch: 6| Step: 5
Training loss: 0.4454361258783043
Validation loss: 2.3153098190708623

Epoch: 6| Step: 6
Training loss: 0.9512970076386493
Validation loss: 2.3725873137462234

Epoch: 6| Step: 7
Training loss: 1.1199286916716267
Validation loss: 2.4444531778590988

Epoch: 6| Step: 8
Training loss: 0.7714914828588708
Validation loss: 2.3698515071207855

Epoch: 6| Step: 9
Training loss: 0.9407338000262889
Validation loss: 2.331537244502276

Epoch: 6| Step: 10
Training loss: 0.9829410826682697
Validation loss: 2.2894698844483936

Epoch: 6| Step: 11
Training loss: 0.951949880388606
Validation loss: 2.305428051041054

Epoch: 6| Step: 12
Training loss: 1.3962294552622585
Validation loss: 2.31184640598257

Epoch: 6| Step: 13
Training loss: 1.2693808598573288
Validation loss: 2.3011654016857532

Epoch: 322| Step: 0
Training loss: 0.6770937307488686
Validation loss: 2.288990879614834

Epoch: 6| Step: 1
Training loss: 0.6984769839875465
Validation loss: 2.3090459528106546

Epoch: 6| Step: 2
Training loss: 0.8527647158947471
Validation loss: 2.336288581058648

Epoch: 6| Step: 3
Training loss: 0.921402050187927
Validation loss: 2.367367951762978

Epoch: 6| Step: 4
Training loss: 1.0195878404133936
Validation loss: 2.3949065189810357

Epoch: 6| Step: 5
Training loss: 1.2073574181009263
Validation loss: 2.419449986292534

Epoch: 6| Step: 6
Training loss: 0.7867576248580097
Validation loss: 2.414227061734677

Epoch: 6| Step: 7
Training loss: 1.0936329915265608
Validation loss: 2.3796802889214432

Epoch: 6| Step: 8
Training loss: 0.8712913391726588
Validation loss: 2.331906065261564

Epoch: 6| Step: 9
Training loss: 1.0025877848025835
Validation loss: 2.3174765986842853

Epoch: 6| Step: 10
Training loss: 1.245596568256372
Validation loss: 2.3075308519634743

Epoch: 6| Step: 11
Training loss: 1.077514475572537
Validation loss: 2.3263626580393884

Epoch: 6| Step: 12
Training loss: 1.000302388248264
Validation loss: 2.317559777799385

Epoch: 6| Step: 13
Training loss: 0.32310353788896423
Validation loss: 2.3557392508481216

Epoch: 323| Step: 0
Training loss: 1.0100634963783235
Validation loss: 2.369499235197698

Epoch: 6| Step: 1
Training loss: 1.0389111630935606
Validation loss: 2.4282962860023005

Epoch: 6| Step: 2
Training loss: 1.052416865039766
Validation loss: 2.3945396977372146

Epoch: 6| Step: 3
Training loss: 1.0098802512535574
Validation loss: 2.3783087746678144

Epoch: 6| Step: 4
Training loss: 0.9574150717099421
Validation loss: 2.346351122482281

Epoch: 6| Step: 5
Training loss: 0.9078851614941075
Validation loss: 2.328284101878353

Epoch: 6| Step: 6
Training loss: 1.0766395618778652
Validation loss: 2.3147356921338296

Epoch: 6| Step: 7
Training loss: 0.9006012444735135
Validation loss: 2.2969051747240594

Epoch: 6| Step: 8
Training loss: 0.99073053754489
Validation loss: 2.3175915553967332

Epoch: 6| Step: 9
Training loss: 1.1254173140586923
Validation loss: 2.2839409452298822

Epoch: 6| Step: 10
Training loss: 0.5626470055809875
Validation loss: 2.277905458238595

Epoch: 6| Step: 11
Training loss: 0.8487842279872616
Validation loss: 2.3222469584128276

Epoch: 6| Step: 12
Training loss: 0.9843343393314421
Validation loss: 2.3539982845393785

Epoch: 6| Step: 13
Training loss: 0.839833849471531
Validation loss: 2.3738887458761266

Epoch: 324| Step: 0
Training loss: 1.070161460744587
Validation loss: 2.3367922155455

Epoch: 6| Step: 1
Training loss: 0.7409853384598368
Validation loss: 2.301497624933088

Epoch: 6| Step: 2
Training loss: 1.163839690115187
Validation loss: 2.2931409508658573

Epoch: 6| Step: 3
Training loss: 0.658352322747192
Validation loss: 2.2895857110021836

Epoch: 6| Step: 4
Training loss: 0.9486659445738663
Validation loss: 2.277443790118785

Epoch: 6| Step: 5
Training loss: 1.0494732852641626
Validation loss: 2.287058354032813

Epoch: 6| Step: 6
Training loss: 1.0617941587501931
Validation loss: 2.2858608183727056

Epoch: 6| Step: 7
Training loss: 0.7076455077174891
Validation loss: 2.3414572359537527

Epoch: 6| Step: 8
Training loss: 0.7714444693372865
Validation loss: 2.3766404624572126

Epoch: 6| Step: 9
Training loss: 0.769633484841174
Validation loss: 2.3720681963693875

Epoch: 6| Step: 10
Training loss: 1.3278623433408105
Validation loss: 2.3875466417617575

Epoch: 6| Step: 11
Training loss: 0.7674179880765514
Validation loss: 2.3736369620892734

Epoch: 6| Step: 12
Training loss: 0.7836646720152858
Validation loss: 2.357926517149223

Epoch: 6| Step: 13
Training loss: 0.6777422681893006
Validation loss: 2.3189234366305587

Epoch: 325| Step: 0
Training loss: 1.0847258909789979
Validation loss: 2.2959922962248847

Epoch: 6| Step: 1
Training loss: 0.9902758467377366
Validation loss: 2.286939321794812

Epoch: 6| Step: 2
Training loss: 0.7038284174050168
Validation loss: 2.2718708885119447

Epoch: 6| Step: 3
Training loss: 0.7868998890062148
Validation loss: 2.2760594341639324

Epoch: 6| Step: 4
Training loss: 1.12317095527183
Validation loss: 2.2996281167146604

Epoch: 6| Step: 5
Training loss: 0.6710740571690902
Validation loss: 2.325074484376646

Epoch: 6| Step: 6
Training loss: 1.2606189292266026
Validation loss: 2.365271096718324

Epoch: 6| Step: 7
Training loss: 0.8442825120466831
Validation loss: 2.3597842647056555

Epoch: 6| Step: 8
Training loss: 1.0648187132009994
Validation loss: 2.3814704783260487

Epoch: 6| Step: 9
Training loss: 0.8505713267774094
Validation loss: 2.314902836834035

Epoch: 6| Step: 10
Training loss: 0.6536274004359768
Validation loss: 2.261985847340668

Epoch: 6| Step: 11
Training loss: 0.8308152818839136
Validation loss: 2.2545953441763973

Epoch: 6| Step: 12
Training loss: 0.7983657506069812
Validation loss: 2.285586080836834

Epoch: 6| Step: 13
Training loss: 0.6611310995465716
Validation loss: 2.239387371612255

Epoch: 326| Step: 0
Training loss: 1.0344202267996225
Validation loss: 2.2490591112327336

Epoch: 6| Step: 1
Training loss: 0.9524947412100373
Validation loss: 2.2834239854894633

Epoch: 6| Step: 2
Training loss: 0.8329024790525097
Validation loss: 2.33890340686538

Epoch: 6| Step: 3
Training loss: 0.8908424112079254
Validation loss: 2.369440038629865

Epoch: 6| Step: 4
Training loss: 0.9996815114678149
Validation loss: 2.4078362931719224

Epoch: 6| Step: 5
Training loss: 0.8559352003709388
Validation loss: 2.3816550426701384

Epoch: 6| Step: 6
Training loss: 0.7326877365782253
Validation loss: 2.303771559276581

Epoch: 6| Step: 7
Training loss: 0.87877718507654
Validation loss: 2.2515685027638406

Epoch: 6| Step: 8
Training loss: 1.2315120089058098
Validation loss: 2.297377280243563

Epoch: 6| Step: 9
Training loss: 1.1138681036155929
Validation loss: 2.25449508084584

Epoch: 6| Step: 10
Training loss: 0.9661627028535695
Validation loss: 2.265134385580506

Epoch: 6| Step: 11
Training loss: 0.8910777630978063
Validation loss: 2.303427769185735

Epoch: 6| Step: 12
Training loss: 0.6652323572169652
Validation loss: 2.299264593022323

Epoch: 6| Step: 13
Training loss: 1.1336694041481454
Validation loss: 2.3461458295033366

Epoch: 327| Step: 0
Training loss: 1.19465549339309
Validation loss: 2.3777378473611446

Epoch: 6| Step: 1
Training loss: 0.8587638068720335
Validation loss: 2.3628554321669473

Epoch: 6| Step: 2
Training loss: 0.8645552473600299
Validation loss: 2.316903447952089

Epoch: 6| Step: 3
Training loss: 0.515685338044573
Validation loss: 2.341254171933819

Epoch: 6| Step: 4
Training loss: 0.9981491723235891
Validation loss: 2.3258003432791416

Epoch: 6| Step: 5
Training loss: 0.964923191275049
Validation loss: 2.3351121943205007

Epoch: 6| Step: 6
Training loss: 0.830012778907665
Validation loss: 2.3302805149034844

Epoch: 6| Step: 7
Training loss: 0.5388521806950833
Validation loss: 2.323449472730197

Epoch: 6| Step: 8
Training loss: 0.9895681513910025
Validation loss: 2.329530817164181

Epoch: 6| Step: 9
Training loss: 1.0369659152190933
Validation loss: 2.351693779810362

Epoch: 6| Step: 10
Training loss: 1.00413943896175
Validation loss: 2.354521191562529

Epoch: 6| Step: 11
Training loss: 0.576615450528811
Validation loss: 2.374309973872432

Epoch: 6| Step: 12
Training loss: 0.8595603049505484
Validation loss: 2.3781475233433

Epoch: 6| Step: 13
Training loss: 1.5040356865210132
Validation loss: 2.376978925710077

Epoch: 328| Step: 0
Training loss: 1.0597483401887335
Validation loss: 2.3542999222967134

Epoch: 6| Step: 1
Training loss: 0.587272192027806
Validation loss: 2.321687250983858

Epoch: 6| Step: 2
Training loss: 0.4811918198728156
Validation loss: 2.2982658487378567

Epoch: 6| Step: 3
Training loss: 0.9568177899899604
Validation loss: 2.2820656431265283

Epoch: 6| Step: 4
Training loss: 0.961520506617829
Validation loss: 2.285519533157516

Epoch: 6| Step: 5
Training loss: 0.7634605251842147
Validation loss: 2.280222198366672

Epoch: 6| Step: 6
Training loss: 0.9721017198967099
Validation loss: 2.2685943195062523

Epoch: 6| Step: 7
Training loss: 1.0055428312408676
Validation loss: 2.252118975778189

Epoch: 6| Step: 8
Training loss: 0.7651357839416753
Validation loss: 2.271254017523429

Epoch: 6| Step: 9
Training loss: 1.0458470892033196
Validation loss: 2.302014145827388

Epoch: 6| Step: 10
Training loss: 0.8783280568866175
Validation loss: 2.352178018072482

Epoch: 6| Step: 11
Training loss: 1.0223987928449043
Validation loss: 2.35956327413397

Epoch: 6| Step: 12
Training loss: 0.9334308370397743
Validation loss: 2.366134218077628

Epoch: 6| Step: 13
Training loss: 0.9787829066429052
Validation loss: 2.336930672415418

Epoch: 329| Step: 0
Training loss: 0.7861766731868641
Validation loss: 2.311117980397349

Epoch: 6| Step: 1
Training loss: 0.69688195537295
Validation loss: 2.296606634558504

Epoch: 6| Step: 2
Training loss: 0.9576742697906439
Validation loss: 2.300374921457933

Epoch: 6| Step: 3
Training loss: 0.91942840752985
Validation loss: 2.304440825567784

Epoch: 6| Step: 4
Training loss: 0.952955137031424
Validation loss: 2.320370125920755

Epoch: 6| Step: 5
Training loss: 0.9368928850844948
Validation loss: 2.3204219678077047

Epoch: 6| Step: 6
Training loss: 0.8142697793433948
Validation loss: 2.3421565971992053

Epoch: 6| Step: 7
Training loss: 1.0194957040019912
Validation loss: 2.3502372343553777

Epoch: 6| Step: 8
Training loss: 0.6786810998738686
Validation loss: 2.3347682580284146

Epoch: 6| Step: 9
Training loss: 0.5995455033768115
Validation loss: 2.3395402188176835

Epoch: 6| Step: 10
Training loss: 0.8796079420089399
Validation loss: 2.339485053174371

Epoch: 6| Step: 11
Training loss: 1.043531915872085
Validation loss: 2.3310685457504285

Epoch: 6| Step: 12
Training loss: 0.736171675435804
Validation loss: 2.3052726707675433

Epoch: 6| Step: 13
Training loss: 1.028991827740484
Validation loss: 2.2940230810855957

Epoch: 330| Step: 0
Training loss: 0.9509380139247021
Validation loss: 2.2860419132692855

Epoch: 6| Step: 1
Training loss: 0.6828425394254982
Validation loss: 2.3157629812383345

Epoch: 6| Step: 2
Training loss: 0.6731139226584629
Validation loss: 2.2751301855417125

Epoch: 6| Step: 3
Training loss: 0.8136614787389425
Validation loss: 2.288398619246599

Epoch: 6| Step: 4
Training loss: 0.8420771864513027
Validation loss: 2.297644816476718

Epoch: 6| Step: 5
Training loss: 0.7374994892183249
Validation loss: 2.3024770496250686

Epoch: 6| Step: 6
Training loss: 0.7094499304768499
Validation loss: 2.324416345056105

Epoch: 6| Step: 7
Training loss: 0.9658899233951097
Validation loss: 2.353529066693255

Epoch: 6| Step: 8
Training loss: 0.796731711576027
Validation loss: 2.361987625365425

Epoch: 6| Step: 9
Training loss: 0.8431319339543419
Validation loss: 2.4135931907322523

Epoch: 6| Step: 10
Training loss: 1.2715739088280251
Validation loss: 2.387971943014984

Epoch: 6| Step: 11
Training loss: 1.0112008201419245
Validation loss: 2.3542805977260306

Epoch: 6| Step: 12
Training loss: 0.8666314756755912
Validation loss: 2.3162814471246405

Epoch: 6| Step: 13
Training loss: 0.6646253108177584
Validation loss: 2.3315526837756066

Epoch: 331| Step: 0
Training loss: 1.0415962704077544
Validation loss: 2.301459332037912

Epoch: 6| Step: 1
Training loss: 0.8731743636270488
Validation loss: 2.3123205659091233

Epoch: 6| Step: 2
Training loss: 1.0715389603559877
Validation loss: 2.3315602398175623

Epoch: 6| Step: 3
Training loss: 0.7664162575848987
Validation loss: 2.2921138927397773

Epoch: 6| Step: 4
Training loss: 0.6268408844204013
Validation loss: 2.278183683767719

Epoch: 6| Step: 5
Training loss: 0.7233840164616694
Validation loss: 2.319267326199365

Epoch: 6| Step: 6
Training loss: 0.915227880711294
Validation loss: 2.356130639319747

Epoch: 6| Step: 7
Training loss: 1.2783749585459858
Validation loss: 2.386967238647856

Epoch: 6| Step: 8
Training loss: 0.9671487803558515
Validation loss: 2.393015977960586

Epoch: 6| Step: 9
Training loss: 0.652745745483933
Validation loss: 2.35467882780596

Epoch: 6| Step: 10
Training loss: 1.1187131907625096
Validation loss: 2.3431072565192155

Epoch: 6| Step: 11
Training loss: 0.6915503314051311
Validation loss: 2.2810884363149797

Epoch: 6| Step: 12
Training loss: 0.80669389969068
Validation loss: 2.277201381405361

Epoch: 6| Step: 13
Training loss: 0.5008169890459276
Validation loss: 2.286844079772578

Epoch: 332| Step: 0
Training loss: 0.8185591351464037
Validation loss: 2.291166879367949

Epoch: 6| Step: 1
Training loss: 0.5342999589666215
Validation loss: 2.2972358094865015

Epoch: 6| Step: 2
Training loss: 0.8214332553777369
Validation loss: 2.286919007648448

Epoch: 6| Step: 3
Training loss: 1.0141237166960957
Validation loss: 2.3184292261962622

Epoch: 6| Step: 4
Training loss: 0.7676825610061502
Validation loss: 2.336524437753972

Epoch: 6| Step: 5
Training loss: 0.7632515767790585
Validation loss: 2.3454772032216304

Epoch: 6| Step: 6
Training loss: 0.40639375930710325
Validation loss: 2.3854404642978175

Epoch: 6| Step: 7
Training loss: 0.8145741251614477
Validation loss: 2.376587881493819

Epoch: 6| Step: 8
Training loss: 0.9373652043393506
Validation loss: 2.354956790954493

Epoch: 6| Step: 9
Training loss: 0.8330278472458825
Validation loss: 2.3227749036362035

Epoch: 6| Step: 10
Training loss: 0.8673729912954101
Validation loss: 2.2985592514787423

Epoch: 6| Step: 11
Training loss: 1.2853097563087568
Validation loss: 2.3113792838872596

Epoch: 6| Step: 12
Training loss: 0.8523328953514222
Validation loss: 2.2948943999388414

Epoch: 6| Step: 13
Training loss: 0.6790880212319678
Validation loss: 2.29057735122769

Epoch: 333| Step: 0
Training loss: 0.7493911894766744
Validation loss: 2.321650337353094

Epoch: 6| Step: 1
Training loss: 0.8367732495992042
Validation loss: 2.3170969723751886

Epoch: 6| Step: 2
Training loss: 0.6654532734884337
Validation loss: 2.290404286603291

Epoch: 6| Step: 3
Training loss: 0.6262511366797694
Validation loss: 2.301554156388259

Epoch: 6| Step: 4
Training loss: 0.9384180977638831
Validation loss: 2.3177116586666626

Epoch: 6| Step: 5
Training loss: 0.9303507963120448
Validation loss: 2.3122940348678567

Epoch: 6| Step: 6
Training loss: 0.927536150184119
Validation loss: 2.297729981538681

Epoch: 6| Step: 7
Training loss: 1.0056086848176038
Validation loss: 2.3148970688086052

Epoch: 6| Step: 8
Training loss: 0.6205388595407251
Validation loss: 2.323529223448782

Epoch: 6| Step: 9
Training loss: 0.7983925524935696
Validation loss: 2.2861751657901204

Epoch: 6| Step: 10
Training loss: 0.8324760000532585
Validation loss: 2.3252523863258903

Epoch: 6| Step: 11
Training loss: 0.7859613267081537
Validation loss: 2.301429931613423

Epoch: 6| Step: 12
Training loss: 0.44150138774947495
Validation loss: 2.3030044620071677

Epoch: 6| Step: 13
Training loss: 1.175051541922705
Validation loss: 2.294698851672275

Epoch: 334| Step: 0
Training loss: 0.9571304892643749
Validation loss: 2.2697155871432138

Epoch: 6| Step: 1
Training loss: 0.6966415946691031
Validation loss: 2.288933176583617

Epoch: 6| Step: 2
Training loss: 0.7584318795642302
Validation loss: 2.2955083865837214

Epoch: 6| Step: 3
Training loss: 0.9702555739555476
Validation loss: 2.2786864090689383

Epoch: 6| Step: 4
Training loss: 0.41723547098909913
Validation loss: 2.303311506761881

Epoch: 6| Step: 5
Training loss: 1.0409643794001755
Validation loss: 2.3196912375529783

Epoch: 6| Step: 6
Training loss: 0.6307565705708973
Validation loss: 2.3591210491373356

Epoch: 6| Step: 7
Training loss: 0.759205511197144
Validation loss: 2.3422569742424253

Epoch: 6| Step: 8
Training loss: 0.7951330330941706
Validation loss: 2.3060022996506557

Epoch: 6| Step: 9
Training loss: 0.5179450120276418
Validation loss: 2.291000721024525

Epoch: 6| Step: 10
Training loss: 0.87189019576199
Validation loss: 2.2631101088087147

Epoch: 6| Step: 11
Training loss: 0.8468914185230988
Validation loss: 2.255258830496807

Epoch: 6| Step: 12
Training loss: 0.9782812024274765
Validation loss: 2.254290667840601

Epoch: 6| Step: 13
Training loss: 0.8918933537177948
Validation loss: 2.2747935474019836

Epoch: 335| Step: 0
Training loss: 0.8188683649946402
Validation loss: 2.2564452989117503

Epoch: 6| Step: 1
Training loss: 0.9182928933402945
Validation loss: 2.2615513440041672

Epoch: 6| Step: 2
Training loss: 0.5422205538389633
Validation loss: 2.28280479342986

Epoch: 6| Step: 3
Training loss: 0.9252786036360177
Validation loss: 2.2796720103315553

Epoch: 6| Step: 4
Training loss: 0.7623391388231582
Validation loss: 2.272613573427843

Epoch: 6| Step: 5
Training loss: 0.46478312762236473
Validation loss: 2.2680463672848

Epoch: 6| Step: 6
Training loss: 0.8538065748333745
Validation loss: 2.2874077133963677

Epoch: 6| Step: 7
Training loss: 0.7250490731041028
Validation loss: 2.3207393146097233

Epoch: 6| Step: 8
Training loss: 0.9205788374318786
Validation loss: 2.2937129851006275

Epoch: 6| Step: 9
Training loss: 0.5394989403032815
Validation loss: 2.3048223051090178

Epoch: 6| Step: 10
Training loss: 0.647136324927283
Validation loss: 2.302728961002102

Epoch: 6| Step: 11
Training loss: 0.8604863696617496
Validation loss: 2.2880252945310158

Epoch: 6| Step: 12
Training loss: 1.0086152775459334
Validation loss: 2.2745466538537626

Epoch: 6| Step: 13
Training loss: 1.0121178152953683
Validation loss: 2.2640758973757666

Epoch: 336| Step: 0
Training loss: 0.7188213561752729
Validation loss: 2.2826519152188776

Epoch: 6| Step: 1
Training loss: 0.8344204408080311
Validation loss: 2.2790870948514885

Epoch: 6| Step: 2
Training loss: 0.679029694496377
Validation loss: 2.286621089825982

Epoch: 6| Step: 3
Training loss: 0.44367337975748106
Validation loss: 2.3021501208407655

Epoch: 6| Step: 4
Training loss: 0.8547900220343951
Validation loss: 2.3073800392109205

Epoch: 6| Step: 5
Training loss: 1.0387890678247682
Validation loss: 2.308362326064736

Epoch: 6| Step: 6
Training loss: 0.831782451557255
Validation loss: 2.328023570944764

Epoch: 6| Step: 7
Training loss: 0.73260540506544
Validation loss: 2.3013593509880814

Epoch: 6| Step: 8
Training loss: 0.617033540862007
Validation loss: 2.310220115007135

Epoch: 6| Step: 9
Training loss: 0.980803170487163
Validation loss: 2.272714867422828

Epoch: 6| Step: 10
Training loss: 0.60917268964901
Validation loss: 2.270827596980249

Epoch: 6| Step: 11
Training loss: 0.9813009431091771
Validation loss: 2.276571072612338

Epoch: 6| Step: 12
Training loss: 0.8019151428711889
Validation loss: 2.2827966919327833

Epoch: 6| Step: 13
Training loss: 0.6592367642028367
Validation loss: 2.286203186328784

Epoch: 337| Step: 0
Training loss: 0.4270383144314953
Validation loss: 2.2996957811362617

Epoch: 6| Step: 1
Training loss: 0.7904594067038139
Validation loss: 2.3206680990468045

Epoch: 6| Step: 2
Training loss: 0.9105999564953582
Validation loss: 2.3112105555219835

Epoch: 6| Step: 3
Training loss: 0.8128714079374948
Validation loss: 2.325437052438621

Epoch: 6| Step: 4
Training loss: 0.8435025735396384
Validation loss: 2.338584982999349

Epoch: 6| Step: 5
Training loss: 0.8544937220968363
Validation loss: 2.31670218116107

Epoch: 6| Step: 6
Training loss: 0.7970924080868692
Validation loss: 2.284651120820772

Epoch: 6| Step: 7
Training loss: 0.9938839204388125
Validation loss: 2.2860073829947005

Epoch: 6| Step: 8
Training loss: 0.8062335596700188
Validation loss: 2.2948794507757238

Epoch: 6| Step: 9
Training loss: 0.8115522285431298
Validation loss: 2.2779391755392466

Epoch: 6| Step: 10
Training loss: 0.9606793064509819
Validation loss: 2.277275388788453

Epoch: 6| Step: 11
Training loss: 0.73512785448293
Validation loss: 2.3252018632827656

Epoch: 6| Step: 12
Training loss: 0.3979696631299414
Validation loss: 2.3140778295743956

Epoch: 6| Step: 13
Training loss: 0.5396133593694803
Validation loss: 2.3260739581398724

Epoch: 338| Step: 0
Training loss: 0.759547028070647
Validation loss: 2.3343804078574095

Epoch: 6| Step: 1
Training loss: 0.7563508478815205
Validation loss: 2.3252060171188775

Epoch: 6| Step: 2
Training loss: 0.8717135631997055
Validation loss: 2.3463451420879715

Epoch: 6| Step: 3
Training loss: 1.144404381500358
Validation loss: 2.2903979659293694

Epoch: 6| Step: 4
Training loss: 0.7970267506636766
Validation loss: 2.258322113974002

Epoch: 6| Step: 5
Training loss: 0.5264827339587185
Validation loss: 2.2706541916661807

Epoch: 6| Step: 6
Training loss: 0.8716150272225027
Validation loss: 2.2516803198227904

Epoch: 6| Step: 7
Training loss: 1.0104221592914433
Validation loss: 2.279623669806058

Epoch: 6| Step: 8
Training loss: 0.7096523364555208
Validation loss: 2.274669529187938

Epoch: 6| Step: 9
Training loss: 0.8097275603089154
Validation loss: 2.2943491303895014

Epoch: 6| Step: 10
Training loss: 0.735466734034683
Validation loss: 2.313777196178331

Epoch: 6| Step: 11
Training loss: 0.7264204809378915
Validation loss: 2.328343156216355

Epoch: 6| Step: 12
Training loss: 0.5274184562607338
Validation loss: 2.394067989367021

Epoch: 6| Step: 13
Training loss: 0.6604308510910707
Validation loss: 2.405741287961527

Epoch: 339| Step: 0
Training loss: 0.6672146650943882
Validation loss: 2.3250995078808505

Epoch: 6| Step: 1
Training loss: 0.867108384381086
Validation loss: 2.2866874647475743

Epoch: 6| Step: 2
Training loss: 0.8403605091117179
Validation loss: 2.2636737776231253

Epoch: 6| Step: 3
Training loss: 0.6811458683047937
Validation loss: 2.2679400267453382

Epoch: 6| Step: 4
Training loss: 1.0324665176837162
Validation loss: 2.2671070562605258

Epoch: 6| Step: 5
Training loss: 0.778714949858475
Validation loss: 2.2876785531401134

Epoch: 6| Step: 6
Training loss: 0.8639695543514554
Validation loss: 2.3404253233594954

Epoch: 6| Step: 7
Training loss: 1.0137364949409842
Validation loss: 2.3729181378061

Epoch: 6| Step: 8
Training loss: 0.8494185660938648
Validation loss: 2.417650006452366

Epoch: 6| Step: 9
Training loss: 0.9044764692620763
Validation loss: 2.361113463788084

Epoch: 6| Step: 10
Training loss: 0.6281720252961888
Validation loss: 2.326648678755758

Epoch: 6| Step: 11
Training loss: 0.8336572653285979
Validation loss: 2.2706862220705117

Epoch: 6| Step: 12
Training loss: 0.7207836736724744
Validation loss: 2.3133358607405885

Epoch: 6| Step: 13
Training loss: 0.9418733632985394
Validation loss: 2.3189906099031683

Epoch: 340| Step: 0
Training loss: 0.9623859003482529
Validation loss: 2.3105282746222864

Epoch: 6| Step: 1
Training loss: 0.5539641163115144
Validation loss: 2.309615441638712

Epoch: 6| Step: 2
Training loss: 0.8749498284806083
Validation loss: 2.3112848421094268

Epoch: 6| Step: 3
Training loss: 0.7748061891449401
Validation loss: 2.3507023341532807

Epoch: 6| Step: 4
Training loss: 0.6820062787880029
Validation loss: 2.3668517882504525

Epoch: 6| Step: 5
Training loss: 0.9123845471542325
Validation loss: 2.3759450872499897

Epoch: 6| Step: 6
Training loss: 0.6856889713317813
Validation loss: 2.3449920207315826

Epoch: 6| Step: 7
Training loss: 0.8455283885275344
Validation loss: 2.346563469319227

Epoch: 6| Step: 8
Training loss: 0.5878895857792283
Validation loss: 2.35648946234261

Epoch: 6| Step: 9
Training loss: 0.6486512946229797
Validation loss: 2.3141660990790345

Epoch: 6| Step: 10
Training loss: 0.6961655901861814
Validation loss: 2.3069931669031756

Epoch: 6| Step: 11
Training loss: 0.9411683474481174
Validation loss: 2.279848618761186

Epoch: 6| Step: 12
Training loss: 0.935444676943445
Validation loss: 2.286970911691089

Epoch: 6| Step: 13
Training loss: 0.700556875859219
Validation loss: 2.28308248759535

Epoch: 341| Step: 0
Training loss: 0.7137418916178238
Validation loss: 2.3133479445304763

Epoch: 6| Step: 1
Training loss: 0.4925842805095135
Validation loss: 2.3159174257834976

Epoch: 6| Step: 2
Training loss: 0.6906650471188116
Validation loss: 2.3049783825173717

Epoch: 6| Step: 3
Training loss: 0.6984230927553785
Validation loss: 2.337217730718408

Epoch: 6| Step: 4
Training loss: 0.5984082446404989
Validation loss: 2.3673351795048654

Epoch: 6| Step: 5
Training loss: 0.943803260260349
Validation loss: 2.3847522596646007

Epoch: 6| Step: 6
Training loss: 1.048127464241493
Validation loss: 2.3445165341856997

Epoch: 6| Step: 7
Training loss: 0.9061938301305762
Validation loss: 2.3271075008229984

Epoch: 6| Step: 8
Training loss: 0.9171100902221501
Validation loss: 2.3204305124433118

Epoch: 6| Step: 9
Training loss: 0.8008355099042781
Validation loss: 2.2944173024548014

Epoch: 6| Step: 10
Training loss: 0.8580245070436509
Validation loss: 2.3153180254839913

Epoch: 6| Step: 11
Training loss: 0.5035230081163421
Validation loss: 2.302659489695884

Epoch: 6| Step: 12
Training loss: 0.4860539716865378
Validation loss: 2.3190209589548347

Epoch: 6| Step: 13
Training loss: 0.6783247253643485
Validation loss: 2.3100192824817296

Epoch: 342| Step: 0
Training loss: 0.4253407570829832
Validation loss: 2.3266497919093494

Epoch: 6| Step: 1
Training loss: 0.8307420655846557
Validation loss: 2.3497660200782824

Epoch: 6| Step: 2
Training loss: 0.814193940488362
Validation loss: 2.370826238884746

Epoch: 6| Step: 3
Training loss: 0.4421933001889325
Validation loss: 2.3878378253435177

Epoch: 6| Step: 4
Training loss: 0.511173919202567
Validation loss: 2.402645264706082

Epoch: 6| Step: 5
Training loss: 1.0397258161450469
Validation loss: 2.39488009678444

Epoch: 6| Step: 6
Training loss: 0.7784519060379971
Validation loss: 2.360079919637826

Epoch: 6| Step: 7
Training loss: 0.9452978085724015
Validation loss: 2.3094717217392855

Epoch: 6| Step: 8
Training loss: 0.6533364606153158
Validation loss: 2.292141582318405

Epoch: 6| Step: 9
Training loss: 0.9368113531642264
Validation loss: 2.3114434145169014

Epoch: 6| Step: 10
Training loss: 0.9586376487921133
Validation loss: 2.321993977082831

Epoch: 6| Step: 11
Training loss: 0.8636414824909021
Validation loss: 2.3102645057257547

Epoch: 6| Step: 12
Training loss: 0.6521380208598186
Validation loss: 2.331532854821611

Epoch: 6| Step: 13
Training loss: 0.6055726731235531
Validation loss: 2.3442832695599143

Epoch: 343| Step: 0
Training loss: 0.5210790880877181
Validation loss: 2.385874364755091

Epoch: 6| Step: 1
Training loss: 0.8647841752647655
Validation loss: 2.3922367591587625

Epoch: 6| Step: 2
Training loss: 0.770153820105984
Validation loss: 2.3680389003833353

Epoch: 6| Step: 3
Training loss: 0.5245853762275038
Validation loss: 2.4000281386110247

Epoch: 6| Step: 4
Training loss: 0.8732063779269487
Validation loss: 2.392844204734624

Epoch: 6| Step: 5
Training loss: 0.9111682030447545
Validation loss: 2.338424919417669

Epoch: 6| Step: 6
Training loss: 1.0613127414232912
Validation loss: 2.317884287020485

Epoch: 6| Step: 7
Training loss: 0.8012065967343471
Validation loss: 2.3306547236325352

Epoch: 6| Step: 8
Training loss: 0.8416828334942706
Validation loss: 2.3125134096031212

Epoch: 6| Step: 9
Training loss: 0.6704262039030943
Validation loss: 2.3211030679139792

Epoch: 6| Step: 10
Training loss: 0.30393972089953447
Validation loss: 2.3448332527610685

Epoch: 6| Step: 11
Training loss: 0.8339327007785433
Validation loss: 2.349623818289582

Epoch: 6| Step: 12
Training loss: 0.7834146266378181
Validation loss: 2.3823468701996173

Epoch: 6| Step: 13
Training loss: 0.3962991967933557
Validation loss: 2.377649878798237

Epoch: 344| Step: 0
Training loss: 0.6519654370534449
Validation loss: 2.3684576685293925

Epoch: 6| Step: 1
Training loss: 0.5021644177262499
Validation loss: 2.354592210700718

Epoch: 6| Step: 2
Training loss: 0.9335831837076125
Validation loss: 2.34137127146627

Epoch: 6| Step: 3
Training loss: 0.5443780845090458
Validation loss: 2.3655670564225106

Epoch: 6| Step: 4
Training loss: 0.5661516340766307
Validation loss: 2.331062923716381

Epoch: 6| Step: 5
Training loss: 0.7196070495508258
Validation loss: 2.3096238769613553

Epoch: 6| Step: 6
Training loss: 0.5969972155807968
Validation loss: 2.3037359393353753

Epoch: 6| Step: 7
Training loss: 0.6140426477227384
Validation loss: 2.3210086876741154

Epoch: 6| Step: 8
Training loss: 0.9685906309892035
Validation loss: 2.2764897967749556

Epoch: 6| Step: 9
Training loss: 0.8160499269718119
Validation loss: 2.2994636949766054

Epoch: 6| Step: 10
Training loss: 0.41125499151267486
Validation loss: 2.2869881673776575

Epoch: 6| Step: 11
Training loss: 0.8040844036844615
Validation loss: 2.2827292588249137

Epoch: 6| Step: 12
Training loss: 0.9622605372699572
Validation loss: 2.265267555178525

Epoch: 6| Step: 13
Training loss: 0.9059017433039404
Validation loss: 2.3109478063351543

Epoch: 345| Step: 0
Training loss: 0.6282216012033539
Validation loss: 2.308325493103528

Epoch: 6| Step: 1
Training loss: 0.6049319687338307
Validation loss: 2.309680383782264

Epoch: 6| Step: 2
Training loss: 0.9123782429395125
Validation loss: 2.3024158431601913

Epoch: 6| Step: 3
Training loss: 0.3947071967265456
Validation loss: 2.286239804936715

Epoch: 6| Step: 4
Training loss: 0.7846961500024543
Validation loss: 2.2841559104697455

Epoch: 6| Step: 5
Training loss: 0.4697622813009522
Validation loss: 2.302016098056977

Epoch: 6| Step: 6
Training loss: 0.4699581154462799
Validation loss: 2.300030987028351

Epoch: 6| Step: 7
Training loss: 0.7889979874327777
Validation loss: 2.288935551015245

Epoch: 6| Step: 8
Training loss: 1.1151708795272832
Validation loss: 2.308529425824744

Epoch: 6| Step: 9
Training loss: 0.9471324709088751
Validation loss: 2.289581702485942

Epoch: 6| Step: 10
Training loss: 0.5594555003032272
Validation loss: 2.3286445248884

Epoch: 6| Step: 11
Training loss: 0.7273544589359585
Validation loss: 2.323617040961351

Epoch: 6| Step: 12
Training loss: 0.7691086901481172
Validation loss: 2.321873367704936

Epoch: 6| Step: 13
Training loss: 0.31985204444569976
Validation loss: 2.306361585660415

Epoch: 346| Step: 0
Training loss: 0.7208633038091379
Validation loss: 2.2643566424274764

Epoch: 6| Step: 1
Training loss: 0.7492550488092814
Validation loss: 2.2666620072902632

Epoch: 6| Step: 2
Training loss: 0.43545962430537344
Validation loss: 2.2803622490830247

Epoch: 6| Step: 3
Training loss: 1.007673564471697
Validation loss: 2.2859823947320765

Epoch: 6| Step: 4
Training loss: 0.5313067686379618
Validation loss: 2.3201455190533307

Epoch: 6| Step: 5
Training loss: 0.6370123437916123
Validation loss: 2.3351244612957114

Epoch: 6| Step: 6
Training loss: 0.695529560969221
Validation loss: 2.3357658107755372

Epoch: 6| Step: 7
Training loss: 0.6544343263099038
Validation loss: 2.338315480914091

Epoch: 6| Step: 8
Training loss: 0.608944178166692
Validation loss: 2.3496079042071547

Epoch: 6| Step: 9
Training loss: 0.627830034716516
Validation loss: 2.3436884269693303

Epoch: 6| Step: 10
Training loss: 0.7641392129093887
Validation loss: 2.2913832387607895

Epoch: 6| Step: 11
Training loss: 0.8427378270128127
Validation loss: 2.2956152458076713

Epoch: 6| Step: 12
Training loss: 0.7657985101391936
Validation loss: 2.2619891635448828

Epoch: 6| Step: 13
Training loss: 0.9018962460537991
Validation loss: 2.28765188647926

Epoch: 347| Step: 0
Training loss: 0.7821295555436889
Validation loss: 2.269738389346923

Epoch: 6| Step: 1
Training loss: 0.7247472256636639
Validation loss: 2.277590275055217

Epoch: 6| Step: 2
Training loss: 0.6381633962574159
Validation loss: 2.297828734693168

Epoch: 6| Step: 3
Training loss: 0.5579426845934821
Validation loss: 2.2840668731974385

Epoch: 6| Step: 4
Training loss: 0.7119676860189732
Validation loss: 2.3079908320857516

Epoch: 6| Step: 5
Training loss: 0.6359179557027721
Validation loss: 2.298009138580509

Epoch: 6| Step: 6
Training loss: 0.7691408900332636
Validation loss: 2.339526642510016

Epoch: 6| Step: 7
Training loss: 0.2782759513971688
Validation loss: 2.33477090098002

Epoch: 6| Step: 8
Training loss: 0.8834486500724934
Validation loss: 2.3360359142903233

Epoch: 6| Step: 9
Training loss: 0.8135246271814773
Validation loss: 2.3248929167015064

Epoch: 6| Step: 10
Training loss: 0.42936361417153
Validation loss: 2.313284237955257

Epoch: 6| Step: 11
Training loss: 0.7486413331695144
Validation loss: 2.3191482419984766

Epoch: 6| Step: 12
Training loss: 0.8767991302469388
Validation loss: 2.3197440361908015

Epoch: 6| Step: 13
Training loss: 0.7004073711718691
Validation loss: 2.312869763266346

Epoch: 348| Step: 0
Training loss: 0.8482176859507851
Validation loss: 2.314661259342382

Epoch: 6| Step: 1
Training loss: 0.6899039115895507
Validation loss: 2.3081659023586787

Epoch: 6| Step: 2
Training loss: 0.6874796040717377
Validation loss: 2.30118769618394

Epoch: 6| Step: 3
Training loss: 0.6246854944468865
Validation loss: 2.3018613890302833

Epoch: 6| Step: 4
Training loss: 0.8554748813635868
Validation loss: 2.340742453124598

Epoch: 6| Step: 5
Training loss: 0.5830235055827349
Validation loss: 2.3255728936832916

Epoch: 6| Step: 6
Training loss: 0.683295484595646
Validation loss: 2.329147356647325

Epoch: 6| Step: 7
Training loss: 0.5461148564921814
Validation loss: 2.2962601685450537

Epoch: 6| Step: 8
Training loss: 0.5552237162030565
Validation loss: 2.3256417411515167

Epoch: 6| Step: 9
Training loss: 0.6938513930862383
Validation loss: 2.2879249416990386

Epoch: 6| Step: 10
Training loss: 0.4456204470579768
Validation loss: 2.295904041796965

Epoch: 6| Step: 11
Training loss: 0.8258316746440696
Validation loss: 2.3089552908331377

Epoch: 6| Step: 12
Training loss: 0.6055286500895347
Validation loss: 2.315345406004469

Epoch: 6| Step: 13
Training loss: 0.8497807823120667
Validation loss: 2.2797068440459896

Epoch: 349| Step: 0
Training loss: 0.6928448769553909
Validation loss: 2.307598976783188

Epoch: 6| Step: 1
Training loss: 0.7354287642725762
Validation loss: 2.3204170220910663

Epoch: 6| Step: 2
Training loss: 0.27235979506763486
Validation loss: 2.313828196368901

Epoch: 6| Step: 3
Training loss: 0.7735459222804086
Validation loss: 2.3200512523492014

Epoch: 6| Step: 4
Training loss: 0.8350555544777716
Validation loss: 2.310961028591943

Epoch: 6| Step: 5
Training loss: 0.7031068799545048
Validation loss: 2.279827798666543

Epoch: 6| Step: 6
Training loss: 0.6433204375055025
Validation loss: 2.2869827514141763

Epoch: 6| Step: 7
Training loss: 0.5619561427234375
Validation loss: 2.2754651391175633

Epoch: 6| Step: 8
Training loss: 0.6531183361096801
Validation loss: 2.2580283711436717

Epoch: 6| Step: 9
Training loss: 0.43754165314890897
Validation loss: 2.27617805492634

Epoch: 6| Step: 10
Training loss: 0.6941424179268664
Validation loss: 2.294713126668015

Epoch: 6| Step: 11
Training loss: 0.8722766320319497
Validation loss: 2.318194376102614

Epoch: 6| Step: 12
Training loss: 0.8407934452598081
Validation loss: 2.318415411818184

Epoch: 6| Step: 13
Training loss: 0.47728725729639604
Validation loss: 2.3249592051839802

Epoch: 350| Step: 0
Training loss: 0.9428655939322054
Validation loss: 2.301575873481257

Epoch: 6| Step: 1
Training loss: 0.7203616442020633
Validation loss: 2.314156444276959

Epoch: 6| Step: 2
Training loss: 0.5781987890630661
Validation loss: 2.2919399922571717

Epoch: 6| Step: 3
Training loss: 0.6042022502768243
Validation loss: 2.294885814403507

Epoch: 6| Step: 4
Training loss: 0.6619407866782396
Validation loss: 2.286882391508572

Epoch: 6| Step: 5
Training loss: 0.6402555191058359
Validation loss: 2.3217508363028476

Epoch: 6| Step: 6
Training loss: 0.47721852034972373
Validation loss: 2.3279613595104123

Epoch: 6| Step: 7
Training loss: 1.062166722704147
Validation loss: 2.347447957046877

Epoch: 6| Step: 8
Training loss: 0.7387076463515585
Validation loss: 2.3554059464804324

Epoch: 6| Step: 9
Training loss: 0.5616844145529966
Validation loss: 2.3688468000535225

Epoch: 6| Step: 10
Training loss: 0.586551395528608
Validation loss: 2.372338218786771

Epoch: 6| Step: 11
Training loss: 0.5974082432205944
Validation loss: 2.365263675465431

Epoch: 6| Step: 12
Training loss: 0.6306944356901206
Validation loss: 2.337234911041475

Epoch: 6| Step: 13
Training loss: 0.6580770354801849
Validation loss: 2.3032046807078217

Epoch: 351| Step: 0
Training loss: 0.5810439164902425
Validation loss: 2.2792994551765244

Epoch: 6| Step: 1
Training loss: 0.820961613644003
Validation loss: 2.2627291550472934

Epoch: 6| Step: 2
Training loss: 0.784839623220334
Validation loss: 2.27425992531085

Epoch: 6| Step: 3
Training loss: 0.8025036408291282
Validation loss: 2.308189108297344

Epoch: 6| Step: 4
Training loss: 0.8413447606421034
Validation loss: 2.300572951985877

Epoch: 6| Step: 5
Training loss: 0.5355954560686081
Validation loss: 2.313371650916542

Epoch: 6| Step: 6
Training loss: 0.6557157021721525
Validation loss: 2.354376436630944

Epoch: 6| Step: 7
Training loss: 0.5046939754956424
Validation loss: 2.328968730714365

Epoch: 6| Step: 8
Training loss: 0.8530097352575842
Validation loss: 2.3264147035916096

Epoch: 6| Step: 9
Training loss: 0.6362145891059603
Validation loss: 2.32462917201745

Epoch: 6| Step: 10
Training loss: 0.510631104272894
Validation loss: 2.3128818129135826

Epoch: 6| Step: 11
Training loss: 0.6332199762774237
Validation loss: 2.2929666005588305

Epoch: 6| Step: 12
Training loss: 0.7640684225090791
Validation loss: 2.2855814758747544

Epoch: 6| Step: 13
Training loss: 0.5086509824741257
Validation loss: 2.300663605815125

Epoch: 352| Step: 0
Training loss: 0.5181558228034241
Validation loss: 2.2981988873696992

Epoch: 6| Step: 1
Training loss: 0.8431650889418917
Validation loss: 2.3301300996662735

Epoch: 6| Step: 2
Training loss: 0.6214244609847154
Validation loss: 2.3440667521506136

Epoch: 6| Step: 3
Training loss: 0.5801071262495328
Validation loss: 2.353043964670998

Epoch: 6| Step: 4
Training loss: 0.666246905400173
Validation loss: 2.3419220652374233

Epoch: 6| Step: 5
Training loss: 0.6195672427638256
Validation loss: 2.3254691694236

Epoch: 6| Step: 6
Training loss: 0.5866376635397579
Validation loss: 2.303201623087473

Epoch: 6| Step: 7
Training loss: 0.7115800908812201
Validation loss: 2.302332192639874

Epoch: 6| Step: 8
Training loss: 0.6279996652010007
Validation loss: 2.3213022622975834

Epoch: 6| Step: 9
Training loss: 0.6906140632971705
Validation loss: 2.2970060838901656

Epoch: 6| Step: 10
Training loss: 0.6249798294627276
Validation loss: 2.306932422531156

Epoch: 6| Step: 11
Training loss: 0.7404668840399706
Validation loss: 2.326972786971425

Epoch: 6| Step: 12
Training loss: 0.6292034892070953
Validation loss: 2.278361325739432

Epoch: 6| Step: 13
Training loss: 0.7293899648352088
Validation loss: 2.2823920229648604

Epoch: 353| Step: 0
Training loss: 0.6026866367345377
Validation loss: 2.2824266281530954

Epoch: 6| Step: 1
Training loss: 0.5943310053254363
Validation loss: 2.288093417479937

Epoch: 6| Step: 2
Training loss: 0.7095013459739258
Validation loss: 2.256845245411

Epoch: 6| Step: 3
Training loss: 0.6605340452205907
Validation loss: 2.2609680914818187

Epoch: 6| Step: 4
Training loss: 0.5494910204243078
Validation loss: 2.2681190768511463

Epoch: 6| Step: 5
Training loss: 0.7452676403692536
Validation loss: 2.3088828768279095

Epoch: 6| Step: 6
Training loss: 0.6385713083959572
Validation loss: 2.2918962007573653

Epoch: 6| Step: 7
Training loss: 0.4910784290483554
Validation loss: 2.2870276441682855

Epoch: 6| Step: 8
Training loss: 0.8680839029557876
Validation loss: 2.2777054923861697

Epoch: 6| Step: 9
Training loss: 0.7017706224613818
Validation loss: 2.2748069685347714

Epoch: 6| Step: 10
Training loss: 1.012807488551184
Validation loss: 2.268185367606149

Epoch: 6| Step: 11
Training loss: 0.35403694787879575
Validation loss: 2.2544655796743576

Epoch: 6| Step: 12
Training loss: 0.6254646481434986
Validation loss: 2.2721424181068377

Epoch: 6| Step: 13
Training loss: 0.24567835429735368
Validation loss: 2.2988422812362463

Epoch: 354| Step: 0
Training loss: 0.612271053966242
Validation loss: 2.3051864792991767

Epoch: 6| Step: 1
Training loss: 0.43593414264329544
Validation loss: 2.3319213267437378

Epoch: 6| Step: 2
Training loss: 0.5619483202746496
Validation loss: 2.3382579357188646

Epoch: 6| Step: 3
Training loss: 0.5152864211535128
Validation loss: 2.345499106037295

Epoch: 6| Step: 4
Training loss: 0.8975591595419349
Validation loss: 2.347706421404103

Epoch: 6| Step: 5
Training loss: 0.8041818011215287
Validation loss: 2.3585780155260965

Epoch: 6| Step: 6
Training loss: 0.542298266614549
Validation loss: 2.3330469424493145

Epoch: 6| Step: 7
Training loss: 0.7434431196259339
Validation loss: 2.2902627013413728

Epoch: 6| Step: 8
Training loss: 0.8207426487421773
Validation loss: 2.287009149000635

Epoch: 6| Step: 9
Training loss: 0.4187204784691019
Validation loss: 2.295667919203543

Epoch: 6| Step: 10
Training loss: 0.5747471927426588
Validation loss: 2.2906731962614715

Epoch: 6| Step: 11
Training loss: 0.9489574936249944
Validation loss: 2.2853765919410716

Epoch: 6| Step: 12
Training loss: 0.3353432233836684
Validation loss: 2.301008372649315

Epoch: 6| Step: 13
Training loss: 0.476267379308473
Validation loss: 2.2759650598060746

Epoch: 355| Step: 0
Training loss: 0.8847221717521724
Validation loss: 2.289770301171023

Epoch: 6| Step: 1
Training loss: 0.3132460153414569
Validation loss: 2.285565757467006

Epoch: 6| Step: 2
Training loss: 0.7034703572148008
Validation loss: 2.3121556960003207

Epoch: 6| Step: 3
Training loss: 0.650877212098672
Validation loss: 2.333388011118869

Epoch: 6| Step: 4
Training loss: 0.6092591786966954
Validation loss: 2.3187076275835254

Epoch: 6| Step: 5
Training loss: 0.7696754591538606
Validation loss: 2.3280996208517166

Epoch: 6| Step: 6
Training loss: 0.4754865883330714
Validation loss: 2.3205209649941607

Epoch: 6| Step: 7
Training loss: 0.5783420361552056
Validation loss: 2.301906175932776

Epoch: 6| Step: 8
Training loss: 0.6642809564629555
Validation loss: 2.28590790157737

Epoch: 6| Step: 9
Training loss: 0.5380957406980463
Validation loss: 2.288256947976353

Epoch: 6| Step: 10
Training loss: 0.49732691768406334
Validation loss: 2.2790519189838903

Epoch: 6| Step: 11
Training loss: 0.6837015557431415
Validation loss: 2.2657870655135994

Epoch: 6| Step: 12
Training loss: 0.5200229984937961
Validation loss: 2.2978800810415545

Epoch: 6| Step: 13
Training loss: 0.9758158461559119
Validation loss: 2.265747074944484

Epoch: 356| Step: 0
Training loss: 0.48730052877421337
Validation loss: 2.288270581432152

Epoch: 6| Step: 1
Training loss: 0.8158133877493885
Validation loss: 2.3056259936359296

Epoch: 6| Step: 2
Training loss: 0.587191955484537
Validation loss: 2.291346251460557

Epoch: 6| Step: 3
Training loss: 0.8856953163741542
Validation loss: 2.3074614407912843

Epoch: 6| Step: 4
Training loss: 0.7368670042346712
Validation loss: 2.286217322060085

Epoch: 6| Step: 5
Training loss: 0.662296955015131
Validation loss: 2.303397224698504

Epoch: 6| Step: 6
Training loss: 0.37796761571328386
Validation loss: 2.287075513780998

Epoch: 6| Step: 7
Training loss: 0.8427800148434315
Validation loss: 2.2887064277346156

Epoch: 6| Step: 8
Training loss: 0.6611143303996686
Validation loss: 2.2663044545393967

Epoch: 6| Step: 9
Training loss: 0.4423382465070042
Validation loss: 2.285258492397422

Epoch: 6| Step: 10
Training loss: 0.5234485738920862
Validation loss: 2.2819758508006664

Epoch: 6| Step: 11
Training loss: 0.500339333304904
Validation loss: 2.3013104513122262

Epoch: 6| Step: 12
Training loss: 0.6226536098601346
Validation loss: 2.3070615781808836

Epoch: 6| Step: 13
Training loss: 0.4448218905642369
Validation loss: 2.348408219456744

Epoch: 357| Step: 0
Training loss: 0.38661697281435614
Validation loss: 2.344182133915063

Epoch: 6| Step: 1
Training loss: 1.0474369192134891
Validation loss: 2.355153597196827

Epoch: 6| Step: 2
Training loss: 0.6291544643591435
Validation loss: 2.3316373667811563

Epoch: 6| Step: 3
Training loss: 0.5090235135187638
Validation loss: 2.3452467450906544

Epoch: 6| Step: 4
Training loss: 0.5312905296124242
Validation loss: 2.2866865583255573

Epoch: 6| Step: 5
Training loss: 0.4328915864596097
Validation loss: 2.282465438041081

Epoch: 6| Step: 6
Training loss: 0.6100773309718839
Validation loss: 2.2879833149945923

Epoch: 6| Step: 7
Training loss: 0.639621530214418
Validation loss: 2.265820305213524

Epoch: 6| Step: 8
Training loss: 0.5292039909365845
Validation loss: 2.2746497112527475

Epoch: 6| Step: 9
Training loss: 0.6627606365051105
Validation loss: 2.288366111934255

Epoch: 6| Step: 10
Training loss: 0.472357663509015
Validation loss: 2.272045682477414

Epoch: 6| Step: 11
Training loss: 0.854700309476108
Validation loss: 2.3072533458584004

Epoch: 6| Step: 12
Training loss: 0.7659830307238755
Validation loss: 2.2913766561860855

Epoch: 6| Step: 13
Training loss: 0.22608974889551153
Validation loss: 2.3384015040190005

Epoch: 358| Step: 0
Training loss: 0.5093346304781275
Validation loss: 2.3486048250950757

Epoch: 6| Step: 1
Training loss: 0.9423548244609267
Validation loss: 2.355408714298148

Epoch: 6| Step: 2
Training loss: 0.5133471024305607
Validation loss: 2.3341856299361776

Epoch: 6| Step: 3
Training loss: 0.4917574320543281
Validation loss: 2.3243523782404654

Epoch: 6| Step: 4
Training loss: 0.6934028289502853
Validation loss: 2.3087250557483525

Epoch: 6| Step: 5
Training loss: 0.6329824902190337
Validation loss: 2.276351775988524

Epoch: 6| Step: 6
Training loss: 0.8127384202778191
Validation loss: 2.29734763117809

Epoch: 6| Step: 7
Training loss: 0.6642464775592183
Validation loss: 2.2808876384743995

Epoch: 6| Step: 8
Training loss: 0.26892961166749124
Validation loss: 2.2743984568427225

Epoch: 6| Step: 9
Training loss: 0.47440431034371827
Validation loss: 2.2608995197407764

Epoch: 6| Step: 10
Training loss: 0.7939191112441301
Validation loss: 2.307481619086279

Epoch: 6| Step: 11
Training loss: 0.5642305351047011
Validation loss: 2.2873156846208955

Epoch: 6| Step: 12
Training loss: 0.5876472197378682
Validation loss: 2.326987973392695

Epoch: 6| Step: 13
Training loss: 0.46262041083870725
Validation loss: 2.2921913722761245

Epoch: 359| Step: 0
Training loss: 0.5499922600114844
Validation loss: 2.3127006946978383

Epoch: 6| Step: 1
Training loss: 0.7606318226040459
Validation loss: 2.321080635565484

Epoch: 6| Step: 2
Training loss: 0.5485675777058174
Validation loss: 2.297682781315745

Epoch: 6| Step: 3
Training loss: 0.6358981549138001
Validation loss: 2.289505880863196

Epoch: 6| Step: 4
Training loss: 0.7141577342026352
Validation loss: 2.2871646737982716

Epoch: 6| Step: 5
Training loss: 0.5132684610245444
Validation loss: 2.2962800963849346

Epoch: 6| Step: 6
Training loss: 0.5774125787283169
Validation loss: 2.270262202045806

Epoch: 6| Step: 7
Training loss: 0.2991978471192765
Validation loss: 2.296126880794788

Epoch: 6| Step: 8
Training loss: 0.5950251989878853
Validation loss: 2.271068037792211

Epoch: 6| Step: 9
Training loss: 0.739610313317419
Validation loss: 2.2793499592381403

Epoch: 6| Step: 10
Training loss: 0.6130036618775211
Validation loss: 2.3217386560147704

Epoch: 6| Step: 11
Training loss: 0.6808218424219176
Validation loss: 2.3350125729188385

Epoch: 6| Step: 12
Training loss: 0.5918871618711187
Validation loss: 2.324621273077064

Epoch: 6| Step: 13
Training loss: 0.7363216086182768
Validation loss: 2.3433910595440763

Epoch: 360| Step: 0
Training loss: 0.38250712456643954
Validation loss: 2.3300739837002626

Epoch: 6| Step: 1
Training loss: 0.4773282480922444
Validation loss: 2.3330647740495207

Epoch: 6| Step: 2
Training loss: 0.800611785076825
Validation loss: 2.2840368150810284

Epoch: 6| Step: 3
Training loss: 0.7554227371168294
Validation loss: 2.255706631644569

Epoch: 6| Step: 4
Training loss: 0.713764731260155
Validation loss: 2.288791720975137

Epoch: 6| Step: 5
Training loss: 0.41737901670722966
Validation loss: 2.2839257155926247

Epoch: 6| Step: 6
Training loss: 0.5531148241475613
Validation loss: 2.2809469842422274

Epoch: 6| Step: 7
Training loss: 0.7728801221682428
Validation loss: 2.2836302598407197

Epoch: 6| Step: 8
Training loss: 0.5502368048750069
Validation loss: 2.282201981044735

Epoch: 6| Step: 9
Training loss: 0.66030006422256
Validation loss: 2.3130367934249167

Epoch: 6| Step: 10
Training loss: 0.41962548375037895
Validation loss: 2.3051436189640833

Epoch: 6| Step: 11
Training loss: 0.7025378000535988
Validation loss: 2.301522899766223

Epoch: 6| Step: 12
Training loss: 0.6620061563251664
Validation loss: 2.352304729792847

Epoch: 6| Step: 13
Training loss: 0.41318858789875756
Validation loss: 2.317255152583639

Epoch: 361| Step: 0
Training loss: 0.5088782644146062
Validation loss: 2.288097612353131

Epoch: 6| Step: 1
Training loss: 0.6025948521831941
Validation loss: 2.277381093609347

Epoch: 6| Step: 2
Training loss: 0.742992005250001
Validation loss: 2.291725954051445

Epoch: 6| Step: 3
Training loss: 0.49408243613221425
Validation loss: 2.284186574206555

Epoch: 6| Step: 4
Training loss: 0.7442812649044995
Validation loss: 2.2643734239811404

Epoch: 6| Step: 5
Training loss: 0.44798016837303334
Validation loss: 2.280825202982824

Epoch: 6| Step: 6
Training loss: 0.632250147424683
Validation loss: 2.329273231154408

Epoch: 6| Step: 7
Training loss: 0.4586939115823373
Validation loss: 2.3107116489013473

Epoch: 6| Step: 8
Training loss: 0.9263660499264968
Validation loss: 2.3136035466694262

Epoch: 6| Step: 9
Training loss: 0.37460218627523884
Validation loss: 2.3364739664388923

Epoch: 6| Step: 10
Training loss: 0.636717790474198
Validation loss: 2.3486366754779415

Epoch: 6| Step: 11
Training loss: 0.6016993181275176
Validation loss: 2.3364416128522216

Epoch: 6| Step: 12
Training loss: 0.5906249677062656
Validation loss: 2.3204147058370377

Epoch: 6| Step: 13
Training loss: 0.4054671594371726
Validation loss: 2.307807767050058

Epoch: 362| Step: 0
Training loss: 0.47407716966034075
Validation loss: 2.316888847712792

Epoch: 6| Step: 1
Training loss: 0.4626441653553357
Validation loss: 2.3003962339996167

Epoch: 6| Step: 2
Training loss: 0.6143827083953938
Validation loss: 2.3041076742800137

Epoch: 6| Step: 3
Training loss: 0.7916619568400239
Validation loss: 2.3115005323242666

Epoch: 6| Step: 4
Training loss: 0.6400316561007595
Validation loss: 2.3345485367033674

Epoch: 6| Step: 5
Training loss: 0.41448972362461517
Validation loss: 2.3496655044804986

Epoch: 6| Step: 6
Training loss: 0.8247434925355682
Validation loss: 2.342812734808433

Epoch: 6| Step: 7
Training loss: 0.5703261386860472
Validation loss: 2.3564176985734093

Epoch: 6| Step: 8
Training loss: 0.6011431086686749
Validation loss: 2.333945406856486

Epoch: 6| Step: 9
Training loss: 0.5698801779707358
Validation loss: 2.3484232274176877

Epoch: 6| Step: 10
Training loss: 0.7679048575660855
Validation loss: 2.3016536994570527

Epoch: 6| Step: 11
Training loss: 0.6971079116390387
Validation loss: 2.264050343211069

Epoch: 6| Step: 12
Training loss: 0.43298862949907796
Validation loss: 2.2793284127899613

Epoch: 6| Step: 13
Training loss: 0.25027861567023113
Validation loss: 2.3044961684785243

Epoch: 363| Step: 0
Training loss: 0.6899393760613487
Validation loss: 2.2656299731037692

Epoch: 6| Step: 1
Training loss: 0.29383160999587543
Validation loss: 2.3039094657618047

Epoch: 6| Step: 2
Training loss: 0.38031064141978344
Validation loss: 2.2752475156059164

Epoch: 6| Step: 3
Training loss: 0.4258179954981583
Validation loss: 2.2999139325818905

Epoch: 6| Step: 4
Training loss: 0.6334911051624772
Validation loss: 2.3292564455649436

Epoch: 6| Step: 5
Training loss: 0.7364628918914501
Validation loss: 2.346557772972773

Epoch: 6| Step: 6
Training loss: 0.6203601030970417
Validation loss: 2.312880577026796

Epoch: 6| Step: 7
Training loss: 0.644942828461285
Validation loss: 2.3107685440498287

Epoch: 6| Step: 8
Training loss: 0.5673721496315454
Validation loss: 2.2799806905517803

Epoch: 6| Step: 9
Training loss: 0.7564761383292143
Validation loss: 2.2858900646463467

Epoch: 6| Step: 10
Training loss: 0.44760009386770716
Validation loss: 2.299506611846587

Epoch: 6| Step: 11
Training loss: 0.8467531799310757
Validation loss: 2.3098166966283973

Epoch: 6| Step: 12
Training loss: 0.27887014320945613
Validation loss: 2.2944213829711337

Epoch: 6| Step: 13
Training loss: 0.8329509612849288
Validation loss: 2.2917718048439597

Epoch: 364| Step: 0
Training loss: 0.8019544241885863
Validation loss: 2.302855536453133

Epoch: 6| Step: 1
Training loss: 0.5826087493234272
Validation loss: 2.2969156696535364

Epoch: 6| Step: 2
Training loss: 0.48777320371188254
Validation loss: 2.281371625421698

Epoch: 6| Step: 3
Training loss: 0.5467413057665993
Validation loss: 2.3104515625703574

Epoch: 6| Step: 4
Training loss: 0.6630219778414125
Validation loss: 2.2875662617427888

Epoch: 6| Step: 5
Training loss: 0.5801485834455041
Validation loss: 2.3181941914209467

Epoch: 6| Step: 6
Training loss: 0.665323272338351
Validation loss: 2.308243685510805

Epoch: 6| Step: 7
Training loss: 0.6236909986734813
Validation loss: 2.2785648709635002

Epoch: 6| Step: 8
Training loss: 0.779679742136184
Validation loss: 2.3004444221944196

Epoch: 6| Step: 9
Training loss: 0.46632495471952284
Validation loss: 2.2969635126090044

Epoch: 6| Step: 10
Training loss: 0.44131487347869913
Validation loss: 2.286756528339969

Epoch: 6| Step: 11
Training loss: 0.3717438674977624
Validation loss: 2.3009864217997134

Epoch: 6| Step: 12
Training loss: 0.4747953639180123
Validation loss: 2.3099947970137777

Epoch: 6| Step: 13
Training loss: 0.4257629985572223
Validation loss: 2.2884333699792894

Epoch: 365| Step: 0
Training loss: 0.29006101223383857
Validation loss: 2.3157978394295387

Epoch: 6| Step: 1
Training loss: 0.4037842564473482
Validation loss: 2.293833347301819

Epoch: 6| Step: 2
Training loss: 0.6904730884340601
Validation loss: 2.3019893480242994

Epoch: 6| Step: 3
Training loss: 0.7502994336980884
Validation loss: 2.299723562246662

Epoch: 6| Step: 4
Training loss: 0.46509993730297333
Validation loss: 2.3129977040156255

Epoch: 6| Step: 5
Training loss: 0.45858862839914355
Validation loss: 2.3116000119499853

Epoch: 6| Step: 6
Training loss: 0.6243140986910247
Validation loss: 2.3137513399929386

Epoch: 6| Step: 7
Training loss: 0.666174055927796
Validation loss: 2.3276111635600945

Epoch: 6| Step: 8
Training loss: 0.5407931424662646
Validation loss: 2.3151614680377577

Epoch: 6| Step: 9
Training loss: 0.4295666437980143
Validation loss: 2.3191273306105513

Epoch: 6| Step: 10
Training loss: 0.7562409455569147
Validation loss: 2.3080883609437226

Epoch: 6| Step: 11
Training loss: 0.5049207662044618
Validation loss: 2.3001810121665494

Epoch: 6| Step: 12
Training loss: 0.639784657191398
Validation loss: 2.287028297681277

Epoch: 6| Step: 13
Training loss: 0.7449538625601536
Validation loss: 2.286292030516283

Epoch: 366| Step: 0
Training loss: 0.41242032726623934
Validation loss: 2.280138881021407

Epoch: 6| Step: 1
Training loss: 0.6289684430759068
Validation loss: 2.2502951388559436

Epoch: 6| Step: 2
Training loss: 0.4281316158034109
Validation loss: 2.2764136809918036

Epoch: 6| Step: 3
Training loss: 0.8701565751773653
Validation loss: 2.294157023815709

Epoch: 6| Step: 4
Training loss: 0.47263459085067205
Validation loss: 2.3016777729990983

Epoch: 6| Step: 5
Training loss: 0.6664418844912176
Validation loss: 2.309388874628438

Epoch: 6| Step: 6
Training loss: 0.6042756661932751
Validation loss: 2.2956870665717917

Epoch: 6| Step: 7
Training loss: 0.7027617893946776
Validation loss: 2.2991196384499695

Epoch: 6| Step: 8
Training loss: 0.4168951381697697
Validation loss: 2.285282115486739

Epoch: 6| Step: 9
Training loss: 0.5662555888828564
Validation loss: 2.304609734759852

Epoch: 6| Step: 10
Training loss: 0.5806196363219833
Validation loss: 2.2705824168555337

Epoch: 6| Step: 11
Training loss: 0.370270830538221
Validation loss: 2.295307310015531

Epoch: 6| Step: 12
Training loss: 0.6980006086816839
Validation loss: 2.28278872629361

Epoch: 6| Step: 13
Training loss: 0.24442278007091506
Validation loss: 2.2690788864358726

Epoch: 367| Step: 0
Training loss: 0.7923575615661743
Validation loss: 2.2723099102998496

Epoch: 6| Step: 1
Training loss: 0.5260938738105341
Validation loss: 2.273675643716324

Epoch: 6| Step: 2
Training loss: 0.39247226711264266
Validation loss: 2.294708994162239

Epoch: 6| Step: 3
Training loss: 0.4579650435985879
Validation loss: 2.3085999164714446

Epoch: 6| Step: 4
Training loss: 0.6163412642459521
Validation loss: 2.3438704308636735

Epoch: 6| Step: 5
Training loss: 0.3760398117963671
Validation loss: 2.316997756974342

Epoch: 6| Step: 6
Training loss: 0.5234768980771115
Validation loss: 2.324886485793331

Epoch: 6| Step: 7
Training loss: 0.8055141980052362
Validation loss: 2.31505818618195

Epoch: 6| Step: 8
Training loss: 0.8441101294661849
Validation loss: 2.279814226890703

Epoch: 6| Step: 9
Training loss: 0.41293768781447265
Validation loss: 2.3127538801634833

Epoch: 6| Step: 10
Training loss: 0.5838195415056253
Validation loss: 2.299166418914638

Epoch: 6| Step: 11
Training loss: 0.5775357929713846
Validation loss: 2.3307941665334795

Epoch: 6| Step: 12
Training loss: 0.35618623698288915
Validation loss: 2.3077543909434524

Epoch: 6| Step: 13
Training loss: 0.43087751154974097
Validation loss: 2.30442566299359

Epoch: 368| Step: 0
Training loss: 0.6040302539157859
Validation loss: 2.304496204076978

Epoch: 6| Step: 1
Training loss: 0.9171288726629211
Validation loss: 2.3210967888663454

Epoch: 6| Step: 2
Training loss: 0.5621168368058337
Validation loss: 2.320784380105558

Epoch: 6| Step: 3
Training loss: 0.48136961614628687
Validation loss: 2.3177167910045586

Epoch: 6| Step: 4
Training loss: 0.6666393324096123
Validation loss: 2.293210940822763

Epoch: 6| Step: 5
Training loss: 0.3282817738532018
Validation loss: 2.304063472036524

Epoch: 6| Step: 6
Training loss: 0.41053906695547693
Validation loss: 2.293029073286586

Epoch: 6| Step: 7
Training loss: 0.23187566736541704
Validation loss: 2.2966010208132857

Epoch: 6| Step: 8
Training loss: 0.6860353951776164
Validation loss: 2.301270987819526

Epoch: 6| Step: 9
Training loss: 0.297223112898727
Validation loss: 2.2840959572473873

Epoch: 6| Step: 10
Training loss: 0.5463704642843064
Validation loss: 2.306953857851063

Epoch: 6| Step: 11
Training loss: 0.6926401625816734
Validation loss: 2.3061590575671174

Epoch: 6| Step: 12
Training loss: 0.6483845976425671
Validation loss: 2.337613810195204

Epoch: 6| Step: 13
Training loss: 0.25225089464038425
Validation loss: 2.3180013580380576

Epoch: 369| Step: 0
Training loss: 0.6215173728138228
Validation loss: 2.3627066626731934

Epoch: 6| Step: 1
Training loss: 0.7222596188383698
Validation loss: 2.3266978663589164

Epoch: 6| Step: 2
Training loss: 0.44815754143156633
Validation loss: 2.2967942551319074

Epoch: 6| Step: 3
Training loss: 0.7873282684299999
Validation loss: 2.2897780499512423

Epoch: 6| Step: 4
Training loss: 0.4657333100840698
Validation loss: 2.277432749561644

Epoch: 6| Step: 5
Training loss: 0.6862643799030838
Validation loss: 2.2919443752760373

Epoch: 6| Step: 6
Training loss: 0.4260192870656529
Validation loss: 2.2952641713811945

Epoch: 6| Step: 7
Training loss: 0.6870791057189032
Validation loss: 2.2799310572836164

Epoch: 6| Step: 8
Training loss: 0.48172242892305406
Validation loss: 2.286799588678266

Epoch: 6| Step: 9
Training loss: 0.407003547472572
Validation loss: 2.3253755655799115

Epoch: 6| Step: 10
Training loss: 0.759514107541121
Validation loss: 2.316032500841479

Epoch: 6| Step: 11
Training loss: 0.5507900967800559
Validation loss: 2.308131100788118

Epoch: 6| Step: 12
Training loss: 0.27456697432382404
Validation loss: 2.3203944146237214

Epoch: 6| Step: 13
Training loss: 0.2663668762822815
Validation loss: 2.3141996384090584

Epoch: 370| Step: 0
Training loss: 0.3449163697819716
Validation loss: 2.295043136684931

Epoch: 6| Step: 1
Training loss: 0.4697269114534664
Validation loss: 2.278264204328392

Epoch: 6| Step: 2
Training loss: 0.5654552763582511
Validation loss: 2.293316651445881

Epoch: 6| Step: 3
Training loss: 0.4692812769917068
Validation loss: 2.3052887174262624

Epoch: 6| Step: 4
Training loss: 0.5540547052255751
Validation loss: 2.2882280551783634

Epoch: 6| Step: 5
Training loss: 0.4003437852211093
Validation loss: 2.2883786210921855

Epoch: 6| Step: 6
Training loss: 0.6034959462732103
Validation loss: 2.311299390678237

Epoch: 6| Step: 7
Training loss: 0.5201833833978216
Validation loss: 2.305215189572771

Epoch: 6| Step: 8
Training loss: 0.51230311333505
Validation loss: 2.320244083312225

Epoch: 6| Step: 9
Training loss: 0.7409487374884266
Validation loss: 2.2984154258181047

Epoch: 6| Step: 10
Training loss: 0.660004231482726
Validation loss: 2.272201059774598

Epoch: 6| Step: 11
Training loss: 0.5987233129299893
Validation loss: 2.275981643691403

Epoch: 6| Step: 12
Training loss: 0.5941817069412753
Validation loss: 2.2902795600403683

Epoch: 6| Step: 13
Training loss: 0.6604063248852486
Validation loss: 2.3031617706921463

Epoch: 371| Step: 0
Training loss: 0.2782660849764116
Validation loss: 2.3107784612414592

Epoch: 6| Step: 1
Training loss: 0.3939540152848523
Validation loss: 2.268903440762964

Epoch: 6| Step: 2
Training loss: 0.6067259257538425
Validation loss: 2.298723759377762

Epoch: 6| Step: 3
Training loss: 0.6211203803345313
Validation loss: 2.2819007078096836

Epoch: 6| Step: 4
Training loss: 0.6483427461081411
Validation loss: 2.2924436540375726

Epoch: 6| Step: 5
Training loss: 0.40421696117286954
Validation loss: 2.28230793676438

Epoch: 6| Step: 6
Training loss: 0.6436077321814996
Validation loss: 2.309011896731452

Epoch: 6| Step: 7
Training loss: 0.6072424964127092
Validation loss: 2.315231326578666

Epoch: 6| Step: 8
Training loss: 0.6072445086124493
Validation loss: 2.2946446673260885

Epoch: 6| Step: 9
Training loss: 0.36139472141506407
Validation loss: 2.3092375140670414

Epoch: 6| Step: 10
Training loss: 0.6211610913507097
Validation loss: 2.2840892105664654

Epoch: 6| Step: 11
Training loss: 0.36600116061980287
Validation loss: 2.3047723408651435

Epoch: 6| Step: 12
Training loss: 0.8144587967123971
Validation loss: 2.2835207970726925

Epoch: 6| Step: 13
Training loss: 0.38552060100538454
Validation loss: 2.298868204743346

Epoch: 372| Step: 0
Training loss: 0.5730847170035883
Validation loss: 2.302209723611188

Epoch: 6| Step: 1
Training loss: 0.7189893738567581
Validation loss: 2.3089019823366157

Epoch: 6| Step: 2
Training loss: 0.6890586178209623
Validation loss: 2.294410170472493

Epoch: 6| Step: 3
Training loss: 0.6175905673989237
Validation loss: 2.2882201577426233

Epoch: 6| Step: 4
Training loss: 0.3985673094577864
Validation loss: 2.286793595481108

Epoch: 6| Step: 5
Training loss: 0.4798586158101772
Validation loss: 2.2800105424053276

Epoch: 6| Step: 6
Training loss: 0.40053172532820014
Validation loss: 2.3038973780900913

Epoch: 6| Step: 7
Training loss: 0.4666756987407242
Validation loss: 2.2817723081847228

Epoch: 6| Step: 8
Training loss: 0.4938664335272103
Validation loss: 2.2851254481015495

Epoch: 6| Step: 9
Training loss: 0.5274309156928787
Validation loss: 2.3104894334795962

Epoch: 6| Step: 10
Training loss: 0.6149028793268168
Validation loss: 2.2703874055531315

Epoch: 6| Step: 11
Training loss: 0.5500140968596939
Validation loss: 2.2990615835888835

Epoch: 6| Step: 12
Training loss: 0.4155521766423371
Validation loss: 2.3049107686235173

Epoch: 6| Step: 13
Training loss: 0.5058718352090386
Validation loss: 2.3215878463658632

Epoch: 373| Step: 0
Training loss: 0.4531375455763856
Validation loss: 2.310770443951398

Epoch: 6| Step: 1
Training loss: 0.5903848856321026
Validation loss: 2.315440715172342

Epoch: 6| Step: 2
Training loss: 0.42307041486656066
Validation loss: 2.2952035505293424

Epoch: 6| Step: 3
Training loss: 0.6955085649408621
Validation loss: 2.3043329788321563

Epoch: 6| Step: 4
Training loss: 0.5544153271084639
Validation loss: 2.2947313240167095

Epoch: 6| Step: 5
Training loss: 0.534878401083763
Validation loss: 2.318316850813817

Epoch: 6| Step: 6
Training loss: 0.3316673977922084
Validation loss: 2.2883534604299456

Epoch: 6| Step: 7
Training loss: 0.529985156301248
Validation loss: 2.3113515874142907

Epoch: 6| Step: 8
Training loss: 0.41563745781147216
Validation loss: 2.302088389523125

Epoch: 6| Step: 9
Training loss: 0.6473348963797517
Validation loss: 2.288528100574884

Epoch: 6| Step: 10
Training loss: 0.6026997653322727
Validation loss: 2.301381476096077

Epoch: 6| Step: 11
Training loss: 0.589525452683145
Validation loss: 2.307457888850925

Epoch: 6| Step: 12
Training loss: 0.4465519237400417
Validation loss: 2.305541510818619

Epoch: 6| Step: 13
Training loss: 0.692854103487621
Validation loss: 2.3268297976228953

Epoch: 374| Step: 0
Training loss: 0.3232397672902575
Validation loss: 2.283296836409845

Epoch: 6| Step: 1
Training loss: 0.5386714622711747
Validation loss: 2.285012299594827

Epoch: 6| Step: 2
Training loss: 0.8282854176740096
Validation loss: 2.3037317707124245

Epoch: 6| Step: 3
Training loss: 0.451123883225646
Validation loss: 2.3027764797270946

Epoch: 6| Step: 4
Training loss: 0.5810086528590058
Validation loss: 2.2894721217136755

Epoch: 6| Step: 5
Training loss: 0.45749998916042295
Validation loss: 2.3151884739230244

Epoch: 6| Step: 6
Training loss: 0.4155281685485902
Validation loss: 2.302859594224772

Epoch: 6| Step: 7
Training loss: 0.848405462963334
Validation loss: 2.3112657407693367

Epoch: 6| Step: 8
Training loss: 0.5738148209267603
Validation loss: 2.3207213537839957

Epoch: 6| Step: 9
Training loss: 0.2368122533060472
Validation loss: 2.3000291222828126

Epoch: 6| Step: 10
Training loss: 0.381338434437554
Validation loss: 2.2877388758440205

Epoch: 6| Step: 11
Training loss: 0.4506209506621408
Validation loss: 2.3056791263119556

Epoch: 6| Step: 12
Training loss: 0.3012704710118801
Validation loss: 2.28817559817182

Epoch: 6| Step: 13
Training loss: 0.6630715549802493
Validation loss: 2.3014295706988372

Epoch: 375| Step: 0
Training loss: 0.3504388229579184
Validation loss: 2.3193806876165333

Epoch: 6| Step: 1
Training loss: 0.7013606930301646
Validation loss: 2.312267016797191

Epoch: 6| Step: 2
Training loss: 0.5282794139777126
Validation loss: 2.3043149379675487

Epoch: 6| Step: 3
Training loss: 0.29918825975253494
Validation loss: 2.2979614498740055

Epoch: 6| Step: 4
Training loss: 0.5094876463200072
Validation loss: 2.2916794691725695

Epoch: 6| Step: 5
Training loss: 0.569642261000004
Validation loss: 2.3140247177453253

Epoch: 6| Step: 6
Training loss: 0.7277033473150807
Validation loss: 2.303377808638218

Epoch: 6| Step: 7
Training loss: 0.38798145333308787
Validation loss: 2.2807578352290414

Epoch: 6| Step: 8
Training loss: 0.7221812981438688
Validation loss: 2.298310036996456

Epoch: 6| Step: 9
Training loss: 0.36404993911489075
Validation loss: 2.2853289503606713

Epoch: 6| Step: 10
Training loss: 0.3887821596955357
Validation loss: 2.2991964609845863

Epoch: 6| Step: 11
Training loss: 0.5044757670507806
Validation loss: 2.2799770502607823

Epoch: 6| Step: 12
Training loss: 0.6205392437527718
Validation loss: 2.3121163732642116

Epoch: 6| Step: 13
Training loss: 0.30224663606511826
Validation loss: 2.296631371599444

Epoch: 376| Step: 0
Training loss: 0.5955294997037468
Validation loss: 2.313361774762789

Epoch: 6| Step: 1
Training loss: 0.40248164804452174
Validation loss: 2.322435319683944

Epoch: 6| Step: 2
Training loss: 0.18006124189758907
Validation loss: 2.3230961920119344

Epoch: 6| Step: 3
Training loss: 0.7820839817435318
Validation loss: 2.304346072722237

Epoch: 6| Step: 4
Training loss: 0.48181453884622183
Validation loss: 2.2980444819370054

Epoch: 6| Step: 5
Training loss: 0.49228585486654763
Validation loss: 2.2969067306062416

Epoch: 6| Step: 6
Training loss: 0.5916559788137077
Validation loss: 2.29579695481514

Epoch: 6| Step: 7
Training loss: 0.7044157895765264
Validation loss: 2.274314859081023

Epoch: 6| Step: 8
Training loss: 0.49732311243113153
Validation loss: 2.2913845488962026

Epoch: 6| Step: 9
Training loss: 0.3447780408596669
Validation loss: 2.3089162566810377

Epoch: 6| Step: 10
Training loss: 0.6801143270691703
Validation loss: 2.302253748760599

Epoch: 6| Step: 11
Training loss: 0.36775571402591095
Validation loss: 2.3001243226887205

Epoch: 6| Step: 12
Training loss: 0.3739825193965946
Validation loss: 2.325929057429542

Epoch: 6| Step: 13
Training loss: 0.44252698961481646
Validation loss: 2.3201855537439027

Epoch: 377| Step: 0
Training loss: 0.6427408029854552
Validation loss: 2.301378892827709

Epoch: 6| Step: 1
Training loss: 0.45626879940755627
Validation loss: 2.3218350249585784

Epoch: 6| Step: 2
Training loss: 0.5994592037461967
Validation loss: 2.322923624307955

Epoch: 6| Step: 3
Training loss: 0.5484807554396753
Validation loss: 2.305665564660452

Epoch: 6| Step: 4
Training loss: 0.38671605272990073
Validation loss: 2.287040893182918

Epoch: 6| Step: 5
Training loss: 0.25071288332636205
Validation loss: 2.305458202778488

Epoch: 6| Step: 6
Training loss: 0.32989330873566286
Validation loss: 2.298943966262528

Epoch: 6| Step: 7
Training loss: 0.43583855890541523
Validation loss: 2.299330052734825

Epoch: 6| Step: 8
Training loss: 0.5834348510780129
Validation loss: 2.289493853194497

Epoch: 6| Step: 9
Training loss: 0.5122479912423867
Validation loss: 2.3000941940974

Epoch: 6| Step: 10
Training loss: 0.4901871221497857
Validation loss: 2.3355223551259083

Epoch: 6| Step: 11
Training loss: 0.6426315285425813
Validation loss: 2.286847930537152

Epoch: 6| Step: 12
Training loss: 0.7666763172026018
Validation loss: 2.305114052553201

Epoch: 6| Step: 13
Training loss: 0.17206932591513763
Validation loss: 2.294784862833

Epoch: 378| Step: 0
Training loss: 0.5664917716870607
Validation loss: 2.3197942393696747

Epoch: 6| Step: 1
Training loss: 0.48776996546853985
Validation loss: 2.303873974806501

Epoch: 6| Step: 2
Training loss: 0.3305609067293178
Validation loss: 2.3244307358856715

Epoch: 6| Step: 3
Training loss: 0.6204829061214664
Validation loss: 2.307719783406415

Epoch: 6| Step: 4
Training loss: 0.4125954532000171
Validation loss: 2.2785735804386986

Epoch: 6| Step: 5
Training loss: 0.524002993849945
Validation loss: 2.333113506908082

Epoch: 6| Step: 6
Training loss: 0.6205562208850944
Validation loss: 2.3012209527356906

Epoch: 6| Step: 7
Training loss: 0.46657255201504394
Validation loss: 2.2921555874785633

Epoch: 6| Step: 8
Training loss: 0.5770017692499125
Validation loss: 2.303875179916725

Epoch: 6| Step: 9
Training loss: 0.660606411371928
Validation loss: 2.2991985984690935

Epoch: 6| Step: 10
Training loss: 0.46864729391891996
Validation loss: 2.317535053968653

Epoch: 6| Step: 11
Training loss: 0.16641961478350584
Validation loss: 2.268534657933393

Epoch: 6| Step: 12
Training loss: 0.6087233898683774
Validation loss: 2.3212322584482745

Epoch: 6| Step: 13
Training loss: 0.125664405573269
Validation loss: 2.305117130992002

Epoch: 379| Step: 0
Training loss: 0.6097433981794166
Validation loss: 2.3090765105633695

Epoch: 6| Step: 1
Training loss: 0.5868541667925187
Validation loss: 2.3268254918860154

Epoch: 6| Step: 2
Training loss: 0.3480897408235784
Validation loss: 2.308878877386596

Epoch: 6| Step: 3
Training loss: 0.3926045802677547
Validation loss: 2.2782487341950106

Epoch: 6| Step: 4
Training loss: 0.3749261624440253
Validation loss: 2.272049956062162

Epoch: 6| Step: 5
Training loss: 0.7505227492389849
Validation loss: 2.285671403592687

Epoch: 6| Step: 6
Training loss: 0.44660120759588035
Validation loss: 2.2582408715671156

Epoch: 6| Step: 7
Training loss: 0.4908809880900945
Validation loss: 2.2951670447766364

Epoch: 6| Step: 8
Training loss: 0.7766064161321005
Validation loss: 2.2957792996840825

Epoch: 6| Step: 9
Training loss: 0.5403378093168547
Validation loss: 2.3079721489049434

Epoch: 6| Step: 10
Training loss: 0.23451102600986581
Validation loss: 2.308608130634457

Epoch: 6| Step: 11
Training loss: 0.14968171176191683
Validation loss: 2.314746250199066

Epoch: 6| Step: 12
Training loss: 0.5214989192234591
Validation loss: 2.3086052656194482

Epoch: 6| Step: 13
Training loss: 0.45160772895677986
Validation loss: 2.281480564856212

Epoch: 380| Step: 0
Training loss: 0.6526887860634792
Validation loss: 2.306163748723368

Epoch: 6| Step: 1
Training loss: 0.516299124959721
Validation loss: 2.307393954100519

Epoch: 6| Step: 2
Training loss: 0.470698661308176
Validation loss: 2.282699575047945

Epoch: 6| Step: 3
Training loss: 0.5193442388117125
Validation loss: 2.28711202706828

Epoch: 6| Step: 4
Training loss: 0.30074659370814544
Validation loss: 2.2861749956227215

Epoch: 6| Step: 5
Training loss: 0.5549635938783692
Validation loss: 2.293583541632603

Epoch: 6| Step: 6
Training loss: 0.39986787491437037
Validation loss: 2.2958684002896925

Epoch: 6| Step: 7
Training loss: 0.47953208866089553
Validation loss: 2.310061101280713

Epoch: 6| Step: 8
Training loss: 0.5942372782063228
Validation loss: 2.2855648096593226

Epoch: 6| Step: 9
Training loss: 0.40707667311481704
Validation loss: 2.3190638380729713

Epoch: 6| Step: 10
Training loss: 0.5621228808277605
Validation loss: 2.3011193358803186

Epoch: 6| Step: 11
Training loss: 0.4720953142823645
Validation loss: 2.2894430505316707

Epoch: 6| Step: 12
Training loss: 0.5742996574026206
Validation loss: 2.3001311605416856

Epoch: 6| Step: 13
Training loss: 0.15753787478437414
Validation loss: 2.2884051381299284

Epoch: 381| Step: 0
Training loss: 0.7693782983580603
Validation loss: 2.2842055417231952

Epoch: 6| Step: 1
Training loss: 0.3353529213026331
Validation loss: 2.290671759253515

Epoch: 6| Step: 2
Training loss: 0.5455942142186789
Validation loss: 2.290194197678022

Epoch: 6| Step: 3
Training loss: 0.6411432867880191
Validation loss: 2.2769045030726462

Epoch: 6| Step: 4
Training loss: 0.3340958191837271
Validation loss: 2.3073022080551038

Epoch: 6| Step: 5
Training loss: 0.3673140530932314
Validation loss: 2.288122631295552

Epoch: 6| Step: 6
Training loss: 0.3141058787474038
Validation loss: 2.270133646112207

Epoch: 6| Step: 7
Training loss: 0.5045317678250999
Validation loss: 2.2903816420115093

Epoch: 6| Step: 8
Training loss: 0.7396900520876979
Validation loss: 2.2711620681797497

Epoch: 6| Step: 9
Training loss: 0.6026107275585612
Validation loss: 2.2977975880547796

Epoch: 6| Step: 10
Training loss: 0.28951050862657296
Validation loss: 2.282087757996523

Epoch: 6| Step: 11
Training loss: 0.3666728654070164
Validation loss: 2.28664793331471

Epoch: 6| Step: 12
Training loss: 0.15420109153997005
Validation loss: 2.290602224450205

Epoch: 6| Step: 13
Training loss: 0.5540356096260453
Validation loss: 2.289502462308665

Epoch: 382| Step: 0
Training loss: 0.6844531950848808
Validation loss: 2.3181925939792016

Epoch: 6| Step: 1
Training loss: 0.4726319109742583
Validation loss: 2.277425356140684

Epoch: 6| Step: 2
Training loss: 0.2247933505039121
Validation loss: 2.2748547307389857

Epoch: 6| Step: 3
Training loss: 0.36656806317178703
Validation loss: 2.2911147268654855

Epoch: 6| Step: 4
Training loss: 0.21181967606577445
Validation loss: 2.2655887588131374

Epoch: 6| Step: 5
Training loss: 0.5972751574257702
Validation loss: 2.278927626569957

Epoch: 6| Step: 6
Training loss: 0.4628788749394588
Validation loss: 2.2932084131901895

Epoch: 6| Step: 7
Training loss: 0.3030735208116694
Validation loss: 2.2927804334200714

Epoch: 6| Step: 8
Training loss: 0.4927481833453006
Validation loss: 2.291124206302446

Epoch: 6| Step: 9
Training loss: 0.2773941961267116
Validation loss: 2.2934396051430457

Epoch: 6| Step: 10
Training loss: 0.5542326391957065
Validation loss: 2.3167265780334634

Epoch: 6| Step: 11
Training loss: 0.7997695859255929
Validation loss: 2.335923923056923

Epoch: 6| Step: 12
Training loss: 0.5136077898901663
Validation loss: 2.304786000650525

Epoch: 6| Step: 13
Training loss: 0.6044537558225052
Validation loss: 2.2986099675360565

Epoch: 383| Step: 0
Training loss: 0.2677228633608699
Validation loss: 2.277575417173561

Epoch: 6| Step: 1
Training loss: 0.45310969162436654
Validation loss: 2.2913659563151607

Epoch: 6| Step: 2
Training loss: 0.30235682910160594
Validation loss: 2.283268524207058

Epoch: 6| Step: 3
Training loss: 0.43414845081831877
Validation loss: 2.309591370358475

Epoch: 6| Step: 4
Training loss: 0.7488491049440837
Validation loss: 2.320096943364146

Epoch: 6| Step: 5
Training loss: 0.2760087374473803
Validation loss: 2.3274585501983123

Epoch: 6| Step: 6
Training loss: 0.510229141145426
Validation loss: 2.317024534000055

Epoch: 6| Step: 7
Training loss: 0.3155246981265183
Validation loss: 2.335951993253011

Epoch: 6| Step: 8
Training loss: 0.5544238202554609
Validation loss: 2.3280594535652703

Epoch: 6| Step: 9
Training loss: 0.505826323029626
Validation loss: 2.3158310653686693

Epoch: 6| Step: 10
Training loss: 0.6425071839476441
Validation loss: 2.3237980679116017

Epoch: 6| Step: 11
Training loss: 0.42421017843617737
Validation loss: 2.2987694293302146

Epoch: 6| Step: 12
Training loss: 0.6483559844473874
Validation loss: 2.325583934990025

Epoch: 6| Step: 13
Training loss: 0.5482293116923097
Validation loss: 2.327796068758516

Epoch: 384| Step: 0
Training loss: 0.4345266255911434
Validation loss: 2.297864079150956

Epoch: 6| Step: 1
Training loss: 0.5361273093019301
Validation loss: 2.3028642815265674

Epoch: 6| Step: 2
Training loss: 0.6597126480433991
Validation loss: 2.2970409131086584

Epoch: 6| Step: 3
Training loss: 0.29561086094616523
Validation loss: 2.3078790584244198

Epoch: 6| Step: 4
Training loss: 0.233571367562981
Validation loss: 2.316383103693895

Epoch: 6| Step: 5
Training loss: 0.6743593416349434
Validation loss: 2.3206819005676045

Epoch: 6| Step: 6
Training loss: 0.24710797411087077
Validation loss: 2.3174632963419293

Epoch: 6| Step: 7
Training loss: 0.6149572808075128
Validation loss: 2.3005322712100633

Epoch: 6| Step: 8
Training loss: 0.4762740121880545
Validation loss: 2.2880688788862766

Epoch: 6| Step: 9
Training loss: 0.33255037229133133
Validation loss: 2.329985687215948

Epoch: 6| Step: 10
Training loss: 0.5220469037483232
Validation loss: 2.3153032901267894

Epoch: 6| Step: 11
Training loss: 0.5660604802715082
Validation loss: 2.3091073440814665

Epoch: 6| Step: 12
Training loss: 0.62473558554749
Validation loss: 2.2881426272056826

Epoch: 6| Step: 13
Training loss: 0.4077706121804887
Validation loss: 2.2910776031922575

Epoch: 385| Step: 0
Training loss: 0.40392275099555863
Validation loss: 2.325578646942612

Epoch: 6| Step: 1
Training loss: 0.4766595772847366
Validation loss: 2.317337241657548

Epoch: 6| Step: 2
Training loss: 0.5546212492586647
Validation loss: 2.3100958279984387

Epoch: 6| Step: 3
Training loss: 0.4532219848759353
Validation loss: 2.340333380256248

Epoch: 6| Step: 4
Training loss: 0.507750169890172
Validation loss: 2.3242240168752306

Epoch: 6| Step: 5
Training loss: 0.4952448994327186
Validation loss: 2.3052791680680556

Epoch: 6| Step: 6
Training loss: 0.3485287315950103
Validation loss: 2.327194342786295

Epoch: 6| Step: 7
Training loss: 0.4378463702336828
Validation loss: 2.313231060250516

Epoch: 6| Step: 8
Training loss: 0.4609323598284138
Validation loss: 2.3079073608603724

Epoch: 6| Step: 9
Training loss: 0.557923882314085
Validation loss: 2.293855201195542

Epoch: 6| Step: 10
Training loss: 0.6632284873582267
Validation loss: 2.342286748205628

Epoch: 6| Step: 11
Training loss: 0.5026640255189985
Validation loss: 2.3207528931182204

Epoch: 6| Step: 12
Training loss: 0.3815842992005735
Validation loss: 2.3227294584509495

Epoch: 6| Step: 13
Training loss: 0.46235074779581625
Validation loss: 2.3055889590671566

Epoch: 386| Step: 0
Training loss: 0.6039427199708076
Validation loss: 2.2843547398797597

Epoch: 6| Step: 1
Training loss: 0.2802821965460521
Validation loss: 2.2903366017667084

Epoch: 6| Step: 2
Training loss: 0.37985731495307307
Validation loss: 2.2986826131531553

Epoch: 6| Step: 3
Training loss: 0.5358371996653571
Validation loss: 2.299172884967299

Epoch: 6| Step: 4
Training loss: 0.3164222148117163
Validation loss: 2.3010926002115077

Epoch: 6| Step: 5
Training loss: 0.4918571756373667
Validation loss: 2.2890841104960855

Epoch: 6| Step: 6
Training loss: 0.5247182691866215
Validation loss: 2.3101199617166186

Epoch: 6| Step: 7
Training loss: 0.4923884571906432
Validation loss: 2.2987608599403884

Epoch: 6| Step: 8
Training loss: 0.5196685322817155
Validation loss: 2.276878175242262

Epoch: 6| Step: 9
Training loss: 0.48247302320895585
Validation loss: 2.2921656590170447

Epoch: 6| Step: 10
Training loss: 0.5389108582761657
Validation loss: 2.287753319214369

Epoch: 6| Step: 11
Training loss: 0.36089847898725613
Validation loss: 2.273070356733629

Epoch: 6| Step: 12
Training loss: 0.20770924591570544
Validation loss: 2.2753675279110044

Epoch: 6| Step: 13
Training loss: 0.7224543108897906
Validation loss: 2.2850374614256386

Epoch: 387| Step: 0
Training loss: 0.5369348693346283
Validation loss: 2.2737457266041874

Epoch: 6| Step: 1
Training loss: 0.5713717408956256
Validation loss: 2.254623115106967

Epoch: 6| Step: 2
Training loss: 0.5640795042058562
Validation loss: 2.2959650762721098

Epoch: 6| Step: 3
Training loss: 0.36338177182370435
Validation loss: 2.251336292246621

Epoch: 6| Step: 4
Training loss: 0.46173747197387616
Validation loss: 2.3048654939784483

Epoch: 6| Step: 5
Training loss: 0.48302486897057056
Validation loss: 2.323004341061997

Epoch: 6| Step: 6
Training loss: 0.5372823540702787
Validation loss: 2.2657268960943413

Epoch: 6| Step: 7
Training loss: 0.4256210900853923
Validation loss: 2.305547194808173

Epoch: 6| Step: 8
Training loss: 0.4140739979137218
Validation loss: 2.2889232017038426

Epoch: 6| Step: 9
Training loss: 0.29027629872958777
Validation loss: 2.297782602552289

Epoch: 6| Step: 10
Training loss: 0.5483215546381589
Validation loss: 2.303266936960219

Epoch: 6| Step: 11
Training loss: 0.34942769279356706
Validation loss: 2.316354182106956

Epoch: 6| Step: 12
Training loss: 0.531001397475866
Validation loss: 2.303763900963365

Epoch: 6| Step: 13
Training loss: 0.3343165569390881
Validation loss: 2.2900998222990507

Epoch: 388| Step: 0
Training loss: 0.3557749466972212
Validation loss: 2.3312572884368032

Epoch: 6| Step: 1
Training loss: 0.41778703108363097
Validation loss: 2.2809078568509658

Epoch: 6| Step: 2
Training loss: 0.5388003278445271
Validation loss: 2.310751280668248

Epoch: 6| Step: 3
Training loss: 0.17483292250392538
Validation loss: 2.292014123263136

Epoch: 6| Step: 4
Training loss: 0.6374418213420388
Validation loss: 2.291586931208147

Epoch: 6| Step: 5
Training loss: 0.6397059989829792
Validation loss: 2.2814836279897706

Epoch: 6| Step: 6
Training loss: 0.43234037408313764
Validation loss: 2.306415291888951

Epoch: 6| Step: 7
Training loss: 0.30267937683620433
Validation loss: 2.2902683854714003

Epoch: 6| Step: 8
Training loss: 0.654567332380777
Validation loss: 2.282842965760902

Epoch: 6| Step: 9
Training loss: 0.24336755043858216
Validation loss: 2.3017130441512292

Epoch: 6| Step: 10
Training loss: 0.47684620401576094
Validation loss: 2.2837270868148103

Epoch: 6| Step: 11
Training loss: 0.44212963952328393
Validation loss: 2.2892718654934505

Epoch: 6| Step: 12
Training loss: 0.32515786215929227
Validation loss: 2.271842804045161

Epoch: 6| Step: 13
Training loss: 0.6307491997567451
Validation loss: 2.2650848304848026

Epoch: 389| Step: 0
Training loss: 0.5357757101720949
Validation loss: 2.3085004291655338

Epoch: 6| Step: 1
Training loss: 0.450528234814243
Validation loss: 2.2917808892058034

Epoch: 6| Step: 2
Training loss: 0.6223688292663847
Validation loss: 2.29782726645835

Epoch: 6| Step: 3
Training loss: 0.4953569061397781
Validation loss: 2.2936766735757024

Epoch: 6| Step: 4
Training loss: 0.5712812113426191
Validation loss: 2.3178243418400233

Epoch: 6| Step: 5
Training loss: 0.4526816863240087
Validation loss: 2.2997767680277708

Epoch: 6| Step: 6
Training loss: 0.5060971853593648
Validation loss: 2.2819134821579072

Epoch: 6| Step: 7
Training loss: 0.4536545553000341
Validation loss: 2.3223904992731126

Epoch: 6| Step: 8
Training loss: 0.3445847087050039
Validation loss: 2.317770836929728

Epoch: 6| Step: 9
Training loss: 0.3898167449832575
Validation loss: 2.332538747048979

Epoch: 6| Step: 10
Training loss: 0.28416124264349946
Validation loss: 2.3199373264204746

Epoch: 6| Step: 11
Training loss: 0.33692803837633994
Validation loss: 2.3377389985371657

Epoch: 6| Step: 12
Training loss: 0.49905904504754117
Validation loss: 2.320871171469602

Epoch: 6| Step: 13
Training loss: 0.30169522769135637
Validation loss: 2.289440593763606

Epoch: 390| Step: 0
Training loss: 0.3823182554985735
Validation loss: 2.2993634051409693

Epoch: 6| Step: 1
Training loss: 0.22736083979131824
Validation loss: 2.310690935202511

Epoch: 6| Step: 2
Training loss: 0.3866282655841347
Validation loss: 2.289082852801267

Epoch: 6| Step: 3
Training loss: 0.714914078718414
Validation loss: 2.298225226960216

Epoch: 6| Step: 4
Training loss: 0.23169106903959755
Validation loss: 2.320482031487889

Epoch: 6| Step: 5
Training loss: 0.29049561912365196
Validation loss: 2.2920209176418442

Epoch: 6| Step: 6
Training loss: 0.3319934374651867
Validation loss: 2.310811242365858

Epoch: 6| Step: 7
Training loss: 0.6061508028733864
Validation loss: 2.3181488632383127

Epoch: 6| Step: 8
Training loss: 0.5962470151318706
Validation loss: 2.3198979935835666

Epoch: 6| Step: 9
Training loss: 0.5573768164448335
Validation loss: 2.3199887967457986

Epoch: 6| Step: 10
Training loss: 0.4143920882255911
Validation loss: 2.3154782808318566

Epoch: 6| Step: 11
Training loss: 0.504931331347061
Validation loss: 2.2972193823853204

Epoch: 6| Step: 12
Training loss: 0.4234098488763618
Validation loss: 2.2967942054618034

Epoch: 6| Step: 13
Training loss: 0.5192305476237093
Validation loss: 2.2941156448236795

Epoch: 391| Step: 0
Training loss: 0.32912244645593947
Validation loss: 2.300516935220013

Epoch: 6| Step: 1
Training loss: 0.5046993490428442
Validation loss: 2.29905712660451

Epoch: 6| Step: 2
Training loss: 0.4351804757351889
Validation loss: 2.3065029496121072

Epoch: 6| Step: 3
Training loss: 0.4516565931024992
Validation loss: 2.294904825308256

Epoch: 6| Step: 4
Training loss: 0.5192700640163507
Validation loss: 2.308702130582192

Epoch: 6| Step: 5
Training loss: 0.4880094152992338
Validation loss: 2.313713487018014

Epoch: 6| Step: 6
Training loss: 0.35984696619117945
Validation loss: 2.270346126879445

Epoch: 6| Step: 7
Training loss: 0.38354066765050926
Validation loss: 2.3028641345788823

Epoch: 6| Step: 8
Training loss: 0.5918156082663096
Validation loss: 2.2957697615799715

Epoch: 6| Step: 9
Training loss: 0.34911055115474027
Validation loss: 2.3082394872667136

Epoch: 6| Step: 10
Training loss: 0.46278085493536764
Validation loss: 2.284779639456165

Epoch: 6| Step: 11
Training loss: 0.4904290227000578
Validation loss: 2.3148281081808078

Epoch: 6| Step: 12
Training loss: 0.49017005285662674
Validation loss: 2.285152974146972

Epoch: 6| Step: 13
Training loss: 0.36431998778177743
Validation loss: 2.293761419318302

Epoch: 392| Step: 0
Training loss: 0.6469062972675268
Validation loss: 2.300695834071686

Epoch: 6| Step: 1
Training loss: 0.5431143476277823
Validation loss: 2.2904413170968385

Epoch: 6| Step: 2
Training loss: 0.39625572790103447
Validation loss: 2.3162861781001096

Epoch: 6| Step: 3
Training loss: 0.14953823788776593
Validation loss: 2.2960968049825303

Epoch: 6| Step: 4
Training loss: 0.42019358870863815
Validation loss: 2.288201554014456

Epoch: 6| Step: 5
Training loss: 0.250098864557281
Validation loss: 2.342136298419157

Epoch: 6| Step: 6
Training loss: 0.6821767889869129
Validation loss: 2.3473031438075624

Epoch: 6| Step: 7
Training loss: 0.44155921648644536
Validation loss: 2.348037069402709

Epoch: 6| Step: 8
Training loss: 0.16366584830466366
Validation loss: 2.3679496810353746

Epoch: 6| Step: 9
Training loss: 0.5440050294377138
Validation loss: 2.354912076768846

Epoch: 6| Step: 10
Training loss: 0.2906195229865374
Validation loss: 2.3577609670756496

Epoch: 6| Step: 11
Training loss: 0.4388523827616214
Validation loss: 2.314781114841109

Epoch: 6| Step: 12
Training loss: 0.34439890475652796
Validation loss: 2.347266123515377

Epoch: 6| Step: 13
Training loss: 0.7141267693309209
Validation loss: 2.3324584586122032

Epoch: 393| Step: 0
Training loss: 0.5070280324777985
Validation loss: 2.3031747977767854

Epoch: 6| Step: 1
Training loss: 0.5541391482966135
Validation loss: 2.318906529690665

Epoch: 6| Step: 2
Training loss: 0.4453817112995424
Validation loss: 2.315211987616644

Epoch: 6| Step: 3
Training loss: 0.37220051006828464
Validation loss: 2.3012036248311363

Epoch: 6| Step: 4
Training loss: 0.7394772081841317
Validation loss: 2.353792074901564

Epoch: 6| Step: 5
Training loss: 0.25698118852815527
Validation loss: 2.3156221914493695

Epoch: 6| Step: 6
Training loss: 0.4464672409067358
Validation loss: 2.3044147133269086

Epoch: 6| Step: 7
Training loss: 0.6686056123819182
Validation loss: 2.316210450341905

Epoch: 6| Step: 8
Training loss: 0.2990306342596284
Validation loss: 2.300503363753055

Epoch: 6| Step: 9
Training loss: 0.4504368727695401
Validation loss: 2.3065679315963927

Epoch: 6| Step: 10
Training loss: 0.36641282683694226
Validation loss: 2.2892049772876715

Epoch: 6| Step: 11
Training loss: 0.2987646147612781
Validation loss: 2.339699383218664

Epoch: 6| Step: 12
Training loss: 0.27242854482954754
Validation loss: 2.3206896405849475

Epoch: 6| Step: 13
Training loss: 0.5031157214333919
Validation loss: 2.3290926600264363

Epoch: 394| Step: 0
Training loss: 0.22618581435710422
Validation loss: 2.307251733619385

Epoch: 6| Step: 1
Training loss: 0.505637072170322
Validation loss: 2.2872151437344463

Epoch: 6| Step: 2
Training loss: 0.5733484952699804
Validation loss: 2.3178417527355624

Epoch: 6| Step: 3
Training loss: 0.588168157925674
Validation loss: 2.344072737810907

Epoch: 6| Step: 4
Training loss: 0.43568414825651786
Validation loss: 2.304502459940416

Epoch: 6| Step: 5
Training loss: 0.4120175046801588
Validation loss: 2.3268766721267116

Epoch: 6| Step: 6
Training loss: 0.4594710995589995
Validation loss: 2.3708672362678427

Epoch: 6| Step: 7
Training loss: 0.5957408455334637
Validation loss: 2.3402920213319467

Epoch: 6| Step: 8
Training loss: 0.5645391537271149
Validation loss: 2.3455897941308175

Epoch: 6| Step: 9
Training loss: 0.3828460522953687
Validation loss: 2.2885063072728027

Epoch: 6| Step: 10
Training loss: 0.2756919564989789
Validation loss: 2.289679212691104

Epoch: 6| Step: 11
Training loss: 0.5068566349338488
Validation loss: 2.306589007973376

Epoch: 6| Step: 12
Training loss: 0.4858559763927993
Validation loss: 2.292682826444509

Epoch: 6| Step: 13
Training loss: 0.3207986561604663
Validation loss: 2.3038050446238274

Epoch: 395| Step: 0
Training loss: 0.5665912983598141
Validation loss: 2.292101034872853

Epoch: 6| Step: 1
Training loss: 0.54061726250376
Validation loss: 2.30513845974445

Epoch: 6| Step: 2
Training loss: 0.2968492873249941
Validation loss: 2.299576150531973

Epoch: 6| Step: 3
Training loss: 0.5494008724122399
Validation loss: 2.3341003891651937

Epoch: 6| Step: 4
Training loss: 0.37521024611707615
Validation loss: 2.335195486841959

Epoch: 6| Step: 5
Training loss: 0.349120517543504
Validation loss: 2.318293501587984

Epoch: 6| Step: 6
Training loss: 0.5057786560463464
Validation loss: 2.3058875145125195

Epoch: 6| Step: 7
Training loss: 0.4976694359821543
Validation loss: 2.299340024278614

Epoch: 6| Step: 8
Training loss: 0.5413895564512562
Validation loss: 2.270702741769695

Epoch: 6| Step: 9
Training loss: 0.23826654576442555
Validation loss: 2.296785121953713

Epoch: 6| Step: 10
Training loss: 0.27665590228450254
Validation loss: 2.2787927836250295

Epoch: 6| Step: 11
Training loss: 0.609407032833826
Validation loss: 2.279875612830989

Epoch: 6| Step: 12
Training loss: 0.5507837931256392
Validation loss: 2.275003121148634

Epoch: 6| Step: 13
Training loss: 0.17710322146837898
Validation loss: 2.296232229421221

Epoch: 396| Step: 0
Training loss: 0.4229288713294589
Validation loss: 2.312928592959723

Epoch: 6| Step: 1
Training loss: 0.4952946331760828
Validation loss: 2.3180090024921007

Epoch: 6| Step: 2
Training loss: 0.6670324444665175
Validation loss: 2.3423761269254197

Epoch: 6| Step: 3
Training loss: 0.4783925735140407
Validation loss: 2.33581840411003

Epoch: 6| Step: 4
Training loss: 0.30145366859298045
Validation loss: 2.316620926115141

Epoch: 6| Step: 5
Training loss: 0.3250500695467178
Validation loss: 2.303854370256348

Epoch: 6| Step: 6
Training loss: 0.43669480068753397
Validation loss: 2.3036854969331193

Epoch: 6| Step: 7
Training loss: 0.24364133515649264
Validation loss: 2.3165926061911635

Epoch: 6| Step: 8
Training loss: 0.485831792563432
Validation loss: 2.3023929242075543

Epoch: 6| Step: 9
Training loss: 0.2846396351973116
Validation loss: 2.3109868694046396

Epoch: 6| Step: 10
Training loss: 0.28003783740960814
Validation loss: 2.283385832976204

Epoch: 6| Step: 11
Training loss: 0.43574100495934165
Validation loss: 2.3045208558739856

Epoch: 6| Step: 12
Training loss: 0.37935541017535135
Validation loss: 2.3075171439890356

Epoch: 6| Step: 13
Training loss: 0.7986168617004635
Validation loss: 2.320100777059053

Epoch: 397| Step: 0
Training loss: 0.4250111045508654
Validation loss: 2.2908913636776154

Epoch: 6| Step: 1
Training loss: 0.519978810896518
Validation loss: 2.3035807031175333

Epoch: 6| Step: 2
Training loss: 0.6454006227264497
Validation loss: 2.312966489537356

Epoch: 6| Step: 3
Training loss: 0.2117565378201036
Validation loss: 2.3211765475239843

Epoch: 6| Step: 4
Training loss: 0.3252952353433727
Validation loss: 2.304010685144186

Epoch: 6| Step: 5
Training loss: 0.27010236576704444
Validation loss: 2.3250699719579897

Epoch: 6| Step: 6
Training loss: 0.4523589960141281
Validation loss: 2.287702201667408

Epoch: 6| Step: 7
Training loss: 0.38288110001599496
Validation loss: 2.3023119647594155

Epoch: 6| Step: 8
Training loss: 0.7164343975032909
Validation loss: 2.323933464969591

Epoch: 6| Step: 9
Training loss: 0.5057198468288173
Validation loss: 2.3075369690589915

Epoch: 6| Step: 10
Training loss: 0.4892969325219525
Validation loss: 2.3320273133439775

Epoch: 6| Step: 11
Training loss: 0.33000906949873915
Validation loss: 2.324735038938689

Epoch: 6| Step: 12
Training loss: 0.17573943170513773
Validation loss: 2.333877027324449

Epoch: 6| Step: 13
Training loss: 0.12323998254293739
Validation loss: 2.338955058279037

Epoch: 398| Step: 0
Training loss: 0.5601392054392035
Validation loss: 2.324831574243393

Epoch: 6| Step: 1
Training loss: 0.4415953577104279
Validation loss: 2.320396742498705

Epoch: 6| Step: 2
Training loss: 0.4326119691693336
Validation loss: 2.3574013433563064

Epoch: 6| Step: 3
Training loss: 0.2517047515424436
Validation loss: 2.3323403576133113

Epoch: 6| Step: 4
Training loss: 0.41310556063024956
Validation loss: 2.3154440323213374

Epoch: 6| Step: 5
Training loss: 0.45812941118435124
Validation loss: 2.3187952014942104

Epoch: 6| Step: 6
Training loss: 0.2517193441543813
Validation loss: 2.3239035783141637

Epoch: 6| Step: 7
Training loss: 0.346698771206703
Validation loss: 2.3022700953996016

Epoch: 6| Step: 8
Training loss: 0.3270900958975881
Validation loss: 2.31775545240794

Epoch: 6| Step: 9
Training loss: 0.5076382264624206
Validation loss: 2.322153437755421

Epoch: 6| Step: 10
Training loss: 0.5916835563111594
Validation loss: 2.3200880151785155

Epoch: 6| Step: 11
Training loss: 0.19367251423387494
Validation loss: 2.3258737163762224

Epoch: 6| Step: 12
Training loss: 0.604373137501763
Validation loss: 2.3055897727176977

Epoch: 6| Step: 13
Training loss: 0.45543496217592505
Validation loss: 2.3085401111089907

Epoch: 399| Step: 0
Training loss: 0.6009843450766978
Validation loss: 2.3118205575891353

Epoch: 6| Step: 1
Training loss: 0.5276858315211594
Validation loss: 2.294862711887167

Epoch: 6| Step: 2
Training loss: 0.46439533884783873
Validation loss: 2.301018153366615

Epoch: 6| Step: 3
Training loss: 0.21132655821834645
Validation loss: 2.3015244514128317

Epoch: 6| Step: 4
Training loss: 0.32854717207492584
Validation loss: 2.324443209226145

Epoch: 6| Step: 5
Training loss: 0.5629343369273214
Validation loss: 2.3679902938183366

Epoch: 6| Step: 6
Training loss: 0.3214713162334306
Validation loss: 2.3282001398171013

Epoch: 6| Step: 7
Training loss: 0.6122728306028834
Validation loss: 2.368157194834017

Epoch: 6| Step: 8
Training loss: 0.28598552467320604
Validation loss: 2.343372181071939

Epoch: 6| Step: 9
Training loss: 0.6836470664894444
Validation loss: 2.3109904647313577

Epoch: 6| Step: 10
Training loss: 0.3692341035224679
Validation loss: 2.2831613375120874

Epoch: 6| Step: 11
Training loss: 0.37350186467630836
Validation loss: 2.285589551797735

Epoch: 6| Step: 12
Training loss: 0.42009171001197526
Validation loss: 2.3006054935256346

Epoch: 6| Step: 13
Training loss: 0.4620981474646719
Validation loss: 2.3216834624209524

Epoch: 400| Step: 0
Training loss: 0.5062076739289837
Validation loss: 2.3232960397865043

Epoch: 6| Step: 1
Training loss: 0.4747201923616892
Validation loss: 2.311601180870444

Epoch: 6| Step: 2
Training loss: 0.46258132193848556
Validation loss: 2.2882983522469234

Epoch: 6| Step: 3
Training loss: 0.238016153048877
Validation loss: 2.3172807500701835

Epoch: 6| Step: 4
Training loss: 0.37573063721707006
Validation loss: 2.273184662414421

Epoch: 6| Step: 5
Training loss: 0.336436178769248
Validation loss: 2.291052130881863

Epoch: 6| Step: 6
Training loss: 0.3848568570951881
Validation loss: 2.3071179755245415

Epoch: 6| Step: 7
Training loss: 0.40356153612876894
Validation loss: 2.304987841920128

Epoch: 6| Step: 8
Training loss: 0.36244733526518796
Validation loss: 2.3150949460778736

Epoch: 6| Step: 9
Training loss: 0.39531923672812475
Validation loss: 2.3425052501305186

Epoch: 6| Step: 10
Training loss: 0.6721030890518803
Validation loss: 2.3315544342461783

Epoch: 6| Step: 11
Training loss: 0.5698149614146004
Validation loss: 2.3276836238123932

Epoch: 6| Step: 12
Training loss: 0.6119737232588418
Validation loss: 2.3164319326775473

Epoch: 6| Step: 13
Training loss: 0.4745173737949904
Validation loss: 2.2923912297523987

Epoch: 401| Step: 0
Training loss: 0.41666630109135167
Validation loss: 2.3035315288245717

Epoch: 6| Step: 1
Training loss: 0.5174186028859881
Validation loss: 2.303717270611748

Epoch: 6| Step: 2
Training loss: 0.33656099035762166
Validation loss: 2.2985482844616896

Epoch: 6| Step: 3
Training loss: 0.4100236950982128
Validation loss: 2.2947871652975076

Epoch: 6| Step: 4
Training loss: 0.4362295300618993
Validation loss: 2.2935219944354865

Epoch: 6| Step: 5
Training loss: 0.2780652265931626
Validation loss: 2.291171129035746

Epoch: 6| Step: 6
Training loss: 0.5517770409398394
Validation loss: 2.2851209658989187

Epoch: 6| Step: 7
Training loss: 0.5500703918320876
Validation loss: 2.3001269441467342

Epoch: 6| Step: 8
Training loss: 0.30010614553821086
Validation loss: 2.2986904155349825

Epoch: 6| Step: 9
Training loss: 0.36364782972979787
Validation loss: 2.2987318248168886

Epoch: 6| Step: 10
Training loss: 0.4531860639270298
Validation loss: 2.29302808607923

Epoch: 6| Step: 11
Training loss: 0.32937714671931945
Validation loss: 2.2994940695752777

Epoch: 6| Step: 12
Training loss: 0.5535639815115251
Validation loss: 2.321737909582202

Epoch: 6| Step: 13
Training loss: 0.5375913087780217
Validation loss: 2.2953886974534288

Epoch: 402| Step: 0
Training loss: 0.31018270576702844
Validation loss: 2.2774751374448527

Epoch: 6| Step: 1
Training loss: 0.36961286099277035
Validation loss: 2.282592280770949

Epoch: 6| Step: 2
Training loss: 0.6078467646259251
Validation loss: 2.3201770424591026

Epoch: 6| Step: 3
Training loss: 0.5436980474799372
Validation loss: 2.303366266884235

Epoch: 6| Step: 4
Training loss: 0.4831685608179406
Validation loss: 2.296703402251044

Epoch: 6| Step: 5
Training loss: 0.3351208496960818
Validation loss: 2.301763490518673

Epoch: 6| Step: 6
Training loss: 0.33788167247047585
Validation loss: 2.3223946498585453

Epoch: 6| Step: 7
Training loss: 0.4575495267335972
Validation loss: 2.2929077352748064

Epoch: 6| Step: 8
Training loss: 0.4936322699596131
Validation loss: 2.335148587201927

Epoch: 6| Step: 9
Training loss: 0.41522015379473676
Validation loss: 2.33186142413824

Epoch: 6| Step: 10
Training loss: 0.3940659980709419
Validation loss: 2.3183629666339907

Epoch: 6| Step: 11
Training loss: 0.40474024248525614
Validation loss: 2.3125619766368937

Epoch: 6| Step: 12
Training loss: 0.2734386580306463
Validation loss: 2.3104883205845796

Epoch: 6| Step: 13
Training loss: 0.4105921835538129
Validation loss: 2.2927301536415094

Epoch: 403| Step: 0
Training loss: 0.44387239863525857
Validation loss: 2.3132015628538336

Epoch: 6| Step: 1
Training loss: 0.4686502986417401
Validation loss: 2.318662699181563

Epoch: 6| Step: 2
Training loss: 0.4102790648644594
Validation loss: 2.3329454988162497

Epoch: 6| Step: 3
Training loss: 0.49192500305005177
Validation loss: 2.3352419991127134

Epoch: 6| Step: 4
Training loss: 0.6008098154010991
Validation loss: 2.3438606263444397

Epoch: 6| Step: 5
Training loss: 0.4278704283166657
Validation loss: 2.3304402556203416

Epoch: 6| Step: 6
Training loss: 0.4601403147815479
Validation loss: 2.3200690492998794

Epoch: 6| Step: 7
Training loss: 0.354038841891452
Validation loss: 2.290789558458153

Epoch: 6| Step: 8
Training loss: 0.29358511619196165
Validation loss: 2.295953165068538

Epoch: 6| Step: 9
Training loss: 0.3170271303633992
Validation loss: 2.3077605485489325

Epoch: 6| Step: 10
Training loss: 0.2288135314747272
Validation loss: 2.31177738498778

Epoch: 6| Step: 11
Training loss: 0.5440938804906315
Validation loss: 2.3048691166501443

Epoch: 6| Step: 12
Training loss: 0.4199455609405931
Validation loss: 2.3218359397418533

Epoch: 6| Step: 13
Training loss: 0.2008105523810163
Validation loss: 2.3366643236035687

Epoch: 404| Step: 0
Training loss: 0.28657990245747283
Validation loss: 2.3272946799902896

Epoch: 6| Step: 1
Training loss: 0.4383676644335052
Validation loss: 2.356505436022303

Epoch: 6| Step: 2
Training loss: 0.2794440088659481
Validation loss: 2.333868303440653

Epoch: 6| Step: 3
Training loss: 0.322698879889485
Validation loss: 2.3097628530553314

Epoch: 6| Step: 4
Training loss: 0.43407279692397643
Validation loss: 2.345724717508608

Epoch: 6| Step: 5
Training loss: 0.4066597266204325
Validation loss: 2.30668323857414

Epoch: 6| Step: 6
Training loss: 0.557292997649793
Validation loss: 2.305643927784841

Epoch: 6| Step: 7
Training loss: 0.46244645839798787
Validation loss: 2.319989489042512

Epoch: 6| Step: 8
Training loss: 0.32157138838128924
Validation loss: 2.3185558893582603

Epoch: 6| Step: 9
Training loss: 0.4728444568048138
Validation loss: 2.309935211997636

Epoch: 6| Step: 10
Training loss: 0.48036733968236844
Validation loss: 2.324947813570643

Epoch: 6| Step: 11
Training loss: 0.454047054177709
Validation loss: 2.3178026846337048

Epoch: 6| Step: 12
Training loss: 0.5423562966150824
Validation loss: 2.3109974812044465

Epoch: 6| Step: 13
Training loss: 0.14007137516352033
Validation loss: 2.3327111963604525

Epoch: 405| Step: 0
Training loss: 0.3600669294964519
Validation loss: 2.3158401262012434

Epoch: 6| Step: 1
Training loss: 0.32481208191859967
Validation loss: 2.2924846561547447

Epoch: 6| Step: 2
Training loss: 0.6529123945853135
Validation loss: 2.270029449721794

Epoch: 6| Step: 3
Training loss: 0.36851832499029535
Validation loss: 2.278065232710896

Epoch: 6| Step: 4
Training loss: 0.4371398737871946
Validation loss: 2.287178047557129

Epoch: 6| Step: 5
Training loss: 0.23622034310587023
Validation loss: 2.29485184394424

Epoch: 6| Step: 6
Training loss: 0.38433798635025657
Validation loss: 2.3022230456060044

Epoch: 6| Step: 7
Training loss: 0.3143714182594678
Validation loss: 2.323420458699968

Epoch: 6| Step: 8
Training loss: 0.32104914557285796
Validation loss: 2.2879426523967594

Epoch: 6| Step: 9
Training loss: 0.5946580318059582
Validation loss: 2.3045021237027887

Epoch: 6| Step: 10
Training loss: 0.46508635272875654
Validation loss: 2.313288213156794

Epoch: 6| Step: 11
Training loss: 0.39761874278714665
Validation loss: 2.329992305951172

Epoch: 6| Step: 12
Training loss: 0.38855032242175097
Validation loss: 2.3584159179017936

Epoch: 6| Step: 13
Training loss: 0.44010073944502937
Validation loss: 2.3497419837039235

Epoch: 406| Step: 0
Training loss: 0.42818394206479693
Validation loss: 2.3479906402667994

Epoch: 6| Step: 1
Training loss: 0.38372656626398166
Validation loss: 2.371602201772623

Epoch: 6| Step: 2
Training loss: 0.23624144296438282
Validation loss: 2.376988916102943

Epoch: 6| Step: 3
Training loss: 0.3997308458829218
Validation loss: 2.3584512315922948

Epoch: 6| Step: 4
Training loss: 0.3193386906029784
Validation loss: 2.348718348849257

Epoch: 6| Step: 5
Training loss: 0.3202264251429491
Validation loss: 2.320967158357449

Epoch: 6| Step: 6
Training loss: 0.5697771982963119
Validation loss: 2.2891955778144255

Epoch: 6| Step: 7
Training loss: 0.2402866740790967
Validation loss: 2.314100672127354

Epoch: 6| Step: 8
Training loss: 0.5527967545858475
Validation loss: 2.3180107676141914

Epoch: 6| Step: 9
Training loss: 0.2600939833669682
Validation loss: 2.3393727593982168

Epoch: 6| Step: 10
Training loss: 0.6621382490405716
Validation loss: 2.301573646867671

Epoch: 6| Step: 11
Training loss: 0.4503981987480985
Validation loss: 2.336711155519667

Epoch: 6| Step: 12
Training loss: 0.4199952527186627
Validation loss: 2.312639518814889

Epoch: 6| Step: 13
Training loss: 0.15925030809227442
Validation loss: 2.330079119614994

Epoch: 407| Step: 0
Training loss: 0.6311451881566149
Validation loss: 2.333485301367665

Epoch: 6| Step: 1
Training loss: 0.25339790220690694
Validation loss: 2.3303339273099546

Epoch: 6| Step: 2
Training loss: 0.4416785623939754
Validation loss: 2.3206834664691502

Epoch: 6| Step: 3
Training loss: 0.38725711455314293
Validation loss: 2.3238034344775027

Epoch: 6| Step: 4
Training loss: 0.5332762559756943
Validation loss: 2.3222517815580423

Epoch: 6| Step: 5
Training loss: 0.26030060884076234
Validation loss: 2.3170525167179092

Epoch: 6| Step: 6
Training loss: 0.3713396562663481
Validation loss: 2.308361864059877

Epoch: 6| Step: 7
Training loss: 0.4217485838913222
Validation loss: 2.3407813382325244

Epoch: 6| Step: 8
Training loss: 0.31735802186834583
Validation loss: 2.3618299575487423

Epoch: 6| Step: 9
Training loss: 0.4297161612921993
Validation loss: 2.360286142558634

Epoch: 6| Step: 10
Training loss: 0.3138174894779934
Validation loss: 2.332081918050398

Epoch: 6| Step: 11
Training loss: 0.5868693507677234
Validation loss: 2.3358663867158613

Epoch: 6| Step: 12
Training loss: 0.3822643481618582
Validation loss: 2.320463781423628

Epoch: 6| Step: 13
Training loss: 0.7816069741085334
Validation loss: 2.3491256265393634

Epoch: 408| Step: 0
Training loss: 0.47231785033475343
Validation loss: 2.3339084262258316

Epoch: 6| Step: 1
Training loss: 0.40463375485824055
Validation loss: 2.3502967667815873

Epoch: 6| Step: 2
Training loss: 0.41588524221449674
Validation loss: 2.433160445985212

Epoch: 6| Step: 3
Training loss: 0.48150179456215964
Validation loss: 2.4376859822719994

Epoch: 6| Step: 4
Training loss: 0.5541428591937153
Validation loss: 2.392819178285076

Epoch: 6| Step: 5
Training loss: 0.4655753237191983
Validation loss: 2.3564630986804995

Epoch: 6| Step: 6
Training loss: 0.48589050948913265
Validation loss: 2.341828372425378

Epoch: 6| Step: 7
Training loss: 0.37313881584927894
Validation loss: 2.3502258954537973

Epoch: 6| Step: 8
Training loss: 0.3143841922621949
Validation loss: 2.3195199682931436

Epoch: 6| Step: 9
Training loss: 0.2794712829236188
Validation loss: 2.3205604303370935

Epoch: 6| Step: 10
Training loss: 0.3465465236176836
Validation loss: 2.340280608501905

Epoch: 6| Step: 11
Training loss: 0.6807148502617989
Validation loss: 2.3124572164607047

Epoch: 6| Step: 12
Training loss: 0.4187661879527771
Validation loss: 2.3426126729981047

Epoch: 6| Step: 13
Training loss: 0.3837590290771828
Validation loss: 2.3264210608513864

Epoch: 409| Step: 0
Training loss: 0.294294675631972
Validation loss: 2.324682638177761

Epoch: 6| Step: 1
Training loss: 0.4697137937971434
Validation loss: 2.3095087728579173

Epoch: 6| Step: 2
Training loss: 0.555053912285021
Validation loss: 2.3203303877551633

Epoch: 6| Step: 3
Training loss: 0.39608297088823696
Validation loss: 2.298484175495146

Epoch: 6| Step: 4
Training loss: 0.3743953598676371
Validation loss: 2.3068993984801196

Epoch: 6| Step: 5
Training loss: 0.43079583537329913
Validation loss: 2.305493060542204

Epoch: 6| Step: 6
Training loss: 0.4121263328787551
Validation loss: 2.324632788151673

Epoch: 6| Step: 7
Training loss: 0.3572578887802563
Validation loss: 2.3390975705437422

Epoch: 6| Step: 8
Training loss: 0.5874693111764194
Validation loss: 2.348129435803058

Epoch: 6| Step: 9
Training loss: 0.48066508925854123
Validation loss: 2.342829339014384

Epoch: 6| Step: 10
Training loss: 0.322052335960369
Validation loss: 2.360340900242542

Epoch: 6| Step: 11
Training loss: 0.32193837745545445
Validation loss: 2.305691819509635

Epoch: 6| Step: 12
Training loss: 0.26641505218462536
Validation loss: 2.3027983088658615

Epoch: 6| Step: 13
Training loss: 0.6177196864027756
Validation loss: 2.3120248029716994

Epoch: 410| Step: 0
Training loss: 0.4718725627558336
Validation loss: 2.3079266144051807

Epoch: 6| Step: 1
Training loss: 0.5004382894716293
Validation loss: 2.323338535457965

Epoch: 6| Step: 2
Training loss: 0.4954252770490825
Validation loss: 2.3430540313505994

Epoch: 6| Step: 3
Training loss: 0.27416636192069077
Validation loss: 2.336695468918114

Epoch: 6| Step: 4
Training loss: 0.5549170328106493
Validation loss: 2.346328992161022

Epoch: 6| Step: 5
Training loss: 0.3054745607725876
Validation loss: 2.3381789666825936

Epoch: 6| Step: 6
Training loss: 0.175220059929624
Validation loss: 2.3008258654454394

Epoch: 6| Step: 7
Training loss: 0.4780655905022347
Validation loss: 2.30635405266079

Epoch: 6| Step: 8
Training loss: 0.40260850658109165
Validation loss: 2.319211646557383

Epoch: 6| Step: 9
Training loss: 0.34644007394210563
Validation loss: 2.31962327915747

Epoch: 6| Step: 10
Training loss: 0.4660733733165321
Validation loss: 2.3216170274032177

Epoch: 6| Step: 11
Training loss: 0.35971068170847964
Validation loss: 2.3363970090119923

Epoch: 6| Step: 12
Training loss: 0.14034345709065782
Validation loss: 2.3601820120469075

Epoch: 6| Step: 13
Training loss: 0.400299750459304
Validation loss: 2.3286905393950494

Epoch: 411| Step: 0
Training loss: 0.48809499621523755
Validation loss: 2.341507212818505

Epoch: 6| Step: 1
Training loss: 0.5896518470890496
Validation loss: 2.338419682334824

Epoch: 6| Step: 2
Training loss: 0.5625673889483412
Validation loss: 2.339647987107996

Epoch: 6| Step: 3
Training loss: 0.3406716052378277
Validation loss: 2.341705714321227

Epoch: 6| Step: 4
Training loss: 0.4497650804859262
Validation loss: 2.346036712920329

Epoch: 6| Step: 5
Training loss: 0.18898029904900115
Validation loss: 2.3288951579122172

Epoch: 6| Step: 6
Training loss: 0.3736373063578459
Validation loss: 2.2948594119076766

Epoch: 6| Step: 7
Training loss: 0.21969154078808648
Validation loss: 2.2973108573578798

Epoch: 6| Step: 8
Training loss: 0.4316635125767913
Validation loss: 2.314993866379662

Epoch: 6| Step: 9
Training loss: 0.26055484284852715
Validation loss: 2.2960597116174046

Epoch: 6| Step: 10
Training loss: 0.17386694271127837
Validation loss: 2.30167643085299

Epoch: 6| Step: 11
Training loss: 0.3531554584533122
Validation loss: 2.330742471757453

Epoch: 6| Step: 12
Training loss: 0.29587605206004775
Validation loss: 2.314968842166256

Epoch: 6| Step: 13
Training loss: 0.5371612801180647
Validation loss: 2.287259854274998

Epoch: 412| Step: 0
Training loss: 0.4317661292813417
Validation loss: 2.317480206067251

Epoch: 6| Step: 1
Training loss: 0.3865890285359965
Validation loss: 2.316830202952341

Epoch: 6| Step: 2
Training loss: 0.3618673064842087
Validation loss: 2.299135060141082

Epoch: 6| Step: 3
Training loss: 0.5030171438674195
Validation loss: 2.3158213192606802

Epoch: 6| Step: 4
Training loss: 0.41190389057187227
Validation loss: 2.311483139100702

Epoch: 6| Step: 5
Training loss: 0.5244981353824807
Validation loss: 2.2987245333577997

Epoch: 6| Step: 6
Training loss: 0.4606711215993264
Validation loss: 2.316498805521138

Epoch: 6| Step: 7
Training loss: 0.30803937248363955
Validation loss: 2.318045314410483

Epoch: 6| Step: 8
Training loss: 0.3790134789452926
Validation loss: 2.329032435351977

Epoch: 6| Step: 9
Training loss: 0.20608270825240987
Validation loss: 2.3086994683366444

Epoch: 6| Step: 10
Training loss: 0.2478737865491397
Validation loss: 2.3154458232033743

Epoch: 6| Step: 11
Training loss: 0.258213425054286
Validation loss: 2.3393276470638447

Epoch: 6| Step: 12
Training loss: 0.23640342174938464
Validation loss: 2.32917740605631

Epoch: 6| Step: 13
Training loss: 0.43565143305243886
Validation loss: 2.32033085511097

Epoch: 413| Step: 0
Training loss: 0.5988285062207666
Validation loss: 2.2920340309762817

Epoch: 6| Step: 1
Training loss: 0.43734271764548227
Validation loss: 2.302350904885632

Epoch: 6| Step: 2
Training loss: 0.3571542039839814
Validation loss: 2.3164770709036073

Epoch: 6| Step: 3
Training loss: 0.3550908521799025
Validation loss: 2.3157177726330542

Epoch: 6| Step: 4
Training loss: 0.22911095303203585
Validation loss: 2.3113586027911377

Epoch: 6| Step: 5
Training loss: 0.21575875936443303
Validation loss: 2.3328422353329525

Epoch: 6| Step: 6
Training loss: 0.5268587213085276
Validation loss: 2.338885495645999

Epoch: 6| Step: 7
Training loss: 0.41460354562431145
Validation loss: 2.3471674248208045

Epoch: 6| Step: 8
Training loss: 0.24835679824802764
Validation loss: 2.328997530877278

Epoch: 6| Step: 9
Training loss: 0.3854623286373825
Validation loss: 2.3193275568432346

Epoch: 6| Step: 10
Training loss: 0.26722292748867277
Validation loss: 2.316681943745532

Epoch: 6| Step: 11
Training loss: 0.2761837245875622
Validation loss: 2.33397868639678

Epoch: 6| Step: 12
Training loss: 0.3339201324425991
Validation loss: 2.3099741234990505

Epoch: 6| Step: 13
Training loss: 0.45683160317441374
Validation loss: 2.3258107188453616

Epoch: 414| Step: 0
Training loss: 0.1833902407958475
Validation loss: 2.309482443735656

Epoch: 6| Step: 1
Training loss: 0.3603249310005814
Validation loss: 2.3451681800088626

Epoch: 6| Step: 2
Training loss: 0.5229772280646093
Validation loss: 2.3025296515017364

Epoch: 6| Step: 3
Training loss: 0.5488958350935544
Validation loss: 2.3118002691230153

Epoch: 6| Step: 4
Training loss: 0.314934356373978
Validation loss: 2.3351120395213685

Epoch: 6| Step: 5
Training loss: 0.49028078748603504
Validation loss: 2.3190929823319224

Epoch: 6| Step: 6
Training loss: 0.39973229972176294
Validation loss: 2.3180358225810247

Epoch: 6| Step: 7
Training loss: 0.2629343526446462
Validation loss: 2.3178422919331427

Epoch: 6| Step: 8
Training loss: 0.2351934131139504
Validation loss: 2.322316398208039

Epoch: 6| Step: 9
Training loss: 0.3039371469869413
Validation loss: 2.3160973571388457

Epoch: 6| Step: 10
Training loss: 0.25450326715388266
Validation loss: 2.3018543538969745

Epoch: 6| Step: 11
Training loss: 0.5461354841403376
Validation loss: 2.2704114549337593

Epoch: 6| Step: 12
Training loss: 0.1820204465549873
Validation loss: 2.279889273916968

Epoch: 6| Step: 13
Training loss: 0.36092709117594596
Validation loss: 2.2922796186631573

Epoch: 415| Step: 0
Training loss: 0.26342301103743043
Validation loss: 2.2903653638692263

Epoch: 6| Step: 1
Training loss: 0.375448157816955
Validation loss: 2.28820682648659

Epoch: 6| Step: 2
Training loss: 0.35951335980178667
Validation loss: 2.2913255271679236

Epoch: 6| Step: 3
Training loss: 0.29514235030120384
Validation loss: 2.304849849799644

Epoch: 6| Step: 4
Training loss: 0.4622861883461455
Validation loss: 2.3136160512346233

Epoch: 6| Step: 5
Training loss: 0.3875544409809839
Validation loss: 2.2733063877961355

Epoch: 6| Step: 6
Training loss: 0.6736942324090957
Validation loss: 2.3018838750287314

Epoch: 6| Step: 7
Training loss: 0.41659183624974905
Validation loss: 2.274654307352049

Epoch: 6| Step: 8
Training loss: 0.28628041493111134
Validation loss: 2.279518450230374

Epoch: 6| Step: 9
Training loss: 0.20569256062513958
Validation loss: 2.261562114085397

Epoch: 6| Step: 10
Training loss: 0.36169046328451165
Validation loss: 2.305686075557253

Epoch: 6| Step: 11
Training loss: 0.24086909453621452
Validation loss: 2.2980213074259424

Epoch: 6| Step: 12
Training loss: 0.21642741089520504
Validation loss: 2.2860972070499375

Epoch: 6| Step: 13
Training loss: 0.49224314299419
Validation loss: 2.2888561305407156

Epoch: 416| Step: 0
Training loss: 0.15123156347498082
Validation loss: 2.314981757958805

Epoch: 6| Step: 1
Training loss: 0.4910030797358729
Validation loss: 2.3139928285697486

Epoch: 6| Step: 2
Training loss: 0.27474050687420754
Validation loss: 2.294196397364126

Epoch: 6| Step: 3
Training loss: 0.5474123902967067
Validation loss: 2.3219848684990296

Epoch: 6| Step: 4
Training loss: 0.27065752204020876
Validation loss: 2.3104358951878017

Epoch: 6| Step: 5
Training loss: 0.4563400878539876
Validation loss: 2.301733862868515

Epoch: 6| Step: 6
Training loss: 0.27534695542846255
Validation loss: 2.3002926438777735

Epoch: 6| Step: 7
Training loss: 0.4315375640869093
Validation loss: 2.3157510827493435

Epoch: 6| Step: 8
Training loss: 0.3873809770096529
Validation loss: 2.3169885867040776

Epoch: 6| Step: 9
Training loss: 0.30511276204791327
Validation loss: 2.3390609250959455

Epoch: 6| Step: 10
Training loss: 0.37435022326269535
Validation loss: 2.3056870195411188

Epoch: 6| Step: 11
Training loss: 0.412317648231709
Validation loss: 2.3209499730429775

Epoch: 6| Step: 12
Training loss: 0.22920138825737602
Validation loss: 2.330951243467185

Epoch: 6| Step: 13
Training loss: 0.26536426650238343
Validation loss: 2.3281494533556444

Epoch: 417| Step: 0
Training loss: 0.3581784064064294
Validation loss: 2.2796682340372705

Epoch: 6| Step: 1
Training loss: 0.17330879685579192
Validation loss: 2.2830503169746343

Epoch: 6| Step: 2
Training loss: 0.2500995199483347
Validation loss: 2.2952216082807357

Epoch: 6| Step: 3
Training loss: 0.41672090733659495
Validation loss: 2.3185210112658243

Epoch: 6| Step: 4
Training loss: 0.3814246262401943
Validation loss: 2.3242538431575155

Epoch: 6| Step: 5
Training loss: 0.3524921523397495
Validation loss: 2.3139196659346095

Epoch: 6| Step: 6
Training loss: 0.2835840228805955
Validation loss: 2.3087241674169774

Epoch: 6| Step: 7
Training loss: 0.4340404065732025
Validation loss: 2.298697631264759

Epoch: 6| Step: 8
Training loss: 0.3002644967328281
Validation loss: 2.3262892645479583

Epoch: 6| Step: 9
Training loss: 0.3335084926819276
Validation loss: 2.3297213564982844

Epoch: 6| Step: 10
Training loss: 0.4392814809648382
Validation loss: 2.3040844811981094

Epoch: 6| Step: 11
Training loss: 0.22387792655708236
Validation loss: 2.3052287016052158

Epoch: 6| Step: 12
Training loss: 0.4397558398843032
Validation loss: 2.323094867757842

Epoch: 6| Step: 13
Training loss: 0.54091692964172
Validation loss: 2.319137389755632

Epoch: 418| Step: 0
Training loss: 0.5403643933644401
Validation loss: 2.3322851903980903

Epoch: 6| Step: 1
Training loss: 0.3633265723392674
Validation loss: 2.3279819016471275

Epoch: 6| Step: 2
Training loss: 0.3699419517668145
Validation loss: 2.303596172845574

Epoch: 6| Step: 3
Training loss: 0.29730479600157844
Validation loss: 2.3108301907597473

Epoch: 6| Step: 4
Training loss: 0.22893607755714304
Validation loss: 2.3005645520095257

Epoch: 6| Step: 5
Training loss: 0.1693289925846164
Validation loss: 2.3008566287486985

Epoch: 6| Step: 6
Training loss: 0.4177529321518548
Validation loss: 2.311025220747008

Epoch: 6| Step: 7
Training loss: 0.32201993419861197
Validation loss: 2.3147907025256105

Epoch: 6| Step: 8
Training loss: 0.36697686017701475
Validation loss: 2.3247843894350093

Epoch: 6| Step: 9
Training loss: 0.31515547699802754
Validation loss: 2.316025541684867

Epoch: 6| Step: 10
Training loss: 0.10881484015630824
Validation loss: 2.3246740110225628

Epoch: 6| Step: 11
Training loss: 0.33039316120017664
Validation loss: 2.326631524939239

Epoch: 6| Step: 12
Training loss: 0.5898231856443411
Validation loss: 2.3251712503567377

Epoch: 6| Step: 13
Training loss: 0.21073794639074458
Validation loss: 2.3142766355360975

Epoch: 419| Step: 0
Training loss: 0.35328938953550454
Validation loss: 2.3084492013253626

Epoch: 6| Step: 1
Training loss: 0.43845729318261156
Validation loss: 2.3094068447735268

Epoch: 6| Step: 2
Training loss: 0.3591628070160725
Validation loss: 2.2808474495845172

Epoch: 6| Step: 3
Training loss: 0.3156103909765703
Validation loss: 2.3024795459275573

Epoch: 6| Step: 4
Training loss: 0.445410533621339
Validation loss: 2.3047189862280186

Epoch: 6| Step: 5
Training loss: 0.3710330311139593
Validation loss: 2.3130268393653206

Epoch: 6| Step: 6
Training loss: 0.09746406718333779
Validation loss: 2.3208754738932535

Epoch: 6| Step: 7
Training loss: 0.10971406764331376
Validation loss: 2.3269943120100303

Epoch: 6| Step: 8
Training loss: 0.368183125374247
Validation loss: 2.3307610703058033

Epoch: 6| Step: 9
Training loss: 0.4994889866642904
Validation loss: 2.3375776086847306

Epoch: 6| Step: 10
Training loss: 0.33922864341629105
Validation loss: 2.322494607734573

Epoch: 6| Step: 11
Training loss: 0.3221223917460659
Validation loss: 2.3260682667230577

Epoch: 6| Step: 12
Training loss: 0.1856865808662565
Validation loss: 2.313271597500401

Epoch: 6| Step: 13
Training loss: 0.4732688685321802
Validation loss: 2.304141325808401

Epoch: 420| Step: 0
Training loss: 0.3792641119748612
Validation loss: 2.280736356597249

Epoch: 6| Step: 1
Training loss: 0.38815464895526464
Validation loss: 2.3072988236457808

Epoch: 6| Step: 2
Training loss: 0.32546636380013594
Validation loss: 2.319690781119954

Epoch: 6| Step: 3
Training loss: 0.3289049846235204
Validation loss: 2.3077394950912944

Epoch: 6| Step: 4
Training loss: 0.5345568397728078
Validation loss: 2.342889098518884

Epoch: 6| Step: 5
Training loss: 0.25982169213092005
Validation loss: 2.3217042188333625

Epoch: 6| Step: 6
Training loss: 0.3388066306408898
Validation loss: 2.291787517042205

Epoch: 6| Step: 7
Training loss: 0.35596019183562333
Validation loss: 2.3246950941762385

Epoch: 6| Step: 8
Training loss: 0.4352530441977472
Validation loss: 2.303479127619242

Epoch: 6| Step: 9
Training loss: 0.2825544887504793
Validation loss: 2.3003138111856343

Epoch: 6| Step: 10
Training loss: 0.308436027492421
Validation loss: 2.3069175680454466

Epoch: 6| Step: 11
Training loss: 0.38399071285570563
Validation loss: 2.287434828681781

Epoch: 6| Step: 12
Training loss: 0.1954791978899525
Validation loss: 2.3040212712153063

Epoch: 6| Step: 13
Training loss: 0.3470320616656365
Validation loss: 2.3270776923880367

Epoch: 421| Step: 0
Training loss: 0.43369821200821324
Validation loss: 2.300210185030664

Epoch: 6| Step: 1
Training loss: 0.3145029727449607
Validation loss: 2.2969326480553685

Epoch: 6| Step: 2
Training loss: 0.43032004874041574
Validation loss: 2.2856172525575844

Epoch: 6| Step: 3
Training loss: 0.5902248187399192
Validation loss: 2.311440477596762

Epoch: 6| Step: 4
Training loss: 0.2369661624540296
Validation loss: 2.281734350516768

Epoch: 6| Step: 5
Training loss: 0.3174724276277363
Validation loss: 2.3035015911482843

Epoch: 6| Step: 6
Training loss: 0.2818999462972714
Validation loss: 2.304718093571682

Epoch: 6| Step: 7
Training loss: 0.14615598107950015
Validation loss: 2.3040225469036915

Epoch: 6| Step: 8
Training loss: 0.24820839886800292
Validation loss: 2.308720729571336

Epoch: 6| Step: 9
Training loss: 0.41596601306793524
Validation loss: 2.295403775089278

Epoch: 6| Step: 10
Training loss: 0.2775673166667536
Validation loss: 2.316729648787741

Epoch: 6| Step: 11
Training loss: 0.3101110939573689
Validation loss: 2.307275601530654

Epoch: 6| Step: 12
Training loss: 0.36246682212534614
Validation loss: 2.3012533100719286

Epoch: 6| Step: 13
Training loss: 0.2423269654763452
Validation loss: 2.2803139029534627

Epoch: 422| Step: 0
Training loss: 0.27710049666880243
Validation loss: 2.320122639330432

Epoch: 6| Step: 1
Training loss: 0.4052991376334465
Validation loss: 2.3238666519005324

Epoch: 6| Step: 2
Training loss: 0.25264914430099306
Validation loss: 2.3222830500668654

Epoch: 6| Step: 3
Training loss: 0.5359667744996311
Validation loss: 2.32379256232834

Epoch: 6| Step: 4
Training loss: 0.19570631378682504
Validation loss: 2.3046245251410595

Epoch: 6| Step: 5
Training loss: 0.3099806920506787
Validation loss: 2.3148702188604413

Epoch: 6| Step: 6
Training loss: 0.40196715943031364
Validation loss: 2.334023562168567

Epoch: 6| Step: 7
Training loss: 0.24194462195566438
Validation loss: 2.3142106043681325

Epoch: 6| Step: 8
Training loss: 0.42653044136502294
Validation loss: 2.308687703062287

Epoch: 6| Step: 9
Training loss: 0.3625480472029679
Validation loss: 2.3259272189580473

Epoch: 6| Step: 10
Training loss: 0.2860065741567029
Validation loss: 2.317058804512363

Epoch: 6| Step: 11
Training loss: 0.44913100339304907
Validation loss: 2.3162609619834322

Epoch: 6| Step: 12
Training loss: 0.2714570807039915
Validation loss: 2.287199086283635

Epoch: 6| Step: 13
Training loss: 0.11936954487075015
Validation loss: 2.3001152983078073

Epoch: 423| Step: 0
Training loss: 0.40247339178477604
Validation loss: 2.289964251266308

Epoch: 6| Step: 1
Training loss: 0.1142416477995404
Validation loss: 2.319853187140653

Epoch: 6| Step: 2
Training loss: 0.2146466825238197
Validation loss: 2.3228837951809416

Epoch: 6| Step: 3
Training loss: 0.3209222479430421
Validation loss: 2.306739968020687

Epoch: 6| Step: 4
Training loss: 0.388406346545682
Validation loss: 2.3449634935361585

Epoch: 6| Step: 5
Training loss: 0.44651820270752596
Validation loss: 2.317405046670313

Epoch: 6| Step: 6
Training loss: 0.3139217459849411
Validation loss: 2.3226828015727747

Epoch: 6| Step: 7
Training loss: 0.20248204958204682
Validation loss: 2.3302451021474146

Epoch: 6| Step: 8
Training loss: 0.4798679627421463
Validation loss: 2.3190105972298722

Epoch: 6| Step: 9
Training loss: 0.278304705265868
Validation loss: 2.3324330024148043

Epoch: 6| Step: 10
Training loss: 0.2867768626347708
Validation loss: 2.3082186447598434

Epoch: 6| Step: 11
Training loss: 0.3241496299693584
Validation loss: 2.33660169819051

Epoch: 6| Step: 12
Training loss: 0.5063152541973422
Validation loss: 2.3117336521054357

Epoch: 6| Step: 13
Training loss: 0.1598795151434569
Validation loss: 2.3290241886528955

Epoch: 424| Step: 0
Training loss: 0.2779595697440549
Validation loss: 2.315423718030757

Epoch: 6| Step: 1
Training loss: 0.17234118052458108
Validation loss: 2.3053920307904296

Epoch: 6| Step: 2
Training loss: 0.40838261358837047
Validation loss: 2.3162517605725785

Epoch: 6| Step: 3
Training loss: 0.3009000518807024
Validation loss: 2.3048222050025315

Epoch: 6| Step: 4
Training loss: 0.23040128787342212
Validation loss: 2.30387764688555

Epoch: 6| Step: 5
Training loss: 0.35422705621660344
Validation loss: 2.300732637079822

Epoch: 6| Step: 6
Training loss: 0.27247146531414723
Validation loss: 2.285694810431657

Epoch: 6| Step: 7
Training loss: 0.38232823317406706
Validation loss: 2.290876323486801

Epoch: 6| Step: 8
Training loss: 0.43903300230371795
Validation loss: 2.301576805784555

Epoch: 6| Step: 9
Training loss: 0.3448900694131686
Validation loss: 2.305763176306505

Epoch: 6| Step: 10
Training loss: 0.1726166535192493
Validation loss: 2.2884933456795222

Epoch: 6| Step: 11
Training loss: 0.4140586852851621
Validation loss: 2.284873298829674

Epoch: 6| Step: 12
Training loss: 0.3502434250162053
Validation loss: 2.2931034910628045

Epoch: 6| Step: 13
Training loss: 0.49564814642197197
Validation loss: 2.3028656129612237

Epoch: 425| Step: 0
Training loss: 0.2633267156809622
Validation loss: 2.3108076051572954

Epoch: 6| Step: 1
Training loss: 0.2766221962634563
Validation loss: 2.303108208018879

Epoch: 6| Step: 2
Training loss: 0.42870024926280914
Validation loss: 2.3101203368098946

Epoch: 6| Step: 3
Training loss: 0.3152570576879839
Validation loss: 2.2887172722132743

Epoch: 6| Step: 4
Training loss: 0.48928957777019483
Validation loss: 2.289198747092772

Epoch: 6| Step: 5
Training loss: 0.40690233967891926
Validation loss: 2.3064913468036603

Epoch: 6| Step: 6
Training loss: 0.2839423692954535
Validation loss: 2.305532610219353

Epoch: 6| Step: 7
Training loss: 0.32190488796910677
Validation loss: 2.3131745886315116

Epoch: 6| Step: 8
Training loss: 0.3506518649962635
Validation loss: 2.297686357293208

Epoch: 6| Step: 9
Training loss: 0.4041770167680518
Validation loss: 2.3177047051049584

Epoch: 6| Step: 10
Training loss: 0.29360681351472134
Validation loss: 2.3172555763066254

Epoch: 6| Step: 11
Training loss: 0.18114333631634566
Validation loss: 2.308385252939716

Epoch: 6| Step: 12
Training loss: 0.3526425090980998
Validation loss: 2.2893645799002336

Epoch: 6| Step: 13
Training loss: 0.1696403956324318
Validation loss: 2.3148704669328675

Epoch: 426| Step: 0
Training loss: 0.33098426002205467
Validation loss: 2.3042807760864736

Epoch: 6| Step: 1
Training loss: 0.4484284622663987
Validation loss: 2.288245287940571

Epoch: 6| Step: 2
Training loss: 0.4857637278677972
Validation loss: 2.29964934030505

Epoch: 6| Step: 3
Training loss: 0.42975518820550707
Validation loss: 2.3011563833372266

Epoch: 6| Step: 4
Training loss: 0.17162132508017128
Validation loss: 2.3013803866456053

Epoch: 6| Step: 5
Training loss: 0.2670843064537908
Validation loss: 2.3169315549517484

Epoch: 6| Step: 6
Training loss: 0.33228730818701285
Validation loss: 2.3083905303977827

Epoch: 6| Step: 7
Training loss: 0.351656043005577
Validation loss: 2.310817930443587

Epoch: 6| Step: 8
Training loss: 0.2523675216485064
Validation loss: 2.351295786119908

Epoch: 6| Step: 9
Training loss: 0.3124824280566831
Validation loss: 2.3383450825053207

Epoch: 6| Step: 10
Training loss: 0.48344595319166966
Validation loss: 2.3118349375575287

Epoch: 6| Step: 11
Training loss: 0.16227724965771864
Validation loss: 2.314060772014861

Epoch: 6| Step: 12
Training loss: 0.19844373783309652
Validation loss: 2.263355756877488

Epoch: 6| Step: 13
Training loss: 0.3821803537232468
Validation loss: 2.2934640236764245

Epoch: 427| Step: 0
Training loss: 0.15856185319849037
Validation loss: 2.320487322311451

Epoch: 6| Step: 1
Training loss: 0.34087732051427416
Validation loss: 2.3201207426673527

Epoch: 6| Step: 2
Training loss: 0.28839914139164796
Validation loss: 2.3228718018325165

Epoch: 6| Step: 3
Training loss: 0.33435909821676096
Validation loss: 2.3377558624914054

Epoch: 6| Step: 4
Training loss: 0.5204263591194648
Validation loss: 2.3326138216202614

Epoch: 6| Step: 5
Training loss: 0.5394720926340887
Validation loss: 2.3084906521086768

Epoch: 6| Step: 6
Training loss: 0.236660990891823
Validation loss: 2.280207595986601

Epoch: 6| Step: 7
Training loss: 0.33421224215940887
Validation loss: 2.303291217917317

Epoch: 6| Step: 8
Training loss: 0.3718611362020779
Validation loss: 2.2762867732755794

Epoch: 6| Step: 9
Training loss: 0.20012537036840036
Validation loss: 2.2851022202623783

Epoch: 6| Step: 10
Training loss: 0.35455603326729906
Validation loss: 2.3142476837470576

Epoch: 6| Step: 11
Training loss: 0.24127446623752927
Validation loss: 2.3215045824332483

Epoch: 6| Step: 12
Training loss: 0.2914999701203843
Validation loss: 2.355255618508785

Epoch: 6| Step: 13
Training loss: 0.5489130463520104
Validation loss: 2.3405531631377445

Epoch: 428| Step: 0
Training loss: 0.17173209535079917
Validation loss: 2.3349816423092253

Epoch: 6| Step: 1
Training loss: 0.3378634800233091
Validation loss: 2.317688485577116

Epoch: 6| Step: 2
Training loss: 0.4595950345751375
Validation loss: 2.3089197253245217

Epoch: 6| Step: 3
Training loss: 0.37735345563391753
Validation loss: 2.3318197659780098

Epoch: 6| Step: 4
Training loss: 0.34413335837963677
Validation loss: 2.3169144968253383

Epoch: 6| Step: 5
Training loss: 0.3248071272455043
Validation loss: 2.316044247899103

Epoch: 6| Step: 6
Training loss: 0.3799567064920536
Validation loss: 2.3099271213062327

Epoch: 6| Step: 7
Training loss: 0.4298118064711693
Validation loss: 2.316569549172717

Epoch: 6| Step: 8
Training loss: 0.3016561441843181
Validation loss: 2.3290335437888823

Epoch: 6| Step: 9
Training loss: 0.3816831239056242
Validation loss: 2.3351403379496674

Epoch: 6| Step: 10
Training loss: 0.2998735429554278
Validation loss: 2.3066242848828122

Epoch: 6| Step: 11
Training loss: 0.3898373865131863
Validation loss: 2.287593294040299

Epoch: 6| Step: 12
Training loss: 0.4185416849299962
Validation loss: 2.291987789472509

Epoch: 6| Step: 13
Training loss: 0.32126647498786126
Validation loss: 2.279941990166019

Epoch: 429| Step: 0
Training loss: 0.31161598098563015
Validation loss: 2.304820402528889

Epoch: 6| Step: 1
Training loss: 0.4401340549710862
Validation loss: 2.302702777023037

Epoch: 6| Step: 2
Training loss: 0.2837690289876461
Validation loss: 2.3383940005062205

Epoch: 6| Step: 3
Training loss: 0.17588448142323704
Validation loss: 2.35203321811831

Epoch: 6| Step: 4
Training loss: 0.31618560350237285
Validation loss: 2.3698400576109955

Epoch: 6| Step: 5
Training loss: 0.31928341401512944
Validation loss: 2.413108311880646

Epoch: 6| Step: 6
Training loss: 0.4149864253156464
Validation loss: 2.3490664649563695

Epoch: 6| Step: 7
Training loss: 0.5638209303832543
Validation loss: 2.328062863954649

Epoch: 6| Step: 8
Training loss: 0.2571295159054145
Validation loss: 2.331847280907159

Epoch: 6| Step: 9
Training loss: 0.3185913317459024
Validation loss: 2.3290174037066627

Epoch: 6| Step: 10
Training loss: 0.49384280793229834
Validation loss: 2.3076825991385053

Epoch: 6| Step: 11
Training loss: 0.38266829285181964
Validation loss: 2.3261189886148697

Epoch: 6| Step: 12
Training loss: 0.2539013495339147
Validation loss: 2.3345336778425274

Epoch: 6| Step: 13
Training loss: 0.13571539964433865
Validation loss: 2.36553836173536

Epoch: 430| Step: 0
Training loss: 0.5198555701299061
Validation loss: 2.36230590675403

Epoch: 6| Step: 1
Training loss: 0.36297257958771795
Validation loss: 2.341711920044516

Epoch: 6| Step: 2
Training loss: 0.2010761792613974
Validation loss: 2.348122314657543

Epoch: 6| Step: 3
Training loss: 0.23460723179852286
Validation loss: 2.3285188811793196

Epoch: 6| Step: 4
Training loss: 0.2509578148634198
Validation loss: 2.2980463008810834

Epoch: 6| Step: 5
Training loss: 0.26388055526111764
Validation loss: 2.331515892252563

Epoch: 6| Step: 6
Training loss: 0.41938140153618225
Validation loss: 2.3323750403190293

Epoch: 6| Step: 7
Training loss: 0.24976706083503697
Validation loss: 2.311302829679653

Epoch: 6| Step: 8
Training loss: 0.38712043322984924
Validation loss: 2.3220982716847898

Epoch: 6| Step: 9
Training loss: 0.29956379261450283
Validation loss: 2.313000460512292

Epoch: 6| Step: 10
Training loss: 0.49791919343166247
Validation loss: 2.318481536086946

Epoch: 6| Step: 11
Training loss: 0.3114309263237985
Validation loss: 2.2765106088278277

Epoch: 6| Step: 12
Training loss: 0.28795944281619934
Validation loss: 2.2823085388352826

Epoch: 6| Step: 13
Training loss: 0.31624450788139286
Validation loss: 2.2795795747911596

Epoch: 431| Step: 0
Training loss: 0.30826925769649094
Validation loss: 2.2420703814046563

Epoch: 6| Step: 1
Training loss: 0.28772218660282906
Validation loss: 2.2860648178431457

Epoch: 6| Step: 2
Training loss: 0.3335069735582904
Validation loss: 2.303829275120457

Epoch: 6| Step: 3
Training loss: 0.2559236052750591
Validation loss: 2.271346800489944

Epoch: 6| Step: 4
Training loss: 0.39118322539961425
Validation loss: 2.2864898601728623

Epoch: 6| Step: 5
Training loss: 0.4514389568666064
Validation loss: 2.256367979764959

Epoch: 6| Step: 6
Training loss: 0.2464177783768012
Validation loss: 2.2622910656632116

Epoch: 6| Step: 7
Training loss: 0.3983957418363105
Validation loss: 2.2562744531529804

Epoch: 6| Step: 8
Training loss: 0.2732111129923801
Validation loss: 2.2744858009320543

Epoch: 6| Step: 9
Training loss: 0.2999454627533095
Validation loss: 2.2864052709859615

Epoch: 6| Step: 10
Training loss: 0.1404697833166422
Validation loss: 2.298299493219375

Epoch: 6| Step: 11
Training loss: 0.21033313496948577
Validation loss: 2.261790573728386

Epoch: 6| Step: 12
Training loss: 0.5400784910960359
Validation loss: 2.282175104358301

Epoch: 6| Step: 13
Training loss: 0.1367589891345507
Validation loss: 2.296348589026331

Epoch: 432| Step: 0
Training loss: 0.2986059921525742
Validation loss: 2.293770695860347

Epoch: 6| Step: 1
Training loss: 0.23571125418578628
Validation loss: 2.2978648991627

Epoch: 6| Step: 2
Training loss: 0.19120763672579652
Validation loss: 2.2966612107435522

Epoch: 6| Step: 3
Training loss: 0.19880729146452733
Validation loss: 2.318436390444291

Epoch: 6| Step: 4
Training loss: 0.181136261670852
Validation loss: 2.3082351657328757

Epoch: 6| Step: 5
Training loss: 0.23621813523895976
Validation loss: 2.296500852391302

Epoch: 6| Step: 6
Training loss: 0.37824592863464707
Validation loss: 2.3296037563836083

Epoch: 6| Step: 7
Training loss: 0.34820930552501894
Validation loss: 2.329450488885034

Epoch: 6| Step: 8
Training loss: 0.1784270903829549
Validation loss: 2.2924109183556363

Epoch: 6| Step: 9
Training loss: 0.34233092955658795
Validation loss: 2.2909445104895245

Epoch: 6| Step: 10
Training loss: 0.35554046745788004
Validation loss: 2.298615313722347

Epoch: 6| Step: 11
Training loss: 0.5014791365892308
Validation loss: 2.320456691932631

Epoch: 6| Step: 12
Training loss: 0.41523554919302025
Validation loss: 2.2994302924608876

Epoch: 6| Step: 13
Training loss: 0.34871298672183043
Validation loss: 2.31215875951996

Epoch: 433| Step: 0
Training loss: 0.20971165429805563
Validation loss: 2.3003515558917216

Epoch: 6| Step: 1
Training loss: 0.22674563832751277
Validation loss: 2.3125006130564683

Epoch: 6| Step: 2
Training loss: 0.38437392537036563
Validation loss: 2.317123842297432

Epoch: 6| Step: 3
Training loss: 0.34391892140748326
Validation loss: 2.302978342385612

Epoch: 6| Step: 4
Training loss: 0.2467375161231492
Validation loss: 2.282810135079068

Epoch: 6| Step: 5
Training loss: 0.1989530399543726
Validation loss: 2.343898244565268

Epoch: 6| Step: 6
Training loss: 0.32683136791027023
Validation loss: 2.3110867277740557

Epoch: 6| Step: 7
Training loss: 0.16863381881007133
Validation loss: 2.325279681289258

Epoch: 6| Step: 8
Training loss: 0.4272770287349785
Validation loss: 2.301528239186106

Epoch: 6| Step: 9
Training loss: 0.2737660205629847
Validation loss: 2.2956607285694943

Epoch: 6| Step: 10
Training loss: 0.5023742571595322
Validation loss: 2.3280024045093035

Epoch: 6| Step: 11
Training loss: 0.3898944126150487
Validation loss: 2.318355477053489

Epoch: 6| Step: 12
Training loss: 0.2814810916096119
Validation loss: 2.3131101491229558

Epoch: 6| Step: 13
Training loss: 0.22711873011944173
Validation loss: 2.2953198293716057

Epoch: 434| Step: 0
Training loss: 0.36115561826419135
Validation loss: 2.302669056598119

Epoch: 6| Step: 1
Training loss: 0.22361602886803253
Validation loss: 2.3124012359219606

Epoch: 6| Step: 2
Training loss: 0.22784730391607655
Validation loss: 2.3399536757804724

Epoch: 6| Step: 3
Training loss: 0.29674480745662274
Validation loss: 2.3472176268792437

Epoch: 6| Step: 4
Training loss: 0.2928996322480078
Validation loss: 2.3122524294134705

Epoch: 6| Step: 5
Training loss: 0.2937250294116099
Validation loss: 2.342137253981743

Epoch: 6| Step: 6
Training loss: 0.45951089081710106
Validation loss: 2.3242797391325687

Epoch: 6| Step: 7
Training loss: 0.21637827179383792
Validation loss: 2.3187274537171834

Epoch: 6| Step: 8
Training loss: 0.45871648884334265
Validation loss: 2.319191399535624

Epoch: 6| Step: 9
Training loss: 0.18719332171702505
Validation loss: 2.3045818823989337

Epoch: 6| Step: 10
Training loss: 0.3851019846233817
Validation loss: 2.316775520392508

Epoch: 6| Step: 11
Training loss: 0.23688642902028503
Validation loss: 2.3139993562258128

Epoch: 6| Step: 12
Training loss: 0.355497065663467
Validation loss: 2.2753594461278595

Epoch: 6| Step: 13
Training loss: 0.1063304070950255
Validation loss: 2.3173027163879794

Epoch: 435| Step: 0
Training loss: 0.276703458091005
Validation loss: 2.326364981044249

Epoch: 6| Step: 1
Training loss: 0.292774173972315
Validation loss: 2.3283669328898617

Epoch: 6| Step: 2
Training loss: 0.30554104117879116
Validation loss: 2.3000284390254015

Epoch: 6| Step: 3
Training loss: 0.43446448248327413
Validation loss: 2.3208263992798357

Epoch: 6| Step: 4
Training loss: 0.204123254015756
Validation loss: 2.3050764180840755

Epoch: 6| Step: 5
Training loss: 0.4145243426228057
Validation loss: 2.2658727728917807

Epoch: 6| Step: 6
Training loss: 0.25504806247933226
Validation loss: 2.27647684953476

Epoch: 6| Step: 7
Training loss: 0.3929283515686752
Validation loss: 2.305538623645672

Epoch: 6| Step: 8
Training loss: 0.2538796337555647
Validation loss: 2.3005731648264818

Epoch: 6| Step: 9
Training loss: 0.353953496040369
Validation loss: 2.330591793735903

Epoch: 6| Step: 10
Training loss: 0.33625351657588487
Validation loss: 2.2937958026891

Epoch: 6| Step: 11
Training loss: 0.37625618977065184
Validation loss: 2.3163194949838144

Epoch: 6| Step: 12
Training loss: 0.28462354990707467
Validation loss: 2.2963130068905135

Epoch: 6| Step: 13
Training loss: 0.26861348288828135
Validation loss: 2.3025800549274433

Epoch: 436| Step: 0
Training loss: 0.2761739587772646
Validation loss: 2.2770946955179006

Epoch: 6| Step: 1
Training loss: 0.37959182303000705
Validation loss: 2.3065950408743925

Epoch: 6| Step: 2
Training loss: 0.2410323682808798
Validation loss: 2.2728643946333205

Epoch: 6| Step: 3
Training loss: 0.21398762138163152
Validation loss: 2.3169659291872917

Epoch: 6| Step: 4
Training loss: 0.2046403481140151
Validation loss: 2.3211346086883764

Epoch: 6| Step: 5
Training loss: 0.2305213173221817
Validation loss: 2.305024223277765

Epoch: 6| Step: 6
Training loss: 0.3685810146419849
Validation loss: 2.3503823870975276

Epoch: 6| Step: 7
Training loss: 0.18963018971899837
Validation loss: 2.334894203919147

Epoch: 6| Step: 8
Training loss: 0.18682306001641932
Validation loss: 2.3413556201925565

Epoch: 6| Step: 9
Training loss: 0.34260000422172077
Validation loss: 2.286770488005269

Epoch: 6| Step: 10
Training loss: 0.49369019496253147
Validation loss: 2.3057598596842284

Epoch: 6| Step: 11
Training loss: 0.5230787670620288
Validation loss: 2.296627898349898

Epoch: 6| Step: 12
Training loss: 0.41558111360641864
Validation loss: 2.312348713093074

Epoch: 6| Step: 13
Training loss: 0.09799908540989863
Validation loss: 2.289847051117285

Epoch: 437| Step: 0
Training loss: 0.19686554477329782
Validation loss: 2.324697946805541

Epoch: 6| Step: 1
Training loss: 0.3653663356065592
Validation loss: 2.3189745922801164

Epoch: 6| Step: 2
Training loss: 0.27063960091052625
Validation loss: 2.3191063046206843

Epoch: 6| Step: 3
Training loss: 0.19195034584017734
Validation loss: 2.3390530003622128

Epoch: 6| Step: 4
Training loss: 0.4595148794818068
Validation loss: 2.3301454960033854

Epoch: 6| Step: 5
Training loss: 0.3147499389602929
Validation loss: 2.333003058842242

Epoch: 6| Step: 6
Training loss: 0.22303640805352193
Validation loss: 2.334565412722978

Epoch: 6| Step: 7
Training loss: 0.37992619362380237
Validation loss: 2.3201175752973264

Epoch: 6| Step: 8
Training loss: 0.26769390524985964
Validation loss: 2.3097501000957874

Epoch: 6| Step: 9
Training loss: 0.15057630347321538
Validation loss: 2.320618605776918

Epoch: 6| Step: 10
Training loss: 0.3587485949392417
Validation loss: 2.3095410391936464

Epoch: 6| Step: 11
Training loss: 0.22761662025047102
Validation loss: 2.3219211427432365

Epoch: 6| Step: 12
Training loss: 0.4426836586602029
Validation loss: 2.3099957658721526

Epoch: 6| Step: 13
Training loss: 0.23995026015891366
Validation loss: 2.302897327818894

Epoch: 438| Step: 0
Training loss: 0.31870033868371295
Validation loss: 2.339392368206293

Epoch: 6| Step: 1
Training loss: 0.21450610071067408
Validation loss: 2.336082582121248

Epoch: 6| Step: 2
Training loss: 0.34551050455738475
Validation loss: 2.3335872752210913

Epoch: 6| Step: 3
Training loss: 0.165356978794771
Validation loss: 2.3147578924784673

Epoch: 6| Step: 4
Training loss: 0.2707297038231619
Validation loss: 2.337178965662901

Epoch: 6| Step: 5
Training loss: 0.47814969454054196
Validation loss: 2.2987933412607

Epoch: 6| Step: 6
Training loss: 0.35821474445429374
Validation loss: 2.3112150500764628

Epoch: 6| Step: 7
Training loss: 0.23331986385591635
Validation loss: 2.3193646715820533

Epoch: 6| Step: 8
Training loss: 0.2571167082017525
Validation loss: 2.299893229201219

Epoch: 6| Step: 9
Training loss: 0.31644159284457923
Validation loss: 2.3085471561290434

Epoch: 6| Step: 10
Training loss: 0.3301068355556337
Validation loss: 2.310503268617258

Epoch: 6| Step: 11
Training loss: 0.4117611684066222
Validation loss: 2.308498564598254

Epoch: 6| Step: 12
Training loss: 0.08647151857492681
Validation loss: 2.290499063280078

Epoch: 6| Step: 13
Training loss: 0.22406443126862344
Validation loss: 2.28834666748544

Epoch: 439| Step: 0
Training loss: 0.13324431037162307
Validation loss: 2.318765068397731

Epoch: 6| Step: 1
Training loss: 0.2693432276501953
Validation loss: 2.2859429985809423

Epoch: 6| Step: 2
Training loss: 0.23771666256161234
Validation loss: 2.337385309983404

Epoch: 6| Step: 3
Training loss: 0.2319697060830621
Validation loss: 2.3269611760595077

Epoch: 6| Step: 4
Training loss: 0.24090181844734784
Validation loss: 2.3205442589407834

Epoch: 6| Step: 5
Training loss: 0.3829030299672801
Validation loss: 2.2984170721402535

Epoch: 6| Step: 6
Training loss: 0.4091730048969989
Validation loss: 2.3075758598975957

Epoch: 6| Step: 7
Training loss: 0.4549481611536858
Validation loss: 2.3225857729709927

Epoch: 6| Step: 8
Training loss: 0.3196989090599893
Validation loss: 2.3203032483635684

Epoch: 6| Step: 9
Training loss: 0.31678854840832954
Validation loss: 2.355158931501444

Epoch: 6| Step: 10
Training loss: 0.20753289572372408
Validation loss: 2.360610883791005

Epoch: 6| Step: 11
Training loss: 0.2789575609723985
Validation loss: 2.2986902125574034

Epoch: 6| Step: 12
Training loss: 0.39035885327158526
Validation loss: 2.2975268911824824

Epoch: 6| Step: 13
Training loss: 0.07062808053294728
Validation loss: 2.3184067956207377

Epoch: 440| Step: 0
Training loss: 0.3340420589491508
Validation loss: 2.309563795636095

Epoch: 6| Step: 1
Training loss: 0.14903614145027835
Validation loss: 2.293321297048909

Epoch: 6| Step: 2
Training loss: 0.4218558554367426
Validation loss: 2.305289731077137

Epoch: 6| Step: 3
Training loss: 0.2846256833216959
Validation loss: 2.2912943592600663

Epoch: 6| Step: 4
Training loss: 0.3643331986622214
Validation loss: 2.2955188610959487

Epoch: 6| Step: 5
Training loss: 0.4837622612377622
Validation loss: 2.3108381559781366

Epoch: 6| Step: 6
Training loss: 0.20149028911393668
Validation loss: 2.3202065456452634

Epoch: 6| Step: 7
Training loss: 0.20902484430657026
Validation loss: 2.3068925973583077

Epoch: 6| Step: 8
Training loss: 0.3968465118996991
Validation loss: 2.304286371678406

Epoch: 6| Step: 9
Training loss: 0.14529242351238403
Validation loss: 2.337231498679371

Epoch: 6| Step: 10
Training loss: 0.11174657048439646
Validation loss: 2.3198146877847217

Epoch: 6| Step: 11
Training loss: 0.2959707945933391
Validation loss: 2.322220350897915

Epoch: 6| Step: 12
Training loss: 0.3844454057302627
Validation loss: 2.322480975938471

Epoch: 6| Step: 13
Training loss: 0.11054435700153772
Validation loss: 2.3438724204191863

Epoch: 441| Step: 0
Training loss: 0.24278620581221808
Validation loss: 2.309938286230973

Epoch: 6| Step: 1
Training loss: 0.21686786485967005
Validation loss: 2.3060742460415553

Epoch: 6| Step: 2
Training loss: 0.24305954950699343
Validation loss: 2.316530408708311

Epoch: 6| Step: 3
Training loss: 0.21002514766653416
Validation loss: 2.3236088423439214

Epoch: 6| Step: 4
Training loss: 0.293128008471181
Validation loss: 2.3388301739823265

Epoch: 6| Step: 5
Training loss: 0.35455120005320456
Validation loss: 2.322599359448897

Epoch: 6| Step: 6
Training loss: 0.5561311230449948
Validation loss: 2.305852793347969

Epoch: 6| Step: 7
Training loss: 0.43257669642555113
Validation loss: 2.302268729101182

Epoch: 6| Step: 8
Training loss: 0.23722587658214353
Validation loss: 2.3086380020907806

Epoch: 6| Step: 9
Training loss: 0.271832030836018
Validation loss: 2.2934009295441546

Epoch: 6| Step: 10
Training loss: 0.2866020131299325
Validation loss: 2.310010970125615

Epoch: 6| Step: 11
Training loss: 0.18708306886198328
Validation loss: 2.321647555238859

Epoch: 6| Step: 12
Training loss: 0.20898677254130443
Validation loss: 2.321487799752877

Epoch: 6| Step: 13
Training loss: 0.15091180905577548
Validation loss: 2.322732802717112

Epoch: 442| Step: 0
Training loss: 0.37785681679979677
Validation loss: 2.3124398952877914

Epoch: 6| Step: 1
Training loss: 0.2846354078250382
Validation loss: 2.329644565562582

Epoch: 6| Step: 2
Training loss: 0.4008338521899846
Validation loss: 2.2960432046427806

Epoch: 6| Step: 3
Training loss: 0.33428136548434983
Validation loss: 2.2760258911994806

Epoch: 6| Step: 4
Training loss: 0.27582030897757737
Validation loss: 2.297951831019946

Epoch: 6| Step: 5
Training loss: 0.1541363750535042
Validation loss: 2.305969384570732

Epoch: 6| Step: 6
Training loss: 0.35401838601852326
Validation loss: 2.299361485222174

Epoch: 6| Step: 7
Training loss: 0.31229893653446095
Validation loss: 2.30463991889482

Epoch: 6| Step: 8
Training loss: 0.3330520533374565
Validation loss: 2.3167683244510813

Epoch: 6| Step: 9
Training loss: 0.20612656663920428
Validation loss: 2.3066749253102348

Epoch: 6| Step: 10
Training loss: 0.2923948898318327
Validation loss: 2.314276729140996

Epoch: 6| Step: 11
Training loss: 0.30200937889548074
Validation loss: 2.324545068566649

Epoch: 6| Step: 12
Training loss: 0.15571478731585814
Validation loss: 2.318505554873625

Epoch: 6| Step: 13
Training loss: 0.20181864867260857
Validation loss: 2.3272842069425943

Epoch: 443| Step: 0
Training loss: 0.2674757350852343
Validation loss: 2.287931482101098

Epoch: 6| Step: 1
Training loss: 0.3310672453802533
Validation loss: 2.3209063594274655

Epoch: 6| Step: 2
Training loss: 0.404898559735168
Validation loss: 2.284554789730292

Epoch: 6| Step: 3
Training loss: 0.13935716303201087
Validation loss: 2.3067031997320657

Epoch: 6| Step: 4
Training loss: 0.3829269432740807
Validation loss: 2.301063634339688

Epoch: 6| Step: 5
Training loss: 0.2011823095930206
Validation loss: 2.3124983858758625

Epoch: 6| Step: 6
Training loss: 0.27552637853011924
Validation loss: 2.306158649591703

Epoch: 6| Step: 7
Training loss: 0.2879084670853987
Validation loss: 2.319057173223411

Epoch: 6| Step: 8
Training loss: 0.27805714797538816
Validation loss: 2.3076291145973036

Epoch: 6| Step: 9
Training loss: 0.287936388413122
Validation loss: 2.323336199496214

Epoch: 6| Step: 10
Training loss: 0.23679400465889128
Validation loss: 2.3219879317473513

Epoch: 6| Step: 11
Training loss: 0.3871951396025274
Validation loss: 2.2917552009850084

Epoch: 6| Step: 12
Training loss: 0.28082914123368263
Validation loss: 2.2991359142659205

Epoch: 6| Step: 13
Training loss: 0.22808174774926362
Validation loss: 2.3045917405579748

Epoch: 444| Step: 0
Training loss: 0.3269085246376111
Validation loss: 2.3120893486822767

Epoch: 6| Step: 1
Training loss: 0.26935568910669544
Validation loss: 2.2878327040156248

Epoch: 6| Step: 2
Training loss: 0.3163004333253727
Validation loss: 2.300285799817908

Epoch: 6| Step: 3
Training loss: 0.19429424931401315
Validation loss: 2.3225207291871057

Epoch: 6| Step: 4
Training loss: 0.15593614050171262
Validation loss: 2.325171132796283

Epoch: 6| Step: 5
Training loss: 0.37614995747983937
Validation loss: 2.3017199839302123

Epoch: 6| Step: 6
Training loss: 0.3024251897182344
Validation loss: 2.3222545745398193

Epoch: 6| Step: 7
Training loss: 0.26145390732249824
Validation loss: 2.332102864978782

Epoch: 6| Step: 8
Training loss: 0.45248030148091956
Validation loss: 2.2782496850463607

Epoch: 6| Step: 9
Training loss: 0.46277391596138523
Validation loss: 2.2696037708020147

Epoch: 6| Step: 10
Training loss: 0.28615711877067573
Validation loss: 2.2866076763721046

Epoch: 6| Step: 11
Training loss: 0.25515504527230976
Validation loss: 2.2746145290334474

Epoch: 6| Step: 12
Training loss: 0.3044599147721799
Validation loss: 2.2776122476584533

Epoch: 6| Step: 13
Training loss: 0.09562068911571654
Validation loss: 2.2945250437529876

Epoch: 445| Step: 0
Training loss: 0.23674085532737818
Validation loss: 2.335050772018565

Epoch: 6| Step: 1
Training loss: 0.30287519071748514
Validation loss: 2.3312456911662984

Epoch: 6| Step: 2
Training loss: 0.5228306968153504
Validation loss: 2.3683880864482707

Epoch: 6| Step: 3
Training loss: 0.3471013258696862
Validation loss: 2.3389356929688336

Epoch: 6| Step: 4
Training loss: 0.2592224235343351
Validation loss: 2.2987746641812126

Epoch: 6| Step: 5
Training loss: 0.3085705350038701
Validation loss: 2.2789420498513326

Epoch: 6| Step: 6
Training loss: 0.5584116819077918
Validation loss: 2.2890319810984763

Epoch: 6| Step: 7
Training loss: 0.47303695164296317
Validation loss: 2.2948650204177303

Epoch: 6| Step: 8
Training loss: 0.31771998175649313
Validation loss: 2.33025539521435

Epoch: 6| Step: 9
Training loss: 0.3701853425173835
Validation loss: 2.3710376077171498

Epoch: 6| Step: 10
Training loss: 0.46186750955663514
Validation loss: 2.3814819192855206

Epoch: 6| Step: 11
Training loss: 0.25139819993525603
Validation loss: 2.3519768192346557

Epoch: 6| Step: 12
Training loss: 0.3528002777719431
Validation loss: 2.302107858775439

Epoch: 6| Step: 13
Training loss: 0.2297873931788854
Validation loss: 2.3048084177951877

Epoch: 446| Step: 0
Training loss: 0.4501950311556452
Validation loss: 2.309731303503543

Epoch: 6| Step: 1
Training loss: 0.32611478660004395
Validation loss: 2.2748860681008813

Epoch: 6| Step: 2
Training loss: 0.3115001657816169
Validation loss: 2.28217535261469

Epoch: 6| Step: 3
Training loss: 0.2510915411215228
Validation loss: 2.2714802470719158

Epoch: 6| Step: 4
Training loss: 0.382409428519615
Validation loss: 2.3008264278510833

Epoch: 6| Step: 5
Training loss: 0.3639820067194988
Validation loss: 2.309380921895428

Epoch: 6| Step: 6
Training loss: 0.46223006619250867
Validation loss: 2.338257300635362

Epoch: 6| Step: 7
Training loss: 0.34039495425549815
Validation loss: 2.338451592508781

Epoch: 6| Step: 8
Training loss: 0.4059372211364305
Validation loss: 2.3480560757787767

Epoch: 6| Step: 9
Training loss: 0.3659106027570839
Validation loss: 2.314073713924823

Epoch: 6| Step: 10
Training loss: 0.4621187687980749
Validation loss: 2.311486418674692

Epoch: 6| Step: 11
Training loss: 0.23530688989646453
Validation loss: 2.3112864570810623

Epoch: 6| Step: 12
Training loss: 0.3416959668114037
Validation loss: 2.307185463065354

Epoch: 6| Step: 13
Training loss: 0.3219804831685344
Validation loss: 2.338377394955253

Epoch: 447| Step: 0
Training loss: 0.27009489032240264
Validation loss: 2.3458777490041234

Epoch: 6| Step: 1
Training loss: 0.23841562546998582
Validation loss: 2.3423171719169855

Epoch: 6| Step: 2
Training loss: 0.26064473020303736
Validation loss: 2.3023256140885415

Epoch: 6| Step: 3
Training loss: 0.3083308101671098
Validation loss: 2.3212521232096823

Epoch: 6| Step: 4
Training loss: 0.3557305053454894
Validation loss: 2.2810423314419963

Epoch: 6| Step: 5
Training loss: 0.22591299648292623
Validation loss: 2.288598883546402

Epoch: 6| Step: 6
Training loss: 0.4805583250082963
Validation loss: 2.305561377339286

Epoch: 6| Step: 7
Training loss: 0.30365173645999155
Validation loss: 2.292430553111053

Epoch: 6| Step: 8
Training loss: 0.3485650816875334
Validation loss: 2.3111144562620267

Epoch: 6| Step: 9
Training loss: 0.4028584049723468
Validation loss: 2.299989886482335

Epoch: 6| Step: 10
Training loss: 0.42265889842107934
Validation loss: 2.3169074733751334

Epoch: 6| Step: 11
Training loss: 0.20545177026943598
Validation loss: 2.3315918249513397

Epoch: 6| Step: 12
Training loss: 0.292829442282166
Validation loss: 2.3289633314697435

Epoch: 6| Step: 13
Training loss: 0.48070982180846566
Validation loss: 2.317593431453257

Epoch: 448| Step: 0
Training loss: 0.41216957411927696
Validation loss: 2.3124064044364467

Epoch: 6| Step: 1
Training loss: 0.22607972239310234
Validation loss: 2.356331392903243

Epoch: 6| Step: 2
Training loss: 0.2409102384133434
Validation loss: 2.325895059800479

Epoch: 6| Step: 3
Training loss: 0.3473416523048527
Validation loss: 2.3460524692850897

Epoch: 6| Step: 4
Training loss: 0.20541771519633859
Validation loss: 2.3385251869556285

Epoch: 6| Step: 5
Training loss: 0.2800555295887657
Validation loss: 2.2998637552511414

Epoch: 6| Step: 6
Training loss: 0.2885469788476624
Validation loss: 2.3303937311184755

Epoch: 6| Step: 7
Training loss: 0.30905421223728413
Validation loss: 2.307264275942538

Epoch: 6| Step: 8
Training loss: 0.36058907060457324
Validation loss: 2.300600907483577

Epoch: 6| Step: 9
Training loss: 0.2819456134238436
Validation loss: 2.286424606365639

Epoch: 6| Step: 10
Training loss: 0.22039626740728008
Validation loss: 2.313368956920525

Epoch: 6| Step: 11
Training loss: 0.3418419508502643
Validation loss: 2.3079623396190843

Epoch: 6| Step: 12
Training loss: 0.4340319781629975
Validation loss: 2.337033393250279

Epoch: 6| Step: 13
Training loss: 0.24461569531492344
Validation loss: 2.3147558922965032

Epoch: 449| Step: 0
Training loss: 0.17482876212283271
Validation loss: 2.328640688195045

Epoch: 6| Step: 1
Training loss: 0.26988398925065327
Validation loss: 2.3160896679110627

Epoch: 6| Step: 2
Training loss: 0.4346989302020251
Validation loss: 2.3109713476460745

Epoch: 6| Step: 3
Training loss: 0.29132227774388914
Validation loss: 2.3203215610104464

Epoch: 6| Step: 4
Training loss: 0.17331211781726164
Validation loss: 2.3312818540935862

Epoch: 6| Step: 5
Training loss: 0.16640619448092256
Validation loss: 2.3252752282531244

Epoch: 6| Step: 6
Training loss: 0.36354777085973516
Validation loss: 2.3311467579233294

Epoch: 6| Step: 7
Training loss: 0.3767389271987851
Validation loss: 2.3271817228059986

Epoch: 6| Step: 8
Training loss: 0.3739802084061746
Validation loss: 2.3116013383530416

Epoch: 6| Step: 9
Training loss: 0.2887452033705521
Validation loss: 2.318529358902116

Epoch: 6| Step: 10
Training loss: 0.25368986446033404
Validation loss: 2.3142311957266033

Epoch: 6| Step: 11
Training loss: 0.2788639848671882
Validation loss: 2.2937302652302303

Epoch: 6| Step: 12
Training loss: 0.30290355262196833
Validation loss: 2.2973041525550553

Epoch: 6| Step: 13
Training loss: 0.2642447288640679
Validation loss: 2.3014442211121064

Epoch: 450| Step: 0
Training loss: 0.2876326405307392
Validation loss: 2.309393115186771

Epoch: 6| Step: 1
Training loss: 0.391856921264165
Validation loss: 2.3029189231505263

Epoch: 6| Step: 2
Training loss: 0.14054881787401788
Validation loss: 2.2948608192031665

Epoch: 6| Step: 3
Training loss: 0.36656954691065435
Validation loss: 2.3023466958962726

Epoch: 6| Step: 4
Training loss: 0.3058540436339722
Validation loss: 2.282430913750512

Epoch: 6| Step: 5
Training loss: 0.30494356399326866
Validation loss: 2.3042540306493047

Epoch: 6| Step: 6
Training loss: 0.1802643142325859
Validation loss: 2.286307987813985

Epoch: 6| Step: 7
Training loss: 0.22153408461511606
Validation loss: 2.30298881910114

Epoch: 6| Step: 8
Training loss: 0.30795757292772885
Validation loss: 2.3194765173422254

Epoch: 6| Step: 9
Training loss: 0.34881729032258196
Validation loss: 2.3032933243325395

Epoch: 6| Step: 10
Training loss: 0.15005120456451035
Validation loss: 2.297447215348977

Epoch: 6| Step: 11
Training loss: 0.2108320131389336
Validation loss: 2.2905973950997023

Epoch: 6| Step: 12
Training loss: 0.2408880164891068
Validation loss: 2.3058911200136674

Epoch: 6| Step: 13
Training loss: 0.29703699259898264
Validation loss: 2.3199913603973976

Testing loss: 3.078028533336199
