Epoch: 1| Step: 0
Training loss: 4.644559860229492
Validation loss: 5.107287852994857

Epoch: 6| Step: 1
Training loss: 5.682003498077393
Validation loss: 5.090903394965715

Epoch: 6| Step: 2
Training loss: 5.4028191566467285
Validation loss: 5.07344453565536

Epoch: 6| Step: 3
Training loss: 6.112444877624512
Validation loss: 5.05393970653575

Epoch: 6| Step: 4
Training loss: 4.3531270027160645
Validation loss: 5.0313408861878095

Epoch: 6| Step: 5
Training loss: 4.570894241333008
Validation loss: 5.006317846236691

Epoch: 6| Step: 6
Training loss: 4.658329486846924
Validation loss: 4.97746664990661

Epoch: 6| Step: 7
Training loss: 4.583794593811035
Validation loss: 4.945035226883427

Epoch: 6| Step: 8
Training loss: 5.040639877319336
Validation loss: 4.907768754548924

Epoch: 6| Step: 9
Training loss: 4.5628581047058105
Validation loss: 4.865625848052322

Epoch: 6| Step: 10
Training loss: 3.765927791595459
Validation loss: 4.817611443099155

Epoch: 6| Step: 11
Training loss: 5.058109760284424
Validation loss: 4.764517045790149

Epoch: 6| Step: 12
Training loss: 4.143830299377441
Validation loss: 4.708072980244954

Epoch: 6| Step: 13
Training loss: 2.8769946098327637
Validation loss: 4.646040449860275

Epoch: 2| Step: 0
Training loss: 4.701545715332031
Validation loss: 4.582024579407067

Epoch: 6| Step: 1
Training loss: 5.205245018005371
Validation loss: 4.512675890358546

Epoch: 6| Step: 2
Training loss: 4.652088642120361
Validation loss: 4.443673461996099

Epoch: 6| Step: 3
Training loss: 3.926454782485962
Validation loss: 4.373181179005613

Epoch: 6| Step: 4
Training loss: 4.159401893615723
Validation loss: 4.302618816334714

Epoch: 6| Step: 5
Training loss: 4.119273662567139
Validation loss: 4.232740192003147

Epoch: 6| Step: 6
Training loss: 2.662480592727661
Validation loss: 4.163153040793635

Epoch: 6| Step: 7
Training loss: 3.7061243057250977
Validation loss: 4.091492647765785

Epoch: 6| Step: 8
Training loss: 3.432016134262085
Validation loss: 4.020206230942921

Epoch: 6| Step: 9
Training loss: 4.933036804199219
Validation loss: 3.9537855732825493

Epoch: 6| Step: 10
Training loss: 2.873805046081543
Validation loss: 3.8992677042561192

Epoch: 6| Step: 11
Training loss: 3.078510284423828
Validation loss: 3.851145052140759

Epoch: 6| Step: 12
Training loss: 4.116893768310547
Validation loss: 3.80585749431323

Epoch: 6| Step: 13
Training loss: 4.51704216003418
Validation loss: 3.7613739018799155

Epoch: 3| Step: 0
Training loss: 3.305614471435547
Validation loss: 3.7209209165265484

Epoch: 6| Step: 1
Training loss: 4.32176399230957
Validation loss: 3.683416730614119

Epoch: 6| Step: 2
Training loss: 3.190988063812256
Validation loss: 3.644618877800562

Epoch: 6| Step: 3
Training loss: 4.021724700927734
Validation loss: 3.599241364386774

Epoch: 6| Step: 4
Training loss: 3.0319161415100098
Validation loss: 3.570698015151485

Epoch: 6| Step: 5
Training loss: 2.8074727058410645
Validation loss: 3.543647768676922

Epoch: 6| Step: 6
Training loss: 4.046772480010986
Validation loss: 3.508820882407568

Epoch: 6| Step: 7
Training loss: 2.924400806427002
Validation loss: 3.468488606073523

Epoch: 6| Step: 8
Training loss: 3.916093349456787
Validation loss: 3.4345913035895235

Epoch: 6| Step: 9
Training loss: 3.092409133911133
Validation loss: 3.4023970378342496

Epoch: 6| Step: 10
Training loss: 3.2291922569274902
Validation loss: 3.380451238283547

Epoch: 6| Step: 11
Training loss: 3.3011326789855957
Validation loss: 3.3594064353614725

Epoch: 6| Step: 12
Training loss: 3.7821080684661865
Validation loss: 3.3267241703566683

Epoch: 6| Step: 13
Training loss: 2.7112278938293457
Validation loss: 3.3035825529406146

Epoch: 4| Step: 0
Training loss: 2.4841482639312744
Validation loss: 3.277981488935409

Epoch: 6| Step: 1
Training loss: 2.5476622581481934
Validation loss: 3.252295245406448

Epoch: 6| Step: 2
Training loss: 4.63608455657959
Validation loss: 3.230374777188865

Epoch: 6| Step: 3
Training loss: 3.8671674728393555
Validation loss: 3.1974916714493946

Epoch: 6| Step: 4
Training loss: 3.69720721244812
Validation loss: 3.174209366562546

Epoch: 6| Step: 5
Training loss: 1.9286463260650635
Validation loss: 3.164662448308801

Epoch: 6| Step: 6
Training loss: 4.464027404785156
Validation loss: 3.161784541222357

Epoch: 6| Step: 7
Training loss: 2.8083667755126953
Validation loss: 3.140010005684309

Epoch: 6| Step: 8
Training loss: 3.0148582458496094
Validation loss: 3.112690930725426

Epoch: 6| Step: 9
Training loss: 3.540708541870117
Validation loss: 3.0938435677559144

Epoch: 6| Step: 10
Training loss: 1.9568809270858765
Validation loss: 3.07695859478366

Epoch: 6| Step: 11
Training loss: 3.699814558029175
Validation loss: 3.0635562865964827

Epoch: 6| Step: 12
Training loss: 2.630527973175049
Validation loss: 3.0431513683770293

Epoch: 6| Step: 13
Training loss: 3.125725030899048
Validation loss: 3.0269242640464538

Epoch: 5| Step: 0
Training loss: 2.882185459136963
Validation loss: 3.013141175752045

Epoch: 6| Step: 1
Training loss: 2.3228750228881836
Validation loss: 3.013687990045035

Epoch: 6| Step: 2
Training loss: 3.513266086578369
Validation loss: 2.997625607316212

Epoch: 6| Step: 3
Training loss: 2.724125385284424
Validation loss: 2.9759652178774596

Epoch: 6| Step: 4
Training loss: 2.15041446685791
Validation loss: 2.9566460963218444

Epoch: 6| Step: 5
Training loss: 3.1401848793029785
Validation loss: 2.9437257859014694

Epoch: 6| Step: 6
Training loss: 3.4891762733459473
Validation loss: 2.9365225043348087

Epoch: 6| Step: 7
Training loss: 3.2558481693267822
Validation loss: 2.9283965300488215

Epoch: 6| Step: 8
Training loss: 3.2844960689544678
Validation loss: 2.909860416125226

Epoch: 6| Step: 9
Training loss: 3.106801748275757
Validation loss: 2.897642699621057

Epoch: 6| Step: 10
Training loss: 3.4852869510650635
Validation loss: 2.8847401219029583

Epoch: 6| Step: 11
Training loss: 2.632899045944214
Validation loss: 2.8743439848705004

Epoch: 6| Step: 12
Training loss: 3.026456356048584
Validation loss: 2.8663287701145297

Epoch: 6| Step: 13
Training loss: 3.5519449710845947
Validation loss: 2.863911359540878

Epoch: 6| Step: 0
Training loss: 3.2284553050994873
Validation loss: 2.8440534837784304

Epoch: 6| Step: 1
Training loss: 2.9397945404052734
Validation loss: 2.830924049500496

Epoch: 6| Step: 2
Training loss: 2.564795970916748
Validation loss: 2.823397785104731

Epoch: 6| Step: 3
Training loss: 3.5109639167785645
Validation loss: 2.815969987582135

Epoch: 6| Step: 4
Training loss: 2.7839276790618896
Validation loss: 2.8077874952746975

Epoch: 6| Step: 5
Training loss: 1.7378770112991333
Validation loss: 2.8048186763640373

Epoch: 6| Step: 6
Training loss: 2.9528212547302246
Validation loss: 2.798722503005817

Epoch: 6| Step: 7
Training loss: 2.985135555267334
Validation loss: 2.782381788376839

Epoch: 6| Step: 8
Training loss: 3.873720407485962
Validation loss: 2.784775815984254

Epoch: 6| Step: 9
Training loss: 2.27048397064209
Validation loss: 2.780437279773015

Epoch: 6| Step: 10
Training loss: 3.156064033508301
Validation loss: 2.768330261271487

Epoch: 6| Step: 11
Training loss: 3.186789035797119
Validation loss: 2.7572787448924077

Epoch: 6| Step: 12
Training loss: 3.1329219341278076
Validation loss: 2.7518220357997443

Epoch: 6| Step: 13
Training loss: 2.443019151687622
Validation loss: 2.7533409057124967

Epoch: 7| Step: 0
Training loss: 2.5357446670532227
Validation loss: 2.7555298446327128

Epoch: 6| Step: 1
Training loss: 3.4520626068115234
Validation loss: 2.7345560109743507

Epoch: 6| Step: 2
Training loss: 3.378812313079834
Validation loss: 2.7270584978083128

Epoch: 6| Step: 3
Training loss: 2.879058837890625
Validation loss: 2.7219133659075667

Epoch: 6| Step: 4
Training loss: 2.9875917434692383
Validation loss: 2.7224747083520375

Epoch: 6| Step: 5
Training loss: 2.828829288482666
Validation loss: 2.7253235001717844

Epoch: 6| Step: 6
Training loss: 2.5339064598083496
Validation loss: 2.7236460255038355

Epoch: 6| Step: 7
Training loss: 2.913168430328369
Validation loss: 2.7240568899339244

Epoch: 6| Step: 8
Training loss: 2.917694568634033
Validation loss: 2.6965333697616414

Epoch: 6| Step: 9
Training loss: 2.955531120300293
Validation loss: 2.69775160666435

Epoch: 6| Step: 10
Training loss: 2.897491455078125
Validation loss: 2.706461191177368

Epoch: 6| Step: 11
Training loss: 2.702920913696289
Validation loss: 2.6956233004088044

Epoch: 6| Step: 12
Training loss: 2.4662013053894043
Validation loss: 2.6908406544757146

Epoch: 6| Step: 13
Training loss: 2.743525981903076
Validation loss: 2.7061614426233436

Epoch: 8| Step: 0
Training loss: 2.8110108375549316
Validation loss: 2.6819955149004535

Epoch: 6| Step: 1
Training loss: 2.415907144546509
Validation loss: 2.6656680645481234

Epoch: 6| Step: 2
Training loss: 3.528606414794922
Validation loss: 2.6614282156831477

Epoch: 6| Step: 3
Training loss: 2.4777331352233887
Validation loss: 2.6617097034249255

Epoch: 6| Step: 4
Training loss: 2.873274803161621
Validation loss: 2.6640335077880533

Epoch: 6| Step: 5
Training loss: 3.1813149452209473
Validation loss: 2.6664381488676994

Epoch: 6| Step: 6
Training loss: 3.6411235332489014
Validation loss: 2.661036793903638

Epoch: 6| Step: 7
Training loss: 2.5705389976501465
Validation loss: 2.6403414844184794

Epoch: 6| Step: 8
Training loss: 2.51478910446167
Validation loss: 2.6526955122588785

Epoch: 6| Step: 9
Training loss: 2.4783971309661865
Validation loss: 2.669405642376151

Epoch: 6| Step: 10
Training loss: 2.2643253803253174
Validation loss: 2.6771759038330405

Epoch: 6| Step: 11
Training loss: 3.280534267425537
Validation loss: 2.6376300960458736

Epoch: 6| Step: 12
Training loss: 2.9962854385375977
Validation loss: 2.628668672295027

Epoch: 6| Step: 13
Training loss: 2.720897674560547
Validation loss: 2.6407466165481077

Epoch: 9| Step: 0
Training loss: 2.6083879470825195
Validation loss: 2.6602724290663198

Epoch: 6| Step: 1
Training loss: 2.880061149597168
Validation loss: 2.672951231720627

Epoch: 6| Step: 2
Training loss: 2.4592843055725098
Validation loss: 2.6731734814182406

Epoch: 6| Step: 3
Training loss: 3.5764448642730713
Validation loss: 2.6545773603582896

Epoch: 6| Step: 4
Training loss: 3.0170369148254395
Validation loss: 2.6404558868818384

Epoch: 6| Step: 5
Training loss: 1.7473193407058716
Validation loss: 2.6412307062456684

Epoch: 6| Step: 6
Training loss: 3.3506319522857666
Validation loss: 2.651995763983778

Epoch: 6| Step: 7
Training loss: 2.5840559005737305
Validation loss: 2.67167152384276

Epoch: 6| Step: 8
Training loss: 3.2281036376953125
Validation loss: 2.6899116526367846

Epoch: 6| Step: 9
Training loss: 3.1344661712646484
Validation loss: 2.6796256726787937

Epoch: 6| Step: 10
Training loss: 2.657405138015747
Validation loss: 2.6377044082969747

Epoch: 6| Step: 11
Training loss: 3.3784823417663574
Validation loss: 2.616671985195529

Epoch: 6| Step: 12
Training loss: 2.7080020904541016
Validation loss: 2.6072412972809165

Epoch: 6| Step: 13
Training loss: 1.886110544204712
Validation loss: 2.605852416766587

Epoch: 10| Step: 0
Training loss: 2.800342082977295
Validation loss: 2.6325026109654415

Epoch: 6| Step: 1
Training loss: 2.457096576690674
Validation loss: 2.6695691077939925

Epoch: 6| Step: 2
Training loss: 2.892455816268921
Validation loss: 2.685643849834319

Epoch: 6| Step: 3
Training loss: 3.285111665725708
Validation loss: 2.685502959835914

Epoch: 6| Step: 4
Training loss: 2.0475645065307617
Validation loss: 2.6765418796129126

Epoch: 6| Step: 5
Training loss: 2.6757028102874756
Validation loss: 2.6903193894252984

Epoch: 6| Step: 6
Training loss: 2.523930072784424
Validation loss: 2.699897586658437

Epoch: 6| Step: 7
Training loss: 3.310075044631958
Validation loss: 2.6938689498491186

Epoch: 6| Step: 8
Training loss: 2.813169479370117
Validation loss: 2.6681288801213747

Epoch: 6| Step: 9
Training loss: 2.2656962871551514
Validation loss: 2.673565464635049

Epoch: 6| Step: 10
Training loss: 2.6815185546875
Validation loss: 2.6923977380157798

Epoch: 6| Step: 11
Training loss: 3.0756750106811523
Validation loss: 2.7171224932516775

Epoch: 6| Step: 12
Training loss: 4.077254295349121
Validation loss: 2.7633621513202624

Epoch: 6| Step: 13
Training loss: 3.080091714859009
Validation loss: 2.748474577421783

Epoch: 11| Step: 0
Training loss: 3.0115833282470703
Validation loss: 2.702626259096207

Epoch: 6| Step: 1
Training loss: 2.6926345825195312
Validation loss: 2.66498762817793

Epoch: 6| Step: 2
Training loss: 2.5355029106140137
Validation loss: 2.6585989434231996

Epoch: 6| Step: 3
Training loss: 2.893927574157715
Validation loss: 2.67687403258457

Epoch: 6| Step: 4
Training loss: 2.372640609741211
Validation loss: 2.6737941247160717

Epoch: 6| Step: 5
Training loss: 3.1031436920166016
Validation loss: 2.682803856429233

Epoch: 6| Step: 6
Training loss: 3.144730567932129
Validation loss: 2.6736547024019304

Epoch: 6| Step: 7
Training loss: 2.994359254837036
Validation loss: 2.654089955873387

Epoch: 6| Step: 8
Training loss: 3.4208321571350098
Validation loss: 2.6276400268718763

Epoch: 6| Step: 9
Training loss: 3.074362277984619
Validation loss: 2.6072880068132953

Epoch: 6| Step: 10
Training loss: 1.7698907852172852
Validation loss: 2.592824125802645

Epoch: 6| Step: 11
Training loss: 3.256650447845459
Validation loss: 2.5933821816598215

Epoch: 6| Step: 12
Training loss: 2.571166515350342
Validation loss: 2.5901081433860202

Epoch: 6| Step: 13
Training loss: 2.6900243759155273
Validation loss: 2.5920120644313034

Epoch: 12| Step: 0
Training loss: 2.6651017665863037
Validation loss: 2.595559517542521

Epoch: 6| Step: 1
Training loss: 3.0029654502868652
Validation loss: 2.583152791505219

Epoch: 6| Step: 2
Training loss: 2.6186249256134033
Validation loss: 2.568367194103938

Epoch: 6| Step: 3
Training loss: 2.351320266723633
Validation loss: 2.5660216218681744

Epoch: 6| Step: 4
Training loss: 3.7702407836914062
Validation loss: 2.564126532564881

Epoch: 6| Step: 5
Training loss: 2.510775089263916
Validation loss: 2.567149116146949

Epoch: 6| Step: 6
Training loss: 2.6185879707336426
Validation loss: 2.559346286199426

Epoch: 6| Step: 7
Training loss: 2.5325517654418945
Validation loss: 2.5538702164926836

Epoch: 6| Step: 8
Training loss: 3.2084248065948486
Validation loss: 2.541192111148629

Epoch: 6| Step: 9
Training loss: 2.1714937686920166
Validation loss: 2.5448432789053967

Epoch: 6| Step: 10
Training loss: 2.693162441253662
Validation loss: 2.570873145134218

Epoch: 6| Step: 11
Training loss: 3.0085833072662354
Validation loss: 2.596915791111608

Epoch: 6| Step: 12
Training loss: 3.317457675933838
Validation loss: 2.5766349172079437

Epoch: 6| Step: 13
Training loss: 2.0159692764282227
Validation loss: 2.558984077104958

Epoch: 13| Step: 0
Training loss: 2.8620355129241943
Validation loss: 2.5477783897871613

Epoch: 6| Step: 1
Training loss: 2.8395872116088867
Validation loss: 2.5383820149206344

Epoch: 6| Step: 2
Training loss: 3.3300323486328125
Validation loss: 2.540930727476715

Epoch: 6| Step: 3
Training loss: 3.2232303619384766
Validation loss: 2.542194169054749

Epoch: 6| Step: 4
Training loss: 2.8242063522338867
Validation loss: 2.5559506390684392

Epoch: 6| Step: 5
Training loss: 3.2339234352111816
Validation loss: 2.5599512746257167

Epoch: 6| Step: 6
Training loss: 3.087351083755493
Validation loss: 2.5654060943152315

Epoch: 6| Step: 7
Training loss: 3.2870044708251953
Validation loss: 2.5723194332532984

Epoch: 6| Step: 8
Training loss: 2.040743350982666
Validation loss: 2.572800085108767

Epoch: 6| Step: 9
Training loss: 2.0113935470581055
Validation loss: 2.5749249817222677

Epoch: 6| Step: 10
Training loss: 2.1827027797698975
Validation loss: 2.546959377104236

Epoch: 6| Step: 11
Training loss: 2.2690272331237793
Validation loss: 2.5244248118451846

Epoch: 6| Step: 12
Training loss: 2.1558637619018555
Validation loss: 2.522529238013811

Epoch: 6| Step: 13
Training loss: 3.4604275226593018
Validation loss: 2.5350600775851997

Epoch: 14| Step: 0
Training loss: 3.7482285499572754
Validation loss: 2.5323473586831042

Epoch: 6| Step: 1
Training loss: 2.2720398902893066
Validation loss: 2.5351423755768807

Epoch: 6| Step: 2
Training loss: 3.5167369842529297
Validation loss: 2.528452470738401

Epoch: 6| Step: 3
Training loss: 3.1010942459106445
Validation loss: 2.526461678166543

Epoch: 6| Step: 4
Training loss: 3.4078898429870605
Validation loss: 2.5232485276396557

Epoch: 6| Step: 5
Training loss: 2.407773494720459
Validation loss: 2.5236723884459464

Epoch: 6| Step: 6
Training loss: 1.9987475872039795
Validation loss: 2.515757360766011

Epoch: 6| Step: 7
Training loss: 2.745077610015869
Validation loss: 2.5172307824575775

Epoch: 6| Step: 8
Training loss: 3.2558703422546387
Validation loss: 2.5107599509659635

Epoch: 6| Step: 9
Training loss: 1.9592902660369873
Validation loss: 2.5064504864395305

Epoch: 6| Step: 10
Training loss: 2.079164981842041
Validation loss: 2.517763235235727

Epoch: 6| Step: 11
Training loss: 2.875793218612671
Validation loss: 2.5401494964476554

Epoch: 6| Step: 12
Training loss: 2.4898219108581543
Validation loss: 2.5944749616807505

Epoch: 6| Step: 13
Training loss: 2.3070313930511475
Validation loss: 2.6552900037457867

Epoch: 15| Step: 0
Training loss: 1.9551351070404053
Validation loss: 2.652150846296741

Epoch: 6| Step: 1
Training loss: 3.2387568950653076
Validation loss: 2.6330821232129167

Epoch: 6| Step: 2
Training loss: 3.3536624908447266
Validation loss: 2.610311113378053

Epoch: 6| Step: 3
Training loss: 2.4478797912597656
Validation loss: 2.5853757858276367

Epoch: 6| Step: 4
Training loss: 2.886967897415161
Validation loss: 2.579529954541114

Epoch: 6| Step: 5
Training loss: 1.8831117153167725
Validation loss: 2.5809799778846

Epoch: 6| Step: 6
Training loss: 2.50773286819458
Validation loss: 2.5802080759438137

Epoch: 6| Step: 7
Training loss: 3.5392603874206543
Validation loss: 2.5774016764856156

Epoch: 6| Step: 8
Training loss: 3.271873950958252
Validation loss: 2.578889182818833

Epoch: 6| Step: 9
Training loss: 3.5265097618103027
Validation loss: 2.5751846323731127

Epoch: 6| Step: 10
Training loss: 1.785205602645874
Validation loss: 2.573824920961934

Epoch: 6| Step: 11
Training loss: 2.8380916118621826
Validation loss: 2.5741157377919843

Epoch: 6| Step: 12
Training loss: 3.4961862564086914
Validation loss: 2.575926434609198

Epoch: 6| Step: 13
Training loss: 1.55849289894104
Validation loss: 2.5671889269223778

Epoch: 16| Step: 0
Training loss: 2.588844060897827
Validation loss: 2.5690757664301063

Epoch: 6| Step: 1
Training loss: 2.66609263420105
Validation loss: 2.57042682555414

Epoch: 6| Step: 2
Training loss: 2.1298680305480957
Validation loss: 2.56147010736568

Epoch: 6| Step: 3
Training loss: 2.280707836151123
Validation loss: 2.559501222384873

Epoch: 6| Step: 4
Training loss: 2.5519416332244873
Validation loss: 2.5596267843759186

Epoch: 6| Step: 5
Training loss: 2.760185480117798
Validation loss: 2.564591566721598

Epoch: 6| Step: 6
Training loss: 3.077061891555786
Validation loss: 2.5690276776590655

Epoch: 6| Step: 7
Training loss: 2.9830844402313232
Validation loss: 2.5760379145222325

Epoch: 6| Step: 8
Training loss: 2.8263187408447266
Validation loss: 2.5655682779127553

Epoch: 6| Step: 9
Training loss: 2.859483480453491
Validation loss: 2.558683177476288

Epoch: 6| Step: 10
Training loss: 3.3000359535217285
Validation loss: 2.559861936876851

Epoch: 6| Step: 11
Training loss: 2.9464521408081055
Validation loss: 2.548989308777676

Epoch: 6| Step: 12
Training loss: 3.3726439476013184
Validation loss: 2.549307718071886

Epoch: 6| Step: 13
Training loss: 1.605520248413086
Validation loss: 2.541905521064676

Epoch: 17| Step: 0
Training loss: 3.5441417694091797
Validation loss: 2.551533083761892

Epoch: 6| Step: 1
Training loss: 2.1750383377075195
Validation loss: 2.552507572276618

Epoch: 6| Step: 2
Training loss: 2.959873914718628
Validation loss: 2.559592698210029

Epoch: 6| Step: 3
Training loss: 2.66233491897583
Validation loss: 2.5492602471382386

Epoch: 6| Step: 4
Training loss: 2.15798282623291
Validation loss: 2.537960795946019

Epoch: 6| Step: 5
Training loss: 2.9007022380828857
Validation loss: 2.5261896361586866

Epoch: 6| Step: 6
Training loss: 3.3421757221221924
Validation loss: 2.51645262523364

Epoch: 6| Step: 7
Training loss: 2.2664740085601807
Validation loss: 2.5006272126269597

Epoch: 6| Step: 8
Training loss: 2.5730156898498535
Validation loss: 2.4967901424695085

Epoch: 6| Step: 9
Training loss: 2.8921985626220703
Validation loss: 2.5382575450404996

Epoch: 6| Step: 10
Training loss: 2.430812120437622
Validation loss: 2.495349604596374

Epoch: 6| Step: 11
Training loss: 3.283923387527466
Validation loss: 2.5034840850419897

Epoch: 6| Step: 12
Training loss: 2.7103610038757324
Validation loss: 2.491321168920045

Epoch: 6| Step: 13
Training loss: 2.0110533237457275
Validation loss: 2.458657403146067

Epoch: 18| Step: 0
Training loss: 2.6669580936431885
Validation loss: 2.4626527037671817

Epoch: 6| Step: 1
Training loss: 2.1472668647766113
Validation loss: 2.4703381779373332

Epoch: 6| Step: 2
Training loss: 3.66810941696167
Validation loss: 2.4790816358340684

Epoch: 6| Step: 3
Training loss: 2.605466842651367
Validation loss: 2.4790217030432915

Epoch: 6| Step: 4
Training loss: 3.7112064361572266
Validation loss: 2.4721211079628236

Epoch: 6| Step: 5
Training loss: 3.028412342071533
Validation loss: 2.4665726025899253

Epoch: 6| Step: 6
Training loss: 2.0938656330108643
Validation loss: 2.463788652932772

Epoch: 6| Step: 7
Training loss: 2.1929099559783936
Validation loss: 2.4590310870960193

Epoch: 6| Step: 8
Training loss: 2.354802131652832
Validation loss: 2.4671407873912523

Epoch: 6| Step: 9
Training loss: 1.6675832271575928
Validation loss: 2.472301367790468

Epoch: 6| Step: 10
Training loss: 2.796419143676758
Validation loss: 2.48240860303243

Epoch: 6| Step: 11
Training loss: 3.21097469329834
Validation loss: 2.5101541139746226

Epoch: 6| Step: 12
Training loss: 2.7043709754943848
Validation loss: 2.5424669660547727

Epoch: 6| Step: 13
Training loss: 3.147120475769043
Validation loss: 2.526710707654235

Epoch: 19| Step: 0
Training loss: 3.1177046298980713
Validation loss: 2.4870421130170106

Epoch: 6| Step: 1
Training loss: 2.458451986312866
Validation loss: 2.4645422427884993

Epoch: 6| Step: 2
Training loss: 3.6917214393615723
Validation loss: 2.45081001968794

Epoch: 6| Step: 3
Training loss: 2.581549644470215
Validation loss: 2.4523979079338813

Epoch: 6| Step: 4
Training loss: 2.3369340896606445
Validation loss: 2.4489441302514847

Epoch: 6| Step: 5
Training loss: 2.4646244049072266
Validation loss: 2.4449693541372977

Epoch: 6| Step: 6
Training loss: 2.8969497680664062
Validation loss: 2.442256591653311

Epoch: 6| Step: 7
Training loss: 2.557814598083496
Validation loss: 2.440697769964895

Epoch: 6| Step: 8
Training loss: 2.834707736968994
Validation loss: 2.4368601409337853

Epoch: 6| Step: 9
Training loss: 2.7448272705078125
Validation loss: 2.4340550463686705

Epoch: 6| Step: 10
Training loss: 2.1904211044311523
Validation loss: 2.4460467266780075

Epoch: 6| Step: 11
Training loss: 2.7326202392578125
Validation loss: 2.4720664588353967

Epoch: 6| Step: 12
Training loss: 2.83925724029541
Validation loss: 2.4666143899322837

Epoch: 6| Step: 13
Training loss: 1.6450209617614746
Validation loss: 2.4574658537423737

Epoch: 20| Step: 0
Training loss: 2.2776808738708496
Validation loss: 2.4508507021011843

Epoch: 6| Step: 1
Training loss: 3.1349191665649414
Validation loss: 2.4505993166277484

Epoch: 6| Step: 2
Training loss: 2.6131362915039062
Validation loss: 2.4522140333729405

Epoch: 6| Step: 3
Training loss: 2.295645236968994
Validation loss: 2.4451203320616033

Epoch: 6| Step: 4
Training loss: 3.0287909507751465
Validation loss: 2.4440235989068144

Epoch: 6| Step: 5
Training loss: 2.0968399047851562
Validation loss: 2.439424331470202

Epoch: 6| Step: 6
Training loss: 2.650430679321289
Validation loss: 2.4385319961014615

Epoch: 6| Step: 7
Training loss: 2.9657297134399414
Validation loss: 2.4332452615102134

Epoch: 6| Step: 8
Training loss: 3.1381685733795166
Validation loss: 2.429098924001058

Epoch: 6| Step: 9
Training loss: 2.945560932159424
Validation loss: 2.4310025809913554

Epoch: 6| Step: 10
Training loss: 2.2062618732452393
Validation loss: 2.4335048890882924

Epoch: 6| Step: 11
Training loss: 2.6287319660186768
Validation loss: 2.431239999750609

Epoch: 6| Step: 12
Training loss: 3.1084375381469727
Validation loss: 2.4361650431027977

Epoch: 6| Step: 13
Training loss: 1.8704087734222412
Validation loss: 2.433723442016109

Epoch: 21| Step: 0
Training loss: 3.136005401611328
Validation loss: 2.4296521807229645

Epoch: 6| Step: 1
Training loss: 2.4850525856018066
Validation loss: 2.430854376926217

Epoch: 6| Step: 2
Training loss: 2.2161498069763184
Validation loss: 2.4314035702777166

Epoch: 6| Step: 3
Training loss: 2.498124599456787
Validation loss: 2.4310787108636673

Epoch: 6| Step: 4
Training loss: 2.8367486000061035
Validation loss: 2.4316325136410293

Epoch: 6| Step: 5
Training loss: 1.8507764339447021
Validation loss: 2.423618419196016

Epoch: 6| Step: 6
Training loss: 2.84879994392395
Validation loss: 2.422764516645862

Epoch: 6| Step: 7
Training loss: 3.562255859375
Validation loss: 2.4186734281560427

Epoch: 6| Step: 8
Training loss: 2.613340377807617
Validation loss: 2.422576201859341

Epoch: 6| Step: 9
Training loss: 2.102341651916504
Validation loss: 2.4108703879899878

Epoch: 6| Step: 10
Training loss: 2.670370101928711
Validation loss: 2.4190623350040887

Epoch: 6| Step: 11
Training loss: 2.3829948902130127
Validation loss: 2.4266309481795116

Epoch: 6| Step: 12
Training loss: 2.9532203674316406
Validation loss: 2.448256256759808

Epoch: 6| Step: 13
Training loss: 3.490109443664551
Validation loss: 2.475185501960016

Epoch: 22| Step: 0
Training loss: 2.4320616722106934
Validation loss: 2.4506066332581224

Epoch: 6| Step: 1
Training loss: 3.1418709754943848
Validation loss: 2.4168002861802296

Epoch: 6| Step: 2
Training loss: 2.308274745941162
Validation loss: 2.406257963949634

Epoch: 6| Step: 3
Training loss: 3.208771228790283
Validation loss: 2.4104272114333285

Epoch: 6| Step: 4
Training loss: 2.5837061405181885
Validation loss: 2.422181619110928

Epoch: 6| Step: 5
Training loss: 3.2094666957855225
Validation loss: 2.4367004825222875

Epoch: 6| Step: 6
Training loss: 2.5218899250030518
Validation loss: 2.4498368129935315

Epoch: 6| Step: 7
Training loss: 2.346816301345825
Validation loss: 2.4607963228738434

Epoch: 6| Step: 8
Training loss: 2.500892162322998
Validation loss: 2.5038897939907607

Epoch: 6| Step: 9
Training loss: 2.019491672515869
Validation loss: 2.4839977141349547

Epoch: 6| Step: 10
Training loss: 2.6303420066833496
Validation loss: 2.4558268541930826

Epoch: 6| Step: 11
Training loss: 2.621335744857788
Validation loss: 2.437135050373693

Epoch: 6| Step: 12
Training loss: 2.9973347187042236
Validation loss: 2.4256512349651707

Epoch: 6| Step: 13
Training loss: 3.240387201309204
Validation loss: 2.411448609444403

Epoch: 23| Step: 0
Training loss: 3.2192695140838623
Validation loss: 2.407037260711834

Epoch: 6| Step: 1
Training loss: 3.2147374153137207
Validation loss: 2.407734404328049

Epoch: 6| Step: 2
Training loss: 2.2786269187927246
Validation loss: 2.4030509930784985

Epoch: 6| Step: 3
Training loss: 2.5051748752593994
Validation loss: 2.4191812828022945

Epoch: 6| Step: 4
Training loss: 2.090881824493408
Validation loss: 2.423112943608274

Epoch: 6| Step: 5
Training loss: 2.1384990215301514
Validation loss: 2.4386539202864452

Epoch: 6| Step: 6
Training loss: 2.9514598846435547
Validation loss: 2.467958060644006

Epoch: 6| Step: 7
Training loss: 2.9224300384521484
Validation loss: 2.489779803060716

Epoch: 6| Step: 8
Training loss: 2.349468231201172
Validation loss: 2.4905772670622794

Epoch: 6| Step: 9
Training loss: 2.187727451324463
Validation loss: 2.5139741641218945

Epoch: 6| Step: 10
Training loss: 2.8167219161987305
Validation loss: 2.487066215084445

Epoch: 6| Step: 11
Training loss: 3.3032917976379395
Validation loss: 2.4587857748872493

Epoch: 6| Step: 12
Training loss: 2.8917479515075684
Validation loss: 2.431179928523238

Epoch: 6| Step: 13
Training loss: 2.391380548477173
Validation loss: 2.404796669560094

Epoch: 24| Step: 0
Training loss: 2.3063509464263916
Validation loss: 2.3930887740145446

Epoch: 6| Step: 1
Training loss: 3.431797504425049
Validation loss: 2.3943339188893638

Epoch: 6| Step: 2
Training loss: 2.470179557800293
Validation loss: 2.402787076529636

Epoch: 6| Step: 3
Training loss: 1.8808412551879883
Validation loss: 2.3972568383780857

Epoch: 6| Step: 4
Training loss: 3.697598934173584
Validation loss: 2.3971473375956216

Epoch: 6| Step: 5
Training loss: 2.5920937061309814
Validation loss: 2.3976060036690003

Epoch: 6| Step: 6
Training loss: 2.593320846557617
Validation loss: 2.401970527505362

Epoch: 6| Step: 7
Training loss: 2.6274404525756836
Validation loss: 2.393719021992017

Epoch: 6| Step: 8
Training loss: 2.036539316177368
Validation loss: 2.394285443008587

Epoch: 6| Step: 9
Training loss: 2.3339877128601074
Validation loss: 2.4064192874457246

Epoch: 6| Step: 10
Training loss: 3.3062334060668945
Validation loss: 2.40994676210547

Epoch: 6| Step: 11
Training loss: 2.4443469047546387
Validation loss: 2.4242363488802345

Epoch: 6| Step: 12
Training loss: 2.390537977218628
Validation loss: 2.4101267219871603

Epoch: 6| Step: 13
Training loss: 3.171221971511841
Validation loss: 2.4268088930396625

Epoch: 25| Step: 0
Training loss: 2.4945147037506104
Validation loss: 2.4251781458495767

Epoch: 6| Step: 1
Training loss: 3.0568387508392334
Validation loss: 2.4473209227285078

Epoch: 6| Step: 2
Training loss: 3.076897382736206
Validation loss: 2.4368533267769763

Epoch: 6| Step: 3
Training loss: 3.2904300689697266
Validation loss: 2.3913843631744385

Epoch: 6| Step: 4
Training loss: 2.7537569999694824
Validation loss: 2.3865130152753604

Epoch: 6| Step: 5
Training loss: 2.046816825866699
Validation loss: 2.391912193708522

Epoch: 6| Step: 6
Training loss: 2.918973684310913
Validation loss: 2.3900327631222305

Epoch: 6| Step: 7
Training loss: 2.905304431915283
Validation loss: 2.3981184292865056

Epoch: 6| Step: 8
Training loss: 2.402364730834961
Validation loss: 2.4135522637315976

Epoch: 6| Step: 9
Training loss: 2.7269158363342285
Validation loss: 2.4431171776146017

Epoch: 6| Step: 10
Training loss: 2.7222580909729004
Validation loss: 2.431799022100305

Epoch: 6| Step: 11
Training loss: 1.8797070980072021
Validation loss: 2.4190694337250083

Epoch: 6| Step: 12
Training loss: 2.8637325763702393
Validation loss: 2.4200484060472056

Epoch: 6| Step: 13
Training loss: 1.8018550872802734
Validation loss: 2.4020108304997927

Epoch: 26| Step: 0
Training loss: 1.9677963256835938
Validation loss: 2.3946364284843527

Epoch: 6| Step: 1
Training loss: 3.3456287384033203
Validation loss: 2.398170248154671

Epoch: 6| Step: 2
Training loss: 2.464832305908203
Validation loss: 2.392812551990632

Epoch: 6| Step: 3
Training loss: 2.1515824794769287
Validation loss: 2.4020505092477284

Epoch: 6| Step: 4
Training loss: 2.6148319244384766
Validation loss: 2.385173607898015

Epoch: 6| Step: 5
Training loss: 3.1200144290924072
Validation loss: 2.376362964671145

Epoch: 6| Step: 6
Training loss: 2.3329110145568848
Validation loss: 2.3725972137143536

Epoch: 6| Step: 7
Training loss: 2.5878241062164307
Validation loss: 2.3758669155900196

Epoch: 6| Step: 8
Training loss: 2.1336026191711426
Validation loss: 2.3752035812665055

Epoch: 6| Step: 9
Training loss: 3.273756504058838
Validation loss: 2.3731798561670447

Epoch: 6| Step: 10
Training loss: 3.3955917358398438
Validation loss: 2.3751634141450286

Epoch: 6| Step: 11
Training loss: 2.601325750350952
Validation loss: 2.375890898448165

Epoch: 6| Step: 12
Training loss: 2.0803885459899902
Validation loss: 2.3769636179811213

Epoch: 6| Step: 13
Training loss: 2.983645439147949
Validation loss: 2.376707153935586

Epoch: 27| Step: 0
Training loss: 2.8384625911712646
Validation loss: 2.3948992708677888

Epoch: 6| Step: 1
Training loss: 2.7729406356811523
Validation loss: 2.3949519434282855

Epoch: 6| Step: 2
Training loss: 2.378443717956543
Validation loss: 2.3939086852535123

Epoch: 6| Step: 3
Training loss: 2.635826349258423
Validation loss: 2.389495793209281

Epoch: 6| Step: 4
Training loss: 2.4286413192749023
Validation loss: 2.3759739270774265

Epoch: 6| Step: 5
Training loss: 2.6852540969848633
Validation loss: 2.36954620704856

Epoch: 6| Step: 6
Training loss: 2.1974406242370605
Validation loss: 2.3668995544474614

Epoch: 6| Step: 7
Training loss: 2.790703296661377
Validation loss: 2.3724681536356607

Epoch: 6| Step: 8
Training loss: 2.2140884399414062
Validation loss: 2.371488507075976

Epoch: 6| Step: 9
Training loss: 2.3455498218536377
Validation loss: 2.371676698807747

Epoch: 6| Step: 10
Training loss: 2.707092523574829
Validation loss: 2.3635953062324115

Epoch: 6| Step: 11
Training loss: 3.1915035247802734
Validation loss: 2.364434854958647

Epoch: 6| Step: 12
Training loss: 2.7941417694091797
Validation loss: 2.3621851654462915

Epoch: 6| Step: 13
Training loss: 3.287163496017456
Validation loss: 2.3601085550041607

Epoch: 28| Step: 0
Training loss: 2.6895666122436523
Validation loss: 2.361069199859455

Epoch: 6| Step: 1
Training loss: 2.608426570892334
Validation loss: 2.3591880029247654

Epoch: 6| Step: 2
Training loss: 2.6338350772857666
Validation loss: 2.360676560350644

Epoch: 6| Step: 3
Training loss: 2.5035901069641113
Validation loss: 2.3581558222411783

Epoch: 6| Step: 4
Training loss: 2.541374444961548
Validation loss: 2.353931744893392

Epoch: 6| Step: 5
Training loss: 2.4064481258392334
Validation loss: 2.354193572075136

Epoch: 6| Step: 6
Training loss: 3.054863929748535
Validation loss: 2.3548617004066386

Epoch: 6| Step: 7
Training loss: 2.199568271636963
Validation loss: 2.359333040893719

Epoch: 6| Step: 8
Training loss: 2.680211305618286
Validation loss: 2.354849415440713

Epoch: 6| Step: 9
Training loss: 2.616145610809326
Validation loss: 2.363677583714967

Epoch: 6| Step: 10
Training loss: 2.5584328174591064
Validation loss: 2.3579895739914267

Epoch: 6| Step: 11
Training loss: 2.2371273040771484
Validation loss: 2.353808072305495

Epoch: 6| Step: 12
Training loss: 2.8245604038238525
Validation loss: 2.349626712901618

Epoch: 6| Step: 13
Training loss: 3.5662825107574463
Validation loss: 2.3489316612161617

Epoch: 29| Step: 0
Training loss: 3.030996084213257
Validation loss: 2.3452945678464827

Epoch: 6| Step: 1
Training loss: 2.685387372970581
Validation loss: 2.344631693696463

Epoch: 6| Step: 2
Training loss: 2.102095127105713
Validation loss: 2.3400070051993094

Epoch: 6| Step: 3
Training loss: 3.2482831478118896
Validation loss: 2.343587572856616

Epoch: 6| Step: 4
Training loss: 2.522738456726074
Validation loss: 2.342720088138375

Epoch: 6| Step: 5
Training loss: 3.0130414962768555
Validation loss: 2.343548559373425

Epoch: 6| Step: 6
Training loss: 1.9826643466949463
Validation loss: 2.3378120442872405

Epoch: 6| Step: 7
Training loss: 2.7750189304351807
Validation loss: 2.3409823858609764

Epoch: 6| Step: 8
Training loss: 3.0628762245178223
Validation loss: 2.342272371374151

Epoch: 6| Step: 9
Training loss: 2.6029810905456543
Validation loss: 2.3414072682780604

Epoch: 6| Step: 10
Training loss: 2.456192970275879
Validation loss: 2.3368712432922853

Epoch: 6| Step: 11
Training loss: 1.9005894660949707
Validation loss: 2.336462466947494

Epoch: 6| Step: 12
Training loss: 2.4215219020843506
Validation loss: 2.3363206002020065

Epoch: 6| Step: 13
Training loss: 2.96394681930542
Validation loss: 2.3375994172147525

Epoch: 30| Step: 0
Training loss: 2.2094345092773438
Validation loss: 2.3746984363884054

Epoch: 6| Step: 1
Training loss: 2.563640594482422
Validation loss: 2.4312754241369103

Epoch: 6| Step: 2
Training loss: 3.0125021934509277
Validation loss: 2.528601643859699

Epoch: 6| Step: 3
Training loss: 2.67488431930542
Validation loss: 2.602953146862727

Epoch: 6| Step: 4
Training loss: 3.1077256202697754
Validation loss: 2.6344953249859553

Epoch: 6| Step: 5
Training loss: 2.761320114135742
Validation loss: 2.6166407318525415

Epoch: 6| Step: 6
Training loss: 2.7135586738586426
Validation loss: 2.44600917959726

Epoch: 6| Step: 7
Training loss: 2.2550601959228516
Validation loss: 2.350364802986063

Epoch: 6| Step: 8
Training loss: 2.4912166595458984
Validation loss: 2.33957935917762

Epoch: 6| Step: 9
Training loss: 2.212151527404785
Validation loss: 2.4070177385883946

Epoch: 6| Step: 10
Training loss: 2.2275657653808594
Validation loss: 2.553124525213754

Epoch: 6| Step: 11
Training loss: 3.459906578063965
Validation loss: 2.6312753718386412

Epoch: 6| Step: 12
Training loss: 3.5876731872558594
Validation loss: 2.690114982666508

Epoch: 6| Step: 13
Training loss: 2.5214648246765137
Validation loss: 2.697868667623048

Epoch: 31| Step: 0
Training loss: 3.104792594909668
Validation loss: 2.658770038235572

Epoch: 6| Step: 1
Training loss: 2.908247947692871
Validation loss: 2.62413852958269

Epoch: 6| Step: 2
Training loss: 2.9237682819366455
Validation loss: 2.5334191655599945

Epoch: 6| Step: 3
Training loss: 2.368596315383911
Validation loss: 2.4518042841265277

Epoch: 6| Step: 4
Training loss: 3.1875805854797363
Validation loss: 2.4083653931976645

Epoch: 6| Step: 5
Training loss: 3.160083770751953
Validation loss: 2.3591602694603706

Epoch: 6| Step: 6
Training loss: 3.1071417331695557
Validation loss: 2.3337094604328112

Epoch: 6| Step: 7
Training loss: 2.919595241546631
Validation loss: 2.338196216091033

Epoch: 6| Step: 8
Training loss: 1.665942907333374
Validation loss: 2.3756066547927035

Epoch: 6| Step: 9
Training loss: 2.5606985092163086
Validation loss: 2.461478192319152

Epoch: 6| Step: 10
Training loss: 2.4614291191101074
Validation loss: 2.596647600973806

Epoch: 6| Step: 11
Training loss: 2.1827783584594727
Validation loss: 2.690079435225456

Epoch: 6| Step: 12
Training loss: 3.117997646331787
Validation loss: 2.679467075614519

Epoch: 6| Step: 13
Training loss: 3.063685417175293
Validation loss: 2.574108933889738

Epoch: 32| Step: 0
Training loss: 2.3176164627075195
Validation loss: 2.4615258145075973

Epoch: 6| Step: 1
Training loss: 1.7708548307418823
Validation loss: 2.4024921540291078

Epoch: 6| Step: 2
Training loss: 2.674466609954834
Validation loss: 2.354344608963177

Epoch: 6| Step: 3
Training loss: 3.24684739112854
Validation loss: 2.328670637581938

Epoch: 6| Step: 4
Training loss: 2.557465076446533
Validation loss: 2.325588518573392

Epoch: 6| Step: 5
Training loss: 2.7142128944396973
Validation loss: 2.334539064797022

Epoch: 6| Step: 6
Training loss: 2.656336545944214
Validation loss: 2.3516508686927056

Epoch: 6| Step: 7
Training loss: 3.03682804107666
Validation loss: 2.372234905919721

Epoch: 6| Step: 8
Training loss: 2.649700164794922
Validation loss: 2.381666378308368

Epoch: 6| Step: 9
Training loss: 2.821125030517578
Validation loss: 2.3663140701991257

Epoch: 6| Step: 10
Training loss: 2.859645366668701
Validation loss: 2.352433937852101

Epoch: 6| Step: 11
Training loss: 2.4410653114318848
Validation loss: 2.3502122099681566

Epoch: 6| Step: 12
Training loss: 2.635946273803711
Validation loss: 2.3346846154941026

Epoch: 6| Step: 13
Training loss: 2.2675182819366455
Validation loss: 2.3347897145055954

Epoch: 33| Step: 0
Training loss: 3.242948293685913
Validation loss: 2.3446596284066477

Epoch: 6| Step: 1
Training loss: 2.8220367431640625
Validation loss: 2.371126156981273

Epoch: 6| Step: 2
Training loss: 1.7823095321655273
Validation loss: 2.385938529045351

Epoch: 6| Step: 3
Training loss: 3.161099672317505
Validation loss: 2.401533506249869

Epoch: 6| Step: 4
Training loss: 2.9962995052337646
Validation loss: 2.4271133228014876

Epoch: 6| Step: 5
Training loss: 2.9025135040283203
Validation loss: 2.4448597046636764

Epoch: 6| Step: 6
Training loss: 2.6591153144836426
Validation loss: 2.4134639898935952

Epoch: 6| Step: 7
Training loss: 2.129159688949585
Validation loss: 2.382294249790971

Epoch: 6| Step: 8
Training loss: 2.7045798301696777
Validation loss: 2.3623491961468934

Epoch: 6| Step: 9
Training loss: 2.6050801277160645
Validation loss: 2.341602494639735

Epoch: 6| Step: 10
Training loss: 2.7503294944763184
Validation loss: 2.3376329611706477

Epoch: 6| Step: 11
Training loss: 2.2737388610839844
Validation loss: 2.3221703062775316

Epoch: 6| Step: 12
Training loss: 2.020867347717285
Validation loss: 2.3175189033631356

Epoch: 6| Step: 13
Training loss: 2.582261085510254
Validation loss: 2.3121192762928624

Epoch: 34| Step: 0
Training loss: 2.633146047592163
Validation loss: 2.311625301197011

Epoch: 6| Step: 1
Training loss: 2.4831020832061768
Validation loss: 2.31262033472779

Epoch: 6| Step: 2
Training loss: 2.777902126312256
Validation loss: 2.3138322394381285

Epoch: 6| Step: 3
Training loss: 2.4173178672790527
Validation loss: 2.3113970602712324

Epoch: 6| Step: 4
Training loss: 2.4009547233581543
Validation loss: 2.311089301622042

Epoch: 6| Step: 5
Training loss: 2.3166303634643555
Validation loss: 2.310577254141531

Epoch: 6| Step: 6
Training loss: 2.7009382247924805
Validation loss: 2.3258708933348298

Epoch: 6| Step: 7
Training loss: 2.457458257675171
Validation loss: 2.313151494149239

Epoch: 6| Step: 8
Training loss: 2.0281996726989746
Validation loss: 2.307850137833626

Epoch: 6| Step: 9
Training loss: 2.7295093536376953
Validation loss: 2.3159053684562765

Epoch: 6| Step: 10
Training loss: 2.392145872116089
Validation loss: 2.3286834711669595

Epoch: 6| Step: 11
Training loss: 3.6044692993164062
Validation loss: 2.3530796420189644

Epoch: 6| Step: 12
Training loss: 2.9659271240234375
Validation loss: 2.3939517364707044

Epoch: 6| Step: 13
Training loss: 2.803528070449829
Validation loss: 2.4056709299805346

Epoch: 35| Step: 0
Training loss: 2.5183637142181396
Validation loss: 2.4059724320647535

Epoch: 6| Step: 1
Training loss: 2.8672289848327637
Validation loss: 2.3889810141696723

Epoch: 6| Step: 2
Training loss: 2.951552152633667
Validation loss: 2.364159289226737

Epoch: 6| Step: 3
Training loss: 2.324645519256592
Validation loss: 2.361674847141389

Epoch: 6| Step: 4
Training loss: 2.7801291942596436
Validation loss: 2.3440396606281237

Epoch: 6| Step: 5
Training loss: 2.3807778358459473
Validation loss: 2.33275584508014

Epoch: 6| Step: 6
Training loss: 2.571017026901245
Validation loss: 2.323314262974647

Epoch: 6| Step: 7
Training loss: 2.9617836475372314
Validation loss: 2.3085137003211567

Epoch: 6| Step: 8
Training loss: 1.6628268957138062
Validation loss: 2.306747895415111

Epoch: 6| Step: 9
Training loss: 2.5065438747406006
Validation loss: 2.3062282454582954

Epoch: 6| Step: 10
Training loss: 3.1569809913635254
Validation loss: 2.3211681560803483

Epoch: 6| Step: 11
Training loss: 2.7095937728881836
Validation loss: 2.3202391978233092

Epoch: 6| Step: 12
Training loss: 2.232208251953125
Validation loss: 2.3033828735351562

Epoch: 6| Step: 13
Training loss: 2.800227165222168
Validation loss: 2.29563933034097

Epoch: 36| Step: 0
Training loss: 2.93456768989563
Validation loss: 2.29150939244096

Epoch: 6| Step: 1
Training loss: 2.4136404991149902
Validation loss: 2.2923629976088002

Epoch: 6| Step: 2
Training loss: 2.5547091960906982
Validation loss: 2.2880733859154487

Epoch: 6| Step: 3
Training loss: 1.8325027227401733
Validation loss: 2.2897420570414555

Epoch: 6| Step: 4
Training loss: 3.23140549659729
Validation loss: 2.2858484868080384

Epoch: 6| Step: 5
Training loss: 2.2453527450561523
Validation loss: 2.2868749108365787

Epoch: 6| Step: 6
Training loss: 2.8880209922790527
Validation loss: 2.2867702386712514

Epoch: 6| Step: 7
Training loss: 1.9763903617858887
Validation loss: 2.292199550136443

Epoch: 6| Step: 8
Training loss: 3.0205698013305664
Validation loss: 2.308327659483879

Epoch: 6| Step: 9
Training loss: 3.0207085609436035
Validation loss: 2.3076531297417096

Epoch: 6| Step: 10
Training loss: 2.6519784927368164
Validation loss: 2.291415624721076

Epoch: 6| Step: 11
Training loss: 2.65040922164917
Validation loss: 2.290359661143313

Epoch: 6| Step: 12
Training loss: 2.357530117034912
Validation loss: 2.281648992210306

Epoch: 6| Step: 13
Training loss: 2.3015224933624268
Validation loss: 2.2804431556373514

Epoch: 37| Step: 0
Training loss: 2.6930251121520996
Validation loss: 2.2770343903572328

Epoch: 6| Step: 1
Training loss: 1.9287091493606567
Validation loss: 2.278105092305009

Epoch: 6| Step: 2
Training loss: 1.9712059497833252
Validation loss: 2.281927313855899

Epoch: 6| Step: 3
Training loss: 2.044332981109619
Validation loss: 2.29455154941928

Epoch: 6| Step: 4
Training loss: 2.3183603286743164
Validation loss: 2.3018172889627437

Epoch: 6| Step: 5
Training loss: 2.9656553268432617
Validation loss: 2.307370619107318

Epoch: 6| Step: 6
Training loss: 2.5516042709350586
Validation loss: 2.3060830485436226

Epoch: 6| Step: 7
Training loss: 2.3069071769714355
Validation loss: 2.3062302271525064

Epoch: 6| Step: 8
Training loss: 3.039811849594116
Validation loss: 2.3186634586703394

Epoch: 6| Step: 9
Training loss: 3.151364326477051
Validation loss: 2.3283253292883597

Epoch: 6| Step: 10
Training loss: 2.7308526039123535
Validation loss: 2.329836045542071

Epoch: 6| Step: 11
Training loss: 3.432281970977783
Validation loss: 2.3252750365964827

Epoch: 6| Step: 12
Training loss: 2.3198580741882324
Validation loss: 2.317150741495112

Epoch: 6| Step: 13
Training loss: 2.7249584197998047
Validation loss: 2.3080822703658894

Epoch: 38| Step: 0
Training loss: 2.856593608856201
Validation loss: 2.298501314655427

Epoch: 6| Step: 1
Training loss: 3.123429298400879
Validation loss: 2.28956744106867

Epoch: 6| Step: 2
Training loss: 2.642425537109375
Validation loss: 2.276441084441318

Epoch: 6| Step: 3
Training loss: 2.355510711669922
Validation loss: 2.2751643683320735

Epoch: 6| Step: 4
Training loss: 2.61592698097229
Validation loss: 2.2688302352864254

Epoch: 6| Step: 5
Training loss: 2.366985559463501
Validation loss: 2.268887968473537

Epoch: 6| Step: 6
Training loss: 2.644566535949707
Validation loss: 2.264395071614173

Epoch: 6| Step: 7
Training loss: 2.205990791320801
Validation loss: 2.2691685384319675

Epoch: 6| Step: 8
Training loss: 1.675868272781372
Validation loss: 2.270172239631735

Epoch: 6| Step: 9
Training loss: 3.393044948577881
Validation loss: 2.269248959838703

Epoch: 6| Step: 10
Training loss: 2.9338700771331787
Validation loss: 2.2703282474189677

Epoch: 6| Step: 11
Training loss: 2.540203094482422
Validation loss: 2.2671433982028755

Epoch: 6| Step: 12
Training loss: 2.270965099334717
Validation loss: 2.2694965639422016

Epoch: 6| Step: 13
Training loss: 2.573842763900757
Validation loss: 2.266451386995213

Epoch: 39| Step: 0
Training loss: 2.2009530067443848
Validation loss: 2.2627157318976616

Epoch: 6| Step: 1
Training loss: 3.2163596153259277
Validation loss: 2.258830926751578

Epoch: 6| Step: 2
Training loss: 3.119950771331787
Validation loss: 2.258933323685841

Epoch: 6| Step: 3
Training loss: 3.05942440032959
Validation loss: 2.26278519117704

Epoch: 6| Step: 4
Training loss: 1.6317188739776611
Validation loss: 2.26807653263051

Epoch: 6| Step: 5
Training loss: 2.227753162384033
Validation loss: 2.2725213214915287

Epoch: 6| Step: 6
Training loss: 2.5760791301727295
Validation loss: 2.275795075201219

Epoch: 6| Step: 7
Training loss: 2.2843692302703857
Validation loss: 2.2968070930050266

Epoch: 6| Step: 8
Training loss: 2.5452804565429688
Validation loss: 2.3297817425061296

Epoch: 6| Step: 9
Training loss: 3.3271708488464355
Validation loss: 2.3629880900024087

Epoch: 6| Step: 10
Training loss: 2.6833417415618896
Validation loss: 2.3543279709354525

Epoch: 6| Step: 11
Training loss: 2.740540027618408
Validation loss: 2.3363726062159382

Epoch: 6| Step: 12
Training loss: 2.4386768341064453
Validation loss: 2.3187188435626287

Epoch: 6| Step: 13
Training loss: 1.8239332437515259
Validation loss: 2.314216944479173

Epoch: 40| Step: 0
Training loss: 2.4281063079833984
Validation loss: 2.2973715233546432

Epoch: 6| Step: 1
Training loss: 3.0090255737304688
Validation loss: 2.2973727282657417

Epoch: 6| Step: 2
Training loss: 2.775449752807617
Validation loss: 2.2915234796462522

Epoch: 6| Step: 3
Training loss: 2.058310031890869
Validation loss: 2.297629544811864

Epoch: 6| Step: 4
Training loss: 2.531785488128662
Validation loss: 2.2886208436822377

Epoch: 6| Step: 5
Training loss: 1.9161721467971802
Validation loss: 2.282542303044309

Epoch: 6| Step: 6
Training loss: 2.700026273727417
Validation loss: 2.28378414979545

Epoch: 6| Step: 7
Training loss: 2.5482170581817627
Validation loss: 2.285729951755975

Epoch: 6| Step: 8
Training loss: 2.851623058319092
Validation loss: 2.281225968432683

Epoch: 6| Step: 9
Training loss: 2.044450521469116
Validation loss: 2.2608546544146795

Epoch: 6| Step: 10
Training loss: 3.0624780654907227
Validation loss: 2.2498071539786553

Epoch: 6| Step: 11
Training loss: 2.3284811973571777
Validation loss: 2.250944840010776

Epoch: 6| Step: 12
Training loss: 2.6998045444488525
Validation loss: 2.2538417949471423

Epoch: 6| Step: 13
Training loss: 3.328582763671875
Validation loss: 2.2535500372609785

Epoch: 41| Step: 0
Training loss: 2.514230728149414
Validation loss: 2.257206714281472

Epoch: 6| Step: 1
Training loss: 3.4426746368408203
Validation loss: 2.256037324987432

Epoch: 6| Step: 2
Training loss: 2.337538003921509
Validation loss: 2.2527526988778064

Epoch: 6| Step: 3
Training loss: 2.8894736766815186
Validation loss: 2.2480788794896935

Epoch: 6| Step: 4
Training loss: 2.0630970001220703
Validation loss: 2.2421582680876537

Epoch: 6| Step: 5
Training loss: 3.0166547298431396
Validation loss: 2.241299221592565

Epoch: 6| Step: 6
Training loss: 2.278334617614746
Validation loss: 2.242666115042984

Epoch: 6| Step: 7
Training loss: 2.860287666320801
Validation loss: 2.2594164238181165

Epoch: 6| Step: 8
Training loss: 2.257988929748535
Validation loss: 2.2790438129055883

Epoch: 6| Step: 9
Training loss: 2.431684732437134
Validation loss: 2.3275909628919376

Epoch: 6| Step: 10
Training loss: 2.1404221057891846
Validation loss: 2.425333587072229

Epoch: 6| Step: 11
Training loss: 2.9501278400421143
Validation loss: 2.48220423729189

Epoch: 6| Step: 12
Training loss: 2.8587276935577393
Validation loss: 2.520348810380505

Epoch: 6| Step: 13
Training loss: 2.0561649799346924
Validation loss: 2.4764779357499975

Epoch: 42| Step: 0
Training loss: 2.8847107887268066
Validation loss: 2.4105980011724655

Epoch: 6| Step: 1
Training loss: 2.176927089691162
Validation loss: 2.3276823207896244

Epoch: 6| Step: 2
Training loss: 2.008718490600586
Validation loss: 2.286786671607725

Epoch: 6| Step: 3
Training loss: 2.462021827697754
Validation loss: 2.2658448219299316

Epoch: 6| Step: 4
Training loss: 2.5910611152648926
Validation loss: 2.27325253845543

Epoch: 6| Step: 5
Training loss: 2.206714630126953
Validation loss: 2.2946962054057787

Epoch: 6| Step: 6
Training loss: 3.332773208618164
Validation loss: 2.368536289020251

Epoch: 6| Step: 7
Training loss: 2.818138599395752
Validation loss: 2.4414852870407926

Epoch: 6| Step: 8
Training loss: 2.297433376312256
Validation loss: 2.604944905927104

Epoch: 6| Step: 9
Training loss: 3.203763008117676
Validation loss: 2.577389206937564

Epoch: 6| Step: 10
Training loss: 2.4238228797912598
Validation loss: 2.5083462807439987

Epoch: 6| Step: 11
Training loss: 2.3870272636413574
Validation loss: 2.4886453331157727

Epoch: 6| Step: 12
Training loss: 3.433302164077759
Validation loss: 2.4683902263641357

Epoch: 6| Step: 13
Training loss: 2.59560489654541
Validation loss: 2.4600647188002065

Epoch: 43| Step: 0
Training loss: 1.9225287437438965
Validation loss: 2.4434702498938448

Epoch: 6| Step: 1
Training loss: 3.3617734909057617
Validation loss: 2.4377206884404665

Epoch: 6| Step: 2
Training loss: 2.7770650386810303
Validation loss: 2.4350183958648355

Epoch: 6| Step: 3
Training loss: 2.868095636367798
Validation loss: 2.4323248427401305

Epoch: 6| Step: 4
Training loss: 2.458024263381958
Validation loss: 2.4296458459669545

Epoch: 6| Step: 5
Training loss: 2.9454057216644287
Validation loss: 2.439434120731969

Epoch: 6| Step: 6
Training loss: 2.4079174995422363
Validation loss: 2.4303983590936147

Epoch: 6| Step: 7
Training loss: 1.9172143936157227
Validation loss: 2.431242589027651

Epoch: 6| Step: 8
Training loss: 3.1542868614196777
Validation loss: 2.396927223410658

Epoch: 6| Step: 9
Training loss: 2.6434926986694336
Validation loss: 2.363332848395071

Epoch: 6| Step: 10
Training loss: 2.4605867862701416
Validation loss: 2.341938372581236

Epoch: 6| Step: 11
Training loss: 2.47945499420166
Validation loss: 2.3688283274250646

Epoch: 6| Step: 12
Training loss: 3.2158100605010986
Validation loss: 2.3903681590992916

Epoch: 6| Step: 13
Training loss: 1.9142377376556396
Validation loss: 2.375509072375554

Epoch: 44| Step: 0
Training loss: 3.3563332557678223
Validation loss: 2.4123260539065123

Epoch: 6| Step: 1
Training loss: 2.7699270248413086
Validation loss: 2.4157789932784213

Epoch: 6| Step: 2
Training loss: 2.343456983566284
Validation loss: 2.376820610415551

Epoch: 6| Step: 3
Training loss: 2.392202377319336
Validation loss: 2.351027860436388

Epoch: 6| Step: 4
Training loss: 1.934112310409546
Validation loss: 2.3157040944663425

Epoch: 6| Step: 5
Training loss: 1.7461471557617188
Validation loss: 2.275100128625029

Epoch: 6| Step: 6
Training loss: 2.939152956008911
Validation loss: 2.2727631292035504

Epoch: 6| Step: 7
Training loss: 3.331871509552002
Validation loss: 2.2673238118489585

Epoch: 6| Step: 8
Training loss: 2.311086654663086
Validation loss: 2.2518246302040676

Epoch: 6| Step: 9
Training loss: 2.5911507606506348
Validation loss: 2.238798467061853

Epoch: 6| Step: 10
Training loss: 2.5921802520751953
Validation loss: 2.2320243620103404

Epoch: 6| Step: 11
Training loss: 2.6571149826049805
Validation loss: 2.2333968864974154

Epoch: 6| Step: 12
Training loss: 2.774125576019287
Validation loss: 2.2335170571522047

Epoch: 6| Step: 13
Training loss: 2.2808005809783936
Validation loss: 2.22926414397455

Epoch: 45| Step: 0
Training loss: 2.4833834171295166
Validation loss: 2.232546279507299

Epoch: 6| Step: 1
Training loss: 3.15830135345459
Validation loss: 2.22846895135859

Epoch: 6| Step: 2
Training loss: 2.684957504272461
Validation loss: 2.2297834516853414

Epoch: 6| Step: 3
Training loss: 2.93080472946167
Validation loss: 2.2221539533266457

Epoch: 6| Step: 4
Training loss: 2.2241616249084473
Validation loss: 2.2209278075925765

Epoch: 6| Step: 5
Training loss: 2.72768235206604
Validation loss: 2.227837319015175

Epoch: 6| Step: 6
Training loss: 2.2814791202545166
Validation loss: 2.231785443521315

Epoch: 6| Step: 7
Training loss: 2.0380496978759766
Validation loss: 2.255749522998769

Epoch: 6| Step: 8
Training loss: 2.6973061561584473
Validation loss: 2.281517421045611

Epoch: 6| Step: 9
Training loss: 2.9725561141967773
Validation loss: 2.3086390341481855

Epoch: 6| Step: 10
Training loss: 2.4137158393859863
Validation loss: 2.3439616913436563

Epoch: 6| Step: 11
Training loss: 2.292696475982666
Validation loss: 2.383122886380842

Epoch: 6| Step: 12
Training loss: 2.599933624267578
Validation loss: 2.4022464111287105

Epoch: 6| Step: 13
Training loss: 2.137988328933716
Validation loss: 2.40259620194794

Epoch: 46| Step: 0
Training loss: 2.381453514099121
Validation loss: 2.414864627263879

Epoch: 6| Step: 1
Training loss: 2.30564546585083
Validation loss: 2.406438619859757

Epoch: 6| Step: 2
Training loss: 2.8751611709594727
Validation loss: 2.3943197740021573

Epoch: 6| Step: 3
Training loss: 2.9644737243652344
Validation loss: 2.3705988622480825

Epoch: 6| Step: 4
Training loss: 3.32127046585083
Validation loss: 2.328666728029969

Epoch: 6| Step: 5
Training loss: 2.1478476524353027
Validation loss: 2.2797415282136653

Epoch: 6| Step: 6
Training loss: 2.6397366523742676
Validation loss: 2.288302178023964

Epoch: 6| Step: 7
Training loss: 2.417738437652588
Validation loss: 2.281936896744595

Epoch: 6| Step: 8
Training loss: 2.7406275272369385
Validation loss: 2.2681071322451354

Epoch: 6| Step: 9
Training loss: 2.2612829208374023
Validation loss: 2.250575242503997

Epoch: 6| Step: 10
Training loss: 2.7943131923675537
Validation loss: 2.2439044983156267

Epoch: 6| Step: 11
Training loss: 2.563525438308716
Validation loss: 2.241383373096425

Epoch: 6| Step: 12
Training loss: 2.306234359741211
Validation loss: 2.2380448413151566

Epoch: 6| Step: 13
Training loss: 1.9783270359039307
Validation loss: 2.249952306029617

Epoch: 47| Step: 0
Training loss: 2.654184103012085
Validation loss: 2.2615678900031635

Epoch: 6| Step: 1
Training loss: 2.251771926879883
Validation loss: 2.273068730549146

Epoch: 6| Step: 2
Training loss: 1.9853858947753906
Validation loss: 2.2731078363234

Epoch: 6| Step: 3
Training loss: 2.6580801010131836
Validation loss: 2.287184912671325

Epoch: 6| Step: 4
Training loss: 1.989849328994751
Validation loss: 2.284290071456663

Epoch: 6| Step: 5
Training loss: 2.542315721511841
Validation loss: 2.3297993957355456

Epoch: 6| Step: 6
Training loss: 2.389559745788574
Validation loss: 2.329865473572926

Epoch: 6| Step: 7
Training loss: 2.307549476623535
Validation loss: 2.328550200308523

Epoch: 6| Step: 8
Training loss: 3.079570770263672
Validation loss: 2.341132169128746

Epoch: 6| Step: 9
Training loss: 3.251021385192871
Validation loss: 2.308314561843872

Epoch: 6| Step: 10
Training loss: 2.0400586128234863
Validation loss: 2.271914118079729

Epoch: 6| Step: 11
Training loss: 3.0720221996307373
Validation loss: 2.2389442510502313

Epoch: 6| Step: 12
Training loss: 2.566248655319214
Validation loss: 2.2191778536765807

Epoch: 6| Step: 13
Training loss: 3.1024982929229736
Validation loss: 2.2052653835665796

Epoch: 48| Step: 0
Training loss: 2.7314891815185547
Validation loss: 2.210749227513549

Epoch: 6| Step: 1
Training loss: 2.7006750106811523
Validation loss: 2.2088944271046627

Epoch: 6| Step: 2
Training loss: 2.581904649734497
Validation loss: 2.204404572004913

Epoch: 6| Step: 3
Training loss: 2.9482228755950928
Validation loss: 2.203048609918164

Epoch: 6| Step: 4
Training loss: 2.0613791942596436
Validation loss: 2.1953822899890203

Epoch: 6| Step: 5
Training loss: 2.0029094219207764
Validation loss: 2.193439696424751

Epoch: 6| Step: 6
Training loss: 3.262396812438965
Validation loss: 2.1877819825244207

Epoch: 6| Step: 7
Training loss: 2.851835250854492
Validation loss: 2.185483201857536

Epoch: 6| Step: 8
Training loss: 2.1349902153015137
Validation loss: 2.192477495439591

Epoch: 6| Step: 9
Training loss: 1.982132911682129
Validation loss: 2.206543955751645

Epoch: 6| Step: 10
Training loss: 3.410520553588867
Validation loss: 2.2235039536670973

Epoch: 6| Step: 11
Training loss: 2.6294898986816406
Validation loss: 2.232672796454481

Epoch: 6| Step: 12
Training loss: 1.5647368431091309
Validation loss: 2.249474033232658

Epoch: 6| Step: 13
Training loss: 2.747180938720703
Validation loss: 2.2570818111460698

Epoch: 49| Step: 0
Training loss: 2.4864249229431152
Validation loss: 2.272957122454079

Epoch: 6| Step: 1
Training loss: 2.9663257598876953
Validation loss: 2.269056781645744

Epoch: 6| Step: 2
Training loss: 1.7106947898864746
Validation loss: 2.2728867735914005

Epoch: 6| Step: 3
Training loss: 2.6616334915161133
Validation loss: 2.26976445926133

Epoch: 6| Step: 4
Training loss: 2.8344407081604004
Validation loss: 2.2498913580371487

Epoch: 6| Step: 5
Training loss: 2.1911368370056152
Validation loss: 2.2296784257376068

Epoch: 6| Step: 6
Training loss: 1.4700417518615723
Validation loss: 2.2104073262983754

Epoch: 6| Step: 7
Training loss: 3.0055172443389893
Validation loss: 2.2032406227563017

Epoch: 6| Step: 8
Training loss: 1.7044185400009155
Validation loss: 2.193359439091016

Epoch: 6| Step: 9
Training loss: 3.6097075939178467
Validation loss: 2.1868457486552577

Epoch: 6| Step: 10
Training loss: 2.312325954437256
Validation loss: 2.1830984597565024

Epoch: 6| Step: 11
Training loss: 3.256171226501465
Validation loss: 2.1793086759505735

Epoch: 6| Step: 12
Training loss: 2.6356003284454346
Validation loss: 2.1775365849976898

Epoch: 6| Step: 13
Training loss: 2.659754514694214
Validation loss: 2.1804444789886475

Epoch: 50| Step: 0
Training loss: 2.752284049987793
Validation loss: 2.179381591017528

Epoch: 6| Step: 1
Training loss: 2.4529006481170654
Validation loss: 2.1759950217380317

Epoch: 6| Step: 2
Training loss: 2.8088788986206055
Validation loss: 2.1735049704069733

Epoch: 6| Step: 3
Training loss: 2.363234519958496
Validation loss: 2.18025718709474

Epoch: 6| Step: 4
Training loss: 2.8546841144561768
Validation loss: 2.1801227395252516

Epoch: 6| Step: 5
Training loss: 2.4577436447143555
Validation loss: 2.1838240033836773

Epoch: 6| Step: 6
Training loss: 2.0705347061157227
Validation loss: 2.184511894820839

Epoch: 6| Step: 7
Training loss: 2.222045421600342
Validation loss: 2.1815649591466433

Epoch: 6| Step: 8
Training loss: 2.474613904953003
Validation loss: 2.1838647165606098

Epoch: 6| Step: 9
Training loss: 2.857835531234741
Validation loss: 2.1893912002604496

Epoch: 6| Step: 10
Training loss: 2.772829532623291
Validation loss: 2.1970114220855055

Epoch: 6| Step: 11
Training loss: 2.553988218307495
Validation loss: 2.23063765546327

Epoch: 6| Step: 12
Training loss: 2.3037424087524414
Validation loss: 2.2010037463198424

Epoch: 6| Step: 13
Training loss: 2.231612205505371
Validation loss: 2.1846126035977433

Epoch: 51| Step: 0
Training loss: 2.0739800930023193
Validation loss: 2.1899517761763705

Epoch: 6| Step: 1
Training loss: 2.5089097023010254
Validation loss: 2.211515103617022

Epoch: 6| Step: 2
Training loss: 2.5076441764831543
Validation loss: 2.21322621837739

Epoch: 6| Step: 3
Training loss: 2.6571927070617676
Validation loss: 2.219034666656166

Epoch: 6| Step: 4
Training loss: 2.56428861618042
Validation loss: 2.218082733051751

Epoch: 6| Step: 5
Training loss: 2.286623239517212
Validation loss: 2.2189085406641804

Epoch: 6| Step: 6
Training loss: 2.279215097427368
Validation loss: 2.2280290049891316

Epoch: 6| Step: 7
Training loss: 3.2797491550445557
Validation loss: 2.2185322238552954

Epoch: 6| Step: 8
Training loss: 2.8709535598754883
Validation loss: 2.2418344431026007

Epoch: 6| Step: 9
Training loss: 2.6574158668518066
Validation loss: 2.2529519450279976

Epoch: 6| Step: 10
Training loss: 2.3047873973846436
Validation loss: 2.281351327896118

Epoch: 6| Step: 11
Training loss: 2.312828779220581
Validation loss: 2.309343986613776

Epoch: 6| Step: 12
Training loss: 2.6915338039398193
Validation loss: 2.3497003688607165

Epoch: 6| Step: 13
Training loss: 1.8820770978927612
Validation loss: 2.3811642457080144

Epoch: 52| Step: 0
Training loss: 2.4551849365234375
Validation loss: 2.3809174312058317

Epoch: 6| Step: 1
Training loss: 2.6594557762145996
Validation loss: 2.3667710263242006

Epoch: 6| Step: 2
Training loss: 3.0758767127990723
Validation loss: 2.290129312904932

Epoch: 6| Step: 3
Training loss: 2.3880629539489746
Validation loss: 2.2574256517553843

Epoch: 6| Step: 4
Training loss: 2.8002986907958984
Validation loss: 2.242688294379942

Epoch: 6| Step: 5
Training loss: 2.740090847015381
Validation loss: 2.234093717349473

Epoch: 6| Step: 6
Training loss: 2.3470780849456787
Validation loss: 2.2282349678777877

Epoch: 6| Step: 7
Training loss: 2.400136947631836
Validation loss: 2.225456222411125

Epoch: 6| Step: 8
Training loss: 2.3463425636291504
Validation loss: 2.237259428988221

Epoch: 6| Step: 9
Training loss: 2.3082733154296875
Validation loss: 2.244231424024028

Epoch: 6| Step: 10
Training loss: 2.6113967895507812
Validation loss: 2.244963909990044

Epoch: 6| Step: 11
Training loss: 2.7223291397094727
Validation loss: 2.2425748148272113

Epoch: 6| Step: 12
Training loss: 2.4899351596832275
Validation loss: 2.240163351899834

Epoch: 6| Step: 13
Training loss: 1.89705228805542
Validation loss: 2.2388341375576553

Epoch: 53| Step: 0
Training loss: 1.8428349494934082
Validation loss: 2.2427159022259455

Epoch: 6| Step: 1
Training loss: 2.7925968170166016
Validation loss: 2.2427999691296647

Epoch: 6| Step: 2
Training loss: 2.9572503566741943
Validation loss: 2.2418905124869397

Epoch: 6| Step: 3
Training loss: 1.6648757457733154
Validation loss: 2.219663150848881

Epoch: 6| Step: 4
Training loss: 2.0959649085998535
Validation loss: 2.2426109083237185

Epoch: 6| Step: 5
Training loss: 3.572274684906006
Validation loss: 2.2407023393979637

Epoch: 6| Step: 6
Training loss: 2.0740575790405273
Validation loss: 2.2390321249602945

Epoch: 6| Step: 7
Training loss: 2.9837827682495117
Validation loss: 2.221558993862521

Epoch: 6| Step: 8
Training loss: 2.4492573738098145
Validation loss: 2.213759467165957

Epoch: 6| Step: 9
Training loss: 3.1332242488861084
Validation loss: 2.1959451244723414

Epoch: 6| Step: 10
Training loss: 2.458704948425293
Validation loss: 2.179358496460863

Epoch: 6| Step: 11
Training loss: 2.4836390018463135
Validation loss: 2.1764676365801083

Epoch: 6| Step: 12
Training loss: 2.1800286769866943
Validation loss: 2.1856292883555093

Epoch: 6| Step: 13
Training loss: 2.3680505752563477
Validation loss: 2.184421075287686

Epoch: 54| Step: 0
Training loss: 2.834871292114258
Validation loss: 2.199743224728492

Epoch: 6| Step: 1
Training loss: 2.25358247756958
Validation loss: 2.195685012366182

Epoch: 6| Step: 2
Training loss: 2.469534397125244
Validation loss: 2.191071997406662

Epoch: 6| Step: 3
Training loss: 2.2323784828186035
Validation loss: 2.1765891710917153

Epoch: 6| Step: 4
Training loss: 2.019254207611084
Validation loss: 2.1691469889815136

Epoch: 6| Step: 5
Training loss: 3.1762592792510986
Validation loss: 2.162875049857683

Epoch: 6| Step: 6
Training loss: 2.035832405090332
Validation loss: 2.1588888860517934

Epoch: 6| Step: 7
Training loss: 2.8715028762817383
Validation loss: 2.1521395560233825

Epoch: 6| Step: 8
Training loss: 2.660210609436035
Validation loss: 2.149856144382108

Epoch: 6| Step: 9
Training loss: 2.915292978286743
Validation loss: 2.1476863263755717

Epoch: 6| Step: 10
Training loss: 1.5760424137115479
Validation loss: 2.1520076515854045

Epoch: 6| Step: 11
Training loss: 2.1696653366088867
Validation loss: 2.1520442039735856

Epoch: 6| Step: 12
Training loss: 2.6582984924316406
Validation loss: 2.1579522907093005

Epoch: 6| Step: 13
Training loss: 3.542137622833252
Validation loss: 2.184562531850671

Epoch: 55| Step: 0
Training loss: 2.6617701053619385
Validation loss: 2.201340224153252

Epoch: 6| Step: 1
Training loss: 2.1978936195373535
Validation loss: 2.2091800922988565

Epoch: 6| Step: 2
Training loss: 2.6457223892211914
Validation loss: 2.2179582324079288

Epoch: 6| Step: 3
Training loss: 3.236692428588867
Validation loss: 2.2197100398361043

Epoch: 6| Step: 4
Training loss: 2.6861181259155273
Validation loss: 2.207050568314009

Epoch: 6| Step: 5
Training loss: 2.150041103363037
Validation loss: 2.2028964719464703

Epoch: 6| Step: 6
Training loss: 3.0039868354797363
Validation loss: 2.1928553991420294

Epoch: 6| Step: 7
Training loss: 2.728814125061035
Validation loss: 2.194147894459386

Epoch: 6| Step: 8
Training loss: 1.587146520614624
Validation loss: 2.184703855104344

Epoch: 6| Step: 9
Training loss: 2.5409226417541504
Validation loss: 2.17703414476046

Epoch: 6| Step: 10
Training loss: 2.189298391342163
Validation loss: 2.162021211398545

Epoch: 6| Step: 11
Training loss: 2.700531482696533
Validation loss: 2.150690932427683

Epoch: 6| Step: 12
Training loss: 2.707054376602173
Validation loss: 2.1411649027178363

Epoch: 6| Step: 13
Training loss: 1.4028890132904053
Validation loss: 2.1464795489465036

Epoch: 56| Step: 0
Training loss: 2.916288375854492
Validation loss: 2.1520136607590543

Epoch: 6| Step: 1
Training loss: 2.7146754264831543
Validation loss: 2.1428271826877388

Epoch: 6| Step: 2
Training loss: 2.6077816486358643
Validation loss: 2.138031659587737

Epoch: 6| Step: 3
Training loss: 2.5092806816101074
Validation loss: 2.135303266586796

Epoch: 6| Step: 4
Training loss: 2.5878026485443115
Validation loss: 2.132705580803656

Epoch: 6| Step: 5
Training loss: 2.429372787475586
Validation loss: 2.1312665208693473

Epoch: 6| Step: 6
Training loss: 2.9684157371520996
Validation loss: 2.131290284536218

Epoch: 6| Step: 7
Training loss: 2.2584080696105957
Validation loss: 2.1307876904805503

Epoch: 6| Step: 8
Training loss: 1.609601616859436
Validation loss: 2.131890812227803

Epoch: 6| Step: 9
Training loss: 2.6706910133361816
Validation loss: 2.1335963510697886

Epoch: 6| Step: 10
Training loss: 2.388223886489868
Validation loss: 2.1345308019268896

Epoch: 6| Step: 11
Training loss: 2.1522018909454346
Validation loss: 2.137338812633227

Epoch: 6| Step: 12
Training loss: 2.4544901847839355
Validation loss: 2.1452276501604306

Epoch: 6| Step: 13
Training loss: 2.587228775024414
Validation loss: 2.1527039004910375

Epoch: 57| Step: 0
Training loss: 2.2148475646972656
Validation loss: 2.1600271732576433

Epoch: 6| Step: 1
Training loss: 3.062777042388916
Validation loss: 2.163330010188523

Epoch: 6| Step: 2
Training loss: 2.7208056449890137
Validation loss: 2.171316490378431

Epoch: 6| Step: 3
Training loss: 2.4571328163146973
Validation loss: 2.176857336874931

Epoch: 6| Step: 4
Training loss: 1.9878222942352295
Validation loss: 2.1862545423610236

Epoch: 6| Step: 5
Training loss: 1.7587387561798096
Validation loss: 2.17621797643682

Epoch: 6| Step: 6
Training loss: 2.3947606086730957
Validation loss: 2.1683752152227584

Epoch: 6| Step: 7
Training loss: 2.8169662952423096
Validation loss: 2.1534336587434173

Epoch: 6| Step: 8
Training loss: 2.2350034713745117
Validation loss: 2.1326492512097923

Epoch: 6| Step: 9
Training loss: 2.894437313079834
Validation loss: 2.128616658590173

Epoch: 6| Step: 10
Training loss: 2.4816575050354004
Validation loss: 2.130083340470509

Epoch: 6| Step: 11
Training loss: 2.6358084678649902
Validation loss: 2.1318044816294024

Epoch: 6| Step: 12
Training loss: 2.388653039932251
Validation loss: 2.137296733035836

Epoch: 6| Step: 13
Training loss: 2.8172965049743652
Validation loss: 2.1450275439088062

Epoch: 58| Step: 0
Training loss: 2.3752665519714355
Validation loss: 2.161543861512215

Epoch: 6| Step: 1
Training loss: 2.2792797088623047
Validation loss: 2.179899905317573

Epoch: 6| Step: 2
Training loss: 2.5206618309020996
Validation loss: 2.191111344163136

Epoch: 6| Step: 3
Training loss: 1.8878180980682373
Validation loss: 2.2449553756303686

Epoch: 6| Step: 4
Training loss: 1.8533995151519775
Validation loss: 2.309644978533509

Epoch: 6| Step: 5
Training loss: 2.830251693725586
Validation loss: 2.2763136740653747

Epoch: 6| Step: 6
Training loss: 3.2210946083068848
Validation loss: 2.196258993558986

Epoch: 6| Step: 7
Training loss: 2.6335105895996094
Validation loss: 2.161437929317515

Epoch: 6| Step: 8
Training loss: 2.7839698791503906
Validation loss: 2.128815325357581

Epoch: 6| Step: 9
Training loss: 2.5169639587402344
Validation loss: 2.1217446378482285

Epoch: 6| Step: 10
Training loss: 2.6637284755706787
Validation loss: 2.1214010048938055

Epoch: 6| Step: 11
Training loss: 2.6788330078125
Validation loss: 2.130649951196486

Epoch: 6| Step: 12
Training loss: 2.191854238510132
Validation loss: 2.141058935913988

Epoch: 6| Step: 13
Training loss: 2.6477644443511963
Validation loss: 2.151004991223735

Epoch: 59| Step: 0
Training loss: 2.062469959259033
Validation loss: 2.165218109725624

Epoch: 6| Step: 1
Training loss: 2.610403299331665
Validation loss: 2.1689465866293958

Epoch: 6| Step: 2
Training loss: 2.8657689094543457
Validation loss: 2.1736719249397196

Epoch: 6| Step: 3
Training loss: 3.1992151737213135
Validation loss: 2.176121178493705

Epoch: 6| Step: 4
Training loss: 2.3023104667663574
Validation loss: 2.1694586456462903

Epoch: 6| Step: 5
Training loss: 2.770385980606079
Validation loss: 2.169330789196876

Epoch: 6| Step: 6
Training loss: 1.6093997955322266
Validation loss: 2.157837301172236

Epoch: 6| Step: 7
Training loss: 1.9343085289001465
Validation loss: 2.1454031031618834

Epoch: 6| Step: 8
Training loss: 2.0817630290985107
Validation loss: 2.1483118252087663

Epoch: 6| Step: 9
Training loss: 2.9830641746520996
Validation loss: 2.138945353928433

Epoch: 6| Step: 10
Training loss: 2.960655450820923
Validation loss: 2.1293478832449964

Epoch: 6| Step: 11
Training loss: 3.057574987411499
Validation loss: 2.1362347269570954

Epoch: 6| Step: 12
Training loss: 2.0166780948638916
Validation loss: 2.1481905009156916

Epoch: 6| Step: 13
Training loss: 2.7670464515686035
Validation loss: 2.1650038996050434

Epoch: 60| Step: 0
Training loss: 3.029188632965088
Validation loss: 2.1939218249372257

Epoch: 6| Step: 1
Training loss: 1.9941750764846802
Validation loss: 2.2244502728985203

Epoch: 6| Step: 2
Training loss: 2.4986090660095215
Validation loss: 2.2596264628953833

Epoch: 6| Step: 3
Training loss: 2.223799228668213
Validation loss: 2.2609960315048054

Epoch: 6| Step: 4
Training loss: 3.231674909591675
Validation loss: 2.2736895494563605

Epoch: 6| Step: 5
Training loss: 2.84848952293396
Validation loss: 2.2701702733193674

Epoch: 6| Step: 6
Training loss: 2.3176870346069336
Validation loss: 2.235836341816892

Epoch: 6| Step: 7
Training loss: 2.1921262741088867
Validation loss: 2.190240801021617

Epoch: 6| Step: 8
Training loss: 2.0792641639709473
Validation loss: 2.1349864134224514

Epoch: 6| Step: 9
Training loss: 2.189939022064209
Validation loss: 2.1143084982390046

Epoch: 6| Step: 10
Training loss: 2.439175844192505
Validation loss: 2.104831700683922

Epoch: 6| Step: 11
Training loss: 2.962326765060425
Validation loss: 2.1015502906614736

Epoch: 6| Step: 12
Training loss: 2.550665855407715
Validation loss: 2.1021951372905443

Epoch: 6| Step: 13
Training loss: 2.116563558578491
Validation loss: 2.098814918148902

Epoch: 61| Step: 0
Training loss: 2.7548775672912598
Validation loss: 2.1026935295392106

Epoch: 6| Step: 1
Training loss: 2.53265380859375
Validation loss: 2.100751884521977

Epoch: 6| Step: 2
Training loss: 2.4130046367645264
Validation loss: 2.1025137516760055

Epoch: 6| Step: 3
Training loss: 1.9970145225524902
Validation loss: 2.1062579770242014

Epoch: 6| Step: 4
Training loss: 1.9959832429885864
Validation loss: 2.1114002286746936

Epoch: 6| Step: 5
Training loss: 2.669753313064575
Validation loss: 2.10370373213163

Epoch: 6| Step: 6
Training loss: 1.886218547821045
Validation loss: 2.1055474691493536

Epoch: 6| Step: 7
Training loss: 2.4824748039245605
Validation loss: 2.1075434146388883

Epoch: 6| Step: 8
Training loss: 2.1550827026367188
Validation loss: 2.116407923800971

Epoch: 6| Step: 9
Training loss: 2.805997133255005
Validation loss: 2.124558666700958

Epoch: 6| Step: 10
Training loss: 3.4603044986724854
Validation loss: 2.130907186897852

Epoch: 6| Step: 11
Training loss: 2.1651086807250977
Validation loss: 2.141646385192871

Epoch: 6| Step: 12
Training loss: 2.5485148429870605
Validation loss: 2.1420473001336537

Epoch: 6| Step: 13
Training loss: 2.7791197299957275
Validation loss: 2.1411652052274315

Epoch: 62| Step: 0
Training loss: 2.487027168273926
Validation loss: 2.1228701722237373

Epoch: 6| Step: 1
Training loss: 2.9847986698150635
Validation loss: 2.1206740410097185

Epoch: 6| Step: 2
Training loss: 2.0365185737609863
Validation loss: 2.10581394421157

Epoch: 6| Step: 3
Training loss: 2.380303382873535
Validation loss: 2.1023533677542083

Epoch: 6| Step: 4
Training loss: 2.862931489944458
Validation loss: 2.0987854337179535

Epoch: 6| Step: 5
Training loss: 2.081244945526123
Validation loss: 2.096875285589567

Epoch: 6| Step: 6
Training loss: 2.485551357269287
Validation loss: 2.0907725826386483

Epoch: 6| Step: 7
Training loss: 1.7934361696243286
Validation loss: 2.090582659167628

Epoch: 6| Step: 8
Training loss: 2.452317476272583
Validation loss: 2.088533100261483

Epoch: 6| Step: 9
Training loss: 2.2686767578125
Validation loss: 2.089953876310779

Epoch: 6| Step: 10
Training loss: 2.681379795074463
Validation loss: 2.088398523228143

Epoch: 6| Step: 11
Training loss: 2.7229678630828857
Validation loss: 2.0922410975220385

Epoch: 6| Step: 12
Training loss: 3.1436920166015625
Validation loss: 2.0919107378170056

Epoch: 6| Step: 13
Training loss: 1.599902629852295
Validation loss: 2.098655600701609

Epoch: 63| Step: 0
Training loss: 1.9896982908248901
Validation loss: 2.1407467690847253

Epoch: 6| Step: 1
Training loss: 2.5436172485351562
Validation loss: 2.1777186957738732

Epoch: 6| Step: 2
Training loss: 2.350602626800537
Validation loss: 2.221307703243789

Epoch: 6| Step: 3
Training loss: 1.993583083152771
Validation loss: 2.208397170548798

Epoch: 6| Step: 4
Training loss: 2.970776319503784
Validation loss: 2.1883188447644635

Epoch: 6| Step: 5
Training loss: 3.10009765625
Validation loss: 2.156187088258805

Epoch: 6| Step: 6
Training loss: 2.406338930130005
Validation loss: 2.1317855183796217

Epoch: 6| Step: 7
Training loss: 2.9327235221862793
Validation loss: 2.10835930865298

Epoch: 6| Step: 8
Training loss: 2.3058648109436035
Validation loss: 2.089731761204299

Epoch: 6| Step: 9
Training loss: 2.197033405303955
Validation loss: 2.084581308467414

Epoch: 6| Step: 10
Training loss: 2.0104691982269287
Validation loss: 2.0894486570871003

Epoch: 6| Step: 11
Training loss: 2.5497047901153564
Validation loss: 2.09623690958946

Epoch: 6| Step: 12
Training loss: 2.64894437789917
Validation loss: 2.103699440597206

Epoch: 6| Step: 13
Training loss: 2.826341152191162
Validation loss: 2.1201862686423847

Epoch: 64| Step: 0
Training loss: 2.4710183143615723
Validation loss: 2.140539412857384

Epoch: 6| Step: 1
Training loss: 2.6291937828063965
Validation loss: 2.1652995629977156

Epoch: 6| Step: 2
Training loss: 2.693006753921509
Validation loss: 2.193777166387086

Epoch: 6| Step: 3
Training loss: 2.7942817211151123
Validation loss: 2.2658822972287416

Epoch: 6| Step: 4
Training loss: 2.402869462966919
Validation loss: 2.278431968022418

Epoch: 6| Step: 5
Training loss: 2.153843402862549
Validation loss: 2.2831106391004337

Epoch: 6| Step: 6
Training loss: 1.938751459121704
Validation loss: 2.218593784557876

Epoch: 6| Step: 7
Training loss: 2.8166141510009766
Validation loss: 2.178808955736058

Epoch: 6| Step: 8
Training loss: 2.5021018981933594
Validation loss: 2.1460027925429808

Epoch: 6| Step: 9
Training loss: 1.9586617946624756
Validation loss: 2.1866169642376643

Epoch: 6| Step: 10
Training loss: 2.80000901222229
Validation loss: 2.183862946366751

Epoch: 6| Step: 11
Training loss: 2.7540369033813477
Validation loss: 2.1971192590651976

Epoch: 6| Step: 12
Training loss: 3.0346014499664307
Validation loss: 2.221837041198566

Epoch: 6| Step: 13
Training loss: 2.153625726699829
Validation loss: 2.2488311747069

Epoch: 65| Step: 0
Training loss: 2.355388879776001
Validation loss: 2.2453697317390033

Epoch: 6| Step: 1
Training loss: 2.472578763961792
Validation loss: 2.2229096761313816

Epoch: 6| Step: 2
Training loss: 2.651599407196045
Validation loss: 2.2291735449144916

Epoch: 6| Step: 3
Training loss: 2.3029677867889404
Validation loss: 2.223785461918

Epoch: 6| Step: 4
Training loss: 2.66856050491333
Validation loss: 2.2471894602621756

Epoch: 6| Step: 5
Training loss: 2.9611189365386963
Validation loss: 2.2624280439910067

Epoch: 6| Step: 6
Training loss: 2.646350622177124
Validation loss: 2.223889648273427

Epoch: 6| Step: 7
Training loss: 1.9483932256698608
Validation loss: 2.1916738787005023

Epoch: 6| Step: 8
Training loss: 2.3638107776641846
Validation loss: 2.1543545646052205

Epoch: 6| Step: 9
Training loss: 3.121232509613037
Validation loss: 2.121966938818655

Epoch: 6| Step: 10
Training loss: 2.2221975326538086
Validation loss: 2.1068955211229223

Epoch: 6| Step: 11
Training loss: 2.2555627822875977
Validation loss: 2.094030604567579

Epoch: 6| Step: 12
Training loss: 2.8122472763061523
Validation loss: 2.0913527447690248

Epoch: 6| Step: 13
Training loss: 1.7430239915847778
Validation loss: 2.1000182910632064

Epoch: 66| Step: 0
Training loss: 2.129991054534912
Validation loss: 2.095401197351435

Epoch: 6| Step: 1
Training loss: 3.0022077560424805
Validation loss: 2.0952675573287474

Epoch: 6| Step: 2
Training loss: 2.5852432250976562
Validation loss: 2.100900830761079

Epoch: 6| Step: 3
Training loss: 2.058285713195801
Validation loss: 2.10759566163504

Epoch: 6| Step: 4
Training loss: 2.456059217453003
Validation loss: 2.102688127948392

Epoch: 6| Step: 5
Training loss: 2.5201034545898438
Validation loss: 2.10608781537702

Epoch: 6| Step: 6
Training loss: 1.5658278465270996
Validation loss: 2.102745666298815

Epoch: 6| Step: 7
Training loss: 2.609266757965088
Validation loss: 2.116560653973651

Epoch: 6| Step: 8
Training loss: 1.6305134296417236
Validation loss: 2.122386855463828

Epoch: 6| Step: 9
Training loss: 2.958611011505127
Validation loss: 2.1213892429105696

Epoch: 6| Step: 10
Training loss: 2.427210807800293
Validation loss: 2.1264458856275006

Epoch: 6| Step: 11
Training loss: 2.616380214691162
Validation loss: 2.1260516105159635

Epoch: 6| Step: 12
Training loss: 2.83211350440979
Validation loss: 2.1172914851096367

Epoch: 6| Step: 13
Training loss: 2.8111305236816406
Validation loss: 2.129333580693891

Epoch: 67| Step: 0
Training loss: 2.823554515838623
Validation loss: 2.1444084080316688

Epoch: 6| Step: 1
Training loss: 2.554537296295166
Validation loss: 2.145617469664543

Epoch: 6| Step: 2
Training loss: 1.9991698265075684
Validation loss: 2.1108617064773396

Epoch: 6| Step: 3
Training loss: 2.219958543777466
Validation loss: 2.095884751248103

Epoch: 6| Step: 4
Training loss: 1.9417136907577515
Validation loss: 2.088060341855531

Epoch: 6| Step: 5
Training loss: 2.515212297439575
Validation loss: 2.08295500663019

Epoch: 6| Step: 6
Training loss: 3.0472278594970703
Validation loss: 2.085337141508697

Epoch: 6| Step: 7
Training loss: 1.9076052904129028
Validation loss: 2.084405013310012

Epoch: 6| Step: 8
Training loss: 2.580742359161377
Validation loss: 2.07560198409583

Epoch: 6| Step: 9
Training loss: 2.1517529487609863
Validation loss: 2.078612587785208

Epoch: 6| Step: 10
Training loss: 2.3819892406463623
Validation loss: 2.080187589891495

Epoch: 6| Step: 11
Training loss: 2.5311291217803955
Validation loss: 2.0845300356547036

Epoch: 6| Step: 12
Training loss: 2.940805435180664
Validation loss: 2.0991353065736833

Epoch: 6| Step: 13
Training loss: 2.58512544631958
Validation loss: 2.1109625652272213

Epoch: 68| Step: 0
Training loss: 2.4138436317443848
Validation loss: 2.0951008412145797

Epoch: 6| Step: 1
Training loss: 2.1669275760650635
Validation loss: 2.0860882779603362

Epoch: 6| Step: 2
Training loss: 2.685326099395752
Validation loss: 2.0832698729730423

Epoch: 6| Step: 3
Training loss: 2.623379707336426
Validation loss: 2.0821947320815055

Epoch: 6| Step: 4
Training loss: 2.311659812927246
Validation loss: 2.0903499395616594

Epoch: 6| Step: 5
Training loss: 3.168388605117798
Validation loss: 2.1065925257180327

Epoch: 6| Step: 6
Training loss: 2.239969253540039
Validation loss: 2.1087272679933937

Epoch: 6| Step: 7
Training loss: 2.6706087589263916
Validation loss: 2.1106580149742866

Epoch: 6| Step: 8
Training loss: 2.3882932662963867
Validation loss: 2.103479159775601

Epoch: 6| Step: 9
Training loss: 2.1962080001831055
Validation loss: 2.098879180928712

Epoch: 6| Step: 10
Training loss: 2.0248069763183594
Validation loss: 2.089222405546455

Epoch: 6| Step: 11
Training loss: 2.1936116218566895
Validation loss: 2.0903606671158985

Epoch: 6| Step: 12
Training loss: 2.5532479286193848
Validation loss: 2.092754328122703

Epoch: 6| Step: 13
Training loss: 2.6237359046936035
Validation loss: 2.080506053022159

Epoch: 69| Step: 0
Training loss: 2.410010814666748
Validation loss: 2.08853615355748

Epoch: 6| Step: 1
Training loss: 2.226576328277588
Validation loss: 2.0814154378829466

Epoch: 6| Step: 2
Training loss: 2.1721391677856445
Validation loss: 2.0869695319924304

Epoch: 6| Step: 3
Training loss: 2.2354040145874023
Validation loss: 2.0939062039057412

Epoch: 6| Step: 4
Training loss: 2.7473526000976562
Validation loss: 2.1027450997342347

Epoch: 6| Step: 5
Training loss: 2.4378368854522705
Validation loss: 2.1222365851043374

Epoch: 6| Step: 6
Training loss: 2.717691421508789
Validation loss: 2.1191906211196736

Epoch: 6| Step: 7
Training loss: 2.6461596488952637
Validation loss: 2.129850187609273

Epoch: 6| Step: 8
Training loss: 2.1496450901031494
Validation loss: 2.1325617772276684

Epoch: 6| Step: 9
Training loss: 2.3927221298217773
Validation loss: 2.135386651562106

Epoch: 6| Step: 10
Training loss: 2.2712833881378174
Validation loss: 2.1311492330284527

Epoch: 6| Step: 11
Training loss: 2.3546552658081055
Validation loss: 2.1204288441647767

Epoch: 6| Step: 12
Training loss: 3.022566080093384
Validation loss: 2.0944386528384302

Epoch: 6| Step: 13
Training loss: 2.02449631690979
Validation loss: 2.072092012692523

Epoch: 70| Step: 0
Training loss: 2.240488290786743
Validation loss: 2.0708548676583076

Epoch: 6| Step: 1
Training loss: 2.4468774795532227
Validation loss: 2.0607167392648678

Epoch: 6| Step: 2
Training loss: 3.126917839050293
Validation loss: 2.057894757998887

Epoch: 6| Step: 3
Training loss: 2.5404934883117676
Validation loss: 2.0496519714273433

Epoch: 6| Step: 4
Training loss: 3.134359359741211
Validation loss: 2.051701541869871

Epoch: 6| Step: 5
Training loss: 2.2336370944976807
Validation loss: 2.052140151300738

Epoch: 6| Step: 6
Training loss: 1.4095202684402466
Validation loss: 2.0519945775308917

Epoch: 6| Step: 7
Training loss: 1.8509477376937866
Validation loss: 2.0510534740263417

Epoch: 6| Step: 8
Training loss: 3.0881357192993164
Validation loss: 2.0603264006235267

Epoch: 6| Step: 9
Training loss: 2.248692512512207
Validation loss: 2.08087129874896

Epoch: 6| Step: 10
Training loss: 2.785923719406128
Validation loss: 2.10283483997468

Epoch: 6| Step: 11
Training loss: 2.106710195541382
Validation loss: 2.11561950560539

Epoch: 6| Step: 12
Training loss: 2.447883129119873
Validation loss: 2.129026964146604

Epoch: 6| Step: 13
Training loss: 2.3839712142944336
Validation loss: 2.139768728645899

Epoch: 71| Step: 0
Training loss: 2.336864948272705
Validation loss: 2.1399127206494732

Epoch: 6| Step: 1
Training loss: 2.965444564819336
Validation loss: 2.13524612047339

Epoch: 6| Step: 2
Training loss: 2.4578256607055664
Validation loss: 2.1309683258815477

Epoch: 6| Step: 3
Training loss: 2.340151786804199
Validation loss: 2.1288565486989994

Epoch: 6| Step: 4
Training loss: 2.8831677436828613
Validation loss: 2.1201831076734807

Epoch: 6| Step: 5
Training loss: 1.9309276342391968
Validation loss: 2.1230257300920385

Epoch: 6| Step: 6
Training loss: 2.1450345516204834
Validation loss: 2.1353414725231867

Epoch: 6| Step: 7
Training loss: 2.102529525756836
Validation loss: 2.1227623160167406

Epoch: 6| Step: 8
Training loss: 2.9704151153564453
Validation loss: 2.1341788076585337

Epoch: 6| Step: 9
Training loss: 2.1116557121276855
Validation loss: 2.12881741985198

Epoch: 6| Step: 10
Training loss: 2.6768951416015625
Validation loss: 2.1250130514944754

Epoch: 6| Step: 11
Training loss: 2.164045810699463
Validation loss: 2.102412854471514

Epoch: 6| Step: 12
Training loss: 2.4638402462005615
Validation loss: 2.098422501676826

Epoch: 6| Step: 13
Training loss: 2.255949020385742
Validation loss: 2.0958609862994124

Epoch: 72| Step: 0
Training loss: 2.8725426197052
Validation loss: 2.094357490539551

Epoch: 6| Step: 1
Training loss: 2.769768476486206
Validation loss: 2.0965309617339924

Epoch: 6| Step: 2
Training loss: 2.2631654739379883
Validation loss: 2.0998928111086608

Epoch: 6| Step: 3
Training loss: 2.0250282287597656
Validation loss: 2.0984666014230378

Epoch: 6| Step: 4
Training loss: 2.1070144176483154
Validation loss: 2.099960691185408

Epoch: 6| Step: 5
Training loss: 2.160228729248047
Validation loss: 2.1245412326628164

Epoch: 6| Step: 6
Training loss: 3.0849802494049072
Validation loss: 2.165918366883391

Epoch: 6| Step: 7
Training loss: 3.1778218746185303
Validation loss: 2.1907277850694555

Epoch: 6| Step: 8
Training loss: 1.6434978246688843
Validation loss: 2.206851941283031

Epoch: 6| Step: 9
Training loss: 2.2209579944610596
Validation loss: 2.1944487966516966

Epoch: 6| Step: 10
Training loss: 2.236196279525757
Validation loss: 2.1581686645425777

Epoch: 6| Step: 11
Training loss: 2.5931339263916016
Validation loss: 2.1504705118876632

Epoch: 6| Step: 12
Training loss: 3.063826084136963
Validation loss: 2.1212739329184256

Epoch: 6| Step: 13
Training loss: 1.5941588878631592
Validation loss: 2.1049039620225147

Epoch: 73| Step: 0
Training loss: 1.7236697673797607
Validation loss: 2.0996341013139292

Epoch: 6| Step: 1
Training loss: 2.916745662689209
Validation loss: 2.093839104457568

Epoch: 6| Step: 2
Training loss: 2.2334113121032715
Validation loss: 2.098831784340643

Epoch: 6| Step: 3
Training loss: 2.418294906616211
Validation loss: 2.101733120538855

Epoch: 6| Step: 4
Training loss: 2.057401180267334
Validation loss: 2.1046517933568647

Epoch: 6| Step: 5
Training loss: 2.6147568225860596
Validation loss: 2.129795064208328

Epoch: 6| Step: 6
Training loss: 2.584066390991211
Validation loss: 2.1347417754511677

Epoch: 6| Step: 7
Training loss: 1.5135234594345093
Validation loss: 2.1376958226644867

Epoch: 6| Step: 8
Training loss: 2.893521785736084
Validation loss: 2.142230410729685

Epoch: 6| Step: 9
Training loss: 3.0264830589294434
Validation loss: 2.1258856455485025

Epoch: 6| Step: 10
Training loss: 2.7786407470703125
Validation loss: 2.107478254584856

Epoch: 6| Step: 11
Training loss: 2.442880630493164
Validation loss: 2.0899187980159635

Epoch: 6| Step: 12
Training loss: 2.564276695251465
Validation loss: 2.081428635504938

Epoch: 6| Step: 13
Training loss: 1.9579739570617676
Validation loss: 2.0745521950465378

Epoch: 74| Step: 0
Training loss: 2.1282081604003906
Validation loss: 2.0699421821102018

Epoch: 6| Step: 1
Training loss: 2.8806862831115723
Validation loss: 2.068532136178786

Epoch: 6| Step: 2
Training loss: 2.370222568511963
Validation loss: 2.079099843578954

Epoch: 6| Step: 3
Training loss: 2.055234909057617
Validation loss: 2.0800635994121595

Epoch: 6| Step: 4
Training loss: 2.1699514389038086
Validation loss: 2.078218165264335

Epoch: 6| Step: 5
Training loss: 2.1954708099365234
Validation loss: 2.069689219997775

Epoch: 6| Step: 6
Training loss: 2.1411209106445312
Validation loss: 2.068497680848645

Epoch: 6| Step: 7
Training loss: 1.9396896362304688
Validation loss: 2.066695269717965

Epoch: 6| Step: 8
Training loss: 1.741978645324707
Validation loss: 2.0750762288288405

Epoch: 6| Step: 9
Training loss: 2.3247766494750977
Validation loss: 2.11119185468202

Epoch: 6| Step: 10
Training loss: 3.00464129447937
Validation loss: 2.171235663916475

Epoch: 6| Step: 11
Training loss: 3.260570526123047
Validation loss: 2.1773149454465477

Epoch: 6| Step: 12
Training loss: 3.4697537422180176
Validation loss: 2.1570070840979136

Epoch: 6| Step: 13
Training loss: 2.6988511085510254
Validation loss: 2.1058644953594414

Epoch: 75| Step: 0
Training loss: 2.8010454177856445
Validation loss: 2.0811731046245945

Epoch: 6| Step: 1
Training loss: 2.0466339588165283
Validation loss: 2.0809298228192072

Epoch: 6| Step: 2
Training loss: 1.8876866102218628
Validation loss: 2.0930396792709187

Epoch: 6| Step: 3
Training loss: 2.623995065689087
Validation loss: 2.094941431476224

Epoch: 6| Step: 4
Training loss: 2.4286770820617676
Validation loss: 2.1441847765317528

Epoch: 6| Step: 5
Training loss: 1.831412434577942
Validation loss: 2.197606025203582

Epoch: 6| Step: 6
Training loss: 3.6909539699554443
Validation loss: 2.2722030198702248

Epoch: 6| Step: 7
Training loss: 2.447862148284912
Validation loss: 2.330627656752063

Epoch: 6| Step: 8
Training loss: 2.9199390411376953
Validation loss: 2.1958971690106135

Epoch: 6| Step: 9
Training loss: 2.2426552772521973
Validation loss: 2.119112583898729

Epoch: 6| Step: 10
Training loss: 2.324025869369507
Validation loss: 2.0955727010644893

Epoch: 6| Step: 11
Training loss: 2.461860179901123
Validation loss: 2.094599631524855

Epoch: 6| Step: 12
Training loss: 2.2943990230560303
Validation loss: 2.0885359497480493

Epoch: 6| Step: 13
Training loss: 2.643738269805908
Validation loss: 2.088127456685548

Epoch: 76| Step: 0
Training loss: 1.9537122249603271
Validation loss: 2.082836453632642

Epoch: 6| Step: 1
Training loss: 2.6062445640563965
Validation loss: 2.080724900768649

Epoch: 6| Step: 2
Training loss: 2.469372272491455
Validation loss: 2.1006728320993404

Epoch: 6| Step: 3
Training loss: 3.0110974311828613
Validation loss: 2.0927746321565364

Epoch: 6| Step: 4
Training loss: 2.2965564727783203
Validation loss: 2.1159835528301936

Epoch: 6| Step: 5
Training loss: 2.2806386947631836
Validation loss: 2.1739710172017417

Epoch: 6| Step: 6
Training loss: 2.6692492961883545
Validation loss: 2.244680173935429

Epoch: 6| Step: 7
Training loss: 2.8316073417663574
Validation loss: 2.26256194678686

Epoch: 6| Step: 8
Training loss: 2.466569185256958
Validation loss: 2.188636197838732

Epoch: 6| Step: 9
Training loss: 1.9082552194595337
Validation loss: 2.117801868787376

Epoch: 6| Step: 10
Training loss: 2.358372211456299
Validation loss: 2.0686705138093684

Epoch: 6| Step: 11
Training loss: 1.9062786102294922
Validation loss: 2.052090516654394

Epoch: 6| Step: 12
Training loss: 2.8017849922180176
Validation loss: 2.038556043819715

Epoch: 6| Step: 13
Training loss: 2.6943538188934326
Validation loss: 2.034892976924937

Epoch: 77| Step: 0
Training loss: 2.5209951400756836
Validation loss: 2.0407120489305064

Epoch: 6| Step: 1
Training loss: 3.4124207496643066
Validation loss: 2.050546118008193

Epoch: 6| Step: 2
Training loss: 1.9540404081344604
Validation loss: 2.0581787529812066

Epoch: 6| Step: 3
Training loss: 2.3352341651916504
Validation loss: 2.0561924121713124

Epoch: 6| Step: 4
Training loss: 2.415760040283203
Validation loss: 2.0791726727639475

Epoch: 6| Step: 5
Training loss: 2.463599443435669
Validation loss: 2.0850618808500228

Epoch: 6| Step: 6
Training loss: 2.4615087509155273
Validation loss: 2.0902885442139

Epoch: 6| Step: 7
Training loss: 2.036743402481079
Validation loss: 2.1024834955892255

Epoch: 6| Step: 8
Training loss: 2.3444008827209473
Validation loss: 2.1208334866390435

Epoch: 6| Step: 9
Training loss: 2.6386730670928955
Validation loss: 2.0990325045841995

Epoch: 6| Step: 10
Training loss: 2.5668506622314453
Validation loss: 2.06026271594468

Epoch: 6| Step: 11
Training loss: 1.754335641860962
Validation loss: 2.049459449706539

Epoch: 6| Step: 12
Training loss: 2.175060272216797
Validation loss: 2.0506028744482223

Epoch: 6| Step: 13
Training loss: 3.0722815990448
Validation loss: 2.0627335527891755

Epoch: 78| Step: 0
Training loss: 2.715668201446533
Validation loss: 2.0582639889050554

Epoch: 6| Step: 1
Training loss: 3.1175918579101562
Validation loss: 2.066479908522739

Epoch: 6| Step: 2
Training loss: 2.263909339904785
Validation loss: 2.069175627923781

Epoch: 6| Step: 3
Training loss: 2.849146842956543
Validation loss: 2.1002025142792733

Epoch: 6| Step: 4
Training loss: 2.5304114818573
Validation loss: 2.089176429215298

Epoch: 6| Step: 5
Training loss: 2.2971324920654297
Validation loss: 2.1211914580355407

Epoch: 6| Step: 6
Training loss: 2.1126708984375
Validation loss: 2.163710783886653

Epoch: 6| Step: 7
Training loss: 2.229013442993164
Validation loss: 2.1410581911763837

Epoch: 6| Step: 8
Training loss: 3.1613881587982178
Validation loss: 2.0960497010138726

Epoch: 6| Step: 9
Training loss: 1.5158488750457764
Validation loss: 2.0590618989800893

Epoch: 6| Step: 10
Training loss: 2.220761775970459
Validation loss: 2.0541549831308346

Epoch: 6| Step: 11
Training loss: 2.1738734245300293
Validation loss: 2.0570186286844234

Epoch: 6| Step: 12
Training loss: 2.2747278213500977
Validation loss: 2.06616287590355

Epoch: 6| Step: 13
Training loss: 1.571441888809204
Validation loss: 2.073723364901799

Epoch: 79| Step: 0
Training loss: 2.92508864402771
Validation loss: 2.073718350420716

Epoch: 6| Step: 1
Training loss: 2.9211740493774414
Validation loss: 2.0782854044309227

Epoch: 6| Step: 2
Training loss: 2.829528331756592
Validation loss: 2.085864265759786

Epoch: 6| Step: 3
Training loss: 2.8368194103240967
Validation loss: 2.135523752499652

Epoch: 6| Step: 4
Training loss: 2.1410908699035645
Validation loss: 2.1547940969467163

Epoch: 6| Step: 5
Training loss: 2.5077877044677734
Validation loss: 2.1602014367298414

Epoch: 6| Step: 6
Training loss: 1.9110281467437744
Validation loss: 2.132749922813908

Epoch: 6| Step: 7
Training loss: 2.4272384643554688
Validation loss: 2.1282090397291284

Epoch: 6| Step: 8
Training loss: 2.0635948181152344
Validation loss: 2.1201421189051803

Epoch: 6| Step: 9
Training loss: 2.054137706756592
Validation loss: 2.1078439476669475

Epoch: 6| Step: 10
Training loss: 2.2575454711914062
Validation loss: 2.1081615763325847

Epoch: 6| Step: 11
Training loss: 2.186676025390625
Validation loss: 2.1021146748655584

Epoch: 6| Step: 12
Training loss: 2.6319355964660645
Validation loss: 2.0986478123613583

Epoch: 6| Step: 13
Training loss: 1.838185429573059
Validation loss: 2.0988139003835697

Epoch: 80| Step: 0
Training loss: 2.1633734703063965
Validation loss: 2.1105922447737826

Epoch: 6| Step: 1
Training loss: 2.369000196456909
Validation loss: 2.130725158158169

Epoch: 6| Step: 2
Training loss: 2.123445510864258
Validation loss: 2.132452578954799

Epoch: 6| Step: 3
Training loss: 2.5210487842559814
Validation loss: 2.1474013097824587

Epoch: 6| Step: 4
Training loss: 2.8334665298461914
Validation loss: 2.128165078419511

Epoch: 6| Step: 5
Training loss: 1.5908044576644897
Validation loss: 2.1078682702074767

Epoch: 6| Step: 6
Training loss: 2.5730056762695312
Validation loss: 2.1046861487050212

Epoch: 6| Step: 7
Training loss: 2.6208672523498535
Validation loss: 2.086106343935895

Epoch: 6| Step: 8
Training loss: 3.008871078491211
Validation loss: 2.0823757545922392

Epoch: 6| Step: 9
Training loss: 2.8461291790008545
Validation loss: 2.070329905838095

Epoch: 6| Step: 10
Training loss: 1.8914563655853271
Validation loss: 2.073778857466995

Epoch: 6| Step: 11
Training loss: 2.505847215652466
Validation loss: 2.07655833613488

Epoch: 6| Step: 12
Training loss: 2.6330559253692627
Validation loss: 2.0781482342750794

Epoch: 6| Step: 13
Training loss: 1.8984968662261963
Validation loss: 2.0747030627342964

Epoch: 81| Step: 0
Training loss: 2.892838954925537
Validation loss: 2.0824736574644684

Epoch: 6| Step: 1
Training loss: 1.8532695770263672
Validation loss: 2.09761800817264

Epoch: 6| Step: 2
Training loss: 2.5528512001037598
Validation loss: 2.118883571317119

Epoch: 6| Step: 3
Training loss: 2.8088698387145996
Validation loss: 2.1525756902592157

Epoch: 6| Step: 4
Training loss: 2.8755645751953125
Validation loss: 2.1731970412756807

Epoch: 6| Step: 5
Training loss: 1.8843538761138916
Validation loss: 2.2122101065933064

Epoch: 6| Step: 6
Training loss: 2.531956434249878
Validation loss: 2.2461341811764624

Epoch: 6| Step: 7
Training loss: 3.0322909355163574
Validation loss: 2.26379555784246

Epoch: 6| Step: 8
Training loss: 2.3140225410461426
Validation loss: 2.22017325252615

Epoch: 6| Step: 9
Training loss: 1.6444123983383179
Validation loss: 2.193212273300335

Epoch: 6| Step: 10
Training loss: 1.9590425491333008
Validation loss: 2.1544693849420034

Epoch: 6| Step: 11
Training loss: 2.4355783462524414
Validation loss: 2.124170022626077

Epoch: 6| Step: 12
Training loss: 2.0436344146728516
Validation loss: 2.1051831450513614

Epoch: 6| Step: 13
Training loss: 3.248931884765625
Validation loss: 2.0791847475113405

Epoch: 82| Step: 0
Training loss: 1.6544028520584106
Validation loss: 2.080462363458449

Epoch: 6| Step: 1
Training loss: 2.972647190093994
Validation loss: 2.0661395570283294

Epoch: 6| Step: 2
Training loss: 2.4205126762390137
Validation loss: 2.067220590447867

Epoch: 6| Step: 3
Training loss: 1.9003524780273438
Validation loss: 2.0675151707023702

Epoch: 6| Step: 4
Training loss: 3.178772449493408
Validation loss: 2.06380945251834

Epoch: 6| Step: 5
Training loss: 2.2163848876953125
Validation loss: 2.072013282006787

Epoch: 6| Step: 6
Training loss: 2.0123531818389893
Validation loss: 2.08300882129259

Epoch: 6| Step: 7
Training loss: 2.9636003971099854
Validation loss: 2.09231178093982

Epoch: 6| Step: 8
Training loss: 2.464195966720581
Validation loss: 2.126908166434175

Epoch: 6| Step: 9
Training loss: 2.0864481925964355
Validation loss: 2.1161977603871334

Epoch: 6| Step: 10
Training loss: 2.7632896900177
Validation loss: 2.122377710957681

Epoch: 6| Step: 11
Training loss: 1.8840304613113403
Validation loss: 2.10932179163861

Epoch: 6| Step: 12
Training loss: 2.604424476623535
Validation loss: 2.1156844105771793

Epoch: 6| Step: 13
Training loss: 2.3554465770721436
Validation loss: 2.1137614404001543

Epoch: 83| Step: 0
Training loss: 2.4963133335113525
Validation loss: 2.093413713157818

Epoch: 6| Step: 1
Training loss: 2.736652135848999
Validation loss: 2.083411838418694

Epoch: 6| Step: 2
Training loss: 2.089223623275757
Validation loss: 2.0832855752719346

Epoch: 6| Step: 3
Training loss: 2.618257522583008
Validation loss: 2.0722337256195726

Epoch: 6| Step: 4
Training loss: 2.3574588298797607
Validation loss: 2.070066839136103

Epoch: 6| Step: 5
Training loss: 2.1050539016723633
Validation loss: 2.0693156078297603

Epoch: 6| Step: 6
Training loss: 2.8350300788879395
Validation loss: 2.072530515732304

Epoch: 6| Step: 7
Training loss: 2.646169662475586
Validation loss: 2.071755378477035

Epoch: 6| Step: 8
Training loss: 1.5024774074554443
Validation loss: 2.0673527768863145

Epoch: 6| Step: 9
Training loss: 2.042823314666748
Validation loss: 2.062913968998899

Epoch: 6| Step: 10
Training loss: 1.9711633920669556
Validation loss: 2.067417767740065

Epoch: 6| Step: 11
Training loss: 2.973119020462036
Validation loss: 2.065118315399334

Epoch: 6| Step: 12
Training loss: 2.131105899810791
Validation loss: 2.06418469900726

Epoch: 6| Step: 13
Training loss: 2.9370036125183105
Validation loss: 2.070410213162822

Epoch: 84| Step: 0
Training loss: 1.4349405765533447
Validation loss: 2.0754886006796234

Epoch: 6| Step: 1
Training loss: 1.7331008911132812
Validation loss: 2.071423133214315

Epoch: 6| Step: 2
Training loss: 2.2318670749664307
Validation loss: 2.0473321073798725

Epoch: 6| Step: 3
Training loss: 3.196993827819824
Validation loss: 2.0360779121357906

Epoch: 6| Step: 4
Training loss: 2.02871036529541
Validation loss: 2.0176225285376272

Epoch: 6| Step: 5
Training loss: 2.730801582336426
Validation loss: 2.0082556227202057

Epoch: 6| Step: 6
Training loss: 2.6230063438415527
Validation loss: 1.9949513737873366

Epoch: 6| Step: 7
Training loss: 2.7459211349487305
Validation loss: 1.997620851762833

Epoch: 6| Step: 8
Training loss: 2.4440345764160156
Validation loss: 1.9952333870754446

Epoch: 6| Step: 9
Training loss: 1.9734351634979248
Validation loss: 1.9976855349797074

Epoch: 6| Step: 10
Training loss: 2.1134800910949707
Validation loss: 2.000542712467973

Epoch: 6| Step: 11
Training loss: 2.888143301010132
Validation loss: 2.0094921755534347

Epoch: 6| Step: 12
Training loss: 2.888115406036377
Validation loss: 2.0129200348290066

Epoch: 6| Step: 13
Training loss: 1.503088355064392
Validation loss: 2.029814256134854

Epoch: 85| Step: 0
Training loss: 1.9504557847976685
Validation loss: 2.0530058850524244

Epoch: 6| Step: 1
Training loss: 2.17421293258667
Validation loss: 2.0850348088049118

Epoch: 6| Step: 2
Training loss: 2.8756520748138428
Validation loss: 2.16071791161773

Epoch: 6| Step: 3
Training loss: 2.5162622928619385
Validation loss: 2.1467971647939375

Epoch: 6| Step: 4
Training loss: 2.5555031299591064
Validation loss: 2.0750338313400105

Epoch: 6| Step: 5
Training loss: 2.533111333847046
Validation loss: 2.0381530305390716

Epoch: 6| Step: 6
Training loss: 2.192384958267212
Validation loss: 2.008769340412591

Epoch: 6| Step: 7
Training loss: 2.492138385772705
Validation loss: 2.0037672993957356

Epoch: 6| Step: 8
Training loss: 2.2080001831054688
Validation loss: 2.0077686284178045

Epoch: 6| Step: 9
Training loss: 2.71225905418396
Validation loss: 2.005050859143657

Epoch: 6| Step: 10
Training loss: 1.9559402465820312
Validation loss: 2.002191748670352

Epoch: 6| Step: 11
Training loss: 2.568117618560791
Validation loss: 2.0050980583313973

Epoch: 6| Step: 12
Training loss: 2.0611093044281006
Validation loss: 2.0093203975308325

Epoch: 6| Step: 13
Training loss: 1.8932569026947021
Validation loss: 2.004345009403844

Epoch: 86| Step: 0
Training loss: 2.830940008163452
Validation loss: 2.0037477426631476

Epoch: 6| Step: 1
Training loss: 2.4513680934906006
Validation loss: 2.0105854375388033

Epoch: 6| Step: 2
Training loss: 2.6064677238464355
Validation loss: 2.001591679870441

Epoch: 6| Step: 3
Training loss: 1.9311003684997559
Validation loss: 2.001723227962371

Epoch: 6| Step: 4
Training loss: 2.6714720726013184
Validation loss: 2.018179311547228

Epoch: 6| Step: 5
Training loss: 2.0308849811553955
Validation loss: 2.0195058443213023

Epoch: 6| Step: 6
Training loss: 2.615326404571533
Validation loss: 2.020788820840979

Epoch: 6| Step: 7
Training loss: 1.7368918657302856
Validation loss: 2.013763455934422

Epoch: 6| Step: 8
Training loss: 2.5862364768981934
Validation loss: 2.01135286208122

Epoch: 6| Step: 9
Training loss: 1.6365504264831543
Validation loss: 2.0152210676541893

Epoch: 6| Step: 10
Training loss: 1.7984561920166016
Validation loss: 2.017800527234231

Epoch: 6| Step: 11
Training loss: 2.1204962730407715
Validation loss: 2.009226950266028

Epoch: 6| Step: 12
Training loss: 3.2147510051727295
Validation loss: 2.0118675283206406

Epoch: 6| Step: 13
Training loss: 2.1436657905578613
Validation loss: 2.0060534477233887

Epoch: 87| Step: 0
Training loss: 2.6853318214416504
Validation loss: 2.013818133261896

Epoch: 6| Step: 1
Training loss: 2.5532493591308594
Validation loss: 2.0144967315017537

Epoch: 6| Step: 2
Training loss: 2.1420154571533203
Validation loss: 2.014881823652534

Epoch: 6| Step: 3
Training loss: 2.4558987617492676
Validation loss: 2.021647218734987

Epoch: 6| Step: 4
Training loss: 1.7909166812896729
Validation loss: 2.028634653296522

Epoch: 6| Step: 5
Training loss: 2.675025463104248
Validation loss: 2.0109420104693343

Epoch: 6| Step: 6
Training loss: 1.3966364860534668
Validation loss: 2.0240548349195913

Epoch: 6| Step: 7
Training loss: 1.8629729747772217
Validation loss: 2.0518904860301683

Epoch: 6| Step: 8
Training loss: 3.24747633934021
Validation loss: 2.0832828116673294

Epoch: 6| Step: 9
Training loss: 2.666874408721924
Validation loss: 2.0744783673235165

Epoch: 6| Step: 10
Training loss: 2.2850773334503174
Validation loss: 2.09859376312584

Epoch: 6| Step: 11
Training loss: 1.6248884201049805
Validation loss: 2.091375071515319

Epoch: 6| Step: 12
Training loss: 2.590581178665161
Validation loss: 2.0852307734950895

Epoch: 6| Step: 13
Training loss: 2.722043037414551
Validation loss: 2.0733184045360935

Epoch: 88| Step: 0
Training loss: 2.624619245529175
Validation loss: 2.065888574046473

Epoch: 6| Step: 1
Training loss: 2.543621778488159
Validation loss: 2.0715630285201536

Epoch: 6| Step: 2
Training loss: 1.6847515106201172
Validation loss: 2.0800585054582164

Epoch: 6| Step: 3
Training loss: 2.2322263717651367
Validation loss: 2.0698245058777514

Epoch: 6| Step: 4
Training loss: 2.525536298751831
Validation loss: 2.069025628028377

Epoch: 6| Step: 5
Training loss: 2.386690378189087
Validation loss: 2.0705177578874814

Epoch: 6| Step: 6
Training loss: 2.5386924743652344
Validation loss: 2.0603913286680817

Epoch: 6| Step: 7
Training loss: 2.0500388145446777
Validation loss: 2.0408295123807845

Epoch: 6| Step: 8
Training loss: 2.8726134300231934
Validation loss: 2.0364224180098502

Epoch: 6| Step: 9
Training loss: 2.7106995582580566
Validation loss: 2.031127811760031

Epoch: 6| Step: 10
Training loss: 2.4875783920288086
Validation loss: 2.0363624659917687

Epoch: 6| Step: 11
Training loss: 2.3835501670837402
Validation loss: 2.0470076991665747

Epoch: 6| Step: 12
Training loss: 1.5356419086456299
Validation loss: 2.053244939414404

Epoch: 6| Step: 13
Training loss: 2.172075033187866
Validation loss: 2.0627380186511624

Epoch: 89| Step: 0
Training loss: 1.912717580795288
Validation loss: 2.045029749152481

Epoch: 6| Step: 1
Training loss: 3.0085270404815674
Validation loss: 2.065446478064342

Epoch: 6| Step: 2
Training loss: 2.1681325435638428
Validation loss: 2.067393038862495

Epoch: 6| Step: 3
Training loss: 2.5624842643737793
Validation loss: 2.0758967553415606

Epoch: 6| Step: 4
Training loss: 2.4905920028686523
Validation loss: 2.0404879816116823

Epoch: 6| Step: 5
Training loss: 2.153899908065796
Validation loss: 2.026290488499467

Epoch: 6| Step: 6
Training loss: 2.800896167755127
Validation loss: 2.004890513676469

Epoch: 6| Step: 7
Training loss: 2.6871631145477295
Validation loss: 2.010081857763311

Epoch: 6| Step: 8
Training loss: 0.8846845626831055
Validation loss: 2.0176041408251693

Epoch: 6| Step: 9
Training loss: 2.629603147506714
Validation loss: 2.0076240429314236

Epoch: 6| Step: 10
Training loss: 2.5313310623168945
Validation loss: 2.0132265949761994

Epoch: 6| Step: 11
Training loss: 1.9785988330841064
Validation loss: 2.01160442444586

Epoch: 6| Step: 12
Training loss: 2.1466622352600098
Validation loss: 2.0081814232692925

Epoch: 6| Step: 13
Training loss: 3.0254533290863037
Validation loss: 2.016489331440259

Epoch: 90| Step: 0
Training loss: 3.337944746017456
Validation loss: 2.0071333787774526

Epoch: 6| Step: 1
Training loss: 2.6252689361572266
Validation loss: 2.0177710466487433

Epoch: 6| Step: 2
Training loss: 1.31366765499115
Validation loss: 2.016918164427562

Epoch: 6| Step: 3
Training loss: 2.8361973762512207
Validation loss: 2.014528561663884

Epoch: 6| Step: 4
Training loss: 1.9638909101486206
Validation loss: 2.0221400876199045

Epoch: 6| Step: 5
Training loss: 1.9579517841339111
Validation loss: 2.02136924189906

Epoch: 6| Step: 6
Training loss: 1.921494960784912
Validation loss: 2.0323521808911393

Epoch: 6| Step: 7
Training loss: 2.610609769821167
Validation loss: 2.0429973422840075

Epoch: 6| Step: 8
Training loss: 2.2690773010253906
Validation loss: 2.061913721023067

Epoch: 6| Step: 9
Training loss: 1.9360103607177734
Validation loss: 2.0562596833834084

Epoch: 6| Step: 10
Training loss: 2.12789249420166
Validation loss: 2.0466961604292675

Epoch: 6| Step: 11
Training loss: 1.8132579326629639
Validation loss: 2.0318579173857167

Epoch: 6| Step: 12
Training loss: 2.9489636421203613
Validation loss: 2.0304192830157537

Epoch: 6| Step: 13
Training loss: 2.734398603439331
Validation loss: 2.0314367971112652

Epoch: 91| Step: 0
Training loss: 2.283233165740967
Validation loss: 2.0507903278514905

Epoch: 6| Step: 1
Training loss: 1.953097939491272
Validation loss: 2.0588409721210437

Epoch: 6| Step: 2
Training loss: 2.5040087699890137
Validation loss: 2.0465912511271815

Epoch: 6| Step: 3
Training loss: 2.774160861968994
Validation loss: 2.0334043938626527

Epoch: 6| Step: 4
Training loss: 1.7453975677490234
Validation loss: 2.03416580923142

Epoch: 6| Step: 5
Training loss: 2.035135269165039
Validation loss: 2.0239047286331013

Epoch: 6| Step: 6
Training loss: 2.5396385192871094
Validation loss: 2.021403835665795

Epoch: 6| Step: 7
Training loss: 2.0732152462005615
Validation loss: 2.0282618461116666

Epoch: 6| Step: 8
Training loss: 2.8001933097839355
Validation loss: 2.016518997889693

Epoch: 6| Step: 9
Training loss: 2.474377155303955
Validation loss: 2.02000254713079

Epoch: 6| Step: 10
Training loss: 2.3989250659942627
Validation loss: 2.025343252766517

Epoch: 6| Step: 11
Training loss: 2.1717116832733154
Validation loss: 2.0262176195780435

Epoch: 6| Step: 12
Training loss: 3.0044281482696533
Validation loss: 2.045824344440173

Epoch: 6| Step: 13
Training loss: 1.327364444732666
Validation loss: 2.064973731194773

Epoch: 92| Step: 0
Training loss: 2.7206833362579346
Validation loss: 2.0638746317996772

Epoch: 6| Step: 1
Training loss: 2.6430203914642334
Validation loss: 2.0665833719315065

Epoch: 6| Step: 2
Training loss: 2.17474365234375
Validation loss: 2.082204975107665

Epoch: 6| Step: 3
Training loss: 2.579880714416504
Validation loss: 2.0688187012108425

Epoch: 6| Step: 4
Training loss: 2.7038002014160156
Validation loss: 2.054003723206059

Epoch: 6| Step: 5
Training loss: 2.704758644104004
Validation loss: 2.0228043089630785

Epoch: 6| Step: 6
Training loss: 1.805769920349121
Validation loss: 2.0126095433388986

Epoch: 6| Step: 7
Training loss: 2.136058807373047
Validation loss: 2.0015040969335907

Epoch: 6| Step: 8
Training loss: 2.657748222351074
Validation loss: 2.007443820276568

Epoch: 6| Step: 9
Training loss: 2.0708017349243164
Validation loss: 1.996569533501902

Epoch: 6| Step: 10
Training loss: 1.5698001384735107
Validation loss: 2.0041746490745136

Epoch: 6| Step: 11
Training loss: 2.337078332901001
Validation loss: 1.9928170942491101

Epoch: 6| Step: 12
Training loss: 2.5086493492126465
Validation loss: 2.0066086656303814

Epoch: 6| Step: 13
Training loss: 1.493010401725769
Validation loss: 2.0205669479985393

Epoch: 93| Step: 0
Training loss: 2.6002402305603027
Validation loss: 2.043861440432969

Epoch: 6| Step: 1
Training loss: 2.3286595344543457
Validation loss: 2.0545021577547957

Epoch: 6| Step: 2
Training loss: 2.8341188430786133
Validation loss: 2.0890418073182464

Epoch: 6| Step: 3
Training loss: 2.6449086666107178
Validation loss: 2.0810236315573416

Epoch: 6| Step: 4
Training loss: 1.5514791011810303
Validation loss: 2.0647342640866517

Epoch: 6| Step: 5
Training loss: 2.1522274017333984
Validation loss: 2.012230457798127

Epoch: 6| Step: 6
Training loss: 1.9210231304168701
Validation loss: 1.982156171593615

Epoch: 6| Step: 7
Training loss: 3.1158385276794434
Validation loss: 1.9782012944580407

Epoch: 6| Step: 8
Training loss: 2.3716397285461426
Validation loss: 1.9828706608023694

Epoch: 6| Step: 9
Training loss: 2.240042209625244
Validation loss: 1.9836040594244515

Epoch: 6| Step: 10
Training loss: 2.058331251144409
Validation loss: 1.989626871642246

Epoch: 6| Step: 11
Training loss: 2.452125310897827
Validation loss: 1.9843947579783778

Epoch: 6| Step: 12
Training loss: 2.0807628631591797
Validation loss: 1.9876953504418815

Epoch: 6| Step: 13
Training loss: 2.1216328144073486
Validation loss: 1.999420194215672

Epoch: 94| Step: 0
Training loss: 2.0814342498779297
Validation loss: 1.9978898930293258

Epoch: 6| Step: 1
Training loss: 1.8969696760177612
Validation loss: 1.9999445663985385

Epoch: 6| Step: 2
Training loss: 1.9802768230438232
Validation loss: 2.0143640630988666

Epoch: 6| Step: 3
Training loss: 2.5354137420654297
Validation loss: 2.001959449501448

Epoch: 6| Step: 4
Training loss: 2.298525810241699
Validation loss: 1.996276117140247

Epoch: 6| Step: 5
Training loss: 2.184792995452881
Validation loss: 1.9910365266184653

Epoch: 6| Step: 6
Training loss: 3.0269792079925537
Validation loss: 1.9951403038476103

Epoch: 6| Step: 7
Training loss: 2.0205676555633545
Validation loss: 2.0051362296586395

Epoch: 6| Step: 8
Training loss: 1.9840683937072754
Validation loss: 2.0133558422006588

Epoch: 6| Step: 9
Training loss: 2.2871620655059814
Validation loss: 2.022627822814449

Epoch: 6| Step: 10
Training loss: 2.3751633167266846
Validation loss: 2.0214955704186552

Epoch: 6| Step: 11
Training loss: 2.50272798538208
Validation loss: 2.0272347311819754

Epoch: 6| Step: 12
Training loss: 2.207871437072754
Validation loss: 2.0287937630889235

Epoch: 6| Step: 13
Training loss: 3.2687716484069824
Validation loss: 2.0239079485657396

Epoch: 95| Step: 0
Training loss: 2.519012212753296
Validation loss: 2.0348722191267115

Epoch: 6| Step: 1
Training loss: 2.035072088241577
Validation loss: 2.056174960187686

Epoch: 6| Step: 2
Training loss: 2.079289674758911
Validation loss: 2.0628193911685737

Epoch: 6| Step: 3
Training loss: 2.0520858764648438
Validation loss: 2.07006061461664

Epoch: 6| Step: 4
Training loss: 1.9698331356048584
Validation loss: 2.0763621458443264

Epoch: 6| Step: 5
Training loss: 2.218015670776367
Validation loss: 2.065817267664017

Epoch: 6| Step: 6
Training loss: 2.9799814224243164
Validation loss: 2.0680185120592833

Epoch: 6| Step: 7
Training loss: 2.9791598320007324
Validation loss: 2.055951943961523

Epoch: 6| Step: 8
Training loss: 2.528501272201538
Validation loss: 2.0339240643285934

Epoch: 6| Step: 9
Training loss: 2.1750645637512207
Validation loss: 2.0243263116446872

Epoch: 6| Step: 10
Training loss: 2.5352349281311035
Validation loss: 2.009931242594155

Epoch: 6| Step: 11
Training loss: 1.5560764074325562
Validation loss: 1.999947851704013

Epoch: 6| Step: 12
Training loss: 2.3605434894561768
Validation loss: 2.0007620293606996

Epoch: 6| Step: 13
Training loss: 1.7246073484420776
Validation loss: 2.0082121023567776

Epoch: 96| Step: 0
Training loss: 2.1998977661132812
Validation loss: 1.9948757412613078

Epoch: 6| Step: 1
Training loss: 2.4901621341705322
Validation loss: 2.003749474402397

Epoch: 6| Step: 2
Training loss: 1.876502275466919
Validation loss: 2.0180841299795333

Epoch: 6| Step: 3
Training loss: 2.913905620574951
Validation loss: 2.0223912744111914

Epoch: 6| Step: 4
Training loss: 2.029296636581421
Validation loss: 2.0182068899113643

Epoch: 6| Step: 5
Training loss: 2.7550010681152344
Validation loss: 2.0253036765642065

Epoch: 6| Step: 6
Training loss: 2.5386810302734375
Validation loss: 2.018014295126802

Epoch: 6| Step: 7
Training loss: 2.809274673461914
Validation loss: 2.029117920065439

Epoch: 6| Step: 8
Training loss: 1.479741096496582
Validation loss: 2.044001738230387

Epoch: 6| Step: 9
Training loss: 2.0550708770751953
Validation loss: 2.036485900161087

Epoch: 6| Step: 10
Training loss: 2.3196613788604736
Validation loss: 2.03978136790696

Epoch: 6| Step: 11
Training loss: 1.9678775072097778
Validation loss: 2.022645649089608

Epoch: 6| Step: 12
Training loss: 1.9614988565444946
Validation loss: 1.988309439792428

Epoch: 6| Step: 13
Training loss: 2.5959558486938477
Validation loss: 1.9847080707550049

Epoch: 97| Step: 0
Training loss: 2.0999374389648438
Validation loss: 1.9920772237162436

Epoch: 6| Step: 1
Training loss: 1.7603166103363037
Validation loss: 1.991652996309342

Epoch: 6| Step: 2
Training loss: 3.185713291168213
Validation loss: 1.9859896462450746

Epoch: 6| Step: 3
Training loss: 2.8181474208831787
Validation loss: 1.9934151403365596

Epoch: 6| Step: 4
Training loss: 1.7750194072723389
Validation loss: 1.9933747142873786

Epoch: 6| Step: 5
Training loss: 1.4305977821350098
Validation loss: 1.9994048533901092

Epoch: 6| Step: 6
Training loss: 2.415318250656128
Validation loss: 2.007659594217936

Epoch: 6| Step: 7
Training loss: 1.9851200580596924
Validation loss: 2.0147264875391477

Epoch: 6| Step: 8
Training loss: 2.800593614578247
Validation loss: 2.0201696657365367

Epoch: 6| Step: 9
Training loss: 2.173025131225586
Validation loss: 2.035385017753929

Epoch: 6| Step: 10
Training loss: 2.524700403213501
Validation loss: 2.037776344565935

Epoch: 6| Step: 11
Training loss: 2.05942964553833
Validation loss: 2.03991868675396

Epoch: 6| Step: 12
Training loss: 2.475114345550537
Validation loss: 2.046126388734387

Epoch: 6| Step: 13
Training loss: 2.2579619884490967
Validation loss: 2.0360150670492523

Epoch: 98| Step: 0
Training loss: 2.760922908782959
Validation loss: 2.017851101454868

Epoch: 6| Step: 1
Training loss: 2.0657546520233154
Validation loss: 2.0186198398631108

Epoch: 6| Step: 2
Training loss: 2.1000192165374756
Validation loss: 2.0127575807673956

Epoch: 6| Step: 3
Training loss: 1.8171472549438477
Validation loss: 2.0115898193851596

Epoch: 6| Step: 4
Training loss: 2.279741048812866
Validation loss: 2.0029891639627437

Epoch: 6| Step: 5
Training loss: 1.8587360382080078
Validation loss: 2.007316925192392

Epoch: 6| Step: 6
Training loss: 2.6467347145080566
Validation loss: 2.0051963688224874

Epoch: 6| Step: 7
Training loss: 2.4088268280029297
Validation loss: 2.0228331973475795

Epoch: 6| Step: 8
Training loss: 2.144188404083252
Validation loss: 2.02939429847143

Epoch: 6| Step: 9
Training loss: 1.9071344137191772
Validation loss: 2.017756172405776

Epoch: 6| Step: 10
Training loss: 2.3119277954101562
Validation loss: 2.0296116503336097

Epoch: 6| Step: 11
Training loss: 2.3095290660858154
Validation loss: 2.0081554766624206

Epoch: 6| Step: 12
Training loss: 2.47830867767334
Validation loss: 1.9953552228148266

Epoch: 6| Step: 13
Training loss: 2.420499801635742
Validation loss: 1.9964058501746065

Epoch: 99| Step: 0
Training loss: 2.2297754287719727
Validation loss: 1.9909697835163405

Epoch: 6| Step: 1
Training loss: 2.1461021900177
Validation loss: 1.9970313989987938

Epoch: 6| Step: 2
Training loss: 2.073261260986328
Validation loss: 1.9934935903036466

Epoch: 6| Step: 3
Training loss: 2.296642541885376
Validation loss: 1.996185197625109

Epoch: 6| Step: 4
Training loss: 2.084446907043457
Validation loss: 1.9947632512738627

Epoch: 6| Step: 5
Training loss: 3.0357041358947754
Validation loss: 2.0084071979727796

Epoch: 6| Step: 6
Training loss: 2.044454574584961
Validation loss: 2.0086627916623185

Epoch: 6| Step: 7
Training loss: 1.9443471431732178
Validation loss: 2.0148656637437883

Epoch: 6| Step: 8
Training loss: 2.1997852325439453
Validation loss: 2.0160852645033147

Epoch: 6| Step: 9
Training loss: 2.467799663543701
Validation loss: 2.0270189239132788

Epoch: 6| Step: 10
Training loss: 1.8033843040466309
Validation loss: 2.031959392691171

Epoch: 6| Step: 11
Training loss: 2.0689854621887207
Validation loss: 2.041984527341781

Epoch: 6| Step: 12
Training loss: 2.6160688400268555
Validation loss: 2.029044364088325

Epoch: 6| Step: 13
Training loss: 2.426692247390747
Validation loss: 2.0347651461119294

Epoch: 100| Step: 0
Training loss: 1.989198923110962
Validation loss: 2.0455022960580806

Epoch: 6| Step: 1
Training loss: 2.417348861694336
Validation loss: 2.0395352609695925

Epoch: 6| Step: 2
Training loss: 2.2861998081207275
Validation loss: 2.021653690645772

Epoch: 6| Step: 3
Training loss: 1.661874532699585
Validation loss: 2.0222045760000906

Epoch: 6| Step: 4
Training loss: 1.6186765432357788
Validation loss: 2.016568876081897

Epoch: 6| Step: 5
Training loss: 2.352888822555542
Validation loss: 2.0059158212395123

Epoch: 6| Step: 6
Training loss: 1.5729937553405762
Validation loss: 2.012608285873167

Epoch: 6| Step: 7
Training loss: 2.4052646160125732
Validation loss: 2.0083587374738467

Epoch: 6| Step: 8
Training loss: 2.429295778274536
Validation loss: 2.0182885867293163

Epoch: 6| Step: 9
Training loss: 2.9528679847717285
Validation loss: 2.027104239309988

Epoch: 6| Step: 10
Training loss: 2.0405209064483643
Validation loss: 2.0451015298084547

Epoch: 6| Step: 11
Training loss: 2.261826992034912
Validation loss: 2.058308575742988

Epoch: 6| Step: 12
Training loss: 2.7846813201904297
Validation loss: 2.05577068175039

Epoch: 6| Step: 13
Training loss: 2.563845634460449
Validation loss: 2.080226646956577

Epoch: 101| Step: 0
Training loss: 2.630673408508301
Validation loss: 2.0975829862779185

Epoch: 6| Step: 1
Training loss: 1.8213305473327637
Validation loss: 2.078049623838035

Epoch: 6| Step: 2
Training loss: 2.385104179382324
Validation loss: 2.0694512987649567

Epoch: 6| Step: 3
Training loss: 2.1550865173339844
Validation loss: 2.0468274880481023

Epoch: 6| Step: 4
Training loss: 2.0681490898132324
Validation loss: 2.04126480830613

Epoch: 6| Step: 5
Training loss: 1.9664673805236816
Validation loss: 2.0252748612434632

Epoch: 6| Step: 6
Training loss: 2.433628559112549
Validation loss: 2.004991785172493

Epoch: 6| Step: 7
Training loss: 1.9397926330566406
Validation loss: 2.0135502981883224

Epoch: 6| Step: 8
Training loss: 1.5851361751556396
Validation loss: 2.0061608540114535

Epoch: 6| Step: 9
Training loss: 2.628922700881958
Validation loss: 2.0265935838863416

Epoch: 6| Step: 10
Training loss: 2.2390966415405273
Validation loss: 2.0415320934787875

Epoch: 6| Step: 11
Training loss: 2.6501264572143555
Validation loss: 2.0705064829959663

Epoch: 6| Step: 12
Training loss: 2.3842434883117676
Validation loss: 2.090619946038851

Epoch: 6| Step: 13
Training loss: 2.784398078918457
Validation loss: 2.0806445267892655

Epoch: 102| Step: 0
Training loss: 2.804478645324707
Validation loss: 2.090229288224251

Epoch: 6| Step: 1
Training loss: 2.6568503379821777
Validation loss: 2.1060533703014417

Epoch: 6| Step: 2
Training loss: 2.135115146636963
Validation loss: 2.094303466940439

Epoch: 6| Step: 3
Training loss: 1.8733022212982178
Validation loss: 2.0488455269926336

Epoch: 6| Step: 4
Training loss: 2.082122564315796
Validation loss: 2.0334770230836767

Epoch: 6| Step: 5
Training loss: 1.7971904277801514
Validation loss: 2.032518761132353

Epoch: 6| Step: 6
Training loss: 1.7645320892333984
Validation loss: 2.0311740239461265

Epoch: 6| Step: 7
Training loss: 2.495136260986328
Validation loss: 2.01652334197875

Epoch: 6| Step: 8
Training loss: 1.9634556770324707
Validation loss: 1.9960226435815134

Epoch: 6| Step: 9
Training loss: 2.4713292121887207
Validation loss: 1.9991589951258835

Epoch: 6| Step: 10
Training loss: 1.8860058784484863
Validation loss: 1.9907028623806533

Epoch: 6| Step: 11
Training loss: 2.8337740898132324
Validation loss: 1.9902741396298973

Epoch: 6| Step: 12
Training loss: 2.48138689994812
Validation loss: 2.012500043838255

Epoch: 6| Step: 13
Training loss: 2.21205735206604
Validation loss: 2.0491266096791914

Epoch: 103| Step: 0
Training loss: 2.3544583320617676
Validation loss: 2.012138843536377

Epoch: 6| Step: 1
Training loss: 2.282130718231201
Validation loss: 1.9815355500867289

Epoch: 6| Step: 2
Training loss: 2.8699750900268555
Validation loss: 1.9753036140113749

Epoch: 6| Step: 3
Training loss: 1.9445329904556274
Validation loss: 1.9776399238135225

Epoch: 6| Step: 4
Training loss: 2.135758876800537
Validation loss: 1.9751259460244128

Epoch: 6| Step: 5
Training loss: 1.7785427570343018
Validation loss: 1.971639189668881

Epoch: 6| Step: 6
Training loss: 2.262132167816162
Validation loss: 1.9834650665201166

Epoch: 6| Step: 7
Training loss: 2.558328866958618
Validation loss: 1.9972149941229052

Epoch: 6| Step: 8
Training loss: 1.9065423011779785
Validation loss: 2.0077213612935876

Epoch: 6| Step: 9
Training loss: 2.152053117752075
Validation loss: 2.0331465569875573

Epoch: 6| Step: 10
Training loss: 2.0949501991271973
Validation loss: 2.06634009268976

Epoch: 6| Step: 11
Training loss: 1.901838779449463
Validation loss: 2.1221813232667985

Epoch: 6| Step: 12
Training loss: 2.6189794540405273
Validation loss: 2.1302020293410107

Epoch: 6| Step: 13
Training loss: 3.319689989089966
Validation loss: 2.1151380154394333

Epoch: 104| Step: 0
Training loss: 1.7898430824279785
Validation loss: 2.0666701229669715

Epoch: 6| Step: 1
Training loss: 2.669848918914795
Validation loss: 2.047635829576882

Epoch: 6| Step: 2
Training loss: 2.851912260055542
Validation loss: 2.0233122866640807

Epoch: 6| Step: 3
Training loss: 2.2586426734924316
Validation loss: 1.995070577949606

Epoch: 6| Step: 4
Training loss: 1.9944859743118286
Validation loss: 1.9988842677044611

Epoch: 6| Step: 5
Training loss: 1.9754377603530884
Validation loss: 1.9988623485770276

Epoch: 6| Step: 6
Training loss: 2.3954572677612305
Validation loss: 1.9927155997163506

Epoch: 6| Step: 7
Training loss: 2.6513683795928955
Validation loss: 1.9750211636225383

Epoch: 6| Step: 8
Training loss: 2.350811004638672
Validation loss: 1.9666757109344646

Epoch: 6| Step: 9
Training loss: 2.139824151992798
Validation loss: 1.9829634748479372

Epoch: 6| Step: 10
Training loss: 2.22512149810791
Validation loss: 1.9851902787403395

Epoch: 6| Step: 11
Training loss: 2.3685200214385986
Validation loss: 1.9938996209893176

Epoch: 6| Step: 12
Training loss: 1.5031201839447021
Validation loss: 1.9902608330531786

Epoch: 6| Step: 13
Training loss: 2.015648126602173
Validation loss: 1.9978807510868195

Epoch: 105| Step: 0
Training loss: 2.0178866386413574
Validation loss: 1.9949519839338077

Epoch: 6| Step: 1
Training loss: 1.9612927436828613
Validation loss: 2.009761961557532

Epoch: 6| Step: 2
Training loss: 2.266162395477295
Validation loss: 2.028009021154014

Epoch: 6| Step: 3
Training loss: 3.2613015174865723
Validation loss: 2.027500803752612

Epoch: 6| Step: 4
Training loss: 2.731330394744873
Validation loss: 2.016355432489867

Epoch: 6| Step: 5
Training loss: 2.25350022315979
Validation loss: 1.9956929094047957

Epoch: 6| Step: 6
Training loss: 2.220205545425415
Validation loss: 1.973335260986

Epoch: 6| Step: 7
Training loss: 2.4298393726348877
Validation loss: 1.9576156447010655

Epoch: 6| Step: 8
Training loss: 2.3038487434387207
Validation loss: 1.9559135014011013

Epoch: 6| Step: 9
Training loss: 2.401517391204834
Validation loss: 1.9760512946754374

Epoch: 6| Step: 10
Training loss: 1.8130284547805786
Validation loss: 1.988845174030591

Epoch: 6| Step: 11
Training loss: 2.0101773738861084
Validation loss: 2.007914690561192

Epoch: 6| Step: 12
Training loss: 1.783204436302185
Validation loss: 2.001926586192141

Epoch: 6| Step: 13
Training loss: 1.3774054050445557
Validation loss: 2.007097375008368

Epoch: 106| Step: 0
Training loss: 1.475550651550293
Validation loss: 2.040166393403084

Epoch: 6| Step: 1
Training loss: 2.092672824859619
Validation loss: 2.054792965612104

Epoch: 6| Step: 2
Training loss: 1.7960858345031738
Validation loss: 2.0499201897651917

Epoch: 6| Step: 3
Training loss: 2.6802663803100586
Validation loss: 2.0580087720706897

Epoch: 6| Step: 4
Training loss: 2.2816238403320312
Validation loss: 2.0277094546184746

Epoch: 6| Step: 5
Training loss: 2.4404513835906982
Validation loss: 2.0143292373226536

Epoch: 6| Step: 6
Training loss: 2.6540799140930176
Validation loss: 2.000155625804778

Epoch: 6| Step: 7
Training loss: 2.435342788696289
Validation loss: 2.0088366872520855

Epoch: 6| Step: 8
Training loss: 2.341226100921631
Validation loss: 2.007469964283769

Epoch: 6| Step: 9
Training loss: 1.3606817722320557
Validation loss: 1.9849140977346769

Epoch: 6| Step: 10
Training loss: 2.620748281478882
Validation loss: 1.9780045786211569

Epoch: 6| Step: 11
Training loss: 1.8601912260055542
Validation loss: 1.9802337461902249

Epoch: 6| Step: 12
Training loss: 2.4466145038604736
Validation loss: 1.9942688326681814

Epoch: 6| Step: 13
Training loss: 2.942906141281128
Validation loss: 2.0211554522155435

Epoch: 107| Step: 0
Training loss: 1.935703992843628
Validation loss: 2.049612068360852

Epoch: 6| Step: 1
Training loss: 2.699829578399658
Validation loss: 2.033774091351417

Epoch: 6| Step: 2
Training loss: 2.158247470855713
Validation loss: 2.0000029866413405

Epoch: 6| Step: 3
Training loss: 2.5942153930664062
Validation loss: 1.9948587776512228

Epoch: 6| Step: 4
Training loss: 1.9251177310943604
Validation loss: 1.9728178567783807

Epoch: 6| Step: 5
Training loss: 3.201627492904663
Validation loss: 1.9741378727779593

Epoch: 6| Step: 6
Training loss: 1.6607301235198975
Validation loss: 2.0005302352289998

Epoch: 6| Step: 7
Training loss: 2.168239116668701
Validation loss: 2.038933907785723

Epoch: 6| Step: 8
Training loss: 1.8445894718170166
Validation loss: 2.0531094471613565

Epoch: 6| Step: 9
Training loss: 1.7452707290649414
Validation loss: 2.0580040331809752

Epoch: 6| Step: 10
Training loss: 2.2267239093780518
Validation loss: 2.067426271336053

Epoch: 6| Step: 11
Training loss: 2.0025081634521484
Validation loss: 2.056364272230415

Epoch: 6| Step: 12
Training loss: 2.4261693954467773
Validation loss: 2.063959497277455

Epoch: 6| Step: 13
Training loss: 2.9792051315307617
Validation loss: 2.04279157423204

Epoch: 108| Step: 0
Training loss: 1.5185139179229736
Validation loss: 2.0275244456465527

Epoch: 6| Step: 1
Training loss: 2.243403911590576
Validation loss: 2.0290514628092446

Epoch: 6| Step: 2
Training loss: 2.446270227432251
Validation loss: 2.022056759044688

Epoch: 6| Step: 3
Training loss: 0.9924553632736206
Validation loss: 2.0088804691068587

Epoch: 6| Step: 4
Training loss: 1.8961129188537598
Validation loss: 1.997371260837842

Epoch: 6| Step: 5
Training loss: 2.3117804527282715
Validation loss: 1.9987559472360918

Epoch: 6| Step: 6
Training loss: 2.2327451705932617
Validation loss: 2.0016261685279106

Epoch: 6| Step: 7
Training loss: 2.5051591396331787
Validation loss: 1.990604910799252

Epoch: 6| Step: 8
Training loss: 2.874056339263916
Validation loss: 1.9912914217159312

Epoch: 6| Step: 9
Training loss: 2.222108840942383
Validation loss: 1.996082753263494

Epoch: 6| Step: 10
Training loss: 2.240792751312256
Validation loss: 1.9803653186367405

Epoch: 6| Step: 11
Training loss: 2.3160927295684814
Validation loss: 1.9938551725879792

Epoch: 6| Step: 12
Training loss: 2.394472122192383
Validation loss: 1.9846917121641097

Epoch: 6| Step: 13
Training loss: 2.4413485527038574
Validation loss: 1.9832539430228613

Epoch: 109| Step: 0
Training loss: 1.8777772188186646
Validation loss: 1.9906994347931237

Epoch: 6| Step: 1
Training loss: 1.5983495712280273
Validation loss: 1.9873376610458537

Epoch: 6| Step: 2
Training loss: 2.670366048812866
Validation loss: 1.9780698117389475

Epoch: 6| Step: 3
Training loss: 1.8784123659133911
Validation loss: 1.9874972745936403

Epoch: 6| Step: 4
Training loss: 0.7972519993782043
Validation loss: 1.9859871941228067

Epoch: 6| Step: 5
Training loss: 2.722479820251465
Validation loss: 1.9789709250132244

Epoch: 6| Step: 6
Training loss: 2.0673084259033203
Validation loss: 1.9933499315733552

Epoch: 6| Step: 7
Training loss: 2.4410858154296875
Validation loss: 1.9945185658752278

Epoch: 6| Step: 8
Training loss: 2.706995725631714
Validation loss: 2.0045618421287945

Epoch: 6| Step: 9
Training loss: 2.380825996398926
Validation loss: 2.013819662473535

Epoch: 6| Step: 10
Training loss: 2.4941587448120117
Validation loss: 2.034110751203311

Epoch: 6| Step: 11
Training loss: 2.5980329513549805
Validation loss: 2.0336608220172185

Epoch: 6| Step: 12
Training loss: 2.029201030731201
Validation loss: 2.033584448599046

Epoch: 6| Step: 13
Training loss: 1.9445089101791382
Validation loss: 2.0364041841158302

Epoch: 110| Step: 0
Training loss: 2.4363303184509277
Validation loss: 2.047928548628284

Epoch: 6| Step: 1
Training loss: 2.123660087585449
Validation loss: 2.0515511343556065

Epoch: 6| Step: 2
Training loss: 2.443615436553955
Validation loss: 2.06911539775069

Epoch: 6| Step: 3
Training loss: 2.053023338317871
Validation loss: 2.085243599389189

Epoch: 6| Step: 4
Training loss: 2.471285343170166
Validation loss: 2.0735453687688357

Epoch: 6| Step: 5
Training loss: 2.4126338958740234
Validation loss: 2.0606772079262683

Epoch: 6| Step: 6
Training loss: 1.7169289588928223
Validation loss: 2.0532427193016134

Epoch: 6| Step: 7
Training loss: 1.8576959371566772
Validation loss: 2.0540057164366528

Epoch: 6| Step: 8
Training loss: 2.0019145011901855
Validation loss: 2.0372813273501653

Epoch: 6| Step: 9
Training loss: 1.5461530685424805
Validation loss: 2.0465394707136255

Epoch: 6| Step: 10
Training loss: 1.910635232925415
Validation loss: 2.035348205156224

Epoch: 6| Step: 11
Training loss: 2.6260623931884766
Validation loss: 2.042548373181333

Epoch: 6| Step: 12
Training loss: 2.6346373558044434
Validation loss: 2.035918248597012

Epoch: 6| Step: 13
Training loss: 1.8790193796157837
Validation loss: 2.0355801659245647

Epoch: 111| Step: 0
Training loss: 1.9183820486068726
Validation loss: 2.039135698349245

Epoch: 6| Step: 1
Training loss: 2.1935319900512695
Validation loss: 2.0480610850036784

Epoch: 6| Step: 2
Training loss: 1.7820963859558105
Validation loss: 2.0724674501726703

Epoch: 6| Step: 3
Training loss: 3.012909412384033
Validation loss: 2.0972246816081386

Epoch: 6| Step: 4
Training loss: 2.1649513244628906
Validation loss: 2.114242733165782

Epoch: 6| Step: 5
Training loss: 2.1060972213745117
Validation loss: 2.0958427652235954

Epoch: 6| Step: 6
Training loss: 1.617983102798462
Validation loss: 2.0944876952837874

Epoch: 6| Step: 7
Training loss: 2.138643980026245
Validation loss: 2.080448176271172

Epoch: 6| Step: 8
Training loss: 2.000089168548584
Validation loss: 2.0541592926107426

Epoch: 6| Step: 9
Training loss: 2.433598279953003
Validation loss: 2.0427803095950874

Epoch: 6| Step: 10
Training loss: 2.410564661026001
Validation loss: 2.0365590485193397

Epoch: 6| Step: 11
Training loss: 2.4183149337768555
Validation loss: 2.008698086584768

Epoch: 6| Step: 12
Training loss: 1.5233455896377563
Validation loss: 1.9932233620715398

Epoch: 6| Step: 13
Training loss: 2.4809465408325195
Validation loss: 1.9842680795218355

Epoch: 112| Step: 0
Training loss: 2.0082106590270996
Validation loss: 1.9731668682508572

Epoch: 6| Step: 1
Training loss: 2.09468936920166
Validation loss: 1.963795756780973

Epoch: 6| Step: 2
Training loss: 1.7812401056289673
Validation loss: 1.9581460093939176

Epoch: 6| Step: 3
Training loss: 2.3080248832702637
Validation loss: 1.9716183818796629

Epoch: 6| Step: 4
Training loss: 2.147061824798584
Validation loss: 1.974554387472009

Epoch: 6| Step: 5
Training loss: 2.197174072265625
Validation loss: 1.9882871220188756

Epoch: 6| Step: 6
Training loss: 2.154860496520996
Validation loss: 2.0007407306342997

Epoch: 6| Step: 7
Training loss: 2.295786142349243
Validation loss: 1.9890470838034024

Epoch: 6| Step: 8
Training loss: 2.368877410888672
Validation loss: 1.9923746790937198

Epoch: 6| Step: 9
Training loss: 2.1247615814208984
Validation loss: 1.9930687706957582

Epoch: 6| Step: 10
Training loss: 2.399961471557617
Validation loss: 1.999285526173089

Epoch: 6| Step: 11
Training loss: 2.01857328414917
Validation loss: 2.0225052090101343

Epoch: 6| Step: 12
Training loss: 2.853206157684326
Validation loss: 2.025471674498691

Epoch: 6| Step: 13
Training loss: 1.29563570022583
Validation loss: 2.0513403287497898

Epoch: 113| Step: 0
Training loss: 1.7708494663238525
Validation loss: 2.0603153949142783

Epoch: 6| Step: 1
Training loss: 1.684565782546997
Validation loss: 2.0583025127328853

Epoch: 6| Step: 2
Training loss: 2.167792797088623
Validation loss: 2.04512482817455

Epoch: 6| Step: 3
Training loss: 2.284109115600586
Validation loss: 2.0363479468130294

Epoch: 6| Step: 4
Training loss: 2.828765869140625
Validation loss: 2.052128122698876

Epoch: 6| Step: 5
Training loss: 2.2607436180114746
Validation loss: 2.060785725552549

Epoch: 6| Step: 6
Training loss: 2.0161116123199463
Validation loss: 2.0892970895254486

Epoch: 6| Step: 7
Training loss: 2.142477512359619
Validation loss: 2.0840848979129585

Epoch: 6| Step: 8
Training loss: 2.2198166847229004
Validation loss: 2.046085887057807

Epoch: 6| Step: 9
Training loss: 1.644514560699463
Validation loss: 2.0502706548219085

Epoch: 6| Step: 10
Training loss: 2.072993278503418
Validation loss: 2.0297525710957025

Epoch: 6| Step: 11
Training loss: 2.344470977783203
Validation loss: 2.028792283868277

Epoch: 6| Step: 12
Training loss: 1.8981337547302246
Validation loss: 2.0217343389347033

Epoch: 6| Step: 13
Training loss: 2.799302577972412
Validation loss: 2.0154332140440583

Epoch: 114| Step: 0
Training loss: 1.7509863376617432
Validation loss: 2.0093869227235035

Epoch: 6| Step: 1
Training loss: 2.6423587799072266
Validation loss: 2.0141767737685994

Epoch: 6| Step: 2
Training loss: 2.3143668174743652
Validation loss: 2.0100015594113256

Epoch: 6| Step: 3
Training loss: 2.1929068565368652
Validation loss: 1.9908502832535775

Epoch: 6| Step: 4
Training loss: 1.670969009399414
Validation loss: 2.0009345380208825

Epoch: 6| Step: 5
Training loss: 1.4225184917449951
Validation loss: 2.0134793519973755

Epoch: 6| Step: 6
Training loss: 1.8100192546844482
Validation loss: 2.0273214309446272

Epoch: 6| Step: 7
Training loss: 2.661703109741211
Validation loss: 2.0903012419259674

Epoch: 6| Step: 8
Training loss: 2.365110397338867
Validation loss: 2.1407858799862605

Epoch: 6| Step: 9
Training loss: 2.507056713104248
Validation loss: 2.1977396549717074

Epoch: 6| Step: 10
Training loss: 2.1036465167999268
Validation loss: 2.1158154049227313

Epoch: 6| Step: 11
Training loss: 2.0310020446777344
Validation loss: 2.0406805751144246

Epoch: 6| Step: 12
Training loss: 2.763251304626465
Validation loss: 1.9901275762947657

Epoch: 6| Step: 13
Training loss: 1.9438230991363525
Validation loss: 1.9696463154208275

Epoch: 115| Step: 0
Training loss: 1.9146263599395752
Validation loss: 1.9715722171209191

Epoch: 6| Step: 1
Training loss: 2.109638214111328
Validation loss: 1.9794951561958558

Epoch: 6| Step: 2
Training loss: 1.5651836395263672
Validation loss: 1.98584335337403

Epoch: 6| Step: 3
Training loss: 2.957956075668335
Validation loss: 1.9904933232133106

Epoch: 6| Step: 4
Training loss: 2.239806652069092
Validation loss: 1.9930404411849154

Epoch: 6| Step: 5
Training loss: 1.662710189819336
Validation loss: 2.011010162291988

Epoch: 6| Step: 6
Training loss: 1.6682376861572266
Validation loss: 2.0002877622522335

Epoch: 6| Step: 7
Training loss: 2.1723506450653076
Validation loss: 2.036765726663733

Epoch: 6| Step: 8
Training loss: 2.312305450439453
Validation loss: 2.0257318276231007

Epoch: 6| Step: 9
Training loss: 2.6899914741516113
Validation loss: 2.0176029884687035

Epoch: 6| Step: 10
Training loss: 2.26020884513855
Validation loss: 2.042980173582672

Epoch: 6| Step: 11
Training loss: 2.0428199768066406
Validation loss: 2.097260848168404

Epoch: 6| Step: 12
Training loss: 1.7267473936080933
Validation loss: 2.156592510079825

Epoch: 6| Step: 13
Training loss: 3.0400640964508057
Validation loss: 2.225469896870275

Epoch: 116| Step: 0
Training loss: 2.6786768436431885
Validation loss: 2.2526864236400974

Epoch: 6| Step: 1
Training loss: 2.4006359577178955
Validation loss: 2.2615340012376026

Epoch: 6| Step: 2
Training loss: 1.7930420637130737
Validation loss: 2.151876944367604

Epoch: 6| Step: 3
Training loss: 2.7341623306274414
Validation loss: 2.0583349594505886

Epoch: 6| Step: 4
Training loss: 2.2731943130493164
Validation loss: 2.0040718137577014

Epoch: 6| Step: 5
Training loss: 2.239938497543335
Validation loss: 1.978258325207618

Epoch: 6| Step: 6
Training loss: 2.0890049934387207
Validation loss: 1.9818342539571947

Epoch: 6| Step: 7
Training loss: 1.8467652797698975
Validation loss: 1.9734269701024538

Epoch: 6| Step: 8
Training loss: 2.2098302841186523
Validation loss: 1.991702752728616

Epoch: 6| Step: 9
Training loss: 1.5099718570709229
Validation loss: 2.0313393121124594

Epoch: 6| Step: 10
Training loss: 2.5766570568084717
Validation loss: 2.098486050482719

Epoch: 6| Step: 11
Training loss: 1.9282783269882202
Validation loss: 2.1659339909912436

Epoch: 6| Step: 12
Training loss: 2.175896167755127
Validation loss: 2.1833224501661075

Epoch: 6| Step: 13
Training loss: 2.9160714149475098
Validation loss: 2.1802718101009244

Epoch: 117| Step: 0
Training loss: 1.7910780906677246
Validation loss: 2.1161044618134857

Epoch: 6| Step: 1
Training loss: 2.135826587677002
Validation loss: 2.0745471190380793

Epoch: 6| Step: 2
Training loss: 2.3934969902038574
Validation loss: 2.066546323478863

Epoch: 6| Step: 3
Training loss: 1.4991741180419922
Validation loss: 2.0530870127421554

Epoch: 6| Step: 4
Training loss: 2.5099880695343018
Validation loss: 2.0516754324718187

Epoch: 6| Step: 5
Training loss: 1.2630681991577148
Validation loss: 2.034773721489855

Epoch: 6| Step: 6
Training loss: 2.670215606689453
Validation loss: 2.0435682547989713

Epoch: 6| Step: 7
Training loss: 1.5537631511688232
Validation loss: 2.041090960143715

Epoch: 6| Step: 8
Training loss: 1.7540146112442017
Validation loss: 2.061105497421757

Epoch: 6| Step: 9
Training loss: 2.911259651184082
Validation loss: 2.0447980268027193

Epoch: 6| Step: 10
Training loss: 2.2019526958465576
Validation loss: 2.037695621931425

Epoch: 6| Step: 11
Training loss: 2.819476842880249
Validation loss: 2.0325504015850764

Epoch: 6| Step: 12
Training loss: 2.164102792739868
Validation loss: 2.025659240702147

Epoch: 6| Step: 13
Training loss: 1.879554271697998
Validation loss: 2.007413605208038

Epoch: 118| Step: 0
Training loss: 2.00380277633667
Validation loss: 2.015241822888774

Epoch: 6| Step: 1
Training loss: 2.7451424598693848
Validation loss: 2.0190218212783977

Epoch: 6| Step: 2
Training loss: 1.4341309070587158
Validation loss: 2.034448613402664

Epoch: 6| Step: 3
Training loss: 2.4915146827697754
Validation loss: 2.054304028070101

Epoch: 6| Step: 4
Training loss: 1.9972329139709473
Validation loss: 2.035935701862458

Epoch: 6| Step: 5
Training loss: 1.759722113609314
Validation loss: 2.0178397881087435

Epoch: 6| Step: 6
Training loss: 1.9440317153930664
Validation loss: 2.025465953734613

Epoch: 6| Step: 7
Training loss: 2.1223621368408203
Validation loss: 2.0257598841062157

Epoch: 6| Step: 8
Training loss: 2.754310131072998
Validation loss: 2.0248992007265807

Epoch: 6| Step: 9
Training loss: 1.0012164115905762
Validation loss: 2.0522907600607923

Epoch: 6| Step: 10
Training loss: 2.089083433151245
Validation loss: 2.050883639243341

Epoch: 6| Step: 11
Training loss: 2.268287181854248
Validation loss: 2.039030184027969

Epoch: 6| Step: 12
Training loss: 2.804849863052368
Validation loss: 2.0353214176752235

Epoch: 6| Step: 13
Training loss: 2.021132230758667
Validation loss: 2.038517721237675

Epoch: 119| Step: 0
Training loss: 1.896216630935669
Validation loss: 2.02932128085885

Epoch: 6| Step: 1
Training loss: 2.2490785121917725
Validation loss: 2.0390830424524125

Epoch: 6| Step: 2
Training loss: 2.629173994064331
Validation loss: 2.0615713237434306

Epoch: 6| Step: 3
Training loss: 2.2599287033081055
Validation loss: 2.090747130814419

Epoch: 6| Step: 4
Training loss: 2.116006851196289
Validation loss: 2.1148533923651582

Epoch: 6| Step: 5
Training loss: 2.003030776977539
Validation loss: 2.1441531565881546

Epoch: 6| Step: 6
Training loss: 1.8630611896514893
Validation loss: 2.1390527730347006

Epoch: 6| Step: 7
Training loss: 1.7521121501922607
Validation loss: 2.133594610357797

Epoch: 6| Step: 8
Training loss: 2.1709275245666504
Validation loss: 2.1052874108796478

Epoch: 6| Step: 9
Training loss: 2.367114543914795
Validation loss: 2.099726706422785

Epoch: 6| Step: 10
Training loss: 2.0701940059661865
Validation loss: 2.095531250840874

Epoch: 6| Step: 11
Training loss: 2.428229808807373
Validation loss: 2.0577049511735157

Epoch: 6| Step: 12
Training loss: 1.5416476726531982
Validation loss: 2.0351552732529177

Epoch: 6| Step: 13
Training loss: 2.4838016033172607
Validation loss: 2.0114282395250056

Epoch: 120| Step: 0
Training loss: 2.41795015335083
Validation loss: 1.9893345217550955

Epoch: 6| Step: 1
Training loss: 1.6971004009246826
Validation loss: 1.9820240902644333

Epoch: 6| Step: 2
Training loss: 2.2925925254821777
Validation loss: 1.977710534167546

Epoch: 6| Step: 3
Training loss: 1.7762160301208496
Validation loss: 1.98228713773912

Epoch: 6| Step: 4
Training loss: 2.290933609008789
Validation loss: 1.9989789711531771

Epoch: 6| Step: 5
Training loss: 1.6840206384658813
Validation loss: 1.9866913377597768

Epoch: 6| Step: 6
Training loss: 2.448154926300049
Validation loss: 1.988627810632029

Epoch: 6| Step: 7
Training loss: 1.7327396869659424
Validation loss: 1.9742704283806585

Epoch: 6| Step: 8
Training loss: 2.148138999938965
Validation loss: 1.986560090895622

Epoch: 6| Step: 9
Training loss: 2.149296283721924
Validation loss: 1.9830022960580804

Epoch: 6| Step: 10
Training loss: 1.885170578956604
Validation loss: 2.0099426315676783

Epoch: 6| Step: 11
Training loss: 2.003371477127075
Validation loss: 2.0308635798833703

Epoch: 6| Step: 12
Training loss: 2.575934410095215
Validation loss: 2.0494307215495775

Epoch: 6| Step: 13
Training loss: 2.1116244792938232
Validation loss: 2.046992906960108

Epoch: 121| Step: 0
Training loss: 2.13865065574646
Validation loss: 2.033163865407308

Epoch: 6| Step: 1
Training loss: 1.9485571384429932
Validation loss: 2.0267159733721005

Epoch: 6| Step: 2
Training loss: 2.023449659347534
Validation loss: 1.9944048696948635

Epoch: 6| Step: 3
Training loss: 1.4312994480133057
Validation loss: 1.9902970124316472

Epoch: 6| Step: 4
Training loss: 1.8950698375701904
Validation loss: 2.010379155476888

Epoch: 6| Step: 5
Training loss: 2.2487502098083496
Validation loss: 2.0219228139487644

Epoch: 6| Step: 6
Training loss: 2.026599407196045
Validation loss: 2.0394936556457193

Epoch: 6| Step: 7
Training loss: 1.0116186141967773
Validation loss: 2.0406135974391812

Epoch: 6| Step: 8
Training loss: 2.7372429370880127
Validation loss: 2.058778178307318

Epoch: 6| Step: 9
Training loss: 1.7461285591125488
Validation loss: 2.0529753303015106

Epoch: 6| Step: 10
Training loss: 2.648926258087158
Validation loss: 2.0488836201288367

Epoch: 6| Step: 11
Training loss: 2.1460790634155273
Validation loss: 2.0593411076453423

Epoch: 6| Step: 12
Training loss: 2.2809207439422607
Validation loss: 2.087758841053132

Epoch: 6| Step: 13
Training loss: 2.938934564590454
Validation loss: 2.1142406463623047

Epoch: 122| Step: 0
Training loss: 2.1553597450256348
Validation loss: 2.0861578526035434

Epoch: 6| Step: 1
Training loss: 2.302669048309326
Validation loss: 2.0321457296289425

Epoch: 6| Step: 2
Training loss: 2.0235519409179688
Validation loss: 2.017887394915345

Epoch: 6| Step: 3
Training loss: 2.562521457672119
Validation loss: 1.9864868835736347

Epoch: 6| Step: 4
Training loss: 1.828646183013916
Validation loss: 1.9792767173500472

Epoch: 6| Step: 5
Training loss: 2.3045873641967773
Validation loss: 1.9666428578797208

Epoch: 6| Step: 6
Training loss: 2.183220148086548
Validation loss: 1.977365973175213

Epoch: 6| Step: 7
Training loss: 2.2853100299835205
Validation loss: 1.968928119187714

Epoch: 6| Step: 8
Training loss: 1.6321996450424194
Validation loss: 1.9705533199412848

Epoch: 6| Step: 9
Training loss: 2.0553040504455566
Validation loss: 1.9620131754106092

Epoch: 6| Step: 10
Training loss: 1.151200532913208
Validation loss: 1.9594185685598722

Epoch: 6| Step: 11
Training loss: 2.0007171630859375
Validation loss: 1.9586907817471413

Epoch: 6| Step: 12
Training loss: 2.012230157852173
Validation loss: 1.9529969141047487

Epoch: 6| Step: 13
Training loss: 2.322585344314575
Validation loss: 1.964682138094338

Epoch: 123| Step: 0
Training loss: 1.3698737621307373
Validation loss: 1.9629077565285467

Epoch: 6| Step: 1
Training loss: 1.9139013290405273
Validation loss: 1.9702137093390188

Epoch: 6| Step: 2
Training loss: 1.7067761421203613
Validation loss: 1.9734516246344453

Epoch: 6| Step: 3
Training loss: 2.778223991394043
Validation loss: 1.9714863172141455

Epoch: 6| Step: 4
Training loss: 1.7993011474609375
Validation loss: 1.9915823449370682

Epoch: 6| Step: 5
Training loss: 1.9862397909164429
Validation loss: 1.9888682467963106

Epoch: 6| Step: 6
Training loss: 1.8044242858886719
Validation loss: 1.9948733083663448

Epoch: 6| Step: 7
Training loss: 2.5851802825927734
Validation loss: 2.0132280588150024

Epoch: 6| Step: 8
Training loss: 2.0140771865844727
Validation loss: 2.0288326509537233

Epoch: 6| Step: 9
Training loss: 1.9187500476837158
Validation loss: 2.0464353215309883

Epoch: 6| Step: 10
Training loss: 2.0438804626464844
Validation loss: 2.0560387911335116

Epoch: 6| Step: 11
Training loss: 1.7821199893951416
Validation loss: 2.0667282176274124

Epoch: 6| Step: 12
Training loss: 2.0751595497131348
Validation loss: 2.048399154857923

Epoch: 6| Step: 13
Training loss: 2.322756052017212
Validation loss: 2.058192572286052

Epoch: 124| Step: 0
Training loss: 1.5740225315093994
Validation loss: 2.0383458522058304

Epoch: 6| Step: 1
Training loss: 2.148921012878418
Validation loss: 2.018840969249766

Epoch: 6| Step: 2
Training loss: 1.3323137760162354
Validation loss: 2.010017523201563

Epoch: 6| Step: 3
Training loss: 1.9910560846328735
Validation loss: 1.997420516065372

Epoch: 6| Step: 4
Training loss: 2.3353142738342285
Validation loss: 1.990628388620192

Epoch: 6| Step: 5
Training loss: 1.5091159343719482
Validation loss: 1.977903332761539

Epoch: 6| Step: 6
Training loss: 1.805962324142456
Validation loss: 1.985587227729059

Epoch: 6| Step: 7
Training loss: 2.3561387062072754
Validation loss: 1.9799027417295723

Epoch: 6| Step: 8
Training loss: 2.1264805793762207
Validation loss: 1.9833356244589693

Epoch: 6| Step: 9
Training loss: 2.3310821056365967
Validation loss: 1.9798623695168445

Epoch: 6| Step: 10
Training loss: 2.393012523651123
Validation loss: 2.006050850755425

Epoch: 6| Step: 11
Training loss: 1.7801387310028076
Validation loss: 2.0176739167141657

Epoch: 6| Step: 12
Training loss: 1.995969295501709
Validation loss: 2.0219075846415695

Epoch: 6| Step: 13
Training loss: 2.151890277862549
Validation loss: 2.0551924551686933

Epoch: 125| Step: 0
Training loss: 1.728650450706482
Validation loss: 2.096904605947515

Epoch: 6| Step: 1
Training loss: 2.704514503479004
Validation loss: 2.117293096357776

Epoch: 6| Step: 2
Training loss: 2.1637041568756104
Validation loss: 2.1081653154024513

Epoch: 6| Step: 3
Training loss: 2.3100390434265137
Validation loss: 2.0753552247119207

Epoch: 6| Step: 4
Training loss: 1.1334974765777588
Validation loss: 2.063562584179704

Epoch: 6| Step: 5
Training loss: 1.8656573295593262
Validation loss: 2.0421796357759865

Epoch: 6| Step: 6
Training loss: 2.210108995437622
Validation loss: 2.018983805051414

Epoch: 6| Step: 7
Training loss: 2.0541701316833496
Validation loss: 1.9998262543832102

Epoch: 6| Step: 8
Training loss: 1.993523120880127
Validation loss: 1.992350391162339

Epoch: 6| Step: 9
Training loss: 1.2700841426849365
Validation loss: 1.993652412968297

Epoch: 6| Step: 10
Training loss: 2.0674891471862793
Validation loss: 1.9964476118805587

Epoch: 6| Step: 11
Training loss: 2.3369083404541016
Validation loss: 1.993356732911961

Epoch: 6| Step: 12
Training loss: 1.8470975160598755
Validation loss: 2.0008356032832975

Epoch: 6| Step: 13
Training loss: 2.3479089736938477
Validation loss: 2.00096115245614

Epoch: 126| Step: 0
Training loss: 2.2237462997436523
Validation loss: 2.020409109771893

Epoch: 6| Step: 1
Training loss: 2.820279598236084
Validation loss: 2.016615216450025

Epoch: 6| Step: 2
Training loss: 1.351196527481079
Validation loss: 2.044568520720287

Epoch: 6| Step: 3
Training loss: 1.9543781280517578
Validation loss: 2.0700671083183697

Epoch: 6| Step: 4
Training loss: 2.1857550144195557
Validation loss: 2.0915753918309368

Epoch: 6| Step: 5
Training loss: 1.9473249912261963
Validation loss: 2.111216313095503

Epoch: 6| Step: 6
Training loss: 2.251905679702759
Validation loss: 2.149581468233498

Epoch: 6| Step: 7
Training loss: 2.021718978881836
Validation loss: 2.123434620518838

Epoch: 6| Step: 8
Training loss: 1.7240957021713257
Validation loss: 2.0704201062520347

Epoch: 6| Step: 9
Training loss: 1.5259029865264893
Validation loss: 2.053602131464148

Epoch: 6| Step: 10
Training loss: 2.1901888847351074
Validation loss: 2.014322534684212

Epoch: 6| Step: 11
Training loss: 1.7912296056747437
Validation loss: 1.9827940592201807

Epoch: 6| Step: 12
Training loss: 1.6754627227783203
Validation loss: 1.9598164045682518

Epoch: 6| Step: 13
Training loss: 2.1799910068511963
Validation loss: 1.9667664202310706

Epoch: 127| Step: 0
Training loss: 0.8632953763008118
Validation loss: 1.9649137937894432

Epoch: 6| Step: 1
Training loss: 1.578034520149231
Validation loss: 1.98492524444416

Epoch: 6| Step: 2
Training loss: 2.5335912704467773
Validation loss: 2.009604420713199

Epoch: 6| Step: 3
Training loss: 2.081465244293213
Validation loss: 2.0227875965897755

Epoch: 6| Step: 4
Training loss: 2.0279979705810547
Validation loss: 2.027687129154

Epoch: 6| Step: 5
Training loss: 2.3173165321350098
Validation loss: 2.0385234445653935

Epoch: 6| Step: 6
Training loss: 1.3970811367034912
Validation loss: 2.047263806866061

Epoch: 6| Step: 7
Training loss: 2.2175421714782715
Validation loss: 2.0535070229602117

Epoch: 6| Step: 8
Training loss: 1.5653140544891357
Validation loss: 2.0751810227670977

Epoch: 6| Step: 9
Training loss: 2.326845169067383
Validation loss: 2.0932280248211277

Epoch: 6| Step: 10
Training loss: 2.0057523250579834
Validation loss: 2.1174942601111626

Epoch: 6| Step: 11
Training loss: 2.5527496337890625
Validation loss: 2.1533375786196802

Epoch: 6| Step: 12
Training loss: 1.4394609928131104
Validation loss: 2.1640060870878157

Epoch: 6| Step: 13
Training loss: 2.388927459716797
Validation loss: 2.156554442580028

Epoch: 128| Step: 0
Training loss: 2.066222667694092
Validation loss: 2.1178084009437153

Epoch: 6| Step: 1
Training loss: 2.0229058265686035
Validation loss: 2.0719498613829255

Epoch: 6| Step: 2
Training loss: 1.34293532371521
Validation loss: 2.0402179046343734

Epoch: 6| Step: 3
Training loss: 1.6135084629058838
Validation loss: 2.0114819003689672

Epoch: 6| Step: 4
Training loss: 1.9570798873901367
Validation loss: 2.003975204242173

Epoch: 6| Step: 5
Training loss: 3.0278797149658203
Validation loss: 2.011938150211047

Epoch: 6| Step: 6
Training loss: 2.472501754760742
Validation loss: 1.9769062380636893

Epoch: 6| Step: 7
Training loss: 1.995213270187378
Validation loss: 1.943568545003091

Epoch: 6| Step: 8
Training loss: 2.2155861854553223
Validation loss: 1.9163346841771116

Epoch: 6| Step: 9
Training loss: 1.872239589691162
Validation loss: 1.9257441682200278

Epoch: 6| Step: 10
Training loss: 2.0801632404327393
Validation loss: 1.9853828312248312

Epoch: 6| Step: 11
Training loss: 1.8820714950561523
Validation loss: 2.0124116046454317

Epoch: 6| Step: 12
Training loss: 1.8591704368591309
Validation loss: 2.0443612939567974

Epoch: 6| Step: 13
Training loss: 1.7508960962295532
Validation loss: 2.115831503304102

Epoch: 129| Step: 0
Training loss: 1.6222140789031982
Validation loss: 2.1292116488179853

Epoch: 6| Step: 1
Training loss: 1.8575429916381836
Validation loss: 2.1212933730053645

Epoch: 6| Step: 2
Training loss: 2.5586657524108887
Validation loss: 2.1196044132273686

Epoch: 6| Step: 3
Training loss: 2.2470831871032715
Validation loss: 2.1495567573014127

Epoch: 6| Step: 4
Training loss: 1.7705051898956299
Validation loss: 2.1349311797849593

Epoch: 6| Step: 5
Training loss: 2.208486557006836
Validation loss: 2.122048008826471

Epoch: 6| Step: 6
Training loss: 1.5446124076843262
Validation loss: 2.0823789899067213

Epoch: 6| Step: 7
Training loss: 2.1926755905151367
Validation loss: 2.0920308789899273

Epoch: 6| Step: 8
Training loss: 2.5912604331970215
Validation loss: 2.103933001077303

Epoch: 6| Step: 9
Training loss: 1.8043761253356934
Validation loss: 2.091422486048873

Epoch: 6| Step: 10
Training loss: 1.3235669136047363
Validation loss: 2.0794825887167327

Epoch: 6| Step: 11
Training loss: 1.766802191734314
Validation loss: 2.0577151493359636

Epoch: 6| Step: 12
Training loss: 2.2363476753234863
Validation loss: 2.028961637968658

Epoch: 6| Step: 13
Training loss: 1.5422799587249756
Validation loss: 2.0258588765257146

Epoch: 130| Step: 0
Training loss: 2.1472885608673096
Validation loss: 2.0369441150337138

Epoch: 6| Step: 1
Training loss: 1.819725513458252
Validation loss: 2.055258140769056

Epoch: 6| Step: 2
Training loss: 1.7544068098068237
Validation loss: 2.103138610880862

Epoch: 6| Step: 3
Training loss: 1.5060386657714844
Validation loss: 2.1664585862108456

Epoch: 6| Step: 4
Training loss: 1.6336548328399658
Validation loss: 2.21661695613656

Epoch: 6| Step: 5
Training loss: 1.9368009567260742
Validation loss: 2.2305897320470502

Epoch: 6| Step: 6
Training loss: 1.5596623420715332
Validation loss: 2.1711622284304712

Epoch: 6| Step: 7
Training loss: 1.935331106185913
Validation loss: 2.1004539458982405

Epoch: 6| Step: 8
Training loss: 2.812788248062134
Validation loss: 2.0578763254227175

Epoch: 6| Step: 9
Training loss: 2.5691733360290527
Validation loss: 2.011139738944269

Epoch: 6| Step: 10
Training loss: 1.986986756324768
Validation loss: 1.9960930065442157

Epoch: 6| Step: 11
Training loss: 2.1324071884155273
Validation loss: 1.9958829008122927

Epoch: 6| Step: 12
Training loss: 2.490821361541748
Validation loss: 2.0001651087114887

Epoch: 6| Step: 13
Training loss: 1.444562554359436
Validation loss: 1.9907637578184887

Epoch: 131| Step: 0
Training loss: 2.603729248046875
Validation loss: 1.9688710499835271

Epoch: 6| Step: 1
Training loss: 1.7455419301986694
Validation loss: 1.9654399976935437

Epoch: 6| Step: 2
Training loss: 1.9817934036254883
Validation loss: 1.9596757722157303

Epoch: 6| Step: 3
Training loss: 2.1260509490966797
Validation loss: 1.9745522840048677

Epoch: 6| Step: 4
Training loss: 1.8482706546783447
Validation loss: 1.9659665887073805

Epoch: 6| Step: 5
Training loss: 1.1156264543533325
Validation loss: 1.9848405981576571

Epoch: 6| Step: 6
Training loss: 1.5953686237335205
Validation loss: 2.0160695416952974

Epoch: 6| Step: 7
Training loss: 2.002047538757324
Validation loss: 2.019700188790598

Epoch: 6| Step: 8
Training loss: 2.1203770637512207
Validation loss: 2.0345452472727787

Epoch: 6| Step: 9
Training loss: 2.183356761932373
Validation loss: 2.053358899649753

Epoch: 6| Step: 10
Training loss: 1.8497226238250732
Validation loss: 2.0632667259503434

Epoch: 6| Step: 11
Training loss: 2.4038755893707275
Validation loss: 2.069509470334617

Epoch: 6| Step: 12
Training loss: 1.4386382102966309
Validation loss: 2.0759194102338565

Epoch: 6| Step: 13
Training loss: 1.33103346824646
Validation loss: 2.0603019627191688

Epoch: 132| Step: 0
Training loss: 1.6285208463668823
Validation loss: 2.051608452232935

Epoch: 6| Step: 1
Training loss: 2.5017709732055664
Validation loss: 2.0666967027930805

Epoch: 6| Step: 2
Training loss: 1.8520268201828003
Validation loss: 2.071948209116536

Epoch: 6| Step: 3
Training loss: 2.7029826641082764
Validation loss: 2.086391810447939

Epoch: 6| Step: 4
Training loss: 2.610398769378662
Validation loss: 2.0820943642688055

Epoch: 6| Step: 5
Training loss: 1.2533199787139893
Validation loss: 2.0686738273148895

Epoch: 6| Step: 6
Training loss: 1.8715040683746338
Validation loss: 2.075506173154359

Epoch: 6| Step: 7
Training loss: 1.228745698928833
Validation loss: 2.068609783726354

Epoch: 6| Step: 8
Training loss: 1.940643548965454
Validation loss: 2.05319502276759

Epoch: 6| Step: 9
Training loss: 1.7181835174560547
Validation loss: 2.0250647529478996

Epoch: 6| Step: 10
Training loss: 1.8390133380889893
Validation loss: 2.0011836495450748

Epoch: 6| Step: 11
Training loss: 1.7620341777801514
Validation loss: 1.9743230445410616

Epoch: 6| Step: 12
Training loss: 1.638042688369751
Validation loss: 1.9709664108932659

Epoch: 6| Step: 13
Training loss: 1.9811749458312988
Validation loss: 1.9549985803583616

Epoch: 133| Step: 0
Training loss: 1.531076431274414
Validation loss: 1.9389685277015931

Epoch: 6| Step: 1
Training loss: 2.5752124786376953
Validation loss: 1.9268750593226442

Epoch: 6| Step: 2
Training loss: 1.9885375499725342
Validation loss: 1.908947681867948

Epoch: 6| Step: 3
Training loss: 2.2122654914855957
Validation loss: 1.9160508673678163

Epoch: 6| Step: 4
Training loss: 2.1239781379699707
Validation loss: 1.913018129205191

Epoch: 6| Step: 5
Training loss: 1.813889980316162
Validation loss: 1.9209681146888322

Epoch: 6| Step: 6
Training loss: 1.5592143535614014
Validation loss: 1.938049413824594

Epoch: 6| Step: 7
Training loss: 1.0884453058242798
Validation loss: 1.9957408366664764

Epoch: 6| Step: 8
Training loss: 1.8962419033050537
Validation loss: 2.01883166451608

Epoch: 6| Step: 9
Training loss: 2.4668378829956055
Validation loss: 2.09453434072515

Epoch: 6| Step: 10
Training loss: 1.8244589567184448
Validation loss: 2.1735727992109073

Epoch: 6| Step: 11
Training loss: 1.393723964691162
Validation loss: 2.1512713252857165

Epoch: 6| Step: 12
Training loss: 2.497962474822998
Validation loss: 2.109313331624513

Epoch: 6| Step: 13
Training loss: 1.2504929304122925
Validation loss: 2.1123811634637977

Epoch: 134| Step: 0
Training loss: 2.0018022060394287
Validation loss: 2.0814114245035316

Epoch: 6| Step: 1
Training loss: 2.249814510345459
Validation loss: 2.0719369239704584

Epoch: 6| Step: 2
Training loss: 1.5914055109024048
Validation loss: 2.0577994367127777

Epoch: 6| Step: 3
Training loss: 1.6119868755340576
Validation loss: 2.044021567990703

Epoch: 6| Step: 4
Training loss: 1.721853494644165
Validation loss: 2.041009808099398

Epoch: 6| Step: 5
Training loss: 1.5304086208343506
Validation loss: 2.070098420625092

Epoch: 6| Step: 6
Training loss: 1.8412330150604248
Validation loss: 2.055278751157945

Epoch: 6| Step: 7
Training loss: 1.9664528369903564
Validation loss: 2.0725679307855587

Epoch: 6| Step: 8
Training loss: 2.5327181816101074
Validation loss: 2.0745980380683817

Epoch: 6| Step: 9
Training loss: 1.7980222702026367
Validation loss: 2.0702949775162565

Epoch: 6| Step: 10
Training loss: 1.3248827457427979
Validation loss: 2.0432296619620374

Epoch: 6| Step: 11
Training loss: 2.341486930847168
Validation loss: 2.028561617738457

Epoch: 6| Step: 12
Training loss: 1.8968416452407837
Validation loss: 2.031900103374194

Epoch: 6| Step: 13
Training loss: 2.07423996925354
Validation loss: 2.0565113636755172

Epoch: 135| Step: 0
Training loss: 1.8811819553375244
Validation loss: 2.042405665561717

Epoch: 6| Step: 1
Training loss: 1.51912522315979
Validation loss: 2.023485832316901

Epoch: 6| Step: 2
Training loss: 2.0904757976531982
Validation loss: 1.9849152411184003

Epoch: 6| Step: 3
Training loss: 1.9065892696380615
Validation loss: 1.9846908661627

Epoch: 6| Step: 4
Training loss: 1.7787033319473267
Validation loss: 1.9924200157965384

Epoch: 6| Step: 5
Training loss: 1.958823800086975
Validation loss: 2.0066583566768195

Epoch: 6| Step: 6
Training loss: 1.8094744682312012
Validation loss: 2.016519800309212

Epoch: 6| Step: 7
Training loss: 1.7180424928665161
Validation loss: 2.026306067743609

Epoch: 6| Step: 8
Training loss: 2.1604814529418945
Validation loss: 2.037073116148672

Epoch: 6| Step: 9
Training loss: 1.3364317417144775
Validation loss: 2.035419928130283

Epoch: 6| Step: 10
Training loss: 2.0677099227905273
Validation loss: 2.0174195035811393

Epoch: 6| Step: 11
Training loss: 1.7348865270614624
Validation loss: 2.0227211598427064

Epoch: 6| Step: 12
Training loss: 2.32261323928833
Validation loss: 2.0294894454299763

Epoch: 6| Step: 13
Training loss: 1.946248173713684
Validation loss: 2.055119493956207

Epoch: 136| Step: 0
Training loss: 1.4080451726913452
Validation loss: 2.0861398789190475

Epoch: 6| Step: 1
Training loss: 2.1807098388671875
Validation loss: 2.1585906308184386

Epoch: 6| Step: 2
Training loss: 2.7437644004821777
Validation loss: 2.1645781173500964

Epoch: 6| Step: 3
Training loss: 1.7649784088134766
Validation loss: 2.1429847517321186

Epoch: 6| Step: 4
Training loss: 1.4939510822296143
Validation loss: 2.0741810952463458

Epoch: 6| Step: 5
Training loss: 1.2829010486602783
Validation loss: 2.050679878521991

Epoch: 6| Step: 6
Training loss: 1.4013465642929077
Validation loss: 2.0215686521222516

Epoch: 6| Step: 7
Training loss: 2.2648842334747314
Validation loss: 2.0408486589308708

Epoch: 6| Step: 8
Training loss: 1.1754997968673706
Validation loss: 2.052565381091128

Epoch: 6| Step: 9
Training loss: 1.6647140979766846
Validation loss: 2.0811845487163914

Epoch: 6| Step: 10
Training loss: 3.4036026000976562
Validation loss: 2.072815433625252

Epoch: 6| Step: 11
Training loss: 1.8363449573516846
Validation loss: 2.062427246442405

Epoch: 6| Step: 12
Training loss: 1.5027318000793457
Validation loss: 2.0534921000080724

Epoch: 6| Step: 13
Training loss: 2.5107967853546143
Validation loss: 2.0621156423322615

Epoch: 137| Step: 0
Training loss: 2.342329978942871
Validation loss: 2.0725840112214446

Epoch: 6| Step: 1
Training loss: 2.535229444503784
Validation loss: 2.075730321227863

Epoch: 6| Step: 2
Training loss: 1.2529926300048828
Validation loss: 2.0879514550649994

Epoch: 6| Step: 3
Training loss: 1.25589120388031
Validation loss: 2.116292906063859

Epoch: 6| Step: 4
Training loss: 1.5562069416046143
Validation loss: 2.1399081471145793

Epoch: 6| Step: 5
Training loss: 2.1073381900787354
Validation loss: 2.118482474357851

Epoch: 6| Step: 6
Training loss: 2.5275325775146484
Validation loss: 2.077781083763287

Epoch: 6| Step: 7
Training loss: 1.776588797569275
Validation loss: 2.009428688274917

Epoch: 6| Step: 8
Training loss: 1.2925803661346436
Validation loss: 1.9983675428616103

Epoch: 6| Step: 9
Training loss: 2.05954647064209
Validation loss: 2.004431209256572

Epoch: 6| Step: 10
Training loss: 2.255920171737671
Validation loss: 2.069612164651194

Epoch: 6| Step: 11
Training loss: 1.4342100620269775
Validation loss: 2.0810814557536954

Epoch: 6| Step: 12
Training loss: 1.7505525350570679
Validation loss: 2.0697048902511597

Epoch: 6| Step: 13
Training loss: 1.5957605838775635
Validation loss: 2.0607581446247716

Epoch: 138| Step: 0
Training loss: 1.4369921684265137
Validation loss: 2.03403054898785

Epoch: 6| Step: 1
Training loss: 2.5173637866973877
Validation loss: 2.0040818247743832

Epoch: 6| Step: 2
Training loss: 1.7887321710586548
Validation loss: 1.956194321314494

Epoch: 6| Step: 3
Training loss: 1.251500129699707
Validation loss: 1.9577255313114454

Epoch: 6| Step: 4
Training loss: 2.042961359024048
Validation loss: 1.9501974646763136

Epoch: 6| Step: 5
Training loss: 1.7222331762313843
Validation loss: 1.9642748345610916

Epoch: 6| Step: 6
Training loss: 1.7002720832824707
Validation loss: 1.9828263739103913

Epoch: 6| Step: 7
Training loss: 2.0428214073181152
Validation loss: 2.013572541616296

Epoch: 6| Step: 8
Training loss: 2.344709634780884
Validation loss: 2.018380400955036

Epoch: 6| Step: 9
Training loss: 1.929906964302063
Validation loss: 2.0190714905338902

Epoch: 6| Step: 10
Training loss: 1.8462705612182617
Validation loss: 2.042986072519774

Epoch: 6| Step: 11
Training loss: 2.1156349182128906
Validation loss: 2.07695508515963

Epoch: 6| Step: 12
Training loss: 1.8868807554244995
Validation loss: 2.1181304249712216

Epoch: 6| Step: 13
Training loss: 1.5738518238067627
Validation loss: 2.150310206156905

Epoch: 139| Step: 0
Training loss: 2.3586769104003906
Validation loss: 2.1181088262988674

Epoch: 6| Step: 1
Training loss: 1.7473760843276978
Validation loss: 2.1149804784405615

Epoch: 6| Step: 2
Training loss: 1.8078300952911377
Validation loss: 2.1320790219050583

Epoch: 6| Step: 3
Training loss: 1.894178867340088
Validation loss: 2.122968727542508

Epoch: 6| Step: 4
Training loss: 2.0224666595458984
Validation loss: 2.0681414860551075

Epoch: 6| Step: 5
Training loss: 1.5596632957458496
Validation loss: 2.0370371110977663

Epoch: 6| Step: 6
Training loss: 1.6965641975402832
Validation loss: 1.9774451614708028

Epoch: 6| Step: 7
Training loss: 1.6688721179962158
Validation loss: 1.9903232243753248

Epoch: 6| Step: 8
Training loss: 2.5492029190063477
Validation loss: 2.0049994504579933

Epoch: 6| Step: 9
Training loss: 1.5843422412872314
Validation loss: 2.023343713052811

Epoch: 6| Step: 10
Training loss: 1.9015376567840576
Validation loss: 2.0772724869430705

Epoch: 6| Step: 11
Training loss: 1.7312707901000977
Validation loss: 2.108887836497317

Epoch: 6| Step: 12
Training loss: 1.575904369354248
Validation loss: 2.1108680514879126

Epoch: 6| Step: 13
Training loss: 1.9154845476150513
Validation loss: 2.1149426660230084

Epoch: 140| Step: 0
Training loss: 1.325688362121582
Validation loss: 2.110434114292104

Epoch: 6| Step: 1
Training loss: 2.2648863792419434
Validation loss: 2.0939772872514624

Epoch: 6| Step: 2
Training loss: 2.428013801574707
Validation loss: 2.085049003683111

Epoch: 6| Step: 3
Training loss: 2.13926362991333
Validation loss: 2.0680084792516564

Epoch: 6| Step: 4
Training loss: 1.8428685665130615
Validation loss: 2.08977012736823

Epoch: 6| Step: 5
Training loss: 1.0653111934661865
Validation loss: 2.123680309582782

Epoch: 6| Step: 6
Training loss: 2.032757520675659
Validation loss: 2.1551927135836695

Epoch: 6| Step: 7
Training loss: 1.9372284412384033
Validation loss: 2.149992166026946

Epoch: 6| Step: 8
Training loss: 1.7947685718536377
Validation loss: 2.1471574947398198

Epoch: 6| Step: 9
Training loss: 2.3479137420654297
Validation loss: 2.1137564912919076

Epoch: 6| Step: 10
Training loss: 1.451876163482666
Validation loss: 2.0687555395146853

Epoch: 6| Step: 11
Training loss: 1.449995756149292
Validation loss: 2.0348706386422597

Epoch: 6| Step: 12
Training loss: 1.6029324531555176
Validation loss: 2.0162967558830016

Epoch: 6| Step: 13
Training loss: 2.614672899246216
Validation loss: 2.009541831990724

Epoch: 141| Step: 0
Training loss: 1.7483410835266113
Validation loss: 2.0169259617405553

Epoch: 6| Step: 1
Training loss: 1.7216986417770386
Validation loss: 2.006048979297761

Epoch: 6| Step: 2
Training loss: 2.04830002784729
Validation loss: 2.017683139411352

Epoch: 6| Step: 3
Training loss: 1.894707441329956
Validation loss: 2.0335169517865745

Epoch: 6| Step: 4
Training loss: 1.5683300495147705
Validation loss: 2.079045395697317

Epoch: 6| Step: 5
Training loss: 1.6710541248321533
Validation loss: 2.0763836599165395

Epoch: 6| Step: 6
Training loss: 2.3355088233947754
Validation loss: 2.088702130061324

Epoch: 6| Step: 7
Training loss: 2.034719228744507
Validation loss: 2.0688354276841685

Epoch: 6| Step: 8
Training loss: 1.9360371828079224
Validation loss: 2.044034509248631

Epoch: 6| Step: 9
Training loss: 1.609135389328003
Validation loss: 1.984772382243987

Epoch: 6| Step: 10
Training loss: 1.8141900300979614
Validation loss: 1.9615482848177674

Epoch: 6| Step: 11
Training loss: 2.5371127128601074
Validation loss: 1.9639971345983527

Epoch: 6| Step: 12
Training loss: 1.8955016136169434
Validation loss: 2.0110655548751994

Epoch: 6| Step: 13
Training loss: 0.40946972370147705
Validation loss: 2.031364587045485

Epoch: 142| Step: 0
Training loss: 1.3729667663574219
Validation loss: 2.0334579085790985

Epoch: 6| Step: 1
Training loss: 1.9432764053344727
Validation loss: 2.0203734392760904

Epoch: 6| Step: 2
Training loss: 1.85383141040802
Validation loss: 2.0107373806738083

Epoch: 6| Step: 3
Training loss: 2.23494815826416
Validation loss: 2.0158768366741877

Epoch: 6| Step: 4
Training loss: 1.745361328125
Validation loss: 2.0241868867669055

Epoch: 6| Step: 5
Training loss: 1.436204195022583
Validation loss: 2.011648012745765

Epoch: 6| Step: 6
Training loss: 2.2023162841796875
Validation loss: 2.011284335967033

Epoch: 6| Step: 7
Training loss: 2.3129539489746094
Validation loss: 1.9927722331016295

Epoch: 6| Step: 8
Training loss: 1.6474907398223877
Validation loss: 1.9886410902905207

Epoch: 6| Step: 9
Training loss: 0.8068464398384094
Validation loss: 2.0052086255883657

Epoch: 6| Step: 10
Training loss: 1.7174869775772095
Validation loss: 2.015066105832336

Epoch: 6| Step: 11
Training loss: 1.6945520639419556
Validation loss: 2.040218286616828

Epoch: 6| Step: 12
Training loss: 1.9048854112625122
Validation loss: 2.096736802849718

Epoch: 6| Step: 13
Training loss: 2.0914454460144043
Validation loss: 2.099265895864015

Epoch: 143| Step: 0
Training loss: 1.9766311645507812
Validation loss: 2.13134273405998

Epoch: 6| Step: 1
Training loss: 1.863954782485962
Validation loss: 2.1593203442071074

Epoch: 6| Step: 2
Training loss: 2.232792854309082
Validation loss: 2.1753910510770735

Epoch: 6| Step: 3
Training loss: 2.6027255058288574
Validation loss: 2.158599776606406

Epoch: 6| Step: 4
Training loss: 0.9077523350715637
Validation loss: 2.099851755685704

Epoch: 6| Step: 5
Training loss: 2.6191530227661133
Validation loss: 2.060530944537091

Epoch: 6| Step: 6
Training loss: 1.6960986852645874
Validation loss: 2.0521816438244236

Epoch: 6| Step: 7
Training loss: 2.0746164321899414
Validation loss: 2.0475996617347962

Epoch: 6| Step: 8
Training loss: 1.5973925590515137
Validation loss: 2.0207531503451768

Epoch: 6| Step: 9
Training loss: 1.8010623455047607
Validation loss: 1.9899182242731894

Epoch: 6| Step: 10
Training loss: 1.398909568786621
Validation loss: 1.9982697322804441

Epoch: 6| Step: 11
Training loss: 1.5509341955184937
Validation loss: 1.992604805577186

Epoch: 6| Step: 12
Training loss: 1.5660030841827393
Validation loss: 2.020499563986255

Epoch: 6| Step: 13
Training loss: 0.9854653477668762
Validation loss: 2.0696594433117936

Epoch: 144| Step: 0
Training loss: 1.3159878253936768
Validation loss: 2.0963505519333707

Epoch: 6| Step: 1
Training loss: 1.894342064857483
Validation loss: 2.1185353699550835

Epoch: 6| Step: 2
Training loss: 1.8391718864440918
Validation loss: 2.0766665768879715

Epoch: 6| Step: 3
Training loss: 1.3125640153884888
Validation loss: 2.0549308766600904

Epoch: 6| Step: 4
Training loss: 1.8654085397720337
Validation loss: 2.081623541411533

Epoch: 6| Step: 5
Training loss: 2.5575051307678223
Validation loss: 2.079643023911343

Epoch: 6| Step: 6
Training loss: 2.637843370437622
Validation loss: 2.0933221668325444

Epoch: 6| Step: 7
Training loss: 1.4740649461746216
Validation loss: 2.1026006642208306

Epoch: 6| Step: 8
Training loss: 1.2999557256698608
Validation loss: 2.0718652227873444

Epoch: 6| Step: 9
Training loss: 1.5737173557281494
Validation loss: 2.0649057472905805

Epoch: 6| Step: 10
Training loss: 1.7660455703735352
Validation loss: 2.0472790771915066

Epoch: 6| Step: 11
Training loss: 1.7069945335388184
Validation loss: 2.05768310382802

Epoch: 6| Step: 12
Training loss: 1.76069974899292
Validation loss: 2.045969424709197

Epoch: 6| Step: 13
Training loss: 1.4368540048599243
Validation loss: 2.0088208362620366

Epoch: 145| Step: 0
Training loss: 1.6575406789779663
Validation loss: 2.0256420335462018

Epoch: 6| Step: 1
Training loss: 1.801084280014038
Validation loss: 2.030279703037713

Epoch: 6| Step: 2
Training loss: 1.488985538482666
Validation loss: 2.041424746154457

Epoch: 6| Step: 3
Training loss: 1.1633882522583008
Validation loss: 2.0567291757111907

Epoch: 6| Step: 4
Training loss: 1.8643313646316528
Validation loss: 2.064241611829368

Epoch: 6| Step: 5
Training loss: 1.793683648109436
Validation loss: 2.0356614871691634

Epoch: 6| Step: 6
Training loss: 1.9805659055709839
Validation loss: 2.0536401400002102

Epoch: 6| Step: 7
Training loss: 1.235980749130249
Validation loss: 2.030053982170679

Epoch: 6| Step: 8
Training loss: 1.5316098928451538
Validation loss: 2.049394420398179

Epoch: 6| Step: 9
Training loss: 1.6689479351043701
Validation loss: 2.1178130616423902

Epoch: 6| Step: 10
Training loss: 1.898542046546936
Validation loss: 2.176174666291924

Epoch: 6| Step: 11
Training loss: 1.9281837940216064
Validation loss: 2.2116043747112317

Epoch: 6| Step: 12
Training loss: 2.1462321281433105
Validation loss: 2.2564939709119898

Epoch: 6| Step: 13
Training loss: 2.0346996784210205
Validation loss: 2.269267330887497

Epoch: 146| Step: 0
Training loss: 1.8411858081817627
Validation loss: 2.338288237971644

Epoch: 6| Step: 1
Training loss: 1.5751910209655762
Validation loss: 2.3724005376138995

Epoch: 6| Step: 2
Training loss: 2.1961922645568848
Validation loss: 2.338901348011468

Epoch: 6| Step: 3
Training loss: 2.0302395820617676
Validation loss: 2.305538108271937

Epoch: 6| Step: 4
Training loss: 1.6425138711929321
Validation loss: 2.173566666982507

Epoch: 6| Step: 5
Training loss: 1.3563315868377686
Validation loss: 2.0903471310933432

Epoch: 6| Step: 6
Training loss: 0.8988943696022034
Validation loss: 2.029402184230025

Epoch: 6| Step: 7
Training loss: 1.217177391052246
Validation loss: 2.017657809360053

Epoch: 6| Step: 8
Training loss: 2.310737371444702
Validation loss: 2.023857746072995

Epoch: 6| Step: 9
Training loss: 2.0013086795806885
Validation loss: 2.015542576389928

Epoch: 6| Step: 10
Training loss: 2.0463757514953613
Validation loss: 2.001336024653527

Epoch: 6| Step: 11
Training loss: 1.7893836498260498
Validation loss: 1.9983346103340067

Epoch: 6| Step: 12
Training loss: 1.7095617055892944
Validation loss: 2.0355925252360683

Epoch: 6| Step: 13
Training loss: 1.95025634765625
Validation loss: 2.0259338963416313

Epoch: 147| Step: 0
Training loss: 2.1350207328796387
Validation loss: 2.036671746161676

Epoch: 6| Step: 1
Training loss: 1.9306788444519043
Validation loss: 2.0231937041846653

Epoch: 6| Step: 2
Training loss: 2.826859712600708
Validation loss: 2.0006893155395344

Epoch: 6| Step: 3
Training loss: 1.5003727674484253
Validation loss: 2.0015554543464416

Epoch: 6| Step: 4
Training loss: 1.6820662021636963
Validation loss: 2.035165597033757

Epoch: 6| Step: 5
Training loss: 1.1451935768127441
Validation loss: 2.0518917524686424

Epoch: 6| Step: 6
Training loss: 1.7769731283187866
Validation loss: 2.0888163325607136

Epoch: 6| Step: 7
Training loss: 1.803792953491211
Validation loss: 2.0689970998353857

Epoch: 6| Step: 8
Training loss: 1.6190710067749023
Validation loss: 2.0750476890994656

Epoch: 6| Step: 9
Training loss: 1.890500783920288
Validation loss: 2.0610527056519703

Epoch: 6| Step: 10
Training loss: 1.5984445810317993
Validation loss: 2.033504471983961

Epoch: 6| Step: 11
Training loss: 1.171414852142334
Validation loss: 2.0807271119086974

Epoch: 6| Step: 12
Training loss: 1.3902218341827393
Validation loss: 2.1058357684843

Epoch: 6| Step: 13
Training loss: 1.4722404479980469
Validation loss: 2.1828124728254092

Epoch: 148| Step: 0
Training loss: 1.4828529357910156
Validation loss: 2.208535518697513

Epoch: 6| Step: 1
Training loss: 2.2483344078063965
Validation loss: 2.222621581887686

Epoch: 6| Step: 2
Training loss: 1.6932200193405151
Validation loss: 2.1879069010416665

Epoch: 6| Step: 3
Training loss: 1.642852783203125
Validation loss: 2.1507939113083707

Epoch: 6| Step: 4
Training loss: 2.083437919616699
Validation loss: 2.073314345011147

Epoch: 6| Step: 5
Training loss: 1.3984185457229614
Validation loss: 2.051087079509612

Epoch: 6| Step: 6
Training loss: 2.093087673187256
Validation loss: 2.029560128847758

Epoch: 6| Step: 7
Training loss: 1.898873209953308
Validation loss: 1.985387115068333

Epoch: 6| Step: 8
Training loss: 1.8300373554229736
Validation loss: 1.9725580458999963

Epoch: 6| Step: 9
Training loss: 1.2653306722640991
Validation loss: 1.9513955218817598

Epoch: 6| Step: 10
Training loss: 2.053493022918701
Validation loss: 1.9519588447386218

Epoch: 6| Step: 11
Training loss: 1.6881420612335205
Validation loss: 1.9591743356438094

Epoch: 6| Step: 12
Training loss: 1.5813156366348267
Validation loss: 1.9828031883444837

Epoch: 6| Step: 13
Training loss: 2.366044759750366
Validation loss: 2.0225447762397026

Epoch: 149| Step: 0
Training loss: 1.5485639572143555
Validation loss: 2.051108096235542

Epoch: 6| Step: 1
Training loss: 1.9645766019821167
Validation loss: 2.081779054416123

Epoch: 6| Step: 2
Training loss: 1.7727617025375366
Validation loss: 2.108766676277243

Epoch: 6| Step: 3
Training loss: 1.892985224723816
Validation loss: 2.0706925494696504

Epoch: 6| Step: 4
Training loss: 1.4889094829559326
Validation loss: 2.0326407391537904

Epoch: 6| Step: 5
Training loss: 1.7094972133636475
Validation loss: 2.0042976025612123

Epoch: 6| Step: 6
Training loss: 1.2335139513015747
Validation loss: 1.9822118974501086

Epoch: 6| Step: 7
Training loss: 1.9156922101974487
Validation loss: 1.965659115904121

Epoch: 6| Step: 8
Training loss: 1.4166004657745361
Validation loss: 1.9524592584179294

Epoch: 6| Step: 9
Training loss: 2.69468092918396
Validation loss: 1.927764900269047

Epoch: 6| Step: 10
Training loss: 1.5297566652297974
Validation loss: 1.919677677974906

Epoch: 6| Step: 11
Training loss: 1.7209237813949585
Validation loss: 1.8977895347020959

Epoch: 6| Step: 12
Training loss: 1.4898711442947388
Validation loss: 1.9316325726047638

Epoch: 6| Step: 13
Training loss: 1.635613203048706
Validation loss: 1.94623532859228

Epoch: 150| Step: 0
Training loss: 1.5141764879226685
Validation loss: 1.9988857135977796

Epoch: 6| Step: 1
Training loss: 1.8858590126037598
Validation loss: 2.0537718008923274

Epoch: 6| Step: 2
Training loss: 1.642214298248291
Validation loss: 2.03911393432207

Epoch: 6| Step: 3
Training loss: 1.9865429401397705
Validation loss: 2.025066621841923

Epoch: 6| Step: 4
Training loss: 2.150327682495117
Validation loss: 2.0092777731598064

Epoch: 6| Step: 5
Training loss: 1.1395288705825806
Validation loss: 2.033319378411898

Epoch: 6| Step: 6
Training loss: 1.8754997253417969
Validation loss: 2.042791904941682

Epoch: 6| Step: 7
Training loss: 1.6557683944702148
Validation loss: 2.0886880377287507

Epoch: 6| Step: 8
Training loss: 1.8038222789764404
Validation loss: 2.0587244790087462

Epoch: 6| Step: 9
Training loss: 1.3616280555725098
Validation loss: 2.033286838121312

Epoch: 6| Step: 10
Training loss: 1.774049997329712
Validation loss: 2.0410183937318864

Epoch: 6| Step: 11
Training loss: 2.045384168624878
Validation loss: 2.025630831718445

Epoch: 6| Step: 12
Training loss: 1.414144515991211
Validation loss: 2.093319414764322

Epoch: 6| Step: 13
Training loss: 1.5677807331085205
Validation loss: 2.115358926916635

Epoch: 151| Step: 0
Training loss: 1.450576663017273
Validation loss: 2.058611959539434

Epoch: 6| Step: 1
Training loss: 1.4163713455200195
Validation loss: 1.9991040755343694

Epoch: 6| Step: 2
Training loss: 2.2078351974487305
Validation loss: 1.9994672344576927

Epoch: 6| Step: 3
Training loss: 1.4702472686767578
Validation loss: 1.9766880491728425

Epoch: 6| Step: 4
Training loss: 1.5425336360931396
Validation loss: 1.947982693231234

Epoch: 6| Step: 5
Training loss: 2.0502378940582275
Validation loss: 1.9328428904215496

Epoch: 6| Step: 6
Training loss: 1.3006792068481445
Validation loss: 1.9452830694055046

Epoch: 6| Step: 7
Training loss: 1.179887056350708
Validation loss: 1.9816833221784202

Epoch: 6| Step: 8
Training loss: 1.7502681016921997
Validation loss: 2.019062795946675

Epoch: 6| Step: 9
Training loss: 1.4300769567489624
Validation loss: 2.0943520312668173

Epoch: 6| Step: 10
Training loss: 1.6811819076538086
Validation loss: 2.1826350663297918

Epoch: 6| Step: 11
Training loss: 2.4094579219818115
Validation loss: 2.2345595436711467

Epoch: 6| Step: 12
Training loss: 1.4066455364227295
Validation loss: 2.2945404732099144

Epoch: 6| Step: 13
Training loss: 2.7198374271392822
Validation loss: 2.3100143863308813

Epoch: 152| Step: 0
Training loss: 1.9182708263397217
Validation loss: 2.272155528427452

Epoch: 6| Step: 1
Training loss: 1.3899002075195312
Validation loss: 2.2300179466124503

Epoch: 6| Step: 2
Training loss: 1.7877919673919678
Validation loss: 2.2063070676660024

Epoch: 6| Step: 3
Training loss: 1.7449650764465332
Validation loss: 2.173482644942499

Epoch: 6| Step: 4
Training loss: 1.6874432563781738
Validation loss: 2.142139551460102

Epoch: 6| Step: 5
Training loss: 1.8721948862075806
Validation loss: 2.094836820838272

Epoch: 6| Step: 6
Training loss: 2.084949493408203
Validation loss: 2.062417809681226

Epoch: 6| Step: 7
Training loss: 1.4020723104476929
Validation loss: 2.007414612718808

Epoch: 6| Step: 8
Training loss: 1.8827486038208008
Validation loss: 1.968297348227552

Epoch: 6| Step: 9
Training loss: 1.315146803855896
Validation loss: 1.9828514783613143

Epoch: 6| Step: 10
Training loss: 1.1323583126068115
Validation loss: 2.0464825655824397

Epoch: 6| Step: 11
Training loss: 1.7966010570526123
Validation loss: 2.135480624373241

Epoch: 6| Step: 12
Training loss: 1.5088095664978027
Validation loss: 2.180283425956644

Epoch: 6| Step: 13
Training loss: 1.7837575674057007
Validation loss: 2.1765184787011917

Epoch: 153| Step: 0
Training loss: 1.8943675756454468
Validation loss: 2.212024660520656

Epoch: 6| Step: 1
Training loss: 1.7689855098724365
Validation loss: 2.226798152410856

Epoch: 6| Step: 2
Training loss: 1.717271089553833
Validation loss: 2.200794212279781

Epoch: 6| Step: 3
Training loss: 1.545035719871521
Validation loss: 2.113207026194501

Epoch: 6| Step: 4
Training loss: 1.908730387687683
Validation loss: 2.025545043330039

Epoch: 6| Step: 5
Training loss: 2.0110864639282227
Validation loss: 1.947033662949839

Epoch: 6| Step: 6
Training loss: 1.4378869533538818
Validation loss: 1.9065434035434519

Epoch: 6| Step: 7
Training loss: 1.9336471557617188
Validation loss: 1.8957144380897604

Epoch: 6| Step: 8
Training loss: 2.862473964691162
Validation loss: 1.8994329334587179

Epoch: 6| Step: 9
Training loss: 1.1944111585617065
Validation loss: 1.9050628600582

Epoch: 6| Step: 10
Training loss: 1.4349156618118286
Validation loss: 1.8956236480384745

Epoch: 6| Step: 11
Training loss: 1.6204701662063599
Validation loss: 1.9204534023038802

Epoch: 6| Step: 12
Training loss: 1.978383183479309
Validation loss: 1.9378211882806593

Epoch: 6| Step: 13
Training loss: 1.0455737113952637
Validation loss: 1.968392950232311

Epoch: 154| Step: 0
Training loss: 1.7446744441986084
Validation loss: 1.9869654640074699

Epoch: 6| Step: 1
Training loss: 1.7825725078582764
Validation loss: 2.032129814547877

Epoch: 6| Step: 2
Training loss: 1.2580084800720215
Validation loss: 2.0458567245032198

Epoch: 6| Step: 3
Training loss: 1.0775766372680664
Validation loss: 2.0479898311758555

Epoch: 6| Step: 4
Training loss: 1.52409029006958
Validation loss: 2.054393160727716

Epoch: 6| Step: 5
Training loss: 2.099407196044922
Validation loss: 2.1088933842156523

Epoch: 6| Step: 6
Training loss: 1.921776294708252
Validation loss: 2.135126216437227

Epoch: 6| Step: 7
Training loss: 1.8251982927322388
Validation loss: 2.1221215064807604

Epoch: 6| Step: 8
Training loss: 1.8464386463165283
Validation loss: 2.1038848635970906

Epoch: 6| Step: 9
Training loss: 1.6250513792037964
Validation loss: 2.0458907465780936

Epoch: 6| Step: 10
Training loss: 1.6957530975341797
Validation loss: 2.0127971620969873

Epoch: 6| Step: 11
Training loss: 1.4310085773468018
Validation loss: 1.9988702266447005

Epoch: 6| Step: 12
Training loss: 1.9399009943008423
Validation loss: 2.0005360226477347

Epoch: 6| Step: 13
Training loss: 1.3838647603988647
Validation loss: 2.036974923585051

Epoch: 155| Step: 0
Training loss: 1.923913836479187
Validation loss: 2.0522550575194822

Epoch: 6| Step: 1
Training loss: 1.8912620544433594
Validation loss: 2.0545608612798874

Epoch: 6| Step: 2
Training loss: 0.8123607039451599
Validation loss: 2.059139806737182

Epoch: 6| Step: 3
Training loss: 1.3465745449066162
Validation loss: 2.125667982203986

Epoch: 6| Step: 4
Training loss: 1.8128085136413574
Validation loss: 2.1226187470138713

Epoch: 6| Step: 5
Training loss: 2.2749922275543213
Validation loss: 2.12586824868315

Epoch: 6| Step: 6
Training loss: 1.2265762090682983
Validation loss: 2.1184492188115276

Epoch: 6| Step: 7
Training loss: 2.1866841316223145
Validation loss: 2.0594090902677147

Epoch: 6| Step: 8
Training loss: 1.402437448501587
Validation loss: 2.0003091442969536

Epoch: 6| Step: 9
Training loss: 1.1745948791503906
Validation loss: 1.9827793516138548

Epoch: 6| Step: 10
Training loss: 1.7649919986724854
Validation loss: 1.941603563165152

Epoch: 6| Step: 11
Training loss: 1.4602432250976562
Validation loss: 1.9303162469658801

Epoch: 6| Step: 12
Training loss: 1.979317307472229
Validation loss: 1.9207895878822572

Epoch: 6| Step: 13
Training loss: 1.671964168548584
Validation loss: 1.9163051548824515

Epoch: 156| Step: 0
Training loss: 1.6898744106292725
Validation loss: 1.9884077682290027

Epoch: 6| Step: 1
Training loss: 1.7939398288726807
Validation loss: 2.039032023440125

Epoch: 6| Step: 2
Training loss: 2.3737616539001465
Validation loss: 2.1123138512334516

Epoch: 6| Step: 3
Training loss: 1.4002078771591187
Validation loss: 2.1557072003682456

Epoch: 6| Step: 4
Training loss: 1.6350294351577759
Validation loss: 2.1257187653613347

Epoch: 6| Step: 5
Training loss: 1.7534986734390259
Validation loss: 2.1179600787419144

Epoch: 6| Step: 6
Training loss: 2.0820975303649902
Validation loss: 2.081864751795287

Epoch: 6| Step: 7
Training loss: 1.4744434356689453
Validation loss: 2.0407925575010237

Epoch: 6| Step: 8
Training loss: 1.2905646562576294
Validation loss: 2.0468472152627926

Epoch: 6| Step: 9
Training loss: 1.3451980352401733
Validation loss: 2.0251079759290143

Epoch: 6| Step: 10
Training loss: 0.9938703775405884
Validation loss: 2.0080007494136853

Epoch: 6| Step: 11
Training loss: 1.9063111543655396
Validation loss: 2.0045066623277563

Epoch: 6| Step: 12
Training loss: 1.6679706573486328
Validation loss: 2.025853386489294

Epoch: 6| Step: 13
Training loss: 1.956544041633606
Validation loss: 2.042714093321113

Epoch: 157| Step: 0
Training loss: 1.590106725692749
Validation loss: 2.0660486528950353

Epoch: 6| Step: 1
Training loss: 1.4266314506530762
Validation loss: 2.096047939792756

Epoch: 6| Step: 2
Training loss: 1.7914642095565796
Validation loss: 2.1106582367292015

Epoch: 6| Step: 3
Training loss: 1.3892911672592163
Validation loss: 2.1057466742812947

Epoch: 6| Step: 4
Training loss: 1.4014568328857422
Validation loss: 2.090028420571358

Epoch: 6| Step: 5
Training loss: 1.7969529628753662
Validation loss: 2.0596202470922984

Epoch: 6| Step: 6
Training loss: 1.9392759799957275
Validation loss: 2.047877980816749

Epoch: 6| Step: 7
Training loss: 1.3434817790985107
Validation loss: 2.0263170349982476

Epoch: 6| Step: 8
Training loss: 1.5859465599060059
Validation loss: 2.009320430858161

Epoch: 6| Step: 9
Training loss: 1.9939398765563965
Validation loss: 1.9779223806114608

Epoch: 6| Step: 10
Training loss: 2.028791904449463
Validation loss: 1.9755727937144618

Epoch: 6| Step: 11
Training loss: 1.5153558254241943
Validation loss: 1.9614688427217546

Epoch: 6| Step: 12
Training loss: 1.235295295715332
Validation loss: 1.9512261472722536

Epoch: 6| Step: 13
Training loss: 0.8055256605148315
Validation loss: 1.966522119378531

Epoch: 158| Step: 0
Training loss: 1.3479760885238647
Validation loss: 1.9946178966952908

Epoch: 6| Step: 1
Training loss: 1.6630659103393555
Validation loss: 2.031662389796267

Epoch: 6| Step: 2
Training loss: 1.850628137588501
Validation loss: 1.9961201990804365

Epoch: 6| Step: 3
Training loss: 0.920264482498169
Validation loss: 1.9944133207362185

Epoch: 6| Step: 4
Training loss: 1.509261131286621
Validation loss: 1.9615213614638134

Epoch: 6| Step: 5
Training loss: 1.9620400667190552
Validation loss: 1.9248536209906302

Epoch: 6| Step: 6
Training loss: 1.4953131675720215
Validation loss: 1.9306290252234346

Epoch: 6| Step: 7
Training loss: 1.69089937210083
Validation loss: 1.928810599029705

Epoch: 6| Step: 8
Training loss: 2.1095733642578125
Validation loss: 1.9623489110700545

Epoch: 6| Step: 9
Training loss: 1.246595859527588
Validation loss: 2.0176120804202173

Epoch: 6| Step: 10
Training loss: 1.6333632469177246
Validation loss: 2.08247725425228

Epoch: 6| Step: 11
Training loss: 1.4465277194976807
Validation loss: 2.1194526636472313

Epoch: 6| Step: 12
Training loss: 1.8342266082763672
Validation loss: 2.115376798055505

Epoch: 6| Step: 13
Training loss: 1.404499888420105
Validation loss: 2.1142582854916974

Epoch: 159| Step: 0
Training loss: 1.698939323425293
Validation loss: 2.10093605133795

Epoch: 6| Step: 1
Training loss: 1.496885895729065
Validation loss: 2.094337522342641

Epoch: 6| Step: 2
Training loss: 0.8668708801269531
Validation loss: 2.0625914271159838

Epoch: 6| Step: 3
Training loss: 1.1053998470306396
Validation loss: 2.0166419936764624

Epoch: 6| Step: 4
Training loss: 1.6856515407562256
Validation loss: 2.002295042878838

Epoch: 6| Step: 5
Training loss: 2.0858473777770996
Validation loss: 2.0335373558023924

Epoch: 6| Step: 6
Training loss: 1.7209250926971436
Validation loss: 2.0578360019191617

Epoch: 6| Step: 7
Training loss: 1.95493483543396
Validation loss: 2.075876896099378

Epoch: 6| Step: 8
Training loss: 1.6889925003051758
Validation loss: 2.117245566460394

Epoch: 6| Step: 9
Training loss: 1.7767291069030762
Validation loss: 2.0822622596576648

Epoch: 6| Step: 10
Training loss: 1.1930489540100098
Validation loss: 2.032324178244478

Epoch: 6| Step: 11
Training loss: 1.8394520282745361
Validation loss: 1.959885315228534

Epoch: 6| Step: 12
Training loss: 2.1204214096069336
Validation loss: 1.8937893977729223

Epoch: 6| Step: 13
Training loss: 0.8620859384536743
Validation loss: 1.8926860376070904

Epoch: 160| Step: 0
Training loss: 1.1492009162902832
Validation loss: 1.8967807972303001

Epoch: 6| Step: 1
Training loss: 1.603191614151001
Validation loss: 1.9006855936460598

Epoch: 6| Step: 2
Training loss: 1.093022346496582
Validation loss: 1.9127276418029622

Epoch: 6| Step: 3
Training loss: 1.788867712020874
Validation loss: 1.9355940998241465

Epoch: 6| Step: 4
Training loss: 1.6226637363433838
Validation loss: 1.9836187196034256

Epoch: 6| Step: 5
Training loss: 1.5050047636032104
Validation loss: 2.091786656328427

Epoch: 6| Step: 6
Training loss: 1.8080942630767822
Validation loss: 2.13818641760016

Epoch: 6| Step: 7
Training loss: 2.449169158935547
Validation loss: 2.1466993990764824

Epoch: 6| Step: 8
Training loss: 1.7281289100646973
Validation loss: 2.1220846842694026

Epoch: 6| Step: 9
Training loss: 1.399454116821289
Validation loss: 2.0936141911373345

Epoch: 6| Step: 10
Training loss: 1.3873841762542725
Validation loss: 2.0162580205548193

Epoch: 6| Step: 11
Training loss: 1.627333164215088
Validation loss: 1.9573148783817087

Epoch: 6| Step: 12
Training loss: 1.8027637004852295
Validation loss: 1.9556927591241815

Epoch: 6| Step: 13
Training loss: 1.0022845268249512
Validation loss: 1.9481832442745086

Epoch: 161| Step: 0
Training loss: 1.7504653930664062
Validation loss: 1.9393866190346338

Epoch: 6| Step: 1
Training loss: 1.112526535987854
Validation loss: 1.9361633510999783

Epoch: 6| Step: 2
Training loss: 1.826347827911377
Validation loss: 1.93283075030132

Epoch: 6| Step: 3
Training loss: 1.1744968891143799
Validation loss: 1.9484396185926212

Epoch: 6| Step: 4
Training loss: 1.219759464263916
Validation loss: 1.9752814744108467

Epoch: 6| Step: 5
Training loss: 0.761459469795227
Validation loss: 1.9999019638184579

Epoch: 6| Step: 6
Training loss: 0.9982219338417053
Validation loss: 2.0436679445287234

Epoch: 6| Step: 7
Training loss: 2.0773448944091797
Validation loss: 2.0951431643578315

Epoch: 6| Step: 8
Training loss: 1.7709109783172607
Validation loss: 2.064976417890159

Epoch: 6| Step: 9
Training loss: 1.4693254232406616
Validation loss: 2.049963971619965

Epoch: 6| Step: 10
Training loss: 2.2179489135742188
Validation loss: 2.0025451234591904

Epoch: 6| Step: 11
Training loss: 2.014038324356079
Validation loss: 1.9664127403689968

Epoch: 6| Step: 12
Training loss: 1.557287335395813
Validation loss: 1.9952944299226165

Epoch: 6| Step: 13
Training loss: 1.8537142276763916
Validation loss: 2.0202411220919703

Epoch: 162| Step: 0
Training loss: 1.7183449268341064
Validation loss: 2.0298237646779707

Epoch: 6| Step: 1
Training loss: 1.6153314113616943
Validation loss: 2.0248733656380766

Epoch: 6| Step: 2
Training loss: 1.391899824142456
Validation loss: 2.0090696222038678

Epoch: 6| Step: 3
Training loss: 2.162884473800659
Validation loss: 2.0184737995106685

Epoch: 6| Step: 4
Training loss: 1.307312250137329
Validation loss: 2.0067324420457244

Epoch: 6| Step: 5
Training loss: 1.4797697067260742
Validation loss: 1.9929595173046153

Epoch: 6| Step: 6
Training loss: 1.744253396987915
Validation loss: 1.9477439593243342

Epoch: 6| Step: 7
Training loss: 1.4609272480010986
Validation loss: 1.9538369281317598

Epoch: 6| Step: 8
Training loss: 1.1739975214004517
Validation loss: 1.9554329661912815

Epoch: 6| Step: 9
Training loss: 1.7355310916900635
Validation loss: 1.9405719567370672

Epoch: 6| Step: 10
Training loss: 1.472611665725708
Validation loss: 1.958445563111254

Epoch: 6| Step: 11
Training loss: 1.7435154914855957
Validation loss: 1.952198310564923

Epoch: 6| Step: 12
Training loss: 1.5684071779251099
Validation loss: 1.9845504504378124

Epoch: 6| Step: 13
Training loss: 1.0498725175857544
Validation loss: 2.0222857690626577

Epoch: 163| Step: 0
Training loss: 1.2902135848999023
Validation loss: 2.0626725381420505

Epoch: 6| Step: 1
Training loss: 2.0263524055480957
Validation loss: 2.091504704567694

Epoch: 6| Step: 2
Training loss: 1.1240298748016357
Validation loss: 2.0898895032944216

Epoch: 6| Step: 3
Training loss: 1.8292438983917236
Validation loss: 2.080965731733589

Epoch: 6| Step: 4
Training loss: 1.7196464538574219
Validation loss: 2.033330350793818

Epoch: 6| Step: 5
Training loss: 1.1327333450317383
Validation loss: 1.9650418553301083

Epoch: 6| Step: 6
Training loss: 1.695004940032959
Validation loss: 1.939135475825238

Epoch: 6| Step: 7
Training loss: 1.7288144826889038
Validation loss: 1.9646834096600931

Epoch: 6| Step: 8
Training loss: 1.709371566772461
Validation loss: 1.9840801813269173

Epoch: 6| Step: 9
Training loss: 1.694807529449463
Validation loss: 2.0260697641680316

Epoch: 6| Step: 10
Training loss: 1.2616676092147827
Validation loss: 2.089268507496003

Epoch: 6| Step: 11
Training loss: 1.6849445104599
Validation loss: 2.0718177262172905

Epoch: 6| Step: 12
Training loss: 0.8275712728500366
Validation loss: 2.0333132936108496

Epoch: 6| Step: 13
Training loss: 1.2433727979660034
Validation loss: 1.9491783111326155

Epoch: 164| Step: 0
Training loss: 1.345534324645996
Validation loss: 1.9340640806382703

Epoch: 6| Step: 1
Training loss: 1.2700875997543335
Validation loss: 1.9116560605264479

Epoch: 6| Step: 2
Training loss: 2.007709503173828
Validation loss: 1.9243609533515027

Epoch: 6| Step: 3
Training loss: 1.0543968677520752
Validation loss: 1.9337759056398947

Epoch: 6| Step: 4
Training loss: 1.740531086921692
Validation loss: 1.9455905652815295

Epoch: 6| Step: 5
Training loss: 1.3428943157196045
Validation loss: 1.9628346171430362

Epoch: 6| Step: 6
Training loss: 1.2415521144866943
Validation loss: 1.9830987511142608

Epoch: 6| Step: 7
Training loss: 1.493295431137085
Validation loss: 2.0098988868856944

Epoch: 6| Step: 8
Training loss: 1.1528092622756958
Validation loss: 2.0207063305762505

Epoch: 6| Step: 9
Training loss: 1.5330753326416016
Validation loss: 2.046699648262352

Epoch: 6| Step: 10
Training loss: 1.734313726425171
Validation loss: 2.0563656219872097

Epoch: 6| Step: 11
Training loss: 1.450081467628479
Validation loss: 2.0605708809309107

Epoch: 6| Step: 12
Training loss: 2.281903028488159
Validation loss: 2.0691671422732774

Epoch: 6| Step: 13
Training loss: 1.4962000846862793
Validation loss: 2.0670908881771948

Epoch: 165| Step: 0
Training loss: 1.8330538272857666
Validation loss: 2.0620965444913475

Epoch: 6| Step: 1
Training loss: 1.737105131149292
Validation loss: 2.0460020162725963

Epoch: 6| Step: 2
Training loss: 1.6489821672439575
Validation loss: 1.9801665659873717

Epoch: 6| Step: 3
Training loss: 1.229011058807373
Validation loss: 1.941917924470799

Epoch: 6| Step: 4
Training loss: 0.8067035675048828
Validation loss: 1.9343016967978528

Epoch: 6| Step: 5
Training loss: 0.8844460248947144
Validation loss: 1.9199528258333924

Epoch: 6| Step: 6
Training loss: 1.2869527339935303
Validation loss: 1.9382576198988064

Epoch: 6| Step: 7
Training loss: 1.0951545238494873
Validation loss: 1.951546892043083

Epoch: 6| Step: 8
Training loss: 1.8609836101531982
Validation loss: 2.008128200807879

Epoch: 6| Step: 9
Training loss: 1.590195655822754
Validation loss: 2.054521829851212

Epoch: 6| Step: 10
Training loss: 1.5188837051391602
Validation loss: 2.064763915154242

Epoch: 6| Step: 11
Training loss: 1.851393461227417
Validation loss: 2.0785432643787836

Epoch: 6| Step: 12
Training loss: 1.9326611757278442
Validation loss: 2.0580540780098207

Epoch: 6| Step: 13
Training loss: 0.9511067867279053
Validation loss: 2.008966585641266

Epoch: 166| Step: 0
Training loss: 1.658109426498413
Validation loss: 1.9794027830964775

Epoch: 6| Step: 1
Training loss: 0.8492465019226074
Validation loss: 1.9351353773506739

Epoch: 6| Step: 2
Training loss: 1.3966349363327026
Validation loss: 1.8892065043090491

Epoch: 6| Step: 3
Training loss: 1.7595393657684326
Validation loss: 1.8910100895871398

Epoch: 6| Step: 4
Training loss: 1.6705436706542969
Validation loss: 1.9057877115024033

Epoch: 6| Step: 5
Training loss: 1.2890198230743408
Validation loss: 1.887723853511195

Epoch: 6| Step: 6
Training loss: 1.17356276512146
Validation loss: 1.9030796135625532

Epoch: 6| Step: 7
Training loss: 1.7990587949752808
Validation loss: 1.9075156437453402

Epoch: 6| Step: 8
Training loss: 1.255312204360962
Validation loss: 1.9517111368076776

Epoch: 6| Step: 9
Training loss: 1.8089765310287476
Validation loss: 2.005830608388429

Epoch: 6| Step: 10
Training loss: 1.8544371128082275
Validation loss: 2.0071980632761472

Epoch: 6| Step: 11
Training loss: 1.5358392000198364
Validation loss: 2.016536401164147

Epoch: 6| Step: 12
Training loss: 1.4017032384872437
Validation loss: 2.012572762786701

Epoch: 6| Step: 13
Training loss: 0.9273722171783447
Validation loss: 2.0291978402804305

Epoch: 167| Step: 0
Training loss: 0.8754293918609619
Validation loss: 2.0702513571708434

Epoch: 6| Step: 1
Training loss: 0.9597002863883972
Validation loss: 2.0431817231639737

Epoch: 6| Step: 2
Training loss: 1.4716335535049438
Validation loss: 2.0421591471600276

Epoch: 6| Step: 3
Training loss: 1.80842924118042
Validation loss: 1.9909083048502605

Epoch: 6| Step: 4
Training loss: 1.1340444087982178
Validation loss: 1.9795941332335114

Epoch: 6| Step: 5
Training loss: 1.8582801818847656
Validation loss: 1.9623893473737983

Epoch: 6| Step: 6
Training loss: 1.6115202903747559
Validation loss: 1.9519400032617713

Epoch: 6| Step: 7
Training loss: 0.7858680486679077
Validation loss: 1.966710357255833

Epoch: 6| Step: 8
Training loss: 1.4921088218688965
Validation loss: 1.9533123162484938

Epoch: 6| Step: 9
Training loss: 1.732628345489502
Validation loss: 1.957175447094825

Epoch: 6| Step: 10
Training loss: 1.7879588603973389
Validation loss: 1.9763763848171438

Epoch: 6| Step: 11
Training loss: 1.4213801622390747
Validation loss: 1.9636015520300916

Epoch: 6| Step: 12
Training loss: 1.7834889888763428
Validation loss: 1.9457119331564954

Epoch: 6| Step: 13
Training loss: 1.2033792734146118
Validation loss: 1.985773185248016

Epoch: 168| Step: 0
Training loss: 1.4100170135498047
Validation loss: 1.966328018455095

Epoch: 6| Step: 1
Training loss: 1.2892646789550781
Validation loss: 1.987428645933828

Epoch: 6| Step: 2
Training loss: 1.8191602230072021
Validation loss: 1.9897015671576224

Epoch: 6| Step: 3
Training loss: 1.4349274635314941
Validation loss: 1.997881441987971

Epoch: 6| Step: 4
Training loss: 1.229843020439148
Validation loss: 2.0499656456773

Epoch: 6| Step: 5
Training loss: 1.489995002746582
Validation loss: 2.069072702879547

Epoch: 6| Step: 6
Training loss: 1.2233915328979492
Validation loss: 2.055623628759897

Epoch: 6| Step: 7
Training loss: 1.6616506576538086
Validation loss: 2.0163930680162165

Epoch: 6| Step: 8
Training loss: 1.4148050546646118
Validation loss: 2.0009221184638237

Epoch: 6| Step: 9
Training loss: 1.6383745670318604
Validation loss: 1.904977088333458

Epoch: 6| Step: 10
Training loss: 1.2487995624542236
Validation loss: 1.89423849890309

Epoch: 6| Step: 11
Training loss: 1.5179938077926636
Validation loss: 1.8915534352743497

Epoch: 6| Step: 12
Training loss: 1.1474382877349854
Validation loss: 1.8997805669743528

Epoch: 6| Step: 13
Training loss: 1.1262823343276978
Validation loss: 1.9126024502579884

Epoch: 169| Step: 0
Training loss: 1.738394021987915
Validation loss: 2.0013003528759046

Epoch: 6| Step: 1
Training loss: 1.597170114517212
Validation loss: 2.050972259172829

Epoch: 6| Step: 2
Training loss: 1.2463922500610352
Validation loss: 2.1059285210024927

Epoch: 6| Step: 3
Training loss: 0.7920098900794983
Validation loss: 2.101465771275182

Epoch: 6| Step: 4
Training loss: 1.497366189956665
Validation loss: 2.1292418177409838

Epoch: 6| Step: 5
Training loss: 1.1858100891113281
Validation loss: 2.099197474859094

Epoch: 6| Step: 6
Training loss: 0.9584004878997803
Validation loss: 2.058881663507031

Epoch: 6| Step: 7
Training loss: 1.6299142837524414
Validation loss: 1.989105983447003

Epoch: 6| Step: 8
Training loss: 1.6856260299682617
Validation loss: 1.9279059812586794

Epoch: 6| Step: 9
Training loss: 1.533229947090149
Validation loss: 1.8974076829930788

Epoch: 6| Step: 10
Training loss: 0.9139424562454224
Validation loss: 1.8741037973793604

Epoch: 6| Step: 11
Training loss: 1.7528076171875
Validation loss: 1.862894368428056

Epoch: 6| Step: 12
Training loss: 1.691657543182373
Validation loss: 1.8786690055683095

Epoch: 6| Step: 13
Training loss: 1.4465187788009644
Validation loss: 1.8631129726286857

Epoch: 170| Step: 0
Training loss: 1.4867217540740967
Validation loss: 1.8689114252726238

Epoch: 6| Step: 1
Training loss: 1.4763672351837158
Validation loss: 1.9220269649259505

Epoch: 6| Step: 2
Training loss: 0.8082433938980103
Validation loss: 2.009735163821969

Epoch: 6| Step: 3
Training loss: 1.8239445686340332
Validation loss: 2.1086840783396075

Epoch: 6| Step: 4
Training loss: 1.7941910028457642
Validation loss: 2.2095440818417456

Epoch: 6| Step: 5
Training loss: 2.352323293685913
Validation loss: 2.1924074542137886

Epoch: 6| Step: 6
Training loss: 1.4594509601593018
Validation loss: 2.154522224139142

Epoch: 6| Step: 7
Training loss: 1.5871434211730957
Validation loss: 2.045906191231102

Epoch: 6| Step: 8
Training loss: 1.2963085174560547
Validation loss: 1.9524436061100294

Epoch: 6| Step: 9
Training loss: 1.3537240028381348
Validation loss: 1.88923591567624

Epoch: 6| Step: 10
Training loss: 0.9768162369728088
Validation loss: 1.8635619712132279

Epoch: 6| Step: 11
Training loss: 1.5855356454849243
Validation loss: 1.879842444132733

Epoch: 6| Step: 12
Training loss: 1.0849841833114624
Validation loss: 1.8606782549171037

Epoch: 6| Step: 13
Training loss: 1.4829230308532715
Validation loss: 1.8635749457984843

Epoch: 171| Step: 0
Training loss: 1.3323426246643066
Validation loss: 1.8750214115265877

Epoch: 6| Step: 1
Training loss: 1.6821236610412598
Validation loss: 1.931775786543405

Epoch: 6| Step: 2
Training loss: 1.1456286907196045
Validation loss: 1.986799237548664

Epoch: 6| Step: 3
Training loss: 1.3258000612258911
Validation loss: 2.054853807213486

Epoch: 6| Step: 4
Training loss: 1.1943325996398926
Validation loss: 2.1036803696745183

Epoch: 6| Step: 5
Training loss: 0.9570428133010864
Validation loss: 2.088267336609543

Epoch: 6| Step: 6
Training loss: 1.7322070598602295
Validation loss: 2.086765197015578

Epoch: 6| Step: 7
Training loss: 1.5549702644348145
Validation loss: 2.023089152510448

Epoch: 6| Step: 8
Training loss: 1.3253132104873657
Validation loss: 1.978249308883503

Epoch: 6| Step: 9
Training loss: 1.6740241050720215
Validation loss: 1.9587781313926942

Epoch: 6| Step: 10
Training loss: 1.384283423423767
Validation loss: 1.9526109182706444

Epoch: 6| Step: 11
Training loss: 1.8337042331695557
Validation loss: 1.9153685415944746

Epoch: 6| Step: 12
Training loss: 1.533251404762268
Validation loss: 1.9026526712602185

Epoch: 6| Step: 13
Training loss: 1.3945679664611816
Validation loss: 1.9211400375571301

Epoch: 172| Step: 0
Training loss: 1.354630947113037
Validation loss: 1.991232213153634

Epoch: 6| Step: 1
Training loss: 1.2116563320159912
Validation loss: 2.026414373869537

Epoch: 6| Step: 2
Training loss: 1.8785631656646729
Validation loss: 2.070381420914845

Epoch: 6| Step: 3
Training loss: 1.482436180114746
Validation loss: 2.055624428615775

Epoch: 6| Step: 4
Training loss: 1.2130850553512573
Validation loss: 2.0414647133119646

Epoch: 6| Step: 5
Training loss: 1.2963433265686035
Validation loss: 2.017363335496636

Epoch: 6| Step: 6
Training loss: 1.4669883251190186
Validation loss: 1.9848811216251825

Epoch: 6| Step: 7
Training loss: 1.583931565284729
Validation loss: 1.9836531864699496

Epoch: 6| Step: 8
Training loss: 0.9792637228965759
Validation loss: 1.958874697326332

Epoch: 6| Step: 9
Training loss: 1.700005054473877
Validation loss: 1.9352210939571421

Epoch: 6| Step: 10
Training loss: 1.3466081619262695
Validation loss: 1.9123136176857898

Epoch: 6| Step: 11
Training loss: 1.1199240684509277
Validation loss: 1.8609637957747265

Epoch: 6| Step: 12
Training loss: 1.5635513067245483
Validation loss: 1.8712027893271497

Epoch: 6| Step: 13
Training loss: 1.6497080326080322
Validation loss: 1.8904736490659817

Epoch: 173| Step: 0
Training loss: 1.646510362625122
Validation loss: 1.9149103228763869

Epoch: 6| Step: 1
Training loss: 1.6813180446624756
Validation loss: 2.0460265451861965

Epoch: 6| Step: 2
Training loss: 1.4531389474868774
Validation loss: 2.1073592144955873

Epoch: 6| Step: 3
Training loss: 0.9574812650680542
Validation loss: 2.0820712658666793

Epoch: 6| Step: 4
Training loss: 1.2815780639648438
Validation loss: 2.0146324250005905

Epoch: 6| Step: 5
Training loss: 1.2482587099075317
Validation loss: 1.9806668412300847

Epoch: 6| Step: 6
Training loss: 1.6606111526489258
Validation loss: 1.93420623963879

Epoch: 6| Step: 7
Training loss: 1.4812865257263184
Validation loss: 1.9579561115593038

Epoch: 6| Step: 8
Training loss: 1.398972511291504
Validation loss: 1.9474134586190666

Epoch: 6| Step: 9
Training loss: 1.5259006023406982
Validation loss: 1.9425209888847925

Epoch: 6| Step: 10
Training loss: 1.0276902914047241
Validation loss: 1.9330488276737992

Epoch: 6| Step: 11
Training loss: 1.2049586772918701
Validation loss: 1.942982219880627

Epoch: 6| Step: 12
Training loss: 2.16373872756958
Validation loss: 1.9563129742940266

Epoch: 6| Step: 13
Training loss: 0.5928773880004883
Validation loss: 1.9468570268282326

Epoch: 174| Step: 0
Training loss: 1.3556649684906006
Validation loss: 1.9331705647130166

Epoch: 6| Step: 1
Training loss: 1.2177016735076904
Validation loss: 1.9582873659749185

Epoch: 6| Step: 2
Training loss: 1.600738525390625
Validation loss: 1.958668355018862

Epoch: 6| Step: 3
Training loss: 1.5962504148483276
Validation loss: 1.9972995288910405

Epoch: 6| Step: 4
Training loss: 1.6593384742736816
Validation loss: 2.0139856107773317

Epoch: 6| Step: 5
Training loss: 0.8769235610961914
Validation loss: 2.0347441563042263

Epoch: 6| Step: 6
Training loss: 1.4337530136108398
Validation loss: 2.0612198075940533

Epoch: 6| Step: 7
Training loss: 1.6167398691177368
Validation loss: 2.0277836963694584

Epoch: 6| Step: 8
Training loss: 0.9796746969223022
Validation loss: 1.9554987774100354

Epoch: 6| Step: 9
Training loss: 1.5371218919754028
Validation loss: 1.9208324314445577

Epoch: 6| Step: 10
Training loss: 1.1909738779067993
Validation loss: 1.8871652208348757

Epoch: 6| Step: 11
Training loss: 1.4792355298995972
Validation loss: 1.829543141908543

Epoch: 6| Step: 12
Training loss: 1.2716891765594482
Validation loss: 1.8315904755746164

Epoch: 6| Step: 13
Training loss: 0.9268010258674622
Validation loss: 1.8174257650170276

Epoch: 175| Step: 0
Training loss: 0.9966403841972351
Validation loss: 1.8314436686936246

Epoch: 6| Step: 1
Training loss: 1.7243025302886963
Validation loss: 1.8649462499926168

Epoch: 6| Step: 2
Training loss: 1.5087132453918457
Validation loss: 1.8632481213538878

Epoch: 6| Step: 3
Training loss: 0.9301577210426331
Validation loss: 1.893362969480535

Epoch: 6| Step: 4
Training loss: 1.846011757850647
Validation loss: 1.9758790257156535

Epoch: 6| Step: 5
Training loss: 1.1159758567810059
Validation loss: 2.0848768782872025

Epoch: 6| Step: 6
Training loss: 0.915641188621521
Validation loss: 2.1700223081855365

Epoch: 6| Step: 7
Training loss: 1.0156804323196411
Validation loss: 2.201132410316057

Epoch: 6| Step: 8
Training loss: 1.142810583114624
Validation loss: 2.1164793558018182

Epoch: 6| Step: 9
Training loss: 0.9515817165374756
Validation loss: 2.0241353037536784

Epoch: 6| Step: 10
Training loss: 1.5716326236724854
Validation loss: 1.9483167586788055

Epoch: 6| Step: 11
Training loss: 1.6375412940979004
Validation loss: 1.9402057099085983

Epoch: 6| Step: 12
Training loss: 1.5968031883239746
Validation loss: 1.9049988536424534

Epoch: 6| Step: 13
Training loss: 1.7850450277328491
Validation loss: 1.8841277783916843

Epoch: 176| Step: 0
Training loss: 1.66435706615448
Validation loss: 1.875185501831834

Epoch: 6| Step: 1
Training loss: 1.1933832168579102
Validation loss: 1.8767111070694462

Epoch: 6| Step: 2
Training loss: 1.3115235567092896
Validation loss: 1.9376696848100232

Epoch: 6| Step: 3
Training loss: 1.3227293491363525
Validation loss: 1.9471836231088127

Epoch: 6| Step: 4
Training loss: 1.6058236360549927
Validation loss: 1.944244897493752

Epoch: 6| Step: 5
Training loss: 1.2150981426239014
Validation loss: 1.9566166157363563

Epoch: 6| Step: 6
Training loss: 1.4069130420684814
Validation loss: 2.0004276229489233

Epoch: 6| Step: 7
Training loss: 1.196861982345581
Validation loss: 1.9814795986298592

Epoch: 6| Step: 8
Training loss: 0.9198558926582336
Validation loss: 1.974280700888685

Epoch: 6| Step: 9
Training loss: 1.484131932258606
Validation loss: 2.0238243149172876

Epoch: 6| Step: 10
Training loss: 1.5916945934295654
Validation loss: 2.0351278025616883

Epoch: 6| Step: 11
Training loss: 1.314496636390686
Validation loss: 2.006279109626688

Epoch: 6| Step: 12
Training loss: 1.701749324798584
Validation loss: 1.9832416196023264

Epoch: 6| Step: 13
Training loss: 1.926400065422058
Validation loss: 1.9791049649638515

Epoch: 177| Step: 0
Training loss: 1.479461908340454
Validation loss: 1.9124456836331276

Epoch: 6| Step: 1
Training loss: 1.3776016235351562
Validation loss: 1.9320463442033338

Epoch: 6| Step: 2
Training loss: 1.4580836296081543
Validation loss: 1.9397451762230165

Epoch: 6| Step: 3
Training loss: 0.7957696914672852
Validation loss: 1.9710741196909258

Epoch: 6| Step: 4
Training loss: 1.6545681953430176
Validation loss: 1.9992999171697965

Epoch: 6| Step: 5
Training loss: 1.5513083934783936
Validation loss: 2.0118949579936203

Epoch: 6| Step: 6
Training loss: 1.4452431201934814
Validation loss: 2.0131996677767847

Epoch: 6| Step: 7
Training loss: 1.4298558235168457
Validation loss: 2.004157030454246

Epoch: 6| Step: 8
Training loss: 1.2019503116607666
Validation loss: 2.018576791209559

Epoch: 6| Step: 9
Training loss: 1.353753685951233
Validation loss: 1.9858051141103108

Epoch: 6| Step: 10
Training loss: 1.1952533721923828
Validation loss: 1.9883958883182977

Epoch: 6| Step: 11
Training loss: 1.034570336341858
Validation loss: 1.9906799613788564

Epoch: 6| Step: 12
Training loss: 1.3020257949829102
Validation loss: 2.014488022814515

Epoch: 6| Step: 13
Training loss: 1.8190966844558716
Validation loss: 2.0014469649202082

Epoch: 178| Step: 0
Training loss: 1.133791208267212
Validation loss: 1.9839506649201917

Epoch: 6| Step: 1
Training loss: 0.867889404296875
Validation loss: 1.9639774753201393

Epoch: 6| Step: 2
Training loss: 1.5072858333587646
Validation loss: 1.9324455543230938

Epoch: 6| Step: 3
Training loss: 1.4030429124832153
Validation loss: 1.9450759426239999

Epoch: 6| Step: 4
Training loss: 1.0356231927871704
Validation loss: 1.9554246074409896

Epoch: 6| Step: 5
Training loss: 1.4050018787384033
Validation loss: 1.9437906857459777

Epoch: 6| Step: 6
Training loss: 1.7857904434204102
Validation loss: 1.9685390482666671

Epoch: 6| Step: 7
Training loss: 1.1983237266540527
Validation loss: 1.974773524909891

Epoch: 6| Step: 8
Training loss: 1.236132264137268
Validation loss: 1.9919803501457296

Epoch: 6| Step: 9
Training loss: 0.7514559030532837
Validation loss: 1.9541533300953526

Epoch: 6| Step: 10
Training loss: 1.133512258529663
Validation loss: 1.9489958440103838

Epoch: 6| Step: 11
Training loss: 0.8898013830184937
Validation loss: 1.934594238958051

Epoch: 6| Step: 12
Training loss: 2.1082277297973633
Validation loss: 1.920675120046062

Epoch: 6| Step: 13
Training loss: 1.207907795906067
Validation loss: 1.9144609705094369

Epoch: 179| Step: 0
Training loss: 1.4314913749694824
Validation loss: 1.8825780268638366

Epoch: 6| Step: 1
Training loss: 1.227940320968628
Validation loss: 1.8759008094828615

Epoch: 6| Step: 2
Training loss: 1.6141386032104492
Validation loss: 1.8898194374576691

Epoch: 6| Step: 3
Training loss: 1.2174394130706787
Validation loss: 1.8591952657186857

Epoch: 6| Step: 4
Training loss: 1.0245054960250854
Validation loss: 1.8706420403654858

Epoch: 6| Step: 5
Training loss: 1.3268975019454956
Validation loss: 1.9306680489611883

Epoch: 6| Step: 6
Training loss: 1.2871938943862915
Validation loss: 1.955918199272566

Epoch: 6| Step: 7
Training loss: 1.2804183959960938
Validation loss: 1.9869395276551605

Epoch: 6| Step: 8
Training loss: 1.1049515008926392
Validation loss: 1.9457092233883437

Epoch: 6| Step: 9
Training loss: 1.0636063814163208
Validation loss: 1.8926110511185021

Epoch: 6| Step: 10
Training loss: 1.2565900087356567
Validation loss: 1.9024819071574877

Epoch: 6| Step: 11
Training loss: 1.133732557296753
Validation loss: 1.9223992952736475

Epoch: 6| Step: 12
Training loss: 1.3945810794830322
Validation loss: 1.9428636861103836

Epoch: 6| Step: 13
Training loss: 1.342520833015442
Validation loss: 1.9503322096281155

Epoch: 180| Step: 0
Training loss: 1.517374873161316
Validation loss: 1.940103639838516

Epoch: 6| Step: 1
Training loss: 1.0436346530914307
Validation loss: 1.8891721592154553

Epoch: 6| Step: 2
Training loss: 1.5996589660644531
Validation loss: 1.8685420636207826

Epoch: 6| Step: 3
Training loss: 1.2930412292480469
Validation loss: 1.9060589062270297

Epoch: 6| Step: 4
Training loss: 1.527927279472351
Validation loss: 1.928156166948298

Epoch: 6| Step: 5
Training loss: 1.095015525817871
Validation loss: 2.0128289191953597

Epoch: 6| Step: 6
Training loss: 0.9136748313903809
Validation loss: 1.9861953104695966

Epoch: 6| Step: 7
Training loss: 1.1005759239196777
Validation loss: 1.9298325507871565

Epoch: 6| Step: 8
Training loss: 1.346352219581604
Validation loss: 1.9031393707439463

Epoch: 6| Step: 9
Training loss: 0.9841558933258057
Validation loss: 1.8521890781259025

Epoch: 6| Step: 10
Training loss: 1.6951850652694702
Validation loss: 1.8374133494592482

Epoch: 6| Step: 11
Training loss: 0.813246488571167
Validation loss: 1.8641380815095798

Epoch: 6| Step: 12
Training loss: 1.8186514377593994
Validation loss: 1.8529348719504573

Epoch: 6| Step: 13
Training loss: 1.3574970960617065
Validation loss: 1.8951829300131848

Epoch: 181| Step: 0
Training loss: 1.4305932521820068
Validation loss: 1.940035125260712

Epoch: 6| Step: 1
Training loss: 1.1532939672470093
Validation loss: 1.9679200303169988

Epoch: 6| Step: 2
Training loss: 1.2226269245147705
Validation loss: 1.9640418803820046

Epoch: 6| Step: 3
Training loss: 1.238368272781372
Validation loss: 1.9972582811950355

Epoch: 6| Step: 4
Training loss: 1.7649850845336914
Validation loss: 2.010814018146966

Epoch: 6| Step: 5
Training loss: 1.1503809690475464
Validation loss: 2.007870938188286

Epoch: 6| Step: 6
Training loss: 1.2021623849868774
Validation loss: 1.9833744341327297

Epoch: 6| Step: 7
Training loss: 0.6527935862541199
Validation loss: 1.9466250288871028

Epoch: 6| Step: 8
Training loss: 1.0814568996429443
Validation loss: 1.9261185071801628

Epoch: 6| Step: 9
Training loss: 1.1091890335083008
Validation loss: 1.9380904064383557

Epoch: 6| Step: 10
Training loss: 0.8624271154403687
Validation loss: 1.929924044557797

Epoch: 6| Step: 11
Training loss: 1.4455151557922363
Validation loss: 1.930890675513975

Epoch: 6| Step: 12
Training loss: 1.5360784530639648
Validation loss: 1.9373543198390673

Epoch: 6| Step: 13
Training loss: 1.2991652488708496
Validation loss: 1.944223698749337

Epoch: 182| Step: 0
Training loss: 1.0163347721099854
Validation loss: 1.9295629532106462

Epoch: 6| Step: 1
Training loss: 1.3976340293884277
Validation loss: 1.9122615732172483

Epoch: 6| Step: 2
Training loss: 1.1923892498016357
Validation loss: 1.9006416938638175

Epoch: 6| Step: 3
Training loss: 1.5402042865753174
Validation loss: 1.8739444696775047

Epoch: 6| Step: 4
Training loss: 0.9775609970092773
Validation loss: 1.869078528496527

Epoch: 6| Step: 5
Training loss: 0.9142724871635437
Validation loss: 1.898705349173597

Epoch: 6| Step: 6
Training loss: 1.4701095819473267
Validation loss: 1.8864950223635601

Epoch: 6| Step: 7
Training loss: 0.8991228342056274
Validation loss: 1.8667385821701379

Epoch: 6| Step: 8
Training loss: 1.4988843202590942
Validation loss: 1.920426005958229

Epoch: 6| Step: 9
Training loss: 1.564492106437683
Validation loss: 1.9757173010098037

Epoch: 6| Step: 10
Training loss: 1.1147878170013428
Validation loss: 2.0114003125057427

Epoch: 6| Step: 11
Training loss: 0.7176892757415771
Validation loss: 1.9658668271956905

Epoch: 6| Step: 12
Training loss: 1.0566067695617676
Validation loss: 1.92152488488023

Epoch: 6| Step: 13
Training loss: 1.2050080299377441
Validation loss: 1.9433588597082323

Epoch: 183| Step: 0
Training loss: 1.274477243423462
Validation loss: 1.9133540340649184

Epoch: 6| Step: 1
Training loss: 1.0799742937088013
Validation loss: 1.9410236753443235

Epoch: 6| Step: 2
Training loss: 1.1285202503204346
Validation loss: 1.9429129656924997

Epoch: 6| Step: 3
Training loss: 1.5074923038482666
Validation loss: 1.9694067637125652

Epoch: 6| Step: 4
Training loss: 0.8060835003852844
Validation loss: 1.9744770860159269

Epoch: 6| Step: 5
Training loss: 0.6593923568725586
Validation loss: 1.983606025736819

Epoch: 6| Step: 6
Training loss: 1.548889398574829
Validation loss: 1.9723841721011746

Epoch: 6| Step: 7
Training loss: 1.5955452919006348
Validation loss: 1.9080253390855686

Epoch: 6| Step: 8
Training loss: 1.1724178791046143
Validation loss: 1.864326419368867

Epoch: 6| Step: 9
Training loss: 1.2276768684387207
Validation loss: 1.8392676256036247

Epoch: 6| Step: 10
Training loss: 1.18958580493927
Validation loss: 1.834834296216247

Epoch: 6| Step: 11
Training loss: 0.8167532682418823
Validation loss: 1.8667776866625714

Epoch: 6| Step: 12
Training loss: 1.297760248184204
Validation loss: 1.866741221438172

Epoch: 6| Step: 13
Training loss: 0.9768630266189575
Validation loss: 1.8531773744090911

Epoch: 184| Step: 0
Training loss: 1.1439335346221924
Validation loss: 1.8628004686806792

Epoch: 6| Step: 1
Training loss: 0.9399330019950867
Validation loss: 1.8563449228963544

Epoch: 6| Step: 2
Training loss: 1.0713021755218506
Validation loss: 1.875025854315809

Epoch: 6| Step: 3
Training loss: 0.8459579944610596
Validation loss: 1.916030506933889

Epoch: 6| Step: 4
Training loss: 1.5790210962295532
Validation loss: 1.9299694773971394

Epoch: 6| Step: 5
Training loss: 1.1445338726043701
Validation loss: 1.9478053174993044

Epoch: 6| Step: 6
Training loss: 1.2628792524337769
Validation loss: 1.9400447530131186

Epoch: 6| Step: 7
Training loss: 1.15653657913208
Validation loss: 1.9728467515719834

Epoch: 6| Step: 8
Training loss: 1.2668581008911133
Validation loss: 1.9425763084042458

Epoch: 6| Step: 9
Training loss: 0.7634737491607666
Validation loss: 1.9196032503599763

Epoch: 6| Step: 10
Training loss: 1.6411645412445068
Validation loss: 1.8896018215405044

Epoch: 6| Step: 11
Training loss: 1.0782475471496582
Validation loss: 1.8338402637871363

Epoch: 6| Step: 12
Training loss: 1.4536170959472656
Validation loss: 1.8071627706609747

Epoch: 6| Step: 13
Training loss: 0.5874747633934021
Validation loss: 1.7880494389482724

Epoch: 185| Step: 0
Training loss: 0.7610796093940735
Validation loss: 1.7990394510248655

Epoch: 6| Step: 1
Training loss: 1.6964683532714844
Validation loss: 1.8511846937159055

Epoch: 6| Step: 2
Training loss: 1.2033863067626953
Validation loss: 1.9456542422694545

Epoch: 6| Step: 3
Training loss: 1.1155738830566406
Validation loss: 2.0233438514894053

Epoch: 6| Step: 4
Training loss: 1.2268915176391602
Validation loss: 2.122248544487902

Epoch: 6| Step: 5
Training loss: 0.9080754518508911
Validation loss: 2.074446737125356

Epoch: 6| Step: 6
Training loss: 1.038301944732666
Validation loss: 1.9723739290750155

Epoch: 6| Step: 7
Training loss: 1.127766489982605
Validation loss: 1.881009606904881

Epoch: 6| Step: 8
Training loss: 1.0208992958068848
Validation loss: 1.8277609489297355

Epoch: 6| Step: 9
Training loss: 1.2705729007720947
Validation loss: 1.7974737767250306

Epoch: 6| Step: 10
Training loss: 1.3794794082641602
Validation loss: 1.7964208677250852

Epoch: 6| Step: 11
Training loss: 1.6123790740966797
Validation loss: 1.7838169836228894

Epoch: 6| Step: 12
Training loss: 1.247063398361206
Validation loss: 1.7977479081000052

Epoch: 6| Step: 13
Training loss: 0.8455190658569336
Validation loss: 1.8182077728291994

Epoch: 186| Step: 0
Training loss: 1.1963615417480469
Validation loss: 1.8812935736871534

Epoch: 6| Step: 1
Training loss: 0.9457209706306458
Validation loss: 1.9592897520270398

Epoch: 6| Step: 2
Training loss: 1.1274092197418213
Validation loss: 2.0774339040120444

Epoch: 6| Step: 3
Training loss: 1.3069236278533936
Validation loss: 2.130258878072103

Epoch: 6| Step: 4
Training loss: 0.9446136951446533
Validation loss: 2.148846105862689

Epoch: 6| Step: 5
Training loss: 1.7121596336364746
Validation loss: 2.071349525964388

Epoch: 6| Step: 6
Training loss: 1.4269698858261108
Validation loss: 1.9944200246564803

Epoch: 6| Step: 7
Training loss: 1.9202297925949097
Validation loss: 1.9334976134761688

Epoch: 6| Step: 8
Training loss: 0.8591964244842529
Validation loss: 1.8624474233196628

Epoch: 6| Step: 9
Training loss: 1.3234082460403442
Validation loss: 1.8290886353420954

Epoch: 6| Step: 10
Training loss: 1.1339073181152344
Validation loss: 1.7533300281852804

Epoch: 6| Step: 11
Training loss: 1.1293798685073853
Validation loss: 1.7469843459385697

Epoch: 6| Step: 12
Training loss: 0.7228822708129883
Validation loss: 1.8031946138669086

Epoch: 6| Step: 13
Training loss: 0.7826462984085083
Validation loss: 1.8254160419587167

Epoch: 187| Step: 0
Training loss: 1.1472773551940918
Validation loss: 1.820124477468511

Epoch: 6| Step: 1
Training loss: 1.3098933696746826
Validation loss: 1.8362955226693103

Epoch: 6| Step: 2
Training loss: 1.0677316188812256
Validation loss: 1.8790211434005408

Epoch: 6| Step: 3
Training loss: 1.666728138923645
Validation loss: 1.8853569569126252

Epoch: 6| Step: 4
Training loss: 1.1752350330352783
Validation loss: 1.8839437897487352

Epoch: 6| Step: 5
Training loss: 1.4260319471359253
Validation loss: 1.8860020509330175

Epoch: 6| Step: 6
Training loss: 1.4091298580169678
Validation loss: 1.8679545220508371

Epoch: 6| Step: 7
Training loss: 0.913036048412323
Validation loss: 1.843630676628441

Epoch: 6| Step: 8
Training loss: 1.4205344915390015
Validation loss: 1.872066060702006

Epoch: 6| Step: 9
Training loss: 1.3012861013412476
Validation loss: 1.876105377751012

Epoch: 6| Step: 10
Training loss: 1.181272029876709
Validation loss: 1.8807231944094422

Epoch: 6| Step: 11
Training loss: 0.8268320560455322
Validation loss: 1.857470868736185

Epoch: 6| Step: 12
Training loss: 1.1328480243682861
Validation loss: 1.9014938262201124

Epoch: 6| Step: 13
Training loss: 0.7566027045249939
Validation loss: 1.925278853344661

Epoch: 188| Step: 0
Training loss: 0.8879642486572266
Validation loss: 1.975866643331384

Epoch: 6| Step: 1
Training loss: 1.1172791719436646
Validation loss: 2.0126157319673927

Epoch: 6| Step: 2
Training loss: 1.1972966194152832
Validation loss: 1.9591271467106317

Epoch: 6| Step: 3
Training loss: 1.0162177085876465
Validation loss: 1.9091761663395872

Epoch: 6| Step: 4
Training loss: 1.3556337356567383
Validation loss: 1.8232678290336364

Epoch: 6| Step: 5
Training loss: 0.9542167782783508
Validation loss: 1.8076128741746307

Epoch: 6| Step: 6
Training loss: 1.2680901288986206
Validation loss: 1.835108668573441

Epoch: 6| Step: 7
Training loss: 1.0041439533233643
Validation loss: 1.8736485768389959

Epoch: 6| Step: 8
Training loss: 1.2652125358581543
Validation loss: 1.8974958876127839

Epoch: 6| Step: 9
Training loss: 1.4502655267715454
Validation loss: 1.8886082633849113

Epoch: 6| Step: 10
Training loss: 1.2639390230178833
Validation loss: 1.8213791142227829

Epoch: 6| Step: 11
Training loss: 1.0038650035858154
Validation loss: 1.8011445883781678

Epoch: 6| Step: 12
Training loss: 1.3184245824813843
Validation loss: 1.8432650245645994

Epoch: 6| Step: 13
Training loss: 1.1325945854187012
Validation loss: 1.8505464330796273

Epoch: 189| Step: 0
Training loss: 1.3570315837860107
Validation loss: 1.8717136524056877

Epoch: 6| Step: 1
Training loss: 1.0293779373168945
Validation loss: 1.881591894293344

Epoch: 6| Step: 2
Training loss: 0.7830407023429871
Validation loss: 1.8709771607511787

Epoch: 6| Step: 3
Training loss: 1.074709415435791
Validation loss: 1.876193420861357

Epoch: 6| Step: 4
Training loss: 1.6605250835418701
Validation loss: 1.848861712281422

Epoch: 6| Step: 5
Training loss: 0.5500082969665527
Validation loss: 1.8694571346364997

Epoch: 6| Step: 6
Training loss: 1.0718271732330322
Validation loss: 1.8971976798067811

Epoch: 6| Step: 7
Training loss: 1.2527453899383545
Validation loss: 1.895796860418012

Epoch: 6| Step: 8
Training loss: 1.6156904697418213
Validation loss: 1.8905480151535363

Epoch: 6| Step: 9
Training loss: 1.0467259883880615
Validation loss: 1.8914103507995605

Epoch: 6| Step: 10
Training loss: 1.1978201866149902
Validation loss: 1.88847263397709

Epoch: 6| Step: 11
Training loss: 0.5852853059768677
Validation loss: 1.8271807086083196

Epoch: 6| Step: 12
Training loss: 0.6996846199035645
Validation loss: 1.8771499856825797

Epoch: 6| Step: 13
Training loss: 1.4446377754211426
Validation loss: 1.8553342498758787

Epoch: 190| Step: 0
Training loss: 1.1016231775283813
Validation loss: 1.8183240070137927

Epoch: 6| Step: 1
Training loss: 0.6448570489883423
Validation loss: 1.8210569427859398

Epoch: 6| Step: 2
Training loss: 1.070041537284851
Validation loss: 1.8562950793132986

Epoch: 6| Step: 3
Training loss: 0.5473949909210205
Validation loss: 1.8947980737173429

Epoch: 6| Step: 4
Training loss: 1.3930869102478027
Validation loss: 1.9225411325372674

Epoch: 6| Step: 5
Training loss: 1.5582854747772217
Validation loss: 1.8956794456769062

Epoch: 6| Step: 6
Training loss: 0.6073487401008606
Validation loss: 1.8979369363477152

Epoch: 6| Step: 7
Training loss: 0.8658155798912048
Validation loss: 1.8888288121069632

Epoch: 6| Step: 8
Training loss: 1.5872948169708252
Validation loss: 1.8762649054168372

Epoch: 6| Step: 9
Training loss: 1.0217576026916504
Validation loss: 1.8660903374354045

Epoch: 6| Step: 10
Training loss: 1.189368486404419
Validation loss: 1.9037633890746741

Epoch: 6| Step: 11
Training loss: 1.2715415954589844
Validation loss: 1.904352213746758

Epoch: 6| Step: 12
Training loss: 1.2810142040252686
Validation loss: 1.9245431141186786

Epoch: 6| Step: 13
Training loss: 1.0994834899902344
Validation loss: 1.9019904380203576

Epoch: 191| Step: 0
Training loss: 1.1541545391082764
Validation loss: 1.8977918958151212

Epoch: 6| Step: 1
Training loss: 0.8384802341461182
Validation loss: 1.9029525685054

Epoch: 6| Step: 2
Training loss: 0.9804573059082031
Validation loss: 1.8931400724636611

Epoch: 6| Step: 3
Training loss: 1.4470709562301636
Validation loss: 1.8950879138003114

Epoch: 6| Step: 4
Training loss: 0.8525736331939697
Validation loss: 1.8267320215061147

Epoch: 6| Step: 5
Training loss: 0.7180613875389099
Validation loss: 1.7829057273044382

Epoch: 6| Step: 6
Training loss: 1.3675774335861206
Validation loss: 1.7810841183508597

Epoch: 6| Step: 7
Training loss: 1.123701810836792
Validation loss: 1.7751703287965508

Epoch: 6| Step: 8
Training loss: 1.1453572511672974
Validation loss: 1.785127075769568

Epoch: 6| Step: 9
Training loss: 1.0053868293762207
Validation loss: 1.8275462952993249

Epoch: 6| Step: 10
Training loss: 1.2986873388290405
Validation loss: 1.8681733877428117

Epoch: 6| Step: 11
Training loss: 1.2533767223358154
Validation loss: 1.9234131638721754

Epoch: 6| Step: 12
Training loss: 1.0377402305603027
Validation loss: 1.991140168200257

Epoch: 6| Step: 13
Training loss: 1.1832634210586548
Validation loss: 2.024876292033862

Epoch: 192| Step: 0
Training loss: 0.9649124145507812
Validation loss: 2.059909188619224

Epoch: 6| Step: 1
Training loss: 1.1988270282745361
Validation loss: 2.0283488919658046

Epoch: 6| Step: 2
Training loss: 0.7548846006393433
Validation loss: 1.9311334753549227

Epoch: 6| Step: 3
Training loss: 0.911570131778717
Validation loss: 1.8451339275606218

Epoch: 6| Step: 4
Training loss: 1.0975170135498047
Validation loss: 1.8076013800918416

Epoch: 6| Step: 5
Training loss: 0.8089531660079956
Validation loss: 1.7590375664413616

Epoch: 6| Step: 6
Training loss: 1.1396540403366089
Validation loss: 1.7736892905286563

Epoch: 6| Step: 7
Training loss: 0.7703970670700073
Validation loss: 1.7843117470382361

Epoch: 6| Step: 8
Training loss: 1.3863412141799927
Validation loss: 1.8034305598146172

Epoch: 6| Step: 9
Training loss: 1.1922502517700195
Validation loss: 1.8518087325557586

Epoch: 6| Step: 10
Training loss: 1.0895451307296753
Validation loss: 1.8891379499948153

Epoch: 6| Step: 11
Training loss: 1.3699829578399658
Validation loss: 1.8937470810387724

Epoch: 6| Step: 12
Training loss: 1.191491961479187
Validation loss: 1.9138166955722276

Epoch: 6| Step: 13
Training loss: 1.3525488376617432
Validation loss: 1.885688974011329

Epoch: 193| Step: 0
Training loss: 1.07798433303833
Validation loss: 1.8838580936513922

Epoch: 6| Step: 1
Training loss: 1.6745803356170654
Validation loss: 1.90879092677947

Epoch: 6| Step: 2
Training loss: 0.8973897695541382
Validation loss: 1.9097140142994542

Epoch: 6| Step: 3
Training loss: 1.0161876678466797
Validation loss: 1.9242916991633754

Epoch: 6| Step: 4
Training loss: 1.1599100828170776
Validation loss: 1.917447707986319

Epoch: 6| Step: 5
Training loss: 1.211609959602356
Validation loss: 1.923937169454431

Epoch: 6| Step: 6
Training loss: 0.8515251874923706
Validation loss: 1.9210100532859884

Epoch: 6| Step: 7
Training loss: 0.9209304451942444
Validation loss: 1.9071273393528436

Epoch: 6| Step: 8
Training loss: 0.8084313869476318
Validation loss: 1.8738899474502893

Epoch: 6| Step: 9
Training loss: 0.7502355575561523
Validation loss: 1.8473992834809005

Epoch: 6| Step: 10
Training loss: 0.5388883352279663
Validation loss: 1.8390662362498622

Epoch: 6| Step: 11
Training loss: 1.5051612854003906
Validation loss: 1.8284001158129783

Epoch: 6| Step: 12
Training loss: 1.1304843425750732
Validation loss: 1.8041611140774143

Epoch: 6| Step: 13
Training loss: 1.0065959692001343
Validation loss: 1.780471565902874

Epoch: 194| Step: 0
Training loss: 0.8005611896514893
Validation loss: 1.763910561479548

Epoch: 6| Step: 1
Training loss: 0.7661486864089966
Validation loss: 1.7670914844800067

Epoch: 6| Step: 2
Training loss: 1.1337039470672607
Validation loss: 1.8033193901020994

Epoch: 6| Step: 3
Training loss: 0.946050226688385
Validation loss: 1.8628990445085751

Epoch: 6| Step: 4
Training loss: 1.1387662887573242
Validation loss: 1.893319563199115

Epoch: 6| Step: 5
Training loss: 0.8428925275802612
Validation loss: 1.9183130751373947

Epoch: 6| Step: 6
Training loss: 1.1654468774795532
Validation loss: 1.960651909151385

Epoch: 6| Step: 7
Training loss: 0.8595496416091919
Validation loss: 1.9629228140718193

Epoch: 6| Step: 8
Training loss: 1.1327311992645264
Validation loss: 1.913938017301662

Epoch: 6| Step: 9
Training loss: 1.3169732093811035
Validation loss: 1.8558201597582908

Epoch: 6| Step: 10
Training loss: 1.4514319896697998
Validation loss: 1.8270962584403254

Epoch: 6| Step: 11
Training loss: 1.3290750980377197
Validation loss: 1.7963603311969387

Epoch: 6| Step: 12
Training loss: 0.8214573860168457
Validation loss: 1.810666157353309

Epoch: 6| Step: 13
Training loss: 0.5354598760604858
Validation loss: 1.7647596020852365

Epoch: 195| Step: 0
Training loss: 0.7735112905502319
Validation loss: 1.7804609396124398

Epoch: 6| Step: 1
Training loss: 1.0222595930099487
Validation loss: 1.810535204026007

Epoch: 6| Step: 2
Training loss: 1.4870734214782715
Validation loss: 1.8296073687973844

Epoch: 6| Step: 3
Training loss: 1.2912896871566772
Validation loss: 1.8530379315858245

Epoch: 6| Step: 4
Training loss: 0.6392906904220581
Validation loss: 1.8772525736080703

Epoch: 6| Step: 5
Training loss: 0.6907432079315186
Validation loss: 1.9086752527503557

Epoch: 6| Step: 6
Training loss: 1.5476195812225342
Validation loss: 1.9370290387061335

Epoch: 6| Step: 7
Training loss: 1.7379322052001953
Validation loss: 1.9078134041960522

Epoch: 6| Step: 8
Training loss: 0.9845302104949951
Validation loss: 1.883238366855088

Epoch: 6| Step: 9
Training loss: 0.6483467817306519
Validation loss: 1.8570011661898704

Epoch: 6| Step: 10
Training loss: 0.6260688304901123
Validation loss: 1.8429776673675866

Epoch: 6| Step: 11
Training loss: 0.950695812702179
Validation loss: 1.8263878322416736

Epoch: 6| Step: 12
Training loss: 0.7282524108886719
Validation loss: 1.7774475133547218

Epoch: 6| Step: 13
Training loss: 1.5269887447357178
Validation loss: 1.77129134567835

Epoch: 196| Step: 0
Training loss: 0.654534637928009
Validation loss: 1.7704474733721824

Epoch: 6| Step: 1
Training loss: 1.608586072921753
Validation loss: 1.7824806013414938

Epoch: 6| Step: 2
Training loss: 1.1333074569702148
Validation loss: 1.8084337403697353

Epoch: 6| Step: 3
Training loss: 1.5326898097991943
Validation loss: 1.8888725426889235

Epoch: 6| Step: 4
Training loss: 0.9867961406707764
Validation loss: 1.9398833205623012

Epoch: 6| Step: 5
Training loss: 1.0717248916625977
Validation loss: 1.909968494087137

Epoch: 6| Step: 6
Training loss: 0.8675968647003174
Validation loss: 1.8929580911513297

Epoch: 6| Step: 7
Training loss: 1.1368509531021118
Validation loss: 1.8504588834701046

Epoch: 6| Step: 8
Training loss: 0.7500372529029846
Validation loss: 1.8069751801029328

Epoch: 6| Step: 9
Training loss: 1.285876750946045
Validation loss: 1.8274946481950822

Epoch: 6| Step: 10
Training loss: 1.097048282623291
Validation loss: 1.841671218154251

Epoch: 6| Step: 11
Training loss: 0.4554935097694397
Validation loss: 1.8654384869401173

Epoch: 6| Step: 12
Training loss: 1.1818292140960693
Validation loss: 1.8742053137030652

Epoch: 6| Step: 13
Training loss: 0.631401538848877
Validation loss: 1.885770422156139

Epoch: 197| Step: 0
Training loss: 0.9770005345344543
Validation loss: 1.9051239490509033

Epoch: 6| Step: 1
Training loss: 0.4141615331172943
Validation loss: 1.9271565547553442

Epoch: 6| Step: 2
Training loss: 1.0076282024383545
Validation loss: 1.9384789107948222

Epoch: 6| Step: 3
Training loss: 0.9889615774154663
Validation loss: 1.961054673758886

Epoch: 6| Step: 4
Training loss: 0.7646109461784363
Validation loss: 2.0097189898131997

Epoch: 6| Step: 5
Training loss: 1.222277283668518
Validation loss: 1.964051442761575

Epoch: 6| Step: 6
Training loss: 0.6247155666351318
Validation loss: 1.9148777095220422

Epoch: 6| Step: 7
Training loss: 1.2762091159820557
Validation loss: 1.8708474482259443

Epoch: 6| Step: 8
Training loss: 1.2088074684143066
Validation loss: 1.8000667902731127

Epoch: 6| Step: 9
Training loss: 1.0290336608886719
Validation loss: 1.7614414948289112

Epoch: 6| Step: 10
Training loss: 1.412353754043579
Validation loss: 1.7455991903940837

Epoch: 6| Step: 11
Training loss: 0.8990991115570068
Validation loss: 1.7648716011355001

Epoch: 6| Step: 12
Training loss: 1.2601890563964844
Validation loss: 1.7999708716587355

Epoch: 6| Step: 13
Training loss: 0.8905431032180786
Validation loss: 1.8561187380103654

Epoch: 198| Step: 0
Training loss: 1.1427583694458008
Validation loss: 1.9235621908659577

Epoch: 6| Step: 1
Training loss: 1.4998993873596191
Validation loss: 1.9060495181750226

Epoch: 6| Step: 2
Training loss: 0.952547550201416
Validation loss: 1.8954784434328797

Epoch: 6| Step: 3
Training loss: 1.0907349586486816
Validation loss: 1.857790785451089

Epoch: 6| Step: 4
Training loss: 0.9375916719436646
Validation loss: 1.807241221909882

Epoch: 6| Step: 5
Training loss: 0.8090266585350037
Validation loss: 1.7972932528424006

Epoch: 6| Step: 6
Training loss: 1.135176420211792
Validation loss: 1.7850356512172247

Epoch: 6| Step: 7
Training loss: 1.1381474733352661
Validation loss: 1.8241678425060806

Epoch: 6| Step: 8
Training loss: 0.753612756729126
Validation loss: 1.8522790003848333

Epoch: 6| Step: 9
Training loss: 1.1140894889831543
Validation loss: 1.876251220703125

Epoch: 6| Step: 10
Training loss: 0.5951616764068604
Validation loss: 1.8508700786098358

Epoch: 6| Step: 11
Training loss: 1.0668545961380005
Validation loss: 1.862690366724486

Epoch: 6| Step: 12
Training loss: 0.6957273483276367
Validation loss: 1.8465922083905948

Epoch: 6| Step: 13
Training loss: 1.649096965789795
Validation loss: 1.8957987062392696

Epoch: 199| Step: 0
Training loss: 0.7022954225540161
Validation loss: 1.862739118196631

Epoch: 6| Step: 1
Training loss: 0.7679011225700378
Validation loss: 1.8316453785024664

Epoch: 6| Step: 2
Training loss: 1.0916692018508911
Validation loss: 1.8159595856102564

Epoch: 6| Step: 3
Training loss: 1.2775261402130127
Validation loss: 1.8096033873096589

Epoch: 6| Step: 4
Training loss: 0.6083277463912964
Validation loss: 1.8381012075690812

Epoch: 6| Step: 5
Training loss: 1.0553478002548218
Validation loss: 1.8593577979713358

Epoch: 6| Step: 6
Training loss: 0.9914119243621826
Validation loss: 1.8977686897400887

Epoch: 6| Step: 7
Training loss: 1.7373197078704834
Validation loss: 1.9579417192807762

Epoch: 6| Step: 8
Training loss: 0.6751358509063721
Validation loss: 1.9741281437617477

Epoch: 6| Step: 9
Training loss: 0.8929065465927124
Validation loss: 1.9434309287737774

Epoch: 6| Step: 10
Training loss: 1.199225902557373
Validation loss: 1.9360588519803938

Epoch: 6| Step: 11
Training loss: 0.7855933308601379
Validation loss: 1.8955626205731464

Epoch: 6| Step: 12
Training loss: 0.6687934398651123
Validation loss: 1.854529917881053

Epoch: 6| Step: 13
Training loss: 1.160317301750183
Validation loss: 1.8756573982136224

Epoch: 200| Step: 0
Training loss: 1.1707979440689087
Validation loss: 1.836720940887287

Epoch: 6| Step: 1
Training loss: 1.2507078647613525
Validation loss: 1.8306474160122614

Epoch: 6| Step: 2
Training loss: 0.4676892161369324
Validation loss: 1.8447441657384236

Epoch: 6| Step: 3
Training loss: 0.6224269270896912
Validation loss: 1.8503570313094764

Epoch: 6| Step: 4
Training loss: 1.071976900100708
Validation loss: 1.8447402433682514

Epoch: 6| Step: 5
Training loss: 0.876300573348999
Validation loss: 1.8391038833125946

Epoch: 6| Step: 6
Training loss: 0.6071595549583435
Validation loss: 1.8580645117708432

Epoch: 6| Step: 7
Training loss: 0.9108189344406128
Validation loss: 1.8727260199926232

Epoch: 6| Step: 8
Training loss: 1.045196533203125
Validation loss: 1.843126953289073

Epoch: 6| Step: 9
Training loss: 1.1434295177459717
Validation loss: 1.8315887733172345

Epoch: 6| Step: 10
Training loss: 1.5424468517303467
Validation loss: 1.8124506319722822

Epoch: 6| Step: 11
Training loss: 0.8808199167251587
Validation loss: 1.812648973157329

Epoch: 6| Step: 12
Training loss: 1.0663655996322632
Validation loss: 1.7834467682787167

Epoch: 6| Step: 13
Training loss: 0.5292804837226868
Validation loss: 1.746150512849131

Epoch: 201| Step: 0
Training loss: 1.0868628025054932
Validation loss: 1.7555797740977297

Epoch: 6| Step: 1
Training loss: 0.8603001236915588
Validation loss: 1.7525967808179959

Epoch: 6| Step: 2
Training loss: 1.4983735084533691
Validation loss: 1.790279806301158

Epoch: 6| Step: 3
Training loss: 0.9304478168487549
Validation loss: 1.8440637050136444

Epoch: 6| Step: 4
Training loss: 0.824591338634491
Validation loss: 1.9089993558904177

Epoch: 6| Step: 5
Training loss: 0.6577199697494507
Validation loss: 1.9562311864668323

Epoch: 6| Step: 6
Training loss: 0.8191753625869751
Validation loss: 1.9636758373629661

Epoch: 6| Step: 7
Training loss: 0.6981494426727295
Validation loss: 1.916838312661776

Epoch: 6| Step: 8
Training loss: 0.5677555799484253
Validation loss: 1.84451340347208

Epoch: 6| Step: 9
Training loss: 0.8552647829055786
Validation loss: 1.7907244928421513

Epoch: 6| Step: 10
Training loss: 0.8469284772872925
Validation loss: 1.7453581684379167

Epoch: 6| Step: 11
Training loss: 1.0670192241668701
Validation loss: 1.7120367314225884

Epoch: 6| Step: 12
Training loss: 1.3446886539459229
Validation loss: 1.7383046739844865

Epoch: 6| Step: 13
Training loss: 1.4762516021728516
Validation loss: 1.736548448121676

Epoch: 202| Step: 0
Training loss: 0.8201993703842163
Validation loss: 1.7688997368658743

Epoch: 6| Step: 1
Training loss: 1.190630555152893
Validation loss: 1.8031744674969745

Epoch: 6| Step: 2
Training loss: 1.0280593633651733
Validation loss: 1.8649844584926483

Epoch: 6| Step: 3
Training loss: 1.1432751417160034
Validation loss: 1.897054672241211

Epoch: 6| Step: 4
Training loss: 1.2271728515625
Validation loss: 1.8696733956695886

Epoch: 6| Step: 5
Training loss: 0.7973767518997192
Validation loss: 1.8570795725750666

Epoch: 6| Step: 6
Training loss: 1.0557188987731934
Validation loss: 1.8398858834338445

Epoch: 6| Step: 7
Training loss: 0.5777214169502258
Validation loss: 1.774972600321616

Epoch: 6| Step: 8
Training loss: 1.091892957687378
Validation loss: 1.7813965505169285

Epoch: 6| Step: 9
Training loss: 0.6440404653549194
Validation loss: 1.7583070224331272

Epoch: 6| Step: 10
Training loss: 1.1068089008331299
Validation loss: 1.754976007246202

Epoch: 6| Step: 11
Training loss: 0.943684458732605
Validation loss: 1.7339184373937628

Epoch: 6| Step: 12
Training loss: 1.0018216371536255
Validation loss: 1.7428353742886615

Epoch: 6| Step: 13
Training loss: 0.8342515230178833
Validation loss: 1.7472272688342678

Epoch: 203| Step: 0
Training loss: 0.8166458606719971
Validation loss: 1.7632615258616786

Epoch: 6| Step: 1
Training loss: 0.7438084483146667
Validation loss: 1.7811414682736961

Epoch: 6| Step: 2
Training loss: 0.7932465672492981
Validation loss: 1.8196306485001759

Epoch: 6| Step: 3
Training loss: 0.5882533192634583
Validation loss: 1.8636884279148553

Epoch: 6| Step: 4
Training loss: 1.4898580312728882
Validation loss: 1.9381765652728338

Epoch: 6| Step: 5
Training loss: 0.9080374240875244
Validation loss: 1.9675526759957755

Epoch: 6| Step: 6
Training loss: 1.1948107481002808
Validation loss: 1.9857387940088909

Epoch: 6| Step: 7
Training loss: 1.1713221073150635
Validation loss: 1.9601363930650937

Epoch: 6| Step: 8
Training loss: 0.6093811392784119
Validation loss: 1.9613855833648353

Epoch: 6| Step: 9
Training loss: 0.9944415092468262
Validation loss: 1.9225428155673447

Epoch: 6| Step: 10
Training loss: 0.5936483144760132
Validation loss: 1.9154618401681223

Epoch: 6| Step: 11
Training loss: 1.113305926322937
Validation loss: 1.8801748444957118

Epoch: 6| Step: 12
Training loss: 0.8307390809059143
Validation loss: 1.8715047118484334

Epoch: 6| Step: 13
Training loss: 1.0446937084197998
Validation loss: 1.8188863159507833

Epoch: 204| Step: 0
Training loss: 0.7740023732185364
Validation loss: 1.7939107623151553

Epoch: 6| Step: 1
Training loss: 0.535251259803772
Validation loss: 1.798167323553434

Epoch: 6| Step: 2
Training loss: 0.7818767428398132
Validation loss: 1.79977431092211

Epoch: 6| Step: 3
Training loss: 0.7041082382202148
Validation loss: 1.8296710996217624

Epoch: 6| Step: 4
Training loss: 0.9893893599510193
Validation loss: 1.858968242522209

Epoch: 6| Step: 5
Training loss: 1.120850682258606
Validation loss: 1.8921707689121205

Epoch: 6| Step: 6
Training loss: 0.8080497980117798
Validation loss: 1.9088949952074277

Epoch: 6| Step: 7
Training loss: 0.9718239307403564
Validation loss: 1.9033852136263283

Epoch: 6| Step: 8
Training loss: 1.4228185415267944
Validation loss: 1.8772819196024249

Epoch: 6| Step: 9
Training loss: 0.9758747220039368
Validation loss: 1.7821759857157224

Epoch: 6| Step: 10
Training loss: 1.1184862852096558
Validation loss: 1.7717077629540556

Epoch: 6| Step: 11
Training loss: 0.9364815354347229
Validation loss: 1.7796236468899636

Epoch: 6| Step: 12
Training loss: 0.8452892303466797
Validation loss: 1.782364373566002

Epoch: 6| Step: 13
Training loss: 0.6024879813194275
Validation loss: 1.812863169177886

Epoch: 205| Step: 0
Training loss: 0.9757225513458252
Validation loss: 1.8142926154598114

Epoch: 6| Step: 1
Training loss: 1.0876665115356445
Validation loss: 1.8216086510689027

Epoch: 6| Step: 2
Training loss: 0.695851743221283
Validation loss: 1.814053463679488

Epoch: 6| Step: 3
Training loss: 0.7685672044754028
Validation loss: 1.7962473925723825

Epoch: 6| Step: 4
Training loss: 1.0181777477264404
Validation loss: 1.8080214979828044

Epoch: 6| Step: 5
Training loss: 1.18839430809021
Validation loss: 1.8092777652125205

Epoch: 6| Step: 6
Training loss: 1.0364054441452026
Validation loss: 1.8326842887427217

Epoch: 6| Step: 7
Training loss: 1.087476134300232
Validation loss: 1.8349357625489593

Epoch: 6| Step: 8
Training loss: 0.846149206161499
Validation loss: 1.8432392766398769

Epoch: 6| Step: 9
Training loss: 0.6411116719245911
Validation loss: 1.8571786931765977

Epoch: 6| Step: 10
Training loss: 0.9405447244644165
Validation loss: 1.797207869509215

Epoch: 6| Step: 11
Training loss: 0.6644787788391113
Validation loss: 1.7668834963152487

Epoch: 6| Step: 12
Training loss: 0.766586422920227
Validation loss: 1.7479947074767082

Epoch: 6| Step: 13
Training loss: 0.6245805025100708
Validation loss: 1.7306170245652557

Epoch: 206| Step: 0
Training loss: 0.4121509790420532
Validation loss: 1.7321887170114825

Epoch: 6| Step: 1
Training loss: 0.6189172267913818
Validation loss: 1.7229197435481574

Epoch: 6| Step: 2
Training loss: 1.0371365547180176
Validation loss: 1.7322590069104267

Epoch: 6| Step: 3
Training loss: 0.8062129020690918
Validation loss: 1.7172581047140143

Epoch: 6| Step: 4
Training loss: 1.4626734256744385
Validation loss: 1.7721196195130706

Epoch: 6| Step: 5
Training loss: 0.5671848058700562
Validation loss: 1.7951926082693122

Epoch: 6| Step: 6
Training loss: 0.4619511663913727
Validation loss: 1.8077332127478816

Epoch: 6| Step: 7
Training loss: 1.3543341159820557
Validation loss: 1.8136782556451776

Epoch: 6| Step: 8
Training loss: 1.5389659404754639
Validation loss: 1.795323823087959

Epoch: 6| Step: 9
Training loss: 0.7209919691085815
Validation loss: 1.806033226751512

Epoch: 6| Step: 10
Training loss: 0.5653473138809204
Validation loss: 1.7909500611725675

Epoch: 6| Step: 11
Training loss: 1.045996904373169
Validation loss: 1.7775088087204964

Epoch: 6| Step: 12
Training loss: 0.8435492515563965
Validation loss: 1.761432578486781

Epoch: 6| Step: 13
Training loss: 1.1728863716125488
Validation loss: 1.7965903807711858

Epoch: 207| Step: 0
Training loss: 1.1221141815185547
Validation loss: 1.855470008747552

Epoch: 6| Step: 1
Training loss: 0.42320987582206726
Validation loss: 1.8631173756814772

Epoch: 6| Step: 2
Training loss: 0.9554024338722229
Validation loss: 1.8961667553071053

Epoch: 6| Step: 3
Training loss: 0.6651955842971802
Validation loss: 1.8862951609396166

Epoch: 6| Step: 4
Training loss: 1.0893619060516357
Validation loss: 1.8573035104300386

Epoch: 6| Step: 5
Training loss: 0.8235411643981934
Validation loss: 1.7796770667517057

Epoch: 6| Step: 6
Training loss: 0.8657145500183105
Validation loss: 1.7533251700862762

Epoch: 6| Step: 7
Training loss: 0.5156933665275574
Validation loss: 1.7482302432419152

Epoch: 6| Step: 8
Training loss: 1.0645861625671387
Validation loss: 1.7614216189230643

Epoch: 6| Step: 9
Training loss: 0.8737182021141052
Validation loss: 1.7641783145166212

Epoch: 6| Step: 10
Training loss: 0.9236605167388916
Validation loss: 1.8257919857578893

Epoch: 6| Step: 11
Training loss: 0.7502112984657288
Validation loss: 1.8588048937500163

Epoch: 6| Step: 12
Training loss: 0.9804307222366333
Validation loss: 1.895351384275703

Epoch: 6| Step: 13
Training loss: 1.0495387315750122
Validation loss: 1.9301518291555426

Epoch: 208| Step: 0
Training loss: 1.0815162658691406
Validation loss: 1.8799618110861829

Epoch: 6| Step: 1
Training loss: 0.9186719655990601
Validation loss: 1.8501659862456783

Epoch: 6| Step: 2
Training loss: 0.7248117327690125
Validation loss: 1.7810682853062947

Epoch: 6| Step: 3
Training loss: 1.444610595703125
Validation loss: 1.756161864085864

Epoch: 6| Step: 4
Training loss: 0.5618557929992676
Validation loss: 1.7598768703399166

Epoch: 6| Step: 5
Training loss: 0.683425784111023
Validation loss: 1.7960163431782876

Epoch: 6| Step: 6
Training loss: 0.5217585563659668
Validation loss: 1.8420943842139295

Epoch: 6| Step: 7
Training loss: 1.1313658952713013
Validation loss: 1.8719719532997376

Epoch: 6| Step: 8
Training loss: 0.8297352194786072
Validation loss: 1.8633753599659089

Epoch: 6| Step: 9
Training loss: 0.5812525749206543
Validation loss: 1.8431679074482252

Epoch: 6| Step: 10
Training loss: 1.3180574178695679
Validation loss: 1.8438231752764793

Epoch: 6| Step: 11
Training loss: 0.6451229453086853
Validation loss: 1.830579665399367

Epoch: 6| Step: 12
Training loss: 0.8188278079032898
Validation loss: 1.818211140171174

Epoch: 6| Step: 13
Training loss: 1.4283945560455322
Validation loss: 1.7823914110019643

Epoch: 209| Step: 0
Training loss: 0.41264957189559937
Validation loss: 1.7664900672051214

Epoch: 6| Step: 1
Training loss: 1.0075149536132812
Validation loss: 1.789879149006259

Epoch: 6| Step: 2
Training loss: 0.6727489233016968
Validation loss: 1.8076587159146544

Epoch: 6| Step: 3
Training loss: 0.684424877166748
Validation loss: 1.8203228301899408

Epoch: 6| Step: 4
Training loss: 1.247262954711914
Validation loss: 1.8319974099436114

Epoch: 6| Step: 5
Training loss: 0.7806794047355652
Validation loss: 1.825258852333151

Epoch: 6| Step: 6
Training loss: 0.6511554718017578
Validation loss: 1.8004273483830113

Epoch: 6| Step: 7
Training loss: 1.1752575635910034
Validation loss: 1.8093491228677894

Epoch: 6| Step: 8
Training loss: 1.5979547500610352
Validation loss: 1.8101393612482215

Epoch: 6| Step: 9
Training loss: 0.6456703543663025
Validation loss: 1.7982528184049873

Epoch: 6| Step: 10
Training loss: 0.7699368000030518
Validation loss: 1.8010090551068705

Epoch: 6| Step: 11
Training loss: 0.6211053729057312
Validation loss: 1.8154063455520137

Epoch: 6| Step: 12
Training loss: 1.2053186893463135
Validation loss: 1.8174311063622917

Epoch: 6| Step: 13
Training loss: 0.8150379657745361
Validation loss: 1.857604685650077

Epoch: 210| Step: 0
Training loss: 1.130751371383667
Validation loss: 1.793370250732668

Epoch: 6| Step: 1
Training loss: 0.8783920407295227
Validation loss: 1.7766730234187136

Epoch: 6| Step: 2
Training loss: 0.5968624949455261
Validation loss: 1.7491164771459435

Epoch: 6| Step: 3
Training loss: 0.5431865453720093
Validation loss: 1.7249335806856874

Epoch: 6| Step: 4
Training loss: 0.8382111191749573
Validation loss: 1.7356426882487472

Epoch: 6| Step: 5
Training loss: 1.2469990253448486
Validation loss: 1.7553663074329335

Epoch: 6| Step: 6
Training loss: 0.7777532339096069
Validation loss: 1.7793957315465456

Epoch: 6| Step: 7
Training loss: 0.9118419289588928
Validation loss: 1.824866546097622

Epoch: 6| Step: 8
Training loss: 0.5921717882156372
Validation loss: 1.8502886346591416

Epoch: 6| Step: 9
Training loss: 0.8063409328460693
Validation loss: 1.8320494903031217

Epoch: 6| Step: 10
Training loss: 1.0905919075012207
Validation loss: 1.7878752600762151

Epoch: 6| Step: 11
Training loss: 1.0081076622009277
Validation loss: 1.7530705819847763

Epoch: 6| Step: 12
Training loss: 0.902272641658783
Validation loss: 1.7389651498486918

Epoch: 6| Step: 13
Training loss: 0.8117132782936096
Validation loss: 1.735944612051851

Epoch: 211| Step: 0
Training loss: 0.9009397029876709
Validation loss: 1.7685460147037302

Epoch: 6| Step: 1
Training loss: 1.1910070180892944
Validation loss: 1.7845821649797502

Epoch: 6| Step: 2
Training loss: 0.5317573547363281
Validation loss: 1.7960378957051102

Epoch: 6| Step: 3
Training loss: 0.8456557989120483
Validation loss: 1.8290482631293676

Epoch: 6| Step: 4
Training loss: 1.1536933183670044
Validation loss: 1.8013649743090394

Epoch: 6| Step: 5
Training loss: 1.2042783498764038
Validation loss: 1.8133384181607155

Epoch: 6| Step: 6
Training loss: 0.6270108819007874
Validation loss: 1.8242117986884168

Epoch: 6| Step: 7
Training loss: 0.6793761253356934
Validation loss: 1.8182944213190386

Epoch: 6| Step: 8
Training loss: 0.7300748229026794
Validation loss: 1.7716610841853644

Epoch: 6| Step: 9
Training loss: 0.49947333335876465
Validation loss: 1.7576269654817478

Epoch: 6| Step: 10
Training loss: 0.6743705868721008
Validation loss: 1.739417145329137

Epoch: 6| Step: 11
Training loss: 1.162827491760254
Validation loss: 1.7096454712652391

Epoch: 6| Step: 12
Training loss: 0.7655612230300903
Validation loss: 1.7299384993891562

Epoch: 6| Step: 13
Training loss: 0.4982074201107025
Validation loss: 1.7641228347696283

Epoch: 212| Step: 0
Training loss: 0.7921605110168457
Validation loss: 1.7817684873457877

Epoch: 6| Step: 1
Training loss: 0.6018643379211426
Validation loss: 1.7907334245661253

Epoch: 6| Step: 2
Training loss: 0.6743412017822266
Validation loss: 1.7950879027766566

Epoch: 6| Step: 3
Training loss: 0.8957698345184326
Validation loss: 1.8094028734391736

Epoch: 6| Step: 4
Training loss: 0.7885668277740479
Validation loss: 1.803211030139718

Epoch: 6| Step: 5
Training loss: 0.6739199161529541
Validation loss: 1.781602123732208

Epoch: 6| Step: 6
Training loss: 0.6720085144042969
Validation loss: 1.7773565528213338

Epoch: 6| Step: 7
Training loss: 1.0767643451690674
Validation loss: 1.7848198862485989

Epoch: 6| Step: 8
Training loss: 1.1088840961456299
Validation loss: 1.8383287742573728

Epoch: 6| Step: 9
Training loss: 0.7211545705795288
Validation loss: 1.8747159357993834

Epoch: 6| Step: 10
Training loss: 1.5231354236602783
Validation loss: 1.8598240613937378

Epoch: 6| Step: 11
Training loss: 0.3590247929096222
Validation loss: 1.8359066722213582

Epoch: 6| Step: 12
Training loss: 0.849799633026123
Validation loss: 1.8058227454462359

Epoch: 6| Step: 13
Training loss: 0.5875250697135925
Validation loss: 1.782211616475095

Epoch: 213| Step: 0
Training loss: 0.9749562740325928
Validation loss: 1.7499121132717337

Epoch: 6| Step: 1
Training loss: 1.627968430519104
Validation loss: 1.7448195988132107

Epoch: 6| Step: 2
Training loss: 0.46361851692199707
Validation loss: 1.748874190033123

Epoch: 6| Step: 3
Training loss: 0.7412497401237488
Validation loss: 1.7990829777973953

Epoch: 6| Step: 4
Training loss: 0.9520187377929688
Validation loss: 1.864240170806967

Epoch: 6| Step: 5
Training loss: 1.041273593902588
Validation loss: 1.9511972819605181

Epoch: 6| Step: 6
Training loss: 0.7534157037734985
Validation loss: 2.0047935093602827

Epoch: 6| Step: 7
Training loss: 1.734179973602295
Validation loss: 1.984339960159794

Epoch: 6| Step: 8
Training loss: 0.4595590829849243
Validation loss: 1.8797999940892702

Epoch: 6| Step: 9
Training loss: 0.6661176681518555
Validation loss: 1.729821922958538

Epoch: 6| Step: 10
Training loss: 0.7923873662948608
Validation loss: 1.6890531406607678

Epoch: 6| Step: 11
Training loss: 0.797768235206604
Validation loss: 1.6532967962244505

Epoch: 6| Step: 12
Training loss: 0.6488954424858093
Validation loss: 1.6705245958861483

Epoch: 6| Step: 13
Training loss: 0.5372784733772278
Validation loss: 1.66154706862665

Epoch: 214| Step: 0
Training loss: 1.0856420993804932
Validation loss: 1.669009058706222

Epoch: 6| Step: 1
Training loss: 0.47661393880844116
Validation loss: 1.6834403750717

Epoch: 6| Step: 2
Training loss: 1.244524359703064
Validation loss: 1.7280169148598947

Epoch: 6| Step: 3
Training loss: 1.074761152267456
Validation loss: 1.7987062559332898

Epoch: 6| Step: 4
Training loss: 0.7438564300537109
Validation loss: 1.8442478397841096

Epoch: 6| Step: 5
Training loss: 0.5360701084136963
Validation loss: 1.8944857966515325

Epoch: 6| Step: 6
Training loss: 0.9684959053993225
Validation loss: 1.8461023684470885

Epoch: 6| Step: 7
Training loss: 0.7880809307098389
Validation loss: 1.8352030836125857

Epoch: 6| Step: 8
Training loss: 0.7118175625801086
Validation loss: 1.7703302996132964

Epoch: 6| Step: 9
Training loss: 0.7145391702651978
Validation loss: 1.7385247112602316

Epoch: 6| Step: 10
Training loss: 0.5147543549537659
Validation loss: 1.7122422418286722

Epoch: 6| Step: 11
Training loss: 1.0547571182250977
Validation loss: 1.7251938953194568

Epoch: 6| Step: 12
Training loss: 0.9140243530273438
Validation loss: 1.7038119557083293

Epoch: 6| Step: 13
Training loss: 1.1105026006698608
Validation loss: 1.7175542487893054

Epoch: 215| Step: 0
Training loss: 0.7770016193389893
Validation loss: 1.7362034436195128

Epoch: 6| Step: 1
Training loss: 0.5563024282455444
Validation loss: 1.749410734381727

Epoch: 6| Step: 2
Training loss: 0.9912571310997009
Validation loss: 1.7851549143432288

Epoch: 6| Step: 3
Training loss: 0.6947436928749084
Validation loss: 1.809560619374757

Epoch: 6| Step: 4
Training loss: 0.6923911571502686
Validation loss: 1.8416565451570737

Epoch: 6| Step: 5
Training loss: 0.9424341320991516
Validation loss: 1.8934525341115973

Epoch: 6| Step: 6
Training loss: 1.1433440446853638
Validation loss: 1.8785524868196057

Epoch: 6| Step: 7
Training loss: 0.9781597852706909
Validation loss: 1.827519533454731

Epoch: 6| Step: 8
Training loss: 0.7627905011177063
Validation loss: 1.7576892632310108

Epoch: 6| Step: 9
Training loss: 0.8204283714294434
Validation loss: 1.6945059555833057

Epoch: 6| Step: 10
Training loss: 1.0026323795318604
Validation loss: 1.6695981294878068

Epoch: 6| Step: 11
Training loss: 1.1742746829986572
Validation loss: 1.65797725800545

Epoch: 6| Step: 12
Training loss: 0.7765779495239258
Validation loss: 1.6509815057118733

Epoch: 6| Step: 13
Training loss: 0.748961865901947
Validation loss: 1.6803347577330887

Epoch: 216| Step: 0
Training loss: 0.37659361958503723
Validation loss: 1.711588616012245

Epoch: 6| Step: 1
Training loss: 0.8668954372406006
Validation loss: 1.8112466745479132

Epoch: 6| Step: 2
Training loss: 1.177842617034912
Validation loss: 1.871482249229185

Epoch: 6| Step: 3
Training loss: 0.5437291860580444
Validation loss: 1.9010525916212349

Epoch: 6| Step: 4
Training loss: 0.776313304901123
Validation loss: 1.951263512334516

Epoch: 6| Step: 5
Training loss: 1.006105899810791
Validation loss: 1.9707219421222646

Epoch: 6| Step: 6
Training loss: 0.4579562544822693
Validation loss: 1.9264667700695735

Epoch: 6| Step: 7
Training loss: 0.8004729151725769
Validation loss: 1.8653739357507357

Epoch: 6| Step: 8
Training loss: 0.8461619019508362
Validation loss: 1.7537454981957712

Epoch: 6| Step: 9
Training loss: 0.7679020166397095
Validation loss: 1.7037825212683728

Epoch: 6| Step: 10
Training loss: 0.8236387968063354
Validation loss: 1.6563823633296515

Epoch: 6| Step: 11
Training loss: 1.5383448600769043
Validation loss: 1.6336839737430695

Epoch: 6| Step: 12
Training loss: 0.7224535942077637
Validation loss: 1.6289596070525467

Epoch: 6| Step: 13
Training loss: 1.4571646451950073
Validation loss: 1.6420448082749561

Epoch: 217| Step: 0
Training loss: 0.6506540775299072
Validation loss: 1.678797714171871

Epoch: 6| Step: 1
Training loss: 0.9067824482917786
Validation loss: 1.7498485003748248

Epoch: 6| Step: 2
Training loss: 0.6757858395576477
Validation loss: 1.7988052086163593

Epoch: 6| Step: 3
Training loss: 0.4098760485649109
Validation loss: 1.853388617115636

Epoch: 6| Step: 4
Training loss: 1.239667296409607
Validation loss: 1.8940634240386307

Epoch: 6| Step: 5
Training loss: 0.8845939636230469
Validation loss: 1.886017584031628

Epoch: 6| Step: 6
Training loss: 0.651658296585083
Validation loss: 1.8433368564933859

Epoch: 6| Step: 7
Training loss: 0.9428598284721375
Validation loss: 1.7843092795341247

Epoch: 6| Step: 8
Training loss: 0.8988544940948486
Validation loss: 1.7477975929937055

Epoch: 6| Step: 9
Training loss: 0.5364834666252136
Validation loss: 1.7054154417848075

Epoch: 6| Step: 10
Training loss: 1.0287697315216064
Validation loss: 1.6568095555869482

Epoch: 6| Step: 11
Training loss: 1.4021271467208862
Validation loss: 1.6636555630673644

Epoch: 6| Step: 12
Training loss: 0.7201229929924011
Validation loss: 1.6357242958520049

Epoch: 6| Step: 13
Training loss: 1.063025712966919
Validation loss: 1.6688334352226668

Epoch: 218| Step: 0
Training loss: 0.7797789573669434
Validation loss: 1.6949111633403326

Epoch: 6| Step: 1
Training loss: 0.7005318403244019
Validation loss: 1.7821999467829222

Epoch: 6| Step: 2
Training loss: 1.4317266941070557
Validation loss: 1.9072570621326406

Epoch: 6| Step: 3
Training loss: 0.8706895112991333
Validation loss: 1.9478115292005642

Epoch: 6| Step: 4
Training loss: 0.8633385896682739
Validation loss: 1.9383425558767011

Epoch: 6| Step: 5
Training loss: 0.5428650379180908
Validation loss: 1.8918414372269825

Epoch: 6| Step: 6
Training loss: 1.089717149734497
Validation loss: 1.8841519471137755

Epoch: 6| Step: 7
Training loss: 0.6782245635986328
Validation loss: 1.8382431948056785

Epoch: 6| Step: 8
Training loss: 0.5570037364959717
Validation loss: 1.7944991447592293

Epoch: 6| Step: 9
Training loss: 0.5698943138122559
Validation loss: 1.792054158385082

Epoch: 6| Step: 10
Training loss: 0.8800931572914124
Validation loss: 1.77527864004976

Epoch: 6| Step: 11
Training loss: 0.9477083683013916
Validation loss: 1.7481048004601591

Epoch: 6| Step: 12
Training loss: 0.7351055145263672
Validation loss: 1.7538627642457203

Epoch: 6| Step: 13
Training loss: 0.4707847833633423
Validation loss: 1.743433362694197

Epoch: 219| Step: 0
Training loss: 0.673862099647522
Validation loss: 1.8021607821987522

Epoch: 6| Step: 1
Training loss: 0.8567444086074829
Validation loss: 1.817652713867926

Epoch: 6| Step: 2
Training loss: 0.5624409914016724
Validation loss: 1.8425891373747139

Epoch: 6| Step: 3
Training loss: 1.2128186225891113
Validation loss: 1.8590802120906051

Epoch: 6| Step: 4
Training loss: 0.7090128064155579
Validation loss: 1.8082879794541227

Epoch: 6| Step: 5
Training loss: 0.45671212673187256
Validation loss: 1.771865265343779

Epoch: 6| Step: 6
Training loss: 0.5388831496238708
Validation loss: 1.7729965589379753

Epoch: 6| Step: 7
Training loss: 0.9825750589370728
Validation loss: 1.7808604676236388

Epoch: 6| Step: 8
Training loss: 0.8325036764144897
Validation loss: 1.8108266579207553

Epoch: 6| Step: 9
Training loss: 0.8049759864807129
Validation loss: 1.8086001411561043

Epoch: 6| Step: 10
Training loss: 0.5906130075454712
Validation loss: 1.8273334362173592

Epoch: 6| Step: 11
Training loss: 0.6541492938995361
Validation loss: 1.8351659505598006

Epoch: 6| Step: 12
Training loss: 1.0704782009124756
Validation loss: 1.815298709818112

Epoch: 6| Step: 13
Training loss: 0.4613431394100189
Validation loss: 1.7885049722527946

Epoch: 220| Step: 0
Training loss: 0.7330325841903687
Validation loss: 1.7710075801418674

Epoch: 6| Step: 1
Training loss: 0.38298290967941284
Validation loss: 1.7654518209477907

Epoch: 6| Step: 2
Training loss: 0.8016133308410645
Validation loss: 1.7451183847201768

Epoch: 6| Step: 3
Training loss: 0.7530852556228638
Validation loss: 1.7604112689213087

Epoch: 6| Step: 4
Training loss: 0.7702267169952393
Validation loss: 1.7638412393549436

Epoch: 6| Step: 5
Training loss: 0.7126550674438477
Validation loss: 1.7440930745934928

Epoch: 6| Step: 6
Training loss: 0.6770049333572388
Validation loss: 1.756985648985832

Epoch: 6| Step: 7
Training loss: 0.9648151993751526
Validation loss: 1.7972721950982207

Epoch: 6| Step: 8
Training loss: 0.903252899646759
Validation loss: 1.7906416334131712

Epoch: 6| Step: 9
Training loss: 0.4940767288208008
Validation loss: 1.7544761575678343

Epoch: 6| Step: 10
Training loss: 0.7880468368530273
Validation loss: 1.7536761324892762

Epoch: 6| Step: 11
Training loss: 0.6590977907180786
Validation loss: 1.7275112944264566

Epoch: 6| Step: 12
Training loss: 0.5058501362800598
Validation loss: 1.716036909370012

Epoch: 6| Step: 13
Training loss: 0.8581182360649109
Validation loss: 1.703534290354739

Epoch: 221| Step: 0
Training loss: 0.381491482257843
Validation loss: 1.6570164426680534

Epoch: 6| Step: 1
Training loss: 0.5927568078041077
Validation loss: 1.692167910196448

Epoch: 6| Step: 2
Training loss: 0.3830867409706116
Validation loss: 1.7007562729620165

Epoch: 6| Step: 3
Training loss: 0.42383497953414917
Validation loss: 1.7092928565958494

Epoch: 6| Step: 4
Training loss: 0.6294289231300354
Validation loss: 1.7263296804120463

Epoch: 6| Step: 5
Training loss: 0.7677823305130005
Validation loss: 1.7609078422669442

Epoch: 6| Step: 6
Training loss: 0.9569637775421143
Validation loss: 1.8144367612818235

Epoch: 6| Step: 7
Training loss: 0.9521517157554626
Validation loss: 1.8158880613183463

Epoch: 6| Step: 8
Training loss: 0.7877667546272278
Validation loss: 1.8828446659990536

Epoch: 6| Step: 9
Training loss: 0.7776914834976196
Validation loss: 1.9048390324397753

Epoch: 6| Step: 10
Training loss: 1.000152587890625
Validation loss: 1.8531574151849235

Epoch: 6| Step: 11
Training loss: 0.4801862835884094
Validation loss: 1.8277355112055296

Epoch: 6| Step: 12
Training loss: 1.3017427921295166
Validation loss: 1.7598862058372908

Epoch: 6| Step: 13
Training loss: 1.0579938888549805
Validation loss: 1.7014821883170836

Epoch: 222| Step: 0
Training loss: 0.7848884463310242
Validation loss: 1.6684587924711165

Epoch: 6| Step: 1
Training loss: 0.8032675385475159
Validation loss: 1.6745691145620039

Epoch: 6| Step: 2
Training loss: 0.80218905210495
Validation loss: 1.6651894764233661

Epoch: 6| Step: 3
Training loss: 0.8059413433074951
Validation loss: 1.6542551248304305

Epoch: 6| Step: 4
Training loss: 0.39588654041290283
Validation loss: 1.6968454173816148

Epoch: 6| Step: 5
Training loss: 0.6454566121101379
Validation loss: 1.7130195184420514

Epoch: 6| Step: 6
Training loss: 0.6823650598526001
Validation loss: 1.7465582893740745

Epoch: 6| Step: 7
Training loss: 0.5995116233825684
Validation loss: 1.7913236105313866

Epoch: 6| Step: 8
Training loss: 0.5278905034065247
Validation loss: 1.8118768943253385

Epoch: 6| Step: 9
Training loss: 0.7679478526115417
Validation loss: 1.8236341373894804

Epoch: 6| Step: 10
Training loss: 0.9795928001403809
Validation loss: 1.7808236973260039

Epoch: 6| Step: 11
Training loss: 1.0746381282806396
Validation loss: 1.7880177664500412

Epoch: 6| Step: 12
Training loss: 1.1446877717971802
Validation loss: 1.7796785857087822

Epoch: 6| Step: 13
Training loss: 0.6628390550613403
Validation loss: 1.7284292879924978

Epoch: 223| Step: 0
Training loss: 0.7386990189552307
Validation loss: 1.7081976372708556

Epoch: 6| Step: 1
Training loss: 0.8301156759262085
Validation loss: 1.6919120614246657

Epoch: 6| Step: 2
Training loss: 0.8168416023254395
Validation loss: 1.7101959041369859

Epoch: 6| Step: 3
Training loss: 0.3871268630027771
Validation loss: 1.7557915449142456

Epoch: 6| Step: 4
Training loss: 1.028184413909912
Validation loss: 1.7682197734873781

Epoch: 6| Step: 5
Training loss: 0.5892459154129028
Validation loss: 1.7695869604746501

Epoch: 6| Step: 6
Training loss: 0.46226221323013306
Validation loss: 1.741401562126734

Epoch: 6| Step: 7
Training loss: 0.9177149534225464
Validation loss: 1.7387131247469174

Epoch: 6| Step: 8
Training loss: 0.7793952226638794
Validation loss: 1.7024103903001355

Epoch: 6| Step: 9
Training loss: 0.46513670682907104
Validation loss: 1.6878173594833703

Epoch: 6| Step: 10
Training loss: 0.6094211339950562
Validation loss: 1.680907444287372

Epoch: 6| Step: 11
Training loss: 0.7660619616508484
Validation loss: 1.7081089186412033

Epoch: 6| Step: 12
Training loss: 0.86885666847229
Validation loss: 1.7043895593253515

Epoch: 6| Step: 13
Training loss: 0.7140933275222778
Validation loss: 1.751295164067258

Epoch: 224| Step: 0
Training loss: 0.7974744439125061
Validation loss: 1.7881898034003474

Epoch: 6| Step: 1
Training loss: 0.7475515007972717
Validation loss: 1.8535745797618743

Epoch: 6| Step: 2
Training loss: 0.8591519594192505
Validation loss: 1.8697454314078055

Epoch: 6| Step: 3
Training loss: 0.6063751578330994
Validation loss: 1.8626889862040037

Epoch: 6| Step: 4
Training loss: 0.5409421920776367
Validation loss: 1.8479010494806434

Epoch: 6| Step: 5
Training loss: 0.772603452205658
Validation loss: 1.794931351497609

Epoch: 6| Step: 6
Training loss: 0.3993646502494812
Validation loss: 1.7298345937523791

Epoch: 6| Step: 7
Training loss: 0.7932590246200562
Validation loss: 1.7096708154165616

Epoch: 6| Step: 8
Training loss: 0.5788267850875854
Validation loss: 1.6998230718797254

Epoch: 6| Step: 9
Training loss: 0.8949731588363647
Validation loss: 1.6845466218968874

Epoch: 6| Step: 10
Training loss: 0.6453306674957275
Validation loss: 1.6822243826363676

Epoch: 6| Step: 11
Training loss: 0.902448296546936
Validation loss: 1.7399922737511255

Epoch: 6| Step: 12
Training loss: 0.7826839089393616
Validation loss: 1.767805145632836

Epoch: 6| Step: 13
Training loss: 0.8494555950164795
Validation loss: 1.735902201744818

Epoch: 225| Step: 0
Training loss: 0.7936354279518127
Validation loss: 1.7148143809328797

Epoch: 6| Step: 1
Training loss: 0.6294063329696655
Validation loss: 1.6958854262546827

Epoch: 6| Step: 2
Training loss: 0.5792869329452515
Validation loss: 1.6920395384552658

Epoch: 6| Step: 3
Training loss: 0.6143014430999756
Validation loss: 1.7149439704033635

Epoch: 6| Step: 4
Training loss: 1.0416595935821533
Validation loss: 1.7066571033129128

Epoch: 6| Step: 5
Training loss: 0.8627868890762329
Validation loss: 1.726375215797014

Epoch: 6| Step: 6
Training loss: 0.5846203565597534
Validation loss: 1.72190232687099

Epoch: 6| Step: 7
Training loss: 0.6008175611495972
Validation loss: 1.736986861434034

Epoch: 6| Step: 8
Training loss: 0.8011537790298462
Validation loss: 1.742671416651818

Epoch: 6| Step: 9
Training loss: 0.4387361407279968
Validation loss: 1.712101867122035

Epoch: 6| Step: 10
Training loss: 0.7242391109466553
Validation loss: 1.7770559621113602

Epoch: 6| Step: 11
Training loss: 0.41199690103530884
Validation loss: 1.7945067280082292

Epoch: 6| Step: 12
Training loss: 0.5316824913024902
Validation loss: 1.835755536633153

Epoch: 6| Step: 13
Training loss: 1.3875290155410767
Validation loss: 1.8531662341087096

Epoch: 226| Step: 0
Training loss: 0.8485596179962158
Validation loss: 1.877731607806298

Epoch: 6| Step: 1
Training loss: 0.9350395202636719
Validation loss: 1.8458148728134811

Epoch: 6| Step: 2
Training loss: 0.91788649559021
Validation loss: 1.8449107472614577

Epoch: 6| Step: 3
Training loss: 0.7024989724159241
Validation loss: 1.8120731871615174

Epoch: 6| Step: 4
Training loss: 0.5563600063323975
Validation loss: 1.7699144783840384

Epoch: 6| Step: 5
Training loss: 0.7768890857696533
Validation loss: 1.7384303128847511

Epoch: 6| Step: 6
Training loss: 0.6194462180137634
Validation loss: 1.7544255474562287

Epoch: 6| Step: 7
Training loss: 0.6441050171852112
Validation loss: 1.7770573785228114

Epoch: 6| Step: 8
Training loss: 0.6165415048599243
Validation loss: 1.772611580869203

Epoch: 6| Step: 9
Training loss: 0.5611710548400879
Validation loss: 1.791007645668522

Epoch: 6| Step: 10
Training loss: 0.6012968420982361
Validation loss: 1.8342032535101778

Epoch: 6| Step: 11
Training loss: 0.8106452822685242
Validation loss: 1.8286292219674716

Epoch: 6| Step: 12
Training loss: 0.5710676908493042
Validation loss: 1.824716273174491

Epoch: 6| Step: 13
Training loss: 0.8621795177459717
Validation loss: 1.809441904867849

Epoch: 227| Step: 0
Training loss: 0.8039219379425049
Validation loss: 1.7925984218556394

Epoch: 6| Step: 1
Training loss: 0.7074344158172607
Validation loss: 1.7668889953244118

Epoch: 6| Step: 2
Training loss: 0.8566515445709229
Validation loss: 1.7424772465100853

Epoch: 6| Step: 3
Training loss: 0.3703169524669647
Validation loss: 1.7434749757089922

Epoch: 6| Step: 4
Training loss: 0.9845896363258362
Validation loss: 1.7169421257511261

Epoch: 6| Step: 5
Training loss: 0.7112312316894531
Validation loss: 1.7473828126025457

Epoch: 6| Step: 6
Training loss: 0.37757670879364014
Validation loss: 1.778234334402187

Epoch: 6| Step: 7
Training loss: 0.34873339533805847
Validation loss: 1.7398405241709884

Epoch: 6| Step: 8
Training loss: 0.6238019466400146
Validation loss: 1.7347286580711283

Epoch: 6| Step: 9
Training loss: 0.628079891204834
Validation loss: 1.7502154534862888

Epoch: 6| Step: 10
Training loss: 0.7169946432113647
Validation loss: 1.7588957637868903

Epoch: 6| Step: 11
Training loss: 0.5738646388053894
Validation loss: 1.775453236795241

Epoch: 6| Step: 12
Training loss: 0.3869549632072449
Validation loss: 1.7570251559698453

Epoch: 6| Step: 13
Training loss: 1.284456491470337
Validation loss: 1.7455280365482453

Epoch: 228| Step: 0
Training loss: 0.41951897740364075
Validation loss: 1.7583345187607633

Epoch: 6| Step: 1
Training loss: 0.7947790026664734
Validation loss: 1.731846937569239

Epoch: 6| Step: 2
Training loss: 0.5326979756355286
Validation loss: 1.7332928026876142

Epoch: 6| Step: 3
Training loss: 0.735715925693512
Validation loss: 1.7325954411619453

Epoch: 6| Step: 4
Training loss: 0.5671404600143433
Validation loss: 1.7509692663787513

Epoch: 6| Step: 5
Training loss: 0.63142329454422
Validation loss: 1.769176956145994

Epoch: 6| Step: 6
Training loss: 0.678351640701294
Validation loss: 1.7854271499059533

Epoch: 6| Step: 7
Training loss: 0.6245212554931641
Validation loss: 1.7397014235937467

Epoch: 6| Step: 8
Training loss: 0.52680504322052
Validation loss: 1.738326766157663

Epoch: 6| Step: 9
Training loss: 0.7642960548400879
Validation loss: 1.7309654989550192

Epoch: 6| Step: 10
Training loss: 1.0795621871948242
Validation loss: 1.726356469174867

Epoch: 6| Step: 11
Training loss: 0.5328909158706665
Validation loss: 1.7369071796376219

Epoch: 6| Step: 12
Training loss: 0.4245584011077881
Validation loss: 1.74319556836159

Epoch: 6| Step: 13
Training loss: 0.42160919308662415
Validation loss: 1.7747669181516093

Epoch: 229| Step: 0
Training loss: 0.7612107396125793
Validation loss: 1.7678600588152487

Epoch: 6| Step: 1
Training loss: 0.75676429271698
Validation loss: 1.7631573702699395

Epoch: 6| Step: 2
Training loss: 0.48149168491363525
Validation loss: 1.7789916825550858

Epoch: 6| Step: 3
Training loss: 0.28416308760643005
Validation loss: 1.7516371678280573

Epoch: 6| Step: 4
Training loss: 0.7508219480514526
Validation loss: 1.7638470601010066

Epoch: 6| Step: 5
Training loss: 0.7507404088973999
Validation loss: 1.755558777880925

Epoch: 6| Step: 6
Training loss: 0.4339733123779297
Validation loss: 1.74617721444817

Epoch: 6| Step: 7
Training loss: 0.610596776008606
Validation loss: 1.7257665959737634

Epoch: 6| Step: 8
Training loss: 0.7619427442550659
Validation loss: 1.7007705601312781

Epoch: 6| Step: 9
Training loss: 0.5679737329483032
Validation loss: 1.6887061570280342

Epoch: 6| Step: 10
Training loss: 1.1652917861938477
Validation loss: 1.7128693878009755

Epoch: 6| Step: 11
Training loss: 0.6152707934379578
Validation loss: 1.6728728125172276

Epoch: 6| Step: 12
Training loss: 0.5217418670654297
Validation loss: 1.7098513700628792

Epoch: 6| Step: 13
Training loss: 0.18963950872421265
Validation loss: 1.7328159860385361

Epoch: 230| Step: 0
Training loss: 0.5505462884902954
Validation loss: 1.747800229698099

Epoch: 6| Step: 1
Training loss: 0.6013696789741516
Validation loss: 1.816190363258444

Epoch: 6| Step: 2
Training loss: 0.604508101940155
Validation loss: 1.8325513710257828

Epoch: 6| Step: 3
Training loss: 0.5451706051826477
Validation loss: 1.8244182755870204

Epoch: 6| Step: 4
Training loss: 0.8380828499794006
Validation loss: 1.793848709393573

Epoch: 6| Step: 5
Training loss: 0.4968584179878235
Validation loss: 1.7379467935972317

Epoch: 6| Step: 6
Training loss: 0.8578228950500488
Validation loss: 1.7397841163860854

Epoch: 6| Step: 7
Training loss: 0.5818978548049927
Validation loss: 1.750485235644925

Epoch: 6| Step: 8
Training loss: 0.7397762537002563
Validation loss: 1.7820900268452142

Epoch: 6| Step: 9
Training loss: 0.23550279438495636
Validation loss: 1.809531158016574

Epoch: 6| Step: 10
Training loss: 0.658003568649292
Validation loss: 1.8249568388026247

Epoch: 6| Step: 11
Training loss: 1.3638606071472168
Validation loss: 1.8475985001492243

Epoch: 6| Step: 12
Training loss: 0.3403477370738983
Validation loss: 1.8157772300063924

Epoch: 6| Step: 13
Training loss: 0.8589163422584534
Validation loss: 1.8084397405706427

Epoch: 231| Step: 0
Training loss: 0.54583740234375
Validation loss: 1.7582115050285094

Epoch: 6| Step: 1
Training loss: 0.8397632837295532
Validation loss: 1.7467339026030673

Epoch: 6| Step: 2
Training loss: 0.4929414391517639
Validation loss: 1.7251678833397486

Epoch: 6| Step: 3
Training loss: 0.7181286215782166
Validation loss: 1.6924660603205364

Epoch: 6| Step: 4
Training loss: 0.5122689008712769
Validation loss: 1.7185067438310193

Epoch: 6| Step: 5
Training loss: 0.33014655113220215
Validation loss: 1.708627180386615

Epoch: 6| Step: 6
Training loss: 0.3795086741447449
Validation loss: 1.7145325611996394

Epoch: 6| Step: 7
Training loss: 0.7853179574012756
Validation loss: 1.7501427614560692

Epoch: 6| Step: 8
Training loss: 0.3511373996734619
Validation loss: 1.7770996965387815

Epoch: 6| Step: 9
Training loss: 0.5481165051460266
Validation loss: 1.8185397783915203

Epoch: 6| Step: 10
Training loss: 0.7622796297073364
Validation loss: 1.8093133587991037

Epoch: 6| Step: 11
Training loss: 0.7870462536811829
Validation loss: 1.8354637392105595

Epoch: 6| Step: 12
Training loss: 0.8522573113441467
Validation loss: 1.8169229825337727

Epoch: 6| Step: 13
Training loss: 0.9004067182540894
Validation loss: 1.8090617015797605

Epoch: 232| Step: 0
Training loss: 0.512305498123169
Validation loss: 1.7830705693973008

Epoch: 6| Step: 1
Training loss: 0.812896728515625
Validation loss: 1.7896343725983814

Epoch: 6| Step: 2
Training loss: 0.8885822296142578
Validation loss: 1.7785749179060741

Epoch: 6| Step: 3
Training loss: 0.3051340878009796
Validation loss: 1.7683534263282694

Epoch: 6| Step: 4
Training loss: 0.38078805804252625
Validation loss: 1.7817636279649631

Epoch: 6| Step: 5
Training loss: 0.30246782302856445
Validation loss: 1.778946756034769

Epoch: 6| Step: 6
Training loss: 0.49195677042007446
Validation loss: 1.7771626403254848

Epoch: 6| Step: 7
Training loss: 0.7150297164916992
Validation loss: 1.7904713384566768

Epoch: 6| Step: 8
Training loss: 0.6867343187332153
Validation loss: 1.820859702684546

Epoch: 6| Step: 9
Training loss: 0.6023180484771729
Validation loss: 1.8286301141144128

Epoch: 6| Step: 10
Training loss: 0.7135344743728638
Validation loss: 1.803693744444078

Epoch: 6| Step: 11
Training loss: 0.5589913129806519
Validation loss: 1.7858490559362596

Epoch: 6| Step: 12
Training loss: 0.4979434907436371
Validation loss: 1.76321501885691

Epoch: 6| Step: 13
Training loss: 0.616835355758667
Validation loss: 1.73105292038251

Epoch: 233| Step: 0
Training loss: 0.5993634462356567
Validation loss: 1.7305763075428624

Epoch: 6| Step: 1
Training loss: 0.713463544845581
Validation loss: 1.7120670362185406

Epoch: 6| Step: 2
Training loss: 0.5042840242385864
Validation loss: 1.7254684330314718

Epoch: 6| Step: 3
Training loss: 0.6197475790977478
Validation loss: 1.6985340169681016

Epoch: 6| Step: 4
Training loss: 0.5284074544906616
Validation loss: 1.658370970397867

Epoch: 6| Step: 5
Training loss: 0.32127493619918823
Validation loss: 1.611146052678426

Epoch: 6| Step: 6
Training loss: 0.7749903202056885
Validation loss: 1.6322489053972307

Epoch: 6| Step: 7
Training loss: 0.25530773401260376
Validation loss: 1.6345910320999801

Epoch: 6| Step: 8
Training loss: 0.4903801679611206
Validation loss: 1.616336468727358

Epoch: 6| Step: 9
Training loss: 0.8595134615898132
Validation loss: 1.6533766132529064

Epoch: 6| Step: 10
Training loss: 1.1222169399261475
Validation loss: 1.66604813965418

Epoch: 6| Step: 11
Training loss: 0.6016051769256592
Validation loss: 1.6902431723892049

Epoch: 6| Step: 12
Training loss: 0.5018123984336853
Validation loss: 1.7406590087439424

Epoch: 6| Step: 13
Training loss: 0.6773171424865723
Validation loss: 1.769616662815053

Epoch: 234| Step: 0
Training loss: 0.413299560546875
Validation loss: 1.7612042561654122

Epoch: 6| Step: 1
Training loss: 0.49145546555519104
Validation loss: 1.7866430846593713

Epoch: 6| Step: 2
Training loss: 0.48206543922424316
Validation loss: 1.7643125813494447

Epoch: 6| Step: 3
Training loss: 0.20049402117729187
Validation loss: 1.7505327040149319

Epoch: 6| Step: 4
Training loss: 0.4581719636917114
Validation loss: 1.7282124142492972

Epoch: 6| Step: 5
Training loss: 0.3663652539253235
Validation loss: 1.748552486460696

Epoch: 6| Step: 6
Training loss: 0.7569832801818848
Validation loss: 1.7729285634973997

Epoch: 6| Step: 7
Training loss: 0.5971266031265259
Validation loss: 1.777961286165381

Epoch: 6| Step: 8
Training loss: 0.7219458818435669
Validation loss: 1.7764425136709725

Epoch: 6| Step: 9
Training loss: 0.6249926686286926
Validation loss: 1.78015766092526

Epoch: 6| Step: 10
Training loss: 0.5105932950973511
Validation loss: 1.7758239828130251

Epoch: 6| Step: 11
Training loss: 0.617573618888855
Validation loss: 1.7512829021740985

Epoch: 6| Step: 12
Training loss: 0.5478605628013611
Validation loss: 1.7306050972271991

Epoch: 6| Step: 13
Training loss: 1.7456645965576172
Validation loss: 1.7141741809024607

Epoch: 235| Step: 0
Training loss: 0.4775242209434509
Validation loss: 1.7266165761537449

Epoch: 6| Step: 1
Training loss: 0.6011766195297241
Validation loss: 1.7348968764787078

Epoch: 6| Step: 2
Training loss: 0.6803526282310486
Validation loss: 1.7872295341184061

Epoch: 6| Step: 3
Training loss: 0.41760677099227905
Validation loss: 1.7885937088279313

Epoch: 6| Step: 4
Training loss: 0.5858678817749023
Validation loss: 1.8105652998852473

Epoch: 6| Step: 5
Training loss: 0.4515717029571533
Validation loss: 1.7604758213925105

Epoch: 6| Step: 6
Training loss: 0.544133186340332
Validation loss: 1.7249242233973678

Epoch: 6| Step: 7
Training loss: 0.555441677570343
Validation loss: 1.7081571432851976

Epoch: 6| Step: 8
Training loss: 0.574108362197876
Validation loss: 1.7152128386241134

Epoch: 6| Step: 9
Training loss: 0.6287734508514404
Validation loss: 1.6764801317645657

Epoch: 6| Step: 10
Training loss: 0.7392280101776123
Validation loss: 1.6946361936548704

Epoch: 6| Step: 11
Training loss: 0.4646840989589691
Validation loss: 1.680798504942207

Epoch: 6| Step: 12
Training loss: 0.5451778769493103
Validation loss: 1.7264661148030271

Epoch: 6| Step: 13
Training loss: 0.7787117958068848
Validation loss: 1.7996197797918831

Epoch: 236| Step: 0
Training loss: 0.4561179578304291
Validation loss: 1.8315406871098343

Epoch: 6| Step: 1
Training loss: 0.7525186538696289
Validation loss: 1.8690009578581779

Epoch: 6| Step: 2
Training loss: 0.549103856086731
Validation loss: 1.8709915120114562

Epoch: 6| Step: 3
Training loss: 0.34771594405174255
Validation loss: 1.8447036230435936

Epoch: 6| Step: 4
Training loss: 0.6065173149108887
Validation loss: 1.7900558453734203

Epoch: 6| Step: 5
Training loss: 0.5246232151985168
Validation loss: 1.7556456519711403

Epoch: 6| Step: 6
Training loss: 0.5580610036849976
Validation loss: 1.6974942761082803

Epoch: 6| Step: 7
Training loss: 0.4295274019241333
Validation loss: 1.667905390903514

Epoch: 6| Step: 8
Training loss: 0.5834672451019287
Validation loss: 1.6491934894233622

Epoch: 6| Step: 9
Training loss: 0.5891438126564026
Validation loss: 1.6663882617027528

Epoch: 6| Step: 10
Training loss: 0.615106463432312
Validation loss: 1.6577415543217813

Epoch: 6| Step: 11
Training loss: 0.5114030241966248
Validation loss: 1.677855855675154

Epoch: 6| Step: 12
Training loss: 0.572169840335846
Validation loss: 1.716525634129842

Epoch: 6| Step: 13
Training loss: 1.0752241611480713
Validation loss: 1.7854697550496748

Epoch: 237| Step: 0
Training loss: 0.3957740068435669
Validation loss: 1.8123024907163394

Epoch: 6| Step: 1
Training loss: 0.6630544662475586
Validation loss: 1.8248692558657738

Epoch: 6| Step: 2
Training loss: 0.6342362761497498
Validation loss: 1.8047775183954546

Epoch: 6| Step: 3
Training loss: 0.5792882442474365
Validation loss: 1.7879136749493179

Epoch: 6| Step: 4
Training loss: 0.7407057285308838
Validation loss: 1.7295506000518799

Epoch: 6| Step: 5
Training loss: 0.3341146409511566
Validation loss: 1.6921326191194597

Epoch: 6| Step: 6
Training loss: 0.4852396547794342
Validation loss: 1.724294339456866

Epoch: 6| Step: 7
Training loss: 0.4372071623802185
Validation loss: 1.6853770248351558

Epoch: 6| Step: 8
Training loss: 0.3076046109199524
Validation loss: 1.70927555330338

Epoch: 6| Step: 9
Training loss: 0.7952741384506226
Validation loss: 1.7665861011833273

Epoch: 6| Step: 10
Training loss: 0.8042334318161011
Validation loss: 1.8066640054025958

Epoch: 6| Step: 11
Training loss: 0.5356462001800537
Validation loss: 1.8202223239406463

Epoch: 6| Step: 12
Training loss: 0.5041893124580383
Validation loss: 1.8299766048308341

Epoch: 6| Step: 13
Training loss: 0.5198774337768555
Validation loss: 1.8385164660792197

Epoch: 238| Step: 0
Training loss: 0.2840940058231354
Validation loss: 1.8342040841297438

Epoch: 6| Step: 1
Training loss: 0.5187159180641174
Validation loss: 1.8057034989838958

Epoch: 6| Step: 2
Training loss: 0.6784327626228333
Validation loss: 1.7919150988260906

Epoch: 6| Step: 3
Training loss: 0.42949366569519043
Validation loss: 1.7479089357519662

Epoch: 6| Step: 4
Training loss: 0.8059385418891907
Validation loss: 1.7648547259710168

Epoch: 6| Step: 5
Training loss: 0.49257028102874756
Validation loss: 1.7432882260250788

Epoch: 6| Step: 6
Training loss: 0.6524389982223511
Validation loss: 1.7099169069720852

Epoch: 6| Step: 7
Training loss: 0.4330156445503235
Validation loss: 1.6852196442183627

Epoch: 6| Step: 8
Training loss: 0.6670956611633301
Validation loss: 1.6944847081297187

Epoch: 6| Step: 9
Training loss: 0.6478027105331421
Validation loss: 1.697219346159248

Epoch: 6| Step: 10
Training loss: 0.4127212464809418
Validation loss: 1.6713291739904752

Epoch: 6| Step: 11
Training loss: 0.6059790849685669
Validation loss: 1.6789113462612193

Epoch: 6| Step: 12
Training loss: 0.4037000238895416
Validation loss: 1.6986179659443517

Epoch: 6| Step: 13
Training loss: 0.565872311592102
Validation loss: 1.7085201945356143

Epoch: 239| Step: 0
Training loss: 0.4547959566116333
Validation loss: 1.770238801997195

Epoch: 6| Step: 1
Training loss: 0.32678845524787903
Validation loss: 1.7711009517792733

Epoch: 6| Step: 2
Training loss: 0.4282715320587158
Validation loss: 1.7627204336145872

Epoch: 6| Step: 3
Training loss: 0.8235069513320923
Validation loss: 1.747334034212174

Epoch: 6| Step: 4
Training loss: 0.5960397720336914
Validation loss: 1.7365479174480642

Epoch: 6| Step: 5
Training loss: 0.46523913741111755
Validation loss: 1.7190364919682986

Epoch: 6| Step: 6
Training loss: 0.6195193529129028
Validation loss: 1.6996087669044413

Epoch: 6| Step: 7
Training loss: 0.553781270980835
Validation loss: 1.7170150946545344

Epoch: 6| Step: 8
Training loss: 0.48146331310272217
Validation loss: 1.7260844284488308

Epoch: 6| Step: 9
Training loss: 0.8416051268577576
Validation loss: 1.7546066238034157

Epoch: 6| Step: 10
Training loss: 0.49264270067214966
Validation loss: 1.7643611379849014

Epoch: 6| Step: 11
Training loss: 0.3611038029193878
Validation loss: 1.7780864623285109

Epoch: 6| Step: 12
Training loss: 0.5088886618614197
Validation loss: 1.7948708893150411

Epoch: 6| Step: 13
Training loss: 0.3791556656360626
Validation loss: 1.787706026466944

Epoch: 240| Step: 0
Training loss: 0.09079869091510773
Validation loss: 1.7268928635504939

Epoch: 6| Step: 1
Training loss: 0.6773868799209595
Validation loss: 1.7120578500532335

Epoch: 6| Step: 2
Training loss: 0.5369235277175903
Validation loss: 1.6752171336963613

Epoch: 6| Step: 3
Training loss: 0.5777797698974609
Validation loss: 1.632666745493489

Epoch: 6| Step: 4
Training loss: 0.7777605652809143
Validation loss: 1.640452402894215

Epoch: 6| Step: 5
Training loss: 0.7925630807876587
Validation loss: 1.6343304854567333

Epoch: 6| Step: 6
Training loss: 0.641624927520752
Validation loss: 1.6800361999901392

Epoch: 6| Step: 7
Training loss: 0.5202754139900208
Validation loss: 1.70421003782621

Epoch: 6| Step: 8
Training loss: 0.5144762992858887
Validation loss: 1.7433315348881546

Epoch: 6| Step: 9
Training loss: 0.36892110109329224
Validation loss: 1.7925712088102936

Epoch: 6| Step: 10
Training loss: 0.6006221175193787
Validation loss: 1.8494176018622615

Epoch: 6| Step: 11
Training loss: 0.6164402365684509
Validation loss: 1.8220387479310394

Epoch: 6| Step: 12
Training loss: 0.41436922550201416
Validation loss: 1.7652541681002545

Epoch: 6| Step: 13
Training loss: 0.3882036805152893
Validation loss: 1.7129980300062446

Epoch: 241| Step: 0
Training loss: 0.4437722861766815
Validation loss: 1.672505231313808

Epoch: 6| Step: 1
Training loss: 0.412659227848053
Validation loss: 1.6613164537696428

Epoch: 6| Step: 2
Training loss: 0.49250370264053345
Validation loss: 1.6524560323325537

Epoch: 6| Step: 3
Training loss: 0.4395133852958679
Validation loss: 1.6986039498800873

Epoch: 6| Step: 4
Training loss: 0.6014421582221985
Validation loss: 1.7245327054813344

Epoch: 6| Step: 5
Training loss: 0.7364155054092407
Validation loss: 1.7504475116729736

Epoch: 6| Step: 6
Training loss: 0.8247283101081848
Validation loss: 1.8332940019587034

Epoch: 6| Step: 7
Training loss: 0.40057307481765747
Validation loss: 1.8418970825851604

Epoch: 6| Step: 8
Training loss: 0.6043189764022827
Validation loss: 1.8082491838803856

Epoch: 6| Step: 9
Training loss: 0.8080226182937622
Validation loss: 1.7348096627061085

Epoch: 6| Step: 10
Training loss: 0.5109784603118896
Validation loss: 1.707628385995024

Epoch: 6| Step: 11
Training loss: 0.4957426190376282
Validation loss: 1.7039176443571686

Epoch: 6| Step: 12
Training loss: 0.40166062116622925
Validation loss: 1.6760913607894734

Epoch: 6| Step: 13
Training loss: 0.3834702670574188
Validation loss: 1.6735449311553792

Epoch: 242| Step: 0
Training loss: 0.5446373224258423
Validation loss: 1.6700697791191839

Epoch: 6| Step: 1
Training loss: 0.7857186794281006
Validation loss: 1.686815115713304

Epoch: 6| Step: 2
Training loss: 0.5022890567779541
Validation loss: 1.6841389786812566

Epoch: 6| Step: 3
Training loss: 0.329539954662323
Validation loss: 1.6998636043199928

Epoch: 6| Step: 4
Training loss: 0.46489715576171875
Validation loss: 1.693858652986506

Epoch: 6| Step: 5
Training loss: 0.5204964876174927
Validation loss: 1.7269448093188706

Epoch: 6| Step: 6
Training loss: 0.732978343963623
Validation loss: 1.7672970705134894

Epoch: 6| Step: 7
Training loss: 0.5142385959625244
Validation loss: 1.7803860813058832

Epoch: 6| Step: 8
Training loss: 0.22601968050003052
Validation loss: 1.775082593323082

Epoch: 6| Step: 9
Training loss: 0.339595228433609
Validation loss: 1.7965534848551596

Epoch: 6| Step: 10
Training loss: 0.6558932662010193
Validation loss: 1.7836186655106083

Epoch: 6| Step: 11
Training loss: 0.42820996046066284
Validation loss: 1.8136445296707975

Epoch: 6| Step: 12
Training loss: 0.541192889213562
Validation loss: 1.8344928820927937

Epoch: 6| Step: 13
Training loss: 0.9090369343757629
Validation loss: 1.8290539230069807

Epoch: 243| Step: 0
Training loss: 0.5281853675842285
Validation loss: 1.7723853177921747

Epoch: 6| Step: 1
Training loss: 0.36843931674957275
Validation loss: 1.7708349150996054

Epoch: 6| Step: 2
Training loss: 0.5195020437240601
Validation loss: 1.6983136900009648

Epoch: 6| Step: 3
Training loss: 0.2881554067134857
Validation loss: 1.7043709870307677

Epoch: 6| Step: 4
Training loss: 0.6226046085357666
Validation loss: 1.6737015836982316

Epoch: 6| Step: 5
Training loss: 0.3986428678035736
Validation loss: 1.651875190837409

Epoch: 6| Step: 6
Training loss: 0.8265171647071838
Validation loss: 1.6566061832571541

Epoch: 6| Step: 7
Training loss: 0.5365028381347656
Validation loss: 1.6595912389857794

Epoch: 6| Step: 8
Training loss: 0.7366676330566406
Validation loss: 1.7086905997286561

Epoch: 6| Step: 9
Training loss: 0.5053426623344421
Validation loss: 1.7703035185413976

Epoch: 6| Step: 10
Training loss: 0.708483099937439
Validation loss: 1.8606308532017533

Epoch: 6| Step: 11
Training loss: 0.6055623292922974
Validation loss: 1.9013045090501026

Epoch: 6| Step: 12
Training loss: 0.5873106122016907
Validation loss: 1.9171363794675438

Epoch: 6| Step: 13
Training loss: 0.8944026231765747
Validation loss: 1.890174311976279

Epoch: 244| Step: 0
Training loss: 0.7541868686676025
Validation loss: 1.8103416940217376

Epoch: 6| Step: 1
Training loss: 0.6491492986679077
Validation loss: 1.7399065532991964

Epoch: 6| Step: 2
Training loss: 0.7159318327903748
Validation loss: 1.6917767537537443

Epoch: 6| Step: 3
Training loss: 0.5867014527320862
Validation loss: 1.6654890544952885

Epoch: 6| Step: 4
Training loss: 0.7417302131652832
Validation loss: 1.6323159548544115

Epoch: 6| Step: 5
Training loss: 0.5646828413009644
Validation loss: 1.6827889027134064

Epoch: 6| Step: 6
Training loss: 0.5016276240348816
Validation loss: 1.7305327615430277

Epoch: 6| Step: 7
Training loss: 0.6429051160812378
Validation loss: 1.7752117162109704

Epoch: 6| Step: 8
Training loss: 0.9595890641212463
Validation loss: 1.8566941394600818

Epoch: 6| Step: 9
Training loss: 0.4135672450065613
Validation loss: 1.8399778950598933

Epoch: 6| Step: 10
Training loss: 0.37769120931625366
Validation loss: 1.7264669620862572

Epoch: 6| Step: 11
Training loss: 0.46422094106674194
Validation loss: 1.6792609691619873

Epoch: 6| Step: 12
Training loss: 0.4331875443458557
Validation loss: 1.6388947040803972

Epoch: 6| Step: 13
Training loss: 0.6314582824707031
Validation loss: 1.6574642876143098

Epoch: 245| Step: 0
Training loss: 0.6571786999702454
Validation loss: 1.660687832422154

Epoch: 6| Step: 1
Training loss: 0.548753023147583
Validation loss: 1.6818395019859396

Epoch: 6| Step: 2
Training loss: 0.5923923254013062
Validation loss: 1.7306545729278235

Epoch: 6| Step: 3
Training loss: 0.6640483140945435
Validation loss: 1.7461353848057408

Epoch: 6| Step: 4
Training loss: 0.5253217816352844
Validation loss: 1.7185557093671573

Epoch: 6| Step: 5
Training loss: 0.5480191707611084
Validation loss: 1.723171898113784

Epoch: 6| Step: 6
Training loss: 0.44850701093673706
Validation loss: 1.722074172830069

Epoch: 6| Step: 7
Training loss: 0.2742309868335724
Validation loss: 1.6816530355843164

Epoch: 6| Step: 8
Training loss: 0.5844711065292358
Validation loss: 1.6617640051790463

Epoch: 6| Step: 9
Training loss: 0.8309651613235474
Validation loss: 1.6185011735526464

Epoch: 6| Step: 10
Training loss: 0.4986325204372406
Validation loss: 1.614851890071746

Epoch: 6| Step: 11
Training loss: 0.848922073841095
Validation loss: 1.6459481152155067

Epoch: 6| Step: 12
Training loss: 0.2676120400428772
Validation loss: 1.6882913779186945

Epoch: 6| Step: 13
Training loss: 0.2959819436073303
Validation loss: 1.703357309423467

Epoch: 246| Step: 0
Training loss: 0.4898565411567688
Validation loss: 1.7803013029918875

Epoch: 6| Step: 1
Training loss: 1.0851322412490845
Validation loss: 1.8100474649860012

Epoch: 6| Step: 2
Training loss: 0.7525092959403992
Validation loss: 1.8082257855323054

Epoch: 6| Step: 3
Training loss: 0.4029150605201721
Validation loss: 1.829632859076223

Epoch: 6| Step: 4
Training loss: 0.38256895542144775
Validation loss: 1.7846565310673048

Epoch: 6| Step: 5
Training loss: 0.2226410210132599
Validation loss: 1.7598487254111999

Epoch: 6| Step: 6
Training loss: 0.41564086079597473
Validation loss: 1.7272275699082242

Epoch: 6| Step: 7
Training loss: 0.5089932084083557
Validation loss: 1.7350792295189315

Epoch: 6| Step: 8
Training loss: 0.4626818299293518
Validation loss: 1.708852482098405

Epoch: 6| Step: 9
Training loss: 0.6030648350715637
Validation loss: 1.723289389764109

Epoch: 6| Step: 10
Training loss: 0.4337165653705597
Validation loss: 1.6846033693641744

Epoch: 6| Step: 11
Training loss: 0.40123432874679565
Validation loss: 1.7013668219248455

Epoch: 6| Step: 12
Training loss: 0.45463889837265015
Validation loss: 1.7100998150405062

Epoch: 6| Step: 13
Training loss: 0.5159356594085693
Validation loss: 1.7600243373583722

Epoch: 247| Step: 0
Training loss: 0.4622347950935364
Validation loss: 1.785992577511777

Epoch: 6| Step: 1
Training loss: 0.6842246055603027
Validation loss: 1.813368555038206

Epoch: 6| Step: 2
Training loss: 0.7285255193710327
Validation loss: 1.7816370328267415

Epoch: 6| Step: 3
Training loss: 0.4004949927330017
Validation loss: 1.7765651684935375

Epoch: 6| Step: 4
Training loss: 0.46248990297317505
Validation loss: 1.7848707399060648

Epoch: 6| Step: 5
Training loss: 0.3388786315917969
Validation loss: 1.7412885376202163

Epoch: 6| Step: 6
Training loss: 0.5737801790237427
Validation loss: 1.7024846051328926

Epoch: 6| Step: 7
Training loss: 0.42095136642456055
Validation loss: 1.6785592789291053

Epoch: 6| Step: 8
Training loss: 0.31438326835632324
Validation loss: 1.679841185128817

Epoch: 6| Step: 9
Training loss: 0.4352453649044037
Validation loss: 1.6629595269439041

Epoch: 6| Step: 10
Training loss: 0.537211537361145
Validation loss: 1.6760277760926114

Epoch: 6| Step: 11
Training loss: 0.78972327709198
Validation loss: 1.7075818302810832

Epoch: 6| Step: 12
Training loss: 0.6879971027374268
Validation loss: 1.7194045935907671

Epoch: 6| Step: 13
Training loss: 0.5553299784660339
Validation loss: 1.7406299088590889

Epoch: 248| Step: 0
Training loss: 0.7349318265914917
Validation loss: 1.7600150364701466

Epoch: 6| Step: 1
Training loss: 0.40459880232810974
Validation loss: 1.7422925092840706

Epoch: 6| Step: 2
Training loss: 0.26982927322387695
Validation loss: 1.7481890622005667

Epoch: 6| Step: 3
Training loss: 0.5373272895812988
Validation loss: 1.7428032313623736

Epoch: 6| Step: 4
Training loss: 0.38571813702583313
Validation loss: 1.7445378675255725

Epoch: 6| Step: 5
Training loss: 0.38152047991752625
Validation loss: 1.749791746498436

Epoch: 6| Step: 6
Training loss: 0.3662096858024597
Validation loss: 1.7661715617743872

Epoch: 6| Step: 7
Training loss: 0.4363366365432739
Validation loss: 1.744416767551053

Epoch: 6| Step: 8
Training loss: 0.5576083660125732
Validation loss: 1.7268117691880913

Epoch: 6| Step: 9
Training loss: 0.6602025032043457
Validation loss: 1.7637712596565165

Epoch: 6| Step: 10
Training loss: 0.97474205493927
Validation loss: 1.7402067979176838

Epoch: 6| Step: 11
Training loss: 0.4310373365879059
Validation loss: 1.701984756736345

Epoch: 6| Step: 12
Training loss: 0.42852556705474854
Validation loss: 1.6713067357258131

Epoch: 6| Step: 13
Training loss: 0.3978082239627838
Validation loss: 1.6390884050758936

Epoch: 249| Step: 0
Training loss: 1.0585553646087646
Validation loss: 1.659981402017737

Epoch: 6| Step: 1
Training loss: 0.3071468472480774
Validation loss: 1.6839766912562872

Epoch: 6| Step: 2
Training loss: 0.6139395236968994
Validation loss: 1.6654951495508994

Epoch: 6| Step: 3
Training loss: 0.5913434028625488
Validation loss: 1.7066192908953595

Epoch: 6| Step: 4
Training loss: 0.5677059888839722
Validation loss: 1.7418280570737776

Epoch: 6| Step: 5
Training loss: 0.5259697437286377
Validation loss: 1.7730890153556742

Epoch: 6| Step: 6
Training loss: 0.45497795939445496
Validation loss: 1.844594790089515

Epoch: 6| Step: 7
Training loss: 0.35884976387023926
Validation loss: 1.8725146093676168

Epoch: 6| Step: 8
Training loss: 0.6710885167121887
Validation loss: 1.8655446190987863

Epoch: 6| Step: 9
Training loss: 0.44316813349723816
Validation loss: 1.884885416235975

Epoch: 6| Step: 10
Training loss: 0.34717828035354614
Validation loss: 1.832822157490638

Epoch: 6| Step: 11
Training loss: 0.41913217306137085
Validation loss: 1.8022435454912082

Epoch: 6| Step: 12
Training loss: 0.5009347796440125
Validation loss: 1.7840447272023847

Epoch: 6| Step: 13
Training loss: 0.5559244751930237
Validation loss: 1.7288113114654378

Epoch: 250| Step: 0
Training loss: 0.755743682384491
Validation loss: 1.6861273473308933

Epoch: 6| Step: 1
Training loss: 0.4805443286895752
Validation loss: 1.6734263435486825

Epoch: 6| Step: 2
Training loss: 0.9610880613327026
Validation loss: 1.6848888269034765

Epoch: 6| Step: 3
Training loss: 0.7870805263519287
Validation loss: 1.694363796582786

Epoch: 6| Step: 4
Training loss: 0.329586386680603
Validation loss: 1.7596797584205546

Epoch: 6| Step: 5
Training loss: 0.6599904894828796
Validation loss: 1.7651636164675477

Epoch: 6| Step: 6
Training loss: 0.4044904410839081
Validation loss: 1.76917661646361

Epoch: 6| Step: 7
Training loss: 0.1290418803691864
Validation loss: 1.7780499394221971

Epoch: 6| Step: 8
Training loss: 0.7094250917434692
Validation loss: 1.7609429974709787

Epoch: 6| Step: 9
Training loss: 0.49029338359832764
Validation loss: 1.7585505990571872

Epoch: 6| Step: 10
Training loss: 0.27667945623397827
Validation loss: 1.7354549964269002

Epoch: 6| Step: 11
Training loss: 0.404121071100235
Validation loss: 1.7210813709484634

Epoch: 6| Step: 12
Training loss: 0.3740086555480957
Validation loss: 1.7327228528197094

Epoch: 6| Step: 13
Training loss: 0.32504522800445557
Validation loss: 1.7480778309606737

Testing loss: 2.205741702185737
