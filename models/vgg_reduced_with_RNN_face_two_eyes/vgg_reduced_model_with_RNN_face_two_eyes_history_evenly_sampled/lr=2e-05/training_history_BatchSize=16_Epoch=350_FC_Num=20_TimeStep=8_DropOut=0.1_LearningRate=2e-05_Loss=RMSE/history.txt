Epoch: 1| Step: 0
Training loss: 4.576344426964494
Validation loss: 5.745808936304522

Epoch: 6| Step: 1
Training loss: 6.4400594123327
Validation loss: 5.725275625545694

Epoch: 6| Step: 2
Training loss: 5.491463712531904
Validation loss: 5.706719764686321

Epoch: 6| Step: 3
Training loss: 6.896156633833035
Validation loss: 5.686822745662286

Epoch: 6| Step: 4
Training loss: 5.218164468228313
Validation loss: 5.66522720893662

Epoch: 6| Step: 5
Training loss: 5.844908247619949
Validation loss: 5.640799281920907

Epoch: 6| Step: 6
Training loss: 5.264449625112456
Validation loss: 5.612327050945173

Epoch: 6| Step: 7
Training loss: 6.231386467482891
Validation loss: 5.580134943012836

Epoch: 6| Step: 8
Training loss: 5.416937699017239
Validation loss: 5.54428974215569

Epoch: 6| Step: 9
Training loss: 5.636931078976906
Validation loss: 5.503318730635038

Epoch: 6| Step: 10
Training loss: 4.364200887865777
Validation loss: 5.459997618359676

Epoch: 6| Step: 11
Training loss: 5.824381835619111
Validation loss: 5.407663013085143

Epoch: 6| Step: 12
Training loss: 5.431548094827192
Validation loss: 5.355521264591442

Epoch: 6| Step: 13
Training loss: 5.4317791539441
Validation loss: 5.296995301410682

Epoch: 2| Step: 0
Training loss: 6.86553275489564
Validation loss: 5.234057066825707

Epoch: 6| Step: 1
Training loss: 5.136626105687837
Validation loss: 5.169116116708217

Epoch: 6| Step: 2
Training loss: 5.269435330275074
Validation loss: 5.104222283762453

Epoch: 6| Step: 3
Training loss: 4.735644683293527
Validation loss: 5.038176881780521

Epoch: 6| Step: 4
Training loss: 5.500830500929035
Validation loss: 4.970347094081221

Epoch: 6| Step: 5
Training loss: 5.189226345839944
Validation loss: 4.903226789540234

Epoch: 6| Step: 6
Training loss: 4.114222926841476
Validation loss: 4.8348467702411515

Epoch: 6| Step: 7
Training loss: 5.100452904132192
Validation loss: 4.775172025638536

Epoch: 6| Step: 8
Training loss: 5.251403257752837
Validation loss: 4.7237460358279195

Epoch: 6| Step: 9
Training loss: 4.801299300771192
Validation loss: 4.682720074341373

Epoch: 6| Step: 10
Training loss: 4.831863092011342
Validation loss: 4.647776027516783

Epoch: 6| Step: 11
Training loss: 4.038018982780771
Validation loss: 4.615576345178242

Epoch: 6| Step: 12
Training loss: 3.636789159369769
Validation loss: 4.584792944917061

Epoch: 6| Step: 13
Training loss: 3.4740568239509324
Validation loss: 4.555491129018348

Epoch: 3| Step: 0
Training loss: 5.001748351553247
Validation loss: 4.525319514905398

Epoch: 6| Step: 1
Training loss: 6.19954303164915
Validation loss: 4.503930028995947

Epoch: 6| Step: 2
Training loss: 4.446669440166136
Validation loss: 4.489957845742899

Epoch: 6| Step: 3
Training loss: 4.815225597258163
Validation loss: 4.46953045579598

Epoch: 6| Step: 4
Training loss: 4.801297711743865
Validation loss: 4.445867001016345

Epoch: 6| Step: 5
Training loss: 4.962620439196932
Validation loss: 4.425218967243265

Epoch: 6| Step: 6
Training loss: 3.7947827763767
Validation loss: 4.4057726171260265

Epoch: 6| Step: 7
Training loss: 4.5154853984016725
Validation loss: 4.37972526797854

Epoch: 6| Step: 8
Training loss: 2.372966699069968
Validation loss: 4.3611694540435515

Epoch: 6| Step: 9
Training loss: 4.323415679931724
Validation loss: 4.346317963105398

Epoch: 6| Step: 10
Training loss: 3.5234653784754904
Validation loss: 4.332320846772067

Epoch: 6| Step: 11
Training loss: 4.613135507527979
Validation loss: 4.319697174714186

Epoch: 6| Step: 12
Training loss: 3.8557890630461173
Validation loss: 4.3041015640724565

Epoch: 6| Step: 13
Training loss: 5.37633480087627
Validation loss: 4.292139883660601

Epoch: 4| Step: 0
Training loss: 4.315781602497293
Validation loss: 4.275418920116075

Epoch: 6| Step: 1
Training loss: 4.51488343587907
Validation loss: 4.2636878496525545

Epoch: 6| Step: 2
Training loss: 3.7058636159984166
Validation loss: 4.2505679224619675

Epoch: 6| Step: 3
Training loss: 4.2523779107115836
Validation loss: 4.239321334921612

Epoch: 6| Step: 4
Training loss: 4.264467187047439
Validation loss: 4.227148393494503

Epoch: 6| Step: 5
Training loss: 3.8209453908836157
Validation loss: 4.212356220327105

Epoch: 6| Step: 6
Training loss: 4.523953159700276
Validation loss: 4.199272859858618

Epoch: 6| Step: 7
Training loss: 4.102228833523051
Validation loss: 4.188436468054025

Epoch: 6| Step: 8
Training loss: 4.63220684344714
Validation loss: 4.184208386346559

Epoch: 6| Step: 9
Training loss: 5.64051358015172
Validation loss: 4.158669449036513

Epoch: 6| Step: 10
Training loss: 3.607506206292982
Validation loss: 4.147500350065902

Epoch: 6| Step: 11
Training loss: 4.2359152382069025
Validation loss: 4.1349572491441196

Epoch: 6| Step: 12
Training loss: 4.301940817084908
Validation loss: 4.122156563386407

Epoch: 6| Step: 13
Training loss: 4.395973070765061
Validation loss: 4.10765328521772

Epoch: 5| Step: 0
Training loss: 4.307274790326798
Validation loss: 4.094604485672125

Epoch: 6| Step: 1
Training loss: 4.120294603721918
Validation loss: 4.079727661957143

Epoch: 6| Step: 2
Training loss: 4.650715450908845
Validation loss: 4.063394894412234

Epoch: 6| Step: 3
Training loss: 3.7999267872232534
Validation loss: 4.047273095003568

Epoch: 6| Step: 4
Training loss: 4.272197201681321
Validation loss: 4.031608233028363

Epoch: 6| Step: 5
Training loss: 3.708620781776878
Validation loss: 4.014805807841931

Epoch: 6| Step: 6
Training loss: 3.990453772878037
Validation loss: 3.998913466129334

Epoch: 6| Step: 7
Training loss: 4.142144841938964
Validation loss: 3.98424641230586

Epoch: 6| Step: 8
Training loss: 4.640398527328406
Validation loss: 3.966185278742789

Epoch: 6| Step: 9
Training loss: 4.042817780997749
Validation loss: 3.9510291946073397

Epoch: 6| Step: 10
Training loss: 4.650949623191046
Validation loss: 3.9382952284089914

Epoch: 6| Step: 11
Training loss: 3.7416550928515986
Validation loss: 3.922843922907287

Epoch: 6| Step: 12
Training loss: 3.8959320518239533
Validation loss: 3.9101738105250035

Epoch: 6| Step: 13
Training loss: 3.781202962283297
Validation loss: 3.893181712734242

Epoch: 6| Step: 0
Training loss: 3.4817133432500484
Validation loss: 3.8782291301959324

Epoch: 6| Step: 1
Training loss: 3.041702810273047
Validation loss: 3.8674805663643816

Epoch: 6| Step: 2
Training loss: 4.344818203440423
Validation loss: 3.8599690792182724

Epoch: 6| Step: 3
Training loss: 4.05169437898495
Validation loss: 3.849265699727302

Epoch: 6| Step: 4
Training loss: 3.576090938333498
Validation loss: 3.832953664766755

Epoch: 6| Step: 5
Training loss: 4.511925260763505
Validation loss: 3.8186576173512656

Epoch: 6| Step: 6
Training loss: 3.18054247709544
Validation loss: 3.803734435208557

Epoch: 6| Step: 7
Training loss: 5.161714005385098
Validation loss: 3.7925316519140426

Epoch: 6| Step: 8
Training loss: 4.203532486346398
Validation loss: 3.778198729100113

Epoch: 6| Step: 9
Training loss: 4.796571405104139
Validation loss: 3.7659971781461787

Epoch: 6| Step: 10
Training loss: 3.041945631917024
Validation loss: 3.75693767554251

Epoch: 6| Step: 11
Training loss: 3.71951850195056
Validation loss: 3.7504075338218854

Epoch: 6| Step: 12
Training loss: 4.237428584664506
Validation loss: 3.7360549850162847

Epoch: 6| Step: 13
Training loss: 3.1778209559597923
Validation loss: 3.7216402760180167

Epoch: 7| Step: 0
Training loss: 3.8385714249857066
Validation loss: 3.7094676467612087

Epoch: 6| Step: 1
Training loss: 3.8106247088892222
Validation loss: 3.6964133165145308

Epoch: 6| Step: 2
Training loss: 3.842050316135106
Validation loss: 3.6874838943922286

Epoch: 6| Step: 3
Training loss: 3.9395388214216496
Validation loss: 3.6784450855546447

Epoch: 6| Step: 4
Training loss: 3.408326802018179
Validation loss: 3.672852185113578

Epoch: 6| Step: 5
Training loss: 2.6928262494141153
Validation loss: 3.662388696224862

Epoch: 6| Step: 6
Training loss: 4.454642482330736
Validation loss: 3.6511908272764173

Epoch: 6| Step: 7
Training loss: 5.351165979550461
Validation loss: 3.63287877359671

Epoch: 6| Step: 8
Training loss: 2.9389881666113333
Validation loss: 3.6239875395114063

Epoch: 6| Step: 9
Training loss: 3.309175370402735
Validation loss: 3.645700781503072

Epoch: 6| Step: 10
Training loss: 3.493666640704936
Validation loss: 3.61063624531477

Epoch: 6| Step: 11
Training loss: 4.653807953364306
Validation loss: 3.6016645982271362

Epoch: 6| Step: 12
Training loss: 3.627813628485132
Validation loss: 3.6118134006318936

Epoch: 6| Step: 13
Training loss: 3.4674610114295
Validation loss: 3.5967358826205884

Epoch: 8| Step: 0
Training loss: 3.6785495561645223
Validation loss: 3.6008662492485604

Epoch: 6| Step: 1
Training loss: 4.233799293485643
Validation loss: 3.5772703398259305

Epoch: 6| Step: 2
Training loss: 3.011341115824797
Validation loss: 3.5587382019087834

Epoch: 6| Step: 3
Training loss: 4.153757136496911
Validation loss: 3.5547030129782136

Epoch: 6| Step: 4
Training loss: 2.821890012040028
Validation loss: 3.540152315867758

Epoch: 6| Step: 5
Training loss: 4.343121599807319
Validation loss: 3.5297382388222007

Epoch: 6| Step: 6
Training loss: 3.5430107408619693
Validation loss: 3.518309721580082

Epoch: 6| Step: 7
Training loss: 3.4352022294174516
Validation loss: 3.514368690972829

Epoch: 6| Step: 8
Training loss: 4.763868064328206
Validation loss: 3.5097786310253176

Epoch: 6| Step: 9
Training loss: 2.8012880428102185
Validation loss: 3.4932409026783624

Epoch: 6| Step: 10
Training loss: 3.761563084947668
Validation loss: 3.488149386464966

Epoch: 6| Step: 11
Training loss: 4.0414198705037006
Validation loss: 3.482495791908966

Epoch: 6| Step: 12
Training loss: 2.996819081346627
Validation loss: 3.475724722692685

Epoch: 6| Step: 13
Training loss: 4.2535239924526245
Validation loss: 3.4610303751832534

Epoch: 9| Step: 0
Training loss: 2.4832718997328764
Validation loss: 3.4540060175319507

Epoch: 6| Step: 1
Training loss: 4.14688270872847
Validation loss: 3.446818845996927

Epoch: 6| Step: 2
Training loss: 4.191644695570732
Validation loss: 3.44048185067578

Epoch: 6| Step: 3
Training loss: 3.2708132473922147
Validation loss: 3.4284607216704006

Epoch: 6| Step: 4
Training loss: 3.6418156457335624
Validation loss: 3.4136750930297035

Epoch: 6| Step: 5
Training loss: 3.505738594716158
Validation loss: 3.406866482381072

Epoch: 6| Step: 6
Training loss: 3.7076454096012745
Validation loss: 3.398500388787862

Epoch: 6| Step: 7
Training loss: 3.461425195780826
Validation loss: 3.3927972280186878

Epoch: 6| Step: 8
Training loss: 3.678349666815582
Validation loss: 3.3817141193232083

Epoch: 6| Step: 9
Training loss: 3.7345021756914454
Validation loss: 3.382184173161243

Epoch: 6| Step: 10
Training loss: 3.7508724469327372
Validation loss: 3.374272871668339

Epoch: 6| Step: 11
Training loss: 3.551405378659865
Validation loss: 3.3704117092008548

Epoch: 6| Step: 12
Training loss: 2.9949086218954024
Validation loss: 3.3675320006557476

Epoch: 6| Step: 13
Training loss: 4.777079240364931
Validation loss: 3.361045577320209

Epoch: 10| Step: 0
Training loss: 3.326630162616603
Validation loss: 3.352428228567395

Epoch: 6| Step: 1
Training loss: 3.3236211111751914
Validation loss: 3.345644255127744

Epoch: 6| Step: 2
Training loss: 2.3861077208588033
Validation loss: 3.339599462274238

Epoch: 6| Step: 3
Training loss: 4.336238376385221
Validation loss: 3.336757771840182

Epoch: 6| Step: 4
Training loss: 3.7480517094647037
Validation loss: 3.325849768399281

Epoch: 6| Step: 5
Training loss: 2.6867181394708886
Validation loss: 3.318293170352667

Epoch: 6| Step: 6
Training loss: 3.060998665401513
Validation loss: 3.316235906543337

Epoch: 6| Step: 7
Training loss: 2.9869073639110297
Validation loss: 3.3189394462569624

Epoch: 6| Step: 8
Training loss: 3.6713878551937493
Validation loss: 3.3858990730523315

Epoch: 6| Step: 9
Training loss: 3.7254969834973495
Validation loss: 3.3107794505211134

Epoch: 6| Step: 10
Training loss: 4.38811749843298
Validation loss: 3.2992381168823806

Epoch: 6| Step: 11
Training loss: 4.061430335439586
Validation loss: 3.2970478848643117

Epoch: 6| Step: 12
Training loss: 3.9950532127149843
Validation loss: 3.2882503888191335

Epoch: 6| Step: 13
Training loss: 3.4256225688377957
Validation loss: 3.2850158902556226

Epoch: 11| Step: 0
Training loss: 2.6011938801934695
Validation loss: 3.285134127968688

Epoch: 6| Step: 1
Training loss: 3.2186726681206395
Validation loss: 3.283373253654963

Epoch: 6| Step: 2
Training loss: 3.2355621665437577
Validation loss: 3.27348158404305

Epoch: 6| Step: 3
Training loss: 3.6159267658987195
Validation loss: 3.27450370845077

Epoch: 6| Step: 4
Training loss: 3.926664065266791
Validation loss: 3.2645243038782175

Epoch: 6| Step: 5
Training loss: 3.300090360849307
Validation loss: 3.2593580189822378

Epoch: 6| Step: 6
Training loss: 3.385275985533525
Validation loss: 3.2572929806356092

Epoch: 6| Step: 7
Training loss: 3.6180150051533295
Validation loss: 3.2574958890381946

Epoch: 6| Step: 8
Training loss: 4.137101426763916
Validation loss: 3.2557790741045087

Epoch: 6| Step: 9
Training loss: 2.9319475332252196
Validation loss: 3.2531395318233742

Epoch: 6| Step: 10
Training loss: 3.561710872587047
Validation loss: 3.2479997763345465

Epoch: 6| Step: 11
Training loss: 3.8115400763072005
Validation loss: 3.24254464708829

Epoch: 6| Step: 12
Training loss: 4.110619186204694
Validation loss: 3.2378850217230424

Epoch: 6| Step: 13
Training loss: 3.180612040707136
Validation loss: 3.237808653605904

Epoch: 12| Step: 0
Training loss: 3.6634761772271482
Validation loss: 3.233770866421061

Epoch: 6| Step: 1
Training loss: 2.7908803107506324
Validation loss: 3.234212262438452

Epoch: 6| Step: 2
Training loss: 3.275863877138445
Validation loss: 3.2297757376512863

Epoch: 6| Step: 3
Training loss: 3.963712122990936
Validation loss: 3.226685750237561

Epoch: 6| Step: 4
Training loss: 2.8640045876066664
Validation loss: 3.2224616300771314

Epoch: 6| Step: 5
Training loss: 3.4647856732202844
Validation loss: 3.218711128800603

Epoch: 6| Step: 6
Training loss: 3.280660812522576
Validation loss: 3.215554316893361

Epoch: 6| Step: 7
Training loss: 3.6815737933257733
Validation loss: 3.2127264751950086

Epoch: 6| Step: 8
Training loss: 3.6961630231565814
Validation loss: 3.2082745424553925

Epoch: 6| Step: 9
Training loss: 3.726518866645432
Validation loss: 3.2027139795664556

Epoch: 6| Step: 10
Training loss: 3.7802834024103356
Validation loss: 3.2001744408642376

Epoch: 6| Step: 11
Training loss: 3.610240221563859
Validation loss: 3.1938025448613048

Epoch: 6| Step: 12
Training loss: 2.7515504107840614
Validation loss: 3.207328430190381

Epoch: 6| Step: 13
Training loss: 4.019913457821452
Validation loss: 3.2079559768002857

Epoch: 13| Step: 0
Training loss: 3.0872873951226194
Validation loss: 3.1915177807400434

Epoch: 6| Step: 1
Training loss: 3.7269028482223536
Validation loss: 3.2204371649179477

Epoch: 6| Step: 2
Training loss: 2.7144083016900185
Validation loss: 3.2168393348598125

Epoch: 6| Step: 3
Training loss: 3.712361851443397
Validation loss: 3.2231586990131933

Epoch: 6| Step: 4
Training loss: 3.639551618438234
Validation loss: 3.220744667339263

Epoch: 6| Step: 5
Training loss: 2.889948255346296
Validation loss: 3.2145235369197027

Epoch: 6| Step: 6
Training loss: 3.6807551363848474
Validation loss: 3.2246171709922455

Epoch: 6| Step: 7
Training loss: 2.2816298704150215
Validation loss: 3.231453905966933

Epoch: 6| Step: 8
Training loss: 3.5234724157256974
Validation loss: 3.229898743041255

Epoch: 6| Step: 9
Training loss: 4.80220615232659
Validation loss: 3.218000531615802

Epoch: 6| Step: 10
Training loss: 4.103948338828529
Validation loss: 3.1912952551951825

Epoch: 6| Step: 11
Training loss: 3.3662252445210177
Validation loss: 3.211763676521201

Epoch: 6| Step: 12
Training loss: 3.324680031890757
Validation loss: 3.185754238818659

Epoch: 6| Step: 13
Training loss: 2.5594750204326093
Validation loss: 3.1744208019046645

Epoch: 14| Step: 0
Training loss: 3.0351546789531003
Validation loss: 3.1787184299061684

Epoch: 6| Step: 1
Training loss: 3.4401332133027283
Validation loss: 3.16604049679022

Epoch: 6| Step: 2
Training loss: 3.1992254571529966
Validation loss: 3.155487755567703

Epoch: 6| Step: 3
Training loss: 3.5487198254147923
Validation loss: 3.150356048434317

Epoch: 6| Step: 4
Training loss: 3.871861817566088
Validation loss: 3.1407281487976784

Epoch: 6| Step: 5
Training loss: 3.74739900031717
Validation loss: 3.1287692433820005

Epoch: 6| Step: 6
Training loss: 3.156774345127039
Validation loss: 3.145373067833081

Epoch: 6| Step: 7
Training loss: 2.562412818728232
Validation loss: 3.142061973602622

Epoch: 6| Step: 8
Training loss: 3.4374522812739023
Validation loss: 3.1737916034525058

Epoch: 6| Step: 9
Training loss: 3.6581339098914563
Validation loss: 3.1215321748337623

Epoch: 6| Step: 10
Training loss: 3.604531609612381
Validation loss: 3.1154986778827856

Epoch: 6| Step: 11
Training loss: 3.1604441357204474
Validation loss: 3.1121184984586927

Epoch: 6| Step: 12
Training loss: 3.724266256481929
Validation loss: 3.116298864168338

Epoch: 6| Step: 13
Training loss: 3.2154280918286298
Validation loss: 3.113744139428095

Epoch: 15| Step: 0
Training loss: 3.6633115214380263
Validation loss: 3.1216979155044493

Epoch: 6| Step: 1
Training loss: 2.8311266065912397
Validation loss: 3.104569163672598

Epoch: 6| Step: 2
Training loss: 3.924964326344092
Validation loss: 3.1266118591318364

Epoch: 6| Step: 3
Training loss: 3.626982179852996
Validation loss: 3.100404854323912

Epoch: 6| Step: 4
Training loss: 3.1032110872649357
Validation loss: 3.101010792041622

Epoch: 6| Step: 5
Training loss: 2.6591483067717805
Validation loss: 3.1149502991184232

Epoch: 6| Step: 6
Training loss: 3.265720785826088
Validation loss: 3.12704669829576

Epoch: 6| Step: 7
Training loss: 3.515624864366317
Validation loss: 3.1136022351764443

Epoch: 6| Step: 8
Training loss: 3.284692466194232
Validation loss: 3.0937593902647573

Epoch: 6| Step: 9
Training loss: 3.5303254394078007
Validation loss: 3.0929019661055293

Epoch: 6| Step: 10
Training loss: 3.4755782545047142
Validation loss: 3.0947414999930034

Epoch: 6| Step: 11
Training loss: 3.9379600377261355
Validation loss: 3.091695224767272

Epoch: 6| Step: 12
Training loss: 3.189093696258488
Validation loss: 3.0869559552796813

Epoch: 6| Step: 13
Training loss: 2.911886676176217
Validation loss: 3.082376727202242

Epoch: 16| Step: 0
Training loss: 3.295849970708458
Validation loss: 3.083638801065721

Epoch: 6| Step: 1
Training loss: 3.170802644505077
Validation loss: 3.0798714589145986

Epoch: 6| Step: 2
Training loss: 3.3968460039657677
Validation loss: 3.0765564122440257

Epoch: 6| Step: 3
Training loss: 2.7449010915255765
Validation loss: 3.075509297910014

Epoch: 6| Step: 4
Training loss: 3.4490561700783404
Validation loss: 3.0760201265454405

Epoch: 6| Step: 5
Training loss: 2.7357946579711525
Validation loss: 3.0747296329588463

Epoch: 6| Step: 6
Training loss: 3.313027681750327
Validation loss: 3.0748267731827696

Epoch: 6| Step: 7
Training loss: 3.96261410714364
Validation loss: 3.0726050706785637

Epoch: 6| Step: 8
Training loss: 3.7541611790308216
Validation loss: 3.0700346254153956

Epoch: 6| Step: 9
Training loss: 3.587323355230257
Validation loss: 3.070659405873406

Epoch: 6| Step: 10
Training loss: 3.266536311708169
Validation loss: 3.0677862762110295

Epoch: 6| Step: 11
Training loss: 3.4448097882958737
Validation loss: 3.0655849991763193

Epoch: 6| Step: 12
Training loss: 3.6482515144729266
Validation loss: 3.0634364692190243

Epoch: 6| Step: 13
Training loss: 2.6816665859313282
Validation loss: 3.062324669586169

Epoch: 17| Step: 0
Training loss: 3.6672131102309296
Validation loss: 3.06183758742182

Epoch: 6| Step: 1
Training loss: 2.4228334560740206
Validation loss: 3.0601965106106155

Epoch: 6| Step: 2
Training loss: 3.3893922595232344
Validation loss: 3.0586887524496515

Epoch: 6| Step: 3
Training loss: 3.100210514919335
Validation loss: 3.0574912690715395

Epoch: 6| Step: 4
Training loss: 3.2090218205742813
Validation loss: 3.0532344814481713

Epoch: 6| Step: 5
Training loss: 3.7406341578117326
Validation loss: 3.0541662640050835

Epoch: 6| Step: 6
Training loss: 4.056519316915163
Validation loss: 3.0528289820361816

Epoch: 6| Step: 7
Training loss: 3.3672353648171365
Validation loss: 3.049254458801883

Epoch: 6| Step: 8
Training loss: 3.4307683054188183
Validation loss: 3.0494140075518854

Epoch: 6| Step: 9
Training loss: 2.900260742567456
Validation loss: 3.046299114973282

Epoch: 6| Step: 10
Training loss: 3.3563913269407353
Validation loss: 3.0477819632106566

Epoch: 6| Step: 11
Training loss: 3.2667072455811708
Validation loss: 3.046189823944782

Epoch: 6| Step: 12
Training loss: 3.348138798907245
Validation loss: 3.045567229171448

Epoch: 6| Step: 13
Training loss: 3.1949513424793414
Validation loss: 3.0448977752224153

Epoch: 18| Step: 0
Training loss: 3.477012348002817
Validation loss: 3.042876783481878

Epoch: 6| Step: 1
Training loss: 3.930189096885832
Validation loss: 3.0469897479717156

Epoch: 6| Step: 2
Training loss: 3.4324417351586303
Validation loss: 3.041854154466986

Epoch: 6| Step: 3
Training loss: 2.616888592859884
Validation loss: 3.0434551818811184

Epoch: 6| Step: 4
Training loss: 3.430192983998233
Validation loss: 3.0442911732647486

Epoch: 6| Step: 5
Training loss: 3.8132329767755415
Validation loss: 3.0584500488500184

Epoch: 6| Step: 6
Training loss: 2.935032396543896
Validation loss: 3.036394126639762

Epoch: 6| Step: 7
Training loss: 2.604709588994379
Validation loss: 3.0370177662281916

Epoch: 6| Step: 8
Training loss: 3.715375250531001
Validation loss: 3.038534336436377

Epoch: 6| Step: 9
Training loss: 3.330181220911458
Validation loss: 3.038222417855972

Epoch: 6| Step: 10
Training loss: 2.968731689396657
Validation loss: 3.044306169596372

Epoch: 6| Step: 11
Training loss: 3.490873290053575
Validation loss: 3.0413778344633915

Epoch: 6| Step: 12
Training loss: 3.043240144548665
Validation loss: 3.037999389262443

Epoch: 6| Step: 13
Training loss: 3.7347142532305857
Validation loss: 3.035283508855244

Epoch: 19| Step: 0
Training loss: 3.1736436244450115
Validation loss: 3.0433307034208052

Epoch: 6| Step: 1
Training loss: 3.587066406205335
Validation loss: 3.033611601022345

Epoch: 6| Step: 2
Training loss: 3.7071787862089254
Validation loss: 3.0569054015647747

Epoch: 6| Step: 3
Training loss: 3.827206995915873
Validation loss: 3.0604778542492506

Epoch: 6| Step: 4
Training loss: 3.374769414866092
Validation loss: 3.0284774934242735

Epoch: 6| Step: 5
Training loss: 3.387085363483106
Validation loss: 3.0254848279162383

Epoch: 6| Step: 6
Training loss: 2.8152531182438096
Validation loss: 3.0260858214671367

Epoch: 6| Step: 7
Training loss: 3.1762508781759164
Validation loss: 3.0300400465921378

Epoch: 6| Step: 8
Training loss: 3.3031608355841993
Validation loss: 3.027012567787108

Epoch: 6| Step: 9
Training loss: 3.9306525378324837
Validation loss: 3.0242330188158015

Epoch: 6| Step: 10
Training loss: 3.0862800504597314
Validation loss: 3.0219881718056882

Epoch: 6| Step: 11
Training loss: 2.990486956592325
Validation loss: 3.018076232032732

Epoch: 6| Step: 12
Training loss: 2.911884056088689
Validation loss: 3.021954474287599

Epoch: 6| Step: 13
Training loss: 2.661356785299496
Validation loss: 3.0262026623339904

Epoch: 20| Step: 0
Training loss: 3.3103921769718534
Validation loss: 3.031617267848878

Epoch: 6| Step: 1
Training loss: 3.6304372590326444
Validation loss: 3.0202080429894114

Epoch: 6| Step: 2
Training loss: 3.252739851814021
Validation loss: 3.0175757547017388

Epoch: 6| Step: 3
Training loss: 2.605599967706368
Validation loss: 3.0196452745497084

Epoch: 6| Step: 4
Training loss: 3.0948052966574084
Validation loss: 3.0207321206613487

Epoch: 6| Step: 5
Training loss: 3.6609430434363706
Validation loss: 3.0302794263965467

Epoch: 6| Step: 6
Training loss: 3.6421733396067504
Validation loss: 3.018111294547833

Epoch: 6| Step: 7
Training loss: 3.297652455725133
Validation loss: 3.016079152172802

Epoch: 6| Step: 8
Training loss: 3.124723956313841
Validation loss: 3.016692604910219

Epoch: 6| Step: 9
Training loss: 3.335389139100341
Validation loss: 3.0161913727187564

Epoch: 6| Step: 10
Training loss: 3.6090896295467036
Validation loss: 3.017988827949373

Epoch: 6| Step: 11
Training loss: 3.57569662922868
Validation loss: 3.0148596085853185

Epoch: 6| Step: 12
Training loss: 3.2302203192432635
Validation loss: 3.012876442796807

Epoch: 6| Step: 13
Training loss: 2.4327896773701685
Validation loss: 3.012691461116528

Epoch: 21| Step: 0
Training loss: 3.2087284852136193
Validation loss: 3.0197342021180735

Epoch: 6| Step: 1
Training loss: 3.126495003722344
Validation loss: 3.0485397212654948

Epoch: 6| Step: 2
Training loss: 3.9900348032721773
Validation loss: 3.0344281160653583

Epoch: 6| Step: 3
Training loss: 3.9985618390110598
Validation loss: 3.0223995418728378

Epoch: 6| Step: 4
Training loss: 2.837467169886825
Validation loss: 3.0067102780826396

Epoch: 6| Step: 5
Training loss: 3.4351951501486044
Validation loss: 3.003617954142725

Epoch: 6| Step: 6
Training loss: 2.7053809481899407
Validation loss: 3.0133611466132124

Epoch: 6| Step: 7
Training loss: 2.8619946429337775
Validation loss: 3.0344609662418827

Epoch: 6| Step: 8
Training loss: 2.7232325640384363
Validation loss: 3.021297031127676

Epoch: 6| Step: 9
Training loss: 3.7056675162138677
Validation loss: 3.010147265480231

Epoch: 6| Step: 10
Training loss: 3.953307015672886
Validation loss: 3.006857602092025

Epoch: 6| Step: 11
Training loss: 3.3991768569837184
Validation loss: 3.019486837468128

Epoch: 6| Step: 12
Training loss: 2.2334006792798653
Validation loss: 3.030515170045774

Epoch: 6| Step: 13
Training loss: 3.831970401012492
Validation loss: 3.066353415112462

Epoch: 22| Step: 0
Training loss: 2.978074057944915
Validation loss: 3.054784064036909

Epoch: 6| Step: 1
Training loss: 3.5927706503539745
Validation loss: 3.0541922732736118

Epoch: 6| Step: 2
Training loss: 2.684684343022002
Validation loss: 3.029802992532417

Epoch: 6| Step: 3
Training loss: 3.884696395970628
Validation loss: 3.0315710873884

Epoch: 6| Step: 4
Training loss: 3.118446038671498
Validation loss: 3.037764866115018

Epoch: 6| Step: 5
Training loss: 3.0268015517484774
Validation loss: 3.0331895959729356

Epoch: 6| Step: 6
Training loss: 3.207454379345255
Validation loss: 3.0249636517134793

Epoch: 6| Step: 7
Training loss: 2.803236562152519
Validation loss: 3.0239314152037426

Epoch: 6| Step: 8
Training loss: 3.8106457312747177
Validation loss: 3.0226978464474406

Epoch: 6| Step: 9
Training loss: 3.217701565253855
Validation loss: 3.025284341960563

Epoch: 6| Step: 10
Training loss: 3.291886302203608
Validation loss: 3.026410081035136

Epoch: 6| Step: 11
Training loss: 3.746265841002857
Validation loss: 3.0287804277627384

Epoch: 6| Step: 12
Training loss: 3.361428276489534
Validation loss: 3.0258715212879572

Epoch: 6| Step: 13
Training loss: 3.4098326714145224
Validation loss: 3.018551966360531

Epoch: 23| Step: 0
Training loss: 3.292820466708831
Validation loss: 3.0059218086592927

Epoch: 6| Step: 1
Training loss: 3.3282800199555553
Validation loss: 2.98554695121677

Epoch: 6| Step: 2
Training loss: 2.5494960099866297
Validation loss: 2.985685744772399

Epoch: 6| Step: 3
Training loss: 2.954420663292294
Validation loss: 2.9852453396315113

Epoch: 6| Step: 4
Training loss: 2.510546943376088
Validation loss: 2.990378155647476

Epoch: 6| Step: 5
Training loss: 3.6093496346511307
Validation loss: 2.9932319734984594

Epoch: 6| Step: 6
Training loss: 3.036157784001923
Validation loss: 2.9832761666127987

Epoch: 6| Step: 7
Training loss: 2.983213987751517
Validation loss: 2.979489613096171

Epoch: 6| Step: 8
Training loss: 3.2088354799411425
Validation loss: 2.9777054396053533

Epoch: 6| Step: 9
Training loss: 3.597464060335457
Validation loss: 2.9732902760227398

Epoch: 6| Step: 10
Training loss: 3.637346748191207
Validation loss: 2.9745210970292115

Epoch: 6| Step: 11
Training loss: 4.188687739670833
Validation loss: 2.9723616085835864

Epoch: 6| Step: 12
Training loss: 3.667611231661072
Validation loss: 2.9730532378954897

Epoch: 6| Step: 13
Training loss: 2.6538701784626353
Validation loss: 2.9732903053383373

Epoch: 24| Step: 0
Training loss: 3.221108026539957
Validation loss: 2.9719106812295073

Epoch: 6| Step: 1
Training loss: 2.5242114695966755
Validation loss: 2.970790426518597

Epoch: 6| Step: 2
Training loss: 4.018805643174029
Validation loss: 2.99116559537102

Epoch: 6| Step: 3
Training loss: 2.8932473324887256
Validation loss: 2.965387783450167

Epoch: 6| Step: 4
Training loss: 3.489547380100856
Validation loss: 2.978524015197287

Epoch: 6| Step: 5
Training loss: 3.493700079655097
Validation loss: 2.992993533922874

Epoch: 6| Step: 6
Training loss: 3.211826025178765
Validation loss: 2.9890397003357334

Epoch: 6| Step: 7
Training loss: 3.646069299237038
Validation loss: 2.9887843356855712

Epoch: 6| Step: 8
Training loss: 2.5406982786677164
Validation loss: 2.974284924115656

Epoch: 6| Step: 9
Training loss: 2.9456712418295097
Validation loss: 2.964420024867716

Epoch: 6| Step: 10
Training loss: 3.574479023779951
Validation loss: 2.956096027319537

Epoch: 6| Step: 11
Training loss: 3.668129816875977
Validation loss: 2.9547616460447226

Epoch: 6| Step: 12
Training loss: 2.843619878118464
Validation loss: 2.9649153420327967

Epoch: 6| Step: 13
Training loss: 3.391245420447919
Validation loss: 2.9797015147093573

Epoch: 25| Step: 0
Training loss: 3.5351691988713125
Validation loss: 2.9636477239787133

Epoch: 6| Step: 1
Training loss: 3.7072702377027285
Validation loss: 2.9518869824614082

Epoch: 6| Step: 2
Training loss: 3.4414953421622574
Validation loss: 2.9483545380284997

Epoch: 6| Step: 3
Training loss: 3.304415644292367
Validation loss: 2.951869274198978

Epoch: 6| Step: 4
Training loss: 3.0351373973835343
Validation loss: 2.958761923936587

Epoch: 6| Step: 5
Training loss: 3.1415121618943447
Validation loss: 2.9858688853079896

Epoch: 6| Step: 6
Training loss: 2.311319513838372
Validation loss: 2.976096923459403

Epoch: 6| Step: 7
Training loss: 3.269137888663495
Validation loss: 2.973720225430404

Epoch: 6| Step: 8
Training loss: 3.447764106133563
Validation loss: 2.95339695800859

Epoch: 6| Step: 9
Training loss: 3.8572082614903964
Validation loss: 2.94147283717327

Epoch: 6| Step: 10
Training loss: 3.3683298390361083
Validation loss: 2.9313851015920473

Epoch: 6| Step: 11
Training loss: 2.443077455352233
Validation loss: 2.933182191963542

Epoch: 6| Step: 12
Training loss: 3.08164505660253
Validation loss: 2.9403237686508983

Epoch: 6| Step: 13
Training loss: 3.2142763622087336
Validation loss: 2.9437462613626524

Epoch: 26| Step: 0
Training loss: 3.291892675696713
Validation loss: 2.9463243650119137

Epoch: 6| Step: 1
Training loss: 2.8396278099855206
Validation loss: 2.933737243731989

Epoch: 6| Step: 2
Training loss: 3.208359623260455
Validation loss: 2.9314973460899445

Epoch: 6| Step: 3
Training loss: 3.1287776239557226
Validation loss: 2.9282661850379927

Epoch: 6| Step: 4
Training loss: 4.135413233117409
Validation loss: 2.9240622807856975

Epoch: 6| Step: 5
Training loss: 3.097541104614334
Validation loss: 2.922448465723515

Epoch: 6| Step: 6
Training loss: 3.3145204536104984
Validation loss: 2.9241969685288773

Epoch: 6| Step: 7
Training loss: 3.625416961893212
Validation loss: 2.926592886512369

Epoch: 6| Step: 8
Training loss: 2.3916400425012765
Validation loss: 2.936041771770714

Epoch: 6| Step: 9
Training loss: 2.515789903247144
Validation loss: 2.9525882797267182

Epoch: 6| Step: 10
Training loss: 3.3112087972114455
Validation loss: 2.96338529635796

Epoch: 6| Step: 11
Training loss: 3.064427606052128
Validation loss: 2.948457271260681

Epoch: 6| Step: 12
Training loss: 2.952674629544634
Validation loss: 2.9178377469584165

Epoch: 6| Step: 13
Training loss: 4.328510583992191
Validation loss: 2.91796753054419

Epoch: 27| Step: 0
Training loss: 3.4008561571049074
Validation loss: 2.93455401719389

Epoch: 6| Step: 1
Training loss: 3.020656361274032
Validation loss: 2.9730379252710595

Epoch: 6| Step: 2
Training loss: 3.4854209253832757
Validation loss: 2.984433710068084

Epoch: 6| Step: 3
Training loss: 2.886328230731491
Validation loss: 2.96726833430541

Epoch: 6| Step: 4
Training loss: 3.8849742865969565
Validation loss: 2.933504977079976

Epoch: 6| Step: 5
Training loss: 2.914810207463297
Validation loss: 2.91149889518388

Epoch: 6| Step: 6
Training loss: 2.7620329725326274
Validation loss: 2.9091854489405704

Epoch: 6| Step: 7
Training loss: 3.4266410627286774
Validation loss: 2.9097853042134667

Epoch: 6| Step: 8
Training loss: 2.3879784788634795
Validation loss: 2.9088895703788857

Epoch: 6| Step: 9
Training loss: 3.3411315933522703
Validation loss: 2.92405733553288

Epoch: 6| Step: 10
Training loss: 3.6580059041121085
Validation loss: 2.9615200395129873

Epoch: 6| Step: 11
Training loss: 3.021642186408832
Validation loss: 2.9253571599982604

Epoch: 6| Step: 12
Training loss: 3.30074917930056
Validation loss: 2.911865510274048

Epoch: 6| Step: 13
Training loss: 3.6338928585098524
Validation loss: 2.9065549868841956

Epoch: 28| Step: 0
Training loss: 2.9238662870129772
Validation loss: 2.9017088492137644

Epoch: 6| Step: 1
Training loss: 3.172502427457177
Validation loss: 2.9011691965992594

Epoch: 6| Step: 2
Training loss: 3.0633000477119463
Validation loss: 2.949160903594801

Epoch: 6| Step: 3
Training loss: 3.0834371360282957
Validation loss: 2.9092459812694793

Epoch: 6| Step: 4
Training loss: 3.2064482034615707
Validation loss: 2.900904839223695

Epoch: 6| Step: 5
Training loss: 3.544264719348411
Validation loss: 2.89757142249502

Epoch: 6| Step: 6
Training loss: 2.9704957346658434
Validation loss: 2.897645958601183

Epoch: 6| Step: 7
Training loss: 2.8540123853728834
Validation loss: 2.8928934328571865

Epoch: 6| Step: 8
Training loss: 3.014172139801324
Validation loss: 2.8882595539735747

Epoch: 6| Step: 9
Training loss: 3.3447103101794924
Validation loss: 2.8872956822522453

Epoch: 6| Step: 10
Training loss: 3.172694208499996
Validation loss: 2.8857277406001516

Epoch: 6| Step: 11
Training loss: 4.220050074564985
Validation loss: 2.8858468662857515

Epoch: 6| Step: 12
Training loss: 3.1431881897453713
Validation loss: 2.88274675622165

Epoch: 6| Step: 13
Training loss: 2.82426433605585
Validation loss: 2.8808497250442078

Epoch: 29| Step: 0
Training loss: 3.3207694423628773
Validation loss: 2.8820067898630177

Epoch: 6| Step: 1
Training loss: 3.7826132090406737
Validation loss: 2.880341591053853

Epoch: 6| Step: 2
Training loss: 3.5451790540318955
Validation loss: 2.881389768512904

Epoch: 6| Step: 3
Training loss: 3.0210225714680345
Validation loss: 2.878062657605907

Epoch: 6| Step: 4
Training loss: 2.7932269637249543
Validation loss: 2.8740804056680407

Epoch: 6| Step: 5
Training loss: 2.919495945105307
Validation loss: 2.8752806010730256

Epoch: 6| Step: 6
Training loss: 2.9209531257940338
Validation loss: 2.872808961752228

Epoch: 6| Step: 7
Training loss: 3.3507535798559522
Validation loss: 2.872847662278332

Epoch: 6| Step: 8
Training loss: 3.474017842863531
Validation loss: 2.8707281595774936

Epoch: 6| Step: 9
Training loss: 3.403560311435527
Validation loss: 2.868556040246773

Epoch: 6| Step: 10
Training loss: 2.964962440497277
Validation loss: 2.8676830041405945

Epoch: 6| Step: 11
Training loss: 3.34696050511546
Validation loss: 2.866686809203842

Epoch: 6| Step: 12
Training loss: 2.1486647607075073
Validation loss: 2.8681528798166465

Epoch: 6| Step: 13
Training loss: 3.3333827650855423
Validation loss: 2.8664234850455075

Epoch: 30| Step: 0
Training loss: 2.805260134923509
Validation loss: 2.8665611197817418

Epoch: 6| Step: 1
Training loss: 3.5676217989857255
Validation loss: 2.8683141695580905

Epoch: 6| Step: 2
Training loss: 3.3456934334725363
Validation loss: 2.868455630820433

Epoch: 6| Step: 3
Training loss: 3.1502241266836624
Validation loss: 2.876121304114641

Epoch: 6| Step: 4
Training loss: 2.6912485638449417
Validation loss: 2.877402362569142

Epoch: 6| Step: 5
Training loss: 3.3570903727594263
Validation loss: 2.8726300284000015

Epoch: 6| Step: 6
Training loss: 2.9033797662513314
Validation loss: 2.8743774209002084

Epoch: 6| Step: 7
Training loss: 3.597952599595435
Validation loss: 2.875416431701567

Epoch: 6| Step: 8
Training loss: 2.6488332987167897
Validation loss: 2.8589226167443957

Epoch: 6| Step: 9
Training loss: 2.849974474876273
Validation loss: 2.859956393193057

Epoch: 6| Step: 10
Training loss: 2.9956601859942613
Validation loss: 2.860025241507218

Epoch: 6| Step: 11
Training loss: 3.1081006683188845
Validation loss: 2.8650437406604685

Epoch: 6| Step: 12
Training loss: 3.7822537941990237
Validation loss: 2.896847508739167

Epoch: 6| Step: 13
Training loss: 3.603291326225626
Validation loss: 2.9145193832974203

Epoch: 31| Step: 0
Training loss: 3.6288509303086363
Validation loss: 2.906936757548874

Epoch: 6| Step: 1
Training loss: 2.6700544791789262
Validation loss: 2.8627306835771047

Epoch: 6| Step: 2
Training loss: 2.7834292671284864
Validation loss: 2.8553900513344006

Epoch: 6| Step: 3
Training loss: 3.6820705982342137
Validation loss: 2.852380714908703

Epoch: 6| Step: 4
Training loss: 2.8373115510582467
Validation loss: 2.85550177090327

Epoch: 6| Step: 5
Training loss: 3.7717835017802597
Validation loss: 2.857087667799427

Epoch: 6| Step: 6
Training loss: 3.455752930587015
Validation loss: 2.8570856291522873

Epoch: 6| Step: 7
Training loss: 2.6854326147568215
Validation loss: 2.865213006732715

Epoch: 6| Step: 8
Training loss: 2.983043113813823
Validation loss: 2.865875450910442

Epoch: 6| Step: 9
Training loss: 3.4876984625237775
Validation loss: 2.8680958529057974

Epoch: 6| Step: 10
Training loss: 3.3135273617808725
Validation loss: 2.8696801669212655

Epoch: 6| Step: 11
Training loss: 2.989897247386063
Validation loss: 2.8567034612034377

Epoch: 6| Step: 12
Training loss: 3.008360656726913
Validation loss: 2.8479466709595287

Epoch: 6| Step: 13
Training loss: 2.4344341853614457
Validation loss: 2.84630272443744

Epoch: 32| Step: 0
Training loss: 3.5167515284949245
Validation loss: 2.8474870935894994

Epoch: 6| Step: 1
Training loss: 3.462801945600286
Validation loss: 2.8478202516586064

Epoch: 6| Step: 2
Training loss: 3.4846194057535325
Validation loss: 2.8515710138027224

Epoch: 6| Step: 3
Training loss: 3.54207713422572
Validation loss: 2.8515367849249387

Epoch: 6| Step: 4
Training loss: 2.266730308574243
Validation loss: 2.8519859782796453

Epoch: 6| Step: 5
Training loss: 3.112663485358399
Validation loss: 2.8505595382061966

Epoch: 6| Step: 6
Training loss: 3.5860589033864363
Validation loss: 2.851169298241239

Epoch: 6| Step: 7
Training loss: 3.3353145115918754
Validation loss: 2.8429859554390307

Epoch: 6| Step: 8
Training loss: 3.356063417046931
Validation loss: 2.841899359350334

Epoch: 6| Step: 9
Training loss: 2.9973154772546766
Validation loss: 2.8393227778840493

Epoch: 6| Step: 10
Training loss: 2.7438748376900226
Validation loss: 2.8373841093674685

Epoch: 6| Step: 11
Training loss: 3.183975964402767
Validation loss: 2.8374392074470056

Epoch: 6| Step: 12
Training loss: 2.1844416355780316
Validation loss: 2.8360475777393406

Epoch: 6| Step: 13
Training loss: 3.1900678277054437
Validation loss: 2.8356047964857334

Epoch: 33| Step: 0
Training loss: 3.088980340709226
Validation loss: 2.829794894331894

Epoch: 6| Step: 1
Training loss: 3.1756809495615586
Validation loss: 2.828100821337821

Epoch: 6| Step: 2
Training loss: 3.1095534997052705
Validation loss: 2.826578007567899

Epoch: 6| Step: 3
Training loss: 2.6988581680169443
Validation loss: 2.8298401994098423

Epoch: 6| Step: 4
Training loss: 2.9823886192481193
Validation loss: 2.8239272695983115

Epoch: 6| Step: 5
Training loss: 2.484996022273052
Validation loss: 2.8169281094469363

Epoch: 6| Step: 6
Training loss: 3.1694185112321187
Validation loss: 2.821466337097832

Epoch: 6| Step: 7
Training loss: 2.8248572254392275
Validation loss: 2.8145050485589533

Epoch: 6| Step: 8
Training loss: 3.13058598039208
Validation loss: 2.8169510980698966

Epoch: 6| Step: 9
Training loss: 3.3036094692794267
Validation loss: 2.811003872481798

Epoch: 6| Step: 10
Training loss: 3.2615683149721058
Validation loss: 2.810600073827266

Epoch: 6| Step: 11
Training loss: 3.537050192983977
Validation loss: 2.808482114245989

Epoch: 6| Step: 12
Training loss: 3.9485665678026316
Validation loss: 2.8126081584884193

Epoch: 6| Step: 13
Training loss: 2.834198221331792
Validation loss: 2.8079337256550416

Epoch: 34| Step: 0
Training loss: 2.907631822453009
Validation loss: 2.809053228176902

Epoch: 6| Step: 1
Training loss: 3.2004448819854643
Validation loss: 2.807756574526203

Epoch: 6| Step: 2
Training loss: 3.541377844908006
Validation loss: 2.806188648670593

Epoch: 6| Step: 3
Training loss: 2.6565300288973948
Validation loss: 2.806519556837873

Epoch: 6| Step: 4
Training loss: 3.1197195071290658
Validation loss: 2.804838887306014

Epoch: 6| Step: 5
Training loss: 2.603353347929321
Validation loss: 2.803037618552607

Epoch: 6| Step: 6
Training loss: 3.436544112034641
Validation loss: 2.802739392084896

Epoch: 6| Step: 7
Training loss: 3.324787024080364
Validation loss: 2.8033408530795567

Epoch: 6| Step: 8
Training loss: 2.8955644624517305
Validation loss: 2.801415506830212

Epoch: 6| Step: 9
Training loss: 3.2422322097820873
Validation loss: 2.7998351830509067

Epoch: 6| Step: 10
Training loss: 3.1875368003964812
Validation loss: 2.796650196288841

Epoch: 6| Step: 11
Training loss: 3.4690563994480215
Validation loss: 2.8080443196088924

Epoch: 6| Step: 12
Training loss: 3.216424490816931
Validation loss: 2.804857295334085

Epoch: 6| Step: 13
Training loss: 2.4173499380124586
Validation loss: 2.8057022473327993

Epoch: 35| Step: 0
Training loss: 3.2359792075791782
Validation loss: 2.828586437159658

Epoch: 6| Step: 1
Training loss: 3.0097439200121814
Validation loss: 2.7985920642608475

Epoch: 6| Step: 2
Training loss: 3.1259858674396814
Validation loss: 2.7947397198279766

Epoch: 6| Step: 3
Training loss: 3.248740025351265
Validation loss: 2.7965794256615935

Epoch: 6| Step: 4
Training loss: 2.4921195759381063
Validation loss: 2.7954662113934443

Epoch: 6| Step: 5
Training loss: 3.4734511951308678
Validation loss: 2.8057796671081805

Epoch: 6| Step: 6
Training loss: 2.4626423092690706
Validation loss: 2.7934838999746314

Epoch: 6| Step: 7
Training loss: 3.522858904171953
Validation loss: 2.793382827626127

Epoch: 6| Step: 8
Training loss: 3.1471992878659503
Validation loss: 2.7925763828191363

Epoch: 6| Step: 9
Training loss: 3.4656638773602735
Validation loss: 2.7924854367807934

Epoch: 6| Step: 10
Training loss: 2.655461991052648
Validation loss: 2.793604865916247

Epoch: 6| Step: 11
Training loss: 3.312302493559109
Validation loss: 2.796458310616135

Epoch: 6| Step: 12
Training loss: 3.2486845435387743
Validation loss: 2.804038849447732

Epoch: 6| Step: 13
Training loss: 2.955593954122093
Validation loss: 2.8115532351418264

Epoch: 36| Step: 0
Training loss: 3.25920035167724
Validation loss: 2.8253322317025864

Epoch: 6| Step: 1
Training loss: 3.836878643615156
Validation loss: 2.8289003679790765

Epoch: 6| Step: 2
Training loss: 2.660703627948135
Validation loss: 2.804390180307406

Epoch: 6| Step: 3
Training loss: 2.766998294886321
Validation loss: 2.799779468559302

Epoch: 6| Step: 4
Training loss: 2.6893228957837816
Validation loss: 2.7883134700550474

Epoch: 6| Step: 5
Training loss: 2.9660055223903576
Validation loss: 2.78692403234373

Epoch: 6| Step: 6
Training loss: 3.0449225014030787
Validation loss: 2.7844834583907674

Epoch: 6| Step: 7
Training loss: 2.478878250228431
Validation loss: 2.786298522567929

Epoch: 6| Step: 8
Training loss: 3.6115607707141693
Validation loss: 2.7867301494762273

Epoch: 6| Step: 9
Training loss: 3.2016650338460826
Validation loss: 2.7862121350595275

Epoch: 6| Step: 10
Training loss: 3.0718359819575047
Validation loss: 2.7878795337258526

Epoch: 6| Step: 11
Training loss: 3.1231858137285387
Validation loss: 2.782502286386545

Epoch: 6| Step: 12
Training loss: 3.2802542492554294
Validation loss: 2.7848830534441125

Epoch: 6| Step: 13
Training loss: 3.576746512662692
Validation loss: 2.781117998294957

Epoch: 37| Step: 0
Training loss: 3.442283631106662
Validation loss: 2.7790314768440973

Epoch: 6| Step: 1
Training loss: 3.268636528656823
Validation loss: 2.777980630980914

Epoch: 6| Step: 2
Training loss: 2.600992684494461
Validation loss: 2.7812448363044777

Epoch: 6| Step: 3
Training loss: 2.9377546808749093
Validation loss: 2.776288205108242

Epoch: 6| Step: 4
Training loss: 3.429178882328368
Validation loss: 2.7769810229844922

Epoch: 6| Step: 5
Training loss: 3.3414235801149257
Validation loss: 2.777134175410583

Epoch: 6| Step: 6
Training loss: 3.014585483834098
Validation loss: 2.7790165139466283

Epoch: 6| Step: 7
Training loss: 3.014685133502767
Validation loss: 2.777744952660769

Epoch: 6| Step: 8
Training loss: 3.7331489880779603
Validation loss: 2.7765403877834935

Epoch: 6| Step: 9
Training loss: 2.9310032852555303
Validation loss: 2.7758517664516282

Epoch: 6| Step: 10
Training loss: 2.6526454029264808
Validation loss: 2.7716835124620514

Epoch: 6| Step: 11
Training loss: 3.0276711957489493
Validation loss: 2.7738118569698686

Epoch: 6| Step: 12
Training loss: 2.6552149831799072
Validation loss: 2.7737328406335258

Epoch: 6| Step: 13
Training loss: 3.1743543734390127
Validation loss: 2.7746402469408036

Epoch: 38| Step: 0
Training loss: 3.399639469553973
Validation loss: 2.775930440798101

Epoch: 6| Step: 1
Training loss: 3.042002062835094
Validation loss: 2.779787362718285

Epoch: 6| Step: 2
Training loss: 3.4239219918143977
Validation loss: 2.782964990888342

Epoch: 6| Step: 3
Training loss: 2.508614480198185
Validation loss: 2.783053206367745

Epoch: 6| Step: 4
Training loss: 3.123234364486247
Validation loss: 2.784872489124114

Epoch: 6| Step: 5
Training loss: 3.1112358620775664
Validation loss: 2.78128006944098

Epoch: 6| Step: 6
Training loss: 2.834865398945629
Validation loss: 2.779310364235357

Epoch: 6| Step: 7
Training loss: 2.6696584330185043
Validation loss: 2.781059631933827

Epoch: 6| Step: 8
Training loss: 3.1389829983477155
Validation loss: 2.7743672710960157

Epoch: 6| Step: 9
Training loss: 4.015618112758563
Validation loss: 2.7681072375222073

Epoch: 6| Step: 10
Training loss: 3.061352261711822
Validation loss: 2.766566627992813

Epoch: 6| Step: 11
Training loss: 2.9120042501774885
Validation loss: 2.765077014191675

Epoch: 6| Step: 12
Training loss: 2.645818535070011
Validation loss: 2.7692386542002816

Epoch: 6| Step: 13
Training loss: 3.2699996630933863
Validation loss: 2.7722462331634166

Epoch: 39| Step: 0
Training loss: 2.503180388220002
Validation loss: 2.7695016213585504

Epoch: 6| Step: 1
Training loss: 3.1179189182429528
Validation loss: 2.7670777629478116

Epoch: 6| Step: 2
Training loss: 3.023240824766312
Validation loss: 2.7639639535690463

Epoch: 6| Step: 3
Training loss: 3.6260043101298263
Validation loss: 2.761774126751329

Epoch: 6| Step: 4
Training loss: 3.4374442356094743
Validation loss: 2.7615010177055113

Epoch: 6| Step: 5
Training loss: 2.838380208221037
Validation loss: 2.7600147000308186

Epoch: 6| Step: 6
Training loss: 2.6959146462804227
Validation loss: 2.765393971857652

Epoch: 6| Step: 7
Training loss: 3.562958537256364
Validation loss: 2.760387009228977

Epoch: 6| Step: 8
Training loss: 2.590766017559142
Validation loss: 2.759122247289469

Epoch: 6| Step: 9
Training loss: 3.551719818457425
Validation loss: 2.758122919801926

Epoch: 6| Step: 10
Training loss: 2.8220175875001483
Validation loss: 2.7590058092295666

Epoch: 6| Step: 11
Training loss: 2.782542839028987
Validation loss: 2.7601510277460326

Epoch: 6| Step: 12
Training loss: 3.30472674695962
Validation loss: 2.7567110318174355

Epoch: 6| Step: 13
Training loss: 3.1423750978349423
Validation loss: 2.7588882837031696

Epoch: 40| Step: 0
Training loss: 3.1267323079434077
Validation loss: 2.7581107918230328

Epoch: 6| Step: 1
Training loss: 3.4552903786732814
Validation loss: 2.754130390197585

Epoch: 6| Step: 2
Training loss: 2.9313281538900715
Validation loss: 2.752939132128696

Epoch: 6| Step: 3
Training loss: 3.290512816282017
Validation loss: 2.755259502543721

Epoch: 6| Step: 4
Training loss: 2.7622019818458576
Validation loss: 2.755213669887805

Epoch: 6| Step: 5
Training loss: 3.164687709497577
Validation loss: 2.7544635651833733

Epoch: 6| Step: 6
Training loss: 3.8913708320480906
Validation loss: 2.7532053666248446

Epoch: 6| Step: 7
Training loss: 2.88352564646278
Validation loss: 2.7515152241528846

Epoch: 6| Step: 8
Training loss: 2.9489146094728484
Validation loss: 2.7473331377583494

Epoch: 6| Step: 9
Training loss: 3.167420213954501
Validation loss: 2.749847589671364

Epoch: 6| Step: 10
Training loss: 2.4054887236174447
Validation loss: 2.7504490316090675

Epoch: 6| Step: 11
Training loss: 2.749555898699949
Validation loss: 2.7523606964021163

Epoch: 6| Step: 12
Training loss: 3.1731297308522324
Validation loss: 2.7504776934092705

Epoch: 6| Step: 13
Training loss: 2.8759861788888466
Validation loss: 2.75020959340673

Epoch: 41| Step: 0
Training loss: 3.2443937217835077
Validation loss: 2.7517002085298556

Epoch: 6| Step: 1
Training loss: 2.640112652253565
Validation loss: 2.7514010903287374

Epoch: 6| Step: 2
Training loss: 3.558020871191796
Validation loss: 2.7494970497512785

Epoch: 6| Step: 3
Training loss: 3.4456470007066895
Validation loss: 2.7514938546152536

Epoch: 6| Step: 4
Training loss: 3.769226631150302
Validation loss: 2.749669740372264

Epoch: 6| Step: 5
Training loss: 2.35354480013037
Validation loss: 2.7489945353207172

Epoch: 6| Step: 6
Training loss: 2.9196429371365076
Validation loss: 2.7462099616376903

Epoch: 6| Step: 7
Training loss: 2.8709824728648328
Validation loss: 2.7484098929140033

Epoch: 6| Step: 8
Training loss: 3.3421494405540284
Validation loss: 2.748616701274576

Epoch: 6| Step: 9
Training loss: 2.7111989535586627
Validation loss: 2.748293749114521

Epoch: 6| Step: 10
Training loss: 3.4386503202245318
Validation loss: 2.747553427851171

Epoch: 6| Step: 11
Training loss: 2.4910243079225727
Validation loss: 2.7498404325129653

Epoch: 6| Step: 12
Training loss: 2.639616101991643
Validation loss: 2.746027494515898

Epoch: 6| Step: 13
Training loss: 3.333084208397831
Validation loss: 2.765040538023156

Epoch: 42| Step: 0
Training loss: 2.494888993968293
Validation loss: 2.759891285569078

Epoch: 6| Step: 1
Training loss: 2.7982925147449103
Validation loss: 2.752412062611025

Epoch: 6| Step: 2
Training loss: 3.1365287219641487
Validation loss: 2.7442168145391586

Epoch: 6| Step: 3
Training loss: 2.713002410628882
Validation loss: 2.738147878105816

Epoch: 6| Step: 4
Training loss: 3.190808841441629
Validation loss: 2.737085945977698

Epoch: 6| Step: 5
Training loss: 2.8451139092729276
Validation loss: 2.7363509887874677

Epoch: 6| Step: 6
Training loss: 3.2474716328592597
Validation loss: 2.736447643422457

Epoch: 6| Step: 7
Training loss: 3.3609093289367364
Validation loss: 2.73736339960049

Epoch: 6| Step: 8
Training loss: 3.200977033233003
Validation loss: 2.732834512185271

Epoch: 6| Step: 9
Training loss: 3.0153226552612957
Validation loss: 2.7356183269191368

Epoch: 6| Step: 10
Training loss: 3.67442590290543
Validation loss: 2.733337284188325

Epoch: 6| Step: 11
Training loss: 3.0242276994971395
Validation loss: 2.7355180873678293

Epoch: 6| Step: 12
Training loss: 3.0230147980514883
Validation loss: 2.7345129153487444

Epoch: 6| Step: 13
Training loss: 3.1284167112750128
Validation loss: 2.732545580662094

Epoch: 43| Step: 0
Training loss: 3.6203343851335976
Validation loss: 2.7331210072203933

Epoch: 6| Step: 1
Training loss: 1.717178666818408
Validation loss: 2.7295002038778424

Epoch: 6| Step: 2
Training loss: 2.767295203759616
Validation loss: 2.7333063234074686

Epoch: 6| Step: 3
Training loss: 3.1406984842538037
Validation loss: 2.741668047098749

Epoch: 6| Step: 4
Training loss: 3.297366860386496
Validation loss: 2.7607767128400553

Epoch: 6| Step: 5
Training loss: 2.8366247768275095
Validation loss: 2.759606351850909

Epoch: 6| Step: 6
Training loss: 2.615442679373443
Validation loss: 2.7364115126316113

Epoch: 6| Step: 7
Training loss: 2.8176635813846422
Validation loss: 2.7398186809530554

Epoch: 6| Step: 8
Training loss: 3.518520265061984
Validation loss: 2.7371422069742772

Epoch: 6| Step: 9
Training loss: 3.005528442329463
Validation loss: 2.7294915704210814

Epoch: 6| Step: 10
Training loss: 3.370693991994957
Validation loss: 2.727069602958128

Epoch: 6| Step: 11
Training loss: 3.0310322791494806
Validation loss: 2.7271000874289997

Epoch: 6| Step: 12
Training loss: 3.4889557838776097
Validation loss: 2.725935941818036

Epoch: 6| Step: 13
Training loss: 3.268213733570799
Validation loss: 2.7266453701797952

Epoch: 44| Step: 0
Training loss: 2.858971572515826
Validation loss: 2.7331316927835103

Epoch: 6| Step: 1
Training loss: 3.263994603891213
Validation loss: 2.742282907491326

Epoch: 6| Step: 2
Training loss: 3.557373641686026
Validation loss: 2.7584485855414833

Epoch: 6| Step: 3
Training loss: 2.817754287956088
Validation loss: 2.7490567913861392

Epoch: 6| Step: 4
Training loss: 2.9632163425118487
Validation loss: 2.737851566910675

Epoch: 6| Step: 5
Training loss: 2.8524095087299726
Validation loss: 2.728449609776043

Epoch: 6| Step: 6
Training loss: 3.301515179361322
Validation loss: 2.7297250971208378

Epoch: 6| Step: 7
Training loss: 2.5508158332384756
Validation loss: 2.7346728334670782

Epoch: 6| Step: 8
Training loss: 3.379005880485627
Validation loss: 2.73837481635483

Epoch: 6| Step: 9
Training loss: 2.556081222521203
Validation loss: 2.7560681470203465

Epoch: 6| Step: 10
Training loss: 2.422178286359083
Validation loss: 2.7492162309117933

Epoch: 6| Step: 11
Training loss: 4.008131583378077
Validation loss: 2.755360918239469

Epoch: 6| Step: 12
Training loss: 2.8252508406550505
Validation loss: 2.72836285548812

Epoch: 6| Step: 13
Training loss: 3.3599242715021855
Validation loss: 2.7262492990914855

Epoch: 45| Step: 0
Training loss: 3.3264307715412396
Validation loss: 2.728350305814602

Epoch: 6| Step: 1
Training loss: 2.994762617329673
Validation loss: 2.732281009244403

Epoch: 6| Step: 2
Training loss: 2.9021275312714416
Validation loss: 2.74208568870957

Epoch: 6| Step: 3
Training loss: 3.1013478702107165
Validation loss: 2.7849549111136827

Epoch: 6| Step: 4
Training loss: 2.649685275984221
Validation loss: 2.8000737904568673

Epoch: 6| Step: 5
Training loss: 3.271651260901966
Validation loss: 2.800231056670827

Epoch: 6| Step: 6
Training loss: 3.2500079228231256
Validation loss: 2.789126804844837

Epoch: 6| Step: 7
Training loss: 3.412760820307508
Validation loss: 2.7207818054054713

Epoch: 6| Step: 8
Training loss: 2.7348377817085865
Validation loss: 2.7151300349731855

Epoch: 6| Step: 9
Training loss: 2.6359694935157822
Validation loss: 2.717069741944354

Epoch: 6| Step: 10
Training loss: 3.671812276101568
Validation loss: 2.7352276594489253

Epoch: 6| Step: 11
Training loss: 2.5014653679636627
Validation loss: 2.7700640412106496

Epoch: 6| Step: 12
Training loss: 3.041738709593808
Validation loss: 2.819555306445306

Epoch: 6| Step: 13
Training loss: 3.560033647185346
Validation loss: 2.8827780062242585

Epoch: 46| Step: 0
Training loss: 3.0582660289984545
Validation loss: 2.817592477822966

Epoch: 6| Step: 1
Training loss: 2.794763375299164
Validation loss: 2.7955839112937437

Epoch: 6| Step: 2
Training loss: 3.611870501624859
Validation loss: 2.7859022583688873

Epoch: 6| Step: 3
Training loss: 3.161164037004036
Validation loss: 2.7913553367054793

Epoch: 6| Step: 4
Training loss: 3.0921574356444923
Validation loss: 2.7927584312436737

Epoch: 6| Step: 5
Training loss: 3.0824842228914977
Validation loss: 2.8037997730216566

Epoch: 6| Step: 6
Training loss: 3.4342470903675166
Validation loss: 2.815533717990527

Epoch: 6| Step: 7
Training loss: 3.2809462633787088
Validation loss: 2.805802304845882

Epoch: 6| Step: 8
Training loss: 3.677367432653584
Validation loss: 2.785292608124086

Epoch: 6| Step: 9
Training loss: 3.3460709547236758
Validation loss: 2.782209182340759

Epoch: 6| Step: 10
Training loss: 3.0274327418875604
Validation loss: 2.7822872825540075

Epoch: 6| Step: 11
Training loss: 2.4519191621084593
Validation loss: 2.7789051143950396

Epoch: 6| Step: 12
Training loss: 2.703650803776665
Validation loss: 2.7851147422130436

Epoch: 6| Step: 13
Training loss: 2.3620906132009254
Validation loss: 2.7824639453303863

Epoch: 47| Step: 0
Training loss: 3.0457767952726105
Validation loss: 2.7819145987556766

Epoch: 6| Step: 1
Training loss: 3.13904330531129
Validation loss: 2.7767500404259797

Epoch: 6| Step: 2
Training loss: 3.787641183972604
Validation loss: 2.77642730809042

Epoch: 6| Step: 3
Training loss: 3.273822916507162
Validation loss: 2.7726356337370532

Epoch: 6| Step: 4
Training loss: 3.146174296581131
Validation loss: 2.774034112484987

Epoch: 6| Step: 5
Training loss: 2.9197861655858603
Validation loss: 2.7758703999537784

Epoch: 6| Step: 6
Training loss: 2.556060328826777
Validation loss: 2.7685618898034314

Epoch: 6| Step: 7
Training loss: 3.1277947707888107
Validation loss: 2.7684745488039413

Epoch: 6| Step: 8
Training loss: 3.137293476739448
Validation loss: 2.769991556618744

Epoch: 6| Step: 9
Training loss: 2.6060870808055703
Validation loss: 2.7681566982391703

Epoch: 6| Step: 10
Training loss: 2.696827868848737
Validation loss: 2.7778507857487322

Epoch: 6| Step: 11
Training loss: 3.578842957275689
Validation loss: 2.780877898100193

Epoch: 6| Step: 12
Training loss: 3.0543443726123596
Validation loss: 2.780245201355626

Epoch: 6| Step: 13
Training loss: 2.9030238467559966
Validation loss: 2.78221377940436

Epoch: 48| Step: 0
Training loss: 3.877904480252058
Validation loss: 2.7888653407077575

Epoch: 6| Step: 1
Training loss: 2.9995949789666265
Validation loss: 2.7765944569893786

Epoch: 6| Step: 2
Training loss: 3.4352809332472405
Validation loss: 2.7750136744162197

Epoch: 6| Step: 3
Training loss: 3.3562233978865286
Validation loss: 2.7729290738983896

Epoch: 6| Step: 4
Training loss: 3.8699300269767525
Validation loss: 2.769276252618819

Epoch: 6| Step: 5
Training loss: 3.060985891554533
Validation loss: 2.7660278542297236

Epoch: 6| Step: 6
Training loss: 2.7303234492812956
Validation loss: 2.767168928875123

Epoch: 6| Step: 7
Training loss: 2.870203910522051
Validation loss: 2.768109099052669

Epoch: 6| Step: 8
Training loss: 2.72958591143314
Validation loss: 2.7661950198500067

Epoch: 6| Step: 9
Training loss: 3.115309376546201
Validation loss: 2.764466437170077

Epoch: 6| Step: 10
Training loss: 2.6422908426622524
Validation loss: 2.765943148911787

Epoch: 6| Step: 11
Training loss: 2.6651877434822135
Validation loss: 2.765052001430899

Epoch: 6| Step: 12
Training loss: 2.8557497817737945
Validation loss: 2.763397111071972

Epoch: 6| Step: 13
Training loss: 2.3355427794445296
Validation loss: 2.7628978819302423

Epoch: 49| Step: 0
Training loss: 3.0420047276025635
Validation loss: 2.7657255990208967

Epoch: 6| Step: 1
Training loss: 3.0194933495357503
Validation loss: 2.7628140790807167

Epoch: 6| Step: 2
Training loss: 3.0038530719549295
Validation loss: 2.764078808233113

Epoch: 6| Step: 3
Training loss: 2.7032707042784954
Validation loss: 2.7680443040901457

Epoch: 6| Step: 4
Training loss: 3.0483347990332477
Validation loss: 2.776420819635367

Epoch: 6| Step: 5
Training loss: 2.9265639273033592
Validation loss: 2.785968716724138

Epoch: 6| Step: 6
Training loss: 3.627503418556038
Validation loss: 2.795248383901519

Epoch: 6| Step: 7
Training loss: 3.469137221709357
Validation loss: 2.8177047316102253

Epoch: 6| Step: 8
Training loss: 3.0425196109287023
Validation loss: 2.7850341254639437

Epoch: 6| Step: 9
Training loss: 3.557217613480823
Validation loss: 2.7661180593760335

Epoch: 6| Step: 10
Training loss: 2.9571144565984975
Validation loss: 2.759528138330609

Epoch: 6| Step: 11
Training loss: 2.3895510586258215
Validation loss: 2.756080494207627

Epoch: 6| Step: 12
Training loss: 2.8112888695458222
Validation loss: 2.7569981351924198

Epoch: 6| Step: 13
Training loss: 3.4745651851286383
Validation loss: 2.755021495304581

Epoch: 50| Step: 0
Training loss: 2.711925667287018
Validation loss: 2.756182893549033

Epoch: 6| Step: 1
Training loss: 2.960066453342412
Validation loss: 2.7557315853329682

Epoch: 6| Step: 2
Training loss: 3.4608675086390575
Validation loss: 2.7577848816812542

Epoch: 6| Step: 3
Training loss: 3.411220318982084
Validation loss: 2.7544491082361127

Epoch: 6| Step: 4
Training loss: 2.940260543696653
Validation loss: 2.753465203213067

Epoch: 6| Step: 5
Training loss: 4.127988715163782
Validation loss: 2.7491669819491573

Epoch: 6| Step: 6
Training loss: 3.1021260631138436
Validation loss: 2.750330570447648

Epoch: 6| Step: 7
Training loss: 1.9576032643953893
Validation loss: 2.7546034073111274

Epoch: 6| Step: 8
Training loss: 2.2705206232837516
Validation loss: 2.7653740051216626

Epoch: 6| Step: 9
Training loss: 3.0799319777470457
Validation loss: 2.7824483762083747

Epoch: 6| Step: 10
Training loss: 3.6198881214198706
Validation loss: 2.7383429763289917

Epoch: 6| Step: 11
Training loss: 2.715594334752962
Validation loss: 2.7303411202867736

Epoch: 6| Step: 12
Training loss: 3.000862633342195
Validation loss: 2.705584590961268

Epoch: 6| Step: 13
Training loss: 2.893469488336043
Validation loss: 2.7039539176551455

Epoch: 51| Step: 0
Training loss: 3.1117320879076433
Validation loss: 2.7127442107608393

Epoch: 6| Step: 1
Training loss: 3.629015178708593
Validation loss: 2.704430712369729

Epoch: 6| Step: 2
Training loss: 2.464463000505257
Validation loss: 2.684418900304278

Epoch: 6| Step: 3
Training loss: 3.063920917576065
Validation loss: 2.6799287195051913

Epoch: 6| Step: 4
Training loss: 2.6973895487123176
Validation loss: 2.686250491090526

Epoch: 6| Step: 5
Training loss: 3.1923055887436322
Validation loss: 2.6953406481219

Epoch: 6| Step: 6
Training loss: 2.987052794626868
Validation loss: 2.6981444578414497

Epoch: 6| Step: 7
Training loss: 3.4816395238606894
Validation loss: 2.693447903957195

Epoch: 6| Step: 8
Training loss: 2.69750887072981
Validation loss: 2.706318591648558

Epoch: 6| Step: 9
Training loss: 2.754506147260414
Validation loss: 2.6803052942209074

Epoch: 6| Step: 10
Training loss: 2.9520350468216963
Validation loss: 2.67584431748108

Epoch: 6| Step: 11
Training loss: 3.532013802083439
Validation loss: 2.675707533500358

Epoch: 6| Step: 12
Training loss: 2.7432143850793187
Validation loss: 2.6725038888020207

Epoch: 6| Step: 13
Training loss: 2.9323729554061106
Validation loss: 2.676875917553678

Epoch: 52| Step: 0
Training loss: 3.000723433688663
Validation loss: 2.6877012375402107

Epoch: 6| Step: 1
Training loss: 2.861286462473989
Validation loss: 2.715340307998891

Epoch: 6| Step: 2
Training loss: 3.290189934903342
Validation loss: 2.7497402340686246

Epoch: 6| Step: 3
Training loss: 3.434842833986652
Validation loss: 2.718492576133868

Epoch: 6| Step: 4
Training loss: 3.1528440926888113
Validation loss: 2.6984655873654506

Epoch: 6| Step: 5
Training loss: 3.376719566550934
Validation loss: 2.675941319143078

Epoch: 6| Step: 6
Training loss: 2.723925082779976
Validation loss: 2.6733161586360867

Epoch: 6| Step: 7
Training loss: 2.391763054725265
Validation loss: 2.6652044054394755

Epoch: 6| Step: 8
Training loss: 3.130169369438668
Validation loss: 2.672395249782109

Epoch: 6| Step: 9
Training loss: 3.0853334246080144
Validation loss: 2.7362316610233046

Epoch: 6| Step: 10
Training loss: 3.1788586935225336
Validation loss: 2.7407887729256073

Epoch: 6| Step: 11
Training loss: 2.2984917588251133
Validation loss: 2.7645031193648117

Epoch: 6| Step: 12
Training loss: 3.105444182292758
Validation loss: 2.7815306354744944

Epoch: 6| Step: 13
Training loss: 3.524231544222786
Validation loss: 2.7912933535900057

Epoch: 53| Step: 0
Training loss: 2.5946407397243467
Validation loss: 2.7797074722330364

Epoch: 6| Step: 1
Training loss: 3.2701066945252872
Validation loss: 2.7367612584316774

Epoch: 6| Step: 2
Training loss: 3.3898798391826044
Validation loss: 2.7365182791177536

Epoch: 6| Step: 3
Training loss: 2.8776037616067778
Validation loss: 2.7371426808999817

Epoch: 6| Step: 4
Training loss: 3.420615883412019
Validation loss: 2.742473331121742

Epoch: 6| Step: 5
Training loss: 3.475963618097983
Validation loss: 2.741060878901499

Epoch: 6| Step: 6
Training loss: 2.7727734267689974
Validation loss: 2.7462519519586936

Epoch: 6| Step: 7
Training loss: 2.028430566559894
Validation loss: 2.742588606246486

Epoch: 6| Step: 8
Training loss: 3.0498314232437633
Validation loss: 2.735623383688916

Epoch: 6| Step: 9
Training loss: 3.138572515637178
Validation loss: 2.736888283389838

Epoch: 6| Step: 10
Training loss: 3.6752773673297967
Validation loss: 2.732309860218898

Epoch: 6| Step: 11
Training loss: 3.2545993245414504
Validation loss: 2.723615166682818

Epoch: 6| Step: 12
Training loss: 2.968514844716257
Validation loss: 2.7259475301728027

Epoch: 6| Step: 13
Training loss: 2.0877983565323213
Validation loss: 2.71141233012616

Epoch: 54| Step: 0
Training loss: 3.2911610919260412
Validation loss: 2.705990315644201

Epoch: 6| Step: 1
Training loss: 3.151516225510083
Validation loss: 2.7021360374188195

Epoch: 6| Step: 2
Training loss: 3.1812413423491597
Validation loss: 2.7076903388456124

Epoch: 6| Step: 3
Training loss: 3.097378539135516
Validation loss: 2.6949268295196664

Epoch: 6| Step: 4
Training loss: 3.098649432176514
Validation loss: 2.6630576977816625

Epoch: 6| Step: 5
Training loss: 3.1020138505814603
Validation loss: 2.665096058530249

Epoch: 6| Step: 6
Training loss: 2.860210859355153
Validation loss: 2.6676500670879038

Epoch: 6| Step: 7
Training loss: 2.9846846334998602
Validation loss: 2.666391791769142

Epoch: 6| Step: 8
Training loss: 3.029722005599421
Validation loss: 2.6684007444602655

Epoch: 6| Step: 9
Training loss: 3.145402150361699
Validation loss: 2.6661699092563613

Epoch: 6| Step: 10
Training loss: 2.758195801808806
Validation loss: 2.681595665035931

Epoch: 6| Step: 11
Training loss: 2.014306516936075
Validation loss: 2.6827986103866293

Epoch: 6| Step: 12
Training loss: 3.324679745043798
Validation loss: 2.6925737450447147

Epoch: 6| Step: 13
Training loss: 3.0565375069966416
Validation loss: 2.6890472018318494

Epoch: 55| Step: 0
Training loss: 2.4973259930330514
Validation loss: 2.702806485191303

Epoch: 6| Step: 1
Training loss: 3.0339066966124717
Validation loss: 2.70304382532378

Epoch: 6| Step: 2
Training loss: 2.8149295062221364
Validation loss: 2.689956330448376

Epoch: 6| Step: 3
Training loss: 3.418131692544646
Validation loss: 2.6766205972646206

Epoch: 6| Step: 4
Training loss: 3.3719255077690917
Validation loss: 2.670003303896642

Epoch: 6| Step: 5
Training loss: 3.1316299299352734
Validation loss: 2.6656160791071315

Epoch: 6| Step: 6
Training loss: 2.982025339961723
Validation loss: 2.6606656977572083

Epoch: 6| Step: 7
Training loss: 2.751397038109171
Validation loss: 2.6585093107432867

Epoch: 6| Step: 8
Training loss: 3.2180177911298626
Validation loss: 2.676490024305943

Epoch: 6| Step: 9
Training loss: 2.7284001931504025
Validation loss: 2.6919412243603564

Epoch: 6| Step: 10
Training loss: 3.0112286872790457
Validation loss: 2.6927580168453678

Epoch: 6| Step: 11
Training loss: 2.5297971724074064
Validation loss: 2.7104961010739133

Epoch: 6| Step: 12
Training loss: 3.3802799321111845
Validation loss: 2.7400371678275124

Epoch: 6| Step: 13
Training loss: 3.529330516796288
Validation loss: 2.7137967481987126

Epoch: 56| Step: 0
Training loss: 3.311211677349667
Validation loss: 2.6882575937829705

Epoch: 6| Step: 1
Training loss: 2.7087020231820675
Validation loss: 2.6886671030864115

Epoch: 6| Step: 2
Training loss: 3.5445861152974922
Validation loss: 2.7103216692819783

Epoch: 6| Step: 3
Training loss: 2.8050313329731598
Validation loss: 2.7079996965248534

Epoch: 6| Step: 4
Training loss: 3.499050556560062
Validation loss: 2.6993383235644215

Epoch: 6| Step: 5
Training loss: 2.1649988675720215
Validation loss: 2.707021499358399

Epoch: 6| Step: 6
Training loss: 2.6873420846364904
Validation loss: 2.7279759426922445

Epoch: 6| Step: 7
Training loss: 2.7423339109106797
Validation loss: 2.7447413322200136

Epoch: 6| Step: 8
Training loss: 3.300579863956407
Validation loss: 2.7610910648637708

Epoch: 6| Step: 9
Training loss: 2.83217806731506
Validation loss: 2.7293215584561086

Epoch: 6| Step: 10
Training loss: 2.4489376022346243
Validation loss: 2.736760449086021

Epoch: 6| Step: 11
Training loss: 3.888056263269303
Validation loss: 2.7308749692270036

Epoch: 6| Step: 12
Training loss: 2.7268986098574297
Validation loss: 2.719857155110599

Epoch: 6| Step: 13
Training loss: 3.5328975648690157
Validation loss: 2.721802257573943

Epoch: 57| Step: 0
Training loss: 3.082907896504149
Validation loss: 2.720481288788098

Epoch: 6| Step: 1
Training loss: 2.8586828509318614
Validation loss: 2.715261980704991

Epoch: 6| Step: 2
Training loss: 2.8336323599003133
Validation loss: 2.70708334374188

Epoch: 6| Step: 3
Training loss: 2.887339441368579
Validation loss: 2.6960035515674767

Epoch: 6| Step: 4
Training loss: 3.2163909859859148
Validation loss: 2.700442433463948

Epoch: 6| Step: 5
Training loss: 2.7090285558198826
Validation loss: 2.6975233923960396

Epoch: 6| Step: 6
Training loss: 2.463653712449898
Validation loss: 2.6737116198449256

Epoch: 6| Step: 7
Training loss: 3.3685891758848645
Validation loss: 2.6728628784176576

Epoch: 6| Step: 8
Training loss: 3.0289378048697273
Validation loss: 2.678325926023368

Epoch: 6| Step: 9
Training loss: 3.2793953149775907
Validation loss: 2.6721336787874814

Epoch: 6| Step: 10
Training loss: 3.5703333346971413
Validation loss: 2.671117370418683

Epoch: 6| Step: 11
Training loss: 2.854997796961374
Validation loss: 2.672816745466953

Epoch: 6| Step: 12
Training loss: 3.0530783080607953
Validation loss: 2.678525470567907

Epoch: 6| Step: 13
Training loss: 2.8008121504735
Validation loss: 2.6759909697112856

Epoch: 58| Step: 0
Training loss: 3.706479898819963
Validation loss: 2.669923807868066

Epoch: 6| Step: 1
Training loss: 3.0605711799050885
Validation loss: 2.670316018629106

Epoch: 6| Step: 2
Training loss: 2.3961456979767775
Validation loss: 2.6734711828337243

Epoch: 6| Step: 3
Training loss: 3.1708528722761753
Validation loss: 2.6789934425527453

Epoch: 6| Step: 4
Training loss: 2.9504849374758675
Validation loss: 2.683563001540451

Epoch: 6| Step: 5
Training loss: 2.751174502552256
Validation loss: 2.6832730189873195

Epoch: 6| Step: 6
Training loss: 3.1541422236178702
Validation loss: 2.711441783239877

Epoch: 6| Step: 7
Training loss: 2.5028983481443667
Validation loss: 2.74619003559101

Epoch: 6| Step: 8
Training loss: 3.087673500529812
Validation loss: 2.7392970559069605

Epoch: 6| Step: 9
Training loss: 2.780344269107828
Validation loss: 2.7356079537644766

Epoch: 6| Step: 10
Training loss: 3.7272889650756627
Validation loss: 2.740630945011291

Epoch: 6| Step: 11
Training loss: 3.0900835602458647
Validation loss: 2.7394327619606007

Epoch: 6| Step: 12
Training loss: 2.8321582002796264
Validation loss: 2.73537006513891

Epoch: 6| Step: 13
Training loss: 3.295355568717856
Validation loss: 2.7283745594442856

Epoch: 59| Step: 0
Training loss: 2.5682587462463546
Validation loss: 2.7304695048765337

Epoch: 6| Step: 1
Training loss: 3.324921835073809
Validation loss: 2.729007272606688

Epoch: 6| Step: 2
Training loss: 3.0205706427348233
Validation loss: 2.7333734762493935

Epoch: 6| Step: 3
Training loss: 2.6569347620927934
Validation loss: 2.730364441707561

Epoch: 6| Step: 4
Training loss: 3.363399773789919
Validation loss: 2.7210939209411675

Epoch: 6| Step: 5
Training loss: 2.9191870744017083
Validation loss: 2.717023324520316

Epoch: 6| Step: 6
Training loss: 3.252389762822335
Validation loss: 2.7148204368970785

Epoch: 6| Step: 7
Training loss: 2.776270834867369
Validation loss: 2.707118007950219

Epoch: 6| Step: 8
Training loss: 2.765626206909606
Validation loss: 2.686427973587423

Epoch: 6| Step: 9
Training loss: 2.7141858957335847
Validation loss: 2.6876849277571075

Epoch: 6| Step: 10
Training loss: 3.4933015211370066
Validation loss: 2.690060918073755

Epoch: 6| Step: 11
Training loss: 2.891401361906078
Validation loss: 2.687702798024242

Epoch: 6| Step: 12
Training loss: 3.3554332229456545
Validation loss: 2.690283919548916

Epoch: 6| Step: 13
Training loss: 3.2361237594364587
Validation loss: 2.689273343596578

Epoch: 60| Step: 0
Training loss: 2.3257071209345606
Validation loss: 2.6890640419997567

Epoch: 6| Step: 1
Training loss: 3.467376437031189
Validation loss: 2.690860348291363

Epoch: 6| Step: 2
Training loss: 2.989559284250823
Validation loss: 2.687812500833241

Epoch: 6| Step: 3
Training loss: 3.0054138924272844
Validation loss: 2.6891373952215427

Epoch: 6| Step: 4
Training loss: 3.5097914383267503
Validation loss: 2.687382152937379

Epoch: 6| Step: 5
Training loss: 2.5939847541190466
Validation loss: 2.6855579388671167

Epoch: 6| Step: 6
Training loss: 3.0691648867088652
Validation loss: 2.6854923664128503

Epoch: 6| Step: 7
Training loss: 3.274546724357434
Validation loss: 2.6893120876298116

Epoch: 6| Step: 8
Training loss: 3.343368936376385
Validation loss: 2.702414620410448

Epoch: 6| Step: 9
Training loss: 2.6404126324551824
Validation loss: 2.706843973960987

Epoch: 6| Step: 10
Training loss: 2.8697632905326818
Validation loss: 2.7116813361438847

Epoch: 6| Step: 11
Training loss: 2.812832537171673
Validation loss: 2.710163241004854

Epoch: 6| Step: 12
Training loss: 3.198405589814332
Validation loss: 2.692956645259886

Epoch: 6| Step: 13
Training loss: 3.026027467117655
Validation loss: 2.6819506149515706

Epoch: 61| Step: 0
Training loss: 3.4742126066763905
Validation loss: 2.689263170132926

Epoch: 6| Step: 1
Training loss: 3.037111259042824
Validation loss: 2.7005882055819357

Epoch: 6| Step: 2
Training loss: 3.4780541809494743
Validation loss: 2.6941650744638372

Epoch: 6| Step: 3
Training loss: 3.0502035104363325
Validation loss: 2.6850080620126824

Epoch: 6| Step: 4
Training loss: 2.875915215814306
Validation loss: 2.682390402388288

Epoch: 6| Step: 5
Training loss: 3.3737738465932394
Validation loss: 2.678147612725005

Epoch: 6| Step: 6
Training loss: 3.0283988836650937
Validation loss: 2.677796908222769

Epoch: 6| Step: 7
Training loss: 2.9815938883201656
Validation loss: 2.6772157382474244

Epoch: 6| Step: 8
Training loss: 3.1984120005013694
Validation loss: 2.6784283021501833

Epoch: 6| Step: 9
Training loss: 2.880726460122397
Validation loss: 2.6820554478529974

Epoch: 6| Step: 10
Training loss: 3.0554981765754112
Validation loss: 2.68324467834765

Epoch: 6| Step: 11
Training loss: 2.331098974004584
Validation loss: 2.6870775923429426

Epoch: 6| Step: 12
Training loss: 2.293842831429986
Validation loss: 2.6970129003447316

Epoch: 6| Step: 13
Training loss: 2.9478352314155396
Validation loss: 2.706033280595995

Epoch: 62| Step: 0
Training loss: 3.1392160168292627
Validation loss: 2.7002287036710935

Epoch: 6| Step: 1
Training loss: 2.870955234222432
Validation loss: 2.6902556032132914

Epoch: 6| Step: 2
Training loss: 3.1921361977912257
Validation loss: 2.682747932397821

Epoch: 6| Step: 3
Training loss: 1.9913562910563463
Validation loss: 2.6756154952069773

Epoch: 6| Step: 4
Training loss: 2.7543442830934497
Validation loss: 2.673712333215943

Epoch: 6| Step: 5
Training loss: 3.0363665000328885
Validation loss: 2.6697252298077467

Epoch: 6| Step: 6
Training loss: 3.0752883465801735
Validation loss: 2.6694033731749207

Epoch: 6| Step: 7
Training loss: 3.808629807521622
Validation loss: 2.668526628277919

Epoch: 6| Step: 8
Training loss: 2.791206027691216
Validation loss: 2.6700066548663544

Epoch: 6| Step: 9
Training loss: 3.222632723635716
Validation loss: 2.665920882637779

Epoch: 6| Step: 10
Training loss: 2.3595707287980243
Validation loss: 2.646148945422555

Epoch: 6| Step: 11
Training loss: 3.290285150524972
Validation loss: 2.6578042305921534

Epoch: 6| Step: 12
Training loss: 2.7392329196172858
Validation loss: 2.715064882125514

Epoch: 6| Step: 13
Training loss: 3.8614250637885483
Validation loss: 2.73468291299578

Epoch: 63| Step: 0
Training loss: 2.5855248804881557
Validation loss: 2.627279765375691

Epoch: 6| Step: 1
Training loss: 2.459879232869271
Validation loss: 2.6092834820122337

Epoch: 6| Step: 2
Training loss: 2.657799661415843
Validation loss: 2.617943355978802

Epoch: 6| Step: 3
Training loss: 2.7668840376553607
Validation loss: 2.6768117672517557

Epoch: 6| Step: 4
Training loss: 3.252688689567859
Validation loss: 2.7891494490624487

Epoch: 6| Step: 5
Training loss: 2.8808072360218278
Validation loss: 2.8297924600546382

Epoch: 6| Step: 6
Training loss: 2.719188698638344
Validation loss: 2.848348528707347

Epoch: 6| Step: 7
Training loss: 2.767951030281493
Validation loss: 2.846685835699882

Epoch: 6| Step: 8
Training loss: 3.450826164507764
Validation loss: 2.8373638062387387

Epoch: 6| Step: 9
Training loss: 3.442002278390914
Validation loss: 2.807258111863279

Epoch: 6| Step: 10
Training loss: 3.91565786044983
Validation loss: 2.774312533817231

Epoch: 6| Step: 11
Training loss: 3.0450543563826895
Validation loss: 2.731593004945677

Epoch: 6| Step: 12
Training loss: 3.5999121867172255
Validation loss: 2.683860624989947

Epoch: 6| Step: 13
Training loss: 3.198577928465294
Validation loss: 2.640022311478369

Epoch: 64| Step: 0
Training loss: 1.9307067897238415
Validation loss: 2.634220345115692

Epoch: 6| Step: 1
Training loss: 3.7275162921756704
Validation loss: 2.6661917939161466

Epoch: 6| Step: 2
Training loss: 3.3200874521618315
Validation loss: 2.7312933451146613

Epoch: 6| Step: 3
Training loss: 3.432766655262904
Validation loss: 2.7048070452875383

Epoch: 6| Step: 4
Training loss: 3.3110935896282583
Validation loss: 2.6686516050677556

Epoch: 6| Step: 5
Training loss: 2.483873232667463
Validation loss: 2.6134577336152165

Epoch: 6| Step: 6
Training loss: 2.5166729941720134
Validation loss: 2.605886881704454

Epoch: 6| Step: 7
Training loss: 3.0594211594369525
Validation loss: 2.608235009528824

Epoch: 6| Step: 8
Training loss: 2.961613318786267
Validation loss: 2.6080903321015447

Epoch: 6| Step: 9
Training loss: 2.670274310790362
Validation loss: 2.60743880678709

Epoch: 6| Step: 10
Training loss: 3.0489945302121604
Validation loss: 2.6099672147145183

Epoch: 6| Step: 11
Training loss: 3.4110564871220475
Validation loss: 2.609364410883896

Epoch: 6| Step: 12
Training loss: 2.7609115348937787
Validation loss: 2.609711231706405

Epoch: 6| Step: 13
Training loss: 2.818802955282261
Validation loss: 2.613851757594497

Epoch: 65| Step: 0
Training loss: 2.8731672001167388
Validation loss: 2.616876608747229

Epoch: 6| Step: 1
Training loss: 2.536346109298004
Validation loss: 2.626620384863381

Epoch: 6| Step: 2
Training loss: 3.460533927999189
Validation loss: 2.644869983553639

Epoch: 6| Step: 3
Training loss: 2.387404123348444
Validation loss: 2.6566503079576003

Epoch: 6| Step: 4
Training loss: 2.8549426803580285
Validation loss: 2.6515496212146807

Epoch: 6| Step: 5
Training loss: 3.387696579300354
Validation loss: 2.6594200949758573

Epoch: 6| Step: 6
Training loss: 2.9335449864871923
Validation loss: 2.6362514218738227

Epoch: 6| Step: 7
Training loss: 3.2545861384540413
Validation loss: 2.6243489977336467

Epoch: 6| Step: 8
Training loss: 2.598574368559015
Validation loss: 2.608453923192165

Epoch: 6| Step: 9
Training loss: 2.7743019153845347
Validation loss: 2.6032946662803784

Epoch: 6| Step: 10
Training loss: 3.119313979900099
Validation loss: 2.6044276205595662

Epoch: 6| Step: 11
Training loss: 3.023203443984659
Validation loss: 2.605342540121559

Epoch: 6| Step: 12
Training loss: 3.3213328510326443
Validation loss: 2.60547277236827

Epoch: 6| Step: 13
Training loss: 2.7174095269297083
Validation loss: 2.605013129867063

Epoch: 66| Step: 0
Training loss: 2.3450084105383513
Validation loss: 2.604274867281334

Epoch: 6| Step: 1
Training loss: 2.502258425093649
Validation loss: 2.6020519926004666

Epoch: 6| Step: 2
Training loss: 2.439331442590429
Validation loss: 2.6025500773467454

Epoch: 6| Step: 3
Training loss: 3.2260064853666877
Validation loss: 2.6034442088160215

Epoch: 6| Step: 4
Training loss: 3.238146366121787
Validation loss: 2.6016003104221483

Epoch: 6| Step: 5
Training loss: 2.9827588883343386
Validation loss: 2.6025179142969934

Epoch: 6| Step: 6
Training loss: 2.5657871840926236
Validation loss: 2.6215218541200342

Epoch: 6| Step: 7
Training loss: 3.350245930768495
Validation loss: 2.659017604706648

Epoch: 6| Step: 8
Training loss: 3.0098423041416607
Validation loss: 2.615769660399339

Epoch: 6| Step: 9
Training loss: 3.0945922013472407
Validation loss: 2.597284376228274

Epoch: 6| Step: 10
Training loss: 2.886297667561169
Validation loss: 2.6019243065570645

Epoch: 6| Step: 11
Training loss: 3.3645548784845927
Validation loss: 2.6041468245868113

Epoch: 6| Step: 12
Training loss: 3.3663700111547383
Validation loss: 2.605313964787919

Epoch: 6| Step: 13
Training loss: 2.786590078691625
Validation loss: 2.6122181310872437

Epoch: 67| Step: 0
Training loss: 3.3472864576606933
Validation loss: 2.618937339839499

Epoch: 6| Step: 1
Training loss: 3.083875213295239
Validation loss: 2.6126730300134455

Epoch: 6| Step: 2
Training loss: 2.1078717562049856
Validation loss: 2.6079037690378533

Epoch: 6| Step: 3
Training loss: 2.99492725010115
Validation loss: 2.6058543840278445

Epoch: 6| Step: 4
Training loss: 3.005674717159376
Validation loss: 2.6024674067400273

Epoch: 6| Step: 5
Training loss: 2.9855360399024895
Validation loss: 2.59690257335794

Epoch: 6| Step: 6
Training loss: 2.9442054023717468
Validation loss: 2.5954846303198478

Epoch: 6| Step: 7
Training loss: 2.8945240015513156
Validation loss: 2.597611275350733

Epoch: 6| Step: 8
Training loss: 3.3529246303280003
Validation loss: 2.599493140178571

Epoch: 6| Step: 9
Training loss: 2.8718131273513836
Validation loss: 2.60166364780684

Epoch: 6| Step: 10
Training loss: 2.3950255538755827
Validation loss: 2.619434788801605

Epoch: 6| Step: 11
Training loss: 3.128176181309722
Validation loss: 2.6462092159646127

Epoch: 6| Step: 12
Training loss: 3.084058899610163
Validation loss: 2.645409467168746

Epoch: 6| Step: 13
Training loss: 3.2312648396547843
Validation loss: 2.623805236616427

Epoch: 68| Step: 0
Training loss: 3.0467363374897842
Validation loss: 2.6007703147604104

Epoch: 6| Step: 1
Training loss: 3.115205904552505
Validation loss: 2.5904117811914555

Epoch: 6| Step: 2
Training loss: 2.914812824920545
Validation loss: 2.5915515179932864

Epoch: 6| Step: 3
Training loss: 3.3615843139405928
Validation loss: 2.590427519790805

Epoch: 6| Step: 4
Training loss: 2.8514618320201612
Validation loss: 2.589951051024679

Epoch: 6| Step: 5
Training loss: 2.776371910582291
Validation loss: 2.589451773447995

Epoch: 6| Step: 6
Training loss: 3.0228016896972942
Validation loss: 2.591338015547945

Epoch: 6| Step: 7
Training loss: 2.62714262211506
Validation loss: 2.5887873003550266

Epoch: 6| Step: 8
Training loss: 2.6866645401535263
Validation loss: 2.590484368165072

Epoch: 6| Step: 9
Training loss: 2.8016536529741045
Validation loss: 2.5885482282578702

Epoch: 6| Step: 10
Training loss: 2.9778066523023443
Validation loss: 2.5847710595721134

Epoch: 6| Step: 11
Training loss: 3.1903577971028825
Validation loss: 2.587235155422857

Epoch: 6| Step: 12
Training loss: 2.8609288063938094
Validation loss: 2.5855551459516013

Epoch: 6| Step: 13
Training loss: 3.0830037911757113
Validation loss: 2.59116341101615

Epoch: 69| Step: 0
Training loss: 2.9789478426154825
Validation loss: 2.6248944335039717

Epoch: 6| Step: 1
Training loss: 3.1516377203177073
Validation loss: 2.6330604167506126

Epoch: 6| Step: 2
Training loss: 2.8571102991973873
Validation loss: 2.6821694801537306

Epoch: 6| Step: 3
Training loss: 3.5400367726285698
Validation loss: 2.7186638056173074

Epoch: 6| Step: 4
Training loss: 2.90846430602918
Validation loss: 2.699917785223814

Epoch: 6| Step: 5
Training loss: 2.774548117471483
Validation loss: 2.6843446837223977

Epoch: 6| Step: 6
Training loss: 3.196330535554339
Validation loss: 2.6815667464391653

Epoch: 6| Step: 7
Training loss: 2.9530617036040696
Validation loss: 2.6702973628451088

Epoch: 6| Step: 8
Training loss: 2.9300073067635837
Validation loss: 2.635320941302472

Epoch: 6| Step: 9
Training loss: 3.4322414056844153
Validation loss: 2.6140350530417797

Epoch: 6| Step: 10
Training loss: 2.5985522567723662
Validation loss: 2.6126866151471044

Epoch: 6| Step: 11
Training loss: 2.553032855422009
Validation loss: 2.6239086368898996

Epoch: 6| Step: 12
Training loss: 3.0055671534977506
Validation loss: 2.636792411185457

Epoch: 6| Step: 13
Training loss: 2.89011440407049
Validation loss: 2.6333201124041903

Epoch: 70| Step: 0
Training loss: 2.8619836466473316
Validation loss: 2.628896323686616

Epoch: 6| Step: 1
Training loss: 2.6107882024973916
Validation loss: 2.6091791228893597

Epoch: 6| Step: 2
Training loss: 3.298210271383966
Validation loss: 2.6061872331177787

Epoch: 6| Step: 3
Training loss: 2.8192681997134086
Validation loss: 2.59732345409506

Epoch: 6| Step: 4
Training loss: 2.9184055231280515
Validation loss: 2.5962490442670907

Epoch: 6| Step: 5
Training loss: 3.143154966189146
Validation loss: 2.5915606723119926

Epoch: 6| Step: 6
Training loss: 2.2614365370332754
Validation loss: 2.5843376492554735

Epoch: 6| Step: 7
Training loss: 2.854568861493757
Validation loss: 2.5774449400839807

Epoch: 6| Step: 8
Training loss: 3.141644364605846
Validation loss: 2.572732932223009

Epoch: 6| Step: 9
Training loss: 2.759166266386494
Validation loss: 2.5775091226798112

Epoch: 6| Step: 10
Training loss: 3.477977678961089
Validation loss: 2.5760190126436147

Epoch: 6| Step: 11
Training loss: 3.2796836384118526
Validation loss: 2.583178914192193

Epoch: 6| Step: 12
Training loss: 2.978132019354923
Validation loss: 2.585549718342142

Epoch: 6| Step: 13
Training loss: 2.6131626438658384
Validation loss: 2.5910213373561284

Epoch: 71| Step: 0
Training loss: 3.135548754641971
Validation loss: 2.6064393952918024

Epoch: 6| Step: 1
Training loss: 2.771000696926243
Validation loss: 2.6165721245151

Epoch: 6| Step: 2
Training loss: 3.200106952787257
Validation loss: 2.6550105601097376

Epoch: 6| Step: 3
Training loss: 2.93982166501969
Validation loss: 2.63846690864997

Epoch: 6| Step: 4
Training loss: 3.178099889665428
Validation loss: 2.6065330657960626

Epoch: 6| Step: 5
Training loss: 2.889201540615913
Validation loss: 2.594227423318933

Epoch: 6| Step: 6
Training loss: 3.0210596635590785
Validation loss: 2.591216325391044

Epoch: 6| Step: 7
Training loss: 2.3591730902972996
Validation loss: 2.591487156403229

Epoch: 6| Step: 8
Training loss: 3.6305919792944494
Validation loss: 2.5965185609631667

Epoch: 6| Step: 9
Training loss: 2.17128235120286
Validation loss: 2.592299370885129

Epoch: 6| Step: 10
Training loss: 2.578220804919722
Validation loss: 2.5928922990212224

Epoch: 6| Step: 11
Training loss: 2.9032188112933475
Validation loss: 2.5901277534536593

Epoch: 6| Step: 12
Training loss: 3.4157783159781094
Validation loss: 2.5910696053800377

Epoch: 6| Step: 13
Training loss: 3.0000181197572906
Validation loss: 2.5905385680680846

Epoch: 72| Step: 0
Training loss: 2.8022255465546357
Validation loss: 2.589976343327266

Epoch: 6| Step: 1
Training loss: 2.610764367728591
Validation loss: 2.589871001317914

Epoch: 6| Step: 2
Training loss: 3.2219583761414254
Validation loss: 2.585064901781733

Epoch: 6| Step: 3
Training loss: 2.810593276605102
Validation loss: 2.5830670790819843

Epoch: 6| Step: 4
Training loss: 2.8135640992380537
Validation loss: 2.5843428572048985

Epoch: 6| Step: 5
Training loss: 3.0926787708514594
Validation loss: 2.5846556601373862

Epoch: 6| Step: 6
Training loss: 2.3704811071428704
Validation loss: 2.5868334550094705

Epoch: 6| Step: 7
Training loss: 3.199255713690613
Validation loss: 2.5898163518912

Epoch: 6| Step: 8
Training loss: 3.23440743397838
Validation loss: 2.6104364582476207

Epoch: 6| Step: 9
Training loss: 3.472984135427578
Validation loss: 2.6195321235943867

Epoch: 6| Step: 10
Training loss: 2.882514090458094
Validation loss: 2.6407985039252337

Epoch: 6| Step: 11
Training loss: 2.9733420745082486
Validation loss: 2.634241233939412

Epoch: 6| Step: 12
Training loss: 3.0553138656589747
Validation loss: 2.617597979437444

Epoch: 6| Step: 13
Training loss: 2.6671579226355053
Validation loss: 2.6055268149601165

Epoch: 73| Step: 0
Training loss: 2.1315789201028785
Validation loss: 2.587179576343599

Epoch: 6| Step: 1
Training loss: 2.951849768064536
Validation loss: 2.5841364308531976

Epoch: 6| Step: 2
Training loss: 2.6154560795682253
Validation loss: 2.5829679384210276

Epoch: 6| Step: 3
Training loss: 2.850075028084427
Validation loss: 2.581623854137742

Epoch: 6| Step: 4
Training loss: 2.665852323009146
Validation loss: 2.5790565764095716

Epoch: 6| Step: 5
Training loss: 3.093336135462884
Validation loss: 2.579841007379265

Epoch: 6| Step: 6
Training loss: 3.2431547996988317
Validation loss: 2.576003965254822

Epoch: 6| Step: 7
Training loss: 2.7461871677967054
Validation loss: 2.5774134285687595

Epoch: 6| Step: 8
Training loss: 3.1720707273932214
Validation loss: 2.578951719799459

Epoch: 6| Step: 9
Training loss: 2.60865463089825
Validation loss: 2.5746348104860775

Epoch: 6| Step: 10
Training loss: 3.2334463656878976
Validation loss: 2.5785632315707883

Epoch: 6| Step: 11
Training loss: 3.6332752876428036
Validation loss: 2.5779148546912265

Epoch: 6| Step: 12
Training loss: 2.99111194054471
Validation loss: 2.5784013447799623

Epoch: 6| Step: 13
Training loss: 3.1608929618228254
Validation loss: 2.574793511484558

Epoch: 74| Step: 0
Training loss: 2.9851667542261535
Validation loss: 2.5755539987598377

Epoch: 6| Step: 1
Training loss: 3.0755620055170847
Validation loss: 2.572720581995007

Epoch: 6| Step: 2
Training loss: 3.382660824941188
Validation loss: 2.5742018217934115

Epoch: 6| Step: 3
Training loss: 2.850073856936033
Validation loss: 2.574071332038657

Epoch: 6| Step: 4
Training loss: 2.9997250113023055
Validation loss: 2.572170834157311

Epoch: 6| Step: 5
Training loss: 2.8804960377339315
Validation loss: 2.578447652733775

Epoch: 6| Step: 6
Training loss: 3.034900787089355
Validation loss: 2.5964925405353307

Epoch: 6| Step: 7
Training loss: 2.842116672835026
Validation loss: 2.5977382052681772

Epoch: 6| Step: 8
Training loss: 3.0411950011323032
Validation loss: 2.6020161523490324

Epoch: 6| Step: 9
Training loss: 2.620798290444959
Validation loss: 2.5875758452394018

Epoch: 6| Step: 10
Training loss: 2.8799669234707617
Validation loss: 2.5746948732034696

Epoch: 6| Step: 11
Training loss: 2.590975000829907
Validation loss: 2.5666525909158793

Epoch: 6| Step: 12
Training loss: 3.100545952005951
Validation loss: 2.563162339132652

Epoch: 6| Step: 13
Training loss: 2.81709600671352
Validation loss: 2.5577543250460213

Epoch: 75| Step: 0
Training loss: 2.5909507997553582
Validation loss: 2.5585882461590104

Epoch: 6| Step: 1
Training loss: 2.9176486042686367
Validation loss: 2.5531248705088454

Epoch: 6| Step: 2
Training loss: 3.566459329467066
Validation loss: 2.5531024509483022

Epoch: 6| Step: 3
Training loss: 2.533581166525807
Validation loss: 2.549220653950057

Epoch: 6| Step: 4
Training loss: 2.9154823260137146
Validation loss: 2.551884550816562

Epoch: 6| Step: 5
Training loss: 3.27533239177512
Validation loss: 2.5526127627517208

Epoch: 6| Step: 6
Training loss: 3.022006541469116
Validation loss: 2.5630774418877174

Epoch: 6| Step: 7
Training loss: 2.938795250560889
Validation loss: 2.5824638233828163

Epoch: 6| Step: 8
Training loss: 3.064480822154152
Validation loss: 2.5838026704746957

Epoch: 6| Step: 9
Training loss: 2.6087733505951394
Validation loss: 2.570416440388472

Epoch: 6| Step: 10
Training loss: 3.0630100370486133
Validation loss: 2.5755051572634025

Epoch: 6| Step: 11
Training loss: 2.5673291362898856
Validation loss: 2.5691118475371457

Epoch: 6| Step: 12
Training loss: 2.7763338680730163
Validation loss: 2.554618805173117

Epoch: 6| Step: 13
Training loss: 3.0950981824643686
Validation loss: 2.548191296861447

Epoch: 76| Step: 0
Training loss: 2.8311848816109317
Validation loss: 2.5490093647824774

Epoch: 6| Step: 1
Training loss: 3.657864727574596
Validation loss: 2.548872062490791

Epoch: 6| Step: 2
Training loss: 3.0749194499064663
Validation loss: 2.549549670491393

Epoch: 6| Step: 3
Training loss: 1.446848532514945
Validation loss: 2.5506474754882125

Epoch: 6| Step: 4
Training loss: 2.816915648551999
Validation loss: 2.547156090861137

Epoch: 6| Step: 5
Training loss: 3.267523546783432
Validation loss: 2.5462767155419463

Epoch: 6| Step: 6
Training loss: 3.1502142878714263
Validation loss: 2.551128650042683

Epoch: 6| Step: 7
Training loss: 2.7084817014304607
Validation loss: 2.5498917046540814

Epoch: 6| Step: 8
Training loss: 2.3459137147871747
Validation loss: 2.5551285664171295

Epoch: 6| Step: 9
Training loss: 2.7193338052360025
Validation loss: 2.5591689508348265

Epoch: 6| Step: 10
Training loss: 2.7986206914855023
Validation loss: 2.5663705392754386

Epoch: 6| Step: 11
Training loss: 3.165652932649161
Validation loss: 2.5574789875648354

Epoch: 6| Step: 12
Training loss: 3.5178989770295352
Validation loss: 2.5573020115988077

Epoch: 6| Step: 13
Training loss: 2.6264853135385864
Validation loss: 2.562006094670336

Epoch: 77| Step: 0
Training loss: 2.9911313894805325
Validation loss: 2.551786976513283

Epoch: 6| Step: 1
Training loss: 3.12758590519275
Validation loss: 2.5584948273483574

Epoch: 6| Step: 2
Training loss: 2.908262970810111
Validation loss: 2.5492958367362264

Epoch: 6| Step: 3
Training loss: 2.7461442793515305
Validation loss: 2.5530193866558415

Epoch: 6| Step: 4
Training loss: 2.6402276998639542
Validation loss: 2.547418363895144

Epoch: 6| Step: 5
Training loss: 2.7020763502028284
Validation loss: 2.548908757620788

Epoch: 6| Step: 6
Training loss: 3.1800617869390524
Validation loss: 2.547776282758241

Epoch: 6| Step: 7
Training loss: 2.8849461214267342
Validation loss: 2.5449627863935014

Epoch: 6| Step: 8
Training loss: 2.954141754633607
Validation loss: 2.5459977317632854

Epoch: 6| Step: 9
Training loss: 3.2156210199596513
Validation loss: 2.5433066644991866

Epoch: 6| Step: 10
Training loss: 2.698222924797782
Validation loss: 2.543550913165571

Epoch: 6| Step: 11
Training loss: 3.3810692363375527
Validation loss: 2.5433035739843564

Epoch: 6| Step: 12
Training loss: 2.4914947790695567
Validation loss: 2.543118458803874

Epoch: 6| Step: 13
Training loss: 2.6748032613404376
Validation loss: 2.5403628317630433

Epoch: 78| Step: 0
Training loss: 2.3762092523427287
Validation loss: 2.5434546681441215

Epoch: 6| Step: 1
Training loss: 3.156677821407193
Validation loss: 2.5432180702674847

Epoch: 6| Step: 2
Training loss: 2.7305738786315668
Validation loss: 2.5439721787608858

Epoch: 6| Step: 3
Training loss: 3.012297222229857
Validation loss: 2.5419302194672104

Epoch: 6| Step: 4
Training loss: 3.1947683603195136
Validation loss: 2.5464358222581347

Epoch: 6| Step: 5
Training loss: 3.110244399399993
Validation loss: 2.549973855416418

Epoch: 6| Step: 6
Training loss: 2.9578693366295346
Validation loss: 2.543584273372557

Epoch: 6| Step: 7
Training loss: 2.929957018852703
Validation loss: 2.541804706476933

Epoch: 6| Step: 8
Training loss: 2.4981119655930475
Validation loss: 2.541781455328752

Epoch: 6| Step: 9
Training loss: 3.092474318006819
Validation loss: 2.5420992695086455

Epoch: 6| Step: 10
Training loss: 3.039676555191467
Validation loss: 2.5421107902877935

Epoch: 6| Step: 11
Training loss: 3.0921723938390326
Validation loss: 2.5420971396109837

Epoch: 6| Step: 12
Training loss: 2.6322850454589592
Validation loss: 2.545819042803398

Epoch: 6| Step: 13
Training loss: 2.8953177635774976
Validation loss: 2.5477027999780555

Epoch: 79| Step: 0
Training loss: 2.795268273896618
Validation loss: 2.5504882656298635

Epoch: 6| Step: 1
Training loss: 3.0094964403979723
Validation loss: 2.5533598315252144

Epoch: 6| Step: 2
Training loss: 3.0669010224840756
Validation loss: 2.5399992436072054

Epoch: 6| Step: 3
Training loss: 2.1594998843879076
Validation loss: 2.5434011824426674

Epoch: 6| Step: 4
Training loss: 3.0502627587871904
Validation loss: 2.53875787540457

Epoch: 6| Step: 5
Training loss: 3.016572635372392
Validation loss: 2.53888637742785

Epoch: 6| Step: 6
Training loss: 2.4795432459234386
Validation loss: 2.536635483369296

Epoch: 6| Step: 7
Training loss: 3.208099967759298
Validation loss: 2.5377394118683263

Epoch: 6| Step: 8
Training loss: 2.8524924238206317
Validation loss: 2.5353246818989965

Epoch: 6| Step: 9
Training loss: 3.3978670891178275
Validation loss: 2.539793031667531

Epoch: 6| Step: 10
Training loss: 2.616367860810298
Validation loss: 2.5381948993298775

Epoch: 6| Step: 11
Training loss: 3.0043946502849197
Validation loss: 2.537440269086863

Epoch: 6| Step: 12
Training loss: 2.8863120405518474
Validation loss: 2.5450633782997976

Epoch: 6| Step: 13
Training loss: 3.179384859196153
Validation loss: 2.5385290113284262

Epoch: 80| Step: 0
Training loss: 2.647412126936158
Validation loss: 2.5458255580872455

Epoch: 6| Step: 1
Training loss: 2.698998625815382
Validation loss: 2.5489344772890123

Epoch: 6| Step: 2
Training loss: 3.1755489625707365
Validation loss: 2.5622572965258885

Epoch: 6| Step: 3
Training loss: 3.265986518378853
Validation loss: 2.552166962315461

Epoch: 6| Step: 4
Training loss: 2.968760600824001
Validation loss: 2.5459626933907353

Epoch: 6| Step: 5
Training loss: 3.1592909261231052
Validation loss: 2.5359393564201187

Epoch: 6| Step: 6
Training loss: 2.797352584895657
Validation loss: 2.534397940336312

Epoch: 6| Step: 7
Training loss: 2.623518480297248
Validation loss: 2.532975081348037

Epoch: 6| Step: 8
Training loss: 3.1064227480220254
Validation loss: 2.539226254719259

Epoch: 6| Step: 9
Training loss: 3.0673231175542806
Validation loss: 2.541777690222369

Epoch: 6| Step: 10
Training loss: 3.2371805158595564
Validation loss: 2.54738041397376

Epoch: 6| Step: 11
Training loss: 2.4514230059974342
Validation loss: 2.5500705445432588

Epoch: 6| Step: 12
Training loss: 2.943056411186967
Validation loss: 2.5572516906860434

Epoch: 6| Step: 13
Training loss: 2.6926921103681747
Validation loss: 2.5602383270816094

Epoch: 81| Step: 0
Training loss: 2.398811037878302
Validation loss: 2.552580184906391

Epoch: 6| Step: 1
Training loss: 2.7172136898873505
Validation loss: 2.5481256559474335

Epoch: 6| Step: 2
Training loss: 3.0826305585130243
Validation loss: 2.5434421455110026

Epoch: 6| Step: 3
Training loss: 3.0238207197178735
Validation loss: 2.5405932379929905

Epoch: 6| Step: 4
Training loss: 3.192293190945275
Validation loss: 2.5407700812327794

Epoch: 6| Step: 5
Training loss: 2.9009368895826237
Validation loss: 2.538901459009738

Epoch: 6| Step: 6
Training loss: 2.9898554626028093
Validation loss: 2.5385126676854752

Epoch: 6| Step: 7
Training loss: 2.790641444586031
Validation loss: 2.5373559034835695

Epoch: 6| Step: 8
Training loss: 3.0971771677918922
Validation loss: 2.538121604787977

Epoch: 6| Step: 9
Training loss: 2.7992947303282754
Validation loss: 2.5465477942666355

Epoch: 6| Step: 10
Training loss: 2.5171672761034833
Validation loss: 2.5544028621429153

Epoch: 6| Step: 11
Training loss: 2.7734114524800164
Validation loss: 2.573274002147827

Epoch: 6| Step: 12
Training loss: 3.4971476239796124
Validation loss: 2.5967444490639875

Epoch: 6| Step: 13
Training loss: 2.6228189944583766
Validation loss: 2.599592683138091

Epoch: 82| Step: 0
Training loss: 2.740631618513513
Validation loss: 2.643939155012617

Epoch: 6| Step: 1
Training loss: 3.4036037420089293
Validation loss: 2.6769855928795288

Epoch: 6| Step: 2
Training loss: 2.3908649398967805
Validation loss: 2.5952834404839096

Epoch: 6| Step: 3
Training loss: 2.9457627010555645
Validation loss: 2.5675164836437445

Epoch: 6| Step: 4
Training loss: 3.0987243734995085
Validation loss: 2.546694324556418

Epoch: 6| Step: 5
Training loss: 2.3497244409558524
Validation loss: 2.5316175879826193

Epoch: 6| Step: 6
Training loss: 3.1127673482401508
Validation loss: 2.532598673225902

Epoch: 6| Step: 7
Training loss: 2.5839002253871683
Validation loss: 2.5307558003390267

Epoch: 6| Step: 8
Training loss: 3.2159628050252174
Validation loss: 2.534616954713628

Epoch: 6| Step: 9
Training loss: 2.857490627376908
Validation loss: 2.533670564181903

Epoch: 6| Step: 10
Training loss: 2.811800043107951
Validation loss: 2.5339568449437873

Epoch: 6| Step: 11
Training loss: 3.1652129165842875
Validation loss: 2.5359405614406185

Epoch: 6| Step: 12
Training loss: 2.7914134997303877
Validation loss: 2.5352830315234423

Epoch: 6| Step: 13
Training loss: 3.3139347352143576
Validation loss: 2.5353312929104943

Epoch: 83| Step: 0
Training loss: 2.9969415969529463
Validation loss: 2.535073762157777

Epoch: 6| Step: 1
Training loss: 3.00778459808487
Validation loss: 2.533725234721294

Epoch: 6| Step: 2
Training loss: 2.2437761905597347
Validation loss: 2.5352810470717446

Epoch: 6| Step: 3
Training loss: 2.8493130106875824
Validation loss: 2.5297859532754066

Epoch: 6| Step: 4
Training loss: 3.0520727962446537
Validation loss: 2.528864399877324

Epoch: 6| Step: 5
Training loss: 3.3481574556886504
Validation loss: 2.533314293467091

Epoch: 6| Step: 6
Training loss: 2.6550714009772145
Validation loss: 2.5617545739658674

Epoch: 6| Step: 7
Training loss: 2.812379283433641
Validation loss: 2.6019991044843636

Epoch: 6| Step: 8
Training loss: 2.4308702343884065
Validation loss: 2.6558699778158226

Epoch: 6| Step: 9
Training loss: 2.7949303201032003
Validation loss: 2.681500563944573

Epoch: 6| Step: 10
Training loss: 2.7752415766683103
Validation loss: 2.7331999829756097

Epoch: 6| Step: 11
Training loss: 3.1342421620479306
Validation loss: 2.6913185731039855

Epoch: 6| Step: 12
Training loss: 3.642844902680507
Validation loss: 2.6663400385256346

Epoch: 6| Step: 13
Training loss: 3.592163133642281
Validation loss: 2.6157626004465766

Epoch: 84| Step: 0
Training loss: 2.639075100892939
Validation loss: 2.5862695406256426

Epoch: 6| Step: 1
Training loss: 2.7470940928916496
Validation loss: 2.573597126582883

Epoch: 6| Step: 2
Training loss: 3.215019508646721
Validation loss: 2.5752736731204355

Epoch: 6| Step: 3
Training loss: 3.0001405047256875
Validation loss: 2.5651858360757043

Epoch: 6| Step: 4
Training loss: 2.3164424796913803
Validation loss: 2.5744762216890518

Epoch: 6| Step: 5
Training loss: 2.4998846027444097
Validation loss: 2.5632001479078013

Epoch: 6| Step: 6
Training loss: 3.0297536401085448
Validation loss: 2.5387499444139086

Epoch: 6| Step: 7
Training loss: 3.4951219625299177
Validation loss: 2.5327980961917365

Epoch: 6| Step: 8
Training loss: 3.277706012550838
Validation loss: 2.5343426935572553

Epoch: 6| Step: 9
Training loss: 2.5993824665597973
Validation loss: 2.534212389092904

Epoch: 6| Step: 10
Training loss: 2.850026843295923
Validation loss: 2.537657135283245

Epoch: 6| Step: 11
Training loss: 2.667887785592046
Validation loss: 2.537463626694837

Epoch: 6| Step: 12
Training loss: 3.252200188859906
Validation loss: 2.5379091653177235

Epoch: 6| Step: 13
Training loss: 3.2233783814504995
Validation loss: 2.532251475657203

Epoch: 85| Step: 0
Training loss: 3.0823971297895514
Validation loss: 2.526690118337594

Epoch: 6| Step: 1
Training loss: 3.348786455947746
Validation loss: 2.528431355986508

Epoch: 6| Step: 2
Training loss: 2.6274542461734445
Validation loss: 2.5281097082689663

Epoch: 6| Step: 3
Training loss: 2.7294652838566766
Validation loss: 2.526054930496195

Epoch: 6| Step: 4
Training loss: 2.9934696010449766
Validation loss: 2.5267396538288343

Epoch: 6| Step: 5
Training loss: 2.6682903492515457
Validation loss: 2.5231165416239367

Epoch: 6| Step: 6
Training loss: 3.2537191092174833
Validation loss: 2.524373487333412

Epoch: 6| Step: 7
Training loss: 2.4713768805587906
Validation loss: 2.5234779413847557

Epoch: 6| Step: 8
Training loss: 3.5227395188910213
Validation loss: 2.526985364811786

Epoch: 6| Step: 9
Training loss: 2.5719636292325783
Validation loss: 2.541116011984193

Epoch: 6| Step: 10
Training loss: 2.716860147228935
Validation loss: 2.5416456467438278

Epoch: 6| Step: 11
Training loss: 2.400863563623567
Validation loss: 2.5417553364903855

Epoch: 6| Step: 12
Training loss: 2.498446744957782
Validation loss: 2.553600306608508

Epoch: 6| Step: 13
Training loss: 3.727917822607448
Validation loss: 2.5477490873228645

Epoch: 86| Step: 0
Training loss: 2.5092118301642996
Validation loss: 2.5514063362660835

Epoch: 6| Step: 1
Training loss: 2.759991182368471
Validation loss: 2.558075094488873

Epoch: 6| Step: 2
Training loss: 2.683787598473147
Validation loss: 2.5503924673614637

Epoch: 6| Step: 3
Training loss: 2.4253635016073773
Validation loss: 2.549769813045642

Epoch: 6| Step: 4
Training loss: 3.108255922991622
Validation loss: 2.548769525748487

Epoch: 6| Step: 5
Training loss: 2.5921492635287886
Validation loss: 2.546516477272136

Epoch: 6| Step: 6
Training loss: 3.0770920312784797
Validation loss: 2.5335269345659044

Epoch: 6| Step: 7
Training loss: 2.8542685014884053
Validation loss: 2.5302353525200716

Epoch: 6| Step: 8
Training loss: 3.2343546548839286
Validation loss: 2.5344475112984504

Epoch: 6| Step: 9
Training loss: 2.9408657190303953
Validation loss: 2.524303128688272

Epoch: 6| Step: 10
Training loss: 3.0363968089933566
Validation loss: 2.5225920319146113

Epoch: 6| Step: 11
Training loss: 2.9373592586484336
Validation loss: 2.5131481045125668

Epoch: 6| Step: 12
Training loss: 2.9720103781558724
Validation loss: 2.515841411132005

Epoch: 6| Step: 13
Training loss: 3.39130700631181
Validation loss: 2.5119916832384326

Epoch: 87| Step: 0
Training loss: 3.3863678676725417
Validation loss: 2.5174535842750054

Epoch: 6| Step: 1
Training loss: 2.549392111632689
Validation loss: 2.513953631321701

Epoch: 6| Step: 2
Training loss: 3.112445331384462
Validation loss: 2.5140807601063777

Epoch: 6| Step: 3
Training loss: 2.645622355141907
Validation loss: 2.5126326117274376

Epoch: 6| Step: 4
Training loss: 2.857497636021448
Validation loss: 2.511144907641011

Epoch: 6| Step: 5
Training loss: 2.7554278992322465
Validation loss: 2.512728000883525

Epoch: 6| Step: 6
Training loss: 2.7271678875510483
Validation loss: 2.5129154812964956

Epoch: 6| Step: 7
Training loss: 3.6518504742933655
Validation loss: 2.5133047030371287

Epoch: 6| Step: 8
Training loss: 2.5825723839925168
Validation loss: 2.514038440644262

Epoch: 6| Step: 9
Training loss: 2.6097875942749527
Validation loss: 2.517541944161272

Epoch: 6| Step: 10
Training loss: 2.8652167342461374
Validation loss: 2.515394418969493

Epoch: 6| Step: 11
Training loss: 2.3162938520106433
Validation loss: 2.524549076814966

Epoch: 6| Step: 12
Training loss: 2.888979221627107
Validation loss: 2.5372173299589225

Epoch: 6| Step: 13
Training loss: 3.3653858436330713
Validation loss: 2.5633599723870706

Epoch: 88| Step: 0
Training loss: 2.8663779630848234
Validation loss: 2.636493195639997

Epoch: 6| Step: 1
Training loss: 2.8645220015924857
Validation loss: 2.6596750442117774

Epoch: 6| Step: 2
Training loss: 2.8073101904168882
Validation loss: 2.6629096064335815

Epoch: 6| Step: 3
Training loss: 2.72061005903506
Validation loss: 2.6238977478544485

Epoch: 6| Step: 4
Training loss: 2.8218526676684137
Validation loss: 2.593688088389918

Epoch: 6| Step: 5
Training loss: 2.742848547570067
Validation loss: 2.5504739280329014

Epoch: 6| Step: 6
Training loss: 3.2020995941113246
Validation loss: 2.5351118695081136

Epoch: 6| Step: 7
Training loss: 2.67086344526895
Validation loss: 2.5150958140085775

Epoch: 6| Step: 8
Training loss: 3.218691630899011
Validation loss: 2.510188488620966

Epoch: 6| Step: 9
Training loss: 2.719394826604152
Validation loss: 2.512204292807941

Epoch: 6| Step: 10
Training loss: 2.3602615610750077
Validation loss: 2.513313091731653

Epoch: 6| Step: 11
Training loss: 2.5287836563050443
Validation loss: 2.520775390490617

Epoch: 6| Step: 12
Training loss: 3.546229904596554
Validation loss: 2.5203446491111112

Epoch: 6| Step: 13
Training loss: 3.090200680879465
Validation loss: 2.524776610251056

Epoch: 89| Step: 0
Training loss: 2.7560348184542636
Validation loss: 2.5252551166074277

Epoch: 6| Step: 1
Training loss: 2.9596424340454277
Validation loss: 2.527757557427446

Epoch: 6| Step: 2
Training loss: 3.161372494147586
Validation loss: 2.5282611203015843

Epoch: 6| Step: 3
Training loss: 2.9930786718039855
Validation loss: 2.52545000832281

Epoch: 6| Step: 4
Training loss: 2.483866513595455
Validation loss: 2.5219353074311526

Epoch: 6| Step: 5
Training loss: 2.939247423242736
Validation loss: 2.5191453344835066

Epoch: 6| Step: 6
Training loss: 2.7871035580484147
Validation loss: 2.5195448163840526

Epoch: 6| Step: 7
Training loss: 3.0933644988967384
Validation loss: 2.5116037013163166

Epoch: 6| Step: 8
Training loss: 2.533005282427027
Validation loss: 2.515363539652852

Epoch: 6| Step: 9
Training loss: 2.6034372350820596
Validation loss: 2.5156837802491614

Epoch: 6| Step: 10
Training loss: 2.7154708906371927
Validation loss: 2.5255562168136634

Epoch: 6| Step: 11
Training loss: 2.4289144285793776
Validation loss: 2.5546656947556783

Epoch: 6| Step: 12
Training loss: 3.475902434706087
Validation loss: 2.583269028817635

Epoch: 6| Step: 13
Training loss: 3.72611526588623
Validation loss: 2.638942322426618

Epoch: 90| Step: 0
Training loss: 2.7031875338515023
Validation loss: 2.667308868159919

Epoch: 6| Step: 1
Training loss: 3.064850819677036
Validation loss: 2.6504574885593453

Epoch: 6| Step: 2
Training loss: 3.2617360006093223
Validation loss: 2.6274444519505002

Epoch: 6| Step: 3
Training loss: 3.1582982432916467
Validation loss: 2.6347149757008554

Epoch: 6| Step: 4
Training loss: 2.9551081381696283
Validation loss: 2.6248050271563614

Epoch: 6| Step: 5
Training loss: 2.3751686437863273
Validation loss: 2.591671627522521

Epoch: 6| Step: 6
Training loss: 3.547110932019225
Validation loss: 2.584343521837689

Epoch: 6| Step: 7
Training loss: 2.8923803000381585
Validation loss: 2.578590331681571

Epoch: 6| Step: 8
Training loss: 3.0569317078853437
Validation loss: 2.578322019286194

Epoch: 6| Step: 9
Training loss: 2.815073319559302
Validation loss: 2.577477502539792

Epoch: 6| Step: 10
Training loss: 2.523222734033929
Validation loss: 2.5733643739656906

Epoch: 6| Step: 11
Training loss: 2.851628885410909
Validation loss: 2.5740040987095933

Epoch: 6| Step: 12
Training loss: 2.4432820918533116
Validation loss: 2.573789982329

Epoch: 6| Step: 13
Training loss: 3.1354187282078114
Validation loss: 2.5771976338129816

Epoch: 91| Step: 0
Training loss: 2.2382530223937236
Validation loss: 2.5754055821628796

Epoch: 6| Step: 1
Training loss: 3.4624507859240814
Validation loss: 2.5701597719248412

Epoch: 6| Step: 2
Training loss: 3.1543458539154012
Validation loss: 2.566905209174828

Epoch: 6| Step: 3
Training loss: 2.4024862603817825
Validation loss: 2.5604165939685757

Epoch: 6| Step: 4
Training loss: 2.494767052854886
Validation loss: 2.5570028063509316

Epoch: 6| Step: 5
Training loss: 2.6123948582568404
Validation loss: 2.5592728369354836

Epoch: 6| Step: 6
Training loss: 2.4984761362148054
Validation loss: 2.560760994454128

Epoch: 6| Step: 7
Training loss: 3.0623172004794896
Validation loss: 2.5619328098975394

Epoch: 6| Step: 8
Training loss: 3.0649267429975233
Validation loss: 2.5654101170826347

Epoch: 6| Step: 9
Training loss: 2.8473204949846562
Validation loss: 2.5749311753945654

Epoch: 6| Step: 10
Training loss: 3.1749096714897482
Validation loss: 2.5920246888187215

Epoch: 6| Step: 11
Training loss: 2.7489295957006865
Validation loss: 2.5980603227248156

Epoch: 6| Step: 12
Training loss: 3.6957421728429436
Validation loss: 2.611406013967337

Epoch: 6| Step: 13
Training loss: 2.7297571043454334
Validation loss: 2.61183000614556

Epoch: 92| Step: 0
Training loss: 3.6008265606046153
Validation loss: 2.600695935923817

Epoch: 6| Step: 1
Training loss: 2.9034508792222815
Validation loss: 2.5719184036608524

Epoch: 6| Step: 2
Training loss: 2.914690619878366
Validation loss: 2.5571151337303646

Epoch: 6| Step: 3
Training loss: 3.1187513821585426
Validation loss: 2.555696557399469

Epoch: 6| Step: 4
Training loss: 2.512818755621323
Validation loss: 2.55514428505963

Epoch: 6| Step: 5
Training loss: 2.2019037419483514
Validation loss: 2.5541480211875736

Epoch: 6| Step: 6
Training loss: 2.5406468539453497
Validation loss: 2.555906950722207

Epoch: 6| Step: 7
Training loss: 3.146638341980948
Validation loss: 2.5612923682565687

Epoch: 6| Step: 8
Training loss: 2.744756381093363
Validation loss: 2.560559940734224

Epoch: 6| Step: 9
Training loss: 2.5505081194097956
Validation loss: 2.5614608070111946

Epoch: 6| Step: 10
Training loss: 2.539462295748035
Validation loss: 2.5605937231074942

Epoch: 6| Step: 11
Training loss: 3.53083569282079
Validation loss: 2.559215358362103

Epoch: 6| Step: 12
Training loss: 3.0742767599950884
Validation loss: 2.5579855695714153

Epoch: 6| Step: 13
Training loss: 3.3532993466858705
Validation loss: 2.5545436877231964

Epoch: 93| Step: 0
Training loss: 3.6576535392026672
Validation loss: 2.554848749067343

Epoch: 6| Step: 1
Training loss: 2.818370626087426
Validation loss: 2.5593619442032467

Epoch: 6| Step: 2
Training loss: 2.7329601878264946
Validation loss: 2.590029270076251

Epoch: 6| Step: 3
Training loss: 2.8479368806766696
Validation loss: 2.61845120938788

Epoch: 6| Step: 4
Training loss: 2.8059759979037184
Validation loss: 2.6753327283225996

Epoch: 6| Step: 5
Training loss: 2.78332168058899
Validation loss: 2.756783186276013

Epoch: 6| Step: 6
Training loss: 2.616194169295834
Validation loss: 2.802569736457103

Epoch: 6| Step: 7
Training loss: 2.445875011741009
Validation loss: 2.8117868437651734

Epoch: 6| Step: 8
Training loss: 2.8469177041896927
Validation loss: 2.7938213331849036

Epoch: 6| Step: 9
Training loss: 3.636566126127403
Validation loss: 2.725647489517199

Epoch: 6| Step: 10
Training loss: 3.2472788349398245
Validation loss: 2.6541669559451235

Epoch: 6| Step: 11
Training loss: 3.4332079361419527
Validation loss: 2.6048035588952154

Epoch: 6| Step: 12
Training loss: 2.270831630134527
Validation loss: 2.608984029943083

Epoch: 6| Step: 13
Training loss: 2.742821948785013
Validation loss: 2.6127322987497683

Epoch: 94| Step: 0
Training loss: 2.9405650928325913
Validation loss: 2.632892961727992

Epoch: 6| Step: 1
Training loss: 2.5744978850343587
Validation loss: 2.6614112102513356

Epoch: 6| Step: 2
Training loss: 2.975448119449513
Validation loss: 2.673989751076679

Epoch: 6| Step: 3
Training loss: 3.210522998498712
Validation loss: 2.7474068695921336

Epoch: 6| Step: 4
Training loss: 2.7017531248829787
Validation loss: 2.718555942804922

Epoch: 6| Step: 5
Training loss: 3.0408685412206413
Validation loss: 2.831068819362616

Epoch: 6| Step: 6
Training loss: 2.9967907588443543
Validation loss: 2.7947725317877343

Epoch: 6| Step: 7
Training loss: 3.1940475235701653
Validation loss: 2.6858657987026153

Epoch: 6| Step: 8
Training loss: 3.5786417625439997
Validation loss: 2.629435749233432

Epoch: 6| Step: 9
Training loss: 3.0386620578884354
Validation loss: 2.5898494942809474

Epoch: 6| Step: 10
Training loss: 3.611413685438577
Validation loss: 2.553094909436828

Epoch: 6| Step: 11
Training loss: 3.0386614301948014
Validation loss: 2.5435284077049167

Epoch: 6| Step: 12
Training loss: 2.721159820674508
Validation loss: 2.5349790813730735

Epoch: 6| Step: 13
Training loss: 2.477088848222305
Validation loss: 2.529270584667279

Epoch: 95| Step: 0
Training loss: 2.6928480297771373
Validation loss: 2.5619088368152547

Epoch: 6| Step: 1
Training loss: 2.515755217599751
Validation loss: 2.643354443698565

Epoch: 6| Step: 2
Training loss: 3.0914297940252045
Validation loss: 2.7218967379469388

Epoch: 6| Step: 3
Training loss: 2.408821218454285
Validation loss: 2.880384602274853

Epoch: 6| Step: 4
Training loss: 3.4012501269603006
Validation loss: 2.9250919535483164

Epoch: 6| Step: 5
Training loss: 2.7495279774009833
Validation loss: 2.9466783360610407

Epoch: 6| Step: 6
Training loss: 2.9074681508098474
Validation loss: 2.9217330242709134

Epoch: 6| Step: 7
Training loss: 2.4576538461550586
Validation loss: 2.847032430589143

Epoch: 6| Step: 8
Training loss: 3.9098106330615767
Validation loss: 2.748958828698215

Epoch: 6| Step: 9
Training loss: 3.479962073371561
Validation loss: 2.5628692106856588

Epoch: 6| Step: 10
Training loss: 3.287659406967319
Validation loss: 2.491610170821984

Epoch: 6| Step: 11
Training loss: 2.9740315888708313
Validation loss: 2.4922873181630214

Epoch: 6| Step: 12
Training loss: 2.5973964934153484
Validation loss: 2.518642746656528

Epoch: 6| Step: 13
Training loss: 3.2471444716625455
Validation loss: 2.540905751978307

Epoch: 96| Step: 0
Training loss: 3.1019409871197166
Validation loss: 2.5611687480412626

Epoch: 6| Step: 1
Training loss: 2.7527110867890845
Validation loss: 2.580523067516397

Epoch: 6| Step: 2
Training loss: 2.3111095887977933
Validation loss: 2.5925033742310526

Epoch: 6| Step: 3
Training loss: 3.281163677714974
Validation loss: 2.611014482034855

Epoch: 6| Step: 4
Training loss: 3.161826014413564
Validation loss: 2.5972876576625237

Epoch: 6| Step: 5
Training loss: 2.89382180439987
Validation loss: 2.575444126984916

Epoch: 6| Step: 6
Training loss: 3.313599026297551
Validation loss: 2.561175546587473

Epoch: 6| Step: 7
Training loss: 2.548412584361935
Validation loss: 2.5420972001194646

Epoch: 6| Step: 8
Training loss: 3.083923455204989
Validation loss: 2.543974738397344

Epoch: 6| Step: 9
Training loss: 3.269427408371882
Validation loss: 2.5293669913534753

Epoch: 6| Step: 10
Training loss: 3.267269906637997
Validation loss: 2.525951022995705

Epoch: 6| Step: 11
Training loss: 2.8635158885037426
Validation loss: 2.5216960642578528

Epoch: 6| Step: 12
Training loss: 2.9008803445465423
Validation loss: 2.5191161350227884

Epoch: 6| Step: 13
Training loss: 2.474286595032578
Validation loss: 2.5160367834146893

Epoch: 97| Step: 0
Training loss: 2.2292840754407393
Validation loss: 2.511219985921308

Epoch: 6| Step: 1
Training loss: 3.0864220347454916
Validation loss: 2.5016875303811696

Epoch: 6| Step: 2
Training loss: 3.218838736783116
Validation loss: 2.4919042213798783

Epoch: 6| Step: 3
Training loss: 2.8491992093109912
Validation loss: 2.4961653433440465

Epoch: 6| Step: 4
Training loss: 2.4756894663694844
Validation loss: 2.53829573318593

Epoch: 6| Step: 5
Training loss: 2.9526332869714014
Validation loss: 2.5593713428723053

Epoch: 6| Step: 6
Training loss: 3.2732535153490065
Validation loss: 2.629477394091645

Epoch: 6| Step: 7
Training loss: 2.8999282828046207
Validation loss: 2.67101841410192

Epoch: 6| Step: 8
Training loss: 2.8451737413502953
Validation loss: 2.675690478006876

Epoch: 6| Step: 9
Training loss: 2.738374411920481
Validation loss: 2.65060191068328

Epoch: 6| Step: 10
Training loss: 3.2578373823427773
Validation loss: 2.579292784139757

Epoch: 6| Step: 11
Training loss: 2.870695789808971
Validation loss: 2.532664316226835

Epoch: 6| Step: 12
Training loss: 3.3902008213211676
Validation loss: 2.4904296283714404

Epoch: 6| Step: 13
Training loss: 1.4882697157525486
Validation loss: 2.498436372154346

Epoch: 98| Step: 0
Training loss: 3.2306556140218867
Validation loss: 2.515815696553268

Epoch: 6| Step: 1
Training loss: 2.8839377091409375
Validation loss: 2.5224162523338087

Epoch: 6| Step: 2
Training loss: 3.0260764736640233
Validation loss: 2.5352061651165334

Epoch: 6| Step: 3
Training loss: 2.990364176538569
Validation loss: 2.540015800235728

Epoch: 6| Step: 4
Training loss: 2.8806183691563003
Validation loss: 2.548320101343721

Epoch: 6| Step: 5
Training loss: 3.2277634720112314
Validation loss: 2.551419399573995

Epoch: 6| Step: 6
Training loss: 2.461943502526276
Validation loss: 2.5560939510221643

Epoch: 6| Step: 7
Training loss: 3.1768986048957517
Validation loss: 2.558043008631224

Epoch: 6| Step: 8
Training loss: 2.694849123721323
Validation loss: 2.555689911797806

Epoch: 6| Step: 9
Training loss: 3.1950364121823243
Validation loss: 2.549072964974087

Epoch: 6| Step: 10
Training loss: 3.2565357807711663
Validation loss: 2.5439560469455484

Epoch: 6| Step: 11
Training loss: 3.1141438934361845
Validation loss: 2.5339325292831703

Epoch: 6| Step: 12
Training loss: 2.3266251616433076
Validation loss: 2.5251616544908373

Epoch: 6| Step: 13
Training loss: 2.3389887959316726
Validation loss: 2.52166227011803

Epoch: 99| Step: 0
Training loss: 2.591512243284273
Validation loss: 2.5155961046423654

Epoch: 6| Step: 1
Training loss: 2.4987774720811915
Validation loss: 2.5098076620659735

Epoch: 6| Step: 2
Training loss: 2.8263728156688486
Validation loss: 2.503056610079754

Epoch: 6| Step: 3
Training loss: 2.638544741715483
Validation loss: 2.4912473664565353

Epoch: 6| Step: 4
Training loss: 2.8143561278338822
Validation loss: 2.4888491677978335

Epoch: 6| Step: 5
Training loss: 2.6680091419206327
Validation loss: 2.486076139407781

Epoch: 6| Step: 6
Training loss: 3.018147890687843
Validation loss: 2.49412521468168

Epoch: 6| Step: 7
Training loss: 3.005236823323216
Validation loss: 2.528594351399105

Epoch: 6| Step: 8
Training loss: 2.9276074973029016
Validation loss: 2.5612670329244884

Epoch: 6| Step: 9
Training loss: 3.039511522399579
Validation loss: 2.5273320178656546

Epoch: 6| Step: 10
Training loss: 3.035167090201443
Validation loss: 2.512986457679282

Epoch: 6| Step: 11
Training loss: 2.85680603358033
Validation loss: 2.4960526692745857

Epoch: 6| Step: 12
Training loss: 3.6009930141797537
Validation loss: 2.5036186439719152

Epoch: 6| Step: 13
Training loss: 2.9298995691474694
Validation loss: 2.538575574505766

Epoch: 100| Step: 0
Training loss: 2.9843986470349146
Validation loss: 2.525726620093259

Epoch: 6| Step: 1
Training loss: 3.010324355737369
Validation loss: 2.5252989231507064

Epoch: 6| Step: 2
Training loss: 2.935146606526945
Validation loss: 2.542516975313494

Epoch: 6| Step: 3
Training loss: 3.192130969532414
Validation loss: 2.553142502773773

Epoch: 6| Step: 4
Training loss: 2.6988129372831264
Validation loss: 2.545491080438267

Epoch: 6| Step: 5
Training loss: 2.888991105480241
Validation loss: 2.546158997517523

Epoch: 6| Step: 6
Training loss: 3.038225936484232
Validation loss: 2.5439566757738494

Epoch: 6| Step: 7
Training loss: 2.7610908884509957
Validation loss: 2.5291469967782314

Epoch: 6| Step: 8
Training loss: 2.8597611963836767
Validation loss: 2.5157012102448832

Epoch: 6| Step: 9
Training loss: 2.565317419388727
Validation loss: 2.5154426603909212

Epoch: 6| Step: 10
Training loss: 3.2717898644681216
Validation loss: 2.508573149745402

Epoch: 6| Step: 11
Training loss: 2.6697380934713304
Validation loss: 2.5103635170042287

Epoch: 6| Step: 12
Training loss: 2.4967956033814014
Validation loss: 2.507983352953788

Epoch: 6| Step: 13
Training loss: 2.7804606314034412
Validation loss: 2.5162622002349866

Epoch: 101| Step: 0
Training loss: 2.677036230561015
Validation loss: 2.5332065628140636

Epoch: 6| Step: 1
Training loss: 2.73833505792577
Validation loss: 2.535859936017081

Epoch: 6| Step: 2
Training loss: 2.4750270957619556
Validation loss: 2.546029401518044

Epoch: 6| Step: 3
Training loss: 2.464960304079905
Validation loss: 2.536557989383607

Epoch: 6| Step: 4
Training loss: 3.0286224617989745
Validation loss: 2.5375605394266434

Epoch: 6| Step: 5
Training loss: 3.0348580507268412
Validation loss: 2.524518654744896

Epoch: 6| Step: 6
Training loss: 3.651075826458793
Validation loss: 2.512932225549885

Epoch: 6| Step: 7
Training loss: 3.268014572008345
Validation loss: 2.534075373619321

Epoch: 6| Step: 8
Training loss: 3.321778743350525
Validation loss: 2.5310316519560945

Epoch: 6| Step: 9
Training loss: 2.892237198215628
Validation loss: 2.5242000062633116

Epoch: 6| Step: 10
Training loss: 2.006206419284253
Validation loss: 2.5058580194471727

Epoch: 6| Step: 11
Training loss: 3.005994529734372
Validation loss: 2.5006229065555803

Epoch: 6| Step: 12
Training loss: 2.8002254940241533
Validation loss: 2.4874471093516553

Epoch: 6| Step: 13
Training loss: 1.6510344383811566
Validation loss: 2.5043068181879877

Epoch: 102| Step: 0
Training loss: 3.264415462213185
Validation loss: 2.5173392274494963

Epoch: 6| Step: 1
Training loss: 2.2705883512261478
Validation loss: 2.550555616277456

Epoch: 6| Step: 2
Training loss: 2.715309158061479
Validation loss: 2.5652996859262047

Epoch: 6| Step: 3
Training loss: 3.2051453708286823
Validation loss: 2.576592325333844

Epoch: 6| Step: 4
Training loss: 2.9557238249653457
Validation loss: 2.5985453488352475

Epoch: 6| Step: 5
Training loss: 2.816547956354
Validation loss: 2.5787378283218945

Epoch: 6| Step: 6
Training loss: 2.8750063025364003
Validation loss: 2.583542295996163

Epoch: 6| Step: 7
Training loss: 2.721371669195859
Validation loss: 2.580136530849464

Epoch: 6| Step: 8
Training loss: 3.0706833477133113
Validation loss: 2.575689825965967

Epoch: 6| Step: 9
Training loss: 2.959585882808148
Validation loss: 2.589350947595866

Epoch: 6| Step: 10
Training loss: 2.7496549216420507
Validation loss: 2.585774656137128

Epoch: 6| Step: 11
Training loss: 2.6146180250645004
Validation loss: 2.5740263158012

Epoch: 6| Step: 12
Training loss: 3.02947537101056
Validation loss: 2.5657908100540245

Epoch: 6| Step: 13
Training loss: 2.8513770474262703
Validation loss: 2.540042072206409

Epoch: 103| Step: 0
Training loss: 2.9215766632033824
Validation loss: 2.5419549891114586

Epoch: 6| Step: 1
Training loss: 2.5055464254054565
Validation loss: 2.540161749050084

Epoch: 6| Step: 2
Training loss: 3.00657505490733
Validation loss: 2.5442035504220564

Epoch: 6| Step: 3
Training loss: 2.9316686010074218
Validation loss: 2.574952483463064

Epoch: 6| Step: 4
Training loss: 2.9271551555541944
Validation loss: 2.6132443806482306

Epoch: 6| Step: 5
Training loss: 3.262374209028806
Validation loss: 2.6595890221687357

Epoch: 6| Step: 6
Training loss: 2.7106697763830767
Validation loss: 2.6365448366066193

Epoch: 6| Step: 7
Training loss: 2.936813761317621
Validation loss: 2.6549008634283715

Epoch: 6| Step: 8
Training loss: 2.8508012147320914
Validation loss: 2.6110382958654

Epoch: 6| Step: 9
Training loss: 3.0349915998615993
Validation loss: 2.5730661527556133

Epoch: 6| Step: 10
Training loss: 2.8627792688595317
Validation loss: 2.5404486122126198

Epoch: 6| Step: 11
Training loss: 2.965859220398394
Validation loss: 2.532087824695043

Epoch: 6| Step: 12
Training loss: 2.3881434107901662
Validation loss: 2.522684312841165

Epoch: 6| Step: 13
Training loss: 2.8881150354421097
Validation loss: 2.5172014055710568

Epoch: 104| Step: 0
Training loss: 2.6269006660073435
Validation loss: 2.5054774831910387

Epoch: 6| Step: 1
Training loss: 2.6355232749957707
Validation loss: 2.5040302707592303

Epoch: 6| Step: 2
Training loss: 3.0880499840283386
Validation loss: 2.499888069969644

Epoch: 6| Step: 3
Training loss: 2.869864978073116
Validation loss: 2.506238196167742

Epoch: 6| Step: 4
Training loss: 3.4147289332748127
Validation loss: 2.502627339096344

Epoch: 6| Step: 5
Training loss: 3.13879204397174
Validation loss: 2.501597603628238

Epoch: 6| Step: 6
Training loss: 2.8341993990403194
Validation loss: 2.500324570700739

Epoch: 6| Step: 7
Training loss: 3.024244728065494
Validation loss: 2.4999404520715838

Epoch: 6| Step: 8
Training loss: 3.174420467561064
Validation loss: 2.502093371848564

Epoch: 6| Step: 9
Training loss: 2.1516335868311733
Validation loss: 2.4999407791998993

Epoch: 6| Step: 10
Training loss: 2.370512889621839
Validation loss: 2.498999079946101

Epoch: 6| Step: 11
Training loss: 2.9144262337399485
Validation loss: 2.5199700533921456

Epoch: 6| Step: 12
Training loss: 2.847116678240743
Validation loss: 2.531831462620438

Epoch: 6| Step: 13
Training loss: 2.485566819018189
Validation loss: 2.560321532156095

Epoch: 105| Step: 0
Training loss: 2.9280289901903327
Validation loss: 2.6248747888051063

Epoch: 6| Step: 1
Training loss: 3.1960528945269755
Validation loss: 2.6643345566736616

Epoch: 6| Step: 2
Training loss: 3.0676602854741257
Validation loss: 2.6307050751047063

Epoch: 6| Step: 3
Training loss: 2.363197716111492
Validation loss: 2.6220223443264956

Epoch: 6| Step: 4
Training loss: 2.9151187240476104
Validation loss: 2.5777168177019814

Epoch: 6| Step: 5
Training loss: 3.1289032020506378
Validation loss: 2.5700195835797914

Epoch: 6| Step: 6
Training loss: 2.9572719944622876
Validation loss: 2.5357006206578774

Epoch: 6| Step: 7
Training loss: 3.1140380858417966
Validation loss: 2.5211115471445336

Epoch: 6| Step: 8
Training loss: 3.1434450157068854
Validation loss: 2.5007719816881546

Epoch: 6| Step: 9
Training loss: 2.063494818083586
Validation loss: 2.4933118716326303

Epoch: 6| Step: 10
Training loss: 2.996011466795059
Validation loss: 2.4917515646573247

Epoch: 6| Step: 11
Training loss: 2.7884837172458465
Validation loss: 2.483072900491667

Epoch: 6| Step: 12
Training loss: 2.0429510112160094
Validation loss: 2.4845317724811857

Epoch: 6| Step: 13
Training loss: 2.917486802098251
Validation loss: 2.4864506490686704

Epoch: 106| Step: 0
Training loss: 3.0056790005883256
Validation loss: 2.4874212228527406

Epoch: 6| Step: 1
Training loss: 2.4193816116861533
Validation loss: 2.484589328912342

Epoch: 6| Step: 2
Training loss: 3.1946555210719403
Validation loss: 2.4879702140892204

Epoch: 6| Step: 3
Training loss: 2.5733181618291026
Validation loss: 2.4910917493455322

Epoch: 6| Step: 4
Training loss: 2.6593455509119672
Validation loss: 2.4995108556598407

Epoch: 6| Step: 5
Training loss: 3.2818136548520456
Validation loss: 2.5160668128508346

Epoch: 6| Step: 6
Training loss: 2.97245220431441
Validation loss: 2.537427622810933

Epoch: 6| Step: 7
Training loss: 2.6331471759650977
Validation loss: 2.5286027349934375

Epoch: 6| Step: 8
Training loss: 3.2533516840599606
Validation loss: 2.528554179919612

Epoch: 6| Step: 9
Training loss: 2.792681741973239
Validation loss: 2.5269699392080684

Epoch: 6| Step: 10
Training loss: 2.3351039866587358
Validation loss: 2.5182339252882064

Epoch: 6| Step: 11
Training loss: 2.963198319553698
Validation loss: 2.5188406476431706

Epoch: 6| Step: 12
Training loss: 2.3770785020472123
Validation loss: 2.5190298459288774

Epoch: 6| Step: 13
Training loss: 3.1133604338757737
Validation loss: 2.5255271320774852

Epoch: 107| Step: 0
Training loss: 2.860055310974936
Validation loss: 2.522064292516814

Epoch: 6| Step: 1
Training loss: 2.4721602052298848
Validation loss: 2.514898362484033

Epoch: 6| Step: 2
Training loss: 2.8870808086548467
Validation loss: 2.5025177777529555

Epoch: 6| Step: 3
Training loss: 3.08364373440336
Validation loss: 2.513058019651227

Epoch: 6| Step: 4
Training loss: 2.408626423285322
Validation loss: 2.541105274621239

Epoch: 6| Step: 5
Training loss: 2.7100038707184684
Validation loss: 2.5512451620381076

Epoch: 6| Step: 6
Training loss: 3.2890223412316013
Validation loss: 2.5567471396250125

Epoch: 6| Step: 7
Training loss: 2.6793478703265445
Validation loss: 2.5654886166986164

Epoch: 6| Step: 8
Training loss: 2.8005899659280864
Validation loss: 2.551635155031678

Epoch: 6| Step: 9
Training loss: 3.0109065800075423
Validation loss: 2.536224636121536

Epoch: 6| Step: 10
Training loss: 2.314443235738366
Validation loss: 2.5292898934624657

Epoch: 6| Step: 11
Training loss: 3.4915268377621667
Validation loss: 2.5058667645403676

Epoch: 6| Step: 12
Training loss: 2.0668971266483527
Validation loss: 2.4886550662450495

Epoch: 6| Step: 13
Training loss: 3.470688973882589
Validation loss: 2.489836196802755

Epoch: 108| Step: 0
Training loss: 3.271403333884286
Validation loss: 2.4914608891160457

Epoch: 6| Step: 1
Training loss: 2.176299932214881
Validation loss: 2.4865245171364534

Epoch: 6| Step: 2
Training loss: 2.596171707787433
Validation loss: 2.4926900995591397

Epoch: 6| Step: 3
Training loss: 2.992540781863419
Validation loss: 2.4959982546056976

Epoch: 6| Step: 4
Training loss: 2.8044517651791683
Validation loss: 2.5042004368530493

Epoch: 6| Step: 5
Training loss: 3.0623349515075273
Validation loss: 2.5278400020730447

Epoch: 6| Step: 6
Training loss: 2.6138975502957997
Validation loss: 2.5661449285906244

Epoch: 6| Step: 7
Training loss: 3.0521474751230326
Validation loss: 2.6001399282596918

Epoch: 6| Step: 8
Training loss: 2.606239124888319
Validation loss: 2.5602073858315393

Epoch: 6| Step: 9
Training loss: 3.086090470397699
Validation loss: 2.5250791792515286

Epoch: 6| Step: 10
Training loss: 2.643346072964397
Validation loss: 2.5050247241416184

Epoch: 6| Step: 11
Training loss: 2.7387525993554207
Validation loss: 2.495943186013925

Epoch: 6| Step: 12
Training loss: 3.1005513346986473
Validation loss: 2.4929437448202214

Epoch: 6| Step: 13
Training loss: 2.702059938382939
Validation loss: 2.491883706752519

Epoch: 109| Step: 0
Training loss: 2.5102277397093475
Validation loss: 2.49550641715614

Epoch: 6| Step: 1
Training loss: 3.3924666646108115
Validation loss: 2.498219707291535

Epoch: 6| Step: 2
Training loss: 3.053606471320339
Validation loss: 2.4972036216875004

Epoch: 6| Step: 3
Training loss: 2.7558095428698017
Validation loss: 2.502681593242345

Epoch: 6| Step: 4
Training loss: 3.087436591976045
Validation loss: 2.511462909652482

Epoch: 6| Step: 5
Training loss: 2.7482124067282565
Validation loss: 2.5354794547256416

Epoch: 6| Step: 6
Training loss: 2.835388634903071
Validation loss: 2.5582429373733544

Epoch: 6| Step: 7
Training loss: 2.724957712527792
Validation loss: 2.5541045066933843

Epoch: 6| Step: 8
Training loss: 2.4357930588978913
Validation loss: 2.5468638118073126

Epoch: 6| Step: 9
Training loss: 2.8386802336208987
Validation loss: 2.555549273773731

Epoch: 6| Step: 10
Training loss: 2.6244571669475913
Validation loss: 2.5712196396777367

Epoch: 6| Step: 11
Training loss: 2.9931415998851256
Validation loss: 2.567624721968353

Epoch: 6| Step: 12
Training loss: 2.427578909600099
Validation loss: 2.53617655144506

Epoch: 6| Step: 13
Training loss: 2.9838015020278106
Validation loss: 2.5430603993754204

Epoch: 110| Step: 0
Training loss: 2.8014470244148875
Validation loss: 2.536519193242373

Epoch: 6| Step: 1
Training loss: 2.865148167265655
Validation loss: 2.5406316515470664

Epoch: 6| Step: 2
Training loss: 2.6595183964763787
Validation loss: 2.526080906196052

Epoch: 6| Step: 3
Training loss: 2.6598688942285977
Validation loss: 2.5306079809393327

Epoch: 6| Step: 4
Training loss: 3.3278180907674715
Validation loss: 2.518769139022457

Epoch: 6| Step: 5
Training loss: 2.6505171900913003
Validation loss: 2.5167834779289104

Epoch: 6| Step: 6
Training loss: 2.6883442461990943
Validation loss: 2.5112690547992234

Epoch: 6| Step: 7
Training loss: 2.6208480515140047
Validation loss: 2.507195763202503

Epoch: 6| Step: 8
Training loss: 3.0134395922715176
Validation loss: 2.5121049364170323

Epoch: 6| Step: 9
Training loss: 3.1234523755664405
Validation loss: 2.513612099193255

Epoch: 6| Step: 10
Training loss: 2.4885545038589685
Validation loss: 2.5232226558005135

Epoch: 6| Step: 11
Training loss: 2.2660898718254625
Validation loss: 2.521149240169581

Epoch: 6| Step: 12
Training loss: 2.8228504037059565
Validation loss: 2.526632391655781

Epoch: 6| Step: 13
Training loss: 3.2004147856824807
Validation loss: 2.525503161597624

Epoch: 111| Step: 0
Training loss: 2.820619180759113
Validation loss: 2.5496354988071337

Epoch: 6| Step: 1
Training loss: 2.362587970528833
Validation loss: 2.5894917852902206

Epoch: 6| Step: 2
Training loss: 3.2287420342288407
Validation loss: 2.5980369800199585

Epoch: 6| Step: 3
Training loss: 2.9428849878991112
Validation loss: 2.630886773464964

Epoch: 6| Step: 4
Training loss: 2.5895554049748712
Validation loss: 2.608636135583758

Epoch: 6| Step: 5
Training loss: 3.021471118466394
Validation loss: 2.586007129463026

Epoch: 6| Step: 6
Training loss: 1.6048631848642327
Validation loss: 2.582632091375378

Epoch: 6| Step: 7
Training loss: 2.291361724909955
Validation loss: 2.566176119931604

Epoch: 6| Step: 8
Training loss: 2.884218446857716
Validation loss: 2.55425701645679

Epoch: 6| Step: 9
Training loss: 3.2845561492064705
Validation loss: 2.5340403646381637

Epoch: 6| Step: 10
Training loss: 3.1409700877827844
Validation loss: 2.521966690783711

Epoch: 6| Step: 11
Training loss: 2.910346968373077
Validation loss: 2.504947362144553

Epoch: 6| Step: 12
Training loss: 2.842921209606119
Validation loss: 2.501473858877384

Epoch: 6| Step: 13
Training loss: 3.0029376270220247
Validation loss: 2.4972075546064882

Epoch: 112| Step: 0
Training loss: 2.8483448844245394
Validation loss: 2.5108166713255753

Epoch: 6| Step: 1
Training loss: 2.218016167295403
Validation loss: 2.5007826718220825

Epoch: 6| Step: 2
Training loss: 2.956613891658108
Validation loss: 2.4954168003315043

Epoch: 6| Step: 3
Training loss: 2.8081888005072653
Validation loss: 2.516457173098564

Epoch: 6| Step: 4
Training loss: 2.5259451202085086
Validation loss: 2.499466307905339

Epoch: 6| Step: 5
Training loss: 2.545091999542023
Validation loss: 2.5030218565477735

Epoch: 6| Step: 6
Training loss: 2.768976196280428
Validation loss: 2.5042601035828134

Epoch: 6| Step: 7
Training loss: 3.0371129860810524
Validation loss: 2.514343387727767

Epoch: 6| Step: 8
Training loss: 3.2634594321379207
Validation loss: 2.529449398744089

Epoch: 6| Step: 9
Training loss: 2.881432179547954
Validation loss: 2.5367087192835376

Epoch: 6| Step: 10
Training loss: 3.177671951215389
Validation loss: 2.548287121038476

Epoch: 6| Step: 11
Training loss: 2.84077700637325
Validation loss: 2.562891726361974

Epoch: 6| Step: 12
Training loss: 2.5989616154488817
Validation loss: 2.563875257014187

Epoch: 6| Step: 13
Training loss: 2.491388748983099
Validation loss: 2.569424113095533

Epoch: 113| Step: 0
Training loss: 2.827824950766747
Validation loss: 2.564388538655652

Epoch: 6| Step: 1
Training loss: 3.321901618800628
Validation loss: 2.556091028417117

Epoch: 6| Step: 2
Training loss: 2.1754086516132256
Validation loss: 2.5406633518652533

Epoch: 6| Step: 3
Training loss: 2.777895844387551
Validation loss: 2.5225342673468134

Epoch: 6| Step: 4
Training loss: 3.2304995995447348
Validation loss: 2.50664250516287

Epoch: 6| Step: 5
Training loss: 2.8056946542667394
Validation loss: 2.5022519531246967

Epoch: 6| Step: 6
Training loss: 2.7568527150901976
Validation loss: 2.4939112627550055

Epoch: 6| Step: 7
Training loss: 2.62788813518106
Validation loss: 2.493388508375176

Epoch: 6| Step: 8
Training loss: 2.6691937294345434
Validation loss: 2.4940800244084986

Epoch: 6| Step: 9
Training loss: 2.6698639199943957
Validation loss: 2.507279144695777

Epoch: 6| Step: 10
Training loss: 2.7331487031157864
Validation loss: 2.5080713217696076

Epoch: 6| Step: 11
Training loss: 2.86450185948886
Validation loss: 2.512815141981605

Epoch: 6| Step: 12
Training loss: 3.2431006926491093
Validation loss: 2.519662638268141

Epoch: 6| Step: 13
Training loss: 1.9426133147074112
Validation loss: 2.5260226236396686

Epoch: 114| Step: 0
Training loss: 3.0786013162064276
Validation loss: 2.524864358994014

Epoch: 6| Step: 1
Training loss: 2.852377746262414
Validation loss: 2.528561620745318

Epoch: 6| Step: 2
Training loss: 2.877656124330609
Validation loss: 2.5374635499108043

Epoch: 6| Step: 3
Training loss: 3.0236481980040217
Validation loss: 2.537927598769511

Epoch: 6| Step: 4
Training loss: 2.73621746659053
Validation loss: 2.5382148926986003

Epoch: 6| Step: 5
Training loss: 2.3848029156392885
Validation loss: 2.5245521562700484

Epoch: 6| Step: 6
Training loss: 2.640155457052168
Validation loss: 2.5155607977212973

Epoch: 6| Step: 7
Training loss: 2.841416795620295
Validation loss: 2.498328538211554

Epoch: 6| Step: 8
Training loss: 2.2484151768852
Validation loss: 2.487900427256646

Epoch: 6| Step: 9
Training loss: 2.915120523359274
Validation loss: 2.4987466151790905

Epoch: 6| Step: 10
Training loss: 3.1160990791483725
Validation loss: 2.4936926143348495

Epoch: 6| Step: 11
Training loss: 2.7945320076070925
Validation loss: 2.484615717483005

Epoch: 6| Step: 12
Training loss: 2.5550995940563404
Validation loss: 2.484976464217429

Epoch: 6| Step: 13
Training loss: 3.3230260912697145
Validation loss: 2.4897540938324045

Epoch: 115| Step: 0
Training loss: 2.4750880717010864
Validation loss: 2.4934374361902223

Epoch: 6| Step: 1
Training loss: 3.090756904710973
Validation loss: 2.527430530194379

Epoch: 6| Step: 2
Training loss: 3.047320367590105
Validation loss: 2.5403575275958277

Epoch: 6| Step: 3
Training loss: 2.3140280546500556
Validation loss: 2.584495750979313

Epoch: 6| Step: 4
Training loss: 3.206523896949621
Validation loss: 2.599749810792126

Epoch: 6| Step: 5
Training loss: 2.7901594638715164
Validation loss: 2.623688199618594

Epoch: 6| Step: 6
Training loss: 2.3531898114725807
Validation loss: 2.6057537028993565

Epoch: 6| Step: 7
Training loss: 2.413406431064081
Validation loss: 2.5900642270114393

Epoch: 6| Step: 8
Training loss: 3.027694032154463
Validation loss: 2.554781951116635

Epoch: 6| Step: 9
Training loss: 2.5503767782365054
Validation loss: 2.513811341595544

Epoch: 6| Step: 10
Training loss: 2.600276319785938
Validation loss: 2.5035284379088663

Epoch: 6| Step: 11
Training loss: 2.758202717004024
Validation loss: 2.4916313333366036

Epoch: 6| Step: 12
Training loss: 3.1005416458450656
Validation loss: 2.4835857908312735

Epoch: 6| Step: 13
Training loss: 2.9844574442555327
Validation loss: 2.483359986697849

Epoch: 116| Step: 0
Training loss: 2.6501324386611036
Validation loss: 2.481077937414843

Epoch: 6| Step: 1
Training loss: 3.3377671952749366
Validation loss: 2.4651220062632917

Epoch: 6| Step: 2
Training loss: 2.604174153635071
Validation loss: 2.4690028640431487

Epoch: 6| Step: 3
Training loss: 2.7077120630795717
Validation loss: 2.4725389026201006

Epoch: 6| Step: 4
Training loss: 2.7556631557758626
Validation loss: 2.475630565989483

Epoch: 6| Step: 5
Training loss: 2.440287829760587
Validation loss: 2.476904263769948

Epoch: 6| Step: 6
Training loss: 3.369827686964356
Validation loss: 2.4774267706441724

Epoch: 6| Step: 7
Training loss: 3.205896285922823
Validation loss: 2.468262808804686

Epoch: 6| Step: 8
Training loss: 2.0251821412482167
Validation loss: 2.470812694800434

Epoch: 6| Step: 9
Training loss: 2.4446086418992183
Validation loss: 2.4703187341850024

Epoch: 6| Step: 10
Training loss: 2.8534880525169424
Validation loss: 2.467479627661278

Epoch: 6| Step: 11
Training loss: 2.8055733049626492
Validation loss: 2.477062803796892

Epoch: 6| Step: 12
Training loss: 2.783220600274085
Validation loss: 2.495831252262299

Epoch: 6| Step: 13
Training loss: 2.9668775576380972
Validation loss: 2.523083219679258

Epoch: 117| Step: 0
Training loss: 3.4507472624949944
Validation loss: 2.5131688979685656

Epoch: 6| Step: 1
Training loss: 2.6047027239614895
Validation loss: 2.511063910787056

Epoch: 6| Step: 2
Training loss: 2.6645956540711433
Validation loss: 2.518218057186327

Epoch: 6| Step: 3
Training loss: 3.122163018886731
Validation loss: 2.5189715284633674

Epoch: 6| Step: 4
Training loss: 2.9071005940336097
Validation loss: 2.514479133441255

Epoch: 6| Step: 5
Training loss: 3.024891742629224
Validation loss: 2.5093556934986494

Epoch: 6| Step: 6
Training loss: 2.3728616022068247
Validation loss: 2.5000524187232576

Epoch: 6| Step: 7
Training loss: 2.078572045908084
Validation loss: 2.4901398033282236

Epoch: 6| Step: 8
Training loss: 3.3486362300398134
Validation loss: 2.5090824643265646

Epoch: 6| Step: 9
Training loss: 2.7856948139222784
Validation loss: 2.507794840367189

Epoch: 6| Step: 10
Training loss: 3.0033934791743606
Validation loss: 2.5111768311404767

Epoch: 6| Step: 11
Training loss: 2.3360785502330366
Validation loss: 2.50539510898498

Epoch: 6| Step: 12
Training loss: 2.0296365051676446
Validation loss: 2.4973726571873276

Epoch: 6| Step: 13
Training loss: 2.6149595884041528
Validation loss: 2.494078569943316

Epoch: 118| Step: 0
Training loss: 3.0524616375886193
Validation loss: 2.496278773323693

Epoch: 6| Step: 1
Training loss: 3.06410860127146
Validation loss: 2.49275840042317

Epoch: 6| Step: 2
Training loss: 2.882155428801765
Validation loss: 2.503737737006454

Epoch: 6| Step: 3
Training loss: 2.786038509127399
Validation loss: 2.515607402344812

Epoch: 6| Step: 4
Training loss: 2.70587644399549
Validation loss: 2.5325689491380796

Epoch: 6| Step: 5
Training loss: 2.759631715888268
Validation loss: 2.541863116320101

Epoch: 6| Step: 6
Training loss: 2.6256469655905836
Validation loss: 2.5493695873454265

Epoch: 6| Step: 7
Training loss: 2.793785391973809
Validation loss: 2.5202743732963997

Epoch: 6| Step: 8
Training loss: 2.546864702636871
Validation loss: 2.506326367903513

Epoch: 6| Step: 9
Training loss: 2.3966682195680526
Validation loss: 2.4911824278681993

Epoch: 6| Step: 10
Training loss: 2.78804993614563
Validation loss: 2.4836943412383308

Epoch: 6| Step: 11
Training loss: 2.6562045822748575
Validation loss: 2.4778095083379896

Epoch: 6| Step: 12
Training loss: 3.0787684353870057
Validation loss: 2.4755531760149014

Epoch: 6| Step: 13
Training loss: 2.5220662929585895
Validation loss: 2.474331271824029

Epoch: 119| Step: 0
Training loss: 2.677793317127999
Validation loss: 2.471522073859459

Epoch: 6| Step: 1
Training loss: 2.8604485836225653
Validation loss: 2.464995618155386

Epoch: 6| Step: 2
Training loss: 2.8099923716811492
Validation loss: 2.4681289896987324

Epoch: 6| Step: 3
Training loss: 2.9801791589120725
Validation loss: 2.4706346206542267

Epoch: 6| Step: 4
Training loss: 2.251663864363652
Validation loss: 2.469683075051635

Epoch: 6| Step: 5
Training loss: 2.615190432964947
Validation loss: 2.480991407227864

Epoch: 6| Step: 6
Training loss: 3.0830016258450756
Validation loss: 2.482693186055588

Epoch: 6| Step: 7
Training loss: 2.8633456984028336
Validation loss: 2.4772214671776474

Epoch: 6| Step: 8
Training loss: 2.5200613011367037
Validation loss: 2.4912079284855353

Epoch: 6| Step: 9
Training loss: 2.6315295435634884
Validation loss: 2.4863868987856708

Epoch: 6| Step: 10
Training loss: 3.040574509141667
Validation loss: 2.485102791398238

Epoch: 6| Step: 11
Training loss: 2.8191047259171618
Validation loss: 2.5032961143638643

Epoch: 6| Step: 12
Training loss: 3.0794676355295447
Validation loss: 2.5267032373928835

Epoch: 6| Step: 13
Training loss: 2.029124042394907
Validation loss: 2.5541643887408823

Epoch: 120| Step: 0
Training loss: 2.249300848100879
Validation loss: 2.565738693235652

Epoch: 6| Step: 1
Training loss: 2.91725683145216
Validation loss: 2.5725958975723833

Epoch: 6| Step: 2
Training loss: 2.2149274968321526
Validation loss: 2.571313048826406

Epoch: 6| Step: 3
Training loss: 3.096495671911555
Validation loss: 2.5652458711873845

Epoch: 6| Step: 4
Training loss: 3.065084184545281
Validation loss: 2.5540645582836214

Epoch: 6| Step: 5
Training loss: 3.37393567292692
Validation loss: 2.54037470454012

Epoch: 6| Step: 6
Training loss: 2.907486191222314
Validation loss: 2.517369498999264

Epoch: 6| Step: 7
Training loss: 2.967652609933418
Validation loss: 2.500505470120537

Epoch: 6| Step: 8
Training loss: 2.3411649562463466
Validation loss: 2.4867593730091313

Epoch: 6| Step: 9
Training loss: 2.466868009168347
Validation loss: 2.485051233385733

Epoch: 6| Step: 10
Training loss: 2.381591884470302
Validation loss: 2.4738869567488067

Epoch: 6| Step: 11
Training loss: 2.5095296429671166
Validation loss: 2.4758564144439035

Epoch: 6| Step: 12
Training loss: 3.0685460102472626
Validation loss: 2.474226157820132

Epoch: 6| Step: 13
Training loss: 2.839755596067723
Validation loss: 2.471307725791057

Epoch: 121| Step: 0
Training loss: 2.747007736106286
Validation loss: 2.467622937129455

Epoch: 6| Step: 1
Training loss: 3.2300672362330074
Validation loss: 2.4632048080094657

Epoch: 6| Step: 2
Training loss: 2.888317610016774
Validation loss: 2.468191627586548

Epoch: 6| Step: 3
Training loss: 2.677304200636409
Validation loss: 2.4704711727361675

Epoch: 6| Step: 4
Training loss: 2.086657796217292
Validation loss: 2.4788572058455935

Epoch: 6| Step: 5
Training loss: 2.827366342530711
Validation loss: 2.481899358905994

Epoch: 6| Step: 6
Training loss: 2.670544834197003
Validation loss: 2.4936322115549396

Epoch: 6| Step: 7
Training loss: 2.9664792662448436
Validation loss: 2.489418858103811

Epoch: 6| Step: 8
Training loss: 3.223245092983678
Validation loss: 2.4872952803724995

Epoch: 6| Step: 9
Training loss: 2.965241778649284
Validation loss: 2.488000901705217

Epoch: 6| Step: 10
Training loss: 2.9420359875872184
Validation loss: 2.4856430638659437

Epoch: 6| Step: 11
Training loss: 2.3227979917674895
Validation loss: 2.4856843372574042

Epoch: 6| Step: 12
Training loss: 1.8528107246368544
Validation loss: 2.486300092460703

Epoch: 6| Step: 13
Training loss: 2.6425668472308774
Validation loss: 2.4786820362402504

Epoch: 122| Step: 0
Training loss: 2.121435317046655
Validation loss: 2.486963959200561

Epoch: 6| Step: 1
Training loss: 2.664071628409489
Validation loss: 2.4833811771926175

Epoch: 6| Step: 2
Training loss: 3.104602928142448
Validation loss: 2.493447718749054

Epoch: 6| Step: 3
Training loss: 2.846858243756859
Validation loss: 2.497716456562481

Epoch: 6| Step: 4
Training loss: 2.4714286854599816
Validation loss: 2.4912306966732958

Epoch: 6| Step: 5
Training loss: 2.909841963419181
Validation loss: 2.4833984953094403

Epoch: 6| Step: 6
Training loss: 3.028936702879218
Validation loss: 2.483008862153993

Epoch: 6| Step: 7
Training loss: 2.3408561643322483
Validation loss: 2.4726085589878877

Epoch: 6| Step: 8
Training loss: 3.3111843159354146
Validation loss: 2.459208501797428

Epoch: 6| Step: 9
Training loss: 2.789085580425772
Validation loss: 2.4519726510574196

Epoch: 6| Step: 10
Training loss: 2.5762342513416057
Validation loss: 2.4547120601118624

Epoch: 6| Step: 11
Training loss: 2.735402290285154
Validation loss: 2.4703440610094805

Epoch: 6| Step: 12
Training loss: 2.7511344650392067
Validation loss: 2.479565679741829

Epoch: 6| Step: 13
Training loss: 2.4304084321559465
Validation loss: 2.484885123851794

Epoch: 123| Step: 0
Training loss: 2.617586384452674
Validation loss: 2.512188490709279

Epoch: 6| Step: 1
Training loss: 2.3538859602303446
Validation loss: 2.5028625076989037

Epoch: 6| Step: 2
Training loss: 3.1196545468332144
Validation loss: 2.5115581962477953

Epoch: 6| Step: 3
Training loss: 2.710205594952686
Validation loss: 2.5039681741218067

Epoch: 6| Step: 4
Training loss: 2.347477098379661
Validation loss: 2.517094941816022

Epoch: 6| Step: 5
Training loss: 2.865776192806385
Validation loss: 2.515678197815036

Epoch: 6| Step: 6
Training loss: 2.811385718123163
Validation loss: 2.5148431368898567

Epoch: 6| Step: 7
Training loss: 2.792136157587908
Validation loss: 2.5158106361459347

Epoch: 6| Step: 8
Training loss: 3.1215250149380953
Validation loss: 2.4997499956211757

Epoch: 6| Step: 9
Training loss: 2.0249013429321434
Validation loss: 2.4902221972790874

Epoch: 6| Step: 10
Training loss: 2.5123935582022945
Validation loss: 2.489582551068841

Epoch: 6| Step: 11
Training loss: 3.3859131590809297
Validation loss: 2.4791946726666843

Epoch: 6| Step: 12
Training loss: 2.557432327493866
Validation loss: 2.473493267359297

Epoch: 6| Step: 13
Training loss: 3.069206834651596
Validation loss: 2.4713846211250368

Epoch: 124| Step: 0
Training loss: 3.0121086847826177
Validation loss: 2.4730328686461474

Epoch: 6| Step: 1
Training loss: 3.2551056298902443
Validation loss: 2.466065656294225

Epoch: 6| Step: 2
Training loss: 2.6858609546452676
Validation loss: 2.4680371328095223

Epoch: 6| Step: 3
Training loss: 2.3027242283358937
Validation loss: 2.467660567238192

Epoch: 6| Step: 4
Training loss: 2.217641204157241
Validation loss: 2.4810586150607015

Epoch: 6| Step: 5
Training loss: 2.5340316935049856
Validation loss: 2.487371594886952

Epoch: 6| Step: 6
Training loss: 2.720709697334802
Validation loss: 2.490387439724659

Epoch: 6| Step: 7
Training loss: 2.8696541219567013
Validation loss: 2.508382734518741

Epoch: 6| Step: 8
Training loss: 2.67266807163259
Validation loss: 2.536767804310957

Epoch: 6| Step: 9
Training loss: 2.2548269840695934
Validation loss: 2.5554355814169374

Epoch: 6| Step: 10
Training loss: 3.1113623014346263
Validation loss: 2.5605345480944517

Epoch: 6| Step: 11
Training loss: 2.6980532657011325
Validation loss: 2.565671455380697

Epoch: 6| Step: 12
Training loss: 2.6263129266084153
Validation loss: 2.5639393243502706

Epoch: 6| Step: 13
Training loss: 3.616148302986803
Validation loss: 2.5620903099815893

Epoch: 125| Step: 0
Training loss: 2.768463402375138
Validation loss: 2.553879504866695

Epoch: 6| Step: 1
Training loss: 2.9277930072514597
Validation loss: 2.5457688634820475

Epoch: 6| Step: 2
Training loss: 2.344577287261997
Validation loss: 2.5257888780787514

Epoch: 6| Step: 3
Training loss: 2.317195249764466
Validation loss: 2.4938488278043223

Epoch: 6| Step: 4
Training loss: 2.8780751575043437
Validation loss: 2.469256667739934

Epoch: 6| Step: 5
Training loss: 2.4815211188797175
Validation loss: 2.4500389483605836

Epoch: 6| Step: 6
Training loss: 2.896619694559026
Validation loss: 2.4389197950304538

Epoch: 6| Step: 7
Training loss: 2.4368124750280127
Validation loss: 2.4469131702905513

Epoch: 6| Step: 8
Training loss: 2.831492405634185
Validation loss: 2.447062640602608

Epoch: 6| Step: 9
Training loss: 2.850260565374216
Validation loss: 2.444414455297292

Epoch: 6| Step: 10
Training loss: 3.1506912078590426
Validation loss: 2.440909322327145

Epoch: 6| Step: 11
Training loss: 2.731868270624862
Validation loss: 2.44395583857656

Epoch: 6| Step: 12
Training loss: 3.3917136136741584
Validation loss: 2.440813104190144

Epoch: 6| Step: 13
Training loss: 2.2469313146248155
Validation loss: 2.4383832784140402

Epoch: 126| Step: 0
Training loss: 2.932463203322895
Validation loss: 2.440056903553994

Epoch: 6| Step: 1
Training loss: 2.819362660074258
Validation loss: 2.444811223950307

Epoch: 6| Step: 2
Training loss: 2.638500736088277
Validation loss: 2.4516203287659297

Epoch: 6| Step: 3
Training loss: 3.1153017234099267
Validation loss: 2.4634755839051055

Epoch: 6| Step: 4
Training loss: 3.018866343655262
Validation loss: 2.481098334217929

Epoch: 6| Step: 5
Training loss: 2.5492690366367348
Validation loss: 2.5033049385578843

Epoch: 6| Step: 6
Training loss: 2.407442169128674
Validation loss: 2.5301665662845525

Epoch: 6| Step: 7
Training loss: 2.7756134523608056
Validation loss: 2.5080716238167446

Epoch: 6| Step: 8
Training loss: 2.2125622067084776
Validation loss: 2.5089995800839913

Epoch: 6| Step: 9
Training loss: 3.10110754716827
Validation loss: 2.482274726976944

Epoch: 6| Step: 10
Training loss: 1.8559994872108936
Validation loss: 2.478773197693952

Epoch: 6| Step: 11
Training loss: 3.1193133684359013
Validation loss: 2.4682531909639716

Epoch: 6| Step: 12
Training loss: 2.435748914033792
Validation loss: 2.46811347669541

Epoch: 6| Step: 13
Training loss: 3.301150473986955
Validation loss: 2.4624182326543576

Epoch: 127| Step: 0
Training loss: 2.7981383810773552
Validation loss: 2.4653518590138175

Epoch: 6| Step: 1
Training loss: 2.57387770852367
Validation loss: 2.465893503177255

Epoch: 6| Step: 2
Training loss: 2.7658408560271757
Validation loss: 2.4715845884147853

Epoch: 6| Step: 3
Training loss: 2.8326881646519406
Validation loss: 2.47985691944596

Epoch: 6| Step: 4
Training loss: 3.0615117561080973
Validation loss: 2.483901522754385

Epoch: 6| Step: 5
Training loss: 2.1774914251042614
Validation loss: 2.505035644812112

Epoch: 6| Step: 6
Training loss: 3.1986637961610755
Validation loss: 2.507201409513755

Epoch: 6| Step: 7
Training loss: 2.548566478877787
Validation loss: 2.5044579465012555

Epoch: 6| Step: 8
Training loss: 2.2635503280434146
Validation loss: 2.4917384313420223

Epoch: 6| Step: 9
Training loss: 2.5964059674685878
Validation loss: 2.4785828079105077

Epoch: 6| Step: 10
Training loss: 2.9149656149143186
Validation loss: 2.478387068078022

Epoch: 6| Step: 11
Training loss: 2.649747811319509
Validation loss: 2.498258978133925

Epoch: 6| Step: 12
Training loss: 2.788312880704589
Validation loss: 2.495529744524584

Epoch: 6| Step: 13
Training loss: 2.92773551508275
Validation loss: 2.503085918530325

Epoch: 128| Step: 0
Training loss: 2.8874439779024117
Validation loss: 2.500621551752339

Epoch: 6| Step: 1
Training loss: 2.5661730609551596
Validation loss: 2.471488494025003

Epoch: 6| Step: 2
Training loss: 2.0546833226846797
Validation loss: 2.4823959288686934

Epoch: 6| Step: 3
Training loss: 2.07280802481985
Validation loss: 2.498638341126853

Epoch: 6| Step: 4
Training loss: 2.4268228502980014
Validation loss: 2.5151684779350267

Epoch: 6| Step: 5
Training loss: 2.6629367810379367
Validation loss: 2.51977088998777

Epoch: 6| Step: 6
Training loss: 2.6299134545536633
Validation loss: 2.5249448776117087

Epoch: 6| Step: 7
Training loss: 3.034260935657838
Validation loss: 2.525979150358568

Epoch: 6| Step: 8
Training loss: 3.2206317623044485
Validation loss: 2.5477141867428705

Epoch: 6| Step: 9
Training loss: 2.6926069308186857
Validation loss: 2.5421550566613793

Epoch: 6| Step: 10
Training loss: 3.2565581836677326
Validation loss: 2.5306683673099344

Epoch: 6| Step: 11
Training loss: 2.725102161977215
Validation loss: 2.5194068434725914

Epoch: 6| Step: 12
Training loss: 3.0056585352615857
Validation loss: 2.4994064836569767

Epoch: 6| Step: 13
Training loss: 3.3753142034008756
Validation loss: 2.497092063210697

Epoch: 129| Step: 0
Training loss: 3.072570281253099
Validation loss: 2.482674355404991

Epoch: 6| Step: 1
Training loss: 3.496731185342097
Validation loss: 2.4883290815850403

Epoch: 6| Step: 2
Training loss: 2.462223746203254
Validation loss: 2.505671602976312

Epoch: 6| Step: 3
Training loss: 2.557247454124449
Validation loss: 2.5162059144031907

Epoch: 6| Step: 4
Training loss: 2.4366760817666377
Validation loss: 2.567285111253967

Epoch: 6| Step: 5
Training loss: 2.763575769916898
Validation loss: 2.577612219883425

Epoch: 6| Step: 6
Training loss: 2.877411038691465
Validation loss: 2.591626007923901

Epoch: 6| Step: 7
Training loss: 2.5989520748779125
Validation loss: 2.569641729923795

Epoch: 6| Step: 8
Training loss: 2.842459249481149
Validation loss: 2.513992169965802

Epoch: 6| Step: 9
Training loss: 2.8693142936398646
Validation loss: 2.4696326328459657

Epoch: 6| Step: 10
Training loss: 2.2204194571325466
Validation loss: 2.438501349553111

Epoch: 6| Step: 11
Training loss: 2.410090267817689
Validation loss: 2.4241040248206387

Epoch: 6| Step: 12
Training loss: 2.8731914304962096
Validation loss: 2.415758419121232

Epoch: 6| Step: 13
Training loss: 2.8054486360309574
Validation loss: 2.400813432054674

Epoch: 130| Step: 0
Training loss: 2.2316494837871717
Validation loss: 2.4061617462845675

Epoch: 6| Step: 1
Training loss: 3.225373647173207
Validation loss: 2.400335384763136

Epoch: 6| Step: 2
Training loss: 2.4689593648861425
Validation loss: 2.406683225590371

Epoch: 6| Step: 3
Training loss: 2.629841200382125
Validation loss: 2.4027334075159223

Epoch: 6| Step: 4
Training loss: 2.7987062224030637
Validation loss: 2.4063659115869562

Epoch: 6| Step: 5
Training loss: 2.719379396042704
Validation loss: 2.406506218311716

Epoch: 6| Step: 6
Training loss: 2.4058476892018112
Validation loss: 2.4142745568980137

Epoch: 6| Step: 7
Training loss: 2.689127584464401
Validation loss: 2.4187189153435553

Epoch: 6| Step: 8
Training loss: 3.095337123474434
Validation loss: 2.431987674856501

Epoch: 6| Step: 9
Training loss: 3.0830017805116
Validation loss: 2.4397154369582146

Epoch: 6| Step: 10
Training loss: 2.5249157051141586
Validation loss: 2.475256308365082

Epoch: 6| Step: 11
Training loss: 2.9277930072514597
Validation loss: 2.5013977522057

Epoch: 6| Step: 12
Training loss: 2.880959015755668
Validation loss: 2.5188005679311525

Epoch: 6| Step: 13
Training loss: 2.924584585833486
Validation loss: 2.5504733691625154

Epoch: 131| Step: 0
Training loss: 2.7808622454255887
Validation loss: 2.507739398023615

Epoch: 6| Step: 1
Training loss: 2.675023415721478
Validation loss: 2.512274780080627

Epoch: 6| Step: 2
Training loss: 3.013739594386588
Validation loss: 2.5064772476198507

Epoch: 6| Step: 3
Training loss: 2.8097348501470925
Validation loss: 2.4785000125450143

Epoch: 6| Step: 4
Training loss: 2.4902563954296006
Validation loss: 2.456173385543704

Epoch: 6| Step: 5
Training loss: 2.736253801380652
Validation loss: 2.445363933461726

Epoch: 6| Step: 6
Training loss: 2.6175270885096933
Validation loss: 2.4491492657995

Epoch: 6| Step: 7
Training loss: 2.6201832493185977
Validation loss: 2.4558767218000885

Epoch: 6| Step: 8
Training loss: 2.938626661742606
Validation loss: 2.460432482791164

Epoch: 6| Step: 9
Training loss: 2.41861037213565
Validation loss: 2.464896322485079

Epoch: 6| Step: 10
Training loss: 3.054599458250099
Validation loss: 2.464709224149785

Epoch: 6| Step: 11
Training loss: 2.4936852812435792
Validation loss: 2.4679143614706787

Epoch: 6| Step: 12
Training loss: 2.779176946694398
Validation loss: 2.4636371067415026

Epoch: 6| Step: 13
Training loss: 2.7519025290327552
Validation loss: 2.4622797240600915

Epoch: 132| Step: 0
Training loss: 2.7089884234716504
Validation loss: 2.464115057275686

Epoch: 6| Step: 1
Training loss: 2.748051559997339
Validation loss: 2.455860359970189

Epoch: 6| Step: 2
Training loss: 2.3668449330239616
Validation loss: 2.459980908079751

Epoch: 6| Step: 3
Training loss: 3.2221374464027357
Validation loss: 2.472947138207843

Epoch: 6| Step: 4
Training loss: 2.454873791964193
Validation loss: 2.4763290322659155

Epoch: 6| Step: 5
Training loss: 2.826316044207439
Validation loss: 2.4814062807693955

Epoch: 6| Step: 6
Training loss: 3.052832154644063
Validation loss: 2.4931834997728046

Epoch: 6| Step: 7
Training loss: 2.3332141323522895
Validation loss: 2.488677176877779

Epoch: 6| Step: 8
Training loss: 2.825240629632444
Validation loss: 2.4818108988447323

Epoch: 6| Step: 9
Training loss: 3.226610086381082
Validation loss: 2.4862088780594416

Epoch: 6| Step: 10
Training loss: 2.3291238779722363
Validation loss: 2.496677787717987

Epoch: 6| Step: 11
Training loss: 2.211457208269875
Validation loss: 2.4825392261176917

Epoch: 6| Step: 12
Training loss: 2.871385375282926
Validation loss: 2.4905228220502016

Epoch: 6| Step: 13
Training loss: 2.047480952135851
Validation loss: 2.4874161510585813

Epoch: 133| Step: 0
Training loss: 2.1736825789733145
Validation loss: 2.48723235466943

Epoch: 6| Step: 1
Training loss: 2.728749619473873
Validation loss: 2.5006919949091317

Epoch: 6| Step: 2
Training loss: 2.442339958171867
Validation loss: 2.505832278127099

Epoch: 6| Step: 3
Training loss: 3.3699082006068917
Validation loss: 2.513737675698548

Epoch: 6| Step: 4
Training loss: 3.272194856386401
Validation loss: 2.5296207503311408

Epoch: 6| Step: 5
Training loss: 2.0413893946036827
Validation loss: 2.5304520890233797

Epoch: 6| Step: 6
Training loss: 2.3150899662802384
Validation loss: 2.545961992557949

Epoch: 6| Step: 7
Training loss: 2.5660436365367203
Validation loss: 2.535901509184507

Epoch: 6| Step: 8
Training loss: 3.407349435302369
Validation loss: 2.5206837841540537

Epoch: 6| Step: 9
Training loss: 2.351290259333474
Validation loss: 2.51256966553224

Epoch: 6| Step: 10
Training loss: 2.5648742469464123
Validation loss: 2.501079089558922

Epoch: 6| Step: 11
Training loss: 3.1596317115275054
Validation loss: 2.4979311191367524

Epoch: 6| Step: 12
Training loss: 2.392124977017331
Validation loss: 2.47998507971713

Epoch: 6| Step: 13
Training loss: 2.4864019606205736
Validation loss: 2.4886484301325495

Epoch: 134| Step: 0
Training loss: 3.3564150522803087
Validation loss: 2.4772780126773064

Epoch: 6| Step: 1
Training loss: 2.497626703998589
Validation loss: 2.475177690730299

Epoch: 6| Step: 2
Training loss: 3.3011529295638025
Validation loss: 2.4699320114989636

Epoch: 6| Step: 3
Training loss: 2.1116700296994924
Validation loss: 2.4727309578145067

Epoch: 6| Step: 4
Training loss: 2.714588707669477
Validation loss: 2.4862296854374404

Epoch: 6| Step: 5
Training loss: 2.7422314936486125
Validation loss: 2.5001521300102527

Epoch: 6| Step: 6
Training loss: 2.7194260381539603
Validation loss: 2.490721732474769

Epoch: 6| Step: 7
Training loss: 2.5534328914717928
Validation loss: 2.5061928269037725

Epoch: 6| Step: 8
Training loss: 3.0093265834569833
Validation loss: 2.5073071170129437

Epoch: 6| Step: 9
Training loss: 2.597598151224111
Validation loss: 2.5239560494740507

Epoch: 6| Step: 10
Training loss: 2.5783076366121347
Validation loss: 2.532400529334066

Epoch: 6| Step: 11
Training loss: 2.6985890693263936
Validation loss: 2.5367152175417127

Epoch: 6| Step: 12
Training loss: 2.0905883603384985
Validation loss: 2.5189456962300425

Epoch: 6| Step: 13
Training loss: 2.9752966724860634
Validation loss: 2.4932969553895523

Epoch: 135| Step: 0
Training loss: 2.3152096312751613
Validation loss: 2.464484284827449

Epoch: 6| Step: 1
Training loss: 2.4307497897573236
Validation loss: 2.463046419942525

Epoch: 6| Step: 2
Training loss: 2.876954450950136
Validation loss: 2.4467124785562815

Epoch: 6| Step: 3
Training loss: 1.9909245695293898
Validation loss: 2.446342173107013

Epoch: 6| Step: 4
Training loss: 2.971067467692884
Validation loss: 2.4434723931086966

Epoch: 6| Step: 5
Training loss: 3.005284106237562
Validation loss: 2.440119862291201

Epoch: 6| Step: 6
Training loss: 2.8132404624230154
Validation loss: 2.4395464207202417

Epoch: 6| Step: 7
Training loss: 2.8735862241240624
Validation loss: 2.4369840262523286

Epoch: 6| Step: 8
Training loss: 2.661434454664595
Validation loss: 2.437185971393708

Epoch: 6| Step: 9
Training loss: 3.1629403090511534
Validation loss: 2.4366212927497424

Epoch: 6| Step: 10
Training loss: 2.1048372415064356
Validation loss: 2.435802815433246

Epoch: 6| Step: 11
Training loss: 3.0079895760071502
Validation loss: 2.4382182089421236

Epoch: 6| Step: 12
Training loss: 2.655472046866058
Validation loss: 2.4540133508820072

Epoch: 6| Step: 13
Training loss: 2.8017819796796672
Validation loss: 2.465862019569032

Epoch: 136| Step: 0
Training loss: 2.4271680519697107
Validation loss: 2.4838090157610337

Epoch: 6| Step: 1
Training loss: 2.640658948330224
Validation loss: 2.4866093712023045

Epoch: 6| Step: 2
Training loss: 2.983424489708264
Validation loss: 2.476017047821933

Epoch: 6| Step: 3
Training loss: 2.7823338486246825
Validation loss: 2.4660247354763487

Epoch: 6| Step: 4
Training loss: 2.929648600002162
Validation loss: 2.4622694571059496

Epoch: 6| Step: 5
Training loss: 2.4179917243519307
Validation loss: 2.4700519082759977

Epoch: 6| Step: 6
Training loss: 2.787497030350681
Validation loss: 2.4734483308258097

Epoch: 6| Step: 7
Training loss: 1.9233391619659557
Validation loss: 2.480877668893869

Epoch: 6| Step: 8
Training loss: 2.019714819351378
Validation loss: 2.4856511333639606

Epoch: 6| Step: 9
Training loss: 3.050353895824304
Validation loss: 2.482865703523346

Epoch: 6| Step: 10
Training loss: 2.794398228756321
Validation loss: 2.474133508737806

Epoch: 6| Step: 11
Training loss: 3.173700568350201
Validation loss: 2.469241405805321

Epoch: 6| Step: 12
Training loss: 2.3768474019344445
Validation loss: 2.466995627338526

Epoch: 6| Step: 13
Training loss: 3.1009562401905417
Validation loss: 2.4645498904797893

Epoch: 137| Step: 0
Training loss: 2.4257924544955607
Validation loss: 2.4620370997277177

Epoch: 6| Step: 1
Training loss: 3.25821615595419
Validation loss: 2.471540612952318

Epoch: 6| Step: 2
Training loss: 1.9830934486319802
Validation loss: 2.4527540885988404

Epoch: 6| Step: 3
Training loss: 2.9784378191681906
Validation loss: 2.4542530403611704

Epoch: 6| Step: 4
Training loss: 2.4909835346769635
Validation loss: 2.4490499630471354

Epoch: 6| Step: 5
Training loss: 2.4966643969122733
Validation loss: 2.453717325031349

Epoch: 6| Step: 6
Training loss: 2.708557139221586
Validation loss: 2.459256491761219

Epoch: 6| Step: 7
Training loss: 2.706993025692882
Validation loss: 2.480145593505071

Epoch: 6| Step: 8
Training loss: 3.2019170204575875
Validation loss: 2.498116495373803

Epoch: 6| Step: 9
Training loss: 1.6000027388310833
Validation loss: 2.5115593017058337

Epoch: 6| Step: 10
Training loss: 3.0668411626789625
Validation loss: 2.5306917357567453

Epoch: 6| Step: 11
Training loss: 2.8834828163456505
Validation loss: 2.542317609847515

Epoch: 6| Step: 12
Training loss: 2.559689725312067
Validation loss: 2.51278519305378

Epoch: 6| Step: 13
Training loss: 2.7729155573184694
Validation loss: 2.5036029868470555

Epoch: 138| Step: 0
Training loss: 2.7842011813829664
Validation loss: 2.4928087027411086

Epoch: 6| Step: 1
Training loss: 2.1772999146219822
Validation loss: 2.483076529539468

Epoch: 6| Step: 2
Training loss: 2.4688027291763066
Validation loss: 2.4723643269411846

Epoch: 6| Step: 3
Training loss: 3.24900611939328
Validation loss: 2.4711770603732135

Epoch: 6| Step: 4
Training loss: 2.600886076547512
Validation loss: 2.462651676278839

Epoch: 6| Step: 5
Training loss: 2.5683582610501388
Validation loss: 2.4524277735483153

Epoch: 6| Step: 6
Training loss: 2.358233042854675
Validation loss: 2.4563398967491676

Epoch: 6| Step: 7
Training loss: 2.762904666588276
Validation loss: 2.4590560354126914

Epoch: 6| Step: 8
Training loss: 2.1816282758645005
Validation loss: 2.457895903952619

Epoch: 6| Step: 9
Training loss: 3.1228187577921576
Validation loss: 2.434801838571717

Epoch: 6| Step: 10
Training loss: 2.4682602215469
Validation loss: 2.446235934495987

Epoch: 6| Step: 11
Training loss: 2.836008286446543
Validation loss: 2.445203145258749

Epoch: 6| Step: 12
Training loss: 2.6179733690695226
Validation loss: 2.4549393573495077

Epoch: 6| Step: 13
Training loss: 2.9066526072567496
Validation loss: 2.461542894494348

Epoch: 139| Step: 0
Training loss: 3.3493746216480678
Validation loss: 2.4802959355777463

Epoch: 6| Step: 1
Training loss: 1.9525245659097241
Validation loss: 2.477021687407566

Epoch: 6| Step: 2
Training loss: 2.6865812993587155
Validation loss: 2.4778981319394995

Epoch: 6| Step: 3
Training loss: 2.358570896580032
Validation loss: 2.4691564158687633

Epoch: 6| Step: 4
Training loss: 2.608943697981672
Validation loss: 2.4547262030013846

Epoch: 6| Step: 5
Training loss: 3.0645471075852915
Validation loss: 2.4625868414334993

Epoch: 6| Step: 6
Training loss: 3.1087705705220583
Validation loss: 2.448583813522085

Epoch: 6| Step: 7
Training loss: 2.703898941995686
Validation loss: 2.452620936856019

Epoch: 6| Step: 8
Training loss: 2.250107656658395
Validation loss: 2.4361563592782356

Epoch: 6| Step: 9
Training loss: 2.4528344826667636
Validation loss: 2.4459976672152695

Epoch: 6| Step: 10
Training loss: 2.706459766742181
Validation loss: 2.4249795017405766

Epoch: 6| Step: 11
Training loss: 2.7718452288588917
Validation loss: 2.419620161035322

Epoch: 6| Step: 12
Training loss: 2.210940195897484
Validation loss: 2.441095322102605

Epoch: 6| Step: 13
Training loss: 2.910408244647595
Validation loss: 2.4686828994614505

Epoch: 140| Step: 0
Training loss: 2.472064340624453
Validation loss: 2.5001279070138267

Epoch: 6| Step: 1
Training loss: 2.52970179553172
Validation loss: 2.537833316898923

Epoch: 6| Step: 2
Training loss: 2.8062017491871667
Validation loss: 2.5872021430404524

Epoch: 6| Step: 3
Training loss: 2.8503773355821145
Validation loss: 2.6436618837277432

Epoch: 6| Step: 4
Training loss: 2.2621013732779174
Validation loss: 2.5915888314821176

Epoch: 6| Step: 5
Training loss: 3.218620964352654
Validation loss: 2.53729768693454

Epoch: 6| Step: 6
Training loss: 2.866441510103977
Validation loss: 2.5113864421709575

Epoch: 6| Step: 7
Training loss: 1.9796190113001852
Validation loss: 2.498267657472224

Epoch: 6| Step: 8
Training loss: 2.7049085433080973
Validation loss: 2.4991696855467813

Epoch: 6| Step: 9
Training loss: 2.8586368129058624
Validation loss: 2.5118857916839095

Epoch: 6| Step: 10
Training loss: 2.7910846464086267
Validation loss: 2.5132785259276957

Epoch: 6| Step: 11
Training loss: 1.9073001907910951
Validation loss: 2.51220653581008

Epoch: 6| Step: 12
Training loss: 3.1591141801554556
Validation loss: 2.5159997239961354

Epoch: 6| Step: 13
Training loss: 3.146597729374985
Validation loss: 2.541676923898233

Epoch: 141| Step: 0
Training loss: 2.590272985822684
Validation loss: 2.536847682371738

Epoch: 6| Step: 1
Training loss: 2.6287050892924766
Validation loss: 2.5020274206600823

Epoch: 6| Step: 2
Training loss: 3.0148273262946663
Validation loss: 2.478680170406158

Epoch: 6| Step: 3
Training loss: 2.8323792552884886
Validation loss: 2.4485903718532094

Epoch: 6| Step: 4
Training loss: 2.727136589756188
Validation loss: 2.441852158119512

Epoch: 6| Step: 5
Training loss: 2.6404709629975303
Validation loss: 2.4506280597549317

Epoch: 6| Step: 6
Training loss: 2.259515667727015
Validation loss: 2.4461152083696063

Epoch: 6| Step: 7
Training loss: 2.5618090744823943
Validation loss: 2.435784661089294

Epoch: 6| Step: 8
Training loss: 2.782319966787251
Validation loss: 2.439497807094187

Epoch: 6| Step: 9
Training loss: 2.6286062264952745
Validation loss: 2.454091735597923

Epoch: 6| Step: 10
Training loss: 2.816455009980132
Validation loss: 2.450948808193894

Epoch: 6| Step: 11
Training loss: 2.563212411985694
Validation loss: 2.442168475603738

Epoch: 6| Step: 12
Training loss: 2.6749659277626625
Validation loss: 2.4600016851058406

Epoch: 6| Step: 13
Training loss: 2.621680840633593
Validation loss: 2.466449553084187

Epoch: 142| Step: 0
Training loss: 2.7308330156475304
Validation loss: 2.483990141610994

Epoch: 6| Step: 1
Training loss: 2.552629394240539
Validation loss: 2.4878015078736064

Epoch: 6| Step: 2
Training loss: 2.7262135804344125
Validation loss: 2.489314727222021

Epoch: 6| Step: 3
Training loss: 2.715730064124372
Validation loss: 2.483135765380679

Epoch: 6| Step: 4
Training loss: 3.4301903427738076
Validation loss: 2.494743956248097

Epoch: 6| Step: 5
Training loss: 2.5976815817608836
Validation loss: 2.497373389619998

Epoch: 6| Step: 6
Training loss: 2.4510905582876283
Validation loss: 2.4688738086663444

Epoch: 6| Step: 7
Training loss: 1.8195904130436154
Validation loss: 2.4556765799239506

Epoch: 6| Step: 8
Training loss: 2.5607919350217925
Validation loss: 2.4495707097083295

Epoch: 6| Step: 9
Training loss: 2.4867557658305732
Validation loss: 2.4409721918621043

Epoch: 6| Step: 10
Training loss: 2.8243961938010935
Validation loss: 2.4391604127653825

Epoch: 6| Step: 11
Training loss: 2.466730958083567
Validation loss: 2.432389986566975

Epoch: 6| Step: 12
Training loss: 2.7792756005422583
Validation loss: 2.418589191836388

Epoch: 6| Step: 13
Training loss: 3.068727661797357
Validation loss: 2.412363125059799

Epoch: 143| Step: 0
Training loss: 2.856355667663835
Validation loss: 2.4148390876470036

Epoch: 6| Step: 1
Training loss: 2.573971448489505
Validation loss: 2.407181296297066

Epoch: 6| Step: 2
Training loss: 2.22652951935552
Validation loss: 2.4196275670823146

Epoch: 6| Step: 3
Training loss: 3.0176697751049617
Validation loss: 2.4360281363227814

Epoch: 6| Step: 4
Training loss: 3.1825965115161465
Validation loss: 2.446639421362225

Epoch: 6| Step: 5
Training loss: 2.5493292655686255
Validation loss: 2.4396179648486838

Epoch: 6| Step: 6
Training loss: 2.5958059963625852
Validation loss: 2.4505578800742818

Epoch: 6| Step: 7
Training loss: 2.8193141195142104
Validation loss: 2.452597300147971

Epoch: 6| Step: 8
Training loss: 2.8699661635687095
Validation loss: 2.4582731111998184

Epoch: 6| Step: 9
Training loss: 2.1397012541261877
Validation loss: 2.4597312386439767

Epoch: 6| Step: 10
Training loss: 2.6450953818648197
Validation loss: 2.4629789641706403

Epoch: 6| Step: 11
Training loss: 2.4611293173012045
Validation loss: 2.4622238336631406

Epoch: 6| Step: 12
Training loss: 1.5199542008577358
Validation loss: 2.4665977730174893

Epoch: 6| Step: 13
Training loss: 3.3445805739125296
Validation loss: 2.4652246268346616

Epoch: 144| Step: 0
Training loss: 2.8213049497648903
Validation loss: 2.4699457776556177

Epoch: 6| Step: 1
Training loss: 3.42192265725589
Validation loss: 2.4750012067649125

Epoch: 6| Step: 2
Training loss: 2.220081413425816
Validation loss: 2.475506549489522

Epoch: 6| Step: 3
Training loss: 3.0277606504774432
Validation loss: 2.488255429875645

Epoch: 6| Step: 4
Training loss: 2.1886580535381452
Validation loss: 2.4926786162241457

Epoch: 6| Step: 5
Training loss: 2.9097813307150977
Validation loss: 2.479137361194209

Epoch: 6| Step: 6
Training loss: 2.5331351713008807
Validation loss: 2.4844430078439004

Epoch: 6| Step: 7
Training loss: 2.673192106719738
Validation loss: 2.504713035647133

Epoch: 6| Step: 8
Training loss: 2.4402678986737016
Validation loss: 2.518729662764115

Epoch: 6| Step: 9
Training loss: 2.457581572163555
Validation loss: 2.5276047033844544

Epoch: 6| Step: 10
Training loss: 2.93839412635696
Validation loss: 2.5685892675428694

Epoch: 6| Step: 11
Training loss: 2.548642159762823
Validation loss: 2.6001382107123345

Epoch: 6| Step: 12
Training loss: 2.66079610111779
Validation loss: 2.6421299011523356

Epoch: 6| Step: 13
Training loss: 2.9718889206039805
Validation loss: 2.6466839064018033

Epoch: 145| Step: 0
Training loss: 3.0477626974589036
Validation loss: 2.6235964851841227

Epoch: 6| Step: 1
Training loss: 2.43632772573199
Validation loss: 2.588831667772598

Epoch: 6| Step: 2
Training loss: 2.756492925824783
Validation loss: 2.600564809395627

Epoch: 6| Step: 3
Training loss: 2.845851415201571
Validation loss: 2.6089203475103333

Epoch: 6| Step: 4
Training loss: 2.8407979881062495
Validation loss: 2.5864822036575825

Epoch: 6| Step: 5
Training loss: 2.625895211295677
Validation loss: 2.5892629515825707

Epoch: 6| Step: 6
Training loss: 2.547418173691562
Validation loss: 2.5813052383388433

Epoch: 6| Step: 7
Training loss: 2.802442071538867
Validation loss: 2.5635125410501627

Epoch: 6| Step: 8
Training loss: 2.7228713094313894
Validation loss: 2.5439049450568803

Epoch: 6| Step: 9
Training loss: 3.0049965892397905
Validation loss: 2.5365513714624517

Epoch: 6| Step: 10
Training loss: 3.099001194419766
Validation loss: 2.5252589119322053

Epoch: 6| Step: 11
Training loss: 2.515664805221762
Validation loss: 2.5292629624671297

Epoch: 6| Step: 12
Training loss: 2.4867952661610047
Validation loss: 2.532825220372694

Epoch: 6| Step: 13
Training loss: 2.6768065332977136
Validation loss: 2.5343892137801993

Epoch: 146| Step: 0
Training loss: 2.0853997726848594
Validation loss: 2.5494640826318986

Epoch: 6| Step: 1
Training loss: 3.022268774182071
Validation loss: 2.5691396101370683

Epoch: 6| Step: 2
Training loss: 2.828098191613702
Validation loss: 2.589035313604671

Epoch: 6| Step: 3
Training loss: 2.9284457003623445
Validation loss: 2.59283686493613

Epoch: 6| Step: 4
Training loss: 2.976318509572247
Validation loss: 2.56136201510628

Epoch: 6| Step: 5
Training loss: 2.9308706920658985
Validation loss: 2.5452711031488837

Epoch: 6| Step: 6
Training loss: 3.0039741895356697
Validation loss: 2.540741395160296

Epoch: 6| Step: 7
Training loss: 3.1058833007505062
Validation loss: 2.5447638180539776

Epoch: 6| Step: 8
Training loss: 1.9666580105714984
Validation loss: 2.545792739818702

Epoch: 6| Step: 9
Training loss: 2.742730676482965
Validation loss: 2.5548455009259357

Epoch: 6| Step: 10
Training loss: 2.768762995773368
Validation loss: 2.5634807127622574

Epoch: 6| Step: 11
Training loss: 2.72013994838614
Validation loss: 2.536263050139634

Epoch: 6| Step: 12
Training loss: 2.451848663880981
Validation loss: 2.530735706508749

Epoch: 6| Step: 13
Training loss: 2.8897712065209586
Validation loss: 2.520378417179977

Epoch: 147| Step: 0
Training loss: 2.962775553189384
Validation loss: 2.515910718433706

Epoch: 6| Step: 1
Training loss: 2.2207168672617894
Validation loss: 2.513320671521413

Epoch: 6| Step: 2
Training loss: 2.4261824173238393
Validation loss: 2.5059759620761723

Epoch: 6| Step: 3
Training loss: 2.8900564923424357
Validation loss: 2.507937821040161

Epoch: 6| Step: 4
Training loss: 3.1562468273788973
Validation loss: 2.490415746915035

Epoch: 6| Step: 5
Training loss: 3.0130164372514567
Validation loss: 2.498853653428157

Epoch: 6| Step: 6
Training loss: 2.958562457027701
Validation loss: 2.5352324899618592

Epoch: 6| Step: 7
Training loss: 2.7136338426355486
Validation loss: 2.525611678632301

Epoch: 6| Step: 8
Training loss: 2.6418954174587514
Validation loss: 2.541090167781956

Epoch: 6| Step: 9
Training loss: 2.522867238710054
Validation loss: 2.5097524051502433

Epoch: 6| Step: 10
Training loss: 3.0703935685265846
Validation loss: 2.462279583502749

Epoch: 6| Step: 11
Training loss: 2.1595579563921414
Validation loss: 2.4336675569752813

Epoch: 6| Step: 12
Training loss: 2.30909230485463
Validation loss: 2.4052351217858714

Epoch: 6| Step: 13
Training loss: 2.445516267031748
Validation loss: 2.4157973261572154

Epoch: 148| Step: 0
Training loss: 2.6808028054942423
Validation loss: 2.415704425988123

Epoch: 6| Step: 1
Training loss: 2.665416921385307
Validation loss: 2.4281462327272143

Epoch: 6| Step: 2
Training loss: 2.8564993985264095
Validation loss: 2.4324697605104926

Epoch: 6| Step: 3
Training loss: 2.9129875593617105
Validation loss: 2.433222812458249

Epoch: 6| Step: 4
Training loss: 2.7950788303238623
Validation loss: 2.439979527888696

Epoch: 6| Step: 5
Training loss: 2.64695567759093
Validation loss: 2.4375269309618357

Epoch: 6| Step: 6
Training loss: 2.463033600906727
Validation loss: 2.4395879285920126

Epoch: 6| Step: 7
Training loss: 2.6455148420103174
Validation loss: 2.4519021297969346

Epoch: 6| Step: 8
Training loss: 2.7127781316669433
Validation loss: 2.479413143765058

Epoch: 6| Step: 9
Training loss: 3.2852921066587397
Validation loss: 2.516057597829895

Epoch: 6| Step: 10
Training loss: 2.602587798558685
Validation loss: 2.541907642169968

Epoch: 6| Step: 11
Training loss: 2.2712855690756952
Validation loss: 2.542001102768736

Epoch: 6| Step: 12
Training loss: 2.493171521544365
Validation loss: 2.550297742098127

Epoch: 6| Step: 13
Training loss: 2.0509800405884233
Validation loss: 2.5611699441943263

Epoch: 149| Step: 0
Training loss: 2.7507226167955907
Validation loss: 2.5392678414256395

Epoch: 6| Step: 1
Training loss: 3.1548761078076004
Validation loss: 2.5095646414442103

Epoch: 6| Step: 2
Training loss: 2.6601261355674293
Validation loss: 2.471650687054253

Epoch: 6| Step: 3
Training loss: 2.5099453516630517
Validation loss: 2.4656541176493088

Epoch: 6| Step: 4
Training loss: 2.2948880067314703
Validation loss: 2.447894202875254

Epoch: 6| Step: 5
Training loss: 2.466104176111399
Validation loss: 2.45557571203275

Epoch: 6| Step: 6
Training loss: 2.8163033094918393
Validation loss: 2.4469421077030127

Epoch: 6| Step: 7
Training loss: 3.157752859542406
Validation loss: 2.446228521499041

Epoch: 6| Step: 8
Training loss: 2.454005769680861
Validation loss: 2.453316211792284

Epoch: 6| Step: 9
Training loss: 2.936221229928696
Validation loss: 2.456484831887561

Epoch: 6| Step: 10
Training loss: 2.447689375910437
Validation loss: 2.4539330946825046

Epoch: 6| Step: 11
Training loss: 2.581347768931707
Validation loss: 2.4615016651938175

Epoch: 6| Step: 12
Training loss: 2.063315028210585
Validation loss: 2.471541306881981

Epoch: 6| Step: 13
Training loss: 2.446972658198682
Validation loss: 2.4781581760835083

Epoch: 150| Step: 0
Training loss: 2.508161764096464
Validation loss: 2.4743462257285054

Epoch: 6| Step: 1
Training loss: 2.9086589058979353
Validation loss: 2.4867734480687944

Epoch: 6| Step: 2
Training loss: 1.8558224632014495
Validation loss: 2.4743697893675565

Epoch: 6| Step: 3
Training loss: 2.718638889190794
Validation loss: 2.4613651422986664

Epoch: 6| Step: 4
Training loss: 3.226131530502067
Validation loss: 2.459029125471152

Epoch: 6| Step: 5
Training loss: 2.5954947061442453
Validation loss: 2.4649918928068995

Epoch: 6| Step: 6
Training loss: 2.436622265969143
Validation loss: 2.4718089967198678

Epoch: 6| Step: 7
Training loss: 3.009977596871278
Validation loss: 2.4491246566444

Epoch: 6| Step: 8
Training loss: 2.7251053990970227
Validation loss: 2.452019670203163

Epoch: 6| Step: 9
Training loss: 2.6536905860808364
Validation loss: 2.44294340574771

Epoch: 6| Step: 10
Training loss: 3.00183875636075
Validation loss: 2.4438923550306417

Epoch: 6| Step: 11
Training loss: 2.2591239525914926
Validation loss: 2.438775367582385

Epoch: 6| Step: 12
Training loss: 2.0746281394045254
Validation loss: 2.45311919159989

Epoch: 6| Step: 13
Training loss: 2.176162111106035
Validation loss: 2.444348946887676

Epoch: 151| Step: 0
Training loss: 2.4020217803806134
Validation loss: 2.454047882815898

Epoch: 6| Step: 1
Training loss: 1.9134675638895087
Validation loss: 2.452834220327891

Epoch: 6| Step: 2
Training loss: 2.9652818197857607
Validation loss: 2.4593131620891793

Epoch: 6| Step: 3
Training loss: 2.6676020670475675
Validation loss: 2.4576134487138064

Epoch: 6| Step: 4
Training loss: 2.6944040730216803
Validation loss: 2.4772154120550476

Epoch: 6| Step: 5
Training loss: 2.6177651749944215
Validation loss: 2.4962191017061683

Epoch: 6| Step: 6
Training loss: 2.448449508355155
Validation loss: 2.4992954358567316

Epoch: 6| Step: 7
Training loss: 2.697996003348046
Validation loss: 2.5170290689764228

Epoch: 6| Step: 8
Training loss: 2.751370262002923
Validation loss: 2.521842111627034

Epoch: 6| Step: 9
Training loss: 3.095635812310372
Validation loss: 2.5336070175061045

Epoch: 6| Step: 10
Training loss: 2.7683406794215353
Validation loss: 2.532093556231316

Epoch: 6| Step: 11
Training loss: 2.259599552629764
Validation loss: 2.51263458906928

Epoch: 6| Step: 12
Training loss: 2.715168051251949
Validation loss: 2.4779530294313616

Epoch: 6| Step: 13
Training loss: 2.8668620161282687
Validation loss: 2.463558157855863

Epoch: 152| Step: 0
Training loss: 2.408539908590259
Validation loss: 2.451507494918574

Epoch: 6| Step: 1
Training loss: 2.350177344265643
Validation loss: 2.462532835036098

Epoch: 6| Step: 2
Training loss: 2.8005205828511857
Validation loss: 2.4729990968123996

Epoch: 6| Step: 3
Training loss: 2.8638212727769288
Validation loss: 2.478692025772115

Epoch: 6| Step: 4
Training loss: 2.5331395008153064
Validation loss: 2.487104728650312

Epoch: 6| Step: 5
Training loss: 2.1650663726006445
Validation loss: 2.495272054249486

Epoch: 6| Step: 6
Training loss: 2.549491053635678
Validation loss: 2.5071033958432607

Epoch: 6| Step: 7
Training loss: 2.711427320043346
Validation loss: 2.5112660085671674

Epoch: 6| Step: 8
Training loss: 3.1273889184339634
Validation loss: 2.5039643982296487

Epoch: 6| Step: 9
Training loss: 2.7024037716484064
Validation loss: 2.4975443408176736

Epoch: 6| Step: 10
Training loss: 2.1294603099254634
Validation loss: 2.4817951284143773

Epoch: 6| Step: 11
Training loss: 3.0117646645535436
Validation loss: 2.491145487527935

Epoch: 6| Step: 12
Training loss: 2.5541482992170423
Validation loss: 2.491676316458843

Epoch: 6| Step: 13
Training loss: 3.7228230201856256
Validation loss: 2.498407885458482

Epoch: 153| Step: 0
Training loss: 2.5086726439694815
Validation loss: 2.5056825556139164

Epoch: 6| Step: 1
Training loss: 2.4304896560696814
Validation loss: 2.5195923001879614

Epoch: 6| Step: 2
Training loss: 2.843679070898149
Validation loss: 2.5185656095595883

Epoch: 6| Step: 3
Training loss: 2.7952550533526375
Validation loss: 2.513525295786042

Epoch: 6| Step: 4
Training loss: 3.08625919258785
Validation loss: 2.5247082784507366

Epoch: 6| Step: 5
Training loss: 2.874034885457577
Validation loss: 2.5394586352220805

Epoch: 6| Step: 6
Training loss: 3.0086069618396616
Validation loss: 2.536383982243293

Epoch: 6| Step: 7
Training loss: 2.5704442138317063
Validation loss: 2.5340301618141603

Epoch: 6| Step: 8
Training loss: 2.4641154765528155
Validation loss: 2.520294793643409

Epoch: 6| Step: 9
Training loss: 2.460343934183816
Validation loss: 2.5071684803582124

Epoch: 6| Step: 10
Training loss: 2.1906848066712326
Validation loss: 2.509429348071908

Epoch: 6| Step: 11
Training loss: 2.6796877669175796
Validation loss: 2.504021344180824

Epoch: 6| Step: 12
Training loss: 2.6580859851462955
Validation loss: 2.5102379698313046

Epoch: 6| Step: 13
Training loss: 2.3472712196287233
Validation loss: 2.498308191778836

Epoch: 154| Step: 0
Training loss: 1.6346956190207715
Validation loss: 2.4757589336518384

Epoch: 6| Step: 1
Training loss: 2.787758402116176
Validation loss: 2.4856314587597286

Epoch: 6| Step: 2
Training loss: 2.566308145955976
Validation loss: 2.4776737505494673

Epoch: 6| Step: 3
Training loss: 1.874861139877629
Validation loss: 2.469072079213176

Epoch: 6| Step: 4
Training loss: 2.6389697603471345
Validation loss: 2.478775511282558

Epoch: 6| Step: 5
Training loss: 2.874448142783118
Validation loss: 2.473800874544783

Epoch: 6| Step: 6
Training loss: 2.7935826193829243
Validation loss: 2.4853660282167165

Epoch: 6| Step: 7
Training loss: 3.203119789677546
Validation loss: 2.478183174513428

Epoch: 6| Step: 8
Training loss: 2.7474219635840225
Validation loss: 2.4939914834511074

Epoch: 6| Step: 9
Training loss: 2.391533473312341
Validation loss: 2.4854985572466384

Epoch: 6| Step: 10
Training loss: 2.5864349532149293
Validation loss: 2.503052543986503

Epoch: 6| Step: 11
Training loss: 2.4541920084743225
Validation loss: 2.5088543934872765

Epoch: 6| Step: 12
Training loss: 3.2550400021581014
Validation loss: 2.4986493943629395

Epoch: 6| Step: 13
Training loss: 2.4484066628350343
Validation loss: 2.505695444980762

Epoch: 155| Step: 0
Training loss: 3.0297569451874553
Validation loss: 2.5001444969667297

Epoch: 6| Step: 1
Training loss: 2.418341045652151
Validation loss: 2.4752273104666784

Epoch: 6| Step: 2
Training loss: 2.0863708731695225
Validation loss: 2.4727880056628035

Epoch: 6| Step: 3
Training loss: 2.7056909631278403
Validation loss: 2.47253074678058

Epoch: 6| Step: 4
Training loss: 2.7154312047080924
Validation loss: 2.4680303799732903

Epoch: 6| Step: 5
Training loss: 2.783890403081125
Validation loss: 2.46561272522949

Epoch: 6| Step: 6
Training loss: 2.8879953331103883
Validation loss: 2.4667291518026504

Epoch: 6| Step: 7
Training loss: 2.134616968784815
Validation loss: 2.466510777451656

Epoch: 6| Step: 8
Training loss: 2.58178146469906
Validation loss: 2.463900607961609

Epoch: 6| Step: 9
Training loss: 2.5280982281336555
Validation loss: 2.4718312995270795

Epoch: 6| Step: 10
Training loss: 2.0806930850787277
Validation loss: 2.4729451747460223

Epoch: 6| Step: 11
Training loss: 2.397985260416249
Validation loss: 2.4744801385615807

Epoch: 6| Step: 12
Training loss: 3.114508603495511
Validation loss: 2.4726583785417087

Epoch: 6| Step: 13
Training loss: 2.8313810878157883
Validation loss: 2.473315750027838

Epoch: 156| Step: 0
Training loss: 2.8560651790329934
Validation loss: 2.476984590218758

Epoch: 6| Step: 1
Training loss: 2.4151549598782704
Validation loss: 2.4791663588574258

Epoch: 6| Step: 2
Training loss: 3.1663993588778947
Validation loss: 2.4696081125771343

Epoch: 6| Step: 3
Training loss: 2.6409397276269853
Validation loss: 2.4661675172089357

Epoch: 6| Step: 4
Training loss: 3.0619658958085614
Validation loss: 2.4615238458038884

Epoch: 6| Step: 5
Training loss: 2.74544590217176
Validation loss: 2.46895753479596

Epoch: 6| Step: 6
Training loss: 2.4588825668335663
Validation loss: 2.4535178209702395

Epoch: 6| Step: 7
Training loss: 1.7901273665054585
Validation loss: 2.465154536154217

Epoch: 6| Step: 8
Training loss: 2.085211238086009
Validation loss: 2.466686471015939

Epoch: 6| Step: 9
Training loss: 2.248799639626294
Validation loss: 2.463837640396158

Epoch: 6| Step: 10
Training loss: 2.6057676861574617
Validation loss: 2.4677501038326266

Epoch: 6| Step: 11
Training loss: 2.8223767954964547
Validation loss: 2.469297675156595

Epoch: 6| Step: 12
Training loss: 2.396209477184961
Validation loss: 2.4736298919599995

Epoch: 6| Step: 13
Training loss: 2.743110436213769
Validation loss: 2.4781758441495567

Epoch: 157| Step: 0
Training loss: 2.0376421779336504
Validation loss: 2.465624636668735

Epoch: 6| Step: 1
Training loss: 3.0642547251442473
Validation loss: 2.483977053953359

Epoch: 6| Step: 2
Training loss: 2.278944130400591
Validation loss: 2.4894567694209098

Epoch: 6| Step: 3
Training loss: 2.591086433279315
Validation loss: 2.500306111740143

Epoch: 6| Step: 4
Training loss: 2.88127562538386
Validation loss: 2.5006226133481304

Epoch: 6| Step: 5
Training loss: 2.4489169626921066
Validation loss: 2.49633919524972

Epoch: 6| Step: 6
Training loss: 2.9656789857153245
Validation loss: 2.5068807439212404

Epoch: 6| Step: 7
Training loss: 2.027063956826399
Validation loss: 2.4991178504636578

Epoch: 6| Step: 8
Training loss: 1.776098599085393
Validation loss: 2.5017647318750313

Epoch: 6| Step: 9
Training loss: 2.939860592605554
Validation loss: 2.502672096406035

Epoch: 6| Step: 10
Training loss: 2.4218860256805477
Validation loss: 2.492430696783193

Epoch: 6| Step: 11
Training loss: 2.8505737262606727
Validation loss: 2.4729456412497637

Epoch: 6| Step: 12
Training loss: 2.819232681122443
Validation loss: 2.4590022006393797

Epoch: 6| Step: 13
Training loss: 2.8283144218278635
Validation loss: 2.447247233041518

Epoch: 158| Step: 0
Training loss: 2.070755130306909
Validation loss: 2.4499690856054683

Epoch: 6| Step: 1
Training loss: 3.004406553753066
Validation loss: 2.440519237806811

Epoch: 6| Step: 2
Training loss: 2.5350812950868016
Validation loss: 2.428592672226672

Epoch: 6| Step: 3
Training loss: 2.8909313142706394
Validation loss: 2.44222349812784

Epoch: 6| Step: 4
Training loss: 2.4280804290019202
Validation loss: 2.4335382479217413

Epoch: 6| Step: 5
Training loss: 2.679358815312695
Validation loss: 2.434026303324349

Epoch: 6| Step: 6
Training loss: 2.4072756872523002
Validation loss: 2.4521144052172112

Epoch: 6| Step: 7
Training loss: 3.3999368100745637
Validation loss: 2.450796470236687

Epoch: 6| Step: 8
Training loss: 2.4350383750821174
Validation loss: 2.4483429512491695

Epoch: 6| Step: 9
Training loss: 2.5131307047542246
Validation loss: 2.4600262834105444

Epoch: 6| Step: 10
Training loss: 2.7467782481994236
Validation loss: 2.468786485204311

Epoch: 6| Step: 11
Training loss: 2.2682081558066107
Validation loss: 2.471671630471812

Epoch: 6| Step: 12
Training loss: 2.145260657276568
Validation loss: 2.4918618529665553

Epoch: 6| Step: 13
Training loss: 2.5586804091359654
Validation loss: 2.499498225688472

Epoch: 159| Step: 0
Training loss: 2.89971188396533
Validation loss: 2.529269299436204

Epoch: 6| Step: 1
Training loss: 2.6675286886572693
Validation loss: 2.518200089776848

Epoch: 6| Step: 2
Training loss: 2.7713200612518527
Validation loss: 2.5154432025844256

Epoch: 6| Step: 3
Training loss: 2.3450161374966334
Validation loss: 2.503844468714039

Epoch: 6| Step: 4
Training loss: 2.713565487064554
Validation loss: 2.4802854031436254

Epoch: 6| Step: 5
Training loss: 2.2068595886988773
Validation loss: 2.446940381630531

Epoch: 6| Step: 6
Training loss: 2.768428437652723
Validation loss: 2.421694943829997

Epoch: 6| Step: 7
Training loss: 2.404007498388291
Validation loss: 2.432311438436889

Epoch: 6| Step: 8
Training loss: 2.469725017916678
Validation loss: 2.430424141522359

Epoch: 6| Step: 9
Training loss: 2.9867576155552276
Validation loss: 2.4312099043192914

Epoch: 6| Step: 10
Training loss: 2.3849155838140152
Validation loss: 2.454820472228632

Epoch: 6| Step: 11
Training loss: 1.9550432474567587
Validation loss: 2.4508929930805152

Epoch: 6| Step: 12
Training loss: 3.257441291426423
Validation loss: 2.4555414171751773

Epoch: 6| Step: 13
Training loss: 2.6517349465828426
Validation loss: 2.4434301139649897

Epoch: 160| Step: 0
Training loss: 2.563999388648569
Validation loss: 2.4425591274714793

Epoch: 6| Step: 1
Training loss: 2.7793895199334018
Validation loss: 2.430016852907447

Epoch: 6| Step: 2
Training loss: 2.8491551937360597
Validation loss: 2.4234393955025824

Epoch: 6| Step: 3
Training loss: 2.780102954028422
Validation loss: 2.43662520456331

Epoch: 6| Step: 4
Training loss: 2.239290073327085
Validation loss: 2.441003955010152

Epoch: 6| Step: 5
Training loss: 2.1244455624000627
Validation loss: 2.4409128386653336

Epoch: 6| Step: 6
Training loss: 2.2910302983665334
Validation loss: 2.4563378459108622

Epoch: 6| Step: 7
Training loss: 2.540450904952913
Validation loss: 2.4506950709221007

Epoch: 6| Step: 8
Training loss: 3.0059609002510146
Validation loss: 2.4702430354754417

Epoch: 6| Step: 9
Training loss: 2.26230404252856
Validation loss: 2.451748974829718

Epoch: 6| Step: 10
Training loss: 3.127893557832629
Validation loss: 2.4422829711527605

Epoch: 6| Step: 11
Training loss: 2.000335784380877
Validation loss: 2.4476033066259695

Epoch: 6| Step: 12
Training loss: 3.1656238612392293
Validation loss: 2.437410812071445

Epoch: 6| Step: 13
Training loss: 2.1734138361330273
Validation loss: 2.438131028796704

Epoch: 161| Step: 0
Training loss: 2.640388884512336
Validation loss: 2.451904388231786

Epoch: 6| Step: 1
Training loss: 2.6146244081307857
Validation loss: 2.4511116125339423

Epoch: 6| Step: 2
Training loss: 2.504495203319365
Validation loss: 2.442314294758798

Epoch: 6| Step: 3
Training loss: 2.6780966437851657
Validation loss: 2.4638231221573785

Epoch: 6| Step: 4
Training loss: 2.7553620514897927
Validation loss: 2.5018001894316595

Epoch: 6| Step: 5
Training loss: 2.74126086106347
Validation loss: 2.5152632694577886

Epoch: 6| Step: 6
Training loss: 2.809016974425371
Validation loss: 2.530022433253351

Epoch: 6| Step: 7
Training loss: 1.7275180847722933
Validation loss: 2.5069341252465045

Epoch: 6| Step: 8
Training loss: 2.6023974296005976
Validation loss: 2.535883098915452

Epoch: 6| Step: 9
Training loss: 2.3559447356382517
Validation loss: 2.540336703384762

Epoch: 6| Step: 10
Training loss: 2.711629729704191
Validation loss: 2.563974005075053

Epoch: 6| Step: 11
Training loss: 2.6085324326192243
Validation loss: 2.559598334838251

Epoch: 6| Step: 12
Training loss: 2.474755720163346
Validation loss: 2.5746195299710393

Epoch: 6| Step: 13
Training loss: 3.4230931173681705
Validation loss: 2.5531921074253847

Epoch: 162| Step: 0
Training loss: 2.230012489591785
Validation loss: 2.5295623537346863

Epoch: 6| Step: 1
Training loss: 2.2061153165431935
Validation loss: 2.5172165956883923

Epoch: 6| Step: 2
Training loss: 2.648352607559285
Validation loss: 2.511002155528279

Epoch: 6| Step: 3
Training loss: 2.539245129399475
Validation loss: 2.4813217188676555

Epoch: 6| Step: 4
Training loss: 2.540884637645182
Validation loss: 2.4626587540835487

Epoch: 6| Step: 5
Training loss: 2.6844020997567988
Validation loss: 2.4523777693363615

Epoch: 6| Step: 6
Training loss: 2.6555428854011818
Validation loss: 2.4592654135140557

Epoch: 6| Step: 7
Training loss: 2.9098304924639593
Validation loss: 2.454432918232325

Epoch: 6| Step: 8
Training loss: 3.0646891651944497
Validation loss: 2.457282030478387

Epoch: 6| Step: 9
Training loss: 2.506322685576588
Validation loss: 2.455179921767458

Epoch: 6| Step: 10
Training loss: 2.8019379550890666
Validation loss: 2.4477702170091473

Epoch: 6| Step: 11
Training loss: 2.4544534184318825
Validation loss: 2.4278423286743354

Epoch: 6| Step: 12
Training loss: 2.346765130083355
Validation loss: 2.4297466199002695

Epoch: 6| Step: 13
Training loss: 2.395894047064586
Validation loss: 2.434574069656933

Epoch: 163| Step: 0
Training loss: 2.368474931271394
Validation loss: 2.455536794238932

Epoch: 6| Step: 1
Training loss: 3.1454821931683323
Validation loss: 2.4726286052296436

Epoch: 6| Step: 2
Training loss: 2.5259126505726113
Validation loss: 2.4875617304225885

Epoch: 6| Step: 3
Training loss: 2.1183396473732206
Validation loss: 2.4897050035336763

Epoch: 6| Step: 4
Training loss: 1.768229361427832
Validation loss: 2.5044784988788873

Epoch: 6| Step: 5
Training loss: 2.334372311836952
Validation loss: 2.507875954558005

Epoch: 6| Step: 6
Training loss: 2.594890205985954
Validation loss: 2.5126189366008864

Epoch: 6| Step: 7
Training loss: 2.891393940695056
Validation loss: 2.4815067867473126

Epoch: 6| Step: 8
Training loss: 2.351700686833442
Validation loss: 2.4791635761636392

Epoch: 6| Step: 9
Training loss: 2.515350326801523
Validation loss: 2.4733264261582737

Epoch: 6| Step: 10
Training loss: 2.2389997091493337
Validation loss: 2.4558401095233235

Epoch: 6| Step: 11
Training loss: 2.7257722512793925
Validation loss: 2.454651469931258

Epoch: 6| Step: 12
Training loss: 2.7690439589163502
Validation loss: 2.4571260776692267

Epoch: 6| Step: 13
Training loss: 3.227646615549125
Validation loss: 2.4459773351143634

Epoch: 164| Step: 0
Training loss: 2.591669374159925
Validation loss: 2.4389413285430845

Epoch: 6| Step: 1
Training loss: 2.6403875300604884
Validation loss: 2.432452958780488

Epoch: 6| Step: 2
Training loss: 2.771304403621908
Validation loss: 2.4331074048303933

Epoch: 6| Step: 3
Training loss: 2.558848500855334
Validation loss: 2.4452711459154206

Epoch: 6| Step: 4
Training loss: 2.9322368465378674
Validation loss: 2.4515966280341384

Epoch: 6| Step: 5
Training loss: 2.7032909893603274
Validation loss: 2.4414382684392364

Epoch: 6| Step: 6
Training loss: 2.4503709434425494
Validation loss: 2.45263284658493

Epoch: 6| Step: 7
Training loss: 2.4198551738373544
Validation loss: 2.454726683411206

Epoch: 6| Step: 8
Training loss: 1.9473714694505275
Validation loss: 2.4642976004627384

Epoch: 6| Step: 9
Training loss: 2.3380150375469997
Validation loss: 2.465232763168777

Epoch: 6| Step: 10
Training loss: 2.8655495603525885
Validation loss: 2.465992692160822

Epoch: 6| Step: 11
Training loss: 2.7166571618910447
Validation loss: 2.475296304980326

Epoch: 6| Step: 12
Training loss: 2.5013501336273007
Validation loss: 2.490099206063318

Epoch: 6| Step: 13
Training loss: 1.5123725679798783
Validation loss: 2.5020025918162405

Epoch: 165| Step: 0
Training loss: 2.6457500494717534
Validation loss: 2.503865245236141

Epoch: 6| Step: 1
Training loss: 2.1419558877757034
Validation loss: 2.5206761319203457

Epoch: 6| Step: 2
Training loss: 3.112805491702751
Validation loss: 2.528338818396493

Epoch: 6| Step: 3
Training loss: 2.049409302066388
Validation loss: 2.517536266561932

Epoch: 6| Step: 4
Training loss: 2.6673172117491504
Validation loss: 2.5200093087914612

Epoch: 6| Step: 5
Training loss: 2.4356408487283465
Validation loss: 2.509692803621557

Epoch: 6| Step: 6
Training loss: 2.116750073729487
Validation loss: 2.509370341630137

Epoch: 6| Step: 7
Training loss: 2.469669991505618
Validation loss: 2.4914928240507628

Epoch: 6| Step: 8
Training loss: 2.241207958876016
Validation loss: 2.48390990237935

Epoch: 6| Step: 9
Training loss: 3.152987162788021
Validation loss: 2.478989827925717

Epoch: 6| Step: 10
Training loss: 2.361006520017922
Validation loss: 2.4775256572404074

Epoch: 6| Step: 11
Training loss: 2.364842931358516
Validation loss: 2.461819010006243

Epoch: 6| Step: 12
Training loss: 2.51185771267028
Validation loss: 2.466898812761147

Epoch: 6| Step: 13
Training loss: 2.7048344140836207
Validation loss: 2.465408833765914

Epoch: 166| Step: 0
Training loss: 2.3487504640165624
Validation loss: 2.47155632226894

Epoch: 6| Step: 1
Training loss: 3.2031768050307665
Validation loss: 2.458859841090615

Epoch: 6| Step: 2
Training loss: 2.167592938816461
Validation loss: 2.4670983726061264

Epoch: 6| Step: 3
Training loss: 2.8368133789685084
Validation loss: 2.485880614218863

Epoch: 6| Step: 4
Training loss: 2.372633909862002
Validation loss: 2.4842827665595957

Epoch: 6| Step: 5
Training loss: 2.594423505365944
Validation loss: 2.481060791157944

Epoch: 6| Step: 6
Training loss: 2.314098218272564
Validation loss: 2.4691203815533345

Epoch: 6| Step: 7
Training loss: 2.245263518434287
Validation loss: 2.4586613131967723

Epoch: 6| Step: 8
Training loss: 2.3155570572372093
Validation loss: 2.4549153842507723

Epoch: 6| Step: 9
Training loss: 2.399114755446735
Validation loss: 2.456492534846528

Epoch: 6| Step: 10
Training loss: 2.482904922944952
Validation loss: 2.469637026973664

Epoch: 6| Step: 11
Training loss: 2.4921166101974483
Validation loss: 2.4602992899460507

Epoch: 6| Step: 12
Training loss: 2.5612168239457382
Validation loss: 2.456872725847821

Epoch: 6| Step: 13
Training loss: 2.557834285393967
Validation loss: 2.459810442717329

Epoch: 167| Step: 0
Training loss: 2.426049848788135
Validation loss: 2.432871010405029

Epoch: 6| Step: 1
Training loss: 2.485065484210714
Validation loss: 2.432153783819136

Epoch: 6| Step: 2
Training loss: 2.129457846760619
Validation loss: 2.4320649384811355

Epoch: 6| Step: 3
Training loss: 2.4759304070313943
Validation loss: 2.42436067099004

Epoch: 6| Step: 4
Training loss: 2.325174189779635
Validation loss: 2.446840788591434

Epoch: 6| Step: 5
Training loss: 2.680100923459865
Validation loss: 2.4401078021854525

Epoch: 6| Step: 6
Training loss: 2.9113496727135133
Validation loss: 2.449259099588543

Epoch: 6| Step: 7
Training loss: 2.606678374508893
Validation loss: 2.450654917583782

Epoch: 6| Step: 8
Training loss: 3.0969888706617015
Validation loss: 2.4620032593239283

Epoch: 6| Step: 9
Training loss: 2.53755222886929
Validation loss: 2.4765066162089764

Epoch: 6| Step: 10
Training loss: 2.531859995492184
Validation loss: 2.4822900409732838

Epoch: 6| Step: 11
Training loss: 2.52720026142497
Validation loss: 2.452375691663833

Epoch: 6| Step: 12
Training loss: 2.213764122649195
Validation loss: 2.4331565486202353

Epoch: 6| Step: 13
Training loss: 2.2791372470479585
Validation loss: 2.4326148131497733

Epoch: 168| Step: 0
Training loss: 3.0520507671888497
Validation loss: 2.4348762269695134

Epoch: 6| Step: 1
Training loss: 2.230998014865541
Validation loss: 2.43073138146484

Epoch: 6| Step: 2
Training loss: 2.675689829357515
Validation loss: 2.4366034180596383

Epoch: 6| Step: 3
Training loss: 2.501914816927161
Validation loss: 2.429377441332421

Epoch: 6| Step: 4
Training loss: 2.6014923911055794
Validation loss: 2.4384096287333876

Epoch: 6| Step: 5
Training loss: 2.648790274111797
Validation loss: 2.4402379429062244

Epoch: 6| Step: 6
Training loss: 2.3447199531026692
Validation loss: 2.424298346190033

Epoch: 6| Step: 7
Training loss: 2.1538451785567454
Validation loss: 2.4298770006187986

Epoch: 6| Step: 8
Training loss: 2.4930324736376415
Validation loss: 2.433015539674089

Epoch: 6| Step: 9
Training loss: 3.1414951618308504
Validation loss: 2.4387476977393505

Epoch: 6| Step: 10
Training loss: 2.0211104632299635
Validation loss: 2.449662611246394

Epoch: 6| Step: 11
Training loss: 2.803768421780956
Validation loss: 2.4514863917847665

Epoch: 6| Step: 12
Training loss: 2.100071147440082
Validation loss: 2.443860774711717

Epoch: 6| Step: 13
Training loss: 1.5139601697482357
Validation loss: 2.461693998815146

Epoch: 169| Step: 0
Training loss: 2.3009380293636603
Validation loss: 2.455614087378167

Epoch: 6| Step: 1
Training loss: 2.6238467089898014
Validation loss: 2.4710453796232943

Epoch: 6| Step: 2
Training loss: 2.420324210525858
Validation loss: 2.4639937172451565

Epoch: 6| Step: 3
Training loss: 2.251385262348011
Validation loss: 2.457602973456137

Epoch: 6| Step: 4
Training loss: 2.9656011646788136
Validation loss: 2.457058038879667

Epoch: 6| Step: 5
Training loss: 2.8145399536885995
Validation loss: 2.4465471914503283

Epoch: 6| Step: 6
Training loss: 2.563998272804476
Validation loss: 2.4309128827850137

Epoch: 6| Step: 7
Training loss: 2.968178463179434
Validation loss: 2.4317619890761812

Epoch: 6| Step: 8
Training loss: 2.1492818387033785
Validation loss: 2.4391797138782234

Epoch: 6| Step: 9
Training loss: 2.1109516044501273
Validation loss: 2.4313331003314858

Epoch: 6| Step: 10
Training loss: 2.4211958394371393
Validation loss: 2.427933808826553

Epoch: 6| Step: 11
Training loss: 2.2599671322618406
Validation loss: 2.440585453002483

Epoch: 6| Step: 12
Training loss: 2.6960946979813967
Validation loss: 2.444732508119755

Epoch: 6| Step: 13
Training loss: 1.9307206820423404
Validation loss: 2.4515816137921798

Epoch: 170| Step: 0
Training loss: 2.7388102283062263
Validation loss: 2.4666910917635385

Epoch: 6| Step: 1
Training loss: 2.73487884239179
Validation loss: 2.4991398910968314

Epoch: 6| Step: 2
Training loss: 2.430998911309322
Validation loss: 2.4990308441764166

Epoch: 6| Step: 3
Training loss: 3.196255495785019
Validation loss: 2.5098649902387984

Epoch: 6| Step: 4
Training loss: 2.6736781410523065
Validation loss: 2.4680060816593654

Epoch: 6| Step: 5
Training loss: 2.0926243047583766
Validation loss: 2.469484227569489

Epoch: 6| Step: 6
Training loss: 2.258711269703154
Validation loss: 2.4547922689129518

Epoch: 6| Step: 7
Training loss: 2.3258043025997908
Validation loss: 2.442711998560494

Epoch: 6| Step: 8
Training loss: 2.030753911400747
Validation loss: 2.4290511668990074

Epoch: 6| Step: 9
Training loss: 2.0458518230071454
Validation loss: 2.4216728398647973

Epoch: 6| Step: 10
Training loss: 2.6480961132297187
Validation loss: 2.4315773017493587

Epoch: 6| Step: 11
Training loss: 2.551619994992678
Validation loss: 2.4218504355008847

Epoch: 6| Step: 12
Training loss: 2.7728319823424257
Validation loss: 2.4230649810584985

Epoch: 6| Step: 13
Training loss: 3.130548815159131
Validation loss: 2.4324343604938248

Epoch: 171| Step: 0
Training loss: 1.7975331303669608
Validation loss: 2.4450265664217277

Epoch: 6| Step: 1
Training loss: 2.563885942014041
Validation loss: 2.4436025382355955

Epoch: 6| Step: 2
Training loss: 2.8559448012352475
Validation loss: 2.44968600888553

Epoch: 6| Step: 3
Training loss: 2.9137026485357893
Validation loss: 2.4453293727269187

Epoch: 6| Step: 4
Training loss: 2.5157029039155323
Validation loss: 2.4403282650360296

Epoch: 6| Step: 5
Training loss: 2.576171875
Validation loss: 2.4539429065493255

Epoch: 6| Step: 6
Training loss: 2.320165969897122
Validation loss: 2.4562328135644202

Epoch: 6| Step: 7
Training loss: 2.229224183478431
Validation loss: 2.47417559685993

Epoch: 6| Step: 8
Training loss: 2.8371095363486116
Validation loss: 2.482318674422844

Epoch: 6| Step: 9
Training loss: 2.6199259992151545
Validation loss: 2.5083663922170927

Epoch: 6| Step: 10
Training loss: 2.0171818597952593
Validation loss: 2.5180214298023205

Epoch: 6| Step: 11
Training loss: 2.0283047965222623
Validation loss: 2.5041463471668446

Epoch: 6| Step: 12
Training loss: 2.692387594357832
Validation loss: 2.506584794414286

Epoch: 6| Step: 13
Training loss: 2.669380674505756
Validation loss: 2.486459450046781

Epoch: 172| Step: 0
Training loss: 2.7737411117927038
Validation loss: 2.488110210510557

Epoch: 6| Step: 1
Training loss: 2.8158398612937283
Validation loss: 2.4914444131802753

Epoch: 6| Step: 2
Training loss: 2.621294585264002
Validation loss: 2.4785809316585388

Epoch: 6| Step: 3
Training loss: 2.1158377648880977
Validation loss: 2.4756152304736427

Epoch: 6| Step: 4
Training loss: 2.1429228318454747
Validation loss: 2.4843391786844644

Epoch: 6| Step: 5
Training loss: 2.5106489356345563
Validation loss: 2.4665657236346985

Epoch: 6| Step: 6
Training loss: 2.505951377981499
Validation loss: 2.4510168031983484

Epoch: 6| Step: 7
Training loss: 2.3056785392387535
Validation loss: 2.425000812288078

Epoch: 6| Step: 8
Training loss: 2.4647393786403384
Validation loss: 2.4485577224139687

Epoch: 6| Step: 9
Training loss: 2.710721493780891
Validation loss: 2.4486884075961752

Epoch: 6| Step: 10
Training loss: 2.473139470086751
Validation loss: 2.4599466183600844

Epoch: 6| Step: 11
Training loss: 2.1106448272053937
Validation loss: 2.459707839107973

Epoch: 6| Step: 12
Training loss: 2.6566475065905304
Validation loss: 2.47723082459488

Epoch: 6| Step: 13
Training loss: 2.545606425943662
Validation loss: 2.478249895758874

Epoch: 173| Step: 0
Training loss: 2.6664128381405754
Validation loss: 2.4741476286836894

Epoch: 6| Step: 1
Training loss: 1.9118791856623283
Validation loss: 2.4659740489825817

Epoch: 6| Step: 2
Training loss: 2.6810101950941423
Validation loss: 2.474557445026666

Epoch: 6| Step: 3
Training loss: 2.541353195954737
Validation loss: 2.442375961442168

Epoch: 6| Step: 4
Training loss: 2.389112804574317
Validation loss: 2.442448556276635

Epoch: 6| Step: 5
Training loss: 2.469836032382609
Validation loss: 2.438327714505364

Epoch: 6| Step: 6
Training loss: 2.4603082730424006
Validation loss: 2.4337979875597955

Epoch: 6| Step: 7
Training loss: 2.5523309600481596
Validation loss: 2.423329757223106

Epoch: 6| Step: 8
Training loss: 2.3384608288041866
Validation loss: 2.416208558656501

Epoch: 6| Step: 9
Training loss: 2.766373786207914
Validation loss: 2.416550663917454

Epoch: 6| Step: 10
Training loss: 2.261700934832416
Validation loss: 2.422669148251652

Epoch: 6| Step: 11
Training loss: 2.4347539251797046
Validation loss: 2.416807686832313

Epoch: 6| Step: 12
Training loss: 2.6448787759501258
Validation loss: 2.4191354882194016

Epoch: 6| Step: 13
Training loss: 2.129330206137606
Validation loss: 2.4283391664666514

Epoch: 174| Step: 0
Training loss: 2.670694815564309
Validation loss: 2.4356065152660356

Epoch: 6| Step: 1
Training loss: 2.848857610527173
Validation loss: 2.430319675967345

Epoch: 6| Step: 2
Training loss: 2.10494937754309
Validation loss: 2.432254189574982

Epoch: 6| Step: 3
Training loss: 2.2039178814829543
Validation loss: 2.437220005963987

Epoch: 6| Step: 4
Training loss: 2.3947849357104416
Validation loss: 2.4783516913862136

Epoch: 6| Step: 5
Training loss: 2.159051374593658
Validation loss: 2.498795411917665

Epoch: 6| Step: 6
Training loss: 2.767607242536048
Validation loss: 2.500833401666375

Epoch: 6| Step: 7
Training loss: 2.0379545629151283
Validation loss: 2.536400197593782

Epoch: 6| Step: 8
Training loss: 3.0207030871144767
Validation loss: 2.561613292132302

Epoch: 6| Step: 9
Training loss: 3.242477367266252
Validation loss: 2.5491256045536064

Epoch: 6| Step: 10
Training loss: 2.7558991708457268
Validation loss: 2.5256224473525086

Epoch: 6| Step: 11
Training loss: 1.9707776481821127
Validation loss: 2.514187193448723

Epoch: 6| Step: 12
Training loss: 2.2350249512237608
Validation loss: 2.492368817729336

Epoch: 6| Step: 13
Training loss: 1.7984683726003226
Validation loss: 2.475566057597574

Epoch: 175| Step: 0
Training loss: 2.187438854997837
Validation loss: 2.472863038133769

Epoch: 6| Step: 1
Training loss: 2.18083242884515
Validation loss: 2.4668051017598263

Epoch: 6| Step: 2
Training loss: 2.734641274702434
Validation loss: 2.462335978629195

Epoch: 6| Step: 3
Training loss: 2.424504581458888
Validation loss: 2.4346469413487863

Epoch: 6| Step: 4
Training loss: 2.844164639939902
Validation loss: 2.413464514187305

Epoch: 6| Step: 5
Training loss: 2.141601785154457
Validation loss: 2.4118740198628137

Epoch: 6| Step: 6
Training loss: 2.0967708828996976
Validation loss: 2.3988565453852924

Epoch: 6| Step: 7
Training loss: 2.1043637123632246
Validation loss: 2.4068382171749665

Epoch: 6| Step: 8
Training loss: 3.2186126679687153
Validation loss: 2.391330947465187

Epoch: 6| Step: 9
Training loss: 2.5434763880736604
Validation loss: 2.3922590772385353

Epoch: 6| Step: 10
Training loss: 2.768267301414605
Validation loss: 2.3884019750936405

Epoch: 6| Step: 11
Training loss: 1.6756115807490723
Validation loss: 2.381655150311276

Epoch: 6| Step: 12
Training loss: 2.7929757498273298
Validation loss: 2.372659201086359

Epoch: 6| Step: 13
Training loss: 1.995451284434738
Validation loss: 2.377342305035657

Epoch: 176| Step: 0
Training loss: 2.51110224773827
Validation loss: 2.3592124371727214

Epoch: 6| Step: 1
Training loss: 1.998479801830833
Validation loss: 2.3730289065752075

Epoch: 6| Step: 2
Training loss: 2.498633583490364
Validation loss: 2.3771821280605545

Epoch: 6| Step: 3
Training loss: 2.7640930070589818
Validation loss: 2.388111979960771

Epoch: 6| Step: 4
Training loss: 2.2328735855748114
Validation loss: 2.3875615819449454

Epoch: 6| Step: 5
Training loss: 2.3193847651110304
Validation loss: 2.3935436694806276

Epoch: 6| Step: 6
Training loss: 2.6838275746477183
Validation loss: 2.400337962996665

Epoch: 6| Step: 7
Training loss: 2.602780260428438
Validation loss: 2.389727848853864

Epoch: 6| Step: 8
Training loss: 2.482949093613691
Validation loss: 2.397557910635229

Epoch: 6| Step: 9
Training loss: 2.0160203885985064
Validation loss: 2.397495495368968

Epoch: 6| Step: 10
Training loss: 2.336399810869901
Validation loss: 2.4087195996337623

Epoch: 6| Step: 11
Training loss: 2.6007938566902142
Validation loss: 2.421239998699097

Epoch: 6| Step: 12
Training loss: 2.490385354644965
Validation loss: 2.407338485773304

Epoch: 6| Step: 13
Training loss: 2.619450470463588
Validation loss: 2.4031249540851625

Epoch: 177| Step: 0
Training loss: 2.5859801873777952
Validation loss: 2.4076987503675196

Epoch: 6| Step: 1
Training loss: 2.7585528625379396
Validation loss: 2.3927256163222297

Epoch: 6| Step: 2
Training loss: 2.2396121237626807
Validation loss: 2.3764528753917364

Epoch: 6| Step: 3
Training loss: 2.31076335134738
Validation loss: 2.3730315744344037

Epoch: 6| Step: 4
Training loss: 2.4441517765472986
Validation loss: 2.371302549783938

Epoch: 6| Step: 5
Training loss: 2.8288409765214406
Validation loss: 2.374218569849026

Epoch: 6| Step: 6
Training loss: 2.383547610096078
Validation loss: 2.3722785529986554

Epoch: 6| Step: 7
Training loss: 2.294113990944758
Validation loss: 2.37885304449128

Epoch: 6| Step: 8
Training loss: 2.3318277906037013
Validation loss: 2.3934978296056486

Epoch: 6| Step: 9
Training loss: 2.324193515159752
Validation loss: 2.3911890228752664

Epoch: 6| Step: 10
Training loss: 2.7321557330514663
Validation loss: 2.389081296360799

Epoch: 6| Step: 11
Training loss: 2.163303614012075
Validation loss: 2.3745790744343247

Epoch: 6| Step: 12
Training loss: 2.5434298939537854
Validation loss: 2.3682882150781803

Epoch: 6| Step: 13
Training loss: 2.130499847039676
Validation loss: 2.3781388877471876

Epoch: 178| Step: 0
Training loss: 2.0794515176355466
Validation loss: 2.391017347848982

Epoch: 6| Step: 1
Training loss: 2.719588490239635
Validation loss: 2.40332607484888

Epoch: 6| Step: 2
Training loss: 2.8706705417255494
Validation loss: 2.4235069881403883

Epoch: 6| Step: 3
Training loss: 2.5199564730200255
Validation loss: 2.428501766885591

Epoch: 6| Step: 4
Training loss: 2.4483991647919274
Validation loss: 2.445327384992802

Epoch: 6| Step: 5
Training loss: 2.188533756678172
Validation loss: 2.4364609366562884

Epoch: 6| Step: 6
Training loss: 2.147481143677674
Validation loss: 2.440844180930969

Epoch: 6| Step: 7
Training loss: 2.3843506898053186
Validation loss: 2.4368603731935763

Epoch: 6| Step: 8
Training loss: 2.5426120771613507
Validation loss: 2.4331593259807227

Epoch: 6| Step: 9
Training loss: 2.4291742402139143
Validation loss: 2.428208140975409

Epoch: 6| Step: 10
Training loss: 2.2565966437598397
Validation loss: 2.4464360276710972

Epoch: 6| Step: 11
Training loss: 2.340278394065748
Validation loss: 2.4300707569638282

Epoch: 6| Step: 12
Training loss: 2.68332631917791
Validation loss: 2.4408801526991906

Epoch: 6| Step: 13
Training loss: 1.9187014048632398
Validation loss: 2.4291701475446463

Epoch: 179| Step: 0
Training loss: 1.7770771874712457
Validation loss: 2.419088580749292

Epoch: 6| Step: 1
Training loss: 2.2118136014713827
Validation loss: 2.4142307077270586

Epoch: 6| Step: 2
Training loss: 1.8871153736433717
Validation loss: 2.4114252654867694

Epoch: 6| Step: 3
Training loss: 2.5371920694760397
Validation loss: 2.4046711743505234

Epoch: 6| Step: 4
Training loss: 2.566449355136483
Validation loss: 2.405922568984125

Epoch: 6| Step: 5
Training loss: 1.8521472635238292
Validation loss: 2.4017393709708297

Epoch: 6| Step: 6
Training loss: 2.841344801348715
Validation loss: 2.3927852535768226

Epoch: 6| Step: 7
Training loss: 2.296252523139477
Validation loss: 2.3604832201816524

Epoch: 6| Step: 8
Training loss: 2.7107387326942285
Validation loss: 2.3670374892046224

Epoch: 6| Step: 9
Training loss: 2.271036669758858
Validation loss: 2.3821087364627296

Epoch: 6| Step: 10
Training loss: 2.841242932211413
Validation loss: 2.3653526693527374

Epoch: 6| Step: 11
Training loss: 2.978006168008108
Validation loss: 2.3493124547560957

Epoch: 6| Step: 12
Training loss: 2.3442297889446
Validation loss: 2.3247034753328712

Epoch: 6| Step: 13
Training loss: 1.4521536913573418
Validation loss: 2.3195576845131485

Epoch: 180| Step: 0
Training loss: 2.0864798880073305
Validation loss: 2.3328669700178133

Epoch: 6| Step: 1
Training loss: 2.6353917378288196
Validation loss: 2.344962719512224

Epoch: 6| Step: 2
Training loss: 2.2965149889256877
Validation loss: 2.3688711836860463

Epoch: 6| Step: 3
Training loss: 2.277765513079532
Validation loss: 2.388913743116445

Epoch: 6| Step: 4
Training loss: 2.89736795356572
Validation loss: 2.390732695949726

Epoch: 6| Step: 5
Training loss: 2.47530489498165
Validation loss: 2.393598274960071

Epoch: 6| Step: 6
Training loss: 2.6149223887959407
Validation loss: 2.3750485553970075

Epoch: 6| Step: 7
Training loss: 2.0605584456132484
Validation loss: 2.353476309240487

Epoch: 6| Step: 8
Training loss: 1.8410682571952561
Validation loss: 2.358605955782299

Epoch: 6| Step: 9
Training loss: 2.7203850926546496
Validation loss: 2.3526580643823314

Epoch: 6| Step: 10
Training loss: 2.024886389477026
Validation loss: 2.3629031456598693

Epoch: 6| Step: 11
Training loss: 2.3425975763767433
Validation loss: 2.3742232550224482

Epoch: 6| Step: 12
Training loss: 2.528195268670583
Validation loss: 2.384358697840156

Epoch: 6| Step: 13
Training loss: 1.7916840249337038
Validation loss: 2.4112868514601704

Epoch: 181| Step: 0
Training loss: 1.9619036114548667
Validation loss: 2.443404948834654

Epoch: 6| Step: 1
Training loss: 2.6962842875614186
Validation loss: 2.459873781211789

Epoch: 6| Step: 2
Training loss: 2.4830261023351987
Validation loss: 2.457154243763983

Epoch: 6| Step: 3
Training loss: 2.2932357502661667
Validation loss: 2.428296925778439

Epoch: 6| Step: 4
Training loss: 2.191945273189538
Validation loss: 2.424002021863908

Epoch: 6| Step: 5
Training loss: 2.301187113535152
Validation loss: 2.4238105325028263

Epoch: 6| Step: 6
Training loss: 2.553534758053941
Validation loss: 2.4234914899308797

Epoch: 6| Step: 7
Training loss: 1.958097734550645
Validation loss: 2.42995554040313

Epoch: 6| Step: 8
Training loss: 2.3774240069674213
Validation loss: 2.4409945196333944

Epoch: 6| Step: 9
Training loss: 2.3878767385380106
Validation loss: 2.4430491920255286

Epoch: 6| Step: 10
Training loss: 1.7942233215449195
Validation loss: 2.4393518763269997

Epoch: 6| Step: 11
Training loss: 2.8168430280680163
Validation loss: 2.433538432277625

Epoch: 6| Step: 12
Training loss: 2.8493270681892793
Validation loss: 2.4480991027615517

Epoch: 6| Step: 13
Training loss: 1.8840410331987494
Validation loss: 2.4384983186011095

Epoch: 182| Step: 0
Training loss: 2.407117216710252
Validation loss: 2.431055596554153

Epoch: 6| Step: 1
Training loss: 2.0014832480208655
Validation loss: 2.435737111727837

Epoch: 6| Step: 2
Training loss: 1.5328888200430706
Validation loss: 2.4146214293537605

Epoch: 6| Step: 3
Training loss: 2.054394138990937
Validation loss: 2.403831928463503

Epoch: 6| Step: 4
Training loss: 2.7408500518087897
Validation loss: 2.4079209646526074

Epoch: 6| Step: 5
Training loss: 2.7384353572563263
Validation loss: 2.3938060697491075

Epoch: 6| Step: 6
Training loss: 1.4558757055383562
Validation loss: 2.3936173543990673

Epoch: 6| Step: 7
Training loss: 2.6681501513984767
Validation loss: 2.427142028507291

Epoch: 6| Step: 8
Training loss: 2.3885263443888065
Validation loss: 2.456416131404073

Epoch: 6| Step: 9
Training loss: 2.403660557551281
Validation loss: 2.4568587320083703

Epoch: 6| Step: 10
Training loss: 2.2972227079900156
Validation loss: 2.433226976277144

Epoch: 6| Step: 11
Training loss: 2.5996926492813603
Validation loss: 2.4382764527762113

Epoch: 6| Step: 12
Training loss: 2.185212819714329
Validation loss: 2.4170033372787794

Epoch: 6| Step: 13
Training loss: 2.2428431599001497
Validation loss: 2.408806633628579

Epoch: 183| Step: 0
Training loss: 1.5507428142867572
Validation loss: 2.408894756388674

Epoch: 6| Step: 1
Training loss: 1.8653381638335986
Validation loss: 2.415786218566388

Epoch: 6| Step: 2
Training loss: 2.245724961232222
Validation loss: 2.4064509171131867

Epoch: 6| Step: 3
Training loss: 2.2129092640777794
Validation loss: 2.38539963812114

Epoch: 6| Step: 4
Training loss: 2.8306283567294557
Validation loss: 2.3762006051172957

Epoch: 6| Step: 5
Training loss: 2.6402143350927956
Validation loss: 2.359153332395934

Epoch: 6| Step: 6
Training loss: 2.2351348225254157
Validation loss: 2.345503315193122

Epoch: 6| Step: 7
Training loss: 2.527540526475505
Validation loss: 2.343953826682474

Epoch: 6| Step: 8
Training loss: 1.9092601086003134
Validation loss: 2.347845579878395

Epoch: 6| Step: 9
Training loss: 2.262171671949404
Validation loss: 2.3432584212872154

Epoch: 6| Step: 10
Training loss: 2.354448239752124
Validation loss: 2.3801628476982795

Epoch: 6| Step: 11
Training loss: 2.3581400285449705
Validation loss: 2.3771988081836835

Epoch: 6| Step: 12
Training loss: 2.316041657186828
Validation loss: 2.3574803728917715

Epoch: 6| Step: 13
Training loss: 2.4785011958430463
Validation loss: 2.36565167161732

Epoch: 184| Step: 0
Training loss: 1.9860401526211615
Validation loss: 2.370102815553929

Epoch: 6| Step: 1
Training loss: 2.434297071196316
Validation loss: 2.362979037498609

Epoch: 6| Step: 2
Training loss: 1.6257932634106842
Validation loss: 2.3534126006952314

Epoch: 6| Step: 3
Training loss: 2.092788703353677
Validation loss: 2.3553263662484767

Epoch: 6| Step: 4
Training loss: 2.1348368780280556
Validation loss: 2.380981017957182

Epoch: 6| Step: 5
Training loss: 2.947756939302419
Validation loss: 2.4148383917552207

Epoch: 6| Step: 6
Training loss: 2.610425634792436
Validation loss: 2.4352509898557657

Epoch: 6| Step: 7
Training loss: 2.223245927998039
Validation loss: 2.4335667207323928

Epoch: 6| Step: 8
Training loss: 2.200460459465949
Validation loss: 2.44215761077608

Epoch: 6| Step: 9
Training loss: 2.7387797599787818
Validation loss: 2.4483271736141194

Epoch: 6| Step: 10
Training loss: 2.1745461702969036
Validation loss: 2.457454696099317

Epoch: 6| Step: 11
Training loss: 1.9589706222644747
Validation loss: 2.4575472562685747

Epoch: 6| Step: 12
Training loss: 2.3516561800017515
Validation loss: 2.4790138231293724

Epoch: 6| Step: 13
Training loss: 2.2928082021626444
Validation loss: 2.464512613880472

Epoch: 185| Step: 0
Training loss: 2.2789221605145014
Validation loss: 2.454695011148129

Epoch: 6| Step: 1
Training loss: 2.068260702025489
Validation loss: 2.4403635605232883

Epoch: 6| Step: 2
Training loss: 2.1657820387320683
Validation loss: 2.4393649196518155

Epoch: 6| Step: 3
Training loss: 2.2367423794131485
Validation loss: 2.3951282942276473

Epoch: 6| Step: 4
Training loss: 1.7007488508735082
Validation loss: 2.370254864747952

Epoch: 6| Step: 5
Training loss: 2.5818651293065167
Validation loss: 2.3548059258937135

Epoch: 6| Step: 6
Training loss: 2.3527109377075397
Validation loss: 2.337556925224088

Epoch: 6| Step: 7
Training loss: 2.7471922499210213
Validation loss: 2.3052656641159763

Epoch: 6| Step: 8
Training loss: 2.5325481712226106
Validation loss: 2.3007192914122507

Epoch: 6| Step: 9
Training loss: 2.4676399149547588
Validation loss: 2.310542586629849

Epoch: 6| Step: 10
Training loss: 2.3649251973619445
Validation loss: 2.3084930936004593

Epoch: 6| Step: 11
Training loss: 2.105151660375944
Validation loss: 2.2955394347348546

Epoch: 6| Step: 12
Training loss: 2.118695724827389
Validation loss: 2.307400423762306

Epoch: 6| Step: 13
Training loss: 2.4384686428272975
Validation loss: 2.338241092105752

Epoch: 186| Step: 0
Training loss: 2.030232688271019
Validation loss: 2.3509785870866233

Epoch: 6| Step: 1
Training loss: 1.9650107098547198
Validation loss: 2.37062397895096

Epoch: 6| Step: 2
Training loss: 2.2761913282362793
Validation loss: 2.413836178032062

Epoch: 6| Step: 3
Training loss: 2.0938950673420935
Validation loss: 2.4361527639898375

Epoch: 6| Step: 4
Training loss: 2.181731984574331
Validation loss: 2.4767518257599566

Epoch: 6| Step: 5
Training loss: 2.7458677456618807
Validation loss: 2.4969693610967743

Epoch: 6| Step: 6
Training loss: 2.2749958792848264
Validation loss: 2.5129039633726653

Epoch: 6| Step: 7
Training loss: 2.887087084818736
Validation loss: 2.527392051919778

Epoch: 6| Step: 8
Training loss: 2.34874853535069
Validation loss: 2.5106242359613007

Epoch: 6| Step: 9
Training loss: 2.4933657357291477
Validation loss: 2.4825575734752596

Epoch: 6| Step: 10
Training loss: 2.3242598842539106
Validation loss: 2.464969702322303

Epoch: 6| Step: 11
Training loss: 1.9350086930545443
Validation loss: 2.41510954930244

Epoch: 6| Step: 12
Training loss: 1.8264418458533465
Validation loss: 2.396882492412883

Epoch: 6| Step: 13
Training loss: 1.8821893190960657
Validation loss: 2.371547921116293

Epoch: 187| Step: 0
Training loss: 2.672096198668788
Validation loss: 2.3765834382978697

Epoch: 6| Step: 1
Training loss: 2.277795344442637
Validation loss: 2.3685655471026683

Epoch: 6| Step: 2
Training loss: 2.446982011854421
Validation loss: 2.3675097098635822

Epoch: 6| Step: 3
Training loss: 1.9593018781290168
Validation loss: 2.358213874444939

Epoch: 6| Step: 4
Training loss: 2.7503986069756174
Validation loss: 2.357686759580373

Epoch: 6| Step: 5
Training loss: 2.270301779966518
Validation loss: 2.3723749356360084

Epoch: 6| Step: 6
Training loss: 2.622747272074423
Validation loss: 2.3690272271475563

Epoch: 6| Step: 7
Training loss: 2.5496517093136766
Validation loss: 2.3793963925165564

Epoch: 6| Step: 8
Training loss: 1.9220971700138736
Validation loss: 2.3835968270631858

Epoch: 6| Step: 9
Training loss: 2.1853287957062704
Validation loss: 2.39089324645119

Epoch: 6| Step: 10
Training loss: 1.9060613820298207
Validation loss: 2.3752678124853546

Epoch: 6| Step: 11
Training loss: 1.561548324682462
Validation loss: 2.4012852534235902

Epoch: 6| Step: 12
Training loss: 1.5953551792036436
Validation loss: 2.4182738715416248

Epoch: 6| Step: 13
Training loss: 2.2347237908285593
Validation loss: 2.396551808990555

Epoch: 188| Step: 0
Training loss: 2.0977505852711307
Validation loss: 2.3781014944968524

Epoch: 6| Step: 1
Training loss: 2.4625595317944775
Validation loss: 2.369275960123944

Epoch: 6| Step: 2
Training loss: 2.3220478594215264
Validation loss: 2.3767947532820584

Epoch: 6| Step: 3
Training loss: 2.237392815095129
Validation loss: 2.3621402251461245

Epoch: 6| Step: 4
Training loss: 2.0953218623442145
Validation loss: 2.3498617736390033

Epoch: 6| Step: 5
Training loss: 1.699848067282268
Validation loss: 2.3607023184042415

Epoch: 6| Step: 6
Training loss: 2.5687643565869624
Validation loss: 2.3569867714292054

Epoch: 6| Step: 7
Training loss: 2.278839405375452
Validation loss: 2.353699912204209

Epoch: 6| Step: 8
Training loss: 2.318463651759244
Validation loss: 2.351615975198152

Epoch: 6| Step: 9
Training loss: 2.468833149342663
Validation loss: 2.3619121266087504

Epoch: 6| Step: 10
Training loss: 2.0127265850008635
Validation loss: 2.3733720451388014

Epoch: 6| Step: 11
Training loss: 2.216017316296122
Validation loss: 2.377537866951649

Epoch: 6| Step: 12
Training loss: 1.7763579265065765
Validation loss: 2.3879693385473764

Epoch: 6| Step: 13
Training loss: 1.8722134546866358
Validation loss: 2.3916696261673156

Epoch: 189| Step: 0
Training loss: 2.765392401445438
Validation loss: 2.398598302183395

Epoch: 6| Step: 1
Training loss: 1.6836645549568845
Validation loss: 2.402387292178712

Epoch: 6| Step: 2
Training loss: 2.6033954750032846
Validation loss: 2.3988349405950555

Epoch: 6| Step: 3
Training loss: 2.296312743416317
Validation loss: 2.416647134651741

Epoch: 6| Step: 4
Training loss: 2.5212369128120673
Validation loss: 2.4300885794844076

Epoch: 6| Step: 5
Training loss: 2.0134241671419004
Validation loss: 2.423042098188286

Epoch: 6| Step: 6
Training loss: 2.1662078029178926
Validation loss: 2.404941272722532

Epoch: 6| Step: 7
Training loss: 2.1123654113873354
Validation loss: 2.3997181545737654

Epoch: 6| Step: 8
Training loss: 1.4257794105831456
Validation loss: 2.3817261773315117

Epoch: 6| Step: 9
Training loss: 1.6809019444611606
Validation loss: 2.3797056517696062

Epoch: 6| Step: 10
Training loss: 2.2889144901687444
Validation loss: 2.374801508710665

Epoch: 6| Step: 11
Training loss: 2.146800246179665
Validation loss: 2.360194673357247

Epoch: 6| Step: 12
Training loss: 2.0316148870356443
Validation loss: 2.375938452480372

Epoch: 6| Step: 13
Training loss: 2.639437707638902
Validation loss: 2.3547320498729665

Epoch: 190| Step: 0
Training loss: 2.2898845563549934
Validation loss: 2.3498918810853997

Epoch: 6| Step: 1
Training loss: 2.056345223769902
Validation loss: 2.337999644786418

Epoch: 6| Step: 2
Training loss: 1.7661261733399032
Validation loss: 2.3385507917021737

Epoch: 6| Step: 3
Training loss: 2.0320454140491795
Validation loss: 2.3300884221052494

Epoch: 6| Step: 4
Training loss: 2.4611227298842158
Validation loss: 2.3492497474685736

Epoch: 6| Step: 5
Training loss: 2.1699587924402324
Validation loss: 2.35873675282263

Epoch: 6| Step: 6
Training loss: 1.7641763736540088
Validation loss: 2.368660180277536

Epoch: 6| Step: 7
Training loss: 1.9882752543960438
Validation loss: 2.364379292525732

Epoch: 6| Step: 8
Training loss: 2.250110411584029
Validation loss: 2.362600126855924

Epoch: 6| Step: 9
Training loss: 2.4858618551526215
Validation loss: 2.358909808269359

Epoch: 6| Step: 10
Training loss: 2.4341324260549224
Validation loss: 2.3669017856362005

Epoch: 6| Step: 11
Training loss: 1.8104620031980245
Validation loss: 2.3654040499325553

Epoch: 6| Step: 12
Training loss: 2.319668356112277
Validation loss: 2.3998156486143416

Epoch: 6| Step: 13
Training loss: 2.480324376027245
Validation loss: 2.394713043478201

Epoch: 191| Step: 0
Training loss: 2.2881369949355683
Validation loss: 2.382121568575016

Epoch: 6| Step: 1
Training loss: 2.1323170068897106
Validation loss: 2.3989407825448223

Epoch: 6| Step: 2
Training loss: 2.182625161653498
Validation loss: 2.3912129696189006

Epoch: 6| Step: 3
Training loss: 2.163318933204879
Validation loss: 2.3788139621311584

Epoch: 6| Step: 4
Training loss: 2.201622091858107
Validation loss: 2.3724649929672474

Epoch: 6| Step: 5
Training loss: 2.0640883831795236
Validation loss: 2.3600755925505323

Epoch: 6| Step: 6
Training loss: 2.163636754431518
Validation loss: 2.349534769835796

Epoch: 6| Step: 7
Training loss: 2.1171154277400652
Validation loss: 2.366828358652818

Epoch: 6| Step: 8
Training loss: 1.6870250033395178
Validation loss: 2.3478906885113675

Epoch: 6| Step: 9
Training loss: 1.909265103587977
Validation loss: 2.3542005852482677

Epoch: 6| Step: 10
Training loss: 2.5585773496611783
Validation loss: 2.3512085957064377

Epoch: 6| Step: 11
Training loss: 1.818536637103658
Validation loss: 2.3514581832339343

Epoch: 6| Step: 12
Training loss: 2.1475547502885837
Validation loss: 2.361132658060464

Epoch: 6| Step: 13
Training loss: 2.439587310692216
Validation loss: 2.3896123907854774

Epoch: 192| Step: 0
Training loss: 2.5378369939115504
Validation loss: 2.420684845933149

Epoch: 6| Step: 1
Training loss: 1.674428113413211
Validation loss: 2.436410320119847

Epoch: 6| Step: 2
Training loss: 2.184439780130168
Validation loss: 2.447497118043477

Epoch: 6| Step: 3
Training loss: 1.779183510813015
Validation loss: 2.4499141679754475

Epoch: 6| Step: 4
Training loss: 1.6434711292262172
Validation loss: 2.464633607991759

Epoch: 6| Step: 5
Training loss: 2.56649134478883
Validation loss: 2.4575827665767322

Epoch: 6| Step: 6
Training loss: 2.0932881998959165
Validation loss: 2.4534746914515275

Epoch: 6| Step: 7
Training loss: 2.0918746064718268
Validation loss: 2.425045826213261

Epoch: 6| Step: 8
Training loss: 2.3643600649743903
Validation loss: 2.416492051325008

Epoch: 6| Step: 9
Training loss: 2.029910775840538
Validation loss: 2.390160772032534

Epoch: 6| Step: 10
Training loss: 2.360034269472008
Validation loss: 2.38055128546254

Epoch: 6| Step: 11
Training loss: 1.7397458881867336
Validation loss: 2.3625931855064124

Epoch: 6| Step: 12
Training loss: 2.2727049601066476
Validation loss: 2.3495934220857078

Epoch: 6| Step: 13
Training loss: 2.1734558499601677
Validation loss: 2.3326073603432036

Epoch: 193| Step: 0
Training loss: 2.1724340144804692
Validation loss: 2.315616720122037

Epoch: 6| Step: 1
Training loss: 2.484574411894268
Validation loss: 2.302400201822307

Epoch: 6| Step: 2
Training loss: 1.5881531370538575
Validation loss: 2.3170848096665027

Epoch: 6| Step: 3
Training loss: 1.7846748487598234
Validation loss: 2.320361700386069

Epoch: 6| Step: 4
Training loss: 1.7045339653321512
Validation loss: 2.3272432418096125

Epoch: 6| Step: 5
Training loss: 2.236331749792368
Validation loss: 2.328369746612902

Epoch: 6| Step: 6
Training loss: 2.2923203547486914
Validation loss: 2.3481038880132727

Epoch: 6| Step: 7
Training loss: 2.123928585346182
Validation loss: 2.3617624309415253

Epoch: 6| Step: 8
Training loss: 1.7927830419169888
Validation loss: 2.346061870710805

Epoch: 6| Step: 9
Training loss: 2.365450684589122
Validation loss: 2.354090610342408

Epoch: 6| Step: 10
Training loss: 2.323403916055302
Validation loss: 2.3699026700895653

Epoch: 6| Step: 11
Training loss: 2.1470247929940065
Validation loss: 2.3739112977384584

Epoch: 6| Step: 12
Training loss: 1.989656883065294
Validation loss: 2.3836540179244285

Epoch: 6| Step: 13
Training loss: 2.2675386962616955
Validation loss: 2.3863408849411427

Epoch: 194| Step: 0
Training loss: 2.4326632513327375
Validation loss: 2.379028220196734

Epoch: 6| Step: 1
Training loss: 2.1040597139377186
Validation loss: 2.3756549603507886

Epoch: 6| Step: 2
Training loss: 2.010916599974251
Validation loss: 2.3743572142456317

Epoch: 6| Step: 3
Training loss: 2.105656942757651
Validation loss: 2.3762087797939797

Epoch: 6| Step: 4
Training loss: 2.238509933746157
Validation loss: 2.3618113143846236

Epoch: 6| Step: 5
Training loss: 1.4680971358486008
Validation loss: 2.375284242163053

Epoch: 6| Step: 6
Training loss: 1.1060316182768248
Validation loss: 2.3743791065445565

Epoch: 6| Step: 7
Training loss: 2.4198912340738197
Validation loss: 2.3706834552339346

Epoch: 6| Step: 8
Training loss: 2.08925590447293
Validation loss: 2.350637891694648

Epoch: 6| Step: 9
Training loss: 1.9524031869328895
Validation loss: 2.3511329896117124

Epoch: 6| Step: 10
Training loss: 2.34534308650577
Validation loss: 2.356809082881157

Epoch: 6| Step: 11
Training loss: 2.581739261986447
Validation loss: 2.3396011065941558

Epoch: 6| Step: 12
Training loss: 1.7380601377980391
Validation loss: 2.335746584756548

Epoch: 6| Step: 13
Training loss: 2.1385780070011027
Validation loss: 2.3253183222376888

Epoch: 195| Step: 0
Training loss: 1.7764565066320774
Validation loss: 2.3392045822018686

Epoch: 6| Step: 1
Training loss: 1.7844874091074276
Validation loss: 2.328488143961671

Epoch: 6| Step: 2
Training loss: 2.0804361671019236
Validation loss: 2.3291890257322567

Epoch: 6| Step: 3
Training loss: 2.373132372913255
Validation loss: 2.327817696314985

Epoch: 6| Step: 4
Training loss: 2.4962189692219443
Validation loss: 2.328298619099235

Epoch: 6| Step: 5
Training loss: 2.0824779153044366
Validation loss: 2.35562782850365

Epoch: 6| Step: 6
Training loss: 1.8973057517037148
Validation loss: 2.3627709859172232

Epoch: 6| Step: 7
Training loss: 2.532762899507344
Validation loss: 2.3967976358074368

Epoch: 6| Step: 8
Training loss: 1.3480579606791177
Validation loss: 2.4181759396121176

Epoch: 6| Step: 9
Training loss: 1.7406286270405154
Validation loss: 2.4178283969805623

Epoch: 6| Step: 10
Training loss: 2.2800764435785945
Validation loss: 2.413428521511001

Epoch: 6| Step: 11
Training loss: 1.9082163065491176
Validation loss: 2.4020467888610315

Epoch: 6| Step: 12
Training loss: 2.517982846941709
Validation loss: 2.407438674185044

Epoch: 6| Step: 13
Training loss: 2.2440237574280197
Validation loss: 2.379558936615766

Epoch: 196| Step: 0
Training loss: 2.3684301356648954
Validation loss: 2.3619351805830036

Epoch: 6| Step: 1
Training loss: 2.5380650835402414
Validation loss: 2.359844053296141

Epoch: 6| Step: 2
Training loss: 2.059182475559504
Validation loss: 2.36904444840543

Epoch: 6| Step: 3
Training loss: 2.2294971066661677
Validation loss: 2.3677504969328047

Epoch: 6| Step: 4
Training loss: 2.255798497555193
Validation loss: 2.376310324908147

Epoch: 6| Step: 5
Training loss: 1.9929134467394887
Validation loss: 2.385085235525546

Epoch: 6| Step: 6
Training loss: 1.7678306104202042
Validation loss: 2.3695447765874813

Epoch: 6| Step: 7
Training loss: 1.3034679172051633
Validation loss: 2.34863046349194

Epoch: 6| Step: 8
Training loss: 1.5087504261588291
Validation loss: 2.3508922245915476

Epoch: 6| Step: 9
Training loss: 2.0877640973998
Validation loss: 2.3396800098247716

Epoch: 6| Step: 10
Training loss: 2.2576521978263386
Validation loss: 2.3567324098428

Epoch: 6| Step: 11
Training loss: 2.1602615413562747
Validation loss: 2.3723673966643886

Epoch: 6| Step: 12
Training loss: 2.3088543998109468
Validation loss: 2.3597322859129592

Epoch: 6| Step: 13
Training loss: 1.528512414918644
Validation loss: 2.342916232877221

Epoch: 197| Step: 0
Training loss: 2.118550667627501
Validation loss: 2.3508979791365388

Epoch: 6| Step: 1
Training loss: 1.9466412154367232
Validation loss: 2.3333208260296203

Epoch: 6| Step: 2
Training loss: 2.307091445215051
Validation loss: 2.3355718552785025

Epoch: 6| Step: 3
Training loss: 2.131994293105054
Validation loss: 2.3302233651001494

Epoch: 6| Step: 4
Training loss: 1.7425160461737779
Validation loss: 2.330147381756133

Epoch: 6| Step: 5
Training loss: 1.2239611794729486
Validation loss: 2.3371384624527867

Epoch: 6| Step: 6
Training loss: 2.3508743850854055
Validation loss: 2.3346049755733924

Epoch: 6| Step: 7
Training loss: 2.133545690139788
Validation loss: 2.349350614219708

Epoch: 6| Step: 8
Training loss: 2.1435754866231806
Validation loss: 2.3550019244884237

Epoch: 6| Step: 9
Training loss: 1.9260201760539515
Validation loss: 2.3520538881781596

Epoch: 6| Step: 10
Training loss: 2.144190248709837
Validation loss: 2.3636579413515135

Epoch: 6| Step: 11
Training loss: 1.8399040066516044
Validation loss: 2.387762505118751

Epoch: 6| Step: 12
Training loss: 2.168544933287191
Validation loss: 2.3961438047847645

Epoch: 6| Step: 13
Training loss: 2.6543603795463824
Validation loss: 2.4217105212877272

Epoch: 198| Step: 0
Training loss: 1.716030049409947
Validation loss: 2.4130365262539275

Epoch: 6| Step: 1
Training loss: 1.8287637360918052
Validation loss: 2.4060015731950406

Epoch: 6| Step: 2
Training loss: 2.165599621380483
Validation loss: 2.421386686458157

Epoch: 6| Step: 3
Training loss: 2.0189026199141673
Validation loss: 2.426111615043666

Epoch: 6| Step: 4
Training loss: 2.4385245688543913
Validation loss: 2.405920785245916

Epoch: 6| Step: 5
Training loss: 2.0943158651875486
Validation loss: 2.4071410060618925

Epoch: 6| Step: 6
Training loss: 2.5519977373573535
Validation loss: 2.3964173798615014

Epoch: 6| Step: 7
Training loss: 1.989494388316433
Validation loss: 2.3560618152893418

Epoch: 6| Step: 8
Training loss: 1.8672966705712604
Validation loss: 2.3518596452302125

Epoch: 6| Step: 9
Training loss: 1.7192910469883074
Validation loss: 2.34884256661037

Epoch: 6| Step: 10
Training loss: 2.0605111213944904
Validation loss: 2.3538364160970304

Epoch: 6| Step: 11
Training loss: 1.4494735617146037
Validation loss: 2.3612884996129098

Epoch: 6| Step: 12
Training loss: 2.0322380597193996
Validation loss: 2.3549586611938453

Epoch: 6| Step: 13
Training loss: 2.024212309614718
Validation loss: 2.3677513739460427

Epoch: 199| Step: 0
Training loss: 1.9795261525052272
Validation loss: 2.3684430803129626

Epoch: 6| Step: 1
Training loss: 1.918558748635692
Validation loss: 2.379355292395282

Epoch: 6| Step: 2
Training loss: 2.13590326735238
Validation loss: 2.365103119460843

Epoch: 6| Step: 3
Training loss: 2.1928240699457398
Validation loss: 2.3712902261706805

Epoch: 6| Step: 4
Training loss: 2.0008640806903832
Validation loss: 2.39303574552673

Epoch: 6| Step: 5
Training loss: 1.8545115360899875
Validation loss: 2.3816403130110113

Epoch: 6| Step: 6
Training loss: 1.9367346944148784
Validation loss: 2.4129682854592813

Epoch: 6| Step: 7
Training loss: 1.8620404284520629
Validation loss: 2.415911354556977

Epoch: 6| Step: 8
Training loss: 1.3365036506531618
Validation loss: 2.39540708868961

Epoch: 6| Step: 9
Training loss: 2.0861957975903866
Validation loss: 2.3904921486519437

Epoch: 6| Step: 10
Training loss: 2.2523122138899594
Validation loss: 2.3773957201237508

Epoch: 6| Step: 11
Training loss: 1.6739907825539793
Validation loss: 2.384470433355132

Epoch: 6| Step: 12
Training loss: 2.7125884643754916
Validation loss: 2.3634512994453707

Epoch: 6| Step: 13
Training loss: 1.8890803939691239
Validation loss: 2.368687713173829

Epoch: 200| Step: 0
Training loss: 2.0496469612375807
Validation loss: 2.3663660611011927

Epoch: 6| Step: 1
Training loss: 1.7104824628112143
Validation loss: 2.382209377391299

Epoch: 6| Step: 2
Training loss: 1.639050554753824
Validation loss: 2.3940505219188166

Epoch: 6| Step: 3
Training loss: 1.8778090733334831
Validation loss: 2.384240152414952

Epoch: 6| Step: 4
Training loss: 1.8197166548235368
Validation loss: 2.3898165056382625

Epoch: 6| Step: 5
Training loss: 1.8521109625776193
Validation loss: 2.39653487311552

Epoch: 6| Step: 6
Training loss: 2.5645142988824148
Validation loss: 2.3874318543024753

Epoch: 6| Step: 7
Training loss: 2.4221975788511623
Validation loss: 2.409538722969803

Epoch: 6| Step: 8
Training loss: 2.3595829549936536
Validation loss: 2.4059041305654842

Epoch: 6| Step: 9
Training loss: 2.017399561200624
Validation loss: 2.419827760155099

Epoch: 6| Step: 10
Training loss: 2.0325370818974817
Validation loss: 2.4356035049206852

Epoch: 6| Step: 11
Training loss: 1.9147822058509698
Validation loss: 2.4627174931439733

Epoch: 6| Step: 12
Training loss: 1.7686051730654782
Validation loss: 2.442198990289684

Epoch: 6| Step: 13
Training loss: 1.542988837389023
Validation loss: 2.434852177942181

Epoch: 201| Step: 0
Training loss: 2.130778589998775
Validation loss: 2.4269206709797446

Epoch: 6| Step: 1
Training loss: 1.1623366702613231
Validation loss: 2.4259819972954872

Epoch: 6| Step: 2
Training loss: 2.28206233362892
Validation loss: 2.434474715756564

Epoch: 6| Step: 3
Training loss: 1.848996730638567
Validation loss: 2.4250749114458228

Epoch: 6| Step: 4
Training loss: 2.096506382567436
Validation loss: 2.4260532820492178

Epoch: 6| Step: 5
Training loss: 2.048402871218194
Validation loss: 2.4262622654038113

Epoch: 6| Step: 6
Training loss: 1.8535542780520835
Validation loss: 2.4336418431926683

Epoch: 6| Step: 7
Training loss: 2.286420423559824
Validation loss: 2.442265482725648

Epoch: 6| Step: 8
Training loss: 1.6577991222593267
Validation loss: 2.4157038624699534

Epoch: 6| Step: 9
Training loss: 2.0425172967073335
Validation loss: 2.4144210413773237

Epoch: 6| Step: 10
Training loss: 2.190106065698648
Validation loss: 2.3681467568962247

Epoch: 6| Step: 11
Training loss: 1.99266949974889
Validation loss: 2.347641893432044

Epoch: 6| Step: 12
Training loss: 1.666406476056119
Validation loss: 2.3504599653229477

Epoch: 6| Step: 13
Training loss: 2.0163383700071975
Validation loss: 2.3530638065554275

Epoch: 202| Step: 0
Training loss: 1.8355040342888782
Validation loss: 2.372595611085547

Epoch: 6| Step: 1
Training loss: 1.955387605453465
Validation loss: 2.374108285279815

Epoch: 6| Step: 2
Training loss: 1.5368433410684943
Validation loss: 2.389041447742378

Epoch: 6| Step: 3
Training loss: 1.5504143038147935
Validation loss: 2.3675515938492038

Epoch: 6| Step: 4
Training loss: 1.7891860319575223
Validation loss: 2.3410699946074693

Epoch: 6| Step: 5
Training loss: 1.9409487394376894
Validation loss: 2.3289072248168807

Epoch: 6| Step: 6
Training loss: 2.4959853362178435
Validation loss: 2.3080912588112104

Epoch: 6| Step: 7
Training loss: 1.7279672561033335
Validation loss: 2.3102003623445646

Epoch: 6| Step: 8
Training loss: 2.0691608032602335
Validation loss: 2.3132177124369635

Epoch: 6| Step: 9
Training loss: 1.9987816676052037
Validation loss: 2.316167283194338

Epoch: 6| Step: 10
Training loss: 1.9799298337583697
Validation loss: 2.344468508825978

Epoch: 6| Step: 11
Training loss: 1.9973304336630362
Validation loss: 2.3639519969733325

Epoch: 6| Step: 12
Training loss: 2.448881135148645
Validation loss: 2.3723870320882514

Epoch: 6| Step: 13
Training loss: 2.0901105763875507
Validation loss: 2.390572259063677

Epoch: 203| Step: 0
Training loss: 2.004406604428469
Validation loss: 2.4063160033190365

Epoch: 6| Step: 1
Training loss: 2.503235916175795
Validation loss: 2.4304292710678737

Epoch: 6| Step: 2
Training loss: 2.1714534213142818
Validation loss: 2.4362140899489835

Epoch: 6| Step: 3
Training loss: 1.7834775281110153
Validation loss: 2.4367949583867303

Epoch: 6| Step: 4
Training loss: 2.153490152386535
Validation loss: 2.4487572913815687

Epoch: 6| Step: 5
Training loss: 1.7270468468334108
Validation loss: 2.459003579936889

Epoch: 6| Step: 6
Training loss: 1.6330976465374691
Validation loss: 2.4608185218011447

Epoch: 6| Step: 7
Training loss: 2.4102610066058405
Validation loss: 2.4556070592162325

Epoch: 6| Step: 8
Training loss: 1.7307739677527396
Validation loss: 2.4491084360299307

Epoch: 6| Step: 9
Training loss: 1.7909099917944247
Validation loss: 2.4331861321931503

Epoch: 6| Step: 10
Training loss: 1.5979449843674798
Validation loss: 2.422946824281557

Epoch: 6| Step: 11
Training loss: 1.2763215620880064
Validation loss: 2.407670181407232

Epoch: 6| Step: 12
Training loss: 1.757432074176999
Validation loss: 2.4029617577791256

Epoch: 6| Step: 13
Training loss: 2.340758487169825
Validation loss: 2.399043025024697

Epoch: 204| Step: 0
Training loss: 2.1438258388439397
Validation loss: 2.379250793438004

Epoch: 6| Step: 1
Training loss: 1.9219555721606192
Validation loss: 2.4005693924983387

Epoch: 6| Step: 2
Training loss: 2.1626926314272645
Validation loss: 2.3767608223161028

Epoch: 6| Step: 3
Training loss: 1.2683990594490484
Validation loss: 2.3789981511971576

Epoch: 6| Step: 4
Training loss: 2.275696566073747
Validation loss: 2.3764215229588523

Epoch: 6| Step: 5
Training loss: 1.8965091409058135
Validation loss: 2.390703548926721

Epoch: 6| Step: 6
Training loss: 1.4001836690313505
Validation loss: 2.3869842445541645

Epoch: 6| Step: 7
Training loss: 1.7067238118369819
Validation loss: 2.416219151836426

Epoch: 6| Step: 8
Training loss: 1.947917373847493
Validation loss: 2.3920651421793524

Epoch: 6| Step: 9
Training loss: 2.0744618418860257
Validation loss: 2.3997448653564275

Epoch: 6| Step: 10
Training loss: 1.8201707121675414
Validation loss: 2.4039141345985664

Epoch: 6| Step: 11
Training loss: 1.8885032160345019
Validation loss: 2.3924211562338114

Epoch: 6| Step: 12
Training loss: 2.0146891469166186
Validation loss: 2.4089212387755636

Epoch: 6| Step: 13
Training loss: 2.0024071750724164
Validation loss: 2.4156923702788333

Epoch: 205| Step: 0
Training loss: 1.89973267381199
Validation loss: 2.4219718201887273

Epoch: 6| Step: 1
Training loss: 2.2273823617340085
Validation loss: 2.423826758473801

Epoch: 6| Step: 2
Training loss: 2.262909623469143
Validation loss: 2.420842509868037

Epoch: 6| Step: 3
Training loss: 1.1157004322868673
Validation loss: 2.407325210352141

Epoch: 6| Step: 4
Training loss: 2.244597412578849
Validation loss: 2.433866455124066

Epoch: 6| Step: 5
Training loss: 1.3086442169023194
Validation loss: 2.4434978806883088

Epoch: 6| Step: 6
Training loss: 1.5643734191325693
Validation loss: 2.4234318783933686

Epoch: 6| Step: 7
Training loss: 2.1580679044177744
Validation loss: 2.4264220107346945

Epoch: 6| Step: 8
Training loss: 1.6844196462287657
Validation loss: 2.4102739893132052

Epoch: 6| Step: 9
Training loss: 1.781610352054697
Validation loss: 2.415905081039082

Epoch: 6| Step: 10
Training loss: 1.7720138280126627
Validation loss: 2.3880442689978065

Epoch: 6| Step: 11
Training loss: 1.9600310035121904
Validation loss: 2.3690002879751786

Epoch: 6| Step: 12
Training loss: 1.5992026458212647
Validation loss: 2.3608283608517

Epoch: 6| Step: 13
Training loss: 2.440017182961918
Validation loss: 2.35181767418054

Epoch: 206| Step: 0
Training loss: 1.7312601660695075
Validation loss: 2.374765686799444

Epoch: 6| Step: 1
Training loss: 1.9740765887614133
Validation loss: 2.4177728532150193

Epoch: 6| Step: 2
Training loss: 1.9852027668432708
Validation loss: 2.436128026704362

Epoch: 6| Step: 3
Training loss: 1.7281797955674332
Validation loss: 2.413284487011003

Epoch: 6| Step: 4
Training loss: 1.8421157447617127
Validation loss: 2.422335408589214

Epoch: 6| Step: 5
Training loss: 1.668101321095573
Validation loss: 2.441008117108766

Epoch: 6| Step: 6
Training loss: 1.9495496449906273
Validation loss: 2.4537873025598547

Epoch: 6| Step: 7
Training loss: 1.593183903104704
Validation loss: 2.467752248033518

Epoch: 6| Step: 8
Training loss: 1.8244680360945857
Validation loss: 2.4844450365140753

Epoch: 6| Step: 9
Training loss: 1.977302322345586
Validation loss: 2.485325349362914

Epoch: 6| Step: 10
Training loss: 2.186519839176081
Validation loss: 2.506987323412653

Epoch: 6| Step: 11
Training loss: 1.6221264594624802
Validation loss: 2.505757045580314

Epoch: 6| Step: 12
Training loss: 2.005167959888468
Validation loss: 2.4916803836256314

Epoch: 6| Step: 13
Training loss: 1.8908425828559816
Validation loss: 2.45011641598517

Epoch: 207| Step: 0
Training loss: 1.4765038049728294
Validation loss: 2.4224910591631263

Epoch: 6| Step: 1
Training loss: 1.6676787005843088
Validation loss: 2.4119611281633895

Epoch: 6| Step: 2
Training loss: 1.9182660713412476
Validation loss: 2.3971953776915615

Epoch: 6| Step: 3
Training loss: 1.6987932746770251
Validation loss: 2.373314576262674

Epoch: 6| Step: 4
Training loss: 1.6605248614215837
Validation loss: 2.3618769341311627

Epoch: 6| Step: 5
Training loss: 1.5676199380111395
Validation loss: 2.3600096288781462

Epoch: 6| Step: 6
Training loss: 2.187648223214865
Validation loss: 2.3473110783676074

Epoch: 6| Step: 7
Training loss: 2.1958919317062082
Validation loss: 2.356821509408882

Epoch: 6| Step: 8
Training loss: 2.2460086176121816
Validation loss: 2.357751310023365

Epoch: 6| Step: 9
Training loss: 2.059390411550831
Validation loss: 2.3434984472770184

Epoch: 6| Step: 10
Training loss: 1.396705620585874
Validation loss: 2.3598983630762027

Epoch: 6| Step: 11
Training loss: 1.7055077639637628
Validation loss: 2.361284617162099

Epoch: 6| Step: 12
Training loss: 1.930214504912121
Validation loss: 2.3595245070565825

Epoch: 6| Step: 13
Training loss: 1.7774307397367575
Validation loss: 2.3797358362553895

Epoch: 208| Step: 0
Training loss: 2.028033835503135
Validation loss: 2.402014887847368

Epoch: 6| Step: 1
Training loss: 1.8123249100926775
Validation loss: 2.4178010854358174

Epoch: 6| Step: 2
Training loss: 1.780571256116393
Validation loss: 2.4493944624788826

Epoch: 6| Step: 3
Training loss: 1.6120583099345092
Validation loss: 2.4601389130759395

Epoch: 6| Step: 4
Training loss: 1.4392594060890298
Validation loss: 2.474675243670503

Epoch: 6| Step: 5
Training loss: 1.401094267849206
Validation loss: 2.4906840740612313

Epoch: 6| Step: 6
Training loss: 2.0770893240956725
Validation loss: 2.482671231750137

Epoch: 6| Step: 7
Training loss: 1.7218400401254748
Validation loss: 2.484823240022265

Epoch: 6| Step: 8
Training loss: 2.089857782334607
Validation loss: 2.4643875255515395

Epoch: 6| Step: 9
Training loss: 1.3953912471408694
Validation loss: 2.4376471869174576

Epoch: 6| Step: 10
Training loss: 1.6845383262361808
Validation loss: 2.4108365383988724

Epoch: 6| Step: 11
Training loss: 1.7815132615813405
Validation loss: 2.377602255296309

Epoch: 6| Step: 12
Training loss: 2.174821241201874
Validation loss: 2.3622972894849728

Epoch: 6| Step: 13
Training loss: 2.2228572600368506
Validation loss: 2.351538262313712

Epoch: 209| Step: 0
Training loss: 1.8936350167495732
Validation loss: 2.344139695670217

Epoch: 6| Step: 1
Training loss: 2.2959034220756185
Validation loss: 2.346022811957499

Epoch: 6| Step: 2
Training loss: 0.8569409666260462
Validation loss: 2.357156261327317

Epoch: 6| Step: 3
Training loss: 1.5830624833923843
Validation loss: 2.3743329765705368

Epoch: 6| Step: 4
Training loss: 2.221298795474313
Validation loss: 2.386802932196937

Epoch: 6| Step: 5
Training loss: 1.41263816292813
Validation loss: 2.414126153113303

Epoch: 6| Step: 6
Training loss: 1.579191546214781
Validation loss: 2.419711921311633

Epoch: 6| Step: 7
Training loss: 2.4847133574005724
Validation loss: 2.436991742459776

Epoch: 6| Step: 8
Training loss: 1.6446907165484292
Validation loss: 2.446730297206522

Epoch: 6| Step: 9
Training loss: 1.8029457042810384
Validation loss: 2.464658200634231

Epoch: 6| Step: 10
Training loss: 1.5210123174546066
Validation loss: 2.469202230998207

Epoch: 6| Step: 11
Training loss: 1.4801988984822254
Validation loss: 2.48041638664726

Epoch: 6| Step: 12
Training loss: 2.084692537064057
Validation loss: 2.4934622053538265

Epoch: 6| Step: 13
Training loss: 1.1682982219276001
Validation loss: 2.5086545008926886

Epoch: 210| Step: 0
Training loss: 1.756641184183464
Validation loss: 2.518802643228883

Epoch: 6| Step: 1
Training loss: 1.9030420169371325
Validation loss: 2.4975675973158658

Epoch: 6| Step: 2
Training loss: 1.9817886318321527
Validation loss: 2.4827969079977597

Epoch: 6| Step: 3
Training loss: 1.966099119999881
Validation loss: 2.4407798528576574

Epoch: 6| Step: 4
Training loss: 1.365775027206903
Validation loss: 2.430869307378599

Epoch: 6| Step: 5
Training loss: 1.9196861642407193
Validation loss: 2.3922169657005075

Epoch: 6| Step: 6
Training loss: 1.4023019258430562
Validation loss: 2.3605785911432724

Epoch: 6| Step: 7
Training loss: 1.817065441332457
Validation loss: 2.3614407255206724

Epoch: 6| Step: 8
Training loss: 1.5874027192353832
Validation loss: 2.3586914326179773

Epoch: 6| Step: 9
Training loss: 2.192333875080212
Validation loss: 2.3506212521247036

Epoch: 6| Step: 10
Training loss: 1.7540690934808099
Validation loss: 2.3422436397009507

Epoch: 6| Step: 11
Training loss: 1.8463483056180297
Validation loss: 2.3350146507182474

Epoch: 6| Step: 12
Training loss: 1.9993775114262493
Validation loss: 2.329133979522066

Epoch: 6| Step: 13
Training loss: 1.4869638454451852
Validation loss: 2.350149634874483

Epoch: 211| Step: 0
Training loss: 1.5019264566065436
Validation loss: 2.3743033626069954

Epoch: 6| Step: 1
Training loss: 1.4690160307506162
Validation loss: 2.414818056339275

Epoch: 6| Step: 2
Training loss: 2.064080990658684
Validation loss: 2.4078725610848095

Epoch: 6| Step: 3
Training loss: 2.111009430806875
Validation loss: 2.40834802650829

Epoch: 6| Step: 4
Training loss: 1.875259508612046
Validation loss: 2.431320803681269

Epoch: 6| Step: 5
Training loss: 1.3870286192358194
Validation loss: 2.448471610361237

Epoch: 6| Step: 6
Training loss: 1.8757635469248697
Validation loss: 2.4642184079699305

Epoch: 6| Step: 7
Training loss: 1.8133875548212834
Validation loss: 2.5184197722373143

Epoch: 6| Step: 8
Training loss: 2.3955444382901256
Validation loss: 2.508913830495926

Epoch: 6| Step: 9
Training loss: 2.0584004436265606
Validation loss: 2.4842178296042676

Epoch: 6| Step: 10
Training loss: 1.513347999624921
Validation loss: 2.4358812736070363

Epoch: 6| Step: 11
Training loss: 1.0200027018866564
Validation loss: 2.408820183981816

Epoch: 6| Step: 12
Training loss: 2.132323268351202
Validation loss: 2.3999196259993347

Epoch: 6| Step: 13
Training loss: 1.0789669453469397
Validation loss: 2.3825439710654495

Epoch: 212| Step: 0
Training loss: 1.325754046456069
Validation loss: 2.343817149195062

Epoch: 6| Step: 1
Training loss: 1.4365325657744477
Validation loss: 2.3420376741638447

Epoch: 6| Step: 2
Training loss: 1.9889070316756396
Validation loss: 2.3444965226452323

Epoch: 6| Step: 3
Training loss: 1.315440245134994
Validation loss: 2.3584395289023306

Epoch: 6| Step: 4
Training loss: 2.0826417410836897
Validation loss: 2.331191599133429

Epoch: 6| Step: 5
Training loss: 1.8552161757574546
Validation loss: 2.371295679315283

Epoch: 6| Step: 6
Training loss: 1.8069713063075594
Validation loss: 2.3768761747304685

Epoch: 6| Step: 7
Training loss: 1.6121832780510992
Validation loss: 2.386041568966085

Epoch: 6| Step: 8
Training loss: 2.076109288618929
Validation loss: 2.398395501219628

Epoch: 6| Step: 9
Training loss: 1.866307581979672
Validation loss: 2.3992509909668005

Epoch: 6| Step: 10
Training loss: 1.5264757426508981
Validation loss: 2.411144829870393

Epoch: 6| Step: 11
Training loss: 1.7748966348128612
Validation loss: 2.4241100804138775

Epoch: 6| Step: 12
Training loss: 1.5786467341268704
Validation loss: 2.4477080934189064

Epoch: 6| Step: 13
Training loss: 1.8412964870284498
Validation loss: 2.447507719302407

Epoch: 213| Step: 0
Training loss: 2.356788682957843
Validation loss: 2.4418247772142396

Epoch: 6| Step: 1
Training loss: 1.2473116576185277
Validation loss: 2.4611241184098516

Epoch: 6| Step: 2
Training loss: 1.410799001526486
Validation loss: 2.506654475269614

Epoch: 6| Step: 3
Training loss: 1.824922152387375
Validation loss: 2.519702886388966

Epoch: 6| Step: 4
Training loss: 1.4891479051401102
Validation loss: 2.5543959120898068

Epoch: 6| Step: 5
Training loss: 1.9876386582092607
Validation loss: 2.576772998195578

Epoch: 6| Step: 6
Training loss: 2.1278510322056827
Validation loss: 2.551240589927392

Epoch: 6| Step: 7
Training loss: 2.004717270473243
Validation loss: 2.5108239492778743

Epoch: 6| Step: 8
Training loss: 1.4629226497715035
Validation loss: 2.507242892435618

Epoch: 6| Step: 9
Training loss: 1.6340993528428887
Validation loss: 2.5139291701119424

Epoch: 6| Step: 10
Training loss: 1.6860796991292542
Validation loss: 2.495409992655992

Epoch: 6| Step: 11
Training loss: 1.62057626576675
Validation loss: 2.4746033891124264

Epoch: 6| Step: 12
Training loss: 1.5126032644282776
Validation loss: 2.4548993366123644

Epoch: 6| Step: 13
Training loss: 1.9221114966793977
Validation loss: 2.4304675339925077

Epoch: 214| Step: 0
Training loss: 1.0064455564984605
Validation loss: 2.395467014494652

Epoch: 6| Step: 1
Training loss: 1.4463813747126733
Validation loss: 2.3886366136676163

Epoch: 6| Step: 2
Training loss: 1.8645840934311437
Validation loss: 2.363501324293039

Epoch: 6| Step: 3
Training loss: 2.036392041726598
Validation loss: 2.386511302227723

Epoch: 6| Step: 4
Training loss: 1.7775255718081826
Validation loss: 2.3910111559056846

Epoch: 6| Step: 5
Training loss: 2.0984235386728414
Validation loss: 2.360451157665649

Epoch: 6| Step: 6
Training loss: 1.6971341379592135
Validation loss: 2.380334114403793

Epoch: 6| Step: 7
Training loss: 1.3415261429988024
Validation loss: 2.3892838380030925

Epoch: 6| Step: 8
Training loss: 1.4443662277873068
Validation loss: 2.3841196171701196

Epoch: 6| Step: 9
Training loss: 2.021542873549708
Validation loss: 2.375723104277308

Epoch: 6| Step: 10
Training loss: 1.8350835234423646
Validation loss: 2.3710816410032085

Epoch: 6| Step: 11
Training loss: 1.9528829806106822
Validation loss: 2.3786397859117066

Epoch: 6| Step: 12
Training loss: 1.220285670807326
Validation loss: 2.381269509793217

Epoch: 6| Step: 13
Training loss: 2.1551388074951303
Validation loss: 2.4118393565740814

Epoch: 215| Step: 0
Training loss: 1.8186118896062156
Validation loss: 2.3752039253495623

Epoch: 6| Step: 1
Training loss: 1.0828398289610177
Validation loss: 2.398831557080901

Epoch: 6| Step: 2
Training loss: 1.654341191550556
Validation loss: 2.4017855413468405

Epoch: 6| Step: 3
Training loss: 1.4429211602988767
Validation loss: 2.4528299277910306

Epoch: 6| Step: 4
Training loss: 1.9165224421874327
Validation loss: 2.467241203386929

Epoch: 6| Step: 5
Training loss: 1.6404854851394222
Validation loss: 2.4967713036692283

Epoch: 6| Step: 6
Training loss: 1.5474574215998411
Validation loss: 2.4832824731829657

Epoch: 6| Step: 7
Training loss: 1.9543088453201884
Validation loss: 2.463694243935507

Epoch: 6| Step: 8
Training loss: 1.2510609892348976
Validation loss: 2.4809618284673616

Epoch: 6| Step: 9
Training loss: 2.056259888042572
Validation loss: 2.480342608503221

Epoch: 6| Step: 10
Training loss: 1.5540628376386418
Validation loss: 2.4530984994546245

Epoch: 6| Step: 11
Training loss: 1.5649296752680442
Validation loss: 2.4376770888104384

Epoch: 6| Step: 12
Training loss: 1.6940238027510444
Validation loss: 2.4245156924603997

Epoch: 6| Step: 13
Training loss: 2.061138397212123
Validation loss: 2.4155855080063606

Epoch: 216| Step: 0
Training loss: 1.7057781028037142
Validation loss: 2.3941537056594826

Epoch: 6| Step: 1
Training loss: 1.478156385028067
Validation loss: 2.376890394628583

Epoch: 6| Step: 2
Training loss: 1.5621042894918313
Validation loss: 2.3964261263710873

Epoch: 6| Step: 3
Training loss: 1.809212564348597
Validation loss: 2.3782855678878088

Epoch: 6| Step: 4
Training loss: 1.2378879247354877
Validation loss: 2.3695573873285936

Epoch: 6| Step: 5
Training loss: 1.845303091466112
Validation loss: 2.3952032046170513

Epoch: 6| Step: 6
Training loss: 1.1167363676456443
Validation loss: 2.409277637156746

Epoch: 6| Step: 7
Training loss: 1.6773658498686028
Validation loss: 2.414680453635507

Epoch: 6| Step: 8
Training loss: 2.085939100172022
Validation loss: 2.44042751614158

Epoch: 6| Step: 9
Training loss: 1.7970415121133247
Validation loss: 2.4762304208967914

Epoch: 6| Step: 10
Training loss: 1.6851199284557787
Validation loss: 2.4833213195405572

Epoch: 6| Step: 11
Training loss: 0.927489045482013
Validation loss: 2.518987147564421

Epoch: 6| Step: 12
Training loss: 1.9534733576055014
Validation loss: 2.5363535333293066

Epoch: 6| Step: 13
Training loss: 1.8689309125104931
Validation loss: 2.528303160127384

Epoch: 217| Step: 0
Training loss: 1.4846204052897611
Validation loss: 2.5071072130225693

Epoch: 6| Step: 1
Training loss: 1.1459411685948337
Validation loss: 2.5211637547014907

Epoch: 6| Step: 2
Training loss: 1.9003345445942337
Validation loss: 2.5116492106638955

Epoch: 6| Step: 3
Training loss: 1.8621130266067747
Validation loss: 2.484861267880989

Epoch: 6| Step: 4
Training loss: 1.0793289428320831
Validation loss: 2.4921223338782976

Epoch: 6| Step: 5
Training loss: 1.481130567797909
Validation loss: 2.4932324907347745

Epoch: 6| Step: 6
Training loss: 1.4135118118240604
Validation loss: 2.4850612752018497

Epoch: 6| Step: 7
Training loss: 1.8126659317356504
Validation loss: 2.472425918103827

Epoch: 6| Step: 8
Training loss: 1.4714442762840965
Validation loss: 2.4583090750900194

Epoch: 6| Step: 9
Training loss: 1.9067744799900967
Validation loss: 2.438176077369395

Epoch: 6| Step: 10
Training loss: 1.7082074126689843
Validation loss: 2.4411197107975218

Epoch: 6| Step: 11
Training loss: 1.651623002805421
Validation loss: 2.426541026267311

Epoch: 6| Step: 12
Training loss: 1.58248103776753
Validation loss: 2.440762426134228

Epoch: 6| Step: 13
Training loss: 2.0493738195026765
Validation loss: 2.4448838314100825

Epoch: 218| Step: 0
Training loss: 1.742876130588025
Validation loss: 2.457754699687851

Epoch: 6| Step: 1
Training loss: 1.4131196814820373
Validation loss: 2.471127506624781

Epoch: 6| Step: 2
Training loss: 1.5279754347049856
Validation loss: 2.4474203625534847

Epoch: 6| Step: 3
Training loss: 1.3986491464045439
Validation loss: 2.432614473806143

Epoch: 6| Step: 4
Training loss: 2.164646772153221
Validation loss: 2.4369130486214843

Epoch: 6| Step: 5
Training loss: 1.5467853712837811
Validation loss: 2.419155808537535

Epoch: 6| Step: 6
Training loss: 1.8624940244847648
Validation loss: 2.3951502300090084

Epoch: 6| Step: 7
Training loss: 1.8039266460417165
Validation loss: 2.405457469339279

Epoch: 6| Step: 8
Training loss: 1.0794785337376631
Validation loss: 2.422014487143438

Epoch: 6| Step: 9
Training loss: 1.8258380115518162
Validation loss: 2.424949304253545

Epoch: 6| Step: 10
Training loss: 1.3780237242839222
Validation loss: 2.4445411670994788

Epoch: 6| Step: 11
Training loss: 1.7136832722723343
Validation loss: 2.4415794975912233

Epoch: 6| Step: 12
Training loss: 1.5930596146572955
Validation loss: 2.4825521571618796

Epoch: 6| Step: 13
Training loss: 1.0942532063002104
Validation loss: 2.46717592699699

Epoch: 219| Step: 0
Training loss: 1.4376373225424388
Validation loss: 2.4732814269927714

Epoch: 6| Step: 1
Training loss: 1.6181083674218804
Validation loss: 2.4415567892936183

Epoch: 6| Step: 2
Training loss: 1.9554331454283023
Validation loss: 2.4821487619511293

Epoch: 6| Step: 3
Training loss: 1.7805174274828968
Validation loss: 2.4627538491160106

Epoch: 6| Step: 4
Training loss: 1.974356283236209
Validation loss: 2.490458832191363

Epoch: 6| Step: 5
Training loss: 1.4300984276729491
Validation loss: 2.5144269583783347

Epoch: 6| Step: 6
Training loss: 1.5543480890795172
Validation loss: 2.525845562387127

Epoch: 6| Step: 7
Training loss: 1.9440499003838598
Validation loss: 2.495161489257109

Epoch: 6| Step: 8
Training loss: 1.80579688912822
Validation loss: 2.433928117812511

Epoch: 6| Step: 9
Training loss: 1.5418510928115512
Validation loss: 2.3954445957366364

Epoch: 6| Step: 10
Training loss: 1.4936602449784888
Validation loss: 2.3730256488552444

Epoch: 6| Step: 11
Training loss: 1.2766345560569117
Validation loss: 2.354943725364339

Epoch: 6| Step: 12
Training loss: 1.691178022320516
Validation loss: 2.3735412809140604

Epoch: 6| Step: 13
Training loss: 0.9780904794274685
Validation loss: 2.3538826079475115

Epoch: 220| Step: 0
Training loss: 1.603882240082254
Validation loss: 2.3341309044778273

Epoch: 6| Step: 1
Training loss: 1.578161409165782
Validation loss: 2.3116976668947804

Epoch: 6| Step: 2
Training loss: 1.3956684423194987
Validation loss: 2.330928339479519

Epoch: 6| Step: 3
Training loss: 1.8183697988045413
Validation loss: 2.3428139833560198

Epoch: 6| Step: 4
Training loss: 1.264207022082949
Validation loss: 2.382499414697475

Epoch: 6| Step: 5
Training loss: 1.9958665572913836
Validation loss: 2.396539718978798

Epoch: 6| Step: 6
Training loss: 1.4186912356402712
Validation loss: 2.408758154199768

Epoch: 6| Step: 7
Training loss: 1.4305298205203802
Validation loss: 2.4601068889683892

Epoch: 6| Step: 8
Training loss: 1.7649883371459514
Validation loss: 2.463715869958954

Epoch: 6| Step: 9
Training loss: 1.8518099720069325
Validation loss: 2.488955752578918

Epoch: 6| Step: 10
Training loss: 1.5109799178914054
Validation loss: 2.5045056278000595

Epoch: 6| Step: 11
Training loss: 1.7091043484674058
Validation loss: 2.50894245897684

Epoch: 6| Step: 12
Training loss: 1.3515975153802826
Validation loss: 2.5037143094839553

Epoch: 6| Step: 13
Training loss: 1.2077217472619715
Validation loss: 2.5210002971677516

Epoch: 221| Step: 0
Training loss: 1.2444626228295292
Validation loss: 2.524167830042558

Epoch: 6| Step: 1
Training loss: 0.9819308925384744
Validation loss: 2.500295719991824

Epoch: 6| Step: 2
Training loss: 2.087182291489585
Validation loss: 2.490760789083774

Epoch: 6| Step: 3
Training loss: 1.1142437973277763
Validation loss: 2.4860073615701634

Epoch: 6| Step: 4
Training loss: 1.5436552041790415
Validation loss: 2.4878271771074956

Epoch: 6| Step: 5
Training loss: 1.8133384475332022
Validation loss: 2.476031798964042

Epoch: 6| Step: 6
Training loss: 1.6011013948926829
Validation loss: 2.481875581662064

Epoch: 6| Step: 7
Training loss: 1.1459811144232999
Validation loss: 2.4588765718536423

Epoch: 6| Step: 8
Training loss: 1.66958775440326
Validation loss: 2.4436588713170613

Epoch: 6| Step: 9
Training loss: 1.4674555979417374
Validation loss: 2.437489465649193

Epoch: 6| Step: 10
Training loss: 2.3599147558172775
Validation loss: 2.4248384623824855

Epoch: 6| Step: 11
Training loss: 1.47532804041788
Validation loss: 2.422987202964809

Epoch: 6| Step: 12
Training loss: 1.480373409693955
Validation loss: 2.428011448523699

Epoch: 6| Step: 13
Training loss: 0.9546480048917853
Validation loss: 2.42596761286072

Epoch: 222| Step: 0
Training loss: 1.3679258260305054
Validation loss: 2.4032170561624078

Epoch: 6| Step: 1
Training loss: 1.6330352339251866
Validation loss: 2.418108812864035

Epoch: 6| Step: 2
Training loss: 1.8034113876363986
Validation loss: 2.416078244632137

Epoch: 6| Step: 3
Training loss: 0.9440540417643022
Validation loss: 2.3973392271305025

Epoch: 6| Step: 4
Training loss: 0.7574317998368657
Validation loss: 2.410568023696335

Epoch: 6| Step: 5
Training loss: 1.6026263913496008
Validation loss: 2.419877179989508

Epoch: 6| Step: 6
Training loss: 1.6347934807121227
Validation loss: 2.414500342990625

Epoch: 6| Step: 7
Training loss: 1.1421784574095926
Validation loss: 2.4334049570693668

Epoch: 6| Step: 8
Training loss: 1.8852681967374723
Validation loss: 2.4528299497397406

Epoch: 6| Step: 9
Training loss: 1.6907123084801823
Validation loss: 2.456831542348335

Epoch: 6| Step: 10
Training loss: 1.717264678026003
Validation loss: 2.480598533257538

Epoch: 6| Step: 11
Training loss: 1.5513607451002454
Validation loss: 2.456162355649233

Epoch: 6| Step: 12
Training loss: 1.5195409779372095
Validation loss: 2.472921661806764

Epoch: 6| Step: 13
Training loss: 1.86991905975608
Validation loss: 2.469461326360394

Epoch: 223| Step: 0
Training loss: 1.2263960998791654
Validation loss: 2.4955316429616206

Epoch: 6| Step: 1
Training loss: 1.0764280038651857
Validation loss: 2.5063346239676765

Epoch: 6| Step: 2
Training loss: 1.705209698576508
Validation loss: 2.4852645554823543

Epoch: 6| Step: 3
Training loss: 1.7858430638881122
Validation loss: 2.5001028111554757

Epoch: 6| Step: 4
Training loss: 1.5074030661218858
Validation loss: 2.4721469128736935

Epoch: 6| Step: 5
Training loss: 1.5576615760720585
Validation loss: 2.4816962724834526

Epoch: 6| Step: 6
Training loss: 1.1563498479672403
Validation loss: 2.4709733396230757

Epoch: 6| Step: 7
Training loss: 1.419487930165917
Validation loss: 2.455839071890898

Epoch: 6| Step: 8
Training loss: 1.707198913860065
Validation loss: 2.454066862088179

Epoch: 6| Step: 9
Training loss: 0.9412262297284695
Validation loss: 2.4296121703325637

Epoch: 6| Step: 10
Training loss: 1.7076936392504656
Validation loss: 2.4331892940887596

Epoch: 6| Step: 11
Training loss: 1.584539840519975
Validation loss: 2.4269134139491753

Epoch: 6| Step: 12
Training loss: 1.5620298059626059
Validation loss: 2.4271648119909663

Epoch: 6| Step: 13
Training loss: 2.1358735750981355
Validation loss: 2.4093065142539185

Epoch: 224| Step: 0
Training loss: 1.5419985267938883
Validation loss: 2.4029210617922643

Epoch: 6| Step: 1
Training loss: 1.0183860222213075
Validation loss: 2.435171339658161

Epoch: 6| Step: 2
Training loss: 1.4535326642229733
Validation loss: 2.4378039651957075

Epoch: 6| Step: 3
Training loss: 1.0430088106955462
Validation loss: 2.4471369506727907

Epoch: 6| Step: 4
Training loss: 1.8292551052579584
Validation loss: 2.4487790289038065

Epoch: 6| Step: 5
Training loss: 1.4839260024569358
Validation loss: 2.4672086087896608

Epoch: 6| Step: 6
Training loss: 1.4254258640456827
Validation loss: 2.4850180984058867

Epoch: 6| Step: 7
Training loss: 1.0956415441279115
Validation loss: 2.4763890289091948

Epoch: 6| Step: 8
Training loss: 1.9183489078957787
Validation loss: 2.4765800676531136

Epoch: 6| Step: 9
Training loss: 1.1984076226400728
Validation loss: 2.4441236536095876

Epoch: 6| Step: 10
Training loss: 2.091108107236425
Validation loss: 2.437324465017762

Epoch: 6| Step: 11
Training loss: 1.054835499869806
Validation loss: 2.425056845406038

Epoch: 6| Step: 12
Training loss: 1.4545387855832066
Validation loss: 2.438512630170363

Epoch: 6| Step: 13
Training loss: 1.7335774417916388
Validation loss: 2.4564596418637983

Epoch: 225| Step: 0
Training loss: 1.2363299570175506
Validation loss: 2.429628152329875

Epoch: 6| Step: 1
Training loss: 1.3718244121843692
Validation loss: 2.463287446716698

Epoch: 6| Step: 2
Training loss: 2.0195853191051425
Validation loss: 2.435408113971044

Epoch: 6| Step: 3
Training loss: 1.3016381634429703
Validation loss: 2.4689623792104474

Epoch: 6| Step: 4
Training loss: 1.2085460059137318
Validation loss: 2.4690827456589166

Epoch: 6| Step: 5
Training loss: 1.2488672846339224
Validation loss: 2.4601132998673263

Epoch: 6| Step: 6
Training loss: 1.7645282546105545
Validation loss: 2.4756578588097726

Epoch: 6| Step: 7
Training loss: 1.2285647238424868
Validation loss: 2.4744628367665

Epoch: 6| Step: 8
Training loss: 1.5555069647117772
Validation loss: 2.469581883374374

Epoch: 6| Step: 9
Training loss: 1.3112610918854144
Validation loss: 2.4441464141032587

Epoch: 6| Step: 10
Training loss: 1.2755471757084822
Validation loss: 2.444054878909052

Epoch: 6| Step: 11
Training loss: 1.6348468573474275
Validation loss: 2.448188075142068

Epoch: 6| Step: 12
Training loss: 1.5789696727398697
Validation loss: 2.4492736863627695

Epoch: 6| Step: 13
Training loss: 1.7154536455251943
Validation loss: 2.4351540459780128

Epoch: 226| Step: 0
Training loss: 1.2883162679360367
Validation loss: 2.419399249103348

Epoch: 6| Step: 1
Training loss: 1.4565325745260618
Validation loss: 2.415741324468487

Epoch: 6| Step: 2
Training loss: 0.9449871543737817
Validation loss: 2.446283817398212

Epoch: 6| Step: 3
Training loss: 1.5002944180511941
Validation loss: 2.475903237326147

Epoch: 6| Step: 4
Training loss: 1.3225355675715342
Validation loss: 2.475133376196078

Epoch: 6| Step: 5
Training loss: 1.5213579117954035
Validation loss: 2.4698531932478742

Epoch: 6| Step: 6
Training loss: 1.6901385554110102
Validation loss: 2.4475601917680025

Epoch: 6| Step: 7
Training loss: 1.532359752616202
Validation loss: 2.457079587673807

Epoch: 6| Step: 8
Training loss: 1.466242333641726
Validation loss: 2.4370900564807694

Epoch: 6| Step: 9
Training loss: 1.2467236018226877
Validation loss: 2.3959840688774823

Epoch: 6| Step: 10
Training loss: 1.6595820612052137
Validation loss: 2.3799381590588893

Epoch: 6| Step: 11
Training loss: 1.054102474012223
Validation loss: 2.378191779102176

Epoch: 6| Step: 12
Training loss: 1.6282003140007704
Validation loss: 2.387159218777904

Epoch: 6| Step: 13
Training loss: 2.0326469899383826
Validation loss: 2.4065162544412226

Epoch: 227| Step: 0
Training loss: 1.3513906292426592
Validation loss: 2.403182365082387

Epoch: 6| Step: 1
Training loss: 1.8227327817177656
Validation loss: 2.417804468911651

Epoch: 6| Step: 2
Training loss: 1.4512481874755265
Validation loss: 2.4205901443586897

Epoch: 6| Step: 3
Training loss: 1.3051826314179102
Validation loss: 2.448488622561077

Epoch: 6| Step: 4
Training loss: 1.563180927677804
Validation loss: 2.4675307601063845

Epoch: 6| Step: 5
Training loss: 0.9268591677650478
Validation loss: 2.4525705472129165

Epoch: 6| Step: 6
Training loss: 1.2641305459548815
Validation loss: 2.4768509426883463

Epoch: 6| Step: 7
Training loss: 1.3974348341705147
Validation loss: 2.4858187397022204

Epoch: 6| Step: 8
Training loss: 1.4669733868286685
Validation loss: 2.4514488501364955

Epoch: 6| Step: 9
Training loss: 1.283041422742399
Validation loss: 2.49190947899433

Epoch: 6| Step: 10
Training loss: 1.5896300376073746
Validation loss: 2.478161428531615

Epoch: 6| Step: 11
Training loss: 1.0411830860449456
Validation loss: 2.448531533655765

Epoch: 6| Step: 12
Training loss: 1.9422922856489018
Validation loss: 2.445714574747671

Epoch: 6| Step: 13
Training loss: 1.492369955202435
Validation loss: 2.4519234802877308

Epoch: 228| Step: 0
Training loss: 1.6262716306263847
Validation loss: 2.4400628833091287

Epoch: 6| Step: 1
Training loss: 0.9705368912812906
Validation loss: 2.4472231233074995

Epoch: 6| Step: 2
Training loss: 1.8089740262757998
Validation loss: 2.4421536637349317

Epoch: 6| Step: 3
Training loss: 1.651957581758294
Validation loss: 2.439293673935811

Epoch: 6| Step: 4
Training loss: 1.0602686395857368
Validation loss: 2.4289394335350716

Epoch: 6| Step: 5
Training loss: 1.4428458945821954
Validation loss: 2.461912886328649

Epoch: 6| Step: 6
Training loss: 1.3573740120552276
Validation loss: 2.4547860018135776

Epoch: 6| Step: 7
Training loss: 1.2016471604780299
Validation loss: 2.4384647539463393

Epoch: 6| Step: 8
Training loss: 1.0396234245953417
Validation loss: 2.456596600174824

Epoch: 6| Step: 9
Training loss: 1.5389946472392153
Validation loss: 2.4315939239723416

Epoch: 6| Step: 10
Training loss: 1.9083482419671256
Validation loss: 2.438034554326148

Epoch: 6| Step: 11
Training loss: 1.300198948748929
Validation loss: 2.4385288487259174

Epoch: 6| Step: 12
Training loss: 1.5006828343353564
Validation loss: 2.4479057413004446

Epoch: 6| Step: 13
Training loss: 1.1201093119682815
Validation loss: 2.431831808786751

Epoch: 229| Step: 0
Training loss: 1.1176864470193364
Validation loss: 2.456795422219055

Epoch: 6| Step: 1
Training loss: 1.2486182204965737
Validation loss: 2.4497066424718486

Epoch: 6| Step: 2
Training loss: 1.1472092892274692
Validation loss: 2.441419827331198

Epoch: 6| Step: 3
Training loss: 1.690768784703647
Validation loss: 2.436657768747144

Epoch: 6| Step: 4
Training loss: 1.2410584122699526
Validation loss: 2.4476075496743364

Epoch: 6| Step: 5
Training loss: 1.3929241761645976
Validation loss: 2.4570940549855615

Epoch: 6| Step: 6
Training loss: 1.1938652801773026
Validation loss: 2.4431393294264834

Epoch: 6| Step: 7
Training loss: 1.7997454728203253
Validation loss: 2.4420220115612707

Epoch: 6| Step: 8
Training loss: 1.1965335767333252
Validation loss: 2.4038870174320293

Epoch: 6| Step: 9
Training loss: 1.6926822210400778
Validation loss: 2.418255817770501

Epoch: 6| Step: 10
Training loss: 1.7925199059055459
Validation loss: 2.42405479057288

Epoch: 6| Step: 11
Training loss: 1.118875255712114
Validation loss: 2.398612101521535

Epoch: 6| Step: 12
Training loss: 1.5230346146956197
Validation loss: 2.4229917695025693

Epoch: 6| Step: 13
Training loss: 1.0297609039677682
Validation loss: 2.4181153393488524

Epoch: 230| Step: 0
Training loss: 1.5972717120846884
Validation loss: 2.42053112490915

Epoch: 6| Step: 1
Training loss: 1.727021307420079
Validation loss: 2.4466814197707856

Epoch: 6| Step: 2
Training loss: 0.9111557739897127
Validation loss: 2.4762318889513444

Epoch: 6| Step: 3
Training loss: 0.968589831001389
Validation loss: 2.471398643707964

Epoch: 6| Step: 4
Training loss: 1.7702971899678612
Validation loss: 2.4925964392336533

Epoch: 6| Step: 5
Training loss: 1.205570757067382
Validation loss: 2.5108405436041132

Epoch: 6| Step: 6
Training loss: 1.6009350547794192
Validation loss: 2.480529026845856

Epoch: 6| Step: 7
Training loss: 0.8212682333537733
Validation loss: 2.5282761861738416

Epoch: 6| Step: 8
Training loss: 1.695778989116385
Validation loss: 2.536215077886361

Epoch: 6| Step: 9
Training loss: 1.0782776876494937
Validation loss: 2.5381610824531946

Epoch: 6| Step: 10
Training loss: 1.3593378171549046
Validation loss: 2.528200985709033

Epoch: 6| Step: 11
Training loss: 1.3710205406358649
Validation loss: 2.558139279026953

Epoch: 6| Step: 12
Training loss: 1.9566361262566194
Validation loss: 2.5375198340043665

Epoch: 6| Step: 13
Training loss: 1.1380063659074255
Validation loss: 2.491084824365022

Epoch: 231| Step: 0
Training loss: 1.2066973375581425
Validation loss: 2.4407492836671567

Epoch: 6| Step: 1
Training loss: 1.0331514341984567
Validation loss: 2.43190321512827

Epoch: 6| Step: 2
Training loss: 1.5136525798921414
Validation loss: 2.419897826731258

Epoch: 6| Step: 3
Training loss: 1.3110932122416843
Validation loss: 2.429423010478411

Epoch: 6| Step: 4
Training loss: 1.780059818377105
Validation loss: 2.400442378059453

Epoch: 6| Step: 5
Training loss: 0.8344722991103317
Validation loss: 2.4193120281984846

Epoch: 6| Step: 6
Training loss: 1.6758263499631199
Validation loss: 2.407358973823737

Epoch: 6| Step: 7
Training loss: 1.6571539085705569
Validation loss: 2.408444174896827

Epoch: 6| Step: 8
Training loss: 1.6539167127246779
Validation loss: 2.4268428601148346

Epoch: 6| Step: 9
Training loss: 1.6091600293036263
Validation loss: 2.4576517327825145

Epoch: 6| Step: 10
Training loss: 1.4789925414562122
Validation loss: 2.450702180120097

Epoch: 6| Step: 11
Training loss: 1.4542783036686906
Validation loss: 2.451001854437635

Epoch: 6| Step: 12
Training loss: 1.3734899378499283
Validation loss: 2.4313742423073066

Epoch: 6| Step: 13
Training loss: 1.5621739619554216
Validation loss: 2.4288143238524387

Epoch: 232| Step: 0
Training loss: 1.1290019169699086
Validation loss: 2.4451109356121363

Epoch: 6| Step: 1
Training loss: 1.5121684034055793
Validation loss: 2.4593421620811604

Epoch: 6| Step: 2
Training loss: 1.5520477120154246
Validation loss: 2.4606840967782055

Epoch: 6| Step: 3
Training loss: 2.159505404607568
Validation loss: 2.4609392688625715

Epoch: 6| Step: 4
Training loss: 1.060673602490513
Validation loss: 2.4746285425889614

Epoch: 6| Step: 5
Training loss: 1.0363639264585462
Validation loss: 2.4934086137492586

Epoch: 6| Step: 6
Training loss: 1.2482191274390388
Validation loss: 2.49242187163286

Epoch: 6| Step: 7
Training loss: 1.6070993129946896
Validation loss: 2.5214312305468702

Epoch: 6| Step: 8
Training loss: 1.3409922490247959
Validation loss: 2.582735266974111

Epoch: 6| Step: 9
Training loss: 1.432663868024627
Validation loss: 2.5539335420451987

Epoch: 6| Step: 10
Training loss: 1.3615855954540148
Validation loss: 2.5340055119860594

Epoch: 6| Step: 11
Training loss: 1.3372970266611621
Validation loss: 2.5075621959350434

Epoch: 6| Step: 12
Training loss: 1.1676321405785193
Validation loss: 2.475933916084772

Epoch: 6| Step: 13
Training loss: 1.310575482074723
Validation loss: 2.4869456206416576

Epoch: 233| Step: 0
Training loss: 1.8562021833740914
Validation loss: 2.47244091982336

Epoch: 6| Step: 1
Training loss: 1.194294065550889
Validation loss: 2.468118962087909

Epoch: 6| Step: 2
Training loss: 1.2975960071596362
Validation loss: 2.439559239171266

Epoch: 6| Step: 3
Training loss: 0.9164724939051121
Validation loss: 2.4181645842682533

Epoch: 6| Step: 4
Training loss: 1.6761155584187326
Validation loss: 2.432716656781339

Epoch: 6| Step: 5
Training loss: 1.2389591900352304
Validation loss: 2.433146248336057

Epoch: 6| Step: 6
Training loss: 1.5761357980449477
Validation loss: 2.4206410398064353

Epoch: 6| Step: 7
Training loss: 1.0735642537403989
Validation loss: 2.430467804019553

Epoch: 6| Step: 8
Training loss: 1.176746061274313
Validation loss: 2.4279875350203315

Epoch: 6| Step: 9
Training loss: 1.6540253291375895
Validation loss: 2.4509240120936546

Epoch: 6| Step: 10
Training loss: 1.4248717869416925
Validation loss: 2.4889823121851515

Epoch: 6| Step: 11
Training loss: 1.0756786621645635
Validation loss: 2.4846968893425325

Epoch: 6| Step: 12
Training loss: 1.642776967100298
Validation loss: 2.4809244517762448

Epoch: 6| Step: 13
Training loss: 1.36030362736906
Validation loss: 2.4718765911134875

Epoch: 234| Step: 0
Training loss: 1.8785631021111007
Validation loss: 2.4452662603315396

Epoch: 6| Step: 1
Training loss: 1.0334700760553286
Validation loss: 2.4258638198515077

Epoch: 6| Step: 2
Training loss: 1.2979042381234474
Validation loss: 2.4254596942205713

Epoch: 6| Step: 3
Training loss: 1.0815407092068665
Validation loss: 2.4637269581260073

Epoch: 6| Step: 4
Training loss: 1.4414557885235135
Validation loss: 2.441875681515559

Epoch: 6| Step: 5
Training loss: 1.387257044372987
Validation loss: 2.428097151182983

Epoch: 6| Step: 6
Training loss: 1.3570754672650078
Validation loss: 2.443377758451513

Epoch: 6| Step: 7
Training loss: 1.7192932657486568
Validation loss: 2.4356499027708463

Epoch: 6| Step: 8
Training loss: 1.187286106722901
Validation loss: 2.4194412763939726

Epoch: 6| Step: 9
Training loss: 1.5235596436661833
Validation loss: 2.435702195996674

Epoch: 6| Step: 10
Training loss: 0.9872784861060265
Validation loss: 2.417236050654191

Epoch: 6| Step: 11
Training loss: 1.521056206802671
Validation loss: 2.440035091480997

Epoch: 6| Step: 12
Training loss: 1.0400098339862984
Validation loss: 2.431688987704664

Epoch: 6| Step: 13
Training loss: 1.0795360674290262
Validation loss: 2.422741998672811

Epoch: 235| Step: 0
Training loss: 1.3915093428188108
Validation loss: 2.455755416814552

Epoch: 6| Step: 1
Training loss: 1.4926170809268726
Validation loss: 2.433953727455634

Epoch: 6| Step: 2
Training loss: 1.19551054865875
Validation loss: 2.4673242799309794

Epoch: 6| Step: 3
Training loss: 1.579128588349049
Validation loss: 2.465838346558534

Epoch: 6| Step: 4
Training loss: 1.4380407560194184
Validation loss: 2.4546122570574616

Epoch: 6| Step: 5
Training loss: 1.1870284901183035
Validation loss: 2.442160898047635

Epoch: 6| Step: 6
Training loss: 1.754573907342958
Validation loss: 2.4248902603351037

Epoch: 6| Step: 7
Training loss: 1.0654868609702648
Validation loss: 2.431159500604414

Epoch: 6| Step: 8
Training loss: 0.9767313696766563
Validation loss: 2.436358943865037

Epoch: 6| Step: 9
Training loss: 1.4580718305551588
Validation loss: 2.438118865796984

Epoch: 6| Step: 10
Training loss: 0.9235816287989556
Validation loss: 2.43181226065057

Epoch: 6| Step: 11
Training loss: 1.5039655401259133
Validation loss: 2.42349758302077

Epoch: 6| Step: 12
Training loss: 1.0821720403524822
Validation loss: 2.4328714782704965

Epoch: 6| Step: 13
Training loss: 1.4374915412985676
Validation loss: 2.463571490829819

Epoch: 236| Step: 0
Training loss: 1.2603712888173266
Validation loss: 2.441589783822987

Epoch: 6| Step: 1
Training loss: 1.163065694765726
Validation loss: 2.453502934467836

Epoch: 6| Step: 2
Training loss: 1.0194990949565916
Validation loss: 2.461907269959517

Epoch: 6| Step: 3
Training loss: 1.468436349696626
Validation loss: 2.4721107811133565

Epoch: 6| Step: 4
Training loss: 1.4156366511995953
Validation loss: 2.4548942320900453

Epoch: 6| Step: 5
Training loss: 1.0668001111322667
Validation loss: 2.442371040676653

Epoch: 6| Step: 6
Training loss: 1.5978321081249447
Validation loss: 2.408347052508008

Epoch: 6| Step: 7
Training loss: 1.5603303723311586
Validation loss: 2.434014536902374

Epoch: 6| Step: 8
Training loss: 1.454304042473692
Validation loss: 2.4460496658547712

Epoch: 6| Step: 9
Training loss: 1.0827361196906717
Validation loss: 2.4295317807637007

Epoch: 6| Step: 10
Training loss: 1.8497136538796692
Validation loss: 2.453423778595308

Epoch: 6| Step: 11
Training loss: 1.2764028180847093
Validation loss: 2.4505002503674187

Epoch: 6| Step: 12
Training loss: 1.0403978185712215
Validation loss: 2.469009336986135

Epoch: 6| Step: 13
Training loss: 0.8152372761388245
Validation loss: 2.44992361922801

Epoch: 237| Step: 0
Training loss: 0.9235943423846712
Validation loss: 2.461161685387148

Epoch: 6| Step: 1
Training loss: 1.1102955182508396
Validation loss: 2.4690221717207206

Epoch: 6| Step: 2
Training loss: 1.59675688484061
Validation loss: 2.47053896249867

Epoch: 6| Step: 3
Training loss: 1.5381206593303047
Validation loss: 2.482898683439088

Epoch: 6| Step: 4
Training loss: 0.9108539902897388
Validation loss: 2.4686230135774756

Epoch: 6| Step: 5
Training loss: 0.9685829387713112
Validation loss: 2.4766130629525507

Epoch: 6| Step: 6
Training loss: 1.148866015564635
Validation loss: 2.4922518847055333

Epoch: 6| Step: 7
Training loss: 1.0653831968295402
Validation loss: 2.498373160637864

Epoch: 6| Step: 8
Training loss: 1.2443349258354073
Validation loss: 2.467973893711777

Epoch: 6| Step: 9
Training loss: 1.560142111296335
Validation loss: 2.495497708181777

Epoch: 6| Step: 10
Training loss: 1.6680465072625
Validation loss: 2.4781341219041044

Epoch: 6| Step: 11
Training loss: 1.2871734186427015
Validation loss: 2.4595763969285707

Epoch: 6| Step: 12
Training loss: 1.7297289366957902
Validation loss: 2.450346429209566

Epoch: 6| Step: 13
Training loss: 0.9643885353310365
Validation loss: 2.450049458051188

Epoch: 238| Step: 0
Training loss: 1.695544600529831
Validation loss: 2.4534276192093363

Epoch: 6| Step: 1
Training loss: 1.3166830071912095
Validation loss: 2.459162618281859

Epoch: 6| Step: 2
Training loss: 1.1398718450690641
Validation loss: 2.4563521933936197

Epoch: 6| Step: 3
Training loss: 1.0636683939954918
Validation loss: 2.471667107716814

Epoch: 6| Step: 4
Training loss: 0.9340870084894185
Validation loss: 2.468093039060565

Epoch: 6| Step: 5
Training loss: 1.7675044766252042
Validation loss: 2.4605318385218085

Epoch: 6| Step: 6
Training loss: 1.1619440554186198
Validation loss: 2.461350376166781

Epoch: 6| Step: 7
Training loss: 1.020304069075284
Validation loss: 2.4628964748916333

Epoch: 6| Step: 8
Training loss: 1.1478898176225318
Validation loss: 2.4765569722346914

Epoch: 6| Step: 9
Training loss: 1.4202513594524349
Validation loss: 2.4682831120887823

Epoch: 6| Step: 10
Training loss: 1.2568475564154324
Validation loss: 2.4466976470452226

Epoch: 6| Step: 11
Training loss: 1.3795747082270804
Validation loss: 2.423616073648293

Epoch: 6| Step: 12
Training loss: 1.3771191652438732
Validation loss: 2.432008749009982

Epoch: 6| Step: 13
Training loss: 1.410454969388462
Validation loss: 2.4369253380933658

Epoch: 239| Step: 0
Training loss: 1.3449703707498115
Validation loss: 2.4232480917827877

Epoch: 6| Step: 1
Training loss: 0.8220927222041696
Validation loss: 2.408893163221812

Epoch: 6| Step: 2
Training loss: 1.4710712352129807
Validation loss: 2.425196529036843

Epoch: 6| Step: 3
Training loss: 1.0999049167286283
Validation loss: 2.416211254701591

Epoch: 6| Step: 4
Training loss: 1.2981323214064138
Validation loss: 2.4697195277870914

Epoch: 6| Step: 5
Training loss: 1.1259670339877617
Validation loss: 2.502757847300937

Epoch: 6| Step: 6
Training loss: 1.8465931840362406
Validation loss: 2.507446683553358

Epoch: 6| Step: 7
Training loss: 0.9218400851604591
Validation loss: 2.461772625297825

Epoch: 6| Step: 8
Training loss: 1.1167449074469584
Validation loss: 2.4633048837255456

Epoch: 6| Step: 9
Training loss: 1.953879370918239
Validation loss: 2.459251726217422

Epoch: 6| Step: 10
Training loss: 1.415034344798899
Validation loss: 2.4545181526911892

Epoch: 6| Step: 11
Training loss: 1.1918432216078498
Validation loss: 2.4776692082271765

Epoch: 6| Step: 12
Training loss: 1.0386469877833004
Validation loss: 2.4879092519584804

Epoch: 6| Step: 13
Training loss: 0.9671867124095169
Validation loss: 2.4699062777244736

Epoch: 240| Step: 0
Training loss: 1.5559333142011476
Validation loss: 2.488551945939116

Epoch: 6| Step: 1
Training loss: 1.2096126569311534
Validation loss: 2.514534660654203

Epoch: 6| Step: 2
Training loss: 0.8478202133868329
Validation loss: 2.4859333229309577

Epoch: 6| Step: 3
Training loss: 1.4236293491756302
Validation loss: 2.5045151698878128

Epoch: 6| Step: 4
Training loss: 1.3668860402858374
Validation loss: 2.5054544239252445

Epoch: 6| Step: 5
Training loss: 1.2152729809378764
Validation loss: 2.4976817672910054

Epoch: 6| Step: 6
Training loss: 1.4475100744552398
Validation loss: 2.507153042239161

Epoch: 6| Step: 7
Training loss: 1.1728087710436386
Validation loss: 2.4721736359539244

Epoch: 6| Step: 8
Training loss: 1.1084009649441173
Validation loss: 2.4740671800762657

Epoch: 6| Step: 9
Training loss: 1.3989863677161634
Validation loss: 2.4811446794915994

Epoch: 6| Step: 10
Training loss: 0.994953535135615
Validation loss: 2.4753115016190073

Epoch: 6| Step: 11
Training loss: 1.5080989901484962
Validation loss: 2.4650504868319736

Epoch: 6| Step: 12
Training loss: 1.2364900070200031
Validation loss: 2.4687736305527492

Epoch: 6| Step: 13
Training loss: 1.3199292591675293
Validation loss: 2.464133125662368

Epoch: 241| Step: 0
Training loss: 1.2967307688469452
Validation loss: 2.4756345342160744

Epoch: 6| Step: 1
Training loss: 1.1310122687992281
Validation loss: 2.4734654013322115

Epoch: 6| Step: 2
Training loss: 0.9756839920576144
Validation loss: 2.45672730018221

Epoch: 6| Step: 3
Training loss: 1.176962123245193
Validation loss: 2.4709363305997583

Epoch: 6| Step: 4
Training loss: 1.1300756608057303
Validation loss: 2.47905773789747

Epoch: 6| Step: 5
Training loss: 1.240115855403683
Validation loss: 2.487752975707084

Epoch: 6| Step: 6
Training loss: 1.0363580600917046
Validation loss: 2.4988035779580695

Epoch: 6| Step: 7
Training loss: 1.3673864601325258
Validation loss: 2.4923268830598913

Epoch: 6| Step: 8
Training loss: 1.70211657145749
Validation loss: 2.5164498788383036

Epoch: 6| Step: 9
Training loss: 1.1108301317398244
Validation loss: 2.497614262601527

Epoch: 6| Step: 10
Training loss: 1.4080518834432916
Validation loss: 2.464599481822257

Epoch: 6| Step: 11
Training loss: 1.813088288696566
Validation loss: 2.4702745296666224

Epoch: 6| Step: 12
Training loss: 1.1274645618358923
Validation loss: 2.468956384823705

Epoch: 6| Step: 13
Training loss: 1.0319726319454463
Validation loss: 2.4459075775033225

Epoch: 242| Step: 0
Training loss: 1.2173738780092387
Validation loss: 2.480174235173682

Epoch: 6| Step: 1
Training loss: 1.2836107509459995
Validation loss: 2.48631184911128

Epoch: 6| Step: 2
Training loss: 1.6166640461903732
Validation loss: 2.4731296099884306

Epoch: 6| Step: 3
Training loss: 1.0275278832951915
Validation loss: 2.4686826974800113

Epoch: 6| Step: 4
Training loss: 0.9611963683248262
Validation loss: 2.4761419902283914

Epoch: 6| Step: 5
Training loss: 1.272979279438643
Validation loss: 2.4879537686191187

Epoch: 6| Step: 6
Training loss: 0.9413386277094031
Validation loss: 2.4776648397262204

Epoch: 6| Step: 7
Training loss: 1.1943458687719501
Validation loss: 2.4831374348043056

Epoch: 6| Step: 8
Training loss: 1.6249609722439238
Validation loss: 2.4570630961282856

Epoch: 6| Step: 9
Training loss: 1.2337233356350121
Validation loss: 2.467989362925934

Epoch: 6| Step: 10
Training loss: 1.3864243745645555
Validation loss: 2.4535557384597144

Epoch: 6| Step: 11
Training loss: 1.2635918758487399
Validation loss: 2.460912704538184

Epoch: 6| Step: 12
Training loss: 1.1043137626314725
Validation loss: 2.4820009242903356

Epoch: 6| Step: 13
Training loss: 1.0645667899103624
Validation loss: 2.488186830764789

Epoch: 243| Step: 0
Training loss: 1.2256888904871956
Validation loss: 2.4908438417823033

Epoch: 6| Step: 1
Training loss: 1.5445861837509824
Validation loss: 2.460629918386046

Epoch: 6| Step: 2
Training loss: 1.0806763356482434
Validation loss: 2.487071389101912

Epoch: 6| Step: 3
Training loss: 1.0556170852752895
Validation loss: 2.484592901059013

Epoch: 6| Step: 4
Training loss: 1.1351444839739389
Validation loss: 2.4722493844312408

Epoch: 6| Step: 5
Training loss: 1.00614762111186
Validation loss: 2.466431901321218

Epoch: 6| Step: 6
Training loss: 1.1008375230623304
Validation loss: 2.439052190644088

Epoch: 6| Step: 7
Training loss: 1.4621876146610393
Validation loss: 2.4719935208807278

Epoch: 6| Step: 8
Training loss: 1.0274512521173937
Validation loss: 2.4368081784653133

Epoch: 6| Step: 9
Training loss: 1.4980126567249865
Validation loss: 2.4583509971883672

Epoch: 6| Step: 10
Training loss: 1.1323691717373245
Validation loss: 2.456476911830456

Epoch: 6| Step: 11
Training loss: 1.444181422389142
Validation loss: 2.487337988878339

Epoch: 6| Step: 12
Training loss: 1.29499588836842
Validation loss: 2.4591416736225002

Epoch: 6| Step: 13
Training loss: 1.0756439741944759
Validation loss: 2.4862861982593585

Epoch: 244| Step: 0
Training loss: 1.5382539590765714
Validation loss: 2.4763590742495825

Epoch: 6| Step: 1
Training loss: 1.2533888655561654
Validation loss: 2.4761106312346874

Epoch: 6| Step: 2
Training loss: 1.2983031165475702
Validation loss: 2.4912959427151606

Epoch: 6| Step: 3
Training loss: 0.770425654335337
Validation loss: 2.50660975173769

Epoch: 6| Step: 4
Training loss: 1.4513458517326436
Validation loss: 2.461820643900045

Epoch: 6| Step: 5
Training loss: 1.0691033097244198
Validation loss: 2.4773121846164794

Epoch: 6| Step: 6
Training loss: 1.280124635290901
Validation loss: 2.4731179503092426

Epoch: 6| Step: 7
Training loss: 0.956642445585513
Validation loss: 2.4613703177668267

Epoch: 6| Step: 8
Training loss: 1.1803274881806567
Validation loss: 2.446455192791052

Epoch: 6| Step: 9
Training loss: 1.1358277279628513
Validation loss: 2.429107751953127

Epoch: 6| Step: 10
Training loss: 1.368173341903422
Validation loss: 2.437462415423832

Epoch: 6| Step: 11
Training loss: 1.4285562344151785
Validation loss: 2.458010499723553

Epoch: 6| Step: 12
Training loss: 1.0837353669512935
Validation loss: 2.4354949436969644

Epoch: 6| Step: 13
Training loss: 1.1344110194180823
Validation loss: 2.451563838768394

Epoch: 245| Step: 0
Training loss: 1.2339251700577811
Validation loss: 2.45782079684368

Epoch: 6| Step: 1
Training loss: 1.1781429259052034
Validation loss: 2.4841927567115194

Epoch: 6| Step: 2
Training loss: 1.4090777470653564
Validation loss: 2.490123144661982

Epoch: 6| Step: 3
Training loss: 1.4558050400871134
Validation loss: 2.521339195572666

Epoch: 6| Step: 4
Training loss: 0.9732636542941273
Validation loss: 2.5284054875768454

Epoch: 6| Step: 5
Training loss: 1.5559640368887664
Validation loss: 2.520266018961784

Epoch: 6| Step: 6
Training loss: 1.3893757041143435
Validation loss: 2.5356336832621613

Epoch: 6| Step: 7
Training loss: 0.7390553286569438
Validation loss: 2.513144547451522

Epoch: 6| Step: 8
Training loss: 1.2295843912445623
Validation loss: 2.507406538270894

Epoch: 6| Step: 9
Training loss: 1.0336638434784768
Validation loss: 2.482703640123491

Epoch: 6| Step: 10
Training loss: 1.0828419757040353
Validation loss: 2.4728232266129426

Epoch: 6| Step: 11
Training loss: 1.3089408755723149
Validation loss: 2.430629936131002

Epoch: 6| Step: 12
Training loss: 1.1111981092938128
Validation loss: 2.4323321013662187

Epoch: 6| Step: 13
Training loss: 0.9205327364701752
Validation loss: 2.4212012246528083

Epoch: 246| Step: 0
Training loss: 0.8921207115708456
Validation loss: 2.4290508133372186

Epoch: 6| Step: 1
Training loss: 1.7970927230951694
Validation loss: 2.4310563473851308

Epoch: 6| Step: 2
Training loss: 0.8933088454287398
Validation loss: 2.429441202863551

Epoch: 6| Step: 3
Training loss: 1.1187225146620168
Validation loss: 2.402439240189295

Epoch: 6| Step: 4
Training loss: 1.3419240921769902
Validation loss: 2.4203656370795317

Epoch: 6| Step: 5
Training loss: 1.0116460472113045
Validation loss: 2.458660346615762

Epoch: 6| Step: 6
Training loss: 1.375219630993593
Validation loss: 2.4631822584869623

Epoch: 6| Step: 7
Training loss: 1.03420008998554
Validation loss: 2.493560208263134

Epoch: 6| Step: 8
Training loss: 1.2716171734395687
Validation loss: 2.5045664807614374

Epoch: 6| Step: 9
Training loss: 1.2030569280217613
Validation loss: 2.5130362796112156

Epoch: 6| Step: 10
Training loss: 1.382514706028125
Validation loss: 2.5316342763871487

Epoch: 6| Step: 11
Training loss: 0.8928637558828412
Validation loss: 2.548520098743967

Epoch: 6| Step: 12
Training loss: 1.234662565705126
Validation loss: 2.5354230323136124

Epoch: 6| Step: 13
Training loss: 1.4999456395789463
Validation loss: 2.509026406211735

Epoch: 247| Step: 0
Training loss: 1.2436163020518531
Validation loss: 2.4789723657699927

Epoch: 6| Step: 1
Training loss: 1.1992710860074378
Validation loss: 2.4554937910142023

Epoch: 6| Step: 2
Training loss: 1.184163677114265
Validation loss: 2.4407356984044335

Epoch: 6| Step: 3
Training loss: 1.1261670099603878
Validation loss: 2.433786468889083

Epoch: 6| Step: 4
Training loss: 1.138111375688414
Validation loss: 2.4251583224864666

Epoch: 6| Step: 5
Training loss: 1.4213740545800908
Validation loss: 2.4587756444328965

Epoch: 6| Step: 6
Training loss: 1.2107458639789066
Validation loss: 2.469032515465223

Epoch: 6| Step: 7
Training loss: 0.9926111413237796
Validation loss: 2.4793344883634894

Epoch: 6| Step: 8
Training loss: 0.92668047020486
Validation loss: 2.4820234345353107

Epoch: 6| Step: 9
Training loss: 1.318189686345143
Validation loss: 2.5255468176664664

Epoch: 6| Step: 10
Training loss: 1.1683249042186967
Validation loss: 2.4762939895536036

Epoch: 6| Step: 11
Training loss: 1.2649924970110304
Validation loss: 2.491500724375179

Epoch: 6| Step: 12
Training loss: 1.7863160086862553
Validation loss: 2.4482704421867534

Epoch: 6| Step: 13
Training loss: 1.0561404921968538
Validation loss: 2.4738957164117603

Epoch: 248| Step: 0
Training loss: 1.3968189612291275
Validation loss: 2.4631654549722826

Epoch: 6| Step: 1
Training loss: 1.076758361628057
Validation loss: 2.4479479331954517

Epoch: 6| Step: 2
Training loss: 1.2850909926708165
Validation loss: 2.4379634285163365

Epoch: 6| Step: 3
Training loss: 1.0658765881798222
Validation loss: 2.458082164018437

Epoch: 6| Step: 4
Training loss: 0.9352518783281273
Validation loss: 2.457964406627236

Epoch: 6| Step: 5
Training loss: 1.374041960482268
Validation loss: 2.4480928447077

Epoch: 6| Step: 6
Training loss: 1.3672119138445211
Validation loss: 2.45724788776084

Epoch: 6| Step: 7
Training loss: 1.2915378731946339
Validation loss: 2.4481594037779946

Epoch: 6| Step: 8
Training loss: 1.7191278215766694
Validation loss: 2.452156288945718

Epoch: 6| Step: 9
Training loss: 1.113378901967207
Validation loss: 2.4154401088022825

Epoch: 6| Step: 10
Training loss: 1.144648366931418
Validation loss: 2.407439999964075

Epoch: 6| Step: 11
Training loss: 1.0186897400428188
Validation loss: 2.3842102900055973

Epoch: 6| Step: 12
Training loss: 0.7351630021047688
Validation loss: 2.4227697396786527

Epoch: 6| Step: 13
Training loss: 1.1754070206040919
Validation loss: 2.412250185646051

Epoch: 249| Step: 0
Training loss: 1.004995623337055
Validation loss: 2.448344362728954

Epoch: 6| Step: 1
Training loss: 1.461692981910808
Validation loss: 2.4721876068782827

Epoch: 6| Step: 2
Training loss: 1.33695739720445
Validation loss: 2.525207116449306

Epoch: 6| Step: 3
Training loss: 1.5353711781002715
Validation loss: 2.5066802434304316

Epoch: 6| Step: 4
Training loss: 0.8291820042276296
Validation loss: 2.510012217287129

Epoch: 6| Step: 5
Training loss: 1.0118265573216787
Validation loss: 2.548299354273516

Epoch: 6| Step: 6
Training loss: 1.085219605630756
Validation loss: 2.5495397680437963

Epoch: 6| Step: 7
Training loss: 1.0436034824987275
Validation loss: 2.5302739359880486

Epoch: 6| Step: 8
Training loss: 1.482449537579518
Validation loss: 2.474062176237547

Epoch: 6| Step: 9
Training loss: 1.1022798623780952
Validation loss: 2.4414596768347683

Epoch: 6| Step: 10
Training loss: 1.0011586391185778
Validation loss: 2.422283051167496

Epoch: 6| Step: 11
Training loss: 1.0838504742925033
Validation loss: 2.413913506497914

Epoch: 6| Step: 12
Training loss: 1.4081012831856614
Validation loss: 2.412204893088446

Epoch: 6| Step: 13
Training loss: 1.3004978547098724
Validation loss: 2.397332405614926

Epoch: 250| Step: 0
Training loss: 1.34770038919451
Validation loss: 2.4171796755612336

Epoch: 6| Step: 1
Training loss: 0.9508735768636116
Validation loss: 2.4081304144131552

Epoch: 6| Step: 2
Training loss: 1.1392373828570153
Validation loss: 2.4059228449626184

Epoch: 6| Step: 3
Training loss: 1.3181694741702514
Validation loss: 2.428285649435371

Epoch: 6| Step: 4
Training loss: 1.0265515540249228
Validation loss: 2.445803589847982

Epoch: 6| Step: 5
Training loss: 0.7801545664889269
Validation loss: 2.458001019594605

Epoch: 6| Step: 6
Training loss: 1.6320148326583075
Validation loss: 2.474394848864455

Epoch: 6| Step: 7
Training loss: 1.3898253123886826
Validation loss: 2.501284147467961

Epoch: 6| Step: 8
Training loss: 1.1649979282737288
Validation loss: 2.5140296148648753

Epoch: 6| Step: 9
Training loss: 1.1196308227469425
Validation loss: 2.5084109689411163

Epoch: 6| Step: 10
Training loss: 1.082100876313551
Validation loss: 2.5149865476235904

Epoch: 6| Step: 11
Training loss: 0.9232813243184856
Validation loss: 2.531685044713264

Epoch: 6| Step: 12
Training loss: 1.556798756990201
Validation loss: 2.5172286866100007

Epoch: 6| Step: 13
Training loss: 1.2768912724276362
Validation loss: 2.481909108760009

Epoch: 251| Step: 0
Training loss: 1.393477183100088
Validation loss: 2.5013283328258606

Epoch: 6| Step: 1
Training loss: 0.8482015235915978
Validation loss: 2.479983225200723

Epoch: 6| Step: 2
Training loss: 1.1742827031935936
Validation loss: 2.4908646886627483

Epoch: 6| Step: 3
Training loss: 1.313538776044617
Validation loss: 2.507193951308548

Epoch: 6| Step: 4
Training loss: 1.0573902679217728
Validation loss: 2.488945105378821

Epoch: 6| Step: 5
Training loss: 1.4657792422991776
Validation loss: 2.494567566279488

Epoch: 6| Step: 6
Training loss: 1.1118315242096342
Validation loss: 2.4788821729225914

Epoch: 6| Step: 7
Training loss: 0.7742127665607037
Validation loss: 2.4515055341543817

Epoch: 6| Step: 8
Training loss: 1.4698551970804885
Validation loss: 2.4514036935662524

Epoch: 6| Step: 9
Training loss: 1.525448845644888
Validation loss: 2.4169247786095247

Epoch: 6| Step: 10
Training loss: 1.1204538147143317
Validation loss: 2.4217490807546453

Epoch: 6| Step: 11
Training loss: 1.0663495170956698
Validation loss: 2.398343151358934

Epoch: 6| Step: 12
Training loss: 0.8200072674312934
Validation loss: 2.396888463831125

Epoch: 6| Step: 13
Training loss: 1.0440378603044453
Validation loss: 2.3916096706001118

Epoch: 252| Step: 0
Training loss: 1.3794838881455622
Validation loss: 2.390383946378613

Epoch: 6| Step: 1
Training loss: 0.7504561944181689
Validation loss: 2.380716132134832

Epoch: 6| Step: 2
Training loss: 0.702721925278499
Validation loss: 2.3894972854797727

Epoch: 6| Step: 3
Training loss: 1.3065503920345587
Validation loss: 2.3715750951103365

Epoch: 6| Step: 4
Training loss: 1.4605583474095598
Validation loss: 2.3610050867280785

Epoch: 6| Step: 5
Training loss: 1.1110678637883085
Validation loss: 2.3696176606808113

Epoch: 6| Step: 6
Training loss: 0.971406371049289
Validation loss: 2.3925897882180203

Epoch: 6| Step: 7
Training loss: 0.9673320483530643
Validation loss: 2.396695176133755

Epoch: 6| Step: 8
Training loss: 0.8582348282470595
Validation loss: 2.4125181544816985

Epoch: 6| Step: 9
Training loss: 1.7083734259514072
Validation loss: 2.46838060146307

Epoch: 6| Step: 10
Training loss: 1.437994498739742
Validation loss: 2.496706234598839

Epoch: 6| Step: 11
Training loss: 0.9281990895096486
Validation loss: 2.5293347095708882

Epoch: 6| Step: 12
Training loss: 1.161684718399958
Validation loss: 2.5476243913221173

Epoch: 6| Step: 13
Training loss: 1.3510211896949962
Validation loss: 2.5507710970520585

Epoch: 253| Step: 0
Training loss: 1.208288581063261
Validation loss: 2.528041772813418

Epoch: 6| Step: 1
Training loss: 0.979309125777232
Validation loss: 2.499868642268332

Epoch: 6| Step: 2
Training loss: 1.4739697818738338
Validation loss: 2.4758217129603226

Epoch: 6| Step: 3
Training loss: 0.7496710294223687
Validation loss: 2.46440341570033

Epoch: 6| Step: 4
Training loss: 1.0869447167418924
Validation loss: 2.4057062016935773

Epoch: 6| Step: 5
Training loss: 0.9490760099361977
Validation loss: 2.404634815507723

Epoch: 6| Step: 6
Training loss: 1.2397240737816497
Validation loss: 2.433412821056225

Epoch: 6| Step: 7
Training loss: 1.6342659645835544
Validation loss: 2.4369788452813355

Epoch: 6| Step: 8
Training loss: 1.0915284074100153
Validation loss: 2.4202477785746783

Epoch: 6| Step: 9
Training loss: 1.3464984287716
Validation loss: 2.4636289006206957

Epoch: 6| Step: 10
Training loss: 1.1638728249674677
Validation loss: 2.4776918307720983

Epoch: 6| Step: 11
Training loss: 0.7371960288310813
Validation loss: 2.4696303968516906

Epoch: 6| Step: 12
Training loss: 1.2263192099542266
Validation loss: 2.453181563776125

Epoch: 6| Step: 13
Training loss: 0.8520440656074887
Validation loss: 2.4594247591059557

Epoch: 254| Step: 0
Training loss: 0.9755306438245344
Validation loss: 2.4365154430874676

Epoch: 6| Step: 1
Training loss: 1.104592882822824
Validation loss: 2.444493807467952

Epoch: 6| Step: 2
Training loss: 0.7343383942266757
Validation loss: 2.4096391566274007

Epoch: 6| Step: 3
Training loss: 1.1767889628106047
Validation loss: 2.4051766112970925

Epoch: 6| Step: 4
Training loss: 0.8073705368072185
Validation loss: 2.4106248830874555

Epoch: 6| Step: 5
Training loss: 1.474006661026085
Validation loss: 2.3974937582913682

Epoch: 6| Step: 6
Training loss: 1.398756150751167
Validation loss: 2.4281748120520668

Epoch: 6| Step: 7
Training loss: 1.561114803474256
Validation loss: 2.389813122228587

Epoch: 6| Step: 8
Training loss: 1.505738724799505
Validation loss: 2.4326660145026606

Epoch: 6| Step: 9
Training loss: 0.7971654250536525
Validation loss: 2.42203727017121

Epoch: 6| Step: 10
Training loss: 0.8806700238643459
Validation loss: 2.4742422868153553

Epoch: 6| Step: 11
Training loss: 1.1214744107698291
Validation loss: 2.494644505628833

Epoch: 6| Step: 12
Training loss: 0.8130373278420484
Validation loss: 2.5114626544585117

Epoch: 6| Step: 13
Training loss: 0.9694903836179152
Validation loss: 2.508937931371248

Epoch: 255| Step: 0
Training loss: 1.0086015081956772
Validation loss: 2.501400156580628

Epoch: 6| Step: 1
Training loss: 0.9126114045684743
Validation loss: 2.5357845257300524

Epoch: 6| Step: 2
Training loss: 1.0449501675492152
Validation loss: 2.512222158192993

Epoch: 6| Step: 3
Training loss: 1.0868168296405243
Validation loss: 2.4958794188361417

Epoch: 6| Step: 4
Training loss: 0.8773039050408511
Validation loss: 2.4867613162854942

Epoch: 6| Step: 5
Training loss: 1.2748357667052344
Validation loss: 2.5035075961264224

Epoch: 6| Step: 6
Training loss: 0.9464937506387292
Validation loss: 2.4486204442567625

Epoch: 6| Step: 7
Training loss: 1.283657696013968
Validation loss: 2.4626286662461725

Epoch: 6| Step: 8
Training loss: 1.1173036955048934
Validation loss: 2.4547311877708933

Epoch: 6| Step: 9
Training loss: 1.0187289417173269
Validation loss: 2.4684169166079113

Epoch: 6| Step: 10
Training loss: 1.5323975603176323
Validation loss: 2.4554445477193148

Epoch: 6| Step: 11
Training loss: 0.982890265804086
Validation loss: 2.4395841234616986

Epoch: 6| Step: 12
Training loss: 0.9442188146914053
Validation loss: 2.428246366052042

Epoch: 6| Step: 13
Training loss: 1.4367290585652641
Validation loss: 2.404224605021765

Epoch: 256| Step: 0
Training loss: 1.0322125884150488
Validation loss: 2.427252981703688

Epoch: 6| Step: 1
Training loss: 1.5606334982118533
Validation loss: 2.39574109756386

Epoch: 6| Step: 2
Training loss: 1.0521471866581111
Validation loss: 2.440436308713095

Epoch: 6| Step: 3
Training loss: 1.043210462357123
Validation loss: 2.4182274827251184

Epoch: 6| Step: 4
Training loss: 1.1142671201887215
Validation loss: 2.434972363850183

Epoch: 6| Step: 5
Training loss: 0.9198736028296498
Validation loss: 2.445150260492939

Epoch: 6| Step: 6
Training loss: 1.4438649119435136
Validation loss: 2.44706181087161

Epoch: 6| Step: 7
Training loss: 0.8446378628241225
Validation loss: 2.431257622887146

Epoch: 6| Step: 8
Training loss: 1.1783614632154826
Validation loss: 2.4459251525630386

Epoch: 6| Step: 9
Training loss: 1.0397363643096076
Validation loss: 2.411236403933815

Epoch: 6| Step: 10
Training loss: 1.0103425788590614
Validation loss: 2.4083618029815583

Epoch: 6| Step: 11
Training loss: 0.7962745199215877
Validation loss: 2.4155368186404194

Epoch: 6| Step: 12
Training loss: 1.1848767065942818
Validation loss: 2.4245185114406946

Epoch: 6| Step: 13
Training loss: 0.9531894099250354
Validation loss: 2.411711972600942

Epoch: 257| Step: 0
Training loss: 1.0930174963267085
Validation loss: 2.4091757907132023

Epoch: 6| Step: 1
Training loss: 0.5280203540664618
Validation loss: 2.423615108957247

Epoch: 6| Step: 2
Training loss: 0.7228460526584921
Validation loss: 2.4445947152346257

Epoch: 6| Step: 3
Training loss: 1.0115168896640143
Validation loss: 2.47246491948203

Epoch: 6| Step: 4
Training loss: 1.3238203411486915
Validation loss: 2.4715247199389054

Epoch: 6| Step: 5
Training loss: 0.8847439323275438
Validation loss: 2.4840616565312943

Epoch: 6| Step: 6
Training loss: 1.118362129359929
Validation loss: 2.503900037231181

Epoch: 6| Step: 7
Training loss: 0.8676444559448084
Validation loss: 2.5251493873375703

Epoch: 6| Step: 8
Training loss: 1.0052344890347458
Validation loss: 2.5341308012408232

Epoch: 6| Step: 9
Training loss: 1.0126796563022544
Validation loss: 2.5268244022954236

Epoch: 6| Step: 10
Training loss: 0.9740845025630707
Validation loss: 2.5202060984576105

Epoch: 6| Step: 11
Training loss: 1.4857392316206877
Validation loss: 2.5199763303092064

Epoch: 6| Step: 12
Training loss: 1.2554566967331575
Validation loss: 2.512216841552583

Epoch: 6| Step: 13
Training loss: 2.043592893762305
Validation loss: 2.5242617753123318

Epoch: 258| Step: 0
Training loss: 0.8410378062950465
Validation loss: 2.4985030989311303

Epoch: 6| Step: 1
Training loss: 0.6632074348704213
Validation loss: 2.439440661200102

Epoch: 6| Step: 2
Training loss: 1.1575692872469996
Validation loss: 2.4465582463556634

Epoch: 6| Step: 3
Training loss: 1.0456536983512326
Validation loss: 2.4089973213386155

Epoch: 6| Step: 4
Training loss: 0.6287873197139067
Validation loss: 2.404518908964636

Epoch: 6| Step: 5
Training loss: 1.8085110935907662
Validation loss: 2.3818716197132037

Epoch: 6| Step: 6
Training loss: 1.0713510417135406
Validation loss: 2.4147985201652427

Epoch: 6| Step: 7
Training loss: 1.291681299844525
Validation loss: 2.40430470304207

Epoch: 6| Step: 8
Training loss: 0.7707101534461578
Validation loss: 2.3973710337011167

Epoch: 6| Step: 9
Training loss: 0.6862069237327223
Validation loss: 2.3897768629111265

Epoch: 6| Step: 10
Training loss: 1.1444437039063249
Validation loss: 2.3944978998560367

Epoch: 6| Step: 11
Training loss: 1.2430917579498553
Validation loss: 2.401267644702679

Epoch: 6| Step: 12
Training loss: 1.290604934351669
Validation loss: 2.40144238847176

Epoch: 6| Step: 13
Training loss: 0.9412846783535388
Validation loss: 2.4069220365284605

Epoch: 259| Step: 0
Training loss: 0.8387003722766192
Validation loss: 2.3923121067586193

Epoch: 6| Step: 1
Training loss: 1.0607577231991574
Validation loss: 2.406449700517276

Epoch: 6| Step: 2
Training loss: 0.9393586489941552
Validation loss: 2.395728279011237

Epoch: 6| Step: 3
Training loss: 1.1593387690638435
Validation loss: 2.4011343636313245

Epoch: 6| Step: 4
Training loss: 1.5827845910823046
Validation loss: 2.4092363498135665

Epoch: 6| Step: 5
Training loss: 1.2214495764625637
Validation loss: 2.423448009577534

Epoch: 6| Step: 6
Training loss: 1.0634039231390668
Validation loss: 2.417446605383154

Epoch: 6| Step: 7
Training loss: 0.8374652983465051
Validation loss: 2.4482741322459214

Epoch: 6| Step: 8
Training loss: 1.3983614597212308
Validation loss: 2.473223367442821

Epoch: 6| Step: 9
Training loss: 1.2181506517194103
Validation loss: 2.4906174141751642

Epoch: 6| Step: 10
Training loss: 0.5081873170709005
Validation loss: 2.5342569219019757

Epoch: 6| Step: 11
Training loss: 1.0725225199933772
Validation loss: 2.5120962354915277

Epoch: 6| Step: 12
Training loss: 0.7493072330227062
Validation loss: 2.5163272709762756

Epoch: 6| Step: 13
Training loss: 1.1546123351124917
Validation loss: 2.5378025984827937

Epoch: 260| Step: 0
Training loss: 1.5696210714930374
Validation loss: 2.5250313168742866

Epoch: 6| Step: 1
Training loss: 1.570003194380505
Validation loss: 2.49370120264957

Epoch: 6| Step: 2
Training loss: 0.8710657294860081
Validation loss: 2.4783385051640754

Epoch: 6| Step: 3
Training loss: 1.1337084154201458
Validation loss: 2.460132832060214

Epoch: 6| Step: 4
Training loss: 0.8456303518933698
Validation loss: 2.4521802613135075

Epoch: 6| Step: 5
Training loss: 0.9274169700145154
Validation loss: 2.419290366595569

Epoch: 6| Step: 6
Training loss: 0.7850946810291335
Validation loss: 2.4006741733903816

Epoch: 6| Step: 7
Training loss: 0.8909427678257884
Validation loss: 2.3804313162271

Epoch: 6| Step: 8
Training loss: 1.0324833170764547
Validation loss: 2.370375246287448

Epoch: 6| Step: 9
Training loss: 0.8885409415906577
Validation loss: 2.3845123150838883

Epoch: 6| Step: 10
Training loss: 0.9811987723809769
Validation loss: 2.3733778099886416

Epoch: 6| Step: 11
Training loss: 1.1999815462600856
Validation loss: 2.369117816443657

Epoch: 6| Step: 12
Training loss: 0.7302602378548076
Validation loss: 2.3685959817883298

Epoch: 6| Step: 13
Training loss: 0.9789625354121112
Validation loss: 2.402058437054641

Epoch: 261| Step: 0
Training loss: 0.8676133356072832
Validation loss: 2.3985205184326794

Epoch: 6| Step: 1
Training loss: 1.1994189365563115
Validation loss: 2.422065700362677

Epoch: 6| Step: 2
Training loss: 1.0417898995302188
Validation loss: 2.4017697332565233

Epoch: 6| Step: 3
Training loss: 1.0274615782262324
Validation loss: 2.4315637047792475

Epoch: 6| Step: 4
Training loss: 1.5284268570589665
Validation loss: 2.4206442202068517

Epoch: 6| Step: 5
Training loss: 1.1398869569680288
Validation loss: 2.4760123647533856

Epoch: 6| Step: 6
Training loss: 0.888425621036491
Validation loss: 2.507987307811696

Epoch: 6| Step: 7
Training loss: 0.9798667853179326
Validation loss: 2.5089171845946834

Epoch: 6| Step: 8
Training loss: 1.061140368564777
Validation loss: 2.5103206630631605

Epoch: 6| Step: 9
Training loss: 0.6222590664639488
Validation loss: 2.512680693954849

Epoch: 6| Step: 10
Training loss: 0.9653276473289745
Validation loss: 2.535256895285305

Epoch: 6| Step: 11
Training loss: 0.9656201532236082
Validation loss: 2.4924805068680604

Epoch: 6| Step: 12
Training loss: 1.1829271107304742
Validation loss: 2.503795148868682

Epoch: 6| Step: 13
Training loss: 1.1408262205958715
Validation loss: 2.477872275008487

Epoch: 262| Step: 0
Training loss: 1.0501301389608657
Validation loss: 2.4540418890835785

Epoch: 6| Step: 1
Training loss: 1.2204885553607128
Validation loss: 2.4387018781352148

Epoch: 6| Step: 2
Training loss: 0.7170912634414569
Validation loss: 2.434114942787814

Epoch: 6| Step: 3
Training loss: 1.04433634386827
Validation loss: 2.443462421688359

Epoch: 6| Step: 4
Training loss: 1.1910586491036255
Validation loss: 2.4537272725394685

Epoch: 6| Step: 5
Training loss: 0.9661829685090357
Validation loss: 2.4346911620004823

Epoch: 6| Step: 6
Training loss: 1.0421145366423905
Validation loss: 2.4232093662664886

Epoch: 6| Step: 7
Training loss: 0.8721807224142923
Validation loss: 2.4050809569137805

Epoch: 6| Step: 8
Training loss: 1.0412777110942615
Validation loss: 2.422608009581342

Epoch: 6| Step: 9
Training loss: 0.7022230297041562
Validation loss: 2.3924663084453335

Epoch: 6| Step: 10
Training loss: 1.3960999713368436
Validation loss: 2.41271229861394

Epoch: 6| Step: 11
Training loss: 0.7992729683213687
Validation loss: 2.426756400613454

Epoch: 6| Step: 12
Training loss: 1.0972756374142691
Validation loss: 2.406658100178489

Epoch: 6| Step: 13
Training loss: 1.1298541672882763
Validation loss: 2.4148903776634456

Epoch: 263| Step: 0
Training loss: 1.1519311198464106
Validation loss: 2.4367909805661423

Epoch: 6| Step: 1
Training loss: 0.9038842662620652
Validation loss: 2.4172916438732037

Epoch: 6| Step: 2
Training loss: 0.9611605253606053
Validation loss: 2.4167929932105463

Epoch: 6| Step: 3
Training loss: 0.7619215866378396
Validation loss: 2.3992374442691617

Epoch: 6| Step: 4
Training loss: 1.002895573794523
Validation loss: 2.394000781505378

Epoch: 6| Step: 5
Training loss: 0.9987075917928752
Validation loss: 2.4000648316091966

Epoch: 6| Step: 6
Training loss: 1.0524935473427763
Validation loss: 2.4049764628897288

Epoch: 6| Step: 7
Training loss: 0.8783810211774362
Validation loss: 2.415682434355242

Epoch: 6| Step: 8
Training loss: 0.9452112632326576
Validation loss: 2.4137083970603066

Epoch: 6| Step: 9
Training loss: 0.9320009122708977
Validation loss: 2.423772435260277

Epoch: 6| Step: 10
Training loss: 1.5318594517691122
Validation loss: 2.4129201223243437

Epoch: 6| Step: 11
Training loss: 0.8505942413240085
Validation loss: 2.404654457709464

Epoch: 6| Step: 12
Training loss: 1.2195151445888115
Validation loss: 2.44153363452957

Epoch: 6| Step: 13
Training loss: 0.757719014487309
Validation loss: 2.4232572434381696

Epoch: 264| Step: 0
Training loss: 1.3027190932445607
Validation loss: 2.44632595081029

Epoch: 6| Step: 1
Training loss: 1.0132906569939089
Validation loss: 2.433665889432603

Epoch: 6| Step: 2
Training loss: 1.0075524756157292
Validation loss: 2.4102120363019686

Epoch: 6| Step: 3
Training loss: 1.1306416725291641
Validation loss: 2.43517190130329

Epoch: 6| Step: 4
Training loss: 0.8652643753947344
Validation loss: 2.455224240385454

Epoch: 6| Step: 5
Training loss: 1.3360008537038486
Validation loss: 2.4292276659065757

Epoch: 6| Step: 6
Training loss: 0.47391493741860236
Validation loss: 2.4109212565693467

Epoch: 6| Step: 7
Training loss: 0.9293499502103901
Validation loss: 2.4268659823291543

Epoch: 6| Step: 8
Training loss: 0.8547927415062988
Validation loss: 2.4377152584790176

Epoch: 6| Step: 9
Training loss: 1.3746669105744784
Validation loss: 2.429295601926149

Epoch: 6| Step: 10
Training loss: 0.9933085378703324
Validation loss: 2.4147679617984292

Epoch: 6| Step: 11
Training loss: 0.8212619917645808
Validation loss: 2.414795383024427

Epoch: 6| Step: 12
Training loss: 0.9176598861209195
Validation loss: 2.4453089386173215

Epoch: 6| Step: 13
Training loss: 0.7682395977454347
Validation loss: 2.4430175924122355

Epoch: 265| Step: 0
Training loss: 0.8295553558347779
Validation loss: 2.4334977651383483

Epoch: 6| Step: 1
Training loss: 1.214350560404234
Validation loss: 2.4532771536560594

Epoch: 6| Step: 2
Training loss: 0.8730969169321963
Validation loss: 2.409048538325792

Epoch: 6| Step: 3
Training loss: 1.5050770351426757
Validation loss: 2.4225109333226045

Epoch: 6| Step: 4
Training loss: 0.5472943469290369
Validation loss: 2.43977133913395

Epoch: 6| Step: 5
Training loss: 0.9068396393016195
Validation loss: 2.431132367821292

Epoch: 6| Step: 6
Training loss: 0.8891315989802498
Validation loss: 2.4524520432743255

Epoch: 6| Step: 7
Training loss: 0.8259687241574498
Validation loss: 2.439217689244225

Epoch: 6| Step: 8
Training loss: 0.9323928643113544
Validation loss: 2.451145549966673

Epoch: 6| Step: 9
Training loss: 1.0535345486704788
Validation loss: 2.457829367606202

Epoch: 6| Step: 10
Training loss: 1.084190995053119
Validation loss: 2.4203517652845923

Epoch: 6| Step: 11
Training loss: 0.9349548122889891
Validation loss: 2.4367036446741634

Epoch: 6| Step: 12
Training loss: 0.9655352442732514
Validation loss: 2.449922350970816

Epoch: 6| Step: 13
Training loss: 1.04828236053176
Validation loss: 2.376377716456603

Epoch: 266| Step: 0
Training loss: 1.0507990045004763
Validation loss: 2.3972901121059214

Epoch: 6| Step: 1
Training loss: 1.1655102629862255
Validation loss: 2.3919818150307885

Epoch: 6| Step: 2
Training loss: 1.190357935231845
Validation loss: 2.3553348952795

Epoch: 6| Step: 3
Training loss: 0.7768847389869014
Validation loss: 2.349150404760243

Epoch: 6| Step: 4
Training loss: 0.9103985247051977
Validation loss: 2.370393740981792

Epoch: 6| Step: 5
Training loss: 1.008916028905713
Validation loss: 2.388091444871557

Epoch: 6| Step: 6
Training loss: 0.9206806787045618
Validation loss: 2.4234575301945673

Epoch: 6| Step: 7
Training loss: 1.1157788552585872
Validation loss: 2.405606392982372

Epoch: 6| Step: 8
Training loss: 0.795322364191364
Validation loss: 2.4055734681366086

Epoch: 6| Step: 9
Training loss: 0.7421839663772788
Validation loss: 2.43949754647378

Epoch: 6| Step: 10
Training loss: 1.1105988964304085
Validation loss: 2.432564092344269

Epoch: 6| Step: 11
Training loss: 0.8491283940708316
Validation loss: 2.4503930166093326

Epoch: 6| Step: 12
Training loss: 1.0029076979621374
Validation loss: 2.427364649060982

Epoch: 6| Step: 13
Training loss: 1.1500307307076452
Validation loss: 2.423256684850172

Epoch: 267| Step: 0
Training loss: 0.587038506185581
Validation loss: 2.4072697362755786

Epoch: 6| Step: 1
Training loss: 0.7157579839822737
Validation loss: 2.422569269071087

Epoch: 6| Step: 2
Training loss: 1.3204872873395603
Validation loss: 2.405459685586423

Epoch: 6| Step: 3
Training loss: 0.7801601819474686
Validation loss: 2.388737194211354

Epoch: 6| Step: 4
Training loss: 0.8326270607334505
Validation loss: 2.4263369399155965

Epoch: 6| Step: 5
Training loss: 1.1070141453791176
Validation loss: 2.4158362224853773

Epoch: 6| Step: 6
Training loss: 0.7545439241995444
Validation loss: 2.4082133552558793

Epoch: 6| Step: 7
Training loss: 1.1613084613714837
Validation loss: 2.4281749609183327

Epoch: 6| Step: 8
Training loss: 0.976369060431384
Validation loss: 2.4180212771753213

Epoch: 6| Step: 9
Training loss: 0.948460688299683
Validation loss: 2.4189609129636698

Epoch: 6| Step: 10
Training loss: 1.035001116950128
Validation loss: 2.451034521524612

Epoch: 6| Step: 11
Training loss: 1.4623513953197278
Validation loss: 2.4272411755817336

Epoch: 6| Step: 12
Training loss: 0.9127764988388055
Validation loss: 2.442345453165955

Epoch: 6| Step: 13
Training loss: 0.2659634509575602
Validation loss: 2.445244805845354

Epoch: 268| Step: 0
Training loss: 0.6318201832524416
Validation loss: 2.4151800043265754

Epoch: 6| Step: 1
Training loss: 0.7457853548683034
Validation loss: 2.4418230721967933

Epoch: 6| Step: 2
Training loss: 1.067466851195476
Validation loss: 2.4142631035637585

Epoch: 6| Step: 3
Training loss: 0.9120439264966383
Validation loss: 2.42161007853632

Epoch: 6| Step: 4
Training loss: 1.3790050611672806
Validation loss: 2.391834699071708

Epoch: 6| Step: 5
Training loss: 1.0389881537664383
Validation loss: 2.3953711939191984

Epoch: 6| Step: 6
Training loss: 0.8548957612815526
Validation loss: 2.4156504703842954

Epoch: 6| Step: 7
Training loss: 1.244964470567029
Validation loss: 2.437509623493542

Epoch: 6| Step: 8
Training loss: 1.063163774378681
Validation loss: 2.424148170235003

Epoch: 6| Step: 9
Training loss: 0.42043838672025563
Validation loss: 2.4690123200996394

Epoch: 6| Step: 10
Training loss: 0.841786324773468
Validation loss: 2.440023936101813

Epoch: 6| Step: 11
Training loss: 1.0288248735252352
Validation loss: 2.420872776584962

Epoch: 6| Step: 12
Training loss: 1.0528230930518985
Validation loss: 2.4036191385256642

Epoch: 6| Step: 13
Training loss: 0.639407699360339
Validation loss: 2.397171687487376

Epoch: 269| Step: 0
Training loss: 0.9052525654745635
Validation loss: 2.3825828039422663

Epoch: 6| Step: 1
Training loss: 1.010974743022927
Validation loss: 2.3902203435022957

Epoch: 6| Step: 2
Training loss: 0.49578204838075024
Validation loss: 2.4154946719413983

Epoch: 6| Step: 3
Training loss: 0.758521701836729
Validation loss: 2.408897460619393

Epoch: 6| Step: 4
Training loss: 0.9209286956832252
Validation loss: 2.401251836405789

Epoch: 6| Step: 5
Training loss: 0.8199856061369922
Validation loss: 2.414133273364699

Epoch: 6| Step: 6
Training loss: 0.9428763722805863
Validation loss: 2.40816035705647

Epoch: 6| Step: 7
Training loss: 1.1760795949806537
Validation loss: 2.395285514773347

Epoch: 6| Step: 8
Training loss: 0.8796621505310112
Validation loss: 2.4137448619155406

Epoch: 6| Step: 9
Training loss: 0.94989291139651
Validation loss: 2.390433913268185

Epoch: 6| Step: 10
Training loss: 1.1446223304103353
Validation loss: 2.3716009251418275

Epoch: 6| Step: 11
Training loss: 0.8577312702011924
Validation loss: 2.3930388522722232

Epoch: 6| Step: 12
Training loss: 1.0067673816151397
Validation loss: 2.4132598796865206

Epoch: 6| Step: 13
Training loss: 1.285867836086119
Validation loss: 2.4123737988880096

Epoch: 270| Step: 0
Training loss: 0.5548929720428218
Validation loss: 2.396338249029383

Epoch: 6| Step: 1
Training loss: 0.8589864372586019
Validation loss: 2.4253685985184785

Epoch: 6| Step: 2
Training loss: 0.5425366390618265
Validation loss: 2.385754235518591

Epoch: 6| Step: 3
Training loss: 0.9215610422127397
Validation loss: 2.4157437551989056

Epoch: 6| Step: 4
Training loss: 1.408939502362159
Validation loss: 2.4345494447994684

Epoch: 6| Step: 5
Training loss: 1.217889873502694
Validation loss: 2.411303405172002

Epoch: 6| Step: 6
Training loss: 0.7969792615712368
Validation loss: 2.456348792566647

Epoch: 6| Step: 7
Training loss: 0.8744019780826793
Validation loss: 2.4326675899928785

Epoch: 6| Step: 8
Training loss: 0.9110722659683373
Validation loss: 2.4673503346793044

Epoch: 6| Step: 9
Training loss: 0.9498937898793695
Validation loss: 2.4405020187884587

Epoch: 6| Step: 10
Training loss: 0.8763235504256804
Validation loss: 2.4285141633168217

Epoch: 6| Step: 11
Training loss: 0.8959480293541352
Validation loss: 2.4261011897471967

Epoch: 6| Step: 12
Training loss: 1.01764934971463
Validation loss: 2.3550079781510993

Epoch: 6| Step: 13
Training loss: 0.9673055832471313
Validation loss: 2.3512179563438074

Epoch: 271| Step: 0
Training loss: 0.7518736165605535
Validation loss: 2.365258658221387

Epoch: 6| Step: 1
Training loss: 0.5332626197795314
Validation loss: 2.371319878844543

Epoch: 6| Step: 2
Training loss: 0.8986445976069892
Validation loss: 2.3748639623155476

Epoch: 6| Step: 3
Training loss: 1.117914350187101
Validation loss: 2.3676362269084597

Epoch: 6| Step: 4
Training loss: 0.7005179073078824
Validation loss: 2.3586928216643455

Epoch: 6| Step: 5
Training loss: 1.4702106274329279
Validation loss: 2.373692783687242

Epoch: 6| Step: 6
Training loss: 0.8000473008477373
Validation loss: 2.4048788987727727

Epoch: 6| Step: 7
Training loss: 0.8402850034278719
Validation loss: 2.437940239623716

Epoch: 6| Step: 8
Training loss: 0.9415057117898684
Validation loss: 2.4541600911398658

Epoch: 6| Step: 9
Training loss: 1.0012640712287428
Validation loss: 2.4225155949429005

Epoch: 6| Step: 10
Training loss: 0.766889112446832
Validation loss: 2.4387876960246753

Epoch: 6| Step: 11
Training loss: 1.211240964212167
Validation loss: 2.4358210527874156

Epoch: 6| Step: 12
Training loss: 0.9821474211450527
Validation loss: 2.4033340132565306

Epoch: 6| Step: 13
Training loss: 0.6850337093997024
Validation loss: 2.409754229641713

Epoch: 272| Step: 0
Training loss: 0.6427072783656764
Validation loss: 2.4317235325072506

Epoch: 6| Step: 1
Training loss: 0.939574108938427
Validation loss: 2.437241613398837

Epoch: 6| Step: 2
Training loss: 0.5987150002047588
Validation loss: 2.4404129862689348

Epoch: 6| Step: 3
Training loss: 1.0019787047097222
Validation loss: 2.4316973848979355

Epoch: 6| Step: 4
Training loss: 1.230500090669197
Validation loss: 2.4282911456166163

Epoch: 6| Step: 5
Training loss: 0.8836181138083705
Validation loss: 2.437636583791116

Epoch: 6| Step: 6
Training loss: 1.1983588301042312
Validation loss: 2.4402915823168216

Epoch: 6| Step: 7
Training loss: 0.8709270505959249
Validation loss: 2.4300690500291666

Epoch: 6| Step: 8
Training loss: 0.8021136108892959
Validation loss: 2.4230602612461523

Epoch: 6| Step: 9
Training loss: 1.0470742562676383
Validation loss: 2.4116137231769215

Epoch: 6| Step: 10
Training loss: 0.9058395640191991
Validation loss: 2.4016859358315212

Epoch: 6| Step: 11
Training loss: 0.7302846421562869
Validation loss: 2.4154920393071246

Epoch: 6| Step: 12
Training loss: 1.0086344834072272
Validation loss: 2.4137087873882597

Epoch: 6| Step: 13
Training loss: 0.7666115146646989
Validation loss: 2.4312346220512104

Epoch: 273| Step: 0
Training loss: 1.3115290729006814
Validation loss: 2.4328646341484386

Epoch: 6| Step: 1
Training loss: 0.9778616541561679
Validation loss: 2.4385608881249126

Epoch: 6| Step: 2
Training loss: 0.9979347121187284
Validation loss: 2.478449651519093

Epoch: 6| Step: 3
Training loss: 0.9620176617751791
Validation loss: 2.4592922051603394

Epoch: 6| Step: 4
Training loss: 0.7547375143154981
Validation loss: 2.432217182707915

Epoch: 6| Step: 5
Training loss: 0.8556664295072367
Validation loss: 2.4476896765061027

Epoch: 6| Step: 6
Training loss: 0.4268734773019467
Validation loss: 2.425215157987058

Epoch: 6| Step: 7
Training loss: 0.8121853732778043
Validation loss: 2.3895498428131363

Epoch: 6| Step: 8
Training loss: 0.7717491371612125
Validation loss: 2.3850263785085044

Epoch: 6| Step: 9
Training loss: 1.0398543932661661
Validation loss: 2.373099118509282

Epoch: 6| Step: 10
Training loss: 0.8616587724330199
Validation loss: 2.370602173093945

Epoch: 6| Step: 11
Training loss: 1.0172048165858723
Validation loss: 2.387871785984839

Epoch: 6| Step: 12
Training loss: 0.8873308732511933
Validation loss: 2.3604975507793933

Epoch: 6| Step: 13
Training loss: 0.9225363864287268
Validation loss: 2.3564972191044964

Epoch: 274| Step: 0
Training loss: 0.8379728192471201
Validation loss: 2.389867521168586

Epoch: 6| Step: 1
Training loss: 0.8241804213448052
Validation loss: 2.3947987880666113

Epoch: 6| Step: 2
Training loss: 0.7251329612485597
Validation loss: 2.385860044209293

Epoch: 6| Step: 3
Training loss: 0.6578809362770999
Validation loss: 2.3949174279672554

Epoch: 6| Step: 4
Training loss: 1.1729645305418928
Validation loss: 2.4035318745558647

Epoch: 6| Step: 5
Training loss: 0.8563017947827559
Validation loss: 2.3951569282279603

Epoch: 6| Step: 6
Training loss: 0.8020397438656337
Validation loss: 2.4139275230858255

Epoch: 6| Step: 7
Training loss: 0.840438844851197
Validation loss: 2.4267870758161445

Epoch: 6| Step: 8
Training loss: 1.0568371376731542
Validation loss: 2.423743294204491

Epoch: 6| Step: 9
Training loss: 0.9572653970583463
Validation loss: 2.408980918859756

Epoch: 6| Step: 10
Training loss: 0.8367331809002435
Validation loss: 2.4241998708399626

Epoch: 6| Step: 11
Training loss: 1.306919769439747
Validation loss: 2.4237958665262083

Epoch: 6| Step: 12
Training loss: 0.8390947772589435
Validation loss: 2.4404031783065014

Epoch: 6| Step: 13
Training loss: 0.6277267579030169
Validation loss: 2.4267426213393763

Epoch: 275| Step: 0
Training loss: 1.1737886698307471
Validation loss: 2.4431560587149956

Epoch: 6| Step: 1
Training loss: 1.1005962814752093
Validation loss: 2.445083430781141

Epoch: 6| Step: 2
Training loss: 0.821966991425435
Validation loss: 2.4448339984905565

Epoch: 6| Step: 3
Training loss: 1.0425256366459124
Validation loss: 2.439655793633788

Epoch: 6| Step: 4
Training loss: 0.7469534988330567
Validation loss: 2.417725417761197

Epoch: 6| Step: 5
Training loss: 0.8238431969860617
Validation loss: 2.428242529424277

Epoch: 6| Step: 6
Training loss: 0.6196436237724653
Validation loss: 2.416986485310152

Epoch: 6| Step: 7
Training loss: 0.6782967380740504
Validation loss: 2.3741004192227937

Epoch: 6| Step: 8
Training loss: 0.9619932810118502
Validation loss: 2.391252100200385

Epoch: 6| Step: 9
Training loss: 0.787988592893071
Validation loss: 2.3866461878138163

Epoch: 6| Step: 10
Training loss: 0.9507222767754355
Validation loss: 2.3693361789609115

Epoch: 6| Step: 11
Training loss: 0.5686846192476983
Validation loss: 2.4054688047371826

Epoch: 6| Step: 12
Training loss: 1.1002125686383883
Validation loss: 2.3998364700898946

Epoch: 6| Step: 13
Training loss: 0.7544864536811112
Validation loss: 2.384359455849579

Epoch: 276| Step: 0
Training loss: 0.9316626972007013
Validation loss: 2.3769934858065955

Epoch: 6| Step: 1
Training loss: 0.9012055587922203
Validation loss: 2.420342013724759

Epoch: 6| Step: 2
Training loss: 0.7730757898259607
Validation loss: 2.409422787926224

Epoch: 6| Step: 3
Training loss: 0.5966505927002135
Validation loss: 2.4240083283641027

Epoch: 6| Step: 4
Training loss: 0.5266005188208841
Validation loss: 2.469040574875543

Epoch: 6| Step: 5
Training loss: 0.8444739167887156
Validation loss: 2.433729675549564

Epoch: 6| Step: 6
Training loss: 0.8875796806134456
Validation loss: 2.4683030548031106

Epoch: 6| Step: 7
Training loss: 0.8350979876558298
Validation loss: 2.4916404107944135

Epoch: 6| Step: 8
Training loss: 0.8064026562382077
Validation loss: 2.4421612554850065

Epoch: 6| Step: 9
Training loss: 0.9216748683097746
Validation loss: 2.4399530842007833

Epoch: 6| Step: 10
Training loss: 0.9561954819340934
Validation loss: 2.421187274526593

Epoch: 6| Step: 11
Training loss: 0.8581136984195528
Validation loss: 2.40374177128382

Epoch: 6| Step: 12
Training loss: 1.3546153083405998
Validation loss: 2.4017941359516075

Epoch: 6| Step: 13
Training loss: 1.1983482357437287
Validation loss: 2.343496410364665

Epoch: 277| Step: 0
Training loss: 0.8956296748420648
Validation loss: 2.3532178805245185

Epoch: 6| Step: 1
Training loss: 0.7435895025360837
Validation loss: 2.330858549393973

Epoch: 6| Step: 2
Training loss: 0.626503447415852
Validation loss: 2.3646970400553586

Epoch: 6| Step: 3
Training loss: 0.7283498048629284
Validation loss: 2.3747810096576054

Epoch: 6| Step: 4
Training loss: 0.9339572406370698
Validation loss: 2.4304668578699706

Epoch: 6| Step: 5
Training loss: 0.847575170620996
Validation loss: 2.4168180843296367

Epoch: 6| Step: 6
Training loss: 1.126524316402521
Validation loss: 2.4344174256226103

Epoch: 6| Step: 7
Training loss: 1.1598221011879855
Validation loss: 2.406603762262724

Epoch: 6| Step: 8
Training loss: 0.9491190602892772
Validation loss: 2.4136745099806816

Epoch: 6| Step: 9
Training loss: 0.8216999491230695
Validation loss: 2.3794092570340184

Epoch: 6| Step: 10
Training loss: 0.9710118744906864
Validation loss: 2.363945369753362

Epoch: 6| Step: 11
Training loss: 0.7142543760305158
Validation loss: 2.3424903536407626

Epoch: 6| Step: 12
Training loss: 1.2290479419504639
Validation loss: 2.323817125259647

Epoch: 6| Step: 13
Training loss: 0.9214483987432385
Validation loss: 2.3075207013931522

Epoch: 278| Step: 0
Training loss: 0.5262484443079772
Validation loss: 2.298403484927956

Epoch: 6| Step: 1
Training loss: 0.8849343650531182
Validation loss: 2.2774283121611405

Epoch: 6| Step: 2
Training loss: 1.0156462447071901
Validation loss: 2.3064268884108805

Epoch: 6| Step: 3
Training loss: 0.7080562601285095
Validation loss: 2.332602610815069

Epoch: 6| Step: 4
Training loss: 1.0784677154278726
Validation loss: 2.332846060720542

Epoch: 6| Step: 5
Training loss: 0.9563077410549671
Validation loss: 2.345115935193733

Epoch: 6| Step: 6
Training loss: 0.7288532446328009
Validation loss: 2.3741942249387304

Epoch: 6| Step: 7
Training loss: 0.7190634831666752
Validation loss: 2.402493313758114

Epoch: 6| Step: 8
Training loss: 0.9337679967716239
Validation loss: 2.4330284030700002

Epoch: 6| Step: 9
Training loss: 1.0632643474774168
Validation loss: 2.4276056285316696

Epoch: 6| Step: 10
Training loss: 0.9506359431272081
Validation loss: 2.4172037646598636

Epoch: 6| Step: 11
Training loss: 0.3897548711825903
Validation loss: 2.4375924113141143

Epoch: 6| Step: 12
Training loss: 1.0847116041348952
Validation loss: 2.4647936612022137

Epoch: 6| Step: 13
Training loss: 0.7693831015562381
Validation loss: 2.448674377453968

Epoch: 279| Step: 0
Training loss: 0.8313493396800691
Validation loss: 2.431224994808684

Epoch: 6| Step: 1
Training loss: 1.0372050612969417
Validation loss: 2.442442079068631

Epoch: 6| Step: 2
Training loss: 0.9921950692916859
Validation loss: 2.408215548208299

Epoch: 6| Step: 3
Training loss: 0.853336132040004
Validation loss: 2.4162624280590093

Epoch: 6| Step: 4
Training loss: 0.7741266128422218
Validation loss: 2.4012945410950763

Epoch: 6| Step: 5
Training loss: 0.8650911096318236
Validation loss: 2.409155965100895

Epoch: 6| Step: 6
Training loss: 0.6971062229576446
Validation loss: 2.432323680014494

Epoch: 6| Step: 7
Training loss: 0.7045016481395148
Validation loss: 2.396247039073636

Epoch: 6| Step: 8
Training loss: 1.026749239445496
Validation loss: 2.3880584062916728

Epoch: 6| Step: 9
Training loss: 0.4552814864237157
Validation loss: 2.379954495634816

Epoch: 6| Step: 10
Training loss: 0.5671521241476588
Validation loss: 2.369436044569147

Epoch: 6| Step: 11
Training loss: 1.2712207526759451
Validation loss: 2.373026109073955

Epoch: 6| Step: 12
Training loss: 0.7824696366753653
Validation loss: 2.419839537821286

Epoch: 6| Step: 13
Training loss: 0.7619323039859849
Validation loss: 2.378981143700562

Epoch: 280| Step: 0
Training loss: 0.9231475194045113
Validation loss: 2.352523040093731

Epoch: 6| Step: 1
Training loss: 0.634771822385612
Validation loss: 2.39482582883395

Epoch: 6| Step: 2
Training loss: 0.9360299983352608
Validation loss: 2.4001613465290217

Epoch: 6| Step: 3
Training loss: 0.7807668717949672
Validation loss: 2.4316066894588113

Epoch: 6| Step: 4
Training loss: 0.6613693828297362
Validation loss: 2.436099676437121

Epoch: 6| Step: 5
Training loss: 0.8614539921630804
Validation loss: 2.4056149888559455

Epoch: 6| Step: 6
Training loss: 1.0849731334752761
Validation loss: 2.4192265420483405

Epoch: 6| Step: 7
Training loss: 0.5393178031184095
Validation loss: 2.4275866710148386

Epoch: 6| Step: 8
Training loss: 0.7952489531485255
Validation loss: 2.4420825896589773

Epoch: 6| Step: 9
Training loss: 0.7480919727247121
Validation loss: 2.4516907404952257

Epoch: 6| Step: 10
Training loss: 0.7713835445135427
Validation loss: 2.4264647605585754

Epoch: 6| Step: 11
Training loss: 0.9243716038557062
Validation loss: 2.4071840226876042

Epoch: 6| Step: 12
Training loss: 0.8180655450396304
Validation loss: 2.4063690820896086

Epoch: 6| Step: 13
Training loss: 1.228910494904362
Validation loss: 2.3873994167937926

Epoch: 281| Step: 0
Training loss: 0.7950641401675956
Validation loss: 2.395430631531173

Epoch: 6| Step: 1
Training loss: 0.5854022060477183
Validation loss: 2.3655541924891037

Epoch: 6| Step: 2
Training loss: 0.7755061911453256
Validation loss: 2.3394056592760357

Epoch: 6| Step: 3
Training loss: 0.9538733874259738
Validation loss: 2.346058645480204

Epoch: 6| Step: 4
Training loss: 0.6092603526717019
Validation loss: 2.3440682789165037

Epoch: 6| Step: 5
Training loss: 0.9612605164526812
Validation loss: 2.3321315077162867

Epoch: 6| Step: 6
Training loss: 1.0793191681753695
Validation loss: 2.3371698581234344

Epoch: 6| Step: 7
Training loss: 0.9435975463204623
Validation loss: 2.3796002309117874

Epoch: 6| Step: 8
Training loss: 0.5997747882730863
Validation loss: 2.372164501096241

Epoch: 6| Step: 9
Training loss: 1.1413741068716945
Validation loss: 2.392976833905406

Epoch: 6| Step: 10
Training loss: 0.412531342905105
Validation loss: 2.4205103755378894

Epoch: 6| Step: 11
Training loss: 1.0478988878525435
Validation loss: 2.4222205215604427

Epoch: 6| Step: 12
Training loss: 0.5417950245798824
Validation loss: 2.463584470963476

Epoch: 6| Step: 13
Training loss: 0.9113247619122103
Validation loss: 2.439947300131197

Epoch: 282| Step: 0
Training loss: 0.9434098571791275
Validation loss: 2.429366798946434

Epoch: 6| Step: 1
Training loss: 0.8928969667272733
Validation loss: 2.4207358908316237

Epoch: 6| Step: 2
Training loss: 0.8521799771096101
Validation loss: 2.3898615236257714

Epoch: 6| Step: 3
Training loss: 0.6886124280694956
Validation loss: 2.394949837778724

Epoch: 6| Step: 4
Training loss: 0.5794050633964735
Validation loss: 2.380740663407434

Epoch: 6| Step: 5
Training loss: 0.8428203264721008
Validation loss: 2.3876206083908644

Epoch: 6| Step: 6
Training loss: 0.6531729082852629
Validation loss: 2.385031037076545

Epoch: 6| Step: 7
Training loss: 0.6473396153079721
Validation loss: 2.409754563693665

Epoch: 6| Step: 8
Training loss: 0.6149240346838415
Validation loss: 2.411490543518639

Epoch: 6| Step: 9
Training loss: 1.0203241064279027
Validation loss: 2.409201110137787

Epoch: 6| Step: 10
Training loss: 0.8883296433336965
Validation loss: 2.368882034543678

Epoch: 6| Step: 11
Training loss: 0.8964466760225983
Validation loss: 2.3964020134848174

Epoch: 6| Step: 12
Training loss: 1.1532330201373209
Validation loss: 2.3978017937417335

Epoch: 6| Step: 13
Training loss: 0.6868830209876372
Validation loss: 2.3975994012229656

Epoch: 283| Step: 0
Training loss: 0.9097264793691122
Validation loss: 2.395575085632632

Epoch: 6| Step: 1
Training loss: 0.6961443136669443
Validation loss: 2.4142457769209855

Epoch: 6| Step: 2
Training loss: 1.1246668004290448
Validation loss: 2.381028424219144

Epoch: 6| Step: 3
Training loss: 0.606334387421631
Validation loss: 2.316228313882102

Epoch: 6| Step: 4
Training loss: 0.9269401925555667
Validation loss: 2.3490599992773116

Epoch: 6| Step: 5
Training loss: 0.6834175318699417
Validation loss: 2.367077383337042

Epoch: 6| Step: 6
Training loss: 0.8181023387524391
Validation loss: 2.343997726200917

Epoch: 6| Step: 7
Training loss: 0.6908339162861658
Validation loss: 2.3652691018592202

Epoch: 6| Step: 8
Training loss: 0.6757518563465584
Validation loss: 2.3706440705715432

Epoch: 6| Step: 9
Training loss: 0.8009214697166485
Validation loss: 2.368020921023505

Epoch: 6| Step: 10
Training loss: 0.452492436825262
Validation loss: 2.399624978855189

Epoch: 6| Step: 11
Training loss: 0.9350292390443677
Validation loss: 2.372256282530402

Epoch: 6| Step: 12
Training loss: 1.1084267768093816
Validation loss: 2.374717167721367

Epoch: 6| Step: 13
Training loss: 0.685084978004761
Validation loss: 2.374135168111779

Epoch: 284| Step: 0
Training loss: 0.6166009167682021
Validation loss: 2.384989179505527

Epoch: 6| Step: 1
Training loss: 0.4374151488173818
Validation loss: 2.3862499868775977

Epoch: 6| Step: 2
Training loss: 0.9043672670193266
Validation loss: 2.3994138578928794

Epoch: 6| Step: 3
Training loss: 0.7798425203075585
Validation loss: 2.428688945944731

Epoch: 6| Step: 4
Training loss: 0.7742758551823539
Validation loss: 2.433957979552989

Epoch: 6| Step: 5
Training loss: 0.6379385421518682
Validation loss: 2.3972951187223304

Epoch: 6| Step: 6
Training loss: 0.6638623553080838
Validation loss: 2.398036483819294

Epoch: 6| Step: 7
Training loss: 1.0860681249421607
Validation loss: 2.41603560123632

Epoch: 6| Step: 8
Training loss: 0.6800137756158424
Validation loss: 2.40357951386268

Epoch: 6| Step: 9
Training loss: 1.0998958126491647
Validation loss: 2.412148471618554

Epoch: 6| Step: 10
Training loss: 1.026666338123748
Validation loss: 2.404909147867314

Epoch: 6| Step: 11
Training loss: 0.8298035650017196
Validation loss: 2.3923211034963043

Epoch: 6| Step: 12
Training loss: 0.6102890592996723
Validation loss: 2.3869330589228936

Epoch: 6| Step: 13
Training loss: 0.9026992559926669
Validation loss: 2.3768703218327936

Epoch: 285| Step: 0
Training loss: 0.2320965164562084
Validation loss: 2.3675401007320858

Epoch: 6| Step: 1
Training loss: 0.81394536499076
Validation loss: 2.3514158141624124

Epoch: 6| Step: 2
Training loss: 0.6339721180218116
Validation loss: 2.3536393281620795

Epoch: 6| Step: 3
Training loss: 0.8369144898172042
Validation loss: 2.346080973404503

Epoch: 6| Step: 4
Training loss: 0.9662745442301947
Validation loss: 2.3834623556440033

Epoch: 6| Step: 5
Training loss: 0.7183437858080697
Validation loss: 2.3590646537082915

Epoch: 6| Step: 6
Training loss: 0.9776704225492945
Validation loss: 2.3740893541108896

Epoch: 6| Step: 7
Training loss: 0.8399884476321424
Validation loss: 2.409378426973942

Epoch: 6| Step: 8
Training loss: 0.656817554099787
Validation loss: 2.4035456253036207

Epoch: 6| Step: 9
Training loss: 0.7237491488410543
Validation loss: 2.4135066225153614

Epoch: 6| Step: 10
Training loss: 0.828894060136938
Validation loss: 2.4251720909416115

Epoch: 6| Step: 11
Training loss: 0.9116769292371188
Validation loss: 2.390995269074961

Epoch: 6| Step: 12
Training loss: 0.7952256805457305
Validation loss: 2.3758880000027687

Epoch: 6| Step: 13
Training loss: 0.3644995002638501
Validation loss: 2.3819744183521276

Epoch: 286| Step: 0
Training loss: 0.7073695601061861
Validation loss: 2.3676788774195274

Epoch: 6| Step: 1
Training loss: 0.8732062755376685
Validation loss: 2.3963143770396504

Epoch: 6| Step: 2
Training loss: 0.3875037231574086
Validation loss: 2.368851842705849

Epoch: 6| Step: 3
Training loss: 1.0306346675865852
Validation loss: 2.3772399261770416

Epoch: 6| Step: 4
Training loss: 0.6403877470261984
Validation loss: 2.365001049787735

Epoch: 6| Step: 5
Training loss: 0.5061922487826745
Validation loss: 2.3320845739400564

Epoch: 6| Step: 6
Training loss: 0.7761878232272583
Validation loss: 2.3562743575990694

Epoch: 6| Step: 7
Training loss: 0.7296536635859044
Validation loss: 2.368333688827887

Epoch: 6| Step: 8
Training loss: 0.4913344028998051
Validation loss: 2.363309191602432

Epoch: 6| Step: 9
Training loss: 0.8506742972412399
Validation loss: 2.3550709958445215

Epoch: 6| Step: 10
Training loss: 0.8467055232100253
Validation loss: 2.3945480126882868

Epoch: 6| Step: 11
Training loss: 0.8363470339964859
Validation loss: 2.407198737688228

Epoch: 6| Step: 12
Training loss: 1.0590683552345737
Validation loss: 2.3985997632432476

Epoch: 6| Step: 13
Training loss: 0.5052696826560842
Validation loss: 2.4085353455195886

Epoch: 287| Step: 0
Training loss: 0.4635911943643583
Validation loss: 2.393622446079488

Epoch: 6| Step: 1
Training loss: 0.503763193331622
Validation loss: 2.4258041778385033

Epoch: 6| Step: 2
Training loss: 1.1809145375401875
Validation loss: 2.4083450842811005

Epoch: 6| Step: 3
Training loss: 0.46708804191418873
Validation loss: 2.407288951232125

Epoch: 6| Step: 4
Training loss: 0.7211672727851034
Validation loss: 2.394162069601187

Epoch: 6| Step: 5
Training loss: 0.6986252807518338
Validation loss: 2.3954385035302455

Epoch: 6| Step: 6
Training loss: 0.9524687712348433
Validation loss: 2.3784288180903186

Epoch: 6| Step: 7
Training loss: 0.5049934782419115
Validation loss: 2.3810540149607586

Epoch: 6| Step: 8
Training loss: 0.9103007386086515
Validation loss: 2.352628955078762

Epoch: 6| Step: 9
Training loss: 0.8476364203739768
Validation loss: 2.377051177424823

Epoch: 6| Step: 10
Training loss: 0.6401233569859532
Validation loss: 2.3656112191715986

Epoch: 6| Step: 11
Training loss: 0.6031732421318771
Validation loss: 2.361499300812062

Epoch: 6| Step: 12
Training loss: 0.8697203342326958
Validation loss: 2.372936423076834

Epoch: 6| Step: 13
Training loss: 0.6663622583356464
Validation loss: 2.361424445150816

Epoch: 288| Step: 0
Training loss: 0.6993313064767044
Validation loss: 2.3582435833753106

Epoch: 6| Step: 1
Training loss: 0.5795359534234479
Validation loss: 2.3715024695425324

Epoch: 6| Step: 2
Training loss: 0.8557786423784652
Validation loss: 2.377945948931745

Epoch: 6| Step: 3
Training loss: 1.042100637953947
Validation loss: 2.3959723804530992

Epoch: 6| Step: 4
Training loss: 0.7802479994044496
Validation loss: 2.392649531718814

Epoch: 6| Step: 5
Training loss: 0.7278343062452914
Validation loss: 2.3760401008587384

Epoch: 6| Step: 6
Training loss: 0.6315887061811337
Validation loss: 2.4207672877970356

Epoch: 6| Step: 7
Training loss: 0.7848274719263513
Validation loss: 2.4359290595818974

Epoch: 6| Step: 8
Training loss: 0.9670835744212939
Validation loss: 2.4411434985457627

Epoch: 6| Step: 9
Training loss: 0.6718557488100906
Validation loss: 2.4586793127009097

Epoch: 6| Step: 10
Training loss: 0.7813896435866825
Validation loss: 2.459170688146556

Epoch: 6| Step: 11
Training loss: 0.8007747370757439
Validation loss: 2.4640235179026617

Epoch: 6| Step: 12
Training loss: 0.4909808490246468
Validation loss: 2.4240155412118956

Epoch: 6| Step: 13
Training loss: 0.3979027843883159
Validation loss: 2.411934505901273

Epoch: 289| Step: 0
Training loss: 0.5431041137138449
Validation loss: 2.395379686320056

Epoch: 6| Step: 1
Training loss: 0.6557175201722996
Validation loss: 2.3759900864466514

Epoch: 6| Step: 2
Training loss: 0.7345530517302847
Validation loss: 2.364040929626515

Epoch: 6| Step: 3
Training loss: 0.7191500586989668
Validation loss: 2.380937525765857

Epoch: 6| Step: 4
Training loss: 0.7767267126466786
Validation loss: 2.370939013569596

Epoch: 6| Step: 5
Training loss: 0.5587492506291017
Validation loss: 2.3515020582183856

Epoch: 6| Step: 6
Training loss: 1.116620967176588
Validation loss: 2.3782032045734365

Epoch: 6| Step: 7
Training loss: 0.8954843166517903
Validation loss: 2.363636024590383

Epoch: 6| Step: 8
Training loss: 0.7388475456319391
Validation loss: 2.3670290240023903

Epoch: 6| Step: 9
Training loss: 0.5736863139591494
Validation loss: 2.38655914862711

Epoch: 6| Step: 10
Training loss: 0.6282376828821117
Validation loss: 2.3868556065896294

Epoch: 6| Step: 11
Training loss: 0.6562395549124586
Validation loss: 2.415712724865717

Epoch: 6| Step: 12
Training loss: 0.8276749593626824
Validation loss: 2.4116947073550423

Epoch: 6| Step: 13
Training loss: 0.7529453617349526
Validation loss: 2.4077388172548

Epoch: 290| Step: 0
Training loss: 0.8484668635280322
Validation loss: 2.4205614278224874

Epoch: 6| Step: 1
Training loss: 0.8922097679338884
Validation loss: 2.400185890544383

Epoch: 6| Step: 2
Training loss: 0.892580428840452
Validation loss: 2.387057612148329

Epoch: 6| Step: 3
Training loss: 0.4901792487651742
Validation loss: 2.3747394053953568

Epoch: 6| Step: 4
Training loss: 0.6598707857223204
Validation loss: 2.404098979089306

Epoch: 6| Step: 5
Training loss: 0.35122783414468495
Validation loss: 2.414392922534139

Epoch: 6| Step: 6
Training loss: 0.5173586974062786
Validation loss: 2.3977341554065803

Epoch: 6| Step: 7
Training loss: 0.5798284847601028
Validation loss: 2.405571097999235

Epoch: 6| Step: 8
Training loss: 0.7540822984773559
Validation loss: 2.4306244832083848

Epoch: 6| Step: 9
Training loss: 0.7427793050690213
Validation loss: 2.42084435674058

Epoch: 6| Step: 10
Training loss: 0.8517053816730689
Validation loss: 2.397537769750363

Epoch: 6| Step: 11
Training loss: 0.6266764092533506
Validation loss: 2.4267605554556892

Epoch: 6| Step: 12
Training loss: 0.863335448069787
Validation loss: 2.4230138455652526

Epoch: 6| Step: 13
Training loss: 1.1100570838443424
Validation loss: 2.4115936964927136

Epoch: 291| Step: 0
Training loss: 0.670053496929466
Validation loss: 2.4401434696259536

Epoch: 6| Step: 1
Training loss: 0.857349331856548
Validation loss: 2.442098518913908

Epoch: 6| Step: 2
Training loss: 0.6475201287694152
Validation loss: 2.4359294205647717

Epoch: 6| Step: 3
Training loss: 0.5621101034768098
Validation loss: 2.4651124323268045

Epoch: 6| Step: 4
Training loss: 0.8527349397777132
Validation loss: 2.4531058002486335

Epoch: 6| Step: 5
Training loss: 0.6956188941269451
Validation loss: 2.4324746180458594

Epoch: 6| Step: 6
Training loss: 0.7008889990466965
Validation loss: 2.4282022265185352

Epoch: 6| Step: 7
Training loss: 0.7536804968070986
Validation loss: 2.389058187784221

Epoch: 6| Step: 8
Training loss: 0.4690168892517751
Validation loss: 2.3621277093852835

Epoch: 6| Step: 9
Training loss: 0.8225610342830796
Validation loss: 2.3694007339231504

Epoch: 6| Step: 10
Training loss: 0.9389365951248315
Validation loss: 2.332095087814618

Epoch: 6| Step: 11
Training loss: 0.8592135190969272
Validation loss: 2.328181800499008

Epoch: 6| Step: 12
Training loss: 0.8017150644482698
Validation loss: 2.34597571570056

Epoch: 6| Step: 13
Training loss: 0.2811678660521132
Validation loss: 2.3369296741344234

Epoch: 292| Step: 0
Training loss: 0.8100043629893784
Validation loss: 2.3102347518430992

Epoch: 6| Step: 1
Training loss: 0.5458419579511282
Validation loss: 2.306986388838441

Epoch: 6| Step: 2
Training loss: 0.43122757701352565
Validation loss: 2.32290182481841

Epoch: 6| Step: 3
Training loss: 0.8070987019596148
Validation loss: 2.3272368278611686

Epoch: 6| Step: 4
Training loss: 0.7643515057824752
Validation loss: 2.315758425767124

Epoch: 6| Step: 5
Training loss: 0.8086281736850891
Validation loss: 2.3488858737951364

Epoch: 6| Step: 6
Training loss: 0.6542970799687762
Validation loss: 2.366173441612935

Epoch: 6| Step: 7
Training loss: 0.9920352007903948
Validation loss: 2.3681522584161527

Epoch: 6| Step: 8
Training loss: 0.7274782296164521
Validation loss: 2.3751785155099996

Epoch: 6| Step: 9
Training loss: 0.5419629888144203
Validation loss: 2.406645332316629

Epoch: 6| Step: 10
Training loss: 0.7096380997819952
Validation loss: 2.3926695760695074

Epoch: 6| Step: 11
Training loss: 0.49116350555449023
Validation loss: 2.389103784487939

Epoch: 6| Step: 12
Training loss: 1.0354259787332014
Validation loss: 2.3890929444580413

Epoch: 6| Step: 13
Training loss: 0.41635248935766583
Validation loss: 2.3832539381328446

Epoch: 293| Step: 0
Training loss: 0.7915513849814619
Validation loss: 2.379195298353641

Epoch: 6| Step: 1
Training loss: 0.7787823041825565
Validation loss: 2.392191126792886

Epoch: 6| Step: 2
Training loss: 0.6016187270008058
Validation loss: 2.3986692603541506

Epoch: 6| Step: 3
Training loss: 0.7737924936362818
Validation loss: 2.3766251936564258

Epoch: 6| Step: 4
Training loss: 1.1062821270431757
Validation loss: 2.418398987468629

Epoch: 6| Step: 5
Training loss: 0.8106151873745386
Validation loss: 2.429138213300779

Epoch: 6| Step: 6
Training loss: 0.4913689603742475
Validation loss: 2.4139277365519463

Epoch: 6| Step: 7
Training loss: 0.37814845177932355
Validation loss: 2.458358598359935

Epoch: 6| Step: 8
Training loss: 0.772543727908697
Validation loss: 2.4565826725951356

Epoch: 6| Step: 9
Training loss: 0.7584369878527496
Validation loss: 2.465039795658294

Epoch: 6| Step: 10
Training loss: 0.9915611813377463
Validation loss: 2.423245881225161

Epoch: 6| Step: 11
Training loss: 0.5289549338897731
Validation loss: 2.3752400612091655

Epoch: 6| Step: 12
Training loss: 0.4487200581170026
Validation loss: 2.3799437938222288

Epoch: 6| Step: 13
Training loss: 0.5236122067533049
Validation loss: 2.351164092098874

Epoch: 294| Step: 0
Training loss: 0.7690628872668529
Validation loss: 2.357882459450386

Epoch: 6| Step: 1
Training loss: 0.6684375478665129
Validation loss: 2.3496647276412292

Epoch: 6| Step: 2
Training loss: 0.8451030619820277
Validation loss: 2.3608934752961344

Epoch: 6| Step: 3
Training loss: 0.9771358180370163
Validation loss: 2.3892283565298795

Epoch: 6| Step: 4
Training loss: 0.7177715690744176
Validation loss: 2.3665788679578057

Epoch: 6| Step: 5
Training loss: 0.7882880007376324
Validation loss: 2.406115792000605

Epoch: 6| Step: 6
Training loss: 0.5699604724680565
Validation loss: 2.4141541964815416

Epoch: 6| Step: 7
Training loss: 0.6777640344467547
Validation loss: 2.4194752236293424

Epoch: 6| Step: 8
Training loss: 0.7387594864005441
Validation loss: 2.4260115806485723

Epoch: 6| Step: 9
Training loss: 0.6880907208517079
Validation loss: 2.4058583415876216

Epoch: 6| Step: 10
Training loss: 0.6422115312149888
Validation loss: 2.3370496732308146

Epoch: 6| Step: 11
Training loss: 0.6976824457562513
Validation loss: 2.3721549875175

Epoch: 6| Step: 12
Training loss: 0.5506745904767263
Validation loss: 2.3690792925552056

Epoch: 6| Step: 13
Training loss: 0.8332563165996942
Validation loss: 2.3733386687917815

Epoch: 295| Step: 0
Training loss: 0.6550412171623157
Validation loss: 2.356048277058629

Epoch: 6| Step: 1
Training loss: 0.5853781764408383
Validation loss: 2.375072303280188

Epoch: 6| Step: 2
Training loss: 0.7606610902547862
Validation loss: 2.3955845436585337

Epoch: 6| Step: 3
Training loss: 1.0386348217068107
Validation loss: 2.4079067768215876

Epoch: 6| Step: 4
Training loss: 0.7004398786052211
Validation loss: 2.401192845034073

Epoch: 6| Step: 5
Training loss: 0.7226541055183553
Validation loss: 2.4263366356179796

Epoch: 6| Step: 6
Training loss: 0.7016123288816676
Validation loss: 2.4160005339506663

Epoch: 6| Step: 7
Training loss: 0.750977276825286
Validation loss: 2.395969403234097

Epoch: 6| Step: 8
Training loss: 0.4237194713071818
Validation loss: 2.4262403900723193

Epoch: 6| Step: 9
Training loss: 0.6877805397549651
Validation loss: 2.40906176966497

Epoch: 6| Step: 10
Training loss: 0.8968870966291599
Validation loss: 2.4047223363583

Epoch: 6| Step: 11
Training loss: 0.5644536529855337
Validation loss: 2.4084804113031035

Epoch: 6| Step: 12
Training loss: 0.667025787266809
Validation loss: 2.3984670233384984

Epoch: 6| Step: 13
Training loss: 0.5127679682521539
Validation loss: 2.4092865402160006

Epoch: 296| Step: 0
Training loss: 0.8036855737663222
Validation loss: 2.3992679920816427

Epoch: 6| Step: 1
Training loss: 1.0825619824748898
Validation loss: 2.3931613335706303

Epoch: 6| Step: 2
Training loss: 0.7514240335607706
Validation loss: 2.406642437008648

Epoch: 6| Step: 3
Training loss: 0.5066895613496077
Validation loss: 2.405094959955503

Epoch: 6| Step: 4
Training loss: 0.7706628989052765
Validation loss: 2.389048260738947

Epoch: 6| Step: 5
Training loss: 0.6359656859578955
Validation loss: 2.3957328648699607

Epoch: 6| Step: 6
Training loss: 0.5262836963349129
Validation loss: 2.3839591234427027

Epoch: 6| Step: 7
Training loss: 0.4817749813691694
Validation loss: 2.3967584925457897

Epoch: 6| Step: 8
Training loss: 0.7340546172893321
Validation loss: 2.3783986913911184

Epoch: 6| Step: 9
Training loss: 0.6813785519182797
Validation loss: 2.3574876337802864

Epoch: 6| Step: 10
Training loss: 0.5097460395879903
Validation loss: 2.3740733464838653

Epoch: 6| Step: 11
Training loss: 0.47202899390612435
Validation loss: 2.3567254185769553

Epoch: 6| Step: 12
Training loss: 0.6856990547489651
Validation loss: 2.3914289096658243

Epoch: 6| Step: 13
Training loss: 0.5832313607414151
Validation loss: 2.409364986163452

Epoch: 297| Step: 0
Training loss: 0.7014866709350305
Validation loss: 2.3842742841881046

Epoch: 6| Step: 1
Training loss: 0.7108983039530936
Validation loss: 2.397795434887162

Epoch: 6| Step: 2
Training loss: 0.8635741207403576
Validation loss: 2.397460515120588

Epoch: 6| Step: 3
Training loss: 0.8174313402069964
Validation loss: 2.374464334075586

Epoch: 6| Step: 4
Training loss: 0.4973449248246996
Validation loss: 2.411456780486421

Epoch: 6| Step: 5
Training loss: 0.6326768988859492
Validation loss: 2.391757518550107

Epoch: 6| Step: 6
Training loss: 0.7011077128941937
Validation loss: 2.429579104416014

Epoch: 6| Step: 7
Training loss: 0.7889243656525677
Validation loss: 2.41766336939155

Epoch: 6| Step: 8
Training loss: 0.6887445023138993
Validation loss: 2.406683494557727

Epoch: 6| Step: 9
Training loss: 0.7265905559414301
Validation loss: 2.421292182799326

Epoch: 6| Step: 10
Training loss: 0.45583990295715743
Validation loss: 2.404609152149418

Epoch: 6| Step: 11
Training loss: 0.7167464818053157
Validation loss: 2.4065748628545713

Epoch: 6| Step: 12
Training loss: 0.6954139464020213
Validation loss: 2.393287535237314

Epoch: 6| Step: 13
Training loss: 0.5151861230382228
Validation loss: 2.3733173745040945

Epoch: 298| Step: 0
Training loss: 0.4684435319416723
Validation loss: 2.378282096929997

Epoch: 6| Step: 1
Training loss: 0.83388831413984
Validation loss: 2.386861374854521

Epoch: 6| Step: 2
Training loss: 0.40646987246908794
Validation loss: 2.382917653948704

Epoch: 6| Step: 3
Training loss: 0.6331779225515323
Validation loss: 2.3623485373829047

Epoch: 6| Step: 4
Training loss: 0.550084803285654
Validation loss: 2.4145518201686436

Epoch: 6| Step: 5
Training loss: 0.456873548638456
Validation loss: 2.372320002659385

Epoch: 6| Step: 6
Training loss: 0.469507066989358
Validation loss: 2.4143762413497556

Epoch: 6| Step: 7
Training loss: 0.8495024865974554
Validation loss: 2.435109573694858

Epoch: 6| Step: 8
Training loss: 0.675369622437346
Validation loss: 2.456571580357884

Epoch: 6| Step: 9
Training loss: 0.7442113487296897
Validation loss: 2.4609281301116575

Epoch: 6| Step: 10
Training loss: 0.8218313778516375
Validation loss: 2.4343721468973247

Epoch: 6| Step: 11
Training loss: 1.0796857400485103
Validation loss: 2.450445109247875

Epoch: 6| Step: 12
Training loss: 0.7946338178509338
Validation loss: 2.4259764385542777

Epoch: 6| Step: 13
Training loss: 0.44206649216378713
Validation loss: 2.406077392208674

Epoch: 299| Step: 0
Training loss: 0.5660395520446538
Validation loss: 2.3584192593928646

Epoch: 6| Step: 1
Training loss: 0.9560884775613914
Validation loss: 2.3393690285171638

Epoch: 6| Step: 2
Training loss: 0.8776828983357118
Validation loss: 2.3419467324860483

Epoch: 6| Step: 3
Training loss: 0.6127672896761029
Validation loss: 2.381026234221159

Epoch: 6| Step: 4
Training loss: 0.8726026185578938
Validation loss: 2.4006157882790538

Epoch: 6| Step: 5
Training loss: 0.8092408838686675
Validation loss: 2.4521377360749135

Epoch: 6| Step: 6
Training loss: 0.5815184721763883
Validation loss: 2.468187305150751

Epoch: 6| Step: 7
Training loss: 0.7161742788503141
Validation loss: 2.506979809350079

Epoch: 6| Step: 8
Training loss: 0.6363789874708525
Validation loss: 2.5116717721178823

Epoch: 6| Step: 9
Training loss: 0.5738253900451092
Validation loss: 2.4930164163347923

Epoch: 6| Step: 10
Training loss: 0.8362158196139656
Validation loss: 2.4671445262571727

Epoch: 6| Step: 11
Training loss: 0.5670524856825048
Validation loss: 2.4653987732544826

Epoch: 6| Step: 12
Training loss: 0.6440937291199411
Validation loss: 2.458070793822901

Epoch: 6| Step: 13
Training loss: 0.7580841600027026
Validation loss: 2.414846399541297

Epoch: 300| Step: 0
Training loss: 0.5580376477889216
Validation loss: 2.3890843299149465

Epoch: 6| Step: 1
Training loss: 0.8767809794478199
Validation loss: 2.390599320292726

Epoch: 6| Step: 2
Training loss: 0.535332448869349
Validation loss: 2.376297798012401

Epoch: 6| Step: 3
Training loss: 0.474258905687102
Validation loss: 2.3597945658114865

Epoch: 6| Step: 4
Training loss: 0.6120496885099601
Validation loss: 2.366027387474429

Epoch: 6| Step: 5
Training loss: 0.6927417852216845
Validation loss: 2.3601323459037107

Epoch: 6| Step: 6
Training loss: 0.6889805457409631
Validation loss: 2.3859268469000194

Epoch: 6| Step: 7
Training loss: 0.6390249693652984
Validation loss: 2.360977245986092

Epoch: 6| Step: 8
Training loss: 0.7960114381294239
Validation loss: 2.362970474760618

Epoch: 6| Step: 9
Training loss: 0.6474571170377715
Validation loss: 2.386338620320418

Epoch: 6| Step: 10
Training loss: 0.6827004399647014
Validation loss: 2.388658210349667

Epoch: 6| Step: 11
Training loss: 0.5438277769916496
Validation loss: 2.409155276612581

Epoch: 6| Step: 12
Training loss: 0.9995254642378155
Validation loss: 2.404280878695569

Epoch: 6| Step: 13
Training loss: 0.7311157788070018
Validation loss: 2.425901400245654

Epoch: 301| Step: 0
Training loss: 0.8623289145914453
Validation loss: 2.439963900006375

Epoch: 6| Step: 1
Training loss: 0.550706709559076
Validation loss: 2.4320968111062196

Epoch: 6| Step: 2
Training loss: 0.45499484892434083
Validation loss: 2.408585077414462

Epoch: 6| Step: 3
Training loss: 0.645004653470308
Validation loss: 2.452859759042369

Epoch: 6| Step: 4
Training loss: 0.5934147390185993
Validation loss: 2.418666423457985

Epoch: 6| Step: 5
Training loss: 0.7756895935064768
Validation loss: 2.4192195252721973

Epoch: 6| Step: 6
Training loss: 0.593341887908873
Validation loss: 2.412179392635014

Epoch: 6| Step: 7
Training loss: 0.8270475467911867
Validation loss: 2.4126395974737713

Epoch: 6| Step: 8
Training loss: 0.7663114934394609
Validation loss: 2.387260458110156

Epoch: 6| Step: 9
Training loss: 0.7136275153945155
Validation loss: 2.3858918496193393

Epoch: 6| Step: 10
Training loss: 0.231465688846659
Validation loss: 2.4074729791480505

Epoch: 6| Step: 11
Training loss: 0.6924944573741783
Validation loss: 2.4241302931998705

Epoch: 6| Step: 12
Training loss: 0.6949625956466403
Validation loss: 2.4125124427797155

Epoch: 6| Step: 13
Training loss: 0.5833528350794536
Validation loss: 2.4142965024220056

Epoch: 302| Step: 0
Training loss: 0.30115462326729886
Validation loss: 2.4381717979300874

Epoch: 6| Step: 1
Training loss: 0.6593118266717776
Validation loss: 2.4167567912755255

Epoch: 6| Step: 2
Training loss: 0.3402289148148766
Validation loss: 2.424312994322287

Epoch: 6| Step: 3
Training loss: 0.6339043040782839
Validation loss: 2.4487346684917526

Epoch: 6| Step: 4
Training loss: 0.8500898734431572
Validation loss: 2.4251851981084673

Epoch: 6| Step: 5
Training loss: 0.4924771198534789
Validation loss: 2.4253858509862702

Epoch: 6| Step: 6
Training loss: 1.0299216298037428
Validation loss: 2.4271627803346068

Epoch: 6| Step: 7
Training loss: 0.506791217573028
Validation loss: 2.4302188453334264

Epoch: 6| Step: 8
Training loss: 0.6922488923757942
Validation loss: 2.4149259536436007

Epoch: 6| Step: 9
Training loss: 0.6699650475295484
Validation loss: 2.4569657117439325

Epoch: 6| Step: 10
Training loss: 0.8581641249548346
Validation loss: 2.4249708222745157

Epoch: 6| Step: 11
Training loss: 0.5566951791900274
Validation loss: 2.419652580070314

Epoch: 6| Step: 12
Training loss: 0.6817799510496695
Validation loss: 2.416834890004233

Epoch: 6| Step: 13
Training loss: 0.29113581434877833
Validation loss: 2.420606021235169

Epoch: 303| Step: 0
Training loss: 0.6194328075959041
Validation loss: 2.409442568783138

Epoch: 6| Step: 1
Training loss: 0.5941462700228907
Validation loss: 2.4255356036352365

Epoch: 6| Step: 2
Training loss: 0.9924236527200059
Validation loss: 2.3938658412604505

Epoch: 6| Step: 3
Training loss: 0.8066428417701834
Validation loss: 2.4004421858218317

Epoch: 6| Step: 4
Training loss: 0.6505178149611178
Validation loss: 2.3901019970978963

Epoch: 6| Step: 5
Training loss: 0.3189057184838254
Validation loss: 2.3882410687262032

Epoch: 6| Step: 6
Training loss: 0.5227858629298511
Validation loss: 2.373084210429118

Epoch: 6| Step: 7
Training loss: 0.6144867244586983
Validation loss: 2.3929788324494536

Epoch: 6| Step: 8
Training loss: 0.43539932557151473
Validation loss: 2.415347234165399

Epoch: 6| Step: 9
Training loss: 0.600520085391935
Validation loss: 2.43531822623826

Epoch: 6| Step: 10
Training loss: 0.5263314031493486
Validation loss: 2.3979746080688593

Epoch: 6| Step: 11
Training loss: 0.5175698909464429
Validation loss: 2.407246091966817

Epoch: 6| Step: 12
Training loss: 0.9868591087951093
Validation loss: 2.450331947168121

Epoch: 6| Step: 13
Training loss: 0.30675641686070904
Validation loss: 2.433392562375749

Epoch: 304| Step: 0
Training loss: 0.8127658849106683
Validation loss: 2.431868036149972

Epoch: 6| Step: 1
Training loss: 0.47245167805562116
Validation loss: 2.429576744507232

Epoch: 6| Step: 2
Training loss: 0.7411180118817468
Validation loss: 2.4354925321528063

Epoch: 6| Step: 3
Training loss: 0.6750446781631027
Validation loss: 2.4136537590210185

Epoch: 6| Step: 4
Training loss: 0.6084945382380114
Validation loss: 2.39736216418723

Epoch: 6| Step: 5
Training loss: 0.5745785941587123
Validation loss: 2.4116485055783814

Epoch: 6| Step: 6
Training loss: 0.35905062507269003
Validation loss: 2.4086097947639726

Epoch: 6| Step: 7
Training loss: 0.6544791579763859
Validation loss: 2.4138479700636455

Epoch: 6| Step: 8
Training loss: 0.6210071335381284
Validation loss: 2.4173956718439804

Epoch: 6| Step: 9
Training loss: 0.619918430946172
Validation loss: 2.4000395712188047

Epoch: 6| Step: 10
Training loss: 0.6468061585583137
Validation loss: 2.4406683056024123

Epoch: 6| Step: 11
Training loss: 0.43901837354587714
Validation loss: 2.4180265220904875

Epoch: 6| Step: 12
Training loss: 0.8593182631750285
Validation loss: 2.409546312680438

Epoch: 6| Step: 13
Training loss: 0.15536056329417944
Validation loss: 2.4071777088523114

Epoch: 305| Step: 0
Training loss: 0.20064880366545026
Validation loss: 2.418533050744305

Epoch: 6| Step: 1
Training loss: 0.4901056310596
Validation loss: 2.4070599639990826

Epoch: 6| Step: 2
Training loss: 0.6836606892100168
Validation loss: 2.418858220427001

Epoch: 6| Step: 3
Training loss: 0.8814461861692089
Validation loss: 2.4084802441887723

Epoch: 6| Step: 4
Training loss: 0.9300138397622656
Validation loss: 2.431424771786242

Epoch: 6| Step: 5
Training loss: 0.5263286003166138
Validation loss: 2.448354518972147

Epoch: 6| Step: 6
Training loss: 0.41035672692485664
Validation loss: 2.440548841376857

Epoch: 6| Step: 7
Training loss: 0.43617384735049575
Validation loss: 2.409570340843388

Epoch: 6| Step: 8
Training loss: 0.38595192917016585
Validation loss: 2.4091743839524655

Epoch: 6| Step: 9
Training loss: 0.3827747014905917
Validation loss: 2.391122819645191

Epoch: 6| Step: 10
Training loss: 0.8445318978983805
Validation loss: 2.4100425460580315

Epoch: 6| Step: 11
Training loss: 0.7545776934933411
Validation loss: 2.396948624264538

Epoch: 6| Step: 12
Training loss: 0.5953408061829727
Validation loss: 2.4123047975568346

Epoch: 6| Step: 13
Training loss: 0.8041185386038767
Validation loss: 2.393989227964639

Epoch: 306| Step: 0
Training loss: 0.5542502224344883
Validation loss: 2.409226163273052

Epoch: 6| Step: 1
Training loss: 0.5771233671007031
Validation loss: 2.378116500485932

Epoch: 6| Step: 2
Training loss: 0.5263278359050956
Validation loss: 2.403000715179219

Epoch: 6| Step: 3
Training loss: 0.6747464321843532
Validation loss: 2.3830946592683637

Epoch: 6| Step: 4
Training loss: 0.496341478266324
Validation loss: 2.3498501339970517

Epoch: 6| Step: 5
Training loss: 1.0495134952253622
Validation loss: 2.3930241447427165

Epoch: 6| Step: 6
Training loss: 0.5336816338345052
Validation loss: 2.3874336531966924

Epoch: 6| Step: 7
Training loss: 0.5005128733478005
Validation loss: 2.4130768179189457

Epoch: 6| Step: 8
Training loss: 0.6672592410394197
Validation loss: 2.392783462188005

Epoch: 6| Step: 9
Training loss: 0.7077375224909142
Validation loss: 2.3805911674313043

Epoch: 6| Step: 10
Training loss: 0.4582555950591161
Validation loss: 2.4150579184148144

Epoch: 6| Step: 11
Training loss: 0.5830838203404517
Validation loss: 2.414167190109888

Epoch: 6| Step: 12
Training loss: 0.4954307210493838
Validation loss: 2.42719626891226

Epoch: 6| Step: 13
Training loss: 0.4355410930437932
Validation loss: 2.40521650809149

Epoch: 307| Step: 0
Training loss: 0.5215559778097114
Validation loss: 2.425838501025956

Epoch: 6| Step: 1
Training loss: 0.5430359284262576
Validation loss: 2.389906178194375

Epoch: 6| Step: 2
Training loss: 0.5164288987633738
Validation loss: 2.397546000523687

Epoch: 6| Step: 3
Training loss: 0.3733171811860112
Validation loss: 2.412431271391387

Epoch: 6| Step: 4
Training loss: 0.46535516703392915
Validation loss: 2.419605915720969

Epoch: 6| Step: 5
Training loss: 0.5506010098811462
Validation loss: 2.40673285887921

Epoch: 6| Step: 6
Training loss: 0.6787341655900453
Validation loss: 2.404644999109548

Epoch: 6| Step: 7
Training loss: 0.7055166471154275
Validation loss: 2.408318489109293

Epoch: 6| Step: 8
Training loss: 0.7421951293553181
Validation loss: 2.3817186168316624

Epoch: 6| Step: 9
Training loss: 0.4741283223694251
Validation loss: 2.383318645341107

Epoch: 6| Step: 10
Training loss: 0.6121156148099516
Validation loss: 2.378682983855291

Epoch: 6| Step: 11
Training loss: 0.9373108355095371
Validation loss: 2.4062995836284293

Epoch: 6| Step: 12
Training loss: 0.5036416652892258
Validation loss: 2.3754584955238935

Epoch: 6| Step: 13
Training loss: 0.5058569300529868
Validation loss: 2.3884278635805978

Epoch: 308| Step: 0
Training loss: 0.3698517141705466
Validation loss: 2.3819258157877883

Epoch: 6| Step: 1
Training loss: 0.5268003701856815
Validation loss: 2.3764970364953206

Epoch: 6| Step: 2
Training loss: 0.5508449057730685
Validation loss: 2.401472151358576

Epoch: 6| Step: 3
Training loss: 0.642920776654018
Validation loss: 2.406126302824612

Epoch: 6| Step: 4
Training loss: 0.5567029416186959
Validation loss: 2.390112313679932

Epoch: 6| Step: 5
Training loss: 0.8051847014387064
Validation loss: 2.3967242422691077

Epoch: 6| Step: 6
Training loss: 0.5988044679352085
Validation loss: 2.3753641666472345

Epoch: 6| Step: 7
Training loss: 0.7134576919779425
Validation loss: 2.38462565493206

Epoch: 6| Step: 8
Training loss: 0.7999897091918916
Validation loss: 2.3868199682741333

Epoch: 6| Step: 9
Training loss: 0.48425054489483205
Validation loss: 2.379149805383522

Epoch: 6| Step: 10
Training loss: 0.40711684544249466
Validation loss: 2.3856243668784427

Epoch: 6| Step: 11
Training loss: 0.5239608198325563
Validation loss: 2.388853365846342

Epoch: 6| Step: 12
Training loss: 0.698826173509887
Validation loss: 2.38048088570637

Epoch: 6| Step: 13
Training loss: 0.3851374461011752
Validation loss: 2.3890179975365156

Epoch: 309| Step: 0
Training loss: 0.4447762456122052
Validation loss: 2.3734357439537836

Epoch: 6| Step: 1
Training loss: 0.7548494911488778
Validation loss: 2.380509435276382

Epoch: 6| Step: 2
Training loss: 0.46744109833259756
Validation loss: 2.37203389382337

Epoch: 6| Step: 3
Training loss: 0.5918637480265432
Validation loss: 2.3754600603913514

Epoch: 6| Step: 4
Training loss: 0.4108977925948032
Validation loss: 2.3830025473228753

Epoch: 6| Step: 5
Training loss: 0.8414030282216566
Validation loss: 2.4323822979199665

Epoch: 6| Step: 6
Training loss: 0.5756996417862317
Validation loss: 2.401283361080808

Epoch: 6| Step: 7
Training loss: 0.20926907122945967
Validation loss: 2.4186714237184916

Epoch: 6| Step: 8
Training loss: 0.6107114661541245
Validation loss: 2.4372945666874144

Epoch: 6| Step: 9
Training loss: 0.6112029706184986
Validation loss: 2.4029556856978433

Epoch: 6| Step: 10
Training loss: 0.9344309161752058
Validation loss: 2.412080485225023

Epoch: 6| Step: 11
Training loss: 0.5833356437183221
Validation loss: 2.4490850407236917

Epoch: 6| Step: 12
Training loss: 0.471530709127242
Validation loss: 2.4142416971724616

Epoch: 6| Step: 13
Training loss: 0.4593106672432358
Validation loss: 2.3989492334555678

Epoch: 310| Step: 0
Training loss: 0.5037216913111479
Validation loss: 2.427924703835894

Epoch: 6| Step: 1
Training loss: 0.7087171907584809
Validation loss: 2.4080294414110153

Epoch: 6| Step: 2
Training loss: 0.40113480423583187
Validation loss: 2.4236030883668813

Epoch: 6| Step: 3
Training loss: 0.5435072060838135
Validation loss: 2.4215477962212986

Epoch: 6| Step: 4
Training loss: 0.5044792525124449
Validation loss: 2.4584281225963394

Epoch: 6| Step: 5
Training loss: 0.8452809890260963
Validation loss: 2.4423499517567335

Epoch: 6| Step: 6
Training loss: 0.5138833658534461
Validation loss: 2.404935531299612

Epoch: 6| Step: 7
Training loss: 0.47907193601986403
Validation loss: 2.432217711833138

Epoch: 6| Step: 8
Training loss: 0.45514112044704286
Validation loss: 2.442266619023221

Epoch: 6| Step: 9
Training loss: 0.820805210916252
Validation loss: 2.425701576322014

Epoch: 6| Step: 10
Training loss: 0.6092199715237382
Validation loss: 2.39426560950848

Epoch: 6| Step: 11
Training loss: 0.69887504441451
Validation loss: 2.4061513410952156

Epoch: 6| Step: 12
Training loss: 0.46191304632159796
Validation loss: 2.3844932805179933

Epoch: 6| Step: 13
Training loss: 0.5312502524431414
Validation loss: 2.363036289603155

Epoch: 311| Step: 0
Training loss: 0.5217483366796706
Validation loss: 2.392013924872693

Epoch: 6| Step: 1
Training loss: 0.7708888978950187
Validation loss: 2.3799804620069236

Epoch: 6| Step: 2
Training loss: 0.7286281958938746
Validation loss: 2.396272533887512

Epoch: 6| Step: 3
Training loss: 0.685567828344539
Validation loss: 2.4162118987386783

Epoch: 6| Step: 4
Training loss: 0.805472981305853
Validation loss: 2.3751900979491314

Epoch: 6| Step: 5
Training loss: 0.6220445612633237
Validation loss: 2.4019030014854397

Epoch: 6| Step: 6
Training loss: 0.31736312805168326
Validation loss: 2.3979035748171342

Epoch: 6| Step: 7
Training loss: 0.55673725561005
Validation loss: 2.39942756492873

Epoch: 6| Step: 8
Training loss: 0.8134768555859316
Validation loss: 2.407391172478247

Epoch: 6| Step: 9
Training loss: 0.44347319633357524
Validation loss: 2.4512744322071427

Epoch: 6| Step: 10
Training loss: 0.5452312015386981
Validation loss: 2.44545991383725

Epoch: 6| Step: 11
Training loss: 0.17956736944150603
Validation loss: 2.448172347819985

Epoch: 6| Step: 12
Training loss: 0.31177103134787953
Validation loss: 2.4306804072536687

Epoch: 6| Step: 13
Training loss: 0.4600515580049246
Validation loss: 2.445055519871285

Epoch: 312| Step: 0
Training loss: 0.49328326304921855
Validation loss: 2.419413424110697

Epoch: 6| Step: 1
Training loss: 0.6866259654337111
Validation loss: 2.4155491245333462

Epoch: 6| Step: 2
Training loss: 0.2984347777716823
Validation loss: 2.3659135532581455

Epoch: 6| Step: 3
Training loss: 0.46856067330852946
Validation loss: 2.405808767246888

Epoch: 6| Step: 4
Training loss: 0.6492119955177432
Validation loss: 2.4174813081037145

Epoch: 6| Step: 5
Training loss: 0.4876093857873042
Validation loss: 2.408046186256758

Epoch: 6| Step: 6
Training loss: 0.8282408003545148
Validation loss: 2.4132381669455465

Epoch: 6| Step: 7
Training loss: 0.6068622918571199
Validation loss: 2.407665344103852

Epoch: 6| Step: 8
Training loss: 0.5446892792261756
Validation loss: 2.415262595879507

Epoch: 6| Step: 9
Training loss: 0.5713211180993955
Validation loss: 2.3999540384396805

Epoch: 6| Step: 10
Training loss: 0.39496354695407826
Validation loss: 2.400558978020096

Epoch: 6| Step: 11
Training loss: 0.5302767533959113
Validation loss: 2.413755410147767

Epoch: 6| Step: 12
Training loss: 0.863480419813858
Validation loss: 2.426613806405521

Epoch: 6| Step: 13
Training loss: 0.366463495268402
Validation loss: 2.436051457073354

Epoch: 313| Step: 0
Training loss: 0.6900084207200637
Validation loss: 2.4295171556550947

Epoch: 6| Step: 1
Training loss: 0.612184844388552
Validation loss: 2.410423734246163

Epoch: 6| Step: 2
Training loss: 0.2746545274276614
Validation loss: 2.443858574931399

Epoch: 6| Step: 3
Training loss: 0.4859139390734877
Validation loss: 2.39306357003844

Epoch: 6| Step: 4
Training loss: 0.8220273576509068
Validation loss: 2.443371316232663

Epoch: 6| Step: 5
Training loss: 0.7607042256629694
Validation loss: 2.4319828448102068

Epoch: 6| Step: 6
Training loss: 0.4153655260448062
Validation loss: 2.4149971820556093

Epoch: 6| Step: 7
Training loss: 0.6578185319057646
Validation loss: 2.437600059338193

Epoch: 6| Step: 8
Training loss: 0.5670973146477601
Validation loss: 2.3975404397425453

Epoch: 6| Step: 9
Training loss: 0.4005653558332563
Validation loss: 2.396418066660498

Epoch: 6| Step: 10
Training loss: 0.4986366669281369
Validation loss: 2.3933561320562498

Epoch: 6| Step: 11
Training loss: 0.654809506139222
Validation loss: 2.4041979280145016

Epoch: 6| Step: 12
Training loss: 0.5216601929044562
Validation loss: 2.401388432157312

Epoch: 6| Step: 13
Training loss: 0.11894355171290917
Validation loss: 2.368640265565251

Epoch: 314| Step: 0
Training loss: 0.4804784262078241
Validation loss: 2.348709511452698

Epoch: 6| Step: 1
Training loss: 0.1255321945361916
Validation loss: 2.386811069487236

Epoch: 6| Step: 2
Training loss: 0.7291609536810003
Validation loss: 2.3673403959370134

Epoch: 6| Step: 3
Training loss: 0.5501684472753321
Validation loss: 2.411574532844448

Epoch: 6| Step: 4
Training loss: 0.15782517155677683
Validation loss: 2.3772125516458225

Epoch: 6| Step: 5
Training loss: 0.3151041482762523
Validation loss: 2.4004047600676666

Epoch: 6| Step: 6
Training loss: 0.7379220563051633
Validation loss: 2.401558154207202

Epoch: 6| Step: 7
Training loss: 0.891697555672458
Validation loss: 2.426016375030496

Epoch: 6| Step: 8
Training loss: 0.5378194103872037
Validation loss: 2.422865196193934

Epoch: 6| Step: 9
Training loss: 0.6086376815825398
Validation loss: 2.425068556447963

Epoch: 6| Step: 10
Training loss: 0.4073952707325617
Validation loss: 2.4225989046805942

Epoch: 6| Step: 11
Training loss: 0.5352419485264321
Validation loss: 2.4267566800328915

Epoch: 6| Step: 12
Training loss: 0.706421267580391
Validation loss: 2.4387633186983666

Epoch: 6| Step: 13
Training loss: 0.49739903220967197
Validation loss: 2.4184663526190353

Epoch: 315| Step: 0
Training loss: 0.404504197631718
Validation loss: 2.3984715916688253

Epoch: 6| Step: 1
Training loss: 0.5278507197597836
Validation loss: 2.4078883541293714

Epoch: 6| Step: 2
Training loss: 0.38805632034274334
Validation loss: 2.4169157021524073

Epoch: 6| Step: 3
Training loss: 0.40867857189375867
Validation loss: 2.411412198080244

Epoch: 6| Step: 4
Training loss: 0.6054569612401354
Validation loss: 2.4014047647939565

Epoch: 6| Step: 5
Training loss: 0.37019111881293854
Validation loss: 2.404720440856779

Epoch: 6| Step: 6
Training loss: 0.7842754148816516
Validation loss: 2.420268120272048

Epoch: 6| Step: 7
Training loss: 0.7377549975234662
Validation loss: 2.421203171840504

Epoch: 6| Step: 8
Training loss: 0.7481819608542423
Validation loss: 2.441693126206534

Epoch: 6| Step: 9
Training loss: 0.4364656755775148
Validation loss: 2.421020111350284

Epoch: 6| Step: 10
Training loss: 0.6573036908129524
Validation loss: 2.4082350036540676

Epoch: 6| Step: 11
Training loss: 0.40215165450526386
Validation loss: 2.389722107890788

Epoch: 6| Step: 12
Training loss: 0.5422342120888896
Validation loss: 2.4068691883049

Epoch: 6| Step: 13
Training loss: 0.8712134856312639
Validation loss: 2.3935973902804744

Epoch: 316| Step: 0
Training loss: 0.3996940321757611
Validation loss: 2.395628524379634

Epoch: 6| Step: 1
Training loss: 0.7274643418005508
Validation loss: 2.359040845474261

Epoch: 6| Step: 2
Training loss: 0.5328764421236344
Validation loss: 2.3295420130389637

Epoch: 6| Step: 3
Training loss: 0.8119330996074863
Validation loss: 2.3674542584631655

Epoch: 6| Step: 4
Training loss: 0.3601729821478598
Validation loss: 2.382794210362759

Epoch: 6| Step: 5
Training loss: 0.6246004496420403
Validation loss: 2.381738099278242

Epoch: 6| Step: 6
Training loss: 0.8306148454376955
Validation loss: 2.3726882661584416

Epoch: 6| Step: 7
Training loss: 0.31020153685520474
Validation loss: 2.3906353837608836

Epoch: 6| Step: 8
Training loss: 0.5557897656860528
Validation loss: 2.4280325381835923

Epoch: 6| Step: 9
Training loss: 0.6942677739374776
Validation loss: 2.4087131743449235

Epoch: 6| Step: 10
Training loss: 0.16143558839337419
Validation loss: 2.4123185099870126

Epoch: 6| Step: 11
Training loss: 0.4636968038746204
Validation loss: 2.4144830000001174

Epoch: 6| Step: 12
Training loss: 0.4954333377575232
Validation loss: 2.4289835174545344

Epoch: 6| Step: 13
Training loss: 0.33361528313708766
Validation loss: 2.4275110681078997

Epoch: 317| Step: 0
Training loss: 0.42650636995350505
Validation loss: 2.4498692363560175

Epoch: 6| Step: 1
Training loss: 0.44926372800474357
Validation loss: 2.4352278488257704

Epoch: 6| Step: 2
Training loss: 0.8151577616043801
Validation loss: 2.443490723251354

Epoch: 6| Step: 3
Training loss: 0.29048248714079583
Validation loss: 2.4787221135830704

Epoch: 6| Step: 4
Training loss: 0.7637774304273026
Validation loss: 2.440537833832018

Epoch: 6| Step: 5
Training loss: 0.5863920864363594
Validation loss: 2.439318765873704

Epoch: 6| Step: 6
Training loss: 0.3434280491744303
Validation loss: 2.4509164046006493

Epoch: 6| Step: 7
Training loss: 0.6951822308868212
Validation loss: 2.4731618811396183

Epoch: 6| Step: 8
Training loss: 0.6595812669273037
Validation loss: 2.4630814757511654

Epoch: 6| Step: 9
Training loss: 0.6294588066527387
Validation loss: 2.467082710760318

Epoch: 6| Step: 10
Training loss: 0.18988487363386058
Validation loss: 2.426731314532712

Epoch: 6| Step: 11
Training loss: 0.5511675622934902
Validation loss: 2.4436415102368145

Epoch: 6| Step: 12
Training loss: 0.5963510960218066
Validation loss: 2.4069312518565766

Epoch: 6| Step: 13
Training loss: 0.25849066751316657
Validation loss: 2.3830075452281463

Epoch: 318| Step: 0
Training loss: 0.517857947372413
Validation loss: 2.388645722452295

Epoch: 6| Step: 1
Training loss: 0.7427423511292326
Validation loss: 2.39645841201192

Epoch: 6| Step: 2
Training loss: 0.5495838107824481
Validation loss: 2.388824771654374

Epoch: 6| Step: 3
Training loss: 0.543475292135506
Validation loss: 2.3561959485981787

Epoch: 6| Step: 4
Training loss: 0.5837014064535293
Validation loss: 2.378657174684514

Epoch: 6| Step: 5
Training loss: 0.5671855432565948
Validation loss: 2.392907162363113

Epoch: 6| Step: 6
Training loss: 0.5923063395486641
Validation loss: 2.3989197555921864

Epoch: 6| Step: 7
Training loss: 0.40637205197811804
Validation loss: 2.4164447689622994

Epoch: 6| Step: 8
Training loss: 0.30100922800252194
Validation loss: 2.405897698823104

Epoch: 6| Step: 9
Training loss: 0.34313866049598196
Validation loss: 2.43709270102361

Epoch: 6| Step: 10
Training loss: 0.5903869048078741
Validation loss: 2.4354642702772797

Epoch: 6| Step: 11
Training loss: 0.5932807573944852
Validation loss: 2.4474748385955865

Epoch: 6| Step: 12
Training loss: 0.6312098990818455
Validation loss: 2.449870655327954

Epoch: 6| Step: 13
Training loss: 0.32023537102623717
Validation loss: 2.4691115571878406

Epoch: 319| Step: 0
Training loss: 0.4775386412449014
Validation loss: 2.466636635817307

Epoch: 6| Step: 1
Training loss: 0.48949416004550905
Validation loss: 2.46577196526847

Epoch: 6| Step: 2
Training loss: 0.7210954461537558
Validation loss: 2.463130436266656

Epoch: 6| Step: 3
Training loss: 0.6706243674283275
Validation loss: 2.440132779639513

Epoch: 6| Step: 4
Training loss: 0.5543105765565367
Validation loss: 2.4590006858091003

Epoch: 6| Step: 5
Training loss: 0.5572611779640233
Validation loss: 2.4205475227283255

Epoch: 6| Step: 6
Training loss: 0.2387921219262668
Validation loss: 2.4158503006083385

Epoch: 6| Step: 7
Training loss: 0.46230604383481594
Validation loss: 2.4135046032613676

Epoch: 6| Step: 8
Training loss: 0.5560968252441574
Validation loss: 2.353332458484195

Epoch: 6| Step: 9
Training loss: 0.4650700443077817
Validation loss: 2.371723008364931

Epoch: 6| Step: 10
Training loss: 0.3916348564473426
Validation loss: 2.3770022940824287

Epoch: 6| Step: 11
Training loss: 0.7610729512125716
Validation loss: 2.3824937682238208

Epoch: 6| Step: 12
Training loss: 0.417957216620637
Validation loss: 2.3599289356094078

Epoch: 6| Step: 13
Training loss: 0.7265188962916613
Validation loss: 2.379764057579153

Epoch: 320| Step: 0
Training loss: 0.5664829596829414
Validation loss: 2.397653106532461

Epoch: 6| Step: 1
Training loss: 0.5729170596959471
Validation loss: 2.3679672598204413

Epoch: 6| Step: 2
Training loss: 0.7237339541117499
Validation loss: 2.361496060840438

Epoch: 6| Step: 3
Training loss: 0.14962200579599189
Validation loss: 2.384610550144048

Epoch: 6| Step: 4
Training loss: 0.19467225996347268
Validation loss: 2.382473253576608

Epoch: 6| Step: 5
Training loss: 0.5395041605282529
Validation loss: 2.4258819554418634

Epoch: 6| Step: 6
Training loss: 0.5953451362935326
Validation loss: 2.389030429296979

Epoch: 6| Step: 7
Training loss: 0.48247008912860373
Validation loss: 2.4011404654088166

Epoch: 6| Step: 8
Training loss: 0.594936991328597
Validation loss: 2.3861453590381867

Epoch: 6| Step: 9
Training loss: 0.4641839802810032
Validation loss: 2.401134040658418

Epoch: 6| Step: 10
Training loss: 0.3309651819273975
Validation loss: 2.403069016061205

Epoch: 6| Step: 11
Training loss: 0.7447917022349387
Validation loss: 2.410010927465139

Epoch: 6| Step: 12
Training loss: 0.5628999506795336
Validation loss: 2.4005472873086284

Epoch: 6| Step: 13
Training loss: 0.7297777793957587
Validation loss: 2.416136847633624

Epoch: 321| Step: 0
Training loss: 0.5986110067207656
Validation loss: 2.416374947331658

Epoch: 6| Step: 1
Training loss: 0.35556810688218726
Validation loss: 2.430422090966897

Epoch: 6| Step: 2
Training loss: 0.6640568676877988
Validation loss: 2.412301737940953

Epoch: 6| Step: 3
Training loss: 0.34451063488032246
Validation loss: 2.4206917107239394

Epoch: 6| Step: 4
Training loss: 0.53312000563005
Validation loss: 2.426061321503991

Epoch: 6| Step: 5
Training loss: 0.5748398205269519
Validation loss: 2.447331471205479

Epoch: 6| Step: 6
Training loss: 0.6037873332404896
Validation loss: 2.4297009782167036

Epoch: 6| Step: 7
Training loss: 0.5413708123393262
Validation loss: 2.4095161271207455

Epoch: 6| Step: 8
Training loss: 0.5749299711623344
Validation loss: 2.4099415138165914

Epoch: 6| Step: 9
Training loss: 0.6275225991286856
Validation loss: 2.3908344916678494

Epoch: 6| Step: 10
Training loss: 0.2655872430333074
Validation loss: 2.4153126472576893

Epoch: 6| Step: 11
Training loss: 0.4089019670506307
Validation loss: 2.3948794491516856

Epoch: 6| Step: 12
Training loss: 0.7265092973816484
Validation loss: 2.414722588535002

Epoch: 6| Step: 13
Training loss: 0.3136180427694883
Validation loss: 2.3881842126046973

Epoch: 322| Step: 0
Training loss: 0.5979377980989591
Validation loss: 2.3912426014523684

Epoch: 6| Step: 1
Training loss: 0.4305988357523776
Validation loss: 2.406595911339112

Epoch: 6| Step: 2
Training loss: 0.16241304840574275
Validation loss: 2.378560496928364

Epoch: 6| Step: 3
Training loss: 0.5527223241995327
Validation loss: 2.4073977455895883

Epoch: 6| Step: 4
Training loss: 0.7073752477941704
Validation loss: 2.392530625059954

Epoch: 6| Step: 5
Training loss: 0.568527930785589
Validation loss: 2.3985180579560126

Epoch: 6| Step: 6
Training loss: 0.6946506135922877
Validation loss: 2.407160170925718

Epoch: 6| Step: 7
Training loss: 0.5828619539689402
Validation loss: 2.4158640263410933

Epoch: 6| Step: 8
Training loss: 0.535446839898666
Validation loss: 2.404618006926535

Epoch: 6| Step: 9
Training loss: 0.5313869187681389
Validation loss: 2.390169636896692

Epoch: 6| Step: 10
Training loss: 0.4253912022834553
Validation loss: 2.3931458059540653

Epoch: 6| Step: 11
Training loss: 0.5084174440973317
Validation loss: 2.426553184439047

Epoch: 6| Step: 12
Training loss: 0.32198934560972686
Validation loss: 2.386958532659541

Epoch: 6| Step: 13
Training loss: 0.3819493274183927
Validation loss: 2.421364720493855

Epoch: 323| Step: 0
Training loss: 0.4365845195866766
Validation loss: 2.390437764998983

Epoch: 6| Step: 1
Training loss: 0.4785167149122632
Validation loss: 2.4112530515534485

Epoch: 6| Step: 2
Training loss: 0.8529547413159372
Validation loss: 2.437198821193359

Epoch: 6| Step: 3
Training loss: 0.4601825900869557
Validation loss: 2.413995140987196

Epoch: 6| Step: 4
Training loss: 0.33793057773302176
Validation loss: 2.4103693195551656

Epoch: 6| Step: 5
Training loss: 0.2976329814396636
Validation loss: 2.4122275408020126

Epoch: 6| Step: 6
Training loss: 0.4850376272844658
Validation loss: 2.412899493436179

Epoch: 6| Step: 7
Training loss: 0.3572930067202218
Validation loss: 2.3912228823169692

Epoch: 6| Step: 8
Training loss: 0.618547847747327
Validation loss: 2.394304107592058

Epoch: 6| Step: 9
Training loss: 0.5738239098608959
Validation loss: 2.420012487153682

Epoch: 6| Step: 10
Training loss: 0.35950585760960385
Validation loss: 2.4060830744362733

Epoch: 6| Step: 11
Training loss: 0.659052676927591
Validation loss: 2.4297930151131135

Epoch: 6| Step: 12
Training loss: 0.5966560121824586
Validation loss: 2.4006003644112166

Epoch: 6| Step: 13
Training loss: 0.33112935262305554
Validation loss: 2.397857101968027

Epoch: 324| Step: 0
Training loss: 0.29674874933986756
Validation loss: 2.3958319437059505

Epoch: 6| Step: 1
Training loss: 0.6135712684998779
Validation loss: 2.4019426121802523

Epoch: 6| Step: 2
Training loss: 0.5704536002160614
Validation loss: 2.375005595746273

Epoch: 6| Step: 3
Training loss: 0.4121917353044452
Validation loss: 2.3831348950848623

Epoch: 6| Step: 4
Training loss: 0.46972960790332946
Validation loss: 2.403497475476394

Epoch: 6| Step: 5
Training loss: 0.845514536350838
Validation loss: 2.397025999134597

Epoch: 6| Step: 6
Training loss: 0.42312880803117453
Validation loss: 2.3847058995298407

Epoch: 6| Step: 7
Training loss: 0.5014824943073389
Validation loss: 2.3898656811978536

Epoch: 6| Step: 8
Training loss: 0.3248179654947388
Validation loss: 2.408522135237563

Epoch: 6| Step: 9
Training loss: 0.330406826611572
Validation loss: 2.386512511800299

Epoch: 6| Step: 10
Training loss: 0.5841392898493293
Validation loss: 2.362347926953063

Epoch: 6| Step: 11
Training loss: 0.35125680984737806
Validation loss: 2.390358009364776

Epoch: 6| Step: 12
Training loss: 0.699341661955796
Validation loss: 2.4013777628790374

Epoch: 6| Step: 13
Training loss: 0.48984493882127783
Validation loss: 2.4196373570152256

Epoch: 325| Step: 0
Training loss: 0.46304085462584743
Validation loss: 2.3813709715249103

Epoch: 6| Step: 1
Training loss: 0.4946548289428558
Validation loss: 2.3994833223433467

Epoch: 6| Step: 2
Training loss: 0.9572185099601039
Validation loss: 2.424057295987176

Epoch: 6| Step: 3
Training loss: 0.4758623639696938
Validation loss: 2.400974678391856

Epoch: 6| Step: 4
Training loss: 0.4246734591837374
Validation loss: 2.374923664889118

Epoch: 6| Step: 5
Training loss: 0.33710037829438144
Validation loss: 2.418499669051201

Epoch: 6| Step: 6
Training loss: 0.4488395417224716
Validation loss: 2.4178940746917275

Epoch: 6| Step: 7
Training loss: 0.5327941667641252
Validation loss: 2.3603192022220223

Epoch: 6| Step: 8
Training loss: 0.36520310130327543
Validation loss: 2.365165653563085

Epoch: 6| Step: 9
Training loss: 0.23274370559576818
Validation loss: 2.36178653493806

Epoch: 6| Step: 10
Training loss: 0.4215695546990076
Validation loss: 2.3758321951833725

Epoch: 6| Step: 11
Training loss: 0.5538610830037187
Validation loss: 2.413874175080065

Epoch: 6| Step: 12
Training loss: 0.3962869763495677
Validation loss: 2.381652394696626

Epoch: 6| Step: 13
Training loss: 0.5791833572132506
Validation loss: 2.3910534205587837

Epoch: 326| Step: 0
Training loss: 0.5468546999842108
Validation loss: 2.3853570712409424

Epoch: 6| Step: 1
Training loss: 0.1938952620541488
Validation loss: 2.3328068691572783

Epoch: 6| Step: 2
Training loss: 0.3828866069452889
Validation loss: 2.3481422838343478

Epoch: 6| Step: 3
Training loss: 0.31340147170778415
Validation loss: 2.379507681220031

Epoch: 6| Step: 4
Training loss: 0.5754290172357289
Validation loss: 2.417717219103543

Epoch: 6| Step: 5
Training loss: 0.6622194406854036
Validation loss: 2.4009134357436333

Epoch: 6| Step: 6
Training loss: 0.5193763157705081
Validation loss: 2.4047581139357814

Epoch: 6| Step: 7
Training loss: 0.47257988683315705
Validation loss: 2.4133962961169177

Epoch: 6| Step: 8
Training loss: 0.4822406505629626
Validation loss: 2.395262142823182

Epoch: 6| Step: 9
Training loss: 0.6595462486298638
Validation loss: 2.389819987734658

Epoch: 6| Step: 10
Training loss: 0.3420724030714285
Validation loss: 2.4052129395665003

Epoch: 6| Step: 11
Training loss: 0.46389108696656006
Validation loss: 2.392317091912428

Epoch: 6| Step: 12
Training loss: 0.47409000943054563
Validation loss: 2.396418990950426

Epoch: 6| Step: 13
Training loss: 0.9061948496381513
Validation loss: 2.371259401180942

Epoch: 327| Step: 0
Training loss: 0.62381563024841
Validation loss: 2.3872134022004774

Epoch: 6| Step: 1
Training loss: 0.522544925391885
Validation loss: 2.4114209810989897

Epoch: 6| Step: 2
Training loss: 0.4619365307623948
Validation loss: 2.438687169257402

Epoch: 6| Step: 3
Training loss: 0.13895286379744234
Validation loss: 2.413317053830658

Epoch: 6| Step: 4
Training loss: 0.5496328840941738
Validation loss: 2.3911032045934606

Epoch: 6| Step: 5
Training loss: 0.346355490813437
Validation loss: 2.3553939862161735

Epoch: 6| Step: 6
Training loss: 0.35869320173928043
Validation loss: 2.3467090082476716

Epoch: 6| Step: 7
Training loss: 0.4280338371283892
Validation loss: 2.3712424598069854

Epoch: 6| Step: 8
Training loss: 0.4189891658852609
Validation loss: 2.366678770568893

Epoch: 6| Step: 9
Training loss: 0.7566038107987547
Validation loss: 2.3949617013920417

Epoch: 6| Step: 10
Training loss: 0.6527460194250473
Validation loss: 2.363281788050903

Epoch: 6| Step: 11
Training loss: 0.42001815401874554
Validation loss: 2.3829334273400824

Epoch: 6| Step: 12
Training loss: 0.4758454384435925
Validation loss: 2.40551260154412

Epoch: 6| Step: 13
Training loss: 0.5189718806048952
Validation loss: 2.4178301114965484

Epoch: 328| Step: 0
Training loss: 0.654731401232488
Validation loss: 2.4071355553103184

Epoch: 6| Step: 1
Training loss: 0.3770047088273322
Validation loss: 2.4291561070404777

Epoch: 6| Step: 2
Training loss: 0.5929429944542678
Validation loss: 2.431517901097149

Epoch: 6| Step: 3
Training loss: 0.5054573906826372
Validation loss: 2.4471865565115523

Epoch: 6| Step: 4
Training loss: 0.5832611504808003
Validation loss: 2.3903749825681597

Epoch: 6| Step: 5
Training loss: 0.5052115220693522
Validation loss: 2.420737363946907

Epoch: 6| Step: 6
Training loss: 0.4427866155937496
Validation loss: 2.4167239377198486

Epoch: 6| Step: 7
Training loss: 0.3306718598926232
Validation loss: 2.402028536815693

Epoch: 6| Step: 8
Training loss: 0.46709024316450426
Validation loss: 2.3932848572869716

Epoch: 6| Step: 9
Training loss: 0.692570756334069
Validation loss: 2.406270016822825

Epoch: 6| Step: 10
Training loss: 0.5080372239764914
Validation loss: 2.4001733194982844

Epoch: 6| Step: 11
Training loss: 0.37701668475236616
Validation loss: 2.4201432267660263

Epoch: 6| Step: 12
Training loss: 0.42511462601227623
Validation loss: 2.403171071171622

Epoch: 6| Step: 13
Training loss: 0.47279491439761273
Validation loss: 2.410165804374705

Epoch: 329| Step: 0
Training loss: 0.33342064022066353
Validation loss: 2.380569945017355

Epoch: 6| Step: 1
Training loss: 0.5440033311566573
Validation loss: 2.396432454358869

Epoch: 6| Step: 2
Training loss: 0.6331012208470401
Validation loss: 2.4112125693990114

Epoch: 6| Step: 3
Training loss: 0.6435162267928732
Validation loss: 2.421274771989314

Epoch: 6| Step: 4
Training loss: 0.37470947376177927
Validation loss: 2.414708051031995

Epoch: 6| Step: 5
Training loss: 0.5871877428899874
Validation loss: 2.3944754120681955

Epoch: 6| Step: 6
Training loss: 0.4852804826539636
Validation loss: 2.376060441233624

Epoch: 6| Step: 7
Training loss: 0.6507059884944386
Validation loss: 2.388221362915202

Epoch: 6| Step: 8
Training loss: 0.37239274999591404
Validation loss: 2.398604579817943

Epoch: 6| Step: 9
Training loss: 0.5023835114543239
Validation loss: 2.389066330269863

Epoch: 6| Step: 10
Training loss: 0.34014944599795643
Validation loss: 2.397388827167147

Epoch: 6| Step: 11
Training loss: 0.1334519350230852
Validation loss: 2.4212222809852166

Epoch: 6| Step: 12
Training loss: 0.5852999970281468
Validation loss: 2.435154695532838

Epoch: 6| Step: 13
Training loss: 0.26697188986006076
Validation loss: 2.4315422182168906

Epoch: 330| Step: 0
Training loss: 0.7501071614955821
Validation loss: 2.4037103140465135

Epoch: 6| Step: 1
Training loss: 0.3970261803986048
Validation loss: 2.4401723507408914

Epoch: 6| Step: 2
Training loss: 0.5547288959798736
Validation loss: 2.439874108664515

Epoch: 6| Step: 3
Training loss: 0.312239991740049
Validation loss: 2.4428504548994

Epoch: 6| Step: 4
Training loss: 0.6496082445824124
Validation loss: 2.4109735959600718

Epoch: 6| Step: 5
Training loss: 0.4218204780951188
Validation loss: 2.4386804465810914

Epoch: 6| Step: 6
Training loss: 0.37961857488003853
Validation loss: 2.407843749837245

Epoch: 6| Step: 7
Training loss: 0.1699152101108496
Validation loss: 2.4368815198778058

Epoch: 6| Step: 8
Training loss: 0.6619567695228308
Validation loss: 2.394781863880729

Epoch: 6| Step: 9
Training loss: 0.6203516239156381
Validation loss: 2.4265773474095624

Epoch: 6| Step: 10
Training loss: 0.273875349165582
Validation loss: 2.4048882157391125

Epoch: 6| Step: 11
Training loss: 0.3656044783090483
Validation loss: 2.4477544681500505

Epoch: 6| Step: 12
Training loss: 0.6229881569867952
Validation loss: 2.4319226502650877

Epoch: 6| Step: 13
Training loss: 0.4387893071187099
Validation loss: 2.435270631450936

Epoch: 331| Step: 0
Training loss: 0.5638827705938759
Validation loss: 2.447673088178603

Epoch: 6| Step: 1
Training loss: 0.5338699028363085
Validation loss: 2.406857315215665

Epoch: 6| Step: 2
Training loss: 0.5948784294470431
Validation loss: 2.411688026101161

Epoch: 6| Step: 3
Training loss: 0.2814764991651551
Validation loss: 2.4009217964245835

Epoch: 6| Step: 4
Training loss: 0.4610803673669088
Validation loss: 2.404778445938082

Epoch: 6| Step: 5
Training loss: 0.4933434641636628
Validation loss: 2.4201706577957367

Epoch: 6| Step: 6
Training loss: 0.4958370625999465
Validation loss: 2.426512808044282

Epoch: 6| Step: 7
Training loss: 0.47884517921254877
Validation loss: 2.4223398832224774

Epoch: 6| Step: 8
Training loss: 0.506121681575585
Validation loss: 2.3959336843424786

Epoch: 6| Step: 9
Training loss: 0.3235127218743079
Validation loss: 2.4249537064032713

Epoch: 6| Step: 10
Training loss: 0.6100619918560065
Validation loss: 2.414544060916715

Epoch: 6| Step: 11
Training loss: 0.4613354791350616
Validation loss: 2.3991961615239625

Epoch: 6| Step: 12
Training loss: 0.30067885501369784
Validation loss: 2.4052264584712444

Epoch: 6| Step: 13
Training loss: 0.6574277300695757
Validation loss: 2.42463411430148

Epoch: 332| Step: 0
Training loss: 0.5056329758136464
Validation loss: 2.418795062802208

Epoch: 6| Step: 1
Training loss: 0.15011903465379323
Validation loss: 2.4333664327009057

Epoch: 6| Step: 2
Training loss: 0.31935855657048134
Validation loss: 2.436531067836114

Epoch: 6| Step: 3
Training loss: 0.43076764372714055
Validation loss: 2.430837497756198

Epoch: 6| Step: 4
Training loss: 0.3572546562548079
Validation loss: 2.454476415802559

Epoch: 6| Step: 5
Training loss: 0.737133688391782
Validation loss: 2.4462827861920617

Epoch: 6| Step: 6
Training loss: 0.5548556972754644
Validation loss: 2.4492223080525832

Epoch: 6| Step: 7
Training loss: 0.3420434334973762
Validation loss: 2.428511399645477

Epoch: 6| Step: 8
Training loss: 0.3904893448837632
Validation loss: 2.44180128062513

Epoch: 6| Step: 9
Training loss: 0.39705267706125746
Validation loss: 2.4166085134036246

Epoch: 6| Step: 10
Training loss: 0.43125620505803086
Validation loss: 2.398979555180877

Epoch: 6| Step: 11
Training loss: 0.4743662552913374
Validation loss: 2.4144387755537204

Epoch: 6| Step: 12
Training loss: 0.7097083144702938
Validation loss: 2.382563113202698

Epoch: 6| Step: 13
Training loss: 0.5434028481946201
Validation loss: 2.4017014989652363

Epoch: 333| Step: 0
Training loss: 0.6305452633627868
Validation loss: 2.4246641592309475

Epoch: 6| Step: 1
Training loss: 0.26256184927867227
Validation loss: 2.408362658819208

Epoch: 6| Step: 2
Training loss: 0.6178938288550733
Validation loss: 2.444333245206754

Epoch: 6| Step: 3
Training loss: 0.5661665573702079
Validation loss: 2.446706674841114

Epoch: 6| Step: 4
Training loss: 0.5015709457399405
Validation loss: 2.443754406719873

Epoch: 6| Step: 5
Training loss: 0.518107765840644
Validation loss: 2.43777489091561

Epoch: 6| Step: 6
Training loss: 0.3819716424602333
Validation loss: 2.432964045369328

Epoch: 6| Step: 7
Training loss: 0.2609888974126632
Validation loss: 2.438117082481097

Epoch: 6| Step: 8
Training loss: 0.45409573787112073
Validation loss: 2.4345499565694064

Epoch: 6| Step: 9
Training loss: 0.45891499096368393
Validation loss: 2.4372724190720967

Epoch: 6| Step: 10
Training loss: 0.3815935150713077
Validation loss: 2.4523837399563244

Epoch: 6| Step: 11
Training loss: 0.5727231016598918
Validation loss: 2.4358744410990125

Epoch: 6| Step: 12
Training loss: 0.38214715240926883
Validation loss: 2.4181330464318966

Epoch: 6| Step: 13
Training loss: 0.6122948799382127
Validation loss: 2.469537966717003

Epoch: 334| Step: 0
Training loss: 0.2533750405822029
Validation loss: 2.4484299777177725

Epoch: 6| Step: 1
Training loss: 0.6946714639464491
Validation loss: 2.45068174425855

Epoch: 6| Step: 2
Training loss: 0.26992075874329663
Validation loss: 2.4005462070870056

Epoch: 6| Step: 3
Training loss: 0.3630763060311647
Validation loss: 2.425395898837993

Epoch: 6| Step: 4
Training loss: 0.7065287326941855
Validation loss: 2.412666947257958

Epoch: 6| Step: 5
Training loss: 0.46691146146473794
Validation loss: 2.444880723435963

Epoch: 6| Step: 6
Training loss: 0.46789542819449653
Validation loss: 2.4298372971972957

Epoch: 6| Step: 7
Training loss: 0.5188268604558979
Validation loss: 2.4358034466597407

Epoch: 6| Step: 8
Training loss: 0.250519332299656
Validation loss: 2.4265105280896604

Epoch: 6| Step: 9
Training loss: 0.3373826127417749
Validation loss: 2.406479837185336

Epoch: 6| Step: 10
Training loss: 0.3997799566136626
Validation loss: 2.442597115894514

Epoch: 6| Step: 11
Training loss: 0.5222964304110924
Validation loss: 2.441430290120216

Epoch: 6| Step: 12
Training loss: 0.4642627836161074
Validation loss: 2.4199572424711864

Epoch: 6| Step: 13
Training loss: 0.6348243568832679
Validation loss: 2.378809243969078

Epoch: 335| Step: 0
Training loss: 0.5167721789306067
Validation loss: 2.4128338263970055

Epoch: 6| Step: 1
Training loss: 0.22690296899198886
Validation loss: 2.3865062114888196

Epoch: 6| Step: 2
Training loss: 0.6895392258781644
Validation loss: 2.411657612489196

Epoch: 6| Step: 3
Training loss: 0.5309139479094165
Validation loss: 2.3994408867163917

Epoch: 6| Step: 4
Training loss: 0.5094963912012476
Validation loss: 2.4113661168738236

Epoch: 6| Step: 5
Training loss: 0.4433959240069616
Validation loss: 2.4243511465175316

Epoch: 6| Step: 6
Training loss: 0.5275097620996342
Validation loss: 2.426742602323956

Epoch: 6| Step: 7
Training loss: 0.4321452337079189
Validation loss: 2.452170530212267

Epoch: 6| Step: 8
Training loss: 0.2805976985658245
Validation loss: 2.4398319920265563

Epoch: 6| Step: 9
Training loss: 0.21091593526175578
Validation loss: 2.4723727228570915

Epoch: 6| Step: 10
Training loss: 0.3741681289679677
Validation loss: 2.4657920535740665

Epoch: 6| Step: 11
Training loss: 0.3253895634774688
Validation loss: 2.4566442461763756

Epoch: 6| Step: 12
Training loss: 0.570597694888508
Validation loss: 2.4442879676688083

Epoch: 6| Step: 13
Training loss: 0.5803637844795573
Validation loss: 2.4687981518407973

Epoch: 336| Step: 0
Training loss: 0.2863866051545731
Validation loss: 2.474528462766865

Epoch: 6| Step: 1
Training loss: 0.3997919771068349
Validation loss: 2.4372818394064755

Epoch: 6| Step: 2
Training loss: 0.4872101747522659
Validation loss: 2.4691949783164557

Epoch: 6| Step: 3
Training loss: 0.2805369132261646
Validation loss: 2.4396945580988203

Epoch: 6| Step: 4
Training loss: 0.413547699673684
Validation loss: 2.4357148999560607

Epoch: 6| Step: 5
Training loss: 0.3112245159938437
Validation loss: 2.4101631118049958

Epoch: 6| Step: 6
Training loss: 0.1718785654044977
Validation loss: 2.4475596052088107

Epoch: 6| Step: 7
Training loss: 0.520638454854146
Validation loss: 2.4431681929651115

Epoch: 6| Step: 8
Training loss: 0.40211924983814573
Validation loss: 2.4215580050367413

Epoch: 6| Step: 9
Training loss: 0.5483337021549147
Validation loss: 2.4349761919798825

Epoch: 6| Step: 10
Training loss: 0.44398316852567427
Validation loss: 2.4491525892202524

Epoch: 6| Step: 11
Training loss: 0.40921124175045165
Validation loss: 2.444646912552208

Epoch: 6| Step: 12
Training loss: 0.8352664143314732
Validation loss: 2.4496559584585467

Epoch: 6| Step: 13
Training loss: 0.6071479645882887
Validation loss: 2.4145881846938706

Epoch: 337| Step: 0
Training loss: 0.2770477380810655
Validation loss: 2.41576453012381

Epoch: 6| Step: 1
Training loss: 0.203133637904856
Validation loss: 2.425082367433892

Epoch: 6| Step: 2
Training loss: 0.5912116149958953
Validation loss: 2.4182974467226863

Epoch: 6| Step: 3
Training loss: 0.6076821999024973
Validation loss: 2.4236667331397443

Epoch: 6| Step: 4
Training loss: 0.4099919671341717
Validation loss: 2.421445147752481

Epoch: 6| Step: 5
Training loss: 0.35214166618857096
Validation loss: 2.4279028899428483

Epoch: 6| Step: 6
Training loss: 0.4163033292018282
Validation loss: 2.4271754539978336

Epoch: 6| Step: 7
Training loss: 0.2875190459037993
Validation loss: 2.4137253547601905

Epoch: 6| Step: 8
Training loss: 0.525535393378676
Validation loss: 2.4135601677137406

Epoch: 6| Step: 9
Training loss: 0.4835394451359321
Validation loss: 2.4022290498297147

Epoch: 6| Step: 10
Training loss: 0.363149188248847
Validation loss: 2.395928279784106

Epoch: 6| Step: 11
Training loss: 0.6611822833846965
Validation loss: 2.4146177950993835

Epoch: 6| Step: 12
Training loss: 0.48041555839051214
Validation loss: 2.426500306301993

Epoch: 6| Step: 13
Training loss: 0.5335844862931081
Validation loss: 2.426971851971282

Epoch: 338| Step: 0
Training loss: 0.53313244361645
Validation loss: 2.42031806284156

Epoch: 6| Step: 1
Training loss: 0.378040918349409
Validation loss: 2.4514553187104693

Epoch: 6| Step: 2
Training loss: 0.4841482493114326
Validation loss: 2.4518260287365408

Epoch: 6| Step: 3
Training loss: 0.3527511212502117
Validation loss: 2.424456091301843

Epoch: 6| Step: 4
Training loss: 0.3725973486585368
Validation loss: 2.4381340707200643

Epoch: 6| Step: 5
Training loss: 0.2458558067593772
Validation loss: 2.448570619329526

Epoch: 6| Step: 6
Training loss: 0.4065343521894756
Validation loss: 2.4768369473508836

Epoch: 6| Step: 7
Training loss: 0.40684875966202155
Validation loss: 2.4347051421551424

Epoch: 6| Step: 8
Training loss: 0.6027524746385593
Validation loss: 2.449854745215025

Epoch: 6| Step: 9
Training loss: 0.40428191078983017
Validation loss: 2.432899947293388

Epoch: 6| Step: 10
Training loss: 0.5965892267409876
Validation loss: 2.4667164620703175

Epoch: 6| Step: 11
Training loss: 0.671385253904652
Validation loss: 2.445348829581198

Epoch: 6| Step: 12
Training loss: 0.4768191100100022
Validation loss: 2.4107413531800734

Epoch: 6| Step: 13
Training loss: 0.4140143096519405
Validation loss: 2.448322231302429

Epoch: 339| Step: 0
Training loss: 0.6756639985254705
Validation loss: 2.4591222075747554

Epoch: 6| Step: 1
Training loss: 0.4655902222312102
Validation loss: 2.4395829002702456

Epoch: 6| Step: 2
Training loss: 0.3615819915555517
Validation loss: 2.413142345550013

Epoch: 6| Step: 3
Training loss: 0.6370833353583579
Validation loss: 2.4340436345078347

Epoch: 6| Step: 4
Training loss: 0.438042015428361
Validation loss: 2.432947449366687

Epoch: 6| Step: 5
Training loss: 0.36627221167069823
Validation loss: 2.388302703417248

Epoch: 6| Step: 6
Training loss: 0.40264351797642994
Validation loss: 2.398911382590386

Epoch: 6| Step: 7
Training loss: 0.3543338054012074
Validation loss: 2.4240034808318294

Epoch: 6| Step: 8
Training loss: 0.3806826450437264
Validation loss: 2.369882531076642

Epoch: 6| Step: 9
Training loss: 0.38701787612102023
Validation loss: 2.3878982943174707

Epoch: 6| Step: 10
Training loss: 0.4922949658494654
Validation loss: 2.3893713648313675

Epoch: 6| Step: 11
Training loss: 0.5336215993558856
Validation loss: 2.4232244790721706

Epoch: 6| Step: 12
Training loss: 0.3010024706305055
Validation loss: 2.393571231570804

Epoch: 6| Step: 13
Training loss: 0.14258304352310971
Validation loss: 2.4235792300051626

Epoch: 340| Step: 0
Training loss: 0.4964875287931985
Validation loss: 2.401059652701604

Epoch: 6| Step: 1
Training loss: 0.2935981094012339
Validation loss: 2.4057707323250037

Epoch: 6| Step: 2
Training loss: 0.26633540691022883
Validation loss: 2.391206882713042

Epoch: 6| Step: 3
Training loss: 0.6742741974168629
Validation loss: 2.435112101424221

Epoch: 6| Step: 4
Training loss: 0.3221075652943915
Validation loss: 2.396790259225207

Epoch: 6| Step: 5
Training loss: 0.32579245742438107
Validation loss: 2.4166637118480243

Epoch: 6| Step: 6
Training loss: 0.5023322844197984
Validation loss: 2.4425717774001554

Epoch: 6| Step: 7
Training loss: 0.43357000200001455
Validation loss: 2.4257704914373543

Epoch: 6| Step: 8
Training loss: 0.6463844014570163
Validation loss: 2.434666673107992

Epoch: 6| Step: 9
Training loss: 0.3056606987228799
Validation loss: 2.4358499220041567

Epoch: 6| Step: 10
Training loss: 0.5258366276455967
Validation loss: 2.3942406288345475

Epoch: 6| Step: 11
Training loss: 0.46308745050525024
Validation loss: 2.440704258955348

Epoch: 6| Step: 12
Training loss: 0.45357734201092925
Validation loss: 2.4178830976054995

Epoch: 6| Step: 13
Training loss: 0.2701478760029849
Validation loss: 2.3972251462529024

Epoch: 341| Step: 0
Training loss: 0.4318386676482911
Validation loss: 2.3837519936779876

Epoch: 6| Step: 1
Training loss: 0.39970629757483667
Validation loss: 2.4131960565890123

Epoch: 6| Step: 2
Training loss: 0.6181347012891573
Validation loss: 2.4005043530640635

Epoch: 6| Step: 3
Training loss: 0.6270225225050833
Validation loss: 2.3834960301402

Epoch: 6| Step: 4
Training loss: 0.43379725586334084
Validation loss: 2.395140762775617

Epoch: 6| Step: 5
Training loss: 0.42728302714248123
Validation loss: 2.4203451849852624

Epoch: 6| Step: 6
Training loss: 0.4226151966457438
Validation loss: 2.4160315754427146

Epoch: 6| Step: 7
Training loss: 0.4017866221675001
Validation loss: 2.4336327416494106

Epoch: 6| Step: 8
Training loss: 0.24834304309483712
Validation loss: 2.4519703503409485

Epoch: 6| Step: 9
Training loss: 0.3850355024812715
Validation loss: 2.4850601889050226

Epoch: 6| Step: 10
Training loss: 0.4085598714579665
Validation loss: 2.4850718451649936

Epoch: 6| Step: 11
Training loss: 0.5204490356467896
Validation loss: 2.4704551742594036

Epoch: 6| Step: 12
Training loss: 0.39332357961608777
Validation loss: 2.4771632738462412

Epoch: 6| Step: 13
Training loss: 0.21648289738140145
Validation loss: 2.484435350269782

Epoch: 342| Step: 0
Training loss: 0.4851243621371803
Validation loss: 2.4517718574536884

Epoch: 6| Step: 1
Training loss: 0.43659620937216914
Validation loss: 2.450871309349069

Epoch: 6| Step: 2
Training loss: 0.4164511500730285
Validation loss: 2.4481213817641794

Epoch: 6| Step: 3
Training loss: 0.4220188743248428
Validation loss: 2.442172734393045

Epoch: 6| Step: 4
Training loss: 0.44067340544365985
Validation loss: 2.4071393925640314

Epoch: 6| Step: 5
Training loss: 0.4959795963182248
Validation loss: 2.4351366858504937

Epoch: 6| Step: 6
Training loss: 0.332181066484854
Validation loss: 2.4110762654627838

Epoch: 6| Step: 7
Training loss: 0.30640815621444
Validation loss: 2.4172618010822764

Epoch: 6| Step: 8
Training loss: 0.6802609972893757
Validation loss: 2.3997924511135276

Epoch: 6| Step: 9
Training loss: 0.32617219479482357
Validation loss: 2.4266073904648713

Epoch: 6| Step: 10
Training loss: 0.379655726009883
Validation loss: 2.3977556332598784

Epoch: 6| Step: 11
Training loss: 0.28870792809023615
Validation loss: 2.471538154634904

Epoch: 6| Step: 12
Training loss: 0.6131186300057633
Validation loss: 2.431074485366377

Epoch: 6| Step: 13
Training loss: 0.43590477919749177
Validation loss: 2.451361275123402

Epoch: 343| Step: 0
Training loss: 0.49996875128849455
Validation loss: 2.4210320023427148

Epoch: 6| Step: 1
Training loss: 0.37577957343284635
Validation loss: 2.4247222296024686

Epoch: 6| Step: 2
Training loss: 0.30657307068996087
Validation loss: 2.453389657419762

Epoch: 6| Step: 3
Training loss: 0.4257291709477395
Validation loss: 2.4266851629250175

Epoch: 6| Step: 4
Training loss: 0.4563241036212928
Validation loss: 2.40336807333591

Epoch: 6| Step: 5
Training loss: 0.40654983826257435
Validation loss: 2.4132536290207045

Epoch: 6| Step: 6
Training loss: 0.19992383832962518
Validation loss: 2.4334554443815315

Epoch: 6| Step: 7
Training loss: 0.3860764226417783
Validation loss: 2.41619887870516

Epoch: 6| Step: 8
Training loss: 0.5611721897350067
Validation loss: 2.433060729849288

Epoch: 6| Step: 9
Training loss: 0.2043560576920334
Validation loss: 2.424097229974378

Epoch: 6| Step: 10
Training loss: 0.20894349669906426
Validation loss: 2.432084719648882

Epoch: 6| Step: 11
Training loss: 0.5325888424399752
Validation loss: 2.439721728584803

Epoch: 6| Step: 12
Training loss: 0.830718962189154
Validation loss: 2.4389169774541206

Epoch: 6| Step: 13
Training loss: 0.5032479473608447
Validation loss: 2.440218657517582

Epoch: 344| Step: 0
Training loss: 0.4206054446590391
Validation loss: 2.435436081758683

Epoch: 6| Step: 1
Training loss: 0.6103632811375022
Validation loss: 2.409444411625935

Epoch: 6| Step: 2
Training loss: 0.30532868483954584
Validation loss: 2.4077587306649963

Epoch: 6| Step: 3
Training loss: 0.3431240581714927
Validation loss: 2.4168862471860875

Epoch: 6| Step: 4
Training loss: 0.5967794731350592
Validation loss: 2.4098886818107514

Epoch: 6| Step: 5
Training loss: 0.22863067274006416
Validation loss: 2.4109140577141512

Epoch: 6| Step: 6
Training loss: 0.19651946025684006
Validation loss: 2.455064426889405

Epoch: 6| Step: 7
Training loss: 0.34871291194103393
Validation loss: 2.453838062131346

Epoch: 6| Step: 8
Training loss: 0.5778970526749968
Validation loss: 2.440205150195698

Epoch: 6| Step: 9
Training loss: 0.6325471109629586
Validation loss: 2.439345082966721

Epoch: 6| Step: 10
Training loss: 0.42628083973290093
Validation loss: 2.4407513079530587

Epoch: 6| Step: 11
Training loss: 0.27568290296867326
Validation loss: 2.467706775823653

Epoch: 6| Step: 12
Training loss: 0.44169349101618577
Validation loss: 2.4225617884166164

Epoch: 6| Step: 13
Training loss: 0.17668343132888525
Validation loss: 2.4571462653508176

Epoch: 345| Step: 0
Training loss: 0.3012669097934723
Validation loss: 2.4514356180298975

Epoch: 6| Step: 1
Training loss: 0.29763765001630055
Validation loss: 2.449647226189219

Epoch: 6| Step: 2
Training loss: 0.3734778665727906
Validation loss: 2.453764884851386

Epoch: 6| Step: 3
Training loss: 0.39330211703775547
Validation loss: 2.43739267706685

Epoch: 6| Step: 4
Training loss: 0.4464393880078691
Validation loss: 2.41958114912317

Epoch: 6| Step: 5
Training loss: 0.25709019248896436
Validation loss: 2.407093860593026

Epoch: 6| Step: 6
Training loss: 0.4807468787829426
Validation loss: 2.4041568520101557

Epoch: 6| Step: 7
Training loss: 0.5571634614543978
Validation loss: 2.3957827790550117

Epoch: 6| Step: 8
Training loss: 0.3930407971871586
Validation loss: 2.404051589479427

Epoch: 6| Step: 9
Training loss: 0.5832247178819343
Validation loss: 2.4099776606919394

Epoch: 6| Step: 10
Training loss: 0.26442690934891855
Validation loss: 2.3967432278321654

Epoch: 6| Step: 11
Training loss: 0.4702033400985261
Validation loss: 2.386276097461764

Epoch: 6| Step: 12
Training loss: 0.5526435157316099
Validation loss: 2.3892781045569635

Epoch: 6| Step: 13
Training loss: 0.4754665467721749
Validation loss: 2.4127294051649857

Epoch: 346| Step: 0
Training loss: 0.48009782134608403
Validation loss: 2.4107981861517853

Epoch: 6| Step: 1
Training loss: 0.787049549186165
Validation loss: 2.433414034180209

Epoch: 6| Step: 2
Training loss: 0.36515199272732973
Validation loss: 2.4122087743541276

Epoch: 6| Step: 3
Training loss: 0.21443327792799619
Validation loss: 2.411723488011164

Epoch: 6| Step: 4
Training loss: 0.5141731398230115
Validation loss: 2.3804282334134848

Epoch: 6| Step: 5
Training loss: 0.31004749188109226
Validation loss: 2.431551395061865

Epoch: 6| Step: 6
Training loss: 0.3230199482038505
Validation loss: 2.4106946046000552

Epoch: 6| Step: 7
Training loss: 0.25150383211860416
Validation loss: 2.410782703011085

Epoch: 6| Step: 8
Training loss: 0.43153744323052085
Validation loss: 2.3953628502531923

Epoch: 6| Step: 9
Training loss: 0.17956932992025315
Validation loss: 2.3868421270223124

Epoch: 6| Step: 10
Training loss: 0.40091481204817414
Validation loss: 2.4093310276195896

Epoch: 6| Step: 11
Training loss: 0.3272665806854493
Validation loss: 2.39281087286155

Epoch: 6| Step: 12
Training loss: 0.38420172096295935
Validation loss: 2.4081067753613112

Epoch: 6| Step: 13
Training loss: 0.5155811291151137
Validation loss: 2.400175054636607

Epoch: 347| Step: 0
Training loss: 0.40078535393887293
Validation loss: 2.3787502866302557

Epoch: 6| Step: 1
Training loss: 0.5544869234883956
Validation loss: 2.37816399511087

Epoch: 6| Step: 2
Training loss: 0.522077701514887
Validation loss: 2.4129354674423276

Epoch: 6| Step: 3
Training loss: 0.42136422779093746
Validation loss: 2.4169898571982222

Epoch: 6| Step: 4
Training loss: 0.4386248603281368
Validation loss: 2.435176421304875

Epoch: 6| Step: 5
Training loss: 0.23927005814335534
Validation loss: 2.4159277163498176

Epoch: 6| Step: 6
Training loss: 0.5489779502022584
Validation loss: 2.4147442587327634

Epoch: 6| Step: 7
Training loss: 0.23285418463684687
Validation loss: 2.4258339113132408

Epoch: 6| Step: 8
Training loss: 0.5815834268354056
Validation loss: 2.4324307807829118

Epoch: 6| Step: 9
Training loss: 0.20565429765753915
Validation loss: 2.383328502669352

Epoch: 6| Step: 10
Training loss: 0.4604225515044174
Validation loss: 2.38332843705436

Epoch: 6| Step: 11
Training loss: 0.43903838189834254
Validation loss: 2.3797123643738556

Epoch: 6| Step: 12
Training loss: 0.18555590958935864
Validation loss: 2.390656880351069

Epoch: 6| Step: 13
Training loss: 0.45229824871695784
Validation loss: 2.4172362723126706

Epoch: 348| Step: 0
Training loss: 0.38536977053053517
Validation loss: 2.3744332598569193

Epoch: 6| Step: 1
Training loss: 0.3081165438685239
Validation loss: 2.422964115154538

Epoch: 6| Step: 2
Training loss: 0.4146824819610482
Validation loss: 2.405676192005251

Epoch: 6| Step: 3
Training loss: 0.28249641901464145
Validation loss: 2.3643879558781884

Epoch: 6| Step: 4
Training loss: 0.3076771147953392
Validation loss: 2.373140674828499

Epoch: 6| Step: 5
Training loss: 0.4229787058340259
Validation loss: 2.4041578287743564

Epoch: 6| Step: 6
Training loss: 0.555904504012314
Validation loss: 2.4002605603146483

Epoch: 6| Step: 7
Training loss: 0.45041308648906514
Validation loss: 2.4114453887184495

Epoch: 6| Step: 8
Training loss: 0.3638796646018368
Validation loss: 2.402414410266693

Epoch: 6| Step: 9
Training loss: 0.3366163514071307
Validation loss: 2.392108160911572

Epoch: 6| Step: 10
Training loss: 0.6636619257279411
Validation loss: 2.3998125826899535

Epoch: 6| Step: 11
Training loss: 0.4901454434527525
Validation loss: 2.402964829820729

Epoch: 6| Step: 12
Training loss: 0.4331980609511817
Validation loss: 2.406193596581437

Epoch: 6| Step: 13
Training loss: 0.2767653949482251
Validation loss: 2.395947525777108

Epoch: 349| Step: 0
Training loss: 0.500903326857187
Validation loss: 2.421251977022099

Epoch: 6| Step: 1
Training loss: 0.6314688180547845
Validation loss: 2.411719291318597

Epoch: 6| Step: 2
Training loss: 0.43869974620186547
Validation loss: 2.401151159230272

Epoch: 6| Step: 3
Training loss: 0.31665686113250946
Validation loss: 2.3906988445782718

Epoch: 6| Step: 4
Training loss: 0.4110667522211065
Validation loss: 2.41353300543782

Epoch: 6| Step: 5
Training loss: 0.4326917872466519
Validation loss: 2.4289921873315694

Epoch: 6| Step: 6
Training loss: 0.5909151111559536
Validation loss: 2.393479772643931

Epoch: 6| Step: 7
Training loss: 0.15120383646794586
Validation loss: 2.4129542569245697

Epoch: 6| Step: 8
Training loss: 0.3982220609554665
Validation loss: 2.4301147254151534

Epoch: 6| Step: 9
Training loss: 0.40253403247279956
Validation loss: 2.4221209662816743

Epoch: 6| Step: 10
Training loss: 0.34745380851032326
Validation loss: 2.4522769115923846

Epoch: 6| Step: 11
Training loss: 0.28686815625589746
Validation loss: 2.4271215321144144

Epoch: 6| Step: 12
Training loss: 0.3988420639068202
Validation loss: 2.447678527210103

Epoch: 6| Step: 13
Training loss: 0.34558271477077207
Validation loss: 2.412150486693775

Epoch: 350| Step: 0
Training loss: 0.4831972878919997
Validation loss: 2.421491816888866

Epoch: 6| Step: 1
Training loss: 0.43216023304639045
Validation loss: 2.4021012426670536

Epoch: 6| Step: 2
Training loss: 0.38808680833278225
Validation loss: 2.3947506133159657

Epoch: 6| Step: 3
Training loss: 0.2648043577893032
Validation loss: 2.404628772705179

Epoch: 6| Step: 4
Training loss: 0.4497537329796096
Validation loss: 2.408040610598559

Epoch: 6| Step: 5
Training loss: 0.24160198220884954
Validation loss: 2.4309075718138

Epoch: 6| Step: 6
Training loss: 0.6270953340955693
Validation loss: 2.4031602369895295

Epoch: 6| Step: 7
Training loss: 0.37931999741073047
Validation loss: 2.4320845488859995

Epoch: 6| Step: 8
Training loss: 0.4965529831873983
Validation loss: 2.453240359417973

Epoch: 6| Step: 9
Training loss: 0.3875289867695864
Validation loss: 2.3930995122767142

Epoch: 6| Step: 10
Training loss: 0.4201376427175713
Validation loss: 2.4146782548757644

Epoch: 6| Step: 11
Training loss: 0.5000078677512089
Validation loss: 2.4505604127917584

Epoch: 6| Step: 12
Training loss: 0.4469160687975299
Validation loss: 2.447337165544168

Epoch: 6| Step: 13
Training loss: 0.18322393018610864
Validation loss: 2.4314136559814292

Testing loss: 2.569796434183367
