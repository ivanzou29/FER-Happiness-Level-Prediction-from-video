Epoch: 1| Step: 0
Training loss: 5.670041967704238
Validation loss: 5.7822360443100065

Epoch: 6| Step: 1
Training loss: 5.150698360758046
Validation loss: 5.776019716645995

Epoch: 6| Step: 2
Training loss: 5.858580024195483
Validation loss: 5.769869360666251

Epoch: 6| Step: 3
Training loss: 5.615965645318224
Validation loss: 5.763414743353881

Epoch: 6| Step: 4
Training loss: 6.601094426823171
Validation loss: 5.758037887812241

Epoch: 6| Step: 5
Training loss: 6.771835612916145
Validation loss: 5.752329708845877

Epoch: 6| Step: 6
Training loss: 5.527143602825062
Validation loss: 5.747093432667258

Epoch: 6| Step: 7
Training loss: 6.030441625311455
Validation loss: 5.7412282656367735

Epoch: 6| Step: 8
Training loss: 5.880383561268492
Validation loss: 5.735482710335704

Epoch: 6| Step: 9
Training loss: 3.6976158915238884
Validation loss: 5.7298249410379976

Epoch: 6| Step: 10
Training loss: 6.6148647298555625
Validation loss: 5.724326761656694

Epoch: 6| Step: 11
Training loss: 4.945111938073609
Validation loss: 5.71842937264392

Epoch: 6| Step: 12
Training loss: 6.482117629949788
Validation loss: 5.712568257837915

Epoch: 6| Step: 13
Training loss: 4.962758224264495
Validation loss: 5.706166122390266

Epoch: 2| Step: 0
Training loss: 6.0899352041721775
Validation loss: 5.700490060380855

Epoch: 6| Step: 1
Training loss: 5.1032590513265434
Validation loss: 5.6936858698965045

Epoch: 6| Step: 2
Training loss: 6.117119526881288
Validation loss: 5.687817694152372

Epoch: 6| Step: 3
Training loss: 5.660254646746525
Validation loss: 5.681012773573755

Epoch: 6| Step: 4
Training loss: 5.283084708700651
Validation loss: 5.6739827556809646

Epoch: 6| Step: 5
Training loss: 5.2747983631809845
Validation loss: 5.666766908954557

Epoch: 6| Step: 6
Training loss: 6.001966154293537
Validation loss: 5.6594801156215055

Epoch: 6| Step: 7
Training loss: 5.792581865557832
Validation loss: 5.651582857244914

Epoch: 6| Step: 8
Training loss: 6.019827823648048
Validation loss: 5.643626239341629

Epoch: 6| Step: 9
Training loss: 5.9493469905744965
Validation loss: 5.634676155652094

Epoch: 6| Step: 10
Training loss: 5.324267828666863
Validation loss: 5.626154886092852

Epoch: 6| Step: 11
Training loss: 6.240037225465511
Validation loss: 5.6165404957410825

Epoch: 6| Step: 12
Training loss: 5.643182148463949
Validation loss: 5.606559210071351

Epoch: 6| Step: 13
Training loss: 4.349824458997936
Validation loss: 5.596065516563836

Epoch: 3| Step: 0
Training loss: 5.412505659492476
Validation loss: 5.586210220762103

Epoch: 6| Step: 1
Training loss: 4.418616722071769
Validation loss: 5.574114846095909

Epoch: 6| Step: 2
Training loss: 6.793652140904853
Validation loss: 5.563332576829934

Epoch: 6| Step: 3
Training loss: 5.569221464636504
Validation loss: 5.5515614353771605

Epoch: 6| Step: 4
Training loss: 5.556674092331112
Validation loss: 5.540030310082059

Epoch: 6| Step: 5
Training loss: 5.7242531901516145
Validation loss: 5.5263270634310455

Epoch: 6| Step: 6
Training loss: 6.210642067462648
Validation loss: 5.513199406348135

Epoch: 6| Step: 7
Training loss: 5.515045913685008
Validation loss: 5.499669185321317

Epoch: 6| Step: 8
Training loss: 4.818585400175976
Validation loss: 5.484905097518741

Epoch: 6| Step: 9
Training loss: 4.0166384831834
Validation loss: 5.470076677746637

Epoch: 6| Step: 10
Training loss: 5.7601778924810425
Validation loss: 5.45495759151822

Epoch: 6| Step: 11
Training loss: 5.204584506964674
Validation loss: 5.438750937253078

Epoch: 6| Step: 12
Training loss: 6.315994353066566
Validation loss: 5.422879792083032

Epoch: 6| Step: 13
Training loss: 5.8253438823520325
Validation loss: 5.406345768467411

Epoch: 4| Step: 0
Training loss: 6.261622494191552
Validation loss: 5.3879347337324655

Epoch: 6| Step: 1
Training loss: 5.670210160493186
Validation loss: 5.369668990222105

Epoch: 6| Step: 2
Training loss: 5.021429868006873
Validation loss: 5.350951496547188

Epoch: 6| Step: 3
Training loss: 4.924034783135902
Validation loss: 5.331451527538606

Epoch: 6| Step: 4
Training loss: 4.33243761831059
Validation loss: 5.31170875404272

Epoch: 6| Step: 5
Training loss: 5.441346660432866
Validation loss: 5.29205858702412

Epoch: 6| Step: 6
Training loss: 6.14270326035098
Validation loss: 5.2724389548933726

Epoch: 6| Step: 7
Training loss: 5.570460078142355
Validation loss: 5.252832639818073

Epoch: 6| Step: 8
Training loss: 5.371446011175814
Validation loss: 5.231919394303536

Epoch: 6| Step: 9
Training loss: 5.194573050055537
Validation loss: 5.211450565207208

Epoch: 6| Step: 10
Training loss: 5.950961944012247
Validation loss: 5.190223788253851

Epoch: 6| Step: 11
Training loss: 4.425564901210264
Validation loss: 5.169302431134341

Epoch: 6| Step: 12
Training loss: 4.576520306570821
Validation loss: 5.148177267170783

Epoch: 6| Step: 13
Training loss: 4.951367183647834
Validation loss: 5.127917514025055

Epoch: 5| Step: 0
Training loss: 5.205281861631818
Validation loss: 5.106271779369162

Epoch: 6| Step: 1
Training loss: 4.495722114853672
Validation loss: 5.085692024736939

Epoch: 6| Step: 2
Training loss: 4.233022551255024
Validation loss: 5.065299587421991

Epoch: 6| Step: 3
Training loss: 4.859211320972286
Validation loss: 5.046197937571119

Epoch: 6| Step: 4
Training loss: 5.07960089730275
Validation loss: 5.025439379632743

Epoch: 6| Step: 5
Training loss: 4.571751868362282
Validation loss: 5.004949333046984

Epoch: 6| Step: 6
Training loss: 6.029963380819442
Validation loss: 4.985110642876299

Epoch: 6| Step: 7
Training loss: 4.9841362109728955
Validation loss: 4.9634058254477935

Epoch: 6| Step: 8
Training loss: 4.975399150842581
Validation loss: 4.940516204683237

Epoch: 6| Step: 9
Training loss: 5.631708679825239
Validation loss: 4.920916324452703

Epoch: 6| Step: 10
Training loss: 5.82554655335134
Validation loss: 4.898727369425312

Epoch: 6| Step: 11
Training loss: 3.7820121060182186
Validation loss: 4.876118567668031

Epoch: 6| Step: 12
Training loss: 4.8300980668942355
Validation loss: 4.856229112723027

Epoch: 6| Step: 13
Training loss: 5.870609672117818
Validation loss: 4.83633264161843

Epoch: 6| Step: 0
Training loss: 4.665972294692071
Validation loss: 4.814801185202277

Epoch: 6| Step: 1
Training loss: 5.242069612590259
Validation loss: 4.794802976405232

Epoch: 6| Step: 2
Training loss: 4.153281392180385
Validation loss: 4.775331734978376

Epoch: 6| Step: 3
Training loss: 4.179654643562447
Validation loss: 4.754950602707797

Epoch: 6| Step: 4
Training loss: 4.733256494319279
Validation loss: 4.735347152388931

Epoch: 6| Step: 5
Training loss: 3.937997695712941
Validation loss: 4.716945927836639

Epoch: 6| Step: 6
Training loss: 4.234279054350035
Validation loss: 4.696536476839511

Epoch: 6| Step: 7
Training loss: 5.782880563446213
Validation loss: 4.676614946142174

Epoch: 6| Step: 8
Training loss: 4.805648087411214
Validation loss: 4.658673049297978

Epoch: 6| Step: 9
Training loss: 4.976331959988298
Validation loss: 4.63807213290076

Epoch: 6| Step: 10
Training loss: 5.460934007286079
Validation loss: 4.620352638706678

Epoch: 6| Step: 11
Training loss: 4.78693007620159
Validation loss: 4.597331742578436

Epoch: 6| Step: 12
Training loss: 5.143761509897511
Validation loss: 4.5785416615040075

Epoch: 6| Step: 13
Training loss: 3.922010077471822
Validation loss: 4.556812566322353

Epoch: 7| Step: 0
Training loss: 5.101570538314398
Validation loss: 4.535000686342454

Epoch: 6| Step: 1
Training loss: 4.421144458825753
Validation loss: 4.5142049605041175

Epoch: 6| Step: 2
Training loss: 4.991064097484154
Validation loss: 4.492895641465987

Epoch: 6| Step: 3
Training loss: 5.606041728119928
Validation loss: 4.475320577444588

Epoch: 6| Step: 4
Training loss: 4.523856188119933
Validation loss: 4.456372617775332

Epoch: 6| Step: 5
Training loss: 4.6558378920502355
Validation loss: 4.4363259717006205

Epoch: 6| Step: 6
Training loss: 3.9147795060427883
Validation loss: 4.416384233827088

Epoch: 6| Step: 7
Training loss: 4.2317514773195155
Validation loss: 4.394678471622965

Epoch: 6| Step: 8
Training loss: 2.8622931926266113
Validation loss: 4.376104683586616

Epoch: 6| Step: 9
Training loss: 4.720786154304477
Validation loss: 4.356513909995122

Epoch: 6| Step: 10
Training loss: 4.276801032207577
Validation loss: 4.338164099551184

Epoch: 6| Step: 11
Training loss: 5.310447026920843
Validation loss: 4.31929295527913

Epoch: 6| Step: 12
Training loss: 3.8923266263068075
Validation loss: 4.300962528217573

Epoch: 6| Step: 13
Training loss: 3.7371759484702105
Validation loss: 4.284667153526808

Epoch: 8| Step: 0
Training loss: 3.7243654824365904
Validation loss: 4.268333813325955

Epoch: 6| Step: 1
Training loss: 5.224696260959781
Validation loss: 4.2537044616386765

Epoch: 6| Step: 2
Training loss: 4.962015830762366
Validation loss: 4.2366170433903

Epoch: 6| Step: 3
Training loss: 4.193117842805321
Validation loss: 4.224332998757594

Epoch: 6| Step: 4
Training loss: 3.584915713672122
Validation loss: 4.208988184232787

Epoch: 6| Step: 5
Training loss: 4.788962931010204
Validation loss: 4.196229482920711

Epoch: 6| Step: 6
Training loss: 4.815942499089977
Validation loss: 4.181492215156996

Epoch: 6| Step: 7
Training loss: 3.828207957089025
Validation loss: 4.167350210091428

Epoch: 6| Step: 8
Training loss: 3.823413300369435
Validation loss: 4.156162623423713

Epoch: 6| Step: 9
Training loss: 4.7395881177717385
Validation loss: 4.14277779138298

Epoch: 6| Step: 10
Training loss: 3.5088061855969612
Validation loss: 4.131136553653518

Epoch: 6| Step: 11
Training loss: 2.9567561355466525
Validation loss: 4.11887529275247

Epoch: 6| Step: 12
Training loss: 4.770758593555473
Validation loss: 4.110375042374713

Epoch: 6| Step: 13
Training loss: 4.962656759481433
Validation loss: 4.0985116539201725

Epoch: 9| Step: 0
Training loss: 4.165677042104465
Validation loss: 4.086093566520317

Epoch: 6| Step: 1
Training loss: 4.958595504027183
Validation loss: 4.076010716435527

Epoch: 6| Step: 2
Training loss: 5.12753865704037
Validation loss: 4.0641329175789425

Epoch: 6| Step: 3
Training loss: 2.438552531386958
Validation loss: 4.052809827319392

Epoch: 6| Step: 4
Training loss: 2.9621291367058884
Validation loss: 4.042502442541949

Epoch: 6| Step: 5
Training loss: 3.644407084190828
Validation loss: 4.033267176048331

Epoch: 6| Step: 6
Training loss: 5.381061418620567
Validation loss: 4.023451013220796

Epoch: 6| Step: 7
Training loss: 4.3731607113086515
Validation loss: 4.012698968183747

Epoch: 6| Step: 8
Training loss: 3.488407282245192
Validation loss: 3.999916666711268

Epoch: 6| Step: 9
Training loss: 3.9628684850293316
Validation loss: 3.9906760315419403

Epoch: 6| Step: 10
Training loss: 4.2765419125714725
Validation loss: 3.98081030602878

Epoch: 6| Step: 11
Training loss: 4.3182451982729315
Validation loss: 3.97265166305187

Epoch: 6| Step: 12
Training loss: 4.071621558030216
Validation loss: 3.963443993517378

Epoch: 6| Step: 13
Training loss: 4.202733585326746
Validation loss: 3.9527094208041547

Epoch: 10| Step: 0
Training loss: 4.4559424338329165
Validation loss: 3.945627816862903

Epoch: 6| Step: 1
Training loss: 3.968054522755029
Validation loss: 3.9375028100746756

Epoch: 6| Step: 2
Training loss: 4.144216915654168
Validation loss: 3.925233434556163

Epoch: 6| Step: 3
Training loss: 3.7202381394159225
Validation loss: 3.9153170873217897

Epoch: 6| Step: 4
Training loss: 4.1086675811012245
Validation loss: 3.908415071723438

Epoch: 6| Step: 5
Training loss: 3.880919948924917
Validation loss: 3.902843531327877

Epoch: 6| Step: 6
Training loss: 3.681732063271005
Validation loss: 3.8937595927018362

Epoch: 6| Step: 7
Training loss: 4.460402795709776
Validation loss: 3.8866466284462793

Epoch: 6| Step: 8
Training loss: 4.380344505174084
Validation loss: 3.879626293455427

Epoch: 6| Step: 9
Training loss: 3.3412252145654957
Validation loss: 3.870898857495069

Epoch: 6| Step: 10
Training loss: 4.477059275173601
Validation loss: 3.8625582339008733

Epoch: 6| Step: 11
Training loss: 3.955008559380491
Validation loss: 3.855256735921243

Epoch: 6| Step: 12
Training loss: 4.3107265198179885
Validation loss: 3.8480040623781537

Epoch: 6| Step: 13
Training loss: 3.3471814667967257
Validation loss: 3.842008470793733

Epoch: 11| Step: 0
Training loss: 4.933615013191511
Validation loss: 3.8377267108185347

Epoch: 6| Step: 1
Training loss: 4.270249092644646
Validation loss: 3.832602029001028

Epoch: 6| Step: 2
Training loss: 4.337674509545044
Validation loss: 3.8233412438974614

Epoch: 6| Step: 3
Training loss: 4.23754966504185
Validation loss: 3.8170792291964437

Epoch: 6| Step: 4
Training loss: 4.669344723980784
Validation loss: 3.81153438610966

Epoch: 6| Step: 5
Training loss: 4.226692465654291
Validation loss: 3.8067490702368207

Epoch: 6| Step: 6
Training loss: 3.402597411342805
Validation loss: 3.8040405324409448

Epoch: 6| Step: 7
Training loss: 3.289543642203642
Validation loss: 3.7983550308177216

Epoch: 6| Step: 8
Training loss: 3.054823772385974
Validation loss: 3.79340142384363

Epoch: 6| Step: 9
Training loss: 3.5290316475205574
Validation loss: 3.786340501808719

Epoch: 6| Step: 10
Training loss: 3.441925252170407
Validation loss: 3.7838861803015593

Epoch: 6| Step: 11
Training loss: 3.9782706378609296
Validation loss: 3.7770746362597105

Epoch: 6| Step: 12
Training loss: 3.874686813003697
Validation loss: 3.772911375983641

Epoch: 6| Step: 13
Training loss: 3.957576853427012
Validation loss: 3.768028063361901

Epoch: 12| Step: 0
Training loss: 4.194830101310114
Validation loss: 3.7624860208998645

Epoch: 6| Step: 1
Training loss: 3.5313817902674884
Validation loss: 3.7578497870246754

Epoch: 6| Step: 2
Training loss: 4.398440752316182
Validation loss: 3.7537571820240205

Epoch: 6| Step: 3
Training loss: 2.59864363870584
Validation loss: 3.749992165506034

Epoch: 6| Step: 4
Training loss: 4.102019598785257
Validation loss: 3.7493607827387545

Epoch: 6| Step: 5
Training loss: 4.339137200937483
Validation loss: 3.740350971767651

Epoch: 6| Step: 6
Training loss: 3.862396169705139
Validation loss: 3.737339413365681

Epoch: 6| Step: 7
Training loss: 4.439956200186024
Validation loss: 3.732733027549406

Epoch: 6| Step: 8
Training loss: 4.030132286607797
Validation loss: 3.7276945156970935

Epoch: 6| Step: 9
Training loss: 3.848813327368666
Validation loss: 3.725012464461856

Epoch: 6| Step: 10
Training loss: 4.3100280311186285
Validation loss: 3.7213666724757677

Epoch: 6| Step: 11
Training loss: 3.618683408872274
Validation loss: 3.71556375470089

Epoch: 6| Step: 12
Training loss: 3.5204887146239967
Validation loss: 3.7092244671136694

Epoch: 6| Step: 13
Training loss: 3.417055821160128
Validation loss: 3.7054643823554683

Epoch: 13| Step: 0
Training loss: 3.856403519651993
Validation loss: 3.702281834626086

Epoch: 6| Step: 1
Training loss: 3.746152429847046
Validation loss: 3.703494681632264

Epoch: 6| Step: 2
Training loss: 3.91495660555627
Validation loss: 3.6982816833473464

Epoch: 6| Step: 3
Training loss: 3.711014724731015
Validation loss: 3.6890182484193454

Epoch: 6| Step: 4
Training loss: 3.8979164035184692
Validation loss: 3.685325121625017

Epoch: 6| Step: 5
Training loss: 4.059641845014168
Validation loss: 3.681809261373778

Epoch: 6| Step: 6
Training loss: 4.530052500372146
Validation loss: 3.6783394647882974

Epoch: 6| Step: 7
Training loss: 3.631480639383378
Validation loss: 3.6752704589203953

Epoch: 6| Step: 8
Training loss: 3.166405683772001
Validation loss: 3.6692355382547768

Epoch: 6| Step: 9
Training loss: 3.547148168858462
Validation loss: 3.665756195514982

Epoch: 6| Step: 10
Training loss: 3.9552919984611528
Validation loss: 3.6624342261832683

Epoch: 6| Step: 11
Training loss: 3.6313015328458653
Validation loss: 3.659254933135387

Epoch: 6| Step: 12
Training loss: 4.488005653731377
Validation loss: 3.6598736539026473

Epoch: 6| Step: 13
Training loss: 3.6567731955724874
Validation loss: 3.6512101556862318

Epoch: 14| Step: 0
Training loss: 3.421434487332885
Validation loss: 3.641812432923756

Epoch: 6| Step: 1
Training loss: 4.4506936379223605
Validation loss: 3.6384831398300297

Epoch: 6| Step: 2
Training loss: 3.5286923488727613
Validation loss: 3.634017705253434

Epoch: 6| Step: 3
Training loss: 4.132440503402337
Validation loss: 3.631025680315484

Epoch: 6| Step: 4
Training loss: 3.7751429398108116
Validation loss: 3.626248779305719

Epoch: 6| Step: 5
Training loss: 3.997734739700876
Validation loss: 3.622166055903636

Epoch: 6| Step: 6
Training loss: 2.24205181495486
Validation loss: 3.6172992025760564

Epoch: 6| Step: 7
Training loss: 3.601236258271682
Validation loss: 3.611021059573619

Epoch: 6| Step: 8
Training loss: 4.149703297866867
Validation loss: 3.6091463502836256

Epoch: 6| Step: 9
Training loss: 3.504213793812264
Validation loss: 3.6063645718634576

Epoch: 6| Step: 10
Training loss: 3.1238309580923755
Validation loss: 3.5998543120772073

Epoch: 6| Step: 11
Training loss: 4.619433790908144
Validation loss: 3.5960378732383367

Epoch: 6| Step: 12
Training loss: 4.354129602496567
Validation loss: 3.5892695164132964

Epoch: 6| Step: 13
Training loss: 3.765154417399801
Validation loss: 3.585336946818351

Epoch: 15| Step: 0
Training loss: 4.222610176957254
Validation loss: 3.586198500261808

Epoch: 6| Step: 1
Training loss: 3.935970433162884
Validation loss: 3.5775151811162695

Epoch: 6| Step: 2
Training loss: 4.357626725070521
Validation loss: 3.5735950560802463

Epoch: 6| Step: 3
Training loss: 3.7777398581253507
Validation loss: 3.5699730243619063

Epoch: 6| Step: 4
Training loss: 3.36727161700689
Validation loss: 3.567937517031793

Epoch: 6| Step: 5
Training loss: 3.222558296333303
Validation loss: 3.5612725008921666

Epoch: 6| Step: 6
Training loss: 3.8284027621647367
Validation loss: 3.561789251215112

Epoch: 6| Step: 7
Training loss: 3.059409937595772
Validation loss: 3.5566259234521116

Epoch: 6| Step: 8
Training loss: 3.359650214698624
Validation loss: 3.5555957281648687

Epoch: 6| Step: 9
Training loss: 3.1963828982464144
Validation loss: 3.5459852932757228

Epoch: 6| Step: 10
Training loss: 3.6215087916135693
Validation loss: 3.5434582304274125

Epoch: 6| Step: 11
Training loss: 4.4243648784471565
Validation loss: 3.53752463161987

Epoch: 6| Step: 12
Training loss: 2.9184942423410956
Validation loss: 3.534545014534118

Epoch: 6| Step: 13
Training loss: 5.444531509239573
Validation loss: 3.528975003392888

Epoch: 16| Step: 0
Training loss: 3.769683297208783
Validation loss: 3.5277292361666523

Epoch: 6| Step: 1
Training loss: 3.963952356115696
Validation loss: 3.523155556734649

Epoch: 6| Step: 2
Training loss: 3.769543899752091
Validation loss: 3.5185367083683494

Epoch: 6| Step: 3
Training loss: 3.7658457078003735
Validation loss: 3.516848328383151

Epoch: 6| Step: 4
Training loss: 3.3861824147748405
Validation loss: 3.5113939076655734

Epoch: 6| Step: 5
Training loss: 3.9494631245484455
Validation loss: 3.5099626750683446

Epoch: 6| Step: 6
Training loss: 3.9361005445679664
Validation loss: 3.5077557573238147

Epoch: 6| Step: 7
Training loss: 3.929421387415757
Validation loss: 3.5027469733831733

Epoch: 6| Step: 8
Training loss: 3.5441911264725547
Validation loss: 3.4984639015398376

Epoch: 6| Step: 9
Training loss: 3.965579471071263
Validation loss: 3.498322426171602

Epoch: 6| Step: 10
Training loss: 3.587015492754899
Validation loss: 3.494950914835875

Epoch: 6| Step: 11
Training loss: 4.14442770178728
Validation loss: 3.48655359096321

Epoch: 6| Step: 12
Training loss: 2.7137066772039167
Validation loss: 3.492086925839923

Epoch: 6| Step: 13
Training loss: 3.0512182335487306
Validation loss: 3.492837256728649

Epoch: 17| Step: 0
Training loss: 3.286437665790716
Validation loss: 3.4922231906504893

Epoch: 6| Step: 1
Training loss: 3.5161330470581253
Validation loss: 3.4808710079717344

Epoch: 6| Step: 2
Training loss: 2.8448221051154357
Validation loss: 3.479896793506455

Epoch: 6| Step: 3
Training loss: 2.727778734602785
Validation loss: 3.474359058648392

Epoch: 6| Step: 4
Training loss: 2.938847009768656
Validation loss: 3.4740596901032794

Epoch: 6| Step: 5
Training loss: 4.314314750638637
Validation loss: 3.469976647103891

Epoch: 6| Step: 6
Training loss: 4.22363518334471
Validation loss: 3.46898074104618

Epoch: 6| Step: 7
Training loss: 3.4779305156064746
Validation loss: 3.466270985120585

Epoch: 6| Step: 8
Training loss: 3.6076480317492012
Validation loss: 3.46774778749545

Epoch: 6| Step: 9
Training loss: 4.421926760960303
Validation loss: 3.464995429301999

Epoch: 6| Step: 10
Training loss: 3.783757158870623
Validation loss: 3.4555627246325935

Epoch: 6| Step: 11
Training loss: 3.8753052868101894
Validation loss: 3.4530758668396624

Epoch: 6| Step: 12
Training loss: 4.3824630298785126
Validation loss: 3.4506115529940558

Epoch: 6| Step: 13
Training loss: 3.511215903801404
Validation loss: 3.44650525679001

Epoch: 18| Step: 0
Training loss: 3.341937563246169
Validation loss: 3.443695945889479

Epoch: 6| Step: 1
Training loss: 4.343134774748633
Validation loss: 3.441418271818207

Epoch: 6| Step: 2
Training loss: 2.884926948349724
Validation loss: 3.443511558418963

Epoch: 6| Step: 3
Training loss: 3.7091556166038107
Validation loss: 3.4462489966538796

Epoch: 6| Step: 4
Training loss: 2.967681371196589
Validation loss: 3.4352871377147673

Epoch: 6| Step: 5
Training loss: 3.7659549805983548
Validation loss: 3.433317667691119

Epoch: 6| Step: 6
Training loss: 3.513253187559915
Validation loss: 3.432412168825649

Epoch: 6| Step: 7
Training loss: 3.4177273910318213
Validation loss: 3.431022493915555

Epoch: 6| Step: 8
Training loss: 3.075448823753908
Validation loss: 3.4299021007709305

Epoch: 6| Step: 9
Training loss: 2.8395917064368845
Validation loss: 3.4297664125993466

Epoch: 6| Step: 10
Training loss: 3.4504718513131074
Validation loss: 3.4289485522071836

Epoch: 6| Step: 11
Training loss: 4.462207833778146
Validation loss: 3.4242484974625174

Epoch: 6| Step: 12
Training loss: 3.9814447136757583
Validation loss: 3.4229657482885663

Epoch: 6| Step: 13
Training loss: 5.447724299441429
Validation loss: 3.4185702730703036

Epoch: 19| Step: 0
Training loss: 3.9043750382996336
Validation loss: 3.4150825933185307

Epoch: 6| Step: 1
Training loss: 3.686753278224225
Validation loss: 3.4118436802217307

Epoch: 6| Step: 2
Training loss: 3.9234156527076167
Validation loss: 3.410592678056219

Epoch: 6| Step: 3
Training loss: 3.4662056604157017
Validation loss: 3.412223736942564

Epoch: 6| Step: 4
Training loss: 4.32806462545323
Validation loss: 3.4149126857597096

Epoch: 6| Step: 5
Training loss: 4.013553782858217
Validation loss: 3.4013085921599484

Epoch: 6| Step: 6
Training loss: 4.169944973955343
Validation loss: 3.402452810269349

Epoch: 6| Step: 7
Training loss: 2.904765580611989
Validation loss: 3.4041321797530015

Epoch: 6| Step: 8
Training loss: 3.926359249855181
Validation loss: 3.40431833413708

Epoch: 6| Step: 9
Training loss: 3.2304325862829955
Validation loss: 3.4054966560419246

Epoch: 6| Step: 10
Training loss: 3.5367055964746705
Validation loss: 3.4064853357741494

Epoch: 6| Step: 11
Training loss: 3.6242519790760843
Validation loss: 3.4029142452151073

Epoch: 6| Step: 12
Training loss: 2.493574659259038
Validation loss: 3.401110747984916

Epoch: 6| Step: 13
Training loss: 2.7652245355531524
Validation loss: 3.398292842620289

Epoch: 20| Step: 0
Training loss: 3.868662789737648
Validation loss: 3.3947499490551336

Epoch: 6| Step: 1
Training loss: 3.993003925966415
Validation loss: 3.3938434965726914

Epoch: 6| Step: 2
Training loss: 4.181069061971658
Validation loss: 3.387441761273164

Epoch: 6| Step: 3
Training loss: 4.498754964890938
Validation loss: 3.3856289724918485

Epoch: 6| Step: 4
Training loss: 2.965919510555002
Validation loss: 3.381745455549332

Epoch: 6| Step: 5
Training loss: 2.530167053648129
Validation loss: 3.3819769476999655

Epoch: 6| Step: 6
Training loss: 4.2226119837527145
Validation loss: 3.3803368367075373

Epoch: 6| Step: 7
Training loss: 2.8768593124767468
Validation loss: 3.3817922455678984

Epoch: 6| Step: 8
Training loss: 3.7275604255429875
Validation loss: 3.3896776318745316

Epoch: 6| Step: 9
Training loss: 3.136378971760969
Validation loss: 3.3778728888297156

Epoch: 6| Step: 10
Training loss: 3.6137197527416234
Validation loss: 3.3736454817957022

Epoch: 6| Step: 11
Training loss: 3.456407600658824
Validation loss: 3.369219697176263

Epoch: 6| Step: 12
Training loss: 3.467684332933656
Validation loss: 3.3660134706372236

Epoch: 6| Step: 13
Training loss: 3.321931332158106
Validation loss: 3.366511180271773

Epoch: 21| Step: 0
Training loss: 3.2436152612121796
Validation loss: 3.362891981524574

Epoch: 6| Step: 1
Training loss: 2.043650176150622
Validation loss: 3.361543462724063

Epoch: 6| Step: 2
Training loss: 4.026566971645751
Validation loss: 3.362096483805183

Epoch: 6| Step: 3
Training loss: 3.2925231559709616
Validation loss: 3.3582039709653997

Epoch: 6| Step: 4
Training loss: 4.236061801866611
Validation loss: 3.3580802534383065

Epoch: 6| Step: 5
Training loss: 3.6868174292956257
Validation loss: 3.3587445609286064

Epoch: 6| Step: 6
Training loss: 4.051086120021525
Validation loss: 3.356911913037881

Epoch: 6| Step: 7
Training loss: 4.2759654154079225
Validation loss: 3.3503164900105866

Epoch: 6| Step: 8
Training loss: 4.204757656956623
Validation loss: 3.3518962759402107

Epoch: 6| Step: 9
Training loss: 3.7482315980078775
Validation loss: 3.355729262599586

Epoch: 6| Step: 10
Training loss: 3.280036338511817
Validation loss: 3.3610022100736248

Epoch: 6| Step: 11
Training loss: 2.8469183741593254
Validation loss: 3.352135447489478

Epoch: 6| Step: 12
Training loss: 2.7353841608754625
Validation loss: 3.350986386737362

Epoch: 6| Step: 13
Training loss: 3.927724662780135
Validation loss: 3.3482598525080145

Epoch: 22| Step: 0
Training loss: 2.8160489896717786
Validation loss: 3.3484883401636827

Epoch: 6| Step: 1
Training loss: 3.5208251471490137
Validation loss: 3.3454551684632405

Epoch: 6| Step: 2
Training loss: 2.9005540384310025
Validation loss: 3.343946023155184

Epoch: 6| Step: 3
Training loss: 2.5065287218622707
Validation loss: 3.3458409258590143

Epoch: 6| Step: 4
Training loss: 4.29271016196854
Validation loss: 3.347991315864251

Epoch: 6| Step: 5
Training loss: 2.8314102228567406
Validation loss: 3.345778024971024

Epoch: 6| Step: 6
Training loss: 4.094007178229005
Validation loss: 3.345179034212822

Epoch: 6| Step: 7
Training loss: 3.9921327949254564
Validation loss: 3.3394312000922723

Epoch: 6| Step: 8
Training loss: 3.496802640682734
Validation loss: 3.3378252824079153

Epoch: 6| Step: 9
Training loss: 4.28136939557511
Validation loss: 3.3354486465240445

Epoch: 6| Step: 10
Training loss: 4.291766761180417
Validation loss: 3.3348062342599123

Epoch: 6| Step: 11
Training loss: 3.4502655203548764
Validation loss: 3.3351789461574843

Epoch: 6| Step: 12
Training loss: 3.550533877779614
Validation loss: 3.332701542159376

Epoch: 6| Step: 13
Training loss: 3.191294935472643
Validation loss: 3.330552647662541

Epoch: 23| Step: 0
Training loss: 2.7143157225936236
Validation loss: 3.3329032687170517

Epoch: 6| Step: 1
Training loss: 3.6244348545858456
Validation loss: 3.333825805391068

Epoch: 6| Step: 2
Training loss: 3.571347543614695
Validation loss: 3.3351524070691263

Epoch: 6| Step: 3
Training loss: 3.669128429644776
Validation loss: 3.335971592427801

Epoch: 6| Step: 4
Training loss: 3.783014437529694
Validation loss: 3.330989455553673

Epoch: 6| Step: 5
Training loss: 3.703569216582377
Validation loss: 3.32779172562903

Epoch: 6| Step: 6
Training loss: 3.482707355840887
Validation loss: 3.3229343674731835

Epoch: 6| Step: 7
Training loss: 1.994527661521663
Validation loss: 3.327666113953412

Epoch: 6| Step: 8
Training loss: 3.7508663448318167
Validation loss: 3.3299149125344782

Epoch: 6| Step: 9
Training loss: 4.578432456879432
Validation loss: 3.3289665403403457

Epoch: 6| Step: 10
Training loss: 3.779371062740838
Validation loss: 3.3231046530045103

Epoch: 6| Step: 11
Training loss: 3.6684584285673
Validation loss: 3.317770497100351

Epoch: 6| Step: 12
Training loss: 3.29206750738887
Validation loss: 3.3173017759662824

Epoch: 6| Step: 13
Training loss: 3.800982855128135
Validation loss: 3.3210116167342774

Epoch: 24| Step: 0
Training loss: 3.3849793293489445
Validation loss: 3.3232968519506665

Epoch: 6| Step: 1
Training loss: 3.319385210587878
Validation loss: 3.333370644350326

Epoch: 6| Step: 2
Training loss: 2.9658437859212667
Validation loss: 3.33660402628029

Epoch: 6| Step: 3
Training loss: 3.1116862692587532
Validation loss: 3.335875228527719

Epoch: 6| Step: 4
Training loss: 4.060810618163191
Validation loss: 3.3178977026862344

Epoch: 6| Step: 5
Training loss: 4.374279289828202
Validation loss: 3.3116225529470453

Epoch: 6| Step: 6
Training loss: 4.123095448405258
Validation loss: 3.314161726276002

Epoch: 6| Step: 7
Training loss: 3.862505797347869
Validation loss: 3.31506000147797

Epoch: 6| Step: 8
Training loss: 3.439680482973843
Validation loss: 3.31606150021265

Epoch: 6| Step: 9
Training loss: 3.5629788796320563
Validation loss: 3.3183478267128588

Epoch: 6| Step: 10
Training loss: 2.3904684177555287
Validation loss: 3.3144963371185545

Epoch: 6| Step: 11
Training loss: 3.9625621225198606
Validation loss: 3.3136383348197334

Epoch: 6| Step: 12
Training loss: 3.6688960551574374
Validation loss: 3.3089452496935623

Epoch: 6| Step: 13
Training loss: 2.5616062745731667
Validation loss: 3.311808298168745

Epoch: 25| Step: 0
Training loss: 3.229260515059306
Validation loss: 3.318726291088626

Epoch: 6| Step: 1
Training loss: 4.455617963100682
Validation loss: 3.3420124647633505

Epoch: 6| Step: 2
Training loss: 3.211309926508464
Validation loss: 3.311831780906753

Epoch: 6| Step: 3
Training loss: 3.6269522047067357
Validation loss: 3.307790112337678

Epoch: 6| Step: 4
Training loss: 3.298554051669778
Validation loss: 3.3104160213403357

Epoch: 6| Step: 5
Training loss: 3.7806168964114364
Validation loss: 3.3092132099649425

Epoch: 6| Step: 6
Training loss: 3.242342216752746
Validation loss: 3.308864243600257

Epoch: 6| Step: 7
Training loss: 2.9379510736098537
Validation loss: 3.3076820076652873

Epoch: 6| Step: 8
Training loss: 4.163865533861778
Validation loss: 3.3079447352042153

Epoch: 6| Step: 9
Training loss: 3.4191189470958228
Validation loss: 3.306515211538661

Epoch: 6| Step: 10
Training loss: 3.964519258196181
Validation loss: 3.306181588790972

Epoch: 6| Step: 11
Training loss: 3.466550524917974
Validation loss: 3.3030910091149344

Epoch: 6| Step: 12
Training loss: 3.1944246061142136
Validation loss: 3.3115208750377536

Epoch: 6| Step: 13
Training loss: 3.284646737483877
Validation loss: 3.305300748752181

Epoch: 26| Step: 0
Training loss: 3.0692405479529836
Validation loss: 3.3015612179785156

Epoch: 6| Step: 1
Training loss: 3.59664972496344
Validation loss: 3.300014492275302

Epoch: 6| Step: 2
Training loss: 3.9647545113879734
Validation loss: 3.2979985903974076

Epoch: 6| Step: 3
Training loss: 3.947995804905233
Validation loss: 3.298035253846101

Epoch: 6| Step: 4
Training loss: 2.8969482544296117
Validation loss: 3.2966217128788027

Epoch: 6| Step: 5
Training loss: 3.35338793574245
Validation loss: 3.2960382910391974

Epoch: 6| Step: 6
Training loss: 4.029098291352773
Validation loss: 3.29418680665185

Epoch: 6| Step: 7
Training loss: 4.02950467911186
Validation loss: 3.2951835162123486

Epoch: 6| Step: 8
Training loss: 3.1552614986910466
Validation loss: 3.2918092414588633

Epoch: 6| Step: 9
Training loss: 3.452399958791546
Validation loss: 3.2897625144789786

Epoch: 6| Step: 10
Training loss: 3.7425610827683164
Validation loss: 3.28978409885933

Epoch: 6| Step: 11
Training loss: 3.3081368555360666
Validation loss: 3.287607819646519

Epoch: 6| Step: 12
Training loss: 2.9943670795601065
Validation loss: 3.2893193293022716

Epoch: 6| Step: 13
Training loss: 3.8425897847633026
Validation loss: 3.2882972087873434

Epoch: 27| Step: 0
Training loss: 3.093851415339818
Validation loss: 3.2862975472202804

Epoch: 6| Step: 1
Training loss: 3.1996047610339398
Validation loss: 3.282809627620123

Epoch: 6| Step: 2
Training loss: 4.126555409654667
Validation loss: 3.2828683513799923

Epoch: 6| Step: 3
Training loss: 3.6526479339407034
Validation loss: 3.2828039721287663

Epoch: 6| Step: 4
Training loss: 3.8260538531839012
Validation loss: 3.2815293872371094

Epoch: 6| Step: 5
Training loss: 2.9927864769995907
Validation loss: 3.2828706066612945

Epoch: 6| Step: 6
Training loss: 4.056369322445643
Validation loss: 3.281337051291625

Epoch: 6| Step: 7
Training loss: 3.0145264833507834
Validation loss: 3.282629718557122

Epoch: 6| Step: 8
Training loss: 3.643099750058924
Validation loss: 3.2877905581357822

Epoch: 6| Step: 9
Training loss: 3.0826194211623883
Validation loss: 3.2809065303549994

Epoch: 6| Step: 10
Training loss: 2.821423678885386
Validation loss: 3.2792662093294025

Epoch: 6| Step: 11
Training loss: 3.8790269661949726
Validation loss: 3.2791082405428478

Epoch: 6| Step: 12
Training loss: 4.140790367423031
Validation loss: 3.2767964991458687

Epoch: 6| Step: 13
Training loss: 3.372941979134016
Validation loss: 3.276430946772465

Epoch: 28| Step: 0
Training loss: 3.673870437272954
Validation loss: 3.2778178276251078

Epoch: 6| Step: 1
Training loss: 3.381308840311955
Validation loss: 3.2800568567245802

Epoch: 6| Step: 2
Training loss: 3.5553238183902858
Validation loss: 3.2833971107522184

Epoch: 6| Step: 3
Training loss: 4.122430405639472
Validation loss: 3.2727813771905896

Epoch: 6| Step: 4
Training loss: 3.6608258167250174
Validation loss: 3.2712166815430033

Epoch: 6| Step: 5
Training loss: 3.0720862004583913
Validation loss: 3.2697327701281202

Epoch: 6| Step: 6
Training loss: 3.2670039865628837
Validation loss: 3.272601306946913

Epoch: 6| Step: 7
Training loss: 3.36664989454668
Validation loss: 3.2670198689923358

Epoch: 6| Step: 8
Training loss: 4.166484650768892
Validation loss: 3.270021250916871

Epoch: 6| Step: 9
Training loss: 3.92306257406404
Validation loss: 3.266337661632684

Epoch: 6| Step: 10
Training loss: 2.5382151906536494
Validation loss: 3.2660557801845966

Epoch: 6| Step: 11
Training loss: 2.846211468515778
Validation loss: 3.265136036842222

Epoch: 6| Step: 12
Training loss: 3.6635335772290083
Validation loss: 3.263748109240039

Epoch: 6| Step: 13
Training loss: 3.702948457396782
Validation loss: 3.2644169637621836

Epoch: 29| Step: 0
Training loss: 2.999600065912108
Validation loss: 3.265226179340178

Epoch: 6| Step: 1
Training loss: 3.7404426855339796
Validation loss: 3.2621629547703366

Epoch: 6| Step: 2
Training loss: 3.4671797763898313
Validation loss: 3.2559012057677967

Epoch: 6| Step: 3
Training loss: 3.835339532615637
Validation loss: 3.2563285864289373

Epoch: 6| Step: 4
Training loss: 3.6780935021982635
Validation loss: 3.258334639958415

Epoch: 6| Step: 5
Training loss: 3.3748912087319742
Validation loss: 3.2590192336968244

Epoch: 6| Step: 6
Training loss: 3.7365274650333085
Validation loss: 3.25545749791953

Epoch: 6| Step: 7
Training loss: 3.1764623983647433
Validation loss: 3.2563405908441307

Epoch: 6| Step: 8
Training loss: 3.0975523422535556
Validation loss: 3.254925702563658

Epoch: 6| Step: 9
Training loss: 3.8221081841137536
Validation loss: 3.2507153552807493

Epoch: 6| Step: 10
Training loss: 3.9200824425260716
Validation loss: 3.251163268172002

Epoch: 6| Step: 11
Training loss: 2.9546708193771614
Validation loss: 3.250216236288452

Epoch: 6| Step: 12
Training loss: 3.5205813586717953
Validation loss: 3.2480003572580283

Epoch: 6| Step: 13
Training loss: 3.618837314006948
Validation loss: 3.2492458037933227

Epoch: 30| Step: 0
Training loss: 2.785454390352871
Validation loss: 3.246420543274893

Epoch: 6| Step: 1
Training loss: 3.2773631007790613
Validation loss: 3.245958492587142

Epoch: 6| Step: 2
Training loss: 3.827181205404822
Validation loss: 3.242530988201915

Epoch: 6| Step: 3
Training loss: 3.1104556558817924
Validation loss: 3.242651504778605

Epoch: 6| Step: 4
Training loss: 3.273180093409032
Validation loss: 3.2447104450376765

Epoch: 6| Step: 5
Training loss: 3.7113855352479295
Validation loss: 3.2488833702867668

Epoch: 6| Step: 6
Training loss: 4.3695090577223406
Validation loss: 3.2415409784276625

Epoch: 6| Step: 7
Training loss: 4.036801323213183
Validation loss: 3.2404145302561673

Epoch: 6| Step: 8
Training loss: 3.283393087343583
Validation loss: 3.24388872394864

Epoch: 6| Step: 9
Training loss: 2.9010060900019696
Validation loss: 3.242824366466278

Epoch: 6| Step: 10
Training loss: 4.123374387453961
Validation loss: 3.239828739790085

Epoch: 6| Step: 11
Training loss: 3.595418260884695
Validation loss: 3.2394674012861815

Epoch: 6| Step: 12
Training loss: 3.169244586937249
Validation loss: 3.238559958648918

Epoch: 6| Step: 13
Training loss: 2.6074290986264637
Validation loss: 3.2357439113920874

Epoch: 31| Step: 0
Training loss: 4.364324351102468
Validation loss: 3.2369108835946934

Epoch: 6| Step: 1
Training loss: 3.728207015408835
Validation loss: 3.2337112906969083

Epoch: 6| Step: 2
Training loss: 3.620585944032402
Validation loss: 3.2375560080831924

Epoch: 6| Step: 3
Training loss: 3.708544921553555
Validation loss: 3.2401274945615746

Epoch: 6| Step: 4
Training loss: 3.6332725315664463
Validation loss: 3.2449215508911227

Epoch: 6| Step: 5
Training loss: 3.2603969065562017
Validation loss: 3.2352089310382555

Epoch: 6| Step: 6
Training loss: 3.2138418163595195
Validation loss: 3.2379623428836832

Epoch: 6| Step: 7
Training loss: 3.3931127466278106
Validation loss: 3.2370676534716183

Epoch: 6| Step: 8
Training loss: 3.6681715449130996
Validation loss: 3.2368125597766197

Epoch: 6| Step: 9
Training loss: 3.270052158511354
Validation loss: 3.236300230291272

Epoch: 6| Step: 10
Training loss: 2.3158298952622327
Validation loss: 3.2368625806023372

Epoch: 6| Step: 11
Training loss: 2.9740838571615145
Validation loss: 3.2370598296510638

Epoch: 6| Step: 12
Training loss: 3.802426396747943
Validation loss: 3.237228378549496

Epoch: 6| Step: 13
Training loss: 3.515011339671265
Validation loss: 3.238587290861836

Epoch: 32| Step: 0
Training loss: 3.5410810697034196
Validation loss: 3.233135217023065

Epoch: 6| Step: 1
Training loss: 3.8771167019175583
Validation loss: 3.230464596391112

Epoch: 6| Step: 2
Training loss: 3.5906617537062453
Validation loss: 3.2319682173056137

Epoch: 6| Step: 3
Training loss: 3.673366552111547
Validation loss: 3.232485487508753

Epoch: 6| Step: 4
Training loss: 3.703304109386525
Validation loss: 3.2312071123659

Epoch: 6| Step: 5
Training loss: 2.2225502672722066
Validation loss: 3.2299352913363704

Epoch: 6| Step: 6
Training loss: 3.545804841180733
Validation loss: 3.230138012689328

Epoch: 6| Step: 7
Training loss: 4.086757132777122
Validation loss: 3.2259421172890783

Epoch: 6| Step: 8
Training loss: 3.5130901777560304
Validation loss: 3.228419018007066

Epoch: 6| Step: 9
Training loss: 3.0099836167811636
Validation loss: 3.2284844356935314

Epoch: 6| Step: 10
Training loss: 3.4444083413587134
Validation loss: 3.228035637777197

Epoch: 6| Step: 11
Training loss: 3.2804664766249716
Validation loss: 3.224580588656086

Epoch: 6| Step: 12
Training loss: 3.2718746852054825
Validation loss: 3.2278038322015585

Epoch: 6| Step: 13
Training loss: 3.7276634013680643
Validation loss: 3.2267627136997312

Epoch: 33| Step: 0
Training loss: 3.402065401483587
Validation loss: 3.2296232876505218

Epoch: 6| Step: 1
Training loss: 3.4422732418288837
Validation loss: 3.228565660028705

Epoch: 6| Step: 2
Training loss: 3.7269541536607034
Validation loss: 3.224970131770988

Epoch: 6| Step: 3
Training loss: 3.2742848904118134
Validation loss: 3.2261651026379212

Epoch: 6| Step: 4
Training loss: 3.5007145016109997
Validation loss: 3.2222475586124797

Epoch: 6| Step: 5
Training loss: 3.2241151408987334
Validation loss: 3.221984817996368

Epoch: 6| Step: 6
Training loss: 2.8140897708230157
Validation loss: 3.2195362087034924

Epoch: 6| Step: 7
Training loss: 3.8098028679659044
Validation loss: 3.2215050386698123

Epoch: 6| Step: 8
Training loss: 3.0531613959775687
Validation loss: 3.222172968062138

Epoch: 6| Step: 9
Training loss: 3.1484811178740415
Validation loss: 3.219465839398265

Epoch: 6| Step: 10
Training loss: 3.843484636776529
Validation loss: 3.2190867876131626

Epoch: 6| Step: 11
Training loss: 3.9327742055272075
Validation loss: 3.2180553602270083

Epoch: 6| Step: 12
Training loss: 3.9878129076981783
Validation loss: 3.214717997846137

Epoch: 6| Step: 13
Training loss: 3.1198161044089745
Validation loss: 3.213246183136052

Epoch: 34| Step: 0
Training loss: 4.107873214325231
Validation loss: 3.213139747775532

Epoch: 6| Step: 1
Training loss: 3.2943189212872768
Validation loss: 3.2137101290575343

Epoch: 6| Step: 2
Training loss: 3.551351939923202
Validation loss: 3.2119115019824154

Epoch: 6| Step: 3
Training loss: 3.9510946374680165
Validation loss: 3.2145698995013565

Epoch: 6| Step: 4
Training loss: 3.0881262634435345
Validation loss: 3.214504697892441

Epoch: 6| Step: 5
Training loss: 2.6066139826934385
Validation loss: 3.2139626924212634

Epoch: 6| Step: 6
Training loss: 3.8405300392472963
Validation loss: 3.216703824438565

Epoch: 6| Step: 7
Training loss: 3.374602117750328
Validation loss: 3.2123469697447975

Epoch: 6| Step: 8
Training loss: 3.1546917080674013
Validation loss: 3.2105123599078054

Epoch: 6| Step: 9
Training loss: 3.9607126145787457
Validation loss: 3.211485217585136

Epoch: 6| Step: 10
Training loss: 3.4678855024926123
Validation loss: 3.2120869565679846

Epoch: 6| Step: 11
Training loss: 3.3528384467529024
Validation loss: 3.212597965281983

Epoch: 6| Step: 12
Training loss: 2.4321496392442183
Validation loss: 3.2129042519070556

Epoch: 6| Step: 13
Training loss: 4.252131656793917
Validation loss: 3.2130203774928123

Epoch: 35| Step: 0
Training loss: 3.5381056142497287
Validation loss: 3.213971652492637

Epoch: 6| Step: 1
Training loss: 3.118231806391031
Validation loss: 3.2136670957675175

Epoch: 6| Step: 2
Training loss: 3.423182964743109
Validation loss: 3.2114876347536407

Epoch: 6| Step: 3
Training loss: 2.2115626445455963
Validation loss: 3.215008136178432

Epoch: 6| Step: 4
Training loss: 3.9002225225495573
Validation loss: 3.213909751473706

Epoch: 6| Step: 5
Training loss: 3.563518579328887
Validation loss: 3.2116333496140723

Epoch: 6| Step: 6
Training loss: 2.8354698615277725
Validation loss: 3.2107582873616143

Epoch: 6| Step: 7
Training loss: 4.027632635431898
Validation loss: 3.2113903191335855

Epoch: 6| Step: 8
Training loss: 3.459979818208081
Validation loss: 3.209954908472947

Epoch: 6| Step: 9
Training loss: 4.391808835550844
Validation loss: 3.208490703182092

Epoch: 6| Step: 10
Training loss: 3.0109140233865173
Validation loss: 3.207898207265959

Epoch: 6| Step: 11
Training loss: 3.7112122122824944
Validation loss: 3.208095981771466

Epoch: 6| Step: 12
Training loss: 3.58161216622187
Validation loss: 3.2069765758536546

Epoch: 6| Step: 13
Training loss: 3.0124610550131914
Validation loss: 3.2054771992805327

Epoch: 36| Step: 0
Training loss: 3.531324807784083
Validation loss: 3.2074089785604674

Epoch: 6| Step: 1
Training loss: 3.9358345021290484
Validation loss: 3.2062681737998506

Epoch: 6| Step: 2
Training loss: 3.8836440610111214
Validation loss: 3.205251703735378

Epoch: 6| Step: 3
Training loss: 3.5925878884880786
Validation loss: 3.2045716083203257

Epoch: 6| Step: 4
Training loss: 3.363814857676997
Validation loss: 3.20508481669185

Epoch: 6| Step: 5
Training loss: 3.0230286787554834
Validation loss: 3.20273364197642

Epoch: 6| Step: 6
Training loss: 3.3224994234037224
Validation loss: 3.204465352048854

Epoch: 6| Step: 7
Training loss: 3.195327721445255
Validation loss: 3.202807127604144

Epoch: 6| Step: 8
Training loss: 2.793468083915055
Validation loss: 3.2041406973471793

Epoch: 6| Step: 9
Training loss: 3.128102098013379
Validation loss: 3.203012439141655

Epoch: 6| Step: 10
Training loss: 3.0302852393119357
Validation loss: 3.2039741965140203

Epoch: 6| Step: 11
Training loss: 3.8618741611739713
Validation loss: 3.2019035765800594

Epoch: 6| Step: 12
Training loss: 4.2577876379004636
Validation loss: 3.201998292623413

Epoch: 6| Step: 13
Training loss: 3.007766525115354
Validation loss: 3.201275894991762

Epoch: 37| Step: 0
Training loss: 3.033232050731362
Validation loss: 3.205614502246104

Epoch: 6| Step: 1
Training loss: 3.8362457710906552
Validation loss: 3.2069337895563987

Epoch: 6| Step: 2
Training loss: 4.386687879037635
Validation loss: 3.2049988250681634

Epoch: 6| Step: 3
Training loss: 3.4982889625191347
Validation loss: 3.20115704813206

Epoch: 6| Step: 4
Training loss: 3.267408696061325
Validation loss: 3.2002943495763803

Epoch: 6| Step: 5
Training loss: 2.8817070389569484
Validation loss: 3.1991571188594365

Epoch: 6| Step: 6
Training loss: 4.02433029194996
Validation loss: 3.19944098086371

Epoch: 6| Step: 7
Training loss: 3.352939420685835
Validation loss: 3.1989211706415883

Epoch: 6| Step: 8
Training loss: 3.1482021347935323
Validation loss: 3.1983284249100508

Epoch: 6| Step: 9
Training loss: 2.8949153918089596
Validation loss: 3.197127703684096

Epoch: 6| Step: 10
Training loss: 3.2829364620663686
Validation loss: 3.1959190937176634

Epoch: 6| Step: 11
Training loss: 4.251121148722789
Validation loss: 3.1967538238101083

Epoch: 6| Step: 12
Training loss: 3.1589513115386687
Validation loss: 3.1977621874037196

Epoch: 6| Step: 13
Training loss: 2.4093502929054007
Validation loss: 3.196224376679019

Epoch: 38| Step: 0
Training loss: 3.4133221764183492
Validation loss: 3.194964845299518

Epoch: 6| Step: 1
Training loss: 3.760853130058277
Validation loss: 3.196321021535017

Epoch: 6| Step: 2
Training loss: 3.094679875742432
Validation loss: 3.197288403102383

Epoch: 6| Step: 3
Training loss: 3.1416927818879112
Validation loss: 3.1952924517408183

Epoch: 6| Step: 4
Training loss: 4.071255682618319
Validation loss: 3.191401832677821

Epoch: 6| Step: 5
Training loss: 3.678568611196849
Validation loss: 3.1947908416687816

Epoch: 6| Step: 6
Training loss: 4.162840243343667
Validation loss: 3.1934692448206135

Epoch: 6| Step: 7
Training loss: 3.52217028513047
Validation loss: 3.191693596565781

Epoch: 6| Step: 8
Training loss: 2.7467505590657533
Validation loss: 3.193188915160599

Epoch: 6| Step: 9
Training loss: 3.560797836825507
Validation loss: 3.1924205202580644

Epoch: 6| Step: 10
Training loss: 3.4111644045559673
Validation loss: 3.1919683061722974

Epoch: 6| Step: 11
Training loss: 2.806650818744536
Validation loss: 3.1938457904176123

Epoch: 6| Step: 12
Training loss: 3.6029535945939357
Validation loss: 3.1903101264142073

Epoch: 6| Step: 13
Training loss: 2.6817057046682424
Validation loss: 3.1915873605681093

Epoch: 39| Step: 0
Training loss: 2.81320952896355
Validation loss: 3.1890106618676994

Epoch: 6| Step: 1
Training loss: 3.626023246778989
Validation loss: 3.194314440102583

Epoch: 6| Step: 2
Training loss: 2.9326451541914906
Validation loss: 3.199780937709313

Epoch: 6| Step: 3
Training loss: 3.627389580632019
Validation loss: 3.2077690547735935

Epoch: 6| Step: 4
Training loss: 3.9685315650241177
Validation loss: 3.2036957407131537

Epoch: 6| Step: 5
Training loss: 4.528520274894102
Validation loss: 3.190619918521743

Epoch: 6| Step: 6
Training loss: 2.5732317176909874
Validation loss: 3.1903615898989814

Epoch: 6| Step: 7
Training loss: 2.990948054325229
Validation loss: 3.1915180329658446

Epoch: 6| Step: 8
Training loss: 3.7719981605630477
Validation loss: 3.190426777877196

Epoch: 6| Step: 9
Training loss: 3.4951693031878697
Validation loss: 3.1911021080262945

Epoch: 6| Step: 10
Training loss: 3.4190349899425088
Validation loss: 3.1968917131410586

Epoch: 6| Step: 11
Training loss: 3.0723643350719123
Validation loss: 3.1920268250089023

Epoch: 6| Step: 12
Training loss: 3.2590256588801596
Validation loss: 3.196029425806157

Epoch: 6| Step: 13
Training loss: 3.9639161476481735
Validation loss: 3.195242160448441

Epoch: 40| Step: 0
Training loss: 2.6633791228819397
Validation loss: 3.1931910772255687

Epoch: 6| Step: 1
Training loss: 3.3950273614379176
Validation loss: 3.195663502269863

Epoch: 6| Step: 2
Training loss: 3.680086345074277
Validation loss: 3.1953998353862207

Epoch: 6| Step: 3
Training loss: 3.6053740549929096
Validation loss: 3.1959408402197287

Epoch: 6| Step: 4
Training loss: 2.8029114776906563
Validation loss: 3.196268954596228

Epoch: 6| Step: 5
Training loss: 3.6013198075683692
Validation loss: 3.192689880554376

Epoch: 6| Step: 6
Training loss: 3.4006491994952
Validation loss: 3.190379857934658

Epoch: 6| Step: 7
Training loss: 3.998751564705278
Validation loss: 3.191336179415819

Epoch: 6| Step: 8
Training loss: 4.416872463589948
Validation loss: 3.1880331411917084

Epoch: 6| Step: 9
Training loss: 3.6708125748554363
Validation loss: 3.1889069966774954

Epoch: 6| Step: 10
Training loss: 3.151875703423138
Validation loss: 3.1875656301331707

Epoch: 6| Step: 11
Training loss: 2.794441315118526
Validation loss: 3.185924067261204

Epoch: 6| Step: 12
Training loss: 2.730492413026712
Validation loss: 3.190880048404602

Epoch: 6| Step: 13
Training loss: 4.131653477159268
Validation loss: 3.189302360754658

Epoch: 41| Step: 0
Training loss: 2.9962027677872207
Validation loss: 3.1886842632090615

Epoch: 6| Step: 1
Training loss: 3.784970683459252
Validation loss: 3.1906931239253167

Epoch: 6| Step: 2
Training loss: 3.497242522506906
Validation loss: 3.1943360755400145

Epoch: 6| Step: 3
Training loss: 3.5039334673552727
Validation loss: 3.202533229264741

Epoch: 6| Step: 4
Training loss: 3.43402770406382
Validation loss: 3.213229314463954

Epoch: 6| Step: 5
Training loss: 2.66441069981503
Validation loss: 3.188242331823609

Epoch: 6| Step: 6
Training loss: 3.8904713060286444
Validation loss: 3.185344658215338

Epoch: 6| Step: 7
Training loss: 3.921490046237432
Validation loss: 3.186669026008083

Epoch: 6| Step: 8
Training loss: 3.09621446880949
Validation loss: 3.1877306364723865

Epoch: 6| Step: 9
Training loss: 3.3464111006627193
Validation loss: 3.1849715973996937

Epoch: 6| Step: 10
Training loss: 3.308114801935635
Validation loss: 3.1860938721679606

Epoch: 6| Step: 11
Training loss: 3.9230160212212732
Validation loss: 3.183200087354761

Epoch: 6| Step: 12
Training loss: 3.4534167688617554
Validation loss: 3.1848005541934516

Epoch: 6| Step: 13
Training loss: 2.8057899114928944
Validation loss: 3.183062175130275

Epoch: 42| Step: 0
Training loss: 3.835962485797254
Validation loss: 3.184132327719199

Epoch: 6| Step: 1
Training loss: 2.9326391381233945
Validation loss: 3.180081237923413

Epoch: 6| Step: 2
Training loss: 3.504846351074625
Validation loss: 3.1809708030645

Epoch: 6| Step: 3
Training loss: 2.6724859955637514
Validation loss: 3.179344408473782

Epoch: 6| Step: 4
Training loss: 2.826808475485026
Validation loss: 3.1797349106968196

Epoch: 6| Step: 5
Training loss: 3.0860246477014246
Validation loss: 3.17854159473221

Epoch: 6| Step: 6
Training loss: 4.5970781168612325
Validation loss: 3.178103803569061

Epoch: 6| Step: 7
Training loss: 3.567341509521711
Validation loss: 3.178244895285618

Epoch: 6| Step: 8
Training loss: 3.243188910201035
Validation loss: 3.1808694565254108

Epoch: 6| Step: 9
Training loss: 3.3369210644772163
Validation loss: 3.180616085318791

Epoch: 6| Step: 10
Training loss: 2.8428145326705865
Validation loss: 3.1808686159132535

Epoch: 6| Step: 11
Training loss: 3.802543020111647
Validation loss: 3.1809167408030583

Epoch: 6| Step: 12
Training loss: 2.899365217517583
Validation loss: 3.1789100262654886

Epoch: 6| Step: 13
Training loss: 4.919744702670366
Validation loss: 3.1750308492562094

Epoch: 43| Step: 0
Training loss: 3.814953499206883
Validation loss: 3.1751371515371773

Epoch: 6| Step: 1
Training loss: 3.1267806511323126
Validation loss: 3.1746929523754743

Epoch: 6| Step: 2
Training loss: 2.869971812571694
Validation loss: 3.1745348384761454

Epoch: 6| Step: 3
Training loss: 3.1515286324174916
Validation loss: 3.1734716895593618

Epoch: 6| Step: 4
Training loss: 3.8210076633786842
Validation loss: 3.173587844373327

Epoch: 6| Step: 5
Training loss: 3.889139772829902
Validation loss: 3.1727869014239984

Epoch: 6| Step: 6
Training loss: 3.36916185455268
Validation loss: 3.171548418106074

Epoch: 6| Step: 7
Training loss: 3.628449738760876
Validation loss: 3.16939676070186

Epoch: 6| Step: 8
Training loss: 3.450294266465908
Validation loss: 3.169185880398954

Epoch: 6| Step: 9
Training loss: 2.975072132165766
Validation loss: 3.16829670746733

Epoch: 6| Step: 10
Training loss: 2.9116895080031497
Validation loss: 3.1703463021248424

Epoch: 6| Step: 11
Training loss: 3.3151398702028834
Validation loss: 3.168075146823079

Epoch: 6| Step: 12
Training loss: 3.5424658976806636
Validation loss: 3.168834092413351

Epoch: 6| Step: 13
Training loss: 4.2893989028053445
Validation loss: 3.169112089201414

Epoch: 44| Step: 0
Training loss: 4.089579780461768
Validation loss: 3.1674225044937683

Epoch: 6| Step: 1
Training loss: 2.8870989764602686
Validation loss: 3.168434013107473

Epoch: 6| Step: 2
Training loss: 3.6396433280333738
Validation loss: 3.171492122647367

Epoch: 6| Step: 3
Training loss: 3.5167024444881383
Validation loss: 3.171298167100543

Epoch: 6| Step: 4
Training loss: 2.912598597613532
Validation loss: 3.1656260170256867

Epoch: 6| Step: 5
Training loss: 3.4492054784569137
Validation loss: 3.167779936204461

Epoch: 6| Step: 6
Training loss: 3.772109277713881
Validation loss: 3.1699800365760478

Epoch: 6| Step: 7
Training loss: 3.0973440544521997
Validation loss: 3.1672463903761803

Epoch: 6| Step: 8
Training loss: 3.5149171922026827
Validation loss: 3.16658880551464

Epoch: 6| Step: 9
Training loss: 3.1619220793627907
Validation loss: 3.167723689503856

Epoch: 6| Step: 10
Training loss: 3.5027686476346878
Validation loss: 3.1675371272764044

Epoch: 6| Step: 11
Training loss: 3.9052496277640647
Validation loss: 3.1649860386839492

Epoch: 6| Step: 12
Training loss: 2.9624151805211616
Validation loss: 3.1652027161513185

Epoch: 6| Step: 13
Training loss: 3.2200708734519665
Validation loss: 3.165189358507475

Epoch: 45| Step: 0
Training loss: 3.060589564256364
Validation loss: 3.1642892253692616

Epoch: 6| Step: 1
Training loss: 4.157747844894352
Validation loss: 3.1624663339217465

Epoch: 6| Step: 2
Training loss: 3.268419885833193
Validation loss: 3.1641948802402413

Epoch: 6| Step: 3
Training loss: 3.8499238588804903
Validation loss: 3.1634498852865915

Epoch: 6| Step: 4
Training loss: 3.4588995933373883
Validation loss: 3.160070439264027

Epoch: 6| Step: 5
Training loss: 2.9645034132313874
Validation loss: 3.1633672637344667

Epoch: 6| Step: 6
Training loss: 3.7837037251077854
Validation loss: 3.1612446522484907

Epoch: 6| Step: 7
Training loss: 3.8163257851995938
Validation loss: 3.1617554844949227

Epoch: 6| Step: 8
Training loss: 3.6378691233643945
Validation loss: 3.1636547802772146

Epoch: 6| Step: 9
Training loss: 3.1651157462844752
Validation loss: 3.160943057519914

Epoch: 6| Step: 10
Training loss: 2.397920136458877
Validation loss: 3.161861373646636

Epoch: 6| Step: 11
Training loss: 3.7094787943072323
Validation loss: 3.1609947890686585

Epoch: 6| Step: 12
Training loss: 3.46204408474097
Validation loss: 3.1590887084972374

Epoch: 6| Step: 13
Training loss: 2.0797484517211506
Validation loss: 3.1619262630133034

Epoch: 46| Step: 0
Training loss: 3.5638905538500727
Validation loss: 3.1584252669570136

Epoch: 6| Step: 1
Training loss: 3.0630651458577494
Validation loss: 3.159607839213702

Epoch: 6| Step: 2
Training loss: 3.618315485824316
Validation loss: 3.15888484343466

Epoch: 6| Step: 3
Training loss: 3.862690231428688
Validation loss: 3.156902955997719

Epoch: 6| Step: 4
Training loss: 3.211589366521703
Validation loss: 3.159049857898918

Epoch: 6| Step: 5
Training loss: 4.357021339026293
Validation loss: 3.1609801873702414

Epoch: 6| Step: 6
Training loss: 3.1892782000982716
Validation loss: 3.1595223138017285

Epoch: 6| Step: 7
Training loss: 3.01527157624779
Validation loss: 3.157719436877329

Epoch: 6| Step: 8
Training loss: 3.460260122587144
Validation loss: 3.1584918202174115

Epoch: 6| Step: 9
Training loss: 3.231527650809564
Validation loss: 3.1595076695964277

Epoch: 6| Step: 10
Training loss: 3.313973728773359
Validation loss: 3.157797318088228

Epoch: 6| Step: 11
Training loss: 3.5570114420057144
Validation loss: 3.1570242483748676

Epoch: 6| Step: 12
Training loss: 3.435921185061382
Validation loss: 3.1548779410243086

Epoch: 6| Step: 13
Training loss: 1.9389505186490787
Validation loss: 3.158555173365288

Epoch: 47| Step: 0
Training loss: 3.760359886071853
Validation loss: 3.1577859449370345

Epoch: 6| Step: 1
Training loss: 2.9778585340768977
Validation loss: 3.1578978066113743

Epoch: 6| Step: 2
Training loss: 3.6141085940471447
Validation loss: 3.155894261564619

Epoch: 6| Step: 3
Training loss: 3.351065930124621
Validation loss: 3.159007544822536

Epoch: 6| Step: 4
Training loss: 3.0450175565767825
Validation loss: 3.1576615909945636

Epoch: 6| Step: 5
Training loss: 3.5813175268281237
Validation loss: 3.1569477805720405

Epoch: 6| Step: 6
Training loss: 3.853152181091717
Validation loss: 3.157285950176266

Epoch: 6| Step: 7
Training loss: 3.4301824190883283
Validation loss: 3.156486015872849

Epoch: 6| Step: 8
Training loss: 3.1783537445719863
Validation loss: 3.15649356103317

Epoch: 6| Step: 9
Training loss: 3.9220722042520086
Validation loss: 3.1542591211194373

Epoch: 6| Step: 10
Training loss: 3.4378209744499735
Validation loss: 3.1539101160891274

Epoch: 6| Step: 11
Training loss: 3.4620480789909776
Validation loss: 3.15560510204374

Epoch: 6| Step: 12
Training loss: 2.84711064892835
Validation loss: 3.1550036056529414

Epoch: 6| Step: 13
Training loss: 2.927177147136848
Validation loss: 3.157608664128008

Epoch: 48| Step: 0
Training loss: 3.021097544373506
Validation loss: 3.1759729299150283

Epoch: 6| Step: 1
Training loss: 3.6100550419634683
Validation loss: 3.1581050798656607

Epoch: 6| Step: 2
Training loss: 3.6365326896298598
Validation loss: 3.155455134357024

Epoch: 6| Step: 3
Training loss: 3.293834567929706
Validation loss: 3.1542621429419797

Epoch: 6| Step: 4
Training loss: 3.434713586807622
Validation loss: 3.152140091214656

Epoch: 6| Step: 5
Training loss: 3.873478129159585
Validation loss: 3.1519284207350586

Epoch: 6| Step: 6
Training loss: 3.3833265376531694
Validation loss: 3.1513926955368787

Epoch: 6| Step: 7
Training loss: 3.6077747843585413
Validation loss: 3.15131115467392

Epoch: 6| Step: 8
Training loss: 3.6209939327700105
Validation loss: 3.1532454004206882

Epoch: 6| Step: 9
Training loss: 2.9453147665566544
Validation loss: 3.1506782036683787

Epoch: 6| Step: 10
Training loss: 2.9704137055454556
Validation loss: 3.1550749617310894

Epoch: 6| Step: 11
Training loss: 3.622304242875535
Validation loss: 3.1550723908374105

Epoch: 6| Step: 12
Training loss: 3.2732855640921765
Validation loss: 3.15645898959408

Epoch: 6| Step: 13
Training loss: 3.394746025147735
Validation loss: 3.1523292855187854

Epoch: 49| Step: 0
Training loss: 3.356714232889684
Validation loss: 3.154428158301849

Epoch: 6| Step: 1
Training loss: 3.7258841418990714
Validation loss: 3.1525311690631868

Epoch: 6| Step: 2
Training loss: 3.87624499102001
Validation loss: 3.150520127100566

Epoch: 6| Step: 3
Training loss: 3.6651021625180293
Validation loss: 3.151929922190312

Epoch: 6| Step: 4
Training loss: 2.7949337322588717
Validation loss: 3.1505680572738735

Epoch: 6| Step: 5
Training loss: 3.3088272174490525
Validation loss: 3.1503917862256854

Epoch: 6| Step: 6
Training loss: 3.1232441356166927
Validation loss: 3.149998187578796

Epoch: 6| Step: 7
Training loss: 3.4122696627616946
Validation loss: 3.1497957510097643

Epoch: 6| Step: 8
Training loss: 3.2548284609079667
Validation loss: 3.1493429387729406

Epoch: 6| Step: 9
Training loss: 4.155514989123382
Validation loss: 3.1462011520886426

Epoch: 6| Step: 10
Training loss: 2.711035998750927
Validation loss: 3.1460604021712557

Epoch: 6| Step: 11
Training loss: 3.6139220293307424
Validation loss: 3.146176133238532

Epoch: 6| Step: 12
Training loss: 3.7132078273070594
Validation loss: 3.1461022211912937

Epoch: 6| Step: 13
Training loss: 1.8949395123291806
Validation loss: 3.147136100383292

Epoch: 50| Step: 0
Training loss: 3.330449255345537
Validation loss: 3.145017455487682

Epoch: 6| Step: 1
Training loss: 3.3812943150688892
Validation loss: 3.1442209504295895

Epoch: 6| Step: 2
Training loss: 2.4579523297770733
Validation loss: 3.1460156555301517

Epoch: 6| Step: 3
Training loss: 3.8345867816666783
Validation loss: 3.1442982520000187

Epoch: 6| Step: 4
Training loss: 2.6794139844809224
Validation loss: 3.1462241189962623

Epoch: 6| Step: 5
Training loss: 3.1046754219576655
Validation loss: 3.144607719725184

Epoch: 6| Step: 6
Training loss: 3.8230332747439966
Validation loss: 3.145654013274692

Epoch: 6| Step: 7
Training loss: 3.8818232851601984
Validation loss: 3.146097424907123

Epoch: 6| Step: 8
Training loss: 3.6256910520421344
Validation loss: 3.1453081434309045

Epoch: 6| Step: 9
Training loss: 3.5101049871583645
Validation loss: 3.1431124652336293

Epoch: 6| Step: 10
Training loss: 3.2227509455784142
Validation loss: 3.1423376437196073

Epoch: 6| Step: 11
Training loss: 3.135353028590497
Validation loss: 3.142436994985019

Epoch: 6| Step: 12
Training loss: 3.8028713019454337
Validation loss: 3.140901381460959

Epoch: 6| Step: 13
Training loss: 3.6636457714611437
Validation loss: 3.143362624373672

Epoch: 51| Step: 0
Training loss: 3.0145736205588896
Validation loss: 3.139072928328664

Epoch: 6| Step: 1
Training loss: 3.383863607358903
Validation loss: 3.139046433251171

Epoch: 6| Step: 2
Training loss: 3.9227571141309325
Validation loss: 3.1439806209011736

Epoch: 6| Step: 3
Training loss: 2.6305503295538593
Validation loss: 3.1405522731881796

Epoch: 6| Step: 4
Training loss: 3.4842291147115616
Validation loss: 3.1419439352783955

Epoch: 6| Step: 5
Training loss: 3.5916634514625363
Validation loss: 3.1346246666648327

Epoch: 6| Step: 6
Training loss: 3.8238686078853563
Validation loss: 3.1384866702219125

Epoch: 6| Step: 7
Training loss: 3.1058940476267067
Validation loss: 3.1359027609344468

Epoch: 6| Step: 8
Training loss: 2.3871469566197177
Validation loss: 3.136929596538964

Epoch: 6| Step: 9
Training loss: 3.8635204460992254
Validation loss: 3.1370230757376154

Epoch: 6| Step: 10
Training loss: 3.2424001601001957
Validation loss: 3.1353610170807475

Epoch: 6| Step: 11
Training loss: 3.2587649190463894
Validation loss: 3.1347684366272817

Epoch: 6| Step: 12
Training loss: 4.06399461688789
Validation loss: 3.1356094007309605

Epoch: 6| Step: 13
Training loss: 3.4446158537377976
Validation loss: 3.134460546004407

Epoch: 52| Step: 0
Training loss: 3.5771355072879194
Validation loss: 3.1382376385787536

Epoch: 6| Step: 1
Training loss: 3.283198332229919
Validation loss: 3.133347134329573

Epoch: 6| Step: 2
Training loss: 2.951762697570066
Validation loss: 3.134115997073785

Epoch: 6| Step: 3
Training loss: 3.178296283918726
Validation loss: 3.133732972244375

Epoch: 6| Step: 4
Training loss: 3.270632176784089
Validation loss: 3.1337787695993597

Epoch: 6| Step: 5
Training loss: 3.2434570768246807
Validation loss: 3.136726836357042

Epoch: 6| Step: 6
Training loss: 3.4552898266650343
Validation loss: 3.131504459548976

Epoch: 6| Step: 7
Training loss: 3.794967109226037
Validation loss: 3.136274192226724

Epoch: 6| Step: 8
Training loss: 3.592746229553474
Validation loss: 3.129193745126949

Epoch: 6| Step: 9
Training loss: 3.6247088874470723
Validation loss: 3.129582970368272

Epoch: 6| Step: 10
Training loss: 3.078700442672273
Validation loss: 3.12946080119235

Epoch: 6| Step: 11
Training loss: 3.348360252468372
Validation loss: 3.128238574940499

Epoch: 6| Step: 12
Training loss: 3.5596727898057425
Validation loss: 3.1263231376346985

Epoch: 6| Step: 13
Training loss: 3.495329738228265
Validation loss: 3.1242519377504556

Epoch: 53| Step: 0
Training loss: 3.9491050092578583
Validation loss: 3.1250867261439974

Epoch: 6| Step: 1
Training loss: 3.1583192293226285
Validation loss: 3.1245706833480758

Epoch: 6| Step: 2
Training loss: 3.694194600413944
Validation loss: 3.1237921384236893

Epoch: 6| Step: 3
Training loss: 3.4652125561186042
Validation loss: 3.1249073909039997

Epoch: 6| Step: 4
Training loss: 2.7336087270338947
Validation loss: 3.1225971606986587

Epoch: 6| Step: 5
Training loss: 3.4095199707985895
Validation loss: 3.118756128432917

Epoch: 6| Step: 6
Training loss: 3.7182315497073026
Validation loss: 3.1170482988385033

Epoch: 6| Step: 7
Training loss: 3.1904089126867996
Validation loss: 3.1194325721014713

Epoch: 6| Step: 8
Training loss: 3.2439877579125245
Validation loss: 3.1179885059217898

Epoch: 6| Step: 9
Training loss: 3.7216693094269497
Validation loss: 3.1152720019066065

Epoch: 6| Step: 10
Training loss: 2.7003729597981976
Validation loss: 3.117669809346809

Epoch: 6| Step: 11
Training loss: 3.414318921827774
Validation loss: 3.1164462098156687

Epoch: 6| Step: 12
Training loss: 3.011128448148634
Validation loss: 3.1140967478154513

Epoch: 6| Step: 13
Training loss: 3.9456412301167063
Validation loss: 3.1146636597498145

Epoch: 54| Step: 0
Training loss: 3.194796420254367
Validation loss: 3.1165389650469644

Epoch: 6| Step: 1
Training loss: 3.997640748447752
Validation loss: 3.116197383014819

Epoch: 6| Step: 2
Training loss: 3.717035234819499
Validation loss: 3.1119578807650488

Epoch: 6| Step: 3
Training loss: 3.4477696382611795
Validation loss: 3.1153272634158977

Epoch: 6| Step: 4
Training loss: 2.686676076520749
Validation loss: 3.111134771165764

Epoch: 6| Step: 5
Training loss: 3.319129499731267
Validation loss: 3.1121227671832505

Epoch: 6| Step: 6
Training loss: 3.7034913215849685
Validation loss: 3.1076219043843105

Epoch: 6| Step: 7
Training loss: 3.810233270908141
Validation loss: 3.1067597258601443

Epoch: 6| Step: 8
Training loss: 3.0376053089363695
Validation loss: 3.1040935699077763

Epoch: 6| Step: 9
Training loss: 3.26301843024569
Validation loss: 3.10432910156964

Epoch: 6| Step: 10
Training loss: 3.285635642182674
Validation loss: 3.10348572866952

Epoch: 6| Step: 11
Training loss: 2.567155656019215
Validation loss: 3.105205082781849

Epoch: 6| Step: 12
Training loss: 3.5943470334573746
Validation loss: 3.10352031031835

Epoch: 6| Step: 13
Training loss: 3.2264719065955454
Validation loss: 3.105277030868975

Epoch: 55| Step: 0
Training loss: 3.6713147324390514
Validation loss: 3.103547130160394

Epoch: 6| Step: 1
Training loss: 3.5134773985142704
Validation loss: 3.1048919222506384

Epoch: 6| Step: 2
Training loss: 3.120086163529251
Validation loss: 3.102378896675405

Epoch: 6| Step: 3
Training loss: 3.5196294739085756
Validation loss: 3.1021018309057435

Epoch: 6| Step: 4
Training loss: 3.198707325431943
Validation loss: 3.1012720697517913

Epoch: 6| Step: 5
Training loss: 3.6288970520100063
Validation loss: 3.1000466306515646

Epoch: 6| Step: 6
Training loss: 2.8140542715948897
Validation loss: 3.09781770521149

Epoch: 6| Step: 7
Training loss: 4.209544898146558
Validation loss: 3.0985873925410665

Epoch: 6| Step: 8
Training loss: 3.218656371893718
Validation loss: 3.098302492001915

Epoch: 6| Step: 9
Training loss: 3.260689249720026
Validation loss: 3.098467603699846

Epoch: 6| Step: 10
Training loss: 3.61034152478656
Validation loss: 3.0990198239748903

Epoch: 6| Step: 11
Training loss: 2.873975654228162
Validation loss: 3.097834782763292

Epoch: 6| Step: 12
Training loss: 2.746201753188186
Validation loss: 3.0986012441354056

Epoch: 6| Step: 13
Training loss: 3.5186015773658856
Validation loss: 3.0989446945627943

Epoch: 56| Step: 0
Training loss: 2.4435299357185967
Validation loss: 3.098792942783726

Epoch: 6| Step: 1
Training loss: 3.524731180749166
Validation loss: 3.099439574746803

Epoch: 6| Step: 2
Training loss: 3.4717855831687023
Validation loss: 3.09814192097546

Epoch: 6| Step: 3
Training loss: 3.0047955331409635
Validation loss: 3.0978649297584804

Epoch: 6| Step: 4
Training loss: 3.4995697301966695
Validation loss: 3.0988461858914946

Epoch: 6| Step: 5
Training loss: 3.547684631704559
Validation loss: 3.0966529671315763

Epoch: 6| Step: 6
Training loss: 3.5662836427702884
Validation loss: 3.0976468607893386

Epoch: 6| Step: 7
Training loss: 4.090839545304216
Validation loss: 3.0956257602491988

Epoch: 6| Step: 8
Training loss: 2.9320039670118527
Validation loss: 3.096362559906925

Epoch: 6| Step: 9
Training loss: 3.5917366026923685
Validation loss: 3.093340106889687

Epoch: 6| Step: 10
Training loss: 3.2370100851058003
Validation loss: 3.0978567055476023

Epoch: 6| Step: 11
Training loss: 2.8783453675773014
Validation loss: 3.0970993225152266

Epoch: 6| Step: 12
Training loss: 3.5643026241771767
Validation loss: 3.09673074829397

Epoch: 6| Step: 13
Training loss: 3.4432449884396896
Validation loss: 3.0935168451377013

Epoch: 57| Step: 0
Training loss: 3.277174243931111
Validation loss: 3.092524722049539

Epoch: 6| Step: 1
Training loss: 3.055392991182379
Validation loss: 3.09123595357301

Epoch: 6| Step: 2
Training loss: 2.4842594527718966
Validation loss: 3.090023962030776

Epoch: 6| Step: 3
Training loss: 3.6811481662518575
Validation loss: 3.0932890464832403

Epoch: 6| Step: 4
Training loss: 3.5167185799140226
Validation loss: 3.093825157779812

Epoch: 6| Step: 5
Training loss: 2.893254584135839
Validation loss: 3.090914256421306

Epoch: 6| Step: 6
Training loss: 3.152714779560975
Validation loss: 3.092647773368226

Epoch: 6| Step: 7
Training loss: 3.567356079235311
Validation loss: 3.0933470891959423

Epoch: 6| Step: 8
Training loss: 3.2819811778345342
Validation loss: 3.092018749290534

Epoch: 6| Step: 9
Training loss: 3.9931185657487
Validation loss: 3.091047126988305

Epoch: 6| Step: 10
Training loss: 3.820016549159447
Validation loss: 3.093280349306143

Epoch: 6| Step: 11
Training loss: 3.77523653413556
Validation loss: 3.0926464039477235

Epoch: 6| Step: 12
Training loss: 2.9383480390013745
Validation loss: 3.090710805802988

Epoch: 6| Step: 13
Training loss: 3.2012196898598795
Validation loss: 3.091486268689518

Epoch: 58| Step: 0
Training loss: 3.8495462026304508
Validation loss: 3.088721293433958

Epoch: 6| Step: 1
Training loss: 3.0637276193648777
Validation loss: 3.0899733628777803

Epoch: 6| Step: 2
Training loss: 2.892907143889009
Validation loss: 3.086382088360353

Epoch: 6| Step: 3
Training loss: 3.509130557371264
Validation loss: 3.093864964975611

Epoch: 6| Step: 4
Training loss: 3.2555736285920616
Validation loss: 3.092566087037708

Epoch: 6| Step: 5
Training loss: 3.330164754417556
Validation loss: 3.088695846339658

Epoch: 6| Step: 6
Training loss: 3.931271667905931
Validation loss: 3.0930199895529595

Epoch: 6| Step: 7
Training loss: 3.705727350909641
Validation loss: 3.090726057163282

Epoch: 6| Step: 8
Training loss: 3.140831935764514
Validation loss: 3.091276822460821

Epoch: 6| Step: 9
Training loss: 3.4040345152686298
Validation loss: 3.0883692734248016

Epoch: 6| Step: 10
Training loss: 3.5832320502109796
Validation loss: 3.0918424345131954

Epoch: 6| Step: 11
Training loss: 2.584773052147832
Validation loss: 3.100445640386435

Epoch: 6| Step: 12
Training loss: 2.921764188082974
Validation loss: 3.0976765693296366

Epoch: 6| Step: 13
Training loss: 3.7041540848668855
Validation loss: 3.102310233939993

Epoch: 59| Step: 0
Training loss: 3.719780146142017
Validation loss: 3.101064334362866

Epoch: 6| Step: 1
Training loss: 3.133017516622026
Validation loss: 3.1004751277983087

Epoch: 6| Step: 2
Training loss: 3.060195990375734
Validation loss: 3.090515683442926

Epoch: 6| Step: 3
Training loss: 3.292028254354118
Validation loss: 3.096792173616492

Epoch: 6| Step: 4
Training loss: 3.237493660821195
Validation loss: 3.093811457158103

Epoch: 6| Step: 5
Training loss: 3.4159997118518715
Validation loss: 3.0878165531945796

Epoch: 6| Step: 6
Training loss: 3.1465659056980466
Validation loss: 3.0915854878524565

Epoch: 6| Step: 7
Training loss: 3.239411197190005
Validation loss: 3.0918117354384154

Epoch: 6| Step: 8
Training loss: 3.3096623772326885
Validation loss: 3.088548059143369

Epoch: 6| Step: 9
Training loss: 3.516646851277381
Validation loss: 3.087678103611416

Epoch: 6| Step: 10
Training loss: 3.97810235028288
Validation loss: 3.08535304071668

Epoch: 6| Step: 11
Training loss: 3.261668898150097
Validation loss: 3.0857637904020083

Epoch: 6| Step: 12
Training loss: 3.289638296726711
Validation loss: 3.082796324970897

Epoch: 6| Step: 13
Training loss: 3.237753168171244
Validation loss: 3.0796790286604154

Epoch: 60| Step: 0
Training loss: 3.5669388806812523
Validation loss: 3.0812389712793697

Epoch: 6| Step: 1
Training loss: 3.395958006896866
Validation loss: 3.0796914669179944

Epoch: 6| Step: 2
Training loss: 2.639346925124113
Validation loss: 3.079288279302778

Epoch: 6| Step: 3
Training loss: 3.2442094128393544
Validation loss: 3.0781352099877126

Epoch: 6| Step: 4
Training loss: 3.358482774638927
Validation loss: 3.078242872117677

Epoch: 6| Step: 5
Training loss: 4.2168097661480815
Validation loss: 3.0796236194500777

Epoch: 6| Step: 6
Training loss: 3.407638686696021
Validation loss: 3.0792112647599827

Epoch: 6| Step: 7
Training loss: 2.705428448519268
Validation loss: 3.078185808018281

Epoch: 6| Step: 8
Training loss: 3.0027142008558663
Validation loss: 3.0768013933798968

Epoch: 6| Step: 9
Training loss: 3.5152129207278127
Validation loss: 3.078196791511316

Epoch: 6| Step: 10
Training loss: 3.126517880877741
Validation loss: 3.0798737879286118

Epoch: 6| Step: 11
Training loss: 2.9054446181187275
Validation loss: 3.0793176729340574

Epoch: 6| Step: 12
Training loss: 4.197289027898344
Validation loss: 3.079169205001492

Epoch: 6| Step: 13
Training loss: 3.0260591402495898
Validation loss: 3.0773688337479954

Epoch: 61| Step: 0
Training loss: 3.121819518000089
Validation loss: 3.0814490656709848

Epoch: 6| Step: 1
Training loss: 3.7356802602519315
Validation loss: 3.0764988977146124

Epoch: 6| Step: 2
Training loss: 3.1382777614066057
Validation loss: 3.079653883947462

Epoch: 6| Step: 3
Training loss: 2.971070517068725
Validation loss: 3.080529682389779

Epoch: 6| Step: 4
Training loss: 3.7439714929848495
Validation loss: 3.079337935111311

Epoch: 6| Step: 5
Training loss: 2.956962554415895
Validation loss: 3.077490811676994

Epoch: 6| Step: 6
Training loss: 3.6446547574195898
Validation loss: 3.0773211338845483

Epoch: 6| Step: 7
Training loss: 3.719867826800402
Validation loss: 3.076849365426207

Epoch: 6| Step: 8
Training loss: 3.4433183846113815
Validation loss: 3.0743503041277376

Epoch: 6| Step: 9
Training loss: 3.3085542606667895
Validation loss: 3.0748192927575437

Epoch: 6| Step: 10
Training loss: 3.0579752290569457
Validation loss: 3.074158416409097

Epoch: 6| Step: 11
Training loss: 3.3481130210458514
Validation loss: 3.0762842184720243

Epoch: 6| Step: 12
Training loss: 2.956456480013344
Validation loss: 3.072197470009301

Epoch: 6| Step: 13
Training loss: 3.6309217557427043
Validation loss: 3.0735696478764667

Epoch: 62| Step: 0
Training loss: 3.2693358149848386
Validation loss: 3.0714852251496754

Epoch: 6| Step: 1
Training loss: 3.099976256494962
Validation loss: 3.073577665160756

Epoch: 6| Step: 2
Training loss: 3.3510548311606767
Validation loss: 3.0718420725922

Epoch: 6| Step: 3
Training loss: 3.73969391187359
Validation loss: 3.070675659328188

Epoch: 6| Step: 4
Training loss: 3.067676451193004
Validation loss: 3.0688333616861065

Epoch: 6| Step: 5
Training loss: 3.5212562051270844
Validation loss: 3.0684027985810283

Epoch: 6| Step: 6
Training loss: 2.366587547090112
Validation loss: 3.0694259110376585

Epoch: 6| Step: 7
Training loss: 2.6283088900974207
Validation loss: 3.0683660156151404

Epoch: 6| Step: 8
Training loss: 4.026602024628967
Validation loss: 3.068243631482103

Epoch: 6| Step: 9
Training loss: 3.588758634625301
Validation loss: 3.0678891865902296

Epoch: 6| Step: 10
Training loss: 3.3414250071625444
Validation loss: 3.066123695332425

Epoch: 6| Step: 11
Training loss: 2.9963467925045237
Validation loss: 3.06736569077381

Epoch: 6| Step: 12
Training loss: 3.8532045280373706
Validation loss: 3.0646759081682147

Epoch: 6| Step: 13
Training loss: 3.6588768285228284
Validation loss: 3.064514291306157

Epoch: 63| Step: 0
Training loss: 2.9024239242795784
Validation loss: 3.065556482416126

Epoch: 6| Step: 1
Training loss: 3.7310541302821782
Validation loss: 3.065958168801745

Epoch: 6| Step: 2
Training loss: 2.8986543229842487
Validation loss: 3.0619090508145588

Epoch: 6| Step: 3
Training loss: 3.4088749002166607
Validation loss: 3.063562051238215

Epoch: 6| Step: 4
Training loss: 3.012413251585452
Validation loss: 3.06458641002959

Epoch: 6| Step: 5
Training loss: 2.91827693266717
Validation loss: 3.0632139942783305

Epoch: 6| Step: 6
Training loss: 3.9241005711319885
Validation loss: 3.063946496803737

Epoch: 6| Step: 7
Training loss: 3.5932358083660367
Validation loss: 3.0597520025830978

Epoch: 6| Step: 8
Training loss: 2.999197375695115
Validation loss: 3.0601302876015257

Epoch: 6| Step: 9
Training loss: 3.4487674888839366
Validation loss: 3.0574456789796653

Epoch: 6| Step: 10
Training loss: 3.2384343864575404
Validation loss: 3.059653066597387

Epoch: 6| Step: 11
Training loss: 3.5316607481141937
Validation loss: 3.0606322428658888

Epoch: 6| Step: 12
Training loss: 3.4716535907950234
Validation loss: 3.0622386456711297

Epoch: 6| Step: 13
Training loss: 3.4019260785180463
Validation loss: 3.057723294094706

Epoch: 64| Step: 0
Training loss: 3.9551838575759035
Validation loss: 3.0598361727366648

Epoch: 6| Step: 1
Training loss: 3.493799985142487
Validation loss: 3.0562848378343754

Epoch: 6| Step: 2
Training loss: 3.299406842184502
Validation loss: 3.0538022217988203

Epoch: 6| Step: 3
Training loss: 3.392131277467996
Validation loss: 3.0583841736124113

Epoch: 6| Step: 4
Training loss: 3.0787227456872457
Validation loss: 3.054707912123731

Epoch: 6| Step: 5
Training loss: 2.773269003464354
Validation loss: 3.0533154727698033

Epoch: 6| Step: 6
Training loss: 3.110515289548681
Validation loss: 3.0600850468006606

Epoch: 6| Step: 7
Training loss: 2.7616391527934456
Validation loss: 3.058333798706023

Epoch: 6| Step: 8
Training loss: 3.850349281617721
Validation loss: 3.0593484580687234

Epoch: 6| Step: 9
Training loss: 3.5201522499450175
Validation loss: 3.0558803455338746

Epoch: 6| Step: 10
Training loss: 2.9310883695047805
Validation loss: 3.0538511654329317

Epoch: 6| Step: 11
Training loss: 3.9490685439103173
Validation loss: 3.0543263787376915

Epoch: 6| Step: 12
Training loss: 2.7883074082900183
Validation loss: 3.05470013233606

Epoch: 6| Step: 13
Training loss: 3.3453804390506057
Validation loss: 3.051868993270446

Epoch: 65| Step: 0
Training loss: 3.4458552687722093
Validation loss: 3.0534256329682186

Epoch: 6| Step: 1
Training loss: 2.900723031772538
Validation loss: 3.053790895360143

Epoch: 6| Step: 2
Training loss: 2.6641859993597614
Validation loss: 3.0520990081443955

Epoch: 6| Step: 3
Training loss: 3.323546649842484
Validation loss: 3.054893645943776

Epoch: 6| Step: 4
Training loss: 3.2570248024323774
Validation loss: 3.0536565094829786

Epoch: 6| Step: 5
Training loss: 3.0640790332929773
Validation loss: 3.0558701257873815

Epoch: 6| Step: 6
Training loss: 3.669816239457267
Validation loss: 3.05287531454806

Epoch: 6| Step: 7
Training loss: 3.7124327528286494
Validation loss: 3.0540440377900415

Epoch: 6| Step: 8
Training loss: 3.5874900365817384
Validation loss: 3.0517951560215186

Epoch: 6| Step: 9
Training loss: 3.4902290468009833
Validation loss: 3.050801927749784

Epoch: 6| Step: 10
Training loss: 3.5201349111192415
Validation loss: 3.048863155067601

Epoch: 6| Step: 11
Training loss: 3.2573997181162744
Validation loss: 3.050150900862816

Epoch: 6| Step: 12
Training loss: 3.0933091591296007
Validation loss: 3.0508101804915957

Epoch: 6| Step: 13
Training loss: 3.4384839123661153
Validation loss: 3.044293578341775

Epoch: 66| Step: 0
Training loss: 3.6135697203260415
Validation loss: 3.047633464721633

Epoch: 6| Step: 1
Training loss: 3.3904497655070425
Validation loss: 3.0462381804381766

Epoch: 6| Step: 2
Training loss: 3.204336095595716
Validation loss: 3.048865420320239

Epoch: 6| Step: 3
Training loss: 4.098035592992763
Validation loss: 3.043901705931983

Epoch: 6| Step: 4
Training loss: 3.2167869433381138
Validation loss: 3.044435999977627

Epoch: 6| Step: 5
Training loss: 3.7860854576126766
Validation loss: 3.0490078940980445

Epoch: 6| Step: 6
Training loss: 2.4756306239803143
Validation loss: 3.046228636952532

Epoch: 6| Step: 7
Training loss: 3.429231582960351
Validation loss: 3.0461587514692887

Epoch: 6| Step: 8
Training loss: 2.2159913872506682
Validation loss: 3.044331197002374

Epoch: 6| Step: 9
Training loss: 3.0813872579524437
Validation loss: 3.047296232939028

Epoch: 6| Step: 10
Training loss: 3.63881117533108
Validation loss: 3.0460963211015266

Epoch: 6| Step: 11
Training loss: 3.424090360705863
Validation loss: 3.0443281174299037

Epoch: 6| Step: 12
Training loss: 3.3222417993156546
Validation loss: 3.0437676060938403

Epoch: 6| Step: 13
Training loss: 2.8635595168224244
Validation loss: 3.0484055285892993

Epoch: 67| Step: 0
Training loss: 4.063360035166786
Validation loss: 3.049039874192421

Epoch: 6| Step: 1
Training loss: 2.9090228235340123
Validation loss: 3.0477268135781053

Epoch: 6| Step: 2
Training loss: 3.141308914038925
Validation loss: 3.0480149931215514

Epoch: 6| Step: 3
Training loss: 2.384990359752693
Validation loss: 3.0481683342559247

Epoch: 6| Step: 4
Training loss: 3.509589817609205
Validation loss: 3.042538468358385

Epoch: 6| Step: 5
Training loss: 3.0223203660263187
Validation loss: 3.0408199897370176

Epoch: 6| Step: 6
Training loss: 2.8515367480643703
Validation loss: 3.040572681206008

Epoch: 6| Step: 7
Training loss: 2.5673779835443367
Validation loss: 3.040331825894448

Epoch: 6| Step: 8
Training loss: 3.426644402467509
Validation loss: 3.038903970134739

Epoch: 6| Step: 9
Training loss: 3.358325883148739
Validation loss: 3.0392058517128193

Epoch: 6| Step: 10
Training loss: 3.9171908548627563
Validation loss: 3.0423543615925355

Epoch: 6| Step: 11
Training loss: 3.535510573360411
Validation loss: 3.0399920047553404

Epoch: 6| Step: 12
Training loss: 3.9253145614240816
Validation loss: 3.0405836614505914

Epoch: 6| Step: 13
Training loss: 3.3117484913665107
Validation loss: 3.0408384538760607

Epoch: 68| Step: 0
Training loss: 3.73524292632058
Validation loss: 3.041879174235419

Epoch: 6| Step: 1
Training loss: 3.503271481312481
Validation loss: 3.0375156478650958

Epoch: 6| Step: 2
Training loss: 2.32073518647111
Validation loss: 3.0368014432197783

Epoch: 6| Step: 3
Training loss: 3.683961237095654
Validation loss: 3.03665730261706

Epoch: 6| Step: 4
Training loss: 2.9025990513765
Validation loss: 3.036386239982998

Epoch: 6| Step: 5
Training loss: 3.2544964716428173
Validation loss: 3.0348530532903113

Epoch: 6| Step: 6
Training loss: 2.807248022604825
Validation loss: 3.0374917703774726

Epoch: 6| Step: 7
Training loss: 3.42300981490444
Validation loss: 3.0339438766545377

Epoch: 6| Step: 8
Training loss: 3.7169867430484667
Validation loss: 3.0354407244704205

Epoch: 6| Step: 9
Training loss: 3.3830464834999656
Validation loss: 3.0340216164992464

Epoch: 6| Step: 10
Training loss: 3.363683873621324
Validation loss: 3.0332967472225194

Epoch: 6| Step: 11
Training loss: 3.6019490793749647
Validation loss: 3.0312754811064955

Epoch: 6| Step: 12
Training loss: 3.17542748164119
Validation loss: 3.0361269322530617

Epoch: 6| Step: 13
Training loss: 3.1020379843043338
Validation loss: 3.033052768283121

Epoch: 69| Step: 0
Training loss: 3.896916216867093
Validation loss: 3.0319216556762507

Epoch: 6| Step: 1
Training loss: 3.3412079462158526
Validation loss: 3.035927512185319

Epoch: 6| Step: 2
Training loss: 3.5635976606153457
Validation loss: 3.03212161652786

Epoch: 6| Step: 3
Training loss: 2.8550395512555338
Validation loss: 3.032295135678566

Epoch: 6| Step: 4
Training loss: 3.652426130212316
Validation loss: 3.03186805918529

Epoch: 6| Step: 5
Training loss: 3.5855386882073033
Validation loss: 3.031080134015003

Epoch: 6| Step: 6
Training loss: 2.7421342893475202
Validation loss: 3.0307721090177577

Epoch: 6| Step: 7
Training loss: 3.1596323151891426
Validation loss: 3.0307210569212923

Epoch: 6| Step: 8
Training loss: 3.3469379949829876
Validation loss: 3.0308655035210985

Epoch: 6| Step: 9
Training loss: 3.308207627862165
Validation loss: 3.031507355337206

Epoch: 6| Step: 10
Training loss: 2.6874875800267155
Validation loss: 3.0299936288789446

Epoch: 6| Step: 11
Training loss: 3.12593949500633
Validation loss: 3.031021161961933

Epoch: 6| Step: 12
Training loss: 3.2066791448000083
Validation loss: 3.030802340277665

Epoch: 6| Step: 13
Training loss: 3.827183946433574
Validation loss: 3.0292749088143345

Epoch: 70| Step: 0
Training loss: 4.659338010337958
Validation loss: 3.028652064432937

Epoch: 6| Step: 1
Training loss: 2.763859761998894
Validation loss: 3.028237740062607

Epoch: 6| Step: 2
Training loss: 2.92402023469157
Validation loss: 3.0288586162667492

Epoch: 6| Step: 3
Training loss: 2.9948294905333364
Validation loss: 3.0296128823697375

Epoch: 6| Step: 4
Training loss: 3.272556377534331
Validation loss: 3.0266179361423373

Epoch: 6| Step: 5
Training loss: 3.578916237314841
Validation loss: 3.029713894263799

Epoch: 6| Step: 6
Training loss: 2.92180906823173
Validation loss: 3.028297409706086

Epoch: 6| Step: 7
Training loss: 3.706588220200736
Validation loss: 3.0296160200559448

Epoch: 6| Step: 8
Training loss: 3.3856623320821413
Validation loss: 3.0325650913567133

Epoch: 6| Step: 9
Training loss: 3.173001845567553
Validation loss: 3.0298475550683746

Epoch: 6| Step: 10
Training loss: 3.089570738718947
Validation loss: 3.0299997934683653

Epoch: 6| Step: 11
Training loss: 2.983108651280036
Validation loss: 3.031254101822242

Epoch: 6| Step: 12
Training loss: 3.2736128803331654
Validation loss: 3.0272565703024013

Epoch: 6| Step: 13
Training loss: 2.95063507227036
Validation loss: 3.0278137032798877

Epoch: 71| Step: 0
Training loss: 3.3635486314846563
Validation loss: 3.0294888091534773

Epoch: 6| Step: 1
Training loss: 3.0847725129917083
Validation loss: 3.027586900233052

Epoch: 6| Step: 2
Training loss: 3.425847225793576
Validation loss: 3.028195935733077

Epoch: 6| Step: 3
Training loss: 3.563562335181417
Validation loss: 3.025853785105184

Epoch: 6| Step: 4
Training loss: 2.918559595469088
Validation loss: 3.025620622666101

Epoch: 6| Step: 5
Training loss: 4.033276662086866
Validation loss: 3.0251982918583

Epoch: 6| Step: 6
Training loss: 3.528690457032571
Validation loss: 3.0287057110631075

Epoch: 6| Step: 7
Training loss: 2.7992059807961267
Validation loss: 3.0258954997911

Epoch: 6| Step: 8
Training loss: 3.1402693969428763
Validation loss: 3.0251769213193604

Epoch: 6| Step: 9
Training loss: 2.7368065186457207
Validation loss: 3.0253389702686495

Epoch: 6| Step: 10
Training loss: 3.5700731593738033
Validation loss: 3.0251578234651757

Epoch: 6| Step: 11
Training loss: 3.2370270254699833
Validation loss: 3.0246429155987653

Epoch: 6| Step: 12
Training loss: 3.22763095557534
Validation loss: 3.0252824454679055

Epoch: 6| Step: 13
Training loss: 3.457910458245507
Validation loss: 3.0250004547940517

Epoch: 72| Step: 0
Training loss: 3.6698346901648318
Validation loss: 3.026072759611341

Epoch: 6| Step: 1
Training loss: 3.532088998694986
Validation loss: 3.027758342340228

Epoch: 6| Step: 2
Training loss: 3.372527028874022
Validation loss: 3.0242999269924367

Epoch: 6| Step: 3
Training loss: 3.0898224532096337
Validation loss: 3.0266376668290556

Epoch: 6| Step: 4
Training loss: 3.7581297171528374
Validation loss: 3.025431194504893

Epoch: 6| Step: 5
Training loss: 3.075950047805432
Validation loss: 3.026135687789728

Epoch: 6| Step: 6
Training loss: 3.4018286611837567
Validation loss: 3.025847796768923

Epoch: 6| Step: 7
Training loss: 3.647602778157413
Validation loss: 3.025100754602598

Epoch: 6| Step: 8
Training loss: 3.490276180586926
Validation loss: 3.0248900323437975

Epoch: 6| Step: 9
Training loss: 2.7684708086389738
Validation loss: 3.0247096468902313

Epoch: 6| Step: 10
Training loss: 3.046671229664441
Validation loss: 3.027890897350416

Epoch: 6| Step: 11
Training loss: 3.0251683842476864
Validation loss: 3.025974266082875

Epoch: 6| Step: 12
Training loss: 3.0280678947426027
Validation loss: 3.0257032580526135

Epoch: 6| Step: 13
Training loss: 2.926916495531426
Validation loss: 3.026656711300528

Epoch: 73| Step: 0
Training loss: 2.982931217251009
Validation loss: 3.0249903392035766

Epoch: 6| Step: 1
Training loss: 3.399095072652021
Validation loss: 3.0259221485625054

Epoch: 6| Step: 2
Training loss: 3.963330510948295
Validation loss: 3.0253506676114155

Epoch: 6| Step: 3
Training loss: 3.534266980693495
Validation loss: 3.0245214458163217

Epoch: 6| Step: 4
Training loss: 3.6992727595961528
Validation loss: 3.0223125283164407

Epoch: 6| Step: 5
Training loss: 2.926014624787897
Validation loss: 3.01986824944849

Epoch: 6| Step: 6
Training loss: 3.199574954891317
Validation loss: 3.0200837107265097

Epoch: 6| Step: 7
Training loss: 3.753263960401042
Validation loss: 3.0185690031671175

Epoch: 6| Step: 8
Training loss: 2.5715080657660407
Validation loss: 3.016200697610469

Epoch: 6| Step: 9
Training loss: 2.699850314900786
Validation loss: 3.0197079784062724

Epoch: 6| Step: 10
Training loss: 3.003316952924976
Validation loss: 3.0200087245366114

Epoch: 6| Step: 11
Training loss: 3.4834419677683823
Validation loss: 3.017797575968587

Epoch: 6| Step: 12
Training loss: 3.530039622054739
Validation loss: 3.017414189424287

Epoch: 6| Step: 13
Training loss: 2.8848074443164644
Validation loss: 3.0179357604348818

Epoch: 74| Step: 0
Training loss: 3.0980836975041077
Validation loss: 3.0173370714257137

Epoch: 6| Step: 1
Training loss: 3.420247984478551
Validation loss: 3.0197609078085335

Epoch: 6| Step: 2
Training loss: 3.758866192132144
Validation loss: 3.0196403657008686

Epoch: 6| Step: 3
Training loss: 3.8065979095458053
Validation loss: 3.0186840806253357

Epoch: 6| Step: 4
Training loss: 3.186791883612805
Validation loss: 3.0168958814016564

Epoch: 6| Step: 5
Training loss: 3.3750933881484144
Validation loss: 3.016554198624259

Epoch: 6| Step: 6
Training loss: 3.4348758738383482
Validation loss: 3.0169466533478744

Epoch: 6| Step: 7
Training loss: 3.4717053719601934
Validation loss: 3.0162632155433267

Epoch: 6| Step: 8
Training loss: 2.543351433199185
Validation loss: 3.015708346232336

Epoch: 6| Step: 9
Training loss: 2.871027316408275
Validation loss: 3.0156461814949624

Epoch: 6| Step: 10
Training loss: 3.2245051218667378
Validation loss: 3.0186323561432618

Epoch: 6| Step: 11
Training loss: 3.3033023032364723
Validation loss: 3.0156584486035363

Epoch: 6| Step: 12
Training loss: 3.333380762398575
Validation loss: 3.0173523860902973

Epoch: 6| Step: 13
Training loss: 2.840358010681966
Validation loss: 3.018213963757206

Epoch: 75| Step: 0
Training loss: 3.1809418474702276
Validation loss: 3.023910261223675

Epoch: 6| Step: 1
Training loss: 2.8942248224694027
Validation loss: 3.01820395452933

Epoch: 6| Step: 2
Training loss: 2.616193257977311
Validation loss: 3.0163259914065064

Epoch: 6| Step: 3
Training loss: 3.432518974190632
Validation loss: 3.019483150969384

Epoch: 6| Step: 4
Training loss: 3.1800709336244846
Validation loss: 3.0175621139813646

Epoch: 6| Step: 5
Training loss: 3.217374933830956
Validation loss: 3.01635791429316

Epoch: 6| Step: 6
Training loss: 3.5723224883561997
Validation loss: 3.013555002567784

Epoch: 6| Step: 7
Training loss: 3.0657373561354206
Validation loss: 3.012772237024626

Epoch: 6| Step: 8
Training loss: 3.5963516769382147
Validation loss: 3.0176964281287453

Epoch: 6| Step: 9
Training loss: 3.7048480053405406
Validation loss: 3.0096580797746655

Epoch: 6| Step: 10
Training loss: 3.477768043921529
Validation loss: 3.013267129598602

Epoch: 6| Step: 11
Training loss: 3.2010935226263832
Validation loss: 3.0156316088192203

Epoch: 6| Step: 12
Training loss: 3.750978087981335
Validation loss: 3.0124206861354574

Epoch: 6| Step: 13
Training loss: 2.700312832970384
Validation loss: 3.012706349247725

Epoch: 76| Step: 0
Training loss: 3.0757864961974244
Validation loss: 3.0213925113894904

Epoch: 6| Step: 1
Training loss: 3.6393626893883644
Validation loss: 3.0173819064269227

Epoch: 6| Step: 2
Training loss: 3.024318202085121
Validation loss: 3.010222703422213

Epoch: 6| Step: 3
Training loss: 3.9352089407874913
Validation loss: 3.0106349189932433

Epoch: 6| Step: 4
Training loss: 3.481510781291861
Validation loss: 3.009636483043024

Epoch: 6| Step: 5
Training loss: 3.0837298645178595
Validation loss: 3.0140903705409468

Epoch: 6| Step: 6
Training loss: 3.3137918508355444
Validation loss: 3.013814598755575

Epoch: 6| Step: 7
Training loss: 3.557000717544805
Validation loss: 3.0067156096341354

Epoch: 6| Step: 8
Training loss: 3.1274718617393953
Validation loss: 2.9997418166054777

Epoch: 6| Step: 9
Training loss: 2.2605230303466364
Validation loss: 3.0017521844651958

Epoch: 6| Step: 10
Training loss: 3.850147660631601
Validation loss: 2.998797618388705

Epoch: 6| Step: 11
Training loss: 2.885871731969622
Validation loss: 2.9984116665049836

Epoch: 6| Step: 12
Training loss: 3.1642225436954137
Validation loss: 2.9989143871836585

Epoch: 6| Step: 13
Training loss: 3.2487947723485635
Validation loss: 3.0091481454818445

Epoch: 77| Step: 0
Training loss: 3.677653987935851
Validation loss: 3.007430546191242

Epoch: 6| Step: 1
Training loss: 2.8395730667507073
Validation loss: 2.999334776010543

Epoch: 6| Step: 2
Training loss: 3.1535763133057007
Validation loss: 2.9990502258906546

Epoch: 6| Step: 3
Training loss: 3.8717796726514706
Validation loss: 2.999606270743204

Epoch: 6| Step: 4
Training loss: 2.7840971357456423
Validation loss: 2.9946609264511217

Epoch: 6| Step: 5
Training loss: 3.4986220780919592
Validation loss: 2.993395132603114

Epoch: 6| Step: 6
Training loss: 2.8613462896714377
Validation loss: 2.9941206510523086

Epoch: 6| Step: 7
Training loss: 2.779451281506753
Validation loss: 2.999537208369245

Epoch: 6| Step: 8
Training loss: 2.874693481027722
Validation loss: 2.9991751642697757

Epoch: 6| Step: 9
Training loss: 3.0477528407894297
Validation loss: 2.999894996569231

Epoch: 6| Step: 10
Training loss: 3.07742472007275
Validation loss: 2.9950650055186623

Epoch: 6| Step: 11
Training loss: 4.626469352941404
Validation loss: 2.9982243071641794

Epoch: 6| Step: 12
Training loss: 3.331151311675784
Validation loss: 2.9942933706058494

Epoch: 6| Step: 13
Training loss: 2.656985282107742
Validation loss: 2.994818221835428

Epoch: 78| Step: 0
Training loss: 3.4347685625716
Validation loss: 2.9949093135430136

Epoch: 6| Step: 1
Training loss: 3.5744443394911896
Validation loss: 2.9897743316438716

Epoch: 6| Step: 2
Training loss: 3.156685676342913
Validation loss: 2.9904897521330938

Epoch: 6| Step: 3
Training loss: 3.2892055888096356
Validation loss: 2.987879491644813

Epoch: 6| Step: 4
Training loss: 3.3136888206126893
Validation loss: 2.989984460907534

Epoch: 6| Step: 5
Training loss: 3.2675695151280024
Validation loss: 2.9902235845283482

Epoch: 6| Step: 6
Training loss: 3.70025832846677
Validation loss: 2.990017128025347

Epoch: 6| Step: 7
Training loss: 3.0147109153410003
Validation loss: 2.9904643829977977

Epoch: 6| Step: 8
Training loss: 2.586070261886568
Validation loss: 2.991435916993818

Epoch: 6| Step: 9
Training loss: 3.6288101955549794
Validation loss: 2.9900572043467855

Epoch: 6| Step: 10
Training loss: 3.1293047438091524
Validation loss: 2.9924997039229226

Epoch: 6| Step: 11
Training loss: 3.46007490925927
Validation loss: 2.988662880449241

Epoch: 6| Step: 12
Training loss: 2.8631921522738017
Validation loss: 2.990241098234617

Epoch: 6| Step: 13
Training loss: 3.1819978985255006
Validation loss: 2.990718322683798

Epoch: 79| Step: 0
Training loss: 3.5078100531554663
Validation loss: 2.9874513448881683

Epoch: 6| Step: 1
Training loss: 2.709488979172877
Validation loss: 2.9890251746259224

Epoch: 6| Step: 2
Training loss: 2.668331272411166
Validation loss: 2.987906313023251

Epoch: 6| Step: 3
Training loss: 3.77473986405153
Validation loss: 2.9859316519551635

Epoch: 6| Step: 4
Training loss: 3.1655209794422565
Validation loss: 2.9869341150565396

Epoch: 6| Step: 5
Training loss: 3.4399726990791883
Validation loss: 2.9881803817931414

Epoch: 6| Step: 6
Training loss: 3.3862443743518558
Validation loss: 2.992955701701072

Epoch: 6| Step: 7
Training loss: 2.514567846099349
Validation loss: 2.9938336957902716

Epoch: 6| Step: 8
Training loss: 3.3098545667155252
Validation loss: 2.9876543627560848

Epoch: 6| Step: 9
Training loss: 2.989229418355835
Validation loss: 2.990955727371071

Epoch: 6| Step: 10
Training loss: 3.410968417256024
Validation loss: 2.9885545483767637

Epoch: 6| Step: 11
Training loss: 4.089353573926799
Validation loss: 2.98803431958305

Epoch: 6| Step: 12
Training loss: 3.4654693210814096
Validation loss: 2.9859310354996045

Epoch: 6| Step: 13
Training loss: 2.6652436532579324
Validation loss: 2.9876057144829353

Epoch: 80| Step: 0
Training loss: 2.908860869415584
Validation loss: 2.9871637034684846

Epoch: 6| Step: 1
Training loss: 3.0903100820464995
Validation loss: 2.985704121411041

Epoch: 6| Step: 2
Training loss: 3.15192653537474
Validation loss: 2.983777901811974

Epoch: 6| Step: 3
Training loss: 3.682656679672559
Validation loss: 2.984253576637198

Epoch: 6| Step: 4
Training loss: 3.1846525151821594
Validation loss: 2.9874705756621953

Epoch: 6| Step: 5
Training loss: 3.122216167270616
Validation loss: 2.987281001679687

Epoch: 6| Step: 6
Training loss: 3.012944111991602
Validation loss: 2.9864732645914693

Epoch: 6| Step: 7
Training loss: 3.663649676070927
Validation loss: 2.9877104650885316

Epoch: 6| Step: 8
Training loss: 3.941897404203168
Validation loss: 2.990352145159469

Epoch: 6| Step: 9
Training loss: 3.529526281368935
Validation loss: 2.9906286403267686

Epoch: 6| Step: 10
Training loss: 2.5285316281730847
Validation loss: 2.9865940431951947

Epoch: 6| Step: 11
Training loss: 3.1031336420251954
Validation loss: 2.984083700370822

Epoch: 6| Step: 12
Training loss: 2.917141921060726
Validation loss: 2.9834144290698026

Epoch: 6| Step: 13
Training loss: 3.8723124136166884
Validation loss: 2.9801125763372585

Epoch: 81| Step: 0
Training loss: 2.70508217931781
Validation loss: 2.979622879453404

Epoch: 6| Step: 1
Training loss: 2.9538424795995994
Validation loss: 2.9778709000295476

Epoch: 6| Step: 2
Training loss: 3.157577688631146
Validation loss: 2.981559579497094

Epoch: 6| Step: 3
Training loss: 3.4710361404669547
Validation loss: 2.9808083338111455

Epoch: 6| Step: 4
Training loss: 2.791404702340697
Validation loss: 2.9826441042983323

Epoch: 6| Step: 5
Training loss: 3.087199819698363
Validation loss: 2.981954663367728

Epoch: 6| Step: 6
Training loss: 3.3095847202954314
Validation loss: 2.9816757078786944

Epoch: 6| Step: 7
Training loss: 3.2412758154379833
Validation loss: 2.97820176919796

Epoch: 6| Step: 8
Training loss: 3.332455964652445
Validation loss: 2.9775512386397507

Epoch: 6| Step: 9
Training loss: 3.658656836060903
Validation loss: 2.9789211058114495

Epoch: 6| Step: 10
Training loss: 3.8720410031992873
Validation loss: 2.980272019334321

Epoch: 6| Step: 11
Training loss: 2.7243087766806946
Validation loss: 2.98426941157255

Epoch: 6| Step: 12
Training loss: 3.8358422790020814
Validation loss: 2.9839659079048326

Epoch: 6| Step: 13
Training loss: 3.3328089460522983
Validation loss: 2.9869848409836752

Epoch: 82| Step: 0
Training loss: 3.6694960659290334
Validation loss: 2.982823263169425

Epoch: 6| Step: 1
Training loss: 2.8222439986195633
Validation loss: 2.9788782023264577

Epoch: 6| Step: 2
Training loss: 3.307382481246809
Validation loss: 2.9815575451336507

Epoch: 6| Step: 3
Training loss: 3.4079847205719473
Validation loss: 2.976194472273621

Epoch: 6| Step: 4
Training loss: 2.90727986782463
Validation loss: 2.9777932047680276

Epoch: 6| Step: 5
Training loss: 3.1328421802969824
Validation loss: 2.978037592605213

Epoch: 6| Step: 6
Training loss: 3.177644940543871
Validation loss: 2.97751966253991

Epoch: 6| Step: 7
Training loss: 2.5514842257900727
Validation loss: 2.980315923801224

Epoch: 6| Step: 8
Training loss: 3.5697871850531686
Validation loss: 2.981914170366524

Epoch: 6| Step: 9
Training loss: 3.963951032888486
Validation loss: 2.9789355577258285

Epoch: 6| Step: 10
Training loss: 2.87200921443428
Validation loss: 2.9787670917087854

Epoch: 6| Step: 11
Training loss: 3.4365328728735203
Validation loss: 2.9775611925238223

Epoch: 6| Step: 12
Training loss: 2.809179762186695
Validation loss: 2.9804131117455563

Epoch: 6| Step: 13
Training loss: 4.082079143334471
Validation loss: 2.9771727597209057

Epoch: 83| Step: 0
Training loss: 3.0055197163825036
Validation loss: 2.9768443287607114

Epoch: 6| Step: 1
Training loss: 3.5425585053969337
Validation loss: 2.976853639115069

Epoch: 6| Step: 2
Training loss: 3.3652114203185484
Validation loss: 2.9768472163429736

Epoch: 6| Step: 3
Training loss: 3.2864064707747125
Validation loss: 2.9774588478568513

Epoch: 6| Step: 4
Training loss: 3.9820159510662307
Validation loss: 2.9781222688116875

Epoch: 6| Step: 5
Training loss: 3.061853768811782
Validation loss: 2.9807058589550732

Epoch: 6| Step: 6
Training loss: 2.318556201167268
Validation loss: 2.9778165752006993

Epoch: 6| Step: 7
Training loss: 2.740464149896228
Validation loss: 2.982638030068158

Epoch: 6| Step: 8
Training loss: 3.590015892907457
Validation loss: 2.9831807906730714

Epoch: 6| Step: 9
Training loss: 3.146610913375427
Validation loss: 2.981691307164109

Epoch: 6| Step: 10
Training loss: 3.258438306387464
Validation loss: 2.9831260091000025

Epoch: 6| Step: 11
Training loss: 3.638598225821339
Validation loss: 2.9851587846154706

Epoch: 6| Step: 12
Training loss: 2.9597576276679436
Validation loss: 2.9754900014414813

Epoch: 6| Step: 13
Training loss: 3.527808073285864
Validation loss: 2.9735474592607845

Epoch: 84| Step: 0
Training loss: 2.821777808457848
Validation loss: 2.97236176210731

Epoch: 6| Step: 1
Training loss: 3.1219641625976338
Validation loss: 2.970520906689734

Epoch: 6| Step: 2
Training loss: 2.8769249484151436
Validation loss: 2.9710913949410327

Epoch: 6| Step: 3
Training loss: 4.050782191718791
Validation loss: 2.969671708844522

Epoch: 6| Step: 4
Training loss: 2.6550510168831405
Validation loss: 2.9755505048441377

Epoch: 6| Step: 5
Training loss: 3.505911058985328
Validation loss: 2.9789187684381355

Epoch: 6| Step: 6
Training loss: 3.6167241040662863
Validation loss: 2.98543788436745

Epoch: 6| Step: 7
Training loss: 3.141608392662376
Validation loss: 2.9901026207276433

Epoch: 6| Step: 8
Training loss: 2.417834843639185
Validation loss: 2.9979700070429742

Epoch: 6| Step: 9
Training loss: 3.4633215965779502
Validation loss: 3.022372515119538

Epoch: 6| Step: 10
Training loss: 2.902253386989158
Validation loss: 2.994722015869231

Epoch: 6| Step: 11
Training loss: 3.304204810853569
Validation loss: 2.991166383876035

Epoch: 6| Step: 12
Training loss: 4.00252786868494
Validation loss: 2.9914009000413015

Epoch: 6| Step: 13
Training loss: 3.3478241814920784
Validation loss: 2.984135976440108

Epoch: 85| Step: 0
Training loss: 3.884364717796754
Validation loss: 2.972121441196645

Epoch: 6| Step: 1
Training loss: 2.481051254960774
Validation loss: 2.970103576921275

Epoch: 6| Step: 2
Training loss: 3.0151401584621067
Validation loss: 2.970612084987598

Epoch: 6| Step: 3
Training loss: 3.613295898407807
Validation loss: 2.9718592684113228

Epoch: 6| Step: 4
Training loss: 3.4372250533686155
Validation loss: 2.9680185691759644

Epoch: 6| Step: 5
Training loss: 2.9426934616028153
Validation loss: 2.9704465412855896

Epoch: 6| Step: 6
Training loss: 3.245824038321261
Validation loss: 2.969314781398872

Epoch: 6| Step: 7
Training loss: 3.670906620975515
Validation loss: 2.9667190348957675

Epoch: 6| Step: 8
Training loss: 3.026839360703328
Validation loss: 2.9726035297080378

Epoch: 6| Step: 9
Training loss: 2.8938717315973057
Validation loss: 2.96669385394527

Epoch: 6| Step: 10
Training loss: 3.1980419486457414
Validation loss: 2.9727618844009265

Epoch: 6| Step: 11
Training loss: 3.151619564479734
Validation loss: 2.9774249081224378

Epoch: 6| Step: 12
Training loss: 2.971948446655843
Validation loss: 2.974809398148353

Epoch: 6| Step: 13
Training loss: 4.087591533044321
Validation loss: 2.972427430721626

Epoch: 86| Step: 0
Training loss: 3.6180376738637023
Validation loss: 2.976615781476474

Epoch: 6| Step: 1
Training loss: 3.818372112750493
Validation loss: 2.9754039725553034

Epoch: 6| Step: 2
Training loss: 3.6547110163342653
Validation loss: 2.967086566033726

Epoch: 6| Step: 3
Training loss: 2.4572652878153285
Validation loss: 2.9684280523178606

Epoch: 6| Step: 4
Training loss: 3.378840627749692
Validation loss: 2.9636318022158443

Epoch: 6| Step: 5
Training loss: 3.1609187579577522
Validation loss: 2.9647622649103265

Epoch: 6| Step: 6
Training loss: 3.166265629587855
Validation loss: 2.9655175219036694

Epoch: 6| Step: 7
Training loss: 2.5390465369089545
Validation loss: 2.9640910111663823

Epoch: 6| Step: 8
Training loss: 3.720213145435775
Validation loss: 2.965386355260784

Epoch: 6| Step: 9
Training loss: 3.1440053180135155
Validation loss: 2.9630866218328227

Epoch: 6| Step: 10
Training loss: 3.1294437094478993
Validation loss: 2.964193324408828

Epoch: 6| Step: 11
Training loss: 2.0477782142175514
Validation loss: 2.9640294227676955

Epoch: 6| Step: 12
Training loss: 3.719996652088915
Validation loss: 2.964109083184946

Epoch: 6| Step: 13
Training loss: 3.5356137480210297
Validation loss: 2.9634533041087576

Epoch: 87| Step: 0
Training loss: 2.9342441777489006
Validation loss: 2.965343682166251

Epoch: 6| Step: 1
Training loss: 3.280207004993049
Validation loss: 2.968740754040243

Epoch: 6| Step: 2
Training loss: 2.9796824686761076
Validation loss: 2.970933766656401

Epoch: 6| Step: 3
Training loss: 2.694930162816561
Validation loss: 2.9752738957537206

Epoch: 6| Step: 4
Training loss: 3.009003480218946
Validation loss: 2.9671268967762354

Epoch: 6| Step: 5
Training loss: 3.783446627585628
Validation loss: 2.971696266644955

Epoch: 6| Step: 6
Training loss: 3.2313507241463912
Validation loss: 2.9704855939918366

Epoch: 6| Step: 7
Training loss: 3.3725749592972876
Validation loss: 2.9744652475437503

Epoch: 6| Step: 8
Training loss: 3.291220059256839
Validation loss: 2.974038894384257

Epoch: 6| Step: 9
Training loss: 3.266411937461414
Validation loss: 2.9728028901310264

Epoch: 6| Step: 10
Training loss: 3.2592397074723056
Validation loss: 2.9662748475094065

Epoch: 6| Step: 11
Training loss: 3.4006253621052633
Validation loss: 2.963754902569173

Epoch: 6| Step: 12
Training loss: 3.910801059782921
Validation loss: 2.966268272191685

Epoch: 6| Step: 13
Training loss: 2.490442125218922
Validation loss: 2.964488608175985

Epoch: 88| Step: 0
Training loss: 2.989108022372089
Validation loss: 2.962500143165805

Epoch: 6| Step: 1
Training loss: 3.0835350245587714
Validation loss: 2.961706783821573

Epoch: 6| Step: 2
Training loss: 3.5306449979518617
Validation loss: 2.957966123255528

Epoch: 6| Step: 3
Training loss: 3.6261473845855092
Validation loss: 2.959486472458366

Epoch: 6| Step: 4
Training loss: 3.5975992568945205
Validation loss: 2.9633984260335975

Epoch: 6| Step: 5
Training loss: 2.2559940182356293
Validation loss: 2.96057708370958

Epoch: 6| Step: 6
Training loss: 3.6362091920306248
Validation loss: 2.9627332405268128

Epoch: 6| Step: 7
Training loss: 2.651155680444958
Validation loss: 2.9604585378003327

Epoch: 6| Step: 8
Training loss: 3.0045054300722267
Validation loss: 2.9601035921532524

Epoch: 6| Step: 9
Training loss: 3.2392585485283307
Validation loss: 2.9603142687026085

Epoch: 6| Step: 10
Training loss: 3.240892119328562
Validation loss: 2.9624319863221347

Epoch: 6| Step: 11
Training loss: 3.303497749596902
Validation loss: 2.960621055104699

Epoch: 6| Step: 12
Training loss: 3.8339160946145436
Validation loss: 2.9595887569114296

Epoch: 6| Step: 13
Training loss: 2.976741274774037
Validation loss: 2.9610421343004245

Epoch: 89| Step: 0
Training loss: 2.8870406739158074
Validation loss: 2.9600724673636405

Epoch: 6| Step: 1
Training loss: 3.649535575479024
Validation loss: 2.9578352128511693

Epoch: 6| Step: 2
Training loss: 2.7593942920187544
Validation loss: 2.965919501911339

Epoch: 6| Step: 3
Training loss: 3.5549019885066007
Validation loss: 2.959859622122631

Epoch: 6| Step: 4
Training loss: 2.9025954372279985
Validation loss: 2.9726077288409907

Epoch: 6| Step: 5
Training loss: 3.0778622587738353
Validation loss: 2.96708790700214

Epoch: 6| Step: 6
Training loss: 2.9061545079447946
Validation loss: 2.9724919930805114

Epoch: 6| Step: 7
Training loss: 3.589961302184758
Validation loss: 2.9841043205330275

Epoch: 6| Step: 8
Training loss: 3.6565061300177555
Validation loss: 2.9719339461000662

Epoch: 6| Step: 9
Training loss: 3.816199087183799
Validation loss: 2.9693958661500424

Epoch: 6| Step: 10
Training loss: 2.444357591107145
Validation loss: 2.9619616111555462

Epoch: 6| Step: 11
Training loss: 3.5475184995398736
Validation loss: 2.9652281703841887

Epoch: 6| Step: 12
Training loss: 2.489366231946471
Validation loss: 2.9690002051001407

Epoch: 6| Step: 13
Training loss: 3.9901994805437044
Validation loss: 2.968768579913872

Epoch: 90| Step: 0
Training loss: 3.7517166023427775
Validation loss: 2.9842888475458156

Epoch: 6| Step: 1
Training loss: 3.2477368030739524
Validation loss: 2.9722538493610284

Epoch: 6| Step: 2
Training loss: 2.9416785855002283
Validation loss: 2.9621832039962577

Epoch: 6| Step: 3
Training loss: 2.9675676099343127
Validation loss: 2.960868664731795

Epoch: 6| Step: 4
Training loss: 3.7818059591365913
Validation loss: 2.956636736703606

Epoch: 6| Step: 5
Training loss: 2.672186047033121
Validation loss: 2.953732965915561

Epoch: 6| Step: 6
Training loss: 4.07211691312698
Validation loss: 2.9577717528960044

Epoch: 6| Step: 7
Training loss: 2.1927396963840993
Validation loss: 2.955515076461869

Epoch: 6| Step: 8
Training loss: 3.086127552988604
Validation loss: 2.957089329104461

Epoch: 6| Step: 9
Training loss: 2.9466463908480356
Validation loss: 2.9571960882705883

Epoch: 6| Step: 10
Training loss: 3.1595775324259168
Validation loss: 2.956077846473226

Epoch: 6| Step: 11
Training loss: 3.1936506879262327
Validation loss: 2.95781374650384

Epoch: 6| Step: 12
Training loss: 3.6008605935046947
Validation loss: 2.9598408173866795

Epoch: 6| Step: 13
Training loss: 3.3973757433537317
Validation loss: 2.960375426925136

Epoch: 91| Step: 0
Training loss: 2.9627922911850515
Validation loss: 2.959116800066603

Epoch: 6| Step: 1
Training loss: 2.8738814126690184
Validation loss: 2.960295840104298

Epoch: 6| Step: 2
Training loss: 2.817454403607315
Validation loss: 2.9615082337510112

Epoch: 6| Step: 3
Training loss: 3.627494742812298
Validation loss: 2.958343501220127

Epoch: 6| Step: 4
Training loss: 2.8901036797639557
Validation loss: 2.9591458574139673

Epoch: 6| Step: 5
Training loss: 3.960838662744606
Validation loss: 2.9559247461991403

Epoch: 6| Step: 6
Training loss: 3.070978068266911
Validation loss: 2.9542345743820806

Epoch: 6| Step: 7
Training loss: 2.931007840497799
Validation loss: 2.9537258280306182

Epoch: 6| Step: 8
Training loss: 3.658747675783848
Validation loss: 2.9550815621809683

Epoch: 6| Step: 9
Training loss: 3.3518861556556594
Validation loss: 2.9535997109793604

Epoch: 6| Step: 10
Training loss: 3.8109225152015513
Validation loss: 2.9504889100286316

Epoch: 6| Step: 11
Training loss: 3.2593829351458417
Validation loss: 2.951062670507429

Epoch: 6| Step: 12
Training loss: 2.669921517808133
Validation loss: 2.952558906043058

Epoch: 6| Step: 13
Training loss: 3.0816808000910645
Validation loss: 2.954332873703011

Epoch: 92| Step: 0
Training loss: 3.1180637437863488
Validation loss: 2.951039819666262

Epoch: 6| Step: 1
Training loss: 3.2794044754160634
Validation loss: 2.9522472560971593

Epoch: 6| Step: 2
Training loss: 2.6036835692855007
Validation loss: 2.956291815564279

Epoch: 6| Step: 3
Training loss: 3.667465354168112
Validation loss: 2.9556593794519115

Epoch: 6| Step: 4
Training loss: 2.3541611415381847
Validation loss: 2.9575753388395114

Epoch: 6| Step: 5
Training loss: 3.531402719621745
Validation loss: 2.9581307465027242

Epoch: 6| Step: 6
Training loss: 2.860964807351927
Validation loss: 2.9591597691461153

Epoch: 6| Step: 7
Training loss: 3.4271183340648737
Validation loss: 2.952550704715998

Epoch: 6| Step: 8
Training loss: 3.414981116135135
Validation loss: 2.952014534395106

Epoch: 6| Step: 9
Training loss: 3.8469046696154785
Validation loss: 2.947273686638121

Epoch: 6| Step: 10
Training loss: 3.319453875653761
Validation loss: 2.9504012728123863

Epoch: 6| Step: 11
Training loss: 2.7425975003989076
Validation loss: 2.9510449260245424

Epoch: 6| Step: 12
Training loss: 3.450777110053479
Validation loss: 2.9489671238659376

Epoch: 6| Step: 13
Training loss: 3.4078565536093253
Validation loss: 2.950740549745568

Epoch: 93| Step: 0
Training loss: 2.8563506594894505
Validation loss: 2.947321608916103

Epoch: 6| Step: 1
Training loss: 3.489286784007208
Validation loss: 2.948662991292316

Epoch: 6| Step: 2
Training loss: 2.8885782779905087
Validation loss: 2.9472576207492254

Epoch: 6| Step: 3
Training loss: 3.362624756721541
Validation loss: 2.9465849459306734

Epoch: 6| Step: 4
Training loss: 3.648879749360476
Validation loss: 2.94751538549704

Epoch: 6| Step: 5
Training loss: 3.416467304150887
Validation loss: 2.9485000809344806

Epoch: 6| Step: 6
Training loss: 2.949418906183941
Validation loss: 2.9480784782080653

Epoch: 6| Step: 7
Training loss: 2.7679553370483214
Validation loss: 2.9479298324809844

Epoch: 6| Step: 8
Training loss: 3.1020310670144258
Validation loss: 2.9458201503399217

Epoch: 6| Step: 9
Training loss: 3.4412184976894933
Validation loss: 2.9454869362043237

Epoch: 6| Step: 10
Training loss: 3.153192228691283
Validation loss: 2.948295652096481

Epoch: 6| Step: 11
Training loss: 3.890979428980324
Validation loss: 2.9500542660896727

Epoch: 6| Step: 12
Training loss: 3.1777475798742234
Validation loss: 2.947619549115629

Epoch: 6| Step: 13
Training loss: 2.7058236647482987
Validation loss: 2.9472540718025653

Epoch: 94| Step: 0
Training loss: 3.6341560750479083
Validation loss: 2.9472388321595067

Epoch: 6| Step: 1
Training loss: 2.770846852052068
Validation loss: 2.9460173272422927

Epoch: 6| Step: 2
Training loss: 3.1866546706714716
Validation loss: 2.94978848594685

Epoch: 6| Step: 3
Training loss: 3.2910682198597763
Validation loss: 2.944369936494576

Epoch: 6| Step: 4
Training loss: 2.2546521940791378
Validation loss: 2.942604208732175

Epoch: 6| Step: 5
Training loss: 3.374133528639878
Validation loss: 2.9432981506373577

Epoch: 6| Step: 6
Training loss: 3.6212499228896533
Validation loss: 2.9438710484113395

Epoch: 6| Step: 7
Training loss: 3.3884928807193244
Validation loss: 2.940334301070403

Epoch: 6| Step: 8
Training loss: 3.147508356327178
Validation loss: 2.9437772086817033

Epoch: 6| Step: 9
Training loss: 2.868332470530399
Validation loss: 2.9432633988953723

Epoch: 6| Step: 10
Training loss: 3.557505536480561
Validation loss: 2.9398137817719765

Epoch: 6| Step: 11
Training loss: 3.2856038590350267
Validation loss: 2.943111341044654

Epoch: 6| Step: 12
Training loss: 2.8520993916124717
Validation loss: 2.9448032325659024

Epoch: 6| Step: 13
Training loss: 4.009553943663613
Validation loss: 2.947177914552659

Epoch: 95| Step: 0
Training loss: 2.937834213398959
Validation loss: 2.9436274487122036

Epoch: 6| Step: 1
Training loss: 3.5257303766341384
Validation loss: 2.9437174238744226

Epoch: 6| Step: 2
Training loss: 2.313164074373702
Validation loss: 2.9431639128189055

Epoch: 6| Step: 3
Training loss: 3.021574644134764
Validation loss: 2.9456189767719856

Epoch: 6| Step: 4
Training loss: 2.848526182065404
Validation loss: 2.9498514449818867

Epoch: 6| Step: 5
Training loss: 3.6985092046545
Validation loss: 2.952845807476566

Epoch: 6| Step: 6
Training loss: 3.551448343895131
Validation loss: 2.9418566305511864

Epoch: 6| Step: 7
Training loss: 2.7125162150518003
Validation loss: 2.940269465059504

Epoch: 6| Step: 8
Training loss: 3.3886586477587666
Validation loss: 2.9442739245448277

Epoch: 6| Step: 9
Training loss: 3.121498282216235
Validation loss: 2.941368392253812

Epoch: 6| Step: 10
Training loss: 4.0633881991789265
Validation loss: 2.940252450623004

Epoch: 6| Step: 11
Training loss: 3.274400373703865
Validation loss: 2.9386263651285884

Epoch: 6| Step: 12
Training loss: 3.4681312077835025
Validation loss: 2.9392774401924027

Epoch: 6| Step: 13
Training loss: 2.565797312591975
Validation loss: 2.939051724230789

Epoch: 96| Step: 0
Training loss: 2.66698476761715
Validation loss: 2.9392313797704603

Epoch: 6| Step: 1
Training loss: 3.1562376116518944
Validation loss: 2.942434661943039

Epoch: 6| Step: 2
Training loss: 3.429826529428661
Validation loss: 2.941674160947064

Epoch: 6| Step: 3
Training loss: 3.1194122712116212
Validation loss: 2.942430119163291

Epoch: 6| Step: 4
Training loss: 3.6815191355120787
Validation loss: 2.9405792842686753

Epoch: 6| Step: 5
Training loss: 3.5185965631615104
Validation loss: 2.937478640759482

Epoch: 6| Step: 6
Training loss: 3.1602778653012598
Validation loss: 2.9400883601015986

Epoch: 6| Step: 7
Training loss: 2.660975482734547
Validation loss: 2.9389375046285875

Epoch: 6| Step: 8
Training loss: 3.2060185458574373
Validation loss: 2.9432207299401645

Epoch: 6| Step: 9
Training loss: 3.153223229381955
Validation loss: 2.941102739817839

Epoch: 6| Step: 10
Training loss: 2.870770037820234
Validation loss: 2.940987237413978

Epoch: 6| Step: 11
Training loss: 3.9565455900294446
Validation loss: 2.939932103260718

Epoch: 6| Step: 12
Training loss: 3.2273793514285463
Validation loss: 2.943243980316359

Epoch: 6| Step: 13
Training loss: 3.0588104444111712
Validation loss: 2.938047076659135

Epoch: 97| Step: 0
Training loss: 3.8323302546047473
Validation loss: 2.944965725878329

Epoch: 6| Step: 1
Training loss: 3.083274600182708
Validation loss: 2.9466932149403946

Epoch: 6| Step: 2
Training loss: 2.9025381030884625
Validation loss: 2.950488520767355

Epoch: 6| Step: 3
Training loss: 3.3611841342724538
Validation loss: 2.946630815712827

Epoch: 6| Step: 4
Training loss: 3.4640391210060475
Validation loss: 2.9475547272367133

Epoch: 6| Step: 5
Training loss: 3.2411625356528377
Validation loss: 2.94861300937767

Epoch: 6| Step: 6
Training loss: 3.1738228665821824
Validation loss: 2.948718461809571

Epoch: 6| Step: 7
Training loss: 2.957620257192325
Validation loss: 2.9454027039525124

Epoch: 6| Step: 8
Training loss: 2.919483695435307
Validation loss: 2.942156516580698

Epoch: 6| Step: 9
Training loss: 2.810811871302399
Validation loss: 2.93771528032467

Epoch: 6| Step: 10
Training loss: 2.7010012536213694
Validation loss: 2.9379390788981556

Epoch: 6| Step: 11
Training loss: 3.2850110977891167
Validation loss: 2.9396922375551533

Epoch: 6| Step: 12
Training loss: 3.4945438636366224
Validation loss: 2.937693100593095

Epoch: 6| Step: 13
Training loss: 4.103183738363599
Validation loss: 2.9374006756825652

Epoch: 98| Step: 0
Training loss: 3.349681691092547
Validation loss: 2.935191882963219

Epoch: 6| Step: 1
Training loss: 2.5203216495809007
Validation loss: 2.935071346597204

Epoch: 6| Step: 2
Training loss: 3.4805279351028418
Validation loss: 2.9413399149518247

Epoch: 6| Step: 3
Training loss: 3.56757087535533
Validation loss: 2.9411403848146267

Epoch: 6| Step: 4
Training loss: 2.5347781612082123
Validation loss: 2.94152571015005

Epoch: 6| Step: 5
Training loss: 2.980276439056995
Validation loss: 2.9447949395584745

Epoch: 6| Step: 6
Training loss: 3.298731276794008
Validation loss: 2.9438282079971367

Epoch: 6| Step: 7
Training loss: 3.700893840562873
Validation loss: 2.9481864401954807

Epoch: 6| Step: 8
Training loss: 3.464615841221952
Validation loss: 2.9459883910251574

Epoch: 6| Step: 9
Training loss: 2.82002548490331
Validation loss: 2.9400260203755

Epoch: 6| Step: 10
Training loss: 3.148606515896097
Validation loss: 2.93778785721192

Epoch: 6| Step: 11
Training loss: 3.501963745713817
Validation loss: 2.9338171761478034

Epoch: 6| Step: 12
Training loss: 3.56079890812943
Validation loss: 2.9326785561701434

Epoch: 6| Step: 13
Training loss: 2.658568772639474
Validation loss: 2.9313550012014975

Epoch: 99| Step: 0
Training loss: 3.3439129941198606
Validation loss: 2.9332345588848976

Epoch: 6| Step: 1
Training loss: 3.556043429149188
Validation loss: 2.9301082422173375

Epoch: 6| Step: 2
Training loss: 2.8724003524029973
Validation loss: 2.934175888788738

Epoch: 6| Step: 3
Training loss: 2.9982825767485926
Validation loss: 2.9305932407171937

Epoch: 6| Step: 4
Training loss: 2.836331594948642
Validation loss: 2.9341639887331223

Epoch: 6| Step: 5
Training loss: 3.6156694757335694
Validation loss: 2.934433865237681

Epoch: 6| Step: 6
Training loss: 2.9937039110940487
Validation loss: 2.933983879604786

Epoch: 6| Step: 7
Training loss: 2.949147932200244
Validation loss: 2.9311751961354697

Epoch: 6| Step: 8
Training loss: 3.870061865812334
Validation loss: 2.929996968212167

Epoch: 6| Step: 9
Training loss: 3.2507892530618263
Validation loss: 2.9317325026917054

Epoch: 6| Step: 10
Training loss: 3.333772264827475
Validation loss: 2.933176998571129

Epoch: 6| Step: 11
Training loss: 3.3501969692341995
Validation loss: 2.9354594327221974

Epoch: 6| Step: 12
Training loss: 3.161738392189419
Validation loss: 2.935431099838443

Epoch: 6| Step: 13
Training loss: 2.3588113679973866
Validation loss: 2.936914056948338

Epoch: 100| Step: 0
Training loss: 3.7692554748539924
Validation loss: 2.938477433193681

Epoch: 6| Step: 1
Training loss: 3.4302591529570052
Validation loss: 2.935997974502237

Epoch: 6| Step: 2
Training loss: 3.517028799590421
Validation loss: 2.9367464207746545

Epoch: 6| Step: 3
Training loss: 3.475285602057641
Validation loss: 2.9391768989947873

Epoch: 6| Step: 4
Training loss: 3.2741791606485724
Validation loss: 2.937098596778449

Epoch: 6| Step: 5
Training loss: 2.8710356206913072
Validation loss: 2.9331182222228653

Epoch: 6| Step: 6
Training loss: 2.6452214792615996
Validation loss: 2.9404400835305626

Epoch: 6| Step: 7
Training loss: 2.6707716777507007
Validation loss: 2.9324402285282765

Epoch: 6| Step: 8
Training loss: 3.538292268385085
Validation loss: 2.92898674660037

Epoch: 6| Step: 9
Training loss: 2.5682591175774165
Validation loss: 2.932823216176381

Epoch: 6| Step: 10
Training loss: 2.8826852992664556
Validation loss: 2.9322374480529114

Epoch: 6| Step: 11
Training loss: 3.144267536738935
Validation loss: 2.929473688014409

Epoch: 6| Step: 12
Training loss: 3.912971268323921
Validation loss: 2.9294503222206734

Epoch: 6| Step: 13
Training loss: 2.952487129874607
Validation loss: 2.930427630384325

Epoch: 101| Step: 0
Training loss: 3.1065232891620105
Validation loss: 2.929893875564659

Epoch: 6| Step: 1
Training loss: 3.1380127628375645
Validation loss: 2.92912139432823

Epoch: 6| Step: 2
Training loss: 3.5302922123031184
Validation loss: 2.928496504456166

Epoch: 6| Step: 3
Training loss: 3.8892216736836667
Validation loss: 2.9293227959601853

Epoch: 6| Step: 4
Training loss: 3.6474639443177033
Validation loss: 2.9275290530424978

Epoch: 6| Step: 5
Training loss: 2.7332574795067854
Validation loss: 2.932212799823754

Epoch: 6| Step: 6
Training loss: 2.9693268867951423
Validation loss: 2.927884692219356

Epoch: 6| Step: 7
Training loss: 2.479593534077366
Validation loss: 2.927798966730277

Epoch: 6| Step: 8
Training loss: 3.226514469555873
Validation loss: 2.929834241466714

Epoch: 6| Step: 9
Training loss: 3.0544533408093897
Validation loss: 2.928689114998388

Epoch: 6| Step: 10
Training loss: 3.108644639313132
Validation loss: 2.9269814083597323

Epoch: 6| Step: 11
Training loss: 3.800599332025513
Validation loss: 2.9284543285588236

Epoch: 6| Step: 12
Training loss: 3.0031315036349975
Validation loss: 2.9293628318575187

Epoch: 6| Step: 13
Training loss: 2.923366879742298
Validation loss: 2.927731530920667

Epoch: 102| Step: 0
Training loss: 2.7740431433240094
Validation loss: 2.9285654038132223

Epoch: 6| Step: 1
Training loss: 3.000681164022615
Validation loss: 2.9300817544561406

Epoch: 6| Step: 2
Training loss: 2.683177665870674
Validation loss: 2.9268960365510144

Epoch: 6| Step: 3
Training loss: 3.5113658282146027
Validation loss: 2.9247944322347004

Epoch: 6| Step: 4
Training loss: 3.496620863065078
Validation loss: 2.9264920540720456

Epoch: 6| Step: 5
Training loss: 3.6714998094137092
Validation loss: 2.925567460983777

Epoch: 6| Step: 6
Training loss: 3.6599850609479687
Validation loss: 2.9252317058627306

Epoch: 6| Step: 7
Training loss: 3.5268485396516627
Validation loss: 2.924693204701348

Epoch: 6| Step: 8
Training loss: 2.768989714499038
Validation loss: 2.9251158309311536

Epoch: 6| Step: 9
Training loss: 2.713883352214363
Validation loss: 2.925169437767712

Epoch: 6| Step: 10
Training loss: 3.146564541818985
Validation loss: 2.92529774978568

Epoch: 6| Step: 11
Training loss: 3.485110491803048
Validation loss: 2.924564738177681

Epoch: 6| Step: 12
Training loss: 3.465310393243439
Validation loss: 2.923825097374805

Epoch: 6| Step: 13
Training loss: 2.4587707669147645
Validation loss: 2.9263129559287564

Epoch: 103| Step: 0
Training loss: 2.963712574478351
Validation loss: 2.9282562325560706

Epoch: 6| Step: 1
Training loss: 3.9140459315392837
Validation loss: 2.9323605226046494

Epoch: 6| Step: 2
Training loss: 3.0015955496720466
Validation loss: 2.9313839638032553

Epoch: 6| Step: 3
Training loss: 3.597323026353432
Validation loss: 2.9327042110091734

Epoch: 6| Step: 4
Training loss: 2.718904688150556
Validation loss: 2.9277655668734948

Epoch: 6| Step: 5
Training loss: 3.623117418450699
Validation loss: 2.925340661761614

Epoch: 6| Step: 6
Training loss: 3.050161613810214
Validation loss: 2.9222437242230788

Epoch: 6| Step: 7
Training loss: 3.9865640049945226
Validation loss: 2.923954502100587

Epoch: 6| Step: 8
Training loss: 2.959394953981699
Validation loss: 2.920871574824775

Epoch: 6| Step: 9
Training loss: 2.9398524827343393
Validation loss: 2.9225741024895306

Epoch: 6| Step: 10
Training loss: 2.855957323434012
Validation loss: 2.9239879980957464

Epoch: 6| Step: 11
Training loss: 2.8085322048357155
Validation loss: 2.920049564243218

Epoch: 6| Step: 12
Training loss: 2.902237449948117
Validation loss: 2.9223886726770303

Epoch: 6| Step: 13
Training loss: 3.401873235216722
Validation loss: 2.9259215354049974

Epoch: 104| Step: 0
Training loss: 3.7439658890824954
Validation loss: 2.9222922964589464

Epoch: 6| Step: 1
Training loss: 3.5395939914182915
Validation loss: 2.9193808067158074

Epoch: 6| Step: 2
Training loss: 2.6061821322672505
Validation loss: 2.9214860070333963

Epoch: 6| Step: 3
Training loss: 3.1127687269276634
Validation loss: 2.918177120981716

Epoch: 6| Step: 4
Training loss: 3.400258245197444
Validation loss: 2.9194104132356395

Epoch: 6| Step: 5
Training loss: 2.9311934605983603
Validation loss: 2.9203362955270973

Epoch: 6| Step: 6
Training loss: 3.116585962675206
Validation loss: 2.921466877197178

Epoch: 6| Step: 7
Training loss: 3.4853648332175906
Validation loss: 2.9199973980876157

Epoch: 6| Step: 8
Training loss: 3.3002794956564943
Validation loss: 2.9203793945263707

Epoch: 6| Step: 9
Training loss: 3.243979085429137
Validation loss: 2.9209308986499063

Epoch: 6| Step: 10
Training loss: 2.1878622572533826
Validation loss: 2.9206911866931615

Epoch: 6| Step: 11
Training loss: 3.7656586831513508
Validation loss: 2.9175292375933273

Epoch: 6| Step: 12
Training loss: 3.1556472958256685
Validation loss: 2.9216357717716264

Epoch: 6| Step: 13
Training loss: 2.7987318641310113
Validation loss: 2.9197888804330137

Epoch: 105| Step: 0
Training loss: 3.5366489694232257
Validation loss: 2.920435807816671

Epoch: 6| Step: 1
Training loss: 3.179531534104857
Validation loss: 2.9180446697849427

Epoch: 6| Step: 2
Training loss: 2.7918688762555792
Validation loss: 2.918564670816097

Epoch: 6| Step: 3
Training loss: 3.3046332460824273
Validation loss: 2.9281230684556534

Epoch: 6| Step: 4
Training loss: 3.3954543075756423
Validation loss: 2.919284202105471

Epoch: 6| Step: 5
Training loss: 2.8332925868376875
Validation loss: 2.923913488185141

Epoch: 6| Step: 6
Training loss: 3.823705745963445
Validation loss: 2.9219786966833174

Epoch: 6| Step: 7
Training loss: 3.330592713631716
Validation loss: 2.917977519875403

Epoch: 6| Step: 8
Training loss: 3.4459358049414304
Validation loss: 2.9168856750979324

Epoch: 6| Step: 9
Training loss: 3.1846391892083936
Validation loss: 2.9152010321856445

Epoch: 6| Step: 10
Training loss: 2.85294222961832
Validation loss: 2.9144577413301893

Epoch: 6| Step: 11
Training loss: 2.655144046101472
Validation loss: 2.915695090721355

Epoch: 6| Step: 12
Training loss: 3.2350255339615637
Validation loss: 2.915765697591594

Epoch: 6| Step: 13
Training loss: 3.112426640515457
Validation loss: 2.9190490473895374

Epoch: 106| Step: 0
Training loss: 3.1980437378794004
Validation loss: 2.91776596190321

Epoch: 6| Step: 1
Training loss: 3.3452306303565797
Validation loss: 2.9184167759073407

Epoch: 6| Step: 2
Training loss: 3.9791507953640175
Validation loss: 2.916119202127095

Epoch: 6| Step: 3
Training loss: 3.4166959125538674
Validation loss: 2.914429827939402

Epoch: 6| Step: 4
Training loss: 3.123877972396774
Validation loss: 2.9167923207324926

Epoch: 6| Step: 5
Training loss: 3.0005403667799206
Validation loss: 2.91547461612962

Epoch: 6| Step: 6
Training loss: 3.89876137651384
Validation loss: 2.9142188586944244

Epoch: 6| Step: 7
Training loss: 3.041441312480513
Validation loss: 2.914389813852148

Epoch: 6| Step: 8
Training loss: 3.2415759141733256
Validation loss: 2.9134816060844964

Epoch: 6| Step: 9
Training loss: 2.7719982442368623
Validation loss: 2.9124262776877097

Epoch: 6| Step: 10
Training loss: 2.5261246395576125
Validation loss: 2.915811100887132

Epoch: 6| Step: 11
Training loss: 2.536411345018571
Validation loss: 2.9120076035041733

Epoch: 6| Step: 12
Training loss: 2.9105553679751273
Validation loss: 2.9130588540534395

Epoch: 6| Step: 13
Training loss: 3.757656800024454
Validation loss: 2.91495909887358

Epoch: 107| Step: 0
Training loss: 2.863317387913576
Validation loss: 2.9162372560135923

Epoch: 6| Step: 1
Training loss: 3.611021120629229
Validation loss: 2.9191952961323544

Epoch: 6| Step: 2
Training loss: 3.7976977551861726
Validation loss: 2.920507222649109

Epoch: 6| Step: 3
Training loss: 3.09076060739135
Validation loss: 2.9133946014794745

Epoch: 6| Step: 4
Training loss: 3.8561328443539993
Validation loss: 2.9153994296216705

Epoch: 6| Step: 5
Training loss: 3.349732937771985
Validation loss: 2.915370514870384

Epoch: 6| Step: 6
Training loss: 3.403216489852892
Validation loss: 2.915656972992356

Epoch: 6| Step: 7
Training loss: 3.4694023549893522
Validation loss: 2.91402769872109

Epoch: 6| Step: 8
Training loss: 3.0070471644506935
Validation loss: 2.9130837162708394

Epoch: 6| Step: 9
Training loss: 3.2221457337110717
Validation loss: 2.917428841453523

Epoch: 6| Step: 10
Training loss: 2.660300543592541
Validation loss: 2.9146917782565565

Epoch: 6| Step: 11
Training loss: 2.6984565420533615
Validation loss: 2.9131505090530823

Epoch: 6| Step: 12
Training loss: 2.626997596335936
Validation loss: 2.912189370218219

Epoch: 6| Step: 13
Training loss: 2.5698483868418696
Validation loss: 2.908371264001768

Epoch: 108| Step: 0
Training loss: 3.300853624622589
Validation loss: 2.9118399474064227

Epoch: 6| Step: 1
Training loss: 3.0871275333496553
Validation loss: 2.9095607516354365

Epoch: 6| Step: 2
Training loss: 2.898614019483752
Validation loss: 2.9100362403484046

Epoch: 6| Step: 3
Training loss: 2.584644928089132
Validation loss: 2.9130826267766783

Epoch: 6| Step: 4
Training loss: 2.989462146673144
Validation loss: 2.9142136710942417

Epoch: 6| Step: 5
Training loss: 3.560283305864518
Validation loss: 2.9108574227843715

Epoch: 6| Step: 6
Training loss: 3.432478687862017
Validation loss: 2.9180807796178496

Epoch: 6| Step: 7
Training loss: 3.661965882605436
Validation loss: 2.9137830452073628

Epoch: 6| Step: 8
Training loss: 3.670258641081258
Validation loss: 2.912359498224686

Epoch: 6| Step: 9
Training loss: 2.775882728325755
Validation loss: 2.9081541261524637

Epoch: 6| Step: 10
Training loss: 3.446580718301272
Validation loss: 2.9080451046334916

Epoch: 6| Step: 11
Training loss: 2.412172929799109
Validation loss: 2.9082715672082977

Epoch: 6| Step: 12
Training loss: 3.180496450334957
Validation loss: 2.9101638603344937

Epoch: 6| Step: 13
Training loss: 3.7656704595204014
Validation loss: 2.9071921608673588

Epoch: 109| Step: 0
Training loss: 2.7537291124878966
Validation loss: 2.907934054869579

Epoch: 6| Step: 1
Training loss: 2.9919226307580855
Validation loss: 2.908919463462763

Epoch: 6| Step: 2
Training loss: 3.290461661694681
Validation loss: 2.906943790728829

Epoch: 6| Step: 3
Training loss: 3.0189034622390376
Validation loss: 2.906070500358244

Epoch: 6| Step: 4
Training loss: 3.2783191488864483
Validation loss: 2.905934634582111

Epoch: 6| Step: 5
Training loss: 3.79624651193066
Validation loss: 2.9033483724347184

Epoch: 6| Step: 6
Training loss: 3.2451123384800518
Validation loss: 2.907985111522712

Epoch: 6| Step: 7
Training loss: 3.6169167205107655
Validation loss: 2.9060958696173818

Epoch: 6| Step: 8
Training loss: 3.6716722797680474
Validation loss: 2.9058190558944164

Epoch: 6| Step: 9
Training loss: 2.782559547301251
Validation loss: 2.90603300359132

Epoch: 6| Step: 10
Training loss: 3.1934489666331345
Validation loss: 2.904990887736956

Epoch: 6| Step: 11
Training loss: 3.124470017314796
Validation loss: 2.90637624172893

Epoch: 6| Step: 12
Training loss: 2.6040529353420365
Validation loss: 2.9108590820540914

Epoch: 6| Step: 13
Training loss: 3.2332674793209537
Validation loss: 2.9079737266913925

Epoch: 110| Step: 0
Training loss: 3.4830776929971146
Validation loss: 2.9162152698415627

Epoch: 6| Step: 1
Training loss: 2.9448128435803556
Validation loss: 2.915705907301147

Epoch: 6| Step: 2
Training loss: 3.2336882078609834
Validation loss: 2.91182670938891

Epoch: 6| Step: 3
Training loss: 2.6187488055169563
Validation loss: 2.917712906145616

Epoch: 6| Step: 4
Training loss: 3.1296059805908474
Validation loss: 2.928775069153391

Epoch: 6| Step: 5
Training loss: 2.9422356600068786
Validation loss: 2.923301853327496

Epoch: 6| Step: 6
Training loss: 2.9974297003181927
Validation loss: 2.9161467846225166

Epoch: 6| Step: 7
Training loss: 3.881221575794167
Validation loss: 2.9237728723195517

Epoch: 6| Step: 8
Training loss: 3.2050925561927546
Validation loss: 2.9211838708593105

Epoch: 6| Step: 9
Training loss: 2.8688168586469636
Validation loss: 2.919408708772333

Epoch: 6| Step: 10
Training loss: 3.191441361830641
Validation loss: 2.9155537118189137

Epoch: 6| Step: 11
Training loss: 3.521206642238736
Validation loss: 2.905266568816991

Epoch: 6| Step: 12
Training loss: 3.679446331957217
Validation loss: 2.9065239695912037

Epoch: 6| Step: 13
Training loss: 2.582789599714627
Validation loss: 2.9023548671942474

Epoch: 111| Step: 0
Training loss: 4.166459243697762
Validation loss: 2.900996118230194

Epoch: 6| Step: 1
Training loss: 2.253805756601214
Validation loss: 2.898953951372317

Epoch: 6| Step: 2
Training loss: 3.245126738578707
Validation loss: 2.902483972276229

Epoch: 6| Step: 3
Training loss: 3.2087237298095896
Validation loss: 2.9000005624450207

Epoch: 6| Step: 4
Training loss: 3.40451761691101
Validation loss: 2.9015025320327035

Epoch: 6| Step: 5
Training loss: 3.1231977224748158
Validation loss: 2.9031582248221115

Epoch: 6| Step: 6
Training loss: 2.6713817654262018
Validation loss: 2.9011609052267726

Epoch: 6| Step: 7
Training loss: 2.6389244969514287
Validation loss: 2.90026234779213

Epoch: 6| Step: 8
Training loss: 3.2270365590760326
Validation loss: 2.9005677203217433

Epoch: 6| Step: 9
Training loss: 3.3034853360656204
Validation loss: 2.9001432016424227

Epoch: 6| Step: 10
Training loss: 2.9496159772327943
Validation loss: 2.9043496268042666

Epoch: 6| Step: 11
Training loss: 2.9985532451034955
Validation loss: 2.9051526401990166

Epoch: 6| Step: 12
Training loss: 3.774936796758198
Validation loss: 2.907159815271875

Epoch: 6| Step: 13
Training loss: 3.5029458863665734
Validation loss: 2.9102145140517264

Epoch: 112| Step: 0
Training loss: 3.11388174126703
Validation loss: 2.903176065073524

Epoch: 6| Step: 1
Training loss: 3.2000479456170727
Validation loss: 2.9032189066610075

Epoch: 6| Step: 2
Training loss: 3.4900737057310907
Validation loss: 2.9037637722027503

Epoch: 6| Step: 3
Training loss: 2.9040230042778585
Validation loss: 2.9008052022083657

Epoch: 6| Step: 4
Training loss: 3.2796907625731895
Validation loss: 2.9017973845043348

Epoch: 6| Step: 5
Training loss: 3.6403177156230075
Validation loss: 2.9013295336341196

Epoch: 6| Step: 6
Training loss: 2.643835159264895
Validation loss: 2.900079822042868

Epoch: 6| Step: 7
Training loss: 3.4361501644392205
Validation loss: 2.9028866479196678

Epoch: 6| Step: 8
Training loss: 3.290223847632452
Validation loss: 2.902413662363906

Epoch: 6| Step: 9
Training loss: 2.6852676523876937
Validation loss: 2.901379227373812

Epoch: 6| Step: 10
Training loss: 2.998943778706396
Validation loss: 2.9054929020806073

Epoch: 6| Step: 11
Training loss: 3.456661019193425
Validation loss: 2.9015675875485263

Epoch: 6| Step: 12
Training loss: 3.867249644387044
Validation loss: 2.9041186546963393

Epoch: 6| Step: 13
Training loss: 1.6710376960159659
Validation loss: 2.903362747549541

Epoch: 113| Step: 0
Training loss: 3.2014441569300263
Validation loss: 2.9085319382358046

Epoch: 6| Step: 1
Training loss: 3.2967075106485564
Validation loss: 2.9061231114631285

Epoch: 6| Step: 2
Training loss: 3.177533444064275
Validation loss: 2.9092370846152953

Epoch: 6| Step: 3
Training loss: 3.2981895971631845
Validation loss: 2.9035473572557002

Epoch: 6| Step: 4
Training loss: 2.964971124981263
Validation loss: 2.9052278412828882

Epoch: 6| Step: 5
Training loss: 3.30030897023464
Validation loss: 2.905680556208929

Epoch: 6| Step: 6
Training loss: 3.275310845219504
Validation loss: 2.9019203816307355

Epoch: 6| Step: 7
Training loss: 2.8016685453004304
Validation loss: 2.8981059969737464

Epoch: 6| Step: 8
Training loss: 3.32880204885246
Validation loss: 2.9006070792615177

Epoch: 6| Step: 9
Training loss: 2.5639873003116977
Validation loss: 2.900883812362738

Epoch: 6| Step: 10
Training loss: 3.5080999923513367
Validation loss: 2.8970518442700257

Epoch: 6| Step: 11
Training loss: 3.1907901612817664
Validation loss: 2.8976580537496184

Epoch: 6| Step: 12
Training loss: 3.398210189057421
Validation loss: 2.898635313103674

Epoch: 6| Step: 13
Training loss: 3.3704819284296135
Validation loss: 2.8987707958011337

Epoch: 114| Step: 0
Training loss: 2.948345535048931
Validation loss: 2.898288004855541

Epoch: 6| Step: 1
Training loss: 2.6430334360098375
Validation loss: 2.8991442756939025

Epoch: 6| Step: 2
Training loss: 3.5855679456650877
Validation loss: 2.8993763231432284

Epoch: 6| Step: 3
Training loss: 2.866579412270916
Validation loss: 2.896877706619168

Epoch: 6| Step: 4
Training loss: 3.6198169881177447
Validation loss: 2.9002355123142345

Epoch: 6| Step: 5
Training loss: 2.954359815674318
Validation loss: 2.898975055018139

Epoch: 6| Step: 6
Training loss: 3.2428974890914852
Validation loss: 2.9002837866492763

Epoch: 6| Step: 7
Training loss: 2.8334603748637197
Validation loss: 2.9022768993090424

Epoch: 6| Step: 8
Training loss: 3.5519280423015314
Validation loss: 2.897817542904293

Epoch: 6| Step: 9
Training loss: 2.9995538061841542
Validation loss: 2.902532393813071

Epoch: 6| Step: 10
Training loss: 3.418521718662439
Validation loss: 2.8975465820087947

Epoch: 6| Step: 11
Training loss: 3.632170852272461
Validation loss: 2.894811093199004

Epoch: 6| Step: 12
Training loss: 3.0519717112538816
Validation loss: 2.8957537417843646

Epoch: 6| Step: 13
Training loss: 3.1544778210967825
Validation loss: 2.8943696736618527

Epoch: 115| Step: 0
Training loss: 3.8352925366329926
Validation loss: 2.894102389418061

Epoch: 6| Step: 1
Training loss: 3.214844936588481
Validation loss: 2.8935466374460934

Epoch: 6| Step: 2
Training loss: 3.197687511538261
Validation loss: 2.895741229666758

Epoch: 6| Step: 3
Training loss: 2.8065104816077246
Validation loss: 2.898108330525825

Epoch: 6| Step: 4
Training loss: 3.557411173222895
Validation loss: 2.8949045506812663

Epoch: 6| Step: 5
Training loss: 2.269215967336471
Validation loss: 2.8934860637489956

Epoch: 6| Step: 6
Training loss: 3.4590010553751536
Validation loss: 2.8938955458884683

Epoch: 6| Step: 7
Training loss: 2.7499498882929774
Validation loss: 2.895499785583921

Epoch: 6| Step: 8
Training loss: 2.9181690887761245
Validation loss: 2.8930270399817326

Epoch: 6| Step: 9
Training loss: 3.0995961449189924
Validation loss: 2.8958802241910178

Epoch: 6| Step: 10
Training loss: 3.974115304442352
Validation loss: 2.892347105421123

Epoch: 6| Step: 11
Training loss: 3.2833943943858577
Validation loss: 2.893159542167338

Epoch: 6| Step: 12
Training loss: 2.520703230934253
Validation loss: 2.8928591195454754

Epoch: 6| Step: 13
Training loss: 3.4314167642282483
Validation loss: 2.8972771973418294

Epoch: 116| Step: 0
Training loss: 2.995111774530485
Validation loss: 2.8960612406490087

Epoch: 6| Step: 1
Training loss: 2.0568497452740173
Validation loss: 2.895633502639257

Epoch: 6| Step: 2
Training loss: 2.7258775610403347
Validation loss: 2.8975471500262815

Epoch: 6| Step: 3
Training loss: 3.0141322735452003
Validation loss: 2.903231758307551

Epoch: 6| Step: 4
Training loss: 3.573468372393422
Validation loss: 2.8993193471193

Epoch: 6| Step: 5
Training loss: 2.570995298092733
Validation loss: 2.9026691077355293

Epoch: 6| Step: 6
Training loss: 3.117495261083946
Validation loss: 2.90148012584378

Epoch: 6| Step: 7
Training loss: 3.6755635666314674
Validation loss: 2.893807491742307

Epoch: 6| Step: 8
Training loss: 3.165495823355043
Validation loss: 2.8917702527731284

Epoch: 6| Step: 9
Training loss: 3.1944038572819764
Validation loss: 2.8875121361915546

Epoch: 6| Step: 10
Training loss: 3.812161039699469
Validation loss: 2.8897112882536473

Epoch: 6| Step: 11
Training loss: 3.8445521812435057
Validation loss: 2.8893759634430296

Epoch: 6| Step: 12
Training loss: 2.8949198391214503
Validation loss: 2.891813997370958

Epoch: 6| Step: 13
Training loss: 3.63042005289154
Validation loss: 2.8886206021205254

Epoch: 117| Step: 0
Training loss: 3.0337751430103004
Validation loss: 2.8899566631614024

Epoch: 6| Step: 1
Training loss: 2.196155969802958
Validation loss: 2.890509722671757

Epoch: 6| Step: 2
Training loss: 2.6369373824287328
Validation loss: 2.8875355599048973

Epoch: 6| Step: 3
Training loss: 3.5392186549348663
Validation loss: 2.8886106062303014

Epoch: 6| Step: 4
Training loss: 4.167876767231268
Validation loss: 2.8893987225743385

Epoch: 6| Step: 5
Training loss: 2.9356766581320013
Validation loss: 2.888648995656075

Epoch: 6| Step: 6
Training loss: 2.7794788164325546
Validation loss: 2.8879726685552223

Epoch: 6| Step: 7
Training loss: 3.111308814382164
Validation loss: 2.888771429098265

Epoch: 6| Step: 8
Training loss: 3.3700092290644386
Validation loss: 2.8881062103939983

Epoch: 6| Step: 9
Training loss: 3.5650150723560046
Validation loss: 2.890336404244238

Epoch: 6| Step: 10
Training loss: 3.426992969809613
Validation loss: 2.8929173961039893

Epoch: 6| Step: 11
Training loss: 3.4534808359593336
Validation loss: 2.8870769868301975

Epoch: 6| Step: 12
Training loss: 3.091541773766033
Validation loss: 2.8872040633390967

Epoch: 6| Step: 13
Training loss: 2.3872723975217998
Validation loss: 2.8876786736631366

Epoch: 118| Step: 0
Training loss: 3.033380919561805
Validation loss: 2.887476520383383

Epoch: 6| Step: 1
Training loss: 2.8928481342370516
Validation loss: 2.897667476977447

Epoch: 6| Step: 2
Training loss: 3.7410912550600157
Validation loss: 2.8845911215873197

Epoch: 6| Step: 3
Training loss: 2.3002564328749138
Validation loss: 2.8870712682913022

Epoch: 6| Step: 4
Training loss: 2.6699687560178624
Validation loss: 2.8865505709413504

Epoch: 6| Step: 5
Training loss: 3.373403100761101
Validation loss: 2.8854075928823733

Epoch: 6| Step: 6
Training loss: 3.6625827819009555
Validation loss: 2.886185875190348

Epoch: 6| Step: 7
Training loss: 3.539021135976884
Validation loss: 2.884749767306454

Epoch: 6| Step: 8
Training loss: 3.3173714571026585
Validation loss: 2.8858300542223962

Epoch: 6| Step: 9
Training loss: 3.287106038554828
Validation loss: 2.888217663924818

Epoch: 6| Step: 10
Training loss: 3.1408744447250445
Validation loss: 2.885093094789632

Epoch: 6| Step: 11
Training loss: 2.612145329543563
Validation loss: 2.886422412289822

Epoch: 6| Step: 12
Training loss: 3.4975599230090486
Validation loss: 2.885716251967241

Epoch: 6| Step: 13
Training loss: 3.1619531452681415
Validation loss: 2.8864238013910746

Epoch: 119| Step: 0
Training loss: 2.8599369351563135
Validation loss: 2.889211566405002

Epoch: 6| Step: 1
Training loss: 2.869130320884322
Validation loss: 2.8859841956332364

Epoch: 6| Step: 2
Training loss: 3.5046908415575633
Validation loss: 2.884154767086801

Epoch: 6| Step: 3
Training loss: 3.7322528507401413
Validation loss: 2.8851763279159823

Epoch: 6| Step: 4
Training loss: 3.6558659017581845
Validation loss: 2.8865430075913525

Epoch: 6| Step: 5
Training loss: 3.411186910222688
Validation loss: 2.888080478949106

Epoch: 6| Step: 6
Training loss: 3.79019091605895
Validation loss: 2.888579573754074

Epoch: 6| Step: 7
Training loss: 2.449775595995201
Validation loss: 2.8894387952806375

Epoch: 6| Step: 8
Training loss: 2.5385323778018263
Validation loss: 2.8877236556527235

Epoch: 6| Step: 9
Training loss: 2.7380461544273524
Validation loss: 2.888111807938203

Epoch: 6| Step: 10
Training loss: 2.8070762896089616
Validation loss: 2.892347492757373

Epoch: 6| Step: 11
Training loss: 3.2565573051256727
Validation loss: 2.8876372359553004

Epoch: 6| Step: 12
Training loss: 3.336505207292657
Validation loss: 2.8921842680348657

Epoch: 6| Step: 13
Training loss: 3.209654465851602
Validation loss: 2.8875767416048084

Epoch: 120| Step: 0
Training loss: 2.998639911063538
Validation loss: 2.8868588733785012

Epoch: 6| Step: 1
Training loss: 2.799320962856596
Validation loss: 2.890667002383013

Epoch: 6| Step: 2
Training loss: 3.0012315765285673
Validation loss: 2.8955825159379893

Epoch: 6| Step: 3
Training loss: 2.917420607714859
Validation loss: 2.893160552325876

Epoch: 6| Step: 4
Training loss: 3.9649048448186996
Validation loss: 2.8915059058597046

Epoch: 6| Step: 5
Training loss: 3.0028723635280645
Validation loss: 2.894139637718397

Epoch: 6| Step: 6
Training loss: 2.6464526635553964
Validation loss: 2.888205560309016

Epoch: 6| Step: 7
Training loss: 3.2634117986216222
Validation loss: 2.8880771528759364

Epoch: 6| Step: 8
Training loss: 3.7957837455740364
Validation loss: 2.8851983631312064

Epoch: 6| Step: 9
Training loss: 3.1498173796986486
Validation loss: 2.8847544240244267

Epoch: 6| Step: 10
Training loss: 3.120769536410795
Validation loss: 2.8820614618321407

Epoch: 6| Step: 11
Training loss: 3.409260110991024
Validation loss: 2.881210200669034

Epoch: 6| Step: 12
Training loss: 2.772801457932007
Validation loss: 2.878773310844708

Epoch: 6| Step: 13
Training loss: 3.4837827991793504
Validation loss: 2.876731279947679

Epoch: 121| Step: 0
Training loss: 2.831775985263116
Validation loss: 2.880739755623806

Epoch: 6| Step: 1
Training loss: 2.306848062850457
Validation loss: 2.8799936772021297

Epoch: 6| Step: 2
Training loss: 2.8460378980117156
Validation loss: 2.8794460133749653

Epoch: 6| Step: 3
Training loss: 3.3282858939523696
Validation loss: 2.882192833278768

Epoch: 6| Step: 4
Training loss: 3.9792036417629633
Validation loss: 2.8814729511355814

Epoch: 6| Step: 5
Training loss: 3.966504760985533
Validation loss: 2.881113620646638

Epoch: 6| Step: 6
Training loss: 3.87449261204528
Validation loss: 2.8829199129019196

Epoch: 6| Step: 7
Training loss: 2.8403739591654604
Validation loss: 2.8816517802165404

Epoch: 6| Step: 8
Training loss: 2.9214506606140627
Validation loss: 2.8827868653694

Epoch: 6| Step: 9
Training loss: 2.6987520689468263
Validation loss: 2.879228381411476

Epoch: 6| Step: 10
Training loss: 3.03474995018236
Validation loss: 2.8764384961401728

Epoch: 6| Step: 11
Training loss: 3.52024463193636
Validation loss: 2.8797623139662183

Epoch: 6| Step: 12
Training loss: 2.8459829429817676
Validation loss: 2.8787342500516946

Epoch: 6| Step: 13
Training loss: 2.71446214367813
Validation loss: 2.87771141436298

Epoch: 122| Step: 0
Training loss: 3.4698446110389236
Validation loss: 2.8778473609823965

Epoch: 6| Step: 1
Training loss: 3.600651756204425
Validation loss: 2.875601430496276

Epoch: 6| Step: 2
Training loss: 2.8054088631816074
Validation loss: 2.8738890164775026

Epoch: 6| Step: 3
Training loss: 2.475401115666138
Validation loss: 2.87780834641621

Epoch: 6| Step: 4
Training loss: 2.996588356542228
Validation loss: 2.87739130934029

Epoch: 6| Step: 5
Training loss: 2.677688431293493
Validation loss: 2.8785359955761938

Epoch: 6| Step: 6
Training loss: 3.2669730438530857
Validation loss: 2.8812570613943342

Epoch: 6| Step: 7
Training loss: 2.8883519488786025
Validation loss: 2.881145028951143

Epoch: 6| Step: 8
Training loss: 2.5793908912755192
Validation loss: 2.882350508111213

Epoch: 6| Step: 9
Training loss: 3.325539601073135
Validation loss: 2.8836258014092078

Epoch: 6| Step: 10
Training loss: 3.206098413880919
Validation loss: 2.87775801046611

Epoch: 6| Step: 11
Training loss: 4.017711527774257
Validation loss: 2.8780414442641558

Epoch: 6| Step: 12
Training loss: 3.3170764906317958
Validation loss: 2.8758779026260495

Epoch: 6| Step: 13
Training loss: 3.6061488674534554
Validation loss: 2.873840419195357

Epoch: 123| Step: 0
Training loss: 3.064841173546744
Validation loss: 2.8755783722704265

Epoch: 6| Step: 1
Training loss: 3.337031950973992
Validation loss: 2.874970083272756

Epoch: 6| Step: 2
Training loss: 3.374620486926809
Validation loss: 2.8759198422664776

Epoch: 6| Step: 3
Training loss: 2.8977811743743014
Validation loss: 2.874656687065884

Epoch: 6| Step: 4
Training loss: 2.587670981245053
Validation loss: 2.877931298053931

Epoch: 6| Step: 5
Training loss: 2.427205378747863
Validation loss: 2.8728650170212027

Epoch: 6| Step: 6
Training loss: 3.0876348921617858
Validation loss: 2.8760169612788795

Epoch: 6| Step: 7
Training loss: 3.487773520842549
Validation loss: 2.874512829552149

Epoch: 6| Step: 8
Training loss: 3.8589419226189445
Validation loss: 2.8812303291816517

Epoch: 6| Step: 9
Training loss: 2.7054352342125205
Validation loss: 2.8733565531817584

Epoch: 6| Step: 10
Training loss: 3.886977113350671
Validation loss: 2.8768633813496365

Epoch: 6| Step: 11
Training loss: 3.1474919946400566
Validation loss: 2.8787243044347712

Epoch: 6| Step: 12
Training loss: 2.886332195659601
Validation loss: 2.875294094728679

Epoch: 6| Step: 13
Training loss: 3.3571525851865314
Validation loss: 2.8768877926838927

Epoch: 124| Step: 0
Training loss: 2.954875124698754
Validation loss: 2.8782797764995594

Epoch: 6| Step: 1
Training loss: 3.0144725435607054
Validation loss: 2.882250762473333

Epoch: 6| Step: 2
Training loss: 3.1222512935794886
Validation loss: 2.8821572771557706

Epoch: 6| Step: 3
Training loss: 3.291117191728356
Validation loss: 2.8875845898992254

Epoch: 6| Step: 4
Training loss: 3.2002926096648703
Validation loss: 2.902379115355468

Epoch: 6| Step: 5
Training loss: 2.595493879416474
Validation loss: 2.9164190219453467

Epoch: 6| Step: 6
Training loss: 3.4242551007474775
Validation loss: 2.905591167814774

Epoch: 6| Step: 7
Training loss: 2.911536382312573
Validation loss: 2.910687849062376

Epoch: 6| Step: 8
Training loss: 2.98324867284693
Validation loss: 2.900029519057823

Epoch: 6| Step: 9
Training loss: 3.8445594989658916
Validation loss: 2.890951932884288

Epoch: 6| Step: 10
Training loss: 2.7369351853824333
Validation loss: 2.8831621099169498

Epoch: 6| Step: 11
Training loss: 3.4852668749780604
Validation loss: 2.8741315633087687

Epoch: 6| Step: 12
Training loss: 3.8310182187038757
Validation loss: 2.871424471762322

Epoch: 6| Step: 13
Training loss: 2.5055031289054654
Validation loss: 2.8694845156966626

Epoch: 125| Step: 0
Training loss: 3.5558252546887514
Validation loss: 2.8739801714083812

Epoch: 6| Step: 1
Training loss: 3.403383641358422
Validation loss: 2.874104037858575

Epoch: 6| Step: 2
Training loss: 3.252720501145055
Validation loss: 2.879528158861228

Epoch: 6| Step: 3
Training loss: 2.845507403615953
Validation loss: 2.884981372150589

Epoch: 6| Step: 4
Training loss: 3.0994601487196083
Validation loss: 2.8936347633191475

Epoch: 6| Step: 5
Training loss: 3.4090999614710986
Validation loss: 2.882973223921077

Epoch: 6| Step: 6
Training loss: 2.675406637212085
Validation loss: 2.8800025618250085

Epoch: 6| Step: 7
Training loss: 2.9462644622149985
Validation loss: 2.8726847663796025

Epoch: 6| Step: 8
Training loss: 3.5734403502632652
Validation loss: 2.872342965342701

Epoch: 6| Step: 9
Training loss: 2.9762473753076844
Validation loss: 2.8694819158577065

Epoch: 6| Step: 10
Training loss: 3.8980794677228077
Validation loss: 2.869700161903795

Epoch: 6| Step: 11
Training loss: 2.5132541264904527
Validation loss: 2.8682200297851224

Epoch: 6| Step: 12
Training loss: 2.9809797056493297
Validation loss: 2.876236716917249

Epoch: 6| Step: 13
Training loss: 2.8824760426752345
Validation loss: 2.8787346151748716

Epoch: 126| Step: 0
Training loss: 3.1374576216187546
Validation loss: 2.884816723789351

Epoch: 6| Step: 1
Training loss: 3.184928305401375
Validation loss: 2.891839450918818

Epoch: 6| Step: 2
Training loss: 3.319988782473078
Validation loss: 2.8916613511693923

Epoch: 6| Step: 3
Training loss: 3.0898912814375064
Validation loss: 2.888953496183197

Epoch: 6| Step: 4
Training loss: 2.789505525339073
Validation loss: 2.884316322809628

Epoch: 6| Step: 5
Training loss: 2.768672320307394
Validation loss: 2.8854391037103535

Epoch: 6| Step: 6
Training loss: 3.3963196919085807
Validation loss: 2.877871947477237

Epoch: 6| Step: 7
Training loss: 2.7131730681693265
Validation loss: 2.8793261946046775

Epoch: 6| Step: 8
Training loss: 3.3307327298326004
Validation loss: 2.8785091116262573

Epoch: 6| Step: 9
Training loss: 3.0059240977437347
Validation loss: 2.8807173383406237

Epoch: 6| Step: 10
Training loss: 3.501490820406797
Validation loss: 2.8784897977053423

Epoch: 6| Step: 11
Training loss: 3.5292499921225433
Validation loss: 2.8706625936057946

Epoch: 6| Step: 12
Training loss: 2.8332654907481674
Validation loss: 2.8688107587700995

Epoch: 6| Step: 13
Training loss: 3.885487300990972
Validation loss: 2.866871745359264

Epoch: 127| Step: 0
Training loss: 2.9255926787007587
Validation loss: 2.8668167130674003

Epoch: 6| Step: 1
Training loss: 3.2272884854507127
Validation loss: 2.865200206454073

Epoch: 6| Step: 2
Training loss: 2.556632232069398
Validation loss: 2.8648840090703787

Epoch: 6| Step: 3
Training loss: 2.9750439231899866
Validation loss: 2.865910285880977

Epoch: 6| Step: 4
Training loss: 3.6371944128712017
Validation loss: 2.865509320867742

Epoch: 6| Step: 5
Training loss: 3.3074289048123444
Validation loss: 2.8663449619391526

Epoch: 6| Step: 6
Training loss: 2.912845797332582
Validation loss: 2.8625478334716172

Epoch: 6| Step: 7
Training loss: 3.42866073219616
Validation loss: 2.8643881576735764

Epoch: 6| Step: 8
Training loss: 3.875528853229184
Validation loss: 2.863848459318661

Epoch: 6| Step: 9
Training loss: 3.580880382697186
Validation loss: 2.865230826457813

Epoch: 6| Step: 10
Training loss: 3.040275116066319
Validation loss: 2.8672611584427807

Epoch: 6| Step: 11
Training loss: 2.992626665919467
Validation loss: 2.864402960116744

Epoch: 6| Step: 12
Training loss: 2.63286574674921
Validation loss: 2.8636304038130684

Epoch: 6| Step: 13
Training loss: 2.6376362878380646
Validation loss: 2.8609732806298536

Epoch: 128| Step: 0
Training loss: 3.0507071628928246
Validation loss: 2.8632707895996274

Epoch: 6| Step: 1
Training loss: 2.4155964838592667
Validation loss: 2.8633085267266405

Epoch: 6| Step: 2
Training loss: 3.254383065961143
Validation loss: 2.8598399495651385

Epoch: 6| Step: 3
Training loss: 3.331006159634422
Validation loss: 2.86361103609404

Epoch: 6| Step: 4
Training loss: 3.602524899801044
Validation loss: 2.8621111932695382

Epoch: 6| Step: 5
Training loss: 3.668004629916365
Validation loss: 2.8629925350093766

Epoch: 6| Step: 6
Training loss: 3.1401369844916114
Validation loss: 2.864442128628734

Epoch: 6| Step: 7
Training loss: 2.9683612769766246
Validation loss: 2.863754883535958

Epoch: 6| Step: 8
Training loss: 3.6480938833352985
Validation loss: 2.875374204760802

Epoch: 6| Step: 9
Training loss: 2.9241301457655746
Validation loss: 2.926767307586779

Epoch: 6| Step: 10
Training loss: 3.0690589267596105
Validation loss: 2.92448791117473

Epoch: 6| Step: 11
Training loss: 3.2192887531237036
Validation loss: 2.9154480727983665

Epoch: 6| Step: 12
Training loss: 2.83665116843425
Validation loss: 2.8938497402781156

Epoch: 6| Step: 13
Training loss: 2.8298166179214603
Validation loss: 2.8728511443006575

Epoch: 129| Step: 0
Training loss: 2.88849227171543
Validation loss: 2.859629701679042

Epoch: 6| Step: 1
Training loss: 3.227786222334857
Validation loss: 2.8596165339460566

Epoch: 6| Step: 2
Training loss: 2.954387415147055
Validation loss: 2.8572646566657762

Epoch: 6| Step: 3
Training loss: 2.7573585893161745
Validation loss: 2.8555364056318004

Epoch: 6| Step: 4
Training loss: 3.468849799292802
Validation loss: 2.855134518899196

Epoch: 6| Step: 5
Training loss: 2.4207044172075785
Validation loss: 2.85403161073294

Epoch: 6| Step: 6
Training loss: 3.71066919260308
Validation loss: 2.8515445175424263

Epoch: 6| Step: 7
Training loss: 3.4950780320085992
Validation loss: 2.851292685592796

Epoch: 6| Step: 8
Training loss: 2.5213478340984006
Validation loss: 2.8508364263393675

Epoch: 6| Step: 9
Training loss: 3.172350166696476
Validation loss: 2.849719376233039

Epoch: 6| Step: 10
Training loss: 3.8160967511001767
Validation loss: 2.8485773585483516

Epoch: 6| Step: 11
Training loss: 3.0457514329606474
Validation loss: 2.848066371459471

Epoch: 6| Step: 12
Training loss: 3.372654700439041
Validation loss: 2.8487927677666076

Epoch: 6| Step: 13
Training loss: 2.8095069217790103
Validation loss: 2.8426960683901408

Epoch: 130| Step: 0
Training loss: 3.487404639468263
Validation loss: 2.846254482992538

Epoch: 6| Step: 1
Training loss: 3.2885301027687746
Validation loss: 2.8406854411790556

Epoch: 6| Step: 2
Training loss: 3.5411540539337465
Validation loss: 2.8458025751487743

Epoch: 6| Step: 3
Training loss: 2.8923390848013875
Validation loss: 2.8406408920772206

Epoch: 6| Step: 4
Training loss: 3.2167436587223075
Validation loss: 2.841590725077032

Epoch: 6| Step: 5
Training loss: 3.122524043556413
Validation loss: 2.83694406380965

Epoch: 6| Step: 6
Training loss: 2.9773566520769714
Validation loss: 2.8368020681821173

Epoch: 6| Step: 7
Training loss: 2.056315658124002
Validation loss: 2.838180159215584

Epoch: 6| Step: 8
Training loss: 2.666555094371684
Validation loss: 2.841451966532535

Epoch: 6| Step: 9
Training loss: 3.633208485012778
Validation loss: 2.8397854919772585

Epoch: 6| Step: 10
Training loss: 3.094751215289153
Validation loss: 2.8394702122318134

Epoch: 6| Step: 11
Training loss: 2.9063294102474244
Validation loss: 2.835896029454878

Epoch: 6| Step: 12
Training loss: 3.2130630771537234
Validation loss: 2.8359259470676603

Epoch: 6| Step: 13
Training loss: 3.8314757338169487
Validation loss: 2.8342124822456083

Epoch: 131| Step: 0
Training loss: 3.4316907867082973
Validation loss: 2.83566318198713

Epoch: 6| Step: 1
Training loss: 3.570169191385017
Validation loss: 2.8362379826518844

Epoch: 6| Step: 2
Training loss: 3.128889486241765
Validation loss: 2.8369857273260033

Epoch: 6| Step: 3
Training loss: 2.9989487077550367
Validation loss: 2.83405324999599

Epoch: 6| Step: 4
Training loss: 2.964196658479184
Validation loss: 2.8298111994963855

Epoch: 6| Step: 5
Training loss: 3.6723481867647005
Validation loss: 2.831863708632188

Epoch: 6| Step: 6
Training loss: 3.1118102385613797
Validation loss: 2.831985088307392

Epoch: 6| Step: 7
Training loss: 3.221486530139027
Validation loss: 2.8307795594214356

Epoch: 6| Step: 8
Training loss: 3.0244391307586374
Validation loss: 2.8329546444308353

Epoch: 6| Step: 9
Training loss: 2.6963364577281386
Validation loss: 2.8260987476132806

Epoch: 6| Step: 10
Training loss: 3.6523395721901237
Validation loss: 2.830138269514545

Epoch: 6| Step: 11
Training loss: 3.171789459428063
Validation loss: 2.832495531745619

Epoch: 6| Step: 12
Training loss: 2.183474515276582
Validation loss: 2.832669584521761

Epoch: 6| Step: 13
Training loss: 2.452031371658041
Validation loss: 2.8298087824460403

Epoch: 132| Step: 0
Training loss: 2.9102779900605977
Validation loss: 2.8385094955320684

Epoch: 6| Step: 1
Training loss: 2.893174650203404
Validation loss: 2.834521926223152

Epoch: 6| Step: 2
Training loss: 2.9190294413792186
Validation loss: 2.8347419657961397

Epoch: 6| Step: 3
Training loss: 3.1288204490908273
Validation loss: 2.8404295317553103

Epoch: 6| Step: 4
Training loss: 2.6715582051891325
Validation loss: 2.8413645301656807

Epoch: 6| Step: 5
Training loss: 2.9445500284933677
Validation loss: 2.844711682003067

Epoch: 6| Step: 6
Training loss: 3.143309551349964
Validation loss: 2.839383902134172

Epoch: 6| Step: 7
Training loss: 3.4768004603867064
Validation loss: 2.830693107508366

Epoch: 6| Step: 8
Training loss: 3.54291114634126
Validation loss: 2.8319873441772927

Epoch: 6| Step: 9
Training loss: 3.411888565229376
Validation loss: 2.8315969958128733

Epoch: 6| Step: 10
Training loss: 3.241276698122063
Validation loss: 2.825845705812691

Epoch: 6| Step: 11
Training loss: 3.1544182627088055
Validation loss: 2.8254816736001196

Epoch: 6| Step: 12
Training loss: 2.995058121921263
Validation loss: 2.8243302157745434

Epoch: 6| Step: 13
Training loss: 3.523154778144054
Validation loss: 2.829541484525659

Epoch: 133| Step: 0
Training loss: 3.4401865777716725
Validation loss: 2.826702869211119

Epoch: 6| Step: 1
Training loss: 2.5808422219116487
Validation loss: 2.8324878946536614

Epoch: 6| Step: 2
Training loss: 3.2937639210821206
Validation loss: 2.828138064169194

Epoch: 6| Step: 3
Training loss: 3.139659828177238
Validation loss: 2.8283181571820384

Epoch: 6| Step: 4
Training loss: 3.3115924095681484
Validation loss: 2.8257411259417933

Epoch: 6| Step: 5
Training loss: 3.345882983253011
Validation loss: 2.827999765110112

Epoch: 6| Step: 6
Training loss: 3.1302216202151882
Validation loss: 2.827355576070629

Epoch: 6| Step: 7
Training loss: 2.92527499740192
Validation loss: 2.8265588222228435

Epoch: 6| Step: 8
Training loss: 3.0220765986451457
Validation loss: 2.826939789245638

Epoch: 6| Step: 9
Training loss: 2.880521696311264
Validation loss: 2.8246376565329143

Epoch: 6| Step: 10
Training loss: 2.370027154533534
Validation loss: 2.826120723673606

Epoch: 6| Step: 11
Training loss: 3.356431674124895
Validation loss: 2.8288422380228817

Epoch: 6| Step: 12
Training loss: 3.422277557522928
Validation loss: 2.8287541218819863

Epoch: 6| Step: 13
Training loss: 3.6070093105905636
Validation loss: 2.8228170517101323

Epoch: 134| Step: 0
Training loss: 2.8103997759998385
Validation loss: 2.8267219619785195

Epoch: 6| Step: 1
Training loss: 3.1548547965851963
Validation loss: 2.8259538170848395

Epoch: 6| Step: 2
Training loss: 3.172945339969179
Validation loss: 2.8232109168630415

Epoch: 6| Step: 3
Training loss: 3.753968745415009
Validation loss: 2.8272126386778833

Epoch: 6| Step: 4
Training loss: 2.7080758681551607
Validation loss: 2.8251832964098775

Epoch: 6| Step: 5
Training loss: 2.9560395244490527
Validation loss: 2.826211437293107

Epoch: 6| Step: 6
Training loss: 3.0710258916957733
Validation loss: 2.8240812693645676

Epoch: 6| Step: 7
Training loss: 3.4605839464764254
Validation loss: 2.8236548925879545

Epoch: 6| Step: 8
Training loss: 3.378278199849896
Validation loss: 2.8266551204032684

Epoch: 6| Step: 9
Training loss: 2.8293343166142275
Validation loss: 2.8253758244650604

Epoch: 6| Step: 10
Training loss: 2.5321986928421985
Validation loss: 2.82532648800224

Epoch: 6| Step: 11
Training loss: 2.620415089463665
Validation loss: 2.8254278730321833

Epoch: 6| Step: 12
Training loss: 3.504764175426644
Validation loss: 2.831874390056834

Epoch: 6| Step: 13
Training loss: 3.893497616837819
Validation loss: 2.8311036801003895

Epoch: 135| Step: 0
Training loss: 3.337561611792688
Validation loss: 2.831893821835884

Epoch: 6| Step: 1
Training loss: 3.3085043939011007
Validation loss: 2.825131540070092

Epoch: 6| Step: 2
Training loss: 3.5564401853956946
Validation loss: 2.8215810325902284

Epoch: 6| Step: 3
Training loss: 3.6192358820690527
Validation loss: 2.820778646957059

Epoch: 6| Step: 4
Training loss: 2.0172114080523667
Validation loss: 2.8198141158125876

Epoch: 6| Step: 5
Training loss: 2.6878470263322076
Validation loss: 2.8250603286351867

Epoch: 6| Step: 6
Training loss: 3.047063264165619
Validation loss: 2.8198158886591163

Epoch: 6| Step: 7
Training loss: 3.2273879207708664
Validation loss: 2.8232663923351873

Epoch: 6| Step: 8
Training loss: 3.1378462155881164
Validation loss: 2.8184046665160483

Epoch: 6| Step: 9
Training loss: 3.836227126365627
Validation loss: 2.8224465105381444

Epoch: 6| Step: 10
Training loss: 3.16990186834221
Validation loss: 2.82124593999214

Epoch: 6| Step: 11
Training loss: 2.8112095733490428
Validation loss: 2.820484935906775

Epoch: 6| Step: 12
Training loss: 2.3429919224859117
Validation loss: 2.8196545155100345

Epoch: 6| Step: 13
Training loss: 3.271263547817538
Validation loss: 2.8203596199177823

Epoch: 136| Step: 0
Training loss: 2.9189614850359105
Validation loss: 2.8211321241556444

Epoch: 6| Step: 1
Training loss: 2.9375361988190987
Validation loss: 2.81769038350792

Epoch: 6| Step: 2
Training loss: 3.0786841799553306
Validation loss: 2.8180103415755595

Epoch: 6| Step: 3
Training loss: 3.379236740972447
Validation loss: 2.8192409461002637

Epoch: 6| Step: 4
Training loss: 3.126167994616797
Validation loss: 2.817903876999494

Epoch: 6| Step: 5
Training loss: 3.141963540645733
Validation loss: 2.8206944851629427

Epoch: 6| Step: 6
Training loss: 2.9434342200794243
Validation loss: 2.819785804666224

Epoch: 6| Step: 7
Training loss: 2.835890756437259
Validation loss: 2.81941364667615

Epoch: 6| Step: 8
Training loss: 3.5604373247511947
Validation loss: 2.8186689586324873

Epoch: 6| Step: 9
Training loss: 3.4531680833709384
Validation loss: 2.8200343730056088

Epoch: 6| Step: 10
Training loss: 2.842957270872418
Validation loss: 2.8211072203657395

Epoch: 6| Step: 11
Training loss: 3.378928547162703
Validation loss: 2.8235869143046703

Epoch: 6| Step: 12
Training loss: 2.328566029397788
Validation loss: 2.8214782381769923

Epoch: 6| Step: 13
Training loss: 3.939309083029122
Validation loss: 2.8252875031215043

Epoch: 137| Step: 0
Training loss: 3.4524560340772377
Validation loss: 2.822122301721218

Epoch: 6| Step: 1
Training loss: 3.209250347981676
Validation loss: 2.821233507255254

Epoch: 6| Step: 2
Training loss: 2.4138995365580596
Validation loss: 2.8231009515627634

Epoch: 6| Step: 3
Training loss: 3.169990769141202
Validation loss: 2.8166233677845107

Epoch: 6| Step: 4
Training loss: 3.174608978462969
Validation loss: 2.82340520109623

Epoch: 6| Step: 5
Training loss: 3.366813762837982
Validation loss: 2.8172249176412643

Epoch: 6| Step: 6
Training loss: 2.2696471192923493
Validation loss: 2.81628277883328

Epoch: 6| Step: 7
Training loss: 3.162003212007246
Validation loss: 2.819821894509382

Epoch: 6| Step: 8
Training loss: 3.231872475025
Validation loss: 2.820893617605259

Epoch: 6| Step: 9
Training loss: 2.353077144060185
Validation loss: 2.819080136144219

Epoch: 6| Step: 10
Training loss: 3.1442096048134998
Validation loss: 2.818382033583604

Epoch: 6| Step: 11
Training loss: 3.4244923793213897
Validation loss: 2.818086628131283

Epoch: 6| Step: 12
Training loss: 3.7479449681218404
Validation loss: 2.8210051429723375

Epoch: 6| Step: 13
Training loss: 3.347713794903604
Validation loss: 2.815956693239729

Epoch: 138| Step: 0
Training loss: 3.1005356479681523
Validation loss: 2.815245473534275

Epoch: 6| Step: 1
Training loss: 3.325887868407505
Validation loss: 2.813569242798907

Epoch: 6| Step: 2
Training loss: 3.267840350403474
Validation loss: 2.8190136244625195

Epoch: 6| Step: 3
Training loss: 3.2346680734143365
Validation loss: 2.8111947169753506

Epoch: 6| Step: 4
Training loss: 2.6802217267963595
Validation loss: 2.8157350481847905

Epoch: 6| Step: 5
Training loss: 2.9030383011896053
Validation loss: 2.816274568894716

Epoch: 6| Step: 6
Training loss: 3.5632030395676417
Validation loss: 2.820127455035378

Epoch: 6| Step: 7
Training loss: 3.017893358079398
Validation loss: 2.815378186204287

Epoch: 6| Step: 8
Training loss: 3.4571300082998193
Validation loss: 2.8172522826650104

Epoch: 6| Step: 9
Training loss: 3.0044584523231204
Validation loss: 2.8128384476522417

Epoch: 6| Step: 10
Training loss: 2.712506546504827
Validation loss: 2.8142302282967075

Epoch: 6| Step: 11
Training loss: 3.249817036100254
Validation loss: 2.8192685425301938

Epoch: 6| Step: 12
Training loss: 2.98809295260509
Validation loss: 2.8159498652483315

Epoch: 6| Step: 13
Training loss: 3.050326695690062
Validation loss: 2.8115757890084896

Epoch: 139| Step: 0
Training loss: 3.3236477963334603
Validation loss: 2.8167200365839613

Epoch: 6| Step: 1
Training loss: 2.9580503695560303
Validation loss: 2.81325984339025

Epoch: 6| Step: 2
Training loss: 2.7877637045619816
Validation loss: 2.816748291170748

Epoch: 6| Step: 3
Training loss: 3.2530602938824797
Validation loss: 2.8149699040918037

Epoch: 6| Step: 4
Training loss: 3.2823968245596684
Validation loss: 2.8124824696567616

Epoch: 6| Step: 5
Training loss: 3.7723473026423386
Validation loss: 2.8176425711367683

Epoch: 6| Step: 6
Training loss: 3.052720004564705
Validation loss: 2.813537648703714

Epoch: 6| Step: 7
Training loss: 3.1945567088279976
Validation loss: 2.817916539131262

Epoch: 6| Step: 8
Training loss: 3.483078651304664
Validation loss: 2.810368874215555

Epoch: 6| Step: 9
Training loss: 2.781561930448197
Validation loss: 2.8138714954544413

Epoch: 6| Step: 10
Training loss: 2.8797001772687922
Validation loss: 2.8123856661400795

Epoch: 6| Step: 11
Training loss: 2.4058361936190384
Validation loss: 2.8091660431273815

Epoch: 6| Step: 12
Training loss: 3.523177921857961
Validation loss: 2.8154936405284983

Epoch: 6| Step: 13
Training loss: 2.36433142666014
Validation loss: 2.8169209379774713

Epoch: 140| Step: 0
Training loss: 2.8968834013750207
Validation loss: 2.813504350326556

Epoch: 6| Step: 1
Training loss: 2.4676874505819746
Validation loss: 2.8126136182580126

Epoch: 6| Step: 2
Training loss: 3.3596761878973416
Validation loss: 2.8080489729775735

Epoch: 6| Step: 3
Training loss: 3.5025869073643463
Validation loss: 2.8067743638021225

Epoch: 6| Step: 4
Training loss: 3.1668249057250555
Validation loss: 2.815768092567755

Epoch: 6| Step: 5
Training loss: 2.824748178246658
Validation loss: 2.8136407031530406

Epoch: 6| Step: 6
Training loss: 3.5054401625234206
Validation loss: 2.80911189722568

Epoch: 6| Step: 7
Training loss: 3.0579507475854157
Validation loss: 2.814016409630872

Epoch: 6| Step: 8
Training loss: 2.5650462084320433
Validation loss: 2.8082170806783524

Epoch: 6| Step: 9
Training loss: 2.909178867961029
Validation loss: 2.8126962080574853

Epoch: 6| Step: 10
Training loss: 2.6400069015586114
Validation loss: 2.813788627644765

Epoch: 6| Step: 11
Training loss: 4.061739336839538
Validation loss: 2.8112985941304243

Epoch: 6| Step: 12
Training loss: 2.9055622886869834
Validation loss: 2.80850180189404

Epoch: 6| Step: 13
Training loss: 3.590320974680803
Validation loss: 2.806732061382423

Epoch: 141| Step: 0
Training loss: 3.2588117425510594
Validation loss: 2.8060177169534133

Epoch: 6| Step: 1
Training loss: 2.5551312262471972
Validation loss: 2.8055745650472232

Epoch: 6| Step: 2
Training loss: 2.92635813425692
Validation loss: 2.809055187603825

Epoch: 6| Step: 3
Training loss: 3.307854327701856
Validation loss: 2.8102676957693395

Epoch: 6| Step: 4
Training loss: 3.2423504524185582
Validation loss: 2.8095860324402038

Epoch: 6| Step: 5
Training loss: 3.5127667145926305
Validation loss: 2.8091263475512283

Epoch: 6| Step: 6
Training loss: 3.1887874621108923
Validation loss: 2.8080032414500984

Epoch: 6| Step: 7
Training loss: 2.733187782862784
Validation loss: 2.8077021886969225

Epoch: 6| Step: 8
Training loss: 3.5381215172962595
Validation loss: 2.8071351944998146

Epoch: 6| Step: 9
Training loss: 2.5563189695422888
Validation loss: 2.8087235933216546

Epoch: 6| Step: 10
Training loss: 2.513828180843459
Validation loss: 2.8035062803080613

Epoch: 6| Step: 11
Training loss: 3.436005701044791
Validation loss: 2.8085607982888994

Epoch: 6| Step: 12
Training loss: 3.480059906893329
Validation loss: 2.8039372633834265

Epoch: 6| Step: 13
Training loss: 3.1017654314122316
Validation loss: 2.8053405807555825

Epoch: 142| Step: 0
Training loss: 3.43389773189559
Validation loss: 2.8062385773898466

Epoch: 6| Step: 1
Training loss: 3.548838739793908
Validation loss: 2.806610758759517

Epoch: 6| Step: 2
Training loss: 2.7912138861144857
Validation loss: 2.805768915580714

Epoch: 6| Step: 3
Training loss: 3.586475473245346
Validation loss: 2.805317928325758

Epoch: 6| Step: 4
Training loss: 2.6697310384374746
Validation loss: 2.8059962348677376

Epoch: 6| Step: 5
Training loss: 2.7764783066160224
Validation loss: 2.8084193562082134

Epoch: 6| Step: 6
Training loss: 3.1843410621159802
Validation loss: 2.8118986254777862

Epoch: 6| Step: 7
Training loss: 2.906378466320198
Validation loss: 2.8145733800840063

Epoch: 6| Step: 8
Training loss: 3.0514226378438787
Validation loss: 2.814106688985195

Epoch: 6| Step: 9
Training loss: 3.4896482243364098
Validation loss: 2.813277357954271

Epoch: 6| Step: 10
Training loss: 2.7762894701739023
Validation loss: 2.8074860228244267

Epoch: 6| Step: 11
Training loss: 3.2093406846274335
Validation loss: 2.8022443386057567

Epoch: 6| Step: 12
Training loss: 2.784229354388635
Validation loss: 2.802934212677952

Epoch: 6| Step: 13
Training loss: 3.328138611098561
Validation loss: 2.804253145481357

Epoch: 143| Step: 0
Training loss: 3.857666131507201
Validation loss: 2.8059187059473243

Epoch: 6| Step: 1
Training loss: 2.9215587097985565
Validation loss: 2.805262391265481

Epoch: 6| Step: 2
Training loss: 3.561971926450541
Validation loss: 2.8076525151908998

Epoch: 6| Step: 3
Training loss: 2.351210254128425
Validation loss: 2.8056854164655216

Epoch: 6| Step: 4
Training loss: 3.37914247954932
Validation loss: 2.8096730571606203

Epoch: 6| Step: 5
Training loss: 3.2148654051708383
Validation loss: 2.8086306737129103

Epoch: 6| Step: 6
Training loss: 2.965503242332681
Validation loss: 2.80927539858625

Epoch: 6| Step: 7
Training loss: 2.755037981522681
Validation loss: 2.8100443758405773

Epoch: 6| Step: 8
Training loss: 2.848584938104737
Validation loss: 2.81157506320262

Epoch: 6| Step: 9
Training loss: 3.0732772529378622
Validation loss: 2.8121929753121697

Epoch: 6| Step: 10
Training loss: 3.028120175132411
Validation loss: 2.8317961564468037

Epoch: 6| Step: 11
Training loss: 2.509288888026203
Validation loss: 2.8199041695516787

Epoch: 6| Step: 12
Training loss: 3.4749164928035334
Validation loss: 2.835244447799

Epoch: 6| Step: 13
Training loss: 3.403915725355113
Validation loss: 2.8322366528957588

Epoch: 144| Step: 0
Training loss: 3.0999207271161464
Validation loss: 2.833615479605563

Epoch: 6| Step: 1
Training loss: 2.786720296839527
Validation loss: 2.814602232779319

Epoch: 6| Step: 2
Training loss: 2.92192297911393
Validation loss: 2.8164152396386606

Epoch: 6| Step: 3
Training loss: 3.4193823806607737
Validation loss: 2.810721694077026

Epoch: 6| Step: 4
Training loss: 2.5502859104912616
Validation loss: 2.8083341329821807

Epoch: 6| Step: 5
Training loss: 2.9217181648144868
Validation loss: 2.799466649471305

Epoch: 6| Step: 6
Training loss: 3.8252405627030606
Validation loss: 2.80157503298964

Epoch: 6| Step: 7
Training loss: 3.1097089885206515
Validation loss: 2.799542844276588

Epoch: 6| Step: 8
Training loss: 3.0158751388931133
Validation loss: 2.798322867367735

Epoch: 6| Step: 9
Training loss: 3.4035527460531614
Validation loss: 2.799107787597794

Epoch: 6| Step: 10
Training loss: 2.38335405042843
Validation loss: 2.800203893345716

Epoch: 6| Step: 11
Training loss: 3.2663357339987673
Validation loss: 2.7969199574740746

Epoch: 6| Step: 12
Training loss: 3.4758346652974446
Validation loss: 2.799621738352907

Epoch: 6| Step: 13
Training loss: 3.1295637756665635
Validation loss: 2.79858163413527

Epoch: 145| Step: 0
Training loss: 2.8552767040626192
Validation loss: 2.7997931686016706

Epoch: 6| Step: 1
Training loss: 3.12147093822388
Validation loss: 2.7983332499028464

Epoch: 6| Step: 2
Training loss: 2.989205011937715
Validation loss: 2.8010265569974524

Epoch: 6| Step: 3
Training loss: 2.899365217517583
Validation loss: 2.800540822620168

Epoch: 6| Step: 4
Training loss: 3.7538904989588904
Validation loss: 2.7974101512641028

Epoch: 6| Step: 5
Training loss: 3.1057311516989525
Validation loss: 2.79617515025806

Epoch: 6| Step: 6
Training loss: 3.434002293225491
Validation loss: 2.795553335436884

Epoch: 6| Step: 7
Training loss: 3.3676600290632215
Validation loss: 2.795496870738701

Epoch: 6| Step: 8
Training loss: 3.3121236911288374
Validation loss: 2.7959153419537675

Epoch: 6| Step: 9
Training loss: 3.583274899974751
Validation loss: 2.794019674142752

Epoch: 6| Step: 10
Training loss: 2.562135996202604
Validation loss: 2.7952223039203576

Epoch: 6| Step: 11
Training loss: 2.413316037219682
Validation loss: 2.804398352819936

Epoch: 6| Step: 12
Training loss: 3.1836454235166047
Validation loss: 2.7997371685000383

Epoch: 6| Step: 13
Training loss: 2.3376757428203248
Validation loss: 2.796319797021452

Epoch: 146| Step: 0
Training loss: 3.4559019496395527
Validation loss: 2.794490534499773

Epoch: 6| Step: 1
Training loss: 2.9165826694564028
Validation loss: 2.7966175841977243

Epoch: 6| Step: 2
Training loss: 3.2940036509527784
Validation loss: 2.7976210971593742

Epoch: 6| Step: 3
Training loss: 3.1208740462604494
Validation loss: 2.799267627520048

Epoch: 6| Step: 4
Training loss: 2.999650299035524
Validation loss: 2.8004393257091653

Epoch: 6| Step: 5
Training loss: 2.8758067782014347
Validation loss: 2.7971337412365744

Epoch: 6| Step: 6
Training loss: 3.7268276160281206
Validation loss: 2.7905787171030934

Epoch: 6| Step: 7
Training loss: 2.2757730449158
Validation loss: 2.7970170432808534

Epoch: 6| Step: 8
Training loss: 3.276574573121683
Validation loss: 2.7996594983012923

Epoch: 6| Step: 9
Training loss: 3.0150882856054344
Validation loss: 2.7934104115296803

Epoch: 6| Step: 10
Training loss: 3.174048519991965
Validation loss: 2.7950113943638444

Epoch: 6| Step: 11
Training loss: 3.1170271829858422
Validation loss: 2.7946179608823987

Epoch: 6| Step: 12
Training loss: 2.5807399550647725
Validation loss: 2.7942138705214

Epoch: 6| Step: 13
Training loss: 3.5333888235473236
Validation loss: 2.7928453496911736

Epoch: 147| Step: 0
Training loss: 2.969277746574697
Validation loss: 2.7932802556254765

Epoch: 6| Step: 1
Training loss: 2.3199872646311093
Validation loss: 2.793519316463784

Epoch: 6| Step: 2
Training loss: 3.1186568924760354
Validation loss: 2.7977605726055614

Epoch: 6| Step: 3
Training loss: 3.8521418570980783
Validation loss: 2.7922646132087534

Epoch: 6| Step: 4
Training loss: 3.018161161817913
Validation loss: 2.79751123572878

Epoch: 6| Step: 5
Training loss: 3.1512243464877225
Validation loss: 2.7967067037015307

Epoch: 6| Step: 6
Training loss: 2.702293841520646
Validation loss: 2.795998461672365

Epoch: 6| Step: 7
Training loss: 3.184886534150408
Validation loss: 2.796020360737759

Epoch: 6| Step: 8
Training loss: 2.8208665805436937
Validation loss: 2.797471348197183

Epoch: 6| Step: 9
Training loss: 3.0537445095792077
Validation loss: 2.7999929534219885

Epoch: 6| Step: 10
Training loss: 2.997404883421032
Validation loss: 2.8000871933341673

Epoch: 6| Step: 11
Training loss: 3.5732764831214925
Validation loss: 2.8010535540079653

Epoch: 6| Step: 12
Training loss: 3.728450784574033
Validation loss: 2.799903819487566

Epoch: 6| Step: 13
Training loss: 2.0715139681496857
Validation loss: 2.7971050758802547

Epoch: 148| Step: 0
Training loss: 2.768742587594127
Validation loss: 2.804224786937926

Epoch: 6| Step: 1
Training loss: 2.586838026646573
Validation loss: 2.804672599024166

Epoch: 6| Step: 2
Training loss: 3.306167018836966
Validation loss: 2.8006808401003602

Epoch: 6| Step: 3
Training loss: 2.629735127299363
Validation loss: 2.800821643245791

Epoch: 6| Step: 4
Training loss: 3.2448669392206315
Validation loss: 2.7991258852842846

Epoch: 6| Step: 5
Training loss: 3.0534924757461703
Validation loss: 2.798907838840977

Epoch: 6| Step: 6
Training loss: 3.3855689537813443
Validation loss: 2.795940304169203

Epoch: 6| Step: 7
Training loss: 2.7545959041987387
Validation loss: 2.7932974659433465

Epoch: 6| Step: 8
Training loss: 2.6771856701558434
Validation loss: 2.7929026316991523

Epoch: 6| Step: 9
Training loss: 3.5100873270066786
Validation loss: 2.799964872189687

Epoch: 6| Step: 10
Training loss: 3.360826755261544
Validation loss: 2.8007347663830604

Epoch: 6| Step: 11
Training loss: 3.3845861423669716
Validation loss: 2.793612033002732

Epoch: 6| Step: 12
Training loss: 3.231993457258797
Validation loss: 2.791274744977626

Epoch: 6| Step: 13
Training loss: 3.4551613443464992
Validation loss: 2.7929559573250504

Epoch: 149| Step: 0
Training loss: 2.992172201331647
Validation loss: 2.7892157068843466

Epoch: 6| Step: 1
Training loss: 2.7159237257257356
Validation loss: 2.7897848203471276

Epoch: 6| Step: 2
Training loss: 2.9786184024275877
Validation loss: 2.7917727859033494

Epoch: 6| Step: 3
Training loss: 2.7642147973230564
Validation loss: 2.7902333163327167

Epoch: 6| Step: 4
Training loss: 2.942750499502011
Validation loss: 2.7918728375941466

Epoch: 6| Step: 5
Training loss: 2.9490961920933887
Validation loss: 2.7925630219258424

Epoch: 6| Step: 6
Training loss: 3.699309882679912
Validation loss: 2.79171124733262

Epoch: 6| Step: 7
Training loss: 2.8034952759054055
Validation loss: 2.7908783449934944

Epoch: 6| Step: 8
Training loss: 3.48021172153491
Validation loss: 2.7924819105493692

Epoch: 6| Step: 9
Training loss: 3.328975371847498
Validation loss: 2.79022621866494

Epoch: 6| Step: 10
Training loss: 3.023738717936883
Validation loss: 2.792749659203775

Epoch: 6| Step: 11
Training loss: 2.9056385996880394
Validation loss: 2.7878679646356654

Epoch: 6| Step: 12
Training loss: 3.5115314981100823
Validation loss: 2.7905461727786767

Epoch: 6| Step: 13
Training loss: 3.1204648488330604
Validation loss: 2.786407419329344

Epoch: 150| Step: 0
Training loss: 3.065348487694863
Validation loss: 2.7821015725777953

Epoch: 6| Step: 1
Training loss: 3.3819531060503247
Validation loss: 2.7886719173248125

Epoch: 6| Step: 2
Training loss: 3.085503888147674
Validation loss: 2.7887451031719106

Epoch: 6| Step: 3
Training loss: 2.864895853276707
Validation loss: 2.786177959871193

Epoch: 6| Step: 4
Training loss: 3.1074720530891313
Validation loss: 2.783623617517503

Epoch: 6| Step: 5
Training loss: 2.1251837707043446
Validation loss: 2.7838266200702577

Epoch: 6| Step: 6
Training loss: 3.1610706642601016
Validation loss: 2.7830095549595577

Epoch: 6| Step: 7
Training loss: 4.03106712695371
Validation loss: 2.7850563555952346

Epoch: 6| Step: 8
Training loss: 2.9155050598529786
Validation loss: 2.7832667491342398

Epoch: 6| Step: 9
Training loss: 2.7667932144392875
Validation loss: 2.7868643465552263

Epoch: 6| Step: 10
Training loss: 2.9023912305272535
Validation loss: 2.7863633843568762

Epoch: 6| Step: 11
Training loss: 3.5142445206304656
Validation loss: 2.7897829346847196

Epoch: 6| Step: 12
Training loss: 3.1813994726653383
Validation loss: 2.7885874272991393

Epoch: 6| Step: 13
Training loss: 2.7574300960143154
Validation loss: 2.7880008136335954

Epoch: 151| Step: 0
Training loss: 3.396507539500148
Validation loss: 2.7898289988839173

Epoch: 6| Step: 1
Training loss: 3.093928476445181
Validation loss: 2.7864623679928364

Epoch: 6| Step: 2
Training loss: 3.4134976336553544
Validation loss: 2.796690407199668

Epoch: 6| Step: 3
Training loss: 3.1458693411747354
Validation loss: 2.794846435715684

Epoch: 6| Step: 4
Training loss: 3.502372618706655
Validation loss: 2.789120661204164

Epoch: 6| Step: 5
Training loss: 2.839286907020997
Validation loss: 2.7868826483950153

Epoch: 6| Step: 6
Training loss: 2.616875564433006
Validation loss: 2.7843162868060225

Epoch: 6| Step: 7
Training loss: 2.7763841046848734
Validation loss: 2.7833142023925506

Epoch: 6| Step: 8
Training loss: 3.276949434804663
Validation loss: 2.7810837798656998

Epoch: 6| Step: 9
Training loss: 3.0014911760298673
Validation loss: 2.7832713030020777

Epoch: 6| Step: 10
Training loss: 3.1302351778543347
Validation loss: 2.782898869819448

Epoch: 6| Step: 11
Training loss: 3.528824369786671
Validation loss: 2.7823265704815956

Epoch: 6| Step: 12
Training loss: 2.575447217752568
Validation loss: 2.7796847667767235

Epoch: 6| Step: 13
Training loss: 2.6716616361320416
Validation loss: 2.785469023231278

Epoch: 152| Step: 0
Training loss: 2.9062509844378375
Validation loss: 2.780908244438681

Epoch: 6| Step: 1
Training loss: 2.416346287592339
Validation loss: 2.7815078978953465

Epoch: 6| Step: 2
Training loss: 3.4309448162056095
Validation loss: 2.7829560313760813

Epoch: 6| Step: 3
Training loss: 3.4425696702388233
Validation loss: 2.7854302057610645

Epoch: 6| Step: 4
Training loss: 2.7727594110812253
Validation loss: 2.7914386601669667

Epoch: 6| Step: 5
Training loss: 2.614376368949763
Validation loss: 2.790706522365569

Epoch: 6| Step: 6
Training loss: 2.6695689461323706
Validation loss: 2.7916628458446593

Epoch: 6| Step: 7
Training loss: 3.33344856698808
Validation loss: 2.793569507408677

Epoch: 6| Step: 8
Training loss: 3.637220632830069
Validation loss: 2.8014978456703648

Epoch: 6| Step: 9
Training loss: 3.7053521134938237
Validation loss: 2.7913497425947784

Epoch: 6| Step: 10
Training loss: 2.9679484038071036
Validation loss: 2.780940946723399

Epoch: 6| Step: 11
Training loss: 3.060222323699896
Validation loss: 2.781763848527111

Epoch: 6| Step: 12
Training loss: 3.235020669815088
Validation loss: 2.7808103998635594

Epoch: 6| Step: 13
Training loss: 2.672174804999958
Validation loss: 2.7790912990316508

Epoch: 153| Step: 0
Training loss: 2.849950883676362
Validation loss: 2.7870420092841166

Epoch: 6| Step: 1
Training loss: 3.040857878154097
Validation loss: 2.7906066897605197

Epoch: 6| Step: 2
Training loss: 2.7165306942696112
Validation loss: 2.7939886379883108

Epoch: 6| Step: 3
Training loss: 3.1457344359626993
Validation loss: 2.802537682644467

Epoch: 6| Step: 4
Training loss: 2.5340214380382617
Validation loss: 2.7983639190618037

Epoch: 6| Step: 5
Training loss: 3.3200654779434746
Validation loss: 2.7886993952223027

Epoch: 6| Step: 6
Training loss: 3.299102609167813
Validation loss: 2.785502795720595

Epoch: 6| Step: 7
Training loss: 3.0737609910244887
Validation loss: 2.7762497560712336

Epoch: 6| Step: 8
Training loss: 2.6967930362485895
Validation loss: 2.7780296445984844

Epoch: 6| Step: 9
Training loss: 3.5107127139322616
Validation loss: 2.7763702835898463

Epoch: 6| Step: 10
Training loss: 2.686123073840095
Validation loss: 2.778940141029707

Epoch: 6| Step: 11
Training loss: 3.779594626513733
Validation loss: 2.784742699187087

Epoch: 6| Step: 12
Training loss: 3.538631185560235
Validation loss: 2.777624562320982

Epoch: 6| Step: 13
Training loss: 3.060297738593474
Validation loss: 2.7810813315279064

Epoch: 154| Step: 0
Training loss: 3.065784639174185
Validation loss: 2.779928946535398

Epoch: 6| Step: 1
Training loss: 3.1778826265740605
Validation loss: 2.7825375773074756

Epoch: 6| Step: 2
Training loss: 2.836757909052218
Validation loss: 2.777842413310942

Epoch: 6| Step: 3
Training loss: 2.9915903157840105
Validation loss: 2.7775080987466967

Epoch: 6| Step: 4
Training loss: 3.271497055712364
Validation loss: 2.7793593221197748

Epoch: 6| Step: 5
Training loss: 3.221436499754146
Validation loss: 2.77986208095466

Epoch: 6| Step: 6
Training loss: 3.0585527478194403
Validation loss: 2.7781144427959146

Epoch: 6| Step: 7
Training loss: 3.6493689840756844
Validation loss: 2.7752898932031025

Epoch: 6| Step: 8
Training loss: 2.7540294430280126
Validation loss: 2.7764010900959186

Epoch: 6| Step: 9
Training loss: 3.501650693464516
Validation loss: 2.7778622313619463

Epoch: 6| Step: 10
Training loss: 2.8070463074498733
Validation loss: 2.77814460431051

Epoch: 6| Step: 11
Training loss: 2.9387300229255566
Validation loss: 2.778566665060561

Epoch: 6| Step: 12
Training loss: 2.3568663744590324
Validation loss: 2.7773529094582337

Epoch: 6| Step: 13
Training loss: 3.7610476203141205
Validation loss: 2.777449277164689

Epoch: 155| Step: 0
Training loss: 2.975807554770191
Validation loss: 2.778323318754043

Epoch: 6| Step: 1
Training loss: 3.1677090953527856
Validation loss: 2.7851286938837587

Epoch: 6| Step: 2
Training loss: 2.6635014902565066
Validation loss: 2.7778521359311674

Epoch: 6| Step: 3
Training loss: 2.5824546755333544
Validation loss: 2.7799015608544098

Epoch: 6| Step: 4
Training loss: 3.0653963989511435
Validation loss: 2.78659166107745

Epoch: 6| Step: 5
Training loss: 3.503491431339979
Validation loss: 2.788539315426641

Epoch: 6| Step: 6
Training loss: 3.264798438494196
Validation loss: 2.7921356011800924

Epoch: 6| Step: 7
Training loss: 2.895207417491087
Validation loss: 2.7982442747340817

Epoch: 6| Step: 8
Training loss: 2.65047320333542
Validation loss: 2.7976305686867304

Epoch: 6| Step: 9
Training loss: 3.598632282479608
Validation loss: 2.803453401353403

Epoch: 6| Step: 10
Training loss: 3.2868749452203954
Validation loss: 2.8044769814121158

Epoch: 6| Step: 11
Training loss: 3.0189824364307007
Validation loss: 2.807592178440216

Epoch: 6| Step: 12
Training loss: 3.113659537772729
Validation loss: 2.789246950558984

Epoch: 6| Step: 13
Training loss: 3.50543975444013
Validation loss: 2.777897124409892

Epoch: 156| Step: 0
Training loss: 2.997012876455593
Validation loss: 2.7716941954971612

Epoch: 6| Step: 1
Training loss: 2.881063618289578
Validation loss: 2.77167784072486

Epoch: 6| Step: 2
Training loss: 3.308927084605055
Validation loss: 2.7763308624349405

Epoch: 6| Step: 3
Training loss: 3.163945551465246
Validation loss: 2.772031898773479

Epoch: 6| Step: 4
Training loss: 3.6695011338282746
Validation loss: 2.7742327397962905

Epoch: 6| Step: 5
Training loss: 2.685517933082684
Validation loss: 2.7722926433105686

Epoch: 6| Step: 6
Training loss: 2.779943952475706
Validation loss: 2.7752953303194325

Epoch: 6| Step: 7
Training loss: 3.2411987267678244
Validation loss: 2.7736504724431126

Epoch: 6| Step: 8
Training loss: 2.7118989410363437
Validation loss: 2.771007002862834

Epoch: 6| Step: 9
Training loss: 3.324916815613514
Validation loss: 2.7727513034186884

Epoch: 6| Step: 10
Training loss: 3.3699014086691603
Validation loss: 2.773595260715676

Epoch: 6| Step: 11
Training loss: 2.898410848407622
Validation loss: 2.7722218815583726

Epoch: 6| Step: 12
Training loss: 3.3438402680663866
Validation loss: 2.771738436698241

Epoch: 6| Step: 13
Training loss: 2.3670038838195526
Validation loss: 2.7726243131012596

Epoch: 157| Step: 0
Training loss: 2.3983690084314064
Validation loss: 2.769301140206355

Epoch: 6| Step: 1
Training loss: 2.3570535114414226
Validation loss: 2.7716592206593424

Epoch: 6| Step: 2
Training loss: 3.0914584834361873
Validation loss: 2.7744620432446054

Epoch: 6| Step: 3
Training loss: 3.2953490572222464
Validation loss: 2.7817743859462105

Epoch: 6| Step: 4
Training loss: 3.2548876469642316
Validation loss: 2.7747031485708544

Epoch: 6| Step: 5
Training loss: 3.1638840613264616
Validation loss: 2.78276431337845

Epoch: 6| Step: 6
Training loss: 3.049916788435684
Validation loss: 2.7771892383188357

Epoch: 6| Step: 7
Training loss: 3.371570398751204
Validation loss: 2.778529766252861

Epoch: 6| Step: 8
Training loss: 3.3898706959508225
Validation loss: 2.777509362333735

Epoch: 6| Step: 9
Training loss: 3.7006613990811714
Validation loss: 2.780474768701948

Epoch: 6| Step: 10
Training loss: 2.7753502495853626
Validation loss: 2.773343025619303

Epoch: 6| Step: 11
Training loss: 2.6705391204545523
Validation loss: 2.7776043909233454

Epoch: 6| Step: 12
Training loss: 3.1694592827611094
Validation loss: 2.7792265886045486

Epoch: 6| Step: 13
Training loss: 3.3421925277636477
Validation loss: 2.7792742648875532

Epoch: 158| Step: 0
Training loss: 2.9871953449770796
Validation loss: 2.770007527084492

Epoch: 6| Step: 1
Training loss: 2.8873143388253597
Validation loss: 2.76765149349026

Epoch: 6| Step: 2
Training loss: 3.327654164996911
Validation loss: 2.7701079530678987

Epoch: 6| Step: 3
Training loss: 3.000774283625733
Validation loss: 2.7703003017146637

Epoch: 6| Step: 4
Training loss: 3.3516250995756476
Validation loss: 2.7696617240712627

Epoch: 6| Step: 5
Training loss: 2.6205495619065653
Validation loss: 2.767145570220188

Epoch: 6| Step: 6
Training loss: 3.2513210839431954
Validation loss: 2.7706493551304896

Epoch: 6| Step: 7
Training loss: 3.236177835790747
Validation loss: 2.7746266116525238

Epoch: 6| Step: 8
Training loss: 2.8510546088258857
Validation loss: 2.7642994415306728

Epoch: 6| Step: 9
Training loss: 3.0194941391336076
Validation loss: 2.7677267218232675

Epoch: 6| Step: 10
Training loss: 3.1388778761348877
Validation loss: 2.7685088804857227

Epoch: 6| Step: 11
Training loss: 3.117534417373104
Validation loss: 2.769801910479805

Epoch: 6| Step: 12
Training loss: 3.3263325767201493
Validation loss: 2.765318743104683

Epoch: 6| Step: 13
Training loss: 2.950149894397582
Validation loss: 2.76966788866078

Epoch: 159| Step: 0
Training loss: 3.481819207657401
Validation loss: 2.7639928021719604

Epoch: 6| Step: 1
Training loss: 2.9727329239249367
Validation loss: 2.769982368191298

Epoch: 6| Step: 2
Training loss: 3.4369176197895297
Validation loss: 2.7682408801884706

Epoch: 6| Step: 3
Training loss: 2.8462660840718828
Validation loss: 2.7661467872735517

Epoch: 6| Step: 4
Training loss: 3.917684192916117
Validation loss: 2.76973578154305

Epoch: 6| Step: 5
Training loss: 2.765537583860791
Validation loss: 2.7692858442348953

Epoch: 6| Step: 6
Training loss: 3.690051731480991
Validation loss: 2.7703414216344586

Epoch: 6| Step: 7
Training loss: 2.930188596468914
Validation loss: 2.7766679039240487

Epoch: 6| Step: 8
Training loss: 2.6777539631623077
Validation loss: 2.7743119627459993

Epoch: 6| Step: 9
Training loss: 2.6948393033160665
Validation loss: 2.7830647706014426

Epoch: 6| Step: 10
Training loss: 3.0171111402919077
Validation loss: 2.773856908204204

Epoch: 6| Step: 11
Training loss: 3.368016399841974
Validation loss: 2.7793262866880837

Epoch: 6| Step: 12
Training loss: 2.133617319139604
Validation loss: 2.7693962282825857

Epoch: 6| Step: 13
Training loss: 2.6104020707152906
Validation loss: 2.769131679121013

Epoch: 160| Step: 0
Training loss: 3.36313436544093
Validation loss: 2.7682492529569314

Epoch: 6| Step: 1
Training loss: 2.9302629643155003
Validation loss: 2.7651668183184936

Epoch: 6| Step: 2
Training loss: 3.54693442139446
Validation loss: 2.7659154199176568

Epoch: 6| Step: 3
Training loss: 2.8916190422892813
Validation loss: 2.7651456789813733

Epoch: 6| Step: 4
Training loss: 3.0888451121069367
Validation loss: 2.7644632526325856

Epoch: 6| Step: 5
Training loss: 3.5066318351649888
Validation loss: 2.761722849269212

Epoch: 6| Step: 6
Training loss: 2.6777251150915746
Validation loss: 2.76953626706549

Epoch: 6| Step: 7
Training loss: 2.5440485898541843
Validation loss: 2.76455924896873

Epoch: 6| Step: 8
Training loss: 3.529609501666286
Validation loss: 2.7642364130595505

Epoch: 6| Step: 9
Training loss: 3.549154347451129
Validation loss: 2.7631535644295826

Epoch: 6| Step: 10
Training loss: 3.0031524625191386
Validation loss: 2.7632672123664044

Epoch: 6| Step: 11
Training loss: 2.90291017983799
Validation loss: 2.7622486804771245

Epoch: 6| Step: 12
Training loss: 2.931973717336223
Validation loss: 2.763883646517941

Epoch: 6| Step: 13
Training loss: 1.8452141977043062
Validation loss: 2.7659805613417743

Epoch: 161| Step: 0
Training loss: 3.7541013541910484
Validation loss: 2.762677039265843

Epoch: 6| Step: 1
Training loss: 3.8090544593144684
Validation loss: 2.7631837055481054

Epoch: 6| Step: 2
Training loss: 2.939430089714558
Validation loss: 2.7622038965460978

Epoch: 6| Step: 3
Training loss: 3.017683522380629
Validation loss: 2.7638946194141965

Epoch: 6| Step: 4
Training loss: 2.4195263703358325
Validation loss: 2.761296188155438

Epoch: 6| Step: 5
Training loss: 2.483603495638417
Validation loss: 2.7634960694202877

Epoch: 6| Step: 6
Training loss: 2.5866539645456648
Validation loss: 2.7700974814006893

Epoch: 6| Step: 7
Training loss: 2.197907566817069
Validation loss: 2.769542387502819

Epoch: 6| Step: 8
Training loss: 3.65023099612521
Validation loss: 2.772129926496567

Epoch: 6| Step: 9
Training loss: 2.852693349184665
Validation loss: 2.7852075194643677

Epoch: 6| Step: 10
Training loss: 3.3996641554172533
Validation loss: 2.784438185029409

Epoch: 6| Step: 11
Training loss: 3.3313236536182207
Validation loss: 2.7857702507230964

Epoch: 6| Step: 12
Training loss: 3.3127824195091335
Validation loss: 2.76314394132093

Epoch: 6| Step: 13
Training loss: 2.714431050719039
Validation loss: 2.7614983728338918

Epoch: 162| Step: 0
Training loss: 3.147650457032706
Validation loss: 2.7617645638144848

Epoch: 6| Step: 1
Training loss: 2.746084026031859
Validation loss: 2.7640624148935062

Epoch: 6| Step: 2
Training loss: 2.6829704438130264
Validation loss: 2.7650144382884525

Epoch: 6| Step: 3
Training loss: 3.0701444545893763
Validation loss: 2.761966762472445

Epoch: 6| Step: 4
Training loss: 3.1218027161868354
Validation loss: 2.764047551824055

Epoch: 6| Step: 5
Training loss: 2.8250595255294044
Validation loss: 2.7612132419306192

Epoch: 6| Step: 6
Training loss: 2.883845115915189
Validation loss: 2.761586966763453

Epoch: 6| Step: 7
Training loss: 2.9806023364046337
Validation loss: 2.7610294794077097

Epoch: 6| Step: 8
Training loss: 3.0443718433618283
Validation loss: 2.7609465502407415

Epoch: 6| Step: 9
Training loss: 3.742414431769118
Validation loss: 2.764667401515138

Epoch: 6| Step: 10
Training loss: 2.8089668970435597
Validation loss: 2.766761833955442

Epoch: 6| Step: 11
Training loss: 2.405656617557186
Validation loss: 2.764282456880554

Epoch: 6| Step: 12
Training loss: 3.9473847338690735
Validation loss: 2.7591046779211075

Epoch: 6| Step: 13
Training loss: 3.5786961262092536
Validation loss: 2.761075559066308

Epoch: 163| Step: 0
Training loss: 3.06804606333225
Validation loss: 2.7600129017759443

Epoch: 6| Step: 1
Training loss: 3.205109962802716
Validation loss: 2.761317454445712

Epoch: 6| Step: 2
Training loss: 2.9402203239874503
Validation loss: 2.7614893965904748

Epoch: 6| Step: 3
Training loss: 3.2283773790728034
Validation loss: 2.7669760429012613

Epoch: 6| Step: 4
Training loss: 3.1099265678052777
Validation loss: 2.7640847023917092

Epoch: 6| Step: 5
Training loss: 3.044572008744524
Validation loss: 2.765271462193403

Epoch: 6| Step: 6
Training loss: 3.4725119321548084
Validation loss: 2.759380881016707

Epoch: 6| Step: 7
Training loss: 3.5728606431904364
Validation loss: 2.76193679557058

Epoch: 6| Step: 8
Training loss: 2.675951252012901
Validation loss: 2.7619001071376865

Epoch: 6| Step: 9
Training loss: 2.6156881564045773
Validation loss: 2.7596782406354983

Epoch: 6| Step: 10
Training loss: 3.154376238601045
Validation loss: 2.7618897445117274

Epoch: 6| Step: 11
Training loss: 3.167439784657115
Validation loss: 2.7651739960699073

Epoch: 6| Step: 12
Training loss: 3.264475935139286
Validation loss: 2.7652414448847407

Epoch: 6| Step: 13
Training loss: 1.5314737273281374
Validation loss: 2.7596332542774973

Epoch: 164| Step: 0
Training loss: 2.7011768178280877
Validation loss: 2.7672447271073883

Epoch: 6| Step: 1
Training loss: 3.691356904845452
Validation loss: 2.769506581086366

Epoch: 6| Step: 2
Training loss: 3.910525858023073
Validation loss: 2.772767352295958

Epoch: 6| Step: 3
Training loss: 3.238600472429338
Validation loss: 2.7751274592897306

Epoch: 6| Step: 4
Training loss: 2.8172522344361184
Validation loss: 2.782779090298801

Epoch: 6| Step: 5
Training loss: 2.6162544067462346
Validation loss: 2.789020927176583

Epoch: 6| Step: 6
Training loss: 2.7126408483264566
Validation loss: 2.793695656217899

Epoch: 6| Step: 7
Training loss: 3.1588313056556743
Validation loss: 2.7888850620442183

Epoch: 6| Step: 8
Training loss: 3.2320722408152687
Validation loss: 2.793133743361258

Epoch: 6| Step: 9
Training loss: 2.711421868314415
Validation loss: 2.7797237742286414

Epoch: 6| Step: 10
Training loss: 2.7567634640557994
Validation loss: 2.7680655842930566

Epoch: 6| Step: 11
Training loss: 2.2071348452940702
Validation loss: 2.7681341638364456

Epoch: 6| Step: 12
Training loss: 3.30370877249227
Validation loss: 2.7618445649018253

Epoch: 6| Step: 13
Training loss: 3.8483294987208536
Validation loss: 2.7579215529377477

Epoch: 165| Step: 0
Training loss: 2.898357709007429
Validation loss: 2.7552907283836543

Epoch: 6| Step: 1
Training loss: 3.040243904719341
Validation loss: 2.7587162630750663

Epoch: 6| Step: 2
Training loss: 2.030368672422171
Validation loss: 2.7554478124378394

Epoch: 6| Step: 3
Training loss: 2.6033027029575946
Validation loss: 2.7591368442098805

Epoch: 6| Step: 4
Training loss: 2.956236476746289
Validation loss: 2.755549684520046

Epoch: 6| Step: 5
Training loss: 3.491013297508875
Validation loss: 2.756763919729209

Epoch: 6| Step: 6
Training loss: 2.73127378894214
Validation loss: 2.7565398671866985

Epoch: 6| Step: 7
Training loss: 3.409176890127039
Validation loss: 2.757535351437463

Epoch: 6| Step: 8
Training loss: 3.7149284666010582
Validation loss: 2.7567857491871415

Epoch: 6| Step: 9
Training loss: 3.5981547023812173
Validation loss: 2.752746644159333

Epoch: 6| Step: 10
Training loss: 3.0365387702525832
Validation loss: 2.753869855807963

Epoch: 6| Step: 11
Training loss: 3.0864541695642127
Validation loss: 2.756735624127479

Epoch: 6| Step: 12
Training loss: 2.7731941223815144
Validation loss: 2.755104205490846

Epoch: 6| Step: 13
Training loss: 3.4141578922868163
Validation loss: 2.7573697220615196

Epoch: 166| Step: 0
Training loss: 3.2315171741877395
Validation loss: 2.7609773301374827

Epoch: 6| Step: 1
Training loss: 2.499887750012947
Validation loss: 2.7568762753338203

Epoch: 6| Step: 2
Training loss: 3.5245693782450913
Validation loss: 2.7680495294569476

Epoch: 6| Step: 3
Training loss: 3.2227388128628447
Validation loss: 2.7757124933161794

Epoch: 6| Step: 4
Training loss: 3.3918041516930755
Validation loss: 2.7771442097559205

Epoch: 6| Step: 5
Training loss: 3.3793597848619186
Validation loss: 2.7702080404040923

Epoch: 6| Step: 6
Training loss: 2.7721274277103256
Validation loss: 2.7573566610241644

Epoch: 6| Step: 7
Training loss: 3.696403616537309
Validation loss: 2.760202741237333

Epoch: 6| Step: 8
Training loss: 2.4027024908404635
Validation loss: 2.7524807201537826

Epoch: 6| Step: 9
Training loss: 2.944305490617867
Validation loss: 2.7527446958732025

Epoch: 6| Step: 10
Training loss: 2.5870840982305037
Validation loss: 2.7503782778463215

Epoch: 6| Step: 11
Training loss: 2.948713610506641
Validation loss: 2.7510456919876054

Epoch: 6| Step: 12
Training loss: 3.240773087799268
Validation loss: 2.7510052099510585

Epoch: 6| Step: 13
Training loss: 2.803222698775801
Validation loss: 2.7489682366101147

Epoch: 167| Step: 0
Training loss: 3.4636042462577654
Validation loss: 2.7491094521389337

Epoch: 6| Step: 1
Training loss: 3.08099432884618
Validation loss: 2.7506237087164753

Epoch: 6| Step: 2
Training loss: 3.433685683407339
Validation loss: 2.751666322094462

Epoch: 6| Step: 3
Training loss: 1.8165621126634863
Validation loss: 2.7509229654965943

Epoch: 6| Step: 4
Training loss: 3.0746925696544336
Validation loss: 2.749588538456461

Epoch: 6| Step: 5
Training loss: 2.8751631980684755
Validation loss: 2.749804561602317

Epoch: 6| Step: 6
Training loss: 2.9199457173984777
Validation loss: 2.7505037940710815

Epoch: 6| Step: 7
Training loss: 3.560277144970462
Validation loss: 2.751123713349739

Epoch: 6| Step: 8
Training loss: 3.1062159760912493
Validation loss: 2.7521939936525825

Epoch: 6| Step: 9
Training loss: 2.85528037810609
Validation loss: 2.7520139354414748

Epoch: 6| Step: 10
Training loss: 2.9555728193207518
Validation loss: 2.756155766763071

Epoch: 6| Step: 11
Training loss: 3.0196784256257243
Validation loss: 2.7628346776605297

Epoch: 6| Step: 12
Training loss: 3.1573304696982945
Validation loss: 2.770792505995272

Epoch: 6| Step: 13
Training loss: 3.395201938337012
Validation loss: 2.767875106902179

Epoch: 168| Step: 0
Training loss: 2.917910900844739
Validation loss: 2.7661667141404185

Epoch: 6| Step: 1
Training loss: 2.7839202920585566
Validation loss: 2.7628885613492002

Epoch: 6| Step: 2
Training loss: 2.8236608521403834
Validation loss: 2.7731006760373234

Epoch: 6| Step: 3
Training loss: 2.365964768876988
Validation loss: 2.7663909832084213

Epoch: 6| Step: 4
Training loss: 2.4429894280847066
Validation loss: 2.780699636405972

Epoch: 6| Step: 5
Training loss: 3.3200344552699583
Validation loss: 2.772416746665522

Epoch: 6| Step: 6
Training loss: 3.2695481677056337
Validation loss: 2.7697185432952387

Epoch: 6| Step: 7
Training loss: 2.796144528606044
Validation loss: 2.7605059326994197

Epoch: 6| Step: 8
Training loss: 3.2646224385743094
Validation loss: 2.7532908511676517

Epoch: 6| Step: 9
Training loss: 3.6327216680512833
Validation loss: 2.7524221172283867

Epoch: 6| Step: 10
Training loss: 3.1547908620542158
Validation loss: 2.7531116645760716

Epoch: 6| Step: 11
Training loss: 3.6816674350399827
Validation loss: 2.7618139998124533

Epoch: 6| Step: 12
Training loss: 3.2458288862779847
Validation loss: 2.749688245492121

Epoch: 6| Step: 13
Training loss: 2.8666710661329473
Validation loss: 2.7496534373405255

Epoch: 169| Step: 0
Training loss: 2.0775875457789925
Validation loss: 2.747505180602351

Epoch: 6| Step: 1
Training loss: 3.095695423393417
Validation loss: 2.7522259724431546

Epoch: 6| Step: 2
Training loss: 3.1188010721860175
Validation loss: 2.7466153853821536

Epoch: 6| Step: 3
Training loss: 2.255835912012722
Validation loss: 2.7467608304070477

Epoch: 6| Step: 4
Training loss: 2.47298348477684
Validation loss: 2.748337715910724

Epoch: 6| Step: 5
Training loss: 3.3731752336969634
Validation loss: 2.7466877224474824

Epoch: 6| Step: 6
Training loss: 3.6123388762659605
Validation loss: 2.747275118364528

Epoch: 6| Step: 7
Training loss: 2.7156006560644688
Validation loss: 2.749804744332957

Epoch: 6| Step: 8
Training loss: 3.6489910873843674
Validation loss: 2.7482928218995086

Epoch: 6| Step: 9
Training loss: 3.55319162271086
Validation loss: 2.747819388339078

Epoch: 6| Step: 10
Training loss: 3.04865232616961
Validation loss: 2.7458551051366733

Epoch: 6| Step: 11
Training loss: 3.150311312354081
Validation loss: 2.7464699503901073

Epoch: 6| Step: 12
Training loss: 3.201373258613684
Validation loss: 2.7527859895585065

Epoch: 6| Step: 13
Training loss: 3.094189545204106
Validation loss: 2.747993151820199

Epoch: 170| Step: 0
Training loss: 2.1883070410693404
Validation loss: 2.7541381347329104

Epoch: 6| Step: 1
Training loss: 3.009252109573435
Validation loss: 2.7539283627626143

Epoch: 6| Step: 2
Training loss: 3.7823504903609333
Validation loss: 2.7673366786738254

Epoch: 6| Step: 3
Training loss: 3.0091096533296553
Validation loss: 2.754623749931031

Epoch: 6| Step: 4
Training loss: 2.949388511773888
Validation loss: 2.748806807374247

Epoch: 6| Step: 5
Training loss: 3.4778764963273288
Validation loss: 2.746634494439953

Epoch: 6| Step: 6
Training loss: 2.823075312324341
Validation loss: 2.7508108131397515

Epoch: 6| Step: 7
Training loss: 2.466971807249956
Validation loss: 2.7486144161534223

Epoch: 6| Step: 8
Training loss: 3.2050031412618063
Validation loss: 2.7453967877410177

Epoch: 6| Step: 9
Training loss: 3.462552970178083
Validation loss: 2.7460773622557744

Epoch: 6| Step: 10
Training loss: 2.5306279866358046
Validation loss: 2.7473565398237145

Epoch: 6| Step: 11
Training loss: 3.2242920209334147
Validation loss: 2.7449653755608985

Epoch: 6| Step: 12
Training loss: 3.163448773425902
Validation loss: 2.7484548922800096

Epoch: 6| Step: 13
Training loss: 3.333136854739006
Validation loss: 2.7499591007715147

Epoch: 171| Step: 0
Training loss: 2.82936161888334
Validation loss: 2.746588562660245

Epoch: 6| Step: 1
Training loss: 2.9755375416559944
Validation loss: 2.7425586753188607

Epoch: 6| Step: 2
Training loss: 2.917803370271609
Validation loss: 2.743727450371912

Epoch: 6| Step: 3
Training loss: 3.2705430956965094
Validation loss: 2.7448001103422013

Epoch: 6| Step: 4
Training loss: 2.9321877352159396
Validation loss: 2.7430881035343435

Epoch: 6| Step: 5
Training loss: 2.903356937468705
Validation loss: 2.741754300907197

Epoch: 6| Step: 6
Training loss: 2.484134110582178
Validation loss: 2.7472391999608314

Epoch: 6| Step: 7
Training loss: 3.3392786094409264
Validation loss: 2.743587280952864

Epoch: 6| Step: 8
Training loss: 3.117966786352661
Validation loss: 2.749651474742116

Epoch: 6| Step: 9
Training loss: 3.6080462499390467
Validation loss: 2.747729509871411

Epoch: 6| Step: 10
Training loss: 3.262414841983816
Validation loss: 2.745923488759624

Epoch: 6| Step: 11
Training loss: 2.979822491216985
Validation loss: 2.7529518490810068

Epoch: 6| Step: 12
Training loss: 2.8395236961798704
Validation loss: 2.7460123069690607

Epoch: 6| Step: 13
Training loss: 3.39156627334614
Validation loss: 2.7523355475858726

Epoch: 172| Step: 0
Training loss: 3.1285069433485484
Validation loss: 2.7517067282574983

Epoch: 6| Step: 1
Training loss: 2.901165852836418
Validation loss: 2.754876108588848

Epoch: 6| Step: 2
Training loss: 3.2288018461488677
Validation loss: 2.7484097399393406

Epoch: 6| Step: 3
Training loss: 2.4727653973491193
Validation loss: 2.746617464022492

Epoch: 6| Step: 4
Training loss: 2.5113441579511346
Validation loss: 2.7445646951316376

Epoch: 6| Step: 5
Training loss: 3.255934944946329
Validation loss: 2.739777058018875

Epoch: 6| Step: 6
Training loss: 2.758970368765772
Validation loss: 2.7402199720891884

Epoch: 6| Step: 7
Training loss: 3.2888850438321753
Validation loss: 2.7437094806212534

Epoch: 6| Step: 8
Training loss: 3.492593285114173
Validation loss: 2.742450785728759

Epoch: 6| Step: 9
Training loss: 3.2187605181772168
Validation loss: 2.744325836030703

Epoch: 6| Step: 10
Training loss: 3.4676210783025283
Validation loss: 2.7434006865650757

Epoch: 6| Step: 11
Training loss: 3.1933859541133938
Validation loss: 2.7496193737056283

Epoch: 6| Step: 12
Training loss: 3.1045055503113637
Validation loss: 2.7490270101508396

Epoch: 6| Step: 13
Training loss: 2.0259319233203437
Validation loss: 2.743543634225299

Epoch: 173| Step: 0
Training loss: 2.965562253394753
Validation loss: 2.7430720408272977

Epoch: 6| Step: 1
Training loss: 2.8342964741891548
Validation loss: 2.7426540166186735

Epoch: 6| Step: 2
Training loss: 3.6969929719032137
Validation loss: 2.7464712133221783

Epoch: 6| Step: 3
Training loss: 3.20568968280903
Validation loss: 2.7450536989779537

Epoch: 6| Step: 4
Training loss: 3.3575594942072304
Validation loss: 2.7420216326055558

Epoch: 6| Step: 5
Training loss: 3.525241838099883
Validation loss: 2.7383339176288826

Epoch: 6| Step: 6
Training loss: 2.913045669978145
Validation loss: 2.739420564338196

Epoch: 6| Step: 7
Training loss: 2.837170209498975
Validation loss: 2.736955849467889

Epoch: 6| Step: 8
Training loss: 2.899460275345338
Validation loss: 2.735213232048617

Epoch: 6| Step: 9
Training loss: 2.759286286773797
Validation loss: 2.7385578448533168

Epoch: 6| Step: 10
Training loss: 2.806398002952639
Validation loss: 2.7402410193052775

Epoch: 6| Step: 11
Training loss: 2.8941468924445397
Validation loss: 2.739384034782613

Epoch: 6| Step: 12
Training loss: 3.225795700916711
Validation loss: 2.7354480462665487

Epoch: 6| Step: 13
Training loss: 2.380646869041203
Validation loss: 2.736840269649141

Epoch: 174| Step: 0
Training loss: 3.155794922909121
Validation loss: 2.738919789798083

Epoch: 6| Step: 1
Training loss: 2.7333722701051864
Validation loss: 2.7418244455210443

Epoch: 6| Step: 2
Training loss: 2.8604695877621573
Validation loss: 2.739899023414125

Epoch: 6| Step: 3
Training loss: 3.4663011309281018
Validation loss: 2.7404823776010714

Epoch: 6| Step: 4
Training loss: 3.4563039930654926
Validation loss: 2.749845459400165

Epoch: 6| Step: 5
Training loss: 3.285085997130809
Validation loss: 2.7443084428423186

Epoch: 6| Step: 6
Training loss: 3.2839923842663574
Validation loss: 2.7459637376237693

Epoch: 6| Step: 7
Training loss: 2.802251751646906
Validation loss: 2.742446365994865

Epoch: 6| Step: 8
Training loss: 3.2389654488200246
Validation loss: 2.7401000774317708

Epoch: 6| Step: 9
Training loss: 2.9571205841236594
Validation loss: 2.7353567622209143

Epoch: 6| Step: 10
Training loss: 2.240971464772926
Validation loss: 2.7338872593498245

Epoch: 6| Step: 11
Training loss: 3.2054693807312624
Validation loss: 2.734667382143991

Epoch: 6| Step: 12
Training loss: 3.2567289091765392
Validation loss: 2.7350359767941117

Epoch: 6| Step: 13
Training loss: 2.2020022730733313
Validation loss: 2.734727526088618

Epoch: 175| Step: 0
Training loss: 3.0194020706318234
Validation loss: 2.7350183417462284

Epoch: 6| Step: 1
Training loss: 3.580364875526898
Validation loss: 2.7375428378516746

Epoch: 6| Step: 2
Training loss: 3.0651020751185425
Validation loss: 2.737499816785143

Epoch: 6| Step: 3
Training loss: 3.4629853607317744
Validation loss: 2.736007096464168

Epoch: 6| Step: 4
Training loss: 2.741173102834954
Validation loss: 2.7333887199529805

Epoch: 6| Step: 5
Training loss: 2.8040534447706897
Validation loss: 2.7329451734311476

Epoch: 6| Step: 6
Training loss: 3.233734214812018
Validation loss: 2.7338979325407746

Epoch: 6| Step: 7
Training loss: 2.987111220341149
Validation loss: 2.7378181439346094

Epoch: 6| Step: 8
Training loss: 3.328305378355381
Validation loss: 2.7317348671686785

Epoch: 6| Step: 9
Training loss: 1.901619023131056
Validation loss: 2.735394824476836

Epoch: 6| Step: 10
Training loss: 2.604237324073998
Validation loss: 2.736789049567629

Epoch: 6| Step: 11
Training loss: 3.0499666618651373
Validation loss: 2.7391992514416685

Epoch: 6| Step: 12
Training loss: 3.5951487597166527
Validation loss: 2.7403507527942312

Epoch: 6| Step: 13
Training loss: 2.976641956780692
Validation loss: 2.738188410726363

Epoch: 176| Step: 0
Training loss: 2.707039352779179
Validation loss: 2.7379723109647576

Epoch: 6| Step: 1
Training loss: 3.0126766358821415
Validation loss: 2.7485079068802984

Epoch: 6| Step: 2
Training loss: 3.59087940506687
Validation loss: 2.7396129237080085

Epoch: 6| Step: 3
Training loss: 2.982240402806151
Validation loss: 2.7448276220796965

Epoch: 6| Step: 4
Training loss: 2.361617885382828
Validation loss: 2.7471320307851435

Epoch: 6| Step: 5
Training loss: 2.443703899290175
Validation loss: 2.747167571713257

Epoch: 6| Step: 6
Training loss: 3.0432670946492686
Validation loss: 2.754863409825142

Epoch: 6| Step: 7
Training loss: 3.1165703566523035
Validation loss: 2.756449754095429

Epoch: 6| Step: 8
Training loss: 3.1648459135757694
Validation loss: 2.746970190332427

Epoch: 6| Step: 9
Training loss: 3.396698605502993
Validation loss: 2.753140964908499

Epoch: 6| Step: 10
Training loss: 2.7669656381351846
Validation loss: 2.7498889445741823

Epoch: 6| Step: 11
Training loss: 3.0021294347826637
Validation loss: 2.7517732271065047

Epoch: 6| Step: 12
Training loss: 3.6558665539116393
Validation loss: 2.7580062499287648

Epoch: 6| Step: 13
Training loss: 3.3413682101967273
Validation loss: 2.742957124354152

Epoch: 177| Step: 0
Training loss: 3.3854485299982895
Validation loss: 2.7343944317995934

Epoch: 6| Step: 1
Training loss: 2.8488992874377606
Validation loss: 2.7315108461189914

Epoch: 6| Step: 2
Training loss: 3.586417637680084
Validation loss: 2.7311539446073403

Epoch: 6| Step: 3
Training loss: 2.993037728012895
Validation loss: 2.7323721126952063

Epoch: 6| Step: 4
Training loss: 2.94534050804198
Validation loss: 2.7304603637207867

Epoch: 6| Step: 5
Training loss: 3.375148628635613
Validation loss: 2.730772069626184

Epoch: 6| Step: 6
Training loss: 2.4943327564628137
Validation loss: 2.7324442892267866

Epoch: 6| Step: 7
Training loss: 3.0654211320663505
Validation loss: 2.7330629618963784

Epoch: 6| Step: 8
Training loss: 3.3515354680036036
Validation loss: 2.729932560304651

Epoch: 6| Step: 9
Training loss: 2.9688595400226987
Validation loss: 2.7312560554509164

Epoch: 6| Step: 10
Training loss: 2.594713330908115
Validation loss: 2.729574423993063

Epoch: 6| Step: 11
Training loss: 2.6079245550675574
Validation loss: 2.730378516339318

Epoch: 6| Step: 12
Training loss: 3.0198334891791907
Validation loss: 2.733248002979873

Epoch: 6| Step: 13
Training loss: 3.4898720389356015
Validation loss: 2.728728660248383

Epoch: 178| Step: 0
Training loss: 3.612730901922
Validation loss: 2.7308309259312407

Epoch: 6| Step: 1
Training loss: 3.222517456765017
Validation loss: 2.730462249978623

Epoch: 6| Step: 2
Training loss: 3.1044041758226704
Validation loss: 2.7288569750839287

Epoch: 6| Step: 3
Training loss: 3.405483334556691
Validation loss: 2.729427662080001

Epoch: 6| Step: 4
Training loss: 2.8224360114278473
Validation loss: 2.737397738431051

Epoch: 6| Step: 5
Training loss: 2.6657455363418254
Validation loss: 2.729968033097501

Epoch: 6| Step: 6
Training loss: 3.326927005261739
Validation loss: 2.7318672834065305

Epoch: 6| Step: 7
Training loss: 2.339025797074997
Validation loss: 2.728802495495653

Epoch: 6| Step: 8
Training loss: 2.6704072545953563
Validation loss: 2.727699184589428

Epoch: 6| Step: 9
Training loss: 2.410697295113892
Validation loss: 2.7328277251065267

Epoch: 6| Step: 10
Training loss: 3.1019103962532957
Validation loss: 2.729948776388395

Epoch: 6| Step: 11
Training loss: 3.2769392489126883
Validation loss: 2.7309202490800444

Epoch: 6| Step: 12
Training loss: 2.963761485192977
Validation loss: 2.7311783347889937

Epoch: 6| Step: 13
Training loss: 3.7163103580032106
Validation loss: 2.7312593331471655

Epoch: 179| Step: 0
Training loss: 2.9528033368964346
Validation loss: 2.7346535892637167

Epoch: 6| Step: 1
Training loss: 3.0396658879434675
Validation loss: 2.7355290091045426

Epoch: 6| Step: 2
Training loss: 3.1025656511982334
Validation loss: 2.7378480573956314

Epoch: 6| Step: 3
Training loss: 3.171853351988934
Validation loss: 2.7463739621195398

Epoch: 6| Step: 4
Training loss: 2.7122880281519235
Validation loss: 2.7433252724239385

Epoch: 6| Step: 5
Training loss: 3.097684419944027
Validation loss: 2.74399642007822

Epoch: 6| Step: 6
Training loss: 3.561950239627516
Validation loss: 2.745934988095174

Epoch: 6| Step: 7
Training loss: 3.1763733784546595
Validation loss: 2.739051662137903

Epoch: 6| Step: 8
Training loss: 2.280951075369119
Validation loss: 2.740883300319002

Epoch: 6| Step: 9
Training loss: 3.4738590315886593
Validation loss: 2.7337855984463566

Epoch: 6| Step: 10
Training loss: 3.201204943297017
Validation loss: 2.739324898993479

Epoch: 6| Step: 11
Training loss: 3.2406029931317164
Validation loss: 2.7276068206941937

Epoch: 6| Step: 12
Training loss: 2.268192914343859
Validation loss: 2.733142451467511

Epoch: 6| Step: 13
Training loss: 3.2292329022577366
Validation loss: 2.729125748620128

Epoch: 180| Step: 0
Training loss: 3.6574002274354687
Validation loss: 2.727504085413153

Epoch: 6| Step: 1
Training loss: 3.1454785549031277
Validation loss: 2.7224097348105047

Epoch: 6| Step: 2
Training loss: 2.691138532414668
Validation loss: 2.7265021040125257

Epoch: 6| Step: 3
Training loss: 3.29082871084564
Validation loss: 2.7242453537307614

Epoch: 6| Step: 4
Training loss: 2.8536347684850525
Validation loss: 2.726044124838978

Epoch: 6| Step: 5
Training loss: 3.163314617920298
Validation loss: 2.728601333416306

Epoch: 6| Step: 6
Training loss: 3.2222877985394494
Validation loss: 2.727852736532112

Epoch: 6| Step: 7
Training loss: 3.027786635950723
Validation loss: 2.7253006201346355

Epoch: 6| Step: 8
Training loss: 3.119622142603503
Validation loss: 2.7249529774765033

Epoch: 6| Step: 9
Training loss: 2.7267531188963794
Validation loss: 2.7277232240845444

Epoch: 6| Step: 10
Training loss: 2.693754060746604
Validation loss: 2.7233041694533413

Epoch: 6| Step: 11
Training loss: 2.962345322059686
Validation loss: 2.7254268219021016

Epoch: 6| Step: 12
Training loss: 2.8859075870006663
Validation loss: 2.7230851920155987

Epoch: 6| Step: 13
Training loss: 3.116075513402172
Validation loss: 2.724012528961127

Epoch: 181| Step: 0
Training loss: 2.331730144237462
Validation loss: 2.7243203813670847

Epoch: 6| Step: 1
Training loss: 2.6368601669252376
Validation loss: 2.72343107089119

Epoch: 6| Step: 2
Training loss: 3.552604450620468
Validation loss: 2.7243928587233652

Epoch: 6| Step: 3
Training loss: 2.997866984881986
Validation loss: 2.7264533013548133

Epoch: 6| Step: 4
Training loss: 3.006354595434679
Validation loss: 2.723998062865827

Epoch: 6| Step: 5
Training loss: 2.72980898415921
Validation loss: 2.7246126701013673

Epoch: 6| Step: 6
Training loss: 3.2102901056697406
Validation loss: 2.722849399207042

Epoch: 6| Step: 7
Training loss: 3.449168290215204
Validation loss: 2.7264244476448414

Epoch: 6| Step: 8
Training loss: 3.297910988554381
Validation loss: 2.7215391106909514

Epoch: 6| Step: 9
Training loss: 3.33301024460613
Validation loss: 2.7230677299989465

Epoch: 6| Step: 10
Training loss: 2.5586797568738615
Validation loss: 2.725036129914699

Epoch: 6| Step: 11
Training loss: 3.0226926847240327
Validation loss: 2.7251141010129283

Epoch: 6| Step: 12
Training loss: 3.078921761966126
Validation loss: 2.723056072901349

Epoch: 6| Step: 13
Training loss: 3.298509382497394
Validation loss: 2.728592574974365

Epoch: 182| Step: 0
Training loss: 3.3740832178586166
Validation loss: 2.725406225609804

Epoch: 6| Step: 1
Training loss: 3.143634018929478
Validation loss: 2.7271785569581017

Epoch: 6| Step: 2
Training loss: 2.645746444917475
Validation loss: 2.7246788018115153

Epoch: 6| Step: 3
Training loss: 3.6081831644597835
Validation loss: 2.7438613984847424

Epoch: 6| Step: 4
Training loss: 3.174404394798928
Validation loss: 2.747566807943011

Epoch: 6| Step: 5
Training loss: 3.196531776655743
Validation loss: 2.7440662392489785

Epoch: 6| Step: 6
Training loss: 3.80936540660323
Validation loss: 2.7278433864289875

Epoch: 6| Step: 7
Training loss: 2.227165274425527
Validation loss: 2.727294121352563

Epoch: 6| Step: 8
Training loss: 3.6769369094411646
Validation loss: 2.7215972859305455

Epoch: 6| Step: 9
Training loss: 2.218924072314393
Validation loss: 2.719523235872875

Epoch: 6| Step: 10
Training loss: 2.9073387485702433
Validation loss: 2.7216386678810447

Epoch: 6| Step: 11
Training loss: 2.665955975322852
Validation loss: 2.720071602688103

Epoch: 6| Step: 12
Training loss: 2.740648582296141
Validation loss: 2.719740167151754

Epoch: 6| Step: 13
Training loss: 2.5675473630226855
Validation loss: 2.720278800308963

Epoch: 183| Step: 0
Training loss: 2.8262855912894356
Validation loss: 2.7262468391231582

Epoch: 6| Step: 1
Training loss: 2.5648236787808365
Validation loss: 2.720881457202287

Epoch: 6| Step: 2
Training loss: 3.067437687297674
Validation loss: 2.7193737792513497

Epoch: 6| Step: 3
Training loss: 3.203957054183734
Validation loss: 2.7244811555782387

Epoch: 6| Step: 4
Training loss: 3.355378368434971
Validation loss: 2.720398692128356

Epoch: 6| Step: 5
Training loss: 2.8400495997651127
Validation loss: 2.720494077836583

Epoch: 6| Step: 6
Training loss: 3.4388982529958643
Validation loss: 2.7187587307441032

Epoch: 6| Step: 7
Training loss: 3.0698897286656717
Validation loss: 2.719719725743263

Epoch: 6| Step: 8
Training loss: 3.112483325591866
Validation loss: 2.719813922163842

Epoch: 6| Step: 9
Training loss: 2.436314808202242
Validation loss: 2.7174325206478924

Epoch: 6| Step: 10
Training loss: 2.844763438977427
Validation loss: 2.720528014250971

Epoch: 6| Step: 11
Training loss: 3.517337365094878
Validation loss: 2.7211900792986112

Epoch: 6| Step: 12
Training loss: 2.910955414074474
Validation loss: 2.7191326337445236

Epoch: 6| Step: 13
Training loss: 3.3494650228553
Validation loss: 2.7224613563139877

Epoch: 184| Step: 0
Training loss: 3.384578534572577
Validation loss: 2.738434292830992

Epoch: 6| Step: 1
Training loss: 2.6817128171045557
Validation loss: 2.7489007503563

Epoch: 6| Step: 2
Training loss: 2.9406648185215087
Validation loss: 2.7559866275929967

Epoch: 6| Step: 3
Training loss: 2.9050247727091265
Validation loss: 2.75580723766545

Epoch: 6| Step: 4
Training loss: 3.264354696018939
Validation loss: 2.7640973198370338

Epoch: 6| Step: 5
Training loss: 2.836021905488934
Validation loss: 2.7498960298216675

Epoch: 6| Step: 6
Training loss: 2.61011581412413
Validation loss: 2.743706818598993

Epoch: 6| Step: 7
Training loss: 3.035027578564802
Validation loss: 2.7312321596874005

Epoch: 6| Step: 8
Training loss: 3.428171157178439
Validation loss: 2.719600674061235

Epoch: 6| Step: 9
Training loss: 3.240801632223328
Validation loss: 2.719519319976616

Epoch: 6| Step: 10
Training loss: 3.0550474457248424
Validation loss: 2.7255484098488516

Epoch: 6| Step: 11
Training loss: 2.9129323941264866
Validation loss: 2.722140979063758

Epoch: 6| Step: 12
Training loss: 3.3006265276699653
Validation loss: 2.72096763409663

Epoch: 6| Step: 13
Training loss: 2.874119333474899
Validation loss: 2.7225737386268984

Epoch: 185| Step: 0
Training loss: 3.0994275333593295
Validation loss: 2.7180332082403194

Epoch: 6| Step: 1
Training loss: 3.168007884507049
Validation loss: 2.7194355755734247

Epoch: 6| Step: 2
Training loss: 3.2453292148326778
Validation loss: 2.7274182457011187

Epoch: 6| Step: 3
Training loss: 3.173686294907915
Validation loss: 2.7251852703530997

Epoch: 6| Step: 4
Training loss: 3.627440321764628
Validation loss: 2.7211173479949484

Epoch: 6| Step: 5
Training loss: 2.9722548826647444
Validation loss: 2.7176089590968737

Epoch: 6| Step: 6
Training loss: 3.224359753360626
Validation loss: 2.7192081060278293

Epoch: 6| Step: 7
Training loss: 2.78853544496496
Validation loss: 2.719777877687893

Epoch: 6| Step: 8
Training loss: 2.0568021038888906
Validation loss: 2.717148381318483

Epoch: 6| Step: 9
Training loss: 3.3382554588687476
Validation loss: 2.715908228246318

Epoch: 6| Step: 10
Training loss: 3.2633692785458313
Validation loss: 2.722040976875807

Epoch: 6| Step: 11
Training loss: 2.240731328040122
Validation loss: 2.727070980162648

Epoch: 6| Step: 12
Training loss: 2.967960132125469
Validation loss: 2.72039025972761

Epoch: 6| Step: 13
Training loss: 3.1426973859634035
Validation loss: 2.7216034067913366

Epoch: 186| Step: 0
Training loss: 2.5566340971674686
Validation loss: 2.7306003207014307

Epoch: 6| Step: 1
Training loss: 2.917683905367932
Validation loss: 2.733858627573168

Epoch: 6| Step: 2
Training loss: 3.07860797636587
Validation loss: 2.73455146841247

Epoch: 6| Step: 3
Training loss: 2.948410873414151
Validation loss: 2.7420264905777842

Epoch: 6| Step: 4
Training loss: 3.387179966972837
Validation loss: 2.734269627475958

Epoch: 6| Step: 5
Training loss: 3.0619781983818437
Validation loss: 2.7375683754078657

Epoch: 6| Step: 6
Training loss: 3.149346686537059
Validation loss: 2.735378428867952

Epoch: 6| Step: 7
Training loss: 2.9377986674961556
Validation loss: 2.734030184004306

Epoch: 6| Step: 8
Training loss: 3.264732859550085
Validation loss: 2.7405704591597746

Epoch: 6| Step: 9
Training loss: 3.400724636722234
Validation loss: 2.748212656729187

Epoch: 6| Step: 10
Training loss: 2.6465305000593022
Validation loss: 2.7273726962152156

Epoch: 6| Step: 11
Training loss: 2.5512127591620004
Validation loss: 2.7167694700704903

Epoch: 6| Step: 12
Training loss: 2.838751119649541
Validation loss: 2.7158183584907456

Epoch: 6| Step: 13
Training loss: 4.081321661934858
Validation loss: 2.718339858226063

Epoch: 187| Step: 0
Training loss: 2.8383610565868516
Validation loss: 2.7122131232625075

Epoch: 6| Step: 1
Training loss: 3.0135348493435425
Validation loss: 2.7149907478744897

Epoch: 6| Step: 2
Training loss: 3.692956669486865
Validation loss: 2.7212335551086526

Epoch: 6| Step: 3
Training loss: 3.7513063062886607
Validation loss: 2.7135374533569157

Epoch: 6| Step: 4
Training loss: 2.9891469461942455
Validation loss: 2.716641880923631

Epoch: 6| Step: 5
Training loss: 3.2080000832288924
Validation loss: 2.719247459659063

Epoch: 6| Step: 6
Training loss: 2.199575391888637
Validation loss: 2.7147153101446624

Epoch: 6| Step: 7
Training loss: 2.4850857275868394
Validation loss: 2.714965766578057

Epoch: 6| Step: 8
Training loss: 2.3269394281665257
Validation loss: 2.7137181826895223

Epoch: 6| Step: 9
Training loss: 2.8175590790560094
Validation loss: 2.711900323109104

Epoch: 6| Step: 10
Training loss: 3.516850914731148
Validation loss: 2.716443962311442

Epoch: 6| Step: 11
Training loss: 3.440209863825974
Validation loss: 2.711733341500694

Epoch: 6| Step: 12
Training loss: 3.0792942053398455
Validation loss: 2.712216860663526

Epoch: 6| Step: 13
Training loss: 2.5054102530102074
Validation loss: 2.7128895864614124

Epoch: 188| Step: 0
Training loss: 3.10015299019614
Validation loss: 2.713127928675402

Epoch: 6| Step: 1
Training loss: 3.123169171942933
Validation loss: 2.715281285867477

Epoch: 6| Step: 2
Training loss: 3.1458990498598616
Validation loss: 2.718582252812561

Epoch: 6| Step: 3
Training loss: 2.6222451604586996
Validation loss: 2.7253393759483595

Epoch: 6| Step: 4
Training loss: 3.2467457544562355
Validation loss: 2.723900971177003

Epoch: 6| Step: 5
Training loss: 2.9458674305224415
Validation loss: 2.729173782541003

Epoch: 6| Step: 6
Training loss: 3.784744161528636
Validation loss: 2.723548828419005

Epoch: 6| Step: 7
Training loss: 2.7418756117427674
Validation loss: 2.724470312820246

Epoch: 6| Step: 8
Training loss: 3.146101849613984
Validation loss: 2.7236136521887806

Epoch: 6| Step: 9
Training loss: 2.5401370547706756
Validation loss: 2.722827659224433

Epoch: 6| Step: 10
Training loss: 2.8150186069883145
Validation loss: 2.7372850197417846

Epoch: 6| Step: 11
Training loss: 2.993587634436117
Validation loss: 2.7373570086682077

Epoch: 6| Step: 12
Training loss: 3.1673338003295393
Validation loss: 2.7402743247887567

Epoch: 6| Step: 13
Training loss: 2.8533931342955907
Validation loss: 2.7331520151235047

Epoch: 189| Step: 0
Training loss: 2.6838501387144618
Validation loss: 2.728543703066279

Epoch: 6| Step: 1
Training loss: 2.4300448532046532
Validation loss: 2.7253789213610693

Epoch: 6| Step: 2
Training loss: 2.504941919532897
Validation loss: 2.7253844966160865

Epoch: 6| Step: 3
Training loss: 3.0037268695424895
Validation loss: 2.730577213478519

Epoch: 6| Step: 4
Training loss: 2.9374551972564062
Validation loss: 2.728146659655052

Epoch: 6| Step: 5
Training loss: 3.875572900568016
Validation loss: 2.714611578901199

Epoch: 6| Step: 6
Training loss: 3.214168955180908
Validation loss: 2.721804179972484

Epoch: 6| Step: 7
Training loss: 3.109718495474108
Validation loss: 2.715755229075899

Epoch: 6| Step: 8
Training loss: 3.7346333051274376
Validation loss: 2.7199145123796638

Epoch: 6| Step: 9
Training loss: 2.3234139724084075
Validation loss: 2.712818304342777

Epoch: 6| Step: 10
Training loss: 2.7534185315852193
Validation loss: 2.7114903346535444

Epoch: 6| Step: 11
Training loss: 3.092058123734377
Validation loss: 2.7102871945531835

Epoch: 6| Step: 12
Training loss: 3.245371236623166
Validation loss: 2.7104618716424858

Epoch: 6| Step: 13
Training loss: 3.223832053493305
Validation loss: 2.715233517920842

Epoch: 190| Step: 0
Training loss: 3.504152287209151
Validation loss: 2.7118297457462424

Epoch: 6| Step: 1
Training loss: 2.26090227058766
Validation loss: 2.7106249574340837

Epoch: 6| Step: 2
Training loss: 3.302073208926752
Validation loss: 2.7144657948721815

Epoch: 6| Step: 3
Training loss: 3.1984142367845223
Validation loss: 2.7136779099699986

Epoch: 6| Step: 4
Training loss: 3.062311594870311
Validation loss: 2.709314198670479

Epoch: 6| Step: 5
Training loss: 3.2462980754642947
Validation loss: 2.7093822111028665

Epoch: 6| Step: 6
Training loss: 3.2647192762188064
Validation loss: 2.711481155987076

Epoch: 6| Step: 7
Training loss: 3.297172930666027
Validation loss: 2.717509134467455

Epoch: 6| Step: 8
Training loss: 2.8542312466260173
Validation loss: 2.710126815607349

Epoch: 6| Step: 9
Training loss: 2.9712692012334947
Validation loss: 2.7110324526310396

Epoch: 6| Step: 10
Training loss: 2.9432433775666333
Validation loss: 2.7156120175842258

Epoch: 6| Step: 11
Training loss: 2.921626605731032
Validation loss: 2.7159754516280756

Epoch: 6| Step: 12
Training loss: 2.880838188481417
Validation loss: 2.710909055171881

Epoch: 6| Step: 13
Training loss: 2.1388760961284885
Validation loss: 2.7162396424571833

Epoch: 191| Step: 0
Training loss: 3.4716273565412443
Validation loss: 2.72243788715039

Epoch: 6| Step: 1
Training loss: 3.046262708910579
Validation loss: 2.7312206050186165

Epoch: 6| Step: 2
Training loss: 2.9519691425457824
Validation loss: 2.7281839523521025

Epoch: 6| Step: 3
Training loss: 2.6985924265994488
Validation loss: 2.741152895140909

Epoch: 6| Step: 4
Training loss: 3.4012267143688937
Validation loss: 2.72125593902012

Epoch: 6| Step: 5
Training loss: 3.1855947747011886
Validation loss: 2.7165146802609126

Epoch: 6| Step: 6
Training loss: 3.176814850682995
Validation loss: 2.7286682741558237

Epoch: 6| Step: 7
Training loss: 3.1759479098912773
Validation loss: 2.730717452686742

Epoch: 6| Step: 8
Training loss: 2.447031020528691
Validation loss: 2.7216701730154553

Epoch: 6| Step: 9
Training loss: 2.618834839677941
Validation loss: 2.723748706166242

Epoch: 6| Step: 10
Training loss: 1.89345748203309
Validation loss: 2.7132472331877313

Epoch: 6| Step: 11
Training loss: 3.038933209412397
Validation loss: 2.716897280631104

Epoch: 6| Step: 12
Training loss: 3.6408035169064346
Validation loss: 2.7150292316141944

Epoch: 6| Step: 13
Training loss: 3.4680212131630235
Validation loss: 2.7164409262699674

Epoch: 192| Step: 0
Training loss: 3.054847498457258
Validation loss: 2.714894428489866

Epoch: 6| Step: 1
Training loss: 2.9892350014953726
Validation loss: 2.7155212439919927

Epoch: 6| Step: 2
Training loss: 3.0671606605820743
Validation loss: 2.717057194834738

Epoch: 6| Step: 3
Training loss: 3.2288037660193054
Validation loss: 2.716038911948933

Epoch: 6| Step: 4
Training loss: 2.9402167560834536
Validation loss: 2.709078203731328

Epoch: 6| Step: 5
Training loss: 3.0070330514007986
Validation loss: 2.707016279303512

Epoch: 6| Step: 6
Training loss: 2.380909043780518
Validation loss: 2.7036070774640453

Epoch: 6| Step: 7
Training loss: 3.0700382178099144
Validation loss: 2.7020745086456244

Epoch: 6| Step: 8
Training loss: 3.0211712527636347
Validation loss: 2.7090061532078566

Epoch: 6| Step: 9
Training loss: 3.0581010638465203
Validation loss: 2.7055404316015497

Epoch: 6| Step: 10
Training loss: 3.2260721124960017
Validation loss: 2.706561227411544

Epoch: 6| Step: 11
Training loss: 3.2924017910224492
Validation loss: 2.7036648828274776

Epoch: 6| Step: 12
Training loss: 3.026957195582984
Validation loss: 2.706045881662266

Epoch: 6| Step: 13
Training loss: 2.956193570975546
Validation loss: 2.705193667833428

Epoch: 193| Step: 0
Training loss: 2.6974576954887386
Validation loss: 2.708291684028442

Epoch: 6| Step: 1
Training loss: 2.7125511973247454
Validation loss: 2.7083375298125993

Epoch: 6| Step: 2
Training loss: 3.4975231125717574
Validation loss: 2.7160311484466244

Epoch: 6| Step: 3
Training loss: 3.00428561232205
Validation loss: 2.716192722884255

Epoch: 6| Step: 4
Training loss: 2.3465890600997823
Validation loss: 2.7186831498027817

Epoch: 6| Step: 5
Training loss: 3.0608550344421928
Validation loss: 2.713707800452833

Epoch: 6| Step: 6
Training loss: 3.345439163368657
Validation loss: 2.7284041742883147

Epoch: 6| Step: 7
Training loss: 2.968317903895886
Validation loss: 2.7206299001071783

Epoch: 6| Step: 8
Training loss: 3.417783477121448
Validation loss: 2.7179389623669925

Epoch: 6| Step: 9
Training loss: 2.9471253500104666
Validation loss: 2.709164519508923

Epoch: 6| Step: 10
Training loss: 3.7567347767524564
Validation loss: 2.712861713978375

Epoch: 6| Step: 11
Training loss: 2.3678072379372086
Validation loss: 2.702628566251175

Epoch: 6| Step: 12
Training loss: 2.9580015256102716
Validation loss: 2.7045016581841477

Epoch: 6| Step: 13
Training loss: 3.017824467847292
Validation loss: 2.701160526771569

Epoch: 194| Step: 0
Training loss: 2.8641774022871664
Validation loss: 2.700544833135393

Epoch: 6| Step: 1
Training loss: 3.134251746723741
Validation loss: 2.7018565489712656

Epoch: 6| Step: 2
Training loss: 2.9852480584976786
Validation loss: 2.700297476599566

Epoch: 6| Step: 3
Training loss: 3.46536226919182
Validation loss: 2.705113091632823

Epoch: 6| Step: 4
Training loss: 2.6908920527722495
Validation loss: 2.7053893307173413

Epoch: 6| Step: 5
Training loss: 3.344069991442466
Validation loss: 2.7052070375796093

Epoch: 6| Step: 6
Training loss: 2.9374881500654437
Validation loss: 2.7047733229786117

Epoch: 6| Step: 7
Training loss: 3.33608729720759
Validation loss: 2.7033077559703798

Epoch: 6| Step: 8
Training loss: 2.6696512884671213
Validation loss: 2.703569483686411

Epoch: 6| Step: 9
Training loss: 2.8921789992509965
Validation loss: 2.704187616204895

Epoch: 6| Step: 10
Training loss: 2.707263226498537
Validation loss: 2.701351063822181

Epoch: 6| Step: 11
Training loss: 3.3530844765069365
Validation loss: 2.70296478223448

Epoch: 6| Step: 12
Training loss: 2.9570202846147415
Validation loss: 2.701371377554156

Epoch: 6| Step: 13
Training loss: 2.8019922423653556
Validation loss: 2.6954191405850696

Epoch: 195| Step: 0
Training loss: 3.4018077756654805
Validation loss: 2.700325168321418

Epoch: 6| Step: 1
Training loss: 3.0863712054308055
Validation loss: 2.698262580693359

Epoch: 6| Step: 2
Training loss: 2.944128633353
Validation loss: 2.696662257408035

Epoch: 6| Step: 3
Training loss: 2.8878419417668
Validation loss: 2.6973545228252367

Epoch: 6| Step: 4
Training loss: 3.2060710477803713
Validation loss: 2.697839078659773

Epoch: 6| Step: 5
Training loss: 2.9138906801515434
Validation loss: 2.6960857350481526

Epoch: 6| Step: 6
Training loss: 2.1353998943383496
Validation loss: 2.698971540740635

Epoch: 6| Step: 7
Training loss: 2.8415473540047276
Validation loss: 2.697519284901256

Epoch: 6| Step: 8
Training loss: 3.3697533976265133
Validation loss: 2.696354244034834

Epoch: 6| Step: 9
Training loss: 2.9351548918578008
Validation loss: 2.6985859571476403

Epoch: 6| Step: 10
Training loss: 2.7356736941031383
Validation loss: 2.697670694505458

Epoch: 6| Step: 11
Training loss: 2.723911340914763
Validation loss: 2.6982243661322878

Epoch: 6| Step: 12
Training loss: 3.731463841839299
Validation loss: 2.6968323538388987

Epoch: 6| Step: 13
Training loss: 3.250236355916863
Validation loss: 2.6930967663939414

Epoch: 196| Step: 0
Training loss: 3.1134212371484136
Validation loss: 2.6987768222548776

Epoch: 6| Step: 1
Training loss: 3.8023070108470107
Validation loss: 2.697696108696565

Epoch: 6| Step: 2
Training loss: 2.9024232671223547
Validation loss: 2.699646487426147

Epoch: 6| Step: 3
Training loss: 3.2753473869295022
Validation loss: 2.6971482141339203

Epoch: 6| Step: 4
Training loss: 3.096973781761711
Validation loss: 2.6986110729737787

Epoch: 6| Step: 5
Training loss: 3.3418462449779525
Validation loss: 2.695604482763991

Epoch: 6| Step: 6
Training loss: 3.0347464934153683
Validation loss: 2.6916184230321107

Epoch: 6| Step: 7
Training loss: 3.061887095875781
Validation loss: 2.6942403564726307

Epoch: 6| Step: 8
Training loss: 2.0660065406777024
Validation loss: 2.6948719979063465

Epoch: 6| Step: 9
Training loss: 2.4727313616343976
Validation loss: 2.6997785346759007

Epoch: 6| Step: 10
Training loss: 2.815665858032621
Validation loss: 2.7066146761373933

Epoch: 6| Step: 11
Training loss: 3.0815947674426596
Validation loss: 2.702882603044654

Epoch: 6| Step: 12
Training loss: 2.6659418452188004
Validation loss: 2.703188508782788

Epoch: 6| Step: 13
Training loss: 3.3336217914382624
Validation loss: 2.716208273482651

Epoch: 197| Step: 0
Training loss: 2.940549525590612
Validation loss: 2.707332917271847

Epoch: 6| Step: 1
Training loss: 2.966100695196542
Validation loss: 2.7001411978931786

Epoch: 6| Step: 2
Training loss: 3.1549368666726805
Validation loss: 2.69761680817785

Epoch: 6| Step: 3
Training loss: 3.5571406692174246
Validation loss: 2.7003104984278927

Epoch: 6| Step: 4
Training loss: 2.949486484122199
Validation loss: 2.6969164018213676

Epoch: 6| Step: 5
Training loss: 2.595451440370497
Validation loss: 2.693273864362874

Epoch: 6| Step: 6
Training loss: 2.3280953014962944
Validation loss: 2.6896083447797743

Epoch: 6| Step: 7
Training loss: 3.426042918669643
Validation loss: 2.692501408065897

Epoch: 6| Step: 8
Training loss: 3.135441388173192
Validation loss: 2.690807254501155

Epoch: 6| Step: 9
Training loss: 3.602748849230249
Validation loss: 2.6900956958486137

Epoch: 6| Step: 10
Training loss: 2.729939028719305
Validation loss: 2.6924458481685596

Epoch: 6| Step: 11
Training loss: 3.1241431015101373
Validation loss: 2.6935639266440923

Epoch: 6| Step: 12
Training loss: 2.40448537749193
Validation loss: 2.6919821765308827

Epoch: 6| Step: 13
Training loss: 3.1250094604348986
Validation loss: 2.6909883795888385

Epoch: 198| Step: 0
Training loss: 3.065665030339595
Validation loss: 2.6942774333924437

Epoch: 6| Step: 1
Training loss: 3.0322781421740235
Validation loss: 2.695177341357983

Epoch: 6| Step: 2
Training loss: 2.8174885906810987
Validation loss: 2.692242281884435

Epoch: 6| Step: 3
Training loss: 4.133679362138497
Validation loss: 2.693863771221741

Epoch: 6| Step: 4
Training loss: 2.3831482697598108
Validation loss: 2.690607625127644

Epoch: 6| Step: 5
Training loss: 2.7406865981866626
Validation loss: 2.6899866088902584

Epoch: 6| Step: 6
Training loss: 2.7617279009417874
Validation loss: 2.689613929367924

Epoch: 6| Step: 7
Training loss: 3.255657846567421
Validation loss: 2.697313577135837

Epoch: 6| Step: 8
Training loss: 2.89443619503799
Validation loss: 2.691533910531073

Epoch: 6| Step: 9
Training loss: 3.5592596475800415
Validation loss: 2.6946594502915313

Epoch: 6| Step: 10
Training loss: 3.0582212803518924
Validation loss: 2.699869168133802

Epoch: 6| Step: 11
Training loss: 3.0386099588755604
Validation loss: 2.6979771816853115

Epoch: 6| Step: 12
Training loss: 2.2347544101219645
Validation loss: 2.7009309239415717

Epoch: 6| Step: 13
Training loss: 2.5926601464184733
Validation loss: 2.6990646907910234

Epoch: 199| Step: 0
Training loss: 3.354476693241145
Validation loss: 2.709143689812461

Epoch: 6| Step: 1
Training loss: 2.9901227475490293
Validation loss: 2.7097251620868485

Epoch: 6| Step: 2
Training loss: 2.9521666894386986
Validation loss: 2.7176375186923054

Epoch: 6| Step: 3
Training loss: 2.2988355923306925
Validation loss: 2.7112155379393577

Epoch: 6| Step: 4
Training loss: 2.811567363813246
Validation loss: 2.715752063881934

Epoch: 6| Step: 5
Training loss: 3.3276929977930707
Validation loss: 2.7094207981592984

Epoch: 6| Step: 6
Training loss: 3.2115994627301814
Validation loss: 2.703808852275039

Epoch: 6| Step: 7
Training loss: 3.4711864265881607
Validation loss: 2.7079875381370084

Epoch: 6| Step: 8
Training loss: 2.9511623420283657
Validation loss: 2.703071809475693

Epoch: 6| Step: 9
Training loss: 2.811866773740424
Validation loss: 2.7069178057035557

Epoch: 6| Step: 10
Training loss: 3.1143620815388116
Validation loss: 2.6981874679165316

Epoch: 6| Step: 11
Training loss: 2.9245971402258446
Validation loss: 2.697793340499171

Epoch: 6| Step: 12
Training loss: 2.718427441634617
Validation loss: 2.6907166254549555

Epoch: 6| Step: 13
Training loss: 3.1641218768541317
Validation loss: 2.6921179974369522

Epoch: 200| Step: 0
Training loss: 2.7584848421865136
Validation loss: 2.689385752469622

Epoch: 6| Step: 1
Training loss: 2.7518172761891737
Validation loss: 2.6868172169576345

Epoch: 6| Step: 2
Training loss: 3.1585201748325464
Validation loss: 2.692367668941981

Epoch: 6| Step: 3
Training loss: 2.6173614899605324
Validation loss: 2.686163711960364

Epoch: 6| Step: 4
Training loss: 3.0394307283645823
Validation loss: 2.68734476051778

Epoch: 6| Step: 5
Training loss: 2.96936510640437
Validation loss: 2.687964083339017

Epoch: 6| Step: 6
Training loss: 2.8267510380239074
Validation loss: 2.688110825877304

Epoch: 6| Step: 7
Training loss: 3.61933060964174
Validation loss: 2.6882577902336204

Epoch: 6| Step: 8
Training loss: 3.0270608486767814
Validation loss: 2.6858873148021027

Epoch: 6| Step: 9
Training loss: 3.113890469819423
Validation loss: 2.6872502635660984

Epoch: 6| Step: 10
Training loss: 2.9059054262717408
Validation loss: 2.6886497197950914

Epoch: 6| Step: 11
Training loss: 3.2708343862220057
Validation loss: 2.6893484860933485

Epoch: 6| Step: 12
Training loss: 2.7401858248661464
Validation loss: 2.6857872895351593

Epoch: 6| Step: 13
Training loss: 3.4599461911818836
Validation loss: 2.686065043676404

Epoch: 201| Step: 0
Training loss: 3.088513190324212
Validation loss: 2.6846269903199484

Epoch: 6| Step: 1
Training loss: 2.174667867973989
Validation loss: 2.687891434410785

Epoch: 6| Step: 2
Training loss: 2.9581291952129627
Validation loss: 2.6875241071760234

Epoch: 6| Step: 3
Training loss: 3.4312932246252834
Validation loss: 2.688774054910387

Epoch: 6| Step: 4
Training loss: 2.597340500076924
Validation loss: 2.681985448188693

Epoch: 6| Step: 5
Training loss: 2.9761071845615747
Validation loss: 2.6842715309358076

Epoch: 6| Step: 6
Training loss: 2.6787752873183504
Validation loss: 2.6890104608413252

Epoch: 6| Step: 7
Training loss: 2.9286091765519644
Validation loss: 2.6887990125842047

Epoch: 6| Step: 8
Training loss: 3.884446228307241
Validation loss: 2.685635727353151

Epoch: 6| Step: 9
Training loss: 2.9793892801693582
Validation loss: 2.7013259886558467

Epoch: 6| Step: 10
Training loss: 3.256173359560232
Validation loss: 2.6954521115695775

Epoch: 6| Step: 11
Training loss: 2.9790850185774485
Validation loss: 2.6908246753019944

Epoch: 6| Step: 12
Training loss: 2.6700499252052157
Validation loss: 2.699056341811425

Epoch: 6| Step: 13
Training loss: 3.3647449245957373
Validation loss: 2.702325068438423

Epoch: 202| Step: 0
Training loss: 2.523783562613234
Validation loss: 2.707938747832098

Epoch: 6| Step: 1
Training loss: 3.26180646401521
Validation loss: 2.699598673592121

Epoch: 6| Step: 2
Training loss: 2.7543119091185737
Validation loss: 2.6893082116310443

Epoch: 6| Step: 3
Training loss: 2.6548488736289833
Validation loss: 2.6873506951455277

Epoch: 6| Step: 4
Training loss: 3.1729487964575487
Validation loss: 2.6876958178080717

Epoch: 6| Step: 5
Training loss: 2.6713142922089887
Validation loss: 2.6846409810163157

Epoch: 6| Step: 6
Training loss: 2.510351779041119
Validation loss: 2.68877669122818

Epoch: 6| Step: 7
Training loss: 3.054289262574044
Validation loss: 2.6821754826249746

Epoch: 6| Step: 8
Training loss: 3.082969919043732
Validation loss: 2.686792856787713

Epoch: 6| Step: 9
Training loss: 3.4265314061623586
Validation loss: 2.6864385146922585

Epoch: 6| Step: 10
Training loss: 3.377956649438871
Validation loss: 2.6914558991274653

Epoch: 6| Step: 11
Training loss: 3.1376896895860757
Validation loss: 2.6899322965346544

Epoch: 6| Step: 12
Training loss: 3.2048607565972733
Validation loss: 2.689868991333283

Epoch: 6| Step: 13
Training loss: 3.1926843705556354
Validation loss: 2.6843686549705876

Epoch: 203| Step: 0
Training loss: 2.7460968755538757
Validation loss: 2.6829099823981877

Epoch: 6| Step: 1
Training loss: 3.1104657737567076
Validation loss: 2.6851633668920787

Epoch: 6| Step: 2
Training loss: 2.9559374137932446
Validation loss: 2.6935883155190794

Epoch: 6| Step: 3
Training loss: 2.5064506279226055
Validation loss: 2.6875388907432427

Epoch: 6| Step: 4
Training loss: 3.548218997626097
Validation loss: 2.703255061237431

Epoch: 6| Step: 5
Training loss: 3.1007340331265842
Validation loss: 2.704727739992674

Epoch: 6| Step: 6
Training loss: 3.2047792210465693
Validation loss: 2.69564430556889

Epoch: 6| Step: 7
Training loss: 2.692400168832341
Validation loss: 2.7024981286170084

Epoch: 6| Step: 8
Training loss: 3.2694198243035153
Validation loss: 2.6880784200444108

Epoch: 6| Step: 9
Training loss: 2.327906041441699
Validation loss: 2.6945833693943815

Epoch: 6| Step: 10
Training loss: 3.434660137304572
Validation loss: 2.696250020330752

Epoch: 6| Step: 11
Training loss: 2.905216976867343
Validation loss: 2.7035241819493616

Epoch: 6| Step: 12
Training loss: 3.074655038976505
Validation loss: 2.694214668945401

Epoch: 6| Step: 13
Training loss: 3.0809842689555813
Validation loss: 2.6904212326352597

Epoch: 204| Step: 0
Training loss: 2.6746529755145265
Validation loss: 2.688672750653386

Epoch: 6| Step: 1
Training loss: 3.1934597174602053
Validation loss: 2.6861207326915153

Epoch: 6| Step: 2
Training loss: 2.8437897396454943
Validation loss: 2.6872888221198843

Epoch: 6| Step: 3
Training loss: 2.6719478128784804
Validation loss: 2.68895340729827

Epoch: 6| Step: 4
Training loss: 3.425152606766401
Validation loss: 2.6856381032891927

Epoch: 6| Step: 5
Training loss: 3.563192467565159
Validation loss: 2.68730393038152

Epoch: 6| Step: 6
Training loss: 2.1199063231806443
Validation loss: 2.6865894017897927

Epoch: 6| Step: 7
Training loss: 2.147784879571512
Validation loss: 2.683410828401976

Epoch: 6| Step: 8
Training loss: 3.1238288210617267
Validation loss: 2.6836194895151637

Epoch: 6| Step: 9
Training loss: 3.305809029086827
Validation loss: 2.692582241708168

Epoch: 6| Step: 10
Training loss: 3.0046957141845274
Validation loss: 2.686916405285393

Epoch: 6| Step: 11
Training loss: 3.2607601744506147
Validation loss: 2.68584273518445

Epoch: 6| Step: 12
Training loss: 3.3049412983862223
Validation loss: 2.6973632558166356

Epoch: 6| Step: 13
Training loss: 3.0933769848911554
Validation loss: 2.6905953023943123

Epoch: 205| Step: 0
Training loss: 2.653282212990171
Validation loss: 2.684990982529685

Epoch: 6| Step: 1
Training loss: 3.1310314718959518
Validation loss: 2.6953291298173574

Epoch: 6| Step: 2
Training loss: 3.5010761241509174
Validation loss: 2.6933931393223896

Epoch: 6| Step: 3
Training loss: 3.2830969562418457
Validation loss: 2.6844878356927038

Epoch: 6| Step: 4
Training loss: 2.9156267401229066
Validation loss: 2.680396337461729

Epoch: 6| Step: 5
Training loss: 3.3662068295322336
Validation loss: 2.680835849137884

Epoch: 6| Step: 6
Training loss: 3.240827086574988
Validation loss: 2.6840332939927087

Epoch: 6| Step: 7
Training loss: 3.0311118812162303
Validation loss: 2.6793918844187643

Epoch: 6| Step: 8
Training loss: 2.759242910677585
Validation loss: 2.680488523387264

Epoch: 6| Step: 9
Training loss: 2.078704523723428
Validation loss: 2.6814038895949235

Epoch: 6| Step: 10
Training loss: 2.943309153208732
Validation loss: 2.6788543809551713

Epoch: 6| Step: 11
Training loss: 2.5357088917880186
Validation loss: 2.6909329618425333

Epoch: 6| Step: 12
Training loss: 3.2715853820694347
Validation loss: 2.6830281481970153

Epoch: 6| Step: 13
Training loss: 3.231425686750995
Validation loss: 2.6862626791498263

Epoch: 206| Step: 0
Training loss: 3.1456152901441823
Validation loss: 2.6784671666860365

Epoch: 6| Step: 1
Training loss: 2.180492840274707
Validation loss: 2.681370943780339

Epoch: 6| Step: 2
Training loss: 3.232077847062576
Validation loss: 2.6809580384200506

Epoch: 6| Step: 3
Training loss: 2.9156522530838767
Validation loss: 2.6869240477755896

Epoch: 6| Step: 4
Training loss: 2.7473966239940113
Validation loss: 2.6846118163814574

Epoch: 6| Step: 5
Training loss: 3.360171201522333
Validation loss: 2.6846524888370267

Epoch: 6| Step: 6
Training loss: 3.1610143979307943
Validation loss: 2.692723286784499

Epoch: 6| Step: 7
Training loss: 3.054774914829804
Validation loss: 2.6848493307273924

Epoch: 6| Step: 8
Training loss: 3.126724682766503
Validation loss: 2.684064462099185

Epoch: 6| Step: 9
Training loss: 3.705758618979206
Validation loss: 2.68439595996705

Epoch: 6| Step: 10
Training loss: 2.708023748065491
Validation loss: 2.6838173518843065

Epoch: 6| Step: 11
Training loss: 2.884702646940771
Validation loss: 2.6872581130785265

Epoch: 6| Step: 12
Training loss: 2.916673242470731
Validation loss: 2.682719388399245

Epoch: 6| Step: 13
Training loss: 2.4114604864804328
Validation loss: 2.6863401046261286

Epoch: 207| Step: 0
Training loss: 2.776307160717826
Validation loss: 2.678435877931442

Epoch: 6| Step: 1
Training loss: 2.839103507804417
Validation loss: 2.684900202032024

Epoch: 6| Step: 2
Training loss: 3.5311159091573034
Validation loss: 2.688953761008606

Epoch: 6| Step: 3
Training loss: 2.7232003455062093
Validation loss: 2.685948512855022

Epoch: 6| Step: 4
Training loss: 3.175293531891481
Validation loss: 2.679999205265163

Epoch: 6| Step: 5
Training loss: 2.7827012636891175
Validation loss: 2.6847733308673205

Epoch: 6| Step: 6
Training loss: 3.6730722626292804
Validation loss: 2.6887029982595334

Epoch: 6| Step: 7
Training loss: 3.2572836320853416
Validation loss: 2.6912684080040954

Epoch: 6| Step: 8
Training loss: 2.420392277820671
Validation loss: 2.681278927787996

Epoch: 6| Step: 9
Training loss: 2.8650093640345853
Validation loss: 2.680541021064047

Epoch: 6| Step: 10
Training loss: 3.074789185779621
Validation loss: 2.6844920910942243

Epoch: 6| Step: 11
Training loss: 2.5740105366761656
Validation loss: 2.68088490988725

Epoch: 6| Step: 12
Training loss: 2.9711319853985287
Validation loss: 2.6824700092045597

Epoch: 6| Step: 13
Training loss: 3.378057719503743
Validation loss: 2.675532503768996

Epoch: 208| Step: 0
Training loss: 3.0082367040555424
Validation loss: 2.674704538197063

Epoch: 6| Step: 1
Training loss: 3.061713760033172
Validation loss: 2.6768350033940576

Epoch: 6| Step: 2
Training loss: 3.2771190980065907
Validation loss: 2.673833524901865

Epoch: 6| Step: 3
Training loss: 2.959536741966685
Validation loss: 2.6769670870037383

Epoch: 6| Step: 4
Training loss: 2.5879081293629707
Validation loss: 2.6736409270931483

Epoch: 6| Step: 5
Training loss: 2.6313573964870063
Validation loss: 2.674912921016052

Epoch: 6| Step: 6
Training loss: 3.086627506422393
Validation loss: 2.6736250742552246

Epoch: 6| Step: 7
Training loss: 3.0715390150674535
Validation loss: 2.671099828765789

Epoch: 6| Step: 8
Training loss: 2.7296401527984475
Validation loss: 2.6759522100423774

Epoch: 6| Step: 9
Training loss: 3.1033774957952973
Validation loss: 2.67277101073455

Epoch: 6| Step: 10
Training loss: 3.47021288567774
Validation loss: 2.675331971304092

Epoch: 6| Step: 11
Training loss: 3.0186189800759884
Validation loss: 2.674421360583645

Epoch: 6| Step: 12
Training loss: 2.3748171886557734
Validation loss: 2.6872200978710836

Epoch: 6| Step: 13
Training loss: 3.825092219818014
Validation loss: 2.682266942185162

Epoch: 209| Step: 0
Training loss: 2.580778109294571
Validation loss: 2.6917986240066663

Epoch: 6| Step: 1
Training loss: 2.9976357044493174
Validation loss: 2.682717576557012

Epoch: 6| Step: 2
Training loss: 2.9179360670023735
Validation loss: 2.6802689049445525

Epoch: 6| Step: 3
Training loss: 3.41967563407127
Validation loss: 2.6830772319216596

Epoch: 6| Step: 4
Training loss: 2.9451933414224905
Validation loss: 2.6794748108559365

Epoch: 6| Step: 5
Training loss: 2.677788331137193
Validation loss: 2.6810894828846052

Epoch: 6| Step: 6
Training loss: 2.725477904663212
Validation loss: 2.681280523561902

Epoch: 6| Step: 7
Training loss: 3.051468892573501
Validation loss: 2.673361686497064

Epoch: 6| Step: 8
Training loss: 3.1406649307065875
Validation loss: 2.676290869216395

Epoch: 6| Step: 9
Training loss: 3.46258133885664
Validation loss: 2.674551480504626

Epoch: 6| Step: 10
Training loss: 3.419144468546123
Validation loss: 2.674982603566849

Epoch: 6| Step: 11
Training loss: 2.6568914200000115
Validation loss: 2.6722544662282632

Epoch: 6| Step: 12
Training loss: 3.114736104597264
Validation loss: 2.676925005866797

Epoch: 6| Step: 13
Training loss: 2.522897763001623
Validation loss: 2.6798783096280467

Epoch: 210| Step: 0
Training loss: 3.100931175415392
Validation loss: 2.67905502774418

Epoch: 6| Step: 1
Training loss: 3.6397190522144336
Validation loss: 2.6765257513800673

Epoch: 6| Step: 2
Training loss: 2.594534514027983
Validation loss: 2.673656791343298

Epoch: 6| Step: 3
Training loss: 2.8498714083388714
Validation loss: 2.675510847864457

Epoch: 6| Step: 4
Training loss: 2.7905693364759254
Validation loss: 2.6736446306776482

Epoch: 6| Step: 5
Training loss: 2.8625873802208055
Validation loss: 2.6695801031076223

Epoch: 6| Step: 6
Training loss: 3.4552971407671516
Validation loss: 2.6676886773410655

Epoch: 6| Step: 7
Training loss: 2.834810395535775
Validation loss: 2.6712984006114784

Epoch: 6| Step: 8
Training loss: 2.757685844819798
Validation loss: 2.671413183824835

Epoch: 6| Step: 9
Training loss: 2.1515518088480294
Validation loss: 2.6749081606314173

Epoch: 6| Step: 10
Training loss: 3.445882667886393
Validation loss: 2.6800082009529334

Epoch: 6| Step: 11
Training loss: 3.137135403182788
Validation loss: 2.675118567869663

Epoch: 6| Step: 12
Training loss: 2.990584698667601
Validation loss: 2.67605553821417

Epoch: 6| Step: 13
Training loss: 3.2518400705291945
Validation loss: 2.6773072714831216

Epoch: 211| Step: 0
Training loss: 3.3729566817161167
Validation loss: 2.6771079559809023

Epoch: 6| Step: 1
Training loss: 2.940035435988513
Validation loss: 2.6836775056909836

Epoch: 6| Step: 2
Training loss: 2.977220837937065
Validation loss: 2.6860269552717897

Epoch: 6| Step: 3
Training loss: 3.00830042460891
Validation loss: 2.6832998961238754

Epoch: 6| Step: 4
Training loss: 3.5148547875917213
Validation loss: 2.6814970724585665

Epoch: 6| Step: 5
Training loss: 3.621170125441855
Validation loss: 2.6748128208121105

Epoch: 6| Step: 6
Training loss: 2.9946804567779863
Validation loss: 2.6867908096283775

Epoch: 6| Step: 7
Training loss: 2.901528409512141
Validation loss: 2.6725355630797227

Epoch: 6| Step: 8
Training loss: 2.8447800332363133
Validation loss: 2.670907239237109

Epoch: 6| Step: 9
Training loss: 2.439514794650586
Validation loss: 2.6670079903686323

Epoch: 6| Step: 10
Training loss: 2.566655209338225
Validation loss: 2.670906477124923

Epoch: 6| Step: 11
Training loss: 2.6819252924402943
Validation loss: 2.6719678186100735

Epoch: 6| Step: 12
Training loss: 2.7671478733906594
Validation loss: 2.6774473211394727

Epoch: 6| Step: 13
Training loss: 3.2439195533495457
Validation loss: 2.6806736794916803

Epoch: 212| Step: 0
Training loss: 2.84812138530208
Validation loss: 2.6791977580902366

Epoch: 6| Step: 1
Training loss: 3.2274511559038532
Validation loss: 2.6786933307283585

Epoch: 6| Step: 2
Training loss: 3.097108039594896
Validation loss: 2.6771638897301906

Epoch: 6| Step: 3
Training loss: 3.020890772481709
Validation loss: 2.6835433535612747

Epoch: 6| Step: 4
Training loss: 2.967186606488889
Validation loss: 2.6757746257539807

Epoch: 6| Step: 5
Training loss: 2.3392170112862796
Validation loss: 2.6736157032689634

Epoch: 6| Step: 6
Training loss: 3.349741051757668
Validation loss: 2.6747836237743567

Epoch: 6| Step: 7
Training loss: 2.86406352557691
Validation loss: 2.6660318548354653

Epoch: 6| Step: 8
Training loss: 3.3281549443433565
Validation loss: 2.681002071020657

Epoch: 6| Step: 9
Training loss: 3.6080718887678223
Validation loss: 2.6754301318195473

Epoch: 6| Step: 10
Training loss: 2.461993278612
Validation loss: 2.678584321592117

Epoch: 6| Step: 11
Training loss: 2.9573822820973583
Validation loss: 2.672477964527598

Epoch: 6| Step: 12
Training loss: 2.7294414372238545
Validation loss: 2.6768924272709715

Epoch: 6| Step: 13
Training loss: 2.9204837526386394
Validation loss: 2.6844628532173895

Epoch: 213| Step: 0
Training loss: 2.922937699720566
Validation loss: 2.6880567412310854

Epoch: 6| Step: 1
Training loss: 2.3740937361043812
Validation loss: 2.686440612220226

Epoch: 6| Step: 2
Training loss: 3.012915941070468
Validation loss: 2.6874363513229027

Epoch: 6| Step: 3
Training loss: 3.5043637456521006
Validation loss: 2.6751846792163865

Epoch: 6| Step: 4
Training loss: 2.9338481198494644
Validation loss: 2.6769560508368295

Epoch: 6| Step: 5
Training loss: 3.392010524355558
Validation loss: 2.6709479437745203

Epoch: 6| Step: 6
Training loss: 2.6027759551543217
Validation loss: 2.666460274072019

Epoch: 6| Step: 7
Training loss: 2.2574811118044398
Validation loss: 2.673778300035829

Epoch: 6| Step: 8
Training loss: 2.9621009654494563
Validation loss: 2.6658276101839666

Epoch: 6| Step: 9
Training loss: 3.287773550278017
Validation loss: 2.6618060198411566

Epoch: 6| Step: 10
Training loss: 3.4312634855189517
Validation loss: 2.665577648496132

Epoch: 6| Step: 11
Training loss: 3.1886276045771456
Validation loss: 2.669349381046226

Epoch: 6| Step: 12
Training loss: 2.5449569125921725
Validation loss: 2.6653101586331993

Epoch: 6| Step: 13
Training loss: 3.416482935981895
Validation loss: 2.667025353710641

Epoch: 214| Step: 0
Training loss: 2.8656149561382565
Validation loss: 2.6682193043718563

Epoch: 6| Step: 1
Training loss: 3.546911163817909
Validation loss: 2.6708032943415727

Epoch: 6| Step: 2
Training loss: 2.9780007239367117
Validation loss: 2.6698633179401683

Epoch: 6| Step: 3
Training loss: 2.437230608798911
Validation loss: 2.6687962750629954

Epoch: 6| Step: 4
Training loss: 3.8050508110272996
Validation loss: 2.670030261320637

Epoch: 6| Step: 5
Training loss: 3.271962709899914
Validation loss: 2.6908090837619985

Epoch: 6| Step: 6
Training loss: 3.0852541396259565
Validation loss: 2.6984862914301244

Epoch: 6| Step: 7
Training loss: 1.9666395228608669
Validation loss: 2.6888158848168024

Epoch: 6| Step: 8
Training loss: 2.5687528475631933
Validation loss: 2.691773215088365

Epoch: 6| Step: 9
Training loss: 2.957865145174982
Validation loss: 2.6751893011134094

Epoch: 6| Step: 10
Training loss: 3.0516193718598736
Validation loss: 2.6825798863459482

Epoch: 6| Step: 11
Training loss: 2.934096292050653
Validation loss: 2.682265779008119

Epoch: 6| Step: 12
Training loss: 2.9603945755229395
Validation loss: 2.6694999644902264

Epoch: 6| Step: 13
Training loss: 3.1335253582274225
Validation loss: 2.6742821149227933

Epoch: 215| Step: 0
Training loss: 2.5534162712405197
Validation loss: 2.672172982170531

Epoch: 6| Step: 1
Training loss: 3.213858433737319
Validation loss: 2.676930255869749

Epoch: 6| Step: 2
Training loss: 3.31512447969257
Validation loss: 2.6728529551718885

Epoch: 6| Step: 3
Training loss: 3.6315894908737425
Validation loss: 2.6646475681907593

Epoch: 6| Step: 4
Training loss: 3.2919097681854828
Validation loss: 2.659284318102053

Epoch: 6| Step: 5
Training loss: 2.5154143061575986
Validation loss: 2.6686975439244454

Epoch: 6| Step: 6
Training loss: 2.8926081272709756
Validation loss: 2.6654910734818227

Epoch: 6| Step: 7
Training loss: 3.0841912459313368
Validation loss: 2.6701966220474804

Epoch: 6| Step: 8
Training loss: 2.9019507325589142
Validation loss: 2.6691396658318993

Epoch: 6| Step: 9
Training loss: 3.485553354036901
Validation loss: 2.6649769639033862

Epoch: 6| Step: 10
Training loss: 2.9560487190743348
Validation loss: 2.6735032153100566

Epoch: 6| Step: 11
Training loss: 1.9574482791347696
Validation loss: 2.67378838092654

Epoch: 6| Step: 12
Training loss: 2.7788813931198266
Validation loss: 2.6791574946640275

Epoch: 6| Step: 13
Training loss: 2.9365231127369293
Validation loss: 2.679166785983204

Epoch: 216| Step: 0
Training loss: 2.1676194468038226
Validation loss: 2.6860424237703695

Epoch: 6| Step: 1
Training loss: 2.493451888925811
Validation loss: 2.6855311564025572

Epoch: 6| Step: 2
Training loss: 3.338298882014488
Validation loss: 2.68098977202923

Epoch: 6| Step: 3
Training loss: 3.3281903327654327
Validation loss: 2.673982041898266

Epoch: 6| Step: 4
Training loss: 3.06532157617377
Validation loss: 2.667023618198578

Epoch: 6| Step: 5
Training loss: 2.8329680899274816
Validation loss: 2.6709233779194204

Epoch: 6| Step: 6
Training loss: 2.8236056304676636
Validation loss: 2.666537769788959

Epoch: 6| Step: 7
Training loss: 3.1857691534670445
Validation loss: 2.658507800625433

Epoch: 6| Step: 8
Training loss: 2.448048581295779
Validation loss: 2.663523398766176

Epoch: 6| Step: 9
Training loss: 3.2455757544924775
Validation loss: 2.659109753762804

Epoch: 6| Step: 10
Training loss: 2.884357978878035
Validation loss: 2.658641918118078

Epoch: 6| Step: 11
Training loss: 3.5614429712684794
Validation loss: 2.6641430042567347

Epoch: 6| Step: 12
Training loss: 3.0004521664959394
Validation loss: 2.665969102385894

Epoch: 6| Step: 13
Training loss: 3.508494831152614
Validation loss: 2.664524765645472

Epoch: 217| Step: 0
Training loss: 2.7973291465260046
Validation loss: 2.664712281675517

Epoch: 6| Step: 1
Training loss: 3.2651115634428964
Validation loss: 2.672111978068144

Epoch: 6| Step: 2
Training loss: 2.6583060890005465
Validation loss: 2.6638364353433714

Epoch: 6| Step: 3
Training loss: 2.540771097297012
Validation loss: 2.6718101759859985

Epoch: 6| Step: 4
Training loss: 2.829554075553159
Validation loss: 2.669066415198088

Epoch: 6| Step: 5
Training loss: 2.423506058314082
Validation loss: 2.686952195041723

Epoch: 6| Step: 6
Training loss: 3.1481177685919435
Validation loss: 2.686015545920449

Epoch: 6| Step: 7
Training loss: 3.0923461811664628
Validation loss: 2.703170766495764

Epoch: 6| Step: 8
Training loss: 2.797829065681806
Validation loss: 2.7058538703274637

Epoch: 6| Step: 9
Training loss: 3.1481357931588607
Validation loss: 2.681185586269706

Epoch: 6| Step: 10
Training loss: 2.988396456623185
Validation loss: 2.660236194030879

Epoch: 6| Step: 11
Training loss: 3.4694888041252825
Validation loss: 2.6636070819933315

Epoch: 6| Step: 12
Training loss: 3.3590272235499676
Validation loss: 2.6621606741021844

Epoch: 6| Step: 13
Training loss: 3.3186809525428185
Validation loss: 2.661797743731604

Epoch: 218| Step: 0
Training loss: 2.414441322800187
Validation loss: 2.675400368498966

Epoch: 6| Step: 1
Training loss: 3.164822560137962
Validation loss: 2.6740287683248667

Epoch: 6| Step: 2
Training loss: 3.0312070548564676
Validation loss: 2.675569750824904

Epoch: 6| Step: 3
Training loss: 2.903615105755762
Validation loss: 2.670216060046525

Epoch: 6| Step: 4
Training loss: 3.727682972849131
Validation loss: 2.6659659771295128

Epoch: 6| Step: 5
Training loss: 2.975528407252763
Validation loss: 2.6636317990584493

Epoch: 6| Step: 6
Training loss: 3.151748317371596
Validation loss: 2.6627792247416164

Epoch: 6| Step: 7
Training loss: 2.341582249469421
Validation loss: 2.6594207871168773

Epoch: 6| Step: 8
Training loss: 3.3289051842838884
Validation loss: 2.657390085850483

Epoch: 6| Step: 9
Training loss: 3.4433325097328327
Validation loss: 2.6687297441697937

Epoch: 6| Step: 10
Training loss: 3.1944758058934295
Validation loss: 2.6678010203219262

Epoch: 6| Step: 11
Training loss: 2.4821099086037006
Validation loss: 2.6701951915065463

Epoch: 6| Step: 12
Training loss: 2.5249809528803278
Validation loss: 2.678442867444041

Epoch: 6| Step: 13
Training loss: 3.100558562871283
Validation loss: 2.6815516699073108

Epoch: 219| Step: 0
Training loss: 3.279274336627804
Validation loss: 2.677780810009073

Epoch: 6| Step: 1
Training loss: 2.595246584133865
Validation loss: 2.6726407849454725

Epoch: 6| Step: 2
Training loss: 2.9492536732203805
Validation loss: 2.6704671101242705

Epoch: 6| Step: 3
Training loss: 3.366964877175118
Validation loss: 2.664349424650535

Epoch: 6| Step: 4
Training loss: 3.4968480495201826
Validation loss: 2.660822675864675

Epoch: 6| Step: 5
Training loss: 2.8063497478879396
Validation loss: 2.6603013617446742

Epoch: 6| Step: 6
Training loss: 2.939372662935295
Validation loss: 2.6604019009935573

Epoch: 6| Step: 7
Training loss: 3.0210882320506562
Validation loss: 2.656135900219607

Epoch: 6| Step: 8
Training loss: 2.540401164537252
Validation loss: 2.655615362203935

Epoch: 6| Step: 9
Training loss: 2.6937745945066602
Validation loss: 2.6563072492786737

Epoch: 6| Step: 10
Training loss: 2.5195478098716935
Validation loss: 2.6588086047627812

Epoch: 6| Step: 11
Training loss: 3.3841282353915343
Validation loss: 2.6573649499199243

Epoch: 6| Step: 12
Training loss: 2.9514043730285966
Validation loss: 2.6583871137844484

Epoch: 6| Step: 13
Training loss: 3.3567632414162514
Validation loss: 2.654166207378132

Epoch: 220| Step: 0
Training loss: 2.907428461508393
Validation loss: 2.661298351891003

Epoch: 6| Step: 1
Training loss: 2.745785691847009
Validation loss: 2.6570837421897378

Epoch: 6| Step: 2
Training loss: 3.3613312459129903
Validation loss: 2.6620222904160884

Epoch: 6| Step: 3
Training loss: 2.9887766707892385
Validation loss: 2.6664420210777693

Epoch: 6| Step: 4
Training loss: 3.3962325035096623
Validation loss: 2.671234062619807

Epoch: 6| Step: 5
Training loss: 2.838112073581999
Validation loss: 2.673548292183719

Epoch: 6| Step: 6
Training loss: 2.3861648741016377
Validation loss: 2.6808673384313164

Epoch: 6| Step: 7
Training loss: 2.3896416530349134
Validation loss: 2.685268350277552

Epoch: 6| Step: 8
Training loss: 3.2301729336672493
Validation loss: 2.684951538324135

Epoch: 6| Step: 9
Training loss: 3.2453973897705186
Validation loss: 2.676171545694858

Epoch: 6| Step: 10
Training loss: 2.991710495339956
Validation loss: 2.6649822990101906

Epoch: 6| Step: 11
Training loss: 2.9034126131056395
Validation loss: 2.6615058357355554

Epoch: 6| Step: 12
Training loss: 3.3542893349782785
Validation loss: 2.6583479527889793

Epoch: 6| Step: 13
Training loss: 2.958576317779381
Validation loss: 2.652727023900879

Epoch: 221| Step: 0
Training loss: 3.5155295125921286
Validation loss: 2.6528946286646238

Epoch: 6| Step: 1
Training loss: 2.8654457227564922
Validation loss: 2.6585977360018225

Epoch: 6| Step: 2
Training loss: 2.873170021472805
Validation loss: 2.6587265986964117

Epoch: 6| Step: 3
Training loss: 3.2656920211704334
Validation loss: 2.6572570030831097

Epoch: 6| Step: 4
Training loss: 2.7896755196626155
Validation loss: 2.6560152648630933

Epoch: 6| Step: 5
Training loss: 2.7698358064319057
Validation loss: 2.6591921548496633

Epoch: 6| Step: 6
Training loss: 3.0244919468499263
Validation loss: 2.6549534267456933

Epoch: 6| Step: 7
Training loss: 2.977124739284002
Validation loss: 2.6534530729202626

Epoch: 6| Step: 8
Training loss: 2.9595135407612547
Validation loss: 2.6517567840882506

Epoch: 6| Step: 9
Training loss: 3.083125201924532
Validation loss: 2.6548370753563226

Epoch: 6| Step: 10
Training loss: 3.1111782346780728
Validation loss: 2.6543235495863926

Epoch: 6| Step: 11
Training loss: 3.6293420766023945
Validation loss: 2.65640427432756

Epoch: 6| Step: 12
Training loss: 1.9452254800598119
Validation loss: 2.655843772444357

Epoch: 6| Step: 13
Training loss: 2.534859238728742
Validation loss: 2.6617060200236415

Epoch: 222| Step: 0
Training loss: 3.17359464285427
Validation loss: 2.65868840309467

Epoch: 6| Step: 1
Training loss: 3.166626143614502
Validation loss: 2.657660091817707

Epoch: 6| Step: 2
Training loss: 2.876261558725009
Validation loss: 2.652857046330492

Epoch: 6| Step: 3
Training loss: 2.791716864594794
Validation loss: 2.656952926985026

Epoch: 6| Step: 4
Training loss: 2.81739872179217
Validation loss: 2.65570480088733

Epoch: 6| Step: 5
Training loss: 2.5428903687757174
Validation loss: 2.660021029208884

Epoch: 6| Step: 6
Training loss: 2.667135038569447
Validation loss: 2.660286119403833

Epoch: 6| Step: 7
Training loss: 2.6232788256064206
Validation loss: 2.6577677107221667

Epoch: 6| Step: 8
Training loss: 3.171220984470908
Validation loss: 2.6699508515509627

Epoch: 6| Step: 9
Training loss: 3.505196664383592
Validation loss: 2.6717926619102186

Epoch: 6| Step: 10
Training loss: 3.2351391760295645
Validation loss: 2.661068520636261

Epoch: 6| Step: 11
Training loss: 2.5665768083308014
Validation loss: 2.666836518472216

Epoch: 6| Step: 12
Training loss: 3.2851463798528897
Validation loss: 2.658786771180327

Epoch: 6| Step: 13
Training loss: 3.311411696820902
Validation loss: 2.6554091636170543

Epoch: 223| Step: 0
Training loss: 2.1033806292641666
Validation loss: 2.6511927333031275

Epoch: 6| Step: 1
Training loss: 3.729370850384454
Validation loss: 2.6533205521178274

Epoch: 6| Step: 2
Training loss: 3.7752941294898013
Validation loss: 2.6512713028341146

Epoch: 6| Step: 3
Training loss: 2.9907937252397723
Validation loss: 2.6498878547372127

Epoch: 6| Step: 4
Training loss: 3.3998400370049295
Validation loss: 2.6548316870297106

Epoch: 6| Step: 5
Training loss: 2.9219533328403577
Validation loss: 2.6563158966904936

Epoch: 6| Step: 6
Training loss: 2.7022491976718874
Validation loss: 2.657330878319498

Epoch: 6| Step: 7
Training loss: 3.033812079185447
Validation loss: 2.660398759560903

Epoch: 6| Step: 8
Training loss: 2.86685802427247
Validation loss: 2.6572862296510427

Epoch: 6| Step: 9
Training loss: 2.681798164868998
Validation loss: 2.66364245732571

Epoch: 6| Step: 10
Training loss: 2.8318559684442257
Validation loss: 2.6657246078001657

Epoch: 6| Step: 11
Training loss: 3.0508204810517743
Validation loss: 2.663322407757574

Epoch: 6| Step: 12
Training loss: 2.336895902366234
Validation loss: 2.6702186599617774

Epoch: 6| Step: 13
Training loss: 2.8042916786325307
Validation loss: 2.6663434969777646

Epoch: 224| Step: 0
Training loss: 2.327176918691115
Validation loss: 2.663659301227856

Epoch: 6| Step: 1
Training loss: 3.029286643428482
Validation loss: 2.660016802123219

Epoch: 6| Step: 2
Training loss: 3.135493855249695
Validation loss: 2.6564244733593942

Epoch: 6| Step: 3
Training loss: 3.1069353970827116
Validation loss: 2.652540689732537

Epoch: 6| Step: 4
Training loss: 2.4362746851352095
Validation loss: 2.6574182922201466

Epoch: 6| Step: 5
Training loss: 2.537959683878889
Validation loss: 2.6492656226530436

Epoch: 6| Step: 6
Training loss: 3.3819838427355644
Validation loss: 2.6541162576819524

Epoch: 6| Step: 7
Training loss: 3.2302944223954086
Validation loss: 2.648006767054874

Epoch: 6| Step: 8
Training loss: 3.083103704063846
Validation loss: 2.653395421001035

Epoch: 6| Step: 9
Training loss: 2.8809653052558426
Validation loss: 2.6501638942240793

Epoch: 6| Step: 10
Training loss: 2.321125440403666
Validation loss: 2.6476211870044857

Epoch: 6| Step: 11
Training loss: 3.461963510092913
Validation loss: 2.654742094357804

Epoch: 6| Step: 12
Training loss: 3.2944798741214387
Validation loss: 2.65141079297087

Epoch: 6| Step: 13
Training loss: 3.441248982156034
Validation loss: 2.6497808939322343

Epoch: 225| Step: 0
Training loss: 3.316340109948543
Validation loss: 2.6670633092836917

Epoch: 6| Step: 1
Training loss: 2.7971339612023627
Validation loss: 2.6611693536244645

Epoch: 6| Step: 2
Training loss: 2.9795626041539642
Validation loss: 2.67199583655281

Epoch: 6| Step: 3
Training loss: 2.5860564328413895
Validation loss: 2.6666548085205415

Epoch: 6| Step: 4
Training loss: 2.8768263281948765
Validation loss: 2.6824299826931846

Epoch: 6| Step: 5
Training loss: 3.3245681596992904
Validation loss: 2.681535518708058

Epoch: 6| Step: 6
Training loss: 3.1884161436656897
Validation loss: 2.6917677330773095

Epoch: 6| Step: 7
Training loss: 2.900043053143006
Validation loss: 2.672792380947257

Epoch: 6| Step: 8
Training loss: 3.499721516020563
Validation loss: 2.6589504000876296

Epoch: 6| Step: 9
Training loss: 2.7804415953109505
Validation loss: 2.6477660998092682

Epoch: 6| Step: 10
Training loss: 2.962761229252621
Validation loss: 2.645561427791216

Epoch: 6| Step: 11
Training loss: 2.7963165919185133
Validation loss: 2.645628372701522

Epoch: 6| Step: 12
Training loss: 2.7087703254475803
Validation loss: 2.6503753556479026

Epoch: 6| Step: 13
Training loss: 3.075577509543844
Validation loss: 2.6482082515407224

Epoch: 226| Step: 0
Training loss: 2.706379425266505
Validation loss: 2.653720751324777

Epoch: 6| Step: 1
Training loss: 3.181859429822811
Validation loss: 2.653773419163617

Epoch: 6| Step: 2
Training loss: 2.945947715196899
Validation loss: 2.655948171532084

Epoch: 6| Step: 3
Training loss: 3.361113626218193
Validation loss: 2.652010657510109

Epoch: 6| Step: 4
Training loss: 2.5304627312744397
Validation loss: 2.6513496776198955

Epoch: 6| Step: 5
Training loss: 3.2895881432145178
Validation loss: 2.653549927952629

Epoch: 6| Step: 6
Training loss: 3.454640879978575
Validation loss: 2.6525820428846583

Epoch: 6| Step: 7
Training loss: 2.381100499223488
Validation loss: 2.649655144136111

Epoch: 6| Step: 8
Training loss: 2.768570016216383
Validation loss: 2.6469303670269464

Epoch: 6| Step: 9
Training loss: 3.3411841128924813
Validation loss: 2.6461451834938545

Epoch: 6| Step: 10
Training loss: 2.9544193721091707
Validation loss: 2.6470673083050675

Epoch: 6| Step: 11
Training loss: 2.756045977941158
Validation loss: 2.643514831582669

Epoch: 6| Step: 12
Training loss: 3.4163515984634443
Validation loss: 2.6444282217815864

Epoch: 6| Step: 13
Training loss: 2.058745000447524
Validation loss: 2.647060034016571

Epoch: 227| Step: 0
Training loss: 3.2371812523601955
Validation loss: 2.652353849531782

Epoch: 6| Step: 1
Training loss: 2.780294189804444
Validation loss: 2.6535485290143312

Epoch: 6| Step: 2
Training loss: 3.138521315471421
Validation loss: 2.649504411056315

Epoch: 6| Step: 3
Training loss: 3.0514091988382814
Validation loss: 2.6485986738293676

Epoch: 6| Step: 4
Training loss: 2.4868784832504587
Validation loss: 2.6569725535358155

Epoch: 6| Step: 5
Training loss: 2.985296616377734
Validation loss: 2.654545161977214

Epoch: 6| Step: 6
Training loss: 2.9956821521995347
Validation loss: 2.6556702282106817

Epoch: 6| Step: 7
Training loss: 2.7360597488393323
Validation loss: 2.6575253401839385

Epoch: 6| Step: 8
Training loss: 3.2506550348849315
Validation loss: 2.6602042774199663

Epoch: 6| Step: 9
Training loss: 3.2094485503834758
Validation loss: 2.665127264376915

Epoch: 6| Step: 10
Training loss: 3.0513532544347615
Validation loss: 2.663828768960249

Epoch: 6| Step: 11
Training loss: 2.9707456607018066
Validation loss: 2.6578335119098586

Epoch: 6| Step: 12
Training loss: 3.0188276450713403
Validation loss: 2.649519082620992

Epoch: 6| Step: 13
Training loss: 2.6240876746824155
Validation loss: 2.6474075194885174

Epoch: 228| Step: 0
Training loss: 3.538760679734856
Validation loss: 2.6421829620726185

Epoch: 6| Step: 1
Training loss: 2.8777924949272946
Validation loss: 2.637947844295381

Epoch: 6| Step: 2
Training loss: 3.081746870296619
Validation loss: 2.6411348294768513

Epoch: 6| Step: 3
Training loss: 2.6478114105442074
Validation loss: 2.6407807851459375

Epoch: 6| Step: 4
Training loss: 2.711978767345661
Validation loss: 2.6420779123320246

Epoch: 6| Step: 5
Training loss: 2.7271397370367194
Validation loss: 2.64018113066493

Epoch: 6| Step: 6
Training loss: 3.5226909244038076
Validation loss: 2.641184045299623

Epoch: 6| Step: 7
Training loss: 2.7409627847632803
Validation loss: 2.6388087503526814

Epoch: 6| Step: 8
Training loss: 2.906793523026748
Validation loss: 2.6521896473878006

Epoch: 6| Step: 9
Training loss: 3.2028464591639425
Validation loss: 2.6424700931505924

Epoch: 6| Step: 10
Training loss: 2.618865884115094
Validation loss: 2.645076811340231

Epoch: 6| Step: 11
Training loss: 2.781823602740241
Validation loss: 2.645625666254906

Epoch: 6| Step: 12
Training loss: 3.0672631105265125
Validation loss: 2.6418574064576013

Epoch: 6| Step: 13
Training loss: 3.1999241164269994
Validation loss: 2.6554549280180817

Epoch: 229| Step: 0
Training loss: 3.363843917301066
Validation loss: 2.654954353727898

Epoch: 6| Step: 1
Training loss: 2.6572434306704587
Validation loss: 2.6497993710215164

Epoch: 6| Step: 2
Training loss: 3.3359189178163664
Validation loss: 2.64812013766641

Epoch: 6| Step: 3
Training loss: 3.326021774587734
Validation loss: 2.653289367801377

Epoch: 6| Step: 4
Training loss: 2.8134745287002367
Validation loss: 2.6496116742560623

Epoch: 6| Step: 5
Training loss: 3.375285101257449
Validation loss: 2.6433244637203166

Epoch: 6| Step: 6
Training loss: 2.516319889740989
Validation loss: 2.641608436452247

Epoch: 6| Step: 7
Training loss: 3.0813151447458655
Validation loss: 2.6431147058932387

Epoch: 6| Step: 8
Training loss: 2.847922146579593
Validation loss: 2.6415139629273887

Epoch: 6| Step: 9
Training loss: 2.4492321835382196
Validation loss: 2.640640111177209

Epoch: 6| Step: 10
Training loss: 2.790615301339617
Validation loss: 2.637887064285482

Epoch: 6| Step: 11
Training loss: 2.490168887006548
Validation loss: 2.6360169686443777

Epoch: 6| Step: 12
Training loss: 3.351979618747995
Validation loss: 2.6404756835226952

Epoch: 6| Step: 13
Training loss: 3.0135106397750775
Validation loss: 2.6359336174483463

Epoch: 230| Step: 0
Training loss: 3.32410800986961
Validation loss: 2.6350709305027813

Epoch: 6| Step: 1
Training loss: 2.373596479404154
Validation loss: 2.639972945814577

Epoch: 6| Step: 2
Training loss: 3.0722808352492206
Validation loss: 2.6372697365867728

Epoch: 6| Step: 3
Training loss: 2.9264179346781214
Validation loss: 2.64473804466256

Epoch: 6| Step: 4
Training loss: 3.4863335959340827
Validation loss: 2.6418080857595023

Epoch: 6| Step: 5
Training loss: 2.546510822494102
Validation loss: 2.641498172529006

Epoch: 6| Step: 6
Training loss: 2.399728036412184
Validation loss: 2.6367809326909453

Epoch: 6| Step: 7
Training loss: 3.056568551965784
Validation loss: 2.6453673995937383

Epoch: 6| Step: 8
Training loss: 2.5965536201004755
Validation loss: 2.6476847228885623

Epoch: 6| Step: 9
Training loss: 3.497909466522301
Validation loss: 2.650384136551742

Epoch: 6| Step: 10
Training loss: 2.819299996929516
Validation loss: 2.64052557280227

Epoch: 6| Step: 11
Training loss: 3.003537317843368
Validation loss: 2.6539494009353115

Epoch: 6| Step: 12
Training loss: 3.077785105262355
Validation loss: 2.6517534255248782

Epoch: 6| Step: 13
Training loss: 3.30906153302868
Validation loss: 2.6536398825808725

Epoch: 231| Step: 0
Training loss: 2.749962199558209
Validation loss: 2.6501031022418777

Epoch: 6| Step: 1
Training loss: 2.9033352581708316
Validation loss: 2.6551843753230213

Epoch: 6| Step: 2
Training loss: 3.01329907468153
Validation loss: 2.658329864453657

Epoch: 6| Step: 3
Training loss: 3.1103380714974294
Validation loss: 2.663562943737809

Epoch: 6| Step: 4
Training loss: 2.7502195097272817
Validation loss: 2.6689841720038023

Epoch: 6| Step: 5
Training loss: 2.8232016519270897
Validation loss: 2.6660814264762274

Epoch: 6| Step: 6
Training loss: 3.71097078007281
Validation loss: 2.6564439870417056

Epoch: 6| Step: 7
Training loss: 3.1484838439711056
Validation loss: 2.642743433624653

Epoch: 6| Step: 8
Training loss: 2.833812747861334
Validation loss: 2.638161350908434

Epoch: 6| Step: 9
Training loss: 2.7146598479192168
Validation loss: 2.638491680501747

Epoch: 6| Step: 10
Training loss: 2.9812071599221506
Validation loss: 2.637231598644753

Epoch: 6| Step: 11
Training loss: 2.9920106043704187
Validation loss: 2.642858421034604

Epoch: 6| Step: 12
Training loss: 2.6710093027150674
Validation loss: 2.642628229727292

Epoch: 6| Step: 13
Training loss: 3.2766295826838805
Validation loss: 2.6429218643201335

Epoch: 232| Step: 0
Training loss: 3.2740214334577473
Validation loss: 2.6478746223618153

Epoch: 6| Step: 1
Training loss: 2.8837662439835454
Validation loss: 2.6390999564053947

Epoch: 6| Step: 2
Training loss: 3.476946794508196
Validation loss: 2.642329964151375

Epoch: 6| Step: 3
Training loss: 3.1862013920353354
Validation loss: 2.632474147072641

Epoch: 6| Step: 4
Training loss: 2.665987275919559
Validation loss: 2.637143615741161

Epoch: 6| Step: 5
Training loss: 2.5367680438215663
Validation loss: 2.6397115835441474

Epoch: 6| Step: 6
Training loss: 3.4885748625381687
Validation loss: 2.637131945321035

Epoch: 6| Step: 7
Training loss: 3.0335454999341773
Validation loss: 2.637866574611696

Epoch: 6| Step: 8
Training loss: 2.333728575156074
Validation loss: 2.6364835400117674

Epoch: 6| Step: 9
Training loss: 2.6645976225524755
Validation loss: 2.637206741076812

Epoch: 6| Step: 10
Training loss: 3.1975167652970122
Validation loss: 2.6410038649510974

Epoch: 6| Step: 11
Training loss: 2.608435364536441
Validation loss: 2.639401541673411

Epoch: 6| Step: 12
Training loss: 2.8467079959462946
Validation loss: 2.646148514297853

Epoch: 6| Step: 13
Training loss: 3.370466366201538
Validation loss: 2.6474042338447283

Epoch: 233| Step: 0
Training loss: 2.8960996180624896
Validation loss: 2.6579881785087047

Epoch: 6| Step: 1
Training loss: 2.9705727853967563
Validation loss: 2.6554220502910324

Epoch: 6| Step: 2
Training loss: 3.104726873108809
Validation loss: 2.6639325981693536

Epoch: 6| Step: 3
Training loss: 2.542703125378064
Validation loss: 2.679720573660073

Epoch: 6| Step: 4
Training loss: 2.896204332329978
Validation loss: 2.6825656048895667

Epoch: 6| Step: 5
Training loss: 3.003472543666188
Validation loss: 2.7121346867495757

Epoch: 6| Step: 6
Training loss: 2.820352062676979
Validation loss: 2.6898969591055404

Epoch: 6| Step: 7
Training loss: 3.429929824645068
Validation loss: 2.6773593700105094

Epoch: 6| Step: 8
Training loss: 2.655586518843572
Validation loss: 2.666385747997425

Epoch: 6| Step: 9
Training loss: 2.794461023708311
Validation loss: 2.6560199075700996

Epoch: 6| Step: 10
Training loss: 3.4870931517944848
Validation loss: 2.654713285931342

Epoch: 6| Step: 11
Training loss: 2.3572971718713047
Validation loss: 2.6424335990489927

Epoch: 6| Step: 12
Training loss: 3.5711137469359175
Validation loss: 2.6390413614454724

Epoch: 6| Step: 13
Training loss: 2.9577718031673466
Validation loss: 2.6365537617791546

Epoch: 234| Step: 0
Training loss: 2.7168389981457683
Validation loss: 2.6408114783997627

Epoch: 6| Step: 1
Training loss: 3.1731501679758853
Validation loss: 2.631686825681055

Epoch: 6| Step: 2
Training loss: 3.4150661503429567
Validation loss: 2.6321891825068224

Epoch: 6| Step: 3
Training loss: 2.567559434598411
Validation loss: 2.635531957529079

Epoch: 6| Step: 4
Training loss: 2.461037479367902
Validation loss: 2.635424132950386

Epoch: 6| Step: 5
Training loss: 3.21810758531533
Validation loss: 2.6309042041853714

Epoch: 6| Step: 6
Training loss: 2.3954323695697646
Validation loss: 2.633769451049499

Epoch: 6| Step: 7
Training loss: 3.440114639501154
Validation loss: 2.629488642204604

Epoch: 6| Step: 8
Training loss: 2.614184122397169
Validation loss: 2.6309481361433877

Epoch: 6| Step: 9
Training loss: 3.1435593898011582
Validation loss: 2.628108531350193

Epoch: 6| Step: 10
Training loss: 3.193211692638223
Validation loss: 2.6303517175313766

Epoch: 6| Step: 11
Training loss: 2.610085944445151
Validation loss: 2.631354391850599

Epoch: 6| Step: 12
Training loss: 3.105962826753849
Validation loss: 2.6278370079722486

Epoch: 6| Step: 13
Training loss: 3.554668317470563
Validation loss: 2.6330415554195357

Epoch: 235| Step: 0
Training loss: 2.9210169547169103
Validation loss: 2.628749913280825

Epoch: 6| Step: 1
Training loss: 2.559885598696134
Validation loss: 2.635382687123724

Epoch: 6| Step: 2
Training loss: 3.2049034577824735
Validation loss: 2.63832518431231

Epoch: 6| Step: 3
Training loss: 2.79986046375272
Validation loss: 2.6434464501986508

Epoch: 6| Step: 4
Training loss: 2.453404210231269
Validation loss: 2.6485647720952885

Epoch: 6| Step: 5
Training loss: 2.37609918154875
Validation loss: 2.6564987201290573

Epoch: 6| Step: 6
Training loss: 2.50619464156735
Validation loss: 2.6589285946660812

Epoch: 6| Step: 7
Training loss: 3.2168463846182407
Validation loss: 2.6403407966769725

Epoch: 6| Step: 8
Training loss: 3.4710583953121548
Validation loss: 2.6311235078221022

Epoch: 6| Step: 9
Training loss: 3.236227343595254
Validation loss: 2.6377151396847993

Epoch: 6| Step: 10
Training loss: 3.4006034876474787
Validation loss: 2.6436046398925637

Epoch: 6| Step: 11
Training loss: 2.8011981648488278
Validation loss: 2.6587310042883088

Epoch: 6| Step: 12
Training loss: 3.5802677851426252
Validation loss: 2.6449241090088917

Epoch: 6| Step: 13
Training loss: 2.681160835971003
Validation loss: 2.6480112185577482

Epoch: 236| Step: 0
Training loss: 2.7614989456265917
Validation loss: 2.6497646584067236

Epoch: 6| Step: 1
Training loss: 3.4465087751406616
Validation loss: 2.6391627338188863

Epoch: 6| Step: 2
Training loss: 2.7157658829047677
Validation loss: 2.6396981666293575

Epoch: 6| Step: 3
Training loss: 3.3560754940194086
Validation loss: 2.638678376703436

Epoch: 6| Step: 4
Training loss: 2.8726979866554334
Validation loss: 2.6336999707530198

Epoch: 6| Step: 5
Training loss: 2.822409402425506
Validation loss: 2.6351589573149994

Epoch: 6| Step: 6
Training loss: 3.0663914771240486
Validation loss: 2.637286390231292

Epoch: 6| Step: 7
Training loss: 2.930013328235504
Validation loss: 2.630592118542291

Epoch: 6| Step: 8
Training loss: 3.381825080521484
Validation loss: 2.6317033354134365

Epoch: 6| Step: 9
Training loss: 3.011150934942141
Validation loss: 2.639821963851322

Epoch: 6| Step: 10
Training loss: 3.068328760141269
Validation loss: 2.6323774865756917

Epoch: 6| Step: 11
Training loss: 2.662207441419831
Validation loss: 2.632668701911016

Epoch: 6| Step: 12
Training loss: 3.0444299521955966
Validation loss: 2.6352126469634776

Epoch: 6| Step: 13
Training loss: 1.5574879177108591
Validation loss: 2.6325168608557203

Epoch: 237| Step: 0
Training loss: 3.546859405079978
Validation loss: 2.6322959246335342

Epoch: 6| Step: 1
Training loss: 2.9080593260599548
Validation loss: 2.6319251878026932

Epoch: 6| Step: 2
Training loss: 2.9404632556307932
Validation loss: 2.638117432175825

Epoch: 6| Step: 3
Training loss: 2.4882823997985963
Validation loss: 2.6350832667502764

Epoch: 6| Step: 4
Training loss: 3.458752357804708
Validation loss: 2.637776585516468

Epoch: 6| Step: 5
Training loss: 2.5701792952043387
Validation loss: 2.6339981828492185

Epoch: 6| Step: 6
Training loss: 2.7630109771830766
Validation loss: 2.6329709439858604

Epoch: 6| Step: 7
Training loss: 2.599253870202504
Validation loss: 2.6397464225296687

Epoch: 6| Step: 8
Training loss: 2.9240968793482978
Validation loss: 2.632762136410039

Epoch: 6| Step: 9
Training loss: 3.2225171608242276
Validation loss: 2.632396446157444

Epoch: 6| Step: 10
Training loss: 2.6046968657857823
Validation loss: 2.637122825733967

Epoch: 6| Step: 11
Training loss: 3.2501387933291896
Validation loss: 2.63719252498176

Epoch: 6| Step: 12
Training loss: 2.9431583206775898
Validation loss: 2.63180902914681

Epoch: 6| Step: 13
Training loss: 3.2989783063708926
Validation loss: 2.6312654125282604

Epoch: 238| Step: 0
Training loss: 3.1845873820839676
Validation loss: 2.638882074381462

Epoch: 6| Step: 1
Training loss: 2.5972314472907296
Validation loss: 2.637621538512847

Epoch: 6| Step: 2
Training loss: 2.224553215516993
Validation loss: 2.633197917730122

Epoch: 6| Step: 3
Training loss: 3.206274949361536
Validation loss: 2.6352774742872134

Epoch: 6| Step: 4
Training loss: 3.644627282614068
Validation loss: 2.6282904472548054

Epoch: 6| Step: 5
Training loss: 2.3478575253646934
Validation loss: 2.644016497324987

Epoch: 6| Step: 6
Training loss: 3.0134935505508262
Validation loss: 2.6361760524766558

Epoch: 6| Step: 7
Training loss: 3.3461147039604824
Validation loss: 2.631313875688816

Epoch: 6| Step: 8
Training loss: 2.6288620830300355
Validation loss: 2.641253881972108

Epoch: 6| Step: 9
Training loss: 2.6901784457611435
Validation loss: 2.638287488206499

Epoch: 6| Step: 10
Training loss: 2.9905177305429733
Validation loss: 2.635376519707991

Epoch: 6| Step: 11
Training loss: 3.6615362832827953
Validation loss: 2.6308329127056314

Epoch: 6| Step: 12
Training loss: 2.9001244419627286
Validation loss: 2.6328356969962954

Epoch: 6| Step: 13
Training loss: 2.5883839263032575
Validation loss: 2.634165023578604

Epoch: 239| Step: 0
Training loss: 3.303733309163464
Validation loss: 2.631866393169061

Epoch: 6| Step: 1
Training loss: 2.360067707965524
Validation loss: 2.6309703956315666

Epoch: 6| Step: 2
Training loss: 3.2794640903429073
Validation loss: 2.6344519921643625

Epoch: 6| Step: 3
Training loss: 2.841211380568124
Validation loss: 2.629470638571015

Epoch: 6| Step: 4
Training loss: 2.560059199095747
Validation loss: 2.6288232945522343

Epoch: 6| Step: 5
Training loss: 3.1023323391253252
Validation loss: 2.62731264497057

Epoch: 6| Step: 6
Training loss: 2.940452552790125
Validation loss: 2.6242473263495487

Epoch: 6| Step: 7
Training loss: 2.717956251711617
Validation loss: 2.6245026456652685

Epoch: 6| Step: 8
Training loss: 3.1526816563977587
Validation loss: 2.6239943094041767

Epoch: 6| Step: 9
Training loss: 2.983976647119444
Validation loss: 2.627007683036729

Epoch: 6| Step: 10
Training loss: 3.1399274212655666
Validation loss: 2.625528975676896

Epoch: 6| Step: 11
Training loss: 3.109429593781091
Validation loss: 2.625987479036884

Epoch: 6| Step: 12
Training loss: 3.1688825651048953
Validation loss: 2.628217530041882

Epoch: 6| Step: 13
Training loss: 2.5436476403339103
Validation loss: 2.6281606287275876

Epoch: 240| Step: 0
Training loss: 2.282836989128463
Validation loss: 2.6254350015649153

Epoch: 6| Step: 1
Training loss: 3.549121968391759
Validation loss: 2.634085341355774

Epoch: 6| Step: 2
Training loss: 3.668983782154587
Validation loss: 2.6349062496877833

Epoch: 6| Step: 3
Training loss: 2.887024322565869
Validation loss: 2.64459505690514

Epoch: 6| Step: 4
Training loss: 2.7894692858933112
Validation loss: 2.642309463329182

Epoch: 6| Step: 5
Training loss: 3.0800536643963725
Validation loss: 2.643801340930068

Epoch: 6| Step: 6
Training loss: 2.7698658470692217
Validation loss: 2.6475808035794404

Epoch: 6| Step: 7
Training loss: 2.8168885642081234
Validation loss: 2.643658857195851

Epoch: 6| Step: 8
Training loss: 3.6237767227308657
Validation loss: 2.6528717814945675

Epoch: 6| Step: 9
Training loss: 2.5467692160139346
Validation loss: 2.6441769982385317

Epoch: 6| Step: 10
Training loss: 2.766672227080246
Validation loss: 2.6453334031472004

Epoch: 6| Step: 11
Training loss: 2.3860674529793235
Validation loss: 2.647495522966922

Epoch: 6| Step: 12
Training loss: 2.8583959352034656
Validation loss: 2.649606696189431

Epoch: 6| Step: 13
Training loss: 3.096468261122447
Validation loss: 2.649105978750692

Epoch: 241| Step: 0
Training loss: 2.969823061106878
Validation loss: 2.6320597033479936

Epoch: 6| Step: 1
Training loss: 2.3650630066686795
Validation loss: 2.6286550956296364

Epoch: 6| Step: 2
Training loss: 2.3245333418593446
Validation loss: 2.632325653802498

Epoch: 6| Step: 3
Training loss: 3.221884525259092
Validation loss: 2.630623120708972

Epoch: 6| Step: 4
Training loss: 3.4987758130439577
Validation loss: 2.622467915624067

Epoch: 6| Step: 5
Training loss: 3.1526846813586102
Validation loss: 2.6319097835603293

Epoch: 6| Step: 6
Training loss: 2.2950884040311204
Validation loss: 2.6306303897734495

Epoch: 6| Step: 7
Training loss: 3.469856429414201
Validation loss: 2.6281549584276345

Epoch: 6| Step: 8
Training loss: 3.3050614814983965
Validation loss: 2.6265511712668164

Epoch: 6| Step: 9
Training loss: 2.979765842890107
Validation loss: 2.6246660198804

Epoch: 6| Step: 10
Training loss: 2.694187626173585
Validation loss: 2.631692471810769

Epoch: 6| Step: 11
Training loss: 3.0705895529420273
Validation loss: 2.6293509511498834

Epoch: 6| Step: 12
Training loss: 3.0294105218245364
Validation loss: 2.6348667980834937

Epoch: 6| Step: 13
Training loss: 2.502871676043241
Validation loss: 2.6334688085466884

Epoch: 242| Step: 0
Training loss: 2.9821411080595945
Validation loss: 2.6538618805030496

Epoch: 6| Step: 1
Training loss: 2.3962704688179515
Validation loss: 2.676678942326554

Epoch: 6| Step: 2
Training loss: 2.7876829694561396
Validation loss: 2.7111783834526304

Epoch: 6| Step: 3
Training loss: 3.4417935000887865
Validation loss: 2.696883013366681

Epoch: 6| Step: 4
Training loss: 2.7818729688765123
Validation loss: 2.6776763392016885

Epoch: 6| Step: 5
Training loss: 2.7802252435342636
Validation loss: 2.650632976704296

Epoch: 6| Step: 6
Training loss: 3.1889719836684156
Validation loss: 2.6349624653547337

Epoch: 6| Step: 7
Training loss: 2.7664733275302034
Validation loss: 2.6259952676096865

Epoch: 6| Step: 8
Training loss: 3.278951366551353
Validation loss: 2.6210110358519016

Epoch: 6| Step: 9
Training loss: 2.9599250129274086
Validation loss: 2.6170390474364176

Epoch: 6| Step: 10
Training loss: 3.2873690270852247
Validation loss: 2.6236030975326363

Epoch: 6| Step: 11
Training loss: 3.112026138696018
Validation loss: 2.6217490934966867

Epoch: 6| Step: 12
Training loss: 2.7850985527750063
Validation loss: 2.6204349123880144

Epoch: 6| Step: 13
Training loss: 3.126477616972287
Validation loss: 2.6217449171558225

Epoch: 243| Step: 0
Training loss: 3.1232224558796853
Validation loss: 2.6267470197560874

Epoch: 6| Step: 1
Training loss: 3.104127683117385
Validation loss: 2.630799504117351

Epoch: 6| Step: 2
Training loss: 3.2013278292452796
Validation loss: 2.6267019361346913

Epoch: 6| Step: 3
Training loss: 2.860635448367553
Validation loss: 2.6335612120057355

Epoch: 6| Step: 4
Training loss: 2.522286072686979
Validation loss: 2.6297182162361024

Epoch: 6| Step: 5
Training loss: 2.4591875908880425
Validation loss: 2.637991167213118

Epoch: 6| Step: 6
Training loss: 3.237142217595402
Validation loss: 2.6333438131119453

Epoch: 6| Step: 7
Training loss: 2.7017198559817963
Validation loss: 2.633979146226979

Epoch: 6| Step: 8
Training loss: 3.0390692468092686
Validation loss: 2.6396117917260624

Epoch: 6| Step: 9
Training loss: 2.549500592264786
Validation loss: 2.6374359572535226

Epoch: 6| Step: 10
Training loss: 2.4842233671542178
Validation loss: 2.6389175878352003

Epoch: 6| Step: 11
Training loss: 3.363691386913925
Validation loss: 2.6372145674788183

Epoch: 6| Step: 12
Training loss: 3.4230946496687498
Validation loss: 2.6402872676245512

Epoch: 6| Step: 13
Training loss: 3.2934998505949777
Validation loss: 2.646366343457995

Epoch: 244| Step: 0
Training loss: 2.9773713862573645
Validation loss: 2.647077353395397

Epoch: 6| Step: 1
Training loss: 2.468775785287364
Validation loss: 2.6549183537499554

Epoch: 6| Step: 2
Training loss: 3.464930175253863
Validation loss: 2.6454037204570673

Epoch: 6| Step: 3
Training loss: 2.9634638252605563
Validation loss: 2.645713317670938

Epoch: 6| Step: 4
Training loss: 2.9780282644310145
Validation loss: 2.656698526133848

Epoch: 6| Step: 5
Training loss: 3.597836103717264
Validation loss: 2.642039313027683

Epoch: 6| Step: 6
Training loss: 2.7528639532159542
Validation loss: 2.6452122945242635

Epoch: 6| Step: 7
Training loss: 3.033751566493161
Validation loss: 2.6338365350770685

Epoch: 6| Step: 8
Training loss: 2.587796836449075
Validation loss: 2.6451064705201603

Epoch: 6| Step: 9
Training loss: 2.7374289760346713
Validation loss: 2.6409636123419364

Epoch: 6| Step: 10
Training loss: 2.461655478722165
Validation loss: 2.6331249426675263

Epoch: 6| Step: 11
Training loss: 3.160957527191483
Validation loss: 2.640613819711978

Epoch: 6| Step: 12
Training loss: 3.1267140074875956
Validation loss: 2.6230007147380796

Epoch: 6| Step: 13
Training loss: 2.7721136667746067
Validation loss: 2.6223166912746882

Epoch: 245| Step: 0
Training loss: 2.8353033696694756
Validation loss: 2.628135031806006

Epoch: 6| Step: 1
Training loss: 3.0391462848950215
Validation loss: 2.624426398670213

Epoch: 6| Step: 2
Training loss: 3.0412461151211123
Validation loss: 2.6240121767067675

Epoch: 6| Step: 3
Training loss: 2.690542938008894
Validation loss: 2.626173496410722

Epoch: 6| Step: 4
Training loss: 2.999720560410879
Validation loss: 2.6217575771880597

Epoch: 6| Step: 5
Training loss: 3.117209986555407
Validation loss: 2.6205055710590996

Epoch: 6| Step: 6
Training loss: 2.9373735441219457
Validation loss: 2.6216180259728037

Epoch: 6| Step: 7
Training loss: 3.3339643516900184
Validation loss: 2.6201042269851014

Epoch: 6| Step: 8
Training loss: 3.226426387252751
Validation loss: 2.6214800242038576

Epoch: 6| Step: 9
Training loss: 2.7370413722631644
Validation loss: 2.6238016615159028

Epoch: 6| Step: 10
Training loss: 2.4518952415577893
Validation loss: 2.631343340721613

Epoch: 6| Step: 11
Training loss: 3.078106410556177
Validation loss: 2.626306139520635

Epoch: 6| Step: 12
Training loss: 2.6942031125231707
Validation loss: 2.6324112101505737

Epoch: 6| Step: 13
Training loss: 3.2487432544222847
Validation loss: 2.620793569692166

Epoch: 246| Step: 0
Training loss: 2.443141082843455
Validation loss: 2.6346966925183777

Epoch: 6| Step: 1
Training loss: 3.294505637424154
Validation loss: 2.62617559912013

Epoch: 6| Step: 2
Training loss: 3.3624619605880106
Validation loss: 2.641232661331126

Epoch: 6| Step: 3
Training loss: 2.88643429068266
Validation loss: 2.6432525916612115

Epoch: 6| Step: 4
Training loss: 3.2587864286773893
Validation loss: 2.6468684973547694

Epoch: 6| Step: 5
Training loss: 2.917113642276064
Validation loss: 2.627342192930662

Epoch: 6| Step: 6
Training loss: 2.2902989091650796
Validation loss: 2.6204122072907237

Epoch: 6| Step: 7
Training loss: 3.431420933091152
Validation loss: 2.622593166461838

Epoch: 6| Step: 8
Training loss: 2.8273370814923346
Validation loss: 2.620267448864979

Epoch: 6| Step: 9
Training loss: 3.0691047603244486
Validation loss: 2.6159384114640702

Epoch: 6| Step: 10
Training loss: 2.629342256980955
Validation loss: 2.6182032233296284

Epoch: 6| Step: 11
Training loss: 3.22844443499476
Validation loss: 2.617087509554457

Epoch: 6| Step: 12
Training loss: 2.3590038083358236
Validation loss: 2.6130941108072308

Epoch: 6| Step: 13
Training loss: 3.2877905191484955
Validation loss: 2.6149582786230146

Epoch: 247| Step: 0
Training loss: 2.8308931576352876
Validation loss: 2.6132270558071125

Epoch: 6| Step: 1
Training loss: 2.6370566370599184
Validation loss: 2.616556286474212

Epoch: 6| Step: 2
Training loss: 2.8476790229713553
Validation loss: 2.6161885112765595

Epoch: 6| Step: 3
Training loss: 2.5739892327617717
Validation loss: 2.6207650904407442

Epoch: 6| Step: 4
Training loss: 2.916857813066648
Validation loss: 2.6213707903482506

Epoch: 6| Step: 5
Training loss: 2.9492058153689866
Validation loss: 2.6327042018023694

Epoch: 6| Step: 6
Training loss: 3.472362115373096
Validation loss: 2.62948277246422

Epoch: 6| Step: 7
Training loss: 2.6752894485598078
Validation loss: 2.617074510525729

Epoch: 6| Step: 8
Training loss: 2.927817599874064
Validation loss: 2.632214590989825

Epoch: 6| Step: 9
Training loss: 3.0592296031968056
Validation loss: 2.6257861493978036

Epoch: 6| Step: 10
Training loss: 3.2652448953148054
Validation loss: 2.632343570710384

Epoch: 6| Step: 11
Training loss: 3.1586376261677094
Validation loss: 2.6319549469714776

Epoch: 6| Step: 12
Training loss: 2.6790001880265497
Validation loss: 2.639569966827669

Epoch: 6| Step: 13
Training loss: 3.4599822988773976
Validation loss: 2.6286130008172437

Epoch: 248| Step: 0
Training loss: 3.062203217742567
Validation loss: 2.620918278444333

Epoch: 6| Step: 1
Training loss: 2.8029220252403806
Validation loss: 2.644081760352551

Epoch: 6| Step: 2
Training loss: 3.1609383689136226
Validation loss: 2.643322524980075

Epoch: 6| Step: 3
Training loss: 2.9581090457049988
Validation loss: 2.6376521120471024

Epoch: 6| Step: 4
Training loss: 2.862565891890106
Validation loss: 2.628096335022355

Epoch: 6| Step: 5
Training loss: 2.5637632838164985
Validation loss: 2.6143916171351824

Epoch: 6| Step: 6
Training loss: 3.020455242480208
Validation loss: 2.6249466102979615

Epoch: 6| Step: 7
Training loss: 2.486402823621357
Validation loss: 2.620018991852234

Epoch: 6| Step: 8
Training loss: 3.0542884819714584
Validation loss: 2.6290204345273183

Epoch: 6| Step: 9
Training loss: 3.0088793955524338
Validation loss: 2.6258150193942695

Epoch: 6| Step: 10
Training loss: 2.875051746731999
Validation loss: 2.6267964065781046

Epoch: 6| Step: 11
Training loss: 3.0589371801424927
Validation loss: 2.6161231580131954

Epoch: 6| Step: 12
Training loss: 3.7110284733914756
Validation loss: 2.6191886214799034

Epoch: 6| Step: 13
Training loss: 2.337058726391056
Validation loss: 2.6211511059680164

Epoch: 249| Step: 0
Training loss: 2.71568406088007
Validation loss: 2.6147643022048865

Epoch: 6| Step: 1
Training loss: 2.9451765034086614
Validation loss: 2.6218842054374107

Epoch: 6| Step: 2
Training loss: 2.807317579122688
Validation loss: 2.61268072384899

Epoch: 6| Step: 3
Training loss: 3.357693131403293
Validation loss: 2.6127109730314806

Epoch: 6| Step: 4
Training loss: 2.6846855863187584
Validation loss: 2.6156488118826493

Epoch: 6| Step: 5
Training loss: 3.3229465941672895
Validation loss: 2.6119423440417564

Epoch: 6| Step: 6
Training loss: 3.0060186412078456
Validation loss: 2.6144306932686825

Epoch: 6| Step: 7
Training loss: 3.106461890379374
Validation loss: 2.6124569781349116

Epoch: 6| Step: 8
Training loss: 3.1840807957581756
Validation loss: 2.6142748323982743

Epoch: 6| Step: 9
Training loss: 3.4604717828233764
Validation loss: 2.6105047350371664

Epoch: 6| Step: 10
Training loss: 2.7943907205697887
Validation loss: 2.614379955958552

Epoch: 6| Step: 11
Training loss: 2.644322622344422
Validation loss: 2.6106407677110557

Epoch: 6| Step: 12
Training loss: 1.8473510490117768
Validation loss: 2.622560773650291

Epoch: 6| Step: 13
Training loss: 3.292624676196906
Validation loss: 2.617769208827457

Epoch: 250| Step: 0
Training loss: 2.8289977355171274
Validation loss: 2.6171392934391284

Epoch: 6| Step: 1
Training loss: 1.807665329121559
Validation loss: 2.6238845060620672

Epoch: 6| Step: 2
Training loss: 3.350012218396124
Validation loss: 2.616341179435902

Epoch: 6| Step: 3
Training loss: 2.9736586295574683
Validation loss: 2.620054319695812

Epoch: 6| Step: 4
Training loss: 2.1435928376089723
Validation loss: 2.6244033295518068

Epoch: 6| Step: 5
Training loss: 3.553411166595315
Validation loss: 2.625363852075228

Epoch: 6| Step: 6
Training loss: 2.8135518120577236
Validation loss: 2.629153130973297

Epoch: 6| Step: 7
Training loss: 2.9473588143815967
Validation loss: 2.6277855344099375

Epoch: 6| Step: 8
Training loss: 2.810932655181866
Validation loss: 2.6469265819954653

Epoch: 6| Step: 9
Training loss: 2.9468510906912155
Validation loss: 2.6503897147997337

Epoch: 6| Step: 10
Training loss: 3.1327931696040943
Validation loss: 2.6560545432595712

Epoch: 6| Step: 11
Training loss: 3.223291544861977
Validation loss: 2.645514504780307

Epoch: 6| Step: 12
Training loss: 2.60494445375467
Validation loss: 2.6347043307979083

Epoch: 6| Step: 13
Training loss: 4.126594004281482
Validation loss: 2.6282100748244415

Epoch: 251| Step: 0
Training loss: 3.2733329082522404
Validation loss: 2.618961222586933

Epoch: 6| Step: 1
Training loss: 2.9862791048645936
Validation loss: 2.6093689145547834

Epoch: 6| Step: 2
Training loss: 2.700461072760199
Validation loss: 2.611711697295611

Epoch: 6| Step: 3
Training loss: 3.2003581681078765
Validation loss: 2.608427466526923

Epoch: 6| Step: 4
Training loss: 2.9777462825564585
Validation loss: 2.606716153998181

Epoch: 6| Step: 5
Training loss: 3.3699157000222346
Validation loss: 2.6105825051963327

Epoch: 6| Step: 6
Training loss: 2.3740292623206
Validation loss: 2.6090487671122644

Epoch: 6| Step: 7
Training loss: 2.9166555858583227
Validation loss: 2.607947869236312

Epoch: 6| Step: 8
Training loss: 2.6844516587774474
Validation loss: 2.61040335724829

Epoch: 6| Step: 9
Training loss: 2.8359664200918657
Validation loss: 2.6071358025160425

Epoch: 6| Step: 10
Training loss: 3.4863921343913815
Validation loss: 2.6082782804682667

Epoch: 6| Step: 11
Training loss: 3.0562097215241097
Validation loss: 2.606808071901685

Epoch: 6| Step: 12
Training loss: 2.4151944466414896
Validation loss: 2.6056694101945346

Epoch: 6| Step: 13
Training loss: 3.046628188871761
Validation loss: 2.611437394105132

Epoch: 252| Step: 0
Training loss: 3.874586144773907
Validation loss: 2.6125671950370175

Epoch: 6| Step: 1
Training loss: 3.09947676395987
Validation loss: 2.6093194945942506

Epoch: 6| Step: 2
Training loss: 2.1902962387598146
Validation loss: 2.62435709985826

Epoch: 6| Step: 3
Training loss: 2.936358940406349
Validation loss: 2.6253096285096014

Epoch: 6| Step: 4
Training loss: 3.2988409896970143
Validation loss: 2.6412494676114013

Epoch: 6| Step: 5
Training loss: 3.2107878044485147
Validation loss: 2.6431502468601202

Epoch: 6| Step: 6
Training loss: 2.371079169893136
Validation loss: 2.6623257913713663

Epoch: 6| Step: 7
Training loss: 2.8846327248076573
Validation loss: 2.652535393873009

Epoch: 6| Step: 8
Training loss: 2.93268108774663
Validation loss: 2.6494516312617185

Epoch: 6| Step: 9
Training loss: 2.6840194519975396
Validation loss: 2.6473658022583866

Epoch: 6| Step: 10
Training loss: 3.14465119506295
Validation loss: 2.6272744229881253

Epoch: 6| Step: 11
Training loss: 2.968002385819702
Validation loss: 2.62120616815968

Epoch: 6| Step: 12
Training loss: 2.334031976828909
Validation loss: 2.6211631820356414

Epoch: 6| Step: 13
Training loss: 3.0496558386066703
Validation loss: 2.613974943923916

Epoch: 253| Step: 0
Training loss: 3.2465975630949915
Validation loss: 2.610173473198263

Epoch: 6| Step: 1
Training loss: 2.8844882467569026
Validation loss: 2.6107908232972767

Epoch: 6| Step: 2
Training loss: 3.1418041843365803
Validation loss: 2.6040771672446037

Epoch: 6| Step: 3
Training loss: 3.2874089159513256
Validation loss: 2.6053326155422374

Epoch: 6| Step: 4
Training loss: 3.2459502297450484
Validation loss: 2.6116408399686537

Epoch: 6| Step: 5
Training loss: 2.811604505604417
Validation loss: 2.6046154385349727

Epoch: 6| Step: 6
Training loss: 2.573856866664202
Validation loss: 2.6128753416031207

Epoch: 6| Step: 7
Training loss: 2.181055439576301
Validation loss: 2.6045666410040567

Epoch: 6| Step: 8
Training loss: 3.1691356537115882
Validation loss: 2.6016520202364872

Epoch: 6| Step: 9
Training loss: 3.1677354380986635
Validation loss: 2.6051392115379537

Epoch: 6| Step: 10
Training loss: 2.585619581335345
Validation loss: 2.619571995023076

Epoch: 6| Step: 11
Training loss: 2.8056939744533245
Validation loss: 2.6162947465326716

Epoch: 6| Step: 12
Training loss: 2.9450871308006854
Validation loss: 2.61643400651685

Epoch: 6| Step: 13
Training loss: 3.1257042663445516
Validation loss: 2.618455895201027

Epoch: 254| Step: 0
Training loss: 2.6800402528672076
Validation loss: 2.614429693083841

Epoch: 6| Step: 1
Training loss: 3.1086495478114604
Validation loss: 2.6188837276719523

Epoch: 6| Step: 2
Training loss: 2.5186614671770946
Validation loss: 2.611173086260706

Epoch: 6| Step: 3
Training loss: 3.0948613800411033
Validation loss: 2.6139535371336917

Epoch: 6| Step: 4
Training loss: 3.449960907424365
Validation loss: 2.6129430219097736

Epoch: 6| Step: 5
Training loss: 2.8787845083761487
Validation loss: 2.616622616509642

Epoch: 6| Step: 6
Training loss: 3.001827954652954
Validation loss: 2.623840871084033

Epoch: 6| Step: 7
Training loss: 2.3579069711454723
Validation loss: 2.6295339344571573

Epoch: 6| Step: 8
Training loss: 2.9113950409717204
Validation loss: 2.6402478187467255

Epoch: 6| Step: 9
Training loss: 3.19712513292811
Validation loss: 2.6317112444230744

Epoch: 6| Step: 10
Training loss: 2.9425246099773346
Validation loss: 2.632998572655735

Epoch: 6| Step: 11
Training loss: 3.0052095321749848
Validation loss: 2.6213084660599284

Epoch: 6| Step: 12
Training loss: 3.3002582564590566
Validation loss: 2.62140302916551

Epoch: 6| Step: 13
Training loss: 2.4167288958550546
Validation loss: 2.6091043922560977

Epoch: 255| Step: 0
Training loss: 3.308104567861962
Validation loss: 2.6076999067637265

Epoch: 6| Step: 1
Training loss: 2.7079376420711663
Validation loss: 2.604894143824014

Epoch: 6| Step: 2
Training loss: 3.1034523229462994
Validation loss: 2.603820994087475

Epoch: 6| Step: 3
Training loss: 2.739621344666467
Validation loss: 2.603845136584496

Epoch: 6| Step: 4
Training loss: 3.0918482320138434
Validation loss: 2.604445039370755

Epoch: 6| Step: 5
Training loss: 3.02740832844428
Validation loss: 2.6029222290338083

Epoch: 6| Step: 6
Training loss: 2.8675782979370945
Validation loss: 2.6027246912127415

Epoch: 6| Step: 7
Training loss: 2.640181193780539
Validation loss: 2.5998797700074987

Epoch: 6| Step: 8
Training loss: 3.0477112233890984
Validation loss: 2.5980242764324095

Epoch: 6| Step: 9
Training loss: 3.4358887103868154
Validation loss: 2.598689109461667

Epoch: 6| Step: 10
Training loss: 2.8415512136086067
Validation loss: 2.600732270480433

Epoch: 6| Step: 11
Training loss: 2.4134622463373754
Validation loss: 2.6013477782137078

Epoch: 6| Step: 12
Training loss: 2.912495127661563
Validation loss: 2.6034883648605835

Epoch: 6| Step: 13
Training loss: 3.097129748170385
Validation loss: 2.607246331873304

Epoch: 256| Step: 0
Training loss: 2.635449998566903
Validation loss: 2.6047213259441833

Epoch: 6| Step: 1
Training loss: 2.6612370965805185
Validation loss: 2.6076530339021544

Epoch: 6| Step: 2
Training loss: 3.2311283346915487
Validation loss: 2.6084645661280277

Epoch: 6| Step: 3
Training loss: 3.357184401142047
Validation loss: 2.6124704319153587

Epoch: 6| Step: 4
Training loss: 2.884727441616374
Validation loss: 2.6103682886852417

Epoch: 6| Step: 5
Training loss: 2.6901824339085185
Validation loss: 2.6188351695753544

Epoch: 6| Step: 6
Training loss: 3.158384904130071
Validation loss: 2.6213846032605903

Epoch: 6| Step: 7
Training loss: 2.412311795656376
Validation loss: 2.6245175390462783

Epoch: 6| Step: 8
Training loss: 3.0106121558544396
Validation loss: 2.6371046895122903

Epoch: 6| Step: 9
Training loss: 2.332106188108407
Validation loss: 2.6348162130003456

Epoch: 6| Step: 10
Training loss: 3.1374833064756036
Validation loss: 2.6419602700227602

Epoch: 6| Step: 11
Training loss: 2.7629360769624873
Validation loss: 2.6363811969300817

Epoch: 6| Step: 12
Training loss: 3.6624934694407703
Validation loss: 2.6396719065725014

Epoch: 6| Step: 13
Training loss: 3.1607329003968947
Validation loss: 2.6312848585005777

Epoch: 257| Step: 0
Training loss: 2.429897483264429
Validation loss: 2.624510937792926

Epoch: 6| Step: 1
Training loss: 3.5607249874025775
Validation loss: 2.632551714228297

Epoch: 6| Step: 2
Training loss: 2.7401276157760472
Validation loss: 2.616149260513274

Epoch: 6| Step: 3
Training loss: 3.4194845969015955
Validation loss: 2.6112673664779553

Epoch: 6| Step: 4
Training loss: 2.6823942788258472
Validation loss: 2.6008882884118423

Epoch: 6| Step: 5
Training loss: 2.5076881449162136
Validation loss: 2.604417937595213

Epoch: 6| Step: 6
Training loss: 2.8029647253989936
Validation loss: 2.6050705028298657

Epoch: 6| Step: 7
Training loss: 3.3118034926090085
Validation loss: 2.598163943409339

Epoch: 6| Step: 8
Training loss: 3.224533070909744
Validation loss: 2.6020856244692494

Epoch: 6| Step: 9
Training loss: 3.126544875705808
Validation loss: 2.5970593958687895

Epoch: 6| Step: 10
Training loss: 3.39164163141282
Validation loss: 2.595565998324385

Epoch: 6| Step: 11
Training loss: 2.7145860728096087
Validation loss: 2.59650417640053

Epoch: 6| Step: 12
Training loss: 2.6639311190340504
Validation loss: 2.600796711318307

Epoch: 6| Step: 13
Training loss: 1.5184629946191748
Validation loss: 2.5971813551475296

Epoch: 258| Step: 0
Training loss: 3.2357976613390016
Validation loss: 2.6005592706641183

Epoch: 6| Step: 1
Training loss: 2.613135454932016
Validation loss: 2.5994455897304265

Epoch: 6| Step: 2
Training loss: 3.509483296327559
Validation loss: 2.600329333150777

Epoch: 6| Step: 3
Training loss: 2.6595424218377657
Validation loss: 2.6019847738661626

Epoch: 6| Step: 4
Training loss: 3.2408056048809732
Validation loss: 2.6072585578883656

Epoch: 6| Step: 5
Training loss: 2.3146603777194983
Validation loss: 2.6027267586920932

Epoch: 6| Step: 6
Training loss: 3.0453102201841773
Validation loss: 2.6019941151326753

Epoch: 6| Step: 7
Training loss: 2.9091510034986543
Validation loss: 2.6063833955688893

Epoch: 6| Step: 8
Training loss: 3.3997237654276233
Validation loss: 2.6059820221197003

Epoch: 6| Step: 9
Training loss: 2.6775082994291473
Validation loss: 2.622581049080027

Epoch: 6| Step: 10
Training loss: 3.002402932712618
Validation loss: 2.6283507947043714

Epoch: 6| Step: 11
Training loss: 3.134472338305063
Validation loss: 2.623193915471948

Epoch: 6| Step: 12
Training loss: 2.6003497622056964
Validation loss: 2.6139322910128264

Epoch: 6| Step: 13
Training loss: 2.3405803355296033
Validation loss: 2.608049586249905

Epoch: 259| Step: 0
Training loss: 2.8967494110241145
Validation loss: 2.607276541845258

Epoch: 6| Step: 1
Training loss: 2.7558758124842
Validation loss: 2.6075681517476648

Epoch: 6| Step: 2
Training loss: 2.0511139518072468
Validation loss: 2.601085011632546

Epoch: 6| Step: 3
Training loss: 2.997935856556043
Validation loss: 2.5962481654451777

Epoch: 6| Step: 4
Training loss: 3.083687340973842
Validation loss: 2.604444308011394

Epoch: 6| Step: 5
Training loss: 2.9186831088845344
Validation loss: 2.6039701696936364

Epoch: 6| Step: 6
Training loss: 3.143906733888841
Validation loss: 2.6025741355918517

Epoch: 6| Step: 7
Training loss: 3.564364430617398
Validation loss: 2.599614231852132

Epoch: 6| Step: 8
Training loss: 3.1032653285140985
Validation loss: 2.601165000078402

Epoch: 6| Step: 9
Training loss: 2.866918733145559
Validation loss: 2.6092921211865305

Epoch: 6| Step: 10
Training loss: 2.9750761391008576
Validation loss: 2.6068939209100193

Epoch: 6| Step: 11
Training loss: 2.9897926248446054
Validation loss: 2.6060283106943345

Epoch: 6| Step: 12
Training loss: 2.7771311918705517
Validation loss: 2.606777794543158

Epoch: 6| Step: 13
Training loss: 2.6656971500198177
Validation loss: 2.601890707088566

Epoch: 260| Step: 0
Training loss: 2.4274131212490713
Validation loss: 2.6028608064505536

Epoch: 6| Step: 1
Training loss: 2.843005072311079
Validation loss: 2.6039876654027707

Epoch: 6| Step: 2
Training loss: 3.2510031105761166
Validation loss: 2.6005502357586257

Epoch: 6| Step: 3
Training loss: 3.1615851605704157
Validation loss: 2.6032039449400304

Epoch: 6| Step: 4
Training loss: 3.0775355050512534
Validation loss: 2.6065202305118667

Epoch: 6| Step: 5
Training loss: 2.7534114311940256
Validation loss: 2.596634673228567

Epoch: 6| Step: 6
Training loss: 3.0355694071073733
Validation loss: 2.605377344730105

Epoch: 6| Step: 7
Training loss: 2.7728790150719815
Validation loss: 2.6029880329040873

Epoch: 6| Step: 8
Training loss: 2.94513748417968
Validation loss: 2.60333375929706

Epoch: 6| Step: 9
Training loss: 3.327089820302915
Validation loss: 2.6033341876645637

Epoch: 6| Step: 10
Training loss: 2.13846495859773
Validation loss: 2.61210189987541

Epoch: 6| Step: 11
Training loss: 2.621989203820018
Validation loss: 2.6079397701986577

Epoch: 6| Step: 12
Training loss: 3.5739029541587484
Validation loss: 2.610786959359471

Epoch: 6| Step: 13
Training loss: 2.9638097515542734
Validation loss: 2.615081959852155

Epoch: 261| Step: 0
Training loss: 3.269649963775957
Validation loss: 2.607219078292388

Epoch: 6| Step: 1
Training loss: 3.4355686657655298
Validation loss: 2.6069767992616604

Epoch: 6| Step: 2
Training loss: 3.0205419114830834
Validation loss: 2.606823103746399

Epoch: 6| Step: 3
Training loss: 2.8109536052282773
Validation loss: 2.617572166594421

Epoch: 6| Step: 4
Training loss: 2.8553949390896367
Validation loss: 2.60786585634788

Epoch: 6| Step: 5
Training loss: 1.6168423344188192
Validation loss: 2.6079800115217946

Epoch: 6| Step: 6
Training loss: 3.1254769533485742
Validation loss: 2.6127453448933804

Epoch: 6| Step: 7
Training loss: 2.971191045154559
Validation loss: 2.608674605100973

Epoch: 6| Step: 8
Training loss: 2.3119210214357864
Validation loss: 2.6087544935035725

Epoch: 6| Step: 9
Training loss: 2.6580895729672993
Validation loss: 2.6107652220251394

Epoch: 6| Step: 10
Training loss: 3.333816318488822
Validation loss: 2.6099521258355325

Epoch: 6| Step: 11
Training loss: 3.662204556054752
Validation loss: 2.6090583626349333

Epoch: 6| Step: 12
Training loss: 2.2529688427866423
Validation loss: 2.609761888857898

Epoch: 6| Step: 13
Training loss: 3.401523075041753
Validation loss: 2.6084004936023266

Epoch: 262| Step: 0
Training loss: 2.9005668612281768
Validation loss: 2.6149280338685856

Epoch: 6| Step: 1
Training loss: 2.896767024360159
Validation loss: 2.615921529791364

Epoch: 6| Step: 2
Training loss: 2.815128623910271
Validation loss: 2.629683166402457

Epoch: 6| Step: 3
Training loss: 2.720560632877997
Validation loss: 2.635380892348868

Epoch: 6| Step: 4
Training loss: 2.8753902336320376
Validation loss: 2.6350595884980925

Epoch: 6| Step: 5
Training loss: 3.3633977889761493
Validation loss: 2.6229696083064145

Epoch: 6| Step: 6
Training loss: 2.6774128415465497
Validation loss: 2.6268059123831784

Epoch: 6| Step: 7
Training loss: 2.1766024945289053
Validation loss: 2.620657755392539

Epoch: 6| Step: 8
Training loss: 3.048514526582844
Validation loss: 2.6124356894220195

Epoch: 6| Step: 9
Training loss: 2.959606183376625
Validation loss: 2.609021634550448

Epoch: 6| Step: 10
Training loss: 3.170218801077317
Validation loss: 2.6038972502776154

Epoch: 6| Step: 11
Training loss: 3.3098767527888926
Validation loss: 2.6029980038481546

Epoch: 6| Step: 12
Training loss: 3.251727745333694
Validation loss: 2.602265410056036

Epoch: 6| Step: 13
Training loss: 2.749793911927756
Validation loss: 2.5943482834877507

Epoch: 263| Step: 0
Training loss: 3.069884758193517
Validation loss: 2.599238286636801

Epoch: 6| Step: 1
Training loss: 2.541520369858419
Validation loss: 2.5985103511007015

Epoch: 6| Step: 2
Training loss: 2.637903922008079
Validation loss: 2.599302050446001

Epoch: 6| Step: 3
Training loss: 3.6364900740403168
Validation loss: 2.600687302695441

Epoch: 6| Step: 4
Training loss: 2.933669169303498
Validation loss: 2.601488966664631

Epoch: 6| Step: 5
Training loss: 3.388755740136576
Validation loss: 2.597095137701086

Epoch: 6| Step: 6
Training loss: 2.5730790204139065
Validation loss: 2.602179497014683

Epoch: 6| Step: 7
Training loss: 3.068465514505336
Validation loss: 2.599637150154784

Epoch: 6| Step: 8
Training loss: 3.114036095215842
Validation loss: 2.604957646664585

Epoch: 6| Step: 9
Training loss: 1.9264396485994688
Validation loss: 2.606362573641662

Epoch: 6| Step: 10
Training loss: 2.787101932721537
Validation loss: 2.6000194497165845

Epoch: 6| Step: 11
Training loss: 3.5020901025044417
Validation loss: 2.6050354471102337

Epoch: 6| Step: 12
Training loss: 2.7207329194572836
Validation loss: 2.6193127078214182

Epoch: 6| Step: 13
Training loss: 2.854687793984317
Validation loss: 2.6313041601349823

Epoch: 264| Step: 0
Training loss: 2.970162948864937
Validation loss: 2.6283872317201555

Epoch: 6| Step: 1
Training loss: 2.763352834665704
Validation loss: 2.635319868303676

Epoch: 6| Step: 2
Training loss: 2.760294804792197
Validation loss: 2.6310375276419316

Epoch: 6| Step: 3
Training loss: 3.7096687798312518
Validation loss: 2.6262144745361735

Epoch: 6| Step: 4
Training loss: 2.724541819839027
Validation loss: 2.620084945581053

Epoch: 6| Step: 5
Training loss: 3.1188214066459037
Validation loss: 2.610533013934692

Epoch: 6| Step: 6
Training loss: 2.539631096190218
Validation loss: 2.61317813850803

Epoch: 6| Step: 7
Training loss: 3.022309637519615
Validation loss: 2.6116679016379347

Epoch: 6| Step: 8
Training loss: 2.958326491943472
Validation loss: 2.6144574255182227

Epoch: 6| Step: 9
Training loss: 2.4264310252182324
Validation loss: 2.6122955921357085

Epoch: 6| Step: 10
Training loss: 2.8775669745664016
Validation loss: 2.6094347690464312

Epoch: 6| Step: 11
Training loss: 3.050743112557719
Validation loss: 2.608956654980899

Epoch: 6| Step: 12
Training loss: 2.999567477518227
Validation loss: 2.59984074634158

Epoch: 6| Step: 13
Training loss: 3.0449109129252645
Validation loss: 2.6047283739940346

Epoch: 265| Step: 0
Training loss: 3.426921172011
Validation loss: 2.6011119451024736

Epoch: 6| Step: 1
Training loss: 3.355216357649775
Validation loss: 2.602128601613135

Epoch: 6| Step: 2
Training loss: 2.934071914571613
Validation loss: 2.5949814353201517

Epoch: 6| Step: 3
Training loss: 2.863685568955118
Validation loss: 2.592630948759443

Epoch: 6| Step: 4
Training loss: 2.3267446432555103
Validation loss: 2.5905392251735946

Epoch: 6| Step: 5
Training loss: 2.7407502757967177
Validation loss: 2.5942074880885895

Epoch: 6| Step: 6
Training loss: 2.702477085323389
Validation loss: 2.5946683576140113

Epoch: 6| Step: 7
Training loss: 1.9393809632613186
Validation loss: 2.5960278976191957

Epoch: 6| Step: 8
Training loss: 3.3824655826280887
Validation loss: 2.6015774054720637

Epoch: 6| Step: 9
Training loss: 3.0797533095018657
Validation loss: 2.597045368684094

Epoch: 6| Step: 10
Training loss: 2.5230181555228937
Validation loss: 2.6061184669500217

Epoch: 6| Step: 11
Training loss: 3.2421975009258404
Validation loss: 2.608719793897651

Epoch: 6| Step: 12
Training loss: 3.2799246881724295
Validation loss: 2.6112413771696614

Epoch: 6| Step: 13
Training loss: 2.9268088070611684
Validation loss: 2.6098220792934805

Epoch: 266| Step: 0
Training loss: 2.8737471794788245
Validation loss: 2.618326241159658

Epoch: 6| Step: 1
Training loss: 3.0966739901102587
Validation loss: 2.6253611222969853

Epoch: 6| Step: 2
Training loss: 2.243479711887622
Validation loss: 2.615376787957432

Epoch: 6| Step: 3
Training loss: 3.0397629898939496
Validation loss: 2.6167792476761207

Epoch: 6| Step: 4
Training loss: 3.38917109525185
Validation loss: 2.610024512664646

Epoch: 6| Step: 5
Training loss: 3.451110390254159
Validation loss: 2.603021709801451

Epoch: 6| Step: 6
Training loss: 2.722783046052171
Validation loss: 2.6035172772995216

Epoch: 6| Step: 7
Training loss: 2.935715153401989
Validation loss: 2.5953399434497944

Epoch: 6| Step: 8
Training loss: 2.742765099536479
Validation loss: 2.597186706627263

Epoch: 6| Step: 9
Training loss: 2.9805421832676338
Validation loss: 2.5920796249891684

Epoch: 6| Step: 10
Training loss: 2.508697353660254
Validation loss: 2.591549837290888

Epoch: 6| Step: 11
Training loss: 2.6516989821745285
Validation loss: 2.5951684808437396

Epoch: 6| Step: 12
Training loss: 3.3657450053320987
Validation loss: 2.5915737389726146

Epoch: 6| Step: 13
Training loss: 3.058011872931535
Validation loss: 2.591332407134684

Epoch: 267| Step: 0
Training loss: 2.5308573853981993
Validation loss: 2.5931878111356963

Epoch: 6| Step: 1
Training loss: 3.417020934431806
Validation loss: 2.591756030268714

Epoch: 6| Step: 2
Training loss: 3.7396519618347237
Validation loss: 2.5906235153863144

Epoch: 6| Step: 3
Training loss: 2.8275441790433864
Validation loss: 2.5973785851536864

Epoch: 6| Step: 4
Training loss: 3.223795223680635
Validation loss: 2.599409386110773

Epoch: 6| Step: 5
Training loss: 3.227963048929071
Validation loss: 2.609943974572977

Epoch: 6| Step: 6
Training loss: 2.3729260072421026
Validation loss: 2.606285945471036

Epoch: 6| Step: 7
Training loss: 2.7824034281489625
Validation loss: 2.616400382715482

Epoch: 6| Step: 8
Training loss: 2.8886415016996825
Validation loss: 2.6245719386806825

Epoch: 6| Step: 9
Training loss: 2.7209286784533657
Validation loss: 2.6302732794479997

Epoch: 6| Step: 10
Training loss: 2.563975025942099
Validation loss: 2.6297601149583465

Epoch: 6| Step: 11
Training loss: 2.908430696477215
Validation loss: 2.6261100062889238

Epoch: 6| Step: 12
Training loss: 2.963880219030248
Validation loss: 2.6200415271673365

Epoch: 6| Step: 13
Training loss: 2.40149684957742
Validation loss: 2.6255978793607566

Epoch: 268| Step: 0
Training loss: 2.824527370110255
Validation loss: 2.6147929262298604

Epoch: 6| Step: 1
Training loss: 3.11660248661428
Validation loss: 2.5997557471706734

Epoch: 6| Step: 2
Training loss: 3.549261827688171
Validation loss: 2.596666434267466

Epoch: 6| Step: 3
Training loss: 2.4803122643798314
Validation loss: 2.590887731340043

Epoch: 6| Step: 4
Training loss: 3.0821952437754416
Validation loss: 2.5894778378945413

Epoch: 6| Step: 5
Training loss: 2.544645023584041
Validation loss: 2.5920169336702537

Epoch: 6| Step: 6
Training loss: 3.439487506926393
Validation loss: 2.588965925999076

Epoch: 6| Step: 7
Training loss: 2.90783910477821
Validation loss: 2.5879513647311887

Epoch: 6| Step: 8
Training loss: 2.1251316029805243
Validation loss: 2.5916275530563646

Epoch: 6| Step: 9
Training loss: 2.2981050272912205
Validation loss: 2.5888478615965203

Epoch: 6| Step: 10
Training loss: 3.2884961725728625
Validation loss: 2.5857886938991355

Epoch: 6| Step: 11
Training loss: 3.237001099311423
Validation loss: 2.5847857187044987

Epoch: 6| Step: 12
Training loss: 2.7384837642994238
Validation loss: 2.5876788801919197

Epoch: 6| Step: 13
Training loss: 3.1260197310846998
Validation loss: 2.5840181428135294

Epoch: 269| Step: 0
Training loss: 2.4637290017729723
Validation loss: 2.593068137636358

Epoch: 6| Step: 1
Training loss: 3.1112160910953652
Validation loss: 2.590240246723381

Epoch: 6| Step: 2
Training loss: 3.161736582410485
Validation loss: 2.593338295317381

Epoch: 6| Step: 3
Training loss: 3.0467602830467437
Validation loss: 2.592163201495576

Epoch: 6| Step: 4
Training loss: 3.320628575259007
Validation loss: 2.6013209516501257

Epoch: 6| Step: 5
Training loss: 3.3786704273288253
Validation loss: 2.605477461843594

Epoch: 6| Step: 6
Training loss: 2.8282402394457695
Validation loss: 2.600945477856948

Epoch: 6| Step: 7
Training loss: 2.4263061348711803
Validation loss: 2.599600131670357

Epoch: 6| Step: 8
Training loss: 2.6423996599359434
Validation loss: 2.5988094770464096

Epoch: 6| Step: 9
Training loss: 3.2124554464018935
Validation loss: 2.595766072960708

Epoch: 6| Step: 10
Training loss: 3.054699675786955
Validation loss: 2.5946885837376112

Epoch: 6| Step: 11
Training loss: 3.2557299061316014
Validation loss: 2.592306491276945

Epoch: 6| Step: 12
Training loss: 2.4431084885994423
Validation loss: 2.594882999815644

Epoch: 6| Step: 13
Training loss: 1.8278371470174375
Validation loss: 2.5894708404079325

Epoch: 270| Step: 0
Training loss: 3.051377945108013
Validation loss: 2.59243022078514

Epoch: 6| Step: 1
Training loss: 2.583684302658834
Validation loss: 2.5945605254381485

Epoch: 6| Step: 2
Training loss: 2.9220404756576928
Validation loss: 2.595313042932418

Epoch: 6| Step: 3
Training loss: 2.322538085559527
Validation loss: 2.5956342060174187

Epoch: 6| Step: 4
Training loss: 2.5377333698165607
Validation loss: 2.5985441442359347

Epoch: 6| Step: 5
Training loss: 3.2405603209232936
Validation loss: 2.6013024317876363

Epoch: 6| Step: 6
Training loss: 3.5454952564436404
Validation loss: 2.6061466921221914

Epoch: 6| Step: 7
Training loss: 2.5315929227648386
Validation loss: 2.6122901989858303

Epoch: 6| Step: 8
Training loss: 2.8387019027606293
Validation loss: 2.6089170271532254

Epoch: 6| Step: 9
Training loss: 3.8816338636476284
Validation loss: 2.616853751297879

Epoch: 6| Step: 10
Training loss: 2.789866270189665
Validation loss: 2.634108630307205

Epoch: 6| Step: 11
Training loss: 2.8154180012439567
Validation loss: 2.6106736084203472

Epoch: 6| Step: 12
Training loss: 2.6012426414550647
Validation loss: 2.6116200010602753

Epoch: 6| Step: 13
Training loss: 2.995483336255711
Validation loss: 2.605819357546115

Epoch: 271| Step: 0
Training loss: 2.3022342362002437
Validation loss: 2.6028118529049875

Epoch: 6| Step: 1
Training loss: 2.3611958532148005
Validation loss: 2.5895953865065446

Epoch: 6| Step: 2
Training loss: 2.8699435674455804
Validation loss: 2.589697795652787

Epoch: 6| Step: 3
Training loss: 2.7049125978800888
Validation loss: 2.585360630330437

Epoch: 6| Step: 4
Training loss: 3.215874730265736
Validation loss: 2.5867131436229602

Epoch: 6| Step: 5
Training loss: 3.150510498339354
Validation loss: 2.5830966935023896

Epoch: 6| Step: 6
Training loss: 2.7956736451284723
Validation loss: 2.582565285403725

Epoch: 6| Step: 7
Training loss: 3.290040946636074
Validation loss: 2.5835411459239688

Epoch: 6| Step: 8
Training loss: 3.3521003913959055
Validation loss: 2.5837100631228

Epoch: 6| Step: 9
Training loss: 2.9983948546016355
Validation loss: 2.581486241756512

Epoch: 6| Step: 10
Training loss: 2.7041567558808377
Validation loss: 2.5866569874082033

Epoch: 6| Step: 11
Training loss: 2.580990395410958
Validation loss: 2.5832132522614413

Epoch: 6| Step: 12
Training loss: 3.01777374719879
Validation loss: 2.586698190159022

Epoch: 6| Step: 13
Training loss: 3.7750526272976894
Validation loss: 2.5942794801999307

Epoch: 272| Step: 0
Training loss: 2.7934013405155973
Validation loss: 2.5925136495260888

Epoch: 6| Step: 1
Training loss: 2.685125144443141
Validation loss: 2.594195849827723

Epoch: 6| Step: 2
Training loss: 2.874612035696978
Validation loss: 2.6064679194361084

Epoch: 6| Step: 3
Training loss: 2.7945134086348626
Validation loss: 2.596012094219702

Epoch: 6| Step: 4
Training loss: 3.105240569938565
Validation loss: 2.6058515241184566

Epoch: 6| Step: 5
Training loss: 3.5394859481685637
Validation loss: 2.5983212650083556

Epoch: 6| Step: 6
Training loss: 2.5549303225219067
Validation loss: 2.6017619312180367

Epoch: 6| Step: 7
Training loss: 3.128086854319116
Validation loss: 2.60935936880683

Epoch: 6| Step: 8
Training loss: 2.69691645125164
Validation loss: 2.620576833376324

Epoch: 6| Step: 9
Training loss: 2.907743008955215
Validation loss: 2.6156189289390843

Epoch: 6| Step: 10
Training loss: 3.2454511646809756
Validation loss: 2.6156624687907164

Epoch: 6| Step: 11
Training loss: 3.1712184282835603
Validation loss: 2.6115528666239842

Epoch: 6| Step: 12
Training loss: 2.6478115906314827
Validation loss: 2.6074014477699494

Epoch: 6| Step: 13
Training loss: 2.425591355414575
Validation loss: 2.599249917114428

Epoch: 273| Step: 0
Training loss: 3.0555437453841265
Validation loss: 2.5998567108634507

Epoch: 6| Step: 1
Training loss: 3.2504027190486005
Validation loss: 2.5951482298124606

Epoch: 6| Step: 2
Training loss: 2.436422647902836
Validation loss: 2.589694615969509

Epoch: 6| Step: 3
Training loss: 2.5241809611914334
Validation loss: 2.5894332300784972

Epoch: 6| Step: 4
Training loss: 3.0505270955874306
Validation loss: 2.5857439540298577

Epoch: 6| Step: 5
Training loss: 3.239272680239847
Validation loss: 2.588005764288847

Epoch: 6| Step: 6
Training loss: 2.630252306479313
Validation loss: 2.5834972999079935

Epoch: 6| Step: 7
Training loss: 2.6517468147305454
Validation loss: 2.5833718842465827

Epoch: 6| Step: 8
Training loss: 2.645949824214269
Validation loss: 2.58518320836742

Epoch: 6| Step: 9
Training loss: 2.8079417271667273
Validation loss: 2.580621868971849

Epoch: 6| Step: 10
Training loss: 2.908162625903788
Validation loss: 2.58897041564355

Epoch: 6| Step: 11
Training loss: 3.082375162757112
Validation loss: 2.5879309680694056

Epoch: 6| Step: 12
Training loss: 3.3580244321405743
Validation loss: 2.585960258956504

Epoch: 6| Step: 13
Training loss: 3.410729638623625
Validation loss: 2.5904699906706674

Epoch: 274| Step: 0
Training loss: 2.9807763897073882
Validation loss: 2.588525922873513

Epoch: 6| Step: 1
Training loss: 2.7458084414043173
Validation loss: 2.5931672757337085

Epoch: 6| Step: 2
Training loss: 3.261825906969207
Validation loss: 2.5943787523464166

Epoch: 6| Step: 3
Training loss: 3.353474816155674
Validation loss: 2.596037571389226

Epoch: 6| Step: 4
Training loss: 3.0716521856581034
Validation loss: 2.5899358569154427

Epoch: 6| Step: 5
Training loss: 2.533881244469002
Validation loss: 2.593023697371807

Epoch: 6| Step: 6
Training loss: 2.5395390928909305
Validation loss: 2.6025775108305513

Epoch: 6| Step: 7
Training loss: 3.1142273426210103
Validation loss: 2.597508815985831

Epoch: 6| Step: 8
Training loss: 2.7656881896305596
Validation loss: 2.6162041134261407

Epoch: 6| Step: 9
Training loss: 3.0873728057978322
Validation loss: 2.6242950770371234

Epoch: 6| Step: 10
Training loss: 2.6436149328192453
Validation loss: 2.6210269941790063

Epoch: 6| Step: 11
Training loss: 2.7718883217337713
Validation loss: 2.6040980458396485

Epoch: 6| Step: 12
Training loss: 3.379123006053355
Validation loss: 2.6037973554704004

Epoch: 6| Step: 13
Training loss: 2.2065811643525577
Validation loss: 2.5957157806888205

Epoch: 275| Step: 0
Training loss: 2.9254999369306858
Validation loss: 2.6067429948645717

Epoch: 6| Step: 1
Training loss: 2.9389138573024782
Validation loss: 2.6065966314864997

Epoch: 6| Step: 2
Training loss: 3.0826986192259436
Validation loss: 2.595104528536352

Epoch: 6| Step: 3
Training loss: 2.3742259922651447
Validation loss: 2.6082488644852546

Epoch: 6| Step: 4
Training loss: 3.172599972712133
Validation loss: 2.593486028691562

Epoch: 6| Step: 5
Training loss: 3.280650638153831
Validation loss: 2.6031417923545854

Epoch: 6| Step: 6
Training loss: 2.6459382904941813
Validation loss: 2.606805166816827

Epoch: 6| Step: 7
Training loss: 2.9451515700190614
Validation loss: 2.6023158200642644

Epoch: 6| Step: 8
Training loss: 2.499950789920947
Validation loss: 2.6046188106362824

Epoch: 6| Step: 9
Training loss: 3.066545267051822
Validation loss: 2.605139950574791

Epoch: 6| Step: 10
Training loss: 3.6808831283060384
Validation loss: 2.6098351439140077

Epoch: 6| Step: 11
Training loss: 2.8257345983036073
Validation loss: 2.61195845837989

Epoch: 6| Step: 12
Training loss: 2.5653553383069148
Validation loss: 2.5999271320689457

Epoch: 6| Step: 13
Training loss: 2.381808510310003
Validation loss: 2.5964178619205973

Epoch: 276| Step: 0
Training loss: 2.6602361949945683
Validation loss: 2.597357014930768

Epoch: 6| Step: 1
Training loss: 2.8451164232510817
Validation loss: 2.5970245538212806

Epoch: 6| Step: 2
Training loss: 3.2593842518164022
Validation loss: 2.606221805613884

Epoch: 6| Step: 3
Training loss: 2.948386937745446
Validation loss: 2.596471567706933

Epoch: 6| Step: 4
Training loss: 1.6646708061651587
Validation loss: 2.5969604024031527

Epoch: 6| Step: 5
Training loss: 3.3409883021469873
Validation loss: 2.5960657501372224

Epoch: 6| Step: 6
Training loss: 2.5618718005288574
Validation loss: 2.6003891439899673

Epoch: 6| Step: 7
Training loss: 2.824645372936065
Validation loss: 2.590314719928719

Epoch: 6| Step: 8
Training loss: 2.5442354531042364
Validation loss: 2.5960763500468746

Epoch: 6| Step: 9
Training loss: 2.5138473390221394
Validation loss: 2.6133216631484157

Epoch: 6| Step: 10
Training loss: 3.534691138256792
Validation loss: 2.616599752922488

Epoch: 6| Step: 11
Training loss: 2.9964803075781448
Validation loss: 2.597750195761204

Epoch: 6| Step: 12
Training loss: 3.1229241151998672
Validation loss: 2.6018826640793824

Epoch: 6| Step: 13
Training loss: 3.9951264971781044
Validation loss: 2.6022675458760776

Epoch: 277| Step: 0
Training loss: 3.0228266135818656
Validation loss: 2.5945665843548196

Epoch: 6| Step: 1
Training loss: 2.621906273965652
Validation loss: 2.5909843709060025

Epoch: 6| Step: 2
Training loss: 3.2951288163933707
Validation loss: 2.5850275784202315

Epoch: 6| Step: 3
Training loss: 2.8357241211370914
Validation loss: 2.5856878213824506

Epoch: 6| Step: 4
Training loss: 2.3852264683842828
Validation loss: 2.5873308608099075

Epoch: 6| Step: 5
Training loss: 2.7935076853829233
Validation loss: 2.5850194274063782

Epoch: 6| Step: 6
Training loss: 3.1884224248849584
Validation loss: 2.592175047669979

Epoch: 6| Step: 7
Training loss: 2.4860523247709456
Validation loss: 2.5832596208321683

Epoch: 6| Step: 8
Training loss: 2.861900839921171
Validation loss: 2.5875046450055206

Epoch: 6| Step: 9
Training loss: 3.384535986962747
Validation loss: 2.583566437471111

Epoch: 6| Step: 10
Training loss: 2.9328763569712177
Validation loss: 2.5922681981728846

Epoch: 6| Step: 11
Training loss: 3.1489321033841984
Validation loss: 2.582501699006335

Epoch: 6| Step: 12
Training loss: 2.929577309125677
Validation loss: 2.5758085014407075

Epoch: 6| Step: 13
Training loss: 2.841111184994866
Validation loss: 2.5867496141326223

Epoch: 278| Step: 0
Training loss: 3.2418046472467528
Validation loss: 2.5858576611428044

Epoch: 6| Step: 1
Training loss: 3.139233484923313
Validation loss: 2.592805779763679

Epoch: 6| Step: 2
Training loss: 2.9250448239796323
Validation loss: 2.6029449911582425

Epoch: 6| Step: 3
Training loss: 3.1453348400613113
Validation loss: 2.5995073050438506

Epoch: 6| Step: 4
Training loss: 2.480462982891918
Validation loss: 2.5951607380534645

Epoch: 6| Step: 5
Training loss: 2.7279601791249815
Validation loss: 2.6071295800794188

Epoch: 6| Step: 6
Training loss: 2.7516141835719585
Validation loss: 2.6161802055094383

Epoch: 6| Step: 7
Training loss: 3.116702852362072
Validation loss: 2.610831359440648

Epoch: 6| Step: 8
Training loss: 3.135299190377785
Validation loss: 2.604685629704915

Epoch: 6| Step: 9
Training loss: 3.3923596985492
Validation loss: 2.612993014985716

Epoch: 6| Step: 10
Training loss: 2.091794823397103
Validation loss: 2.606314343915067

Epoch: 6| Step: 11
Training loss: 2.7760952961639824
Validation loss: 2.603884004736914

Epoch: 6| Step: 12
Training loss: 3.0310089959363804
Validation loss: 2.586729891836018

Epoch: 6| Step: 13
Training loss: 2.7184054276920175
Validation loss: 2.580387937829286

Epoch: 279| Step: 0
Training loss: 2.7488010567246737
Validation loss: 2.581473575892814

Epoch: 6| Step: 1
Training loss: 2.5719019836270998
Validation loss: 2.5737285996057917

Epoch: 6| Step: 2
Training loss: 3.0752906723961173
Validation loss: 2.576962139334458

Epoch: 6| Step: 3
Training loss: 2.845124803162218
Validation loss: 2.5783994129024324

Epoch: 6| Step: 4
Training loss: 3.0410287963346745
Validation loss: 2.5786239166133336

Epoch: 6| Step: 5
Training loss: 2.5371276056047285
Validation loss: 2.5785453237471962

Epoch: 6| Step: 6
Training loss: 3.1369394721143387
Validation loss: 2.5810905297834226

Epoch: 6| Step: 7
Training loss: 2.9459245688317584
Validation loss: 2.5802023624072197

Epoch: 6| Step: 8
Training loss: 2.6739443077330827
Validation loss: 2.5821432719482873

Epoch: 6| Step: 9
Training loss: 2.9787711212139354
Validation loss: 2.5751745350625392

Epoch: 6| Step: 10
Training loss: 2.9057487137506195
Validation loss: 2.5792163725273514

Epoch: 6| Step: 11
Training loss: 3.058669516841732
Validation loss: 2.586141574967259

Epoch: 6| Step: 12
Training loss: 2.9733856950377424
Validation loss: 2.585607401726262

Epoch: 6| Step: 13
Training loss: 3.562462923626624
Validation loss: 2.5869338398792845

Epoch: 280| Step: 0
Training loss: 3.1475332016894284
Validation loss: 2.5964869620154913

Epoch: 6| Step: 1
Training loss: 3.152095969293097
Validation loss: 2.5923032722689006

Epoch: 6| Step: 2
Training loss: 2.7799282576545568
Validation loss: 2.601512581911951

Epoch: 6| Step: 3
Training loss: 2.895828759352184
Validation loss: 2.597871629198089

Epoch: 6| Step: 4
Training loss: 2.7742366875058124
Validation loss: 2.595848344679029

Epoch: 6| Step: 5
Training loss: 2.7932311461640404
Validation loss: 2.585057271536107

Epoch: 6| Step: 6
Training loss: 2.863651100825361
Validation loss: 2.5840057790589945

Epoch: 6| Step: 7
Training loss: 2.6897743714731157
Validation loss: 2.586126691554985

Epoch: 6| Step: 8
Training loss: 2.582758583203023
Validation loss: 2.587599852980782

Epoch: 6| Step: 9
Training loss: 2.9539855026271615
Validation loss: 2.5886860762603776

Epoch: 6| Step: 10
Training loss: 2.6720494442036973
Validation loss: 2.5896860648591833

Epoch: 6| Step: 11
Training loss: 3.373105117657264
Validation loss: 2.588638689763949

Epoch: 6| Step: 12
Training loss: 3.345737045125045
Validation loss: 2.6000037336835407

Epoch: 6| Step: 13
Training loss: 2.4513734043149795
Validation loss: 2.592040172341873

Epoch: 281| Step: 0
Training loss: 2.9268286832948425
Validation loss: 2.6042874448927504

Epoch: 6| Step: 1
Training loss: 3.2824719288214754
Validation loss: 2.5982808464670164

Epoch: 6| Step: 2
Training loss: 2.37462010607873
Validation loss: 2.5883617750035333

Epoch: 6| Step: 3
Training loss: 3.0580260625692888
Validation loss: 2.596473809496761

Epoch: 6| Step: 4
Training loss: 2.6531493995721753
Validation loss: 2.5922552536881733

Epoch: 6| Step: 5
Training loss: 3.1487176737350717
Validation loss: 2.5900799513911297

Epoch: 6| Step: 6
Training loss: 2.0737734099222807
Validation loss: 2.5985711267320792

Epoch: 6| Step: 7
Training loss: 3.329229037417153
Validation loss: 2.59756046414329

Epoch: 6| Step: 8
Training loss: 2.974874022565372
Validation loss: 2.6014254653799456

Epoch: 6| Step: 9
Training loss: 2.7826398312923253
Validation loss: 2.59792040347591

Epoch: 6| Step: 10
Training loss: 3.041678824901232
Validation loss: 2.600761625592503

Epoch: 6| Step: 11
Training loss: 3.0620974840608994
Validation loss: 2.605535145832182

Epoch: 6| Step: 12
Training loss: 3.510830742537524
Validation loss: 2.601864822166511

Epoch: 6| Step: 13
Training loss: 1.9656956306709756
Validation loss: 2.6021213750947525

Epoch: 282| Step: 0
Training loss: 2.9200080986433203
Validation loss: 2.6104150194936886

Epoch: 6| Step: 1
Training loss: 2.710583050776842
Validation loss: 2.6011425840863946

Epoch: 6| Step: 2
Training loss: 2.4892975604601673
Validation loss: 2.590030092609438

Epoch: 6| Step: 3
Training loss: 2.4851501023457243
Validation loss: 2.6004511928003553

Epoch: 6| Step: 4
Training loss: 3.2707249001835454
Validation loss: 2.602886466754818

Epoch: 6| Step: 5
Training loss: 3.213651007096159
Validation loss: 2.5930971721902853

Epoch: 6| Step: 6
Training loss: 2.9007993056980825
Validation loss: 2.5979815866340927

Epoch: 6| Step: 7
Training loss: 2.7575948051140315
Validation loss: 2.5976060278792747

Epoch: 6| Step: 8
Training loss: 3.0775841562151354
Validation loss: 2.5892917288069777

Epoch: 6| Step: 9
Training loss: 2.453575433088062
Validation loss: 2.5834393114018104

Epoch: 6| Step: 10
Training loss: 3.6679851300053588
Validation loss: 2.6058532064184767

Epoch: 6| Step: 11
Training loss: 3.1274756734193137
Validation loss: 2.597369305261856

Epoch: 6| Step: 12
Training loss: 2.757350461472537
Validation loss: 2.5898333077099642

Epoch: 6| Step: 13
Training loss: 2.717379257341301
Validation loss: 2.5781720885211654

Epoch: 283| Step: 0
Training loss: 2.5322084849190816
Validation loss: 2.5819538669496294

Epoch: 6| Step: 1
Training loss: 3.0662227502818027
Validation loss: 2.5817760817839823

Epoch: 6| Step: 2
Training loss: 2.7951534663123665
Validation loss: 2.5912827124420277

Epoch: 6| Step: 3
Training loss: 2.958050691955633
Validation loss: 2.58326402214609

Epoch: 6| Step: 4
Training loss: 2.8960917149452485
Validation loss: 2.586202839519462

Epoch: 6| Step: 5
Training loss: 3.195099690632681
Validation loss: 2.5899681039552545

Epoch: 6| Step: 6
Training loss: 3.119684505161245
Validation loss: 2.5896496515433993

Epoch: 6| Step: 7
Training loss: 2.8746380785486023
Validation loss: 2.586439790202841

Epoch: 6| Step: 8
Training loss: 3.126890754911635
Validation loss: 2.5839976982389765

Epoch: 6| Step: 9
Training loss: 3.0136696598541763
Validation loss: 2.5810291299772925

Epoch: 6| Step: 10
Training loss: 3.0175343531918357
Validation loss: 2.593420293129096

Epoch: 6| Step: 11
Training loss: 2.4866439726597647
Validation loss: 2.584139378287355

Epoch: 6| Step: 12
Training loss: 3.2518386041678258
Validation loss: 2.598943095543032

Epoch: 6| Step: 13
Training loss: 1.7561628951331802
Validation loss: 2.582232433886793

Epoch: 284| Step: 0
Training loss: 3.0921478746987354
Validation loss: 2.5967245390805775

Epoch: 6| Step: 1
Training loss: 2.414628737129455
Validation loss: 2.586215478256739

Epoch: 6| Step: 2
Training loss: 2.3731526669126985
Validation loss: 2.5906236044489095

Epoch: 6| Step: 3
Training loss: 3.2861505153683637
Validation loss: 2.5912598023641937

Epoch: 6| Step: 4
Training loss: 2.5749605120251395
Validation loss: 2.578374287425681

Epoch: 6| Step: 5
Training loss: 2.757367235932041
Validation loss: 2.588184355715229

Epoch: 6| Step: 6
Training loss: 2.6041551106514436
Validation loss: 2.5890591880006846

Epoch: 6| Step: 7
Training loss: 3.1013048194674373
Validation loss: 2.5891999752264874

Epoch: 6| Step: 8
Training loss: 3.727709323831261
Validation loss: 2.5838010695647293

Epoch: 6| Step: 9
Training loss: 2.42810026374697
Validation loss: 2.590903138046922

Epoch: 6| Step: 10
Training loss: 2.269388585030277
Validation loss: 2.5797765399566073

Epoch: 6| Step: 11
Training loss: 3.3535814584303205
Validation loss: 2.5856981505314582

Epoch: 6| Step: 12
Training loss: 3.3212871960906987
Validation loss: 2.5854081106223235

Epoch: 6| Step: 13
Training loss: 3.0977075098710376
Validation loss: 2.582048325450138

Epoch: 285| Step: 0
Training loss: 3.042431530522901
Validation loss: 2.593974165428506

Epoch: 6| Step: 1
Training loss: 3.3222928951518944
Validation loss: 2.5909904183964674

Epoch: 6| Step: 2
Training loss: 3.188538176567779
Validation loss: 2.5940715957611147

Epoch: 6| Step: 3
Training loss: 2.3037589578770032
Validation loss: 2.617793232480745

Epoch: 6| Step: 4
Training loss: 2.530587663061818
Validation loss: 2.6271436584447194

Epoch: 6| Step: 5
Training loss: 2.241893788948373
Validation loss: 2.638126884555573

Epoch: 6| Step: 6
Training loss: 3.6157653517588075
Validation loss: 2.6363945412641434

Epoch: 6| Step: 7
Training loss: 3.0158191677694384
Validation loss: 2.652009048957255

Epoch: 6| Step: 8
Training loss: 2.9517315195700045
Validation loss: 2.6164479630698256

Epoch: 6| Step: 9
Training loss: 3.1374842183601475
Validation loss: 2.5988470552610385

Epoch: 6| Step: 10
Training loss: 2.569193123792474
Validation loss: 2.5837763334696975

Epoch: 6| Step: 11
Training loss: 2.8243873303172307
Validation loss: 2.574624264690042

Epoch: 6| Step: 12
Training loss: 2.6971090769932653
Validation loss: 2.5672571328754046

Epoch: 6| Step: 13
Training loss: 3.193149870086663
Validation loss: 2.565960380224223

Epoch: 286| Step: 0
Training loss: 2.362394812931731
Validation loss: 2.5688897548976084

Epoch: 6| Step: 1
Training loss: 2.31415951954946
Validation loss: 2.5689873112922115

Epoch: 6| Step: 2
Training loss: 3.355386752990778
Validation loss: 2.5694972789919297

Epoch: 6| Step: 3
Training loss: 3.2016851398888915
Validation loss: 2.5685920826073647

Epoch: 6| Step: 4
Training loss: 2.8825666948263433
Validation loss: 2.5740267998402415

Epoch: 6| Step: 5
Training loss: 2.880996587039577
Validation loss: 2.571459956953402

Epoch: 6| Step: 6
Training loss: 2.777410707592138
Validation loss: 2.5704362509518166

Epoch: 6| Step: 7
Training loss: 3.1868839042495787
Validation loss: 2.5660179954428957

Epoch: 6| Step: 8
Training loss: 3.2784209635092703
Validation loss: 2.5702647807450503

Epoch: 6| Step: 9
Training loss: 3.092530289473103
Validation loss: 2.5776839315590037

Epoch: 6| Step: 10
Training loss: 2.609116958376959
Validation loss: 2.5844422734590613

Epoch: 6| Step: 11
Training loss: 3.1568169415107796
Validation loss: 2.579321457913458

Epoch: 6| Step: 12
Training loss: 3.0124127767131594
Validation loss: 2.5957293518564137

Epoch: 6| Step: 13
Training loss: 2.356477081932031
Validation loss: 2.5978279993934894

Epoch: 287| Step: 0
Training loss: 3.250885769374627
Validation loss: 2.627017160752801

Epoch: 6| Step: 1
Training loss: 3.398584261827447
Validation loss: 2.661267247570753

Epoch: 6| Step: 2
Training loss: 2.632231968116064
Validation loss: 2.6334464582249653

Epoch: 6| Step: 3
Training loss: 2.9502882477190098
Validation loss: 2.6290305037158874

Epoch: 6| Step: 4
Training loss: 3.149074139843713
Validation loss: 2.613562259323114

Epoch: 6| Step: 5
Training loss: 3.3786093167940185
Validation loss: 2.60550649783209

Epoch: 6| Step: 6
Training loss: 2.6483845663266554
Validation loss: 2.591686914330123

Epoch: 6| Step: 7
Training loss: 2.7270570322919627
Validation loss: 2.5791304441564313

Epoch: 6| Step: 8
Training loss: 2.7537263419182225
Validation loss: 2.5699618346225113

Epoch: 6| Step: 9
Training loss: 2.71213577567537
Validation loss: 2.5677342783687034

Epoch: 6| Step: 10
Training loss: 3.1061366100838077
Validation loss: 2.576017672115918

Epoch: 6| Step: 11
Training loss: 2.8736718468577536
Validation loss: 2.577665405475584

Epoch: 6| Step: 12
Training loss: 1.9989252182796975
Validation loss: 2.57280449441924

Epoch: 6| Step: 13
Training loss: 2.9895133476616502
Validation loss: 2.57403199877236

Epoch: 288| Step: 0
Training loss: 2.916442553674644
Validation loss: 2.569221752626557

Epoch: 6| Step: 1
Training loss: 3.357808728258119
Validation loss: 2.569462634902356

Epoch: 6| Step: 2
Training loss: 3.0737955851546808
Validation loss: 2.576508872584611

Epoch: 6| Step: 3
Training loss: 2.8325413737764316
Validation loss: 2.5701448488296643

Epoch: 6| Step: 4
Training loss: 3.502738834708812
Validation loss: 2.571792539973849

Epoch: 6| Step: 5
Training loss: 3.151013553378376
Validation loss: 2.5751373590490396

Epoch: 6| Step: 6
Training loss: 2.5220096670354213
Validation loss: 2.575636542844567

Epoch: 6| Step: 7
Training loss: 2.7575973988794376
Validation loss: 2.5709346463750555

Epoch: 6| Step: 8
Training loss: 2.8156952403597364
Validation loss: 2.5808632050326543

Epoch: 6| Step: 9
Training loss: 2.7228648298758613
Validation loss: 2.5826446721461296

Epoch: 6| Step: 10
Training loss: 2.7552632336594214
Validation loss: 2.583556428247889

Epoch: 6| Step: 11
Training loss: 2.4604836666105356
Validation loss: 2.596396873678211

Epoch: 6| Step: 12
Training loss: 3.0484064410498126
Validation loss: 2.5936203672293185

Epoch: 6| Step: 13
Training loss: 2.3828595266235495
Validation loss: 2.608236729607581

Epoch: 289| Step: 0
Training loss: 2.525362113443558
Validation loss: 2.598805891235206

Epoch: 6| Step: 1
Training loss: 3.2239993354190872
Validation loss: 2.6119168522081964

Epoch: 6| Step: 2
Training loss: 2.8118389624367697
Validation loss: 2.5922062610616177

Epoch: 6| Step: 3
Training loss: 2.4103724847919032
Validation loss: 2.594967671546905

Epoch: 6| Step: 4
Training loss: 2.8314491252474845
Validation loss: 2.584907170088329

Epoch: 6| Step: 5
Training loss: 3.488304214999993
Validation loss: 2.592615422289772

Epoch: 6| Step: 6
Training loss: 3.0612491466541276
Validation loss: 2.5842944337822686

Epoch: 6| Step: 7
Training loss: 2.906509880013689
Validation loss: 2.574683792956767

Epoch: 6| Step: 8
Training loss: 2.8234838687739234
Validation loss: 2.5768671163435317

Epoch: 6| Step: 9
Training loss: 2.521143387151286
Validation loss: 2.5637355269941624

Epoch: 6| Step: 10
Training loss: 2.9821737269883277
Validation loss: 2.5737881236866147

Epoch: 6| Step: 11
Training loss: 2.815029956122959
Validation loss: 2.5645203613092313

Epoch: 6| Step: 12
Training loss: 3.2127546751252365
Validation loss: 2.568303227732056

Epoch: 6| Step: 13
Training loss: 2.999998092650761
Validation loss: 2.5684934247580014

Epoch: 290| Step: 0
Training loss: 2.8105736811395388
Validation loss: 2.5694393406974068

Epoch: 6| Step: 1
Training loss: 2.8936354348756965
Validation loss: 2.563400694521837

Epoch: 6| Step: 2
Training loss: 3.217546552841489
Validation loss: 2.5677794837857544

Epoch: 6| Step: 3
Training loss: 2.677242843289222
Validation loss: 2.564664620247266

Epoch: 6| Step: 4
Training loss: 2.3600972061827954
Validation loss: 2.5683048023677215

Epoch: 6| Step: 5
Training loss: 2.5821234012843868
Validation loss: 2.5700782249953025

Epoch: 6| Step: 6
Training loss: 3.304652725650003
Validation loss: 2.576844177587842

Epoch: 6| Step: 7
Training loss: 3.4400148382532225
Validation loss: 2.578132704458847

Epoch: 6| Step: 8
Training loss: 2.8772559229973513
Validation loss: 2.586005195336591

Epoch: 6| Step: 9
Training loss: 3.1515250011325744
Validation loss: 2.590707476304352

Epoch: 6| Step: 10
Training loss: 3.107592507885865
Validation loss: 2.617071066311065

Epoch: 6| Step: 11
Training loss: 2.76424774532497
Validation loss: 2.602192787190821

Epoch: 6| Step: 12
Training loss: 2.632359949717498
Validation loss: 2.5689274204996346

Epoch: 6| Step: 13
Training loss: 2.6588147515723453
Validation loss: 2.565233850685897

Epoch: 291| Step: 0
Training loss: 2.920540081400259
Validation loss: 2.5671870997137756

Epoch: 6| Step: 1
Training loss: 2.618253485103354
Validation loss: 2.5680023952170496

Epoch: 6| Step: 2
Training loss: 2.9215387977114395
Validation loss: 2.566041987082288

Epoch: 6| Step: 3
Training loss: 2.3463696907255303
Validation loss: 2.5747337114415316

Epoch: 6| Step: 4
Training loss: 3.0909491296714666
Validation loss: 2.563485441052853

Epoch: 6| Step: 5
Training loss: 2.72260379603906
Validation loss: 2.580985261152555

Epoch: 6| Step: 6
Training loss: 3.0372877258725963
Validation loss: 2.586664453367985

Epoch: 6| Step: 7
Training loss: 2.888312987446504
Validation loss: 2.5881361468032544

Epoch: 6| Step: 8
Training loss: 3.282058906756464
Validation loss: 2.5829351067291273

Epoch: 6| Step: 9
Training loss: 3.6744349869258173
Validation loss: 2.5910535135001886

Epoch: 6| Step: 10
Training loss: 3.1438739729415457
Validation loss: 2.5821680698537253

Epoch: 6| Step: 11
Training loss: 2.842455223354863
Validation loss: 2.5961877442441943

Epoch: 6| Step: 12
Training loss: 2.2545573386664977
Validation loss: 2.5810951523151378

Epoch: 6| Step: 13
Training loss: 2.4709213944471444
Validation loss: 2.5783177586821586

Epoch: 292| Step: 0
Training loss: 2.7582628784708842
Validation loss: 2.5757675683953685

Epoch: 6| Step: 1
Training loss: 2.9819920797876067
Validation loss: 2.578388400278021

Epoch: 6| Step: 2
Training loss: 2.6605751279171774
Validation loss: 2.5924658682180075

Epoch: 6| Step: 3
Training loss: 2.951397102693585
Validation loss: 2.5826097726156507

Epoch: 6| Step: 4
Training loss: 3.363267072233474
Validation loss: 2.5849956287583424

Epoch: 6| Step: 5
Training loss: 3.0414863080066614
Validation loss: 2.5723641715606127

Epoch: 6| Step: 6
Training loss: 2.817461681088468
Validation loss: 2.5767618612210326

Epoch: 6| Step: 7
Training loss: 3.363792318576194
Validation loss: 2.57488381951739

Epoch: 6| Step: 8
Training loss: 3.0049591401887814
Validation loss: 2.576853888554966

Epoch: 6| Step: 9
Training loss: 3.241111337775582
Validation loss: 2.574879659757192

Epoch: 6| Step: 10
Training loss: 2.7884447284464997
Validation loss: 2.598968705751271

Epoch: 6| Step: 11
Training loss: 2.5436680736048793
Validation loss: 2.6059007412750606

Epoch: 6| Step: 12
Training loss: 2.2571784056335464
Validation loss: 2.587180444373341

Epoch: 6| Step: 13
Training loss: 2.854435223569917
Validation loss: 2.596029806502968

Epoch: 293| Step: 0
Training loss: 2.717678165719178
Validation loss: 2.5991374665995743

Epoch: 6| Step: 1
Training loss: 3.135704627178895
Validation loss: 2.6099133387210824

Epoch: 6| Step: 2
Training loss: 2.882298865732665
Validation loss: 2.5943872030088295

Epoch: 6| Step: 3
Training loss: 2.5167360873047633
Validation loss: 2.5977845050423336

Epoch: 6| Step: 4
Training loss: 2.792066393650322
Validation loss: 2.5915273371411534

Epoch: 6| Step: 5
Training loss: 2.6704267179415346
Validation loss: 2.5721129142244705

Epoch: 6| Step: 6
Training loss: 3.1397066054584424
Validation loss: 2.579547134601182

Epoch: 6| Step: 7
Training loss: 3.1018934865996726
Validation loss: 2.5706504960854617

Epoch: 6| Step: 8
Training loss: 2.943250506032364
Validation loss: 2.571874154156693

Epoch: 6| Step: 9
Training loss: 2.7366374220158645
Validation loss: 2.569195526587229

Epoch: 6| Step: 10
Training loss: 3.252379206790122
Validation loss: 2.568376413581484

Epoch: 6| Step: 11
Training loss: 3.1948813448320976
Validation loss: 2.576116670249969

Epoch: 6| Step: 12
Training loss: 2.9705759958005067
Validation loss: 2.5704627824855977

Epoch: 6| Step: 13
Training loss: 2.3555696633454275
Validation loss: 2.569935560272846

Epoch: 294| Step: 0
Training loss: 2.871916402657386
Validation loss: 2.575955418913178

Epoch: 6| Step: 1
Training loss: 3.106328804352023
Validation loss: 2.5921077172025875

Epoch: 6| Step: 2
Training loss: 2.6162843882583062
Validation loss: 2.5922912101008997

Epoch: 6| Step: 3
Training loss: 2.7683885635510146
Validation loss: 2.621151088362953

Epoch: 6| Step: 4
Training loss: 3.0135922869533736
Validation loss: 2.647603145936037

Epoch: 6| Step: 5
Training loss: 3.1358597316707053
Validation loss: 2.627327646344192

Epoch: 6| Step: 6
Training loss: 2.6435985188114532
Validation loss: 2.6295209082372164

Epoch: 6| Step: 7
Training loss: 2.363712592996458
Validation loss: 2.6113626112726096

Epoch: 6| Step: 8
Training loss: 3.1449630914654128
Validation loss: 2.6169971380304515

Epoch: 6| Step: 9
Training loss: 2.702571569689586
Validation loss: 2.5933832630094216

Epoch: 6| Step: 10
Training loss: 2.7802708648894843
Validation loss: 2.590978194773063

Epoch: 6| Step: 11
Training loss: 3.4080100455695734
Validation loss: 2.57949957425543

Epoch: 6| Step: 12
Training loss: 3.187488929878908
Validation loss: 2.5783281123851682

Epoch: 6| Step: 13
Training loss: 2.63940970540518
Validation loss: 2.5734553592492864

Epoch: 295| Step: 0
Training loss: 3.38630633279519
Validation loss: 2.565150717002716

Epoch: 6| Step: 1
Training loss: 2.617162539234983
Validation loss: 2.5729523297122037

Epoch: 6| Step: 2
Training loss: 3.264308390250927
Validation loss: 2.5602235103749575

Epoch: 6| Step: 3
Training loss: 3.3046944259679196
Validation loss: 2.567103375168664

Epoch: 6| Step: 4
Training loss: 2.904624402293005
Validation loss: 2.5645731221611667

Epoch: 6| Step: 5
Training loss: 2.150142256887557
Validation loss: 2.5725362243273597

Epoch: 6| Step: 6
Training loss: 2.139273000743525
Validation loss: 2.5651853743539594

Epoch: 6| Step: 7
Training loss: 3.2146239269278682
Validation loss: 2.5650148754195863

Epoch: 6| Step: 8
Training loss: 3.0193780660327465
Validation loss: 2.5772042398704356

Epoch: 6| Step: 9
Training loss: 2.955803680600996
Validation loss: 2.5671808783127275

Epoch: 6| Step: 10
Training loss: 3.3377097646108056
Validation loss: 2.5745375975407225

Epoch: 6| Step: 11
Training loss: 2.526918826575859
Validation loss: 2.5690896368420457

Epoch: 6| Step: 12
Training loss: 2.8584911877461443
Validation loss: 2.567456580758255

Epoch: 6| Step: 13
Training loss: 2.343786315636619
Validation loss: 2.5688312410384477

Epoch: 296| Step: 0
Training loss: 3.070179866032288
Validation loss: 2.582102650802614

Epoch: 6| Step: 1
Training loss: 2.693023151659401
Validation loss: 2.5768159239471387

Epoch: 6| Step: 2
Training loss: 2.6805804574849628
Validation loss: 2.5623492895147253

Epoch: 6| Step: 3
Training loss: 2.8349072815603593
Validation loss: 2.560688126568791

Epoch: 6| Step: 4
Training loss: 2.635599082292868
Validation loss: 2.567494851507092

Epoch: 6| Step: 5
Training loss: 2.5030497069351587
Validation loss: 2.5709266481190314

Epoch: 6| Step: 6
Training loss: 3.141782936217992
Validation loss: 2.5650682662434643

Epoch: 6| Step: 7
Training loss: 3.3201797997379434
Validation loss: 2.5635835301143217

Epoch: 6| Step: 8
Training loss: 2.9838569550987546
Validation loss: 2.5565578285877137

Epoch: 6| Step: 9
Training loss: 3.2463750430449316
Validation loss: 2.558614857466109

Epoch: 6| Step: 10
Training loss: 2.4747644871103587
Validation loss: 2.5616241016577543

Epoch: 6| Step: 11
Training loss: 3.396682882622771
Validation loss: 2.559248843945191

Epoch: 6| Step: 12
Training loss: 2.696914241147238
Validation loss: 2.5581372927638304

Epoch: 6| Step: 13
Training loss: 2.757020744807442
Validation loss: 2.552825453850488

Epoch: 297| Step: 0
Training loss: 3.1335547274297544
Validation loss: 2.559922119929678

Epoch: 6| Step: 1
Training loss: 1.8063542319454093
Validation loss: 2.560489022531802

Epoch: 6| Step: 2
Training loss: 2.712106326317286
Validation loss: 2.566712738044991

Epoch: 6| Step: 3
Training loss: 2.9428794788565833
Validation loss: 2.562496572472706

Epoch: 6| Step: 4
Training loss: 3.4607561808809733
Validation loss: 2.5565164469247827

Epoch: 6| Step: 5
Training loss: 2.9020708451249964
Validation loss: 2.5611132959741156

Epoch: 6| Step: 6
Training loss: 2.8187748740847476
Validation loss: 2.581814361702276

Epoch: 6| Step: 7
Training loss: 3.3738245859908207
Validation loss: 2.5803256549434375

Epoch: 6| Step: 8
Training loss: 3.1288958869600547
Validation loss: 2.588399231537235

Epoch: 6| Step: 9
Training loss: 2.722867281601388
Validation loss: 2.6140161211234876

Epoch: 6| Step: 10
Training loss: 2.9776325855474783
Validation loss: 2.607981287453633

Epoch: 6| Step: 11
Training loss: 2.553568743800563
Validation loss: 2.604715550485681

Epoch: 6| Step: 12
Training loss: 2.6718248507606353
Validation loss: 2.6034972290652503

Epoch: 6| Step: 13
Training loss: 3.042592643637526
Validation loss: 2.6000419710335527

Epoch: 298| Step: 0
Training loss: 3.2278210861560153
Validation loss: 2.5892166390351803

Epoch: 6| Step: 1
Training loss: 3.088392454577496
Validation loss: 2.588539488159248

Epoch: 6| Step: 2
Training loss: 2.3754078364301527
Validation loss: 2.57864522200475

Epoch: 6| Step: 3
Training loss: 2.7455458548931215
Validation loss: 2.580163150426042

Epoch: 6| Step: 4
Training loss: 2.445438662068416
Validation loss: 2.5661730050104223

Epoch: 6| Step: 5
Training loss: 3.581086777833787
Validation loss: 2.5615643439564826

Epoch: 6| Step: 6
Training loss: 2.703889418987453
Validation loss: 2.563309357346163

Epoch: 6| Step: 7
Training loss: 3.433353211675584
Validation loss: 2.571428430916645

Epoch: 6| Step: 8
Training loss: 2.339991493209635
Validation loss: 2.5625280293178005

Epoch: 6| Step: 9
Training loss: 2.9529567448554515
Validation loss: 2.5604223632175076

Epoch: 6| Step: 10
Training loss: 2.948073006697735
Validation loss: 2.5655039895711043

Epoch: 6| Step: 11
Training loss: 2.883280728986686
Validation loss: 2.5655688845815146

Epoch: 6| Step: 12
Training loss: 2.912615787676695
Validation loss: 2.5743023855381217

Epoch: 6| Step: 13
Training loss: 2.474100905208608
Validation loss: 2.5659545275134463

Epoch: 299| Step: 0
Training loss: 2.4674938241249413
Validation loss: 2.5741619776260056

Epoch: 6| Step: 1
Training loss: 3.222509762295658
Validation loss: 2.57546374259585

Epoch: 6| Step: 2
Training loss: 3.385338665968411
Validation loss: 2.5999341073296383

Epoch: 6| Step: 3
Training loss: 2.4881122238264277
Validation loss: 2.5896412844171195

Epoch: 6| Step: 4
Training loss: 2.978370257723147
Validation loss: 2.5969558801747947

Epoch: 6| Step: 5
Training loss: 2.920371091855956
Validation loss: 2.59324647829752

Epoch: 6| Step: 6
Training loss: 2.862977473653685
Validation loss: 2.60092272386097

Epoch: 6| Step: 7
Training loss: 3.1874991024240464
Validation loss: 2.5953102168456494

Epoch: 6| Step: 8
Training loss: 2.928242156495121
Validation loss: 2.606778295120139

Epoch: 6| Step: 9
Training loss: 3.3030902438469014
Validation loss: 2.6065445929093016

Epoch: 6| Step: 10
Training loss: 2.698309252440843
Validation loss: 2.6276156163028936

Epoch: 6| Step: 11
Training loss: 2.7799984119602854
Validation loss: 2.6079155476445224

Epoch: 6| Step: 12
Training loss: 2.272614844749207
Validation loss: 2.6134289360525784

Epoch: 6| Step: 13
Training loss: 2.7956721100653183
Validation loss: 2.585961683553253

Epoch: 300| Step: 0
Training loss: 2.6605443909369826
Validation loss: 2.5754957388345643

Epoch: 6| Step: 1
Training loss: 3.519488166096591
Validation loss: 2.5746235318297943

Epoch: 6| Step: 2
Training loss: 2.8100110378930996
Validation loss: 2.570116526529731

Epoch: 6| Step: 3
Training loss: 3.0452463345412815
Validation loss: 2.5653333149427455

Epoch: 6| Step: 4
Training loss: 2.6943475295090886
Validation loss: 2.555380350051363

Epoch: 6| Step: 5
Training loss: 2.983653036139336
Validation loss: 2.5544533013985666

Epoch: 6| Step: 6
Training loss: 3.5419628393462936
Validation loss: 2.564748387419929

Epoch: 6| Step: 7
Training loss: 3.034623304239393
Validation loss: 2.565691943069254

Epoch: 6| Step: 8
Training loss: 2.547023839053444
Validation loss: 2.572456695052789

Epoch: 6| Step: 9
Training loss: 2.592686998323719
Validation loss: 2.5628977926269183

Epoch: 6| Step: 10
Training loss: 2.598095849492827
Validation loss: 2.5576628313369705

Epoch: 6| Step: 11
Training loss: 2.6246230445139083
Validation loss: 2.5692662134485693

Epoch: 6| Step: 12
Training loss: 2.4285665299662704
Validation loss: 2.5665454660359712

Epoch: 6| Step: 13
Training loss: 3.356087570948427
Validation loss: 2.5717378482999016

Epoch: 301| Step: 0
Training loss: 3.0450848920542257
Validation loss: 2.568908433584476

Epoch: 6| Step: 1
Training loss: 3.0770097445239766
Validation loss: 2.5738687881288733

Epoch: 6| Step: 2
Training loss: 2.3905910913393806
Validation loss: 2.5829895662772526

Epoch: 6| Step: 3
Training loss: 2.9661047142512214
Validation loss: 2.5813275127615825

Epoch: 6| Step: 4
Training loss: 2.549626648442425
Validation loss: 2.6082156757655652

Epoch: 6| Step: 5
Training loss: 3.1349956107222936
Validation loss: 2.597834956606316

Epoch: 6| Step: 6
Training loss: 2.8464550525112453
Validation loss: 2.6117411115769666

Epoch: 6| Step: 7
Training loss: 3.35123696335701
Validation loss: 2.5958056516871193

Epoch: 6| Step: 8
Training loss: 2.696177645063061
Validation loss: 2.5876065820832497

Epoch: 6| Step: 9
Training loss: 3.665724517694152
Validation loss: 2.576580550792601

Epoch: 6| Step: 10
Training loss: 2.785262652875256
Validation loss: 2.572290657659108

Epoch: 6| Step: 11
Training loss: 2.3517319120804583
Validation loss: 2.565560497875879

Epoch: 6| Step: 12
Training loss: 2.466743426374393
Validation loss: 2.5551555538816975

Epoch: 6| Step: 13
Training loss: 3.0528710469545706
Validation loss: 2.556692582342807

Epoch: 302| Step: 0
Training loss: 2.94028649160417
Validation loss: 2.5534074008480925

Epoch: 6| Step: 1
Training loss: 2.366140606221068
Validation loss: 2.553623778426881

Epoch: 6| Step: 2
Training loss: 3.2003168962446766
Validation loss: 2.5647590737800683

Epoch: 6| Step: 3
Training loss: 2.7806552722575204
Validation loss: 2.560366472946289

Epoch: 6| Step: 4
Training loss: 3.2874308183592316
Validation loss: 2.5525213930835804

Epoch: 6| Step: 5
Training loss: 3.046675768476228
Validation loss: 2.5641034499743487

Epoch: 6| Step: 6
Training loss: 1.962608628394903
Validation loss: 2.5565792155863414

Epoch: 6| Step: 7
Training loss: 2.7909582197560443
Validation loss: 2.550582978791812

Epoch: 6| Step: 8
Training loss: 3.118485641742464
Validation loss: 2.5577412119037293

Epoch: 6| Step: 9
Training loss: 3.445007449115733
Validation loss: 2.562251271267582

Epoch: 6| Step: 10
Training loss: 3.341335672806481
Validation loss: 2.5634059490082395

Epoch: 6| Step: 11
Training loss: 2.8079694072545798
Validation loss: 2.580272625527915

Epoch: 6| Step: 12
Training loss: 2.4972215471654575
Validation loss: 2.5756954196692856

Epoch: 6| Step: 13
Training loss: 2.083686785914729
Validation loss: 2.585288946655579

Epoch: 303| Step: 0
Training loss: 2.9914011108641216
Validation loss: 2.620659045205884

Epoch: 6| Step: 1
Training loss: 2.9061236610434125
Validation loss: 2.6236501788874835

Epoch: 6| Step: 2
Training loss: 2.7997689219899073
Validation loss: 2.620375736669652

Epoch: 6| Step: 3
Training loss: 3.082586008869046
Validation loss: 2.6352944926789776

Epoch: 6| Step: 4
Training loss: 3.1855578021827453
Validation loss: 2.627474849243315

Epoch: 6| Step: 5
Training loss: 2.9679659159366403
Validation loss: 2.590581635340897

Epoch: 6| Step: 6
Training loss: 3.380000189831971
Validation loss: 2.574112970286783

Epoch: 6| Step: 7
Training loss: 3.367356015124147
Validation loss: 2.5589543149666647

Epoch: 6| Step: 8
Training loss: 2.7550338276415
Validation loss: 2.56057089787787

Epoch: 6| Step: 9
Training loss: 2.176197388882364
Validation loss: 2.558696474168847

Epoch: 6| Step: 10
Training loss: 2.3302246456970757
Validation loss: 2.551709237889892

Epoch: 6| Step: 11
Training loss: 2.8745627692749993
Validation loss: 2.552045472705329

Epoch: 6| Step: 12
Training loss: 2.53862554458296
Validation loss: 2.5487117650407587

Epoch: 6| Step: 13
Training loss: 3.0250961918945394
Validation loss: 2.552851093889411

Epoch: 304| Step: 0
Training loss: 3.2186074827178937
Validation loss: 2.551182356597845

Epoch: 6| Step: 1
Training loss: 2.6918547191613156
Validation loss: 2.549338670051336

Epoch: 6| Step: 2
Training loss: 2.517441182817933
Validation loss: 2.551458692588204

Epoch: 6| Step: 3
Training loss: 3.0488031008742413
Validation loss: 2.548696615777162

Epoch: 6| Step: 4
Training loss: 2.1404051284919654
Validation loss: 2.550318310065018

Epoch: 6| Step: 5
Training loss: 3.5027785852202586
Validation loss: 2.558935923781715

Epoch: 6| Step: 6
Training loss: 2.9597036563890273
Validation loss: 2.564593781563369

Epoch: 6| Step: 7
Training loss: 2.6190825476526043
Validation loss: 2.562601569178931

Epoch: 6| Step: 8
Training loss: 3.0527512445551164
Validation loss: 2.573697199971528

Epoch: 6| Step: 9
Training loss: 2.7477765197723603
Validation loss: 2.582846489647368

Epoch: 6| Step: 10
Training loss: 3.0540734964256875
Validation loss: 2.5752016837758758

Epoch: 6| Step: 11
Training loss: 2.6070151251093323
Validation loss: 2.589161143086439

Epoch: 6| Step: 12
Training loss: 3.0973606810438725
Validation loss: 2.597295917738176

Epoch: 6| Step: 13
Training loss: 3.080795291675743
Validation loss: 2.5838673876821994

Epoch: 305| Step: 0
Training loss: 2.2962190898212373
Validation loss: 2.5998677725728703

Epoch: 6| Step: 1
Training loss: 2.9192235003039015
Validation loss: 2.6031512210576495

Epoch: 6| Step: 2
Training loss: 2.7612312890278403
Validation loss: 2.6091217484024067

Epoch: 6| Step: 3
Training loss: 3.2659619901259207
Validation loss: 2.5862835429904445

Epoch: 6| Step: 4
Training loss: 2.6795906961377747
Validation loss: 2.58891181002034

Epoch: 6| Step: 5
Training loss: 2.8021342522250205
Validation loss: 2.601987336535274

Epoch: 6| Step: 6
Training loss: 2.9876114636939666
Validation loss: 2.6019364797420717

Epoch: 6| Step: 7
Training loss: 3.529541277379136
Validation loss: 2.6096545241575395

Epoch: 6| Step: 8
Training loss: 2.807309171283528
Validation loss: 2.6038742596935682

Epoch: 6| Step: 9
Training loss: 3.431688007685472
Validation loss: 2.600892976296335

Epoch: 6| Step: 10
Training loss: 2.7194796054564203
Validation loss: 2.568580861754901

Epoch: 6| Step: 11
Training loss: 2.025634868613088
Validation loss: 2.5636451577463473

Epoch: 6| Step: 12
Training loss: 2.909878834040412
Validation loss: 2.551846753209469

Epoch: 6| Step: 13
Training loss: 3.1344686872604126
Validation loss: 2.5491297087880125

Epoch: 306| Step: 0
Training loss: 2.8352635110772497
Validation loss: 2.548759804338314

Epoch: 6| Step: 1
Training loss: 2.034032705548564
Validation loss: 2.5439085407349897

Epoch: 6| Step: 2
Training loss: 2.9039399184850394
Validation loss: 2.546340706161315

Epoch: 6| Step: 3
Training loss: 3.496361339707018
Validation loss: 2.539426882512307

Epoch: 6| Step: 4
Training loss: 2.117929026119661
Validation loss: 2.545685740664783

Epoch: 6| Step: 5
Training loss: 3.4124796884232684
Validation loss: 2.5488366985227926

Epoch: 6| Step: 6
Training loss: 2.940039977236538
Validation loss: 2.5451341894503026

Epoch: 6| Step: 7
Training loss: 3.0659782742740225
Validation loss: 2.5478131124033574

Epoch: 6| Step: 8
Training loss: 2.9657034249583303
Validation loss: 2.550254692678826

Epoch: 6| Step: 9
Training loss: 2.570462579027017
Validation loss: 2.5511713470722674

Epoch: 6| Step: 10
Training loss: 3.061828539671622
Validation loss: 2.562381688129693

Epoch: 6| Step: 11
Training loss: 2.809906166111871
Validation loss: 2.555583674117283

Epoch: 6| Step: 12
Training loss: 2.9163598217092788
Validation loss: 2.5815699268552823

Epoch: 6| Step: 13
Training loss: 3.1011928847380017
Validation loss: 2.58202008209015

Epoch: 307| Step: 0
Training loss: 2.6305175196650277
Validation loss: 2.59627681192403

Epoch: 6| Step: 1
Training loss: 2.7033671893513516
Validation loss: 2.5981795699269625

Epoch: 6| Step: 2
Training loss: 2.868207453866105
Validation loss: 2.626314493307475

Epoch: 6| Step: 3
Training loss: 3.6669435541049307
Validation loss: 2.631378718200307

Epoch: 6| Step: 4
Training loss: 3.1112095007400447
Validation loss: 2.6487729891617797

Epoch: 6| Step: 5
Training loss: 2.1625174505158102
Validation loss: 2.629446912701858

Epoch: 6| Step: 6
Training loss: 2.8873173115063433
Validation loss: 2.600829292890875

Epoch: 6| Step: 7
Training loss: 2.9944097568419252
Validation loss: 2.5863340979739236

Epoch: 6| Step: 8
Training loss: 2.7117691743119536
Validation loss: 2.5693414771872227

Epoch: 6| Step: 9
Training loss: 2.944395858635702
Validation loss: 2.57405884879888

Epoch: 6| Step: 10
Training loss: 2.754092725568228
Validation loss: 2.5646790184558146

Epoch: 6| Step: 11
Training loss: 3.2222891303675807
Validation loss: 2.5532144845291946

Epoch: 6| Step: 12
Training loss: 2.7366634710698245
Validation loss: 2.548898477525945

Epoch: 6| Step: 13
Training loss: 2.9514499333869026
Validation loss: 2.5515461225482454

Epoch: 308| Step: 0
Training loss: 2.825237169690793
Validation loss: 2.546141339042377

Epoch: 6| Step: 1
Training loss: 2.4937827048391923
Validation loss: 2.546845480780969

Epoch: 6| Step: 2
Training loss: 2.608543217738789
Validation loss: 2.5464888737422986

Epoch: 6| Step: 3
Training loss: 2.934784628457374
Validation loss: 2.548723677382323

Epoch: 6| Step: 4
Training loss: 2.423858322705472
Validation loss: 2.5456748020308564

Epoch: 6| Step: 5
Training loss: 2.9845906923650602
Validation loss: 2.5418717476264714

Epoch: 6| Step: 6
Training loss: 2.76267097599965
Validation loss: 2.5439094915531695

Epoch: 6| Step: 7
Training loss: 2.943138878757807
Validation loss: 2.552245712555688

Epoch: 6| Step: 8
Training loss: 3.019252986349613
Validation loss: 2.5474907438813332

Epoch: 6| Step: 9
Training loss: 3.3731316940696385
Validation loss: 2.5497581871160784

Epoch: 6| Step: 10
Training loss: 3.198481771799122
Validation loss: 2.5561689396723075

Epoch: 6| Step: 11
Training loss: 2.8174093843525982
Validation loss: 2.5577960675500933

Epoch: 6| Step: 12
Training loss: 3.2122066616210874
Validation loss: 2.5552460638518757

Epoch: 6| Step: 13
Training loss: 2.739408035375041
Validation loss: 2.563849535239178

Epoch: 309| Step: 0
Training loss: 2.9075872154635953
Validation loss: 2.570050055577111

Epoch: 6| Step: 1
Training loss: 3.2387490297034107
Validation loss: 2.5835429092354847

Epoch: 6| Step: 2
Training loss: 2.0598385140167914
Validation loss: 2.5776514577407594

Epoch: 6| Step: 3
Training loss: 2.7651147748914067
Validation loss: 2.5695228414669473

Epoch: 6| Step: 4
Training loss: 3.1488612341834874
Validation loss: 2.566913056170351

Epoch: 6| Step: 5
Training loss: 2.9478970224829046
Validation loss: 2.5706578439832937

Epoch: 6| Step: 6
Training loss: 3.113899657742878
Validation loss: 2.575413956717066

Epoch: 6| Step: 7
Training loss: 3.156920862191379
Validation loss: 2.574471434916547

Epoch: 6| Step: 8
Training loss: 2.7508101570411156
Validation loss: 2.5820384225368267

Epoch: 6| Step: 9
Training loss: 2.526171829697889
Validation loss: 2.582356414766149

Epoch: 6| Step: 10
Training loss: 2.824172994366991
Validation loss: 2.591855860488982

Epoch: 6| Step: 11
Training loss: 2.539543505370153
Validation loss: 2.584571228858643

Epoch: 6| Step: 12
Training loss: 3.0454140314955502
Validation loss: 2.5824669563773095

Epoch: 6| Step: 13
Training loss: 3.226540627763336
Validation loss: 2.5846652842274183

Epoch: 310| Step: 0
Training loss: 2.8930157646543466
Validation loss: 2.590130335772263

Epoch: 6| Step: 1
Training loss: 3.3405670988883447
Validation loss: 2.5939331118542355

Epoch: 6| Step: 2
Training loss: 2.7583031582598405
Validation loss: 2.5788972574915805

Epoch: 6| Step: 3
Training loss: 2.914215983830821
Validation loss: 2.5744976221476943

Epoch: 6| Step: 4
Training loss: 2.6408306696324524
Validation loss: 2.58676842153138

Epoch: 6| Step: 5
Training loss: 2.9205260401294524
Validation loss: 2.571213801430956

Epoch: 6| Step: 6
Training loss: 3.092272164687793
Validation loss: 2.5705956813813895

Epoch: 6| Step: 7
Training loss: 2.3903014518850525
Validation loss: 2.572415540248999

Epoch: 6| Step: 8
Training loss: 2.543538066461426
Validation loss: 2.559023453919973

Epoch: 6| Step: 9
Training loss: 3.0649267429975233
Validation loss: 2.556495109540801

Epoch: 6| Step: 10
Training loss: 2.8733708285240334
Validation loss: 2.5489152851225554

Epoch: 6| Step: 11
Training loss: 3.1150748759129283
Validation loss: 2.5636316117344546

Epoch: 6| Step: 12
Training loss: 2.58660870741114
Validation loss: 2.5557342980705244

Epoch: 6| Step: 13
Training loss: 3.207197029391764
Validation loss: 2.5465513751392783

Epoch: 311| Step: 0
Training loss: 2.61731047839568
Validation loss: 2.5500562166616008

Epoch: 6| Step: 1
Training loss: 3.279435591635033
Validation loss: 2.5583894261174565

Epoch: 6| Step: 2
Training loss: 2.4026387847604975
Validation loss: 2.5613530170928565

Epoch: 6| Step: 3
Training loss: 3.042121661570488
Validation loss: 2.556783617452467

Epoch: 6| Step: 4
Training loss: 2.291446004705428
Validation loss: 2.564885687415787

Epoch: 6| Step: 5
Training loss: 2.5327592282867473
Validation loss: 2.5593831605252904

Epoch: 6| Step: 6
Training loss: 2.655438108343181
Validation loss: 2.560506034388894

Epoch: 6| Step: 7
Training loss: 3.0150144285043408
Validation loss: 2.5720221695101193

Epoch: 6| Step: 8
Training loss: 3.237381427022204
Validation loss: 2.5571177955042734

Epoch: 6| Step: 9
Training loss: 3.144766283432998
Validation loss: 2.571038456913897

Epoch: 6| Step: 10
Training loss: 2.889994454560025
Validation loss: 2.584691224358817

Epoch: 6| Step: 11
Training loss: 3.1244094290594355
Validation loss: 2.5769605177601687

Epoch: 6| Step: 12
Training loss: 2.954887389023738
Validation loss: 2.571015519999659

Epoch: 6| Step: 13
Training loss: 3.0544633319681367
Validation loss: 2.574924496799095

Epoch: 312| Step: 0
Training loss: 3.189101172310381
Validation loss: 2.576894458134403

Epoch: 6| Step: 1
Training loss: 2.200447565849109
Validation loss: 2.5526951648921923

Epoch: 6| Step: 2
Training loss: 2.9600564657444473
Validation loss: 2.5473246506814125

Epoch: 6| Step: 3
Training loss: 2.7320333863169015
Validation loss: 2.5453529482963293

Epoch: 6| Step: 4
Training loss: 2.5176494342657483
Validation loss: 2.543506894842328

Epoch: 6| Step: 5
Training loss: 2.4351805386205494
Validation loss: 2.543541972084057

Epoch: 6| Step: 6
Training loss: 3.0254423212174566
Validation loss: 2.5456542750972084

Epoch: 6| Step: 7
Training loss: 2.4401322847996947
Validation loss: 2.546130066068778

Epoch: 6| Step: 8
Training loss: 2.919968743091666
Validation loss: 2.5514238618423732

Epoch: 6| Step: 9
Training loss: 2.7794354981241103
Validation loss: 2.5530898747212074

Epoch: 6| Step: 10
Training loss: 2.727991817059368
Validation loss: 2.5532973040126055

Epoch: 6| Step: 11
Training loss: 3.5077350157610105
Validation loss: 2.551162141279696

Epoch: 6| Step: 12
Training loss: 3.490669620402898
Validation loss: 2.552774052489248

Epoch: 6| Step: 13
Training loss: 3.2997792545816282
Validation loss: 2.5592892248039085

Epoch: 313| Step: 0
Training loss: 3.4179118298831916
Validation loss: 2.5572209694404036

Epoch: 6| Step: 1
Training loss: 2.47449433526751
Validation loss: 2.5537176053176536

Epoch: 6| Step: 2
Training loss: 2.3943032285268875
Validation loss: 2.5558336615847015

Epoch: 6| Step: 3
Training loss: 2.9121021703046357
Validation loss: 2.560604475864703

Epoch: 6| Step: 4
Training loss: 2.962840090517465
Validation loss: 2.564034081558936

Epoch: 6| Step: 5
Training loss: 3.65312922390187
Validation loss: 2.580004247620731

Epoch: 6| Step: 6
Training loss: 2.476504544804433
Validation loss: 2.5835818873410146

Epoch: 6| Step: 7
Training loss: 2.910168211227516
Validation loss: 2.582533650733883

Epoch: 6| Step: 8
Training loss: 3.219054568797263
Validation loss: 2.6094758862430893

Epoch: 6| Step: 9
Training loss: 2.2859951468321915
Validation loss: 2.604112533170765

Epoch: 6| Step: 10
Training loss: 3.436094378142208
Validation loss: 2.6236584580753903

Epoch: 6| Step: 11
Training loss: 3.002558570817796
Validation loss: 2.607927663373295

Epoch: 6| Step: 12
Training loss: 2.0785870719549475
Validation loss: 2.5864688932166175

Epoch: 6| Step: 13
Training loss: 2.410377529379363
Validation loss: 2.5926330648295006

Epoch: 314| Step: 0
Training loss: 3.0863115687542417
Validation loss: 2.5815282609150922

Epoch: 6| Step: 1
Training loss: 3.4852318501348423
Validation loss: 2.570622378813402

Epoch: 6| Step: 2
Training loss: 2.906507091020734
Validation loss: 2.5563679579834657

Epoch: 6| Step: 3
Training loss: 2.8460053942502572
Validation loss: 2.558534228131889

Epoch: 6| Step: 4
Training loss: 2.184713387099267
Validation loss: 2.557835374861253

Epoch: 6| Step: 5
Training loss: 2.762742086306505
Validation loss: 2.5490358533216524

Epoch: 6| Step: 6
Training loss: 3.179441250350242
Validation loss: 2.544886107590025

Epoch: 6| Step: 7
Training loss: 3.0743423689110716
Validation loss: 2.539300062552709

Epoch: 6| Step: 8
Training loss: 2.224437355310096
Validation loss: 2.5435975572632064

Epoch: 6| Step: 9
Training loss: 2.9232235004956597
Validation loss: 2.548112786027243

Epoch: 6| Step: 10
Training loss: 3.017990054559721
Validation loss: 2.546186304580792

Epoch: 6| Step: 11
Training loss: 2.39004210303343
Validation loss: 2.5411404425190094

Epoch: 6| Step: 12
Training loss: 2.926902484850282
Validation loss: 2.5480881728281117

Epoch: 6| Step: 13
Training loss: 2.969687865838397
Validation loss: 2.5552603997543155

Epoch: 315| Step: 0
Training loss: 2.710164424370374
Validation loss: 2.5473920411945405

Epoch: 6| Step: 1
Training loss: 3.2044076723918553
Validation loss: 2.552957598922607

Epoch: 6| Step: 2
Training loss: 3.0472507342945527
Validation loss: 2.548887867491222

Epoch: 6| Step: 3
Training loss: 3.015434931166096
Validation loss: 2.57216971488132

Epoch: 6| Step: 4
Training loss: 2.776679580615704
Validation loss: 2.5678783852074427

Epoch: 6| Step: 5
Training loss: 3.0799942150309345
Validation loss: 2.5700821401608924

Epoch: 6| Step: 6
Training loss: 2.7447235465720285
Validation loss: 2.6068803306661565

Epoch: 6| Step: 7
Training loss: 2.6401068726495205
Validation loss: 2.62399950703537

Epoch: 6| Step: 8
Training loss: 2.700815791051812
Validation loss: 2.6484930606335224

Epoch: 6| Step: 9
Training loss: 2.5467819477705085
Validation loss: 2.6957451937784507

Epoch: 6| Step: 10
Training loss: 2.7470355094389314
Validation loss: 2.682309628617745

Epoch: 6| Step: 11
Training loss: 3.1067845274161643
Validation loss: 2.693957721200765

Epoch: 6| Step: 12
Training loss: 3.259430481245574
Validation loss: 2.6368574116174486

Epoch: 6| Step: 13
Training loss: 2.74818082806964
Validation loss: 2.6007919375030606

Epoch: 316| Step: 0
Training loss: 3.1691940327567107
Validation loss: 2.561715527942494

Epoch: 6| Step: 1
Training loss: 3.232447690370857
Validation loss: 2.535489862027052

Epoch: 6| Step: 2
Training loss: 3.1764946730953487
Validation loss: 2.533019565063902

Epoch: 6| Step: 3
Training loss: 2.5298005651944586
Validation loss: 2.5387015844249112

Epoch: 6| Step: 4
Training loss: 2.688803245907487
Validation loss: 2.5367759365424893

Epoch: 6| Step: 5
Training loss: 3.0005775531496965
Validation loss: 2.53660683492922

Epoch: 6| Step: 6
Training loss: 2.6222878932362534
Validation loss: 2.5448849390411414

Epoch: 6| Step: 7
Training loss: 2.72093533786711
Validation loss: 2.540469226618349

Epoch: 6| Step: 8
Training loss: 3.07685105349536
Validation loss: 2.5469524573837976

Epoch: 6| Step: 9
Training loss: 2.758626239664151
Validation loss: 2.544193231162425

Epoch: 6| Step: 10
Training loss: 2.3311267932723556
Validation loss: 2.541617401253465

Epoch: 6| Step: 11
Training loss: 2.9129566211240245
Validation loss: 2.5492372502472915

Epoch: 6| Step: 12
Training loss: 3.194982087229868
Validation loss: 2.5617079522425015

Epoch: 6| Step: 13
Training loss: 3.0369069905940553
Validation loss: 2.5505545880289904

Epoch: 317| Step: 0
Training loss: 2.6325761366337233
Validation loss: 2.558004277771068

Epoch: 6| Step: 1
Training loss: 2.434688022061658
Validation loss: 2.5566180542713575

Epoch: 6| Step: 2
Training loss: 3.305603766067516
Validation loss: 2.588828393940079

Epoch: 6| Step: 3
Training loss: 2.077198940823507
Validation loss: 2.6024365420058526

Epoch: 6| Step: 4
Training loss: 2.900399502827322
Validation loss: 2.6226453108387435

Epoch: 6| Step: 5
Training loss: 2.765160386881644
Validation loss: 2.6311821758291947

Epoch: 6| Step: 6
Training loss: 3.2317506029764838
Validation loss: 2.6171390808749586

Epoch: 6| Step: 7
Training loss: 3.278749075979262
Validation loss: 2.61550486212738

Epoch: 6| Step: 8
Training loss: 2.636307747915165
Validation loss: 2.592493208659943

Epoch: 6| Step: 9
Training loss: 2.9015681795178665
Validation loss: 2.571472212543518

Epoch: 6| Step: 10
Training loss: 3.1659448369823866
Validation loss: 2.561568724500541

Epoch: 6| Step: 11
Training loss: 2.572651178868749
Validation loss: 2.5576089461230778

Epoch: 6| Step: 12
Training loss: 3.1157458803225704
Validation loss: 2.5406403041909873

Epoch: 6| Step: 13
Training loss: 3.4783389235632707
Validation loss: 2.539911428287505

Epoch: 318| Step: 0
Training loss: 2.7840030203342496
Validation loss: 2.534150765975328

Epoch: 6| Step: 1
Training loss: 2.53685074942408
Validation loss: 2.5424780966698672

Epoch: 6| Step: 2
Training loss: 3.076343931200188
Validation loss: 2.5400592099033066

Epoch: 6| Step: 3
Training loss: 2.295496935929414
Validation loss: 2.545929284799442

Epoch: 6| Step: 4
Training loss: 3.0006471571673345
Validation loss: 2.548710324652529

Epoch: 6| Step: 5
Training loss: 2.848170272001909
Validation loss: 2.551992721573019

Epoch: 6| Step: 6
Training loss: 3.187729471959841
Validation loss: 2.552609816074467

Epoch: 6| Step: 7
Training loss: 2.3297527178738155
Validation loss: 2.55057286224419

Epoch: 6| Step: 8
Training loss: 3.5322431669933887
Validation loss: 2.5527858273727704

Epoch: 6| Step: 9
Training loss: 3.004172284830442
Validation loss: 2.5477390319718283

Epoch: 6| Step: 10
Training loss: 2.4673270458452943
Validation loss: 2.5480470228593743

Epoch: 6| Step: 11
Training loss: 3.347718068000557
Validation loss: 2.55705158418342

Epoch: 6| Step: 12
Training loss: 2.39333992177044
Validation loss: 2.5575355894813163

Epoch: 6| Step: 13
Training loss: 3.1862895387551133
Validation loss: 2.554982711986838

Epoch: 319| Step: 0
Training loss: 3.078577153646566
Validation loss: 2.560144035209104

Epoch: 6| Step: 1
Training loss: 3.539356076356503
Validation loss: 2.569045502269888

Epoch: 6| Step: 2
Training loss: 2.735856009358473
Validation loss: 2.5662643081950822

Epoch: 6| Step: 3
Training loss: 3.043884374640673
Validation loss: 2.5622221072962925

Epoch: 6| Step: 4
Training loss: 3.236813717718845
Validation loss: 2.559864804153445

Epoch: 6| Step: 5
Training loss: 2.253812738392702
Validation loss: 2.5499355705336617

Epoch: 6| Step: 6
Training loss: 2.692015115329881
Validation loss: 2.5450684550833564

Epoch: 6| Step: 7
Training loss: 2.6181729866851824
Validation loss: 2.5593946355563584

Epoch: 6| Step: 8
Training loss: 2.483578344287112
Validation loss: 2.5472964580980624

Epoch: 6| Step: 9
Training loss: 2.7878285304227486
Validation loss: 2.564105192659149

Epoch: 6| Step: 10
Training loss: 3.002422308508237
Validation loss: 2.5596787063066375

Epoch: 6| Step: 11
Training loss: 2.823002428016605
Validation loss: 2.567984061344611

Epoch: 6| Step: 12
Training loss: 3.0371980807483827
Validation loss: 2.562642888593074

Epoch: 6| Step: 13
Training loss: 2.572349413735944
Validation loss: 2.5763011617779292

Epoch: 320| Step: 0
Training loss: 3.253658289809442
Validation loss: 2.566589329959029

Epoch: 6| Step: 1
Training loss: 2.944855267476947
Validation loss: 2.558227418652002

Epoch: 6| Step: 2
Training loss: 2.9375618461429114
Validation loss: 2.551116434394454

Epoch: 6| Step: 3
Training loss: 2.3249938185414822
Validation loss: 2.5497541040022327

Epoch: 6| Step: 4
Training loss: 2.1770562591572795
Validation loss: 2.537957415151187

Epoch: 6| Step: 5
Training loss: 2.9285764494796407
Validation loss: 2.538011432744428

Epoch: 6| Step: 6
Training loss: 2.4484071497201567
Validation loss: 2.551299610725052

Epoch: 6| Step: 7
Training loss: 3.804041750898395
Validation loss: 2.5393460477482788

Epoch: 6| Step: 8
Training loss: 3.202592163427398
Validation loss: 2.5426576384784547

Epoch: 6| Step: 9
Training loss: 2.982846652635232
Validation loss: 2.5379243314970417

Epoch: 6| Step: 10
Training loss: 2.595606311976071
Validation loss: 2.552853526124756

Epoch: 6| Step: 11
Training loss: 2.7425543819519547
Validation loss: 2.5571139928260482

Epoch: 6| Step: 12
Training loss: 2.93180327247017
Validation loss: 2.5684312217492367

Epoch: 6| Step: 13
Training loss: 2.2372271067681755
Validation loss: 2.5720972878187425

Epoch: 321| Step: 0
Training loss: 3.0759170281340236
Validation loss: 2.561410623849974

Epoch: 6| Step: 1
Training loss: 2.030821065363447
Validation loss: 2.580845362834673

Epoch: 6| Step: 2
Training loss: 2.81659976119837
Validation loss: 2.57022581413404

Epoch: 6| Step: 3
Training loss: 2.267617553052728
Validation loss: 2.571299877212317

Epoch: 6| Step: 4
Training loss: 2.922252283880454
Validation loss: 2.5594611528619278

Epoch: 6| Step: 5
Training loss: 3.070434878485062
Validation loss: 2.5696826099040155

Epoch: 6| Step: 6
Training loss: 3.1977877181871186
Validation loss: 2.5564636957901308

Epoch: 6| Step: 7
Training loss: 2.9010902460072687
Validation loss: 2.5616848677355675

Epoch: 6| Step: 8
Training loss: 3.1498898925913617
Validation loss: 2.5494653144433377

Epoch: 6| Step: 9
Training loss: 2.7252088974142694
Validation loss: 2.5617396649540067

Epoch: 6| Step: 10
Training loss: 2.0631675795789786
Validation loss: 2.559534710727434

Epoch: 6| Step: 11
Training loss: 3.0968302795691827
Validation loss: 2.551095686952638

Epoch: 6| Step: 12
Training loss: 3.2498028035126607
Validation loss: 2.563248516762298

Epoch: 6| Step: 13
Training loss: 3.2676795446659725
Validation loss: 2.555303835372211

Epoch: 322| Step: 0
Training loss: 2.9114520369150574
Validation loss: 2.54918482919243

Epoch: 6| Step: 1
Training loss: 2.5962719893132684
Validation loss: 2.544548719195923

Epoch: 6| Step: 2
Training loss: 2.1949501688868667
Validation loss: 2.5570222255579784

Epoch: 6| Step: 3
Training loss: 2.6347880662962013
Validation loss: 2.5618202594489543

Epoch: 6| Step: 4
Training loss: 2.7424057224311906
Validation loss: 2.5605868243990284

Epoch: 6| Step: 5
Training loss: 2.4770641119756363
Validation loss: 2.5669693676717293

Epoch: 6| Step: 6
Training loss: 2.9304019311188823
Validation loss: 2.560449105649201

Epoch: 6| Step: 7
Training loss: 3.0515534306560856
Validation loss: 2.5580778604922414

Epoch: 6| Step: 8
Training loss: 3.161595718105212
Validation loss: 2.556448082031698

Epoch: 6| Step: 9
Training loss: 3.0455259809048107
Validation loss: 2.572784265648163

Epoch: 6| Step: 10
Training loss: 3.010749156150709
Validation loss: 2.546374828196144

Epoch: 6| Step: 11
Training loss: 2.7339593189899234
Validation loss: 2.550277553946048

Epoch: 6| Step: 12
Training loss: 3.3915837070776034
Validation loss: 2.555876852749559

Epoch: 6| Step: 13
Training loss: 3.0585418345989153
Validation loss: 2.5586149416311055

Epoch: 323| Step: 0
Training loss: 3.2089906159593906
Validation loss: 2.546576428019677

Epoch: 6| Step: 1
Training loss: 2.6986235253513207
Validation loss: 2.541535599219083

Epoch: 6| Step: 2
Training loss: 2.4945096763779477
Validation loss: 2.548362176442813

Epoch: 6| Step: 3
Training loss: 2.897697745052042
Validation loss: 2.5518240501648823

Epoch: 6| Step: 4
Training loss: 3.196044837952242
Validation loss: 2.552238637096778

Epoch: 6| Step: 5
Training loss: 2.5939477132793742
Validation loss: 2.5428001731399728

Epoch: 6| Step: 6
Training loss: 2.4038540690365107
Validation loss: 2.5501685132480114

Epoch: 6| Step: 7
Training loss: 3.2102917395430772
Validation loss: 2.542461971507921

Epoch: 6| Step: 8
Training loss: 2.8012393592724294
Validation loss: 2.5544271294724874

Epoch: 6| Step: 9
Training loss: 3.097826343306495
Validation loss: 2.542140803164832

Epoch: 6| Step: 10
Training loss: 3.203282198886499
Validation loss: 2.560141966386561

Epoch: 6| Step: 11
Training loss: 2.5236314634058674
Validation loss: 2.5461642473108417

Epoch: 6| Step: 12
Training loss: 2.7605958892413587
Validation loss: 2.539457864956294

Epoch: 6| Step: 13
Training loss: 2.760238833667166
Validation loss: 2.549469822365349

Epoch: 324| Step: 0
Training loss: 2.6894600396493353
Validation loss: 2.5472735564893636

Epoch: 6| Step: 1
Training loss: 2.8627697746720533
Validation loss: 2.553072353552295

Epoch: 6| Step: 2
Training loss: 2.7153584163970494
Validation loss: 2.5550682303730414

Epoch: 6| Step: 3
Training loss: 2.905846680578704
Validation loss: 2.5862912766723865

Epoch: 6| Step: 4
Training loss: 2.477366416247617
Validation loss: 2.567327688372703

Epoch: 6| Step: 5
Training loss: 3.0996246049070546
Validation loss: 2.574301651590382

Epoch: 6| Step: 6
Training loss: 2.328811646657563
Validation loss: 2.558883053210143

Epoch: 6| Step: 7
Training loss: 3.0780459940883977
Validation loss: 2.5521533272549584

Epoch: 6| Step: 8
Training loss: 3.0555097248994443
Validation loss: 2.5630627526186207

Epoch: 6| Step: 9
Training loss: 3.237637703224199
Validation loss: 2.5634343914542033

Epoch: 6| Step: 10
Training loss: 2.9266543543505215
Validation loss: 2.5943227699653533

Epoch: 6| Step: 11
Training loss: 2.822852092909943
Validation loss: 2.5962548602832634

Epoch: 6| Step: 12
Training loss: 2.6302917366527168
Validation loss: 2.603313008499904

Epoch: 6| Step: 13
Training loss: 3.3215740365375264
Validation loss: 2.6102238090541245

Epoch: 325| Step: 0
Training loss: 2.834159861415046
Validation loss: 2.61223924982889

Epoch: 6| Step: 1
Training loss: 3.25762075321879
Validation loss: 2.5878935810365546

Epoch: 6| Step: 2
Training loss: 3.061855326159301
Validation loss: 2.5852579534362152

Epoch: 6| Step: 3
Training loss: 2.7667696895338243
Validation loss: 2.5695049005690884

Epoch: 6| Step: 4
Training loss: 2.831593783561219
Validation loss: 2.5447430772496173

Epoch: 6| Step: 5
Training loss: 2.40408425897837
Validation loss: 2.5567231449924077

Epoch: 6| Step: 6
Training loss: 2.9524186515745083
Validation loss: 2.536985066510683

Epoch: 6| Step: 7
Training loss: 3.1605192713886963
Validation loss: 2.5467691737356994

Epoch: 6| Step: 8
Training loss: 2.032105016487747
Validation loss: 2.543778674880737

Epoch: 6| Step: 9
Training loss: 3.166839360664649
Validation loss: 2.5478870075556777

Epoch: 6| Step: 10
Training loss: 2.7812804316881032
Validation loss: 2.5481589482138034

Epoch: 6| Step: 11
Training loss: 2.746920335067887
Validation loss: 2.5522733462334983

Epoch: 6| Step: 12
Training loss: 3.043188123912081
Validation loss: 2.5494171748094465

Epoch: 6| Step: 13
Training loss: 2.8941628740371677
Validation loss: 2.5484983443426428

Epoch: 326| Step: 0
Training loss: 3.198727151924036
Validation loss: 2.5534557463721304

Epoch: 6| Step: 1
Training loss: 3.1786971365867838
Validation loss: 2.5485940599053216

Epoch: 6| Step: 2
Training loss: 2.4113953309586527
Validation loss: 2.545607232618175

Epoch: 6| Step: 3
Training loss: 2.4017079077874173
Validation loss: 2.559299452142943

Epoch: 6| Step: 4
Training loss: 2.2856204873661916
Validation loss: 2.5532544658185974

Epoch: 6| Step: 5
Training loss: 2.639091994740172
Validation loss: 2.5611517535987263

Epoch: 6| Step: 6
Training loss: 2.655697215286371
Validation loss: 2.5554340133979383

Epoch: 6| Step: 7
Training loss: 3.2203331174380185
Validation loss: 2.5487351259722337

Epoch: 6| Step: 8
Training loss: 2.620762538307514
Validation loss: 2.5754048405660757

Epoch: 6| Step: 9
Training loss: 3.1584303472778936
Validation loss: 2.5620761904040914

Epoch: 6| Step: 10
Training loss: 2.881975088505555
Validation loss: 2.578386359517022

Epoch: 6| Step: 11
Training loss: 2.797607496444524
Validation loss: 2.5780321131206794

Epoch: 6| Step: 12
Training loss: 3.130593443848777
Validation loss: 2.5643346887999643

Epoch: 6| Step: 13
Training loss: 3.458985064273294
Validation loss: 2.570727406632335

Epoch: 327| Step: 0
Training loss: 2.4170766241564325
Validation loss: 2.5960610209479924

Epoch: 6| Step: 1
Training loss: 2.251216771348135
Validation loss: 2.582222833491916

Epoch: 6| Step: 2
Training loss: 2.69599724516459
Validation loss: 2.5788785467736766

Epoch: 6| Step: 3
Training loss: 3.185581901727266
Validation loss: 2.5762818873919304

Epoch: 6| Step: 4
Training loss: 2.1736820305523734
Validation loss: 2.5700283497524796

Epoch: 6| Step: 5
Training loss: 2.8962150340465915
Validation loss: 2.5671207536364595

Epoch: 6| Step: 6
Training loss: 2.8097119393450973
Validation loss: 2.569059940788819

Epoch: 6| Step: 7
Training loss: 3.8402352739817505
Validation loss: 2.576032477593592

Epoch: 6| Step: 8
Training loss: 2.093317698928536
Validation loss: 2.5595514434719773

Epoch: 6| Step: 9
Training loss: 3.4559260956403324
Validation loss: 2.5714951713047887

Epoch: 6| Step: 10
Training loss: 3.261863769231241
Validation loss: 2.5637571651019253

Epoch: 6| Step: 11
Training loss: 3.010834362439162
Validation loss: 2.558472639716735

Epoch: 6| Step: 12
Training loss: 2.7861192918857878
Validation loss: 2.535814942048474

Epoch: 6| Step: 13
Training loss: 2.3278542175528756
Validation loss: 2.5336412371686494

Epoch: 328| Step: 0
Training loss: 2.6937682219771864
Validation loss: 2.5318294516681297

Epoch: 6| Step: 1
Training loss: 2.608858160126419
Validation loss: 2.5342012749890803

Epoch: 6| Step: 2
Training loss: 2.8401503364638674
Validation loss: 2.5308528311555407

Epoch: 6| Step: 3
Training loss: 3.383003352818419
Validation loss: 2.5353280197642523

Epoch: 6| Step: 4
Training loss: 2.0845947515813026
Validation loss: 2.5336958172771653

Epoch: 6| Step: 5
Training loss: 3.0538669274297496
Validation loss: 2.533987855823897

Epoch: 6| Step: 6
Training loss: 3.027618592614696
Validation loss: 2.539050785665569

Epoch: 6| Step: 7
Training loss: 2.705978827512793
Validation loss: 2.540094305486756

Epoch: 6| Step: 8
Training loss: 3.1239921470475007
Validation loss: 2.5489122979628043

Epoch: 6| Step: 9
Training loss: 3.251186154393879
Validation loss: 2.538129286239289

Epoch: 6| Step: 10
Training loss: 2.2826573459503283
Validation loss: 2.5403522774079925

Epoch: 6| Step: 11
Training loss: 3.0497099378893773
Validation loss: 2.5437358971003987

Epoch: 6| Step: 12
Training loss: 2.8282694911401496
Validation loss: 2.558178245349256

Epoch: 6| Step: 13
Training loss: 2.9681129173535723
Validation loss: 2.5494135255602703

Epoch: 329| Step: 0
Training loss: 3.233800127476238
Validation loss: 2.551103616744107

Epoch: 6| Step: 1
Training loss: 3.044523769777666
Validation loss: 2.5538457892719575

Epoch: 6| Step: 2
Training loss: 2.515810468008988
Validation loss: 2.5519182089416486

Epoch: 6| Step: 3
Training loss: 2.711551651659828
Validation loss: 2.54782153136692

Epoch: 6| Step: 4
Training loss: 2.4726387011250286
Validation loss: 2.55392388345525

Epoch: 6| Step: 5
Training loss: 2.5086074472324884
Validation loss: 2.5625279742939195

Epoch: 6| Step: 6
Training loss: 2.33166061344229
Validation loss: 2.562611616231403

Epoch: 6| Step: 7
Training loss: 2.8193059165844065
Validation loss: 2.5520215604403487

Epoch: 6| Step: 8
Training loss: 2.473253319655068
Validation loss: 2.58619723880437

Epoch: 6| Step: 9
Training loss: 2.2978465821503615
Validation loss: 2.5717433070527176

Epoch: 6| Step: 10
Training loss: 2.967256190271756
Validation loss: 2.5648065686195647

Epoch: 6| Step: 11
Training loss: 3.2305390097785804
Validation loss: 2.5667957517226827

Epoch: 6| Step: 12
Training loss: 3.6066643911508467
Validation loss: 2.5519976841155523

Epoch: 6| Step: 13
Training loss: 3.6857217930139607
Validation loss: 2.563578873006354

Epoch: 330| Step: 0
Training loss: 2.8455224853656804
Validation loss: 2.5444370128640506

Epoch: 6| Step: 1
Training loss: 2.343313557996733
Validation loss: 2.5444494016354584

Epoch: 6| Step: 2
Training loss: 2.447716162295647
Validation loss: 2.548534276325157

Epoch: 6| Step: 3
Training loss: 3.1884002910096543
Validation loss: 2.536746006729665

Epoch: 6| Step: 4
Training loss: 3.074896809156836
Validation loss: 2.529212210394272

Epoch: 6| Step: 5
Training loss: 2.757020139469147
Validation loss: 2.534423201356893

Epoch: 6| Step: 6
Training loss: 2.5783105956811165
Validation loss: 2.5279386315125176

Epoch: 6| Step: 7
Training loss: 3.1130456775484245
Validation loss: 2.533048395766343

Epoch: 6| Step: 8
Training loss: 3.359747151897389
Validation loss: 2.5289541771498234

Epoch: 6| Step: 9
Training loss: 2.5761372619571046
Validation loss: 2.5314023564390715

Epoch: 6| Step: 10
Training loss: 2.621765869197359
Validation loss: 2.539978277677778

Epoch: 6| Step: 11
Training loss: 3.0822028244087796
Validation loss: 2.551337073793549

Epoch: 6| Step: 12
Training loss: 2.5862614639050276
Validation loss: 2.569447532156039

Epoch: 6| Step: 13
Training loss: 2.9719781290124954
Validation loss: 2.5743631222249865

Epoch: 331| Step: 0
Training loss: 3.517486486347975
Validation loss: 2.6383491131018206

Epoch: 6| Step: 1
Training loss: 2.884903147111336
Validation loss: 2.595152832243641

Epoch: 6| Step: 2
Training loss: 2.5218146334658984
Validation loss: 2.636158156754153

Epoch: 6| Step: 3
Training loss: 2.8106095636413424
Validation loss: 2.64243506014218

Epoch: 6| Step: 4
Training loss: 2.8668357363087704
Validation loss: 2.6073010830108996

Epoch: 6| Step: 5
Training loss: 2.48475097114597
Validation loss: 2.5905684246366065

Epoch: 6| Step: 6
Training loss: 3.162028245079519
Validation loss: 2.5657078622820046

Epoch: 6| Step: 7
Training loss: 2.5859848894000845
Validation loss: 2.5718040762646153

Epoch: 6| Step: 8
Training loss: 2.913709194661871
Validation loss: 2.5756758177666663

Epoch: 6| Step: 9
Training loss: 2.8027295262098737
Validation loss: 2.556055872646638

Epoch: 6| Step: 10
Training loss: 2.9774271192367094
Validation loss: 2.5482279248319406

Epoch: 6| Step: 11
Training loss: 2.6709909147610067
Validation loss: 2.5377440456809253

Epoch: 6| Step: 12
Training loss: 3.0911120332810524
Validation loss: 2.5405815090214787

Epoch: 6| Step: 13
Training loss: 2.72586190478019
Validation loss: 2.5382415499419184

Epoch: 332| Step: 0
Training loss: 3.0845953618169397
Validation loss: 2.5259702617641446

Epoch: 6| Step: 1
Training loss: 2.419547359128394
Validation loss: 2.5226455787385706

Epoch: 6| Step: 2
Training loss: 2.8880146509258573
Validation loss: 2.528271683051017

Epoch: 6| Step: 3
Training loss: 3.278703846113958
Validation loss: 2.533808954286997

Epoch: 6| Step: 4
Training loss: 3.116890264503945
Validation loss: 2.518530698500717

Epoch: 6| Step: 5
Training loss: 3.066764509326411
Validation loss: 2.5161860996976038

Epoch: 6| Step: 6
Training loss: 3.3791444551151044
Validation loss: 2.522648342939284

Epoch: 6| Step: 7
Training loss: 2.0900976864558802
Validation loss: 2.518918130496231

Epoch: 6| Step: 8
Training loss: 2.731012685840578
Validation loss: 2.5237737104216973

Epoch: 6| Step: 9
Training loss: 2.8934259814123653
Validation loss: 2.520507375141479

Epoch: 6| Step: 10
Training loss: 2.9422014638252345
Validation loss: 2.519790233933881

Epoch: 6| Step: 11
Training loss: 2.7191495053771453
Validation loss: 2.548808648391731

Epoch: 6| Step: 12
Training loss: 2.56455037033585
Validation loss: 2.5588579995934357

Epoch: 6| Step: 13
Training loss: 2.1142196968994997
Validation loss: 2.5806411432291356

Epoch: 333| Step: 0
Training loss: 3.119014653843209
Validation loss: 2.620171118834907

Epoch: 6| Step: 1
Training loss: 3.051435764257323
Validation loss: 2.677578374968865

Epoch: 6| Step: 2
Training loss: 2.9086708732829285
Validation loss: 2.6571003169948204

Epoch: 6| Step: 3
Training loss: 2.689804153970833
Validation loss: 2.6431200618504413

Epoch: 6| Step: 4
Training loss: 2.76146536046394
Validation loss: 2.6454248834122067

Epoch: 6| Step: 5
Training loss: 2.3793918759123547
Validation loss: 2.6280654591259984

Epoch: 6| Step: 6
Training loss: 3.146457096599632
Validation loss: 2.6370704601648702

Epoch: 6| Step: 7
Training loss: 3.1781606546538126
Validation loss: 2.571584713400094

Epoch: 6| Step: 8
Training loss: 3.155803082239459
Validation loss: 2.5509760557566996

Epoch: 6| Step: 9
Training loss: 2.4983266952592724
Validation loss: 2.545442942690231

Epoch: 6| Step: 10
Training loss: 2.552616318042857
Validation loss: 2.515039073957206

Epoch: 6| Step: 11
Training loss: 2.8007755465695503
Validation loss: 2.5297649244892106

Epoch: 6| Step: 12
Training loss: 3.1300957903356963
Validation loss: 2.521213763813118

Epoch: 6| Step: 13
Training loss: 2.026953275558869
Validation loss: 2.5148500892141232

Epoch: 334| Step: 0
Training loss: 2.8859588077008467
Validation loss: 2.5241631794321093

Epoch: 6| Step: 1
Training loss: 2.165216021431606
Validation loss: 2.5252725891653656

Epoch: 6| Step: 2
Training loss: 2.748172673082363
Validation loss: 2.518811405465139

Epoch: 6| Step: 3
Training loss: 2.9331932150002387
Validation loss: 2.5207472884577387

Epoch: 6| Step: 4
Training loss: 2.5369086417415523
Validation loss: 2.514598117368304

Epoch: 6| Step: 5
Training loss: 3.4668422642275174
Validation loss: 2.5175063238999216

Epoch: 6| Step: 6
Training loss: 3.3147704782328833
Validation loss: 2.516549142126535

Epoch: 6| Step: 7
Training loss: 3.001868302009984
Validation loss: 2.5218675492449525

Epoch: 6| Step: 8
Training loss: 2.9578071090399236
Validation loss: 2.5223604000987665

Epoch: 6| Step: 9
Training loss: 3.0281913505977394
Validation loss: 2.5238975847870653

Epoch: 6| Step: 10
Training loss: 1.7026971402071278
Validation loss: 2.5264456734261764

Epoch: 6| Step: 11
Training loss: 3.0356036510663227
Validation loss: 2.5394125248631694

Epoch: 6| Step: 12
Training loss: 3.3288314141270656
Validation loss: 2.533924493145814

Epoch: 6| Step: 13
Training loss: 2.0592368929085656
Validation loss: 2.5516563718016134

Epoch: 335| Step: 0
Training loss: 2.974899187704006
Validation loss: 2.543757462448377

Epoch: 6| Step: 1
Training loss: 2.6617640987168674
Validation loss: 2.563532704478351

Epoch: 6| Step: 2
Training loss: 2.801211612681812
Validation loss: 2.572287389683555

Epoch: 6| Step: 3
Training loss: 2.182240512099646
Validation loss: 2.5798080524191853

Epoch: 6| Step: 4
Training loss: 3.1872151565436497
Validation loss: 2.589725517732259

Epoch: 6| Step: 5
Training loss: 3.175395646562335
Validation loss: 2.581973535373831

Epoch: 6| Step: 6
Training loss: 2.954587866738824
Validation loss: 2.563677245488932

Epoch: 6| Step: 7
Training loss: 3.1448402774200472
Validation loss: 2.550884744043722

Epoch: 6| Step: 8
Training loss: 2.2984356411447275
Validation loss: 2.555222795554874

Epoch: 6| Step: 9
Training loss: 2.4636167443565022
Validation loss: 2.53791786360842

Epoch: 6| Step: 10
Training loss: 3.2427758843460324
Validation loss: 2.53440132898742

Epoch: 6| Step: 11
Training loss: 2.726142566773161
Validation loss: 2.5306943275663736

Epoch: 6| Step: 12
Training loss: 3.008644206996639
Validation loss: 2.5314382303089578

Epoch: 6| Step: 13
Training loss: 2.773356519779457
Validation loss: 2.523355795402597

Epoch: 336| Step: 0
Training loss: 2.6403901486667674
Validation loss: 2.5341110922972057

Epoch: 6| Step: 1
Training loss: 2.8912897118967718
Validation loss: 2.5387541007650456

Epoch: 6| Step: 2
Training loss: 2.6827545852941883
Validation loss: 2.531081345567012

Epoch: 6| Step: 3
Training loss: 3.0838047045311536
Validation loss: 2.535802383709811

Epoch: 6| Step: 4
Training loss: 3.1579195649024303
Validation loss: 2.528554747690161

Epoch: 6| Step: 5
Training loss: 3.2231297000705017
Validation loss: 2.549290100633564

Epoch: 6| Step: 6
Training loss: 2.777055813957553
Validation loss: 2.532223276228927

Epoch: 6| Step: 7
Training loss: 2.5158581359119156
Validation loss: 2.532258566467118

Epoch: 6| Step: 8
Training loss: 2.689112778170883
Validation loss: 2.524080277486109

Epoch: 6| Step: 9
Training loss: 2.974497962713706
Validation loss: 2.5402154967302577

Epoch: 6| Step: 10
Training loss: 2.9822890096571095
Validation loss: 2.5253184937735003

Epoch: 6| Step: 11
Training loss: 2.533951718581724
Validation loss: 2.5427481517172823

Epoch: 6| Step: 12
Training loss: 2.7208328161390045
Validation loss: 2.5379286326389003

Epoch: 6| Step: 13
Training loss: 3.0707404927919693
Validation loss: 2.552315433504737

Epoch: 337| Step: 0
Training loss: 2.848850245869142
Validation loss: 2.5642653596319764

Epoch: 6| Step: 1
Training loss: 2.9963951705247984
Validation loss: 2.5742223362000844

Epoch: 6| Step: 2
Training loss: 2.7657373265446124
Validation loss: 2.5666380534543505

Epoch: 6| Step: 3
Training loss: 2.864383168018472
Validation loss: 2.5589533697386186

Epoch: 6| Step: 4
Training loss: 2.3225029775150787
Validation loss: 2.559450517501124

Epoch: 6| Step: 5
Training loss: 2.7110520044599347
Validation loss: 2.5423367308144376

Epoch: 6| Step: 6
Training loss: 3.2155108402848307
Validation loss: 2.5514419680618157

Epoch: 6| Step: 7
Training loss: 3.327530928768233
Validation loss: 2.571350245235877

Epoch: 6| Step: 8
Training loss: 2.792576219411593
Validation loss: 2.582795408321

Epoch: 6| Step: 9
Training loss: 2.7639232507696407
Validation loss: 2.584330952313083

Epoch: 6| Step: 10
Training loss: 2.798694977451588
Validation loss: 2.609365473923842

Epoch: 6| Step: 11
Training loss: 2.9764071046010048
Validation loss: 2.5860658722879806

Epoch: 6| Step: 12
Training loss: 2.883675794899262
Validation loss: 2.57296618335536

Epoch: 6| Step: 13
Training loss: 2.1619033784263735
Validation loss: 2.577359731486304

Epoch: 338| Step: 0
Training loss: 3.2837681871251054
Validation loss: 2.5776116748537246

Epoch: 6| Step: 1
Training loss: 2.9369072823415454
Validation loss: 2.576900389463034

Epoch: 6| Step: 2
Training loss: 2.747598292889511
Validation loss: 2.569721015103181

Epoch: 6| Step: 3
Training loss: 2.9225939513834427
Validation loss: 2.5753671592038954

Epoch: 6| Step: 4
Training loss: 3.2374421103467905
Validation loss: 2.559719096408572

Epoch: 6| Step: 5
Training loss: 2.887996158660701
Validation loss: 2.5468798758825426

Epoch: 6| Step: 6
Training loss: 2.7225888215175362
Validation loss: 2.5425449678107803

Epoch: 6| Step: 7
Training loss: 2.9528259448858503
Validation loss: 2.5402875783592003

Epoch: 6| Step: 8
Training loss: 2.864045877611338
Validation loss: 2.5286039039698562

Epoch: 6| Step: 9
Training loss: 2.849310500412124
Validation loss: 2.528323248955058

Epoch: 6| Step: 10
Training loss: 2.911074991301404
Validation loss: 2.525777936504755

Epoch: 6| Step: 11
Training loss: 1.5058892985536125
Validation loss: 2.534932420276428

Epoch: 6| Step: 12
Training loss: 2.6433740334987292
Validation loss: 2.5339141947525

Epoch: 6| Step: 13
Training loss: 2.9523582472272403
Validation loss: 2.535930137792162

Epoch: 339| Step: 0
Training loss: 2.75459616385777
Validation loss: 2.5421136593812728

Epoch: 6| Step: 1
Training loss: 2.309587242274102
Validation loss: 2.5339163547981856

Epoch: 6| Step: 2
Training loss: 2.755507848909455
Validation loss: 2.5424848060461653

Epoch: 6| Step: 3
Training loss: 2.8324004675808894
Validation loss: 2.5488660920896637

Epoch: 6| Step: 4
Training loss: 2.7375399338409254
Validation loss: 2.552157419588857

Epoch: 6| Step: 5
Training loss: 3.2311715741850184
Validation loss: 2.5544802016600605

Epoch: 6| Step: 6
Training loss: 3.1334647928892334
Validation loss: 2.562780283384204

Epoch: 6| Step: 7
Training loss: 3.0541103432437566
Validation loss: 2.5486969617941466

Epoch: 6| Step: 8
Training loss: 2.9499030727691564
Validation loss: 2.554139946275179

Epoch: 6| Step: 9
Training loss: 2.74310704651053
Validation loss: 2.5526870211093544

Epoch: 6| Step: 10
Training loss: 2.062154336342693
Validation loss: 2.5582852681505432

Epoch: 6| Step: 11
Training loss: 2.9736474047774144
Validation loss: 2.571246892962784

Epoch: 6| Step: 12
Training loss: 2.7023533066875323
Validation loss: 2.546931041888854

Epoch: 6| Step: 13
Training loss: 3.6839291368310643
Validation loss: 2.5483280206579835

Epoch: 340| Step: 0
Training loss: 2.713288708475298
Validation loss: 2.544780925967342

Epoch: 6| Step: 1
Training loss: 2.4017525790659215
Validation loss: 2.542585110825037

Epoch: 6| Step: 2
Training loss: 2.839816716418354
Validation loss: 2.539523211536436

Epoch: 6| Step: 3
Training loss: 2.5179305795397435
Validation loss: 2.5315678562897967

Epoch: 6| Step: 4
Training loss: 2.8230263288718045
Validation loss: 2.5272915199777444

Epoch: 6| Step: 5
Training loss: 2.332709694581723
Validation loss: 2.526673251170597

Epoch: 6| Step: 6
Training loss: 3.599799728121075
Validation loss: 2.530130385609512

Epoch: 6| Step: 7
Training loss: 2.9930756448502764
Validation loss: 2.5287171370009323

Epoch: 6| Step: 8
Training loss: 2.9153153331708888
Validation loss: 2.534619396860683

Epoch: 6| Step: 9
Training loss: 3.272557106073507
Validation loss: 2.5280949613406367

Epoch: 6| Step: 10
Training loss: 2.638680368405557
Validation loss: 2.526963442266621

Epoch: 6| Step: 11
Training loss: 3.102019538163634
Validation loss: 2.538600624298593

Epoch: 6| Step: 12
Training loss: 2.4662592431120944
Validation loss: 2.5333687247792556

Epoch: 6| Step: 13
Training loss: 2.970014764511452
Validation loss: 2.5311600377827523

Epoch: 341| Step: 0
Training loss: 2.5584605873923465
Validation loss: 2.539741929796278

Epoch: 6| Step: 1
Training loss: 2.1359089601810375
Validation loss: 2.5557148861300787

Epoch: 6| Step: 2
Training loss: 3.157106188984683
Validation loss: 2.549839687153939

Epoch: 6| Step: 3
Training loss: 2.327830865700221
Validation loss: 2.5523803755718566

Epoch: 6| Step: 4
Training loss: 3.000499206970039
Validation loss: 2.565981325186332

Epoch: 6| Step: 5
Training loss: 3.3056448773907827
Validation loss: 2.5670771834123824

Epoch: 6| Step: 6
Training loss: 2.6414438817599475
Validation loss: 2.5952876949676376

Epoch: 6| Step: 7
Training loss: 2.487054783069331
Validation loss: 2.5839915560051625

Epoch: 6| Step: 8
Training loss: 2.889730284093505
Validation loss: 2.584736648965447

Epoch: 6| Step: 9
Training loss: 3.024806774683289
Validation loss: 2.565909382862638

Epoch: 6| Step: 10
Training loss: 2.455165330404774
Validation loss: 2.5620515212311963

Epoch: 6| Step: 11
Training loss: 3.174432784949864
Validation loss: 2.5656219900880304

Epoch: 6| Step: 12
Training loss: 3.1742580838574814
Validation loss: 2.556294420313027

Epoch: 6| Step: 13
Training loss: 3.1320536543438977
Validation loss: 2.553736150031215

Epoch: 342| Step: 0
Training loss: 2.7464733051396526
Validation loss: 2.5278213758952246

Epoch: 6| Step: 1
Training loss: 2.9336317849773006
Validation loss: 2.5320740551855097

Epoch: 6| Step: 2
Training loss: 3.101924385078893
Validation loss: 2.519896001885153

Epoch: 6| Step: 3
Training loss: 2.80761064876956
Validation loss: 2.519730811845966

Epoch: 6| Step: 4
Training loss: 2.8369611253626386
Validation loss: 2.521274365014085

Epoch: 6| Step: 5
Training loss: 2.908752676417911
Validation loss: 2.512547674345615

Epoch: 6| Step: 6
Training loss: 3.39025229941468
Validation loss: 2.5312525785780675

Epoch: 6| Step: 7
Training loss: 2.6259046539754674
Validation loss: 2.5205552929102404

Epoch: 6| Step: 8
Training loss: 2.6494363797207865
Validation loss: 2.52612875173135

Epoch: 6| Step: 9
Training loss: 2.4796493979244723
Validation loss: 2.51630926714264

Epoch: 6| Step: 10
Training loss: 2.8749026406430302
Validation loss: 2.5236362612788485

Epoch: 6| Step: 11
Training loss: 2.5947432856654356
Validation loss: 2.532941181624872

Epoch: 6| Step: 12
Training loss: 2.6684737837563115
Validation loss: 2.536282439630212

Epoch: 6| Step: 13
Training loss: 2.9852213832734953
Validation loss: 2.5681150969897897

Epoch: 343| Step: 0
Training loss: 3.4544664081856697
Validation loss: 2.5661346266333953

Epoch: 6| Step: 1
Training loss: 2.943951927435264
Validation loss: 2.629678121363882

Epoch: 6| Step: 2
Training loss: 2.821618535922594
Validation loss: 2.636760025096345

Epoch: 6| Step: 3
Training loss: 2.45577975909052
Validation loss: 2.6159719608436545

Epoch: 6| Step: 4
Training loss: 2.586375127450819
Validation loss: 2.587544996074362

Epoch: 6| Step: 5
Training loss: 3.16162784295853
Validation loss: 2.566183618504421

Epoch: 6| Step: 6
Training loss: 1.9761144559970922
Validation loss: 2.551847704586046

Epoch: 6| Step: 7
Training loss: 3.1307998242250616
Validation loss: 2.550411587095532

Epoch: 6| Step: 8
Training loss: 2.4168702620762446
Validation loss: 2.53878540950336

Epoch: 6| Step: 9
Training loss: 2.5439463434198966
Validation loss: 2.5282917771987017

Epoch: 6| Step: 10
Training loss: 2.9035257676736608
Validation loss: 2.5317638336001913

Epoch: 6| Step: 11
Training loss: 2.886726678778015
Validation loss: 2.5255255262025282

Epoch: 6| Step: 12
Training loss: 3.258997274074017
Validation loss: 2.531320124031712

Epoch: 6| Step: 13
Training loss: 2.910697569201491
Validation loss: 2.5163924235745654

Epoch: 344| Step: 0
Training loss: 2.214633077192576
Validation loss: 2.529252154512833

Epoch: 6| Step: 1
Training loss: 3.150115898058929
Validation loss: 2.54026020284031

Epoch: 6| Step: 2
Training loss: 2.7908817630217224
Validation loss: 2.5299801494171947

Epoch: 6| Step: 3
Training loss: 2.7369301329097167
Validation loss: 2.541342202356476

Epoch: 6| Step: 4
Training loss: 3.310567904155186
Validation loss: 2.542793792260299

Epoch: 6| Step: 5
Training loss: 2.5936262721689602
Validation loss: 2.544042073042638

Epoch: 6| Step: 6
Training loss: 2.082887169428841
Validation loss: 2.559795207704356

Epoch: 6| Step: 7
Training loss: 2.539161468924534
Validation loss: 2.5527281967088196

Epoch: 6| Step: 8
Training loss: 3.008280769656801
Validation loss: 2.549270220271841

Epoch: 6| Step: 9
Training loss: 3.114046048332891
Validation loss: 2.5379926236372077

Epoch: 6| Step: 10
Training loss: 2.94537822943484
Validation loss: 2.5571655224949406

Epoch: 6| Step: 11
Training loss: 3.2002356919275052
Validation loss: 2.5571848141482305

Epoch: 6| Step: 12
Training loss: 2.923221053689808
Validation loss: 2.569117877660822

Epoch: 6| Step: 13
Training loss: 2.8614292790886995
Validation loss: 2.5432536434046686

Epoch: 345| Step: 0
Training loss: 3.0576597617105454
Validation loss: 2.552537615393049

Epoch: 6| Step: 1
Training loss: 3.179268174323704
Validation loss: 2.5406232299483693

Epoch: 6| Step: 2
Training loss: 3.3380579049931716
Validation loss: 2.5607643722460494

Epoch: 6| Step: 3
Training loss: 1.934374225967573
Validation loss: 2.550687841756572

Epoch: 6| Step: 4
Training loss: 2.8024738895176564
Validation loss: 2.55927267165388

Epoch: 6| Step: 5
Training loss: 2.738327744289212
Validation loss: 2.5420659513312707

Epoch: 6| Step: 6
Training loss: 2.6484618059241414
Validation loss: 2.5569140630390144

Epoch: 6| Step: 7
Training loss: 2.8378096356948226
Validation loss: 2.5504984900643866

Epoch: 6| Step: 8
Training loss: 2.4849363448588555
Validation loss: 2.5577383282663106

Epoch: 6| Step: 9
Training loss: 2.9845724789456995
Validation loss: 2.5556497870432553

Epoch: 6| Step: 10
Training loss: 3.2507863193904236
Validation loss: 2.551988515459069

Epoch: 6| Step: 11
Training loss: 3.1152896314162932
Validation loss: 2.557070068625365

Epoch: 6| Step: 12
Training loss: 2.197436191296424
Validation loss: 2.58011450249754

Epoch: 6| Step: 13
Training loss: 2.5418404274834137
Validation loss: 2.564975932998903

Epoch: 346| Step: 0
Training loss: 3.04112162126608
Validation loss: 2.5614476638020127

Epoch: 6| Step: 1
Training loss: 3.1253477284563216
Validation loss: 2.5617731685784237

Epoch: 6| Step: 2
Training loss: 2.762230983425959
Validation loss: 2.5327991103931478

Epoch: 6| Step: 3
Training loss: 3.0335022729073216
Validation loss: 2.5357134150667004

Epoch: 6| Step: 4
Training loss: 2.684999145138283
Validation loss: 2.528120456208127

Epoch: 6| Step: 5
Training loss: 2.44282634479864
Validation loss: 2.5338704946599524

Epoch: 6| Step: 6
Training loss: 2.820087962841596
Validation loss: 2.522006869606437

Epoch: 6| Step: 7
Training loss: 2.5894447352995216
Validation loss: 2.5372910012261496

Epoch: 6| Step: 8
Training loss: 2.3958043856876086
Validation loss: 2.525383259088606

Epoch: 6| Step: 9
Training loss: 3.1211553192749917
Validation loss: 2.5377798900114814

Epoch: 6| Step: 10
Training loss: 2.4638212232199423
Validation loss: 2.5560372063527614

Epoch: 6| Step: 11
Training loss: 2.911971991488144
Validation loss: 2.5546127122238875

Epoch: 6| Step: 12
Training loss: 2.7013715227533717
Validation loss: 2.555171149452138

Epoch: 6| Step: 13
Training loss: 3.5841666442923126
Validation loss: 2.570434184428856

Epoch: 347| Step: 0
Training loss: 2.3586147675110056
Validation loss: 2.6023673265184373

Epoch: 6| Step: 1
Training loss: 2.8992624265669757
Validation loss: 2.605884462568269

Epoch: 6| Step: 2
Training loss: 3.457831166282084
Validation loss: 2.6289136915411357

Epoch: 6| Step: 3
Training loss: 2.31475915615843
Validation loss: 2.6150414631286756

Epoch: 6| Step: 4
Training loss: 2.6464202310030998
Validation loss: 2.601720130453952

Epoch: 6| Step: 5
Training loss: 2.618366397266057
Validation loss: 2.615270648727927

Epoch: 6| Step: 6
Training loss: 2.5483454104682686
Validation loss: 2.6142036758169245

Epoch: 6| Step: 7
Training loss: 3.1930672888208136
Validation loss: 2.601357804719882

Epoch: 6| Step: 8
Training loss: 2.938831920187806
Validation loss: 2.588871139607708

Epoch: 6| Step: 9
Training loss: 2.089003463515811
Validation loss: 2.613050250511637

Epoch: 6| Step: 10
Training loss: 3.010008013134806
Validation loss: 2.5689019049911908

Epoch: 6| Step: 11
Training loss: 2.871525862996945
Validation loss: 2.5884591798796674

Epoch: 6| Step: 12
Training loss: 3.376060036798859
Validation loss: 2.5665328363154467

Epoch: 6| Step: 13
Training loss: 3.0044008400942417
Validation loss: 2.547229630677003

Epoch: 348| Step: 0
Training loss: 3.126959834666443
Validation loss: 2.5238203005163573

Epoch: 6| Step: 1
Training loss: 2.8679436042699566
Validation loss: 2.526056471082368

Epoch: 6| Step: 2
Training loss: 3.0103579364754425
Validation loss: 2.5251055142386547

Epoch: 6| Step: 3
Training loss: 2.6417210578333026
Validation loss: 2.5151023268263164

Epoch: 6| Step: 4
Training loss: 2.095353380866924
Validation loss: 2.5128011199492577

Epoch: 6| Step: 5
Training loss: 2.788027103691858
Validation loss: 2.507962496060551

Epoch: 6| Step: 6
Training loss: 2.8177149426470303
Validation loss: 2.512138196819993

Epoch: 6| Step: 7
Training loss: 2.7367004968904025
Validation loss: 2.518691801209333

Epoch: 6| Step: 8
Training loss: 3.061436994144451
Validation loss: 2.51668003617666

Epoch: 6| Step: 9
Training loss: 2.8269242746299708
Validation loss: 2.5413570262512

Epoch: 6| Step: 10
Training loss: 2.8249988454630697
Validation loss: 2.5340110560684415

Epoch: 6| Step: 11
Training loss: 2.5055320567598356
Validation loss: 2.5563578512923235

Epoch: 6| Step: 12
Training loss: 3.173199006157386
Validation loss: 2.5491632333271297

Epoch: 6| Step: 13
Training loss: 3.0735053236769265
Validation loss: 2.5610911420381566

Epoch: 349| Step: 0
Training loss: 2.4309415371517185
Validation loss: 2.5461828430106466

Epoch: 6| Step: 1
Training loss: 3.7259730866586898
Validation loss: 2.5623113191072435

Epoch: 6| Step: 2
Training loss: 2.7525220923095866
Validation loss: 2.5548725355315667

Epoch: 6| Step: 3
Training loss: 2.845614482308063
Validation loss: 2.5388902326505973

Epoch: 6| Step: 4
Training loss: 2.7988061471463506
Validation loss: 2.52550957804252

Epoch: 6| Step: 5
Training loss: 2.4467923984738156
Validation loss: 2.548838957566818

Epoch: 6| Step: 6
Training loss: 2.555680201664984
Validation loss: 2.5358248505762466

Epoch: 6| Step: 7
Training loss: 2.667624053358601
Validation loss: 2.5495769764321623

Epoch: 6| Step: 8
Training loss: 2.39069540880027
Validation loss: 2.5557354044824905

Epoch: 6| Step: 9
Training loss: 2.6939628428478777
Validation loss: 2.557295311022818

Epoch: 6| Step: 10
Training loss: 3.5782370737173212
Validation loss: 2.568769011279815

Epoch: 6| Step: 11
Training loss: 2.7277471816018912
Validation loss: 2.5785532158513353

Epoch: 6| Step: 12
Training loss: 2.3392988535305084
Validation loss: 2.56348070976207

Epoch: 6| Step: 13
Training loss: 3.309160672632836
Validation loss: 2.553754972682399

Epoch: 350| Step: 0
Training loss: 3.354433763819833
Validation loss: 2.5392594667934754

Epoch: 6| Step: 1
Training loss: 3.3140810666065548
Validation loss: 2.5301984139290488

Epoch: 6| Step: 2
Training loss: 2.8912567273171774
Validation loss: 2.5317556893197013

Epoch: 6| Step: 3
Training loss: 2.75231021597555
Validation loss: 2.5496103583418157

Epoch: 6| Step: 4
Training loss: 2.752821255402678
Validation loss: 2.5266085945141805

Epoch: 6| Step: 5
Training loss: 2.6505077451439134
Validation loss: 2.5276749822999487

Epoch: 6| Step: 6
Training loss: 2.262983163067212
Validation loss: 2.530645672317801

Epoch: 6| Step: 7
Training loss: 2.8867280002389006
Validation loss: 2.5239761434455046

Epoch: 6| Step: 8
Training loss: 2.7444221107854325
Validation loss: 2.550171624596491

Epoch: 6| Step: 9
Training loss: 2.1876732893833903
Validation loss: 2.5375001140024445

Epoch: 6| Step: 10
Training loss: 2.8954098252285934
Validation loss: 2.538428795223012

Epoch: 6| Step: 11
Training loss: 2.717487348932404
Validation loss: 2.5494018698495604

Epoch: 6| Step: 12
Training loss: 2.9824314679364385
Validation loss: 2.5523249274277457

Epoch: 6| Step: 13
Training loss: 2.8809396506294345
Validation loss: 2.5595865782737626

Epoch: 351| Step: 0
Training loss: 3.0750345119617535
Validation loss: 2.5595322307543116

Epoch: 6| Step: 1
Training loss: 2.32739266776018
Validation loss: 2.5560971674885784

Epoch: 6| Step: 2
Training loss: 2.331165760144381
Validation loss: 2.574225543957715

Epoch: 6| Step: 3
Training loss: 3.17967835221158
Validation loss: 2.5681904114331027

Epoch: 6| Step: 4
Training loss: 2.575232900808819
Validation loss: 2.579905913398091

Epoch: 6| Step: 5
Training loss: 2.9370730475335223
Validation loss: 2.5700674310773195

Epoch: 6| Step: 6
Training loss: 2.6693172593460073
Validation loss: 2.5732064261867067

Epoch: 6| Step: 7
Training loss: 2.613600638676925
Validation loss: 2.545915331361753

Epoch: 6| Step: 8
Training loss: 3.353789187844684
Validation loss: 2.5567609627574273

Epoch: 6| Step: 9
Training loss: 3.057055713878363
Validation loss: 2.554621038029898

Epoch: 6| Step: 10
Training loss: 2.4820450707646073
Validation loss: 2.566260353239599

Epoch: 6| Step: 11
Training loss: 2.8279427316848134
Validation loss: 2.5667349043864385

Epoch: 6| Step: 12
Training loss: 3.279853160176433
Validation loss: 2.5607608923394243

Epoch: 6| Step: 13
Training loss: 2.1536629678827968
Validation loss: 2.564844598041874

Epoch: 352| Step: 0
Training loss: 2.940897336504602
Validation loss: 2.54421940961469

Epoch: 6| Step: 1
Training loss: 2.323524794641425
Validation loss: 2.564137324635149

Epoch: 6| Step: 2
Training loss: 2.7762542605034617
Validation loss: 2.5381022379329807

Epoch: 6| Step: 3
Training loss: 2.87661962913463
Validation loss: 2.55345957959799

Epoch: 6| Step: 4
Training loss: 3.0034987392737236
Validation loss: 2.5576577053793237

Epoch: 6| Step: 5
Training loss: 2.6353271428962
Validation loss: 2.5487526035306103

Epoch: 6| Step: 6
Training loss: 2.8594860618159563
Validation loss: 2.540799486391184

Epoch: 6| Step: 7
Training loss: 2.1086626898798113
Validation loss: 2.545853832413354

Epoch: 6| Step: 8
Training loss: 3.110858505832521
Validation loss: 2.5261144686983563

Epoch: 6| Step: 9
Training loss: 2.728692040170813
Validation loss: 2.5384539848236

Epoch: 6| Step: 10
Training loss: 2.915320240050959
Validation loss: 2.5447095932074935

Epoch: 6| Step: 11
Training loss: 3.1284148822195834
Validation loss: 2.5429655945541585

Epoch: 6| Step: 12
Training loss: 2.232876895645978
Validation loss: 2.5325163875453285

Epoch: 6| Step: 13
Training loss: 3.752943663778295
Validation loss: 2.5493417552611604

Epoch: 353| Step: 0
Training loss: 2.7427950020403955
Validation loss: 2.538745878938502

Epoch: 6| Step: 1
Training loss: 2.9342828543173245
Validation loss: 2.5342338453007294

Epoch: 6| Step: 2
Training loss: 2.3194220789924325
Validation loss: 2.5351383621876855

Epoch: 6| Step: 3
Training loss: 2.757171988739237
Validation loss: 2.538071738927493

Epoch: 6| Step: 4
Training loss: 3.2609627035909847
Validation loss: 2.5481808111496673

Epoch: 6| Step: 5
Training loss: 1.7827888667740923
Validation loss: 2.524229947726406

Epoch: 6| Step: 6
Training loss: 3.3236598476250307
Validation loss: 2.521973732238285

Epoch: 6| Step: 7
Training loss: 2.7996124850916257
Validation loss: 2.5268449776944766

Epoch: 6| Step: 8
Training loss: 2.9351253244914757
Validation loss: 2.5397785458762794

Epoch: 6| Step: 9
Training loss: 2.746817220833146
Validation loss: 2.542719458722091

Epoch: 6| Step: 10
Training loss: 2.9947170790077617
Validation loss: 2.547779149496624

Epoch: 6| Step: 11
Training loss: 2.7784165940588537
Validation loss: 2.557460149719321

Epoch: 6| Step: 12
Training loss: 2.8096435452471327
Validation loss: 2.541935826948526

Epoch: 6| Step: 13
Training loss: 3.0673402177876707
Validation loss: 2.566342821640842

Epoch: 354| Step: 0
Training loss: 2.763691544210042
Validation loss: 2.5565281183322877

Epoch: 6| Step: 1
Training loss: 2.6020549502834167
Validation loss: 2.566328610580515

Epoch: 6| Step: 2
Training loss: 2.8221715997259205
Validation loss: 2.553144975900056

Epoch: 6| Step: 3
Training loss: 2.7298507318456
Validation loss: 2.561616068326231

Epoch: 6| Step: 4
Training loss: 2.850684629158307
Validation loss: 2.5430128230032913

Epoch: 6| Step: 5
Training loss: 3.092729188140591
Validation loss: 2.5357633060728264

Epoch: 6| Step: 6
Training loss: 1.82736640253986
Validation loss: 2.558927949134493

Epoch: 6| Step: 7
Training loss: 2.81009079212928
Validation loss: 2.5418511536723347

Epoch: 6| Step: 8
Training loss: 2.8508306530900174
Validation loss: 2.530103100815157

Epoch: 6| Step: 9
Training loss: 3.5279982457059273
Validation loss: 2.5320916598951015

Epoch: 6| Step: 10
Training loss: 2.737048950660727
Validation loss: 2.5430329922113786

Epoch: 6| Step: 11
Training loss: 2.9523059173283834
Validation loss: 2.5334995026917397

Epoch: 6| Step: 12
Training loss: 2.8005857093470947
Validation loss: 2.5369062386828776

Epoch: 6| Step: 13
Training loss: 2.514873416058472
Validation loss: 2.5512216261314737

Epoch: 355| Step: 0
Training loss: 3.1894698694447174
Validation loss: 2.576493289755523

Epoch: 6| Step: 1
Training loss: 2.7407184371766253
Validation loss: 2.5534685632593086

Epoch: 6| Step: 2
Training loss: 1.8918460654449019
Validation loss: 2.581724091044406

Epoch: 6| Step: 3
Training loss: 2.2400332213390577
Validation loss: 2.5858353563436514

Epoch: 6| Step: 4
Training loss: 2.509981637408807
Validation loss: 2.5879642772506326

Epoch: 6| Step: 5
Training loss: 3.2322979583498697
Validation loss: 2.580573225717171

Epoch: 6| Step: 6
Training loss: 1.7985333958172005
Validation loss: 2.5671106193735955

Epoch: 6| Step: 7
Training loss: 2.9111044753422064
Validation loss: 2.5478899244785733

Epoch: 6| Step: 8
Training loss: 3.637139088137813
Validation loss: 2.536128049387454

Epoch: 6| Step: 9
Training loss: 3.4126129914186314
Validation loss: 2.5332023244956727

Epoch: 6| Step: 10
Training loss: 2.9058719512179128
Validation loss: 2.531918619565943

Epoch: 6| Step: 11
Training loss: 2.5788745137422633
Validation loss: 2.523853636092083

Epoch: 6| Step: 12
Training loss: 2.858199748336635
Validation loss: 2.530685469208994

Epoch: 6| Step: 13
Training loss: 2.941742126822583
Validation loss: 2.530950032473731

Epoch: 356| Step: 0
Training loss: 3.172370909461065
Validation loss: 2.53799940547734

Epoch: 6| Step: 1
Training loss: 2.836026108883872
Validation loss: 2.530658868118469

Epoch: 6| Step: 2
Training loss: 2.4104553729493663
Validation loss: 2.551202759667498

Epoch: 6| Step: 3
Training loss: 2.6873223002037028
Validation loss: 2.560621849381561

Epoch: 6| Step: 4
Training loss: 2.714746970228666
Validation loss: 2.566945095073322

Epoch: 6| Step: 5
Training loss: 2.8352964743412827
Validation loss: 2.577394206763103

Epoch: 6| Step: 6
Training loss: 3.18775370467052
Validation loss: 2.5740511002758915

Epoch: 6| Step: 7
Training loss: 2.6401039828427533
Validation loss: 2.5758671683175014

Epoch: 6| Step: 8
Training loss: 2.8361137062166324
Validation loss: 2.60382161338111

Epoch: 6| Step: 9
Training loss: 3.282787435110018
Validation loss: 2.56957666141356

Epoch: 6| Step: 10
Training loss: 2.487862879675817
Validation loss: 2.54124635287006

Epoch: 6| Step: 11
Training loss: 2.3799274927202023
Validation loss: 2.526686150139703

Epoch: 6| Step: 12
Training loss: 2.642155220831664
Validation loss: 2.5102409264176355

Epoch: 6| Step: 13
Training loss: 3.6310516355767524
Validation loss: 2.5089328254158034

Epoch: 357| Step: 0
Training loss: 2.765614482622569
Validation loss: 2.514388164364174

Epoch: 6| Step: 1
Training loss: 2.4187519241049356
Validation loss: 2.518200083668579

Epoch: 6| Step: 2
Training loss: 2.3579408442589083
Validation loss: 2.52242809067176

Epoch: 6| Step: 3
Training loss: 2.831442557348887
Validation loss: 2.535069146723431

Epoch: 6| Step: 4
Training loss: 2.76600480569793
Validation loss: 2.5289713930255053

Epoch: 6| Step: 5
Training loss: 3.18619166431923
Validation loss: 2.5295506531733047

Epoch: 6| Step: 6
Training loss: 3.0406638979016476
Validation loss: 2.525607708232452

Epoch: 6| Step: 7
Training loss: 2.9081001545320033
Validation loss: 2.527257900070401

Epoch: 6| Step: 8
Training loss: 2.7986373037706476
Validation loss: 2.5377604988294404

Epoch: 6| Step: 9
Training loss: 3.0242199735409887
Validation loss: 2.5308323693769883

Epoch: 6| Step: 10
Training loss: 3.4011019379599636
Validation loss: 2.530019637591017

Epoch: 6| Step: 11
Training loss: 2.67820587570233
Validation loss: 2.5507586404895486

Epoch: 6| Step: 12
Training loss: 1.5403900617318018
Validation loss: 2.56455531257728

Epoch: 6| Step: 13
Training loss: 3.289483775073184
Validation loss: 2.576412057720355

Epoch: 358| Step: 0
Training loss: 2.574661703016388
Validation loss: 2.586394069402675

Epoch: 6| Step: 1
Training loss: 2.944820292094982
Validation loss: 2.6037350092991427

Epoch: 6| Step: 2
Training loss: 2.9029931308456134
Validation loss: 2.611405261978179

Epoch: 6| Step: 3
Training loss: 2.680656324698532
Validation loss: 2.618151993161886

Epoch: 6| Step: 4
Training loss: 2.6765159767681688
Validation loss: 2.583916387611597

Epoch: 6| Step: 5
Training loss: 2.7716294103501413
Validation loss: 2.585765712340686

Epoch: 6| Step: 6
Training loss: 2.378247600508095
Validation loss: 2.5549246331853097

Epoch: 6| Step: 7
Training loss: 3.143099896233436
Validation loss: 2.5377998154318866

Epoch: 6| Step: 8
Training loss: 3.3120122586451903
Validation loss: 2.5241374450191834

Epoch: 6| Step: 9
Training loss: 3.217516320104935
Validation loss: 2.513187850527475

Epoch: 6| Step: 10
Training loss: 2.8233620173841105
Validation loss: 2.51280557121844

Epoch: 6| Step: 11
Training loss: 2.974594627138424
Validation loss: 2.510908301738004

Epoch: 6| Step: 12
Training loss: 2.6602265156835974
Validation loss: 2.512053920356823

Epoch: 6| Step: 13
Training loss: 1.9864916588785535
Validation loss: 2.502965745146887

Epoch: 359| Step: 0
Training loss: 3.0200586487588876
Validation loss: 2.4980368771743793

Epoch: 6| Step: 1
Training loss: 2.8626829930079634
Validation loss: 2.5073455599714665

Epoch: 6| Step: 2
Training loss: 3.0298830076488206
Validation loss: 2.5242957880399772

Epoch: 6| Step: 3
Training loss: 2.1857203192320394
Validation loss: 2.5256044372029605

Epoch: 6| Step: 4
Training loss: 2.9284789173786536
Validation loss: 2.528269643917552

Epoch: 6| Step: 5
Training loss: 3.0078240728774928
Validation loss: 2.5479330148587387

Epoch: 6| Step: 6
Training loss: 1.9579231224865559
Validation loss: 2.559498545550225

Epoch: 6| Step: 7
Training loss: 3.373343166995385
Validation loss: 2.571917934176732

Epoch: 6| Step: 8
Training loss: 3.1796170163602313
Validation loss: 2.5936160072125287

Epoch: 6| Step: 9
Training loss: 2.8977049855617825
Validation loss: 2.6037224575726894

Epoch: 6| Step: 10
Training loss: 2.599410349666745
Validation loss: 2.5764942215836903

Epoch: 6| Step: 11
Training loss: 2.605431414884302
Validation loss: 2.575160131822706

Epoch: 6| Step: 12
Training loss: 2.8414881168179424
Validation loss: 2.5386723963173545

Epoch: 6| Step: 13
Training loss: 2.4954636424707846
Validation loss: 2.5195114665341

Epoch: 360| Step: 0
Training loss: 2.7085111901987116
Validation loss: 2.5124130824162307

Epoch: 6| Step: 1
Training loss: 2.751090440434519
Validation loss: 2.51176399087253

Epoch: 6| Step: 2
Training loss: 2.5270861062466805
Validation loss: 2.5163826387198163

Epoch: 6| Step: 3
Training loss: 2.0469556020926483
Validation loss: 2.5106328204757284

Epoch: 6| Step: 4
Training loss: 2.7490277739197593
Validation loss: 2.4986038288190144

Epoch: 6| Step: 5
Training loss: 3.370457170305719
Validation loss: 2.5108466713012856

Epoch: 6| Step: 6
Training loss: 3.3565238741442305
Validation loss: 2.518704750214174

Epoch: 6| Step: 7
Training loss: 3.034122953937328
Validation loss: 2.5068658583053325

Epoch: 6| Step: 8
Training loss: 2.362225358126977
Validation loss: 2.5140997450498586

Epoch: 6| Step: 9
Training loss: 2.7078598978040302
Validation loss: 2.5183459092813485

Epoch: 6| Step: 10
Training loss: 2.5409663647884213
Validation loss: 2.5190622699452585

Epoch: 6| Step: 11
Training loss: 3.1592694937486514
Validation loss: 2.52314743375731

Epoch: 6| Step: 12
Training loss: 2.338172685248564
Validation loss: 2.5231076683465163

Epoch: 6| Step: 13
Training loss: 3.7285053938440034
Validation loss: 2.5594726065091304

Epoch: 361| Step: 0
Training loss: 3.62486885096641
Validation loss: 2.5559592138506426

Epoch: 6| Step: 1
Training loss: 2.4000799165771607
Validation loss: 2.5818540728809602

Epoch: 6| Step: 2
Training loss: 3.1208624342277607
Validation loss: 2.5863688996715095

Epoch: 6| Step: 3
Training loss: 2.4186653772972453
Validation loss: 2.6123055383487084

Epoch: 6| Step: 4
Training loss: 2.143096944470132
Validation loss: 2.6305494509839296

Epoch: 6| Step: 5
Training loss: 3.1408102256091524
Validation loss: 2.661879117776862

Epoch: 6| Step: 6
Training loss: 2.4534334608391433
Validation loss: 2.6368124259980004

Epoch: 6| Step: 7
Training loss: 3.0383064486733073
Validation loss: 2.5855268823982813

Epoch: 6| Step: 8
Training loss: 2.873082724113528
Validation loss: 2.555003175012872

Epoch: 6| Step: 9
Training loss: 3.0290292686844205
Validation loss: 2.5330437973892184

Epoch: 6| Step: 10
Training loss: 2.8584242944359195
Validation loss: 2.521566124985482

Epoch: 6| Step: 11
Training loss: 2.9181566701327792
Validation loss: 2.509853123286818

Epoch: 6| Step: 12
Training loss: 2.5496281446207574
Validation loss: 2.5000325385406508

Epoch: 6| Step: 13
Training loss: 2.312966789353523
Validation loss: 2.496187126588802

Epoch: 362| Step: 0
Training loss: 2.3876210207000543
Validation loss: 2.496787820435021

Epoch: 6| Step: 1
Training loss: 2.7379688296943647
Validation loss: 2.499488095203237

Epoch: 6| Step: 2
Training loss: 2.4653998713340055
Validation loss: 2.4958653858838447

Epoch: 6| Step: 3
Training loss: 2.822655293844332
Validation loss: 2.4980551199433125

Epoch: 6| Step: 4
Training loss: 3.2183496911456144
Validation loss: 2.4944581976903017

Epoch: 6| Step: 5
Training loss: 2.423102480016499
Validation loss: 2.5034725764621015

Epoch: 6| Step: 6
Training loss: 3.0361653225281815
Validation loss: 2.4951746076375136

Epoch: 6| Step: 7
Training loss: 2.8771670922957786
Validation loss: 2.501115901634399

Epoch: 6| Step: 8
Training loss: 3.3277885732615404
Validation loss: 2.50544482606747

Epoch: 6| Step: 9
Training loss: 3.2365062528774065
Validation loss: 2.497846701510932

Epoch: 6| Step: 10
Training loss: 2.254529103341476
Validation loss: 2.516414334298263

Epoch: 6| Step: 11
Training loss: 2.928190372677736
Validation loss: 2.5258685410525064

Epoch: 6| Step: 12
Training loss: 2.79828765825806
Validation loss: 2.533658979728442

Epoch: 6| Step: 13
Training loss: 2.9669513272933603
Validation loss: 2.5494247860263144

Epoch: 363| Step: 0
Training loss: 2.7527414009196205
Validation loss: 2.56819545946922

Epoch: 6| Step: 1
Training loss: 3.361580058469819
Validation loss: 2.560530975763754

Epoch: 6| Step: 2
Training loss: 2.352395147891555
Validation loss: 2.560465349319825

Epoch: 6| Step: 3
Training loss: 2.9765054692289095
Validation loss: 2.562986471288791

Epoch: 6| Step: 4
Training loss: 2.8676333379632997
Validation loss: 2.5566414622860694

Epoch: 6| Step: 5
Training loss: 2.452691009424877
Validation loss: 2.566856301987376

Epoch: 6| Step: 6
Training loss: 3.3598503308794343
Validation loss: 2.5581701090000952

Epoch: 6| Step: 7
Training loss: 2.924596161963441
Validation loss: 2.569414217400752

Epoch: 6| Step: 8
Training loss: 2.6096035977126535
Validation loss: 2.564918411314318

Epoch: 6| Step: 9
Training loss: 2.6652700422646407
Validation loss: 2.557238111809655

Epoch: 6| Step: 10
Training loss: 2.816777769602426
Validation loss: 2.5544677360876094

Epoch: 6| Step: 11
Training loss: 2.5973617960462394
Validation loss: 2.5536324502956176

Epoch: 6| Step: 12
Training loss: 2.933007884033511
Validation loss: 2.5535952226926466

Epoch: 6| Step: 13
Training loss: 2.344556949300482
Validation loss: 2.526766225158209

Epoch: 364| Step: 0
Training loss: 3.2747587391752524
Validation loss: 2.513963734108175

Epoch: 6| Step: 1
Training loss: 2.9089562726292977
Validation loss: 2.50656010276324

Epoch: 6| Step: 2
Training loss: 2.577119573422105
Validation loss: 2.5032193354455963

Epoch: 6| Step: 3
Training loss: 2.59354041298363
Validation loss: 2.502794917394475

Epoch: 6| Step: 4
Training loss: 2.695697082503915
Validation loss: 2.5039720892490944

Epoch: 6| Step: 5
Training loss: 2.1581439118008254
Validation loss: 2.5044290497450006

Epoch: 6| Step: 6
Training loss: 2.984158013729052
Validation loss: 2.5096766996887454

Epoch: 6| Step: 7
Training loss: 2.4816129673599967
Validation loss: 2.4998603638240384

Epoch: 6| Step: 8
Training loss: 2.6954103313880102
Validation loss: 2.5163126852473234

Epoch: 6| Step: 9
Training loss: 2.82030201748831
Validation loss: 2.5299721017389096

Epoch: 6| Step: 10
Training loss: 3.295223744600287
Validation loss: 2.554055475841496

Epoch: 6| Step: 11
Training loss: 2.7633292804714373
Validation loss: 2.580496952360429

Epoch: 6| Step: 12
Training loss: 2.516553624458535
Validation loss: 2.5844499888440415

Epoch: 6| Step: 13
Training loss: 3.8326508840582214
Validation loss: 2.630893979437006

Epoch: 365| Step: 0
Training loss: 2.9037719334247334
Validation loss: 2.645581202806974

Epoch: 6| Step: 1
Training loss: 2.8282557504683647
Validation loss: 2.697791198582591

Epoch: 6| Step: 2
Training loss: 2.0214709295295603
Validation loss: 2.6865859751257157

Epoch: 6| Step: 3
Training loss: 3.290692792956703
Validation loss: 2.6760128353660932

Epoch: 6| Step: 4
Training loss: 2.5594227619861387
Validation loss: 2.6289639660060704

Epoch: 6| Step: 5
Training loss: 2.6858978818908588
Validation loss: 2.57990868481307

Epoch: 6| Step: 6
Training loss: 3.093983805135054
Validation loss: 2.5608610568977173

Epoch: 6| Step: 7
Training loss: 3.461063976861553
Validation loss: 2.5376327762794912

Epoch: 6| Step: 8
Training loss: 2.658092084439121
Validation loss: 2.526389710874344

Epoch: 6| Step: 9
Training loss: 2.89705853420927
Validation loss: 2.5260615454702324

Epoch: 6| Step: 10
Training loss: 3.288124657525583
Validation loss: 2.5172817222138204

Epoch: 6| Step: 11
Training loss: 2.6548284878263173
Validation loss: 2.505148411178421

Epoch: 6| Step: 12
Training loss: 2.7541465708527997
Validation loss: 2.513191036730387

Epoch: 6| Step: 13
Training loss: 2.133437627488106
Validation loss: 2.5017012222225294

Epoch: 366| Step: 0
Training loss: 3.019866016775801
Validation loss: 2.507139139874953

Epoch: 6| Step: 1
Training loss: 2.6468913648655668
Validation loss: 2.507956530491063

Epoch: 6| Step: 2
Training loss: 2.809072737510156
Validation loss: 2.5022636758081

Epoch: 6| Step: 3
Training loss: 2.9380935718549024
Validation loss: 2.500434866379303

Epoch: 6| Step: 4
Training loss: 2.7665626962115084
Validation loss: 2.5017912610444886

Epoch: 6| Step: 5
Training loss: 2.286746783878062
Validation loss: 2.5060249116449604

Epoch: 6| Step: 6
Training loss: 2.1848237151170102
Validation loss: 2.5044220710508407

Epoch: 6| Step: 7
Training loss: 3.388806677343978
Validation loss: 2.5112175695100265

Epoch: 6| Step: 8
Training loss: 2.5915402110691588
Validation loss: 2.53300102150573

Epoch: 6| Step: 9
Training loss: 2.911510341955439
Validation loss: 2.551798497758868

Epoch: 6| Step: 10
Training loss: 2.981007538538643
Validation loss: 2.5448672233713885

Epoch: 6| Step: 11
Training loss: 3.162379742774768
Validation loss: 2.5623480608955562

Epoch: 6| Step: 12
Training loss: 2.5738604792652677
Validation loss: 2.5805940833696126

Epoch: 6| Step: 13
Training loss: 3.0481966722269878
Validation loss: 2.580577150789456

Epoch: 367| Step: 0
Training loss: 3.0630847606183575
Validation loss: 2.598801141384137

Epoch: 6| Step: 1
Training loss: 2.0321815115441377
Validation loss: 2.592315378883011

Epoch: 6| Step: 2
Training loss: 2.7428322058634
Validation loss: 2.590787123158035

Epoch: 6| Step: 3
Training loss: 3.2613715255395386
Validation loss: 2.559951950024155

Epoch: 6| Step: 4
Training loss: 3.27969439734342
Validation loss: 2.5546403749897486

Epoch: 6| Step: 5
Training loss: 2.953464387636676
Validation loss: 2.544244081400612

Epoch: 6| Step: 6
Training loss: 2.6256589516576447
Validation loss: 2.5308735034616396

Epoch: 6| Step: 7
Training loss: 2.918935347559521
Validation loss: 2.530697758151819

Epoch: 6| Step: 8
Training loss: 2.977648279195709
Validation loss: 2.51764818281466

Epoch: 6| Step: 9
Training loss: 2.4128211326528684
Validation loss: 2.5220522003817325

Epoch: 6| Step: 10
Training loss: 2.9414313772478367
Validation loss: 2.50932596890988

Epoch: 6| Step: 11
Training loss: 2.503894252421042
Validation loss: 2.5079762323538852

Epoch: 6| Step: 12
Training loss: 3.0636820166401852
Validation loss: 2.504734112019998

Epoch: 6| Step: 13
Training loss: 1.9998267217913035
Validation loss: 2.501518242776614

Epoch: 368| Step: 0
Training loss: 2.6241217460999198
Validation loss: 2.5075365273175394

Epoch: 6| Step: 1
Training loss: 3.023159911352586
Validation loss: 2.498344066774982

Epoch: 6| Step: 2
Training loss: 2.1262850522264256
Validation loss: 2.514534025487648

Epoch: 6| Step: 3
Training loss: 3.1753539000790245
Validation loss: 2.5141466174028015

Epoch: 6| Step: 4
Training loss: 2.8913700277744123
Validation loss: 2.5205265720577708

Epoch: 6| Step: 5
Training loss: 2.210739935684978
Validation loss: 2.5439493167598393

Epoch: 6| Step: 6
Training loss: 1.8891006503737253
Validation loss: 2.558848399666182

Epoch: 6| Step: 7
Training loss: 2.4376257839515585
Validation loss: 2.566954021551805

Epoch: 6| Step: 8
Training loss: 2.901482065264031
Validation loss: 2.577959478837897

Epoch: 6| Step: 9
Training loss: 3.0188619209850645
Validation loss: 2.578680477417929

Epoch: 6| Step: 10
Training loss: 2.9046239097984867
Validation loss: 2.5782028191469477

Epoch: 6| Step: 11
Training loss: 3.13856309608481
Validation loss: 2.5583816156069723

Epoch: 6| Step: 12
Training loss: 3.3241453061804567
Validation loss: 2.548524992603632

Epoch: 6| Step: 13
Training loss: 3.55683140083314
Validation loss: 2.5250741506073515

Epoch: 369| Step: 0
Training loss: 2.590614353797674
Validation loss: 2.5283438557569515

Epoch: 6| Step: 1
Training loss: 2.6202650508326424
Validation loss: 2.526189221325663

Epoch: 6| Step: 2
Training loss: 2.765951277457504
Validation loss: 2.526383720829124

Epoch: 6| Step: 3
Training loss: 2.9334035677159847
Validation loss: 2.5278621877953977

Epoch: 6| Step: 4
Training loss: 3.217386345741853
Validation loss: 2.5217313066276676

Epoch: 6| Step: 5
Training loss: 2.6434958838583564
Validation loss: 2.5299349191467826

Epoch: 6| Step: 6
Training loss: 2.6752906071039266
Validation loss: 2.531429130994492

Epoch: 6| Step: 7
Training loss: 2.5034354447196967
Validation loss: 2.531761740574249

Epoch: 6| Step: 8
Training loss: 2.75374071421813
Validation loss: 2.5306158260115277

Epoch: 6| Step: 9
Training loss: 2.614868047240621
Validation loss: 2.5351771733925896

Epoch: 6| Step: 10
Training loss: 2.6192295591316457
Validation loss: 2.541108728984054

Epoch: 6| Step: 11
Training loss: 3.247262829114338
Validation loss: 2.5528580682326996

Epoch: 6| Step: 12
Training loss: 3.210951459348458
Validation loss: 2.558182605636081

Epoch: 6| Step: 13
Training loss: 2.1928542957669075
Validation loss: 2.5797188066876138

Epoch: 370| Step: 0
Training loss: 2.51278592660528
Validation loss: 2.5882872168819455

Epoch: 6| Step: 1
Training loss: 2.9235787549698795
Validation loss: 2.5713427697060607

Epoch: 6| Step: 2
Training loss: 2.6535151146515226
Validation loss: 2.5647171627219993

Epoch: 6| Step: 3
Training loss: 2.9402491914151065
Validation loss: 2.5607601234756427

Epoch: 6| Step: 4
Training loss: 2.914083444964943
Validation loss: 2.5547825240965083

Epoch: 6| Step: 5
Training loss: 2.4383666625214504
Validation loss: 2.54463462954707

Epoch: 6| Step: 6
Training loss: 3.3709367381779582
Validation loss: 2.562128957061562

Epoch: 6| Step: 7
Training loss: 2.7061109863944632
Validation loss: 2.5352758126621455

Epoch: 6| Step: 8
Training loss: 2.7164762789081833
Validation loss: 2.550391088234154

Epoch: 6| Step: 9
Training loss: 2.134600326685888
Validation loss: 2.554486658724395

Epoch: 6| Step: 10
Training loss: 3.0054505425246996
Validation loss: 2.5469776552872827

Epoch: 6| Step: 11
Training loss: 3.2265178686569667
Validation loss: 2.5432101723385565

Epoch: 6| Step: 12
Training loss: 2.928469961847628
Validation loss: 2.5412286279757375

Epoch: 6| Step: 13
Training loss: 2.0202871416924117
Validation loss: 2.5282599389987457

Epoch: 371| Step: 0
Training loss: 2.7066997198457545
Validation loss: 2.523371162839185

Epoch: 6| Step: 1
Training loss: 2.5760677568220207
Validation loss: 2.5156559138130072

Epoch: 6| Step: 2
Training loss: 2.6599709870613357
Validation loss: 2.510527725292334

Epoch: 6| Step: 3
Training loss: 3.086827403333194
Validation loss: 2.5309377153811043

Epoch: 6| Step: 4
Training loss: 2.5262008983855395
Validation loss: 2.5232655903406096

Epoch: 6| Step: 5
Training loss: 3.200557964079561
Validation loss: 2.523765113212928

Epoch: 6| Step: 6
Training loss: 2.826423090780668
Validation loss: 2.5286062763921495

Epoch: 6| Step: 7
Training loss: 2.616948267692506
Validation loss: 2.533026153753173

Epoch: 6| Step: 8
Training loss: 2.832413935620596
Validation loss: 2.5333623424071603

Epoch: 6| Step: 9
Training loss: 2.51619775542567
Validation loss: 2.555245165911437

Epoch: 6| Step: 10
Training loss: 2.66709248798716
Validation loss: 2.5389538136987992

Epoch: 6| Step: 11
Training loss: 3.2993290883862554
Validation loss: 2.5557546327024356

Epoch: 6| Step: 12
Training loss: 2.6931550610277264
Validation loss: 2.544897272745341

Epoch: 6| Step: 13
Training loss: 2.6618814349807662
Validation loss: 2.5453566214964085

Epoch: 372| Step: 0
Training loss: 2.8414246829937224
Validation loss: 2.538834563595047

Epoch: 6| Step: 1
Training loss: 2.3371100401331475
Validation loss: 2.5498561436922556

Epoch: 6| Step: 2
Training loss: 2.6610804897379126
Validation loss: 2.524262429866543

Epoch: 6| Step: 3
Training loss: 3.2725292757617575
Validation loss: 2.556762646274687

Epoch: 6| Step: 4
Training loss: 3.174455166424263
Validation loss: 2.540370874780861

Epoch: 6| Step: 5
Training loss: 2.8152992729073607
Validation loss: 2.5537378129552915

Epoch: 6| Step: 6
Training loss: 2.9613342824513875
Validation loss: 2.540605599595285

Epoch: 6| Step: 7
Training loss: 2.924417297487859
Validation loss: 2.546872274172248

Epoch: 6| Step: 8
Training loss: 1.5938791708865852
Validation loss: 2.5482997878681872

Epoch: 6| Step: 9
Training loss: 3.600004376302814
Validation loss: 2.5347695826126575

Epoch: 6| Step: 10
Training loss: 1.71855578625732
Validation loss: 2.523981898480598

Epoch: 6| Step: 11
Training loss: 2.545311570796715
Validation loss: 2.548956376820719

Epoch: 6| Step: 12
Training loss: 3.036721865350859
Validation loss: 2.5453166067972752

Epoch: 6| Step: 13
Training loss: 2.9576062307360775
Validation loss: 2.5354399808070824

Epoch: 373| Step: 0
Training loss: 2.708321752278925
Validation loss: 2.5375211574889405

Epoch: 6| Step: 1
Training loss: 2.7105399508126
Validation loss: 2.5544702842036946

Epoch: 6| Step: 2
Training loss: 2.4337441289249995
Validation loss: 2.5718808167501113

Epoch: 6| Step: 3
Training loss: 2.4110028775362924
Validation loss: 2.563406704077251

Epoch: 6| Step: 4
Training loss: 2.301204001377764
Validation loss: 2.56163570175603

Epoch: 6| Step: 5
Training loss: 2.5239673920291863
Validation loss: 2.538354485858828

Epoch: 6| Step: 6
Training loss: 3.3817427355497283
Validation loss: 2.535967391195063

Epoch: 6| Step: 7
Training loss: 3.0965109171330747
Validation loss: 2.5202016348285934

Epoch: 6| Step: 8
Training loss: 3.0695243775175993
Validation loss: 2.5178468176862996

Epoch: 6| Step: 9
Training loss: 2.6147220671019125
Validation loss: 2.510641297744268

Epoch: 6| Step: 10
Training loss: 2.755475748181413
Validation loss: 2.5021574678485496

Epoch: 6| Step: 11
Training loss: 2.96760360266969
Validation loss: 2.5234915612206446

Epoch: 6| Step: 12
Training loss: 3.0380834262485603
Validation loss: 2.504533446333922

Epoch: 6| Step: 13
Training loss: 2.9746845558970256
Validation loss: 2.5156762758569378

Epoch: 374| Step: 0
Training loss: 2.736207358985197
Validation loss: 2.514610916177947

Epoch: 6| Step: 1
Training loss: 2.576839056955568
Validation loss: 2.5151102105800733

Epoch: 6| Step: 2
Training loss: 2.3104364621891222
Validation loss: 2.51244786522232

Epoch: 6| Step: 3
Training loss: 2.9832012005178257
Validation loss: 2.5099424345629227

Epoch: 6| Step: 4
Training loss: 2.6396609019197945
Validation loss: 2.517518009156773

Epoch: 6| Step: 5
Training loss: 2.337548966328387
Validation loss: 2.52034437040416

Epoch: 6| Step: 6
Training loss: 2.512604505348797
Validation loss: 2.5392388587202626

Epoch: 6| Step: 7
Training loss: 3.4950461069975978
Validation loss: 2.5321400053943113

Epoch: 6| Step: 8
Training loss: 2.7766825000117645
Validation loss: 2.5333214571997735

Epoch: 6| Step: 9
Training loss: 3.1510448781567226
Validation loss: 2.5346835614212213

Epoch: 6| Step: 10
Training loss: 2.680945098542476
Validation loss: 2.5353664802296625

Epoch: 6| Step: 11
Training loss: 3.4790850113901346
Validation loss: 2.540399777967586

Epoch: 6| Step: 12
Training loss: 2.4573831715565575
Validation loss: 2.5492037397551925

Epoch: 6| Step: 13
Training loss: 2.8077551766362197
Validation loss: 2.533310071520501

Epoch: 375| Step: 0
Training loss: 2.8993224569248097
Validation loss: 2.527937216810577

Epoch: 6| Step: 1
Training loss: 3.1237195252591663
Validation loss: 2.506169344588483

Epoch: 6| Step: 2
Training loss: 3.197905367521688
Validation loss: 2.5019938383399922

Epoch: 6| Step: 3
Training loss: 2.827904455532248
Validation loss: 2.5253660898128913

Epoch: 6| Step: 4
Training loss: 3.040659350115903
Validation loss: 2.516822066952611

Epoch: 6| Step: 5
Training loss: 2.121091726734187
Validation loss: 2.5310918884442075

Epoch: 6| Step: 6
Training loss: 2.669422116838439
Validation loss: 2.5322410854182897

Epoch: 6| Step: 7
Training loss: 2.980619294250492
Validation loss: 2.5463673951245362

Epoch: 6| Step: 8
Training loss: 2.9787202158218062
Validation loss: 2.5372107450804795

Epoch: 6| Step: 9
Training loss: 2.170252351634572
Validation loss: 2.549161299405148

Epoch: 6| Step: 10
Training loss: 2.8768157201042555
Validation loss: 2.5475546959556805

Epoch: 6| Step: 11
Training loss: 2.2600969946985807
Validation loss: 2.5448070268485297

Epoch: 6| Step: 12
Training loss: 2.6598744516214805
Validation loss: 2.5501623327616456

Epoch: 6| Step: 13
Training loss: 3.157777322292929
Validation loss: 2.5688297041497274

Epoch: 376| Step: 0
Training loss: 2.9287449655721574
Validation loss: 2.555797736932784

Epoch: 6| Step: 1
Training loss: 3.316638592420702
Validation loss: 2.558706157826173

Epoch: 6| Step: 2
Training loss: 3.186770486563663
Validation loss: 2.536455207521756

Epoch: 6| Step: 3
Training loss: 2.3584820402819004
Validation loss: 2.5293256635029633

Epoch: 6| Step: 4
Training loss: 2.914187840279452
Validation loss: 2.5258131868791796

Epoch: 6| Step: 5
Training loss: 2.9274718184055324
Validation loss: 2.4974449924738233

Epoch: 6| Step: 6
Training loss: 2.863982277437071
Validation loss: 2.513962855074566

Epoch: 6| Step: 7
Training loss: 2.4457912768550356
Validation loss: 2.515020269390812

Epoch: 6| Step: 8
Training loss: 2.5029754098681805
Validation loss: 2.506952894341237

Epoch: 6| Step: 9
Training loss: 2.255456242726514
Validation loss: 2.5218236678466237

Epoch: 6| Step: 10
Training loss: 2.823865010966121
Validation loss: 2.5228459612140335

Epoch: 6| Step: 11
Training loss: 2.597218136662371
Validation loss: 2.5335905292899774

Epoch: 6| Step: 12
Training loss: 3.2576052373368105
Validation loss: 2.545102842974267

Epoch: 6| Step: 13
Training loss: 2.536763438543993
Validation loss: 2.534940941686906

Epoch: 377| Step: 0
Training loss: 2.372042068809572
Validation loss: 2.5579830685532667

Epoch: 6| Step: 1
Training loss: 2.814434657674926
Validation loss: 2.5739266904621436

Epoch: 6| Step: 2
Training loss: 2.2303582212516853
Validation loss: 2.5875829053139037

Epoch: 6| Step: 3
Training loss: 2.876279629086801
Validation loss: 2.5848018937406674

Epoch: 6| Step: 4
Training loss: 2.863251273504407
Validation loss: 2.584918525862006

Epoch: 6| Step: 5
Training loss: 3.135600915777922
Validation loss: 2.5504857668088228

Epoch: 6| Step: 6
Training loss: 2.847753033870554
Validation loss: 2.5527276021780603

Epoch: 6| Step: 7
Training loss: 3.39149724051335
Validation loss: 2.550092131719535

Epoch: 6| Step: 8
Training loss: 2.5215970818633413
Validation loss: 2.529571987274505

Epoch: 6| Step: 9
Training loss: 2.7596359492435187
Validation loss: 2.5301981302282077

Epoch: 6| Step: 10
Training loss: 2.5488246640002843
Validation loss: 2.505559350260751

Epoch: 6| Step: 11
Training loss: 2.8707085798717564
Validation loss: 2.5163804957148974

Epoch: 6| Step: 12
Training loss: 2.708321048024019
Validation loss: 2.507809818606163

Epoch: 6| Step: 13
Training loss: 3.089366234534051
Validation loss: 2.5162173672889163

Epoch: 378| Step: 0
Training loss: 2.644228671413203
Validation loss: 2.507834194343674

Epoch: 6| Step: 1
Training loss: 2.715886504441024
Validation loss: 2.5046930419970286

Epoch: 6| Step: 2
Training loss: 2.607224909168702
Validation loss: 2.518878398059162

Epoch: 6| Step: 3
Training loss: 2.4295293137060985
Validation loss: 2.521404765675853

Epoch: 6| Step: 4
Training loss: 2.8202074195116578
Validation loss: 2.5407822931476924

Epoch: 6| Step: 5
Training loss: 2.628559968313267
Validation loss: 2.52283588281884

Epoch: 6| Step: 6
Training loss: 2.3523142680712295
Validation loss: 2.5331220997252872

Epoch: 6| Step: 7
Training loss: 2.9183537281601106
Validation loss: 2.5521169017788163

Epoch: 6| Step: 8
Training loss: 2.8407140602444154
Validation loss: 2.570959871481067

Epoch: 6| Step: 9
Training loss: 3.0687430449676945
Validation loss: 2.607753091173516

Epoch: 6| Step: 10
Training loss: 3.161127382119988
Validation loss: 2.5976196473995734

Epoch: 6| Step: 11
Training loss: 2.444201329693543
Validation loss: 2.5962083021653983

Epoch: 6| Step: 12
Training loss: 2.678340117139915
Validation loss: 2.5703503332599276

Epoch: 6| Step: 13
Training loss: 4.002854759034335
Validation loss: 2.56388190639702

Epoch: 379| Step: 0
Training loss: 3.3758615877514533
Validation loss: 2.538980484388009

Epoch: 6| Step: 1
Training loss: 2.9304733646512084
Validation loss: 2.535807051391329

Epoch: 6| Step: 2
Training loss: 2.6231953003020214
Validation loss: 2.521653935631326

Epoch: 6| Step: 3
Training loss: 2.851947580751956
Validation loss: 2.508666133364871

Epoch: 6| Step: 4
Training loss: 2.9412431608380762
Validation loss: 2.5074015835838086

Epoch: 6| Step: 5
Training loss: 3.0492034622422937
Validation loss: 2.507574293535858

Epoch: 6| Step: 6
Training loss: 1.6816733043654337
Validation loss: 2.5244170725554524

Epoch: 6| Step: 7
Training loss: 2.729038458765986
Validation loss: 2.5228258694187895

Epoch: 6| Step: 8
Training loss: 2.815574660787952
Validation loss: 2.534147679469013

Epoch: 6| Step: 9
Training loss: 2.9440131521345836
Validation loss: 2.538800718886477

Epoch: 6| Step: 10
Training loss: 2.196832965215354
Validation loss: 2.5538275053497714

Epoch: 6| Step: 11
Training loss: 2.75184820664198
Validation loss: 2.577757960469239

Epoch: 6| Step: 12
Training loss: 2.580586501000877
Validation loss: 2.5961985411476483

Epoch: 6| Step: 13
Training loss: 3.367789159422938
Validation loss: 2.5833667328892083

Epoch: 380| Step: 0
Training loss: 2.8123859806260976
Validation loss: 2.555201256740639

Epoch: 6| Step: 1
Training loss: 3.0566120767936007
Validation loss: 2.521967422681161

Epoch: 6| Step: 2
Training loss: 2.2927658797140427
Validation loss: 2.5109544158591794

Epoch: 6| Step: 3
Training loss: 2.73568789979133
Validation loss: 2.499657801311654

Epoch: 6| Step: 4
Training loss: 2.6893997574929296
Validation loss: 2.5042185507758328

Epoch: 6| Step: 5
Training loss: 2.8802616236322782
Validation loss: 2.501985149385605

Epoch: 6| Step: 6
Training loss: 2.274606096310212
Validation loss: 2.5104068573287046

Epoch: 6| Step: 7
Training loss: 3.7083886960358177
Validation loss: 2.5037724375974095

Epoch: 6| Step: 8
Training loss: 3.0586971104721763
Validation loss: 2.509019107207837

Epoch: 6| Step: 9
Training loss: 2.79042203876384
Validation loss: 2.5169537545187466

Epoch: 6| Step: 10
Training loss: 2.728086379084806
Validation loss: 2.51734629203179

Epoch: 6| Step: 11
Training loss: 2.659808658515599
Validation loss: 2.5067469737124366

Epoch: 6| Step: 12
Training loss: 2.477525686213644
Validation loss: 2.5202324345216724

Epoch: 6| Step: 13
Training loss: 2.6013792964362197
Validation loss: 2.5172250385634567

Epoch: 381| Step: 0
Training loss: 2.7534920455349456
Validation loss: 2.526277162522423

Epoch: 6| Step: 1
Training loss: 2.8573766510540346
Validation loss: 2.534024770538364

Epoch: 6| Step: 2
Training loss: 2.470118565821797
Validation loss: 2.5351671925584505

Epoch: 6| Step: 3
Training loss: 2.549521726747244
Validation loss: 2.5545965688236807

Epoch: 6| Step: 4
Training loss: 3.0371401475531066
Validation loss: 2.5318415831743994

Epoch: 6| Step: 5
Training loss: 2.7146421947718977
Validation loss: 2.5387964111437906

Epoch: 6| Step: 6
Training loss: 2.1599430027258624
Validation loss: 2.5383758136339614

Epoch: 6| Step: 7
Training loss: 2.9275874634796555
Validation loss: 2.5472982651178593

Epoch: 6| Step: 8
Training loss: 3.092111018518301
Validation loss: 2.54914264698922

Epoch: 6| Step: 9
Training loss: 2.4904610803668996
Validation loss: 2.543877227529028

Epoch: 6| Step: 10
Training loss: 2.662013544049619
Validation loss: 2.524374928405837

Epoch: 6| Step: 11
Training loss: 3.0456960108772884
Validation loss: 2.540017062871038

Epoch: 6| Step: 12
Training loss: 2.829233700422078
Validation loss: 2.544550558895856

Epoch: 6| Step: 13
Training loss: 3.253794875419868
Validation loss: 2.555272371360116

Epoch: 382| Step: 0
Training loss: 2.9796618247963855
Validation loss: 2.5543424698150243

Epoch: 6| Step: 1
Training loss: 2.9330764903705218
Validation loss: 2.5841659149640677

Epoch: 6| Step: 2
Training loss: 2.689469436451988
Validation loss: 2.5807880438645197

Epoch: 6| Step: 3
Training loss: 3.50461764221366
Validation loss: 2.619624369818742

Epoch: 6| Step: 4
Training loss: 2.9518979061222534
Validation loss: 2.549059229888836

Epoch: 6| Step: 5
Training loss: 2.5099687189835413
Validation loss: 2.5412595824004223

Epoch: 6| Step: 6
Training loss: 2.7833525179203713
Validation loss: 2.538309602262165

Epoch: 6| Step: 7
Training loss: 2.4310490267732057
Validation loss: 2.534080615061045

Epoch: 6| Step: 8
Training loss: 2.537227307780372
Validation loss: 2.5359728187774087

Epoch: 6| Step: 9
Training loss: 2.496235588234611
Validation loss: 2.5337592656055046

Epoch: 6| Step: 10
Training loss: 2.8586334767882113
Validation loss: 2.5091681075132777

Epoch: 6| Step: 11
Training loss: 2.7675298822541956
Validation loss: 2.517247379964877

Epoch: 6| Step: 12
Training loss: 2.738229008283756
Validation loss: 2.5178512529079717

Epoch: 6| Step: 13
Training loss: 2.371127233630187
Validation loss: 2.504172923791575

Epoch: 383| Step: 0
Training loss: 2.4730309176920615
Validation loss: 2.512960738370447

Epoch: 6| Step: 1
Training loss: 2.723074006659725
Validation loss: 2.5089784036450578

Epoch: 6| Step: 2
Training loss: 2.7138081503339264
Validation loss: 2.506845104606748

Epoch: 6| Step: 3
Training loss: 2.6432897000201137
Validation loss: 2.5013586833514454

Epoch: 6| Step: 4
Training loss: 2.6842600787857247
Validation loss: 2.5059041006706533

Epoch: 6| Step: 5
Training loss: 2.7979585051278435
Validation loss: 2.5118577585979724

Epoch: 6| Step: 6
Training loss: 2.931601913572695
Validation loss: 2.5136454793783947

Epoch: 6| Step: 7
Training loss: 3.258919580376273
Validation loss: 2.5320549407547372

Epoch: 6| Step: 8
Training loss: 3.1111794608040695
Validation loss: 2.5138705772706387

Epoch: 6| Step: 9
Training loss: 2.8584459807179523
Validation loss: 2.5504583077605147

Epoch: 6| Step: 10
Training loss: 2.3613402411289655
Validation loss: 2.568591654933344

Epoch: 6| Step: 11
Training loss: 2.6152140450631114
Validation loss: 2.5966737658092582

Epoch: 6| Step: 12
Training loss: 3.044805988213268
Validation loss: 2.592792572976096

Epoch: 6| Step: 13
Training loss: 2.6224112688587025
Validation loss: 2.604791642207021

Epoch: 384| Step: 0
Training loss: 2.938283775143906
Validation loss: 2.6172048338877913

Epoch: 6| Step: 1
Training loss: 3.2602752232365293
Validation loss: 2.597256549262298

Epoch: 6| Step: 2
Training loss: 2.2932315916218537
Validation loss: 2.5595250632579023

Epoch: 6| Step: 3
Training loss: 2.564635247811116
Validation loss: 2.5512836146722786

Epoch: 6| Step: 4
Training loss: 2.9882234854506824
Validation loss: 2.5425892266253536

Epoch: 6| Step: 5
Training loss: 2.938075719378296
Validation loss: 2.5526981928181423

Epoch: 6| Step: 6
Training loss: 2.5954139611554727
Validation loss: 2.5265228154927066

Epoch: 6| Step: 7
Training loss: 2.786539084907353
Validation loss: 2.527533825100807

Epoch: 6| Step: 8
Training loss: 2.540487411921306
Validation loss: 2.527114604946542

Epoch: 6| Step: 9
Training loss: 2.7624179327326646
Validation loss: 2.5219917357871133

Epoch: 6| Step: 10
Training loss: 2.9621840296416204
Validation loss: 2.5249079986936716

Epoch: 6| Step: 11
Training loss: 2.3948809071279875
Validation loss: 2.5198882658701347

Epoch: 6| Step: 12
Training loss: 3.015457227714446
Validation loss: 2.5204212933702297

Epoch: 6| Step: 13
Training loss: 2.452363302949488
Validation loss: 2.525130058049127

Epoch: 385| Step: 0
Training loss: 2.313410399341468
Validation loss: 2.516978637546903

Epoch: 6| Step: 1
Training loss: 2.5704079468232357
Validation loss: 2.5065811574686165

Epoch: 6| Step: 2
Training loss: 2.575367510596542
Validation loss: 2.5088328326306617

Epoch: 6| Step: 3
Training loss: 2.646765617263276
Validation loss: 2.497962517219054

Epoch: 6| Step: 4
Training loss: 2.5328497835082664
Validation loss: 2.5206948139476513

Epoch: 6| Step: 5
Training loss: 3.406574058866544
Validation loss: 2.519738481194458

Epoch: 6| Step: 6
Training loss: 2.8225028284834144
Validation loss: 2.5296028375635213

Epoch: 6| Step: 7
Training loss: 2.7579580814310183
Validation loss: 2.537398476627949

Epoch: 6| Step: 8
Training loss: 2.8595727737485994
Validation loss: 2.5248801518193185

Epoch: 6| Step: 9
Training loss: 2.7190121929853546
Validation loss: 2.535048882804227

Epoch: 6| Step: 10
Training loss: 2.7669144550110105
Validation loss: 2.552367056033947

Epoch: 6| Step: 11
Training loss: 2.99507276901975
Validation loss: 2.5380267922503164

Epoch: 6| Step: 12
Training loss: 3.0276067804079942
Validation loss: 2.541372861848047

Epoch: 6| Step: 13
Training loss: 2.5200393519280833
Validation loss: 2.5546860669950417

Epoch: 386| Step: 0
Training loss: 2.8247707138861826
Validation loss: 2.5375117667952987

Epoch: 6| Step: 1
Training loss: 2.784927166135357
Validation loss: 2.5475802189765715

Epoch: 6| Step: 2
Training loss: 2.736439824462221
Validation loss: 2.5580125980503294

Epoch: 6| Step: 3
Training loss: 2.3866486234711015
Validation loss: 2.5799829296041144

Epoch: 6| Step: 4
Training loss: 2.9910924914824246
Validation loss: 2.5804421262638773

Epoch: 6| Step: 5
Training loss: 2.4437460467606593
Validation loss: 2.5732318760983492

Epoch: 6| Step: 6
Training loss: 2.6671439776811194
Validation loss: 2.5639254004347287

Epoch: 6| Step: 7
Training loss: 2.9490952219577156
Validation loss: 2.572211440722372

Epoch: 6| Step: 8
Training loss: 2.3909111101067486
Validation loss: 2.6114709473163136

Epoch: 6| Step: 9
Training loss: 3.801636022443963
Validation loss: 2.56850826262803

Epoch: 6| Step: 10
Training loss: 2.789989669944754
Validation loss: 2.561226819376501

Epoch: 6| Step: 11
Training loss: 2.7902340605531464
Validation loss: 2.52419121398236

Epoch: 6| Step: 12
Training loss: 2.8559830355100315
Validation loss: 2.5027308756203235

Epoch: 6| Step: 13
Training loss: 1.6254051143676083
Validation loss: 2.5102833742390156

Epoch: 387| Step: 0
Training loss: 3.3452542923090918
Validation loss: 2.4917840853906106

Epoch: 6| Step: 1
Training loss: 2.7507685541034945
Validation loss: 2.499858517898996

Epoch: 6| Step: 2
Training loss: 2.9492924763135724
Validation loss: 2.4949568118081737

Epoch: 6| Step: 3
Training loss: 3.111197852636034
Validation loss: 2.4974227900910098

Epoch: 6| Step: 4
Training loss: 2.5376793483248727
Validation loss: 2.489190829134179

Epoch: 6| Step: 5
Training loss: 2.4283610461173795
Validation loss: 2.488579048630025

Epoch: 6| Step: 6
Training loss: 2.4881609014753967
Validation loss: 2.491028984381199

Epoch: 6| Step: 7
Training loss: 2.4407440508186116
Validation loss: 2.4930959357344147

Epoch: 6| Step: 8
Training loss: 1.961026497451285
Validation loss: 2.494554233515479

Epoch: 6| Step: 9
Training loss: 3.198786928799249
Validation loss: 2.4945746115941936

Epoch: 6| Step: 10
Training loss: 2.9928602453372455
Validation loss: 2.4981016129504616

Epoch: 6| Step: 11
Training loss: 2.8182378942330635
Validation loss: 2.513467864445954

Epoch: 6| Step: 12
Training loss: 2.917614773647684
Validation loss: 2.5192946278154533

Epoch: 6| Step: 13
Training loss: 2.5218011138567453
Validation loss: 2.5398940019288854

Epoch: 388| Step: 0
Training loss: 2.2167959070413636
Validation loss: 2.5641370296922754

Epoch: 6| Step: 1
Training loss: 2.486776474819917
Validation loss: 2.5638556537333077

Epoch: 6| Step: 2
Training loss: 2.969253015567886
Validation loss: 2.6199688104269585

Epoch: 6| Step: 3
Training loss: 2.477857762439432
Validation loss: 2.6585942096165045

Epoch: 6| Step: 4
Training loss: 2.576274785899388
Validation loss: 2.6917288805754542

Epoch: 6| Step: 5
Training loss: 3.1898509313019976
Validation loss: 2.7327960812433627

Epoch: 6| Step: 6
Training loss: 2.6016589081001142
Validation loss: 2.753089729628732

Epoch: 6| Step: 7
Training loss: 3.028863498326014
Validation loss: 2.7242479265497543

Epoch: 6| Step: 8
Training loss: 2.8304300767287094
Validation loss: 2.637456867265986

Epoch: 6| Step: 9
Training loss: 2.911022574491517
Validation loss: 2.5681679741550787

Epoch: 6| Step: 10
Training loss: 2.916937751887872
Validation loss: 2.5477662466329214

Epoch: 6| Step: 11
Training loss: 3.1964656922056514
Validation loss: 2.5127931998741437

Epoch: 6| Step: 12
Training loss: 2.696557064477524
Validation loss: 2.493865482143105

Epoch: 6| Step: 13
Training loss: 3.166182045913306
Validation loss: 2.494708645031995

Epoch: 389| Step: 0
Training loss: 1.7687637652073822
Validation loss: 2.4835817671815454

Epoch: 6| Step: 1
Training loss: 3.0629309526183923
Validation loss: 2.491057974318011

Epoch: 6| Step: 2
Training loss: 2.6433775510933946
Validation loss: 2.4917174086337703

Epoch: 6| Step: 3
Training loss: 3.195992469721434
Validation loss: 2.495813389728465

Epoch: 6| Step: 4
Training loss: 2.206118666762597
Validation loss: 2.497952999362647

Epoch: 6| Step: 5
Training loss: 3.492054503637088
Validation loss: 2.492788165218783

Epoch: 6| Step: 6
Training loss: 3.3894543011065292
Validation loss: 2.5029894213944597

Epoch: 6| Step: 7
Training loss: 2.6331096900261244
Validation loss: 2.491806533492513

Epoch: 6| Step: 8
Training loss: 2.67748265436219
Validation loss: 2.505744094120901

Epoch: 6| Step: 9
Training loss: 2.5213928442430387
Validation loss: 2.505861169443898

Epoch: 6| Step: 10
Training loss: 2.5342536342173694
Validation loss: 2.5210246663783895

Epoch: 6| Step: 11
Training loss: 2.5256217266647774
Validation loss: 2.5172851802438543

Epoch: 6| Step: 12
Training loss: 3.4098763017787928
Validation loss: 2.540231348526247

Epoch: 6| Step: 13
Training loss: 2.60202004014903
Validation loss: 2.5553638087002466

Epoch: 390| Step: 0
Training loss: 2.7353377037146687
Validation loss: 2.5494740668235574

Epoch: 6| Step: 1
Training loss: 3.317697729615773
Validation loss: 2.5523392968128102

Epoch: 6| Step: 2
Training loss: 3.174900059366104
Validation loss: 2.5465358113435785

Epoch: 6| Step: 3
Training loss: 2.74066711184641
Validation loss: 2.554117230993153

Epoch: 6| Step: 4
Training loss: 2.9781198507546645
Validation loss: 2.5336592013199346

Epoch: 6| Step: 5
Training loss: 2.7964900087464204
Validation loss: 2.514712772153726

Epoch: 6| Step: 6
Training loss: 2.608517625857019
Validation loss: 2.5153271144544163

Epoch: 6| Step: 7
Training loss: 2.7089651886825075
Validation loss: 2.5140281668426523

Epoch: 6| Step: 8
Training loss: 3.287406740207473
Validation loss: 2.5018191922494757

Epoch: 6| Step: 9
Training loss: 2.6717370427080613
Validation loss: 2.5113408106666855

Epoch: 6| Step: 10
Training loss: 2.865948068759221
Validation loss: 2.522437602565304

Epoch: 6| Step: 11
Training loss: 1.9754065348712617
Validation loss: 2.524528129312335

Epoch: 6| Step: 12
Training loss: 2.405659095243055
Validation loss: 2.5148645524335813

Epoch: 6| Step: 13
Training loss: 2.1381100548091134
Validation loss: 2.522789919826688

Epoch: 391| Step: 0
Training loss: 3.037815495185329
Validation loss: 2.5276288233138824

Epoch: 6| Step: 1
Training loss: 2.057906960974688
Validation loss: 2.5440673874415927

Epoch: 6| Step: 2
Training loss: 2.29852640380697
Validation loss: 2.5360022623752005

Epoch: 6| Step: 3
Training loss: 3.58268480568276
Validation loss: 2.541856881347909

Epoch: 6| Step: 4
Training loss: 2.77111960249253
Validation loss: 2.550508761699913

Epoch: 6| Step: 5
Training loss: 2.8924755874170676
Validation loss: 2.529539478554584

Epoch: 6| Step: 6
Training loss: 2.5587875642241436
Validation loss: 2.541887439827135

Epoch: 6| Step: 7
Training loss: 2.6882963553161967
Validation loss: 2.5258260262973056

Epoch: 6| Step: 8
Training loss: 3.374415876914992
Validation loss: 2.52151648887636

Epoch: 6| Step: 9
Training loss: 2.142435352502974
Validation loss: 2.5226142475312536

Epoch: 6| Step: 10
Training loss: 2.6583509327017913
Validation loss: 2.535787922638062

Epoch: 6| Step: 11
Training loss: 2.3188190213441753
Validation loss: 2.5182771657910163

Epoch: 6| Step: 12
Training loss: 3.0948203961299203
Validation loss: 2.516779495129872

Epoch: 6| Step: 13
Training loss: 2.729555252793348
Validation loss: 2.5170473115949097

Epoch: 392| Step: 0
Training loss: 2.401010332434052
Validation loss: 2.536677749751012

Epoch: 6| Step: 1
Training loss: 2.856283215219036
Validation loss: 2.529778775984168

Epoch: 6| Step: 2
Training loss: 3.697457269778898
Validation loss: 2.5494284865436794

Epoch: 6| Step: 3
Training loss: 2.3898828887976853
Validation loss: 2.5433219839624583

Epoch: 6| Step: 4
Training loss: 2.945036938472882
Validation loss: 2.524166947453027

Epoch: 6| Step: 5
Training loss: 2.72538281472831
Validation loss: 2.526117699995538

Epoch: 6| Step: 6
Training loss: 2.212863905123326
Validation loss: 2.531559857203648

Epoch: 6| Step: 7
Training loss: 3.2388996412717805
Validation loss: 2.544533078670262

Epoch: 6| Step: 8
Training loss: 3.171190911548113
Validation loss: 2.5189052019257576

Epoch: 6| Step: 9
Training loss: 1.8820283768609374
Validation loss: 2.509836549500125

Epoch: 6| Step: 10
Training loss: 1.9655501383245608
Validation loss: 2.5245856299329454

Epoch: 6| Step: 11
Training loss: 2.910852868594945
Validation loss: 2.528741008076351

Epoch: 6| Step: 12
Training loss: 3.1257974751496387
Validation loss: 2.5162147559825785

Epoch: 6| Step: 13
Training loss: 2.4692693236536223
Validation loss: 2.52288199739696

Epoch: 393| Step: 0
Training loss: 3.024954481807023
Validation loss: 2.53869771780761

Epoch: 6| Step: 1
Training loss: 2.240482120400861
Validation loss: 2.5523923290471506

Epoch: 6| Step: 2
Training loss: 2.810399351827806
Validation loss: 2.5349996937368524

Epoch: 6| Step: 3
Training loss: 2.3431143343711476
Validation loss: 2.5825472306195416

Epoch: 6| Step: 4
Training loss: 2.6935473868162063
Validation loss: 2.582967379633668

Epoch: 6| Step: 5
Training loss: 2.506681002802469
Validation loss: 2.574969927433668

Epoch: 6| Step: 6
Training loss: 2.2713475009814865
Validation loss: 2.6078653471322792

Epoch: 6| Step: 7
Training loss: 2.3507731687610347
Validation loss: 2.6120077351695845

Epoch: 6| Step: 8
Training loss: 3.1770896703104494
Validation loss: 2.6156507221290672

Epoch: 6| Step: 9
Training loss: 3.2028436304582515
Validation loss: 2.5993177421196134

Epoch: 6| Step: 10
Training loss: 3.003101970413617
Validation loss: 2.6010399070307777

Epoch: 6| Step: 11
Training loss: 3.2042639219474633
Validation loss: 2.592143176709238

Epoch: 6| Step: 12
Training loss: 2.82352026272909
Validation loss: 2.582510292766434

Epoch: 6| Step: 13
Training loss: 2.680761272286833
Validation loss: 2.5448632089709924

Epoch: 394| Step: 0
Training loss: 2.182099132799931
Validation loss: 2.5203719083329332

Epoch: 6| Step: 1
Training loss: 2.321625103858022
Validation loss: 2.507758319545344

Epoch: 6| Step: 2
Training loss: 3.3448312027427196
Validation loss: 2.5105085765006074

Epoch: 6| Step: 3
Training loss: 1.9180727928517152
Validation loss: 2.4805225994662146

Epoch: 6| Step: 4
Training loss: 3.2362722830596464
Validation loss: 2.4945397208798923

Epoch: 6| Step: 5
Training loss: 2.7647355368101625
Validation loss: 2.484965825758996

Epoch: 6| Step: 6
Training loss: 2.6736023433480987
Validation loss: 2.4956747417143643

Epoch: 6| Step: 7
Training loss: 3.391186223848784
Validation loss: 2.509487204871167

Epoch: 6| Step: 8
Training loss: 3.2336538496789444
Validation loss: 2.4959548340750475

Epoch: 6| Step: 9
Training loss: 2.84409003268421
Validation loss: 2.500677217004044

Epoch: 6| Step: 10
Training loss: 2.4238053043345524
Validation loss: 2.5121032984900085

Epoch: 6| Step: 11
Training loss: 2.413296574932626
Validation loss: 2.5354143497310413

Epoch: 6| Step: 12
Training loss: 2.263889674191121
Validation loss: 2.5269394225110737

Epoch: 6| Step: 13
Training loss: 3.3781590688506675
Validation loss: 2.536837916286465

Epoch: 395| Step: 0
Training loss: 2.99706044821609
Validation loss: 2.552122045896805

Epoch: 6| Step: 1
Training loss: 2.973750190109497
Validation loss: 2.568035098367556

Epoch: 6| Step: 2
Training loss: 2.50574462818193
Validation loss: 2.584613578747319

Epoch: 6| Step: 3
Training loss: 2.0625369906720765
Validation loss: 2.605245962302245

Epoch: 6| Step: 4
Training loss: 2.8449714468812046
Validation loss: 2.604751813223877

Epoch: 6| Step: 5
Training loss: 3.0827614193690045
Validation loss: 2.605782783033443

Epoch: 6| Step: 6
Training loss: 3.351282637144453
Validation loss: 2.5718079269997673

Epoch: 6| Step: 7
Training loss: 2.3738318130190827
Validation loss: 2.5586422710613324

Epoch: 6| Step: 8
Training loss: 2.1072932390580195
Validation loss: 2.5449586089546417

Epoch: 6| Step: 9
Training loss: 2.9133709043383265
Validation loss: 2.5151866810466013

Epoch: 6| Step: 10
Training loss: 2.6127980331460217
Validation loss: 2.50322740461146

Epoch: 6| Step: 11
Training loss: 2.642571448566492
Validation loss: 2.490334138651344

Epoch: 6| Step: 12
Training loss: 3.0477113798465547
Validation loss: 2.4963296676096345

Epoch: 6| Step: 13
Training loss: 3.1108563598903305
Validation loss: 2.491697530884203

Epoch: 396| Step: 0
Training loss: 3.360537305740909
Validation loss: 2.499555317492391

Epoch: 6| Step: 1
Training loss: 2.2969090465695174
Validation loss: 2.502790696204838

Epoch: 6| Step: 2
Training loss: 2.932150332001756
Validation loss: 2.502883829604447

Epoch: 6| Step: 3
Training loss: 2.232635140766052
Validation loss: 2.5115371802036677

Epoch: 6| Step: 4
Training loss: 2.0111413812320493
Validation loss: 2.5202635379845617

Epoch: 6| Step: 5
Training loss: 2.9216822596335357
Validation loss: 2.5138607963672817

Epoch: 6| Step: 6
Training loss: 2.6520082601473263
Validation loss: 2.545314113978243

Epoch: 6| Step: 7
Training loss: 2.778349317456243
Validation loss: 2.5451445189965702

Epoch: 6| Step: 8
Training loss: 2.4224006328536585
Validation loss: 2.5612670329244884

Epoch: 6| Step: 9
Training loss: 3.296602789321383
Validation loss: 2.581144507803781

Epoch: 6| Step: 10
Training loss: 2.9815065669374947
Validation loss: 2.5814024317911257

Epoch: 6| Step: 11
Training loss: 2.4449934583705146
Validation loss: 2.572075362051262

Epoch: 6| Step: 12
Training loss: 2.996460734226747
Validation loss: 2.583108029446244

Epoch: 6| Step: 13
Training loss: 3.278871091700058
Validation loss: 2.586026608444564

Epoch: 397| Step: 0
Training loss: 2.606405064203109
Validation loss: 2.5315769966249237

Epoch: 6| Step: 1
Training loss: 2.3663449440360633
Validation loss: 2.519020820864757

Epoch: 6| Step: 2
Training loss: 3.1863553853077176
Validation loss: 2.5280332737812765

Epoch: 6| Step: 3
Training loss: 2.5912119385739003
Validation loss: 2.5148856538239

Epoch: 6| Step: 4
Training loss: 2.595570029125111
Validation loss: 2.518051825504405

Epoch: 6| Step: 5
Training loss: 3.1900500400648384
Validation loss: 2.509185277280959

Epoch: 6| Step: 6
Training loss: 2.6462254471466458
Validation loss: 2.4997215320998603

Epoch: 6| Step: 7
Training loss: 2.552138990976051
Validation loss: 2.5122290963407816

Epoch: 6| Step: 8
Training loss: 2.2817873387253864
Validation loss: 2.499725646685278

Epoch: 6| Step: 9
Training loss: 3.1269319284591544
Validation loss: 2.4997242734482756

Epoch: 6| Step: 10
Training loss: 2.8569357217908884
Validation loss: 2.5068294799056274

Epoch: 6| Step: 11
Training loss: 2.694456633532593
Validation loss: 2.50972113464741

Epoch: 6| Step: 12
Training loss: 2.7442730311695467
Validation loss: 2.5220529393697952

Epoch: 6| Step: 13
Training loss: 3.0067828112694652
Validation loss: 2.5245894785608103

Epoch: 398| Step: 0
Training loss: 3.164068528157838
Validation loss: 2.526288589538633

Epoch: 6| Step: 1
Training loss: 2.9462867966928643
Validation loss: 2.543318030626447

Epoch: 6| Step: 2
Training loss: 2.503975758651539
Validation loss: 2.5386512603795537

Epoch: 6| Step: 3
Training loss: 2.3691446503984763
Validation loss: 2.57579060432373

Epoch: 6| Step: 4
Training loss: 2.743144767587446
Validation loss: 2.5693817473210783

Epoch: 6| Step: 5
Training loss: 2.7523048452269183
Validation loss: 2.561647716123895

Epoch: 6| Step: 6
Training loss: 2.293961526124055
Validation loss: 2.571917164661173

Epoch: 6| Step: 7
Training loss: 2.0890488868789117
Validation loss: 2.559440513130055

Epoch: 6| Step: 8
Training loss: 3.0058947505938973
Validation loss: 2.55581796874777

Epoch: 6| Step: 9
Training loss: 2.6142184140895615
Validation loss: 2.550360122005784

Epoch: 6| Step: 10
Training loss: 3.3330241218836245
Validation loss: 2.5197479808578835

Epoch: 6| Step: 11
Training loss: 3.052923058788226
Validation loss: 2.5028231800269958

Epoch: 6| Step: 12
Training loss: 2.8212867808109934
Validation loss: 2.4969245462279863

Epoch: 6| Step: 13
Training loss: 2.654892877691415
Validation loss: 2.508148471399283

Epoch: 399| Step: 0
Training loss: 3.035016737865064
Validation loss: 2.4927917523555596

Epoch: 6| Step: 1
Training loss: 2.6062151570358085
Validation loss: 2.488588498292038

Epoch: 6| Step: 2
Training loss: 2.707331212806701
Validation loss: 2.523023693265894

Epoch: 6| Step: 3
Training loss: 2.5652206678446885
Validation loss: 2.517255269730912

Epoch: 6| Step: 4
Training loss: 2.9168548704915462
Validation loss: 2.5295276876871484

Epoch: 6| Step: 5
Training loss: 2.767115390727645
Validation loss: 2.505586222941525

Epoch: 6| Step: 6
Training loss: 2.8421007341307902
Validation loss: 2.5437218691455166

Epoch: 6| Step: 7
Training loss: 3.0312896411309387
Validation loss: 2.5288608172762075

Epoch: 6| Step: 8
Training loss: 2.7128008064797546
Validation loss: 2.5385053762064107

Epoch: 6| Step: 9
Training loss: 2.1829149422878737
Validation loss: 2.5618760384493924

Epoch: 6| Step: 10
Training loss: 2.6601140359226236
Validation loss: 2.538969589565471

Epoch: 6| Step: 11
Training loss: 3.00477918781552
Validation loss: 2.5990191481372493

Epoch: 6| Step: 12
Training loss: 2.9726098917931734
Validation loss: 2.5515982750581876

Epoch: 6| Step: 13
Training loss: 2.163670914128578
Validation loss: 2.545956897417238

Epoch: 400| Step: 0
Training loss: 2.433614519499052
Validation loss: 2.5219661408439595

Epoch: 6| Step: 1
Training loss: 2.487283407778525
Validation loss: 2.5458878804158083

Epoch: 6| Step: 2
Training loss: 2.8689868903992424
Validation loss: 2.535454521719326

Epoch: 6| Step: 3
Training loss: 2.5372238309561066
Validation loss: 2.5387832172478815

Epoch: 6| Step: 4
Training loss: 2.8372833169219107
Validation loss: 2.5269459489353974

Epoch: 6| Step: 5
Training loss: 3.4053301487875167
Validation loss: 2.5445421553049834

Epoch: 6| Step: 6
Training loss: 3.0700309177792664
Validation loss: 2.5311355838416434

Epoch: 6| Step: 7
Training loss: 2.9198371185963956
Validation loss: 2.5543464803578773

Epoch: 6| Step: 8
Training loss: 2.4770969331676533
Validation loss: 2.5320820860585527

Epoch: 6| Step: 9
Training loss: 2.5425823521663182
Validation loss: 2.547584254253157

Epoch: 6| Step: 10
Training loss: 2.9590172491985727
Validation loss: 2.542391150465222

Epoch: 6| Step: 11
Training loss: 2.5658633791618137
Validation loss: 2.523992721892626

Epoch: 6| Step: 12
Training loss: 2.573445645419619
Validation loss: 2.5223017230989067

Epoch: 6| Step: 13
Training loss: 2.1232247510581304
Validation loss: 2.540322896843764

Epoch: 401| Step: 0
Training loss: 3.0294645104426854
Validation loss: 2.5420708505567213

Epoch: 6| Step: 1
Training loss: 3.41812792598106
Validation loss: 2.5465204709452647

Epoch: 6| Step: 2
Training loss: 2.2131243024306233
Validation loss: 2.5695181641945593

Epoch: 6| Step: 3
Training loss: 2.283895656740939
Validation loss: 2.5582292625447827

Epoch: 6| Step: 4
Training loss: 2.9345976106259446
Validation loss: 2.5715737952095723

Epoch: 6| Step: 5
Training loss: 2.658857793304232
Validation loss: 2.557878546257635

Epoch: 6| Step: 6
Training loss: 2.713857348061508
Validation loss: 2.573465381858816

Epoch: 6| Step: 7
Training loss: 2.4106349871475286
Validation loss: 2.5609376397873898

Epoch: 6| Step: 8
Training loss: 2.632006151006636
Validation loss: 2.571339744792247

Epoch: 6| Step: 9
Training loss: 2.340509947125103
Validation loss: 2.5892755625115753

Epoch: 6| Step: 10
Training loss: 2.7533386078322954
Validation loss: 2.6105926690692893

Epoch: 6| Step: 11
Training loss: 3.4473259334313884
Validation loss: 2.572244934526542

Epoch: 6| Step: 12
Training loss: 2.0295400611474133
Validation loss: 2.560846162705707

Epoch: 6| Step: 13
Training loss: 3.5737532515776214
Validation loss: 2.543958900857359

Epoch: 402| Step: 0
Training loss: 2.7304116435484773
Validation loss: 2.529296492880921

Epoch: 6| Step: 1
Training loss: 2.3489405820955396
Validation loss: 2.5202171049110595

Epoch: 6| Step: 2
Training loss: 2.5674262726922557
Validation loss: 2.4932949215831766

Epoch: 6| Step: 3
Training loss: 2.9926276219433254
Validation loss: 2.50628761727874

Epoch: 6| Step: 4
Training loss: 2.9702684233644505
Validation loss: 2.5067528255733333

Epoch: 6| Step: 5
Training loss: 3.391778283934279
Validation loss: 2.4903432717944263

Epoch: 6| Step: 6
Training loss: 2.9786152006920843
Validation loss: 2.506397147312813

Epoch: 6| Step: 7
Training loss: 3.1106279618653647
Validation loss: 2.514234603566569

Epoch: 6| Step: 8
Training loss: 2.94118609370733
Validation loss: 2.5242696649897605

Epoch: 6| Step: 9
Training loss: 3.039594981167085
Validation loss: 2.5269782906547995

Epoch: 6| Step: 10
Training loss: 1.939916764666208
Validation loss: 2.548497863502488

Epoch: 6| Step: 11
Training loss: 2.5653786655982183
Validation loss: 2.557450460341628

Epoch: 6| Step: 12
Training loss: 1.8343226046772103
Validation loss: 2.574604725329766

Epoch: 6| Step: 13
Training loss: 2.683351286439091
Validation loss: 2.566935897911703

Epoch: 403| Step: 0
Training loss: 2.723925783000551
Validation loss: 2.5981396030733173

Epoch: 6| Step: 1
Training loss: 2.9459559701502607
Validation loss: 2.5810849537317853

Epoch: 6| Step: 2
Training loss: 2.4847463654118194
Validation loss: 2.6105338368817694

Epoch: 6| Step: 3
Training loss: 3.094297110221196
Validation loss: 2.6121796165950637

Epoch: 6| Step: 4
Training loss: 2.823456087457624
Validation loss: 2.5932455747320593

Epoch: 6| Step: 5
Training loss: 2.9458237262517017
Validation loss: 2.579714857452659

Epoch: 6| Step: 6
Training loss: 2.933631134810891
Validation loss: 2.51499762482854

Epoch: 6| Step: 7
Training loss: 2.9223239166234523
Validation loss: 2.5189917334370406

Epoch: 6| Step: 8
Training loss: 2.682876779878182
Validation loss: 2.502904614612913

Epoch: 6| Step: 9
Training loss: 2.1696370622040573
Validation loss: 2.4872088190929795

Epoch: 6| Step: 10
Training loss: 2.42602301973018
Validation loss: 2.5016558516348137

Epoch: 6| Step: 11
Training loss: 2.434022819694177
Validation loss: 2.482679836506225

Epoch: 6| Step: 12
Training loss: 3.2473870557448703
Validation loss: 2.4910805344488027

Epoch: 6| Step: 13
Training loss: 2.697198092135202
Validation loss: 2.4847768483210717

Epoch: 404| Step: 0
Training loss: 2.4786192238802083
Validation loss: 2.484643238683761

Epoch: 6| Step: 1
Training loss: 2.5676968608442574
Validation loss: 2.4916493076484305

Epoch: 6| Step: 2
Training loss: 2.47360100558163
Validation loss: 2.4950021655012704

Epoch: 6| Step: 3
Training loss: 3.2272369197172877
Validation loss: 2.5054522608291645

Epoch: 6| Step: 4
Training loss: 2.6428466119151386
Validation loss: 2.498641042623117

Epoch: 6| Step: 5
Training loss: 2.778647072722359
Validation loss: 2.5033520816445938

Epoch: 6| Step: 6
Training loss: 2.6924134516641662
Validation loss: 2.5146563180890977

Epoch: 6| Step: 7
Training loss: 2.849945194989005
Validation loss: 2.531674820245643

Epoch: 6| Step: 8
Training loss: 2.4839507886400933
Validation loss: 2.550216868904539

Epoch: 6| Step: 9
Training loss: 2.712949418487512
Validation loss: 2.5502861929627194

Epoch: 6| Step: 10
Training loss: 2.6521080485408683
Validation loss: 2.5666393988809193

Epoch: 6| Step: 11
Training loss: 3.018415829819361
Validation loss: 2.554187092562805

Epoch: 6| Step: 12
Training loss: 3.2502172837615944
Validation loss: 2.5495429988120493

Epoch: 6| Step: 13
Training loss: 2.5475142911111464
Validation loss: 2.571408469477541

Epoch: 405| Step: 0
Training loss: 2.9235789180703753
Validation loss: 2.5587305847265283

Epoch: 6| Step: 1
Training loss: 2.8032656495053723
Validation loss: 2.5562367032728184

Epoch: 6| Step: 2
Training loss: 2.7869913227232286
Validation loss: 2.5194327849429223

Epoch: 6| Step: 3
Training loss: 2.6078207903822217
Validation loss: 2.5096210670328882

Epoch: 6| Step: 4
Training loss: 3.0137054184377567
Validation loss: 2.5040139184801036

Epoch: 6| Step: 5
Training loss: 2.6620097823905473
Validation loss: 2.502444727021302

Epoch: 6| Step: 6
Training loss: 2.435472280771784
Validation loss: 2.50419693260159

Epoch: 6| Step: 7
Training loss: 2.6300516113322727
Validation loss: 2.503300598408083

Epoch: 6| Step: 8
Training loss: 3.3941769607079397
Validation loss: 2.4977819098626224

Epoch: 6| Step: 9
Training loss: 2.67225617483894
Validation loss: 2.4986493225422

Epoch: 6| Step: 10
Training loss: 2.338452978229492
Validation loss: 2.4971722053370113

Epoch: 6| Step: 11
Training loss: 2.6518629759174948
Validation loss: 2.507345455170128

Epoch: 6| Step: 12
Training loss: 3.0780845678162283
Validation loss: 2.5073231201156685

Epoch: 6| Step: 13
Training loss: 2.1533079116706415
Validation loss: 2.5112750717091896

Epoch: 406| Step: 0
Training loss: 2.8309268455418573
Validation loss: 2.5211395139425146

Epoch: 6| Step: 1
Training loss: 3.194148740120164
Validation loss: 2.5212807444312646

Epoch: 6| Step: 2
Training loss: 2.1628720972178037
Validation loss: 2.5157623671336227

Epoch: 6| Step: 3
Training loss: 2.2438308063715655
Validation loss: 2.534135325313015

Epoch: 6| Step: 4
Training loss: 3.0439434326871
Validation loss: 2.529491206999254

Epoch: 6| Step: 5
Training loss: 2.7915328169281945
Validation loss: 2.5450520572374495

Epoch: 6| Step: 6
Training loss: 2.280364713945376
Validation loss: 2.5707040949676845

Epoch: 6| Step: 7
Training loss: 2.4927569369593647
Validation loss: 2.5669146411466803

Epoch: 6| Step: 8
Training loss: 2.49591493637682
Validation loss: 2.5983150500757017

Epoch: 6| Step: 9
Training loss: 2.7579463245460647
Validation loss: 2.5871242943381394

Epoch: 6| Step: 10
Training loss: 2.7520648833432957
Validation loss: 2.572270661052002

Epoch: 6| Step: 11
Training loss: 2.52987803259411
Validation loss: 2.574490663607582

Epoch: 6| Step: 12
Training loss: 3.5212192361535255
Validation loss: 2.5481128554477186

Epoch: 6| Step: 13
Training loss: 3.0477614458201026
Validation loss: 2.5525844708940717

Epoch: 407| Step: 0
Training loss: 2.3082737838096565
Validation loss: 2.5314420675058877

Epoch: 6| Step: 1
Training loss: 3.027438884593902
Validation loss: 2.543377311877988

Epoch: 6| Step: 2
Training loss: 3.4554979275241973
Validation loss: 2.539725401664871

Epoch: 6| Step: 3
Training loss: 2.7657806869910555
Validation loss: 2.5343163857701407

Epoch: 6| Step: 4
Training loss: 2.4722403467302145
Validation loss: 2.534785319792373

Epoch: 6| Step: 5
Training loss: 2.5096407016879136
Validation loss: 2.5105191802437647

Epoch: 6| Step: 6
Training loss: 2.572325593543321
Validation loss: 2.5272531668936224

Epoch: 6| Step: 7
Training loss: 2.825634866455511
Validation loss: 2.497156616101924

Epoch: 6| Step: 8
Training loss: 2.831539221805699
Validation loss: 2.501464343107915

Epoch: 6| Step: 9
Training loss: 2.1543920501131684
Validation loss: 2.487292503680974

Epoch: 6| Step: 10
Training loss: 2.384049391606103
Validation loss: 2.5104043563958274

Epoch: 6| Step: 11
Training loss: 2.972977369009981
Validation loss: 2.506178939671585

Epoch: 6| Step: 12
Training loss: 2.9655992352056844
Validation loss: 2.5276688705501176

Epoch: 6| Step: 13
Training loss: 2.5865384697198253
Validation loss: 2.5362180668603473

Epoch: 408| Step: 0
Training loss: 2.3199788377059747
Validation loss: 2.5661751109293265

Epoch: 6| Step: 1
Training loss: 2.3314136601086077
Validation loss: 2.5928395829800257

Epoch: 6| Step: 2
Training loss: 2.2388022783353363
Validation loss: 2.625389978414126

Epoch: 6| Step: 3
Training loss: 2.6968916979788866
Validation loss: 2.648500481987766

Epoch: 6| Step: 4
Training loss: 3.052745465180991
Validation loss: 2.677601242546541

Epoch: 6| Step: 5
Training loss: 2.3619202280874934
Validation loss: 2.633031200713317

Epoch: 6| Step: 6
Training loss: 3.3019812214142386
Validation loss: 2.6080124414261583

Epoch: 6| Step: 7
Training loss: 2.8903683110269305
Validation loss: 2.5646525180526316

Epoch: 6| Step: 8
Training loss: 2.88383668317014
Validation loss: 2.5191319872909617

Epoch: 6| Step: 9
Training loss: 3.171998871888469
Validation loss: 2.503518961693225

Epoch: 6| Step: 10
Training loss: 3.1034375727677213
Validation loss: 2.477244987944169

Epoch: 6| Step: 11
Training loss: 2.3830801391380954
Validation loss: 2.4790190496537234

Epoch: 6| Step: 12
Training loss: 3.013945591203232
Validation loss: 2.483552952167505

Epoch: 6| Step: 13
Training loss: 2.899652519454968
Validation loss: 2.4786769010560055

Epoch: 409| Step: 0
Training loss: 2.8062304659632975
Validation loss: 2.476429725670234

Epoch: 6| Step: 1
Training loss: 3.2213013546232157
Validation loss: 2.480294846160236

Epoch: 6| Step: 2
Training loss: 2.45616573742484
Validation loss: 2.4819433780722377

Epoch: 6| Step: 3
Training loss: 3.152610568982189
Validation loss: 2.4806798500005955

Epoch: 6| Step: 4
Training loss: 2.321244177988174
Validation loss: 2.4969634678267796

Epoch: 6| Step: 5
Training loss: 2.5434918546791803
Validation loss: 2.4930282647113278

Epoch: 6| Step: 6
Training loss: 3.037470932809658
Validation loss: 2.499552091856637

Epoch: 6| Step: 7
Training loss: 2.820191441524086
Validation loss: 2.5031278322138357

Epoch: 6| Step: 8
Training loss: 2.473654306034483
Validation loss: 2.5296216269640373

Epoch: 6| Step: 9
Training loss: 2.531349274372216
Validation loss: 2.5380306174659526

Epoch: 6| Step: 10
Training loss: 2.436068187680069
Validation loss: 2.5680741980467006

Epoch: 6| Step: 11
Training loss: 2.502367996255563
Validation loss: 2.6126232162710785

Epoch: 6| Step: 12
Training loss: 3.2179373298550287
Validation loss: 2.60715361622373

Epoch: 6| Step: 13
Training loss: 2.9679851952258103
Validation loss: 2.6079451983948987

Epoch: 410| Step: 0
Training loss: 2.6031550667847845
Validation loss: 2.6446675438925595

Epoch: 6| Step: 1
Training loss: 3.4024777303915665
Validation loss: 2.616892121564686

Epoch: 6| Step: 2
Training loss: 2.704464442742427
Validation loss: 2.5621467454889864

Epoch: 6| Step: 3
Training loss: 2.507723417512189
Validation loss: 2.55631397326824

Epoch: 6| Step: 4
Training loss: 2.2907400396376754
Validation loss: 2.5242883833882024

Epoch: 6| Step: 5
Training loss: 2.937003073358535
Validation loss: 2.5131545167985943

Epoch: 6| Step: 6
Training loss: 2.058623282928279
Validation loss: 2.51502095947848

Epoch: 6| Step: 7
Training loss: 3.0760726670510428
Validation loss: 2.5124993691759663

Epoch: 6| Step: 8
Training loss: 2.9641374593616137
Validation loss: 2.488405530262558

Epoch: 6| Step: 9
Training loss: 3.019756274209467
Validation loss: 2.478882277376002

Epoch: 6| Step: 10
Training loss: 2.659549055667971
Validation loss: 2.4803504389177493

Epoch: 6| Step: 11
Training loss: 3.2212335578874827
Validation loss: 2.4809775256623956

Epoch: 6| Step: 12
Training loss: 2.338681857545089
Validation loss: 2.480349993444724

Epoch: 6| Step: 13
Training loss: 2.3338613820888474
Validation loss: 2.501616696629582

Epoch: 411| Step: 0
Training loss: 3.384881424285011
Validation loss: 2.5008037474902434

Epoch: 6| Step: 1
Training loss: 1.9693457292507985
Validation loss: 2.5296165313410555

Epoch: 6| Step: 2
Training loss: 2.5992898264581252
Validation loss: 2.5139529021899873

Epoch: 6| Step: 3
Training loss: 2.0996607006808023
Validation loss: 2.520655732969591

Epoch: 6| Step: 4
Training loss: 3.1656466062510744
Validation loss: 2.5724258947862726

Epoch: 6| Step: 5
Training loss: 2.5758658943927957
Validation loss: 2.564444293783649

Epoch: 6| Step: 6
Training loss: 2.6340020545887737
Validation loss: 2.5748972645173143

Epoch: 6| Step: 7
Training loss: 2.96087807467371
Validation loss: 2.6012472616840405

Epoch: 6| Step: 8
Training loss: 3.1831881212065105
Validation loss: 2.5943818650234496

Epoch: 6| Step: 9
Training loss: 2.897844197299311
Validation loss: 2.6165911682484

Epoch: 6| Step: 10
Training loss: 2.5828669547486602
Validation loss: 2.6184678965621924

Epoch: 6| Step: 11
Training loss: 3.1241545487198787
Validation loss: 2.5891203993579857

Epoch: 6| Step: 12
Training loss: 1.9781378096275735
Validation loss: 2.57827169299936

Epoch: 6| Step: 13
Training loss: 2.8203264484430437
Validation loss: 2.538027627596288

Epoch: 412| Step: 0
Training loss: 2.9252412549807425
Validation loss: 2.52047424043584

Epoch: 6| Step: 1
Training loss: 1.9714581467599737
Validation loss: 2.518852426452494

Epoch: 6| Step: 2
Training loss: 2.6785391524050564
Validation loss: 2.477537435867967

Epoch: 6| Step: 3
Training loss: 2.631975986243622
Validation loss: 2.4990702079337477

Epoch: 6| Step: 4
Training loss: 2.7998017922137977
Validation loss: 2.488894276910996

Epoch: 6| Step: 5
Training loss: 2.952892798927521
Validation loss: 2.496195046974659

Epoch: 6| Step: 6
Training loss: 2.795289511929913
Validation loss: 2.4964755512816827

Epoch: 6| Step: 7
Training loss: 2.8932371142278517
Validation loss: 2.484569956479233

Epoch: 6| Step: 8
Training loss: 3.0508728404345167
Validation loss: 2.504360667940387

Epoch: 6| Step: 9
Training loss: 2.5376573635972868
Validation loss: 2.5013014389986763

Epoch: 6| Step: 10
Training loss: 2.154318566442246
Validation loss: 2.4982437527900565

Epoch: 6| Step: 11
Training loss: 3.214290603755078
Validation loss: 2.496838785971796

Epoch: 6| Step: 12
Training loss: 2.756490504007159
Validation loss: 2.538981735421636

Epoch: 6| Step: 13
Training loss: 2.86320980550148
Validation loss: 2.53147940012066

Epoch: 413| Step: 0
Training loss: 2.8764021398301614
Validation loss: 2.538730946389442

Epoch: 6| Step: 1
Training loss: 2.450848051163384
Validation loss: 2.5254283272475377

Epoch: 6| Step: 2
Training loss: 3.390900490815211
Validation loss: 2.5480357713964827

Epoch: 6| Step: 3
Training loss: 2.541698320118732
Validation loss: 2.5555996492739292

Epoch: 6| Step: 4
Training loss: 2.2229846785442495
Validation loss: 2.529355659835904

Epoch: 6| Step: 5
Training loss: 2.5471292380534365
Validation loss: 2.537243965855296

Epoch: 6| Step: 6
Training loss: 2.6723271929804504
Validation loss: 2.5376081695285504

Epoch: 6| Step: 7
Training loss: 3.2414329294176496
Validation loss: 2.5416374342710135

Epoch: 6| Step: 8
Training loss: 2.6934835669506785
Validation loss: 2.5385262810834086

Epoch: 6| Step: 9
Training loss: 2.8171065857872746
Validation loss: 2.5069334983804494

Epoch: 6| Step: 10
Training loss: 2.3406490920575127
Validation loss: 2.515102953185315

Epoch: 6| Step: 11
Training loss: 2.7146006523354695
Validation loss: 2.5009944988628017

Epoch: 6| Step: 12
Training loss: 2.3271008997714913
Validation loss: 2.515569110612057

Epoch: 6| Step: 13
Training loss: 3.361205555943677
Validation loss: 2.4881813453094286

Epoch: 414| Step: 0
Training loss: 2.69866672728404
Validation loss: 2.4810421826750293

Epoch: 6| Step: 1
Training loss: 3.4062721181728848
Validation loss: 2.5111072135001113

Epoch: 6| Step: 2
Training loss: 1.94472375256369
Validation loss: 2.4834607341337094

Epoch: 6| Step: 3
Training loss: 2.7448458488275227
Validation loss: 2.482531811545121

Epoch: 6| Step: 4
Training loss: 2.8772227775339294
Validation loss: 2.485305956363191

Epoch: 6| Step: 5
Training loss: 2.2303819522570794
Validation loss: 2.5011760406621653

Epoch: 6| Step: 6
Training loss: 2.602838793129536
Validation loss: 2.5050314642405676

Epoch: 6| Step: 7
Training loss: 3.139495950321089
Validation loss: 2.5084446605533257

Epoch: 6| Step: 8
Training loss: 2.6181450302075397
Validation loss: 2.5068757738779426

Epoch: 6| Step: 9
Training loss: 2.4277330001127444
Validation loss: 2.5354238230166386

Epoch: 6| Step: 10
Training loss: 2.726866434640348
Validation loss: 2.5423897266632274

Epoch: 6| Step: 11
Training loss: 2.8736207390213133
Validation loss: 2.5408491463633376

Epoch: 6| Step: 12
Training loss: 2.668810955843404
Validation loss: 2.5650864420573525

Epoch: 6| Step: 13
Training loss: 2.9288690262955357
Validation loss: 2.594926800653033

Epoch: 415| Step: 0
Training loss: 2.1582824416279154
Validation loss: 2.561210884323201

Epoch: 6| Step: 1
Training loss: 2.6509000869048145
Validation loss: 2.537980457895854

Epoch: 6| Step: 2
Training loss: 3.320680413899369
Validation loss: 2.5409018039634734

Epoch: 6| Step: 3
Training loss: 2.9357609572428216
Validation loss: 2.5420483430860963

Epoch: 6| Step: 4
Training loss: 2.8083060466070844
Validation loss: 2.5339325636817898

Epoch: 6| Step: 5
Training loss: 2.421911817701497
Validation loss: 2.5393809048378797

Epoch: 6| Step: 6
Training loss: 3.2309422359326687
Validation loss: 2.529455071393858

Epoch: 6| Step: 7
Training loss: 2.14346670608878
Validation loss: 2.5113899823268286

Epoch: 6| Step: 8
Training loss: 3.147215802585586
Validation loss: 2.501062692359069

Epoch: 6| Step: 9
Training loss: 2.981778598203363
Validation loss: 2.4873343804775443

Epoch: 6| Step: 10
Training loss: 2.551100706510486
Validation loss: 2.4920956050813436

Epoch: 6| Step: 11
Training loss: 2.4778383259961476
Validation loss: 2.495938612744609

Epoch: 6| Step: 12
Training loss: 2.1801628223474045
Validation loss: 2.4947063441645003

Epoch: 6| Step: 13
Training loss: 2.842643606404902
Validation loss: 2.503992483850819

Epoch: 416| Step: 0
Training loss: 3.1045702132181305
Validation loss: 2.4947547297586694

Epoch: 6| Step: 1
Training loss: 2.7305023671537936
Validation loss: 2.499088766296127

Epoch: 6| Step: 2
Training loss: 2.4152950362537697
Validation loss: 2.504486097217455

Epoch: 6| Step: 3
Training loss: 2.63875626570962
Validation loss: 2.5194971205496883

Epoch: 6| Step: 4
Training loss: 3.0711949757051222
Validation loss: 2.5161802881151165

Epoch: 6| Step: 5
Training loss: 3.062910402786547
Validation loss: 2.5283070385854995

Epoch: 6| Step: 6
Training loss: 2.353635159697828
Validation loss: 2.525958655189789

Epoch: 6| Step: 7
Training loss: 2.5980288589671914
Validation loss: 2.539564428957578

Epoch: 6| Step: 8
Training loss: 2.843247589333023
Validation loss: 2.5688389394399285

Epoch: 6| Step: 9
Training loss: 3.0057641919627605
Validation loss: 2.58903924070099

Epoch: 6| Step: 10
Training loss: 2.7400431277368447
Validation loss: 2.5846495154996845

Epoch: 6| Step: 11
Training loss: 2.7874677784515756
Validation loss: 2.6055741501348364

Epoch: 6| Step: 12
Training loss: 1.699312615268421
Validation loss: 2.5784281274332073

Epoch: 6| Step: 13
Training loss: 2.7528677639419463
Validation loss: 2.5892189638408447

Epoch: 417| Step: 0
Training loss: 2.871482189656613
Validation loss: 2.594923621449436

Epoch: 6| Step: 1
Training loss: 2.4786306704731853
Validation loss: 2.5835764942851704

Epoch: 6| Step: 2
Training loss: 3.0179630367374086
Validation loss: 2.5979904390374653

Epoch: 6| Step: 3
Training loss: 2.442260983192004
Validation loss: 2.5902954513414747

Epoch: 6| Step: 4
Training loss: 3.041258187931702
Validation loss: 2.542663361312568

Epoch: 6| Step: 5
Training loss: 2.3803972855129545
Validation loss: 2.5306382107742333

Epoch: 6| Step: 6
Training loss: 2.0143146839396913
Validation loss: 2.5079864440606303

Epoch: 6| Step: 7
Training loss: 3.295886574052723
Validation loss: 2.5059992845693335

Epoch: 6| Step: 8
Training loss: 2.4420540156283566
Validation loss: 2.491832102826633

Epoch: 6| Step: 9
Training loss: 2.9812906514401205
Validation loss: 2.486666913566829

Epoch: 6| Step: 10
Training loss: 2.722569380787774
Validation loss: 2.467981325013032

Epoch: 6| Step: 11
Training loss: 3.069685311357925
Validation loss: 2.4798639812260608

Epoch: 6| Step: 12
Training loss: 2.5251917926729277
Validation loss: 2.4793998871908007

Epoch: 6| Step: 13
Training loss: 2.663129447354961
Validation loss: 2.4841170473408405

Epoch: 418| Step: 0
Training loss: 2.505297769600986
Validation loss: 2.48376375803872

Epoch: 6| Step: 1
Training loss: 2.7078222134829204
Validation loss: 2.4916576535003627

Epoch: 6| Step: 2
Training loss: 2.5339239619889153
Validation loss: 2.490544585680171

Epoch: 6| Step: 3
Training loss: 3.2247848971290263
Validation loss: 2.5137095184443505

Epoch: 6| Step: 4
Training loss: 2.209481882318445
Validation loss: 2.5298382159075996

Epoch: 6| Step: 5
Training loss: 2.388312324419101
Validation loss: 2.515787369961745

Epoch: 6| Step: 6
Training loss: 2.7684565128095966
Validation loss: 2.5282442575315156

Epoch: 6| Step: 7
Training loss: 3.138547903198839
Validation loss: 2.526168377236224

Epoch: 6| Step: 8
Training loss: 2.4231784389409383
Validation loss: 2.534548914003106

Epoch: 6| Step: 9
Training loss: 2.7663463793968393
Validation loss: 2.542021050065032

Epoch: 6| Step: 10
Training loss: 3.0719437087981305
Validation loss: 2.5515052373376594

Epoch: 6| Step: 11
Training loss: 2.673359776252746
Validation loss: 2.5571747778549505

Epoch: 6| Step: 12
Training loss: 2.792474193402527
Validation loss: 2.54653512878943

Epoch: 6| Step: 13
Training loss: 2.723838078972876
Validation loss: 2.587915289574212

Epoch: 419| Step: 0
Training loss: 2.646725892029676
Validation loss: 2.5461074756688493

Epoch: 6| Step: 1
Training loss: 2.4150454794508867
Validation loss: 2.5736751782629725

Epoch: 6| Step: 2
Training loss: 3.308081216758428
Validation loss: 2.5564578865204357

Epoch: 6| Step: 3
Training loss: 2.991505995945737
Validation loss: 2.5400976098341435

Epoch: 6| Step: 4
Training loss: 2.5188850461286143
Validation loss: 2.53694642443675

Epoch: 6| Step: 5
Training loss: 3.082652833093581
Validation loss: 2.5174372886378267

Epoch: 6| Step: 6
Training loss: 2.1192785543390342
Validation loss: 2.4954509550319472

Epoch: 6| Step: 7
Training loss: 2.5427200969302555
Validation loss: 2.501107546855755

Epoch: 6| Step: 8
Training loss: 1.9066239287292677
Validation loss: 2.4945041811891713

Epoch: 6| Step: 9
Training loss: 2.9646739081787623
Validation loss: 2.4648137278383078

Epoch: 6| Step: 10
Training loss: 2.846523734739713
Validation loss: 2.4990643832200417

Epoch: 6| Step: 11
Training loss: 2.9964798301808515
Validation loss: 2.4785914516836205

Epoch: 6| Step: 12
Training loss: 2.909726760201164
Validation loss: 2.4854872557416656

Epoch: 6| Step: 13
Training loss: 2.363926016125885
Validation loss: 2.4925359029228122

Epoch: 420| Step: 0
Training loss: 3.0046315997830813
Validation loss: 2.4940000398989484

Epoch: 6| Step: 1
Training loss: 2.4185287492678595
Validation loss: 2.5049852549002467

Epoch: 6| Step: 2
Training loss: 2.9051245694527603
Validation loss: 2.5228055701615215

Epoch: 6| Step: 3
Training loss: 3.1762322625239556
Validation loss: 2.5449454016751716

Epoch: 6| Step: 4
Training loss: 2.8538932576524685
Validation loss: 2.5442290859005148

Epoch: 6| Step: 5
Training loss: 2.1603485077051
Validation loss: 2.5493797348133715

Epoch: 6| Step: 6
Training loss: 2.6428485965958792
Validation loss: 2.5376420139783114

Epoch: 6| Step: 7
Training loss: 3.0967311175167884
Validation loss: 2.542080839582243

Epoch: 6| Step: 8
Training loss: 2.602677847935287
Validation loss: 2.5267017215519245

Epoch: 6| Step: 9
Training loss: 2.4038198510711672
Validation loss: 2.514437803547863

Epoch: 6| Step: 10
Training loss: 2.6112533478740523
Validation loss: 2.5102258421739063

Epoch: 6| Step: 11
Training loss: 2.7777976565179547
Validation loss: 2.5118538353494264

Epoch: 6| Step: 12
Training loss: 2.2975121477239697
Validation loss: 2.5223280230528866

Epoch: 6| Step: 13
Training loss: 3.030143299805869
Validation loss: 2.5342699279404663

Epoch: 421| Step: 0
Training loss: 2.156679856949356
Validation loss: 2.5320979280250357

Epoch: 6| Step: 1
Training loss: 2.8376005986736
Validation loss: 2.5329975257231423

Epoch: 6| Step: 2
Training loss: 2.7253990861024064
Validation loss: 2.528430737491972

Epoch: 6| Step: 3
Training loss: 2.5154619815677774
Validation loss: 2.5365384731370555

Epoch: 6| Step: 4
Training loss: 3.0079554932527923
Validation loss: 2.537217316823537

Epoch: 6| Step: 5
Training loss: 3.0429776819609766
Validation loss: 2.5116802417970665

Epoch: 6| Step: 6
Training loss: 2.6850017202361154
Validation loss: 2.576372992038252

Epoch: 6| Step: 7
Training loss: 2.4097106620616335
Validation loss: 2.5882141106752425

Epoch: 6| Step: 8
Training loss: 2.6981361525717973
Validation loss: 2.597022071149613

Epoch: 6| Step: 9
Training loss: 2.3806440648772456
Validation loss: 2.60298771380173

Epoch: 6| Step: 10
Training loss: 2.8613974500987522
Validation loss: 2.616531272657919

Epoch: 6| Step: 11
Training loss: 2.7464606309975808
Validation loss: 2.5874702172499573

Epoch: 6| Step: 12
Training loss: 3.263228856077776
Validation loss: 2.5463768034988052

Epoch: 6| Step: 13
Training loss: 2.485456986805054
Validation loss: 2.544232836295267

Epoch: 422| Step: 0
Training loss: 2.777328040484975
Validation loss: 2.5234244289864156

Epoch: 6| Step: 1
Training loss: 2.3371038172542766
Validation loss: 2.4970575726513706

Epoch: 6| Step: 2
Training loss: 2.325341628212235
Validation loss: 2.481610561375658

Epoch: 6| Step: 3
Training loss: 3.191667711807226
Validation loss: 2.4802276372702052

Epoch: 6| Step: 4
Training loss: 2.7780057866507915
Validation loss: 2.4880151067840353

Epoch: 6| Step: 5
Training loss: 2.815092714317569
Validation loss: 2.4647401805777056

Epoch: 6| Step: 6
Training loss: 2.585125660304626
Validation loss: 2.48265295028768

Epoch: 6| Step: 7
Training loss: 2.470575068476129
Validation loss: 2.4715452878977167

Epoch: 6| Step: 8
Training loss: 2.980640091476902
Validation loss: 2.4912673795164544

Epoch: 6| Step: 9
Training loss: 2.6125060158984263
Validation loss: 2.4788940619677393

Epoch: 6| Step: 10
Training loss: 2.7824145675663905
Validation loss: 2.4898859527394714

Epoch: 6| Step: 11
Training loss: 2.6714508433830595
Validation loss: 2.4954781245640345

Epoch: 6| Step: 12
Training loss: 2.619709951492713
Validation loss: 2.496464782116602

Epoch: 6| Step: 13
Training loss: 2.991857126986237
Validation loss: 2.5023712766571453

Epoch: 423| Step: 0
Training loss: 2.768682826069037
Validation loss: 2.5096577527917185

Epoch: 6| Step: 1
Training loss: 2.364104324646546
Validation loss: 2.5097549945792426

Epoch: 6| Step: 2
Training loss: 3.327637542702117
Validation loss: 2.558314843762497

Epoch: 6| Step: 3
Training loss: 2.3628068432023155
Validation loss: 2.523184294718348

Epoch: 6| Step: 4
Training loss: 2.8240480490100865
Validation loss: 2.531860856161484

Epoch: 6| Step: 5
Training loss: 2.8528150342047707
Validation loss: 2.5667461437960326

Epoch: 6| Step: 6
Training loss: 2.7633000315771286
Validation loss: 2.532659174089535

Epoch: 6| Step: 7
Training loss: 2.6104854573661425
Validation loss: 2.5637161586379054

Epoch: 6| Step: 8
Training loss: 2.8418336217018507
Validation loss: 2.573372864746596

Epoch: 6| Step: 9
Training loss: 2.5629338153118004
Validation loss: 2.5319982871196727

Epoch: 6| Step: 10
Training loss: 2.497844338874534
Validation loss: 2.5534154861091225

Epoch: 6| Step: 11
Training loss: 2.1276695088905373
Validation loss: 2.5308327259400905

Epoch: 6| Step: 12
Training loss: 2.9104495316772683
Validation loss: 2.538132103270637

Epoch: 6| Step: 13
Training loss: 3.0110434085449667
Validation loss: 2.5173236765404283

Epoch: 424| Step: 0
Training loss: 2.3969489333625673
Validation loss: 2.515734990708366

Epoch: 6| Step: 1
Training loss: 3.180763006501401
Validation loss: 2.5076554562648115

Epoch: 6| Step: 2
Training loss: 2.679294657480357
Validation loss: 2.511823642256316

Epoch: 6| Step: 3
Training loss: 2.5634594493476404
Validation loss: 2.4989084157684154

Epoch: 6| Step: 4
Training loss: 2.520291094088953
Validation loss: 2.502211872033573

Epoch: 6| Step: 5
Training loss: 2.6786771153989446
Validation loss: 2.498485164691351

Epoch: 6| Step: 6
Training loss: 2.932895054008436
Validation loss: 2.486119804138738

Epoch: 6| Step: 7
Training loss: 2.6124550920487017
Validation loss: 2.519073491040913

Epoch: 6| Step: 8
Training loss: 2.9804873084694163
Validation loss: 2.5050254497316415

Epoch: 6| Step: 9
Training loss: 2.124653844127778
Validation loss: 2.4945496191611607

Epoch: 6| Step: 10
Training loss: 2.7411740595800462
Validation loss: 2.486944715564816

Epoch: 6| Step: 11
Training loss: 2.9724440229453366
Validation loss: 2.488661591086004

Epoch: 6| Step: 12
Training loss: 2.6625721809739704
Validation loss: 2.500346844208724

Epoch: 6| Step: 13
Training loss: 2.7074622489572793
Validation loss: 2.4899561575357287

Epoch: 425| Step: 0
Training loss: 2.2456147587089044
Validation loss: 2.506567392051944

Epoch: 6| Step: 1
Training loss: 2.7909247328184636
Validation loss: 2.508044898381735

Epoch: 6| Step: 2
Training loss: 2.2851388262223025
Validation loss: 2.534245437242377

Epoch: 6| Step: 3
Training loss: 2.9807007225626245
Validation loss: 2.5202694103387513

Epoch: 6| Step: 4
Training loss: 3.039356835240612
Validation loss: 2.519936048914085

Epoch: 6| Step: 5
Training loss: 2.7744218825512372
Validation loss: 2.5241719362634423

Epoch: 6| Step: 6
Training loss: 2.9474364699488884
Validation loss: 2.5165292628878917

Epoch: 6| Step: 7
Training loss: 2.774820246330306
Validation loss: 2.5584120678955466

Epoch: 6| Step: 8
Training loss: 2.2241909313438595
Validation loss: 2.5559111895057582

Epoch: 6| Step: 9
Training loss: 2.664518882164862
Validation loss: 2.5542580161156168

Epoch: 6| Step: 10
Training loss: 2.8481691000702916
Validation loss: 2.5288480023900886

Epoch: 6| Step: 11
Training loss: 2.6322968201510712
Validation loss: 2.5220211474400434

Epoch: 6| Step: 12
Training loss: 2.886392990541934
Validation loss: 2.5243317314202414

Epoch: 6| Step: 13
Training loss: 2.2993433139252972
Validation loss: 2.5916241502026

Epoch: 426| Step: 0
Training loss: 2.9118475383733533
Validation loss: 2.537815429772765

Epoch: 6| Step: 1
Training loss: 2.539963970078969
Validation loss: 2.5439441153021765

Epoch: 6| Step: 2
Training loss: 2.190824652483276
Validation loss: 2.5362393949120134

Epoch: 6| Step: 3
Training loss: 2.8659821765076576
Validation loss: 2.482652984364187

Epoch: 6| Step: 4
Training loss: 2.748432926696824
Validation loss: 2.5055969411358507

Epoch: 6| Step: 5
Training loss: 3.001723747946232
Validation loss: 2.4886468653589553

Epoch: 6| Step: 6
Training loss: 2.617842134050916
Validation loss: 2.4854824481770597

Epoch: 6| Step: 7
Training loss: 3.0117051338254135
Validation loss: 2.490770566006034

Epoch: 6| Step: 8
Training loss: 3.4020488624360383
Validation loss: 2.5171843200167725

Epoch: 6| Step: 9
Training loss: 2.5154073869871985
Validation loss: 2.49441598827913

Epoch: 6| Step: 10
Training loss: 2.756457117304489
Validation loss: 2.51633414075248

Epoch: 6| Step: 11
Training loss: 2.0026280302916866
Validation loss: 2.511723809465289

Epoch: 6| Step: 12
Training loss: 2.4521344365639726
Validation loss: 2.541606969618142

Epoch: 6| Step: 13
Training loss: 2.6187100209391434
Validation loss: 2.5241749080134945

Epoch: 427| Step: 0
Training loss: 3.0645284357779103
Validation loss: 2.5348573287855425

Epoch: 6| Step: 1
Training loss: 2.8465498670548324
Validation loss: 2.5414808909120072

Epoch: 6| Step: 2
Training loss: 2.706580979191982
Validation loss: 2.539105901733712

Epoch: 6| Step: 3
Training loss: 2.4495537877029965
Validation loss: 2.518334543443089

Epoch: 6| Step: 4
Training loss: 2.6512979459766197
Validation loss: 2.520639002391171

Epoch: 6| Step: 5
Training loss: 2.201228847629485
Validation loss: 2.5161956606589415

Epoch: 6| Step: 6
Training loss: 2.494625035550065
Validation loss: 2.492031586682836

Epoch: 6| Step: 7
Training loss: 2.501742709243289
Validation loss: 2.495004542131659

Epoch: 6| Step: 8
Training loss: 2.8671988089439777
Validation loss: 2.503667745608215

Epoch: 6| Step: 9
Training loss: 2.8798437364888807
Validation loss: 2.475547932852925

Epoch: 6| Step: 10
Training loss: 2.9296194653558665
Validation loss: 2.4982111427199896

Epoch: 6| Step: 11
Training loss: 2.3790731136636953
Validation loss: 2.4897481618605157

Epoch: 6| Step: 12
Training loss: 2.9602631377199318
Validation loss: 2.5081380119748817

Epoch: 6| Step: 13
Training loss: 2.8510883930034927
Validation loss: 2.5061778144505213

Epoch: 428| Step: 0
Training loss: 3.116355230373296
Validation loss: 2.5272292726350543

Epoch: 6| Step: 1
Training loss: 3.4256587599253265
Validation loss: 2.5200155947665466

Epoch: 6| Step: 2
Training loss: 2.2847840617377284
Validation loss: 2.5316701500086043

Epoch: 6| Step: 3
Training loss: 2.9440086170153354
Validation loss: 2.531251966849651

Epoch: 6| Step: 4
Training loss: 2.6840937119566877
Validation loss: 2.5410215290989053

Epoch: 6| Step: 5
Training loss: 2.7663621512741154
Validation loss: 2.5048903175012414

Epoch: 6| Step: 6
Training loss: 2.477262091275784
Validation loss: 2.540101193744242

Epoch: 6| Step: 7
Training loss: 2.727311957684043
Validation loss: 2.5598020649810116

Epoch: 6| Step: 8
Training loss: 2.379260608357241
Validation loss: 2.567508988214775

Epoch: 6| Step: 9
Training loss: 2.883766078631318
Validation loss: 2.5840282454908774

Epoch: 6| Step: 10
Training loss: 2.504517098363693
Validation loss: 2.582429801954848

Epoch: 6| Step: 11
Training loss: 2.1476625466696753
Validation loss: 2.543422030952899

Epoch: 6| Step: 12
Training loss: 2.740510607151327
Validation loss: 2.5209953132670404

Epoch: 6| Step: 13
Training loss: 1.9531555783739118
Validation loss: 2.522739092405676

Epoch: 429| Step: 0
Training loss: 2.8857811836409146
Validation loss: 2.5024904551767646

Epoch: 6| Step: 1
Training loss: 2.7849722824224092
Validation loss: 2.4865543029414403

Epoch: 6| Step: 2
Training loss: 2.3269061283772365
Validation loss: 2.4834643249364072

Epoch: 6| Step: 3
Training loss: 2.0885935814193117
Validation loss: 2.4795352609735732

Epoch: 6| Step: 4
Training loss: 2.791306135515986
Validation loss: 2.483716974963737

Epoch: 6| Step: 5
Training loss: 2.305330038212101
Validation loss: 2.4749067459859626

Epoch: 6| Step: 6
Training loss: 2.760233305593234
Validation loss: 2.473958404143785

Epoch: 6| Step: 7
Training loss: 3.0812167214227237
Validation loss: 2.4650102553299575

Epoch: 6| Step: 8
Training loss: 2.923351220917501
Validation loss: 2.4664383493094584

Epoch: 6| Step: 9
Training loss: 2.8888687984876515
Validation loss: 2.4849125027916608

Epoch: 6| Step: 10
Training loss: 2.8420327839151738
Validation loss: 2.501699263907472

Epoch: 6| Step: 11
Training loss: 2.2144385342227464
Validation loss: 2.4985708417605808

Epoch: 6| Step: 12
Training loss: 2.3201831306330267
Validation loss: 2.5237854631604497

Epoch: 6| Step: 13
Training loss: 3.624679156607145
Validation loss: 2.5636956491600618

Epoch: 430| Step: 0
Training loss: 3.295323445214679
Validation loss: 2.601320558429639

Epoch: 6| Step: 1
Training loss: 3.299451643726877
Validation loss: 2.56631078920427

Epoch: 6| Step: 2
Training loss: 2.552447815902467
Validation loss: 2.551892939269761

Epoch: 6| Step: 3
Training loss: 2.705717221999521
Validation loss: 2.521731592297666

Epoch: 6| Step: 4
Training loss: 2.84006370311804
Validation loss: 2.5171824796667095

Epoch: 6| Step: 5
Training loss: 1.8425189935748179
Validation loss: 2.501005091691469

Epoch: 6| Step: 6
Training loss: 2.5545352808781523
Validation loss: 2.486377853186123

Epoch: 6| Step: 7
Training loss: 2.654886591441436
Validation loss: 2.490265798577565

Epoch: 6| Step: 8
Training loss: 2.8025698517151496
Validation loss: 2.4930683751920704

Epoch: 6| Step: 9
Training loss: 2.759526743880046
Validation loss: 2.492020088482877

Epoch: 6| Step: 10
Training loss: 2.5998347963520207
Validation loss: 2.465380759897191

Epoch: 6| Step: 11
Training loss: 2.3905950806185348
Validation loss: 2.481126637345937

Epoch: 6| Step: 12
Training loss: 2.605429584717816
Validation loss: 2.4905490386417997

Epoch: 6| Step: 13
Training loss: 2.9173063575792253
Validation loss: 2.509581294663771

Epoch: 431| Step: 0
Training loss: 2.097934924604664
Validation loss: 2.5424203765475593

Epoch: 6| Step: 1
Training loss: 2.697281535638265
Validation loss: 2.5472173681497803

Epoch: 6| Step: 2
Training loss: 3.2142995046895004
Validation loss: 2.558277919789509

Epoch: 6| Step: 3
Training loss: 2.5063689167987073
Validation loss: 2.55123427738656

Epoch: 6| Step: 4
Training loss: 3.376756846612954
Validation loss: 2.534368775495653

Epoch: 6| Step: 5
Training loss: 2.2010490430596072
Validation loss: 2.5192609347697434

Epoch: 6| Step: 6
Training loss: 3.112120676480986
Validation loss: 2.5136439536232373

Epoch: 6| Step: 7
Training loss: 2.833891327458971
Validation loss: 2.5108700077713055

Epoch: 6| Step: 8
Training loss: 2.5856015082184953
Validation loss: 2.500407616394507

Epoch: 6| Step: 9
Training loss: 2.5199260077134378
Validation loss: 2.4910423529942114

Epoch: 6| Step: 10
Training loss: 2.4848772416984777
Validation loss: 2.483570026510111

Epoch: 6| Step: 11
Training loss: 2.482186943360542
Validation loss: 2.508711277024377

Epoch: 6| Step: 12
Training loss: 2.753831448452206
Validation loss: 2.4932427278682394

Epoch: 6| Step: 13
Training loss: 2.4418936037009584
Validation loss: 2.4968995537015775

Epoch: 432| Step: 0
Training loss: 2.5417576028367397
Validation loss: 2.524308147696996

Epoch: 6| Step: 1
Training loss: 2.930021302598191
Validation loss: 2.5224770766926627

Epoch: 6| Step: 2
Training loss: 2.9333951148838464
Validation loss: 2.5195828330058685

Epoch: 6| Step: 3
Training loss: 2.7875975279574985
Validation loss: 2.531353890512502

Epoch: 6| Step: 4
Training loss: 2.8555959941937976
Validation loss: 2.497751375261188

Epoch: 6| Step: 5
Training loss: 2.2906450132820186
Validation loss: 2.5191515966641074

Epoch: 6| Step: 6
Training loss: 2.4597407261747
Validation loss: 2.5068555101117713

Epoch: 6| Step: 7
Training loss: 2.3210220022806336
Validation loss: 2.4954464841069557

Epoch: 6| Step: 8
Training loss: 2.716187859292688
Validation loss: 2.5004608498623875

Epoch: 6| Step: 9
Training loss: 2.6789190230311197
Validation loss: 2.490186504858586

Epoch: 6| Step: 10
Training loss: 3.06131705968078
Validation loss: 2.4923861284258666

Epoch: 6| Step: 11
Training loss: 1.6698873237470935
Validation loss: 2.5014231804545473

Epoch: 6| Step: 12
Training loss: 3.215560517994531
Validation loss: 2.5112556335875715

Epoch: 6| Step: 13
Training loss: 2.943708473771179
Validation loss: 2.524928579555993

Epoch: 433| Step: 0
Training loss: 2.832122674979029
Validation loss: 2.5385411345503335

Epoch: 6| Step: 1
Training loss: 2.559792553722043
Validation loss: 2.520002130613974

Epoch: 6| Step: 2
Training loss: 3.1188162083755393
Validation loss: 2.5231245227714623

Epoch: 6| Step: 3
Training loss: 2.4018338786607147
Validation loss: 2.5284198681862495

Epoch: 6| Step: 4
Training loss: 2.472322414334822
Validation loss: 2.5345061149703123

Epoch: 6| Step: 5
Training loss: 2.747915605068122
Validation loss: 2.539592789142908

Epoch: 6| Step: 6
Training loss: 2.8275366745517303
Validation loss: 2.540642783432916

Epoch: 6| Step: 7
Training loss: 2.8724642641983693
Validation loss: 2.5066459190627763

Epoch: 6| Step: 8
Training loss: 2.4644002137525676
Validation loss: 2.517494006205743

Epoch: 6| Step: 9
Training loss: 2.4760488464824832
Validation loss: 2.512380987381247

Epoch: 6| Step: 10
Training loss: 2.9302548278815688
Validation loss: 2.4960433084686815

Epoch: 6| Step: 11
Training loss: 2.457977743347566
Validation loss: 2.4886922712068715

Epoch: 6| Step: 12
Training loss: 2.6589333836595106
Validation loss: 2.488219026146308

Epoch: 6| Step: 13
Training loss: 3.1931105957184225
Validation loss: 2.482701021447635

Epoch: 434| Step: 0
Training loss: 3.0822899230010137
Validation loss: 2.4932347919341673

Epoch: 6| Step: 1
Training loss: 2.685513671669742
Validation loss: 2.492787716826323

Epoch: 6| Step: 2
Training loss: 2.733821180661466
Validation loss: 2.485699565272269

Epoch: 6| Step: 3
Training loss: 3.1717527769997713
Validation loss: 2.5142902126519724

Epoch: 6| Step: 4
Training loss: 2.6553740010609155
Validation loss: 2.5096765423773792

Epoch: 6| Step: 5
Training loss: 2.5359321899734533
Validation loss: 2.501122765016512

Epoch: 6| Step: 6
Training loss: 2.459816522966735
Validation loss: 2.507095950639679

Epoch: 6| Step: 7
Training loss: 2.467136773426874
Validation loss: 2.497981886365628

Epoch: 6| Step: 8
Training loss: 3.115711598928918
Validation loss: 2.494273232546076

Epoch: 6| Step: 9
Training loss: 2.5836808883511155
Validation loss: 2.5283278630154125

Epoch: 6| Step: 10
Training loss: 2.4141010170243393
Validation loss: 2.5559627454298606

Epoch: 6| Step: 11
Training loss: 2.31056441673656
Validation loss: 2.557920738743095

Epoch: 6| Step: 12
Training loss: 2.461464283586613
Validation loss: 2.5657191211785157

Epoch: 6| Step: 13
Training loss: 2.4894708158426218
Validation loss: 2.619995898603874

Epoch: 435| Step: 0
Training loss: 3.222772547617464
Validation loss: 2.6311289369062334

Epoch: 6| Step: 1
Training loss: 3.2573168626832882
Validation loss: 2.6373601133264595

Epoch: 6| Step: 2
Training loss: 2.615363553014153
Validation loss: 2.614156045788137

Epoch: 6| Step: 3
Training loss: 1.8464124174483927
Validation loss: 2.608099000784877

Epoch: 6| Step: 4
Training loss: 2.7371385832194868
Validation loss: 2.599166309076928

Epoch: 6| Step: 5
Training loss: 3.1595625915074574
Validation loss: 2.5743408811523145

Epoch: 6| Step: 6
Training loss: 2.638662658720489
Validation loss: 2.5173266074918677

Epoch: 6| Step: 7
Training loss: 2.8548511510417653
Validation loss: 2.494922903632436

Epoch: 6| Step: 8
Training loss: 2.6012419082097797
Validation loss: 2.475458961028551

Epoch: 6| Step: 9
Training loss: 2.837217940372984
Validation loss: 2.4703667195022043

Epoch: 6| Step: 10
Training loss: 2.5387356122208837
Validation loss: 2.474133154365191

Epoch: 6| Step: 11
Training loss: 2.482490544603671
Validation loss: 2.4754026391017505

Epoch: 6| Step: 12
Training loss: 2.559231045392575
Validation loss: 2.477438317430421

Epoch: 6| Step: 13
Training loss: 2.559893142735001
Validation loss: 2.4939612817515093

Epoch: 436| Step: 0
Training loss: 2.7752428653049055
Validation loss: 2.473248303804279

Epoch: 6| Step: 1
Training loss: 3.0149609719149617
Validation loss: 2.481065246674928

Epoch: 6| Step: 2
Training loss: 3.0650182218772293
Validation loss: 2.4832670187108516

Epoch: 6| Step: 3
Training loss: 3.102012928269855
Validation loss: 2.4925590734728256

Epoch: 6| Step: 4
Training loss: 2.3031656704214125
Validation loss: 2.515080290000642

Epoch: 6| Step: 5
Training loss: 2.288651569443706
Validation loss: 2.5121824474134993

Epoch: 6| Step: 6
Training loss: 1.8026714871928038
Validation loss: 2.5528229332154946

Epoch: 6| Step: 7
Training loss: 2.354316796661088
Validation loss: 2.5459855217049254

Epoch: 6| Step: 8
Training loss: 3.179491641599176
Validation loss: 2.585737247840825

Epoch: 6| Step: 9
Training loss: 2.619574616821537
Validation loss: 2.5472993399694617

Epoch: 6| Step: 10
Training loss: 2.992466368267146
Validation loss: 2.5618903552639205

Epoch: 6| Step: 11
Training loss: 2.756682080506757
Validation loss: 2.5501839643983937

Epoch: 6| Step: 12
Training loss: 2.35449188371654
Validation loss: 2.5415492125642456

Epoch: 6| Step: 13
Training loss: 2.643797373967216
Validation loss: 2.5220579425267453

Epoch: 437| Step: 0
Training loss: 2.6795762820282794
Validation loss: 2.531919987492043

Epoch: 6| Step: 1
Training loss: 3.1811271239047305
Validation loss: 2.5429945887199956

Epoch: 6| Step: 2
Training loss: 2.9973625669558372
Validation loss: 2.5217785261173433

Epoch: 6| Step: 3
Training loss: 2.334535924632225
Validation loss: 2.4986556550714627

Epoch: 6| Step: 4
Training loss: 2.7926115647913945
Validation loss: 2.5048937204843034

Epoch: 6| Step: 5
Training loss: 2.3904851735430612
Validation loss: 2.5283020285290716

Epoch: 6| Step: 6
Training loss: 2.2628116371965494
Validation loss: 2.496645462163719

Epoch: 6| Step: 7
Training loss: 2.943286472118881
Validation loss: 2.5125140193865816

Epoch: 6| Step: 8
Training loss: 2.634113296053401
Validation loss: 2.509849307219413

Epoch: 6| Step: 9
Training loss: 2.6611481328400743
Validation loss: 2.493898408084013

Epoch: 6| Step: 10
Training loss: 2.8050884502153393
Validation loss: 2.50215236547448

Epoch: 6| Step: 11
Training loss: 2.9887742776494943
Validation loss: 2.4627784709387948

Epoch: 6| Step: 12
Training loss: 1.9459057251930556
Validation loss: 2.4927219236144578

Epoch: 6| Step: 13
Training loss: 2.6975334415713914
Validation loss: 2.494892465053405

Epoch: 438| Step: 0
Training loss: 3.3084971876589333
Validation loss: 2.503198554586596

Epoch: 6| Step: 1
Training loss: 2.8273213124498264
Validation loss: 2.512890476418669

Epoch: 6| Step: 2
Training loss: 2.3935250039596574
Validation loss: 2.5192063024362663

Epoch: 6| Step: 3
Training loss: 2.731646238867033
Validation loss: 2.5133874402092418

Epoch: 6| Step: 4
Training loss: 2.496025932238433
Validation loss: 2.523966327555865

Epoch: 6| Step: 5
Training loss: 2.49568137044317
Validation loss: 2.5304774122291223

Epoch: 6| Step: 6
Training loss: 2.806638926038978
Validation loss: 2.5504690168044166

Epoch: 6| Step: 7
Training loss: 2.7298688106664954
Validation loss: 2.53376136659341

Epoch: 6| Step: 8
Training loss: 2.316041863071353
Validation loss: 2.5331628980794987

Epoch: 6| Step: 9
Training loss: 3.0074763915291953
Validation loss: 2.5489511870892403

Epoch: 6| Step: 10
Training loss: 2.621620182208083
Validation loss: 2.5409202495043073

Epoch: 6| Step: 11
Training loss: 2.4624131395540907
Validation loss: 2.508909485232605

Epoch: 6| Step: 12
Training loss: 2.544598831904949
Validation loss: 2.5227150100715408

Epoch: 6| Step: 13
Training loss: 2.254942551619064
Validation loss: 2.5145878387168032

Epoch: 439| Step: 0
Training loss: 2.645784923280804
Validation loss: 2.5255223530230935

Epoch: 6| Step: 1
Training loss: 2.4406614098171433
Validation loss: 2.510425982387576

Epoch: 6| Step: 2
Training loss: 2.3233926282601725
Validation loss: 2.5107705863272884

Epoch: 6| Step: 3
Training loss: 2.6757553210707674
Validation loss: 2.5284821744280417

Epoch: 6| Step: 4
Training loss: 2.3168540380253573
Validation loss: 2.532721256601697

Epoch: 6| Step: 5
Training loss: 2.5625354485269614
Validation loss: 2.5781895375556334

Epoch: 6| Step: 6
Training loss: 2.430938104466879
Validation loss: 2.5967191358044177

Epoch: 6| Step: 7
Training loss: 3.2497928259914097
Validation loss: 2.576895600229605

Epoch: 6| Step: 8
Training loss: 1.9749753105455279
Validation loss: 2.6074986054672142

Epoch: 6| Step: 9
Training loss: 3.486855757079537
Validation loss: 2.6037847498924593

Epoch: 6| Step: 10
Training loss: 2.917270071192231
Validation loss: 2.5834435079886604

Epoch: 6| Step: 11
Training loss: 3.0548147189680948
Validation loss: 2.565063396950434

Epoch: 6| Step: 12
Training loss: 2.751714865318027
Validation loss: 2.514866401615637

Epoch: 6| Step: 13
Training loss: 2.358195837571045
Validation loss: 2.4931346620901573

Epoch: 440| Step: 0
Training loss: 3.0243659750072
Validation loss: 2.46142981143421

Epoch: 6| Step: 1
Training loss: 2.601059507024403
Validation loss: 2.4627353526594087

Epoch: 6| Step: 2
Training loss: 2.761771583321543
Validation loss: 2.4500383875076475

Epoch: 6| Step: 3
Training loss: 3.0025858860611843
Validation loss: 2.4604810701308595

Epoch: 6| Step: 4
Training loss: 2.9708840179043268
Validation loss: 2.468717590177445

Epoch: 6| Step: 5
Training loss: 3.1568068211454237
Validation loss: 2.4563086883364527

Epoch: 6| Step: 6
Training loss: 2.7858788193680666
Validation loss: 2.4621478683752045

Epoch: 6| Step: 7
Training loss: 2.748099884411214
Validation loss: 2.4542776168958134

Epoch: 6| Step: 8
Training loss: 2.7973806254507916
Validation loss: 2.4692786945943483

Epoch: 6| Step: 9
Training loss: 2.2564026545822253
Validation loss: 2.471502338643664

Epoch: 6| Step: 10
Training loss: 2.198154984942961
Validation loss: 2.4786985763223

Epoch: 6| Step: 11
Training loss: 1.833591406893442
Validation loss: 2.4715198904009426

Epoch: 6| Step: 12
Training loss: 3.064254258305909
Validation loss: 2.51212830201859

Epoch: 6| Step: 13
Training loss: 2.487985734144323
Validation loss: 2.550802795985501

Epoch: 441| Step: 0
Training loss: 2.7198764615894953
Validation loss: 2.5730567582782684

Epoch: 6| Step: 1
Training loss: 2.572278972061044
Validation loss: 2.608523882328722

Epoch: 6| Step: 2
Training loss: 3.1170778183534953
Validation loss: 2.6112016082754823

Epoch: 6| Step: 3
Training loss: 2.2182009380258454
Validation loss: 2.640550487476945

Epoch: 6| Step: 4
Training loss: 2.7772919855243283
Validation loss: 2.6461170914152667

Epoch: 6| Step: 5
Training loss: 2.845707314094806
Validation loss: 2.592223819356411

Epoch: 6| Step: 6
Training loss: 3.1441721456442733
Validation loss: 2.5617053943128476

Epoch: 6| Step: 7
Training loss: 2.5982386344926094
Validation loss: 2.539051303633748

Epoch: 6| Step: 8
Training loss: 2.6102073392689302
Validation loss: 2.5090062338936665

Epoch: 6| Step: 9
Training loss: 2.183968663658051
Validation loss: 2.52577317720977

Epoch: 6| Step: 10
Training loss: 2.6335224586689443
Validation loss: 2.5071660631096586

Epoch: 6| Step: 11
Training loss: 2.743068021163837
Validation loss: 2.4980209546667544

Epoch: 6| Step: 12
Training loss: 2.224538425188282
Validation loss: 2.487416554040369

Epoch: 6| Step: 13
Training loss: 3.5327756843521367
Validation loss: 2.494202863523918

Epoch: 442| Step: 0
Training loss: 2.467571218558534
Validation loss: 2.4801148924196217

Epoch: 6| Step: 1
Training loss: 3.277642874087809
Validation loss: 2.4619973260897265

Epoch: 6| Step: 2
Training loss: 2.3966276317206545
Validation loss: 2.4685439676356578

Epoch: 6| Step: 3
Training loss: 2.485487203138027
Validation loss: 2.4683660465902246

Epoch: 6| Step: 4
Training loss: 2.6357973650555517
Validation loss: 2.4787612791103006

Epoch: 6| Step: 5
Training loss: 3.0097477223571225
Validation loss: 2.471750939403396

Epoch: 6| Step: 6
Training loss: 2.465402385684707
Validation loss: 2.4704070152822664

Epoch: 6| Step: 7
Training loss: 2.8587320574225306
Validation loss: 2.5002655011369916

Epoch: 6| Step: 8
Training loss: 1.460033932905532
Validation loss: 2.4996882921137185

Epoch: 6| Step: 9
Training loss: 2.9962404854264935
Validation loss: 2.512134261763377

Epoch: 6| Step: 10
Training loss: 2.6174728010307464
Validation loss: 2.5392118929068355

Epoch: 6| Step: 11
Training loss: 2.600742795183799
Validation loss: 2.5424601625632888

Epoch: 6| Step: 12
Training loss: 2.9875350120120845
Validation loss: 2.553232179432086

Epoch: 6| Step: 13
Training loss: 3.1477536199435425
Validation loss: 2.4966824674493098

Epoch: 443| Step: 0
Training loss: 2.687921624045787
Validation loss: 2.499863841850768

Epoch: 6| Step: 1
Training loss: 2.781120983088816
Validation loss: 2.4856325210850705

Epoch: 6| Step: 2
Training loss: 2.721377276211437
Validation loss: 2.470727800418466

Epoch: 6| Step: 3
Training loss: 2.448372385879097
Validation loss: 2.4795864539507666

Epoch: 6| Step: 4
Training loss: 2.9792407544578303
Validation loss: 2.4713391789243224

Epoch: 6| Step: 5
Training loss: 3.1540501548248074
Validation loss: 2.4683333170268478

Epoch: 6| Step: 6
Training loss: 2.8926183477537646
Validation loss: 2.4707903298821585

Epoch: 6| Step: 7
Training loss: 2.411786534253021
Validation loss: 2.4684254651190605

Epoch: 6| Step: 8
Training loss: 3.0208233712569212
Validation loss: 2.473306699639038

Epoch: 6| Step: 9
Training loss: 2.394144198078434
Validation loss: 2.471667307379949

Epoch: 6| Step: 10
Training loss: 2.6004240277118975
Validation loss: 2.4998361913276668

Epoch: 6| Step: 11
Training loss: 2.4412720666250394
Validation loss: 2.5021431975681816

Epoch: 6| Step: 12
Training loss: 2.351944192217767
Validation loss: 2.5121534226552664

Epoch: 6| Step: 13
Training loss: 2.6530753518571304
Validation loss: 2.5457505990914084

Epoch: 444| Step: 0
Training loss: 2.6539576793018744
Validation loss: 2.555048794308266

Epoch: 6| Step: 1
Training loss: 2.652965894046349
Validation loss: 2.52093916362117

Epoch: 6| Step: 2
Training loss: 3.41588692180002
Validation loss: 2.5486204265212518

Epoch: 6| Step: 3
Training loss: 2.7740275870108637
Validation loss: 2.553597382153405

Epoch: 6| Step: 4
Training loss: 2.628114578280838
Validation loss: 2.537229469047109

Epoch: 6| Step: 5
Training loss: 3.117126617219506
Validation loss: 2.5221591806272396

Epoch: 6| Step: 6
Training loss: 2.4918215491937064
Validation loss: 2.516479040471368

Epoch: 6| Step: 7
Training loss: 2.247268290048176
Validation loss: 2.498850829050407

Epoch: 6| Step: 8
Training loss: 2.6412900730456474
Validation loss: 2.489619949146383

Epoch: 6| Step: 9
Training loss: 2.705966932896844
Validation loss: 2.4806115870666217

Epoch: 6| Step: 10
Training loss: 2.6625695841834625
Validation loss: 2.494341328184493

Epoch: 6| Step: 11
Training loss: 2.9839160825982156
Validation loss: 2.4920472491271757

Epoch: 6| Step: 12
Training loss: 1.8952929666366423
Validation loss: 2.4965601102563992

Epoch: 6| Step: 13
Training loss: 2.087569494860955
Validation loss: 2.5172378535511952

Epoch: 445| Step: 0
Training loss: 2.994759432854156
Validation loss: 2.501983921863437

Epoch: 6| Step: 1
Training loss: 2.3796712212309465
Validation loss: 2.516601628714947

Epoch: 6| Step: 2
Training loss: 2.750867100042004
Validation loss: 2.5020791708757137

Epoch: 6| Step: 3
Training loss: 2.3995040858035823
Validation loss: 2.509132646794643

Epoch: 6| Step: 4
Training loss: 1.8755623292097579
Validation loss: 2.510098374141847

Epoch: 6| Step: 5
Training loss: 3.090615890998647
Validation loss: 2.4988590887818027

Epoch: 6| Step: 6
Training loss: 2.753925036643589
Validation loss: 2.4969050395117085

Epoch: 6| Step: 7
Training loss: 2.755822174015835
Validation loss: 2.502297324173817

Epoch: 6| Step: 8
Training loss: 2.486716264872698
Validation loss: 2.4985079209453778

Epoch: 6| Step: 9
Training loss: 2.882206385299453
Validation loss: 2.4947772816361837

Epoch: 6| Step: 10
Training loss: 2.536965780915296
Validation loss: 2.480379560897195

Epoch: 6| Step: 11
Training loss: 2.7555252402528287
Validation loss: 2.4792030082252627

Epoch: 6| Step: 12
Training loss: 2.6778834195049406
Validation loss: 2.508547411759394

Epoch: 6| Step: 13
Training loss: 2.722000809399599
Validation loss: 2.493745484328619

Epoch: 446| Step: 0
Training loss: 3.0974822987688766
Validation loss: 2.491959717176042

Epoch: 6| Step: 1
Training loss: 2.0694191210717143
Validation loss: 2.517914643345738

Epoch: 6| Step: 2
Training loss: 2.8908572541830044
Validation loss: 2.5097826323538066

Epoch: 6| Step: 3
Training loss: 2.9305366607908625
Validation loss: 2.5051318860873977

Epoch: 6| Step: 4
Training loss: 2.655648915216142
Validation loss: 2.475298985345646

Epoch: 6| Step: 5
Training loss: 3.0393671897993357
Validation loss: 2.507744133273307

Epoch: 6| Step: 6
Training loss: 2.480016183492709
Validation loss: 2.48447745373707

Epoch: 6| Step: 7
Training loss: 2.794093277768845
Validation loss: 2.4960993330975536

Epoch: 6| Step: 8
Training loss: 2.736506737400866
Validation loss: 2.488608832507919

Epoch: 6| Step: 9
Training loss: 2.9463665844230396
Validation loss: 2.4845681972175067

Epoch: 6| Step: 10
Training loss: 2.5943396024556757
Validation loss: 2.501643424127174

Epoch: 6| Step: 11
Training loss: 1.901043269187217
Validation loss: 2.4953785398547508

Epoch: 6| Step: 12
Training loss: 2.3027824157414543
Validation loss: 2.4961654316687607

Epoch: 6| Step: 13
Training loss: 2.5070593347637633
Validation loss: 2.502149479247432

Epoch: 447| Step: 0
Training loss: 2.660581759172458
Validation loss: 2.4941274066170407

Epoch: 6| Step: 1
Training loss: 2.1729328680364057
Validation loss: 2.542523902381177

Epoch: 6| Step: 2
Training loss: 2.0540970218554215
Validation loss: 2.524195932588143

Epoch: 6| Step: 3
Training loss: 2.3780104981777015
Validation loss: 2.5343463938423914

Epoch: 6| Step: 4
Training loss: 3.1834143090725733
Validation loss: 2.541954563511303

Epoch: 6| Step: 5
Training loss: 2.640031917263487
Validation loss: 2.538547515010732

Epoch: 6| Step: 6
Training loss: 2.5192891795655137
Validation loss: 2.518548730733282

Epoch: 6| Step: 7
Training loss: 2.7620976254268994
Validation loss: 2.5039542172165627

Epoch: 6| Step: 8
Training loss: 2.605336610568799
Validation loss: 2.5079095291576867

Epoch: 6| Step: 9
Training loss: 2.980974586928751
Validation loss: 2.4757124062691167

Epoch: 6| Step: 10
Training loss: 2.757569731922661
Validation loss: 2.510577734891805

Epoch: 6| Step: 11
Training loss: 3.0369699525875986
Validation loss: 2.5211767286333293

Epoch: 6| Step: 12
Training loss: 2.441736696386902
Validation loss: 2.521649477615115

Epoch: 6| Step: 13
Training loss: 2.896376872109451
Validation loss: 2.5083107519627226

Epoch: 448| Step: 0
Training loss: 2.965648114804709
Validation loss: 2.4804134317188122

Epoch: 6| Step: 1
Training loss: 2.62533203931434
Validation loss: 2.489871412379209

Epoch: 6| Step: 2
Training loss: 2.4160317102018607
Validation loss: 2.4913587817315186

Epoch: 6| Step: 3
Training loss: 2.912329437107715
Validation loss: 2.4910633320009445

Epoch: 6| Step: 4
Training loss: 2.012740562703973
Validation loss: 2.52203808231374

Epoch: 6| Step: 5
Training loss: 2.2916898784039907
Validation loss: 2.5020829065795587

Epoch: 6| Step: 6
Training loss: 2.8303298364381893
Validation loss: 2.508279480862137

Epoch: 6| Step: 7
Training loss: 2.5326161406717778
Validation loss: 2.5041927127515193

Epoch: 6| Step: 8
Training loss: 2.9862192257572495
Validation loss: 2.4869454701391533

Epoch: 6| Step: 9
Training loss: 2.788580502873873
Validation loss: 2.4944818796629242

Epoch: 6| Step: 10
Training loss: 2.6080484273252447
Validation loss: 2.487008169106342

Epoch: 6| Step: 11
Training loss: 2.6884594468840857
Validation loss: 2.4960155884042585

Epoch: 6| Step: 12
Training loss: 2.6749353561433775
Validation loss: 2.4971117768743993

Epoch: 6| Step: 13
Training loss: 2.6939870035301228
Validation loss: 2.5024943367607344

Epoch: 449| Step: 0
Training loss: 2.4840942800017185
Validation loss: 2.5075822106698755

Epoch: 6| Step: 1
Training loss: 2.201044926879413
Validation loss: 2.5127819466522197

Epoch: 6| Step: 2
Training loss: 3.024148862282999
Validation loss: 2.54868853465782

Epoch: 6| Step: 3
Training loss: 2.3264963482636043
Validation loss: 2.5463692093477266

Epoch: 6| Step: 4
Training loss: 3.0239793553127017
Validation loss: 2.5376638291191496

Epoch: 6| Step: 5
Training loss: 2.693360702813079
Validation loss: 2.5818828522557644

Epoch: 6| Step: 6
Training loss: 2.437451582207673
Validation loss: 2.5345650854628463

Epoch: 6| Step: 7
Training loss: 2.4132098324755433
Validation loss: 2.531074142069512

Epoch: 6| Step: 8
Training loss: 3.286502666547173
Validation loss: 2.5250726591702763

Epoch: 6| Step: 9
Training loss: 2.05551919675867
Validation loss: 2.4943877557761613

Epoch: 6| Step: 10
Training loss: 2.7007932804491874
Validation loss: 2.4847625772692763

Epoch: 6| Step: 11
Training loss: 3.284248072297619
Validation loss: 2.482529888709454

Epoch: 6| Step: 12
Training loss: 2.7942957573330465
Validation loss: 2.4595059305636577

Epoch: 6| Step: 13
Training loss: 1.60324469820327
Validation loss: 2.45919919047572

Epoch: 450| Step: 0
Training loss: 2.7412031966569987
Validation loss: 2.4543433146727076

Epoch: 6| Step: 1
Training loss: 2.7461079017849697
Validation loss: 2.470514788476182

Epoch: 6| Step: 2
Training loss: 2.4982129385527845
Validation loss: 2.455826383301983

Epoch: 6| Step: 3
Training loss: 1.968578331138552
Validation loss: 2.458244806708042

Epoch: 6| Step: 4
Training loss: 2.5617607725186273
Validation loss: 2.4517758642958656

Epoch: 6| Step: 5
Training loss: 3.127660153174005
Validation loss: 2.482100449769669

Epoch: 6| Step: 6
Training loss: 2.881300946031421
Validation loss: 2.4763394572968878

Epoch: 6| Step: 7
Training loss: 3.039430571480872
Validation loss: 2.495592858563605

Epoch: 6| Step: 8
Training loss: 2.225789467986211
Validation loss: 2.5120026358747425

Epoch: 6| Step: 9
Training loss: 2.3405272642950448
Validation loss: 2.546011118857946

Epoch: 6| Step: 10
Training loss: 2.5907147584097596
Validation loss: 2.5678441934990164

Epoch: 6| Step: 11
Training loss: 2.8682242449848725
Validation loss: 2.6213471378650848

Epoch: 6| Step: 12
Training loss: 2.4141450639451034
Validation loss: 2.610662753542737

Epoch: 6| Step: 13
Training loss: 3.1771758185928234
Validation loss: 2.587263512283074

Testing loss: 2.735565248140458
