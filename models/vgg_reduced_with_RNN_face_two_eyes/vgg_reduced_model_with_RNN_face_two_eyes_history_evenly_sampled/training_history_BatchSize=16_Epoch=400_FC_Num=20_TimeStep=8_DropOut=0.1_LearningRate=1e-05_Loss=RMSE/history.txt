Epoch: 1| Step: 0
Training loss: 4.772090340922291
Validation loss: 5.833432323594469

Epoch: 6| Step: 1
Training loss: 6.08246902526921
Validation loss: 5.821115929192277

Epoch: 6| Step: 2
Training loss: 5.082782381978763
Validation loss: 5.810003032980405

Epoch: 6| Step: 3
Training loss: 5.060368407034906
Validation loss: 5.799831953998276

Epoch: 6| Step: 4
Training loss: 5.502919549264175
Validation loss: 5.790035117440977

Epoch: 6| Step: 5
Training loss: 5.816895822348604
Validation loss: 5.78021812110005

Epoch: 6| Step: 6
Training loss: 5.188623513499872
Validation loss: 5.770340498596449

Epoch: 6| Step: 7
Training loss: 6.131692149855981
Validation loss: 5.759986432203655

Epoch: 6| Step: 8
Training loss: 6.679040424615826
Validation loss: 5.749533180879699

Epoch: 6| Step: 9
Training loss: 6.227779714580457
Validation loss: 5.738084250007907

Epoch: 6| Step: 10
Training loss: 6.262502753281892
Validation loss: 5.72533300147516

Epoch: 6| Step: 11
Training loss: 6.2132055975645475
Validation loss: 5.7119422853427135

Epoch: 6| Step: 12
Training loss: 6.1315851429093025
Validation loss: 5.697547671037409

Epoch: 6| Step: 13
Training loss: 5.476043023519316
Validation loss: 5.681758149009808

Epoch: 2| Step: 0
Training loss: 6.102049511413857
Validation loss: 5.664619815665201

Epoch: 6| Step: 1
Training loss: 4.89991399728466
Validation loss: 5.646296322303072

Epoch: 6| Step: 2
Training loss: 6.308116637337479
Validation loss: 5.626433999365203

Epoch: 6| Step: 3
Training loss: 6.694347263051141
Validation loss: 5.603772409775406

Epoch: 6| Step: 4
Training loss: 4.861138811789409
Validation loss: 5.579544630808403

Epoch: 6| Step: 5
Training loss: 5.918604931770569
Validation loss: 5.554176475170925

Epoch: 6| Step: 6
Training loss: 5.102956864623395
Validation loss: 5.526655968847294

Epoch: 6| Step: 7
Training loss: 5.376716339739568
Validation loss: 5.4968710470238715

Epoch: 6| Step: 8
Training loss: 5.967566247963077
Validation loss: 5.465602584786618

Epoch: 6| Step: 9
Training loss: 5.177424930634293
Validation loss: 5.432347924380235

Epoch: 6| Step: 10
Training loss: 3.761563465244733
Validation loss: 5.39785496810278

Epoch: 6| Step: 11
Training loss: 5.928481792356681
Validation loss: 5.360632244868098

Epoch: 6| Step: 12
Training loss: 5.749465254091707
Validation loss: 5.322692068144992

Epoch: 6| Step: 13
Training loss: 4.860902601341796
Validation loss: 5.282709055953821

Epoch: 3| Step: 0
Training loss: 5.241941170511876
Validation loss: 5.242760303056906

Epoch: 6| Step: 1
Training loss: 5.368912909526297
Validation loss: 5.201892956597626

Epoch: 6| Step: 2
Training loss: 5.112360557389316
Validation loss: 5.159020776671269

Epoch: 6| Step: 3
Training loss: 4.95399289394542
Validation loss: 5.117046268019943

Epoch: 6| Step: 4
Training loss: 5.966182775784069
Validation loss: 5.076935645475443

Epoch: 6| Step: 5
Training loss: 4.15289079107643
Validation loss: 5.034340198560249

Epoch: 6| Step: 6
Training loss: 5.145999221084127
Validation loss: 4.993704546766814

Epoch: 6| Step: 7
Training loss: 5.4016262855107176
Validation loss: 4.954748727381329

Epoch: 6| Step: 8
Training loss: 4.041231086042457
Validation loss: 4.915966166877921

Epoch: 6| Step: 9
Training loss: 5.027446185582276
Validation loss: 4.879514170771114

Epoch: 6| Step: 10
Training loss: 4.831811972401814
Validation loss: 4.84535087834825

Epoch: 6| Step: 11
Training loss: 4.979715208007025
Validation loss: 4.8106197076727035

Epoch: 6| Step: 12
Training loss: 5.92767227366564
Validation loss: 4.778764596032017

Epoch: 6| Step: 13
Training loss: 3.292218721347641
Validation loss: 4.747387174447078

Epoch: 4| Step: 0
Training loss: 5.449148395043135
Validation loss: 4.718773177699219

Epoch: 6| Step: 1
Training loss: 4.429198761204984
Validation loss: 4.688728723857319

Epoch: 6| Step: 2
Training loss: 4.685343335251906
Validation loss: 4.6625959438011

Epoch: 6| Step: 3
Training loss: 4.080460738178402
Validation loss: 4.634071442306043

Epoch: 6| Step: 4
Training loss: 4.974957313546162
Validation loss: 4.606103455857227

Epoch: 6| Step: 5
Training loss: 3.621603064741486
Validation loss: 4.579531306243747

Epoch: 6| Step: 6
Training loss: 4.08584717163838
Validation loss: 4.552964163187095

Epoch: 6| Step: 7
Training loss: 4.580924054009041
Validation loss: 4.528384673666612

Epoch: 6| Step: 8
Training loss: 3.9984747839825787
Validation loss: 4.50220557594462

Epoch: 6| Step: 9
Training loss: 5.182346587792624
Validation loss: 4.480922416486779

Epoch: 6| Step: 10
Training loss: 5.306155017231831
Validation loss: 4.458503650121959

Epoch: 6| Step: 11
Training loss: 4.077001658098951
Validation loss: 4.439293251352849

Epoch: 6| Step: 12
Training loss: 6.093422279348682
Validation loss: 4.421837241017627

Epoch: 6| Step: 13
Training loss: 2.9209978551598823
Validation loss: 4.404089133745651

Epoch: 5| Step: 0
Training loss: 4.139065200384288
Validation loss: 4.390937958387081

Epoch: 6| Step: 1
Training loss: 4.8077091298909425
Validation loss: 4.3772782003336905

Epoch: 6| Step: 2
Training loss: 4.453313027143343
Validation loss: 4.361625550038457

Epoch: 6| Step: 3
Training loss: 3.614079831515133
Validation loss: 4.34726929056237

Epoch: 6| Step: 4
Training loss: 3.3405189946968816
Validation loss: 4.334335961711573

Epoch: 6| Step: 5
Training loss: 3.636257187412328
Validation loss: 4.3235595312098845

Epoch: 6| Step: 6
Training loss: 4.2942476875355355
Validation loss: 4.311472987600073

Epoch: 6| Step: 7
Training loss: 4.917273510913129
Validation loss: 4.300537013026937

Epoch: 6| Step: 8
Training loss: 5.3497010049427205
Validation loss: 4.287249230189044

Epoch: 6| Step: 9
Training loss: 4.633506581385862
Validation loss: 4.272547282153619

Epoch: 6| Step: 10
Training loss: 5.098705104921076
Validation loss: 4.2568177269012155

Epoch: 6| Step: 11
Training loss: 3.5632798529222622
Validation loss: 4.23986376633883

Epoch: 6| Step: 12
Training loss: 5.205262624251226
Validation loss: 4.224223480737514

Epoch: 6| Step: 13
Training loss: 4.199871860547597
Validation loss: 4.20995363135453

Epoch: 6| Step: 0
Training loss: 5.104246966709974
Validation loss: 4.192288589128622

Epoch: 6| Step: 1
Training loss: 3.877295275755447
Validation loss: 4.178857252318646

Epoch: 6| Step: 2
Training loss: 3.3527360475463324
Validation loss: 4.168830289321347

Epoch: 6| Step: 3
Training loss: 4.662982349143919
Validation loss: 4.154013458266173

Epoch: 6| Step: 4
Training loss: 4.2379155858243855
Validation loss: 4.141628164447208

Epoch: 6| Step: 5
Training loss: 4.07661755057873
Validation loss: 4.131286540360146

Epoch: 6| Step: 6
Training loss: 3.8761433791105255
Validation loss: 4.119347045912523

Epoch: 6| Step: 7
Training loss: 3.6956690158606573
Validation loss: 4.107312028412629

Epoch: 6| Step: 8
Training loss: 4.602236427994563
Validation loss: 4.0981815752590744

Epoch: 6| Step: 9
Training loss: 4.1635045577778245
Validation loss: 4.086101421638998

Epoch: 6| Step: 10
Training loss: 4.4794154371626895
Validation loss: 4.07518904555923

Epoch: 6| Step: 11
Training loss: 4.696542385199622
Validation loss: 4.065149935733986

Epoch: 6| Step: 12
Training loss: 4.395407898671422
Validation loss: 4.051974718081873

Epoch: 6| Step: 13
Training loss: 3.942868040101372
Validation loss: 4.042918683804626

Epoch: 7| Step: 0
Training loss: 4.529936501434788
Validation loss: 4.032173361965348

Epoch: 6| Step: 1
Training loss: 4.098884449365223
Validation loss: 4.02084210102788

Epoch: 6| Step: 2
Training loss: 3.17971629286718
Validation loss: 4.012699630065313

Epoch: 6| Step: 3
Training loss: 4.179676547882847
Validation loss: 4.0069839768380096

Epoch: 6| Step: 4
Training loss: 4.402679078566556
Validation loss: 3.998003920505767

Epoch: 6| Step: 5
Training loss: 4.011566604953302
Validation loss: 3.9895661540392364

Epoch: 6| Step: 6
Training loss: 3.9618816868054174
Validation loss: 3.981203833505024

Epoch: 6| Step: 7
Training loss: 5.07085134878644
Validation loss: 3.976971364370758

Epoch: 6| Step: 8
Training loss: 4.425069241601622
Validation loss: 3.9691666085752475

Epoch: 6| Step: 9
Training loss: 4.181740971180404
Validation loss: 3.9618312701642395

Epoch: 6| Step: 10
Training loss: 3.605109795156291
Validation loss: 3.9545199800834228

Epoch: 6| Step: 11
Training loss: 4.579089795417009
Validation loss: 3.946396883258044

Epoch: 6| Step: 12
Training loss: 3.5526307580065755
Validation loss: 3.9374646082529643

Epoch: 6| Step: 13
Training loss: 3.440802634882855
Validation loss: 3.9313187750962575

Epoch: 8| Step: 0
Training loss: 3.9916338452693414
Validation loss: 3.9248938742673385

Epoch: 6| Step: 1
Training loss: 3.0857316733178206
Validation loss: 3.9197360317203342

Epoch: 6| Step: 2
Training loss: 4.081405781552053
Validation loss: 3.911855157947145

Epoch: 6| Step: 3
Training loss: 3.536097482390476
Validation loss: 3.906088663030356

Epoch: 6| Step: 4
Training loss: 5.47405992214645
Validation loss: 3.9007731130747962

Epoch: 6| Step: 5
Training loss: 2.7459137641885456
Validation loss: 3.8946085047423047

Epoch: 6| Step: 6
Training loss: 5.031731244877722
Validation loss: 3.8935749157924815

Epoch: 6| Step: 7
Training loss: 3.0804710161789473
Validation loss: 3.887480393596274

Epoch: 6| Step: 8
Training loss: 3.550083809521469
Validation loss: 3.8807853913263695

Epoch: 6| Step: 9
Training loss: 5.177976023453844
Validation loss: 3.876052992563939

Epoch: 6| Step: 10
Training loss: 4.183935441738991
Validation loss: 3.869736861921514

Epoch: 6| Step: 11
Training loss: 4.024998275093041
Validation loss: 3.864701146565913

Epoch: 6| Step: 12
Training loss: 3.8210276302964963
Validation loss: 3.8579896643637257

Epoch: 6| Step: 13
Training loss: 3.8462900592452245
Validation loss: 3.852761905868727

Epoch: 9| Step: 0
Training loss: 4.440079919594107
Validation loss: 3.8470669039516636

Epoch: 6| Step: 1
Training loss: 3.5360606685802045
Validation loss: 3.842485848422503

Epoch: 6| Step: 2
Training loss: 4.490649787765399
Validation loss: 3.8374140786572872

Epoch: 6| Step: 3
Training loss: 3.1081776829697385
Validation loss: 3.8324822011055013

Epoch: 6| Step: 4
Training loss: 3.651085229777927
Validation loss: 3.8271852968517095

Epoch: 6| Step: 5
Training loss: 4.000039100455867
Validation loss: 3.821300973351067

Epoch: 6| Step: 6
Training loss: 4.929759851762043
Validation loss: 3.8169129194715925

Epoch: 6| Step: 7
Training loss: 3.9662417197539286
Validation loss: 3.811833447616522

Epoch: 6| Step: 8
Training loss: 3.8437136516558166
Validation loss: 3.8062181084395674

Epoch: 6| Step: 9
Training loss: 4.121724764708428
Validation loss: 3.801184093463507

Epoch: 6| Step: 10
Training loss: 3.5701482221676835
Validation loss: 3.797637229608344

Epoch: 6| Step: 11
Training loss: 4.281429983100893
Validation loss: 3.790463685511972

Epoch: 6| Step: 12
Training loss: 3.586974681712785
Validation loss: 3.7877220226002954

Epoch: 6| Step: 13
Training loss: 3.9038695139184223
Validation loss: 3.7834332654088665

Epoch: 10| Step: 0
Training loss: 4.138765198113116
Validation loss: 3.7784943485137927

Epoch: 6| Step: 1
Training loss: 4.488856611565936
Validation loss: 3.7749543411415454

Epoch: 6| Step: 2
Training loss: 3.9890797083864893
Validation loss: 3.771939472281238

Epoch: 6| Step: 3
Training loss: 4.234874738081542
Validation loss: 3.7678187209746197

Epoch: 6| Step: 4
Training loss: 3.8798268926485555
Validation loss: 3.7638696796855546

Epoch: 6| Step: 5
Training loss: 4.064792866326965
Validation loss: 3.7578162822048147

Epoch: 6| Step: 6
Training loss: 2.9229081719062755
Validation loss: 3.75218546772324

Epoch: 6| Step: 7
Training loss: 3.620374161578361
Validation loss: 3.74642214302926

Epoch: 6| Step: 8
Training loss: 3.920947690965551
Validation loss: 3.7429440364081312

Epoch: 6| Step: 9
Training loss: 4.0050448552547495
Validation loss: 3.7359679752106905

Epoch: 6| Step: 10
Training loss: 4.150969628730446
Validation loss: 3.73295676513887

Epoch: 6| Step: 11
Training loss: 4.20447186867245
Validation loss: 3.727565871166776

Epoch: 6| Step: 12
Training loss: 3.983140941320411
Validation loss: 3.725146453636609

Epoch: 6| Step: 13
Training loss: 2.362820263504131
Validation loss: 3.7194792839923467

Epoch: 11| Step: 0
Training loss: 3.1084907846398577
Validation loss: 3.7159113719427475

Epoch: 6| Step: 1
Training loss: 4.379800397252755
Validation loss: 3.714398473011589

Epoch: 6| Step: 2
Training loss: 3.1514970098375685
Validation loss: 3.709932930534724

Epoch: 6| Step: 3
Training loss: 4.277751969318785
Validation loss: 3.7068220079691354

Epoch: 6| Step: 4
Training loss: 2.863938988552544
Validation loss: 3.700127757282703

Epoch: 6| Step: 5
Training loss: 4.346263131052433
Validation loss: 3.696639815467048

Epoch: 6| Step: 6
Training loss: 4.098225251321758
Validation loss: 3.693816491053905

Epoch: 6| Step: 7
Training loss: 4.4314626537782145
Validation loss: 3.687732806677147

Epoch: 6| Step: 8
Training loss: 4.000412919666172
Validation loss: 3.684253845446683

Epoch: 6| Step: 9
Training loss: 4.163300464175614
Validation loss: 3.679582868010309

Epoch: 6| Step: 10
Training loss: 4.086934247075305
Validation loss: 3.677903239272842

Epoch: 6| Step: 11
Training loss: 3.185241647173902
Validation loss: 3.673652357353515

Epoch: 6| Step: 12
Training loss: 3.8318219453383224
Validation loss: 3.671927251642565

Epoch: 6| Step: 13
Training loss: 3.9171644395013274
Validation loss: 3.667084123856018

Epoch: 12| Step: 0
Training loss: 4.010073851097978
Validation loss: 3.663067871316545

Epoch: 6| Step: 1
Training loss: 3.178189311319259
Validation loss: 3.6580512138989767

Epoch: 6| Step: 2
Training loss: 4.442097605876836
Validation loss: 3.6550930490089923

Epoch: 6| Step: 3
Training loss: 3.52086767296532
Validation loss: 3.652546909892365

Epoch: 6| Step: 4
Training loss: 4.198706364088341
Validation loss: 3.653131235161694

Epoch: 6| Step: 5
Training loss: 4.830627385495594
Validation loss: 3.6420713732054604

Epoch: 6| Step: 6
Training loss: 2.378661094523576
Validation loss: 3.6471785568911868

Epoch: 6| Step: 7
Training loss: 4.0487894957153845
Validation loss: 3.668528894039973

Epoch: 6| Step: 8
Training loss: 2.274441946144556
Validation loss: 3.6376185637583687

Epoch: 6| Step: 9
Training loss: 2.7172689679015765
Validation loss: 3.631311636874241

Epoch: 6| Step: 10
Training loss: 4.116098915105256
Validation loss: 3.630455851967949

Epoch: 6| Step: 11
Training loss: 4.088650154893584
Validation loss: 3.6286404229284916

Epoch: 6| Step: 12
Training loss: 4.529247183319478
Validation loss: 3.6249309698709715

Epoch: 6| Step: 13
Training loss: 4.559113800536266
Validation loss: 3.6208900572867813

Epoch: 13| Step: 0
Training loss: 3.8110173578720357
Validation loss: 3.615450174105056

Epoch: 6| Step: 1
Training loss: 3.083262382584531
Validation loss: 3.613379446977385

Epoch: 6| Step: 2
Training loss: 4.050747818841072
Validation loss: 3.6130250230982925

Epoch: 6| Step: 3
Training loss: 4.143305763609154
Validation loss: 3.612255239755241

Epoch: 6| Step: 4
Training loss: 3.297284286187715
Validation loss: 3.6066292643422138

Epoch: 6| Step: 5
Training loss: 3.384333526272673
Validation loss: 3.6017547243638304

Epoch: 6| Step: 6
Training loss: 4.4026431207826295
Validation loss: 3.6021022234287527

Epoch: 6| Step: 7
Training loss: 4.671714142036341
Validation loss: 3.59629710682814

Epoch: 6| Step: 8
Training loss: 3.5025835038985473
Validation loss: 3.5881335198444004

Epoch: 6| Step: 9
Training loss: 3.8944052596455574
Validation loss: 3.5848364046893106

Epoch: 6| Step: 10
Training loss: 3.6122965032686416
Validation loss: 3.5816114218122537

Epoch: 6| Step: 11
Training loss: 3.626941818523707
Validation loss: 3.5788479142914404

Epoch: 6| Step: 12
Training loss: 3.0474812222435035
Validation loss: 3.575866410537409

Epoch: 6| Step: 13
Training loss: 4.5060026611509905
Validation loss: 3.57147599368979

Epoch: 14| Step: 0
Training loss: 3.8237027530301404
Validation loss: 3.568681885377605

Epoch: 6| Step: 1
Training loss: 4.6063342393395335
Validation loss: 3.5663011238420217

Epoch: 6| Step: 2
Training loss: 3.8097788370576686
Validation loss: 3.565096383437711

Epoch: 6| Step: 3
Training loss: 3.8627099828831617
Validation loss: 3.5611437158932415

Epoch: 6| Step: 4
Training loss: 3.9666708959562262
Validation loss: 3.5557221473826885

Epoch: 6| Step: 5
Training loss: 2.5881734441568196
Validation loss: 3.5524451718922823

Epoch: 6| Step: 6
Training loss: 3.556799896042548
Validation loss: 3.548579060488344

Epoch: 6| Step: 7
Training loss: 3.52741215197036
Validation loss: 3.542872349740605

Epoch: 6| Step: 8
Training loss: 3.6511638510262747
Validation loss: 3.5371058960346082

Epoch: 6| Step: 9
Training loss: 3.6874246104664343
Validation loss: 3.532997785618169

Epoch: 6| Step: 10
Training loss: 3.461816404872581
Validation loss: 3.529458353278809

Epoch: 6| Step: 11
Training loss: 4.393163198515842
Validation loss: 3.524788777494229

Epoch: 6| Step: 12
Training loss: 2.8062010694965975
Validation loss: 3.5199046304793478

Epoch: 6| Step: 13
Training loss: 4.637227982514598
Validation loss: 3.516842575428643

Epoch: 15| Step: 0
Training loss: 4.124248783026067
Validation loss: 3.51392075225077

Epoch: 6| Step: 1
Training loss: 3.2471127523072383
Validation loss: 3.5075309284674354

Epoch: 6| Step: 2
Training loss: 3.7918187764157074
Validation loss: 3.5052944269623563

Epoch: 6| Step: 3
Training loss: 4.236408491414388
Validation loss: 3.497419633733139

Epoch: 6| Step: 4
Training loss: 3.2997389372241264
Validation loss: 3.4946436481677003

Epoch: 6| Step: 5
Training loss: 3.2648346597070748
Validation loss: 3.489659302713637

Epoch: 6| Step: 6
Training loss: 3.6223193813495365
Validation loss: 3.487774267639493

Epoch: 6| Step: 7
Training loss: 4.085251701379371
Validation loss: 3.484223655188725

Epoch: 6| Step: 8
Training loss: 3.639326265045791
Validation loss: 3.4800107031725855

Epoch: 6| Step: 9
Training loss: 3.990247520092763
Validation loss: 3.476361382716097

Epoch: 6| Step: 10
Training loss: 3.920704944439525
Validation loss: 3.4701339634754227

Epoch: 6| Step: 11
Training loss: 3.0692591910942775
Validation loss: 3.465343269850864

Epoch: 6| Step: 12
Training loss: 3.663305924312762
Validation loss: 3.4621740828466896

Epoch: 6| Step: 13
Training loss: 3.629004141449109
Validation loss: 3.4581195608568396

Epoch: 16| Step: 0
Training loss: 3.325955682382415
Validation loss: 3.458583716471153

Epoch: 6| Step: 1
Training loss: 3.0697740077734172
Validation loss: 3.4586082454986475

Epoch: 6| Step: 2
Training loss: 3.784798462514942
Validation loss: 3.4536455027822646

Epoch: 6| Step: 3
Training loss: 3.1600984584583562
Validation loss: 3.4414090584220665

Epoch: 6| Step: 4
Training loss: 2.3668091726605334
Validation loss: 3.4405172327214575

Epoch: 6| Step: 5
Training loss: 3.640954522540082
Validation loss: 3.441082746157333

Epoch: 6| Step: 6
Training loss: 3.874362154731804
Validation loss: 3.4453832612425805

Epoch: 6| Step: 7
Training loss: 4.720620296258248
Validation loss: 3.4404560553226666

Epoch: 6| Step: 8
Training loss: 3.230959208111421
Validation loss: 3.431908705889751

Epoch: 6| Step: 9
Training loss: 4.3930151464599305
Validation loss: 3.4278457685671486

Epoch: 6| Step: 10
Training loss: 3.817696703606448
Validation loss: 3.427310842669858

Epoch: 6| Step: 11
Training loss: 3.8802113099908184
Validation loss: 3.4247235915294243

Epoch: 6| Step: 12
Training loss: 3.8547439280362608
Validation loss: 3.4220202711967818

Epoch: 6| Step: 13
Training loss: 3.364973929362319
Validation loss: 3.423192947639201

Epoch: 17| Step: 0
Training loss: 4.131106855766354
Validation loss: 3.4199647994509617

Epoch: 6| Step: 1
Training loss: 3.728061590430863
Validation loss: 3.4151902514146975

Epoch: 6| Step: 2
Training loss: 2.866912412829683
Validation loss: 3.4112012781185967

Epoch: 6| Step: 3
Training loss: 4.079727501090519
Validation loss: 3.4121088971502656

Epoch: 6| Step: 4
Training loss: 2.8203807199105086
Validation loss: 3.405443564012449

Epoch: 6| Step: 5
Training loss: 3.276757789216636
Validation loss: 3.404429316141109

Epoch: 6| Step: 6
Training loss: 3.873916474489139
Validation loss: 3.399811901870881

Epoch: 6| Step: 7
Training loss: 2.940076306968222
Validation loss: 3.3896531750514054

Epoch: 6| Step: 8
Training loss: 3.3859946984994824
Validation loss: 3.382595392244834

Epoch: 6| Step: 9
Training loss: 4.411917646412451
Validation loss: 3.380347213851197

Epoch: 6| Step: 10
Training loss: 2.8940562734978674
Validation loss: 3.374884151079275

Epoch: 6| Step: 11
Training loss: 3.7314803264845064
Validation loss: 3.370700832532999

Epoch: 6| Step: 12
Training loss: 4.169437911025476
Validation loss: 3.369407824549407

Epoch: 6| Step: 13
Training loss: 3.9887452336697984
Validation loss: 3.3580631595575063

Epoch: 18| Step: 0
Training loss: 3.671722408938783
Validation loss: 3.3527918674298807

Epoch: 6| Step: 1
Training loss: 3.2312154033882146
Validation loss: 3.352572590767124

Epoch: 6| Step: 2
Training loss: 3.2732664805601743
Validation loss: 3.347993555609114

Epoch: 6| Step: 3
Training loss: 3.964814885978679
Validation loss: 3.3486229671485135

Epoch: 6| Step: 4
Training loss: 3.4693811890538835
Validation loss: 3.3454445213979307

Epoch: 6| Step: 5
Training loss: 3.928862771464785
Validation loss: 3.342136546192785

Epoch: 6| Step: 6
Training loss: 3.1815959629884025
Validation loss: 3.3401770007558067

Epoch: 6| Step: 7
Training loss: 3.9199811154514004
Validation loss: 3.3389154813354507

Epoch: 6| Step: 8
Training loss: 3.0618860057439123
Validation loss: 3.333520466155999

Epoch: 6| Step: 9
Training loss: 3.078534249146653
Validation loss: 3.3302903580666476

Epoch: 6| Step: 10
Training loss: 3.1955426046998885
Validation loss: 3.329548273133112

Epoch: 6| Step: 11
Training loss: 3.8877475622901834
Validation loss: 3.322790697361283

Epoch: 6| Step: 12
Training loss: 3.87357550248629
Validation loss: 3.3173589764761497

Epoch: 6| Step: 13
Training loss: 4.339531036564846
Validation loss: 3.313615729845982

Epoch: 19| Step: 0
Training loss: 3.8041579487015826
Validation loss: 3.3100123058165067

Epoch: 6| Step: 1
Training loss: 3.1773020351158108
Validation loss: 3.3108534417098587

Epoch: 6| Step: 2
Training loss: 3.6564471851876115
Validation loss: 3.308697648613311

Epoch: 6| Step: 3
Training loss: 3.482494993185701
Validation loss: 3.3052611564749266

Epoch: 6| Step: 4
Training loss: 3.0458143686799155
Validation loss: 3.302516450921639

Epoch: 6| Step: 5
Training loss: 4.137221294132222
Validation loss: 3.3023128401943707

Epoch: 6| Step: 6
Training loss: 4.0813560109879825
Validation loss: 3.296321560977155

Epoch: 6| Step: 7
Training loss: 3.1865924216310875
Validation loss: 3.296372018009673

Epoch: 6| Step: 8
Training loss: 3.314938205701154
Validation loss: 3.292845394376769

Epoch: 6| Step: 9
Training loss: 3.269669214252396
Validation loss: 3.29079191724903

Epoch: 6| Step: 10
Training loss: 3.442991551894372
Validation loss: 3.2864898081566007

Epoch: 6| Step: 11
Training loss: 3.2191155976001995
Validation loss: 3.284418582370491

Epoch: 6| Step: 12
Training loss: 4.152462947710008
Validation loss: 3.279558813778061

Epoch: 6| Step: 13
Training loss: 3.0926160179091933
Validation loss: 3.278439502501369

Epoch: 20| Step: 0
Training loss: 4.190678998242241
Validation loss: 3.2787877139220454

Epoch: 6| Step: 1
Training loss: 3.900359450183689
Validation loss: 3.2758808544848543

Epoch: 6| Step: 2
Training loss: 3.937225816656654
Validation loss: 3.271850664953068

Epoch: 6| Step: 3
Training loss: 3.623820145748195
Validation loss: 3.2661726768531913

Epoch: 6| Step: 4
Training loss: 3.0696342049039824
Validation loss: 3.2632235437466917

Epoch: 6| Step: 5
Training loss: 1.7686165641353238
Validation loss: 3.26383384117659

Epoch: 6| Step: 6
Training loss: 3.423052859407213
Validation loss: 3.2616062085205897

Epoch: 6| Step: 7
Training loss: 3.4248329511683053
Validation loss: 3.2588946929230915

Epoch: 6| Step: 8
Training loss: 2.89643910244668
Validation loss: 3.256837182781859

Epoch: 6| Step: 9
Training loss: 3.6404054763818143
Validation loss: 3.257315165823301

Epoch: 6| Step: 10
Training loss: 3.768562658913894
Validation loss: 3.2500868802254734

Epoch: 6| Step: 11
Training loss: 3.9167765879255456
Validation loss: 3.2515165546938265

Epoch: 6| Step: 12
Training loss: 3.6409271507780745
Validation loss: 3.2481766043290587

Epoch: 6| Step: 13
Training loss: 3.0701005003443056
Validation loss: 3.2439904638111066

Epoch: 21| Step: 0
Training loss: 3.049305264503764
Validation loss: 3.2407523129580986

Epoch: 6| Step: 1
Training loss: 3.2192320231268803
Validation loss: 3.2366505213987327

Epoch: 6| Step: 2
Training loss: 3.7701105651022626
Validation loss: 3.2324783211711003

Epoch: 6| Step: 3
Training loss: 3.346755201402217
Validation loss: 3.2335836591656957

Epoch: 6| Step: 4
Training loss: 2.81636984877005
Validation loss: 3.2306007802381442

Epoch: 6| Step: 5
Training loss: 3.2404114052283974
Validation loss: 3.230872368968344

Epoch: 6| Step: 6
Training loss: 2.873868470805126
Validation loss: 3.2301026786246867

Epoch: 6| Step: 7
Training loss: 3.8637529630967435
Validation loss: 3.2289383923005963

Epoch: 6| Step: 8
Training loss: 3.8322565943792926
Validation loss: 3.2237593445463153

Epoch: 6| Step: 9
Training loss: 4.170954570602429
Validation loss: 3.215741878570553

Epoch: 6| Step: 10
Training loss: 3.0202024831533407
Validation loss: 3.2126517274251385

Epoch: 6| Step: 11
Training loss: 3.6667949191696074
Validation loss: 3.2129928245962835

Epoch: 6| Step: 12
Training loss: 3.7307707819077054
Validation loss: 3.213476330378529

Epoch: 6| Step: 13
Training loss: 3.904628325491364
Validation loss: 3.207350460619152

Epoch: 22| Step: 0
Training loss: 3.091376733337733
Validation loss: 3.2023973592414428

Epoch: 6| Step: 1
Training loss: 3.5192018750653364
Validation loss: 3.203235608904099

Epoch: 6| Step: 2
Training loss: 3.340436345225196
Validation loss: 3.202023197163704

Epoch: 6| Step: 3
Training loss: 3.06608449620659
Validation loss: 3.1990618162355937

Epoch: 6| Step: 4
Training loss: 3.587548120687653
Validation loss: 3.196363966737053

Epoch: 6| Step: 5
Training loss: 3.462127687564397
Validation loss: 3.194061373735689

Epoch: 6| Step: 6
Training loss: 2.1464834864079143
Validation loss: 3.1874419723205722

Epoch: 6| Step: 7
Training loss: 3.5483903378670396
Validation loss: 3.184870907018682

Epoch: 6| Step: 8
Training loss: 3.6274161343702556
Validation loss: 3.1874221737565755

Epoch: 6| Step: 9
Training loss: 3.489541640910373
Validation loss: 3.1831388612435014

Epoch: 6| Step: 10
Training loss: 4.2866043801377804
Validation loss: 3.17506948170088

Epoch: 6| Step: 11
Training loss: 3.95337878230593
Validation loss: 3.173579582939206

Epoch: 6| Step: 12
Training loss: 3.390539212174369
Validation loss: 3.1795668625338513

Epoch: 6| Step: 13
Training loss: 3.218153074152813
Validation loss: 3.1839220143622

Epoch: 23| Step: 0
Training loss: 2.826010403505305
Validation loss: 3.1920905237220105

Epoch: 6| Step: 1
Training loss: 3.50048102751768
Validation loss: 3.1787341921290455

Epoch: 6| Step: 2
Training loss: 2.741198847859206
Validation loss: 3.175117138985275

Epoch: 6| Step: 3
Training loss: 3.9253752996734126
Validation loss: 3.1733609431799383

Epoch: 6| Step: 4
Training loss: 4.154824837161037
Validation loss: 3.1672485952424267

Epoch: 6| Step: 5
Training loss: 3.672092382611127
Validation loss: 3.164453358513887

Epoch: 6| Step: 6
Training loss: 2.8629897985406534
Validation loss: 3.165159899730479

Epoch: 6| Step: 7
Training loss: 3.069297564537015
Validation loss: 3.164201138243126

Epoch: 6| Step: 8
Training loss: 3.419699896422462
Validation loss: 3.1614884982944145

Epoch: 6| Step: 9
Training loss: 2.779101795848258
Validation loss: 3.1603026200078297

Epoch: 6| Step: 10
Training loss: 3.4157414618039694
Validation loss: 3.1573559344300217

Epoch: 6| Step: 11
Training loss: 3.4051469889323944
Validation loss: 3.15848069306769

Epoch: 6| Step: 12
Training loss: 4.1673101818332805
Validation loss: 3.1621961129935494

Epoch: 6| Step: 13
Training loss: 3.747936443950274
Validation loss: 3.1639640854580686

Epoch: 24| Step: 0
Training loss: 2.9270829894222903
Validation loss: 3.1656803258393773

Epoch: 6| Step: 1
Training loss: 4.180509283261029
Validation loss: 3.159771449628751

Epoch: 6| Step: 2
Training loss: 3.009308678202209
Validation loss: 3.1530521177031363

Epoch: 6| Step: 3
Training loss: 4.31417062438072
Validation loss: 3.149867868850696

Epoch: 6| Step: 4
Training loss: 3.4153885350300692
Validation loss: 3.1470367736452998

Epoch: 6| Step: 5
Training loss: 4.171923462089778
Validation loss: 3.1447831614673256

Epoch: 6| Step: 6
Training loss: 3.422594526056939
Validation loss: 3.1444944566691166

Epoch: 6| Step: 7
Training loss: 2.952081889652679
Validation loss: 3.1410252832267083

Epoch: 6| Step: 8
Training loss: 3.2171641767192765
Validation loss: 3.136553669010784

Epoch: 6| Step: 9
Training loss: 3.6361593600896778
Validation loss: 3.1377119916277114

Epoch: 6| Step: 10
Training loss: 3.195935176998841
Validation loss: 3.1500714043465687

Epoch: 6| Step: 11
Training loss: 2.7602986052595386
Validation loss: 3.1393108072256295

Epoch: 6| Step: 12
Training loss: 3.4186494857824523
Validation loss: 3.147463739415587

Epoch: 6| Step: 13
Training loss: 1.4768798325661767
Validation loss: 3.1374334367732097

Epoch: 25| Step: 0
Training loss: 3.824869196032755
Validation loss: 3.130396770826168

Epoch: 6| Step: 1
Training loss: 3.0424542561385866
Validation loss: 3.128639979120159

Epoch: 6| Step: 2
Training loss: 3.26753259457221
Validation loss: 3.129170736788647

Epoch: 6| Step: 3
Training loss: 3.470280215247591
Validation loss: 3.129103678691771

Epoch: 6| Step: 4
Training loss: 3.098225602576489
Validation loss: 3.125556490991314

Epoch: 6| Step: 5
Training loss: 3.1387192746887598
Validation loss: 3.123840106930561

Epoch: 6| Step: 6
Training loss: 3.613478404671913
Validation loss: 3.122788074262128

Epoch: 6| Step: 7
Training loss: 3.648949270684548
Validation loss: 3.1239431796914956

Epoch: 6| Step: 8
Training loss: 2.800434000576206
Validation loss: 3.1180910617495528

Epoch: 6| Step: 9
Training loss: 3.4453714586260564
Validation loss: 3.117123445900361

Epoch: 6| Step: 10
Training loss: 3.279973681041913
Validation loss: 3.116932070227376

Epoch: 6| Step: 11
Training loss: 3.3590752046461763
Validation loss: 3.122908998920646

Epoch: 6| Step: 12
Training loss: 3.867059385701428
Validation loss: 3.1131591328260426

Epoch: 6| Step: 13
Training loss: 3.4300948402928046
Validation loss: 3.1143098256249964

Epoch: 26| Step: 0
Training loss: 3.038233312933416
Validation loss: 3.1104991519607954

Epoch: 6| Step: 1
Training loss: 3.623443532447679
Validation loss: 3.111760464912131

Epoch: 6| Step: 2
Training loss: 2.985091038630335
Validation loss: 3.113338357585354

Epoch: 6| Step: 3
Training loss: 3.4782170505458696
Validation loss: 3.1100771647036467

Epoch: 6| Step: 4
Training loss: 2.6112185607157
Validation loss: 3.1080267498794014

Epoch: 6| Step: 5
Training loss: 3.7901875192355905
Validation loss: 3.105478993091496

Epoch: 6| Step: 6
Training loss: 3.76607045431576
Validation loss: 3.1082058317888714

Epoch: 6| Step: 7
Training loss: 3.3811534310757176
Validation loss: 3.1033833510506463

Epoch: 6| Step: 8
Training loss: 2.9889366877191224
Validation loss: 3.0998858009710064

Epoch: 6| Step: 9
Training loss: 3.432448403345049
Validation loss: 3.099502053891768

Epoch: 6| Step: 10
Training loss: 4.131078230018078
Validation loss: 3.1018552816831155

Epoch: 6| Step: 11
Training loss: 2.5774376155137557
Validation loss: 3.103724972196961

Epoch: 6| Step: 12
Training loss: 3.8020436463396727
Validation loss: 3.1019239321745036

Epoch: 6| Step: 13
Training loss: 3.0362879780027074
Validation loss: 3.096862842812484

Epoch: 27| Step: 0
Training loss: 4.042727432789056
Validation loss: 3.096125054324412

Epoch: 6| Step: 1
Training loss: 3.5157332340110066
Validation loss: 3.094272914466499

Epoch: 6| Step: 2
Training loss: 2.9816607370276755
Validation loss: 3.0944979780533903

Epoch: 6| Step: 3
Training loss: 2.504665218070922
Validation loss: 3.0922564840428373

Epoch: 6| Step: 4
Training loss: 3.3745708899208315
Validation loss: 3.091986144981167

Epoch: 6| Step: 5
Training loss: 3.3237759108033766
Validation loss: 3.09215788003043

Epoch: 6| Step: 6
Training loss: 3.4282615669192777
Validation loss: 3.0894874732521447

Epoch: 6| Step: 7
Training loss: 3.1523998685660817
Validation loss: 3.0874890145955853

Epoch: 6| Step: 8
Training loss: 3.8834711817122387
Validation loss: 3.0871790710122027

Epoch: 6| Step: 9
Training loss: 2.984756365470767
Validation loss: 3.0871516406132087

Epoch: 6| Step: 10
Training loss: 3.697246537358283
Validation loss: 3.0872059306772

Epoch: 6| Step: 11
Training loss: 3.3539208426736757
Validation loss: 3.086447795454159

Epoch: 6| Step: 12
Training loss: 3.324420855572197
Validation loss: 3.0853782602949678

Epoch: 6| Step: 13
Training loss: 3.040189480146807
Validation loss: 3.0847980913460344

Epoch: 28| Step: 0
Training loss: 3.5127220545183766
Validation loss: 3.0854567411205056

Epoch: 6| Step: 1
Training loss: 3.2870192897916497
Validation loss: 3.0881422439930115

Epoch: 6| Step: 2
Training loss: 3.851735325895583
Validation loss: 3.084281049604269

Epoch: 6| Step: 3
Training loss: 3.527784959947646
Validation loss: 3.0827921869471617

Epoch: 6| Step: 4
Training loss: 2.842914668211127
Validation loss: 3.081488145885849

Epoch: 6| Step: 5
Training loss: 2.5733292798354617
Validation loss: 3.081351749006762

Epoch: 6| Step: 6
Training loss: 3.844691711686407
Validation loss: 3.0788278526323953

Epoch: 6| Step: 7
Training loss: 3.9506514579419267
Validation loss: 3.079395838264206

Epoch: 6| Step: 8
Training loss: 3.2256061900949877
Validation loss: 3.0793328933066353

Epoch: 6| Step: 9
Training loss: 2.6874195352972916
Validation loss: 3.0803605639811242

Epoch: 6| Step: 10
Training loss: 3.441714945185905
Validation loss: 3.080996483938405

Epoch: 6| Step: 11
Training loss: 3.5427116797069766
Validation loss: 3.0786800164195163

Epoch: 6| Step: 12
Training loss: 2.837154747212663
Validation loss: 3.0865751131915555

Epoch: 6| Step: 13
Training loss: 3.430342835400536
Validation loss: 3.0991607894938573

Epoch: 29| Step: 0
Training loss: 4.100461626814536
Validation loss: 3.075700473713195

Epoch: 6| Step: 1
Training loss: 2.8678987125084316
Validation loss: 3.0726885633588723

Epoch: 6| Step: 2
Training loss: 3.558346920895747
Validation loss: 3.0711768251262304

Epoch: 6| Step: 3
Training loss: 3.0880510649239006
Validation loss: 3.071344823233444

Epoch: 6| Step: 4
Training loss: 3.398857283700058
Validation loss: 3.070921356702334

Epoch: 6| Step: 5
Training loss: 3.9029110485655623
Validation loss: 3.071525417022473

Epoch: 6| Step: 6
Training loss: 3.887695925764521
Validation loss: 3.0705178674397566

Epoch: 6| Step: 7
Training loss: 3.049863005516312
Validation loss: 3.069779945496274

Epoch: 6| Step: 8
Training loss: 3.3291332168394625
Validation loss: 3.0691036393440227

Epoch: 6| Step: 9
Training loss: 2.9892656288181865
Validation loss: 3.0691896546076927

Epoch: 6| Step: 10
Training loss: 1.9210612117064163
Validation loss: 3.0672150529068314

Epoch: 6| Step: 11
Training loss: 3.4742723100984465
Validation loss: 3.069259166036368

Epoch: 6| Step: 12
Training loss: 2.7665534750828806
Validation loss: 3.0845184415498226

Epoch: 6| Step: 13
Training loss: 4.119622858433468
Validation loss: 3.0961498118995054

Epoch: 30| Step: 0
Training loss: 3.665069897077526
Validation loss: 3.0676929661451746

Epoch: 6| Step: 1
Training loss: 3.655207036908582
Validation loss: 3.065932342127845

Epoch: 6| Step: 2
Training loss: 3.8622640692001338
Validation loss: 3.071632867646442

Epoch: 6| Step: 3
Training loss: 3.120053152463005
Validation loss: 3.0872992762645204

Epoch: 6| Step: 4
Training loss: 2.7116913640500324
Validation loss: 3.09579065199852

Epoch: 6| Step: 5
Training loss: 3.7440328806386987
Validation loss: 3.068776318098688

Epoch: 6| Step: 6
Training loss: 2.9097311848755556
Validation loss: 3.0661664156383006

Epoch: 6| Step: 7
Training loss: 3.55622015808135
Validation loss: 3.0673523901537862

Epoch: 6| Step: 8
Training loss: 3.257467347667228
Validation loss: 3.071709906946114

Epoch: 6| Step: 9
Training loss: 3.130859984209236
Validation loss: 3.085258614198937

Epoch: 6| Step: 10
Training loss: 3.252376861000533
Validation loss: 3.0678341811504217

Epoch: 6| Step: 11
Training loss: 3.381563797525612
Validation loss: 3.0673654316822274

Epoch: 6| Step: 12
Training loss: 2.8324008042826625
Validation loss: 3.0696072273952066

Epoch: 6| Step: 13
Training loss: 3.6094090844068414
Validation loss: 3.0649985249740013

Epoch: 31| Step: 0
Training loss: 2.6334823525994318
Validation loss: 3.068037383170334

Epoch: 6| Step: 1
Training loss: 3.295516905000273
Validation loss: 3.0612723606578127

Epoch: 6| Step: 2
Training loss: 3.2347028630624926
Validation loss: 3.062868979624813

Epoch: 6| Step: 3
Training loss: 3.162964580924919
Validation loss: 3.0698936185221717

Epoch: 6| Step: 4
Training loss: 3.661783579257961
Validation loss: 3.059610173233834

Epoch: 6| Step: 5
Training loss: 3.747832116697755
Validation loss: 3.058853706021835

Epoch: 6| Step: 6
Training loss: 2.640061357825514
Validation loss: 3.0584899769909377

Epoch: 6| Step: 7
Training loss: 3.5572910709110652
Validation loss: 3.062400503176757

Epoch: 6| Step: 8
Training loss: 2.9549222452484036
Validation loss: 3.0606411015009587

Epoch: 6| Step: 9
Training loss: 3.821456769016677
Validation loss: 3.0600512560887303

Epoch: 6| Step: 10
Training loss: 3.3463843120399646
Validation loss: 3.0580331716150835

Epoch: 6| Step: 11
Training loss: 3.6177276801197853
Validation loss: 3.0544424943556843

Epoch: 6| Step: 12
Training loss: 3.50355186073635
Validation loss: 3.0569127295851355

Epoch: 6| Step: 13
Training loss: 3.1830420642102326
Validation loss: 3.055286343841163

Epoch: 32| Step: 0
Training loss: 3.0750377683723666
Validation loss: 3.0584830542505883

Epoch: 6| Step: 1
Training loss: 3.2274295851799653
Validation loss: 3.0665062087491277

Epoch: 6| Step: 2
Training loss: 3.2169925373098742
Validation loss: 3.051238352126931

Epoch: 6| Step: 3
Training loss: 3.1363692415511513
Validation loss: 3.0504047647359847

Epoch: 6| Step: 4
Training loss: 2.3817332340634176
Validation loss: 3.0472407093918696

Epoch: 6| Step: 5
Training loss: 3.7846056967868353
Validation loss: 3.048134919434447

Epoch: 6| Step: 6
Training loss: 3.4518394321126658
Validation loss: 3.048207885728411

Epoch: 6| Step: 7
Training loss: 4.058742252456418
Validation loss: 3.044173692707305

Epoch: 6| Step: 8
Training loss: 2.9660632373450313
Validation loss: 3.0455285112725035

Epoch: 6| Step: 9
Training loss: 3.6032259527457513
Validation loss: 3.0413952592722406

Epoch: 6| Step: 10
Training loss: 3.361529559805374
Validation loss: 3.043012932705929

Epoch: 6| Step: 11
Training loss: 3.457277450846453
Validation loss: 3.040277989780974

Epoch: 6| Step: 12
Training loss: 3.240537365985636
Validation loss: 3.0436747843685663

Epoch: 6| Step: 13
Training loss: 3.256225931441084
Validation loss: 3.0425679103189727

Epoch: 33| Step: 0
Training loss: 3.256370463129103
Validation loss: 3.038417981590402

Epoch: 6| Step: 1
Training loss: 3.4875989291471545
Validation loss: 3.0369638705223947

Epoch: 6| Step: 2
Training loss: 3.796077691652853
Validation loss: 3.036257257605489

Epoch: 6| Step: 3
Training loss: 3.083822331873311
Validation loss: 3.038476076041496

Epoch: 6| Step: 4
Training loss: 3.117988808494973
Validation loss: 3.0387860197778083

Epoch: 6| Step: 5
Training loss: 2.652297186688572
Validation loss: 3.0377697802765824

Epoch: 6| Step: 6
Training loss: 3.449045386445181
Validation loss: 3.0414599894724224

Epoch: 6| Step: 7
Training loss: 2.800124513037444
Validation loss: 3.0332654505475203

Epoch: 6| Step: 8
Training loss: 3.788023879075641
Validation loss: 3.028315165439352

Epoch: 6| Step: 9
Training loss: 3.91083861350589
Validation loss: 3.0295336047892776

Epoch: 6| Step: 10
Training loss: 2.613721231733709
Validation loss: 3.027940310614964

Epoch: 6| Step: 11
Training loss: 3.2540460490114325
Validation loss: 3.0302736134700066

Epoch: 6| Step: 12
Training loss: 3.0358832432507
Validation loss: 3.029339488404343

Epoch: 6| Step: 13
Training loss: 4.069594541406467
Validation loss: 3.0270520204997844

Epoch: 34| Step: 0
Training loss: 3.032771092662333
Validation loss: 3.026610781259065

Epoch: 6| Step: 1
Training loss: 3.1778181049778786
Validation loss: 3.024478367837022

Epoch: 6| Step: 2
Training loss: 3.85402515598356
Validation loss: 3.02553212231427

Epoch: 6| Step: 3
Training loss: 3.297110743478408
Validation loss: 3.0225750279474792

Epoch: 6| Step: 4
Training loss: 3.03403022921043
Validation loss: 3.0237529174946345

Epoch: 6| Step: 5
Training loss: 3.4428320019430974
Validation loss: 3.023771149262749

Epoch: 6| Step: 6
Training loss: 3.6992347338289844
Validation loss: 3.0271124011931447

Epoch: 6| Step: 7
Training loss: 2.984744543393764
Validation loss: 3.023904164760222

Epoch: 6| Step: 8
Training loss: 3.2848099062190976
Validation loss: 3.027879782175802

Epoch: 6| Step: 9
Training loss: 3.306015144761157
Validation loss: 3.0221830606587496

Epoch: 6| Step: 10
Training loss: 3.017124732069383
Validation loss: 3.0195260590908752

Epoch: 6| Step: 11
Training loss: 3.9655431572154503
Validation loss: 3.020562073972285

Epoch: 6| Step: 12
Training loss: 2.8194102696026815
Validation loss: 3.0182933093266793

Epoch: 6| Step: 13
Training loss: 2.9647782912837317
Validation loss: 3.0173795249293995

Epoch: 35| Step: 0
Training loss: 3.8815660529215985
Validation loss: 3.0178007735118273

Epoch: 6| Step: 1
Training loss: 3.329493711319825
Validation loss: 3.017075270824704

Epoch: 6| Step: 2
Training loss: 3.5508935153113335
Validation loss: 3.017474666119744

Epoch: 6| Step: 3
Training loss: 2.8949170389625305
Validation loss: 3.0157374754702047

Epoch: 6| Step: 4
Training loss: 3.1583622577990096
Validation loss: 3.0166684716730923

Epoch: 6| Step: 5
Training loss: 3.3760442178008976
Validation loss: 3.014354622065797

Epoch: 6| Step: 6
Training loss: 3.4994890657513813
Validation loss: 3.0158473047711842

Epoch: 6| Step: 7
Training loss: 2.972308465611551
Validation loss: 3.0131275024358746

Epoch: 6| Step: 8
Training loss: 2.7345057864927447
Validation loss: 3.013943638241366

Epoch: 6| Step: 9
Training loss: 3.5018813662562187
Validation loss: 3.0145364435583604

Epoch: 6| Step: 10
Training loss: 3.4173252742502136
Validation loss: 3.0152657003798136

Epoch: 6| Step: 11
Training loss: 2.858339716363866
Validation loss: 3.013669231116087

Epoch: 6| Step: 12
Training loss: 3.4650843041142796
Validation loss: 3.0166278412606524

Epoch: 6| Step: 13
Training loss: 3.218328800234441
Validation loss: 3.0130275766268486

Epoch: 36| Step: 0
Training loss: 3.043080789366722
Validation loss: 3.0143809986580616

Epoch: 6| Step: 1
Training loss: 3.6686163544885555
Validation loss: 3.013744876924742

Epoch: 6| Step: 2
Training loss: 2.8807039484025925
Validation loss: 3.0095436580931865

Epoch: 6| Step: 3
Training loss: 4.205135275970202
Validation loss: 3.0092786688994213

Epoch: 6| Step: 4
Training loss: 2.817855652479461
Validation loss: 3.010394931741292

Epoch: 6| Step: 5
Training loss: 3.0229810424371784
Validation loss: 3.009961470471575

Epoch: 6| Step: 6
Training loss: 3.004257042769197
Validation loss: 3.008915744425816

Epoch: 6| Step: 7
Training loss: 2.3463447957305124
Validation loss: 3.0097480536992296

Epoch: 6| Step: 8
Training loss: 3.1681787160209174
Validation loss: 3.0084893728454163

Epoch: 6| Step: 9
Training loss: 2.619191782975867
Validation loss: 3.008217225947326

Epoch: 6| Step: 10
Training loss: 3.900299667191802
Validation loss: 3.0091709018044908

Epoch: 6| Step: 11
Training loss: 4.315708459576092
Validation loss: 3.0193648410065603

Epoch: 6| Step: 12
Training loss: 3.0610285746883505
Validation loss: 3.0046277167326365

Epoch: 6| Step: 13
Training loss: 3.2765328059854264
Validation loss: 3.0045610931805813

Epoch: 37| Step: 0
Training loss: 2.667926391444032
Validation loss: 3.005700537051176

Epoch: 6| Step: 1
Training loss: 3.7568721110082626
Validation loss: 3.0035416487045596

Epoch: 6| Step: 2
Training loss: 2.8384900756253892
Validation loss: 3.003503599391618

Epoch: 6| Step: 3
Training loss: 3.1550314788940694
Validation loss: 3.004138133166798

Epoch: 6| Step: 4
Training loss: 2.8281563604312705
Validation loss: 3.0023679360816447

Epoch: 6| Step: 5
Training loss: 3.733387836557994
Validation loss: 3.0027756788163926

Epoch: 6| Step: 6
Training loss: 3.670056481199617
Validation loss: 3.0017099617401577

Epoch: 6| Step: 7
Training loss: 3.2977059569111176
Validation loss: 3.0000234640564294

Epoch: 6| Step: 8
Training loss: 2.846328907418562
Validation loss: 3.000322389542005

Epoch: 6| Step: 9
Training loss: 3.4982668809060216
Validation loss: 2.9981976396531707

Epoch: 6| Step: 10
Training loss: 3.424123643567859
Validation loss: 3.0002043152011995

Epoch: 6| Step: 11
Training loss: 3.677109902837938
Validation loss: 3.0014166307237233

Epoch: 6| Step: 12
Training loss: 3.400490186921959
Validation loss: 3.0035977222945958

Epoch: 6| Step: 13
Training loss: 2.3801452717402363
Validation loss: 3.0123189054158814

Epoch: 38| Step: 0
Training loss: 2.6784739957981656
Validation loss: 3.0486191386555213

Epoch: 6| Step: 1
Training loss: 2.862253876478809
Validation loss: 3.0429058009203236

Epoch: 6| Step: 2
Training loss: 3.4052683964509574
Validation loss: 3.0176948637084773

Epoch: 6| Step: 3
Training loss: 3.1573235225213616
Validation loss: 2.9981178999176996

Epoch: 6| Step: 4
Training loss: 3.581730654218728
Validation loss: 3.0010869285819437

Epoch: 6| Step: 5
Training loss: 2.998105881697418
Validation loss: 3.007934448514546

Epoch: 6| Step: 6
Training loss: 2.938084321039657
Validation loss: 3.014190331709927

Epoch: 6| Step: 7
Training loss: 3.542355519042522
Validation loss: 3.0076939031400185

Epoch: 6| Step: 8
Training loss: 3.4001216530072895
Validation loss: 3.0108952199214767

Epoch: 6| Step: 9
Training loss: 3.0501034578380493
Validation loss: 3.0068652754638077

Epoch: 6| Step: 10
Training loss: 3.4493417858329383
Validation loss: 3.0039672819759335

Epoch: 6| Step: 11
Training loss: 3.203926693214619
Validation loss: 3.001795357992344

Epoch: 6| Step: 12
Training loss: 3.728343737853028
Validation loss: 2.99804134247469

Epoch: 6| Step: 13
Training loss: 4.319726831841731
Validation loss: 2.9975575943985318

Epoch: 39| Step: 0
Training loss: 2.290017719616695
Validation loss: 2.996276620570722

Epoch: 6| Step: 1
Training loss: 3.0930467827481296
Validation loss: 2.9966671043929596

Epoch: 6| Step: 2
Training loss: 3.53987297562974
Validation loss: 2.997754958352365

Epoch: 6| Step: 3
Training loss: 4.302076264284005
Validation loss: 3.0004415238452267

Epoch: 6| Step: 4
Training loss: 2.583733209814727
Validation loss: 2.9996124362472294

Epoch: 6| Step: 5
Training loss: 3.524575601555674
Validation loss: 2.9994083243220326

Epoch: 6| Step: 6
Training loss: 3.3257761802213532
Validation loss: 2.999571188493505

Epoch: 6| Step: 7
Training loss: 3.619301361615444
Validation loss: 2.998223092988699

Epoch: 6| Step: 8
Training loss: 3.0678149443895766
Validation loss: 2.992192405907215

Epoch: 6| Step: 9
Training loss: 3.050515215773401
Validation loss: 2.989086587637711

Epoch: 6| Step: 10
Training loss: 3.4232963501574
Validation loss: 2.9900245891106922

Epoch: 6| Step: 11
Training loss: 3.305446672827922
Validation loss: 2.988912307215324

Epoch: 6| Step: 12
Training loss: 2.997077790241975
Validation loss: 2.9889177948830916

Epoch: 6| Step: 13
Training loss: 3.2651155065227107
Validation loss: 2.9904844585202586

Epoch: 40| Step: 0
Training loss: 3.9493184817556704
Validation loss: 2.9898105149275986

Epoch: 6| Step: 1
Training loss: 3.2886965586584056
Validation loss: 2.991590055271472

Epoch: 6| Step: 2
Training loss: 2.4943253008910125
Validation loss: 2.9934397926513325

Epoch: 6| Step: 3
Training loss: 3.320843248021455
Validation loss: 2.9925219640389145

Epoch: 6| Step: 4
Training loss: 2.3426590478534743
Validation loss: 2.989303262466109

Epoch: 6| Step: 5
Training loss: 3.7112363674880924
Validation loss: 2.9930361245795303

Epoch: 6| Step: 6
Training loss: 2.9762167742339343
Validation loss: 2.9879167274782383

Epoch: 6| Step: 7
Training loss: 3.4140837295535595
Validation loss: 2.9858449725897853

Epoch: 6| Step: 8
Training loss: 3.24964095846722
Validation loss: 2.98305950776876

Epoch: 6| Step: 9
Training loss: 3.1465580254997545
Validation loss: 2.9835747524943024

Epoch: 6| Step: 10
Training loss: 3.3701225641075627
Validation loss: 2.983403388794771

Epoch: 6| Step: 11
Training loss: 3.957267912314503
Validation loss: 2.9803984803395687

Epoch: 6| Step: 12
Training loss: 2.8380850235056334
Validation loss: 2.9836867830190683

Epoch: 6| Step: 13
Training loss: 3.1918841859749936
Validation loss: 2.984858995004175

Epoch: 41| Step: 0
Training loss: 3.3858747123526327
Validation loss: 2.988769395295372

Epoch: 6| Step: 1
Training loss: 2.1726244175515497
Validation loss: 3.0505700746470072

Epoch: 6| Step: 2
Training loss: 3.4139133307300478
Validation loss: 3.035314149579669

Epoch: 6| Step: 3
Training loss: 2.7904337442608487
Validation loss: 3.0005430837483775

Epoch: 6| Step: 4
Training loss: 3.4089681996311127
Validation loss: 3.000185806919226

Epoch: 6| Step: 5
Training loss: 2.7403389549827226
Validation loss: 2.993131517091718

Epoch: 6| Step: 6
Training loss: 3.630156959524099
Validation loss: 2.982833262201393

Epoch: 6| Step: 7
Training loss: 3.6036044143448165
Validation loss: 2.9782078877689404

Epoch: 6| Step: 8
Training loss: 2.7922734602220025
Validation loss: 2.9820799457468605

Epoch: 6| Step: 9
Training loss: 3.179385459107311
Validation loss: 2.990218325595348

Epoch: 6| Step: 10
Training loss: 3.767698737903822
Validation loss: 3.008887062064121

Epoch: 6| Step: 11
Training loss: 3.9799116678835063
Validation loss: 2.992705127392012

Epoch: 6| Step: 12
Training loss: 2.970918846950555
Validation loss: 2.9841587130228637

Epoch: 6| Step: 13
Training loss: 3.6101068192420414
Validation loss: 2.981538257304429

Epoch: 42| Step: 0
Training loss: 3.6181599770135504
Validation loss: 2.9814069416349027

Epoch: 6| Step: 1
Training loss: 3.3589934376331403
Validation loss: 2.982963803475875

Epoch: 6| Step: 2
Training loss: 3.1359585687664198
Validation loss: 2.9814949950888834

Epoch: 6| Step: 3
Training loss: 3.14598150514864
Validation loss: 2.979164715287315

Epoch: 6| Step: 4
Training loss: 3.557601773702198
Validation loss: 2.975545018370764

Epoch: 6| Step: 5
Training loss: 2.9981518456786165
Validation loss: 2.973345442292513

Epoch: 6| Step: 6
Training loss: 3.594389220070142
Validation loss: 2.9751590487013155

Epoch: 6| Step: 7
Training loss: 3.0952924486075992
Validation loss: 2.974731734960009

Epoch: 6| Step: 8
Training loss: 3.1035472755426685
Validation loss: 2.9756372118363683

Epoch: 6| Step: 9
Training loss: 3.107187392944469
Validation loss: 2.980300737952394

Epoch: 6| Step: 10
Training loss: 2.805361186010131
Validation loss: 2.9772578867559734

Epoch: 6| Step: 11
Training loss: 2.6831927714840194
Validation loss: 2.9822953493611184

Epoch: 6| Step: 12
Training loss: 3.891675079685133
Validation loss: 2.9797535622332476

Epoch: 6| Step: 13
Training loss: 3.4034513122653802
Validation loss: 2.9741717705683275

Epoch: 43| Step: 0
Training loss: 3.2022900493332256
Validation loss: 2.9717589470201236

Epoch: 6| Step: 1
Training loss: 3.6841407604352194
Validation loss: 2.9676565318617314

Epoch: 6| Step: 2
Training loss: 3.57535175647028
Validation loss: 2.9667513498477227

Epoch: 6| Step: 3
Training loss: 3.0266833957204193
Validation loss: 2.966956247278916

Epoch: 6| Step: 4
Training loss: 2.703710062734634
Validation loss: 2.967602179002198

Epoch: 6| Step: 5
Training loss: 3.2007884365575596
Validation loss: 2.9670900238647047

Epoch: 6| Step: 6
Training loss: 2.6364094870714805
Validation loss: 2.966902999709688

Epoch: 6| Step: 7
Training loss: 2.9337289832345306
Validation loss: 2.968137655268707

Epoch: 6| Step: 8
Training loss: 3.1626380257019946
Validation loss: 2.968571847644647

Epoch: 6| Step: 9
Training loss: 3.5108129502169625
Validation loss: 2.9675031391364284

Epoch: 6| Step: 10
Training loss: 3.1411215925707117
Validation loss: 2.9655493718941095

Epoch: 6| Step: 11
Training loss: 4.159009433332982
Validation loss: 2.9664842397296267

Epoch: 6| Step: 12
Training loss: 2.9497613066750707
Validation loss: 2.9652832584001123

Epoch: 6| Step: 13
Training loss: 3.4317806868827336
Validation loss: 2.9654332257948797

Epoch: 44| Step: 0
Training loss: 2.8611879698502714
Validation loss: 2.964803066534144

Epoch: 6| Step: 1
Training loss: 3.7100399819247865
Validation loss: 2.9635843556164723

Epoch: 6| Step: 2
Training loss: 2.563666287621997
Validation loss: 2.9610363923756533

Epoch: 6| Step: 3
Training loss: 3.1977856305806287
Validation loss: 2.9610714220993133

Epoch: 6| Step: 4
Training loss: 3.339991516056821
Validation loss: 2.9604607113607964

Epoch: 6| Step: 5
Training loss: 3.4787402929183617
Validation loss: 2.959574298012734

Epoch: 6| Step: 6
Training loss: 3.489835010771252
Validation loss: 2.961652155573593

Epoch: 6| Step: 7
Training loss: 3.615605513009959
Validation loss: 2.9594884024518047

Epoch: 6| Step: 8
Training loss: 3.6225769889869417
Validation loss: 2.958006287146124

Epoch: 6| Step: 9
Training loss: 2.9337637657749513
Validation loss: 2.958310761655195

Epoch: 6| Step: 10
Training loss: 3.373420345656795
Validation loss: 2.9582687213733507

Epoch: 6| Step: 11
Training loss: 3.061175001354221
Validation loss: 2.9576920006696428

Epoch: 6| Step: 12
Training loss: 3.302459903909683
Validation loss: 2.96307910156915

Epoch: 6| Step: 13
Training loss: 1.982707486930245
Validation loss: 2.9833594850801046

Epoch: 45| Step: 0
Training loss: 3.5282490900211894
Validation loss: 3.052661131429971

Epoch: 6| Step: 1
Training loss: 2.600138781584975
Validation loss: 3.04772017846263

Epoch: 6| Step: 2
Training loss: 3.532511392994817
Validation loss: 3.0650262498199083

Epoch: 6| Step: 3
Training loss: 2.8989438337008444
Validation loss: 3.044585211847583

Epoch: 6| Step: 4
Training loss: 3.6510938494658585
Validation loss: 3.0276341490935956

Epoch: 6| Step: 5
Training loss: 3.152228635744761
Validation loss: 3.021214982062417

Epoch: 6| Step: 6
Training loss: 4.27396279406921
Validation loss: 3.0194497668099105

Epoch: 6| Step: 7
Training loss: 3.533141043366967
Validation loss: 3.017197490712198

Epoch: 6| Step: 8
Training loss: 3.1230488598824993
Validation loss: 3.0177156942610233

Epoch: 6| Step: 9
Training loss: 3.024083110474581
Validation loss: 3.0177283267487467

Epoch: 6| Step: 10
Training loss: 2.8317135126176702
Validation loss: 3.0163690421784706

Epoch: 6| Step: 11
Training loss: 3.243788431928519
Validation loss: 3.0147465986468687

Epoch: 6| Step: 12
Training loss: 3.381288110091665
Validation loss: 3.012429089980272

Epoch: 6| Step: 13
Training loss: 2.7983848715923414
Validation loss: 3.0120389311239495

Epoch: 46| Step: 0
Training loss: 3.836258449451915
Validation loss: 3.012964716724728

Epoch: 6| Step: 1
Training loss: 3.3026383632463046
Validation loss: 3.01020225365683

Epoch: 6| Step: 2
Training loss: 3.0258218200627045
Validation loss: 3.010251967499992

Epoch: 6| Step: 3
Training loss: 3.437115873202105
Validation loss: 3.008856308992947

Epoch: 6| Step: 4
Training loss: 2.5070315657318574
Validation loss: 3.01037356426728

Epoch: 6| Step: 5
Training loss: 3.747847638741171
Validation loss: 3.01230171411236

Epoch: 6| Step: 6
Training loss: 3.3241008374541643
Validation loss: 3.0141260679975885

Epoch: 6| Step: 7
Training loss: 2.432782327199041
Validation loss: 3.0185767554767873

Epoch: 6| Step: 8
Training loss: 2.8000126293442507
Validation loss: 3.011488662770003

Epoch: 6| Step: 9
Training loss: 3.360894573652241
Validation loss: 3.0135254549515476

Epoch: 6| Step: 10
Training loss: 3.875458474877899
Validation loss: 3.007664228901802

Epoch: 6| Step: 11
Training loss: 3.333399787876184
Validation loss: 2.9988302014705885

Epoch: 6| Step: 12
Training loss: 3.4755770197360305
Validation loss: 2.9805890477026726

Epoch: 6| Step: 13
Training loss: 2.992912184803835
Validation loss: 2.9592389291052097

Epoch: 47| Step: 0
Training loss: 3.3337766988262305
Validation loss: 2.9518169547385007

Epoch: 6| Step: 1
Training loss: 3.0217867344270632
Validation loss: 2.9511633497067935

Epoch: 6| Step: 2
Training loss: 3.0920868073155074
Validation loss: 2.9554212282478676

Epoch: 6| Step: 3
Training loss: 3.6938660837383215
Validation loss: 2.954077266795586

Epoch: 6| Step: 4
Training loss: 3.4301598990401887
Validation loss: 2.954175793508284

Epoch: 6| Step: 5
Training loss: 3.1277212882789476
Validation loss: 2.9517610699785664

Epoch: 6| Step: 6
Training loss: 2.8256120845750106
Validation loss: 2.951501583591486

Epoch: 6| Step: 7
Training loss: 3.023661602694631
Validation loss: 2.9491779327012813

Epoch: 6| Step: 8
Training loss: 2.9831112088105027
Validation loss: 2.946800543010049

Epoch: 6| Step: 9
Training loss: 3.504861316630933
Validation loss: 2.9447688624858164

Epoch: 6| Step: 10
Training loss: 3.193610374548885
Validation loss: 2.9431734264031286

Epoch: 6| Step: 11
Training loss: 3.2104037321516254
Validation loss: 2.9421882334576304

Epoch: 6| Step: 12
Training loss: 3.714498445685895
Validation loss: 2.941636596858794

Epoch: 6| Step: 13
Training loss: 2.946549780528213
Validation loss: 2.941636136705979

Epoch: 48| Step: 0
Training loss: 3.18895508708171
Validation loss: 2.9411492459800357

Epoch: 6| Step: 1
Training loss: 3.090420250817056
Validation loss: 2.9418378144385824

Epoch: 6| Step: 2
Training loss: 3.046701905640106
Validation loss: 2.947829635960499

Epoch: 6| Step: 3
Training loss: 3.5538694006216387
Validation loss: 2.9572197619182474

Epoch: 6| Step: 4
Training loss: 2.552996060910382
Validation loss: 2.954969257468067

Epoch: 6| Step: 5
Training loss: 2.881854965679725
Validation loss: 2.947189833389586

Epoch: 6| Step: 6
Training loss: 3.8219934053708466
Validation loss: 2.9481458059984056

Epoch: 6| Step: 7
Training loss: 3.336248521800909
Validation loss: 2.9441836616278216

Epoch: 6| Step: 8
Training loss: 3.118871707108651
Validation loss: 2.9482491121442207

Epoch: 6| Step: 9
Training loss: 3.293942996311815
Validation loss: 2.944710914736801

Epoch: 6| Step: 10
Training loss: 3.3100190858780487
Validation loss: 2.9387822316690206

Epoch: 6| Step: 11
Training loss: 2.9082834656674725
Validation loss: 2.9379432281001256

Epoch: 6| Step: 12
Training loss: 3.301918835960021
Validation loss: 2.935584606089489

Epoch: 6| Step: 13
Training loss: 3.9339732770220657
Validation loss: 2.9364751216142517

Epoch: 49| Step: 0
Training loss: 3.7784539596177655
Validation loss: 2.936780289397131

Epoch: 6| Step: 1
Training loss: 3.567446035873853
Validation loss: 2.9361626943841195

Epoch: 6| Step: 2
Training loss: 2.522132654275532
Validation loss: 2.9360742436194793

Epoch: 6| Step: 3
Training loss: 3.515283729095693
Validation loss: 2.9346532281993563

Epoch: 6| Step: 4
Training loss: 3.4991988218761634
Validation loss: 2.936298539203977

Epoch: 6| Step: 5
Training loss: 3.551121257957929
Validation loss: 2.9351244842470665

Epoch: 6| Step: 6
Training loss: 3.1482327302361983
Validation loss: 2.9343990067697066

Epoch: 6| Step: 7
Training loss: 2.8487531645063875
Validation loss: 2.9322596200911137

Epoch: 6| Step: 8
Training loss: 2.565611648060187
Validation loss: 2.9352350625366688

Epoch: 6| Step: 9
Training loss: 3.4012548935759312
Validation loss: 2.9338487105483777

Epoch: 6| Step: 10
Training loss: 3.5006141123834773
Validation loss: 2.939254062496826

Epoch: 6| Step: 11
Training loss: 2.913040759266668
Validation loss: 2.9401179882948942

Epoch: 6| Step: 12
Training loss: 3.125050963939897
Validation loss: 2.942397232156196

Epoch: 6| Step: 13
Training loss: 2.5963258936244005
Validation loss: 2.943278241906001

Epoch: 50| Step: 0
Training loss: 3.535632224733882
Validation loss: 2.9517410559145265

Epoch: 6| Step: 1
Training loss: 3.467219521992238
Validation loss: 2.9584488511802998

Epoch: 6| Step: 2
Training loss: 3.0923045471152055
Validation loss: 2.956880694342389

Epoch: 6| Step: 3
Training loss: 3.6941171531419648
Validation loss: 2.9520013393235986

Epoch: 6| Step: 4
Training loss: 4.180506317648547
Validation loss: 2.9468960585465016

Epoch: 6| Step: 5
Training loss: 2.665833899484113
Validation loss: 2.9383281970659025

Epoch: 6| Step: 6
Training loss: 3.1829894820509037
Validation loss: 2.934585905345038

Epoch: 6| Step: 7
Training loss: 2.745477425447191
Validation loss: 2.9384065554409022

Epoch: 6| Step: 8
Training loss: 2.640520172747091
Validation loss: 2.9372316236567326

Epoch: 6| Step: 9
Training loss: 2.8917300199958023
Validation loss: 2.9249436541945433

Epoch: 6| Step: 10
Training loss: 3.562840763324902
Validation loss: 2.9261640534887707

Epoch: 6| Step: 11
Training loss: 3.1352173666910828
Validation loss: 2.9255804677026007

Epoch: 6| Step: 12
Training loss: 2.879987619691306
Validation loss: 2.926767517809754

Epoch: 6| Step: 13
Training loss: 3.004126730418434
Validation loss: 2.9269716249310864

Epoch: 51| Step: 0
Training loss: 2.4585846810163012
Validation loss: 2.927274223417652

Epoch: 6| Step: 1
Training loss: 3.6850003320908624
Validation loss: 2.926304011290474

Epoch: 6| Step: 2
Training loss: 1.8194911560908713
Validation loss: 2.9255146264541887

Epoch: 6| Step: 3
Training loss: 3.5715151040629527
Validation loss: 2.9260183633364028

Epoch: 6| Step: 4
Training loss: 3.0401107431619128
Validation loss: 2.926554871305078

Epoch: 6| Step: 5
Training loss: 3.3441790724358746
Validation loss: 2.9268481407110234

Epoch: 6| Step: 6
Training loss: 3.7727620090836713
Validation loss: 2.925652991608896

Epoch: 6| Step: 7
Training loss: 3.509925664565614
Validation loss: 2.9256080854288715

Epoch: 6| Step: 8
Training loss: 3.135586012684764
Validation loss: 2.927208618196764

Epoch: 6| Step: 9
Training loss: 3.3322323093372574
Validation loss: 2.932098629447401

Epoch: 6| Step: 10
Training loss: 2.739994922271256
Validation loss: 2.949262899432215

Epoch: 6| Step: 11
Training loss: 3.060849581941106
Validation loss: 2.9497451943667845

Epoch: 6| Step: 12
Training loss: 3.484019308367372
Validation loss: 2.9403082236724165

Epoch: 6| Step: 13
Training loss: 3.7924522731848276
Validation loss: 2.9264997252945215

Epoch: 52| Step: 0
Training loss: 2.868422904720841
Validation loss: 2.922193159709083

Epoch: 6| Step: 1
Training loss: 3.2847903089790074
Validation loss: 2.9215323954885473

Epoch: 6| Step: 2
Training loss: 3.3763532398063996
Validation loss: 2.927007805060736

Epoch: 6| Step: 3
Training loss: 2.9168708911422976
Validation loss: 2.9321137641718695

Epoch: 6| Step: 4
Training loss: 2.9580872840822368
Validation loss: 2.9357882355653024

Epoch: 6| Step: 5
Training loss: 3.152198230357932
Validation loss: 2.929815979905685

Epoch: 6| Step: 6
Training loss: 3.3265549085825192
Validation loss: 2.9221613819685515

Epoch: 6| Step: 7
Training loss: 3.4018942605012503
Validation loss: 2.920400071215803

Epoch: 6| Step: 8
Training loss: 3.3705221069407725
Validation loss: 2.9195968690144896

Epoch: 6| Step: 9
Training loss: 3.496232184540983
Validation loss: 2.9192966335157253

Epoch: 6| Step: 10
Training loss: 2.914547141020616
Validation loss: 2.916187792607618

Epoch: 6| Step: 11
Training loss: 3.1810457295186083
Validation loss: 2.915879976442247

Epoch: 6| Step: 12
Training loss: 3.6484338405027152
Validation loss: 2.916019510879061

Epoch: 6| Step: 13
Training loss: 2.8298021264875115
Validation loss: 2.9186357212340357

Epoch: 53| Step: 0
Training loss: 3.80106351927503
Validation loss: 2.916983019172003

Epoch: 6| Step: 1
Training loss: 3.6774377120789827
Validation loss: 2.919963066141698

Epoch: 6| Step: 2
Training loss: 3.0711516575483713
Validation loss: 2.920539221159302

Epoch: 6| Step: 3
Training loss: 3.137425857215033
Validation loss: 2.9174795254467982

Epoch: 6| Step: 4
Training loss: 2.62111667219392
Validation loss: 2.9154078941801393

Epoch: 6| Step: 5
Training loss: 3.508266631977587
Validation loss: 2.9136441198839513

Epoch: 6| Step: 6
Training loss: 2.5897374196038365
Validation loss: 2.9145876956546917

Epoch: 6| Step: 7
Training loss: 3.41067651229861
Validation loss: 2.9107350684119058

Epoch: 6| Step: 8
Training loss: 2.870663565242289
Validation loss: 2.9117246233760765

Epoch: 6| Step: 9
Training loss: 3.4552956227472307
Validation loss: 2.9119383396652

Epoch: 6| Step: 10
Training loss: 3.1605409970321374
Validation loss: 2.9100805085125985

Epoch: 6| Step: 11
Training loss: 3.4465105737379793
Validation loss: 2.909680876935478

Epoch: 6| Step: 12
Training loss: 2.4720107165477763
Validation loss: 2.9113602359850983

Epoch: 6| Step: 13
Training loss: 3.5080416802047423
Validation loss: 2.908926514762781

Epoch: 54| Step: 0
Training loss: 3.6541689957916135
Validation loss: 2.9105043088454807

Epoch: 6| Step: 1
Training loss: 2.7916201877046065
Validation loss: 2.9103531150853614

Epoch: 6| Step: 2
Training loss: 3.942436756504856
Validation loss: 2.9073207769041245

Epoch: 6| Step: 3
Training loss: 3.5825594280715096
Validation loss: 2.908145108031956

Epoch: 6| Step: 4
Training loss: 3.193464495593953
Validation loss: 2.907308348075396

Epoch: 6| Step: 5
Training loss: 3.4124970153124825
Validation loss: 2.9069447784593225

Epoch: 6| Step: 6
Training loss: 2.6566978525830582
Validation loss: 2.907516010561892

Epoch: 6| Step: 7
Training loss: 1.90639020060279
Validation loss: 2.9034847318387214

Epoch: 6| Step: 8
Training loss: 3.1654992879777275
Validation loss: 2.9062451219115313

Epoch: 6| Step: 9
Training loss: 3.169151301808559
Validation loss: 2.9048010629859533

Epoch: 6| Step: 10
Training loss: 3.3635405508074774
Validation loss: 2.9056328056278833

Epoch: 6| Step: 11
Training loss: 2.5944760696621976
Validation loss: 2.902715168958591

Epoch: 6| Step: 12
Training loss: 3.64714729972664
Validation loss: 2.9027496121685363

Epoch: 6| Step: 13
Training loss: 3.2047650860229675
Validation loss: 2.903447758828223

Epoch: 55| Step: 0
Training loss: 3.455263054159191
Validation loss: 2.9061690579567347

Epoch: 6| Step: 1
Training loss: 3.2658405141580347
Validation loss: 2.9180989301266287

Epoch: 6| Step: 2
Training loss: 3.385767397196671
Validation loss: 2.923407908341866

Epoch: 6| Step: 3
Training loss: 3.51622444976192
Validation loss: 2.9338764252037697

Epoch: 6| Step: 4
Training loss: 3.4233821528394817
Validation loss: 2.9234685425521456

Epoch: 6| Step: 5
Training loss: 2.993979612078463
Validation loss: 2.9198407763758416

Epoch: 6| Step: 6
Training loss: 2.943925039995632
Validation loss: 2.9166325568623237

Epoch: 6| Step: 7
Training loss: 2.5712965730817485
Validation loss: 2.9069550393718693

Epoch: 6| Step: 8
Training loss: 3.5076300694662246
Validation loss: 2.903339358812902

Epoch: 6| Step: 9
Training loss: 2.839646617233666
Validation loss: 2.905332267140095

Epoch: 6| Step: 10
Training loss: 2.6000585476078744
Validation loss: 2.9004904556813016

Epoch: 6| Step: 11
Training loss: 3.575600612312501
Validation loss: 2.899296803803343

Epoch: 6| Step: 12
Training loss: 3.1316294731406935
Validation loss: 2.8990516977035607

Epoch: 6| Step: 13
Training loss: 3.376178959392515
Validation loss: 2.8991926601621403

Epoch: 56| Step: 0
Training loss: 2.6810860501473424
Validation loss: 2.8996810180373345

Epoch: 6| Step: 1
Training loss: 3.438781222080719
Validation loss: 2.8975483771914057

Epoch: 6| Step: 2
Training loss: 3.54872600637335
Validation loss: 2.8989027524613493

Epoch: 6| Step: 3
Training loss: 2.697871754001216
Validation loss: 2.896061907216811

Epoch: 6| Step: 4
Training loss: 2.752108372572702
Validation loss: 2.897842783593654

Epoch: 6| Step: 5
Training loss: 3.074607737262936
Validation loss: 2.897283353200499

Epoch: 6| Step: 6
Training loss: 3.596306331168147
Validation loss: 2.8977773383520193

Epoch: 6| Step: 7
Training loss: 3.6656945991900702
Validation loss: 2.8955413878943075

Epoch: 6| Step: 8
Training loss: 3.482400925124519
Validation loss: 2.8979977138447452

Epoch: 6| Step: 9
Training loss: 3.474202999133328
Validation loss: 2.897361281152481

Epoch: 6| Step: 10
Training loss: 3.3389667274117447
Validation loss: 2.8962938918208305

Epoch: 6| Step: 11
Training loss: 2.6621557666881253
Validation loss: 2.895771532040346

Epoch: 6| Step: 12
Training loss: 2.469791241059467
Validation loss: 2.895276590156509

Epoch: 6| Step: 13
Training loss: 3.736297368004287
Validation loss: 2.8942679683935206

Epoch: 57| Step: 0
Training loss: 3.4846943935558383
Validation loss: 2.8947067465495597

Epoch: 6| Step: 1
Training loss: 3.7500307717650223
Validation loss: 2.892780284233512

Epoch: 6| Step: 2
Training loss: 3.475437899655287
Validation loss: 2.892901460801814

Epoch: 6| Step: 3
Training loss: 2.2574363315935915
Validation loss: 2.8915667373664604

Epoch: 6| Step: 4
Training loss: 2.7214450851414274
Validation loss: 2.891785697854851

Epoch: 6| Step: 5
Training loss: 2.8780796308389722
Validation loss: 2.8922428582324726

Epoch: 6| Step: 6
Training loss: 3.280395687240819
Validation loss: 2.8908971009345614

Epoch: 6| Step: 7
Training loss: 3.150343098196217
Validation loss: 2.8907589044128645

Epoch: 6| Step: 8
Training loss: 3.4464970150581427
Validation loss: 2.8903098668777996

Epoch: 6| Step: 9
Training loss: 2.9266406682741715
Validation loss: 2.889328007287667

Epoch: 6| Step: 10
Training loss: 2.9424348327109944
Validation loss: 2.890581845818055

Epoch: 6| Step: 11
Training loss: 3.4991685697207116
Validation loss: 2.8906551626683226

Epoch: 6| Step: 12
Training loss: 3.5105882974356017
Validation loss: 2.8911438125775106

Epoch: 6| Step: 13
Training loss: 2.8171566877409733
Validation loss: 2.891925006601298

Epoch: 58| Step: 0
Training loss: 3.2271444243888836
Validation loss: 2.890215269149274

Epoch: 6| Step: 1
Training loss: 3.1687829491822757
Validation loss: 2.8982086307979866

Epoch: 6| Step: 2
Training loss: 3.4979574510484976
Validation loss: 2.8887064909786164

Epoch: 6| Step: 3
Training loss: 4.26347011590315
Validation loss: 2.886698681071407

Epoch: 6| Step: 4
Training loss: 3.303913142967656
Validation loss: 2.8838998294836036

Epoch: 6| Step: 5
Training loss: 3.098237915074593
Validation loss: 2.8874507185135316

Epoch: 6| Step: 6
Training loss: 2.274392468164447
Validation loss: 2.8854543268016055

Epoch: 6| Step: 7
Training loss: 3.002607483984688
Validation loss: 2.8862996251770126

Epoch: 6| Step: 8
Training loss: 3.177100176323609
Validation loss: 2.8861035052647455

Epoch: 6| Step: 9
Training loss: 2.273472107299418
Validation loss: 2.8841782918425203

Epoch: 6| Step: 10
Training loss: 2.6928074792038426
Validation loss: 2.884489908752445

Epoch: 6| Step: 11
Training loss: 3.611421211491271
Validation loss: 2.885354791527704

Epoch: 6| Step: 12
Training loss: 3.606276994997533
Validation loss: 2.8830708362599853

Epoch: 6| Step: 13
Training loss: 2.527313939763335
Validation loss: 2.8828277547469208

Epoch: 59| Step: 0
Training loss: 2.9665397045385244
Validation loss: 2.883574020063045

Epoch: 6| Step: 1
Training loss: 2.7290693852992876
Validation loss: 2.882038866250622

Epoch: 6| Step: 2
Training loss: 3.338068618626815
Validation loss: 2.883279144983089

Epoch: 6| Step: 3
Training loss: 3.6520979038665256
Validation loss: 2.88680817661496

Epoch: 6| Step: 4
Training loss: 3.671817081075783
Validation loss: 2.8900511824230684

Epoch: 6| Step: 5
Training loss: 3.477186785591843
Validation loss: 2.8929499124618046

Epoch: 6| Step: 6
Training loss: 4.079067778955444
Validation loss: 2.900081735879895

Epoch: 6| Step: 7
Training loss: 1.9410693607427096
Validation loss: 2.89776094142278

Epoch: 6| Step: 8
Training loss: 3.0906377994592455
Validation loss: 2.894327155476825

Epoch: 6| Step: 9
Training loss: 3.15896459492849
Validation loss: 2.885935724742023

Epoch: 6| Step: 10
Training loss: 2.6290495381409276
Validation loss: 2.8825777104230674

Epoch: 6| Step: 11
Training loss: 2.7007141828830634
Validation loss: 2.8844220532285996

Epoch: 6| Step: 12
Training loss: 2.959958843254373
Validation loss: 2.884663104768773

Epoch: 6| Step: 13
Training loss: 3.879467880295018
Validation loss: 2.8846527672284017

Epoch: 60| Step: 0
Training loss: 3.027046513885937
Validation loss: 2.88241154973572

Epoch: 6| Step: 1
Training loss: 3.5991443782845534
Validation loss: 2.8801235193978543

Epoch: 6| Step: 2
Training loss: 2.4977980453242874
Validation loss: 2.87908513165458

Epoch: 6| Step: 3
Training loss: 2.956549702265763
Validation loss: 2.875113625441228

Epoch: 6| Step: 4
Training loss: 3.080353370806357
Validation loss: 2.8804391199101977

Epoch: 6| Step: 5
Training loss: 2.9555024764506057
Validation loss: 2.877733415870993

Epoch: 6| Step: 6
Training loss: 3.053398777567161
Validation loss: 2.8772998374752925

Epoch: 6| Step: 7
Training loss: 2.3127906204299977
Validation loss: 2.8796043353852285

Epoch: 6| Step: 8
Training loss: 3.759941909422464
Validation loss: 2.8818875063336153

Epoch: 6| Step: 9
Training loss: 3.133927829293647
Validation loss: 2.881023698711876

Epoch: 6| Step: 10
Training loss: 3.8515684425664096
Validation loss: 2.877812032672165

Epoch: 6| Step: 11
Training loss: 3.3384451452973103
Validation loss: 2.8782597796610605

Epoch: 6| Step: 12
Training loss: 3.035373046673292
Validation loss: 2.8800019333774816

Epoch: 6| Step: 13
Training loss: 3.7284671546499135
Validation loss: 2.8809695115961325

Epoch: 61| Step: 0
Training loss: 2.5722279933299865
Validation loss: 2.879675294794604

Epoch: 6| Step: 1
Training loss: 3.106082879527233
Validation loss: 2.8772774602158586

Epoch: 6| Step: 2
Training loss: 2.9455533928345385
Validation loss: 2.884821835395835

Epoch: 6| Step: 3
Training loss: 3.3974833935913513
Validation loss: 2.88178563186749

Epoch: 6| Step: 4
Training loss: 3.510628230721792
Validation loss: 2.8778381516825378

Epoch: 6| Step: 5
Training loss: 3.4946999611266114
Validation loss: 2.8754973701387723

Epoch: 6| Step: 6
Training loss: 3.1500598901777317
Validation loss: 2.8754192437181225

Epoch: 6| Step: 7
Training loss: 2.7646073877648316
Validation loss: 2.8752792262038027

Epoch: 6| Step: 8
Training loss: 3.18929494546138
Validation loss: 2.8793444291465176

Epoch: 6| Step: 9
Training loss: 2.9330660857212214
Validation loss: 2.8714763213189385

Epoch: 6| Step: 10
Training loss: 2.852290815595162
Validation loss: 2.8687987162561037

Epoch: 6| Step: 11
Training loss: 3.8582099669626486
Validation loss: 2.869244727374484

Epoch: 6| Step: 12
Training loss: 3.126078000101681
Validation loss: 2.8666686944699205

Epoch: 6| Step: 13
Training loss: 3.3568643813887715
Validation loss: 2.8654801227766957

Epoch: 62| Step: 0
Training loss: 3.560008599988858
Validation loss: 2.8687180544156976

Epoch: 6| Step: 1
Training loss: 3.8920882204334997
Validation loss: 2.865506815834216

Epoch: 6| Step: 2
Training loss: 2.063044851757656
Validation loss: 2.8664083746394824

Epoch: 6| Step: 3
Training loss: 3.23660348976568
Validation loss: 2.8665346010994015

Epoch: 6| Step: 4
Training loss: 2.8632337870703792
Validation loss: 2.866943181763142

Epoch: 6| Step: 5
Training loss: 2.646222383826251
Validation loss: 2.865942680180874

Epoch: 6| Step: 6
Training loss: 3.531757149526624
Validation loss: 2.864274320668858

Epoch: 6| Step: 7
Training loss: 3.1779585503095147
Validation loss: 2.8631538441446676

Epoch: 6| Step: 8
Training loss: 3.102982126502275
Validation loss: 2.862935820802282

Epoch: 6| Step: 9
Training loss: 3.203730530607114
Validation loss: 2.86457736435135

Epoch: 6| Step: 10
Training loss: 3.1008613620288537
Validation loss: 2.868011051435118

Epoch: 6| Step: 11
Training loss: 3.0670934988222283
Validation loss: 2.8716487925897627

Epoch: 6| Step: 12
Training loss: 3.0207717538454584
Validation loss: 2.8728908436971254

Epoch: 6| Step: 13
Training loss: 3.7475179723470258
Validation loss: 2.883315231863439

Epoch: 63| Step: 0
Training loss: 2.9217039660002184
Validation loss: 2.864879645779852

Epoch: 6| Step: 1
Training loss: 3.3870960628198206
Validation loss: 2.862182825520387

Epoch: 6| Step: 2
Training loss: 3.075419519851478
Validation loss: 2.8625343343622016

Epoch: 6| Step: 3
Training loss: 3.2229415119958498
Validation loss: 2.8635077235635644

Epoch: 6| Step: 4
Training loss: 3.566745971677413
Validation loss: 2.8628473185699197

Epoch: 6| Step: 5
Training loss: 3.1655856010493224
Validation loss: 2.8619140096849085

Epoch: 6| Step: 6
Training loss: 3.122662394739232
Validation loss: 2.8623095544910755

Epoch: 6| Step: 7
Training loss: 3.300118970171402
Validation loss: 2.8617082957491804

Epoch: 6| Step: 8
Training loss: 2.691461703721622
Validation loss: 2.8624992514257923

Epoch: 6| Step: 9
Training loss: 2.6276355410096266
Validation loss: 2.8603200011560794

Epoch: 6| Step: 10
Training loss: 3.183571582553192
Validation loss: 2.862266457059982

Epoch: 6| Step: 11
Training loss: 3.293236772483301
Validation loss: 2.8583313429071024

Epoch: 6| Step: 12
Training loss: 3.070083726120215
Validation loss: 2.8610887498383644

Epoch: 6| Step: 13
Training loss: 3.7787972053408474
Validation loss: 2.8583975971232363

Epoch: 64| Step: 0
Training loss: 3.161141561425953
Validation loss: 2.858389961073742

Epoch: 6| Step: 1
Training loss: 3.5400765084226413
Validation loss: 2.858113758965992

Epoch: 6| Step: 2
Training loss: 3.03644988820563
Validation loss: 2.8604811544920707

Epoch: 6| Step: 3
Training loss: 3.1849531582871666
Validation loss: 2.8581643440056546

Epoch: 6| Step: 4
Training loss: 3.2453450832650534
Validation loss: 2.8591724711570623

Epoch: 6| Step: 5
Training loss: 2.522076880636195
Validation loss: 2.860724006482441

Epoch: 6| Step: 6
Training loss: 3.592454494328807
Validation loss: 2.8690653331570637

Epoch: 6| Step: 7
Training loss: 2.895397308968534
Validation loss: 2.8781209736706876

Epoch: 6| Step: 8
Training loss: 2.4818809033882983
Validation loss: 2.875386321376014

Epoch: 6| Step: 9
Training loss: 3.125739048351393
Validation loss: 2.883735767452079

Epoch: 6| Step: 10
Training loss: 3.216791242120903
Validation loss: 2.8875558245530595

Epoch: 6| Step: 11
Training loss: 3.7586034628362603
Validation loss: 2.87254208812047

Epoch: 6| Step: 12
Training loss: 3.0554764843352475
Validation loss: 2.8666703775281226

Epoch: 6| Step: 13
Training loss: 3.226059105423298
Validation loss: 2.863862127686945

Epoch: 65| Step: 0
Training loss: 3.626157510045405
Validation loss: 2.8560686707446146

Epoch: 6| Step: 1
Training loss: 3.408114141925785
Validation loss: 2.855454103248712

Epoch: 6| Step: 2
Training loss: 3.3441347275200597
Validation loss: 2.8549583731636745

Epoch: 6| Step: 3
Training loss: 2.6481512134398906
Validation loss: 2.857232566840988

Epoch: 6| Step: 4
Training loss: 2.925848070102289
Validation loss: 2.857140943988769

Epoch: 6| Step: 5
Training loss: 3.0216688557227807
Validation loss: 2.8589595289088763

Epoch: 6| Step: 6
Training loss: 2.9306043487231235
Validation loss: 2.8579241207820907

Epoch: 6| Step: 7
Training loss: 2.753997671354884
Validation loss: 2.8576259462642803

Epoch: 6| Step: 8
Training loss: 2.8915964504661837
Validation loss: 2.8563884252158602

Epoch: 6| Step: 9
Training loss: 3.5785001199979978
Validation loss: 2.860081672816026

Epoch: 6| Step: 10
Training loss: 3.3430364685260345
Validation loss: 2.8612715749175774

Epoch: 6| Step: 11
Training loss: 3.0296691232943354
Validation loss: 2.8586450670898977

Epoch: 6| Step: 12
Training loss: 3.3064522867029496
Validation loss: 2.858287501146327

Epoch: 6| Step: 13
Training loss: 3.473654364346622
Validation loss: 2.8574667958831075

Epoch: 66| Step: 0
Training loss: 3.225605746608868
Validation loss: 2.854291500136784

Epoch: 6| Step: 1
Training loss: 3.026033927833173
Validation loss: 2.858059520504571

Epoch: 6| Step: 2
Training loss: 3.3961328167683402
Validation loss: 2.858500784035569

Epoch: 6| Step: 3
Training loss: 3.4812460223026256
Validation loss: 2.863853440953664

Epoch: 6| Step: 4
Training loss: 3.570125783633108
Validation loss: 2.8592123210267526

Epoch: 6| Step: 5
Training loss: 3.7341385132036833
Validation loss: 2.855637281890212

Epoch: 6| Step: 6
Training loss: 2.7479446706629487
Validation loss: 2.8517526565150586

Epoch: 6| Step: 7
Training loss: 2.754004856806221
Validation loss: 2.8511934638050924

Epoch: 6| Step: 8
Training loss: 3.403531590913215
Validation loss: 2.8523508800078043

Epoch: 6| Step: 9
Training loss: 2.8197352275595025
Validation loss: 2.850016318956166

Epoch: 6| Step: 10
Training loss: 3.08271176714503
Validation loss: 2.851068506677216

Epoch: 6| Step: 11
Training loss: 2.5251834840487914
Validation loss: 2.8495114971954916

Epoch: 6| Step: 12
Training loss: 2.4423295129255247
Validation loss: 2.8474246406250767

Epoch: 6| Step: 13
Training loss: 3.9349888862734055
Validation loss: 2.8467801076360546

Epoch: 67| Step: 0
Training loss: 2.919883824741627
Validation loss: 2.85061204426712

Epoch: 6| Step: 1
Training loss: 3.066009379174107
Validation loss: 2.849461017657855

Epoch: 6| Step: 2
Training loss: 3.094278926139967
Validation loss: 2.848809218868165

Epoch: 6| Step: 3
Training loss: 3.2193327441040855
Validation loss: 2.8498739001290048

Epoch: 6| Step: 4
Training loss: 2.629489601562969
Validation loss: 2.8534776990661004

Epoch: 6| Step: 5
Training loss: 2.819227860707754
Validation loss: 2.8675193580039617

Epoch: 6| Step: 6
Training loss: 3.4306055460868414
Validation loss: 2.8886310905349624

Epoch: 6| Step: 7
Training loss: 2.9208323204339885
Validation loss: 2.851364503314345

Epoch: 6| Step: 8
Training loss: 3.2912865592296607
Validation loss: 2.8487044677960225

Epoch: 6| Step: 9
Training loss: 3.9781018708209204
Validation loss: 2.847466106225861

Epoch: 6| Step: 10
Training loss: 2.9731425665768882
Validation loss: 2.8448674799751172

Epoch: 6| Step: 11
Training loss: 3.353260810426791
Validation loss: 2.8471499310738695

Epoch: 6| Step: 12
Training loss: 3.290235151797813
Validation loss: 2.8468987914402257

Epoch: 6| Step: 13
Training loss: 2.830063297925273
Validation loss: 2.8471892342872858

Epoch: 68| Step: 0
Training loss: 3.082040842329021
Validation loss: 2.8506999964748645

Epoch: 6| Step: 1
Training loss: 2.436304434984831
Validation loss: 2.8497940223279374

Epoch: 6| Step: 2
Training loss: 2.8470252322977125
Validation loss: 2.84774742721527

Epoch: 6| Step: 3
Training loss: 3.286720293650844
Validation loss: 2.8467714300150653

Epoch: 6| Step: 4
Training loss: 2.727541422612432
Validation loss: 2.841884900662169

Epoch: 6| Step: 5
Training loss: 2.905124897725865
Validation loss: 2.8428068989516553

Epoch: 6| Step: 6
Training loss: 3.9028850252583336
Validation loss: 2.842909484861809

Epoch: 6| Step: 7
Training loss: 3.4845274477055677
Validation loss: 2.840858107809468

Epoch: 6| Step: 8
Training loss: 2.992144791021894
Validation loss: 2.8419174199779564

Epoch: 6| Step: 9
Training loss: 3.139124725469382
Validation loss: 2.8398569037945314

Epoch: 6| Step: 10
Training loss: 3.391142493630926
Validation loss: 2.8449433896897984

Epoch: 6| Step: 11
Training loss: 3.5080870794886763
Validation loss: 2.8439015597478767

Epoch: 6| Step: 12
Training loss: 2.8155736446460238
Validation loss: 2.8432954273664848

Epoch: 6| Step: 13
Training loss: 3.325693020984381
Validation loss: 2.8421547377432623

Epoch: 69| Step: 0
Training loss: 2.9509951060767396
Validation loss: 2.836824922864589

Epoch: 6| Step: 1
Training loss: 2.8529400568139245
Validation loss: 2.836785418217635

Epoch: 6| Step: 2
Training loss: 3.176485966456136
Validation loss: 2.8339427428946915

Epoch: 6| Step: 3
Training loss: 3.139623074110227
Validation loss: 2.834981152035479

Epoch: 6| Step: 4
Training loss: 2.7274026969805143
Validation loss: 2.8349790613198738

Epoch: 6| Step: 5
Training loss: 3.5906576369273915
Validation loss: 2.8366296463061946

Epoch: 6| Step: 6
Training loss: 4.056585613643611
Validation loss: 2.836660983207898

Epoch: 6| Step: 7
Training loss: 3.367829370059077
Validation loss: 2.8346303459999884

Epoch: 6| Step: 8
Training loss: 2.683518943132665
Validation loss: 2.8386047226825455

Epoch: 6| Step: 9
Training loss: 3.3603607860506224
Validation loss: 2.83600852147637

Epoch: 6| Step: 10
Training loss: 3.1629113634675026
Validation loss: 2.8364757421543607

Epoch: 6| Step: 11
Training loss: 2.8955745078216655
Validation loss: 2.833485368224209

Epoch: 6| Step: 12
Training loss: 2.9264392800366132
Validation loss: 2.832411243827996

Epoch: 6| Step: 13
Training loss: 2.51872081881674
Validation loss: 2.8333457838529275

Epoch: 70| Step: 0
Training loss: 3.0245663607924693
Validation loss: 2.839629651714631

Epoch: 6| Step: 1
Training loss: 2.7917117404620226
Validation loss: 2.843121420052552

Epoch: 6| Step: 2
Training loss: 3.8357256735683136
Validation loss: 2.8453991586334912

Epoch: 6| Step: 3
Training loss: 2.295512930868326
Validation loss: 2.8397700637917147

Epoch: 6| Step: 4
Training loss: 3.3157902337553833
Validation loss: 2.840144391653595

Epoch: 6| Step: 5
Training loss: 3.4780343015623405
Validation loss: 2.838747448596503

Epoch: 6| Step: 6
Training loss: 2.474019089337578
Validation loss: 2.8328585585820285

Epoch: 6| Step: 7
Training loss: 3.029508267275681
Validation loss: 2.8325682161358814

Epoch: 6| Step: 8
Training loss: 3.0646717389855667
Validation loss: 2.8282712079262993

Epoch: 6| Step: 9
Training loss: 2.8697440160175023
Validation loss: 2.8341965804989724

Epoch: 6| Step: 10
Training loss: 3.443466833972693
Validation loss: 2.832285343096684

Epoch: 6| Step: 11
Training loss: 3.050937546012368
Validation loss: 2.8284139667413943

Epoch: 6| Step: 12
Training loss: 3.5715607645910232
Validation loss: 2.829173620042894

Epoch: 6| Step: 13
Training loss: 3.348013468215086
Validation loss: 2.826926752185953

Epoch: 71| Step: 0
Training loss: 3.2459694738733114
Validation loss: 2.8253853254439134

Epoch: 6| Step: 1
Training loss: 3.0162435104863103
Validation loss: 2.824338926037057

Epoch: 6| Step: 2
Training loss: 2.897221806413282
Validation loss: 2.826091039714113

Epoch: 6| Step: 3
Training loss: 3.1567962475947233
Validation loss: 2.8238510936196346

Epoch: 6| Step: 4
Training loss: 2.9248775619573215
Validation loss: 2.82512982863555

Epoch: 6| Step: 5
Training loss: 3.63699854379855
Validation loss: 2.8234015999817883

Epoch: 6| Step: 6
Training loss: 3.1370566674204237
Validation loss: 2.824566456244676

Epoch: 6| Step: 7
Training loss: 2.8173391461087496
Validation loss: 2.8226742314353626

Epoch: 6| Step: 8
Training loss: 2.9091682139334
Validation loss: 2.824882636144695

Epoch: 6| Step: 9
Training loss: 3.099082281802128
Validation loss: 2.8244545078422916

Epoch: 6| Step: 10
Training loss: 3.0192583560384185
Validation loss: 2.823562960994155

Epoch: 6| Step: 11
Training loss: 2.8629976264818526
Validation loss: 2.824674172668135

Epoch: 6| Step: 12
Training loss: 3.1231525300686513
Validation loss: 2.8278797736571577

Epoch: 6| Step: 13
Training loss: 4.315073986634741
Validation loss: 2.829404154699258

Epoch: 72| Step: 0
Training loss: 3.112666396017329
Validation loss: 2.8308888044402627

Epoch: 6| Step: 1
Training loss: 3.5253028414884504
Validation loss: 2.8266655775409784

Epoch: 6| Step: 2
Training loss: 3.460922895620287
Validation loss: 2.821217823136853

Epoch: 6| Step: 3
Training loss: 3.278917628085155
Validation loss: 2.8206709580923572

Epoch: 6| Step: 4
Training loss: 3.058248722108268
Validation loss: 2.819212480974551

Epoch: 6| Step: 5
Training loss: 2.7967684421805905
Validation loss: 2.82319220988816

Epoch: 6| Step: 6
Training loss: 3.0852850501926694
Validation loss: 2.818744522503043

Epoch: 6| Step: 7
Training loss: 3.207863182860387
Validation loss: 2.8202327530312714

Epoch: 6| Step: 8
Training loss: 3.014261678756106
Validation loss: 2.8182150807566506

Epoch: 6| Step: 9
Training loss: 3.063587851869609
Validation loss: 2.8200256394476213

Epoch: 6| Step: 10
Training loss: 3.0961000398643685
Validation loss: 2.8199515599337937

Epoch: 6| Step: 11
Training loss: 2.998820549857324
Validation loss: 2.818303494570333

Epoch: 6| Step: 12
Training loss: 2.832772835287068
Validation loss: 2.8193426063463525

Epoch: 6| Step: 13
Training loss: 3.316163106930963
Validation loss: 2.820533274533311

Epoch: 73| Step: 0
Training loss: 2.426542448315917
Validation loss: 2.82340280852575

Epoch: 6| Step: 1
Training loss: 3.046986113258419
Validation loss: 2.8346200159205357

Epoch: 6| Step: 2
Training loss: 3.2562647374381593
Validation loss: 2.839173118227877

Epoch: 6| Step: 3
Training loss: 3.661281807534368
Validation loss: 2.8389293979722217

Epoch: 6| Step: 4
Training loss: 2.947041052370236
Validation loss: 2.829857518950252

Epoch: 6| Step: 5
Training loss: 3.2239524500253434
Validation loss: 2.8229273668094037

Epoch: 6| Step: 6
Training loss: 2.8972329981225458
Validation loss: 2.8196655145817036

Epoch: 6| Step: 7
Training loss: 3.1046668210850403
Validation loss: 2.8157387920325263

Epoch: 6| Step: 8
Training loss: 3.1719447536972982
Validation loss: 2.817039580675666

Epoch: 6| Step: 9
Training loss: 3.1987733635714397
Validation loss: 2.8153328032017235

Epoch: 6| Step: 10
Training loss: 2.9063415512923725
Validation loss: 2.8152521493383538

Epoch: 6| Step: 11
Training loss: 3.187157406814955
Validation loss: 2.8146008351013503

Epoch: 6| Step: 12
Training loss: 3.4933432900187387
Validation loss: 2.814936329402724

Epoch: 6| Step: 13
Training loss: 3.0542561648493107
Validation loss: 2.8150596210257697

Epoch: 74| Step: 0
Training loss: 3.2046698589760063
Validation loss: 2.8145511635712053

Epoch: 6| Step: 1
Training loss: 3.124297406369513
Validation loss: 2.8131393699425606

Epoch: 6| Step: 2
Training loss: 3.5139052868553864
Validation loss: 2.8127962455461826

Epoch: 6| Step: 3
Training loss: 3.1930913316882186
Validation loss: 2.814210721011808

Epoch: 6| Step: 4
Training loss: 2.635903465535178
Validation loss: 2.8136348380928884

Epoch: 6| Step: 5
Training loss: 2.8946094991426485
Validation loss: 2.8154655654781124

Epoch: 6| Step: 6
Training loss: 2.9916816463113145
Validation loss: 2.8193985352866067

Epoch: 6| Step: 7
Training loss: 3.393384522487255
Validation loss: 2.8171359767482373

Epoch: 6| Step: 8
Training loss: 3.6488402836585507
Validation loss: 2.8271569921796353

Epoch: 6| Step: 9
Training loss: 3.2672869819955035
Validation loss: 2.818994943289796

Epoch: 6| Step: 10
Training loss: 3.1948789568256086
Validation loss: 2.8123610531701972

Epoch: 6| Step: 11
Training loss: 2.9200796231426915
Validation loss: 2.8105187642173917

Epoch: 6| Step: 12
Training loss: 2.814484976615393
Validation loss: 2.8119070834137134

Epoch: 6| Step: 13
Training loss: 2.3977770563929224
Validation loss: 2.8115484672120994

Epoch: 75| Step: 0
Training loss: 3.202763830152545
Validation loss: 2.811215596673813

Epoch: 6| Step: 1
Training loss: 2.6606419773828125
Validation loss: 2.8123712125070446

Epoch: 6| Step: 2
Training loss: 3.1682505076614245
Validation loss: 2.810240941446053

Epoch: 6| Step: 3
Training loss: 2.94346840193934
Validation loss: 2.809969625374908

Epoch: 6| Step: 4
Training loss: 3.8719089854475346
Validation loss: 2.8103865098751837

Epoch: 6| Step: 5
Training loss: 3.093336135462884
Validation loss: 2.8096016345855044

Epoch: 6| Step: 6
Training loss: 2.4482040128405904
Validation loss: 2.810948114873805

Epoch: 6| Step: 7
Training loss: 3.4204827528988386
Validation loss: 2.810000753245324

Epoch: 6| Step: 8
Training loss: 3.2736386621979534
Validation loss: 2.8098722499073774

Epoch: 6| Step: 9
Training loss: 3.1035666344533652
Validation loss: 2.8078131359859566

Epoch: 6| Step: 10
Training loss: 3.4686928134362627
Validation loss: 2.8102823773331904

Epoch: 6| Step: 11
Training loss: 2.2144551146439952
Validation loss: 2.810268075261455

Epoch: 6| Step: 12
Training loss: 3.4326070467933425
Validation loss: 2.8110627224309312

Epoch: 6| Step: 13
Training loss: 2.916425222666739
Validation loss: 2.80958246288639

Epoch: 76| Step: 0
Training loss: 2.781128441372255
Validation loss: 2.8119820795854245

Epoch: 6| Step: 1
Training loss: 2.9773276639657453
Validation loss: 2.8095092258096215

Epoch: 6| Step: 2
Training loss: 3.3856682473628705
Validation loss: 2.8094290261828063

Epoch: 6| Step: 3
Training loss: 2.898684426865949
Validation loss: 2.808304869907175

Epoch: 6| Step: 4
Training loss: 3.8003068649467284
Validation loss: 2.8097941007571285

Epoch: 6| Step: 5
Training loss: 3.828342229168235
Validation loss: 2.8066879799276947

Epoch: 6| Step: 6
Training loss: 3.1445230614217916
Validation loss: 2.804068680912212

Epoch: 6| Step: 7
Training loss: 2.980111636944553
Validation loss: 2.8057872544619924

Epoch: 6| Step: 8
Training loss: 3.040063060809149
Validation loss: 2.8081666631186426

Epoch: 6| Step: 9
Training loss: 2.622997973704164
Validation loss: 2.8087215825498024

Epoch: 6| Step: 10
Training loss: 3.2036507523933606
Validation loss: 2.817870826729779

Epoch: 6| Step: 11
Training loss: 2.773778760089621
Validation loss: 2.8184015720313087

Epoch: 6| Step: 12
Training loss: 2.355805886910154
Validation loss: 2.8346969063700116

Epoch: 6| Step: 13
Training loss: 3.638446336063991
Validation loss: 2.8402418999541625

Epoch: 77| Step: 0
Training loss: 3.258896023164121
Validation loss: 2.828300213659356

Epoch: 6| Step: 1
Training loss: 2.781075118492355
Validation loss: 2.819287230983215

Epoch: 6| Step: 2
Training loss: 2.560388951556375
Validation loss: 2.8146163215530864

Epoch: 6| Step: 3
Training loss: 3.215103602423475
Validation loss: 2.8067435152680345

Epoch: 6| Step: 4
Training loss: 2.7282735707661208
Validation loss: 2.8025136655995895

Epoch: 6| Step: 5
Training loss: 2.4293872120253184
Validation loss: 2.800472045256941

Epoch: 6| Step: 6
Training loss: 2.738191567773996
Validation loss: 2.8016433532027514

Epoch: 6| Step: 7
Training loss: 3.705467931565177
Validation loss: 2.801051266818363

Epoch: 6| Step: 8
Training loss: 3.1222120437214818
Validation loss: 2.802418364705191

Epoch: 6| Step: 9
Training loss: 3.3654109224402124
Validation loss: 2.8031637244726046

Epoch: 6| Step: 10
Training loss: 3.1674879581791564
Validation loss: 2.8039853789373272

Epoch: 6| Step: 11
Training loss: 3.8334001590598366
Validation loss: 2.8139308648605845

Epoch: 6| Step: 12
Training loss: 3.3905482129661926
Validation loss: 2.821407740496643

Epoch: 6| Step: 13
Training loss: 2.8305464857873512
Validation loss: 2.807979282108731

Epoch: 78| Step: 0
Training loss: 2.851254297610284
Validation loss: 2.809374482923617

Epoch: 6| Step: 1
Training loss: 2.7534873697944713
Validation loss: 2.813172059335742

Epoch: 6| Step: 2
Training loss: 3.167252202024725
Validation loss: 2.8175579699120794

Epoch: 6| Step: 3
Training loss: 3.2146945330080365
Validation loss: 2.8353328079932174

Epoch: 6| Step: 4
Training loss: 2.6502405741192643
Validation loss: 2.834944920583997

Epoch: 6| Step: 5
Training loss: 3.0769939377768094
Validation loss: 2.81966019029992

Epoch: 6| Step: 6
Training loss: 2.912061725433858
Validation loss: 2.8030321501913518

Epoch: 6| Step: 7
Training loss: 2.761438163953233
Validation loss: 2.7994927961394978

Epoch: 6| Step: 8
Training loss: 3.3665302104175168
Validation loss: 2.794926289718259

Epoch: 6| Step: 9
Training loss: 3.881818494457665
Validation loss: 2.794886749627706

Epoch: 6| Step: 10
Training loss: 2.5079488271575863
Validation loss: 2.7941360871587104

Epoch: 6| Step: 11
Training loss: 3.150455556958331
Validation loss: 2.7969533524681114

Epoch: 6| Step: 12
Training loss: 3.8762118997826476
Validation loss: 2.795269580814843

Epoch: 6| Step: 13
Training loss: 2.9103667931913058
Validation loss: 2.7963715695597444

Epoch: 79| Step: 0
Training loss: 2.8215015050142807
Validation loss: 2.7937650445360194

Epoch: 6| Step: 1
Training loss: 3.8674487709642276
Validation loss: 2.791722969463281

Epoch: 6| Step: 2
Training loss: 2.9591229598322286
Validation loss: 2.7954465392369556

Epoch: 6| Step: 3
Training loss: 3.866276920889644
Validation loss: 2.8008624770856057

Epoch: 6| Step: 4
Training loss: 3.760090159491834
Validation loss: 2.8071976680057107

Epoch: 6| Step: 5
Training loss: 3.248564476478328
Validation loss: 2.8172992826923546

Epoch: 6| Step: 6
Training loss: 2.4105893925199773
Validation loss: 2.81515680067181

Epoch: 6| Step: 7
Training loss: 2.3368377481793465
Validation loss: 2.8192501149322253

Epoch: 6| Step: 8
Training loss: 2.6824137440773903
Validation loss: 2.8028042840901652

Epoch: 6| Step: 9
Training loss: 2.480425496362544
Validation loss: 2.796107810420259

Epoch: 6| Step: 10
Training loss: 3.2641025626580396
Validation loss: 2.795465308995561

Epoch: 6| Step: 11
Training loss: 2.902073966999553
Validation loss: 2.7925013465381254

Epoch: 6| Step: 12
Training loss: 3.0382286045636637
Validation loss: 2.7905473854462675

Epoch: 6| Step: 13
Training loss: 3.4609523798706654
Validation loss: 2.7903547796672123

Epoch: 80| Step: 0
Training loss: 3.2582825977899073
Validation loss: 2.786854475534919

Epoch: 6| Step: 1
Training loss: 3.3840294602556904
Validation loss: 2.7906230640481597

Epoch: 6| Step: 2
Training loss: 3.1810836538655543
Validation loss: 2.7893770648941607

Epoch: 6| Step: 3
Training loss: 2.84117613629697
Validation loss: 2.789868082282863

Epoch: 6| Step: 4
Training loss: 3.513358915936768
Validation loss: 2.7907075604229057

Epoch: 6| Step: 5
Training loss: 2.9471261589972526
Validation loss: 2.794169920958054

Epoch: 6| Step: 6
Training loss: 3.4625295589576233
Validation loss: 2.7934504460672476

Epoch: 6| Step: 7
Training loss: 2.691685544431013
Validation loss: 2.799868026859283

Epoch: 6| Step: 8
Training loss: 2.9268459526997592
Validation loss: 2.8044585964833733

Epoch: 6| Step: 9
Training loss: 2.898982323289017
Validation loss: 2.809465221692087

Epoch: 6| Step: 10
Training loss: 3.314575696577142
Validation loss: 2.8100657585564948

Epoch: 6| Step: 11
Training loss: 2.834654799070783
Validation loss: 2.8241666255917726

Epoch: 6| Step: 12
Training loss: 2.837714193048811
Validation loss: 2.7978054856114816

Epoch: 6| Step: 13
Training loss: 3.4712509899254753
Validation loss: 2.7914254499558013

Epoch: 81| Step: 0
Training loss: 2.9275285013507046
Validation loss: 2.789990224942791

Epoch: 6| Step: 1
Training loss: 3.2204718567474764
Validation loss: 2.787073592828895

Epoch: 6| Step: 2
Training loss: 2.937750785349031
Validation loss: 2.789324170832988

Epoch: 6| Step: 3
Training loss: 2.960096415934112
Validation loss: 2.784313376334851

Epoch: 6| Step: 4
Training loss: 2.969028821199498
Validation loss: 2.7843120467797826

Epoch: 6| Step: 5
Training loss: 3.678456094338503
Validation loss: 2.785136269380641

Epoch: 6| Step: 6
Training loss: 2.8002161283185645
Validation loss: 2.787851328639376

Epoch: 6| Step: 7
Training loss: 3.172440501948511
Validation loss: 2.7854388241402734

Epoch: 6| Step: 8
Training loss: 2.9889293491440716
Validation loss: 2.7842518275819335

Epoch: 6| Step: 9
Training loss: 3.6576955171216317
Validation loss: 2.787016034640977

Epoch: 6| Step: 10
Training loss: 3.2173292857825877
Validation loss: 2.7845343774982885

Epoch: 6| Step: 11
Training loss: 3.236649307953486
Validation loss: 2.7863237751966277

Epoch: 6| Step: 12
Training loss: 2.6216531943888324
Validation loss: 2.7841977109557425

Epoch: 6| Step: 13
Training loss: 2.429199071529518
Validation loss: 2.78484159129595

Epoch: 82| Step: 0
Training loss: 3.1734771440547496
Validation loss: 2.7886546720249683

Epoch: 6| Step: 1
Training loss: 2.584516151937152
Validation loss: 2.7851034828867527

Epoch: 6| Step: 2
Training loss: 3.2052743539012156
Validation loss: 2.7833373139060473

Epoch: 6| Step: 3
Training loss: 3.2831849705309346
Validation loss: 2.7860301171264514

Epoch: 6| Step: 4
Training loss: 2.740125092484089
Validation loss: 2.7861097573013223

Epoch: 6| Step: 5
Training loss: 2.865099570256739
Validation loss: 2.7867682487701835

Epoch: 6| Step: 6
Training loss: 3.545347313270776
Validation loss: 2.7851727539000612

Epoch: 6| Step: 7
Training loss: 3.1738771029874746
Validation loss: 2.7833763493802413

Epoch: 6| Step: 8
Training loss: 2.94825350900443
Validation loss: 2.781621101917165

Epoch: 6| Step: 9
Training loss: 3.090966716269987
Validation loss: 2.782340829137499

Epoch: 6| Step: 10
Training loss: 2.49350734667846
Validation loss: 2.7860955298960266

Epoch: 6| Step: 11
Training loss: 3.181647219337856
Validation loss: 2.7819128533617348

Epoch: 6| Step: 12
Training loss: 3.425530140632945
Validation loss: 2.7862051127191463

Epoch: 6| Step: 13
Training loss: 3.5403914156541503
Validation loss: 2.783225426864288

Epoch: 83| Step: 0
Training loss: 2.4071629761505555
Validation loss: 2.7860787259688213

Epoch: 6| Step: 1
Training loss: 3.652880036663654
Validation loss: 2.7909028479654268

Epoch: 6| Step: 2
Training loss: 2.632478687167498
Validation loss: 2.796217923190863

Epoch: 6| Step: 3
Training loss: 2.6644838956323658
Validation loss: 2.802908825248216

Epoch: 6| Step: 4
Training loss: 3.298905890605739
Validation loss: 2.8051989415792167

Epoch: 6| Step: 5
Training loss: 3.093013483096414
Validation loss: 2.7941258165616025

Epoch: 6| Step: 6
Training loss: 2.99584959942713
Validation loss: 2.797185630686772

Epoch: 6| Step: 7
Training loss: 2.7617867770308098
Validation loss: 2.7895952019739996

Epoch: 6| Step: 8
Training loss: 3.506772437247068
Validation loss: 2.778217528581339

Epoch: 6| Step: 9
Training loss: 3.584269216584542
Validation loss: 2.776190369463118

Epoch: 6| Step: 10
Training loss: 3.0077620861237735
Validation loss: 2.7749059371282745

Epoch: 6| Step: 11
Training loss: 3.254909328715499
Validation loss: 2.7764218076322056

Epoch: 6| Step: 12
Training loss: 3.4875890850324667
Validation loss: 2.776068580049243

Epoch: 6| Step: 13
Training loss: 2.253459390278159
Validation loss: 2.7738765116629156

Epoch: 84| Step: 0
Training loss: 2.913620329744993
Validation loss: 2.7758193801002786

Epoch: 6| Step: 1
Training loss: 3.068181276160812
Validation loss: 2.7754638109850314

Epoch: 6| Step: 2
Training loss: 3.8848703254257453
Validation loss: 2.775191499509666

Epoch: 6| Step: 3
Training loss: 2.691390127457606
Validation loss: 2.7761419642500456

Epoch: 6| Step: 4
Training loss: 3.0617911627855547
Validation loss: 2.776673957861323

Epoch: 6| Step: 5
Training loss: 3.164938873616751
Validation loss: 2.7819376702909535

Epoch: 6| Step: 6
Training loss: 3.2583967457980534
Validation loss: 2.778681381128444

Epoch: 6| Step: 7
Training loss: 3.1658025030924506
Validation loss: 2.776195067913433

Epoch: 6| Step: 8
Training loss: 2.6487936044932043
Validation loss: 2.777939560461932

Epoch: 6| Step: 9
Training loss: 3.1652409372328774
Validation loss: 2.774600205708729

Epoch: 6| Step: 10
Training loss: 3.04164778472753
Validation loss: 2.7741090697761437

Epoch: 6| Step: 11
Training loss: 2.8192205877857828
Validation loss: 2.775061471116524

Epoch: 6| Step: 12
Training loss: 2.562818181822709
Validation loss: 2.7732415557143004

Epoch: 6| Step: 13
Training loss: 3.7693818532166365
Validation loss: 2.7764365933784036

Epoch: 85| Step: 0
Training loss: 2.8329371193997837
Validation loss: 2.7783103829803357

Epoch: 6| Step: 1
Training loss: 3.230503880080299
Validation loss: 2.790997090774667

Epoch: 6| Step: 2
Training loss: 2.614715045990388
Validation loss: 2.796406291241115

Epoch: 6| Step: 3
Training loss: 3.516313273555239
Validation loss: 2.786085008820185

Epoch: 6| Step: 4
Training loss: 3.158714012481422
Validation loss: 2.7760121604587127

Epoch: 6| Step: 5
Training loss: 3.2394306273618123
Validation loss: 2.7709826412925143

Epoch: 6| Step: 6
Training loss: 3.303413740835327
Validation loss: 2.770255784907743

Epoch: 6| Step: 7
Training loss: 2.4700904780198827
Validation loss: 2.767418011056506

Epoch: 6| Step: 8
Training loss: 3.6425451364122834
Validation loss: 2.7674229893403535

Epoch: 6| Step: 9
Training loss: 3.3370003715608667
Validation loss: 2.7677762495460887

Epoch: 6| Step: 10
Training loss: 2.7590299950103296
Validation loss: 2.768767137390402

Epoch: 6| Step: 11
Training loss: 3.23936129644205
Validation loss: 2.7669236777162194

Epoch: 6| Step: 12
Training loss: 2.6224738181728244
Validation loss: 2.7676044941961013

Epoch: 6| Step: 13
Training loss: 2.891307853255153
Validation loss: 2.767376422490184

Epoch: 86| Step: 0
Training loss: 2.4595723558900726
Validation loss: 2.7666644286754387

Epoch: 6| Step: 1
Training loss: 3.051203387137635
Validation loss: 2.7668954934253778

Epoch: 6| Step: 2
Training loss: 3.3687109100961425
Validation loss: 2.7633141870898057

Epoch: 6| Step: 3
Training loss: 3.4186126625608075
Validation loss: 2.7621120265632086

Epoch: 6| Step: 4
Training loss: 2.6425666667861805
Validation loss: 2.766078427233133

Epoch: 6| Step: 5
Training loss: 2.698732721539339
Validation loss: 2.766608220392503

Epoch: 6| Step: 6
Training loss: 3.084912402672972
Validation loss: 2.7648853527028017

Epoch: 6| Step: 7
Training loss: 2.91401815508526
Validation loss: 2.765306322209457

Epoch: 6| Step: 8
Training loss: 2.8195683139427117
Validation loss: 2.7694750508401476

Epoch: 6| Step: 9
Training loss: 3.4708754067925773
Validation loss: 2.7733979234611525

Epoch: 6| Step: 10
Training loss: 3.320568263357007
Validation loss: 2.7714665667206075

Epoch: 6| Step: 11
Training loss: 3.0369033792680606
Validation loss: 2.7741803360076136

Epoch: 6| Step: 12
Training loss: 2.95658002305692
Validation loss: 2.766704345231088

Epoch: 6| Step: 13
Training loss: 4.027514005479193
Validation loss: 2.765087887783297

Epoch: 87| Step: 0
Training loss: 2.708013095018288
Validation loss: 2.766301252185038

Epoch: 6| Step: 1
Training loss: 2.9313834609371994
Validation loss: 2.763733521234897

Epoch: 6| Step: 2
Training loss: 2.785145891980871
Validation loss: 2.7654863205397158

Epoch: 6| Step: 3
Training loss: 3.004565579563777
Validation loss: 2.766099291594663

Epoch: 6| Step: 4
Training loss: 2.7307457080790924
Validation loss: 2.76381940921475

Epoch: 6| Step: 5
Training loss: 3.14426101565928
Validation loss: 2.7635255630000652

Epoch: 6| Step: 6
Training loss: 2.743989184127489
Validation loss: 2.7632004701098842

Epoch: 6| Step: 7
Training loss: 3.0049724695655167
Validation loss: 2.761492614264704

Epoch: 6| Step: 8
Training loss: 3.432951814014964
Validation loss: 2.7617991701270523

Epoch: 6| Step: 9
Training loss: 3.2160569563514545
Validation loss: 2.761154427889467

Epoch: 6| Step: 10
Training loss: 3.503172118170383
Validation loss: 2.7612117118492505

Epoch: 6| Step: 11
Training loss: 2.9310779577981103
Validation loss: 2.759115664248218

Epoch: 6| Step: 12
Training loss: 3.4826401296055365
Validation loss: 2.7604003206133987

Epoch: 6| Step: 13
Training loss: 3.3923966661765887
Validation loss: 2.757379613561953

Epoch: 88| Step: 0
Training loss: 2.952002902517985
Validation loss: 2.7592777325777242

Epoch: 6| Step: 1
Training loss: 3.339172795588942
Validation loss: 2.758275919416693

Epoch: 6| Step: 2
Training loss: 3.0068706672746663
Validation loss: 2.75903218044521

Epoch: 6| Step: 3
Training loss: 3.097766465370592
Validation loss: 2.7584613096223936

Epoch: 6| Step: 4
Training loss: 3.0637466073299504
Validation loss: 2.7577444548800703

Epoch: 6| Step: 5
Training loss: 3.4399993133544235
Validation loss: 2.7597010150131625

Epoch: 6| Step: 6
Training loss: 3.0858381424372863
Validation loss: 2.7579159914026956

Epoch: 6| Step: 7
Training loss: 2.821641603536167
Validation loss: 2.759027024414309

Epoch: 6| Step: 8
Training loss: 2.983973610932608
Validation loss: 2.754422943509516

Epoch: 6| Step: 9
Training loss: 2.5369959476244617
Validation loss: 2.7566743142890795

Epoch: 6| Step: 10
Training loss: 3.249627898996067
Validation loss: 2.7582070306270987

Epoch: 6| Step: 11
Training loss: 3.0696983596778984
Validation loss: 2.7606696420207237

Epoch: 6| Step: 12
Training loss: 3.47234783369256
Validation loss: 2.759234615569565

Epoch: 6| Step: 13
Training loss: 2.457480287987012
Validation loss: 2.7559234610991488

Epoch: 89| Step: 0
Training loss: 3.5432652325214953
Validation loss: 2.7549914761204777

Epoch: 6| Step: 1
Training loss: 3.6799787985149495
Validation loss: 2.7561306562962757

Epoch: 6| Step: 2
Training loss: 3.0481972979570973
Validation loss: 2.7585349624124214

Epoch: 6| Step: 3
Training loss: 2.031137786113182
Validation loss: 2.7554445616538383

Epoch: 6| Step: 4
Training loss: 3.194514018604939
Validation loss: 2.757251086373166

Epoch: 6| Step: 5
Training loss: 3.1164442816015736
Validation loss: 2.7530662431367303

Epoch: 6| Step: 6
Training loss: 3.0381893678653022
Validation loss: 2.7553743683462515

Epoch: 6| Step: 7
Training loss: 2.9500066854110223
Validation loss: 2.75168642276737

Epoch: 6| Step: 8
Training loss: 3.758725124894631
Validation loss: 2.751770523508437

Epoch: 6| Step: 9
Training loss: 3.467468299858336
Validation loss: 2.7533400286944403

Epoch: 6| Step: 10
Training loss: 2.122998360761242
Validation loss: 2.7512637839402734

Epoch: 6| Step: 11
Training loss: 2.576560915824445
Validation loss: 2.7502908590138055

Epoch: 6| Step: 12
Training loss: 2.7815099016116536
Validation loss: 2.7508404809364286

Epoch: 6| Step: 13
Training loss: 3.007028769900656
Validation loss: 2.7503055466158455

Epoch: 90| Step: 0
Training loss: 3.506242090444092
Validation loss: 2.7543946182747137

Epoch: 6| Step: 1
Training loss: 3.2036381008150174
Validation loss: 2.7593021352403313

Epoch: 6| Step: 2
Training loss: 3.331968425413371
Validation loss: 2.750433895973931

Epoch: 6| Step: 3
Training loss: 3.132736852022684
Validation loss: 2.749749186200541

Epoch: 6| Step: 4
Training loss: 2.868854588947801
Validation loss: 2.7502298314995572

Epoch: 6| Step: 5
Training loss: 2.390944615359595
Validation loss: 2.749119041379063

Epoch: 6| Step: 6
Training loss: 2.6280034457841692
Validation loss: 2.7547617654933187

Epoch: 6| Step: 7
Training loss: 2.7646816390458233
Validation loss: 2.7476794500576065

Epoch: 6| Step: 8
Training loss: 3.2068782495762105
Validation loss: 2.749143265648139

Epoch: 6| Step: 9
Training loss: 3.357645130557115
Validation loss: 2.748546481898213

Epoch: 6| Step: 10
Training loss: 3.179920834689533
Validation loss: 2.74921831411316

Epoch: 6| Step: 11
Training loss: 2.5741318730005207
Validation loss: 2.7477092916160255

Epoch: 6| Step: 12
Training loss: 2.718318159512055
Validation loss: 2.74832178556075

Epoch: 6| Step: 13
Training loss: 4.15035983444461
Validation loss: 2.74616558456119

Epoch: 91| Step: 0
Training loss: 2.803530993877252
Validation loss: 2.7584393930512157

Epoch: 6| Step: 1
Training loss: 3.2152578427873353
Validation loss: 2.7641816319050916

Epoch: 6| Step: 2
Training loss: 2.9981254443084215
Validation loss: 2.763466874241937

Epoch: 6| Step: 3
Training loss: 3.1859061052048663
Validation loss: 2.752080281548988

Epoch: 6| Step: 4
Training loss: 2.661799120998216
Validation loss: 2.7527492983710107

Epoch: 6| Step: 5
Training loss: 3.2522765769133564
Validation loss: 2.744638171615639

Epoch: 6| Step: 6
Training loss: 3.3857265545770474
Validation loss: 2.7421466796424503

Epoch: 6| Step: 7
Training loss: 3.013061382490128
Validation loss: 2.7472520711416344

Epoch: 6| Step: 8
Training loss: 3.379600215495488
Validation loss: 2.7432520056205094

Epoch: 6| Step: 9
Training loss: 2.9997687250635887
Validation loss: 2.7465052002582766

Epoch: 6| Step: 10
Training loss: 2.4378514158802673
Validation loss: 2.746106868340248

Epoch: 6| Step: 11
Training loss: 2.8611244728080893
Validation loss: 2.7428772602848768

Epoch: 6| Step: 12
Training loss: 3.573684135435828
Validation loss: 2.7467109946761687

Epoch: 6| Step: 13
Training loss: 2.79993565349211
Validation loss: 2.746623586995219

Epoch: 92| Step: 0
Training loss: 2.4039137757400173
Validation loss: 2.7477514446908886

Epoch: 6| Step: 1
Training loss: 3.0459933056723356
Validation loss: 2.7481432097008693

Epoch: 6| Step: 2
Training loss: 2.6357602786290952
Validation loss: 2.766354313072887

Epoch: 6| Step: 3
Training loss: 3.29325675383683
Validation loss: 2.764133631306438

Epoch: 6| Step: 4
Training loss: 3.744522799556564
Validation loss: 2.7657066849008345

Epoch: 6| Step: 5
Training loss: 3.5682241396445638
Validation loss: 2.7615088613270884

Epoch: 6| Step: 6
Training loss: 3.033982922791995
Validation loss: 2.7536339907936345

Epoch: 6| Step: 7
Training loss: 2.4628482243202883
Validation loss: 2.7495061369406417

Epoch: 6| Step: 8
Training loss: 3.696673991268
Validation loss: 2.742714945373819

Epoch: 6| Step: 9
Training loss: 2.782326907714624
Validation loss: 2.740050517257919

Epoch: 6| Step: 10
Training loss: 2.8289153117087675
Validation loss: 2.7393582343323604

Epoch: 6| Step: 11
Training loss: 2.99192231200841
Validation loss: 2.7390276284718147

Epoch: 6| Step: 12
Training loss: 3.0084936386327708
Validation loss: 2.7420336335390254

Epoch: 6| Step: 13
Training loss: 2.8728787433278047
Validation loss: 2.740161149983906

Epoch: 93| Step: 0
Training loss: 2.0320907026757853
Validation loss: 2.7546662932364123

Epoch: 6| Step: 1
Training loss: 3.558567620693383
Validation loss: 2.7590209521976035

Epoch: 6| Step: 2
Training loss: 3.112603280065924
Validation loss: 2.7517037488240046

Epoch: 6| Step: 3
Training loss: 3.0543115877235487
Validation loss: 2.7511416160356115

Epoch: 6| Step: 4
Training loss: 2.383562814117298
Validation loss: 2.7397662177808235

Epoch: 6| Step: 5
Training loss: 3.019726114042962
Validation loss: 2.7378865606870746

Epoch: 6| Step: 6
Training loss: 3.6627384876291353
Validation loss: 2.7373753872409647

Epoch: 6| Step: 7
Training loss: 3.082936201209415
Validation loss: 2.739157853075674

Epoch: 6| Step: 8
Training loss: 2.982252234809928
Validation loss: 2.7375905171284534

Epoch: 6| Step: 9
Training loss: 2.930999380756522
Validation loss: 2.7373415407521744

Epoch: 6| Step: 10
Training loss: 2.9964155399838717
Validation loss: 2.736666600836621

Epoch: 6| Step: 11
Training loss: 3.2830346476701604
Validation loss: 2.736773812626124

Epoch: 6| Step: 12
Training loss: 3.4798957532856285
Validation loss: 2.7361732600641666

Epoch: 6| Step: 13
Training loss: 2.6609814858063094
Validation loss: 2.7370114368724883

Epoch: 94| Step: 0
Training loss: 3.03591732660444
Validation loss: 2.7368298430493185

Epoch: 6| Step: 1
Training loss: 3.00778871997499
Validation loss: 2.7345204229402835

Epoch: 6| Step: 2
Training loss: 3.2493755034020575
Validation loss: 2.73959162742931

Epoch: 6| Step: 3
Training loss: 3.578175640164305
Validation loss: 2.740785696505102

Epoch: 6| Step: 4
Training loss: 3.1146669068281962
Validation loss: 2.738732941995145

Epoch: 6| Step: 5
Training loss: 3.1924902056825335
Validation loss: 2.7368495693445856

Epoch: 6| Step: 6
Training loss: 3.0021329291061445
Validation loss: 2.734892638822958

Epoch: 6| Step: 7
Training loss: 3.1707436935312763
Validation loss: 2.733139920788719

Epoch: 6| Step: 8
Training loss: 3.106320208057333
Validation loss: 2.7349103862291915

Epoch: 6| Step: 9
Training loss: 3.0916640830907456
Validation loss: 2.734931209030761

Epoch: 6| Step: 10
Training loss: 2.973072639406823
Validation loss: 2.732727720917849

Epoch: 6| Step: 11
Training loss: 2.6461171476074723
Validation loss: 2.7355190901376485

Epoch: 6| Step: 12
Training loss: 2.526508552952008
Validation loss: 2.733642183658134

Epoch: 6| Step: 13
Training loss: 2.731656974308243
Validation loss: 2.734919145060874

Epoch: 95| Step: 0
Training loss: 3.168804166733396
Validation loss: 2.740954003155365

Epoch: 6| Step: 1
Training loss: 3.254400501975487
Validation loss: 2.7372240338078906

Epoch: 6| Step: 2
Training loss: 3.0371252323239566
Validation loss: 2.7407346249882636

Epoch: 6| Step: 3
Training loss: 2.838739025476055
Validation loss: 2.746038706807558

Epoch: 6| Step: 4
Training loss: 3.118769423552366
Validation loss: 2.7423523589610554

Epoch: 6| Step: 5
Training loss: 3.7903076642855007
Validation loss: 2.7520827202889677

Epoch: 6| Step: 6
Training loss: 2.629787439089418
Validation loss: 2.7626542708622477

Epoch: 6| Step: 7
Training loss: 3.0787574389449532
Validation loss: 2.7749484586488316

Epoch: 6| Step: 8
Training loss: 3.077224677233101
Validation loss: 2.7511698918289147

Epoch: 6| Step: 9
Training loss: 3.136620696971102
Validation loss: 2.7391054015808054

Epoch: 6| Step: 10
Training loss: 2.8825575966552113
Validation loss: 2.7304957151119402

Epoch: 6| Step: 11
Training loss: 2.9150789753339588
Validation loss: 2.73314500184158

Epoch: 6| Step: 12
Training loss: 3.0927345844378293
Validation loss: 2.7277453930894655

Epoch: 6| Step: 13
Training loss: 1.9198133373917492
Validation loss: 2.73061113442402

Epoch: 96| Step: 0
Training loss: 2.955116367533858
Validation loss: 2.729901621011782

Epoch: 6| Step: 1
Training loss: 2.310445852642815
Validation loss: 2.7267744891197774

Epoch: 6| Step: 2
Training loss: 2.867676072240003
Validation loss: 2.7293095701958068

Epoch: 6| Step: 3
Training loss: 2.572991641621481
Validation loss: 2.744488430246403

Epoch: 6| Step: 4
Training loss: 3.28274356818693
Validation loss: 2.7783112817228197

Epoch: 6| Step: 5
Training loss: 3.500014850039995
Validation loss: 2.7939325142031537

Epoch: 6| Step: 6
Training loss: 3.1564019799230745
Validation loss: 2.7884645345819794

Epoch: 6| Step: 7
Training loss: 3.458252840752291
Validation loss: 2.7549408373147113

Epoch: 6| Step: 8
Training loss: 3.041200018494383
Validation loss: 2.7234796693151564

Epoch: 6| Step: 9
Training loss: 3.039709811665538
Validation loss: 2.7276175955309383

Epoch: 6| Step: 10
Training loss: 3.154927647119206
Validation loss: 2.732293229356777

Epoch: 6| Step: 11
Training loss: 3.0840227198376167
Validation loss: 2.7437178712536685

Epoch: 6| Step: 12
Training loss: 3.3930488044698324
Validation loss: 2.746871316064019

Epoch: 6| Step: 13
Training loss: 2.861876680565678
Validation loss: 2.754628402337268

Epoch: 97| Step: 0
Training loss: 1.892534410977676
Validation loss: 2.764575699637884

Epoch: 6| Step: 1
Training loss: 3.5320109669913635
Validation loss: 2.7563267938748335

Epoch: 6| Step: 2
Training loss: 2.8018438433059987
Validation loss: 2.7531598154374093

Epoch: 6| Step: 3
Training loss: 2.528249304206365
Validation loss: 2.7499378202909437

Epoch: 6| Step: 4
Training loss: 3.4344268933750066
Validation loss: 2.7445080155581207

Epoch: 6| Step: 5
Training loss: 2.8821593994703134
Validation loss: 2.737129648849819

Epoch: 6| Step: 6
Training loss: 3.21071235999779
Validation loss: 2.7350323099433007

Epoch: 6| Step: 7
Training loss: 3.410949544846032
Validation loss: 2.7341212188568704

Epoch: 6| Step: 8
Training loss: 4.053307564887739
Validation loss: 2.731772003897751

Epoch: 6| Step: 9
Training loss: 2.7843041099489234
Validation loss: 2.7288979200203007

Epoch: 6| Step: 10
Training loss: 2.7983715805732814
Validation loss: 2.7292713338405403

Epoch: 6| Step: 11
Training loss: 2.7785556043271638
Validation loss: 2.7249129648826593

Epoch: 6| Step: 12
Training loss: 3.22936417170489
Validation loss: 2.7247038201334894

Epoch: 6| Step: 13
Training loss: 3.0448369961910973
Validation loss: 2.727440025228364

Epoch: 98| Step: 0
Training loss: 2.762549980712577
Validation loss: 2.728056841607802

Epoch: 6| Step: 1
Training loss: 3.2909993972151836
Validation loss: 2.7362173532221568

Epoch: 6| Step: 2
Training loss: 3.0205505940330286
Validation loss: 2.7433965234737148

Epoch: 6| Step: 3
Training loss: 2.7233546057827085
Validation loss: 2.76213923128912

Epoch: 6| Step: 4
Training loss: 3.304878824525917
Validation loss: 2.789343545188066

Epoch: 6| Step: 5
Training loss: 2.8450247454111808
Validation loss: 2.803953634796513

Epoch: 6| Step: 6
Training loss: 2.60858288465935
Validation loss: 2.7802009894800563

Epoch: 6| Step: 7
Training loss: 3.0339412736735047
Validation loss: 2.773380908564901

Epoch: 6| Step: 8
Training loss: 3.195020443130066
Validation loss: 2.7976688704979016

Epoch: 6| Step: 9
Training loss: 2.9662440916983965
Validation loss: 2.74623658641917

Epoch: 6| Step: 10
Training loss: 2.965308674381605
Validation loss: 2.7319877645753397

Epoch: 6| Step: 11
Training loss: 3.1915286167923043
Validation loss: 2.722951622816474

Epoch: 6| Step: 12
Training loss: 3.485705066217563
Validation loss: 2.7199499744451265

Epoch: 6| Step: 13
Training loss: 3.262885738091935
Validation loss: 2.7184885427591854

Epoch: 99| Step: 0
Training loss: 2.6380472636930743
Validation loss: 2.7199924446178367

Epoch: 6| Step: 1
Training loss: 3.497010452878851
Validation loss: 2.7197662441936097

Epoch: 6| Step: 2
Training loss: 3.1933841622700068
Validation loss: 2.719877153426795

Epoch: 6| Step: 3
Training loss: 3.2327045052043886
Validation loss: 2.719024097476217

Epoch: 6| Step: 4
Training loss: 3.26178073481522
Validation loss: 2.7173141367238034

Epoch: 6| Step: 5
Training loss: 2.827311277558801
Validation loss: 2.7153895355577005

Epoch: 6| Step: 6
Training loss: 2.0617658291002425
Validation loss: 2.716382247047372

Epoch: 6| Step: 7
Training loss: 3.253693609170347
Validation loss: 2.7150591298816544

Epoch: 6| Step: 8
Training loss: 2.590754238167528
Validation loss: 2.7130626880612994

Epoch: 6| Step: 9
Training loss: 3.4996456239315186
Validation loss: 2.7145652016070283

Epoch: 6| Step: 10
Training loss: 3.243830473678884
Validation loss: 2.7139864840748333

Epoch: 6| Step: 11
Training loss: 2.7675553820960386
Validation loss: 2.716019121345491

Epoch: 6| Step: 12
Training loss: 3.277165513767418
Validation loss: 2.7154436101636032

Epoch: 6| Step: 13
Training loss: 2.8055418620598958
Validation loss: 2.716477721882496

Epoch: 100| Step: 0
Training loss: 3.06480196638211
Validation loss: 2.7244755276624626

Epoch: 6| Step: 1
Training loss: 3.3524658124006916
Validation loss: 2.7264249901944435

Epoch: 6| Step: 2
Training loss: 3.2068879145420013
Validation loss: 2.7205908689546963

Epoch: 6| Step: 3
Training loss: 3.4529410611007463
Validation loss: 2.7178986144756974

Epoch: 6| Step: 4
Training loss: 2.9011670033599026
Validation loss: 2.7143694436370223

Epoch: 6| Step: 5
Training loss: 2.928602012447996
Validation loss: 2.711704632746008

Epoch: 6| Step: 6
Training loss: 3.6459855983363907
Validation loss: 2.71298803985284

Epoch: 6| Step: 7
Training loss: 2.761908841639044
Validation loss: 2.7161626624832658

Epoch: 6| Step: 8
Training loss: 2.636407768842768
Validation loss: 2.7178809550105316

Epoch: 6| Step: 9
Training loss: 2.456922762223854
Validation loss: 2.7172328594752595

Epoch: 6| Step: 10
Training loss: 2.909463561909414
Validation loss: 2.717471152826246

Epoch: 6| Step: 11
Training loss: 3.355715581588249
Validation loss: 2.7186027706697633

Epoch: 6| Step: 12
Training loss: 2.6208108445149283
Validation loss: 2.7248006480011475

Epoch: 6| Step: 13
Training loss: 2.791196887975452
Validation loss: 2.7242268649340695

Epoch: 101| Step: 0
Training loss: 3.101155367248859
Validation loss: 2.7251616835384627

Epoch: 6| Step: 1
Training loss: 2.694115414362525
Validation loss: 2.7275811419361813

Epoch: 6| Step: 2
Training loss: 3.009838660342362
Validation loss: 2.7206327383034234

Epoch: 6| Step: 3
Training loss: 3.181311490227193
Validation loss: 2.7224310732109642

Epoch: 6| Step: 4
Training loss: 3.092227753950185
Validation loss: 2.7196693530304685

Epoch: 6| Step: 5
Training loss: 2.899385939731834
Validation loss: 2.7187616727316968

Epoch: 6| Step: 6
Training loss: 3.2448222657419747
Validation loss: 2.713758520939178

Epoch: 6| Step: 7
Training loss: 3.4102619587353207
Validation loss: 2.7061541161617604

Epoch: 6| Step: 8
Training loss: 2.8742482404966427
Validation loss: 2.7067768031972284

Epoch: 6| Step: 9
Training loss: 2.360407925281236
Validation loss: 2.7061478769913494

Epoch: 6| Step: 10
Training loss: 3.277672552226525
Validation loss: 2.707023188866025

Epoch: 6| Step: 11
Training loss: 3.0420000250701604
Validation loss: 2.7070058382165003

Epoch: 6| Step: 12
Training loss: 3.026842984036702
Validation loss: 2.706648429493143

Epoch: 6| Step: 13
Training loss: 3.1360935904102893
Validation loss: 2.707087211336463

Epoch: 102| Step: 0
Training loss: 3.139916942737116
Validation loss: 2.7105943245626856

Epoch: 6| Step: 1
Training loss: 2.3401644937457036
Validation loss: 2.7152718594287992

Epoch: 6| Step: 2
Training loss: 3.368444646184886
Validation loss: 2.719019713205192

Epoch: 6| Step: 3
Training loss: 2.9956563657682063
Validation loss: 2.7120780412098715

Epoch: 6| Step: 4
Training loss: 2.825975391488673
Validation loss: 2.708507726905993

Epoch: 6| Step: 5
Training loss: 2.9493836615730915
Validation loss: 2.7070397713652894

Epoch: 6| Step: 6
Training loss: 2.682454807295432
Validation loss: 2.70528235725694

Epoch: 6| Step: 7
Training loss: 2.7685349667231933
Validation loss: 2.7092669736967205

Epoch: 6| Step: 8
Training loss: 3.2295488849158227
Validation loss: 2.7071714617820173

Epoch: 6| Step: 9
Training loss: 3.1646715873046234
Validation loss: 2.7085330204830207

Epoch: 6| Step: 10
Training loss: 2.7704689149542947
Validation loss: 2.7082340872275794

Epoch: 6| Step: 11
Training loss: 3.6451505766484367
Validation loss: 2.708112234046874

Epoch: 6| Step: 12
Training loss: 2.950774695621692
Validation loss: 2.710904755181369

Epoch: 6| Step: 13
Training loss: 3.513206633491599
Validation loss: 2.7087643809626054

Epoch: 103| Step: 0
Training loss: 2.6585851839002097
Validation loss: 2.70598608741876

Epoch: 6| Step: 1
Training loss: 2.782831663807891
Validation loss: 2.7075937559704144

Epoch: 6| Step: 2
Training loss: 2.803187061928368
Validation loss: 2.7120341577323557

Epoch: 6| Step: 3
Training loss: 3.7152703939742793
Validation loss: 2.7163584913036165

Epoch: 6| Step: 4
Training loss: 3.899208497156426
Validation loss: 2.7126783230035802

Epoch: 6| Step: 5
Training loss: 2.9828584822342177
Validation loss: 2.7096719038595154

Epoch: 6| Step: 6
Training loss: 2.001030418077103
Validation loss: 2.7078336114264414

Epoch: 6| Step: 7
Training loss: 2.3510151476386256
Validation loss: 2.708819058186168

Epoch: 6| Step: 8
Training loss: 3.1907541456248656
Validation loss: 2.705244400116492

Epoch: 6| Step: 9
Training loss: 3.1315708506166104
Validation loss: 2.7056688180806225

Epoch: 6| Step: 10
Training loss: 3.108167864474968
Validation loss: 2.7075523657718046

Epoch: 6| Step: 11
Training loss: 2.3272248646571976
Validation loss: 2.7088861716845782

Epoch: 6| Step: 12
Training loss: 3.53834253528876
Validation loss: 2.713329601112434

Epoch: 6| Step: 13
Training loss: 3.338974867560211
Validation loss: 2.7116431376784464

Epoch: 104| Step: 0
Training loss: 3.1535995988215593
Validation loss: 2.705684196078475

Epoch: 6| Step: 1
Training loss: 3.2763725724154704
Validation loss: 2.706363103955114

Epoch: 6| Step: 2
Training loss: 2.6850795047859353
Validation loss: 2.704198979222724

Epoch: 6| Step: 3
Training loss: 2.281922959654604
Validation loss: 2.700236967376281

Epoch: 6| Step: 4
Training loss: 3.213877721657379
Validation loss: 2.698667200366882

Epoch: 6| Step: 5
Training loss: 3.4868694323289984
Validation loss: 2.7004044443685373

Epoch: 6| Step: 6
Training loss: 3.1067349521625243
Validation loss: 2.699732690732835

Epoch: 6| Step: 7
Training loss: 3.0393596592146714
Validation loss: 2.698892218804504

Epoch: 6| Step: 8
Training loss: 2.968144405234885
Validation loss: 2.7016551075532886

Epoch: 6| Step: 9
Training loss: 3.238824704426502
Validation loss: 2.6992994119257365

Epoch: 6| Step: 10
Training loss: 2.1443838266865343
Validation loss: 2.695395467348255

Epoch: 6| Step: 11
Training loss: 3.370184111504084
Validation loss: 2.6948230957163046

Epoch: 6| Step: 12
Training loss: 2.8602316985277074
Validation loss: 2.694529363288274

Epoch: 6| Step: 13
Training loss: 3.2921962714383923
Validation loss: 2.694983841266225

Epoch: 105| Step: 0
Training loss: 2.9414911954450687
Validation loss: 2.6950866928020925

Epoch: 6| Step: 1
Training loss: 3.3544981577457786
Validation loss: 2.693409132801052

Epoch: 6| Step: 2
Training loss: 2.954633539393983
Validation loss: 2.697209256484113

Epoch: 6| Step: 3
Training loss: 2.9185377023342167
Validation loss: 2.6926655616694717

Epoch: 6| Step: 4
Training loss: 2.9956074982801804
Validation loss: 2.691372629350927

Epoch: 6| Step: 5
Training loss: 2.8642959358079154
Validation loss: 2.6967105282849353

Epoch: 6| Step: 6
Training loss: 2.9270218993196275
Validation loss: 2.69285091343906

Epoch: 6| Step: 7
Training loss: 2.776076058370943
Validation loss: 2.70202461724294

Epoch: 6| Step: 8
Training loss: 2.819634184275681
Validation loss: 2.6970250663831226

Epoch: 6| Step: 9
Training loss: 3.564942442869405
Validation loss: 2.697568892793889

Epoch: 6| Step: 10
Training loss: 3.179449948896674
Validation loss: 2.700363673089957

Epoch: 6| Step: 11
Training loss: 2.970060681580514
Validation loss: 2.7003123753660367

Epoch: 6| Step: 12
Training loss: 2.9853507638717445
Validation loss: 2.704656899634082

Epoch: 6| Step: 13
Training loss: 2.891742387232765
Validation loss: 2.701334805134398

Epoch: 106| Step: 0
Training loss: 2.8491961968598587
Validation loss: 2.7098667760541018

Epoch: 6| Step: 1
Training loss: 2.6978049433096523
Validation loss: 2.7146537699534585

Epoch: 6| Step: 2
Training loss: 3.1344581904833544
Validation loss: 2.716921642162052

Epoch: 6| Step: 3
Training loss: 2.6522113390584146
Validation loss: 2.732491652163132

Epoch: 6| Step: 4
Training loss: 2.889529788825977
Validation loss: 2.7310066912045405

Epoch: 6| Step: 5
Training loss: 2.5070525827329373
Validation loss: 2.7273894849161233

Epoch: 6| Step: 6
Training loss: 2.8292433071476975
Validation loss: 2.7369714141673778

Epoch: 6| Step: 7
Training loss: 3.180595099709087
Validation loss: 2.724355589412082

Epoch: 6| Step: 8
Training loss: 3.2728913427417727
Validation loss: 2.7073973234887228

Epoch: 6| Step: 9
Training loss: 3.4480109686887244
Validation loss: 2.6970441931589892

Epoch: 6| Step: 10
Training loss: 3.255530127323676
Validation loss: 2.6876198798397986

Epoch: 6| Step: 11
Training loss: 2.9999103532748355
Validation loss: 2.6904483551907714

Epoch: 6| Step: 12
Training loss: 3.2038728166690116
Validation loss: 2.6886785603025936

Epoch: 6| Step: 13
Training loss: 3.3433946081944192
Validation loss: 2.694716047194633

Epoch: 107| Step: 0
Training loss: 2.808272681633096
Validation loss: 2.694574391919938

Epoch: 6| Step: 1
Training loss: 3.322956208538895
Validation loss: 2.6937976110515542

Epoch: 6| Step: 2
Training loss: 3.1297226887180223
Validation loss: 2.693915897858105

Epoch: 6| Step: 3
Training loss: 2.76399027469652
Validation loss: 2.694551393427214

Epoch: 6| Step: 4
Training loss: 3.2365731403838534
Validation loss: 2.694244212054557

Epoch: 6| Step: 5
Training loss: 2.8653553610171407
Validation loss: 2.6893513172655523

Epoch: 6| Step: 6
Training loss: 3.265495772291702
Validation loss: 2.6873055626448994

Epoch: 6| Step: 7
Training loss: 3.0346924416375427
Validation loss: 2.6843195394675714

Epoch: 6| Step: 8
Training loss: 3.044602079402071
Validation loss: 2.6860000514970537

Epoch: 6| Step: 9
Training loss: 2.3682168164227284
Validation loss: 2.6828671029389604

Epoch: 6| Step: 10
Training loss: 2.6935005621250063
Validation loss: 2.6844108553076227

Epoch: 6| Step: 11
Training loss: 3.036119619925503
Validation loss: 2.6838756780441564

Epoch: 6| Step: 12
Training loss: 3.6354869555188283
Validation loss: 2.687569111047261

Epoch: 6| Step: 13
Training loss: 2.686913537199193
Validation loss: 2.6928941889413918

Epoch: 108| Step: 0
Training loss: 2.572235779237918
Validation loss: 2.702548824229475

Epoch: 6| Step: 1
Training loss: 3.550428450613019
Validation loss: 2.700381213568308

Epoch: 6| Step: 2
Training loss: 3.591275632124824
Validation loss: 2.7070308730819117

Epoch: 6| Step: 3
Training loss: 3.171350445147155
Validation loss: 2.7152709785309646

Epoch: 6| Step: 4
Training loss: 2.642673668328924
Validation loss: 2.720201260792392

Epoch: 6| Step: 5
Training loss: 3.188071704531958
Validation loss: 2.729010244879659

Epoch: 6| Step: 6
Training loss: 3.039968948707609
Validation loss: 2.735834936841338

Epoch: 6| Step: 7
Training loss: 3.0720526736035194
Validation loss: 2.727451239676072

Epoch: 6| Step: 8
Training loss: 2.379968966434009
Validation loss: 2.727289279438179

Epoch: 6| Step: 9
Training loss: 2.7778972176198593
Validation loss: 2.723715417914575

Epoch: 6| Step: 10
Training loss: 3.645619384300894
Validation loss: 2.723199562255238

Epoch: 6| Step: 11
Training loss: 2.6446611606350507
Validation loss: 2.703183354351237

Epoch: 6| Step: 12
Training loss: 2.712851516518641
Validation loss: 2.6894586107757785

Epoch: 6| Step: 13
Training loss: 2.7574983153074344
Validation loss: 2.6829993453690726

Epoch: 109| Step: 0
Training loss: 3.5555374638441535
Validation loss: 2.683120690859382

Epoch: 6| Step: 1
Training loss: 3.190911206776022
Validation loss: 2.680045281540252

Epoch: 6| Step: 2
Training loss: 2.745924443849569
Validation loss: 2.679754712642414

Epoch: 6| Step: 3
Training loss: 3.189717288270131
Validation loss: 2.6784094071107845

Epoch: 6| Step: 4
Training loss: 3.126100270172075
Validation loss: 2.6787983159836304

Epoch: 6| Step: 5
Training loss: 2.5541362576025386
Validation loss: 2.677034686842686

Epoch: 6| Step: 6
Training loss: 3.295531229544017
Validation loss: 2.678599179383424

Epoch: 6| Step: 7
Training loss: 2.2956494026330696
Validation loss: 2.679208526669616

Epoch: 6| Step: 8
Training loss: 3.162490868837948
Validation loss: 2.6765386168412864

Epoch: 6| Step: 9
Training loss: 3.0691030512885535
Validation loss: 2.6782333459510954

Epoch: 6| Step: 10
Training loss: 2.562534611165838
Validation loss: 2.676437617668128

Epoch: 6| Step: 11
Training loss: 3.04609020592013
Validation loss: 2.683514558173818

Epoch: 6| Step: 12
Training loss: 3.3744218119104885
Validation loss: 2.683533552923148

Epoch: 6| Step: 13
Training loss: 2.4971295089776446
Validation loss: 2.6822480139728033

Epoch: 110| Step: 0
Training loss: 3.315006819037649
Validation loss: 2.688582841084343

Epoch: 6| Step: 1
Training loss: 2.6769368370336597
Validation loss: 2.6981644356110945

Epoch: 6| Step: 2
Training loss: 3.1692325503007415
Validation loss: 2.7091005423449763

Epoch: 6| Step: 3
Training loss: 3.1206341573381065
Validation loss: 2.7130718462584955

Epoch: 6| Step: 4
Training loss: 2.875691206397304
Validation loss: 2.7214741272924154

Epoch: 6| Step: 5
Training loss: 2.883349691649616
Validation loss: 2.7132547882832387

Epoch: 6| Step: 6
Training loss: 2.644168079406701
Validation loss: 2.6973714717503534

Epoch: 6| Step: 7
Training loss: 3.4534551540327736
Validation loss: 2.6967724151981303

Epoch: 6| Step: 8
Training loss: 3.206653865489932
Validation loss: 2.6890767149573858

Epoch: 6| Step: 9
Training loss: 2.8737556418305013
Validation loss: 2.678979468296129

Epoch: 6| Step: 10
Training loss: 2.960754388869245
Validation loss: 2.6794190956564603

Epoch: 6| Step: 11
Training loss: 2.9284142741128067
Validation loss: 2.6749424194940845

Epoch: 6| Step: 12
Training loss: 2.493769702498922
Validation loss: 2.674636918763528

Epoch: 6| Step: 13
Training loss: 3.530748855003966
Validation loss: 2.6720874958301377

Epoch: 111| Step: 0
Training loss: 3.0206809871448908
Validation loss: 2.6707930322849296

Epoch: 6| Step: 1
Training loss: 2.8890006785486047
Validation loss: 2.672338984065621

Epoch: 6| Step: 2
Training loss: 2.41629034159651
Validation loss: 2.670935634959839

Epoch: 6| Step: 3
Training loss: 3.0408280840934956
Validation loss: 2.6713510088369437

Epoch: 6| Step: 4
Training loss: 3.247372371993655
Validation loss: 2.6713572237137564

Epoch: 6| Step: 5
Training loss: 2.9871658138282515
Validation loss: 2.67154977888426

Epoch: 6| Step: 6
Training loss: 2.7522492313749503
Validation loss: 2.670765890582046

Epoch: 6| Step: 7
Training loss: 3.206386338694436
Validation loss: 2.6720771859374195

Epoch: 6| Step: 8
Training loss: 3.2728266544376527
Validation loss: 2.6709343948608915

Epoch: 6| Step: 9
Training loss: 3.030743114131011
Validation loss: 2.673136650900813

Epoch: 6| Step: 10
Training loss: 3.066240789723861
Validation loss: 2.6779383376166197

Epoch: 6| Step: 11
Training loss: 2.8364960091608364
Validation loss: 2.6799813075447605

Epoch: 6| Step: 12
Training loss: 3.098846707083373
Validation loss: 2.6859474457642767

Epoch: 6| Step: 13
Training loss: 3.213350971484812
Validation loss: 2.6983279416256547

Epoch: 112| Step: 0
Training loss: 3.389480327282943
Validation loss: 2.7010829414614577

Epoch: 6| Step: 1
Training loss: 2.4492485373113877
Validation loss: 2.703206270869139

Epoch: 6| Step: 2
Training loss: 3.2587425313204803
Validation loss: 2.7101750018000637

Epoch: 6| Step: 3
Training loss: 2.8821823961514057
Validation loss: 2.7378736520320466

Epoch: 6| Step: 4
Training loss: 3.4277944706270427
Validation loss: 2.7518881508589224

Epoch: 6| Step: 5
Training loss: 3.2196464401332783
Validation loss: 2.7512681205561167

Epoch: 6| Step: 6
Training loss: 2.3972712859369265
Validation loss: 2.7286360267924077

Epoch: 6| Step: 7
Training loss: 2.3869273192931306
Validation loss: 2.7069400039861735

Epoch: 6| Step: 8
Training loss: 2.815451535587705
Validation loss: 2.694828784607291

Epoch: 6| Step: 9
Training loss: 3.5951792652919217
Validation loss: 2.6877852295913347

Epoch: 6| Step: 10
Training loss: 3.1444153947989806
Validation loss: 2.6838153688432764

Epoch: 6| Step: 11
Training loss: 2.7866911223432056
Validation loss: 2.686865866028696

Epoch: 6| Step: 12
Training loss: 3.1288654072318716
Validation loss: 2.6837819157901004

Epoch: 6| Step: 13
Training loss: 2.8386021225583677
Validation loss: 2.6808360050121838

Epoch: 113| Step: 0
Training loss: 2.818962978935929
Validation loss: 2.681020353976253

Epoch: 6| Step: 1
Training loss: 3.640714325034139
Validation loss: 2.6808776862397967

Epoch: 6| Step: 2
Training loss: 3.321243119812351
Validation loss: 2.6819819133636535

Epoch: 6| Step: 3
Training loss: 2.8085250739984637
Validation loss: 2.6782534071527433

Epoch: 6| Step: 4
Training loss: 2.684392862848927
Validation loss: 2.677642743388437

Epoch: 6| Step: 5
Training loss: 2.9317077994989655
Validation loss: 2.6728074598890523

Epoch: 6| Step: 6
Training loss: 3.077694625588124
Validation loss: 2.670084797519386

Epoch: 6| Step: 7
Training loss: 2.576785762776668
Validation loss: 2.667316183819598

Epoch: 6| Step: 8
Training loss: 2.506175805418202
Validation loss: 2.6730541905502503

Epoch: 6| Step: 9
Training loss: 3.3508947458610745
Validation loss: 2.673088267935867

Epoch: 6| Step: 10
Training loss: 3.720023057517509
Validation loss: 2.6790227755271903

Epoch: 6| Step: 11
Training loss: 2.7407549732667325
Validation loss: 2.68944971628295

Epoch: 6| Step: 12
Training loss: 2.7409419086400404
Validation loss: 2.714942022046868

Epoch: 6| Step: 13
Training loss: 2.9138394595126527
Validation loss: 2.7144348558998255

Epoch: 114| Step: 0
Training loss: 3.097843736937266
Validation loss: 2.7070899235738346

Epoch: 6| Step: 1
Training loss: 3.1503954684556694
Validation loss: 2.697437114684139

Epoch: 6| Step: 2
Training loss: 2.9521358387508205
Validation loss: 2.6854624664077886

Epoch: 6| Step: 3
Training loss: 2.465042323896256
Validation loss: 2.6802419079812174

Epoch: 6| Step: 4
Training loss: 3.0735827397606035
Validation loss: 2.675016158036646

Epoch: 6| Step: 5
Training loss: 2.6542918448719814
Validation loss: 2.6751599232301997

Epoch: 6| Step: 6
Training loss: 2.8678376918391666
Validation loss: 2.672969810419121

Epoch: 6| Step: 7
Training loss: 3.3799887626506293
Validation loss: 2.674083321722636

Epoch: 6| Step: 8
Training loss: 2.823224031013262
Validation loss: 2.676785938331429

Epoch: 6| Step: 9
Training loss: 3.113745603309446
Validation loss: 2.6736863928522987

Epoch: 6| Step: 10
Training loss: 2.943607231290291
Validation loss: 2.6768005044212244

Epoch: 6| Step: 11
Training loss: 2.5553961188112586
Validation loss: 2.677045482318275

Epoch: 6| Step: 12
Training loss: 3.344714159420434
Validation loss: 2.6826144509974763

Epoch: 6| Step: 13
Training loss: 3.7148350215131423
Validation loss: 2.6831186165337693

Epoch: 115| Step: 0
Training loss: 2.568449046379004
Validation loss: 2.6861771869213964

Epoch: 6| Step: 1
Training loss: 2.6761126904672903
Validation loss: 2.6882448235062792

Epoch: 6| Step: 2
Training loss: 3.1180761308753464
Validation loss: 2.6882866530648655

Epoch: 6| Step: 3
Training loss: 2.5789361775766992
Validation loss: 2.6849423835114807

Epoch: 6| Step: 4
Training loss: 2.895995723278618
Validation loss: 2.681998843775969

Epoch: 6| Step: 5
Training loss: 3.02020769327178
Validation loss: 2.6804696706067057

Epoch: 6| Step: 6
Training loss: 2.9543977447079715
Validation loss: 2.6679299756407993

Epoch: 6| Step: 7
Training loss: 2.8245937156533327
Validation loss: 2.6627610370149766

Epoch: 6| Step: 8
Training loss: 3.6499710290882574
Validation loss: 2.663523878091014

Epoch: 6| Step: 9
Training loss: 2.992628259292395
Validation loss: 2.6610113179143964

Epoch: 6| Step: 10
Training loss: 2.842805139541113
Validation loss: 2.663533782193362

Epoch: 6| Step: 11
Training loss: 3.2384307053776396
Validation loss: 2.66061564557321

Epoch: 6| Step: 12
Training loss: 3.1444624046229133
Validation loss: 2.6660368762753883

Epoch: 6| Step: 13
Training loss: 3.39024822057786
Validation loss: 2.6746787579385343

Epoch: 116| Step: 0
Training loss: 2.9282773298865563
Validation loss: 2.676064569192469

Epoch: 6| Step: 1
Training loss: 2.1744727098441436
Validation loss: 2.682123770607828

Epoch: 6| Step: 2
Training loss: 2.6478966804988677
Validation loss: 2.676999657987387

Epoch: 6| Step: 3
Training loss: 3.4700284784121314
Validation loss: 2.671684626319452

Epoch: 6| Step: 4
Training loss: 3.473713940093176
Validation loss: 2.6592859646717035

Epoch: 6| Step: 5
Training loss: 2.82055299531339
Validation loss: 2.6605922600715246

Epoch: 6| Step: 6
Training loss: 3.223738868815451
Validation loss: 2.6581061540384523

Epoch: 6| Step: 7
Training loss: 2.3225621065473216
Validation loss: 2.6554411658594503

Epoch: 6| Step: 8
Training loss: 3.639538254847185
Validation loss: 2.6574933263817426

Epoch: 6| Step: 9
Training loss: 2.371830984317847
Validation loss: 2.656419237839133

Epoch: 6| Step: 10
Training loss: 3.094355052004571
Validation loss: 2.657450551959893

Epoch: 6| Step: 11
Training loss: 2.3896205013436536
Validation loss: 2.6581986625964067

Epoch: 6| Step: 12
Training loss: 3.702972795279896
Validation loss: 2.6560841044690764

Epoch: 6| Step: 13
Training loss: 3.1609689919321484
Validation loss: 2.6586412277028244

Epoch: 117| Step: 0
Training loss: 2.911912549413971
Validation loss: 2.661673852313654

Epoch: 6| Step: 1
Training loss: 3.0462439250298474
Validation loss: 2.6608704272681156

Epoch: 6| Step: 2
Training loss: 2.371868679354844
Validation loss: 2.658051649840143

Epoch: 6| Step: 3
Training loss: 3.3043520060475706
Validation loss: 2.6614911387409848

Epoch: 6| Step: 4
Training loss: 3.078230957686155
Validation loss: 2.6601293023789583

Epoch: 6| Step: 5
Training loss: 3.403311625706274
Validation loss: 2.660816002816724

Epoch: 6| Step: 6
Training loss: 3.171222337745728
Validation loss: 2.65882326066174

Epoch: 6| Step: 7
Training loss: 2.54722003120856
Validation loss: 2.6591477823103804

Epoch: 6| Step: 8
Training loss: 2.4795409382207714
Validation loss: 2.6560053346550436

Epoch: 6| Step: 9
Training loss: 3.2496669305179195
Validation loss: 2.658562889478209

Epoch: 6| Step: 10
Training loss: 3.1838516598943354
Validation loss: 2.6611936790939184

Epoch: 6| Step: 11
Training loss: 3.281894293608334
Validation loss: 2.664313575673352

Epoch: 6| Step: 12
Training loss: 2.792211640717375
Validation loss: 2.667482165521975

Epoch: 6| Step: 13
Training loss: 2.5769306537503645
Validation loss: 2.662628630934123

Epoch: 118| Step: 0
Training loss: 3.2316222339845964
Validation loss: 2.665071033757112

Epoch: 6| Step: 1
Training loss: 2.818653918741223
Validation loss: 2.668247458716248

Epoch: 6| Step: 2
Training loss: 2.8575336802075504
Validation loss: 2.6682276134076464

Epoch: 6| Step: 3
Training loss: 2.0715015379734023
Validation loss: 2.666941319698605

Epoch: 6| Step: 4
Training loss: 3.406399644836794
Validation loss: 2.6711841835107704

Epoch: 6| Step: 5
Training loss: 2.961133965488942
Validation loss: 2.6760252415357626

Epoch: 6| Step: 6
Training loss: 2.788590677139642
Validation loss: 2.7079160162124443

Epoch: 6| Step: 7
Training loss: 2.7288181189135416
Validation loss: 2.73298362572747

Epoch: 6| Step: 8
Training loss: 2.4540215087171875
Validation loss: 2.7350597362185303

Epoch: 6| Step: 9
Training loss: 3.681517322205774
Validation loss: 2.747458615810657

Epoch: 6| Step: 10
Training loss: 3.388083916481714
Validation loss: 2.702114168736063

Epoch: 6| Step: 11
Training loss: 3.3094521662114857
Validation loss: 2.6619803380275724

Epoch: 6| Step: 12
Training loss: 2.9385007411663113
Validation loss: 2.6490683276668294

Epoch: 6| Step: 13
Training loss: 2.8368469965717233
Validation loss: 2.6497394801326233

Epoch: 119| Step: 0
Training loss: 2.8728188243320396
Validation loss: 2.652530570132645

Epoch: 6| Step: 1
Training loss: 3.1118500793157913
Validation loss: 2.659955036368664

Epoch: 6| Step: 2
Training loss: 3.304095853324928
Validation loss: 2.6613312446826396

Epoch: 6| Step: 3
Training loss: 2.775381862725876
Validation loss: 2.6573414480197837

Epoch: 6| Step: 4
Training loss: 2.9241174262977743
Validation loss: 2.655659194282965

Epoch: 6| Step: 5
Training loss: 3.5000758844051134
Validation loss: 2.654763130723807

Epoch: 6| Step: 6
Training loss: 3.0669952410053734
Validation loss: 2.651327910731298

Epoch: 6| Step: 7
Training loss: 3.0343723536753875
Validation loss: 2.6470435977893074

Epoch: 6| Step: 8
Training loss: 3.1332039529047653
Validation loss: 2.648616534859657

Epoch: 6| Step: 9
Training loss: 2.6840539174015405
Validation loss: 2.651329765780166

Epoch: 6| Step: 10
Training loss: 2.9316313538223655
Validation loss: 2.6490233045673572

Epoch: 6| Step: 11
Training loss: 3.0035957404128424
Validation loss: 2.6523155312268853

Epoch: 6| Step: 12
Training loss: 3.006030696872058
Validation loss: 2.6578123025915255

Epoch: 6| Step: 13
Training loss: 2.1609662211971923
Validation loss: 2.6784012473911947

Epoch: 120| Step: 0
Training loss: 3.2033545435091786
Validation loss: 2.7032846108138355

Epoch: 6| Step: 1
Training loss: 2.8321925465920708
Validation loss: 2.7593009515791334

Epoch: 6| Step: 2
Training loss: 3.133958411938293
Validation loss: 2.7536716672834896

Epoch: 6| Step: 3
Training loss: 3.498589367656136
Validation loss: 2.680235839963792

Epoch: 6| Step: 4
Training loss: 2.95934887142389
Validation loss: 2.669966050239769

Epoch: 6| Step: 5
Training loss: 2.8989372542329184
Validation loss: 2.6538043833345992

Epoch: 6| Step: 6
Training loss: 2.610317950704851
Validation loss: 2.651453214262115

Epoch: 6| Step: 7
Training loss: 3.332413753186167
Validation loss: 2.647968733411268

Epoch: 6| Step: 8
Training loss: 2.8309288668035033
Validation loss: 2.650916308706858

Epoch: 6| Step: 9
Training loss: 2.7087880168618197
Validation loss: 2.6486022851491136

Epoch: 6| Step: 10
Training loss: 2.9484647279582914
Validation loss: 2.6531067754273985

Epoch: 6| Step: 11
Training loss: 2.847311619127927
Validation loss: 2.6568000759538077

Epoch: 6| Step: 12
Training loss: 2.779164507482358
Validation loss: 2.6558905148932137

Epoch: 6| Step: 13
Training loss: 3.4662426658687595
Validation loss: 2.669022161674266

Epoch: 121| Step: 0
Training loss: 2.7966936787909935
Validation loss: 2.6650131858556887

Epoch: 6| Step: 1
Training loss: 3.5016568213325483
Validation loss: 2.6556051051709537

Epoch: 6| Step: 2
Training loss: 2.7070814516110775
Validation loss: 2.6502194534884724

Epoch: 6| Step: 3
Training loss: 2.4763151701160386
Validation loss: 2.6446116266147413

Epoch: 6| Step: 4
Training loss: 2.9902869979244557
Validation loss: 2.643529771560965

Epoch: 6| Step: 5
Training loss: 3.1173233346814087
Validation loss: 2.6428211960355448

Epoch: 6| Step: 6
Training loss: 2.627884143220631
Validation loss: 2.6447324913289703

Epoch: 6| Step: 7
Training loss: 3.0363713683319076
Validation loss: 2.641689080560909

Epoch: 6| Step: 8
Training loss: 2.83187061775052
Validation loss: 2.6428923620165077

Epoch: 6| Step: 9
Training loss: 3.343827291290549
Validation loss: 2.6398331445796197

Epoch: 6| Step: 10
Training loss: 2.984542921844406
Validation loss: 2.638756047114528

Epoch: 6| Step: 11
Training loss: 2.525447647147223
Validation loss: 2.6454635379781415

Epoch: 6| Step: 12
Training loss: 3.666292662764129
Validation loss: 2.651228329397047

Epoch: 6| Step: 13
Training loss: 2.9759615394096426
Validation loss: 2.6725389564388666

Epoch: 122| Step: 0
Training loss: 3.6588995047189155
Validation loss: 2.6913869917138125

Epoch: 6| Step: 1
Training loss: 2.7843204651360955
Validation loss: 2.720058821549436

Epoch: 6| Step: 2
Training loss: 3.513763477431227
Validation loss: 2.7512737123018667

Epoch: 6| Step: 3
Training loss: 3.149944086940988
Validation loss: 2.726954605337142

Epoch: 6| Step: 4
Training loss: 2.702021202563289
Validation loss: 2.673065885399399

Epoch: 6| Step: 5
Training loss: 3.324953098970204
Validation loss: 2.649077855650016

Epoch: 6| Step: 6
Training loss: 3.0717054318324095
Validation loss: 2.637425944455964

Epoch: 6| Step: 7
Training loss: 2.8057440252756263
Validation loss: 2.63778860685252

Epoch: 6| Step: 8
Training loss: 3.020238480151815
Validation loss: 2.634491765266858

Epoch: 6| Step: 9
Training loss: 2.968525285749028
Validation loss: 2.6385860562597974

Epoch: 6| Step: 10
Training loss: 2.76075315523887
Validation loss: 2.6340461840366407

Epoch: 6| Step: 11
Training loss: 2.3432187304773455
Validation loss: 2.6385383008944325

Epoch: 6| Step: 12
Training loss: 2.857449242649186
Validation loss: 2.6376551133973343

Epoch: 6| Step: 13
Training loss: 2.449106995681068
Validation loss: 2.638548582493278

Epoch: 123| Step: 0
Training loss: 3.373149223078093
Validation loss: 2.6344491808162074

Epoch: 6| Step: 1
Training loss: 2.9622197658448823
Validation loss: 2.6391288148119934

Epoch: 6| Step: 2
Training loss: 2.6264001654316678
Validation loss: 2.639278832060601

Epoch: 6| Step: 3
Training loss: 2.590803471987531
Validation loss: 2.6358987796156357

Epoch: 6| Step: 4
Training loss: 3.1630663398590175
Validation loss: 2.638507157568518

Epoch: 6| Step: 5
Training loss: 3.0218604260066573
Validation loss: 2.6349215250097475

Epoch: 6| Step: 6
Training loss: 3.138469506738366
Validation loss: 2.636892203729503

Epoch: 6| Step: 7
Training loss: 3.5396372347374863
Validation loss: 2.635892315795141

Epoch: 6| Step: 8
Training loss: 2.8704050911976244
Validation loss: 2.6363526497663807

Epoch: 6| Step: 9
Training loss: 2.751534987251984
Validation loss: 2.635894413669404

Epoch: 6| Step: 10
Training loss: 2.386176764202164
Validation loss: 2.6352332827676905

Epoch: 6| Step: 11
Training loss: 2.9358327476406316
Validation loss: 2.636800710360596

Epoch: 6| Step: 12
Training loss: 2.9079228990557895
Validation loss: 2.635217899322149

Epoch: 6| Step: 13
Training loss: 3.4349704104819057
Validation loss: 2.638477899821537

Epoch: 124| Step: 0
Training loss: 2.8318345836886376
Validation loss: 2.636822028892844

Epoch: 6| Step: 1
Training loss: 2.935903074540804
Validation loss: 2.6332277277446945

Epoch: 6| Step: 2
Training loss: 2.9320241332888917
Validation loss: 2.6350191273617423

Epoch: 6| Step: 3
Training loss: 2.8151591975185073
Validation loss: 2.633793362827328

Epoch: 6| Step: 4
Training loss: 2.844648952715356
Validation loss: 2.6358190428173853

Epoch: 6| Step: 5
Training loss: 2.912824188657517
Validation loss: 2.6380165198133665

Epoch: 6| Step: 6
Training loss: 2.573693182727094
Validation loss: 2.6374361788740854

Epoch: 6| Step: 7
Training loss: 3.0479731219250508
Validation loss: 2.637806509979314

Epoch: 6| Step: 8
Training loss: 3.2762475527710926
Validation loss: 2.6394365566684486

Epoch: 6| Step: 9
Training loss: 3.218532221565427
Validation loss: 2.6376955370145447

Epoch: 6| Step: 10
Training loss: 3.3943177255916432
Validation loss: 2.646750607891963

Epoch: 6| Step: 11
Training loss: 2.8361010964026145
Validation loss: 2.6400104032471847

Epoch: 6| Step: 12
Training loss: 3.1660632177561023
Validation loss: 2.6342748596927223

Epoch: 6| Step: 13
Training loss: 2.5423806443607755
Validation loss: 2.632932111855933

Epoch: 125| Step: 0
Training loss: 2.923403416673979
Validation loss: 2.6356081288504307

Epoch: 6| Step: 1
Training loss: 2.877873187486195
Validation loss: 2.6335502480135373

Epoch: 6| Step: 2
Training loss: 3.354352452284272
Validation loss: 2.647043130007614

Epoch: 6| Step: 3
Training loss: 3.0482040245476605
Validation loss: 2.6470459405704982

Epoch: 6| Step: 4
Training loss: 3.2957539030808793
Validation loss: 2.6538079634197955

Epoch: 6| Step: 5
Training loss: 3.163530319104753
Validation loss: 2.6574120582504075

Epoch: 6| Step: 6
Training loss: 2.833799286469685
Validation loss: 2.65505137607558

Epoch: 6| Step: 7
Training loss: 2.3149862584804093
Validation loss: 2.639896080329385

Epoch: 6| Step: 8
Training loss: 3.177405585950493
Validation loss: 2.6323992801493543

Epoch: 6| Step: 9
Training loss: 2.680151718456952
Validation loss: 2.6346051112279834

Epoch: 6| Step: 10
Training loss: 3.288121757164933
Validation loss: 2.6334066498647486

Epoch: 6| Step: 11
Training loss: 2.5247903038046617
Validation loss: 2.635506753201753

Epoch: 6| Step: 12
Training loss: 3.3253339786156726
Validation loss: 2.6377786070563163

Epoch: 6| Step: 13
Training loss: 2.4398244875960726
Validation loss: 2.6470955520345583

Epoch: 126| Step: 0
Training loss: 3.180774549767744
Validation loss: 2.652068547846574

Epoch: 6| Step: 1
Training loss: 2.564571380793972
Validation loss: 2.653262072165493

Epoch: 6| Step: 2
Training loss: 2.8737969576602698
Validation loss: 2.65206104126099

Epoch: 6| Step: 3
Training loss: 3.132655570268783
Validation loss: 2.6458118048009975

Epoch: 6| Step: 4
Training loss: 2.760248594145671
Validation loss: 2.639573024271172

Epoch: 6| Step: 5
Training loss: 2.70485530445116
Validation loss: 2.639443110879985

Epoch: 6| Step: 6
Training loss: 2.9363237014296697
Validation loss: 2.6429043799684657

Epoch: 6| Step: 7
Training loss: 2.720751935160919
Validation loss: 2.65724123001897

Epoch: 6| Step: 8
Training loss: 2.9112990625226587
Validation loss: 2.6698807784178524

Epoch: 6| Step: 9
Training loss: 3.109172105159892
Validation loss: 2.673464176007995

Epoch: 6| Step: 10
Training loss: 2.559336034829828
Validation loss: 2.6866233189441973

Epoch: 6| Step: 11
Training loss: 3.751341134896128
Validation loss: 2.6796398122124576

Epoch: 6| Step: 12
Training loss: 3.1045245960580337
Validation loss: 2.6630251545884436

Epoch: 6| Step: 13
Training loss: 3.341869645521969
Validation loss: 2.656400801970162

Epoch: 127| Step: 0
Training loss: 2.950650909510463
Validation loss: 2.638756666953007

Epoch: 6| Step: 1
Training loss: 2.9655606454794685
Validation loss: 2.6273617001396805

Epoch: 6| Step: 2
Training loss: 2.964210653749947
Validation loss: 2.6282512474935014

Epoch: 6| Step: 3
Training loss: 2.926267861006636
Validation loss: 2.626900322484052

Epoch: 6| Step: 4
Training loss: 3.1456653137473607
Validation loss: 2.626098805206215

Epoch: 6| Step: 5
Training loss: 2.1986365081140655
Validation loss: 2.626503265406503

Epoch: 6| Step: 6
Training loss: 2.6774638656329275
Validation loss: 2.6247426564632774

Epoch: 6| Step: 7
Training loss: 3.4071197799170707
Validation loss: 2.625940234570456

Epoch: 6| Step: 8
Training loss: 3.0490802316090444
Validation loss: 2.6263049193462273

Epoch: 6| Step: 9
Training loss: 3.1312973658468426
Validation loss: 2.6247862871935994

Epoch: 6| Step: 10
Training loss: 2.803936786118638
Validation loss: 2.6251471185744597

Epoch: 6| Step: 11
Training loss: 3.483759941248402
Validation loss: 2.625405857882806

Epoch: 6| Step: 12
Training loss: 2.5629739090525065
Validation loss: 2.624138035744767

Epoch: 6| Step: 13
Training loss: 3.1355218373315172
Validation loss: 2.6242616623929496

Epoch: 128| Step: 0
Training loss: 2.337807203699116
Validation loss: 2.6259266535693984

Epoch: 6| Step: 1
Training loss: 3.1184412985018892
Validation loss: 2.628524863047138

Epoch: 6| Step: 2
Training loss: 3.0830412202220683
Validation loss: 2.630459028829738

Epoch: 6| Step: 3
Training loss: 2.8675472023495336
Validation loss: 2.644245227906424

Epoch: 6| Step: 4
Training loss: 3.329492708806861
Validation loss: 2.6566446608308785

Epoch: 6| Step: 5
Training loss: 2.6324487995265753
Validation loss: 2.6709741439688615

Epoch: 6| Step: 6
Training loss: 3.13823491338396
Validation loss: 2.664139772932267

Epoch: 6| Step: 7
Training loss: 2.379245978089565
Validation loss: 2.650833542049553

Epoch: 6| Step: 8
Training loss: 2.6622764887592156
Validation loss: 2.6550203588568886

Epoch: 6| Step: 9
Training loss: 3.7313409075373585
Validation loss: 2.650116324275679

Epoch: 6| Step: 10
Training loss: 2.8275913135411868
Validation loss: 2.6375196196364805

Epoch: 6| Step: 11
Training loss: 2.6079165100237383
Validation loss: 2.630988158069133

Epoch: 6| Step: 12
Training loss: 3.0359138711666525
Validation loss: 2.6276336443542054

Epoch: 6| Step: 13
Training loss: 3.7299328803602068
Validation loss: 2.6239197437572095

Epoch: 129| Step: 0
Training loss: 3.0728662174200054
Validation loss: 2.620555347469335

Epoch: 6| Step: 1
Training loss: 3.6334973417823297
Validation loss: 2.621381898188756

Epoch: 6| Step: 2
Training loss: 2.225530981077459
Validation loss: 2.622927231656463

Epoch: 6| Step: 3
Training loss: 2.7111067045763124
Validation loss: 2.622346970081067

Epoch: 6| Step: 4
Training loss: 2.762727501938887
Validation loss: 2.6194819392036095

Epoch: 6| Step: 5
Training loss: 3.1736603020533862
Validation loss: 2.6181318249250207

Epoch: 6| Step: 6
Training loss: 2.808343656013451
Validation loss: 2.6197573954090734

Epoch: 6| Step: 7
Training loss: 3.052225745375401
Validation loss: 2.618268436551315

Epoch: 6| Step: 8
Training loss: 2.511645278923979
Validation loss: 2.617880474162504

Epoch: 6| Step: 9
Training loss: 2.9138716975277617
Validation loss: 2.6162424648037197

Epoch: 6| Step: 10
Training loss: 3.1236616702068476
Validation loss: 2.6172669120866243

Epoch: 6| Step: 11
Training loss: 2.6940219609102485
Validation loss: 2.618334660549891

Epoch: 6| Step: 12
Training loss: 3.244502038821895
Validation loss: 2.617096472675316

Epoch: 6| Step: 13
Training loss: 3.5082950387587832
Validation loss: 2.6163129711559385

Epoch: 130| Step: 0
Training loss: 3.0822199967949366
Validation loss: 2.6216039952429626

Epoch: 6| Step: 1
Training loss: 3.155942694178782
Validation loss: 2.6183328540892137

Epoch: 6| Step: 2
Training loss: 2.5435268182347412
Validation loss: 2.6198710236282925

Epoch: 6| Step: 3
Training loss: 3.111050101847615
Validation loss: 2.6231731849572437

Epoch: 6| Step: 4
Training loss: 2.984803493555581
Validation loss: 2.62428377638005

Epoch: 6| Step: 5
Training loss: 2.7873156123053806
Validation loss: 2.6317925746273096

Epoch: 6| Step: 6
Training loss: 2.585447236115269
Validation loss: 2.63644349746211

Epoch: 6| Step: 7
Training loss: 3.1769593928608404
Validation loss: 2.63350886420205

Epoch: 6| Step: 8
Training loss: 2.473888795109604
Validation loss: 2.625742784250661

Epoch: 6| Step: 9
Training loss: 2.884151984920202
Validation loss: 2.628245119917509

Epoch: 6| Step: 10
Training loss: 2.835416047046901
Validation loss: 2.6297581203997176

Epoch: 6| Step: 11
Training loss: 2.8286272309043436
Validation loss: 2.622622676685806

Epoch: 6| Step: 12
Training loss: 2.977999122737348
Validation loss: 2.6200772783802444

Epoch: 6| Step: 13
Training loss: 4.3015537382425295
Validation loss: 2.6155062108416023

Epoch: 131| Step: 0
Training loss: 2.3883352845692656
Validation loss: 2.6174960037083252

Epoch: 6| Step: 1
Training loss: 2.6556633694184852
Validation loss: 2.6148257745963535

Epoch: 6| Step: 2
Training loss: 3.2173235056263705
Validation loss: 2.615259080674707

Epoch: 6| Step: 3
Training loss: 2.83646390038564
Validation loss: 2.6317302760193795

Epoch: 6| Step: 4
Training loss: 3.423599853565896
Validation loss: 2.622239455858838

Epoch: 6| Step: 5
Training loss: 3.4687175577382092
Validation loss: 2.637335541782537

Epoch: 6| Step: 6
Training loss: 3.2849920823743557
Validation loss: 2.642074310530397

Epoch: 6| Step: 7
Training loss: 3.4054368474646997
Validation loss: 2.633681969625777

Epoch: 6| Step: 8
Training loss: 2.7838420148012717
Validation loss: 2.629567677926128

Epoch: 6| Step: 9
Training loss: 2.0011691014309543
Validation loss: 2.620826577612302

Epoch: 6| Step: 10
Training loss: 2.780833781098202
Validation loss: 2.6242224473890596

Epoch: 6| Step: 11
Training loss: 2.8096825793035145
Validation loss: 2.619810000374038

Epoch: 6| Step: 12
Training loss: 3.0337592681755767
Validation loss: 2.61667881250812

Epoch: 6| Step: 13
Training loss: 2.953981951349142
Validation loss: 2.6150091047086725

Epoch: 132| Step: 0
Training loss: 3.3598921976506904
Validation loss: 2.615623980512511

Epoch: 6| Step: 1
Training loss: 3.2235989388272546
Validation loss: 2.6129247109889366

Epoch: 6| Step: 2
Training loss: 3.350242372541567
Validation loss: 2.6111958874034134

Epoch: 6| Step: 3
Training loss: 3.0409892821595053
Validation loss: 2.6096723236194355

Epoch: 6| Step: 4
Training loss: 3.039207317755782
Validation loss: 2.611989579637865

Epoch: 6| Step: 5
Training loss: 2.7750426039990828
Validation loss: 2.614758110667941

Epoch: 6| Step: 6
Training loss: 2.172725593258632
Validation loss: 2.6157040702688774

Epoch: 6| Step: 7
Training loss: 3.0660005143097346
Validation loss: 2.6147957459661453

Epoch: 6| Step: 8
Training loss: 2.9103128890310996
Validation loss: 2.6146911930914047

Epoch: 6| Step: 9
Training loss: 3.4656451652084654
Validation loss: 2.6160050658606933

Epoch: 6| Step: 10
Training loss: 2.8282440329102405
Validation loss: 2.611633000734204

Epoch: 6| Step: 11
Training loss: 2.7439732836543236
Validation loss: 2.61187549664606

Epoch: 6| Step: 12
Training loss: 2.4054235054560738
Validation loss: 2.6208159741176096

Epoch: 6| Step: 13
Training loss: 2.3939435278048746
Validation loss: 2.6202381312770218

Epoch: 133| Step: 0
Training loss: 2.413837903880146
Validation loss: 2.628164283738121

Epoch: 6| Step: 1
Training loss: 3.3025660277356623
Validation loss: 2.6217188253865507

Epoch: 6| Step: 2
Training loss: 2.863676244284622
Validation loss: 2.6218822381320344

Epoch: 6| Step: 3
Training loss: 2.8345345213559825
Validation loss: 2.6204225619665267

Epoch: 6| Step: 4
Training loss: 2.979229230601714
Validation loss: 2.6356480766105

Epoch: 6| Step: 5
Training loss: 3.230400850442715
Validation loss: 2.634656298787353

Epoch: 6| Step: 6
Training loss: 3.0880334617205114
Validation loss: 2.6436356901964593

Epoch: 6| Step: 7
Training loss: 3.1860816642319114
Validation loss: 2.613994856877298

Epoch: 6| Step: 8
Training loss: 2.6517089623467336
Validation loss: 2.6145062502437626

Epoch: 6| Step: 9
Training loss: 2.8985737154228515
Validation loss: 2.606954749892662

Epoch: 6| Step: 10
Training loss: 2.4811784825239585
Validation loss: 2.611630438695304

Epoch: 6| Step: 11
Training loss: 2.871270788015361
Validation loss: 2.6164956856096335

Epoch: 6| Step: 12
Training loss: 3.271601997652294
Validation loss: 2.6141581042266853

Epoch: 6| Step: 13
Training loss: 3.3565220273274066
Validation loss: 2.617339169584793

Epoch: 134| Step: 0
Training loss: 2.554063446630977
Validation loss: 2.6156784082940425

Epoch: 6| Step: 1
Training loss: 3.6165764376962515
Validation loss: 2.613332824821038

Epoch: 6| Step: 2
Training loss: 2.9465939595097317
Validation loss: 2.6141879832750785

Epoch: 6| Step: 3
Training loss: 3.2338536528795156
Validation loss: 2.611882407607113

Epoch: 6| Step: 4
Training loss: 3.065624900452343
Validation loss: 2.6127589443690447

Epoch: 6| Step: 5
Training loss: 3.355928009897886
Validation loss: 2.6131446042743

Epoch: 6| Step: 6
Training loss: 3.4793685732673016
Validation loss: 2.618752647917606

Epoch: 6| Step: 7
Training loss: 2.8294187505569792
Validation loss: 2.628020070353514

Epoch: 6| Step: 8
Training loss: 2.2332296570394012
Validation loss: 2.6584183202718754

Epoch: 6| Step: 9
Training loss: 2.893140533398973
Validation loss: 2.6843682423995205

Epoch: 6| Step: 10
Training loss: 1.9634064712999084
Validation loss: 2.726144658202515

Epoch: 6| Step: 11
Training loss: 2.3238629750023803
Validation loss: 2.7202745697897384

Epoch: 6| Step: 12
Training loss: 3.60202135981825
Validation loss: 2.7146784802558592

Epoch: 6| Step: 13
Training loss: 2.9886622765660795
Validation loss: 2.6969295155457598

Epoch: 135| Step: 0
Training loss: 3.6417143014779274
Validation loss: 2.651891412185005

Epoch: 6| Step: 1
Training loss: 2.8917425521289006
Validation loss: 2.6214995104913643

Epoch: 6| Step: 2
Training loss: 2.8664435063225935
Validation loss: 2.6174000917724802

Epoch: 6| Step: 3
Training loss: 3.1942638364589078
Validation loss: 2.6169698596249256

Epoch: 6| Step: 4
Training loss: 3.1613949680838798
Validation loss: 2.612008386874075

Epoch: 6| Step: 5
Training loss: 2.649597364103462
Validation loss: 2.609603029892909

Epoch: 6| Step: 6
Training loss: 2.5750914325962233
Validation loss: 2.609630235982441

Epoch: 6| Step: 7
Training loss: 3.2101509263158583
Validation loss: 2.610996803654968

Epoch: 6| Step: 8
Training loss: 2.6650225120581275
Validation loss: 2.6129305889821706

Epoch: 6| Step: 9
Training loss: 3.1787128876242097
Validation loss: 2.6086160441381674

Epoch: 6| Step: 10
Training loss: 2.3799759788262653
Validation loss: 2.604881433326866

Epoch: 6| Step: 11
Training loss: 3.133745848778865
Validation loss: 2.6039985126637104

Epoch: 6| Step: 12
Training loss: 2.730218136355137
Validation loss: 2.6045521670260445

Epoch: 6| Step: 13
Training loss: 2.7658849044486615
Validation loss: 2.6029349293999493

Epoch: 136| Step: 0
Training loss: 2.8476318023427587
Validation loss: 2.6067080717866324

Epoch: 6| Step: 1
Training loss: 3.335717080045961
Validation loss: 2.609069774928145

Epoch: 6| Step: 2
Training loss: 2.627679093461165
Validation loss: 2.6145439842788747

Epoch: 6| Step: 3
Training loss: 2.656899585955607
Validation loss: 2.620078493137968

Epoch: 6| Step: 4
Training loss: 3.2715852363183346
Validation loss: 2.6345551429203504

Epoch: 6| Step: 5
Training loss: 3.435687610374247
Validation loss: 2.6547840558712736

Epoch: 6| Step: 6
Training loss: 3.226491562476861
Validation loss: 2.6541893259270783

Epoch: 6| Step: 7
Training loss: 2.83080135605518
Validation loss: 2.6632933302118573

Epoch: 6| Step: 8
Training loss: 3.5375283391781163
Validation loss: 2.672283373356231

Epoch: 6| Step: 9
Training loss: 1.9414950989438584
Validation loss: 2.66308647755101

Epoch: 6| Step: 10
Training loss: 2.9258845760501497
Validation loss: 2.6393286740281185

Epoch: 6| Step: 11
Training loss: 3.0842388644800107
Validation loss: 2.622470339013944

Epoch: 6| Step: 12
Training loss: 2.395438739513232
Validation loss: 2.6085585668506517

Epoch: 6| Step: 13
Training loss: 2.5825129303511547
Validation loss: 2.6023258369298623

Epoch: 137| Step: 0
Training loss: 2.2558517654092434
Validation loss: 2.599679876865711

Epoch: 6| Step: 1
Training loss: 2.8951314903533394
Validation loss: 2.5979562479305383

Epoch: 6| Step: 2
Training loss: 3.1020977797896663
Validation loss: 2.5998169315103645

Epoch: 6| Step: 3
Training loss: 2.6668450375347335
Validation loss: 2.5961306316895705

Epoch: 6| Step: 4
Training loss: 3.6139496056273614
Validation loss: 2.6012206479488196

Epoch: 6| Step: 5
Training loss: 2.421111940338349
Validation loss: 2.600675432206069

Epoch: 6| Step: 6
Training loss: 2.79400231504242
Validation loss: 2.6003984929601014

Epoch: 6| Step: 7
Training loss: 3.3930816891587208
Validation loss: 2.5997123541003333

Epoch: 6| Step: 8
Training loss: 3.285780331439491
Validation loss: 2.598216989514305

Epoch: 6| Step: 9
Training loss: 2.990434656094837
Validation loss: 2.601503294101356

Epoch: 6| Step: 10
Training loss: 2.8351982561385944
Validation loss: 2.6060867237178806

Epoch: 6| Step: 11
Training loss: 2.5456740467376977
Validation loss: 2.6045809259196075

Epoch: 6| Step: 12
Training loss: 3.286292570178669
Validation loss: 2.604245663008723

Epoch: 6| Step: 13
Training loss: 2.7403060675315083
Validation loss: 2.6112562548825595

Epoch: 138| Step: 0
Training loss: 3.066310147279874
Validation loss: 2.6138457943822377

Epoch: 6| Step: 1
Training loss: 2.7524061946839655
Validation loss: 2.616139828679254

Epoch: 6| Step: 2
Training loss: 2.5894491548115024
Validation loss: 2.6127505442972323

Epoch: 6| Step: 3
Training loss: 3.0019952179160967
Validation loss: 2.6163948828959183

Epoch: 6| Step: 4
Training loss: 2.4071426717443587
Validation loss: 2.628798065887523

Epoch: 6| Step: 5
Training loss: 3.098060764295558
Validation loss: 2.6172169933025575

Epoch: 6| Step: 6
Training loss: 3.3889558260895822
Validation loss: 2.6180763152049726

Epoch: 6| Step: 7
Training loss: 3.1260319341101064
Validation loss: 2.608003845196344

Epoch: 6| Step: 8
Training loss: 2.618553055889139
Validation loss: 2.6042009419472385

Epoch: 6| Step: 9
Training loss: 2.318268874602593
Validation loss: 2.6046731731101165

Epoch: 6| Step: 10
Training loss: 3.427859433927694
Validation loss: 2.5967498947392147

Epoch: 6| Step: 11
Training loss: 2.9897144745209627
Validation loss: 2.5992979090513515

Epoch: 6| Step: 12
Training loss: 3.232796398950585
Validation loss: 2.5983292914154976

Epoch: 6| Step: 13
Training loss: 2.8955333380514854
Validation loss: 2.602538747282809

Epoch: 139| Step: 0
Training loss: 2.906155164258288
Validation loss: 2.597791077498594

Epoch: 6| Step: 1
Training loss: 2.876125612913971
Validation loss: 2.599733605001344

Epoch: 6| Step: 2
Training loss: 3.007336546656925
Validation loss: 2.5979416364706007

Epoch: 6| Step: 3
Training loss: 2.7504232254339236
Validation loss: 2.596692041260504

Epoch: 6| Step: 4
Training loss: 3.043693250561828
Validation loss: 2.5995587990980136

Epoch: 6| Step: 5
Training loss: 2.9686881611055385
Validation loss: 2.5983710924641557

Epoch: 6| Step: 6
Training loss: 2.280839229859979
Validation loss: 2.6014157416766293

Epoch: 6| Step: 7
Training loss: 2.6523626267852753
Validation loss: 2.603525778058732

Epoch: 6| Step: 8
Training loss: 3.41137310047788
Validation loss: 2.6147444186422564

Epoch: 6| Step: 9
Training loss: 3.1628400536859584
Validation loss: 2.6294512162306534

Epoch: 6| Step: 10
Training loss: 3.5021426590511275
Validation loss: 2.650344033178264

Epoch: 6| Step: 11
Training loss: 2.8414981855487014
Validation loss: 2.6206260175670137

Epoch: 6| Step: 12
Training loss: 2.483408998023653
Validation loss: 2.6064738124821685

Epoch: 6| Step: 13
Training loss: 3.161614269116669
Validation loss: 2.5986238054254134

Epoch: 140| Step: 0
Training loss: 2.861205302131398
Validation loss: 2.593698802788158

Epoch: 6| Step: 1
Training loss: 2.6289775322918625
Validation loss: 2.592221197586365

Epoch: 6| Step: 2
Training loss: 3.109892988909075
Validation loss: 2.5945382075158987

Epoch: 6| Step: 3
Training loss: 3.118814985251842
Validation loss: 2.5954319195196645

Epoch: 6| Step: 4
Training loss: 3.109694881374863
Validation loss: 2.595017925958228

Epoch: 6| Step: 5
Training loss: 2.517866948194649
Validation loss: 2.595831905160428

Epoch: 6| Step: 6
Training loss: 2.8127658294511693
Validation loss: 2.595671371927098

Epoch: 6| Step: 7
Training loss: 2.6062173525734535
Validation loss: 2.593542779383186

Epoch: 6| Step: 8
Training loss: 3.2618780953779445
Validation loss: 2.5938488886682904

Epoch: 6| Step: 9
Training loss: 3.046540070733994
Validation loss: 2.5926561575677582

Epoch: 6| Step: 10
Training loss: 3.1291730864586396
Validation loss: 2.5933901224193274

Epoch: 6| Step: 11
Training loss: 2.3853901912991287
Validation loss: 2.5944687319100774

Epoch: 6| Step: 12
Training loss: 3.2781124554767724
Validation loss: 2.5940986840739604

Epoch: 6| Step: 13
Training loss: 3.36794419426794
Validation loss: 2.6009149114619285

Epoch: 141| Step: 0
Training loss: 2.8170429414801377
Validation loss: 2.604928974106608

Epoch: 6| Step: 1
Training loss: 2.7800393201942617
Validation loss: 2.6067331100385904

Epoch: 6| Step: 2
Training loss: 3.105970195855708
Validation loss: 2.6524690243891933

Epoch: 6| Step: 3
Training loss: 2.875188738391285
Validation loss: 2.661819082615965

Epoch: 6| Step: 4
Training loss: 3.359560939167422
Validation loss: 2.6810351408947493

Epoch: 6| Step: 5
Training loss: 2.4104106651325954
Validation loss: 2.6494117789028104

Epoch: 6| Step: 6
Training loss: 2.8535500484533856
Validation loss: 2.61799591220066

Epoch: 6| Step: 7
Training loss: 3.416276925040541
Validation loss: 2.5915252815011156

Epoch: 6| Step: 8
Training loss: 3.1415971608319335
Validation loss: 2.5909523532061574

Epoch: 6| Step: 9
Training loss: 2.7141255478462
Validation loss: 2.5866481398264773

Epoch: 6| Step: 10
Training loss: 2.494377489425652
Validation loss: 2.5883632369060177

Epoch: 6| Step: 11
Training loss: 2.869152258634515
Validation loss: 2.591627845859852

Epoch: 6| Step: 12
Training loss: 3.3497278131393213
Validation loss: 2.5915991420579565

Epoch: 6| Step: 13
Training loss: 2.863415307709706
Validation loss: 2.5958183394670122

Epoch: 142| Step: 0
Training loss: 2.8186356481122354
Validation loss: 2.5940713042217323

Epoch: 6| Step: 1
Training loss: 2.85871104051658
Validation loss: 2.5946280664411385

Epoch: 6| Step: 2
Training loss: 3.178750989811031
Validation loss: 2.5964665435433116

Epoch: 6| Step: 3
Training loss: 2.90479545700445
Validation loss: 2.598227491845667

Epoch: 6| Step: 4
Training loss: 2.607201681947824
Validation loss: 2.5920647568810162

Epoch: 6| Step: 5
Training loss: 3.2622384211299433
Validation loss: 2.589401667433587

Epoch: 6| Step: 6
Training loss: 2.773969658315081
Validation loss: 2.5867723233284976

Epoch: 6| Step: 7
Training loss: 2.171762587018894
Validation loss: 2.586025466416615

Epoch: 6| Step: 8
Training loss: 3.2219270008230807
Validation loss: 2.586412671235768

Epoch: 6| Step: 9
Training loss: 3.310503087837267
Validation loss: 2.588245029123655

Epoch: 6| Step: 10
Training loss: 3.070195863173004
Validation loss: 2.5981784184402374

Epoch: 6| Step: 11
Training loss: 2.495745949550163
Validation loss: 2.602446706170087

Epoch: 6| Step: 12
Training loss: 3.0862695442900328
Validation loss: 2.616741410674436

Epoch: 6| Step: 13
Training loss: 3.6286145309617335
Validation loss: 2.6485826062521793

Epoch: 143| Step: 0
Training loss: 2.5924832111576492
Validation loss: 2.6616241542770807

Epoch: 6| Step: 1
Training loss: 3.071726698996849
Validation loss: 2.6916028889514845

Epoch: 6| Step: 2
Training loss: 3.188981254323971
Validation loss: 2.662570210995196

Epoch: 6| Step: 3
Training loss: 3.4018543123495415
Validation loss: 2.6575877151519838

Epoch: 6| Step: 4
Training loss: 2.6106854648725077
Validation loss: 2.6361525406114334

Epoch: 6| Step: 5
Training loss: 3.401013750523511
Validation loss: 2.6205704520911

Epoch: 6| Step: 6
Training loss: 2.8429524068213263
Validation loss: 2.5974135655668107

Epoch: 6| Step: 7
Training loss: 3.6032218503218365
Validation loss: 2.584184515971317

Epoch: 6| Step: 8
Training loss: 3.1236609069404206
Validation loss: 2.5829065713334014

Epoch: 6| Step: 9
Training loss: 2.3828229059711306
Validation loss: 2.580443384020531

Epoch: 6| Step: 10
Training loss: 2.7519808484231665
Validation loss: 2.582565214924001

Epoch: 6| Step: 11
Training loss: 2.9222106740777347
Validation loss: 2.580675595530895

Epoch: 6| Step: 12
Training loss: 2.5085364511908383
Validation loss: 2.5809077662823445

Epoch: 6| Step: 13
Training loss: 1.8718691435707961
Validation loss: 2.582340858288534

Epoch: 144| Step: 0
Training loss: 3.156858177887922
Validation loss: 2.5877782069202797

Epoch: 6| Step: 1
Training loss: 2.294820684271742
Validation loss: 2.5886041968720184

Epoch: 6| Step: 2
Training loss: 2.4725785326081255
Validation loss: 2.5816879536960022

Epoch: 6| Step: 3
Training loss: 2.9729311762034425
Validation loss: 2.585403459113345

Epoch: 6| Step: 4
Training loss: 2.789048908104355
Validation loss: 2.5828782460434243

Epoch: 6| Step: 5
Training loss: 3.1932744099457464
Validation loss: 2.5825996763013923

Epoch: 6| Step: 6
Training loss: 3.0825176362881272
Validation loss: 2.5819677566913657

Epoch: 6| Step: 7
Training loss: 2.9148895480919483
Validation loss: 2.5812213321162396

Epoch: 6| Step: 8
Training loss: 3.448116346648827
Validation loss: 2.591112130046342

Epoch: 6| Step: 9
Training loss: 2.9243408242870386
Validation loss: 2.5872761339486314

Epoch: 6| Step: 10
Training loss: 3.422489616205529
Validation loss: 2.61735338381133

Epoch: 6| Step: 11
Training loss: 2.428280438292375
Validation loss: 2.6228266487572687

Epoch: 6| Step: 12
Training loss: 3.0747203296545234
Validation loss: 2.638104989616709

Epoch: 6| Step: 13
Training loss: 2.051187529510523
Validation loss: 2.6564548449637937

Epoch: 145| Step: 0
Training loss: 3.028649856857728
Validation loss: 2.7400149934827165

Epoch: 6| Step: 1
Training loss: 2.9672854374717037
Validation loss: 2.7763199913241876

Epoch: 6| Step: 2
Training loss: 2.294249714564023
Validation loss: 2.8414559282177283

Epoch: 6| Step: 3
Training loss: 3.5168684053333767
Validation loss: 2.8111416762263755

Epoch: 6| Step: 4
Training loss: 2.6029083161769444
Validation loss: 2.6997708953388857

Epoch: 6| Step: 5
Training loss: 2.9794150473462113
Validation loss: 2.624549245929973

Epoch: 6| Step: 6
Training loss: 3.0435520930249482
Validation loss: 2.5896292464785944

Epoch: 6| Step: 7
Training loss: 2.177654672028021
Validation loss: 2.5792434518602727

Epoch: 6| Step: 8
Training loss: 2.78236572517444
Validation loss: 2.584161285028546

Epoch: 6| Step: 9
Training loss: 3.3520052246198704
Validation loss: 2.59459472177051

Epoch: 6| Step: 10
Training loss: 3.2819910575005644
Validation loss: 2.6045157371290624

Epoch: 6| Step: 11
Training loss: 2.93375758946611
Validation loss: 2.619197762401607

Epoch: 6| Step: 12
Training loss: 3.4960131417470484
Validation loss: 2.6294683298539674

Epoch: 6| Step: 13
Training loss: 2.0637879251822784
Validation loss: 2.6476272503716154

Epoch: 146| Step: 0
Training loss: 3.0864473718420005
Validation loss: 2.716458016581698

Epoch: 6| Step: 1
Training loss: 3.4142868003227846
Validation loss: 2.6829831761301084

Epoch: 6| Step: 2
Training loss: 2.859944271264951
Validation loss: 2.6495190042464314

Epoch: 6| Step: 3
Training loss: 2.3988645092705614
Validation loss: 2.6108358311233606

Epoch: 6| Step: 4
Training loss: 3.0121992348866726
Validation loss: 2.5966353505118467

Epoch: 6| Step: 5
Training loss: 2.9722686795637476
Validation loss: 2.5818153487051925

Epoch: 6| Step: 6
Training loss: 2.9621333221268418
Validation loss: 2.5761724352613458

Epoch: 6| Step: 7
Training loss: 3.245361539335193
Validation loss: 2.589678489807095

Epoch: 6| Step: 8
Training loss: 2.6951929038230937
Validation loss: 2.6104685256987343

Epoch: 6| Step: 9
Training loss: 2.6256416989680567
Validation loss: 2.6195747460030283

Epoch: 6| Step: 10
Training loss: 3.0379931767721695
Validation loss: 2.6354862226491607

Epoch: 6| Step: 11
Training loss: 3.1168503351882153
Validation loss: 2.644331149952392

Epoch: 6| Step: 12
Training loss: 3.2856656835053455
Validation loss: 2.6511249029133412

Epoch: 6| Step: 13
Training loss: 2.7231509663637654
Validation loss: 2.655299600226112

Epoch: 147| Step: 0
Training loss: 2.8299069349535237
Validation loss: 2.6444688801971994

Epoch: 6| Step: 1
Training loss: 2.8235423015318966
Validation loss: 2.6349934423707175

Epoch: 6| Step: 2
Training loss: 3.3201187615811905
Validation loss: 2.614558101921736

Epoch: 6| Step: 3
Training loss: 2.8747140493409975
Validation loss: 2.593068093147041

Epoch: 6| Step: 4
Training loss: 2.76067042114118
Validation loss: 2.5833179716221792

Epoch: 6| Step: 5
Training loss: 3.185799238451746
Validation loss: 2.580301089704427

Epoch: 6| Step: 6
Training loss: 2.811332799524129
Validation loss: 2.5776933235934343

Epoch: 6| Step: 7
Training loss: 2.7271768047341163
Validation loss: 2.5763903318611416

Epoch: 6| Step: 8
Training loss: 3.5001845992316936
Validation loss: 2.5783413425534363

Epoch: 6| Step: 9
Training loss: 2.6086085672977366
Validation loss: 2.5760961510252796

Epoch: 6| Step: 10
Training loss: 2.7004308780609545
Validation loss: 2.574308655952853

Epoch: 6| Step: 11
Training loss: 2.7748445621980977
Validation loss: 2.575901695915727

Epoch: 6| Step: 12
Training loss: 3.0347424081402115
Validation loss: 2.574494704502227

Epoch: 6| Step: 13
Training loss: 3.1631025200244554
Validation loss: 2.5741779858771574

Epoch: 148| Step: 0
Training loss: 2.4097272840502293
Validation loss: 2.5731610391390163

Epoch: 6| Step: 1
Training loss: 3.304112305420482
Validation loss: 2.5714422837971105

Epoch: 6| Step: 2
Training loss: 2.587184547692642
Validation loss: 2.5737778304091457

Epoch: 6| Step: 3
Training loss: 3.3721801845968575
Validation loss: 2.58077085974624

Epoch: 6| Step: 4
Training loss: 2.8620601199464675
Validation loss: 2.57710592166306

Epoch: 6| Step: 5
Training loss: 3.3597460164851873
Validation loss: 2.5780917774892607

Epoch: 6| Step: 6
Training loss: 3.777779239454797
Validation loss: 2.591698974364741

Epoch: 6| Step: 7
Training loss: 2.977038888530555
Validation loss: 2.6096547009837416

Epoch: 6| Step: 8
Training loss: 2.6682759634502697
Validation loss: 2.615804419375277

Epoch: 6| Step: 9
Training loss: 2.9653033678041023
Validation loss: 2.6421416775744704

Epoch: 6| Step: 10
Training loss: 3.012668880303415
Validation loss: 2.6793063365725795

Epoch: 6| Step: 11
Training loss: 2.841088359378479
Validation loss: 2.63110316863121

Epoch: 6| Step: 12
Training loss: 2.225154927035487
Validation loss: 2.6022046566695494

Epoch: 6| Step: 13
Training loss: 1.3868658283303419
Validation loss: 2.587329241770699

Epoch: 149| Step: 0
Training loss: 2.810461365099474
Validation loss: 2.579508947255972

Epoch: 6| Step: 1
Training loss: 2.9665228269474504
Validation loss: 2.575563947508214

Epoch: 6| Step: 2
Training loss: 3.0664945747629786
Validation loss: 2.5675879768096994

Epoch: 6| Step: 3
Training loss: 2.747873437718342
Validation loss: 2.5693100209443918

Epoch: 6| Step: 4
Training loss: 2.213017755477703
Validation loss: 2.567223905533491

Epoch: 6| Step: 5
Training loss: 2.8443572685009215
Validation loss: 2.5690615414047615

Epoch: 6| Step: 6
Training loss: 2.8173386383560333
Validation loss: 2.5736253079790212

Epoch: 6| Step: 7
Training loss: 3.4005607198716055
Validation loss: 2.5688811095845296

Epoch: 6| Step: 8
Training loss: 2.927343137530794
Validation loss: 2.5681183712729143

Epoch: 6| Step: 9
Training loss: 3.105213850584421
Validation loss: 2.5722940292806467

Epoch: 6| Step: 10
Training loss: 3.3251641942835413
Validation loss: 2.575027465514542

Epoch: 6| Step: 11
Training loss: 2.8002464390342023
Validation loss: 2.5839403658562867

Epoch: 6| Step: 12
Training loss: 2.654876353802469
Validation loss: 2.588703656450748

Epoch: 6| Step: 13
Training loss: 3.0948884969170716
Validation loss: 2.586482002450295

Epoch: 150| Step: 0
Training loss: 2.8741503579582206
Validation loss: 2.590504336005211

Epoch: 6| Step: 1
Training loss: 2.8943940206062124
Validation loss: 2.5908827062432644

Epoch: 6| Step: 2
Training loss: 2.9737497090631755
Validation loss: 2.591144200188096

Epoch: 6| Step: 3
Training loss: 2.1457628281747754
Validation loss: 2.5858193845695454

Epoch: 6| Step: 4
Training loss: 2.7376752718899344
Validation loss: 2.5967664321068025

Epoch: 6| Step: 5
Training loss: 2.725486564943228
Validation loss: 2.5942592622510303

Epoch: 6| Step: 6
Training loss: 3.777258413429795
Validation loss: 2.5909876707082593

Epoch: 6| Step: 7
Training loss: 2.6094554957234615
Validation loss: 2.5780172246566324

Epoch: 6| Step: 8
Training loss: 2.1983588860072443
Validation loss: 2.5745650317824667

Epoch: 6| Step: 9
Training loss: 3.0287158244019707
Validation loss: 2.5682669574416583

Epoch: 6| Step: 10
Training loss: 2.8859535204448408
Validation loss: 2.5696740001809073

Epoch: 6| Step: 11
Training loss: 3.3419492632189507
Validation loss: 2.564585355682214

Epoch: 6| Step: 12
Training loss: 2.947223882967327
Validation loss: 2.563602849471868

Epoch: 6| Step: 13
Training loss: 3.6881921409568297
Validation loss: 2.5632719612410217

Epoch: 151| Step: 0
Training loss: 2.6733902767075066
Validation loss: 2.564116349613121

Epoch: 6| Step: 1
Training loss: 2.754086838881642
Validation loss: 2.566082565751266

Epoch: 6| Step: 2
Training loss: 3.2236643191337486
Validation loss: 2.565502551615863

Epoch: 6| Step: 3
Training loss: 3.0700142984958148
Validation loss: 2.5635485370960254

Epoch: 6| Step: 4
Training loss: 3.1818831077986407
Validation loss: 2.5640750009524043

Epoch: 6| Step: 5
Training loss: 2.9851044567240375
Validation loss: 2.5652564075683277

Epoch: 6| Step: 6
Training loss: 2.4919507144383286
Validation loss: 2.5656180181547317

Epoch: 6| Step: 7
Training loss: 3.408565049506362
Validation loss: 2.5638564186690367

Epoch: 6| Step: 8
Training loss: 2.7131222762643623
Validation loss: 2.565807037392487

Epoch: 6| Step: 9
Training loss: 3.0779102850834463
Validation loss: 2.5691032498714983

Epoch: 6| Step: 10
Training loss: 3.052601602099051
Validation loss: 2.574049644188377

Epoch: 6| Step: 11
Training loss: 2.363736699882381
Validation loss: 2.5714428062072634

Epoch: 6| Step: 12
Training loss: 2.738341152607981
Validation loss: 2.5783184069705545

Epoch: 6| Step: 13
Training loss: 2.9834773925722557
Validation loss: 2.5804112226127884

Epoch: 152| Step: 0
Training loss: 3.0227277055637054
Validation loss: 2.585999591219383

Epoch: 6| Step: 1
Training loss: 2.8340725401947524
Validation loss: 2.587212399754134

Epoch: 6| Step: 2
Training loss: 3.04528516715062
Validation loss: 2.5823235425380826

Epoch: 6| Step: 3
Training loss: 3.1876151868165694
Validation loss: 2.5859416181794685

Epoch: 6| Step: 4
Training loss: 3.4017154012650166
Validation loss: 2.5890003724831385

Epoch: 6| Step: 5
Training loss: 2.295362947972988
Validation loss: 2.5913626839140935

Epoch: 6| Step: 6
Training loss: 3.305331552931519
Validation loss: 2.5905486660988117

Epoch: 6| Step: 7
Training loss: 2.774543305353818
Validation loss: 2.590406686389515

Epoch: 6| Step: 8
Training loss: 2.8284470179887293
Validation loss: 2.582087742123865

Epoch: 6| Step: 9
Training loss: 2.80336286031056
Validation loss: 2.574494314154869

Epoch: 6| Step: 10
Training loss: 3.2122981026582504
Validation loss: 2.5730019769021997

Epoch: 6| Step: 11
Training loss: 2.6246566547916306
Validation loss: 2.5658912488465786

Epoch: 6| Step: 12
Training loss: 2.4143385250961447
Validation loss: 2.5643483260716797

Epoch: 6| Step: 13
Training loss: 2.712189926496243
Validation loss: 2.560357205093066

Epoch: 153| Step: 0
Training loss: 2.4680314768819556
Validation loss: 2.5612161833399933

Epoch: 6| Step: 1
Training loss: 3.248232727789349
Validation loss: 2.569576601552167

Epoch: 6| Step: 2
Training loss: 2.2106098700629264
Validation loss: 2.5661404499616625

Epoch: 6| Step: 3
Training loss: 2.742397115580579
Validation loss: 2.565942006783837

Epoch: 6| Step: 4
Training loss: 3.8147743820330224
Validation loss: 2.56724507985013

Epoch: 6| Step: 5
Training loss: 3.3263685579326783
Validation loss: 2.5718976386252135

Epoch: 6| Step: 6
Training loss: 2.6277698254168103
Validation loss: 2.577151128320675

Epoch: 6| Step: 7
Training loss: 2.2299217181300417
Validation loss: 2.5835555728926236

Epoch: 6| Step: 8
Training loss: 2.506119771794116
Validation loss: 2.595330128788874

Epoch: 6| Step: 9
Training loss: 3.219018128717621
Validation loss: 2.6064546810576488

Epoch: 6| Step: 10
Training loss: 2.9197778366438167
Validation loss: 2.634049864944807

Epoch: 6| Step: 11
Training loss: 3.055808093491482
Validation loss: 2.64090791756898

Epoch: 6| Step: 12
Training loss: 2.736085019145902
Validation loss: 2.6480472872663587

Epoch: 6| Step: 13
Training loss: 3.2060900850924368
Validation loss: 2.6413053298897085

Epoch: 154| Step: 0
Training loss: 2.742851155280208
Validation loss: 2.6384348219790303

Epoch: 6| Step: 1
Training loss: 2.667653636279781
Validation loss: 2.626511864534219

Epoch: 6| Step: 2
Training loss: 3.476142497891796
Validation loss: 2.599860232116938

Epoch: 6| Step: 3
Training loss: 3.0822354673311736
Validation loss: 2.594544671601144

Epoch: 6| Step: 4
Training loss: 2.2480277848613857
Validation loss: 2.589044180753936

Epoch: 6| Step: 5
Training loss: 2.6087285685881296
Validation loss: 2.57342889742003

Epoch: 6| Step: 6
Training loss: 2.8652380362749272
Validation loss: 2.5627524839040348

Epoch: 6| Step: 7
Training loss: 3.1617589029449356
Validation loss: 2.556855703248234

Epoch: 6| Step: 8
Training loss: 1.8797223069669637
Validation loss: 2.560673036144948

Epoch: 6| Step: 9
Training loss: 2.920325536479396
Validation loss: 2.5565484947833585

Epoch: 6| Step: 10
Training loss: 3.0100853197545994
Validation loss: 2.5562290220776056

Epoch: 6| Step: 11
Training loss: 3.593114514762747
Validation loss: 2.5579234026853968

Epoch: 6| Step: 12
Training loss: 3.2798243740793023
Validation loss: 2.5571494999760085

Epoch: 6| Step: 13
Training loss: 2.4801499049196205
Validation loss: 2.559977167183755

Epoch: 155| Step: 0
Training loss: 3.0558822129703134
Validation loss: 2.559553647987391

Epoch: 6| Step: 1
Training loss: 3.1233436772661376
Validation loss: 2.5644202502081574

Epoch: 6| Step: 2
Training loss: 2.3081597502773272
Validation loss: 2.5728778790519553

Epoch: 6| Step: 3
Training loss: 3.2970552078822157
Validation loss: 2.5731519179953106

Epoch: 6| Step: 4
Training loss: 2.899942423807991
Validation loss: 2.58748637500925

Epoch: 6| Step: 5
Training loss: 3.054708729545794
Validation loss: 2.610761981588475

Epoch: 6| Step: 6
Training loss: 3.482502113226628
Validation loss: 2.621892535179753

Epoch: 6| Step: 7
Training loss: 3.0727855244902145
Validation loss: 2.6252448855984074

Epoch: 6| Step: 8
Training loss: 2.4894824040808707
Validation loss: 2.5800510117010234

Epoch: 6| Step: 9
Training loss: 2.9151679593570945
Validation loss: 2.5706382116458424

Epoch: 6| Step: 10
Training loss: 2.016884107400707
Validation loss: 2.5595558755376113

Epoch: 6| Step: 11
Training loss: 2.8939275897180377
Validation loss: 2.5520689266786825

Epoch: 6| Step: 12
Training loss: 2.931175078062864
Validation loss: 2.5536757318971093

Epoch: 6| Step: 13
Training loss: 3.0028074162099063
Validation loss: 2.5542779038251244

Epoch: 156| Step: 0
Training loss: 3.1776435900042683
Validation loss: 2.5594751000619964

Epoch: 6| Step: 1
Training loss: 2.8607654630227604
Validation loss: 2.5575175113664073

Epoch: 6| Step: 2
Training loss: 2.9120024489402954
Validation loss: 2.5592590534147788

Epoch: 6| Step: 3
Training loss: 2.7832224848559126
Validation loss: 2.5544608092936607

Epoch: 6| Step: 4
Training loss: 2.331360993798374
Validation loss: 2.554756182944972

Epoch: 6| Step: 5
Training loss: 2.6584835759420193
Validation loss: 2.5527615826024244

Epoch: 6| Step: 6
Training loss: 3.5190792492080982
Validation loss: 2.5506036761281528

Epoch: 6| Step: 7
Training loss: 3.031190851951924
Validation loss: 2.5541968133903747

Epoch: 6| Step: 8
Training loss: 2.8597391865923774
Validation loss: 2.5505379038104716

Epoch: 6| Step: 9
Training loss: 2.928448305632142
Validation loss: 2.5546309804909484

Epoch: 6| Step: 10
Training loss: 2.806091807097266
Validation loss: 2.5580381480136136

Epoch: 6| Step: 11
Training loss: 3.064582272513643
Validation loss: 2.5656850235965605

Epoch: 6| Step: 12
Training loss: 2.641338274627459
Validation loss: 2.576331418178304

Epoch: 6| Step: 13
Training loss: 3.054609448930918
Validation loss: 2.572742410589185

Epoch: 157| Step: 0
Training loss: 3.208459793835233
Validation loss: 2.583231123755724

Epoch: 6| Step: 1
Training loss: 2.728417145597763
Validation loss: 2.5928442280699096

Epoch: 6| Step: 2
Training loss: 2.6572594014991213
Validation loss: 2.5840847108228093

Epoch: 6| Step: 3
Training loss: 2.6529914166325668
Validation loss: 2.5939728776652653

Epoch: 6| Step: 4
Training loss: 2.801520384404404
Validation loss: 2.599963277205623

Epoch: 6| Step: 5
Training loss: 3.3776079627343902
Validation loss: 2.6002658592507837

Epoch: 6| Step: 6
Training loss: 3.2083545700625438
Validation loss: 2.596200167492759

Epoch: 6| Step: 7
Training loss: 3.017248477645567
Validation loss: 2.5947673990037257

Epoch: 6| Step: 8
Training loss: 2.872504602599544
Validation loss: 2.5930015234217296

Epoch: 6| Step: 9
Training loss: 3.054128922614785
Validation loss: 2.5969970059042873

Epoch: 6| Step: 10
Training loss: 3.046157048074778
Validation loss: 2.5979150451196693

Epoch: 6| Step: 11
Training loss: 2.1434065296178644
Validation loss: 2.596767042223179

Epoch: 6| Step: 12
Training loss: 2.6578211905882867
Validation loss: 2.6081771198624697

Epoch: 6| Step: 13
Training loss: 2.877473513483796
Validation loss: 2.5947952279638793

Epoch: 158| Step: 0
Training loss: 2.913792329183716
Validation loss: 2.5838136381943917

Epoch: 6| Step: 1
Training loss: 2.595889943721527
Validation loss: 2.5725150218103967

Epoch: 6| Step: 2
Training loss: 2.258266310970034
Validation loss: 2.562002584429853

Epoch: 6| Step: 3
Training loss: 2.602710184336685
Validation loss: 2.5599250201347337

Epoch: 6| Step: 4
Training loss: 3.234520360656426
Validation loss: 2.5546118306191437

Epoch: 6| Step: 5
Training loss: 2.4998983362507676
Validation loss: 2.549576960343905

Epoch: 6| Step: 6
Training loss: 3.5408172636025816
Validation loss: 2.5539274770733207

Epoch: 6| Step: 7
Training loss: 2.863783476162233
Validation loss: 2.5527820092032707

Epoch: 6| Step: 8
Training loss: 2.6486148381008348
Validation loss: 2.5582802496621615

Epoch: 6| Step: 9
Training loss: 2.7728102283603904
Validation loss: 2.5611549256763397

Epoch: 6| Step: 10
Training loss: 3.0437404060604223
Validation loss: 2.5596994422687707

Epoch: 6| Step: 11
Training loss: 2.8071461051802875
Validation loss: 2.5604442711260433

Epoch: 6| Step: 12
Training loss: 3.473861914139758
Validation loss: 2.5647576833862775

Epoch: 6| Step: 13
Training loss: 3.1354520337379714
Validation loss: 2.5595559216110217

Epoch: 159| Step: 0
Training loss: 2.8558477940753084
Validation loss: 2.5628877081850066

Epoch: 6| Step: 1
Training loss: 2.8921890563795785
Validation loss: 2.575336031398737

Epoch: 6| Step: 2
Training loss: 2.2964467797768386
Validation loss: 2.5748146091145037

Epoch: 6| Step: 3
Training loss: 3.2755461026381254
Validation loss: 2.5764875982830513

Epoch: 6| Step: 4
Training loss: 2.8339633428212494
Validation loss: 2.587565229331927

Epoch: 6| Step: 5
Training loss: 2.6066595327502466
Validation loss: 2.580598283093249

Epoch: 6| Step: 6
Training loss: 3.1444169112558837
Validation loss: 2.6053350105909163

Epoch: 6| Step: 7
Training loss: 2.6831642484604457
Validation loss: 2.5970585765490366

Epoch: 6| Step: 8
Training loss: 2.913153867220467
Validation loss: 2.583552799435959

Epoch: 6| Step: 9
Training loss: 2.8582007493242143
Validation loss: 2.5856455664248177

Epoch: 6| Step: 10
Training loss: 3.1812088159919374
Validation loss: 2.5777785529887023

Epoch: 6| Step: 11
Training loss: 3.3881725811920216
Validation loss: 2.569707366438415

Epoch: 6| Step: 12
Training loss: 2.6999397694969294
Validation loss: 2.5636167146387354

Epoch: 6| Step: 13
Training loss: 2.431644939127699
Validation loss: 2.561441096175567

Epoch: 160| Step: 0
Training loss: 2.878080127875724
Validation loss: 2.560931378177763

Epoch: 6| Step: 1
Training loss: 2.9434321140750734
Validation loss: 2.5489497327556165

Epoch: 6| Step: 2
Training loss: 3.0873051570308685
Validation loss: 2.5516536505792575

Epoch: 6| Step: 3
Training loss: 2.4400144470287435
Validation loss: 2.557607874601797

Epoch: 6| Step: 4
Training loss: 3.1186379330363194
Validation loss: 2.5611470830601313

Epoch: 6| Step: 5
Training loss: 2.3961082853579745
Validation loss: 2.5594138603250745

Epoch: 6| Step: 6
Training loss: 2.870685491275444
Validation loss: 2.5807925894564154

Epoch: 6| Step: 7
Training loss: 2.849268160099491
Validation loss: 2.5852031883950466

Epoch: 6| Step: 8
Training loss: 3.0889053173527854
Validation loss: 2.602194611752328

Epoch: 6| Step: 9
Training loss: 2.4969473321055617
Validation loss: 2.5984756182886044

Epoch: 6| Step: 10
Training loss: 2.7589288888790886
Validation loss: 2.607177078881847

Epoch: 6| Step: 11
Training loss: 3.430714377477604
Validation loss: 2.5904457314368683

Epoch: 6| Step: 12
Training loss: 3.464773149426921
Validation loss: 2.5845315455420677

Epoch: 6| Step: 13
Training loss: 1.7860448449582402
Validation loss: 2.56828699320701

Epoch: 161| Step: 0
Training loss: 3.408957429064468
Validation loss: 2.5504808626392528

Epoch: 6| Step: 1
Training loss: 2.749109297338128
Validation loss: 2.553363650838718

Epoch: 6| Step: 2
Training loss: 3.4808994630378716
Validation loss: 2.5516430771184195

Epoch: 6| Step: 3
Training loss: 2.312124479579295
Validation loss: 2.5445066555952547

Epoch: 6| Step: 4
Training loss: 2.7066808696743747
Validation loss: 2.545953612757881

Epoch: 6| Step: 5
Training loss: 2.6115983639151517
Validation loss: 2.550004204528032

Epoch: 6| Step: 6
Training loss: 3.457669818759669
Validation loss: 2.5521413917458595

Epoch: 6| Step: 7
Training loss: 2.8416023948165323
Validation loss: 2.5549511632463533

Epoch: 6| Step: 8
Training loss: 2.1681467893885076
Validation loss: 2.5583429269496203

Epoch: 6| Step: 9
Training loss: 3.030018664513439
Validation loss: 2.566482352771976

Epoch: 6| Step: 10
Training loss: 3.1038152167189548
Validation loss: 2.5710232298090783

Epoch: 6| Step: 11
Training loss: 2.8948771775830173
Validation loss: 2.5873407048239248

Epoch: 6| Step: 12
Training loss: 2.7468528946300617
Validation loss: 2.5834028874407506

Epoch: 6| Step: 13
Training loss: 2.600987276285943
Validation loss: 2.575298804956463

Epoch: 162| Step: 0
Training loss: 2.5636705655756216
Validation loss: 2.571667224391461

Epoch: 6| Step: 1
Training loss: 2.3313221324571223
Validation loss: 2.5819364522911736

Epoch: 6| Step: 2
Training loss: 3.146954587140232
Validation loss: 2.575563903711907

Epoch: 6| Step: 3
Training loss: 2.9517551050304363
Validation loss: 2.5703616815335004

Epoch: 6| Step: 4
Training loss: 2.604384532716029
Validation loss: 2.560360808705927

Epoch: 6| Step: 5
Training loss: 2.3058200962728495
Validation loss: 2.5657152313292815

Epoch: 6| Step: 6
Training loss: 3.193338320601464
Validation loss: 2.551555356092802

Epoch: 6| Step: 7
Training loss: 3.0197684329348506
Validation loss: 2.5534952891636578

Epoch: 6| Step: 8
Training loss: 3.0843238957740753
Validation loss: 2.5602256472223113

Epoch: 6| Step: 9
Training loss: 3.2431559759290183
Validation loss: 2.560787195751166

Epoch: 6| Step: 10
Training loss: 2.95397323455772
Validation loss: 2.570683887564402

Epoch: 6| Step: 11
Training loss: 2.78550497603156
Validation loss: 2.563392341726459

Epoch: 6| Step: 12
Training loss: 2.9164383026822374
Validation loss: 2.5813113502180425

Epoch: 6| Step: 13
Training loss: 3.0139481225665548
Validation loss: 2.5923680531712674

Epoch: 163| Step: 0
Training loss: 2.8421191894643654
Validation loss: 2.618456798878612

Epoch: 6| Step: 1
Training loss: 3.2525721421916427
Validation loss: 2.635831436838098

Epoch: 6| Step: 2
Training loss: 3.200675213626043
Validation loss: 2.6400016315376855

Epoch: 6| Step: 3
Training loss: 3.194964177702429
Validation loss: 2.616848921543832

Epoch: 6| Step: 4
Training loss: 2.7191354763320383
Validation loss: 2.578124251230379

Epoch: 6| Step: 5
Training loss: 3.0744572974673425
Validation loss: 2.561177211187542

Epoch: 6| Step: 6
Training loss: 2.95013890343498
Validation loss: 2.5561366533710155

Epoch: 6| Step: 7
Training loss: 3.1300452132204417
Validation loss: 2.546454602223313

Epoch: 6| Step: 8
Training loss: 2.6823485927034763
Validation loss: 2.542964324309679

Epoch: 6| Step: 9
Training loss: 2.8353578589902186
Validation loss: 2.5452725233246296

Epoch: 6| Step: 10
Training loss: 2.116042048990162
Validation loss: 2.5395695389424606

Epoch: 6| Step: 11
Training loss: 2.73868565423296
Validation loss: 2.5433068509782717

Epoch: 6| Step: 12
Training loss: 2.528320689696766
Validation loss: 2.544343129889965

Epoch: 6| Step: 13
Training loss: 3.198995170186562
Validation loss: 2.544729972616953

Epoch: 164| Step: 0
Training loss: 2.853948227442873
Validation loss: 2.5572626559896365

Epoch: 6| Step: 1
Training loss: 2.8712355805742016
Validation loss: 2.567461416555673

Epoch: 6| Step: 2
Training loss: 3.167000468546451
Validation loss: 2.5855543269524386

Epoch: 6| Step: 3
Training loss: 2.8824555297491488
Validation loss: 2.5589592965681636

Epoch: 6| Step: 4
Training loss: 2.362605024960221
Validation loss: 2.5524457358200117

Epoch: 6| Step: 5
Training loss: 2.719611546603026
Validation loss: 2.549414992701859

Epoch: 6| Step: 6
Training loss: 1.707624179686588
Validation loss: 2.5523782432049904

Epoch: 6| Step: 7
Training loss: 3.104770183566125
Validation loss: 2.5583447406970485

Epoch: 6| Step: 8
Training loss: 2.7101569467402356
Validation loss: 2.5632198342147383

Epoch: 6| Step: 9
Training loss: 2.8548521532034528
Validation loss: 2.565443991477978

Epoch: 6| Step: 10
Training loss: 3.31372939993759
Validation loss: 2.575528469269511

Epoch: 6| Step: 11
Training loss: 3.5128663493076626
Validation loss: 2.593426573171433

Epoch: 6| Step: 12
Training loss: 2.848622099418491
Validation loss: 2.5885107520915698

Epoch: 6| Step: 13
Training loss: 3.0046292192715383
Validation loss: 2.606181142688304

Epoch: 165| Step: 0
Training loss: 3.091004665957446
Validation loss: 2.603329247155069

Epoch: 6| Step: 1
Training loss: 2.6102156512738146
Validation loss: 2.595854808958393

Epoch: 6| Step: 2
Training loss: 2.9679247863678455
Validation loss: 2.586574338100974

Epoch: 6| Step: 3
Training loss: 2.7314129289787967
Validation loss: 2.567289031677688

Epoch: 6| Step: 4
Training loss: 3.0641260306830036
Validation loss: 2.5677402338520205

Epoch: 6| Step: 5
Training loss: 3.118418973735241
Validation loss: 2.5475072618848116

Epoch: 6| Step: 6
Training loss: 2.47429285832805
Validation loss: 2.5464295139145356

Epoch: 6| Step: 7
Training loss: 2.920376153520597
Validation loss: 2.544925833903399

Epoch: 6| Step: 8
Training loss: 3.506471645265059
Validation loss: 2.5525918215847185

Epoch: 6| Step: 9
Training loss: 2.7980717490801568
Validation loss: 2.5492341025606087

Epoch: 6| Step: 10
Training loss: 2.9161533085588203
Validation loss: 2.553027762342911

Epoch: 6| Step: 11
Training loss: 2.7154831826214827
Validation loss: 2.561518841700412

Epoch: 6| Step: 12
Training loss: 2.814814653545323
Validation loss: 2.569591688574619

Epoch: 6| Step: 13
Training loss: 2.232070694983101
Validation loss: 2.5665860497298434

Epoch: 166| Step: 0
Training loss: 2.140206177663768
Validation loss: 2.5778691109817395

Epoch: 6| Step: 1
Training loss: 2.4105582373435825
Validation loss: 2.567513898800345

Epoch: 6| Step: 2
Training loss: 3.227322763648557
Validation loss: 2.585854724589881

Epoch: 6| Step: 3
Training loss: 3.1435147935007413
Validation loss: 2.575679958325194

Epoch: 6| Step: 4
Training loss: 2.2137618609842473
Validation loss: 2.5691761544894574

Epoch: 6| Step: 5
Training loss: 3.510424892215921
Validation loss: 2.5584590412678074

Epoch: 6| Step: 6
Training loss: 2.8462233634040754
Validation loss: 2.571877296064058

Epoch: 6| Step: 7
Training loss: 2.572602061034881
Validation loss: 2.5627061134200044

Epoch: 6| Step: 8
Training loss: 2.4070227236845905
Validation loss: 2.563695827156236

Epoch: 6| Step: 9
Training loss: 3.39473689502232
Validation loss: 2.5540540153805833

Epoch: 6| Step: 10
Training loss: 3.198835226505962
Validation loss: 2.563271421163297

Epoch: 6| Step: 11
Training loss: 2.757893158594954
Validation loss: 2.566886117415436

Epoch: 6| Step: 12
Training loss: 3.052594885198835
Validation loss: 2.5858978475642176

Epoch: 6| Step: 13
Training loss: 2.7558001127298803
Validation loss: 2.579432385014366

Epoch: 167| Step: 0
Training loss: 2.638738917946867
Validation loss: 2.5808357672134346

Epoch: 6| Step: 1
Training loss: 2.947496975160297
Validation loss: 2.5757878613222838

Epoch: 6| Step: 2
Training loss: 2.8900084791752065
Validation loss: 2.583751520241079

Epoch: 6| Step: 3
Training loss: 2.6893983390729788
Validation loss: 2.5820981988593434

Epoch: 6| Step: 4
Training loss: 2.9718788122880713
Validation loss: 2.5710975028468326

Epoch: 6| Step: 5
Training loss: 2.3616673531146546
Validation loss: 2.565562535349244

Epoch: 6| Step: 6
Training loss: 3.4193239500864445
Validation loss: 2.561450796479832

Epoch: 6| Step: 7
Training loss: 2.91977685676672
Validation loss: 2.565105190415358

Epoch: 6| Step: 8
Training loss: 2.7445647539786227
Validation loss: 2.5701682373838683

Epoch: 6| Step: 9
Training loss: 2.8551611362821085
Validation loss: 2.568226061915158

Epoch: 6| Step: 10
Training loss: 2.517876985388644
Validation loss: 2.5655367805276463

Epoch: 6| Step: 11
Training loss: 3.1630660383559
Validation loss: 2.5629467468445326

Epoch: 6| Step: 12
Training loss: 2.930745251759847
Validation loss: 2.5595036062217886

Epoch: 6| Step: 13
Training loss: 2.786439319201092
Validation loss: 2.5579353252464454

Epoch: 168| Step: 0
Training loss: 3.4390262336673225
Validation loss: 2.552678813025705

Epoch: 6| Step: 1
Training loss: 2.8800805024975777
Validation loss: 2.565937405909897

Epoch: 6| Step: 2
Training loss: 2.8820652600642207
Validation loss: 2.566250986793816

Epoch: 6| Step: 3
Training loss: 3.025665487433418
Validation loss: 2.563371025573327

Epoch: 6| Step: 4
Training loss: 2.426543430860158
Validation loss: 2.561370130306405

Epoch: 6| Step: 5
Training loss: 3.0207655975815513
Validation loss: 2.5675941732612833

Epoch: 6| Step: 6
Training loss: 2.52035854271528
Validation loss: 2.575091644649056

Epoch: 6| Step: 7
Training loss: 3.1673539737560685
Validation loss: 2.5798523387480907

Epoch: 6| Step: 8
Training loss: 2.3935745095249708
Validation loss: 2.5778253435221417

Epoch: 6| Step: 9
Training loss: 2.689981246655976
Validation loss: 2.5831388412867002

Epoch: 6| Step: 10
Training loss: 2.792147941287782
Validation loss: 2.5742910546363946

Epoch: 6| Step: 11
Training loss: 3.4876495165204675
Validation loss: 2.5811850089525334

Epoch: 6| Step: 12
Training loss: 2.6574189250704814
Validation loss: 2.5768362882084466

Epoch: 6| Step: 13
Training loss: 1.9796612238777305
Validation loss: 2.548158436121253

Epoch: 169| Step: 0
Training loss: 2.7807593609378722
Validation loss: 2.5383964064950515

Epoch: 6| Step: 1
Training loss: 2.7495994276128846
Validation loss: 2.543155558522052

Epoch: 6| Step: 2
Training loss: 2.909787066295264
Validation loss: 2.543429216613812

Epoch: 6| Step: 3
Training loss: 3.1062802963774994
Validation loss: 2.544899312155121

Epoch: 6| Step: 4
Training loss: 2.2781691977317338
Validation loss: 2.5517263916676165

Epoch: 6| Step: 5
Training loss: 3.161972146593793
Validation loss: 2.55677647032595

Epoch: 6| Step: 6
Training loss: 2.5954275566195557
Validation loss: 2.5635871271919233

Epoch: 6| Step: 7
Training loss: 3.1242305571286955
Validation loss: 2.5834727241416613

Epoch: 6| Step: 8
Training loss: 3.254307753027672
Validation loss: 2.5883174025027342

Epoch: 6| Step: 9
Training loss: 2.310168973018841
Validation loss: 2.5937687516970884

Epoch: 6| Step: 10
Training loss: 2.5660563655736928
Validation loss: 2.5815773916380853

Epoch: 6| Step: 11
Training loss: 2.747220628886012
Validation loss: 2.591722673870648

Epoch: 6| Step: 12
Training loss: 3.1523861037272476
Validation loss: 2.583700402730852

Epoch: 6| Step: 13
Training loss: 3.342277701838382
Validation loss: 2.570663965220907

Epoch: 170| Step: 0
Training loss: 2.6684282166931235
Validation loss: 2.549984139721468

Epoch: 6| Step: 1
Training loss: 3.1303680091453567
Validation loss: 2.549056680386579

Epoch: 6| Step: 2
Training loss: 2.6263231848097703
Validation loss: 2.5345664074559

Epoch: 6| Step: 3
Training loss: 3.1616626822192297
Validation loss: 2.538953749076512

Epoch: 6| Step: 4
Training loss: 2.679384620387623
Validation loss: 2.5388481611302494

Epoch: 6| Step: 5
Training loss: 3.0159832835455136
Validation loss: 2.539296304872533

Epoch: 6| Step: 6
Training loss: 2.2289050177441387
Validation loss: 2.538721183004637

Epoch: 6| Step: 7
Training loss: 3.197174648885111
Validation loss: 2.546611694519395

Epoch: 6| Step: 8
Training loss: 2.6514033362521925
Validation loss: 2.5640832275453485

Epoch: 6| Step: 9
Training loss: 2.6360927714692592
Validation loss: 2.5705774088887505

Epoch: 6| Step: 10
Training loss: 3.3204038360599277
Validation loss: 2.5821649692598463

Epoch: 6| Step: 11
Training loss: 2.7653812796753288
Validation loss: 2.594382189136907

Epoch: 6| Step: 12
Training loss: 3.3219069299033563
Validation loss: 2.599025903898131

Epoch: 6| Step: 13
Training loss: 1.8485150589395318
Validation loss: 2.5988039232294304

Epoch: 171| Step: 0
Training loss: 2.83139877096889
Validation loss: 2.619148553347764

Epoch: 6| Step: 1
Training loss: 2.71569705424178
Validation loss: 2.6372502142054515

Epoch: 6| Step: 2
Training loss: 3.0525494285786783
Validation loss: 2.6328936705794943

Epoch: 6| Step: 3
Training loss: 3.3934595591432966
Validation loss: 2.59969026678487

Epoch: 6| Step: 4
Training loss: 1.9863788969589704
Validation loss: 2.5658764188229233

Epoch: 6| Step: 5
Training loss: 2.8472854938041494
Validation loss: 2.538876984715551

Epoch: 6| Step: 6
Training loss: 3.382557073028469
Validation loss: 2.538253515461521

Epoch: 6| Step: 7
Training loss: 3.086617310406076
Validation loss: 2.5384989835212473

Epoch: 6| Step: 8
Training loss: 2.328843178802007
Validation loss: 2.5422454244305914

Epoch: 6| Step: 9
Training loss: 3.0143806380587566
Validation loss: 2.5441201295822524

Epoch: 6| Step: 10
Training loss: 3.2090025034675094
Validation loss: 2.544526829082656

Epoch: 6| Step: 11
Training loss: 2.37187229804688
Validation loss: 2.5491938842358386

Epoch: 6| Step: 12
Training loss: 2.600025536338406
Validation loss: 2.5560582737493927

Epoch: 6| Step: 13
Training loss: 3.3889292330676843
Validation loss: 2.567835824208339

Epoch: 172| Step: 0
Training loss: 3.099632450587545
Validation loss: 2.568927691939851

Epoch: 6| Step: 1
Training loss: 2.8701776613014887
Validation loss: 2.5679227205368833

Epoch: 6| Step: 2
Training loss: 2.786201355870189
Validation loss: 2.577828868018564

Epoch: 6| Step: 3
Training loss: 3.4078992298253965
Validation loss: 2.5887154461634063

Epoch: 6| Step: 4
Training loss: 3.00781281706573
Validation loss: 2.5669108140314028

Epoch: 6| Step: 5
Training loss: 2.5238905933928657
Validation loss: 2.5777365522694304

Epoch: 6| Step: 6
Training loss: 3.0895085400106646
Validation loss: 2.5744570247557044

Epoch: 6| Step: 7
Training loss: 2.311533545539264
Validation loss: 2.5794081412387717

Epoch: 6| Step: 8
Training loss: 2.793990539163397
Validation loss: 2.579706425308975

Epoch: 6| Step: 9
Training loss: 2.277099177476137
Validation loss: 2.577641252494214

Epoch: 6| Step: 10
Training loss: 3.0824341021174297
Validation loss: 2.5688097125368308

Epoch: 6| Step: 11
Training loss: 2.4432744805020894
Validation loss: 2.5559138585516146

Epoch: 6| Step: 12
Training loss: 2.8803904213121894
Validation loss: 2.543576810980488

Epoch: 6| Step: 13
Training loss: 3.2050471795428694
Validation loss: 2.53809380289116

Epoch: 173| Step: 0
Training loss: 2.4986373048514
Validation loss: 2.542641187779277

Epoch: 6| Step: 1
Training loss: 2.355750021264822
Validation loss: 2.551836047938128

Epoch: 6| Step: 2
Training loss: 2.620518264471032
Validation loss: 2.5492749678800286

Epoch: 6| Step: 3
Training loss: 3.0139092026205145
Validation loss: 2.5577365591927363

Epoch: 6| Step: 4
Training loss: 2.953316657088869
Validation loss: 2.55805030855999

Epoch: 6| Step: 5
Training loss: 3.296253019121022
Validation loss: 2.565005762288484

Epoch: 6| Step: 6
Training loss: 3.1222532789677557
Validation loss: 2.575836062478973

Epoch: 6| Step: 7
Training loss: 2.8299854545084666
Validation loss: 2.556413137753829

Epoch: 6| Step: 8
Training loss: 3.0824180137949457
Validation loss: 2.5452806334194507

Epoch: 6| Step: 9
Training loss: 2.325985533507765
Validation loss: 2.5420824309650167

Epoch: 6| Step: 10
Training loss: 2.8261764304882946
Validation loss: 2.5380999178194945

Epoch: 6| Step: 11
Training loss: 3.2480248538226744
Validation loss: 2.5442565164543076

Epoch: 6| Step: 12
Training loss: 2.8630580841152313
Validation loss: 2.541821230164968

Epoch: 6| Step: 13
Training loss: 2.449825035387223
Validation loss: 2.5365747665651224

Epoch: 174| Step: 0
Training loss: 2.450785402021457
Validation loss: 2.5392640725921836

Epoch: 6| Step: 1
Training loss: 2.4225825106935295
Validation loss: 2.5379625839281315

Epoch: 6| Step: 2
Training loss: 2.891854679324002
Validation loss: 2.5425538065275126

Epoch: 6| Step: 3
Training loss: 3.0186505729776476
Validation loss: 2.5408805372449534

Epoch: 6| Step: 4
Training loss: 3.237377744745029
Validation loss: 2.5481771118386067

Epoch: 6| Step: 5
Training loss: 2.8123836917140137
Validation loss: 2.5527204783430664

Epoch: 6| Step: 6
Training loss: 3.1122340567467943
Validation loss: 2.549170161442249

Epoch: 6| Step: 7
Training loss: 2.504531472832191
Validation loss: 2.5463796778534076

Epoch: 6| Step: 8
Training loss: 2.878321511914913
Validation loss: 2.5482117716675767

Epoch: 6| Step: 9
Training loss: 2.509228458139904
Validation loss: 2.5586081473026785

Epoch: 6| Step: 10
Training loss: 3.103677254483784
Validation loss: 2.5621138230929836

Epoch: 6| Step: 11
Training loss: 2.5804549352846036
Validation loss: 2.5541542642968738

Epoch: 6| Step: 12
Training loss: 3.218261385376348
Validation loss: 2.549093407052966

Epoch: 6| Step: 13
Training loss: 2.833207090220667
Validation loss: 2.5671462159451672

Epoch: 175| Step: 0
Training loss: 2.676995084225826
Validation loss: 2.5623322928969197

Epoch: 6| Step: 1
Training loss: 3.112368269128154
Validation loss: 2.5631997188340416

Epoch: 6| Step: 2
Training loss: 2.700194164641483
Validation loss: 2.546429313569502

Epoch: 6| Step: 3
Training loss: 3.711595079485048
Validation loss: 2.5494510666222516

Epoch: 6| Step: 4
Training loss: 2.974910407760896
Validation loss: 2.54522200084055

Epoch: 6| Step: 5
Training loss: 2.088323136183231
Validation loss: 2.5444507799530767

Epoch: 6| Step: 6
Training loss: 3.070614554808477
Validation loss: 2.5563572756569957

Epoch: 6| Step: 7
Training loss: 3.240672591769477
Validation loss: 2.548339902601246

Epoch: 6| Step: 8
Training loss: 2.5443303788764893
Validation loss: 2.5603431760867696

Epoch: 6| Step: 9
Training loss: 2.908328389889543
Validation loss: 2.5675614455237077

Epoch: 6| Step: 10
Training loss: 2.376049512565622
Validation loss: 2.576390176633129

Epoch: 6| Step: 11
Training loss: 3.077599650054904
Validation loss: 2.5751606908108804

Epoch: 6| Step: 12
Training loss: 2.233033424376703
Validation loss: 2.5600816994302416

Epoch: 6| Step: 13
Training loss: 2.5022387017749526
Validation loss: 2.5683831910525963

Epoch: 176| Step: 0
Training loss: 3.0429645190619654
Validation loss: 2.5580037265591278

Epoch: 6| Step: 1
Training loss: 3.1135786768803553
Validation loss: 2.5478173727022475

Epoch: 6| Step: 2
Training loss: 2.8279926416606216
Validation loss: 2.5549658329273357

Epoch: 6| Step: 3
Training loss: 2.865359188551925
Validation loss: 2.542489432218368

Epoch: 6| Step: 4
Training loss: 1.9085532485093597
Validation loss: 2.5397402309588557

Epoch: 6| Step: 5
Training loss: 3.2484267902060107
Validation loss: 2.537895737506521

Epoch: 6| Step: 6
Training loss: 2.2321766529249607
Validation loss: 2.5435259020463445

Epoch: 6| Step: 7
Training loss: 3.0282615796162786
Validation loss: 2.5421140879801967

Epoch: 6| Step: 8
Training loss: 3.114384129170376
Validation loss: 2.5499769071835865

Epoch: 6| Step: 9
Training loss: 2.46513720426512
Validation loss: 2.55077402977271

Epoch: 6| Step: 10
Training loss: 2.787549888267049
Validation loss: 2.5590755271763617

Epoch: 6| Step: 11
Training loss: 2.792369602201738
Validation loss: 2.568555885762859

Epoch: 6| Step: 12
Training loss: 2.9277461015442277
Validation loss: 2.5662272378654585

Epoch: 6| Step: 13
Training loss: 3.3078698961903066
Validation loss: 2.5775607866733212

Epoch: 177| Step: 0
Training loss: 2.3751086160016293
Validation loss: 2.5744885286424495

Epoch: 6| Step: 1
Training loss: 2.8795417073973963
Validation loss: 2.556118105011376

Epoch: 6| Step: 2
Training loss: 2.814563587570294
Validation loss: 2.5629861952183313

Epoch: 6| Step: 3
Training loss: 3.033967992041676
Validation loss: 2.5462947939257905

Epoch: 6| Step: 4
Training loss: 2.822977260112894
Validation loss: 2.551222760627044

Epoch: 6| Step: 5
Training loss: 3.4224220430845773
Validation loss: 2.5606309070312934

Epoch: 6| Step: 6
Training loss: 2.4703555137754805
Validation loss: 2.5488919731142192

Epoch: 6| Step: 7
Training loss: 2.892349635957931
Validation loss: 2.5538147856295397

Epoch: 6| Step: 8
Training loss: 3.0180905397762046
Validation loss: 2.547753641549654

Epoch: 6| Step: 9
Training loss: 2.519145610778957
Validation loss: 2.5440337745890513

Epoch: 6| Step: 10
Training loss: 3.2107187461124935
Validation loss: 2.546265552911485

Epoch: 6| Step: 11
Training loss: 2.7046435726660127
Validation loss: 2.5401378117102222

Epoch: 6| Step: 12
Training loss: 2.428808905907588
Validation loss: 2.5429969431803467

Epoch: 6| Step: 13
Training loss: 2.6696614694470524
Validation loss: 2.5432526615967914

Epoch: 178| Step: 0
Training loss: 2.9382571604075154
Validation loss: 2.5384447480597854

Epoch: 6| Step: 1
Training loss: 2.3941998649160565
Validation loss: 2.5384285316307293

Epoch: 6| Step: 2
Training loss: 3.3121248428661993
Validation loss: 2.5476724068475747

Epoch: 6| Step: 3
Training loss: 2.4227191069320746
Validation loss: 2.561155914635045

Epoch: 6| Step: 4
Training loss: 3.1577453092724914
Validation loss: 2.589441652329037

Epoch: 6| Step: 5
Training loss: 3.1286936484126526
Validation loss: 2.5889859738748813

Epoch: 6| Step: 6
Training loss: 2.803762044145189
Validation loss: 2.5885431872300853

Epoch: 6| Step: 7
Training loss: 3.014827009966644
Validation loss: 2.5813994375346305

Epoch: 6| Step: 8
Training loss: 2.619495251206566
Validation loss: 2.595863213830742

Epoch: 6| Step: 9
Training loss: 2.718797354450204
Validation loss: 2.568795755640175

Epoch: 6| Step: 10
Training loss: 2.8824403103870746
Validation loss: 2.563213224121222

Epoch: 6| Step: 11
Training loss: 2.9422528389813225
Validation loss: 2.5611802906447694

Epoch: 6| Step: 12
Training loss: 2.679267160796194
Validation loss: 2.5445232645036477

Epoch: 6| Step: 13
Training loss: 2.221071989346665
Validation loss: 2.533754842041358

Epoch: 179| Step: 0
Training loss: 3.058165772410078
Validation loss: 2.5321439974433435

Epoch: 6| Step: 1
Training loss: 3.0459809385368266
Validation loss: 2.5398822015969538

Epoch: 6| Step: 2
Training loss: 3.012498252519916
Validation loss: 2.5587317619810124

Epoch: 6| Step: 3
Training loss: 2.184781810769429
Validation loss: 2.5680993494265025

Epoch: 6| Step: 4
Training loss: 3.003615267268278
Validation loss: 2.5731259970328146

Epoch: 6| Step: 5
Training loss: 2.362277033542663
Validation loss: 2.5950456376355837

Epoch: 6| Step: 6
Training loss: 3.0007993904644015
Validation loss: 2.568014414738945

Epoch: 6| Step: 7
Training loss: 2.583633918092361
Validation loss: 2.5621297004998307

Epoch: 6| Step: 8
Training loss: 3.281722988370576
Validation loss: 2.5527318803861805

Epoch: 6| Step: 9
Training loss: 2.5020990143050845
Validation loss: 2.543449249472065

Epoch: 6| Step: 10
Training loss: 2.8958185502002007
Validation loss: 2.542053073927295

Epoch: 6| Step: 11
Training loss: 3.3595992612281784
Validation loss: 2.5368224444829393

Epoch: 6| Step: 12
Training loss: 2.4059576872595456
Validation loss: 2.545051923266039

Epoch: 6| Step: 13
Training loss: 2.6751825929873934
Validation loss: 2.5578497443601313

Epoch: 180| Step: 0
Training loss: 2.7630239205638287
Validation loss: 2.5624195419393963

Epoch: 6| Step: 1
Training loss: 2.6181588718885043
Validation loss: 2.55711356874637

Epoch: 6| Step: 2
Training loss: 3.326075249532361
Validation loss: 2.563499539867581

Epoch: 6| Step: 3
Training loss: 2.766206410819171
Validation loss: 2.571865587654993

Epoch: 6| Step: 4
Training loss: 3.5139066438557243
Validation loss: 2.5723257699457087

Epoch: 6| Step: 5
Training loss: 2.154043865823329
Validation loss: 2.557176455585872

Epoch: 6| Step: 6
Training loss: 2.6994086501012955
Validation loss: 2.5614420209688493

Epoch: 6| Step: 7
Training loss: 2.4073258013900167
Validation loss: 2.5376452366584172

Epoch: 6| Step: 8
Training loss: 3.1428350008147405
Validation loss: 2.5364438369200952

Epoch: 6| Step: 9
Training loss: 3.046411410545169
Validation loss: 2.5354202709178613

Epoch: 6| Step: 10
Training loss: 2.3387950145440604
Validation loss: 2.529904378427772

Epoch: 6| Step: 11
Training loss: 3.272034118922146
Validation loss: 2.5309810842464677

Epoch: 6| Step: 12
Training loss: 2.1020557150965615
Validation loss: 2.528867387401879

Epoch: 6| Step: 13
Training loss: 2.997942536865192
Validation loss: 2.5308981868329288

Epoch: 181| Step: 0
Training loss: 2.9127518311693614
Validation loss: 2.5256382394976695

Epoch: 6| Step: 1
Training loss: 2.7466012586132553
Validation loss: 2.5301967492125876

Epoch: 6| Step: 2
Training loss: 2.4584146798678406
Validation loss: 2.53313246610964

Epoch: 6| Step: 3
Training loss: 2.6879861081536403
Validation loss: 2.5368053627342153

Epoch: 6| Step: 4
Training loss: 2.967292026086852
Validation loss: 2.53683167906912

Epoch: 6| Step: 5
Training loss: 2.5818335476209247
Validation loss: 2.5517521723509375

Epoch: 6| Step: 6
Training loss: 3.1876241622378596
Validation loss: 2.5735046391110443

Epoch: 6| Step: 7
Training loss: 2.4680555308445795
Validation loss: 2.5826773348126575

Epoch: 6| Step: 8
Training loss: 2.3205387506091366
Validation loss: 2.595784793304396

Epoch: 6| Step: 9
Training loss: 3.2132120731103675
Validation loss: 2.5916433782460686

Epoch: 6| Step: 10
Training loss: 3.0007488587649096
Validation loss: 2.5832942644777903

Epoch: 6| Step: 11
Training loss: 2.9950533456780084
Validation loss: 2.578209407713611

Epoch: 6| Step: 12
Training loss: 3.1546152243570242
Validation loss: 2.5702534659561618

Epoch: 6| Step: 13
Training loss: 2.4707202051348847
Validation loss: 2.575142144583699

Epoch: 182| Step: 0
Training loss: 2.7912810234809173
Validation loss: 2.5653901008201614

Epoch: 6| Step: 1
Training loss: 2.4027956653828304
Validation loss: 2.5512142684783368

Epoch: 6| Step: 2
Training loss: 3.059113479050746
Validation loss: 2.5382602693346143

Epoch: 6| Step: 3
Training loss: 3.2679567909979457
Validation loss: 2.5424975370743104

Epoch: 6| Step: 4
Training loss: 3.02307599885829
Validation loss: 2.53943247835934

Epoch: 6| Step: 5
Training loss: 3.0257709182889867
Validation loss: 2.53669927201941

Epoch: 6| Step: 6
Training loss: 2.9166045772664893
Validation loss: 2.5351255385842064

Epoch: 6| Step: 7
Training loss: 2.4637452593196043
Validation loss: 2.536320807288129

Epoch: 6| Step: 8
Training loss: 2.391555904078762
Validation loss: 2.5397801074103943

Epoch: 6| Step: 9
Training loss: 2.146384072845604
Validation loss: 2.5402103345559497

Epoch: 6| Step: 10
Training loss: 3.076885767857231
Validation loss: 2.5455182148958233

Epoch: 6| Step: 11
Training loss: 2.790347447107588
Validation loss: 2.538980146134259

Epoch: 6| Step: 12
Training loss: 2.9941355287790943
Validation loss: 2.544993416370538

Epoch: 6| Step: 13
Training loss: 2.7816667565981343
Validation loss: 2.5508629324229832

Epoch: 183| Step: 0
Training loss: 2.8095578381338036
Validation loss: 2.577350715717539

Epoch: 6| Step: 1
Training loss: 2.8713930142715096
Validation loss: 2.594493960410102

Epoch: 6| Step: 2
Training loss: 2.601287002410286
Validation loss: 2.61874459698045

Epoch: 6| Step: 3
Training loss: 2.775988713678508
Validation loss: 2.642640092208355

Epoch: 6| Step: 4
Training loss: 3.1549803946924224
Validation loss: 2.6350719189613336

Epoch: 6| Step: 5
Training loss: 2.7942395287022563
Validation loss: 2.6164666432174655

Epoch: 6| Step: 6
Training loss: 2.7377728957625345
Validation loss: 2.579271911491444

Epoch: 6| Step: 7
Training loss: 2.545432308180393
Validation loss: 2.5398939888073424

Epoch: 6| Step: 8
Training loss: 3.064457326269826
Validation loss: 2.531924629930033

Epoch: 6| Step: 9
Training loss: 2.8271911090799544
Validation loss: 2.524718669227708

Epoch: 6| Step: 10
Training loss: 3.0564577870635743
Validation loss: 2.524562079045926

Epoch: 6| Step: 11
Training loss: 2.064227219043684
Validation loss: 2.5309565293107767

Epoch: 6| Step: 12
Training loss: 3.2399943460014837
Validation loss: 2.5376269087472916

Epoch: 6| Step: 13
Training loss: 3.734380235229398
Validation loss: 2.545521218123936

Epoch: 184| Step: 0
Training loss: 2.7050423409749587
Validation loss: 2.5381761511741563

Epoch: 6| Step: 1
Training loss: 2.48686611590988
Validation loss: 2.5299778482013004

Epoch: 6| Step: 2
Training loss: 3.2184199191719913
Validation loss: 2.531876894933499

Epoch: 6| Step: 3
Training loss: 3.125623717053201
Validation loss: 2.529389877215379

Epoch: 6| Step: 4
Training loss: 3.1556731348414337
Validation loss: 2.52427107971595

Epoch: 6| Step: 5
Training loss: 2.6814394192599944
Validation loss: 2.5203475002611073

Epoch: 6| Step: 6
Training loss: 2.8667427570387582
Validation loss: 2.5371732785449073

Epoch: 6| Step: 7
Training loss: 2.338760762192447
Validation loss: 2.5550632697808133

Epoch: 6| Step: 8
Training loss: 3.2384287912144374
Validation loss: 2.569212012811903

Epoch: 6| Step: 9
Training loss: 3.4896911300786506
Validation loss: 2.574303514841291

Epoch: 6| Step: 10
Training loss: 2.974794999440514
Validation loss: 2.5617835150943957

Epoch: 6| Step: 11
Training loss: 2.1747485574537055
Validation loss: 2.538234664717809

Epoch: 6| Step: 12
Training loss: 2.6560816992006044
Validation loss: 2.539706596166516

Epoch: 6| Step: 13
Training loss: 2.81985799661858
Validation loss: 2.5343702260578818

Epoch: 185| Step: 0
Training loss: 2.8086156512641383
Validation loss: 2.5375729163076453

Epoch: 6| Step: 1
Training loss: 2.806430285807342
Validation loss: 2.53853674557602

Epoch: 6| Step: 2
Training loss: 3.154077669918098
Validation loss: 2.5427387087440327

Epoch: 6| Step: 3
Training loss: 2.795792439403772
Validation loss: 2.564387334006807

Epoch: 6| Step: 4
Training loss: 2.736202915112415
Validation loss: 2.5374385141508444

Epoch: 6| Step: 5
Training loss: 2.9317590332516645
Validation loss: 2.5431502027202835

Epoch: 6| Step: 6
Training loss: 3.1625341421101223
Validation loss: 2.518892208660842

Epoch: 6| Step: 7
Training loss: 2.937673847654445
Validation loss: 2.5282832678531384

Epoch: 6| Step: 8
Training loss: 2.7614259901902307
Validation loss: 2.519679903384606

Epoch: 6| Step: 9
Training loss: 2.9541419160466957
Validation loss: 2.520784813022345

Epoch: 6| Step: 10
Training loss: 2.579051643070474
Validation loss: 2.515309258892233

Epoch: 6| Step: 11
Training loss: 1.9777570288828226
Validation loss: 2.5328574718381622

Epoch: 6| Step: 12
Training loss: 2.920437219363925
Validation loss: 2.529859644359011

Epoch: 6| Step: 13
Training loss: 2.6822167741017324
Validation loss: 2.5477177025823816

Epoch: 186| Step: 0
Training loss: 1.9456751228834102
Validation loss: 2.5496983011261722

Epoch: 6| Step: 1
Training loss: 3.363673241574815
Validation loss: 2.5648181083453734

Epoch: 6| Step: 2
Training loss: 2.4919963512240866
Validation loss: 2.5832156578940393

Epoch: 6| Step: 3
Training loss: 3.1633195923271304
Validation loss: 2.587355550536889

Epoch: 6| Step: 4
Training loss: 1.9186933279210847
Validation loss: 2.5928680466312324

Epoch: 6| Step: 5
Training loss: 3.0945798743438258
Validation loss: 2.591638486672246

Epoch: 6| Step: 6
Training loss: 3.1757773461499683
Validation loss: 2.611822520837766

Epoch: 6| Step: 7
Training loss: 2.6914834951269935
Validation loss: 2.6081054676294353

Epoch: 6| Step: 8
Training loss: 2.394188313406803
Validation loss: 2.571549196212898

Epoch: 6| Step: 9
Training loss: 2.943469859924538
Validation loss: 2.546994519846951

Epoch: 6| Step: 10
Training loss: 2.807561310585276
Validation loss: 2.5374316459439776

Epoch: 6| Step: 11
Training loss: 3.1478788954671275
Validation loss: 2.5234914149295817

Epoch: 6| Step: 12
Training loss: 2.9778394788388036
Validation loss: 2.5123910521042667

Epoch: 6| Step: 13
Training loss: 2.8705964572516534
Validation loss: 2.514238188655262

Epoch: 187| Step: 0
Training loss: 2.971408015483976
Validation loss: 2.513786987613309

Epoch: 6| Step: 1
Training loss: 3.029956344944677
Validation loss: 2.5169619354907184

Epoch: 6| Step: 2
Training loss: 2.6335230923942605
Validation loss: 2.5163495806155756

Epoch: 6| Step: 3
Training loss: 2.8983157561611725
Validation loss: 2.5194268740069328

Epoch: 6| Step: 4
Training loss: 3.2145687463066404
Validation loss: 2.5198623138282876

Epoch: 6| Step: 5
Training loss: 2.6258815919861727
Validation loss: 2.525661818921293

Epoch: 6| Step: 6
Training loss: 3.1104072122670767
Validation loss: 2.5339937560632153

Epoch: 6| Step: 7
Training loss: 2.8060439715974392
Validation loss: 2.532895149985289

Epoch: 6| Step: 8
Training loss: 2.879193109224367
Validation loss: 2.5444054351282577

Epoch: 6| Step: 9
Training loss: 2.7411463138368015
Validation loss: 2.54692965283474

Epoch: 6| Step: 10
Training loss: 2.340483971129948
Validation loss: 2.5484531218344304

Epoch: 6| Step: 11
Training loss: 2.9199729889443415
Validation loss: 2.537575062125948

Epoch: 6| Step: 12
Training loss: 2.2980935114865586
Validation loss: 2.532858345326509

Epoch: 6| Step: 13
Training loss: 2.7658368045715758
Validation loss: 2.5434899386193055

Epoch: 188| Step: 0
Training loss: 2.6204389274364543
Validation loss: 2.53123025647192

Epoch: 6| Step: 1
Training loss: 3.06557357076111
Validation loss: 2.5283535167535174

Epoch: 6| Step: 2
Training loss: 3.3221528103089937
Validation loss: 2.518968750050545

Epoch: 6| Step: 3
Training loss: 3.392887468130785
Validation loss: 2.5087027625770517

Epoch: 6| Step: 4
Training loss: 2.7682322480886445
Validation loss: 2.520525859066938

Epoch: 6| Step: 5
Training loss: 2.7517113995704343
Validation loss: 2.515032094633517

Epoch: 6| Step: 6
Training loss: 3.0881531306431005
Validation loss: 2.5182529064078825

Epoch: 6| Step: 7
Training loss: 3.0504170492236526
Validation loss: 2.5181691496766807

Epoch: 6| Step: 8
Training loss: 2.1380391338895586
Validation loss: 2.5166951836014335

Epoch: 6| Step: 9
Training loss: 2.7459872185784016
Validation loss: 2.521763161682927

Epoch: 6| Step: 10
Training loss: 2.3231741473130887
Validation loss: 2.5346773684624524

Epoch: 6| Step: 11
Training loss: 2.7740054986152525
Validation loss: 2.53025761146659

Epoch: 6| Step: 12
Training loss: 2.4791767750595417
Validation loss: 2.5397332407810356

Epoch: 6| Step: 13
Training loss: 2.1163292302972954
Validation loss: 2.5539733815860144

Epoch: 189| Step: 0
Training loss: 2.848762370639671
Validation loss: 2.5539256742420937

Epoch: 6| Step: 1
Training loss: 3.1470573183069726
Validation loss: 2.5847795297439973

Epoch: 6| Step: 2
Training loss: 3.2127620961183667
Validation loss: 2.5812152398877197

Epoch: 6| Step: 3
Training loss: 2.40770261440757
Validation loss: 2.576503852776706

Epoch: 6| Step: 4
Training loss: 2.4991756987612552
Validation loss: 2.556777761783511

Epoch: 6| Step: 5
Training loss: 2.408037685828112
Validation loss: 2.5707103985919018

Epoch: 6| Step: 6
Training loss: 3.2955555377181946
Validation loss: 2.5432852596333326

Epoch: 6| Step: 7
Training loss: 2.1868921797852447
Validation loss: 2.541510250524196

Epoch: 6| Step: 8
Training loss: 2.5815338717596714
Validation loss: 2.5349650115333717

Epoch: 6| Step: 9
Training loss: 3.1271269617122948
Validation loss: 2.521612537284743

Epoch: 6| Step: 10
Training loss: 3.29061584761199
Validation loss: 2.5149823091807426

Epoch: 6| Step: 11
Training loss: 2.3183731554324014
Validation loss: 2.512276621984899

Epoch: 6| Step: 12
Training loss: 3.1584930003796536
Validation loss: 2.508540254947888

Epoch: 6| Step: 13
Training loss: 2.065551811918483
Validation loss: 2.5034160450597316

Epoch: 190| Step: 0
Training loss: 2.9991112028227582
Validation loss: 2.5043868891280714

Epoch: 6| Step: 1
Training loss: 3.00809990636812
Validation loss: 2.506451264114779

Epoch: 6| Step: 2
Training loss: 3.0134392757978214
Validation loss: 2.5064355310963142

Epoch: 6| Step: 3
Training loss: 2.806480918168333
Validation loss: 2.5118034235098503

Epoch: 6| Step: 4
Training loss: 2.15899019690899
Validation loss: 2.511589534722794

Epoch: 6| Step: 5
Training loss: 2.922881580304428
Validation loss: 2.5024237963049085

Epoch: 6| Step: 6
Training loss: 2.836242491240164
Validation loss: 2.5093214001087354

Epoch: 6| Step: 7
Training loss: 2.943784605823082
Validation loss: 2.5135407182252707

Epoch: 6| Step: 8
Training loss: 2.691863753324299
Validation loss: 2.5147633346558793

Epoch: 6| Step: 9
Training loss: 2.615723157565404
Validation loss: 2.517130902468705

Epoch: 6| Step: 10
Training loss: 2.778981001188792
Validation loss: 2.541126593937362

Epoch: 6| Step: 11
Training loss: 3.1205039678596362
Validation loss: 2.5527946828527996

Epoch: 6| Step: 12
Training loss: 2.7503043786574697
Validation loss: 2.5775483203332077

Epoch: 6| Step: 13
Training loss: 2.707771761456252
Validation loss: 2.5894365833394

Epoch: 191| Step: 0
Training loss: 2.967315327169408
Validation loss: 2.605167787312322

Epoch: 6| Step: 1
Training loss: 2.9480029701207595
Validation loss: 2.55905079701977

Epoch: 6| Step: 2
Training loss: 2.4950948277496168
Validation loss: 2.5305602950605897

Epoch: 6| Step: 3
Training loss: 2.5946814461699126
Validation loss: 2.51813718399979

Epoch: 6| Step: 4
Training loss: 2.537039740401924
Validation loss: 2.5190855425193215

Epoch: 6| Step: 5
Training loss: 2.429288089219219
Validation loss: 2.513970818373616

Epoch: 6| Step: 6
Training loss: 3.029852790907557
Validation loss: 2.510869766811313

Epoch: 6| Step: 7
Training loss: 2.811123489918885
Validation loss: 2.509290334696656

Epoch: 6| Step: 8
Training loss: 3.280602672847586
Validation loss: 2.510655720369349

Epoch: 6| Step: 9
Training loss: 3.1161234098292137
Validation loss: 2.5108655663439943

Epoch: 6| Step: 10
Training loss: 3.1205186373681713
Validation loss: 2.507963499861287

Epoch: 6| Step: 11
Training loss: 2.78897239902827
Validation loss: 2.508559954270138

Epoch: 6| Step: 12
Training loss: 2.6964704154818024
Validation loss: 2.506594662006327

Epoch: 6| Step: 13
Training loss: 2.223827087198401
Validation loss: 2.5119778035710763

Epoch: 192| Step: 0
Training loss: 2.077817506914651
Validation loss: 2.5200641831260286

Epoch: 6| Step: 1
Training loss: 3.2764849259303226
Validation loss: 2.522680299725108

Epoch: 6| Step: 2
Training loss: 3.2558384318556324
Validation loss: 2.5220311691176307

Epoch: 6| Step: 3
Training loss: 2.6894677521218524
Validation loss: 2.542252463163631

Epoch: 6| Step: 4
Training loss: 2.900822647748636
Validation loss: 2.5388307517079696

Epoch: 6| Step: 5
Training loss: 2.4705488194465617
Validation loss: 2.539654269109318

Epoch: 6| Step: 6
Training loss: 2.920559183950986
Validation loss: 2.5413137678769377

Epoch: 6| Step: 7
Training loss: 2.013965248618765
Validation loss: 2.5624333814939906

Epoch: 6| Step: 8
Training loss: 2.8866412780855137
Validation loss: 2.566989057030679

Epoch: 6| Step: 9
Training loss: 2.3606420487365685
Validation loss: 2.55448084796938

Epoch: 6| Step: 10
Training loss: 2.5907273662299577
Validation loss: 2.5297841545209545

Epoch: 6| Step: 11
Training loss: 3.0345690931322773
Validation loss: 2.525962471278183

Epoch: 6| Step: 12
Training loss: 3.256003190716204
Validation loss: 2.5298475671901883

Epoch: 6| Step: 13
Training loss: 3.375067109747641
Validation loss: 2.5122454420881373

Epoch: 193| Step: 0
Training loss: 2.750357084499145
Validation loss: 2.5204142404584466

Epoch: 6| Step: 1
Training loss: 2.8815339517415133
Validation loss: 2.518024331434338

Epoch: 6| Step: 2
Training loss: 2.832299960312387
Validation loss: 2.511250313880043

Epoch: 6| Step: 3
Training loss: 2.853326121466724
Validation loss: 2.5116414502689404

Epoch: 6| Step: 4
Training loss: 2.703599303865463
Validation loss: 2.5153667929144534

Epoch: 6| Step: 5
Training loss: 2.461741870031862
Validation loss: 2.5203431121537814

Epoch: 6| Step: 6
Training loss: 3.132481583695646
Validation loss: 2.516790974945297

Epoch: 6| Step: 7
Training loss: 2.7168955123404332
Validation loss: 2.5252499664892794

Epoch: 6| Step: 8
Training loss: 2.375790012874079
Validation loss: 2.5281791659812676

Epoch: 6| Step: 9
Training loss: 3.0691507485693577
Validation loss: 2.5214184836420572

Epoch: 6| Step: 10
Training loss: 2.966082529001453
Validation loss: 2.532449090634208

Epoch: 6| Step: 11
Training loss: 3.2755676476462274
Validation loss: 2.529217852154107

Epoch: 6| Step: 12
Training loss: 2.5499567215182712
Validation loss: 2.5084383302521704

Epoch: 6| Step: 13
Training loss: 1.9644448575042897
Validation loss: 2.5181284351976148

Epoch: 194| Step: 0
Training loss: 3.0697747844382413
Validation loss: 2.5282006125504792

Epoch: 6| Step: 1
Training loss: 2.62736395704182
Validation loss: 2.512650739343331

Epoch: 6| Step: 2
Training loss: 3.157436034701641
Validation loss: 2.5235682145392517

Epoch: 6| Step: 3
Training loss: 2.7184395448418495
Validation loss: 2.5194513001555032

Epoch: 6| Step: 4
Training loss: 3.2041551375626067
Validation loss: 2.5166760725684836

Epoch: 6| Step: 5
Training loss: 3.1034501718829564
Validation loss: 2.514710816835129

Epoch: 6| Step: 6
Training loss: 2.3488242596737696
Validation loss: 2.5238902145182696

Epoch: 6| Step: 7
Training loss: 2.357290597719587
Validation loss: 2.526197078598026

Epoch: 6| Step: 8
Training loss: 2.319344777943678
Validation loss: 2.5252571459927116

Epoch: 6| Step: 9
Training loss: 2.8916112918297143
Validation loss: 2.5328137727446154

Epoch: 6| Step: 10
Training loss: 2.7840421569745533
Validation loss: 2.528806068944364

Epoch: 6| Step: 11
Training loss: 2.781997751592938
Validation loss: 2.515757076317467

Epoch: 6| Step: 12
Training loss: 2.769728552673197
Validation loss: 2.508109108044052

Epoch: 6| Step: 13
Training loss: 2.644345162858289
Validation loss: 2.5065434519723317

Epoch: 195| Step: 0
Training loss: 2.948605586093832
Validation loss: 2.513778800897882

Epoch: 6| Step: 1
Training loss: 2.9221556829589383
Validation loss: 2.508732710167956

Epoch: 6| Step: 2
Training loss: 2.674871894407143
Validation loss: 2.508309205587548

Epoch: 6| Step: 3
Training loss: 2.51716708666944
Validation loss: 2.5115945066662597

Epoch: 6| Step: 4
Training loss: 2.7884427618917402
Validation loss: 2.5147271790737062

Epoch: 6| Step: 5
Training loss: 2.96688061132035
Validation loss: 2.509972101803414

Epoch: 6| Step: 6
Training loss: 2.3470765983457373
Validation loss: 2.5091550321531946

Epoch: 6| Step: 7
Training loss: 3.051363880824954
Validation loss: 2.5132804435991782

Epoch: 6| Step: 8
Training loss: 2.9881325279576663
Validation loss: 2.5205619345226427

Epoch: 6| Step: 9
Training loss: 2.935941404428368
Validation loss: 2.521760007659517

Epoch: 6| Step: 10
Training loss: 2.2410996619298635
Validation loss: 2.51663181949322

Epoch: 6| Step: 11
Training loss: 3.025337824597758
Validation loss: 2.5202121448923314

Epoch: 6| Step: 12
Training loss: 2.777525218502346
Validation loss: 2.5194695201477817

Epoch: 6| Step: 13
Training loss: 2.8258765962064416
Validation loss: 2.5101448886875257

Epoch: 196| Step: 0
Training loss: 3.01574517045215
Validation loss: 2.508414543956799

Epoch: 6| Step: 1
Training loss: 2.713755173926427
Validation loss: 2.508491741794675

Epoch: 6| Step: 2
Training loss: 2.725641045718864
Validation loss: 2.5088496174158683

Epoch: 6| Step: 3
Training loss: 2.672234672742968
Validation loss: 2.509765726125147

Epoch: 6| Step: 4
Training loss: 2.5641881452852453
Validation loss: 2.5078111455028997

Epoch: 6| Step: 5
Training loss: 3.4909727300727824
Validation loss: 2.51923288402416

Epoch: 6| Step: 6
Training loss: 2.1576458379756835
Validation loss: 2.5272040482492546

Epoch: 6| Step: 7
Training loss: 2.7522446401500393
Validation loss: 2.531807776619555

Epoch: 6| Step: 8
Training loss: 2.406041916606561
Validation loss: 2.5371232010492752

Epoch: 6| Step: 9
Training loss: 3.1530263320108833
Validation loss: 2.5578174371793425

Epoch: 6| Step: 10
Training loss: 2.6667974757854163
Validation loss: 2.5474427309699483

Epoch: 6| Step: 11
Training loss: 3.0956057752832153
Validation loss: 2.5397291587101725

Epoch: 6| Step: 12
Training loss: 2.4470106572027066
Validation loss: 2.53637838068131

Epoch: 6| Step: 13
Training loss: 2.920698938982807
Validation loss: 2.5281722310446186

Epoch: 197| Step: 0
Training loss: 2.9521169405262375
Validation loss: 2.5138036633424057

Epoch: 6| Step: 1
Training loss: 2.714730371536522
Validation loss: 2.5142512737777505

Epoch: 6| Step: 2
Training loss: 2.742092554779924
Validation loss: 2.5117152848166624

Epoch: 6| Step: 3
Training loss: 2.765676034575029
Validation loss: 2.5129080951406078

Epoch: 6| Step: 4
Training loss: 2.558360035246464
Validation loss: 2.5159367244829918

Epoch: 6| Step: 5
Training loss: 2.7633799260548044
Validation loss: 2.509796927635021

Epoch: 6| Step: 6
Training loss: 2.686796406751998
Validation loss: 2.5153159897783235

Epoch: 6| Step: 7
Training loss: 3.4340890780999964
Validation loss: 2.5107146144053973

Epoch: 6| Step: 8
Training loss: 2.883531930364673
Validation loss: 2.514172030913769

Epoch: 6| Step: 9
Training loss: 2.5843150416733525
Validation loss: 2.5109730864976063

Epoch: 6| Step: 10
Training loss: 2.618500246506498
Validation loss: 2.517181458154721

Epoch: 6| Step: 11
Training loss: 3.1603803142618654
Validation loss: 2.5180427134500105

Epoch: 6| Step: 12
Training loss: 2.5670863720785526
Validation loss: 2.524230594671775

Epoch: 6| Step: 13
Training loss: 1.8818501272493042
Validation loss: 2.5249816321232155

Epoch: 198| Step: 0
Training loss: 2.77135593581769
Validation loss: 2.540070769204474

Epoch: 6| Step: 1
Training loss: 3.2866593595143683
Validation loss: 2.5743745598612917

Epoch: 6| Step: 2
Training loss: 2.9875967800154184
Validation loss: 2.6019661976417487

Epoch: 6| Step: 3
Training loss: 3.4936892973347007
Validation loss: 2.5977094683213906

Epoch: 6| Step: 4
Training loss: 2.35932831370666
Validation loss: 2.5658328024902453

Epoch: 6| Step: 5
Training loss: 2.5365533726072
Validation loss: 2.548738584075995

Epoch: 6| Step: 6
Training loss: 2.5451971975195704
Validation loss: 2.539212350264926

Epoch: 6| Step: 7
Training loss: 2.782481745876816
Validation loss: 2.5170397919161984

Epoch: 6| Step: 8
Training loss: 2.850503803362381
Validation loss: 2.522126703926347

Epoch: 6| Step: 9
Training loss: 2.753027982875112
Validation loss: 2.5197766882018975

Epoch: 6| Step: 10
Training loss: 2.5422777681555107
Validation loss: 2.523212369609306

Epoch: 6| Step: 11
Training loss: 2.984107519815487
Validation loss: 2.5186147030217665

Epoch: 6| Step: 12
Training loss: 2.5636541977144627
Validation loss: 2.5212175545448843

Epoch: 6| Step: 13
Training loss: 2.1306975781406963
Validation loss: 2.518923722034062

Epoch: 199| Step: 0
Training loss: 1.9843456236099142
Validation loss: 2.517543100453138

Epoch: 6| Step: 1
Training loss: 2.746973279425189
Validation loss: 2.5381476923363153

Epoch: 6| Step: 2
Training loss: 3.058641767064021
Validation loss: 2.5648012330406114

Epoch: 6| Step: 3
Training loss: 3.2138790569706375
Validation loss: 2.5675063092557355

Epoch: 6| Step: 4
Training loss: 2.7464036834456524
Validation loss: 2.562080435991418

Epoch: 6| Step: 5
Training loss: 2.650918254465405
Validation loss: 2.5523822578386324

Epoch: 6| Step: 6
Training loss: 3.170664589226986
Validation loss: 2.5307778136175703

Epoch: 6| Step: 7
Training loss: 2.6362060952724673
Validation loss: 2.5391918599358605

Epoch: 6| Step: 8
Training loss: 2.4150233655790423
Validation loss: 2.528613503141726

Epoch: 6| Step: 9
Training loss: 2.1920517567420346
Validation loss: 2.5185635829256423

Epoch: 6| Step: 10
Training loss: 3.1888541542787343
Validation loss: 2.5164086628143156

Epoch: 6| Step: 11
Training loss: 2.5406347483392797
Validation loss: 2.519480751639981

Epoch: 6| Step: 12
Training loss: 3.0035703394353104
Validation loss: 2.507259503816957

Epoch: 6| Step: 13
Training loss: 3.2798598478193988
Validation loss: 2.5093913318918486

Epoch: 200| Step: 0
Training loss: 2.517474708771025
Validation loss: 2.5095265629551786

Epoch: 6| Step: 1
Training loss: 2.993351403700808
Validation loss: 2.514085182597426

Epoch: 6| Step: 2
Training loss: 3.1074002383262287
Validation loss: 2.510835192896718

Epoch: 6| Step: 3
Training loss: 2.8037262440804747
Validation loss: 2.515012103508922

Epoch: 6| Step: 4
Training loss: 2.591009415656899
Validation loss: 2.5141875809231995

Epoch: 6| Step: 5
Training loss: 2.331419386858974
Validation loss: 2.5129952463161596

Epoch: 6| Step: 6
Training loss: 2.4771161829313204
Validation loss: 2.507378403983909

Epoch: 6| Step: 7
Training loss: 3.241054548379476
Validation loss: 2.53037479471647

Epoch: 6| Step: 8
Training loss: 2.691302514810776
Validation loss: 2.52199334797826

Epoch: 6| Step: 9
Training loss: 3.1675608192391667
Validation loss: 2.522711919735963

Epoch: 6| Step: 10
Training loss: 2.6812651413710094
Validation loss: 2.520413233479238

Epoch: 6| Step: 11
Training loss: 2.9868593111522177
Validation loss: 2.5147390719586213

Epoch: 6| Step: 12
Training loss: 2.4797429502232946
Validation loss: 2.5192090978869257

Epoch: 6| Step: 13
Training loss: 2.2833656011747068
Validation loss: 2.511883832123504

Epoch: 201| Step: 0
Training loss: 3.0704969976771093
Validation loss: 2.521033375131134

Epoch: 6| Step: 1
Training loss: 2.378637239125892
Validation loss: 2.526092990209656

Epoch: 6| Step: 2
Training loss: 3.1698800564285636
Validation loss: 2.5267211595560064

Epoch: 6| Step: 3
Training loss: 2.679394052525402
Validation loss: 2.5352797765162496

Epoch: 6| Step: 4
Training loss: 3.002744531893434
Validation loss: 2.5193351148427503

Epoch: 6| Step: 5
Training loss: 1.9650939418089604
Validation loss: 2.5204857847928936

Epoch: 6| Step: 6
Training loss: 2.3910067384402334
Validation loss: 2.5288117653402575

Epoch: 6| Step: 7
Training loss: 2.9879830005882226
Validation loss: 2.5133752563488767

Epoch: 6| Step: 8
Training loss: 3.3695366049002486
Validation loss: 2.515565358247703

Epoch: 6| Step: 9
Training loss: 2.6732980608178836
Validation loss: 2.530999035878795

Epoch: 6| Step: 10
Training loss: 2.2810523587664178
Validation loss: 2.5455202009343956

Epoch: 6| Step: 11
Training loss: 2.561604133873534
Validation loss: 2.522059207037008

Epoch: 6| Step: 12
Training loss: 3.3203449561832814
Validation loss: 2.513365414357769

Epoch: 6| Step: 13
Training loss: 2.279907354011824
Validation loss: 2.517995125591947

Epoch: 202| Step: 0
Training loss: 2.84241244541088
Validation loss: 2.5043300559047115

Epoch: 6| Step: 1
Training loss: 2.465824566828013
Validation loss: 2.5063088195214354

Epoch: 6| Step: 2
Training loss: 2.9894956427461215
Validation loss: 2.506641973338619

Epoch: 6| Step: 3
Training loss: 2.9343215303759624
Validation loss: 2.50622826682065

Epoch: 6| Step: 4
Training loss: 3.3097332610095944
Validation loss: 2.501856282911619

Epoch: 6| Step: 5
Training loss: 2.9979733933380874
Validation loss: 2.5112006321065383

Epoch: 6| Step: 6
Training loss: 2.077999828268857
Validation loss: 2.5098314617158426

Epoch: 6| Step: 7
Training loss: 3.1727193075121307
Validation loss: 2.506025249231929

Epoch: 6| Step: 8
Training loss: 2.3112838227689196
Validation loss: 2.508017652373358

Epoch: 6| Step: 9
Training loss: 2.311287845778297
Validation loss: 2.5164072416303287

Epoch: 6| Step: 10
Training loss: 2.710553320670748
Validation loss: 2.5383195050917395

Epoch: 6| Step: 11
Training loss: 2.5455462962496083
Validation loss: 2.5462056018922805

Epoch: 6| Step: 12
Training loss: 2.7935612830272416
Validation loss: 2.5674413084454

Epoch: 6| Step: 13
Training loss: 3.023796750196518
Validation loss: 2.5564285250881156

Epoch: 203| Step: 0
Training loss: 3.3296492403894256
Validation loss: 2.5559261846727384

Epoch: 6| Step: 1
Training loss: 2.863326547220143
Validation loss: 2.538502124321183

Epoch: 6| Step: 2
Training loss: 2.334771212819564
Validation loss: 2.5235226570221694

Epoch: 6| Step: 3
Training loss: 2.826229746027655
Validation loss: 2.51935683512647

Epoch: 6| Step: 4
Training loss: 2.7710978350677795
Validation loss: 2.5187811583693525

Epoch: 6| Step: 5
Training loss: 2.3976703622252904
Validation loss: 2.5150722629399147

Epoch: 6| Step: 6
Training loss: 2.4926246570571426
Validation loss: 2.5226339782087983

Epoch: 6| Step: 7
Training loss: 2.5764351595287827
Validation loss: 2.5256178420528603

Epoch: 6| Step: 8
Training loss: 2.617463783370666
Validation loss: 2.5198988087789966

Epoch: 6| Step: 9
Training loss: 2.40571875714824
Validation loss: 2.526445284280164

Epoch: 6| Step: 10
Training loss: 2.665420857133464
Validation loss: 2.5385013411413695

Epoch: 6| Step: 11
Training loss: 2.728639352733365
Validation loss: 2.548542044085239

Epoch: 6| Step: 12
Training loss: 3.1973491417772673
Validation loss: 2.5496640717414873

Epoch: 6| Step: 13
Training loss: 3.573738707944543
Validation loss: 2.551237687888911

Epoch: 204| Step: 0
Training loss: 2.253579577171512
Validation loss: 2.555764725729681

Epoch: 6| Step: 1
Training loss: 3.071912508761735
Validation loss: 2.5510472163076106

Epoch: 6| Step: 2
Training loss: 3.0145728296722156
Validation loss: 2.5702668045150685

Epoch: 6| Step: 3
Training loss: 2.5027066837289373
Validation loss: 2.5517576035313936

Epoch: 6| Step: 4
Training loss: 2.6509598055468513
Validation loss: 2.5546547995901037

Epoch: 6| Step: 5
Training loss: 2.484218760441891
Validation loss: 2.560993008568002

Epoch: 6| Step: 6
Training loss: 3.353235214142782
Validation loss: 2.539768439790002

Epoch: 6| Step: 7
Training loss: 2.707486024998379
Validation loss: 2.536724744584686

Epoch: 6| Step: 8
Training loss: 2.7322136756701596
Validation loss: 2.5289682495124657

Epoch: 6| Step: 9
Training loss: 2.7775929442476497
Validation loss: 2.528154494596486

Epoch: 6| Step: 10
Training loss: 2.6857165251812396
Validation loss: 2.5078790749309077

Epoch: 6| Step: 11
Training loss: 2.821949745109243
Validation loss: 2.5225237578114705

Epoch: 6| Step: 12
Training loss: 2.7851633550652273
Validation loss: 2.500868480326717

Epoch: 6| Step: 13
Training loss: 2.6482419642280863
Validation loss: 2.491786714068756

Epoch: 205| Step: 0
Training loss: 1.8148585134588044
Validation loss: 2.498440393429283

Epoch: 6| Step: 1
Training loss: 2.4356588599455486
Validation loss: 2.502518175229647

Epoch: 6| Step: 2
Training loss: 1.778542183741202
Validation loss: 2.4918686399857557

Epoch: 6| Step: 3
Training loss: 2.7873312655300357
Validation loss: 2.513011022938911

Epoch: 6| Step: 4
Training loss: 2.993634942059703
Validation loss: 2.5196915276892082

Epoch: 6| Step: 5
Training loss: 3.0966995512903597
Validation loss: 2.5243170797204177

Epoch: 6| Step: 6
Training loss: 3.0399672232918835
Validation loss: 2.522737593490837

Epoch: 6| Step: 7
Training loss: 2.938026543359066
Validation loss: 2.5190691739882616

Epoch: 6| Step: 8
Training loss: 2.7041884078066327
Validation loss: 2.521205170585426

Epoch: 6| Step: 9
Training loss: 3.0817420736783276
Validation loss: 2.5360428374906823

Epoch: 6| Step: 10
Training loss: 2.6482665420313762
Validation loss: 2.5107019397065886

Epoch: 6| Step: 11
Training loss: 2.4931334610587697
Validation loss: 2.498536405474645

Epoch: 6| Step: 12
Training loss: 3.2668151147030566
Validation loss: 2.4993986308872627

Epoch: 6| Step: 13
Training loss: 3.2204638612612086
Validation loss: 2.5023986322932665

Epoch: 206| Step: 0
Training loss: 2.6747192948558944
Validation loss: 2.5107668257704367

Epoch: 6| Step: 1
Training loss: 2.916011700432724
Validation loss: 2.504204332166255

Epoch: 6| Step: 2
Training loss: 2.4613991924924017
Validation loss: 2.5052583379187023

Epoch: 6| Step: 3
Training loss: 2.6071071249049167
Validation loss: 2.5104993921360257

Epoch: 6| Step: 4
Training loss: 2.898458228846867
Validation loss: 2.5223811425132068

Epoch: 6| Step: 5
Training loss: 2.600861326012211
Validation loss: 2.5205687978427695

Epoch: 6| Step: 6
Training loss: 2.6485347223582156
Validation loss: 2.5218043710126117

Epoch: 6| Step: 7
Training loss: 2.591762102665668
Validation loss: 2.5597813188336076

Epoch: 6| Step: 8
Training loss: 2.518215764564636
Validation loss: 2.548768477668594

Epoch: 6| Step: 9
Training loss: 2.804707391609911
Validation loss: 2.5451051708058574

Epoch: 6| Step: 10
Training loss: 3.2872795292134858
Validation loss: 2.537569341960324

Epoch: 6| Step: 11
Training loss: 2.6153521578919423
Validation loss: 2.5363367850073457

Epoch: 6| Step: 12
Training loss: 2.9886310048587674
Validation loss: 2.5187942819772253

Epoch: 6| Step: 13
Training loss: 2.6770959895882482
Validation loss: 2.5155056050147087

Epoch: 207| Step: 0
Training loss: 2.9856427281240467
Validation loss: 2.521837645810863

Epoch: 6| Step: 1
Training loss: 3.0820244425225836
Validation loss: 2.5082505969590265

Epoch: 6| Step: 2
Training loss: 2.612652211112859
Validation loss: 2.49007033262796

Epoch: 6| Step: 3
Training loss: 1.9117255444205221
Validation loss: 2.5055416568414297

Epoch: 6| Step: 4
Training loss: 2.5595744110039678
Validation loss: 2.50586140679328

Epoch: 6| Step: 5
Training loss: 2.787562717707239
Validation loss: 2.497309949991553

Epoch: 6| Step: 6
Training loss: 2.9060358768461705
Validation loss: 2.499355877169793

Epoch: 6| Step: 7
Training loss: 2.570880398146893
Validation loss: 2.5110322931582347

Epoch: 6| Step: 8
Training loss: 2.9277946359083504
Validation loss: 2.5059060689992276

Epoch: 6| Step: 9
Training loss: 2.894926921864276
Validation loss: 2.50909342353169

Epoch: 6| Step: 10
Training loss: 2.6416917260201815
Validation loss: 2.514218588884407

Epoch: 6| Step: 11
Training loss: 2.931041679218735
Validation loss: 2.5334012567155586

Epoch: 6| Step: 12
Training loss: 2.5775497257086966
Validation loss: 2.5303959460897643

Epoch: 6| Step: 13
Training loss: 2.8498767625364976
Validation loss: 2.495037331796366

Epoch: 208| Step: 0
Training loss: 2.4275693829694878
Validation loss: 2.49334513390612

Epoch: 6| Step: 1
Training loss: 2.204808234701295
Validation loss: 2.505916161262563

Epoch: 6| Step: 2
Training loss: 2.592289892822123
Validation loss: 2.514488498003115

Epoch: 6| Step: 3
Training loss: 2.9694070189397106
Validation loss: 2.4919079965138122

Epoch: 6| Step: 4
Training loss: 3.0343539676271276
Validation loss: 2.4990484446904704

Epoch: 6| Step: 5
Training loss: 2.8893271342048044
Validation loss: 2.510976327580511

Epoch: 6| Step: 6
Training loss: 2.3951701918878143
Validation loss: 2.5241063151493868

Epoch: 6| Step: 7
Training loss: 2.7308351109948736
Validation loss: 2.521464540771118

Epoch: 6| Step: 8
Training loss: 2.6818867103038295
Validation loss: 2.5314365319752845

Epoch: 6| Step: 9
Training loss: 2.9736049105833824
Validation loss: 2.5250370512292517

Epoch: 6| Step: 10
Training loss: 2.768994191856258
Validation loss: 2.5130872634879875

Epoch: 6| Step: 11
Training loss: 2.840649601963046
Validation loss: 2.5032489830247027

Epoch: 6| Step: 12
Training loss: 3.2165227795243
Validation loss: 2.5098661270853584

Epoch: 6| Step: 13
Training loss: 2.066553236812111
Validation loss: 2.4948526798398345

Epoch: 209| Step: 0
Training loss: 2.8393139456470466
Validation loss: 2.50031013923592

Epoch: 6| Step: 1
Training loss: 2.7151969405485774
Validation loss: 2.5088552993457505

Epoch: 6| Step: 2
Training loss: 3.26890144070272
Validation loss: 2.4987407784253675

Epoch: 6| Step: 3
Training loss: 2.8100298736721956
Validation loss: 2.488734077065671

Epoch: 6| Step: 4
Training loss: 3.0027610470939616
Validation loss: 2.4979923216068425

Epoch: 6| Step: 5
Training loss: 3.3020142910034056
Validation loss: 2.508128501046365

Epoch: 6| Step: 6
Training loss: 2.7065722584193397
Validation loss: 2.502638428494185

Epoch: 6| Step: 7
Training loss: 2.553609171311203
Validation loss: 2.517156629073333

Epoch: 6| Step: 8
Training loss: 2.7114913330727455
Validation loss: 2.526859595460015

Epoch: 6| Step: 9
Training loss: 2.1379353130178953
Validation loss: 2.5259213830701084

Epoch: 6| Step: 10
Training loss: 2.8829375449252197
Validation loss: 2.5102515476316887

Epoch: 6| Step: 11
Training loss: 1.8825317426743469
Validation loss: 2.5259876380337776

Epoch: 6| Step: 12
Training loss: 2.290865763960501
Validation loss: 2.529237062525639

Epoch: 6| Step: 13
Training loss: 2.9499514042359265
Validation loss: 2.5071992571274992

Epoch: 210| Step: 0
Training loss: 2.406147050513045
Validation loss: 2.504806696823087

Epoch: 6| Step: 1
Training loss: 2.3746716121719897
Validation loss: 2.5128567240298594

Epoch: 6| Step: 2
Training loss: 2.6274742091806855
Validation loss: 2.4946788651274177

Epoch: 6| Step: 3
Training loss: 2.193548070411732
Validation loss: 2.489128893741581

Epoch: 6| Step: 4
Training loss: 2.2811795576533145
Validation loss: 2.498425498569877

Epoch: 6| Step: 5
Training loss: 2.61971677719879
Validation loss: 2.50585237215505

Epoch: 6| Step: 6
Training loss: 3.3615126794646573
Validation loss: 2.5071707789917315

Epoch: 6| Step: 7
Training loss: 3.21219270772741
Validation loss: 2.505196107988859

Epoch: 6| Step: 8
Training loss: 2.417203964049103
Validation loss: 2.5073255198309843

Epoch: 6| Step: 9
Training loss: 2.301055425554145
Validation loss: 2.5131001811842433

Epoch: 6| Step: 10
Training loss: 3.008581603171078
Validation loss: 2.533653727296114

Epoch: 6| Step: 11
Training loss: 3.3307570674265503
Validation loss: 2.5364820358753364

Epoch: 6| Step: 12
Training loss: 3.0962178569506693
Validation loss: 2.520484845989445

Epoch: 6| Step: 13
Training loss: 2.5813355771119375
Validation loss: 2.496088085751954

Epoch: 211| Step: 0
Training loss: 2.5967513953583725
Validation loss: 2.492530550976486

Epoch: 6| Step: 1
Training loss: 2.4584692793504184
Validation loss: 2.4851640565408792

Epoch: 6| Step: 2
Training loss: 2.705094694782284
Validation loss: 2.485475542637288

Epoch: 6| Step: 3
Training loss: 2.9052731092436788
Validation loss: 2.4719015576549306

Epoch: 6| Step: 4
Training loss: 3.1250195311889652
Validation loss: 2.4790902498676486

Epoch: 6| Step: 5
Training loss: 2.7254785170071476
Validation loss: 2.4823852555983184

Epoch: 6| Step: 6
Training loss: 2.5421726369393993
Validation loss: 2.4755063506538444

Epoch: 6| Step: 7
Training loss: 2.42786439653332
Validation loss: 2.485085694575302

Epoch: 6| Step: 8
Training loss: 2.4822091312323176
Validation loss: 2.483197833734297

Epoch: 6| Step: 9
Training loss: 3.560611826795463
Validation loss: 2.4898114698204528

Epoch: 6| Step: 10
Training loss: 2.3230959448178945
Validation loss: 2.4852562779054286

Epoch: 6| Step: 11
Training loss: 2.57195936507285
Validation loss: 2.4970467485029424

Epoch: 6| Step: 12
Training loss: 2.6409365678974495
Validation loss: 2.4963373867724092

Epoch: 6| Step: 13
Training loss: 3.193408202751702
Validation loss: 2.503372614427146

Epoch: 212| Step: 0
Training loss: 2.533822153849087
Validation loss: 2.5115911423631556

Epoch: 6| Step: 1
Training loss: 1.9438603507851309
Validation loss: 2.4949229354862696

Epoch: 6| Step: 2
Training loss: 2.666630287716996
Validation loss: 2.4860416476054343

Epoch: 6| Step: 3
Training loss: 2.8182780782139574
Validation loss: 2.4939624371549347

Epoch: 6| Step: 4
Training loss: 2.8079721243037117
Validation loss: 2.487413303387464

Epoch: 6| Step: 5
Training loss: 3.015066777086054
Validation loss: 2.498551581836853

Epoch: 6| Step: 6
Training loss: 2.9700590761005654
Validation loss: 2.5028951196470923

Epoch: 6| Step: 7
Training loss: 2.1507201119908816
Validation loss: 2.4844891478141897

Epoch: 6| Step: 8
Training loss: 2.711368405617622
Validation loss: 2.4867438525166268

Epoch: 6| Step: 9
Training loss: 3.179293221437497
Validation loss: 2.4992381237304775

Epoch: 6| Step: 10
Training loss: 2.9726395675451736
Validation loss: 2.4926730964293213

Epoch: 6| Step: 11
Training loss: 2.7571985355602977
Validation loss: 2.4861949266350756

Epoch: 6| Step: 12
Training loss: 2.7429397290290907
Validation loss: 2.5024856392997656

Epoch: 6| Step: 13
Training loss: 2.8753230701207055
Validation loss: 2.505666130220537

Epoch: 213| Step: 0
Training loss: 2.773989512351521
Validation loss: 2.5096750193168242

Epoch: 6| Step: 1
Training loss: 2.4367213839620363
Validation loss: 2.514821246117505

Epoch: 6| Step: 2
Training loss: 2.278095939042715
Validation loss: 2.5115943402885117

Epoch: 6| Step: 3
Training loss: 2.348657784755493
Validation loss: 2.5055199380431596

Epoch: 6| Step: 4
Training loss: 2.4961132353259408
Validation loss: 2.514738568352257

Epoch: 6| Step: 5
Training loss: 2.5709199042765456
Validation loss: 2.5117549203087557

Epoch: 6| Step: 6
Training loss: 3.1783348411819197
Validation loss: 2.525127004172488

Epoch: 6| Step: 7
Training loss: 3.010539614444826
Validation loss: 2.5272633382422076

Epoch: 6| Step: 8
Training loss: 2.9858755763014173
Validation loss: 2.502211007313405

Epoch: 6| Step: 9
Training loss: 3.2571083972895862
Validation loss: 2.4973844340832416

Epoch: 6| Step: 10
Training loss: 2.767684600655583
Validation loss: 2.5014421354055845

Epoch: 6| Step: 11
Training loss: 2.8438827986677992
Validation loss: 2.4889585397749814

Epoch: 6| Step: 12
Training loss: 2.845046366228285
Validation loss: 2.489584541569363

Epoch: 6| Step: 13
Training loss: 1.6463550593771883
Validation loss: 2.4933558527977064

Epoch: 214| Step: 0
Training loss: 2.5883593325548575
Validation loss: 2.4794134084615527

Epoch: 6| Step: 1
Training loss: 2.2023619283986156
Validation loss: 2.495916041573425

Epoch: 6| Step: 2
Training loss: 3.1431179495759127
Validation loss: 2.501366479747881

Epoch: 6| Step: 3
Training loss: 2.9178651436384033
Validation loss: 2.4981067420703806

Epoch: 6| Step: 4
Training loss: 3.0618329002786084
Validation loss: 2.505612522364974

Epoch: 6| Step: 5
Training loss: 2.1024063855171486
Validation loss: 2.4901425418412706

Epoch: 6| Step: 6
Training loss: 3.016780019355184
Validation loss: 2.4972313460164584

Epoch: 6| Step: 7
Training loss: 2.341094076216043
Validation loss: 2.4838069463178587

Epoch: 6| Step: 8
Training loss: 3.0132159953213526
Validation loss: 2.497712257581997

Epoch: 6| Step: 9
Training loss: 2.648786943726202
Validation loss: 2.488649714708952

Epoch: 6| Step: 10
Training loss: 2.996316555845198
Validation loss: 2.4879337299347823

Epoch: 6| Step: 11
Training loss: 2.5491814963973645
Validation loss: 2.502273161900185

Epoch: 6| Step: 12
Training loss: 2.2080991608840566
Validation loss: 2.5107192113036305

Epoch: 6| Step: 13
Training loss: 3.2453619801216385
Validation loss: 2.4863461350721012

Epoch: 215| Step: 0
Training loss: 3.15047568710722
Validation loss: 2.5140439196480444

Epoch: 6| Step: 1
Training loss: 3.3052106582981273
Validation loss: 2.5470071251642383

Epoch: 6| Step: 2
Training loss: 2.6707282923982376
Validation loss: 2.575361687227795

Epoch: 6| Step: 3
Training loss: 1.9950050923753342
Validation loss: 2.599581548267387

Epoch: 6| Step: 4
Training loss: 2.843141930932874
Validation loss: 2.647642009800187

Epoch: 6| Step: 5
Training loss: 3.2155270041611757
Validation loss: 2.5949490233552366

Epoch: 6| Step: 6
Training loss: 3.0109102225144464
Validation loss: 2.5375136025043625

Epoch: 6| Step: 7
Training loss: 1.5645663521662514
Validation loss: 2.500194907025224

Epoch: 6| Step: 8
Training loss: 2.3476036434023766
Validation loss: 2.4710918164380944

Epoch: 6| Step: 9
Training loss: 2.845790592019717
Validation loss: 2.468955214603081

Epoch: 6| Step: 10
Training loss: 1.795758904185545
Validation loss: 2.487484944566428

Epoch: 6| Step: 11
Training loss: 2.6624987535070805
Validation loss: 2.4814547201090487

Epoch: 6| Step: 12
Training loss: 3.0211366873827634
Validation loss: 2.4778311839495393

Epoch: 6| Step: 13
Training loss: 3.7557131163020014
Validation loss: 2.473448397159517

Epoch: 216| Step: 0
Training loss: 3.0971848657138996
Validation loss: 2.476397672057773

Epoch: 6| Step: 1
Training loss: 2.865644741510346
Validation loss: 2.4715969845077805

Epoch: 6| Step: 2
Training loss: 2.0861385405738346
Validation loss: 2.474325612670251

Epoch: 6| Step: 3
Training loss: 2.8131387620990576
Validation loss: 2.471217643785775

Epoch: 6| Step: 4
Training loss: 2.558102812513533
Validation loss: 2.4652781801417443

Epoch: 6| Step: 5
Training loss: 2.347857017628167
Validation loss: 2.4737301086611985

Epoch: 6| Step: 6
Training loss: 3.372485601735185
Validation loss: 2.4886721364866635

Epoch: 6| Step: 7
Training loss: 2.216954539065628
Validation loss: 2.484860020550868

Epoch: 6| Step: 8
Training loss: 3.028131827867367
Validation loss: 2.4954943540242986

Epoch: 6| Step: 9
Training loss: 2.7283557143212884
Validation loss: 2.5157144487676977

Epoch: 6| Step: 10
Training loss: 2.5870733158087402
Validation loss: 2.517334451181818

Epoch: 6| Step: 11
Training loss: 2.7320449929113972
Validation loss: 2.5074948447752163

Epoch: 6| Step: 12
Training loss: 2.8350948206200686
Validation loss: 2.5063359736369804

Epoch: 6| Step: 13
Training loss: 2.669816412025306
Validation loss: 2.5137955088058885

Epoch: 217| Step: 0
Training loss: 2.387981074732639
Validation loss: 2.4949815658880343

Epoch: 6| Step: 1
Training loss: 2.2709013435841903
Validation loss: 2.479931712713873

Epoch: 6| Step: 2
Training loss: 3.510009485432994
Validation loss: 2.485556983464672

Epoch: 6| Step: 3
Training loss: 2.813689933823763
Validation loss: 2.4809684696402012

Epoch: 6| Step: 4
Training loss: 2.255188998403031
Validation loss: 2.4738941153636493

Epoch: 6| Step: 5
Training loss: 2.027226850781335
Validation loss: 2.4682304092034095

Epoch: 6| Step: 6
Training loss: 3.288077091287848
Validation loss: 2.466844501697635

Epoch: 6| Step: 7
Training loss: 2.681014374736765
Validation loss: 2.469808523680981

Epoch: 6| Step: 8
Training loss: 2.9463047612587228
Validation loss: 2.4794813311295956

Epoch: 6| Step: 9
Training loss: 2.2637309608943745
Validation loss: 2.466175036075485

Epoch: 6| Step: 10
Training loss: 3.092930540738667
Validation loss: 2.481830807230105

Epoch: 6| Step: 11
Training loss: 2.9912362840196924
Validation loss: 2.4773297262564986

Epoch: 6| Step: 12
Training loss: 2.8756014982513842
Validation loss: 2.4933845401292034

Epoch: 6| Step: 13
Training loss: 1.8559389181239254
Validation loss: 2.5310172897313077

Epoch: 218| Step: 0
Training loss: 2.419415708104299
Validation loss: 2.5345414998580336

Epoch: 6| Step: 1
Training loss: 2.5082110982452406
Validation loss: 2.5777977351316146

Epoch: 6| Step: 2
Training loss: 3.0469238277337554
Validation loss: 2.633274798627302

Epoch: 6| Step: 3
Training loss: 3.130003318906737
Validation loss: 2.7012354429896086

Epoch: 6| Step: 4
Training loss: 3.209788764349325
Validation loss: 2.667993153765392

Epoch: 6| Step: 5
Training loss: 2.501928253407554
Validation loss: 2.5209319026682833

Epoch: 6| Step: 6
Training loss: 2.5655162086606733
Validation loss: 2.469496375713054

Epoch: 6| Step: 7
Training loss: 2.5037940799148597
Validation loss: 2.4815432269588302

Epoch: 6| Step: 8
Training loss: 2.5512664940920917
Validation loss: 2.4809809283787585

Epoch: 6| Step: 9
Training loss: 3.1616279937786675
Validation loss: 2.4868074122112303

Epoch: 6| Step: 10
Training loss: 2.976032680506364
Validation loss: 2.51094591310213

Epoch: 6| Step: 11
Training loss: 2.601769149866682
Validation loss: 2.522943071673078

Epoch: 6| Step: 12
Training loss: 3.0296280444382084
Validation loss: 2.5406019871337517

Epoch: 6| Step: 13
Training loss: 2.335607294837782
Validation loss: 2.5332792314647175

Epoch: 219| Step: 0
Training loss: 2.689813195020964
Validation loss: 2.5336136835921126

Epoch: 6| Step: 1
Training loss: 2.9970303778599625
Validation loss: 2.527228746157444

Epoch: 6| Step: 2
Training loss: 2.918350133522545
Validation loss: 2.51073471837026

Epoch: 6| Step: 3
Training loss: 3.130137683411747
Validation loss: 2.496700408477313

Epoch: 6| Step: 4
Training loss: 2.3390184580517817
Validation loss: 2.4875741159469675

Epoch: 6| Step: 5
Training loss: 1.9169217921199844
Validation loss: 2.47720961667517

Epoch: 6| Step: 6
Training loss: 2.7771590931987977
Validation loss: 2.471627088157168

Epoch: 6| Step: 7
Training loss: 2.712440975267761
Validation loss: 2.466037330008164

Epoch: 6| Step: 8
Training loss: 2.7889081126847
Validation loss: 2.463385011514242

Epoch: 6| Step: 9
Training loss: 2.809102103925655
Validation loss: 2.4656076532845916

Epoch: 6| Step: 10
Training loss: 2.373357405576175
Validation loss: 2.480278732234346

Epoch: 6| Step: 11
Training loss: 2.78037633996873
Validation loss: 2.50183528886409

Epoch: 6| Step: 12
Training loss: 3.485750619623003
Validation loss: 2.537743056690457

Epoch: 6| Step: 13
Training loss: 2.647850129026591
Validation loss: 2.5403543951448433

Epoch: 220| Step: 0
Training loss: 3.2979054942195827
Validation loss: 2.5296958153559936

Epoch: 6| Step: 1
Training loss: 2.430554495917195
Validation loss: 2.540097154653986

Epoch: 6| Step: 2
Training loss: 2.081093410523707
Validation loss: 2.5339919977285867

Epoch: 6| Step: 3
Training loss: 2.6797689086292507
Validation loss: 2.5016923631660046

Epoch: 6| Step: 4
Training loss: 2.716439679576169
Validation loss: 2.509819019021467

Epoch: 6| Step: 5
Training loss: 2.9755912257398855
Validation loss: 2.4949424058091174

Epoch: 6| Step: 6
Training loss: 3.210408485067159
Validation loss: 2.500809368253497

Epoch: 6| Step: 7
Training loss: 2.5873497739664497
Validation loss: 2.472801954454842

Epoch: 6| Step: 8
Training loss: 2.2460215681336377
Validation loss: 2.481794493132611

Epoch: 6| Step: 9
Training loss: 3.104684176392833
Validation loss: 2.4629496000152225

Epoch: 6| Step: 10
Training loss: 2.542281800756078
Validation loss: 2.47646862879652

Epoch: 6| Step: 11
Training loss: 2.8630707417501275
Validation loss: 2.4760839164774784

Epoch: 6| Step: 12
Training loss: 2.47004588435871
Validation loss: 2.478003986110552

Epoch: 6| Step: 13
Training loss: 2.440967343360025
Validation loss: 2.471303686300269

Epoch: 221| Step: 0
Training loss: 2.914446521644694
Validation loss: 2.4752385272810113

Epoch: 6| Step: 1
Training loss: 2.799879112358825
Validation loss: 2.4707893742715377

Epoch: 6| Step: 2
Training loss: 2.7877232517768538
Validation loss: 2.464072238613302

Epoch: 6| Step: 3
Training loss: 2.4618795862322216
Validation loss: 2.4631853673067496

Epoch: 6| Step: 4
Training loss: 2.7698291785110327
Validation loss: 2.4745352496707236

Epoch: 6| Step: 5
Training loss: 3.180122514439993
Validation loss: 2.4651849451822794

Epoch: 6| Step: 6
Training loss: 1.9691804687730914
Validation loss: 2.4630173896645067

Epoch: 6| Step: 7
Training loss: 2.6610715302576797
Validation loss: 2.467713728489566

Epoch: 6| Step: 8
Training loss: 3.004153872677406
Validation loss: 2.472952951870239

Epoch: 6| Step: 9
Training loss: 2.644016412969712
Validation loss: 2.4701643413111745

Epoch: 6| Step: 10
Training loss: 2.68885458586314
Validation loss: 2.473857525173286

Epoch: 6| Step: 11
Training loss: 2.9261953470828894
Validation loss: 2.465601407437333

Epoch: 6| Step: 12
Training loss: 2.575725571710651
Validation loss: 2.48810488047045

Epoch: 6| Step: 13
Training loss: 2.1552670214704004
Validation loss: 2.4867812159666034

Epoch: 222| Step: 0
Training loss: 2.3779729004992958
Validation loss: 2.5081726700860627

Epoch: 6| Step: 1
Training loss: 2.816035274035433
Validation loss: 2.5268582603039293

Epoch: 6| Step: 2
Training loss: 2.923038189936399
Validation loss: 2.5248133529967887

Epoch: 6| Step: 3
Training loss: 2.5098019133441736
Validation loss: 2.5217494166182823

Epoch: 6| Step: 4
Training loss: 2.768310622233689
Validation loss: 2.491192584925028

Epoch: 6| Step: 5
Training loss: 2.953795987552963
Validation loss: 2.496737177298767

Epoch: 6| Step: 6
Training loss: 2.158873358174523
Validation loss: 2.4753160006264223

Epoch: 6| Step: 7
Training loss: 3.1328718603127785
Validation loss: 2.4738901484904674

Epoch: 6| Step: 8
Training loss: 2.655008003237169
Validation loss: 2.4758637692776815

Epoch: 6| Step: 9
Training loss: 2.922572414783476
Validation loss: 2.489752470032444

Epoch: 6| Step: 10
Training loss: 2.464031974492129
Validation loss: 2.488702185019286

Epoch: 6| Step: 11
Training loss: 2.6536964259442595
Validation loss: 2.479462019597044

Epoch: 6| Step: 12
Training loss: 2.359049591461694
Validation loss: 2.47221550597392

Epoch: 6| Step: 13
Training loss: 3.231298485397689
Validation loss: 2.4660402761733065

Epoch: 223| Step: 0
Training loss: 2.2727439845077604
Validation loss: 2.475650776747394

Epoch: 6| Step: 1
Training loss: 2.7703936139499383
Validation loss: 2.4678399436303677

Epoch: 6| Step: 2
Training loss: 2.987859000498576
Validation loss: 2.491869741318567

Epoch: 6| Step: 3
Training loss: 2.886421074701922
Validation loss: 2.4822865078563994

Epoch: 6| Step: 4
Training loss: 2.9959852057220298
Validation loss: 2.5136912342646824

Epoch: 6| Step: 5
Training loss: 2.2566116465853487
Validation loss: 2.5186547381064743

Epoch: 6| Step: 6
Training loss: 2.6792529229200417
Validation loss: 2.518327782959119

Epoch: 6| Step: 7
Training loss: 2.4012741561063833
Validation loss: 2.5090822007165285

Epoch: 6| Step: 8
Training loss: 2.8778330900292644
Validation loss: 2.5251179080044115

Epoch: 6| Step: 9
Training loss: 2.3780093953209307
Validation loss: 2.5123636297591774

Epoch: 6| Step: 10
Training loss: 2.4306744597884293
Validation loss: 2.5459708606965235

Epoch: 6| Step: 11
Training loss: 2.518210651970028
Validation loss: 2.538786083033336

Epoch: 6| Step: 12
Training loss: 3.2386817454393673
Validation loss: 2.5501190126407414

Epoch: 6| Step: 13
Training loss: 3.2560834435682837
Validation loss: 2.5546579456153298

Epoch: 224| Step: 0
Training loss: 2.3164638878790353
Validation loss: 2.4993850587485205

Epoch: 6| Step: 1
Training loss: 2.6353381802377376
Validation loss: 2.505501653444971

Epoch: 6| Step: 2
Training loss: 2.555376619026945
Validation loss: 2.498958886667586

Epoch: 6| Step: 3
Training loss: 2.4456683500188023
Validation loss: 2.4846978478585195

Epoch: 6| Step: 4
Training loss: 2.304099625433618
Validation loss: 2.490210147155097

Epoch: 6| Step: 5
Training loss: 3.131125283565293
Validation loss: 2.4905614906283935

Epoch: 6| Step: 6
Training loss: 2.362630051358553
Validation loss: 2.488434491009376

Epoch: 6| Step: 7
Training loss: 3.000429122751327
Validation loss: 2.477803566393795

Epoch: 6| Step: 8
Training loss: 3.0539381273918274
Validation loss: 2.4891312811294575

Epoch: 6| Step: 9
Training loss: 3.0660863624448376
Validation loss: 2.5044323361478877

Epoch: 6| Step: 10
Training loss: 3.3505059557635373
Validation loss: 2.484626877468288

Epoch: 6| Step: 11
Training loss: 1.929088236928924
Validation loss: 2.482298907824861

Epoch: 6| Step: 12
Training loss: 2.457781605850712
Validation loss: 2.491650605596665

Epoch: 6| Step: 13
Training loss: 2.852014793165023
Validation loss: 2.480203239319678

Epoch: 225| Step: 0
Training loss: 2.8420700309012226
Validation loss: 2.487612484092138

Epoch: 6| Step: 1
Training loss: 2.717442165064639
Validation loss: 2.4885640308768333

Epoch: 6| Step: 2
Training loss: 2.8124365905395385
Validation loss: 2.4828490641991907

Epoch: 6| Step: 3
Training loss: 2.607517883590567
Validation loss: 2.5006235806250237

Epoch: 6| Step: 4
Training loss: 2.592593383284352
Validation loss: 2.4891895963325132

Epoch: 6| Step: 5
Training loss: 3.0180671567226254
Validation loss: 2.4813897711337276

Epoch: 6| Step: 6
Training loss: 2.7846814536019497
Validation loss: 2.4843781369912397

Epoch: 6| Step: 7
Training loss: 2.773683520943409
Validation loss: 2.4868638799475167

Epoch: 6| Step: 8
Training loss: 2.6185004286096474
Validation loss: 2.483944899057781

Epoch: 6| Step: 9
Training loss: 2.696818586093178
Validation loss: 2.4787138596654397

Epoch: 6| Step: 10
Training loss: 2.548623824427116
Validation loss: 2.488237858108335

Epoch: 6| Step: 11
Training loss: 2.2722386086247957
Validation loss: 2.4786482886282037

Epoch: 6| Step: 12
Training loss: 2.794078259736689
Validation loss: 2.483976336663923

Epoch: 6| Step: 13
Training loss: 2.567813203126092
Validation loss: 2.486838122423287

Epoch: 226| Step: 0
Training loss: 2.722760979760301
Validation loss: 2.5104759633784894

Epoch: 6| Step: 1
Training loss: 2.6641968276538264
Validation loss: 2.517602569085404

Epoch: 6| Step: 2
Training loss: 2.9390871346073517
Validation loss: 2.540250377211632

Epoch: 6| Step: 3
Training loss: 2.238651052021025
Validation loss: 2.5584377080606693

Epoch: 6| Step: 4
Training loss: 2.900535461714034
Validation loss: 2.587220363517789

Epoch: 6| Step: 5
Training loss: 2.063864747709592
Validation loss: 2.5897156105183936

Epoch: 6| Step: 6
Training loss: 3.2713488194863727
Validation loss: 2.5534869862924467

Epoch: 6| Step: 7
Training loss: 2.635419330419669
Validation loss: 2.515208898877261

Epoch: 6| Step: 8
Training loss: 2.805968605665253
Validation loss: 2.4857702760820937

Epoch: 6| Step: 9
Training loss: 2.403779383979167
Validation loss: 2.463424122727905

Epoch: 6| Step: 10
Training loss: 3.0269272646978957
Validation loss: 2.4644419178081387

Epoch: 6| Step: 11
Training loss: 2.678348573769121
Validation loss: 2.456831574696039

Epoch: 6| Step: 12
Training loss: 3.2191244851934315
Validation loss: 2.4543849660855113

Epoch: 6| Step: 13
Training loss: 1.887749621324952
Validation loss: 2.460676437154074

Epoch: 227| Step: 0
Training loss: 3.5667081372948792
Validation loss: 2.457231291971094

Epoch: 6| Step: 1
Training loss: 2.913305434814303
Validation loss: 2.4548892121454085

Epoch: 6| Step: 2
Training loss: 2.6660096332636423
Validation loss: 2.45725093418772

Epoch: 6| Step: 3
Training loss: 2.5056018057720455
Validation loss: 2.456209170908544

Epoch: 6| Step: 4
Training loss: 1.9936179616608807
Validation loss: 2.4586400848215018

Epoch: 6| Step: 5
Training loss: 2.3493879535761417
Validation loss: 2.4542496287911337

Epoch: 6| Step: 6
Training loss: 2.4565223445796183
Validation loss: 2.464776400623375

Epoch: 6| Step: 7
Training loss: 2.965887034409589
Validation loss: 2.4701126946330563

Epoch: 6| Step: 8
Training loss: 2.5205092313718884
Validation loss: 2.4757113976760015

Epoch: 6| Step: 9
Training loss: 2.667924157324308
Validation loss: 2.521201648278924

Epoch: 6| Step: 10
Training loss: 2.548808013719747
Validation loss: 2.5224864847373687

Epoch: 6| Step: 11
Training loss: 2.484519714363235
Validation loss: 2.524379692368091

Epoch: 6| Step: 12
Training loss: 2.9166140597004238
Validation loss: 2.5087026230878453

Epoch: 6| Step: 13
Training loss: 3.15431441074847
Validation loss: 2.5060345747982047

Epoch: 228| Step: 0
Training loss: 2.532170069631115
Validation loss: 2.5016660266299424

Epoch: 6| Step: 1
Training loss: 2.45776336873027
Validation loss: 2.496455415667586

Epoch: 6| Step: 2
Training loss: 3.0861783863162424
Validation loss: 2.514447257985307

Epoch: 6| Step: 3
Training loss: 2.920431341423849
Validation loss: 2.513445906617308

Epoch: 6| Step: 4
Training loss: 1.9429912275939905
Validation loss: 2.517693515698872

Epoch: 6| Step: 5
Training loss: 2.343003319373651
Validation loss: 2.494672626295648

Epoch: 6| Step: 6
Training loss: 2.5942019333133812
Validation loss: 2.5082868959789377

Epoch: 6| Step: 7
Training loss: 2.8678159103049046
Validation loss: 2.483197557052464

Epoch: 6| Step: 8
Training loss: 3.551838498146973
Validation loss: 2.4751785535016

Epoch: 6| Step: 9
Training loss: 2.362016222634029
Validation loss: 2.4681140095507734

Epoch: 6| Step: 10
Training loss: 2.9449210071170295
Validation loss: 2.466593278375456

Epoch: 6| Step: 11
Training loss: 2.3481011246865306
Validation loss: 2.4836027028885574

Epoch: 6| Step: 12
Training loss: 2.425334305676892
Validation loss: 2.475832216751975

Epoch: 6| Step: 13
Training loss: 2.9395318004940383
Validation loss: 2.4645141071189305

Epoch: 229| Step: 0
Training loss: 2.9277298146645605
Validation loss: 2.4583451635939184

Epoch: 6| Step: 1
Training loss: 2.0785480728297947
Validation loss: 2.4583883666950155

Epoch: 6| Step: 2
Training loss: 2.754010743668044
Validation loss: 2.459890135105812

Epoch: 6| Step: 3
Training loss: 2.767380755163458
Validation loss: 2.459969934337632

Epoch: 6| Step: 4
Training loss: 2.2636594467546014
Validation loss: 2.4627469568768996

Epoch: 6| Step: 5
Training loss: 2.4692116800617496
Validation loss: 2.448153795125653

Epoch: 6| Step: 6
Training loss: 2.878250440748756
Validation loss: 2.4646311947936406

Epoch: 6| Step: 7
Training loss: 2.1984998703644894
Validation loss: 2.4824515127840288

Epoch: 6| Step: 8
Training loss: 2.5849571559461855
Validation loss: 2.5065166734229267

Epoch: 6| Step: 9
Training loss: 2.900703634204351
Validation loss: 2.5140984928515357

Epoch: 6| Step: 10
Training loss: 2.7465398000225503
Validation loss: 2.5309624518104656

Epoch: 6| Step: 11
Training loss: 3.0771543260019825
Validation loss: 2.550298010495029

Epoch: 6| Step: 12
Training loss: 3.3342951499580376
Validation loss: 2.54940112973879

Epoch: 6| Step: 13
Training loss: 2.325180752198742
Validation loss: 2.510075359369392

Epoch: 230| Step: 0
Training loss: 2.4622847487195414
Validation loss: 2.4660190510227626

Epoch: 6| Step: 1
Training loss: 3.0632942882397547
Validation loss: 2.446890123837856

Epoch: 6| Step: 2
Training loss: 3.050171619026965
Validation loss: 2.4528434032169235

Epoch: 6| Step: 3
Training loss: 2.2541891941865164
Validation loss: 2.4632552486268544

Epoch: 6| Step: 4
Training loss: 2.9587155663791638
Validation loss: 2.4692891493909674

Epoch: 6| Step: 5
Training loss: 2.482500436711729
Validation loss: 2.468475868640991

Epoch: 6| Step: 6
Training loss: 2.781610872666419
Validation loss: 2.4657713019455967

Epoch: 6| Step: 7
Training loss: 2.7505044474466103
Validation loss: 2.4638334731615728

Epoch: 6| Step: 8
Training loss: 2.807269594651872
Validation loss: 2.45447424851481

Epoch: 6| Step: 9
Training loss: 2.599254970911587
Validation loss: 2.4754682443299223

Epoch: 6| Step: 10
Training loss: 2.886536877675253
Validation loss: 2.464066639130721

Epoch: 6| Step: 11
Training loss: 2.719429282030441
Validation loss: 2.4701550567579798

Epoch: 6| Step: 12
Training loss: 2.49105235110555
Validation loss: 2.4571949674890594

Epoch: 6| Step: 13
Training loss: 2.6449751375756927
Validation loss: 2.46510700056247

Epoch: 231| Step: 0
Training loss: 2.6480425424817504
Validation loss: 2.4774918173033607

Epoch: 6| Step: 1
Training loss: 3.021956995548874
Validation loss: 2.480730067576434

Epoch: 6| Step: 2
Training loss: 2.51345665402331
Validation loss: 2.4905937582460953

Epoch: 6| Step: 3
Training loss: 2.605668227582216
Validation loss: 2.5031104457607696

Epoch: 6| Step: 4
Training loss: 2.592595038589454
Validation loss: 2.517466572235747

Epoch: 6| Step: 5
Training loss: 2.5244323847860226
Validation loss: 2.512903389005374

Epoch: 6| Step: 6
Training loss: 2.8641451043819477
Validation loss: 2.498492893611855

Epoch: 6| Step: 7
Training loss: 2.3605204448012533
Validation loss: 2.5268884797050575

Epoch: 6| Step: 8
Training loss: 2.655964555549813
Validation loss: 2.5179789373091657

Epoch: 6| Step: 9
Training loss: 2.056420005565091
Validation loss: 2.509958399924827

Epoch: 6| Step: 10
Training loss: 2.8534034952408733
Validation loss: 2.512896473123188

Epoch: 6| Step: 11
Training loss: 3.3029216259843373
Validation loss: 2.520214269889245

Epoch: 6| Step: 12
Training loss: 2.752581338538165
Validation loss: 2.53038465058746

Epoch: 6| Step: 13
Training loss: 2.5150086968880174
Validation loss: 2.5290413166803263

Epoch: 232| Step: 0
Training loss: 2.4027978483426358
Validation loss: 2.5249134591874545

Epoch: 6| Step: 1
Training loss: 2.3041119390223135
Validation loss: 2.5209230023792966

Epoch: 6| Step: 2
Training loss: 2.8605964428186987
Validation loss: 2.5307731660369046

Epoch: 6| Step: 3
Training loss: 1.8662960206762464
Validation loss: 2.5260627222193226

Epoch: 6| Step: 4
Training loss: 2.5455891926563003
Validation loss: 2.5365660626580575

Epoch: 6| Step: 5
Training loss: 2.728431389067468
Validation loss: 2.5557555510271257

Epoch: 6| Step: 6
Training loss: 2.9267661215785457
Validation loss: 2.5239015685424673

Epoch: 6| Step: 7
Training loss: 2.7631716433878575
Validation loss: 2.5035545551729492

Epoch: 6| Step: 8
Training loss: 3.4925659793855472
Validation loss: 2.4857488274933686

Epoch: 6| Step: 9
Training loss: 2.846193039717429
Validation loss: 2.4608636941697446

Epoch: 6| Step: 10
Training loss: 3.0214780623722035
Validation loss: 2.4544184383682803

Epoch: 6| Step: 11
Training loss: 2.6995160481512372
Validation loss: 2.47478721908022

Epoch: 6| Step: 12
Training loss: 2.296826628091306
Validation loss: 2.4721714318123866

Epoch: 6| Step: 13
Training loss: 1.9778075989547812
Validation loss: 2.466867930186946

Epoch: 233| Step: 0
Training loss: 2.801138925524818
Validation loss: 2.475699608289663

Epoch: 6| Step: 1
Training loss: 2.6425649525609427
Validation loss: 2.4735307076283495

Epoch: 6| Step: 2
Training loss: 2.2653929492896285
Validation loss: 2.478203251695946

Epoch: 6| Step: 3
Training loss: 2.4782835939705437
Validation loss: 2.497973975750497

Epoch: 6| Step: 4
Training loss: 2.424481177132849
Validation loss: 2.5012101874408734

Epoch: 6| Step: 5
Training loss: 2.81225881602048
Validation loss: 2.515433891515835

Epoch: 6| Step: 6
Training loss: 3.048767128333618
Validation loss: 2.5339438848491476

Epoch: 6| Step: 7
Training loss: 3.1015758754336122
Validation loss: 2.5623182656998265

Epoch: 6| Step: 8
Training loss: 2.687433197610663
Validation loss: 2.5836948933344104

Epoch: 6| Step: 9
Training loss: 2.5673489167539474
Validation loss: 2.5793775730641078

Epoch: 6| Step: 10
Training loss: 2.9702831927062183
Validation loss: 2.5398499696864305

Epoch: 6| Step: 11
Training loss: 2.6936569658043448
Validation loss: 2.5107475644428012

Epoch: 6| Step: 12
Training loss: 2.3420564763713925
Validation loss: 2.500971067169595

Epoch: 6| Step: 13
Training loss: 2.4538032906060865
Validation loss: 2.4946772023996058

Epoch: 234| Step: 0
Training loss: 2.5815589923047493
Validation loss: 2.5002337572065025

Epoch: 6| Step: 1
Training loss: 2.536635521268523
Validation loss: 2.4999262706590324

Epoch: 6| Step: 2
Training loss: 2.9721897476022545
Validation loss: 2.5031897551092173

Epoch: 6| Step: 3
Training loss: 2.37948456047293
Validation loss: 2.5205726973556897

Epoch: 6| Step: 4
Training loss: 3.2220301534329794
Validation loss: 2.539603068546705

Epoch: 6| Step: 5
Training loss: 2.8749401252150935
Validation loss: 2.5370220295692794

Epoch: 6| Step: 6
Training loss: 2.6466043705499067
Validation loss: 2.5307828015521023

Epoch: 6| Step: 7
Training loss: 2.48360935145083
Validation loss: 2.532616377538262

Epoch: 6| Step: 8
Training loss: 2.3854622538068293
Validation loss: 2.540411116734872

Epoch: 6| Step: 9
Training loss: 2.4955496277044737
Validation loss: 2.52161433373496

Epoch: 6| Step: 10
Training loss: 2.7967044202903235
Validation loss: 2.5267947350752453

Epoch: 6| Step: 11
Training loss: 2.0878538551340102
Validation loss: 2.5227942772571126

Epoch: 6| Step: 12
Training loss: 3.115571867739423
Validation loss: 2.544305551749487

Epoch: 6| Step: 13
Training loss: 2.7492640984522256
Validation loss: 2.524916461540198

Epoch: 235| Step: 0
Training loss: 2.9187211747961834
Validation loss: 2.5057581853137227

Epoch: 6| Step: 1
Training loss: 2.4157162035939055
Validation loss: 2.4874929792321896

Epoch: 6| Step: 2
Training loss: 2.936889585015125
Validation loss: 2.4623652626472996

Epoch: 6| Step: 3
Training loss: 2.856681347085569
Validation loss: 2.4548841838360898

Epoch: 6| Step: 4
Training loss: 2.5660628694368235
Validation loss: 2.4534137530544506

Epoch: 6| Step: 5
Training loss: 2.4324054786689433
Validation loss: 2.4557757452100963

Epoch: 6| Step: 6
Training loss: 3.104424143786794
Validation loss: 2.4787610205496247

Epoch: 6| Step: 7
Training loss: 2.207446466058168
Validation loss: 2.4759068893080647

Epoch: 6| Step: 8
Training loss: 2.872919407862369
Validation loss: 2.4858073076451133

Epoch: 6| Step: 9
Training loss: 2.3826379930976387
Validation loss: 2.5130133192887403

Epoch: 6| Step: 10
Training loss: 1.99851517395871
Validation loss: 2.489874184135499

Epoch: 6| Step: 11
Training loss: 2.9354390158162325
Validation loss: 2.518481724280325

Epoch: 6| Step: 12
Training loss: 2.4956684735278327
Validation loss: 2.516132488766345

Epoch: 6| Step: 13
Training loss: 2.813282666978
Validation loss: 2.4780053537968043

Epoch: 236| Step: 0
Training loss: 2.4559024710534945
Validation loss: 2.4662559624937854

Epoch: 6| Step: 1
Training loss: 2.918561392659433
Validation loss: 2.4565555894567326

Epoch: 6| Step: 2
Training loss: 1.7317018270487432
Validation loss: 2.460848902630886

Epoch: 6| Step: 3
Training loss: 2.64564966079894
Validation loss: 2.4594694452770653

Epoch: 6| Step: 4
Training loss: 2.362277840962064
Validation loss: 2.464256518163038

Epoch: 6| Step: 5
Training loss: 2.918476106588677
Validation loss: 2.472695334834726

Epoch: 6| Step: 6
Training loss: 2.9366690901170043
Validation loss: 2.4757440731916067

Epoch: 6| Step: 7
Training loss: 2.3638628787761276
Validation loss: 2.4729528606431175

Epoch: 6| Step: 8
Training loss: 2.847147159569064
Validation loss: 2.4944743320413267

Epoch: 6| Step: 9
Training loss: 2.4851955762076257
Validation loss: 2.496677268146618

Epoch: 6| Step: 10
Training loss: 3.3690278230663537
Validation loss: 2.4708266319174754

Epoch: 6| Step: 11
Training loss: 2.402398829875436
Validation loss: 2.479523944695387

Epoch: 6| Step: 12
Training loss: 2.6966651949821516
Validation loss: 2.4834123055332626

Epoch: 6| Step: 13
Training loss: 2.591566706586952
Validation loss: 2.4970329120456998

Epoch: 237| Step: 0
Training loss: 2.1296397774066045
Validation loss: 2.4833060232597313

Epoch: 6| Step: 1
Training loss: 2.252138922537842
Validation loss: 2.469846891706473

Epoch: 6| Step: 2
Training loss: 2.520553405183828
Validation loss: 2.4594712078989875

Epoch: 6| Step: 3
Training loss: 3.131590188557536
Validation loss: 2.461546519873577

Epoch: 6| Step: 4
Training loss: 3.0178347382798085
Validation loss: 2.4547016132035413

Epoch: 6| Step: 5
Training loss: 2.3679749843977236
Validation loss: 2.460567112486587

Epoch: 6| Step: 6
Training loss: 2.706996548693077
Validation loss: 2.453236861794395

Epoch: 6| Step: 7
Training loss: 2.686139583031304
Validation loss: 2.4504567334803182

Epoch: 6| Step: 8
Training loss: 3.1765514157801267
Validation loss: 2.4660879990881477

Epoch: 6| Step: 9
Training loss: 2.155087143625207
Validation loss: 2.4654854706389164

Epoch: 6| Step: 10
Training loss: 2.6381291439093437
Validation loss: 2.493325889138798

Epoch: 6| Step: 11
Training loss: 1.8055566453522873
Validation loss: 2.48810367495042

Epoch: 6| Step: 12
Training loss: 2.732495517569981
Validation loss: 2.4789249581193236

Epoch: 6| Step: 13
Training loss: 3.5075920052672944
Validation loss: 2.484107130709874

Epoch: 238| Step: 0
Training loss: 2.9639709555043283
Validation loss: 2.4640370798526505

Epoch: 6| Step: 1
Training loss: 2.8917440361936975
Validation loss: 2.470437894086256

Epoch: 6| Step: 2
Training loss: 2.1735402042522085
Validation loss: 2.464266809088527

Epoch: 6| Step: 3
Training loss: 2.2470703125
Validation loss: 2.452168669296802

Epoch: 6| Step: 4
Training loss: 2.833444555754905
Validation loss: 2.4625423284298757

Epoch: 6| Step: 5
Training loss: 2.6466159013672756
Validation loss: 2.466082680185715

Epoch: 6| Step: 6
Training loss: 2.9119700264802915
Validation loss: 2.4516108160841195

Epoch: 6| Step: 7
Training loss: 2.4480672803496746
Validation loss: 2.45532231822233

Epoch: 6| Step: 8
Training loss: 2.233164212480207
Validation loss: 2.4664184673952256

Epoch: 6| Step: 9
Training loss: 2.6234728594379937
Validation loss: 2.4762040268253296

Epoch: 6| Step: 10
Training loss: 3.26298964176761
Validation loss: 2.502815258593957

Epoch: 6| Step: 11
Training loss: 2.1791880045539656
Validation loss: 2.5470384034141564

Epoch: 6| Step: 12
Training loss: 3.191383837991225
Validation loss: 2.551061558721998

Epoch: 6| Step: 13
Training loss: 2.079187336769892
Validation loss: 2.527754609159068

Epoch: 239| Step: 0
Training loss: 2.1719816991270378
Validation loss: 2.513427933653166

Epoch: 6| Step: 1
Training loss: 1.8668937930938607
Validation loss: 2.5129352575199855

Epoch: 6| Step: 2
Training loss: 2.319920259453628
Validation loss: 2.4985821394923664

Epoch: 6| Step: 3
Training loss: 2.7874191101380403
Validation loss: 2.4893538265030104

Epoch: 6| Step: 4
Training loss: 2.48794855262087
Validation loss: 2.4706471698959658

Epoch: 6| Step: 5
Training loss: 2.5944053097844963
Validation loss: 2.460132052067648

Epoch: 6| Step: 6
Training loss: 3.2219690318404166
Validation loss: 2.454216417441764

Epoch: 6| Step: 7
Training loss: 2.833644139315374
Validation loss: 2.473143218406498

Epoch: 6| Step: 8
Training loss: 3.5127439095192727
Validation loss: 2.4599218608499216

Epoch: 6| Step: 9
Training loss: 3.138640578659308
Validation loss: 2.4957684308392762

Epoch: 6| Step: 10
Training loss: 2.0974812070529807
Validation loss: 2.4915553859491633

Epoch: 6| Step: 11
Training loss: 2.2800463283583623
Validation loss: 2.491740370735281

Epoch: 6| Step: 12
Training loss: 2.593863243480447
Validation loss: 2.4865789499355646

Epoch: 6| Step: 13
Training loss: 2.6966051623101417
Validation loss: 2.4660231875348178

Epoch: 240| Step: 0
Training loss: 2.8136873917666168
Validation loss: 2.4562523614811065

Epoch: 6| Step: 1
Training loss: 2.3514281579864673
Validation loss: 2.4420164203071413

Epoch: 6| Step: 2
Training loss: 2.9012391567068683
Validation loss: 2.443990999856722

Epoch: 6| Step: 3
Training loss: 2.7050897591130685
Validation loss: 2.4308813310585693

Epoch: 6| Step: 4
Training loss: 2.943443292080941
Validation loss: 2.4354689702618093

Epoch: 6| Step: 5
Training loss: 1.9059810761415925
Validation loss: 2.4342858152757527

Epoch: 6| Step: 6
Training loss: 2.2676700175851834
Validation loss: 2.443109066783272

Epoch: 6| Step: 7
Training loss: 2.414412488535238
Validation loss: 2.4360309061997856

Epoch: 6| Step: 8
Training loss: 2.7160750636204263
Validation loss: 2.4556950966630393

Epoch: 6| Step: 9
Training loss: 2.1222702894154293
Validation loss: 2.463290825475286

Epoch: 6| Step: 10
Training loss: 3.1020582749324133
Validation loss: 2.466907948491798

Epoch: 6| Step: 11
Training loss: 2.6228895331916697
Validation loss: 2.4671554675676344

Epoch: 6| Step: 12
Training loss: 3.1762124457422996
Validation loss: 2.4892235079398612

Epoch: 6| Step: 13
Training loss: 2.875611945000149
Validation loss: 2.4891990302879483

Epoch: 241| Step: 0
Training loss: 2.793208782845534
Validation loss: 2.4775097477779924

Epoch: 6| Step: 1
Training loss: 2.0551837278408676
Validation loss: 2.4925965215138186

Epoch: 6| Step: 2
Training loss: 2.6916359414471867
Validation loss: 2.4745819235052156

Epoch: 6| Step: 3
Training loss: 2.4998691524595733
Validation loss: 2.4914018985476694

Epoch: 6| Step: 4
Training loss: 2.8185052126812065
Validation loss: 2.4847886740828335

Epoch: 6| Step: 5
Training loss: 2.9964855589433523
Validation loss: 2.4909853089620277

Epoch: 6| Step: 6
Training loss: 2.1791930372734702
Validation loss: 2.474342337286878

Epoch: 6| Step: 7
Training loss: 2.10642403356197
Validation loss: 2.468859826777605

Epoch: 6| Step: 8
Training loss: 2.5663354593903955
Validation loss: 2.460739899212554

Epoch: 6| Step: 9
Training loss: 2.789828668071282
Validation loss: 2.482035224354104

Epoch: 6| Step: 10
Training loss: 3.4348864243122805
Validation loss: 2.4977244223919057

Epoch: 6| Step: 11
Training loss: 2.2005026069804225
Validation loss: 2.4826497584527933

Epoch: 6| Step: 12
Training loss: 2.7891353309162032
Validation loss: 2.4885311734309887

Epoch: 6| Step: 13
Training loss: 2.296527135547904
Validation loss: 2.4656531122199654

Epoch: 242| Step: 0
Training loss: 2.5615742569658595
Validation loss: 2.463587660443502

Epoch: 6| Step: 1
Training loss: 2.5724015022602065
Validation loss: 2.478334711429197

Epoch: 6| Step: 2
Training loss: 2.376595212371429
Validation loss: 2.489658581291636

Epoch: 6| Step: 3
Training loss: 2.1441615607681097
Validation loss: 2.5124465122038373

Epoch: 6| Step: 4
Training loss: 3.140530864766151
Validation loss: 2.5105277263134895

Epoch: 6| Step: 5
Training loss: 3.0188755048800613
Validation loss: 2.515853852063692

Epoch: 6| Step: 6
Training loss: 3.3543186192814485
Validation loss: 2.518581350271187

Epoch: 6| Step: 7
Training loss: 2.4668133056286727
Validation loss: 2.4950609116884133

Epoch: 6| Step: 8
Training loss: 2.658159893281349
Validation loss: 2.500228312536956

Epoch: 6| Step: 9
Training loss: 2.4608235650708896
Validation loss: 2.47573203026139

Epoch: 6| Step: 10
Training loss: 2.5122846140990416
Validation loss: 2.4819168268077716

Epoch: 6| Step: 11
Training loss: 2.1175624613911785
Validation loss: 2.482622145966745

Epoch: 6| Step: 12
Training loss: 2.191991717622243
Validation loss: 2.5075232118806863

Epoch: 6| Step: 13
Training loss: 2.9205662045151546
Validation loss: 2.498664308407762

Epoch: 243| Step: 0
Training loss: 2.534058884403925
Validation loss: 2.5083709913746635

Epoch: 6| Step: 1
Training loss: 2.908257888063135
Validation loss: 2.505838578181307

Epoch: 6| Step: 2
Training loss: 2.497677678078045
Validation loss: 2.4998219724045936

Epoch: 6| Step: 3
Training loss: 2.4636092926055766
Validation loss: 2.499426341125487

Epoch: 6| Step: 4
Training loss: 2.3179586782516273
Validation loss: 2.489805915868606

Epoch: 6| Step: 5
Training loss: 2.232734344588137
Validation loss: 2.5092240771515546

Epoch: 6| Step: 6
Training loss: 2.7380919561109756
Validation loss: 2.498804370502187

Epoch: 6| Step: 7
Training loss: 2.580048739246452
Validation loss: 2.486338770002563

Epoch: 6| Step: 8
Training loss: 2.808035634578207
Validation loss: 2.4994875321123904

Epoch: 6| Step: 9
Training loss: 2.400057764152928
Validation loss: 2.5082330375092896

Epoch: 6| Step: 10
Training loss: 2.826528868045492
Validation loss: 2.501041276513204

Epoch: 6| Step: 11
Training loss: 2.829001612242438
Validation loss: 2.4953687234545283

Epoch: 6| Step: 12
Training loss: 2.659575859759352
Validation loss: 2.496873997758129

Epoch: 6| Step: 13
Training loss: 2.7969979200577053
Validation loss: 2.4779826823857856

Epoch: 244| Step: 0
Training loss: 2.3914230111801844
Validation loss: 2.4924452736413945

Epoch: 6| Step: 1
Training loss: 2.868590798874374
Validation loss: 2.4878522411946022

Epoch: 6| Step: 2
Training loss: 2.444684322705716
Validation loss: 2.48209814754309

Epoch: 6| Step: 3
Training loss: 2.6192797141014026
Validation loss: 2.46744881157866

Epoch: 6| Step: 4
Training loss: 2.4338527682432542
Validation loss: 2.480186627613841

Epoch: 6| Step: 5
Training loss: 3.194127093782486
Validation loss: 2.4668271993493933

Epoch: 6| Step: 6
Training loss: 2.466132502669197
Validation loss: 2.464945189230581

Epoch: 6| Step: 7
Training loss: 2.3545744101155512
Validation loss: 2.4594920986771514

Epoch: 6| Step: 8
Training loss: 2.2874356370219613
Validation loss: 2.4700166633770912

Epoch: 6| Step: 9
Training loss: 2.4230660739884033
Validation loss: 2.4717493328173235

Epoch: 6| Step: 10
Training loss: 2.782442672975232
Validation loss: 2.4770080055972095

Epoch: 6| Step: 11
Training loss: 3.2584036238195253
Validation loss: 2.4841516494576394

Epoch: 6| Step: 12
Training loss: 1.9519952787436
Validation loss: 2.5252152524088567

Epoch: 6| Step: 13
Training loss: 2.832165103248415
Validation loss: 2.55581280899817

Epoch: 245| Step: 0
Training loss: 2.43364488967385
Validation loss: 2.623941435622693

Epoch: 6| Step: 1
Training loss: 2.678693581475171
Validation loss: 2.6956310167834143

Epoch: 6| Step: 2
Training loss: 2.9728573945375913
Validation loss: 2.7407056484946253

Epoch: 6| Step: 3
Training loss: 2.3211025344441016
Validation loss: 2.7507890900407896

Epoch: 6| Step: 4
Training loss: 2.7607635184166646
Validation loss: 2.7491387494332327

Epoch: 6| Step: 5
Training loss: 2.538086313245451
Validation loss: 2.631528239107048

Epoch: 6| Step: 6
Training loss: 2.5510650056327195
Validation loss: 2.5396534918367517

Epoch: 6| Step: 7
Training loss: 1.9860099004938567
Validation loss: 2.502300636427964

Epoch: 6| Step: 8
Training loss: 2.7167763397296336
Validation loss: 2.4995746194251467

Epoch: 6| Step: 9
Training loss: 2.0729178679445197
Validation loss: 2.5108910528828274

Epoch: 6| Step: 10
Training loss: 3.3640144426214964
Validation loss: 2.518559535760256

Epoch: 6| Step: 11
Training loss: 2.654775681583125
Validation loss: 2.525704137496624

Epoch: 6| Step: 12
Training loss: 2.7004795249102016
Validation loss: 2.5322383620610798

Epoch: 6| Step: 13
Training loss: 3.940442998738359
Validation loss: 2.5137694469500924

Epoch: 246| Step: 0
Training loss: 2.601880486560675
Validation loss: 2.5247698010160473

Epoch: 6| Step: 1
Training loss: 2.8326087099848145
Validation loss: 2.5017860329071966

Epoch: 6| Step: 2
Training loss: 2.590076004592184
Validation loss: 2.4905744160478416

Epoch: 6| Step: 3
Training loss: 2.930530965821413
Validation loss: 2.484745008658308

Epoch: 6| Step: 4
Training loss: 3.3490515775538916
Validation loss: 2.472309971068982

Epoch: 6| Step: 5
Training loss: 3.383636444745499
Validation loss: 2.4550594187792742

Epoch: 6| Step: 6
Training loss: 2.643326951396433
Validation loss: 2.455348826611247

Epoch: 6| Step: 7
Training loss: 1.985558825030437
Validation loss: 2.4538670683233286

Epoch: 6| Step: 8
Training loss: 2.328648041209556
Validation loss: 2.462291598523688

Epoch: 6| Step: 9
Training loss: 2.5753751018605433
Validation loss: 2.461448870226036

Epoch: 6| Step: 10
Training loss: 2.609176902332614
Validation loss: 2.4830459617439984

Epoch: 6| Step: 11
Training loss: 2.6177213665209824
Validation loss: 2.5039251144845527

Epoch: 6| Step: 12
Training loss: 2.187030632889438
Validation loss: 2.584410308625657

Epoch: 6| Step: 13
Training loss: 2.0994661788015057
Validation loss: 2.6302693983210377

Epoch: 247| Step: 0
Training loss: 3.1324368296812244
Validation loss: 2.7084244560518305

Epoch: 6| Step: 1
Training loss: 3.05020913829749
Validation loss: 2.7048314531564426

Epoch: 6| Step: 2
Training loss: 2.7102722758938373
Validation loss: 2.630822726658729

Epoch: 6| Step: 3
Training loss: 1.998436137565047
Validation loss: 2.536498727649687

Epoch: 6| Step: 4
Training loss: 2.7569488815754486
Validation loss: 2.486742633965721

Epoch: 6| Step: 5
Training loss: 2.9702908984205965
Validation loss: 2.4619354927747015

Epoch: 6| Step: 6
Training loss: 2.4008079519875514
Validation loss: 2.47921734333508

Epoch: 6| Step: 7
Training loss: 2.3010577050325463
Validation loss: 2.4775117500476624

Epoch: 6| Step: 8
Training loss: 2.8623286766522873
Validation loss: 2.471203610839132

Epoch: 6| Step: 9
Training loss: 2.0338436294132913
Validation loss: 2.4804245889065877

Epoch: 6| Step: 10
Training loss: 3.3260819876011216
Validation loss: 2.5123694164968646

Epoch: 6| Step: 11
Training loss: 3.2671102404296244
Validation loss: 2.5114955017924707

Epoch: 6| Step: 12
Training loss: 2.260561843171241
Validation loss: 2.5259127571409286

Epoch: 6| Step: 13
Training loss: 2.244140200038036
Validation loss: 2.5157352954020267

Epoch: 248| Step: 0
Training loss: 2.5838917364582645
Validation loss: 2.5078961921900174

Epoch: 6| Step: 1
Training loss: 2.882482990568716
Validation loss: 2.493560919711392

Epoch: 6| Step: 2
Training loss: 2.3163097033394884
Validation loss: 2.4869146169334426

Epoch: 6| Step: 3
Training loss: 2.7613924041402655
Validation loss: 2.5093237590905084

Epoch: 6| Step: 4
Training loss: 2.791385313820871
Validation loss: 2.5031549317343433

Epoch: 6| Step: 5
Training loss: 2.3917650483883017
Validation loss: 2.507874329713641

Epoch: 6| Step: 6
Training loss: 2.7046405755109486
Validation loss: 2.5202485737442015

Epoch: 6| Step: 7
Training loss: 2.630104188777175
Validation loss: 2.5082286854450544

Epoch: 6| Step: 8
Training loss: 3.017199485751051
Validation loss: 2.508526612698444

Epoch: 6| Step: 9
Training loss: 2.4994694146736256
Validation loss: 2.5124587311791706

Epoch: 6| Step: 10
Training loss: 1.8558471293879437
Validation loss: 2.5213581034937365

Epoch: 6| Step: 11
Training loss: 3.048593515757128
Validation loss: 2.520836238169558

Epoch: 6| Step: 12
Training loss: 2.6501029300493135
Validation loss: 2.533808016878719

Epoch: 6| Step: 13
Training loss: 2.556637081321551
Validation loss: 2.548193158580098

Epoch: 249| Step: 0
Training loss: 2.675239630688063
Validation loss: 2.536980413122648

Epoch: 6| Step: 1
Training loss: 2.69520148449475
Validation loss: 2.5113845679687703

Epoch: 6| Step: 2
Training loss: 3.169984451400218
Validation loss: 2.499598955986341

Epoch: 6| Step: 3
Training loss: 3.1040562518322012
Validation loss: 2.4740126362374593

Epoch: 6| Step: 4
Training loss: 2.5762814490533303
Validation loss: 2.4722217911080855

Epoch: 6| Step: 5
Training loss: 3.1579200178941367
Validation loss: 2.457117896754186

Epoch: 6| Step: 6
Training loss: 2.6308504938486883
Validation loss: 2.4709651194783198

Epoch: 6| Step: 7
Training loss: 2.4927539719770038
Validation loss: 2.465347517560877

Epoch: 6| Step: 8
Training loss: 1.818010503652548
Validation loss: 2.4553731567346424

Epoch: 6| Step: 9
Training loss: 2.4068347170937425
Validation loss: 2.4737988775621043

Epoch: 6| Step: 10
Training loss: 2.4672021963250743
Validation loss: 2.4659779766097243

Epoch: 6| Step: 11
Training loss: 2.8663431946168227
Validation loss: 2.4690170351352494

Epoch: 6| Step: 12
Training loss: 2.2861611789408443
Validation loss: 2.4699656581629386

Epoch: 6| Step: 13
Training loss: 1.043628498246524
Validation loss: 2.47267810764115

Epoch: 250| Step: 0
Training loss: 2.136482183830741
Validation loss: 2.471202536086625

Epoch: 6| Step: 1
Training loss: 2.472699061018608
Validation loss: 2.4577282167264816

Epoch: 6| Step: 2
Training loss: 2.9827962963849104
Validation loss: 2.4497322891395306

Epoch: 6| Step: 3
Training loss: 2.7001428636972156
Validation loss: 2.462534282106929

Epoch: 6| Step: 4
Training loss: 2.562176474640443
Validation loss: 2.4611809743723203

Epoch: 6| Step: 5
Training loss: 2.4179288155211456
Validation loss: 2.486489543877609

Epoch: 6| Step: 6
Training loss: 2.705819611541508
Validation loss: 2.479406730036281

Epoch: 6| Step: 7
Training loss: 2.519158292860154
Validation loss: 2.4921251195902454

Epoch: 6| Step: 8
Training loss: 2.9012370200731734
Validation loss: 2.513185847608993

Epoch: 6| Step: 9
Training loss: 2.566828073240291
Validation loss: 2.5355897377953696

Epoch: 6| Step: 10
Training loss: 2.422101607027084
Validation loss: 2.510919283603951

Epoch: 6| Step: 11
Training loss: 2.822753357239719
Validation loss: 2.5330815061629712

Epoch: 6| Step: 12
Training loss: 2.281099288351533
Validation loss: 2.5123713083316868

Epoch: 6| Step: 13
Training loss: 3.1512901691568502
Validation loss: 2.512127144765137

Epoch: 251| Step: 0
Training loss: 2.1907673004557315
Validation loss: 2.4685170354618164

Epoch: 6| Step: 1
Training loss: 2.6965140939970547
Validation loss: 2.4614199940001686

Epoch: 6| Step: 2
Training loss: 3.073506719976265
Validation loss: 2.439658531019991

Epoch: 6| Step: 3
Training loss: 2.687036075027605
Validation loss: 2.444309750705755

Epoch: 6| Step: 4
Training loss: 2.4681212191867923
Validation loss: 2.4528360535638907

Epoch: 6| Step: 5
Training loss: 2.4698205871905263
Validation loss: 2.453614057045797

Epoch: 6| Step: 6
Training loss: 2.37671529164626
Validation loss: 2.45637737721359

Epoch: 6| Step: 7
Training loss: 2.323085681827841
Validation loss: 2.4468973142873405

Epoch: 6| Step: 8
Training loss: 2.680421689720276
Validation loss: 2.465611245653366

Epoch: 6| Step: 9
Training loss: 2.5579652436544444
Validation loss: 2.4505470691805744

Epoch: 6| Step: 10
Training loss: 2.368145537943011
Validation loss: 2.4632083664147486

Epoch: 6| Step: 11
Training loss: 2.7058064826343484
Validation loss: 2.466283471320299

Epoch: 6| Step: 12
Training loss: 3.2299159175451644
Validation loss: 2.4676775437657095

Epoch: 6| Step: 13
Training loss: 2.3368968205786316
Validation loss: 2.4777996368188333

Epoch: 252| Step: 0
Training loss: 2.037902502076876
Validation loss: 2.501191834438049

Epoch: 6| Step: 1
Training loss: 2.8073303182249503
Validation loss: 2.543193528645676

Epoch: 6| Step: 2
Training loss: 2.447288519165409
Validation loss: 2.5655044072674724

Epoch: 6| Step: 3
Training loss: 2.5145862401288626
Validation loss: 2.5997712152189396

Epoch: 6| Step: 4
Training loss: 3.431807364688478
Validation loss: 2.6135370088987955

Epoch: 6| Step: 5
Training loss: 2.8435870113405097
Validation loss: 2.620552046745708

Epoch: 6| Step: 6
Training loss: 2.651108736540051
Validation loss: 2.604166666994813

Epoch: 6| Step: 7
Training loss: 2.158010565681507
Validation loss: 2.5573774460012095

Epoch: 6| Step: 8
Training loss: 2.3328013721974843
Validation loss: 2.496320668821594

Epoch: 6| Step: 9
Training loss: 2.913623602902346
Validation loss: 2.489119036730422

Epoch: 6| Step: 10
Training loss: 2.7235452741176265
Validation loss: 2.459177480948451

Epoch: 6| Step: 11
Training loss: 1.5796533114905857
Validation loss: 2.477387668874346

Epoch: 6| Step: 12
Training loss: 3.1476253096138493
Validation loss: 2.4735772231913695

Epoch: 6| Step: 13
Training loss: 2.5959908790193036
Validation loss: 2.484481740092737

Epoch: 253| Step: 0
Training loss: 2.1028009899117484
Validation loss: 2.4846679562241425

Epoch: 6| Step: 1
Training loss: 2.6866975517801053
Validation loss: 2.495980394807681

Epoch: 6| Step: 2
Training loss: 2.5381802478630413
Validation loss: 2.4870163903427454

Epoch: 6| Step: 3
Training loss: 2.6709912718098634
Validation loss: 2.4917774895053717

Epoch: 6| Step: 4
Training loss: 2.2796684949368977
Validation loss: 2.4972480979075655

Epoch: 6| Step: 5
Training loss: 2.840873688910722
Validation loss: 2.4933535208643507

Epoch: 6| Step: 6
Training loss: 2.794958384959824
Validation loss: 2.502101158783588

Epoch: 6| Step: 7
Training loss: 2.502782608217618
Validation loss: 2.516953697480004

Epoch: 6| Step: 8
Training loss: 2.7424634484886736
Validation loss: 2.511152689988506

Epoch: 6| Step: 9
Training loss: 3.1110701804269065
Validation loss: 2.531743808020053

Epoch: 6| Step: 10
Training loss: 2.98583469343638
Validation loss: 2.5329845222602114

Epoch: 6| Step: 11
Training loss: 1.801192958545412
Validation loss: 2.529221133207713

Epoch: 6| Step: 12
Training loss: 2.5217464674252406
Validation loss: 2.520327272589228

Epoch: 6| Step: 13
Training loss: 2.890679436248408
Validation loss: 2.5154360083193725

Epoch: 254| Step: 0
Training loss: 2.916455143115807
Validation loss: 2.5155359363375434

Epoch: 6| Step: 1
Training loss: 2.5343021782174238
Validation loss: 2.507610102419364

Epoch: 6| Step: 2
Training loss: 2.3364196075708663
Validation loss: 2.5019988631649377

Epoch: 6| Step: 3
Training loss: 2.1859608276082274
Validation loss: 2.497429089802376

Epoch: 6| Step: 4
Training loss: 2.539432064450817
Validation loss: 2.4887104907941096

Epoch: 6| Step: 5
Training loss: 2.440398229401588
Validation loss: 2.489921556803687

Epoch: 6| Step: 6
Training loss: 2.8987530230678704
Validation loss: 2.4913871272775507

Epoch: 6| Step: 7
Training loss: 2.33124491918588
Validation loss: 2.4894284441173626

Epoch: 6| Step: 8
Training loss: 3.1237343323166975
Validation loss: 2.49745844171065

Epoch: 6| Step: 9
Training loss: 2.067817768368662
Validation loss: 2.4899765536832006

Epoch: 6| Step: 10
Training loss: 2.5223110271099536
Validation loss: 2.486852952670532

Epoch: 6| Step: 11
Training loss: 2.166381694931049
Validation loss: 2.4687191810828626

Epoch: 6| Step: 12
Training loss: 2.9956353544378214
Validation loss: 2.480328086615701

Epoch: 6| Step: 13
Training loss: 3.032889640412729
Validation loss: 2.490964626215432

Epoch: 255| Step: 0
Training loss: 2.500879705148087
Validation loss: 2.4948382444673056

Epoch: 6| Step: 1
Training loss: 2.463428217807361
Validation loss: 2.492305876630097

Epoch: 6| Step: 2
Training loss: 3.2264458956211564
Validation loss: 2.5009271737968297

Epoch: 6| Step: 3
Training loss: 2.3747199043947504
Validation loss: 2.50315305956224

Epoch: 6| Step: 4
Training loss: 2.2922013670457013
Validation loss: 2.526462025622299

Epoch: 6| Step: 5
Training loss: 2.9173833420678874
Validation loss: 2.5434476932144148

Epoch: 6| Step: 6
Training loss: 2.500585678161355
Validation loss: 2.5404315851201624

Epoch: 6| Step: 7
Training loss: 2.6781707118794715
Validation loss: 2.5431572530619153

Epoch: 6| Step: 8
Training loss: 1.9751613309613965
Validation loss: 2.504388343748482

Epoch: 6| Step: 9
Training loss: 2.436295040334723
Validation loss: 2.496812111772324

Epoch: 6| Step: 10
Training loss: 2.4949767190768237
Validation loss: 2.4760682462396733

Epoch: 6| Step: 11
Training loss: 3.0075808745534975
Validation loss: 2.4896565723154116

Epoch: 6| Step: 12
Training loss: 2.3194907431889566
Validation loss: 2.483762702139213

Epoch: 6| Step: 13
Training loss: 2.5705481887868284
Validation loss: 2.4850545510890742

Epoch: 256| Step: 0
Training loss: 2.6167048222701945
Validation loss: 2.4823932272498768

Epoch: 6| Step: 1
Training loss: 2.0323862272468984
Validation loss: 2.4701213566294404

Epoch: 6| Step: 2
Training loss: 2.1189145859790006
Validation loss: 2.4826975183447977

Epoch: 6| Step: 3
Training loss: 2.323538133998244
Validation loss: 2.4576741139939298

Epoch: 6| Step: 4
Training loss: 2.4334364054897732
Validation loss: 2.449390370102823

Epoch: 6| Step: 5
Training loss: 2.9161943507372707
Validation loss: 2.4578188098243694

Epoch: 6| Step: 6
Training loss: 2.630141717551877
Validation loss: 2.4704097434997085

Epoch: 6| Step: 7
Training loss: 1.9063550576198787
Validation loss: 2.4513332725460484

Epoch: 6| Step: 8
Training loss: 2.673611439186065
Validation loss: 2.4683982065752703

Epoch: 6| Step: 9
Training loss: 2.725190875166602
Validation loss: 2.471428194811739

Epoch: 6| Step: 10
Training loss: 2.9786710704826693
Validation loss: 2.4837244788941177

Epoch: 6| Step: 11
Training loss: 2.6052541572926384
Validation loss: 2.477588029625782

Epoch: 6| Step: 12
Training loss: 3.0596309379466717
Validation loss: 2.4878168908971183

Epoch: 6| Step: 13
Training loss: 3.0893123666509794
Validation loss: 2.4760901783326825

Epoch: 257| Step: 0
Training loss: 2.975692982464944
Validation loss: 2.466531595094972

Epoch: 6| Step: 1
Training loss: 2.6388236679137536
Validation loss: 2.4807492385109455

Epoch: 6| Step: 2
Training loss: 2.3548053673985154
Validation loss: 2.5030451666221105

Epoch: 6| Step: 3
Training loss: 2.437565631471931
Validation loss: 2.487217139131265

Epoch: 6| Step: 4
Training loss: 2.574077596542587
Validation loss: 2.519923918080634

Epoch: 6| Step: 5
Training loss: 2.662305504227371
Validation loss: 2.5219733327452865

Epoch: 6| Step: 6
Training loss: 2.0740171287807807
Validation loss: 2.528821147790304

Epoch: 6| Step: 7
Training loss: 2.6593154272989348
Validation loss: 2.518452668290075

Epoch: 6| Step: 8
Training loss: 2.677803467152025
Validation loss: 2.5181484255067623

Epoch: 6| Step: 9
Training loss: 2.711242130983927
Validation loss: 2.4999838582409915

Epoch: 6| Step: 10
Training loss: 3.033965791714364
Validation loss: 2.5267360296600745

Epoch: 6| Step: 11
Training loss: 2.4051482415460916
Validation loss: 2.5059781390423463

Epoch: 6| Step: 12
Training loss: 2.250937796236141
Validation loss: 2.505911016412871

Epoch: 6| Step: 13
Training loss: 2.0943492202743133
Validation loss: 2.498856233632428

Epoch: 258| Step: 0
Training loss: 2.866682876127088
Validation loss: 2.4981095046892303

Epoch: 6| Step: 1
Training loss: 2.669137991724288
Validation loss: 2.4840746013229915

Epoch: 6| Step: 2
Training loss: 2.5630336298885066
Validation loss: 2.478405745112572

Epoch: 6| Step: 3
Training loss: 2.9865574071971857
Validation loss: 2.4704529784430003

Epoch: 6| Step: 4
Training loss: 2.1324236728474055
Validation loss: 2.451527059599229

Epoch: 6| Step: 5
Training loss: 2.3639647449117227
Validation loss: 2.451134286698592

Epoch: 6| Step: 6
Training loss: 2.423777958598999
Validation loss: 2.449164058389138

Epoch: 6| Step: 7
Training loss: 2.5489168933596384
Validation loss: 2.4415330255222916

Epoch: 6| Step: 8
Training loss: 2.0416965352682714
Validation loss: 2.4464464428095885

Epoch: 6| Step: 9
Training loss: 2.1040896285152493
Validation loss: 2.4515471260711164

Epoch: 6| Step: 10
Training loss: 2.400504647286797
Validation loss: 2.4580707437613847

Epoch: 6| Step: 11
Training loss: 2.9860779063032177
Validation loss: 2.486306684316974

Epoch: 6| Step: 12
Training loss: 2.621621000696929
Validation loss: 2.492061901267596

Epoch: 6| Step: 13
Training loss: 3.0755719281032143
Validation loss: 2.5331154971168672

Epoch: 259| Step: 0
Training loss: 3.0178323681830994
Validation loss: 2.5643375450251082

Epoch: 6| Step: 1
Training loss: 2.7405916009692546
Validation loss: 2.5680861403658266

Epoch: 6| Step: 2
Training loss: 2.5476107792450624
Validation loss: 2.5903112569577873

Epoch: 6| Step: 3
Training loss: 3.245288955683883
Validation loss: 2.565613301788212

Epoch: 6| Step: 4
Training loss: 2.3719854799054576
Validation loss: 2.5638022506561238

Epoch: 6| Step: 5
Training loss: 2.5529164933003856
Validation loss: 2.5892035248346548

Epoch: 6| Step: 6
Training loss: 1.7927855686866563
Validation loss: 2.595757312721854

Epoch: 6| Step: 7
Training loss: 2.3387521990261617
Validation loss: 2.558186985958111

Epoch: 6| Step: 8
Training loss: 2.652012035992728
Validation loss: 2.5553903121307413

Epoch: 6| Step: 9
Training loss: 2.5730240731208434
Validation loss: 2.527674528939657

Epoch: 6| Step: 10
Training loss: 2.1112567561365037
Validation loss: 2.4996440059732175

Epoch: 6| Step: 11
Training loss: 2.4927011755715527
Validation loss: 2.4743080735629217

Epoch: 6| Step: 12
Training loss: 2.1383915965744658
Validation loss: 2.4460076796568977

Epoch: 6| Step: 13
Training loss: 2.7186550255333364
Validation loss: 2.459713784118304

Epoch: 260| Step: 0
Training loss: 2.365182360983611
Validation loss: 2.455707272305956

Epoch: 6| Step: 1
Training loss: 2.7294836272786163
Validation loss: 2.456842651150885

Epoch: 6| Step: 2
Training loss: 2.224467794653792
Validation loss: 2.4374387253263277

Epoch: 6| Step: 3
Training loss: 2.8829678129211493
Validation loss: 2.4299558463575908

Epoch: 6| Step: 4
Training loss: 2.497756141762718
Validation loss: 2.4220177520059116

Epoch: 6| Step: 5
Training loss: 2.870763892084593
Validation loss: 2.4314726695953954

Epoch: 6| Step: 6
Training loss: 2.439257941519784
Validation loss: 2.4600738192188203

Epoch: 6| Step: 7
Training loss: 2.392675281031207
Validation loss: 2.484623069087672

Epoch: 6| Step: 8
Training loss: 2.6248690254597222
Validation loss: 2.5174117258028548

Epoch: 6| Step: 9
Training loss: 2.964136494148814
Validation loss: 2.5696865266700106

Epoch: 6| Step: 10
Training loss: 2.514023264975318
Validation loss: 2.666040191843711

Epoch: 6| Step: 11
Training loss: 2.1081378841147798
Validation loss: 2.6758028481473097

Epoch: 6| Step: 12
Training loss: 2.679051804836563
Validation loss: 2.685120263723572

Epoch: 6| Step: 13
Training loss: 2.5924420103615438
Validation loss: 2.633171632765038

Epoch: 261| Step: 0
Training loss: 2.208233045304106
Validation loss: 2.553307831465326

Epoch: 6| Step: 1
Training loss: 1.5528375555340466
Validation loss: 2.5056867366338516

Epoch: 6| Step: 2
Training loss: 2.6790331161064107
Validation loss: 2.5005370732200527

Epoch: 6| Step: 3
Training loss: 2.5206390074764697
Validation loss: 2.4901029360605174

Epoch: 6| Step: 4
Training loss: 2.660101577712317
Validation loss: 2.492777128158919

Epoch: 6| Step: 5
Training loss: 2.502370473461153
Validation loss: 2.4991844036380497

Epoch: 6| Step: 6
Training loss: 2.970472298005449
Validation loss: 2.496486932432355

Epoch: 6| Step: 7
Training loss: 2.7271306448830526
Validation loss: 2.50349210061516

Epoch: 6| Step: 8
Training loss: 2.4851331213864505
Validation loss: 2.5098975398009107

Epoch: 6| Step: 9
Training loss: 2.548608669611298
Validation loss: 2.5040459891998585

Epoch: 6| Step: 10
Training loss: 3.1154884545680592
Validation loss: 2.4922862545597346

Epoch: 6| Step: 11
Training loss: 2.6047461106651815
Validation loss: 2.469177594323511

Epoch: 6| Step: 12
Training loss: 2.7993081873053294
Validation loss: 2.4823045937264703

Epoch: 6| Step: 13
Training loss: 1.994742038464701
Validation loss: 2.4912128762748362

Epoch: 262| Step: 0
Training loss: 2.953332157034313
Validation loss: 2.503352120559753

Epoch: 6| Step: 1
Training loss: 2.1847409969082783
Validation loss: 2.507303833355654

Epoch: 6| Step: 2
Training loss: 2.7834846862788343
Validation loss: 2.5111777795490755

Epoch: 6| Step: 3
Training loss: 2.84127431567923
Validation loss: 2.532829870260959

Epoch: 6| Step: 4
Training loss: 2.3165038218541834
Validation loss: 2.5301948068731286

Epoch: 6| Step: 5
Training loss: 2.354900032076049
Validation loss: 2.562462240921858

Epoch: 6| Step: 6
Training loss: 2.7787113390526965
Validation loss: 2.5770333055440924

Epoch: 6| Step: 7
Training loss: 1.9575409063788385
Validation loss: 2.5714358882519988

Epoch: 6| Step: 8
Training loss: 2.1883616249171234
Validation loss: 2.549592726787319

Epoch: 6| Step: 9
Training loss: 1.9816660976596248
Validation loss: 2.553463673854353

Epoch: 6| Step: 10
Training loss: 2.7450156557786642
Validation loss: 2.53952436034357

Epoch: 6| Step: 11
Training loss: 2.530096662582139
Validation loss: 2.5139907729094833

Epoch: 6| Step: 12
Training loss: 2.8274176961858384
Validation loss: 2.503741393953309

Epoch: 6| Step: 13
Training loss: 3.218371322726336
Validation loss: 2.4989800290107596

Epoch: 263| Step: 0
Training loss: 1.243270210235317
Validation loss: 2.4789106161477914

Epoch: 6| Step: 1
Training loss: 2.893038015749411
Validation loss: 2.477402166088024

Epoch: 6| Step: 2
Training loss: 2.65087076671768
Validation loss: 2.482818526644911

Epoch: 6| Step: 3
Training loss: 2.556269351354349
Validation loss: 2.4823121442697147

Epoch: 6| Step: 4
Training loss: 2.4460827281682875
Validation loss: 2.489581256676287

Epoch: 6| Step: 5
Training loss: 2.680712623364799
Validation loss: 2.46645220044796

Epoch: 6| Step: 6
Training loss: 1.8717174406402923
Validation loss: 2.471456692703469

Epoch: 6| Step: 7
Training loss: 2.5485850017248484
Validation loss: 2.4798460729426153

Epoch: 6| Step: 8
Training loss: 2.43919997967213
Validation loss: 2.4921406271432307

Epoch: 6| Step: 9
Training loss: 2.879388196917846
Validation loss: 2.508063227812728

Epoch: 6| Step: 10
Training loss: 2.759179919076714
Validation loss: 2.497978665882107

Epoch: 6| Step: 11
Training loss: 2.5224052656397618
Validation loss: 2.5064014861918986

Epoch: 6| Step: 12
Training loss: 2.8820594693149495
Validation loss: 2.4892175129096596

Epoch: 6| Step: 13
Training loss: 2.594826991758214
Validation loss: 2.476065511832547

Epoch: 264| Step: 0
Training loss: 3.08237315168294
Validation loss: 2.4940769021897933

Epoch: 6| Step: 1
Training loss: 2.562626347101902
Validation loss: 2.554844218526059

Epoch: 6| Step: 2
Training loss: 2.528088420136463
Validation loss: 2.596826256889512

Epoch: 6| Step: 3
Training loss: 1.948368598068448
Validation loss: 2.608101567275798

Epoch: 6| Step: 4
Training loss: 1.8779855482786487
Validation loss: 2.6008717496534572

Epoch: 6| Step: 5
Training loss: 3.0076377916995876
Validation loss: 2.5879799584208354

Epoch: 6| Step: 6
Training loss: 2.3588068195851863
Validation loss: 2.53618664354104

Epoch: 6| Step: 7
Training loss: 2.3725647738812543
Validation loss: 2.5131994615067814

Epoch: 6| Step: 8
Training loss: 2.0434670068640917
Validation loss: 2.5187271446494495

Epoch: 6| Step: 9
Training loss: 2.9057789082340038
Validation loss: 2.491036031985361

Epoch: 6| Step: 10
Training loss: 2.7062865715110647
Validation loss: 2.4867269607911537

Epoch: 6| Step: 11
Training loss: 2.4878763920476743
Validation loss: 2.4821069443300434

Epoch: 6| Step: 12
Training loss: 2.4226854506488547
Validation loss: 2.489745718431776

Epoch: 6| Step: 13
Training loss: 3.0390841524975767
Validation loss: 2.4879885945555444

Epoch: 265| Step: 0
Training loss: 2.6831760664478113
Validation loss: 2.482058349361454

Epoch: 6| Step: 1
Training loss: 2.4925995010824806
Validation loss: 2.4655860417747206

Epoch: 6| Step: 2
Training loss: 2.2657876844204936
Validation loss: 2.463257107411262

Epoch: 6| Step: 3
Training loss: 2.539870852393558
Validation loss: 2.472370396018488

Epoch: 6| Step: 4
Training loss: 3.115920036220304
Validation loss: 2.4750881763146158

Epoch: 6| Step: 5
Training loss: 1.832239590574018
Validation loss: 2.4887859522732616

Epoch: 6| Step: 6
Training loss: 2.112647336979548
Validation loss: 2.4945058830854743

Epoch: 6| Step: 7
Training loss: 2.7354162359031537
Validation loss: 2.51602247162123

Epoch: 6| Step: 8
Training loss: 2.612565699577129
Validation loss: 2.526027849314156

Epoch: 6| Step: 9
Training loss: 3.0476104631189513
Validation loss: 2.538976714118289

Epoch: 6| Step: 10
Training loss: 2.2006514711746172
Validation loss: 2.5522167376034797

Epoch: 6| Step: 11
Training loss: 2.683948210249276
Validation loss: 2.5381820361222283

Epoch: 6| Step: 12
Training loss: 1.7144342511403445
Validation loss: 2.5500597875809796

Epoch: 6| Step: 13
Training loss: 2.7658374079802326
Validation loss: 2.5717189459330014

Epoch: 266| Step: 0
Training loss: 2.977913617440817
Validation loss: 2.573412625496384

Epoch: 6| Step: 1
Training loss: 2.2699707446124684
Validation loss: 2.6313040636807483

Epoch: 6| Step: 2
Training loss: 2.5496298278203313
Validation loss: 2.6204960257684835

Epoch: 6| Step: 3
Training loss: 2.679143466720473
Validation loss: 2.5986394854100436

Epoch: 6| Step: 4
Training loss: 2.0849521324096862
Validation loss: 2.607027764235549

Epoch: 6| Step: 5
Training loss: 2.3449250391059153
Validation loss: 2.576779833173987

Epoch: 6| Step: 6
Training loss: 2.5499426031197885
Validation loss: 2.564356259869286

Epoch: 6| Step: 7
Training loss: 2.617402116317051
Validation loss: 2.5635883052162405

Epoch: 6| Step: 8
Training loss: 2.946652540141402
Validation loss: 2.5672682751329403

Epoch: 6| Step: 9
Training loss: 2.0458696531760925
Validation loss: 2.565717283667629

Epoch: 6| Step: 10
Training loss: 2.5320655545009174
Validation loss: 2.5467384090872414

Epoch: 6| Step: 11
Training loss: 2.4759259774786018
Validation loss: 2.552761607708966

Epoch: 6| Step: 12
Training loss: 2.354782181565766
Validation loss: 2.5225010373086483

Epoch: 6| Step: 13
Training loss: 2.358301891301527
Validation loss: 2.5021182069637002

Epoch: 267| Step: 0
Training loss: 1.9822539159721908
Validation loss: 2.5035657392793316

Epoch: 6| Step: 1
Training loss: 2.9369300126960973
Validation loss: 2.487662639011961

Epoch: 6| Step: 2
Training loss: 2.255043100084729
Validation loss: 2.4678697617295646

Epoch: 6| Step: 3
Training loss: 2.063635542414528
Validation loss: 2.466596792917034

Epoch: 6| Step: 4
Training loss: 2.177519454956738
Validation loss: 2.4830496424539943

Epoch: 6| Step: 5
Training loss: 2.3311025537083867
Validation loss: 2.5093289204409017

Epoch: 6| Step: 6
Training loss: 2.2163735140889673
Validation loss: 2.497865378781173

Epoch: 6| Step: 7
Training loss: 2.290465253851619
Validation loss: 2.511660531223347

Epoch: 6| Step: 8
Training loss: 2.4512355841757927
Validation loss: 2.5256445896215327

Epoch: 6| Step: 9
Training loss: 2.9232644434097157
Validation loss: 2.5554847041660094

Epoch: 6| Step: 10
Training loss: 2.6875066535335064
Validation loss: 2.5732794177917957

Epoch: 6| Step: 11
Training loss: 3.1699281928657004
Validation loss: 2.5920765955930882

Epoch: 6| Step: 12
Training loss: 2.178177286448174
Validation loss: 2.605259485793816

Epoch: 6| Step: 13
Training loss: 2.8270023710107997
Validation loss: 2.6405476942722537

Epoch: 268| Step: 0
Training loss: 2.1154471701596163
Validation loss: 2.6150054264092693

Epoch: 6| Step: 1
Training loss: 2.951544929318813
Validation loss: 2.5714397245840077

Epoch: 6| Step: 2
Training loss: 2.8167653271552746
Validation loss: 2.5462166399370267

Epoch: 6| Step: 3
Training loss: 2.6030307784779674
Validation loss: 2.5113549786632645

Epoch: 6| Step: 4
Training loss: 2.265873336335983
Validation loss: 2.489019134252684

Epoch: 6| Step: 5
Training loss: 2.53287180996451
Validation loss: 2.4668219864852667

Epoch: 6| Step: 6
Training loss: 1.8029919871122058
Validation loss: 2.4795969066422443

Epoch: 6| Step: 7
Training loss: 3.0968316653517656
Validation loss: 2.468915618869757

Epoch: 6| Step: 8
Training loss: 2.0606822471083124
Validation loss: 2.4893070032751914

Epoch: 6| Step: 9
Training loss: 2.9723360588480765
Validation loss: 2.49092219447752

Epoch: 6| Step: 10
Training loss: 2.105076231312356
Validation loss: 2.5339509021264175

Epoch: 6| Step: 11
Training loss: 1.821255288309498
Validation loss: 2.5350628879626003

Epoch: 6| Step: 12
Training loss: 2.6873262925897627
Validation loss: 2.61296873331465

Epoch: 6| Step: 13
Training loss: 2.954847207032326
Validation loss: 2.6338954005851267

Epoch: 269| Step: 0
Training loss: 2.0061454531800993
Validation loss: 2.6090809390690435

Epoch: 6| Step: 1
Training loss: 1.937019903936418
Validation loss: 2.609602137885171

Epoch: 6| Step: 2
Training loss: 2.9967326809659607
Validation loss: 2.5754808695518148

Epoch: 6| Step: 3
Training loss: 2.0750629553379154
Validation loss: 2.6068479569929446

Epoch: 6| Step: 4
Training loss: 2.7144304358829237
Validation loss: 2.612314852523309

Epoch: 6| Step: 5
Training loss: 2.368578008280714
Validation loss: 2.5817177805497233

Epoch: 6| Step: 6
Training loss: 2.6894954991101745
Validation loss: 2.5482449410778223

Epoch: 6| Step: 7
Training loss: 2.4113956275735147
Validation loss: 2.5183435200673

Epoch: 6| Step: 8
Training loss: 2.3757004959647374
Validation loss: 2.474964160603768

Epoch: 6| Step: 9
Training loss: 3.097827728643499
Validation loss: 2.4452667478419574

Epoch: 6| Step: 10
Training loss: 2.2855059494712235
Validation loss: 2.4429056708981376

Epoch: 6| Step: 11
Training loss: 2.6117155804787453
Validation loss: 2.4268521371262963

Epoch: 6| Step: 12
Training loss: 2.667446817084205
Validation loss: 2.417413359276954

Epoch: 6| Step: 13
Training loss: 1.833836753680927
Validation loss: 2.42485588672236

Epoch: 270| Step: 0
Training loss: 2.3530649853838406
Validation loss: 2.444767197883928

Epoch: 6| Step: 1
Training loss: 2.085560739617241
Validation loss: 2.4759614064311704

Epoch: 6| Step: 2
Training loss: 2.2200645528463654
Validation loss: 2.484406633898655

Epoch: 6| Step: 3
Training loss: 2.4020036161968825
Validation loss: 2.514922203663413

Epoch: 6| Step: 4
Training loss: 1.9366519671794362
Validation loss: 2.5121158303904676

Epoch: 6| Step: 5
Training loss: 1.8744032227978942
Validation loss: 2.5617122774995873

Epoch: 6| Step: 6
Training loss: 2.7202471414653915
Validation loss: 2.5534690090280012

Epoch: 6| Step: 7
Training loss: 2.541417927895472
Validation loss: 2.5106102792978153

Epoch: 6| Step: 8
Training loss: 2.7930250895759916
Validation loss: 2.489184931866884

Epoch: 6| Step: 9
Training loss: 2.534008265818277
Validation loss: 2.4749933314593533

Epoch: 6| Step: 10
Training loss: 2.9343114551492846
Validation loss: 2.47077453061328

Epoch: 6| Step: 11
Training loss: 2.7245599338872153
Validation loss: 2.455802533170552

Epoch: 6| Step: 12
Training loss: 2.866995407446758
Validation loss: 2.4736268553409415

Epoch: 6| Step: 13
Training loss: 2.409163655512628
Validation loss: 2.48062566083751

Epoch: 271| Step: 0
Training loss: 2.0886600172292336
Validation loss: 2.521607883994897

Epoch: 6| Step: 1
Training loss: 2.4307717605585086
Validation loss: 2.5337989963931027

Epoch: 6| Step: 2
Training loss: 2.7402425536117256
Validation loss: 2.5863376465592305

Epoch: 6| Step: 3
Training loss: 2.4286349552725457
Validation loss: 2.6032623824389964

Epoch: 6| Step: 4
Training loss: 2.065694704481178
Validation loss: 2.590634224646633

Epoch: 6| Step: 5
Training loss: 2.6164312835889967
Validation loss: 2.5965146945458977

Epoch: 6| Step: 6
Training loss: 3.1327847981357837
Validation loss: 2.5707871084012583

Epoch: 6| Step: 7
Training loss: 2.6965884519471643
Validation loss: 2.5438396233582465

Epoch: 6| Step: 8
Training loss: 2.6864439197837475
Validation loss: 2.4879101711105847

Epoch: 6| Step: 9
Training loss: 2.329539746025856
Validation loss: 2.452185844029275

Epoch: 6| Step: 10
Training loss: 1.9975694550242487
Validation loss: 2.458528694105892

Epoch: 6| Step: 11
Training loss: 2.187981906669608
Validation loss: 2.466381373393315

Epoch: 6| Step: 12
Training loss: 2.2784684873322503
Validation loss: 2.457842421351013

Epoch: 6| Step: 13
Training loss: 2.659082316375104
Validation loss: 2.4769282320846076

Epoch: 272| Step: 0
Training loss: 2.61015591385904
Validation loss: 2.486057377692086

Epoch: 6| Step: 1
Training loss: 2.542358325173039
Validation loss: 2.522971312843559

Epoch: 6| Step: 2
Training loss: 2.2311072295857204
Validation loss: 2.547649198181979

Epoch: 6| Step: 3
Training loss: 2.522745137850452
Validation loss: 2.556101247490667

Epoch: 6| Step: 4
Training loss: 2.033187763548178
Validation loss: 2.564238973926027

Epoch: 6| Step: 5
Training loss: 2.553582095220126
Validation loss: 2.5643930173451506

Epoch: 6| Step: 6
Training loss: 2.3356406747293548
Validation loss: 2.565289392566849

Epoch: 6| Step: 7
Training loss: 2.331651103922361
Validation loss: 2.5932610460228065

Epoch: 6| Step: 8
Training loss: 2.5759667813072507
Validation loss: 2.604091944124969

Epoch: 6| Step: 9
Training loss: 2.471598080870807
Validation loss: 2.5896951802348833

Epoch: 6| Step: 10
Training loss: 2.180065053966594
Validation loss: 2.6051578399258366

Epoch: 6| Step: 11
Training loss: 2.6243992072540423
Validation loss: 2.5505528682498384

Epoch: 6| Step: 12
Training loss: 2.2012292808757707
Validation loss: 2.5056570488368517

Epoch: 6| Step: 13
Training loss: 3.100561792474886
Validation loss: 2.4781578729766447

Epoch: 273| Step: 0
Training loss: 2.4942213028993465
Validation loss: 2.4456228540030387

Epoch: 6| Step: 1
Training loss: 2.4150142830373014
Validation loss: 2.443153527240915

Epoch: 6| Step: 2
Training loss: 2.058373571561129
Validation loss: 2.4381907199346378

Epoch: 6| Step: 3
Training loss: 2.5005351447503865
Validation loss: 2.4362869525726483

Epoch: 6| Step: 4
Training loss: 2.8630480912060476
Validation loss: 2.4593081668008234

Epoch: 6| Step: 5
Training loss: 2.741435325470545
Validation loss: 2.4646386361736967

Epoch: 6| Step: 6
Training loss: 2.503055040998708
Validation loss: 2.4496628634596407

Epoch: 6| Step: 7
Training loss: 1.3334868859245903
Validation loss: 2.484280959625037

Epoch: 6| Step: 8
Training loss: 2.5939490919801544
Validation loss: 2.4954303935391304

Epoch: 6| Step: 9
Training loss: 2.1802856280942784
Validation loss: 2.5184207667801757

Epoch: 6| Step: 10
Training loss: 2.4794333391992445
Validation loss: 2.5474759747995925

Epoch: 6| Step: 11
Training loss: 2.754335713548896
Validation loss: 2.584685610449651

Epoch: 6| Step: 12
Training loss: 2.2641943262025594
Validation loss: 2.591201332616338

Epoch: 6| Step: 13
Training loss: 2.7021877891175974
Validation loss: 2.589061504036097

Epoch: 274| Step: 0
Training loss: 1.6759697512443898
Validation loss: 2.5894398623432044

Epoch: 6| Step: 1
Training loss: 2.374197272115391
Validation loss: 2.5613142972495018

Epoch: 6| Step: 2
Training loss: 1.8934666739553772
Validation loss: 2.5024079867416695

Epoch: 6| Step: 3
Training loss: 2.290481388018921
Validation loss: 2.471662718754018

Epoch: 6| Step: 4
Training loss: 2.5020478444331395
Validation loss: 2.429871771787604

Epoch: 6| Step: 5
Training loss: 2.7070081745611914
Validation loss: 2.422273639178896

Epoch: 6| Step: 6
Training loss: 3.0710283760093917
Validation loss: 2.4431836219695433

Epoch: 6| Step: 7
Training loss: 2.506195878279261
Validation loss: 2.4388789727036375

Epoch: 6| Step: 8
Training loss: 2.372306702018089
Validation loss: 2.4425550010773387

Epoch: 6| Step: 9
Training loss: 2.37427067852063
Validation loss: 2.443267679161568

Epoch: 6| Step: 10
Training loss: 2.5450245506436486
Validation loss: 2.4339252402130023

Epoch: 6| Step: 11
Training loss: 2.5103533936015068
Validation loss: 2.4672855682345753

Epoch: 6| Step: 12
Training loss: 2.7425416896993142
Validation loss: 2.521760293326264

Epoch: 6| Step: 13
Training loss: 2.5836165693329076
Validation loss: 2.593908767397483

Epoch: 275| Step: 0
Training loss: 2.746757676675356
Validation loss: 2.6604535635377884

Epoch: 6| Step: 1
Training loss: 1.9511749909063896
Validation loss: 2.7095163479848803

Epoch: 6| Step: 2
Training loss: 2.1295221120380927
Validation loss: 2.69605862736619

Epoch: 6| Step: 3
Training loss: 2.3305769943485912
Validation loss: 2.674854198151344

Epoch: 6| Step: 4
Training loss: 2.2179135102383287
Validation loss: 2.674001950918752

Epoch: 6| Step: 5
Training loss: 2.986119903630365
Validation loss: 2.6214811664332784

Epoch: 6| Step: 6
Training loss: 2.5303200791424345
Validation loss: 2.584652163795691

Epoch: 6| Step: 7
Training loss: 2.967443881576805
Validation loss: 2.5859173501708086

Epoch: 6| Step: 8
Training loss: 2.451327108505821
Validation loss: 2.579427301324307

Epoch: 6| Step: 9
Training loss: 1.490424187847154
Validation loss: 2.5455213621418284

Epoch: 6| Step: 10
Training loss: 2.17811095398762
Validation loss: 2.525958838889921

Epoch: 6| Step: 11
Training loss: 2.552052109715459
Validation loss: 2.5017882176181896

Epoch: 6| Step: 12
Training loss: 2.086716867072578
Validation loss: 2.476311711295672

Epoch: 6| Step: 13
Training loss: 2.925360737262199
Validation loss: 2.458145905286878

Epoch: 276| Step: 0
Training loss: 1.924032535440467
Validation loss: 2.458317287497681

Epoch: 6| Step: 1
Training loss: 2.6279063711049884
Validation loss: 2.4516853616023346

Epoch: 6| Step: 2
Training loss: 2.58109496161352
Validation loss: 2.4830177847732005

Epoch: 6| Step: 3
Training loss: 1.5426655531813005
Validation loss: 2.5108407993718274

Epoch: 6| Step: 4
Training loss: 2.402154086930049
Validation loss: 2.5459685940729226

Epoch: 6| Step: 5
Training loss: 2.4893904628555954
Validation loss: 2.559622460766041

Epoch: 6| Step: 6
Training loss: 2.408292423767609
Validation loss: 2.5796495779291155

Epoch: 6| Step: 7
Training loss: 2.956053397030607
Validation loss: 2.582334734947327

Epoch: 6| Step: 8
Training loss: 2.621501589567789
Validation loss: 2.5734825380530153

Epoch: 6| Step: 9
Training loss: 2.1762804318249835
Validation loss: 2.5567411475055133

Epoch: 6| Step: 10
Training loss: 2.475032201229965
Validation loss: 2.538293884912693

Epoch: 6| Step: 11
Training loss: 2.0103687682564866
Validation loss: 2.5057079137788962

Epoch: 6| Step: 12
Training loss: 2.8017442821921903
Validation loss: 2.4812082674126916

Epoch: 6| Step: 13
Training loss: 2.4961450419282567
Validation loss: 2.4644670460073588

Epoch: 277| Step: 0
Training loss: 3.076356021274018
Validation loss: 2.467085986122706

Epoch: 6| Step: 1
Training loss: 2.6004740869675564
Validation loss: 2.440557725949318

Epoch: 6| Step: 2
Training loss: 2.355206577773342
Validation loss: 2.447125385051385

Epoch: 6| Step: 3
Training loss: 2.0392678109939495
Validation loss: 2.4485333387028985

Epoch: 6| Step: 4
Training loss: 2.0489313410532675
Validation loss: 2.473016941683729

Epoch: 6| Step: 5
Training loss: 2.1483114309602627
Validation loss: 2.4593943049161053

Epoch: 6| Step: 6
Training loss: 2.5744345405215054
Validation loss: 2.505870618387262

Epoch: 6| Step: 7
Training loss: 2.5198264725294393
Validation loss: 2.531170092148997

Epoch: 6| Step: 8
Training loss: 2.365770778422457
Validation loss: 2.5408502612749744

Epoch: 6| Step: 9
Training loss: 2.1649816881422934
Validation loss: 2.561460034354098

Epoch: 6| Step: 10
Training loss: 2.212785790730309
Validation loss: 2.590882770559815

Epoch: 6| Step: 11
Training loss: 2.6518344755400634
Validation loss: 2.590071843496575

Epoch: 6| Step: 12
Training loss: 1.895336302555123
Validation loss: 2.5940683987088127

Epoch: 6| Step: 13
Training loss: 2.571082373808061
Validation loss: 2.5503701187728804

Epoch: 278| Step: 0
Training loss: 2.611117300968634
Validation loss: 2.529960768878336

Epoch: 6| Step: 1
Training loss: 2.922056631062985
Validation loss: 2.49002790675673

Epoch: 6| Step: 2
Training loss: 2.6297853538906635
Validation loss: 2.467858106286356

Epoch: 6| Step: 3
Training loss: 2.1475979361001447
Validation loss: 2.4617222355308255

Epoch: 6| Step: 4
Training loss: 1.9966705742969177
Validation loss: 2.4698266490247405

Epoch: 6| Step: 5
Training loss: 2.6443085569664144
Validation loss: 2.452239254504018

Epoch: 6| Step: 6
Training loss: 2.6283836355417174
Validation loss: 2.4563545343621587

Epoch: 6| Step: 7
Training loss: 1.2897557099747043
Validation loss: 2.4907294839418768

Epoch: 6| Step: 8
Training loss: 2.2541201273496827
Validation loss: 2.4758023371583286

Epoch: 6| Step: 9
Training loss: 2.6469971107320145
Validation loss: 2.5191143327203354

Epoch: 6| Step: 10
Training loss: 2.7223963346615268
Validation loss: 2.5382324184561154

Epoch: 6| Step: 11
Training loss: 2.260962588810998
Validation loss: 2.595550443977579

Epoch: 6| Step: 12
Training loss: 2.1444356372413016
Validation loss: 2.6267583615424424

Epoch: 6| Step: 13
Training loss: 1.9378370791671051
Validation loss: 2.6207956297647783

Epoch: 279| Step: 0
Training loss: 2.064878075350807
Validation loss: 2.5863924780263434

Epoch: 6| Step: 1
Training loss: 2.9050484090898165
Validation loss: 2.5309884034795354

Epoch: 6| Step: 2
Training loss: 2.5799242619183818
Validation loss: 2.4867735604380266

Epoch: 6| Step: 3
Training loss: 1.9954685493691968
Validation loss: 2.468919091166741

Epoch: 6| Step: 4
Training loss: 2.9208525638427956
Validation loss: 2.4493187974219626

Epoch: 6| Step: 5
Training loss: 2.2281928267461146
Validation loss: 2.449087499596589

Epoch: 6| Step: 6
Training loss: 2.5989896865411124
Validation loss: 2.466947416413127

Epoch: 6| Step: 7
Training loss: 2.793396646226711
Validation loss: 2.4484802148970766

Epoch: 6| Step: 8
Training loss: 2.283438273150829
Validation loss: 2.4706527409751637

Epoch: 6| Step: 9
Training loss: 2.488162817898785
Validation loss: 2.4605604980380855

Epoch: 6| Step: 10
Training loss: 1.7369094064440573
Validation loss: 2.4645694993331353

Epoch: 6| Step: 11
Training loss: 2.7560145755487593
Validation loss: 2.4854605216037875

Epoch: 6| Step: 12
Training loss: 1.9166070956495591
Validation loss: 2.495352822448002

Epoch: 6| Step: 13
Training loss: 1.6698743311488544
Validation loss: 2.515627905415247

Epoch: 280| Step: 0
Training loss: 2.157415323905385
Validation loss: 2.523651535581463

Epoch: 6| Step: 1
Training loss: 2.0315396615883348
Validation loss: 2.536296733125096

Epoch: 6| Step: 2
Training loss: 2.2715570072491285
Validation loss: 2.538330325946706

Epoch: 6| Step: 3
Training loss: 2.876306319963965
Validation loss: 2.5398652030068654

Epoch: 6| Step: 4
Training loss: 1.9604377261688357
Validation loss: 2.5266363974799915

Epoch: 6| Step: 5
Training loss: 2.528549449169332
Validation loss: 2.517660292028858

Epoch: 6| Step: 6
Training loss: 3.1360780814629323
Validation loss: 2.503752992424344

Epoch: 6| Step: 7
Training loss: 2.338632413353757
Validation loss: 2.4967660362703628

Epoch: 6| Step: 8
Training loss: 2.6859159902584584
Validation loss: 2.483777086280022

Epoch: 6| Step: 9
Training loss: 2.0133680378952246
Validation loss: 2.509258842862601

Epoch: 6| Step: 10
Training loss: 2.0950370362861475
Validation loss: 2.4927496761915866

Epoch: 6| Step: 11
Training loss: 2.3129282374417013
Validation loss: 2.5045563103845407

Epoch: 6| Step: 12
Training loss: 2.3337939579751357
Validation loss: 2.5156872501567915

Epoch: 6| Step: 13
Training loss: 2.5390268176579256
Validation loss: 2.498739792465096

Epoch: 281| Step: 0
Training loss: 2.9885241042044703
Validation loss: 2.4811292432178784

Epoch: 6| Step: 1
Training loss: 2.5380637684199185
Validation loss: 2.488736995332323

Epoch: 6| Step: 2
Training loss: 2.6751045206631026
Validation loss: 2.4908459105252136

Epoch: 6| Step: 3
Training loss: 2.687177771834496
Validation loss: 2.4961617959744498

Epoch: 6| Step: 4
Training loss: 2.4887840445703224
Validation loss: 2.491780981386271

Epoch: 6| Step: 5
Training loss: 2.3697004922507894
Validation loss: 2.468573480216774

Epoch: 6| Step: 6
Training loss: 2.283620360588411
Validation loss: 2.46562205704017

Epoch: 6| Step: 7
Training loss: 2.267701558804034
Validation loss: 2.463541708638829

Epoch: 6| Step: 8
Training loss: 2.1922220761650917
Validation loss: 2.436607079493683

Epoch: 6| Step: 9
Training loss: 2.2128264105588134
Validation loss: 2.448151924873901

Epoch: 6| Step: 10
Training loss: 1.8343771939370133
Validation loss: 2.479505920223498

Epoch: 6| Step: 11
Training loss: 2.061542288632131
Validation loss: 2.4946167833806774

Epoch: 6| Step: 12
Training loss: 2.2739452306346934
Validation loss: 2.521102389204051

Epoch: 6| Step: 13
Training loss: 2.170038887941182
Validation loss: 2.5752987740967974

Epoch: 282| Step: 0
Training loss: 2.832129241300388
Validation loss: 2.6084649631856496

Epoch: 6| Step: 1
Training loss: 2.639185405825677
Validation loss: 2.6460666516477738

Epoch: 6| Step: 2
Training loss: 1.9891232129920013
Validation loss: 2.6893638754325204

Epoch: 6| Step: 3
Training loss: 2.807122833516109
Validation loss: 2.724724498887512

Epoch: 6| Step: 4
Training loss: 2.5267799373524085
Validation loss: 2.6517588549101787

Epoch: 6| Step: 5
Training loss: 1.9230309708313622
Validation loss: 2.524168419620318

Epoch: 6| Step: 6
Training loss: 2.61969748315703
Validation loss: 2.4698948519381414

Epoch: 6| Step: 7
Training loss: 2.171038569476325
Validation loss: 2.4223660641064075

Epoch: 6| Step: 8
Training loss: 2.239419963703599
Validation loss: 2.4271364071999666

Epoch: 6| Step: 9
Training loss: 2.733765278003004
Validation loss: 2.425696232803481

Epoch: 6| Step: 10
Training loss: 2.456176415037631
Validation loss: 2.4145248161018147

Epoch: 6| Step: 11
Training loss: 2.378636838192794
Validation loss: 2.4169575201842033

Epoch: 6| Step: 12
Training loss: 2.4404588005341314
Validation loss: 2.4508097967994162

Epoch: 6| Step: 13
Training loss: 1.7979512184450614
Validation loss: 2.4671430694210637

Epoch: 283| Step: 0
Training loss: 2.342706778732017
Validation loss: 2.462783862036888

Epoch: 6| Step: 1
Training loss: 2.1990257707016445
Validation loss: 2.5277595280087617

Epoch: 6| Step: 2
Training loss: 2.397238863664635
Validation loss: 2.6031318613544543

Epoch: 6| Step: 3
Training loss: 2.4596449591130294
Validation loss: 2.684597502762002

Epoch: 6| Step: 4
Training loss: 3.1877746463708694
Validation loss: 2.7640893954499903

Epoch: 6| Step: 5
Training loss: 2.3576906773143547
Validation loss: 2.700050767734984

Epoch: 6| Step: 6
Training loss: 2.272743145280378
Validation loss: 2.592154774736209

Epoch: 6| Step: 7
Training loss: 2.33533850297166
Validation loss: 2.503094798259431

Epoch: 6| Step: 8
Training loss: 2.0450825304758533
Validation loss: 2.452154601566562

Epoch: 6| Step: 9
Training loss: 1.7223250228526794
Validation loss: 2.4119879914041973

Epoch: 6| Step: 10
Training loss: 2.5329191567840192
Validation loss: 2.414139153795115

Epoch: 6| Step: 11
Training loss: 2.643912892475016
Validation loss: 2.39748170350488

Epoch: 6| Step: 12
Training loss: 2.6980375363486675
Validation loss: 2.397758338292476

Epoch: 6| Step: 13
Training loss: 1.9169466049208448
Validation loss: 2.41287788901287

Epoch: 284| Step: 0
Training loss: 1.9780577782272
Validation loss: 2.4145952855334536

Epoch: 6| Step: 1
Training loss: 3.11122789239443
Validation loss: 2.4194427534763014

Epoch: 6| Step: 2
Training loss: 2.5970366463233034
Validation loss: 2.4426373974930007

Epoch: 6| Step: 3
Training loss: 2.154740842030307
Validation loss: 2.4893121453667275

Epoch: 6| Step: 4
Training loss: 1.6938618021308638
Validation loss: 2.5064648936239164

Epoch: 6| Step: 5
Training loss: 2.4618502422868858
Validation loss: 2.543860679908061

Epoch: 6| Step: 6
Training loss: 2.7895999679088455
Validation loss: 2.5670385928523896

Epoch: 6| Step: 7
Training loss: 2.5042425396977497
Validation loss: 2.6253277251272333

Epoch: 6| Step: 8
Training loss: 2.0319296066751806
Validation loss: 2.6330751361283187

Epoch: 6| Step: 9
Training loss: 2.518905017711214
Validation loss: 2.602941583401861

Epoch: 6| Step: 10
Training loss: 2.1003690259126913
Validation loss: 2.5428200556930136

Epoch: 6| Step: 11
Training loss: 2.4194700051655933
Validation loss: 2.4915005124105636

Epoch: 6| Step: 12
Training loss: 2.175613698209466
Validation loss: 2.4701647263505766

Epoch: 6| Step: 13
Training loss: 2.10747515988446
Validation loss: 2.4399772846832875

Epoch: 285| Step: 0
Training loss: 2.7541228513555613
Validation loss: 2.4400237233427315

Epoch: 6| Step: 1
Training loss: 2.5359054892465185
Validation loss: 2.4584952506720654

Epoch: 6| Step: 2
Training loss: 1.3127224597413991
Validation loss: 2.449763379359746

Epoch: 6| Step: 3
Training loss: 2.6164808543456277
Validation loss: 2.4610380533395855

Epoch: 6| Step: 4
Training loss: 2.315938300844362
Validation loss: 2.4752057808764762

Epoch: 6| Step: 5
Training loss: 2.2241435513582166
Validation loss: 2.498123563005802

Epoch: 6| Step: 6
Training loss: 2.3662526516262217
Validation loss: 2.5214188181512704

Epoch: 6| Step: 7
Training loss: 2.365809275455659
Validation loss: 2.5186278857701434

Epoch: 6| Step: 8
Training loss: 1.844602613995315
Validation loss: 2.53662929467065

Epoch: 6| Step: 9
Training loss: 2.6952220072274953
Validation loss: 2.571912744926159

Epoch: 6| Step: 10
Training loss: 1.990520542823557
Validation loss: 2.5946621487522963

Epoch: 6| Step: 11
Training loss: 1.9864270270977424
Validation loss: 2.5932672888849164

Epoch: 6| Step: 12
Training loss: 2.289858734904376
Validation loss: 2.6233175064781973

Epoch: 6| Step: 13
Training loss: 3.122954652914473
Validation loss: 2.5753132701351764

Epoch: 286| Step: 0
Training loss: 2.527235827728603
Validation loss: 2.526226711229678

Epoch: 6| Step: 1
Training loss: 2.355969124402253
Validation loss: 2.5189267132065565

Epoch: 6| Step: 2
Training loss: 2.4685671774856606
Validation loss: 2.4849634859522918

Epoch: 6| Step: 3
Training loss: 2.2717564191134585
Validation loss: 2.479865422318812

Epoch: 6| Step: 4
Training loss: 2.4050127291590355
Validation loss: 2.459652434339334

Epoch: 6| Step: 5
Training loss: 2.2430120673227045
Validation loss: 2.4532233989798393

Epoch: 6| Step: 6
Training loss: 2.5057450087770765
Validation loss: 2.4721080993653013

Epoch: 6| Step: 7
Training loss: 2.250710269294694
Validation loss: 2.4619836664765367

Epoch: 6| Step: 8
Training loss: 2.3765747471280014
Validation loss: 2.4587628229413703

Epoch: 6| Step: 9
Training loss: 1.814181238669925
Validation loss: 2.470070731366013

Epoch: 6| Step: 10
Training loss: 2.064445040857516
Validation loss: 2.4824664301661103

Epoch: 6| Step: 11
Training loss: 2.0090613136638082
Validation loss: 2.4743782561842464

Epoch: 6| Step: 12
Training loss: 2.460055141606312
Validation loss: 2.5117656943425954

Epoch: 6| Step: 13
Training loss: 2.6692879628197836
Validation loss: 2.4845542799171985

Epoch: 287| Step: 0
Training loss: 2.274907112321279
Validation loss: 2.5112614769838904

Epoch: 6| Step: 1
Training loss: 2.2799361116258727
Validation loss: 2.5072678922875395

Epoch: 6| Step: 2
Training loss: 2.6477379339139686
Validation loss: 2.4885645954091866

Epoch: 6| Step: 3
Training loss: 1.9958634514284905
Validation loss: 2.475959954782847

Epoch: 6| Step: 4
Training loss: 2.5229421784937816
Validation loss: 2.481534589335103

Epoch: 6| Step: 5
Training loss: 1.8422111296169597
Validation loss: 2.4796996280976753

Epoch: 6| Step: 6
Training loss: 2.4031766610613583
Validation loss: 2.4766397114469947

Epoch: 6| Step: 7
Training loss: 2.9253721473203
Validation loss: 2.4883289064398286

Epoch: 6| Step: 8
Training loss: 2.61851991357346
Validation loss: 2.4873595639344517

Epoch: 6| Step: 9
Training loss: 2.2578105992503894
Validation loss: 2.515250112137868

Epoch: 6| Step: 10
Training loss: 1.749971934502211
Validation loss: 2.5168827504690428

Epoch: 6| Step: 11
Training loss: 2.1560363663700923
Validation loss: 2.5293226065835084

Epoch: 6| Step: 12
Training loss: 1.9057373858498141
Validation loss: 2.5290772493822034

Epoch: 6| Step: 13
Training loss: 2.6731629418495944
Validation loss: 2.5574652840922476

Epoch: 288| Step: 0
Training loss: 2.742532648606816
Validation loss: 2.5763618891568227

Epoch: 6| Step: 1
Training loss: 2.348600733928538
Validation loss: 2.6176228136280786

Epoch: 6| Step: 2
Training loss: 2.5497996382442345
Validation loss: 2.643463916417914

Epoch: 6| Step: 3
Training loss: 2.729788110076591
Validation loss: 2.5929697649487595

Epoch: 6| Step: 4
Training loss: 1.7532441178651117
Validation loss: 2.540082725097933

Epoch: 6| Step: 5
Training loss: 2.636339490953329
Validation loss: 2.519285018576255

Epoch: 6| Step: 6
Training loss: 2.1285594972768003
Validation loss: 2.4890686799311585

Epoch: 6| Step: 7
Training loss: 2.292923831012321
Validation loss: 2.470108390607981

Epoch: 6| Step: 8
Training loss: 2.2200718555334396
Validation loss: 2.477905346215138

Epoch: 6| Step: 9
Training loss: 2.2659443597317535
Validation loss: 2.4603148845220084

Epoch: 6| Step: 10
Training loss: 2.256108786266467
Validation loss: 2.47142365449558

Epoch: 6| Step: 11
Training loss: 2.150678873448851
Validation loss: 2.488574515911213

Epoch: 6| Step: 12
Training loss: 1.939162986543139
Validation loss: 2.4827269437387103

Epoch: 6| Step: 13
Training loss: 2.0449626812875796
Validation loss: 2.480127927067154

Epoch: 289| Step: 0
Training loss: 2.127737525922201
Validation loss: 2.497954984219456

Epoch: 6| Step: 1
Training loss: 1.969014165200601
Validation loss: 2.5293624384814963

Epoch: 6| Step: 2
Training loss: 2.836412458344184
Validation loss: 2.525747543446066

Epoch: 6| Step: 3
Training loss: 1.7251957105102564
Validation loss: 2.511518353500453

Epoch: 6| Step: 4
Training loss: 2.3851575974511525
Validation loss: 2.5461328349799217

Epoch: 6| Step: 5
Training loss: 2.1421210636935943
Validation loss: 2.5568210573201995

Epoch: 6| Step: 6
Training loss: 2.7253636563729913
Validation loss: 2.5466078781664927

Epoch: 6| Step: 7
Training loss: 1.9429461936116865
Validation loss: 2.5379466038176317

Epoch: 6| Step: 8
Training loss: 1.7479944999136914
Validation loss: 2.4989357744318172

Epoch: 6| Step: 9
Training loss: 2.092122826349406
Validation loss: 2.465075803304744

Epoch: 6| Step: 10
Training loss: 2.492241359595077
Validation loss: 2.4500226438110873

Epoch: 6| Step: 11
Training loss: 2.3827932888569823
Validation loss: 2.449722159015202

Epoch: 6| Step: 12
Training loss: 2.7154366483875574
Validation loss: 2.4587770363692805

Epoch: 6| Step: 13
Training loss: 2.640063615523772
Validation loss: 2.48048061180363

Epoch: 290| Step: 0
Training loss: 2.5742657994325158
Validation loss: 2.4800755647879673

Epoch: 6| Step: 1
Training loss: 1.836288548448596
Validation loss: 2.5171539627256525

Epoch: 6| Step: 2
Training loss: 1.7650595240511306
Validation loss: 2.51942935580805

Epoch: 6| Step: 3
Training loss: 2.7169128875863704
Validation loss: 2.561222597397787

Epoch: 6| Step: 4
Training loss: 2.3595130324249336
Validation loss: 2.555829223064373

Epoch: 6| Step: 5
Training loss: 2.4635244184754503
Validation loss: 2.561920495664567

Epoch: 6| Step: 6
Training loss: 2.6008035738471924
Validation loss: 2.566294635977734

Epoch: 6| Step: 7
Training loss: 1.160575405657382
Validation loss: 2.5349090969910217

Epoch: 6| Step: 8
Training loss: 2.2725342729290054
Validation loss: 2.523615019726683

Epoch: 6| Step: 9
Training loss: 2.6019171395739136
Validation loss: 2.5243614844579034

Epoch: 6| Step: 10
Training loss: 2.1372337487799102
Validation loss: 2.488594956347398

Epoch: 6| Step: 11
Training loss: 2.2471123284859384
Validation loss: 2.498467773634974

Epoch: 6| Step: 12
Training loss: 2.5584347741045046
Validation loss: 2.4834735607647156

Epoch: 6| Step: 13
Training loss: 2.0942208059679785
Validation loss: 2.4903331153913424

Epoch: 291| Step: 0
Training loss: 2.1187811340025027
Validation loss: 2.4921014306523697

Epoch: 6| Step: 1
Training loss: 2.652778241577463
Validation loss: 2.491145915633968

Epoch: 6| Step: 2
Training loss: 1.741669445248567
Validation loss: 2.498917357533412

Epoch: 6| Step: 3
Training loss: 2.566404113304143
Validation loss: 2.537117389934477

Epoch: 6| Step: 4
Training loss: 2.539394697319023
Validation loss: 2.5454100358941263

Epoch: 6| Step: 5
Training loss: 2.6721369743187724
Validation loss: 2.542333236776532

Epoch: 6| Step: 6
Training loss: 1.9770619360754405
Validation loss: 2.5273402758088808

Epoch: 6| Step: 7
Training loss: 2.196626643200692
Validation loss: 2.509383487892663

Epoch: 6| Step: 8
Training loss: 2.5772006140512067
Validation loss: 2.463912223858978

Epoch: 6| Step: 9
Training loss: 2.1194848690730237
Validation loss: 2.479810659171722

Epoch: 6| Step: 10
Training loss: 1.8548818202044703
Validation loss: 2.4879867470352717

Epoch: 6| Step: 11
Training loss: 2.5183340140879746
Validation loss: 2.486372961764201

Epoch: 6| Step: 12
Training loss: 1.6430563939145162
Validation loss: 2.4926952033037373

Epoch: 6| Step: 13
Training loss: 2.3193835315840396
Validation loss: 2.549354271038208

Epoch: 292| Step: 0
Training loss: 2.2514620375341705
Validation loss: 2.590312917680064

Epoch: 6| Step: 1
Training loss: 2.3269550020582703
Validation loss: 2.608515231764914

Epoch: 6| Step: 2
Training loss: 2.2265939810685653
Validation loss: 2.600910284728546

Epoch: 6| Step: 3
Training loss: 2.7844511319251235
Validation loss: 2.543173227648429

Epoch: 6| Step: 4
Training loss: 2.2382394943203794
Validation loss: 2.5067619796890463

Epoch: 6| Step: 5
Training loss: 2.337859622810317
Validation loss: 2.49557631950722

Epoch: 6| Step: 6
Training loss: 2.4907446245018505
Validation loss: 2.4897220295078

Epoch: 6| Step: 7
Training loss: 2.5290574361811022
Validation loss: 2.470081089401341

Epoch: 6| Step: 8
Training loss: 1.8692546558574687
Validation loss: 2.445065184400644

Epoch: 6| Step: 9
Training loss: 2.163606120438046
Validation loss: 2.4206431579556957

Epoch: 6| Step: 10
Training loss: 1.826853383236869
Validation loss: 2.428265576549434

Epoch: 6| Step: 11
Training loss: 1.8991329975611337
Validation loss: 2.417694967433298

Epoch: 6| Step: 12
Training loss: 2.464190848520737
Validation loss: 2.444874352286382

Epoch: 6| Step: 13
Training loss: 2.2085159034355035
Validation loss: 2.463709297782329

Epoch: 293| Step: 0
Training loss: 2.321809125456111
Validation loss: 2.4810530156830017

Epoch: 6| Step: 1
Training loss: 2.4097959474785178
Validation loss: 2.485580043733184

Epoch: 6| Step: 2
Training loss: 1.7698716263635514
Validation loss: 2.5504989212748908

Epoch: 6| Step: 3
Training loss: 2.2021456225730347
Validation loss: 2.6221520502561755

Epoch: 6| Step: 4
Training loss: 2.4937649222097202
Validation loss: 2.6626632596083786

Epoch: 6| Step: 5
Training loss: 2.6910286736805316
Validation loss: 2.6675342358584766

Epoch: 6| Step: 6
Training loss: 2.681095832002668
Validation loss: 2.6102587577728324

Epoch: 6| Step: 7
Training loss: 2.4915986994868713
Validation loss: 2.5460509645572196

Epoch: 6| Step: 8
Training loss: 2.2905689269068357
Validation loss: 2.5007490512582486

Epoch: 6| Step: 9
Training loss: 1.7420693943378722
Validation loss: 2.4631608765280637

Epoch: 6| Step: 10
Training loss: 2.2136632070645983
Validation loss: 2.434668689552312

Epoch: 6| Step: 11
Training loss: 2.225910399128849
Validation loss: 2.444604446080383

Epoch: 6| Step: 12
Training loss: 1.9808237333256342
Validation loss: 2.445141299294514

Epoch: 6| Step: 13
Training loss: 2.255671664268189
Validation loss: 2.427356564284039

Epoch: 294| Step: 0
Training loss: 2.272748390446434
Validation loss: 2.4339710644222743

Epoch: 6| Step: 1
Training loss: 1.8835706015595939
Validation loss: 2.467409937154454

Epoch: 6| Step: 2
Training loss: 2.253509222065516
Validation loss: 2.5027948118904284

Epoch: 6| Step: 3
Training loss: 2.1903845161205586
Validation loss: 2.5738851438224177

Epoch: 6| Step: 4
Training loss: 2.5510360333489657
Validation loss: 2.615812704774387

Epoch: 6| Step: 5
Training loss: 2.3674217586619903
Validation loss: 2.638605747529962

Epoch: 6| Step: 6
Training loss: 2.688772210916586
Validation loss: 2.665856423519579

Epoch: 6| Step: 7
Training loss: 2.0498423725097084
Validation loss: 2.6141958550549695

Epoch: 6| Step: 8
Training loss: 1.7396881239464916
Validation loss: 2.5927067642966226

Epoch: 6| Step: 9
Training loss: 2.57868812653226
Validation loss: 2.565886213262359

Epoch: 6| Step: 10
Training loss: 2.081426078061053
Validation loss: 2.5322919569901465

Epoch: 6| Step: 11
Training loss: 2.1957271089382373
Validation loss: 2.495066091240932

Epoch: 6| Step: 12
Training loss: 2.689311636733046
Validation loss: 2.4527194595351784

Epoch: 6| Step: 13
Training loss: 2.2462724962843392
Validation loss: 2.486995944663579

Epoch: 295| Step: 0
Training loss: 2.3104456462596277
Validation loss: 2.4720390449065017

Epoch: 6| Step: 1
Training loss: 2.2817731283617935
Validation loss: 2.4248004975886768

Epoch: 6| Step: 2
Training loss: 2.0494692138533614
Validation loss: 2.437125671310249

Epoch: 6| Step: 3
Training loss: 2.184522837164338
Validation loss: 2.4193337277547577

Epoch: 6| Step: 4
Training loss: 2.2258944395935263
Validation loss: 2.4108990421303185

Epoch: 6| Step: 5
Training loss: 2.502079289729789
Validation loss: 2.409340627163431

Epoch: 6| Step: 6
Training loss: 2.8732035456093175
Validation loss: 2.4376416056108186

Epoch: 6| Step: 7
Training loss: 1.8715766172183954
Validation loss: 2.4670345773953

Epoch: 6| Step: 8
Training loss: 1.762452372455307
Validation loss: 2.4877419801997736

Epoch: 6| Step: 9
Training loss: 2.3889537280053754
Validation loss: 2.498805116365483

Epoch: 6| Step: 10
Training loss: 2.0607388230723767
Validation loss: 2.5050809859116225

Epoch: 6| Step: 11
Training loss: 2.4908430245769195
Validation loss: 2.5133583600060954

Epoch: 6| Step: 12
Training loss: 2.2914456925637565
Validation loss: 2.499536383104864

Epoch: 6| Step: 13
Training loss: 2.140602056004434
Validation loss: 2.5330769781845284

Epoch: 296| Step: 0
Training loss: 2.2471834143499483
Validation loss: 2.5383344648054873

Epoch: 6| Step: 1
Training loss: 2.384968966875969
Validation loss: 2.5432373386918816

Epoch: 6| Step: 2
Training loss: 2.3166710636271
Validation loss: 2.5619557000441233

Epoch: 6| Step: 3
Training loss: 2.4793037141591703
Validation loss: 2.546779914398097

Epoch: 6| Step: 4
Training loss: 2.239510563104327
Validation loss: 2.5114972156522626

Epoch: 6| Step: 5
Training loss: 2.3417991148211765
Validation loss: 2.499430441837192

Epoch: 6| Step: 6
Training loss: 1.8060481899206886
Validation loss: 2.519580604710215

Epoch: 6| Step: 7
Training loss: 2.353137429902378
Validation loss: 2.523301901958934

Epoch: 6| Step: 8
Training loss: 2.1057458245839373
Validation loss: 2.5593595211580626

Epoch: 6| Step: 9
Training loss: 2.0900512592290252
Validation loss: 2.6225825075481137

Epoch: 6| Step: 10
Training loss: 2.4254932570464978
Validation loss: 2.610949199566816

Epoch: 6| Step: 11
Training loss: 2.2427672590306673
Validation loss: 2.599214623109519

Epoch: 6| Step: 12
Training loss: 1.8413645296545567
Validation loss: 2.5402105101608785

Epoch: 6| Step: 13
Training loss: 2.1872364430375297
Validation loss: 2.4898657164721243

Epoch: 297| Step: 0
Training loss: 2.392551817457409
Validation loss: 2.486280928238078

Epoch: 6| Step: 1
Training loss: 2.103025926634216
Validation loss: 2.4477910285567974

Epoch: 6| Step: 2
Training loss: 2.605084026248189
Validation loss: 2.4312312034881853

Epoch: 6| Step: 3
Training loss: 2.601477819215853
Validation loss: 2.4363575896284524

Epoch: 6| Step: 4
Training loss: 2.641889280772908
Validation loss: 2.4532486932933155

Epoch: 6| Step: 5
Training loss: 1.8809835327620097
Validation loss: 2.5135331238000553

Epoch: 6| Step: 6
Training loss: 2.109888311024439
Validation loss: 2.5452160279207807

Epoch: 6| Step: 7
Training loss: 2.5625868061528383
Validation loss: 2.6067559991905194

Epoch: 6| Step: 8
Training loss: 2.2253033206226998
Validation loss: 2.5540110202416355

Epoch: 6| Step: 9
Training loss: 2.4724069864425857
Validation loss: 2.5303329899158755

Epoch: 6| Step: 10
Training loss: 2.0597981181801996
Validation loss: 2.4955688399141125

Epoch: 6| Step: 11
Training loss: 1.3260676437114916
Validation loss: 2.457310844743377

Epoch: 6| Step: 12
Training loss: 1.8982167056693313
Validation loss: 2.4437595743751754

Epoch: 6| Step: 13
Training loss: 1.8046227645823185
Validation loss: 2.443024443769463

Epoch: 298| Step: 0
Training loss: 2.186395093619086
Validation loss: 2.457596667625744

Epoch: 6| Step: 1
Training loss: 2.0609883635450172
Validation loss: 2.4682809454991044

Epoch: 6| Step: 2
Training loss: 2.291283269079805
Validation loss: 2.506914526660193

Epoch: 6| Step: 3
Training loss: 2.233250688570472
Validation loss: 2.538471447325589

Epoch: 6| Step: 4
Training loss: 2.401018077764809
Validation loss: 2.5438370504846297

Epoch: 6| Step: 5
Training loss: 2.012865528532845
Validation loss: 2.5824498102341837

Epoch: 6| Step: 6
Training loss: 2.5989586798923137
Validation loss: 2.5419332107978114

Epoch: 6| Step: 7
Training loss: 2.190456245659326
Validation loss: 2.5559035885774857

Epoch: 6| Step: 8
Training loss: 1.8292272782186003
Validation loss: 2.5118071100496064

Epoch: 6| Step: 9
Training loss: 2.0560743633730096
Validation loss: 2.508320931134933

Epoch: 6| Step: 10
Training loss: 2.4042230961974105
Validation loss: 2.4864168594570377

Epoch: 6| Step: 11
Training loss: 1.8357305531843864
Validation loss: 2.489481890216299

Epoch: 6| Step: 12
Training loss: 2.6763841381425655
Validation loss: 2.4916648516015765

Epoch: 6| Step: 13
Training loss: 1.827065511317165
Validation loss: 2.4843739588069664

Epoch: 299| Step: 0
Training loss: 2.2945239432260447
Validation loss: 2.4514204480267163

Epoch: 6| Step: 1
Training loss: 2.271959801183947
Validation loss: 2.4547902073826124

Epoch: 6| Step: 2
Training loss: 2.270680226988667
Validation loss: 2.4555266181107998

Epoch: 6| Step: 3
Training loss: 2.447026830958722
Validation loss: 2.4269533748831935

Epoch: 6| Step: 4
Training loss: 2.2718105721553536
Validation loss: 2.43879386547841

Epoch: 6| Step: 5
Training loss: 1.8768251436962304
Validation loss: 2.4440941017299944

Epoch: 6| Step: 6
Training loss: 2.415396115216322
Validation loss: 2.444925829567677

Epoch: 6| Step: 7
Training loss: 2.789569712447249
Validation loss: 2.5097475061679924

Epoch: 6| Step: 8
Training loss: 1.4180684540639696
Validation loss: 2.576276723350497

Epoch: 6| Step: 9
Training loss: 2.4272160855335487
Validation loss: 2.635562738172931

Epoch: 6| Step: 10
Training loss: 2.1584507864828555
Validation loss: 2.6966762569639307

Epoch: 6| Step: 11
Training loss: 2.096878447437437
Validation loss: 2.736442861736512

Epoch: 6| Step: 12
Training loss: 2.1305051066783482
Validation loss: 2.684911155893681

Epoch: 6| Step: 13
Training loss: 1.9800057556569608
Validation loss: 2.575276858663411

Epoch: 300| Step: 0
Training loss: 2.068771422122552
Validation loss: 2.5076865398852637

Epoch: 6| Step: 1
Training loss: 2.2750672466693542
Validation loss: 2.441068096541256

Epoch: 6| Step: 2
Training loss: 1.80335731530358
Validation loss: 2.422609828652599

Epoch: 6| Step: 3
Training loss: 2.6787360367831585
Validation loss: 2.3981961594545864

Epoch: 6| Step: 4
Training loss: 2.5714613367445502
Validation loss: 2.402983561241375

Epoch: 6| Step: 5
Training loss: 2.2796966280633524
Validation loss: 2.3990136818916286

Epoch: 6| Step: 6
Training loss: 2.3876339021052155
Validation loss: 2.395326512799327

Epoch: 6| Step: 7
Training loss: 1.7227597713722012
Validation loss: 2.3920195118982894

Epoch: 6| Step: 8
Training loss: 2.5455061153352645
Validation loss: 2.4534158758246893

Epoch: 6| Step: 9
Training loss: 2.135869221687817
Validation loss: 2.4876399340087367

Epoch: 6| Step: 10
Training loss: 1.7130550014219417
Validation loss: 2.508172927659002

Epoch: 6| Step: 11
Training loss: 2.384235894981342
Validation loss: 2.545488918632632

Epoch: 6| Step: 12
Training loss: 2.14213475357883
Validation loss: 2.5412591849304054

Epoch: 6| Step: 13
Training loss: 2.3958839964001895
Validation loss: 2.522781291319934

Epoch: 301| Step: 0
Training loss: 2.0764729522846728
Validation loss: 2.538813399723716

Epoch: 6| Step: 1
Training loss: 2.3816256209356497
Validation loss: 2.539554953956425

Epoch: 6| Step: 2
Training loss: 1.942489352595975
Validation loss: 2.538105951928256

Epoch: 6| Step: 3
Training loss: 2.3480519803806685
Validation loss: 2.5062865821202687

Epoch: 6| Step: 4
Training loss: 1.5706719893239565
Validation loss: 2.52202865023335

Epoch: 6| Step: 5
Training loss: 2.2316154031181274
Validation loss: 2.508984762215317

Epoch: 6| Step: 6
Training loss: 2.463058574858173
Validation loss: 2.51749877504241

Epoch: 6| Step: 7
Training loss: 2.532112916396229
Validation loss: 2.4859391459269973

Epoch: 6| Step: 8
Training loss: 1.937320639399147
Validation loss: 2.4867391061440807

Epoch: 6| Step: 9
Training loss: 2.413760268171251
Validation loss: 2.492022681934956

Epoch: 6| Step: 10
Training loss: 2.2536409377263915
Validation loss: 2.5184554096084097

Epoch: 6| Step: 11
Training loss: 1.9687813650387833
Validation loss: 2.5122917184059217

Epoch: 6| Step: 12
Training loss: 2.0517090070349497
Validation loss: 2.525192061200219

Epoch: 6| Step: 13
Training loss: 1.991548084043448
Validation loss: 2.5166452527807475

Epoch: 302| Step: 0
Training loss: 2.1768845341156307
Validation loss: 2.520656893426869

Epoch: 6| Step: 1
Training loss: 2.0268750540150773
Validation loss: 2.51679780984159

Epoch: 6| Step: 2
Training loss: 1.1536445129708455
Validation loss: 2.4936504238349237

Epoch: 6| Step: 3
Training loss: 1.7883028641540701
Validation loss: 2.48096075690879

Epoch: 6| Step: 4
Training loss: 2.186657443589244
Validation loss: 2.4629713189694566

Epoch: 6| Step: 5
Training loss: 2.342659556716583
Validation loss: 2.453908652600059

Epoch: 6| Step: 6
Training loss: 2.3964654724320735
Validation loss: 2.4357729815723017

Epoch: 6| Step: 7
Training loss: 2.388982370553451
Validation loss: 2.4263565194851755

Epoch: 6| Step: 8
Training loss: 2.333890802909859
Validation loss: 2.455122303444276

Epoch: 6| Step: 9
Training loss: 2.364410887044263
Validation loss: 2.4342707995776425

Epoch: 6| Step: 10
Training loss: 2.3028756988877164
Validation loss: 2.444101732555868

Epoch: 6| Step: 11
Training loss: 2.386279476217516
Validation loss: 2.484390685948488

Epoch: 6| Step: 12
Training loss: 2.1518348050580642
Validation loss: 2.5103097051307888

Epoch: 6| Step: 13
Training loss: 2.0931979917805648
Validation loss: 2.5320149558026945

Epoch: 303| Step: 0
Training loss: 2.5243099818365047
Validation loss: 2.538990113998999

Epoch: 6| Step: 1
Training loss: 1.9621784797238766
Validation loss: 2.534194638268241

Epoch: 6| Step: 2
Training loss: 2.4470560603670988
Validation loss: 2.5287974538688553

Epoch: 6| Step: 3
Training loss: 2.0531934520626685
Validation loss: 2.5253956783926075

Epoch: 6| Step: 4
Training loss: 2.004294553021945
Validation loss: 2.502451693301863

Epoch: 6| Step: 5
Training loss: 1.9221130471779206
Validation loss: 2.481670609563906

Epoch: 6| Step: 6
Training loss: 1.8120905972836103
Validation loss: 2.4994282489111592

Epoch: 6| Step: 7
Training loss: 1.5836168420177867
Validation loss: 2.4778663611494447

Epoch: 6| Step: 8
Training loss: 2.3827166428593
Validation loss: 2.4736286441483872

Epoch: 6| Step: 9
Training loss: 1.9005047880502315
Validation loss: 2.4811318294552476

Epoch: 6| Step: 10
Training loss: 2.60688196657357
Validation loss: 2.489490248998175

Epoch: 6| Step: 11
Training loss: 2.4108428718948707
Validation loss: 2.4753792623917374

Epoch: 6| Step: 12
Training loss: 2.1855525476076965
Validation loss: 2.4832022482507177

Epoch: 6| Step: 13
Training loss: 1.8892272322068908
Validation loss: 2.4768129797054383

Epoch: 304| Step: 0
Training loss: 2.530379911101658
Validation loss: 2.4882921854285867

Epoch: 6| Step: 1
Training loss: 2.2250403839904083
Validation loss: 2.484252852387517

Epoch: 6| Step: 2
Training loss: 1.6938746107369973
Validation loss: 2.48657217116019

Epoch: 6| Step: 3
Training loss: 2.4827305371515815
Validation loss: 2.496857674077434

Epoch: 6| Step: 4
Training loss: 2.073845608871604
Validation loss: 2.510792935130003

Epoch: 6| Step: 5
Training loss: 1.9742096176509878
Validation loss: 2.5218070060120317

Epoch: 6| Step: 6
Training loss: 1.9793537319186232
Validation loss: 2.5166057849727497

Epoch: 6| Step: 7
Training loss: 2.170733034986036
Validation loss: 2.4973675578691212

Epoch: 6| Step: 8
Training loss: 2.0622070566849278
Validation loss: 2.5060578711714547

Epoch: 6| Step: 9
Training loss: 2.0029250451326623
Validation loss: 2.507967368885825

Epoch: 6| Step: 10
Training loss: 2.07917988326383
Validation loss: 2.4955289771364764

Epoch: 6| Step: 11
Training loss: 2.006925631929581
Validation loss: 2.5015696181960623

Epoch: 6| Step: 12
Training loss: 2.6936613028454452
Validation loss: 2.493426653903455

Epoch: 6| Step: 13
Training loss: 0.9027252711815469
Validation loss: 2.5026860389499035

Epoch: 305| Step: 0
Training loss: 2.4439275067343154
Validation loss: 2.502436526249995

Epoch: 6| Step: 1
Training loss: 2.2362833476685307
Validation loss: 2.511525855005217

Epoch: 6| Step: 2
Training loss: 2.268793560692294
Validation loss: 2.5121365680991743

Epoch: 6| Step: 3
Training loss: 2.1167293489241086
Validation loss: 2.523252396515727

Epoch: 6| Step: 4
Training loss: 1.9612870835639191
Validation loss: 2.531635730541459

Epoch: 6| Step: 5
Training loss: 1.9894827040011314
Validation loss: 2.5619380784018557

Epoch: 6| Step: 6
Training loss: 1.9237437273286375
Validation loss: 2.596719010422214

Epoch: 6| Step: 7
Training loss: 2.208116436749246
Validation loss: 2.6018128485721426

Epoch: 6| Step: 8
Training loss: 2.19581636232867
Validation loss: 2.606540554491301

Epoch: 6| Step: 9
Training loss: 2.0491968628575834
Validation loss: 2.592935836875708

Epoch: 6| Step: 10
Training loss: 2.1224769873208387
Validation loss: 2.6355037250866196

Epoch: 6| Step: 11
Training loss: 1.9671574160795675
Validation loss: 2.540870106620255

Epoch: 6| Step: 12
Training loss: 2.1071131129162906
Validation loss: 2.496636942506856

Epoch: 6| Step: 13
Training loss: 2.119267079320398
Validation loss: 2.4690485044706634

Epoch: 306| Step: 0
Training loss: 2.125792411710407
Validation loss: 2.420849792510365

Epoch: 6| Step: 1
Training loss: 2.1338596777502996
Validation loss: 2.4185732169218603

Epoch: 6| Step: 2
Training loss: 2.4814441595333805
Validation loss: 2.4080970503338612

Epoch: 6| Step: 3
Training loss: 1.8132892074311744
Validation loss: 2.3909792062956394

Epoch: 6| Step: 4
Training loss: 2.4361691876743947
Validation loss: 2.3823733883550395

Epoch: 6| Step: 5
Training loss: 2.239412191786425
Validation loss: 2.40931948667585

Epoch: 6| Step: 6
Training loss: 2.0176466628303067
Validation loss: 2.397532389124324

Epoch: 6| Step: 7
Training loss: 1.8838008961323172
Validation loss: 2.4588511300388123

Epoch: 6| Step: 8
Training loss: 1.7461528725396767
Validation loss: 2.5562967414633255

Epoch: 6| Step: 9
Training loss: 2.3466605869489
Validation loss: 2.5799012400443977

Epoch: 6| Step: 10
Training loss: 1.9919789523004707
Validation loss: 2.605998817667464

Epoch: 6| Step: 11
Training loss: 2.365853717586698
Validation loss: 2.5722435272493738

Epoch: 6| Step: 12
Training loss: 2.4492956511427
Validation loss: 2.5545774944617756

Epoch: 6| Step: 13
Training loss: 1.2173436682907584
Validation loss: 2.5587315525800416

Epoch: 307| Step: 0
Training loss: 1.9501156014631091
Validation loss: 2.5341761063434203

Epoch: 6| Step: 1
Training loss: 2.2126540135804054
Validation loss: 2.5249089571746546

Epoch: 6| Step: 2
Training loss: 1.9058471629257177
Validation loss: 2.5243456934655417

Epoch: 6| Step: 3
Training loss: 2.7293060403039093
Validation loss: 2.5214052343979874

Epoch: 6| Step: 4
Training loss: 1.7546303662503875
Validation loss: 2.51590662114706

Epoch: 6| Step: 5
Training loss: 1.366663587186802
Validation loss: 2.512442766399999

Epoch: 6| Step: 6
Training loss: 2.289396294222189
Validation loss: 2.5139607288725125

Epoch: 6| Step: 7
Training loss: 2.0453104344088713
Validation loss: 2.537073682366469

Epoch: 6| Step: 8
Training loss: 1.9411750517634274
Validation loss: 2.5148194957853454

Epoch: 6| Step: 9
Training loss: 1.5354332128053365
Validation loss: 2.543381404221093

Epoch: 6| Step: 10
Training loss: 2.5663136272467426
Validation loss: 2.550853882299364

Epoch: 6| Step: 11
Training loss: 2.349114750449371
Validation loss: 2.573786212251807

Epoch: 6| Step: 12
Training loss: 2.4666745116994013
Validation loss: 2.5682565022876127

Epoch: 6| Step: 13
Training loss: 1.8727265244126403
Validation loss: 2.586105844324243

Epoch: 308| Step: 0
Training loss: 1.8299447156549609
Validation loss: 2.539145505446039

Epoch: 6| Step: 1
Training loss: 1.8514252301931087
Validation loss: 2.508930219811162

Epoch: 6| Step: 2
Training loss: 2.5706022615213104
Validation loss: 2.4919233099498066

Epoch: 6| Step: 3
Training loss: 2.5155734418241376
Validation loss: 2.4867372133657084

Epoch: 6| Step: 4
Training loss: 2.076907037607844
Validation loss: 2.4612047046790315

Epoch: 6| Step: 5
Training loss: 2.008177134136601
Validation loss: 2.490170755556923

Epoch: 6| Step: 6
Training loss: 1.972657942063012
Validation loss: 2.4818032667209597

Epoch: 6| Step: 7
Training loss: 2.3673438092988905
Validation loss: 2.4975956665953323

Epoch: 6| Step: 8
Training loss: 1.8715330496174911
Validation loss: 2.495678684233324

Epoch: 6| Step: 9
Training loss: 1.8167652062571948
Validation loss: 2.462890506336574

Epoch: 6| Step: 10
Training loss: 2.19497308788442
Validation loss: 2.4489230333485827

Epoch: 6| Step: 11
Training loss: 1.898431597413985
Validation loss: 2.4590423980349096

Epoch: 6| Step: 12
Training loss: 2.2523356077303074
Validation loss: 2.474253531408063

Epoch: 6| Step: 13
Training loss: 1.3421653008540302
Validation loss: 2.48460060148366

Epoch: 309| Step: 0
Training loss: 1.9047234473149488
Validation loss: 2.4945355499524338

Epoch: 6| Step: 1
Training loss: 2.1950424951423964
Validation loss: 2.508344892576652

Epoch: 6| Step: 2
Training loss: 2.039788712424159
Validation loss: 2.5391707232738656

Epoch: 6| Step: 3
Training loss: 2.1360954756454587
Validation loss: 2.5268336470418005

Epoch: 6| Step: 4
Training loss: 1.634812366906626
Validation loss: 2.5260686556853607

Epoch: 6| Step: 5
Training loss: 2.2693667327553775
Validation loss: 2.535820214267592

Epoch: 6| Step: 6
Training loss: 1.7418064675812328
Validation loss: 2.5576282384411195

Epoch: 6| Step: 7
Training loss: 2.0506925436544243
Validation loss: 2.560678442397376

Epoch: 6| Step: 8
Training loss: 2.295443964881444
Validation loss: 2.5804524585278568

Epoch: 6| Step: 9
Training loss: 2.3774605102147577
Validation loss: 2.5631383345417516

Epoch: 6| Step: 10
Training loss: 2.3314836073104237
Validation loss: 2.55330736357946

Epoch: 6| Step: 11
Training loss: 1.9857765114493806
Validation loss: 2.5242983005996407

Epoch: 6| Step: 12
Training loss: 2.053545384212273
Validation loss: 2.506765610236238

Epoch: 6| Step: 13
Training loss: 1.6324898432931214
Validation loss: 2.4940089941223365

Epoch: 310| Step: 0
Training loss: 2.4737433624564047
Validation loss: 2.4913045084209036

Epoch: 6| Step: 1
Training loss: 1.545208891046053
Validation loss: 2.480520178988651

Epoch: 6| Step: 2
Training loss: 2.073175947628821
Validation loss: 2.476391351971856

Epoch: 6| Step: 3
Training loss: 2.1489006514272804
Validation loss: 2.5162447995961337

Epoch: 6| Step: 4
Training loss: 1.5995078700910335
Validation loss: 2.5124692368995114

Epoch: 6| Step: 5
Training loss: 2.124132091330117
Validation loss: 2.5362595239807155

Epoch: 6| Step: 6
Training loss: 1.8968553268694475
Validation loss: 2.558271339015162

Epoch: 6| Step: 7
Training loss: 2.0196190820479654
Validation loss: 2.595320652903999

Epoch: 6| Step: 8
Training loss: 1.7120507507244143
Validation loss: 2.6143020457654806

Epoch: 6| Step: 9
Training loss: 2.2831136328630657
Validation loss: 2.5989980502041488

Epoch: 6| Step: 10
Training loss: 2.3509928371331683
Validation loss: 2.584801538175611

Epoch: 6| Step: 11
Training loss: 2.3397770077670734
Validation loss: 2.5530477259096824

Epoch: 6| Step: 12
Training loss: 2.196720092868537
Validation loss: 2.5016837182542293

Epoch: 6| Step: 13
Training loss: 1.8582117625387198
Validation loss: 2.4930562925509516

Epoch: 311| Step: 0
Training loss: 1.651889459010511
Validation loss: 2.4409630992717775

Epoch: 6| Step: 1
Training loss: 1.9187513568885801
Validation loss: 2.4665508192202603

Epoch: 6| Step: 2
Training loss: 2.1736030564922344
Validation loss: 2.4486520050685234

Epoch: 6| Step: 3
Training loss: 1.891354002579562
Validation loss: 2.4824776473174612

Epoch: 6| Step: 4
Training loss: 2.3286004317079683
Validation loss: 2.5075792949101

Epoch: 6| Step: 5
Training loss: 2.1260497922117496
Validation loss: 2.5331498428395682

Epoch: 6| Step: 6
Training loss: 1.9712042270684744
Validation loss: 2.584927528128536

Epoch: 6| Step: 7
Training loss: 2.1050143910548096
Validation loss: 2.579483077254458

Epoch: 6| Step: 8
Training loss: 2.443845363619679
Validation loss: 2.5926134594731725

Epoch: 6| Step: 9
Training loss: 1.759533865821438
Validation loss: 2.5591674902868182

Epoch: 6| Step: 10
Training loss: 1.9076779129831738
Validation loss: 2.5395351457799356

Epoch: 6| Step: 11
Training loss: 1.997789472628941
Validation loss: 2.5157974633463684

Epoch: 6| Step: 12
Training loss: 2.1168022227496923
Validation loss: 2.514898190208569

Epoch: 6| Step: 13
Training loss: 2.422999754574677
Validation loss: 2.5123897827279276

Epoch: 312| Step: 0
Training loss: 1.9194731551785056
Validation loss: 2.5083868931524913

Epoch: 6| Step: 1
Training loss: 1.9122986431959426
Validation loss: 2.4643808433362717

Epoch: 6| Step: 2
Training loss: 2.2134654551831305
Validation loss: 2.4601452769983294

Epoch: 6| Step: 3
Training loss: 2.4216881464587323
Validation loss: 2.441746561463176

Epoch: 6| Step: 4
Training loss: 2.3085766063899205
Validation loss: 2.419008147205172

Epoch: 6| Step: 5
Training loss: 2.0973565084596086
Validation loss: 2.424572987115398

Epoch: 6| Step: 6
Training loss: 2.246769599405444
Validation loss: 2.4641952721189355

Epoch: 6| Step: 7
Training loss: 1.401037261086194
Validation loss: 2.463611836880002

Epoch: 6| Step: 8
Training loss: 2.188548681389232
Validation loss: 2.507774956136274

Epoch: 6| Step: 9
Training loss: 2.176367634459368
Validation loss: 2.541463499524338

Epoch: 6| Step: 10
Training loss: 2.2345977885542014
Validation loss: 2.571547673908594

Epoch: 6| Step: 11
Training loss: 1.7995285343919107
Validation loss: 2.6370052496467853

Epoch: 6| Step: 12
Training loss: 1.5599718621968626
Validation loss: 2.677114189094301

Epoch: 6| Step: 13
Training loss: 2.272733179431522
Validation loss: 2.738563706412418

Epoch: 313| Step: 0
Training loss: 2.5412901510884276
Validation loss: 2.7440280319434005

Epoch: 6| Step: 1
Training loss: 2.3463065890203216
Validation loss: 2.646319695315023

Epoch: 6| Step: 2
Training loss: 1.9374637600370515
Validation loss: 2.527371523070018

Epoch: 6| Step: 3
Training loss: 1.6815388257696582
Validation loss: 2.4656975389129605

Epoch: 6| Step: 4
Training loss: 2.284407220657578
Validation loss: 2.4351242346991935

Epoch: 6| Step: 5
Training loss: 1.712626490132977
Validation loss: 2.4602933536445692

Epoch: 6| Step: 6
Training loss: 2.2727737768790672
Validation loss: 2.444591899479921

Epoch: 6| Step: 7
Training loss: 2.1700849222890537
Validation loss: 2.4871978428254637

Epoch: 6| Step: 8
Training loss: 1.7781903943739543
Validation loss: 2.480582066819592

Epoch: 6| Step: 9
Training loss: 2.14393704768893
Validation loss: 2.4695915448303816

Epoch: 6| Step: 10
Training loss: 1.7767924700935125
Validation loss: 2.4664937783420386

Epoch: 6| Step: 11
Training loss: 2.080095891025949
Validation loss: 2.503716028670179

Epoch: 6| Step: 12
Training loss: 1.9505169354456282
Validation loss: 2.5169640357309766

Epoch: 6| Step: 13
Training loss: 2.876423359022804
Validation loss: 2.548838225339054

Epoch: 314| Step: 0
Training loss: 1.7207719180745058
Validation loss: 2.56326229583283

Epoch: 6| Step: 1
Training loss: 2.662401682869673
Validation loss: 2.6097785849323056

Epoch: 6| Step: 2
Training loss: 1.7524943286624406
Validation loss: 2.60097736564319

Epoch: 6| Step: 3
Training loss: 1.8900462123731276
Validation loss: 2.5587948760552965

Epoch: 6| Step: 4
Training loss: 2.406787168316255
Validation loss: 2.5367082372192433

Epoch: 6| Step: 5
Training loss: 2.355079428918718
Validation loss: 2.495400943293543

Epoch: 6| Step: 6
Training loss: 1.84044454366782
Validation loss: 2.4858311009093215

Epoch: 6| Step: 7
Training loss: 2.1385373147237963
Validation loss: 2.4782926267016196

Epoch: 6| Step: 8
Training loss: 2.144443197475108
Validation loss: 2.458169850008942

Epoch: 6| Step: 9
Training loss: 1.9015563964745796
Validation loss: 2.4833366528913015

Epoch: 6| Step: 10
Training loss: 2.04839262865912
Validation loss: 2.4818676269409172

Epoch: 6| Step: 11
Training loss: 1.7765364270071002
Validation loss: 2.4923715491645595

Epoch: 6| Step: 12
Training loss: 1.7236424951038236
Validation loss: 2.4935395772034616

Epoch: 6| Step: 13
Training loss: 2.0030109867017454
Validation loss: 2.512567843229003

Epoch: 315| Step: 0
Training loss: 1.3491074861329673
Validation loss: 2.511930039579726

Epoch: 6| Step: 1
Training loss: 2.476714698134076
Validation loss: 2.5044483929354953

Epoch: 6| Step: 2
Training loss: 1.870483999906345
Validation loss: 2.5137197292971654

Epoch: 6| Step: 3
Training loss: 2.4013385933891325
Validation loss: 2.545727295363424

Epoch: 6| Step: 4
Training loss: 2.1945773485501783
Validation loss: 2.526937335634389

Epoch: 6| Step: 5
Training loss: 2.3607547590827256
Validation loss: 2.553968762664323

Epoch: 6| Step: 6
Training loss: 2.0698301509152133
Validation loss: 2.594361623662553

Epoch: 6| Step: 7
Training loss: 1.7838338214985632
Validation loss: 2.5974772448764236

Epoch: 6| Step: 8
Training loss: 2.126708073506901
Validation loss: 2.5947038498066033

Epoch: 6| Step: 9
Training loss: 1.503083239191359
Validation loss: 2.6280719929220164

Epoch: 6| Step: 10
Training loss: 1.5215698531578958
Validation loss: 2.6458524438931548

Epoch: 6| Step: 11
Training loss: 1.65983596404924
Validation loss: 2.6434939641547883

Epoch: 6| Step: 12
Training loss: 2.082715693153605
Validation loss: 2.6218046115031957

Epoch: 6| Step: 13
Training loss: 2.8740013710183288
Validation loss: 2.599928592398609

Epoch: 316| Step: 0
Training loss: 1.1406487240349046
Validation loss: 2.59271333429862

Epoch: 6| Step: 1
Training loss: 1.7796923870927193
Validation loss: 2.574783332248154

Epoch: 6| Step: 2
Training loss: 1.9579953314557008
Validation loss: 2.5550224518883655

Epoch: 6| Step: 3
Training loss: 2.4687460404376376
Validation loss: 2.5565750932281976

Epoch: 6| Step: 4
Training loss: 1.9868597858874832
Validation loss: 2.5541051259969705

Epoch: 6| Step: 5
Training loss: 2.266958541403522
Validation loss: 2.5847931236175747

Epoch: 6| Step: 6
Training loss: 1.7440409701285864
Validation loss: 2.5710134260225965

Epoch: 6| Step: 7
Training loss: 1.9675498816481582
Validation loss: 2.553254571245716

Epoch: 6| Step: 8
Training loss: 1.883690087391478
Validation loss: 2.5224962271133236

Epoch: 6| Step: 9
Training loss: 1.8220070740345744
Validation loss: 2.4839138439618567

Epoch: 6| Step: 10
Training loss: 2.025491857251948
Validation loss: 2.4730020398670263

Epoch: 6| Step: 11
Training loss: 2.2000969171850873
Validation loss: 2.4812179941518595

Epoch: 6| Step: 12
Training loss: 2.147384996099248
Validation loss: 2.43754794670763

Epoch: 6| Step: 13
Training loss: 2.4686967868140126
Validation loss: 2.489867982686898

Epoch: 317| Step: 0
Training loss: 1.862003360048698
Validation loss: 2.476801366347627

Epoch: 6| Step: 1
Training loss: 2.3094866941126124
Validation loss: 2.4879356104681483

Epoch: 6| Step: 2
Training loss: 1.6951720008114826
Validation loss: 2.5132803354751867

Epoch: 6| Step: 3
Training loss: 2.234375
Validation loss: 2.5374147451051163

Epoch: 6| Step: 4
Training loss: 1.7966534685323656
Validation loss: 2.550124015020327

Epoch: 6| Step: 5
Training loss: 2.038179988546264
Validation loss: 2.557926047582477

Epoch: 6| Step: 6
Training loss: 2.117594662186395
Validation loss: 2.542162298342855

Epoch: 6| Step: 7
Training loss: 1.7070963343034526
Validation loss: 2.534170042644724

Epoch: 6| Step: 8
Training loss: 2.358891115399675
Validation loss: 2.5182283261105334

Epoch: 6| Step: 9
Training loss: 2.2881515825650456
Validation loss: 2.5161683409102196

Epoch: 6| Step: 10
Training loss: 1.7319563763875443
Validation loss: 2.5152399625369064

Epoch: 6| Step: 11
Training loss: 2.1125339166751345
Validation loss: 2.525816178012696

Epoch: 6| Step: 12
Training loss: 1.875540846068407
Validation loss: 2.533830990616984

Epoch: 6| Step: 13
Training loss: 0.9337787524677249
Validation loss: 2.5267544609189723

Epoch: 318| Step: 0
Training loss: 2.179641777844268
Validation loss: 2.547686717947627

Epoch: 6| Step: 1
Training loss: 1.8400880039979814
Validation loss: 2.5437228165060666

Epoch: 6| Step: 2
Training loss: 1.8694999134260608
Validation loss: 2.5431311070228175

Epoch: 6| Step: 3
Training loss: 1.454025645736929
Validation loss: 2.5225951417062107

Epoch: 6| Step: 4
Training loss: 2.8347082915756316
Validation loss: 2.5001832689769845

Epoch: 6| Step: 5
Training loss: 1.572162961273588
Validation loss: 2.5111863723800916

Epoch: 6| Step: 6
Training loss: 2.2156250129129385
Validation loss: 2.5021153893447337

Epoch: 6| Step: 7
Training loss: 2.0132048515772216
Validation loss: 2.488398465936195

Epoch: 6| Step: 8
Training loss: 1.6967560559590875
Validation loss: 2.48632648349613

Epoch: 6| Step: 9
Training loss: 2.1062421351435945
Validation loss: 2.4801934899952616

Epoch: 6| Step: 10
Training loss: 1.9920378984116984
Validation loss: 2.505143547196824

Epoch: 6| Step: 11
Training loss: 1.756518213826475
Validation loss: 2.487499627702668

Epoch: 6| Step: 12
Training loss: 1.7735267650304285
Validation loss: 2.4943942861767523

Epoch: 6| Step: 13
Training loss: 2.251550775797893
Validation loss: 2.535211281863528

Epoch: 319| Step: 0
Training loss: 2.3287895329509145
Validation loss: 2.569280879224471

Epoch: 6| Step: 1
Training loss: 2.0287483656260266
Validation loss: 2.608388178586641

Epoch: 6| Step: 2
Training loss: 1.479280825584024
Validation loss: 2.625475116319205

Epoch: 6| Step: 3
Training loss: 1.6502275194458125
Validation loss: 2.633878676833215

Epoch: 6| Step: 4
Training loss: 1.9769865644092002
Validation loss: 2.5978489134098535

Epoch: 6| Step: 5
Training loss: 2.465909651846916
Validation loss: 2.5738804774652984

Epoch: 6| Step: 6
Training loss: 2.2510018767218134
Validation loss: 2.530485400553541

Epoch: 6| Step: 7
Training loss: 1.2253127808146118
Validation loss: 2.5156503771754952

Epoch: 6| Step: 8
Training loss: 2.113329084775166
Validation loss: 2.4848564477564934

Epoch: 6| Step: 9
Training loss: 1.9895233291711572
Validation loss: 2.4910275121827476

Epoch: 6| Step: 10
Training loss: 1.5352863130485004
Validation loss: 2.46779277557323

Epoch: 6| Step: 11
Training loss: 1.960267336188458
Validation loss: 2.449931622208757

Epoch: 6| Step: 12
Training loss: 2.2586269295735026
Validation loss: 2.4468330447700914

Epoch: 6| Step: 13
Training loss: 1.7729946037163027
Validation loss: 2.476974639857875

Epoch: 320| Step: 0
Training loss: 2.3232562468377136
Validation loss: 2.482644960882834

Epoch: 6| Step: 1
Training loss: 2.1902651068074257
Validation loss: 2.504802871020471

Epoch: 6| Step: 2
Training loss: 1.8493872633021746
Validation loss: 2.5697539647422944

Epoch: 6| Step: 3
Training loss: 2.468401727374926
Validation loss: 2.5716227014033683

Epoch: 6| Step: 4
Training loss: 1.6779792082979528
Validation loss: 2.595150076120347

Epoch: 6| Step: 5
Training loss: 1.2292043820214609
Validation loss: 2.607833189670771

Epoch: 6| Step: 6
Training loss: 1.5041219185101977
Validation loss: 2.605643056112523

Epoch: 6| Step: 7
Training loss: 2.2655750137602713
Validation loss: 2.6137377774603436

Epoch: 6| Step: 8
Training loss: 1.7878683177580688
Validation loss: 2.5780581299383782

Epoch: 6| Step: 9
Training loss: 2.151562114374795
Validation loss: 2.5671448967487267

Epoch: 6| Step: 10
Training loss: 1.9625115631151624
Validation loss: 2.507789900759071

Epoch: 6| Step: 11
Training loss: 1.5978053986339158
Validation loss: 2.470221245540034

Epoch: 6| Step: 12
Training loss: 2.0120812543156665
Validation loss: 2.4671894061555357

Epoch: 6| Step: 13
Training loss: 2.190197834154343
Validation loss: 2.427733147950121

Epoch: 321| Step: 0
Training loss: 1.9525339681916263
Validation loss: 2.4535893453476265

Epoch: 6| Step: 1
Training loss: 2.1074078464836603
Validation loss: 2.4538831509201113

Epoch: 6| Step: 2
Training loss: 2.1724009803181157
Validation loss: 2.476268569326634

Epoch: 6| Step: 3
Training loss: 2.0590898469772525
Validation loss: 2.4926451445025535

Epoch: 6| Step: 4
Training loss: 0.9670258838420235
Validation loss: 2.522430803277603

Epoch: 6| Step: 5
Training loss: 1.614267412677518
Validation loss: 2.5117998778128543

Epoch: 6| Step: 6
Training loss: 1.692303355751617
Validation loss: 2.5366601627204974

Epoch: 6| Step: 7
Training loss: 2.096626696829785
Validation loss: 2.5139454762518705

Epoch: 6| Step: 8
Training loss: 1.843529898226969
Validation loss: 2.519844852589857

Epoch: 6| Step: 9
Training loss: 1.921658387421338
Validation loss: 2.5494163874408873

Epoch: 6| Step: 10
Training loss: 2.415172136699605
Validation loss: 2.545112841252739

Epoch: 6| Step: 11
Training loss: 2.341318522284084
Validation loss: 2.5587834444218873

Epoch: 6| Step: 12
Training loss: 1.846583629673835
Validation loss: 2.602423121071465

Epoch: 6| Step: 13
Training loss: 2.0220795423292803
Validation loss: 2.573546437942824

Epoch: 322| Step: 0
Training loss: 1.613352111294655
Validation loss: 2.5417491516844457

Epoch: 6| Step: 1
Training loss: 1.518484348250369
Validation loss: 2.4995221593993273

Epoch: 6| Step: 2
Training loss: 1.8028865266447451
Validation loss: 2.4957552929817632

Epoch: 6| Step: 3
Training loss: 2.2170463791307564
Validation loss: 2.4550610582159504

Epoch: 6| Step: 4
Training loss: 1.6690590932954505
Validation loss: 2.4825931866031863

Epoch: 6| Step: 5
Training loss: 1.5407339401881273
Validation loss: 2.48498700152847

Epoch: 6| Step: 6
Training loss: 2.166418012386929
Validation loss: 2.461017466318705

Epoch: 6| Step: 7
Training loss: 1.8155687595921244
Validation loss: 2.4692050903274807

Epoch: 6| Step: 8
Training loss: 2.060058420149169
Validation loss: 2.5020529439465116

Epoch: 6| Step: 9
Training loss: 2.1199970817545832
Validation loss: 2.5025947047073673

Epoch: 6| Step: 10
Training loss: 1.7352159540518421
Validation loss: 2.520198632962426

Epoch: 6| Step: 11
Training loss: 2.147128729562118
Validation loss: 2.5032959223439772

Epoch: 6| Step: 12
Training loss: 2.4770565081770233
Validation loss: 2.4993449239891103

Epoch: 6| Step: 13
Training loss: 1.9417699707230154
Validation loss: 2.5200791993255884

Epoch: 323| Step: 0
Training loss: 1.766448849919786
Validation loss: 2.5134877597376466

Epoch: 6| Step: 1
Training loss: 2.3987585592191736
Validation loss: 2.510921671714407

Epoch: 6| Step: 2
Training loss: 1.763491125972994
Validation loss: 2.513028748950524

Epoch: 6| Step: 3
Training loss: 1.7608990506812319
Validation loss: 2.544650694597846

Epoch: 6| Step: 4
Training loss: 1.3312731960227888
Validation loss: 2.5407123303798245

Epoch: 6| Step: 5
Training loss: 1.8061215206505838
Validation loss: 2.567788388394318

Epoch: 6| Step: 6
Training loss: 1.9631311070038426
Validation loss: 2.565222032003562

Epoch: 6| Step: 7
Training loss: 1.8880409678120003
Validation loss: 2.562057901177971

Epoch: 6| Step: 8
Training loss: 1.8669383628980887
Validation loss: 2.5762053252746875

Epoch: 6| Step: 9
Training loss: 2.0481579669141934
Validation loss: 2.5732345889474457

Epoch: 6| Step: 10
Training loss: 2.291778723549113
Validation loss: 2.582372769318081

Epoch: 6| Step: 11
Training loss: 2.2942737199734133
Validation loss: 2.531268456626093

Epoch: 6| Step: 12
Training loss: 1.5891709462298078
Validation loss: 2.5164828138855877

Epoch: 6| Step: 13
Training loss: 2.3380033104173967
Validation loss: 2.4990880266724704

Epoch: 324| Step: 0
Training loss: 1.661830641149844
Validation loss: 2.4823813993711084

Epoch: 6| Step: 1
Training loss: 2.110551407163316
Validation loss: 2.436586990989123

Epoch: 6| Step: 2
Training loss: 2.3259905561089784
Validation loss: 2.44336857880912

Epoch: 6| Step: 3
Training loss: 1.6522842288287762
Validation loss: 2.4511381952226863

Epoch: 6| Step: 4
Training loss: 2.0577708269793282
Validation loss: 2.477823254525858

Epoch: 6| Step: 5
Training loss: 1.6687809487662573
Validation loss: 2.4859030650977565

Epoch: 6| Step: 6
Training loss: 1.4515365614693372
Validation loss: 2.492905507575931

Epoch: 6| Step: 7
Training loss: 1.6051415622826046
Validation loss: 2.5476635657635933

Epoch: 6| Step: 8
Training loss: 2.056021369815603
Validation loss: 2.576021069710372

Epoch: 6| Step: 9
Training loss: 1.538124844497989
Validation loss: 2.568070210938908

Epoch: 6| Step: 10
Training loss: 2.2789716447687347
Validation loss: 2.5698228605257207

Epoch: 6| Step: 11
Training loss: 2.629098689615658
Validation loss: 2.5454166277618397

Epoch: 6| Step: 12
Training loss: 1.5874568632978412
Validation loss: 2.559921330784916

Epoch: 6| Step: 13
Training loss: 2.176740944935208
Validation loss: 2.5643547902790917

Epoch: 325| Step: 0
Training loss: 1.7052376618967298
Validation loss: 2.5658413251883263

Epoch: 6| Step: 1
Training loss: 2.011046184220024
Validation loss: 2.571825871768204

Epoch: 6| Step: 2
Training loss: 2.012864225611621
Validation loss: 2.5520501799917263

Epoch: 6| Step: 3
Training loss: 1.8106070532154581
Validation loss: 2.5412258658268314

Epoch: 6| Step: 4
Training loss: 1.6225250911095048
Validation loss: 2.5251652524925428

Epoch: 6| Step: 5
Training loss: 2.5821797245983777
Validation loss: 2.527275390227968

Epoch: 6| Step: 6
Training loss: 1.8718856378167053
Validation loss: 2.5167623150349847

Epoch: 6| Step: 7
Training loss: 1.8860034415940794
Validation loss: 2.503064413477998

Epoch: 6| Step: 8
Training loss: 1.9493063255314276
Validation loss: 2.4653045279252126

Epoch: 6| Step: 9
Training loss: 0.929719299285471
Validation loss: 2.474877896264005

Epoch: 6| Step: 10
Training loss: 2.1494178338648195
Validation loss: 2.4718407525418935

Epoch: 6| Step: 11
Training loss: 1.8517476564693545
Validation loss: 2.4768415263909773

Epoch: 6| Step: 12
Training loss: 1.6858627005769282
Validation loss: 2.5164611034328264

Epoch: 6| Step: 13
Training loss: 2.3266856205158204
Validation loss: 2.5749071311750535

Epoch: 326| Step: 0
Training loss: 2.0195497847689716
Validation loss: 2.587027407021987

Epoch: 6| Step: 1
Training loss: 1.7674904480154012
Validation loss: 2.61720746295523

Epoch: 6| Step: 2
Training loss: 2.0265342551610885
Validation loss: 2.6047955632640605

Epoch: 6| Step: 3
Training loss: 2.0366445652979475
Validation loss: 2.616921067148766

Epoch: 6| Step: 4
Training loss: 2.0853746204793175
Validation loss: 2.529079432818691

Epoch: 6| Step: 5
Training loss: 1.6200683292060205
Validation loss: 2.5057385202357825

Epoch: 6| Step: 6
Training loss: 1.9005431754033544
Validation loss: 2.5159223902125687

Epoch: 6| Step: 7
Training loss: 2.102888065045624
Validation loss: 2.4806073849691606

Epoch: 6| Step: 8
Training loss: 2.079488436073093
Validation loss: 2.5048867354088133

Epoch: 6| Step: 9
Training loss: 1.7515336537091384
Validation loss: 2.5249938716629274

Epoch: 6| Step: 10
Training loss: 1.3651536472885613
Validation loss: 2.509382068859715

Epoch: 6| Step: 11
Training loss: 2.337560083769646
Validation loss: 2.51392158501844

Epoch: 6| Step: 12
Training loss: 1.6912626068931027
Validation loss: 2.543154588772973

Epoch: 6| Step: 13
Training loss: 1.5793412309183184
Validation loss: 2.5425736809242476

Epoch: 327| Step: 0
Training loss: 1.849605894639347
Validation loss: 2.519068694654519

Epoch: 6| Step: 1
Training loss: 2.2372507649138087
Validation loss: 2.48907341671169

Epoch: 6| Step: 2
Training loss: 2.238080346909197
Validation loss: 2.4676308276459533

Epoch: 6| Step: 3
Training loss: 1.2239190548485428
Validation loss: 2.4531085184459482

Epoch: 6| Step: 4
Training loss: 1.6826454554312598
Validation loss: 2.4633647448718494

Epoch: 6| Step: 5
Training loss: 2.1284206011432736
Validation loss: 2.4615611832855935

Epoch: 6| Step: 6
Training loss: 1.478427093153155
Validation loss: 2.4699932284272927

Epoch: 6| Step: 7
Training loss: 1.7597876408731392
Validation loss: 2.491411199618068

Epoch: 6| Step: 8
Training loss: 2.1712814727592904
Validation loss: 2.501393572728351

Epoch: 6| Step: 9
Training loss: 2.0460513255821575
Validation loss: 2.5032367165337726

Epoch: 6| Step: 10
Training loss: 1.8564418449550073
Validation loss: 2.5371825704589885

Epoch: 6| Step: 11
Training loss: 2.307825673969042
Validation loss: 2.561237692591204

Epoch: 6| Step: 12
Training loss: 1.7251260573173353
Validation loss: 2.5939239836980534

Epoch: 6| Step: 13
Training loss: 1.3243700689320308
Validation loss: 2.6068916649708287

Epoch: 328| Step: 0
Training loss: 1.7590665963661096
Validation loss: 2.6353545347963103

Epoch: 6| Step: 1
Training loss: 1.8937087957853667
Validation loss: 2.6218980958229285

Epoch: 6| Step: 2
Training loss: 1.7813204031968013
Validation loss: 2.5977765124788985

Epoch: 6| Step: 3
Training loss: 1.7543252898900485
Validation loss: 2.5626808550881734

Epoch: 6| Step: 4
Training loss: 1.70288084187388
Validation loss: 2.5457935570077876

Epoch: 6| Step: 5
Training loss: 1.677075079982502
Validation loss: 2.533916125135336

Epoch: 6| Step: 6
Training loss: 2.12763858115208
Validation loss: 2.4903276974593966

Epoch: 6| Step: 7
Training loss: 1.7228163733422386
Validation loss: 2.49153773970584

Epoch: 6| Step: 8
Training loss: 2.100818601640101
Validation loss: 2.462369158550078

Epoch: 6| Step: 9
Training loss: 1.5814552294568724
Validation loss: 2.454106817008937

Epoch: 6| Step: 10
Training loss: 2.1320989623872055
Validation loss: 2.419497681967568

Epoch: 6| Step: 11
Training loss: 1.9939750879160598
Validation loss: 2.4268158834795304

Epoch: 6| Step: 12
Training loss: 1.8068295271807904
Validation loss: 2.425313008630054

Epoch: 6| Step: 13
Training loss: 2.4185298336476846
Validation loss: 2.433656982860287

Epoch: 329| Step: 0
Training loss: 0.9339368500976916
Validation loss: 2.461174131893478

Epoch: 6| Step: 1
Training loss: 1.819305665383214
Validation loss: 2.463755427515565

Epoch: 6| Step: 2
Training loss: 2.001463116479646
Validation loss: 2.5452884614695757

Epoch: 6| Step: 3
Training loss: 1.9859503552780846
Validation loss: 2.5585630543876237

Epoch: 6| Step: 4
Training loss: 1.8814565754262955
Validation loss: 2.636943287588214

Epoch: 6| Step: 5
Training loss: 2.473614017552215
Validation loss: 2.679016840632953

Epoch: 6| Step: 6
Training loss: 1.8441439062346696
Validation loss: 2.644651487329045

Epoch: 6| Step: 7
Training loss: 1.5683296552338613
Validation loss: 2.6236879787909793

Epoch: 6| Step: 8
Training loss: 2.1116617876020074
Validation loss: 2.5960809992203493

Epoch: 6| Step: 9
Training loss: 1.9735675783998963
Validation loss: 2.575039515962182

Epoch: 6| Step: 10
Training loss: 1.8548906891482757
Validation loss: 2.5348822752509133

Epoch: 6| Step: 11
Training loss: 2.211589380143779
Validation loss: 2.515329652789786

Epoch: 6| Step: 12
Training loss: 1.7932220479524947
Validation loss: 2.4736222537677555

Epoch: 6| Step: 13
Training loss: 1.775363095178127
Validation loss: 2.4364378755117935

Epoch: 330| Step: 0
Training loss: 1.8997472946362586
Validation loss: 2.433290765471189

Epoch: 6| Step: 1
Training loss: 1.8789484411883592
Validation loss: 2.429331702485836

Epoch: 6| Step: 2
Training loss: 2.064520684095903
Validation loss: 2.4688935804690613

Epoch: 6| Step: 3
Training loss: 1.6599047661086008
Validation loss: 2.507259064147442

Epoch: 6| Step: 4
Training loss: 1.8239261629443568
Validation loss: 2.491116880410476

Epoch: 6| Step: 5
Training loss: 1.7928561838089925
Validation loss: 2.5249016233644

Epoch: 6| Step: 6
Training loss: 2.006832135793236
Validation loss: 2.5253639782874484

Epoch: 6| Step: 7
Training loss: 1.4728166811548007
Validation loss: 2.572206904882653

Epoch: 6| Step: 8
Training loss: 2.0750137788246157
Validation loss: 2.5913656735834207

Epoch: 6| Step: 9
Training loss: 1.9985325913700558
Validation loss: 2.610286183408942

Epoch: 6| Step: 10
Training loss: 2.075306982289547
Validation loss: 2.6344075970357954

Epoch: 6| Step: 11
Training loss: 1.7018933523633621
Validation loss: 2.577242709050652

Epoch: 6| Step: 12
Training loss: 1.627955683069852
Validation loss: 2.5105206854324895

Epoch: 6| Step: 13
Training loss: 2.714520200481706
Validation loss: 2.486561337453131

Epoch: 331| Step: 0
Training loss: 1.5482690867770952
Validation loss: 2.479999062974285

Epoch: 6| Step: 1
Training loss: 1.789978059602246
Validation loss: 2.4518170401799053

Epoch: 6| Step: 2
Training loss: 2.140764329371618
Validation loss: 2.4914466038727445

Epoch: 6| Step: 3
Training loss: 2.1895484052849103
Validation loss: 2.486238694455305

Epoch: 6| Step: 4
Training loss: 1.6099031192940068
Validation loss: 2.4759481531195986

Epoch: 6| Step: 5
Training loss: 2.32648292338804
Validation loss: 2.481282811242248

Epoch: 6| Step: 6
Training loss: 2.408705313267551
Validation loss: 2.4901862402777297

Epoch: 6| Step: 7
Training loss: 1.358468509844028
Validation loss: 2.493731217312704

Epoch: 6| Step: 8
Training loss: 1.6001445913546617
Validation loss: 2.493511939314687

Epoch: 6| Step: 9
Training loss: 1.3758962051394719
Validation loss: 2.5377271156060432

Epoch: 6| Step: 10
Training loss: 2.0652994750621265
Validation loss: 2.5649014217260127

Epoch: 6| Step: 11
Training loss: 1.7579767447138868
Validation loss: 2.5973391142931144

Epoch: 6| Step: 12
Training loss: 2.0981722007171633
Validation loss: 2.6046311385526897

Epoch: 6| Step: 13
Training loss: 1.744345111543029
Validation loss: 2.614907510373111

Epoch: 332| Step: 0
Training loss: 2.3684454367313768
Validation loss: 2.620847684699414

Epoch: 6| Step: 1
Training loss: 2.396349765569311
Validation loss: 2.551743044003471

Epoch: 6| Step: 2
Training loss: 1.5471000122409593
Validation loss: 2.5635345245543313

Epoch: 6| Step: 3
Training loss: 1.6160937309984333
Validation loss: 2.5153071817314405

Epoch: 6| Step: 4
Training loss: 1.619334468120828
Validation loss: 2.4820478130444346

Epoch: 6| Step: 5
Training loss: 1.9721201555350099
Validation loss: 2.4809068342851717

Epoch: 6| Step: 6
Training loss: 2.0341194425938416
Validation loss: 2.458302265288637

Epoch: 6| Step: 7
Training loss: 2.166142864978906
Validation loss: 2.4816429309154353

Epoch: 6| Step: 8
Training loss: 1.8266624403763119
Validation loss: 2.4820152205170203

Epoch: 6| Step: 9
Training loss: 1.6766964562931541
Validation loss: 2.4826781801988385

Epoch: 6| Step: 10
Training loss: 2.089608608814341
Validation loss: 2.501657310917551

Epoch: 6| Step: 11
Training loss: 1.6341044594095215
Validation loss: 2.4976701380608928

Epoch: 6| Step: 12
Training loss: 1.3317784044241747
Validation loss: 2.538292774938119

Epoch: 6| Step: 13
Training loss: 1.1925649542882488
Validation loss: 2.568944259718197

Epoch: 333| Step: 0
Training loss: 1.2529719309178353
Validation loss: 2.5951579019222843

Epoch: 6| Step: 1
Training loss: 1.678960172515946
Validation loss: 2.6314588876602274

Epoch: 6| Step: 2
Training loss: 1.7255879409165293
Validation loss: 2.625051016441211

Epoch: 6| Step: 3
Training loss: 1.8449951105647442
Validation loss: 2.624107943687663

Epoch: 6| Step: 4
Training loss: 2.050441517618899
Validation loss: 2.573513134409993

Epoch: 6| Step: 5
Training loss: 2.0206062215492353
Validation loss: 2.5292662829922525

Epoch: 6| Step: 6
Training loss: 1.8617918191482339
Validation loss: 2.4962693743400868

Epoch: 6| Step: 7
Training loss: 2.0178145706759283
Validation loss: 2.467820734741394

Epoch: 6| Step: 8
Training loss: 1.945495045381353
Validation loss: 2.461387222588563

Epoch: 6| Step: 9
Training loss: 2.2483075452286614
Validation loss: 2.452384554296956

Epoch: 6| Step: 10
Training loss: 1.834924686351933
Validation loss: 2.444902677350722

Epoch: 6| Step: 11
Training loss: 2.099570766360139
Validation loss: 2.464266310772361

Epoch: 6| Step: 12
Training loss: 1.3813017442772184
Validation loss: 2.5140700347429967

Epoch: 6| Step: 13
Training loss: 1.9072029983463337
Validation loss: 2.5545447886294697

Epoch: 334| Step: 0
Training loss: 1.3492147086678807
Validation loss: 2.55522678063699

Epoch: 6| Step: 1
Training loss: 1.8634562860002872
Validation loss: 2.549612549331716

Epoch: 6| Step: 2
Training loss: 1.6756924692391633
Validation loss: 2.5901724453150625

Epoch: 6| Step: 3
Training loss: 1.4849405917733516
Validation loss: 2.5884169909624335

Epoch: 6| Step: 4
Training loss: 2.0190714860629675
Validation loss: 2.573000451471978

Epoch: 6| Step: 5
Training loss: 2.055819819477736
Validation loss: 2.5477966909673424

Epoch: 6| Step: 6
Training loss: 2.115818383353224
Validation loss: 2.5507102689719736

Epoch: 6| Step: 7
Training loss: 1.7859346458165282
Validation loss: 2.5473999452791842

Epoch: 6| Step: 8
Training loss: 1.8042008705802655
Validation loss: 2.5106266733659663

Epoch: 6| Step: 9
Training loss: 1.5148587206946234
Validation loss: 2.5349788700100215

Epoch: 6| Step: 10
Training loss: 2.11987708167246
Validation loss: 2.5384799992722167

Epoch: 6| Step: 11
Training loss: 1.7787057206519383
Validation loss: 2.5291303548074464

Epoch: 6| Step: 12
Training loss: 1.9392268576117113
Validation loss: 2.5230906746071846

Epoch: 6| Step: 13
Training loss: 1.9391815517866797
Validation loss: 2.5234727993226502

Epoch: 335| Step: 0
Training loss: 1.6820422323234276
Validation loss: 2.5570681677527567

Epoch: 6| Step: 1
Training loss: 1.7810176229317214
Validation loss: 2.549405392411871

Epoch: 6| Step: 2
Training loss: 1.7603959829104754
Validation loss: 2.5604581704180953

Epoch: 6| Step: 3
Training loss: 1.8180387646578342
Validation loss: 2.582769363785851

Epoch: 6| Step: 4
Training loss: 1.5965709777595
Validation loss: 2.5932316653203054

Epoch: 6| Step: 5
Training loss: 1.6797742244599159
Validation loss: 2.6460226306308554

Epoch: 6| Step: 6
Training loss: 2.147873128109942
Validation loss: 2.601782361341025

Epoch: 6| Step: 7
Training loss: 1.4460712812379417
Validation loss: 2.6196288352995123

Epoch: 6| Step: 8
Training loss: 1.8506120906380865
Validation loss: 2.565280097527927

Epoch: 6| Step: 9
Training loss: 2.0831859027830903
Validation loss: 2.5262416654285325

Epoch: 6| Step: 10
Training loss: 1.9070301648191172
Validation loss: 2.520559959331319

Epoch: 6| Step: 11
Training loss: 1.8752690440112207
Validation loss: 2.5075025771078563

Epoch: 6| Step: 12
Training loss: 1.438688864647765
Validation loss: 2.5040858668904873

Epoch: 6| Step: 13
Training loss: 2.5148304697464083
Validation loss: 2.4849484226201413

Epoch: 336| Step: 0
Training loss: 1.6095807582838906
Validation loss: 2.5017452198597416

Epoch: 6| Step: 1
Training loss: 2.1372103221537664
Validation loss: 2.5197062286694973

Epoch: 6| Step: 2
Training loss: 1.783848924466712
Validation loss: 2.512565929094952

Epoch: 6| Step: 3
Training loss: 1.6795624442454866
Validation loss: 2.537168762921046

Epoch: 6| Step: 4
Training loss: 1.4565726778157269
Validation loss: 2.543417709870276

Epoch: 6| Step: 5
Training loss: 1.7816389228128515
Validation loss: 2.542321131133315

Epoch: 6| Step: 6
Training loss: 2.0645754226651065
Validation loss: 2.5462144349497

Epoch: 6| Step: 7
Training loss: 1.8577093148671866
Validation loss: 2.529770773774454

Epoch: 6| Step: 8
Training loss: 2.247003148951444
Validation loss: 2.5874475756088153

Epoch: 6| Step: 9
Training loss: 1.8081614428743122
Validation loss: 2.5750877480510224

Epoch: 6| Step: 10
Training loss: 1.8452154897954678
Validation loss: 2.598483305324929

Epoch: 6| Step: 11
Training loss: 1.642293535723702
Validation loss: 2.5784859273822156

Epoch: 6| Step: 12
Training loss: 1.52043238889483
Validation loss: 2.5602742835486976

Epoch: 6| Step: 13
Training loss: 1.620776336112315
Validation loss: 2.550487777626188

Epoch: 337| Step: 0
Training loss: 1.1604822901599323
Validation loss: 2.508515404721013

Epoch: 6| Step: 1
Training loss: 1.610028624902101
Validation loss: 2.4861079078854265

Epoch: 6| Step: 2
Training loss: 0.6013811506909508
Validation loss: 2.4833918761197724

Epoch: 6| Step: 3
Training loss: 1.7217885295112305
Validation loss: 2.4912434292735184

Epoch: 6| Step: 4
Training loss: 2.025723612973509
Validation loss: 2.508851021422399

Epoch: 6| Step: 5
Training loss: 1.6986583969647508
Validation loss: 2.510617891754484

Epoch: 6| Step: 6
Training loss: 1.915174511559979
Validation loss: 2.5448855364114564

Epoch: 6| Step: 7
Training loss: 1.5140517416494066
Validation loss: 2.580594131550987

Epoch: 6| Step: 8
Training loss: 2.080171882056607
Validation loss: 2.597655651935339

Epoch: 6| Step: 9
Training loss: 2.331740062431917
Validation loss: 2.6271847922050933

Epoch: 6| Step: 10
Training loss: 1.8341761804611545
Validation loss: 2.5878571355645277

Epoch: 6| Step: 11
Training loss: 1.9339449476870338
Validation loss: 2.5878456896585695

Epoch: 6| Step: 12
Training loss: 1.9582049415651483
Validation loss: 2.585877086723218

Epoch: 6| Step: 13
Training loss: 2.19248601250009
Validation loss: 2.578594603765643

Epoch: 338| Step: 0
Training loss: 1.5987211749451171
Validation loss: 2.544820664500322

Epoch: 6| Step: 1
Training loss: 1.9441183323853444
Validation loss: 2.5466753294234286

Epoch: 6| Step: 2
Training loss: 1.6349954568875624
Validation loss: 2.5285443818020554

Epoch: 6| Step: 3
Training loss: 2.147364789016849
Validation loss: 2.526480342188665

Epoch: 6| Step: 4
Training loss: 1.985615140021713
Validation loss: 2.51886993324601

Epoch: 6| Step: 5
Training loss: 1.6968625624957832
Validation loss: 2.5077434319825738

Epoch: 6| Step: 6
Training loss: 1.718664271210707
Validation loss: 2.503868729474372

Epoch: 6| Step: 7
Training loss: 1.5276496756436473
Validation loss: 2.4968109463931647

Epoch: 6| Step: 8
Training loss: 1.764948487435132
Validation loss: 2.538284907133546

Epoch: 6| Step: 9
Training loss: 1.8968284286991122
Validation loss: 2.541871342183664

Epoch: 6| Step: 10
Training loss: 1.622128958104124
Validation loss: 2.56919181163409

Epoch: 6| Step: 11
Training loss: 1.585618010412681
Validation loss: 2.616473422515273

Epoch: 6| Step: 12
Training loss: 1.951887181000043
Validation loss: 2.6185707312277082

Epoch: 6| Step: 13
Training loss: 1.893362160427405
Validation loss: 2.653619338712242

Epoch: 339| Step: 0
Training loss: 1.601199299637248
Validation loss: 2.626131301295588

Epoch: 6| Step: 1
Training loss: 1.8640332893583365
Validation loss: 2.6155015795344094

Epoch: 6| Step: 2
Training loss: 1.8781312863059052
Validation loss: 2.5899145770939174

Epoch: 6| Step: 3
Training loss: 1.7858496056101791
Validation loss: 2.585397588938716

Epoch: 6| Step: 4
Training loss: 1.8520250346302274
Validation loss: 2.5430857255623223

Epoch: 6| Step: 5
Training loss: 1.767736944155521
Validation loss: 2.536142703106975

Epoch: 6| Step: 6
Training loss: 1.678619471039296
Validation loss: 2.515519789300244

Epoch: 6| Step: 7
Training loss: 1.9399556011349848
Validation loss: 2.5172444713266784

Epoch: 6| Step: 8
Training loss: 1.7568732570991026
Validation loss: 2.51084132315952

Epoch: 6| Step: 9
Training loss: 1.7160993076746083
Validation loss: 2.5191250684094606

Epoch: 6| Step: 10
Training loss: 1.6746579831656505
Validation loss: 2.5451496953375323

Epoch: 6| Step: 11
Training loss: 1.9766401192724876
Validation loss: 2.5348933646251046

Epoch: 6| Step: 12
Training loss: 1.7571453947897386
Validation loss: 2.542586646436762

Epoch: 6| Step: 13
Training loss: 1.4985970452966177
Validation loss: 2.528599514982745

Epoch: 340| Step: 0
Training loss: 0.9150033005409957
Validation loss: 2.4870535121002586

Epoch: 6| Step: 1
Training loss: 1.8998164439629301
Validation loss: 2.5379016034070565

Epoch: 6| Step: 2
Training loss: 1.3315443116570511
Validation loss: 2.5695743806934783

Epoch: 6| Step: 3
Training loss: 2.1792608684458266
Validation loss: 2.558154377382289

Epoch: 6| Step: 4
Training loss: 1.4908424426774782
Validation loss: 2.602589928203952

Epoch: 6| Step: 5
Training loss: 1.3736502785279412
Validation loss: 2.5912939017703276

Epoch: 6| Step: 6
Training loss: 2.1818692353084206
Validation loss: 2.570127260392957

Epoch: 6| Step: 7
Training loss: 2.167544431659987
Validation loss: 2.614712031054014

Epoch: 6| Step: 8
Training loss: 1.6555573076556078
Validation loss: 2.629611460628434

Epoch: 6| Step: 9
Training loss: 1.573022278867414
Validation loss: 2.603726240426018

Epoch: 6| Step: 10
Training loss: 2.0680673769557565
Validation loss: 2.583478170999483

Epoch: 6| Step: 11
Training loss: 1.585513053433696
Validation loss: 2.5447401103779748

Epoch: 6| Step: 12
Training loss: 1.9202003936697245
Validation loss: 2.5480167721779594

Epoch: 6| Step: 13
Training loss: 1.9035963129437918
Validation loss: 2.5295289038699313

Epoch: 341| Step: 0
Training loss: 1.5694650669299641
Validation loss: 2.5231502847883127

Epoch: 6| Step: 1
Training loss: 2.0975417917518953
Validation loss: 2.5119797691815706

Epoch: 6| Step: 2
Training loss: 1.8262306897489118
Validation loss: 2.514291437224871

Epoch: 6| Step: 3
Training loss: 1.7390003559974276
Validation loss: 2.523513127884598

Epoch: 6| Step: 4
Training loss: 1.40814373933435
Validation loss: 2.5267987934002702

Epoch: 6| Step: 5
Training loss: 1.9141651359599592
Validation loss: 2.5089509143682482

Epoch: 6| Step: 6
Training loss: 1.201938142828784
Validation loss: 2.5150070741034862

Epoch: 6| Step: 7
Training loss: 1.7631725056335787
Validation loss: 2.543516983050969

Epoch: 6| Step: 8
Training loss: 1.4845495824040256
Validation loss: 2.5253789416556365

Epoch: 6| Step: 9
Training loss: 1.7842028052090846
Validation loss: 2.5571518679706746

Epoch: 6| Step: 10
Training loss: 1.7661117287930348
Validation loss: 2.532204572952462

Epoch: 6| Step: 11
Training loss: 1.8936785165117958
Validation loss: 2.532376199742185

Epoch: 6| Step: 12
Training loss: 2.0180568957895004
Validation loss: 2.5234449569290747

Epoch: 6| Step: 13
Training loss: 1.8992578437324854
Validation loss: 2.518919824039396

Epoch: 342| Step: 0
Training loss: 1.6900354341031345
Validation loss: 2.5479353350738227

Epoch: 6| Step: 1
Training loss: 1.449568631692567
Validation loss: 2.541085900239965

Epoch: 6| Step: 2
Training loss: 1.8119562583089985
Validation loss: 2.5657474320689846

Epoch: 6| Step: 3
Training loss: 2.256251022888121
Validation loss: 2.5592663318441917

Epoch: 6| Step: 4
Training loss: 1.6264138306789133
Validation loss: 2.5723696439334254

Epoch: 6| Step: 5
Training loss: 1.0860552278002884
Validation loss: 2.5718701041606673

Epoch: 6| Step: 6
Training loss: 1.3829329702196504
Validation loss: 2.5882376667728226

Epoch: 6| Step: 7
Training loss: 1.757824842621598
Validation loss: 2.5753547359996216

Epoch: 6| Step: 8
Training loss: 2.295009140628073
Validation loss: 2.5792008338873185

Epoch: 6| Step: 9
Training loss: 1.8519940738459577
Validation loss: 2.5880756283410773

Epoch: 6| Step: 10
Training loss: 1.476414748777082
Validation loss: 2.5849529241299947

Epoch: 6| Step: 11
Training loss: 1.4103549806674667
Validation loss: 2.566265403074331

Epoch: 6| Step: 12
Training loss: 2.175869349231878
Validation loss: 2.561341616894748

Epoch: 6| Step: 13
Training loss: 1.6981007372850103
Validation loss: 2.523184724500627

Epoch: 343| Step: 0
Training loss: 1.75456867579988
Validation loss: 2.5760703383070993

Epoch: 6| Step: 1
Training loss: 1.6687072977038713
Validation loss: 2.60551484500394

Epoch: 6| Step: 2
Training loss: 1.783565087574771
Validation loss: 2.625237813042085

Epoch: 6| Step: 3
Training loss: 1.6902104262543527
Validation loss: 2.6345633450235924

Epoch: 6| Step: 4
Training loss: 1.8139748985042667
Validation loss: 2.612976180018642

Epoch: 6| Step: 5
Training loss: 1.8546287160940182
Validation loss: 2.5919129841540447

Epoch: 6| Step: 6
Training loss: 1.621539907071994
Validation loss: 2.563239633388161

Epoch: 6| Step: 7
Training loss: 1.4466272920679195
Validation loss: 2.525787225680819

Epoch: 6| Step: 8
Training loss: 1.526378902456243
Validation loss: 2.5342910205035962

Epoch: 6| Step: 9
Training loss: 1.734894270959672
Validation loss: 2.51073888127689

Epoch: 6| Step: 10
Training loss: 2.1642115572608187
Validation loss: 2.476285718742736

Epoch: 6| Step: 11
Training loss: 2.064802560673293
Validation loss: 2.5095657559527855

Epoch: 6| Step: 12
Training loss: 1.5650499517494474
Validation loss: 2.5365805354643087

Epoch: 6| Step: 13
Training loss: 1.5385760007973257
Validation loss: 2.5482382307709455

Epoch: 344| Step: 0
Training loss: 1.491735100197544
Validation loss: 2.566152923768066

Epoch: 6| Step: 1
Training loss: 1.6782940429563595
Validation loss: 2.545618496829204

Epoch: 6| Step: 2
Training loss: 1.250254176046853
Validation loss: 2.5220963065101163

Epoch: 6| Step: 3
Training loss: 2.014033199123801
Validation loss: 2.5286963325048006

Epoch: 6| Step: 4
Training loss: 1.5925860923360078
Validation loss: 2.5501889299580425

Epoch: 6| Step: 5
Training loss: 2.1399535079611782
Validation loss: 2.543369804527999

Epoch: 6| Step: 6
Training loss: 1.8165042973789631
Validation loss: 2.5719809250225456

Epoch: 6| Step: 7
Training loss: 1.87104437330873
Validation loss: 2.562358133954552

Epoch: 6| Step: 8
Training loss: 1.7419158313182692
Validation loss: 2.5797517190625494

Epoch: 6| Step: 9
Training loss: 1.7176635082434712
Validation loss: 2.5635432619010876

Epoch: 6| Step: 10
Training loss: 1.660860374576349
Validation loss: 2.5788840048259885

Epoch: 6| Step: 11
Training loss: 1.6675974233783555
Validation loss: 2.584714374662312

Epoch: 6| Step: 12
Training loss: 1.5408753692658694
Validation loss: 2.591894247714827

Epoch: 6| Step: 13
Training loss: 2.033540109636995
Validation loss: 2.579131180706009

Epoch: 345| Step: 0
Training loss: 1.864671552336403
Validation loss: 2.5736246505394824

Epoch: 6| Step: 1
Training loss: 2.0268010642428904
Validation loss: 2.573375102251484

Epoch: 6| Step: 2
Training loss: 1.4851920037779416
Validation loss: 2.556469074843205

Epoch: 6| Step: 3
Training loss: 1.3160740917213618
Validation loss: 2.557008174243967

Epoch: 6| Step: 4
Training loss: 1.668502114847619
Validation loss: 2.5396138405258153

Epoch: 6| Step: 5
Training loss: 1.8721527097395674
Validation loss: 2.53723982067082

Epoch: 6| Step: 6
Training loss: 1.4243081203424994
Validation loss: 2.5352706485194534

Epoch: 6| Step: 7
Training loss: 1.8824519528441743
Validation loss: 2.5314428513506257

Epoch: 6| Step: 8
Training loss: 1.6778049298728648
Validation loss: 2.5091402902990256

Epoch: 6| Step: 9
Training loss: 2.2782561632029266
Validation loss: 2.508966557022681

Epoch: 6| Step: 10
Training loss: 1.6717724634974258
Validation loss: 2.5485368474744723

Epoch: 6| Step: 11
Training loss: 1.5125887631939248
Validation loss: 2.5534305049682513

Epoch: 6| Step: 12
Training loss: 1.6973444982887156
Validation loss: 2.5900772012523614

Epoch: 6| Step: 13
Training loss: 1.8985868795517187
Validation loss: 2.5759546575702754

Epoch: 346| Step: 0
Training loss: 1.6306036651607567
Validation loss: 2.5967460809907026

Epoch: 6| Step: 1
Training loss: 1.8189655608806676
Validation loss: 2.644717635207657

Epoch: 6| Step: 2
Training loss: 1.589370694651531
Validation loss: 2.642295437686879

Epoch: 6| Step: 3
Training loss: 1.594100838734666
Validation loss: 2.6345771218527907

Epoch: 6| Step: 4
Training loss: 1.254907321319514
Validation loss: 2.6480190081857033

Epoch: 6| Step: 5
Training loss: 2.075291817608999
Validation loss: 2.651219729211035

Epoch: 6| Step: 6
Training loss: 1.3719601407058248
Validation loss: 2.5974686799081805

Epoch: 6| Step: 7
Training loss: 1.9959328543658383
Validation loss: 2.5451701054697953

Epoch: 6| Step: 8
Training loss: 1.9791290748104662
Validation loss: 2.5365190355743557

Epoch: 6| Step: 9
Training loss: 2.1676405649683907
Validation loss: 2.5042127441793847

Epoch: 6| Step: 10
Training loss: 1.415918386343393
Validation loss: 2.5191263249784672

Epoch: 6| Step: 11
Training loss: 1.6582054973895353
Validation loss: 2.552894730169153

Epoch: 6| Step: 12
Training loss: 1.7794091600650312
Validation loss: 2.5790555297035156

Epoch: 6| Step: 13
Training loss: 1.8784394824484476
Validation loss: 2.5752465510488487

Epoch: 347| Step: 0
Training loss: 1.5887381343563531
Validation loss: 2.569916130907309

Epoch: 6| Step: 1
Training loss: 1.9353619746052164
Validation loss: 2.5756087746285177

Epoch: 6| Step: 2
Training loss: 1.4142541070601662
Validation loss: 2.570284901675976

Epoch: 6| Step: 3
Training loss: 1.5269715619090312
Validation loss: 2.612198002419048

Epoch: 6| Step: 4
Training loss: 2.0055795565384535
Validation loss: 2.654339221191371

Epoch: 6| Step: 5
Training loss: 2.2336975351073667
Validation loss: 2.633706317306154

Epoch: 6| Step: 6
Training loss: 1.2351371247308647
Validation loss: 2.6042898576372804

Epoch: 6| Step: 7
Training loss: 1.907899236933391
Validation loss: 2.555146359433627

Epoch: 6| Step: 8
Training loss: 1.7914045570921187
Validation loss: 2.548587015550764

Epoch: 6| Step: 9
Training loss: 1.5617036697552693
Validation loss: 2.5546044385746787

Epoch: 6| Step: 10
Training loss: 2.0183028537875414
Validation loss: 2.5279485891663582

Epoch: 6| Step: 11
Training loss: 1.5664789273341995
Validation loss: 2.5149961987698313

Epoch: 6| Step: 12
Training loss: 1.5742912938367988
Validation loss: 2.546132432229397

Epoch: 6| Step: 13
Training loss: 1.8423441036529111
Validation loss: 2.5420864890874273

Epoch: 348| Step: 0
Training loss: 1.6846525398862708
Validation loss: 2.5445349959596584

Epoch: 6| Step: 1
Training loss: 1.5355081324807598
Validation loss: 2.587130643173189

Epoch: 6| Step: 2
Training loss: 1.6128172865399115
Validation loss: 2.6093246271376342

Epoch: 6| Step: 3
Training loss: 1.6912155220030396
Validation loss: 2.600382022069252

Epoch: 6| Step: 4
Training loss: 1.3844157262456143
Validation loss: 2.612377805502131

Epoch: 6| Step: 5
Training loss: 1.9559741182155632
Validation loss: 2.5965938799136983

Epoch: 6| Step: 6
Training loss: 1.8635343303788336
Validation loss: 2.5927835189165727

Epoch: 6| Step: 7
Training loss: 1.6455393258990938
Validation loss: 2.590161045271844

Epoch: 6| Step: 8
Training loss: 1.874481638145107
Validation loss: 2.5614062630529766

Epoch: 6| Step: 9
Training loss: 1.289228347744444
Validation loss: 2.549341482741147

Epoch: 6| Step: 10
Training loss: 1.3333635128102543
Validation loss: 2.5331702352972134

Epoch: 6| Step: 11
Training loss: 1.7735795959816607
Validation loss: 2.515795971504892

Epoch: 6| Step: 12
Training loss: 2.040570983639143
Validation loss: 2.5461318703923084

Epoch: 6| Step: 13
Training loss: 2.2092109112054485
Validation loss: 2.558079562184132

Epoch: 349| Step: 0
Training loss: 1.5914307717413023
Validation loss: 2.559666361198403

Epoch: 6| Step: 1
Training loss: 1.7791071936191278
Validation loss: 2.5842370087797835

Epoch: 6| Step: 2
Training loss: 1.2648494840495508
Validation loss: 2.6109978179190447

Epoch: 6| Step: 3
Training loss: 1.5843350437400399
Validation loss: 2.6274402836867434

Epoch: 6| Step: 4
Training loss: 1.8048017721617229
Validation loss: 2.6097066863852962

Epoch: 6| Step: 5
Training loss: 1.2689995694050762
Validation loss: 2.6238766125424404

Epoch: 6| Step: 6
Training loss: 1.7496548721042877
Validation loss: 2.598459964939945

Epoch: 6| Step: 7
Training loss: 1.1036246726920995
Validation loss: 2.594131390289998

Epoch: 6| Step: 8
Training loss: 2.229205894719244
Validation loss: 2.627588174947857

Epoch: 6| Step: 9
Training loss: 1.692992279494787
Validation loss: 2.5928678558067664

Epoch: 6| Step: 10
Training loss: 1.825097274800645
Validation loss: 2.6074499120369

Epoch: 6| Step: 11
Training loss: 1.6315976236534162
Validation loss: 2.575287635724275

Epoch: 6| Step: 12
Training loss: 1.8830029403169257
Validation loss: 2.596451956283084

Epoch: 6| Step: 13
Training loss: 1.9560168410709302
Validation loss: 2.608581982475055

Epoch: 350| Step: 0
Training loss: 1.8949920408539722
Validation loss: 2.6295471185522357

Epoch: 6| Step: 1
Training loss: 1.5617396221130564
Validation loss: 2.6246180805881143

Epoch: 6| Step: 2
Training loss: 1.7525594931393336
Validation loss: 2.6190609662856255

Epoch: 6| Step: 3
Training loss: 1.8779404154375388
Validation loss: 2.584852846153861

Epoch: 6| Step: 4
Training loss: 1.48190455400398
Validation loss: 2.5319715651581975

Epoch: 6| Step: 5
Training loss: 1.9723479077164572
Validation loss: 2.552270746705766

Epoch: 6| Step: 6
Training loss: 1.7822067635886563
Validation loss: 2.512891872046313

Epoch: 6| Step: 7
Training loss: 1.5757705952894545
Validation loss: 2.51327106535568

Epoch: 6| Step: 8
Training loss: 0.9238723518479177
Validation loss: 2.5188095164317668

Epoch: 6| Step: 9
Training loss: 1.936001043993298
Validation loss: 2.5259561016550798

Epoch: 6| Step: 10
Training loss: 1.5946582375423795
Validation loss: 2.5387166873009375

Epoch: 6| Step: 11
Training loss: 1.3387449780538276
Validation loss: 2.5648467020529044

Epoch: 6| Step: 12
Training loss: 1.9286315747121228
Validation loss: 2.558915300852221

Epoch: 6| Step: 13
Training loss: 1.5330240521668586
Validation loss: 2.595350688564389

Epoch: 351| Step: 0
Training loss: 1.6366360081263345
Validation loss: 2.593137606278918

Epoch: 6| Step: 1
Training loss: 1.5180930266894401
Validation loss: 2.5636603946741894

Epoch: 6| Step: 2
Training loss: 1.828818360913337
Validation loss: 2.5862703078533142

Epoch: 6| Step: 3
Training loss: 1.943233558760926
Validation loss: 2.5777071656801698

Epoch: 6| Step: 4
Training loss: 1.5839351547627851
Validation loss: 2.585516091499356

Epoch: 6| Step: 5
Training loss: 1.844675639930428
Validation loss: 2.567963833036441

Epoch: 6| Step: 6
Training loss: 1.7174015651075145
Validation loss: 2.5558489210083284

Epoch: 6| Step: 7
Training loss: 1.498763528465319
Validation loss: 2.5554621503142836

Epoch: 6| Step: 8
Training loss: 1.467079998786486
Validation loss: 2.581257426338544

Epoch: 6| Step: 9
Training loss: 1.2079364629103406
Validation loss: 2.5864862218530487

Epoch: 6| Step: 10
Training loss: 1.8406069846963629
Validation loss: 2.596578651614264

Epoch: 6| Step: 11
Training loss: 1.8643175997771262
Validation loss: 2.5956351324555436

Epoch: 6| Step: 12
Training loss: 1.7437347247367316
Validation loss: 2.60510905353898

Epoch: 6| Step: 13
Training loss: 1.2019963110107075
Validation loss: 2.606263442698419

Epoch: 352| Step: 0
Training loss: 1.5516462628053889
Validation loss: 2.603009643133797

Epoch: 6| Step: 1
Training loss: 1.1080477659760748
Validation loss: 2.6224598780479043

Epoch: 6| Step: 2
Training loss: 1.9507738534147796
Validation loss: 2.579975535726781

Epoch: 6| Step: 3
Training loss: 1.4753888021856294
Validation loss: 2.570876109255205

Epoch: 6| Step: 4
Training loss: 1.3580499088122016
Validation loss: 2.5859947831487693

Epoch: 6| Step: 5
Training loss: 1.7382593046367536
Validation loss: 2.5990573190898845

Epoch: 6| Step: 6
Training loss: 1.7893178166277133
Validation loss: 2.6051196009073023

Epoch: 6| Step: 7
Training loss: 1.3751473781324213
Validation loss: 2.6128696145840964

Epoch: 6| Step: 8
Training loss: 1.848274756496038
Validation loss: 2.612136954978656

Epoch: 6| Step: 9
Training loss: 1.895360014242056
Validation loss: 2.6324443187858275

Epoch: 6| Step: 10
Training loss: 1.752991911652397
Validation loss: 2.6161115261135657

Epoch: 6| Step: 11
Training loss: 2.026957862894046
Validation loss: 2.58642820669199

Epoch: 6| Step: 12
Training loss: 1.358206060020736
Validation loss: 2.588505237582406

Epoch: 6| Step: 13
Training loss: 1.5723603214155266
Validation loss: 2.5780825942384387

Epoch: 353| Step: 0
Training loss: 1.8735635341218058
Validation loss: 2.5847110038688244

Epoch: 6| Step: 1
Training loss: 2.029922755984491
Validation loss: 2.5702125875747504

Epoch: 6| Step: 2
Training loss: 1.532971562678578
Validation loss: 2.5534270953867515

Epoch: 6| Step: 3
Training loss: 1.7468144851602863
Validation loss: 2.5675967852318826

Epoch: 6| Step: 4
Training loss: 1.463698689826222
Validation loss: 2.558675604835927

Epoch: 6| Step: 5
Training loss: 1.3795003934764958
Validation loss: 2.581087498415199

Epoch: 6| Step: 6
Training loss: 1.7988243475759402
Validation loss: 2.570270548834498

Epoch: 6| Step: 7
Training loss: 1.4219855800010193
Validation loss: 2.5889602569948766

Epoch: 6| Step: 8
Training loss: 1.802119421919134
Validation loss: 2.6121198907258654

Epoch: 6| Step: 9
Training loss: 2.078319224982976
Validation loss: 2.5731043101815154

Epoch: 6| Step: 10
Training loss: 1.0987751643887123
Validation loss: 2.5501285918975145

Epoch: 6| Step: 11
Training loss: 1.7717068331672852
Validation loss: 2.539204046123406

Epoch: 6| Step: 12
Training loss: 1.1963332062965029
Validation loss: 2.5449919446653353

Epoch: 6| Step: 13
Training loss: 1.488645974471698
Validation loss: 2.5227068873892295

Epoch: 354| Step: 0
Training loss: 1.3957731129575555
Validation loss: 2.524620287681636

Epoch: 6| Step: 1
Training loss: 1.551626210666984
Validation loss: 2.4913365122466153

Epoch: 6| Step: 2
Training loss: 1.6212008153650288
Validation loss: 2.5242188876770992

Epoch: 6| Step: 3
Training loss: 1.5955312162362267
Validation loss: 2.530627012086096

Epoch: 6| Step: 4
Training loss: 1.876934071264501
Validation loss: 2.564616272102869

Epoch: 6| Step: 5
Training loss: 1.2661190246145766
Validation loss: 2.553553565122465

Epoch: 6| Step: 6
Training loss: 1.9385945089668786
Validation loss: 2.553767738878382

Epoch: 6| Step: 7
Training loss: 1.4758227882173658
Validation loss: 2.6117247426478185

Epoch: 6| Step: 8
Training loss: 1.647155624888902
Validation loss: 2.677735827362798

Epoch: 6| Step: 9
Training loss: 1.7949352243153276
Validation loss: 2.7028265992325142

Epoch: 6| Step: 10
Training loss: 1.9464977897045521
Validation loss: 2.686818413467997

Epoch: 6| Step: 11
Training loss: 1.4892701395493924
Validation loss: 2.647534461518491

Epoch: 6| Step: 12
Training loss: 2.006165775420675
Validation loss: 2.5814119895537964

Epoch: 6| Step: 13
Training loss: 1.1962412299110745
Validation loss: 2.514945887635018

Epoch: 355| Step: 0
Training loss: 2.1095094991118817
Validation loss: 2.49522705272917

Epoch: 6| Step: 1
Training loss: 1.8237850482336575
Validation loss: 2.488321731657155

Epoch: 6| Step: 2
Training loss: 1.6764317385971985
Validation loss: 2.4804967006471212

Epoch: 6| Step: 3
Training loss: 1.7672499209711703
Validation loss: 2.461057756320866

Epoch: 6| Step: 4
Training loss: 1.884082160324498
Validation loss: 2.475599576427039

Epoch: 6| Step: 5
Training loss: 0.9735117141575281
Validation loss: 2.507184463384227

Epoch: 6| Step: 6
Training loss: 1.2327392943177917
Validation loss: 2.5240207928698672

Epoch: 6| Step: 7
Training loss: 1.1395193515555495
Validation loss: 2.5770129856165394

Epoch: 6| Step: 8
Training loss: 1.88097396295547
Validation loss: 2.580527693051526

Epoch: 6| Step: 9
Training loss: 1.5624707028503366
Validation loss: 2.627363542349614

Epoch: 6| Step: 10
Training loss: 1.5849916992210815
Validation loss: 2.6348575178999716

Epoch: 6| Step: 11
Training loss: 1.5327202103233144
Validation loss: 2.612909035294522

Epoch: 6| Step: 12
Training loss: 1.778313273835432
Validation loss: 2.628443619973931

Epoch: 6| Step: 13
Training loss: 1.7844771882039672
Validation loss: 2.596964901918772

Epoch: 356| Step: 0
Training loss: 1.1820780803432378
Validation loss: 2.5871184924782193

Epoch: 6| Step: 1
Training loss: 2.0234571772616463
Validation loss: 2.564309252560118

Epoch: 6| Step: 2
Training loss: 1.3895021684649589
Validation loss: 2.5454913256744294

Epoch: 6| Step: 3
Training loss: 1.5852958997462263
Validation loss: 2.5593438659671044

Epoch: 6| Step: 4
Training loss: 1.524848480201637
Validation loss: 2.5417878790936825

Epoch: 6| Step: 5
Training loss: 2.0666752948375784
Validation loss: 2.5397985499943996

Epoch: 6| Step: 6
Training loss: 1.4418226844877349
Validation loss: 2.534220697451791

Epoch: 6| Step: 7
Training loss: 1.6309399978902166
Validation loss: 2.5209412849544384

Epoch: 6| Step: 8
Training loss: 1.6796265347084756
Validation loss: 2.5187044458797354

Epoch: 6| Step: 9
Training loss: 1.697961802750537
Validation loss: 2.5860918330667455

Epoch: 6| Step: 10
Training loss: 1.6590481998461775
Validation loss: 2.6012664097255653

Epoch: 6| Step: 11
Training loss: 1.611757015600567
Validation loss: 2.6463819013748657

Epoch: 6| Step: 12
Training loss: 1.301801768059467
Validation loss: 2.6809456789831936

Epoch: 6| Step: 13
Training loss: 2.0690146930923263
Validation loss: 2.6892550118871723

Epoch: 357| Step: 0
Training loss: 1.112913479207134
Validation loss: 2.6891669740897273

Epoch: 6| Step: 1
Training loss: 1.8279999910308704
Validation loss: 2.6670930277075025

Epoch: 6| Step: 2
Training loss: 1.795104307050236
Validation loss: 2.6817352852051903

Epoch: 6| Step: 3
Training loss: 1.6923440707571566
Validation loss: 2.642046814610842

Epoch: 6| Step: 4
Training loss: 1.118307978934377
Validation loss: 2.625029009508823

Epoch: 6| Step: 5
Training loss: 1.288235346969339
Validation loss: 2.6281710474938733

Epoch: 6| Step: 6
Training loss: 2.0395570352616885
Validation loss: 2.597248615778375

Epoch: 6| Step: 7
Training loss: 1.5157665697815685
Validation loss: 2.5495643008650055

Epoch: 6| Step: 8
Training loss: 1.5481449655378106
Validation loss: 2.528423066119296

Epoch: 6| Step: 9
Training loss: 1.932449217865638
Validation loss: 2.4985976049177765

Epoch: 6| Step: 10
Training loss: 1.7396550953695784
Validation loss: 2.454807337665475

Epoch: 6| Step: 11
Training loss: 1.4400900850992948
Validation loss: 2.4758819181141023

Epoch: 6| Step: 12
Training loss: 1.4844165996946324
Validation loss: 2.4453895260808234

Epoch: 6| Step: 13
Training loss: 2.148612386347891
Validation loss: 2.4789775484302727

Epoch: 358| Step: 0
Training loss: 1.3259338255145143
Validation loss: 2.529371215827536

Epoch: 6| Step: 1
Training loss: 1.69849761042344
Validation loss: 2.622111341061837

Epoch: 6| Step: 2
Training loss: 1.505946214994634
Validation loss: 2.699253574091668

Epoch: 6| Step: 3
Training loss: 1.362781422100403
Validation loss: 2.7327386669403153

Epoch: 6| Step: 4
Training loss: 2.020745567172501
Validation loss: 2.721417926728893

Epoch: 6| Step: 5
Training loss: 1.6481154430055895
Validation loss: 2.6861825013953733

Epoch: 6| Step: 6
Training loss: 1.3051292904937752
Validation loss: 2.6174891820053428

Epoch: 6| Step: 7
Training loss: 1.8226917091710568
Validation loss: 2.558907256011247

Epoch: 6| Step: 8
Training loss: 1.9115830535806426
Validation loss: 2.522337808728633

Epoch: 6| Step: 9
Training loss: 1.8097628610920442
Validation loss: 2.497882302948194

Epoch: 6| Step: 10
Training loss: 1.8205100021946654
Validation loss: 2.4647107385919678

Epoch: 6| Step: 11
Training loss: 1.7645418338632182
Validation loss: 2.4553811409092727

Epoch: 6| Step: 12
Training loss: 1.2474228996042815
Validation loss: 2.468642712618164

Epoch: 6| Step: 13
Training loss: 1.6631310233401664
Validation loss: 2.5174695503736446

Epoch: 359| Step: 0
Training loss: 1.7779765920267465
Validation loss: 2.5144426077482764

Epoch: 6| Step: 1
Training loss: 2.113103213893235
Validation loss: 2.5372047795720425

Epoch: 6| Step: 2
Training loss: 1.4872075410451635
Validation loss: 2.5419280722826905

Epoch: 6| Step: 3
Training loss: 1.3695158396679166
Validation loss: 2.539184450261006

Epoch: 6| Step: 4
Training loss: 1.461114638090208
Validation loss: 2.5423337722268085

Epoch: 6| Step: 5
Training loss: 1.3313031485966822
Validation loss: 2.5033120591318556

Epoch: 6| Step: 6
Training loss: 1.8326528182067925
Validation loss: 2.5206694021257023

Epoch: 6| Step: 7
Training loss: 1.343299390957218
Validation loss: 2.524342860033732

Epoch: 6| Step: 8
Training loss: 1.6066103401177103
Validation loss: 2.548356729977879

Epoch: 6| Step: 9
Training loss: 1.0382465801664926
Validation loss: 2.5683414509291023

Epoch: 6| Step: 10
Training loss: 2.1241243465613167
Validation loss: 2.611592166835709

Epoch: 6| Step: 11
Training loss: 1.3130255963749677
Validation loss: 2.6286047986774173

Epoch: 6| Step: 12
Training loss: 2.131445478049396
Validation loss: 2.68637691649375

Epoch: 6| Step: 13
Training loss: 1.2121914677507055
Validation loss: 2.6432709630844786

Epoch: 360| Step: 0
Training loss: 1.0503387654001712
Validation loss: 2.638783215916805

Epoch: 6| Step: 1
Training loss: 1.491239556198449
Validation loss: 2.5807894713163333

Epoch: 6| Step: 2
Training loss: 1.4401433110450002
Validation loss: 2.608342981587668

Epoch: 6| Step: 3
Training loss: 2.1015250617454084
Validation loss: 2.569049981322887

Epoch: 6| Step: 4
Training loss: 1.7937063391286416
Validation loss: 2.568554761917354

Epoch: 6| Step: 5
Training loss: 1.3862274159138848
Validation loss: 2.5730578139008027

Epoch: 6| Step: 6
Training loss: 1.766566810245003
Validation loss: 2.556619418006675

Epoch: 6| Step: 7
Training loss: 1.6454269615708434
Validation loss: 2.555278584132388

Epoch: 6| Step: 8
Training loss: 1.3883643473763196
Validation loss: 2.5466097546329975

Epoch: 6| Step: 9
Training loss: 1.6819974407761706
Validation loss: 2.5517168322233057

Epoch: 6| Step: 10
Training loss: 1.6173375746526453
Validation loss: 2.5591809166785784

Epoch: 6| Step: 11
Training loss: 1.5130695153533515
Validation loss: 2.5578738346634338

Epoch: 6| Step: 12
Training loss: 1.6227273454367415
Validation loss: 2.539024232839474

Epoch: 6| Step: 13
Training loss: 1.6804936093700038
Validation loss: 2.5382541053025074

Epoch: 361| Step: 0
Training loss: 1.3651359642698573
Validation loss: 2.5545840476205326

Epoch: 6| Step: 1
Training loss: 1.3923526276382583
Validation loss: 2.5843248287272558

Epoch: 6| Step: 2
Training loss: 1.7768872691404136
Validation loss: 2.5946779830987765

Epoch: 6| Step: 3
Training loss: 1.03165370090782
Validation loss: 2.6194725095825793

Epoch: 6| Step: 4
Training loss: 1.278638550944156
Validation loss: 2.603963804813901

Epoch: 6| Step: 5
Training loss: 1.383248729110236
Validation loss: 2.6290570611863924

Epoch: 6| Step: 6
Training loss: 1.7219668715211134
Validation loss: 2.6226104548462565

Epoch: 6| Step: 7
Training loss: 1.8617452052098065
Validation loss: 2.635274834062707

Epoch: 6| Step: 8
Training loss: 1.42564713356801
Validation loss: 2.571330221375224

Epoch: 6| Step: 9
Training loss: 2.1935915463162945
Validation loss: 2.584189950416322

Epoch: 6| Step: 10
Training loss: 2.138644673771081
Validation loss: 2.55807953111674

Epoch: 6| Step: 11
Training loss: 1.26378337480223
Validation loss: 2.5588374211203835

Epoch: 6| Step: 12
Training loss: 1.4721285332352874
Validation loss: 2.566874791728353

Epoch: 6| Step: 13
Training loss: 1.4814672801652817
Validation loss: 2.5157472344730687

Epoch: 362| Step: 0
Training loss: 1.7925012847597845
Validation loss: 2.5479225446858145

Epoch: 6| Step: 1
Training loss: 1.4492595492066964
Validation loss: 2.5401190738577433

Epoch: 6| Step: 2
Training loss: 1.0094357215403222
Validation loss: 2.5913987269081153

Epoch: 6| Step: 3
Training loss: 1.9648745706920445
Validation loss: 2.5572401057887113

Epoch: 6| Step: 4
Training loss: 1.4346896356306258
Validation loss: 2.587378785496985

Epoch: 6| Step: 5
Training loss: 1.1258176375470785
Validation loss: 2.580768768717622

Epoch: 6| Step: 6
Training loss: 1.4296252127665003
Validation loss: 2.60077544938949

Epoch: 6| Step: 7
Training loss: 1.8467506947777519
Validation loss: 2.570198799384017

Epoch: 6| Step: 8
Training loss: 1.8735884757528798
Validation loss: 2.5829550143233044

Epoch: 6| Step: 9
Training loss: 1.5390761321572666
Validation loss: 2.5694154635938946

Epoch: 6| Step: 10
Training loss: 1.1536165094487867
Validation loss: 2.538157494793595

Epoch: 6| Step: 11
Training loss: 1.380694432099303
Validation loss: 2.5272828977106254

Epoch: 6| Step: 12
Training loss: 2.0028270767688547
Validation loss: 2.5340610180227836

Epoch: 6| Step: 13
Training loss: 1.832089811580686
Validation loss: 2.5376579182184797

Epoch: 363| Step: 0
Training loss: 1.721704129085053
Validation loss: 2.5753471695619483

Epoch: 6| Step: 1
Training loss: 1.718969851217802
Validation loss: 2.591987312369904

Epoch: 6| Step: 2
Training loss: 1.7091528934771312
Validation loss: 2.6326504765778473

Epoch: 6| Step: 3
Training loss: 1.571654244728122
Validation loss: 2.6517643674264026

Epoch: 6| Step: 4
Training loss: 1.5076904247457823
Validation loss: 2.655787870391479

Epoch: 6| Step: 5
Training loss: 1.448511655487371
Validation loss: 2.6872692691156845

Epoch: 6| Step: 6
Training loss: 1.3657706193954284
Validation loss: 2.686243841126154

Epoch: 6| Step: 7
Training loss: 1.6024102177218464
Validation loss: 2.6525185788811143

Epoch: 6| Step: 8
Training loss: 1.4874756402337137
Validation loss: 2.6188327712104225

Epoch: 6| Step: 9
Training loss: 1.7913709514748652
Validation loss: 2.5673656934317517

Epoch: 6| Step: 10
Training loss: 1.4517926086090482
Validation loss: 2.548006086533046

Epoch: 6| Step: 11
Training loss: 1.7246368164091226
Validation loss: 2.545028747113219

Epoch: 6| Step: 12
Training loss: 1.2582553060394348
Validation loss: 2.534196015081965

Epoch: 6| Step: 13
Training loss: 1.7600274267010354
Validation loss: 2.5281554193974967

Epoch: 364| Step: 0
Training loss: 2.003615211336772
Validation loss: 2.5512289897925813

Epoch: 6| Step: 1
Training loss: 1.3500202177441163
Validation loss: 2.557550800660044

Epoch: 6| Step: 2
Training loss: 2.038617549595629
Validation loss: 2.5730223334876587

Epoch: 6| Step: 3
Training loss: 1.600439431524249
Validation loss: 2.5762159511739444

Epoch: 6| Step: 4
Training loss: 1.4922343141891636
Validation loss: 2.568598833060569

Epoch: 6| Step: 5
Training loss: 1.1981070767983826
Validation loss: 2.5668327134667828

Epoch: 6| Step: 6
Training loss: 1.6179036936443278
Validation loss: 2.5929601360888923

Epoch: 6| Step: 7
Training loss: 1.7312967975777869
Validation loss: 2.5967181816160747

Epoch: 6| Step: 8
Training loss: 1.0075837696358338
Validation loss: 2.6152600923055025

Epoch: 6| Step: 9
Training loss: 1.2491749901947002
Validation loss: 2.6225644535720294

Epoch: 6| Step: 10
Training loss: 1.4641125290830597
Validation loss: 2.630655022972092

Epoch: 6| Step: 11
Training loss: 1.5516343544785829
Validation loss: 2.6419307341774516

Epoch: 6| Step: 12
Training loss: 1.3485686378761863
Validation loss: 2.6706309737188683

Epoch: 6| Step: 13
Training loss: 2.0454436677585703
Validation loss: 2.693703082555228

Epoch: 365| Step: 0
Training loss: 1.6763387966318561
Validation loss: 2.684573332062234

Epoch: 6| Step: 1
Training loss: 1.4301790320091512
Validation loss: 2.6158554186579903

Epoch: 6| Step: 2
Training loss: 1.6687137271210648
Validation loss: 2.5710443668529503

Epoch: 6| Step: 3
Training loss: 1.554564351327475
Validation loss: 2.5802750691732474

Epoch: 6| Step: 4
Training loss: 1.4924876924706996
Validation loss: 2.528640100403285

Epoch: 6| Step: 5
Training loss: 1.7345668927135245
Validation loss: 2.5335414647023873

Epoch: 6| Step: 6
Training loss: 1.502412286822744
Validation loss: 2.525408559523806

Epoch: 6| Step: 7
Training loss: 1.1336057319244488
Validation loss: 2.498312977740997

Epoch: 6| Step: 8
Training loss: 1.4806416191691674
Validation loss: 2.5097289469468693

Epoch: 6| Step: 9
Training loss: 1.3005532187983535
Validation loss: 2.524844246707277

Epoch: 6| Step: 10
Training loss: 1.4680981102466601
Validation loss: 2.543780060616434

Epoch: 6| Step: 11
Training loss: 1.7447835286268547
Validation loss: 2.563284725044796

Epoch: 6| Step: 12
Training loss: 1.9764866870921036
Validation loss: 2.561244410879564

Epoch: 6| Step: 13
Training loss: 1.578052179148315
Validation loss: 2.617918996835451

Epoch: 366| Step: 0
Training loss: 1.644803348602048
Validation loss: 2.5940992009332176

Epoch: 6| Step: 1
Training loss: 0.9578822186783075
Validation loss: 2.634434303684021

Epoch: 6| Step: 2
Training loss: 1.0194616769020781
Validation loss: 2.5985621677851785

Epoch: 6| Step: 3
Training loss: 1.259934477616216
Validation loss: 2.6117269993202687

Epoch: 6| Step: 4
Training loss: 1.647899811180646
Validation loss: 2.603170425016141

Epoch: 6| Step: 5
Training loss: 1.803677759448849
Validation loss: 2.588466736711024

Epoch: 6| Step: 6
Training loss: 1.204287772155074
Validation loss: 2.5560824591674063

Epoch: 6| Step: 7
Training loss: 1.8673280160295493
Validation loss: 2.5661048219550806

Epoch: 6| Step: 8
Training loss: 2.3228942687547094
Validation loss: 2.5440946484327416

Epoch: 6| Step: 9
Training loss: 1.809797113228219
Validation loss: 2.530335393138188

Epoch: 6| Step: 10
Training loss: 0.9646118441351079
Validation loss: 2.5320958545119567

Epoch: 6| Step: 11
Training loss: 1.4675723285169664
Validation loss: 2.542260037342989

Epoch: 6| Step: 12
Training loss: 1.6206136337217107
Validation loss: 2.5836399153143006

Epoch: 6| Step: 13
Training loss: 1.6123754438450968
Validation loss: 2.624113218273228

Epoch: 367| Step: 0
Training loss: 1.7756873828063091
Validation loss: 2.624173313020522

Epoch: 6| Step: 1
Training loss: 1.5213372253637876
Validation loss: 2.667632096124638

Epoch: 6| Step: 2
Training loss: 0.7992345247175502
Validation loss: 2.6706825698976107

Epoch: 6| Step: 3
Training loss: 1.911976826236061
Validation loss: 2.7067994117883627

Epoch: 6| Step: 4
Training loss: 1.5480594916531036
Validation loss: 2.6978827169618813

Epoch: 6| Step: 5
Training loss: 1.7677723477547465
Validation loss: 2.7012786330445415

Epoch: 6| Step: 6
Training loss: 1.1282291163534701
Validation loss: 2.6284726894978965

Epoch: 6| Step: 7
Training loss: 1.7201238516640238
Validation loss: 2.6094378971671217

Epoch: 6| Step: 8
Training loss: 1.5102587211722067
Validation loss: 2.5533581628328212

Epoch: 6| Step: 9
Training loss: 1.4078068063093712
Validation loss: 2.5179201240964684

Epoch: 6| Step: 10
Training loss: 1.7542630450788574
Validation loss: 2.4966450380812093

Epoch: 6| Step: 11
Training loss: 1.673239890576003
Validation loss: 2.461233415731867

Epoch: 6| Step: 12
Training loss: 1.6624462893421579
Validation loss: 2.4587515591167493

Epoch: 6| Step: 13
Training loss: 1.3505553975103668
Validation loss: 2.484822224810052

Epoch: 368| Step: 0
Training loss: 1.678879867495531
Validation loss: 2.516875604117775

Epoch: 6| Step: 1
Training loss: 1.5010616995617179
Validation loss: 2.6143565157771302

Epoch: 6| Step: 2
Training loss: 1.3498050531280026
Validation loss: 2.644247097134492

Epoch: 6| Step: 3
Training loss: 1.3937715657024055
Validation loss: 2.696931789801575

Epoch: 6| Step: 4
Training loss: 1.6118321595668743
Validation loss: 2.6928381573291458

Epoch: 6| Step: 5
Training loss: 1.4239652591175054
Validation loss: 2.639701233636232

Epoch: 6| Step: 6
Training loss: 1.214707639864362
Validation loss: 2.551316627585476

Epoch: 6| Step: 7
Training loss: 1.8594918094135622
Validation loss: 2.52850781392685

Epoch: 6| Step: 8
Training loss: 1.0704400759213992
Validation loss: 2.518516333696729

Epoch: 6| Step: 9
Training loss: 2.1755572602669404
Validation loss: 2.513060505701724

Epoch: 6| Step: 10
Training loss: 1.4283565308516935
Validation loss: 2.486166584276479

Epoch: 6| Step: 11
Training loss: 1.5844248054696763
Validation loss: 2.5081118392027673

Epoch: 6| Step: 12
Training loss: 1.7357660162526198
Validation loss: 2.5257862847879013

Epoch: 6| Step: 13
Training loss: 1.8712156889170908
Validation loss: 2.5602187580360702

Epoch: 369| Step: 0
Training loss: 1.2472908703226062
Validation loss: 2.62295473154816

Epoch: 6| Step: 1
Training loss: 1.38412585632193
Validation loss: 2.6649699174287877

Epoch: 6| Step: 2
Training loss: 1.5088375738054767
Validation loss: 2.6937968744490286

Epoch: 6| Step: 3
Training loss: 1.7872243708732436
Validation loss: 2.697419708076408

Epoch: 6| Step: 4
Training loss: 1.5098494769223343
Validation loss: 2.65805876577233

Epoch: 6| Step: 5
Training loss: 1.674148155073349
Validation loss: 2.635362343352094

Epoch: 6| Step: 6
Training loss: 1.742307513426948
Validation loss: 2.622455250222869

Epoch: 6| Step: 7
Training loss: 1.2165155223259074
Validation loss: 2.5589778904541207

Epoch: 6| Step: 8
Training loss: 1.577492237706742
Validation loss: 2.5479598833431822

Epoch: 6| Step: 9
Training loss: 1.4374751213242856
Validation loss: 2.507532448552376

Epoch: 6| Step: 10
Training loss: 1.6447682696903612
Validation loss: 2.5008853083140394

Epoch: 6| Step: 11
Training loss: 2.0589797293289105
Validation loss: 2.5165650762711858

Epoch: 6| Step: 12
Training loss: 1.5055004043299836
Validation loss: 2.523896059135065

Epoch: 6| Step: 13
Training loss: 1.2132520643900946
Validation loss: 2.5462328480455403

Epoch: 370| Step: 0
Training loss: 1.7789301572859297
Validation loss: 2.5895486730165795

Epoch: 6| Step: 1
Training loss: 1.2813034976862365
Validation loss: 2.6175634734579503

Epoch: 6| Step: 2
Training loss: 1.5106469428252618
Validation loss: 2.6343255505415337

Epoch: 6| Step: 3
Training loss: 1.787457675032603
Validation loss: 2.6566688955274524

Epoch: 6| Step: 4
Training loss: 1.3002521252063766
Validation loss: 2.679042895888271

Epoch: 6| Step: 5
Training loss: 1.5406728926636961
Validation loss: 2.657976519556939

Epoch: 6| Step: 6
Training loss: 1.143850651465733
Validation loss: 2.62171428034843

Epoch: 6| Step: 7
Training loss: 1.6671409250062115
Validation loss: 2.6275985218338986

Epoch: 6| Step: 8
Training loss: 1.1698016326198968
Validation loss: 2.619414714610491

Epoch: 6| Step: 9
Training loss: 1.3451155001033048
Validation loss: 2.560595479194019

Epoch: 6| Step: 10
Training loss: 1.5368913546789948
Validation loss: 2.6054033649818646

Epoch: 6| Step: 11
Training loss: 1.7043343546224115
Validation loss: 2.5955456615009287

Epoch: 6| Step: 12
Training loss: 1.9221480260922168
Validation loss: 2.604033369693157

Epoch: 6| Step: 13
Training loss: 1.2029281554264222
Validation loss: 2.605414331312505

Epoch: 371| Step: 0
Training loss: 1.588443148533701
Validation loss: 2.5750360971611377

Epoch: 6| Step: 1
Training loss: 1.5406374545880326
Validation loss: 2.5645251581586814

Epoch: 6| Step: 2
Training loss: 1.3903934843245405
Validation loss: 2.5520512056285196

Epoch: 6| Step: 3
Training loss: 1.7587891980583652
Validation loss: 2.544661008979969

Epoch: 6| Step: 4
Training loss: 1.198653445129192
Validation loss: 2.5242634708562113

Epoch: 6| Step: 5
Training loss: 1.3264398093488137
Validation loss: 2.5165373535552638

Epoch: 6| Step: 6
Training loss: 1.3123315067222026
Validation loss: 2.5579917181269756

Epoch: 6| Step: 7
Training loss: 1.683135994904675
Validation loss: 2.533685735496259

Epoch: 6| Step: 8
Training loss: 1.5836688572932622
Validation loss: 2.5678556067594815

Epoch: 6| Step: 9
Training loss: 1.5689591226595612
Validation loss: 2.591007431834914

Epoch: 6| Step: 10
Training loss: 1.5400492801460348
Validation loss: 2.5860579793189316

Epoch: 6| Step: 11
Training loss: 1.7882304026456342
Validation loss: 2.5809830133592913

Epoch: 6| Step: 12
Training loss: 1.4248090381830423
Validation loss: 2.5704372901968093

Epoch: 6| Step: 13
Training loss: 1.2829113865233976
Validation loss: 2.593527489675781

Epoch: 372| Step: 0
Training loss: 1.1315104927557542
Validation loss: 2.5992137196461385

Epoch: 6| Step: 1
Training loss: 1.451812643747521
Validation loss: 2.604729478295048

Epoch: 6| Step: 2
Training loss: 1.0327296190580146
Validation loss: 2.6130614565114243

Epoch: 6| Step: 3
Training loss: 1.50966597569953
Validation loss: 2.595530824112293

Epoch: 6| Step: 4
Training loss: 2.1883578117184985
Validation loss: 2.606657943419351

Epoch: 6| Step: 5
Training loss: 1.6128527647246451
Validation loss: 2.5559855395951514

Epoch: 6| Step: 6
Training loss: 1.030729682746181
Validation loss: 2.553166024989558

Epoch: 6| Step: 7
Training loss: 1.1765578230604048
Validation loss: 2.583943486146924

Epoch: 6| Step: 8
Training loss: 2.0656797000723555
Validation loss: 2.5612928907351002

Epoch: 6| Step: 9
Training loss: 1.5700011442872754
Validation loss: 2.561147054031897

Epoch: 6| Step: 10
Training loss: 1.4896794357065524
Validation loss: 2.5501911692066495

Epoch: 6| Step: 11
Training loss: 1.6790420356609537
Validation loss: 2.5460636797673852

Epoch: 6| Step: 12
Training loss: 1.3828493964666237
Validation loss: 2.5610190613419

Epoch: 6| Step: 13
Training loss: 0.788473835038709
Validation loss: 2.5726031821158015

Epoch: 373| Step: 0
Training loss: 1.3571474085996786
Validation loss: 2.594646686310033

Epoch: 6| Step: 1
Training loss: 1.0096356365422379
Validation loss: 2.6002796220922315

Epoch: 6| Step: 2
Training loss: 1.4747075938678484
Validation loss: 2.660679865034879

Epoch: 6| Step: 3
Training loss: 1.7185242938182759
Validation loss: 2.696174629939404

Epoch: 6| Step: 4
Training loss: 1.630557387482919
Validation loss: 2.66349543511382

Epoch: 6| Step: 5
Training loss: 1.5155089029109152
Validation loss: 2.620244559356254

Epoch: 6| Step: 6
Training loss: 1.8287348585877385
Validation loss: 2.573232847464036

Epoch: 6| Step: 7
Training loss: 1.5025422487332978
Validation loss: 2.516199177237405

Epoch: 6| Step: 8
Training loss: 1.1425460941356946
Validation loss: 2.4787000987655263

Epoch: 6| Step: 9
Training loss: 1.700271595969607
Validation loss: 2.487045848132676

Epoch: 6| Step: 10
Training loss: 1.268126852411127
Validation loss: 2.4866023254857046

Epoch: 6| Step: 11
Training loss: 1.6313146264147251
Validation loss: 2.5264739961948317

Epoch: 6| Step: 12
Training loss: 1.6733826586430596
Validation loss: 2.5178412522662343

Epoch: 6| Step: 13
Training loss: 1.5004955903560184
Validation loss: 2.567637042791279

Epoch: 374| Step: 0
Training loss: 2.095158800465951
Validation loss: 2.6115499962668745

Epoch: 6| Step: 1
Training loss: 1.0724594969315129
Validation loss: 2.6171013470328552

Epoch: 6| Step: 2
Training loss: 1.463619279896372
Validation loss: 2.6567609417425824

Epoch: 6| Step: 3
Training loss: 1.2633102347611687
Validation loss: 2.6318890871181813

Epoch: 6| Step: 4
Training loss: 1.4683334084437536
Validation loss: 2.6511972829228854

Epoch: 6| Step: 5
Training loss: 1.4059701853096584
Validation loss: 2.6060161300620663

Epoch: 6| Step: 6
Training loss: 1.9240061411333318
Validation loss: 2.6145926142270746

Epoch: 6| Step: 7
Training loss: 1.2561564472341726
Validation loss: 2.582655037785624

Epoch: 6| Step: 8
Training loss: 1.6723992069590126
Validation loss: 2.586502729196624

Epoch: 6| Step: 9
Training loss: 1.6994684847013681
Validation loss: 2.559205288960839

Epoch: 6| Step: 10
Training loss: 1.0590061637187536
Validation loss: 2.546359727449984

Epoch: 6| Step: 11
Training loss: 1.4383773614120294
Validation loss: 2.5237361561437264

Epoch: 6| Step: 12
Training loss: 1.4438853873314417
Validation loss: 2.522645257603291

Epoch: 6| Step: 13
Training loss: 1.3444407705820782
Validation loss: 2.5166950481204995

Epoch: 375| Step: 0
Training loss: 1.6160575125440608
Validation loss: 2.5255520219936654

Epoch: 6| Step: 1
Training loss: 1.505040046057721
Validation loss: 2.5593985535424832

Epoch: 6| Step: 2
Training loss: 1.513424800273662
Validation loss: 2.5747588933537275

Epoch: 6| Step: 3
Training loss: 1.7214211255168599
Validation loss: 2.5405025132628456

Epoch: 6| Step: 4
Training loss: 1.1468061421275437
Validation loss: 2.5768477004416352

Epoch: 6| Step: 5
Training loss: 1.0623456057400325
Validation loss: 2.565668622623136

Epoch: 6| Step: 6
Training loss: 1.8124515921606792
Validation loss: 2.6142616183534306

Epoch: 6| Step: 7
Training loss: 1.2128678226016796
Validation loss: 2.630840705448264

Epoch: 6| Step: 8
Training loss: 1.4837809930149881
Validation loss: 2.654503538570091

Epoch: 6| Step: 9
Training loss: 1.1358217980649665
Validation loss: 2.6256488568464103

Epoch: 6| Step: 10
Training loss: 1.5123163663503587
Validation loss: 2.625279991269245

Epoch: 6| Step: 11
Training loss: 1.7166329957690682
Validation loss: 2.5852995461278794

Epoch: 6| Step: 12
Training loss: 1.596929482801533
Validation loss: 2.547051888709966

Epoch: 6| Step: 13
Training loss: 1.6840009086361787
Validation loss: 2.534013570123699

Epoch: 376| Step: 0
Training loss: 1.0662859055800464
Validation loss: 2.516687769829536

Epoch: 6| Step: 1
Training loss: 1.2678016500782132
Validation loss: 2.551465559207906

Epoch: 6| Step: 2
Training loss: 1.3368086623558946
Validation loss: 2.571971910334173

Epoch: 6| Step: 3
Training loss: 1.657741522820109
Validation loss: 2.5673998026429845

Epoch: 6| Step: 4
Training loss: 1.578756225042084
Validation loss: 2.622879127655334

Epoch: 6| Step: 5
Training loss: 1.34193937164115
Validation loss: 2.6159431664586847

Epoch: 6| Step: 6
Training loss: 1.8125957595258717
Validation loss: 2.6307116198858957

Epoch: 6| Step: 7
Training loss: 1.7302029579931912
Validation loss: 2.6174812035775474

Epoch: 6| Step: 8
Training loss: 1.4360354052883582
Validation loss: 2.636479739982421

Epoch: 6| Step: 9
Training loss: 1.679273758432099
Validation loss: 2.63397520242976

Epoch: 6| Step: 10
Training loss: 1.4950165618183244
Validation loss: 2.6499703249098876

Epoch: 6| Step: 11
Training loss: 1.2165403631485796
Validation loss: 2.6054422561344666

Epoch: 6| Step: 12
Training loss: 1.155390858426742
Validation loss: 2.595684846536706

Epoch: 6| Step: 13
Training loss: 1.7729131116581145
Validation loss: 2.5734453116959712

Epoch: 377| Step: 0
Training loss: 1.5615836699071644
Validation loss: 2.5992701943805323

Epoch: 6| Step: 1
Training loss: 0.9652654676010715
Validation loss: 2.5880230856065802

Epoch: 6| Step: 2
Training loss: 1.841637257590023
Validation loss: 2.5768345461745072

Epoch: 6| Step: 3
Training loss: 1.6027751518564441
Validation loss: 2.610882564364476

Epoch: 6| Step: 4
Training loss: 1.1198993128408863
Validation loss: 2.6110536087094025

Epoch: 6| Step: 5
Training loss: 1.9982133872415975
Validation loss: 2.6139490016412905

Epoch: 6| Step: 6
Training loss: 1.45072648823743
Validation loss: 2.595659734303918

Epoch: 6| Step: 7
Training loss: 1.2934540820205147
Validation loss: 2.5698964659693777

Epoch: 6| Step: 8
Training loss: 1.2126034997241824
Validation loss: 2.5816400941670614

Epoch: 6| Step: 9
Training loss: 1.4117372056676167
Validation loss: 2.578921746635928

Epoch: 6| Step: 10
Training loss: 1.550980792912314
Validation loss: 2.5878679573179246

Epoch: 6| Step: 11
Training loss: 1.4064673785573933
Validation loss: 2.548642663962574

Epoch: 6| Step: 12
Training loss: 1.2559895544377064
Validation loss: 2.5448342980494703

Epoch: 6| Step: 13
Training loss: 1.5494205068389082
Validation loss: 2.525230643046768

Epoch: 378| Step: 0
Training loss: 1.4009509382213945
Validation loss: 2.522328042364083

Epoch: 6| Step: 1
Training loss: 1.3737279903741773
Validation loss: 2.5119451380836577

Epoch: 6| Step: 2
Training loss: 1.5758976845568917
Validation loss: 2.54335161513909

Epoch: 6| Step: 3
Training loss: 1.2183012992223847
Validation loss: 2.525866287853396

Epoch: 6| Step: 4
Training loss: 1.5974240309153667
Validation loss: 2.5768144405702116

Epoch: 6| Step: 5
Training loss: 1.3110596155481413
Validation loss: 2.580593359655458

Epoch: 6| Step: 6
Training loss: 1.2662359576185676
Validation loss: 2.5858305430105677

Epoch: 6| Step: 7
Training loss: 1.4661611914183212
Validation loss: 2.5948958956256156

Epoch: 6| Step: 8
Training loss: 1.7531924420064375
Validation loss: 2.586588330886745

Epoch: 6| Step: 9
Training loss: 1.7625127724259129
Validation loss: 2.625254541059621

Epoch: 6| Step: 10
Training loss: 1.4976025336417342
Validation loss: 2.5964604179703463

Epoch: 6| Step: 11
Training loss: 1.6110170746176071
Validation loss: 2.611516101469372

Epoch: 6| Step: 12
Training loss: 1.3995581883432335
Validation loss: 2.579314737013855

Epoch: 6| Step: 13
Training loss: 0.4705200789116681
Validation loss: 2.5999147187406613

Epoch: 379| Step: 0
Training loss: 1.6329652997667494
Validation loss: 2.5614303779571985

Epoch: 6| Step: 1
Training loss: 1.714530759849746
Validation loss: 2.56298862083639

Epoch: 6| Step: 2
Training loss: 1.0648278932797162
Validation loss: 2.5769983790152424

Epoch: 6| Step: 3
Training loss: 1.1349005036289335
Validation loss: 2.5884865467951346

Epoch: 6| Step: 4
Training loss: 1.5091339803463397
Validation loss: 2.5859827183219113

Epoch: 6| Step: 5
Training loss: 1.4006633413191523
Validation loss: 2.5738380396217395

Epoch: 6| Step: 6
Training loss: 1.9532369963006668
Validation loss: 2.585691519575501

Epoch: 6| Step: 7
Training loss: 1.2138927208446908
Validation loss: 2.6040173382347667

Epoch: 6| Step: 8
Training loss: 1.5449954858115211
Validation loss: 2.606894886616609

Epoch: 6| Step: 9
Training loss: 1.5316957097556732
Validation loss: 2.6126783060972185

Epoch: 6| Step: 10
Training loss: 0.897416969857767
Validation loss: 2.5995225487313913

Epoch: 6| Step: 11
Training loss: 1.3936031897163457
Validation loss: 2.569958860952999

Epoch: 6| Step: 12
Training loss: 1.7764643579112978
Validation loss: 2.5830379407175377

Epoch: 6| Step: 13
Training loss: 0.712140250151345
Validation loss: 2.5748338680992795

Epoch: 380| Step: 0
Training loss: 1.4023335491011297
Validation loss: 2.554551147181852

Epoch: 6| Step: 1
Training loss: 1.6173605711096029
Validation loss: 2.58053933930955

Epoch: 6| Step: 2
Training loss: 1.409097501244325
Validation loss: 2.6135054842716854

Epoch: 6| Step: 3
Training loss: 1.095959964779747
Validation loss: 2.6390113314978474

Epoch: 6| Step: 4
Training loss: 1.347139829014734
Validation loss: 2.655342641008879

Epoch: 6| Step: 5
Training loss: 1.5222749627081216
Validation loss: 2.6472017129502596

Epoch: 6| Step: 6
Training loss: 1.007323272009371
Validation loss: 2.6352683969235575

Epoch: 6| Step: 7
Training loss: 0.87262778923049
Validation loss: 2.5813829228814256

Epoch: 6| Step: 8
Training loss: 1.8118152640404959
Validation loss: 2.5896207268313782

Epoch: 6| Step: 9
Training loss: 1.691622255553529
Validation loss: 2.5746113639294363

Epoch: 6| Step: 10
Training loss: 1.9352776487401007
Validation loss: 2.5382017493110722

Epoch: 6| Step: 11
Training loss: 1.497744931424625
Validation loss: 2.5442647275264587

Epoch: 6| Step: 12
Training loss: 1.3467258503548891
Validation loss: 2.5368982008493908

Epoch: 6| Step: 13
Training loss: 1.293808909010277
Validation loss: 2.530266087829445

Epoch: 381| Step: 0
Training loss: 1.2018077624830343
Validation loss: 2.5354948417029406

Epoch: 6| Step: 1
Training loss: 1.4514570610588713
Validation loss: 2.534026907221005

Epoch: 6| Step: 2
Training loss: 0.8277794458883092
Validation loss: 2.543203643298255

Epoch: 6| Step: 3
Training loss: 1.355396059928955
Validation loss: 2.6058276805962435

Epoch: 6| Step: 4
Training loss: 1.5018646253845809
Validation loss: 2.5941091625599664

Epoch: 6| Step: 5
Training loss: 1.8242566515234202
Validation loss: 2.605761687719831

Epoch: 6| Step: 6
Training loss: 1.9261861688829678
Validation loss: 2.628852082435142

Epoch: 6| Step: 7
Training loss: 1.2643390291747623
Validation loss: 2.5983411607834435

Epoch: 6| Step: 8
Training loss: 1.590896820045807
Validation loss: 2.5798850029810736

Epoch: 6| Step: 9
Training loss: 1.2053704054168415
Validation loss: 2.5525215628197695

Epoch: 6| Step: 10
Training loss: 1.520745427277949
Validation loss: 2.518898413458265

Epoch: 6| Step: 11
Training loss: 1.4631676608925703
Validation loss: 2.512882523978815

Epoch: 6| Step: 12
Training loss: 1.4178935890139448
Validation loss: 2.5059803262367204

Epoch: 6| Step: 13
Training loss: 1.495118064556201
Validation loss: 2.5493355697536084

Epoch: 382| Step: 0
Training loss: 1.5930367912215413
Validation loss: 2.5461726314519857

Epoch: 6| Step: 1
Training loss: 1.6851820390661834
Validation loss: 2.615108643290581

Epoch: 6| Step: 2
Training loss: 1.470733115408446
Validation loss: 2.662508253167261

Epoch: 6| Step: 3
Training loss: 1.4400589598400308
Validation loss: 2.6484246616195737

Epoch: 6| Step: 4
Training loss: 1.3913765922868333
Validation loss: 2.6663361050957555

Epoch: 6| Step: 5
Training loss: 1.7633791793651488
Validation loss: 2.654490851215554

Epoch: 6| Step: 6
Training loss: 1.219388110052713
Validation loss: 2.618122236218808

Epoch: 6| Step: 7
Training loss: 1.1428507683354803
Validation loss: 2.606230794299221

Epoch: 6| Step: 8
Training loss: 1.2359273300041833
Validation loss: 2.5609245879928983

Epoch: 6| Step: 9
Training loss: 1.1554163427635606
Validation loss: 2.5312122953385088

Epoch: 6| Step: 10
Training loss: 1.4485568362624541
Validation loss: 2.5455132961201934

Epoch: 6| Step: 11
Training loss: 1.2442207250755468
Validation loss: 2.510834843704082

Epoch: 6| Step: 12
Training loss: 1.7672852668734769
Validation loss: 2.557375014058616

Epoch: 6| Step: 13
Training loss: 1.4135328955531643
Validation loss: 2.5362103674907166

Epoch: 383| Step: 0
Training loss: 1.3635647104684874
Validation loss: 2.518455756726486

Epoch: 6| Step: 1
Training loss: 1.3512399983278525
Validation loss: 2.5752385482659377

Epoch: 6| Step: 2
Training loss: 1.7559730229923256
Validation loss: 2.558526754234053

Epoch: 6| Step: 3
Training loss: 1.707379547830277
Validation loss: 2.590892479866962

Epoch: 6| Step: 4
Training loss: 1.5530449706552885
Validation loss: 2.6012007101366024

Epoch: 6| Step: 5
Training loss: 1.5690258315557177
Validation loss: 2.6311122462367798

Epoch: 6| Step: 6
Training loss: 0.9753919070552028
Validation loss: 2.6324125842884665

Epoch: 6| Step: 7
Training loss: 1.2048735359911984
Validation loss: 2.600383699034897

Epoch: 6| Step: 8
Training loss: 1.8384591175022889
Validation loss: 2.599850799367245

Epoch: 6| Step: 9
Training loss: 1.267175642868241
Validation loss: 2.5973371145781377

Epoch: 6| Step: 10
Training loss: 1.60788168651724
Validation loss: 2.5552912383766144

Epoch: 6| Step: 11
Training loss: 1.1555585082232418
Validation loss: 2.5686443685883855

Epoch: 6| Step: 12
Training loss: 1.22878253990698
Validation loss: 2.5951381417763506

Epoch: 6| Step: 13
Training loss: 0.6708754489741521
Validation loss: 2.608428190872495

Epoch: 384| Step: 0
Training loss: 1.1781846130021658
Validation loss: 2.607191308196265

Epoch: 6| Step: 1
Training loss: 1.727612413538686
Validation loss: 2.60934211445458

Epoch: 6| Step: 2
Training loss: 1.5090564083530174
Validation loss: 2.617508034935554

Epoch: 6| Step: 3
Training loss: 1.6989049862972974
Validation loss: 2.629399912717041

Epoch: 6| Step: 4
Training loss: 1.0796082838839554
Validation loss: 2.6593830391407214

Epoch: 6| Step: 5
Training loss: 0.5663497370446761
Validation loss: 2.6367963186845973

Epoch: 6| Step: 6
Training loss: 1.7163206097330088
Validation loss: 2.6135611195182147

Epoch: 6| Step: 7
Training loss: 1.9459799115711351
Validation loss: 2.5772030302698554

Epoch: 6| Step: 8
Training loss: 1.3009521555390062
Validation loss: 2.5840954799206624

Epoch: 6| Step: 9
Training loss: 1.3460024208795278
Validation loss: 2.570653707302896

Epoch: 6| Step: 10
Training loss: 1.036425923874307
Validation loss: 2.559443116393772

Epoch: 6| Step: 11
Training loss: 1.2691247846906981
Validation loss: 2.543103269164428

Epoch: 6| Step: 12
Training loss: 1.5910846638094618
Validation loss: 2.5317377055862837

Epoch: 6| Step: 13
Training loss: 1.479489367391083
Validation loss: 2.5371586282515257

Epoch: 385| Step: 0
Training loss: 2.107428889223151
Validation loss: 2.5441623869975354

Epoch: 6| Step: 1
Training loss: 1.4485766692723772
Validation loss: 2.556984939026237

Epoch: 6| Step: 2
Training loss: 1.2663667647967838
Validation loss: 2.5670508555695393

Epoch: 6| Step: 3
Training loss: 1.599492069922319
Validation loss: 2.568123018152316

Epoch: 6| Step: 4
Training loss: 1.0766328630858923
Validation loss: 2.572060329466438

Epoch: 6| Step: 5
Training loss: 1.5760101651381873
Validation loss: 2.579749579507593

Epoch: 6| Step: 6
Training loss: 1.5148236230592231
Validation loss: 2.5762731479709147

Epoch: 6| Step: 7
Training loss: 0.8063787815831417
Validation loss: 2.6025069278810298

Epoch: 6| Step: 8
Training loss: 1.382735169398246
Validation loss: 2.6117631382062596

Epoch: 6| Step: 9
Training loss: 1.4949742204618717
Validation loss: 2.572031657472738

Epoch: 6| Step: 10
Training loss: 1.5575415709505984
Validation loss: 2.564970280936605

Epoch: 6| Step: 11
Training loss: 1.3848860544368997
Validation loss: 2.558412817424107

Epoch: 6| Step: 12
Training loss: 0.8794078158699519
Validation loss: 2.52217250417674

Epoch: 6| Step: 13
Training loss: 1.2358936673384013
Validation loss: 2.502460704361893

Epoch: 386| Step: 0
Training loss: 1.2491798094214357
Validation loss: 2.556519702971053

Epoch: 6| Step: 1
Training loss: 1.4459474560700094
Validation loss: 2.5480813916809524

Epoch: 6| Step: 2
Training loss: 2.0686198674787812
Validation loss: 2.5677265516950767

Epoch: 6| Step: 3
Training loss: 1.5831859001316335
Validation loss: 2.5736876683441605

Epoch: 6| Step: 4
Training loss: 1.6030085292691576
Validation loss: 2.587838450002803

Epoch: 6| Step: 5
Training loss: 1.3700698550715869
Validation loss: 2.602502238963476

Epoch: 6| Step: 6
Training loss: 1.247081831219439
Validation loss: 2.582393990172682

Epoch: 6| Step: 7
Training loss: 0.7570754724268363
Validation loss: 2.56299193067605

Epoch: 6| Step: 8
Training loss: 1.3860961806020453
Validation loss: 2.5770713982615887

Epoch: 6| Step: 9
Training loss: 1.250097604755609
Validation loss: 2.5895224558322156

Epoch: 6| Step: 10
Training loss: 1.2049335906220924
Validation loss: 2.6010542477828427

Epoch: 6| Step: 11
Training loss: 1.3390859345885957
Validation loss: 2.614884580808747

Epoch: 6| Step: 12
Training loss: 1.4209395464951002
Validation loss: 2.6114811597605345

Epoch: 6| Step: 13
Training loss: 1.6121874188406315
Validation loss: 2.6039525926441387

Epoch: 387| Step: 0
Training loss: 0.8580966110701369
Validation loss: 2.615397355800729

Epoch: 6| Step: 1
Training loss: 1.7217834060594241
Validation loss: 2.6170792820681905

Epoch: 6| Step: 2
Training loss: 1.422937520192243
Validation loss: 2.6580058983199293

Epoch: 6| Step: 3
Training loss: 1.5005790864211364
Validation loss: 2.628925515464037

Epoch: 6| Step: 4
Training loss: 1.7848078348065626
Validation loss: 2.5970352278016957

Epoch: 6| Step: 5
Training loss: 1.1909952424064054
Validation loss: 2.59114776988871

Epoch: 6| Step: 6
Training loss: 1.2121076283271737
Validation loss: 2.5754029283403117

Epoch: 6| Step: 7
Training loss: 1.1647795446496634
Validation loss: 2.5490679032060224

Epoch: 6| Step: 8
Training loss: 2.09404854994549
Validation loss: 2.5281650070897963

Epoch: 6| Step: 9
Training loss: 1.473398522420727
Validation loss: 2.530309202755057

Epoch: 6| Step: 10
Training loss: 1.272805788587694
Validation loss: 2.5190609072493935

Epoch: 6| Step: 11
Training loss: 1.0831816579326508
Validation loss: 2.5296007305880615

Epoch: 6| Step: 12
Training loss: 0.9923171011317178
Validation loss: 2.5334223443678665

Epoch: 6| Step: 13
Training loss: 1.4673696484096475
Validation loss: 2.5565842604772775

Epoch: 388| Step: 0
Training loss: 1.2733522164274458
Validation loss: 2.5480425355609846

Epoch: 6| Step: 1
Training loss: 1.2561430662581095
Validation loss: 2.5626474533655803

Epoch: 6| Step: 2
Training loss: 1.5912473139474257
Validation loss: 2.579520953909591

Epoch: 6| Step: 3
Training loss: 1.837991288090794
Validation loss: 2.603625093977081

Epoch: 6| Step: 4
Training loss: 1.1068744147206013
Validation loss: 2.622636787986291

Epoch: 6| Step: 5
Training loss: 2.0760469300362385
Validation loss: 2.6760150502787488

Epoch: 6| Step: 6
Training loss: 1.4961331115803629
Validation loss: 2.6732478610752883

Epoch: 6| Step: 7
Training loss: 1.377129812605628
Validation loss: 2.637856202886715

Epoch: 6| Step: 8
Training loss: 1.1927868457700808
Validation loss: 2.642730231937305

Epoch: 6| Step: 9
Training loss: 0.9850553250629662
Validation loss: 2.6065150688410617

Epoch: 6| Step: 10
Training loss: 1.2182537437896537
Validation loss: 2.5677477737835908

Epoch: 6| Step: 11
Training loss: 1.2561075727658604
Validation loss: 2.550703307852365

Epoch: 6| Step: 12
Training loss: 1.0959416910031006
Validation loss: 2.561482363249541

Epoch: 6| Step: 13
Training loss: 1.2163340268410563
Validation loss: 2.5147166950198208

Epoch: 389| Step: 0
Training loss: 1.581642159545787
Validation loss: 2.514454611072221

Epoch: 6| Step: 1
Training loss: 1.1491653315863946
Validation loss: 2.514187295415696

Epoch: 6| Step: 2
Training loss: 1.2912643123841652
Validation loss: 2.5570452799726295

Epoch: 6| Step: 3
Training loss: 1.3399942830661264
Validation loss: 2.565741278618497

Epoch: 6| Step: 4
Training loss: 1.3531605528638433
Validation loss: 2.5624562821759556

Epoch: 6| Step: 5
Training loss: 1.300801778178859
Validation loss: 2.5278898415855533

Epoch: 6| Step: 6
Training loss: 1.496215098267971
Validation loss: 2.5549332374240206

Epoch: 6| Step: 7
Training loss: 1.2198374860428527
Validation loss: 2.601497033556312

Epoch: 6| Step: 8
Training loss: 1.7017540970079519
Validation loss: 2.6048174448979395

Epoch: 6| Step: 9
Training loss: 1.3270494481685757
Validation loss: 2.5855710226849618

Epoch: 6| Step: 10
Training loss: 1.5305198952977854
Validation loss: 2.5877915225147294

Epoch: 6| Step: 11
Training loss: 1.6595017523048026
Validation loss: 2.574312654809382

Epoch: 6| Step: 12
Training loss: 1.1788149000082435
Validation loss: 2.576068497232809

Epoch: 6| Step: 13
Training loss: 1.2635637617367654
Validation loss: 2.6175804258308415

Epoch: 390| Step: 0
Training loss: 1.2857529202968982
Validation loss: 2.628464436690333

Epoch: 6| Step: 1
Training loss: 1.361849669894487
Validation loss: 2.6549501803742133

Epoch: 6| Step: 2
Training loss: 1.4098293950642595
Validation loss: 2.646714812096276

Epoch: 6| Step: 3
Training loss: 1.2669570412251543
Validation loss: 2.6113945819416826

Epoch: 6| Step: 4
Training loss: 1.536608836243612
Validation loss: 2.6204941875354177

Epoch: 6| Step: 5
Training loss: 1.6828627271603516
Validation loss: 2.6152374687361246

Epoch: 6| Step: 6
Training loss: 1.4015790294068018
Validation loss: 2.5979936243559227

Epoch: 6| Step: 7
Training loss: 0.9962130007699845
Validation loss: 2.544288718738962

Epoch: 6| Step: 8
Training loss: 1.5547018385949578
Validation loss: 2.5635159287171922

Epoch: 6| Step: 9
Training loss: 1.195425439622682
Validation loss: 2.5329371589504137

Epoch: 6| Step: 10
Training loss: 1.5535607016557957
Validation loss: 2.52817913201138

Epoch: 6| Step: 11
Training loss: 1.3209955829803524
Validation loss: 2.5364779000581357

Epoch: 6| Step: 12
Training loss: 1.5001730024389535
Validation loss: 2.530115126101695

Epoch: 6| Step: 13
Training loss: 1.2525478146805067
Validation loss: 2.5410914682206323

Epoch: 391| Step: 0
Training loss: 1.3637396798586898
Validation loss: 2.573086695146866

Epoch: 6| Step: 1
Training loss: 1.4494201849193982
Validation loss: 2.5837452871301267

Epoch: 6| Step: 2
Training loss: 1.4747805868631536
Validation loss: 2.6245082447346664

Epoch: 6| Step: 3
Training loss: 1.059091317332647
Validation loss: 2.671829739455747

Epoch: 6| Step: 4
Training loss: 1.5322690414462976
Validation loss: 2.684926079885368

Epoch: 6| Step: 5
Training loss: 1.3271331673951352
Validation loss: 2.674578785080704

Epoch: 6| Step: 6
Training loss: 1.1695058143311359
Validation loss: 2.6209100737431466

Epoch: 6| Step: 7
Training loss: 1.2770802637325733
Validation loss: 2.554545940716839

Epoch: 6| Step: 8
Training loss: 1.529261485112946
Validation loss: 2.543281402000723

Epoch: 6| Step: 9
Training loss: 1.881845439576101
Validation loss: 2.5171256970259437

Epoch: 6| Step: 10
Training loss: 1.7788402251939854
Validation loss: 2.499745708781666

Epoch: 6| Step: 11
Training loss: 0.9865727791599598
Validation loss: 2.4707511402052575

Epoch: 6| Step: 12
Training loss: 0.9449491827284406
Validation loss: 2.4847080747574184

Epoch: 6| Step: 13
Training loss: 1.2353878453169813
Validation loss: 2.515268268793235

Epoch: 392| Step: 0
Training loss: 1.3667283513329487
Validation loss: 2.5215170455227667

Epoch: 6| Step: 1
Training loss: 1.9561939999301063
Validation loss: 2.5404146951569753

Epoch: 6| Step: 2
Training loss: 1.7601460882808717
Validation loss: 2.575341058460222

Epoch: 6| Step: 3
Training loss: 1.3506387629904402
Validation loss: 2.5994030435957662

Epoch: 6| Step: 4
Training loss: 1.2699470660674812
Validation loss: 2.6309928390931123

Epoch: 6| Step: 5
Training loss: 1.6058239323503012
Validation loss: 2.6330077615389085

Epoch: 6| Step: 6
Training loss: 1.3813535677371078
Validation loss: 2.642831465822511

Epoch: 6| Step: 7
Training loss: 1.6111601770902404
Validation loss: 2.6004748825369823

Epoch: 6| Step: 8
Training loss: 1.0842877487567042
Validation loss: 2.6187634487043185

Epoch: 6| Step: 9
Training loss: 0.7598133611514951
Validation loss: 2.5753550764439987

Epoch: 6| Step: 10
Training loss: 1.0460373673119265
Validation loss: 2.5794234808476086

Epoch: 6| Step: 11
Training loss: 0.9994741487733247
Validation loss: 2.582156746661445

Epoch: 6| Step: 12
Training loss: 1.2259681865460101
Validation loss: 2.569607242421841

Epoch: 6| Step: 13
Training loss: 1.2151475630738229
Validation loss: 2.5672914192787077

Epoch: 393| Step: 0
Training loss: 0.9774057943408488
Validation loss: 2.5531176599216887

Epoch: 6| Step: 1
Training loss: 1.3673616570856466
Validation loss: 2.5517320871303397

Epoch: 6| Step: 2
Training loss: 1.3742035379700968
Validation loss: 2.579327009947747

Epoch: 6| Step: 3
Training loss: 1.857263857179902
Validation loss: 2.591835722051921

Epoch: 6| Step: 4
Training loss: 1.0508137524197498
Validation loss: 2.575098445263742

Epoch: 6| Step: 5
Training loss: 1.296491405333525
Validation loss: 2.615283592025862

Epoch: 6| Step: 6
Training loss: 1.0322379379583992
Validation loss: 2.6084294420143737

Epoch: 6| Step: 7
Training loss: 1.2595162078220425
Validation loss: 2.6200309107107036

Epoch: 6| Step: 8
Training loss: 1.3709280669264103
Validation loss: 2.638501778644688

Epoch: 6| Step: 9
Training loss: 1.6270285928906536
Validation loss: 2.6466243886521967

Epoch: 6| Step: 10
Training loss: 1.094032087734178
Validation loss: 2.6135312244750413

Epoch: 6| Step: 11
Training loss: 1.683633401142707
Validation loss: 2.5644902059798262

Epoch: 6| Step: 12
Training loss: 1.3224315905409878
Validation loss: 2.5455463566761014

Epoch: 6| Step: 13
Training loss: 1.4971091706470339
Validation loss: 2.537096710907316

Epoch: 394| Step: 0
Training loss: 1.3557989064687281
Validation loss: 2.5076742404069856

Epoch: 6| Step: 1
Training loss: 1.5110160515296807
Validation loss: 2.473710461533162

Epoch: 6| Step: 2
Training loss: 1.1384379701197174
Validation loss: 2.499243067931481

Epoch: 6| Step: 3
Training loss: 1.2397285931956992
Validation loss: 2.5061295552894842

Epoch: 6| Step: 4
Training loss: 1.1189459985992944
Validation loss: 2.4957672490512492

Epoch: 6| Step: 5
Training loss: 1.342742719819101
Validation loss: 2.5322341859035347

Epoch: 6| Step: 6
Training loss: 1.322741739717718
Validation loss: 2.5650087466975626

Epoch: 6| Step: 7
Training loss: 1.4002391781176775
Validation loss: 2.60196455223943

Epoch: 6| Step: 8
Training loss: 1.243415657229338
Validation loss: 2.5937659091019256

Epoch: 6| Step: 9
Training loss: 1.831171480650196
Validation loss: 2.6136697950312016

Epoch: 6| Step: 10
Training loss: 1.3172163918291642
Validation loss: 2.6286395956651063

Epoch: 6| Step: 11
Training loss: 1.4685496741502404
Validation loss: 2.6295887577470074

Epoch: 6| Step: 12
Training loss: 1.3393964104091511
Validation loss: 2.6151776323287392

Epoch: 6| Step: 13
Training loss: 0.9641617128832358
Validation loss: 2.6450400808516075

Epoch: 395| Step: 0
Training loss: 1.1343716119552754
Validation loss: 2.5877147813099506

Epoch: 6| Step: 1
Training loss: 1.655629599634321
Validation loss: 2.624457342776447

Epoch: 6| Step: 2
Training loss: 1.0699082885191515
Validation loss: 2.586546255170195

Epoch: 6| Step: 3
Training loss: 1.935484791827239
Validation loss: 2.5271762429058606

Epoch: 6| Step: 4
Training loss: 1.3709114149093247
Validation loss: 2.535738930898437

Epoch: 6| Step: 5
Training loss: 1.4417458731147568
Validation loss: 2.506825268577697

Epoch: 6| Step: 6
Training loss: 1.401894585127808
Validation loss: 2.527482711700246

Epoch: 6| Step: 7
Training loss: 1.1423864480983246
Validation loss: 2.5741452616748215

Epoch: 6| Step: 8
Training loss: 1.171920978915709
Validation loss: 2.567862858825848

Epoch: 6| Step: 9
Training loss: 1.3834845854710793
Validation loss: 2.599507139361823

Epoch: 6| Step: 10
Training loss: 1.361489547725795
Validation loss: 2.621636639945462

Epoch: 6| Step: 11
Training loss: 1.114102833406978
Validation loss: 2.650159427957365

Epoch: 6| Step: 12
Training loss: 1.364511104545544
Validation loss: 2.642112464926278

Epoch: 6| Step: 13
Training loss: 0.7280704068522387
Validation loss: 2.6354430540774914

Epoch: 396| Step: 0
Training loss: 1.2280848100992492
Validation loss: 2.6602945707852452

Epoch: 6| Step: 1
Training loss: 0.5913486608889877
Validation loss: 2.6030541945843373

Epoch: 6| Step: 2
Training loss: 1.1555283846371003
Validation loss: 2.6058562335719766

Epoch: 6| Step: 3
Training loss: 1.3949756929200918
Validation loss: 2.5518661584085356

Epoch: 6| Step: 4
Training loss: 1.2570836105489673
Validation loss: 2.563888395778074

Epoch: 6| Step: 5
Training loss: 1.350975703048488
Validation loss: 2.5545866839324916

Epoch: 6| Step: 6
Training loss: 1.4335475155393635
Validation loss: 2.5485157651806363

Epoch: 6| Step: 7
Training loss: 1.9902029886662795
Validation loss: 2.5520223620734295

Epoch: 6| Step: 8
Training loss: 0.9056610298229363
Validation loss: 2.5546213300573144

Epoch: 6| Step: 9
Training loss: 1.2937310959176607
Validation loss: 2.5735735769352206

Epoch: 6| Step: 10
Training loss: 1.249809632110472
Validation loss: 2.5896962751073476

Epoch: 6| Step: 11
Training loss: 1.4635048405730462
Validation loss: 2.638523667376068

Epoch: 6| Step: 12
Training loss: 1.497232586351585
Validation loss: 2.6349271068043505

Epoch: 6| Step: 13
Training loss: 1.6484584716619917
Validation loss: 2.6437341005414545

Epoch: 397| Step: 0
Training loss: 1.7156168035926347
Validation loss: 2.608209349750699

Epoch: 6| Step: 1
Training loss: 1.1709032225650244
Validation loss: 2.619259773791403

Epoch: 6| Step: 2
Training loss: 1.3845255957125189
Validation loss: 2.5541490861306095

Epoch: 6| Step: 3
Training loss: 0.7195747453463884
Validation loss: 2.542722349813878

Epoch: 6| Step: 4
Training loss: 1.5621698412170897
Validation loss: 2.539966010926533

Epoch: 6| Step: 5
Training loss: 0.9323835309905776
Validation loss: 2.522724729208149

Epoch: 6| Step: 6
Training loss: 1.0597476090145292
Validation loss: 2.548682913869139

Epoch: 6| Step: 7
Training loss: 1.0514699954741678
Validation loss: 2.5528443002883203

Epoch: 6| Step: 8
Training loss: 1.2672449740959078
Validation loss: 2.579972591485089

Epoch: 6| Step: 9
Training loss: 1.418345839956677
Validation loss: 2.5742392114899806

Epoch: 6| Step: 10
Training loss: 1.5744272855925765
Validation loss: 2.583096939634425

Epoch: 6| Step: 11
Training loss: 1.572093504020063
Validation loss: 2.6180020882463677

Epoch: 6| Step: 12
Training loss: 1.4535994216724646
Validation loss: 2.6082840126540803

Epoch: 6| Step: 13
Training loss: 1.3497066655954437
Validation loss: 2.635848320351453

Epoch: 398| Step: 0
Training loss: 1.0327670758252465
Validation loss: 2.6373332652239174

Epoch: 6| Step: 1
Training loss: 1.5715477483318365
Validation loss: 2.6683372675811663

Epoch: 6| Step: 2
Training loss: 1.0972108853769844
Validation loss: 2.6744499701401945

Epoch: 6| Step: 3
Training loss: 1.222065401974287
Validation loss: 2.6361107600239695

Epoch: 6| Step: 4
Training loss: 1.1816294267612457
Validation loss: 2.6664404298837794

Epoch: 6| Step: 5
Training loss: 1.203605654926397
Validation loss: 2.642340599678531

Epoch: 6| Step: 6
Training loss: 1.2857670129833108
Validation loss: 2.6140022594672714

Epoch: 6| Step: 7
Training loss: 1.3796315649494553
Validation loss: 2.5766635316059383

Epoch: 6| Step: 8
Training loss: 1.8913905587819797
Validation loss: 2.5518350915340737

Epoch: 6| Step: 9
Training loss: 1.207599641862799
Validation loss: 2.5837066374384365

Epoch: 6| Step: 10
Training loss: 1.2264263782168983
Validation loss: 2.5626194733731396

Epoch: 6| Step: 11
Training loss: 1.1907499413002731
Validation loss: 2.55712292454931

Epoch: 6| Step: 12
Training loss: 1.5485669525571453
Validation loss: 2.5253547921160675

Epoch: 6| Step: 13
Training loss: 1.1202746865077244
Validation loss: 2.539413882695227

Epoch: 399| Step: 0
Training loss: 1.5250091271049153
Validation loss: 2.5335286633726803

Epoch: 6| Step: 1
Training loss: 1.3667686474750675
Validation loss: 2.5331797017947126

Epoch: 6| Step: 2
Training loss: 1.1812451418014815
Validation loss: 2.584679044342541

Epoch: 6| Step: 3
Training loss: 1.2547615437969428
Validation loss: 2.5826745489976326

Epoch: 6| Step: 4
Training loss: 1.5856991292776568
Validation loss: 2.6046222004500112

Epoch: 6| Step: 5
Training loss: 1.3867364156967854
Validation loss: 2.5921191878054897

Epoch: 6| Step: 6
Training loss: 0.8436885034261437
Validation loss: 2.5940795216666754

Epoch: 6| Step: 7
Training loss: 0.9183040574652234
Validation loss: 2.5965908705939715

Epoch: 6| Step: 8
Training loss: 1.34005410903603
Validation loss: 2.604306231952968

Epoch: 6| Step: 9
Training loss: 1.2820412588339023
Validation loss: 2.593645879753755

Epoch: 6| Step: 10
Training loss: 1.5369626354473391
Validation loss: 2.64673473104985

Epoch: 6| Step: 11
Training loss: 1.513471430150633
Validation loss: 2.6423723905488616

Epoch: 6| Step: 12
Training loss: 1.429574430403324
Validation loss: 2.6898444467406963

Epoch: 6| Step: 13
Training loss: 1.0316033769359245
Validation loss: 2.709796590377019

Epoch: 400| Step: 0
Training loss: 1.2267007932027727
Validation loss: 2.6686009418178354

Epoch: 6| Step: 1
Training loss: 1.0557114893081474
Validation loss: 2.6311426264889524

Epoch: 6| Step: 2
Training loss: 1.4134829687732657
Validation loss: 2.616828686442898

Epoch: 6| Step: 3
Training loss: 1.4611113745701645
Validation loss: 2.5860093163823064

Epoch: 6| Step: 4
Training loss: 1.637626305288079
Validation loss: 2.5446581155572043

Epoch: 6| Step: 5
Training loss: 0.9683204436853203
Validation loss: 2.5080747689890015

Epoch: 6| Step: 6
Training loss: 1.0237339551364666
Validation loss: 2.5046985445143775

Epoch: 6| Step: 7
Training loss: 1.5349688621866864
Validation loss: 2.518380907393518

Epoch: 6| Step: 8
Training loss: 1.260984602831891
Validation loss: 2.501993706161549

Epoch: 6| Step: 9
Training loss: 1.3133295253433817
Validation loss: 2.5332303298525565

Epoch: 6| Step: 10
Training loss: 0.8958048852942754
Validation loss: 2.5715050555023233

Epoch: 6| Step: 11
Training loss: 1.6582412984922517
Validation loss: 2.59912419236371

Epoch: 6| Step: 12
Training loss: 1.6127433711483241
Validation loss: 2.6480343279141283

Epoch: 6| Step: 13
Training loss: 0.9823191230688026
Validation loss: 2.642565992543789

Testing loss: 2.292195086967557
