Epoch: 1| Step: 0
Training loss: 6.331103324890137
Validation loss: 5.249111636992423

Epoch: 6| Step: 1
Training loss: 3.8899009227752686
Validation loss: 5.239434416576098

Epoch: 6| Step: 2
Training loss: 5.6045637130737305
Validation loss: 5.229867971071633

Epoch: 6| Step: 3
Training loss: 5.6574201583862305
Validation loss: 5.2211775266995994

Epoch: 6| Step: 4
Training loss: 4.603437900543213
Validation loss: 5.212829420643468

Epoch: 6| Step: 5
Training loss: 6.518389701843262
Validation loss: 5.203902757295999

Epoch: 6| Step: 6
Training loss: 4.29778528213501
Validation loss: 5.195497328235257

Epoch: 6| Step: 7
Training loss: 3.172640085220337
Validation loss: 5.186435709717453

Epoch: 6| Step: 8
Training loss: 4.781988620758057
Validation loss: 5.176748901285151

Epoch: 6| Step: 9
Training loss: 5.759346008300781
Validation loss: 5.16670359334638

Epoch: 6| Step: 10
Training loss: 4.591209411621094
Validation loss: 5.156109297147361

Epoch: 6| Step: 11
Training loss: 4.346057891845703
Validation loss: 5.144017542562177

Epoch: 6| Step: 12
Training loss: 5.071880340576172
Validation loss: 5.131364858278665

Epoch: 6| Step: 13
Training loss: 5.300173759460449
Validation loss: 5.11693686310963

Epoch: 2| Step: 0
Training loss: 5.7973127365112305
Validation loss: 5.10159283812328

Epoch: 6| Step: 1
Training loss: 5.1831512451171875
Validation loss: 5.084807934299592

Epoch: 6| Step: 2
Training loss: 5.851693153381348
Validation loss: 5.066727915117817

Epoch: 6| Step: 3
Training loss: 4.743031978607178
Validation loss: 5.047349842645788

Epoch: 6| Step: 4
Training loss: 4.147043228149414
Validation loss: 5.026635595547256

Epoch: 6| Step: 5
Training loss: 4.685769557952881
Validation loss: 5.004119965337938

Epoch: 6| Step: 6
Training loss: 4.934645175933838
Validation loss: 4.980445774652624

Epoch: 6| Step: 7
Training loss: 4.202658653259277
Validation loss: 4.955734555439283

Epoch: 6| Step: 8
Training loss: 4.782706260681152
Validation loss: 4.92924480540778

Epoch: 6| Step: 9
Training loss: 4.342293739318848
Validation loss: 4.901499820011918

Epoch: 6| Step: 10
Training loss: 5.024631977081299
Validation loss: 4.872483373970113

Epoch: 6| Step: 11
Training loss: 3.382190227508545
Validation loss: 4.841453993192283

Epoch: 6| Step: 12
Training loss: 5.439934730529785
Validation loss: 4.809782945981589

Epoch: 6| Step: 13
Training loss: 3.454231023788452
Validation loss: 4.776724630786527

Epoch: 3| Step: 0
Training loss: 5.225423812866211
Validation loss: 4.743152392807827

Epoch: 6| Step: 1
Training loss: 5.445099830627441
Validation loss: 4.705460712473879

Epoch: 6| Step: 2
Training loss: 3.279776096343994
Validation loss: 4.668313487883537

Epoch: 6| Step: 3
Training loss: 4.682074546813965
Validation loss: 4.627658577375515

Epoch: 6| Step: 4
Training loss: 5.2870869636535645
Validation loss: 4.5850658262929604

Epoch: 6| Step: 5
Training loss: 4.672975063323975
Validation loss: 4.542375046719787

Epoch: 6| Step: 6
Training loss: 4.404777526855469
Validation loss: 4.497599222326792

Epoch: 6| Step: 7
Training loss: 4.927082538604736
Validation loss: 4.451318771608414

Epoch: 6| Step: 8
Training loss: 3.7579832077026367
Validation loss: 4.4032120397014

Epoch: 6| Step: 9
Training loss: 2.120185613632202
Validation loss: 4.355663494397235

Epoch: 6| Step: 10
Training loss: 5.292180061340332
Validation loss: 4.308959986573907

Epoch: 6| Step: 11
Training loss: 3.132716178894043
Validation loss: 4.264162560944916

Epoch: 6| Step: 12
Training loss: 3.8342270851135254
Validation loss: 4.216338132017402

Epoch: 6| Step: 13
Training loss: 3.672102928161621
Validation loss: 4.16399872174827

Epoch: 4| Step: 0
Training loss: 5.35053014755249
Validation loss: 4.118142553555068

Epoch: 6| Step: 1
Training loss: 3.3637497425079346
Validation loss: 4.076276471537929

Epoch: 6| Step: 2
Training loss: 4.634157180786133
Validation loss: 4.0328946985224245

Epoch: 6| Step: 3
Training loss: 3.4317030906677246
Validation loss: 3.9922314254186486

Epoch: 6| Step: 4
Training loss: 4.543314456939697
Validation loss: 3.954700167461108

Epoch: 6| Step: 5
Training loss: 3.8388729095458984
Validation loss: 3.918398593061714

Epoch: 6| Step: 6
Training loss: 2.54215669631958
Validation loss: 3.8885063509787283

Epoch: 6| Step: 7
Training loss: 5.241718292236328
Validation loss: 3.8617511462139826

Epoch: 6| Step: 8
Training loss: 2.881491184234619
Validation loss: 3.8389886579205914

Epoch: 6| Step: 9
Training loss: 2.369241714477539
Validation loss: 3.8134885090653614

Epoch: 6| Step: 10
Training loss: 3.556373119354248
Validation loss: 3.791271681426674

Epoch: 6| Step: 11
Training loss: 2.565847158432007
Validation loss: 3.7668323747573362

Epoch: 6| Step: 12
Training loss: 4.579410552978516
Validation loss: 3.743813878746443

Epoch: 6| Step: 13
Training loss: 4.014286041259766
Validation loss: 3.7216800899915796

Epoch: 5| Step: 0
Training loss: 3.6936540603637695
Validation loss: 3.6996253562229935

Epoch: 6| Step: 1
Training loss: 3.8591995239257812
Validation loss: 3.677468515211536

Epoch: 6| Step: 2
Training loss: 4.6111016273498535
Validation loss: 3.656591779442244

Epoch: 6| Step: 3
Training loss: 2.8312721252441406
Validation loss: 3.6395319507968042

Epoch: 6| Step: 4
Training loss: 4.294893264770508
Validation loss: 3.6188531691028225

Epoch: 6| Step: 5
Training loss: 3.974630355834961
Validation loss: 3.5980541654812392

Epoch: 6| Step: 6
Training loss: 3.1372292041778564
Validation loss: 3.5823555249039845

Epoch: 6| Step: 7
Training loss: 2.5711498260498047
Validation loss: 3.5654665321432133

Epoch: 6| Step: 8
Training loss: 3.5797858238220215
Validation loss: 3.5512901070297405

Epoch: 6| Step: 9
Training loss: 4.217811584472656
Validation loss: 3.5352303699780534

Epoch: 6| Step: 10
Training loss: 2.281405448913574
Validation loss: 3.522091163102017

Epoch: 6| Step: 11
Training loss: 2.8079729080200195
Validation loss: 3.5094291958757626

Epoch: 6| Step: 12
Training loss: 3.8268349170684814
Validation loss: 3.4945901004217004

Epoch: 6| Step: 13
Training loss: 3.195301055908203
Validation loss: 3.4819376571204073

Epoch: 6| Step: 0
Training loss: 2.392941951751709
Validation loss: 3.469060574808428

Epoch: 6| Step: 1
Training loss: 3.860149621963501
Validation loss: 3.4586258267843597

Epoch: 6| Step: 2
Training loss: 3.684500217437744
Validation loss: 3.4481940064378964

Epoch: 6| Step: 3
Training loss: 3.7703380584716797
Validation loss: 3.4353969379137923

Epoch: 6| Step: 4
Training loss: 3.269967794418335
Validation loss: 3.427734592909454

Epoch: 6| Step: 5
Training loss: 4.079586505889893
Validation loss: 3.417944618450698

Epoch: 6| Step: 6
Training loss: 2.9184935092926025
Validation loss: 3.4093576195419475

Epoch: 6| Step: 7
Training loss: 3.055418014526367
Validation loss: 3.3993809351357083

Epoch: 6| Step: 8
Training loss: 2.6978962421417236
Validation loss: 3.387128755610476

Epoch: 6| Step: 9
Training loss: 2.9099090099334717
Validation loss: 3.3762313294154342

Epoch: 6| Step: 10
Training loss: 3.9514169692993164
Validation loss: 3.3654124659876667

Epoch: 6| Step: 11
Training loss: 3.5207741260528564
Validation loss: 3.3582603341789654

Epoch: 6| Step: 12
Training loss: 2.928628921508789
Validation loss: 3.3490676008244997

Epoch: 6| Step: 13
Training loss: 4.2963151931762695
Validation loss: 3.3474188414953088

Epoch: 7| Step: 0
Training loss: 3.067479372024536
Validation loss: 3.3324326545961442

Epoch: 6| Step: 1
Training loss: 3.469191551208496
Validation loss: 3.3185944172643844

Epoch: 6| Step: 2
Training loss: 2.7500216960906982
Validation loss: 3.3034086304326213

Epoch: 6| Step: 3
Training loss: 2.698862075805664
Validation loss: 3.2997353282026065

Epoch: 6| Step: 4
Training loss: 2.880463123321533
Validation loss: 3.298151828909433

Epoch: 6| Step: 5
Training loss: 2.491610050201416
Validation loss: 3.2863258828399

Epoch: 6| Step: 6
Training loss: 3.49277400970459
Validation loss: 3.2765684999445432

Epoch: 6| Step: 7
Training loss: 3.1288657188415527
Validation loss: 3.265675293501987

Epoch: 6| Step: 8
Training loss: 3.459667205810547
Validation loss: 3.2573873458370084

Epoch: 6| Step: 9
Training loss: 4.075583457946777
Validation loss: 3.255240527532434

Epoch: 6| Step: 10
Training loss: 3.783883571624756
Validation loss: 3.2477809895751295

Epoch: 6| Step: 11
Training loss: 3.312159299850464
Validation loss: 3.2368757570943525

Epoch: 6| Step: 12
Training loss: 3.9120688438415527
Validation loss: 3.229428983503772

Epoch: 6| Step: 13
Training loss: 2.7366716861724854
Validation loss: 3.22382019412133

Epoch: 8| Step: 0
Training loss: 3.4316086769104004
Validation loss: 3.222438807128578

Epoch: 6| Step: 1
Training loss: 3.1024365425109863
Validation loss: 3.2178473549504436

Epoch: 6| Step: 2
Training loss: 2.627767562866211
Validation loss: 3.2142947463579077

Epoch: 6| Step: 3
Training loss: 3.362039804458618
Validation loss: 3.2072707119808403

Epoch: 6| Step: 4
Training loss: 3.278381824493408
Validation loss: 3.200627291074363

Epoch: 6| Step: 5
Training loss: 3.891751766204834
Validation loss: 3.1913799265379548

Epoch: 6| Step: 6
Training loss: 2.4728593826293945
Validation loss: 3.1864074891613376

Epoch: 6| Step: 7
Training loss: 3.8509514331817627
Validation loss: 3.1822403656539096

Epoch: 6| Step: 8
Training loss: 3.222076892852783
Validation loss: 3.1788097120100454

Epoch: 6| Step: 9
Training loss: 3.7325186729431152
Validation loss: 3.1734694229659213

Epoch: 6| Step: 10
Training loss: 2.8113274574279785
Validation loss: 3.169507852164648

Epoch: 6| Step: 11
Training loss: 3.4479613304138184
Validation loss: 3.1674617234096734

Epoch: 6| Step: 12
Training loss: 2.377110481262207
Validation loss: 3.160466089043566

Epoch: 6| Step: 13
Training loss: 3.0135884284973145
Validation loss: 3.1581674057950258

Epoch: 9| Step: 0
Training loss: 2.303999423980713
Validation loss: 3.159385368388186

Epoch: 6| Step: 1
Training loss: 3.2945034503936768
Validation loss: 3.15976877879071

Epoch: 6| Step: 2
Training loss: 2.82417631149292
Validation loss: 3.165247837702433

Epoch: 6| Step: 3
Training loss: 2.8142011165618896
Validation loss: 3.145000162944999

Epoch: 6| Step: 4
Training loss: 2.656315803527832
Validation loss: 3.133297215225876

Epoch: 6| Step: 5
Training loss: 2.8854899406433105
Validation loss: 3.130826393763224

Epoch: 6| Step: 6
Training loss: 3.0582363605499268
Validation loss: 3.1302505103490685

Epoch: 6| Step: 7
Training loss: 4.217804431915283
Validation loss: 3.121498477074408

Epoch: 6| Step: 8
Training loss: 3.239687204360962
Validation loss: 3.1078420351910334

Epoch: 6| Step: 9
Training loss: 3.1137142181396484
Validation loss: 3.0959620039950133

Epoch: 6| Step: 10
Training loss: 3.974801540374756
Validation loss: 3.095216897226149

Epoch: 6| Step: 11
Training loss: 3.6515791416168213
Validation loss: 3.0984882257317983

Epoch: 6| Step: 12
Training loss: 3.409945011138916
Validation loss: 3.0932771749393915

Epoch: 6| Step: 13
Training loss: 2.0447380542755127
Validation loss: 3.083204097645257

Epoch: 10| Step: 0
Training loss: 2.763650417327881
Validation loss: 3.0768279670387186

Epoch: 6| Step: 1
Training loss: 2.7869768142700195
Validation loss: 3.0767746715135473

Epoch: 6| Step: 2
Training loss: 3.047597885131836
Validation loss: 3.0807669188386653

Epoch: 6| Step: 3
Training loss: 3.139193058013916
Validation loss: 3.082412399271483

Epoch: 6| Step: 4
Training loss: 4.028939247131348
Validation loss: 3.071979525268719

Epoch: 6| Step: 5
Training loss: 2.985352039337158
Validation loss: 3.061766706487184

Epoch: 6| Step: 6
Training loss: 3.3726181983947754
Validation loss: 3.05315339180731

Epoch: 6| Step: 7
Training loss: 3.0296874046325684
Validation loss: 3.0486193523612073

Epoch: 6| Step: 8
Training loss: 2.793214797973633
Validation loss: 3.0460711781696608

Epoch: 6| Step: 9
Training loss: 3.487487316131592
Validation loss: 3.0424380892066547

Epoch: 6| Step: 10
Training loss: 2.8383209705352783
Validation loss: 3.032747014876335

Epoch: 6| Step: 11
Training loss: 2.886953830718994
Validation loss: 3.0267416584876274

Epoch: 6| Step: 12
Training loss: 2.6215765476226807
Validation loss: 3.024319118069064

Epoch: 6| Step: 13
Training loss: 4.025651454925537
Validation loss: 3.023395576784688

Epoch: 11| Step: 0
Training loss: 3.2429027557373047
Validation loss: 3.0212236732564945

Epoch: 6| Step: 1
Training loss: 3.672070026397705
Validation loss: 3.0145030149849514

Epoch: 6| Step: 2
Training loss: 2.1344332695007324
Validation loss: 3.0079837229944046

Epoch: 6| Step: 3
Training loss: 3.0737271308898926
Validation loss: 3.006840944290161

Epoch: 6| Step: 4
Training loss: 3.103412389755249
Validation loss: 3.006611454871393

Epoch: 6| Step: 5
Training loss: 2.552227020263672
Validation loss: 3.0093091790394118

Epoch: 6| Step: 6
Training loss: 3.6749255657196045
Validation loss: 3.000509859413229

Epoch: 6| Step: 7
Training loss: 3.142658233642578
Validation loss: 2.9940577527528167

Epoch: 6| Step: 8
Training loss: 3.8862686157226562
Validation loss: 2.9898296607437955

Epoch: 6| Step: 9
Training loss: 2.8928537368774414
Validation loss: 2.984954203328779

Epoch: 6| Step: 10
Training loss: 2.208184003829956
Validation loss: 2.9858640060629895

Epoch: 6| Step: 11
Training loss: 3.9575366973876953
Validation loss: 2.983282148197133

Epoch: 6| Step: 12
Training loss: 2.5374345779418945
Validation loss: 2.973356234130039

Epoch: 6| Step: 13
Training loss: 2.5490784645080566
Validation loss: 2.9726767283613964

Epoch: 12| Step: 0
Training loss: 2.7022392749786377
Validation loss: 2.9779818647651264

Epoch: 6| Step: 1
Training loss: 3.6191463470458984
Validation loss: 2.989378575355776

Epoch: 6| Step: 2
Training loss: 3.5963172912597656
Validation loss: 2.9685275605929795

Epoch: 6| Step: 3
Training loss: 2.9051811695098877
Validation loss: 2.96637902721282

Epoch: 6| Step: 4
Training loss: 2.5381832122802734
Validation loss: 2.9603066341851347

Epoch: 6| Step: 5
Training loss: 3.7345619201660156
Validation loss: 2.9615011753574496

Epoch: 6| Step: 6
Training loss: 2.702510118484497
Validation loss: 2.9546223763496644

Epoch: 6| Step: 7
Training loss: 4.076772689819336
Validation loss: 2.946552279174969

Epoch: 6| Step: 8
Training loss: 2.7857260704040527
Validation loss: 2.9380524004659345

Epoch: 6| Step: 9
Training loss: 3.01554012298584
Validation loss: 2.9379750195369927

Epoch: 6| Step: 10
Training loss: 2.817194938659668
Validation loss: 2.935931859477874

Epoch: 6| Step: 11
Training loss: 3.0702285766601562
Validation loss: 2.9358154676293813

Epoch: 6| Step: 12
Training loss: 1.725020408630371
Validation loss: 2.9289268293688373

Epoch: 6| Step: 13
Training loss: 3.186152935028076
Validation loss: 2.9274041447588193

Epoch: 13| Step: 0
Training loss: 3.875563144683838
Validation loss: 2.9263598867641982

Epoch: 6| Step: 1
Training loss: 3.297602653503418
Validation loss: 2.9222810422220538

Epoch: 6| Step: 2
Training loss: 3.7014026641845703
Validation loss: 2.9195543591694166

Epoch: 6| Step: 3
Training loss: 3.219135284423828
Validation loss: 2.9208169880733696

Epoch: 6| Step: 4
Training loss: 1.6538071632385254
Validation loss: 2.910250771430231

Epoch: 6| Step: 5
Training loss: 2.6753346920013428
Validation loss: 2.9156586457324285

Epoch: 6| Step: 6
Training loss: 2.9210093021392822
Validation loss: 2.9052796876558693

Epoch: 6| Step: 7
Training loss: 3.1960439682006836
Validation loss: 2.9007947291097333

Epoch: 6| Step: 8
Training loss: 3.1260440349578857
Validation loss: 2.897497982107183

Epoch: 6| Step: 9
Training loss: 2.726353883743286
Validation loss: 2.8978325551556003

Epoch: 6| Step: 10
Training loss: 2.855093002319336
Validation loss: 2.896163148264731

Epoch: 6| Step: 11
Training loss: 2.7226638793945312
Validation loss: 2.890961757270239

Epoch: 6| Step: 12
Training loss: 2.979860782623291
Validation loss: 2.8893417312252905

Epoch: 6| Step: 13
Training loss: 3.029071569442749
Validation loss: 2.8887496097113496

Epoch: 14| Step: 0
Training loss: 3.2108829021453857
Validation loss: 2.8796351955782984

Epoch: 6| Step: 1
Training loss: 3.062516689300537
Validation loss: 2.8758839176547144

Epoch: 6| Step: 2
Training loss: 2.6394176483154297
Validation loss: 2.8675986771942465

Epoch: 6| Step: 3
Training loss: 2.7896780967712402
Validation loss: 2.8708108317467476

Epoch: 6| Step: 4
Training loss: 3.2783055305480957
Validation loss: 2.867275817419893

Epoch: 6| Step: 5
Training loss: 3.042257070541382
Validation loss: 2.8680525415687153

Epoch: 6| Step: 6
Training loss: 3.5385630130767822
Validation loss: 2.8642073856886996

Epoch: 6| Step: 7
Training loss: 2.562417984008789
Validation loss: 2.8621692913834766

Epoch: 6| Step: 8
Training loss: 2.702268600463867
Validation loss: 2.8651610189868557

Epoch: 6| Step: 9
Training loss: 2.9741811752319336
Validation loss: 2.856224375386392

Epoch: 6| Step: 10
Training loss: 3.3021605014801025
Validation loss: 2.8486268315263974

Epoch: 6| Step: 11
Training loss: 3.143688201904297
Validation loss: 2.8426098874820176

Epoch: 6| Step: 12
Training loss: 2.6019716262817383
Validation loss: 2.8403561807447866

Epoch: 6| Step: 13
Training loss: 2.5056698322296143
Validation loss: 2.8404973681255052

Epoch: 15| Step: 0
Training loss: 3.0375192165374756
Validation loss: 2.8386796571875132

Epoch: 6| Step: 1
Training loss: 3.001265048980713
Validation loss: 2.8333202228751233

Epoch: 6| Step: 2
Training loss: 2.643657922744751
Validation loss: 2.8376838391827

Epoch: 6| Step: 3
Training loss: 2.8012804985046387
Validation loss: 2.843433969764299

Epoch: 6| Step: 4
Training loss: 3.521747589111328
Validation loss: 2.853472355873354

Epoch: 6| Step: 5
Training loss: 3.427839517593384
Validation loss: 2.8719826667539534

Epoch: 6| Step: 6
Training loss: 2.9384407997131348
Validation loss: 2.857166523574501

Epoch: 6| Step: 7
Training loss: 2.851109504699707
Validation loss: 2.839129065954557

Epoch: 6| Step: 8
Training loss: 2.303590774536133
Validation loss: 2.8195366449253534

Epoch: 6| Step: 9
Training loss: 3.534533977508545
Validation loss: 2.810471967984271

Epoch: 6| Step: 10
Training loss: 2.8803980350494385
Validation loss: 2.8121769864072084

Epoch: 6| Step: 11
Training loss: 3.5262651443481445
Validation loss: 2.8073419294049664

Epoch: 6| Step: 12
Training loss: 2.2647602558135986
Validation loss: 2.811161438624064

Epoch: 6| Step: 13
Training loss: 2.1967477798461914
Validation loss: 2.8048014358807634

Epoch: 16| Step: 0
Training loss: 2.1553618907928467
Validation loss: 2.804464950356432

Epoch: 6| Step: 1
Training loss: 2.884101390838623
Validation loss: 2.804519030355638

Epoch: 6| Step: 2
Training loss: 3.4651551246643066
Validation loss: 2.795455253252419

Epoch: 6| Step: 3
Training loss: 3.6120104789733887
Validation loss: 2.796912626553607

Epoch: 6| Step: 4
Training loss: 2.597259283065796
Validation loss: 2.795133831680462

Epoch: 6| Step: 5
Training loss: 3.870596408843994
Validation loss: 2.794706654805009

Epoch: 6| Step: 6
Training loss: 2.5364348888397217
Validation loss: 2.7877945412871656

Epoch: 6| Step: 7
Training loss: 3.504854440689087
Validation loss: 2.786726972108246

Epoch: 6| Step: 8
Training loss: 2.59270977973938
Validation loss: 2.785645354178644

Epoch: 6| Step: 9
Training loss: 3.3753695487976074
Validation loss: 2.7862052097115466

Epoch: 6| Step: 10
Training loss: 1.9284007549285889
Validation loss: 2.7996849116458686

Epoch: 6| Step: 11
Training loss: 3.092473268508911
Validation loss: 2.79602381490892

Epoch: 6| Step: 12
Training loss: 2.614410400390625
Validation loss: 2.802381851339853

Epoch: 6| Step: 13
Training loss: 2.604388952255249
Validation loss: 2.786851877807289

Epoch: 17| Step: 0
Training loss: 2.6746277809143066
Validation loss: 2.7766695048219416

Epoch: 6| Step: 1
Training loss: 2.765852451324463
Validation loss: 2.7716956882066626

Epoch: 6| Step: 2
Training loss: 3.01139760017395
Validation loss: 2.7787911686846005

Epoch: 6| Step: 3
Training loss: 2.453659772872925
Validation loss: 2.7770401790577877

Epoch: 6| Step: 4
Training loss: 2.2625770568847656
Validation loss: 2.770617546573762

Epoch: 6| Step: 5
Training loss: 3.0450406074523926
Validation loss: 2.7634618564318587

Epoch: 6| Step: 6
Training loss: 4.071556091308594
Validation loss: 2.764769438774355

Epoch: 6| Step: 7
Training loss: 3.2625367641448975
Validation loss: 2.7607332301396195

Epoch: 6| Step: 8
Training loss: 3.04707932472229
Validation loss: 2.757435696099394

Epoch: 6| Step: 9
Training loss: 2.7295379638671875
Validation loss: 2.7537733995786278

Epoch: 6| Step: 10
Training loss: 2.026998996734619
Validation loss: 2.751953089109031

Epoch: 6| Step: 11
Training loss: 3.9063076972961426
Validation loss: 2.7502808801589476

Epoch: 6| Step: 12
Training loss: 2.393301010131836
Validation loss: 2.7477722475605626

Epoch: 6| Step: 13
Training loss: 3.0823638439178467
Validation loss: 2.749770700290639

Epoch: 18| Step: 0
Training loss: 2.4413623809814453
Validation loss: 2.764769838702294

Epoch: 6| Step: 1
Training loss: 3.6638498306274414
Validation loss: 2.786559207465059

Epoch: 6| Step: 2
Training loss: 3.2571475505828857
Validation loss: 2.746889352798462

Epoch: 6| Step: 3
Training loss: 2.5237879753112793
Validation loss: 2.7414976550686743

Epoch: 6| Step: 4
Training loss: 2.3998022079467773
Validation loss: 2.7585895753675893

Epoch: 6| Step: 5
Training loss: 2.9112324714660645
Validation loss: 2.7943777371478338

Epoch: 6| Step: 6
Training loss: 2.8252158164978027
Validation loss: 2.7806373462882092

Epoch: 6| Step: 7
Training loss: 3.801823616027832
Validation loss: 2.7750036331915084

Epoch: 6| Step: 8
Training loss: 3.049980640411377
Validation loss: 2.763629610820483

Epoch: 6| Step: 9
Training loss: 3.2171356678009033
Validation loss: 2.7520163853963218

Epoch: 6| Step: 10
Training loss: 2.6966235637664795
Validation loss: 2.7486819862037577

Epoch: 6| Step: 11
Training loss: 2.44832181930542
Validation loss: 2.7374131371898036

Epoch: 6| Step: 12
Training loss: 2.2676379680633545
Validation loss: 2.738530912706929

Epoch: 6| Step: 13
Training loss: 3.3120341300964355
Validation loss: 2.7307302874903523

Epoch: 19| Step: 0
Training loss: 2.2494893074035645
Validation loss: 2.734212283165224

Epoch: 6| Step: 1
Training loss: 3.0215916633605957
Validation loss: 2.737982475629417

Epoch: 6| Step: 2
Training loss: 3.231973171234131
Validation loss: 2.7467779292855212

Epoch: 6| Step: 3
Training loss: 2.527780532836914
Validation loss: 2.7567292618495163

Epoch: 6| Step: 4
Training loss: 3.7541542053222656
Validation loss: 2.7558421396440074

Epoch: 6| Step: 5
Training loss: 3.2038164138793945
Validation loss: 2.735468344021869

Epoch: 6| Step: 6
Training loss: 2.9350414276123047
Validation loss: 2.7252524565624934

Epoch: 6| Step: 7
Training loss: 2.8234479427337646
Validation loss: 2.714960480249056

Epoch: 6| Step: 8
Training loss: 2.9583840370178223
Validation loss: 2.715962894501225

Epoch: 6| Step: 9
Training loss: 2.871596097946167
Validation loss: 2.7159248398196314

Epoch: 6| Step: 10
Training loss: 3.5068516731262207
Validation loss: 2.7144869681327575

Epoch: 6| Step: 11
Training loss: 2.080305576324463
Validation loss: 2.7186642872389926

Epoch: 6| Step: 12
Training loss: 2.7895424365997314
Validation loss: 2.7224854884609098

Epoch: 6| Step: 13
Training loss: 2.063896894454956
Validation loss: 2.7350492733781055

Epoch: 20| Step: 0
Training loss: 3.4296388626098633
Validation loss: 2.7710040512905327

Epoch: 6| Step: 1
Training loss: 3.749490261077881
Validation loss: 2.7660616520912416

Epoch: 6| Step: 2
Training loss: 3.7828590869903564
Validation loss: 2.7080895849453506

Epoch: 6| Step: 3
Training loss: 3.2838053703308105
Validation loss: 2.7138382491245063

Epoch: 6| Step: 4
Training loss: 2.630685806274414
Validation loss: 2.717660116892989

Epoch: 6| Step: 5
Training loss: 2.3043839931488037
Validation loss: 2.737368601624684

Epoch: 6| Step: 6
Training loss: 2.398390769958496
Validation loss: 2.752279999435589

Epoch: 6| Step: 7
Training loss: 2.5764334201812744
Validation loss: 2.7624364411959084

Epoch: 6| Step: 8
Training loss: 3.059055805206299
Validation loss: 2.755660274977325

Epoch: 6| Step: 9
Training loss: 2.4695441722869873
Validation loss: 2.749406491556475

Epoch: 6| Step: 10
Training loss: 2.7135117053985596
Validation loss: 2.735512148949408

Epoch: 6| Step: 11
Training loss: 3.2595579624176025
Validation loss: 2.7258458727149555

Epoch: 6| Step: 12
Training loss: 2.240658760070801
Validation loss: 2.715210137828704

Epoch: 6| Step: 13
Training loss: 2.163172960281372
Validation loss: 2.7045306185240388

Epoch: 21| Step: 0
Training loss: 2.4774794578552246
Validation loss: 2.698931706848965

Epoch: 6| Step: 1
Training loss: 3.1219494342803955
Validation loss: 2.7020292769196215

Epoch: 6| Step: 2
Training loss: 2.6745152473449707
Validation loss: 2.701442510850968

Epoch: 6| Step: 3
Training loss: 3.370466947555542
Validation loss: 2.7084396013649563

Epoch: 6| Step: 4
Training loss: 3.3369221687316895
Validation loss: 2.6949407592896493

Epoch: 6| Step: 5
Training loss: 2.8420629501342773
Validation loss: 2.6805904296136673

Epoch: 6| Step: 6
Training loss: 2.780893087387085
Validation loss: 2.680486814950102

Epoch: 6| Step: 7
Training loss: 3.2180323600769043
Validation loss: 2.6806172734947613

Epoch: 6| Step: 8
Training loss: 2.133533000946045
Validation loss: 2.691762098702051

Epoch: 6| Step: 9
Training loss: 2.7661495208740234
Validation loss: 2.6983085499014905

Epoch: 6| Step: 10
Training loss: 2.5736827850341797
Validation loss: 2.699768676552721

Epoch: 6| Step: 11
Training loss: 2.795280694961548
Validation loss: 2.7048148365430933

Epoch: 6| Step: 12
Training loss: 2.6248722076416016
Validation loss: 2.6972077508126535

Epoch: 6| Step: 13
Training loss: 3.687229633331299
Validation loss: 2.6958220748491186

Epoch: 22| Step: 0
Training loss: 2.7774267196655273
Validation loss: 2.6846777162244244

Epoch: 6| Step: 1
Training loss: 1.8460205793380737
Validation loss: 2.672068252358385

Epoch: 6| Step: 2
Training loss: 2.440783739089966
Validation loss: 2.6618621656971593

Epoch: 6| Step: 3
Training loss: 3.16513729095459
Validation loss: 2.660962730325678

Epoch: 6| Step: 4
Training loss: 2.36865234375
Validation loss: 2.6600126809971307

Epoch: 6| Step: 5
Training loss: 3.3965842723846436
Validation loss: 2.658532770731116

Epoch: 6| Step: 6
Training loss: 3.5431737899780273
Validation loss: 2.6580872484432754

Epoch: 6| Step: 7
Training loss: 2.8452696800231934
Validation loss: 2.6582700770388366

Epoch: 6| Step: 8
Training loss: 2.811079740524292
Validation loss: 2.6549526286381546

Epoch: 6| Step: 9
Training loss: 1.8933584690093994
Validation loss: 2.650617907124181

Epoch: 6| Step: 10
Training loss: 2.965041160583496
Validation loss: 2.647366295578659

Epoch: 6| Step: 11
Training loss: 3.182096481323242
Validation loss: 2.653158244266305

Epoch: 6| Step: 12
Training loss: 3.3392627239227295
Validation loss: 2.6492403245741323

Epoch: 6| Step: 13
Training loss: 3.333104133605957
Validation loss: 2.6532854521146385

Epoch: 23| Step: 0
Training loss: 2.8918633460998535
Validation loss: 2.6578768735290854

Epoch: 6| Step: 1
Training loss: 3.1172266006469727
Validation loss: 2.654872320031607

Epoch: 6| Step: 2
Training loss: 3.39372181892395
Validation loss: 2.6494901821177494

Epoch: 6| Step: 3
Training loss: 2.662062644958496
Validation loss: 2.6446556327163533

Epoch: 6| Step: 4
Training loss: 2.9131991863250732
Validation loss: 2.6463049073373117

Epoch: 6| Step: 5
Training loss: 2.7501399517059326
Validation loss: 2.641411404455862

Epoch: 6| Step: 6
Training loss: 3.1055734157562256
Validation loss: 2.648742421980827

Epoch: 6| Step: 7
Training loss: 2.5876541137695312
Validation loss: 2.6413899621655865

Epoch: 6| Step: 8
Training loss: 2.0015978813171387
Validation loss: 2.6427454435697166

Epoch: 6| Step: 9
Training loss: 2.6951897144317627
Validation loss: 2.6435355396680933

Epoch: 6| Step: 10
Training loss: 3.8727285861968994
Validation loss: 2.6557913800721527

Epoch: 6| Step: 11
Training loss: 2.906151294708252
Validation loss: 2.641223628033874

Epoch: 6| Step: 12
Training loss: 2.2796926498413086
Validation loss: 2.6375219796293523

Epoch: 6| Step: 13
Training loss: 2.2486915588378906
Validation loss: 2.633187811861756

Epoch: 24| Step: 0
Training loss: 2.635782241821289
Validation loss: 2.6374088282226236

Epoch: 6| Step: 1
Training loss: 2.7908177375793457
Validation loss: 2.634739827084285

Epoch: 6| Step: 2
Training loss: 2.668813467025757
Validation loss: 2.6364238031448854

Epoch: 6| Step: 3
Training loss: 3.667506694793701
Validation loss: 2.639661822267758

Epoch: 6| Step: 4
Training loss: 2.680746555328369
Validation loss: 2.6370565070900867

Epoch: 6| Step: 5
Training loss: 2.7541065216064453
Validation loss: 2.6360968748728433

Epoch: 6| Step: 6
Training loss: 2.9681198596954346
Validation loss: 2.636238064817203

Epoch: 6| Step: 7
Training loss: 3.0666728019714355
Validation loss: 2.6349923251777567

Epoch: 6| Step: 8
Training loss: 2.832425594329834
Validation loss: 2.6315536345205

Epoch: 6| Step: 9
Training loss: 1.9092187881469727
Validation loss: 2.6280156873887583

Epoch: 6| Step: 10
Training loss: 3.124823808670044
Validation loss: 2.6275274676661335

Epoch: 6| Step: 11
Training loss: 2.354281425476074
Validation loss: 2.6323814468999065

Epoch: 6| Step: 12
Training loss: 2.787952423095703
Validation loss: 2.627787600281418

Epoch: 6| Step: 13
Training loss: 3.541292667388916
Validation loss: 2.632567944065217

Epoch: 25| Step: 0
Training loss: 3.226807117462158
Validation loss: 2.6269470286625687

Epoch: 6| Step: 1
Training loss: 2.0121679306030273
Validation loss: 2.620530977044054

Epoch: 6| Step: 2
Training loss: 2.9296305179595947
Validation loss: 2.6172202171817904

Epoch: 6| Step: 3
Training loss: 2.6298398971557617
Validation loss: 2.622797252029501

Epoch: 6| Step: 4
Training loss: 2.9720191955566406
Validation loss: 2.620249068865212

Epoch: 6| Step: 5
Training loss: 3.2043168544769287
Validation loss: 2.632192498894148

Epoch: 6| Step: 6
Training loss: 2.425151824951172
Validation loss: 2.6288300073275

Epoch: 6| Step: 7
Training loss: 1.86551833152771
Validation loss: 2.620542626227102

Epoch: 6| Step: 8
Training loss: 2.331821918487549
Validation loss: 2.6179385082696074

Epoch: 6| Step: 9
Training loss: 3.2080070972442627
Validation loss: 2.6143209947052823

Epoch: 6| Step: 10
Training loss: 3.093432664871216
Validation loss: 2.6164484895685667

Epoch: 6| Step: 11
Training loss: 4.003331184387207
Validation loss: 2.614157945879044

Epoch: 6| Step: 12
Training loss: 2.3515777587890625
Validation loss: 2.6210767671626103

Epoch: 6| Step: 13
Training loss: 3.2529454231262207
Validation loss: 2.616741124019828

Epoch: 26| Step: 0
Training loss: 2.6897335052490234
Validation loss: 2.618483522886871

Epoch: 6| Step: 1
Training loss: 2.2696120738983154
Validation loss: 2.6149280635259484

Epoch: 6| Step: 2
Training loss: 2.0466535091400146
Validation loss: 2.614114974134712

Epoch: 6| Step: 3
Training loss: 3.056230068206787
Validation loss: 2.611221759550033

Epoch: 6| Step: 4
Training loss: 2.5055418014526367
Validation loss: 2.6098626377762004

Epoch: 6| Step: 5
Training loss: 2.6295595169067383
Validation loss: 2.6133276160045336

Epoch: 6| Step: 6
Training loss: 3.8948235511779785
Validation loss: 2.6100408466913367

Epoch: 6| Step: 7
Training loss: 3.3436598777770996
Validation loss: 2.6124932765960693

Epoch: 6| Step: 8
Training loss: 2.92147159576416
Validation loss: 2.613421893888904

Epoch: 6| Step: 9
Training loss: 2.768868923187256
Validation loss: 2.6190779465501026

Epoch: 6| Step: 10
Training loss: 2.2267799377441406
Validation loss: 2.6243503914084485

Epoch: 6| Step: 11
Training loss: 3.336709976196289
Validation loss: 2.617465114080778

Epoch: 6| Step: 12
Training loss: 2.7038521766662598
Validation loss: 2.6074373798985637

Epoch: 6| Step: 13
Training loss: 2.604281425476074
Validation loss: 2.604818400516305

Epoch: 27| Step: 0
Training loss: 2.7091569900512695
Validation loss: 2.6085212512682845

Epoch: 6| Step: 1
Training loss: 2.176253318786621
Validation loss: 2.62737153678812

Epoch: 6| Step: 2
Training loss: 2.7883262634277344
Validation loss: 2.6460151749272502

Epoch: 6| Step: 3
Training loss: 2.4912166595458984
Validation loss: 2.622083674194992

Epoch: 6| Step: 4
Training loss: 3.1108036041259766
Validation loss: 2.614240533562117

Epoch: 6| Step: 5
Training loss: 2.5262112617492676
Validation loss: 2.60217252854378

Epoch: 6| Step: 6
Training loss: 2.615952253341675
Validation loss: 2.619612673277496

Epoch: 6| Step: 7
Training loss: 3.216568946838379
Validation loss: 2.64279527818003

Epoch: 6| Step: 8
Training loss: 2.737098217010498
Validation loss: 2.6338706298541

Epoch: 6| Step: 9
Training loss: 3.1253662109375
Validation loss: 2.6370188651546353

Epoch: 6| Step: 10
Training loss: 3.0550005435943604
Validation loss: 2.6386660760448826

Epoch: 6| Step: 11
Training loss: 3.694948196411133
Validation loss: 2.6384265371548232

Epoch: 6| Step: 12
Training loss: 2.7951014041900635
Validation loss: 2.6158448855082193

Epoch: 6| Step: 13
Training loss: 1.603686809539795
Validation loss: 2.5992237111573577

Epoch: 28| Step: 0
Training loss: 2.297855854034424
Validation loss: 2.60208547499872

Epoch: 6| Step: 1
Training loss: 3.4915788173675537
Validation loss: 2.6007675355480564

Epoch: 6| Step: 2
Training loss: 3.6155433654785156
Validation loss: 2.6057667014419392

Epoch: 6| Step: 3
Training loss: 2.5163698196411133
Validation loss: 2.6043404891926754

Epoch: 6| Step: 4
Training loss: 2.9953994750976562
Validation loss: 2.6064015126997426

Epoch: 6| Step: 5
Training loss: 2.341768264770508
Validation loss: 2.606633374767919

Epoch: 6| Step: 6
Training loss: 2.996487855911255
Validation loss: 2.6072494727309032

Epoch: 6| Step: 7
Training loss: 2.7687764167785645
Validation loss: 2.6042045162570093

Epoch: 6| Step: 8
Training loss: 2.8173718452453613
Validation loss: 2.5945563239435994

Epoch: 6| Step: 9
Training loss: 3.15999698638916
Validation loss: 2.5978813197023127

Epoch: 6| Step: 10
Training loss: 2.285770893096924
Validation loss: 2.5975463467259563

Epoch: 6| Step: 11
Training loss: 2.6679341793060303
Validation loss: 2.6004840430393013

Epoch: 6| Step: 12
Training loss: 2.376664638519287
Validation loss: 2.6028843413117113

Epoch: 6| Step: 13
Training loss: 2.571084976196289
Validation loss: 2.608572654826667

Epoch: 29| Step: 0
Training loss: 2.9802017211914062
Validation loss: 2.618860734406338

Epoch: 6| Step: 1
Training loss: 2.3756532669067383
Validation loss: 2.6181427407008346

Epoch: 6| Step: 2
Training loss: 2.6295218467712402
Validation loss: 2.609941118506975

Epoch: 6| Step: 3
Training loss: 2.7554478645324707
Validation loss: 2.6100108777323077

Epoch: 6| Step: 4
Training loss: 3.194471836090088
Validation loss: 2.601202626382151

Epoch: 6| Step: 5
Training loss: 2.112854242324829
Validation loss: 2.605465351894338

Epoch: 6| Step: 6
Training loss: 2.8758761882781982
Validation loss: 2.6092402973482685

Epoch: 6| Step: 7
Training loss: 2.1341824531555176
Validation loss: 2.6199495997480167

Epoch: 6| Step: 8
Training loss: 2.5060410499572754
Validation loss: 2.6251126053512737

Epoch: 6| Step: 9
Training loss: 3.1056714057922363
Validation loss: 2.614390339902652

Epoch: 6| Step: 10
Training loss: 3.143324851989746
Validation loss: 2.605538434879754

Epoch: 6| Step: 11
Training loss: 2.9146158695220947
Validation loss: 2.5928891525473645

Epoch: 6| Step: 12
Training loss: 3.0264341831207275
Validation loss: 2.595293098880399

Epoch: 6| Step: 13
Training loss: 3.392399311065674
Validation loss: 2.5991650986415085

Epoch: 30| Step: 0
Training loss: 2.0585904121398926
Validation loss: 2.604658034539992

Epoch: 6| Step: 1
Training loss: 2.089733123779297
Validation loss: 2.6105086931618313

Epoch: 6| Step: 2
Training loss: 3.460843563079834
Validation loss: 2.604513542626494

Epoch: 6| Step: 3
Training loss: 3.0235445499420166
Validation loss: 2.587233143468057

Epoch: 6| Step: 4
Training loss: 3.207827568054199
Validation loss: 2.5796111450400403

Epoch: 6| Step: 5
Training loss: 3.4446182250976562
Validation loss: 2.5825859551788657

Epoch: 6| Step: 6
Training loss: 2.5722620487213135
Validation loss: 2.5915948447360786

Epoch: 6| Step: 7
Training loss: 2.7745413780212402
Validation loss: 2.5994775320893977

Epoch: 6| Step: 8
Training loss: 3.1565380096435547
Validation loss: 2.5976962376666326

Epoch: 6| Step: 9
Training loss: 2.4970288276672363
Validation loss: 2.600195530922182

Epoch: 6| Step: 10
Training loss: 3.0672645568847656
Validation loss: 2.592187863524242

Epoch: 6| Step: 11
Training loss: 2.128281593322754
Validation loss: 2.580768403186593

Epoch: 6| Step: 12
Training loss: 2.6431968212127686
Validation loss: 2.5743348803571475

Epoch: 6| Step: 13
Training loss: 2.576303482055664
Validation loss: 2.5761273650712866

Epoch: 31| Step: 0
Training loss: 2.943033456802368
Validation loss: 2.578301506657754

Epoch: 6| Step: 1
Training loss: 2.053006410598755
Validation loss: 2.5763320384487027

Epoch: 6| Step: 2
Training loss: 2.344550609588623
Validation loss: 2.5779480882870254

Epoch: 6| Step: 3
Training loss: 2.860424041748047
Validation loss: 2.5835270253560876

Epoch: 6| Step: 4
Training loss: 2.798786163330078
Validation loss: 2.583118354120562

Epoch: 6| Step: 5
Training loss: 2.719564437866211
Validation loss: 2.5800162643514652

Epoch: 6| Step: 6
Training loss: 2.839458703994751
Validation loss: 2.5744310989174792

Epoch: 6| Step: 7
Training loss: 3.193542957305908
Validation loss: 2.57111604239351

Epoch: 6| Step: 8
Training loss: 3.05722713470459
Validation loss: 2.5715406607556086

Epoch: 6| Step: 9
Training loss: 3.151747465133667
Validation loss: 2.5730651040231027

Epoch: 6| Step: 10
Training loss: 2.8259754180908203
Validation loss: 2.5881398134334113

Epoch: 6| Step: 11
Training loss: 2.92573618888855
Validation loss: 2.600644334670036

Epoch: 6| Step: 12
Training loss: 2.255000114440918
Validation loss: 2.5934696761510705

Epoch: 6| Step: 13
Training loss: 2.9637794494628906
Validation loss: 2.5874969728531374

Epoch: 32| Step: 0
Training loss: 1.7282222509384155
Validation loss: 2.57497057607097

Epoch: 6| Step: 1
Training loss: 2.6893105506896973
Validation loss: 2.5667353342938166

Epoch: 6| Step: 2
Training loss: 3.8765242099761963
Validation loss: 2.5661453585470877

Epoch: 6| Step: 3
Training loss: 3.0007619857788086
Validation loss: 2.5635965152453353

Epoch: 6| Step: 4
Training loss: 3.1713690757751465
Validation loss: 2.5649431290165072

Epoch: 6| Step: 5
Training loss: 2.8584775924682617
Validation loss: 2.5650796633894726

Epoch: 6| Step: 6
Training loss: 3.3110718727111816
Validation loss: 2.566630376282559

Epoch: 6| Step: 7
Training loss: 3.1805620193481445
Validation loss: 2.561885428685014

Epoch: 6| Step: 8
Training loss: 1.5923750400543213
Validation loss: 2.563653015321301

Epoch: 6| Step: 9
Training loss: 2.448310136795044
Validation loss: 2.5645509483993694

Epoch: 6| Step: 10
Training loss: 3.183103322982788
Validation loss: 2.5653896434332735

Epoch: 6| Step: 11
Training loss: 2.2578587532043457
Validation loss: 2.5658156256521902

Epoch: 6| Step: 12
Training loss: 2.7967050075531006
Validation loss: 2.569413323556223

Epoch: 6| Step: 13
Training loss: 2.2085447311401367
Validation loss: 2.5625216858361357

Epoch: 33| Step: 0
Training loss: 3.021510362625122
Validation loss: 2.558679688361383

Epoch: 6| Step: 1
Training loss: 3.2236502170562744
Validation loss: 2.5495743418252594

Epoch: 6| Step: 2
Training loss: 2.5658786296844482
Validation loss: 2.551565957325761

Epoch: 6| Step: 3
Training loss: 2.564384937286377
Validation loss: 2.5527071542637323

Epoch: 6| Step: 4
Training loss: 3.3955535888671875
Validation loss: 2.5575200896109305

Epoch: 6| Step: 5
Training loss: 2.3345746994018555
Validation loss: 2.559463608649469

Epoch: 6| Step: 6
Training loss: 2.001112222671509
Validation loss: 2.5535888723147813

Epoch: 6| Step: 7
Training loss: 3.523603677749634
Validation loss: 2.5548263852314284

Epoch: 6| Step: 8
Training loss: 2.939175605773926
Validation loss: 2.55283607462401

Epoch: 6| Step: 9
Training loss: 3.008044719696045
Validation loss: 2.5508990774872484

Epoch: 6| Step: 10
Training loss: 2.891118049621582
Validation loss: 2.5492696377538864

Epoch: 6| Step: 11
Training loss: 1.8442561626434326
Validation loss: 2.5496542787039154

Epoch: 6| Step: 12
Training loss: 2.6273984909057617
Validation loss: 2.548973245005454

Epoch: 6| Step: 13
Training loss: 2.1081550121307373
Validation loss: 2.547522819170388

Epoch: 34| Step: 0
Training loss: 2.5048537254333496
Validation loss: 2.546124004548596

Epoch: 6| Step: 1
Training loss: 3.1636009216308594
Validation loss: 2.545492469623525

Epoch: 6| Step: 2
Training loss: 2.8804702758789062
Validation loss: 2.5429197639547367

Epoch: 6| Step: 3
Training loss: 1.9696857929229736
Validation loss: 2.5468832113409556

Epoch: 6| Step: 4
Training loss: 3.0321292877197266
Validation loss: 2.5432595386300036

Epoch: 6| Step: 5
Training loss: 2.9671454429626465
Validation loss: 2.540234224770659

Epoch: 6| Step: 6
Training loss: 2.3794591426849365
Validation loss: 2.547813876982658

Epoch: 6| Step: 7
Training loss: 2.5732338428497314
Validation loss: 2.558521145133562

Epoch: 6| Step: 8
Training loss: 2.5980658531188965
Validation loss: 2.5600957255209646

Epoch: 6| Step: 9
Training loss: 3.2469964027404785
Validation loss: 2.566456781920566

Epoch: 6| Step: 10
Training loss: 2.307270050048828
Validation loss: 2.5613781662397486

Epoch: 6| Step: 11
Training loss: 3.2008190155029297
Validation loss: 2.5583692596804712

Epoch: 6| Step: 12
Training loss: 2.2494449615478516
Validation loss: 2.5370594839895926

Epoch: 6| Step: 13
Training loss: 3.6006431579589844
Validation loss: 2.526671992835178

Epoch: 35| Step: 0
Training loss: 3.34364652633667
Validation loss: 2.528945440887123

Epoch: 6| Step: 1
Training loss: 3.1447651386260986
Validation loss: 2.535542962371662

Epoch: 6| Step: 2
Training loss: 3.2764840126037598
Validation loss: 2.551935047231695

Epoch: 6| Step: 3
Training loss: 2.7408175468444824
Validation loss: 2.556480940952096

Epoch: 6| Step: 4
Training loss: 2.732309341430664
Validation loss: 2.5439401544550413

Epoch: 6| Step: 5
Training loss: 2.1001007556915283
Validation loss: 2.536050578599335

Epoch: 6| Step: 6
Training loss: 1.9259793758392334
Validation loss: 2.5234068593671246

Epoch: 6| Step: 7
Training loss: 2.811225414276123
Validation loss: 2.538219628795501

Epoch: 6| Step: 8
Training loss: 2.437012195587158
Validation loss: 2.543191655989616

Epoch: 6| Step: 9
Training loss: 2.7204363346099854
Validation loss: 2.5465127165599535

Epoch: 6| Step: 10
Training loss: 3.016239881515503
Validation loss: 2.5488082952396844

Epoch: 6| Step: 11
Training loss: 2.9452028274536133
Validation loss: 2.549161370082568

Epoch: 6| Step: 12
Training loss: 2.3300395011901855
Validation loss: 2.5461285934653333

Epoch: 6| Step: 13
Training loss: 2.989440441131592
Validation loss: 2.529211426293978

Epoch: 36| Step: 0
Training loss: 3.3216302394866943
Validation loss: 2.530827458186816

Epoch: 6| Step: 1
Training loss: 1.9944334030151367
Validation loss: 2.527288708635556

Epoch: 6| Step: 2
Training loss: 3.4402894973754883
Validation loss: 2.5187327528512604

Epoch: 6| Step: 3
Training loss: 2.416825294494629
Validation loss: 2.524365343073363

Epoch: 6| Step: 4
Training loss: 3.1372604370117188
Validation loss: 2.5176505222115466

Epoch: 6| Step: 5
Training loss: 2.4100522994995117
Validation loss: 2.5185473836878294

Epoch: 6| Step: 6
Training loss: 2.928438663482666
Validation loss: 2.5192794133258123

Epoch: 6| Step: 7
Training loss: 3.15913724899292
Validation loss: 2.5155718608569075

Epoch: 6| Step: 8
Training loss: 2.7203798294067383
Validation loss: 2.5149673672132593

Epoch: 6| Step: 9
Training loss: 2.1086225509643555
Validation loss: 2.519238168193448

Epoch: 6| Step: 10
Training loss: 3.111510753631592
Validation loss: 2.524512429391184

Epoch: 6| Step: 11
Training loss: 2.1118993759155273
Validation loss: 2.5259785882888304

Epoch: 6| Step: 12
Training loss: 1.7888007164001465
Validation loss: 2.5287239372089343

Epoch: 6| Step: 13
Training loss: 3.823415994644165
Validation loss: 2.526154687327723

Epoch: 37| Step: 0
Training loss: 2.9945006370544434
Validation loss: 2.526474368187689

Epoch: 6| Step: 1
Training loss: 2.554258346557617
Validation loss: 2.525196757367862

Epoch: 6| Step: 2
Training loss: 2.3877291679382324
Validation loss: 2.525828666584466

Epoch: 6| Step: 3
Training loss: 2.5570974349975586
Validation loss: 2.5243659839835217

Epoch: 6| Step: 4
Training loss: 2.704056978225708
Validation loss: 2.534631690671367

Epoch: 6| Step: 5
Training loss: 1.8442988395690918
Validation loss: 2.54678508030471

Epoch: 6| Step: 6
Training loss: 2.3711609840393066
Validation loss: 2.5429262935474353

Epoch: 6| Step: 7
Training loss: 2.705930709838867
Validation loss: 2.5439551722618843

Epoch: 6| Step: 8
Training loss: 2.6925559043884277
Validation loss: 2.5435156360749276

Epoch: 6| Step: 9
Training loss: 2.6982522010803223
Validation loss: 2.5406255375954414

Epoch: 6| Step: 10
Training loss: 3.3429672718048096
Validation loss: 2.5272517101739043

Epoch: 6| Step: 11
Training loss: 4.114827632904053
Validation loss: 2.517231079839891

Epoch: 6| Step: 12
Training loss: 2.7593276500701904
Validation loss: 2.514881908252675

Epoch: 6| Step: 13
Training loss: 2.0593342781066895
Validation loss: 2.508971793677217

Epoch: 38| Step: 0
Training loss: 2.800853729248047
Validation loss: 2.509091370849199

Epoch: 6| Step: 1
Training loss: 2.933382034301758
Validation loss: 2.5088175009655695

Epoch: 6| Step: 2
Training loss: 2.384492874145508
Validation loss: 2.512463585022957

Epoch: 6| Step: 3
Training loss: 2.922942638397217
Validation loss: 2.5179899507953274

Epoch: 6| Step: 4
Training loss: 2.5375800132751465
Validation loss: 2.508745167845039

Epoch: 6| Step: 5
Training loss: 2.675189971923828
Validation loss: 2.5154667413362892

Epoch: 6| Step: 6
Training loss: 2.3555915355682373
Validation loss: 2.524054483700824

Epoch: 6| Step: 7
Training loss: 3.1782031059265137
Validation loss: 2.550971382407732

Epoch: 6| Step: 8
Training loss: 2.6016383171081543
Validation loss: 2.5619823445555983

Epoch: 6| Step: 9
Training loss: 2.823286533355713
Validation loss: 2.56013261887335

Epoch: 6| Step: 10
Training loss: 2.2001686096191406
Validation loss: 2.562238524037023

Epoch: 6| Step: 11
Training loss: 3.191645860671997
Validation loss: 2.554698667218608

Epoch: 6| Step: 12
Training loss: 2.97769832611084
Validation loss: 2.5334997612942933

Epoch: 6| Step: 13
Training loss: 2.3376691341400146
Validation loss: 2.521539436873569

Epoch: 39| Step: 0
Training loss: 3.028935432434082
Validation loss: 2.5130943380376345

Epoch: 6| Step: 1
Training loss: 1.8997057676315308
Validation loss: 2.511308644407539

Epoch: 6| Step: 2
Training loss: 2.768982410430908
Validation loss: 2.5081447016808296

Epoch: 6| Step: 3
Training loss: 2.9795451164245605
Validation loss: 2.5110376214468353

Epoch: 6| Step: 4
Training loss: 3.0705392360687256
Validation loss: 2.512678397599087

Epoch: 6| Step: 5
Training loss: 2.6407785415649414
Validation loss: 2.5124878319360877

Epoch: 6| Step: 6
Training loss: 3.1091456413269043
Validation loss: 2.5134529067624

Epoch: 6| Step: 7
Training loss: 2.9282174110412598
Validation loss: 2.510555439097907

Epoch: 6| Step: 8
Training loss: 2.878917694091797
Validation loss: 2.5089686121991885

Epoch: 6| Step: 9
Training loss: 2.526569366455078
Validation loss: 2.5077725482243363

Epoch: 6| Step: 10
Training loss: 2.32080078125
Validation loss: 2.5068376653937885

Epoch: 6| Step: 11
Training loss: 2.213899612426758
Validation loss: 2.5138802272017284

Epoch: 6| Step: 12
Training loss: 2.533898115158081
Validation loss: 2.5302131457995345

Epoch: 6| Step: 13
Training loss: 3.225280284881592
Validation loss: 2.5333355472933863

Epoch: 40| Step: 0
Training loss: 2.4905943870544434
Validation loss: 2.520336630523846

Epoch: 6| Step: 1
Training loss: 2.907121419906616
Validation loss: 2.516014386248845

Epoch: 6| Step: 2
Training loss: 3.033702850341797
Validation loss: 2.514888637809343

Epoch: 6| Step: 3
Training loss: 2.545078754425049
Validation loss: 2.512424176739108

Epoch: 6| Step: 4
Training loss: 2.6778039932250977
Validation loss: 2.507939569411739

Epoch: 6| Step: 5
Training loss: 2.8705554008483887
Validation loss: 2.5104255650633123

Epoch: 6| Step: 6
Training loss: 3.0573225021362305
Validation loss: 2.5079293353583223

Epoch: 6| Step: 7
Training loss: 2.859804630279541
Validation loss: 2.4995870333845898

Epoch: 6| Step: 8
Training loss: 2.9651877880096436
Validation loss: 2.4988283649567635

Epoch: 6| Step: 9
Training loss: 2.6976397037506104
Validation loss: 2.497655104565364

Epoch: 6| Step: 10
Training loss: 2.4228429794311523
Validation loss: 2.4980303292633383

Epoch: 6| Step: 11
Training loss: 2.8833506107330322
Validation loss: 2.505083473779822

Epoch: 6| Step: 12
Training loss: 1.6660587787628174
Validation loss: 2.4947384121597453

Epoch: 6| Step: 13
Training loss: 2.5689117908477783
Validation loss: 2.4972348943833382

Epoch: 41| Step: 0
Training loss: 2.097013473510742
Validation loss: 2.5024746746145268

Epoch: 6| Step: 1
Training loss: 2.08054256439209
Validation loss: 2.5073430384359052

Epoch: 6| Step: 2
Training loss: 2.8694443702697754
Validation loss: 2.5093832631264963

Epoch: 6| Step: 3
Training loss: 2.76702880859375
Validation loss: 2.511937120909332

Epoch: 6| Step: 4
Training loss: 3.176532745361328
Validation loss: 2.513228419006512

Epoch: 6| Step: 5
Training loss: 2.561554431915283
Validation loss: 2.512232167746431

Epoch: 6| Step: 6
Training loss: 2.7709155082702637
Validation loss: 2.5035895173267653

Epoch: 6| Step: 7
Training loss: 2.9943435192108154
Validation loss: 2.488992444930538

Epoch: 6| Step: 8
Training loss: 2.7885804176330566
Validation loss: 2.48702972678728

Epoch: 6| Step: 9
Training loss: 2.794210195541382
Validation loss: 2.4833349361214587

Epoch: 6| Step: 10
Training loss: 2.510789394378662
Validation loss: 2.487606325457173

Epoch: 6| Step: 11
Training loss: 2.8562960624694824
Validation loss: 2.4863028577578965

Epoch: 6| Step: 12
Training loss: 2.6851913928985596
Validation loss: 2.491130421238561

Epoch: 6| Step: 13
Training loss: 2.7294044494628906
Validation loss: 2.49177650995152

Epoch: 42| Step: 0
Training loss: 2.748962879180908
Validation loss: 2.5013151655914965

Epoch: 6| Step: 1
Training loss: 2.614027738571167
Validation loss: 2.4951908960137317

Epoch: 6| Step: 2
Training loss: 2.4332563877105713
Validation loss: 2.4938447167796474

Epoch: 6| Step: 3
Training loss: 3.089334487915039
Validation loss: 2.4862796696283485

Epoch: 6| Step: 4
Training loss: 2.6943106651306152
Validation loss: 2.4853527187019266

Epoch: 6| Step: 5
Training loss: 2.6091389656066895
Validation loss: 2.485884366496917

Epoch: 6| Step: 6
Training loss: 2.7979323863983154
Validation loss: 2.4918641864612536

Epoch: 6| Step: 7
Training loss: 2.377634048461914
Validation loss: 2.4877421138107136

Epoch: 6| Step: 8
Training loss: 2.58036732673645
Validation loss: 2.502138988946074

Epoch: 6| Step: 9
Training loss: 2.6659131050109863
Validation loss: 2.518517663401942

Epoch: 6| Step: 10
Training loss: 2.7801270484924316
Validation loss: 2.5307550276479414

Epoch: 6| Step: 11
Training loss: 2.8038620948791504
Validation loss: 2.5187641779581704

Epoch: 6| Step: 12
Training loss: 2.5282769203186035
Validation loss: 2.510580955013152

Epoch: 6| Step: 13
Training loss: 3.321601390838623
Validation loss: 2.497684553105344

Epoch: 43| Step: 0
Training loss: 2.6247763633728027
Validation loss: 2.4900879039559314

Epoch: 6| Step: 1
Training loss: 3.0636720657348633
Validation loss: 2.4840247169617684

Epoch: 6| Step: 2
Training loss: 3.2185277938842773
Validation loss: 2.498279695869774

Epoch: 6| Step: 3
Training loss: 2.88417387008667
Validation loss: 2.514318448241039

Epoch: 6| Step: 4
Training loss: 2.361682415008545
Validation loss: 2.5315128398197952

Epoch: 6| Step: 5
Training loss: 2.4478750228881836
Validation loss: 2.5435973854475122

Epoch: 6| Step: 6
Training loss: 2.165853261947632
Validation loss: 2.558095916624992

Epoch: 6| Step: 7
Training loss: 3.667825698852539
Validation loss: 2.566366244387883

Epoch: 6| Step: 8
Training loss: 2.544003486633301
Validation loss: 2.5670892371926257

Epoch: 6| Step: 9
Training loss: 3.1863389015197754
Validation loss: 2.556087488769203

Epoch: 6| Step: 10
Training loss: 2.444002628326416
Validation loss: 2.550620448204779

Epoch: 6| Step: 11
Training loss: 3.079519271850586
Validation loss: 2.539804907255275

Epoch: 6| Step: 12
Training loss: 2.2509872913360596
Validation loss: 2.510230359210763

Epoch: 6| Step: 13
Training loss: 1.662302851676941
Validation loss: 2.496583548925256

Epoch: 44| Step: 0
Training loss: 2.3497538566589355
Validation loss: 2.484809167923466

Epoch: 6| Step: 1
Training loss: 2.505509853363037
Validation loss: 2.470609088097849

Epoch: 6| Step: 2
Training loss: 2.8009328842163086
Validation loss: 2.4736115676100536

Epoch: 6| Step: 3
Training loss: 3.1468260288238525
Validation loss: 2.4737069376053347

Epoch: 6| Step: 4
Training loss: 2.1128549575805664
Validation loss: 2.476937340151879

Epoch: 6| Step: 5
Training loss: 3.3786520957946777
Validation loss: 2.4752974561465684

Epoch: 6| Step: 6
Training loss: 2.970559597015381
Validation loss: 2.496947899941475

Epoch: 6| Step: 7
Training loss: 2.7994065284729004
Validation loss: 2.5175536806865404

Epoch: 6| Step: 8
Training loss: 2.2671408653259277
Validation loss: 2.537281531159596

Epoch: 6| Step: 9
Training loss: 2.807730197906494
Validation loss: 2.550288482378888

Epoch: 6| Step: 10
Training loss: 2.1668219566345215
Validation loss: 2.5245734542928715

Epoch: 6| Step: 11
Training loss: 2.885220527648926
Validation loss: 2.5103739205227105

Epoch: 6| Step: 12
Training loss: 2.597493886947632
Validation loss: 2.4811904712389876

Epoch: 6| Step: 13
Training loss: 3.209043025970459
Validation loss: 2.474834701066376

Epoch: 45| Step: 0
Training loss: 2.0783872604370117
Validation loss: 2.477833576099847

Epoch: 6| Step: 1
Training loss: 3.6027469635009766
Validation loss: 2.47774492027939

Epoch: 6| Step: 2
Training loss: 2.2545275688171387
Validation loss: 2.4913147546911754

Epoch: 6| Step: 3
Training loss: 2.1992785930633545
Validation loss: 2.4938920031311693

Epoch: 6| Step: 4
Training loss: 2.8231959342956543
Validation loss: 2.5014745958389772

Epoch: 6| Step: 5
Training loss: 2.9635043144226074
Validation loss: 2.509775883408003

Epoch: 6| Step: 6
Training loss: 3.0001749992370605
Validation loss: 2.500892457141671

Epoch: 6| Step: 7
Training loss: 3.114917039871216
Validation loss: 2.5021509944751696

Epoch: 6| Step: 8
Training loss: 2.415846824645996
Validation loss: 2.4898016927062825

Epoch: 6| Step: 9
Training loss: 2.6677565574645996
Validation loss: 2.481571969165597

Epoch: 6| Step: 10
Training loss: 2.7035017013549805
Validation loss: 2.478600048249768

Epoch: 6| Step: 11
Training loss: 1.8150471448898315
Validation loss: 2.4799921256239696

Epoch: 6| Step: 12
Training loss: 3.2824273109436035
Validation loss: 2.482311305179391

Epoch: 6| Step: 13
Training loss: 2.845156669616699
Validation loss: 2.4827747191152265

Epoch: 46| Step: 0
Training loss: 2.6352105140686035
Validation loss: 2.4831119737317486

Epoch: 6| Step: 1
Training loss: 2.51041316986084
Validation loss: 2.486601993601809

Epoch: 6| Step: 2
Training loss: 3.259263515472412
Validation loss: 2.487022904939549

Epoch: 6| Step: 3
Training loss: 2.496751070022583
Validation loss: 2.485423134219262

Epoch: 6| Step: 4
Training loss: 2.4320220947265625
Validation loss: 2.482562167670137

Epoch: 6| Step: 5
Training loss: 2.9626245498657227
Validation loss: 2.4820528568760043

Epoch: 6| Step: 6
Training loss: 2.403693199157715
Validation loss: 2.475018480772613

Epoch: 6| Step: 7
Training loss: 2.4342522621154785
Validation loss: 2.4660064379374185

Epoch: 6| Step: 8
Training loss: 2.593071222305298
Validation loss: 2.470543025642313

Epoch: 6| Step: 9
Training loss: 2.8704495429992676
Validation loss: 2.4722553760774675

Epoch: 6| Step: 10
Training loss: 2.329594850540161
Validation loss: 2.490575785277992

Epoch: 6| Step: 11
Training loss: 2.7451963424682617
Validation loss: 2.495657818291777

Epoch: 6| Step: 12
Training loss: 3.249549388885498
Validation loss: 2.4808023488649757

Epoch: 6| Step: 13
Training loss: 2.5846445560455322
Validation loss: 2.4625954089626187

Epoch: 47| Step: 0
Training loss: 2.442269802093506
Validation loss: 2.458490643450009

Epoch: 6| Step: 1
Training loss: 2.872790813446045
Validation loss: 2.4604872016496557

Epoch: 6| Step: 2
Training loss: 2.4952340126037598
Validation loss: 2.4643190189074446

Epoch: 6| Step: 3
Training loss: 3.088273525238037
Validation loss: 2.4631314277648926

Epoch: 6| Step: 4
Training loss: 2.4351513385772705
Validation loss: 2.4618497099927676

Epoch: 6| Step: 5
Training loss: 3.0780932903289795
Validation loss: 2.460076226983019

Epoch: 6| Step: 6
Training loss: 2.335484027862549
Validation loss: 2.457492656605218

Epoch: 6| Step: 7
Training loss: 2.55427885055542
Validation loss: 2.4586771918881323

Epoch: 6| Step: 8
Training loss: 2.6870250701904297
Validation loss: 2.4520599124252156

Epoch: 6| Step: 9
Training loss: 2.3472211360931396
Validation loss: 2.4545699011894966

Epoch: 6| Step: 10
Training loss: 3.2223711013793945
Validation loss: 2.4467158240656697

Epoch: 6| Step: 11
Training loss: 2.9076128005981445
Validation loss: 2.4487772116097073

Epoch: 6| Step: 12
Training loss: 2.4104113578796387
Validation loss: 2.4612978350731636

Epoch: 6| Step: 13
Training loss: 2.5844905376434326
Validation loss: 2.466058636224398

Epoch: 48| Step: 0
Training loss: 2.867176055908203
Validation loss: 2.4756923285863732

Epoch: 6| Step: 1
Training loss: 2.7642626762390137
Validation loss: 2.4903631235963557

Epoch: 6| Step: 2
Training loss: 2.5664749145507812
Validation loss: 2.4895950491710375

Epoch: 6| Step: 3
Training loss: 2.6794838905334473
Validation loss: 2.4857261462878157

Epoch: 6| Step: 4
Training loss: 2.573791980743408
Validation loss: 2.472994419836229

Epoch: 6| Step: 5
Training loss: 2.480894088745117
Validation loss: 2.4564373365012546

Epoch: 6| Step: 6
Training loss: 3.0719661712646484
Validation loss: 2.4535469239757908

Epoch: 6| Step: 7
Training loss: 1.9233232736587524
Validation loss: 2.447610015510231

Epoch: 6| Step: 8
Training loss: 2.234072208404541
Validation loss: 2.444661683933709

Epoch: 6| Step: 9
Training loss: 3.0952610969543457
Validation loss: 2.4473422983641266

Epoch: 6| Step: 10
Training loss: 2.753420829772949
Validation loss: 2.44729289444544

Epoch: 6| Step: 11
Training loss: 3.1192970275878906
Validation loss: 2.456916014353434

Epoch: 6| Step: 12
Training loss: 2.862746238708496
Validation loss: 2.456063134695894

Epoch: 6| Step: 13
Training loss: 2.4072461128234863
Validation loss: 2.4558100162013883

Epoch: 49| Step: 0
Training loss: 2.6126017570495605
Validation loss: 2.4556995771264516

Epoch: 6| Step: 1
Training loss: 3.000863790512085
Validation loss: 2.4619664504963863

Epoch: 6| Step: 2
Training loss: 1.8217087984085083
Validation loss: 2.45807150871523

Epoch: 6| Step: 3
Training loss: 3.076580047607422
Validation loss: 2.4615356845240437

Epoch: 6| Step: 4
Training loss: 2.3778281211853027
Validation loss: 2.462121799427976

Epoch: 6| Step: 5
Training loss: 2.4816360473632812
Validation loss: 2.4620561163912535

Epoch: 6| Step: 6
Training loss: 3.057042121887207
Validation loss: 2.4552318896016767

Epoch: 6| Step: 7
Training loss: 2.4990620613098145
Validation loss: 2.4594490861379974

Epoch: 6| Step: 8
Training loss: 2.358104705810547
Validation loss: 2.460198404968426

Epoch: 6| Step: 9
Training loss: 3.2965736389160156
Validation loss: 2.4577596033773115

Epoch: 6| Step: 10
Training loss: 1.9454727172851562
Validation loss: 2.467649882839572

Epoch: 6| Step: 11
Training loss: 2.9606051445007324
Validation loss: 2.4799663917992705

Epoch: 6| Step: 12
Training loss: 3.0666141510009766
Validation loss: 2.4980754698476484

Epoch: 6| Step: 13
Training loss: 2.859692335128784
Validation loss: 2.5002462671649073

Epoch: 50| Step: 0
Training loss: 2.183234453201294
Validation loss: 2.493546365409769

Epoch: 6| Step: 1
Training loss: 3.1926729679107666
Validation loss: 2.4955400497682634

Epoch: 6| Step: 2
Training loss: 2.358757972717285
Validation loss: 2.4889419642827844

Epoch: 6| Step: 3
Training loss: 2.53963565826416
Validation loss: 2.4790084374848234

Epoch: 6| Step: 4
Training loss: 2.6655659675598145
Validation loss: 2.4718502490751204

Epoch: 6| Step: 5
Training loss: 2.169389486312866
Validation loss: 2.469885577437698

Epoch: 6| Step: 6
Training loss: 2.606050968170166
Validation loss: 2.4716610959781113

Epoch: 6| Step: 7
Training loss: 3.0152041912078857
Validation loss: 2.4762883647795646

Epoch: 6| Step: 8
Training loss: 2.9624381065368652
Validation loss: 2.470517079035441

Epoch: 6| Step: 9
Training loss: 2.7449147701263428
Validation loss: 2.475303160246982

Epoch: 6| Step: 10
Training loss: 2.7375173568725586
Validation loss: 2.4697617561586442

Epoch: 6| Step: 11
Training loss: 2.1655611991882324
Validation loss: 2.461498886026362

Epoch: 6| Step: 12
Training loss: 3.652554988861084
Validation loss: 2.4544295213555776

Epoch: 6| Step: 13
Training loss: 1.9913842678070068
Validation loss: 2.4456300991837696

Epoch: 51| Step: 0
Training loss: 2.77829909324646
Validation loss: 2.448188643301687

Epoch: 6| Step: 1
Training loss: 2.4132564067840576
Validation loss: 2.4414356934126986

Epoch: 6| Step: 2
Training loss: 2.3766682147979736
Validation loss: 2.4416579277284685

Epoch: 6| Step: 3
Training loss: 2.2132270336151123
Validation loss: 2.4415563434682865

Epoch: 6| Step: 4
Training loss: 2.502072811126709
Validation loss: 2.4391569475973807

Epoch: 6| Step: 5
Training loss: 2.800408363342285
Validation loss: 2.434292980419692

Epoch: 6| Step: 6
Training loss: 2.8994526863098145
Validation loss: 2.4386698558766353

Epoch: 6| Step: 7
Training loss: 2.74232816696167
Validation loss: 2.4328485714491976

Epoch: 6| Step: 8
Training loss: 2.831359386444092
Validation loss: 2.4377258311035814

Epoch: 6| Step: 9
Training loss: 2.802888870239258
Validation loss: 2.4416046783488285

Epoch: 6| Step: 10
Training loss: 3.33357834815979
Validation loss: 2.4430173084300053

Epoch: 6| Step: 11
Training loss: 2.4391932487487793
Validation loss: 2.4398113219968733

Epoch: 6| Step: 12
Training loss: 2.4053232669830322
Validation loss: 2.4475386347821964

Epoch: 6| Step: 13
Training loss: 2.77347469329834
Validation loss: 2.4583748591843473

Epoch: 52| Step: 0
Training loss: 2.280860424041748
Validation loss: 2.4698143902645318

Epoch: 6| Step: 1
Training loss: 2.77091646194458
Validation loss: 2.4715644749262

Epoch: 6| Step: 2
Training loss: 2.4255588054656982
Validation loss: 2.4788052561462566

Epoch: 6| Step: 3
Training loss: 2.5944550037384033
Validation loss: 2.4859386797874206

Epoch: 6| Step: 4
Training loss: 2.536665916442871
Validation loss: 2.4898454784065165

Epoch: 6| Step: 5
Training loss: 3.1119167804718018
Validation loss: 2.4825711045213925

Epoch: 6| Step: 6
Training loss: 2.419708490371704
Validation loss: 2.4931264872192056

Epoch: 6| Step: 7
Training loss: 2.677781820297241
Validation loss: 2.49064617003164

Epoch: 6| Step: 8
Training loss: 2.1483330726623535
Validation loss: 2.4940211849827922

Epoch: 6| Step: 9
Training loss: 2.8899788856506348
Validation loss: 2.5134618205408894

Epoch: 6| Step: 10
Training loss: 2.3457155227661133
Validation loss: 2.528240483294251

Epoch: 6| Step: 11
Training loss: 2.6987295150756836
Validation loss: 2.531637627591369

Epoch: 6| Step: 12
Training loss: 3.1058590412139893
Validation loss: 2.507395021377071

Epoch: 6| Step: 13
Training loss: 3.8982009887695312
Validation loss: 2.483440678606751

Epoch: 53| Step: 0
Training loss: 2.920407295227051
Validation loss: 2.4679265432460333

Epoch: 6| Step: 1
Training loss: 2.67067813873291
Validation loss: 2.4571904033742924

Epoch: 6| Step: 2
Training loss: 3.2410202026367188
Validation loss: 2.4723907234848186

Epoch: 6| Step: 3
Training loss: 3.1197540760040283
Validation loss: 2.499582390631399

Epoch: 6| Step: 4
Training loss: 2.4512693881988525
Validation loss: 2.52738376843032

Epoch: 6| Step: 5
Training loss: 2.9785099029541016
Validation loss: 2.5348920873416367

Epoch: 6| Step: 6
Training loss: 3.041780948638916
Validation loss: 2.5141033587917203

Epoch: 6| Step: 7
Training loss: 2.295069694519043
Validation loss: 2.4955493045109574

Epoch: 6| Step: 8
Training loss: 2.5199928283691406
Validation loss: 2.467163734538581

Epoch: 6| Step: 9
Training loss: 2.0951480865478516
Validation loss: 2.451297337009061

Epoch: 6| Step: 10
Training loss: 3.0223960876464844
Validation loss: 2.443885321258217

Epoch: 6| Step: 11
Training loss: 2.842360496520996
Validation loss: 2.447581555253716

Epoch: 6| Step: 12
Training loss: 2.0788915157318115
Validation loss: 2.454768555138701

Epoch: 6| Step: 13
Training loss: 1.9221305847167969
Validation loss: 2.4575640642514793

Epoch: 54| Step: 0
Training loss: 2.9820261001586914
Validation loss: 2.4712606117289555

Epoch: 6| Step: 1
Training loss: 2.6068243980407715
Validation loss: 2.459051670566682

Epoch: 6| Step: 2
Training loss: 2.8227601051330566
Validation loss: 2.455286154183008

Epoch: 6| Step: 3
Training loss: 2.848283290863037
Validation loss: 2.4442010746207288

Epoch: 6| Step: 4
Training loss: 2.6436214447021484
Validation loss: 2.446100616967806

Epoch: 6| Step: 5
Training loss: 2.208798885345459
Validation loss: 2.437488748181251

Epoch: 6| Step: 6
Training loss: 2.5654656887054443
Validation loss: 2.448191729925012

Epoch: 6| Step: 7
Training loss: 3.267317056655884
Validation loss: 2.445488755420972

Epoch: 6| Step: 8
Training loss: 2.45017147064209
Validation loss: 2.4471995574171825

Epoch: 6| Step: 9
Training loss: 2.41019606590271
Validation loss: 2.439643462498983

Epoch: 6| Step: 10
Training loss: 2.0186800956726074
Validation loss: 2.4372722230931765

Epoch: 6| Step: 11
Training loss: 2.292896270751953
Validation loss: 2.434670832849318

Epoch: 6| Step: 12
Training loss: 2.6056458950042725
Validation loss: 2.437238823982977

Epoch: 6| Step: 13
Training loss: 4.055240631103516
Validation loss: 2.444357982245825

Epoch: 55| Step: 0
Training loss: 2.3795456886291504
Validation loss: 2.450296396850258

Epoch: 6| Step: 1
Training loss: 2.4115171432495117
Validation loss: 2.450180535675377

Epoch: 6| Step: 2
Training loss: 3.190730333328247
Validation loss: 2.4415006688846055

Epoch: 6| Step: 3
Training loss: 2.272195816040039
Validation loss: 2.4310981714597313

Epoch: 6| Step: 4
Training loss: 2.56020450592041
Validation loss: 2.436357703260196

Epoch: 6| Step: 5
Training loss: 2.8521459102630615
Validation loss: 2.4437995956790064

Epoch: 6| Step: 6
Training loss: 2.2309536933898926
Validation loss: 2.4706035813977643

Epoch: 6| Step: 7
Training loss: 2.5655555725097656
Validation loss: 2.4939132249483498

Epoch: 6| Step: 8
Training loss: 2.483062982559204
Validation loss: 2.4864627186970045

Epoch: 6| Step: 9
Training loss: 2.4907031059265137
Validation loss: 2.466189851043045

Epoch: 6| Step: 10
Training loss: 2.733880043029785
Validation loss: 2.4301463019463325

Epoch: 6| Step: 11
Training loss: 2.753925323486328
Validation loss: 2.417869475580031

Epoch: 6| Step: 12
Training loss: 3.123697519302368
Validation loss: 2.4121289048143613

Epoch: 6| Step: 13
Training loss: 3.8427865505218506
Validation loss: 2.4128079055457987

Epoch: 56| Step: 0
Training loss: 3.18168306350708
Validation loss: 2.4223057377722954

Epoch: 6| Step: 1
Training loss: 2.4541802406311035
Validation loss: 2.4225224628243396

Epoch: 6| Step: 2
Training loss: 3.0239522457122803
Validation loss: 2.422360763754896

Epoch: 6| Step: 3
Training loss: 2.2111120223999023
Validation loss: 2.4239567313143002

Epoch: 6| Step: 4
Training loss: 3.002269744873047
Validation loss: 2.4225485478678057

Epoch: 6| Step: 5
Training loss: 2.4296555519104004
Validation loss: 2.420388380686442

Epoch: 6| Step: 6
Training loss: 3.2302870750427246
Validation loss: 2.417709283931281

Epoch: 6| Step: 7
Training loss: 2.2343955039978027
Validation loss: 2.4155024892540387

Epoch: 6| Step: 8
Training loss: 2.118096113204956
Validation loss: 2.41595624339196

Epoch: 6| Step: 9
Training loss: 2.740204095840454
Validation loss: 2.4217693472421296

Epoch: 6| Step: 10
Training loss: 2.398940086364746
Validation loss: 2.4454807260985016

Epoch: 6| Step: 11
Training loss: 2.811803102493286
Validation loss: 2.4729774510988625

Epoch: 6| Step: 12
Training loss: 2.2368102073669434
Validation loss: 2.4782875327653784

Epoch: 6| Step: 13
Training loss: 3.4485597610473633
Validation loss: 2.454510017107892

Epoch: 57| Step: 0
Training loss: 3.20731782913208
Validation loss: 2.4244538686608754

Epoch: 6| Step: 1
Training loss: 2.0631678104400635
Validation loss: 2.4223819855720765

Epoch: 6| Step: 2
Training loss: 2.94879150390625
Validation loss: 2.4310670104078067

Epoch: 6| Step: 3
Training loss: 2.3279945850372314
Validation loss: 2.4315521563253095

Epoch: 6| Step: 4
Training loss: 3.0441203117370605
Validation loss: 2.43648354212443

Epoch: 6| Step: 5
Training loss: 2.7350058555603027
Validation loss: 2.442155789303523

Epoch: 6| Step: 6
Training loss: 2.8075549602508545
Validation loss: 2.452147704298778

Epoch: 6| Step: 7
Training loss: 1.9577736854553223
Validation loss: 2.452838772086687

Epoch: 6| Step: 8
Training loss: 2.131608009338379
Validation loss: 2.4367043587469284

Epoch: 6| Step: 9
Training loss: 2.994137763977051
Validation loss: 2.4216892180904264

Epoch: 6| Step: 10
Training loss: 2.4814510345458984
Validation loss: 2.416382651175222

Epoch: 6| Step: 11
Training loss: 3.4940414428710938
Validation loss: 2.4118633552264144

Epoch: 6| Step: 12
Training loss: 2.3645124435424805
Validation loss: 2.409638435609879

Epoch: 6| Step: 13
Training loss: 2.4778857231140137
Validation loss: 2.408059145814629

Epoch: 58| Step: 0
Training loss: 2.818234920501709
Validation loss: 2.405950048918365

Epoch: 6| Step: 1
Training loss: 2.3610928058624268
Validation loss: 2.408239636369931

Epoch: 6| Step: 2
Training loss: 2.437457799911499
Validation loss: 2.4081463275417203

Epoch: 6| Step: 3
Training loss: 2.26159930229187
Validation loss: 2.406172429361651

Epoch: 6| Step: 4
Training loss: 2.1839396953582764
Validation loss: 2.406155465751566

Epoch: 6| Step: 5
Training loss: 3.2038018703460693
Validation loss: 2.4114875396092734

Epoch: 6| Step: 6
Training loss: 2.8323769569396973
Validation loss: 2.412893449106524

Epoch: 6| Step: 7
Training loss: 2.7784876823425293
Validation loss: 2.4147822882539485

Epoch: 6| Step: 8
Training loss: 2.6597752571105957
Validation loss: 2.426689819623065

Epoch: 6| Step: 9
Training loss: 3.226982831954956
Validation loss: 2.426087979347475

Epoch: 6| Step: 10
Training loss: 2.2104105949401855
Validation loss: 2.441641992138278

Epoch: 6| Step: 11
Training loss: 3.131500244140625
Validation loss: 2.4532247563844085

Epoch: 6| Step: 12
Training loss: 2.385024070739746
Validation loss: 2.4604226286693285

Epoch: 6| Step: 13
Training loss: 2.7124006748199463
Validation loss: 2.4312886832862772

Epoch: 59| Step: 0
Training loss: 3.2036192417144775
Validation loss: 2.431284640424995

Epoch: 6| Step: 1
Training loss: 2.336379051208496
Validation loss: 2.43266628121817

Epoch: 6| Step: 2
Training loss: 3.2184975147247314
Validation loss: 2.4400337357674875

Epoch: 6| Step: 3
Training loss: 2.866795539855957
Validation loss: 2.4322368791026454

Epoch: 6| Step: 4
Training loss: 3.7000951766967773
Validation loss: 2.4397103081467333

Epoch: 6| Step: 5
Training loss: 2.824162244796753
Validation loss: 2.4354769388834634

Epoch: 6| Step: 6
Training loss: 2.2226219177246094
Validation loss: 2.4332660782721733

Epoch: 6| Step: 7
Training loss: 1.8474502563476562
Validation loss: 2.4279882241320867

Epoch: 6| Step: 8
Training loss: 2.5386013984680176
Validation loss: 2.431175237060875

Epoch: 6| Step: 9
Training loss: 2.3974084854125977
Validation loss: 2.4185934246227307

Epoch: 6| Step: 10
Training loss: 1.9986600875854492
Validation loss: 2.419601712175595

Epoch: 6| Step: 11
Training loss: 3.149618148803711
Validation loss: 2.417253932645244

Epoch: 6| Step: 12
Training loss: 2.358015537261963
Validation loss: 2.425831938302645

Epoch: 6| Step: 13
Training loss: 2.0478246212005615
Validation loss: 2.444232956055672

Epoch: 60| Step: 0
Training loss: 1.8966925144195557
Validation loss: 2.455755454237743

Epoch: 6| Step: 1
Training loss: 2.5380961894989014
Validation loss: 2.4561968503459806

Epoch: 6| Step: 2
Training loss: 2.755819797515869
Validation loss: 2.4641977561417447

Epoch: 6| Step: 3
Training loss: 2.782644510269165
Validation loss: 2.4543648637751097

Epoch: 6| Step: 4
Training loss: 2.145275115966797
Validation loss: 2.420484250591647

Epoch: 6| Step: 5
Training loss: 2.821909189224243
Validation loss: 2.409498945359261

Epoch: 6| Step: 6
Training loss: 2.862766742706299
Validation loss: 2.419089173757902

Epoch: 6| Step: 7
Training loss: 3.2938308715820312
Validation loss: 2.4176510585251676

Epoch: 6| Step: 8
Training loss: 3.329991102218628
Validation loss: 2.4162289609191236

Epoch: 6| Step: 9
Training loss: 2.2738962173461914
Validation loss: 2.4163696778717862

Epoch: 6| Step: 10
Training loss: 2.3245179653167725
Validation loss: 2.415388327772899

Epoch: 6| Step: 11
Training loss: 2.345339775085449
Validation loss: 2.4292543729146323

Epoch: 6| Step: 12
Training loss: 2.953775644302368
Validation loss: 2.425465013391228

Epoch: 6| Step: 13
Training loss: 2.501056432723999
Validation loss: 2.4172237098857923

Epoch: 61| Step: 0
Training loss: 3.400961399078369
Validation loss: 2.4103712676673807

Epoch: 6| Step: 1
Training loss: 1.8539879322052002
Validation loss: 2.4080529110406035

Epoch: 6| Step: 2
Training loss: 3.0782814025878906
Validation loss: 2.407793196298743

Epoch: 6| Step: 3
Training loss: 2.602138042449951
Validation loss: 2.4050060959272486

Epoch: 6| Step: 4
Training loss: 2.348234176635742
Validation loss: 2.404160273972378

Epoch: 6| Step: 5
Training loss: 2.1593503952026367
Validation loss: 2.396108470937257

Epoch: 6| Step: 6
Training loss: 2.1681370735168457
Validation loss: 2.3993418831979074

Epoch: 6| Step: 7
Training loss: 2.839604377746582
Validation loss: 2.4020697891071277

Epoch: 6| Step: 8
Training loss: 2.508477210998535
Validation loss: 2.3990065846391904

Epoch: 6| Step: 9
Training loss: 2.0650761127471924
Validation loss: 2.3952935664884505

Epoch: 6| Step: 10
Training loss: 3.0345001220703125
Validation loss: 2.3973471913286435

Epoch: 6| Step: 11
Training loss: 3.356995105743408
Validation loss: 2.399237294350901

Epoch: 6| Step: 12
Training loss: 2.578984022140503
Validation loss: 2.4037650041682745

Epoch: 6| Step: 13
Training loss: 3.035449981689453
Validation loss: 2.400588543184342

Epoch: 62| Step: 0
Training loss: 3.0230720043182373
Validation loss: 2.4107637841214418

Epoch: 6| Step: 1
Training loss: 2.187251567840576
Validation loss: 2.4159403744564263

Epoch: 6| Step: 2
Training loss: 3.465890407562256
Validation loss: 2.413016052656276

Epoch: 6| Step: 3
Training loss: 2.290574312210083
Validation loss: 2.4085572714446695

Epoch: 6| Step: 4
Training loss: 2.5187156200408936
Validation loss: 2.409835102737591

Epoch: 6| Step: 5
Training loss: 2.461010694503784
Validation loss: 2.4037931785788587

Epoch: 6| Step: 6
Training loss: 3.6263413429260254
Validation loss: 2.411252962645664

Epoch: 6| Step: 7
Training loss: 2.385319709777832
Validation loss: 2.4079771631507465

Epoch: 6| Step: 8
Training loss: 2.042553663253784
Validation loss: 2.413575462115708

Epoch: 6| Step: 9
Training loss: 1.9067027568817139
Validation loss: 2.426016428137338

Epoch: 6| Step: 10
Training loss: 2.285419464111328
Validation loss: 2.437388753378263

Epoch: 6| Step: 11
Training loss: 3.117103338241577
Validation loss: 2.4412642371269966

Epoch: 6| Step: 12
Training loss: 3.0976781845092773
Validation loss: 2.441656420307775

Epoch: 6| Step: 13
Training loss: 2.1232383251190186
Validation loss: 2.457798627115065

Epoch: 63| Step: 0
Training loss: 2.846069812774658
Validation loss: 2.463537399486829

Epoch: 6| Step: 1
Training loss: 2.6229512691497803
Validation loss: 2.4601812824126212

Epoch: 6| Step: 2
Training loss: 3.2200698852539062
Validation loss: 2.443964050662133

Epoch: 6| Step: 3
Training loss: 2.6157379150390625
Validation loss: 2.4400752949458298

Epoch: 6| Step: 4
Training loss: 2.8973050117492676
Validation loss: 2.427301552987868

Epoch: 6| Step: 5
Training loss: 2.8093698024749756
Validation loss: 2.4239291990956953

Epoch: 6| Step: 6
Training loss: 1.4730275869369507
Validation loss: 2.418852945809723

Epoch: 6| Step: 7
Training loss: 3.086850643157959
Validation loss: 2.43978573173605

Epoch: 6| Step: 8
Training loss: 2.5098390579223633
Validation loss: 2.475097087121779

Epoch: 6| Step: 9
Training loss: 2.6978695392608643
Validation loss: 2.4557385060095016

Epoch: 6| Step: 10
Training loss: 2.9949734210968018
Validation loss: 2.4613164701769428

Epoch: 6| Step: 11
Training loss: 2.199892282485962
Validation loss: 2.46154111431491

Epoch: 6| Step: 12
Training loss: 2.0406494140625
Validation loss: 2.4748280099643174

Epoch: 6| Step: 13
Training loss: 2.8763818740844727
Validation loss: 2.4570579580081406

Epoch: 64| Step: 0
Training loss: 2.558436155319214
Validation loss: 2.4264491988766577

Epoch: 6| Step: 1
Training loss: 2.571777105331421
Validation loss: 2.4162115563628492

Epoch: 6| Step: 2
Training loss: 2.891613006591797
Validation loss: 2.3997120959784395

Epoch: 6| Step: 3
Training loss: 2.259312152862549
Validation loss: 2.3871000992354525

Epoch: 6| Step: 4
Training loss: 2.4171252250671387
Validation loss: 2.3826383724007556

Epoch: 6| Step: 5
Training loss: 2.619786500930786
Validation loss: 2.3828077649557464

Epoch: 6| Step: 6
Training loss: 2.1238980293273926
Validation loss: 2.378492345092117

Epoch: 6| Step: 7
Training loss: 3.244988441467285
Validation loss: 2.387307549035677

Epoch: 6| Step: 8
Training loss: 3.5381548404693604
Validation loss: 2.379137126348352

Epoch: 6| Step: 9
Training loss: 2.171297311782837
Validation loss: 2.3877140886040142

Epoch: 6| Step: 10
Training loss: 3.041998863220215
Validation loss: 2.3819069759820097

Epoch: 6| Step: 11
Training loss: 2.5817761421203613
Validation loss: 2.380793383044581

Epoch: 6| Step: 12
Training loss: 2.792264223098755
Validation loss: 2.3856184303119616

Epoch: 6| Step: 13
Training loss: 1.3541204929351807
Validation loss: 2.3956401630114486

Epoch: 65| Step: 0
Training loss: 2.649657964706421
Validation loss: 2.3999683677509265

Epoch: 6| Step: 1
Training loss: 2.7540698051452637
Validation loss: 2.4152660113508984

Epoch: 6| Step: 2
Training loss: 2.1859829425811768
Validation loss: 2.3985294372804704

Epoch: 6| Step: 3
Training loss: 2.822117805480957
Validation loss: 2.399813308510729

Epoch: 6| Step: 4
Training loss: 2.653270721435547
Validation loss: 2.42565627508266

Epoch: 6| Step: 5
Training loss: 2.8247151374816895
Validation loss: 2.4383672821906304

Epoch: 6| Step: 6
Training loss: 3.517629861831665
Validation loss: 2.4450886198269424

Epoch: 6| Step: 7
Training loss: 2.6360819339752197
Validation loss: 2.4275700661443893

Epoch: 6| Step: 8
Training loss: 2.509963035583496
Validation loss: 2.4141425624970467

Epoch: 6| Step: 9
Training loss: 2.62524676322937
Validation loss: 2.408458261079686

Epoch: 6| Step: 10
Training loss: 2.4347715377807617
Validation loss: 2.421298747421593

Epoch: 6| Step: 11
Training loss: 2.3867225646972656
Validation loss: 2.402006405656056

Epoch: 6| Step: 12
Training loss: 2.2704854011535645
Validation loss: 2.4127326370567403

Epoch: 6| Step: 13
Training loss: 2.382646322250366
Validation loss: 2.4043236419718754

Epoch: 66| Step: 0
Training loss: 2.3123910427093506
Validation loss: 2.3881364291714084

Epoch: 6| Step: 1
Training loss: 3.0578465461730957
Validation loss: 2.3849777739535094

Epoch: 6| Step: 2
Training loss: 1.8218145370483398
Validation loss: 2.3918699910563808

Epoch: 6| Step: 3
Training loss: 2.5239548683166504
Validation loss: 2.405834810708159

Epoch: 6| Step: 4
Training loss: 3.0952959060668945
Validation loss: 2.426208039765717

Epoch: 6| Step: 5
Training loss: 3.4200117588043213
Validation loss: 2.4402099886248187

Epoch: 6| Step: 6
Training loss: 1.347944736480713
Validation loss: 2.4497797309711413

Epoch: 6| Step: 7
Training loss: 2.741117000579834
Validation loss: 2.445424475977498

Epoch: 6| Step: 8
Training loss: 2.5470292568206787
Validation loss: 2.4210536890132452

Epoch: 6| Step: 9
Training loss: 2.923459529876709
Validation loss: 2.423539920519757

Epoch: 6| Step: 10
Training loss: 2.5684409141540527
Validation loss: 2.4225753199669624

Epoch: 6| Step: 11
Training loss: 3.24436354637146
Validation loss: 2.4222008002701627

Epoch: 6| Step: 12
Training loss: 2.5130128860473633
Validation loss: 2.4177575803572133

Epoch: 6| Step: 13
Training loss: 2.740661859512329
Validation loss: 2.419237559841525

Epoch: 67| Step: 0
Training loss: 1.765800952911377
Validation loss: 2.413550774256388

Epoch: 6| Step: 1
Training loss: 2.0006465911865234
Validation loss: 2.422285064574211

Epoch: 6| Step: 2
Training loss: 2.9235754013061523
Validation loss: 2.407857011723262

Epoch: 6| Step: 3
Training loss: 2.6930408477783203
Validation loss: 2.4101032569844234

Epoch: 6| Step: 4
Training loss: 2.421848773956299
Validation loss: 2.399944992475612

Epoch: 6| Step: 5
Training loss: 2.6152117252349854
Validation loss: 2.4084260181714128

Epoch: 6| Step: 6
Training loss: 2.6867258548736572
Validation loss: 2.4187027023684595

Epoch: 6| Step: 7
Training loss: 3.77203369140625
Validation loss: 2.4220063583825224

Epoch: 6| Step: 8
Training loss: 2.8402533531188965
Validation loss: 2.4147853312953824

Epoch: 6| Step: 9
Training loss: 3.0390725135803223
Validation loss: 2.4124160966565533

Epoch: 6| Step: 10
Training loss: 2.046034812927246
Validation loss: 2.414743374752742

Epoch: 6| Step: 11
Training loss: 2.8234143257141113
Validation loss: 2.422708175515616

Epoch: 6| Step: 12
Training loss: 2.567479133605957
Validation loss: 2.427358217136834

Epoch: 6| Step: 13
Training loss: 2.2852001190185547
Validation loss: 2.4229339809827906

Epoch: 68| Step: 0
Training loss: 2.465787887573242
Validation loss: 2.414563307198145

Epoch: 6| Step: 1
Training loss: 2.6449079513549805
Validation loss: 2.4057889061589397

Epoch: 6| Step: 2
Training loss: 2.9138376712799072
Validation loss: 2.3905217468097644

Epoch: 6| Step: 3
Training loss: 3.004455089569092
Validation loss: 2.39314301295947

Epoch: 6| Step: 4
Training loss: 2.716311454772949
Validation loss: 2.3800470124008837

Epoch: 6| Step: 5
Training loss: 2.515744686126709
Validation loss: 2.383749549106885

Epoch: 6| Step: 6
Training loss: 2.4322891235351562
Validation loss: 2.3901445506721415

Epoch: 6| Step: 7
Training loss: 2.8154523372650146
Validation loss: 2.3967299538273967

Epoch: 6| Step: 8
Training loss: 2.636233329772949
Validation loss: 2.392998118554392

Epoch: 6| Step: 9
Training loss: 2.8481903076171875
Validation loss: 2.396450881035097

Epoch: 6| Step: 10
Training loss: 1.908517599105835
Validation loss: 2.384007243699925

Epoch: 6| Step: 11
Training loss: 2.3631343841552734
Validation loss: 2.3808480385811097

Epoch: 6| Step: 12
Training loss: 2.530562400817871
Validation loss: 2.37802347957447

Epoch: 6| Step: 13
Training loss: 3.006438732147217
Validation loss: 2.382631496716571

Epoch: 69| Step: 0
Training loss: 2.763134241104126
Validation loss: 2.3879052541589223

Epoch: 6| Step: 1
Training loss: 2.654686689376831
Validation loss: 2.3793219238199215

Epoch: 6| Step: 2
Training loss: 2.7047829627990723
Validation loss: 2.3726029857512443

Epoch: 6| Step: 3
Training loss: 2.236633062362671
Validation loss: 2.369847018231628

Epoch: 6| Step: 4
Training loss: 2.567028522491455
Validation loss: 2.3696605672118483

Epoch: 6| Step: 5
Training loss: 3.2676444053649902
Validation loss: 2.371329794647873

Epoch: 6| Step: 6
Training loss: 2.3861563205718994
Validation loss: 2.3652700224230365

Epoch: 6| Step: 7
Training loss: 2.2210240364074707
Validation loss: 2.376354589257189

Epoch: 6| Step: 8
Training loss: 2.451446533203125
Validation loss: 2.3813837279555616

Epoch: 6| Step: 9
Training loss: 2.2838664054870605
Validation loss: 2.3796904625431186

Epoch: 6| Step: 10
Training loss: 2.5999386310577393
Validation loss: 2.380171322053479

Epoch: 6| Step: 11
Training loss: 2.8230347633361816
Validation loss: 2.3751091136727283

Epoch: 6| Step: 12
Training loss: 2.629345417022705
Validation loss: 2.3820849080239572

Epoch: 6| Step: 13
Training loss: 3.279007911682129
Validation loss: 2.379906994040294

Epoch: 70| Step: 0
Training loss: 2.961207866668701
Validation loss: 2.371589752935594

Epoch: 6| Step: 1
Training loss: 2.689995765686035
Validation loss: 2.36983843516278

Epoch: 6| Step: 2
Training loss: 2.7760872840881348
Validation loss: 2.367332325186781

Epoch: 6| Step: 3
Training loss: 2.39931583404541
Validation loss: 2.368987952509234

Epoch: 6| Step: 4
Training loss: 2.481027364730835
Validation loss: 2.3693877497026996

Epoch: 6| Step: 5
Training loss: 2.8439083099365234
Validation loss: 2.3704892999382428

Epoch: 6| Step: 6
Training loss: 3.1946682929992676
Validation loss: 2.369942201081143

Epoch: 6| Step: 7
Training loss: 3.5096983909606934
Validation loss: 2.367440685149162

Epoch: 6| Step: 8
Training loss: 1.9433592557907104
Validation loss: 2.37088155874642

Epoch: 6| Step: 9
Training loss: 2.1658148765563965
Validation loss: 2.368410741129229

Epoch: 6| Step: 10
Training loss: 2.0702099800109863
Validation loss: 2.3637620556739067

Epoch: 6| Step: 11
Training loss: 1.794159173965454
Validation loss: 2.3600466866647043

Epoch: 6| Step: 12
Training loss: 2.796898126602173
Validation loss: 2.365037102853098

Epoch: 6| Step: 13
Training loss: 2.9212934970855713
Validation loss: 2.364957212119974

Epoch: 71| Step: 0
Training loss: 3.000105381011963
Validation loss: 2.3664344587633686

Epoch: 6| Step: 1
Training loss: 3.2854251861572266
Validation loss: 2.369260440590561

Epoch: 6| Step: 2
Training loss: 2.878553867340088
Validation loss: 2.3739903396175754

Epoch: 6| Step: 3
Training loss: 2.0200631618499756
Validation loss: 2.374135266068161

Epoch: 6| Step: 4
Training loss: 2.1514551639556885
Validation loss: 2.3765443499370287

Epoch: 6| Step: 5
Training loss: 2.4088664054870605
Validation loss: 2.3840913157309256

Epoch: 6| Step: 6
Training loss: 2.499622344970703
Validation loss: 2.3737731620829594

Epoch: 6| Step: 7
Training loss: 3.0364603996276855
Validation loss: 2.376176121414349

Epoch: 6| Step: 8
Training loss: 3.288252115249634
Validation loss: 2.3792220905262935

Epoch: 6| Step: 9
Training loss: 2.621018648147583
Validation loss: 2.379068805325416

Epoch: 6| Step: 10
Training loss: 2.05916428565979
Validation loss: 2.376510394516812

Epoch: 6| Step: 11
Training loss: 2.4628615379333496
Validation loss: 2.3892860592052503

Epoch: 6| Step: 12
Training loss: 2.57651424407959
Validation loss: 2.3935127540301253

Epoch: 6| Step: 13
Training loss: 1.731532335281372
Validation loss: 2.393863562614687

Epoch: 72| Step: 0
Training loss: 2.472411632537842
Validation loss: 2.379531060495684

Epoch: 6| Step: 1
Training loss: 3.3095712661743164
Validation loss: 2.3669398651328137

Epoch: 6| Step: 2
Training loss: 2.623181104660034
Validation loss: 2.36136318022205

Epoch: 6| Step: 3
Training loss: 2.802410125732422
Validation loss: 2.3601326865534626

Epoch: 6| Step: 4
Training loss: 2.5056538581848145
Validation loss: 2.371020952860514

Epoch: 6| Step: 5
Training loss: 2.525583267211914
Validation loss: 2.369673877634028

Epoch: 6| Step: 6
Training loss: 2.6153712272644043
Validation loss: 2.385611953273896

Epoch: 6| Step: 7
Training loss: 2.6178770065307617
Validation loss: 2.3802692197984263

Epoch: 6| Step: 8
Training loss: 2.3326144218444824
Validation loss: 2.376256481293709

Epoch: 6| Step: 9
Training loss: 2.963149070739746
Validation loss: 2.374291771201677

Epoch: 6| Step: 10
Training loss: 1.6886391639709473
Validation loss: 2.372564015849944

Epoch: 6| Step: 11
Training loss: 1.8548632860183716
Validation loss: 2.3841055747001403

Epoch: 6| Step: 12
Training loss: 3.1467013359069824
Validation loss: 2.3847118244376233

Epoch: 6| Step: 13
Training loss: 3.3120100498199463
Validation loss: 2.392084913869058

Epoch: 73| Step: 0
Training loss: 3.1177940368652344
Validation loss: 2.398645907320002

Epoch: 6| Step: 1
Training loss: 1.9691153764724731
Validation loss: 2.395833953734367

Epoch: 6| Step: 2
Training loss: 2.0867815017700195
Validation loss: 2.3904414048758884

Epoch: 6| Step: 3
Training loss: 2.829946756362915
Validation loss: 2.39430054285193

Epoch: 6| Step: 4
Training loss: 2.3600409030914307
Validation loss: 2.390566538738948

Epoch: 6| Step: 5
Training loss: 2.4843027591705322
Validation loss: 2.3907087490122807

Epoch: 6| Step: 6
Training loss: 2.904869556427002
Validation loss: 2.3928406905102473

Epoch: 6| Step: 7
Training loss: 2.8617022037506104
Validation loss: 2.3849597695053264

Epoch: 6| Step: 8
Training loss: 2.558298110961914
Validation loss: 2.387178777366556

Epoch: 6| Step: 9
Training loss: 3.084766387939453
Validation loss: 2.3801527612952778

Epoch: 6| Step: 10
Training loss: 2.0763773918151855
Validation loss: 2.3758173450346916

Epoch: 6| Step: 11
Training loss: 2.100531578063965
Validation loss: 2.374554926349271

Epoch: 6| Step: 12
Training loss: 2.9727001190185547
Validation loss: 2.3750636449424167

Epoch: 6| Step: 13
Training loss: 3.1043179035186768
Validation loss: 2.378759984047182

Epoch: 74| Step: 0
Training loss: 2.6373472213745117
Validation loss: 2.3706799707105084

Epoch: 6| Step: 1
Training loss: 2.8720405101776123
Validation loss: 2.3708906942798245

Epoch: 6| Step: 2
Training loss: 2.3229777812957764
Validation loss: 2.3733650663847565

Epoch: 6| Step: 3
Training loss: 1.9991631507873535
Validation loss: 2.367447486487768

Epoch: 6| Step: 4
Training loss: 2.3738913536071777
Validation loss: 2.3671372013707317

Epoch: 6| Step: 5
Training loss: 2.546541213989258
Validation loss: 2.368040923149355

Epoch: 6| Step: 6
Training loss: 2.9000933170318604
Validation loss: 2.3883658865446686

Epoch: 6| Step: 7
Training loss: 2.534203290939331
Validation loss: 2.378294906308574

Epoch: 6| Step: 8
Training loss: 2.0599606037139893
Validation loss: 2.398395961330783

Epoch: 6| Step: 9
Training loss: 3.107283592224121
Validation loss: 2.403661858650946

Epoch: 6| Step: 10
Training loss: 3.299966812133789
Validation loss: 2.414344451760733

Epoch: 6| Step: 11
Training loss: 2.5518035888671875
Validation loss: 2.39794724218307

Epoch: 6| Step: 12
Training loss: 2.6782779693603516
Validation loss: 2.379007636859853

Epoch: 6| Step: 13
Training loss: 2.9360358715057373
Validation loss: 2.360428426855354

Epoch: 75| Step: 0
Training loss: 2.62788987159729
Validation loss: 2.343795627676031

Epoch: 6| Step: 1
Training loss: 2.3799796104431152
Validation loss: 2.342377185821533

Epoch: 6| Step: 2
Training loss: 2.681551694869995
Validation loss: 2.34943356949796

Epoch: 6| Step: 3
Training loss: 2.2227673530578613
Validation loss: 2.3790001561564784

Epoch: 6| Step: 4
Training loss: 2.831569194793701
Validation loss: 2.4108831600476335

Epoch: 6| Step: 5
Training loss: 2.225888252258301
Validation loss: 2.4454308530335784

Epoch: 6| Step: 6
Training loss: 2.536640167236328
Validation loss: 2.4482613302046254

Epoch: 6| Step: 7
Training loss: 2.5830867290496826
Validation loss: 2.419157887017855

Epoch: 6| Step: 8
Training loss: 2.746843099594116
Validation loss: 2.3777700495976273

Epoch: 6| Step: 9
Training loss: 2.702500343322754
Validation loss: 2.3643706844699

Epoch: 6| Step: 10
Training loss: 2.247532367706299
Validation loss: 2.3382514292193997

Epoch: 6| Step: 11
Training loss: 2.8346874713897705
Validation loss: 2.333385113746889

Epoch: 6| Step: 12
Training loss: 2.7045607566833496
Validation loss: 2.351768130897194

Epoch: 6| Step: 13
Training loss: 4.061818599700928
Validation loss: 2.361094979829686

Epoch: 76| Step: 0
Training loss: 2.371614933013916
Validation loss: 2.367586766519854

Epoch: 6| Step: 1
Training loss: 2.441643238067627
Validation loss: 2.394160052781464

Epoch: 6| Step: 2
Training loss: 1.8383152484893799
Validation loss: 2.4055875065506145

Epoch: 6| Step: 3
Training loss: 2.8696389198303223
Validation loss: 2.3957690103079683

Epoch: 6| Step: 4
Training loss: 3.523879051208496
Validation loss: 2.371260130277244

Epoch: 6| Step: 5
Training loss: 2.328681707382202
Validation loss: 2.364587022412208

Epoch: 6| Step: 6
Training loss: 2.359292984008789
Validation loss: 2.348499018658874

Epoch: 6| Step: 7
Training loss: 2.8900442123413086
Validation loss: 2.3370633714942524

Epoch: 6| Step: 8
Training loss: 2.656122922897339
Validation loss: 2.325654384910419

Epoch: 6| Step: 9
Training loss: 2.555077314376831
Validation loss: 2.3306316034768217

Epoch: 6| Step: 10
Training loss: 3.084702968597412
Validation loss: 2.3287922028572328

Epoch: 6| Step: 11
Training loss: 3.004397392272949
Validation loss: 2.3324043622580906

Epoch: 6| Step: 12
Training loss: 2.0711138248443604
Validation loss: 2.3314164351391535

Epoch: 6| Step: 13
Training loss: 2.6399497985839844
Validation loss: 2.3298266292900167

Epoch: 77| Step: 0
Training loss: 1.99753737449646
Validation loss: 2.335561603628179

Epoch: 6| Step: 1
Training loss: 2.8133959770202637
Validation loss: 2.334166740858427

Epoch: 6| Step: 2
Training loss: 3.0767552852630615
Validation loss: 2.337434781494961

Epoch: 6| Step: 3
Training loss: 2.8534762859344482
Validation loss: 2.330839744178198

Epoch: 6| Step: 4
Training loss: 3.2496604919433594
Validation loss: 2.3336572390730663

Epoch: 6| Step: 5
Training loss: 2.179865837097168
Validation loss: 2.335198297295519

Epoch: 6| Step: 6
Training loss: 2.2380213737487793
Validation loss: 2.3299215121935775

Epoch: 6| Step: 7
Training loss: 2.1121809482574463
Validation loss: 2.3336244065274476

Epoch: 6| Step: 8
Training loss: 2.6940808296203613
Validation loss: 2.3327626054004957

Epoch: 6| Step: 9
Training loss: 2.482982635498047
Validation loss: 2.337915139813577

Epoch: 6| Step: 10
Training loss: 2.8666224479675293
Validation loss: 2.350679269400976

Epoch: 6| Step: 11
Training loss: 2.2976789474487305
Validation loss: 2.348247120457311

Epoch: 6| Step: 12
Training loss: 2.7851223945617676
Validation loss: 2.3596395010589273

Epoch: 6| Step: 13
Training loss: 2.8328027725219727
Validation loss: 2.376982222321213

Epoch: 78| Step: 0
Training loss: 2.1411309242248535
Validation loss: 2.3626843575508363

Epoch: 6| Step: 1
Training loss: 2.6222848892211914
Validation loss: 2.3608781291592504

Epoch: 6| Step: 2
Training loss: 2.2074973583221436
Validation loss: 2.366671731395106

Epoch: 6| Step: 3
Training loss: 3.150926113128662
Validation loss: 2.3679228764708324

Epoch: 6| Step: 4
Training loss: 2.3310303688049316
Validation loss: 2.3658862293407483

Epoch: 6| Step: 5
Training loss: 2.970839500427246
Validation loss: 2.3808577060699463

Epoch: 6| Step: 6
Training loss: 3.0302953720092773
Validation loss: 2.3760130200334775

Epoch: 6| Step: 7
Training loss: 2.396120548248291
Validation loss: 2.362635822706325

Epoch: 6| Step: 8
Training loss: 2.77264404296875
Validation loss: 2.3674052722992434

Epoch: 6| Step: 9
Training loss: 2.4243850708007812
Validation loss: 2.355360483610502

Epoch: 6| Step: 10
Training loss: 2.6213531494140625
Validation loss: 2.349974719426965

Epoch: 6| Step: 11
Training loss: 1.7730532884597778
Validation loss: 2.3577282787651144

Epoch: 6| Step: 12
Training loss: 3.112182140350342
Validation loss: 2.348881693296535

Epoch: 6| Step: 13
Training loss: 2.82700777053833
Validation loss: 2.3584996859232583

Epoch: 79| Step: 0
Training loss: 2.547097682952881
Validation loss: 2.3574691100787093

Epoch: 6| Step: 1
Training loss: 2.899155378341675
Validation loss: 2.361337505361085

Epoch: 6| Step: 2
Training loss: 1.892624855041504
Validation loss: 2.3570454838455364

Epoch: 6| Step: 3
Training loss: 2.1591527462005615
Validation loss: 2.35045349982477

Epoch: 6| Step: 4
Training loss: 1.601844310760498
Validation loss: 2.348481068047144

Epoch: 6| Step: 5
Training loss: 2.7199618816375732
Validation loss: 2.34818265258625

Epoch: 6| Step: 6
Training loss: 2.687859058380127
Validation loss: 2.3464547511070006

Epoch: 6| Step: 7
Training loss: 2.804473876953125
Validation loss: 2.3527713616689048

Epoch: 6| Step: 8
Training loss: 2.593956470489502
Validation loss: 2.3481212495475687

Epoch: 6| Step: 9
Training loss: 3.2337918281555176
Validation loss: 2.3605298662698395

Epoch: 6| Step: 10
Training loss: 2.859368324279785
Validation loss: 2.3518463257820375

Epoch: 6| Step: 11
Training loss: 2.778684616088867
Validation loss: 2.3617319727456696

Epoch: 6| Step: 12
Training loss: 2.184140682220459
Validation loss: 2.3644377928908153

Epoch: 6| Step: 13
Training loss: 3.4824395179748535
Validation loss: 2.3639454585249706

Epoch: 80| Step: 0
Training loss: 2.5914111137390137
Validation loss: 2.34947455826626

Epoch: 6| Step: 1
Training loss: 2.8076486587524414
Validation loss: 2.353137077823762

Epoch: 6| Step: 2
Training loss: 2.063887357711792
Validation loss: 2.351375836198048

Epoch: 6| Step: 3
Training loss: 2.5721828937530518
Validation loss: 2.3650822306192048

Epoch: 6| Step: 4
Training loss: 2.784095287322998
Validation loss: 2.366124750465475

Epoch: 6| Step: 5
Training loss: 2.6893234252929688
Validation loss: 2.358264861568328

Epoch: 6| Step: 6
Training loss: 2.8060545921325684
Validation loss: 2.35698410003416

Epoch: 6| Step: 7
Training loss: 1.9321006536483765
Validation loss: 2.3508352694972867

Epoch: 6| Step: 8
Training loss: 2.846015453338623
Validation loss: 2.347844642977561

Epoch: 6| Step: 9
Training loss: 2.787003517150879
Validation loss: 2.3391119869806434

Epoch: 6| Step: 10
Training loss: 2.0047690868377686
Validation loss: 2.3334473281778316

Epoch: 6| Step: 11
Training loss: 3.149859666824341
Validation loss: 2.3298847598414265

Epoch: 6| Step: 12
Training loss: 2.601388454437256
Validation loss: 2.31869307128332

Epoch: 6| Step: 13
Training loss: 2.4587643146514893
Validation loss: 2.326062140926238

Epoch: 81| Step: 0
Training loss: 2.7977218627929688
Validation loss: 2.326411244689777

Epoch: 6| Step: 1
Training loss: 2.2079193592071533
Validation loss: 2.3253538121459303

Epoch: 6| Step: 2
Training loss: 3.373713493347168
Validation loss: 2.3314121307865268

Epoch: 6| Step: 3
Training loss: 2.335195541381836
Validation loss: 2.3291408913109892

Epoch: 6| Step: 4
Training loss: 2.613922119140625
Validation loss: 2.3313620436576104

Epoch: 6| Step: 5
Training loss: 2.7285594940185547
Validation loss: 2.3304805191614295

Epoch: 6| Step: 6
Training loss: 2.793365001678467
Validation loss: 2.3233879304701284

Epoch: 6| Step: 7
Training loss: 3.0719070434570312
Validation loss: 2.3234149204787387

Epoch: 6| Step: 8
Training loss: 2.1914310455322266
Validation loss: 2.3252729856839744

Epoch: 6| Step: 9
Training loss: 1.7129982709884644
Validation loss: 2.3191256318041074

Epoch: 6| Step: 10
Training loss: 2.8012807369232178
Validation loss: 2.3243327461263186

Epoch: 6| Step: 11
Training loss: 2.3196072578430176
Validation loss: 2.3483720184654318

Epoch: 6| Step: 12
Training loss: 2.6240975856781006
Validation loss: 2.349602412152034

Epoch: 6| Step: 13
Training loss: 2.2301080226898193
Validation loss: 2.352598421035274

Epoch: 82| Step: 0
Training loss: 2.896578788757324
Validation loss: 2.370178481583954

Epoch: 6| Step: 1
Training loss: 2.8047289848327637
Validation loss: 2.3822731023193686

Epoch: 6| Step: 2
Training loss: 2.438253402709961
Validation loss: 2.386674068307364

Epoch: 6| Step: 3
Training loss: 2.8282957077026367
Validation loss: 2.390798512325492

Epoch: 6| Step: 4
Training loss: 2.882986068725586
Validation loss: 2.394118050093292

Epoch: 6| Step: 5
Training loss: 3.1660053730010986
Validation loss: 2.3833752832105084

Epoch: 6| Step: 6
Training loss: 1.9349160194396973
Validation loss: 2.3816739641210085

Epoch: 6| Step: 7
Training loss: 1.579744577407837
Validation loss: 2.362912754858694

Epoch: 6| Step: 8
Training loss: 2.9619951248168945
Validation loss: 2.3687101897372993

Epoch: 6| Step: 9
Training loss: 2.4342429637908936
Validation loss: 2.348867493291055

Epoch: 6| Step: 10
Training loss: 2.1021909713745117
Validation loss: 2.3390353366892827

Epoch: 6| Step: 11
Training loss: 2.945098876953125
Validation loss: 2.3323845888978694

Epoch: 6| Step: 12
Training loss: 2.71712589263916
Validation loss: 2.332520754106583

Epoch: 6| Step: 13
Training loss: 2.20803165435791
Validation loss: 2.3320468715442124

Epoch: 83| Step: 0
Training loss: 2.529386520385742
Validation loss: 2.331844788725658

Epoch: 6| Step: 1
Training loss: 3.0237531661987305
Validation loss: 2.338594913482666

Epoch: 6| Step: 2
Training loss: 2.458850860595703
Validation loss: 2.3342274440232145

Epoch: 6| Step: 3
Training loss: 3.0995676517486572
Validation loss: 2.332123043716595

Epoch: 6| Step: 4
Training loss: 2.2760519981384277
Validation loss: 2.331290768038842

Epoch: 6| Step: 5
Training loss: 2.980745315551758
Validation loss: 2.3331639407783427

Epoch: 6| Step: 6
Training loss: 2.4716782569885254
Validation loss: 2.3297933763073337

Epoch: 6| Step: 7
Training loss: 2.110670566558838
Validation loss: 2.331623092774422

Epoch: 6| Step: 8
Training loss: 2.1852707862854004
Validation loss: 2.3320456102330196

Epoch: 6| Step: 9
Training loss: 2.620363712310791
Validation loss: 2.3304920273442424

Epoch: 6| Step: 10
Training loss: 2.5006051063537598
Validation loss: 2.3297753436591035

Epoch: 6| Step: 11
Training loss: 2.3352322578430176
Validation loss: 2.3408106039929133

Epoch: 6| Step: 12
Training loss: 3.280125856399536
Validation loss: 2.3376703031601442

Epoch: 6| Step: 13
Training loss: 1.9016766548156738
Validation loss: 2.344744118311072

Epoch: 84| Step: 0
Training loss: 2.2473196983337402
Validation loss: 2.3481147186730498

Epoch: 6| Step: 1
Training loss: 2.752655029296875
Validation loss: 2.361785678453343

Epoch: 6| Step: 2
Training loss: 2.6853904724121094
Validation loss: 2.3829871557092153

Epoch: 6| Step: 3
Training loss: 3.374345541000366
Validation loss: 2.3685045191036758

Epoch: 6| Step: 4
Training loss: 3.036940336227417
Validation loss: 2.3725488211518977

Epoch: 6| Step: 5
Training loss: 2.7501120567321777
Validation loss: 2.3677680184764247

Epoch: 6| Step: 6
Training loss: 2.381563663482666
Validation loss: 2.3473043749409337

Epoch: 6| Step: 7
Training loss: 2.3172788619995117
Validation loss: 2.3337233861287436

Epoch: 6| Step: 8
Training loss: 2.8067004680633545
Validation loss: 2.3335706213469147

Epoch: 6| Step: 9
Training loss: 2.057445526123047
Validation loss: 2.33609377825132

Epoch: 6| Step: 10
Training loss: 2.810417413711548
Validation loss: 2.348330728469356

Epoch: 6| Step: 11
Training loss: 2.212733745574951
Validation loss: 2.354873821299563

Epoch: 6| Step: 12
Training loss: 3.1351113319396973
Validation loss: 2.3470607649895454

Epoch: 6| Step: 13
Training loss: 1.0079936981201172
Validation loss: 2.3444093965714976

Epoch: 85| Step: 0
Training loss: 2.1996278762817383
Validation loss: 2.3514028620976273

Epoch: 6| Step: 1
Training loss: 2.778721332550049
Validation loss: 2.3590080635522

Epoch: 6| Step: 2
Training loss: 2.7305798530578613
Validation loss: 2.3537968973959646

Epoch: 6| Step: 3
Training loss: 3.3678879737854004
Validation loss: 2.3455127516100482

Epoch: 6| Step: 4
Training loss: 2.3671746253967285
Validation loss: 2.335706962052212

Epoch: 6| Step: 5
Training loss: 3.657541275024414
Validation loss: 2.334224554800218

Epoch: 6| Step: 6
Training loss: 2.6124839782714844
Validation loss: 2.3279955053842194

Epoch: 6| Step: 7
Training loss: 1.9145493507385254
Validation loss: 2.3230521140560025

Epoch: 6| Step: 8
Training loss: 1.509468674659729
Validation loss: 2.319806723184483

Epoch: 6| Step: 9
Training loss: 2.212716817855835
Validation loss: 2.3261118140271915

Epoch: 6| Step: 10
Training loss: 2.4953529834747314
Validation loss: 2.337164087962079

Epoch: 6| Step: 11
Training loss: 2.7297425270080566
Validation loss: 2.3279995226090953

Epoch: 6| Step: 12
Training loss: 2.609541416168213
Validation loss: 2.3201008176290863

Epoch: 6| Step: 13
Training loss: 2.7394542694091797
Validation loss: 2.327503793983049

Epoch: 86| Step: 0
Training loss: 3.1529154777526855
Validation loss: 2.323623744390344

Epoch: 6| Step: 1
Training loss: 2.387834072113037
Validation loss: 2.318253860678724

Epoch: 6| Step: 2
Training loss: 3.3747029304504395
Validation loss: 2.307764594272901

Epoch: 6| Step: 3
Training loss: 2.9284958839416504
Validation loss: 2.3062890216868412

Epoch: 6| Step: 4
Training loss: 2.2796502113342285
Validation loss: 2.3050003256849063

Epoch: 6| Step: 5
Training loss: 2.4806571006774902
Validation loss: 2.300148553745721

Epoch: 6| Step: 6
Training loss: 2.1651525497436523
Validation loss: 2.310902585265457

Epoch: 6| Step: 7
Training loss: 3.0515975952148438
Validation loss: 2.307264199820898

Epoch: 6| Step: 8
Training loss: 2.0584945678710938
Validation loss: 2.3017218343673216

Epoch: 6| Step: 9
Training loss: 2.697068691253662
Validation loss: 2.3032382893305954

Epoch: 6| Step: 10
Training loss: 2.6269643306732178
Validation loss: 2.304699218401345

Epoch: 6| Step: 11
Training loss: 2.116636037826538
Validation loss: 2.304931120205951

Epoch: 6| Step: 12
Training loss: 2.344052791595459
Validation loss: 2.32228922587569

Epoch: 6| Step: 13
Training loss: 1.9784281253814697
Validation loss: 2.316159212461082

Epoch: 87| Step: 0
Training loss: 2.6928937435150146
Validation loss: 2.3320361901355047

Epoch: 6| Step: 1
Training loss: 2.742199420928955
Validation loss: 2.3375970650744695

Epoch: 6| Step: 2
Training loss: 1.9595458507537842
Validation loss: 2.3480106553723736

Epoch: 6| Step: 3
Training loss: 1.797205924987793
Validation loss: 2.3605108325199415

Epoch: 6| Step: 4
Training loss: 2.8036506175994873
Validation loss: 2.388449227938088

Epoch: 6| Step: 5
Training loss: 2.987128257751465
Validation loss: 2.394322697834302

Epoch: 6| Step: 6
Training loss: 2.731231212615967
Validation loss: 2.3879590162666897

Epoch: 6| Step: 7
Training loss: 3.0834178924560547
Validation loss: 2.3802259814354683

Epoch: 6| Step: 8
Training loss: 2.661710023880005
Validation loss: 2.3614452064678235

Epoch: 6| Step: 9
Training loss: 2.503115177154541
Validation loss: 2.34556624966283

Epoch: 6| Step: 10
Training loss: 2.641677141189575
Validation loss: 2.3388769908617904

Epoch: 6| Step: 11
Training loss: 2.4890995025634766
Validation loss: 2.3434252174951697

Epoch: 6| Step: 12
Training loss: 2.282417058944702
Validation loss: 2.3510186313301005

Epoch: 6| Step: 13
Training loss: 3.020822286605835
Validation loss: 2.3634129108921176

Epoch: 88| Step: 0
Training loss: 2.5861544609069824
Validation loss: 2.3522679241754676

Epoch: 6| Step: 1
Training loss: 2.49308705329895
Validation loss: 2.355012506567022

Epoch: 6| Step: 2
Training loss: 2.0730955600738525
Validation loss: 2.3557200739460606

Epoch: 6| Step: 3
Training loss: 2.4192161560058594
Validation loss: 2.3565768170100387

Epoch: 6| Step: 4
Training loss: 2.8838131427764893
Validation loss: 2.335535523711994

Epoch: 6| Step: 5
Training loss: 2.7455532550811768
Validation loss: 2.3458673133645007

Epoch: 6| Step: 6
Training loss: 2.4214444160461426
Validation loss: 2.33576020374093

Epoch: 6| Step: 7
Training loss: 2.492993116378784
Validation loss: 2.3392888499844458

Epoch: 6| Step: 8
Training loss: 3.3144936561584473
Validation loss: 2.33854426107099

Epoch: 6| Step: 9
Training loss: 2.4003539085388184
Validation loss: 2.3392224798920336

Epoch: 6| Step: 10
Training loss: 2.696159839630127
Validation loss: 2.350785938642358

Epoch: 6| Step: 11
Training loss: 2.5664682388305664
Validation loss: 2.3526542699465187

Epoch: 6| Step: 12
Training loss: 2.062042236328125
Validation loss: 2.3542237922709477

Epoch: 6| Step: 13
Training loss: 2.900273323059082
Validation loss: 2.343949963969569

Epoch: 89| Step: 0
Training loss: 3.097942590713501
Validation loss: 2.3415725154261433

Epoch: 6| Step: 1
Training loss: 2.094841957092285
Validation loss: 2.332316234547605

Epoch: 6| Step: 2
Training loss: 2.2070677280426025
Validation loss: 2.328386455453852

Epoch: 6| Step: 3
Training loss: 2.8851261138916016
Validation loss: 2.3212295373280845

Epoch: 6| Step: 4
Training loss: 3.29364013671875
Validation loss: 2.3043970318250757

Epoch: 6| Step: 5
Training loss: 2.1931891441345215
Validation loss: 2.30337163453461

Epoch: 6| Step: 6
Training loss: 3.176624298095703
Validation loss: 2.296957864556261

Epoch: 6| Step: 7
Training loss: 1.9638748168945312
Validation loss: 2.2931246244779198

Epoch: 6| Step: 8
Training loss: 2.0747835636138916
Validation loss: 2.2914711967591317

Epoch: 6| Step: 9
Training loss: 3.0865461826324463
Validation loss: 2.2906156586062525

Epoch: 6| Step: 10
Training loss: 2.3852462768554688
Validation loss: 2.2940852513877292

Epoch: 6| Step: 11
Training loss: 2.4803552627563477
Validation loss: 2.3038791200166107

Epoch: 6| Step: 12
Training loss: 2.2531073093414307
Validation loss: 2.2942444893621627

Epoch: 6| Step: 13
Training loss: 2.607983112335205
Validation loss: 2.293992119450723

Epoch: 90| Step: 0
Training loss: 2.84110426902771
Validation loss: 2.289617076996834

Epoch: 6| Step: 1
Training loss: 2.3403875827789307
Validation loss: 2.2958095381336827

Epoch: 6| Step: 2
Training loss: 2.0287275314331055
Validation loss: 2.2908359189187326

Epoch: 6| Step: 3
Training loss: 2.5645346641540527
Validation loss: 2.2907286459399807

Epoch: 6| Step: 4
Training loss: 2.7884507179260254
Validation loss: 2.2861596768902195

Epoch: 6| Step: 5
Training loss: 3.287423610687256
Validation loss: 2.284125966410483

Epoch: 6| Step: 6
Training loss: 2.01910400390625
Validation loss: 2.289535378897062

Epoch: 6| Step: 7
Training loss: 2.600055456161499
Validation loss: 2.290052103739913

Epoch: 6| Step: 8
Training loss: 3.3086676597595215
Validation loss: 2.2894242912210445

Epoch: 6| Step: 9
Training loss: 2.2323801517486572
Validation loss: 2.2920232460062993

Epoch: 6| Step: 10
Training loss: 2.049276351928711
Validation loss: 2.290011126507995

Epoch: 6| Step: 11
Training loss: 3.2318711280822754
Validation loss: 2.2964714073365733

Epoch: 6| Step: 12
Training loss: 1.8891355991363525
Validation loss: 2.295853317424815

Epoch: 6| Step: 13
Training loss: 2.5613462924957275
Validation loss: 2.300470462409399

Epoch: 91| Step: 0
Training loss: 3.203705310821533
Validation loss: 2.314066089609618

Epoch: 6| Step: 1
Training loss: 2.6974754333496094
Validation loss: 2.3218008600255495

Epoch: 6| Step: 2
Training loss: 2.2176108360290527
Validation loss: 2.3196030406541723

Epoch: 6| Step: 3
Training loss: 3.2244887351989746
Validation loss: 2.3336857518842145

Epoch: 6| Step: 4
Training loss: 1.7655876874923706
Validation loss: 2.312612541260258

Epoch: 6| Step: 5
Training loss: 3.056746244430542
Validation loss: 2.2989228053759505

Epoch: 6| Step: 6
Training loss: 2.3115992546081543
Validation loss: 2.3091882826179586

Epoch: 6| Step: 7
Training loss: 2.300116777420044
Validation loss: 2.3366843769627232

Epoch: 6| Step: 8
Training loss: 2.4577579498291016
Validation loss: 2.3305699466377177

Epoch: 6| Step: 9
Training loss: 2.0941002368927
Validation loss: 2.3341294462962816

Epoch: 6| Step: 10
Training loss: 2.52990460395813
Validation loss: 2.331967828094318

Epoch: 6| Step: 11
Training loss: 2.2959694862365723
Validation loss: 2.3465963743066274

Epoch: 6| Step: 12
Training loss: 3.1977810859680176
Validation loss: 2.3274976361182427

Epoch: 6| Step: 13
Training loss: 2.314425230026245
Validation loss: 2.3205027041896695

Epoch: 92| Step: 0
Training loss: 1.8352453708648682
Validation loss: 2.325011948103546

Epoch: 6| Step: 1
Training loss: 2.2207906246185303
Validation loss: 2.336333067186417

Epoch: 6| Step: 2
Training loss: 3.1848232746124268
Validation loss: 2.340349643461166

Epoch: 6| Step: 3
Training loss: 2.291933059692383
Validation loss: 2.341610852108207

Epoch: 6| Step: 4
Training loss: 2.9342002868652344
Validation loss: 2.339488334553216

Epoch: 6| Step: 5
Training loss: 2.2713119983673096
Validation loss: 2.3322413249682357

Epoch: 6| Step: 6
Training loss: 2.592904567718506
Validation loss: 2.3276765692618584

Epoch: 6| Step: 7
Training loss: 3.4726297855377197
Validation loss: 2.329982260222076

Epoch: 6| Step: 8
Training loss: 2.035191059112549
Validation loss: 2.3211593666384296

Epoch: 6| Step: 9
Training loss: 2.650724411010742
Validation loss: 2.313135213749383

Epoch: 6| Step: 10
Training loss: 2.6797873973846436
Validation loss: 2.2993356873912196

Epoch: 6| Step: 11
Training loss: 2.32783842086792
Validation loss: 2.297603295695397

Epoch: 6| Step: 12
Training loss: 2.9512321949005127
Validation loss: 2.2904066347306773

Epoch: 6| Step: 13
Training loss: 2.141392707824707
Validation loss: 2.2925725803580335

Epoch: 93| Step: 0
Training loss: 2.724863052368164
Validation loss: 2.29099674635036

Epoch: 6| Step: 1
Training loss: 2.1866016387939453
Validation loss: 2.293962001800537

Epoch: 6| Step: 2
Training loss: 2.5015454292297363
Validation loss: 2.290379883140646

Epoch: 6| Step: 3
Training loss: 3.0054807662963867
Validation loss: 2.2965293930422876

Epoch: 6| Step: 4
Training loss: 2.434706687927246
Validation loss: 2.2977732381513043

Epoch: 6| Step: 5
Training loss: 1.8930556774139404
Validation loss: 2.303438776282854

Epoch: 6| Step: 6
Training loss: 2.622192859649658
Validation loss: 2.2973727154475387

Epoch: 6| Step: 7
Training loss: 2.5158042907714844
Validation loss: 2.2982618552382275

Epoch: 6| Step: 8
Training loss: 2.6954150199890137
Validation loss: 2.2968493379572386

Epoch: 6| Step: 9
Training loss: 2.340001106262207
Validation loss: 2.296343021495368

Epoch: 6| Step: 10
Training loss: 3.2131030559539795
Validation loss: 2.2997372201693955

Epoch: 6| Step: 11
Training loss: 2.255361557006836
Validation loss: 2.299195046065956

Epoch: 6| Step: 12
Training loss: 2.449950933456421
Validation loss: 2.301946945087884

Epoch: 6| Step: 13
Training loss: 3.0026144981384277
Validation loss: 2.3045711722425235

Epoch: 94| Step: 0
Training loss: 2.849057674407959
Validation loss: 2.305612797378212

Epoch: 6| Step: 1
Training loss: 3.0339555740356445
Validation loss: 2.308695177878103

Epoch: 6| Step: 2
Training loss: 2.4790873527526855
Validation loss: 2.3152495571362075

Epoch: 6| Step: 3
Training loss: 2.2614283561706543
Validation loss: 2.3036280203891057

Epoch: 6| Step: 4
Training loss: 1.9618701934814453
Validation loss: 2.296580478709231

Epoch: 6| Step: 5
Training loss: 2.580453872680664
Validation loss: 2.3068830172220864

Epoch: 6| Step: 6
Training loss: 2.4180426597595215
Validation loss: 2.3064899675307737

Epoch: 6| Step: 7
Training loss: 2.3933777809143066
Validation loss: 2.303947728167298

Epoch: 6| Step: 8
Training loss: 2.5934195518493652
Validation loss: 2.3032667380507275

Epoch: 6| Step: 9
Training loss: 2.500047206878662
Validation loss: 2.3146321209528113

Epoch: 6| Step: 10
Training loss: 2.460503101348877
Validation loss: 2.314573895546698

Epoch: 6| Step: 11
Training loss: 2.6965322494506836
Validation loss: 2.3184147086194766

Epoch: 6| Step: 12
Training loss: 3.108884334564209
Validation loss: 2.3263545138861543

Epoch: 6| Step: 13
Training loss: 2.0092172622680664
Validation loss: 2.312109467803791

Epoch: 95| Step: 0
Training loss: 1.8422133922576904
Validation loss: 2.3240801659963464

Epoch: 6| Step: 1
Training loss: 2.1820623874664307
Validation loss: 2.321471247621762

Epoch: 6| Step: 2
Training loss: 2.506748914718628
Validation loss: 2.3235589150459535

Epoch: 6| Step: 3
Training loss: 2.5699830055236816
Validation loss: 2.328865510161205

Epoch: 6| Step: 4
Training loss: 2.513585090637207
Validation loss: 2.3292403503130843

Epoch: 6| Step: 5
Training loss: 1.7839410305023193
Validation loss: 2.3275784318165114

Epoch: 6| Step: 6
Training loss: 3.5015134811401367
Validation loss: 2.3270000385981735

Epoch: 6| Step: 7
Training loss: 2.1342310905456543
Validation loss: 2.3075071611712055

Epoch: 6| Step: 8
Training loss: 3.5571694374084473
Validation loss: 2.3108936484142015

Epoch: 6| Step: 9
Training loss: 2.4120516777038574
Validation loss: 2.302159068404987

Epoch: 6| Step: 10
Training loss: 2.7517104148864746
Validation loss: 2.2910847266515098

Epoch: 6| Step: 11
Training loss: 2.3594915866851807
Validation loss: 2.292000550095753

Epoch: 6| Step: 12
Training loss: 2.6427903175354004
Validation loss: 2.2936337199262393

Epoch: 6| Step: 13
Training loss: 3.124983549118042
Validation loss: 2.297520511893816

Epoch: 96| Step: 0
Training loss: 3.2902259826660156
Validation loss: 2.2934509554216937

Epoch: 6| Step: 1
Training loss: 2.786776542663574
Validation loss: 2.29164037909559

Epoch: 6| Step: 2
Training loss: 2.620084285736084
Validation loss: 2.288532200679984

Epoch: 6| Step: 3
Training loss: 2.424321413040161
Validation loss: 2.2764300248956166

Epoch: 6| Step: 4
Training loss: 2.4255523681640625
Validation loss: 2.2758549592828237

Epoch: 6| Step: 5
Training loss: 2.3818302154541016
Validation loss: 2.2754789731835805

Epoch: 6| Step: 6
Training loss: 2.745023012161255
Validation loss: 2.2751469278848298

Epoch: 6| Step: 7
Training loss: 2.174170732498169
Validation loss: 2.2664940408481065

Epoch: 6| Step: 8
Training loss: 1.829810619354248
Validation loss: 2.2650753272477018

Epoch: 6| Step: 9
Training loss: 2.256037712097168
Validation loss: 2.267350535238943

Epoch: 6| Step: 10
Training loss: 3.084804058074951
Validation loss: 2.2665005832590084

Epoch: 6| Step: 11
Training loss: 2.3510642051696777
Validation loss: 2.2658092565433954

Epoch: 6| Step: 12
Training loss: 2.190577507019043
Validation loss: 2.259971905780095

Epoch: 6| Step: 13
Training loss: 3.2448644638061523
Validation loss: 2.269410720435522

Epoch: 97| Step: 0
Training loss: 1.7432093620300293
Validation loss: 2.271183062625188

Epoch: 6| Step: 1
Training loss: 2.491011142730713
Validation loss: 2.2875295710820023

Epoch: 6| Step: 2
Training loss: 2.4240050315856934
Validation loss: 2.2865670240053566

Epoch: 6| Step: 3
Training loss: 2.4384727478027344
Validation loss: 2.2975364039021153

Epoch: 6| Step: 4
Training loss: 3.0753438472747803
Validation loss: 2.2935108113032516

Epoch: 6| Step: 5
Training loss: 3.046994209289551
Validation loss: 2.296862545833793

Epoch: 6| Step: 6
Training loss: 3.0278639793395996
Validation loss: 2.283389937493109

Epoch: 6| Step: 7
Training loss: 2.5385470390319824
Validation loss: 2.2812027431303457

Epoch: 6| Step: 8
Training loss: 3.244173765182495
Validation loss: 2.282226385608796

Epoch: 6| Step: 9
Training loss: 2.309997081756592
Validation loss: 2.284801096044561

Epoch: 6| Step: 10
Training loss: 2.7009572982788086
Validation loss: 2.286756661630446

Epoch: 6| Step: 11
Training loss: 1.6818842887878418
Validation loss: 2.295828333465002

Epoch: 6| Step: 12
Training loss: 2.610642671585083
Validation loss: 2.3050782526693037

Epoch: 6| Step: 13
Training loss: 1.6525886058807373
Validation loss: 2.3067761108439457

Epoch: 98| Step: 0
Training loss: 2.682985782623291
Validation loss: 2.3091304456034014

Epoch: 6| Step: 1
Training loss: 2.7554149627685547
Validation loss: 2.31406505005334

Epoch: 6| Step: 2
Training loss: 2.515450954437256
Validation loss: 2.3184749208470827

Epoch: 6| Step: 3
Training loss: 2.6616780757904053
Validation loss: 2.301548360496439

Epoch: 6| Step: 4
Training loss: 1.765272617340088
Validation loss: 2.3115749961586407

Epoch: 6| Step: 5
Training loss: 2.3256962299346924
Validation loss: 2.302273255522533

Epoch: 6| Step: 6
Training loss: 2.6718645095825195
Validation loss: 2.308484685036444

Epoch: 6| Step: 7
Training loss: 2.23449969291687
Validation loss: 2.3093781727616505

Epoch: 6| Step: 8
Training loss: 2.4427928924560547
Validation loss: 2.3038093338730516

Epoch: 6| Step: 9
Training loss: 3.2761480808258057
Validation loss: 2.3093984883318663

Epoch: 6| Step: 10
Training loss: 2.7278318405151367
Validation loss: 2.315289839621513

Epoch: 6| Step: 11
Training loss: 2.534116744995117
Validation loss: 2.3112516044288554

Epoch: 6| Step: 12
Training loss: 2.511291742324829
Validation loss: 2.3073141831223682

Epoch: 6| Step: 13
Training loss: 2.107109546661377
Validation loss: 2.3133582633028746

Epoch: 99| Step: 0
Training loss: 2.946122646331787
Validation loss: 2.315537284779292

Epoch: 6| Step: 1
Training loss: 2.8261289596557617
Validation loss: 2.3175203800201416

Epoch: 6| Step: 2
Training loss: 2.12612247467041
Validation loss: 2.302671468386086

Epoch: 6| Step: 3
Training loss: 2.5821115970611572
Validation loss: 2.2985681359485914

Epoch: 6| Step: 4
Training loss: 2.410186767578125
Validation loss: 2.280860279196052

Epoch: 6| Step: 5
Training loss: 2.4308595657348633
Validation loss: 2.276346304083383

Epoch: 6| Step: 6
Training loss: 2.566704750061035
Validation loss: 2.2771618571332706

Epoch: 6| Step: 7
Training loss: 2.614824056625366
Validation loss: 2.289473064484135

Epoch: 6| Step: 8
Training loss: 2.822613000869751
Validation loss: 2.296397283513059

Epoch: 6| Step: 9
Training loss: 2.1467528343200684
Validation loss: 2.291611853466239

Epoch: 6| Step: 10
Training loss: 2.656780481338501
Validation loss: 2.272671530323644

Epoch: 6| Step: 11
Training loss: 2.45652437210083
Validation loss: 2.2627380022438626

Epoch: 6| Step: 12
Training loss: 2.337246894836426
Validation loss: 2.2651613886638353

Epoch: 6| Step: 13
Training loss: 2.6572353839874268
Validation loss: 2.2680342658873527

Epoch: 100| Step: 0
Training loss: 2.1267507076263428
Validation loss: 2.2821472908860896

Epoch: 6| Step: 1
Training loss: 2.613468647003174
Validation loss: 2.305547300205436

Epoch: 6| Step: 2
Training loss: 2.70402455329895
Validation loss: 2.326020253601895

Epoch: 6| Step: 3
Training loss: 1.9623640775680542
Validation loss: 2.348659735853954

Epoch: 6| Step: 4
Training loss: 2.00378155708313
Validation loss: 2.3620280117116947

Epoch: 6| Step: 5
Training loss: 2.843742609024048
Validation loss: 2.3766795794169107

Epoch: 6| Step: 6
Training loss: 2.4462075233459473
Validation loss: 2.3478295546706005

Epoch: 6| Step: 7
Training loss: 2.230276346206665
Validation loss: 2.3477750055251585

Epoch: 6| Step: 8
Training loss: 2.324991226196289
Validation loss: 2.31891546967209

Epoch: 6| Step: 9
Training loss: 2.7976598739624023
Validation loss: 2.3104093446526477

Epoch: 6| Step: 10
Training loss: 2.9356226921081543
Validation loss: 2.2976960725681757

Epoch: 6| Step: 11
Training loss: 2.4395411014556885
Validation loss: 2.294944683710734

Epoch: 6| Step: 12
Training loss: 3.1593947410583496
Validation loss: 2.3145541042409916

Epoch: 6| Step: 13
Training loss: 3.5254926681518555
Validation loss: 2.3419115774093138

Epoch: 101| Step: 0
Training loss: 3.0134975910186768
Validation loss: 2.342790698492399

Epoch: 6| Step: 1
Training loss: 2.813734769821167
Validation loss: 2.3218633846570085

Epoch: 6| Step: 2
Training loss: 2.527709484100342
Validation loss: 2.33044498197494

Epoch: 6| Step: 3
Training loss: 2.383237361907959
Validation loss: 2.3006522347850185

Epoch: 6| Step: 4
Training loss: 3.173398494720459
Validation loss: 2.2769707889967066

Epoch: 6| Step: 5
Training loss: 3.2590620517730713
Validation loss: 2.261877547028244

Epoch: 6| Step: 6
Training loss: 1.2804644107818604
Validation loss: 2.256368342266288

Epoch: 6| Step: 7
Training loss: 2.877856969833374
Validation loss: 2.2585263764986427

Epoch: 6| Step: 8
Training loss: 1.968697190284729
Validation loss: 2.255845905632101

Epoch: 6| Step: 9
Training loss: 1.6425800323486328
Validation loss: 2.258596158796741

Epoch: 6| Step: 10
Training loss: 2.8480916023254395
Validation loss: 2.276827791685699

Epoch: 6| Step: 11
Training loss: 2.6293163299560547
Validation loss: 2.291273740030104

Epoch: 6| Step: 12
Training loss: 2.3985185623168945
Validation loss: 2.2953661744312575

Epoch: 6| Step: 13
Training loss: 2.8262782096862793
Validation loss: 2.3000197923311623

Epoch: 102| Step: 0
Training loss: 2.8030009269714355
Validation loss: 2.2948560381448395

Epoch: 6| Step: 1
Training loss: 2.8762569427490234
Validation loss: 2.3037841217492216

Epoch: 6| Step: 2
Training loss: 2.381162643432617
Validation loss: 2.311206122880341

Epoch: 6| Step: 3
Training loss: 2.3485240936279297
Validation loss: 2.3062918109278523

Epoch: 6| Step: 4
Training loss: 2.7289211750030518
Validation loss: 2.295154248514483

Epoch: 6| Step: 5
Training loss: 2.534350872039795
Validation loss: 2.27738881111145

Epoch: 6| Step: 6
Training loss: 2.733297348022461
Validation loss: 2.276296715582571

Epoch: 6| Step: 7
Training loss: 2.8698537349700928
Validation loss: 2.277492582157094

Epoch: 6| Step: 8
Training loss: 1.5812225341796875
Validation loss: 2.2890281728518906

Epoch: 6| Step: 9
Training loss: 2.1535658836364746
Validation loss: 2.2987771034240723

Epoch: 6| Step: 10
Training loss: 2.179826021194458
Validation loss: 2.310470683600313

Epoch: 6| Step: 11
Training loss: 2.5129926204681396
Validation loss: 2.3097684870484056

Epoch: 6| Step: 12
Training loss: 3.391484260559082
Validation loss: 2.309066040541536

Epoch: 6| Step: 13
Training loss: 2.377902030944824
Validation loss: 2.2746099425900366

Epoch: 103| Step: 0
Training loss: 2.5986952781677246
Validation loss: 2.262751322920604

Epoch: 6| Step: 1
Training loss: 3.909120798110962
Validation loss: 2.2647363652465162

Epoch: 6| Step: 2
Training loss: 2.4474780559539795
Validation loss: 2.2576202833524315

Epoch: 6| Step: 3
Training loss: 2.2991862297058105
Validation loss: 2.2641746895287627

Epoch: 6| Step: 4
Training loss: 2.7687337398529053
Validation loss: 2.2653204356470416

Epoch: 6| Step: 5
Training loss: 2.4675827026367188
Validation loss: 2.263597793476556

Epoch: 6| Step: 6
Training loss: 2.2976863384246826
Validation loss: 2.292306069404848

Epoch: 6| Step: 7
Training loss: 2.434328556060791
Validation loss: 2.2838016479246077

Epoch: 6| Step: 8
Training loss: 2.6994481086730957
Validation loss: 2.2871012277500604

Epoch: 6| Step: 9
Training loss: 2.4622435569763184
Validation loss: 2.2780924099747852

Epoch: 6| Step: 10
Training loss: 2.5596799850463867
Validation loss: 2.2574223651680896

Epoch: 6| Step: 11
Training loss: 1.5609580278396606
Validation loss: 2.2400587348527807

Epoch: 6| Step: 12
Training loss: 2.7751126289367676
Validation loss: 2.234930584507604

Epoch: 6| Step: 13
Training loss: 2.0914735794067383
Validation loss: 2.2289128713710333

Epoch: 104| Step: 0
Training loss: 2.444490909576416
Validation loss: 2.228140305447322

Epoch: 6| Step: 1
Training loss: 4.0216169357299805
Validation loss: 2.2349914684090564

Epoch: 6| Step: 2
Training loss: 2.4708590507507324
Validation loss: 2.23813376375424

Epoch: 6| Step: 3
Training loss: 2.462536334991455
Validation loss: 2.2434653056565153

Epoch: 6| Step: 4
Training loss: 1.6821484565734863
Validation loss: 2.2479688582881803

Epoch: 6| Step: 5
Training loss: 2.5326619148254395
Validation loss: 2.2722193092428227

Epoch: 6| Step: 6
Training loss: 2.7616724967956543
Validation loss: 2.2853036670274633

Epoch: 6| Step: 7
Training loss: 2.1640071868896484
Validation loss: 2.2997611632911106

Epoch: 6| Step: 8
Training loss: 3.022045135498047
Validation loss: 2.2891492023262927

Epoch: 6| Step: 9
Training loss: 2.3991947174072266
Validation loss: 2.290275683967016

Epoch: 6| Step: 10
Training loss: 2.1883111000061035
Validation loss: 2.277201480762933

Epoch: 6| Step: 11
Training loss: 2.5964102745056152
Validation loss: 2.263504643594065

Epoch: 6| Step: 12
Training loss: 2.21304988861084
Validation loss: 2.251535254140054

Epoch: 6| Step: 13
Training loss: 2.3838579654693604
Validation loss: 2.2470738887786865

Epoch: 105| Step: 0
Training loss: 2.729705810546875
Validation loss: 2.237084698933427

Epoch: 6| Step: 1
Training loss: 2.284080743789673
Validation loss: 2.245988407442647

Epoch: 6| Step: 2
Training loss: 1.993674397468567
Validation loss: 2.2475685355483845

Epoch: 6| Step: 3
Training loss: 2.7644801139831543
Validation loss: 2.2635624895813646

Epoch: 6| Step: 4
Training loss: 2.342290163040161
Validation loss: 2.2773895417490313

Epoch: 6| Step: 5
Training loss: 2.9233107566833496
Validation loss: 2.27483360357182

Epoch: 6| Step: 6
Training loss: 3.257810115814209
Validation loss: 2.265996474091725

Epoch: 6| Step: 7
Training loss: 2.6973822116851807
Validation loss: 2.266654265824185

Epoch: 6| Step: 8
Training loss: 2.4414682388305664
Validation loss: 2.25760639995657

Epoch: 6| Step: 9
Training loss: 2.3564093112945557
Validation loss: 2.250771059784838

Epoch: 6| Step: 10
Training loss: 2.181809663772583
Validation loss: 2.2458275338654876

Epoch: 6| Step: 11
Training loss: 2.420480251312256
Validation loss: 2.244711983588434

Epoch: 6| Step: 12
Training loss: 2.613028049468994
Validation loss: 2.243629963167252

Epoch: 6| Step: 13
Training loss: 2.1243791580200195
Validation loss: 2.2432844715733684

Epoch: 106| Step: 0
Training loss: 2.603578567504883
Validation loss: 2.2518081485584216

Epoch: 6| Step: 1
Training loss: 2.3622424602508545
Validation loss: 2.25411993201061

Epoch: 6| Step: 2
Training loss: 2.806619167327881
Validation loss: 2.2591000577454925

Epoch: 6| Step: 3
Training loss: 2.310237169265747
Validation loss: 2.2651270179338354

Epoch: 6| Step: 4
Training loss: 2.316035032272339
Validation loss: 2.2646770297840075

Epoch: 6| Step: 5
Training loss: 2.3555030822753906
Validation loss: 2.269253880746903

Epoch: 6| Step: 6
Training loss: 2.027757167816162
Validation loss: 2.2783656620210215

Epoch: 6| Step: 7
Training loss: 2.736436605453491
Validation loss: 2.2776389711646625

Epoch: 6| Step: 8
Training loss: 3.068540573120117
Validation loss: 2.2860495351975962

Epoch: 6| Step: 9
Training loss: 2.726854085922241
Validation loss: 2.279829717451526

Epoch: 6| Step: 10
Training loss: 2.2179789543151855
Validation loss: 2.2823421211652857

Epoch: 6| Step: 11
Training loss: 2.004563093185425
Validation loss: 2.2826079476264214

Epoch: 6| Step: 12
Training loss: 2.885143280029297
Validation loss: 2.2918422888684016

Epoch: 6| Step: 13
Training loss: 2.6519267559051514
Validation loss: 2.2896740795463644

Epoch: 107| Step: 0
Training loss: 2.9463233947753906
Validation loss: 2.2988084490581224

Epoch: 6| Step: 1
Training loss: 2.8169713020324707
Validation loss: 2.3007986750653995

Epoch: 6| Step: 2
Training loss: 2.6912918090820312
Validation loss: 2.2979194989768406

Epoch: 6| Step: 3
Training loss: 2.4436001777648926
Validation loss: 2.291144158250542

Epoch: 6| Step: 4
Training loss: 1.9954320192337036
Validation loss: 2.29346393000695

Epoch: 6| Step: 5
Training loss: 2.8471310138702393
Validation loss: 2.2839678256742415

Epoch: 6| Step: 6
Training loss: 2.5165534019470215
Validation loss: 2.277694907239688

Epoch: 6| Step: 7
Training loss: 2.6393823623657227
Validation loss: 2.2784366120574293

Epoch: 6| Step: 8
Training loss: 2.502084255218506
Validation loss: 2.2739521662394204

Epoch: 6| Step: 9
Training loss: 2.85532808303833
Validation loss: 2.2755989156743532

Epoch: 6| Step: 10
Training loss: 2.3733630180358887
Validation loss: 2.290752257070234

Epoch: 6| Step: 11
Training loss: 2.331731081008911
Validation loss: 2.3143963275417203

Epoch: 6| Step: 12
Training loss: 1.8920931816101074
Validation loss: 2.296032069831766

Epoch: 6| Step: 13
Training loss: 1.7874488830566406
Validation loss: 2.2870817684358165

Epoch: 108| Step: 0
Training loss: 1.6417757272720337
Validation loss: 2.2850078357163297

Epoch: 6| Step: 1
Training loss: 2.694028854370117
Validation loss: 2.2896694009022047

Epoch: 6| Step: 2
Training loss: 2.2156829833984375
Validation loss: 2.303305120878322

Epoch: 6| Step: 3
Training loss: 3.467181921005249
Validation loss: 2.30077939392418

Epoch: 6| Step: 4
Training loss: 2.752378463745117
Validation loss: 2.2979539491797007

Epoch: 6| Step: 5
Training loss: 1.7093435525894165
Validation loss: 2.270307269147647

Epoch: 6| Step: 6
Training loss: 3.293397903442383
Validation loss: 2.2778767821609334

Epoch: 6| Step: 7
Training loss: 1.9565119743347168
Validation loss: 2.2655609653842066

Epoch: 6| Step: 8
Training loss: 3.3602209091186523
Validation loss: 2.254600573611516

Epoch: 6| Step: 9
Training loss: 2.816258192062378
Validation loss: 2.2501557334776847

Epoch: 6| Step: 10
Training loss: 2.5392885208129883
Validation loss: 2.238959925149077

Epoch: 6| Step: 11
Training loss: 2.0055508613586426
Validation loss: 2.229018326728575

Epoch: 6| Step: 12
Training loss: 2.2400875091552734
Validation loss: 2.2228249478083786

Epoch: 6| Step: 13
Training loss: 1.8795465230941772
Validation loss: 2.228764710887786

Epoch: 109| Step: 0
Training loss: 2.2249491214752197
Validation loss: 2.2261924359106247

Epoch: 6| Step: 1
Training loss: 2.9610514640808105
Validation loss: 2.227640485250822

Epoch: 6| Step: 2
Training loss: 2.0851171016693115
Validation loss: 2.225002037581577

Epoch: 6| Step: 3
Training loss: 2.1903605461120605
Validation loss: 2.2283775268062467

Epoch: 6| Step: 4
Training loss: 1.90809166431427
Validation loss: 2.2307710545037382

Epoch: 6| Step: 5
Training loss: 3.10762357711792
Validation loss: 2.232441556069159

Epoch: 6| Step: 6
Training loss: 2.6434519290924072
Validation loss: 2.241872828493836

Epoch: 6| Step: 7
Training loss: 2.572512626647949
Validation loss: 2.2452989957665883

Epoch: 6| Step: 8
Training loss: 2.0279693603515625
Validation loss: 2.2411818735061155

Epoch: 6| Step: 9
Training loss: 2.5637636184692383
Validation loss: 2.2460081936210714

Epoch: 6| Step: 10
Training loss: 2.337559223175049
Validation loss: 2.252814592853669

Epoch: 6| Step: 11
Training loss: 3.2110846042633057
Validation loss: 2.2551487594522457

Epoch: 6| Step: 12
Training loss: 2.520839214324951
Validation loss: 2.2617082480461366

Epoch: 6| Step: 13
Training loss: 2.886068820953369
Validation loss: 2.2732797412462133

Epoch: 110| Step: 0
Training loss: 2.9506053924560547
Validation loss: 2.272166436718356

Epoch: 6| Step: 1
Training loss: 2.795858860015869
Validation loss: 2.2728988098841842

Epoch: 6| Step: 2
Training loss: 1.606375813484192
Validation loss: 2.282551024549751

Epoch: 6| Step: 3
Training loss: 2.4066784381866455
Validation loss: 2.2803965255778325

Epoch: 6| Step: 4
Training loss: 2.2344746589660645
Validation loss: 2.2832560334154355

Epoch: 6| Step: 5
Training loss: 2.2354989051818848
Validation loss: 2.2924972503416

Epoch: 6| Step: 6
Training loss: 1.9967670440673828
Validation loss: 2.293657964275729

Epoch: 6| Step: 7
Training loss: 2.130030632019043
Validation loss: 2.2603735257220525

Epoch: 6| Step: 8
Training loss: 3.229450225830078
Validation loss: 2.270520612757693

Epoch: 6| Step: 9
Training loss: 2.088622570037842
Validation loss: 2.2571724230243313

Epoch: 6| Step: 10
Training loss: 2.563314437866211
Validation loss: 2.252801038885629

Epoch: 6| Step: 11
Training loss: 3.3892228603363037
Validation loss: 2.2474647106662875

Epoch: 6| Step: 12
Training loss: 2.718691825866699
Validation loss: 2.241415726241245

Epoch: 6| Step: 13
Training loss: 2.6081037521362305
Validation loss: 2.247154676786033

Epoch: 111| Step: 0
Training loss: 2.786393404006958
Validation loss: 2.2608943139353106

Epoch: 6| Step: 1
Training loss: 2.4040889739990234
Validation loss: 2.274733586977887

Epoch: 6| Step: 2
Training loss: 1.9314825534820557
Validation loss: 2.3172241641629125

Epoch: 6| Step: 3
Training loss: 2.836411714553833
Validation loss: 2.3031261326164327

Epoch: 6| Step: 4
Training loss: 2.3887856006622314
Validation loss: 2.29627642836622

Epoch: 6| Step: 5
Training loss: 2.1987693309783936
Validation loss: 2.2961090854419175

Epoch: 6| Step: 6
Training loss: 3.275639533996582
Validation loss: 2.2886151113817768

Epoch: 6| Step: 7
Training loss: 2.8948004245758057
Validation loss: 2.2738204745836157

Epoch: 6| Step: 8
Training loss: 1.6897718906402588
Validation loss: 2.2747240117801133

Epoch: 6| Step: 9
Training loss: 3.347038507461548
Validation loss: 2.2760015790180494

Epoch: 6| Step: 10
Training loss: 1.885750651359558
Validation loss: 2.265961029196298

Epoch: 6| Step: 11
Training loss: 2.512864589691162
Validation loss: 2.2485100069353656

Epoch: 6| Step: 12
Training loss: 2.456516981124878
Validation loss: 2.229926763042327

Epoch: 6| Step: 13
Training loss: 2.6598668098449707
Validation loss: 2.2262913591118267

Epoch: 112| Step: 0
Training loss: 2.5541439056396484
Validation loss: 2.235189653212024

Epoch: 6| Step: 1
Training loss: 3.075368881225586
Validation loss: 2.2359984074869463

Epoch: 6| Step: 2
Training loss: 2.499011993408203
Validation loss: 2.237564730387862

Epoch: 6| Step: 3
Training loss: 2.1311144828796387
Validation loss: 2.2332525407114336

Epoch: 6| Step: 4
Training loss: 2.906219005584717
Validation loss: 2.228365775077574

Epoch: 6| Step: 5
Training loss: 2.385105609893799
Validation loss: 2.2239795730959986

Epoch: 6| Step: 6
Training loss: 2.976881980895996
Validation loss: 2.2272981418076383

Epoch: 6| Step: 7
Training loss: 2.070565700531006
Validation loss: 2.221919318681122

Epoch: 6| Step: 8
Training loss: 2.4925780296325684
Validation loss: 2.228981507721768

Epoch: 6| Step: 9
Training loss: 2.086270332336426
Validation loss: 2.247057230241837

Epoch: 6| Step: 10
Training loss: 2.753112316131592
Validation loss: 2.2680776119232178

Epoch: 6| Step: 11
Training loss: 2.0703065395355225
Validation loss: 2.258132988406766

Epoch: 6| Step: 12
Training loss: 2.6258156299591064
Validation loss: 2.239980502795148

Epoch: 6| Step: 13
Training loss: 2.2977888584136963
Validation loss: 2.2444389148425032

Epoch: 113| Step: 0
Training loss: 2.098391532897949
Validation loss: 2.228772860701366

Epoch: 6| Step: 1
Training loss: 2.7897462844848633
Validation loss: 2.2323892578001945

Epoch: 6| Step: 2
Training loss: 2.4114911556243896
Validation loss: 2.2199727591647895

Epoch: 6| Step: 3
Training loss: 2.3837006092071533
Validation loss: 2.2199670012279222

Epoch: 6| Step: 4
Training loss: 2.292306900024414
Validation loss: 2.21789264422591

Epoch: 6| Step: 5
Training loss: 2.897019386291504
Validation loss: 2.22320040323401

Epoch: 6| Step: 6
Training loss: 1.941817045211792
Validation loss: 2.2272195649403397

Epoch: 6| Step: 7
Training loss: 3.0278372764587402
Validation loss: 2.2247340781714326

Epoch: 6| Step: 8
Training loss: 2.2921361923217773
Validation loss: 2.2264117220396638

Epoch: 6| Step: 9
Training loss: 2.2748661041259766
Validation loss: 2.2351244136851323

Epoch: 6| Step: 10
Training loss: 2.8436965942382812
Validation loss: 2.2362517336363434

Epoch: 6| Step: 11
Training loss: 2.518472194671631
Validation loss: 2.240200404197939

Epoch: 6| Step: 12
Training loss: 2.1262645721435547
Validation loss: 2.2399277289708457

Epoch: 6| Step: 13
Training loss: 3.3323354721069336
Validation loss: 2.2407440011219313

Epoch: 114| Step: 0
Training loss: 1.9106106758117676
Validation loss: 2.2367447422396753

Epoch: 6| Step: 1
Training loss: 2.9547083377838135
Validation loss: 2.233112727442095

Epoch: 6| Step: 2
Training loss: 2.9510974884033203
Validation loss: 2.235541997417327

Epoch: 6| Step: 3
Training loss: 2.2490789890289307
Validation loss: 2.2308035255760275

Epoch: 6| Step: 4
Training loss: 2.5897421836853027
Validation loss: 2.2497719654472927

Epoch: 6| Step: 5
Training loss: 2.377092123031616
Validation loss: 2.2673584415066625

Epoch: 6| Step: 6
Training loss: 2.171250343322754
Validation loss: 2.2748796145121255

Epoch: 6| Step: 7
Training loss: 2.4723191261291504
Validation loss: 2.269298723948899

Epoch: 6| Step: 8
Training loss: 2.4434683322906494
Validation loss: 2.2367816791739514

Epoch: 6| Step: 9
Training loss: 2.237415313720703
Validation loss: 2.221702262919436

Epoch: 6| Step: 10
Training loss: 2.1906330585479736
Validation loss: 2.2156782739905903

Epoch: 6| Step: 11
Training loss: 2.3028900623321533
Validation loss: 2.2081184925571566

Epoch: 6| Step: 12
Training loss: 2.992253303527832
Validation loss: 2.2191103504550074

Epoch: 6| Step: 13
Training loss: 3.563836097717285
Validation loss: 2.226645977266373

Epoch: 115| Step: 0
Training loss: 2.2069952487945557
Validation loss: 2.231337526793121

Epoch: 6| Step: 1
Training loss: 2.120544910430908
Validation loss: 2.2286761653038765

Epoch: 6| Step: 2
Training loss: 3.388906240463257
Validation loss: 2.2173365034082884

Epoch: 6| Step: 3
Training loss: 2.0746712684631348
Validation loss: 2.209031112732426

Epoch: 6| Step: 4
Training loss: 2.618252992630005
Validation loss: 2.225939812198762

Epoch: 6| Step: 5
Training loss: 2.251389980316162
Validation loss: 2.2256961381563576

Epoch: 6| Step: 6
Training loss: 2.7406234741210938
Validation loss: 2.2158511941150953

Epoch: 6| Step: 7
Training loss: 2.9275174140930176
Validation loss: 2.222788845339129

Epoch: 6| Step: 8
Training loss: 2.4580345153808594
Validation loss: 2.2311923401330107

Epoch: 6| Step: 9
Training loss: 2.711956024169922
Validation loss: 2.232178213775799

Epoch: 6| Step: 10
Training loss: 2.3024063110351562
Validation loss: 2.227135399336456

Epoch: 6| Step: 11
Training loss: 2.5216667652130127
Validation loss: 2.248068045544368

Epoch: 6| Step: 12
Training loss: 2.244649887084961
Validation loss: 2.2387558260271625

Epoch: 6| Step: 13
Training loss: 1.7179878950119019
Validation loss: 2.2382143146248272

Epoch: 116| Step: 0
Training loss: 2.061565399169922
Validation loss: 2.2405109033789685

Epoch: 6| Step: 1
Training loss: 2.4970970153808594
Validation loss: 2.2469250976398425

Epoch: 6| Step: 2
Training loss: 2.4207537174224854
Validation loss: 2.25763379117494

Epoch: 6| Step: 3
Training loss: 2.5438284873962402
Validation loss: 2.2553086716641664

Epoch: 6| Step: 4
Training loss: 2.0085198879241943
Validation loss: 2.2557207256235103

Epoch: 6| Step: 5
Training loss: 2.6347806453704834
Validation loss: 2.257981631063646

Epoch: 6| Step: 6
Training loss: 2.6170897483825684
Validation loss: 2.2573946983583513

Epoch: 6| Step: 7
Training loss: 2.1835861206054688
Validation loss: 2.259640911574005

Epoch: 6| Step: 8
Training loss: 2.8912007808685303
Validation loss: 2.2659940360694804

Epoch: 6| Step: 9
Training loss: 2.701228380203247
Validation loss: 2.268539697893204

Epoch: 6| Step: 10
Training loss: 2.713867664337158
Validation loss: 2.274211750235609

Epoch: 6| Step: 11
Training loss: 2.004899024963379
Validation loss: 2.2727886015369045

Epoch: 6| Step: 12
Training loss: 2.2542850971221924
Validation loss: 2.263922888745544

Epoch: 6| Step: 13
Training loss: 3.3924601078033447
Validation loss: 2.261754351277505

Epoch: 117| Step: 0
Training loss: 2.343292236328125
Validation loss: 2.25738416435898

Epoch: 6| Step: 1
Training loss: 2.5363690853118896
Validation loss: 2.24865250561827

Epoch: 6| Step: 2
Training loss: 2.5056095123291016
Validation loss: 2.253899779371036

Epoch: 6| Step: 3
Training loss: 2.0287535190582275
Validation loss: 2.2408979887603433

Epoch: 6| Step: 4
Training loss: 2.0793240070343018
Validation loss: 2.243982402227258

Epoch: 6| Step: 5
Training loss: 2.0056161880493164
Validation loss: 2.241106802417386

Epoch: 6| Step: 6
Training loss: 2.790273427963257
Validation loss: 2.244118977618474

Epoch: 6| Step: 7
Training loss: 2.8707728385925293
Validation loss: 2.262914316628569

Epoch: 6| Step: 8
Training loss: 2.4132707118988037
Validation loss: 2.28123745354273

Epoch: 6| Step: 9
Training loss: 2.6513729095458984
Validation loss: 2.2789070067867154

Epoch: 6| Step: 10
Training loss: 2.912487030029297
Validation loss: 2.2798855817446144

Epoch: 6| Step: 11
Training loss: 2.77022647857666
Validation loss: 2.2651858227227324

Epoch: 6| Step: 12
Training loss: 2.5209290981292725
Validation loss: 2.2558528095163326

Epoch: 6| Step: 13
Training loss: 1.9251573085784912
Validation loss: 2.229485265670284

Epoch: 118| Step: 0
Training loss: 2.1677982807159424
Validation loss: 2.2157017697570143

Epoch: 6| Step: 1
Training loss: 3.2995147705078125
Validation loss: 2.219400405883789

Epoch: 6| Step: 2
Training loss: 1.691910743713379
Validation loss: 2.2175522978587816

Epoch: 6| Step: 3
Training loss: 2.761754274368286
Validation loss: 2.2286026170176845

Epoch: 6| Step: 4
Training loss: 3.0308189392089844
Validation loss: 2.2234892768244587

Epoch: 6| Step: 5
Training loss: 2.613399028778076
Validation loss: 2.220938046773275

Epoch: 6| Step: 6
Training loss: 2.591472625732422
Validation loss: 2.2236411340775026

Epoch: 6| Step: 7
Training loss: 1.6996004581451416
Validation loss: 2.216516092259397

Epoch: 6| Step: 8
Training loss: 2.3675990104675293
Validation loss: 2.2173692872447353

Epoch: 6| Step: 9
Training loss: 2.4692039489746094
Validation loss: 2.2217061660623036

Epoch: 6| Step: 10
Training loss: 2.2385776042938232
Validation loss: 2.224711251515214

Epoch: 6| Step: 11
Training loss: 2.890424966812134
Validation loss: 2.212848917130501

Epoch: 6| Step: 12
Training loss: 2.3466219902038574
Validation loss: 2.221826127780381

Epoch: 6| Step: 13
Training loss: 2.148463249206543
Validation loss: 2.222649807571083

Epoch: 119| Step: 0
Training loss: 3.047184705734253
Validation loss: 2.244248713216474

Epoch: 6| Step: 1
Training loss: 2.2311899662017822
Validation loss: 2.2824166692713255

Epoch: 6| Step: 2
Training loss: 2.8985702991485596
Validation loss: 2.280581025667088

Epoch: 6| Step: 3
Training loss: 2.7076284885406494
Validation loss: 2.276829747743504

Epoch: 6| Step: 4
Training loss: 2.4489827156066895
Validation loss: 2.280048067851733

Epoch: 6| Step: 5
Training loss: 1.8340566158294678
Validation loss: 2.270094907411965

Epoch: 6| Step: 6
Training loss: 2.7140700817108154
Validation loss: 2.251502493376373

Epoch: 6| Step: 7
Training loss: 2.8697731494903564
Validation loss: 2.2380004775139595

Epoch: 6| Step: 8
Training loss: 2.3498425483703613
Validation loss: 2.23966230628311

Epoch: 6| Step: 9
Training loss: 2.3191230297088623
Validation loss: 2.232718736894669

Epoch: 6| Step: 10
Training loss: 2.1957361698150635
Validation loss: 2.234272005737469

Epoch: 6| Step: 11
Training loss: 2.4217886924743652
Validation loss: 2.2401052751848773

Epoch: 6| Step: 12
Training loss: 2.0503621101379395
Validation loss: 2.2367179573223157

Epoch: 6| Step: 13
Training loss: 1.977060079574585
Validation loss: 2.2481857397223033

Epoch: 120| Step: 0
Training loss: 2.0748708248138428
Validation loss: 2.2350884522161176

Epoch: 6| Step: 1
Training loss: 2.6133899688720703
Validation loss: 2.2426625708098054

Epoch: 6| Step: 2
Training loss: 2.7218332290649414
Validation loss: 2.2340402398058163

Epoch: 6| Step: 3
Training loss: 1.8084392547607422
Validation loss: 2.2341155288039998

Epoch: 6| Step: 4
Training loss: 3.291012763977051
Validation loss: 2.24031469257929

Epoch: 6| Step: 5
Training loss: 2.3265414237976074
Validation loss: 2.2378760230156685

Epoch: 6| Step: 6
Training loss: 2.6597282886505127
Validation loss: 2.242193651455705

Epoch: 6| Step: 7
Training loss: 2.3331661224365234
Validation loss: 2.254240137274547

Epoch: 6| Step: 8
Training loss: 2.9950203895568848
Validation loss: 2.2511129635636524

Epoch: 6| Step: 9
Training loss: 2.583963632583618
Validation loss: 2.2484911334130073

Epoch: 6| Step: 10
Training loss: 2.4737982749938965
Validation loss: 2.259884707389339

Epoch: 6| Step: 11
Training loss: 2.31427001953125
Validation loss: 2.254717311551494

Epoch: 6| Step: 12
Training loss: 2.1528356075286865
Validation loss: 2.2476270942277807

Epoch: 6| Step: 13
Training loss: 1.2921032905578613
Validation loss: 2.2305351688015844

Epoch: 121| Step: 0
Training loss: 2.63511323928833
Validation loss: 2.2269962372318393

Epoch: 6| Step: 1
Training loss: 2.46885347366333
Validation loss: 2.23603916680941

Epoch: 6| Step: 2
Training loss: 2.1811394691467285
Validation loss: 2.2396632984120357

Epoch: 6| Step: 3
Training loss: 1.5151416063308716
Validation loss: 2.247355550848028

Epoch: 6| Step: 4
Training loss: 2.239722728729248
Validation loss: 2.251934415550642

Epoch: 6| Step: 5
Training loss: 3.127493381500244
Validation loss: 2.2572862819958757

Epoch: 6| Step: 6
Training loss: 2.222486734390259
Validation loss: 2.271903840444421

Epoch: 6| Step: 7
Training loss: 2.8778257369995117
Validation loss: 2.2634488510829147

Epoch: 6| Step: 8
Training loss: 2.9385581016540527
Validation loss: 2.267237135159072

Epoch: 6| Step: 9
Training loss: 2.3324291706085205
Validation loss: 2.2514924900506132

Epoch: 6| Step: 10
Training loss: 2.3899903297424316
Validation loss: 2.2629970171118297

Epoch: 6| Step: 11
Training loss: 2.7328057289123535
Validation loss: 2.2430653905355804

Epoch: 6| Step: 12
Training loss: 2.221034049987793
Validation loss: 2.2336346487845145

Epoch: 6| Step: 13
Training loss: 2.273479700088501
Validation loss: 2.2416270958480013

Epoch: 122| Step: 0
Training loss: 2.762652635574341
Validation loss: 2.2329713503519693

Epoch: 6| Step: 1
Training loss: 2.0723791122436523
Validation loss: 2.252266929995629

Epoch: 6| Step: 2
Training loss: 2.3912110328674316
Validation loss: 2.264384315859887

Epoch: 6| Step: 3
Training loss: 2.471461534500122
Validation loss: 2.2759440534858295

Epoch: 6| Step: 4
Training loss: 2.4437122344970703
Validation loss: 2.283357056238318

Epoch: 6| Step: 5
Training loss: 2.426886796951294
Validation loss: 2.2954292784455004

Epoch: 6| Step: 6
Training loss: 2.467435359954834
Validation loss: 2.2935539958297566

Epoch: 6| Step: 7
Training loss: 2.4359474182128906
Validation loss: 2.2972986057240474

Epoch: 6| Step: 8
Training loss: 2.9299116134643555
Validation loss: 2.2979260054967736

Epoch: 6| Step: 9
Training loss: 2.2131197452545166
Validation loss: 2.2955392919560915

Epoch: 6| Step: 10
Training loss: 2.2099320888519287
Validation loss: 2.29104773588078

Epoch: 6| Step: 11
Training loss: 2.8933050632476807
Validation loss: 2.287425579563264

Epoch: 6| Step: 12
Training loss: 1.7145862579345703
Validation loss: 2.283073822657267

Epoch: 6| Step: 13
Training loss: 2.8749232292175293
Validation loss: 2.263346997640466

Epoch: 123| Step: 0
Training loss: 2.4663476943969727
Validation loss: 2.246789886105445

Epoch: 6| Step: 1
Training loss: 1.7763700485229492
Validation loss: 2.2347683932191584

Epoch: 6| Step: 2
Training loss: 2.9667272567749023
Validation loss: 2.2099152585511566

Epoch: 6| Step: 3
Training loss: 2.5431127548217773
Validation loss: 2.2180923185040875

Epoch: 6| Step: 4
Training loss: 2.033230781555176
Validation loss: 2.1976131880155174

Epoch: 6| Step: 5
Training loss: 2.6923513412475586
Validation loss: 2.2008617308831986

Epoch: 6| Step: 6
Training loss: 1.9769070148468018
Validation loss: 2.2022759593943113

Epoch: 6| Step: 7
Training loss: 2.421006679534912
Validation loss: 2.192443327237201

Epoch: 6| Step: 8
Training loss: 2.746217966079712
Validation loss: 2.1821302188340055

Epoch: 6| Step: 9
Training loss: 2.5994873046875
Validation loss: 2.17769714068341

Epoch: 6| Step: 10
Training loss: 2.4301366806030273
Validation loss: 2.1893587855882544

Epoch: 6| Step: 11
Training loss: 1.5075541734695435
Validation loss: 2.1897738825890327

Epoch: 6| Step: 12
Training loss: 3.848231554031372
Validation loss: 2.187444310034475

Epoch: 6| Step: 13
Training loss: 1.9288438558578491
Validation loss: 2.1857447111478416

Epoch: 124| Step: 0
Training loss: 2.5246706008911133
Validation loss: 2.188398281733195

Epoch: 6| Step: 1
Training loss: 2.4349775314331055
Validation loss: 2.184000809987386

Epoch: 6| Step: 2
Training loss: 1.9475338459014893
Validation loss: 2.174359780485912

Epoch: 6| Step: 3
Training loss: 2.5645971298217773
Validation loss: 2.1815694788450837

Epoch: 6| Step: 4
Training loss: 2.914097547531128
Validation loss: 2.1989370315305647

Epoch: 6| Step: 5
Training loss: 2.3439879417419434
Validation loss: 2.209235175963371

Epoch: 6| Step: 6
Training loss: 2.24769926071167
Validation loss: 2.218209825536256

Epoch: 6| Step: 7
Training loss: 2.8796873092651367
Validation loss: 2.222506335986558

Epoch: 6| Step: 8
Training loss: 2.4928410053253174
Validation loss: 2.2064573200800086

Epoch: 6| Step: 9
Training loss: 2.8566031455993652
Validation loss: 2.202484679478471

Epoch: 6| Step: 10
Training loss: 1.7652320861816406
Validation loss: 2.2017437565711235

Epoch: 6| Step: 11
Training loss: 2.28265380859375
Validation loss: 2.209001032255029

Epoch: 6| Step: 12
Training loss: 2.7269999980926514
Validation loss: 2.2024563999586206

Epoch: 6| Step: 13
Training loss: 2.0846028327941895
Validation loss: 2.209027974836288

Epoch: 125| Step: 0
Training loss: 1.7628978490829468
Validation loss: 2.2029194588302285

Epoch: 6| Step: 1
Training loss: 3.0372796058654785
Validation loss: 2.219256744589857

Epoch: 6| Step: 2
Training loss: 2.3596246242523193
Validation loss: 2.2311761110059676

Epoch: 6| Step: 3
Training loss: 1.7318222522735596
Validation loss: 2.259080256185224

Epoch: 6| Step: 4
Training loss: 2.3550517559051514
Validation loss: 2.2891878697179977

Epoch: 6| Step: 5
Training loss: 2.7449262142181396
Validation loss: 2.3457087342457106

Epoch: 6| Step: 6
Training loss: 2.2036471366882324
Validation loss: 2.3910802513040523

Epoch: 6| Step: 7
Training loss: 2.610729694366455
Validation loss: 2.3810674503285396

Epoch: 6| Step: 8
Training loss: 2.4858808517456055
Validation loss: 2.331077719247469

Epoch: 6| Step: 9
Training loss: 3.0817818641662598
Validation loss: 2.2754165382795435

Epoch: 6| Step: 10
Training loss: 2.812243938446045
Validation loss: 2.252686300585347

Epoch: 6| Step: 11
Training loss: 2.7886180877685547
Validation loss: 2.273620190158967

Epoch: 6| Step: 12
Training loss: 2.467312812805176
Validation loss: 2.303348877096689

Epoch: 6| Step: 13
Training loss: 2.241366386413574
Validation loss: 2.33516518274943

Epoch: 126| Step: 0
Training loss: 2.755767822265625
Validation loss: 2.338092009226481

Epoch: 6| Step: 1
Training loss: 2.5703330039978027
Validation loss: 2.3386404745040403

Epoch: 6| Step: 2
Training loss: 2.883230686187744
Validation loss: 2.2961893235483477

Epoch: 6| Step: 3
Training loss: 2.4469830989837646
Validation loss: 2.274202372438164

Epoch: 6| Step: 4
Training loss: 2.6384425163269043
Validation loss: 2.2484109042793192

Epoch: 6| Step: 5
Training loss: 1.8868485689163208
Validation loss: 2.211433959263627

Epoch: 6| Step: 6
Training loss: 2.335616111755371
Validation loss: 2.195450472575362

Epoch: 6| Step: 7
Training loss: 2.077836036682129
Validation loss: 2.1889771876796598

Epoch: 6| Step: 8
Training loss: 2.6754064559936523
Validation loss: 2.1947666393813265

Epoch: 6| Step: 9
Training loss: 3.0878829956054688
Validation loss: 2.205563493954238

Epoch: 6| Step: 10
Training loss: 2.129450559616089
Validation loss: 2.2042461056863107

Epoch: 6| Step: 11
Training loss: 2.552135705947876
Validation loss: 2.2053871872604534

Epoch: 6| Step: 12
Training loss: 2.1764726638793945
Validation loss: 2.2291680484689693

Epoch: 6| Step: 13
Training loss: 2.1959924697875977
Validation loss: 2.2244763169237363

Epoch: 127| Step: 0
Training loss: 2.6289708614349365
Validation loss: 2.206411600112915

Epoch: 6| Step: 1
Training loss: 1.5484676361083984
Validation loss: 2.202945424664405

Epoch: 6| Step: 2
Training loss: 2.0206491947174072
Validation loss: 2.1901680731004283

Epoch: 6| Step: 3
Training loss: 2.9527668952941895
Validation loss: 2.1892944266719203

Epoch: 6| Step: 4
Training loss: 3.031583309173584
Validation loss: 2.195321795760944

Epoch: 6| Step: 5
Training loss: 2.3156280517578125
Validation loss: 2.1961997426966184

Epoch: 6| Step: 6
Training loss: 2.070197105407715
Validation loss: 2.181382583033654

Epoch: 6| Step: 7
Training loss: 2.8884329795837402
Validation loss: 2.1924292143955024

Epoch: 6| Step: 8
Training loss: 2.1770641803741455
Validation loss: 2.202778649586503

Epoch: 6| Step: 9
Training loss: 2.1939663887023926
Validation loss: 2.204699070222916

Epoch: 6| Step: 10
Training loss: 2.867156505584717
Validation loss: 2.1972918587346233

Epoch: 6| Step: 11
Training loss: 2.769968032836914
Validation loss: 2.199863128764655

Epoch: 6| Step: 12
Training loss: 2.516974449157715
Validation loss: 2.1903481765459945

Epoch: 6| Step: 13
Training loss: 1.8370671272277832
Validation loss: 2.2053830521081084

Epoch: 128| Step: 0
Training loss: 2.559414863586426
Validation loss: 2.21289639319143

Epoch: 6| Step: 1
Training loss: 2.314404249191284
Validation loss: 2.2213052011305288

Epoch: 6| Step: 2
Training loss: 2.2448959350585938
Validation loss: 2.2309003863283383

Epoch: 6| Step: 3
Training loss: 2.5095767974853516
Validation loss: 2.2417630354563394

Epoch: 6| Step: 4
Training loss: 2.5193817615509033
Validation loss: 2.2459372474301245

Epoch: 6| Step: 5
Training loss: 2.6528544425964355
Validation loss: 2.2373642536901657

Epoch: 6| Step: 6
Training loss: 2.4369139671325684
Validation loss: 2.2216886294785367

Epoch: 6| Step: 7
Training loss: 2.3537771701812744
Validation loss: 2.219782321683822

Epoch: 6| Step: 8
Training loss: 2.939631462097168
Validation loss: 2.211325935138169

Epoch: 6| Step: 9
Training loss: 2.040915012359619
Validation loss: 2.202326601551425

Epoch: 6| Step: 10
Training loss: 2.2378768920898438
Validation loss: 2.2213826115413378

Epoch: 6| Step: 11
Training loss: 2.693192481994629
Validation loss: 2.2139064368381294

Epoch: 6| Step: 12
Training loss: 2.702854871749878
Validation loss: 2.220024142214047

Epoch: 6| Step: 13
Training loss: 1.2778480052947998
Validation loss: 2.2136436226547405

Epoch: 129| Step: 0
Training loss: 2.1477105617523193
Validation loss: 2.2035957562026156

Epoch: 6| Step: 1
Training loss: 2.266023635864258
Validation loss: 2.2044901565838884

Epoch: 6| Step: 2
Training loss: 3.0107531547546387
Validation loss: 2.2123022079467773

Epoch: 6| Step: 3
Training loss: 1.928982138633728
Validation loss: 2.2124429979631977

Epoch: 6| Step: 4
Training loss: 2.1993813514709473
Validation loss: 2.2128551595954487

Epoch: 6| Step: 5
Training loss: 2.6575815677642822
Validation loss: 2.2190540067611204

Epoch: 6| Step: 6
Training loss: 2.7670345306396484
Validation loss: 2.2246720585771786

Epoch: 6| Step: 7
Training loss: 1.904448390007019
Validation loss: 2.2197746435801187

Epoch: 6| Step: 8
Training loss: 3.2589144706726074
Validation loss: 2.221311758923274

Epoch: 6| Step: 9
Training loss: 2.575937271118164
Validation loss: 2.22315187351678

Epoch: 6| Step: 10
Training loss: 2.6046791076660156
Validation loss: 2.213943809591314

Epoch: 6| Step: 11
Training loss: 2.19675612449646
Validation loss: 2.2165047596859675

Epoch: 6| Step: 12
Training loss: 1.7730181217193604
Validation loss: 2.2298681992356495

Epoch: 6| Step: 13
Training loss: 2.678070068359375
Validation loss: 2.233356629648516

Epoch: 130| Step: 0
Training loss: 2.1302530765533447
Validation loss: 2.203034713704099

Epoch: 6| Step: 1
Training loss: 1.675074815750122
Validation loss: 2.183728489824521

Epoch: 6| Step: 2
Training loss: 2.20208477973938
Validation loss: 2.1857390942112094

Epoch: 6| Step: 3
Training loss: 2.343879222869873
Validation loss: 2.192689408538162

Epoch: 6| Step: 4
Training loss: 2.361027240753174
Validation loss: 2.201172585128456

Epoch: 6| Step: 5
Training loss: 2.7348945140838623
Validation loss: 2.2085108577564196

Epoch: 6| Step: 6
Training loss: 2.47672438621521
Validation loss: 2.2198337842059392

Epoch: 6| Step: 7
Training loss: 3.2661185264587402
Validation loss: 2.2346872116929744

Epoch: 6| Step: 8
Training loss: 2.249654531478882
Validation loss: 2.2347766955693564

Epoch: 6| Step: 9
Training loss: 2.527982711791992
Validation loss: 2.2352196760075067

Epoch: 6| Step: 10
Training loss: 2.3920910358428955
Validation loss: 2.2373107864010717

Epoch: 6| Step: 11
Training loss: 2.732715129852295
Validation loss: 2.2214332652348343

Epoch: 6| Step: 12
Training loss: 2.7981557846069336
Validation loss: 2.2102059753992225

Epoch: 6| Step: 13
Training loss: 1.8297094106674194
Validation loss: 2.189473263679012

Epoch: 131| Step: 0
Training loss: 1.7502875328063965
Validation loss: 2.198356895036595

Epoch: 6| Step: 1
Training loss: 2.8654184341430664
Validation loss: 2.1962477519947994

Epoch: 6| Step: 2
Training loss: 2.8198070526123047
Validation loss: 2.21066697694922

Epoch: 6| Step: 3
Training loss: 3.430788278579712
Validation loss: 2.2158878234124955

Epoch: 6| Step: 4
Training loss: 2.140866994857788
Validation loss: 2.211907627762005

Epoch: 6| Step: 5
Training loss: 1.8338348865509033
Validation loss: 2.2033548688375824

Epoch: 6| Step: 6
Training loss: 2.5782980918884277
Validation loss: 2.1955037963005806

Epoch: 6| Step: 7
Training loss: 2.251476764678955
Validation loss: 2.203118557571083

Epoch: 6| Step: 8
Training loss: 2.1726186275482178
Validation loss: 2.208254732111449

Epoch: 6| Step: 9
Training loss: 2.905338764190674
Validation loss: 2.2167902684980825

Epoch: 6| Step: 10
Training loss: 2.255303382873535
Validation loss: 2.235643620132118

Epoch: 6| Step: 11
Training loss: 2.122509479522705
Validation loss: 2.2503879762464956

Epoch: 6| Step: 12
Training loss: 2.217317581176758
Validation loss: 2.259691184566867

Epoch: 6| Step: 13
Training loss: 2.7623414993286133
Validation loss: 2.25462176979229

Epoch: 132| Step: 0
Training loss: 2.5958800315856934
Validation loss: 2.2485880685108963

Epoch: 6| Step: 1
Training loss: 2.403618812561035
Validation loss: 2.250185210217712

Epoch: 6| Step: 2
Training loss: 2.684809684753418
Validation loss: 2.2215338881297777

Epoch: 6| Step: 3
Training loss: 2.9165358543395996
Validation loss: 2.2222838376158025

Epoch: 6| Step: 4
Training loss: 1.994181513786316
Validation loss: 2.204389586243578

Epoch: 6| Step: 5
Training loss: 2.264835834503174
Validation loss: 2.1996310551961265

Epoch: 6| Step: 6
Training loss: 1.9583773612976074
Validation loss: 2.1952308659912436

Epoch: 6| Step: 7
Training loss: 2.3623998165130615
Validation loss: 2.2068157324226956

Epoch: 6| Step: 8
Training loss: 2.9061641693115234
Validation loss: 2.208046490146268

Epoch: 6| Step: 9
Training loss: 2.6991333961486816
Validation loss: 2.215390396374528

Epoch: 6| Step: 10
Training loss: 2.460599899291992
Validation loss: 2.224095226615988

Epoch: 6| Step: 11
Training loss: 1.7912650108337402
Validation loss: 2.2351377907619683

Epoch: 6| Step: 12
Training loss: 2.4093575477600098
Validation loss: 2.2283438123682493

Epoch: 6| Step: 13
Training loss: 2.315406560897827
Validation loss: 2.226312386092319

Epoch: 133| Step: 0
Training loss: 2.483067274093628
Validation loss: 2.2333510870574624

Epoch: 6| Step: 1
Training loss: 2.8754734992980957
Validation loss: 2.2225636730911913

Epoch: 6| Step: 2
Training loss: 2.5217392444610596
Validation loss: 2.2284901680484897

Epoch: 6| Step: 3
Training loss: 2.033421516418457
Validation loss: 2.2263060090362385

Epoch: 6| Step: 4
Training loss: 1.9015891551971436
Validation loss: 2.2281160508432696

Epoch: 6| Step: 5
Training loss: 2.343952178955078
Validation loss: 2.211849361337641

Epoch: 6| Step: 6
Training loss: 2.796109199523926
Validation loss: 2.217829604302683

Epoch: 6| Step: 7
Training loss: 2.622365951538086
Validation loss: 2.205753900671518

Epoch: 6| Step: 8
Training loss: 2.154198169708252
Validation loss: 2.2080128295447237

Epoch: 6| Step: 9
Training loss: 2.1493563652038574
Validation loss: 2.2144162680513118

Epoch: 6| Step: 10
Training loss: 2.419620990753174
Validation loss: 2.211971390631891

Epoch: 6| Step: 11
Training loss: 3.0004830360412598
Validation loss: 2.2030643083715953

Epoch: 6| Step: 12
Training loss: 2.0409765243530273
Validation loss: 2.2041316263137327

Epoch: 6| Step: 13
Training loss: 2.0567126274108887
Validation loss: 2.217737961840886

Epoch: 134| Step: 0
Training loss: 2.6147429943084717
Validation loss: 2.2289422891473256

Epoch: 6| Step: 1
Training loss: 1.989949345588684
Validation loss: 2.218111238171977

Epoch: 6| Step: 2
Training loss: 2.3388333320617676
Validation loss: 2.225789341875302

Epoch: 6| Step: 3
Training loss: 2.5192809104919434
Validation loss: 2.2205625477657525

Epoch: 6| Step: 4
Training loss: 2.288783550262451
Validation loss: 2.2053366989217777

Epoch: 6| Step: 5
Training loss: 2.608367919921875
Validation loss: 2.1974493380515807

Epoch: 6| Step: 6
Training loss: 2.100477457046509
Validation loss: 2.1911017176925496

Epoch: 6| Step: 7
Training loss: 3.140153408050537
Validation loss: 2.2005179697467434

Epoch: 6| Step: 8
Training loss: 2.279392719268799
Validation loss: 2.2010051127403014

Epoch: 6| Step: 9
Training loss: 1.8540953397750854
Validation loss: 2.199189552696802

Epoch: 6| Step: 10
Training loss: 2.302643299102783
Validation loss: 2.201909847156976

Epoch: 6| Step: 11
Training loss: 1.831342339515686
Validation loss: 2.2095417771288144

Epoch: 6| Step: 12
Training loss: 3.141388416290283
Validation loss: 2.2267568419056554

Epoch: 6| Step: 13
Training loss: 2.5995068550109863
Validation loss: 2.21157951893345

Epoch: 135| Step: 0
Training loss: 1.394447922706604
Validation loss: 2.230431733592864

Epoch: 6| Step: 1
Training loss: 2.062896966934204
Validation loss: 2.221679522145179

Epoch: 6| Step: 2
Training loss: 2.618044853210449
Validation loss: 2.2162084553831365

Epoch: 6| Step: 3
Training loss: 2.223954677581787
Validation loss: 2.2073282375130603

Epoch: 6| Step: 4
Training loss: 2.472567319869995
Validation loss: 2.2106741679612028

Epoch: 6| Step: 5
Training loss: 2.18231201171875
Validation loss: 2.221984068552653

Epoch: 6| Step: 6
Training loss: 2.734032154083252
Validation loss: 2.213729045724356

Epoch: 6| Step: 7
Training loss: 2.223842144012451
Validation loss: 2.2318130334218345

Epoch: 6| Step: 8
Training loss: 2.5870542526245117
Validation loss: 2.2175965514234317

Epoch: 6| Step: 9
Training loss: 2.321908950805664
Validation loss: 2.223995247194844

Epoch: 6| Step: 10
Training loss: 3.298743724822998
Validation loss: 2.225225002534928

Epoch: 6| Step: 11
Training loss: 2.4902987480163574
Validation loss: 2.209509530375081

Epoch: 6| Step: 12
Training loss: 2.2912073135375977
Validation loss: 2.190945861160114

Epoch: 6| Step: 13
Training loss: 2.6758527755737305
Validation loss: 2.1898604054604807

Epoch: 136| Step: 0
Training loss: 1.7690091133117676
Validation loss: 2.1869786503494426

Epoch: 6| Step: 1
Training loss: 1.8355803489685059
Validation loss: 2.194316235921716

Epoch: 6| Step: 2
Training loss: 2.9151053428649902
Validation loss: 2.2019570360901537

Epoch: 6| Step: 3
Training loss: 2.301886558532715
Validation loss: 2.1894537838556434

Epoch: 6| Step: 4
Training loss: 2.676760196685791
Validation loss: 2.1907413480102376

Epoch: 6| Step: 5
Training loss: 2.432548999786377
Validation loss: 2.176457579417895

Epoch: 6| Step: 6
Training loss: 2.7332608699798584
Validation loss: 2.180017891750541

Epoch: 6| Step: 7
Training loss: 2.262373924255371
Validation loss: 2.181476490471953

Epoch: 6| Step: 8
Training loss: 2.7710773944854736
Validation loss: 2.19080715281989

Epoch: 6| Step: 9
Training loss: 2.341108798980713
Validation loss: 2.1789825167707217

Epoch: 6| Step: 10
Training loss: 2.5550684928894043
Validation loss: 2.1766290562127226

Epoch: 6| Step: 11
Training loss: 2.1423532962799072
Validation loss: 2.179035953296128

Epoch: 6| Step: 12
Training loss: 2.3504629135131836
Validation loss: 2.199815078448224

Epoch: 6| Step: 13
Training loss: 2.613246202468872
Validation loss: 2.1996913007510606

Epoch: 137| Step: 0
Training loss: 2.21993350982666
Validation loss: 2.201220581608434

Epoch: 6| Step: 1
Training loss: 2.088192939758301
Validation loss: 2.2063122718564925

Epoch: 6| Step: 2
Training loss: 1.8282427787780762
Validation loss: 2.1991691332991405

Epoch: 6| Step: 3
Training loss: 2.2605464458465576
Validation loss: 2.210580092604442

Epoch: 6| Step: 4
Training loss: 2.870134115219116
Validation loss: 2.204494225081577

Epoch: 6| Step: 5
Training loss: 2.308964729309082
Validation loss: 2.2087295760390577

Epoch: 6| Step: 6
Training loss: 2.288078546524048
Validation loss: 2.2076814123379287

Epoch: 6| Step: 7
Training loss: 1.7413032054901123
Validation loss: 2.2049785224340295

Epoch: 6| Step: 8
Training loss: 2.974642038345337
Validation loss: 2.2237961907540598

Epoch: 6| Step: 9
Training loss: 2.220966339111328
Validation loss: 2.2358133126330633

Epoch: 6| Step: 10
Training loss: 2.56380033493042
Validation loss: 2.242583167168402

Epoch: 6| Step: 11
Training loss: 2.9683828353881836
Validation loss: 2.237644244265813

Epoch: 6| Step: 12
Training loss: 2.6797711849212646
Validation loss: 2.224075622456048

Epoch: 6| Step: 13
Training loss: 2.5947422981262207
Validation loss: 2.1941255882222164

Epoch: 138| Step: 0
Training loss: 3.0907812118530273
Validation loss: 2.19694023747598

Epoch: 6| Step: 1
Training loss: 1.5603008270263672
Validation loss: 2.187619347726145

Epoch: 6| Step: 2
Training loss: 2.3179211616516113
Validation loss: 2.1863807632077124

Epoch: 6| Step: 3
Training loss: 2.335481882095337
Validation loss: 2.182009918715364

Epoch: 6| Step: 4
Training loss: 2.8953540325164795
Validation loss: 2.1851241216864636

Epoch: 6| Step: 5
Training loss: 1.9101333618164062
Validation loss: 2.180657725180349

Epoch: 6| Step: 6
Training loss: 1.9899619817733765
Validation loss: 2.18952521201103

Epoch: 6| Step: 7
Training loss: 2.895840644836426
Validation loss: 2.1849257766559558

Epoch: 6| Step: 8
Training loss: 2.5677132606506348
Validation loss: 2.200854411689184

Epoch: 6| Step: 9
Training loss: 2.9596047401428223
Validation loss: 2.197107163808679

Epoch: 6| Step: 10
Training loss: 1.7651500701904297
Validation loss: 2.188675816341113

Epoch: 6| Step: 11
Training loss: 2.41286563873291
Validation loss: 2.192101993868428

Epoch: 6| Step: 12
Training loss: 2.6502108573913574
Validation loss: 2.177776539197532

Epoch: 6| Step: 13
Training loss: 1.5802010297775269
Validation loss: 2.182902628375638

Epoch: 139| Step: 0
Training loss: 1.959061861038208
Validation loss: 2.1743333672964447

Epoch: 6| Step: 1
Training loss: 2.4197263717651367
Validation loss: 2.1917330347081667

Epoch: 6| Step: 2
Training loss: 2.9759457111358643
Validation loss: 2.2014381231800204

Epoch: 6| Step: 3
Training loss: 2.084832191467285
Validation loss: 2.2051604409371652

Epoch: 6| Step: 4
Training loss: 3.452223300933838
Validation loss: 2.187473071518765

Epoch: 6| Step: 5
Training loss: 2.559971332550049
Validation loss: 2.172849419296429

Epoch: 6| Step: 6
Training loss: 2.1518733501434326
Validation loss: 2.169451803289434

Epoch: 6| Step: 7
Training loss: 1.5117566585540771
Validation loss: 2.1682873925855084

Epoch: 6| Step: 8
Training loss: 2.9692180156707764
Validation loss: 2.1705173882105018

Epoch: 6| Step: 9
Training loss: 2.3593311309814453
Validation loss: 2.1695182861820346

Epoch: 6| Step: 10
Training loss: 1.9971309900283813
Validation loss: 2.1594397893515964

Epoch: 6| Step: 11
Training loss: 2.529388904571533
Validation loss: 2.1586012430088495

Epoch: 6| Step: 12
Training loss: 2.262256622314453
Validation loss: 2.158802288834767

Epoch: 6| Step: 13
Training loss: 2.146369457244873
Validation loss: 2.176094557649346

Epoch: 140| Step: 0
Training loss: 2.375051498413086
Validation loss: 2.1725244881004415

Epoch: 6| Step: 1
Training loss: 2.2617292404174805
Validation loss: 2.191110177706647

Epoch: 6| Step: 2
Training loss: 1.9804599285125732
Validation loss: 2.1842500548208914

Epoch: 6| Step: 3
Training loss: 2.286341667175293
Validation loss: 2.1962399149453766

Epoch: 6| Step: 4
Training loss: 2.715106248855591
Validation loss: 2.2134946289882866

Epoch: 6| Step: 5
Training loss: 1.9011694192886353
Validation loss: 2.2319513751614477

Epoch: 6| Step: 6
Training loss: 2.0239105224609375
Validation loss: 2.2483216203669065

Epoch: 6| Step: 7
Training loss: 1.6124958992004395
Validation loss: 2.2518118222554526

Epoch: 6| Step: 8
Training loss: 2.251295566558838
Validation loss: 2.242285102926275

Epoch: 6| Step: 9
Training loss: 2.156183958053589
Validation loss: 2.2433550652637275

Epoch: 6| Step: 10
Training loss: 3.1235761642456055
Validation loss: 2.2456636736469884

Epoch: 6| Step: 11
Training loss: 2.668632984161377
Validation loss: 2.2453705649222098

Epoch: 6| Step: 12
Training loss: 3.2795252799987793
Validation loss: 2.2275544071710236

Epoch: 6| Step: 13
Training loss: 3.706122875213623
Validation loss: 2.2356469528649443

Epoch: 141| Step: 0
Training loss: 3.0210020542144775
Validation loss: 2.2206735610961914

Epoch: 6| Step: 1
Training loss: 1.6854110956192017
Validation loss: 2.1990278920819684

Epoch: 6| Step: 2
Training loss: 2.336394786834717
Validation loss: 2.1820006934545373

Epoch: 6| Step: 3
Training loss: 3.338993549346924
Validation loss: 2.167342580774779

Epoch: 6| Step: 4
Training loss: 2.370251178741455
Validation loss: 2.1711742801050984

Epoch: 6| Step: 5
Training loss: 2.2849907875061035
Validation loss: 2.1931671788615565

Epoch: 6| Step: 6
Training loss: 2.184629440307617
Validation loss: 2.230213378065376

Epoch: 6| Step: 7
Training loss: 2.434706687927246
Validation loss: 2.2296273657070693

Epoch: 6| Step: 8
Training loss: 2.207441806793213
Validation loss: 2.2233010620199223

Epoch: 6| Step: 9
Training loss: 2.7416751384735107
Validation loss: 2.210071858539376

Epoch: 6| Step: 10
Training loss: 2.2783937454223633
Validation loss: 2.177250362211658

Epoch: 6| Step: 11
Training loss: 2.0664753913879395
Validation loss: 2.1459912587237615

Epoch: 6| Step: 12
Training loss: 2.157062292098999
Validation loss: 2.140401541545827

Epoch: 6| Step: 13
Training loss: 2.3449864387512207
Validation loss: 2.144147483251428

Epoch: 142| Step: 0
Training loss: 2.3644895553588867
Validation loss: 2.137279151588358

Epoch: 6| Step: 1
Training loss: 2.1586391925811768
Validation loss: 2.14997959649691

Epoch: 6| Step: 2
Training loss: 2.328603744506836
Validation loss: 2.153830089876729

Epoch: 6| Step: 3
Training loss: 2.6481857299804688
Validation loss: 2.165505108012948

Epoch: 6| Step: 4
Training loss: 2.438237428665161
Validation loss: 2.17349584128267

Epoch: 6| Step: 5
Training loss: 2.298919200897217
Validation loss: 2.152820461539812

Epoch: 6| Step: 6
Training loss: 2.6526591777801514
Validation loss: 2.1571816462342457

Epoch: 6| Step: 7
Training loss: 2.9964771270751953
Validation loss: 2.16309356176725

Epoch: 6| Step: 8
Training loss: 2.241818428039551
Validation loss: 2.159833961917508

Epoch: 6| Step: 9
Training loss: 2.0713295936584473
Validation loss: 2.16438784650577

Epoch: 6| Step: 10
Training loss: 2.6205246448516846
Validation loss: 2.1695491344698015

Epoch: 6| Step: 11
Training loss: 2.0975327491760254
Validation loss: 2.1636888134864067

Epoch: 6| Step: 12
Training loss: 2.428595542907715
Validation loss: 2.154141585032145

Epoch: 6| Step: 13
Training loss: 1.8540071249008179
Validation loss: 2.1502008412473943

Epoch: 143| Step: 0
Training loss: 1.781005859375
Validation loss: 2.1600929665309128

Epoch: 6| Step: 1
Training loss: 2.443721294403076
Validation loss: 2.1549151187301963

Epoch: 6| Step: 2
Training loss: 2.4462757110595703
Validation loss: 2.169749529130997

Epoch: 6| Step: 3
Training loss: 2.637897491455078
Validation loss: 2.160999413459532

Epoch: 6| Step: 4
Training loss: 2.4274682998657227
Validation loss: 2.1549803198024793

Epoch: 6| Step: 5
Training loss: 2.5471749305725098
Validation loss: 2.1556370976150676

Epoch: 6| Step: 6
Training loss: 2.4912068843841553
Validation loss: 2.1600796343177877

Epoch: 6| Step: 7
Training loss: 2.256856679916382
Validation loss: 2.175934689019316

Epoch: 6| Step: 8
Training loss: 1.860948920249939
Validation loss: 2.172614674414358

Epoch: 6| Step: 9
Training loss: 2.335637092590332
Validation loss: 2.1770174182871336

Epoch: 6| Step: 10
Training loss: 2.505873203277588
Validation loss: 2.1798242163914505

Epoch: 6| Step: 11
Training loss: 2.5644617080688477
Validation loss: 2.1858217998217513

Epoch: 6| Step: 12
Training loss: 2.452869415283203
Validation loss: 2.1839698796631186

Epoch: 6| Step: 13
Training loss: 2.135084867477417
Validation loss: 2.18330967298118

Epoch: 144| Step: 0
Training loss: 1.9999730587005615
Validation loss: 2.1824898232695875

Epoch: 6| Step: 1
Training loss: 2.8959102630615234
Validation loss: 2.1968547144243793

Epoch: 6| Step: 2
Training loss: 2.542742967605591
Validation loss: 2.1952796700180217

Epoch: 6| Step: 3
Training loss: 2.709319591522217
Validation loss: 2.2082790764429236

Epoch: 6| Step: 4
Training loss: 2.4068217277526855
Validation loss: 2.2135018584548787

Epoch: 6| Step: 5
Training loss: 1.6952322721481323
Validation loss: 2.214359252683578

Epoch: 6| Step: 6
Training loss: 1.7776615619659424
Validation loss: 2.2256399303354244

Epoch: 6| Step: 7
Training loss: 2.312499523162842
Validation loss: 2.231968836117816

Epoch: 6| Step: 8
Training loss: 2.7276358604431152
Validation loss: 2.2248370596157607

Epoch: 6| Step: 9
Training loss: 2.4098730087280273
Validation loss: 2.222472436966435

Epoch: 6| Step: 10
Training loss: 2.6862709522247314
Validation loss: 2.22195089632465

Epoch: 6| Step: 11
Training loss: 2.4889280796051025
Validation loss: 2.214443850260909

Epoch: 6| Step: 12
Training loss: 2.4899020195007324
Validation loss: 2.187588340492659

Epoch: 6| Step: 13
Training loss: 1.6121351718902588
Validation loss: 2.170387732085361

Epoch: 145| Step: 0
Training loss: 2.5575783252716064
Validation loss: 2.181954992714749

Epoch: 6| Step: 1
Training loss: 1.7131463289260864
Validation loss: 2.182086129342356

Epoch: 6| Step: 2
Training loss: 2.2559728622436523
Validation loss: 2.1913507061619915

Epoch: 6| Step: 3
Training loss: 2.6640212535858154
Validation loss: 2.2009869365281958

Epoch: 6| Step: 4
Training loss: 2.174302101135254
Validation loss: 2.2043363381457586

Epoch: 6| Step: 5
Training loss: 2.5923783779144287
Validation loss: 2.2085285250858595

Epoch: 6| Step: 6
Training loss: 2.682349681854248
Validation loss: 2.2048802760339554

Epoch: 6| Step: 7
Training loss: 3.045879364013672
Validation loss: 2.2102124383372646

Epoch: 6| Step: 8
Training loss: 2.513451099395752
Validation loss: 2.209844789197368

Epoch: 6| Step: 9
Training loss: 2.461483955383301
Validation loss: 2.202497805318525

Epoch: 6| Step: 10
Training loss: 1.8132644891738892
Validation loss: 2.2123889615458827

Epoch: 6| Step: 11
Training loss: 2.378509759902954
Validation loss: 2.231990214317076

Epoch: 6| Step: 12
Training loss: 2.1114706993103027
Validation loss: 2.227592557989141

Epoch: 6| Step: 13
Training loss: 1.7154682874679565
Validation loss: 2.1861218329398864

Epoch: 146| Step: 0
Training loss: 1.8192064762115479
Validation loss: 2.1961487557298396

Epoch: 6| Step: 1
Training loss: 1.942584753036499
Validation loss: 2.195779231286818

Epoch: 6| Step: 2
Training loss: 2.5014233589172363
Validation loss: 2.190936629490186

Epoch: 6| Step: 3
Training loss: 2.209411144256592
Validation loss: 2.1939825601475214

Epoch: 6| Step: 4
Training loss: 1.823967695236206
Validation loss: 2.1713662352613223

Epoch: 6| Step: 5
Training loss: 2.405683994293213
Validation loss: 2.185529755007836

Epoch: 6| Step: 6
Training loss: 2.5729217529296875
Validation loss: 2.174689946636077

Epoch: 6| Step: 7
Training loss: 2.6616663932800293
Validation loss: 2.1764114197864326

Epoch: 6| Step: 8
Training loss: 2.667322874069214
Validation loss: 2.191183646519979

Epoch: 6| Step: 9
Training loss: 2.1029248237609863
Validation loss: 2.175939598391133

Epoch: 6| Step: 10
Training loss: 2.3528668880462646
Validation loss: 2.1793508504026677

Epoch: 6| Step: 11
Training loss: 2.815201997756958
Validation loss: 2.18871154580065

Epoch: 6| Step: 12
Training loss: 2.4597558975219727
Validation loss: 2.1778965662884455

Epoch: 6| Step: 13
Training loss: 2.4942562580108643
Validation loss: 2.197808106740316

Epoch: 147| Step: 0
Training loss: 3.0441412925720215
Validation loss: 2.2078147370328187

Epoch: 6| Step: 1
Training loss: 1.6861944198608398
Validation loss: 2.21116869167615

Epoch: 6| Step: 2
Training loss: 2.0824203491210938
Validation loss: 2.2426788037823093

Epoch: 6| Step: 3
Training loss: 3.199713945388794
Validation loss: 2.237534241009784

Epoch: 6| Step: 4
Training loss: 2.6419572830200195
Validation loss: 2.2194810554545414

Epoch: 6| Step: 5
Training loss: 2.431034564971924
Validation loss: 2.196090526478265

Epoch: 6| Step: 6
Training loss: 2.630845069885254
Validation loss: 2.1803172455039075

Epoch: 6| Step: 7
Training loss: 1.9722394943237305
Validation loss: 2.176179396208896

Epoch: 6| Step: 8
Training loss: 2.2681877613067627
Validation loss: 2.1622424689672326

Epoch: 6| Step: 9
Training loss: 2.860821485519409
Validation loss: 2.164404082041915

Epoch: 6| Step: 10
Training loss: 2.3373653888702393
Validation loss: 2.169572304653865

Epoch: 6| Step: 11
Training loss: 1.588317632675171
Validation loss: 2.184137708397322

Epoch: 6| Step: 12
Training loss: 1.9630167484283447
Validation loss: 2.197393876250072

Epoch: 6| Step: 13
Training loss: 2.1983156204223633
Validation loss: 2.1778647412535963

Epoch: 148| Step: 0
Training loss: 2.176100254058838
Validation loss: 2.1726302767312653

Epoch: 6| Step: 1
Training loss: 2.394893169403076
Validation loss: 2.1671650563516924

Epoch: 6| Step: 2
Training loss: 1.8735051155090332
Validation loss: 2.167585398561211

Epoch: 6| Step: 3
Training loss: 2.1702582836151123
Validation loss: 2.176504868333058

Epoch: 6| Step: 4
Training loss: 2.861514091491699
Validation loss: 2.1851220643648537

Epoch: 6| Step: 5
Training loss: 2.077852725982666
Validation loss: 2.1742473084439515

Epoch: 6| Step: 6
Training loss: 2.1580700874328613
Validation loss: 2.1787055307818997

Epoch: 6| Step: 7
Training loss: 3.110119342803955
Validation loss: 2.1696323489630096

Epoch: 6| Step: 8
Training loss: 2.4915671348571777
Validation loss: 2.156368227415187

Epoch: 6| Step: 9
Training loss: 1.958442211151123
Validation loss: 2.1614661703827562

Epoch: 6| Step: 10
Training loss: 2.5390372276306152
Validation loss: 2.1561903184460056

Epoch: 6| Step: 11
Training loss: 1.679321527481079
Validation loss: 2.147503383698002

Epoch: 6| Step: 12
Training loss: 2.21811580657959
Validation loss: 2.1482270110038018

Epoch: 6| Step: 13
Training loss: 3.2905256748199463
Validation loss: 2.156173365090483

Epoch: 149| Step: 0
Training loss: 2.113323450088501
Validation loss: 2.155654215043591

Epoch: 6| Step: 1
Training loss: 2.042044162750244
Validation loss: 2.1702345443028275

Epoch: 6| Step: 2
Training loss: 2.5149662494659424
Validation loss: 2.1785736289075626

Epoch: 6| Step: 3
Training loss: 2.3599698543548584
Validation loss: 2.197065381593602

Epoch: 6| Step: 4
Training loss: 2.138730049133301
Validation loss: 2.1849841148622575

Epoch: 6| Step: 5
Training loss: 1.9009318351745605
Validation loss: 2.1824963451713644

Epoch: 6| Step: 6
Training loss: 2.041456460952759
Validation loss: 2.1635918463430097

Epoch: 6| Step: 7
Training loss: 2.862849473953247
Validation loss: 2.156907639195842

Epoch: 6| Step: 8
Training loss: 2.7681946754455566
Validation loss: 2.1533933198580177

Epoch: 6| Step: 9
Training loss: 2.6360106468200684
Validation loss: 2.155601502746664

Epoch: 6| Step: 10
Training loss: 2.314305305480957
Validation loss: 2.1697134971618652

Epoch: 6| Step: 11
Training loss: 1.8963027000427246
Validation loss: 2.1855882342143724

Epoch: 6| Step: 12
Training loss: 2.67547607421875
Validation loss: 2.1995261946032123

Epoch: 6| Step: 13
Training loss: 2.408749580383301
Validation loss: 2.208514928817749

Epoch: 150| Step: 0
Training loss: 2.6332478523254395
Validation loss: 2.198821936884234

Epoch: 6| Step: 1
Training loss: 2.4689714908599854
Validation loss: 2.2139881631379486

Epoch: 6| Step: 2
Training loss: 1.9129459857940674
Validation loss: 2.198857304870441

Epoch: 6| Step: 3
Training loss: 1.8457772731781006
Validation loss: 2.1893398761749268

Epoch: 6| Step: 4
Training loss: 1.6956825256347656
Validation loss: 2.197726167658324

Epoch: 6| Step: 5
Training loss: 2.7470483779907227
Validation loss: 2.20358613229567

Epoch: 6| Step: 6
Training loss: 2.4888534545898438
Validation loss: 2.2069373515344437

Epoch: 6| Step: 7
Training loss: 2.29063081741333
Validation loss: 2.2016355914454304

Epoch: 6| Step: 8
Training loss: 2.0685648918151855
Validation loss: 2.194055026577365

Epoch: 6| Step: 9
Training loss: 2.869843006134033
Validation loss: 2.19866539842339

Epoch: 6| Step: 10
Training loss: 1.8140029907226562
Validation loss: 2.2063911294424408

Epoch: 6| Step: 11
Training loss: 3.2376277446746826
Validation loss: 2.2082301070613246

Epoch: 6| Step: 12
Training loss: 2.276555061340332
Validation loss: 2.1951263925080657

Epoch: 6| Step: 13
Training loss: 2.096587657928467
Validation loss: 2.175563548200874

Epoch: 151| Step: 0
Training loss: 2.1237759590148926
Validation loss: 2.177901219296199

Epoch: 6| Step: 1
Training loss: 2.991337776184082
Validation loss: 2.1856991834537958

Epoch: 6| Step: 2
Training loss: 2.36214017868042
Validation loss: 2.198048960778021

Epoch: 6| Step: 3
Training loss: 2.109830379486084
Validation loss: 2.174257219478648

Epoch: 6| Step: 4
Training loss: 1.795562744140625
Validation loss: 2.153683662414551

Epoch: 6| Step: 5
Training loss: 3.1987364292144775
Validation loss: 2.1319689340488885

Epoch: 6| Step: 6
Training loss: 2.252969741821289
Validation loss: 2.1220799646069928

Epoch: 6| Step: 7
Training loss: 1.8800652027130127
Validation loss: 2.1296254460529616

Epoch: 6| Step: 8
Training loss: 2.011627435684204
Validation loss: 2.1486058594078146

Epoch: 6| Step: 9
Training loss: 1.8939189910888672
Validation loss: 2.166408590091172

Epoch: 6| Step: 10
Training loss: 2.5771501064300537
Validation loss: 2.207429955082555

Epoch: 6| Step: 11
Training loss: 2.511496067047119
Validation loss: 2.216730933035574

Epoch: 6| Step: 12
Training loss: 3.13339900970459
Validation loss: 2.2072567427030174

Epoch: 6| Step: 13
Training loss: 2.2693541049957275
Validation loss: 2.1933581854707453

Epoch: 152| Step: 0
Training loss: 2.4653069972991943
Validation loss: 2.168193177510333

Epoch: 6| Step: 1
Training loss: 2.287370204925537
Validation loss: 2.1623829949286675

Epoch: 6| Step: 2
Training loss: 2.724684238433838
Validation loss: 2.1613165768243934

Epoch: 6| Step: 3
Training loss: 2.353257894515991
Validation loss: 2.1807957656921877

Epoch: 6| Step: 4
Training loss: 3.1474666595458984
Validation loss: 2.199295756637409

Epoch: 6| Step: 5
Training loss: 2.288757562637329
Validation loss: 2.232657200546675

Epoch: 6| Step: 6
Training loss: 2.1312906742095947
Validation loss: 2.235572789305

Epoch: 6| Step: 7
Training loss: 2.7618749141693115
Validation loss: 2.2393013251725065

Epoch: 6| Step: 8
Training loss: 1.5865135192871094
Validation loss: 2.187016999849709

Epoch: 6| Step: 9
Training loss: 2.2529807090759277
Validation loss: 2.1620941392837034

Epoch: 6| Step: 10
Training loss: 2.8126745223999023
Validation loss: 2.1359349719939695

Epoch: 6| Step: 11
Training loss: 1.5312585830688477
Validation loss: 2.132229544783151

Epoch: 6| Step: 12
Training loss: 2.1996517181396484
Validation loss: 2.141059560160483

Epoch: 6| Step: 13
Training loss: 2.4250411987304688
Validation loss: 2.1590739783420356

Epoch: 153| Step: 0
Training loss: 2.3439817428588867
Validation loss: 2.1738291030289023

Epoch: 6| Step: 1
Training loss: 2.2505054473876953
Validation loss: 2.1891669393867574

Epoch: 6| Step: 2
Training loss: 2.684112310409546
Validation loss: 2.2008826565998856

Epoch: 6| Step: 3
Training loss: 2.8443005084991455
Validation loss: 2.21051271500126

Epoch: 6| Step: 4
Training loss: 2.2042574882507324
Validation loss: 2.2372917693148375

Epoch: 6| Step: 5
Training loss: 2.3379602432250977
Validation loss: 2.2590262197679087

Epoch: 6| Step: 6
Training loss: 2.7464919090270996
Validation loss: 2.238091343192644

Epoch: 6| Step: 7
Training loss: 2.709317684173584
Validation loss: 2.2077842476547405

Epoch: 6| Step: 8
Training loss: 1.8514715433120728
Validation loss: 2.176487586831534

Epoch: 6| Step: 9
Training loss: 1.6737028360366821
Validation loss: 2.1515092260094097

Epoch: 6| Step: 10
Training loss: 2.1696081161499023
Validation loss: 2.152925301623601

Epoch: 6| Step: 11
Training loss: 1.8133211135864258
Validation loss: 2.167737783924226

Epoch: 6| Step: 12
Training loss: 3.130720853805542
Validation loss: 2.2005448443915254

Epoch: 6| Step: 13
Training loss: 2.364257335662842
Validation loss: 2.2104008005511377

Epoch: 154| Step: 0
Training loss: 2.9698426723480225
Validation loss: 2.2002688120770197

Epoch: 6| Step: 1
Training loss: 2.233663320541382
Validation loss: 2.168377717336019

Epoch: 6| Step: 2
Training loss: 1.7231764793395996
Validation loss: 2.146438205113975

Epoch: 6| Step: 3
Training loss: 2.0162291526794434
Validation loss: 2.128259115321662

Epoch: 6| Step: 4
Training loss: 2.5694117546081543
Validation loss: 2.1135933386382235

Epoch: 6| Step: 5
Training loss: 2.105329751968384
Validation loss: 2.129347394871455

Epoch: 6| Step: 6
Training loss: 2.07578182220459
Validation loss: 2.1549557203887613

Epoch: 6| Step: 7
Training loss: 2.3765687942504883
Validation loss: 2.1650095473053637

Epoch: 6| Step: 8
Training loss: 2.319551706314087
Validation loss: 2.180595754295267

Epoch: 6| Step: 9
Training loss: 2.778141498565674
Validation loss: 2.1930758594184794

Epoch: 6| Step: 10
Training loss: 2.594221591949463
Validation loss: 2.203471515768318

Epoch: 6| Step: 11
Training loss: 2.2078497409820557
Validation loss: 2.1808703894256265

Epoch: 6| Step: 12
Training loss: 2.800537586212158
Validation loss: 2.1945251534062047

Epoch: 6| Step: 13
Training loss: 2.016361713409424
Validation loss: 2.1861029260901996

Epoch: 155| Step: 0
Training loss: 2.2176592350006104
Validation loss: 2.16709065821863

Epoch: 6| Step: 1
Training loss: 2.3648970127105713
Validation loss: 2.1748999780224216

Epoch: 6| Step: 2
Training loss: 2.1715140342712402
Validation loss: 2.1643688319831766

Epoch: 6| Step: 3
Training loss: 1.6793615818023682
Validation loss: 2.1831266277579853

Epoch: 6| Step: 4
Training loss: 2.0806801319122314
Validation loss: 2.199246152754753

Epoch: 6| Step: 5
Training loss: 2.352456569671631
Validation loss: 2.235306275788174

Epoch: 6| Step: 6
Training loss: 2.15636944770813
Validation loss: 2.243689311447964

Epoch: 6| Step: 7
Training loss: 2.6695916652679443
Validation loss: 2.2548715837540163

Epoch: 6| Step: 8
Training loss: 2.7670834064483643
Validation loss: 2.2176537052277596

Epoch: 6| Step: 9
Training loss: 2.3502895832061768
Validation loss: 2.2016186855172597

Epoch: 6| Step: 10
Training loss: 1.9430773258209229
Validation loss: 2.1916711202231784

Epoch: 6| Step: 11
Training loss: 3.0002219676971436
Validation loss: 2.1598704527783137

Epoch: 6| Step: 12
Training loss: 2.828482151031494
Validation loss: 2.165204789048882

Epoch: 6| Step: 13
Training loss: 2.3473498821258545
Validation loss: 2.176144738351145

Epoch: 156| Step: 0
Training loss: 2.2273035049438477
Validation loss: 2.227864347478395

Epoch: 6| Step: 1
Training loss: 1.693990707397461
Validation loss: 2.2568794911907566

Epoch: 6| Step: 2
Training loss: 3.248842239379883
Validation loss: 2.2530071338017783

Epoch: 6| Step: 3
Training loss: 2.763390302658081
Validation loss: 2.2700514767759588

Epoch: 6| Step: 4
Training loss: 2.7111663818359375
Validation loss: 2.2556054771587415

Epoch: 6| Step: 5
Training loss: 2.5965824127197266
Validation loss: 2.2343699586006904

Epoch: 6| Step: 6
Training loss: 2.0473010540008545
Validation loss: 2.2260687735772904

Epoch: 6| Step: 7
Training loss: 2.081249713897705
Validation loss: 2.188254958839827

Epoch: 6| Step: 8
Training loss: 2.6630373001098633
Validation loss: 2.159095207850138

Epoch: 6| Step: 9
Training loss: 2.023557662963867
Validation loss: 2.146096629481162

Epoch: 6| Step: 10
Training loss: 1.8247679471969604
Validation loss: 2.157933428723325

Epoch: 6| Step: 11
Training loss: 2.56911039352417
Validation loss: 2.155489070441133

Epoch: 6| Step: 12
Training loss: 2.1489272117614746
Validation loss: 2.1668468354850687

Epoch: 6| Step: 13
Training loss: 2.542161703109741
Validation loss: 2.1665989827084284

Epoch: 157| Step: 0
Training loss: 2.659332752227783
Validation loss: 2.1623296609488865

Epoch: 6| Step: 1
Training loss: 2.1608572006225586
Validation loss: 2.1741797078040337

Epoch: 6| Step: 2
Training loss: 2.219625473022461
Validation loss: 2.1763984285375124

Epoch: 6| Step: 3
Training loss: 2.806448459625244
Validation loss: 2.1818491681929557

Epoch: 6| Step: 4
Training loss: 2.327040433883667
Validation loss: 2.1903223183847245

Epoch: 6| Step: 5
Training loss: 1.8043118715286255
Validation loss: 2.17959023803793

Epoch: 6| Step: 6
Training loss: 1.7264046669006348
Validation loss: 2.175457126350813

Epoch: 6| Step: 7
Training loss: 1.4912502765655518
Validation loss: 2.17784224530702

Epoch: 6| Step: 8
Training loss: 2.3991646766662598
Validation loss: 2.183657379560573

Epoch: 6| Step: 9
Training loss: 2.4060792922973633
Validation loss: 2.1843743555007444

Epoch: 6| Step: 10
Training loss: 3.136963129043579
Validation loss: 2.195037290614138

Epoch: 6| Step: 11
Training loss: 1.9819191694259644
Validation loss: 2.186859684605752

Epoch: 6| Step: 12
Training loss: 2.8353846073150635
Validation loss: 2.1707783822090394

Epoch: 6| Step: 13
Training loss: 2.1814117431640625
Validation loss: 2.174585691062353

Epoch: 158| Step: 0
Training loss: 1.6258792877197266
Validation loss: 2.167044294777737

Epoch: 6| Step: 1
Training loss: 3.082763671875
Validation loss: 2.1803886608410905

Epoch: 6| Step: 2
Training loss: 2.404066562652588
Validation loss: 2.1740529434655302

Epoch: 6| Step: 3
Training loss: 3.0981407165527344
Validation loss: 2.179425516436177

Epoch: 6| Step: 4
Training loss: 2.6661031246185303
Validation loss: 2.1663538461090415

Epoch: 6| Step: 5
Training loss: 2.169604539871216
Validation loss: 2.1536551496034027

Epoch: 6| Step: 6
Training loss: 2.6345341205596924
Validation loss: 2.147520920281769

Epoch: 6| Step: 7
Training loss: 2.0404815673828125
Validation loss: 2.1365461554578555

Epoch: 6| Step: 8
Training loss: 1.72538423538208
Validation loss: 2.142434186832879

Epoch: 6| Step: 9
Training loss: 2.3255791664123535
Validation loss: 2.1513989022983018

Epoch: 6| Step: 10
Training loss: 2.2810275554656982
Validation loss: 2.1497024143895795

Epoch: 6| Step: 11
Training loss: 2.3182010650634766
Validation loss: 2.138022889373123

Epoch: 6| Step: 12
Training loss: 2.160975933074951
Validation loss: 2.1471727586561635

Epoch: 6| Step: 13
Training loss: 1.2643208503723145
Validation loss: 2.1455351844910653

Epoch: 159| Step: 0
Training loss: 1.9965794086456299
Validation loss: 2.1455602786874257

Epoch: 6| Step: 1
Training loss: 2.125048875808716
Validation loss: 2.146733937724944

Epoch: 6| Step: 2
Training loss: 2.580568790435791
Validation loss: 2.1492452262550272

Epoch: 6| Step: 3
Training loss: 2.1519017219543457
Validation loss: 2.159112625224616

Epoch: 6| Step: 4
Training loss: 2.366715908050537
Validation loss: 2.1568779407009

Epoch: 6| Step: 5
Training loss: 2.4535534381866455
Validation loss: 2.150355928687639

Epoch: 6| Step: 6
Training loss: 2.3683576583862305
Validation loss: 2.1554599744017406

Epoch: 6| Step: 7
Training loss: 2.297314167022705
Validation loss: 2.150585800088862

Epoch: 6| Step: 8
Training loss: 2.320770025253296
Validation loss: 2.145694153283232

Epoch: 6| Step: 9
Training loss: 2.1037938594818115
Validation loss: 2.1585212676755843

Epoch: 6| Step: 10
Training loss: 2.30051326751709
Validation loss: 2.156010870010622

Epoch: 6| Step: 11
Training loss: 2.499910354614258
Validation loss: 2.165268845455621

Epoch: 6| Step: 12
Training loss: 1.8050451278686523
Validation loss: 2.172055221373035

Epoch: 6| Step: 13
Training loss: 2.9152913093566895
Validation loss: 2.178901272435342

Epoch: 160| Step: 0
Training loss: 1.5967984199523926
Validation loss: 2.1950578843393633

Epoch: 6| Step: 1
Training loss: 2.2300567626953125
Validation loss: 2.220834767946633

Epoch: 6| Step: 2
Training loss: 2.3126282691955566
Validation loss: 2.2395577328179472

Epoch: 6| Step: 3
Training loss: 2.4598214626312256
Validation loss: 2.280025453977687

Epoch: 6| Step: 4
Training loss: 2.6439528465270996
Validation loss: 2.2824946116375666

Epoch: 6| Step: 5
Training loss: 3.0851006507873535
Validation loss: 2.2896384218687653

Epoch: 6| Step: 6
Training loss: 2.2729504108428955
Validation loss: 2.2864124672387236

Epoch: 6| Step: 7
Training loss: 2.5224103927612305
Validation loss: 2.2807685867432625

Epoch: 6| Step: 8
Training loss: 2.694305419921875
Validation loss: 2.269824335652013

Epoch: 6| Step: 9
Training loss: 2.703897476196289
Validation loss: 2.250118145378687

Epoch: 6| Step: 10
Training loss: 2.08066463470459
Validation loss: 2.2250106821778

Epoch: 6| Step: 11
Training loss: 2.0388896465301514
Validation loss: 2.203026158835298

Epoch: 6| Step: 12
Training loss: 2.00362229347229
Validation loss: 2.197108012373729

Epoch: 6| Step: 13
Training loss: 0.7957726120948792
Validation loss: 2.1821667814767487

Epoch: 161| Step: 0
Training loss: 2.378089427947998
Validation loss: 2.160461151471702

Epoch: 6| Step: 1
Training loss: 1.935399055480957
Validation loss: 2.153432624314421

Epoch: 6| Step: 2
Training loss: 2.024641275405884
Validation loss: 2.1442785391243557

Epoch: 6| Step: 3
Training loss: 2.6228580474853516
Validation loss: 2.1503309716460524

Epoch: 6| Step: 4
Training loss: 2.3644895553588867
Validation loss: 2.1321869101575626

Epoch: 6| Step: 5
Training loss: 2.368293285369873
Validation loss: 2.1471727599379835

Epoch: 6| Step: 6
Training loss: 2.725731372833252
Validation loss: 2.140379539100073

Epoch: 6| Step: 7
Training loss: 2.130392074584961
Validation loss: 2.1219766627075853

Epoch: 6| Step: 8
Training loss: 2.346038818359375
Validation loss: 2.123931254110029

Epoch: 6| Step: 9
Training loss: 1.8451050519943237
Validation loss: 2.118423805441908

Epoch: 6| Step: 10
Training loss: 1.664323091506958
Validation loss: 2.1208601356834493

Epoch: 6| Step: 11
Training loss: 2.7789225578308105
Validation loss: 2.1219638547589703

Epoch: 6| Step: 12
Training loss: 2.0892953872680664
Validation loss: 2.1333428672564927

Epoch: 6| Step: 13
Training loss: 2.7842516899108887
Validation loss: 2.136571817500617

Epoch: 162| Step: 0
Training loss: 2.7912817001342773
Validation loss: 2.152753032663817

Epoch: 6| Step: 1
Training loss: 2.3157196044921875
Validation loss: 2.1535727324024325

Epoch: 6| Step: 2
Training loss: 2.6796061992645264
Validation loss: 2.1605435584181096

Epoch: 6| Step: 3
Training loss: 2.4021949768066406
Validation loss: 2.1554005889482397

Epoch: 6| Step: 4
Training loss: 2.989880084991455
Validation loss: 2.144989352072439

Epoch: 6| Step: 5
Training loss: 2.015491485595703
Validation loss: 2.145328575564969

Epoch: 6| Step: 6
Training loss: 2.443544387817383
Validation loss: 2.1360904580803326

Epoch: 6| Step: 7
Training loss: 1.997275471687317
Validation loss: 2.1289343654468493

Epoch: 6| Step: 8
Training loss: 1.529193639755249
Validation loss: 2.138267065889092

Epoch: 6| Step: 9
Training loss: 1.9538702964782715
Validation loss: 2.1455972861218195

Epoch: 6| Step: 10
Training loss: 2.047922372817993
Validation loss: 2.1328587737134708

Epoch: 6| Step: 11
Training loss: 1.9410514831542969
Validation loss: 2.1503089858639624

Epoch: 6| Step: 12
Training loss: 2.685837745666504
Validation loss: 2.1523467520231843

Epoch: 6| Step: 13
Training loss: 1.6516484022140503
Validation loss: 2.159327619819231

Epoch: 163| Step: 0
Training loss: 1.985140323638916
Validation loss: 2.191202171387211

Epoch: 6| Step: 1
Training loss: 2.4667341709136963
Validation loss: 2.202050551291435

Epoch: 6| Step: 2
Training loss: 2.517605781555176
Validation loss: 2.2063620782667592

Epoch: 6| Step: 3
Training loss: 2.2827017307281494
Validation loss: 2.2062560601900985

Epoch: 6| Step: 4
Training loss: 1.3984386920928955
Validation loss: 2.201526664918469

Epoch: 6| Step: 5
Training loss: 1.8559080362319946
Validation loss: 2.205147848334364

Epoch: 6| Step: 6
Training loss: 2.9590094089508057
Validation loss: 2.1827684653702604

Epoch: 6| Step: 7
Training loss: 2.525003433227539
Validation loss: 2.1730802469356085

Epoch: 6| Step: 8
Training loss: 2.0748679637908936
Validation loss: 2.1436281857951993

Epoch: 6| Step: 9
Training loss: 2.8024654388427734
Validation loss: 2.1452424474941787

Epoch: 6| Step: 10
Training loss: 1.9491475820541382
Validation loss: 2.1486578167125745

Epoch: 6| Step: 11
Training loss: 1.4560184478759766
Validation loss: 2.1439024299703617

Epoch: 6| Step: 12
Training loss: 2.5663037300109863
Validation loss: 2.1461460615998957

Epoch: 6| Step: 13
Training loss: 2.9626433849334717
Validation loss: 2.132567697955716

Epoch: 164| Step: 0
Training loss: 1.8001629114151
Validation loss: 2.1427560570419475

Epoch: 6| Step: 1
Training loss: 2.2103023529052734
Validation loss: 2.1605219379548104

Epoch: 6| Step: 2
Training loss: 2.9063737392425537
Validation loss: 2.1578755814542054

Epoch: 6| Step: 3
Training loss: 2.2553768157958984
Validation loss: 2.1442237387421312

Epoch: 6| Step: 4
Training loss: 1.999361515045166
Validation loss: 2.131613971084677

Epoch: 6| Step: 5
Training loss: 1.849048137664795
Validation loss: 2.1435205936431885

Epoch: 6| Step: 6
Training loss: 2.292130708694458
Validation loss: 2.1417190720958095

Epoch: 6| Step: 7
Training loss: 1.709773302078247
Validation loss: 2.1515452374694166

Epoch: 6| Step: 8
Training loss: 2.0709171295166016
Validation loss: 2.1600862241560415

Epoch: 6| Step: 9
Training loss: 2.711099863052368
Validation loss: 2.185135825987785

Epoch: 6| Step: 10
Training loss: 2.607792854309082
Validation loss: 2.176716072584993

Epoch: 6| Step: 11
Training loss: 2.5502171516418457
Validation loss: 2.1635370600608086

Epoch: 6| Step: 12
Training loss: 2.2898874282836914
Validation loss: 2.1414938152477307

Epoch: 6| Step: 13
Training loss: 2.6622865200042725
Validation loss: 2.1560722422856156

Epoch: 165| Step: 0
Training loss: 2.4804534912109375
Validation loss: 2.1544572499490555

Epoch: 6| Step: 1
Training loss: 2.282989501953125
Validation loss: 2.172706219457811

Epoch: 6| Step: 2
Training loss: 2.8446552753448486
Validation loss: 2.163021510647189

Epoch: 6| Step: 3
Training loss: 2.550809860229492
Validation loss: 2.1583683131843485

Epoch: 6| Step: 4
Training loss: 1.7422304153442383
Validation loss: 2.1286089561318837

Epoch: 6| Step: 5
Training loss: 1.7093349695205688
Validation loss: 2.123281809591478

Epoch: 6| Step: 6
Training loss: 2.0279340744018555
Validation loss: 2.1242346430337555

Epoch: 6| Step: 7
Training loss: 2.8127307891845703
Validation loss: 2.157002102944159

Epoch: 6| Step: 8
Training loss: 1.6221400499343872
Validation loss: 2.16958196701542

Epoch: 6| Step: 9
Training loss: 2.050257682800293
Validation loss: 2.2010143136465423

Epoch: 6| Step: 10
Training loss: 2.0307259559631348
Validation loss: 2.2127034741063274

Epoch: 6| Step: 11
Training loss: 2.7708144187927246
Validation loss: 2.210623615531511

Epoch: 6| Step: 12
Training loss: 2.6290459632873535
Validation loss: 2.151351812065289

Epoch: 6| Step: 13
Training loss: 2.9445583820343018
Validation loss: 2.1320381536278674

Epoch: 166| Step: 0
Training loss: 1.6394002437591553
Validation loss: 2.13396873781758

Epoch: 6| Step: 1
Training loss: 1.6091971397399902
Validation loss: 2.1324456532796225

Epoch: 6| Step: 2
Training loss: 1.6209737062454224
Validation loss: 2.1426688573693715

Epoch: 6| Step: 3
Training loss: 2.4037864208221436
Validation loss: 2.1537415955656316

Epoch: 6| Step: 4
Training loss: 1.9248762130737305
Validation loss: 2.17392631499998

Epoch: 6| Step: 5
Training loss: 2.8503730297088623
Validation loss: 2.177760672825639

Epoch: 6| Step: 6
Training loss: 2.333108425140381
Validation loss: 2.1551916727455716

Epoch: 6| Step: 7
Training loss: 2.5377206802368164
Validation loss: 2.1611618149665093

Epoch: 6| Step: 8
Training loss: 1.9497567415237427
Validation loss: 2.152713191124701

Epoch: 6| Step: 9
Training loss: 2.668225049972534
Validation loss: 2.150446025274133

Epoch: 6| Step: 10
Training loss: 2.7629482746124268
Validation loss: 2.1725335556973695

Epoch: 6| Step: 11
Training loss: 2.3546581268310547
Validation loss: 2.185440530059158

Epoch: 6| Step: 12
Training loss: 2.246962785720825
Validation loss: 2.1765743019760295

Epoch: 6| Step: 13
Training loss: 3.328566789627075
Validation loss: 2.161927389842208

Epoch: 167| Step: 0
Training loss: 1.9994404315948486
Validation loss: 2.141382646817033

Epoch: 6| Step: 1
Training loss: 2.530636787414551
Validation loss: 2.1296041011810303

Epoch: 6| Step: 2
Training loss: 2.4614243507385254
Validation loss: 2.1235433214454242

Epoch: 6| Step: 3
Training loss: 2.5620687007904053
Validation loss: 2.115321061944449

Epoch: 6| Step: 4
Training loss: 2.2838010787963867
Validation loss: 2.1096537741281653

Epoch: 6| Step: 5
Training loss: 2.178508758544922
Validation loss: 2.1000321013953096

Epoch: 6| Step: 6
Training loss: 1.5481722354888916
Validation loss: 2.101938198971492

Epoch: 6| Step: 7
Training loss: 2.512547492980957
Validation loss: 2.1123303059608705

Epoch: 6| Step: 8
Training loss: 1.5688114166259766
Validation loss: 2.1118527638014926

Epoch: 6| Step: 9
Training loss: 2.4118425846099854
Validation loss: 2.109550327383062

Epoch: 6| Step: 10
Training loss: 1.9014759063720703
Validation loss: 2.1209900097180436

Epoch: 6| Step: 11
Training loss: 2.36086368560791
Validation loss: 2.1372338238582818

Epoch: 6| Step: 12
Training loss: 2.45527720451355
Validation loss: 2.139531026604355

Epoch: 6| Step: 13
Training loss: 2.9088518619537354
Validation loss: 2.1489650587881766

Epoch: 168| Step: 0
Training loss: 2.3719632625579834
Validation loss: 2.151581218165736

Epoch: 6| Step: 1
Training loss: 1.9971683025360107
Validation loss: 2.1561250520008866

Epoch: 6| Step: 2
Training loss: 1.9686477184295654
Validation loss: 2.1840068396701606

Epoch: 6| Step: 3
Training loss: 2.3732986450195312
Validation loss: 2.1807226032339115

Epoch: 6| Step: 4
Training loss: 2.572903633117676
Validation loss: 2.174159437097529

Epoch: 6| Step: 5
Training loss: 2.602025032043457
Validation loss: 2.1675764694008777

Epoch: 6| Step: 6
Training loss: 2.8018534183502197
Validation loss: 2.143764357413015

Epoch: 6| Step: 7
Training loss: 2.6424789428710938
Validation loss: 2.1393368577444427

Epoch: 6| Step: 8
Training loss: 2.238698720932007
Validation loss: 2.1337820381246586

Epoch: 6| Step: 9
Training loss: 2.4466090202331543
Validation loss: 2.131345902719805

Epoch: 6| Step: 10
Training loss: 1.6587793827056885
Validation loss: 2.142875873914329

Epoch: 6| Step: 11
Training loss: 1.8615553379058838
Validation loss: 2.1435477349065963

Epoch: 6| Step: 12
Training loss: 1.4563020467758179
Validation loss: 2.132550172908332

Epoch: 6| Step: 13
Training loss: 2.680812120437622
Validation loss: 2.112420928093695

Epoch: 169| Step: 0
Training loss: 3.120185375213623
Validation loss: 2.115232975252213

Epoch: 6| Step: 1
Training loss: 2.5914828777313232
Validation loss: 2.121026392905943

Epoch: 6| Step: 2
Training loss: 2.285583019256592
Validation loss: 2.119165156477241

Epoch: 6| Step: 3
Training loss: 2.2928972244262695
Validation loss: 2.142597858623792

Epoch: 6| Step: 4
Training loss: 2.6089296340942383
Validation loss: 2.1362560872108705

Epoch: 6| Step: 5
Training loss: 1.843529224395752
Validation loss: 2.1536357838620424

Epoch: 6| Step: 6
Training loss: 0.9948146343231201
Validation loss: 2.1502066940389652

Epoch: 6| Step: 7
Training loss: 2.3255152702331543
Validation loss: 2.126639909641717

Epoch: 6| Step: 8
Training loss: 1.9278804063796997
Validation loss: 2.1256165184000486

Epoch: 6| Step: 9
Training loss: 2.4544262886047363
Validation loss: 2.1459173105096303

Epoch: 6| Step: 10
Training loss: 2.596292495727539
Validation loss: 2.154588560904226

Epoch: 6| Step: 11
Training loss: 2.2982232570648193
Validation loss: 2.170450947617972

Epoch: 6| Step: 12
Training loss: 2.0532286167144775
Validation loss: 2.2010569239175446

Epoch: 6| Step: 13
Training loss: 1.596834659576416
Validation loss: 2.2084903870859454

Epoch: 170| Step: 0
Training loss: 2.314647912979126
Validation loss: 2.2044612438448015

Epoch: 6| Step: 1
Training loss: 1.794886827468872
Validation loss: 2.213191573337842

Epoch: 6| Step: 2
Training loss: 1.8432817459106445
Validation loss: 2.189082440509591

Epoch: 6| Step: 3
Training loss: 2.0467758178710938
Validation loss: 2.1935272268069688

Epoch: 6| Step: 4
Training loss: 2.0056354999542236
Validation loss: 2.1868568184555217

Epoch: 6| Step: 5
Training loss: 2.1654934883117676
Validation loss: 2.1793722004018803

Epoch: 6| Step: 6
Training loss: 2.880704402923584
Validation loss: 2.1735987483814196

Epoch: 6| Step: 7
Training loss: 2.439378499984741
Validation loss: 2.1774158605965237

Epoch: 6| Step: 8
Training loss: 1.7946014404296875
Validation loss: 2.1806805620911303

Epoch: 6| Step: 9
Training loss: 1.5730053186416626
Validation loss: 2.1704090128662767

Epoch: 6| Step: 10
Training loss: 2.4439008235931396
Validation loss: 2.166181702767649

Epoch: 6| Step: 11
Training loss: 2.800776243209839
Validation loss: 2.166698504519719

Epoch: 6| Step: 12
Training loss: 2.6283278465270996
Validation loss: 2.156400233186701

Epoch: 6| Step: 13
Training loss: 2.4404702186584473
Validation loss: 2.1639042310817267

Epoch: 171| Step: 0
Training loss: 2.0664052963256836
Validation loss: 2.1405972998629332

Epoch: 6| Step: 1
Training loss: 1.520298719406128
Validation loss: 2.132069477470972

Epoch: 6| Step: 2
Training loss: 3.3878579139709473
Validation loss: 2.156867563083608

Epoch: 6| Step: 3
Training loss: 2.177665948867798
Validation loss: 2.1485420862833657

Epoch: 6| Step: 4
Training loss: 1.448514699935913
Validation loss: 2.1496002725375596

Epoch: 6| Step: 5
Training loss: 2.842632532119751
Validation loss: 2.122841409457627

Epoch: 6| Step: 6
Training loss: 1.9603773355484009
Validation loss: 2.133777182589295

Epoch: 6| Step: 7
Training loss: 2.3218812942504883
Validation loss: 2.123104941460394

Epoch: 6| Step: 8
Training loss: 2.0994417667388916
Validation loss: 2.1368714801726805

Epoch: 6| Step: 9
Training loss: 2.1378414630889893
Validation loss: 2.148531513829385

Epoch: 6| Step: 10
Training loss: 2.398564100265503
Validation loss: 2.173185634356673

Epoch: 6| Step: 11
Training loss: 2.345898151397705
Validation loss: 2.189883268007668

Epoch: 6| Step: 12
Training loss: 2.377145767211914
Validation loss: 2.1865210276778027

Epoch: 6| Step: 13
Training loss: 2.351292610168457
Validation loss: 2.1733046475277153

Epoch: 172| Step: 0
Training loss: 1.8520501852035522
Validation loss: 2.122403114072738

Epoch: 6| Step: 1
Training loss: 1.9522087574005127
Validation loss: 2.104469468516688

Epoch: 6| Step: 2
Training loss: 2.1324872970581055
Validation loss: 2.110354087686026

Epoch: 6| Step: 3
Training loss: 2.1293723583221436
Validation loss: 2.143121275850522

Epoch: 6| Step: 4
Training loss: 2.342080593109131
Validation loss: 2.1962477776312057

Epoch: 6| Step: 5
Training loss: 2.3418939113616943
Validation loss: 2.2287640751049085

Epoch: 6| Step: 6
Training loss: 2.8135104179382324
Validation loss: 2.264341354370117

Epoch: 6| Step: 7
Training loss: 2.0459938049316406
Validation loss: 2.22845317855958

Epoch: 6| Step: 8
Training loss: 2.5693702697753906
Validation loss: 2.204344754577965

Epoch: 6| Step: 9
Training loss: 2.288449287414551
Validation loss: 2.1691302919900544

Epoch: 6| Step: 10
Training loss: 1.904322862625122
Validation loss: 2.124694788327781

Epoch: 6| Step: 11
Training loss: 2.767122268676758
Validation loss: 2.1113229400368145

Epoch: 6| Step: 12
Training loss: 2.388244152069092
Validation loss: 2.1345785715246715

Epoch: 6| Step: 13
Training loss: 1.4530915021896362
Validation loss: 2.1611759457536923

Epoch: 173| Step: 0
Training loss: 2.000115394592285
Validation loss: 2.179914379632601

Epoch: 6| Step: 1
Training loss: 1.9235764741897583
Validation loss: 2.2102796159764773

Epoch: 6| Step: 2
Training loss: 2.052492141723633
Validation loss: 2.232003552939302

Epoch: 6| Step: 3
Training loss: 1.620790719985962
Validation loss: 2.233194546032977

Epoch: 6| Step: 4
Training loss: 2.939422130584717
Validation loss: 2.179928357883166

Epoch: 6| Step: 5
Training loss: 2.901277542114258
Validation loss: 2.1489951636201594

Epoch: 6| Step: 6
Training loss: 2.037278890609741
Validation loss: 2.1267023842821837

Epoch: 6| Step: 7
Training loss: 2.815659523010254
Validation loss: 2.132500010152017

Epoch: 6| Step: 8
Training loss: 2.404226541519165
Validation loss: 2.155860459932717

Epoch: 6| Step: 9
Training loss: 2.0873360633850098
Validation loss: 2.1688042840650006

Epoch: 6| Step: 10
Training loss: 2.804103136062622
Validation loss: 2.1825680348180954

Epoch: 6| Step: 11
Training loss: 1.984242558479309
Validation loss: 2.18055833026927

Epoch: 6| Step: 12
Training loss: 2.878098964691162
Validation loss: 2.146376863602669

Epoch: 6| Step: 13
Training loss: 1.5564773082733154
Validation loss: 2.11959925518241

Epoch: 174| Step: 0
Training loss: 2.581825017929077
Validation loss: 2.0956770630292993

Epoch: 6| Step: 1
Training loss: 1.6862633228302002
Validation loss: 2.1098837442295526

Epoch: 6| Step: 2
Training loss: 2.3000543117523193
Validation loss: 2.1330441018586517

Epoch: 6| Step: 3
Training loss: 2.127105712890625
Validation loss: 2.166470337939519

Epoch: 6| Step: 4
Training loss: 2.5966644287109375
Validation loss: 2.2418375925351213

Epoch: 6| Step: 5
Training loss: 2.2823214530944824
Validation loss: 2.3178506999887447

Epoch: 6| Step: 6
Training loss: 2.359842538833618
Validation loss: 2.315432443413683

Epoch: 6| Step: 7
Training loss: 2.4220433235168457
Validation loss: 2.264256000518799

Epoch: 6| Step: 8
Training loss: 1.6174169778823853
Validation loss: 2.1754966525621313

Epoch: 6| Step: 9
Training loss: 1.916500210762024
Validation loss: 2.1144928214370564

Epoch: 6| Step: 10
Training loss: 2.8062970638275146
Validation loss: 2.128050575974167

Epoch: 6| Step: 11
Training loss: 2.618159770965576
Validation loss: 2.128635794885697

Epoch: 6| Step: 12
Training loss: 2.082310199737549
Validation loss: 2.1317838930314585

Epoch: 6| Step: 13
Training loss: 2.1116104125976562
Validation loss: 2.139271838690645

Epoch: 175| Step: 0
Training loss: 2.167034149169922
Validation loss: 2.158739835985245

Epoch: 6| Step: 1
Training loss: 2.4421796798706055
Validation loss: 2.1713588571035736

Epoch: 6| Step: 2
Training loss: 1.6623218059539795
Validation loss: 2.150726549087032

Epoch: 6| Step: 3
Training loss: 2.3757667541503906
Validation loss: 2.1381792073608725

Epoch: 6| Step: 4
Training loss: 2.5289199352264404
Validation loss: 2.1312654402948197

Epoch: 6| Step: 5
Training loss: 2.4466090202331543
Validation loss: 2.1448177906774704

Epoch: 6| Step: 6
Training loss: 2.064984083175659
Validation loss: 2.1487745828525995

Epoch: 6| Step: 7
Training loss: 1.7958109378814697
Validation loss: 2.153257357176914

Epoch: 6| Step: 8
Training loss: 2.318624496459961
Validation loss: 2.1356499143826064

Epoch: 6| Step: 9
Training loss: 2.5756895542144775
Validation loss: 2.1347665812379573

Epoch: 6| Step: 10
Training loss: 2.3363592624664307
Validation loss: 2.1383625307390766

Epoch: 6| Step: 11
Training loss: 2.4911556243896484
Validation loss: 2.129971227338237

Epoch: 6| Step: 12
Training loss: 1.8552297353744507
Validation loss: 2.111938415035125

Epoch: 6| Step: 13
Training loss: 1.789226770401001
Validation loss: 2.117373799764982

Epoch: 176| Step: 0
Training loss: 1.9288403987884521
Validation loss: 2.1144080982413342

Epoch: 6| Step: 1
Training loss: 2.0916695594787598
Validation loss: 2.1121301010090816

Epoch: 6| Step: 2
Training loss: 2.845900535583496
Validation loss: 2.1304741892763364

Epoch: 6| Step: 3
Training loss: 1.8433876037597656
Validation loss: 2.1274280714732345

Epoch: 6| Step: 4
Training loss: 2.319408655166626
Validation loss: 2.1354159770473355

Epoch: 6| Step: 5
Training loss: 2.248116970062256
Validation loss: 2.1406850122636363

Epoch: 6| Step: 6
Training loss: 1.4986824989318848
Validation loss: 2.144600342678767

Epoch: 6| Step: 7
Training loss: 1.8500802516937256
Validation loss: 2.152919726987039

Epoch: 6| Step: 8
Training loss: 2.025439739227295
Validation loss: 2.1370912572389007

Epoch: 6| Step: 9
Training loss: 1.7446694374084473
Validation loss: 2.1419275319704445

Epoch: 6| Step: 10
Training loss: 3.0638234615325928
Validation loss: 2.1444009888556694

Epoch: 6| Step: 11
Training loss: 2.687476873397827
Validation loss: 2.144551847570686

Epoch: 6| Step: 12
Training loss: 2.424487829208374
Validation loss: 2.141182373928767

Epoch: 6| Step: 13
Training loss: 2.3146791458129883
Validation loss: 2.1544890070474274

Epoch: 177| Step: 0
Training loss: 1.3465080261230469
Validation loss: 2.1672872394643803

Epoch: 6| Step: 1
Training loss: 2.2495687007904053
Validation loss: 2.152518521073044

Epoch: 6| Step: 2
Training loss: 1.8855438232421875
Validation loss: 2.165955712718348

Epoch: 6| Step: 3
Training loss: 2.553408145904541
Validation loss: 2.1521084846988803

Epoch: 6| Step: 4
Training loss: 1.9672398567199707
Validation loss: 2.1597967327281995

Epoch: 6| Step: 5
Training loss: 2.4011378288269043
Validation loss: 2.164731207714286

Epoch: 6| Step: 6
Training loss: 1.862373948097229
Validation loss: 2.1708574089952695

Epoch: 6| Step: 7
Training loss: 2.680513858795166
Validation loss: 2.1684843468409714

Epoch: 6| Step: 8
Training loss: 2.4301297664642334
Validation loss: 2.1569878401294833

Epoch: 6| Step: 9
Training loss: 3.267951488494873
Validation loss: 2.1772021824313748

Epoch: 6| Step: 10
Training loss: 1.7081272602081299
Validation loss: 2.178281407202444

Epoch: 6| Step: 11
Training loss: 2.4113335609436035
Validation loss: 2.167465476579564

Epoch: 6| Step: 12
Training loss: 1.710198998451233
Validation loss: 2.158365954634964

Epoch: 6| Step: 13
Training loss: 2.1017911434173584
Validation loss: 2.151030772475786

Epoch: 178| Step: 0
Training loss: 1.1715290546417236
Validation loss: 2.1425677499463482

Epoch: 6| Step: 1
Training loss: 2.892056465148926
Validation loss: 2.134934648390739

Epoch: 6| Step: 2
Training loss: 2.8006157875061035
Validation loss: 2.138870567403814

Epoch: 6| Step: 3
Training loss: 2.2106051445007324
Validation loss: 2.1421054370941652

Epoch: 6| Step: 4
Training loss: 2.2930798530578613
Validation loss: 2.153157905865741

Epoch: 6| Step: 5
Training loss: 2.3797221183776855
Validation loss: 2.1380743980407715

Epoch: 6| Step: 6
Training loss: 1.875749111175537
Validation loss: 2.140348769003345

Epoch: 6| Step: 7
Training loss: 2.0282955169677734
Validation loss: 2.131022132853026

Epoch: 6| Step: 8
Training loss: 2.760199785232544
Validation loss: 2.132539563281562

Epoch: 6| Step: 9
Training loss: 1.1400624513626099
Validation loss: 2.125779709508342

Epoch: 6| Step: 10
Training loss: 2.232710599899292
Validation loss: 2.1322158331512124

Epoch: 6| Step: 11
Training loss: 2.389124870300293
Validation loss: 2.1387315232266664

Epoch: 6| Step: 12
Training loss: 1.800972819328308
Validation loss: 2.1438674388393277

Epoch: 6| Step: 13
Training loss: 2.2352991104125977
Validation loss: 2.152233044306437

Epoch: 179| Step: 0
Training loss: 1.791955590248108
Validation loss: 2.1589498340442614

Epoch: 6| Step: 1
Training loss: 2.7662601470947266
Validation loss: 2.1580962852765153

Epoch: 6| Step: 2
Training loss: 2.3851559162139893
Validation loss: 2.1707700837043022

Epoch: 6| Step: 3
Training loss: 2.4543166160583496
Validation loss: 2.167194361327797

Epoch: 6| Step: 4
Training loss: 2.9724740982055664
Validation loss: 2.171518241205523

Epoch: 6| Step: 5
Training loss: 2.2645270824432373
Validation loss: 2.1716167055150515

Epoch: 6| Step: 6
Training loss: 1.777400016784668
Validation loss: 2.1647585361234603

Epoch: 6| Step: 7
Training loss: 1.6213241815567017
Validation loss: 2.1634507756079397

Epoch: 6| Step: 8
Training loss: 2.0284945964813232
Validation loss: 2.164745943520659

Epoch: 6| Step: 9
Training loss: 1.7570828199386597
Validation loss: 2.159056968586419

Epoch: 6| Step: 10
Training loss: 2.3420848846435547
Validation loss: 2.1403612629059823

Epoch: 6| Step: 11
Training loss: 1.9767440557479858
Validation loss: 2.156911475684053

Epoch: 6| Step: 12
Training loss: 1.9249656200408936
Validation loss: 2.1509914731466644

Epoch: 6| Step: 13
Training loss: 2.147900342941284
Validation loss: 2.156299583373531

Epoch: 180| Step: 0
Training loss: 1.9393669366836548
Validation loss: 2.152160329203452

Epoch: 6| Step: 1
Training loss: 2.3958003520965576
Validation loss: 2.144190469095784

Epoch: 6| Step: 2
Training loss: 1.9707239866256714
Validation loss: 2.1530956632347515

Epoch: 6| Step: 3
Training loss: 1.9730255603790283
Validation loss: 2.1616808637495963

Epoch: 6| Step: 4
Training loss: 2.2447259426116943
Validation loss: 2.1628591655403056

Epoch: 6| Step: 5
Training loss: 2.5849015712738037
Validation loss: 2.1629327753538727

Epoch: 6| Step: 6
Training loss: 2.2988924980163574
Validation loss: 2.1540996131076606

Epoch: 6| Step: 7
Training loss: 1.4769012928009033
Validation loss: 2.1728262465487242

Epoch: 6| Step: 8
Training loss: 1.5300248861312866
Validation loss: 2.194904117174046

Epoch: 6| Step: 9
Training loss: 1.879156231880188
Validation loss: 2.1971440007609706

Epoch: 6| Step: 10
Training loss: 2.8234314918518066
Validation loss: 2.1986801367934032

Epoch: 6| Step: 11
Training loss: 2.477506160736084
Validation loss: 2.19041520549405

Epoch: 6| Step: 12
Training loss: 2.3939194679260254
Validation loss: 2.1749163519951606

Epoch: 6| Step: 13
Training loss: 1.9318362474441528
Validation loss: 2.1388521027821366

Epoch: 181| Step: 0
Training loss: 1.7473363876342773
Validation loss: 2.1221284404877694

Epoch: 6| Step: 1
Training loss: 2.251556396484375
Validation loss: 2.109167157962758

Epoch: 6| Step: 2
Training loss: 2.115492582321167
Validation loss: 2.1022698648514284

Epoch: 6| Step: 3
Training loss: 2.2816247940063477
Validation loss: 2.09661832932503

Epoch: 6| Step: 4
Training loss: 2.0219240188598633
Validation loss: 2.0805451126508814

Epoch: 6| Step: 5
Training loss: 2.093015432357788
Validation loss: 2.092433662824733

Epoch: 6| Step: 6
Training loss: 2.4676098823547363
Validation loss: 2.087469562407463

Epoch: 6| Step: 7
Training loss: 2.327145576477051
Validation loss: 2.0938666097579466

Epoch: 6| Step: 8
Training loss: 1.6164932250976562
Validation loss: 2.1062445768746

Epoch: 6| Step: 9
Training loss: 1.7944402694702148
Validation loss: 2.1159526084059026

Epoch: 6| Step: 10
Training loss: 2.039518356323242
Validation loss: 2.1356197762232956

Epoch: 6| Step: 11
Training loss: 2.905402660369873
Validation loss: 2.1421111245309152

Epoch: 6| Step: 12
Training loss: 2.2752299308776855
Validation loss: 2.1349481895405757

Epoch: 6| Step: 13
Training loss: 2.1071972846984863
Validation loss: 2.1526330363365913

Epoch: 182| Step: 0
Training loss: 2.329392433166504
Validation loss: 2.1588283033781153

Epoch: 6| Step: 1
Training loss: 1.9167598485946655
Validation loss: 2.149720750829225

Epoch: 6| Step: 2
Training loss: 2.7679476737976074
Validation loss: 2.1345619565697125

Epoch: 6| Step: 3
Training loss: 1.6241455078125
Validation loss: 2.134687216051163

Epoch: 6| Step: 4
Training loss: 2.1522557735443115
Validation loss: 2.1354277262123684

Epoch: 6| Step: 5
Training loss: 1.5370519161224365
Validation loss: 2.1449238869451706

Epoch: 6| Step: 6
Training loss: 2.2015318870544434
Validation loss: 2.131531882029708

Epoch: 6| Step: 7
Training loss: 2.49560546875
Validation loss: 2.1381850396433184

Epoch: 6| Step: 8
Training loss: 2.398193836212158
Validation loss: 2.146119661228631

Epoch: 6| Step: 9
Training loss: 2.539151191711426
Validation loss: 2.143465663797112

Epoch: 6| Step: 10
Training loss: 2.2544476985931396
Validation loss: 2.161007178727017

Epoch: 6| Step: 11
Training loss: 1.3910621404647827
Validation loss: 2.149720452165091

Epoch: 6| Step: 12
Training loss: 2.2800540924072266
Validation loss: 2.1512763474577214

Epoch: 6| Step: 13
Training loss: 1.6341853141784668
Validation loss: 2.149491830538678

Epoch: 183| Step: 0
Training loss: 2.1931962966918945
Validation loss: 2.144816125592878

Epoch: 6| Step: 1
Training loss: 1.8992972373962402
Validation loss: 2.15055247019696

Epoch: 6| Step: 2
Training loss: 1.8833973407745361
Validation loss: 2.157727535052966

Epoch: 6| Step: 3
Training loss: 2.6196563243865967
Validation loss: 2.157753675214706

Epoch: 6| Step: 4
Training loss: 2.062154531478882
Validation loss: 2.145328575564969

Epoch: 6| Step: 5
Training loss: 3.540426731109619
Validation loss: 2.1466783426141225

Epoch: 6| Step: 6
Training loss: 2.0962629318237305
Validation loss: 2.1486668176548456

Epoch: 6| Step: 7
Training loss: 1.9079322814941406
Validation loss: 2.1509077369525866

Epoch: 6| Step: 8
Training loss: 1.7468715906143188
Validation loss: 2.1366956721069994

Epoch: 6| Step: 9
Training loss: 1.6795762777328491
Validation loss: 2.128099674819618

Epoch: 6| Step: 10
Training loss: 1.7303526401519775
Validation loss: 2.1179392542890323

Epoch: 6| Step: 11
Training loss: 1.8626341819763184
Validation loss: 2.1165359814961753

Epoch: 6| Step: 12
Training loss: 2.2453866004943848
Validation loss: 2.1299535433451333

Epoch: 6| Step: 13
Training loss: 2.6305787563323975
Validation loss: 2.1322126311640583

Epoch: 184| Step: 0
Training loss: 2.412958860397339
Validation loss: 2.1265531714244554

Epoch: 6| Step: 1
Training loss: 2.009582042694092
Validation loss: 2.14208988476825

Epoch: 6| Step: 2
Training loss: 2.439582347869873
Validation loss: 2.126907023050452

Epoch: 6| Step: 3
Training loss: 2.227642297744751
Validation loss: 2.1207917992786696

Epoch: 6| Step: 4
Training loss: 2.4614272117614746
Validation loss: 2.120061202715802

Epoch: 6| Step: 5
Training loss: 1.645660638809204
Validation loss: 2.114889103879211

Epoch: 6| Step: 6
Training loss: 2.0359067916870117
Validation loss: 2.113357283735788

Epoch: 6| Step: 7
Training loss: 2.018065929412842
Validation loss: 2.103227529474484

Epoch: 6| Step: 8
Training loss: 2.5746779441833496
Validation loss: 2.108159369037997

Epoch: 6| Step: 9
Training loss: 2.400783061981201
Validation loss: 2.097430057423089

Epoch: 6| Step: 10
Training loss: 1.1466481685638428
Validation loss: 2.0996297405612085

Epoch: 6| Step: 11
Training loss: 2.27154803276062
Validation loss: 2.110918729535995

Epoch: 6| Step: 12
Training loss: 2.2009801864624023
Validation loss: 2.1275040167634205

Epoch: 6| Step: 13
Training loss: 1.5518749952316284
Validation loss: 2.13900311018831

Epoch: 185| Step: 0
Training loss: 2.6316769123077393
Validation loss: 2.138512061488244

Epoch: 6| Step: 1
Training loss: 1.4703878164291382
Validation loss: 2.1466271390197096

Epoch: 6| Step: 2
Training loss: 2.0487678050994873
Validation loss: 2.139384336369012

Epoch: 6| Step: 3
Training loss: 2.181020498275757
Validation loss: 2.1561503820521857

Epoch: 6| Step: 4
Training loss: 1.704309344291687
Validation loss: 2.159714501391175

Epoch: 6| Step: 5
Training loss: 2.1921441555023193
Validation loss: 2.181845759832731

Epoch: 6| Step: 6
Training loss: 1.8007110357284546
Validation loss: 2.1801341041441886

Epoch: 6| Step: 7
Training loss: 2.3783516883850098
Validation loss: 2.156917941185736

Epoch: 6| Step: 8
Training loss: 1.9896270036697388
Validation loss: 2.157025924292944

Epoch: 6| Step: 9
Training loss: 1.953065276145935
Validation loss: 2.1494762077126452

Epoch: 6| Step: 10
Training loss: 2.800760269165039
Validation loss: 2.141749794765185

Epoch: 6| Step: 11
Training loss: 2.234738349914551
Validation loss: 2.1295318167696715

Epoch: 6| Step: 12
Training loss: 2.2548916339874268
Validation loss: 2.131273477308212

Epoch: 6| Step: 13
Training loss: 1.95705246925354
Validation loss: 2.115985228169349

Epoch: 186| Step: 0
Training loss: 1.9419763088226318
Validation loss: 2.127337981295842

Epoch: 6| Step: 1
Training loss: 1.7093346118927002
Validation loss: 2.108424243106637

Epoch: 6| Step: 2
Training loss: 3.303884506225586
Validation loss: 2.0927675052355696

Epoch: 6| Step: 3
Training loss: 1.898689866065979
Validation loss: 2.090399264007486

Epoch: 6| Step: 4
Training loss: 1.8957874774932861
Validation loss: 2.0760758089762863

Epoch: 6| Step: 5
Training loss: 1.6623917818069458
Validation loss: 2.0777562792583177

Epoch: 6| Step: 6
Training loss: 2.604158401489258
Validation loss: 2.071177413386683

Epoch: 6| Step: 7
Training loss: 1.3499078750610352
Validation loss: 2.0769386291503906

Epoch: 6| Step: 8
Training loss: 1.5206973552703857
Validation loss: 2.080815415228567

Epoch: 6| Step: 9
Training loss: 2.7533023357391357
Validation loss: 2.104133903339345

Epoch: 6| Step: 10
Training loss: 2.334486246109009
Validation loss: 2.097601298362978

Epoch: 6| Step: 11
Training loss: 2.422515869140625
Validation loss: 2.110914949447878

Epoch: 6| Step: 12
Training loss: 1.805537223815918
Validation loss: 2.107522961913898

Epoch: 6| Step: 13
Training loss: 2.5805349349975586
Validation loss: 2.10211012183979

Epoch: 187| Step: 0
Training loss: 2.2062129974365234
Validation loss: 2.1263191802527315

Epoch: 6| Step: 1
Training loss: 1.3390320539474487
Validation loss: 2.1305666174939883

Epoch: 6| Step: 2
Training loss: 2.6015210151672363
Validation loss: 2.1536674960967033

Epoch: 6| Step: 3
Training loss: 2.476961135864258
Validation loss: 2.163288136964203

Epoch: 6| Step: 4
Training loss: 2.649613857269287
Validation loss: 2.1886982558875956

Epoch: 6| Step: 5
Training loss: 2.044847249984741
Validation loss: 2.1965597175782725

Epoch: 6| Step: 6
Training loss: 2.3296308517456055
Validation loss: 2.2009721917490803

Epoch: 6| Step: 7
Training loss: 2.1693544387817383
Validation loss: 2.2113555964603218

Epoch: 6| Step: 8
Training loss: 1.374814510345459
Validation loss: 2.203769970965642

Epoch: 6| Step: 9
Training loss: 1.9211074113845825
Validation loss: 2.2007368136477727

Epoch: 6| Step: 10
Training loss: 2.215857982635498
Validation loss: 2.18020551179045

Epoch: 6| Step: 11
Training loss: 2.5585293769836426
Validation loss: 2.1897267936378397

Epoch: 6| Step: 12
Training loss: 2.2298758029937744
Validation loss: 2.166845311400711

Epoch: 6| Step: 13
Training loss: 0.9667820334434509
Validation loss: 2.1600456596702657

Epoch: 188| Step: 0
Training loss: 3.015237808227539
Validation loss: 2.1276736644006546

Epoch: 6| Step: 1
Training loss: 2.072053909301758
Validation loss: 2.0896754905741703

Epoch: 6| Step: 2
Training loss: 1.8321516513824463
Validation loss: 2.0826116659307994

Epoch: 6| Step: 3
Training loss: 1.5986863374710083
Validation loss: 2.0807880496466034

Epoch: 6| Step: 4
Training loss: 1.8904038667678833
Validation loss: 2.0811563973785727

Epoch: 6| Step: 5
Training loss: 1.2594126462936401
Validation loss: 2.0874088887245423

Epoch: 6| Step: 6
Training loss: 2.561476707458496
Validation loss: 2.083539519258725

Epoch: 6| Step: 7
Training loss: 1.8138360977172852
Validation loss: 2.0963938966874154

Epoch: 6| Step: 8
Training loss: 1.8151874542236328
Validation loss: 2.0965154542717883

Epoch: 6| Step: 9
Training loss: 2.4214446544647217
Validation loss: 2.1072743554269113

Epoch: 6| Step: 10
Training loss: 2.3425703048706055
Validation loss: 2.126291359624555

Epoch: 6| Step: 11
Training loss: 2.7330727577209473
Validation loss: 2.1274435340717273

Epoch: 6| Step: 12
Training loss: 2.004784345626831
Validation loss: 2.1268266118982786

Epoch: 6| Step: 13
Training loss: 2.2297799587249756
Validation loss: 2.127414554677984

Epoch: 189| Step: 0
Training loss: 1.554040551185608
Validation loss: 2.1509061295499086

Epoch: 6| Step: 1
Training loss: 2.3845019340515137
Validation loss: 2.155815726967268

Epoch: 6| Step: 2
Training loss: 2.778014659881592
Validation loss: 2.1394575770183275

Epoch: 6| Step: 3
Training loss: 1.6921017169952393
Validation loss: 2.1279694341844126

Epoch: 6| Step: 4
Training loss: 1.8263521194458008
Validation loss: 2.1409426966021137

Epoch: 6| Step: 5
Training loss: 2.1375889778137207
Validation loss: 2.121496464616509

Epoch: 6| Step: 6
Training loss: 1.323708415031433
Validation loss: 2.1239482843747703

Epoch: 6| Step: 7
Training loss: 2.327220916748047
Validation loss: 2.1194479824394308

Epoch: 6| Step: 8
Training loss: 1.9786977767944336
Validation loss: 2.132677862721105

Epoch: 6| Step: 9
Training loss: 2.8236923217773438
Validation loss: 2.1130722312517065

Epoch: 6| Step: 10
Training loss: 1.9304002523422241
Validation loss: 2.1156776899932535

Epoch: 6| Step: 11
Training loss: 2.6220016479492188
Validation loss: 2.1036812695123817

Epoch: 6| Step: 12
Training loss: 2.1281206607818604
Validation loss: 2.099464693377095

Epoch: 6| Step: 13
Training loss: 1.7143338918685913
Validation loss: 2.10084133378921

Epoch: 190| Step: 0
Training loss: 2.6614487171173096
Validation loss: 2.097789934886399

Epoch: 6| Step: 1
Training loss: 2.5260024070739746
Validation loss: 2.1052094685134066

Epoch: 6| Step: 2
Training loss: 1.6955811977386475
Validation loss: 2.1049846731206423

Epoch: 6| Step: 3
Training loss: 1.8703680038452148
Validation loss: 2.116961932951404

Epoch: 6| Step: 4
Training loss: 1.6222256422042847
Validation loss: 2.1360108288385535

Epoch: 6| Step: 5
Training loss: 1.3360244035720825
Validation loss: 2.1427675036973852

Epoch: 6| Step: 6
Training loss: 2.52013897895813
Validation loss: 2.1484716233386787

Epoch: 6| Step: 7
Training loss: 2.84586501121521
Validation loss: 2.1508978310451714

Epoch: 6| Step: 8
Training loss: 1.7114506959915161
Validation loss: 2.139816907144362

Epoch: 6| Step: 9
Training loss: 2.031430721282959
Validation loss: 2.132907090648528

Epoch: 6| Step: 10
Training loss: 2.1019067764282227
Validation loss: 2.1370043049576464

Epoch: 6| Step: 11
Training loss: 1.961618185043335
Validation loss: 2.1371150965331704

Epoch: 6| Step: 12
Training loss: 2.600907564163208
Validation loss: 2.119647733626827

Epoch: 6| Step: 13
Training loss: 1.3329569101333618
Validation loss: 2.130191731196578

Epoch: 191| Step: 0
Training loss: 2.0055606365203857
Validation loss: 2.1154334083680184

Epoch: 6| Step: 1
Training loss: 2.4535105228424072
Validation loss: 2.128395918876894

Epoch: 6| Step: 2
Training loss: 2.0467963218688965
Validation loss: 2.1257619627060427

Epoch: 6| Step: 3
Training loss: 1.9517886638641357
Validation loss: 2.1240385347797024

Epoch: 6| Step: 4
Training loss: 2.834792137145996
Validation loss: 2.1175023407064457

Epoch: 6| Step: 5
Training loss: 2.5240318775177
Validation loss: 2.1107622231206586

Epoch: 6| Step: 6
Training loss: 2.0180625915527344
Validation loss: 2.1187071928413967

Epoch: 6| Step: 7
Training loss: 1.881211519241333
Validation loss: 2.128028727346851

Epoch: 6| Step: 8
Training loss: 1.6861720085144043
Validation loss: 2.1217607144386537

Epoch: 6| Step: 9
Training loss: 1.4697299003601074
Validation loss: 2.1323963019155685

Epoch: 6| Step: 10
Training loss: 1.6040654182434082
Validation loss: 2.1317846826327744

Epoch: 6| Step: 11
Training loss: 2.7327537536621094
Validation loss: 2.1163824296766713

Epoch: 6| Step: 12
Training loss: 2.2132863998413086
Validation loss: 2.103231886381744

Epoch: 6| Step: 13
Training loss: 1.6015639305114746
Validation loss: 2.0809377752324587

Epoch: 192| Step: 0
Training loss: 1.7952381372451782
Validation loss: 2.074552705211024

Epoch: 6| Step: 1
Training loss: 1.8765093088150024
Validation loss: 2.079722196825089

Epoch: 6| Step: 2
Training loss: 1.8390916585922241
Validation loss: 2.087377007289599

Epoch: 6| Step: 3
Training loss: 2.0467684268951416
Validation loss: 2.088030328032791

Epoch: 6| Step: 4
Training loss: 1.9230163097381592
Validation loss: 2.110744369927273

Epoch: 6| Step: 5
Training loss: 1.8576319217681885
Validation loss: 2.113876022318358

Epoch: 6| Step: 6
Training loss: 2.6162445545196533
Validation loss: 2.1414474030976653

Epoch: 6| Step: 7
Training loss: 1.7505582571029663
Validation loss: 2.165260761014877

Epoch: 6| Step: 8
Training loss: 2.0472538471221924
Validation loss: 2.186514095593524

Epoch: 6| Step: 9
Training loss: 1.5346693992614746
Validation loss: 2.187391145254976

Epoch: 6| Step: 10
Training loss: 2.2141761779785156
Validation loss: 2.174063040364173

Epoch: 6| Step: 11
Training loss: 2.624295949935913
Validation loss: 2.1845116999841507

Epoch: 6| Step: 12
Training loss: 2.452627182006836
Validation loss: 2.1813837302628385

Epoch: 6| Step: 13
Training loss: 3.243804931640625
Validation loss: 2.168701310311594

Epoch: 193| Step: 0
Training loss: 2.2000248432159424
Validation loss: 2.178875102791735

Epoch: 6| Step: 1
Training loss: 1.9066535234451294
Validation loss: 2.1535770098368325

Epoch: 6| Step: 2
Training loss: 2.2538938522338867
Validation loss: 2.1335950333585023

Epoch: 6| Step: 3
Training loss: 2.218761444091797
Validation loss: 2.12753023639802

Epoch: 6| Step: 4
Training loss: 2.6408848762512207
Validation loss: 2.094033666836318

Epoch: 6| Step: 5
Training loss: 1.742798924446106
Validation loss: 2.0844847207428305

Epoch: 6| Step: 6
Training loss: 2.933746814727783
Validation loss: 2.0896457510609783

Epoch: 6| Step: 7
Training loss: 1.8579213619232178
Validation loss: 2.085910636891601

Epoch: 6| Step: 8
Training loss: 1.5541455745697021
Validation loss: 2.0869809876206102

Epoch: 6| Step: 9
Training loss: 1.9342772960662842
Validation loss: 2.092046845343805

Epoch: 6| Step: 10
Training loss: 1.7714285850524902
Validation loss: 2.0930684612643335

Epoch: 6| Step: 11
Training loss: 1.6861015558242798
Validation loss: 2.11516619882276

Epoch: 6| Step: 12
Training loss: 1.8307936191558838
Validation loss: 2.125531009448472

Epoch: 6| Step: 13
Training loss: 2.9988508224487305
Validation loss: 2.1281978686650596

Epoch: 194| Step: 0
Training loss: 2.248518466949463
Validation loss: 2.1193053055835027

Epoch: 6| Step: 1
Training loss: 1.9404064416885376
Validation loss: 2.115293200298022

Epoch: 6| Step: 2
Training loss: 1.560218095779419
Validation loss: 2.1122080972117763

Epoch: 6| Step: 3
Training loss: 1.6220526695251465
Validation loss: 2.110384838555449

Epoch: 6| Step: 4
Training loss: 2.388566017150879
Validation loss: 2.114489152867307

Epoch: 6| Step: 5
Training loss: 1.3221768140792847
Validation loss: 2.1176848155195995

Epoch: 6| Step: 6
Training loss: 2.328204393386841
Validation loss: 2.127529723669893

Epoch: 6| Step: 7
Training loss: 2.3767480850219727
Validation loss: 2.1212897736539125

Epoch: 6| Step: 8
Training loss: 2.9557337760925293
Validation loss: 2.1189088936774962

Epoch: 6| Step: 9
Training loss: 1.8675048351287842
Validation loss: 2.113657195080993

Epoch: 6| Step: 10
Training loss: 2.140343189239502
Validation loss: 2.109652844808435

Epoch: 6| Step: 11
Training loss: 2.06396484375
Validation loss: 2.0947272034101587

Epoch: 6| Step: 12
Training loss: 1.9011117219924927
Validation loss: 2.092181659513904

Epoch: 6| Step: 13
Training loss: 2.3436975479125977
Validation loss: 2.0812551654795164

Epoch: 195| Step: 0
Training loss: 2.257249116897583
Validation loss: 2.0730685085378666

Epoch: 6| Step: 1
Training loss: 2.25738787651062
Validation loss: 2.0784665846055552

Epoch: 6| Step: 2
Training loss: 1.820814609527588
Validation loss: 2.0828939407102522

Epoch: 6| Step: 3
Training loss: 2.182638168334961
Validation loss: 2.080105553391159

Epoch: 6| Step: 4
Training loss: 2.704472541809082
Validation loss: 2.087376271524737

Epoch: 6| Step: 5
Training loss: 2.136406183242798
Validation loss: 2.106551399794958

Epoch: 6| Step: 6
Training loss: 2.460022449493408
Validation loss: 2.1028477504689205

Epoch: 6| Step: 7
Training loss: 1.579388976097107
Validation loss: 2.1109986817964943

Epoch: 6| Step: 8
Training loss: 1.5627527236938477
Validation loss: 2.1150287376937045

Epoch: 6| Step: 9
Training loss: 2.4444918632507324
Validation loss: 2.1191255341293993

Epoch: 6| Step: 10
Training loss: 1.6137335300445557
Validation loss: 2.131011527071717

Epoch: 6| Step: 11
Training loss: 1.6745202541351318
Validation loss: 2.1167017259905414

Epoch: 6| Step: 12
Training loss: 2.446603536605835
Validation loss: 2.1203407446543374

Epoch: 6| Step: 13
Training loss: 1.3849784135818481
Validation loss: 2.1048002178950975

Epoch: 196| Step: 0
Training loss: 1.6584124565124512
Validation loss: 2.0944718878756285

Epoch: 6| Step: 1
Training loss: 2.4429869651794434
Validation loss: 2.087781743336749

Epoch: 6| Step: 2
Training loss: 2.1382858753204346
Validation loss: 2.0859523639884046

Epoch: 6| Step: 3
Training loss: 2.029080867767334
Validation loss: 2.0725492969635995

Epoch: 6| Step: 4
Training loss: 2.252662181854248
Validation loss: 2.065742866967314

Epoch: 6| Step: 5
Training loss: 2.1589503288269043
Validation loss: 2.0617206276104016

Epoch: 6| Step: 6
Training loss: 2.1665313243865967
Validation loss: 2.0565791604339436

Epoch: 6| Step: 7
Training loss: 2.4848954677581787
Validation loss: 2.0646259784698486

Epoch: 6| Step: 8
Training loss: 2.307882070541382
Validation loss: 2.076141772731658

Epoch: 6| Step: 9
Training loss: 1.7469685077667236
Validation loss: 2.076669011064755

Epoch: 6| Step: 10
Training loss: 2.0285937786102295
Validation loss: 2.082620051599318

Epoch: 6| Step: 11
Training loss: 1.9438468217849731
Validation loss: 2.090719852396237

Epoch: 6| Step: 12
Training loss: 1.5751209259033203
Validation loss: 2.0933786515266664

Epoch: 6| Step: 13
Training loss: 1.6704336404800415
Validation loss: 2.0840235756289576

Epoch: 197| Step: 0
Training loss: 2.355790138244629
Validation loss: 2.0918228318614345

Epoch: 6| Step: 1
Training loss: 1.8947045803070068
Validation loss: 2.093652102255052

Epoch: 6| Step: 2
Training loss: 1.818986415863037
Validation loss: 2.0890204957736436

Epoch: 6| Step: 3
Training loss: 1.659711241722107
Validation loss: 2.11074750397795

Epoch: 6| Step: 4
Training loss: 2.3150954246520996
Validation loss: 2.117579476807707

Epoch: 6| Step: 5
Training loss: 2.629744052886963
Validation loss: 2.1103138205825642

Epoch: 6| Step: 6
Training loss: 1.9049279689788818
Validation loss: 2.1053399501308316

Epoch: 6| Step: 7
Training loss: 1.3893258571624756
Validation loss: 2.1312183949255172

Epoch: 6| Step: 8
Training loss: 2.3778905868530273
Validation loss: 2.1519813486324844

Epoch: 6| Step: 9
Training loss: 2.049302816390991
Validation loss: 2.1325372777959353

Epoch: 6| Step: 10
Training loss: 2.085322380065918
Validation loss: 2.170491494158263

Epoch: 6| Step: 11
Training loss: 1.7084585428237915
Validation loss: 2.1471691336683048

Epoch: 6| Step: 12
Training loss: 2.253798484802246
Validation loss: 2.1445284658862698

Epoch: 6| Step: 13
Training loss: 2.013896942138672
Validation loss: 2.13377054532369

Epoch: 198| Step: 0
Training loss: 1.9701701402664185
Validation loss: 2.12658667308028

Epoch: 6| Step: 1
Training loss: 2.1479761600494385
Validation loss: 2.128911873345734

Epoch: 6| Step: 2
Training loss: 2.2107093334198
Validation loss: 2.107565990058325

Epoch: 6| Step: 3
Training loss: 2.094376802444458
Validation loss: 2.101124148215017

Epoch: 6| Step: 4
Training loss: 2.8472328186035156
Validation loss: 2.113106078999017

Epoch: 6| Step: 5
Training loss: 1.9827287197113037
Validation loss: 2.0860804960291874

Epoch: 6| Step: 6
Training loss: 2.5528371334075928
Validation loss: 2.06821979630378

Epoch: 6| Step: 7
Training loss: 2.120370864868164
Validation loss: 2.06419450236905

Epoch: 6| Step: 8
Training loss: 1.8712204694747925
Validation loss: 2.0724461540099113

Epoch: 6| Step: 9
Training loss: 1.0658197402954102
Validation loss: 2.0819609498464935

Epoch: 6| Step: 10
Training loss: 2.243161916732788
Validation loss: 2.10214949423267

Epoch: 6| Step: 11
Training loss: 1.7427325248718262
Validation loss: 2.1011296446605394

Epoch: 6| Step: 12
Training loss: 1.6507620811462402
Validation loss: 2.1054906601546914

Epoch: 6| Step: 13
Training loss: 1.781431794166565
Validation loss: 2.113439654791227

Epoch: 199| Step: 0
Training loss: 1.8459746837615967
Validation loss: 2.1332133854589155

Epoch: 6| Step: 1
Training loss: 2.0239715576171875
Validation loss: 2.1361774782980643

Epoch: 6| Step: 2
Training loss: 1.8535938262939453
Validation loss: 2.168447821371017

Epoch: 6| Step: 3
Training loss: 2.2212538719177246
Validation loss: 2.1707724281536636

Epoch: 6| Step: 4
Training loss: 1.5623753070831299
Validation loss: 2.181330288610151

Epoch: 6| Step: 5
Training loss: 2.2840590476989746
Validation loss: 2.1465806294513006

Epoch: 6| Step: 6
Training loss: 1.714003562927246
Validation loss: 2.13958849189102

Epoch: 6| Step: 7
Training loss: 2.3328909873962402
Validation loss: 2.121733555229761

Epoch: 6| Step: 8
Training loss: 2.293503761291504
Validation loss: 2.1323258235890377

Epoch: 6| Step: 9
Training loss: 2.403233051300049
Validation loss: 2.1358315252488658

Epoch: 6| Step: 10
Training loss: 1.8861010074615479
Validation loss: 2.120131097814088

Epoch: 6| Step: 11
Training loss: 2.4290695190429688
Validation loss: 2.099506449955766

Epoch: 6| Step: 12
Training loss: 1.7923554182052612
Validation loss: 2.0823377422107163

Epoch: 6| Step: 13
Training loss: 1.9229791164398193
Validation loss: 2.085819782749299

Epoch: 200| Step: 0
Training loss: 2.390775203704834
Validation loss: 2.0847816005829842

Epoch: 6| Step: 1
Training loss: 1.932190179824829
Validation loss: 2.087072462163946

Epoch: 6| Step: 2
Training loss: 2.146822214126587
Validation loss: 2.0949411892121836

Epoch: 6| Step: 3
Training loss: 1.5836193561553955
Validation loss: 2.0786461932684785

Epoch: 6| Step: 4
Training loss: 2.0177783966064453
Validation loss: 2.081251070063601

Epoch: 6| Step: 5
Training loss: 1.790565848350525
Validation loss: 2.084661176127772

Epoch: 6| Step: 6
Training loss: 2.5638132095336914
Validation loss: 2.087732389409055

Epoch: 6| Step: 7
Training loss: 2.8058066368103027
Validation loss: 2.08832190626411

Epoch: 6| Step: 8
Training loss: 1.7973599433898926
Validation loss: 2.091484505643127

Epoch: 6| Step: 9
Training loss: 1.415669322013855
Validation loss: 2.0867963760129866

Epoch: 6| Step: 10
Training loss: 2.315268039703369
Validation loss: 2.0888824821800314

Epoch: 6| Step: 11
Training loss: 1.668020486831665
Validation loss: 2.082072819432905

Epoch: 6| Step: 12
Training loss: 2.3777823448181152
Validation loss: 2.091687927963913

Epoch: 6| Step: 13
Training loss: 1.316047191619873
Validation loss: 2.0948751254748275

Epoch: 201| Step: 0
Training loss: 2.326446056365967
Validation loss: 2.0871677937046176

Epoch: 6| Step: 1
Training loss: 1.7215912342071533
Validation loss: 2.095004338090138

Epoch: 6| Step: 2
Training loss: 1.9158836603164673
Validation loss: 2.110218976133613

Epoch: 6| Step: 3
Training loss: 1.7481709718704224
Validation loss: 2.1207150566962456

Epoch: 6| Step: 4
Training loss: 1.581701397895813
Validation loss: 2.117155126346055

Epoch: 6| Step: 5
Training loss: 2.7199888229370117
Validation loss: 2.1095899689582085

Epoch: 6| Step: 6
Training loss: 1.968554973602295
Validation loss: 2.099743661060128

Epoch: 6| Step: 7
Training loss: 1.8736706972122192
Validation loss: 2.0826605942941483

Epoch: 6| Step: 8
Training loss: 2.156224489212036
Validation loss: 2.1000278047336045

Epoch: 6| Step: 9
Training loss: 2.4402942657470703
Validation loss: 2.114864019937413

Epoch: 6| Step: 10
Training loss: 1.6493449211120605
Validation loss: 2.11421799659729

Epoch: 6| Step: 11
Training loss: 1.3820819854736328
Validation loss: 2.1055083941387873

Epoch: 6| Step: 12
Training loss: 2.4552695751190186
Validation loss: 2.098988416374371

Epoch: 6| Step: 13
Training loss: 2.985558032989502
Validation loss: 2.096276471691747

Epoch: 202| Step: 0
Training loss: 2.2538046836853027
Validation loss: 2.0860974929666005

Epoch: 6| Step: 1
Training loss: 1.8922972679138184
Validation loss: 2.0863843579446115

Epoch: 6| Step: 2
Training loss: 2.125610828399658
Validation loss: 2.0780488624367663

Epoch: 6| Step: 3
Training loss: 2.77302622795105
Validation loss: 2.076526258581428

Epoch: 6| Step: 4
Training loss: 1.7341257333755493
Validation loss: 2.083673566900274

Epoch: 6| Step: 5
Training loss: 1.7579755783081055
Validation loss: 2.0699382033399356

Epoch: 6| Step: 6
Training loss: 1.6044647693634033
Validation loss: 2.056951258772163

Epoch: 6| Step: 7
Training loss: 2.0903968811035156
Validation loss: 2.0720538477743826

Epoch: 6| Step: 8
Training loss: 1.9726191759109497
Validation loss: 2.0936453829529467

Epoch: 6| Step: 9
Training loss: 1.5201497077941895
Validation loss: 2.099335781989559

Epoch: 6| Step: 10
Training loss: 2.6927061080932617
Validation loss: 2.093148757052678

Epoch: 6| Step: 11
Training loss: 2.3721156120300293
Validation loss: 2.077350333172788

Epoch: 6| Step: 12
Training loss: 1.9716322422027588
Validation loss: 2.0692465459146807

Epoch: 6| Step: 13
Training loss: 1.3820960521697998
Validation loss: 2.0791417450033207

Epoch: 203| Step: 0
Training loss: 1.3446199893951416
Validation loss: 2.103552068433454

Epoch: 6| Step: 1
Training loss: 2.201618194580078
Validation loss: 2.1634717218337522

Epoch: 6| Step: 2
Training loss: 2.068603515625
Validation loss: 2.206125577290853

Epoch: 6| Step: 3
Training loss: 2.4680004119873047
Validation loss: 2.2305690473125828

Epoch: 6| Step: 4
Training loss: 2.28656005859375
Validation loss: 2.1950820056341027

Epoch: 6| Step: 5
Training loss: 2.4921915531158447
Validation loss: 2.171380648048975

Epoch: 6| Step: 6
Training loss: 2.792259931564331
Validation loss: 2.142878834919263

Epoch: 6| Step: 7
Training loss: 1.6615278720855713
Validation loss: 2.0947868849641536

Epoch: 6| Step: 8
Training loss: 1.3298671245574951
Validation loss: 2.0845867408219205

Epoch: 6| Step: 9
Training loss: 2.447852373123169
Validation loss: 2.094740729178152

Epoch: 6| Step: 10
Training loss: 1.9004085063934326
Validation loss: 2.070264653492999

Epoch: 6| Step: 11
Training loss: 2.282916784286499
Validation loss: 2.059133732190696

Epoch: 6| Step: 12
Training loss: 2.101094961166382
Validation loss: 2.0680976708730063

Epoch: 6| Step: 13
Training loss: 1.395080327987671
Validation loss: 2.0770758685245307

Epoch: 204| Step: 0
Training loss: 2.4520998001098633
Validation loss: 2.0911651401109594

Epoch: 6| Step: 1
Training loss: 1.8256231546401978
Validation loss: 2.086112162118317

Epoch: 6| Step: 2
Training loss: 2.394993305206299
Validation loss: 2.091911618427564

Epoch: 6| Step: 3
Training loss: 1.649743914604187
Validation loss: 2.0926740118252334

Epoch: 6| Step: 4
Training loss: 2.020024061203003
Validation loss: 2.0990050838839625

Epoch: 6| Step: 5
Training loss: 2.393536329269409
Validation loss: 2.1035864045543056

Epoch: 6| Step: 6
Training loss: 1.308419108390808
Validation loss: 2.0853933326659666

Epoch: 6| Step: 7
Training loss: 1.6785621643066406
Validation loss: 2.0736433024047525

Epoch: 6| Step: 8
Training loss: 1.8913779258728027
Validation loss: 2.080355760871723

Epoch: 6| Step: 9
Training loss: 2.0051658153533936
Validation loss: 2.089003680854715

Epoch: 6| Step: 10
Training loss: 2.473662853240967
Validation loss: 2.1100892994993474

Epoch: 6| Step: 11
Training loss: 2.468977212905884
Validation loss: 2.1371571915124052

Epoch: 6| Step: 12
Training loss: 1.6834796667099
Validation loss: 2.10432505607605

Epoch: 6| Step: 13
Training loss: 1.8958691358566284
Validation loss: 2.098076133317845

Epoch: 205| Step: 0
Training loss: 1.7523794174194336
Validation loss: 2.107158035360357

Epoch: 6| Step: 1
Training loss: 1.679196834564209
Validation loss: 2.0987034536177114

Epoch: 6| Step: 2
Training loss: 2.4070324897766113
Validation loss: 2.0926837023868354

Epoch: 6| Step: 3
Training loss: 2.4844138622283936
Validation loss: 2.0906704907776206

Epoch: 6| Step: 4
Training loss: 1.5824041366577148
Validation loss: 2.099201302374563

Epoch: 6| Step: 5
Training loss: 1.7675204277038574
Validation loss: 2.1092008762462164

Epoch: 6| Step: 6
Training loss: 2.1236751079559326
Validation loss: 2.109734376271566

Epoch: 6| Step: 7
Training loss: 1.9368339776992798
Validation loss: 2.1250944214482463

Epoch: 6| Step: 8
Training loss: 2.4746696949005127
Validation loss: 2.1108898398696736

Epoch: 6| Step: 9
Training loss: 1.8981869220733643
Validation loss: 2.0873096963410736

Epoch: 6| Step: 10
Training loss: 1.914870023727417
Validation loss: 2.066362216908445

Epoch: 6| Step: 11
Training loss: 1.3902466297149658
Validation loss: 2.065319764998651

Epoch: 6| Step: 12
Training loss: 2.6643595695495605
Validation loss: 2.0762277162203224

Epoch: 6| Step: 13
Training loss: 2.0802557468414307
Validation loss: 2.073381680314259

Epoch: 206| Step: 0
Training loss: 1.2908838987350464
Validation loss: 2.078274393594393

Epoch: 6| Step: 1
Training loss: 2.004798412322998
Validation loss: 2.0787889983064387

Epoch: 6| Step: 2
Training loss: 1.8518223762512207
Validation loss: 2.095091219871275

Epoch: 6| Step: 3
Training loss: 1.8566421270370483
Validation loss: 2.0861988349627425

Epoch: 6| Step: 4
Training loss: 1.9525047540664673
Validation loss: 2.0960512238164104

Epoch: 6| Step: 5
Training loss: 1.8177449703216553
Validation loss: 2.0806372216952744

Epoch: 6| Step: 6
Training loss: 2.3082590103149414
Validation loss: 2.075932700146911

Epoch: 6| Step: 7
Training loss: 2.4742956161499023
Validation loss: 2.081488028649361

Epoch: 6| Step: 8
Training loss: 1.943777322769165
Validation loss: 2.072323629933019

Epoch: 6| Step: 9
Training loss: 2.2134690284729004
Validation loss: 2.094559787422098

Epoch: 6| Step: 10
Training loss: 2.717360258102417
Validation loss: 2.086181422715546

Epoch: 6| Step: 11
Training loss: 2.083413600921631
Validation loss: 2.1028594150338122

Epoch: 6| Step: 12
Training loss: 1.6026029586791992
Validation loss: 2.1094531205392655

Epoch: 6| Step: 13
Training loss: 1.895965814590454
Validation loss: 2.120149753426993

Epoch: 207| Step: 0
Training loss: 2.486751079559326
Validation loss: 2.119592353861819

Epoch: 6| Step: 1
Training loss: 1.6283634901046753
Validation loss: 2.115377213365288

Epoch: 6| Step: 2
Training loss: 1.6044864654541016
Validation loss: 2.0992813930716565

Epoch: 6| Step: 3
Training loss: 1.6507301330566406
Validation loss: 2.0870347381919943

Epoch: 6| Step: 4
Training loss: 1.8965644836425781
Validation loss: 2.083470893162553

Epoch: 6| Step: 5
Training loss: 2.4157814979553223
Validation loss: 2.0898001642637354

Epoch: 6| Step: 6
Training loss: 1.965986728668213
Validation loss: 2.075652104552074

Epoch: 6| Step: 7
Training loss: 2.2879157066345215
Validation loss: 2.0821054545781945

Epoch: 6| Step: 8
Training loss: 2.153651714324951
Validation loss: 2.0791022187920025

Epoch: 6| Step: 9
Training loss: 1.9403283596038818
Validation loss: 2.079606702250819

Epoch: 6| Step: 10
Training loss: 1.7042009830474854
Validation loss: 2.0744743731714066

Epoch: 6| Step: 11
Training loss: 1.8519580364227295
Validation loss: 2.0746438990357103

Epoch: 6| Step: 12
Training loss: 2.3242990970611572
Validation loss: 2.0856097205992667

Epoch: 6| Step: 13
Training loss: 1.9749764204025269
Validation loss: 2.0668614577221613

Epoch: 208| Step: 0
Training loss: 1.2604751586914062
Validation loss: 2.0883950700042067

Epoch: 6| Step: 1
Training loss: 1.4889183044433594
Validation loss: 2.0716800535878828

Epoch: 6| Step: 2
Training loss: 1.879515528678894
Validation loss: 2.076532430546258

Epoch: 6| Step: 3
Training loss: 2.023658275604248
Validation loss: 2.106618679979796

Epoch: 6| Step: 4
Training loss: 1.9715352058410645
Validation loss: 2.098510152550154

Epoch: 6| Step: 5
Training loss: 2.3326025009155273
Validation loss: 2.1177475683150755

Epoch: 6| Step: 6
Training loss: 1.658042311668396
Validation loss: 2.1138828851843394

Epoch: 6| Step: 7
Training loss: 2.08506178855896
Validation loss: 2.127243741866081

Epoch: 6| Step: 8
Training loss: 2.5763344764709473
Validation loss: 2.1404717199264036

Epoch: 6| Step: 9
Training loss: 2.3230655193328857
Validation loss: 2.153317064367315

Epoch: 6| Step: 10
Training loss: 1.5292762517929077
Validation loss: 2.164434584238196

Epoch: 6| Step: 11
Training loss: 2.178864002227783
Validation loss: 2.1793199021329164

Epoch: 6| Step: 12
Training loss: 2.4631876945495605
Validation loss: 2.1577935141901814

Epoch: 6| Step: 13
Training loss: 2.5806658267974854
Validation loss: 2.1095854864325574

Epoch: 209| Step: 0
Training loss: 1.699920892715454
Validation loss: 2.0918174943616314

Epoch: 6| Step: 1
Training loss: 2.2761077880859375
Validation loss: 2.0422397159760997

Epoch: 6| Step: 2
Training loss: 2.2723422050476074
Validation loss: 2.0347920951022895

Epoch: 6| Step: 3
Training loss: 2.4186511039733887
Validation loss: 2.038123728126608

Epoch: 6| Step: 4
Training loss: 2.4805846214294434
Validation loss: 2.03870887653802

Epoch: 6| Step: 5
Training loss: 1.7703044414520264
Validation loss: 2.0579012875915854

Epoch: 6| Step: 6
Training loss: 2.0933589935302734
Validation loss: 2.074873349999869

Epoch: 6| Step: 7
Training loss: 2.0585145950317383
Validation loss: 2.0899329403395295

Epoch: 6| Step: 8
Training loss: 2.212944984436035
Validation loss: 2.086116301116123

Epoch: 6| Step: 9
Training loss: 1.5671367645263672
Validation loss: 2.086101755019157

Epoch: 6| Step: 10
Training loss: 1.87173593044281
Validation loss: 2.055583346274591

Epoch: 6| Step: 11
Training loss: 1.746795892715454
Validation loss: 2.0571904195252286

Epoch: 6| Step: 12
Training loss: 1.8220994472503662
Validation loss: 2.0753413887434107

Epoch: 6| Step: 13
Training loss: 2.2026655673980713
Validation loss: 2.0897715501887824

Epoch: 210| Step: 0
Training loss: 2.096900224685669
Validation loss: 2.1269593469558226

Epoch: 6| Step: 1
Training loss: 2.3318073749542236
Validation loss: 2.1034950415293374

Epoch: 6| Step: 2
Training loss: 2.0479345321655273
Validation loss: 2.0914745638447423

Epoch: 6| Step: 3
Training loss: 1.9333198070526123
Validation loss: 2.076169499786951

Epoch: 6| Step: 4
Training loss: 1.664275884628296
Validation loss: 2.035719980475723

Epoch: 6| Step: 5
Training loss: 2.442807197570801
Validation loss: 2.026189011912192

Epoch: 6| Step: 6
Training loss: 1.5508136749267578
Validation loss: 2.035997559947352

Epoch: 6| Step: 7
Training loss: 1.297652006149292
Validation loss: 2.0572798059832667

Epoch: 6| Step: 8
Training loss: 1.5230752229690552
Validation loss: 2.0622227935380835

Epoch: 6| Step: 9
Training loss: 2.0243048667907715
Validation loss: 2.050581532139932

Epoch: 6| Step: 10
Training loss: 2.2696542739868164
Validation loss: 2.07211196678941

Epoch: 6| Step: 11
Training loss: 2.2461130619049072
Validation loss: 2.068862081855856

Epoch: 6| Step: 12
Training loss: 2.376046657562256
Validation loss: 2.099442094884893

Epoch: 6| Step: 13
Training loss: 2.2913436889648438
Validation loss: 2.123994060741958

Epoch: 211| Step: 0
Training loss: 1.5929803848266602
Validation loss: 2.1443981932055567

Epoch: 6| Step: 1
Training loss: 2.0090343952178955
Validation loss: 2.138448207609115

Epoch: 6| Step: 2
Training loss: 1.3441072702407837
Validation loss: 2.1574855542952016

Epoch: 6| Step: 3
Training loss: 1.926807165145874
Validation loss: 2.1437817260783207

Epoch: 6| Step: 4
Training loss: 1.9313856363296509
Validation loss: 2.1328265769507295

Epoch: 6| Step: 5
Training loss: 1.5881198644638062
Validation loss: 2.131786787381736

Epoch: 6| Step: 6
Training loss: 2.6524462699890137
Validation loss: 2.128667252038115

Epoch: 6| Step: 7
Training loss: 1.9635779857635498
Validation loss: 2.115110861357822

Epoch: 6| Step: 8
Training loss: 2.5940351486206055
Validation loss: 2.106272984576482

Epoch: 6| Step: 9
Training loss: 1.5834226608276367
Validation loss: 2.0860743125279746

Epoch: 6| Step: 10
Training loss: 2.2207400798797607
Validation loss: 2.0712159679782007

Epoch: 6| Step: 11
Training loss: 2.1857433319091797
Validation loss: 2.057612721638013

Epoch: 6| Step: 12
Training loss: 2.0897817611694336
Validation loss: 2.0417584116740892

Epoch: 6| Step: 13
Training loss: 1.9554495811462402
Validation loss: 2.0342084438570085

Epoch: 212| Step: 0
Training loss: 2.515026330947876
Validation loss: 2.0165340515875045

Epoch: 6| Step: 1
Training loss: 1.945469617843628
Validation loss: 2.0191700791799896

Epoch: 6| Step: 2
Training loss: 2.3987112045288086
Validation loss: 2.015919434126987

Epoch: 6| Step: 3
Training loss: 2.081582546234131
Validation loss: 2.009563728045392

Epoch: 6| Step: 4
Training loss: 2.161668300628662
Validation loss: 2.027355594019736

Epoch: 6| Step: 5
Training loss: 1.5703964233398438
Validation loss: 2.034661953167249

Epoch: 6| Step: 6
Training loss: 1.9314013719558716
Validation loss: 2.0472862848671536

Epoch: 6| Step: 7
Training loss: 2.1564407348632812
Validation loss: 2.054688552374481

Epoch: 6| Step: 8
Training loss: 1.59067702293396
Validation loss: 2.054642378642995

Epoch: 6| Step: 9
Training loss: 2.045828342437744
Validation loss: 2.0834988150545346

Epoch: 6| Step: 10
Training loss: 1.4901541471481323
Validation loss: 2.0827518868189987

Epoch: 6| Step: 11
Training loss: 1.374319314956665
Validation loss: 2.1019058509539534

Epoch: 6| Step: 12
Training loss: 1.516284704208374
Validation loss: 2.1054328897947907

Epoch: 6| Step: 13
Training loss: 3.4248783588409424
Validation loss: 2.1052193231480096

Epoch: 213| Step: 0
Training loss: 2.085569381713867
Validation loss: 2.1006126890900316

Epoch: 6| Step: 1
Training loss: 1.8264738321304321
Validation loss: 2.1171477866429154

Epoch: 6| Step: 2
Training loss: 2.1264305114746094
Validation loss: 2.1121852039009013

Epoch: 6| Step: 3
Training loss: 2.116300582885742
Validation loss: 2.068751863254014

Epoch: 6| Step: 4
Training loss: 1.7962419986724854
Validation loss: 2.0645328913965533

Epoch: 6| Step: 5
Training loss: 1.937497615814209
Validation loss: 2.0673662898361043

Epoch: 6| Step: 6
Training loss: 2.3244729042053223
Validation loss: 2.0728653246356594

Epoch: 6| Step: 7
Training loss: 2.0776824951171875
Validation loss: 2.080387828170612

Epoch: 6| Step: 8
Training loss: 2.7626781463623047
Validation loss: 2.0632311246728383

Epoch: 6| Step: 9
Training loss: 1.7120368480682373
Validation loss: 2.0460212897228938

Epoch: 6| Step: 10
Training loss: 2.4436960220336914
Validation loss: 2.030526996940695

Epoch: 6| Step: 11
Training loss: 1.9393625259399414
Validation loss: 2.0301075584145

Epoch: 6| Step: 12
Training loss: 1.0206772089004517
Validation loss: 2.0384150922939344

Epoch: 6| Step: 13
Training loss: 1.156265139579773
Validation loss: 2.0409677413202103

Epoch: 214| Step: 0
Training loss: 1.6517497301101685
Validation loss: 2.084882620842226

Epoch: 6| Step: 1
Training loss: 1.4786535501480103
Validation loss: 2.1087154470464236

Epoch: 6| Step: 2
Training loss: 2.2949540615081787
Validation loss: 2.1115594397309008

Epoch: 6| Step: 3
Training loss: 1.7866265773773193
Validation loss: 2.1085451456808273

Epoch: 6| Step: 4
Training loss: 1.9362059831619263
Validation loss: 2.101794009567589

Epoch: 6| Step: 5
Training loss: 2.084625244140625
Validation loss: 2.101920061213996

Epoch: 6| Step: 6
Training loss: 1.9746938943862915
Validation loss: 2.077355986000389

Epoch: 6| Step: 7
Training loss: 1.730116844177246
Validation loss: 2.083420202296267

Epoch: 6| Step: 8
Training loss: 2.3847734928131104
Validation loss: 2.0913115983368247

Epoch: 6| Step: 9
Training loss: 2.4501290321350098
Validation loss: 2.0897510333727767

Epoch: 6| Step: 10
Training loss: 1.3461484909057617
Validation loss: 2.119364292390885

Epoch: 6| Step: 11
Training loss: 1.9774184226989746
Validation loss: 2.1171301000861713

Epoch: 6| Step: 12
Training loss: 2.234663248062134
Validation loss: 2.083749960827571

Epoch: 6| Step: 13
Training loss: 2.43526554107666
Validation loss: 2.1011093329357844

Epoch: 215| Step: 0
Training loss: 2.696125030517578
Validation loss: 2.090706950874739

Epoch: 6| Step: 1
Training loss: 1.9569430351257324
Validation loss: 2.1042492671679427

Epoch: 6| Step: 2
Training loss: 1.7894020080566406
Validation loss: 2.1103493821236396

Epoch: 6| Step: 3
Training loss: 2.0967583656311035
Validation loss: 2.0893296887797694

Epoch: 6| Step: 4
Training loss: 2.220522880554199
Validation loss: 2.080631508622118

Epoch: 6| Step: 5
Training loss: 2.6516618728637695
Validation loss: 2.063560164102944

Epoch: 6| Step: 6
Training loss: 1.7414100170135498
Validation loss: 2.0495561220312632

Epoch: 6| Step: 7
Training loss: 1.5688587427139282
Validation loss: 2.0242634896309144

Epoch: 6| Step: 8
Training loss: 1.3665369749069214
Validation loss: 2.0230195650490383

Epoch: 6| Step: 9
Training loss: 1.5209786891937256
Validation loss: 2.0356085249172744

Epoch: 6| Step: 10
Training loss: 2.183492660522461
Validation loss: 2.039674312837662

Epoch: 6| Step: 11
Training loss: 2.443563222885132
Validation loss: 2.0398649669462636

Epoch: 6| Step: 12
Training loss: 1.2659941911697388
Validation loss: 2.0444326990394184

Epoch: 6| Step: 13
Training loss: 2.0381994247436523
Validation loss: 2.0512299845295567

Epoch: 216| Step: 0
Training loss: 1.7207003831863403
Validation loss: 2.033042884642078

Epoch: 6| Step: 1
Training loss: 2.450369358062744
Validation loss: 2.066632402840481

Epoch: 6| Step: 2
Training loss: 1.9927234649658203
Validation loss: 2.0745903676556003

Epoch: 6| Step: 3
Training loss: 1.42082941532135
Validation loss: 2.0633177641899354

Epoch: 6| Step: 4
Training loss: 1.8558485507965088
Validation loss: 2.0729127904420257

Epoch: 6| Step: 5
Training loss: 2.466836452484131
Validation loss: 2.080577012031309

Epoch: 6| Step: 6
Training loss: 2.3616080284118652
Validation loss: 2.0909389039521575

Epoch: 6| Step: 7
Training loss: 2.114025115966797
Validation loss: 2.10381664511978

Epoch: 6| Step: 8
Training loss: 0.970002293586731
Validation loss: 2.0924442737333235

Epoch: 6| Step: 9
Training loss: 1.7892482280731201
Validation loss: 2.0980571828862673

Epoch: 6| Step: 10
Training loss: 1.0006871223449707
Validation loss: 2.1010887430560206

Epoch: 6| Step: 11
Training loss: 2.9585952758789062
Validation loss: 2.101866352942682

Epoch: 6| Step: 12
Training loss: 2.0077037811279297
Validation loss: 2.1041667692122923

Epoch: 6| Step: 13
Training loss: 2.1488730907440186
Validation loss: 2.1032933112113708

Epoch: 217| Step: 0
Training loss: 1.7497024536132812
Validation loss: 2.1010769836364256

Epoch: 6| Step: 1
Training loss: 2.008340358734131
Validation loss: 2.0860340210699264

Epoch: 6| Step: 2
Training loss: 2.158957004547119
Validation loss: 2.0755976861523044

Epoch: 6| Step: 3
Training loss: 2.0181565284729004
Validation loss: 2.0597373080509964

Epoch: 6| Step: 4
Training loss: 1.9394521713256836
Validation loss: 2.038115116857713

Epoch: 6| Step: 5
Training loss: 1.8864914178848267
Validation loss: 2.0285237758390364

Epoch: 6| Step: 6
Training loss: 1.964362621307373
Validation loss: 2.0281847779468825

Epoch: 6| Step: 7
Training loss: 1.469114065170288
Validation loss: 2.0510454895675823

Epoch: 6| Step: 8
Training loss: 2.3712024688720703
Validation loss: 2.049292920738138

Epoch: 6| Step: 9
Training loss: 1.5443122386932373
Validation loss: 2.0821441975972985

Epoch: 6| Step: 10
Training loss: 2.206386089324951
Validation loss: 2.0859763340283464

Epoch: 6| Step: 11
Training loss: 2.1483919620513916
Validation loss: 2.084711282483993

Epoch: 6| Step: 12
Training loss: 1.8120794296264648
Validation loss: 2.0938182620592016

Epoch: 6| Step: 13
Training loss: 1.9006609916687012
Validation loss: 2.09851404928392

Epoch: 218| Step: 0
Training loss: 1.232107400894165
Validation loss: 2.118085659960265

Epoch: 6| Step: 1
Training loss: 1.8841649293899536
Validation loss: 2.1149689253940376

Epoch: 6| Step: 2
Training loss: 1.9121489524841309
Validation loss: 2.1104908040774766

Epoch: 6| Step: 3
Training loss: 1.9806842803955078
Validation loss: 2.100299567304632

Epoch: 6| Step: 4
Training loss: 2.2335939407348633
Validation loss: 2.0792601993007045

Epoch: 6| Step: 5
Training loss: 1.7534661293029785
Validation loss: 2.0595468372427006

Epoch: 6| Step: 6
Training loss: 1.5539519786834717
Validation loss: 2.070819398408295

Epoch: 6| Step: 7
Training loss: 1.9621198177337646
Validation loss: 2.0924556973159953

Epoch: 6| Step: 8
Training loss: 2.3975577354431152
Validation loss: 2.094090695022255

Epoch: 6| Step: 9
Training loss: 2.237034320831299
Validation loss: 2.0955526495492585

Epoch: 6| Step: 10
Training loss: 1.5785585641860962
Validation loss: 2.0874996390393985

Epoch: 6| Step: 11
Training loss: 2.578249931335449
Validation loss: 2.0842957240279003

Epoch: 6| Step: 12
Training loss: 2.600396156311035
Validation loss: 2.0917715487941617

Epoch: 6| Step: 13
Training loss: 1.2294936180114746
Validation loss: 2.0877345608126734

Epoch: 219| Step: 0
Training loss: 1.718227505683899
Validation loss: 2.0957542055396625

Epoch: 6| Step: 1
Training loss: 2.0139381885528564
Validation loss: 2.0951764968133744

Epoch: 6| Step: 2
Training loss: 2.291029691696167
Validation loss: 2.0927329217233965

Epoch: 6| Step: 3
Training loss: 1.4502263069152832
Validation loss: 2.0908131753244708

Epoch: 6| Step: 4
Training loss: 1.5800344944000244
Validation loss: 2.0754440420417377

Epoch: 6| Step: 5
Training loss: 2.1047780513763428
Validation loss: 2.05846115081541

Epoch: 6| Step: 6
Training loss: 1.734360933303833
Validation loss: 2.0538536361468736

Epoch: 6| Step: 7
Training loss: 1.661769151687622
Validation loss: 2.042747894922892

Epoch: 6| Step: 8
Training loss: 1.755689024925232
Validation loss: 2.0559540153831564

Epoch: 6| Step: 9
Training loss: 2.5161240100860596
Validation loss: 2.09078578154246

Epoch: 6| Step: 10
Training loss: 2.3431336879730225
Validation loss: 2.1117499105391966

Epoch: 6| Step: 11
Training loss: 2.108356475830078
Validation loss: 2.0928563994746052

Epoch: 6| Step: 12
Training loss: 2.0116705894470215
Validation loss: 2.07250149532031

Epoch: 6| Step: 13
Training loss: 2.4186508655548096
Validation loss: 2.0672792337274037

Epoch: 220| Step: 0
Training loss: 1.828560709953308
Validation loss: 2.060725914534702

Epoch: 6| Step: 1
Training loss: 1.527756690979004
Validation loss: 2.0760666016609437

Epoch: 6| Step: 2
Training loss: 2.2013368606567383
Validation loss: 2.094057127993594

Epoch: 6| Step: 3
Training loss: 1.8763867616653442
Validation loss: 2.074276094795555

Epoch: 6| Step: 4
Training loss: 1.788280725479126
Validation loss: 2.060592502676031

Epoch: 6| Step: 5
Training loss: 2.196718692779541
Validation loss: 2.0417618084979314

Epoch: 6| Step: 6
Training loss: 2.2229342460632324
Validation loss: 2.0517668031877085

Epoch: 6| Step: 7
Training loss: 1.9966001510620117
Validation loss: 2.0305915468482563

Epoch: 6| Step: 8
Training loss: 1.9010969400405884
Validation loss: 2.0260111362703386

Epoch: 6| Step: 9
Training loss: 1.562011480331421
Validation loss: 2.021405968614804

Epoch: 6| Step: 10
Training loss: 2.0314736366271973
Validation loss: 2.0217546288685133

Epoch: 6| Step: 11
Training loss: 2.3377320766448975
Validation loss: 2.0219023535328526

Epoch: 6| Step: 12
Training loss: 1.6890501976013184
Validation loss: 2.0266472652394283

Epoch: 6| Step: 13
Training loss: 2.590447187423706
Validation loss: 2.0295478515727545

Epoch: 221| Step: 0
Training loss: 1.5135164260864258
Validation loss: 2.0332029968179683

Epoch: 6| Step: 1
Training loss: 1.6130248308181763
Validation loss: 2.0300551165816603

Epoch: 6| Step: 2
Training loss: 1.194366693496704
Validation loss: 2.0165653459487425

Epoch: 6| Step: 3
Training loss: 1.5666694641113281
Validation loss: 2.0437116648561213

Epoch: 6| Step: 4
Training loss: 1.6986033916473389
Validation loss: 2.0536749286036335

Epoch: 6| Step: 5
Training loss: 2.791621446609497
Validation loss: 2.068873668229708

Epoch: 6| Step: 6
Training loss: 1.325190782546997
Validation loss: 2.08023065392689

Epoch: 6| Step: 7
Training loss: 1.8897840976715088
Validation loss: 2.068455893506286

Epoch: 6| Step: 8
Training loss: 1.8746269941329956
Validation loss: 2.0531171675651305

Epoch: 6| Step: 9
Training loss: 2.1183369159698486
Validation loss: 2.0462005945944015

Epoch: 6| Step: 10
Training loss: 2.207503080368042
Validation loss: 2.0367939190198014

Epoch: 6| Step: 11
Training loss: 2.3730483055114746
Validation loss: 2.04939938617009

Epoch: 6| Step: 12
Training loss: 2.391709327697754
Validation loss: 2.0396237552806897

Epoch: 6| Step: 13
Training loss: 2.9436328411102295
Validation loss: 2.035930984763689

Epoch: 222| Step: 0
Training loss: 2.053612232208252
Validation loss: 2.030294256825601

Epoch: 6| Step: 1
Training loss: 1.9355440139770508
Validation loss: 2.037985191550306

Epoch: 6| Step: 2
Training loss: 2.3791778087615967
Validation loss: 2.0409984742441485

Epoch: 6| Step: 3
Training loss: 0.9898152351379395
Validation loss: 2.047937058633374

Epoch: 6| Step: 4
Training loss: 1.75002121925354
Validation loss: 2.049702200838315

Epoch: 6| Step: 5
Training loss: 1.7441153526306152
Validation loss: 2.04996044148681

Epoch: 6| Step: 6
Training loss: 2.1802849769592285
Validation loss: 2.0533945054136296

Epoch: 6| Step: 7
Training loss: 1.954392671585083
Validation loss: 2.0444092776185725

Epoch: 6| Step: 8
Training loss: 1.8604528903961182
Validation loss: 2.0369068717443817

Epoch: 6| Step: 9
Training loss: 2.384338855743408
Validation loss: 2.0340898908594602

Epoch: 6| Step: 10
Training loss: 2.2746260166168213
Validation loss: 2.021763119646298

Epoch: 6| Step: 11
Training loss: 2.067227363586426
Validation loss: 2.039317677097936

Epoch: 6| Step: 12
Training loss: 1.6795912981033325
Validation loss: 2.0487914700661936

Epoch: 6| Step: 13
Training loss: 1.6524808406829834
Validation loss: 2.0600906597670687

Epoch: 223| Step: 0
Training loss: 2.228410243988037
Validation loss: 2.075173403627129

Epoch: 6| Step: 1
Training loss: 2.1438732147216797
Validation loss: 2.0783548380738948

Epoch: 6| Step: 2
Training loss: 1.5534741878509521
Validation loss: 2.063404301161407

Epoch: 6| Step: 3
Training loss: 0.9170030951499939
Validation loss: 2.062912946106285

Epoch: 6| Step: 4
Training loss: 2.0603699684143066
Validation loss: 2.0557929597875124

Epoch: 6| Step: 5
Training loss: 2.191443920135498
Validation loss: 2.0509423478957145

Epoch: 6| Step: 6
Training loss: 1.4251744747161865
Validation loss: 2.044199994815293

Epoch: 6| Step: 7
Training loss: 1.9168022871017456
Validation loss: 2.046057988238591

Epoch: 6| Step: 8
Training loss: 2.0561347007751465
Validation loss: 2.057748512555194

Epoch: 6| Step: 9
Training loss: 2.1800711154937744
Validation loss: 2.049350353979295

Epoch: 6| Step: 10
Training loss: 2.3687195777893066
Validation loss: 2.0493023728811615

Epoch: 6| Step: 11
Training loss: 2.2055742740631104
Validation loss: 2.0494754493877454

Epoch: 6| Step: 12
Training loss: 1.7009303569793701
Validation loss: 2.0548231191532587

Epoch: 6| Step: 13
Training loss: 1.6743167638778687
Validation loss: 2.0538901846895934

Epoch: 224| Step: 0
Training loss: 1.3911445140838623
Validation loss: 2.074139421985995

Epoch: 6| Step: 1
Training loss: 2.1200623512268066
Validation loss: 2.0686917663902364

Epoch: 6| Step: 2
Training loss: 1.9458640813827515
Validation loss: 2.0811855831453876

Epoch: 6| Step: 3
Training loss: 2.4407236576080322
Validation loss: 2.0851123102249636

Epoch: 6| Step: 4
Training loss: 1.2254947423934937
Validation loss: 2.077826282029511

Epoch: 6| Step: 5
Training loss: 1.5131303071975708
Validation loss: 2.0810381494542605

Epoch: 6| Step: 6
Training loss: 2.304124116897583
Validation loss: 2.0689624035230247

Epoch: 6| Step: 7
Training loss: 1.7438769340515137
Validation loss: 2.0742452349714053

Epoch: 6| Step: 8
Training loss: 2.383744478225708
Validation loss: 2.07250403717

Epoch: 6| Step: 9
Training loss: 2.1695914268493652
Validation loss: 2.0588814443157566

Epoch: 6| Step: 10
Training loss: 1.915208101272583
Validation loss: 2.0586870460100073

Epoch: 6| Step: 11
Training loss: 1.6589343547821045
Validation loss: 2.0620826803227907

Epoch: 6| Step: 12
Training loss: 1.8694350719451904
Validation loss: 2.0328868050729074

Epoch: 6| Step: 13
Training loss: 2.0691311359405518
Validation loss: 2.0362680189071165

Epoch: 225| Step: 0
Training loss: 1.4806641340255737
Validation loss: 2.026168836060391

Epoch: 6| Step: 1
Training loss: 1.7785670757293701
Validation loss: 2.049284319723806

Epoch: 6| Step: 2
Training loss: 2.1981215476989746
Validation loss: 2.043969423540177

Epoch: 6| Step: 3
Training loss: 1.256119966506958
Validation loss: 2.0552539030710855

Epoch: 6| Step: 4
Training loss: 1.985107660293579
Validation loss: 2.055678011268698

Epoch: 6| Step: 5
Training loss: 2.0723648071289062
Validation loss: 2.045858726706556

Epoch: 6| Step: 6
Training loss: 1.607400894165039
Validation loss: 2.054879516683599

Epoch: 6| Step: 7
Training loss: 1.4542607069015503
Validation loss: 2.0580438542109665

Epoch: 6| Step: 8
Training loss: 2.035536766052246
Validation loss: 2.0592681413055747

Epoch: 6| Step: 9
Training loss: 1.7076109647750854
Validation loss: 2.0614788865530365

Epoch: 6| Step: 10
Training loss: 2.494115114212036
Validation loss: 2.0520904423088155

Epoch: 6| Step: 11
Training loss: 2.7580902576446533
Validation loss: 2.0756846448426605

Epoch: 6| Step: 12
Training loss: 2.082134246826172
Validation loss: 2.072371362358011

Epoch: 6| Step: 13
Training loss: 1.536331057548523
Validation loss: 2.0587691568559214

Epoch: 226| Step: 0
Training loss: 2.137449264526367
Validation loss: 2.0465316798097346

Epoch: 6| Step: 1
Training loss: 1.808703064918518
Validation loss: 2.050390451185165

Epoch: 6| Step: 2
Training loss: 2.1522469520568848
Validation loss: 2.0524445438897736

Epoch: 6| Step: 3
Training loss: 1.5751006603240967
Validation loss: 2.049617700679328

Epoch: 6| Step: 4
Training loss: 1.973634958267212
Validation loss: 2.0422012934120755

Epoch: 6| Step: 5
Training loss: 1.5655171871185303
Validation loss: 2.033019649085178

Epoch: 6| Step: 6
Training loss: 1.4257532358169556
Validation loss: 2.027388413747152

Epoch: 6| Step: 7
Training loss: 1.9341012239456177
Validation loss: 2.0090661766708537

Epoch: 6| Step: 8
Training loss: 2.543722629547119
Validation loss: 2.0250061942685034

Epoch: 6| Step: 9
Training loss: 1.9032453298568726
Validation loss: 2.034674527824566

Epoch: 6| Step: 10
Training loss: 2.0098838806152344
Validation loss: 2.051709626310615

Epoch: 6| Step: 11
Training loss: 1.7910171747207642
Validation loss: 2.0530221257158505

Epoch: 6| Step: 12
Training loss: 1.9955049753189087
Validation loss: 2.061083930794911

Epoch: 6| Step: 13
Training loss: 1.8214831352233887
Validation loss: 2.0838086451253583

Epoch: 227| Step: 0
Training loss: 2.39982271194458
Validation loss: 2.0944028810788224

Epoch: 6| Step: 1
Training loss: 1.6819689273834229
Validation loss: 2.1099640092542096

Epoch: 6| Step: 2
Training loss: 2.0184364318847656
Validation loss: 2.0926590401639222

Epoch: 6| Step: 3
Training loss: 0.9201532602310181
Validation loss: 2.0811683926531064

Epoch: 6| Step: 4
Training loss: 1.6888842582702637
Validation loss: 2.05630890528361

Epoch: 6| Step: 5
Training loss: 1.675579309463501
Validation loss: 2.0436014975270917

Epoch: 6| Step: 6
Training loss: 2.1750729084014893
Validation loss: 2.0445772037711194

Epoch: 6| Step: 7
Training loss: 2.052133798599243
Validation loss: 2.065540353457133

Epoch: 6| Step: 8
Training loss: 1.9402427673339844
Validation loss: 2.0606861165774766

Epoch: 6| Step: 9
Training loss: 2.140381336212158
Validation loss: 2.0661275232991865

Epoch: 6| Step: 10
Training loss: 1.6208131313323975
Validation loss: 2.0501368404716573

Epoch: 6| Step: 11
Training loss: 2.455019474029541
Validation loss: 2.0468361403352473

Epoch: 6| Step: 12
Training loss: 1.9219748973846436
Validation loss: 2.0385947663296937

Epoch: 6| Step: 13
Training loss: 2.120439052581787
Validation loss: 2.0586087024340065

Epoch: 228| Step: 0
Training loss: 1.315373420715332
Validation loss: 2.053329616464594

Epoch: 6| Step: 1
Training loss: 1.775936484336853
Validation loss: 2.062640251651887

Epoch: 6| Step: 2
Training loss: 1.5503979921340942
Validation loss: 2.0761372299604517

Epoch: 6| Step: 3
Training loss: 1.729088306427002
Validation loss: 2.070847083163518

Epoch: 6| Step: 4
Training loss: 2.064969301223755
Validation loss: 2.062455919481093

Epoch: 6| Step: 5
Training loss: 1.8814599514007568
Validation loss: 2.0614542192028416

Epoch: 6| Step: 6
Training loss: 2.0148162841796875
Validation loss: 2.043120784144248

Epoch: 6| Step: 7
Training loss: 1.864367127418518
Validation loss: 2.0554416064293153

Epoch: 6| Step: 8
Training loss: 1.8943359851837158
Validation loss: 2.0624366729490218

Epoch: 6| Step: 9
Training loss: 1.8097076416015625
Validation loss: 2.0541763382573284

Epoch: 6| Step: 10
Training loss: 2.328922748565674
Validation loss: 2.0529319496564966

Epoch: 6| Step: 11
Training loss: 2.21559476852417
Validation loss: 2.0401933962298977

Epoch: 6| Step: 12
Training loss: 2.0195255279541016
Validation loss: 2.0320239631078576

Epoch: 6| Step: 13
Training loss: 1.967470645904541
Validation loss: 2.0286584284997757

Epoch: 229| Step: 0
Training loss: 1.790666103363037
Validation loss: 2.050234197288431

Epoch: 6| Step: 1
Training loss: 2.262190341949463
Validation loss: 2.0714285014778056

Epoch: 6| Step: 2
Training loss: 2.2024762630462646
Validation loss: 2.06602337796201

Epoch: 6| Step: 3
Training loss: 1.4089865684509277
Validation loss: 2.0350729009156585

Epoch: 6| Step: 4
Training loss: 1.5184929370880127
Validation loss: 2.0422747429981025

Epoch: 6| Step: 5
Training loss: 1.5634018182754517
Validation loss: 2.0082207469530005

Epoch: 6| Step: 6
Training loss: 2.4454236030578613
Validation loss: 2.049947302828553

Epoch: 6| Step: 7
Training loss: 1.8567373752593994
Validation loss: 2.0927356725097983

Epoch: 6| Step: 8
Training loss: 2.367905855178833
Validation loss: 2.1524193363804973

Epoch: 6| Step: 9
Training loss: 1.867898941040039
Validation loss: 2.1453424064061974

Epoch: 6| Step: 10
Training loss: 2.669229745864868
Validation loss: 2.1372508105411323

Epoch: 6| Step: 11
Training loss: 1.1206358671188354
Validation loss: 2.107447660097512

Epoch: 6| Step: 12
Training loss: 1.628969669342041
Validation loss: 2.0707353225318332

Epoch: 6| Step: 13
Training loss: 2.607786178588867
Validation loss: 2.0578850571827223

Epoch: 230| Step: 0
Training loss: 1.9130887985229492
Validation loss: 2.0486282687033377

Epoch: 6| Step: 1
Training loss: 1.5460423231124878
Validation loss: 2.0749930027992494

Epoch: 6| Step: 2
Training loss: 1.0363490581512451
Validation loss: 2.0475042379030617

Epoch: 6| Step: 3
Training loss: 2.0875723361968994
Validation loss: 2.0608072101428943

Epoch: 6| Step: 4
Training loss: 3.118105888366699
Validation loss: 2.044226551568636

Epoch: 6| Step: 5
Training loss: 2.01360821723938
Validation loss: 2.0312409529121975

Epoch: 6| Step: 6
Training loss: 1.9648489952087402
Validation loss: 2.031160521250899

Epoch: 6| Step: 7
Training loss: 1.7069685459136963
Validation loss: 2.033147427343553

Epoch: 6| Step: 8
Training loss: 2.292534589767456
Validation loss: 2.034409239727964

Epoch: 6| Step: 9
Training loss: 2.5101168155670166
Validation loss: 2.0555031325227473

Epoch: 6| Step: 10
Training loss: 1.5370559692382812
Validation loss: 2.0673784107290287

Epoch: 6| Step: 11
Training loss: 1.9624686241149902
Validation loss: 2.064415195936798

Epoch: 6| Step: 12
Training loss: 1.0287222862243652
Validation loss: 2.0792339899206675

Epoch: 6| Step: 13
Training loss: 1.5367047786712646
Validation loss: 2.076427012361506

Epoch: 231| Step: 0
Training loss: 2.2804136276245117
Validation loss: 2.0662242520240044

Epoch: 6| Step: 1
Training loss: 2.172286033630371
Validation loss: 2.0847980540285826

Epoch: 6| Step: 2
Training loss: 1.6742382049560547
Validation loss: 2.081400353421447

Epoch: 6| Step: 3
Training loss: 1.4848899841308594
Validation loss: 2.088931324661419

Epoch: 6| Step: 4
Training loss: 1.8178296089172363
Validation loss: 2.083155826855731

Epoch: 6| Step: 5
Training loss: 1.6766865253448486
Validation loss: 2.0920417360080186

Epoch: 6| Step: 6
Training loss: 2.091691493988037
Validation loss: 2.101177784704393

Epoch: 6| Step: 7
Training loss: 1.305532455444336
Validation loss: 2.1053001931918565

Epoch: 6| Step: 8
Training loss: 1.963416337966919
Validation loss: 2.1277972267520044

Epoch: 6| Step: 9
Training loss: 2.2306883335113525
Validation loss: 2.1196287549952024

Epoch: 6| Step: 10
Training loss: 2.208373546600342
Validation loss: 2.0928050061707855

Epoch: 6| Step: 11
Training loss: 2.165951728820801
Validation loss: 2.056664090002737

Epoch: 6| Step: 12
Training loss: 1.8024030923843384
Validation loss: 2.0423103583756315

Epoch: 6| Step: 13
Training loss: 1.0621914863586426
Validation loss: 2.026963104483902

Epoch: 232| Step: 0
Training loss: 2.1249043941497803
Validation loss: 2.0281137189557477

Epoch: 6| Step: 1
Training loss: 1.7844603061676025
Validation loss: 2.008810394553728

Epoch: 6| Step: 2
Training loss: 1.8909326791763306
Validation loss: 2.0046567916870117

Epoch: 6| Step: 3
Training loss: 1.6710553169250488
Validation loss: 2.00120263074034

Epoch: 6| Step: 4
Training loss: 1.4823790788650513
Validation loss: 2.0053612980791318

Epoch: 6| Step: 5
Training loss: 1.1419520378112793
Validation loss: 2.0251076503466536

Epoch: 6| Step: 6
Training loss: 2.052706003189087
Validation loss: 2.0368736879799956

Epoch: 6| Step: 7
Training loss: 1.5235296487808228
Validation loss: 2.0478598046046432

Epoch: 6| Step: 8
Training loss: 2.2168922424316406
Validation loss: 2.051970879236857

Epoch: 6| Step: 9
Training loss: 2.4044127464294434
Validation loss: 2.070164381816823

Epoch: 6| Step: 10
Training loss: 2.1590728759765625
Validation loss: 2.067353497269333

Epoch: 6| Step: 11
Training loss: 1.7396740913391113
Validation loss: 2.0549966263514694

Epoch: 6| Step: 12
Training loss: 2.442166805267334
Validation loss: 2.0693417569642425

Epoch: 6| Step: 13
Training loss: 1.426573634147644
Validation loss: 2.095950357375606

Epoch: 233| Step: 0
Training loss: 1.9651615619659424
Validation loss: 2.115109420591785

Epoch: 6| Step: 1
Training loss: 1.3821065425872803
Validation loss: 2.134303737712163

Epoch: 6| Step: 2
Training loss: 2.558089017868042
Validation loss: 2.1341179724662536

Epoch: 6| Step: 3
Training loss: 1.8583266735076904
Validation loss: 2.09659186614457

Epoch: 6| Step: 4
Training loss: 1.793163537979126
Validation loss: 2.083852034743114

Epoch: 6| Step: 5
Training loss: 1.966879963874817
Validation loss: 2.0584853131283998

Epoch: 6| Step: 6
Training loss: 2.33253812789917
Validation loss: 2.0460510202633437

Epoch: 6| Step: 7
Training loss: 1.9061031341552734
Validation loss: 2.0485323167616323

Epoch: 6| Step: 8
Training loss: 1.8019574880599976
Validation loss: 2.033210274993732

Epoch: 6| Step: 9
Training loss: 1.9376587867736816
Validation loss: 2.0386120273220922

Epoch: 6| Step: 10
Training loss: 1.6469398736953735
Validation loss: 2.0226084852731354

Epoch: 6| Step: 11
Training loss: 1.9746792316436768
Validation loss: 2.020941598441011

Epoch: 6| Step: 12
Training loss: 1.4334781169891357
Validation loss: 2.0316041054264193

Epoch: 6| Step: 13
Training loss: 1.674634337425232
Validation loss: 2.0144877023594354

Epoch: 234| Step: 0
Training loss: 2.0123181343078613
Validation loss: 2.0210988060120614

Epoch: 6| Step: 1
Training loss: 2.032412528991699
Validation loss: 2.0317358432277555

Epoch: 6| Step: 2
Training loss: 1.623177170753479
Validation loss: 2.0446163979909753

Epoch: 6| Step: 3
Training loss: 2.5662312507629395
Validation loss: 2.058582055953241

Epoch: 6| Step: 4
Training loss: 1.0754928588867188
Validation loss: 2.06590094617618

Epoch: 6| Step: 5
Training loss: 2.068126678466797
Validation loss: 2.0446672670302855

Epoch: 6| Step: 6
Training loss: 2.8771748542785645
Validation loss: 2.052018024588144

Epoch: 6| Step: 7
Training loss: 1.0414793491363525
Validation loss: 2.0556712817120295

Epoch: 6| Step: 8
Training loss: 1.7038888931274414
Validation loss: 2.0592854612617084

Epoch: 6| Step: 9
Training loss: 1.4457616806030273
Validation loss: 2.0736571229914182

Epoch: 6| Step: 10
Training loss: 2.2646565437316895
Validation loss: 2.094146513169812

Epoch: 6| Step: 11
Training loss: 2.0507984161376953
Validation loss: 2.1163100401560464

Epoch: 6| Step: 12
Training loss: 1.4695942401885986
Validation loss: 2.0995828285012195

Epoch: 6| Step: 13
Training loss: 1.829154372215271
Validation loss: 2.0733041404395975

Epoch: 235| Step: 0
Training loss: 2.47139310836792
Validation loss: 2.057699103509226

Epoch: 6| Step: 1
Training loss: 1.7538390159606934
Validation loss: 2.056145821848223

Epoch: 6| Step: 2
Training loss: 1.2404115200042725
Validation loss: 2.036779357540992

Epoch: 6| Step: 3
Training loss: 2.5670735836029053
Validation loss: 2.0439491271972656

Epoch: 6| Step: 4
Training loss: 1.941417932510376
Validation loss: 2.0299705305407123

Epoch: 6| Step: 5
Training loss: 1.5226603746414185
Validation loss: 2.0124032702497257

Epoch: 6| Step: 6
Training loss: 1.6296117305755615
Validation loss: 2.016435933369462

Epoch: 6| Step: 7
Training loss: 1.4391628503799438
Validation loss: 2.0141117931694112

Epoch: 6| Step: 8
Training loss: 1.3461060523986816
Validation loss: 2.027765384284399

Epoch: 6| Step: 9
Training loss: 2.0809173583984375
Validation loss: 2.026852705145395

Epoch: 6| Step: 10
Training loss: 1.6063181161880493
Validation loss: 2.0378049201862787

Epoch: 6| Step: 11
Training loss: 2.265213966369629
Validation loss: 2.0307936463304745

Epoch: 6| Step: 12
Training loss: 2.5262982845306396
Validation loss: 2.049788232772581

Epoch: 6| Step: 13
Training loss: 1.1562573909759521
Validation loss: 2.0619002003823557

Epoch: 236| Step: 0
Training loss: 1.993356466293335
Validation loss: 2.066584651188184

Epoch: 6| Step: 1
Training loss: 1.2156280279159546
Validation loss: 2.0932982737018215

Epoch: 6| Step: 2
Training loss: 2.1298820972442627
Validation loss: 2.111612560928509

Epoch: 6| Step: 3
Training loss: 2.263518810272217
Validation loss: 2.145225035246982

Epoch: 6| Step: 4
Training loss: 2.1773736476898193
Validation loss: 2.125438860667649

Epoch: 6| Step: 5
Training loss: 1.2308685779571533
Validation loss: 2.0924394669071322

Epoch: 6| Step: 6
Training loss: 1.6104938983917236
Validation loss: 2.057607255956178

Epoch: 6| Step: 7
Training loss: 1.6309186220169067
Validation loss: 2.05073352782957

Epoch: 6| Step: 8
Training loss: 1.5145410299301147
Validation loss: 2.0746812999889417

Epoch: 6| Step: 9
Training loss: 2.325582981109619
Validation loss: 2.0800966908854823

Epoch: 6| Step: 10
Training loss: 1.870997428894043
Validation loss: 2.0480099903639926

Epoch: 6| Step: 11
Training loss: 1.7227706909179688
Validation loss: 2.0161639028979885

Epoch: 6| Step: 12
Training loss: 2.4248247146606445
Validation loss: 2.0222929434109758

Epoch: 6| Step: 13
Training loss: 1.7803832292556763
Validation loss: 2.0343998273213706

Epoch: 237| Step: 0
Training loss: 1.8320305347442627
Validation loss: 2.0521122242814753

Epoch: 6| Step: 1
Training loss: 1.84782874584198
Validation loss: 2.0583935347936486

Epoch: 6| Step: 2
Training loss: 2.057615041732788
Validation loss: 2.0764334970904934

Epoch: 6| Step: 3
Training loss: 2.2418644428253174
Validation loss: 2.0839769712058445

Epoch: 6| Step: 4
Training loss: 1.7717525959014893
Validation loss: 2.077327561634843

Epoch: 6| Step: 5
Training loss: 2.5843896865844727
Validation loss: 2.099822671182694

Epoch: 6| Step: 6
Training loss: 1.603819489479065
Validation loss: 2.060147375188848

Epoch: 6| Step: 7
Training loss: 2.0299978256225586
Validation loss: 2.0471179767321517

Epoch: 6| Step: 8
Training loss: 1.588779091835022
Validation loss: 2.0541202368274813

Epoch: 6| Step: 9
Training loss: 1.2335147857666016
Validation loss: 2.0684209844117523

Epoch: 6| Step: 10
Training loss: 1.5494379997253418
Validation loss: 2.059198639726126

Epoch: 6| Step: 11
Training loss: 2.113314628601074
Validation loss: 2.060545736743558

Epoch: 6| Step: 12
Training loss: 1.681309461593628
Validation loss: 2.0517053757944415

Epoch: 6| Step: 13
Training loss: 1.3647027015686035
Validation loss: 2.0377774315495647

Epoch: 238| Step: 0
Training loss: 1.2595367431640625
Validation loss: 2.057205820596346

Epoch: 6| Step: 1
Training loss: 2.238934278488159
Validation loss: 2.0795043847894155

Epoch: 6| Step: 2
Training loss: 2.459230422973633
Validation loss: 2.0981605065766202

Epoch: 6| Step: 3
Training loss: 2.4148612022399902
Validation loss: 2.1687015769302205

Epoch: 6| Step: 4
Training loss: 2.045870065689087
Validation loss: 2.1662360134945122

Epoch: 6| Step: 5
Training loss: 2.588063955307007
Validation loss: 2.1795826522252892

Epoch: 6| Step: 6
Training loss: 0.7706687450408936
Validation loss: 2.160462471746629

Epoch: 6| Step: 7
Training loss: 1.6323074102401733
Validation loss: 2.149830033702235

Epoch: 6| Step: 8
Training loss: 1.1873269081115723
Validation loss: 2.1204095091871036

Epoch: 6| Step: 9
Training loss: 1.9648356437683105
Validation loss: 2.146701866580594

Epoch: 6| Step: 10
Training loss: 1.7379199266433716
Validation loss: 2.1652572859999952

Epoch: 6| Step: 11
Training loss: 1.9063503742218018
Validation loss: 2.2122223838683097

Epoch: 6| Step: 12
Training loss: 2.261880397796631
Validation loss: 2.169304094006938

Epoch: 6| Step: 13
Training loss: 1.4227968454360962
Validation loss: 2.1135089217975573

Epoch: 239| Step: 0
Training loss: 1.7974940538406372
Validation loss: 2.039170898416991

Epoch: 6| Step: 1
Training loss: 2.12506103515625
Validation loss: 2.033437152062693

Epoch: 6| Step: 2
Training loss: 1.685085654258728
Validation loss: 2.01012840834997

Epoch: 6| Step: 3
Training loss: 1.7682925462722778
Validation loss: 2.0009616216023765

Epoch: 6| Step: 4
Training loss: 1.652407169342041
Validation loss: 2.006014136857884

Epoch: 6| Step: 5
Training loss: 0.9061191082000732
Validation loss: 2.00765065480304

Epoch: 6| Step: 6
Training loss: 1.8500444889068604
Validation loss: 2.003822107468882

Epoch: 6| Step: 7
Training loss: 1.288654088973999
Validation loss: 2.0123738883644022

Epoch: 6| Step: 8
Training loss: 2.739575147628784
Validation loss: 2.0297622206390544

Epoch: 6| Step: 9
Training loss: 1.8492238521575928
Validation loss: 2.0183641577279694

Epoch: 6| Step: 10
Training loss: 1.6967896223068237
Validation loss: 2.03137872808723

Epoch: 6| Step: 11
Training loss: 2.0008115768432617
Validation loss: 2.013271795806064

Epoch: 6| Step: 12
Training loss: 2.2588648796081543
Validation loss: 2.0248689677125666

Epoch: 6| Step: 13
Training loss: 1.7804216146469116
Validation loss: 2.0461388531551568

Epoch: 240| Step: 0
Training loss: 1.667509913444519
Validation loss: 2.0737638960602465

Epoch: 6| Step: 1
Training loss: 2.463953733444214
Validation loss: 2.0799158619296167

Epoch: 6| Step: 2
Training loss: 1.1339563131332397
Validation loss: 2.0699827747960247

Epoch: 6| Step: 3
Training loss: 1.3579585552215576
Validation loss: 2.059651901645045

Epoch: 6| Step: 4
Training loss: 1.7793023586273193
Validation loss: 2.063721608090144

Epoch: 6| Step: 5
Training loss: 1.8458456993103027
Validation loss: 2.053461044065414

Epoch: 6| Step: 6
Training loss: 1.6913939714431763
Validation loss: 2.050626952161071

Epoch: 6| Step: 7
Training loss: 2.3091821670532227
Validation loss: 2.0286850544714157

Epoch: 6| Step: 8
Training loss: 2.587277889251709
Validation loss: 2.0313643037631945

Epoch: 6| Step: 9
Training loss: 1.2352303266525269
Validation loss: 2.0335594672028736

Epoch: 6| Step: 10
Training loss: 1.6042958498001099
Validation loss: 2.0129762977682133

Epoch: 6| Step: 11
Training loss: 2.166461706161499
Validation loss: 2.0113329105479743

Epoch: 6| Step: 12
Training loss: 2.146790027618408
Validation loss: 2.0217112725780857

Epoch: 6| Step: 13
Training loss: 1.1322375535964966
Validation loss: 2.048141587165094

Epoch: 241| Step: 0
Training loss: 1.660193681716919
Validation loss: 2.02858950373947

Epoch: 6| Step: 1
Training loss: 1.387583613395691
Validation loss: 2.030490093333747

Epoch: 6| Step: 2
Training loss: 1.9866054058074951
Validation loss: 2.0477499846489198

Epoch: 6| Step: 3
Training loss: 2.447813034057617
Validation loss: 2.065314023725448

Epoch: 6| Step: 4
Training loss: 1.9168987274169922
Validation loss: 2.065328323712913

Epoch: 6| Step: 5
Training loss: 1.5710303783416748
Validation loss: 2.0785997119001163

Epoch: 6| Step: 6
Training loss: 1.6542234420776367
Validation loss: 2.078527949189627

Epoch: 6| Step: 7
Training loss: 1.653037667274475
Validation loss: 2.0483059242207515

Epoch: 6| Step: 8
Training loss: 1.5404002666473389
Validation loss: 2.06065530930796

Epoch: 6| Step: 9
Training loss: 1.7989554405212402
Validation loss: 2.031577532009412

Epoch: 6| Step: 10
Training loss: 1.9030020236968994
Validation loss: 2.0164110929735246

Epoch: 6| Step: 11
Training loss: 1.8683302402496338
Validation loss: 2.0124161140893095

Epoch: 6| Step: 12
Training loss: 1.8139570951461792
Validation loss: 1.9798888993519608

Epoch: 6| Step: 13
Training loss: 1.9421530961990356
Validation loss: 1.9970857686893915

Epoch: 242| Step: 0
Training loss: 1.2676129341125488
Validation loss: 1.9913051230933076

Epoch: 6| Step: 1
Training loss: 2.270209789276123
Validation loss: 2.013028170472832

Epoch: 6| Step: 2
Training loss: 1.7657573223114014
Validation loss: 2.006795306359568

Epoch: 6| Step: 3
Training loss: 1.6639834642410278
Validation loss: 2.0067773403659945

Epoch: 6| Step: 4
Training loss: 1.9198569059371948
Validation loss: 2.0061178873944026

Epoch: 6| Step: 5
Training loss: 1.7706385850906372
Validation loss: 2.0083103231204453

Epoch: 6| Step: 6
Training loss: 2.5022287368774414
Validation loss: 1.9982176724300589

Epoch: 6| Step: 7
Training loss: 1.1865084171295166
Validation loss: 1.9946571652607252

Epoch: 6| Step: 8
Training loss: 1.5200697183609009
Validation loss: 1.996017744464259

Epoch: 6| Step: 9
Training loss: 1.4407236576080322
Validation loss: 2.0071627324627292

Epoch: 6| Step: 10
Training loss: 1.8474138975143433
Validation loss: 2.0101297081157727

Epoch: 6| Step: 11
Training loss: 1.8078268766403198
Validation loss: 2.0296261438759426

Epoch: 6| Step: 12
Training loss: 1.9627313613891602
Validation loss: 2.0619398547757055

Epoch: 6| Step: 13
Training loss: 2.3446547985076904
Validation loss: 2.0929771418212564

Epoch: 243| Step: 0
Training loss: 1.8604447841644287
Validation loss: 2.1112216967408375

Epoch: 6| Step: 1
Training loss: 1.6790717840194702
Validation loss: 2.1348760384385304

Epoch: 6| Step: 2
Training loss: 1.4468812942504883
Validation loss: 2.127574236162247

Epoch: 6| Step: 3
Training loss: 1.9941222667694092
Validation loss: 2.1077248127229753

Epoch: 6| Step: 4
Training loss: 1.8405113220214844
Validation loss: 2.1094411316738335

Epoch: 6| Step: 5
Training loss: 1.9353301525115967
Validation loss: 2.1141066256389824

Epoch: 6| Step: 6
Training loss: 1.4804459810256958
Validation loss: 2.0891774431351693

Epoch: 6| Step: 7
Training loss: 2.2402403354644775
Validation loss: 2.088115317847139

Epoch: 6| Step: 8
Training loss: 1.6356711387634277
Validation loss: 2.0632475806820776

Epoch: 6| Step: 9
Training loss: 1.1370254755020142
Validation loss: 2.0355658300461306

Epoch: 6| Step: 10
Training loss: 2.241518497467041
Validation loss: 2.027045416575606

Epoch: 6| Step: 11
Training loss: 1.9225132465362549
Validation loss: 2.0137506146584787

Epoch: 6| Step: 12
Training loss: 1.7312445640563965
Validation loss: 2.028283408893052

Epoch: 6| Step: 13
Training loss: 2.180612087249756
Validation loss: 2.043355623881022

Epoch: 244| Step: 0
Training loss: 2.2544353008270264
Validation loss: 2.013875722885132

Epoch: 6| Step: 1
Training loss: 1.3391368389129639
Validation loss: 2.0023223917971373

Epoch: 6| Step: 2
Training loss: 1.3051965236663818
Validation loss: 1.9985662198835803

Epoch: 6| Step: 3
Training loss: 2.0290298461914062
Validation loss: 2.0014280349977556

Epoch: 6| Step: 4
Training loss: 1.7844172716140747
Validation loss: 1.9997037495336225

Epoch: 6| Step: 5
Training loss: 0.9609835147857666
Validation loss: 2.0159997478608163

Epoch: 6| Step: 6
Training loss: 2.510629177093506
Validation loss: 2.0093396312447003

Epoch: 6| Step: 7
Training loss: 2.117086172103882
Validation loss: 2.0213491314200946

Epoch: 6| Step: 8
Training loss: 1.6469879150390625
Validation loss: 2.015767043636691

Epoch: 6| Step: 9
Training loss: 2.1220109462738037
Validation loss: 2.042524673605478

Epoch: 6| Step: 10
Training loss: 1.7203211784362793
Validation loss: 2.03473557964448

Epoch: 6| Step: 11
Training loss: 2.085374355316162
Validation loss: 2.0540305619598715

Epoch: 6| Step: 12
Training loss: 1.479419231414795
Validation loss: 2.0722518672225294

Epoch: 6| Step: 13
Training loss: 1.072715163230896
Validation loss: 2.07024444559569

Epoch: 245| Step: 0
Training loss: 1.9483755826950073
Validation loss: 2.0986563415937525

Epoch: 6| Step: 1
Training loss: 2.0713436603546143
Validation loss: 2.096904995620892

Epoch: 6| Step: 2
Training loss: 1.7010650634765625
Validation loss: 2.0802933721132177

Epoch: 6| Step: 3
Training loss: 1.6870002746582031
Validation loss: 2.0870223096621934

Epoch: 6| Step: 4
Training loss: 1.6072232723236084
Validation loss: 2.0795451928210515

Epoch: 6| Step: 5
Training loss: 1.4079482555389404
Validation loss: 2.066759256906407

Epoch: 6| Step: 6
Training loss: 2.0653586387634277
Validation loss: 2.0731935065279723

Epoch: 6| Step: 7
Training loss: 0.9438486099243164
Validation loss: 2.048172773853425

Epoch: 6| Step: 8
Training loss: 1.742650032043457
Validation loss: 2.0491292156198972

Epoch: 6| Step: 9
Training loss: 2.050185203552246
Validation loss: 2.0520104900483163

Epoch: 6| Step: 10
Training loss: 1.8123703002929688
Validation loss: 2.044395728777814

Epoch: 6| Step: 11
Training loss: 1.5366594791412354
Validation loss: 2.007874995149592

Epoch: 6| Step: 12
Training loss: 2.0177905559539795
Validation loss: 1.9946266015370686

Epoch: 6| Step: 13
Training loss: 2.8077056407928467
Validation loss: 1.9949237121048795

Epoch: 246| Step: 0
Training loss: 1.8499019145965576
Validation loss: 2.0157969408137824

Epoch: 6| Step: 1
Training loss: 1.8912147283554077
Validation loss: 2.021151384999675

Epoch: 6| Step: 2
Training loss: 1.682316780090332
Validation loss: 2.0263432956510976

Epoch: 6| Step: 3
Training loss: 1.2295536994934082
Validation loss: 2.0216607252756753

Epoch: 6| Step: 4
Training loss: 1.8711706399917603
Validation loss: 2.0264624216223277

Epoch: 6| Step: 5
Training loss: 1.8369468450546265
Validation loss: 2.022712858774329

Epoch: 6| Step: 6
Training loss: 1.1353659629821777
Validation loss: 2.036131660143534

Epoch: 6| Step: 7
Training loss: 2.3114442825317383
Validation loss: 2.066102881585398

Epoch: 6| Step: 8
Training loss: 1.5382152795791626
Validation loss: 2.1039060367050992

Epoch: 6| Step: 9
Training loss: 1.7779598236083984
Validation loss: 2.0991955277740315

Epoch: 6| Step: 10
Training loss: 2.23587703704834
Validation loss: 2.0855876617534186

Epoch: 6| Step: 11
Training loss: 1.5512933731079102
Validation loss: 2.073685198701838

Epoch: 6| Step: 12
Training loss: 2.1604912281036377
Validation loss: 2.0803213081052228

Epoch: 6| Step: 13
Training loss: 1.6982464790344238
Validation loss: 2.0471088924715595

Epoch: 247| Step: 0
Training loss: 1.5623352527618408
Validation loss: 2.0605494463315575

Epoch: 6| Step: 1
Training loss: 1.4557132720947266
Validation loss: 2.051469995129493

Epoch: 6| Step: 2
Training loss: 1.4360129833221436
Validation loss: 2.034943865191552

Epoch: 6| Step: 3
Training loss: 1.7774831056594849
Validation loss: 2.0144749033835625

Epoch: 6| Step: 4
Training loss: 1.817352294921875
Validation loss: 2.0211006620878815

Epoch: 6| Step: 5
Training loss: 1.5152812004089355
Validation loss: 1.9921009444421338

Epoch: 6| Step: 6
Training loss: 2.367648124694824
Validation loss: 1.9795730293437999

Epoch: 6| Step: 7
Training loss: 1.8729815483093262
Validation loss: 1.9828639350911623

Epoch: 6| Step: 8
Training loss: 1.6483951807022095
Validation loss: 1.9920047560045797

Epoch: 6| Step: 9
Training loss: 1.9716598987579346
Validation loss: 2.005291073553024

Epoch: 6| Step: 10
Training loss: 2.051511287689209
Validation loss: 2.0217104727222073

Epoch: 6| Step: 11
Training loss: 1.422703504562378
Validation loss: 2.0009231900656097

Epoch: 6| Step: 12
Training loss: 1.7736761569976807
Validation loss: 2.009662699955766

Epoch: 6| Step: 13
Training loss: 2.155606746673584
Validation loss: 2.0335743273458173

Epoch: 248| Step: 0
Training loss: 1.9032490253448486
Validation loss: 2.0353167262128604

Epoch: 6| Step: 1
Training loss: 1.8779343366622925
Validation loss: 2.0479796342952277

Epoch: 6| Step: 2
Training loss: 1.335025668144226
Validation loss: 2.0613013364935435

Epoch: 6| Step: 3
Training loss: 1.9200408458709717
Validation loss: 2.055659482556005

Epoch: 6| Step: 4
Training loss: 2.1167235374450684
Validation loss: 2.04605092412682

Epoch: 6| Step: 5
Training loss: 1.2931238412857056
Validation loss: 2.0649388221002396

Epoch: 6| Step: 6
Training loss: 1.9457664489746094
Validation loss: 2.062509536743164

Epoch: 6| Step: 7
Training loss: 1.703986644744873
Validation loss: 2.040907241964853

Epoch: 6| Step: 8
Training loss: 1.8487855195999146
Validation loss: 2.0466621088725265

Epoch: 6| Step: 9
Training loss: 1.3282939195632935
Validation loss: 2.0402326673589726

Epoch: 6| Step: 10
Training loss: 1.7791520357131958
Validation loss: 2.0563208031397995

Epoch: 6| Step: 11
Training loss: 1.2975356578826904
Validation loss: 2.0701396285846667

Epoch: 6| Step: 12
Training loss: 2.2172794342041016
Validation loss: 2.0684088583915465

Epoch: 6| Step: 13
Training loss: 1.77734375
Validation loss: 2.0799200534820557

Epoch: 249| Step: 0
Training loss: 2.067133903503418
Validation loss: 2.0455321522169214

Epoch: 6| Step: 1
Training loss: 2.0036439895629883
Validation loss: 2.0551069372443744

Epoch: 6| Step: 2
Training loss: 1.8842624425888062
Validation loss: 2.0309712322809363

Epoch: 6| Step: 3
Training loss: 1.1953009366989136
Validation loss: 2.0134563728045394

Epoch: 6| Step: 4
Training loss: 1.6843643188476562
Validation loss: 2.02994603367262

Epoch: 6| Step: 5
Training loss: 2.1668543815612793
Validation loss: 2.0451284147077993

Epoch: 6| Step: 6
Training loss: 1.2977776527404785
Validation loss: 2.017885805458151

Epoch: 6| Step: 7
Training loss: 1.3775485754013062
Validation loss: 2.002132422180586

Epoch: 6| Step: 8
Training loss: 2.3090572357177734
Validation loss: 1.9853509702990133

Epoch: 6| Step: 9
Training loss: 1.675356149673462
Validation loss: 1.967924460288017

Epoch: 6| Step: 10
Training loss: 1.9095417261123657
Validation loss: 1.972606514089851

Epoch: 6| Step: 11
Training loss: 2.0360565185546875
Validation loss: 1.9817953148195822

Epoch: 6| Step: 12
Training loss: 1.2836153507232666
Validation loss: 2.0062394283151113

Epoch: 6| Step: 13
Training loss: 1.6405465602874756
Validation loss: 2.0285456231845322

Epoch: 250| Step: 0
Training loss: 1.6764798164367676
Validation loss: 2.020188723841021

Epoch: 6| Step: 1
Training loss: 1.9145901203155518
Validation loss: 2.044122475449757

Epoch: 6| Step: 2
Training loss: 1.4437259435653687
Validation loss: 2.03628662965631

Epoch: 6| Step: 3
Training loss: 1.2710788249969482
Validation loss: 2.046416315981137

Epoch: 6| Step: 4
Training loss: 1.0092107057571411
Validation loss: 2.0377682101341987

Epoch: 6| Step: 5
Training loss: 1.933039665222168
Validation loss: 2.057097265797277

Epoch: 6| Step: 6
Training loss: 1.9366793632507324
Validation loss: 2.1172612943956928

Epoch: 6| Step: 7
Training loss: 2.1780266761779785
Validation loss: 2.0967310474764917

Epoch: 6| Step: 8
Training loss: 2.155240297317505
Validation loss: 2.089813196530906

Epoch: 6| Step: 9
Training loss: 2.3712551593780518
Validation loss: 2.094545095197616

Epoch: 6| Step: 10
Training loss: 1.6681015491485596
Validation loss: 2.073743485635327

Epoch: 6| Step: 11
Training loss: 1.5203759670257568
Validation loss: 2.067327176370928

Epoch: 6| Step: 12
Training loss: 1.7813111543655396
Validation loss: 2.0436382703883673

Epoch: 6| Step: 13
Training loss: 1.9252790212631226
Validation loss: 2.043133330601518

Epoch: 251| Step: 0
Training loss: 1.4964509010314941
Validation loss: 2.033484323050386

Epoch: 6| Step: 1
Training loss: 1.5812437534332275
Validation loss: 2.0227944492011942

Epoch: 6| Step: 2
Training loss: 1.731685996055603
Validation loss: 2.011367565842085

Epoch: 6| Step: 3
Training loss: 1.5190024375915527
Validation loss: 2.028816165462617

Epoch: 6| Step: 4
Training loss: 1.725449800491333
Validation loss: 2.0538469873448855

Epoch: 6| Step: 5
Training loss: 3.0996177196502686
Validation loss: 2.090099944863268

Epoch: 6| Step: 6
Training loss: 1.5562095642089844
Validation loss: 2.0615234708273285

Epoch: 6| Step: 7
Training loss: 1.722111463546753
Validation loss: 2.045528963047971

Epoch: 6| Step: 8
Training loss: 1.4403928518295288
Validation loss: 2.036686012821813

Epoch: 6| Step: 9
Training loss: 1.8783349990844727
Validation loss: 2.029525133871263

Epoch: 6| Step: 10
Training loss: 1.7765841484069824
Validation loss: 2.037932893281342

Epoch: 6| Step: 11
Training loss: 1.62599778175354
Validation loss: 2.076933168595837

Epoch: 6| Step: 12
Training loss: 1.671753168106079
Validation loss: 2.0800011939899896

Epoch: 6| Step: 13
Training loss: 1.720428228378296
Validation loss: 2.071178276051757

Epoch: 252| Step: 0
Training loss: 2.00248122215271
Validation loss: 2.0511956419996036

Epoch: 6| Step: 1
Training loss: 1.162766695022583
Validation loss: 2.0359865632108463

Epoch: 6| Step: 2
Training loss: 2.1392674446105957
Validation loss: 2.0465056819300496

Epoch: 6| Step: 3
Training loss: 2.4528956413269043
Validation loss: 2.069537208926293

Epoch: 6| Step: 4
Training loss: 1.4039618968963623
Validation loss: 2.108238306096805

Epoch: 6| Step: 5
Training loss: 2.18227219581604
Validation loss: 2.160361305359871

Epoch: 6| Step: 6
Training loss: 1.4521300792694092
Validation loss: 2.1260242218612344

Epoch: 6| Step: 7
Training loss: 1.56516695022583
Validation loss: 2.089633286640208

Epoch: 6| Step: 8
Training loss: 1.7840759754180908
Validation loss: 2.056615262903193

Epoch: 6| Step: 9
Training loss: 1.814892292022705
Validation loss: 2.0345624646832867

Epoch: 6| Step: 10
Training loss: 1.3527008295059204
Validation loss: 1.9991601974733415

Epoch: 6| Step: 11
Training loss: 1.9859837293624878
Validation loss: 2.029613826864509

Epoch: 6| Step: 12
Training loss: 1.560330867767334
Validation loss: 2.0563114234196243

Epoch: 6| Step: 13
Training loss: 1.4225163459777832
Validation loss: 2.051544525290048

Epoch: 253| Step: 0
Training loss: 1.5291717052459717
Validation loss: 2.0374304274077057

Epoch: 6| Step: 1
Training loss: 2.1098480224609375
Validation loss: 2.003820401366039

Epoch: 6| Step: 2
Training loss: 2.114443778991699
Validation loss: 2.0119819769295315

Epoch: 6| Step: 3
Training loss: 1.6392624378204346
Validation loss: 2.017799351805

Epoch: 6| Step: 4
Training loss: 2.042652130126953
Validation loss: 2.0111313635303127

Epoch: 6| Step: 5
Training loss: 1.6135674715042114
Validation loss: 2.0425568754955004

Epoch: 6| Step: 6
Training loss: 1.5936918258666992
Validation loss: 2.062162979956596

Epoch: 6| Step: 7
Training loss: 1.780696153640747
Validation loss: 2.0675884446790143

Epoch: 6| Step: 8
Training loss: 2.667034149169922
Validation loss: 2.063082277133901

Epoch: 6| Step: 9
Training loss: 1.3637014627456665
Validation loss: 2.0478345681262273

Epoch: 6| Step: 10
Training loss: 1.990544319152832
Validation loss: 2.044267619809797

Epoch: 6| Step: 11
Training loss: 1.1847994327545166
Validation loss: 2.0573970502422703

Epoch: 6| Step: 12
Training loss: 1.0268572568893433
Validation loss: 2.049003267800936

Epoch: 6| Step: 13
Training loss: 1.4588983058929443
Validation loss: 2.0742060907425417

Epoch: 254| Step: 0
Training loss: 1.88260817527771
Validation loss: 2.0682022033199186

Epoch: 6| Step: 1
Training loss: 1.7947099208831787
Validation loss: 2.0463548911515104

Epoch: 6| Step: 2
Training loss: 1.2576851844787598
Validation loss: 2.03978895115596

Epoch: 6| Step: 3
Training loss: 2.1175100803375244
Validation loss: 2.065876183971282

Epoch: 6| Step: 4
Training loss: 0.8811038732528687
Validation loss: 2.0725078916036956

Epoch: 6| Step: 5
Training loss: 2.1219847202301025
Validation loss: 2.0716685479687107

Epoch: 6| Step: 6
Training loss: 2.0557236671447754
Validation loss: 2.0552954481494043

Epoch: 6| Step: 7
Training loss: 1.8444483280181885
Validation loss: 2.0278641728944677

Epoch: 6| Step: 8
Training loss: 1.7918100357055664
Validation loss: 2.023584524790446

Epoch: 6| Step: 9
Training loss: 1.4150135517120361
Validation loss: 2.031928305984825

Epoch: 6| Step: 10
Training loss: 2.095465898513794
Validation loss: 2.0247458937347576

Epoch: 6| Step: 11
Training loss: 1.4156343936920166
Validation loss: 2.0162124377425

Epoch: 6| Step: 12
Training loss: 1.6759319305419922
Validation loss: 2.022019218373042

Epoch: 6| Step: 13
Training loss: 1.566201090812683
Validation loss: 2.0081023580284527

Epoch: 255| Step: 0
Training loss: 1.7158572673797607
Validation loss: 1.995686520812332

Epoch: 6| Step: 1
Training loss: 1.6032874584197998
Validation loss: 2.0276433601174304

Epoch: 6| Step: 2
Training loss: 1.8582358360290527
Validation loss: 2.0245113847076253

Epoch: 6| Step: 3
Training loss: 2.059072494506836
Validation loss: 2.0168811967295985

Epoch: 6| Step: 4
Training loss: 1.3446897268295288
Validation loss: 2.030886093775431

Epoch: 6| Step: 5
Training loss: 1.624154806137085
Validation loss: 2.020199655204691

Epoch: 6| Step: 6
Training loss: 2.2853493690490723
Validation loss: 2.038067771542457

Epoch: 6| Step: 7
Training loss: 2.5144400596618652
Validation loss: 2.0121473240595993

Epoch: 6| Step: 8
Training loss: 1.8119738101959229
Validation loss: 2.0012721066833823

Epoch: 6| Step: 9
Training loss: 1.5208981037139893
Validation loss: 2.008075685911281

Epoch: 6| Step: 10
Training loss: 1.285917043685913
Validation loss: 2.014593921681886

Epoch: 6| Step: 11
Training loss: 0.9685457348823547
Validation loss: 2.021490195746063

Epoch: 6| Step: 12
Training loss: 1.2403717041015625
Validation loss: 2.0153688077003724

Epoch: 6| Step: 13
Training loss: 1.8796168565750122
Validation loss: 2.0163456252826157

Epoch: 256| Step: 0
Training loss: 1.803667664527893
Validation loss: 2.0210890769958496

Epoch: 6| Step: 1
Training loss: 1.5942981243133545
Validation loss: 2.0307582744988064

Epoch: 6| Step: 2
Training loss: 2.091322422027588
Validation loss: 2.0058407655326267

Epoch: 6| Step: 3
Training loss: 1.9698774814605713
Validation loss: 2.0207859085452173

Epoch: 6| Step: 4
Training loss: 1.6231212615966797
Validation loss: 2.0145262031144995

Epoch: 6| Step: 5
Training loss: 1.315983533859253
Validation loss: 2.0219079243239535

Epoch: 6| Step: 6
Training loss: 1.9077231884002686
Validation loss: 2.0331002922468286

Epoch: 6| Step: 7
Training loss: 1.2430998086929321
Validation loss: 2.050349943099483

Epoch: 6| Step: 8
Training loss: 1.6620006561279297
Validation loss: 2.049793299808297

Epoch: 6| Step: 9
Training loss: 1.716076135635376
Validation loss: 2.0457313047942294

Epoch: 6| Step: 10
Training loss: 1.8115274906158447
Validation loss: 2.0455919363165416

Epoch: 6| Step: 11
Training loss: 1.3484723567962646
Validation loss: 2.055706634316393

Epoch: 6| Step: 12
Training loss: 2.038331985473633
Validation loss: 2.0348700605412966

Epoch: 6| Step: 13
Training loss: 1.3587710857391357
Validation loss: 2.021273784739997

Epoch: 257| Step: 0
Training loss: 1.478736400604248
Validation loss: 2.0078888298362814

Epoch: 6| Step: 1
Training loss: 1.8733428716659546
Validation loss: 2.003287165395675

Epoch: 6| Step: 2
Training loss: 1.7114062309265137
Validation loss: 2.000909674552179

Epoch: 6| Step: 3
Training loss: 1.7535853385925293
Validation loss: 2.021697832692054

Epoch: 6| Step: 4
Training loss: 1.3818905353546143
Validation loss: 2.007435908881567

Epoch: 6| Step: 5
Training loss: 1.7983342409133911
Validation loss: 1.9990806784681094

Epoch: 6| Step: 6
Training loss: 1.9248454570770264
Validation loss: 1.9970732529958088

Epoch: 6| Step: 7
Training loss: 1.6620855331420898
Validation loss: 2.004030732698338

Epoch: 6| Step: 8
Training loss: 1.8247572183609009
Validation loss: 2.002591825300647

Epoch: 6| Step: 9
Training loss: 1.7127912044525146
Validation loss: 2.0082540242902693

Epoch: 6| Step: 10
Training loss: 1.4189157485961914
Validation loss: 2.022300443341655

Epoch: 6| Step: 11
Training loss: 1.6454613208770752
Validation loss: 2.036132348481045

Epoch: 6| Step: 12
Training loss: 1.6315385103225708
Validation loss: 2.0422483105813303

Epoch: 6| Step: 13
Training loss: 1.8035166263580322
Validation loss: 2.0618397856271393

Epoch: 258| Step: 0
Training loss: 1.6475005149841309
Validation loss: 2.031878582892879

Epoch: 6| Step: 1
Training loss: 1.2572486400604248
Validation loss: 2.010975146806368

Epoch: 6| Step: 2
Training loss: 1.7087278366088867
Validation loss: 2.019407113393148

Epoch: 6| Step: 3
Training loss: 1.9050650596618652
Validation loss: 2.0110766246754634

Epoch: 6| Step: 4
Training loss: 2.0276052951812744
Validation loss: 2.0075206090045232

Epoch: 6| Step: 5
Training loss: 1.5547780990600586
Validation loss: 1.9818111260732014

Epoch: 6| Step: 6
Training loss: 2.215024948120117
Validation loss: 1.9735905290931783

Epoch: 6| Step: 7
Training loss: 1.527859091758728
Validation loss: 1.971146487420605

Epoch: 6| Step: 8
Training loss: 1.1715539693832397
Validation loss: 1.982495823214131

Epoch: 6| Step: 9
Training loss: 1.5719032287597656
Validation loss: 1.991763553311748

Epoch: 6| Step: 10
Training loss: 2.1693525314331055
Validation loss: 2.000010153298737

Epoch: 6| Step: 11
Training loss: 1.674076795578003
Validation loss: 2.011808636367962

Epoch: 6| Step: 12
Training loss: 1.3462402820587158
Validation loss: 2.0231932722112185

Epoch: 6| Step: 13
Training loss: 1.5256396532058716
Validation loss: 2.0513779694034207

Epoch: 259| Step: 0
Training loss: 1.8921856880187988
Validation loss: 2.049852971107729

Epoch: 6| Step: 1
Training loss: 1.1438353061676025
Validation loss: 2.069899082183838

Epoch: 6| Step: 2
Training loss: 1.4365363121032715
Validation loss: 2.0620420107277493

Epoch: 6| Step: 3
Training loss: 1.1762112379074097
Validation loss: 2.047428474631361

Epoch: 6| Step: 4
Training loss: 1.875428557395935
Validation loss: 2.0307079797149985

Epoch: 6| Step: 5
Training loss: 2.5730738639831543
Validation loss: 2.0228347239955777

Epoch: 6| Step: 6
Training loss: 1.994520664215088
Validation loss: 2.016815418838173

Epoch: 6| Step: 7
Training loss: 1.7587974071502686
Validation loss: 2.017780548782759

Epoch: 6| Step: 8
Training loss: 1.1363309621810913
Validation loss: 2.011412435962308

Epoch: 6| Step: 9
Training loss: 1.8834545612335205
Validation loss: 2.0181324853692004

Epoch: 6| Step: 10
Training loss: 1.8264482021331787
Validation loss: 2.0134341024583384

Epoch: 6| Step: 11
Training loss: 1.700758457183838
Validation loss: 1.9884988774535477

Epoch: 6| Step: 12
Training loss: 1.6104450225830078
Validation loss: 2.0117906062833724

Epoch: 6| Step: 13
Training loss: 0.9452758431434631
Validation loss: 2.0338086005180114

Epoch: 260| Step: 0
Training loss: 0.9080301523208618
Validation loss: 2.042028542487852

Epoch: 6| Step: 1
Training loss: 1.473159909248352
Validation loss: 2.058597254496749

Epoch: 6| Step: 2
Training loss: 2.0282351970672607
Validation loss: 2.0493594241398636

Epoch: 6| Step: 3
Training loss: 2.299846649169922
Validation loss: 2.015799601872762

Epoch: 6| Step: 4
Training loss: 1.7998085021972656
Validation loss: 1.9914547909972489

Epoch: 6| Step: 5
Training loss: 1.629853367805481
Validation loss: 1.9764548745206607

Epoch: 6| Step: 6
Training loss: 2.244630813598633
Validation loss: 1.9636680003135436

Epoch: 6| Step: 7
Training loss: 1.601097583770752
Validation loss: 1.9808321255509571

Epoch: 6| Step: 8
Training loss: 1.4480698108673096
Validation loss: 1.9595710846685594

Epoch: 6| Step: 9
Training loss: 1.2499594688415527
Validation loss: 1.9565261704947359

Epoch: 6| Step: 10
Training loss: 1.6647212505340576
Validation loss: 1.9915390412012737

Epoch: 6| Step: 11
Training loss: 1.606756329536438
Validation loss: 2.002506413767415

Epoch: 6| Step: 12
Training loss: 1.5880162715911865
Validation loss: 2.0150767987774265

Epoch: 6| Step: 13
Training loss: 1.6055924892425537
Validation loss: 2.0496418399195515

Epoch: 261| Step: 0
Training loss: 1.855074405670166
Validation loss: 2.0518070305547407

Epoch: 6| Step: 1
Training loss: 1.6830835342407227
Validation loss: 2.036648383704565

Epoch: 6| Step: 2
Training loss: 1.5310004949569702
Validation loss: 2.0271855195363364

Epoch: 6| Step: 3
Training loss: 1.8986316919326782
Validation loss: 2.0300716123273297

Epoch: 6| Step: 4
Training loss: 1.8098394870758057
Validation loss: 2.014357369433167

Epoch: 6| Step: 5
Training loss: 1.6245310306549072
Validation loss: 2.0039942469648135

Epoch: 6| Step: 6
Training loss: 1.4504001140594482
Validation loss: 2.0212996006011963

Epoch: 6| Step: 7
Training loss: 2.1366665363311768
Validation loss: 2.0344320881751274

Epoch: 6| Step: 8
Training loss: 1.7816908359527588
Validation loss: 2.037590144782938

Epoch: 6| Step: 9
Training loss: 1.6158387660980225
Validation loss: 2.0348930397341327

Epoch: 6| Step: 10
Training loss: 1.5832304954528809
Validation loss: 2.0320062534783476

Epoch: 6| Step: 11
Training loss: 1.255285382270813
Validation loss: 2.0248501698176065

Epoch: 6| Step: 12
Training loss: 1.3543635606765747
Validation loss: 2.0150381416402836

Epoch: 6| Step: 13
Training loss: 1.781812071800232
Validation loss: 2.0119714826665898

Epoch: 262| Step: 0
Training loss: 2.1411070823669434
Validation loss: 2.01217427433178

Epoch: 6| Step: 1
Training loss: 1.107072114944458
Validation loss: 2.001235863213898

Epoch: 6| Step: 2
Training loss: 1.469344139099121
Validation loss: 1.9867496900661017

Epoch: 6| Step: 3
Training loss: 1.2634834051132202
Validation loss: 1.9893283536357265

Epoch: 6| Step: 4
Training loss: 2.0781168937683105
Validation loss: 1.984554325380633

Epoch: 6| Step: 5
Training loss: 1.749901533126831
Validation loss: 2.0038504241615214

Epoch: 6| Step: 6
Training loss: 0.8720135688781738
Validation loss: 1.9880804733563495

Epoch: 6| Step: 7
Training loss: 1.8493385314941406
Validation loss: 2.005057350281746

Epoch: 6| Step: 8
Training loss: 1.6737918853759766
Validation loss: 2.0151106080701275

Epoch: 6| Step: 9
Training loss: 2.273824691772461
Validation loss: 1.9976039945438344

Epoch: 6| Step: 10
Training loss: 1.6393580436706543
Validation loss: 2.0204124860866095

Epoch: 6| Step: 11
Training loss: 1.953930377960205
Validation loss: 2.0245029618663173

Epoch: 6| Step: 12
Training loss: 1.3596745729446411
Validation loss: 2.0190823437065206

Epoch: 6| Step: 13
Training loss: 1.3820271492004395
Validation loss: 2.025643907567506

Epoch: 263| Step: 0
Training loss: 2.0946853160858154
Validation loss: 2.009079046146844

Epoch: 6| Step: 1
Training loss: 1.94429612159729
Validation loss: 2.0160018218460904

Epoch: 6| Step: 2
Training loss: 2.2455174922943115
Validation loss: 2.0117993175342517

Epoch: 6| Step: 3
Training loss: 1.6450273990631104
Validation loss: 1.9822426919014222

Epoch: 6| Step: 4
Training loss: 1.0977866649627686
Validation loss: 1.9842628714858845

Epoch: 6| Step: 5
Training loss: 2.150724411010742
Validation loss: 1.988775876260573

Epoch: 6| Step: 6
Training loss: 1.3810057640075684
Validation loss: 1.9808414136209795

Epoch: 6| Step: 7
Training loss: 0.7033050656318665
Validation loss: 1.987981419409475

Epoch: 6| Step: 8
Training loss: 1.5075573921203613
Validation loss: 1.9835713704427083

Epoch: 6| Step: 9
Training loss: 1.483961820602417
Validation loss: 1.9969010122360722

Epoch: 6| Step: 10
Training loss: 1.7345010042190552
Validation loss: 1.9937921339465725

Epoch: 6| Step: 11
Training loss: 1.7979509830474854
Validation loss: 2.0168264835111556

Epoch: 6| Step: 12
Training loss: 1.5212054252624512
Validation loss: 2.00799028078715

Epoch: 6| Step: 13
Training loss: 1.2673901319503784
Validation loss: 2.03187418753101

Epoch: 264| Step: 0
Training loss: 1.2661917209625244
Validation loss: 2.049566635521509

Epoch: 6| Step: 1
Training loss: 1.9344619512557983
Validation loss: 2.062411046797229

Epoch: 6| Step: 2
Training loss: 1.6586852073669434
Validation loss: 2.0859669100853706

Epoch: 6| Step: 3
Training loss: 1.6754212379455566
Validation loss: 2.1106345486897293

Epoch: 6| Step: 4
Training loss: 1.5170350074768066
Validation loss: 2.102060697411978

Epoch: 6| Step: 5
Training loss: 1.716140866279602
Validation loss: 2.0969973494929652

Epoch: 6| Step: 6
Training loss: 2.2607178688049316
Validation loss: 2.0644910873905307

Epoch: 6| Step: 7
Training loss: 1.5805280208587646
Validation loss: 2.0611057384039766

Epoch: 6| Step: 8
Training loss: 1.829491376876831
Validation loss: 2.03405334103492

Epoch: 6| Step: 9
Training loss: 1.5858843326568604
Validation loss: 2.0312482746698524

Epoch: 6| Step: 10
Training loss: 1.4076218605041504
Validation loss: 1.9843030552710257

Epoch: 6| Step: 11
Training loss: 1.735450267791748
Validation loss: 1.966675325106549

Epoch: 6| Step: 12
Training loss: 0.8758414387702942
Validation loss: 1.9541594610419324

Epoch: 6| Step: 13
Training loss: 1.9945577383041382
Validation loss: 1.9339936933209818

Epoch: 265| Step: 0
Training loss: 1.5465562343597412
Validation loss: 1.9374346374183573

Epoch: 6| Step: 1
Training loss: 2.1126699447631836
Validation loss: 1.9396104158893708

Epoch: 6| Step: 2
Training loss: 1.492922306060791
Validation loss: 1.9392186287910707

Epoch: 6| Step: 3
Training loss: 1.7993223667144775
Validation loss: 1.9318453701593543

Epoch: 6| Step: 4
Training loss: 1.6831963062286377
Validation loss: 1.9564346267331032

Epoch: 6| Step: 5
Training loss: 1.5649960041046143
Validation loss: 1.9872294113200197

Epoch: 6| Step: 6
Training loss: 1.8493982553482056
Validation loss: 2.0090528021576586

Epoch: 6| Step: 7
Training loss: 1.4430549144744873
Validation loss: 2.0208677848180137

Epoch: 6| Step: 8
Training loss: 1.7848793268203735
Validation loss: 2.024507700756032

Epoch: 6| Step: 9
Training loss: 1.7377976179122925
Validation loss: 2.0487398383437947

Epoch: 6| Step: 10
Training loss: 1.0691301822662354
Validation loss: 2.0956844898962204

Epoch: 6| Step: 11
Training loss: 1.618687391281128
Validation loss: 2.1090651840291996

Epoch: 6| Step: 12
Training loss: 1.5445879697799683
Validation loss: 2.0993385878942346

Epoch: 6| Step: 13
Training loss: 1.8880165815353394
Validation loss: 2.054115888892963

Epoch: 266| Step: 0
Training loss: 1.9947831630706787
Validation loss: 2.043546615108367

Epoch: 6| Step: 1
Training loss: 1.1364161968231201
Validation loss: 2.0365948010516424

Epoch: 6| Step: 2
Training loss: 2.026494264602661
Validation loss: 2.027524020082207

Epoch: 6| Step: 3
Training loss: 2.115830421447754
Validation loss: 2.0202003986604753

Epoch: 6| Step: 4
Training loss: 1.3434185981750488
Validation loss: 1.9949241286964827

Epoch: 6| Step: 5
Training loss: 1.35743248462677
Validation loss: 1.9793750393775202

Epoch: 6| Step: 6
Training loss: 1.894940972328186
Validation loss: 1.957109312857351

Epoch: 6| Step: 7
Training loss: 1.939700961112976
Validation loss: 1.9666496630637877

Epoch: 6| Step: 8
Training loss: 1.5777018070220947
Validation loss: 1.9701868000850882

Epoch: 6| Step: 9
Training loss: 1.5246421098709106
Validation loss: 1.981430451075236

Epoch: 6| Step: 10
Training loss: 0.7353183627128601
Validation loss: 1.9927254697327972

Epoch: 6| Step: 11
Training loss: 1.483614206314087
Validation loss: 2.0063444465719242

Epoch: 6| Step: 12
Training loss: 1.3746777772903442
Validation loss: 2.0038770603877243

Epoch: 6| Step: 13
Training loss: 2.269721031188965
Validation loss: 2.0209332178997736

Epoch: 267| Step: 0
Training loss: 1.5173252820968628
Validation loss: 2.0351404067008727

Epoch: 6| Step: 1
Training loss: 1.481518268585205
Validation loss: 2.0330014690276115

Epoch: 6| Step: 2
Training loss: 1.1656339168548584
Validation loss: 2.044627353709231

Epoch: 6| Step: 3
Training loss: 2.204749345779419
Validation loss: 2.0415924915703396

Epoch: 6| Step: 4
Training loss: 2.221850872039795
Validation loss: 2.046386108603529

Epoch: 6| Step: 5
Training loss: 1.9815740585327148
Validation loss: 2.008086407056419

Epoch: 6| Step: 6
Training loss: 1.149351716041565
Validation loss: 2.0154645507053663

Epoch: 6| Step: 7
Training loss: 1.2828890085220337
Validation loss: 1.9974788952899236

Epoch: 6| Step: 8
Training loss: 1.6069087982177734
Validation loss: 2.001006903186921

Epoch: 6| Step: 9
Training loss: 1.6522489786148071
Validation loss: 1.9756690097111527

Epoch: 6| Step: 10
Training loss: 2.0665440559387207
Validation loss: 1.9637998278423021

Epoch: 6| Step: 11
Training loss: 1.281124234199524
Validation loss: 1.9739057428093367

Epoch: 6| Step: 12
Training loss: 1.6645870208740234
Validation loss: 1.9708923114243375

Epoch: 6| Step: 13
Training loss: 0.8094814419746399
Validation loss: 1.9663757393437047

Epoch: 268| Step: 0
Training loss: 0.9314783811569214
Validation loss: 1.9763342847106278

Epoch: 6| Step: 1
Training loss: 1.7104301452636719
Validation loss: 2.0132167211142917

Epoch: 6| Step: 2
Training loss: 2.4845163822174072
Validation loss: 2.0443573203138126

Epoch: 6| Step: 3
Training loss: 1.3409290313720703
Validation loss: 2.045484371082757

Epoch: 6| Step: 4
Training loss: 2.254333257675171
Validation loss: 2.008151591465037

Epoch: 6| Step: 5
Training loss: 1.2537293434143066
Validation loss: 1.9870661240752026

Epoch: 6| Step: 6
Training loss: 1.7660322189331055
Validation loss: 1.9753115920610325

Epoch: 6| Step: 7
Training loss: 1.6119184494018555
Validation loss: 1.9902581937851445

Epoch: 6| Step: 8
Training loss: 1.3724339008331299
Validation loss: 1.9835070358809603

Epoch: 6| Step: 9
Training loss: 1.6484037637710571
Validation loss: 1.9790824382535872

Epoch: 6| Step: 10
Training loss: 1.51667320728302
Validation loss: 1.9788173142299856

Epoch: 6| Step: 11
Training loss: 1.6668403148651123
Validation loss: 1.9762656432326122

Epoch: 6| Step: 12
Training loss: 1.5710772275924683
Validation loss: 1.9870069796039211

Epoch: 6| Step: 13
Training loss: 1.763722538948059
Validation loss: 2.012064218521118

Epoch: 269| Step: 0
Training loss: 1.3982465267181396
Validation loss: 2.0329271695947133

Epoch: 6| Step: 1
Training loss: 1.9369523525238037
Validation loss: 2.0313833836586244

Epoch: 6| Step: 2
Training loss: 1.9751777648925781
Validation loss: 2.021725421310753

Epoch: 6| Step: 3
Training loss: 1.253080129623413
Validation loss: 1.995605763568673

Epoch: 6| Step: 4
Training loss: 1.9078243970870972
Validation loss: 2.0069207145321752

Epoch: 6| Step: 5
Training loss: 0.9190398454666138
Validation loss: 2.027453855801654

Epoch: 6| Step: 6
Training loss: 1.674168586730957
Validation loss: 2.030932012424674

Epoch: 6| Step: 7
Training loss: 1.6669256687164307
Validation loss: 2.0319635970618135

Epoch: 6| Step: 8
Training loss: 1.158132553100586
Validation loss: 2.005966753088018

Epoch: 6| Step: 9
Training loss: 1.183205008506775
Validation loss: 2.0231910213347404

Epoch: 6| Step: 10
Training loss: 1.2321950197219849
Validation loss: 1.9930311864422214

Epoch: 6| Step: 11
Training loss: 2.0024659633636475
Validation loss: 1.9887434769702215

Epoch: 6| Step: 12
Training loss: 2.0110127925872803
Validation loss: 1.9813234857333604

Epoch: 6| Step: 13
Training loss: 1.7645691633224487
Validation loss: 1.9831184084697435

Epoch: 270| Step: 0
Training loss: 1.4518752098083496
Validation loss: 1.975018931973365

Epoch: 6| Step: 1
Training loss: 1.384177327156067
Validation loss: 1.9856526441471551

Epoch: 6| Step: 2
Training loss: 2.0455338954925537
Validation loss: 1.9882287735580115

Epoch: 6| Step: 3
Training loss: 1.8189610242843628
Validation loss: 2.0103670012566353

Epoch: 6| Step: 4
Training loss: 1.2148538827896118
Validation loss: 1.994106552934134

Epoch: 6| Step: 5
Training loss: 2.0114312171936035
Validation loss: 1.9927402260482951

Epoch: 6| Step: 6
Training loss: 1.7232208251953125
Validation loss: 2.011169038793092

Epoch: 6| Step: 7
Training loss: 1.3034603595733643
Validation loss: 2.03368821964469

Epoch: 6| Step: 8
Training loss: 1.3303120136260986
Validation loss: 2.0023211574041717

Epoch: 6| Step: 9
Training loss: 1.4169416427612305
Validation loss: 2.0157101051781767

Epoch: 6| Step: 10
Training loss: 1.5919692516326904
Validation loss: 2.003443579519949

Epoch: 6| Step: 11
Training loss: 1.6431201696395874
Validation loss: 1.9803223686833535

Epoch: 6| Step: 12
Training loss: 1.250450849533081
Validation loss: 1.9566334909008396

Epoch: 6| Step: 13
Training loss: 2.3655030727386475
Validation loss: 1.985185428332257

Epoch: 271| Step: 0
Training loss: 1.4524470567703247
Validation loss: 2.0076122309571955

Epoch: 6| Step: 1
Training loss: 1.551225185394287
Validation loss: 1.9991459961860412

Epoch: 6| Step: 2
Training loss: 1.1536409854888916
Validation loss: 1.9786890399071477

Epoch: 6| Step: 3
Training loss: 2.0447332859039307
Validation loss: 1.983428567968389

Epoch: 6| Step: 4
Training loss: 1.0717275142669678
Validation loss: 1.9895069086423485

Epoch: 6| Step: 5
Training loss: 2.0953075885772705
Validation loss: 2.003334124883016

Epoch: 6| Step: 6
Training loss: 1.3637950420379639
Validation loss: 2.038082343275829

Epoch: 6| Step: 7
Training loss: 1.405484914779663
Validation loss: 2.026545023405424

Epoch: 6| Step: 8
Training loss: 1.97545325756073
Validation loss: 1.9964437100195116

Epoch: 6| Step: 9
Training loss: 1.5807470083236694
Validation loss: 1.9661714902488134

Epoch: 6| Step: 10
Training loss: 1.5258253812789917
Validation loss: 1.9583314311119817

Epoch: 6| Step: 11
Training loss: 1.9131911993026733
Validation loss: 1.985649852342503

Epoch: 6| Step: 12
Training loss: 1.6910152435302734
Validation loss: 1.9932286470167098

Epoch: 6| Step: 13
Training loss: 1.6163874864578247
Validation loss: 1.9786477934929632

Epoch: 272| Step: 0
Training loss: 1.3155958652496338
Validation loss: 1.9696143493857434

Epoch: 6| Step: 1
Training loss: 1.5067589282989502
Validation loss: 1.990016504000592

Epoch: 6| Step: 2
Training loss: 1.618544578552246
Validation loss: 2.00044249462825

Epoch: 6| Step: 3
Training loss: 1.1808676719665527
Validation loss: 1.9888001667555941

Epoch: 6| Step: 4
Training loss: 1.8297922611236572
Validation loss: 2.0004256463819936

Epoch: 6| Step: 5
Training loss: 1.5094799995422363
Validation loss: 1.9836921743167344

Epoch: 6| Step: 6
Training loss: 1.7861908674240112
Validation loss: 1.9857138331218431

Epoch: 6| Step: 7
Training loss: 1.2950857877731323
Validation loss: 1.9860077532388831

Epoch: 6| Step: 8
Training loss: 2.1052842140197754
Validation loss: 1.9792244767629972

Epoch: 6| Step: 9
Training loss: 1.1645772457122803
Validation loss: 1.9475591362163585

Epoch: 6| Step: 10
Training loss: 1.8828099966049194
Validation loss: 1.981397231419881

Epoch: 6| Step: 11
Training loss: 1.060544729232788
Validation loss: 1.9596478413510066

Epoch: 6| Step: 12
Training loss: 2.002293586730957
Validation loss: 1.965399294771174

Epoch: 6| Step: 13
Training loss: 1.2500152587890625
Validation loss: 1.9618286240485407

Epoch: 273| Step: 0
Training loss: 1.496598720550537
Validation loss: 1.9877679681265226

Epoch: 6| Step: 1
Training loss: 1.9297428131103516
Validation loss: 1.9895997470425022

Epoch: 6| Step: 2
Training loss: 1.4183716773986816
Validation loss: 1.9966558769185057

Epoch: 6| Step: 3
Training loss: 1.5088169574737549
Validation loss: 2.01880972103406

Epoch: 6| Step: 4
Training loss: 1.7581024169921875
Validation loss: 1.9973172013477614

Epoch: 6| Step: 5
Training loss: 1.6304928064346313
Validation loss: 1.9921667319472118

Epoch: 6| Step: 6
Training loss: 1.3834240436553955
Validation loss: 1.993481364301456

Epoch: 6| Step: 7
Training loss: 1.011635661125183
Validation loss: 1.9647887483719857

Epoch: 6| Step: 8
Training loss: 1.287432312965393
Validation loss: 1.9651708449086835

Epoch: 6| Step: 9
Training loss: 1.5489718914031982
Validation loss: 1.9559346091362737

Epoch: 6| Step: 10
Training loss: 1.449559211730957
Validation loss: 1.9401317565671858

Epoch: 6| Step: 11
Training loss: 2.054610013961792
Validation loss: 1.9638816746332313

Epoch: 6| Step: 12
Training loss: 1.361204981803894
Validation loss: 1.9740569335158153

Epoch: 6| Step: 13
Training loss: 2.2215042114257812
Validation loss: 1.9960996104824928

Epoch: 274| Step: 0
Training loss: 1.3749487400054932
Validation loss: 1.9996200428214124

Epoch: 6| Step: 1
Training loss: 1.5600955486297607
Validation loss: 2.0078917908412155

Epoch: 6| Step: 2
Training loss: 1.1460318565368652
Validation loss: 2.013374715723017

Epoch: 6| Step: 3
Training loss: 1.4207019805908203
Validation loss: 2.0480875046022478

Epoch: 6| Step: 4
Training loss: 2.041775703430176
Validation loss: 2.0797787122828986

Epoch: 6| Step: 5
Training loss: 1.2592557668685913
Validation loss: 2.069087187449137

Epoch: 6| Step: 6
Training loss: 1.484631896018982
Validation loss: 2.110034533726272

Epoch: 6| Step: 7
Training loss: 1.8620245456695557
Validation loss: 2.059913906999814

Epoch: 6| Step: 8
Training loss: 1.2532527446746826
Validation loss: 2.0251634608032885

Epoch: 6| Step: 9
Training loss: 1.9400335550308228
Validation loss: 2.005307984608476

Epoch: 6| Step: 10
Training loss: 1.6603772640228271
Validation loss: 1.9776111777110765

Epoch: 6| Step: 11
Training loss: 2.3101463317871094
Validation loss: 1.9728342076783538

Epoch: 6| Step: 12
Training loss: 1.6095435619354248
Validation loss: 1.9688873803743752

Epoch: 6| Step: 13
Training loss: 0.8035728931427002
Validation loss: 1.9669620170388171

Epoch: 275| Step: 0
Training loss: 1.5113184452056885
Validation loss: 1.9519018293708883

Epoch: 6| Step: 1
Training loss: 1.3828933238983154
Validation loss: 1.955771045018268

Epoch: 6| Step: 2
Training loss: 1.2352406978607178
Validation loss: 1.931539233012866

Epoch: 6| Step: 3
Training loss: 1.14339017868042
Validation loss: 1.9499594562797136

Epoch: 6| Step: 4
Training loss: 1.2461894750595093
Validation loss: 1.9722047416112756

Epoch: 6| Step: 5
Training loss: 1.3780193328857422
Validation loss: 1.965771775091848

Epoch: 6| Step: 6
Training loss: 1.794346570968628
Validation loss: 1.992431176606045

Epoch: 6| Step: 7
Training loss: 2.0962281227111816
Validation loss: 2.033971381443803

Epoch: 6| Step: 8
Training loss: 1.6004929542541504
Validation loss: 2.0350815826846707

Epoch: 6| Step: 9
Training loss: 1.7147572040557861
Validation loss: 2.0647955735524497

Epoch: 6| Step: 10
Training loss: 1.2368781566619873
Validation loss: 2.0616226862835627

Epoch: 6| Step: 11
Training loss: 1.5271918773651123
Validation loss: 2.0939761669405046

Epoch: 6| Step: 12
Training loss: 2.324877977371216
Validation loss: 2.109833353309221

Epoch: 6| Step: 13
Training loss: 1.789766550064087
Validation loss: 2.1086890851297686

Epoch: 276| Step: 0
Training loss: 1.5721771717071533
Validation loss: 2.0478838246355773

Epoch: 6| Step: 1
Training loss: 1.5535303354263306
Validation loss: 2.013452196633944

Epoch: 6| Step: 2
Training loss: 1.4211900234222412
Validation loss: 1.9670156996737245

Epoch: 6| Step: 3
Training loss: 1.3395649194717407
Validation loss: 1.9430300317784792

Epoch: 6| Step: 4
Training loss: 1.0368196964263916
Validation loss: 1.9443573131356189

Epoch: 6| Step: 5
Training loss: 1.6095560789108276
Validation loss: 1.939887200632403

Epoch: 6| Step: 6
Training loss: 2.2628092765808105
Validation loss: 1.939053480343152

Epoch: 6| Step: 7
Training loss: 1.9793403148651123
Validation loss: 1.9285011009503437

Epoch: 6| Step: 8
Training loss: 1.9760322570800781
Validation loss: 1.9134686121376612

Epoch: 6| Step: 9
Training loss: 1.047365665435791
Validation loss: 1.9363307055606638

Epoch: 6| Step: 10
Training loss: 1.5479342937469482
Validation loss: 1.954158244594451

Epoch: 6| Step: 11
Training loss: 1.648672342300415
Validation loss: 1.97418640505883

Epoch: 6| Step: 12
Training loss: 1.5491034984588623
Validation loss: 1.9842513376666653

Epoch: 6| Step: 13
Training loss: 1.3336434364318848
Validation loss: 1.9722227665685839

Epoch: 277| Step: 0
Training loss: 1.5152404308319092
Validation loss: 1.9881781660100466

Epoch: 6| Step: 1
Training loss: 1.6768100261688232
Validation loss: 1.9948524352042907

Epoch: 6| Step: 2
Training loss: 0.9711974859237671
Validation loss: 2.014928981822024

Epoch: 6| Step: 3
Training loss: 1.7022038698196411
Validation loss: 2.015565462009881

Epoch: 6| Step: 4
Training loss: 1.4476853609085083
Validation loss: 1.988726298014323

Epoch: 6| Step: 5
Training loss: 1.480659008026123
Validation loss: 2.0064365017798638

Epoch: 6| Step: 6
Training loss: 1.754973292350769
Validation loss: 2.0060751899596183

Epoch: 6| Step: 7
Training loss: 1.7160155773162842
Validation loss: 1.9832814508868801

Epoch: 6| Step: 8
Training loss: 1.1629544496536255
Validation loss: 2.0029893613630727

Epoch: 6| Step: 9
Training loss: 1.5647327899932861
Validation loss: 2.001921917802544

Epoch: 6| Step: 10
Training loss: 1.2997260093688965
Validation loss: 2.0006771010737263

Epoch: 6| Step: 11
Training loss: 1.8674136400222778
Validation loss: 2.0011390434798373

Epoch: 6| Step: 12
Training loss: 1.9689457416534424
Validation loss: 2.0007574481348835

Epoch: 6| Step: 13
Training loss: 1.2277474403381348
Validation loss: 1.9541689452304636

Epoch: 278| Step: 0
Training loss: 1.4334454536437988
Validation loss: 1.941876817775029

Epoch: 6| Step: 1
Training loss: 1.1039067506790161
Validation loss: 1.9321870778196601

Epoch: 6| Step: 2
Training loss: 1.8486719131469727
Validation loss: 1.9309664567311604

Epoch: 6| Step: 3
Training loss: 1.4721347093582153
Validation loss: 1.937624644207698

Epoch: 6| Step: 4
Training loss: 1.236057996749878
Validation loss: 1.9296898893130723

Epoch: 6| Step: 5
Training loss: 1.4673789739608765
Validation loss: 1.9296624557946318

Epoch: 6| Step: 6
Training loss: 1.4575440883636475
Validation loss: 1.9355591830386911

Epoch: 6| Step: 7
Training loss: 1.5100802183151245
Validation loss: 1.973657282449866

Epoch: 6| Step: 8
Training loss: 1.9470348358154297
Validation loss: 2.0391085378585325

Epoch: 6| Step: 9
Training loss: 1.6164982318878174
Validation loss: 2.061709896210701

Epoch: 6| Step: 10
Training loss: 1.7235177755355835
Validation loss: 2.0642159203047394

Epoch: 6| Step: 11
Training loss: 1.7866511344909668
Validation loss: 2.0341050189028502

Epoch: 6| Step: 12
Training loss: 2.0372767448425293
Validation loss: 2.029747534823674

Epoch: 6| Step: 13
Training loss: 0.7467837929725647
Validation loss: 2.0040605247661634

Epoch: 279| Step: 0
Training loss: 1.9825680255889893
Validation loss: 2.031782652742119

Epoch: 6| Step: 1
Training loss: 1.3165830373764038
Validation loss: 1.9963800535407117

Epoch: 6| Step: 2
Training loss: 1.5668210983276367
Validation loss: 2.0164058618648077

Epoch: 6| Step: 3
Training loss: 1.7803581953048706
Validation loss: 2.0015234396021855

Epoch: 6| Step: 4
Training loss: 1.5772703886032104
Validation loss: 1.9761305726984495

Epoch: 6| Step: 5
Training loss: 1.6907340288162231
Validation loss: 1.9771521988735403

Epoch: 6| Step: 6
Training loss: 1.0675134658813477
Validation loss: 1.982482594828452

Epoch: 6| Step: 7
Training loss: 1.6715656518936157
Validation loss: 1.9559391147346907

Epoch: 6| Step: 8
Training loss: 0.9811245203018188
Validation loss: 1.970312544094619

Epoch: 6| Step: 9
Training loss: 1.5181670188903809
Validation loss: 1.9605094899413407

Epoch: 6| Step: 10
Training loss: 1.9276762008666992
Validation loss: 1.9641937466077908

Epoch: 6| Step: 11
Training loss: 1.9492747783660889
Validation loss: 1.938250389150394

Epoch: 6| Step: 12
Training loss: 0.8525189757347107
Validation loss: 1.9587682344580208

Epoch: 6| Step: 13
Training loss: 1.3417551517486572
Validation loss: 1.9595858332931355

Epoch: 280| Step: 0
Training loss: 1.6893823146820068
Validation loss: 1.9671416051926152

Epoch: 6| Step: 1
Training loss: 1.5628197193145752
Validation loss: 1.9984080868382608

Epoch: 6| Step: 2
Training loss: 1.439067006111145
Validation loss: 2.00192565302695

Epoch: 6| Step: 3
Training loss: 2.508180618286133
Validation loss: 1.998112355509112

Epoch: 6| Step: 4
Training loss: 0.8178436756134033
Validation loss: 2.0142817087070917

Epoch: 6| Step: 5
Training loss: 1.6444323062896729
Validation loss: 2.0099350098640687

Epoch: 6| Step: 6
Training loss: 1.5582513809204102
Validation loss: 1.9911194219384143

Epoch: 6| Step: 7
Training loss: 0.9740872383117676
Validation loss: 1.9872331183443788

Epoch: 6| Step: 8
Training loss: 1.3120319843292236
Validation loss: 1.961726306587137

Epoch: 6| Step: 9
Training loss: 1.3917750120162964
Validation loss: 1.9600467989521642

Epoch: 6| Step: 10
Training loss: 1.2272567749023438
Validation loss: 1.9346417970554803

Epoch: 6| Step: 11
Training loss: 1.5632065534591675
Validation loss: 1.9508580392406834

Epoch: 6| Step: 12
Training loss: 1.9975529909133911
Validation loss: 1.941471568999752

Epoch: 6| Step: 13
Training loss: 1.327303171157837
Validation loss: 1.9366286852026497

Epoch: 281| Step: 0
Training loss: 1.5092873573303223
Validation loss: 1.936955382747035

Epoch: 6| Step: 1
Training loss: 1.5967918634414673
Validation loss: 1.9459451244723411

Epoch: 6| Step: 2
Training loss: 1.4670372009277344
Validation loss: 1.9652175057318904

Epoch: 6| Step: 3
Training loss: 1.7614161968231201
Validation loss: 1.9707286537334483

Epoch: 6| Step: 4
Training loss: 1.5576906204223633
Validation loss: 1.9571188572914369

Epoch: 6| Step: 5
Training loss: 1.2040622234344482
Validation loss: 1.956562865164972

Epoch: 6| Step: 6
Training loss: 1.3601832389831543
Validation loss: 1.958493335272676

Epoch: 6| Step: 7
Training loss: 1.3568741083145142
Validation loss: 1.9429677558201615

Epoch: 6| Step: 8
Training loss: 1.55906081199646
Validation loss: 1.9346858160470122

Epoch: 6| Step: 9
Training loss: 1.4740102291107178
Validation loss: 1.953448300720543

Epoch: 6| Step: 10
Training loss: 1.2964495420455933
Validation loss: 1.9778239419383388

Epoch: 6| Step: 11
Training loss: 1.9857091903686523
Validation loss: 2.002995116736299

Epoch: 6| Step: 12
Training loss: 1.398699164390564
Validation loss: 2.028419666392829

Epoch: 6| Step: 13
Training loss: 1.6385477781295776
Validation loss: 2.030873948527921

Epoch: 282| Step: 0
Training loss: 1.0197269916534424
Validation loss: 2.054898564533521

Epoch: 6| Step: 1
Training loss: 1.7058669328689575
Validation loss: 2.0350406387800812

Epoch: 6| Step: 2
Training loss: 1.4080419540405273
Validation loss: 2.0357636943940194

Epoch: 6| Step: 3
Training loss: 2.0282795429229736
Validation loss: 2.035374761909567

Epoch: 6| Step: 4
Training loss: 1.660419225692749
Validation loss: 2.019902406200286

Epoch: 6| Step: 5
Training loss: 1.337733507156372
Validation loss: 2.007274090602834

Epoch: 6| Step: 6
Training loss: 1.5059798955917358
Validation loss: 1.9814787295556837

Epoch: 6| Step: 7
Training loss: 1.3914945125579834
Validation loss: 1.949440792042722

Epoch: 6| Step: 8
Training loss: 1.540362000465393
Validation loss: 1.9553412442566247

Epoch: 6| Step: 9
Training loss: 1.1149916648864746
Validation loss: 1.9639172938562208

Epoch: 6| Step: 10
Training loss: 1.4317047595977783
Validation loss: 1.9602596464977469

Epoch: 6| Step: 11
Training loss: 1.4355262517929077
Validation loss: 1.968121164588518

Epoch: 6| Step: 12
Training loss: 1.8102729320526123
Validation loss: 1.9669791908674343

Epoch: 6| Step: 13
Training loss: 1.7288163900375366
Validation loss: 1.9851407748396679

Epoch: 283| Step: 0
Training loss: 1.1016910076141357
Validation loss: 2.003337821652812

Epoch: 6| Step: 1
Training loss: 0.9109421968460083
Validation loss: 1.9979024138501895

Epoch: 6| Step: 2
Training loss: 1.9751367568969727
Validation loss: 2.012274465253276

Epoch: 6| Step: 3
Training loss: 1.4195277690887451
Validation loss: 1.9915540205535067

Epoch: 6| Step: 4
Training loss: 2.4508724212646484
Validation loss: 1.9996780862090409

Epoch: 6| Step: 5
Training loss: 1.916945219039917
Validation loss: 1.981101200144778

Epoch: 6| Step: 6
Training loss: 1.1715660095214844
Validation loss: 1.9518394124123357

Epoch: 6| Step: 7
Training loss: 1.3016153573989868
Validation loss: 1.9374482298410067

Epoch: 6| Step: 8
Training loss: 1.3812566995620728
Validation loss: 1.9415874532473985

Epoch: 6| Step: 9
Training loss: 1.6426180601119995
Validation loss: 1.9239019117047709

Epoch: 6| Step: 10
Training loss: 0.8384978175163269
Validation loss: 1.9210814775959137

Epoch: 6| Step: 11
Training loss: 1.7152434587478638
Validation loss: 1.9457494340917116

Epoch: 6| Step: 12
Training loss: 1.585937738418579
Validation loss: 1.944779190965878

Epoch: 6| Step: 13
Training loss: 1.294247031211853
Validation loss: 1.9582352535699004

Epoch: 284| Step: 0
Training loss: 1.8906993865966797
Validation loss: 1.9376207038920412

Epoch: 6| Step: 1
Training loss: 1.1647247076034546
Validation loss: 1.9538863435868294

Epoch: 6| Step: 2
Training loss: 1.4677801132202148
Validation loss: 1.9694104322823145

Epoch: 6| Step: 3
Training loss: 1.4325659275054932
Validation loss: 1.973336786352178

Epoch: 6| Step: 4
Training loss: 1.2570412158966064
Validation loss: 1.9699062531994236

Epoch: 6| Step: 5
Training loss: 0.6626782417297363
Validation loss: 1.9585652441106818

Epoch: 6| Step: 6
Training loss: 1.3038405179977417
Validation loss: 1.9910971631285965

Epoch: 6| Step: 7
Training loss: 1.655300259590149
Validation loss: 1.9674610271248767

Epoch: 6| Step: 8
Training loss: 1.7884119749069214
Validation loss: 1.9889829466419835

Epoch: 6| Step: 9
Training loss: 1.5577068328857422
Validation loss: 1.9634041606739003

Epoch: 6| Step: 10
Training loss: 1.8577027320861816
Validation loss: 1.9700903469516384

Epoch: 6| Step: 11
Training loss: 1.366487741470337
Validation loss: 1.9766835884381366

Epoch: 6| Step: 12
Training loss: 1.2988967895507812
Validation loss: 1.9899349545919767

Epoch: 6| Step: 13
Training loss: 2.5115880966186523
Validation loss: 1.979639031553781

Epoch: 285| Step: 0
Training loss: 1.892647385597229
Validation loss: 1.9648435423451085

Epoch: 6| Step: 1
Training loss: 1.0998835563659668
Validation loss: 1.9893908218670917

Epoch: 6| Step: 2
Training loss: 0.9216521978378296
Validation loss: 1.9669971517337266

Epoch: 6| Step: 3
Training loss: 1.1315556764602661
Validation loss: 1.9583761794592744

Epoch: 6| Step: 4
Training loss: 1.0291295051574707
Validation loss: 1.9760922526800504

Epoch: 6| Step: 5
Training loss: 1.5925732851028442
Validation loss: 2.0021066101648475

Epoch: 6| Step: 6
Training loss: 1.3854103088378906
Validation loss: 1.9882681036508212

Epoch: 6| Step: 7
Training loss: 1.2717926502227783
Validation loss: 1.9984309634854716

Epoch: 6| Step: 8
Training loss: 2.5078439712524414
Validation loss: 2.0104497530127086

Epoch: 6| Step: 9
Training loss: 1.483077883720398
Validation loss: 1.9700517808237383

Epoch: 6| Step: 10
Training loss: 1.0884342193603516
Validation loss: 1.990895830174928

Epoch: 6| Step: 11
Training loss: 2.305245876312256
Validation loss: 1.9656217559691398

Epoch: 6| Step: 12
Training loss: 1.2553218603134155
Validation loss: 1.9677312950934134

Epoch: 6| Step: 13
Training loss: 1.7131223678588867
Validation loss: 1.9604219185408724

Epoch: 286| Step: 0
Training loss: 1.4322937726974487
Validation loss: 1.9551589296710106

Epoch: 6| Step: 1
Training loss: 1.3920503854751587
Validation loss: 1.9483149769485637

Epoch: 6| Step: 2
Training loss: 2.0195255279541016
Validation loss: 1.9606445348390968

Epoch: 6| Step: 3
Training loss: 1.40863037109375
Validation loss: 1.9905163805971864

Epoch: 6| Step: 4
Training loss: 1.5860390663146973
Validation loss: 1.9639642392435381

Epoch: 6| Step: 5
Training loss: 1.375612497329712
Validation loss: 1.9763930689903997

Epoch: 6| Step: 6
Training loss: 1.484447956085205
Validation loss: 1.9925947048330819

Epoch: 6| Step: 7
Training loss: 1.6051193475723267
Validation loss: 1.9778335837907688

Epoch: 6| Step: 8
Training loss: 1.9146908521652222
Validation loss: 1.9605622881202287

Epoch: 6| Step: 9
Training loss: 1.43514084815979
Validation loss: 1.9825755434651529

Epoch: 6| Step: 10
Training loss: 1.2110443115234375
Validation loss: 1.9912363611241823

Epoch: 6| Step: 11
Training loss: 1.4743456840515137
Validation loss: 1.9638589364226147

Epoch: 6| Step: 12
Training loss: 0.8929544687271118
Validation loss: 1.9645555750016244

Epoch: 6| Step: 13
Training loss: 1.4741148948669434
Validation loss: 1.954959318202029

Epoch: 287| Step: 0
Training loss: 1.248401165008545
Validation loss: 1.9511766882352932

Epoch: 6| Step: 1
Training loss: 2.2802774906158447
Validation loss: 1.9653974361317132

Epoch: 6| Step: 2
Training loss: 1.947950839996338
Validation loss: 1.983826078394408

Epoch: 6| Step: 3
Training loss: 1.2238564491271973
Validation loss: 1.9824758396353772

Epoch: 6| Step: 4
Training loss: 0.9717852473258972
Validation loss: 1.9956444283967376

Epoch: 6| Step: 5
Training loss: 1.6629348993301392
Validation loss: 2.0137156619820544

Epoch: 6| Step: 6
Training loss: 1.0585302114486694
Validation loss: 2.0156803105467107

Epoch: 6| Step: 7
Training loss: 1.505402684211731
Validation loss: 2.0284550625790834

Epoch: 6| Step: 8
Training loss: 1.4140193462371826
Validation loss: 1.996122899875846

Epoch: 6| Step: 9
Training loss: 1.5698943138122559
Validation loss: 1.9842272932811449

Epoch: 6| Step: 10
Training loss: 1.1209839582443237
Validation loss: 1.9708968618864655

Epoch: 6| Step: 11
Training loss: 1.388502836227417
Validation loss: 1.9553160462328183

Epoch: 6| Step: 12
Training loss: 1.437363862991333
Validation loss: 1.9350209364327051

Epoch: 6| Step: 13
Training loss: 1.5730032920837402
Validation loss: 1.9412267477281633

Epoch: 288| Step: 0
Training loss: 0.8275831937789917
Validation loss: 1.9375013766750213

Epoch: 6| Step: 1
Training loss: 1.4083466529846191
Validation loss: 1.9548333242375364

Epoch: 6| Step: 2
Training loss: 1.1202600002288818
Validation loss: 1.9581756617433281

Epoch: 6| Step: 3
Training loss: 1.8707196712493896
Validation loss: 1.9620397026820848

Epoch: 6| Step: 4
Training loss: 1.5467712879180908
Validation loss: 1.9675138253037647

Epoch: 6| Step: 5
Training loss: 1.50173020362854
Validation loss: 1.9515254997438

Epoch: 6| Step: 6
Training loss: 1.0133546590805054
Validation loss: 1.9468667481535225

Epoch: 6| Step: 7
Training loss: 1.3881303071975708
Validation loss: 1.9464768607129332

Epoch: 6| Step: 8
Training loss: 1.7517623901367188
Validation loss: 1.9485531673636487

Epoch: 6| Step: 9
Training loss: 2.071563720703125
Validation loss: 1.9775491606804632

Epoch: 6| Step: 10
Training loss: 1.4148871898651123
Validation loss: 1.9681536074607604

Epoch: 6| Step: 11
Training loss: 1.6374257802963257
Validation loss: 1.9731340062233709

Epoch: 6| Step: 12
Training loss: 1.1889474391937256
Validation loss: 1.9921449717654978

Epoch: 6| Step: 13
Training loss: 1.5470362901687622
Validation loss: 2.002422627582345

Epoch: 289| Step: 0
Training loss: 1.3362749814987183
Validation loss: 1.9829677535641579

Epoch: 6| Step: 1
Training loss: 1.219470500946045
Validation loss: 2.0018311649240474

Epoch: 6| Step: 2
Training loss: 1.8894789218902588
Validation loss: 1.9828672844876525

Epoch: 6| Step: 3
Training loss: 1.288966178894043
Validation loss: 1.9712760820183703

Epoch: 6| Step: 4
Training loss: 1.9309678077697754
Validation loss: 1.9731248886354509

Epoch: 6| Step: 5
Training loss: 1.0643973350524902
Validation loss: 1.9495673999991467

Epoch: 6| Step: 6
Training loss: 1.450028896331787
Validation loss: 1.9781345436649937

Epoch: 6| Step: 7
Training loss: 1.1315873861312866
Validation loss: 1.946046265222693

Epoch: 6| Step: 8
Training loss: 1.4646449089050293
Validation loss: 1.9827837944030762

Epoch: 6| Step: 9
Training loss: 1.7653841972351074
Validation loss: 1.976948312533799

Epoch: 6| Step: 10
Training loss: 1.187892198562622
Validation loss: 1.9796354539932743

Epoch: 6| Step: 11
Training loss: 1.5460810661315918
Validation loss: 1.988795623984388

Epoch: 6| Step: 12
Training loss: 1.3734362125396729
Validation loss: 2.0007879413584226

Epoch: 6| Step: 13
Training loss: 2.120035171508789
Validation loss: 2.017565518297175

Epoch: 290| Step: 0
Training loss: 1.247776746749878
Validation loss: 2.017338557909894

Epoch: 6| Step: 1
Training loss: 1.3938822746276855
Validation loss: 1.9829100921589842

Epoch: 6| Step: 2
Training loss: 1.5933125019073486
Validation loss: 1.9702505065548805

Epoch: 6| Step: 3
Training loss: 1.5509313344955444
Validation loss: 1.9718667935299616

Epoch: 6| Step: 4
Training loss: 1.3893898725509644
Validation loss: 1.9765280382607573

Epoch: 6| Step: 5
Training loss: 1.653670310974121
Validation loss: 1.9813081192713913

Epoch: 6| Step: 6
Training loss: 1.5087697505950928
Validation loss: 1.988349655623077

Epoch: 6| Step: 7
Training loss: 1.0643794536590576
Validation loss: 1.9525190194447835

Epoch: 6| Step: 8
Training loss: 1.80281662940979
Validation loss: 1.9497250331345426

Epoch: 6| Step: 9
Training loss: 1.9175065755844116
Validation loss: 1.939432023673929

Epoch: 6| Step: 10
Training loss: 1.3588643074035645
Validation loss: 1.957895314821633

Epoch: 6| Step: 11
Training loss: 1.2307699918746948
Validation loss: 1.9509817977105417

Epoch: 6| Step: 12
Training loss: 1.4637125730514526
Validation loss: 1.9559486796779018

Epoch: 6| Step: 13
Training loss: 0.5532543659210205
Validation loss: 1.9595760453131892

Epoch: 291| Step: 0
Training loss: 1.4129648208618164
Validation loss: 1.9394449854409823

Epoch: 6| Step: 1
Training loss: 1.3101069927215576
Validation loss: 1.9311985431178924

Epoch: 6| Step: 2
Training loss: 1.1569428443908691
Validation loss: 1.9475931595730525

Epoch: 6| Step: 3
Training loss: 1.353501796722412
Validation loss: 1.9594898813514299

Epoch: 6| Step: 4
Training loss: 0.8257837891578674
Validation loss: 1.9767888528044506

Epoch: 6| Step: 5
Training loss: 1.937303066253662
Validation loss: 1.9579752414457259

Epoch: 6| Step: 6
Training loss: 1.386664867401123
Validation loss: 1.9882657169013895

Epoch: 6| Step: 7
Training loss: 1.5313432216644287
Validation loss: 1.962314505730906

Epoch: 6| Step: 8
Training loss: 1.6328315734863281
Validation loss: 1.9641185114460606

Epoch: 6| Step: 9
Training loss: 1.9104812145233154
Validation loss: 1.9506308776076122

Epoch: 6| Step: 10
Training loss: 1.7174227237701416
Validation loss: 1.9688116376117994

Epoch: 6| Step: 11
Training loss: 1.2256355285644531
Validation loss: 1.9738466457654071

Epoch: 6| Step: 12
Training loss: 1.0840858221054077
Validation loss: 1.9514141492946173

Epoch: 6| Step: 13
Training loss: 1.6337647438049316
Validation loss: 1.9523904733760382

Epoch: 292| Step: 0
Training loss: 1.7946243286132812
Validation loss: 1.9768597541316864

Epoch: 6| Step: 1
Training loss: 0.946350634098053
Validation loss: 1.9707477528561828

Epoch: 6| Step: 2
Training loss: 1.5836081504821777
Validation loss: 1.9854127886474773

Epoch: 6| Step: 3
Training loss: 1.19189453125
Validation loss: 1.9890937728266562

Epoch: 6| Step: 4
Training loss: 1.5595935583114624
Validation loss: 1.9709757733088669

Epoch: 6| Step: 5
Training loss: 2.0296857357025146
Validation loss: 1.9857697794514317

Epoch: 6| Step: 6
Training loss: 1.4436438083648682
Validation loss: 1.9958650014733756

Epoch: 6| Step: 7
Training loss: 1.44472074508667
Validation loss: 2.020547438693303

Epoch: 6| Step: 8
Training loss: 1.4146103858947754
Validation loss: 2.0137838086774273

Epoch: 6| Step: 9
Training loss: 1.0689219236373901
Validation loss: 1.9995897636618665

Epoch: 6| Step: 10
Training loss: 1.3852512836456299
Validation loss: 1.9915637175242107

Epoch: 6| Step: 11
Training loss: 1.4713642597198486
Validation loss: 1.987251086901593

Epoch: 6| Step: 12
Training loss: 1.6874699592590332
Validation loss: 1.9892245736173404

Epoch: 6| Step: 13
Training loss: 1.1573617458343506
Validation loss: 1.9400030669345651

Epoch: 293| Step: 0
Training loss: 1.0877140760421753
Validation loss: 1.949208200618785

Epoch: 6| Step: 1
Training loss: 1.4493612051010132
Validation loss: 1.9627857054433515

Epoch: 6| Step: 2
Training loss: 0.876105785369873
Validation loss: 1.9774871257043654

Epoch: 6| Step: 3
Training loss: 2.190908193588257
Validation loss: 1.9610690237373434

Epoch: 6| Step: 4
Training loss: 1.8642126321792603
Validation loss: 1.9833407555857012

Epoch: 6| Step: 5
Training loss: 1.8554385900497437
Validation loss: 1.9909024956405803

Epoch: 6| Step: 6
Training loss: 0.8607447743415833
Validation loss: 1.9827672845573836

Epoch: 6| Step: 7
Training loss: 1.2567012310028076
Validation loss: 1.9739073745666011

Epoch: 6| Step: 8
Training loss: 1.3507760763168335
Validation loss: 1.9542057668009112

Epoch: 6| Step: 9
Training loss: 1.6579151153564453
Validation loss: 1.9719987710316975

Epoch: 6| Step: 10
Training loss: 1.3664054870605469
Validation loss: 1.9604449182428338

Epoch: 6| Step: 11
Training loss: 1.222486972808838
Validation loss: 1.9387045624435588

Epoch: 6| Step: 12
Training loss: 1.0120267868041992
Validation loss: 1.9350724502276349

Epoch: 6| Step: 13
Training loss: 2.0501644611358643
Validation loss: 1.9480117726069626

Epoch: 294| Step: 0
Training loss: 1.670398473739624
Validation loss: 1.9236967717447588

Epoch: 6| Step: 1
Training loss: 1.3635060787200928
Validation loss: 1.9263612070391256

Epoch: 6| Step: 2
Training loss: 2.1541309356689453
Validation loss: 1.9147286902191818

Epoch: 6| Step: 3
Training loss: 1.3348217010498047
Validation loss: 1.9277657744705037

Epoch: 6| Step: 4
Training loss: 1.2735037803649902
Validation loss: 1.9163166117924515

Epoch: 6| Step: 5
Training loss: 1.2791976928710938
Validation loss: 1.8961831446616881

Epoch: 6| Step: 6
Training loss: 1.2500933408737183
Validation loss: 1.9518005155747937

Epoch: 6| Step: 7
Training loss: 1.2176148891448975
Validation loss: 1.9195274973428378

Epoch: 6| Step: 8
Training loss: 1.323458194732666
Validation loss: 1.951232575601147

Epoch: 6| Step: 9
Training loss: 1.2152810096740723
Validation loss: 1.944674486755043

Epoch: 6| Step: 10
Training loss: 1.4215154647827148
Validation loss: 1.9765902565371605

Epoch: 6| Step: 11
Training loss: 1.8587594032287598
Validation loss: 1.9663440681272937

Epoch: 6| Step: 12
Training loss: 1.227110743522644
Validation loss: 1.9817684401748001

Epoch: 6| Step: 13
Training loss: 1.0453323125839233
Validation loss: 1.9915797197690575

Epoch: 295| Step: 0
Training loss: 1.7640652656555176
Validation loss: 1.9518058633291593

Epoch: 6| Step: 1
Training loss: 1.313358187675476
Validation loss: 1.9564404410700644

Epoch: 6| Step: 2
Training loss: 1.3229475021362305
Validation loss: 1.940885284895538

Epoch: 6| Step: 3
Training loss: 0.9826481342315674
Validation loss: 1.9363964308974564

Epoch: 6| Step: 4
Training loss: 1.681473731994629
Validation loss: 1.915382791590947

Epoch: 6| Step: 5
Training loss: 1.3107330799102783
Validation loss: 1.95552703385712

Epoch: 6| Step: 6
Training loss: 1.9410920143127441
Validation loss: 1.952571399750248

Epoch: 6| Step: 7
Training loss: 1.0927234888076782
Validation loss: 1.9255334613143757

Epoch: 6| Step: 8
Training loss: 1.475793719291687
Validation loss: 1.9467723754144484

Epoch: 6| Step: 9
Training loss: 1.479101300239563
Validation loss: 1.9491894296420518

Epoch: 6| Step: 10
Training loss: 1.4527151584625244
Validation loss: 1.948724994095423

Epoch: 6| Step: 11
Training loss: 1.581608533859253
Validation loss: 1.9321167161387782

Epoch: 6| Step: 12
Training loss: 0.7883754968643188
Validation loss: 1.9172463737508303

Epoch: 6| Step: 13
Training loss: 1.6950145959854126
Validation loss: 1.9402069507106658

Epoch: 296| Step: 0
Training loss: 1.2328212261199951
Validation loss: 1.9297456536241757

Epoch: 6| Step: 1
Training loss: 1.509591817855835
Validation loss: 1.9286509611273324

Epoch: 6| Step: 2
Training loss: 1.7111902236938477
Validation loss: 1.9564347908061037

Epoch: 6| Step: 3
Training loss: 1.3531261682510376
Validation loss: 1.962578110797431

Epoch: 6| Step: 4
Training loss: 0.9453843832015991
Validation loss: 1.9703166779651438

Epoch: 6| Step: 5
Training loss: 1.8721034526824951
Validation loss: 1.9989825205136371

Epoch: 6| Step: 6
Training loss: 1.65224289894104
Validation loss: 2.019022262224587

Epoch: 6| Step: 7
Training loss: 0.836505115032196
Validation loss: 2.0020510329995105

Epoch: 6| Step: 8
Training loss: 1.4909909963607788
Validation loss: 1.990457591190133

Epoch: 6| Step: 9
Training loss: 1.5285696983337402
Validation loss: 1.9716554252050256

Epoch: 6| Step: 10
Training loss: 1.9309229850769043
Validation loss: 1.9742798587327361

Epoch: 6| Step: 11
Training loss: 1.1862761974334717
Validation loss: 1.918383744455153

Epoch: 6| Step: 12
Training loss: 1.137312889099121
Validation loss: 1.9188355515080113

Epoch: 6| Step: 13
Training loss: 1.1306416988372803
Validation loss: 1.8919204435040873

Epoch: 297| Step: 0
Training loss: 1.6631801128387451
Validation loss: 1.8790901219973

Epoch: 6| Step: 1
Training loss: 1.2265324592590332
Validation loss: 1.871299414224522

Epoch: 6| Step: 2
Training loss: 1.5781543254852295
Validation loss: 1.8847992292014502

Epoch: 6| Step: 3
Training loss: 1.441763162612915
Validation loss: 1.8527412337641562

Epoch: 6| Step: 4
Training loss: 1.3112971782684326
Validation loss: 1.8763209914648404

Epoch: 6| Step: 5
Training loss: 1.3403799533843994
Validation loss: 1.903872803975177

Epoch: 6| Step: 6
Training loss: 1.0247385501861572
Validation loss: 1.9152186801356654

Epoch: 6| Step: 7
Training loss: 1.621370792388916
Validation loss: 1.965049502670124

Epoch: 6| Step: 8
Training loss: 1.5710864067077637
Validation loss: 1.9490908397141324

Epoch: 6| Step: 9
Training loss: 1.3439356088638306
Validation loss: 1.9565715571885467

Epoch: 6| Step: 10
Training loss: 1.4249567985534668
Validation loss: 1.9357856960706814

Epoch: 6| Step: 11
Training loss: 1.83269464969635
Validation loss: 1.9350860067593154

Epoch: 6| Step: 12
Training loss: 1.2066739797592163
Validation loss: 1.9437161478945004

Epoch: 6| Step: 13
Training loss: 1.4378899335861206
Validation loss: 1.9217894436210714

Epoch: 298| Step: 0
Training loss: 1.421992540359497
Validation loss: 1.9257845801691855

Epoch: 6| Step: 1
Training loss: 1.207374095916748
Validation loss: 1.9295788823917348

Epoch: 6| Step: 2
Training loss: 0.9269523620605469
Validation loss: 1.918751576895355

Epoch: 6| Step: 3
Training loss: 1.8795781135559082
Validation loss: 1.885865044850175

Epoch: 6| Step: 4
Training loss: 1.7558338642120361
Validation loss: 1.881446256432482

Epoch: 6| Step: 5
Training loss: 1.254647970199585
Validation loss: 1.8902847151602469

Epoch: 6| Step: 6
Training loss: 1.65205979347229
Validation loss: 1.9085801903919508

Epoch: 6| Step: 7
Training loss: 1.310827612876892
Validation loss: 1.9224003566208707

Epoch: 6| Step: 8
Training loss: 1.1818151473999023
Validation loss: 1.95541246732076

Epoch: 6| Step: 9
Training loss: 1.0567724704742432
Validation loss: 1.9705258133590862

Epoch: 6| Step: 10
Training loss: 1.1758525371551514
Validation loss: 1.941232967120345

Epoch: 6| Step: 11
Training loss: 1.7802422046661377
Validation loss: 1.9637775985143517

Epoch: 6| Step: 12
Training loss: 1.238787055015564
Validation loss: 1.9683625249452488

Epoch: 6| Step: 13
Training loss: 2.0786972045898438
Validation loss: 1.988839114865949

Epoch: 299| Step: 0
Training loss: 1.5821514129638672
Validation loss: 2.0331997307397986

Epoch: 6| Step: 1
Training loss: 1.2050855159759521
Validation loss: 2.0353939174323954

Epoch: 6| Step: 2
Training loss: 1.625715732574463
Validation loss: 1.9754194662135134

Epoch: 6| Step: 3
Training loss: 1.5548948049545288
Validation loss: 1.9535647617873324

Epoch: 6| Step: 4
Training loss: 1.2398762702941895
Validation loss: 1.9519743150280369

Epoch: 6| Step: 5
Training loss: 1.1048321723937988
Validation loss: 1.9478574465679865

Epoch: 6| Step: 6
Training loss: 1.7485052347183228
Validation loss: 1.9508056486806562

Epoch: 6| Step: 7
Training loss: 1.1116585731506348
Validation loss: 1.9169316919901038

Epoch: 6| Step: 8
Training loss: 1.422650694847107
Validation loss: 1.9076697236748152

Epoch: 6| Step: 9
Training loss: 1.093681812286377
Validation loss: 1.8887129291411369

Epoch: 6| Step: 10
Training loss: 1.4636614322662354
Validation loss: 1.9028470157295145

Epoch: 6| Step: 11
Training loss: 1.3985872268676758
Validation loss: 1.9009509996701313

Epoch: 6| Step: 12
Training loss: 1.4898420572280884
Validation loss: 1.9024942664689914

Epoch: 6| Step: 13
Training loss: 2.1604433059692383
Validation loss: 1.9313150195665256

Epoch: 300| Step: 0
Training loss: 1.1643478870391846
Validation loss: 1.9225459624362249

Epoch: 6| Step: 1
Training loss: 1.3828413486480713
Validation loss: 1.9404593616403558

Epoch: 6| Step: 2
Training loss: 1.332220435142517
Validation loss: 1.9817987090797835

Epoch: 6| Step: 3
Training loss: 1.6049855947494507
Validation loss: 1.9646782926333848

Epoch: 6| Step: 4
Training loss: 0.8063474893569946
Validation loss: 1.9311837355295818

Epoch: 6| Step: 5
Training loss: 1.4267244338989258
Validation loss: 1.9560765784273866

Epoch: 6| Step: 6
Training loss: 1.6922541856765747
Validation loss: 1.9349723272426154

Epoch: 6| Step: 7
Training loss: 1.3129181861877441
Validation loss: 1.9307975769042969

Epoch: 6| Step: 8
Training loss: 1.2957143783569336
Validation loss: 1.9289717123072634

Epoch: 6| Step: 9
Training loss: 1.6109532117843628
Validation loss: 1.93492692260332

Epoch: 6| Step: 10
Training loss: 1.2900290489196777
Validation loss: 1.9207451446082002

Epoch: 6| Step: 11
Training loss: 1.6220695972442627
Validation loss: 1.9076457561985138

Epoch: 6| Step: 12
Training loss: 1.2053916454315186
Validation loss: 1.8811449927668418

Epoch: 6| Step: 13
Training loss: 1.5077205896377563
Validation loss: 1.8826384377735916

Epoch: 301| Step: 0
Training loss: 0.7576389312744141
Validation loss: 1.8778544420837073

Epoch: 6| Step: 1
Training loss: 1.6213401556015015
Validation loss: 1.894010882223806

Epoch: 6| Step: 2
Training loss: 1.6770758628845215
Validation loss: 1.90324818447072

Epoch: 6| Step: 3
Training loss: 1.9248285293579102
Validation loss: 1.9032379401627408

Epoch: 6| Step: 4
Training loss: 2.1436424255371094
Validation loss: 1.9194279614315237

Epoch: 6| Step: 5
Training loss: 1.25685715675354
Validation loss: 1.9590885152098954

Epoch: 6| Step: 6
Training loss: 1.4928908348083496
Validation loss: 1.9697711480561124

Epoch: 6| Step: 7
Training loss: 1.1374033689498901
Validation loss: 1.9442507887399325

Epoch: 6| Step: 8
Training loss: 1.112381935119629
Validation loss: 1.9528626395810036

Epoch: 6| Step: 9
Training loss: 1.2601065635681152
Validation loss: 1.9360258438253914

Epoch: 6| Step: 10
Training loss: 1.130589485168457
Validation loss: 1.946869368194252

Epoch: 6| Step: 11
Training loss: 1.3807365894317627
Validation loss: 1.9566488317264024

Epoch: 6| Step: 12
Training loss: 1.5667634010314941
Validation loss: 1.9233812478280836

Epoch: 6| Step: 13
Training loss: 0.34092235565185547
Validation loss: 1.9095958022661106

Epoch: 302| Step: 0
Training loss: 1.3480417728424072
Validation loss: 1.9013075661915604

Epoch: 6| Step: 1
Training loss: 1.5320301055908203
Validation loss: 1.8867686910013999

Epoch: 6| Step: 2
Training loss: 1.0348414182662964
Validation loss: 1.8927894997340378

Epoch: 6| Step: 3
Training loss: 1.5607916116714478
Validation loss: 1.8775380683201615

Epoch: 6| Step: 4
Training loss: 1.3257768154144287
Validation loss: 1.9026699822436097

Epoch: 6| Step: 5
Training loss: 1.512864589691162
Validation loss: 1.8858807791945755

Epoch: 6| Step: 6
Training loss: 1.8666164875030518
Validation loss: 1.9130426683733541

Epoch: 6| Step: 7
Training loss: 1.417067527770996
Validation loss: 1.8781170114394157

Epoch: 6| Step: 8
Training loss: 1.2411946058273315
Validation loss: 1.893210877654373

Epoch: 6| Step: 9
Training loss: 0.856586217880249
Validation loss: 1.917541819234048

Epoch: 6| Step: 10
Training loss: 1.1393135786056519
Validation loss: 1.9163579838250273

Epoch: 6| Step: 11
Training loss: 1.0119317770004272
Validation loss: 1.9346901524451472

Epoch: 6| Step: 12
Training loss: 1.7441643476486206
Validation loss: 1.916364360881108

Epoch: 6| Step: 13
Training loss: 1.238357663154602
Validation loss: 1.8923618614032705

Epoch: 303| Step: 0
Training loss: 1.023282527923584
Validation loss: 1.9058710259775962

Epoch: 6| Step: 1
Training loss: 1.0896424055099487
Validation loss: 1.9019526076573197

Epoch: 6| Step: 2
Training loss: 1.2338600158691406
Validation loss: 1.9153758197702386

Epoch: 6| Step: 3
Training loss: 1.9036478996276855
Validation loss: 1.9142460823059082

Epoch: 6| Step: 4
Training loss: 1.3415311574935913
Validation loss: 1.934367032461269

Epoch: 6| Step: 5
Training loss: 0.8389614820480347
Validation loss: 1.9449124566970333

Epoch: 6| Step: 6
Training loss: 1.8022754192352295
Validation loss: 1.9340191284815471

Epoch: 6| Step: 7
Training loss: 0.45453208684921265
Validation loss: 1.9484170329186223

Epoch: 6| Step: 8
Training loss: 1.0693086385726929
Validation loss: 1.929587907688592

Epoch: 6| Step: 9
Training loss: 1.6311821937561035
Validation loss: 1.9220438029176445

Epoch: 6| Step: 10
Training loss: 1.9416489601135254
Validation loss: 1.9115792269347816

Epoch: 6| Step: 11
Training loss: 1.729414939880371
Validation loss: 1.8855187662186161

Epoch: 6| Step: 12
Training loss: 1.3830723762512207
Validation loss: 1.8826874904735114

Epoch: 6| Step: 13
Training loss: 1.1766326427459717
Validation loss: 1.8853447475740988

Epoch: 304| Step: 0
Training loss: 1.5146633386611938
Validation loss: 1.8984914005443614

Epoch: 6| Step: 1
Training loss: 1.3197968006134033
Validation loss: 1.883224110449514

Epoch: 6| Step: 2
Training loss: 1.1823735237121582
Validation loss: 1.890038094212932

Epoch: 6| Step: 3
Training loss: 1.642990231513977
Validation loss: 1.899986103016843

Epoch: 6| Step: 4
Training loss: 0.983217716217041
Validation loss: 1.9153632451129217

Epoch: 6| Step: 5
Training loss: 1.0204119682312012
Validation loss: 1.918166196474465

Epoch: 6| Step: 6
Training loss: 1.2321583032608032
Validation loss: 1.9237024309814617

Epoch: 6| Step: 7
Training loss: 1.7001709938049316
Validation loss: 1.951199923792193

Epoch: 6| Step: 8
Training loss: 1.8531560897827148
Validation loss: 1.9594308125075472

Epoch: 6| Step: 9
Training loss: 1.4094345569610596
Validation loss: 1.976216140613761

Epoch: 6| Step: 10
Training loss: 1.4713177680969238
Validation loss: 1.9894365187614196

Epoch: 6| Step: 11
Training loss: 0.8037890195846558
Validation loss: 1.9666282182098718

Epoch: 6| Step: 12
Training loss: 1.2853307723999023
Validation loss: 1.9862259126478625

Epoch: 6| Step: 13
Training loss: 1.4037437438964844
Validation loss: 1.9227800933263635

Epoch: 305| Step: 0
Training loss: 1.5018870830535889
Validation loss: 1.9320382841171757

Epoch: 6| Step: 1
Training loss: 0.8339322209358215
Validation loss: 1.9063194836339643

Epoch: 6| Step: 2
Training loss: 1.6007648706436157
Validation loss: 1.9459366362581971

Epoch: 6| Step: 3
Training loss: 0.8932942748069763
Validation loss: 1.9183268662421935

Epoch: 6| Step: 4
Training loss: 1.968425989151001
Validation loss: 1.9278309678518644

Epoch: 6| Step: 5
Training loss: 0.9977726936340332
Validation loss: 1.9237774341337142

Epoch: 6| Step: 6
Training loss: 1.8234808444976807
Validation loss: 1.917648699975783

Epoch: 6| Step: 7
Training loss: 1.2732017040252686
Validation loss: 1.9378613502748552

Epoch: 6| Step: 8
Training loss: 1.1136481761932373
Validation loss: 1.9152040558476602

Epoch: 6| Step: 9
Training loss: 0.8759783506393433
Validation loss: 1.9600138869336856

Epoch: 6| Step: 10
Training loss: 0.914867639541626
Validation loss: 1.9846147683358961

Epoch: 6| Step: 11
Training loss: 1.6404659748077393
Validation loss: 2.002233987213463

Epoch: 6| Step: 12
Training loss: 1.604923963546753
Validation loss: 2.011475269512464

Epoch: 6| Step: 13
Training loss: 2.0465333461761475
Validation loss: 1.9786890757981168

Epoch: 306| Step: 0
Training loss: 1.1224902868270874
Validation loss: 1.9549592489837317

Epoch: 6| Step: 1
Training loss: 1.3294378519058228
Validation loss: 1.9566527117965042

Epoch: 6| Step: 2
Training loss: 1.2631423473358154
Validation loss: 1.9766501560006091

Epoch: 6| Step: 3
Training loss: 0.901865541934967
Validation loss: 1.9542585175524476

Epoch: 6| Step: 4
Training loss: 1.3770577907562256
Validation loss: 1.9074751074596117

Epoch: 6| Step: 5
Training loss: 1.2075742483139038
Validation loss: 1.9144997981286818

Epoch: 6| Step: 6
Training loss: 1.2343477010726929
Validation loss: 1.9217341574289466

Epoch: 6| Step: 7
Training loss: 1.4835244417190552
Validation loss: 1.9052562918714298

Epoch: 6| Step: 8
Training loss: 1.408198356628418
Validation loss: 1.9177491049612723

Epoch: 6| Step: 9
Training loss: 1.309532642364502
Validation loss: 1.922690583813575

Epoch: 6| Step: 10
Training loss: 1.564000129699707
Validation loss: 1.9245822634748233

Epoch: 6| Step: 11
Training loss: 1.4208765029907227
Validation loss: 1.9226993540281891

Epoch: 6| Step: 12
Training loss: 2.0170764923095703
Validation loss: 1.9320823274632937

Epoch: 6| Step: 13
Training loss: 1.3667958974838257
Validation loss: 1.9225362398291146

Epoch: 307| Step: 0
Training loss: 1.9618961811065674
Validation loss: 1.9456076904009747

Epoch: 6| Step: 1
Training loss: 1.042117714881897
Validation loss: 1.9180017466186194

Epoch: 6| Step: 2
Training loss: 1.062205195426941
Validation loss: 1.927727694152504

Epoch: 6| Step: 3
Training loss: 0.999723494052887
Validation loss: 1.9287694141428957

Epoch: 6| Step: 4
Training loss: 1.5047714710235596
Validation loss: 1.9115663895042994

Epoch: 6| Step: 5
Training loss: 0.995232880115509
Validation loss: 1.9296046674892466

Epoch: 6| Step: 6
Training loss: 1.8203142881393433
Validation loss: 1.9403807834912372

Epoch: 6| Step: 7
Training loss: 1.0629432201385498
Validation loss: 1.957192999060436

Epoch: 6| Step: 8
Training loss: 1.6153011322021484
Validation loss: 1.921884705943446

Epoch: 6| Step: 9
Training loss: 1.0136502981185913
Validation loss: 1.9119510599361953

Epoch: 6| Step: 10
Training loss: 1.792510986328125
Validation loss: 1.9211580420053134

Epoch: 6| Step: 11
Training loss: 1.4115005731582642
Validation loss: 1.9079226268235074

Epoch: 6| Step: 12
Training loss: 1.0237131118774414
Validation loss: 1.923624143805555

Epoch: 6| Step: 13
Training loss: 1.1663060188293457
Validation loss: 1.955741895142422

Epoch: 308| Step: 0
Training loss: 1.5668200254440308
Validation loss: 1.9737304513172438

Epoch: 6| Step: 1
Training loss: 1.4507472515106201
Validation loss: 1.9832519241558608

Epoch: 6| Step: 2
Training loss: 1.0978217124938965
Validation loss: 2.025935842144874

Epoch: 6| Step: 3
Training loss: 1.3243372440338135
Validation loss: 2.0200844208399453

Epoch: 6| Step: 4
Training loss: 0.7824388742446899
Validation loss: 1.9974361824732956

Epoch: 6| Step: 5
Training loss: 1.3280220031738281
Validation loss: 1.9942905402952624

Epoch: 6| Step: 6
Training loss: 1.0780518054962158
Validation loss: 1.9396394760377946

Epoch: 6| Step: 7
Training loss: 1.2989343404769897
Validation loss: 1.91179153227037

Epoch: 6| Step: 8
Training loss: 1.3653956651687622
Validation loss: 1.9309235785597114

Epoch: 6| Step: 9
Training loss: 1.2922461032867432
Validation loss: 1.9217357148406327

Epoch: 6| Step: 10
Training loss: 1.7009756565093994
Validation loss: 1.9126393064375846

Epoch: 6| Step: 11
Training loss: 1.6901965141296387
Validation loss: 1.8622865779425508

Epoch: 6| Step: 12
Training loss: 1.6462087631225586
Validation loss: 1.882722523904616

Epoch: 6| Step: 13
Training loss: 0.9067984819412231
Validation loss: 1.8813747000950638

Epoch: 309| Step: 0
Training loss: 1.105823278427124
Validation loss: 1.9073631507094189

Epoch: 6| Step: 1
Training loss: 1.5057233572006226
Validation loss: 1.8973870995224162

Epoch: 6| Step: 2
Training loss: 1.922893762588501
Validation loss: 1.902167736843068

Epoch: 6| Step: 3
Training loss: 1.0627349615097046
Validation loss: 1.9012211433020971

Epoch: 6| Step: 4
Training loss: 1.2045104503631592
Validation loss: 1.9056135736485964

Epoch: 6| Step: 5
Training loss: 1.8322131633758545
Validation loss: 1.9364438223582443

Epoch: 6| Step: 6
Training loss: 1.1497105360031128
Validation loss: 1.917240976005472

Epoch: 6| Step: 7
Training loss: 1.2708507776260376
Validation loss: 1.9232083225762973

Epoch: 6| Step: 8
Training loss: 1.5233728885650635
Validation loss: 1.9194943238330144

Epoch: 6| Step: 9
Training loss: 0.8488704562187195
Validation loss: 1.9310172168157433

Epoch: 6| Step: 10
Training loss: 0.9965699911117554
Validation loss: 1.9508100786516744

Epoch: 6| Step: 11
Training loss: 1.603872537612915
Validation loss: 1.9308002533451203

Epoch: 6| Step: 12
Training loss: 1.3202283382415771
Validation loss: 1.920916481684613

Epoch: 6| Step: 13
Training loss: 0.7405142188072205
Validation loss: 1.9107638879488873

Epoch: 310| Step: 0
Training loss: 1.230465292930603
Validation loss: 1.8760487212929675

Epoch: 6| Step: 1
Training loss: 1.483163595199585
Validation loss: 1.8633135980175388

Epoch: 6| Step: 2
Training loss: 1.2695130109786987
Validation loss: 1.877860910149031

Epoch: 6| Step: 3
Training loss: 0.6716985702514648
Validation loss: 1.8924051202753538

Epoch: 6| Step: 4
Training loss: 1.0301234722137451
Validation loss: 1.8796489366921045

Epoch: 6| Step: 5
Training loss: 1.40610671043396
Validation loss: 1.8922821398704284

Epoch: 6| Step: 6
Training loss: 1.3074333667755127
Validation loss: 1.9016062264801354

Epoch: 6| Step: 7
Training loss: 1.709264874458313
Validation loss: 1.9250978731339978

Epoch: 6| Step: 8
Training loss: 1.4012383222579956
Validation loss: 1.9328464333729078

Epoch: 6| Step: 9
Training loss: 1.3983652591705322
Validation loss: 1.9370009360774871

Epoch: 6| Step: 10
Training loss: 1.5594464540481567
Validation loss: 1.9036157592650382

Epoch: 6| Step: 11
Training loss: 1.5012340545654297
Validation loss: 1.8864978385227982

Epoch: 6| Step: 12
Training loss: 1.6086941957473755
Validation loss: 1.910433292388916

Epoch: 6| Step: 13
Training loss: 0.6221181154251099
Validation loss: 1.9124698767098047

Epoch: 311| Step: 0
Training loss: 1.0914580821990967
Validation loss: 1.9069089312707224

Epoch: 6| Step: 1
Training loss: 1.5054576396942139
Validation loss: 1.8805597841098745

Epoch: 6| Step: 2
Training loss: 0.7160423994064331
Validation loss: 1.9118670430234683

Epoch: 6| Step: 3
Training loss: 1.631885290145874
Validation loss: 1.9318341798679803

Epoch: 6| Step: 4
Training loss: 1.5710256099700928
Validation loss: 1.9142896308693835

Epoch: 6| Step: 5
Training loss: 1.304131269454956
Validation loss: 1.8929118879379765

Epoch: 6| Step: 6
Training loss: 1.5200361013412476
Validation loss: 1.926162983781548

Epoch: 6| Step: 7
Training loss: 1.5897974967956543
Validation loss: 1.9113605406976515

Epoch: 6| Step: 8
Training loss: 1.8076894283294678
Validation loss: 1.920649742567411

Epoch: 6| Step: 9
Training loss: 0.727288544178009
Validation loss: 1.9111619892940725

Epoch: 6| Step: 10
Training loss: 0.9220422506332397
Validation loss: 1.9439533141351515

Epoch: 6| Step: 11
Training loss: 1.2537355422973633
Validation loss: 1.9307814234046525

Epoch: 6| Step: 12
Training loss: 1.2176570892333984
Validation loss: 1.9177726199550014

Epoch: 6| Step: 13
Training loss: 1.6492905616760254
Validation loss: 1.9430356820424397

Epoch: 312| Step: 0
Training loss: 1.477018117904663
Validation loss: 1.918447381706648

Epoch: 6| Step: 1
Training loss: 0.9947922825813293
Validation loss: 1.9287077816583778

Epoch: 6| Step: 2
Training loss: 0.8438310623168945
Validation loss: 1.9040665088161346

Epoch: 6| Step: 3
Training loss: 1.197432518005371
Validation loss: 1.8915365819008119

Epoch: 6| Step: 4
Training loss: 1.5831818580627441
Validation loss: 1.8818417287641955

Epoch: 6| Step: 5
Training loss: 1.2734949588775635
Validation loss: 1.8736204870285527

Epoch: 6| Step: 6
Training loss: 1.4644113779067993
Validation loss: 1.8754945570422756

Epoch: 6| Step: 7
Training loss: 1.263091802597046
Validation loss: 1.8746312613128333

Epoch: 6| Step: 8
Training loss: 1.8145534992218018
Validation loss: 1.859140533272938

Epoch: 6| Step: 9
Training loss: 1.2601526975631714
Validation loss: 1.849054277584117

Epoch: 6| Step: 10
Training loss: 0.8886585831642151
Validation loss: 1.860312120888823

Epoch: 6| Step: 11
Training loss: 1.3702497482299805
Validation loss: 1.8570551308252479

Epoch: 6| Step: 12
Training loss: 1.6117304563522339
Validation loss: 1.8702517901697466

Epoch: 6| Step: 13
Training loss: 0.7247728705406189
Validation loss: 1.8783558235373548

Epoch: 313| Step: 0
Training loss: 1.055422067642212
Validation loss: 1.9066292624319754

Epoch: 6| Step: 1
Training loss: 1.2002103328704834
Validation loss: 1.9151056761382728

Epoch: 6| Step: 2
Training loss: 1.6467453241348267
Validation loss: 1.9279202094642065

Epoch: 6| Step: 3
Training loss: 1.7310397624969482
Validation loss: 1.9612973261904973

Epoch: 6| Step: 4
Training loss: 1.475684404373169
Validation loss: 1.9392457290362286

Epoch: 6| Step: 5
Training loss: 1.179811954498291
Validation loss: 1.9607664820968465

Epoch: 6| Step: 6
Training loss: 1.4806103706359863
Validation loss: 1.9442379013184579

Epoch: 6| Step: 7
Training loss: 1.1443700790405273
Validation loss: 1.9832708502328524

Epoch: 6| Step: 8
Training loss: 1.067597508430481
Validation loss: 1.9553767429885043

Epoch: 6| Step: 9
Training loss: 0.9814860820770264
Validation loss: 1.9423931619172454

Epoch: 6| Step: 10
Training loss: 1.0024197101593018
Validation loss: 1.9055141146465013

Epoch: 6| Step: 11
Training loss: 1.5390387773513794
Validation loss: 1.9144883976187757

Epoch: 6| Step: 12
Training loss: 1.611210584640503
Validation loss: 1.8915074948341615

Epoch: 6| Step: 13
Training loss: 0.6316158771514893
Validation loss: 1.9017918878985989

Epoch: 314| Step: 0
Training loss: 1.721800446510315
Validation loss: 1.91355247523195

Epoch: 6| Step: 1
Training loss: 1.8353056907653809
Validation loss: 1.9162394064728931

Epoch: 6| Step: 2
Training loss: 1.147921085357666
Validation loss: 1.9094163884398758

Epoch: 6| Step: 3
Training loss: 1.6225380897521973
Validation loss: 1.9274317218411354

Epoch: 6| Step: 4
Training loss: 1.202277421951294
Validation loss: 1.9034756460497457

Epoch: 6| Step: 5
Training loss: 0.9091091156005859
Validation loss: 1.8793005507479432

Epoch: 6| Step: 6
Training loss: 1.7134557962417603
Validation loss: 1.8970921142126924

Epoch: 6| Step: 7
Training loss: 1.4918279647827148
Validation loss: 1.90272230486716

Epoch: 6| Step: 8
Training loss: 1.029860019683838
Validation loss: 1.9064645562120663

Epoch: 6| Step: 9
Training loss: 1.5148448944091797
Validation loss: 1.948438247044881

Epoch: 6| Step: 10
Training loss: 0.918201744556427
Validation loss: 1.9429488194886075

Epoch: 6| Step: 11
Training loss: 0.7168118953704834
Validation loss: 1.9156643498328425

Epoch: 6| Step: 12
Training loss: 0.6799401044845581
Validation loss: 1.9329307233133624

Epoch: 6| Step: 13
Training loss: 1.310310959815979
Validation loss: 1.917025173864057

Epoch: 315| Step: 0
Training loss: 1.3865137100219727
Validation loss: 1.905370307225053

Epoch: 6| Step: 1
Training loss: 1.1833997964859009
Validation loss: 1.8865977359074417

Epoch: 6| Step: 2
Training loss: 1.4998486042022705
Validation loss: 1.8792316426513016

Epoch: 6| Step: 3
Training loss: 1.494051218032837
Validation loss: 1.8600522869376725

Epoch: 6| Step: 4
Training loss: 1.7852094173431396
Validation loss: 1.8569084367444437

Epoch: 6| Step: 5
Training loss: 0.8618186116218567
Validation loss: 1.838751587816464

Epoch: 6| Step: 6
Training loss: 1.4353327751159668
Validation loss: 1.8331979564441148

Epoch: 6| Step: 7
Training loss: 1.4424476623535156
Validation loss: 1.8518450695981261

Epoch: 6| Step: 8
Training loss: 0.8488882780075073
Validation loss: 1.8622342796735867

Epoch: 6| Step: 9
Training loss: 0.9885287284851074
Validation loss: 1.8551288471427014

Epoch: 6| Step: 10
Training loss: 1.3886373043060303
Validation loss: 1.8564142834755681

Epoch: 6| Step: 11
Training loss: 0.7072646617889404
Validation loss: 1.8777223158908147

Epoch: 6| Step: 12
Training loss: 1.6208851337432861
Validation loss: 1.8937485769230833

Epoch: 6| Step: 13
Training loss: 1.1576428413391113
Validation loss: 1.902283896682083

Epoch: 316| Step: 0
Training loss: 1.4891037940979004
Validation loss: 1.8929984133730653

Epoch: 6| Step: 1
Training loss: 1.7620023488998413
Validation loss: 1.9295188021916214

Epoch: 6| Step: 2
Training loss: 1.3705592155456543
Validation loss: 1.9180072687005485

Epoch: 6| Step: 3
Training loss: 0.8220178484916687
Validation loss: 1.9236681884334934

Epoch: 6| Step: 4
Training loss: 0.9388881325721741
Validation loss: 1.9455541449208413

Epoch: 6| Step: 5
Training loss: 1.3391269445419312
Validation loss: 1.9154715538024902

Epoch: 6| Step: 6
Training loss: 0.933178722858429
Validation loss: 1.8900736378085228

Epoch: 6| Step: 7
Training loss: 1.8707557916641235
Validation loss: 1.913127617169452

Epoch: 6| Step: 8
Training loss: 1.1804437637329102
Validation loss: 1.887052038664459

Epoch: 6| Step: 9
Training loss: 1.052693486213684
Validation loss: 1.8650814102542015

Epoch: 6| Step: 10
Training loss: 0.815234899520874
Validation loss: 1.888545774644421

Epoch: 6| Step: 11
Training loss: 0.9098438024520874
Validation loss: 1.8796197240070631

Epoch: 6| Step: 12
Training loss: 1.3830273151397705
Validation loss: 1.8754228084318099

Epoch: 6| Step: 13
Training loss: 2.099414348602295
Validation loss: 1.8767218794873965

Epoch: 317| Step: 0
Training loss: 0.9638452529907227
Validation loss: 1.899612493412469

Epoch: 6| Step: 1
Training loss: 1.0524804592132568
Validation loss: 1.8708856887714838

Epoch: 6| Step: 2
Training loss: 1.8536908626556396
Validation loss: 1.891443133354187

Epoch: 6| Step: 3
Training loss: 1.9006755352020264
Validation loss: 1.88140223744095

Epoch: 6| Step: 4
Training loss: 1.4558736085891724
Validation loss: 1.8779348416994976

Epoch: 6| Step: 5
Training loss: 0.6184023022651672
Validation loss: 1.8520250140979726

Epoch: 6| Step: 6
Training loss: 1.1349282264709473
Validation loss: 1.8785126939896615

Epoch: 6| Step: 7
Training loss: 1.6175503730773926
Validation loss: 1.8625608849269089

Epoch: 6| Step: 8
Training loss: 0.9416182637214661
Validation loss: 1.8732245288869387

Epoch: 6| Step: 9
Training loss: 0.9234806299209595
Validation loss: 1.8676722946987356

Epoch: 6| Step: 10
Training loss: 1.3424654006958008
Validation loss: 1.8664457323730632

Epoch: 6| Step: 11
Training loss: 1.2374591827392578
Validation loss: 1.8915414476907382

Epoch: 6| Step: 12
Training loss: 1.462018609046936
Validation loss: 1.882771586859098

Epoch: 6| Step: 13
Training loss: 0.8718158602714539
Validation loss: 1.8850084812410417

Epoch: 318| Step: 0
Training loss: 1.0482380390167236
Validation loss: 1.905459398864418

Epoch: 6| Step: 1
Training loss: 1.204979658126831
Validation loss: 1.9137219946871522

Epoch: 6| Step: 2
Training loss: 1.5066413879394531
Validation loss: 1.9301033673747894

Epoch: 6| Step: 3
Training loss: 1.6339517831802368
Validation loss: 1.958749419899397

Epoch: 6| Step: 4
Training loss: 1.406301498413086
Validation loss: 1.9532137993843324

Epoch: 6| Step: 5
Training loss: 0.7179510593414307
Validation loss: 1.935255963315246

Epoch: 6| Step: 6
Training loss: 1.0860328674316406
Validation loss: 1.885056664866786

Epoch: 6| Step: 7
Training loss: 1.3518723249435425
Validation loss: 1.8629768907382924

Epoch: 6| Step: 8
Training loss: 1.3045203685760498
Validation loss: 1.8766919425738755

Epoch: 6| Step: 9
Training loss: 1.5826694965362549
Validation loss: 1.8653394842660556

Epoch: 6| Step: 10
Training loss: 1.159348964691162
Validation loss: 1.8674948164211806

Epoch: 6| Step: 11
Training loss: 1.070447564125061
Validation loss: 1.8753283382743917

Epoch: 6| Step: 12
Training loss: 1.4746687412261963
Validation loss: 1.8536100964392386

Epoch: 6| Step: 13
Training loss: 0.7059062123298645
Validation loss: 1.879218304029075

Epoch: 319| Step: 0
Training loss: 1.4401335716247559
Validation loss: 1.8606104696950605

Epoch: 6| Step: 1
Training loss: 1.2832658290863037
Validation loss: 1.8551400361522552

Epoch: 6| Step: 2
Training loss: 1.6042402982711792
Validation loss: 1.8547566013951455

Epoch: 6| Step: 3
Training loss: 1.3589997291564941
Validation loss: 1.873692548403176

Epoch: 6| Step: 4
Training loss: 0.9666064977645874
Validation loss: 1.8934097738676174

Epoch: 6| Step: 5
Training loss: 0.9879195690155029
Validation loss: 1.892763513390736

Epoch: 6| Step: 6
Training loss: 1.3634977340698242
Validation loss: 1.8862252466140255

Epoch: 6| Step: 7
Training loss: 1.4319677352905273
Validation loss: 1.9039301667162167

Epoch: 6| Step: 8
Training loss: 1.4252766370773315
Validation loss: 1.9204744395389353

Epoch: 6| Step: 9
Training loss: 1.0749399662017822
Validation loss: 1.8986305985399472

Epoch: 6| Step: 10
Training loss: 0.7611210346221924
Validation loss: 1.9144760216436079

Epoch: 6| Step: 11
Training loss: 1.2384885549545288
Validation loss: 1.9116827749436902

Epoch: 6| Step: 12
Training loss: 1.4089957475662231
Validation loss: 1.8918990870957733

Epoch: 6| Step: 13
Training loss: 1.5143754482269287
Validation loss: 1.8788915654664398

Epoch: 320| Step: 0
Training loss: 1.3105413913726807
Validation loss: 1.8652695045676282

Epoch: 6| Step: 1
Training loss: 1.4232537746429443
Validation loss: 1.8668345110390776

Epoch: 6| Step: 2
Training loss: 1.4281470775604248
Validation loss: 1.8637006436624834

Epoch: 6| Step: 3
Training loss: 1.1680047512054443
Validation loss: 1.8728643566049554

Epoch: 6| Step: 4
Training loss: 1.4316133260726929
Validation loss: 1.8929413339143157

Epoch: 6| Step: 5
Training loss: 1.2376329898834229
Validation loss: 1.9161379644947667

Epoch: 6| Step: 6
Training loss: 1.0119168758392334
Validation loss: 1.9047024326939737

Epoch: 6| Step: 7
Training loss: 1.058531403541565
Validation loss: 1.8983986544352707

Epoch: 6| Step: 8
Training loss: 1.1572470664978027
Validation loss: 1.8886771509724278

Epoch: 6| Step: 9
Training loss: 0.7854204177856445
Validation loss: 1.8411644543370893

Epoch: 6| Step: 10
Training loss: 1.5354595184326172
Validation loss: 1.8813485201968942

Epoch: 6| Step: 11
Training loss: 0.8527053594589233
Validation loss: 1.8896283103573708

Epoch: 6| Step: 12
Training loss: 1.7160807847976685
Validation loss: 1.8806142550642773

Epoch: 6| Step: 13
Training loss: 1.8869661092758179
Validation loss: 1.8633614022244689

Epoch: 321| Step: 0
Training loss: 1.6451191902160645
Validation loss: 1.8551453633974957

Epoch: 6| Step: 1
Training loss: 1.2524868249893188
Validation loss: 1.8874450396465998

Epoch: 6| Step: 2
Training loss: 0.629344642162323
Validation loss: 1.887836112770983

Epoch: 6| Step: 3
Training loss: 1.7003474235534668
Validation loss: 1.9305157969074864

Epoch: 6| Step: 4
Training loss: 1.7326953411102295
Validation loss: 1.955958197193761

Epoch: 6| Step: 5
Training loss: 1.07603120803833
Validation loss: 1.9257737616057038

Epoch: 6| Step: 6
Training loss: 0.7451183795928955
Validation loss: 1.8918135909623996

Epoch: 6| Step: 7
Training loss: 1.2001104354858398
Validation loss: 1.905592856868621

Epoch: 6| Step: 8
Training loss: 0.6611977815628052
Validation loss: 1.9233545462290447

Epoch: 6| Step: 9
Training loss: 1.0556915998458862
Validation loss: 1.948706885819794

Epoch: 6| Step: 10
Training loss: 0.9667549729347229
Validation loss: 1.9142659338571693

Epoch: 6| Step: 11
Training loss: 1.4444330930709839
Validation loss: 1.8971110313169417

Epoch: 6| Step: 12
Training loss: 1.616814136505127
Validation loss: 1.8891006746599752

Epoch: 6| Step: 13
Training loss: 2.7955093383789062
Validation loss: 1.901020206430907

Epoch: 322| Step: 0
Training loss: 0.8485022783279419
Validation loss: 1.9200288723873835

Epoch: 6| Step: 1
Training loss: 1.1651177406311035
Validation loss: 1.9580546630326139

Epoch: 6| Step: 2
Training loss: 1.0821654796600342
Validation loss: 1.9600339358852756

Epoch: 6| Step: 3
Training loss: 1.4368386268615723
Validation loss: 1.9285864676198652

Epoch: 6| Step: 4
Training loss: 1.4995338916778564
Validation loss: 1.884338435306344

Epoch: 6| Step: 5
Training loss: 0.739888608455658
Validation loss: 1.8699467194977628

Epoch: 6| Step: 6
Training loss: 1.450362205505371
Validation loss: 1.8699999675955823

Epoch: 6| Step: 7
Training loss: 1.159721851348877
Validation loss: 1.8743551790073354

Epoch: 6| Step: 8
Training loss: 0.8529471158981323
Validation loss: 1.8495111696181759

Epoch: 6| Step: 9
Training loss: 1.0910109281539917
Validation loss: 1.858387194653993

Epoch: 6| Step: 10
Training loss: 1.654491901397705
Validation loss: 1.8626654378829464

Epoch: 6| Step: 11
Training loss: 1.4945577383041382
Validation loss: 1.892092720154793

Epoch: 6| Step: 12
Training loss: 1.3153818845748901
Validation loss: 1.8972834976770545

Epoch: 6| Step: 13
Training loss: 2.239492893218994
Validation loss: 1.911080793667865

Epoch: 323| Step: 0
Training loss: 1.655512809753418
Validation loss: 1.9467710243758334

Epoch: 6| Step: 1
Training loss: 2.7331786155700684
Validation loss: 1.9222512565633303

Epoch: 6| Step: 2
Training loss: 1.1131277084350586
Validation loss: 1.9210345693813857

Epoch: 6| Step: 3
Training loss: 1.4125109910964966
Validation loss: 1.8923875516460789

Epoch: 6| Step: 4
Training loss: 1.0877230167388916
Validation loss: 1.908938551461825

Epoch: 6| Step: 5
Training loss: 1.045204520225525
Validation loss: 1.8888647017940399

Epoch: 6| Step: 6
Training loss: 1.5155683755874634
Validation loss: 1.9016599347514491

Epoch: 6| Step: 7
Training loss: 1.4322203397750854
Validation loss: 1.8552783919918923

Epoch: 6| Step: 8
Training loss: 0.8088598251342773
Validation loss: 1.8535512070502005

Epoch: 6| Step: 9
Training loss: 0.930689811706543
Validation loss: 1.864640248719082

Epoch: 6| Step: 10
Training loss: 0.720815896987915
Validation loss: 1.8618270389495357

Epoch: 6| Step: 11
Training loss: 1.166942834854126
Validation loss: 1.8693379356015114

Epoch: 6| Step: 12
Training loss: 0.6010881662368774
Validation loss: 1.8626684219606462

Epoch: 6| Step: 13
Training loss: 0.5146788954734802
Validation loss: 1.866568084686033

Epoch: 324| Step: 0
Training loss: 1.190448522567749
Validation loss: 1.864177235993006

Epoch: 6| Step: 1
Training loss: 1.0929768085479736
Validation loss: 1.8843866086775256

Epoch: 6| Step: 2
Training loss: 1.517240285873413
Validation loss: 1.9085492472494803

Epoch: 6| Step: 3
Training loss: 1.122970700263977
Validation loss: 1.9162014120368547

Epoch: 6| Step: 4
Training loss: 1.2293434143066406
Validation loss: 1.9191493731673046

Epoch: 6| Step: 5
Training loss: 0.9385555982589722
Validation loss: 1.8717313222987677

Epoch: 6| Step: 6
Training loss: 1.0825765132904053
Validation loss: 1.876448650513926

Epoch: 6| Step: 7
Training loss: 0.9843624234199524
Validation loss: 1.8570120193625008

Epoch: 6| Step: 8
Training loss: 1.387282371520996
Validation loss: 1.8561371039318781

Epoch: 6| Step: 9
Training loss: 1.215676188468933
Validation loss: 1.8375641671560143

Epoch: 6| Step: 10
Training loss: 1.5969699621200562
Validation loss: 1.8467624072105653

Epoch: 6| Step: 11
Training loss: 1.140320062637329
Validation loss: 1.856157895057432

Epoch: 6| Step: 12
Training loss: 1.2865406274795532
Validation loss: 1.8639870971761725

Epoch: 6| Step: 13
Training loss: 1.2292433977127075
Validation loss: 1.8841078435221026

Epoch: 325| Step: 0
Training loss: 1.336400032043457
Validation loss: 1.9169653064461165

Epoch: 6| Step: 1
Training loss: 1.3365963697433472
Validation loss: 1.8903914190107776

Epoch: 6| Step: 2
Training loss: 0.9277169704437256
Validation loss: 1.9171595252970213

Epoch: 6| Step: 3
Training loss: 1.2237882614135742
Validation loss: 1.9085190719173801

Epoch: 6| Step: 4
Training loss: 1.497579574584961
Validation loss: 1.911607934582618

Epoch: 6| Step: 5
Training loss: 0.638390302658081
Validation loss: 1.9072883821302844

Epoch: 6| Step: 6
Training loss: 1.368257999420166
Validation loss: 1.945980320694626

Epoch: 6| Step: 7
Training loss: 1.7777670621871948
Validation loss: 1.9013458426280687

Epoch: 6| Step: 8
Training loss: 1.2166588306427002
Validation loss: 1.8743274545156827

Epoch: 6| Step: 9
Training loss: 1.1945446729660034
Validation loss: 1.8232707182566326

Epoch: 6| Step: 10
Training loss: 0.9530630707740784
Validation loss: 1.8421674697629866

Epoch: 6| Step: 11
Training loss: 1.010504961013794
Validation loss: 1.8339457255537792

Epoch: 6| Step: 12
Training loss: 1.4152672290802002
Validation loss: 1.8000253272312943

Epoch: 6| Step: 13
Training loss: 1.3054156303405762
Validation loss: 1.7974587794273131

Epoch: 326| Step: 0
Training loss: 1.6715800762176514
Validation loss: 1.8102232833062448

Epoch: 6| Step: 1
Training loss: 1.0506179332733154
Validation loss: 1.8106121837451894

Epoch: 6| Step: 2
Training loss: 1.5146284103393555
Validation loss: 1.8185467822577364

Epoch: 6| Step: 3
Training loss: 1.2480895519256592
Validation loss: 1.8243736426035564

Epoch: 6| Step: 4
Training loss: 1.149957537651062
Validation loss: 1.8357919262301536

Epoch: 6| Step: 5
Training loss: 0.8800222277641296
Validation loss: 1.833239169530971

Epoch: 6| Step: 6
Training loss: 1.4563984870910645
Validation loss: 1.8646756090143675

Epoch: 6| Step: 7
Training loss: 1.4239695072174072
Validation loss: 1.9079427488388554

Epoch: 6| Step: 8
Training loss: 1.3762409687042236
Validation loss: 1.9384497852735623

Epoch: 6| Step: 9
Training loss: 1.392072081565857
Validation loss: 1.931946595509847

Epoch: 6| Step: 10
Training loss: 0.39854973554611206
Validation loss: 1.9400868992651663

Epoch: 6| Step: 11
Training loss: 0.8210042715072632
Validation loss: 1.9300467609077372

Epoch: 6| Step: 12
Training loss: 1.0511983633041382
Validation loss: 1.891877766578428

Epoch: 6| Step: 13
Training loss: 1.2133539915084839
Validation loss: 1.8995288443821732

Epoch: 327| Step: 0
Training loss: 1.4183363914489746
Validation loss: 1.890638025858069

Epoch: 6| Step: 1
Training loss: 1.191339135169983
Validation loss: 1.8775636816537509

Epoch: 6| Step: 2
Training loss: 1.1868629455566406
Validation loss: 1.8523302385883946

Epoch: 6| Step: 3
Training loss: 0.9440181255340576
Validation loss: 1.8577915442887174

Epoch: 6| Step: 4
Training loss: 1.5480358600616455
Validation loss: 1.825982552702709

Epoch: 6| Step: 5
Training loss: 1.555727481842041
Validation loss: 1.8442108784952471

Epoch: 6| Step: 6
Training loss: 1.1044433116912842
Validation loss: 1.8194234627549366

Epoch: 6| Step: 7
Training loss: 1.3782203197479248
Validation loss: 1.842453633585284

Epoch: 6| Step: 8
Training loss: 0.808074951171875
Validation loss: 1.831101535468973

Epoch: 6| Step: 9
Training loss: 0.9640719294548035
Validation loss: 1.827665259761195

Epoch: 6| Step: 10
Training loss: 0.9369704723358154
Validation loss: 1.816124459748627

Epoch: 6| Step: 11
Training loss: 0.7515038847923279
Validation loss: 1.861958372977472

Epoch: 6| Step: 12
Training loss: 1.8000984191894531
Validation loss: 1.8508826635217155

Epoch: 6| Step: 13
Training loss: 1.062740445137024
Validation loss: 1.8722279046171455

Epoch: 328| Step: 0
Training loss: 0.9048577547073364
Validation loss: 1.8619536456241403

Epoch: 6| Step: 1
Training loss: 1.1342525482177734
Validation loss: 1.8746694646855837

Epoch: 6| Step: 2
Training loss: 1.2113492488861084
Validation loss: 1.8632444015113256

Epoch: 6| Step: 3
Training loss: 0.8319246768951416
Validation loss: 1.8871219632446126

Epoch: 6| Step: 4
Training loss: 1.0576956272125244
Validation loss: 1.8829875402553107

Epoch: 6| Step: 5
Training loss: 0.7893145084381104
Validation loss: 1.9169756007450882

Epoch: 6| Step: 6
Training loss: 1.213550329208374
Validation loss: 1.9258916570294289

Epoch: 6| Step: 7
Training loss: 1.6153459548950195
Validation loss: 1.924215821809666

Epoch: 6| Step: 8
Training loss: 1.5356183052062988
Validation loss: 1.904162197984675

Epoch: 6| Step: 9
Training loss: 1.6250967979431152
Validation loss: 1.8776980330867152

Epoch: 6| Step: 10
Training loss: 1.243148684501648
Validation loss: 1.8611640699448124

Epoch: 6| Step: 11
Training loss: 1.039771556854248
Validation loss: 1.846878900322863

Epoch: 6| Step: 12
Training loss: 1.0168585777282715
Validation loss: 1.8354394307700537

Epoch: 6| Step: 13
Training loss: 1.2366948127746582
Validation loss: 1.8329515162334646

Epoch: 329| Step: 0
Training loss: 0.9361447095870972
Validation loss: 1.837528214659742

Epoch: 6| Step: 1
Training loss: 1.2154756784439087
Validation loss: 1.8455029943937897

Epoch: 6| Step: 2
Training loss: 0.87422776222229
Validation loss: 1.8563955342897804

Epoch: 6| Step: 3
Training loss: 0.7954471111297607
Validation loss: 1.8289124491394206

Epoch: 6| Step: 4
Training loss: 1.656217336654663
Validation loss: 1.8254662047150314

Epoch: 6| Step: 5
Training loss: 0.8415672183036804
Validation loss: 1.867658471548429

Epoch: 6| Step: 6
Training loss: 1.0777616500854492
Validation loss: 1.8814715749473983

Epoch: 6| Step: 7
Training loss: 1.5690245628356934
Validation loss: 1.9236719531397666

Epoch: 6| Step: 8
Training loss: 1.266972541809082
Validation loss: 1.922049819782216

Epoch: 6| Step: 9
Training loss: 1.0742849111557007
Validation loss: 1.912541667620341

Epoch: 6| Step: 10
Training loss: 1.6107367277145386
Validation loss: 1.879126924340443

Epoch: 6| Step: 11
Training loss: 1.135120153427124
Validation loss: 1.8901268487335534

Epoch: 6| Step: 12
Training loss: 1.1167632341384888
Validation loss: 1.8983886652095343

Epoch: 6| Step: 13
Training loss: 1.61618971824646
Validation loss: 1.9082158304029895

Epoch: 330| Step: 0
Training loss: 0.9160643219947815
Validation loss: 1.91129974139634

Epoch: 6| Step: 1
Training loss: 1.202736258506775
Validation loss: 1.8732985476011872

Epoch: 6| Step: 2
Training loss: 1.1325585842132568
Validation loss: 1.8672172254131687

Epoch: 6| Step: 3
Training loss: 1.4919273853302002
Validation loss: 1.847451348458567

Epoch: 6| Step: 4
Training loss: 1.193512201309204
Validation loss: 1.8367944334142952

Epoch: 6| Step: 5
Training loss: 0.9258455634117126
Validation loss: 1.818195048198905

Epoch: 6| Step: 6
Training loss: 1.1333352327346802
Validation loss: 1.8183072459313177

Epoch: 6| Step: 7
Training loss: 0.9429295659065247
Validation loss: 1.8071406554150324

Epoch: 6| Step: 8
Training loss: 0.9937261343002319
Validation loss: 1.8346467364218928

Epoch: 6| Step: 9
Training loss: 1.2350869178771973
Validation loss: 1.8576487046416088

Epoch: 6| Step: 10
Training loss: 0.6711744070053101
Validation loss: 1.8323769902670255

Epoch: 6| Step: 11
Training loss: 1.2979395389556885
Validation loss: 1.8664152365858837

Epoch: 6| Step: 12
Training loss: 1.5084755420684814
Validation loss: 1.8648395076874764

Epoch: 6| Step: 13
Training loss: 1.8267207145690918
Validation loss: 1.870814807953373

Epoch: 331| Step: 0
Training loss: 0.9357951879501343
Validation loss: 1.87571596330212

Epoch: 6| Step: 1
Training loss: 0.9333239793777466
Validation loss: 1.8624792470726916

Epoch: 6| Step: 2
Training loss: 0.9204033017158508
Validation loss: 1.842085596053831

Epoch: 6| Step: 3
Training loss: 1.3685065507888794
Validation loss: 1.8624295675626366

Epoch: 6| Step: 4
Training loss: 0.9949343800544739
Validation loss: 1.8772776537044074

Epoch: 6| Step: 5
Training loss: 0.8435915112495422
Validation loss: 1.8983212940154537

Epoch: 6| Step: 6
Training loss: 1.5457078218460083
Validation loss: 1.9096335557199293

Epoch: 6| Step: 7
Training loss: 1.6875286102294922
Validation loss: 1.919008429332446

Epoch: 6| Step: 8
Training loss: 0.6809960603713989
Validation loss: 1.8656917336166545

Epoch: 6| Step: 9
Training loss: 1.30191969871521
Validation loss: 1.8765290244933097

Epoch: 6| Step: 10
Training loss: 1.6398396492004395
Validation loss: 1.86931199155828

Epoch: 6| Step: 11
Training loss: 1.3398394584655762
Validation loss: 1.8597533484940887

Epoch: 6| Step: 12
Training loss: 1.227266788482666
Validation loss: 1.861039961538007

Epoch: 6| Step: 13
Training loss: 0.6175349950790405
Validation loss: 1.8596225284760999

Epoch: 332| Step: 0
Training loss: 0.9405547380447388
Validation loss: 1.8352915984328075

Epoch: 6| Step: 1
Training loss: 1.1873592138290405
Validation loss: 1.8166354804910638

Epoch: 6| Step: 2
Training loss: 1.087369680404663
Validation loss: 1.8645275074948546

Epoch: 6| Step: 3
Training loss: 0.8307589292526245
Validation loss: 1.8783401648203533

Epoch: 6| Step: 4
Training loss: 1.3906621932983398
Validation loss: 1.8701345100197742

Epoch: 6| Step: 5
Training loss: 1.3611876964569092
Validation loss: 1.8688591859673942

Epoch: 6| Step: 6
Training loss: 0.9401037693023682
Validation loss: 1.8179770182537776

Epoch: 6| Step: 7
Training loss: 1.2257091999053955
Validation loss: 1.8288899954929148

Epoch: 6| Step: 8
Training loss: 1.0960025787353516
Validation loss: 1.8137656181089339

Epoch: 6| Step: 9
Training loss: 1.980663776397705
Validation loss: 1.834835498563705

Epoch: 6| Step: 10
Training loss: 1.5325138568878174
Validation loss: 1.8243337177461194

Epoch: 6| Step: 11
Training loss: 1.1619460582733154
Validation loss: 1.849157315428539

Epoch: 6| Step: 12
Training loss: 0.8680024147033691
Validation loss: 1.8517338921946864

Epoch: 6| Step: 13
Training loss: 0.531565248966217
Validation loss: 1.842776124195386

Epoch: 333| Step: 0
Training loss: 0.607219398021698
Validation loss: 1.8373112088890486

Epoch: 6| Step: 1
Training loss: 1.591100811958313
Validation loss: 1.852815689579133

Epoch: 6| Step: 2
Training loss: 1.5558654069900513
Validation loss: 1.8444018261407011

Epoch: 6| Step: 3
Training loss: 1.2479746341705322
Validation loss: 1.8355809719331804

Epoch: 6| Step: 4
Training loss: 1.3523523807525635
Validation loss: 1.8288710066067275

Epoch: 6| Step: 5
Training loss: 0.8012620210647583
Validation loss: 1.8455508191098449

Epoch: 6| Step: 6
Training loss: 0.9207967519760132
Validation loss: 1.8670888575174476

Epoch: 6| Step: 7
Training loss: 0.7338052988052368
Validation loss: 1.832422355169891

Epoch: 6| Step: 8
Training loss: 1.1099185943603516
Validation loss: 1.8445414894370622

Epoch: 6| Step: 9
Training loss: 2.03113055229187
Validation loss: 1.857140346880882

Epoch: 6| Step: 10
Training loss: 0.7304240465164185
Validation loss: 1.8518398833531204

Epoch: 6| Step: 11
Training loss: 1.2720584869384766
Validation loss: 1.850616939606205

Epoch: 6| Step: 12
Training loss: 1.111180305480957
Validation loss: 1.8489664626377884

Epoch: 6| Step: 13
Training loss: 0.6356284618377686
Validation loss: 1.8559349377950032

Epoch: 334| Step: 0
Training loss: 0.9404865503311157
Validation loss: 1.8257896746358564

Epoch: 6| Step: 1
Training loss: 1.258971095085144
Validation loss: 1.8375581003004504

Epoch: 6| Step: 2
Training loss: 1.2179183959960938
Validation loss: 1.8201366573251703

Epoch: 6| Step: 3
Training loss: 0.9400617480278015
Validation loss: 1.8389084774960753

Epoch: 6| Step: 4
Training loss: 1.1832170486450195
Validation loss: 1.8000073996923303

Epoch: 6| Step: 5
Training loss: 1.311821460723877
Validation loss: 1.8214212835475962

Epoch: 6| Step: 6
Training loss: 1.2141444683074951
Validation loss: 1.8443137240666214

Epoch: 6| Step: 7
Training loss: 0.9434911012649536
Validation loss: 1.8342551287784372

Epoch: 6| Step: 8
Training loss: 1.3311331272125244
Validation loss: 1.8299042306920534

Epoch: 6| Step: 9
Training loss: 0.998602569103241
Validation loss: 1.8148663274703487

Epoch: 6| Step: 10
Training loss: 1.1594676971435547
Validation loss: 1.844362401193188

Epoch: 6| Step: 11
Training loss: 0.9427950382232666
Validation loss: 1.86026519344699

Epoch: 6| Step: 12
Training loss: 1.2669888734817505
Validation loss: 1.8596824702396189

Epoch: 6| Step: 13
Training loss: 1.2760326862335205
Validation loss: 1.8773177131529777

Epoch: 335| Step: 0
Training loss: 1.0921987295150757
Validation loss: 1.886777380461334

Epoch: 6| Step: 1
Training loss: 0.9788612127304077
Validation loss: 1.8706496287417669

Epoch: 6| Step: 2
Training loss: 0.8911188840866089
Validation loss: 1.8599589396548528

Epoch: 6| Step: 3
Training loss: 1.20060133934021
Validation loss: 1.842309174999114

Epoch: 6| Step: 4
Training loss: 1.1038682460784912
Validation loss: 1.8334428661613054

Epoch: 6| Step: 5
Training loss: 0.7963120341300964
Validation loss: 1.8279776880818028

Epoch: 6| Step: 6
Training loss: 1.1838781833648682
Validation loss: 1.8418491783962454

Epoch: 6| Step: 7
Training loss: 0.9106572270393372
Validation loss: 1.8060075006177347

Epoch: 6| Step: 8
Training loss: 1.1844056844711304
Validation loss: 1.7896249037916943

Epoch: 6| Step: 9
Training loss: 1.4916975498199463
Validation loss: 1.8244059406301028

Epoch: 6| Step: 10
Training loss: 1.360220193862915
Validation loss: 1.8053888095322477

Epoch: 6| Step: 11
Training loss: 1.087132453918457
Validation loss: 1.8181635077281664

Epoch: 6| Step: 12
Training loss: 1.3634846210479736
Validation loss: 1.8028752457711004

Epoch: 6| Step: 13
Training loss: 1.3785699605941772
Validation loss: 1.829945719370278

Epoch: 336| Step: 0
Training loss: 1.411181092262268
Validation loss: 1.8674624632763606

Epoch: 6| Step: 1
Training loss: 1.1756041049957275
Validation loss: 1.8776944145079582

Epoch: 6| Step: 2
Training loss: 0.7864296436309814
Validation loss: 1.8591897744004444

Epoch: 6| Step: 3
Training loss: 1.1106536388397217
Validation loss: 1.8963663437033211

Epoch: 6| Step: 4
Training loss: 1.2588603496551514
Validation loss: 1.8689687431499522

Epoch: 6| Step: 5
Training loss: 1.311476230621338
Validation loss: 1.857406311137702

Epoch: 6| Step: 6
Training loss: 0.9938485622406006
Validation loss: 1.8645725942427112

Epoch: 6| Step: 7
Training loss: 1.8048365116119385
Validation loss: 1.8483981688817341

Epoch: 6| Step: 8
Training loss: 0.9571472406387329
Validation loss: 1.8299888641603532

Epoch: 6| Step: 9
Training loss: 0.5742638111114502
Validation loss: 1.8151581659111926

Epoch: 6| Step: 10
Training loss: 1.085780382156372
Validation loss: 1.8282938721359416

Epoch: 6| Step: 11
Training loss: 0.9650272727012634
Validation loss: 1.82294451549489

Epoch: 6| Step: 12
Training loss: 1.0274852514266968
Validation loss: 1.8136938694984681

Epoch: 6| Step: 13
Training loss: 1.281653881072998
Validation loss: 1.8293281947412798

Epoch: 337| Step: 0
Training loss: 0.8385506868362427
Validation loss: 1.8298270240906747

Epoch: 6| Step: 1
Training loss: 1.1668124198913574
Validation loss: 1.8055595313349078

Epoch: 6| Step: 2
Training loss: 1.5515400171279907
Validation loss: 1.8660846846078032

Epoch: 6| Step: 3
Training loss: 0.87679523229599
Validation loss: 1.8764967136485602

Epoch: 6| Step: 4
Training loss: 0.5720385313034058
Validation loss: 1.8683501994738014

Epoch: 6| Step: 5
Training loss: 1.299389362335205
Validation loss: 1.8613523834495134

Epoch: 6| Step: 6
Training loss: 0.728242814540863
Validation loss: 1.8458685926211778

Epoch: 6| Step: 7
Training loss: 0.747515082359314
Validation loss: 1.8164502343823832

Epoch: 6| Step: 8
Training loss: 1.2962597608566284
Validation loss: 1.7878117048612205

Epoch: 6| Step: 9
Training loss: 0.9058226346969604
Validation loss: 1.7735169767051615

Epoch: 6| Step: 10
Training loss: 1.813677191734314
Validation loss: 1.760358884770383

Epoch: 6| Step: 11
Training loss: 1.3614213466644287
Validation loss: 1.780435836443337

Epoch: 6| Step: 12
Training loss: 1.261513352394104
Validation loss: 1.7730570275296447

Epoch: 6| Step: 13
Training loss: 1.1946046352386475
Validation loss: 1.8035879442768712

Epoch: 338| Step: 0
Training loss: 1.1000888347625732
Validation loss: 1.8343113673630582

Epoch: 6| Step: 1
Training loss: 0.878056526184082
Validation loss: 1.8570372212317683

Epoch: 6| Step: 2
Training loss: 0.7807630896568298
Validation loss: 1.8702388848027875

Epoch: 6| Step: 3
Training loss: 0.9422587156295776
Validation loss: 1.8783562285925752

Epoch: 6| Step: 4
Training loss: 1.1052582263946533
Validation loss: 1.8777149441421672

Epoch: 6| Step: 5
Training loss: 0.8197608590126038
Validation loss: 1.860573935252364

Epoch: 6| Step: 6
Training loss: 1.0099432468414307
Validation loss: 1.8638959148878693

Epoch: 6| Step: 7
Training loss: 2.0020244121551514
Validation loss: 1.856166370453373

Epoch: 6| Step: 8
Training loss: 1.2104134559631348
Validation loss: 1.8356100077270179

Epoch: 6| Step: 9
Training loss: 1.2789623737335205
Validation loss: 1.8371879234108874

Epoch: 6| Step: 10
Training loss: 1.1107177734375
Validation loss: 1.8359652911463091

Epoch: 6| Step: 11
Training loss: 0.5021194219589233
Validation loss: 1.8099424069927585

Epoch: 6| Step: 12
Training loss: 1.4478697776794434
Validation loss: 1.7979583612052343

Epoch: 6| Step: 13
Training loss: 0.9629091620445251
Validation loss: 1.7732764021042855

Epoch: 339| Step: 0
Training loss: 1.0476359128952026
Validation loss: 1.7686732943340013

Epoch: 6| Step: 1
Training loss: 0.8740488290786743
Validation loss: 1.770839306616014

Epoch: 6| Step: 2
Training loss: 1.1466110944747925
Validation loss: 1.7828605213472921

Epoch: 6| Step: 3
Training loss: 1.7568312883377075
Validation loss: 1.7532304743284821

Epoch: 6| Step: 4
Training loss: 1.0650922060012817
Validation loss: 1.7777439189213577

Epoch: 6| Step: 5
Training loss: 0.6570879220962524
Validation loss: 1.7739803124499578

Epoch: 6| Step: 6
Training loss: 0.7296949028968811
Validation loss: 1.793447466306789

Epoch: 6| Step: 7
Training loss: 0.8683978915214539
Validation loss: 1.8125145012332546

Epoch: 6| Step: 8
Training loss: 1.4965529441833496
Validation loss: 1.8152635917868665

Epoch: 6| Step: 9
Training loss: 1.515527606010437
Validation loss: 1.8102616699793006

Epoch: 6| Step: 10
Training loss: 1.1064231395721436
Validation loss: 1.8372218557583389

Epoch: 6| Step: 11
Training loss: 1.157509446144104
Validation loss: 1.845693924093759

Epoch: 6| Step: 12
Training loss: 1.0156207084655762
Validation loss: 1.8504289414293023

Epoch: 6| Step: 13
Training loss: 0.7558775544166565
Validation loss: 1.858392055316638

Epoch: 340| Step: 0
Training loss: 1.1485743522644043
Validation loss: 1.799658376683471

Epoch: 6| Step: 1
Training loss: 1.1671831607818604
Validation loss: 1.8071444355031496

Epoch: 6| Step: 2
Training loss: 1.5158264636993408
Validation loss: 1.801032688028069

Epoch: 6| Step: 3
Training loss: 1.0360698699951172
Validation loss: 1.8026804206191853

Epoch: 6| Step: 4
Training loss: 0.9256002902984619
Validation loss: 1.790707277995284

Epoch: 6| Step: 5
Training loss: 0.5468853712081909
Validation loss: 1.7922947829769504

Epoch: 6| Step: 6
Training loss: 0.7199326753616333
Validation loss: 1.7874075007695023

Epoch: 6| Step: 7
Training loss: 0.8732735514640808
Validation loss: 1.786433002000214

Epoch: 6| Step: 8
Training loss: 1.8931514024734497
Validation loss: 1.8054460479367165

Epoch: 6| Step: 9
Training loss: 0.9707977771759033
Validation loss: 1.8131627318679646

Epoch: 6| Step: 10
Training loss: 0.7935924530029297
Validation loss: 1.8293415205453032

Epoch: 6| Step: 11
Training loss: 1.3574162721633911
Validation loss: 1.831312951221261

Epoch: 6| Step: 12
Training loss: 1.2561726570129395
Validation loss: 1.859142412421524

Epoch: 6| Step: 13
Training loss: 1.5722002983093262
Validation loss: 1.8863393465677898

Epoch: 341| Step: 0
Training loss: 1.5766257047653198
Validation loss: 1.8588642253670642

Epoch: 6| Step: 1
Training loss: 1.0108332633972168
Validation loss: 1.8361493618257585

Epoch: 6| Step: 2
Training loss: 0.8108510375022888
Validation loss: 1.838607657340265

Epoch: 6| Step: 3
Training loss: 0.754652738571167
Validation loss: 1.7926304981272707

Epoch: 6| Step: 4
Training loss: 1.23874032497406
Validation loss: 1.8341624159966745

Epoch: 6| Step: 5
Training loss: 0.5292919874191284
Validation loss: 1.8374881898203204

Epoch: 6| Step: 6
Training loss: 1.7730789184570312
Validation loss: 1.8791611027973953

Epoch: 6| Step: 7
Training loss: 1.066292405128479
Validation loss: 1.8797608754968131

Epoch: 6| Step: 8
Training loss: 0.7478804588317871
Validation loss: 1.8391481625136508

Epoch: 6| Step: 9
Training loss: 2.0825986862182617
Validation loss: 1.7849856384338871

Epoch: 6| Step: 10
Training loss: 1.3048298358917236
Validation loss: 1.8288356206750358

Epoch: 6| Step: 11
Training loss: 0.9980182647705078
Validation loss: 1.8144970901550785

Epoch: 6| Step: 12
Training loss: 0.7426724433898926
Validation loss: 1.8334658197177354

Epoch: 6| Step: 13
Training loss: 1.1249042749404907
Validation loss: 1.7927295084922545

Epoch: 342| Step: 0
Training loss: 1.0499956607818604
Validation loss: 1.812798269333378

Epoch: 6| Step: 1
Training loss: 1.3008136749267578
Validation loss: 1.809256253703948

Epoch: 6| Step: 2
Training loss: 1.1668763160705566
Validation loss: 1.7793074551449026

Epoch: 6| Step: 3
Training loss: 0.7258119583129883
Validation loss: 1.7600879874280704

Epoch: 6| Step: 4
Training loss: 0.8895860314369202
Validation loss: 1.8060865350948867

Epoch: 6| Step: 5
Training loss: 0.7030295133590698
Validation loss: 1.821010858781876

Epoch: 6| Step: 6
Training loss: 1.328837275505066
Validation loss: 1.8124244084922216

Epoch: 6| Step: 7
Training loss: 0.6721088886260986
Validation loss: 1.8117728246155607

Epoch: 6| Step: 8
Training loss: 1.0933632850646973
Validation loss: 1.825502977576307

Epoch: 6| Step: 9
Training loss: 1.0205142498016357
Validation loss: 1.8299164374669392

Epoch: 6| Step: 10
Training loss: 1.2966134548187256
Validation loss: 1.8376285311996297

Epoch: 6| Step: 11
Training loss: 1.5658373832702637
Validation loss: 1.8555126984914143

Epoch: 6| Step: 12
Training loss: 1.3850533962249756
Validation loss: 1.8437650742069367

Epoch: 6| Step: 13
Training loss: 0.9302928447723389
Validation loss: 1.837923921564574

Epoch: 343| Step: 0
Training loss: 1.038863182067871
Validation loss: 1.8759400921483194

Epoch: 6| Step: 1
Training loss: 0.7418321371078491
Validation loss: 1.8191466818573654

Epoch: 6| Step: 2
Training loss: 1.4643155336380005
Validation loss: 1.8361324469248455

Epoch: 6| Step: 3
Training loss: 1.3347755670547485
Validation loss: 1.833821145437097

Epoch: 6| Step: 4
Training loss: 0.9834508895874023
Validation loss: 1.819766358662677

Epoch: 6| Step: 5
Training loss: 0.9845403432846069
Validation loss: 1.8171474061986452

Epoch: 6| Step: 6
Training loss: 1.3145358562469482
Validation loss: 1.8029072194971063

Epoch: 6| Step: 7
Training loss: 1.2834428548812866
Validation loss: 1.8112797173120643

Epoch: 6| Step: 8
Training loss: 1.5040700435638428
Validation loss: 1.7936584052219187

Epoch: 6| Step: 9
Training loss: 1.11965811252594
Validation loss: 1.813520714800845

Epoch: 6| Step: 10
Training loss: 0.6858633756637573
Validation loss: 1.788846226148708

Epoch: 6| Step: 11
Training loss: 1.3097997903823853
Validation loss: 1.8073883889823832

Epoch: 6| Step: 12
Training loss: 0.7143591642379761
Validation loss: 1.7966941787350563

Epoch: 6| Step: 13
Training loss: 0.47173818945884705
Validation loss: 1.8168281739757908

Epoch: 344| Step: 0
Training loss: 1.209116816520691
Validation loss: 1.8012116826990598

Epoch: 6| Step: 1
Training loss: 1.682424783706665
Validation loss: 1.8032076833068684

Epoch: 6| Step: 2
Training loss: 0.7117287516593933
Validation loss: 1.7997802406228998

Epoch: 6| Step: 3
Training loss: 1.2951161861419678
Validation loss: 1.8281467806908391

Epoch: 6| Step: 4
Training loss: 0.8726112246513367
Validation loss: 1.824108923635175

Epoch: 6| Step: 5
Training loss: 1.1253087520599365
Validation loss: 1.809936592655797

Epoch: 6| Step: 6
Training loss: 0.7768754363059998
Validation loss: 1.8150140828983758

Epoch: 6| Step: 7
Training loss: 1.4262446165084839
Validation loss: 1.8153079889153922

Epoch: 6| Step: 8
Training loss: 1.2185112237930298
Validation loss: 1.822780050257201

Epoch: 6| Step: 9
Training loss: 0.6038203239440918
Validation loss: 1.8065630146252212

Epoch: 6| Step: 10
Training loss: 0.6388300657272339
Validation loss: 1.826551382259656

Epoch: 6| Step: 11
Training loss: 0.7269185781478882
Validation loss: 1.8048324815688594

Epoch: 6| Step: 12
Training loss: 1.4825167655944824
Validation loss: 1.7964433264988724

Epoch: 6| Step: 13
Training loss: 1.2093424797058105
Validation loss: 1.8281108422945904

Epoch: 345| Step: 0
Training loss: 0.8836074471473694
Validation loss: 1.8110516507138488

Epoch: 6| Step: 1
Training loss: 1.1869029998779297
Validation loss: 1.8390146891276042

Epoch: 6| Step: 2
Training loss: 1.2779682874679565
Validation loss: 1.836718987393123

Epoch: 6| Step: 3
Training loss: 1.7495365142822266
Validation loss: 1.8200232956999092

Epoch: 6| Step: 4
Training loss: 0.9352061748504639
Validation loss: 1.8425055498717933

Epoch: 6| Step: 5
Training loss: 0.8688095808029175
Validation loss: 1.8349453633831394

Epoch: 6| Step: 6
Training loss: 0.9594912528991699
Validation loss: 1.8494325889054166

Epoch: 6| Step: 7
Training loss: 0.6712602376937866
Validation loss: 1.8486490147088164

Epoch: 6| Step: 8
Training loss: 1.283801555633545
Validation loss: 1.8339867181675409

Epoch: 6| Step: 9
Training loss: 0.8556320667266846
Validation loss: 1.8173227425544494

Epoch: 6| Step: 10
Training loss: 0.9216153621673584
Validation loss: 1.7939499937078005

Epoch: 6| Step: 11
Training loss: 1.1293683052062988
Validation loss: 1.7799971231850245

Epoch: 6| Step: 12
Training loss: 1.1873457431793213
Validation loss: 1.7911066983335762

Epoch: 6| Step: 13
Training loss: 0.8904845118522644
Validation loss: 1.789916742232538

Epoch: 346| Step: 0
Training loss: 1.3024189472198486
Validation loss: 1.781749935560329

Epoch: 6| Step: 1
Training loss: 1.098170280456543
Validation loss: 1.781336143452634

Epoch: 6| Step: 2
Training loss: 0.7514808177947998
Validation loss: 1.812575417180215

Epoch: 6| Step: 3
Training loss: 1.058381199836731
Validation loss: 1.823942611294408

Epoch: 6| Step: 4
Training loss: 1.1604564189910889
Validation loss: 1.8000894131199006

Epoch: 6| Step: 5
Training loss: 0.812706470489502
Validation loss: 1.8071071422228249

Epoch: 6| Step: 6
Training loss: 0.9533689618110657
Validation loss: 1.8141816867295133

Epoch: 6| Step: 7
Training loss: 0.9371549487113953
Validation loss: 1.8249858733146422

Epoch: 6| Step: 8
Training loss: 0.9534940719604492
Validation loss: 1.8503135199187903

Epoch: 6| Step: 9
Training loss: 1.264117956161499
Validation loss: 1.8431696584147792

Epoch: 6| Step: 10
Training loss: 1.0938358306884766
Validation loss: 1.83533929112137

Epoch: 6| Step: 11
Training loss: 1.354706048965454
Validation loss: 1.8302911635368102

Epoch: 6| Step: 12
Training loss: 1.095015287399292
Validation loss: 1.8110854318065028

Epoch: 6| Step: 13
Training loss: 0.9498770236968994
Validation loss: 1.7928789097775695

Epoch: 347| Step: 0
Training loss: 0.7767560482025146
Validation loss: 1.791472283742761

Epoch: 6| Step: 1
Training loss: 0.8857437372207642
Validation loss: 1.8084511359532673

Epoch: 6| Step: 2
Training loss: 1.056832194328308
Validation loss: 1.7815536632332751

Epoch: 6| Step: 3
Training loss: 1.496375322341919
Validation loss: 1.7893481639123732

Epoch: 6| Step: 4
Training loss: 0.8090255856513977
Validation loss: 1.7825705953823623

Epoch: 6| Step: 5
Training loss: 0.8676682710647583
Validation loss: 1.8061253024685768

Epoch: 6| Step: 6
Training loss: 1.1394927501678467
Validation loss: 1.83221354920377

Epoch: 6| Step: 7
Training loss: 1.211298942565918
Validation loss: 1.8171855723986061

Epoch: 6| Step: 8
Training loss: 0.7941195964813232
Validation loss: 1.8219989204919467

Epoch: 6| Step: 9
Training loss: 1.18062162399292
Validation loss: 1.8566863049742997

Epoch: 6| Step: 10
Training loss: 1.1324526071548462
Validation loss: 1.8491340785898187

Epoch: 6| Step: 11
Training loss: 1.5843197107315063
Validation loss: 1.821377661920363

Epoch: 6| Step: 12
Training loss: 1.1741065979003906
Validation loss: 1.8077684499884163

Epoch: 6| Step: 13
Training loss: 0.8383716344833374
Validation loss: 1.8439902631185388

Epoch: 348| Step: 0
Training loss: 1.3831924200057983
Validation loss: 1.8425747707325926

Epoch: 6| Step: 1
Training loss: 0.9034216403961182
Validation loss: 1.8724823638957033

Epoch: 6| Step: 2
Training loss: 0.811683177947998
Validation loss: 1.815950515449688

Epoch: 6| Step: 3
Training loss: 1.274886131286621
Validation loss: 1.7718284822279406

Epoch: 6| Step: 4
Training loss: 0.8667417168617249
Validation loss: 1.7706112041268298

Epoch: 6| Step: 5
Training loss: 1.3214304447174072
Validation loss: 1.7827708118705339

Epoch: 6| Step: 6
Training loss: 0.8564785718917847
Validation loss: 1.8265822779747747

Epoch: 6| Step: 7
Training loss: 1.3112704753875732
Validation loss: 1.8310449392564836

Epoch: 6| Step: 8
Training loss: 1.5070130825042725
Validation loss: 1.8031319136260657

Epoch: 6| Step: 9
Training loss: 0.7874763011932373
Validation loss: 1.7901359206886702

Epoch: 6| Step: 10
Training loss: 0.7093546390533447
Validation loss: 1.7852894939402097

Epoch: 6| Step: 11
Training loss: 1.0101215839385986
Validation loss: 1.8342805036934473

Epoch: 6| Step: 12
Training loss: 1.2418824434280396
Validation loss: 1.862542237004926

Epoch: 6| Step: 13
Training loss: 1.8439019918441772
Validation loss: 1.8832553343106342

Epoch: 349| Step: 0
Training loss: 1.319319725036621
Validation loss: 1.822472619754012

Epoch: 6| Step: 1
Training loss: 0.5635913610458374
Validation loss: 1.8413239525210472

Epoch: 6| Step: 2
Training loss: 0.729093611240387
Validation loss: 1.8482532270493046

Epoch: 6| Step: 3
Training loss: 1.0564056634902954
Validation loss: 1.8437009485819007

Epoch: 6| Step: 4
Training loss: 1.16878342628479
Validation loss: 1.8550945123036702

Epoch: 6| Step: 5
Training loss: 1.5534687042236328
Validation loss: 1.8293281806412565

Epoch: 6| Step: 6
Training loss: 1.0688916444778442
Validation loss: 1.812529710031325

Epoch: 6| Step: 7
Training loss: 1.2645621299743652
Validation loss: 1.786193932256391

Epoch: 6| Step: 8
Training loss: 1.2998919486999512
Validation loss: 1.7672122550267044

Epoch: 6| Step: 9
Training loss: 1.1304099559783936
Validation loss: 1.8138050007563766

Epoch: 6| Step: 10
Training loss: 1.0348745584487915
Validation loss: 1.8529157407822148

Epoch: 6| Step: 11
Training loss: 0.9190660715103149
Validation loss: 1.8309866125865648

Epoch: 6| Step: 12
Training loss: 1.7364130020141602
Validation loss: 1.8505682009522633

Epoch: 6| Step: 13
Training loss: 0.641846776008606
Validation loss: 1.795195282146495

Epoch: 350| Step: 0
Training loss: 1.3551627397537231
Validation loss: 1.8156399547412831

Epoch: 6| Step: 1
Training loss: 0.7544063329696655
Validation loss: 1.8589846831496044

Epoch: 6| Step: 2
Training loss: 1.4813576936721802
Validation loss: 1.867650717817327

Epoch: 6| Step: 3
Training loss: 1.098522663116455
Validation loss: 1.8467915058135986

Epoch: 6| Step: 4
Training loss: 1.1866226196289062
Validation loss: 1.834019140530658

Epoch: 6| Step: 5
Training loss: 0.8006452322006226
Validation loss: 1.8069866036856046

Epoch: 6| Step: 6
Training loss: 1.297692060470581
Validation loss: 1.7949000340636059

Epoch: 6| Step: 7
Training loss: 0.8582122921943665
Validation loss: 1.7995067386217014

Epoch: 6| Step: 8
Training loss: 0.6987818479537964
Validation loss: 1.8126504305870301

Epoch: 6| Step: 9
Training loss: 1.2165942192077637
Validation loss: 1.8207638622612081

Epoch: 6| Step: 10
Training loss: 0.9590148329734802
Validation loss: 1.7881264686584473

Epoch: 6| Step: 11
Training loss: 0.5979148149490356
Validation loss: 1.7882130633118332

Epoch: 6| Step: 12
Training loss: 1.3590525388717651
Validation loss: 1.814459381564971

Epoch: 6| Step: 13
Training loss: 1.4589811563491821
Validation loss: 1.8100703993151266

Epoch: 351| Step: 0
Training loss: 0.8740019798278809
Validation loss: 1.8111676208434566

Epoch: 6| Step: 1
Training loss: 1.0628650188446045
Validation loss: 1.788361410940847

Epoch: 6| Step: 2
Training loss: 0.8199608325958252
Validation loss: 1.7818607822541268

Epoch: 6| Step: 3
Training loss: 1.1774766445159912
Validation loss: 1.7754033765485209

Epoch: 6| Step: 4
Training loss: 1.3946665525436401
Validation loss: 1.7684177173081266

Epoch: 6| Step: 5
Training loss: 0.9760223627090454
Validation loss: 1.8195395174846853

Epoch: 6| Step: 6
Training loss: 1.1039022207260132
Validation loss: 1.7820001263772287

Epoch: 6| Step: 7
Training loss: 1.1741316318511963
Validation loss: 1.8022151198438419

Epoch: 6| Step: 8
Training loss: 0.7673164010047913
Validation loss: 1.7806060339814873

Epoch: 6| Step: 9
Training loss: 0.8903504610061646
Validation loss: 1.7737272042100147

Epoch: 6| Step: 10
Training loss: 1.2093770503997803
Validation loss: 1.7557842487929969

Epoch: 6| Step: 11
Training loss: 1.325860619544983
Validation loss: 1.7600575313773206

Epoch: 6| Step: 12
Training loss: 0.699194073677063
Validation loss: 1.7699872575780398

Epoch: 6| Step: 13
Training loss: 0.8843938708305359
Validation loss: 1.7655581812704764

Epoch: 352| Step: 0
Training loss: 0.763313889503479
Validation loss: 1.7879857222239177

Epoch: 6| Step: 1
Training loss: 0.8820044994354248
Validation loss: 1.8101673049311484

Epoch: 6| Step: 2
Training loss: 1.057222843170166
Validation loss: 1.790944198126434

Epoch: 6| Step: 3
Training loss: 1.3610658645629883
Validation loss: 1.811564839014443

Epoch: 6| Step: 4
Training loss: 0.6859200596809387
Validation loss: 1.8326681352430774

Epoch: 6| Step: 5
Training loss: 1.278588056564331
Validation loss: 1.8762540535260273

Epoch: 6| Step: 6
Training loss: 1.1293530464172363
Validation loss: 1.9040185802726335

Epoch: 6| Step: 7
Training loss: 1.22413170337677
Validation loss: 1.9304626603280344

Epoch: 6| Step: 8
Training loss: 1.1221578121185303
Validation loss: 1.8823098315987536

Epoch: 6| Step: 9
Training loss: 1.474806547164917
Validation loss: 1.8395815677540277

Epoch: 6| Step: 10
Training loss: 0.6939593553543091
Validation loss: 1.7956945357784149

Epoch: 6| Step: 11
Training loss: 0.9288416504859924
Validation loss: 1.7785545843903736

Epoch: 6| Step: 12
Training loss: 0.89422607421875
Validation loss: 1.8208529423641902

Epoch: 6| Step: 13
Training loss: 1.657248616218567
Validation loss: 1.8040082377772177

Epoch: 353| Step: 0
Training loss: 0.7264809608459473
Validation loss: 1.7829897006352742

Epoch: 6| Step: 1
Training loss: 1.7313562631607056
Validation loss: 1.8087189069358252

Epoch: 6| Step: 2
Training loss: 0.9550362825393677
Validation loss: 1.7920027394448557

Epoch: 6| Step: 3
Training loss: 1.0097815990447998
Validation loss: 1.8188728670920096

Epoch: 6| Step: 4
Training loss: 1.135404109954834
Validation loss: 1.7992397969768894

Epoch: 6| Step: 5
Training loss: 1.2429192066192627
Validation loss: 1.7977766247205837

Epoch: 6| Step: 6
Training loss: 0.7041404843330383
Validation loss: 1.7990029396549347

Epoch: 6| Step: 7
Training loss: 0.7139798998832703
Validation loss: 1.810245640816227

Epoch: 6| Step: 8
Training loss: 0.5372331142425537
Validation loss: 1.8050644705372472

Epoch: 6| Step: 9
Training loss: 0.7750837802886963
Validation loss: 1.7930149083496423

Epoch: 6| Step: 10
Training loss: 1.159738540649414
Validation loss: 1.7650278293958275

Epoch: 6| Step: 11
Training loss: 1.520349144935608
Validation loss: 1.739665849234468

Epoch: 6| Step: 12
Training loss: 0.9802581667900085
Validation loss: 1.7515024715854275

Epoch: 6| Step: 13
Training loss: 1.1397136449813843
Validation loss: 1.761404061830172

Epoch: 354| Step: 0
Training loss: 0.8123730421066284
Validation loss: 1.765004087519902

Epoch: 6| Step: 1
Training loss: 1.1124188899993896
Validation loss: 1.788561786374738

Epoch: 6| Step: 2
Training loss: 1.4538997411727905
Validation loss: 1.810257855282035

Epoch: 6| Step: 3
Training loss: 1.079071283340454
Validation loss: 1.8277380581825011

Epoch: 6| Step: 4
Training loss: 1.1141960620880127
Validation loss: 1.7855311324519496

Epoch: 6| Step: 5
Training loss: 0.9789140224456787
Validation loss: 1.7747213943030244

Epoch: 6| Step: 6
Training loss: 0.7697874307632446
Validation loss: 1.7930083633750997

Epoch: 6| Step: 7
Training loss: 0.4019196629524231
Validation loss: 1.7859322704294676

Epoch: 6| Step: 8
Training loss: 0.963422954082489
Validation loss: 1.7829526329553256

Epoch: 6| Step: 9
Training loss: 1.3134796619415283
Validation loss: 1.7789311408996582

Epoch: 6| Step: 10
Training loss: 1.1726584434509277
Validation loss: 1.801470188684361

Epoch: 6| Step: 11
Training loss: 0.9019749164581299
Validation loss: 1.7808223193691624

Epoch: 6| Step: 12
Training loss: 1.2396111488342285
Validation loss: 1.7855621178944905

Epoch: 6| Step: 13
Training loss: 1.0470023155212402
Validation loss: 1.7803123356193624

Epoch: 355| Step: 0
Training loss: 0.5461829900741577
Validation loss: 1.7583309078729281

Epoch: 6| Step: 1
Training loss: 1.2637369632720947
Validation loss: 1.762548533819055

Epoch: 6| Step: 2
Training loss: 1.0284628868103027
Validation loss: 1.7657244102929228

Epoch: 6| Step: 3
Training loss: 1.201864242553711
Validation loss: 1.7696403175271966

Epoch: 6| Step: 4
Training loss: 0.7544551491737366
Validation loss: 1.7548291055105065

Epoch: 6| Step: 5
Training loss: 0.9464702010154724
Validation loss: 1.7848857833493141

Epoch: 6| Step: 6
Training loss: 1.626243233680725
Validation loss: 1.8053605671851867

Epoch: 6| Step: 7
Training loss: 0.7135663032531738
Validation loss: 1.7987947617807696

Epoch: 6| Step: 8
Training loss: 1.112037181854248
Validation loss: 1.7709618089019612

Epoch: 6| Step: 9
Training loss: 1.0773226022720337
Validation loss: 1.7876540127620901

Epoch: 6| Step: 10
Training loss: 0.5510770678520203
Validation loss: 1.7896508414258239

Epoch: 6| Step: 11
Training loss: 1.181887149810791
Validation loss: 1.802756558182419

Epoch: 6| Step: 12
Training loss: 1.2369227409362793
Validation loss: 1.7985132586571477

Epoch: 6| Step: 13
Training loss: 1.2459568977355957
Validation loss: 1.800979188693467

Epoch: 356| Step: 0
Training loss: 1.4573955535888672
Validation loss: 1.7674281238227763

Epoch: 6| Step: 1
Training loss: 0.48790937662124634
Validation loss: 1.7382314602533977

Epoch: 6| Step: 2
Training loss: 1.4263824224472046
Validation loss: 1.7579486626450733

Epoch: 6| Step: 3
Training loss: 1.2838603258132935
Validation loss: 1.794236639494537

Epoch: 6| Step: 4
Training loss: 1.0179171562194824
Validation loss: 1.7642377691884195

Epoch: 6| Step: 5
Training loss: 0.8046252727508545
Validation loss: 1.7923495846409951

Epoch: 6| Step: 6
Training loss: 1.3750593662261963
Validation loss: 1.7790418542841429

Epoch: 6| Step: 7
Training loss: 1.041196584701538
Validation loss: 1.794165765085528

Epoch: 6| Step: 8
Training loss: 0.6587668657302856
Validation loss: 1.7784431557501517

Epoch: 6| Step: 9
Training loss: 0.7679266333580017
Validation loss: 1.8199793305448306

Epoch: 6| Step: 10
Training loss: 0.946075439453125
Validation loss: 1.8219830861655615

Epoch: 6| Step: 11
Training loss: 1.1556376218795776
Validation loss: 1.826966465160411

Epoch: 6| Step: 12
Training loss: 1.063905954360962
Validation loss: 1.8464387411712317

Epoch: 6| Step: 13
Training loss: 0.6255091428756714
Validation loss: 1.8184930970591884

Epoch: 357| Step: 0
Training loss: 0.6552837491035461
Validation loss: 1.813685142865745

Epoch: 6| Step: 1
Training loss: 0.6499877572059631
Validation loss: 1.8005541806579919

Epoch: 6| Step: 2
Training loss: 0.770153820514679
Validation loss: 1.7790997156532862

Epoch: 6| Step: 3
Training loss: 1.2238678932189941
Validation loss: 1.788613985943538

Epoch: 6| Step: 4
Training loss: 0.8121381402015686
Validation loss: 1.7654476037589453

Epoch: 6| Step: 5
Training loss: 1.3826180696487427
Validation loss: 1.7523903667285878

Epoch: 6| Step: 6
Training loss: 1.0404587984085083
Validation loss: 1.7676132084220968

Epoch: 6| Step: 7
Training loss: 1.1371097564697266
Validation loss: 1.7719399852137412

Epoch: 6| Step: 8
Training loss: 1.2168571949005127
Validation loss: 1.7783547960301882

Epoch: 6| Step: 9
Training loss: 0.694212019443512
Validation loss: 1.7772807510950233

Epoch: 6| Step: 10
Training loss: 1.065575122833252
Validation loss: 1.7970692214145456

Epoch: 6| Step: 11
Training loss: 1.069864273071289
Validation loss: 1.7724689591315486

Epoch: 6| Step: 12
Training loss: 1.022833228111267
Validation loss: 1.7857581133483558

Epoch: 6| Step: 13
Training loss: 1.0952296257019043
Validation loss: 1.7841395716513357

Epoch: 358| Step: 0
Training loss: 1.070717215538025
Validation loss: 1.7911685538548294

Epoch: 6| Step: 1
Training loss: 1.1546190977096558
Validation loss: 1.815531631951691

Epoch: 6| Step: 2
Training loss: 0.9409277439117432
Validation loss: 1.834332137979487

Epoch: 6| Step: 3
Training loss: 1.0130293369293213
Validation loss: 1.819220696726153

Epoch: 6| Step: 4
Training loss: 0.7390737533569336
Validation loss: 1.8201583944341189

Epoch: 6| Step: 5
Training loss: 0.7128764390945435
Validation loss: 1.8251859500843992

Epoch: 6| Step: 6
Training loss: 1.083389163017273
Validation loss: 1.8230143439385198

Epoch: 6| Step: 7
Training loss: 0.8467840552330017
Validation loss: 1.8101040406893658

Epoch: 6| Step: 8
Training loss: 0.8328094482421875
Validation loss: 1.7994462892573366

Epoch: 6| Step: 9
Training loss: 1.6787586212158203
Validation loss: 1.774454519312869

Epoch: 6| Step: 10
Training loss: 0.9720990657806396
Validation loss: 1.76700335420588

Epoch: 6| Step: 11
Training loss: 1.258432149887085
Validation loss: 1.7655309079795756

Epoch: 6| Step: 12
Training loss: 1.006495475769043
Validation loss: 1.7670518172684537

Epoch: 6| Step: 13
Training loss: 0.42237675189971924
Validation loss: 1.7871653726024013

Epoch: 359| Step: 0
Training loss: 0.8112972974777222
Validation loss: 1.7807323125100905

Epoch: 6| Step: 1
Training loss: 0.4510376453399658
Validation loss: 1.7884520087190854

Epoch: 6| Step: 2
Training loss: 0.8136495351791382
Validation loss: 1.7895260780088362

Epoch: 6| Step: 3
Training loss: 0.9610421657562256
Validation loss: 1.7549843019054783

Epoch: 6| Step: 4
Training loss: 0.47024571895599365
Validation loss: 1.786550591068883

Epoch: 6| Step: 5
Training loss: 1.0332931280136108
Validation loss: 1.8268075425137755

Epoch: 6| Step: 6
Training loss: 1.40993332862854
Validation loss: 1.82487351663651

Epoch: 6| Step: 7
Training loss: 1.2045645713806152
Validation loss: 1.7909044373419978

Epoch: 6| Step: 8
Training loss: 1.4170591831207275
Validation loss: 1.7905130540170977

Epoch: 6| Step: 9
Training loss: 0.8466256856918335
Validation loss: 1.7941615350784794

Epoch: 6| Step: 10
Training loss: 1.2904047966003418
Validation loss: 1.7711718031155166

Epoch: 6| Step: 11
Training loss: 1.2230286598205566
Validation loss: 1.7817383273955314

Epoch: 6| Step: 12
Training loss: 0.7772949934005737
Validation loss: 1.771030996435432

Epoch: 6| Step: 13
Training loss: 1.362945556640625
Validation loss: 1.7556784511894308

Epoch: 360| Step: 0
Training loss: 0.648308515548706
Validation loss: 1.7526715545244114

Epoch: 6| Step: 1
Training loss: 1.0231776237487793
Validation loss: 1.7466878557717929

Epoch: 6| Step: 2
Training loss: 1.044041395187378
Validation loss: 1.7562928007495018

Epoch: 6| Step: 3
Training loss: 0.9653393030166626
Validation loss: 1.7582239207401071

Epoch: 6| Step: 4
Training loss: 0.782282292842865
Validation loss: 1.7501065487502723

Epoch: 6| Step: 5
Training loss: 0.6935583353042603
Validation loss: 1.7605937168162356

Epoch: 6| Step: 6
Training loss: 1.095487117767334
Validation loss: 1.7550879178508636

Epoch: 6| Step: 7
Training loss: 1.5876331329345703
Validation loss: 1.7456971317209222

Epoch: 6| Step: 8
Training loss: 0.8429234027862549
Validation loss: 1.798067892751386

Epoch: 6| Step: 9
Training loss: 1.474726915359497
Validation loss: 1.811856282654629

Epoch: 6| Step: 10
Training loss: 1.1004811525344849
Validation loss: 1.8149431649074759

Epoch: 6| Step: 11
Training loss: 0.8509833812713623
Validation loss: 1.8177135298329015

Epoch: 6| Step: 12
Training loss: 1.130005121231079
Validation loss: 1.8046624955310617

Epoch: 6| Step: 13
Training loss: 0.6794090270996094
Validation loss: 1.7590922258233512

Epoch: 361| Step: 0
Training loss: 0.9418027400970459
Validation loss: 1.757774572218618

Epoch: 6| Step: 1
Training loss: 0.7639153599739075
Validation loss: 1.763045677574732

Epoch: 6| Step: 2
Training loss: 1.3368077278137207
Validation loss: 1.7783951836247598

Epoch: 6| Step: 3
Training loss: 1.3837635517120361
Validation loss: 1.771461235579624

Epoch: 6| Step: 4
Training loss: 0.8582403659820557
Validation loss: 1.7458385088110482

Epoch: 6| Step: 5
Training loss: 1.1826400756835938
Validation loss: 1.7279774271031862

Epoch: 6| Step: 6
Training loss: 0.8204342126846313
Validation loss: 1.739999416053936

Epoch: 6| Step: 7
Training loss: 0.8669536113739014
Validation loss: 1.7894551843725226

Epoch: 6| Step: 8
Training loss: 1.03914213180542
Validation loss: 1.7938252956636491

Epoch: 6| Step: 9
Training loss: 0.4952869713306427
Validation loss: 1.787730020861472

Epoch: 6| Step: 10
Training loss: 1.259476661682129
Validation loss: 1.7978473312111312

Epoch: 6| Step: 11
Training loss: 1.2089639902114868
Validation loss: 1.7576361984334967

Epoch: 6| Step: 12
Training loss: 0.9118051528930664
Validation loss: 1.7069912290060392

Epoch: 6| Step: 13
Training loss: 0.9797676801681519
Validation loss: 1.724410782578171

Epoch: 362| Step: 0
Training loss: 1.0382263660430908
Validation loss: 1.753788592994854

Epoch: 6| Step: 1
Training loss: 1.3979592323303223
Validation loss: 1.7586975533475158

Epoch: 6| Step: 2
Training loss: 0.944976806640625
Validation loss: 1.7278886405370568

Epoch: 6| Step: 3
Training loss: 1.256264567375183
Validation loss: 1.7569643707685574

Epoch: 6| Step: 4
Training loss: 1.0077341794967651
Validation loss: 1.7886949508420882

Epoch: 6| Step: 5
Training loss: 0.7643434405326843
Validation loss: 1.77175163069079

Epoch: 6| Step: 6
Training loss: 1.057544469833374
Validation loss: 1.819559576690838

Epoch: 6| Step: 7
Training loss: 0.721943736076355
Validation loss: 1.8113464091413765

Epoch: 6| Step: 8
Training loss: 0.6265382766723633
Validation loss: 1.8010719681298861

Epoch: 6| Step: 9
Training loss: 0.9231196641921997
Validation loss: 1.791773021862071

Epoch: 6| Step: 10
Training loss: 0.8553057909011841
Validation loss: 1.7926804634832567

Epoch: 6| Step: 11
Training loss: 1.1333967447280884
Validation loss: 1.7765618652425788

Epoch: 6| Step: 12
Training loss: 0.8901997804641724
Validation loss: 1.7627588446422289

Epoch: 6| Step: 13
Training loss: 1.2691930532455444
Validation loss: 1.754970637700891

Epoch: 363| Step: 0
Training loss: 0.9170436859130859
Validation loss: 1.7190508970650293

Epoch: 6| Step: 1
Training loss: 1.3561474084854126
Validation loss: 1.7318589007982643

Epoch: 6| Step: 2
Training loss: 1.0636320114135742
Validation loss: 1.7291228284117997

Epoch: 6| Step: 3
Training loss: 0.7831075191497803
Validation loss: 1.7317868445509224

Epoch: 6| Step: 4
Training loss: 0.8873600959777832
Validation loss: 1.735534030263142

Epoch: 6| Step: 5
Training loss: 0.6954806447029114
Validation loss: 1.7253666680346254

Epoch: 6| Step: 6
Training loss: 0.9379383325576782
Validation loss: 1.718873614905983

Epoch: 6| Step: 7
Training loss: 0.7097762823104858
Validation loss: 1.7227060000101726

Epoch: 6| Step: 8
Training loss: 1.3867835998535156
Validation loss: 1.7474881936145086

Epoch: 6| Step: 9
Training loss: 0.5969157218933105
Validation loss: 1.740438481812836

Epoch: 6| Step: 10
Training loss: 0.8017476797103882
Validation loss: 1.7867400274481824

Epoch: 6| Step: 11
Training loss: 1.4293575286865234
Validation loss: 1.785069691237583

Epoch: 6| Step: 12
Training loss: 0.9330456256866455
Validation loss: 1.8086653781193558

Epoch: 6| Step: 13
Training loss: 0.7546914219856262
Validation loss: 1.8174930746837328

Epoch: 364| Step: 0
Training loss: 0.8053910136222839
Validation loss: 1.817488670349121

Epoch: 6| Step: 1
Training loss: 0.6072540879249573
Validation loss: 1.8371555818024503

Epoch: 6| Step: 2
Training loss: 0.9572837948799133
Validation loss: 1.8267445359178769

Epoch: 6| Step: 3
Training loss: 1.0506439208984375
Validation loss: 1.8239633601198915

Epoch: 6| Step: 4
Training loss: 0.8950926661491394
Validation loss: 1.8080039908809047

Epoch: 6| Step: 5
Training loss: 1.5453505516052246
Validation loss: 1.7676602191822504

Epoch: 6| Step: 6
Training loss: 1.2607762813568115
Validation loss: 1.722602948065727

Epoch: 6| Step: 7
Training loss: 0.8238506317138672
Validation loss: 1.7119219841495636

Epoch: 6| Step: 8
Training loss: 0.9425041079521179
Validation loss: 1.7213519568084388

Epoch: 6| Step: 9
Training loss: 0.9829035401344299
Validation loss: 1.7203816662552536

Epoch: 6| Step: 10
Training loss: 1.075411081314087
Validation loss: 1.728408944222235

Epoch: 6| Step: 11
Training loss: 1.4741642475128174
Validation loss: 1.7244773577618342

Epoch: 6| Step: 12
Training loss: 0.388177752494812
Validation loss: 1.760281733287278

Epoch: 6| Step: 13
Training loss: 0.4994870722293854
Validation loss: 1.7651016314824421

Epoch: 365| Step: 0
Training loss: 0.4966750741004944
Validation loss: 1.8104679885730948

Epoch: 6| Step: 1
Training loss: 0.8470799922943115
Validation loss: 1.815100060996189

Epoch: 6| Step: 2
Training loss: 1.0934176445007324
Validation loss: 1.8287927463490476

Epoch: 6| Step: 3
Training loss: 1.0897033214569092
Validation loss: 1.8350122462036789

Epoch: 6| Step: 4
Training loss: 0.8020410537719727
Validation loss: 1.82032746653403

Epoch: 6| Step: 5
Training loss: 1.1960315704345703
Validation loss: 1.811097623199545

Epoch: 6| Step: 6
Training loss: 1.1675621271133423
Validation loss: 1.7973786630938131

Epoch: 6| Step: 7
Training loss: 1.4974675178527832
Validation loss: 1.7717368666843702

Epoch: 6| Step: 8
Training loss: 1.2848389148712158
Validation loss: 1.7530072889020365

Epoch: 6| Step: 9
Training loss: 1.1053825616836548
Validation loss: 1.7533495746633059

Epoch: 6| Step: 10
Training loss: 0.5785704851150513
Validation loss: 1.7577998433061826

Epoch: 6| Step: 11
Training loss: 0.2804921865463257
Validation loss: 1.7493059788980792

Epoch: 6| Step: 12
Training loss: 1.0756479501724243
Validation loss: 1.7309782530671807

Epoch: 6| Step: 13
Training loss: 0.9374024868011475
Validation loss: 1.7479252866519395

Epoch: 366| Step: 0
Training loss: 0.8481014370918274
Validation loss: 1.7376675810865176

Epoch: 6| Step: 1
Training loss: 0.8340861797332764
Validation loss: 1.768827897246166

Epoch: 6| Step: 2
Training loss: 1.0355846881866455
Validation loss: 1.7733295181746125

Epoch: 6| Step: 3
Training loss: 1.1574527025222778
Validation loss: 1.7574640961103543

Epoch: 6| Step: 4
Training loss: 0.7927141189575195
Validation loss: 1.762880024089608

Epoch: 6| Step: 5
Training loss: 1.0997681617736816
Validation loss: 1.7866974569136096

Epoch: 6| Step: 6
Training loss: 1.2146251201629639
Validation loss: 1.7801979100832375

Epoch: 6| Step: 7
Training loss: 0.8602066040039062
Validation loss: 1.7803429493340113

Epoch: 6| Step: 8
Training loss: 1.1506404876708984
Validation loss: 1.7600005198550481

Epoch: 6| Step: 9
Training loss: 1.0096532106399536
Validation loss: 1.7544169733601231

Epoch: 6| Step: 10
Training loss: 0.743798017501831
Validation loss: 1.7463322019064298

Epoch: 6| Step: 11
Training loss: 1.1680221557617188
Validation loss: 1.7727075622927757

Epoch: 6| Step: 12
Training loss: 0.7839155197143555
Validation loss: 1.7953164756938975

Epoch: 6| Step: 13
Training loss: 1.0259811878204346
Validation loss: 1.8308543069388277

Epoch: 367| Step: 0
Training loss: 0.933143675327301
Validation loss: 1.8247926632563274

Epoch: 6| Step: 1
Training loss: 1.4804531335830688
Validation loss: 1.75252535522625

Epoch: 6| Step: 2
Training loss: 0.8369128704071045
Validation loss: 1.7157800735965851

Epoch: 6| Step: 3
Training loss: 0.722748875617981
Validation loss: 1.7107078811173797

Epoch: 6| Step: 4
Training loss: 0.6632035374641418
Validation loss: 1.759686964814381

Epoch: 6| Step: 5
Training loss: 0.8570986390113831
Validation loss: 1.7858771995831562

Epoch: 6| Step: 6
Training loss: 0.8480318188667297
Validation loss: 1.7601869580566243

Epoch: 6| Step: 7
Training loss: 1.2849674224853516
Validation loss: 1.730186100929014

Epoch: 6| Step: 8
Training loss: 1.048885464668274
Validation loss: 1.7082159660195793

Epoch: 6| Step: 9
Training loss: 1.0110046863555908
Validation loss: 1.7638670757252684

Epoch: 6| Step: 10
Training loss: 1.4295709133148193
Validation loss: 1.792250310221026

Epoch: 6| Step: 11
Training loss: 1.0218186378479004
Validation loss: 1.797651235775281

Epoch: 6| Step: 12
Training loss: 0.9081676006317139
Validation loss: 1.785100798453054

Epoch: 6| Step: 13
Training loss: 0.7867956161499023
Validation loss: 1.7651664928723407

Epoch: 368| Step: 0
Training loss: 0.9708528518676758
Validation loss: 1.7353880200334775

Epoch: 6| Step: 1
Training loss: 0.7943747043609619
Validation loss: 1.744917779840449

Epoch: 6| Step: 2
Training loss: 1.164417028427124
Validation loss: 1.746583233597458

Epoch: 6| Step: 3
Training loss: 0.7375447750091553
Validation loss: 1.7283111887593423

Epoch: 6| Step: 4
Training loss: 0.7976418733596802
Validation loss: 1.7770260072523547

Epoch: 6| Step: 5
Training loss: 1.1347333192825317
Validation loss: 1.7883216475927701

Epoch: 6| Step: 6
Training loss: 1.1271758079528809
Validation loss: 1.8105491848402127

Epoch: 6| Step: 7
Training loss: 1.6811327934265137
Validation loss: 1.802053411801656

Epoch: 6| Step: 8
Training loss: 0.8223702907562256
Validation loss: 1.8136341789717316

Epoch: 6| Step: 9
Training loss: 1.012411117553711
Validation loss: 1.792286548563229

Epoch: 6| Step: 10
Training loss: 0.9271868467330933
Validation loss: 1.7818179310009044

Epoch: 6| Step: 11
Training loss: 0.6589094996452332
Validation loss: 1.7414451875994283

Epoch: 6| Step: 12
Training loss: 0.8986454010009766
Validation loss: 1.704323745542957

Epoch: 6| Step: 13
Training loss: 0.6654880046844482
Validation loss: 1.7244189259826497

Epoch: 369| Step: 0
Training loss: 1.1782004833221436
Validation loss: 1.7106765765015797

Epoch: 6| Step: 1
Training loss: 0.6979252099990845
Validation loss: 1.681294862942029

Epoch: 6| Step: 2
Training loss: 0.7918064594268799
Validation loss: 1.6909187993695658

Epoch: 6| Step: 3
Training loss: 0.7449967861175537
Validation loss: 1.7097839668232908

Epoch: 6| Step: 4
Training loss: 0.781911313533783
Validation loss: 1.7076476414998372

Epoch: 6| Step: 5
Training loss: 0.8294858932495117
Validation loss: 1.7003144012984408

Epoch: 6| Step: 6
Training loss: 1.2652292251586914
Validation loss: 1.7090536817427604

Epoch: 6| Step: 7
Training loss: 1.01008939743042
Validation loss: 1.7552788411417315

Epoch: 6| Step: 8
Training loss: 1.009507179260254
Validation loss: 1.776788778202508

Epoch: 6| Step: 9
Training loss: 1.0983721017837524
Validation loss: 1.7598112808760775

Epoch: 6| Step: 10
Training loss: 0.8919492959976196
Validation loss: 1.823855112957698

Epoch: 6| Step: 11
Training loss: 0.9083333015441895
Validation loss: 1.7931544447457919

Epoch: 6| Step: 12
Training loss: 1.1841906309127808
Validation loss: 1.803648925596668

Epoch: 6| Step: 13
Training loss: 1.2300220727920532
Validation loss: 1.795110833260321

Epoch: 370| Step: 0
Training loss: 0.8553623557090759
Validation loss: 1.778662645688621

Epoch: 6| Step: 1
Training loss: 0.8207961916923523
Validation loss: 1.769374801266578

Epoch: 6| Step: 2
Training loss: 0.6494158506393433
Validation loss: 1.7685064949015135

Epoch: 6| Step: 3
Training loss: 0.975350022315979
Validation loss: 1.7664542736545685

Epoch: 6| Step: 4
Training loss: 0.7599091529846191
Validation loss: 1.7711630329009025

Epoch: 6| Step: 5
Training loss: 0.6253723502159119
Validation loss: 1.7601762663933538

Epoch: 6| Step: 6
Training loss: 1.1941531896591187
Validation loss: 1.7484589622866722

Epoch: 6| Step: 7
Training loss: 1.0026031732559204
Validation loss: 1.7429550065789172

Epoch: 6| Step: 8
Training loss: 1.16972815990448
Validation loss: 1.7308900330656318

Epoch: 6| Step: 9
Training loss: 0.9781328439712524
Validation loss: 1.711416511125462

Epoch: 6| Step: 10
Training loss: 1.3512519598007202
Validation loss: 1.6986181146355086

Epoch: 6| Step: 11
Training loss: 0.9666701555252075
Validation loss: 1.6874908247301657

Epoch: 6| Step: 12
Training loss: 1.1540706157684326
Validation loss: 1.7178581478775188

Epoch: 6| Step: 13
Training loss: 0.5499699115753174
Validation loss: 1.7331262455191663

Epoch: 371| Step: 0
Training loss: 1.151068925857544
Validation loss: 1.7238860002128027

Epoch: 6| Step: 1
Training loss: 0.7889489531517029
Validation loss: 1.725019424192367

Epoch: 6| Step: 2
Training loss: 1.586883783340454
Validation loss: 1.7457162334072975

Epoch: 6| Step: 3
Training loss: 1.537950038909912
Validation loss: 1.7283020173349688

Epoch: 6| Step: 4
Training loss: 0.7137884497642517
Validation loss: 1.7523574431737263

Epoch: 6| Step: 5
Training loss: 1.036189317703247
Validation loss: 1.7656665155964513

Epoch: 6| Step: 6
Training loss: 1.1676974296569824
Validation loss: 1.803822704540786

Epoch: 6| Step: 7
Training loss: 0.6519186496734619
Validation loss: 1.8313633024051625

Epoch: 6| Step: 8
Training loss: 0.5263475179672241
Validation loss: 1.8738809477898382

Epoch: 6| Step: 9
Training loss: 1.1647835969924927
Validation loss: 1.8342547096231931

Epoch: 6| Step: 10
Training loss: 0.5882713794708252
Validation loss: 1.8204663133108487

Epoch: 6| Step: 11
Training loss: 0.9370042085647583
Validation loss: 1.8234876009725756

Epoch: 6| Step: 12
Training loss: 1.0918071269989014
Validation loss: 1.8030708284788235

Epoch: 6| Step: 13
Training loss: 0.7373358011245728
Validation loss: 1.7700661497731363

Epoch: 372| Step: 0
Training loss: 0.7909884452819824
Validation loss: 1.7637818013468096

Epoch: 6| Step: 1
Training loss: 0.5074166655540466
Validation loss: 1.7441248663010136

Epoch: 6| Step: 2
Training loss: 1.4768579006195068
Validation loss: 1.6982525253808627

Epoch: 6| Step: 3
Training loss: 1.3051180839538574
Validation loss: 1.687378660325081

Epoch: 6| Step: 4
Training loss: 0.8995370864868164
Validation loss: 1.7015676242049023

Epoch: 6| Step: 5
Training loss: 0.38687264919281006
Validation loss: 1.7096191478031937

Epoch: 6| Step: 6
Training loss: 1.164684772491455
Validation loss: 1.7136626243591309

Epoch: 6| Step: 7
Training loss: 1.0567712783813477
Validation loss: 1.7182925362740793

Epoch: 6| Step: 8
Training loss: 0.8854593634605408
Validation loss: 1.7150048004683627

Epoch: 6| Step: 9
Training loss: 0.8799389600753784
Validation loss: 1.6946828352507723

Epoch: 6| Step: 10
Training loss: 1.1722831726074219
Validation loss: 1.7061829566955566

Epoch: 6| Step: 11
Training loss: 0.8891973495483398
Validation loss: 1.7258837530689854

Epoch: 6| Step: 12
Training loss: 0.9363565444946289
Validation loss: 1.7538542568042714

Epoch: 6| Step: 13
Training loss: 0.6456809639930725
Validation loss: 1.7466669249278244

Epoch: 373| Step: 0
Training loss: 1.4274872541427612
Validation loss: 1.7620981098503194

Epoch: 6| Step: 1
Training loss: 0.7385400533676147
Validation loss: 1.7722772859757947

Epoch: 6| Step: 2
Training loss: 1.0363835096359253
Validation loss: 1.756433839439064

Epoch: 6| Step: 3
Training loss: 0.8964838981628418
Validation loss: 1.7649054937465216

Epoch: 6| Step: 4
Training loss: 0.5376365184783936
Validation loss: 1.7720177711979035

Epoch: 6| Step: 5
Training loss: 1.1881332397460938
Validation loss: 1.7517338824528519

Epoch: 6| Step: 6
Training loss: 1.075219988822937
Validation loss: 1.7178638032687608

Epoch: 6| Step: 7
Training loss: 0.6920183300971985
Validation loss: 1.7229904128659157

Epoch: 6| Step: 8
Training loss: 0.7468783855438232
Validation loss: 1.7352058451662782

Epoch: 6| Step: 9
Training loss: 0.9563788175582886
Validation loss: 1.7267283624218357

Epoch: 6| Step: 10
Training loss: 0.7881250381469727
Validation loss: 1.7066805272973993

Epoch: 6| Step: 11
Training loss: 1.369573950767517
Validation loss: 1.7197076697503366

Epoch: 6| Step: 12
Training loss: 0.666935384273529
Validation loss: 1.7300733622684275

Epoch: 6| Step: 13
Training loss: 0.48194974660873413
Validation loss: 1.7276888457677697

Epoch: 374| Step: 0
Training loss: 0.6732892394065857
Validation loss: 1.6952766295402282

Epoch: 6| Step: 1
Training loss: 0.6267843842506409
Validation loss: 1.7092757558309903

Epoch: 6| Step: 2
Training loss: 0.9851412177085876
Validation loss: 1.7036614007847284

Epoch: 6| Step: 3
Training loss: 1.3043090105056763
Validation loss: 1.7358176964585499

Epoch: 6| Step: 4
Training loss: 0.9362432360649109
Validation loss: 1.7311399367547804

Epoch: 6| Step: 5
Training loss: 0.5604506731033325
Validation loss: 1.7181327727533156

Epoch: 6| Step: 6
Training loss: 0.7308082580566406
Validation loss: 1.746424481432925

Epoch: 6| Step: 7
Training loss: 1.2125424146652222
Validation loss: 1.7408564757275324

Epoch: 6| Step: 8
Training loss: 1.3455290794372559
Validation loss: 1.7316454610516947

Epoch: 6| Step: 9
Training loss: 0.7454637289047241
Validation loss: 1.7303991984295588

Epoch: 6| Step: 10
Training loss: 0.9983969926834106
Validation loss: 1.7395005418408302

Epoch: 6| Step: 11
Training loss: 0.452597975730896
Validation loss: 1.7170358127163303

Epoch: 6| Step: 12
Training loss: 0.6933431625366211
Validation loss: 1.7462315315841346

Epoch: 6| Step: 13
Training loss: 1.3368250131607056
Validation loss: 1.7481809405870334

Epoch: 375| Step: 0
Training loss: 0.6378365159034729
Validation loss: 1.7220264122050295

Epoch: 6| Step: 1
Training loss: 0.5729027390480042
Validation loss: 1.7494872154728058

Epoch: 6| Step: 2
Training loss: 0.8752415180206299
Validation loss: 1.7499990129983554

Epoch: 6| Step: 3
Training loss: 0.8555436134338379
Validation loss: 1.7323941915265975

Epoch: 6| Step: 4
Training loss: 0.740257978439331
Validation loss: 1.7241916387311873

Epoch: 6| Step: 5
Training loss: 0.69021075963974
Validation loss: 1.7028882529145928

Epoch: 6| Step: 6
Training loss: 0.9241541028022766
Validation loss: 1.7214953412291825

Epoch: 6| Step: 7
Training loss: 0.8211586475372314
Validation loss: 1.7081960888319119

Epoch: 6| Step: 8
Training loss: 0.5494561791419983
Validation loss: 1.7059972055496708

Epoch: 6| Step: 9
Training loss: 1.262557029724121
Validation loss: 1.7233977830538185

Epoch: 6| Step: 10
Training loss: 1.2345722913742065
Validation loss: 1.728700158416584

Epoch: 6| Step: 11
Training loss: 1.1113910675048828
Validation loss: 1.7053686418840963

Epoch: 6| Step: 12
Training loss: 1.3393330574035645
Validation loss: 1.7004337541518673

Epoch: 6| Step: 13
Training loss: 0.9848908185958862
Validation loss: 1.696066559642874

Epoch: 376| Step: 0
Training loss: 0.8291652798652649
Validation loss: 1.6908967841056086

Epoch: 6| Step: 1
Training loss: 1.0185744762420654
Validation loss: 1.7057038391790083

Epoch: 6| Step: 2
Training loss: 0.6952643394470215
Validation loss: 1.7022847462725896

Epoch: 6| Step: 3
Training loss: 0.8060867786407471
Validation loss: 1.734797853295521

Epoch: 6| Step: 4
Training loss: 0.4181576371192932
Validation loss: 1.7078491731356549

Epoch: 6| Step: 5
Training loss: 1.212097406387329
Validation loss: 1.7101136997181883

Epoch: 6| Step: 6
Training loss: 0.6974204778671265
Validation loss: 1.7341459540910618

Epoch: 6| Step: 7
Training loss: 0.8639345765113831
Validation loss: 1.7347391305431243

Epoch: 6| Step: 8
Training loss: 1.0516310930252075
Validation loss: 1.7286771523055209

Epoch: 6| Step: 9
Training loss: 0.7835508584976196
Validation loss: 1.7252169706488167

Epoch: 6| Step: 10
Training loss: 1.1983181238174438
Validation loss: 1.7366564273834229

Epoch: 6| Step: 11
Training loss: 0.803459644317627
Validation loss: 1.76236427855748

Epoch: 6| Step: 12
Training loss: 1.0261917114257812
Validation loss: 1.7173812261191748

Epoch: 6| Step: 13
Training loss: 1.0586564540863037
Validation loss: 1.7362793312277844

Epoch: 377| Step: 0
Training loss: 1.3599278926849365
Validation loss: 1.7271254447198683

Epoch: 6| Step: 1
Training loss: 0.5213111042976379
Validation loss: 1.7153444623434415

Epoch: 6| Step: 2
Training loss: 1.3408946990966797
Validation loss: 1.71293750052811

Epoch: 6| Step: 3
Training loss: 0.808840811252594
Validation loss: 1.7102856161773845

Epoch: 6| Step: 4
Training loss: 1.017975091934204
Validation loss: 1.7008893246291785

Epoch: 6| Step: 5
Training loss: 0.5562302470207214
Validation loss: 1.6944668446817706

Epoch: 6| Step: 6
Training loss: 1.0338389873504639
Validation loss: 1.7097882916850429

Epoch: 6| Step: 7
Training loss: 1.3554677963256836
Validation loss: 1.7122494841134677

Epoch: 6| Step: 8
Training loss: 0.761746883392334
Validation loss: 1.7043735801532705

Epoch: 6| Step: 9
Training loss: 0.750289797782898
Validation loss: 1.7440155180551673

Epoch: 6| Step: 10
Training loss: 0.6589014530181885
Validation loss: 1.756264704529957

Epoch: 6| Step: 11
Training loss: 1.0482138395309448
Validation loss: 1.773029637593095

Epoch: 6| Step: 12
Training loss: 0.3009871244430542
Validation loss: 1.7243802214181552

Epoch: 6| Step: 13
Training loss: 0.9903799891471863
Validation loss: 1.7291736564328593

Epoch: 378| Step: 0
Training loss: 0.9890927076339722
Validation loss: 1.7169608736550936

Epoch: 6| Step: 1
Training loss: 1.0776536464691162
Validation loss: 1.7329244536738242

Epoch: 6| Step: 2
Training loss: 0.9213114976882935
Validation loss: 1.7058146384454542

Epoch: 6| Step: 3
Training loss: 0.8258638978004456
Validation loss: 1.7420166448880268

Epoch: 6| Step: 4
Training loss: 1.139509677886963
Validation loss: 1.7180213800040625

Epoch: 6| Step: 5
Training loss: 0.5686031579971313
Validation loss: 1.722861143850511

Epoch: 6| Step: 6
Training loss: 1.2755329608917236
Validation loss: 1.7256274351509668

Epoch: 6| Step: 7
Training loss: 0.8640562295913696
Validation loss: 1.7356514341087752

Epoch: 6| Step: 8
Training loss: 0.6537020206451416
Validation loss: 1.7066683000133884

Epoch: 6| Step: 9
Training loss: 0.8336689472198486
Validation loss: 1.725101863184283

Epoch: 6| Step: 10
Training loss: 1.032753348350525
Validation loss: 1.7002669226738714

Epoch: 6| Step: 11
Training loss: 0.9790059328079224
Validation loss: 1.7274488633678806

Epoch: 6| Step: 12
Training loss: 0.406835675239563
Validation loss: 1.6983751558488416

Epoch: 6| Step: 13
Training loss: 0.6030304431915283
Validation loss: 1.7176679847060994

Epoch: 379| Step: 0
Training loss: 0.6596794128417969
Validation loss: 1.714672287305196

Epoch: 6| Step: 1
Training loss: 0.7223397493362427
Validation loss: 1.6940041229289065

Epoch: 6| Step: 2
Training loss: 0.8214263916015625
Validation loss: 1.6850304821486115

Epoch: 6| Step: 3
Training loss: 0.9561851024627686
Validation loss: 1.7040162791487992

Epoch: 6| Step: 4
Training loss: 1.0001485347747803
Validation loss: 1.7118229071299236

Epoch: 6| Step: 5
Training loss: 0.9589505791664124
Validation loss: 1.7283356574273878

Epoch: 6| Step: 6
Training loss: 0.48099130392074585
Validation loss: 1.7408665764716365

Epoch: 6| Step: 7
Training loss: 1.1701325178146362
Validation loss: 1.7366692468684206

Epoch: 6| Step: 8
Training loss: 0.5881443023681641
Validation loss: 1.7522245081522132

Epoch: 6| Step: 9
Training loss: 1.0605614185333252
Validation loss: 1.7700833953836912

Epoch: 6| Step: 10
Training loss: 1.2941646575927734
Validation loss: 1.7478997553548505

Epoch: 6| Step: 11
Training loss: 0.802959144115448
Validation loss: 1.779792857426469

Epoch: 6| Step: 12
Training loss: 0.7197058200836182
Validation loss: 1.7904297510782878

Epoch: 6| Step: 13
Training loss: 1.216941237449646
Validation loss: 1.7492755484837357

Epoch: 380| Step: 0
Training loss: 1.0431065559387207
Validation loss: 1.7659790451808641

Epoch: 6| Step: 1
Training loss: 0.9164301753044128
Validation loss: 1.7481579383214314

Epoch: 6| Step: 2
Training loss: 0.3381485939025879
Validation loss: 1.7627116390453872

Epoch: 6| Step: 3
Training loss: 1.1715753078460693
Validation loss: 1.7680895648976809

Epoch: 6| Step: 4
Training loss: 0.6786787509918213
Validation loss: 1.7427943227111653

Epoch: 6| Step: 5
Training loss: 0.9988473653793335
Validation loss: 1.7236777851658482

Epoch: 6| Step: 6
Training loss: 0.6633328795433044
Validation loss: 1.726180604709092

Epoch: 6| Step: 7
Training loss: 1.2055577039718628
Validation loss: 1.7125951756713211

Epoch: 6| Step: 8
Training loss: 0.7792898416519165
Validation loss: 1.724939230949648

Epoch: 6| Step: 9
Training loss: 0.62177973985672
Validation loss: 1.7096186094386603

Epoch: 6| Step: 10
Training loss: 0.9324319362640381
Validation loss: 1.7049019234154814

Epoch: 6| Step: 11
Training loss: 1.1070191860198975
Validation loss: 1.732718547185262

Epoch: 6| Step: 12
Training loss: 1.090876817703247
Validation loss: 1.734207804485034

Epoch: 6| Step: 13
Training loss: 0.9976332187652588
Validation loss: 1.7483258029466033

Epoch: 381| Step: 0
Training loss: 0.5847753882408142
Validation loss: 1.7828909081797446

Epoch: 6| Step: 1
Training loss: 0.5473326444625854
Validation loss: 1.7468483999211302

Epoch: 6| Step: 2
Training loss: 1.3670854568481445
Validation loss: 1.7649075074862408

Epoch: 6| Step: 3
Training loss: 1.1346449851989746
Validation loss: 1.7923827325144122

Epoch: 6| Step: 4
Training loss: 1.1868919134140015
Validation loss: 1.7519924512473486

Epoch: 6| Step: 5
Training loss: 0.5645124316215515
Validation loss: 1.78392324268177

Epoch: 6| Step: 6
Training loss: 1.3695118427276611
Validation loss: 1.743396250150537

Epoch: 6| Step: 7
Training loss: 0.936937689781189
Validation loss: 1.7476767211832025

Epoch: 6| Step: 8
Training loss: 0.8104081153869629
Validation loss: 1.7111911607044998

Epoch: 6| Step: 9
Training loss: 1.0146013498306274
Validation loss: 1.68122765966641

Epoch: 6| Step: 10
Training loss: 0.7281054258346558
Validation loss: 1.6953443122166458

Epoch: 6| Step: 11
Training loss: 0.9283326864242554
Validation loss: 1.684065846986668

Epoch: 6| Step: 12
Training loss: 0.8026423454284668
Validation loss: 1.712080713241331

Epoch: 6| Step: 13
Training loss: 0.6043429970741272
Validation loss: 1.7016727873074111

Epoch: 382| Step: 0
Training loss: 1.0321177244186401
Validation loss: 1.7222140424995012

Epoch: 6| Step: 1
Training loss: 1.0512652397155762
Validation loss: 1.7631652252648466

Epoch: 6| Step: 2
Training loss: 1.1514887809753418
Validation loss: 1.7464020380409815

Epoch: 6| Step: 3
Training loss: 1.2816627025604248
Validation loss: 1.7628531635448497

Epoch: 6| Step: 4
Training loss: 0.7161322236061096
Validation loss: 1.7712031731041529

Epoch: 6| Step: 5
Training loss: 0.3325022757053375
Validation loss: 1.7485017853398477

Epoch: 6| Step: 6
Training loss: 1.0293301343917847
Validation loss: 1.7441995092617568

Epoch: 6| Step: 7
Training loss: 0.42544323205947876
Validation loss: 1.7070661232035647

Epoch: 6| Step: 8
Training loss: 0.6501624584197998
Validation loss: 1.70681034621372

Epoch: 6| Step: 9
Training loss: 0.5026994347572327
Validation loss: 1.7238355144377677

Epoch: 6| Step: 10
Training loss: 1.2479190826416016
Validation loss: 1.715198447627406

Epoch: 6| Step: 11
Training loss: 1.4748992919921875
Validation loss: 1.6974010057346796

Epoch: 6| Step: 12
Training loss: 0.6444445848464966
Validation loss: 1.7064506879416845

Epoch: 6| Step: 13
Training loss: 0.6745756268501282
Validation loss: 1.6997430093826786

Epoch: 383| Step: 0
Training loss: 1.1497910022735596
Validation loss: 1.711437136896195

Epoch: 6| Step: 1
Training loss: 0.9057687520980835
Validation loss: 1.7291163808556014

Epoch: 6| Step: 2
Training loss: 0.49058085680007935
Validation loss: 1.727930667579815

Epoch: 6| Step: 3
Training loss: 1.0389511585235596
Validation loss: 1.6987471670232794

Epoch: 6| Step: 4
Training loss: 0.8526902794837952
Validation loss: 1.7233601283001643

Epoch: 6| Step: 5
Training loss: 1.1745296716690063
Validation loss: 1.7200931195289857

Epoch: 6| Step: 6
Training loss: 0.697521984577179
Validation loss: 1.6921610704032324

Epoch: 6| Step: 7
Training loss: 0.7410074472427368
Validation loss: 1.688611574070428

Epoch: 6| Step: 8
Training loss: 1.015681266784668
Validation loss: 1.6944610226538874

Epoch: 6| Step: 9
Training loss: 0.68331378698349
Validation loss: 1.6645692779171852

Epoch: 6| Step: 10
Training loss: 0.6010593175888062
Validation loss: 1.680572400810898

Epoch: 6| Step: 11
Training loss: 0.9568519592285156
Validation loss: 1.6882907370085358

Epoch: 6| Step: 12
Training loss: 0.9082164764404297
Validation loss: 1.701345407834617

Epoch: 6| Step: 13
Training loss: 0.9697220921516418
Validation loss: 1.731226280171384

Epoch: 384| Step: 0
Training loss: 0.8550766706466675
Validation loss: 1.7100525799617972

Epoch: 6| Step: 1
Training loss: 0.8021534085273743
Validation loss: 1.7205391788995394

Epoch: 6| Step: 2
Training loss: 0.5689125657081604
Validation loss: 1.7264801827810143

Epoch: 6| Step: 3
Training loss: 0.8268546462059021
Validation loss: 1.7047411357202837

Epoch: 6| Step: 4
Training loss: 0.6513199210166931
Validation loss: 1.7152458775428034

Epoch: 6| Step: 5
Training loss: 1.3990201950073242
Validation loss: 1.7165663421794932

Epoch: 6| Step: 6
Training loss: 0.525073766708374
Validation loss: 1.7202523613488803

Epoch: 6| Step: 7
Training loss: 0.9448649883270264
Validation loss: 1.7285055332286383

Epoch: 6| Step: 8
Training loss: 0.8659243583679199
Validation loss: 1.7008732749569802

Epoch: 6| Step: 9
Training loss: 0.998615026473999
Validation loss: 1.690019258888819

Epoch: 6| Step: 10
Training loss: 0.8567444682121277
Validation loss: 1.6954520645961966

Epoch: 6| Step: 11
Training loss: 0.5882259011268616
Validation loss: 1.7147662998527609

Epoch: 6| Step: 12
Training loss: 0.9181547164916992
Validation loss: 1.721860110118825

Epoch: 6| Step: 13
Training loss: 1.5212478637695312
Validation loss: 1.7058972402285504

Epoch: 385| Step: 0
Training loss: 0.5479049682617188
Validation loss: 1.6978945885935137

Epoch: 6| Step: 1
Training loss: 1.1747472286224365
Validation loss: 1.73101725885945

Epoch: 6| Step: 2
Training loss: 0.8912222981452942
Validation loss: 1.7102456426107755

Epoch: 6| Step: 3
Training loss: 1.0705883502960205
Validation loss: 1.7093406697755218

Epoch: 6| Step: 4
Training loss: 0.7860097885131836
Validation loss: 1.6957176539205736

Epoch: 6| Step: 5
Training loss: 0.8360660076141357
Validation loss: 1.7177936171972623

Epoch: 6| Step: 6
Training loss: 0.8526920080184937
Validation loss: 1.7105502851547734

Epoch: 6| Step: 7
Training loss: 0.7269365787506104
Validation loss: 1.6864326974397064

Epoch: 6| Step: 8
Training loss: 0.7813863754272461
Validation loss: 1.6890792385224374

Epoch: 6| Step: 9
Training loss: 0.9794737100601196
Validation loss: 1.704051076724965

Epoch: 6| Step: 10
Training loss: 0.6162406802177429
Validation loss: 1.719548353584864

Epoch: 6| Step: 11
Training loss: 0.8740829229354858
Validation loss: 1.7426226792796966

Epoch: 6| Step: 12
Training loss: 0.9140352010726929
Validation loss: 1.7547841655310763

Epoch: 6| Step: 13
Training loss: 0.9440314173698425
Validation loss: 1.757744369327381

Epoch: 386| Step: 0
Training loss: 0.6478468179702759
Validation loss: 1.765619707363908

Epoch: 6| Step: 1
Training loss: 1.0928337574005127
Validation loss: 1.7574680261714484

Epoch: 6| Step: 2
Training loss: 0.9067925214767456
Validation loss: 1.738493811699652

Epoch: 6| Step: 3
Training loss: 0.9152624011039734
Validation loss: 1.7138482883412351

Epoch: 6| Step: 4
Training loss: 1.0715487003326416
Validation loss: 1.7055981812938568

Epoch: 6| Step: 5
Training loss: 1.2559418678283691
Validation loss: 1.7197118856573617

Epoch: 6| Step: 6
Training loss: 0.9642436504364014
Validation loss: 1.7355277281935497

Epoch: 6| Step: 7
Training loss: 0.5816596746444702
Validation loss: 1.7111192364846506

Epoch: 6| Step: 8
Training loss: 0.5769917964935303
Validation loss: 1.7109502694940055

Epoch: 6| Step: 9
Training loss: 1.1751315593719482
Validation loss: 1.7205468711032663

Epoch: 6| Step: 10
Training loss: 0.6282200813293457
Validation loss: 1.73530964825743

Epoch: 6| Step: 11
Training loss: 0.40608227252960205
Validation loss: 1.7376811517182218

Epoch: 6| Step: 12
Training loss: 0.6955252885818481
Validation loss: 1.7630671455014137

Epoch: 6| Step: 13
Training loss: 0.6719170808792114
Validation loss: 1.7755345606034802

Epoch: 387| Step: 0
Training loss: 1.0784847736358643
Validation loss: 1.7864581641330515

Epoch: 6| Step: 1
Training loss: 0.8305294513702393
Validation loss: 1.7731349160594325

Epoch: 6| Step: 2
Training loss: 0.8191512823104858
Validation loss: 1.7954714439248527

Epoch: 6| Step: 3
Training loss: 1.1084790229797363
Validation loss: 1.7796170596153504

Epoch: 6| Step: 4
Training loss: 0.7826108932495117
Validation loss: 1.7673812002264044

Epoch: 6| Step: 5
Training loss: 0.7821890711784363
Validation loss: 1.735318019825925

Epoch: 6| Step: 6
Training loss: 0.7315310835838318
Validation loss: 1.7393962593488796

Epoch: 6| Step: 7
Training loss: 0.8799872398376465
Validation loss: 1.7136603747644732

Epoch: 6| Step: 8
Training loss: 0.8164573907852173
Validation loss: 1.7134432427344783

Epoch: 6| Step: 9
Training loss: 1.107799768447876
Validation loss: 1.7122708084762737

Epoch: 6| Step: 10
Training loss: 0.4068392515182495
Validation loss: 1.701621837513421

Epoch: 6| Step: 11
Training loss: 1.1299372911453247
Validation loss: 1.7080240198360976

Epoch: 6| Step: 12
Training loss: 0.7641869783401489
Validation loss: 1.7091461996878348

Epoch: 6| Step: 13
Training loss: 0.5170342326164246
Validation loss: 1.696503318766112

Epoch: 388| Step: 0
Training loss: 1.2887041568756104
Validation loss: 1.682000660127209

Epoch: 6| Step: 1
Training loss: 0.5863062143325806
Validation loss: 1.7148745521422355

Epoch: 6| Step: 2
Training loss: 0.7815310955047607
Validation loss: 1.6893377573259416

Epoch: 6| Step: 3
Training loss: 0.721839964389801
Validation loss: 1.7149172085587696

Epoch: 6| Step: 4
Training loss: 1.0508408546447754
Validation loss: 1.720155958206423

Epoch: 6| Step: 5
Training loss: 0.8972392082214355
Validation loss: 1.7625806587998585

Epoch: 6| Step: 6
Training loss: 0.619013786315918
Validation loss: 1.7452605027024464

Epoch: 6| Step: 7
Training loss: 0.9171310663223267
Validation loss: 1.7803021464296567

Epoch: 6| Step: 8
Training loss: 0.837064266204834
Validation loss: 1.7507259820097236

Epoch: 6| Step: 9
Training loss: 0.7022322416305542
Validation loss: 1.7337623462882092

Epoch: 6| Step: 10
Training loss: 1.1717400550842285
Validation loss: 1.7232905946752077

Epoch: 6| Step: 11
Training loss: 0.7027950286865234
Validation loss: 1.686924329368017

Epoch: 6| Step: 12
Training loss: 0.9885575175285339
Validation loss: 1.713369276574863

Epoch: 6| Step: 13
Training loss: 0.8197300434112549
Validation loss: 1.695255087267968

Epoch: 389| Step: 0
Training loss: 1.1161577701568604
Validation loss: 1.6922687003689427

Epoch: 6| Step: 1
Training loss: 0.5890543460845947
Validation loss: 1.7004240892266715

Epoch: 6| Step: 2
Training loss: 1.3879876136779785
Validation loss: 1.731048899312173

Epoch: 6| Step: 3
Training loss: 0.9817736148834229
Validation loss: 1.757259823942697

Epoch: 6| Step: 4
Training loss: 0.4373854398727417
Validation loss: 1.7459414505189466

Epoch: 6| Step: 5
Training loss: 0.7307584881782532
Validation loss: 1.743117300412988

Epoch: 6| Step: 6
Training loss: 0.8993452787399292
Validation loss: 1.7796813147042387

Epoch: 6| Step: 7
Training loss: 1.0314345359802246
Validation loss: 1.7355309788898756

Epoch: 6| Step: 8
Training loss: 0.8630973696708679
Validation loss: 1.7422936911224036

Epoch: 6| Step: 9
Training loss: 0.5189113020896912
Validation loss: 1.7305677911286712

Epoch: 6| Step: 10
Training loss: 0.7709245085716248
Validation loss: 1.7302219162705124

Epoch: 6| Step: 11
Training loss: 0.6861075162887573
Validation loss: 1.7090616251832695

Epoch: 6| Step: 12
Training loss: 1.0458316802978516
Validation loss: 1.727501097545829

Epoch: 6| Step: 13
Training loss: 0.2590620815753937
Validation loss: 1.7213473550734981

Epoch: 390| Step: 0
Training loss: 0.8953860402107239
Validation loss: 1.7266677771845171

Epoch: 6| Step: 1
Training loss: 0.7358114719390869
Validation loss: 1.7256015462260093

Epoch: 6| Step: 2
Training loss: 0.9420549869537354
Validation loss: 1.7325858903187576

Epoch: 6| Step: 3
Training loss: 0.8419054746627808
Validation loss: 1.7180464511276574

Epoch: 6| Step: 4
Training loss: 0.5272819995880127
Validation loss: 1.7265930124508437

Epoch: 6| Step: 5
Training loss: 0.38813716173171997
Validation loss: 1.7147934872617003

Epoch: 6| Step: 6
Training loss: 0.6687967777252197
Validation loss: 1.7139206342799689

Epoch: 6| Step: 7
Training loss: 1.082454800605774
Validation loss: 1.7081841679029568

Epoch: 6| Step: 8
Training loss: 0.9717919826507568
Validation loss: 1.7173481372094923

Epoch: 6| Step: 9
Training loss: 0.8343870043754578
Validation loss: 1.7242297741674608

Epoch: 6| Step: 10
Training loss: 0.9205291867256165
Validation loss: 1.708925329228883

Epoch: 6| Step: 11
Training loss: 1.146611213684082
Validation loss: 1.6942260675532843

Epoch: 6| Step: 12
Training loss: 0.9663828015327454
Validation loss: 1.7081579162228493

Epoch: 6| Step: 13
Training loss: 0.302848219871521
Validation loss: 1.6950473003489996

Epoch: 391| Step: 0
Training loss: 0.7694125175476074
Validation loss: 1.6893722729016376

Epoch: 6| Step: 1
Training loss: 1.3669270277023315
Validation loss: 1.6984239867938462

Epoch: 6| Step: 2
Training loss: 0.9199064373970032
Validation loss: 1.7061786369610858

Epoch: 6| Step: 3
Training loss: 0.6466025114059448
Validation loss: 1.6840088803281066

Epoch: 6| Step: 4
Training loss: 0.995082437992096
Validation loss: 1.7241303779745614

Epoch: 6| Step: 5
Training loss: 0.5705884695053101
Validation loss: 1.6900544217837754

Epoch: 6| Step: 6
Training loss: 0.788318395614624
Validation loss: 1.6904666923707532

Epoch: 6| Step: 7
Training loss: 0.7652677893638611
Validation loss: 1.6904987955606112

Epoch: 6| Step: 8
Training loss: 1.0208237171173096
Validation loss: 1.679831862449646

Epoch: 6| Step: 9
Training loss: 0.6411269307136536
Validation loss: 1.6886803155304284

Epoch: 6| Step: 10
Training loss: 0.6426566243171692
Validation loss: 1.6671965391405168

Epoch: 6| Step: 11
Training loss: 0.8144530653953552
Validation loss: 1.6862112117070023

Epoch: 6| Step: 12
Training loss: 0.7101258039474487
Validation loss: 1.6730554680670462

Epoch: 6| Step: 13
Training loss: 1.1332589387893677
Validation loss: 1.6737705417858657

Epoch: 392| Step: 0
Training loss: 0.8034172058105469
Validation loss: 1.6719888499988023

Epoch: 6| Step: 1
Training loss: 0.6599252223968506
Validation loss: 1.69231120745341

Epoch: 6| Step: 2
Training loss: 0.9754786491394043
Validation loss: 1.7073869141199256

Epoch: 6| Step: 3
Training loss: 0.7521541118621826
Validation loss: 1.717060765912456

Epoch: 6| Step: 4
Training loss: 0.7945654988288879
Validation loss: 1.7296323417335429

Epoch: 6| Step: 5
Training loss: 1.1744619607925415
Validation loss: 1.7480066219965618

Epoch: 6| Step: 6
Training loss: 0.8248521685600281
Validation loss: 1.7252349699697187

Epoch: 6| Step: 7
Training loss: 0.6368942856788635
Validation loss: 1.740772540851306

Epoch: 6| Step: 8
Training loss: 0.5988170504570007
Validation loss: 1.708156567747875

Epoch: 6| Step: 9
Training loss: 0.9924783706665039
Validation loss: 1.7149047095288512

Epoch: 6| Step: 10
Training loss: 1.0194453001022339
Validation loss: 1.7224637590428835

Epoch: 6| Step: 11
Training loss: 1.1624228954315186
Validation loss: 1.7016138389546385

Epoch: 6| Step: 12
Training loss: 0.4709767997264862
Validation loss: 1.705315379686253

Epoch: 6| Step: 13
Training loss: 0.663712739944458
Validation loss: 1.693050584485454

Epoch: 393| Step: 0
Training loss: 1.148875117301941
Validation loss: 1.6889917773585166

Epoch: 6| Step: 1
Training loss: 0.7908656001091003
Validation loss: 1.6720514425667383

Epoch: 6| Step: 2
Training loss: 1.055488109588623
Validation loss: 1.6817208515700472

Epoch: 6| Step: 3
Training loss: 0.7661310434341431
Validation loss: 1.6938356814845916

Epoch: 6| Step: 4
Training loss: 1.0496431589126587
Validation loss: 1.683456547798649

Epoch: 6| Step: 5
Training loss: 0.6633709669113159
Validation loss: 1.683406114578247

Epoch: 6| Step: 6
Training loss: 0.6203842163085938
Validation loss: 1.6829331677447084

Epoch: 6| Step: 7
Training loss: 0.6239601373672485
Validation loss: 1.7056467328020322

Epoch: 6| Step: 8
Training loss: 1.0246155261993408
Validation loss: 1.6997019898506902

Epoch: 6| Step: 9
Training loss: 0.7491263747215271
Validation loss: 1.725951971546296

Epoch: 6| Step: 10
Training loss: 0.6442131996154785
Validation loss: 1.7378335498994397

Epoch: 6| Step: 11
Training loss: 0.5762995481491089
Validation loss: 1.742503091853152

Epoch: 6| Step: 12
Training loss: 0.8198174834251404
Validation loss: 1.7298024162169425

Epoch: 6| Step: 13
Training loss: 1.3512002229690552
Validation loss: 1.7130716513561945

Epoch: 394| Step: 0
Training loss: 0.53790283203125
Validation loss: 1.6888110996574484

Epoch: 6| Step: 1
Training loss: 0.861803412437439
Validation loss: 1.7002639719235

Epoch: 6| Step: 2
Training loss: 0.5711398124694824
Validation loss: 1.677378826243903

Epoch: 6| Step: 3
Training loss: 0.9039260149002075
Validation loss: 1.6573002248682

Epoch: 6| Step: 4
Training loss: 0.8617631793022156
Validation loss: 1.6740115265692435

Epoch: 6| Step: 5
Training loss: 0.44545310735702515
Validation loss: 1.666168374399985

Epoch: 6| Step: 6
Training loss: 0.8156030774116516
Validation loss: 1.6779244881804272

Epoch: 6| Step: 7
Training loss: 1.417600393295288
Validation loss: 1.6791256986638552

Epoch: 6| Step: 8
Training loss: 1.0169336795806885
Validation loss: 1.6855150076650804

Epoch: 6| Step: 9
Training loss: 0.771918535232544
Validation loss: 1.6999241818663895

Epoch: 6| Step: 10
Training loss: 0.6548371315002441
Validation loss: 1.6834218245680614

Epoch: 6| Step: 11
Training loss: 0.8973156213760376
Validation loss: 1.6989112566876154

Epoch: 6| Step: 12
Training loss: 0.9568696022033691
Validation loss: 1.6752403474623156

Epoch: 6| Step: 13
Training loss: 0.8200792074203491
Validation loss: 1.7169851013409194

Epoch: 395| Step: 0
Training loss: 0.6373331546783447
Validation loss: 1.6781472300970426

Epoch: 6| Step: 1
Training loss: 0.5273897051811218
Validation loss: 1.7054428644077753

Epoch: 6| Step: 2
Training loss: 1.0438371896743774
Validation loss: 1.6710367356577227

Epoch: 6| Step: 3
Training loss: 1.070547103881836
Validation loss: 1.6786910641577937

Epoch: 6| Step: 4
Training loss: 0.8914207816123962
Validation loss: 1.6717195299363905

Epoch: 6| Step: 5
Training loss: 0.584865927696228
Validation loss: 1.6836055606924079

Epoch: 6| Step: 6
Training loss: 0.7404271364212036
Validation loss: 1.6740151810389694

Epoch: 6| Step: 7
Training loss: 0.760613203048706
Validation loss: 1.6617596969809583

Epoch: 6| Step: 8
Training loss: 1.1470930576324463
Validation loss: 1.6677170748351722

Epoch: 6| Step: 9
Training loss: 0.6672723889350891
Validation loss: 1.709161562304343

Epoch: 6| Step: 10
Training loss: 1.188056230545044
Validation loss: 1.7236589898345291

Epoch: 6| Step: 11
Training loss: 1.100765347480774
Validation loss: 1.7479473519068893

Epoch: 6| Step: 12
Training loss: 0.7062786817550659
Validation loss: 1.762372434780162

Epoch: 6| Step: 13
Training loss: 0.760080099105835
Validation loss: 1.7523584929845666

Epoch: 396| Step: 0
Training loss: 0.7977166175842285
Validation loss: 1.7485684348690895

Epoch: 6| Step: 1
Training loss: 0.8896589279174805
Validation loss: 1.7623087142103462

Epoch: 6| Step: 2
Training loss: 1.097107172012329
Validation loss: 1.7264908846988474

Epoch: 6| Step: 3
Training loss: 0.7840196490287781
Validation loss: 1.7305566034009379

Epoch: 6| Step: 4
Training loss: 0.578235924243927
Validation loss: 1.734159714432173

Epoch: 6| Step: 5
Training loss: 1.2128061056137085
Validation loss: 1.7144297444692222

Epoch: 6| Step: 6
Training loss: 0.47534310817718506
Validation loss: 1.6930080767600768

Epoch: 6| Step: 7
Training loss: 1.032055377960205
Validation loss: 1.6869056814460344

Epoch: 6| Step: 8
Training loss: 0.6596352458000183
Validation loss: 1.6902537563795685

Epoch: 6| Step: 9
Training loss: 0.9860808253288269
Validation loss: 1.7201573938451789

Epoch: 6| Step: 10
Training loss: 1.1571099758148193
Validation loss: 1.7090208735517276

Epoch: 6| Step: 11
Training loss: 0.4956720471382141
Validation loss: 1.7514400559086953

Epoch: 6| Step: 12
Training loss: 0.5815587043762207
Validation loss: 1.7407352526982625

Epoch: 6| Step: 13
Training loss: 1.3578457832336426
Validation loss: 1.7340184860332037

Epoch: 397| Step: 0
Training loss: 0.706710159778595
Validation loss: 1.7139066662839664

Epoch: 6| Step: 1
Training loss: 0.9965866804122925
Validation loss: 1.7473279096746956

Epoch: 6| Step: 2
Training loss: 0.8851377964019775
Validation loss: 1.7561818374100553

Epoch: 6| Step: 3
Training loss: 1.0078448057174683
Validation loss: 1.8087556862062024

Epoch: 6| Step: 4
Training loss: 1.0195480585098267
Validation loss: 1.754645195058597

Epoch: 6| Step: 5
Training loss: 0.8285548686981201
Validation loss: 1.7348025178396573

Epoch: 6| Step: 6
Training loss: 0.8434076905250549
Validation loss: 1.719089336292718

Epoch: 6| Step: 7
Training loss: 0.5867454409599304
Validation loss: 1.706624085544258

Epoch: 6| Step: 8
Training loss: 0.8802001476287842
Validation loss: 1.7185935820302656

Epoch: 6| Step: 9
Training loss: 0.9440336227416992
Validation loss: 1.7788481225249588

Epoch: 6| Step: 10
Training loss: 0.739417552947998
Validation loss: 1.7554684428758518

Epoch: 6| Step: 11
Training loss: 0.9126923680305481
Validation loss: 1.7419208454829391

Epoch: 6| Step: 12
Training loss: 1.1101458072662354
Validation loss: 1.7150994116260159

Epoch: 6| Step: 13
Training loss: 0.38962459564208984
Validation loss: 1.7084801299597627

Epoch: 398| Step: 0
Training loss: 0.9021353125572205
Validation loss: 1.736853696966684

Epoch: 6| Step: 1
Training loss: 0.8760460615158081
Validation loss: 1.721590438196736

Epoch: 6| Step: 2
Training loss: 0.919187068939209
Validation loss: 1.697696606318156

Epoch: 6| Step: 3
Training loss: 0.8596913814544678
Validation loss: 1.7054858399975685

Epoch: 6| Step: 4
Training loss: 0.823272168636322
Validation loss: 1.6909754827458372

Epoch: 6| Step: 5
Training loss: 1.1785917282104492
Validation loss: 1.6818155345096384

Epoch: 6| Step: 6
Training loss: 0.7568939328193665
Validation loss: 1.7249813284925235

Epoch: 6| Step: 7
Training loss: 0.5620625615119934
Validation loss: 1.7440394252859137

Epoch: 6| Step: 8
Training loss: 0.7295346260070801
Validation loss: 1.7350683366098711

Epoch: 6| Step: 9
Training loss: 0.982054591178894
Validation loss: 1.7442390944368096

Epoch: 6| Step: 10
Training loss: 0.8981310129165649
Validation loss: 1.7358006226119174

Epoch: 6| Step: 11
Training loss: 0.6469994187355042
Validation loss: 1.701144156917449

Epoch: 6| Step: 12
Training loss: 0.6625926494598389
Validation loss: 1.7075600213901971

Epoch: 6| Step: 13
Training loss: 0.7122625112533569
Validation loss: 1.714468930357246

Epoch: 399| Step: 0
Training loss: 0.93614262342453
Validation loss: 1.7147888009266188

Epoch: 6| Step: 1
Training loss: 0.8730891346931458
Validation loss: 1.6869459318858322

Epoch: 6| Step: 2
Training loss: 0.6175852417945862
Validation loss: 1.7099128794926468

Epoch: 6| Step: 3
Training loss: 0.8415510058403015
Validation loss: 1.6900563368233301

Epoch: 6| Step: 4
Training loss: 0.658180296421051
Validation loss: 1.7126726335094822

Epoch: 6| Step: 5
Training loss: 0.5463587641716003
Validation loss: 1.70654684112918

Epoch: 6| Step: 6
Training loss: 1.237804889678955
Validation loss: 1.712483771385685

Epoch: 6| Step: 7
Training loss: 0.4951920509338379
Validation loss: 1.7144747139305196

Epoch: 6| Step: 8
Training loss: 0.8289617300033569
Validation loss: 1.7141087491025206

Epoch: 6| Step: 9
Training loss: 0.7262189388275146
Validation loss: 1.7062570753917898

Epoch: 6| Step: 10
Training loss: 1.0694832801818848
Validation loss: 1.7429276563787972

Epoch: 6| Step: 11
Training loss: 0.9148555397987366
Validation loss: 1.7315219551004388

Epoch: 6| Step: 12
Training loss: 0.8302743434906006
Validation loss: 1.7018978300914969

Epoch: 6| Step: 13
Training loss: 0.9927051067352295
Validation loss: 1.725670861941512

Epoch: 400| Step: 0
Training loss: 0.7716638445854187
Validation loss: 1.6633431347467567

Epoch: 6| Step: 1
Training loss: 1.1523767709732056
Validation loss: 1.6836997373129732

Epoch: 6| Step: 2
Training loss: 0.7261512279510498
Validation loss: 1.7060374649622108

Epoch: 6| Step: 3
Training loss: 0.8045185804367065
Validation loss: 1.7404769569314935

Epoch: 6| Step: 4
Training loss: 1.34525728225708
Validation loss: 1.7441869051225725

Epoch: 6| Step: 5
Training loss: 0.9062247276306152
Validation loss: 1.7266690102956628

Epoch: 6| Step: 6
Training loss: 0.8920844197273254
Validation loss: 1.6616701041498492

Epoch: 6| Step: 7
Training loss: 0.90935879945755
Validation loss: 1.6581576678060717

Epoch: 6| Step: 8
Training loss: 0.6608308553695679
Validation loss: 1.6757208070447367

Epoch: 6| Step: 9
Training loss: 0.2192014902830124
Validation loss: 1.7141198496664725

Epoch: 6| Step: 10
Training loss: 0.907047688961029
Validation loss: 1.715382734934489

Epoch: 6| Step: 11
Training loss: 0.7673895955085754
Validation loss: 1.699311069262925

Epoch: 6| Step: 12
Training loss: 0.8534582853317261
Validation loss: 1.7409622874311221

Epoch: 6| Step: 13
Training loss: 0.42683422565460205
Validation loss: 1.7045425561166578

Testing loss: 2.054721154106988
