Epoch: 1| Step: 0
Training loss: 6.679015865356774
Validation loss: 5.84642455699514

Epoch: 6| Step: 1
Training loss: 5.381548418904151
Validation loss: 5.841117742914729

Epoch: 6| Step: 2
Training loss: 6.663273074761956
Validation loss: 5.836193246206146

Epoch: 6| Step: 3
Training loss: 4.728835487813123
Validation loss: 5.830579792810744

Epoch: 6| Step: 4
Training loss: 5.848766438118063
Validation loss: 5.825500969097893

Epoch: 6| Step: 5
Training loss: 5.89327757025066
Validation loss: 5.819774285721416

Epoch: 6| Step: 6
Training loss: 5.725944954125544
Validation loss: 5.813940604714315

Epoch: 6| Step: 7
Training loss: 4.481411369961621
Validation loss: 5.808395773296801

Epoch: 6| Step: 8
Training loss: 6.514172289154852
Validation loss: 5.802666238633745

Epoch: 6| Step: 9
Training loss: 6.236304574904642
Validation loss: 5.796845809968727

Epoch: 6| Step: 10
Training loss: 5.516900539146767
Validation loss: 5.790992328689836

Epoch: 6| Step: 11
Training loss: 5.794175005059635
Validation loss: 5.784524328152304

Epoch: 6| Step: 12
Training loss: 6.102610245349167
Validation loss: 5.778104430657499

Epoch: 6| Step: 13
Training loss: 5.754552614535472
Validation loss: 5.770835926515411

Epoch: 2| Step: 0
Training loss: 6.77910217867211
Validation loss: 5.763982374817967

Epoch: 6| Step: 1
Training loss: 6.241411946306388
Validation loss: 5.756504214473805

Epoch: 6| Step: 2
Training loss: 4.682748853564701
Validation loss: 5.749008325038505

Epoch: 6| Step: 3
Training loss: 6.084525144004859
Validation loss: 5.739639714614013

Epoch: 6| Step: 4
Training loss: 4.871752317399751
Validation loss: 5.731472707397894

Epoch: 6| Step: 5
Training loss: 5.483599050899453
Validation loss: 5.722459944991259

Epoch: 6| Step: 6
Training loss: 5.381142765620446
Validation loss: 5.712848796272405

Epoch: 6| Step: 7
Training loss: 6.094938661111763
Validation loss: 5.7021964240565115

Epoch: 6| Step: 8
Training loss: 6.276123991831252
Validation loss: 5.691251281898282

Epoch: 6| Step: 9
Training loss: 5.188484190452938
Validation loss: 5.6794966413012995

Epoch: 6| Step: 10
Training loss: 5.704366972002198
Validation loss: 5.667163620185239

Epoch: 6| Step: 11
Training loss: 6.234582118367984
Validation loss: 5.654374499642433

Epoch: 6| Step: 12
Training loss: 5.732601546375079
Validation loss: 5.641385483904875

Epoch: 6| Step: 13
Training loss: 4.674284552841495
Validation loss: 5.62592181055207

Epoch: 3| Step: 0
Training loss: 5.196725386474798
Validation loss: 5.611289144820286

Epoch: 6| Step: 1
Training loss: 5.533893880065833
Validation loss: 5.594350042359724

Epoch: 6| Step: 2
Training loss: 6.752973113675445
Validation loss: 5.579748106721076

Epoch: 6| Step: 3
Training loss: 5.5386070849783575
Validation loss: 5.560043314176863

Epoch: 6| Step: 4
Training loss: 5.705579590037453
Validation loss: 5.541783042547451

Epoch: 6| Step: 5
Training loss: 6.780048597943714
Validation loss: 5.522768037873441

Epoch: 6| Step: 6
Training loss: 4.708257061275829
Validation loss: 5.501605495923699

Epoch: 6| Step: 7
Training loss: 5.658052441793203
Validation loss: 5.479447022821128

Epoch: 6| Step: 8
Training loss: 6.486553074520721
Validation loss: 5.456719589309514

Epoch: 6| Step: 9
Training loss: 5.285727143732287
Validation loss: 5.4332063436750975

Epoch: 6| Step: 10
Training loss: 3.5666054610470312
Validation loss: 5.408068161807369

Epoch: 6| Step: 11
Training loss: 5.594212177299281
Validation loss: 5.385055724435792

Epoch: 6| Step: 12
Training loss: 4.347127136772252
Validation loss: 5.3583856489407395

Epoch: 6| Step: 13
Training loss: 5.1669418917947585
Validation loss: 5.330983930120599

Epoch: 4| Step: 0
Training loss: 4.685594909091012
Validation loss: 5.302754107717894

Epoch: 6| Step: 1
Training loss: 5.030445863897117
Validation loss: 5.275104070555481

Epoch: 6| Step: 2
Training loss: 4.905550378374532
Validation loss: 5.245908112347955

Epoch: 6| Step: 3
Training loss: 4.7320170054190624
Validation loss: 5.2146011925997104

Epoch: 6| Step: 4
Training loss: 5.166598206753579
Validation loss: 5.184634826257658

Epoch: 6| Step: 5
Training loss: 5.568924526301166
Validation loss: 5.154443920111931

Epoch: 6| Step: 6
Training loss: 6.118125638970526
Validation loss: 5.121821158225847

Epoch: 6| Step: 7
Training loss: 4.791685397346487
Validation loss: 5.087794509687463

Epoch: 6| Step: 8
Training loss: 5.6897803126398045
Validation loss: 5.057578764302193

Epoch: 6| Step: 9
Training loss: 5.083136424435589
Validation loss: 5.023611592981591

Epoch: 6| Step: 10
Training loss: 5.537313295407272
Validation loss: 4.990294937412629

Epoch: 6| Step: 11
Training loss: 5.1290892127495455
Validation loss: 4.957758639169278

Epoch: 6| Step: 12
Training loss: 5.288366455076992
Validation loss: 4.924079114238305

Epoch: 6| Step: 13
Training loss: 3.2617995931691657
Validation loss: 4.889318869501845

Epoch: 5| Step: 0
Training loss: 4.757567952202493
Validation loss: 4.856580678064421

Epoch: 6| Step: 1
Training loss: 4.905589648471867
Validation loss: 4.824560961991447

Epoch: 6| Step: 2
Training loss: 4.853930204250404
Validation loss: 4.791902278263319

Epoch: 6| Step: 3
Training loss: 4.87837337274588
Validation loss: 4.758755574655129

Epoch: 6| Step: 4
Training loss: 5.410944493570415
Validation loss: 4.727284793417422

Epoch: 6| Step: 5
Training loss: 4.272434932956576
Validation loss: 4.69183856312101

Epoch: 6| Step: 6
Training loss: 4.893714781886565
Validation loss: 4.660231870948773

Epoch: 6| Step: 7
Training loss: 5.266582096402696
Validation loss: 4.62862204080764

Epoch: 6| Step: 8
Training loss: 3.891437246570236
Validation loss: 4.598142162548892

Epoch: 6| Step: 9
Training loss: 5.445572571858351
Validation loss: 4.567502028484258

Epoch: 6| Step: 10
Training loss: 4.338686839495441
Validation loss: 4.537858581069681

Epoch: 6| Step: 11
Training loss: 3.9030703611802506
Validation loss: 4.510825344144765

Epoch: 6| Step: 12
Training loss: 4.61692889372015
Validation loss: 4.484720434109014

Epoch: 6| Step: 13
Training loss: 4.465616688276795
Validation loss: 4.4576020183900615

Epoch: 6| Step: 0
Training loss: 4.215162546229705
Validation loss: 4.432671496161916

Epoch: 6| Step: 1
Training loss: 4.376911726572405
Validation loss: 4.4089638230520345

Epoch: 6| Step: 2
Training loss: 4.959310526149315
Validation loss: 4.383337701010582

Epoch: 6| Step: 3
Training loss: 4.31652931279605
Validation loss: 4.3588282603627375

Epoch: 6| Step: 4
Training loss: 5.54232007909421
Validation loss: 4.334255827090162

Epoch: 6| Step: 5
Training loss: 4.489703797083598
Validation loss: 4.3134308616310015

Epoch: 6| Step: 6
Training loss: 3.128832183989945
Validation loss: 4.287960232497472

Epoch: 6| Step: 7
Training loss: 3.7991356418751634
Validation loss: 4.26556081031277

Epoch: 6| Step: 8
Training loss: 4.206656294949457
Validation loss: 4.244939122852665

Epoch: 6| Step: 9
Training loss: 4.04692684420218
Validation loss: 4.223969465196333

Epoch: 6| Step: 10
Training loss: 4.424209679323652
Validation loss: 4.205998569359493

Epoch: 6| Step: 11
Training loss: 4.30648029746918
Validation loss: 4.187415239519791

Epoch: 6| Step: 12
Training loss: 5.187680896224698
Validation loss: 4.171821916208755

Epoch: 6| Step: 13
Training loss: 3.92971613666877
Validation loss: 4.154909339433877

Epoch: 7| Step: 0
Training loss: 3.893865744644632
Validation loss: 4.141373008732369

Epoch: 6| Step: 1
Training loss: 3.8149030022645416
Validation loss: 4.1256413090218835

Epoch: 6| Step: 2
Training loss: 3.7473829674339743
Validation loss: 4.109122452075169

Epoch: 6| Step: 3
Training loss: 4.999820706013883
Validation loss: 4.0958085885464275

Epoch: 6| Step: 4
Training loss: 4.464167452744417
Validation loss: 4.078888096880072

Epoch: 6| Step: 5
Training loss: 4.551644566716381
Validation loss: 4.065612027593537

Epoch: 6| Step: 6
Training loss: 3.97256190545237
Validation loss: 4.052932068734539

Epoch: 6| Step: 7
Training loss: 3.6564522711728027
Validation loss: 4.039501398405945

Epoch: 6| Step: 8
Training loss: 2.998783500710056
Validation loss: 4.027097187996964

Epoch: 6| Step: 9
Training loss: 4.662398202720615
Validation loss: 4.014694660880609

Epoch: 6| Step: 10
Training loss: 4.54820205881109
Validation loss: 4.0044412286225075

Epoch: 6| Step: 11
Training loss: 3.9911379395621376
Validation loss: 3.9940705022315934

Epoch: 6| Step: 12
Training loss: 4.534861421160613
Validation loss: 3.982467142475565

Epoch: 6| Step: 13
Training loss: 4.623341030856112
Validation loss: 3.9730577487712004

Epoch: 8| Step: 0
Training loss: 3.0964815045677057
Validation loss: 3.963436950919051

Epoch: 6| Step: 1
Training loss: 4.827228944459395
Validation loss: 3.951702670897818

Epoch: 6| Step: 2
Training loss: 5.155880076692473
Validation loss: 3.943061680892736

Epoch: 6| Step: 3
Training loss: 3.853809869420591
Validation loss: 3.934009192834163

Epoch: 6| Step: 4
Training loss: 4.050988893695674
Validation loss: 3.9259833657552443

Epoch: 6| Step: 5
Training loss: 3.921056289630721
Validation loss: 3.917226099936788

Epoch: 6| Step: 6
Training loss: 3.025741606043141
Validation loss: 3.9092762187790115

Epoch: 6| Step: 7
Training loss: 2.7780897209064372
Validation loss: 3.899855590368001

Epoch: 6| Step: 8
Training loss: 2.8551372539176634
Validation loss: 3.8955459782678172

Epoch: 6| Step: 9
Training loss: 4.7838131884330695
Validation loss: 3.886603458562271

Epoch: 6| Step: 10
Training loss: 3.9229455223919785
Validation loss: 3.8796772061136817

Epoch: 6| Step: 11
Training loss: 4.605071357232176
Validation loss: 3.869618882235859

Epoch: 6| Step: 12
Training loss: 4.583410135261471
Validation loss: 3.862734859218509

Epoch: 6| Step: 13
Training loss: 4.6610273392830415
Validation loss: 3.8546661084393423

Epoch: 9| Step: 0
Training loss: 3.767753537664195
Validation loss: 3.848811391722293

Epoch: 6| Step: 1
Training loss: 4.0293167564948185
Validation loss: 3.8419819789178837

Epoch: 6| Step: 2
Training loss: 4.289317750544568
Validation loss: 3.835596343979011

Epoch: 6| Step: 3
Training loss: 3.7714092735110567
Validation loss: 3.830766143701786

Epoch: 6| Step: 4
Training loss: 4.416585069778331
Validation loss: 3.8230205686177365

Epoch: 6| Step: 5
Training loss: 3.1965040303035863
Validation loss: 3.8171954881640593

Epoch: 6| Step: 6
Training loss: 3.4324909127289467
Validation loss: 3.8114714920459862

Epoch: 6| Step: 7
Training loss: 3.23582831271759
Validation loss: 3.8043608587474003

Epoch: 6| Step: 8
Training loss: 4.649072632555168
Validation loss: 3.7982681212150036

Epoch: 6| Step: 9
Training loss: 3.2297945622165405
Validation loss: 3.792640131507706

Epoch: 6| Step: 10
Training loss: 4.114011983999584
Validation loss: 3.7859580793977603

Epoch: 6| Step: 11
Training loss: 4.391791246494214
Validation loss: 3.782829535794808

Epoch: 6| Step: 12
Training loss: 4.295338858936037
Validation loss: 3.7733028177812886

Epoch: 6| Step: 13
Training loss: 4.781490145368273
Validation loss: 3.7693425637071547

Epoch: 10| Step: 0
Training loss: 3.7122535700842847
Validation loss: 3.7633176881583448

Epoch: 6| Step: 1
Training loss: 3.704278951229638
Validation loss: 3.758117402804995

Epoch: 6| Step: 2
Training loss: 4.427472457240038
Validation loss: 3.751141440751311

Epoch: 6| Step: 3
Training loss: 4.6964175023700125
Validation loss: 3.7465462671424232

Epoch: 6| Step: 4
Training loss: 4.11593487267457
Validation loss: 3.7394874695975395

Epoch: 6| Step: 5
Training loss: 3.910768992519758
Validation loss: 3.7334806717161255

Epoch: 6| Step: 6
Training loss: 4.116642664377354
Validation loss: 3.7307541704377662

Epoch: 6| Step: 7
Training loss: 4.18274133655202
Validation loss: 3.7214455834834395

Epoch: 6| Step: 8
Training loss: 4.02402552779729
Validation loss: 3.7179311593788613

Epoch: 6| Step: 9
Training loss: 3.064206640421804
Validation loss: 3.7104904732829507

Epoch: 6| Step: 10
Training loss: 3.112508450538776
Validation loss: 3.705845162041403

Epoch: 6| Step: 11
Training loss: 3.874362154731804
Validation loss: 3.7021782926931555

Epoch: 6| Step: 12
Training loss: 3.967365293661784
Validation loss: 3.6983553695367877

Epoch: 6| Step: 13
Training loss: 3.118025205861429
Validation loss: 3.6916086629608285

Epoch: 11| Step: 0
Training loss: 4.439809278911142
Validation loss: 3.6878207765730786

Epoch: 6| Step: 1
Training loss: 3.3439857185916657
Validation loss: 3.681358169762324

Epoch: 6| Step: 2
Training loss: 4.145473649925489
Validation loss: 3.6756687594109896

Epoch: 6| Step: 3
Training loss: 1.800033447166799
Validation loss: 3.673640092005941

Epoch: 6| Step: 4
Training loss: 4.2724014504787275
Validation loss: 3.6718008773538013

Epoch: 6| Step: 5
Training loss: 3.7833107621336075
Validation loss: 3.667274267207775

Epoch: 6| Step: 6
Training loss: 2.9949393504120385
Validation loss: 3.6602983173011934

Epoch: 6| Step: 7
Training loss: 4.150062027433201
Validation loss: 3.655074386413195

Epoch: 6| Step: 8
Training loss: 4.69543192833762
Validation loss: 3.6483785583185684

Epoch: 6| Step: 9
Training loss: 4.580891369031062
Validation loss: 3.643735498056741

Epoch: 6| Step: 10
Training loss: 4.311988247347582
Validation loss: 3.6373026465134104

Epoch: 6| Step: 11
Training loss: 3.029311041734282
Validation loss: 3.634548701500821

Epoch: 6| Step: 12
Training loss: 3.2092536167862256
Validation loss: 3.631070694169316

Epoch: 6| Step: 13
Training loss: 4.1052415605252355
Validation loss: 3.627752809755256

Epoch: 12| Step: 0
Training loss: 3.1931467341282374
Validation loss: 3.6201591757813674

Epoch: 6| Step: 1
Training loss: 3.14514472616297
Validation loss: 3.616568152549626

Epoch: 6| Step: 2
Training loss: 3.3871962970697185
Validation loss: 3.6081868605170917

Epoch: 6| Step: 3
Training loss: 4.468595275334432
Validation loss: 3.5997955149681164

Epoch: 6| Step: 4
Training loss: 3.3925514198178925
Validation loss: 3.5938104040376007

Epoch: 6| Step: 5
Training loss: 3.5781721753337985
Validation loss: 3.587639238850381

Epoch: 6| Step: 6
Training loss: 3.5433169091873657
Validation loss: 3.5850941599770665

Epoch: 6| Step: 7
Training loss: 4.263268347258054
Validation loss: 3.580200778252988

Epoch: 6| Step: 8
Training loss: 5.028669370743994
Validation loss: 3.5748765537029494

Epoch: 6| Step: 9
Training loss: 4.388388284604064
Validation loss: 3.5662611382263423

Epoch: 6| Step: 10
Training loss: 3.070264820767276
Validation loss: 3.5570497427701055

Epoch: 6| Step: 11
Training loss: 3.5043154406329484
Validation loss: 3.5493859373095242

Epoch: 6| Step: 12
Training loss: 3.7033534241093307
Validation loss: 3.5434280566128447

Epoch: 6| Step: 13
Training loss: 3.602703716334163
Validation loss: 3.5399735311822527

Epoch: 13| Step: 0
Training loss: 3.109943893760604
Validation loss: 3.535877511676002

Epoch: 6| Step: 1
Training loss: 4.333842663298312
Validation loss: 3.530121459149562

Epoch: 6| Step: 2
Training loss: 4.3182500569185605
Validation loss: 3.524009210553443

Epoch: 6| Step: 3
Training loss: 3.471407173288139
Validation loss: 3.5139391358320484

Epoch: 6| Step: 4
Training loss: 3.7647407728219284
Validation loss: 3.508078523503468

Epoch: 6| Step: 5
Training loss: 3.384461034243055
Validation loss: 3.5074279970536923

Epoch: 6| Step: 6
Training loss: 3.6558351199827808
Validation loss: 3.50439692305267

Epoch: 6| Step: 7
Training loss: 3.95790203488682
Validation loss: 3.4974877955909203

Epoch: 6| Step: 8
Training loss: 3.7520509833184437
Validation loss: 3.4908244928495247

Epoch: 6| Step: 9
Training loss: 3.3503484060823694
Validation loss: 3.4841264301024806

Epoch: 6| Step: 10
Training loss: 4.214646894296545
Validation loss: 3.4757996811206127

Epoch: 6| Step: 11
Training loss: 3.3811349563629736
Validation loss: 3.4706130186685527

Epoch: 6| Step: 12
Training loss: 3.173026341032906
Validation loss: 3.466884005819544

Epoch: 6| Step: 13
Training loss: 3.879588947742065
Validation loss: 3.4621568387074952

Epoch: 14| Step: 0
Training loss: 3.5197442230582543
Validation loss: 3.457792937193831

Epoch: 6| Step: 1
Training loss: 4.1524751199233005
Validation loss: 3.4487989279772298

Epoch: 6| Step: 2
Training loss: 4.408219134192241
Validation loss: 3.439866612555753

Epoch: 6| Step: 3
Training loss: 3.4961474878027854
Validation loss: 3.433847479987328

Epoch: 6| Step: 4
Training loss: 2.9987663275594993
Validation loss: 3.4336461932289324

Epoch: 6| Step: 5
Training loss: 3.2593250011145902
Validation loss: 3.427063171245623

Epoch: 6| Step: 6
Training loss: 2.8829294403259245
Validation loss: 3.426226992190336

Epoch: 6| Step: 7
Training loss: 3.5855295119554538
Validation loss: 3.4186819457413296

Epoch: 6| Step: 8
Training loss: 3.768546716069245
Validation loss: 3.4148200052097275

Epoch: 6| Step: 9
Training loss: 3.179304470077087
Validation loss: 3.404727512373305

Epoch: 6| Step: 10
Training loss: 4.312656123334524
Validation loss: 3.4030343281647832

Epoch: 6| Step: 11
Training loss: 2.9455995293351127
Validation loss: 3.3964548156909147

Epoch: 6| Step: 12
Training loss: 4.234333108504726
Validation loss: 3.3918739915401317

Epoch: 6| Step: 13
Training loss: 3.894663113090185
Validation loss: 3.389333095606715

Epoch: 15| Step: 0
Training loss: 3.674427979254927
Validation loss: 3.383302510018736

Epoch: 6| Step: 1
Training loss: 4.329065984902026
Validation loss: 3.374839190955547

Epoch: 6| Step: 2
Training loss: 3.552632637098129
Validation loss: 3.370174134375466

Epoch: 6| Step: 3
Training loss: 3.5055156571149175
Validation loss: 3.3666608080776936

Epoch: 6| Step: 4
Training loss: 3.8703017516866676
Validation loss: 3.3668884581573795

Epoch: 6| Step: 5
Training loss: 3.542512067237174
Validation loss: 3.3587603949995395

Epoch: 6| Step: 6
Training loss: 3.951417576857604
Validation loss: 3.356947252614563

Epoch: 6| Step: 7
Training loss: 3.117152316628669
Validation loss: 3.3502406003135845

Epoch: 6| Step: 8
Training loss: 3.182680862693412
Validation loss: 3.343947587123513

Epoch: 6| Step: 9
Training loss: 4.1902939315067
Validation loss: 3.3372087090432885

Epoch: 6| Step: 10
Training loss: 3.197636064940567
Validation loss: 3.330563289992072

Epoch: 6| Step: 11
Training loss: 2.723643579526719
Validation loss: 3.326683211641695

Epoch: 6| Step: 12
Training loss: 3.825979324332813
Validation loss: 3.3238785944205285

Epoch: 6| Step: 13
Training loss: 2.8649639269836333
Validation loss: 3.3192111303876555

Epoch: 16| Step: 0
Training loss: 3.9522173295592387
Validation loss: 3.31192585107332

Epoch: 6| Step: 1
Training loss: 3.2154390657607115
Validation loss: 3.30828650739412

Epoch: 6| Step: 2
Training loss: 3.1870022553411093
Validation loss: 3.3020962314128015

Epoch: 6| Step: 3
Training loss: 3.266627399701632
Validation loss: 3.303092586218476

Epoch: 6| Step: 4
Training loss: 3.794451407082833
Validation loss: 3.300139901087789

Epoch: 6| Step: 5
Training loss: 2.91884517146932
Validation loss: 3.2956355804182476

Epoch: 6| Step: 6
Training loss: 3.727628863209627
Validation loss: 3.292004706669592

Epoch: 6| Step: 7
Training loss: 3.8928868103896703
Validation loss: 3.2897340668005755

Epoch: 6| Step: 8
Training loss: 3.5159248732785198
Validation loss: 3.2845943816605145

Epoch: 6| Step: 9
Training loss: 3.138293715308126
Validation loss: 3.2814376535192498

Epoch: 6| Step: 10
Training loss: 3.87692803439614
Validation loss: 3.276894432176533

Epoch: 6| Step: 11
Training loss: 3.2764435942562438
Validation loss: 3.2711813005953916

Epoch: 6| Step: 12
Training loss: 3.5333634525190947
Validation loss: 3.2679583803502523

Epoch: 6| Step: 13
Training loss: 4.251905126480346
Validation loss: 3.263385375059155

Epoch: 17| Step: 0
Training loss: 3.584950695683068
Validation loss: 3.264528641888948

Epoch: 6| Step: 1
Training loss: 4.44093039722182
Validation loss: 3.259064579424898

Epoch: 6| Step: 2
Training loss: 3.9244042254175473
Validation loss: 3.2582497452709727

Epoch: 6| Step: 3
Training loss: 3.2713677684442657
Validation loss: 3.2519676445905352

Epoch: 6| Step: 4
Training loss: 3.010615165176467
Validation loss: 3.2516325722453696

Epoch: 6| Step: 5
Training loss: 3.4822163416895267
Validation loss: 3.2503786394974554

Epoch: 6| Step: 6
Training loss: 4.118528896758829
Validation loss: 3.243926021085166

Epoch: 6| Step: 7
Training loss: 3.4976148652744166
Validation loss: 3.2421073111956047

Epoch: 6| Step: 8
Training loss: 3.4129765439818813
Validation loss: 3.2365564138843

Epoch: 6| Step: 9
Training loss: 2.8764764063195933
Validation loss: 3.232826812336098

Epoch: 6| Step: 10
Training loss: 3.3096223243460225
Validation loss: 3.2328236419094463

Epoch: 6| Step: 11
Training loss: 2.7910808024394154
Validation loss: 3.237949734319319

Epoch: 6| Step: 12
Training loss: 2.844964239770639
Validation loss: 3.232450624030831

Epoch: 6| Step: 13
Training loss: 4.229553179938598
Validation loss: 3.2318724797844216

Epoch: 18| Step: 0
Training loss: 4.377276455036665
Validation loss: 3.2197190970454037

Epoch: 6| Step: 1
Training loss: 3.4133858784962445
Validation loss: 3.21634456038319

Epoch: 6| Step: 2
Training loss: 3.1560803358347322
Validation loss: 3.2179860029607097

Epoch: 6| Step: 3
Training loss: 2.729701642511303
Validation loss: 3.2165200537066116

Epoch: 6| Step: 4
Training loss: 3.7437422355864287
Validation loss: 3.219858262502954

Epoch: 6| Step: 5
Training loss: 3.1781121927939155
Validation loss: 3.208181521197733

Epoch: 6| Step: 6
Training loss: 4.218046906834009
Validation loss: 3.210534411608193

Epoch: 6| Step: 7
Training loss: 3.5898591581891854
Validation loss: 3.2109942711515864

Epoch: 6| Step: 8
Training loss: 3.211997049940757
Validation loss: 3.216178708877651

Epoch: 6| Step: 9
Training loss: 3.173890023434866
Validation loss: 3.2159494222558425

Epoch: 6| Step: 10
Training loss: 3.5487805595842365
Validation loss: 3.2076026191991036

Epoch: 6| Step: 11
Training loss: 3.231324162176313
Validation loss: 3.197592997320528

Epoch: 6| Step: 12
Training loss: 2.9898707731255265
Validation loss: 3.1938674804009652

Epoch: 6| Step: 13
Training loss: 3.7294716026615076
Validation loss: 3.18844997301513

Epoch: 19| Step: 0
Training loss: 3.351743608752172
Validation loss: 3.187881908503871

Epoch: 6| Step: 1
Training loss: 4.044760133022898
Validation loss: 3.185050694089294

Epoch: 6| Step: 2
Training loss: 3.437021950512633
Validation loss: 3.1831658172427515

Epoch: 6| Step: 3
Training loss: 3.390267911468892
Validation loss: 3.1775838510456684

Epoch: 6| Step: 4
Training loss: 3.536435800891644
Validation loss: 3.1717658338073154

Epoch: 6| Step: 5
Training loss: 2.970637795396468
Validation loss: 3.169299132226941

Epoch: 6| Step: 6
Training loss: 3.0689486126617047
Validation loss: 3.1703268464007435

Epoch: 6| Step: 7
Training loss: 3.326601064591956
Validation loss: 3.1687402725596296

Epoch: 6| Step: 8
Training loss: 3.8595709500008963
Validation loss: 3.1651439978220046

Epoch: 6| Step: 9
Training loss: 3.8776613756019813
Validation loss: 3.16015548905813

Epoch: 6| Step: 10
Training loss: 3.2727721637479172
Validation loss: 3.161068343166089

Epoch: 6| Step: 11
Training loss: 2.964117028956944
Validation loss: 3.1578624646963456

Epoch: 6| Step: 12
Training loss: 3.2236776317033518
Validation loss: 3.163347048675321

Epoch: 6| Step: 13
Training loss: 3.676362497423694
Validation loss: 3.164830686473435

Epoch: 20| Step: 0
Training loss: 3.078933532175815
Validation loss: 3.1625391825947626

Epoch: 6| Step: 1
Training loss: 3.1631316146072908
Validation loss: 3.158118929365874

Epoch: 6| Step: 2
Training loss: 3.347874459596237
Validation loss: 3.150518080594582

Epoch: 6| Step: 3
Training loss: 3.3875164073814195
Validation loss: 3.1457315501960084

Epoch: 6| Step: 4
Training loss: 3.5997560153510615
Validation loss: 3.1418132286150384

Epoch: 6| Step: 5
Training loss: 3.718135366215365
Validation loss: 3.1451795898780195

Epoch: 6| Step: 6
Training loss: 3.7210532356601926
Validation loss: 3.139877433618531

Epoch: 6| Step: 7
Training loss: 2.9520203477111706
Validation loss: 3.140465456585967

Epoch: 6| Step: 8
Training loss: 3.06658771731159
Validation loss: 3.1351960011567117

Epoch: 6| Step: 9
Training loss: 2.7460622337996337
Validation loss: 3.1300806104070498

Epoch: 6| Step: 10
Training loss: 3.9541441316166805
Validation loss: 3.1300578936136048

Epoch: 6| Step: 11
Training loss: 3.4354605433474945
Validation loss: 3.1356521718049

Epoch: 6| Step: 12
Training loss: 3.299739515254238
Validation loss: 3.132744431469016

Epoch: 6| Step: 13
Training loss: 4.410139166610513
Validation loss: 3.1261070095515615

Epoch: 21| Step: 0
Training loss: 2.912056649317284
Validation loss: 3.1233229273720364

Epoch: 6| Step: 1
Training loss: 3.379743562710434
Validation loss: 3.1210242102003405

Epoch: 6| Step: 2
Training loss: 2.7925768170425056
Validation loss: 3.1167060915581244

Epoch: 6| Step: 3
Training loss: 3.9618325811577457
Validation loss: 3.1166499669516687

Epoch: 6| Step: 4
Training loss: 4.071883881237916
Validation loss: 3.114727872256976

Epoch: 6| Step: 5
Training loss: 3.9269468788029753
Validation loss: 3.1138127023470648

Epoch: 6| Step: 6
Training loss: 3.4016362011853714
Validation loss: 3.105555841616868

Epoch: 6| Step: 7
Training loss: 3.2738214599920226
Validation loss: 3.1083738112976325

Epoch: 6| Step: 8
Training loss: 3.0538077490050517
Validation loss: 3.104778027803808

Epoch: 6| Step: 9
Training loss: 3.0020220617694644
Validation loss: 3.104895850823591

Epoch: 6| Step: 10
Training loss: 4.0005273471350975
Validation loss: 3.1059497425930847

Epoch: 6| Step: 11
Training loss: 3.5331101371038183
Validation loss: 3.1009918652555655

Epoch: 6| Step: 12
Training loss: 2.7478446316670624
Validation loss: 3.1003118876142093

Epoch: 6| Step: 13
Training loss: 2.376537528022823
Validation loss: 3.1006768786008245

Epoch: 22| Step: 0
Training loss: 3.4530109369417943
Validation loss: 3.096019780254821

Epoch: 6| Step: 1
Training loss: 3.203133634229979
Validation loss: 3.0933040870554094

Epoch: 6| Step: 2
Training loss: 3.207243119000716
Validation loss: 3.0939233059536666

Epoch: 6| Step: 3
Training loss: 3.989622482758443
Validation loss: 3.092063801439728

Epoch: 6| Step: 4
Training loss: 3.0160743497188904
Validation loss: 3.0907700017616686

Epoch: 6| Step: 5
Training loss: 2.9618136033285105
Validation loss: 3.0888660421530107

Epoch: 6| Step: 6
Training loss: 3.282896373608755
Validation loss: 3.088356812009907

Epoch: 6| Step: 7
Training loss: 3.2814389129025896
Validation loss: 3.0921197687296686

Epoch: 6| Step: 8
Training loss: 2.729721643838092
Validation loss: 3.0859701839994007

Epoch: 6| Step: 9
Training loss: 3.4832868715926297
Validation loss: 3.0836143321264524

Epoch: 6| Step: 10
Training loss: 3.6433600765083223
Validation loss: 3.0813776169980063

Epoch: 6| Step: 11
Training loss: 3.1707140672454255
Validation loss: 3.0806830711010087

Epoch: 6| Step: 12
Training loss: 3.372982693819762
Validation loss: 3.076602724070547

Epoch: 6| Step: 13
Training loss: 4.524516396998577
Validation loss: 3.0775175534738524

Epoch: 23| Step: 0
Training loss: 2.5944190943276144
Validation loss: 3.0760379260111104

Epoch: 6| Step: 1
Training loss: 2.800116509329623
Validation loss: 3.073377785656048

Epoch: 6| Step: 2
Training loss: 2.891697700033478
Validation loss: 3.0710756059684745

Epoch: 6| Step: 3
Training loss: 3.3490649612245433
Validation loss: 3.0680491734112425

Epoch: 6| Step: 4
Training loss: 3.3405404061436115
Validation loss: 3.0705406824132457

Epoch: 6| Step: 5
Training loss: 4.379159094855057
Validation loss: 3.068610944680655

Epoch: 6| Step: 6
Training loss: 3.261697113513567
Validation loss: 3.061213281844784

Epoch: 6| Step: 7
Training loss: 3.7390459926701536
Validation loss: 3.061903892397703

Epoch: 6| Step: 8
Training loss: 2.8534220445811997
Validation loss: 3.060915723222548

Epoch: 6| Step: 9
Training loss: 4.0344745839399
Validation loss: 3.064666264833445

Epoch: 6| Step: 10
Training loss: 3.0028491795610432
Validation loss: 3.051701914810654

Epoch: 6| Step: 11
Training loss: 3.2287588702887464
Validation loss: 3.053607623176127

Epoch: 6| Step: 12
Training loss: 2.6437862817605904
Validation loss: 3.0527683928225486

Epoch: 6| Step: 13
Training loss: 4.596325003411672
Validation loss: 3.0614384411675255

Epoch: 24| Step: 0
Training loss: 2.228498293301907
Validation loss: 3.0524288719519688

Epoch: 6| Step: 1
Training loss: 3.186748640477157
Validation loss: 3.0482477293630654

Epoch: 6| Step: 2
Training loss: 2.933981878660235
Validation loss: 3.0508159013486957

Epoch: 6| Step: 3
Training loss: 3.171602585092223
Validation loss: 3.0465788229003667

Epoch: 6| Step: 4
Training loss: 3.7618335932138502
Validation loss: 3.0441295512713333

Epoch: 6| Step: 5
Training loss: 2.302716670077452
Validation loss: 3.0391340855989672

Epoch: 6| Step: 6
Training loss: 3.888758200008682
Validation loss: 3.0412129142233892

Epoch: 6| Step: 7
Training loss: 4.506838370970361
Validation loss: 3.040207471681581

Epoch: 6| Step: 8
Training loss: 3.6268697717771263
Validation loss: 3.0346140874902274

Epoch: 6| Step: 9
Training loss: 3.2674120526200006
Validation loss: 3.0329552672337146

Epoch: 6| Step: 10
Training loss: 2.6690033767810326
Validation loss: 3.039792492470897

Epoch: 6| Step: 11
Training loss: 3.783019983588248
Validation loss: 3.046596005910291

Epoch: 6| Step: 12
Training loss: 2.6462375201983788
Validation loss: 3.0405182136152695

Epoch: 6| Step: 13
Training loss: 4.017176465702222
Validation loss: 3.0332576901392043

Epoch: 25| Step: 0
Training loss: 3.746874205881119
Validation loss: 3.0305176994118628

Epoch: 6| Step: 1
Training loss: 3.0901690479443107
Validation loss: 3.0243286284765767

Epoch: 6| Step: 2
Training loss: 3.1178574379952186
Validation loss: 3.020363030123089

Epoch: 6| Step: 3
Training loss: 3.1738278245192166
Validation loss: 3.022233907497339

Epoch: 6| Step: 4
Training loss: 2.6679121824106993
Validation loss: 3.0210986543149385

Epoch: 6| Step: 5
Training loss: 3.1984042480410007
Validation loss: 3.0244039915690784

Epoch: 6| Step: 6
Training loss: 3.6337029791100246
Validation loss: 3.014628917480043

Epoch: 6| Step: 7
Training loss: 3.4571109740983794
Validation loss: 3.0174931006422328

Epoch: 6| Step: 8
Training loss: 3.1833295279541707
Validation loss: 3.007801576553793

Epoch: 6| Step: 9
Training loss: 3.488267580285366
Validation loss: 3.009521065587521

Epoch: 6| Step: 10
Training loss: 3.1095262040222424
Validation loss: 3.008606528119606

Epoch: 6| Step: 11
Training loss: 3.598051200667794
Validation loss: 3.0105844910688995

Epoch: 6| Step: 12
Training loss: 3.401848705553866
Validation loss: 3.0158801966784283

Epoch: 6| Step: 13
Training loss: 3.2560258901724266
Validation loss: 3.0135704581023903

Epoch: 26| Step: 0
Training loss: 2.74438788226585
Validation loss: 3.0087092549707526

Epoch: 6| Step: 1
Training loss: 3.3700921437149023
Validation loss: 3.0015150008235723

Epoch: 6| Step: 2
Training loss: 2.86066378539856
Validation loss: 2.9999311987873303

Epoch: 6| Step: 3
Training loss: 3.637151542831288
Validation loss: 3.001685033331172

Epoch: 6| Step: 4
Training loss: 4.160233961642132
Validation loss: 2.9983247930168697

Epoch: 6| Step: 5
Training loss: 3.3787010527468997
Validation loss: 2.9921476355643404

Epoch: 6| Step: 6
Training loss: 3.780455198379953
Validation loss: 2.99053480189934

Epoch: 6| Step: 7
Training loss: 3.2049216093334727
Validation loss: 2.9948652480806905

Epoch: 6| Step: 8
Training loss: 3.257511554969793
Validation loss: 2.992495052099749

Epoch: 6| Step: 9
Training loss: 2.4972902871675426
Validation loss: 2.9907444542799264

Epoch: 6| Step: 10
Training loss: 2.931467883505867
Validation loss: 2.992557493013539

Epoch: 6| Step: 11
Training loss: 2.70052013685364
Validation loss: 2.989012510029404

Epoch: 6| Step: 12
Training loss: 3.6024146406238353
Validation loss: 2.9935982483581363

Epoch: 6| Step: 13
Training loss: 3.6350367802119488
Validation loss: 2.9866628537926454

Epoch: 27| Step: 0
Training loss: 3.5036337926226846
Validation loss: 2.990902600210524

Epoch: 6| Step: 1
Training loss: 2.695231472400717
Validation loss: 2.985640648458009

Epoch: 6| Step: 2
Training loss: 3.0001268360028535
Validation loss: 2.9842288778188717

Epoch: 6| Step: 3
Training loss: 2.9645613182753454
Validation loss: 2.9873182346749765

Epoch: 6| Step: 4
Training loss: 3.698266169548595
Validation loss: 2.984656887295975

Epoch: 6| Step: 5
Training loss: 3.5307468292129176
Validation loss: 2.9748208598422643

Epoch: 6| Step: 6
Training loss: 3.9271666554213263
Validation loss: 2.9706528804817647

Epoch: 6| Step: 7
Training loss: 3.1758485155852934
Validation loss: 2.974934192935108

Epoch: 6| Step: 8
Training loss: 3.3478012498680627
Validation loss: 2.9840896505247456

Epoch: 6| Step: 9
Training loss: 3.562178747850903
Validation loss: 2.9737771716834285

Epoch: 6| Step: 10
Training loss: 2.9170078804608
Validation loss: 2.973628348417845

Epoch: 6| Step: 11
Training loss: 3.0151872860764697
Validation loss: 2.968359627394745

Epoch: 6| Step: 12
Training loss: 3.3653006876446745
Validation loss: 2.966740216454988

Epoch: 6| Step: 13
Training loss: 2.602179193576214
Validation loss: 2.9670807442192406

Epoch: 28| Step: 0
Training loss: 3.431794581599104
Validation loss: 2.9715623687291735

Epoch: 6| Step: 1
Training loss: 3.381984124722209
Validation loss: 2.975959905239457

Epoch: 6| Step: 2
Training loss: 2.748170417443312
Validation loss: 2.9724682185504077

Epoch: 6| Step: 3
Training loss: 3.2350429269103427
Validation loss: 2.975817542915963

Epoch: 6| Step: 4
Training loss: 3.7354954271723826
Validation loss: 2.9653677204385698

Epoch: 6| Step: 5
Training loss: 3.5586843301109123
Validation loss: 2.9577715102067548

Epoch: 6| Step: 6
Training loss: 3.7330129525680094
Validation loss: 2.955200769679773

Epoch: 6| Step: 7
Training loss: 3.8383854593129567
Validation loss: 2.9513371048079438

Epoch: 6| Step: 8
Training loss: 2.669487494382773
Validation loss: 2.950411852672387

Epoch: 6| Step: 9
Training loss: 3.034538765916591
Validation loss: 2.947666244685796

Epoch: 6| Step: 10
Training loss: 2.8531892499761033
Validation loss: 2.949237230429486

Epoch: 6| Step: 11
Training loss: 3.033361741516336
Validation loss: 2.948605888659526

Epoch: 6| Step: 12
Training loss: 3.0077208666033766
Validation loss: 2.947959033141723

Epoch: 6| Step: 13
Training loss: 2.869702807999078
Validation loss: 2.9450383504158224

Epoch: 29| Step: 0
Training loss: 2.9632613994276458
Validation loss: 2.9458928434484113

Epoch: 6| Step: 1
Training loss: 3.852531636162044
Validation loss: 2.9443189004150643

Epoch: 6| Step: 2
Training loss: 2.895278895883561
Validation loss: 2.9449914791196243

Epoch: 6| Step: 3
Training loss: 3.284095620160655
Validation loss: 2.9491981188889085

Epoch: 6| Step: 4
Training loss: 2.716472417131433
Validation loss: 2.947048330841872

Epoch: 6| Step: 5
Training loss: 3.498257066811009
Validation loss: 2.9433537936819634

Epoch: 6| Step: 6
Training loss: 3.4857675823005443
Validation loss: 2.941796046804866

Epoch: 6| Step: 7
Training loss: 2.8443001015947895
Validation loss: 2.9386611926439836

Epoch: 6| Step: 8
Training loss: 3.84939384147392
Validation loss: 2.9354471990144333

Epoch: 6| Step: 9
Training loss: 2.717802386827043
Validation loss: 2.9331873835987357

Epoch: 6| Step: 10
Training loss: 3.3598598396495416
Validation loss: 2.935194332891288

Epoch: 6| Step: 11
Training loss: 3.1570487947266757
Validation loss: 2.9344868213599593

Epoch: 6| Step: 12
Training loss: 3.427573001899392
Validation loss: 2.9410580303103586

Epoch: 6| Step: 13
Training loss: 3.0172410498933657
Validation loss: 2.9364492159821665

Epoch: 30| Step: 0
Training loss: 3.2795052385505006
Validation loss: 2.933827315113222

Epoch: 6| Step: 1
Training loss: 3.0336679469683854
Validation loss: 2.928373709607888

Epoch: 6| Step: 2
Training loss: 3.510938173641179
Validation loss: 2.92392746408909

Epoch: 6| Step: 3
Training loss: 3.0420964255314864
Validation loss: 2.9234082521006233

Epoch: 6| Step: 4
Training loss: 3.9437285312364465
Validation loss: 2.9279094556869993

Epoch: 6| Step: 5
Training loss: 2.95765701586552
Validation loss: 2.9259856572271974

Epoch: 6| Step: 6
Training loss: 2.794288163547629
Validation loss: 2.9188887606162663

Epoch: 6| Step: 7
Training loss: 4.058514327152384
Validation loss: 2.9209843299614953

Epoch: 6| Step: 8
Training loss: 3.093390704012097
Validation loss: 2.9190043478827152

Epoch: 6| Step: 9
Training loss: 3.2573225718708363
Validation loss: 2.918235748472703

Epoch: 6| Step: 10
Training loss: 2.67742023253028
Validation loss: 2.9196986262166074

Epoch: 6| Step: 11
Training loss: 2.8270899106096534
Validation loss: 2.9150594719005882

Epoch: 6| Step: 12
Training loss: 3.3892906833229235
Validation loss: 2.9178388469775913

Epoch: 6| Step: 13
Training loss: 2.8561164340586505
Validation loss: 2.915493095899791

Epoch: 31| Step: 0
Training loss: 2.860040139136712
Validation loss: 2.9143923120547734

Epoch: 6| Step: 1
Training loss: 3.4130980921189153
Validation loss: 2.9147492963881274

Epoch: 6| Step: 2
Training loss: 3.6147141373389036
Validation loss: 2.91019679711122

Epoch: 6| Step: 3
Training loss: 2.70141697541852
Validation loss: 2.907892767389084

Epoch: 6| Step: 4
Training loss: 2.8831092247571686
Validation loss: 2.9048348363244343

Epoch: 6| Step: 5
Training loss: 3.6846066778204776
Validation loss: 2.9100333014470396

Epoch: 6| Step: 6
Training loss: 3.071093588523113
Validation loss: 2.9025970261467235

Epoch: 6| Step: 7
Training loss: 2.4270574434615892
Validation loss: 2.9023789863952167

Epoch: 6| Step: 8
Training loss: 3.307341247347151
Validation loss: 2.901071055026256

Epoch: 6| Step: 9
Training loss: 3.6870407853049905
Validation loss: 2.902381070957486

Epoch: 6| Step: 10
Training loss: 3.2407729406624104
Validation loss: 2.9003612486024646

Epoch: 6| Step: 11
Training loss: 3.433824134362443
Validation loss: 2.8984596908989535

Epoch: 6| Step: 12
Training loss: 3.5470129313936303
Validation loss: 2.897948622060529

Epoch: 6| Step: 13
Training loss: 2.4987894942276356
Validation loss: 2.8960113848374793

Epoch: 32| Step: 0
Training loss: 2.9910386073542403
Validation loss: 2.8959830767647468

Epoch: 6| Step: 1
Training loss: 3.1432205027303097
Validation loss: 2.8967316409339534

Epoch: 6| Step: 2
Training loss: 2.9208819491865783
Validation loss: 2.895226336538656

Epoch: 6| Step: 3
Training loss: 3.287240073948353
Validation loss: 2.892313616150518

Epoch: 6| Step: 4
Training loss: 2.583246403944074
Validation loss: 2.893201770037854

Epoch: 6| Step: 5
Training loss: 3.6803913455695128
Validation loss: 2.8964906307880858

Epoch: 6| Step: 6
Training loss: 3.290909853177866
Validation loss: 2.8960531037292863

Epoch: 6| Step: 7
Training loss: 3.704924970889018
Validation loss: 2.891645783077118

Epoch: 6| Step: 8
Training loss: 3.5037584560699164
Validation loss: 2.886745617883421

Epoch: 6| Step: 9
Training loss: 3.0927381305708876
Validation loss: 2.8863121045027027

Epoch: 6| Step: 10
Training loss: 2.7791978787600207
Validation loss: 2.8874524649258855

Epoch: 6| Step: 11
Training loss: 3.3577093208830515
Validation loss: 2.8845044845012

Epoch: 6| Step: 12
Training loss: 3.1938058150279653
Validation loss: 2.8881044892313015

Epoch: 6| Step: 13
Training loss: 3.1577247724469895
Validation loss: 2.882835112639016

Epoch: 33| Step: 0
Training loss: 2.5948762401844485
Validation loss: 2.882370495247564

Epoch: 6| Step: 1
Training loss: 3.6738849738922967
Validation loss: 2.880794555757993

Epoch: 6| Step: 2
Training loss: 2.954239892164159
Validation loss: 2.8798656389183557

Epoch: 6| Step: 3
Training loss: 2.991454350863603
Validation loss: 2.881532556724291

Epoch: 6| Step: 4
Training loss: 3.1968653107288407
Validation loss: 2.880237628967503

Epoch: 6| Step: 5
Training loss: 3.5765358673477334
Validation loss: 2.8887804544521827

Epoch: 6| Step: 6
Training loss: 2.901757983400076
Validation loss: 2.9019444452536325

Epoch: 6| Step: 7
Training loss: 3.070955709005717
Validation loss: 2.8800099082418

Epoch: 6| Step: 8
Training loss: 3.3548917440808657
Validation loss: 2.8760326273413757

Epoch: 6| Step: 9
Training loss: 3.887421664218402
Validation loss: 2.8802919767125608

Epoch: 6| Step: 10
Training loss: 2.6888667335157965
Validation loss: 2.8763789703750113

Epoch: 6| Step: 11
Training loss: 3.1495874164983957
Validation loss: 2.880578097208251

Epoch: 6| Step: 12
Training loss: 3.3519121890162897
Validation loss: 2.8840185764375486

Epoch: 6| Step: 13
Training loss: 2.9843436833680843
Validation loss: 2.8829142021236236

Epoch: 34| Step: 0
Training loss: 3.207426281481034
Validation loss: 2.890626940495162

Epoch: 6| Step: 1
Training loss: 2.865725443337054
Validation loss: 2.878749228969358

Epoch: 6| Step: 2
Training loss: 3.4651132025123776
Validation loss: 2.8776750037560106

Epoch: 6| Step: 3
Training loss: 2.8585070350591097
Validation loss: 2.87824296603431

Epoch: 6| Step: 4
Training loss: 3.6581479876467444
Validation loss: 2.8720869587483366

Epoch: 6| Step: 5
Training loss: 2.839958429972553
Validation loss: 2.8741843300166288

Epoch: 6| Step: 6
Training loss: 2.990817959259588
Validation loss: 2.8713379481014694

Epoch: 6| Step: 7
Training loss: 3.3038408353675113
Validation loss: 2.871440404831187

Epoch: 6| Step: 8
Training loss: 2.9855496157112404
Validation loss: 2.8748976772623953

Epoch: 6| Step: 9
Training loss: 3.2402844094614935
Validation loss: 2.867042039112626

Epoch: 6| Step: 10
Training loss: 3.733274417366906
Validation loss: 2.866016579033913

Epoch: 6| Step: 11
Training loss: 2.5835409901333044
Validation loss: 2.8638888904298914

Epoch: 6| Step: 12
Training loss: 2.9413115750865773
Validation loss: 2.8624658455293077

Epoch: 6| Step: 13
Training loss: 4.106640039787008
Validation loss: 2.8613724693886398

Epoch: 35| Step: 0
Training loss: 3.40142676766473
Validation loss: 2.8603389322680837

Epoch: 6| Step: 1
Training loss: 2.8119355377036443
Validation loss: 2.859556077064737

Epoch: 6| Step: 2
Training loss: 3.257772395118105
Validation loss: 2.8585922090496383

Epoch: 6| Step: 3
Training loss: 3.3617155216457744
Validation loss: 2.8559293750675967

Epoch: 6| Step: 4
Training loss: 3.9296525532740327
Validation loss: 2.8574324797260107

Epoch: 6| Step: 5
Training loss: 2.377109193340817
Validation loss: 2.861262738754241

Epoch: 6| Step: 6
Training loss: 3.2383787280827767
Validation loss: 2.8581913080958805

Epoch: 6| Step: 7
Training loss: 2.622652548252433
Validation loss: 2.8526834979059856

Epoch: 6| Step: 8
Training loss: 3.56547181505001
Validation loss: 2.85796259588826

Epoch: 6| Step: 9
Training loss: 3.1220808509264586
Validation loss: 2.857773916515704

Epoch: 6| Step: 10
Training loss: 3.5832300540914805
Validation loss: 2.862316583579516

Epoch: 6| Step: 11
Training loss: 2.7551083369338105
Validation loss: 2.8582702202347954

Epoch: 6| Step: 12
Training loss: 3.2150915891614624
Validation loss: 2.8589013618144743

Epoch: 6| Step: 13
Training loss: 2.6936635156188267
Validation loss: 2.84964619188885

Epoch: 36| Step: 0
Training loss: 2.785186382200256
Validation loss: 2.8527657436261835

Epoch: 6| Step: 1
Training loss: 3.134258897177081
Validation loss: 2.857432339765416

Epoch: 6| Step: 2
Training loss: 3.9584312560701624
Validation loss: 2.856554234702131

Epoch: 6| Step: 3
Training loss: 3.3600082865113303
Validation loss: 2.8506772863072127

Epoch: 6| Step: 4
Training loss: 2.3572584346823025
Validation loss: 2.8506251897419115

Epoch: 6| Step: 5
Training loss: 3.7972660569739234
Validation loss: 2.846613352378794

Epoch: 6| Step: 6
Training loss: 2.3524356881086064
Validation loss: 2.8502746937552437

Epoch: 6| Step: 7
Training loss: 3.163217690795686
Validation loss: 2.8560054602296905

Epoch: 6| Step: 8
Training loss: 2.671018764428509
Validation loss: 2.8551442252398185

Epoch: 6| Step: 9
Training loss: 3.413647938574679
Validation loss: 2.850846807367665

Epoch: 6| Step: 10
Training loss: 3.178874893765082
Validation loss: 2.8470151038728453

Epoch: 6| Step: 11
Training loss: 3.074689933216812
Validation loss: 2.848679323581773

Epoch: 6| Step: 12
Training loss: 3.6279065548555907
Validation loss: 2.855122059537005

Epoch: 6| Step: 13
Training loss: 3.060990409140655
Validation loss: 2.854088001560879

Epoch: 37| Step: 0
Training loss: 3.3297315847914546
Validation loss: 2.854179104450869

Epoch: 6| Step: 1
Training loss: 3.3501806011198303
Validation loss: 2.8648637361783846

Epoch: 6| Step: 2
Training loss: 4.206760351726771
Validation loss: 2.8488463061652287

Epoch: 6| Step: 3
Training loss: 3.4262082606949473
Validation loss: 2.8483797726832965

Epoch: 6| Step: 4
Training loss: 3.4446590435351503
Validation loss: 2.8403462699414734

Epoch: 6| Step: 5
Training loss: 2.2397009057226205
Validation loss: 2.8417205140612585

Epoch: 6| Step: 6
Training loss: 3.10131035459648
Validation loss: 2.839357727341631

Epoch: 6| Step: 7
Training loss: 3.151421810370659
Validation loss: 2.8406612863985434

Epoch: 6| Step: 8
Training loss: 3.197258018899398
Validation loss: 2.838830117032012

Epoch: 6| Step: 9
Training loss: 3.580115418518251
Validation loss: 2.8362554646900713

Epoch: 6| Step: 10
Training loss: 2.29180577173842
Validation loss: 2.8383121147410617

Epoch: 6| Step: 11
Training loss: 2.10486420000818
Validation loss: 2.83716323648092

Epoch: 6| Step: 12
Training loss: 3.1911632954301457
Validation loss: 2.836189972250188

Epoch: 6| Step: 13
Training loss: 2.8838006370407747
Validation loss: 2.833710079612783

Epoch: 38| Step: 0
Training loss: 2.504249680127503
Validation loss: 2.8339356922794243

Epoch: 6| Step: 1
Training loss: 3.4476186079904645
Validation loss: 2.837262041743517

Epoch: 6| Step: 2
Training loss: 3.287838089532165
Validation loss: 2.837082066470689

Epoch: 6| Step: 3
Training loss: 3.122030296701643
Validation loss: 2.8385882142468812

Epoch: 6| Step: 4
Training loss: 3.238939685397759
Validation loss: 2.8308923435059175

Epoch: 6| Step: 5
Training loss: 2.9232815707534465
Validation loss: 2.8299437590444145

Epoch: 6| Step: 6
Training loss: 3.7791331016679037
Validation loss: 2.8313334459724593

Epoch: 6| Step: 7
Training loss: 2.302517350884255
Validation loss: 2.831813490278162

Epoch: 6| Step: 8
Training loss: 3.025284708039438
Validation loss: 2.830583728139655

Epoch: 6| Step: 9
Training loss: 3.4434820662876593
Validation loss: 2.832675297042368

Epoch: 6| Step: 10
Training loss: 3.6140538394888533
Validation loss: 2.8318515633172794

Epoch: 6| Step: 11
Training loss: 3.327879704135249
Validation loss: 2.831554530058666

Epoch: 6| Step: 12
Training loss: 2.5312619621088395
Validation loss: 2.8270829245170694

Epoch: 6| Step: 13
Training loss: 3.385957801803753
Validation loss: 2.8296567913108737

Epoch: 39| Step: 0
Training loss: 2.6797673961417465
Validation loss: 2.8296646108993904

Epoch: 6| Step: 1
Training loss: 3.816562176957941
Validation loss: 2.8274334202623828

Epoch: 6| Step: 2
Training loss: 3.2956727353275457
Validation loss: 2.8281331855085745

Epoch: 6| Step: 3
Training loss: 2.8332996553401624
Validation loss: 2.8267823919320954

Epoch: 6| Step: 4
Training loss: 2.977930910844915
Validation loss: 2.8257973473798783

Epoch: 6| Step: 5
Training loss: 2.716633904928484
Validation loss: 2.8273536574349003

Epoch: 6| Step: 6
Training loss: 4.002129464758174
Validation loss: 2.823396887472593

Epoch: 6| Step: 7
Training loss: 3.5015949974611735
Validation loss: 2.8255876793611323

Epoch: 6| Step: 8
Training loss: 2.8430609235002136
Validation loss: 2.822656742482348

Epoch: 6| Step: 9
Training loss: 2.9122650903099108
Validation loss: 2.822557692075535

Epoch: 6| Step: 10
Training loss: 3.2964756439017417
Validation loss: 2.8232843642184293

Epoch: 6| Step: 11
Training loss: 2.755661165826805
Validation loss: 2.8295911388929897

Epoch: 6| Step: 12
Training loss: 2.808564038709762
Validation loss: 2.8235644954212447

Epoch: 6| Step: 13
Training loss: 3.476446737012262
Validation loss: 2.823123390472827

Epoch: 40| Step: 0
Training loss: 3.606157065636972
Validation loss: 2.8217245559835846

Epoch: 6| Step: 1
Training loss: 2.9404501203209032
Validation loss: 2.830690054532676

Epoch: 6| Step: 2
Training loss: 2.6796388315835986
Validation loss: 2.8283802461855556

Epoch: 6| Step: 3
Training loss: 3.2638658960132236
Validation loss: 2.825809685644885

Epoch: 6| Step: 4
Training loss: 3.207793912912693
Validation loss: 2.8299491926159197

Epoch: 6| Step: 5
Training loss: 3.0318791631207245
Validation loss: 2.826016373512061

Epoch: 6| Step: 6
Training loss: 2.653362634663157
Validation loss: 2.8318157082621918

Epoch: 6| Step: 7
Training loss: 3.4316686934146636
Validation loss: 2.8236205123344753

Epoch: 6| Step: 8
Training loss: 3.6664404076790236
Validation loss: 2.824976043933552

Epoch: 6| Step: 9
Training loss: 3.1555522487366354
Validation loss: 2.8187028017324645

Epoch: 6| Step: 10
Training loss: 2.7274904612121778
Validation loss: 2.816486772509706

Epoch: 6| Step: 11
Training loss: 2.8463821805300777
Validation loss: 2.8163398972776874

Epoch: 6| Step: 12
Training loss: 3.6219361610284393
Validation loss: 2.814392864816457

Epoch: 6| Step: 13
Training loss: 2.80568972561575
Validation loss: 2.8142320957564153

Epoch: 41| Step: 0
Training loss: 2.7875267095954013
Validation loss: 2.8115663480466595

Epoch: 6| Step: 1
Training loss: 3.3104139273175828
Validation loss: 2.8130187983777906

Epoch: 6| Step: 2
Training loss: 3.437172891485372
Validation loss: 2.8120122124219407

Epoch: 6| Step: 3
Training loss: 3.348083824885798
Validation loss: 2.8122377553659486

Epoch: 6| Step: 4
Training loss: 3.4316089435432833
Validation loss: 2.8104167045165687

Epoch: 6| Step: 5
Training loss: 3.3479422555043277
Validation loss: 2.809464172315409

Epoch: 6| Step: 6
Training loss: 2.935500093190109
Validation loss: 2.808421982450852

Epoch: 6| Step: 7
Training loss: 2.882799102007738
Validation loss: 2.8069553836285026

Epoch: 6| Step: 8
Training loss: 3.6369089963916705
Validation loss: 2.8074530151933828

Epoch: 6| Step: 9
Training loss: 2.477672436484421
Validation loss: 2.8059951321168444

Epoch: 6| Step: 10
Training loss: 3.2957048554261634
Validation loss: 2.807576734054345

Epoch: 6| Step: 11
Training loss: 2.187764832950387
Validation loss: 2.8148390515245816

Epoch: 6| Step: 12
Training loss: 3.820510578286152
Validation loss: 2.823917751004241

Epoch: 6| Step: 13
Training loss: 2.0265189608071132
Validation loss: 2.8161504519890665

Epoch: 42| Step: 0
Training loss: 2.6093673249091838
Validation loss: 2.8256863041995146

Epoch: 6| Step: 1
Training loss: 3.5773713096861672
Validation loss: 2.8190795323098183

Epoch: 6| Step: 2
Training loss: 2.598427840058337
Validation loss: 2.8102726893706222

Epoch: 6| Step: 3
Training loss: 3.351366157382629
Validation loss: 2.8040085202992087

Epoch: 6| Step: 4
Training loss: 3.420455847359435
Validation loss: 2.8065538917259127

Epoch: 6| Step: 5
Training loss: 2.8114880754712166
Validation loss: 2.8067267408813814

Epoch: 6| Step: 6
Training loss: 3.5838311019677866
Validation loss: 2.8017101454851203

Epoch: 6| Step: 7
Training loss: 2.3906585092627
Validation loss: 2.802148921510164

Epoch: 6| Step: 8
Training loss: 3.2517622058258357
Validation loss: 2.8105588323503294

Epoch: 6| Step: 9
Training loss: 3.2964588643901958
Validation loss: 2.812051436956092

Epoch: 6| Step: 10
Training loss: 2.8371288645013326
Validation loss: 2.809118252676742

Epoch: 6| Step: 11
Training loss: 2.9942775826879346
Validation loss: 2.8052963010611487

Epoch: 6| Step: 12
Training loss: 3.277467127445274
Validation loss: 2.8074813603043474

Epoch: 6| Step: 13
Training loss: 3.8614092573750707
Validation loss: 2.8070056512438497

Epoch: 43| Step: 0
Training loss: 2.8016103371292767
Validation loss: 2.8015068154310656

Epoch: 6| Step: 1
Training loss: 2.6683497680437513
Validation loss: 2.8031323597161686

Epoch: 6| Step: 2
Training loss: 3.585295576097033
Validation loss: 2.8027778234805365

Epoch: 6| Step: 3
Training loss: 3.6155038297324564
Validation loss: 2.8040748813992704

Epoch: 6| Step: 4
Training loss: 2.4907043252946064
Validation loss: 2.804523860058216

Epoch: 6| Step: 5
Training loss: 3.4527069805399413
Validation loss: 2.8083100568770063

Epoch: 6| Step: 6
Training loss: 3.268392020293072
Validation loss: 2.8057928106506327

Epoch: 6| Step: 7
Training loss: 2.6802774119206942
Validation loss: 2.8065405142501776

Epoch: 6| Step: 8
Training loss: 2.8320723326761565
Validation loss: 2.807996106530621

Epoch: 6| Step: 9
Training loss: 3.470034112460306
Validation loss: 2.8143515951146756

Epoch: 6| Step: 10
Training loss: 3.220570762232356
Validation loss: 2.8151005998600445

Epoch: 6| Step: 11
Training loss: 3.003603519419245
Validation loss: 2.8121815764402736

Epoch: 6| Step: 12
Training loss: 2.8158877843909593
Validation loss: 2.8131886749997257

Epoch: 6| Step: 13
Training loss: 4.021556703529387
Validation loss: 2.813902469012098

Epoch: 44| Step: 0
Training loss: 2.77233796150959
Validation loss: 2.8080639509841894

Epoch: 6| Step: 1
Training loss: 3.2659973224318226
Validation loss: 2.8027225681219314

Epoch: 6| Step: 2
Training loss: 3.2219055411133537
Validation loss: 2.8082838380247734

Epoch: 6| Step: 3
Training loss: 2.5053516328450223
Validation loss: 2.805290735664385

Epoch: 6| Step: 4
Training loss: 3.360962532549662
Validation loss: 2.8052689948707212

Epoch: 6| Step: 5
Training loss: 2.9741803747195945
Validation loss: 2.8047809780060464

Epoch: 6| Step: 6
Training loss: 2.9707745525292837
Validation loss: 2.80303682559973

Epoch: 6| Step: 7
Training loss: 3.509101477924662
Validation loss: 2.8051922427643783

Epoch: 6| Step: 8
Training loss: 2.433651649435383
Validation loss: 2.806442378536596

Epoch: 6| Step: 9
Training loss: 3.5391287892177536
Validation loss: 2.807965470450233

Epoch: 6| Step: 10
Training loss: 3.1446951687186786
Validation loss: 2.8081360772844453

Epoch: 6| Step: 11
Training loss: 3.177249357961382
Validation loss: 2.8089707293136006

Epoch: 6| Step: 12
Training loss: 2.967554755280168
Validation loss: 2.8043296536091566

Epoch: 6| Step: 13
Training loss: 4.120816045145632
Validation loss: 2.806548321515358

Epoch: 45| Step: 0
Training loss: 2.846837474186251
Validation loss: 2.802558205139999

Epoch: 6| Step: 1
Training loss: 3.3993864291195877
Validation loss: 2.8020317562974135

Epoch: 6| Step: 2
Training loss: 3.3052904377111116
Validation loss: 2.799437160000311

Epoch: 6| Step: 3
Training loss: 4.184694175712042
Validation loss: 2.800822052392615

Epoch: 6| Step: 4
Training loss: 2.2309331460577106
Validation loss: 2.793487998516484

Epoch: 6| Step: 5
Training loss: 3.528127724686171
Validation loss: 2.7966342202984684

Epoch: 6| Step: 6
Training loss: 2.570511644991112
Validation loss: 2.7926833906742536

Epoch: 6| Step: 7
Training loss: 3.0896742975619045
Validation loss: 2.796479037238846

Epoch: 6| Step: 8
Training loss: 2.9982768514196265
Validation loss: 2.7975374923120766

Epoch: 6| Step: 9
Training loss: 2.9590809016330843
Validation loss: 2.799478633085955

Epoch: 6| Step: 10
Training loss: 3.276945069426265
Validation loss: 2.7899619575762293

Epoch: 6| Step: 11
Training loss: 2.8651871108490945
Validation loss: 2.7869423471297607

Epoch: 6| Step: 12
Training loss: 2.5388303679945166
Validation loss: 2.785329605103971

Epoch: 6| Step: 13
Training loss: 3.679334619532814
Validation loss: 2.784277992827802

Epoch: 46| Step: 0
Training loss: 3.123557100968813
Validation loss: 2.785498256545141

Epoch: 6| Step: 1
Training loss: 3.672639028723451
Validation loss: 2.784147579419898

Epoch: 6| Step: 2
Training loss: 2.996969599816882
Validation loss: 2.7813922282980013

Epoch: 6| Step: 3
Training loss: 3.8003433775104196
Validation loss: 2.781934513125394

Epoch: 6| Step: 4
Training loss: 3.221039929658524
Validation loss: 2.780913390321799

Epoch: 6| Step: 5
Training loss: 2.9216137121536847
Validation loss: 2.7830159423841843

Epoch: 6| Step: 6
Training loss: 1.9604772506362962
Validation loss: 2.7810599057148067

Epoch: 6| Step: 7
Training loss: 2.4727350255582006
Validation loss: 2.778144510186054

Epoch: 6| Step: 8
Training loss: 3.1844533684158782
Validation loss: 2.782819982529463

Epoch: 6| Step: 9
Training loss: 2.6396986561075777
Validation loss: 2.774897631562491

Epoch: 6| Step: 10
Training loss: 3.187682651447652
Validation loss: 2.7821928856937066

Epoch: 6| Step: 11
Training loss: 3.0767245907219776
Validation loss: 2.7798119367081338

Epoch: 6| Step: 12
Training loss: 3.5948115895523487
Validation loss: 2.7832754921117857

Epoch: 6| Step: 13
Training loss: 3.374063715162992
Validation loss: 2.7825274168407215

Epoch: 47| Step: 0
Training loss: 2.8469349558574923
Validation loss: 2.782583917152229

Epoch: 6| Step: 1
Training loss: 2.4994221973279354
Validation loss: 2.786439197755572

Epoch: 6| Step: 2
Training loss: 2.5462654179970987
Validation loss: 2.7835407941547774

Epoch: 6| Step: 3
Training loss: 3.1722327721177788
Validation loss: 2.78135376317622

Epoch: 6| Step: 4
Training loss: 2.9634393675477546
Validation loss: 2.7806944689226074

Epoch: 6| Step: 5
Training loss: 3.144023517821588
Validation loss: 2.7833353013735436

Epoch: 6| Step: 6
Training loss: 3.6365181348231252
Validation loss: 2.7761587932328338

Epoch: 6| Step: 7
Training loss: 3.5690545802241034
Validation loss: 2.7803722405399927

Epoch: 6| Step: 8
Training loss: 3.3534712613547804
Validation loss: 2.778522377574951

Epoch: 6| Step: 9
Training loss: 3.661565324170654
Validation loss: 2.772722787261842

Epoch: 6| Step: 10
Training loss: 3.044725491281725
Validation loss: 2.7764495545026344

Epoch: 6| Step: 11
Training loss: 3.530449160348257
Validation loss: 2.771599672792773

Epoch: 6| Step: 12
Training loss: 2.288561352758133
Validation loss: 2.7702410744467225

Epoch: 6| Step: 13
Training loss: 2.510908930674725
Validation loss: 2.771950001655749

Epoch: 48| Step: 0
Training loss: 2.2254595249860363
Validation loss: 2.7703985276631498

Epoch: 6| Step: 1
Training loss: 2.9986690111819687
Validation loss: 2.7655968979527707

Epoch: 6| Step: 2
Training loss: 3.0197952767006564
Validation loss: 2.768067261548036

Epoch: 6| Step: 3
Training loss: 2.961596735134211
Validation loss: 2.7697138486679256

Epoch: 6| Step: 4
Training loss: 3.193682191729863
Validation loss: 2.7738681494105455

Epoch: 6| Step: 5
Training loss: 2.5845805408151725
Validation loss: 2.7759311445239176

Epoch: 6| Step: 6
Training loss: 3.434882259655389
Validation loss: 2.767479652584691

Epoch: 6| Step: 7
Training loss: 3.690716391391982
Validation loss: 2.770292482059181

Epoch: 6| Step: 8
Training loss: 3.2799264327382107
Validation loss: 2.766701559856625

Epoch: 6| Step: 9
Training loss: 2.8786153866380713
Validation loss: 2.7679583888285015

Epoch: 6| Step: 10
Training loss: 3.0973314304989135
Validation loss: 2.765574496571516

Epoch: 6| Step: 11
Training loss: 2.9504796042371706
Validation loss: 2.7681827757560398

Epoch: 6| Step: 12
Training loss: 3.4499010597084294
Validation loss: 2.7716567279233786

Epoch: 6| Step: 13
Training loss: 3.563246799294928
Validation loss: 2.7684431410770056

Epoch: 49| Step: 0
Training loss: 3.434528523034437
Validation loss: 2.7747827378156185

Epoch: 6| Step: 1
Training loss: 2.7855002684352557
Validation loss: 2.7860609852106872

Epoch: 6| Step: 2
Training loss: 3.465134807347798
Validation loss: 2.791189115841084

Epoch: 6| Step: 3
Training loss: 3.224922262038483
Validation loss: 2.787565240363693

Epoch: 6| Step: 4
Training loss: 3.599320448210163
Validation loss: 2.7822072897010215

Epoch: 6| Step: 5
Training loss: 2.9751594821272684
Validation loss: 2.7810465719966837

Epoch: 6| Step: 6
Training loss: 2.469683120725587
Validation loss: 2.770459274689261

Epoch: 6| Step: 7
Training loss: 2.9881135382369624
Validation loss: 2.767538312753189

Epoch: 6| Step: 8
Training loss: 3.3415908259460605
Validation loss: 2.766383191424487

Epoch: 6| Step: 9
Training loss: 2.7871932917300675
Validation loss: 2.7677975957203924

Epoch: 6| Step: 10
Training loss: 2.1462904310556197
Validation loss: 2.763926519407529

Epoch: 6| Step: 11
Training loss: 3.2172938636364377
Validation loss: 2.765106374088917

Epoch: 6| Step: 12
Training loss: 3.1698598990783733
Validation loss: 2.7626395459079003

Epoch: 6| Step: 13
Training loss: 3.6672760428168956
Validation loss: 2.7654626482449114

Epoch: 50| Step: 0
Training loss: 2.9373214342751037
Validation loss: 2.7655116834878624

Epoch: 6| Step: 1
Training loss: 2.8185222998970736
Validation loss: 2.763826352080116

Epoch: 6| Step: 2
Training loss: 3.040417209907669
Validation loss: 2.7625342566710738

Epoch: 6| Step: 3
Training loss: 2.9280027708030056
Validation loss: 2.7615937527854926

Epoch: 6| Step: 4
Training loss: 2.7510219755747527
Validation loss: 2.7625489255787405

Epoch: 6| Step: 5
Training loss: 3.3102852957129953
Validation loss: 2.7611972967327874

Epoch: 6| Step: 6
Training loss: 3.4042786659546
Validation loss: 2.7671291496523907

Epoch: 6| Step: 7
Training loss: 3.6419761671682696
Validation loss: 2.7691626263312683

Epoch: 6| Step: 8
Training loss: 3.3579476096341723
Validation loss: 2.7738984911056876

Epoch: 6| Step: 9
Training loss: 3.211314529596191
Validation loss: 2.7706280531344474

Epoch: 6| Step: 10
Training loss: 3.1734218489966715
Validation loss: 2.7723874059295373

Epoch: 6| Step: 11
Training loss: 2.4560725490155684
Validation loss: 2.7691260317825566

Epoch: 6| Step: 12
Training loss: 2.7890876320099305
Validation loss: 2.7641576961683016

Epoch: 6| Step: 13
Training loss: 3.453104148560136
Validation loss: 2.762570035602827

Epoch: 51| Step: 0
Training loss: 2.871246209281176
Validation loss: 2.762704950162567

Epoch: 6| Step: 1
Training loss: 3.7623334879481556
Validation loss: 2.760958092858298

Epoch: 6| Step: 2
Training loss: 3.21017380145862
Validation loss: 2.7629092131906003

Epoch: 6| Step: 3
Training loss: 2.749104440691564
Validation loss: 2.760684587351407

Epoch: 6| Step: 4
Training loss: 2.756585472261172
Validation loss: 2.758263330178826

Epoch: 6| Step: 5
Training loss: 3.136761922764847
Validation loss: 2.759694267069004

Epoch: 6| Step: 6
Training loss: 3.4207221052987755
Validation loss: 2.761051874953215

Epoch: 6| Step: 7
Training loss: 3.786918741575775
Validation loss: 2.7605762249058396

Epoch: 6| Step: 8
Training loss: 3.032138183092048
Validation loss: 2.762725602448553

Epoch: 6| Step: 9
Training loss: 2.592509145251544
Validation loss: 2.757716010373339

Epoch: 6| Step: 10
Training loss: 3.1958208868852847
Validation loss: 2.763491446785896

Epoch: 6| Step: 11
Training loss: 2.75669583198713
Validation loss: 2.7598897909816205

Epoch: 6| Step: 12
Training loss: 3.0725483991568194
Validation loss: 2.762246848408807

Epoch: 6| Step: 13
Training loss: 2.0478628555735945
Validation loss: 2.76127759185452

Epoch: 52| Step: 0
Training loss: 1.7667126301718235
Validation loss: 2.773805693271941

Epoch: 6| Step: 1
Training loss: 3.2735496629240073
Validation loss: 2.774217198407727

Epoch: 6| Step: 2
Training loss: 2.813286056874625
Validation loss: 2.7805485953412292

Epoch: 6| Step: 3
Training loss: 2.5326306380744854
Validation loss: 2.7837083751627363

Epoch: 6| Step: 4
Training loss: 3.358651584536359
Validation loss: 2.7701958024572835

Epoch: 6| Step: 5
Training loss: 2.8787157676341018
Validation loss: 2.7703474847698297

Epoch: 6| Step: 6
Training loss: 2.7505043607648445
Validation loss: 2.763373666726221

Epoch: 6| Step: 7
Training loss: 3.223439772175641
Validation loss: 2.7582105746523857

Epoch: 6| Step: 8
Training loss: 4.046848370674332
Validation loss: 2.7624904629248483

Epoch: 6| Step: 9
Training loss: 3.7746705119864514
Validation loss: 2.754486445965103

Epoch: 6| Step: 10
Training loss: 3.0946599989883183
Validation loss: 2.7555314262340724

Epoch: 6| Step: 11
Training loss: 3.0464508543922943
Validation loss: 2.7542660830330656

Epoch: 6| Step: 12
Training loss: 3.1219241454386824
Validation loss: 2.75630642196956

Epoch: 6| Step: 13
Training loss: 2.7836308093819975
Validation loss: 2.7545578801733064

Epoch: 53| Step: 0
Training loss: 2.9036541903023423
Validation loss: 2.75357720369939

Epoch: 6| Step: 1
Training loss: 3.163912696588789
Validation loss: 2.7531705498638916

Epoch: 6| Step: 2
Training loss: 2.9618630283787524
Validation loss: 2.755477696397287

Epoch: 6| Step: 3
Training loss: 2.8414471702786197
Validation loss: 2.7561339062710473

Epoch: 6| Step: 4
Training loss: 3.0643986635735767
Validation loss: 2.757440537690971

Epoch: 6| Step: 5
Training loss: 3.3920162879894664
Validation loss: 2.7694132000842044

Epoch: 6| Step: 6
Training loss: 2.826006691408436
Validation loss: 2.7720545457623054

Epoch: 6| Step: 7
Training loss: 2.785710048322983
Validation loss: 2.773502814150521

Epoch: 6| Step: 8
Training loss: 2.793747671924278
Validation loss: 2.782983792320913

Epoch: 6| Step: 9
Training loss: 3.6892971250188515
Validation loss: 2.7845373218032625

Epoch: 6| Step: 10
Training loss: 3.4770835228872885
Validation loss: 2.773545787915121

Epoch: 6| Step: 11
Training loss: 3.4358291726862435
Validation loss: 2.762873107394671

Epoch: 6| Step: 12
Training loss: 2.929103294616745
Validation loss: 2.7516443346317248

Epoch: 6| Step: 13
Training loss: 2.5780920777964234
Validation loss: 2.749776323978693

Epoch: 54| Step: 0
Training loss: 2.6227876332009936
Validation loss: 2.7497776851491884

Epoch: 6| Step: 1
Training loss: 3.46304126461338
Validation loss: 2.7519055753253294

Epoch: 6| Step: 2
Training loss: 3.117004848090946
Validation loss: 2.7558892442639493

Epoch: 6| Step: 3
Training loss: 3.0115271679297053
Validation loss: 2.7532707929352593

Epoch: 6| Step: 4
Training loss: 2.734388602086704
Validation loss: 2.749297713308049

Epoch: 6| Step: 5
Training loss: 3.246105354738207
Validation loss: 2.7461370443925928

Epoch: 6| Step: 6
Training loss: 3.5091838237699644
Validation loss: 2.7504408661034114

Epoch: 6| Step: 7
Training loss: 3.1811115347176178
Validation loss: 2.749531645432593

Epoch: 6| Step: 8
Training loss: 3.0903890830198457
Validation loss: 2.7489768406060335

Epoch: 6| Step: 9
Training loss: 3.391973130785488
Validation loss: 2.7498639530824573

Epoch: 6| Step: 10
Training loss: 2.3227692515949117
Validation loss: 2.7536155419826516

Epoch: 6| Step: 11
Training loss: 3.2825765199015224
Validation loss: 2.753875318458385

Epoch: 6| Step: 12
Training loss: 2.7242005181584497
Validation loss: 2.7462381444477195

Epoch: 6| Step: 13
Training loss: 3.2885405427586245
Validation loss: 2.750116233942223

Epoch: 55| Step: 0
Training loss: 3.2744972134256614
Validation loss: 2.7560059842219844

Epoch: 6| Step: 1
Training loss: 2.8578971003487235
Validation loss: 2.7623247371548794

Epoch: 6| Step: 2
Training loss: 3.5129300108815915
Validation loss: 2.755473228710131

Epoch: 6| Step: 3
Training loss: 2.2828329159804785
Validation loss: 2.7566792645462717

Epoch: 6| Step: 4
Training loss: 3.1458440279410427
Validation loss: 2.750630819099865

Epoch: 6| Step: 5
Training loss: 3.7082923858324928
Validation loss: 2.7473872974805333

Epoch: 6| Step: 6
Training loss: 2.4485839799933506
Validation loss: 2.7491587343040487

Epoch: 6| Step: 7
Training loss: 2.97517438746088
Validation loss: 2.7473280586841424

Epoch: 6| Step: 8
Training loss: 2.7701655469926996
Validation loss: 2.7425931659637532

Epoch: 6| Step: 9
Training loss: 3.0966373417851316
Validation loss: 2.7411681432800195

Epoch: 6| Step: 10
Training loss: 3.021169200948414
Validation loss: 2.743072513728494

Epoch: 6| Step: 11
Training loss: 3.2653674156411343
Validation loss: 2.740160289249947

Epoch: 6| Step: 12
Training loss: 3.292963681833659
Validation loss: 2.739923169201311

Epoch: 6| Step: 13
Training loss: 3.0287082673337364
Validation loss: 2.7412404305007234

Epoch: 56| Step: 0
Training loss: 2.6322886684467575
Validation loss: 2.7406688554454792

Epoch: 6| Step: 1
Training loss: 3.2394232674619605
Validation loss: 2.740933514186344

Epoch: 6| Step: 2
Training loss: 3.252739558622926
Validation loss: 2.7423303229963283

Epoch: 6| Step: 3
Training loss: 2.8568400835646233
Validation loss: 2.745676536912702

Epoch: 6| Step: 4
Training loss: 2.8620399605169218
Validation loss: 2.7421241904631417

Epoch: 6| Step: 5
Training loss: 2.951102235125148
Validation loss: 2.7376843955100174

Epoch: 6| Step: 6
Training loss: 3.457006422050675
Validation loss: 2.7375330076551587

Epoch: 6| Step: 7
Training loss: 3.0906206738448456
Validation loss: 2.733720552614913

Epoch: 6| Step: 8
Training loss: 3.007164030644512
Validation loss: 2.735738445166477

Epoch: 6| Step: 9
Training loss: 3.2210371169302876
Validation loss: 2.7409962825651544

Epoch: 6| Step: 10
Training loss: 3.0485739641719136
Validation loss: 2.743081587621232

Epoch: 6| Step: 11
Training loss: 2.7919829649637817
Validation loss: 2.7397304030510723

Epoch: 6| Step: 12
Training loss: 2.920383827640577
Validation loss: 2.739258831682685

Epoch: 6| Step: 13
Training loss: 3.810973064886965
Validation loss: 2.7354856367883307

Epoch: 57| Step: 0
Training loss: 3.1050174409189144
Validation loss: 2.73790608648055

Epoch: 6| Step: 1
Training loss: 3.3479416857965343
Validation loss: 2.7358064275888125

Epoch: 6| Step: 2
Training loss: 2.6155955469075187
Validation loss: 2.7361847198000713

Epoch: 6| Step: 3
Training loss: 2.99242812501387
Validation loss: 2.737198122148248

Epoch: 6| Step: 4
Training loss: 3.562468946890428
Validation loss: 2.735476330581611

Epoch: 6| Step: 5
Training loss: 2.9974680388387567
Validation loss: 2.7352505999178276

Epoch: 6| Step: 6
Training loss: 3.1377225151034485
Validation loss: 2.7338626092019553

Epoch: 6| Step: 7
Training loss: 3.058863134688738
Validation loss: 2.731321225676414

Epoch: 6| Step: 8
Training loss: 2.8042617517214703
Validation loss: 2.7340453077749536

Epoch: 6| Step: 9
Training loss: 3.362859294088282
Validation loss: 2.7340696224670062

Epoch: 6| Step: 10
Training loss: 2.6871450322842696
Validation loss: 2.7390217290627836

Epoch: 6| Step: 11
Training loss: 3.078562748953343
Validation loss: 2.740153710239711

Epoch: 6| Step: 12
Training loss: 3.3683727329170217
Validation loss: 2.7457012985487395

Epoch: 6| Step: 13
Training loss: 2.3125207229922933
Validation loss: 2.7552282986810313

Epoch: 58| Step: 0
Training loss: 2.6259133702651365
Validation loss: 2.756857078251232

Epoch: 6| Step: 1
Training loss: 2.9502769340227637
Validation loss: 2.7602065938434386

Epoch: 6| Step: 2
Training loss: 3.060710773570924
Validation loss: 2.7711578877296903

Epoch: 6| Step: 3
Training loss: 3.5044489241481163
Validation loss: 2.7517496753428747

Epoch: 6| Step: 4
Training loss: 2.6912012561967527
Validation loss: 2.7470496265088102

Epoch: 6| Step: 5
Training loss: 2.305351859852068
Validation loss: 2.7466124704294463

Epoch: 6| Step: 6
Training loss: 2.249540282014909
Validation loss: 2.7392856522418856

Epoch: 6| Step: 7
Training loss: 3.026786428034297
Validation loss: 2.7345765182843866

Epoch: 6| Step: 8
Training loss: 3.7029238618074194
Validation loss: 2.7369771390920503

Epoch: 6| Step: 9
Training loss: 3.0684624065192927
Validation loss: 2.7334673503397457

Epoch: 6| Step: 10
Training loss: 3.4668510669179935
Validation loss: 2.7325986637443735

Epoch: 6| Step: 11
Training loss: 3.973058329501849
Validation loss: 2.7330082115750365

Epoch: 6| Step: 12
Training loss: 3.068189357658396
Validation loss: 2.7346540486212785

Epoch: 6| Step: 13
Training loss: 2.216800746830319
Validation loss: 2.733599227810082

Epoch: 59| Step: 0
Training loss: 4.2380895333943105
Validation loss: 2.7381334370678614

Epoch: 6| Step: 1
Training loss: 2.6922670712393373
Validation loss: 2.7320098755161832

Epoch: 6| Step: 2
Training loss: 2.612210041363714
Validation loss: 2.7304504836142764

Epoch: 6| Step: 3
Training loss: 2.991234849316765
Validation loss: 2.7321748850657452

Epoch: 6| Step: 4
Training loss: 2.7256352725291366
Validation loss: 2.728742375974729

Epoch: 6| Step: 5
Training loss: 3.5742590396465554
Validation loss: 2.7297838055461137

Epoch: 6| Step: 6
Training loss: 3.3306050261308218
Validation loss: 2.7326243216207047

Epoch: 6| Step: 7
Training loss: 3.1602241499388053
Validation loss: 2.726642983905859

Epoch: 6| Step: 8
Training loss: 3.029651653044281
Validation loss: 2.729680516848812

Epoch: 6| Step: 9
Training loss: 3.023423936601521
Validation loss: 2.72958369866535

Epoch: 6| Step: 10
Training loss: 3.0646843418786944
Validation loss: 2.7393363979530903

Epoch: 6| Step: 11
Training loss: 2.460221443754023
Validation loss: 2.754109428647119

Epoch: 6| Step: 12
Training loss: 2.651877091132964
Validation loss: 2.7584310341875518

Epoch: 6| Step: 13
Training loss: 2.611396235146255
Validation loss: 2.763564719686745

Epoch: 60| Step: 0
Training loss: 2.9632488479270873
Validation loss: 2.7877642912697254

Epoch: 6| Step: 1
Training loss: 3.8293360448879037
Validation loss: 2.8318418975430792

Epoch: 6| Step: 2
Training loss: 3.2016885653502634
Validation loss: 2.8134756421875653

Epoch: 6| Step: 3
Training loss: 2.9535757861135723
Validation loss: 2.7361071166524393

Epoch: 6| Step: 4
Training loss: 3.2923935357262195
Validation loss: 2.723918994429783

Epoch: 6| Step: 5
Training loss: 3.614801464406475
Validation loss: 2.7275281200484116

Epoch: 6| Step: 6
Training loss: 2.338858216971315
Validation loss: 2.740938733248044

Epoch: 6| Step: 7
Training loss: 2.9260434694014132
Validation loss: 2.7715868175595553

Epoch: 6| Step: 8
Training loss: 2.540440393851892
Validation loss: 2.7894764976099498

Epoch: 6| Step: 9
Training loss: 2.744812320484338
Validation loss: 2.816059971418474

Epoch: 6| Step: 10
Training loss: 3.318155606880082
Validation loss: 2.8227619506687933

Epoch: 6| Step: 11
Training loss: 3.384916642260017
Validation loss: 2.815633394260847

Epoch: 6| Step: 12
Training loss: 3.118581665633371
Validation loss: 2.781027558812507

Epoch: 6| Step: 13
Training loss: 3.0342456919719747
Validation loss: 2.745351257336388

Epoch: 61| Step: 0
Training loss: 2.596792435968915
Validation loss: 2.725982829115112

Epoch: 6| Step: 1
Training loss: 3.0731861750635225
Validation loss: 2.7277052099906363

Epoch: 6| Step: 2
Training loss: 2.5020589932653525
Validation loss: 2.735355873732893

Epoch: 6| Step: 3
Training loss: 2.812828129594733
Validation loss: 2.775235562099198

Epoch: 6| Step: 4
Training loss: 2.983660068059597
Validation loss: 2.8282821839119587

Epoch: 6| Step: 5
Training loss: 3.4490998572728295
Validation loss: 2.8453824724811674

Epoch: 6| Step: 6
Training loss: 3.719024904492356
Validation loss: 2.801285020933919

Epoch: 6| Step: 7
Training loss: 2.660336750197366
Validation loss: 2.7518136927208197

Epoch: 6| Step: 8
Training loss: 3.6518697992118376
Validation loss: 2.7362408325552625

Epoch: 6| Step: 9
Training loss: 3.400762635137789
Validation loss: 2.7289316100723493

Epoch: 6| Step: 10
Training loss: 3.363359084873524
Validation loss: 2.7286330249862836

Epoch: 6| Step: 11
Training loss: 3.2808401669279372
Validation loss: 2.739073975314634

Epoch: 6| Step: 12
Training loss: 2.2683249335468654
Validation loss: 2.738907948382387

Epoch: 6| Step: 13
Training loss: 3.1899835223785837
Validation loss: 2.7491063458632725

Epoch: 62| Step: 0
Training loss: 3.011709883660749
Validation loss: 2.749017107247434

Epoch: 6| Step: 1
Training loss: 2.9982075104563455
Validation loss: 2.7523497594896

Epoch: 6| Step: 2
Training loss: 3.197422515431375
Validation loss: 2.7489457892492406

Epoch: 6| Step: 3
Training loss: 2.9637376734985255
Validation loss: 2.746032491039868

Epoch: 6| Step: 4
Training loss: 3.869340393670772
Validation loss: 2.740141083585373

Epoch: 6| Step: 5
Training loss: 2.819776235725411
Validation loss: 2.735300914376937

Epoch: 6| Step: 6
Training loss: 3.4862591904949563
Validation loss: 2.733175361334232

Epoch: 6| Step: 7
Training loss: 2.835808364828493
Validation loss: 2.729056491301546

Epoch: 6| Step: 8
Training loss: 2.928817253561707
Validation loss: 2.7315730051207248

Epoch: 6| Step: 9
Training loss: 3.252692647707314
Validation loss: 2.7310061824202307

Epoch: 6| Step: 10
Training loss: 2.5826361751197378
Validation loss: 2.733377219419824

Epoch: 6| Step: 11
Training loss: 3.2154826645262977
Validation loss: 2.7351469360739986

Epoch: 6| Step: 12
Training loss: 2.532675259429555
Validation loss: 2.742569058639564

Epoch: 6| Step: 13
Training loss: 3.2204542370384472
Validation loss: 2.7457809712389025

Epoch: 63| Step: 0
Training loss: 3.212288899295046
Validation loss: 2.7524312133887903

Epoch: 6| Step: 1
Training loss: 2.7922944648802845
Validation loss: 2.7502406304946496

Epoch: 6| Step: 2
Training loss: 3.150016899669061
Validation loss: 2.755687252744779

Epoch: 6| Step: 3
Training loss: 2.6309629560100647
Validation loss: 2.7575030549037036

Epoch: 6| Step: 4
Training loss: 3.142308329682806
Validation loss: 2.7580983445090452

Epoch: 6| Step: 5
Training loss: 2.975756598681204
Validation loss: 2.743661598397699

Epoch: 6| Step: 6
Training loss: 3.0396183554863065
Validation loss: 2.7356699212758677

Epoch: 6| Step: 7
Training loss: 3.314942521047187
Validation loss: 2.7250803609429055

Epoch: 6| Step: 8
Training loss: 2.652610529431264
Validation loss: 2.7213416424511316

Epoch: 6| Step: 9
Training loss: 2.884840833216905
Validation loss: 2.7218874587445945

Epoch: 6| Step: 10
Training loss: 3.3135785919949368
Validation loss: 2.719432264771921

Epoch: 6| Step: 11
Training loss: 3.243337698368639
Validation loss: 2.7218046151257136

Epoch: 6| Step: 12
Training loss: 3.2083114689333785
Validation loss: 2.72333215439828

Epoch: 6| Step: 13
Training loss: 3.414340848072853
Validation loss: 2.7230764779673717

Epoch: 64| Step: 0
Training loss: 2.7495073397369008
Validation loss: 2.7261191443474995

Epoch: 6| Step: 1
Training loss: 3.106865718615122
Validation loss: 2.7252424167094103

Epoch: 6| Step: 2
Training loss: 2.900184454477873
Validation loss: 2.727463154330033

Epoch: 6| Step: 3
Training loss: 3.3654894164818248
Validation loss: 2.7252035033580686

Epoch: 6| Step: 4
Training loss: 3.5978905749557573
Validation loss: 2.7283022038358964

Epoch: 6| Step: 5
Training loss: 2.8575378519589933
Validation loss: 2.7226879815804996

Epoch: 6| Step: 6
Training loss: 2.2853899453153366
Validation loss: 2.7206748001754564

Epoch: 6| Step: 7
Training loss: 3.3217091214812795
Validation loss: 2.721057987635563

Epoch: 6| Step: 8
Training loss: 3.0981968219213063
Validation loss: 2.7171674843788236

Epoch: 6| Step: 9
Training loss: 3.2137567993234577
Validation loss: 2.7153256257569676

Epoch: 6| Step: 10
Training loss: 2.754374406129389
Validation loss: 2.71880277818883

Epoch: 6| Step: 11
Training loss: 2.6164389379583186
Validation loss: 2.721338723977823

Epoch: 6| Step: 12
Training loss: 3.1906032042174557
Validation loss: 2.717484221604654

Epoch: 6| Step: 13
Training loss: 3.7958179148344464
Validation loss: 2.724011196325543

Epoch: 65| Step: 0
Training loss: 2.9981588435931834
Validation loss: 2.7262558383084254

Epoch: 6| Step: 1
Training loss: 3.8843784666774805
Validation loss: 2.7243455949468802

Epoch: 6| Step: 2
Training loss: 2.918857587183351
Validation loss: 2.718985062129701

Epoch: 6| Step: 3
Training loss: 2.4483810525411243
Validation loss: 2.717663850797863

Epoch: 6| Step: 4
Training loss: 3.230617238406442
Validation loss: 2.7176022122908168

Epoch: 6| Step: 5
Training loss: 3.4619880270219254
Validation loss: 2.7135799870467867

Epoch: 6| Step: 6
Training loss: 2.984275616493925
Validation loss: 2.7152435487589353

Epoch: 6| Step: 7
Training loss: 2.955763995039617
Validation loss: 2.712847701556982

Epoch: 6| Step: 8
Training loss: 2.4930287439102354
Validation loss: 2.7153314019837955

Epoch: 6| Step: 9
Training loss: 3.046589529895991
Validation loss: 2.7093336625992017

Epoch: 6| Step: 10
Training loss: 3.2611668285380815
Validation loss: 2.7109011521490998

Epoch: 6| Step: 11
Training loss: 2.5087986608479778
Validation loss: 2.7137501614293873

Epoch: 6| Step: 12
Training loss: 3.2643976414753646
Validation loss: 2.7115678878502023

Epoch: 6| Step: 13
Training loss: 2.7216485017947813
Validation loss: 2.718112150792344

Epoch: 66| Step: 0
Training loss: 2.3548526495901476
Validation loss: 2.7140552106527953

Epoch: 6| Step: 1
Training loss: 2.951227779603684
Validation loss: 2.7158202766293114

Epoch: 6| Step: 2
Training loss: 3.0575153500786874
Validation loss: 2.7119145824287965

Epoch: 6| Step: 3
Training loss: 3.27505562422012
Validation loss: 2.713331681631702

Epoch: 6| Step: 4
Training loss: 3.341843533928725
Validation loss: 2.714503762843721

Epoch: 6| Step: 5
Training loss: 3.6785473525149603
Validation loss: 2.7177069340022073

Epoch: 6| Step: 6
Training loss: 2.8717131692579008
Validation loss: 2.725483630214731

Epoch: 6| Step: 7
Training loss: 3.3141389067320692
Validation loss: 2.716576704881956

Epoch: 6| Step: 8
Training loss: 2.6007601213728537
Validation loss: 2.7099963311556996

Epoch: 6| Step: 9
Training loss: 2.9330969744159714
Validation loss: 2.7135591572330564

Epoch: 6| Step: 10
Training loss: 2.3073899798548405
Validation loss: 2.7115311778298286

Epoch: 6| Step: 11
Training loss: 3.4034045172061544
Validation loss: 2.709538050955387

Epoch: 6| Step: 12
Training loss: 3.505169456836941
Validation loss: 2.710163399922076

Epoch: 6| Step: 13
Training loss: 2.1825786271411998
Validation loss: 2.7009795437506923

Epoch: 67| Step: 0
Training loss: 2.899005351003424
Validation loss: 2.7048389436135154

Epoch: 6| Step: 1
Training loss: 2.7828321778567147
Validation loss: 2.7008493681881824

Epoch: 6| Step: 2
Training loss: 3.0556546994703147
Validation loss: 2.6999512686067066

Epoch: 6| Step: 3
Training loss: 2.323333109888023
Validation loss: 2.702903410804383

Epoch: 6| Step: 4
Training loss: 3.9537172137772516
Validation loss: 2.699346857818217

Epoch: 6| Step: 5
Training loss: 2.5527917203175385
Validation loss: 2.701421749825714

Epoch: 6| Step: 6
Training loss: 3.476681413652763
Validation loss: 2.6969934064327252

Epoch: 6| Step: 7
Training loss: 2.4768604376126824
Validation loss: 2.693015894885956

Epoch: 6| Step: 8
Training loss: 3.168053791677997
Validation loss: 2.691957651205787

Epoch: 6| Step: 9
Training loss: 2.465634275160291
Validation loss: 2.6872762618877246

Epoch: 6| Step: 10
Training loss: 3.340085597511844
Validation loss: 2.6890215104576622

Epoch: 6| Step: 11
Training loss: 3.271767420125031
Validation loss: 2.6887876474130574

Epoch: 6| Step: 12
Training loss: 3.138451578590504
Validation loss: 2.688350417976824

Epoch: 6| Step: 13
Training loss: 3.2569619950773037
Validation loss: 2.695724838601168

Epoch: 68| Step: 0
Training loss: 3.1172188587571314
Validation loss: 2.695268295042106

Epoch: 6| Step: 1
Training loss: 3.3473474277771187
Validation loss: 2.7132545435649917

Epoch: 6| Step: 2
Training loss: 2.9254168091196986
Validation loss: 2.701215581890514

Epoch: 6| Step: 3
Training loss: 3.3604262015831594
Validation loss: 2.690228880857372

Epoch: 6| Step: 4
Training loss: 2.396501287697554
Validation loss: 2.6884788491510037

Epoch: 6| Step: 5
Training loss: 2.936032192292804
Validation loss: 2.6829314849362604

Epoch: 6| Step: 6
Training loss: 2.9081258974908115
Validation loss: 2.6791757662852764

Epoch: 6| Step: 7
Training loss: 2.7786739291933937
Validation loss: 2.6752778487169615

Epoch: 6| Step: 8
Training loss: 2.8044088326154695
Validation loss: 2.6786158095988526

Epoch: 6| Step: 9
Training loss: 2.695759169567114
Validation loss: 2.6777498904447588

Epoch: 6| Step: 10
Training loss: 3.23057384389211
Validation loss: 2.680506522925165

Epoch: 6| Step: 11
Training loss: 3.5555394755105816
Validation loss: 2.6766088020538903

Epoch: 6| Step: 12
Training loss: 2.9635048558385413
Validation loss: 2.673242734743998

Epoch: 6| Step: 13
Training loss: 3.2832159056860104
Validation loss: 2.6752701355842

Epoch: 69| Step: 0
Training loss: 2.7701900758495706
Validation loss: 2.6785604268290997

Epoch: 6| Step: 1
Training loss: 3.4291658113338723
Validation loss: 2.6871379657095495

Epoch: 6| Step: 2
Training loss: 3.4880208327257463
Validation loss: 2.687065840172296

Epoch: 6| Step: 3
Training loss: 3.4424236755110127
Validation loss: 2.6889021969871023

Epoch: 6| Step: 4
Training loss: 2.900237395994507
Validation loss: 2.6749115399590906

Epoch: 6| Step: 5
Training loss: 3.0108156742775036
Validation loss: 2.6722696901891076

Epoch: 6| Step: 6
Training loss: 3.4826294499619377
Validation loss: 2.669533871171736

Epoch: 6| Step: 7
Training loss: 2.9209101914883866
Validation loss: 2.676562429083683

Epoch: 6| Step: 8
Training loss: 3.0890337512888335
Validation loss: 2.6709568989198598

Epoch: 6| Step: 9
Training loss: 2.6191195971436367
Validation loss: 2.669843163928527

Epoch: 6| Step: 10
Training loss: 2.4869245007217327
Validation loss: 2.688507665745499

Epoch: 6| Step: 11
Training loss: 2.940543363534561
Validation loss: 2.6935654742139996

Epoch: 6| Step: 12
Training loss: 2.8378718061144785
Validation loss: 2.6870445405438432

Epoch: 6| Step: 13
Training loss: 2.3286819303907667
Validation loss: 2.675921314376971

Epoch: 70| Step: 0
Training loss: 2.7822889466286096
Validation loss: 2.662016579567862

Epoch: 6| Step: 1
Training loss: 2.9081306525347026
Validation loss: 2.6614457834851453

Epoch: 6| Step: 2
Training loss: 2.703970980702944
Validation loss: 2.6660511174198915

Epoch: 6| Step: 3
Training loss: 3.008207696490894
Validation loss: 2.66267115753271

Epoch: 6| Step: 4
Training loss: 3.1736120719731993
Validation loss: 2.6674561261282346

Epoch: 6| Step: 5
Training loss: 3.0266562979544385
Validation loss: 2.670883665489978

Epoch: 6| Step: 6
Training loss: 2.565117499353966
Validation loss: 2.665484984387185

Epoch: 6| Step: 7
Training loss: 3.4369905961335063
Validation loss: 2.6688016476827703

Epoch: 6| Step: 8
Training loss: 3.2925076597409952
Validation loss: 2.6673627708806444

Epoch: 6| Step: 9
Training loss: 3.1689788675515462
Validation loss: 2.6663184310304873

Epoch: 6| Step: 10
Training loss: 3.2385851598947686
Validation loss: 2.6664912649376364

Epoch: 6| Step: 11
Training loss: 3.286984328522445
Validation loss: 2.6665625096817105

Epoch: 6| Step: 12
Training loss: 2.2178908283000145
Validation loss: 2.6673106106948796

Epoch: 6| Step: 13
Training loss: 3.199421597898
Validation loss: 2.670791645258067

Epoch: 71| Step: 0
Training loss: 3.1242920645877827
Validation loss: 2.6905045594896317

Epoch: 6| Step: 1
Training loss: 2.640484145882759
Validation loss: 2.691754568966946

Epoch: 6| Step: 2
Training loss: 3.2954243003868378
Validation loss: 2.7037240779482263

Epoch: 6| Step: 3
Training loss: 2.640022705731863
Validation loss: 2.7235247144263144

Epoch: 6| Step: 4
Training loss: 3.7190826010827935
Validation loss: 2.708795958227813

Epoch: 6| Step: 5
Training loss: 3.7444346774609345
Validation loss: 2.6764921966789195

Epoch: 6| Step: 6
Training loss: 3.1761571983042405
Validation loss: 2.667133875521532

Epoch: 6| Step: 7
Training loss: 2.549850691369753
Validation loss: 2.6624695581604945

Epoch: 6| Step: 8
Training loss: 2.516443628781443
Validation loss: 2.6596277060694833

Epoch: 6| Step: 9
Training loss: 3.1699188664880977
Validation loss: 2.66114868099121

Epoch: 6| Step: 10
Training loss: 2.7569779384146824
Validation loss: 2.661798003293443

Epoch: 6| Step: 11
Training loss: 2.788659160097169
Validation loss: 2.66212362559877

Epoch: 6| Step: 12
Training loss: 2.838823347668463
Validation loss: 2.6707855692080273

Epoch: 6| Step: 13
Training loss: 2.8854249111750914
Validation loss: 2.665548503222279

Epoch: 72| Step: 0
Training loss: 3.2614643660158262
Validation loss: 2.6662701464484075

Epoch: 6| Step: 1
Training loss: 3.0290739763255594
Validation loss: 2.665340525169408

Epoch: 6| Step: 2
Training loss: 2.602506265916711
Validation loss: 2.6603228118885083

Epoch: 6| Step: 3
Training loss: 2.322983973145262
Validation loss: 2.661414478602841

Epoch: 6| Step: 4
Training loss: 3.2333537530418117
Validation loss: 2.66315407162711

Epoch: 6| Step: 5
Training loss: 3.368954931476862
Validation loss: 2.667075345681736

Epoch: 6| Step: 6
Training loss: 2.67180593300946
Validation loss: 2.6645015000839547

Epoch: 6| Step: 7
Training loss: 2.32389806250081
Validation loss: 2.664536576825873

Epoch: 6| Step: 8
Training loss: 3.556679773089051
Validation loss: 2.67397955014439

Epoch: 6| Step: 9
Training loss: 2.659391183949589
Validation loss: 2.7093894032245713

Epoch: 6| Step: 10
Training loss: 2.769313959763186
Validation loss: 2.709385907937181

Epoch: 6| Step: 11
Training loss: 3.161730398991312
Validation loss: 2.6970034300168395

Epoch: 6| Step: 12
Training loss: 3.535401461195219
Validation loss: 2.701095273295563

Epoch: 6| Step: 13
Training loss: 3.432131928048979
Validation loss: 2.6835703612560087

Epoch: 73| Step: 0
Training loss: 2.686675366591889
Validation loss: 2.6601331341580434

Epoch: 6| Step: 1
Training loss: 2.9104690281265806
Validation loss: 2.657040778817913

Epoch: 6| Step: 2
Training loss: 2.4076312175734023
Validation loss: 2.6585548395259173

Epoch: 6| Step: 3
Training loss: 3.154031710507012
Validation loss: 2.6565332887787663

Epoch: 6| Step: 4
Training loss: 2.6144310854979276
Validation loss: 2.6575153972896746

Epoch: 6| Step: 5
Training loss: 3.020301158112111
Validation loss: 2.6598025438821895

Epoch: 6| Step: 6
Training loss: 2.6305984560261044
Validation loss: 2.6625258735702526

Epoch: 6| Step: 7
Training loss: 3.339491083810906
Validation loss: 2.6657954345077557

Epoch: 6| Step: 8
Training loss: 3.280315738460879
Validation loss: 2.6593854414233125

Epoch: 6| Step: 9
Training loss: 3.3084288717034696
Validation loss: 2.657182465872036

Epoch: 6| Step: 10
Training loss: 3.1613406683671674
Validation loss: 2.656733590102949

Epoch: 6| Step: 11
Training loss: 3.403606824157595
Validation loss: 2.653102848467749

Epoch: 6| Step: 12
Training loss: 2.986969623810951
Validation loss: 2.659152339529419

Epoch: 6| Step: 13
Training loss: 2.9961999031369895
Validation loss: 2.6686941509642725

Epoch: 74| Step: 0
Training loss: 2.821057841965897
Validation loss: 2.6950097944721785

Epoch: 6| Step: 1
Training loss: 3.069726941518317
Validation loss: 2.7183596357060678

Epoch: 6| Step: 2
Training loss: 2.7803817422431183
Validation loss: 2.7131701994923607

Epoch: 6| Step: 3
Training loss: 3.794724220237066
Validation loss: 2.696603864615411

Epoch: 6| Step: 4
Training loss: 3.250784265818867
Validation loss: 2.6721888676074963

Epoch: 6| Step: 5
Training loss: 3.437582535186357
Validation loss: 2.6549558591076843

Epoch: 6| Step: 6
Training loss: 2.397511157346983
Validation loss: 2.6547981883882867

Epoch: 6| Step: 7
Training loss: 2.635541639016077
Validation loss: 2.658863608319914

Epoch: 6| Step: 8
Training loss: 3.1218505247453057
Validation loss: 2.6612181016377083

Epoch: 6| Step: 9
Training loss: 3.006608836117597
Validation loss: 2.664772542193669

Epoch: 6| Step: 10
Training loss: 3.138269556511386
Validation loss: 2.6679515268435936

Epoch: 6| Step: 11
Training loss: 2.718827432867098
Validation loss: 2.661163332672782

Epoch: 6| Step: 12
Training loss: 3.1512809389344056
Validation loss: 2.665412795191483

Epoch: 6| Step: 13
Training loss: 2.5195478098716935
Validation loss: 2.661973197908282

Epoch: 75| Step: 0
Training loss: 2.652349502939269
Validation loss: 2.6590867898291486

Epoch: 6| Step: 1
Training loss: 3.0295210164498494
Validation loss: 2.662522732717888

Epoch: 6| Step: 2
Training loss: 2.767878675596798
Validation loss: 2.6645634000183773

Epoch: 6| Step: 3
Training loss: 3.105598955603713
Validation loss: 2.6639671357933183

Epoch: 6| Step: 4
Training loss: 2.781654242809139
Validation loss: 2.6710644187884007

Epoch: 6| Step: 5
Training loss: 2.6482887788949485
Validation loss: 2.6683138219702847

Epoch: 6| Step: 6
Training loss: 3.433994933767253
Validation loss: 2.6642919084435293

Epoch: 6| Step: 7
Training loss: 2.7069814878351455
Validation loss: 2.665149934823588

Epoch: 6| Step: 8
Training loss: 2.979109347843528
Validation loss: 2.6598055607191564

Epoch: 6| Step: 9
Training loss: 3.5203099209724797
Validation loss: 2.6633729635052084

Epoch: 6| Step: 10
Training loss: 2.8487956798551775
Validation loss: 2.6617827863776786

Epoch: 6| Step: 11
Training loss: 2.6758662523565127
Validation loss: 2.660291648942393

Epoch: 6| Step: 12
Training loss: 3.7071331239294816
Validation loss: 2.6587040586136697

Epoch: 6| Step: 13
Training loss: 2.939503412672003
Validation loss: 2.654515109438641

Epoch: 76| Step: 0
Training loss: 2.753301892351219
Validation loss: 2.659206521344195

Epoch: 6| Step: 1
Training loss: 2.877102622028047
Validation loss: 2.6572512839230797

Epoch: 6| Step: 2
Training loss: 3.175443999716719
Validation loss: 2.6567262670143004

Epoch: 6| Step: 3
Training loss: 3.2806586323033584
Validation loss: 2.6645668463446377

Epoch: 6| Step: 4
Training loss: 3.138330029124423
Validation loss: 2.653977315445456

Epoch: 6| Step: 5
Training loss: 2.888408904263726
Validation loss: 2.6570803536959877

Epoch: 6| Step: 6
Training loss: 2.4426506594184767
Validation loss: 2.665982732307354

Epoch: 6| Step: 7
Training loss: 3.223595388727408
Validation loss: 2.677527099336199

Epoch: 6| Step: 8
Training loss: 2.4110325436699815
Validation loss: 2.677584356136517

Epoch: 6| Step: 9
Training loss: 2.8920874942613493
Validation loss: 2.688166422920095

Epoch: 6| Step: 10
Training loss: 3.074342834217532
Validation loss: 2.6719017543195633

Epoch: 6| Step: 11
Training loss: 3.3967213473974036
Validation loss: 2.6624964743924058

Epoch: 6| Step: 12
Training loss: 3.3202873677817224
Validation loss: 2.65328521115311

Epoch: 6| Step: 13
Training loss: 2.90453673695325
Validation loss: 2.6500413540449697

Epoch: 77| Step: 0
Training loss: 2.5379057611475293
Validation loss: 2.6480497143544848

Epoch: 6| Step: 1
Training loss: 3.2236502669173026
Validation loss: 2.65195845057853

Epoch: 6| Step: 2
Training loss: 3.3050920676192144
Validation loss: 2.649459405043435

Epoch: 6| Step: 3
Training loss: 3.4320367574701853
Validation loss: 2.651392538863173

Epoch: 6| Step: 4
Training loss: 2.3322328515507493
Validation loss: 2.6519774277420822

Epoch: 6| Step: 5
Training loss: 3.4972622927093053
Validation loss: 2.649973594795562

Epoch: 6| Step: 6
Training loss: 2.83504520386949
Validation loss: 2.653052894212216

Epoch: 6| Step: 7
Training loss: 3.3398795856538723
Validation loss: 2.664536007242617

Epoch: 6| Step: 8
Training loss: 1.9235081750325664
Validation loss: 2.6530540837252192

Epoch: 6| Step: 9
Training loss: 3.116662155664889
Validation loss: 2.658897535901178

Epoch: 6| Step: 10
Training loss: 3.0285287814209427
Validation loss: 2.65598668356226

Epoch: 6| Step: 11
Training loss: 3.184125273161844
Validation loss: 2.6585512253324124

Epoch: 6| Step: 12
Training loss: 3.132060809815454
Validation loss: 2.6565222053587902

Epoch: 6| Step: 13
Training loss: 2.306716284613302
Validation loss: 2.6478125133365227

Epoch: 78| Step: 0
Training loss: 2.8312130081421185
Validation loss: 2.650380087550788

Epoch: 6| Step: 1
Training loss: 3.2930582380522972
Validation loss: 2.646549902644573

Epoch: 6| Step: 2
Training loss: 2.99300809519215
Validation loss: 2.6452339048220477

Epoch: 6| Step: 3
Training loss: 3.205548072408062
Validation loss: 2.6450780853693217

Epoch: 6| Step: 4
Training loss: 2.9376353780515174
Validation loss: 2.644539837038584

Epoch: 6| Step: 5
Training loss: 2.9814163641425453
Validation loss: 2.6474465857034133

Epoch: 6| Step: 6
Training loss: 2.755440445601278
Validation loss: 2.648622204910633

Epoch: 6| Step: 7
Training loss: 2.3915989705605596
Validation loss: 2.649842159626644

Epoch: 6| Step: 8
Training loss: 3.0480247480133675
Validation loss: 2.64706497522763

Epoch: 6| Step: 9
Training loss: 2.8735981716354093
Validation loss: 2.646778448193586

Epoch: 6| Step: 10
Training loss: 3.829049384168526
Validation loss: 2.6451992098286055

Epoch: 6| Step: 11
Training loss: 3.4023686965395714
Validation loss: 2.6478916449898464

Epoch: 6| Step: 12
Training loss: 2.346193286208274
Validation loss: 2.648479843079454

Epoch: 6| Step: 13
Training loss: 2.451401512058262
Validation loss: 2.646639242788277

Epoch: 79| Step: 0
Training loss: 2.9177085831975824
Validation loss: 2.645858160562444

Epoch: 6| Step: 1
Training loss: 3.392035265739222
Validation loss: 2.646023306899045

Epoch: 6| Step: 2
Training loss: 3.4590621241614894
Validation loss: 2.648695276630594

Epoch: 6| Step: 3
Training loss: 2.4957424149381264
Validation loss: 2.6503025720748394

Epoch: 6| Step: 4
Training loss: 3.128171913183899
Validation loss: 2.65601651578869

Epoch: 6| Step: 5
Training loss: 3.3212368026430994
Validation loss: 2.65428014264019

Epoch: 6| Step: 6
Training loss: 2.6607579294430823
Validation loss: 2.6566404891675273

Epoch: 6| Step: 7
Training loss: 3.354465179112524
Validation loss: 2.6572610695836394

Epoch: 6| Step: 8
Training loss: 3.1830621380818402
Validation loss: 2.668695000165355

Epoch: 6| Step: 9
Training loss: 3.0024478780143498
Validation loss: 2.6569269397459587

Epoch: 6| Step: 10
Training loss: 2.5141929199075363
Validation loss: 2.656447097443796

Epoch: 6| Step: 11
Training loss: 2.785312728445274
Validation loss: 2.6526452637581395

Epoch: 6| Step: 12
Training loss: 2.7624049002041895
Validation loss: 2.6498765984034427

Epoch: 6| Step: 13
Training loss: 2.4277662918067415
Validation loss: 2.6487746606549574

Epoch: 80| Step: 0
Training loss: 3.7291426133955348
Validation loss: 2.648142213120207

Epoch: 6| Step: 1
Training loss: 2.6100371657023693
Validation loss: 2.6449587630251936

Epoch: 6| Step: 2
Training loss: 3.2536645916322273
Validation loss: 2.6474485892076567

Epoch: 6| Step: 3
Training loss: 2.852536220738485
Validation loss: 2.6536016591682214

Epoch: 6| Step: 4
Training loss: 1.9188681550566413
Validation loss: 2.6550731756827504

Epoch: 6| Step: 5
Training loss: 2.233726887639407
Validation loss: 2.6717093137548193

Epoch: 6| Step: 6
Training loss: 2.844098415619525
Validation loss: 2.6789811477371095

Epoch: 6| Step: 7
Training loss: 3.1836448244081748
Validation loss: 2.6986713697620766

Epoch: 6| Step: 8
Training loss: 3.577462613958734
Validation loss: 2.677780702783061

Epoch: 6| Step: 9
Training loss: 3.5001580338903318
Validation loss: 2.657754631893357

Epoch: 6| Step: 10
Training loss: 3.0264089408522614
Validation loss: 2.6472410969387576

Epoch: 6| Step: 11
Training loss: 3.177158709189534
Validation loss: 2.6439936451886674

Epoch: 6| Step: 12
Training loss: 2.5112836825825786
Validation loss: 2.6514093068500584

Epoch: 6| Step: 13
Training loss: 2.880323208845589
Validation loss: 2.65275752288136

Epoch: 81| Step: 0
Training loss: 3.5240138358581716
Validation loss: 2.6484236036095745

Epoch: 6| Step: 1
Training loss: 2.5185353757983924
Validation loss: 2.6448575417440976

Epoch: 6| Step: 2
Training loss: 3.1928756860844976
Validation loss: 2.6468665650846397

Epoch: 6| Step: 3
Training loss: 2.791887578242046
Validation loss: 2.6467170156884388

Epoch: 6| Step: 4
Training loss: 2.8652829697225424
Validation loss: 2.64736785521081

Epoch: 6| Step: 5
Training loss: 2.9600074938086425
Validation loss: 2.6472282362928663

Epoch: 6| Step: 6
Training loss: 3.4217325816716935
Validation loss: 2.648850319055288

Epoch: 6| Step: 7
Training loss: 2.8745987653633702
Validation loss: 2.64743638804667

Epoch: 6| Step: 8
Training loss: 3.2212322256229218
Validation loss: 2.646892190068108

Epoch: 6| Step: 9
Training loss: 2.8882520678828216
Validation loss: 2.6532367637875054

Epoch: 6| Step: 10
Training loss: 2.873472554344107
Validation loss: 2.6639766379159795

Epoch: 6| Step: 11
Training loss: 2.6300898660601404
Validation loss: 2.668719344455226

Epoch: 6| Step: 12
Training loss: 2.578530481992354
Validation loss: 2.676442345638964

Epoch: 6| Step: 13
Training loss: 3.535554001492997
Validation loss: 2.6872032137109283

Epoch: 82| Step: 0
Training loss: 3.232658778610985
Validation loss: 2.6791703647113456

Epoch: 6| Step: 1
Training loss: 3.0120540684562274
Validation loss: 2.6662424346762807

Epoch: 6| Step: 2
Training loss: 2.93989676235878
Validation loss: 2.6503866591942162

Epoch: 6| Step: 3
Training loss: 2.5833310363103026
Validation loss: 2.6390488346362195

Epoch: 6| Step: 4
Training loss: 2.600961243396071
Validation loss: 2.6404224601320774

Epoch: 6| Step: 5
Training loss: 2.6993160865115264
Validation loss: 2.641953461999915

Epoch: 6| Step: 6
Training loss: 2.8001372848642463
Validation loss: 2.644288673544213

Epoch: 6| Step: 7
Training loss: 2.729504503689789
Validation loss: 2.64720685048863

Epoch: 6| Step: 8
Training loss: 3.419990194652399
Validation loss: 2.654426818601622

Epoch: 6| Step: 9
Training loss: 3.0084752529268286
Validation loss: 2.6424336533791655

Epoch: 6| Step: 10
Training loss: 3.5695989717975336
Validation loss: 2.64868772225321

Epoch: 6| Step: 11
Training loss: 3.6206936743828275
Validation loss: 2.6436456290483137

Epoch: 6| Step: 12
Training loss: 2.489631609801087
Validation loss: 2.6465249940775917

Epoch: 6| Step: 13
Training loss: 2.800365209603816
Validation loss: 2.644390249126407

Epoch: 83| Step: 0
Training loss: 3.098032136025178
Validation loss: 2.64080783312735

Epoch: 6| Step: 1
Training loss: 2.7878460622237546
Validation loss: 2.6418298985764954

Epoch: 6| Step: 2
Training loss: 2.9022551942769472
Validation loss: 2.6378700208298795

Epoch: 6| Step: 3
Training loss: 2.6611148938616913
Validation loss: 2.6408714455637354

Epoch: 6| Step: 4
Training loss: 2.3912193207834136
Validation loss: 2.6448817778232607

Epoch: 6| Step: 5
Training loss: 2.974625725804536
Validation loss: 2.6558216306924076

Epoch: 6| Step: 6
Training loss: 3.293124266512332
Validation loss: 2.6782609977867646

Epoch: 6| Step: 7
Training loss: 3.7645517933039216
Validation loss: 2.694384714373781

Epoch: 6| Step: 8
Training loss: 3.1347143626552345
Validation loss: 2.688218828829867

Epoch: 6| Step: 9
Training loss: 2.3665766667549364
Validation loss: 2.665655735369893

Epoch: 6| Step: 10
Training loss: 3.0229635335355023
Validation loss: 2.655322882692197

Epoch: 6| Step: 11
Training loss: 2.882287119724082
Validation loss: 2.6491741269548603

Epoch: 6| Step: 12
Training loss: 2.773380246713185
Validation loss: 2.6338515421202873

Epoch: 6| Step: 13
Training loss: 3.9106279178246965
Validation loss: 2.638887616225409

Epoch: 84| Step: 0
Training loss: 3.2591108118153036
Validation loss: 2.63676304496284

Epoch: 6| Step: 1
Training loss: 3.1685021418256776
Validation loss: 2.6385457779390333

Epoch: 6| Step: 2
Training loss: 3.0550630538601857
Validation loss: 2.6385474563968514

Epoch: 6| Step: 3
Training loss: 2.8309879880681983
Validation loss: 2.6398687947920028

Epoch: 6| Step: 4
Training loss: 2.9421084352344553
Validation loss: 2.6410572290229735

Epoch: 6| Step: 5
Training loss: 2.058141437908551
Validation loss: 2.640371484365153

Epoch: 6| Step: 6
Training loss: 2.582025617400012
Validation loss: 2.6389781080476156

Epoch: 6| Step: 7
Training loss: 2.7663830941197203
Validation loss: 2.642181997620386

Epoch: 6| Step: 8
Training loss: 3.6069814168368333
Validation loss: 2.644910596407425

Epoch: 6| Step: 9
Training loss: 3.3874467289526042
Validation loss: 2.656656582314326

Epoch: 6| Step: 10
Training loss: 3.1071949126043816
Validation loss: 2.6746841168252384

Epoch: 6| Step: 11
Training loss: 2.6656059201844546
Validation loss: 2.6863055005906964

Epoch: 6| Step: 12
Training loss: 3.1216825042121905
Validation loss: 2.6937582891379668

Epoch: 6| Step: 13
Training loss: 3.1272922501146185
Validation loss: 2.6862802773463232

Epoch: 85| Step: 0
Training loss: 2.9406207126176738
Validation loss: 2.666625373146324

Epoch: 6| Step: 1
Training loss: 2.972104556486858
Validation loss: 2.643136078250968

Epoch: 6| Step: 2
Training loss: 3.4394897251033907
Validation loss: 2.632846788599543

Epoch: 6| Step: 3
Training loss: 2.5608785197720305
Validation loss: 2.6315461146827506

Epoch: 6| Step: 4
Training loss: 2.7022656965714793
Validation loss: 2.6305483550856965

Epoch: 6| Step: 5
Training loss: 3.1780169173235113
Validation loss: 2.63214829934548

Epoch: 6| Step: 6
Training loss: 3.6212567701134883
Validation loss: 2.6344700619867933

Epoch: 6| Step: 7
Training loss: 3.1048692424473066
Validation loss: 2.631454677043925

Epoch: 6| Step: 8
Training loss: 2.6966575915070345
Validation loss: 2.6367444142954

Epoch: 6| Step: 9
Training loss: 2.9701130197515475
Validation loss: 2.6322559932017557

Epoch: 6| Step: 10
Training loss: 3.114540142325467
Validation loss: 2.634890775793639

Epoch: 6| Step: 11
Training loss: 2.4114913333972
Validation loss: 2.6340620268935426

Epoch: 6| Step: 12
Training loss: 2.8405957177460586
Validation loss: 2.631989122066865

Epoch: 6| Step: 13
Training loss: 2.9721074443612627
Validation loss: 2.6348575441701954

Epoch: 86| Step: 0
Training loss: 3.2419009897879194
Validation loss: 2.6416874783390565

Epoch: 6| Step: 1
Training loss: 2.3483204338454047
Validation loss: 2.651836539534131

Epoch: 6| Step: 2
Training loss: 3.332562277942416
Validation loss: 2.6500326764844795

Epoch: 6| Step: 3
Training loss: 2.949689693617831
Validation loss: 2.647505608554583

Epoch: 6| Step: 4
Training loss: 2.834539904523645
Validation loss: 2.639268935045138

Epoch: 6| Step: 5
Training loss: 3.22115554546745
Validation loss: 2.6338512841844124

Epoch: 6| Step: 6
Training loss: 2.814842435448451
Validation loss: 2.6322419110687116

Epoch: 6| Step: 7
Training loss: 3.204447849934403
Validation loss: 2.6314173628173063

Epoch: 6| Step: 8
Training loss: 3.0207068756644566
Validation loss: 2.629706164831523

Epoch: 6| Step: 9
Training loss: 2.890878532219802
Validation loss: 2.632835489594262

Epoch: 6| Step: 10
Training loss: 3.082817257830607
Validation loss: 2.6308310271254474

Epoch: 6| Step: 11
Training loss: 2.4452594592889705
Validation loss: 2.6305284095606285

Epoch: 6| Step: 12
Training loss: 3.029750492410992
Validation loss: 2.638462681039874

Epoch: 6| Step: 13
Training loss: 3.257158318939414
Validation loss: 2.6364279139586944

Epoch: 87| Step: 0
Training loss: 2.8916680181172167
Validation loss: 2.6336320938001476

Epoch: 6| Step: 1
Training loss: 3.4946219132531855
Validation loss: 2.6313940860943386

Epoch: 6| Step: 2
Training loss: 2.7240876166527177
Validation loss: 2.6318267060488423

Epoch: 6| Step: 3
Training loss: 2.8566678265361887
Validation loss: 2.6369626980089715

Epoch: 6| Step: 4
Training loss: 3.1858450389277486
Validation loss: 2.641690827379508

Epoch: 6| Step: 5
Training loss: 3.346584081606017
Validation loss: 2.642949331251267

Epoch: 6| Step: 6
Training loss: 2.849111344844611
Validation loss: 2.6379937502973823

Epoch: 6| Step: 7
Training loss: 2.9773196561504616
Validation loss: 2.6283287539514952

Epoch: 6| Step: 8
Training loss: 3.3567869641271817
Validation loss: 2.6330052811521467

Epoch: 6| Step: 9
Training loss: 3.150201421685982
Validation loss: 2.6288808992583026

Epoch: 6| Step: 10
Training loss: 1.9857190604020176
Validation loss: 2.6293042331823635

Epoch: 6| Step: 11
Training loss: 2.5834371689468267
Validation loss: 2.6333744635692238

Epoch: 6| Step: 12
Training loss: 3.217213236042111
Validation loss: 2.6305570277262746

Epoch: 6| Step: 13
Training loss: 2.5439015448790157
Validation loss: 2.631515194507077

Epoch: 88| Step: 0
Training loss: 3.1254995328286186
Validation loss: 2.6316761451499633

Epoch: 6| Step: 1
Training loss: 2.8040061696919305
Validation loss: 2.6307423312198273

Epoch: 6| Step: 2
Training loss: 3.115513861385213
Validation loss: 2.6359988034180732

Epoch: 6| Step: 3
Training loss: 2.898671431239522
Validation loss: 2.634312113980317

Epoch: 6| Step: 4
Training loss: 2.7185048836893455
Validation loss: 2.6311639859931204

Epoch: 6| Step: 5
Training loss: 2.7342232798309882
Validation loss: 2.6324708320777996

Epoch: 6| Step: 6
Training loss: 2.5775437133219863
Validation loss: 2.6316524713118796

Epoch: 6| Step: 7
Training loss: 2.472415761717981
Validation loss: 2.6299116282645167

Epoch: 6| Step: 8
Training loss: 3.461134928632754
Validation loss: 2.634901581453888

Epoch: 6| Step: 9
Training loss: 3.5047497536737864
Validation loss: 2.634978941915214

Epoch: 6| Step: 10
Training loss: 2.914718431382476
Validation loss: 2.630419584595638

Epoch: 6| Step: 11
Training loss: 2.834799966634344
Validation loss: 2.6298258146400104

Epoch: 6| Step: 12
Training loss: 3.595240540926176
Validation loss: 2.6366360889696225

Epoch: 6| Step: 13
Training loss: 2.4317497504692933
Validation loss: 2.6363514449383874

Epoch: 89| Step: 0
Training loss: 3.1653539212025197
Validation loss: 2.63386176122732

Epoch: 6| Step: 1
Training loss: 2.8525409012853538
Validation loss: 2.6273088951016645

Epoch: 6| Step: 2
Training loss: 2.5216395347364284
Validation loss: 2.628406164489479

Epoch: 6| Step: 3
Training loss: 3.186983852109765
Validation loss: 2.62925574272997

Epoch: 6| Step: 4
Training loss: 3.11752279290109
Validation loss: 2.6255480276755803

Epoch: 6| Step: 5
Training loss: 2.7189753647277835
Validation loss: 2.626537726167964

Epoch: 6| Step: 6
Training loss: 2.949281482155667
Validation loss: 2.626529381875632

Epoch: 6| Step: 7
Training loss: 2.9971629079049067
Validation loss: 2.6250740525230247

Epoch: 6| Step: 8
Training loss: 2.8756543948904114
Validation loss: 2.626903303913393

Epoch: 6| Step: 9
Training loss: 3.0629658247448153
Validation loss: 2.6272513622889813

Epoch: 6| Step: 10
Training loss: 3.056686800769429
Validation loss: 2.6247964610165337

Epoch: 6| Step: 11
Training loss: 3.3587410262072797
Validation loss: 2.622830757887696

Epoch: 6| Step: 12
Training loss: 2.7238463943461784
Validation loss: 2.626919261090291

Epoch: 6| Step: 13
Training loss: 3.020958645731714
Validation loss: 2.6229303133867066

Epoch: 90| Step: 0
Training loss: 2.9783452820142404
Validation loss: 2.624727692081895

Epoch: 6| Step: 1
Training loss: 3.330448109945133
Validation loss: 2.623300329274574

Epoch: 6| Step: 2
Training loss: 3.1185406876466777
Validation loss: 2.624517781293792

Epoch: 6| Step: 3
Training loss: 2.5807774626174096
Validation loss: 2.6244878449972244

Epoch: 6| Step: 4
Training loss: 2.8953449377146083
Validation loss: 2.627670775232844

Epoch: 6| Step: 5
Training loss: 2.2980597937086418
Validation loss: 2.625555663277903

Epoch: 6| Step: 6
Training loss: 3.164031304099685
Validation loss: 2.625771138729239

Epoch: 6| Step: 7
Training loss: 2.4546039763772827
Validation loss: 2.6244537568423

Epoch: 6| Step: 8
Training loss: 3.2605380359683864
Validation loss: 2.6285669797522946

Epoch: 6| Step: 9
Training loss: 3.198033300668944
Validation loss: 2.633666302616916

Epoch: 6| Step: 10
Training loss: 3.075516113139812
Validation loss: 2.6323100235210957

Epoch: 6| Step: 11
Training loss: 3.0731967259606208
Validation loss: 2.628374006693642

Epoch: 6| Step: 12
Training loss: 2.8832502988939024
Validation loss: 2.6286996547147194

Epoch: 6| Step: 13
Training loss: 3.1593383183222308
Validation loss: 2.6337919942766583

Epoch: 91| Step: 0
Training loss: 2.371937634592238
Validation loss: 2.6266013806602304

Epoch: 6| Step: 1
Training loss: 3.2818722089567793
Validation loss: 2.647011287245152

Epoch: 6| Step: 2
Training loss: 2.9062468826113155
Validation loss: 2.6438201759225297

Epoch: 6| Step: 3
Training loss: 3.159350241725367
Validation loss: 2.635182283474999

Epoch: 6| Step: 4
Training loss: 2.668580639935008
Validation loss: 2.6242477688875283

Epoch: 6| Step: 5
Training loss: 2.836964991205941
Validation loss: 2.6205111639943084

Epoch: 6| Step: 6
Training loss: 2.551551971133503
Validation loss: 2.619824799091435

Epoch: 6| Step: 7
Training loss: 2.8573731465855357
Validation loss: 2.621501075177444

Epoch: 6| Step: 8
Training loss: 3.0091153580474628
Validation loss: 2.6215547785493203

Epoch: 6| Step: 9
Training loss: 3.2921547024925855
Validation loss: 2.621309364842109

Epoch: 6| Step: 10
Training loss: 3.3684580943618223
Validation loss: 2.6206063995668134

Epoch: 6| Step: 11
Training loss: 3.203222803623076
Validation loss: 2.621144939298272

Epoch: 6| Step: 12
Training loss: 2.680069787696777
Validation loss: 2.6192361531413844

Epoch: 6| Step: 13
Training loss: 3.3599251230161946
Validation loss: 2.621894843723217

Epoch: 92| Step: 0
Training loss: 3.444388129344788
Validation loss: 2.6254756562950425

Epoch: 6| Step: 1
Training loss: 2.90138904585127
Validation loss: 2.620352010633098

Epoch: 6| Step: 2
Training loss: 2.576747641958629
Validation loss: 2.6218528985109804

Epoch: 6| Step: 3
Training loss: 3.257076482168228
Validation loss: 2.6228460414700936

Epoch: 6| Step: 4
Training loss: 2.367925245690253
Validation loss: 2.618461659934156

Epoch: 6| Step: 5
Training loss: 2.488882138984852
Validation loss: 2.622152402223014

Epoch: 6| Step: 6
Training loss: 3.3704979150072707
Validation loss: 2.624653107223203

Epoch: 6| Step: 7
Training loss: 3.0804094077152513
Validation loss: 2.6223566689622606

Epoch: 6| Step: 8
Training loss: 2.909290159240198
Validation loss: 2.6251627631835994

Epoch: 6| Step: 9
Training loss: 2.3923112494654304
Validation loss: 2.6185036976527396

Epoch: 6| Step: 10
Training loss: 3.728398220797596
Validation loss: 2.625404315053387

Epoch: 6| Step: 11
Training loss: 2.5261223744087067
Validation loss: 2.62270311379598

Epoch: 6| Step: 12
Training loss: 3.1041043337168306
Validation loss: 2.6272524824934904

Epoch: 6| Step: 13
Training loss: 2.9419959542293985
Validation loss: 2.629962395900967

Epoch: 93| Step: 0
Training loss: 2.7073933853193726
Validation loss: 2.6376464320213184

Epoch: 6| Step: 1
Training loss: 2.958245737274382
Validation loss: 2.6411562168851814

Epoch: 6| Step: 2
Training loss: 3.4944334723039727
Validation loss: 2.6544465671696913

Epoch: 6| Step: 3
Training loss: 2.6739377987802193
Validation loss: 2.6733508934069468

Epoch: 6| Step: 4
Training loss: 2.783568540978767
Validation loss: 2.6867088990752395

Epoch: 6| Step: 5
Training loss: 2.4185995286766153
Validation loss: 2.690221852877516

Epoch: 6| Step: 6
Training loss: 2.9474442353930894
Validation loss: 2.6633834880512293

Epoch: 6| Step: 7
Training loss: 2.9861619003668634
Validation loss: 2.6620621562254345

Epoch: 6| Step: 8
Training loss: 3.6615296416124026
Validation loss: 2.6357326409751067

Epoch: 6| Step: 9
Training loss: 3.2142489173841646
Validation loss: 2.623356462360442

Epoch: 6| Step: 10
Training loss: 3.3299453843137137
Validation loss: 2.622722209781669

Epoch: 6| Step: 11
Training loss: 2.591778844958952
Validation loss: 2.621272912571564

Epoch: 6| Step: 12
Training loss: 2.5814607252509543
Validation loss: 2.622080715379786

Epoch: 6| Step: 13
Training loss: 2.7687350098352677
Validation loss: 2.6212899182173937

Epoch: 94| Step: 0
Training loss: 3.2464195482751226
Validation loss: 2.618959239381588

Epoch: 6| Step: 1
Training loss: 2.309366526091312
Validation loss: 2.6197834186419633

Epoch: 6| Step: 2
Training loss: 1.953017392055187
Validation loss: 2.621455704769625

Epoch: 6| Step: 3
Training loss: 3.5577398253378396
Validation loss: 2.6291130840389676

Epoch: 6| Step: 4
Training loss: 3.0544561508260903
Validation loss: 2.6234023979541754

Epoch: 6| Step: 5
Training loss: 2.91969781226438
Validation loss: 2.6311285228074257

Epoch: 6| Step: 6
Training loss: 2.5527073830284426
Validation loss: 2.6278525887647732

Epoch: 6| Step: 7
Training loss: 3.1525431100800327
Validation loss: 2.62152893034508

Epoch: 6| Step: 8
Training loss: 3.119648127154064
Validation loss: 2.619534339287751

Epoch: 6| Step: 9
Training loss: 3.1888762850037895
Validation loss: 2.623327743166359

Epoch: 6| Step: 10
Training loss: 2.496825491518223
Validation loss: 2.6255110044536427

Epoch: 6| Step: 11
Training loss: 3.1427823528457073
Validation loss: 2.6323624808678483

Epoch: 6| Step: 12
Training loss: 3.3356930645407403
Validation loss: 2.6459449826545924

Epoch: 6| Step: 13
Training loss: 3.219862069913489
Validation loss: 2.65913147189485

Epoch: 95| Step: 0
Training loss: 2.6702622571295476
Validation loss: 2.6717428690333014

Epoch: 6| Step: 1
Training loss: 2.887439684217261
Validation loss: 2.7010075711201456

Epoch: 6| Step: 2
Training loss: 2.675677889198931
Validation loss: 2.7058610007694335

Epoch: 6| Step: 3
Training loss: 2.870464894459981
Validation loss: 2.6767395195848827

Epoch: 6| Step: 4
Training loss: 3.1267477107440356
Validation loss: 2.6601790736370368

Epoch: 6| Step: 5
Training loss: 3.3441934737129104
Validation loss: 2.6240405386504007

Epoch: 6| Step: 6
Training loss: 3.004576371429578
Validation loss: 2.620608412830004

Epoch: 6| Step: 7
Training loss: 3.1236621281666146
Validation loss: 2.6162211049842665

Epoch: 6| Step: 8
Training loss: 2.8709160366981314
Validation loss: 2.6168757211781317

Epoch: 6| Step: 9
Training loss: 2.886624759284713
Validation loss: 2.6153427712146238

Epoch: 6| Step: 10
Training loss: 2.980161238539021
Validation loss: 2.6152598928221353

Epoch: 6| Step: 11
Training loss: 3.1625855566220027
Validation loss: 2.616829147869601

Epoch: 6| Step: 12
Training loss: 2.861828028003296
Validation loss: 2.620044674913998

Epoch: 6| Step: 13
Training loss: 3.1584401604964
Validation loss: 2.6183962282927684

Epoch: 96| Step: 0
Training loss: 2.509449077192145
Validation loss: 2.616104469533244

Epoch: 6| Step: 1
Training loss: 2.669633248389786
Validation loss: 2.618300834978831

Epoch: 6| Step: 2
Training loss: 3.34263663606832
Validation loss: 2.6215465416132955

Epoch: 6| Step: 3
Training loss: 2.6418166321587195
Validation loss: 2.617251892228267

Epoch: 6| Step: 4
Training loss: 3.263743173218815
Validation loss: 2.616896133231911

Epoch: 6| Step: 5
Training loss: 3.40566003572445
Validation loss: 2.6161588481214415

Epoch: 6| Step: 6
Training loss: 3.1800461925294568
Validation loss: 2.617830763427884

Epoch: 6| Step: 7
Training loss: 2.6520257908126568
Validation loss: 2.6145044274102536

Epoch: 6| Step: 8
Training loss: 2.7423475604606544
Validation loss: 2.617769018838859

Epoch: 6| Step: 9
Training loss: 3.5563057035297185
Validation loss: 2.6178823602570502

Epoch: 6| Step: 10
Training loss: 2.8098675594138833
Validation loss: 2.618548831373527

Epoch: 6| Step: 11
Training loss: 1.996323842860757
Validation loss: 2.616102834003162

Epoch: 6| Step: 12
Training loss: 3.1606303119973096
Validation loss: 2.6144745343282634

Epoch: 6| Step: 13
Training loss: 3.3505090867571
Validation loss: 2.6174523200159894

Epoch: 97| Step: 0
Training loss: 3.596684725424112
Validation loss: 2.6169817002864244

Epoch: 6| Step: 1
Training loss: 2.9156380247293314
Validation loss: 2.6203022743871034

Epoch: 6| Step: 2
Training loss: 2.8394244486596216
Validation loss: 2.622387636513653

Epoch: 6| Step: 3
Training loss: 3.4382969712667446
Validation loss: 2.6215804719906823

Epoch: 6| Step: 4
Training loss: 2.8110490235050736
Validation loss: 2.6168111404117225

Epoch: 6| Step: 5
Training loss: 2.984322272828554
Validation loss: 2.6212691863369866

Epoch: 6| Step: 6
Training loss: 2.472753055840979
Validation loss: 2.6240339068875267

Epoch: 6| Step: 7
Training loss: 2.7461746659709223
Validation loss: 2.620377327463808

Epoch: 6| Step: 8
Training loss: 2.438771136498766
Validation loss: 2.6212176542190457

Epoch: 6| Step: 9
Training loss: 2.932376207631534
Validation loss: 2.626871724012509

Epoch: 6| Step: 10
Training loss: 3.2244304420184102
Validation loss: 2.6140644029322875

Epoch: 6| Step: 11
Training loss: 2.6416769246123835
Validation loss: 2.616525084322404

Epoch: 6| Step: 12
Training loss: 2.877938965988606
Validation loss: 2.6152623361247365

Epoch: 6| Step: 13
Training loss: 3.477959033060127
Validation loss: 2.612630749328529

Epoch: 98| Step: 0
Training loss: 3.1370598594492227
Validation loss: 2.6109784859582947

Epoch: 6| Step: 1
Training loss: 3.1868889914918275
Validation loss: 2.6199574710500633

Epoch: 6| Step: 2
Training loss: 2.8232320536613353
Validation loss: 2.611063105062543

Epoch: 6| Step: 3
Training loss: 3.169858244364829
Validation loss: 2.616070610226211

Epoch: 6| Step: 4
Training loss: 3.062696178147397
Validation loss: 2.611374116085575

Epoch: 6| Step: 5
Training loss: 3.1909173336480814
Validation loss: 2.6123417192804683

Epoch: 6| Step: 6
Training loss: 2.564184612037397
Validation loss: 2.609612409709117

Epoch: 6| Step: 7
Training loss: 3.0815240517587044
Validation loss: 2.6118654928478584

Epoch: 6| Step: 8
Training loss: 2.8891990649975328
Validation loss: 2.6111315402288713

Epoch: 6| Step: 9
Training loss: 3.406142066855411
Validation loss: 2.6094510030088944

Epoch: 6| Step: 10
Training loss: 2.1711622207458254
Validation loss: 2.611506650938686

Epoch: 6| Step: 11
Training loss: 2.845793608075896
Validation loss: 2.6113406814016957

Epoch: 6| Step: 12
Training loss: 2.9981111302153383
Validation loss: 2.6091970847658486

Epoch: 6| Step: 13
Training loss: 2.400966541055562
Validation loss: 2.6149296309180134

Epoch: 99| Step: 0
Training loss: 2.563573193863243
Validation loss: 2.6124581046831534

Epoch: 6| Step: 1
Training loss: 2.6030253745039214
Validation loss: 2.6094662603264798

Epoch: 6| Step: 2
Training loss: 2.8699322693173004
Validation loss: 2.6117378497746713

Epoch: 6| Step: 3
Training loss: 3.0156790772960593
Validation loss: 2.6119628525575362

Epoch: 6| Step: 4
Training loss: 2.5010192700619465
Validation loss: 2.612757046726401

Epoch: 6| Step: 5
Training loss: 3.016597294580584
Validation loss: 2.6169491415221855

Epoch: 6| Step: 6
Training loss: 3.38137427364298
Validation loss: 2.62890525239696

Epoch: 6| Step: 7
Training loss: 2.6025500556756564
Validation loss: 2.630200748601208

Epoch: 6| Step: 8
Training loss: 2.8664020845014364
Validation loss: 2.626008496805936

Epoch: 6| Step: 9
Training loss: 3.0978648246595255
Validation loss: 2.625484910077087

Epoch: 6| Step: 10
Training loss: 3.872838802009779
Validation loss: 2.6263317298638387

Epoch: 6| Step: 11
Training loss: 3.012465487080649
Validation loss: 2.6215508884265204

Epoch: 6| Step: 12
Training loss: 2.7066100482311883
Validation loss: 2.6262045253583346

Epoch: 6| Step: 13
Training loss: 2.9957276758512825
Validation loss: 2.6233821147026326

Epoch: 100| Step: 0
Training loss: 3.0084186686267897
Validation loss: 2.6220383781388428

Epoch: 6| Step: 1
Training loss: 2.8036389954523906
Validation loss: 2.6249680417054546

Epoch: 6| Step: 2
Training loss: 2.7597996627965538
Validation loss: 2.626268075668952

Epoch: 6| Step: 3
Training loss: 2.9697140383244625
Validation loss: 2.6249946729935107

Epoch: 6| Step: 4
Training loss: 2.79247692552833
Validation loss: 2.6209023023376146

Epoch: 6| Step: 5
Training loss: 2.5947861038285183
Validation loss: 2.616911239381521

Epoch: 6| Step: 6
Training loss: 2.9369261160763824
Validation loss: 2.6144753609374676

Epoch: 6| Step: 7
Training loss: 3.316741243479251
Validation loss: 2.608254926988445

Epoch: 6| Step: 8
Training loss: 3.0253171770256495
Validation loss: 2.610333144028408

Epoch: 6| Step: 9
Training loss: 3.087714270442386
Validation loss: 2.605523076537803

Epoch: 6| Step: 10
Training loss: 2.616472562244028
Validation loss: 2.603527248186057

Epoch: 6| Step: 11
Training loss: 3.2566002069861275
Validation loss: 2.6056314640101106

Epoch: 6| Step: 12
Training loss: 3.279213264131022
Validation loss: 2.6032230145774813

Epoch: 6| Step: 13
Training loss: 2.7655834475052
Validation loss: 2.6042307728085925

Epoch: 101| Step: 0
Training loss: 2.5951857671965923
Validation loss: 2.606686366331771

Epoch: 6| Step: 1
Training loss: 2.9735418897737524
Validation loss: 2.6065222507209422

Epoch: 6| Step: 2
Training loss: 3.122087571063887
Validation loss: 2.6082428697880395

Epoch: 6| Step: 3
Training loss: 2.6905337221832175
Validation loss: 2.606117411438926

Epoch: 6| Step: 4
Training loss: 2.7925287500334144
Validation loss: 2.606053386464599

Epoch: 6| Step: 5
Training loss: 3.3704583021096353
Validation loss: 2.607355906741333

Epoch: 6| Step: 6
Training loss: 2.863037598613867
Validation loss: 2.602133014853311

Epoch: 6| Step: 7
Training loss: 2.5623665751635025
Validation loss: 2.6066244944669674

Epoch: 6| Step: 8
Training loss: 2.4995334189848455
Validation loss: 2.6023686091426272

Epoch: 6| Step: 9
Training loss: 2.9623028267058342
Validation loss: 2.6038188526496846

Epoch: 6| Step: 10
Training loss: 3.046668255956501
Validation loss: 2.6035989437029596

Epoch: 6| Step: 11
Training loss: 3.1623035957957013
Validation loss: 2.6044789927244754

Epoch: 6| Step: 12
Training loss: 3.426802201417047
Validation loss: 2.608131191337855

Epoch: 6| Step: 13
Training loss: 3.2527279775535294
Validation loss: 2.6070813419253063

Epoch: 102| Step: 0
Training loss: 2.5503564921996076
Validation loss: 2.606377110352585

Epoch: 6| Step: 1
Training loss: 2.514262428655797
Validation loss: 2.6134283543497263

Epoch: 6| Step: 2
Training loss: 3.05141857489494
Validation loss: 2.611938724240103

Epoch: 6| Step: 3
Training loss: 2.4220013985413247
Validation loss: 2.610822099871287

Epoch: 6| Step: 4
Training loss: 3.2478181410929254
Validation loss: 2.6093446345285165

Epoch: 6| Step: 5
Training loss: 2.9025285746689935
Validation loss: 2.6159378107190823

Epoch: 6| Step: 6
Training loss: 2.6089288935535695
Validation loss: 2.6145207416759204

Epoch: 6| Step: 7
Training loss: 3.69515326320165
Validation loss: 2.6140134113686817

Epoch: 6| Step: 8
Training loss: 2.8792123204838127
Validation loss: 2.6073499326055023

Epoch: 6| Step: 9
Training loss: 3.3030706107029486
Validation loss: 2.6124495407454362

Epoch: 6| Step: 10
Training loss: 2.980236759381337
Validation loss: 2.6161987611604656

Epoch: 6| Step: 11
Training loss: 3.12505874578572
Validation loss: 2.6111678984427686

Epoch: 6| Step: 12
Training loss: 2.4886679356378725
Validation loss: 2.6103152871990702

Epoch: 6| Step: 13
Training loss: 3.4436929576878095
Validation loss: 2.6163516893626815

Epoch: 103| Step: 0
Training loss: 3.144854378535646
Validation loss: 2.6148761326626206

Epoch: 6| Step: 1
Training loss: 2.4687363829418265
Validation loss: 2.621016280968753

Epoch: 6| Step: 2
Training loss: 2.592920469436256
Validation loss: 2.6210038951402836

Epoch: 6| Step: 3
Training loss: 2.717091372315752
Validation loss: 2.6126402801801736

Epoch: 6| Step: 4
Training loss: 2.6470911435416795
Validation loss: 2.6134092748167856

Epoch: 6| Step: 5
Training loss: 2.649421441601869
Validation loss: 2.615694707396716

Epoch: 6| Step: 6
Training loss: 2.835323719198809
Validation loss: 2.6198101315010422

Epoch: 6| Step: 7
Training loss: 3.269115571974292
Validation loss: 2.615713277272842

Epoch: 6| Step: 8
Training loss: 2.976166466025732
Validation loss: 2.618745267566506

Epoch: 6| Step: 9
Training loss: 3.4664579499821055
Validation loss: 2.6191079110129754

Epoch: 6| Step: 10
Training loss: 3.6020613384880704
Validation loss: 2.614790336893549

Epoch: 6| Step: 11
Training loss: 2.8123123106319
Validation loss: 2.6140285773290444

Epoch: 6| Step: 12
Training loss: 3.120366590677654
Validation loss: 2.612603835499414

Epoch: 6| Step: 13
Training loss: 2.580566544835025
Validation loss: 2.6151353646887934

Epoch: 104| Step: 0
Training loss: 3.1720967332730727
Validation loss: 2.614565009223811

Epoch: 6| Step: 1
Training loss: 2.4598497681373592
Validation loss: 2.614622086304484

Epoch: 6| Step: 2
Training loss: 2.9295634739372263
Validation loss: 2.6158026866317616

Epoch: 6| Step: 3
Training loss: 2.950894275184292
Validation loss: 2.607412017328004

Epoch: 6| Step: 4
Training loss: 3.041105314388689
Validation loss: 2.6108394784750537

Epoch: 6| Step: 5
Training loss: 2.0201328938270184
Validation loss: 2.607530747391635

Epoch: 6| Step: 6
Training loss: 3.3379387670698093
Validation loss: 2.6020671159606104

Epoch: 6| Step: 7
Training loss: 3.3376999070093896
Validation loss: 2.6031510693950546

Epoch: 6| Step: 8
Training loss: 1.9971917225090685
Validation loss: 2.602260880299057

Epoch: 6| Step: 9
Training loss: 3.1126091014936605
Validation loss: 2.6054212308770457

Epoch: 6| Step: 10
Training loss: 3.100069931225941
Validation loss: 2.604852149247018

Epoch: 6| Step: 11
Training loss: 3.529843210515208
Validation loss: 2.6090091583706627

Epoch: 6| Step: 12
Training loss: 2.6252394975670663
Validation loss: 2.6111004362351387

Epoch: 6| Step: 13
Training loss: 3.283610920540105
Validation loss: 2.613695163836295

Epoch: 105| Step: 0
Training loss: 3.004297198785495
Validation loss: 2.6114149033266782

Epoch: 6| Step: 1
Training loss: 2.351404533276605
Validation loss: 2.612299213405605

Epoch: 6| Step: 2
Training loss: 2.8543881147102987
Validation loss: 2.6137327251839486

Epoch: 6| Step: 3
Training loss: 2.9066376786434303
Validation loss: 2.61326007885638

Epoch: 6| Step: 4
Training loss: 3.0779810837925985
Validation loss: 2.6162669414647106

Epoch: 6| Step: 5
Training loss: 3.165494166360245
Validation loss: 2.6252896353713964

Epoch: 6| Step: 6
Training loss: 3.2161472500734902
Validation loss: 2.614521175074305

Epoch: 6| Step: 7
Training loss: 3.64056448824778
Validation loss: 2.6062930817514505

Epoch: 6| Step: 8
Training loss: 2.5789299835250117
Validation loss: 2.6091930101690775

Epoch: 6| Step: 9
Training loss: 2.8288185575894924
Validation loss: 2.6175686162802307

Epoch: 6| Step: 10
Training loss: 2.6367947037671424
Validation loss: 2.616249609202071

Epoch: 6| Step: 11
Training loss: 2.516479157626592
Validation loss: 2.622084132482139

Epoch: 6| Step: 12
Training loss: 3.052613005174877
Validation loss: 2.629448214290943

Epoch: 6| Step: 13
Training loss: 3.2852299848666298
Validation loss: 2.62517674168995

Epoch: 106| Step: 0
Training loss: 2.8728543443307797
Validation loss: 2.641647294374814

Epoch: 6| Step: 1
Training loss: 2.554078382384107
Validation loss: 2.657405806901165

Epoch: 6| Step: 2
Training loss: 2.943943828834712
Validation loss: 2.645437165562493

Epoch: 6| Step: 3
Training loss: 2.6839788568690093
Validation loss: 2.632654341535351

Epoch: 6| Step: 4
Training loss: 2.4852160103935934
Validation loss: 2.618475991428675

Epoch: 6| Step: 5
Training loss: 2.507452537870915
Validation loss: 2.6212915984333702

Epoch: 6| Step: 6
Training loss: 3.223294503557663
Validation loss: 2.6167301763468283

Epoch: 6| Step: 7
Training loss: 3.016769745331933
Validation loss: 2.6169181987611836

Epoch: 6| Step: 8
Training loss: 3.490147210107014
Validation loss: 2.606280994818712

Epoch: 6| Step: 9
Training loss: 2.9272693470849758
Validation loss: 2.6016010770703195

Epoch: 6| Step: 10
Training loss: 3.717071410808094
Validation loss: 2.6011503879169977

Epoch: 6| Step: 11
Training loss: 3.0575003782881893
Validation loss: 2.596862922501078

Epoch: 6| Step: 12
Training loss: 2.6213171418868053
Validation loss: 2.598082703145433

Epoch: 6| Step: 13
Training loss: 2.727051699236081
Validation loss: 2.597459446726292

Epoch: 107| Step: 0
Training loss: 3.3743354708282847
Validation loss: 2.5959203964605355

Epoch: 6| Step: 1
Training loss: 2.4054275692533484
Validation loss: 2.5981921671781407

Epoch: 6| Step: 2
Training loss: 3.214533442078981
Validation loss: 2.5934236550740044

Epoch: 6| Step: 3
Training loss: 3.219814235707299
Validation loss: 2.599957441876163

Epoch: 6| Step: 4
Training loss: 3.0522094978234238
Validation loss: 2.6001380440845456

Epoch: 6| Step: 5
Training loss: 2.9396163134726563
Validation loss: 2.6006873381826225

Epoch: 6| Step: 6
Training loss: 2.7990637371933147
Validation loss: 2.600577568099972

Epoch: 6| Step: 7
Training loss: 3.223927897780577
Validation loss: 2.603989394194163

Epoch: 6| Step: 8
Training loss: 2.7401774720682193
Validation loss: 2.6119062169597442

Epoch: 6| Step: 9
Training loss: 2.8920517158474586
Validation loss: 2.6278207432081797

Epoch: 6| Step: 10
Training loss: 2.9077233302379306
Validation loss: 2.621671408165051

Epoch: 6| Step: 11
Training loss: 2.7505067878532596
Validation loss: 2.628623578711509

Epoch: 6| Step: 12
Training loss: 2.535325149058833
Validation loss: 2.648171906217633

Epoch: 6| Step: 13
Training loss: 3.1727239665883418
Validation loss: 2.678122232238294

Epoch: 108| Step: 0
Training loss: 2.460814070255349
Validation loss: 2.6365259836725414

Epoch: 6| Step: 1
Training loss: 3.1227115644337755
Validation loss: 2.606493564392173

Epoch: 6| Step: 2
Training loss: 2.6847140931792866
Validation loss: 2.605446690820549

Epoch: 6| Step: 3
Training loss: 2.8561351327315276
Validation loss: 2.5993530406419394

Epoch: 6| Step: 4
Training loss: 2.829181115661789
Validation loss: 2.596012726239025

Epoch: 6| Step: 5
Training loss: 3.612571192901158
Validation loss: 2.5959352454483557

Epoch: 6| Step: 6
Training loss: 2.7362355904790077
Validation loss: 2.5958797459836513

Epoch: 6| Step: 7
Training loss: 2.283540803528458
Validation loss: 2.5969124215635473

Epoch: 6| Step: 8
Training loss: 3.6397905826062975
Validation loss: 2.5934474890724384

Epoch: 6| Step: 9
Training loss: 3.0808168056444716
Validation loss: 2.60067043144308

Epoch: 6| Step: 10
Training loss: 3.4468868749972517
Validation loss: 2.6009176457056955

Epoch: 6| Step: 11
Training loss: 2.21758099774673
Validation loss: 2.597671911152475

Epoch: 6| Step: 12
Training loss: 2.563292590124641
Validation loss: 2.598560638614854

Epoch: 6| Step: 13
Training loss: 3.489807000275219
Validation loss: 2.5966866517385543

Epoch: 109| Step: 0
Training loss: 2.7233530299557276
Validation loss: 2.5959648147879104

Epoch: 6| Step: 1
Training loss: 3.268363716831107
Validation loss: 2.5945198951551744

Epoch: 6| Step: 2
Training loss: 2.641426280864414
Validation loss: 2.598680893768268

Epoch: 6| Step: 3
Training loss: 2.7464592420469485
Validation loss: 2.5943689795044147

Epoch: 6| Step: 4
Training loss: 2.92347632606124
Validation loss: 2.594786597826923

Epoch: 6| Step: 5
Training loss: 2.6369748139551112
Validation loss: 2.600412157006574

Epoch: 6| Step: 6
Training loss: 2.946025246102176
Validation loss: 2.598894688669971

Epoch: 6| Step: 7
Training loss: 3.075935010722032
Validation loss: 2.596419875673131

Epoch: 6| Step: 8
Training loss: 3.3258441398468617
Validation loss: 2.6038078599079713

Epoch: 6| Step: 9
Training loss: 3.1711154272556077
Validation loss: 2.5992473172258794

Epoch: 6| Step: 10
Training loss: 2.5321227088048217
Validation loss: 2.5988874087696074

Epoch: 6| Step: 11
Training loss: 3.2516837526853726
Validation loss: 2.597267077192474

Epoch: 6| Step: 12
Training loss: 2.8469053097230503
Validation loss: 2.6065882420450537

Epoch: 6| Step: 13
Training loss: 2.945958721796241
Validation loss: 2.6057085157922426

Epoch: 110| Step: 0
Training loss: 3.046902856943969
Validation loss: 2.6042524012737407

Epoch: 6| Step: 1
Training loss: 2.4550348124784214
Validation loss: 2.5978444489777073

Epoch: 6| Step: 2
Training loss: 2.76732561659589
Validation loss: 2.5998748949162227

Epoch: 6| Step: 3
Training loss: 3.226948491023788
Validation loss: 2.609803305417497

Epoch: 6| Step: 4
Training loss: 3.0219656740330754
Validation loss: 2.6086049851288173

Epoch: 6| Step: 5
Training loss: 2.4528184444079892
Validation loss: 2.5996339638916672

Epoch: 6| Step: 6
Training loss: 2.9230592337161894
Validation loss: 2.6047850706832807

Epoch: 6| Step: 7
Training loss: 2.842312963232063
Validation loss: 2.5995397706278287

Epoch: 6| Step: 8
Training loss: 3.108464860221432
Validation loss: 2.599586016619513

Epoch: 6| Step: 9
Training loss: 3.1373459128427417
Validation loss: 2.6010639905785733

Epoch: 6| Step: 10
Training loss: 2.8085968060005975
Validation loss: 2.593794537530171

Epoch: 6| Step: 11
Training loss: 3.0479715574844812
Validation loss: 2.5971986142840486

Epoch: 6| Step: 12
Training loss: 3.3511541513511673
Validation loss: 2.5928440936016943

Epoch: 6| Step: 13
Training loss: 2.7792905269933654
Validation loss: 2.59347497238306

Epoch: 111| Step: 0
Training loss: 3.188504827353664
Validation loss: 2.59757299728519

Epoch: 6| Step: 1
Training loss: 3.2399092793420463
Validation loss: 2.5956339057644797

Epoch: 6| Step: 2
Training loss: 2.935751049380378
Validation loss: 2.595475000912443

Epoch: 6| Step: 3
Training loss: 3.079853637487458
Validation loss: 2.5989750029652208

Epoch: 6| Step: 4
Training loss: 2.8022195057356223
Validation loss: 2.5994280368221205

Epoch: 6| Step: 5
Training loss: 2.752936962344059
Validation loss: 2.6040965583142026

Epoch: 6| Step: 6
Training loss: 3.0657947489398167
Validation loss: 2.607266921574508

Epoch: 6| Step: 7
Training loss: 3.6827825338692564
Validation loss: 2.60571914928071

Epoch: 6| Step: 8
Training loss: 2.5768947555965296
Validation loss: 2.6109955635619557

Epoch: 6| Step: 9
Training loss: 2.579573068558814
Validation loss: 2.603481922981291

Epoch: 6| Step: 10
Training loss: 2.842192338516789
Validation loss: 2.6109745889145883

Epoch: 6| Step: 11
Training loss: 2.3764346959286873
Validation loss: 2.605179423300278

Epoch: 6| Step: 12
Training loss: 3.1298247666711885
Validation loss: 2.6029701916736707

Epoch: 6| Step: 13
Training loss: 2.363971199647676
Validation loss: 2.607853121012799

Epoch: 112| Step: 0
Training loss: 3.4783411169642857
Validation loss: 2.6114239595451387

Epoch: 6| Step: 1
Training loss: 2.418890116573535
Validation loss: 2.6059304139664983

Epoch: 6| Step: 2
Training loss: 2.961032191551503
Validation loss: 2.6020545079119968

Epoch: 6| Step: 3
Training loss: 2.4737857691495293
Validation loss: 2.5894118392012535

Epoch: 6| Step: 4
Training loss: 3.200224814862484
Validation loss: 2.5936778266433924

Epoch: 6| Step: 5
Training loss: 3.3470773274219687
Validation loss: 2.591895883684457

Epoch: 6| Step: 6
Training loss: 2.3846896422682358
Validation loss: 2.58870468539127

Epoch: 6| Step: 7
Training loss: 3.1511393045898735
Validation loss: 2.587717203562382

Epoch: 6| Step: 8
Training loss: 2.6721355467354106
Validation loss: 2.588936445061225

Epoch: 6| Step: 9
Training loss: 3.1192824893380555
Validation loss: 2.5979843881057727

Epoch: 6| Step: 10
Training loss: 2.7933269137700982
Validation loss: 2.6029102308489023

Epoch: 6| Step: 11
Training loss: 2.8995941404271077
Validation loss: 2.603967984075435

Epoch: 6| Step: 12
Training loss: 2.851721019780547
Validation loss: 2.609683023474856

Epoch: 6| Step: 13
Training loss: 3.3084202240135863
Validation loss: 2.601324440370638

Epoch: 113| Step: 0
Training loss: 3.390222903549912
Validation loss: 2.5973194753671507

Epoch: 6| Step: 1
Training loss: 2.862368824714294
Validation loss: 2.5923543576032704

Epoch: 6| Step: 2
Training loss: 2.5131104026736693
Validation loss: 2.5925913719982367

Epoch: 6| Step: 3
Training loss: 2.761590806298628
Validation loss: 2.588300409020123

Epoch: 6| Step: 4
Training loss: 2.9899401479490977
Validation loss: 2.5881606436198488

Epoch: 6| Step: 5
Training loss: 2.670591882830222
Validation loss: 2.5919365076245198

Epoch: 6| Step: 6
Training loss: 3.0193919634554724
Validation loss: 2.5898065519336497

Epoch: 6| Step: 7
Training loss: 2.799791062597647
Validation loss: 2.5876396854063097

Epoch: 6| Step: 8
Training loss: 3.033756124634095
Validation loss: 2.591528397605444

Epoch: 6| Step: 9
Training loss: 3.4248850225376235
Validation loss: 2.5942500136937157

Epoch: 6| Step: 10
Training loss: 3.1941424701615833
Validation loss: 2.594453723345988

Epoch: 6| Step: 11
Training loss: 2.393804492778388
Validation loss: 2.5892083447690006

Epoch: 6| Step: 12
Training loss: 2.7087932978586022
Validation loss: 2.5921925705727222

Epoch: 6| Step: 13
Training loss: 3.2786958471982515
Validation loss: 2.5971941665015295

Epoch: 114| Step: 0
Training loss: 3.1973422815528014
Validation loss: 2.595708157060967

Epoch: 6| Step: 1
Training loss: 2.7125954958370855
Validation loss: 2.601109550107662

Epoch: 6| Step: 2
Training loss: 3.022697575045838
Validation loss: 2.607017874589137

Epoch: 6| Step: 3
Training loss: 2.8306425070226506
Validation loss: 2.6073862235981897

Epoch: 6| Step: 4
Training loss: 2.589888306201376
Validation loss: 2.6054864098035155

Epoch: 6| Step: 5
Training loss: 2.8250457692447455
Validation loss: 2.6045342853264986

Epoch: 6| Step: 6
Training loss: 2.71235606431322
Validation loss: 2.598958339580602

Epoch: 6| Step: 7
Training loss: 3.08345399225266
Validation loss: 2.5941001615203207

Epoch: 6| Step: 8
Training loss: 2.9432590925704343
Validation loss: 2.5934697600363825

Epoch: 6| Step: 9
Training loss: 2.288938134886864
Validation loss: 2.5917504049552407

Epoch: 6| Step: 10
Training loss: 3.2504228170162546
Validation loss: 2.592264755612819

Epoch: 6| Step: 11
Training loss: 3.168959908238729
Validation loss: 2.594500904824909

Epoch: 6| Step: 12
Training loss: 3.356665649817981
Validation loss: 2.5895172157295154

Epoch: 6| Step: 13
Training loss: 2.858069950643867
Validation loss: 2.5869016174493478

Epoch: 115| Step: 0
Training loss: 2.866200290120769
Validation loss: 2.5887284212223225

Epoch: 6| Step: 1
Training loss: 2.3234279280916232
Validation loss: 2.596051509711618

Epoch: 6| Step: 2
Training loss: 2.7824109686825595
Validation loss: 2.597389675183015

Epoch: 6| Step: 3
Training loss: 2.9648291143928125
Validation loss: 2.598881709126066

Epoch: 6| Step: 4
Training loss: 3.0529127502069193
Validation loss: 2.605988090880164

Epoch: 6| Step: 5
Training loss: 3.4372078511329
Validation loss: 2.6022868647221866

Epoch: 6| Step: 6
Training loss: 2.681421013915873
Validation loss: 2.6052421314699643

Epoch: 6| Step: 7
Training loss: 3.222793113807763
Validation loss: 2.610033040359129

Epoch: 6| Step: 8
Training loss: 2.5124385389715256
Validation loss: 2.602182347167144

Epoch: 6| Step: 9
Training loss: 3.383419977841941
Validation loss: 2.5996296632684968

Epoch: 6| Step: 10
Training loss: 2.1702257659476594
Validation loss: 2.5993178920333233

Epoch: 6| Step: 11
Training loss: 2.500648605132296
Validation loss: 2.5929907626403255

Epoch: 6| Step: 12
Training loss: 3.353968896820578
Validation loss: 2.5920027872148066

Epoch: 6| Step: 13
Training loss: 3.6927282479004324
Validation loss: 2.5845705384949573

Epoch: 116| Step: 0
Training loss: 3.395454026707673
Validation loss: 2.5837777930055945

Epoch: 6| Step: 1
Training loss: 2.899073446174394
Validation loss: 2.5834950225462747

Epoch: 6| Step: 2
Training loss: 2.8587115409208983
Validation loss: 2.5813179308504783

Epoch: 6| Step: 3
Training loss: 2.365409359495367
Validation loss: 2.5826984906296633

Epoch: 6| Step: 4
Training loss: 2.7207853218582243
Validation loss: 2.5817465028575817

Epoch: 6| Step: 5
Training loss: 2.432976854244819
Validation loss: 2.579685824328161

Epoch: 6| Step: 6
Training loss: 2.6128707586152835
Validation loss: 2.585030621035678

Epoch: 6| Step: 7
Training loss: 3.4086537410292808
Validation loss: 2.58377239440541

Epoch: 6| Step: 8
Training loss: 3.5776556115258797
Validation loss: 2.5829422405288014

Epoch: 6| Step: 9
Training loss: 2.979150483058553
Validation loss: 2.5831067074844203

Epoch: 6| Step: 10
Training loss: 2.663013598554545
Validation loss: 2.58165215446271

Epoch: 6| Step: 11
Training loss: 3.182567744706465
Validation loss: 2.586069694847603

Epoch: 6| Step: 12
Training loss: 2.9432448356633008
Validation loss: 2.58651324588905

Epoch: 6| Step: 13
Training loss: 2.5924275715347505
Validation loss: 2.592087186101059

Epoch: 117| Step: 0
Training loss: 2.8451452500418055
Validation loss: 2.5917545643450497

Epoch: 6| Step: 1
Training loss: 2.7869772074424053
Validation loss: 2.598531380973696

Epoch: 6| Step: 2
Training loss: 3.0394650857021124
Validation loss: 2.5987128724785906

Epoch: 6| Step: 3
Training loss: 2.1350031630695865
Validation loss: 2.598510909505421

Epoch: 6| Step: 4
Training loss: 2.918808904212731
Validation loss: 2.6022015474388214

Epoch: 6| Step: 5
Training loss: 3.4387232597972615
Validation loss: 2.598261494874946

Epoch: 6| Step: 6
Training loss: 2.9403910917842278
Validation loss: 2.5898316912250534

Epoch: 6| Step: 7
Training loss: 2.9432208579819257
Validation loss: 2.5831622590717886

Epoch: 6| Step: 8
Training loss: 2.580069715903452
Validation loss: 2.5867904318714525

Epoch: 6| Step: 9
Training loss: 3.0165152545115173
Validation loss: 2.582754222716955

Epoch: 6| Step: 10
Training loss: 2.743771261423931
Validation loss: 2.580860348223144

Epoch: 6| Step: 11
Training loss: 3.0607174726604103
Validation loss: 2.5819107476077456

Epoch: 6| Step: 12
Training loss: 3.2752645487624177
Validation loss: 2.584218693857054

Epoch: 6| Step: 13
Training loss: 3.2525375436760853
Validation loss: 2.5843137808409886

Epoch: 118| Step: 0
Training loss: 3.1000487046876453
Validation loss: 2.588332657616605

Epoch: 6| Step: 1
Training loss: 3.030674830660528
Validation loss: 2.5842942611728787

Epoch: 6| Step: 2
Training loss: 3.0767814686173995
Validation loss: 2.5817685728916295

Epoch: 6| Step: 3
Training loss: 2.24146750982369
Validation loss: 2.5853082882551366

Epoch: 6| Step: 4
Training loss: 3.3463187645055035
Validation loss: 2.591412392901693

Epoch: 6| Step: 5
Training loss: 2.3617364042974374
Validation loss: 2.594146887921501

Epoch: 6| Step: 6
Training loss: 2.7107169201732364
Validation loss: 2.601028298355838

Epoch: 6| Step: 7
Training loss: 2.5437913258637774
Validation loss: 2.600337905949659

Epoch: 6| Step: 8
Training loss: 3.3015161903697274
Validation loss: 2.6021759227437213

Epoch: 6| Step: 9
Training loss: 2.7340788762644985
Validation loss: 2.5979091588095127

Epoch: 6| Step: 10
Training loss: 3.258695853148937
Validation loss: 2.5920150861196642

Epoch: 6| Step: 11
Training loss: 3.0054011996486607
Validation loss: 2.5938110393799803

Epoch: 6| Step: 12
Training loss: 3.0736393655209104
Validation loss: 2.591422169968699

Epoch: 6| Step: 13
Training loss: 3.161166299637272
Validation loss: 2.590145313961209

Epoch: 119| Step: 0
Training loss: 2.6105859196728503
Validation loss: 2.5809965586927657

Epoch: 6| Step: 1
Training loss: 3.264088830617978
Validation loss: 2.577965981509917

Epoch: 6| Step: 2
Training loss: 3.1549791855888722
Validation loss: 2.57857885955483

Epoch: 6| Step: 3
Training loss: 2.879871387788885
Validation loss: 2.5777076231699123

Epoch: 6| Step: 4
Training loss: 2.8798422462915205
Validation loss: 2.5762038335851907

Epoch: 6| Step: 5
Training loss: 3.4653614435859907
Validation loss: 2.5771112501700304

Epoch: 6| Step: 6
Training loss: 2.608345056899499
Validation loss: 2.576967881489935

Epoch: 6| Step: 7
Training loss: 3.0758683506010938
Validation loss: 2.574525367496344

Epoch: 6| Step: 8
Training loss: 1.9236201604759582
Validation loss: 2.5760998858766855

Epoch: 6| Step: 9
Training loss: 3.0892467669576353
Validation loss: 2.5748070669768337

Epoch: 6| Step: 10
Training loss: 3.2640546463524474
Validation loss: 2.5768968428047336

Epoch: 6| Step: 11
Training loss: 2.5135743686168075
Validation loss: 2.588716640481576

Epoch: 6| Step: 12
Training loss: 2.4840870816359057
Validation loss: 2.639410551401401

Epoch: 6| Step: 13
Training loss: 3.7176925053165593
Validation loss: 2.6718733957301786

Epoch: 120| Step: 0
Training loss: 3.583932619474738
Validation loss: 2.652516071797091

Epoch: 6| Step: 1
Training loss: 3.004925657803091
Validation loss: 2.6002642591105456

Epoch: 6| Step: 2
Training loss: 2.4462105074088814
Validation loss: 2.5895832642061962

Epoch: 6| Step: 3
Training loss: 3.45219498620491
Validation loss: 2.589594111415475

Epoch: 6| Step: 4
Training loss: 2.48462853247663
Validation loss: 2.5753766328523287

Epoch: 6| Step: 5
Training loss: 2.84415877202441
Validation loss: 2.579686965187552

Epoch: 6| Step: 6
Training loss: 2.804454825693266
Validation loss: 2.5807239825506656

Epoch: 6| Step: 7
Training loss: 3.1131835309515075
Validation loss: 2.577674484789794

Epoch: 6| Step: 8
Training loss: 2.5936724180085804
Validation loss: 2.5751411281436507

Epoch: 6| Step: 9
Training loss: 3.0149897563500936
Validation loss: 2.5746258180344426

Epoch: 6| Step: 10
Training loss: 2.9259517197292446
Validation loss: 2.5776065368490935

Epoch: 6| Step: 11
Training loss: 2.8250245017280418
Validation loss: 2.5843135407768494

Epoch: 6| Step: 12
Training loss: 3.217058200099835
Validation loss: 2.593161686105954

Epoch: 6| Step: 13
Training loss: 2.18167657916462
Validation loss: 2.5984044000197115

Epoch: 121| Step: 0
Training loss: 2.93842512131984
Validation loss: 2.626015259280558

Epoch: 6| Step: 1
Training loss: 2.8332319989502253
Validation loss: 2.6352979821458655

Epoch: 6| Step: 2
Training loss: 2.5087051466660917
Validation loss: 2.6439781968445213

Epoch: 6| Step: 3
Training loss: 3.001554245468299
Validation loss: 2.651738862033337

Epoch: 6| Step: 4
Training loss: 2.916120605214276
Validation loss: 2.683626736351639

Epoch: 6| Step: 5
Training loss: 2.6185274707867574
Validation loss: 2.6838529107326066

Epoch: 6| Step: 6
Training loss: 2.7539363778272214
Validation loss: 2.667784964613009

Epoch: 6| Step: 7
Training loss: 2.861411114944091
Validation loss: 2.6611781384093702

Epoch: 6| Step: 8
Training loss: 2.33145354254223
Validation loss: 2.656827445242564

Epoch: 6| Step: 9
Training loss: 3.0919421529947515
Validation loss: 2.6490912526399617

Epoch: 6| Step: 10
Training loss: 3.4056576555002245
Validation loss: 2.6468681079951875

Epoch: 6| Step: 11
Training loss: 3.584082828177703
Validation loss: 2.6402061398640004

Epoch: 6| Step: 12
Training loss: 3.422523193280788
Validation loss: 2.6377610351581473

Epoch: 6| Step: 13
Training loss: 2.8854511869456556
Validation loss: 2.643456017356367

Epoch: 122| Step: 0
Training loss: 3.080322565552043
Validation loss: 2.629141057476756

Epoch: 6| Step: 1
Training loss: 3.135088391191077
Validation loss: 2.6249752365795933

Epoch: 6| Step: 2
Training loss: 3.1641384539494664
Validation loss: 2.621920612053883

Epoch: 6| Step: 3
Training loss: 2.4043240456552675
Validation loss: 2.623315863718125

Epoch: 6| Step: 4
Training loss: 2.750583586759185
Validation loss: 2.6328593066411554

Epoch: 6| Step: 5
Training loss: 3.1198969564783656
Validation loss: 2.622069132396275

Epoch: 6| Step: 6
Training loss: 2.8019249361971665
Validation loss: 2.6288132733304055

Epoch: 6| Step: 7
Training loss: 3.245060468207299
Validation loss: 2.630032524699441

Epoch: 6| Step: 8
Training loss: 2.768791498084188
Validation loss: 2.6235227915964727

Epoch: 6| Step: 9
Training loss: 2.9350910454686803
Validation loss: 2.6214966392899783

Epoch: 6| Step: 10
Training loss: 2.5283823606112654
Validation loss: 2.616949997718247

Epoch: 6| Step: 11
Training loss: 3.128178772668988
Validation loss: 2.61146056009162

Epoch: 6| Step: 12
Training loss: 3.0380725964529485
Validation loss: 2.6204965892712835

Epoch: 6| Step: 13
Training loss: 3.2290106622892614
Validation loss: 2.6145450609013583

Epoch: 123| Step: 0
Training loss: 3.5142285095326278
Validation loss: 2.612476445369728

Epoch: 6| Step: 1
Training loss: 3.0044887657520496
Validation loss: 2.614255783559125

Epoch: 6| Step: 2
Training loss: 3.0359446558374716
Validation loss: 2.6200783400090555

Epoch: 6| Step: 3
Training loss: 3.322375565402414
Validation loss: 2.619559233413401

Epoch: 6| Step: 4
Training loss: 1.8184394859752833
Validation loss: 2.619466346790638

Epoch: 6| Step: 5
Training loss: 2.1952078037479144
Validation loss: 2.6274034832509945

Epoch: 6| Step: 6
Training loss: 3.1596116397124114
Validation loss: 2.634827783730534

Epoch: 6| Step: 7
Training loss: 2.9926298526644746
Validation loss: 2.653552362567244

Epoch: 6| Step: 8
Training loss: 2.963648217045088
Validation loss: 2.6642081351056133

Epoch: 6| Step: 9
Training loss: 3.1501183199988976
Validation loss: 2.6627973979025956

Epoch: 6| Step: 10
Training loss: 2.859882080474856
Validation loss: 2.6580721478783746

Epoch: 6| Step: 11
Training loss: 3.0031769143657674
Validation loss: 2.634087980826034

Epoch: 6| Step: 12
Training loss: 3.0990924368086805
Validation loss: 2.6332313387261896

Epoch: 6| Step: 13
Training loss: 2.863986106806894
Validation loss: 2.6244574111543315

Epoch: 124| Step: 0
Training loss: 2.2751026675355
Validation loss: 2.6220007969340435

Epoch: 6| Step: 1
Training loss: 2.728315778880504
Validation loss: 2.617560815366069

Epoch: 6| Step: 2
Training loss: 2.8888387573815715
Validation loss: 2.61594482413872

Epoch: 6| Step: 3
Training loss: 3.584132319834744
Validation loss: 2.619327294025615

Epoch: 6| Step: 4
Training loss: 2.7337219330332805
Validation loss: 2.614846650703158

Epoch: 6| Step: 5
Training loss: 2.86384841276965
Validation loss: 2.6141558790731763

Epoch: 6| Step: 6
Training loss: 3.548656402783263
Validation loss: 2.617913855680752

Epoch: 6| Step: 7
Training loss: 3.7183896699607613
Validation loss: 2.616986135989952

Epoch: 6| Step: 8
Training loss: 3.1093605846281736
Validation loss: 2.6134210138960325

Epoch: 6| Step: 9
Training loss: 2.4102884067798653
Validation loss: 2.6161752392830886

Epoch: 6| Step: 10
Training loss: 2.8969499004273334
Validation loss: 2.612410971766358

Epoch: 6| Step: 11
Training loss: 2.7000708111554976
Validation loss: 2.605945703701656

Epoch: 6| Step: 12
Training loss: 2.776815672727298
Validation loss: 2.6030674586278533

Epoch: 6| Step: 13
Training loss: 2.774266336731714
Validation loss: 2.606369575941861

Epoch: 125| Step: 0
Training loss: 2.951323105820705
Validation loss: 2.601475816769498

Epoch: 6| Step: 1
Training loss: 3.2127928188475487
Validation loss: 2.6032404069813446

Epoch: 6| Step: 2
Training loss: 2.9333118856975324
Validation loss: 2.5832464585266464

Epoch: 6| Step: 3
Training loss: 2.985033531831297
Validation loss: 2.5799184547972365

Epoch: 6| Step: 4
Training loss: 2.963639206892906
Validation loss: 2.6366634760220324

Epoch: 6| Step: 5
Training loss: 2.8896337510715835
Validation loss: 2.668113156276723

Epoch: 6| Step: 6
Training loss: 2.9934363087342017
Validation loss: 2.712011341333035

Epoch: 6| Step: 7
Training loss: 3.098913180666111
Validation loss: 2.752926078008024

Epoch: 6| Step: 8
Training loss: 2.7602475576363177
Validation loss: 2.7518992423867106

Epoch: 6| Step: 9
Training loss: 3.2654071351892586
Validation loss: 2.735899926781219

Epoch: 6| Step: 10
Training loss: 3.446187226197998
Validation loss: 2.6496224953505636

Epoch: 6| Step: 11
Training loss: 2.743727292464362
Validation loss: 2.6023845226930984

Epoch: 6| Step: 12
Training loss: 2.5524110129571493
Validation loss: 2.581680889416833

Epoch: 6| Step: 13
Training loss: 2.3706211077786152
Validation loss: 2.57767665590379

Epoch: 126| Step: 0
Training loss: 2.7327532509367494
Validation loss: 2.581561970487256

Epoch: 6| Step: 1
Training loss: 2.8293218451196895
Validation loss: 2.582934741478054

Epoch: 6| Step: 2
Training loss: 2.9797826454722856
Validation loss: 2.6043805263854427

Epoch: 6| Step: 3
Training loss: 2.7827494147730807
Validation loss: 2.6103838097350214

Epoch: 6| Step: 4
Training loss: 3.568836666731695
Validation loss: 2.618975204827208

Epoch: 6| Step: 5
Training loss: 2.8286216679084415
Validation loss: 2.6085211658857355

Epoch: 6| Step: 6
Training loss: 2.9946108733075385
Validation loss: 2.594387028106484

Epoch: 6| Step: 7
Training loss: 2.9731197923121893
Validation loss: 2.5797438336062157

Epoch: 6| Step: 8
Training loss: 2.527539394535756
Validation loss: 2.579554846738451

Epoch: 6| Step: 9
Training loss: 2.4214502762031915
Validation loss: 2.576581666162555

Epoch: 6| Step: 10
Training loss: 2.8530951574630423
Validation loss: 2.584168467526215

Epoch: 6| Step: 11
Training loss: 3.2638793368008128
Validation loss: 2.588743056955271

Epoch: 6| Step: 12
Training loss: 3.3205744381973092
Validation loss: 2.5940457771040606

Epoch: 6| Step: 13
Training loss: 3.1608321665902417
Validation loss: 2.6071471253852945

Epoch: 127| Step: 0
Training loss: 3.0583938786666165
Validation loss: 2.634307304556438

Epoch: 6| Step: 1
Training loss: 3.7183638941251167
Validation loss: 2.655693894527796

Epoch: 6| Step: 2
Training loss: 2.939557917048185
Validation loss: 2.6526521506493888

Epoch: 6| Step: 3
Training loss: 2.6510329230763277
Validation loss: 2.6398232370175085

Epoch: 6| Step: 4
Training loss: 2.2334522395957284
Validation loss: 2.6092862310668186

Epoch: 6| Step: 5
Training loss: 3.3024791075213837
Validation loss: 2.599267404157621

Epoch: 6| Step: 6
Training loss: 2.9116947485259765
Validation loss: 2.593243845698369

Epoch: 6| Step: 7
Training loss: 3.0271978921515967
Validation loss: 2.5884622026148576

Epoch: 6| Step: 8
Training loss: 3.2688964810929027
Validation loss: 2.5844040552803333

Epoch: 6| Step: 9
Training loss: 2.5042726245706213
Validation loss: 2.5832800732328023

Epoch: 6| Step: 10
Training loss: 2.4011571915666123
Validation loss: 2.5793126214475564

Epoch: 6| Step: 11
Training loss: 3.015234412954236
Validation loss: 2.574030560601384

Epoch: 6| Step: 12
Training loss: 3.050100487476374
Validation loss: 2.5819379893214593

Epoch: 6| Step: 13
Training loss: 2.408606131215897
Validation loss: 2.5808531714189606

Epoch: 128| Step: 0
Training loss: 3.1409857243866584
Validation loss: 2.5865571398942415

Epoch: 6| Step: 1
Training loss: 3.1975459941213487
Validation loss: 2.5944405486622113

Epoch: 6| Step: 2
Training loss: 2.456751966751071
Validation loss: 2.5968388226977916

Epoch: 6| Step: 3
Training loss: 2.623729852650833
Validation loss: 2.61601368969736

Epoch: 6| Step: 4
Training loss: 3.1933648998900983
Validation loss: 2.617464344587954

Epoch: 6| Step: 5
Training loss: 3.4780467776047854
Validation loss: 2.6284290443704865

Epoch: 6| Step: 6
Training loss: 2.842358930135272
Validation loss: 2.6256195817719887

Epoch: 6| Step: 7
Training loss: 2.9253775263322552
Validation loss: 2.6220899958087625

Epoch: 6| Step: 8
Training loss: 2.554844096106006
Validation loss: 2.6217987871399537

Epoch: 6| Step: 9
Training loss: 2.796228856299673
Validation loss: 2.6256817256201423

Epoch: 6| Step: 10
Training loss: 2.989204373858751
Validation loss: 2.6082136627656065

Epoch: 6| Step: 11
Training loss: 2.5645771446948733
Validation loss: 2.613237164267439

Epoch: 6| Step: 12
Training loss: 2.9561219524371225
Validation loss: 2.605002894526402

Epoch: 6| Step: 13
Training loss: 3.324999277215176
Validation loss: 2.6078079535715277

Epoch: 129| Step: 0
Training loss: 2.756999644365589
Validation loss: 2.607419503498831

Epoch: 6| Step: 1
Training loss: 2.4665816236561984
Validation loss: 2.610041450159089

Epoch: 6| Step: 2
Training loss: 2.8130785029225076
Validation loss: 2.6118035797526304

Epoch: 6| Step: 3
Training loss: 2.6725734221718613
Validation loss: 2.6126917351885406

Epoch: 6| Step: 4
Training loss: 3.4248602400060384
Validation loss: 2.6195088244473803

Epoch: 6| Step: 5
Training loss: 3.1003926182351536
Validation loss: 2.617419382180705

Epoch: 6| Step: 6
Training loss: 3.07583967080226
Validation loss: 2.6150101164361725

Epoch: 6| Step: 7
Training loss: 2.9643565545341652
Validation loss: 2.6134362656936116

Epoch: 6| Step: 8
Training loss: 2.774056550905123
Validation loss: 2.5997668793230697

Epoch: 6| Step: 9
Training loss: 3.0735656742583997
Validation loss: 2.5867615098753043

Epoch: 6| Step: 10
Training loss: 3.048085446659381
Validation loss: 2.5851311304552658

Epoch: 6| Step: 11
Training loss: 2.823298429643446
Validation loss: 2.5776611925197117

Epoch: 6| Step: 12
Training loss: 2.920451261061774
Validation loss: 2.573998515274432

Epoch: 6| Step: 13
Training loss: 2.8502697666387204
Validation loss: 2.5793657585603516

Epoch: 130| Step: 0
Training loss: 3.341411022069599
Validation loss: 2.5769028945051415

Epoch: 6| Step: 1
Training loss: 2.9747788098597066
Validation loss: 2.577070106031182

Epoch: 6| Step: 2
Training loss: 2.7050722197871013
Validation loss: 2.5749011454735777

Epoch: 6| Step: 3
Training loss: 3.089580770651401
Validation loss: 2.5775360100864253

Epoch: 6| Step: 4
Training loss: 2.631171374380826
Validation loss: 2.5813631556093446

Epoch: 6| Step: 5
Training loss: 3.097863439339111
Validation loss: 2.5844947044922306

Epoch: 6| Step: 6
Training loss: 3.1361090992809504
Validation loss: 2.5829397130568474

Epoch: 6| Step: 7
Training loss: 2.881866217066019
Validation loss: 2.580542384236552

Epoch: 6| Step: 8
Training loss: 3.118134548335501
Validation loss: 2.576193129020882

Epoch: 6| Step: 9
Training loss: 2.776236397865772
Validation loss: 2.5809846622047403

Epoch: 6| Step: 10
Training loss: 3.12042481244651
Validation loss: 2.572817510858297

Epoch: 6| Step: 11
Training loss: 2.858294173288447
Validation loss: 2.5803569918012985

Epoch: 6| Step: 12
Training loss: 2.2816638309896757
Validation loss: 2.5750824745925307

Epoch: 6| Step: 13
Training loss: 2.4666770247508274
Validation loss: 2.574192620681843

Epoch: 131| Step: 0
Training loss: 2.6528949866994966
Validation loss: 2.5750166490348905

Epoch: 6| Step: 1
Training loss: 2.6933512310654613
Validation loss: 2.595875426302246

Epoch: 6| Step: 2
Training loss: 3.58350324597537
Validation loss: 2.600501588685414

Epoch: 6| Step: 3
Training loss: 2.7727550257901314
Validation loss: 2.6073991834209163

Epoch: 6| Step: 4
Training loss: 2.29227875135898
Validation loss: 2.601714471503933

Epoch: 6| Step: 5
Training loss: 2.7729392020448818
Validation loss: 2.5668065229437294

Epoch: 6| Step: 6
Training loss: 3.2259831312463394
Validation loss: 2.5698531986856703

Epoch: 6| Step: 7
Training loss: 3.1660734591417237
Validation loss: 2.563485201038312

Epoch: 6| Step: 8
Training loss: 3.4783705906562608
Validation loss: 2.5650458046533924

Epoch: 6| Step: 9
Training loss: 2.7254692443556783
Validation loss: 2.562156858362034

Epoch: 6| Step: 10
Training loss: 2.9872291857183995
Validation loss: 2.5594858690373643

Epoch: 6| Step: 11
Training loss: 2.77761569080052
Validation loss: 2.5623648988298617

Epoch: 6| Step: 12
Training loss: 2.769699113114105
Validation loss: 2.5639420400324293

Epoch: 6| Step: 13
Training loss: 2.758879803540876
Validation loss: 2.5608758368800273

Epoch: 132| Step: 0
Training loss: 2.705783396750489
Validation loss: 2.5593832276367423

Epoch: 6| Step: 1
Training loss: 2.5508520984011365
Validation loss: 2.5594794426143213

Epoch: 6| Step: 2
Training loss: 2.584923675118661
Validation loss: 2.5701211892472213

Epoch: 6| Step: 3
Training loss: 2.944605573008178
Validation loss: 2.5675243160403465

Epoch: 6| Step: 4
Training loss: 3.396829720259392
Validation loss: 2.5682064479224693

Epoch: 6| Step: 5
Training loss: 3.2378296025228295
Validation loss: 2.5665633497098175

Epoch: 6| Step: 6
Training loss: 2.702857825686139
Validation loss: 2.5770534402795056

Epoch: 6| Step: 7
Training loss: 3.353655252899119
Validation loss: 2.5744390037258276

Epoch: 6| Step: 8
Training loss: 2.9027385212151624
Validation loss: 2.5856042100722263

Epoch: 6| Step: 9
Training loss: 2.6559580923014434
Validation loss: 2.594730983883831

Epoch: 6| Step: 10
Training loss: 2.924684204269266
Validation loss: 2.584804799255801

Epoch: 6| Step: 11
Training loss: 2.8631373599588597
Validation loss: 2.5932776728617006

Epoch: 6| Step: 12
Training loss: 2.999895252942257
Validation loss: 2.599628411836112

Epoch: 6| Step: 13
Training loss: 2.6175847449515697
Validation loss: 2.6129712969847043

Epoch: 133| Step: 0
Training loss: 3.128404212708265
Validation loss: 2.597790910720255

Epoch: 6| Step: 1
Training loss: 2.597547485828044
Validation loss: 2.628555994928612

Epoch: 6| Step: 2
Training loss: 3.0162020906895286
Validation loss: 2.606381474595937

Epoch: 6| Step: 3
Training loss: 2.5939799746855843
Validation loss: 2.5839221619361448

Epoch: 6| Step: 4
Training loss: 3.166332494938878
Validation loss: 2.5720191807796944

Epoch: 6| Step: 5
Training loss: 2.640314659526825
Validation loss: 2.5582271981864717

Epoch: 6| Step: 6
Training loss: 2.7946358353749887
Validation loss: 2.5584324964784275

Epoch: 6| Step: 7
Training loss: 2.8770615194065967
Validation loss: 2.559957688274195

Epoch: 6| Step: 8
Training loss: 3.576720116018316
Validation loss: 2.5579465682427647

Epoch: 6| Step: 9
Training loss: 2.22124652370681
Validation loss: 2.556863082768253

Epoch: 6| Step: 10
Training loss: 3.1003392495369337
Validation loss: 2.5600174003616663

Epoch: 6| Step: 11
Training loss: 2.859867574653705
Validation loss: 2.5616115567593702

Epoch: 6| Step: 12
Training loss: 3.061636043832215
Validation loss: 2.562585962806027

Epoch: 6| Step: 13
Training loss: 3.160421051511864
Validation loss: 2.563646080744553

Epoch: 134| Step: 0
Training loss: 3.093007778953442
Validation loss: 2.5636512257284623

Epoch: 6| Step: 1
Training loss: 2.7840040479992343
Validation loss: 2.5696799242321857

Epoch: 6| Step: 2
Training loss: 2.568717484836886
Validation loss: 2.572002042234966

Epoch: 6| Step: 3
Training loss: 2.888450010496073
Validation loss: 2.572442237729065

Epoch: 6| Step: 4
Training loss: 3.07176209219956
Validation loss: 2.5737788334427356

Epoch: 6| Step: 5
Training loss: 3.4050414014811596
Validation loss: 2.5732082274649093

Epoch: 6| Step: 6
Training loss: 2.865372335262896
Validation loss: 2.567979871439897

Epoch: 6| Step: 7
Training loss: 2.417049695496406
Validation loss: 2.5731288345326155

Epoch: 6| Step: 8
Training loss: 2.7618158692976875
Validation loss: 2.5724783146144907

Epoch: 6| Step: 9
Training loss: 2.6449334023353606
Validation loss: 2.5725359761883664

Epoch: 6| Step: 10
Training loss: 3.5158699458939644
Validation loss: 2.571390711223565

Epoch: 6| Step: 11
Training loss: 2.558010541534774
Validation loss: 2.5800158445716437

Epoch: 6| Step: 12
Training loss: 3.1789906930946223
Validation loss: 2.595527807633746

Epoch: 6| Step: 13
Training loss: 2.7684208590339683
Validation loss: 2.594140770706505

Epoch: 135| Step: 0
Training loss: 3.059446408429114
Validation loss: 2.5835575326678994

Epoch: 6| Step: 1
Training loss: 3.2956819952079113
Validation loss: 2.5671417300753228

Epoch: 6| Step: 2
Training loss: 2.1119500160949354
Validation loss: 2.5672526412078116

Epoch: 6| Step: 3
Training loss: 2.859327805760203
Validation loss: 2.567854913898545

Epoch: 6| Step: 4
Training loss: 3.7079881371696195
Validation loss: 2.56243653697801

Epoch: 6| Step: 5
Training loss: 3.22439361904068
Validation loss: 2.5653586021218198

Epoch: 6| Step: 6
Training loss: 2.784317896264889
Validation loss: 2.567743262007813

Epoch: 6| Step: 7
Training loss: 2.86976096430496
Validation loss: 2.565218347273861

Epoch: 6| Step: 8
Training loss: 2.4136627755191906
Validation loss: 2.5663031851130156

Epoch: 6| Step: 9
Training loss: 2.9548738337142155
Validation loss: 2.565792777403216

Epoch: 6| Step: 10
Training loss: 2.829448916963523
Validation loss: 2.5744408997388875

Epoch: 6| Step: 11
Training loss: 3.4262324767863244
Validation loss: 2.5731888726247534

Epoch: 6| Step: 12
Training loss: 2.469132019616985
Validation loss: 2.57445607376789

Epoch: 6| Step: 13
Training loss: 1.8753570852397188
Validation loss: 2.5698591776895614

Epoch: 136| Step: 0
Training loss: 3.068405529818763
Validation loss: 2.565572475877796

Epoch: 6| Step: 1
Training loss: 3.0684423599336768
Validation loss: 2.5690414687704526

Epoch: 6| Step: 2
Training loss: 2.8677149814944807
Validation loss: 2.5641194110432077

Epoch: 6| Step: 3
Training loss: 2.8706640635630842
Validation loss: 2.5656762216006457

Epoch: 6| Step: 4
Training loss: 2.419801476587737
Validation loss: 2.5669658532326065

Epoch: 6| Step: 5
Training loss: 3.047883321736566
Validation loss: 2.5685988530219626

Epoch: 6| Step: 6
Training loss: 2.94951057253448
Validation loss: 2.5709703365816736

Epoch: 6| Step: 7
Training loss: 3.2733493692920748
Validation loss: 2.5709312460473344

Epoch: 6| Step: 8
Training loss: 2.8519530982485275
Validation loss: 2.5793162756064367

Epoch: 6| Step: 9
Training loss: 2.889736389492446
Validation loss: 2.5789496441949566

Epoch: 6| Step: 10
Training loss: 2.869993910035374
Validation loss: 2.583320313644812

Epoch: 6| Step: 11
Training loss: 3.0573085457348332
Validation loss: 2.587188701541244

Epoch: 6| Step: 12
Training loss: 2.6015031137647586
Validation loss: 2.6018928510985777

Epoch: 6| Step: 13
Training loss: 2.7484982464850503
Validation loss: 2.6017636151770396

Epoch: 137| Step: 0
Training loss: 3.352672330906027
Validation loss: 2.5904946643338094

Epoch: 6| Step: 1
Training loss: 2.9247494190834042
Validation loss: 2.5913779972765933

Epoch: 6| Step: 2
Training loss: 2.990582306974687
Validation loss: 2.5956273219199275

Epoch: 6| Step: 3
Training loss: 3.145351667771449
Validation loss: 2.5991976268986354

Epoch: 6| Step: 4
Training loss: 3.118327838098389
Validation loss: 2.598612152414685

Epoch: 6| Step: 5
Training loss: 2.8617863727549846
Validation loss: 2.587747639540595

Epoch: 6| Step: 6
Training loss: 3.2989842325407883
Validation loss: 2.578908510498498

Epoch: 6| Step: 7
Training loss: 2.4899178337420333
Validation loss: 2.57019279573519

Epoch: 6| Step: 8
Training loss: 2.70273132985651
Validation loss: 2.567598792134093

Epoch: 6| Step: 9
Training loss: 3.35234661755587
Validation loss: 2.5567868230244666

Epoch: 6| Step: 10
Training loss: 2.5586136911794477
Validation loss: 2.5572015111406237

Epoch: 6| Step: 11
Training loss: 2.7839370777045964
Validation loss: 2.5508676629967546

Epoch: 6| Step: 12
Training loss: 2.1351688768478976
Validation loss: 2.553513533298042

Epoch: 6| Step: 13
Training loss: 2.798049509658862
Validation loss: 2.5528676274204285

Epoch: 138| Step: 0
Training loss: 2.567199305799182
Validation loss: 2.554702785336206

Epoch: 6| Step: 1
Training loss: 3.173766525844535
Validation loss: 2.557245861151414

Epoch: 6| Step: 2
Training loss: 3.0023228871168834
Validation loss: 2.559185923383372

Epoch: 6| Step: 3
Training loss: 2.2647355010687287
Validation loss: 2.572027608721461

Epoch: 6| Step: 4
Training loss: 2.5506444079392865
Validation loss: 2.573051204172203

Epoch: 6| Step: 5
Training loss: 3.3638386724118727
Validation loss: 2.5794716791654975

Epoch: 6| Step: 6
Training loss: 2.425204246807454
Validation loss: 2.578626716746336

Epoch: 6| Step: 7
Training loss: 3.0778055557790798
Validation loss: 2.575465016719476

Epoch: 6| Step: 8
Training loss: 2.950405584353212
Validation loss: 2.574672848079638

Epoch: 6| Step: 9
Training loss: 3.1940808149133084
Validation loss: 2.582379690734993

Epoch: 6| Step: 10
Training loss: 3.0102735087181096
Validation loss: 2.592990928738724

Epoch: 6| Step: 11
Training loss: 3.2333847225339603
Validation loss: 2.5775063148676516

Epoch: 6| Step: 12
Training loss: 2.67470485449419
Validation loss: 2.5693203181518625

Epoch: 6| Step: 13
Training loss: 3.1544259721066488
Validation loss: 2.561043457172955

Epoch: 139| Step: 0
Training loss: 3.3780644950423926
Validation loss: 2.55990803846609

Epoch: 6| Step: 1
Training loss: 2.250668638272951
Validation loss: 2.5548288055945565

Epoch: 6| Step: 2
Training loss: 2.8973258218095888
Validation loss: 2.5586103666583666

Epoch: 6| Step: 3
Training loss: 2.7929270067630125
Validation loss: 2.557051517010772

Epoch: 6| Step: 4
Training loss: 2.890716716239231
Validation loss: 2.5579578582940834

Epoch: 6| Step: 5
Training loss: 3.1251992734315723
Validation loss: 2.5564860653162667

Epoch: 6| Step: 6
Training loss: 2.722587945811974
Validation loss: 2.561063631531856

Epoch: 6| Step: 7
Training loss: 2.343981311827753
Validation loss: 2.561410261534784

Epoch: 6| Step: 8
Training loss: 2.866533002028965
Validation loss: 2.5631560219462766

Epoch: 6| Step: 9
Training loss: 2.5084482498290277
Validation loss: 2.562701991914282

Epoch: 6| Step: 10
Training loss: 2.9501385801707545
Validation loss: 2.574495127710392

Epoch: 6| Step: 11
Training loss: 3.3975396735181596
Validation loss: 2.574716095606123

Epoch: 6| Step: 12
Training loss: 3.321990327456986
Validation loss: 2.6017453487455104

Epoch: 6| Step: 13
Training loss: 3.176585340816493
Validation loss: 2.596089448291696

Epoch: 140| Step: 0
Training loss: 2.7623649391541067
Validation loss: 2.5883871838604766

Epoch: 6| Step: 1
Training loss: 3.4066612625328045
Validation loss: 2.572637871605849

Epoch: 6| Step: 2
Training loss: 2.276285177395791
Validation loss: 2.5669954966117277

Epoch: 6| Step: 3
Training loss: 2.696214961574569
Validation loss: 2.571882314934136

Epoch: 6| Step: 4
Training loss: 2.4449240281485167
Validation loss: 2.569425524910143

Epoch: 6| Step: 5
Training loss: 3.0337110144550805
Validation loss: 2.563970978466839

Epoch: 6| Step: 6
Training loss: 3.108732991097261
Validation loss: 2.5712833634962102

Epoch: 6| Step: 7
Training loss: 2.463202508937627
Validation loss: 2.5693269753942625

Epoch: 6| Step: 8
Training loss: 3.103041750126373
Validation loss: 2.5732010004262706

Epoch: 6| Step: 9
Training loss: 2.7310774619906986
Validation loss: 2.572501879271373

Epoch: 6| Step: 10
Training loss: 3.005863340894476
Validation loss: 2.589728267749531

Epoch: 6| Step: 11
Training loss: 3.8346147606837904
Validation loss: 2.588360049640596

Epoch: 6| Step: 12
Training loss: 2.642419419805879
Validation loss: 2.5869550262922765

Epoch: 6| Step: 13
Training loss: 2.9946654893029816
Validation loss: 2.589446255992667

Epoch: 141| Step: 0
Training loss: 2.806469194649237
Validation loss: 2.5924838727146304

Epoch: 6| Step: 1
Training loss: 2.3400865533911475
Validation loss: 2.584395805086965

Epoch: 6| Step: 2
Training loss: 2.430747631900069
Validation loss: 2.5923534220812914

Epoch: 6| Step: 3
Training loss: 3.1998572079271046
Validation loss: 2.5833878850453242

Epoch: 6| Step: 4
Training loss: 2.8478489772637605
Validation loss: 2.590409655389533

Epoch: 6| Step: 5
Training loss: 3.021753754101622
Validation loss: 2.5841444616361122

Epoch: 6| Step: 6
Training loss: 2.904826810470484
Validation loss: 2.5754002919351016

Epoch: 6| Step: 7
Training loss: 3.352681006680497
Validation loss: 2.563202716347827

Epoch: 6| Step: 8
Training loss: 3.325865215651143
Validation loss: 2.5720631741222357

Epoch: 6| Step: 9
Training loss: 2.9536261562193555
Validation loss: 2.562125496018384

Epoch: 6| Step: 10
Training loss: 2.9690831047702635
Validation loss: 2.557680911431724

Epoch: 6| Step: 11
Training loss: 2.739823672893006
Validation loss: 2.557352203206665

Epoch: 6| Step: 12
Training loss: 2.6482974215121846
Validation loss: 2.5615017164695386

Epoch: 6| Step: 13
Training loss: 3.0820351178781973
Validation loss: 2.5624860522563164

Epoch: 142| Step: 0
Training loss: 2.876425845636695
Validation loss: 2.561409126547091

Epoch: 6| Step: 1
Training loss: 2.8574053541580677
Validation loss: 2.5675829145991917

Epoch: 6| Step: 2
Training loss: 2.747848883181578
Validation loss: 2.5648911547547013

Epoch: 6| Step: 3
Training loss: 2.5049966470235288
Validation loss: 2.5653002295743272

Epoch: 6| Step: 4
Training loss: 2.327488549815858
Validation loss: 2.5653568373038653

Epoch: 6| Step: 5
Training loss: 3.0135278871346265
Validation loss: 2.5703268396410373

Epoch: 6| Step: 6
Training loss: 2.755752182896056
Validation loss: 2.559099831339897

Epoch: 6| Step: 7
Training loss: 3.3037578456524264
Validation loss: 2.5623536226937533

Epoch: 6| Step: 8
Training loss: 3.0482365622645444
Validation loss: 2.564963364514513

Epoch: 6| Step: 9
Training loss: 2.41178060291037
Validation loss: 2.5733588548932675

Epoch: 6| Step: 10
Training loss: 3.680161496226173
Validation loss: 2.5755585575707673

Epoch: 6| Step: 11
Training loss: 3.0065392115180383
Validation loss: 2.576113784292942

Epoch: 6| Step: 12
Training loss: 2.8934764098317665
Validation loss: 2.5940286481980923

Epoch: 6| Step: 13
Training loss: 3.006937271199665
Validation loss: 2.620419918514821

Epoch: 143| Step: 0
Training loss: 2.933345210166931
Validation loss: 2.583742446406155

Epoch: 6| Step: 1
Training loss: 2.9101110262845187
Validation loss: 2.5786211845793394

Epoch: 6| Step: 2
Training loss: 2.708689348345403
Validation loss: 2.5753924384477442

Epoch: 6| Step: 3
Training loss: 3.414809226073409
Validation loss: 2.57201783567544

Epoch: 6| Step: 4
Training loss: 2.4653594479591816
Validation loss: 2.5667771001096913

Epoch: 6| Step: 5
Training loss: 3.1516876483328433
Validation loss: 2.5657735534693735

Epoch: 6| Step: 6
Training loss: 2.6907954747937293
Validation loss: 2.56265693702211

Epoch: 6| Step: 7
Training loss: 3.0010734862724244
Validation loss: 2.5599490137976946

Epoch: 6| Step: 8
Training loss: 2.609724832257945
Validation loss: 2.554318568013248

Epoch: 6| Step: 9
Training loss: 3.2214746886979997
Validation loss: 2.5535371093215655

Epoch: 6| Step: 10
Training loss: 3.295414171599365
Validation loss: 2.554581364139178

Epoch: 6| Step: 11
Training loss: 2.729750815816157
Validation loss: 2.5521224004899885

Epoch: 6| Step: 12
Training loss: 2.98522921016039
Validation loss: 2.5522418765022485

Epoch: 6| Step: 13
Training loss: 1.588866962416433
Validation loss: 2.549829322335649

Epoch: 144| Step: 0
Training loss: 2.5903683414485017
Validation loss: 2.5506010588169246

Epoch: 6| Step: 1
Training loss: 3.0757864961974244
Validation loss: 2.547565621486245

Epoch: 6| Step: 2
Training loss: 2.3486216459583815
Validation loss: 2.5533283922535372

Epoch: 6| Step: 3
Training loss: 2.686459894513883
Validation loss: 2.553291858034335

Epoch: 6| Step: 4
Training loss: 2.472360795193802
Validation loss: 2.5606383397465677

Epoch: 6| Step: 5
Training loss: 2.7339853935604976
Validation loss: 2.5601461095374822

Epoch: 6| Step: 6
Training loss: 2.3963529493238585
Validation loss: 2.56153663936885

Epoch: 6| Step: 7
Training loss: 3.401256575909265
Validation loss: 2.577142660432812

Epoch: 6| Step: 8
Training loss: 3.3093351684132832
Validation loss: 2.5882976139049365

Epoch: 6| Step: 9
Training loss: 3.2343609943178793
Validation loss: 2.6082307771473503

Epoch: 6| Step: 10
Training loss: 2.7395071640352646
Validation loss: 2.614186452457773

Epoch: 6| Step: 11
Training loss: 3.0828582466393213
Validation loss: 2.643184398443958

Epoch: 6| Step: 12
Training loss: 3.3185453132684235
Validation loss: 2.623391064135032

Epoch: 6| Step: 13
Training loss: 3.121092374989919
Validation loss: 2.608550278066284

Epoch: 145| Step: 0
Training loss: 2.822422749194546
Validation loss: 2.6233135789019886

Epoch: 6| Step: 1
Training loss: 2.470288919701855
Validation loss: 2.6037983252791874

Epoch: 6| Step: 2
Training loss: 2.752420660498698
Validation loss: 2.5783165317064354

Epoch: 6| Step: 3
Training loss: 2.9916357423110274
Validation loss: 2.588534922498262

Epoch: 6| Step: 4
Training loss: 2.6289806157061695
Validation loss: 2.5759586274983115

Epoch: 6| Step: 5
Training loss: 2.5887020580764992
Validation loss: 2.5691983305101616

Epoch: 6| Step: 6
Training loss: 2.775522227593261
Validation loss: 2.566012405620453

Epoch: 6| Step: 7
Training loss: 3.278597386219121
Validation loss: 2.566950403725125

Epoch: 6| Step: 8
Training loss: 3.2269668141051495
Validation loss: 2.5633488491451852

Epoch: 6| Step: 9
Training loss: 2.607778917648369
Validation loss: 2.561966396051689

Epoch: 6| Step: 10
Training loss: 2.8925141630757403
Validation loss: 2.5553811145144194

Epoch: 6| Step: 11
Training loss: 2.8770522380882273
Validation loss: 2.5583771364145007

Epoch: 6| Step: 12
Training loss: 3.327888301258667
Validation loss: 2.5574895043200296

Epoch: 6| Step: 13
Training loss: 3.4783208279521207
Validation loss: 2.5574814409603377

Epoch: 146| Step: 0
Training loss: 2.795725666214842
Validation loss: 2.557842101083688

Epoch: 6| Step: 1
Training loss: 3.0039208539550724
Validation loss: 2.5745253366274072

Epoch: 6| Step: 2
Training loss: 3.3431204800406733
Validation loss: 2.573373806172532

Epoch: 6| Step: 3
Training loss: 2.3343598514662847
Validation loss: 2.5728316641557134

Epoch: 6| Step: 4
Training loss: 2.866449827672375
Validation loss: 2.5796511322226836

Epoch: 6| Step: 5
Training loss: 2.444048570115974
Validation loss: 2.5770687511283974

Epoch: 6| Step: 6
Training loss: 3.0796714035225117
Validation loss: 2.575291890391161

Epoch: 6| Step: 7
Training loss: 2.998005044750934
Validation loss: 2.582552513652257

Epoch: 6| Step: 8
Training loss: 3.185589236335063
Validation loss: 2.585933721857025

Epoch: 6| Step: 9
Training loss: 3.4068048707682443
Validation loss: 2.576017863193405

Epoch: 6| Step: 10
Training loss: 3.025532629868165
Validation loss: 2.57424051211263

Epoch: 6| Step: 11
Training loss: 2.4952039490786238
Validation loss: 2.5613801931989224

Epoch: 6| Step: 12
Training loss: 2.5275081716644974
Validation loss: 2.5637448876305955

Epoch: 6| Step: 13
Training loss: 2.8336707269579433
Validation loss: 2.565002085243856

Epoch: 147| Step: 0
Training loss: 2.784920317299232
Validation loss: 2.565823484441167

Epoch: 6| Step: 1
Training loss: 3.0181851760954213
Validation loss: 2.5679545381939564

Epoch: 6| Step: 2
Training loss: 2.8260217084975503
Validation loss: 2.566038823044077

Epoch: 6| Step: 3
Training loss: 2.854012886601034
Validation loss: 2.5671046953850922

Epoch: 6| Step: 4
Training loss: 2.988965084644128
Validation loss: 2.562982312724277

Epoch: 6| Step: 5
Training loss: 2.760205319549054
Validation loss: 2.569055070080431

Epoch: 6| Step: 6
Training loss: 3.217910212618526
Validation loss: 2.5781243049270124

Epoch: 6| Step: 7
Training loss: 2.8389630952689098
Validation loss: 2.585199551978047

Epoch: 6| Step: 8
Training loss: 3.1245602107528856
Validation loss: 2.5807941599486077

Epoch: 6| Step: 9
Training loss: 2.742914608796173
Validation loss: 2.6009479686114982

Epoch: 6| Step: 10
Training loss: 2.716423881150989
Validation loss: 2.592928546177514

Epoch: 6| Step: 11
Training loss: 2.5085450050372553
Validation loss: 2.6050431703916597

Epoch: 6| Step: 12
Training loss: 3.2322100336550155
Validation loss: 2.6069753340297406

Epoch: 6| Step: 13
Training loss: 2.6327820728026645
Validation loss: 2.5913727975300827

Epoch: 148| Step: 0
Training loss: 3.078883353600478
Validation loss: 2.606943668101647

Epoch: 6| Step: 1
Training loss: 2.660533995842919
Validation loss: 2.6175563267692663

Epoch: 6| Step: 2
Training loss: 3.1608914532704078
Validation loss: 2.5954952563082196

Epoch: 6| Step: 3
Training loss: 2.60131669816421
Validation loss: 2.6051635799616704

Epoch: 6| Step: 4
Training loss: 2.7088298244711377
Validation loss: 2.5858904854704376

Epoch: 6| Step: 5
Training loss: 3.1185067427872544
Validation loss: 2.593774577228346

Epoch: 6| Step: 6
Training loss: 2.7018096016551927
Validation loss: 2.5763375040442367

Epoch: 6| Step: 7
Training loss: 2.96386396982939
Validation loss: 2.5646948989743463

Epoch: 6| Step: 8
Training loss: 2.9441939033423927
Validation loss: 2.5726196395274874

Epoch: 6| Step: 9
Training loss: 3.193923163152041
Validation loss: 2.5702528046618647

Epoch: 6| Step: 10
Training loss: 2.653690855613277
Validation loss: 2.573734376865678

Epoch: 6| Step: 11
Training loss: 2.828229702017764
Validation loss: 2.575442683629992

Epoch: 6| Step: 12
Training loss: 2.9634480564951566
Validation loss: 2.5699299839592133

Epoch: 6| Step: 13
Training loss: 2.6443642770635005
Validation loss: 2.573934594735766

Epoch: 149| Step: 0
Training loss: 2.5794565172488255
Validation loss: 2.5650908395735303

Epoch: 6| Step: 1
Training loss: 3.3388156312285258
Validation loss: 2.565213936984241

Epoch: 6| Step: 2
Training loss: 3.0310767999306183
Validation loss: 2.5694998201853076

Epoch: 6| Step: 3
Training loss: 2.4716456368345465
Validation loss: 2.5709705240456886

Epoch: 6| Step: 4
Training loss: 3.221025421876018
Validation loss: 2.585586221126482

Epoch: 6| Step: 5
Training loss: 2.663140100894237
Validation loss: 2.5945319998248677

Epoch: 6| Step: 6
Training loss: 2.158611828524322
Validation loss: 2.590051506095095

Epoch: 6| Step: 7
Training loss: 2.700318660298629
Validation loss: 2.5892088249797163

Epoch: 6| Step: 8
Training loss: 3.5250289266495134
Validation loss: 2.5941212706285923

Epoch: 6| Step: 9
Training loss: 2.8396296571314794
Validation loss: 2.5856325302869636

Epoch: 6| Step: 10
Training loss: 2.900938368943773
Validation loss: 2.580831400498624

Epoch: 6| Step: 11
Training loss: 2.917226265402999
Validation loss: 2.5712129634063996

Epoch: 6| Step: 12
Training loss: 2.469573064810297
Validation loss: 2.564281608620825

Epoch: 6| Step: 13
Training loss: 3.6711073052610055
Validation loss: 2.5545583155876934

Epoch: 150| Step: 0
Training loss: 2.505056988644654
Validation loss: 2.5414139877375095

Epoch: 6| Step: 1
Training loss: 2.488602023206448
Validation loss: 2.5471427128035713

Epoch: 6| Step: 2
Training loss: 2.9649376734958266
Validation loss: 2.54553408201164

Epoch: 6| Step: 3
Training loss: 3.2253964143534546
Validation loss: 2.542126202677061

Epoch: 6| Step: 4
Training loss: 2.881662858026862
Validation loss: 2.544119293213697

Epoch: 6| Step: 5
Training loss: 2.474151496707934
Validation loss: 2.542730947452767

Epoch: 6| Step: 6
Training loss: 3.1542025430941063
Validation loss: 2.541332823764744

Epoch: 6| Step: 7
Training loss: 2.3673532761543328
Validation loss: 2.5409330408361774

Epoch: 6| Step: 8
Training loss: 3.152028196818683
Validation loss: 2.5447275658624284

Epoch: 6| Step: 9
Training loss: 2.6917759789472457
Validation loss: 2.5412771567676344

Epoch: 6| Step: 10
Training loss: 2.831559093184064
Validation loss: 2.547710794667582

Epoch: 6| Step: 11
Training loss: 3.0559742746618497
Validation loss: 2.561630883983692

Epoch: 6| Step: 12
Training loss: 3.4906998096123414
Validation loss: 2.570288850438805

Epoch: 6| Step: 13
Training loss: 3.22610167382984
Validation loss: 2.5682830842885775

Epoch: 151| Step: 0
Training loss: 3.5630093929778295
Validation loss: 2.562673964499202

Epoch: 6| Step: 1
Training loss: 2.684074525369826
Validation loss: 2.5604172873404685

Epoch: 6| Step: 2
Training loss: 2.3571275528910487
Validation loss: 2.549528067158372

Epoch: 6| Step: 3
Training loss: 2.688729559387513
Validation loss: 2.5492819751364535

Epoch: 6| Step: 4
Training loss: 2.7266112927112527
Validation loss: 2.554271317763556

Epoch: 6| Step: 5
Training loss: 2.3248479937013387
Validation loss: 2.556260188993267

Epoch: 6| Step: 6
Training loss: 2.41702947414421
Validation loss: 2.558651834689828

Epoch: 6| Step: 7
Training loss: 2.60986734645088
Validation loss: 2.5641087070199036

Epoch: 6| Step: 8
Training loss: 2.87503831257378
Validation loss: 2.5700317632449536

Epoch: 6| Step: 9
Training loss: 3.6070877027813784
Validation loss: 2.5902104180438035

Epoch: 6| Step: 10
Training loss: 2.991661244620366
Validation loss: 2.579560089189732

Epoch: 6| Step: 11
Training loss: 3.340970033503819
Validation loss: 2.5958656067528207

Epoch: 6| Step: 12
Training loss: 2.9430539808698657
Validation loss: 2.599634226208741

Epoch: 6| Step: 13
Training loss: 3.025117156226999
Validation loss: 2.592006060994135

Epoch: 152| Step: 0
Training loss: 2.8865509190894407
Validation loss: 2.571239763106973

Epoch: 6| Step: 1
Training loss: 2.300228965806556
Validation loss: 2.5584432633291083

Epoch: 6| Step: 2
Training loss: 3.0235273954053405
Validation loss: 2.5673518215505413

Epoch: 6| Step: 3
Training loss: 2.487146043754296
Validation loss: 2.5468900252175266

Epoch: 6| Step: 4
Training loss: 3.354967357402793
Validation loss: 2.5455618681094965

Epoch: 6| Step: 5
Training loss: 2.7305741405749293
Validation loss: 2.544614488146089

Epoch: 6| Step: 6
Training loss: 3.4952549785984828
Validation loss: 2.5449624811697227

Epoch: 6| Step: 7
Training loss: 2.4736763776759823
Validation loss: 2.5419629494348865

Epoch: 6| Step: 8
Training loss: 3.0516903117534877
Validation loss: 2.5430494071088146

Epoch: 6| Step: 9
Training loss: 2.7936378371148463
Validation loss: 2.5441705620979795

Epoch: 6| Step: 10
Training loss: 3.1948920908392093
Validation loss: 2.546504051240791

Epoch: 6| Step: 11
Training loss: 3.1365566948136414
Validation loss: 2.53996051617792

Epoch: 6| Step: 12
Training loss: 2.6243114476640956
Validation loss: 2.5477296316467952

Epoch: 6| Step: 13
Training loss: 2.5614163968651957
Validation loss: 2.550214557802074

Epoch: 153| Step: 0
Training loss: 3.1577483293826236
Validation loss: 2.556915406563851

Epoch: 6| Step: 1
Training loss: 2.714143116510822
Validation loss: 2.559016433265984

Epoch: 6| Step: 2
Training loss: 2.7767465542234135
Validation loss: 2.5779122725670605

Epoch: 6| Step: 3
Training loss: 2.7987466868167568
Validation loss: 2.5965353920542005

Epoch: 6| Step: 4
Training loss: 2.7322196967452963
Validation loss: 2.600769092462879

Epoch: 6| Step: 5
Training loss: 2.9217362804428557
Validation loss: 2.5929394268498878

Epoch: 6| Step: 6
Training loss: 3.0109319190947077
Validation loss: 2.5707352808532287

Epoch: 6| Step: 7
Training loss: 3.2363761571382836
Validation loss: 2.561832684241375

Epoch: 6| Step: 8
Training loss: 2.76070246146692
Validation loss: 2.5540837820187914

Epoch: 6| Step: 9
Training loss: 2.8011574805053034
Validation loss: 2.5513441668249937

Epoch: 6| Step: 10
Training loss: 2.4711469771772987
Validation loss: 2.549514490886495

Epoch: 6| Step: 11
Training loss: 3.3488257556418772
Validation loss: 2.5576239964891405

Epoch: 6| Step: 12
Training loss: 3.0390315900078955
Validation loss: 2.5510876516198557

Epoch: 6| Step: 13
Training loss: 2.3845417689326442
Validation loss: 2.559733904016648

Epoch: 154| Step: 0
Training loss: 1.6630962593264542
Validation loss: 2.5642093506687678

Epoch: 6| Step: 1
Training loss: 2.556619922388009
Validation loss: 2.5723357032742076

Epoch: 6| Step: 2
Training loss: 2.9551347625004474
Validation loss: 2.5868526869492547

Epoch: 6| Step: 3
Training loss: 3.259945397651087
Validation loss: 2.588728683654151

Epoch: 6| Step: 4
Training loss: 2.5839146195941805
Validation loss: 2.599617664679607

Epoch: 6| Step: 5
Training loss: 2.781710468706955
Validation loss: 2.6153797315518434

Epoch: 6| Step: 6
Training loss: 2.8983050622012763
Validation loss: 2.6177461466571734

Epoch: 6| Step: 7
Training loss: 3.4927420975831427
Validation loss: 2.61631409016464

Epoch: 6| Step: 8
Training loss: 2.76443076346359
Validation loss: 2.606407704164209

Epoch: 6| Step: 9
Training loss: 2.802240946330109
Validation loss: 2.6028524079227062

Epoch: 6| Step: 10
Training loss: 2.9423064821143945
Validation loss: 2.594525921559561

Epoch: 6| Step: 11
Training loss: 3.51618105411571
Validation loss: 2.593690129466427

Epoch: 6| Step: 12
Training loss: 2.934324617938503
Validation loss: 2.5963514901524656

Epoch: 6| Step: 13
Training loss: 3.3207061175234283
Validation loss: 2.5896571534232717

Epoch: 155| Step: 0
Training loss: 2.983523102448553
Validation loss: 2.5932738876183152

Epoch: 6| Step: 1
Training loss: 2.8633680135323876
Validation loss: 2.591065517118016

Epoch: 6| Step: 2
Training loss: 2.825258013665392
Validation loss: 2.5923676684819563

Epoch: 6| Step: 3
Training loss: 2.5843351534039907
Validation loss: 2.592230402944568

Epoch: 6| Step: 4
Training loss: 2.634794581475426
Validation loss: 2.587256501871501

Epoch: 6| Step: 5
Training loss: 3.199809968789513
Validation loss: 2.588784108660266

Epoch: 6| Step: 6
Training loss: 2.9621994831878293
Validation loss: 2.599001690001924

Epoch: 6| Step: 7
Training loss: 2.4430209504086826
Validation loss: 2.5963374235965446

Epoch: 6| Step: 8
Training loss: 3.1416234189673347
Validation loss: 2.5909277610801533

Epoch: 6| Step: 9
Training loss: 3.014750141273177
Validation loss: 2.6023468418802227

Epoch: 6| Step: 10
Training loss: 2.5193823008903493
Validation loss: 2.6116421622113637

Epoch: 6| Step: 11
Training loss: 3.2289814229355804
Validation loss: 2.6202986455883215

Epoch: 6| Step: 12
Training loss: 3.4470198157316108
Validation loss: 2.6175213804832205

Epoch: 6| Step: 13
Training loss: 2.4003290427668045
Validation loss: 2.637303080709273

Epoch: 156| Step: 0
Training loss: 3.6353152606159735
Validation loss: 2.627393994243935

Epoch: 6| Step: 1
Training loss: 2.714835055769577
Validation loss: 2.627716352478827

Epoch: 6| Step: 2
Training loss: 3.498691723042798
Validation loss: 2.6205351184878265

Epoch: 6| Step: 3
Training loss: 2.8832469912557697
Validation loss: 2.5936527819599804

Epoch: 6| Step: 4
Training loss: 2.85526902195645
Validation loss: 2.588522891299245

Epoch: 6| Step: 5
Training loss: 2.9244611586132074
Validation loss: 2.5788526535485206

Epoch: 6| Step: 6
Training loss: 3.1363731944525304
Validation loss: 2.5754627949659947

Epoch: 6| Step: 7
Training loss: 2.7104576191800334
Validation loss: 2.5809240843219783

Epoch: 6| Step: 8
Training loss: 2.556668041714626
Validation loss: 2.570411389732583

Epoch: 6| Step: 9
Training loss: 2.034574165498056
Validation loss: 2.5727739205248104

Epoch: 6| Step: 10
Training loss: 3.3290638920114954
Validation loss: 2.580606168918952

Epoch: 6| Step: 11
Training loss: 2.8548053852831714
Validation loss: 2.574466086506785

Epoch: 6| Step: 12
Training loss: 2.8176776275559967
Validation loss: 2.5782784772715877

Epoch: 6| Step: 13
Training loss: 2.2829939564488306
Validation loss: 2.577573337493688

Epoch: 157| Step: 0
Training loss: 3.0127456438259252
Validation loss: 2.5791041031763084

Epoch: 6| Step: 1
Training loss: 3.0524313319275196
Validation loss: 2.5772055240756937

Epoch: 6| Step: 2
Training loss: 2.876314940567027
Validation loss: 2.5760905144047523

Epoch: 6| Step: 3
Training loss: 3.168988497635252
Validation loss: 2.5885792467039455

Epoch: 6| Step: 4
Training loss: 3.2073181990421884
Validation loss: 2.5838461342803534

Epoch: 6| Step: 5
Training loss: 2.4460163505051384
Validation loss: 2.5901056893217325

Epoch: 6| Step: 6
Training loss: 2.6882975969424523
Validation loss: 2.605458552363378

Epoch: 6| Step: 7
Training loss: 2.515617891858407
Validation loss: 2.6247327651935297

Epoch: 6| Step: 8
Training loss: 2.6965905739037583
Validation loss: 2.614330111981047

Epoch: 6| Step: 9
Training loss: 3.3816453008100544
Validation loss: 2.6092509352652353

Epoch: 6| Step: 10
Training loss: 3.030772378004556
Validation loss: 2.5812297096518657

Epoch: 6| Step: 11
Training loss: 2.6081022710698796
Validation loss: 2.567617406326961

Epoch: 6| Step: 12
Training loss: 2.5524470686398195
Validation loss: 2.5584034262562825

Epoch: 6| Step: 13
Training loss: 3.3300676720418787
Validation loss: 2.560149231290877

Epoch: 158| Step: 0
Training loss: 2.5554333452590323
Validation loss: 2.553813608116129

Epoch: 6| Step: 1
Training loss: 2.576526863217204
Validation loss: 2.55438970670511

Epoch: 6| Step: 2
Training loss: 2.23945168988022
Validation loss: 2.5494975293692175

Epoch: 6| Step: 3
Training loss: 2.7666040616439913
Validation loss: 2.5373533417167695

Epoch: 6| Step: 4
Training loss: 3.116635993221795
Validation loss: 2.5375185974044157

Epoch: 6| Step: 5
Training loss: 2.8908211306456177
Validation loss: 2.530859145910625

Epoch: 6| Step: 6
Training loss: 3.080279685363567
Validation loss: 2.533532993226557

Epoch: 6| Step: 7
Training loss: 3.30255086739788
Validation loss: 2.539635159239107

Epoch: 6| Step: 8
Training loss: 2.712968840271427
Validation loss: 2.533812424667565

Epoch: 6| Step: 9
Training loss: 3.008238606181157
Validation loss: 2.533770273892638

Epoch: 6| Step: 10
Training loss: 2.7898153362894296
Validation loss: 2.5415205433554244

Epoch: 6| Step: 11
Training loss: 2.7483911142777724
Validation loss: 2.5369042317532413

Epoch: 6| Step: 12
Training loss: 3.41646004649075
Validation loss: 2.5389622398251386

Epoch: 6| Step: 13
Training loss: 3.1494208757193745
Validation loss: 2.550307916029856

Epoch: 159| Step: 0
Training loss: 2.8278707316204996
Validation loss: 2.5513179398937065

Epoch: 6| Step: 1
Training loss: 3.5825441215870146
Validation loss: 2.55088622239914

Epoch: 6| Step: 2
Training loss: 2.8149389923694117
Validation loss: 2.5449646560142667

Epoch: 6| Step: 3
Training loss: 2.7897143203336623
Validation loss: 2.5613440110406493

Epoch: 6| Step: 4
Training loss: 3.1694227238129153
Validation loss: 2.5716655336843957

Epoch: 6| Step: 5
Training loss: 2.8120902716688176
Validation loss: 2.5690608478711683

Epoch: 6| Step: 6
Training loss: 2.575628933439558
Validation loss: 2.581777780764663

Epoch: 6| Step: 7
Training loss: 2.855929607560355
Validation loss: 2.6099854903964483

Epoch: 6| Step: 8
Training loss: 2.336071099891084
Validation loss: 2.596677043572391

Epoch: 6| Step: 9
Training loss: 2.7868842158964013
Validation loss: 2.616678076730241

Epoch: 6| Step: 10
Training loss: 3.041535535798874
Validation loss: 2.614751304372406

Epoch: 6| Step: 11
Training loss: 2.785107113269659
Validation loss: 2.6385978203224263

Epoch: 6| Step: 12
Training loss: 3.1336130085032115
Validation loss: 2.6180427575400844

Epoch: 6| Step: 13
Training loss: 2.543780078756969
Validation loss: 2.628611022943299

Epoch: 160| Step: 0
Training loss: 3.216219305313779
Validation loss: 2.6322795632456293

Epoch: 6| Step: 1
Training loss: 3.130762356916577
Validation loss: 2.6247474658318812

Epoch: 6| Step: 2
Training loss: 3.1339602377583837
Validation loss: 2.6050209216106603

Epoch: 6| Step: 3
Training loss: 2.6175800996928644
Validation loss: 2.579542926706254

Epoch: 6| Step: 4
Training loss: 3.041342696263965
Validation loss: 2.5689256012506765

Epoch: 6| Step: 5
Training loss: 2.4164235442190494
Validation loss: 2.563703302984391

Epoch: 6| Step: 6
Training loss: 3.051595151915045
Validation loss: 2.5529643008416483

Epoch: 6| Step: 7
Training loss: 2.6337365586164596
Validation loss: 2.557874043132367

Epoch: 6| Step: 8
Training loss: 3.0196380004173435
Validation loss: 2.549884964497429

Epoch: 6| Step: 9
Training loss: 2.797289513926891
Validation loss: 2.546186668055453

Epoch: 6| Step: 10
Training loss: 2.9967229746902087
Validation loss: 2.5592119164184157

Epoch: 6| Step: 11
Training loss: 2.4868587338245636
Validation loss: 2.557233136379017

Epoch: 6| Step: 12
Training loss: 3.1036130338906207
Validation loss: 2.5679923233334954

Epoch: 6| Step: 13
Training loss: 2.4351568452738284
Validation loss: 2.558360493690729

Epoch: 161| Step: 0
Training loss: 2.91796352074498
Validation loss: 2.5726951389832484

Epoch: 6| Step: 1
Training loss: 2.593285392605766
Validation loss: 2.5654760237452234

Epoch: 6| Step: 2
Training loss: 3.1270825885227103
Validation loss: 2.5534547333473627

Epoch: 6| Step: 3
Training loss: 2.2441673974414784
Validation loss: 2.5530334097154936

Epoch: 6| Step: 4
Training loss: 2.838666459353063
Validation loss: 2.558459804309944

Epoch: 6| Step: 5
Training loss: 2.974750117217864
Validation loss: 2.5493006898873407

Epoch: 6| Step: 6
Training loss: 2.856764972765373
Validation loss: 2.545422608268152

Epoch: 6| Step: 7
Training loss: 3.4481297606725225
Validation loss: 2.5492378013434736

Epoch: 6| Step: 8
Training loss: 2.7983680874103602
Validation loss: 2.553672390908467

Epoch: 6| Step: 9
Training loss: 3.1280499642715895
Validation loss: 2.54903074069045

Epoch: 6| Step: 10
Training loss: 2.858974574666817
Validation loss: 2.5535749029910564

Epoch: 6| Step: 11
Training loss: 2.480852617012229
Validation loss: 2.5492937882732756

Epoch: 6| Step: 12
Training loss: 2.792916336101285
Validation loss: 2.5556042316426613

Epoch: 6| Step: 13
Training loss: 3.327761204854646
Validation loss: 2.5602147586947392

Epoch: 162| Step: 0
Training loss: 2.596645990549739
Validation loss: 2.564320678554669

Epoch: 6| Step: 1
Training loss: 2.5588676946618754
Validation loss: 2.563979899301806

Epoch: 6| Step: 2
Training loss: 2.7431694511450275
Validation loss: 2.559036218878205

Epoch: 6| Step: 3
Training loss: 2.9253020562604006
Validation loss: 2.560670224889175

Epoch: 6| Step: 4
Training loss: 2.409176916546846
Validation loss: 2.5713864216875617

Epoch: 6| Step: 5
Training loss: 2.480720855637032
Validation loss: 2.559115767517044

Epoch: 6| Step: 6
Training loss: 2.773369414877317
Validation loss: 2.5645311890707663

Epoch: 6| Step: 7
Training loss: 3.2452868986336725
Validation loss: 2.5721799717368556

Epoch: 6| Step: 8
Training loss: 2.970796381723695
Validation loss: 2.5780596334822534

Epoch: 6| Step: 9
Training loss: 3.5597526262896384
Validation loss: 2.585289367105116

Epoch: 6| Step: 10
Training loss: 3.2756017117617766
Validation loss: 2.5913943621641287

Epoch: 6| Step: 11
Training loss: 3.1606263894335855
Validation loss: 2.576009288577214

Epoch: 6| Step: 12
Training loss: 2.2628961374382626
Validation loss: 2.582761832966363

Epoch: 6| Step: 13
Training loss: 2.8327805783997615
Validation loss: 2.6076510912526847

Epoch: 163| Step: 0
Training loss: 3.0070793546425056
Validation loss: 2.616161767317727

Epoch: 6| Step: 1
Training loss: 2.3987418612232263
Validation loss: 2.661974186007939

Epoch: 6| Step: 2
Training loss: 3.070988316207219
Validation loss: 2.66037416760409

Epoch: 6| Step: 3
Training loss: 2.827319963222853
Validation loss: 2.659793031666807

Epoch: 6| Step: 4
Training loss: 2.6745690043118504
Validation loss: 2.625647299514014

Epoch: 6| Step: 5
Training loss: 2.3641890366519744
Validation loss: 2.622375592479919

Epoch: 6| Step: 6
Training loss: 2.946538128818305
Validation loss: 2.604821816675382

Epoch: 6| Step: 7
Training loss: 2.9114924902552968
Validation loss: 2.6048191652650847

Epoch: 6| Step: 8
Training loss: 3.128324037787708
Validation loss: 2.5851283834811376

Epoch: 6| Step: 9
Training loss: 2.4006510407838744
Validation loss: 2.5700172713321714

Epoch: 6| Step: 10
Training loss: 2.31383609836172
Validation loss: 2.5582220082219806

Epoch: 6| Step: 11
Training loss: 3.3920341411347885
Validation loss: 2.547416000941697

Epoch: 6| Step: 12
Training loss: 3.2258063439399947
Validation loss: 2.5480039082476886

Epoch: 6| Step: 13
Training loss: 3.6009870553540106
Validation loss: 2.5453045717465894

Epoch: 164| Step: 0
Training loss: 2.4292345023348374
Validation loss: 2.5448170272966246

Epoch: 6| Step: 1
Training loss: 2.8937763254109305
Validation loss: 2.5480397184189445

Epoch: 6| Step: 2
Training loss: 2.7914375856457303
Validation loss: 2.538064191642278

Epoch: 6| Step: 3
Training loss: 2.7241497568200996
Validation loss: 2.5446965488490667

Epoch: 6| Step: 4
Training loss: 2.355005323076003
Validation loss: 2.5390393620675997

Epoch: 6| Step: 5
Training loss: 2.83700180049351
Validation loss: 2.540651848739747

Epoch: 6| Step: 6
Training loss: 2.815990401425042
Validation loss: 2.542715788769979

Epoch: 6| Step: 7
Training loss: 2.9164199906441137
Validation loss: 2.5427532250576363

Epoch: 6| Step: 8
Training loss: 3.132452661106352
Validation loss: 2.548765258994444

Epoch: 6| Step: 9
Training loss: 3.660680189871091
Validation loss: 2.5395732306023446

Epoch: 6| Step: 10
Training loss: 2.755369752555384
Validation loss: 2.5398992767836783

Epoch: 6| Step: 11
Training loss: 2.9208584409352025
Validation loss: 2.5463332860784615

Epoch: 6| Step: 12
Training loss: 3.2400792632591795
Validation loss: 2.5717853996687587

Epoch: 6| Step: 13
Training loss: 2.477688602540123
Validation loss: 2.577047228770202

Epoch: 165| Step: 0
Training loss: 2.3823828137809686
Validation loss: 2.5982439689944843

Epoch: 6| Step: 1
Training loss: 3.2015013510662316
Validation loss: 2.6419940410888154

Epoch: 6| Step: 2
Training loss: 2.8670371533299353
Validation loss: 2.672863444308197

Epoch: 6| Step: 3
Training loss: 2.7418125689642023
Validation loss: 2.6550294073131004

Epoch: 6| Step: 4
Training loss: 2.6255330952244065
Validation loss: 2.5982560553279077

Epoch: 6| Step: 5
Training loss: 2.635970850237768
Validation loss: 2.5899037381558503

Epoch: 6| Step: 6
Training loss: 3.328761653270944
Validation loss: 2.568994467357682

Epoch: 6| Step: 7
Training loss: 2.655712477207704
Validation loss: 2.5548551861348856

Epoch: 6| Step: 8
Training loss: 3.378838369757108
Validation loss: 2.5486440719492793

Epoch: 6| Step: 9
Training loss: 2.4601251139265
Validation loss: 2.5542035883386673

Epoch: 6| Step: 10
Training loss: 3.6952430766965825
Validation loss: 2.549114283429741

Epoch: 6| Step: 11
Training loss: 3.125826764412994
Validation loss: 2.548643238071196

Epoch: 6| Step: 12
Training loss: 2.624779919072392
Validation loss: 2.548277318311698

Epoch: 6| Step: 13
Training loss: 2.141947316979533
Validation loss: 2.5482938543551272

Epoch: 166| Step: 0
Training loss: 2.6083765003991415
Validation loss: 2.5447943245001365

Epoch: 6| Step: 1
Training loss: 2.9288353252803176
Validation loss: 2.550021755826226

Epoch: 6| Step: 2
Training loss: 3.139822026937171
Validation loss: 2.5544731865841026

Epoch: 6| Step: 3
Training loss: 2.5421109254226733
Validation loss: 2.5540566301570906

Epoch: 6| Step: 4
Training loss: 3.483365720996838
Validation loss: 2.5593606450346176

Epoch: 6| Step: 5
Training loss: 2.7808169767199558
Validation loss: 2.5562104102021816

Epoch: 6| Step: 6
Training loss: 2.987078814963167
Validation loss: 2.5672643956196497

Epoch: 6| Step: 7
Training loss: 3.162466744108588
Validation loss: 2.5727398755880273

Epoch: 6| Step: 8
Training loss: 3.0977483016548124
Validation loss: 2.573450832575353

Epoch: 6| Step: 9
Training loss: 2.457445555478715
Validation loss: 2.571067943655309

Epoch: 6| Step: 10
Training loss: 2.6455149321321234
Validation loss: 2.565036946493376

Epoch: 6| Step: 11
Training loss: 2.8829193508949653
Validation loss: 2.5617020167609756

Epoch: 6| Step: 12
Training loss: 2.93802264819365
Validation loss: 2.566086389106576

Epoch: 6| Step: 13
Training loss: 1.839410815964472
Validation loss: 2.5790219066547864

Epoch: 167| Step: 0
Training loss: 2.978023140637405
Validation loss: 2.5730851418696425

Epoch: 6| Step: 1
Training loss: 2.488775518603623
Validation loss: 2.5735823031104097

Epoch: 6| Step: 2
Training loss: 3.4327576262611808
Validation loss: 2.6037261429501686

Epoch: 6| Step: 3
Training loss: 3.202474388478744
Validation loss: 2.5795669555425067

Epoch: 6| Step: 4
Training loss: 2.670572063582923
Validation loss: 2.5856624831646844

Epoch: 6| Step: 5
Training loss: 3.190460625280438
Validation loss: 2.578014496951823

Epoch: 6| Step: 6
Training loss: 2.5309068423655314
Validation loss: 2.56271822980815

Epoch: 6| Step: 7
Training loss: 2.3458281395574048
Validation loss: 2.560943522983636

Epoch: 6| Step: 8
Training loss: 2.765063988633278
Validation loss: 2.5564475986755473

Epoch: 6| Step: 9
Training loss: 3.5261055261115506
Validation loss: 2.56026435248885

Epoch: 6| Step: 10
Training loss: 2.698864793549066
Validation loss: 2.552594219919975

Epoch: 6| Step: 11
Training loss: 2.0824413933355355
Validation loss: 2.560977523528898

Epoch: 6| Step: 12
Training loss: 2.7857682463900715
Validation loss: 2.5826327485072595

Epoch: 6| Step: 13
Training loss: 3.551098162081454
Validation loss: 2.583008374256118

Epoch: 168| Step: 0
Training loss: 2.721771315341827
Validation loss: 2.5773894960311887

Epoch: 6| Step: 1
Training loss: 3.013063281569957
Validation loss: 2.5794939987400656

Epoch: 6| Step: 2
Training loss: 2.9103500813700007
Validation loss: 2.580976604704205

Epoch: 6| Step: 3
Training loss: 3.469426544471774
Validation loss: 2.576792115196616

Epoch: 6| Step: 4
Training loss: 2.4821195140654475
Validation loss: 2.574939898960233

Epoch: 6| Step: 5
Training loss: 2.3718901903874783
Validation loss: 2.5483400333817885

Epoch: 6| Step: 6
Training loss: 2.778236299394315
Validation loss: 2.558517803363472

Epoch: 6| Step: 7
Training loss: 2.6853602563000227
Validation loss: 2.5622837366566222

Epoch: 6| Step: 8
Training loss: 3.433847463562576
Validation loss: 2.572086018966411

Epoch: 6| Step: 9
Training loss: 2.9655236631873008
Validation loss: 2.579455721160017

Epoch: 6| Step: 10
Training loss: 2.8549613867184473
Validation loss: 2.5666149164018695

Epoch: 6| Step: 11
Training loss: 2.496026123276969
Validation loss: 2.557387475484461

Epoch: 6| Step: 12
Training loss: 2.4469513200377073
Validation loss: 2.5587397111898778

Epoch: 6| Step: 13
Training loss: 3.350361499924416
Validation loss: 2.549289617931489

Epoch: 169| Step: 0
Training loss: 2.796957515586202
Validation loss: 2.5571677019988943

Epoch: 6| Step: 1
Training loss: 3.2464759500665257
Validation loss: 2.551194921628127

Epoch: 6| Step: 2
Training loss: 2.9127117227375847
Validation loss: 2.536950085555972

Epoch: 6| Step: 3
Training loss: 2.9607110654059747
Validation loss: 2.5351738803284047

Epoch: 6| Step: 4
Training loss: 2.6155443185921228
Validation loss: 2.5347315146181826

Epoch: 6| Step: 5
Training loss: 3.029830915057857
Validation loss: 2.5317566735608836

Epoch: 6| Step: 6
Training loss: 2.637198759114387
Validation loss: 2.530233770910567

Epoch: 6| Step: 7
Training loss: 2.550862660065484
Validation loss: 2.5262401777251466

Epoch: 6| Step: 8
Training loss: 2.9355657174628145
Validation loss: 2.5259059905513217

Epoch: 6| Step: 9
Training loss: 2.754760609661124
Validation loss: 2.5368460220186266

Epoch: 6| Step: 10
Training loss: 2.7475546454982074
Validation loss: 2.5398557866615437

Epoch: 6| Step: 11
Training loss: 3.1647125706621804
Validation loss: 2.56865143179264

Epoch: 6| Step: 12
Training loss: 3.2160455397233134
Validation loss: 2.597211028749017

Epoch: 6| Step: 13
Training loss: 2.353214330104813
Validation loss: 2.617799485390908

Epoch: 170| Step: 0
Training loss: 2.955065216016087
Validation loss: 2.5986539686438666

Epoch: 6| Step: 1
Training loss: 3.1263348589472235
Validation loss: 2.5960476618553248

Epoch: 6| Step: 2
Training loss: 2.4045481422699053
Validation loss: 2.5806957614524304

Epoch: 6| Step: 3
Training loss: 2.662595999692887
Validation loss: 2.544416517254382

Epoch: 6| Step: 4
Training loss: 2.8501692203008906
Validation loss: 2.552010840833939

Epoch: 6| Step: 5
Training loss: 3.542282828792777
Validation loss: 2.5411111058734974

Epoch: 6| Step: 6
Training loss: 2.8414871099429044
Validation loss: 2.5371606410425525

Epoch: 6| Step: 7
Training loss: 2.917215804221703
Validation loss: 2.5386202983870843

Epoch: 6| Step: 8
Training loss: 3.193732059674722
Validation loss: 2.54322977347125

Epoch: 6| Step: 9
Training loss: 2.8137184047068975
Validation loss: 2.5374292201430233

Epoch: 6| Step: 10
Training loss: 3.178126296321638
Validation loss: 2.5478522527510585

Epoch: 6| Step: 11
Training loss: 2.7595734849957876
Validation loss: 2.538488917786717

Epoch: 6| Step: 12
Training loss: 1.9987417673939822
Validation loss: 2.547138096592485

Epoch: 6| Step: 13
Training loss: 2.2197422441565515
Validation loss: 2.5510359147659276

Epoch: 171| Step: 0
Training loss: 3.0159269982161927
Validation loss: 2.5541507181725147

Epoch: 6| Step: 1
Training loss: 2.5042511082110104
Validation loss: 2.558830146480361

Epoch: 6| Step: 2
Training loss: 2.984358223273771
Validation loss: 2.5551784375193276

Epoch: 6| Step: 3
Training loss: 2.901888620417334
Validation loss: 2.5597000992787358

Epoch: 6| Step: 4
Training loss: 3.2286463328520765
Validation loss: 2.5500389591581105

Epoch: 6| Step: 5
Training loss: 2.226353257369351
Validation loss: 2.5414606599587013

Epoch: 6| Step: 6
Training loss: 2.9891799672361445
Validation loss: 2.5427760095947214

Epoch: 6| Step: 7
Training loss: 3.0301036436779953
Validation loss: 2.5350102400382273

Epoch: 6| Step: 8
Training loss: 2.5908616311078116
Validation loss: 2.5431434739301935

Epoch: 6| Step: 9
Training loss: 2.5250326022318967
Validation loss: 2.545512046282365

Epoch: 6| Step: 10
Training loss: 2.957759712018217
Validation loss: 2.5706048315410737

Epoch: 6| Step: 11
Training loss: 2.8305261019130064
Validation loss: 2.5733409671395524

Epoch: 6| Step: 12
Training loss: 3.5991898207829816
Validation loss: 2.5778700756276716

Epoch: 6| Step: 13
Training loss: 2.3305569434158664
Validation loss: 2.6037293379900084

Epoch: 172| Step: 0
Training loss: 2.9048456880485944
Validation loss: 2.6170043528596083

Epoch: 6| Step: 1
Training loss: 2.8707675463073703
Validation loss: 2.581934711712491

Epoch: 6| Step: 2
Training loss: 3.0654133543786757
Validation loss: 2.5955103131743025

Epoch: 6| Step: 3
Training loss: 2.4726712917937035
Validation loss: 2.5738851547786354

Epoch: 6| Step: 4
Training loss: 3.0067842385536006
Validation loss: 2.5726401237010093

Epoch: 6| Step: 5
Training loss: 2.8398916038458646
Validation loss: 2.54738601801197

Epoch: 6| Step: 6
Training loss: 2.524160275716196
Validation loss: 2.538073182323032

Epoch: 6| Step: 7
Training loss: 2.5771419616132163
Validation loss: 2.5428491064639376

Epoch: 6| Step: 8
Training loss: 2.8067305835172225
Validation loss: 2.5356614272057287

Epoch: 6| Step: 9
Training loss: 2.684903509583524
Validation loss: 2.5396178945171783

Epoch: 6| Step: 10
Training loss: 2.7270412953757357
Validation loss: 2.52872782457135

Epoch: 6| Step: 11
Training loss: 3.415297784514431
Validation loss: 2.5361038020542384

Epoch: 6| Step: 12
Training loss: 2.6642625123952848
Validation loss: 2.538813450212669

Epoch: 6| Step: 13
Training loss: 3.7165318132463323
Validation loss: 2.5378583578556184

Epoch: 173| Step: 0
Training loss: 2.404868782254716
Validation loss: 2.538327454596837

Epoch: 6| Step: 1
Training loss: 2.7949119796950965
Validation loss: 2.538087749562228

Epoch: 6| Step: 2
Training loss: 2.552978317174642
Validation loss: 2.544935057217812

Epoch: 6| Step: 3
Training loss: 2.3960714691787883
Validation loss: 2.553874115340263

Epoch: 6| Step: 4
Training loss: 3.358400141301545
Validation loss: 2.5534218986778043

Epoch: 6| Step: 5
Training loss: 3.2402042067895622
Validation loss: 2.561546710114194

Epoch: 6| Step: 6
Training loss: 2.5485754596689323
Validation loss: 2.562204264361245

Epoch: 6| Step: 7
Training loss: 2.6360312688822383
Validation loss: 2.5403591553789155

Epoch: 6| Step: 8
Training loss: 3.3581039508136454
Validation loss: 2.5408029371337815

Epoch: 6| Step: 9
Training loss: 2.7921718500912323
Validation loss: 2.540739963370704

Epoch: 6| Step: 10
Training loss: 2.8332377211950015
Validation loss: 2.536196260511

Epoch: 6| Step: 11
Training loss: 3.3193136709958524
Validation loss: 2.5343983469746845

Epoch: 6| Step: 12
Training loss: 2.863482417472784
Validation loss: 2.538595501254841

Epoch: 6| Step: 13
Training loss: 2.636761700315694
Validation loss: 2.537084393341701

Epoch: 174| Step: 0
Training loss: 2.7330647844493763
Validation loss: 2.540433407618888

Epoch: 6| Step: 1
Training loss: 2.629771120098478
Validation loss: 2.5472628053280633

Epoch: 6| Step: 2
Training loss: 3.084749017086007
Validation loss: 2.5514605524251284

Epoch: 6| Step: 3
Training loss: 2.903387813765006
Validation loss: 2.5489344249889965

Epoch: 6| Step: 4
Training loss: 2.4301286401175415
Validation loss: 2.5584633629991873

Epoch: 6| Step: 5
Training loss: 2.8005956697364724
Validation loss: 2.5429094924929463

Epoch: 6| Step: 6
Training loss: 2.8717877230494118
Validation loss: 2.5468686484544465

Epoch: 6| Step: 7
Training loss: 2.352860710226705
Validation loss: 2.545911947966338

Epoch: 6| Step: 8
Training loss: 2.9912675284905483
Validation loss: 2.54304671246394

Epoch: 6| Step: 9
Training loss: 3.582782762206912
Validation loss: 2.538431573544603

Epoch: 6| Step: 10
Training loss: 3.014174512776133
Validation loss: 2.539410661250108

Epoch: 6| Step: 11
Training loss: 2.8054169367756994
Validation loss: 2.5485722880289

Epoch: 6| Step: 12
Training loss: 3.025406070913605
Validation loss: 2.5451133096377814

Epoch: 6| Step: 13
Training loss: 2.2397606239820536
Validation loss: 2.5643227080155215

Epoch: 175| Step: 0
Training loss: 2.7127217074729253
Validation loss: 2.5616486328363637

Epoch: 6| Step: 1
Training loss: 2.816054831496603
Validation loss: 2.5679572935559585

Epoch: 6| Step: 2
Training loss: 3.263057739990845
Validation loss: 2.575124338407433

Epoch: 6| Step: 3
Training loss: 2.717277742086134
Validation loss: 2.5790998547983204

Epoch: 6| Step: 4
Training loss: 2.646899831896321
Validation loss: 2.565372123025432

Epoch: 6| Step: 5
Training loss: 3.1751529686791025
Validation loss: 2.54451998303122

Epoch: 6| Step: 6
Training loss: 2.689086179834046
Validation loss: 2.519353828183391

Epoch: 6| Step: 7
Training loss: 2.5468398951820026
Validation loss: 2.521575086038768

Epoch: 6| Step: 8
Training loss: 2.4504157978591024
Validation loss: 2.5233313532033512

Epoch: 6| Step: 9
Training loss: 3.1568537974924773
Validation loss: 2.5249734761199307

Epoch: 6| Step: 10
Training loss: 3.264532755297854
Validation loss: 2.521532528377276

Epoch: 6| Step: 11
Training loss: 2.7097189855390575
Validation loss: 2.52575018955678

Epoch: 6| Step: 12
Training loss: 2.416453538463392
Validation loss: 2.5249827997301444

Epoch: 6| Step: 13
Training loss: 3.7100871507222832
Validation loss: 2.52195902719474

Epoch: 176| Step: 0
Training loss: 2.7637539153845565
Validation loss: 2.5216188111299305

Epoch: 6| Step: 1
Training loss: 3.01116170320633
Validation loss: 2.5205279929533084

Epoch: 6| Step: 2
Training loss: 2.615449333900522
Validation loss: 2.523507535340941

Epoch: 6| Step: 3
Training loss: 2.9589618140641565
Validation loss: 2.5150428525898305

Epoch: 6| Step: 4
Training loss: 2.670087785456399
Validation loss: 2.52761132038813

Epoch: 6| Step: 5
Training loss: 2.5210622468108403
Validation loss: 2.5271973378669528

Epoch: 6| Step: 6
Training loss: 2.8547803307249993
Validation loss: 2.5341994545839586

Epoch: 6| Step: 7
Training loss: 3.2588373488706126
Validation loss: 2.5370965765158235

Epoch: 6| Step: 8
Training loss: 3.107664931961891
Validation loss: 2.5488707599870204

Epoch: 6| Step: 9
Training loss: 2.6037617686532673
Validation loss: 2.5467785232483138

Epoch: 6| Step: 10
Training loss: 2.7159066952955637
Validation loss: 2.554384249005123

Epoch: 6| Step: 11
Training loss: 2.860360397893063
Validation loss: 2.576653764204215

Epoch: 6| Step: 12
Training loss: 3.18750299191802
Validation loss: 2.5807572744868286

Epoch: 6| Step: 13
Training loss: 2.378345642681743
Validation loss: 2.5822213889619867

Epoch: 177| Step: 0
Training loss: 3.234884323339582
Validation loss: 2.5806644376488594

Epoch: 6| Step: 1
Training loss: 2.6921900257136384
Validation loss: 2.558504220184703

Epoch: 6| Step: 2
Training loss: 3.0940428315880135
Validation loss: 2.5493377127103707

Epoch: 6| Step: 3
Training loss: 1.5405314449975123
Validation loss: 2.534458128174764

Epoch: 6| Step: 4
Training loss: 3.2629029825315197
Validation loss: 2.5290177768751416

Epoch: 6| Step: 5
Training loss: 3.0658141907031
Validation loss: 2.5246414243082844

Epoch: 6| Step: 6
Training loss: 2.7442308078486413
Validation loss: 2.526344204237252

Epoch: 6| Step: 7
Training loss: 2.6114357674324555
Validation loss: 2.520205899079637

Epoch: 6| Step: 8
Training loss: 2.6437888068198485
Validation loss: 2.520600722003205

Epoch: 6| Step: 9
Training loss: 3.1450069091429875
Validation loss: 2.527448890457911

Epoch: 6| Step: 10
Training loss: 2.955923056719937
Validation loss: 2.5311049289775465

Epoch: 6| Step: 11
Training loss: 2.8069072641859742
Validation loss: 2.5363219085233744

Epoch: 6| Step: 12
Training loss: 3.0121059935665433
Validation loss: 2.526885475637211

Epoch: 6| Step: 13
Training loss: 2.6548994333362517
Validation loss: 2.5314589737880446

Epoch: 178| Step: 0
Training loss: 3.0187055438383505
Validation loss: 2.5686167663141175

Epoch: 6| Step: 1
Training loss: 2.846005561796371
Validation loss: 2.6307022763189774

Epoch: 6| Step: 2
Training loss: 2.7056991580379686
Validation loss: 2.6827216656232693

Epoch: 6| Step: 3
Training loss: 2.374258829213476
Validation loss: 2.6533403968433595

Epoch: 6| Step: 4
Training loss: 2.4324391964941516
Validation loss: 2.6275119150432764

Epoch: 6| Step: 5
Training loss: 2.7398722294441393
Validation loss: 2.588285868841515

Epoch: 6| Step: 6
Training loss: 3.019702427837145
Validation loss: 2.5725640575974715

Epoch: 6| Step: 7
Training loss: 2.6678223688453144
Validation loss: 2.556374499532548

Epoch: 6| Step: 8
Training loss: 3.3049721741767386
Validation loss: 2.5562143746894295

Epoch: 6| Step: 9
Training loss: 2.664047017430038
Validation loss: 2.53333228321194

Epoch: 6| Step: 10
Training loss: 2.9946226564345553
Validation loss: 2.533748138890211

Epoch: 6| Step: 11
Training loss: 2.6651448934361963
Validation loss: 2.53625282037369

Epoch: 6| Step: 12
Training loss: 3.26186274593264
Validation loss: 2.5277055631402026

Epoch: 6| Step: 13
Training loss: 3.1873789745617054
Validation loss: 2.5325453570905805

Epoch: 179| Step: 0
Training loss: 3.047286255298067
Validation loss: 2.5361163113902507

Epoch: 6| Step: 1
Training loss: 3.273355196188993
Validation loss: 2.52663033800889

Epoch: 6| Step: 2
Training loss: 2.5496394594409675
Validation loss: 2.536744008768687

Epoch: 6| Step: 3
Training loss: 2.907145372512174
Validation loss: 2.5412969987792278

Epoch: 6| Step: 4
Training loss: 2.598792632075759
Validation loss: 2.5425484887817027

Epoch: 6| Step: 5
Training loss: 3.269379570107683
Validation loss: 2.553438005830726

Epoch: 6| Step: 6
Training loss: 2.555084664272705
Validation loss: 2.5562685330011923

Epoch: 6| Step: 7
Training loss: 2.2484398837206134
Validation loss: 2.562792036301517

Epoch: 6| Step: 8
Training loss: 1.8479402416607706
Validation loss: 2.572517660674257

Epoch: 6| Step: 9
Training loss: 3.0586745055391167
Validation loss: 2.594548499454487

Epoch: 6| Step: 10
Training loss: 3.1136089999610856
Validation loss: 2.6114082473542255

Epoch: 6| Step: 11
Training loss: 2.807279276540352
Validation loss: 2.6154144339570795

Epoch: 6| Step: 12
Training loss: 3.4289587545731672
Validation loss: 2.623056016159204

Epoch: 6| Step: 13
Training loss: 2.601974133983829
Validation loss: 2.6182175151142593

Epoch: 180| Step: 0
Training loss: 2.6947319843027286
Validation loss: 2.584148057871143

Epoch: 6| Step: 1
Training loss: 3.0994581487309785
Validation loss: 2.5463370253196604

Epoch: 6| Step: 2
Training loss: 3.3791530629239714
Validation loss: 2.5399135781861912

Epoch: 6| Step: 3
Training loss: 2.021112468619529
Validation loss: 2.5385490974997738

Epoch: 6| Step: 4
Training loss: 2.715801876791526
Validation loss: 2.5338476199262687

Epoch: 6| Step: 5
Training loss: 2.57442324206741
Validation loss: 2.534380978805

Epoch: 6| Step: 6
Training loss: 3.3184697321996763
Validation loss: 2.5286814146196765

Epoch: 6| Step: 7
Training loss: 2.5718114128919805
Validation loss: 2.5305391318909467

Epoch: 6| Step: 8
Training loss: 2.1617455594213624
Validation loss: 2.520093812592888

Epoch: 6| Step: 9
Training loss: 2.757356341191608
Validation loss: 2.523865932905766

Epoch: 6| Step: 10
Training loss: 3.1643714283021334
Validation loss: 2.5294895712088974

Epoch: 6| Step: 11
Training loss: 3.2169992074061287
Validation loss: 2.534216648989071

Epoch: 6| Step: 12
Training loss: 3.136502877261914
Validation loss: 2.548629820040077

Epoch: 6| Step: 13
Training loss: 2.4841550333782307
Validation loss: 2.5778176112931583

Epoch: 181| Step: 0
Training loss: 3.218821996976188
Validation loss: 2.564886001263345

Epoch: 6| Step: 1
Training loss: 2.795451563899106
Validation loss: 2.63184734210129

Epoch: 6| Step: 2
Training loss: 2.4966583807298024
Validation loss: 2.6380304263224894

Epoch: 6| Step: 3
Training loss: 3.137842872395892
Validation loss: 2.668405501082186

Epoch: 6| Step: 4
Training loss: 2.729034964220411
Validation loss: 2.6478671992534335

Epoch: 6| Step: 5
Training loss: 2.5620717877135974
Validation loss: 2.5945155485072173

Epoch: 6| Step: 6
Training loss: 3.384084977591296
Validation loss: 2.5661111953210414

Epoch: 6| Step: 7
Training loss: 2.59349830968922
Validation loss: 2.53065367733268

Epoch: 6| Step: 8
Training loss: 2.975919398723728
Validation loss: 2.5270351085720035

Epoch: 6| Step: 9
Training loss: 2.459166261764936
Validation loss: 2.533428701290668

Epoch: 6| Step: 10
Training loss: 3.2158336575413964
Validation loss: 2.5275661329269

Epoch: 6| Step: 11
Training loss: 2.784434092501494
Validation loss: 2.529566871788859

Epoch: 6| Step: 12
Training loss: 1.92218387261701
Validation loss: 2.5329746886506705

Epoch: 6| Step: 13
Training loss: 3.7702728332633506
Validation loss: 2.533297942998646

Epoch: 182| Step: 0
Training loss: 2.164696776055063
Validation loss: 2.532237476210055

Epoch: 6| Step: 1
Training loss: 2.771050427950232
Validation loss: 2.5384162811239457

Epoch: 6| Step: 2
Training loss: 2.8107868487120866
Validation loss: 2.528892769560083

Epoch: 6| Step: 3
Training loss: 3.237680708507134
Validation loss: 2.5361156937590277

Epoch: 6| Step: 4
Training loss: 2.803280278118474
Validation loss: 2.543274080849111

Epoch: 6| Step: 5
Training loss: 3.0742745885176666
Validation loss: 2.5315895344051897

Epoch: 6| Step: 6
Training loss: 3.1554830393570366
Validation loss: 2.5445642891006655

Epoch: 6| Step: 7
Training loss: 3.018868397035652
Validation loss: 2.5454870091116626

Epoch: 6| Step: 8
Training loss: 3.021323241047222
Validation loss: 2.5622247367498883

Epoch: 6| Step: 9
Training loss: 2.943988856771361
Validation loss: 2.579652187631209

Epoch: 6| Step: 10
Training loss: 2.862535741324696
Validation loss: 2.581956229074825

Epoch: 6| Step: 11
Training loss: 2.725932313511148
Validation loss: 2.599134840953603

Epoch: 6| Step: 12
Training loss: 2.0892531656750464
Validation loss: 2.5835278034614153

Epoch: 6| Step: 13
Training loss: 3.41298772100279
Validation loss: 2.6013401725695515

Epoch: 183| Step: 0
Training loss: 2.6259059251028463
Validation loss: 2.567279412349205

Epoch: 6| Step: 1
Training loss: 3.302959594627254
Validation loss: 2.535857527920795

Epoch: 6| Step: 2
Training loss: 3.12931601975989
Validation loss: 2.5218521594303622

Epoch: 6| Step: 3
Training loss: 2.353869855506327
Validation loss: 2.52045417296264

Epoch: 6| Step: 4
Training loss: 2.6549947128674294
Validation loss: 2.5231269775661844

Epoch: 6| Step: 5
Training loss: 3.026306525942943
Validation loss: 2.5251395648409236

Epoch: 6| Step: 6
Training loss: 2.800510366792839
Validation loss: 2.526555421371468

Epoch: 6| Step: 7
Training loss: 3.0805154416180685
Validation loss: 2.524203846338522

Epoch: 6| Step: 8
Training loss: 3.1716281437768616
Validation loss: 2.5216086576799084

Epoch: 6| Step: 9
Training loss: 2.78148992982283
Validation loss: 2.5290302857817593

Epoch: 6| Step: 10
Training loss: 2.2362313195477714
Validation loss: 2.5322694192959267

Epoch: 6| Step: 11
Training loss: 3.0336508141120806
Validation loss: 2.5309677229957277

Epoch: 6| Step: 12
Training loss: 3.1026365020503097
Validation loss: 2.5335148551470414

Epoch: 6| Step: 13
Training loss: 2.3213232645316357
Validation loss: 2.5384691477478736

Epoch: 184| Step: 0
Training loss: 3.150485373749569
Validation loss: 2.5580637819048353

Epoch: 6| Step: 1
Training loss: 2.7071608034869814
Validation loss: 2.5778678121898424

Epoch: 6| Step: 2
Training loss: 2.900890535884469
Validation loss: 2.6010455802614594

Epoch: 6| Step: 3
Training loss: 2.3661871581037905
Validation loss: 2.661337960750019

Epoch: 6| Step: 4
Training loss: 3.29591767934198
Validation loss: 2.694214547148867

Epoch: 6| Step: 5
Training loss: 2.815012424231531
Validation loss: 2.717890191296765

Epoch: 6| Step: 6
Training loss: 2.706459766742181
Validation loss: 2.658956278534883

Epoch: 6| Step: 7
Training loss: 3.3454827783358265
Validation loss: 2.6477696260924164

Epoch: 6| Step: 8
Training loss: 3.1847477418661105
Validation loss: 2.583728986908345

Epoch: 6| Step: 9
Training loss: 2.7306898297703333
Validation loss: 2.5513449053672956

Epoch: 6| Step: 10
Training loss: 2.7503773690440476
Validation loss: 2.530291879466035

Epoch: 6| Step: 11
Training loss: 2.577434192931098
Validation loss: 2.518068547820123

Epoch: 6| Step: 12
Training loss: 2.181483031670946
Validation loss: 2.515317919146197

Epoch: 6| Step: 13
Training loss: 3.363079494756155
Validation loss: 2.521352700881909

Epoch: 185| Step: 0
Training loss: 2.6581670687190013
Validation loss: 2.5198941930189607

Epoch: 6| Step: 1
Training loss: 3.0347515214387815
Validation loss: 2.5155714864101952

Epoch: 6| Step: 2
Training loss: 3.383999728516191
Validation loss: 2.5216006219175755

Epoch: 6| Step: 3
Training loss: 3.0939851921925605
Validation loss: 2.5207721625153607

Epoch: 6| Step: 4
Training loss: 2.4099631456271795
Validation loss: 2.5244505424241472

Epoch: 6| Step: 5
Training loss: 3.5267480830966615
Validation loss: 2.5375827179544275

Epoch: 6| Step: 6
Training loss: 2.489709848251198
Validation loss: 2.5215968866620444

Epoch: 6| Step: 7
Training loss: 2.8863609412255125
Validation loss: 2.5381923692156634

Epoch: 6| Step: 8
Training loss: 3.1937829719528588
Validation loss: 2.5370376911374897

Epoch: 6| Step: 9
Training loss: 2.7238895463494237
Validation loss: 2.537609823321442

Epoch: 6| Step: 10
Training loss: 2.68790982692331
Validation loss: 2.521470534368625

Epoch: 6| Step: 11
Training loss: 2.1969614589819724
Validation loss: 2.5263515988044447

Epoch: 6| Step: 12
Training loss: 2.8662511975451834
Validation loss: 2.5289186137244495

Epoch: 6| Step: 13
Training loss: 2.174422930753608
Validation loss: 2.528230214601266

Epoch: 186| Step: 0
Training loss: 3.2522660205137703
Validation loss: 2.531244990704541

Epoch: 6| Step: 1
Training loss: 3.2130884544432727
Validation loss: 2.536147766917039

Epoch: 6| Step: 2
Training loss: 2.3237067163467446
Validation loss: 2.54137520116629

Epoch: 6| Step: 3
Training loss: 3.3280568003942466
Validation loss: 2.5483440604131973

Epoch: 6| Step: 4
Training loss: 3.0127609962957203
Validation loss: 2.5890569808833503

Epoch: 6| Step: 5
Training loss: 3.3143187514194743
Validation loss: 2.6074898148394796

Epoch: 6| Step: 6
Training loss: 2.688723263574356
Validation loss: 2.5885042541207546

Epoch: 6| Step: 7
Training loss: 2.740744186471753
Validation loss: 2.5824445617365135

Epoch: 6| Step: 8
Training loss: 2.5537936545518507
Validation loss: 2.582989437251067

Epoch: 6| Step: 9
Training loss: 3.1373877091089755
Validation loss: 2.5879804735303105

Epoch: 6| Step: 10
Training loss: 1.9920039073645328
Validation loss: 2.546769246212673

Epoch: 6| Step: 11
Training loss: 2.467176104682954
Validation loss: 2.5333638805734613

Epoch: 6| Step: 12
Training loss: 2.923692107620283
Validation loss: 2.52821887291859

Epoch: 6| Step: 13
Training loss: 2.1743894882136128
Validation loss: 2.519618098829013

Epoch: 187| Step: 0
Training loss: 3.045411056560012
Validation loss: 2.5166675473772395

Epoch: 6| Step: 1
Training loss: 3.037330585040869
Validation loss: 2.521731039256786

Epoch: 6| Step: 2
Training loss: 3.211105602161415
Validation loss: 2.519254452546472

Epoch: 6| Step: 3
Training loss: 2.3424424656791656
Validation loss: 2.518206811918028

Epoch: 6| Step: 4
Training loss: 2.3987275485627557
Validation loss: 2.518246590582174

Epoch: 6| Step: 5
Training loss: 2.9701672835072106
Validation loss: 2.52230590452127

Epoch: 6| Step: 6
Training loss: 2.552008761399874
Validation loss: 2.517715961894924

Epoch: 6| Step: 7
Training loss: 2.4295892726263197
Validation loss: 2.522742165432365

Epoch: 6| Step: 8
Training loss: 2.915322693487897
Validation loss: 2.5202814367716364

Epoch: 6| Step: 9
Training loss: 2.988468578176626
Validation loss: 2.522234495161504

Epoch: 6| Step: 10
Training loss: 3.5756439536008564
Validation loss: 2.5246457034001106

Epoch: 6| Step: 11
Training loss: 2.1741961692873866
Validation loss: 2.5360137218935987

Epoch: 6| Step: 12
Training loss: 3.065423309815363
Validation loss: 2.5490680530578342

Epoch: 6| Step: 13
Training loss: 2.6317308507544968
Validation loss: 2.593359739810941

Epoch: 188| Step: 0
Training loss: 3.187718103464188
Validation loss: 2.612697776589036

Epoch: 6| Step: 1
Training loss: 2.614503127206554
Validation loss: 2.6657125402987396

Epoch: 6| Step: 2
Training loss: 2.3041170093044143
Validation loss: 2.6432101667832537

Epoch: 6| Step: 3
Training loss: 2.690944327479889
Validation loss: 2.681303829019264

Epoch: 6| Step: 4
Training loss: 3.13948744484204
Validation loss: 2.6408559697332743

Epoch: 6| Step: 5
Training loss: 2.785152226641773
Validation loss: 2.573980093637205

Epoch: 6| Step: 6
Training loss: 2.639138791035744
Validation loss: 2.5527972015071927

Epoch: 6| Step: 7
Training loss: 2.517690627941102
Validation loss: 2.5434202690567886

Epoch: 6| Step: 8
Training loss: 3.741491838433299
Validation loss: 2.5419795870657254

Epoch: 6| Step: 9
Training loss: 3.2246463433866652
Validation loss: 2.539833929785466

Epoch: 6| Step: 10
Training loss: 2.4913946821937665
Validation loss: 2.5249649383310175

Epoch: 6| Step: 11
Training loss: 2.7422066277600337
Validation loss: 2.528674259539057

Epoch: 6| Step: 12
Training loss: 3.0020639948825405
Validation loss: 2.5212278143026485

Epoch: 6| Step: 13
Training loss: 2.565443999472355
Validation loss: 2.526492472997564

Epoch: 189| Step: 0
Training loss: 3.033020131915624
Validation loss: 2.520345260435374

Epoch: 6| Step: 1
Training loss: 2.470005343968097
Validation loss: 2.5241692448258233

Epoch: 6| Step: 2
Training loss: 2.93004457459378
Validation loss: 2.5218970680676662

Epoch: 6| Step: 3
Training loss: 2.5799282356749598
Validation loss: 2.517722411422684

Epoch: 6| Step: 4
Training loss: 2.533277947255401
Validation loss: 2.51786202936444

Epoch: 6| Step: 5
Training loss: 3.2063460367256935
Validation loss: 2.516786234307368

Epoch: 6| Step: 6
Training loss: 3.3081377203801465
Validation loss: 2.5152579837072007

Epoch: 6| Step: 7
Training loss: 2.7679063256460235
Validation loss: 2.5307040722808356

Epoch: 6| Step: 8
Training loss: 3.451104448973489
Validation loss: 2.5367051406866636

Epoch: 6| Step: 9
Training loss: 2.771495472278919
Validation loss: 2.5436851203543602

Epoch: 6| Step: 10
Training loss: 2.6070435667447196
Validation loss: 2.5446913615118603

Epoch: 6| Step: 11
Training loss: 2.597182794318115
Validation loss: 2.5500093529079515

Epoch: 6| Step: 12
Training loss: 2.667551748100941
Validation loss: 2.5435797650986047

Epoch: 6| Step: 13
Training loss: 2.562194712991957
Validation loss: 2.548973976569782

Epoch: 190| Step: 0
Training loss: 3.004631917184478
Validation loss: 2.5622324900202953

Epoch: 6| Step: 1
Training loss: 2.4086231567686176
Validation loss: 2.5653874246450252

Epoch: 6| Step: 2
Training loss: 3.1279609385634455
Validation loss: 2.582656335659029

Epoch: 6| Step: 3
Training loss: 2.5759304069394546
Validation loss: 2.605008097574173

Epoch: 6| Step: 4
Training loss: 2.547175103041446
Validation loss: 2.6160202820133307

Epoch: 6| Step: 5
Training loss: 3.6327821791829416
Validation loss: 2.611090343066641

Epoch: 6| Step: 6
Training loss: 2.5500840640703757
Validation loss: 2.596593421802259

Epoch: 6| Step: 7
Training loss: 3.371902457223559
Validation loss: 2.6021113318264706

Epoch: 6| Step: 8
Training loss: 3.2136373562325056
Validation loss: 2.5904522403720187

Epoch: 6| Step: 9
Training loss: 2.72229737115359
Validation loss: 2.573098293385446

Epoch: 6| Step: 10
Training loss: 2.356223825162609
Validation loss: 2.5535731711908296

Epoch: 6| Step: 11
Training loss: 2.5669425044113026
Validation loss: 2.548668931248532

Epoch: 6| Step: 12
Training loss: 2.8523665457289753
Validation loss: 2.527167060278706

Epoch: 6| Step: 13
Training loss: 2.1637910197494667
Validation loss: 2.5235708141729645

Epoch: 191| Step: 0
Training loss: 2.3882362548662597
Validation loss: 2.5256311037096357

Epoch: 6| Step: 1
Training loss: 3.0771374352687313
Validation loss: 2.5252904849351876

Epoch: 6| Step: 2
Training loss: 3.0377184879544954
Validation loss: 2.5223658595013054

Epoch: 6| Step: 3
Training loss: 2.532051053862792
Validation loss: 2.5218440908970035

Epoch: 6| Step: 4
Training loss: 2.6623995336642223
Validation loss: 2.5320735221217414

Epoch: 6| Step: 5
Training loss: 3.043503837892617
Validation loss: 2.5279254610631843

Epoch: 6| Step: 6
Training loss: 2.7593252555536614
Validation loss: 2.5303227103396986

Epoch: 6| Step: 7
Training loss: 2.831007358014601
Validation loss: 2.534961149835408

Epoch: 6| Step: 8
Training loss: 3.30789771747331
Validation loss: 2.5188336717285713

Epoch: 6| Step: 9
Training loss: 2.513498485545758
Validation loss: 2.520480261816336

Epoch: 6| Step: 10
Training loss: 2.6425515996104982
Validation loss: 2.5251092808534006

Epoch: 6| Step: 11
Training loss: 2.783420872786923
Validation loss: 2.527386847831314

Epoch: 6| Step: 12
Training loss: 2.9129129141647563
Validation loss: 2.5248838548032144

Epoch: 6| Step: 13
Training loss: 3.252741610960037
Validation loss: 2.52243355348497

Epoch: 192| Step: 0
Training loss: 2.756329707855093
Validation loss: 2.5397877121788444

Epoch: 6| Step: 1
Training loss: 2.6994272860890476
Validation loss: 2.564167403631077

Epoch: 6| Step: 2
Training loss: 2.7749640763165586
Validation loss: 2.564564843159164

Epoch: 6| Step: 3
Training loss: 2.920326189608095
Validation loss: 2.5760149512505777

Epoch: 6| Step: 4
Training loss: 2.664960693012243
Validation loss: 2.5632847290453515

Epoch: 6| Step: 5
Training loss: 2.947243783312457
Validation loss: 2.5634476364855465

Epoch: 6| Step: 6
Training loss: 3.070866580888396
Validation loss: 2.5656211407443195

Epoch: 6| Step: 7
Training loss: 3.3850141237040328
Validation loss: 2.528967114156908

Epoch: 6| Step: 8
Training loss: 2.906322191223681
Validation loss: 2.5307441022563917

Epoch: 6| Step: 9
Training loss: 2.7921161764179416
Validation loss: 2.5217678934730983

Epoch: 6| Step: 10
Training loss: 2.3006722338614716
Validation loss: 2.522561938893349

Epoch: 6| Step: 11
Training loss: 2.7761033691267083
Validation loss: 2.522330189971478

Epoch: 6| Step: 12
Training loss: 2.7933980971895727
Validation loss: 2.528703542775948

Epoch: 6| Step: 13
Training loss: 2.418233188349474
Validation loss: 2.559718063828852

Epoch: 193| Step: 0
Training loss: 2.7323919462319552
Validation loss: 2.5556192566986096

Epoch: 6| Step: 1
Training loss: 2.4042516560024714
Validation loss: 2.558429669734225

Epoch: 6| Step: 2
Training loss: 2.937375816804508
Validation loss: 2.5490297751879796

Epoch: 6| Step: 3
Training loss: 2.546244350121831
Validation loss: 2.5529575939016844

Epoch: 6| Step: 4
Training loss: 2.8790496831848995
Validation loss: 2.5629245967535814

Epoch: 6| Step: 5
Training loss: 1.9660390930169716
Validation loss: 2.5559309068783462

Epoch: 6| Step: 6
Training loss: 3.0701338932027675
Validation loss: 2.560593189473209

Epoch: 6| Step: 7
Training loss: 3.061405219757042
Validation loss: 2.5668808860328505

Epoch: 6| Step: 8
Training loss: 2.3921972353068766
Validation loss: 2.573528997273531

Epoch: 6| Step: 9
Training loss: 2.8441537423729235
Validation loss: 2.5739931170790826

Epoch: 6| Step: 10
Training loss: 3.3132349314619347
Validation loss: 2.5965327766122988

Epoch: 6| Step: 11
Training loss: 3.2379590508061193
Validation loss: 2.597722901765941

Epoch: 6| Step: 12
Training loss: 2.797372954810142
Validation loss: 2.583435321214423

Epoch: 6| Step: 13
Training loss: 3.239897652410598
Validation loss: 2.5436106808324226

Epoch: 194| Step: 0
Training loss: 2.323952026449822
Validation loss: 2.5317092209543235

Epoch: 6| Step: 1
Training loss: 2.832583964114272
Validation loss: 2.5146991185338687

Epoch: 6| Step: 2
Training loss: 2.8887408740280383
Validation loss: 2.511641460475973

Epoch: 6| Step: 3
Training loss: 2.834328102808946
Validation loss: 2.5186405653689006

Epoch: 6| Step: 4
Training loss: 3.4036552975831182
Validation loss: 2.5146474506405307

Epoch: 6| Step: 5
Training loss: 3.0002619311109218
Validation loss: 2.5149198550298157

Epoch: 6| Step: 6
Training loss: 2.128581450997418
Validation loss: 2.5198462026532185

Epoch: 6| Step: 7
Training loss: 2.5523118104970894
Validation loss: 2.515987538520791

Epoch: 6| Step: 8
Training loss: 3.1350639034979992
Validation loss: 2.517195762340184

Epoch: 6| Step: 9
Training loss: 2.9117918602577655
Validation loss: 2.530683959805422

Epoch: 6| Step: 10
Training loss: 2.848059103770379
Validation loss: 2.533814993555542

Epoch: 6| Step: 11
Training loss: 3.1324834103765307
Validation loss: 2.5501008698846976

Epoch: 6| Step: 12
Training loss: 2.491868623524916
Validation loss: 2.594717649560106

Epoch: 6| Step: 13
Training loss: 2.99347007892234
Validation loss: 2.5964021186565267

Epoch: 195| Step: 0
Training loss: 2.3371145287568007
Validation loss: 2.587312973045695

Epoch: 6| Step: 1
Training loss: 2.780981072271927
Validation loss: 2.6259540244231037

Epoch: 6| Step: 2
Training loss: 3.6454103642296314
Validation loss: 2.684332841273775

Epoch: 6| Step: 3
Training loss: 2.8558147340838054
Validation loss: 2.681100527854262

Epoch: 6| Step: 4
Training loss: 3.106889507694939
Validation loss: 2.6688637552659236

Epoch: 6| Step: 5
Training loss: 2.888912374042352
Validation loss: 2.6839596465369873

Epoch: 6| Step: 6
Training loss: 2.9732278883273873
Validation loss: 2.6165555006932566

Epoch: 6| Step: 7
Training loss: 1.4119387110654757
Validation loss: 2.634805985919275

Epoch: 6| Step: 8
Training loss: 3.147164743034563
Validation loss: 2.605632036630877

Epoch: 6| Step: 9
Training loss: 2.8463235465470924
Validation loss: 2.591289849478055

Epoch: 6| Step: 10
Training loss: 2.657650387690397
Validation loss: 2.600450306525954

Epoch: 6| Step: 11
Training loss: 3.0074437299301695
Validation loss: 2.6133043800214644

Epoch: 6| Step: 12
Training loss: 2.930078098961805
Validation loss: 2.614143230280051

Epoch: 6| Step: 13
Training loss: 2.719452252072106
Validation loss: 2.5851065186530198

Epoch: 196| Step: 0
Training loss: 3.1556676950662235
Validation loss: 2.52598910102071

Epoch: 6| Step: 1
Training loss: 2.518795408686766
Validation loss: 2.509932435093823

Epoch: 6| Step: 2
Training loss: 2.901706219936196
Validation loss: 2.509304476469408

Epoch: 6| Step: 3
Training loss: 2.4648645463601193
Validation loss: 2.517747308236951

Epoch: 6| Step: 4
Training loss: 2.8258804772135324
Validation loss: 2.5197406828975124

Epoch: 6| Step: 5
Training loss: 2.710729233714726
Validation loss: 2.521940292523837

Epoch: 6| Step: 6
Training loss: 3.136864379694583
Validation loss: 2.5202631585647057

Epoch: 6| Step: 7
Training loss: 3.319391818584857
Validation loss: 2.519940993198791

Epoch: 6| Step: 8
Training loss: 2.907437153839758
Validation loss: 2.518019956586469

Epoch: 6| Step: 9
Training loss: 2.9797423191158794
Validation loss: 2.5195612276123334

Epoch: 6| Step: 10
Training loss: 2.8151534385262713
Validation loss: 2.5167575682313013

Epoch: 6| Step: 11
Training loss: 2.6490213206417113
Validation loss: 2.5114807649998245

Epoch: 6| Step: 12
Training loss: 2.8304811221006863
Validation loss: 2.513051214368698

Epoch: 6| Step: 13
Training loss: 2.8013217463022975
Validation loss: 2.521218831678552

Epoch: 197| Step: 0
Training loss: 3.045827988925599
Validation loss: 2.5461795042724473

Epoch: 6| Step: 1
Training loss: 3.0907717154058676
Validation loss: 2.582058824045653

Epoch: 6| Step: 2
Training loss: 3.0618313429196835
Validation loss: 2.6091131263502696

Epoch: 6| Step: 3
Training loss: 2.766895670394601
Validation loss: 2.629525966251695

Epoch: 6| Step: 4
Training loss: 2.2003832049848264
Validation loss: 2.6627886675608092

Epoch: 6| Step: 5
Training loss: 3.1700443190114975
Validation loss: 2.6933019676367547

Epoch: 6| Step: 6
Training loss: 2.354429303488064
Validation loss: 2.684387154706657

Epoch: 6| Step: 7
Training loss: 2.519784746059351
Validation loss: 2.6741488153920074

Epoch: 6| Step: 8
Training loss: 2.9366877630069936
Validation loss: 2.650219773675164

Epoch: 6| Step: 9
Training loss: 3.239154030831078
Validation loss: 2.6227432918386224

Epoch: 6| Step: 10
Training loss: 2.486050982135887
Validation loss: 2.596589890194764

Epoch: 6| Step: 11
Training loss: 2.8364052294858175
Validation loss: 2.5865186139896372

Epoch: 6| Step: 12
Training loss: 3.2271550629641332
Validation loss: 2.566863915426261

Epoch: 6| Step: 13
Training loss: 2.778502746921161
Validation loss: 2.5464686845894473

Epoch: 198| Step: 0
Training loss: 2.695201219113562
Validation loss: 2.542397837887152

Epoch: 6| Step: 1
Training loss: 2.368315575855464
Validation loss: 2.5331482023275282

Epoch: 6| Step: 2
Training loss: 2.6767861365817205
Validation loss: 2.5257923006096052

Epoch: 6| Step: 3
Training loss: 2.308207471517104
Validation loss: 2.5328036348196443

Epoch: 6| Step: 4
Training loss: 3.0469801664542593
Validation loss: 2.528999702713589

Epoch: 6| Step: 5
Training loss: 3.0518943719446328
Validation loss: 2.516919441407404

Epoch: 6| Step: 6
Training loss: 2.431437656250497
Validation loss: 2.5139995345812416

Epoch: 6| Step: 7
Training loss: 3.0699002908922806
Validation loss: 2.514239030885254

Epoch: 6| Step: 8
Training loss: 3.295084679634117
Validation loss: 2.513386378395045

Epoch: 6| Step: 9
Training loss: 2.677680239697125
Validation loss: 2.5062285603951935

Epoch: 6| Step: 10
Training loss: 3.173441683204407
Validation loss: 2.5088662498357692

Epoch: 6| Step: 11
Training loss: 3.2189473212044732
Validation loss: 2.5136498429718404

Epoch: 6| Step: 12
Training loss: 2.4716561511127506
Validation loss: 2.5146570092961222

Epoch: 6| Step: 13
Training loss: 3.0356542308861645
Validation loss: 2.537740374594858

Epoch: 199| Step: 0
Training loss: 2.7181008978130556
Validation loss: 2.545244225921681

Epoch: 6| Step: 1
Training loss: 2.1654755423800096
Validation loss: 2.545325081356527

Epoch: 6| Step: 2
Training loss: 2.6220813147173736
Validation loss: 2.5397253602787955

Epoch: 6| Step: 3
Training loss: 2.967320951541233
Validation loss: 2.5342436497459753

Epoch: 6| Step: 4
Training loss: 3.043441637778434
Validation loss: 2.5459339087405612

Epoch: 6| Step: 5
Training loss: 2.8102391798918935
Validation loss: 2.5610930479328253

Epoch: 6| Step: 6
Training loss: 2.3151426937872395
Validation loss: 2.5551695903007037

Epoch: 6| Step: 7
Training loss: 2.897956911123426
Validation loss: 2.5808696288691926

Epoch: 6| Step: 8
Training loss: 3.0299733413178207
Validation loss: 2.5850753712671857

Epoch: 6| Step: 9
Training loss: 3.2053171983409037
Validation loss: 2.592536161881738

Epoch: 6| Step: 10
Training loss: 2.973616456235805
Validation loss: 2.57915546833536

Epoch: 6| Step: 11
Training loss: 3.4725109709311655
Validation loss: 2.5959222511073112

Epoch: 6| Step: 12
Training loss: 2.546669606544968
Validation loss: 2.5557659314335104

Epoch: 6| Step: 13
Training loss: 2.3944448234555837
Validation loss: 2.524316787233966

Epoch: 200| Step: 0
Training loss: 2.4461360434302812
Validation loss: 2.5233599252960803

Epoch: 6| Step: 1
Training loss: 2.646040920814806
Validation loss: 2.5199287901575436

Epoch: 6| Step: 2
Training loss: 2.9525131318319544
Validation loss: 2.5113576327930813

Epoch: 6| Step: 3
Training loss: 2.585971152095281
Validation loss: 2.4973067389071364

Epoch: 6| Step: 4
Training loss: 2.4091914640153496
Validation loss: 2.4994919393974664

Epoch: 6| Step: 5
Training loss: 2.8514288884044507
Validation loss: 2.506335981819892

Epoch: 6| Step: 6
Training loss: 2.769710647949395
Validation loss: 2.5082126732996617

Epoch: 6| Step: 7
Training loss: 3.1473810965187603
Validation loss: 2.509955641155135

Epoch: 6| Step: 8
Training loss: 3.1757524214558686
Validation loss: 2.528772188353425

Epoch: 6| Step: 9
Training loss: 3.3159001012463136
Validation loss: 2.527360829003378

Epoch: 6| Step: 10
Training loss: 2.824710027615632
Validation loss: 2.5198323804932934

Epoch: 6| Step: 11
Training loss: 3.057779839623419
Validation loss: 2.5173034245707573

Epoch: 6| Step: 12
Training loss: 2.300630781502728
Validation loss: 2.5110098770606055

Epoch: 6| Step: 13
Training loss: 2.86480680576593
Validation loss: 2.520313208433143

Epoch: 201| Step: 0
Training loss: 3.4091532522338737
Validation loss: 2.527036372620699

Epoch: 6| Step: 1
Training loss: 2.423037145565264
Validation loss: 2.523801989023506

Epoch: 6| Step: 2
Training loss: 2.951985780283684
Validation loss: 2.530167772027949

Epoch: 6| Step: 3
Training loss: 2.400466309387083
Validation loss: 2.543857124473381

Epoch: 6| Step: 4
Training loss: 2.5359929236785645
Validation loss: 2.5343542637583685

Epoch: 6| Step: 5
Training loss: 2.741527597519793
Validation loss: 2.57068969859281

Epoch: 6| Step: 6
Training loss: 2.61801435020483
Validation loss: 2.554544228642564

Epoch: 6| Step: 7
Training loss: 3.214617696905164
Validation loss: 2.5683766411610693

Epoch: 6| Step: 8
Training loss: 2.184138303492748
Validation loss: 2.5733497822696108

Epoch: 6| Step: 9
Training loss: 2.8423822488275055
Validation loss: 2.5523122102636417

Epoch: 6| Step: 10
Training loss: 3.4355751890888393
Validation loss: 2.5623555046378463

Epoch: 6| Step: 11
Training loss: 2.799763812594026
Validation loss: 2.5533343010147167

Epoch: 6| Step: 12
Training loss: 2.9527116112778438
Validation loss: 2.53679542872936

Epoch: 6| Step: 13
Training loss: 2.6203669579339794
Validation loss: 2.530719350523668

Epoch: 202| Step: 0
Training loss: 2.809890384097232
Validation loss: 2.525689641952022

Epoch: 6| Step: 1
Training loss: 3.1799805152344107
Validation loss: 2.5145703597133036

Epoch: 6| Step: 2
Training loss: 2.5031681966685717
Validation loss: 2.5199927387272916

Epoch: 6| Step: 3
Training loss: 2.7955094738770563
Validation loss: 2.512556346158844

Epoch: 6| Step: 4
Training loss: 2.339828058104206
Validation loss: 2.50841641015793

Epoch: 6| Step: 5
Training loss: 3.100441218325388
Validation loss: 2.5141426905881405

Epoch: 6| Step: 6
Training loss: 2.696275268209915
Validation loss: 2.502377063963505

Epoch: 6| Step: 7
Training loss: 3.284595346363912
Validation loss: 2.5205865032509616

Epoch: 6| Step: 8
Training loss: 2.2171039116596307
Validation loss: 2.5280666014652877

Epoch: 6| Step: 9
Training loss: 2.697073629232065
Validation loss: 2.539035485867782

Epoch: 6| Step: 10
Training loss: 3.1974717285242593
Validation loss: 2.5717299871172528

Epoch: 6| Step: 11
Training loss: 2.8798944027403257
Validation loss: 2.567166372303666

Epoch: 6| Step: 12
Training loss: 2.3722435867137652
Validation loss: 2.553865071872052

Epoch: 6| Step: 13
Training loss: 3.316753607397978
Validation loss: 2.5419141553767184

Epoch: 203| Step: 0
Training loss: 3.061595238143292
Validation loss: 2.517305467495332

Epoch: 6| Step: 1
Training loss: 2.758357439963422
Validation loss: 2.514024032836591

Epoch: 6| Step: 2
Training loss: 2.529892074484368
Validation loss: 2.5100896315354686

Epoch: 6| Step: 3
Training loss: 2.802737267256783
Validation loss: 2.502453014844075

Epoch: 6| Step: 4
Training loss: 3.0392954916009916
Validation loss: 2.5090373559549715

Epoch: 6| Step: 5
Training loss: 2.9071686636092986
Validation loss: 2.501153713551916

Epoch: 6| Step: 6
Training loss: 2.685941732335598
Validation loss: 2.5020932857823044

Epoch: 6| Step: 7
Training loss: 2.7076535080834154
Validation loss: 2.503096244413022

Epoch: 6| Step: 8
Training loss: 2.7300352699321015
Validation loss: 2.5126630552731912

Epoch: 6| Step: 9
Training loss: 3.0265523159031034
Validation loss: 2.505557083913887

Epoch: 6| Step: 10
Training loss: 2.4456888220063715
Validation loss: 2.516949959402451

Epoch: 6| Step: 11
Training loss: 2.756784566305378
Validation loss: 2.5344283925144944

Epoch: 6| Step: 12
Training loss: 2.8713335624761456
Validation loss: 2.5240082235867827

Epoch: 6| Step: 13
Training loss: 3.1169745580462815
Validation loss: 2.558611972809386

Epoch: 204| Step: 0
Training loss: 2.6392188306526947
Validation loss: 2.5868811986364477

Epoch: 6| Step: 1
Training loss: 2.657435792019912
Validation loss: 2.5976210922488416

Epoch: 6| Step: 2
Training loss: 2.260416291642634
Validation loss: 2.634334864713482

Epoch: 6| Step: 3
Training loss: 2.9703021358848973
Validation loss: 2.6206009907485703

Epoch: 6| Step: 4
Training loss: 2.6056307123221782
Validation loss: 2.6236607875388698

Epoch: 6| Step: 5
Training loss: 3.164095654725985
Validation loss: 2.589982801970926

Epoch: 6| Step: 6
Training loss: 2.0510382790938713
Validation loss: 2.5865006938467068

Epoch: 6| Step: 7
Training loss: 3.2543577176392136
Validation loss: 2.6008108897837845

Epoch: 6| Step: 8
Training loss: 2.746228753321556
Validation loss: 2.5442450880164893

Epoch: 6| Step: 9
Training loss: 3.136357534852457
Validation loss: 2.528749743986089

Epoch: 6| Step: 10
Training loss: 2.807597401424846
Validation loss: 2.515153524152049

Epoch: 6| Step: 11
Training loss: 2.563796947984927
Validation loss: 2.5125216087294073

Epoch: 6| Step: 12
Training loss: 3.1529581258299806
Validation loss: 2.5092279258420542

Epoch: 6| Step: 13
Training loss: 2.966787070784903
Validation loss: 2.507014482450194

Epoch: 205| Step: 0
Training loss: 2.517080987420768
Validation loss: 2.498559370575686

Epoch: 6| Step: 1
Training loss: 2.3673962793721723
Validation loss: 2.500793342432826

Epoch: 6| Step: 2
Training loss: 3.615538779560234
Validation loss: 2.510020541404593

Epoch: 6| Step: 3
Training loss: 3.098431830465927
Validation loss: 2.5136520036030707

Epoch: 6| Step: 4
Training loss: 2.304712741519613
Validation loss: 2.5133168913196076

Epoch: 6| Step: 5
Training loss: 2.1330206353771697
Validation loss: 2.504234092978144

Epoch: 6| Step: 6
Training loss: 2.572447194705765
Validation loss: 2.517853370733746

Epoch: 6| Step: 7
Training loss: 3.113603333549244
Validation loss: 2.5049375504929077

Epoch: 6| Step: 8
Training loss: 2.634884615983151
Validation loss: 2.510344169862404

Epoch: 6| Step: 9
Training loss: 3.037323363391878
Validation loss: 2.5157907215202013

Epoch: 6| Step: 10
Training loss: 2.8931105366491803
Validation loss: 2.5119272074519747

Epoch: 6| Step: 11
Training loss: 3.1243776846178015
Validation loss: 2.5254041528017073

Epoch: 6| Step: 12
Training loss: 2.82379231590524
Validation loss: 2.5272152331945756

Epoch: 6| Step: 13
Training loss: 2.5314971426417068
Validation loss: 2.5422692037740475

Epoch: 206| Step: 0
Training loss: 2.8693370609022883
Validation loss: 2.5797152688729894

Epoch: 6| Step: 1
Training loss: 2.8173707958474234
Validation loss: 2.5544783038781795

Epoch: 6| Step: 2
Training loss: 2.9936051558653545
Validation loss: 2.546135634094308

Epoch: 6| Step: 3
Training loss: 2.3860989279307074
Validation loss: 2.5032250234984614

Epoch: 6| Step: 4
Training loss: 2.9632708934760856
Validation loss: 2.4891967449258248

Epoch: 6| Step: 5
Training loss: 3.1449541459129446
Validation loss: 2.4915683545721605

Epoch: 6| Step: 6
Training loss: 2.3214143647817673
Validation loss: 2.4870298531964785

Epoch: 6| Step: 7
Training loss: 2.9311415662413265
Validation loss: 2.4941435657209285

Epoch: 6| Step: 8
Training loss: 3.0526887642545955
Validation loss: 2.4921421125714343

Epoch: 6| Step: 9
Training loss: 2.718450069326076
Validation loss: 2.4922387632846075

Epoch: 6| Step: 10
Training loss: 2.394622253381347
Validation loss: 2.5017509122889368

Epoch: 6| Step: 11
Training loss: 3.1773446564477283
Validation loss: 2.4968461149351646

Epoch: 6| Step: 12
Training loss: 2.6013192644480183
Validation loss: 2.5134076859927665

Epoch: 6| Step: 13
Training loss: 3.3653847101232492
Validation loss: 2.5052545445282615

Epoch: 207| Step: 0
Training loss: 2.908426761675003
Validation loss: 2.5245931017491747

Epoch: 6| Step: 1
Training loss: 2.946826009656655
Validation loss: 2.5465700898232857

Epoch: 6| Step: 2
Training loss: 2.606093667736655
Validation loss: 2.581144722338981

Epoch: 6| Step: 3
Training loss: 2.5473952434889826
Validation loss: 2.5923195076982073

Epoch: 6| Step: 4
Training loss: 3.283423003958644
Validation loss: 2.6021578956539977

Epoch: 6| Step: 5
Training loss: 2.560249456828175
Validation loss: 2.592015858570044

Epoch: 6| Step: 6
Training loss: 3.0307973936724473
Validation loss: 2.585622100734459

Epoch: 6| Step: 7
Training loss: 2.715281850470838
Validation loss: 2.5418752997868106

Epoch: 6| Step: 8
Training loss: 2.508155870549452
Validation loss: 2.508294497089699

Epoch: 6| Step: 9
Training loss: 2.982393096005549
Validation loss: 2.5031099930722895

Epoch: 6| Step: 10
Training loss: 2.5947085528166856
Validation loss: 2.4920460774048614

Epoch: 6| Step: 11
Training loss: 3.1627230599486045
Validation loss: 2.493965697774525

Epoch: 6| Step: 12
Training loss: 2.5797018142016555
Validation loss: 2.494777180931087

Epoch: 6| Step: 13
Training loss: 3.360597184108487
Validation loss: 2.490657526426247

Epoch: 208| Step: 0
Training loss: 2.6828667379149946
Validation loss: 2.4897292455613695

Epoch: 6| Step: 1
Training loss: 2.7947974987066337
Validation loss: 2.4939063223750964

Epoch: 6| Step: 2
Training loss: 1.9797080119454573
Validation loss: 2.4910440860716614

Epoch: 6| Step: 3
Training loss: 3.1994269632813284
Validation loss: 2.5057365231285527

Epoch: 6| Step: 4
Training loss: 3.401416393781673
Validation loss: 2.517133935492218

Epoch: 6| Step: 5
Training loss: 2.86929003051902
Validation loss: 2.5245795472611103

Epoch: 6| Step: 6
Training loss: 2.592930583897096
Validation loss: 2.531599602761843

Epoch: 6| Step: 7
Training loss: 2.628155038414748
Validation loss: 2.5568285101347077

Epoch: 6| Step: 8
Training loss: 2.4233320221860226
Validation loss: 2.5782155110221896

Epoch: 6| Step: 9
Training loss: 3.268413320674976
Validation loss: 2.596537185047202

Epoch: 6| Step: 10
Training loss: 3.164375044845108
Validation loss: 2.6419542722487077

Epoch: 6| Step: 11
Training loss: 2.9529460872969593
Validation loss: 2.6374957746891696

Epoch: 6| Step: 12
Training loss: 2.50802525838882
Validation loss: 2.5953130794808814

Epoch: 6| Step: 13
Training loss: 3.077818879527478
Validation loss: 2.5773387675870407

Epoch: 209| Step: 0
Training loss: 2.6386300400608964
Validation loss: 2.5468255320131803

Epoch: 6| Step: 1
Training loss: 2.681933115478624
Validation loss: 2.533268133000684

Epoch: 6| Step: 2
Training loss: 2.6000880739993617
Validation loss: 2.517360258704581

Epoch: 6| Step: 3
Training loss: 3.1717693142125842
Validation loss: 2.519159761339673

Epoch: 6| Step: 4
Training loss: 3.2728415153773995
Validation loss: 2.5110150288194633

Epoch: 6| Step: 5
Training loss: 2.629646548464001
Validation loss: 2.492242872736738

Epoch: 6| Step: 6
Training loss: 2.6854837528093114
Validation loss: 2.4930591697673146

Epoch: 6| Step: 7
Training loss: 3.0450095701771946
Validation loss: 2.498226691510627

Epoch: 6| Step: 8
Training loss: 2.8064573011740244
Validation loss: 2.496692052271525

Epoch: 6| Step: 9
Training loss: 2.576528713913945
Validation loss: 2.5056118296860643

Epoch: 6| Step: 10
Training loss: 2.1247711058364063
Validation loss: 2.4934574069966136

Epoch: 6| Step: 11
Training loss: 3.4295267749569303
Validation loss: 2.5102681196996612

Epoch: 6| Step: 12
Training loss: 2.541246619196499
Validation loss: 2.5146225669733537

Epoch: 6| Step: 13
Training loss: 2.6022126356321653
Validation loss: 2.5375036439940692

Epoch: 210| Step: 0
Training loss: 3.029038556593749
Validation loss: 2.557157723785495

Epoch: 6| Step: 1
Training loss: 2.3570962979726264
Validation loss: 2.575959325146101

Epoch: 6| Step: 2
Training loss: 2.6470742106769607
Validation loss: 2.556187407429818

Epoch: 6| Step: 3
Training loss: 3.060723860150684
Validation loss: 2.5649035856608866

Epoch: 6| Step: 4
Training loss: 2.780734067918386
Validation loss: 2.561965995790259

Epoch: 6| Step: 5
Training loss: 2.3537443564292118
Validation loss: 2.5388559504474006

Epoch: 6| Step: 6
Training loss: 3.2970371296868484
Validation loss: 2.557912985432481

Epoch: 6| Step: 7
Training loss: 2.703506442813523
Validation loss: 2.547749890300252

Epoch: 6| Step: 8
Training loss: 2.883927127208458
Validation loss: 2.52013591338476

Epoch: 6| Step: 9
Training loss: 2.5035506783047814
Validation loss: 2.506727378776421

Epoch: 6| Step: 10
Training loss: 2.937530517419604
Validation loss: 2.501282653119881

Epoch: 6| Step: 11
Training loss: 3.164190897279086
Validation loss: 2.5092606021819472

Epoch: 6| Step: 12
Training loss: 2.6861956780196734
Validation loss: 2.5059925675335086

Epoch: 6| Step: 13
Training loss: 2.3648034103980655
Validation loss: 2.517221244874606

Epoch: 211| Step: 0
Training loss: 3.148725851404769
Validation loss: 2.5067914064009873

Epoch: 6| Step: 1
Training loss: 3.265378513798807
Validation loss: 2.496097272816871

Epoch: 6| Step: 2
Training loss: 3.118598178998183
Validation loss: 2.4950506666025567

Epoch: 6| Step: 3
Training loss: 2.3659642650262804
Validation loss: 2.504274477479042

Epoch: 6| Step: 4
Training loss: 3.095986530797082
Validation loss: 2.5025885317072034

Epoch: 6| Step: 5
Training loss: 3.0939081324998376
Validation loss: 2.505022507457679

Epoch: 6| Step: 6
Training loss: 2.3051023982673313
Validation loss: 2.5124891477515865

Epoch: 6| Step: 7
Training loss: 1.9889809327283245
Validation loss: 2.523132891010552

Epoch: 6| Step: 8
Training loss: 3.0077015249413903
Validation loss: 2.5466503036894426

Epoch: 6| Step: 9
Training loss: 2.496691803782303
Validation loss: 2.550512683787231

Epoch: 6| Step: 10
Training loss: 2.2444627230228313
Validation loss: 2.545976703964318

Epoch: 6| Step: 11
Training loss: 2.9181636964769533
Validation loss: 2.5363093971690596

Epoch: 6| Step: 12
Training loss: 2.8905448283856847
Validation loss: 2.5365349104709725

Epoch: 6| Step: 13
Training loss: 3.1046242771325234
Validation loss: 2.512630310948465

Epoch: 212| Step: 0
Training loss: 2.911302010713249
Validation loss: 2.4941288055487543

Epoch: 6| Step: 1
Training loss: 2.609682350560159
Validation loss: 2.4892949137055

Epoch: 6| Step: 2
Training loss: 2.727196037774804
Validation loss: 2.488938973716267

Epoch: 6| Step: 3
Training loss: 2.773096541816894
Validation loss: 2.4880452642292936

Epoch: 6| Step: 4
Training loss: 2.723639027618178
Validation loss: 2.4857376395423203

Epoch: 6| Step: 5
Training loss: 3.221359380390427
Validation loss: 2.495147653647406

Epoch: 6| Step: 6
Training loss: 2.928529067846297
Validation loss: 2.50119307772346

Epoch: 6| Step: 7
Training loss: 2.722673413347086
Validation loss: 2.509886878274947

Epoch: 6| Step: 8
Training loss: 2.5934175025434643
Validation loss: 2.528949294076427

Epoch: 6| Step: 9
Training loss: 2.9471556059650945
Validation loss: 2.519404131681128

Epoch: 6| Step: 10
Training loss: 2.913189386467729
Validation loss: 2.529425971184026

Epoch: 6| Step: 11
Training loss: 2.6570338270785614
Validation loss: 2.5396822235085676

Epoch: 6| Step: 12
Training loss: 2.555074959866561
Validation loss: 2.5605351318016

Epoch: 6| Step: 13
Training loss: 2.4872811072571905
Validation loss: 2.5839470409917293

Epoch: 213| Step: 0
Training loss: 2.937061520579946
Validation loss: 2.598639368999282

Epoch: 6| Step: 1
Training loss: 3.1519446894444996
Validation loss: 2.601367603537555

Epoch: 6| Step: 2
Training loss: 2.5889303630659297
Validation loss: 2.6065264780082837

Epoch: 6| Step: 3
Training loss: 2.223360992423546
Validation loss: 2.553353825432329

Epoch: 6| Step: 4
Training loss: 3.183393338688091
Validation loss: 2.545549232975525

Epoch: 6| Step: 5
Training loss: 2.425909410614061
Validation loss: 2.539229036206757

Epoch: 6| Step: 6
Training loss: 3.0421436057820617
Validation loss: 2.500286128990125

Epoch: 6| Step: 7
Training loss: 3.240129005783735
Validation loss: 2.503095595077873

Epoch: 6| Step: 8
Training loss: 2.9908136545467263
Validation loss: 2.520850993492636

Epoch: 6| Step: 9
Training loss: 2.738361874426033
Validation loss: 2.5007530021797533

Epoch: 6| Step: 10
Training loss: 2.22949486096122
Validation loss: 2.4961715563638553

Epoch: 6| Step: 11
Training loss: 2.725173202749754
Validation loss: 2.4998649376102144

Epoch: 6| Step: 12
Training loss: 3.0478811314550134
Validation loss: 2.504455520494759

Epoch: 6| Step: 13
Training loss: 1.8545135930710717
Validation loss: 2.499105971460389

Epoch: 214| Step: 0
Training loss: 2.523856113540201
Validation loss: 2.503314863114724

Epoch: 6| Step: 1
Training loss: 2.7366819404829417
Validation loss: 2.4890080701798794

Epoch: 6| Step: 2
Training loss: 2.4792325521310796
Validation loss: 2.4948275668825333

Epoch: 6| Step: 3
Training loss: 2.917692894005548
Validation loss: 2.502552332378714

Epoch: 6| Step: 4
Training loss: 2.90102055448912
Validation loss: 2.517769144040269

Epoch: 6| Step: 5
Training loss: 2.4602394688360225
Validation loss: 2.5190718800341525

Epoch: 6| Step: 6
Training loss: 2.7693395292696135
Validation loss: 2.520228501931054

Epoch: 6| Step: 7
Training loss: 3.066729058446462
Validation loss: 2.5114653207238344

Epoch: 6| Step: 8
Training loss: 2.760138290092025
Validation loss: 2.5202365023967173

Epoch: 6| Step: 9
Training loss: 2.71995745625603
Validation loss: 2.521142295047341

Epoch: 6| Step: 10
Training loss: 2.752013682991211
Validation loss: 2.5412837280829526

Epoch: 6| Step: 11
Training loss: 3.429257168199401
Validation loss: 2.538423998041169

Epoch: 6| Step: 12
Training loss: 2.8032389435845637
Validation loss: 2.5344927298196867

Epoch: 6| Step: 13
Training loss: 1.9860447144098992
Validation loss: 2.551947634322393

Epoch: 215| Step: 0
Training loss: 2.9026291143464507
Validation loss: 2.5476920149059152

Epoch: 6| Step: 1
Training loss: 3.020740656691705
Validation loss: 2.550730471790367

Epoch: 6| Step: 2
Training loss: 2.342000486352676
Validation loss: 2.51912629241301

Epoch: 6| Step: 3
Training loss: 2.2259093280226776
Validation loss: 2.4918715514950716

Epoch: 6| Step: 4
Training loss: 2.6568227711391765
Validation loss: 2.517527541638554

Epoch: 6| Step: 5
Training loss: 2.602658885609351
Validation loss: 2.493995332006003

Epoch: 6| Step: 6
Training loss: 2.945167436745957
Validation loss: 2.5076032588379737

Epoch: 6| Step: 7
Training loss: 3.1950352182372526
Validation loss: 2.4984978049141335

Epoch: 6| Step: 8
Training loss: 2.515220656981829
Validation loss: 2.506333857074923

Epoch: 6| Step: 9
Training loss: 3.0893328952100254
Validation loss: 2.5220373494202994

Epoch: 6| Step: 10
Training loss: 3.0360253855833843
Validation loss: 2.5223866288042625

Epoch: 6| Step: 11
Training loss: 2.5370272416820088
Validation loss: 2.5454944840320963

Epoch: 6| Step: 12
Training loss: 2.7339751032914474
Validation loss: 2.5530107127046984

Epoch: 6| Step: 13
Training loss: 3.120124523172128
Validation loss: 2.5439146164923083

Epoch: 216| Step: 0
Training loss: 2.9511592720817927
Validation loss: 2.541786038402769

Epoch: 6| Step: 1
Training loss: 2.7308639218578046
Validation loss: 2.5564880799378513

Epoch: 6| Step: 2
Training loss: 2.9417398575132756
Validation loss: 2.5512726628599847

Epoch: 6| Step: 3
Training loss: 2.8082298923839915
Validation loss: 2.524616084706054

Epoch: 6| Step: 4
Training loss: 1.7740560788792166
Validation loss: 2.536085318449662

Epoch: 6| Step: 5
Training loss: 3.2856183719259757
Validation loss: 2.522360201399261

Epoch: 6| Step: 6
Training loss: 2.3807565292914594
Validation loss: 2.5059965715683017

Epoch: 6| Step: 7
Training loss: 2.5645899739761795
Validation loss: 2.5001572774821157

Epoch: 6| Step: 8
Training loss: 3.268551915660238
Validation loss: 2.5007581012581146

Epoch: 6| Step: 9
Training loss: 1.9529151498593196
Validation loss: 2.4914499871460096

Epoch: 6| Step: 10
Training loss: 3.410881603305453
Validation loss: 2.5021393451522926

Epoch: 6| Step: 11
Training loss: 2.6434419493069012
Validation loss: 2.547330493359784

Epoch: 6| Step: 12
Training loss: 2.6779854487735317
Validation loss: 2.576500572234918

Epoch: 6| Step: 13
Training loss: 2.9052847623203646
Validation loss: 2.5873220739925338

Epoch: 217| Step: 0
Training loss: 3.553324746293886
Validation loss: 2.605532002202826

Epoch: 6| Step: 1
Training loss: 3.3047915322813295
Validation loss: 2.6019209132284873

Epoch: 6| Step: 2
Training loss: 2.8779180893471756
Validation loss: 2.527761167961264

Epoch: 6| Step: 3
Training loss: 2.8683983015837113
Validation loss: 2.508145765833604

Epoch: 6| Step: 4
Training loss: 2.661256985348358
Validation loss: 2.5035398760855005

Epoch: 6| Step: 5
Training loss: 2.5623612715222497
Validation loss: 2.4905527947283006

Epoch: 6| Step: 6
Training loss: 2.267749921154231
Validation loss: 2.4996400789389357

Epoch: 6| Step: 7
Training loss: 3.211102780731319
Validation loss: 2.492348492074889

Epoch: 6| Step: 8
Training loss: 2.7687112430934064
Validation loss: 2.489398100553213

Epoch: 6| Step: 9
Training loss: 3.145058610185035
Validation loss: 2.4972671687280728

Epoch: 6| Step: 10
Training loss: 2.6228576273758906
Validation loss: 2.4985878483621993

Epoch: 6| Step: 11
Training loss: 2.37144062955092
Validation loss: 2.4978159711549743

Epoch: 6| Step: 12
Training loss: 1.7822720456525023
Validation loss: 2.5025157104633697

Epoch: 6| Step: 13
Training loss: 2.0799868854696144
Validation loss: 2.522725663113177

Epoch: 218| Step: 0
Training loss: 2.6244945947842524
Validation loss: 2.5558298690325567

Epoch: 6| Step: 1
Training loss: 2.700947143297371
Validation loss: 2.579888968848506

Epoch: 6| Step: 2
Training loss: 2.761901417778759
Validation loss: 2.6059707138632375

Epoch: 6| Step: 3
Training loss: 2.7522085164717534
Validation loss: 2.5399166546577656

Epoch: 6| Step: 4
Training loss: 2.8652010904678855
Validation loss: 2.53942156023755

Epoch: 6| Step: 5
Training loss: 3.0993929176251123
Validation loss: 2.5485630668126404

Epoch: 6| Step: 6
Training loss: 2.2841372051749014
Validation loss: 2.5409032013576183

Epoch: 6| Step: 7
Training loss: 3.071904281833672
Validation loss: 2.5412376750516446

Epoch: 6| Step: 8
Training loss: 2.7641388946723584
Validation loss: 2.5326557648872385

Epoch: 6| Step: 9
Training loss: 2.938929433208444
Validation loss: 2.531590496432449

Epoch: 6| Step: 10
Training loss: 2.4211306504831547
Validation loss: 2.501540413934425

Epoch: 6| Step: 11
Training loss: 2.814514117139257
Validation loss: 2.486653924536192

Epoch: 6| Step: 12
Training loss: 2.9167762372461934
Validation loss: 2.4954985402997796

Epoch: 6| Step: 13
Training loss: 2.7885122744854565
Validation loss: 2.4932435268070803

Epoch: 219| Step: 0
Training loss: 2.7873547024343024
Validation loss: 2.4920320136079113

Epoch: 6| Step: 1
Training loss: 2.9270926008156968
Validation loss: 2.4958059950745417

Epoch: 6| Step: 2
Training loss: 2.941803721692338
Validation loss: 2.4942462760100406

Epoch: 6| Step: 3
Training loss: 2.770023619623393
Validation loss: 2.4887071686935283

Epoch: 6| Step: 4
Training loss: 2.949454150373633
Validation loss: 2.4942140844243

Epoch: 6| Step: 5
Training loss: 2.550681142901858
Validation loss: 2.4834649546296035

Epoch: 6| Step: 6
Training loss: 2.3306947389471677
Validation loss: 2.519146605035262

Epoch: 6| Step: 7
Training loss: 2.423443686147206
Validation loss: 2.5259322179627106

Epoch: 6| Step: 8
Training loss: 3.158176551758954
Validation loss: 2.5518269902147646

Epoch: 6| Step: 9
Training loss: 1.9679927277779545
Validation loss: 2.504128888955506

Epoch: 6| Step: 10
Training loss: 2.6024423205518534
Validation loss: 2.5101241799730585

Epoch: 6| Step: 11
Training loss: 3.359731539945984
Validation loss: 2.5184542516995254

Epoch: 6| Step: 12
Training loss: 3.0255444501726796
Validation loss: 2.506406681176567

Epoch: 6| Step: 13
Training loss: 3.0998302782420604
Validation loss: 2.5121306859182013

Epoch: 220| Step: 0
Training loss: 2.8996201233508523
Validation loss: 2.5183549958071296

Epoch: 6| Step: 1
Training loss: 3.407524220526769
Validation loss: 2.5113418723249383

Epoch: 6| Step: 2
Training loss: 3.060436254083332
Validation loss: 2.507214138718969

Epoch: 6| Step: 3
Training loss: 2.292502880697822
Validation loss: 2.4961583615736043

Epoch: 6| Step: 4
Training loss: 2.6582782855258666
Validation loss: 2.510879499126187

Epoch: 6| Step: 5
Training loss: 2.7655465497458245
Validation loss: 2.5310569587281426

Epoch: 6| Step: 6
Training loss: 2.7823345341457237
Validation loss: 2.5745175437027497

Epoch: 6| Step: 7
Training loss: 2.300393763297284
Validation loss: 2.6131664836888584

Epoch: 6| Step: 8
Training loss: 2.3500801559738242
Validation loss: 2.607971939125002

Epoch: 6| Step: 9
Training loss: 2.8776393882471627
Validation loss: 2.5679073930927094

Epoch: 6| Step: 10
Training loss: 2.9979272675652635
Validation loss: 2.582099473680636

Epoch: 6| Step: 11
Training loss: 2.568858468765854
Validation loss: 2.537769103681601

Epoch: 6| Step: 12
Training loss: 2.7380601736552257
Validation loss: 2.5045835694810727

Epoch: 6| Step: 13
Training loss: 2.8933559404828912
Validation loss: 2.522726479136547

Epoch: 221| Step: 0
Training loss: 2.5308706682214948
Validation loss: 2.4928008929491012

Epoch: 6| Step: 1
Training loss: 2.723489510701057
Validation loss: 2.4966472529617043

Epoch: 6| Step: 2
Training loss: 2.9872949505909476
Validation loss: 2.496640543623651

Epoch: 6| Step: 3
Training loss: 2.722544685606558
Validation loss: 2.4845210309978203

Epoch: 6| Step: 4
Training loss: 2.9279423513209224
Validation loss: 2.5022253970787314

Epoch: 6| Step: 5
Training loss: 2.8020093451922023
Validation loss: 2.5111970232845104

Epoch: 6| Step: 6
Training loss: 2.81362621223186
Validation loss: 2.5141123934415996

Epoch: 6| Step: 7
Training loss: 2.4445808461693903
Validation loss: 2.511066784725958

Epoch: 6| Step: 8
Training loss: 2.657852048764671
Validation loss: 2.4983505375798347

Epoch: 6| Step: 9
Training loss: 2.9601238008332973
Validation loss: 2.488452271552048

Epoch: 6| Step: 10
Training loss: 2.944824178269047
Validation loss: 2.499947614018396

Epoch: 6| Step: 11
Training loss: 2.482971754782238
Validation loss: 2.480879279902144

Epoch: 6| Step: 12
Training loss: 3.116780113426621
Validation loss: 2.476808917106514

Epoch: 6| Step: 13
Training loss: 2.7721716342541245
Validation loss: 2.4810388942215775

Epoch: 222| Step: 0
Training loss: 3.0827369800565223
Validation loss: 2.485574677325186

Epoch: 6| Step: 1
Training loss: 2.593373466645327
Validation loss: 2.479019550175066

Epoch: 6| Step: 2
Training loss: 2.5244642123584877
Validation loss: 2.476240113353703

Epoch: 6| Step: 3
Training loss: 3.00599024675504
Validation loss: 2.4915827059972524

Epoch: 6| Step: 4
Training loss: 2.4890348290427733
Validation loss: 2.4938720231630955

Epoch: 6| Step: 5
Training loss: 2.5695040744586626
Validation loss: 2.5068202426890998

Epoch: 6| Step: 6
Training loss: 2.983576323205358
Validation loss: 2.52053598229734

Epoch: 6| Step: 7
Training loss: 2.4902799474996673
Validation loss: 2.531091498493244

Epoch: 6| Step: 8
Training loss: 2.6042541692655896
Validation loss: 2.5415854641957596

Epoch: 6| Step: 9
Training loss: 3.2969532455632695
Validation loss: 2.5366984999051256

Epoch: 6| Step: 10
Training loss: 3.274736606401894
Validation loss: 2.5761723168402186

Epoch: 6| Step: 11
Training loss: 2.4855405364674406
Validation loss: 2.5820457757564172

Epoch: 6| Step: 12
Training loss: 2.6664729246649386
Validation loss: 2.5553876626026453

Epoch: 6| Step: 13
Training loss: 2.4131638913008118
Validation loss: 2.5332540936320815

Epoch: 223| Step: 0
Training loss: 2.8141061223454713
Validation loss: 2.5488184933308933

Epoch: 6| Step: 1
Training loss: 2.6798287846546236
Validation loss: 2.534992051344811

Epoch: 6| Step: 2
Training loss: 2.89991989682819
Validation loss: 2.5597915732501457

Epoch: 6| Step: 3
Training loss: 2.8558120625526278
Validation loss: 2.5489747037297814

Epoch: 6| Step: 4
Training loss: 2.4357296309928635
Validation loss: 2.544386112073009

Epoch: 6| Step: 5
Training loss: 2.739094612033446
Validation loss: 2.5339657378977805

Epoch: 6| Step: 6
Training loss: 2.986541600702567
Validation loss: 2.53237644675457

Epoch: 6| Step: 7
Training loss: 2.5816568862142018
Validation loss: 2.5138496468456917

Epoch: 6| Step: 8
Training loss: 2.761626202922468
Validation loss: 2.4995549585188246

Epoch: 6| Step: 9
Training loss: 2.6301400858771555
Validation loss: 2.4956205319607037

Epoch: 6| Step: 10
Training loss: 2.8645146772075543
Validation loss: 2.483015975885621

Epoch: 6| Step: 11
Training loss: 2.922179180774304
Validation loss: 2.483740329969366

Epoch: 6| Step: 12
Training loss: 2.585404816589331
Validation loss: 2.4863632340542954

Epoch: 6| Step: 13
Training loss: 2.7851640398898336
Validation loss: 2.4818215849148477

Epoch: 224| Step: 0
Training loss: 3.118590533932751
Validation loss: 2.4766726060632487

Epoch: 6| Step: 1
Training loss: 2.4412283138282698
Validation loss: 2.486581624324903

Epoch: 6| Step: 2
Training loss: 3.0786305898229736
Validation loss: 2.499830976535484

Epoch: 6| Step: 3
Training loss: 3.290075440628877
Validation loss: 2.522352845441082

Epoch: 6| Step: 4
Training loss: 2.9591875768202205
Validation loss: 2.5458194143864956

Epoch: 6| Step: 5
Training loss: 2.411866408246532
Validation loss: 2.570350077928183

Epoch: 6| Step: 6
Training loss: 2.9912777306960656
Validation loss: 2.6263421607660424

Epoch: 6| Step: 7
Training loss: 3.07680208078315
Validation loss: 2.682236753897835

Epoch: 6| Step: 8
Training loss: 2.8188159808029987
Validation loss: 2.6467764499936117

Epoch: 6| Step: 9
Training loss: 2.43881151177491
Validation loss: 2.573201511520241

Epoch: 6| Step: 10
Training loss: 2.4582126609366326
Validation loss: 2.5044361103109045

Epoch: 6| Step: 11
Training loss: 2.4118072938374286
Validation loss: 2.4796697496156654

Epoch: 6| Step: 12
Training loss: 2.3768050712672584
Validation loss: 2.4634073406361305

Epoch: 6| Step: 13
Training loss: 2.5041037256981142
Validation loss: 2.48540231179174

Epoch: 225| Step: 0
Training loss: 3.0333766752507145
Validation loss: 2.4699829073885757

Epoch: 6| Step: 1
Training loss: 2.6294943164532625
Validation loss: 2.476513508456099

Epoch: 6| Step: 2
Training loss: 2.895012242846387
Validation loss: 2.4688274900466993

Epoch: 6| Step: 3
Training loss: 2.7697007486533747
Validation loss: 2.4708792695697896

Epoch: 6| Step: 4
Training loss: 2.904752940507289
Validation loss: 2.473096027102504

Epoch: 6| Step: 5
Training loss: 3.1637571587815034
Validation loss: 2.478660443572096

Epoch: 6| Step: 6
Training loss: 2.6186149689814893
Validation loss: 2.482082597903886

Epoch: 6| Step: 7
Training loss: 1.7621907957221754
Validation loss: 2.47532479976646

Epoch: 6| Step: 8
Training loss: 3.095004973523114
Validation loss: 2.4822039630654076

Epoch: 6| Step: 9
Training loss: 2.9006934422097608
Validation loss: 2.4783885358894997

Epoch: 6| Step: 10
Training loss: 2.919369852710352
Validation loss: 2.503210745990172

Epoch: 6| Step: 11
Training loss: 2.079080691754687
Validation loss: 2.529336657638649

Epoch: 6| Step: 12
Training loss: 2.980777189561238
Validation loss: 2.5928178998513878

Epoch: 6| Step: 13
Training loss: 2.484862849482302
Validation loss: 2.603361773398649

Epoch: 226| Step: 0
Training loss: 2.847872585875439
Validation loss: 2.6231288256791965

Epoch: 6| Step: 1
Training loss: 2.847138115692511
Validation loss: 2.6209045824087625

Epoch: 6| Step: 2
Training loss: 3.1779840578768077
Validation loss: 2.625748095582386

Epoch: 6| Step: 3
Training loss: 2.6088870386048137
Validation loss: 2.544802847139177

Epoch: 6| Step: 4
Training loss: 2.8407778456455457
Validation loss: 2.507888902674607

Epoch: 6| Step: 5
Training loss: 2.5384768705638616
Validation loss: 2.510981443163712

Epoch: 6| Step: 6
Training loss: 2.497839089133617
Validation loss: 2.482495039894743

Epoch: 6| Step: 7
Training loss: 3.2227204657427833
Validation loss: 2.4914723816649933

Epoch: 6| Step: 8
Training loss: 2.922383799596411
Validation loss: 2.4654196741160024

Epoch: 6| Step: 9
Training loss: 2.8130236667975934
Validation loss: 2.4903777729901875

Epoch: 6| Step: 10
Training loss: 2.5723926046510432
Validation loss: 2.4819509483068085

Epoch: 6| Step: 11
Training loss: 2.370657313493973
Validation loss: 2.478704631958806

Epoch: 6| Step: 12
Training loss: 2.313585490556387
Validation loss: 2.4766930945246246

Epoch: 6| Step: 13
Training loss: 2.8851836256168917
Validation loss: 2.4960005876630107

Epoch: 227| Step: 0
Training loss: 2.5803374074274537
Validation loss: 2.48863233836187

Epoch: 6| Step: 1
Training loss: 2.804553440471007
Validation loss: 2.4975729810663014

Epoch: 6| Step: 2
Training loss: 2.4490972607428487
Validation loss: 2.5046482291930183

Epoch: 6| Step: 3
Training loss: 3.131567805260699
Validation loss: 2.510553088638778

Epoch: 6| Step: 4
Training loss: 2.2041269824007688
Validation loss: 2.520177197642011

Epoch: 6| Step: 5
Training loss: 2.327291659527413
Validation loss: 2.5266384166240328

Epoch: 6| Step: 6
Training loss: 2.8054935922693973
Validation loss: 2.549415758953676

Epoch: 6| Step: 7
Training loss: 2.4234149589941385
Validation loss: 2.5198791940295275

Epoch: 6| Step: 8
Training loss: 2.453073877664467
Validation loss: 2.511040194284683

Epoch: 6| Step: 9
Training loss: 2.8607127911308825
Validation loss: 2.526780312749945

Epoch: 6| Step: 10
Training loss: 3.0529041596959074
Validation loss: 2.53762775735816

Epoch: 6| Step: 11
Training loss: 2.939366173963134
Validation loss: 2.5589480199516843

Epoch: 6| Step: 12
Training loss: 3.1775119846697235
Validation loss: 2.5280780553784736

Epoch: 6| Step: 13
Training loss: 3.1398599936014575
Validation loss: 2.492176231914029

Epoch: 228| Step: 0
Training loss: 2.4350945757098157
Validation loss: 2.4676222202807545

Epoch: 6| Step: 1
Training loss: 2.789004114218406
Validation loss: 2.488202552956628

Epoch: 6| Step: 2
Training loss: 2.8978932324651954
Validation loss: 2.4813163639136198

Epoch: 6| Step: 3
Training loss: 2.9655426367687188
Validation loss: 2.476135216528876

Epoch: 6| Step: 4
Training loss: 2.9476653801852204
Validation loss: 2.477319025984695

Epoch: 6| Step: 5
Training loss: 3.066769484855715
Validation loss: 2.4708977865097093

Epoch: 6| Step: 6
Training loss: 2.8072416528741937
Validation loss: 2.4808492430542963

Epoch: 6| Step: 7
Training loss: 2.7550503565899103
Validation loss: 2.4825147951206086

Epoch: 6| Step: 8
Training loss: 2.8952685200973667
Validation loss: 2.4830618563838365

Epoch: 6| Step: 9
Training loss: 2.802835432084907
Validation loss: 2.491947225881581

Epoch: 6| Step: 10
Training loss: 1.9547565207123199
Validation loss: 2.5133947443771634

Epoch: 6| Step: 11
Training loss: 2.985227453105934
Validation loss: 2.525674711890571

Epoch: 6| Step: 12
Training loss: 2.81468988570312
Validation loss: 2.5143544861190477

Epoch: 6| Step: 13
Training loss: 3.116559646591369
Validation loss: 2.537602168584999

Epoch: 229| Step: 0
Training loss: 2.7515307414330348
Validation loss: 2.5546967854111085

Epoch: 6| Step: 1
Training loss: 2.995052708844999
Validation loss: 2.5549575468757477

Epoch: 6| Step: 2
Training loss: 1.944465667366586
Validation loss: 2.5553550935481804

Epoch: 6| Step: 3
Training loss: 2.604286211448845
Validation loss: 2.5510441924516836

Epoch: 6| Step: 4
Training loss: 2.936986188389141
Validation loss: 2.553365948046612

Epoch: 6| Step: 5
Training loss: 2.3245373419381634
Validation loss: 2.521402476968475

Epoch: 6| Step: 6
Training loss: 3.248826328509633
Validation loss: 2.5069678039828984

Epoch: 6| Step: 7
Training loss: 2.5675194124641254
Validation loss: 2.490267024669674

Epoch: 6| Step: 8
Training loss: 2.933247999192715
Validation loss: 2.488572991267575

Epoch: 6| Step: 9
Training loss: 3.160277110878333
Validation loss: 2.4840955628050776

Epoch: 6| Step: 10
Training loss: 2.4361231901342277
Validation loss: 2.4652319842698556

Epoch: 6| Step: 11
Training loss: 3.381818876518111
Validation loss: 2.4715643672259695

Epoch: 6| Step: 12
Training loss: 2.53449267621016
Validation loss: 2.4853791230010507

Epoch: 6| Step: 13
Training loss: 2.8013162993007463
Validation loss: 2.4946876874316617

Epoch: 230| Step: 0
Training loss: 2.559917544288708
Validation loss: 2.505440704502762

Epoch: 6| Step: 1
Training loss: 2.7846352195519684
Validation loss: 2.510546003919516

Epoch: 6| Step: 2
Training loss: 2.233273961810547
Validation loss: 2.5014516461352287

Epoch: 6| Step: 3
Training loss: 3.022746951077616
Validation loss: 2.4855017041656358

Epoch: 6| Step: 4
Training loss: 2.7491807584313728
Validation loss: 2.5160553093530766

Epoch: 6| Step: 5
Training loss: 2.7126245883157165
Validation loss: 2.494253440945345

Epoch: 6| Step: 6
Training loss: 3.036733799124982
Validation loss: 2.486835475112794

Epoch: 6| Step: 7
Training loss: 2.812820840125407
Validation loss: 2.4856535643157307

Epoch: 6| Step: 8
Training loss: 2.8222659629108793
Validation loss: 2.4764474288424063

Epoch: 6| Step: 9
Training loss: 2.7936368983371795
Validation loss: 2.498219561572974

Epoch: 6| Step: 10
Training loss: 2.682772714878632
Validation loss: 2.4888828291095315

Epoch: 6| Step: 11
Training loss: 2.7601585027543525
Validation loss: 2.5033965710047257

Epoch: 6| Step: 12
Training loss: 2.614034546989386
Validation loss: 2.5297660219912665

Epoch: 6| Step: 13
Training loss: 2.728142835071552
Validation loss: 2.6007386077823353

Epoch: 231| Step: 0
Training loss: 2.599929067671152
Validation loss: 2.6388593123339543

Epoch: 6| Step: 1
Training loss: 3.1492764323125306
Validation loss: 2.638010142813808

Epoch: 6| Step: 2
Training loss: 2.613036276792151
Validation loss: 2.6219680423682097

Epoch: 6| Step: 3
Training loss: 2.2386695831185923
Validation loss: 2.5462927621779823

Epoch: 6| Step: 4
Training loss: 2.956648404976387
Validation loss: 2.5187098668950325

Epoch: 6| Step: 5
Training loss: 3.2429658621874187
Validation loss: 2.4787981609630787

Epoch: 6| Step: 6
Training loss: 2.500750238380623
Validation loss: 2.4896147685607035

Epoch: 6| Step: 7
Training loss: 2.7003669560047796
Validation loss: 2.4743845907366713

Epoch: 6| Step: 8
Training loss: 2.556343125416798
Validation loss: 2.4801996742880843

Epoch: 6| Step: 9
Training loss: 2.447702817842202
Validation loss: 2.4890185945429564

Epoch: 6| Step: 10
Training loss: 3.206259779887314
Validation loss: 2.4814603619712523

Epoch: 6| Step: 11
Training loss: 2.9275636833163934
Validation loss: 2.4826050258646326

Epoch: 6| Step: 12
Training loss: 2.374767794049152
Validation loss: 2.4856460373304925

Epoch: 6| Step: 13
Training loss: 3.14257721459356
Validation loss: 2.497092588855661

Epoch: 232| Step: 0
Training loss: 3.2115682831604784
Validation loss: 2.5045625276669505

Epoch: 6| Step: 1
Training loss: 2.6406106440588406
Validation loss: 2.486715823632857

Epoch: 6| Step: 2
Training loss: 3.340216650417831
Validation loss: 2.5070711402926715

Epoch: 6| Step: 3
Training loss: 2.7205381980139567
Validation loss: 2.5067608506389325

Epoch: 6| Step: 4
Training loss: 2.418759514053125
Validation loss: 2.51150622079748

Epoch: 6| Step: 5
Training loss: 2.466964655566919
Validation loss: 2.5149073656445196

Epoch: 6| Step: 6
Training loss: 2.339831318766539
Validation loss: 2.5293143622073817

Epoch: 6| Step: 7
Training loss: 2.9466902447385777
Validation loss: 2.5185993343005815

Epoch: 6| Step: 8
Training loss: 2.9313104228805393
Validation loss: 2.534404930056467

Epoch: 6| Step: 9
Training loss: 3.0716832331022488
Validation loss: 2.5291629280835357

Epoch: 6| Step: 10
Training loss: 1.9615921204478708
Validation loss: 2.5227695095142595

Epoch: 6| Step: 11
Training loss: 2.7402356800992527
Validation loss: 2.5145499168376606

Epoch: 6| Step: 12
Training loss: 3.0747277736342786
Validation loss: 2.505956199474365

Epoch: 6| Step: 13
Training loss: 2.0727379752221995
Validation loss: 2.516668960264916

Epoch: 233| Step: 0
Training loss: 2.5184117395333385
Validation loss: 2.530804538053743

Epoch: 6| Step: 1
Training loss: 3.4176002870591717
Validation loss: 2.5010819206454946

Epoch: 6| Step: 2
Training loss: 2.7149976069262447
Validation loss: 2.513766252811672

Epoch: 6| Step: 3
Training loss: 2.591591821879775
Validation loss: 2.528192577459998

Epoch: 6| Step: 4
Training loss: 2.7654934436952807
Validation loss: 2.511649508708311

Epoch: 6| Step: 5
Training loss: 3.0678558227800137
Validation loss: 2.524046762080087

Epoch: 6| Step: 6
Training loss: 3.006658793549757
Validation loss: 2.5008536050543104

Epoch: 6| Step: 7
Training loss: 2.7846624463632117
Validation loss: 2.4993433551421917

Epoch: 6| Step: 8
Training loss: 3.0019645616242787
Validation loss: 2.4977510057645653

Epoch: 6| Step: 9
Training loss: 2.8558820224511496
Validation loss: 2.4756183754581977

Epoch: 6| Step: 10
Training loss: 2.6546826394560328
Validation loss: 2.486760343101129

Epoch: 6| Step: 11
Training loss: 2.5180002691679335
Validation loss: 2.480099735550229

Epoch: 6| Step: 12
Training loss: 1.6246393977383768
Validation loss: 2.4860785457108032

Epoch: 6| Step: 13
Training loss: 2.382973987547827
Validation loss: 2.4776233861799892

Epoch: 234| Step: 0
Training loss: 3.2152424190839115
Validation loss: 2.4853526950869624

Epoch: 6| Step: 1
Training loss: 2.9575398056950153
Validation loss: 2.512455626187563

Epoch: 6| Step: 2
Training loss: 2.6399905554284593
Validation loss: 2.5161847160857396

Epoch: 6| Step: 3
Training loss: 2.3112907340884035
Validation loss: 2.516195023873963

Epoch: 6| Step: 4
Training loss: 2.48479318997788
Validation loss: 2.503690720982941

Epoch: 6| Step: 5
Training loss: 2.8874628039850094
Validation loss: 2.5042759536625594

Epoch: 6| Step: 6
Training loss: 2.9815788551508113
Validation loss: 2.5141549064183377

Epoch: 6| Step: 7
Training loss: 2.9010723301872408
Validation loss: 2.518970601308367

Epoch: 6| Step: 8
Training loss: 2.3653093699402925
Validation loss: 2.5054048062878915

Epoch: 6| Step: 9
Training loss: 2.171084912073816
Validation loss: 2.4850473070184065

Epoch: 6| Step: 10
Training loss: 3.241968354321924
Validation loss: 2.4937727916916934

Epoch: 6| Step: 11
Training loss: 2.8764591660554433
Validation loss: 2.470982125696068

Epoch: 6| Step: 12
Training loss: 2.7140579074256355
Validation loss: 2.4880337063914144

Epoch: 6| Step: 13
Training loss: 2.274058149112651
Validation loss: 2.4954261840342724

Epoch: 235| Step: 0
Training loss: 2.310983727787822
Validation loss: 2.491582516675865

Epoch: 6| Step: 1
Training loss: 2.7520079651262654
Validation loss: 2.500967968417057

Epoch: 6| Step: 2
Training loss: 3.122805626040043
Validation loss: 2.5179694879873185

Epoch: 6| Step: 3
Training loss: 2.3438303615780263
Validation loss: 2.5399215600476466

Epoch: 6| Step: 4
Training loss: 2.711423275213253
Validation loss: 2.5312379740281608

Epoch: 6| Step: 5
Training loss: 2.93300316932109
Validation loss: 2.529992232032922

Epoch: 6| Step: 6
Training loss: 2.3614696778937936
Validation loss: 2.517385010927039

Epoch: 6| Step: 7
Training loss: 3.05850550888436
Validation loss: 2.5384786873965877

Epoch: 6| Step: 8
Training loss: 2.672492418840466
Validation loss: 2.506921856845971

Epoch: 6| Step: 9
Training loss: 2.9862101240278105
Validation loss: 2.5441909125728945

Epoch: 6| Step: 10
Training loss: 2.6048105486550774
Validation loss: 2.500549286826734

Epoch: 6| Step: 11
Training loss: 2.954935477596391
Validation loss: 2.4986735383265164

Epoch: 6| Step: 12
Training loss: 2.544352587060267
Validation loss: 2.526450375644702

Epoch: 6| Step: 13
Training loss: 2.6865078181343476
Validation loss: 2.5182863645459386

Epoch: 236| Step: 0
Training loss: 3.102128368808251
Validation loss: 2.5198246473351187

Epoch: 6| Step: 1
Training loss: 2.4720532494090453
Validation loss: 2.4964983617951875

Epoch: 6| Step: 2
Training loss: 3.171758640203271
Validation loss: 2.4905192378216063

Epoch: 6| Step: 3
Training loss: 2.5486329921114583
Validation loss: 2.4940036150134617

Epoch: 6| Step: 4
Training loss: 2.925505478700767
Validation loss: 2.511749659836261

Epoch: 6| Step: 5
Training loss: 2.246138437904633
Validation loss: 2.4860961219126594

Epoch: 6| Step: 6
Training loss: 2.5222284119017053
Validation loss: 2.4694414023433486

Epoch: 6| Step: 7
Training loss: 2.7696286118453664
Validation loss: 2.4726082043967184

Epoch: 6| Step: 8
Training loss: 2.8560892205927897
Validation loss: 2.482956245718884

Epoch: 6| Step: 9
Training loss: 2.882629554133223
Validation loss: 2.494654763686906

Epoch: 6| Step: 10
Training loss: 1.9211225820071076
Validation loss: 2.5033399482782643

Epoch: 6| Step: 11
Training loss: 2.705187060644985
Validation loss: 2.512810560140148

Epoch: 6| Step: 12
Training loss: 3.237081675953579
Validation loss: 2.5334302465001524

Epoch: 6| Step: 13
Training loss: 2.2468297664667882
Validation loss: 2.505432407121667

Epoch: 237| Step: 0
Training loss: 3.123565955142143
Validation loss: 2.481152219615827

Epoch: 6| Step: 1
Training loss: 2.7051121458262286
Validation loss: 2.478819741055194

Epoch: 6| Step: 2
Training loss: 2.4411238117878287
Validation loss: 2.482538785168104

Epoch: 6| Step: 3
Training loss: 3.115048087837261
Validation loss: 2.484022248962546

Epoch: 6| Step: 4
Training loss: 2.7596405281714795
Validation loss: 2.483303220428269

Epoch: 6| Step: 5
Training loss: 3.0029839934113967
Validation loss: 2.5018826850740967

Epoch: 6| Step: 6
Training loss: 2.7633478304947072
Validation loss: 2.5318888085161895

Epoch: 6| Step: 7
Training loss: 2.2993526459934777
Validation loss: 2.514764824051644

Epoch: 6| Step: 8
Training loss: 2.732411491586999
Validation loss: 2.5500932616910372

Epoch: 6| Step: 9
Training loss: 3.01626975326931
Validation loss: 2.548062737396529

Epoch: 6| Step: 10
Training loss: 2.9258791979703678
Validation loss: 2.529316527194912

Epoch: 6| Step: 11
Training loss: 2.6066322759845875
Validation loss: 2.5561773000248094

Epoch: 6| Step: 12
Training loss: 2.2385281464914124
Validation loss: 2.569281621591089

Epoch: 6| Step: 13
Training loss: 2.124884433969775
Validation loss: 2.556084362778965

Epoch: 238| Step: 0
Training loss: 3.2545871640405335
Validation loss: 2.513846110153674

Epoch: 6| Step: 1
Training loss: 2.9840314577505254
Validation loss: 2.4956125357888412

Epoch: 6| Step: 2
Training loss: 3.1432481126232727
Validation loss: 2.475706063723445

Epoch: 6| Step: 3
Training loss: 2.4436438964287968
Validation loss: 2.4673959890502224

Epoch: 6| Step: 4
Training loss: 2.7663343996048293
Validation loss: 2.4755688940428615

Epoch: 6| Step: 5
Training loss: 2.4902032588435876
Validation loss: 2.4690026864886505

Epoch: 6| Step: 6
Training loss: 2.4369312503150775
Validation loss: 2.4561279030230074

Epoch: 6| Step: 7
Training loss: 2.422513422343229
Validation loss: 2.4624355003930094

Epoch: 6| Step: 8
Training loss: 3.32021326253354
Validation loss: 2.465969972685329

Epoch: 6| Step: 9
Training loss: 2.905633348242504
Validation loss: 2.483989970288108

Epoch: 6| Step: 10
Training loss: 2.7331756577332147
Validation loss: 2.494175537228894

Epoch: 6| Step: 11
Training loss: 2.6902130981330643
Validation loss: 2.5130933091984455

Epoch: 6| Step: 12
Training loss: 2.251124630772691
Validation loss: 2.524500091394996

Epoch: 6| Step: 13
Training loss: 2.4006418045516464
Validation loss: 2.551228125608563

Epoch: 239| Step: 0
Training loss: 2.811620956377966
Validation loss: 2.58609849670101

Epoch: 6| Step: 1
Training loss: 3.1024260964148396
Validation loss: 2.614594449745755

Epoch: 6| Step: 2
Training loss: 3.2326162965510674
Validation loss: 2.614709423008688

Epoch: 6| Step: 3
Training loss: 3.509708699150553
Validation loss: 2.605673895655181

Epoch: 6| Step: 4
Training loss: 3.140156117828529
Validation loss: 2.5873075719133865

Epoch: 6| Step: 5
Training loss: 2.620138298344882
Validation loss: 2.5648774494034052

Epoch: 6| Step: 6
Training loss: 2.8570442080497265
Validation loss: 2.5355993125426632

Epoch: 6| Step: 7
Training loss: 2.3799863971994655
Validation loss: 2.5369141329949256

Epoch: 6| Step: 8
Training loss: 2.13403721115003
Validation loss: 2.514092890582021

Epoch: 6| Step: 9
Training loss: 2.116596209737626
Validation loss: 2.490055593611364

Epoch: 6| Step: 10
Training loss: 3.1094627176304885
Validation loss: 2.474541973359595

Epoch: 6| Step: 11
Training loss: 2.1609363216636903
Validation loss: 2.5056455159641624

Epoch: 6| Step: 12
Training loss: 2.2264175100133494
Validation loss: 2.4812831490958884

Epoch: 6| Step: 13
Training loss: 3.3048537192240066
Validation loss: 2.4696226388493567

Epoch: 240| Step: 0
Training loss: 3.048249076678558
Validation loss: 2.4833910502682954

Epoch: 6| Step: 1
Training loss: 2.700991985208878
Validation loss: 2.4934033783170277

Epoch: 6| Step: 2
Training loss: 3.3128857657890904
Validation loss: 2.4787498031272848

Epoch: 6| Step: 3
Training loss: 2.6579567306647753
Validation loss: 2.465604792382821

Epoch: 6| Step: 4
Training loss: 2.6088206907381237
Validation loss: 2.4630243186174963

Epoch: 6| Step: 5
Training loss: 3.2255290225924083
Validation loss: 2.475731748603164

Epoch: 6| Step: 6
Training loss: 2.421229122546478
Validation loss: 2.464356940237633

Epoch: 6| Step: 7
Training loss: 2.4407901566388532
Validation loss: 2.4689338390292073

Epoch: 6| Step: 8
Training loss: 2.7693031120224676
Validation loss: 2.464925809056285

Epoch: 6| Step: 9
Training loss: 2.7563826444718016
Validation loss: 2.4902288904517733

Epoch: 6| Step: 10
Training loss: 2.7488888316290248
Validation loss: 2.4999640800602796

Epoch: 6| Step: 11
Training loss: 2.4401525101135637
Validation loss: 2.5392860434091435

Epoch: 6| Step: 12
Training loss: 2.799104196438702
Validation loss: 2.575096143549876

Epoch: 6| Step: 13
Training loss: 2.3209970408514864
Validation loss: 2.5729311983786625

Epoch: 241| Step: 0
Training loss: 3.391497381111179
Validation loss: 2.607984741706649

Epoch: 6| Step: 1
Training loss: 2.437944225033165
Validation loss: 2.566493128804425

Epoch: 6| Step: 2
Training loss: 2.6294550556665746
Validation loss: 2.5818004795755076

Epoch: 6| Step: 3
Training loss: 2.418696329472574
Validation loss: 2.565828595084542

Epoch: 6| Step: 4
Training loss: 3.1213797389310667
Validation loss: 2.539153670448179

Epoch: 6| Step: 5
Training loss: 2.2474353797117783
Validation loss: 2.538542970524912

Epoch: 6| Step: 6
Training loss: 2.9905402128663154
Validation loss: 2.5108179935701607

Epoch: 6| Step: 7
Training loss: 2.4743425786957687
Validation loss: 2.5262493129813577

Epoch: 6| Step: 8
Training loss: 3.4209732888167736
Validation loss: 2.494245256410631

Epoch: 6| Step: 9
Training loss: 2.252966303004904
Validation loss: 2.4968647257645222

Epoch: 6| Step: 10
Training loss: 2.37984374166482
Validation loss: 2.465165924634468

Epoch: 6| Step: 11
Training loss: 3.194504166933985
Validation loss: 2.476075827189038

Epoch: 6| Step: 12
Training loss: 2.47117678960741
Validation loss: 2.473604146908714

Epoch: 6| Step: 13
Training loss: 2.316949944592211
Validation loss: 2.4625557819397104

Epoch: 242| Step: 0
Training loss: 2.7001232613578736
Validation loss: 2.460347859336896

Epoch: 6| Step: 1
Training loss: 2.776633728521953
Validation loss: 2.4702178757419495

Epoch: 6| Step: 2
Training loss: 2.7410660322516973
Validation loss: 2.471545726659611

Epoch: 6| Step: 3
Training loss: 2.4408397780316275
Validation loss: 2.479932411531835

Epoch: 6| Step: 4
Training loss: 2.7016253418284824
Validation loss: 2.516006723052162

Epoch: 6| Step: 5
Training loss: 2.631975261560378
Validation loss: 2.506653929129625

Epoch: 6| Step: 6
Training loss: 2.634672419183966
Validation loss: 2.531914615011194

Epoch: 6| Step: 7
Training loss: 2.454481296632011
Validation loss: 2.546748190558368

Epoch: 6| Step: 8
Training loss: 2.6352164050422515
Validation loss: 2.5476407514793546

Epoch: 6| Step: 9
Training loss: 3.323618672198427
Validation loss: 2.547617926927918

Epoch: 6| Step: 10
Training loss: 2.667570517268402
Validation loss: 2.5282044490842326

Epoch: 6| Step: 11
Training loss: 3.1578562964224606
Validation loss: 2.52667363470103

Epoch: 6| Step: 12
Training loss: 2.8660613714702934
Validation loss: 2.5221605507971576

Epoch: 6| Step: 13
Training loss: 2.8852839433646547
Validation loss: 2.510390908094612

Epoch: 243| Step: 0
Training loss: 3.065408065539785
Validation loss: 2.496225656071947

Epoch: 6| Step: 1
Training loss: 2.9288351624725397
Validation loss: 2.4726384139304227

Epoch: 6| Step: 2
Training loss: 2.542185391716531
Validation loss: 2.473262473375141

Epoch: 6| Step: 3
Training loss: 2.3717807233365957
Validation loss: 2.4644659662365553

Epoch: 6| Step: 4
Training loss: 3.4873403751936882
Validation loss: 2.4629317373693596

Epoch: 6| Step: 5
Training loss: 2.428732926745048
Validation loss: 2.4473508801934805

Epoch: 6| Step: 6
Training loss: 2.2165175476205716
Validation loss: 2.4545129784417825

Epoch: 6| Step: 7
Training loss: 3.0981688105456255
Validation loss: 2.4684839454469496

Epoch: 6| Step: 8
Training loss: 2.744035060386105
Validation loss: 2.482808002846876

Epoch: 6| Step: 9
Training loss: 2.9122135136057805
Validation loss: 2.488580281734146

Epoch: 6| Step: 10
Training loss: 2.817493583313101
Validation loss: 2.5087218444229533

Epoch: 6| Step: 11
Training loss: 2.502169240153845
Validation loss: 2.5486402661838166

Epoch: 6| Step: 12
Training loss: 2.5518430220417296
Validation loss: 2.57338589126155

Epoch: 6| Step: 13
Training loss: 2.3897676613533467
Validation loss: 2.5695597096088627

Epoch: 244| Step: 0
Training loss: 2.8732518395936038
Validation loss: 2.5288253042400304

Epoch: 6| Step: 1
Training loss: 2.5615051943688907
Validation loss: 2.5174807352892135

Epoch: 6| Step: 2
Training loss: 2.260375366771204
Validation loss: 2.504638422510895

Epoch: 6| Step: 3
Training loss: 3.0687256417793627
Validation loss: 2.4872910545229927

Epoch: 6| Step: 4
Training loss: 2.6040681337153484
Validation loss: 2.4706342315374767

Epoch: 6| Step: 5
Training loss: 2.436123581606319
Validation loss: 2.455819069717782

Epoch: 6| Step: 6
Training loss: 2.542378768806322
Validation loss: 2.4565900204311846

Epoch: 6| Step: 7
Training loss: 2.334704938294187
Validation loss: 2.4371730752431002

Epoch: 6| Step: 8
Training loss: 2.8907178709215358
Validation loss: 2.451775710588836

Epoch: 6| Step: 9
Training loss: 3.197759833616529
Validation loss: 2.445730851413695

Epoch: 6| Step: 10
Training loss: 2.3807455134214814
Validation loss: 2.447633380682964

Epoch: 6| Step: 11
Training loss: 3.2521808349799133
Validation loss: 2.47615073880791

Epoch: 6| Step: 12
Training loss: 3.1894925939076573
Validation loss: 2.4496034984427966

Epoch: 6| Step: 13
Training loss: 2.053718367348662
Validation loss: 2.460496109253206

Epoch: 245| Step: 0
Training loss: 2.428698764796596
Validation loss: 2.484316584165458

Epoch: 6| Step: 1
Training loss: 2.5533617411826803
Validation loss: 2.516276154076834

Epoch: 6| Step: 2
Training loss: 2.788321260318586
Validation loss: 2.5264027097208457

Epoch: 6| Step: 3
Training loss: 3.0317640360301814
Validation loss: 2.5509228312711882

Epoch: 6| Step: 4
Training loss: 2.3003893066651213
Validation loss: 2.5834700031892552

Epoch: 6| Step: 5
Training loss: 2.8569499086896357
Validation loss: 2.5793442036852494

Epoch: 6| Step: 6
Training loss: 2.619286814001373
Validation loss: 2.5544975636393183

Epoch: 6| Step: 7
Training loss: 3.3264709087357187
Validation loss: 2.5379328883176466

Epoch: 6| Step: 8
Training loss: 2.6118137133533277
Validation loss: 2.5074436858430236

Epoch: 6| Step: 9
Training loss: 3.149191337812506
Validation loss: 2.488121639199086

Epoch: 6| Step: 10
Training loss: 2.755931180130719
Validation loss: 2.4726819644859597

Epoch: 6| Step: 11
Training loss: 2.1711652954656344
Validation loss: 2.4711047168681675

Epoch: 6| Step: 12
Training loss: 3.1121885519201173
Validation loss: 2.4753987222857945

Epoch: 6| Step: 13
Training loss: 2.0387681770566886
Validation loss: 2.464326431526383

Epoch: 246| Step: 0
Training loss: 3.1663538795053827
Validation loss: 2.462157252884279

Epoch: 6| Step: 1
Training loss: 2.5393056899762967
Validation loss: 2.4618713627983766

Epoch: 6| Step: 2
Training loss: 2.5308592694908527
Validation loss: 2.4571988491580266

Epoch: 6| Step: 3
Training loss: 2.245140550117679
Validation loss: 2.4574567814746704

Epoch: 6| Step: 4
Training loss: 2.956742266262239
Validation loss: 2.474517256202073

Epoch: 6| Step: 5
Training loss: 2.5170056836833594
Validation loss: 2.4772879111116217

Epoch: 6| Step: 6
Training loss: 2.8214901819107316
Validation loss: 2.4815045118636423

Epoch: 6| Step: 7
Training loss: 3.1955967709066493
Validation loss: 2.476324171722571

Epoch: 6| Step: 8
Training loss: 3.1159059571947982
Validation loss: 2.484970544568813

Epoch: 6| Step: 9
Training loss: 2.701516615575584
Validation loss: 2.4939997993648952

Epoch: 6| Step: 10
Training loss: 2.7633711256963873
Validation loss: 2.5117131710014453

Epoch: 6| Step: 11
Training loss: 2.3310360725979615
Validation loss: 2.516980221374384

Epoch: 6| Step: 12
Training loss: 2.808750790170203
Validation loss: 2.499020064479975

Epoch: 6| Step: 13
Training loss: 1.765213369813065
Validation loss: 2.5280614408494624

Epoch: 247| Step: 0
Training loss: 2.7538047825943743
Validation loss: 2.532703451800965

Epoch: 6| Step: 1
Training loss: 2.32323664583986
Validation loss: 2.5481265463358493

Epoch: 6| Step: 2
Training loss: 3.1533414828764412
Validation loss: 2.565242484305859

Epoch: 6| Step: 3
Training loss: 2.8087035941554563
Validation loss: 2.572753353714104

Epoch: 6| Step: 4
Training loss: 2.626351145013565
Validation loss: 2.582435148762013

Epoch: 6| Step: 5
Training loss: 2.063660728515468
Validation loss: 2.584401070453285

Epoch: 6| Step: 6
Training loss: 2.5649250000218924
Validation loss: 2.5435569464376258

Epoch: 6| Step: 7
Training loss: 2.589290139706593
Validation loss: 2.523181991368575

Epoch: 6| Step: 8
Training loss: 2.6612714986797306
Validation loss: 2.531368998742534

Epoch: 6| Step: 9
Training loss: 2.8515613294625166
Validation loss: 2.5350478047810308

Epoch: 6| Step: 10
Training loss: 3.2515706888487106
Validation loss: 2.491801395519576

Epoch: 6| Step: 11
Training loss: 2.9617392227081094
Validation loss: 2.46017716930722

Epoch: 6| Step: 12
Training loss: 2.770520892967888
Validation loss: 2.465483702958395

Epoch: 6| Step: 13
Training loss: 2.283833334351848
Validation loss: 2.475455301136448

Epoch: 248| Step: 0
Training loss: 2.692915937339105
Validation loss: 2.4518797858178085

Epoch: 6| Step: 1
Training loss: 2.67275825758545
Validation loss: 2.4598831368780822

Epoch: 6| Step: 2
Training loss: 1.7491915061365868
Validation loss: 2.453445015532533

Epoch: 6| Step: 3
Training loss: 2.922876522978537
Validation loss: 2.456179648581204

Epoch: 6| Step: 4
Training loss: 2.7470242265564098
Validation loss: 2.4520079216437267

Epoch: 6| Step: 5
Training loss: 2.642683592367133
Validation loss: 2.4614178026218947

Epoch: 6| Step: 6
Training loss: 2.752834246693852
Validation loss: 2.4557196138760515

Epoch: 6| Step: 7
Training loss: 3.0301659602173543
Validation loss: 2.465593921133771

Epoch: 6| Step: 8
Training loss: 2.45706996674956
Validation loss: 2.4905479990005226

Epoch: 6| Step: 9
Training loss: 2.349313871172433
Validation loss: 2.4852798185625358

Epoch: 6| Step: 10
Training loss: 2.6807994259425283
Validation loss: 2.5117035000955212

Epoch: 6| Step: 11
Training loss: 3.284743129958501
Validation loss: 2.520836512754207

Epoch: 6| Step: 12
Training loss: 2.958009585722892
Validation loss: 2.5199828727323745

Epoch: 6| Step: 13
Training loss: 2.9310813741434383
Validation loss: 2.5531993077613957

Epoch: 249| Step: 0
Training loss: 2.665989243373362
Validation loss: 2.521943672500526

Epoch: 6| Step: 1
Training loss: 2.9043730550701605
Validation loss: 2.4853421613893905

Epoch: 6| Step: 2
Training loss: 2.088500773218992
Validation loss: 2.4754660985275225

Epoch: 6| Step: 3
Training loss: 3.3031286436293614
Validation loss: 2.4726779770059784

Epoch: 6| Step: 4
Training loss: 2.2724854878212972
Validation loss: 2.4523407101890413

Epoch: 6| Step: 5
Training loss: 2.9722205505683292
Validation loss: 2.4761137191635267

Epoch: 6| Step: 6
Training loss: 2.180081895812341
Validation loss: 2.4781119741005844

Epoch: 6| Step: 7
Training loss: 3.142432153131732
Validation loss: 2.473628478326199

Epoch: 6| Step: 8
Training loss: 2.4672374679211595
Validation loss: 2.474209269743353

Epoch: 6| Step: 9
Training loss: 2.5361418373202924
Validation loss: 2.4888523563174942

Epoch: 6| Step: 10
Training loss: 3.18798585068687
Validation loss: 2.465756570517486

Epoch: 6| Step: 11
Training loss: 3.022808630546555
Validation loss: 2.4758053058740397

Epoch: 6| Step: 12
Training loss: 2.63383993595426
Validation loss: 2.488709492619238

Epoch: 6| Step: 13
Training loss: 1.5426545028344345
Validation loss: 2.490064521866537

Epoch: 250| Step: 0
Training loss: 3.111901565073678
Validation loss: 2.528669315095321

Epoch: 6| Step: 1
Training loss: 2.649505039991375
Validation loss: 2.5149596500056868

Epoch: 6| Step: 2
Training loss: 2.5146399044151337
Validation loss: 2.512562963000554

Epoch: 6| Step: 3
Training loss: 2.578173827662621
Validation loss: 2.571827976048757

Epoch: 6| Step: 4
Training loss: 2.2980001379665405
Validation loss: 2.601707675919357

Epoch: 6| Step: 5
Training loss: 3.249241960593493
Validation loss: 2.574403670311005

Epoch: 6| Step: 6
Training loss: 3.183652762585726
Validation loss: 2.5402989065262216

Epoch: 6| Step: 7
Training loss: 2.2700694721363033
Validation loss: 2.488454494239726

Epoch: 6| Step: 8
Training loss: 2.1573105567339628
Validation loss: 2.479081684357753

Epoch: 6| Step: 9
Training loss: 2.745992167562385
Validation loss: 2.455662592839766

Epoch: 6| Step: 10
Training loss: 2.794966915255536
Validation loss: 2.4584294844884003

Epoch: 6| Step: 11
Training loss: 2.9652538392894625
Validation loss: 2.4463915278401296

Epoch: 6| Step: 12
Training loss: 2.4138584482809677
Validation loss: 2.4515285152579342

Epoch: 6| Step: 13
Training loss: 2.9280260588419162
Validation loss: 2.442629555332884

Epoch: 251| Step: 0
Training loss: 2.9177425761575773
Validation loss: 2.4567100476286

Epoch: 6| Step: 1
Training loss: 2.541312667291652
Validation loss: 2.4376249436465227

Epoch: 6| Step: 2
Training loss: 3.2851053023044794
Validation loss: 2.448750179677936

Epoch: 6| Step: 3
Training loss: 2.201623716241047
Validation loss: 2.4686003577728273

Epoch: 6| Step: 4
Training loss: 3.238491516281213
Validation loss: 2.48803398974816

Epoch: 6| Step: 5
Training loss: 2.708697094085968
Validation loss: 2.4932243830515346

Epoch: 6| Step: 6
Training loss: 2.4393596890883114
Validation loss: 2.522127903348734

Epoch: 6| Step: 7
Training loss: 2.4559500397064635
Validation loss: 2.507531191540945

Epoch: 6| Step: 8
Training loss: 3.0594249000415323
Validation loss: 2.5374700361327815

Epoch: 6| Step: 9
Training loss: 2.5992855154026993
Validation loss: 2.5143912741064227

Epoch: 6| Step: 10
Training loss: 3.0360600955729886
Validation loss: 2.482687412756036

Epoch: 6| Step: 11
Training loss: 2.6082459708341466
Validation loss: 2.486132164880104

Epoch: 6| Step: 12
Training loss: 2.2452626689353403
Validation loss: 2.5154186386554023

Epoch: 6| Step: 13
Training loss: 2.8842050553964964
Validation loss: 2.4995687440923895

Epoch: 252| Step: 0
Training loss: 2.6850912255501425
Validation loss: 2.504737383181628

Epoch: 6| Step: 1
Training loss: 2.68340655122304
Validation loss: 2.468365773438872

Epoch: 6| Step: 2
Training loss: 2.7965196778048265
Validation loss: 2.46017429531705

Epoch: 6| Step: 3
Training loss: 3.26089339178475
Validation loss: 2.455323381131905

Epoch: 6| Step: 4
Training loss: 2.6827630280080688
Validation loss: 2.4500568286197346

Epoch: 6| Step: 5
Training loss: 2.3129587491682604
Validation loss: 2.4461045371445556

Epoch: 6| Step: 6
Training loss: 3.073098973615354
Validation loss: 2.453780262896978

Epoch: 6| Step: 7
Training loss: 2.754127006610712
Validation loss: 2.445693165861266

Epoch: 6| Step: 8
Training loss: 2.211853700197339
Validation loss: 2.4491217832922194

Epoch: 6| Step: 9
Training loss: 2.5118075958722716
Validation loss: 2.454063042322946

Epoch: 6| Step: 10
Training loss: 2.385232865583376
Validation loss: 2.473514945555582

Epoch: 6| Step: 11
Training loss: 3.012792334084019
Validation loss: 2.4830312801480177

Epoch: 6| Step: 12
Training loss: 2.7279640246393577
Validation loss: 2.520812758020489

Epoch: 6| Step: 13
Training loss: 3.2290945393700468
Validation loss: 2.5443921111225545

Epoch: 253| Step: 0
Training loss: 2.9290562470968746
Validation loss: 2.571808064561517

Epoch: 6| Step: 1
Training loss: 2.343487941078526
Validation loss: 2.5883579558289194

Epoch: 6| Step: 2
Training loss: 2.2842866726562048
Validation loss: 2.578342859852327

Epoch: 6| Step: 3
Training loss: 3.0018087338709063
Validation loss: 2.5428417749940797

Epoch: 6| Step: 4
Training loss: 2.4739364034115754
Validation loss: 2.515771496618617

Epoch: 6| Step: 5
Training loss: 3.2169261320418396
Validation loss: 2.476317499459568

Epoch: 6| Step: 6
Training loss: 2.429387310164706
Validation loss: 2.4770888523620687

Epoch: 6| Step: 7
Training loss: 1.8207103638258533
Validation loss: 2.481839793996279

Epoch: 6| Step: 8
Training loss: 3.066310924822058
Validation loss: 2.4794920934116607

Epoch: 6| Step: 9
Training loss: 2.3721006665539357
Validation loss: 2.481416553261359

Epoch: 6| Step: 10
Training loss: 2.9002413419073583
Validation loss: 2.4763258529850756

Epoch: 6| Step: 11
Training loss: 3.0491773465214433
Validation loss: 2.476616222197063

Epoch: 6| Step: 12
Training loss: 3.0904017353318625
Validation loss: 2.475177114858771

Epoch: 6| Step: 13
Training loss: 2.714264952071095
Validation loss: 2.471948726130127

Epoch: 254| Step: 0
Training loss: 3.000155921698803
Validation loss: 2.488015009926816

Epoch: 6| Step: 1
Training loss: 2.985396764510998
Validation loss: 2.519418691881055

Epoch: 6| Step: 2
Training loss: 2.8224268038966915
Validation loss: 2.5030332120296195

Epoch: 6| Step: 3
Training loss: 2.32659626379678
Validation loss: 2.5027642042617573

Epoch: 6| Step: 4
Training loss: 2.903585874112341
Validation loss: 2.495169398514453

Epoch: 6| Step: 5
Training loss: 2.3988317109742576
Validation loss: 2.499475976926861

Epoch: 6| Step: 6
Training loss: 2.7813153205658923
Validation loss: 2.5088932628497127

Epoch: 6| Step: 7
Training loss: 2.6115175690619594
Validation loss: 2.49936497734577

Epoch: 6| Step: 8
Training loss: 2.799172507353134
Validation loss: 2.481815391234962

Epoch: 6| Step: 9
Training loss: 2.5371868071805928
Validation loss: 2.4656715810702

Epoch: 6| Step: 10
Training loss: 2.536342819267653
Validation loss: 2.4721179013166212

Epoch: 6| Step: 11
Training loss: 2.3399356575621395
Validation loss: 2.472377847286258

Epoch: 6| Step: 12
Training loss: 2.858742565817564
Validation loss: 2.4743465168692396

Epoch: 6| Step: 13
Training loss: 2.9107480260312677
Validation loss: 2.4846243454272066

Epoch: 255| Step: 0
Training loss: 2.9268278686977545
Validation loss: 2.4978402211901183

Epoch: 6| Step: 1
Training loss: 3.2837520687356685
Validation loss: 2.4738246703295443

Epoch: 6| Step: 2
Training loss: 2.5885973386451253
Validation loss: 2.499370278244548

Epoch: 6| Step: 3
Training loss: 3.2261872523641424
Validation loss: 2.5020451783784106

Epoch: 6| Step: 4
Training loss: 2.396372748202507
Validation loss: 2.480048998695326

Epoch: 6| Step: 5
Training loss: 2.75960113186352
Validation loss: 2.463617387447482

Epoch: 6| Step: 6
Training loss: 2.5630540016310817
Validation loss: 2.463003314160404

Epoch: 6| Step: 7
Training loss: 2.6810461220222686
Validation loss: 2.4662579125703403

Epoch: 6| Step: 8
Training loss: 2.219921716048681
Validation loss: 2.4556181996578856

Epoch: 6| Step: 9
Training loss: 2.4152704568432304
Validation loss: 2.446465073945068

Epoch: 6| Step: 10
Training loss: 2.5779888695120707
Validation loss: 2.448011966090427

Epoch: 6| Step: 11
Training loss: 2.8822894358422393
Validation loss: 2.4501938267528076

Epoch: 6| Step: 12
Training loss: 2.1838465017167077
Validation loss: 2.4539207681557973

Epoch: 6| Step: 13
Training loss: 3.0083551090822556
Validation loss: 2.4471751430254067

Epoch: 256| Step: 0
Training loss: 2.62855271205399
Validation loss: 2.4554876295878336

Epoch: 6| Step: 1
Training loss: 3.214365815875132
Validation loss: 2.4550830923474916

Epoch: 6| Step: 2
Training loss: 2.414403008701682
Validation loss: 2.496003996603498

Epoch: 6| Step: 3
Training loss: 2.265056459847389
Validation loss: 2.5018373751605703

Epoch: 6| Step: 4
Training loss: 2.6409647344959604
Validation loss: 2.509947166677773

Epoch: 6| Step: 5
Training loss: 2.4049491834129437
Validation loss: 2.5227084381498144

Epoch: 6| Step: 6
Training loss: 2.6334852496723236
Validation loss: 2.569549496169866

Epoch: 6| Step: 7
Training loss: 3.0158201164412053
Validation loss: 2.577744582105619

Epoch: 6| Step: 8
Training loss: 3.015362031371493
Validation loss: 2.5480508667372828

Epoch: 6| Step: 9
Training loss: 3.078118338795537
Validation loss: 2.523406766857163

Epoch: 6| Step: 10
Training loss: 2.6420286161272095
Validation loss: 2.445146066651971

Epoch: 6| Step: 11
Training loss: 2.5444502258050012
Validation loss: 2.4593029796959995

Epoch: 6| Step: 12
Training loss: 2.4820501617969506
Validation loss: 2.444375711146231

Epoch: 6| Step: 13
Training loss: 2.231855025125945
Validation loss: 2.442256170838961

Epoch: 257| Step: 0
Training loss: 2.043393501196581
Validation loss: 2.4493099153222126

Epoch: 6| Step: 1
Training loss: 2.6157245247887437
Validation loss: 2.449418541420623

Epoch: 6| Step: 2
Training loss: 2.9890288969744407
Validation loss: 2.4607686167303187

Epoch: 6| Step: 3
Training loss: 3.3471853131958533
Validation loss: 2.445077090041741

Epoch: 6| Step: 4
Training loss: 3.1987736617089326
Validation loss: 2.441149601397983

Epoch: 6| Step: 5
Training loss: 2.6712158460847957
Validation loss: 2.4604285929388574

Epoch: 6| Step: 6
Training loss: 2.1548742798423923
Validation loss: 2.462775670769266

Epoch: 6| Step: 7
Training loss: 2.713005398546325
Validation loss: 2.470153652551893

Epoch: 6| Step: 8
Training loss: 2.618970394647399
Validation loss: 2.484202031110747

Epoch: 6| Step: 9
Training loss: 2.9720192024873615
Validation loss: 2.5283059171286797

Epoch: 6| Step: 10
Training loss: 3.016850672075119
Validation loss: 2.5744951197441215

Epoch: 6| Step: 11
Training loss: 2.6725662854130965
Validation loss: 2.548535004616541

Epoch: 6| Step: 12
Training loss: 2.1717478762959113
Validation loss: 2.499920222332353

Epoch: 6| Step: 13
Training loss: 2.978339198155989
Validation loss: 2.4871020589465664

Epoch: 258| Step: 0
Training loss: 2.2618342816455304
Validation loss: 2.47847960780556

Epoch: 6| Step: 1
Training loss: 2.9560333946829758
Validation loss: 2.4499887797668167

Epoch: 6| Step: 2
Training loss: 2.646465095928394
Validation loss: 2.442642823073384

Epoch: 6| Step: 3
Training loss: 2.4448664931841635
Validation loss: 2.454992210331215

Epoch: 6| Step: 4
Training loss: 3.1635449398267936
Validation loss: 2.453603884436581

Epoch: 6| Step: 5
Training loss: 3.1547408320022186
Validation loss: 2.4511613941773396

Epoch: 6| Step: 6
Training loss: 2.476364753602203
Validation loss: 2.4485517126249525

Epoch: 6| Step: 7
Training loss: 1.8987829576938136
Validation loss: 2.4652085215143673

Epoch: 6| Step: 8
Training loss: 2.6326145358043624
Validation loss: 2.4703003405521655

Epoch: 6| Step: 9
Training loss: 2.867844342656354
Validation loss: 2.508886772232267

Epoch: 6| Step: 10
Training loss: 3.375469457683393
Validation loss: 2.502500490529051

Epoch: 6| Step: 11
Training loss: 2.5250972804601712
Validation loss: 2.5033578513223

Epoch: 6| Step: 12
Training loss: 2.347543215450353
Validation loss: 2.522288205084187

Epoch: 6| Step: 13
Training loss: 3.027463612798484
Validation loss: 2.4814419672423265

Epoch: 259| Step: 0
Training loss: 2.78749095761325
Validation loss: 2.464428985361334

Epoch: 6| Step: 1
Training loss: 2.41573298164823
Validation loss: 2.469855661546153

Epoch: 6| Step: 2
Training loss: 2.332247981187239
Validation loss: 2.4626232992723045

Epoch: 6| Step: 3
Training loss: 2.1477223818724682
Validation loss: 2.5058043195271797

Epoch: 6| Step: 4
Training loss: 2.920877051649811
Validation loss: 2.5091972250404524

Epoch: 6| Step: 5
Training loss: 2.915132791363745
Validation loss: 2.5186041417596323

Epoch: 6| Step: 6
Training loss: 2.9523540479485986
Validation loss: 2.5102308821801174

Epoch: 6| Step: 7
Training loss: 2.31765008631748
Validation loss: 2.5305688190368882

Epoch: 6| Step: 8
Training loss: 3.1888022660981896
Validation loss: 2.5033507779864297

Epoch: 6| Step: 9
Training loss: 3.029576104857257
Validation loss: 2.474002675477819

Epoch: 6| Step: 10
Training loss: 2.7724728048244605
Validation loss: 2.4579627764280225

Epoch: 6| Step: 11
Training loss: 2.1059542575661365
Validation loss: 2.4760374790673425

Epoch: 6| Step: 12
Training loss: 2.8073773674749614
Validation loss: 2.4618329975183433

Epoch: 6| Step: 13
Training loss: 2.8422933348023762
Validation loss: 2.453710572488154

Epoch: 260| Step: 0
Training loss: 2.7316848164347824
Validation loss: 2.443525626836917

Epoch: 6| Step: 1
Training loss: 2.5846387477183876
Validation loss: 2.446287240077297

Epoch: 6| Step: 2
Training loss: 2.6231624893079917
Validation loss: 2.4495700953732396

Epoch: 6| Step: 3
Training loss: 2.562202808545159
Validation loss: 2.4618900474583714

Epoch: 6| Step: 4
Training loss: 2.5056482405998928
Validation loss: 2.4778473738005142

Epoch: 6| Step: 5
Training loss: 2.48280524798343
Validation loss: 2.5065563246389355

Epoch: 6| Step: 6
Training loss: 2.5171027729875264
Validation loss: 2.543419101850341

Epoch: 6| Step: 7
Training loss: 3.182593365159002
Validation loss: 2.5389760376097392

Epoch: 6| Step: 8
Training loss: 3.077164708333292
Validation loss: 2.5703203086660853

Epoch: 6| Step: 9
Training loss: 2.606542088815487
Validation loss: 2.5474386360939367

Epoch: 6| Step: 10
Training loss: 2.9335378344371525
Validation loss: 2.5125665025190584

Epoch: 6| Step: 11
Training loss: 2.806198350732675
Validation loss: 2.480636621746662

Epoch: 6| Step: 12
Training loss: 2.5570794436362148
Validation loss: 2.4481574885021553

Epoch: 6| Step: 13
Training loss: 2.019545888939932
Validation loss: 2.4447588413879977

Epoch: 261| Step: 0
Training loss: 2.4673547785886147
Validation loss: 2.434913655632001

Epoch: 6| Step: 1
Training loss: 2.4288458148238847
Validation loss: 2.4458325183767338

Epoch: 6| Step: 2
Training loss: 2.890040488041988
Validation loss: 2.4375518738617337

Epoch: 6| Step: 3
Training loss: 3.2593454829604855
Validation loss: 2.432639895993083

Epoch: 6| Step: 4
Training loss: 2.30615870183924
Validation loss: 2.4474371767545726

Epoch: 6| Step: 5
Training loss: 2.6321113173415447
Validation loss: 2.437538228709375

Epoch: 6| Step: 6
Training loss: 3.029198650486846
Validation loss: 2.4292175726945158

Epoch: 6| Step: 7
Training loss: 2.737421398689187
Validation loss: 2.4321244733433023

Epoch: 6| Step: 8
Training loss: 2.997255341357961
Validation loss: 2.4462848475559538

Epoch: 6| Step: 9
Training loss: 2.593175341820154
Validation loss: 2.44115449285781

Epoch: 6| Step: 10
Training loss: 2.3061249985972734
Validation loss: 2.4521726660814784

Epoch: 6| Step: 11
Training loss: 2.6081649807192777
Validation loss: 2.4933315493799006

Epoch: 6| Step: 12
Training loss: 2.2035840144750773
Validation loss: 2.495720429559398

Epoch: 6| Step: 13
Training loss: 3.457397441542789
Validation loss: 2.6072778259874623

Epoch: 262| Step: 0
Training loss: 2.4643122709118854
Validation loss: 2.651182354725798

Epoch: 6| Step: 1
Training loss: 2.893696570675586
Validation loss: 2.6377604228609126

Epoch: 6| Step: 2
Training loss: 2.6243118110638934
Validation loss: 2.6581448460170716

Epoch: 6| Step: 3
Training loss: 2.8838583437008833
Validation loss: 2.606561902170713

Epoch: 6| Step: 4
Training loss: 2.8448574718312654
Validation loss: 2.6096998246741796

Epoch: 6| Step: 5
Training loss: 2.6753994188959265
Validation loss: 2.5195206618001085

Epoch: 6| Step: 6
Training loss: 2.7245160924331584
Validation loss: 2.4618990903538553

Epoch: 6| Step: 7
Training loss: 2.3556292781249497
Validation loss: 2.443858902223589

Epoch: 6| Step: 8
Training loss: 2.7963283580020786
Validation loss: 2.4364809609643796

Epoch: 6| Step: 9
Training loss: 2.69141882905941
Validation loss: 2.443772647676035

Epoch: 6| Step: 10
Training loss: 2.702041497025527
Validation loss: 2.441756747249098

Epoch: 6| Step: 11
Training loss: 2.901034361432304
Validation loss: 2.440287271919288

Epoch: 6| Step: 12
Training loss: 3.0235859048384897
Validation loss: 2.456560221955219

Epoch: 6| Step: 13
Training loss: 2.8760980913945273
Validation loss: 2.440892295112506

Epoch: 263| Step: 0
Training loss: 2.2606916714456013
Validation loss: 2.4602667469174286

Epoch: 6| Step: 1
Training loss: 2.836175913811926
Validation loss: 2.4583131411477304

Epoch: 6| Step: 2
Training loss: 3.1996142989409373
Validation loss: 2.468236980766845

Epoch: 6| Step: 3
Training loss: 3.0166127855185367
Validation loss: 2.4755219364228314

Epoch: 6| Step: 4
Training loss: 2.8720528797605076
Validation loss: 2.5095201740891753

Epoch: 6| Step: 5
Training loss: 3.0344655393691884
Validation loss: 2.5583994907134215

Epoch: 6| Step: 6
Training loss: 1.8699632387066811
Validation loss: 2.649649783005564

Epoch: 6| Step: 7
Training loss: 2.1955309993299013
Validation loss: 2.687219403350145

Epoch: 6| Step: 8
Training loss: 3.415635364234047
Validation loss: 2.698766056712121

Epoch: 6| Step: 9
Training loss: 2.8634880792667077
Validation loss: 2.6348226541631785

Epoch: 6| Step: 10
Training loss: 2.3463088245364583
Validation loss: 2.568095209623155

Epoch: 6| Step: 11
Training loss: 2.817158295728108
Validation loss: 2.548205385223825

Epoch: 6| Step: 12
Training loss: 2.66958153877974
Validation loss: 2.4863685848407693

Epoch: 6| Step: 13
Training loss: 2.663684448982274
Validation loss: 2.463511247067031

Epoch: 264| Step: 0
Training loss: 2.722351057113635
Validation loss: 2.458810644877192

Epoch: 6| Step: 1
Training loss: 2.6435343047907414
Validation loss: 2.469140425485562

Epoch: 6| Step: 2
Training loss: 2.5534087080657546
Validation loss: 2.4488892860027156

Epoch: 6| Step: 3
Training loss: 3.068126570078949
Validation loss: 2.451440446350523

Epoch: 6| Step: 4
Training loss: 3.212871331154075
Validation loss: 2.456395189418056

Epoch: 6| Step: 5
Training loss: 2.773491571463443
Validation loss: 2.455150916467441

Epoch: 6| Step: 6
Training loss: 2.9785820625274786
Validation loss: 2.4479210906991318

Epoch: 6| Step: 7
Training loss: 2.1636347709486703
Validation loss: 2.4664381871614958

Epoch: 6| Step: 8
Training loss: 2.49057633987813
Validation loss: 2.47493040372932

Epoch: 6| Step: 9
Training loss: 2.5973873142622623
Validation loss: 2.4883489100038183

Epoch: 6| Step: 10
Training loss: 2.468176859709049
Validation loss: 2.5054587368099153

Epoch: 6| Step: 11
Training loss: 2.3707783974806538
Validation loss: 2.513877403790376

Epoch: 6| Step: 12
Training loss: 3.13489157165214
Validation loss: 2.517506526546668

Epoch: 6| Step: 13
Training loss: 3.081378746824914
Validation loss: 2.520770431570405

Epoch: 265| Step: 0
Training loss: 2.647196701298604
Validation loss: 2.5377384723761858

Epoch: 6| Step: 1
Training loss: 3.1738553183931186
Validation loss: 2.552128873564831

Epoch: 6| Step: 2
Training loss: 2.1976059849235767
Validation loss: 2.5418051048702357

Epoch: 6| Step: 3
Training loss: 2.1912160644688883
Validation loss: 2.578629289207403

Epoch: 6| Step: 4
Training loss: 2.8031816185514047
Validation loss: 2.6105425745407334

Epoch: 6| Step: 5
Training loss: 3.20840807410702
Validation loss: 2.5289942713166376

Epoch: 6| Step: 6
Training loss: 2.866724460226231
Validation loss: 2.4922872008992383

Epoch: 6| Step: 7
Training loss: 2.6894423097435953
Validation loss: 2.461647790877588

Epoch: 6| Step: 8
Training loss: 3.0423003455472784
Validation loss: 2.4601279046080347

Epoch: 6| Step: 9
Training loss: 2.015250237689556
Validation loss: 2.4400141770075225

Epoch: 6| Step: 10
Training loss: 2.468687515433787
Validation loss: 2.432375635811521

Epoch: 6| Step: 11
Training loss: 2.3749002134541874
Validation loss: 2.4397360560947883

Epoch: 6| Step: 12
Training loss: 2.606100895044662
Validation loss: 2.435891540224695

Epoch: 6| Step: 13
Training loss: 3.4562910246526877
Validation loss: 2.4357971393867417

Epoch: 266| Step: 0
Training loss: 2.6251407767194532
Validation loss: 2.4331174429215623

Epoch: 6| Step: 1
Training loss: 2.830840266813184
Validation loss: 2.4456486970639877

Epoch: 6| Step: 2
Training loss: 2.6542223203404527
Validation loss: 2.4585290361291814

Epoch: 6| Step: 3
Training loss: 2.638763945672334
Validation loss: 2.50572228960101

Epoch: 6| Step: 4
Training loss: 2.3388366060109242
Validation loss: 2.5677434537010364

Epoch: 6| Step: 5
Training loss: 3.4076171371242188
Validation loss: 2.610165849564096

Epoch: 6| Step: 6
Training loss: 2.537206916607927
Validation loss: 2.6441256333439522

Epoch: 6| Step: 7
Training loss: 2.558185480755642
Validation loss: 2.677001844311604

Epoch: 6| Step: 8
Training loss: 2.8712276090181508
Validation loss: 2.765501703343845

Epoch: 6| Step: 9
Training loss: 2.4514523775009933
Validation loss: 2.7291069359259925

Epoch: 6| Step: 10
Training loss: 3.1345572238943356
Validation loss: 2.6897567265601223

Epoch: 6| Step: 11
Training loss: 2.898058761158904
Validation loss: 2.535932108088419

Epoch: 6| Step: 12
Training loss: 2.5966940108668517
Validation loss: 2.4597492391778197

Epoch: 6| Step: 13
Training loss: 2.924104869845806
Validation loss: 2.44688419481808

Epoch: 267| Step: 0
Training loss: 2.9565853452913715
Validation loss: 2.4494357574153196

Epoch: 6| Step: 1
Training loss: 2.757079980840591
Validation loss: 2.455177848032492

Epoch: 6| Step: 2
Training loss: 2.0865186246127094
Validation loss: 2.4583819784110688

Epoch: 6| Step: 3
Training loss: 2.9090044648158173
Validation loss: 2.461317309584005

Epoch: 6| Step: 4
Training loss: 3.243229195418306
Validation loss: 2.47067927839827

Epoch: 6| Step: 5
Training loss: 2.8711618428362393
Validation loss: 2.4816611650675173

Epoch: 6| Step: 6
Training loss: 2.8364277565650937
Validation loss: 2.4644337174879745

Epoch: 6| Step: 7
Training loss: 2.596100626777681
Validation loss: 2.467218212778266

Epoch: 6| Step: 8
Training loss: 3.17305789932915
Validation loss: 2.472759168544578

Epoch: 6| Step: 9
Training loss: 3.0922393193078594
Validation loss: 2.4642394358808866

Epoch: 6| Step: 10
Training loss: 2.2377247276613605
Validation loss: 2.4632326974845813

Epoch: 6| Step: 11
Training loss: 3.1949761173985434
Validation loss: 2.470379884453864

Epoch: 6| Step: 12
Training loss: 2.9241968405308167
Validation loss: 2.465363522146302

Epoch: 6| Step: 13
Training loss: 2.280010147741389
Validation loss: 2.4703746666333948

Epoch: 268| Step: 0
Training loss: 2.7709651619281295
Validation loss: 2.475487266496892

Epoch: 6| Step: 1
Training loss: 3.0156019140753316
Validation loss: 2.4702071892899635

Epoch: 6| Step: 2
Training loss: 3.2159499053374785
Validation loss: 2.4683392454170994

Epoch: 6| Step: 3
Training loss: 2.3620973758635615
Validation loss: 2.4880684786598724

Epoch: 6| Step: 4
Training loss: 3.0035357302576857
Validation loss: 2.496022195686063

Epoch: 6| Step: 5
Training loss: 2.8309037693691077
Validation loss: 2.526805906613734

Epoch: 6| Step: 6
Training loss: 1.9432614709163933
Validation loss: 2.543286518629487

Epoch: 6| Step: 7
Training loss: 3.0357311985602595
Validation loss: 2.556714416425191

Epoch: 6| Step: 8
Training loss: 2.5345685891980927
Validation loss: 2.555478123221034

Epoch: 6| Step: 9
Training loss: 2.4965244930447925
Validation loss: 2.5437340467330225

Epoch: 6| Step: 10
Training loss: 3.081169210926246
Validation loss: 2.525481464736914

Epoch: 6| Step: 11
Training loss: 2.4692038589682213
Validation loss: 2.5081834860825194

Epoch: 6| Step: 12
Training loss: 2.511128072859531
Validation loss: 2.499164012883222

Epoch: 6| Step: 13
Training loss: 2.519842651995201
Validation loss: 2.493149639972378

Epoch: 269| Step: 0
Training loss: 2.821824954783598
Validation loss: 2.4982236755535876

Epoch: 6| Step: 1
Training loss: 2.833101562295336
Validation loss: 2.5017426211154823

Epoch: 6| Step: 2
Training loss: 2.194358102358017
Validation loss: 2.4972533375984423

Epoch: 6| Step: 3
Training loss: 2.8895228578766092
Validation loss: 2.4976542984081176

Epoch: 6| Step: 4
Training loss: 2.7119933608882514
Validation loss: 2.493068209634575

Epoch: 6| Step: 5
Training loss: 2.6795606221671218
Validation loss: 2.5126645204067164

Epoch: 6| Step: 6
Training loss: 2.8039156986140084
Validation loss: 2.5179196221445013

Epoch: 6| Step: 7
Training loss: 2.430101561759069
Validation loss: 2.5051848063143307

Epoch: 6| Step: 8
Training loss: 2.754042688331172
Validation loss: 2.545459250396644

Epoch: 6| Step: 9
Training loss: 2.469446977180905
Validation loss: 2.507644291420918

Epoch: 6| Step: 10
Training loss: 2.8607691300170988
Validation loss: 2.4988411463246862

Epoch: 6| Step: 11
Training loss: 2.865286298098038
Validation loss: 2.5109131657834767

Epoch: 6| Step: 12
Training loss: 2.0160343434647983
Validation loss: 2.4864018595762567

Epoch: 6| Step: 13
Training loss: 3.514552787884701
Validation loss: 2.493189484238285

Epoch: 270| Step: 0
Training loss: 2.288501032690074
Validation loss: 2.4749416405343787

Epoch: 6| Step: 1
Training loss: 2.904287023982957
Validation loss: 2.494560650434111

Epoch: 6| Step: 2
Training loss: 2.9437586887498663
Validation loss: 2.4728657745270137

Epoch: 6| Step: 3
Training loss: 2.910229327417202
Validation loss: 2.46868248615237

Epoch: 6| Step: 4
Training loss: 2.603756640897826
Validation loss: 2.472364963609143

Epoch: 6| Step: 5
Training loss: 2.5614275665317705
Validation loss: 2.457142513494897

Epoch: 6| Step: 6
Training loss: 2.806170313326078
Validation loss: 2.4478441819818126

Epoch: 6| Step: 7
Training loss: 1.4523954303281899
Validation loss: 2.4658724846930626

Epoch: 6| Step: 8
Training loss: 2.5452312009226
Validation loss: 2.4790928237546743

Epoch: 6| Step: 9
Training loss: 2.92347094355119
Validation loss: 2.4741314488167516

Epoch: 6| Step: 10
Training loss: 2.291470143532569
Validation loss: 2.4908391423330696

Epoch: 6| Step: 11
Training loss: 3.166319242458981
Validation loss: 2.5311211518136676

Epoch: 6| Step: 12
Training loss: 3.1748486940871183
Validation loss: 2.5882316920903734

Epoch: 6| Step: 13
Training loss: 2.1928058037799016
Validation loss: 2.6737656092199975

Epoch: 271| Step: 0
Training loss: 2.7851487168989992
Validation loss: 2.6734571969726795

Epoch: 6| Step: 1
Training loss: 3.0781596999947674
Validation loss: 2.6665239100417373

Epoch: 6| Step: 2
Training loss: 2.8525031223664508
Validation loss: 2.5927216771735435

Epoch: 6| Step: 3
Training loss: 2.055699320511173
Validation loss: 2.5352476852989865

Epoch: 6| Step: 4
Training loss: 2.5802256031610895
Validation loss: 2.487635448014765

Epoch: 6| Step: 5
Training loss: 3.2910488047752495
Validation loss: 2.463460306968136

Epoch: 6| Step: 6
Training loss: 2.621900272361252
Validation loss: 2.427142862935491

Epoch: 6| Step: 7
Training loss: 2.606934828399806
Validation loss: 2.436972776430442

Epoch: 6| Step: 8
Training loss: 2.3869351103216507
Validation loss: 2.4586571663842975

Epoch: 6| Step: 9
Training loss: 3.0061079471517984
Validation loss: 2.44134114601535

Epoch: 6| Step: 10
Training loss: 2.530244038689689
Validation loss: 2.4472441762567576

Epoch: 6| Step: 11
Training loss: 2.772316805649425
Validation loss: 2.448683225215871

Epoch: 6| Step: 12
Training loss: 2.790026586262357
Validation loss: 2.4443351697719593

Epoch: 6| Step: 13
Training loss: 1.501773897943913
Validation loss: 2.4380119086991447

Epoch: 272| Step: 0
Training loss: 3.081995510575814
Validation loss: 2.4599596952605958

Epoch: 6| Step: 1
Training loss: 2.8329118714364703
Validation loss: 2.443606088466647

Epoch: 6| Step: 2
Training loss: 3.2640818184901326
Validation loss: 2.452991714759922

Epoch: 6| Step: 3
Training loss: 2.639551791088198
Validation loss: 2.4315740460323485

Epoch: 6| Step: 4
Training loss: 2.4051483406745238
Validation loss: 2.4461471085779793

Epoch: 6| Step: 5
Training loss: 2.7669421146956905
Validation loss: 2.4410292593678897

Epoch: 6| Step: 6
Training loss: 2.5055802056715772
Validation loss: 2.4521054422865713

Epoch: 6| Step: 7
Training loss: 2.8608541362956896
Validation loss: 2.462105907843248

Epoch: 6| Step: 8
Training loss: 2.224774951483254
Validation loss: 2.473259660198328

Epoch: 6| Step: 9
Training loss: 2.730128189263202
Validation loss: 2.464423421017901

Epoch: 6| Step: 10
Training loss: 2.534735646205059
Validation loss: 2.4725565418898783

Epoch: 6| Step: 11
Training loss: 2.4414685538925123
Validation loss: 2.5078216344026636

Epoch: 6| Step: 12
Training loss: 2.782879469942253
Validation loss: 2.5489952300735648

Epoch: 6| Step: 13
Training loss: 1.9667555985575325
Validation loss: 2.5251075843545703

Epoch: 273| Step: 0
Training loss: 2.6446374508425396
Validation loss: 2.5625008113608687

Epoch: 6| Step: 1
Training loss: 2.415843516505205
Validation loss: 2.571632086166107

Epoch: 6| Step: 2
Training loss: 2.6662697695371627
Validation loss: 2.547474509560322

Epoch: 6| Step: 3
Training loss: 2.49653289704792
Validation loss: 2.5447842635182365

Epoch: 6| Step: 4
Training loss: 2.7931836879161596
Validation loss: 2.5506475960994974

Epoch: 6| Step: 5
Training loss: 3.011444673053095
Validation loss: 2.5634050209231107

Epoch: 6| Step: 6
Training loss: 2.4607419859711004
Validation loss: 2.523670594807072

Epoch: 6| Step: 7
Training loss: 3.0715053269943846
Validation loss: 2.5004061866284704

Epoch: 6| Step: 8
Training loss: 2.7578768195845793
Validation loss: 2.478841252701628

Epoch: 6| Step: 9
Training loss: 2.4097820962240006
Validation loss: 2.442761067715635

Epoch: 6| Step: 10
Training loss: 2.051869131097874
Validation loss: 2.4208479562318144

Epoch: 6| Step: 11
Training loss: 2.877485610567997
Validation loss: 2.44716429204539

Epoch: 6| Step: 12
Training loss: 2.918762344236226
Validation loss: 2.4398089890142405

Epoch: 6| Step: 13
Training loss: 3.274105031271651
Validation loss: 2.4329974704287554

Epoch: 274| Step: 0
Training loss: 2.3601468068059908
Validation loss: 2.4344472581935603

Epoch: 6| Step: 1
Training loss: 2.2942002480798824
Validation loss: 2.4290475347088076

Epoch: 6| Step: 2
Training loss: 2.8154793112063627
Validation loss: 2.41712261399513

Epoch: 6| Step: 3
Training loss: 3.1859191265390225
Validation loss: 2.4542435373614997

Epoch: 6| Step: 4
Training loss: 2.6960271357860126
Validation loss: 2.445259143716781

Epoch: 6| Step: 5
Training loss: 2.025122217328423
Validation loss: 2.4652655016589464

Epoch: 6| Step: 6
Training loss: 2.72101717722615
Validation loss: 2.456090603502236

Epoch: 6| Step: 7
Training loss: 2.8211972019323928
Validation loss: 2.4812409232335626

Epoch: 6| Step: 8
Training loss: 3.0502491583440388
Validation loss: 2.4979660086642963

Epoch: 6| Step: 9
Training loss: 2.529252005514172
Validation loss: 2.5377173680583867

Epoch: 6| Step: 10
Training loss: 2.551476002784593
Validation loss: 2.5457476182885257

Epoch: 6| Step: 11
Training loss: 2.627504425625835
Validation loss: 2.547413154928418

Epoch: 6| Step: 12
Training loss: 2.784422704285859
Validation loss: 2.535778250537128

Epoch: 6| Step: 13
Training loss: 3.0355782037575527
Validation loss: 2.499074129708505

Epoch: 275| Step: 0
Training loss: 2.9111932532617812
Validation loss: 2.466944875578839

Epoch: 6| Step: 1
Training loss: 2.6756978488371
Validation loss: 2.450257754919516

Epoch: 6| Step: 2
Training loss: 3.0048883665552344
Validation loss: 2.4575961147564684

Epoch: 6| Step: 3
Training loss: 2.7026329695237092
Validation loss: 2.441906847619067

Epoch: 6| Step: 4
Training loss: 2.7719376927869197
Validation loss: 2.4459546928011293

Epoch: 6| Step: 5
Training loss: 2.828873677502083
Validation loss: 2.437762430103236

Epoch: 6| Step: 6
Training loss: 2.3568742648588628
Validation loss: 2.433739931229514

Epoch: 6| Step: 7
Training loss: 2.9797999280293945
Validation loss: 2.4674798437673093

Epoch: 6| Step: 8
Training loss: 2.8302090379594516
Validation loss: 2.4486759709119688

Epoch: 6| Step: 9
Training loss: 2.676933986985617
Validation loss: 2.4706123340233117

Epoch: 6| Step: 10
Training loss: 2.5473002447365163
Validation loss: 2.471893868489003

Epoch: 6| Step: 11
Training loss: 2.648178673083902
Validation loss: 2.501130942420613

Epoch: 6| Step: 12
Training loss: 2.031056321520643
Validation loss: 2.531820748661251

Epoch: 6| Step: 13
Training loss: 1.7115487178340227
Validation loss: 2.560470853130853

Epoch: 276| Step: 0
Training loss: 2.433251223637622
Validation loss: 2.547287359575398

Epoch: 6| Step: 1
Training loss: 3.108077962440046
Validation loss: 2.5597319670641947

Epoch: 6| Step: 2
Training loss: 2.8630357665700195
Validation loss: 2.5969659818803343

Epoch: 6| Step: 3
Training loss: 2.8681600724563667
Validation loss: 2.572115765799046

Epoch: 6| Step: 4
Training loss: 2.3419638376156064
Validation loss: 2.5505201630764422

Epoch: 6| Step: 5
Training loss: 2.5923454434298083
Validation loss: 2.5190482938816525

Epoch: 6| Step: 6
Training loss: 2.746111114143181
Validation loss: 2.481324359662651

Epoch: 6| Step: 7
Training loss: 2.5262952749356336
Validation loss: 2.4516043264835936

Epoch: 6| Step: 8
Training loss: 2.8376884834773977
Validation loss: 2.4378421891384914

Epoch: 6| Step: 9
Training loss: 2.9911218244459317
Validation loss: 2.4331287137299

Epoch: 6| Step: 10
Training loss: 2.7238724781945685
Validation loss: 2.432683288985817

Epoch: 6| Step: 11
Training loss: 2.2803899110376507
Validation loss: 2.438699008271081

Epoch: 6| Step: 12
Training loss: 2.578127404414125
Validation loss: 2.4408461366055625

Epoch: 6| Step: 13
Training loss: 2.187799378753359
Validation loss: 2.458581767626238

Epoch: 277| Step: 0
Training loss: 2.546645265292905
Validation loss: 2.4430627161531504

Epoch: 6| Step: 1
Training loss: 2.368145537943011
Validation loss: 2.463940959547496

Epoch: 6| Step: 2
Training loss: 2.7463853662229316
Validation loss: 2.4791155284454796

Epoch: 6| Step: 3
Training loss: 3.2759835258786962
Validation loss: 2.497601147797176

Epoch: 6| Step: 4
Training loss: 2.4170324333770496
Validation loss: 2.4960886773403836

Epoch: 6| Step: 5
Training loss: 1.9446971486897568
Validation loss: 2.501551348791061

Epoch: 6| Step: 6
Training loss: 2.196701099355501
Validation loss: 2.5112405391050143

Epoch: 6| Step: 7
Training loss: 2.693128059971528
Validation loss: 2.5228334826143306

Epoch: 6| Step: 8
Training loss: 2.720863923567305
Validation loss: 2.540352703781172

Epoch: 6| Step: 9
Training loss: 2.8974673557499693
Validation loss: 2.5380568857437646

Epoch: 6| Step: 10
Training loss: 2.4623116668096334
Validation loss: 2.518604451195598

Epoch: 6| Step: 11
Training loss: 3.052968666033317
Validation loss: 2.498505409128074

Epoch: 6| Step: 12
Training loss: 2.7734667279489833
Validation loss: 2.5010038062857753

Epoch: 6| Step: 13
Training loss: 3.1679958431717545
Validation loss: 2.4591721246860287

Epoch: 278| Step: 0
Training loss: 2.789228845759364
Validation loss: 2.434214202369469

Epoch: 6| Step: 1
Training loss: 2.8052936207162693
Validation loss: 2.4244383241293344

Epoch: 6| Step: 2
Training loss: 2.5370044994923315
Validation loss: 2.4221053898760156

Epoch: 6| Step: 3
Training loss: 2.7369837931779304
Validation loss: 2.423612458170444

Epoch: 6| Step: 4
Training loss: 2.792267568643134
Validation loss: 2.4306987115175995

Epoch: 6| Step: 5
Training loss: 2.217695388529207
Validation loss: 2.4239635289069787

Epoch: 6| Step: 6
Training loss: 2.4326388474108467
Validation loss: 2.416230298816355

Epoch: 6| Step: 7
Training loss: 2.472598781791695
Validation loss: 2.433543654283913

Epoch: 6| Step: 8
Training loss: 2.7778129342291575
Validation loss: 2.4373234500057013

Epoch: 6| Step: 9
Training loss: 2.5900372509137015
Validation loss: 2.4448201559491576

Epoch: 6| Step: 10
Training loss: 3.117075217765527
Validation loss: 2.4474640371278236

Epoch: 6| Step: 11
Training loss: 2.698807283388099
Validation loss: 2.4591804191734754

Epoch: 6| Step: 12
Training loss: 2.5638780377581885
Validation loss: 2.470582280269302

Epoch: 6| Step: 13
Training loss: 2.7742840401763824
Validation loss: 2.5073517866967863

Epoch: 279| Step: 0
Training loss: 2.366273911441468
Validation loss: 2.5493041240945757

Epoch: 6| Step: 1
Training loss: 3.116819737665239
Validation loss: 2.6025669856663765

Epoch: 6| Step: 2
Training loss: 3.1988884425791415
Validation loss: 2.571889208762353

Epoch: 6| Step: 3
Training loss: 2.832453497616882
Validation loss: 2.5146718824348797

Epoch: 6| Step: 4
Training loss: 2.8186013057761206
Validation loss: 2.525911827459075

Epoch: 6| Step: 5
Training loss: 2.513003482001033
Validation loss: 2.5023078981686973

Epoch: 6| Step: 6
Training loss: 2.5664085724934793
Validation loss: 2.4850877918386773

Epoch: 6| Step: 7
Training loss: 2.4954819862359114
Validation loss: 2.4660596080856263

Epoch: 6| Step: 8
Training loss: 2.505469633077877
Validation loss: 2.448353369793695

Epoch: 6| Step: 9
Training loss: 2.59864363870584
Validation loss: 2.4324925315069548

Epoch: 6| Step: 10
Training loss: 2.646423654457939
Validation loss: 2.4329536357374772

Epoch: 6| Step: 11
Training loss: 2.4591280627821313
Validation loss: 2.427637522742551

Epoch: 6| Step: 12
Training loss: 2.600531296365507
Validation loss: 2.4322696256252647

Epoch: 6| Step: 13
Training loss: 2.551609903655602
Validation loss: 2.426106023049549

Epoch: 280| Step: 0
Training loss: 2.411171771847558
Validation loss: 2.4276688336174015

Epoch: 6| Step: 1
Training loss: 2.9604085887679714
Validation loss: 2.4271503368643987

Epoch: 6| Step: 2
Training loss: 2.4454281325620424
Validation loss: 2.426504273522888

Epoch: 6| Step: 3
Training loss: 2.5602760899200327
Validation loss: 2.4358812557154046

Epoch: 6| Step: 4
Training loss: 2.8802611269719796
Validation loss: 2.469812253182179

Epoch: 6| Step: 5
Training loss: 2.664197901531831
Validation loss: 2.4606201821518576

Epoch: 6| Step: 6
Training loss: 2.5473196191539187
Validation loss: 2.478129649737578

Epoch: 6| Step: 7
Training loss: 3.2767602630731583
Validation loss: 2.501881647068391

Epoch: 6| Step: 8
Training loss: 2.896635662508476
Validation loss: 2.4995876238766352

Epoch: 6| Step: 9
Training loss: 1.9317272695273133
Validation loss: 2.493168126211525

Epoch: 6| Step: 10
Training loss: 2.4928465542781146
Validation loss: 2.502676236871297

Epoch: 6| Step: 11
Training loss: 2.1744674469104703
Validation loss: 2.5100212461445586

Epoch: 6| Step: 12
Training loss: 2.790094521264746
Validation loss: 2.5358430418894686

Epoch: 6| Step: 13
Training loss: 3.0770075749752515
Validation loss: 2.5264224889458546

Epoch: 281| Step: 0
Training loss: 2.657133965103811
Validation loss: 2.5067477356209986

Epoch: 6| Step: 1
Training loss: 2.355304769245431
Validation loss: 2.4610825966756837

Epoch: 6| Step: 2
Training loss: 2.901570808920521
Validation loss: 2.44240515938975

Epoch: 6| Step: 3
Training loss: 2.828658080046699
Validation loss: 2.449339120101863

Epoch: 6| Step: 4
Training loss: 2.5728808154698486
Validation loss: 2.4562741960143013

Epoch: 6| Step: 5
Training loss: 2.911000297061508
Validation loss: 2.439827347205006

Epoch: 6| Step: 6
Training loss: 2.393793835749033
Validation loss: 2.4349408720960866

Epoch: 6| Step: 7
Training loss: 1.5663007667393984
Validation loss: 2.441327626002126

Epoch: 6| Step: 8
Training loss: 2.4634695439067444
Validation loss: 2.4615398440059364

Epoch: 6| Step: 9
Training loss: 2.924217549842794
Validation loss: 2.4565596031065238

Epoch: 6| Step: 10
Training loss: 2.596654529600299
Validation loss: 2.4555137587737614

Epoch: 6| Step: 11
Training loss: 3.023361007945097
Validation loss: 2.481889933356511

Epoch: 6| Step: 12
Training loss: 2.880195898175198
Validation loss: 2.4626127859867157

Epoch: 6| Step: 13
Training loss: 2.7647376064633646
Validation loss: 2.4703991626897985

Epoch: 282| Step: 0
Training loss: 2.1869100592616526
Validation loss: 2.4939529420666062

Epoch: 6| Step: 1
Training loss: 2.7545835270898653
Validation loss: 2.489671032583263

Epoch: 6| Step: 2
Training loss: 2.506623268394308
Validation loss: 2.5267076692439647

Epoch: 6| Step: 3
Training loss: 2.711884522818053
Validation loss: 2.518002685178918

Epoch: 6| Step: 4
Training loss: 3.0440360120931422
Validation loss: 2.5179964593389066

Epoch: 6| Step: 5
Training loss: 2.6315502910559565
Validation loss: 2.4968367447828754

Epoch: 6| Step: 6
Training loss: 2.875354081615954
Validation loss: 2.46528161908577

Epoch: 6| Step: 7
Training loss: 3.1530842531745304
Validation loss: 2.431557485878383

Epoch: 6| Step: 8
Training loss: 2.376983617306472
Validation loss: 2.434579852803079

Epoch: 6| Step: 9
Training loss: 1.8456371800181917
Validation loss: 2.4609973364354656

Epoch: 6| Step: 10
Training loss: 2.3640807257615974
Validation loss: 2.4558223517514106

Epoch: 6| Step: 11
Training loss: 2.708498778547322
Validation loss: 2.4619247047685766

Epoch: 6| Step: 12
Training loss: 3.000370479596069
Validation loss: 2.4866796520089522

Epoch: 6| Step: 13
Training loss: 2.751931292607684
Validation loss: 2.5155123129545083

Epoch: 283| Step: 0
Training loss: 1.8713447545791029
Validation loss: 2.5058473816569617

Epoch: 6| Step: 1
Training loss: 2.908629724944558
Validation loss: 2.5305138452675697

Epoch: 6| Step: 2
Training loss: 2.5536403551431293
Validation loss: 2.558355760437627

Epoch: 6| Step: 3
Training loss: 3.197850793083414
Validation loss: 2.5594073525872507

Epoch: 6| Step: 4
Training loss: 2.8180092999296056
Validation loss: 2.5029001068132426

Epoch: 6| Step: 5
Training loss: 2.721807930576606
Validation loss: 2.499037197281786

Epoch: 6| Step: 6
Training loss: 2.815977532167102
Validation loss: 2.4979771233737114

Epoch: 6| Step: 7
Training loss: 2.510331169561415
Validation loss: 2.4937015953632784

Epoch: 6| Step: 8
Training loss: 2.5435090084407577
Validation loss: 2.476118712644328

Epoch: 6| Step: 9
Training loss: 2.2173223066042396
Validation loss: 2.473741622439956

Epoch: 6| Step: 10
Training loss: 2.718355522914985
Validation loss: 2.477746834232093

Epoch: 6| Step: 11
Training loss: 2.358883433891446
Validation loss: 2.4907288560852607

Epoch: 6| Step: 12
Training loss: 2.790109389837087
Validation loss: 2.4885729541816373

Epoch: 6| Step: 13
Training loss: 2.547995665961252
Validation loss: 2.494173243064572

Epoch: 284| Step: 0
Training loss: 2.353857700924674
Validation loss: 2.453510599246322

Epoch: 6| Step: 1
Training loss: 2.1022063336209915
Validation loss: 2.4467297596941564

Epoch: 6| Step: 2
Training loss: 2.7792297912779813
Validation loss: 2.4355547968052598

Epoch: 6| Step: 3
Training loss: 2.6099507501859103
Validation loss: 2.4262892471378947

Epoch: 6| Step: 4
Training loss: 2.8659558886203356
Validation loss: 2.4302189086274946

Epoch: 6| Step: 5
Training loss: 2.721039520520624
Validation loss: 2.453909512402184

Epoch: 6| Step: 6
Training loss: 2.5483285699387768
Validation loss: 2.472903770633413

Epoch: 6| Step: 7
Training loss: 2.785446943652548
Validation loss: 2.4815101835724533

Epoch: 6| Step: 8
Training loss: 2.2354697366644176
Validation loss: 2.5260937594763906

Epoch: 6| Step: 9
Training loss: 3.0817518216367024
Validation loss: 2.5909859599567295

Epoch: 6| Step: 10
Training loss: 2.7513102964443243
Validation loss: 2.581616310046323

Epoch: 6| Step: 11
Training loss: 3.319995963772078
Validation loss: 2.575657245886329

Epoch: 6| Step: 12
Training loss: 2.521543376536652
Validation loss: 2.5478746093383804

Epoch: 6| Step: 13
Training loss: 2.6171740175725486
Validation loss: 2.4925292072026286

Epoch: 285| Step: 0
Training loss: 2.174150770291805
Validation loss: 2.439128416977126

Epoch: 6| Step: 1
Training loss: 2.8289314932593697
Validation loss: 2.422127748149551

Epoch: 6| Step: 2
Training loss: 2.6751387444282058
Validation loss: 2.422011926162969

Epoch: 6| Step: 3
Training loss: 2.992359604629425
Validation loss: 2.4213351121295745

Epoch: 6| Step: 4
Training loss: 3.2095151103636113
Validation loss: 2.430224504871464

Epoch: 6| Step: 5
Training loss: 2.107042619662502
Validation loss: 2.4242142784540577

Epoch: 6| Step: 6
Training loss: 3.306653459302101
Validation loss: 2.4159731423199173

Epoch: 6| Step: 7
Training loss: 2.805639078976391
Validation loss: 2.4215566816938097

Epoch: 6| Step: 8
Training loss: 2.626192548614568
Validation loss: 2.4211962788525514

Epoch: 6| Step: 9
Training loss: 2.7647374339923236
Validation loss: 2.4206643298147745

Epoch: 6| Step: 10
Training loss: 2.9320651159406763
Validation loss: 2.3983027628876967

Epoch: 6| Step: 11
Training loss: 2.7399876130652445
Validation loss: 2.4196557583265683

Epoch: 6| Step: 12
Training loss: 1.7548183456917537
Validation loss: 2.4111886538233613

Epoch: 6| Step: 13
Training loss: 2.3697115594647875
Validation loss: 2.4269805179433277

Epoch: 286| Step: 0
Training loss: 2.360463983701779
Validation loss: 2.456220192764781

Epoch: 6| Step: 1
Training loss: 2.8016519509889126
Validation loss: 2.4612126574367164

Epoch: 6| Step: 2
Training loss: 2.4165871267273715
Validation loss: 2.509777056201675

Epoch: 6| Step: 3
Training loss: 2.336126721733553
Validation loss: 2.5670973752657824

Epoch: 6| Step: 4
Training loss: 2.9807149602904857
Validation loss: 2.5707872046329983

Epoch: 6| Step: 5
Training loss: 2.833384980871661
Validation loss: 2.5977714863982

Epoch: 6| Step: 6
Training loss: 2.901025156810816
Validation loss: 2.634409192980695

Epoch: 6| Step: 7
Training loss: 3.016240664869613
Validation loss: 2.620561553679385

Epoch: 6| Step: 8
Training loss: 2.8347940793343356
Validation loss: 2.569269993151713

Epoch: 6| Step: 9
Training loss: 2.2952009055767753
Validation loss: 2.5144441309796823

Epoch: 6| Step: 10
Training loss: 2.8764449096051123
Validation loss: 2.4619908524130025

Epoch: 6| Step: 11
Training loss: 2.030244549081994
Validation loss: 2.4446730967835144

Epoch: 6| Step: 12
Training loss: 2.813728742277697
Validation loss: 2.4343421743948066

Epoch: 6| Step: 13
Training loss: 2.109673712030875
Validation loss: 2.435933198778814

Epoch: 287| Step: 0
Training loss: 2.9317086127401284
Validation loss: 2.4291735985581258

Epoch: 6| Step: 1
Training loss: 2.624082041498771
Validation loss: 2.4399221894401513

Epoch: 6| Step: 2
Training loss: 2.377431628570852
Validation loss: 2.427523666027715

Epoch: 6| Step: 3
Training loss: 2.3358133850806393
Validation loss: 2.4286874132629177

Epoch: 6| Step: 4
Training loss: 2.821197117422674
Validation loss: 2.4477085102696288

Epoch: 6| Step: 5
Training loss: 2.7467351953821515
Validation loss: 2.4484736416123853

Epoch: 6| Step: 6
Training loss: 2.685619849860793
Validation loss: 2.4390869801154103

Epoch: 6| Step: 7
Training loss: 3.0844050598225716
Validation loss: 2.444701115876004

Epoch: 6| Step: 8
Training loss: 2.7788991529595557
Validation loss: 2.4668849371105304

Epoch: 6| Step: 9
Training loss: 2.9438864901055504
Validation loss: 2.50265900298466

Epoch: 6| Step: 10
Training loss: 2.635227080953077
Validation loss: 2.4878525173587733

Epoch: 6| Step: 11
Training loss: 1.9632026386423573
Validation loss: 2.537658341508526

Epoch: 6| Step: 12
Training loss: 2.5180790464251537
Validation loss: 2.593780056813501

Epoch: 6| Step: 13
Training loss: 2.6090815944523484
Validation loss: 2.578703734870373

Epoch: 288| Step: 0
Training loss: 3.016717268236626
Validation loss: 2.618142598897364

Epoch: 6| Step: 1
Training loss: 2.407616363597044
Validation loss: 2.557841996847922

Epoch: 6| Step: 2
Training loss: 2.3950746302434993
Validation loss: 2.5061286172458392

Epoch: 6| Step: 3
Training loss: 2.867319545771534
Validation loss: 2.4793064212125584

Epoch: 6| Step: 4
Training loss: 2.5077337805256077
Validation loss: 2.45105654687818

Epoch: 6| Step: 5
Training loss: 2.7071834372805137
Validation loss: 2.4568026473308806

Epoch: 6| Step: 6
Training loss: 2.50959149064557
Validation loss: 2.458693955676051

Epoch: 6| Step: 7
Training loss: 2.8137388256093447
Validation loss: 2.459897661695752

Epoch: 6| Step: 8
Training loss: 3.129690084013536
Validation loss: 2.4663095786425733

Epoch: 6| Step: 9
Training loss: 2.236276097921009
Validation loss: 2.464845766198933

Epoch: 6| Step: 10
Training loss: 2.312477111703136
Validation loss: 2.4836955870894886

Epoch: 6| Step: 11
Training loss: 2.7316509519927594
Validation loss: 2.450835567906723

Epoch: 6| Step: 12
Training loss: 2.5577023882692074
Validation loss: 2.4609217447745686

Epoch: 6| Step: 13
Training loss: 2.508696688402537
Validation loss: 2.46519407374518

Epoch: 289| Step: 0
Training loss: 2.445971902781047
Validation loss: 2.4603598775394273

Epoch: 6| Step: 1
Training loss: 2.5517061434864123
Validation loss: 2.4678625731739485

Epoch: 6| Step: 2
Training loss: 3.01931284204651
Validation loss: 2.500421154274928

Epoch: 6| Step: 3
Training loss: 2.8305532242259255
Validation loss: 2.4861589175748047

Epoch: 6| Step: 4
Training loss: 2.9076685571069274
Validation loss: 2.4754746734410347

Epoch: 6| Step: 5
Training loss: 3.0584525006297545
Validation loss: 2.4670721614036784

Epoch: 6| Step: 6
Training loss: 1.7582296597017362
Validation loss: 2.4546834367512296

Epoch: 6| Step: 7
Training loss: 2.7719112011116347
Validation loss: 2.4640055714837104

Epoch: 6| Step: 8
Training loss: 2.9507212064379376
Validation loss: 2.458797596272675

Epoch: 6| Step: 9
Training loss: 2.099626635103474
Validation loss: 2.4879654999383223

Epoch: 6| Step: 10
Training loss: 2.3647437244303378
Validation loss: 2.4911125787146413

Epoch: 6| Step: 11
Training loss: 2.546978813817156
Validation loss: 2.5164173997671995

Epoch: 6| Step: 12
Training loss: 2.9462220586099983
Validation loss: 2.5187117661815224

Epoch: 6| Step: 13
Training loss: 1.6558499122919788
Validation loss: 2.508354367935288

Epoch: 290| Step: 0
Training loss: 2.3783061456050816
Validation loss: 2.492450599542496

Epoch: 6| Step: 1
Training loss: 2.4192127977739135
Validation loss: 2.4943439325842616

Epoch: 6| Step: 2
Training loss: 2.8365395487518414
Validation loss: 2.4891064935873723

Epoch: 6| Step: 3
Training loss: 2.618920779975662
Validation loss: 2.522380071272323

Epoch: 6| Step: 4
Training loss: 2.6159488308886387
Validation loss: 2.514850428674625

Epoch: 6| Step: 5
Training loss: 3.314245375965602
Validation loss: 2.5022057575129852

Epoch: 6| Step: 6
Training loss: 2.6133697449165165
Validation loss: 2.491803343094465

Epoch: 6| Step: 7
Training loss: 2.2841232181922693
Validation loss: 2.4778394278746037

Epoch: 6| Step: 8
Training loss: 2.2211417618002645
Validation loss: 2.4902886217045075

Epoch: 6| Step: 9
Training loss: 2.4135111453832487
Validation loss: 2.4944411680722576

Epoch: 6| Step: 10
Training loss: 2.857261668868423
Validation loss: 2.5069005196872753

Epoch: 6| Step: 11
Training loss: 2.638626064351826
Validation loss: 2.5056671820055247

Epoch: 6| Step: 12
Training loss: 2.590240494156077
Validation loss: 2.4896851848854307

Epoch: 6| Step: 13
Training loss: 2.660962042972546
Validation loss: 2.5073853228168295

Epoch: 291| Step: 0
Training loss: 1.9706455974669925
Validation loss: 2.483742036144711

Epoch: 6| Step: 1
Training loss: 2.3373932145966227
Validation loss: 2.456808371891686

Epoch: 6| Step: 2
Training loss: 3.027213013810136
Validation loss: 2.445490035219455

Epoch: 6| Step: 3
Training loss: 2.057995124655418
Validation loss: 2.4499079893772673

Epoch: 6| Step: 4
Training loss: 2.5506808624843
Validation loss: 2.4411055594400355

Epoch: 6| Step: 5
Training loss: 2.4493835491119804
Validation loss: 2.467878626893451

Epoch: 6| Step: 6
Training loss: 2.825789103392935
Validation loss: 2.4796658002530427

Epoch: 6| Step: 7
Training loss: 2.7046841220845637
Validation loss: 2.531091342512842

Epoch: 6| Step: 8
Training loss: 2.9571383216249214
Validation loss: 2.6250574434775857

Epoch: 6| Step: 9
Training loss: 2.4563431739121677
Validation loss: 2.5974452351617803

Epoch: 6| Step: 10
Training loss: 2.9887599187707905
Validation loss: 2.5569402135202126

Epoch: 6| Step: 11
Training loss: 2.8463669358106953
Validation loss: 2.5101133713176638

Epoch: 6| Step: 12
Training loss: 2.1884135927046273
Validation loss: 2.4691602616022528

Epoch: 6| Step: 13
Training loss: 3.6816630314719365
Validation loss: 2.4551538109565763

Epoch: 292| Step: 0
Training loss: 2.54570279907955
Validation loss: 2.4394585996987215

Epoch: 6| Step: 1
Training loss: 1.9623298717062392
Validation loss: 2.429898709221362

Epoch: 6| Step: 2
Training loss: 2.6076290662647943
Validation loss: 2.4304948540377165

Epoch: 6| Step: 3
Training loss: 2.4622333324130454
Validation loss: 2.409063931516393

Epoch: 6| Step: 4
Training loss: 2.5799723162385626
Validation loss: 2.4315270073935475

Epoch: 6| Step: 5
Training loss: 2.8109572523863915
Validation loss: 2.4039956143646863

Epoch: 6| Step: 6
Training loss: 2.8262059566232836
Validation loss: 2.4276554581679615

Epoch: 6| Step: 7
Training loss: 2.848395273938763
Validation loss: 2.425225409504023

Epoch: 6| Step: 8
Training loss: 2.3687706616791413
Validation loss: 2.4299725165974198

Epoch: 6| Step: 9
Training loss: 2.6287066311598672
Validation loss: 2.447860384791329

Epoch: 6| Step: 10
Training loss: 2.51530985309444
Validation loss: 2.4569801285990676

Epoch: 6| Step: 11
Training loss: 2.8387452405438656
Validation loss: 2.4902497553486134

Epoch: 6| Step: 12
Training loss: 2.919042999787248
Validation loss: 2.519559719684478

Epoch: 6| Step: 13
Training loss: 2.6235256596032523
Validation loss: 2.52568616751566

Epoch: 293| Step: 0
Training loss: 2.7386250626983073
Validation loss: 2.5540596775477526

Epoch: 6| Step: 1
Training loss: 2.045901933544149
Validation loss: 2.513657245816037

Epoch: 6| Step: 2
Training loss: 2.699610989415168
Validation loss: 2.523146298830672

Epoch: 6| Step: 3
Training loss: 2.457610287990494
Validation loss: 2.5037801046327193

Epoch: 6| Step: 4
Training loss: 2.619718779402533
Validation loss: 2.4442160263652744

Epoch: 6| Step: 5
Training loss: 3.093175044723432
Validation loss: 2.450400534706724

Epoch: 6| Step: 6
Training loss: 2.84487926153208
Validation loss: 2.438955455668633

Epoch: 6| Step: 7
Training loss: 2.9112784251049306
Validation loss: 2.416123270406914

Epoch: 6| Step: 8
Training loss: 2.7340080668979896
Validation loss: 2.426399682521966

Epoch: 6| Step: 9
Training loss: 2.5396786925072896
Validation loss: 2.4173435844469324

Epoch: 6| Step: 10
Training loss: 2.2673582616077046
Validation loss: 2.420109039698665

Epoch: 6| Step: 11
Training loss: 2.3522589276444688
Validation loss: 2.4123885523702957

Epoch: 6| Step: 12
Training loss: 2.7696594294705488
Validation loss: 2.415681754625144

Epoch: 6| Step: 13
Training loss: 2.9202948392657526
Validation loss: 2.4257301453456073

Epoch: 294| Step: 0
Training loss: 2.75490938137999
Validation loss: 2.4415866354311264

Epoch: 6| Step: 1
Training loss: 2.3528084226631973
Validation loss: 2.45497624464751

Epoch: 6| Step: 2
Training loss: 2.68295400398516
Validation loss: 2.504953098468408

Epoch: 6| Step: 3
Training loss: 2.613792289636232
Validation loss: 2.553579855431252

Epoch: 6| Step: 4
Training loss: 2.898270512215017
Validation loss: 2.6484765306948934

Epoch: 6| Step: 5
Training loss: 2.367653275294535
Validation loss: 2.5903462209741335

Epoch: 6| Step: 6
Training loss: 2.3179544611054257
Validation loss: 2.566793050545644

Epoch: 6| Step: 7
Training loss: 2.642412652743771
Validation loss: 2.5622658651351853

Epoch: 6| Step: 8
Training loss: 2.606024595617364
Validation loss: 2.4899188077515104

Epoch: 6| Step: 9
Training loss: 2.7383808547772435
Validation loss: 2.460770522190619

Epoch: 6| Step: 10
Training loss: 2.3240683627160448
Validation loss: 2.419484462136853

Epoch: 6| Step: 11
Training loss: 3.224210976770827
Validation loss: 2.4182034663727427

Epoch: 6| Step: 12
Training loss: 2.815915894379438
Validation loss: 2.4081228899700386

Epoch: 6| Step: 13
Training loss: 2.107193447457092
Validation loss: 2.426602247557993

Epoch: 295| Step: 0
Training loss: 2.4305612642735848
Validation loss: 2.4128918298060444

Epoch: 6| Step: 1
Training loss: 3.1669263900523115
Validation loss: 2.416124222173418

Epoch: 6| Step: 2
Training loss: 2.3735483652205227
Validation loss: 2.43142684574676

Epoch: 6| Step: 3
Training loss: 2.9063359729807217
Validation loss: 2.4239314234773457

Epoch: 6| Step: 4
Training loss: 2.5669816067508107
Validation loss: 2.4055649840144815

Epoch: 6| Step: 5
Training loss: 2.5246495976313845
Validation loss: 2.4359697019182467

Epoch: 6| Step: 6
Training loss: 2.3952121979876173
Validation loss: 2.4449205385504658

Epoch: 6| Step: 7
Training loss: 2.4249526618977675
Validation loss: 2.47443116795192

Epoch: 6| Step: 8
Training loss: 2.87110537572051
Validation loss: 2.5174006928267136

Epoch: 6| Step: 9
Training loss: 2.7338352215551915
Validation loss: 2.5520206342424157

Epoch: 6| Step: 10
Training loss: 2.612455639622258
Validation loss: 2.569885296201662

Epoch: 6| Step: 11
Training loss: 2.620299535911486
Validation loss: 2.537091204892145

Epoch: 6| Step: 12
Training loss: 2.788155630012283
Validation loss: 2.526136179404311

Epoch: 6| Step: 13
Training loss: 2.267952926638362
Validation loss: 2.4793386326462103

Epoch: 296| Step: 0
Training loss: 2.224957232117826
Validation loss: 2.4526712998553917

Epoch: 6| Step: 1
Training loss: 2.9288617000208665
Validation loss: 2.444737828905725

Epoch: 6| Step: 2
Training loss: 2.596407161211344
Validation loss: 2.419625881917248

Epoch: 6| Step: 3
Training loss: 3.09736529952572
Validation loss: 2.4154984858332105

Epoch: 6| Step: 4
Training loss: 2.8627133085907532
Validation loss: 2.4028062664828447

Epoch: 6| Step: 5
Training loss: 2.6751209196051824
Validation loss: 2.4371347271999335

Epoch: 6| Step: 6
Training loss: 2.363320392883484
Validation loss: 2.4265616252889592

Epoch: 6| Step: 7
Training loss: 2.1588369137972268
Validation loss: 2.4386556623996154

Epoch: 6| Step: 8
Training loss: 2.970833458884844
Validation loss: 2.4585874546772195

Epoch: 6| Step: 9
Training loss: 1.7268353414934672
Validation loss: 2.4652963408732647

Epoch: 6| Step: 10
Training loss: 2.9810406497409114
Validation loss: 2.484516157589044

Epoch: 6| Step: 11
Training loss: 2.477207232286369
Validation loss: 2.490239625330487

Epoch: 6| Step: 12
Training loss: 2.165642117078987
Validation loss: 2.4990968580313493

Epoch: 6| Step: 13
Training loss: 2.8302060052953157
Validation loss: 2.4971690762049734

Epoch: 297| Step: 0
Training loss: 2.46145798764823
Validation loss: 2.499065917876467

Epoch: 6| Step: 1
Training loss: 3.085101127759973
Validation loss: 2.502448028835815

Epoch: 6| Step: 2
Training loss: 2.0439499783451285
Validation loss: 2.478707877484289

Epoch: 6| Step: 3
Training loss: 2.285532863263002
Validation loss: 2.45472768078347

Epoch: 6| Step: 4
Training loss: 3.208230466968826
Validation loss: 2.4739636382395283

Epoch: 6| Step: 5
Training loss: 2.5744240755616192
Validation loss: 2.498210379234113

Epoch: 6| Step: 6
Training loss: 2.6015630498662143
Validation loss: 2.5072448402857956

Epoch: 6| Step: 7
Training loss: 2.6973031032425183
Validation loss: 2.5273511923606398

Epoch: 6| Step: 8
Training loss: 2.9167618508929074
Validation loss: 2.5344567166061673

Epoch: 6| Step: 9
Training loss: 2.276492029904616
Validation loss: 2.5633978762565155

Epoch: 6| Step: 10
Training loss: 2.017157275315476
Validation loss: 2.5280317627941673

Epoch: 6| Step: 11
Training loss: 2.5078813299793095
Validation loss: 2.511840944924095

Epoch: 6| Step: 12
Training loss: 3.047545999832283
Validation loss: 2.487912546272242

Epoch: 6| Step: 13
Training loss: 2.3829441722072393
Validation loss: 2.4512373239574403

Epoch: 298| Step: 0
Training loss: 2.6622383383105848
Validation loss: 2.423736233916297

Epoch: 6| Step: 1
Training loss: 2.5994089738625616
Validation loss: 2.406882742642296

Epoch: 6| Step: 2
Training loss: 2.708080006024704
Validation loss: 2.389804749502692

Epoch: 6| Step: 3
Training loss: 2.5320819382388806
Validation loss: 2.4085621756550446

Epoch: 6| Step: 4
Training loss: 2.5140959078961846
Validation loss: 2.3933614958280365

Epoch: 6| Step: 5
Training loss: 2.5258203363624325
Validation loss: 2.4152068445027925

Epoch: 6| Step: 6
Training loss: 2.3778544889932176
Validation loss: 2.3988912803204254

Epoch: 6| Step: 7
Training loss: 2.5355559094282314
Validation loss: 2.4188446393981304

Epoch: 6| Step: 8
Training loss: 2.347026112005269
Validation loss: 2.4492665437109284

Epoch: 6| Step: 9
Training loss: 2.3563122607031914
Validation loss: 2.473574309840615

Epoch: 6| Step: 10
Training loss: 3.1909487150034592
Validation loss: 2.4826752114406268

Epoch: 6| Step: 11
Training loss: 2.4229831252382277
Validation loss: 2.525293049294811

Epoch: 6| Step: 12
Training loss: 2.9127333322470004
Validation loss: 2.5143259605546096

Epoch: 6| Step: 13
Training loss: 2.940527958337939
Validation loss: 2.5225153108207325

Epoch: 299| Step: 0
Training loss: 1.647034830231173
Validation loss: 2.5071000091526545

Epoch: 6| Step: 1
Training loss: 3.1243544865526385
Validation loss: 2.500273735688095

Epoch: 6| Step: 2
Training loss: 2.4389401607390893
Validation loss: 2.479603197879919

Epoch: 6| Step: 3
Training loss: 2.6642843472913014
Validation loss: 2.5058708393668883

Epoch: 6| Step: 4
Training loss: 2.5220875628015924
Validation loss: 2.4886438614853605

Epoch: 6| Step: 5
Training loss: 2.734442748184157
Validation loss: 2.455458967241388

Epoch: 6| Step: 6
Training loss: 3.0823007521388535
Validation loss: 2.4445362611796733

Epoch: 6| Step: 7
Training loss: 2.892550430319817
Validation loss: 2.45315183676185

Epoch: 6| Step: 8
Training loss: 2.62238263023005
Validation loss: 2.4469177958991937

Epoch: 6| Step: 9
Training loss: 2.3101058113337807
Validation loss: 2.489880619293295

Epoch: 6| Step: 10
Training loss: 2.32111547685262
Validation loss: 2.5041127471936515

Epoch: 6| Step: 11
Training loss: 2.444234104450889
Validation loss: 2.5053482949497687

Epoch: 6| Step: 12
Training loss: 2.7370235150365065
Validation loss: 2.4648522953022933

Epoch: 6| Step: 13
Training loss: 2.363057376566957
Validation loss: 2.450012759739872

Epoch: 300| Step: 0
Training loss: 1.9108353794162918
Validation loss: 2.4347117052293594

Epoch: 6| Step: 1
Training loss: 2.3469596756086597
Validation loss: 2.417446935190721

Epoch: 6| Step: 2
Training loss: 2.733606372159788
Validation loss: 2.4433672420975445

Epoch: 6| Step: 3
Training loss: 2.773611659639606
Validation loss: 2.424558116392735

Epoch: 6| Step: 4
Training loss: 2.8154859163436416
Validation loss: 2.4385494794726252

Epoch: 6| Step: 5
Training loss: 2.769031388082489
Validation loss: 2.428336300191409

Epoch: 6| Step: 6
Training loss: 2.3304689627943667
Validation loss: 2.440622809866051

Epoch: 6| Step: 7
Training loss: 2.6480752252686557
Validation loss: 2.462128366224303

Epoch: 6| Step: 8
Training loss: 2.854425367525305
Validation loss: 2.437594017274956

Epoch: 6| Step: 9
Training loss: 2.3722990639495514
Validation loss: 2.450666660076364

Epoch: 6| Step: 10
Training loss: 2.692624285706387
Validation loss: 2.466139721216659

Epoch: 6| Step: 11
Training loss: 2.701662847840585
Validation loss: 2.5075678455106414

Epoch: 6| Step: 12
Training loss: 2.522194949136604
Validation loss: 2.5053195599082168

Epoch: 6| Step: 13
Training loss: 2.809716012390217
Validation loss: 2.5516587142508023

Epoch: 301| Step: 0
Training loss: 2.406337686897874
Validation loss: 2.5402590422555003

Epoch: 6| Step: 1
Training loss: 2.7813242355897674
Validation loss: 2.5198209684555923

Epoch: 6| Step: 2
Training loss: 2.7137876803023824
Validation loss: 2.4823126234717936

Epoch: 6| Step: 3
Training loss: 2.9028484167562145
Validation loss: 2.4803316648993667

Epoch: 6| Step: 4
Training loss: 2.823128010813873
Validation loss: 2.428692453586866

Epoch: 6| Step: 5
Training loss: 2.377628879202816
Validation loss: 2.40738245622273

Epoch: 6| Step: 6
Training loss: 2.6651886380478578
Validation loss: 2.4300809457985695

Epoch: 6| Step: 7
Training loss: 2.3842718939530436
Validation loss: 2.4054161281490627

Epoch: 6| Step: 8
Training loss: 2.488235161802129
Validation loss: 2.405120954424479

Epoch: 6| Step: 9
Training loss: 2.1961812645496805
Validation loss: 2.3953750965744467

Epoch: 6| Step: 10
Training loss: 2.4812191286256464
Validation loss: 2.415058495883507

Epoch: 6| Step: 11
Training loss: 3.0381179557739033
Validation loss: 2.4461375945242803

Epoch: 6| Step: 12
Training loss: 2.5103162584498677
Validation loss: 2.493865341310017

Epoch: 6| Step: 13
Training loss: 2.588628285197738
Validation loss: 2.5682225861297256

Epoch: 302| Step: 0
Training loss: 2.985625319677523
Validation loss: 2.6828824434562195

Epoch: 6| Step: 1
Training loss: 2.6274872757942043
Validation loss: 2.6795986962890757

Epoch: 6| Step: 2
Training loss: 2.6062325383248597
Validation loss: 2.681972960619361

Epoch: 6| Step: 3
Training loss: 2.4644984080455963
Validation loss: 2.701367168671523

Epoch: 6| Step: 4
Training loss: 2.219452652685938
Validation loss: 2.678153865435275

Epoch: 6| Step: 5
Training loss: 2.702334867332133
Validation loss: 2.5644547054986084

Epoch: 6| Step: 6
Training loss: 2.5030496116839207
Validation loss: 2.5553744851473956

Epoch: 6| Step: 7
Training loss: 2.1091968602441242
Validation loss: 2.45436752994337

Epoch: 6| Step: 8
Training loss: 1.9649041168464858
Validation loss: 2.436570085079017

Epoch: 6| Step: 9
Training loss: 2.535640253026311
Validation loss: 2.4272741582233612

Epoch: 6| Step: 10
Training loss: 3.0624806928999186
Validation loss: 2.4112709504338192

Epoch: 6| Step: 11
Training loss: 3.0471186613808863
Validation loss: 2.4197110705476335

Epoch: 6| Step: 12
Training loss: 3.127571878682126
Validation loss: 2.4148275738236027

Epoch: 6| Step: 13
Training loss: 1.9768916523196172
Validation loss: 2.4143410023670295

Epoch: 303| Step: 0
Training loss: 2.549790661764852
Validation loss: 2.409538421338558

Epoch: 6| Step: 1
Training loss: 2.8572718489002873
Validation loss: 2.411160729070381

Epoch: 6| Step: 2
Training loss: 2.6325324840660724
Validation loss: 2.39969507364562

Epoch: 6| Step: 3
Training loss: 2.600066616965552
Validation loss: 2.3884903397730373

Epoch: 6| Step: 4
Training loss: 3.0500926707213
Validation loss: 2.4003431130472306

Epoch: 6| Step: 5
Training loss: 2.2951674569398
Validation loss: 2.414488640148816

Epoch: 6| Step: 6
Training loss: 2.6326051171917078
Validation loss: 2.455495303831767

Epoch: 6| Step: 7
Training loss: 2.597137078052921
Validation loss: 2.505243534760705

Epoch: 6| Step: 8
Training loss: 2.7160215169534645
Validation loss: 2.493577244925696

Epoch: 6| Step: 9
Training loss: 2.542432971772233
Validation loss: 2.5187640163551035

Epoch: 6| Step: 10
Training loss: 2.3705599590926445
Validation loss: 2.5295062077758645

Epoch: 6| Step: 11
Training loss: 2.310783986737362
Validation loss: 2.507309105200671

Epoch: 6| Step: 12
Training loss: 2.486103152564847
Validation loss: 2.51753210674871

Epoch: 6| Step: 13
Training loss: 2.636216224537249
Validation loss: 2.5051378072156503

Epoch: 304| Step: 0
Training loss: 2.5626078327099444
Validation loss: 2.490396386863647

Epoch: 6| Step: 1
Training loss: 2.276280254600771
Validation loss: 2.4839194183128224

Epoch: 6| Step: 2
Training loss: 2.9404744449225664
Validation loss: 2.500906980741515

Epoch: 6| Step: 3
Training loss: 2.7259867150367114
Validation loss: 2.495514757299679

Epoch: 6| Step: 4
Training loss: 2.2105225082594124
Validation loss: 2.466513675239883

Epoch: 6| Step: 5
Training loss: 2.198203033545963
Validation loss: 2.4498851087032496

Epoch: 6| Step: 6
Training loss: 2.866027431039981
Validation loss: 2.469371777064313

Epoch: 6| Step: 7
Training loss: 2.954853177884892
Validation loss: 2.485435934689791

Epoch: 6| Step: 8
Training loss: 2.434266709158205
Validation loss: 2.4658905027754265

Epoch: 6| Step: 9
Training loss: 2.516136449155296
Validation loss: 2.4962961118497415

Epoch: 6| Step: 10
Training loss: 2.630282581653649
Validation loss: 2.475090150505737

Epoch: 6| Step: 11
Training loss: 2.376959945681463
Validation loss: 2.480188998801856

Epoch: 6| Step: 12
Training loss: 2.876340802221194
Validation loss: 2.4533278339156266

Epoch: 6| Step: 13
Training loss: 2.4448416259584764
Validation loss: 2.4411284231620423

Epoch: 305| Step: 0
Training loss: 2.697753950438348
Validation loss: 2.436631573083367

Epoch: 6| Step: 1
Training loss: 2.5666563240272247
Validation loss: 2.447376877845753

Epoch: 6| Step: 2
Training loss: 2.4687802276692263
Validation loss: 2.4308404781462905

Epoch: 6| Step: 3
Training loss: 2.5265004373924107
Validation loss: 2.4289938628322676

Epoch: 6| Step: 4
Training loss: 1.7606444202092775
Validation loss: 2.4225299443168806

Epoch: 6| Step: 5
Training loss: 2.7947463134391883
Validation loss: 2.4681935730177553

Epoch: 6| Step: 6
Training loss: 2.9483309792753074
Validation loss: 2.4711573058032617

Epoch: 6| Step: 7
Training loss: 2.455705585278867
Validation loss: 2.4925089697675866

Epoch: 6| Step: 8
Training loss: 2.562439801509226
Validation loss: 2.4937082190566295

Epoch: 6| Step: 9
Training loss: 3.1614850130584156
Validation loss: 2.530395904044531

Epoch: 6| Step: 10
Training loss: 2.271612529468727
Validation loss: 2.5013034355473076

Epoch: 6| Step: 11
Training loss: 2.947029564405319
Validation loss: 2.473881384662668

Epoch: 6| Step: 12
Training loss: 2.5932600179015557
Validation loss: 2.4395664743469148

Epoch: 6| Step: 13
Training loss: 1.6963409257777475
Validation loss: 2.4439749958725656

Epoch: 306| Step: 0
Training loss: 2.7872988470055216
Validation loss: 2.446887389303219

Epoch: 6| Step: 1
Training loss: 3.1782668780650827
Validation loss: 2.4283891130130204

Epoch: 6| Step: 2
Training loss: 2.801328725257556
Validation loss: 2.4273348308337725

Epoch: 6| Step: 3
Training loss: 2.2603023752127895
Validation loss: 2.44536593584327

Epoch: 6| Step: 4
Training loss: 2.4032684283369923
Validation loss: 2.429516410679674

Epoch: 6| Step: 5
Training loss: 2.7614861677722313
Validation loss: 2.4440581311120084

Epoch: 6| Step: 6
Training loss: 2.5062769291446516
Validation loss: 2.436947757120089

Epoch: 6| Step: 7
Training loss: 2.5555084495994373
Validation loss: 2.447218765407136

Epoch: 6| Step: 8
Training loss: 2.0923814998420696
Validation loss: 2.4457388995602853

Epoch: 6| Step: 9
Training loss: 2.0848971283414923
Validation loss: 2.4770088511714006

Epoch: 6| Step: 10
Training loss: 2.6711251617664376
Validation loss: 2.497666011877971

Epoch: 6| Step: 11
Training loss: 1.9322026344482732
Validation loss: 2.4946113285070224

Epoch: 6| Step: 12
Training loss: 2.9522770062766046
Validation loss: 2.518344083013976

Epoch: 6| Step: 13
Training loss: 2.8544808282146543
Validation loss: 2.5423302035645516

Epoch: 307| Step: 0
Training loss: 2.644097567317743
Validation loss: 2.4585359850310655

Epoch: 6| Step: 1
Training loss: 2.8165232386741814
Validation loss: 2.4129272386973626

Epoch: 6| Step: 2
Training loss: 2.5097629651007307
Validation loss: 2.3953587426244902

Epoch: 6| Step: 3
Training loss: 2.8890934366371948
Validation loss: 2.3895987851550324

Epoch: 6| Step: 4
Training loss: 2.9463565503850804
Validation loss: 2.388751135299038

Epoch: 6| Step: 5
Training loss: 2.7776278794427656
Validation loss: 2.3776141472440884

Epoch: 6| Step: 6
Training loss: 2.742077078049655
Validation loss: 2.397491297295618

Epoch: 6| Step: 7
Training loss: 2.3178918201523553
Validation loss: 2.399672248894566

Epoch: 6| Step: 8
Training loss: 2.171593078318941
Validation loss: 2.4045486167124626

Epoch: 6| Step: 9
Training loss: 2.4512911216636373
Validation loss: 2.404322114119922

Epoch: 6| Step: 10
Training loss: 2.4504492678649528
Validation loss: 2.430348883210288

Epoch: 6| Step: 11
Training loss: 2.7729827937938083
Validation loss: 2.4657809305066687

Epoch: 6| Step: 12
Training loss: 2.0254789092228394
Validation loss: 2.5178842205332868

Epoch: 6| Step: 13
Training loss: 3.2250365558297145
Validation loss: 2.5741455798709794

Epoch: 308| Step: 0
Training loss: 2.5276196666729365
Validation loss: 2.6024146107998325

Epoch: 6| Step: 1
Training loss: 2.7732310043615636
Validation loss: 2.6283771171509547

Epoch: 6| Step: 2
Training loss: 2.492147415460603
Validation loss: 2.594187880795686

Epoch: 6| Step: 3
Training loss: 2.224965161683015
Validation loss: 2.5361506922874835

Epoch: 6| Step: 4
Training loss: 2.7670286248218496
Validation loss: 2.5078445456546015

Epoch: 6| Step: 5
Training loss: 2.753985378129604
Validation loss: 2.488720736227385

Epoch: 6| Step: 6
Training loss: 2.619104759204003
Validation loss: 2.4362631921171043

Epoch: 6| Step: 7
Training loss: 2.1786644288164005
Validation loss: 2.4485666166652442

Epoch: 6| Step: 8
Training loss: 3.1402675747910687
Validation loss: 2.4199302780655803

Epoch: 6| Step: 9
Training loss: 2.284702145051202
Validation loss: 2.428048668366068

Epoch: 6| Step: 10
Training loss: 2.9629727014628835
Validation loss: 2.4549790954835973

Epoch: 6| Step: 11
Training loss: 1.790622480833402
Validation loss: 2.438216597083768

Epoch: 6| Step: 12
Training loss: 2.4261663994199902
Validation loss: 2.4531629705877065

Epoch: 6| Step: 13
Training loss: 2.625835558197167
Validation loss: 2.4327063298697937

Epoch: 309| Step: 0
Training loss: 2.6001493264378857
Validation loss: 2.4428626232001958

Epoch: 6| Step: 1
Training loss: 2.546534416033574
Validation loss: 2.439039598665035

Epoch: 6| Step: 2
Training loss: 1.858290861126236
Validation loss: 2.4134267751875895

Epoch: 6| Step: 3
Training loss: 2.938812287391364
Validation loss: 2.427126186463807

Epoch: 6| Step: 4
Training loss: 2.3671093414799165
Validation loss: 2.429995279345106

Epoch: 6| Step: 5
Training loss: 2.5994663901382244
Validation loss: 2.444390117304761

Epoch: 6| Step: 6
Training loss: 2.209310951005961
Validation loss: 2.4915122105666816

Epoch: 6| Step: 7
Training loss: 2.3969993628674913
Validation loss: 2.509727691546308

Epoch: 6| Step: 8
Training loss: 2.5432676265656577
Validation loss: 2.5799288010826875

Epoch: 6| Step: 9
Training loss: 2.716247371386166
Validation loss: 2.539669783218094

Epoch: 6| Step: 10
Training loss: 3.5869611222409787
Validation loss: 2.5033012620275112

Epoch: 6| Step: 11
Training loss: 2.291089303083175
Validation loss: 2.465469540152319

Epoch: 6| Step: 12
Training loss: 2.1409657896213807
Validation loss: 2.4425079891849912

Epoch: 6| Step: 13
Training loss: 2.5938477095618335
Validation loss: 2.4267298936511983

Epoch: 310| Step: 0
Training loss: 2.6259387018177605
Validation loss: 2.4098526346633093

Epoch: 6| Step: 1
Training loss: 2.5649565110414514
Validation loss: 2.4023062226100333

Epoch: 6| Step: 2
Training loss: 2.168180768067455
Validation loss: 2.4228153717333436

Epoch: 6| Step: 3
Training loss: 2.4944956264706013
Validation loss: 2.428962098308594

Epoch: 6| Step: 4
Training loss: 2.5666100640268987
Validation loss: 2.427686806827542

Epoch: 6| Step: 5
Training loss: 2.8361700293680983
Validation loss: 2.4303055144658168

Epoch: 6| Step: 6
Training loss: 2.494583556561396
Validation loss: 2.476456947570753

Epoch: 6| Step: 7
Training loss: 2.922005553567297
Validation loss: 2.4797934596984454

Epoch: 6| Step: 8
Training loss: 3.561470552244794
Validation loss: 2.50292244395141

Epoch: 6| Step: 9
Training loss: 2.230778714369794
Validation loss: 2.493757962503468

Epoch: 6| Step: 10
Training loss: 2.3614349467282376
Validation loss: 2.4669411303115836

Epoch: 6| Step: 11
Training loss: 2.017382188498306
Validation loss: 2.4764239450151773

Epoch: 6| Step: 12
Training loss: 1.8236520936765193
Validation loss: 2.516284286310831

Epoch: 6| Step: 13
Training loss: 3.0444595543825974
Validation loss: 2.5009757701317086

Epoch: 311| Step: 0
Training loss: 2.352108508623769
Validation loss: 2.5262674469049107

Epoch: 6| Step: 1
Training loss: 2.5657915514321092
Validation loss: 2.5449532388151828

Epoch: 6| Step: 2
Training loss: 2.6334591759015624
Validation loss: 2.553326050834109

Epoch: 6| Step: 3
Training loss: 2.980638491695407
Validation loss: 2.533035373841031

Epoch: 6| Step: 4
Training loss: 2.0282426138750083
Validation loss: 2.4669468677178457

Epoch: 6| Step: 5
Training loss: 2.3121451028215043
Validation loss: 2.4064798595567902

Epoch: 6| Step: 6
Training loss: 3.0068605179756087
Validation loss: 2.3919563422738337

Epoch: 6| Step: 7
Training loss: 2.821015246642519
Validation loss: 2.3858530931664315

Epoch: 6| Step: 8
Training loss: 2.9682361358830294
Validation loss: 2.387197960469174

Epoch: 6| Step: 9
Training loss: 2.75725768130439
Validation loss: 2.400248024372005

Epoch: 6| Step: 10
Training loss: 2.2579687783825513
Validation loss: 2.3848762363936835

Epoch: 6| Step: 11
Training loss: 2.4623396496920478
Validation loss: 2.4038129562281654

Epoch: 6| Step: 12
Training loss: 2.3363736871314935
Validation loss: 2.425344095300439

Epoch: 6| Step: 13
Training loss: 2.785063882502583
Validation loss: 2.411741114465392

Epoch: 312| Step: 0
Training loss: 2.5198056566896883
Validation loss: 2.466123755973496

Epoch: 6| Step: 1
Training loss: 2.651281399682564
Validation loss: 2.547840185404956

Epoch: 6| Step: 2
Training loss: 2.474835584940008
Validation loss: 2.608431212580586

Epoch: 6| Step: 3
Training loss: 2.568814568740651
Validation loss: 2.6650865603987794

Epoch: 6| Step: 4
Training loss: 2.6642892690669187
Validation loss: 2.571963190656401

Epoch: 6| Step: 5
Training loss: 2.3465042207404787
Validation loss: 2.4887051929429247

Epoch: 6| Step: 6
Training loss: 2.7612501985231246
Validation loss: 2.457401243538145

Epoch: 6| Step: 7
Training loss: 2.6901578845519714
Validation loss: 2.419039009152786

Epoch: 6| Step: 8
Training loss: 2.5826716242112275
Validation loss: 2.411304064341219

Epoch: 6| Step: 9
Training loss: 2.4030909423002145
Validation loss: 2.4026222022942285

Epoch: 6| Step: 10
Training loss: 2.6655392846550865
Validation loss: 2.412974495429103

Epoch: 6| Step: 11
Training loss: 2.94461431753021
Validation loss: 2.405706253910423

Epoch: 6| Step: 12
Training loss: 2.653980317652951
Validation loss: 2.429131502190957

Epoch: 6| Step: 13
Training loss: 2.9171429018229054
Validation loss: 2.4432929600746816

Epoch: 313| Step: 0
Training loss: 2.6244439035569957
Validation loss: 2.4489601949854274

Epoch: 6| Step: 1
Training loss: 2.231609847599229
Validation loss: 2.4230474274575093

Epoch: 6| Step: 2
Training loss: 2.582362351418925
Validation loss: 2.469039530330933

Epoch: 6| Step: 3
Training loss: 2.032454148417002
Validation loss: 2.469685745938379

Epoch: 6| Step: 4
Training loss: 2.653397318565329
Validation loss: 2.470306769621866

Epoch: 6| Step: 5
Training loss: 2.573732182504528
Validation loss: 2.4709162312027853

Epoch: 6| Step: 6
Training loss: 2.697578516993839
Validation loss: 2.5000958608891493

Epoch: 6| Step: 7
Training loss: 2.532510890805475
Validation loss: 2.5220004544150973

Epoch: 6| Step: 8
Training loss: 3.1134396157376694
Validation loss: 2.5046420377122383

Epoch: 6| Step: 9
Training loss: 2.5608079487661444
Validation loss: 2.5015031684497187

Epoch: 6| Step: 10
Training loss: 2.0495691404906573
Validation loss: 2.4930184133485653

Epoch: 6| Step: 11
Training loss: 2.822318676512628
Validation loss: 2.4878160345697324

Epoch: 6| Step: 12
Training loss: 2.29855772905959
Validation loss: 2.4550116543031337

Epoch: 6| Step: 13
Training loss: 2.8881594478729684
Validation loss: 2.4560278699315097

Epoch: 314| Step: 0
Training loss: 2.804852239079422
Validation loss: 2.4218077831222633

Epoch: 6| Step: 1
Training loss: 2.824340986505815
Validation loss: 2.4204417231996125

Epoch: 6| Step: 2
Training loss: 2.3502271542436466
Validation loss: 2.4313298147637386

Epoch: 6| Step: 3
Training loss: 2.7608608440299296
Validation loss: 2.427259550669295

Epoch: 6| Step: 4
Training loss: 2.2014729683988445
Validation loss: 2.419721085811468

Epoch: 6| Step: 5
Training loss: 2.28717525657674
Validation loss: 2.4497573505522303

Epoch: 6| Step: 6
Training loss: 2.4953969541051237
Validation loss: 2.489547653721745

Epoch: 6| Step: 7
Training loss: 2.646336445069933
Validation loss: 2.515645706233194

Epoch: 6| Step: 8
Training loss: 2.38749240254896
Validation loss: 2.545503486739924

Epoch: 6| Step: 9
Training loss: 1.937511444057999
Validation loss: 2.5718390057999954

Epoch: 6| Step: 10
Training loss: 3.2957284389028723
Validation loss: 2.608398660604872

Epoch: 6| Step: 11
Training loss: 1.9065909159002257
Validation loss: 2.51916407314881

Epoch: 6| Step: 12
Training loss: 2.688664383706693
Validation loss: 2.500607061514222

Epoch: 6| Step: 13
Training loss: 3.0943145236903433
Validation loss: 2.4488663282875645

Epoch: 315| Step: 0
Training loss: 2.720135478264104
Validation loss: 2.4122751300653413

Epoch: 6| Step: 1
Training loss: 2.6850454077264194
Validation loss: 2.397377647117821

Epoch: 6| Step: 2
Training loss: 2.4167122233689833
Validation loss: 2.4061869482636595

Epoch: 6| Step: 3
Training loss: 2.1700330649111357
Validation loss: 2.4122762331975416

Epoch: 6| Step: 4
Training loss: 2.6592896067876013
Validation loss: 2.39606811065059

Epoch: 6| Step: 5
Training loss: 1.9420363326715548
Validation loss: 2.3967899378061506

Epoch: 6| Step: 6
Training loss: 2.494886700460028
Validation loss: 2.398657975119627

Epoch: 6| Step: 7
Training loss: 2.8275092703400007
Validation loss: 2.405574610576091

Epoch: 6| Step: 8
Training loss: 2.5187385199121906
Validation loss: 2.3997764429445563

Epoch: 6| Step: 9
Training loss: 2.385507928915445
Validation loss: 2.4313554928968877

Epoch: 6| Step: 10
Training loss: 2.692419296089409
Validation loss: 2.4261333816418023

Epoch: 6| Step: 11
Training loss: 2.525780124823346
Validation loss: 2.4780787877153547

Epoch: 6| Step: 12
Training loss: 3.2165595443624544
Validation loss: 2.4792735062208053

Epoch: 6| Step: 13
Training loss: 2.3167318851795553
Validation loss: 2.4893798092761275

Epoch: 316| Step: 0
Training loss: 2.467814594222986
Validation loss: 2.4968505813004414

Epoch: 6| Step: 1
Training loss: 2.958896386377425
Validation loss: 2.5211538688846424

Epoch: 6| Step: 2
Training loss: 2.11022830234233
Validation loss: 2.5293614502679964

Epoch: 6| Step: 3
Training loss: 2.0596015678193833
Validation loss: 2.5741319048700997

Epoch: 6| Step: 4
Training loss: 2.6171853136651317
Validation loss: 2.5419783022092255

Epoch: 6| Step: 5
Training loss: 2.54949713217796
Validation loss: 2.5473020120002707

Epoch: 6| Step: 6
Training loss: 2.905259322444703
Validation loss: 2.554421841462376

Epoch: 6| Step: 7
Training loss: 3.006759181689209
Validation loss: 2.5877104797010673

Epoch: 6| Step: 8
Training loss: 2.4616155749860034
Validation loss: 2.5482580306525735

Epoch: 6| Step: 9
Training loss: 2.520391462286949
Validation loss: 2.4945929855333446

Epoch: 6| Step: 10
Training loss: 2.597756657775154
Validation loss: 2.452750084399913

Epoch: 6| Step: 11
Training loss: 2.661294881102684
Validation loss: 2.4119985010847875

Epoch: 6| Step: 12
Training loss: 2.405105120290678
Validation loss: 2.4136204596085866

Epoch: 6| Step: 13
Training loss: 1.6038966591571961
Validation loss: 2.4148728166602718

Epoch: 317| Step: 0
Training loss: 2.1313332818279593
Validation loss: 2.3951729929595893

Epoch: 6| Step: 1
Training loss: 2.5829721834144803
Validation loss: 2.4080903700103673

Epoch: 6| Step: 2
Training loss: 2.560056032670257
Validation loss: 2.3910164321929224

Epoch: 6| Step: 3
Training loss: 2.3661574335224658
Validation loss: 2.435988761001883

Epoch: 6| Step: 4
Training loss: 2.2492237871437606
Validation loss: 2.4764706029223724

Epoch: 6| Step: 5
Training loss: 2.429818005752007
Validation loss: 2.5224071875524143

Epoch: 6| Step: 6
Training loss: 2.5734625995201776
Validation loss: 2.610894036926201

Epoch: 6| Step: 7
Training loss: 2.6685901102594807
Validation loss: 2.5937779960401395

Epoch: 6| Step: 8
Training loss: 2.461081945630647
Validation loss: 2.5823735282724045

Epoch: 6| Step: 9
Training loss: 2.7033333229538448
Validation loss: 2.5734784756455156

Epoch: 6| Step: 10
Training loss: 3.10577675113735
Validation loss: 2.5087175943740854

Epoch: 6| Step: 11
Training loss: 2.4945359600057317
Validation loss: 2.4296892409669075

Epoch: 6| Step: 12
Training loss: 3.016588442580323
Validation loss: 2.4125474853194957

Epoch: 6| Step: 13
Training loss: 2.393304955766734
Validation loss: 2.390492977641852

Epoch: 318| Step: 0
Training loss: 2.7421522002379843
Validation loss: 2.3930097076270673

Epoch: 6| Step: 1
Training loss: 2.5237970716027016
Validation loss: 2.389288896536026

Epoch: 6| Step: 2
Training loss: 2.7643274399152427
Validation loss: 2.3714467817858735

Epoch: 6| Step: 3
Training loss: 2.9016687524719744
Validation loss: 2.377222938993237

Epoch: 6| Step: 4
Training loss: 2.979086939316205
Validation loss: 2.3934240499624053

Epoch: 6| Step: 5
Training loss: 2.024735906828622
Validation loss: 2.380771824360136

Epoch: 6| Step: 6
Training loss: 2.392955167995246
Validation loss: 2.375600055738087

Epoch: 6| Step: 7
Training loss: 2.747946579437523
Validation loss: 2.397952239482047

Epoch: 6| Step: 8
Training loss: 1.7091634950774233
Validation loss: 2.402764886078622

Epoch: 6| Step: 9
Training loss: 2.127573138368325
Validation loss: 2.4282532337484115

Epoch: 6| Step: 10
Training loss: 2.648518248820868
Validation loss: 2.4362511876323185

Epoch: 6| Step: 11
Training loss: 2.7664578148324543
Validation loss: 2.486141347488342

Epoch: 6| Step: 12
Training loss: 3.261205283312037
Validation loss: 2.522898844184179

Epoch: 6| Step: 13
Training loss: 1.2803622170632964
Validation loss: 2.550278522997083

Epoch: 319| Step: 0
Training loss: 2.9821163238310913
Validation loss: 2.581568086723918

Epoch: 6| Step: 1
Training loss: 2.2102354842512835
Validation loss: 2.5700972092534076

Epoch: 6| Step: 2
Training loss: 2.754848367772525
Validation loss: 2.5139848104275466

Epoch: 6| Step: 3
Training loss: 2.7900491459937666
Validation loss: 2.5040472740677027

Epoch: 6| Step: 4
Training loss: 2.606101352468545
Validation loss: 2.431907390694047

Epoch: 6| Step: 5
Training loss: 2.9860095595802747
Validation loss: 2.403502738219199

Epoch: 6| Step: 6
Training loss: 2.589236733485378
Validation loss: 2.3914809635929806

Epoch: 6| Step: 7
Training loss: 2.4793244853930734
Validation loss: 2.389860234758185

Epoch: 6| Step: 8
Training loss: 2.5352359988419657
Validation loss: 2.3922417326814607

Epoch: 6| Step: 9
Training loss: 2.254619518584895
Validation loss: 2.387839998358046

Epoch: 6| Step: 10
Training loss: 2.3724096125437404
Validation loss: 2.3951478645421034

Epoch: 6| Step: 11
Training loss: 2.631526281934073
Validation loss: 2.4066990685153007

Epoch: 6| Step: 12
Training loss: 2.384289793239436
Validation loss: 2.4161510041137046

Epoch: 6| Step: 13
Training loss: 2.190355018162768
Validation loss: 2.4426670845429204

Epoch: 320| Step: 0
Training loss: 2.8748659849030083
Validation loss: 2.4603199559159963

Epoch: 6| Step: 1
Training loss: 2.217685497829924
Validation loss: 2.507408715017449

Epoch: 6| Step: 2
Training loss: 2.812709207171343
Validation loss: 2.4951484232076915

Epoch: 6| Step: 3
Training loss: 2.4582760906559344
Validation loss: 2.4709554322677048

Epoch: 6| Step: 4
Training loss: 2.0309286010002516
Validation loss: 2.463755531049477

Epoch: 6| Step: 5
Training loss: 2.5878336889373554
Validation loss: 2.4695995110653435

Epoch: 6| Step: 6
Training loss: 2.0928413355177824
Validation loss: 2.4939989400208242

Epoch: 6| Step: 7
Training loss: 1.940182766612965
Validation loss: 2.469951073189074

Epoch: 6| Step: 8
Training loss: 2.9956966370728577
Validation loss: 2.475586475995944

Epoch: 6| Step: 9
Training loss: 2.1636150462147343
Validation loss: 2.4410436716230683

Epoch: 6| Step: 10
Training loss: 2.394632408905237
Validation loss: 2.442034775025828

Epoch: 6| Step: 11
Training loss: 2.9611800202667107
Validation loss: 2.423116680440983

Epoch: 6| Step: 12
Training loss: 2.813829743430154
Validation loss: 2.452815114457243

Epoch: 6| Step: 13
Training loss: 2.496650836607486
Validation loss: 2.4598486769600134

Epoch: 321| Step: 0
Training loss: 2.404027928448777
Validation loss: 2.4687959171675655

Epoch: 6| Step: 1
Training loss: 1.7476988376685814
Validation loss: 2.500233590072755

Epoch: 6| Step: 2
Training loss: 2.5306327915048152
Validation loss: 2.521130290007617

Epoch: 6| Step: 3
Training loss: 2.4344441748059418
Validation loss: 2.4727065506934314

Epoch: 6| Step: 4
Training loss: 2.9703475669143375
Validation loss: 2.506133326896539

Epoch: 6| Step: 5
Training loss: 2.2274097637561594
Validation loss: 2.4731912277019985

Epoch: 6| Step: 6
Training loss: 2.5412244776895054
Validation loss: 2.460880172746716

Epoch: 6| Step: 7
Training loss: 2.6607395602495196
Validation loss: 2.4551437094670416

Epoch: 6| Step: 8
Training loss: 2.6420123727466875
Validation loss: 2.435564689026037

Epoch: 6| Step: 9
Training loss: 2.0641394370537536
Validation loss: 2.419652681783055

Epoch: 6| Step: 10
Training loss: 2.912517557377756
Validation loss: 2.420442400004231

Epoch: 6| Step: 11
Training loss: 2.506244109567774
Validation loss: 2.3928235018723036

Epoch: 6| Step: 12
Training loss: 2.7703779510838964
Validation loss: 2.400895867007127

Epoch: 6| Step: 13
Training loss: 2.586734798638536
Validation loss: 2.4222276624700823

Epoch: 322| Step: 0
Training loss: 1.967424218779627
Validation loss: 2.467719109325293

Epoch: 6| Step: 1
Training loss: 2.674572391736237
Validation loss: 2.501200221734

Epoch: 6| Step: 2
Training loss: 2.6401013639526383
Validation loss: 2.563027290379632

Epoch: 6| Step: 3
Training loss: 2.9766392334987133
Validation loss: 2.643486711551585

Epoch: 6| Step: 4
Training loss: 2.2057089296123435
Validation loss: 2.6615207349260155

Epoch: 6| Step: 5
Training loss: 2.901174399571407
Validation loss: 2.671009746143652

Epoch: 6| Step: 6
Training loss: 2.396811465300371
Validation loss: 2.580062785308771

Epoch: 6| Step: 7
Training loss: 2.631446551957791
Validation loss: 2.475261142523444

Epoch: 6| Step: 8
Training loss: 2.3548902114254564
Validation loss: 2.3975521055525664

Epoch: 6| Step: 9
Training loss: 2.5706426993924016
Validation loss: 2.40984466666567

Epoch: 6| Step: 10
Training loss: 2.53318288967077
Validation loss: 2.384059323336408

Epoch: 6| Step: 11
Training loss: 2.7774049561700327
Validation loss: 2.3737683192302024

Epoch: 6| Step: 12
Training loss: 2.238522714635527
Validation loss: 2.380887347196051

Epoch: 6| Step: 13
Training loss: 3.0410673692009116
Validation loss: 2.375981549558698

Epoch: 323| Step: 0
Training loss: 2.6216199093784107
Validation loss: 2.3828715676999024

Epoch: 6| Step: 1
Training loss: 2.8251669572764753
Validation loss: 2.3929481004318944

Epoch: 6| Step: 2
Training loss: 2.4855651883570684
Validation loss: 2.408812949047748

Epoch: 6| Step: 3
Training loss: 2.6242164168896855
Validation loss: 2.4181853760308663

Epoch: 6| Step: 4
Training loss: 2.2297395225609784
Validation loss: 2.4659746004933347

Epoch: 6| Step: 5
Training loss: 2.7476269279783168
Validation loss: 2.4610592256135018

Epoch: 6| Step: 6
Training loss: 2.4838259108164
Validation loss: 2.495234091558443

Epoch: 6| Step: 7
Training loss: 2.3813322879059915
Validation loss: 2.520350213071898

Epoch: 6| Step: 8
Training loss: 2.75294796117893
Validation loss: 2.5631824728099155

Epoch: 6| Step: 9
Training loss: 2.2140175221894727
Validation loss: 2.563019766568537

Epoch: 6| Step: 10
Training loss: 2.525667510228316
Validation loss: 2.559674815290388

Epoch: 6| Step: 11
Training loss: 2.6698036418819373
Validation loss: 2.533385447185776

Epoch: 6| Step: 12
Training loss: 2.9452691112934746
Validation loss: 2.518050917354765

Epoch: 6| Step: 13
Training loss: 1.5701773666008083
Validation loss: 2.4975375117399325

Epoch: 324| Step: 0
Training loss: 2.107823910692914
Validation loss: 2.495365356795345

Epoch: 6| Step: 1
Training loss: 2.5329471126416068
Validation loss: 2.441265188297119

Epoch: 6| Step: 2
Training loss: 2.3145546935123944
Validation loss: 2.460584430202757

Epoch: 6| Step: 3
Training loss: 2.255687096032497
Validation loss: 2.4314651878654274

Epoch: 6| Step: 4
Training loss: 2.629793060051739
Validation loss: 2.418008286233767

Epoch: 6| Step: 5
Training loss: 3.1745585097092452
Validation loss: 2.415627708837355

Epoch: 6| Step: 6
Training loss: 2.100190576352711
Validation loss: 2.3917824778630354

Epoch: 6| Step: 7
Training loss: 2.756295713707324
Validation loss: 2.3873285821867047

Epoch: 6| Step: 8
Training loss: 2.7147190422121796
Validation loss: 2.3719086759713

Epoch: 6| Step: 9
Training loss: 2.9284711016440066
Validation loss: 2.380700765636727

Epoch: 6| Step: 10
Training loss: 2.4974751120120553
Validation loss: 2.412638830285487

Epoch: 6| Step: 11
Training loss: 2.2509967927168475
Validation loss: 2.434490409414419

Epoch: 6| Step: 12
Training loss: 2.6339503696084607
Validation loss: 2.445462661499681

Epoch: 6| Step: 13
Training loss: 2.1354572819514677
Validation loss: 2.4667213051699672

Epoch: 325| Step: 0
Training loss: 2.4998218472900176
Validation loss: 2.4849844729492903

Epoch: 6| Step: 1
Training loss: 2.750426172699374
Validation loss: 2.4910975268372053

Epoch: 6| Step: 2
Training loss: 2.625410956048761
Validation loss: 2.489710490780508

Epoch: 6| Step: 3
Training loss: 1.9603482763162714
Validation loss: 2.4847149556042667

Epoch: 6| Step: 4
Training loss: 2.233091185618297
Validation loss: 2.492464888288532

Epoch: 6| Step: 5
Training loss: 2.7034011435166874
Validation loss: 2.4903922784822385

Epoch: 6| Step: 6
Training loss: 2.8495283840872245
Validation loss: 2.4956055750716137

Epoch: 6| Step: 7
Training loss: 2.457189994499282
Validation loss: 2.4681938056800075

Epoch: 6| Step: 8
Training loss: 2.549930822144669
Validation loss: 2.4621576225163793

Epoch: 6| Step: 9
Training loss: 3.0504739486914993
Validation loss: 2.456539426257757

Epoch: 6| Step: 10
Training loss: 2.1232709020701717
Validation loss: 2.450047311960125

Epoch: 6| Step: 11
Training loss: 2.5270131763134356
Validation loss: 2.4202975203111188

Epoch: 6| Step: 12
Training loss: 2.168856822084706
Validation loss: 2.4359894545350245

Epoch: 6| Step: 13
Training loss: 2.503400111706719
Validation loss: 2.4373614648113624

Epoch: 326| Step: 0
Training loss: 2.598766393715296
Validation loss: 2.4438590050268956

Epoch: 6| Step: 1
Training loss: 2.6091072721817063
Validation loss: 2.4432172540074113

Epoch: 6| Step: 2
Training loss: 2.6286793309034935
Validation loss: 2.44476854117042

Epoch: 6| Step: 3
Training loss: 2.5579106241558622
Validation loss: 2.4489517428798147

Epoch: 6| Step: 4
Training loss: 2.3610693298333154
Validation loss: 2.4571504689667893

Epoch: 6| Step: 5
Training loss: 2.642162890914651
Validation loss: 2.480302211605547

Epoch: 6| Step: 6
Training loss: 2.1080903839336433
Validation loss: 2.4886890623948297

Epoch: 6| Step: 7
Training loss: 2.9441896924190005
Validation loss: 2.532070462951148

Epoch: 6| Step: 8
Training loss: 2.4006510407838744
Validation loss: 2.54941824273423

Epoch: 6| Step: 9
Training loss: 2.701938170154101
Validation loss: 2.563801669692683

Epoch: 6| Step: 10
Training loss: 2.5193436900270285
Validation loss: 2.537400351822289

Epoch: 6| Step: 11
Training loss: 2.612454270688153
Validation loss: 2.482213139549404

Epoch: 6| Step: 12
Training loss: 2.2738996213031153
Validation loss: 2.4361007519432576

Epoch: 6| Step: 13
Training loss: 1.867812622642162
Validation loss: 2.4144230736683063

Epoch: 327| Step: 0
Training loss: 3.3768480680593047
Validation loss: 2.4104205850302094

Epoch: 6| Step: 1
Training loss: 2.795429559498708
Validation loss: 2.378311920053522

Epoch: 6| Step: 2
Training loss: 3.081355689288585
Validation loss: 2.371587738835101

Epoch: 6| Step: 3
Training loss: 2.000757789101883
Validation loss: 2.3850237761987687

Epoch: 6| Step: 4
Training loss: 2.5939629708605243
Validation loss: 2.3830380611888704

Epoch: 6| Step: 5
Training loss: 2.142797996068021
Validation loss: 2.3790791815066408

Epoch: 6| Step: 6
Training loss: 2.273730911250252
Validation loss: 2.3885954262225075

Epoch: 6| Step: 7
Training loss: 2.173399246285054
Validation loss: 2.4039974789787

Epoch: 6| Step: 8
Training loss: 3.000819094418515
Validation loss: 2.446489769058338

Epoch: 6| Step: 9
Training loss: 2.578175769652809
Validation loss: 2.5132060103508698

Epoch: 6| Step: 10
Training loss: 2.657718566634013
Validation loss: 2.578081018116844

Epoch: 6| Step: 11
Training loss: 2.1759771673182673
Validation loss: 2.589378021929059

Epoch: 6| Step: 12
Training loss: 1.8018111389042806
Validation loss: 2.5829841868723586

Epoch: 6| Step: 13
Training loss: 2.910653664495086
Validation loss: 2.5684368741805033

Epoch: 328| Step: 0
Training loss: 2.1047257791619196
Validation loss: 2.5025326144496574

Epoch: 6| Step: 1
Training loss: 2.7491665357404873
Validation loss: 2.468679803276294

Epoch: 6| Step: 2
Training loss: 3.0914498457920763
Validation loss: 2.4189363676235462

Epoch: 6| Step: 3
Training loss: 1.8514707518432556
Validation loss: 2.43003733648423

Epoch: 6| Step: 4
Training loss: 2.4218309952214425
Validation loss: 2.4304461247605684

Epoch: 6| Step: 5
Training loss: 2.45248414434038
Validation loss: 2.4139850170076524

Epoch: 6| Step: 6
Training loss: 2.7406530189604292
Validation loss: 2.417939709699675

Epoch: 6| Step: 7
Training loss: 2.5358314026586943
Validation loss: 2.4403502525520304

Epoch: 6| Step: 8
Training loss: 2.4044848817130706
Validation loss: 2.4278758268852756

Epoch: 6| Step: 9
Training loss: 2.3347702937712125
Validation loss: 2.4077915814426736

Epoch: 6| Step: 10
Training loss: 2.5522309137348693
Validation loss: 2.4341365282852503

Epoch: 6| Step: 11
Training loss: 2.4052857287546283
Validation loss: 2.439442047354351

Epoch: 6| Step: 12
Training loss: 2.6498249212046274
Validation loss: 2.452195591796898

Epoch: 6| Step: 13
Training loss: 2.2922819756486743
Validation loss: 2.45147430393665

Epoch: 329| Step: 0
Training loss: 2.858192240918613
Validation loss: 2.4441527551592888

Epoch: 6| Step: 1
Training loss: 2.4356700190024276
Validation loss: 2.427770401626102

Epoch: 6| Step: 2
Training loss: 2.370717655124157
Validation loss: 2.4343362643099953

Epoch: 6| Step: 3
Training loss: 2.855817071671536
Validation loss: 2.458102950835985

Epoch: 6| Step: 4
Training loss: 1.8596673302893996
Validation loss: 2.4760449545024295

Epoch: 6| Step: 5
Training loss: 2.7459154138949935
Validation loss: 2.4803704592817764

Epoch: 6| Step: 6
Training loss: 2.921962308344219
Validation loss: 2.533520359827576

Epoch: 6| Step: 7
Training loss: 1.9694209696284293
Validation loss: 2.5395254879507707

Epoch: 6| Step: 8
Training loss: 2.0442813427567903
Validation loss: 2.536632130043481

Epoch: 6| Step: 9
Training loss: 2.8192837600980134
Validation loss: 2.528497506652466

Epoch: 6| Step: 10
Training loss: 2.447917586522572
Validation loss: 2.484232000588945

Epoch: 6| Step: 11
Training loss: 2.392560287720499
Validation loss: 2.4540145647913287

Epoch: 6| Step: 12
Training loss: 2.269689032475194
Validation loss: 2.409089662879809

Epoch: 6| Step: 13
Training loss: 2.5849564180813815
Validation loss: 2.3984873562964335

Epoch: 330| Step: 0
Training loss: 1.6264476929822251
Validation loss: 2.3891263475165725

Epoch: 6| Step: 1
Training loss: 2.6552084283141553
Validation loss: 2.4006521481896077

Epoch: 6| Step: 2
Training loss: 2.532398198935146
Validation loss: 2.381725970666687

Epoch: 6| Step: 3
Training loss: 3.088595016216004
Validation loss: 2.3863420054334292

Epoch: 6| Step: 4
Training loss: 2.3278089475201322
Validation loss: 2.408242704458465

Epoch: 6| Step: 5
Training loss: 2.3339952029691298
Validation loss: 2.4067676287344697

Epoch: 6| Step: 6
Training loss: 2.8922352197997987
Validation loss: 2.3979986634481008

Epoch: 6| Step: 7
Training loss: 3.034176072927924
Validation loss: 2.3953113213711954

Epoch: 6| Step: 8
Training loss: 2.7345929740128616
Validation loss: 2.4332156142605994

Epoch: 6| Step: 9
Training loss: 2.2583351454311105
Validation loss: 2.4686723891354334

Epoch: 6| Step: 10
Training loss: 2.4283419007739506
Validation loss: 2.53191356096678

Epoch: 6| Step: 11
Training loss: 2.186739762216504
Validation loss: 2.550582082225079

Epoch: 6| Step: 12
Training loss: 2.2150002614316078
Validation loss: 2.578387640647806

Epoch: 6| Step: 13
Training loss: 2.5081126190952228
Validation loss: 2.601159633622349

Epoch: 331| Step: 0
Training loss: 2.603986555864638
Validation loss: 2.6030845516926666

Epoch: 6| Step: 1
Training loss: 2.8355958170542066
Validation loss: 2.6053242200625153

Epoch: 6| Step: 2
Training loss: 2.725946307576426
Validation loss: 2.527988243949667

Epoch: 6| Step: 3
Training loss: 2.373438472383462
Validation loss: 2.4299022847497116

Epoch: 6| Step: 4
Training loss: 2.6677066344693063
Validation loss: 2.3986345740403143

Epoch: 6| Step: 5
Training loss: 2.0744086284618355
Validation loss: 2.3746568780606454

Epoch: 6| Step: 6
Training loss: 2.4237581868498213
Validation loss: 2.37972225710853

Epoch: 6| Step: 7
Training loss: 2.4245739080736786
Validation loss: 2.3629388696620395

Epoch: 6| Step: 8
Training loss: 2.1174853351179785
Validation loss: 2.3651495627769568

Epoch: 6| Step: 9
Training loss: 3.1907305334797975
Validation loss: 2.366776557308207

Epoch: 6| Step: 10
Training loss: 2.528767156915168
Validation loss: 2.379617230213004

Epoch: 6| Step: 11
Training loss: 2.5125738560084105
Validation loss: 2.374630974390319

Epoch: 6| Step: 12
Training loss: 2.392959452233355
Validation loss: 2.3973280896248306

Epoch: 6| Step: 13
Training loss: 2.4646460307238227
Validation loss: 2.4373568442066023

Epoch: 332| Step: 0
Training loss: 2.6312511126953093
Validation loss: 2.450735106442694

Epoch: 6| Step: 1
Training loss: 2.4741765511626777
Validation loss: 2.4662276851709644

Epoch: 6| Step: 2
Training loss: 2.7999904053387423
Validation loss: 2.4544301774783475

Epoch: 6| Step: 3
Training loss: 2.5491583014711883
Validation loss: 2.464209752793241

Epoch: 6| Step: 4
Training loss: 2.3468729194398232
Validation loss: 2.4604520668915377

Epoch: 6| Step: 5
Training loss: 2.3278638450028777
Validation loss: 2.4527853098380166

Epoch: 6| Step: 6
Training loss: 2.1967822819077916
Validation loss: 2.4622188921746786

Epoch: 6| Step: 7
Training loss: 2.1288275187921744
Validation loss: 2.463644847691935

Epoch: 6| Step: 8
Training loss: 2.960052921749972
Validation loss: 2.4767393964670115

Epoch: 6| Step: 9
Training loss: 2.289647362889473
Validation loss: 2.4456337202082454

Epoch: 6| Step: 10
Training loss: 2.1467248367144425
Validation loss: 2.4595963002752383

Epoch: 6| Step: 11
Training loss: 2.8086446829091756
Validation loss: 2.4445735702532647

Epoch: 6| Step: 12
Training loss: 2.668619771812993
Validation loss: 2.406574936357874

Epoch: 6| Step: 13
Training loss: 2.3878984048979675
Validation loss: 2.418920640882006

Epoch: 333| Step: 0
Training loss: 2.782684127871033
Validation loss: 2.398692650407414

Epoch: 6| Step: 1
Training loss: 2.7930903908443425
Validation loss: 2.456359432855091

Epoch: 6| Step: 2
Training loss: 2.2685761272125067
Validation loss: 2.4836330563568367

Epoch: 6| Step: 3
Training loss: 2.4731063071608053
Validation loss: 2.478470870549643

Epoch: 6| Step: 4
Training loss: 2.286372143301968
Validation loss: 2.497087761541698

Epoch: 6| Step: 5
Training loss: 2.16340136843745
Validation loss: 2.4765958837136184

Epoch: 6| Step: 6
Training loss: 2.5763675132429102
Validation loss: 2.467170314815601

Epoch: 6| Step: 7
Training loss: 2.740720177001484
Validation loss: 2.487529506952535

Epoch: 6| Step: 8
Training loss: 2.4769697847213656
Validation loss: 2.5179610537172867

Epoch: 6| Step: 9
Training loss: 2.3798088779164925
Validation loss: 2.52854579920593

Epoch: 6| Step: 10
Training loss: 2.665039151961569
Validation loss: 2.453350201280026

Epoch: 6| Step: 11
Training loss: 2.3937642547740747
Validation loss: 2.4509029572817758

Epoch: 6| Step: 12
Training loss: 2.3019001285156047
Validation loss: 2.429230872001756

Epoch: 6| Step: 13
Training loss: 2.4879382030257897
Validation loss: 2.4020553195621437

Epoch: 334| Step: 0
Training loss: 2.2280016079799254
Validation loss: 2.388984029580782

Epoch: 6| Step: 1
Training loss: 2.3885257454790825
Validation loss: 2.386330416960939

Epoch: 6| Step: 2
Training loss: 2.487543928055613
Validation loss: 2.4160936874708163

Epoch: 6| Step: 3
Training loss: 2.551780610068465
Validation loss: 2.387718232415158

Epoch: 6| Step: 4
Training loss: 2.1746799277332602
Validation loss: 2.394961666067827

Epoch: 6| Step: 5
Training loss: 2.511973319197452
Validation loss: 2.386387063182984

Epoch: 6| Step: 6
Training loss: 2.6358627625313065
Validation loss: 2.380191056419562

Epoch: 6| Step: 7
Training loss: 2.326623419584712
Validation loss: 2.416024217794158

Epoch: 6| Step: 8
Training loss: 2.6046560412579853
Validation loss: 2.430402920721189

Epoch: 6| Step: 9
Training loss: 2.4150499219453585
Validation loss: 2.484975795704315

Epoch: 6| Step: 10
Training loss: 2.7399506316645086
Validation loss: 2.4889990639759456

Epoch: 6| Step: 11
Training loss: 2.648883703222824
Validation loss: 2.5413276255264092

Epoch: 6| Step: 12
Training loss: 2.7067027147207106
Validation loss: 2.5955646175193645

Epoch: 6| Step: 13
Training loss: 2.7757787144544954
Validation loss: 2.5669024267165366

Epoch: 335| Step: 0
Training loss: 2.0672609115794236
Validation loss: 2.4813026939023404

Epoch: 6| Step: 1
Training loss: 2.792431845110749
Validation loss: 2.4431182127728057

Epoch: 6| Step: 2
Training loss: 2.479730835736047
Validation loss: 2.3967506628540782

Epoch: 6| Step: 3
Training loss: 2.239518654059368
Validation loss: 2.397632804457686

Epoch: 6| Step: 4
Training loss: 2.364808350554242
Validation loss: 2.374239623362852

Epoch: 6| Step: 5
Training loss: 2.9974884010071436
Validation loss: 2.3524938065220224

Epoch: 6| Step: 6
Training loss: 2.8067346608887918
Validation loss: 2.365470705269897

Epoch: 6| Step: 7
Training loss: 2.050859838523956
Validation loss: 2.3521627038268953

Epoch: 6| Step: 8
Training loss: 1.4460294852462512
Validation loss: 2.3832779258823455

Epoch: 6| Step: 9
Training loss: 2.8734375398271816
Validation loss: 2.393499463010362

Epoch: 6| Step: 10
Training loss: 2.5296816264432467
Validation loss: 2.406428014751768

Epoch: 6| Step: 11
Training loss: 2.9006697703422133
Validation loss: 2.4351508055706392

Epoch: 6| Step: 12
Training loss: 2.122651541504255
Validation loss: 2.482037298373117

Epoch: 6| Step: 13
Training loss: 2.8922525308924207
Validation loss: 2.4827015914435613

Epoch: 336| Step: 0
Training loss: 2.020171014326268
Validation loss: 2.4751318494874575

Epoch: 6| Step: 1
Training loss: 2.2091954785567496
Validation loss: 2.4542315362137623

Epoch: 6| Step: 2
Training loss: 1.749101339934376
Validation loss: 2.481676827881281

Epoch: 6| Step: 3
Training loss: 2.65057979574877
Validation loss: 2.4796293810435683

Epoch: 6| Step: 4
Training loss: 2.7312239447077604
Validation loss: 2.4683886723492194

Epoch: 6| Step: 5
Training loss: 2.809747238873312
Validation loss: 2.4553009419480976

Epoch: 6| Step: 6
Training loss: 3.0159515045982386
Validation loss: 2.438098151493113

Epoch: 6| Step: 7
Training loss: 2.359315378812604
Validation loss: 2.4227243776545775

Epoch: 6| Step: 8
Training loss: 3.0143501077281067
Validation loss: 2.413960970129305

Epoch: 6| Step: 9
Training loss: 2.0998947162575687
Validation loss: 2.4010380207553976

Epoch: 6| Step: 10
Training loss: 2.024264486982083
Validation loss: 2.397938738902451

Epoch: 6| Step: 11
Training loss: 2.530920124929266
Validation loss: 2.4128386395260195

Epoch: 6| Step: 12
Training loss: 2.8243556747906537
Validation loss: 2.4388673563584025

Epoch: 6| Step: 13
Training loss: 1.110540717795871
Validation loss: 2.453000512461129

Epoch: 337| Step: 0
Training loss: 2.3140416548135865
Validation loss: 2.4440075355535664

Epoch: 6| Step: 1
Training loss: 2.310887057751387
Validation loss: 2.483846259250596

Epoch: 6| Step: 2
Training loss: 2.348854305109378
Validation loss: 2.4883217553533408

Epoch: 6| Step: 3
Training loss: 2.348069546541999
Validation loss: 2.4551564558817955

Epoch: 6| Step: 4
Training loss: 2.4067764697118617
Validation loss: 2.4241889857588186

Epoch: 6| Step: 5
Training loss: 2.45638005734964
Validation loss: 2.4679762568970878

Epoch: 6| Step: 6
Training loss: 2.8102249268620625
Validation loss: 2.4958795965329528

Epoch: 6| Step: 7
Training loss: 2.330364813998186
Validation loss: 2.499212479377466

Epoch: 6| Step: 8
Training loss: 2.1157273328365402
Validation loss: 2.480350881289955

Epoch: 6| Step: 9
Training loss: 2.786329880840476
Validation loss: 2.462755957069295

Epoch: 6| Step: 10
Training loss: 2.194708364312289
Validation loss: 2.4412245501101983

Epoch: 6| Step: 11
Training loss: 2.4532422080254923
Validation loss: 2.4262730693335883

Epoch: 6| Step: 12
Training loss: 2.897874145049587
Validation loss: 2.388529763967258

Epoch: 6| Step: 13
Training loss: 2.3811267330274113
Validation loss: 2.365467132057369

Epoch: 338| Step: 0
Training loss: 2.0249915322962666
Validation loss: 2.3859957407560652

Epoch: 6| Step: 1
Training loss: 1.9329911342956292
Validation loss: 2.398247580387335

Epoch: 6| Step: 2
Training loss: 2.6708136341084616
Validation loss: 2.438359708709457

Epoch: 6| Step: 3
Training loss: 2.340871340084469
Validation loss: 2.4512798778895135

Epoch: 6| Step: 4
Training loss: 2.653104827408771
Validation loss: 2.467406661702594

Epoch: 6| Step: 5
Training loss: 1.986795226082885
Validation loss: 2.4656002792944314

Epoch: 6| Step: 6
Training loss: 2.059342481619802
Validation loss: 2.471694727976294

Epoch: 6| Step: 7
Training loss: 2.6748046875
Validation loss: 2.4485620999182514

Epoch: 6| Step: 8
Training loss: 2.590576160370871
Validation loss: 2.456774560685073

Epoch: 6| Step: 9
Training loss: 2.393984360340249
Validation loss: 2.404787554346445

Epoch: 6| Step: 10
Training loss: 2.3887351550924008
Validation loss: 2.3793434651775116

Epoch: 6| Step: 11
Training loss: 3.104136439097312
Validation loss: 2.3950356060016014

Epoch: 6| Step: 12
Training loss: 2.8840584065611528
Validation loss: 2.4248170732288368

Epoch: 6| Step: 13
Training loss: 2.4405274785641544
Validation loss: 2.4027999875559654

Epoch: 339| Step: 0
Training loss: 2.5741178871967536
Validation loss: 2.396083222385516

Epoch: 6| Step: 1
Training loss: 2.0809482527554
Validation loss: 2.4040221885769437

Epoch: 6| Step: 2
Training loss: 2.102268143070106
Validation loss: 2.3889262344418714

Epoch: 6| Step: 3
Training loss: 2.3585361227278065
Validation loss: 2.3932087026232627

Epoch: 6| Step: 4
Training loss: 2.548385920841698
Validation loss: 2.397555372183055

Epoch: 6| Step: 5
Training loss: 2.6215175053028217
Validation loss: 2.405809914902655

Epoch: 6| Step: 6
Training loss: 2.3695940431348688
Validation loss: 2.3919362147777665

Epoch: 6| Step: 7
Training loss: 2.535085527230017
Validation loss: 2.399199820207226

Epoch: 6| Step: 8
Training loss: 2.3453143176351947
Validation loss: 2.4157066630796726

Epoch: 6| Step: 9
Training loss: 2.766031181551367
Validation loss: 2.4291471406628236

Epoch: 6| Step: 10
Training loss: 2.212741937717675
Validation loss: 2.435575485373938

Epoch: 6| Step: 11
Training loss: 2.9972545459015065
Validation loss: 2.480143285329205

Epoch: 6| Step: 12
Training loss: 2.237011401144415
Validation loss: 2.48376477368357

Epoch: 6| Step: 13
Training loss: 2.035978594092238
Validation loss: 2.4829985275898543

Epoch: 340| Step: 0
Training loss: 2.258133070208342
Validation loss: 2.5165321509596255

Epoch: 6| Step: 1
Training loss: 2.634082883882008
Validation loss: 2.486805288563883

Epoch: 6| Step: 2
Training loss: 2.245282419702714
Validation loss: 2.495089723262379

Epoch: 6| Step: 3
Training loss: 2.0756865227462575
Validation loss: 2.476393669338565

Epoch: 6| Step: 4
Training loss: 2.72523129382781
Validation loss: 2.454058652693422

Epoch: 6| Step: 5
Training loss: 2.7242845348470195
Validation loss: 2.456990501128119

Epoch: 6| Step: 6
Training loss: 3.150808799693203
Validation loss: 2.438112096339778

Epoch: 6| Step: 7
Training loss: 1.9244179378227753
Validation loss: 2.474215586077851

Epoch: 6| Step: 8
Training loss: 1.881404809506906
Validation loss: 2.4576329992097175

Epoch: 6| Step: 9
Training loss: 2.5926202358810673
Validation loss: 2.497377932032255

Epoch: 6| Step: 10
Training loss: 2.639625314942197
Validation loss: 2.407378184873288

Epoch: 6| Step: 11
Training loss: 2.2564298098446076
Validation loss: 2.3897481177814637

Epoch: 6| Step: 12
Training loss: 2.5362320837569703
Validation loss: 2.369571340641607

Epoch: 6| Step: 13
Training loss: 2.3632365577191967
Validation loss: 2.3327392189455947

Epoch: 341| Step: 0
Training loss: 2.1654083804168422
Validation loss: 2.346042348791508

Epoch: 6| Step: 1
Training loss: 2.6153024745789573
Validation loss: 2.346248180762758

Epoch: 6| Step: 2
Training loss: 3.019836489311992
Validation loss: 2.351060669790869

Epoch: 6| Step: 3
Training loss: 2.3943329024192566
Validation loss: 2.3724867525274056

Epoch: 6| Step: 4
Training loss: 1.9656694925727907
Validation loss: 2.4142188050043285

Epoch: 6| Step: 5
Training loss: 2.223229091417712
Validation loss: 2.4867858251483783

Epoch: 6| Step: 6
Training loss: 2.2080242252541256
Validation loss: 2.5555000629823303

Epoch: 6| Step: 7
Training loss: 3.3723142321912483
Validation loss: 2.584904736276719

Epoch: 6| Step: 8
Training loss: 2.213878495263634
Validation loss: 2.519497989512271

Epoch: 6| Step: 9
Training loss: 2.4809282493010416
Validation loss: 2.439641486668975

Epoch: 6| Step: 10
Training loss: 2.5634476374856217
Validation loss: 2.393380390776576

Epoch: 6| Step: 11
Training loss: 2.5428352379505994
Validation loss: 2.3652494051771846

Epoch: 6| Step: 12
Training loss: 2.5236000977087314
Validation loss: 2.3767562988158644

Epoch: 6| Step: 13
Training loss: 3.025164758908592
Validation loss: 2.353759914160329

Epoch: 342| Step: 0
Training loss: 3.0667082230889724
Validation loss: 2.3571485241358068

Epoch: 6| Step: 1
Training loss: 2.448665964146046
Validation loss: 2.3701016657512124

Epoch: 6| Step: 2
Training loss: 2.672901424880859
Validation loss: 2.3428309968023093

Epoch: 6| Step: 3
Training loss: 2.491431142420086
Validation loss: 2.3862737522049584

Epoch: 6| Step: 4
Training loss: 2.9114754573384407
Validation loss: 2.4037572165886565

Epoch: 6| Step: 5
Training loss: 2.148106109029965
Validation loss: 2.435245187248939

Epoch: 6| Step: 6
Training loss: 1.9291199378443589
Validation loss: 2.4700044773139775

Epoch: 6| Step: 7
Training loss: 2.0916116527399837
Validation loss: 2.4981317050736953

Epoch: 6| Step: 8
Training loss: 2.5099764130536553
Validation loss: 2.4468325711923447

Epoch: 6| Step: 9
Training loss: 2.737385340688806
Validation loss: 2.4883438519484784

Epoch: 6| Step: 10
Training loss: 2.2621232957367168
Validation loss: 2.4859551107559454

Epoch: 6| Step: 11
Training loss: 1.9292521738611312
Validation loss: 2.481041347775084

Epoch: 6| Step: 12
Training loss: 2.4356478966118096
Validation loss: 2.477375317796045

Epoch: 6| Step: 13
Training loss: 2.3985699048601807
Validation loss: 2.513027092242949

Epoch: 343| Step: 0
Training loss: 2.3523839992093825
Validation loss: 2.5461374756682464

Epoch: 6| Step: 1
Training loss: 2.7865958111560056
Validation loss: 2.567563009131862

Epoch: 6| Step: 2
Training loss: 2.402855993723866
Validation loss: 2.5581799640106593

Epoch: 6| Step: 3
Training loss: 2.203152054424422
Validation loss: 2.504301992495899

Epoch: 6| Step: 4
Training loss: 3.1418497155353826
Validation loss: 2.4511911024499704

Epoch: 6| Step: 5
Training loss: 2.1700556977327117
Validation loss: 2.428122959581394

Epoch: 6| Step: 6
Training loss: 2.418727478395632
Validation loss: 2.387231408299298

Epoch: 6| Step: 7
Training loss: 2.434529573089745
Validation loss: 2.3557736731316856

Epoch: 6| Step: 8
Training loss: 2.165142024185434
Validation loss: 2.3535862213536167

Epoch: 6| Step: 9
Training loss: 2.1690751285512357
Validation loss: 2.3639757869241063

Epoch: 6| Step: 10
Training loss: 2.791278033937884
Validation loss: 2.3543787608507034

Epoch: 6| Step: 11
Training loss: 2.4136574414610825
Validation loss: 2.3482789350230338

Epoch: 6| Step: 12
Training loss: 2.5924488158953323
Validation loss: 2.3649972742429157

Epoch: 6| Step: 13
Training loss: 2.936438023574887
Validation loss: 2.382528347352087

Epoch: 344| Step: 0
Training loss: 2.602476766960812
Validation loss: 2.435598109446247

Epoch: 6| Step: 1
Training loss: 2.448691181997285
Validation loss: 2.505966216855728

Epoch: 6| Step: 2
Training loss: 2.552576995644807
Validation loss: 2.5167106579208585

Epoch: 6| Step: 3
Training loss: 2.2233809377481943
Validation loss: 2.4942948195601065

Epoch: 6| Step: 4
Training loss: 2.9007864839284183
Validation loss: 2.4751289555745033

Epoch: 6| Step: 5
Training loss: 2.3349954498050636
Validation loss: 2.439181807520576

Epoch: 6| Step: 6
Training loss: 2.4964461816556014
Validation loss: 2.4239847754110637

Epoch: 6| Step: 7
Training loss: 2.7512101198501133
Validation loss: 2.399283355062005

Epoch: 6| Step: 8
Training loss: 2.8228422955127503
Validation loss: 2.3990950262147055

Epoch: 6| Step: 9
Training loss: 2.334711167566968
Validation loss: 2.3883813872187134

Epoch: 6| Step: 10
Training loss: 2.0757761135762807
Validation loss: 2.4054100105730694

Epoch: 6| Step: 11
Training loss: 2.1894194764572594
Validation loss: 2.4090732078216424

Epoch: 6| Step: 12
Training loss: 2.2007327246741393
Validation loss: 2.4317193603156415

Epoch: 6| Step: 13
Training loss: 1.931877468851734
Validation loss: 2.4411477318185906

Epoch: 345| Step: 0
Training loss: 2.4258215466283635
Validation loss: 2.465632527341696

Epoch: 6| Step: 1
Training loss: 1.7411213850183347
Validation loss: 2.484047422652335

Epoch: 6| Step: 2
Training loss: 2.590585271625033
Validation loss: 2.5532889944732537

Epoch: 6| Step: 3
Training loss: 2.5528627931009473
Validation loss: 2.5250536024052623

Epoch: 6| Step: 4
Training loss: 1.089707013921717
Validation loss: 2.4968874587978056

Epoch: 6| Step: 5
Training loss: 1.8226960911588383
Validation loss: 2.460815637100376

Epoch: 6| Step: 6
Training loss: 2.6906358034136333
Validation loss: 2.445782368318298

Epoch: 6| Step: 7
Training loss: 2.9391358061697956
Validation loss: 2.4250571641357217

Epoch: 6| Step: 8
Training loss: 2.780551265425733
Validation loss: 2.4169428985399413

Epoch: 6| Step: 9
Training loss: 2.872882560839204
Validation loss: 2.393712220244165

Epoch: 6| Step: 10
Training loss: 2.348151384844568
Validation loss: 2.3929389651709077

Epoch: 6| Step: 11
Training loss: 2.7348656786305554
Validation loss: 2.385174956978788

Epoch: 6| Step: 12
Training loss: 2.509739595864538
Validation loss: 2.396931852695452

Epoch: 6| Step: 13
Training loss: 2.1122383181320825
Validation loss: 2.3826993299776116

Epoch: 346| Step: 0
Training loss: 2.1141427869980585
Validation loss: 2.3786490439886685

Epoch: 6| Step: 1
Training loss: 2.2875330896537838
Validation loss: 2.3626636473406943

Epoch: 6| Step: 2
Training loss: 2.407545657413229
Validation loss: 2.3890745853999467

Epoch: 6| Step: 3
Training loss: 2.631660367810388
Validation loss: 2.3649603227987686

Epoch: 6| Step: 4
Training loss: 1.8848560687091616
Validation loss: 2.3933919419006706

Epoch: 6| Step: 5
Training loss: 2.637872468944348
Validation loss: 2.395667111452059

Epoch: 6| Step: 6
Training loss: 2.3142075291635167
Validation loss: 2.4633696830210408

Epoch: 6| Step: 7
Training loss: 2.5527615534788355
Validation loss: 2.490496768852337

Epoch: 6| Step: 8
Training loss: 1.8868990667829368
Validation loss: 2.5728608085032802

Epoch: 6| Step: 9
Training loss: 2.974071992660786
Validation loss: 2.545090353632895

Epoch: 6| Step: 10
Training loss: 2.7689862703731736
Validation loss: 2.451585752704388

Epoch: 6| Step: 11
Training loss: 2.74702934725499
Validation loss: 2.4217802930951944

Epoch: 6| Step: 12
Training loss: 2.3929776850678968
Validation loss: 2.404018545230842

Epoch: 6| Step: 13
Training loss: 2.448432370237078
Validation loss: 2.4114988744387795

Epoch: 347| Step: 0
Training loss: 2.548644591991324
Validation loss: 2.3750583369501244

Epoch: 6| Step: 1
Training loss: 2.7258474729523625
Validation loss: 2.3894010865608646

Epoch: 6| Step: 2
Training loss: 2.2332671293248487
Validation loss: 2.375278886138384

Epoch: 6| Step: 3
Training loss: 1.7057386169948332
Validation loss: 2.369686625164243

Epoch: 6| Step: 4
Training loss: 2.25917978036926
Validation loss: 2.3576352999805654

Epoch: 6| Step: 5
Training loss: 2.8018834114841917
Validation loss: 2.4010098103120145

Epoch: 6| Step: 6
Training loss: 2.146547686239306
Validation loss: 2.404022531423365

Epoch: 6| Step: 7
Training loss: 2.0351693707590486
Validation loss: 2.398160122561419

Epoch: 6| Step: 8
Training loss: 2.5644439209005143
Validation loss: 2.4115307568323607

Epoch: 6| Step: 9
Training loss: 2.4440291574552573
Validation loss: 2.4251807445814038

Epoch: 6| Step: 10
Training loss: 2.795653518677982
Validation loss: 2.4357596643075645

Epoch: 6| Step: 11
Training loss: 2.1252239333697927
Validation loss: 2.485789886677194

Epoch: 6| Step: 12
Training loss: 2.795323714206605
Validation loss: 2.5075527226948426

Epoch: 6| Step: 13
Training loss: 2.277223665660359
Validation loss: 2.505446643319269

Epoch: 348| Step: 0
Training loss: 2.446953853345091
Validation loss: 2.497156136668522

Epoch: 6| Step: 1
Training loss: 2.152062704080367
Validation loss: 2.466230243376101

Epoch: 6| Step: 2
Training loss: 2.4146176783105164
Validation loss: 2.452447833695701

Epoch: 6| Step: 3
Training loss: 2.2996860870427485
Validation loss: 2.4454918760575675

Epoch: 6| Step: 4
Training loss: 2.639131925221925
Validation loss: 2.5018239802051534

Epoch: 6| Step: 5
Training loss: 2.5276582454417196
Validation loss: 2.5215549342993397

Epoch: 6| Step: 6
Training loss: 2.6863825049366277
Validation loss: 2.4938025495200566

Epoch: 6| Step: 7
Training loss: 2.612340829189239
Validation loss: 2.4887141322232953

Epoch: 6| Step: 8
Training loss: 2.146253550842583
Validation loss: 2.4334889780478264

Epoch: 6| Step: 9
Training loss: 2.4640573253589353
Validation loss: 2.392271142803424

Epoch: 6| Step: 10
Training loss: 2.1207045730245793
Validation loss: 2.366937892276915

Epoch: 6| Step: 11
Training loss: 2.4749770038191454
Validation loss: 2.3629901703677514

Epoch: 6| Step: 12
Training loss: 2.2857522301419455
Validation loss: 2.359142450374753

Epoch: 6| Step: 13
Training loss: 2.48032456827514
Validation loss: 2.3775126858524804

Epoch: 349| Step: 0
Training loss: 2.3299443861255025
Validation loss: 2.370081533837529

Epoch: 6| Step: 1
Training loss: 2.7928714335100016
Validation loss: 2.3919425913523322

Epoch: 6| Step: 2
Training loss: 2.4120208106210734
Validation loss: 2.421363358929958

Epoch: 6| Step: 3
Training loss: 2.027135231893168
Validation loss: 2.4802811529475344

Epoch: 6| Step: 4
Training loss: 2.526764368451387
Validation loss: 2.52546977166165

Epoch: 6| Step: 5
Training loss: 2.6312657915307476
Validation loss: 2.5887627668856137

Epoch: 6| Step: 6
Training loss: 3.145047390676269
Validation loss: 2.5749114342605646

Epoch: 6| Step: 7
Training loss: 2.8188163191274107
Validation loss: 2.5191380444450906

Epoch: 6| Step: 8
Training loss: 2.4107202398640406
Validation loss: 2.4332133426938065

Epoch: 6| Step: 9
Training loss: 2.567147668957873
Validation loss: 2.379689576346688

Epoch: 6| Step: 10
Training loss: 2.306144848419034
Validation loss: 2.34262959707594

Epoch: 6| Step: 11
Training loss: 2.559591829572616
Validation loss: 2.3560817242468315

Epoch: 6| Step: 12
Training loss: 2.3378222972601863
Validation loss: 2.3567482948528578

Epoch: 6| Step: 13
Training loss: 1.224247734539794
Validation loss: 2.353460164676791

Epoch: 350| Step: 0
Training loss: 2.016560182308495
Validation loss: 2.3633017175436115

Epoch: 6| Step: 1
Training loss: 2.5739432898071137
Validation loss: 2.3921658148736844

Epoch: 6| Step: 2
Training loss: 2.95686821633002
Validation loss: 2.428061883273699

Epoch: 6| Step: 3
Training loss: 2.672840680067817
Validation loss: 2.45494094830744

Epoch: 6| Step: 4
Training loss: 2.7317991494649783
Validation loss: 2.46696307807868

Epoch: 6| Step: 5
Training loss: 1.815685564038858
Validation loss: 2.508344261974985

Epoch: 6| Step: 6
Training loss: 1.904283040314329
Validation loss: 2.5360653790533187

Epoch: 6| Step: 7
Training loss: 2.1375587946072576
Validation loss: 2.5385157246469903

Epoch: 6| Step: 8
Training loss: 2.6141379738245276
Validation loss: 2.573431225529993

Epoch: 6| Step: 9
Training loss: 2.2926568984126496
Validation loss: 2.572179471403388

Epoch: 6| Step: 10
Training loss: 2.013813713102963
Validation loss: 2.5879391148660793

Epoch: 6| Step: 11
Training loss: 2.5395076420190765
Validation loss: 2.559583116797561

Epoch: 6| Step: 12
Training loss: 3.024809769883378
Validation loss: 2.4807165886187326

Epoch: 6| Step: 13
Training loss: 2.6992809327135507
Validation loss: 2.403822273060048

Epoch: 351| Step: 0
Training loss: 2.445028757811629
Validation loss: 2.3874446145834085

Epoch: 6| Step: 1
Training loss: 2.4129274533144374
Validation loss: 2.35731617427491

Epoch: 6| Step: 2
Training loss: 2.6807120897337025
Validation loss: 2.351435809336838

Epoch: 6| Step: 3
Training loss: 2.898194007208277
Validation loss: 2.3697111310574654

Epoch: 6| Step: 4
Training loss: 1.984900697775407
Validation loss: 2.353159556657853

Epoch: 6| Step: 5
Training loss: 2.4158443060217065
Validation loss: 2.3571615840304867

Epoch: 6| Step: 6
Training loss: 2.7868467446447798
Validation loss: 2.3682095310559936

Epoch: 6| Step: 7
Training loss: 2.294988571171779
Validation loss: 2.3646586083942007

Epoch: 6| Step: 8
Training loss: 2.273275782545598
Validation loss: 2.351409063299589

Epoch: 6| Step: 9
Training loss: 2.0754168080323017
Validation loss: 2.3564920874599746

Epoch: 6| Step: 10
Training loss: 2.801625484986132
Validation loss: 2.3745458608037775

Epoch: 6| Step: 11
Training loss: 2.0802758351241346
Validation loss: 2.363687235328296

Epoch: 6| Step: 12
Training loss: 2.108301864610316
Validation loss: 2.447908467890184

Epoch: 6| Step: 13
Training loss: 2.417056600309629
Validation loss: 2.509846717887717

Epoch: 352| Step: 0
Training loss: 2.1668568552125094
Validation loss: 2.5645199049657874

Epoch: 6| Step: 1
Training loss: 2.5957890044989567
Validation loss: 2.58346300530725

Epoch: 6| Step: 2
Training loss: 2.3580395285259366
Validation loss: 2.6011548979251207

Epoch: 6| Step: 3
Training loss: 2.7187838497466226
Validation loss: 2.5401913035521404

Epoch: 6| Step: 4
Training loss: 2.804733998542783
Validation loss: 2.4366026047575935

Epoch: 6| Step: 5
Training loss: 2.583224345543604
Validation loss: 2.365685690669722

Epoch: 6| Step: 6
Training loss: 2.29826468642053
Validation loss: 2.3669507551887636

Epoch: 6| Step: 7
Training loss: 2.6130151085692335
Validation loss: 2.360602635551205

Epoch: 6| Step: 8
Training loss: 3.0899082567737057
Validation loss: 2.341996498586303

Epoch: 6| Step: 9
Training loss: 2.008787756934736
Validation loss: 2.3718749580197933

Epoch: 6| Step: 10
Training loss: 2.0918868016165666
Validation loss: 2.3642049881295253

Epoch: 6| Step: 11
Training loss: 2.3441985654734276
Validation loss: 2.381636516481502

Epoch: 6| Step: 12
Training loss: 2.0594987707613663
Validation loss: 2.3991025971383433

Epoch: 6| Step: 13
Training loss: 2.2528550789214816
Validation loss: 2.4453451319625805

Epoch: 353| Step: 0
Training loss: 2.0955609133802366
Validation loss: 2.5399371038130933

Epoch: 6| Step: 1
Training loss: 2.8337885173103237
Validation loss: 2.6315432154750598

Epoch: 6| Step: 2
Training loss: 2.478585845698032
Validation loss: 2.6935492246856283

Epoch: 6| Step: 3
Training loss: 2.4493191103777536
Validation loss: 2.645110545039296

Epoch: 6| Step: 4
Training loss: 1.9909206775630577
Validation loss: 2.602310918012131

Epoch: 6| Step: 5
Training loss: 2.054822561952345
Validation loss: 2.5736485393938144

Epoch: 6| Step: 6
Training loss: 2.7304827208154743
Validation loss: 2.5176340614341264

Epoch: 6| Step: 7
Training loss: 2.743486319625837
Validation loss: 2.451877958140315

Epoch: 6| Step: 8
Training loss: 2.8551123692834492
Validation loss: 2.4034065169486025

Epoch: 6| Step: 9
Training loss: 1.821882365033556
Validation loss: 2.3910923060816778

Epoch: 6| Step: 10
Training loss: 2.5519134672555714
Validation loss: 2.358017218162721

Epoch: 6| Step: 11
Training loss: 2.300926838593274
Validation loss: 2.3417807123168215

Epoch: 6| Step: 12
Training loss: 2.1838318723933634
Validation loss: 2.351408643550534

Epoch: 6| Step: 13
Training loss: 2.845088098968739
Validation loss: 2.3464957535702107

Epoch: 354| Step: 0
Training loss: 1.6361294871480099
Validation loss: 2.3605634693224284

Epoch: 6| Step: 1
Training loss: 2.538412345396234
Validation loss: 2.383642321738614

Epoch: 6| Step: 2
Training loss: 2.7169006020704476
Validation loss: 2.3885425728531975

Epoch: 6| Step: 3
Training loss: 2.3144201606302257
Validation loss: 2.3911994309897597

Epoch: 6| Step: 4
Training loss: 2.5265557359216815
Validation loss: 2.40565042279851

Epoch: 6| Step: 5
Training loss: 2.0760959672374115
Validation loss: 2.4662039668135667

Epoch: 6| Step: 6
Training loss: 2.1751235707575756
Validation loss: 2.468034934322413

Epoch: 6| Step: 7
Training loss: 2.5975624469083276
Validation loss: 2.4798824869022327

Epoch: 6| Step: 8
Training loss: 2.188138160262838
Validation loss: 2.4784803153078285

Epoch: 6| Step: 9
Training loss: 2.073663267192416
Validation loss: 2.4906716895917858

Epoch: 6| Step: 10
Training loss: 2.8003600161573465
Validation loss: 2.4944359533065823

Epoch: 6| Step: 11
Training loss: 2.5605831885654418
Validation loss: 2.451421407004604

Epoch: 6| Step: 12
Training loss: 2.8323026540210368
Validation loss: 2.4453202727494805

Epoch: 6| Step: 13
Training loss: 2.0942665715440256
Validation loss: 2.3928092497007207

Epoch: 355| Step: 0
Training loss: 2.491659365572062
Validation loss: 2.3933851455533435

Epoch: 6| Step: 1
Training loss: 2.6413517239755357
Validation loss: 2.4068874797989115

Epoch: 6| Step: 2
Training loss: 2.3220160296442938
Validation loss: 2.3931743485173325

Epoch: 6| Step: 3
Training loss: 2.037739408504595
Validation loss: 2.356551654971192

Epoch: 6| Step: 4
Training loss: 2.7735998831479094
Validation loss: 2.355297393870333

Epoch: 6| Step: 5
Training loss: 2.604029038925101
Validation loss: 2.354404732176295

Epoch: 6| Step: 6
Training loss: 2.613374853809893
Validation loss: 2.3886773786165376

Epoch: 6| Step: 7
Training loss: 1.6498906388309282
Validation loss: 2.4010047193492636

Epoch: 6| Step: 8
Training loss: 2.5591557708114103
Validation loss: 2.4648553801741055

Epoch: 6| Step: 9
Training loss: 1.6684597463030295
Validation loss: 2.485695763691925

Epoch: 6| Step: 10
Training loss: 2.4279690764844486
Validation loss: 2.512103703124416

Epoch: 6| Step: 11
Training loss: 2.43511846547924
Validation loss: 2.5733507067681374

Epoch: 6| Step: 12
Training loss: 2.6096249763308603
Validation loss: 2.613012109331344

Epoch: 6| Step: 13
Training loss: 2.6098023938319685
Validation loss: 2.561457448153003

Epoch: 356| Step: 0
Training loss: 2.1697874946084084
Validation loss: 2.5070719153960463

Epoch: 6| Step: 1
Training loss: 2.3611473853622167
Validation loss: 2.4344902904197423

Epoch: 6| Step: 2
Training loss: 2.4602427637292084
Validation loss: 2.4227025254034458

Epoch: 6| Step: 3
Training loss: 2.5810533942841065
Validation loss: 2.3902028650967346

Epoch: 6| Step: 4
Training loss: 1.9215467219155495
Validation loss: 2.3497122103785912

Epoch: 6| Step: 5
Training loss: 2.7297377146669684
Validation loss: 2.3600926233163295

Epoch: 6| Step: 6
Training loss: 2.4096104329978854
Validation loss: 2.3474517717382475

Epoch: 6| Step: 7
Training loss: 2.3488770419403178
Validation loss: 2.379735543235347

Epoch: 6| Step: 8
Training loss: 2.703710062734634
Validation loss: 2.3585867779034517

Epoch: 6| Step: 9
Training loss: 1.9889504256516986
Validation loss: 2.3473094466791293

Epoch: 6| Step: 10
Training loss: 2.111432576661484
Validation loss: 2.3724913049691096

Epoch: 6| Step: 11
Training loss: 2.725586374871203
Validation loss: 2.370776924681832

Epoch: 6| Step: 12
Training loss: 2.439870610793144
Validation loss: 2.406877819610972

Epoch: 6| Step: 13
Training loss: 2.196368740565038
Validation loss: 2.4293869661491994

Epoch: 357| Step: 0
Training loss: 2.2384812829873444
Validation loss: 2.449076253033028

Epoch: 6| Step: 1
Training loss: 2.327080204163863
Validation loss: 2.4624245771516895

Epoch: 6| Step: 2
Training loss: 2.570504595874298
Validation loss: 2.4494281055281837

Epoch: 6| Step: 3
Training loss: 2.3113218863465743
Validation loss: 2.422364182940276

Epoch: 6| Step: 4
Training loss: 2.186558766183995
Validation loss: 2.411288515341931

Epoch: 6| Step: 5
Training loss: 2.0512053132986683
Validation loss: 2.403123445637177

Epoch: 6| Step: 6
Training loss: 2.820857198849972
Validation loss: 2.363955230867741

Epoch: 6| Step: 7
Training loss: 2.5262333643165924
Validation loss: 2.35193509171396

Epoch: 6| Step: 8
Training loss: 0.9749482813591837
Validation loss: 2.3839068146700106

Epoch: 6| Step: 9
Training loss: 2.86302011087478
Validation loss: 2.3960495182925667

Epoch: 6| Step: 10
Training loss: 2.659906003051303
Validation loss: 2.430129739365085

Epoch: 6| Step: 11
Training loss: 2.201932327256203
Validation loss: 2.4158169200479036

Epoch: 6| Step: 12
Training loss: 2.5527642619711806
Validation loss: 2.490490915337573

Epoch: 6| Step: 13
Training loss: 2.45980964125721
Validation loss: 2.4981506501077857

Epoch: 358| Step: 0
Training loss: 2.424065368501147
Validation loss: 2.5389962378754243

Epoch: 6| Step: 1
Training loss: 2.041035132794034
Validation loss: 2.566189503659933

Epoch: 6| Step: 2
Training loss: 2.393054899084122
Validation loss: 2.5383612046196835

Epoch: 6| Step: 3
Training loss: 2.78778936141535
Validation loss: 2.5610966515113063

Epoch: 6| Step: 4
Training loss: 2.354500592160186
Validation loss: 2.490469423509746

Epoch: 6| Step: 5
Training loss: 2.5125877099361267
Validation loss: 2.42211054021428

Epoch: 6| Step: 6
Training loss: 2.0708555265141833
Validation loss: 2.383677656412949

Epoch: 6| Step: 7
Training loss: 2.211730599110568
Validation loss: 2.3478733131861094

Epoch: 6| Step: 8
Training loss: 2.535174870826742
Validation loss: 2.3419634927994966

Epoch: 6| Step: 9
Training loss: 2.25288058369223
Validation loss: 2.3219061075688114

Epoch: 6| Step: 10
Training loss: 3.014222130075764
Validation loss: 2.348854386967603

Epoch: 6| Step: 11
Training loss: 2.335861766187131
Validation loss: 2.350241774536587

Epoch: 6| Step: 12
Training loss: 2.0882195837161555
Validation loss: 2.3601158623439793

Epoch: 6| Step: 13
Training loss: 2.5138822406753483
Validation loss: 2.406754995667043

Epoch: 359| Step: 0
Training loss: 2.498020723756294
Validation loss: 2.4811680561269096

Epoch: 6| Step: 1
Training loss: 2.4529465531483843
Validation loss: 2.549799381860013

Epoch: 6| Step: 2
Training loss: 2.2695561471646952
Validation loss: 2.558240865009192

Epoch: 6| Step: 3
Training loss: 2.4383298977219043
Validation loss: 2.572564945506717

Epoch: 6| Step: 4
Training loss: 2.2076866594588416
Validation loss: 2.5052803337395395

Epoch: 6| Step: 5
Training loss: 2.4942524645172726
Validation loss: 2.451460712225877

Epoch: 6| Step: 6
Training loss: 2.6720953956409867
Validation loss: 2.405770091886492

Epoch: 6| Step: 7
Training loss: 2.4842004294811297
Validation loss: 2.3411641119797855

Epoch: 6| Step: 8
Training loss: 2.5209913178006524
Validation loss: 2.334050653510029

Epoch: 6| Step: 9
Training loss: 2.287360173522204
Validation loss: 2.340442741929221

Epoch: 6| Step: 10
Training loss: 2.3331075513684407
Validation loss: 2.346967421266132

Epoch: 6| Step: 11
Training loss: 2.359604173860481
Validation loss: 2.351466954425998

Epoch: 6| Step: 12
Training loss: 2.6658417697433947
Validation loss: 2.3597533920808105

Epoch: 6| Step: 13
Training loss: 1.7356378579959837
Validation loss: 2.393114621332228

Epoch: 360| Step: 0
Training loss: 2.6613125297686318
Validation loss: 2.4264395346402017

Epoch: 6| Step: 1
Training loss: 2.545691841384959
Validation loss: 2.4859210988746216

Epoch: 6| Step: 2
Training loss: 1.8210705664430162
Validation loss: 2.538924783990092

Epoch: 6| Step: 3
Training loss: 2.19365404141954
Validation loss: 2.598307085784026

Epoch: 6| Step: 4
Training loss: 3.0697316015757616
Validation loss: 2.651920571247479

Epoch: 6| Step: 5
Training loss: 2.021447576657822
Validation loss: 2.61583188928302

Epoch: 6| Step: 6
Training loss: 2.5692025892740857
Validation loss: 2.5129333987554388

Epoch: 6| Step: 7
Training loss: 2.6525880591528077
Validation loss: 2.4867525741072

Epoch: 6| Step: 8
Training loss: 2.087437693870995
Validation loss: 2.4322185055207566

Epoch: 6| Step: 9
Training loss: 2.319457028088981
Validation loss: 2.3744402221972303

Epoch: 6| Step: 10
Training loss: 2.7008226766104366
Validation loss: 2.326656412696803

Epoch: 6| Step: 11
Training loss: 2.5454563800384054
Validation loss: 2.3145286820834357

Epoch: 6| Step: 12
Training loss: 2.191581623859373
Validation loss: 2.3143728488499846

Epoch: 6| Step: 13
Training loss: 1.7401940954408301
Validation loss: 2.325495673622294

Epoch: 361| Step: 0
Training loss: 2.2665213028726936
Validation loss: 2.319454915905213

Epoch: 6| Step: 1
Training loss: 2.253084399827077
Validation loss: 2.3171120359889312

Epoch: 6| Step: 2
Training loss: 2.6988683271595466
Validation loss: 2.320259419291177

Epoch: 6| Step: 3
Training loss: 2.8396650885168495
Validation loss: 2.3738577372893213

Epoch: 6| Step: 4
Training loss: 1.8121107275354
Validation loss: 2.4066253399203053

Epoch: 6| Step: 5
Training loss: 1.9574079626864467
Validation loss: 2.5103251565164735

Epoch: 6| Step: 6
Training loss: 2.572405394954538
Validation loss: 2.5759712776844426

Epoch: 6| Step: 7
Training loss: 2.73150257191056
Validation loss: 2.59725636665672

Epoch: 6| Step: 8
Training loss: 2.285785712250092
Validation loss: 2.5743842318465915

Epoch: 6| Step: 9
Training loss: 2.115281489332748
Validation loss: 2.5378888068977665

Epoch: 6| Step: 10
Training loss: 2.913418696161866
Validation loss: 2.4735969636174557

Epoch: 6| Step: 11
Training loss: 2.0646238085041277
Validation loss: 2.3855548733882057

Epoch: 6| Step: 12
Training loss: 2.4736694381418016
Validation loss: 2.3580050066801435

Epoch: 6| Step: 13
Training loss: 2.860882471160594
Validation loss: 2.330700786447809

Epoch: 362| Step: 0
Training loss: 2.706847697939222
Validation loss: 2.32846871251965

Epoch: 6| Step: 1
Training loss: 2.043199106799642
Validation loss: 2.331682450337395

Epoch: 6| Step: 2
Training loss: 2.071357779867007
Validation loss: 2.323376035212113

Epoch: 6| Step: 3
Training loss: 2.283488599227133
Validation loss: 2.330435362516779

Epoch: 6| Step: 4
Training loss: 2.9194796122005524
Validation loss: 2.3261469798541072

Epoch: 6| Step: 5
Training loss: 2.889413610716532
Validation loss: 2.3399881812783105

Epoch: 6| Step: 6
Training loss: 2.8064200912617654
Validation loss: 2.356125302046737

Epoch: 6| Step: 7
Training loss: 1.7760453732210413
Validation loss: 2.3874183943643486

Epoch: 6| Step: 8
Training loss: 2.30533096899717
Validation loss: 2.455359664391516

Epoch: 6| Step: 9
Training loss: 2.467955545967913
Validation loss: 2.5181015237994897

Epoch: 6| Step: 10
Training loss: 1.864797810698623
Validation loss: 2.5894343488226528

Epoch: 6| Step: 11
Training loss: 2.4427312810561452
Validation loss: 2.6845078176856574

Epoch: 6| Step: 12
Training loss: 2.1412784664936355
Validation loss: 2.6795544894619527

Epoch: 6| Step: 13
Training loss: 2.358015262285817
Validation loss: 2.6687877065141734

Epoch: 363| Step: 0
Training loss: 2.5842243524300725
Validation loss: 2.645582689294565

Epoch: 6| Step: 1
Training loss: 2.433392413828677
Validation loss: 2.541310211905347

Epoch: 6| Step: 2
Training loss: 2.0812331740240455
Validation loss: 2.5363766725157753

Epoch: 6| Step: 3
Training loss: 2.078100448119182
Validation loss: 2.492495368341604

Epoch: 6| Step: 4
Training loss: 2.27704860547927
Validation loss: 2.4621131892166437

Epoch: 6| Step: 5
Training loss: 2.1234059806544767
Validation loss: 2.4277546233454097

Epoch: 6| Step: 6
Training loss: 2.1903980132086294
Validation loss: 2.4196661353743636

Epoch: 6| Step: 7
Training loss: 2.691730186334918
Validation loss: 2.4103561831401294

Epoch: 6| Step: 8
Training loss: 2.3950843856694357
Validation loss: 2.3684587666333847

Epoch: 6| Step: 9
Training loss: 2.6114825115344993
Validation loss: 2.4012487520301975

Epoch: 6| Step: 10
Training loss: 2.556128419255875
Validation loss: 2.4196883318353493

Epoch: 6| Step: 11
Training loss: 2.4865571041703034
Validation loss: 2.4676476599708894

Epoch: 6| Step: 12
Training loss: 2.382164638809426
Validation loss: 2.4333971852403855

Epoch: 6| Step: 13
Training loss: 1.7041177918281627
Validation loss: 2.454494568720711

Epoch: 364| Step: 0
Training loss: 2.124557897915865
Validation loss: 2.456338085958182

Epoch: 6| Step: 1
Training loss: 2.333787828413662
Validation loss: 2.449084460810354

Epoch: 6| Step: 2
Training loss: 2.515842215122324
Validation loss: 2.471376846326803

Epoch: 6| Step: 3
Training loss: 2.61012650135743
Validation loss: 2.514825140270881

Epoch: 6| Step: 4
Training loss: 2.9733908268226705
Validation loss: 2.4488942920750842

Epoch: 6| Step: 5
Training loss: 2.328457597362435
Validation loss: 2.3968366458002506

Epoch: 6| Step: 6
Training loss: 2.173671939582359
Validation loss: 2.3485853865327098

Epoch: 6| Step: 7
Training loss: 2.3558163109690518
Validation loss: 2.296288463469494

Epoch: 6| Step: 8
Training loss: 2.257842172605894
Validation loss: 2.3283379036136984

Epoch: 6| Step: 9
Training loss: 2.337241838856125
Validation loss: 2.3180370170108717

Epoch: 6| Step: 10
Training loss: 2.2447924219352946
Validation loss: 2.3100552150436573

Epoch: 6| Step: 11
Training loss: 2.15931307183551
Validation loss: 2.3057853907705415

Epoch: 6| Step: 12
Training loss: 2.660728001033439
Validation loss: 2.3212299573653508

Epoch: 6| Step: 13
Training loss: 2.3590964853979566
Validation loss: 2.3411653526463647

Epoch: 365| Step: 0
Training loss: 1.6978307206882173
Validation loss: 2.358611505642653

Epoch: 6| Step: 1
Training loss: 2.4590289753451287
Validation loss: 2.387226930144629

Epoch: 6| Step: 2
Training loss: 2.348097266286501
Validation loss: 2.4661799696370155

Epoch: 6| Step: 3
Training loss: 2.488518480523155
Validation loss: 2.5043027541246277

Epoch: 6| Step: 4
Training loss: 2.476691883449953
Validation loss: 2.5339562358916434

Epoch: 6| Step: 5
Training loss: 2.522085104962234
Validation loss: 2.5650374891977297

Epoch: 6| Step: 6
Training loss: 2.733902111033982
Validation loss: 2.5198238303720153

Epoch: 6| Step: 7
Training loss: 1.9205761994587056
Validation loss: 2.4720994661078954

Epoch: 6| Step: 8
Training loss: 1.638681477642454
Validation loss: 2.4063920755663357

Epoch: 6| Step: 9
Training loss: 2.6911639587567637
Validation loss: 2.3870241763817797

Epoch: 6| Step: 10
Training loss: 2.4422621546565946
Validation loss: 2.363369419287486

Epoch: 6| Step: 11
Training loss: 2.6509000869048145
Validation loss: 2.352369605016461

Epoch: 6| Step: 12
Training loss: 2.638335459939851
Validation loss: 2.3601778497070844

Epoch: 6| Step: 13
Training loss: 2.403848018938955
Validation loss: 2.3675448283579605

Epoch: 366| Step: 0
Training loss: 2.353521500576172
Validation loss: 2.3909247007637013

Epoch: 6| Step: 1
Training loss: 1.9971611617859586
Validation loss: 2.401579264807539

Epoch: 6| Step: 2
Training loss: 2.3740062642388424
Validation loss: 2.418224800589359

Epoch: 6| Step: 3
Training loss: 2.4806136922465645
Validation loss: 2.413457333540407

Epoch: 6| Step: 4
Training loss: 2.4443579812604694
Validation loss: 2.4294779507494444

Epoch: 6| Step: 5
Training loss: 2.1748851526565933
Validation loss: 2.4208430721900442

Epoch: 6| Step: 6
Training loss: 2.664504207562664
Validation loss: 2.426441664632389

Epoch: 6| Step: 7
Training loss: 2.441528219609525
Validation loss: 2.409514296036421

Epoch: 6| Step: 8
Training loss: 1.8259068913908076
Validation loss: 2.367251865558735

Epoch: 6| Step: 9
Training loss: 2.3976818969587907
Validation loss: 2.3573796142011245

Epoch: 6| Step: 10
Training loss: 2.0830447823650204
Validation loss: 2.3425805251211127

Epoch: 6| Step: 11
Training loss: 2.3148927423994135
Validation loss: 2.3607133870788966

Epoch: 6| Step: 12
Training loss: 2.9622228243287374
Validation loss: 2.403121763300506

Epoch: 6| Step: 13
Training loss: 2.0978751467927643
Validation loss: 2.4679216807623905

Epoch: 367| Step: 0
Training loss: 2.3682355417691943
Validation loss: 2.5340018132265425

Epoch: 6| Step: 1
Training loss: 2.3060633803538413
Validation loss: 2.5553208225572015

Epoch: 6| Step: 2
Training loss: 2.5058803066886886
Validation loss: 2.6134966520502014

Epoch: 6| Step: 3
Training loss: 2.592127188911623
Validation loss: 2.6006092578186637

Epoch: 6| Step: 4
Training loss: 2.5434567969049855
Validation loss: 2.578402806364162

Epoch: 6| Step: 5
Training loss: 2.5249096618203994
Validation loss: 2.5528977146774543

Epoch: 6| Step: 6
Training loss: 2.385487740025612
Validation loss: 2.5069666780933004

Epoch: 6| Step: 7
Training loss: 2.113757631546402
Validation loss: 2.472857728620299

Epoch: 6| Step: 8
Training loss: 2.083975680189219
Validation loss: 2.4182895357026584

Epoch: 6| Step: 9
Training loss: 1.9649265036779255
Validation loss: 2.390259732727159

Epoch: 6| Step: 10
Training loss: 2.2460270880053317
Validation loss: 2.3688979955438394

Epoch: 6| Step: 11
Training loss: 2.542325502482184
Validation loss: 2.3379940372261423

Epoch: 6| Step: 12
Training loss: 2.317579515856337
Validation loss: 2.3525184326645854

Epoch: 6| Step: 13
Training loss: 2.2693768184468626
Validation loss: 2.336415040804384

Epoch: 368| Step: 0
Training loss: 2.5978266839354096
Validation loss: 2.3223133676825465

Epoch: 6| Step: 1
Training loss: 2.453423548712085
Validation loss: 2.3377935575622035

Epoch: 6| Step: 2
Training loss: 2.30372791033383
Validation loss: 2.3266062578688005

Epoch: 6| Step: 3
Training loss: 2.508287996746303
Validation loss: 2.345371518359842

Epoch: 6| Step: 4
Training loss: 2.5942712283075124
Validation loss: 2.34199697147029

Epoch: 6| Step: 5
Training loss: 1.5892272803768024
Validation loss: 2.361151965095689

Epoch: 6| Step: 6
Training loss: 1.8371459230538503
Validation loss: 2.3639010424896574

Epoch: 6| Step: 7
Training loss: 1.7938096146197335
Validation loss: 2.3742302374145874

Epoch: 6| Step: 8
Training loss: 2.869127329359936
Validation loss: 2.3894456655114404

Epoch: 6| Step: 9
Training loss: 2.3941030695118974
Validation loss: 2.418025185152408

Epoch: 6| Step: 10
Training loss: 2.2592789794441073
Validation loss: 2.4371192577971073

Epoch: 6| Step: 11
Training loss: 2.4397005760455186
Validation loss: 2.4759651546204804

Epoch: 6| Step: 12
Training loss: 2.489436625436898
Validation loss: 2.487311608575252

Epoch: 6| Step: 13
Training loss: 2.1961421824149
Validation loss: 2.5184143607771556

Epoch: 369| Step: 0
Training loss: 1.8049818187019853
Validation loss: 2.55135129400049

Epoch: 6| Step: 1
Training loss: 2.269322817451208
Validation loss: 2.596794588137179

Epoch: 6| Step: 2
Training loss: 2.907056142920329
Validation loss: 2.5936378665292437

Epoch: 6| Step: 3
Training loss: 2.4770033771859943
Validation loss: 2.5456918091593383

Epoch: 6| Step: 4
Training loss: 2.2703049304518297
Validation loss: 2.5290042258277174

Epoch: 6| Step: 5
Training loss: 2.087818454961759
Validation loss: 2.4636142052901526

Epoch: 6| Step: 6
Training loss: 2.353255666724547
Validation loss: 2.395445563210762

Epoch: 6| Step: 7
Training loss: 2.3081302080630213
Validation loss: 2.3630980094232727

Epoch: 6| Step: 8
Training loss: 2.964136655017636
Validation loss: 2.3431175291898736

Epoch: 6| Step: 9
Training loss: 2.1940855894407365
Validation loss: 2.3256900428468517

Epoch: 6| Step: 10
Training loss: 2.2238281593074825
Validation loss: 2.328006518660102

Epoch: 6| Step: 11
Training loss: 2.0008104589580147
Validation loss: 2.3647193903880557

Epoch: 6| Step: 12
Training loss: 2.2200423224599084
Validation loss: 2.3732496935112692

Epoch: 6| Step: 13
Training loss: 2.7014499832824064
Validation loss: 2.3822627449587443

Epoch: 370| Step: 0
Training loss: 2.562175823268345
Validation loss: 2.437104308996925

Epoch: 6| Step: 1
Training loss: 2.159894654919337
Validation loss: 2.4733762685663776

Epoch: 6| Step: 2
Training loss: 2.150020501682207
Validation loss: 2.501399311052624

Epoch: 6| Step: 3
Training loss: 2.2298529688513797
Validation loss: 2.5566338870933185

Epoch: 6| Step: 4
Training loss: 2.1104550457621944
Validation loss: 2.581033712888525

Epoch: 6| Step: 5
Training loss: 2.8245954882228044
Validation loss: 2.599422663821438

Epoch: 6| Step: 6
Training loss: 1.8545263848709777
Validation loss: 2.546472887739828

Epoch: 6| Step: 7
Training loss: 2.48401240935735
Validation loss: 2.5471265124977593

Epoch: 6| Step: 8
Training loss: 2.8748460811379757
Validation loss: 2.5223496982532514

Epoch: 6| Step: 9
Training loss: 2.491079628301467
Validation loss: 2.4452426951152852

Epoch: 6| Step: 10
Training loss: 2.1255003396202
Validation loss: 2.3605265972602614

Epoch: 6| Step: 11
Training loss: 2.2664947944815284
Validation loss: 2.3231911258210185

Epoch: 6| Step: 12
Training loss: 2.3941967778802473
Validation loss: 2.323254343353363

Epoch: 6| Step: 13
Training loss: 1.9048735855490797
Validation loss: 2.322897974777193

Epoch: 371| Step: 0
Training loss: 2.905162648885513
Validation loss: 2.306934218353874

Epoch: 6| Step: 1
Training loss: 2.3622550312577677
Validation loss: 2.3116859570806394

Epoch: 6| Step: 2
Training loss: 2.0543597870191785
Validation loss: 2.3196563594012014

Epoch: 6| Step: 3
Training loss: 1.9486338745126528
Validation loss: 2.3381916205029114

Epoch: 6| Step: 4
Training loss: 2.3127178398834745
Validation loss: 2.3534154841473733

Epoch: 6| Step: 5
Training loss: 2.0467003900729717
Validation loss: 2.426345383102665

Epoch: 6| Step: 6
Training loss: 2.191603925360492
Validation loss: 2.475290403609357

Epoch: 6| Step: 7
Training loss: 2.69400957100463
Validation loss: 2.58106109596121

Epoch: 6| Step: 8
Training loss: 2.691597764242476
Validation loss: 2.6447559579370323

Epoch: 6| Step: 9
Training loss: 2.406510772446363
Validation loss: 2.6592200760249547

Epoch: 6| Step: 10
Training loss: 2.328461590699751
Validation loss: 2.6742875397908583

Epoch: 6| Step: 11
Training loss: 2.2964117919539384
Validation loss: 2.607167871723779

Epoch: 6| Step: 12
Training loss: 3.059596651209244
Validation loss: 2.5091090412869357

Epoch: 6| Step: 13
Training loss: 2.397054665010191
Validation loss: 2.3881575764811123

Epoch: 372| Step: 0
Training loss: 2.063050167803257
Validation loss: 2.3270228903830845

Epoch: 6| Step: 1
Training loss: 2.0571418289151726
Validation loss: 2.3057407492648747

Epoch: 6| Step: 2
Training loss: 2.811539040747776
Validation loss: 2.3395245270776055

Epoch: 6| Step: 3
Training loss: 2.7682375018095104
Validation loss: 2.3376150001049187

Epoch: 6| Step: 4
Training loss: 2.4479040483731187
Validation loss: 2.323926891306281

Epoch: 6| Step: 5
Training loss: 2.497868964784657
Validation loss: 2.3559064985361813

Epoch: 6| Step: 6
Training loss: 2.105744239463205
Validation loss: 2.3451885225079994

Epoch: 6| Step: 7
Training loss: 2.764608077681383
Validation loss: 2.3199933328601694

Epoch: 6| Step: 8
Training loss: 2.175950651576948
Validation loss: 2.3237670757372797

Epoch: 6| Step: 9
Training loss: 2.5612829155805925
Validation loss: 2.324812170683423

Epoch: 6| Step: 10
Training loss: 2.599383934099199
Validation loss: 2.3817761972263725

Epoch: 6| Step: 11
Training loss: 2.827194650960805
Validation loss: 2.4348764480750065

Epoch: 6| Step: 12
Training loss: 1.8966601179352902
Validation loss: 2.4880459391303544

Epoch: 6| Step: 13
Training loss: 2.7860465532782634
Validation loss: 2.5606805548373526

Epoch: 373| Step: 0
Training loss: 2.269661720714576
Validation loss: 2.637349988941035

Epoch: 6| Step: 1
Training loss: 2.5407220200222853
Validation loss: 2.6949282221990076

Epoch: 6| Step: 2
Training loss: 2.7304557396138085
Validation loss: 2.683577920610542

Epoch: 6| Step: 3
Training loss: 1.9250727156739624
Validation loss: 2.690949230027503

Epoch: 6| Step: 4
Training loss: 2.8086533414118806
Validation loss: 2.6306870612802586

Epoch: 6| Step: 5
Training loss: 2.7757101713915318
Validation loss: 2.550579684008031

Epoch: 6| Step: 6
Training loss: 2.131674885837118
Validation loss: 2.469915003759524

Epoch: 6| Step: 7
Training loss: 1.8067014611801038
Validation loss: 2.3925826124258447

Epoch: 6| Step: 8
Training loss: 2.3194208454852863
Validation loss: 2.3433881889189965

Epoch: 6| Step: 9
Training loss: 2.437212609197072
Validation loss: 2.3162748462106824

Epoch: 6| Step: 10
Training loss: 2.5896080680846403
Validation loss: 2.3156420373574247

Epoch: 6| Step: 11
Training loss: 2.23189604566357
Validation loss: 2.3329769421220794

Epoch: 6| Step: 12
Training loss: 2.412175400791694
Validation loss: 2.3287504976950943

Epoch: 6| Step: 13
Training loss: 2.7713073286803755
Validation loss: 2.3395103375776127

Epoch: 374| Step: 0
Training loss: 2.2757912737399404
Validation loss: 2.345234500453452

Epoch: 6| Step: 1
Training loss: 2.1889103294049717
Validation loss: 2.3652137540094467

Epoch: 6| Step: 2
Training loss: 1.8423057977615498
Validation loss: 2.4073383579820167

Epoch: 6| Step: 3
Training loss: 2.9636939109665814
Validation loss: 2.446773917041562

Epoch: 6| Step: 4
Training loss: 1.951410929991692
Validation loss: 2.470566562683801

Epoch: 6| Step: 5
Training loss: 2.4307369406699584
Validation loss: 2.5012688124214373

Epoch: 6| Step: 6
Training loss: 2.8675194322082276
Validation loss: 2.5374399498239817

Epoch: 6| Step: 7
Training loss: 2.5009340448723867
Validation loss: 2.588025784932227

Epoch: 6| Step: 8
Training loss: 2.3049991720202234
Validation loss: 2.5876309422389525

Epoch: 6| Step: 9
Training loss: 2.4198826624269514
Validation loss: 2.57197682236643

Epoch: 6| Step: 10
Training loss: 1.9490101307018
Validation loss: 2.533062186799346

Epoch: 6| Step: 11
Training loss: 2.3282834197555804
Validation loss: 2.5112818746589136

Epoch: 6| Step: 12
Training loss: 2.0781331456533847
Validation loss: 2.442656317440268

Epoch: 6| Step: 13
Training loss: 2.123185336625922
Validation loss: 2.390439296466444

Epoch: 375| Step: 0
Training loss: 2.3105013690507734
Validation loss: 2.363551841600447

Epoch: 6| Step: 1
Training loss: 2.5251349535843577
Validation loss: 2.358836052082876

Epoch: 6| Step: 2
Training loss: 2.3694552898966235
Validation loss: 2.34691757269057

Epoch: 6| Step: 3
Training loss: 2.2844024197332664
Validation loss: 2.3628322265935484

Epoch: 6| Step: 4
Training loss: 2.4034406437330627
Validation loss: 2.3616208413178774

Epoch: 6| Step: 5
Training loss: 1.8536456015289182
Validation loss: 2.3601026352223813

Epoch: 6| Step: 6
Training loss: 1.9923896238227239
Validation loss: 2.386219289601352

Epoch: 6| Step: 7
Training loss: 2.6937509629674903
Validation loss: 2.4206301535490704

Epoch: 6| Step: 8
Training loss: 2.158158715252928
Validation loss: 2.429960216227101

Epoch: 6| Step: 9
Training loss: 2.6184918697479347
Validation loss: 2.4714399547830777

Epoch: 6| Step: 10
Training loss: 2.356901577577375
Validation loss: 2.4962133566086293

Epoch: 6| Step: 11
Training loss: 2.288030502422791
Validation loss: 2.512541658442539

Epoch: 6| Step: 12
Training loss: 2.288884595395766
Validation loss: 2.4336707382601026

Epoch: 6| Step: 13
Training loss: 2.249686537206025
Validation loss: 2.433616247122353

Epoch: 376| Step: 0
Training loss: 1.8690783132532485
Validation loss: 2.4477197500255876

Epoch: 6| Step: 1
Training loss: 2.5883635696967118
Validation loss: 2.4646657781933894

Epoch: 6| Step: 2
Training loss: 2.2298473020200125
Validation loss: 2.467192783207311

Epoch: 6| Step: 3
Training loss: 2.5652166713047353
Validation loss: 2.4657192087092317

Epoch: 6| Step: 4
Training loss: 2.2796387926719732
Validation loss: 2.4303916815748328

Epoch: 6| Step: 5
Training loss: 2.2500900674382955
Validation loss: 2.4603740390204045

Epoch: 6| Step: 6
Training loss: 2.050731956252812
Validation loss: 2.448721231177265

Epoch: 6| Step: 7
Training loss: 2.206725837033301
Validation loss: 2.4560273584617263

Epoch: 6| Step: 8
Training loss: 2.72787243000562
Validation loss: 2.426152281302536

Epoch: 6| Step: 9
Training loss: 2.3784628268487134
Validation loss: 2.3961296579550537

Epoch: 6| Step: 10
Training loss: 2.393268295704305
Validation loss: 2.3722334520575394

Epoch: 6| Step: 11
Training loss: 1.7368418016311769
Validation loss: 2.3562049151369298

Epoch: 6| Step: 12
Training loss: 1.966725655926449
Validation loss: 2.3309114041318124

Epoch: 6| Step: 13
Training loss: 2.8865575267901296
Validation loss: 2.358361487019638

Epoch: 377| Step: 0
Training loss: 2.736232627928522
Validation loss: 2.362307268172228

Epoch: 6| Step: 1
Training loss: 2.3011198717547443
Validation loss: 2.349665131335825

Epoch: 6| Step: 2
Training loss: 2.2503187165759155
Validation loss: 2.3703029949518886

Epoch: 6| Step: 3
Training loss: 2.5548581874183554
Validation loss: 2.3773730899751464

Epoch: 6| Step: 4
Training loss: 2.1763206374937947
Validation loss: 2.395588656785891

Epoch: 6| Step: 5
Training loss: 2.090391055304993
Validation loss: 2.4248866234981947

Epoch: 6| Step: 6
Training loss: 2.1815958180688573
Validation loss: 2.425328226714608

Epoch: 6| Step: 7
Training loss: 2.015525519703224
Validation loss: 2.461625791553814

Epoch: 6| Step: 8
Training loss: 2.3501939815243884
Validation loss: 2.4889622488215175

Epoch: 6| Step: 9
Training loss: 2.1830082144134906
Validation loss: 2.5131213687962375

Epoch: 6| Step: 10
Training loss: 2.4640327485682585
Validation loss: 2.5276045005330565

Epoch: 6| Step: 11
Training loss: 2.4095339474033075
Validation loss: 2.5160928142300536

Epoch: 6| Step: 12
Training loss: 2.372332932566218
Validation loss: 2.477756205185173

Epoch: 6| Step: 13
Training loss: 2.034388538321408
Validation loss: 2.4422841111161118

Epoch: 378| Step: 0
Training loss: 2.645498529912886
Validation loss: 2.38709586683781

Epoch: 6| Step: 1
Training loss: 2.7271537249062474
Validation loss: 2.3754893847376333

Epoch: 6| Step: 2
Training loss: 1.5122257929898446
Validation loss: 2.374657123665903

Epoch: 6| Step: 3
Training loss: 1.8262942023283795
Validation loss: 2.340127309032546

Epoch: 6| Step: 4
Training loss: 2.25097359679848
Validation loss: 2.3420164307824924

Epoch: 6| Step: 5
Training loss: 2.353767248608094
Validation loss: 2.375750271520617

Epoch: 6| Step: 6
Training loss: 2.6166675563575867
Validation loss: 2.3528930804708903

Epoch: 6| Step: 7
Training loss: 2.5185283705366994
Validation loss: 2.377159669508558

Epoch: 6| Step: 8
Training loss: 2.7225578213691333
Validation loss: 2.3456244145412946

Epoch: 6| Step: 9
Training loss: 2.3396389319136564
Validation loss: 2.374138644052524

Epoch: 6| Step: 10
Training loss: 2.7750746502157413
Validation loss: 2.381840788512782

Epoch: 6| Step: 11
Training loss: 1.904019160438747
Validation loss: 2.4260292522897737

Epoch: 6| Step: 12
Training loss: 1.6316724383700532
Validation loss: 2.4694047077633265

Epoch: 6| Step: 13
Training loss: 1.2351083629187585
Validation loss: 2.536207881894296

Epoch: 379| Step: 0
Training loss: 2.0273905548396507
Validation loss: 2.5976031203985186

Epoch: 6| Step: 1
Training loss: 2.7443510470369055
Validation loss: 2.6222424543193017

Epoch: 6| Step: 2
Training loss: 1.7206558065154225
Validation loss: 2.604708178588382

Epoch: 6| Step: 3
Training loss: 2.3988154110480737
Validation loss: 2.580038145030863

Epoch: 6| Step: 4
Training loss: 2.8207637182874317
Validation loss: 2.5448649366246365

Epoch: 6| Step: 5
Training loss: 2.758427278545764
Validation loss: 2.4649263582014562

Epoch: 6| Step: 6
Training loss: 2.3060416688355314
Validation loss: 2.365910252691727

Epoch: 6| Step: 7
Training loss: 2.578316513808892
Validation loss: 2.31395612622588

Epoch: 6| Step: 8
Training loss: 2.7000596852240086
Validation loss: 2.307930619939868

Epoch: 6| Step: 9
Training loss: 2.450550064307151
Validation loss: 2.2947012832597062

Epoch: 6| Step: 10
Training loss: 2.5186656322500682
Validation loss: 2.326931507872739

Epoch: 6| Step: 11
Training loss: 2.011454563015513
Validation loss: 2.303333370898571

Epoch: 6| Step: 12
Training loss: 1.667384239536661
Validation loss: 2.32449582658607

Epoch: 6| Step: 13
Training loss: 1.3743466645737707
Validation loss: 2.343514537947228

Epoch: 380| Step: 0
Training loss: 2.092972340568262
Validation loss: 2.367407154857611

Epoch: 6| Step: 1
Training loss: 1.8719013677150544
Validation loss: 2.3987059340605845

Epoch: 6| Step: 2
Training loss: 1.8228983705601554
Validation loss: 2.494671299604159

Epoch: 6| Step: 3
Training loss: 1.7329605796015328
Validation loss: 2.5314656799626176

Epoch: 6| Step: 4
Training loss: 2.4659678560437515
Validation loss: 2.5739304095374584

Epoch: 6| Step: 5
Training loss: 2.2614924131473226
Validation loss: 2.592553901867905

Epoch: 6| Step: 6
Training loss: 2.235456191747758
Validation loss: 2.5950224821888854

Epoch: 6| Step: 7
Training loss: 2.6890285492016686
Validation loss: 2.589221034183485

Epoch: 6| Step: 8
Training loss: 2.374577836111033
Validation loss: 2.550225213585479

Epoch: 6| Step: 9
Training loss: 2.0734397445471084
Validation loss: 2.4607940397623085

Epoch: 6| Step: 10
Training loss: 2.559513398505209
Validation loss: 2.412517798496947

Epoch: 6| Step: 11
Training loss: 2.6663687559454123
Validation loss: 2.3654068385654177

Epoch: 6| Step: 12
Training loss: 2.9518009830574794
Validation loss: 2.3150342985670735

Epoch: 6| Step: 13
Training loss: 1.9422349600237234
Validation loss: 2.3106808867172863

Epoch: 381| Step: 0
Training loss: 2.0655739736097813
Validation loss: 2.3055310006688754

Epoch: 6| Step: 1
Training loss: 2.3340860129216647
Validation loss: 2.294850467084971

Epoch: 6| Step: 2
Training loss: 2.2420868003642123
Validation loss: 2.3062201196674765

Epoch: 6| Step: 3
Training loss: 1.8524729104062663
Validation loss: 2.3140791966552987

Epoch: 6| Step: 4
Training loss: 2.395943901717188
Validation loss: 2.3063640922086197

Epoch: 6| Step: 5
Training loss: 2.250618743591172
Validation loss: 2.3226284858346604

Epoch: 6| Step: 6
Training loss: 2.4288269677877685
Validation loss: 2.378130605166925

Epoch: 6| Step: 7
Training loss: 2.251785417649442
Validation loss: 2.439029015781612

Epoch: 6| Step: 8
Training loss: 2.209155547426901
Validation loss: 2.508533397552579

Epoch: 6| Step: 9
Training loss: 2.442453779175652
Validation loss: 2.5142586621056178

Epoch: 6| Step: 10
Training loss: 2.7890588242108567
Validation loss: 2.5620018829815634

Epoch: 6| Step: 11
Training loss: 2.522184551011839
Validation loss: 2.5218126704381927

Epoch: 6| Step: 12
Training loss: 2.2544431261852895
Validation loss: 2.458523978767772

Epoch: 6| Step: 13
Training loss: 2.5505193368477483
Validation loss: 2.4547543151726705

Epoch: 382| Step: 0
Training loss: 2.4401309168980183
Validation loss: 2.4232339503151925

Epoch: 6| Step: 1
Training loss: 2.377227240799801
Validation loss: 2.3823039711342555

Epoch: 6| Step: 2
Training loss: 2.7140926062935122
Validation loss: 2.3597033899022977

Epoch: 6| Step: 3
Training loss: 1.9033270767741526
Validation loss: 2.330631397089719

Epoch: 6| Step: 4
Training loss: 2.02565428913037
Validation loss: 2.3421833066012008

Epoch: 6| Step: 5
Training loss: 2.4870000442241054
Validation loss: 2.337156777010887

Epoch: 6| Step: 6
Training loss: 2.1110114637359065
Validation loss: 2.3268689003563123

Epoch: 6| Step: 7
Training loss: 1.9811348481514475
Validation loss: 2.3652795736313967

Epoch: 6| Step: 8
Training loss: 2.2635968831948357
Validation loss: 2.363061900524489

Epoch: 6| Step: 9
Training loss: 2.552082004676525
Validation loss: 2.3887153353021042

Epoch: 6| Step: 10
Training loss: 2.2549456178320315
Validation loss: 2.446826999312772

Epoch: 6| Step: 11
Training loss: 1.8749886830306257
Validation loss: 2.569282648331663

Epoch: 6| Step: 12
Training loss: 2.481550230220009
Validation loss: 2.6124157047228946

Epoch: 6| Step: 13
Training loss: 2.9807642319024437
Validation loss: 2.616193959594611

Epoch: 383| Step: 0
Training loss: 2.1862488574662446
Validation loss: 2.551557011897912

Epoch: 6| Step: 1
Training loss: 1.6425698514859264
Validation loss: 2.4839671450201037

Epoch: 6| Step: 2
Training loss: 3.000730902327157
Validation loss: 2.420742647456537

Epoch: 6| Step: 3
Training loss: 2.623325086028898
Validation loss: 2.370427932073818

Epoch: 6| Step: 4
Training loss: 2.4331176684014593
Validation loss: 2.299016124619105

Epoch: 6| Step: 5
Training loss: 1.9891111069798602
Validation loss: 2.2916416856703714

Epoch: 6| Step: 6
Training loss: 2.1307162648508715
Validation loss: 2.306695810661783

Epoch: 6| Step: 7
Training loss: 2.269513811316931
Validation loss: 2.302185217999327

Epoch: 6| Step: 8
Training loss: 2.8859708692173576
Validation loss: 2.2833989285372756

Epoch: 6| Step: 9
Training loss: 2.0372196215224117
Validation loss: 2.316218584941143

Epoch: 6| Step: 10
Training loss: 1.393873385454703
Validation loss: 2.3424097594877775

Epoch: 6| Step: 11
Training loss: 2.4908199564256686
Validation loss: 2.4242172669868927

Epoch: 6| Step: 12
Training loss: 2.5733446596650746
Validation loss: 2.463130708957781

Epoch: 6| Step: 13
Training loss: 2.2646375937981547
Validation loss: 2.5340384333382895

Epoch: 384| Step: 0
Training loss: 2.1769331617139898
Validation loss: 2.590192013226776

Epoch: 6| Step: 1
Training loss: 2.0698579109187234
Validation loss: 2.6026468965530682

Epoch: 6| Step: 2
Training loss: 2.5071324647494757
Validation loss: 2.6128330906836608

Epoch: 6| Step: 3
Training loss: 2.09290991483654
Validation loss: 2.6549855320064704

Epoch: 6| Step: 4
Training loss: 2.684746862373966
Validation loss: 2.6204181105566784

Epoch: 6| Step: 5
Training loss: 2.307574516738099
Validation loss: 2.5236456233523907

Epoch: 6| Step: 6
Training loss: 1.8203851251481027
Validation loss: 2.4400306303861026

Epoch: 6| Step: 7
Training loss: 2.500661190336464
Validation loss: 2.364272552864598

Epoch: 6| Step: 8
Training loss: 2.401155304995088
Validation loss: 2.3281361283072615

Epoch: 6| Step: 9
Training loss: 2.1880213524928966
Validation loss: 2.2887365326155007

Epoch: 6| Step: 10
Training loss: 2.4724794056404025
Validation loss: 2.2960244878856026

Epoch: 6| Step: 11
Training loss: 2.7699229147751363
Validation loss: 2.314704848308346

Epoch: 6| Step: 12
Training loss: 2.2242035801286115
Validation loss: 2.347948377861902

Epoch: 6| Step: 13
Training loss: 2.409911602345992
Validation loss: 2.376221340064631

Epoch: 385| Step: 0
Training loss: 2.3806334490837693
Validation loss: 2.431606775911332

Epoch: 6| Step: 1
Training loss: 2.2349025930389708
Validation loss: 2.454463050656871

Epoch: 6| Step: 2
Training loss: 2.6882366678919616
Validation loss: 2.5064869877850007

Epoch: 6| Step: 3
Training loss: 2.130080041232175
Validation loss: 2.5216232092172497

Epoch: 6| Step: 4
Training loss: 2.869945561228307
Validation loss: 2.5430963880303175

Epoch: 6| Step: 5
Training loss: 2.578605745749144
Validation loss: 2.4679994097608717

Epoch: 6| Step: 6
Training loss: 2.374073952279055
Validation loss: 2.422880178884351

Epoch: 6| Step: 7
Training loss: 2.2686702913936716
Validation loss: 2.4035039072419795

Epoch: 6| Step: 8
Training loss: 1.725283325810949
Validation loss: 2.373961732831322

Epoch: 6| Step: 9
Training loss: 2.2917535476399107
Validation loss: 2.352073573832467

Epoch: 6| Step: 10
Training loss: 2.387053071376937
Validation loss: 2.3331915692217704

Epoch: 6| Step: 11
Training loss: 2.001662874347907
Validation loss: 2.3326039554990707

Epoch: 6| Step: 12
Training loss: 2.2805479876875006
Validation loss: 2.34775805440708

Epoch: 6| Step: 13
Training loss: 2.3948693589037005
Validation loss: 2.362644159515691

Epoch: 386| Step: 0
Training loss: 1.7597181375173954
Validation loss: 2.4006531477376414

Epoch: 6| Step: 1
Training loss: 2.2487084602560854
Validation loss: 2.4300041286538594

Epoch: 6| Step: 2
Training loss: 2.4659721101172205
Validation loss: 2.4499589941307014

Epoch: 6| Step: 3
Training loss: 2.141569277358676
Validation loss: 2.4762290812186047

Epoch: 6| Step: 4
Training loss: 2.235703720144415
Validation loss: 2.4649733460621506

Epoch: 6| Step: 5
Training loss: 2.3102913696693226
Validation loss: 2.5052643815442646

Epoch: 6| Step: 6
Training loss: 2.049139153770405
Validation loss: 2.5212555510284593

Epoch: 6| Step: 7
Training loss: 1.9244290260593457
Validation loss: 2.4953777066693763

Epoch: 6| Step: 8
Training loss: 1.9530568225405383
Validation loss: 2.520311778770384

Epoch: 6| Step: 9
Training loss: 2.840098961193958
Validation loss: 2.476981092486201

Epoch: 6| Step: 10
Training loss: 2.703327678513012
Validation loss: 2.4376682268667538

Epoch: 6| Step: 11
Training loss: 2.406018629964364
Validation loss: 2.3852694535351997

Epoch: 6| Step: 12
Training loss: 2.505948238328388
Validation loss: 2.364217481507928

Epoch: 6| Step: 13
Training loss: 2.133893867205917
Validation loss: 2.34517024279813

Epoch: 387| Step: 0
Training loss: 1.8424960252571452
Validation loss: 2.3360885640960802

Epoch: 6| Step: 1
Training loss: 2.7750277406147927
Validation loss: 2.3647584238224884

Epoch: 6| Step: 2
Training loss: 2.3301491354828148
Validation loss: 2.3531456117057257

Epoch: 6| Step: 3
Training loss: 2.2294771091186893
Validation loss: 2.4042819769654407

Epoch: 6| Step: 4
Training loss: 2.4793862210888395
Validation loss: 2.4126115014345584

Epoch: 6| Step: 5
Training loss: 2.5830321802962115
Validation loss: 2.448574695276778

Epoch: 6| Step: 6
Training loss: 1.7729734914468662
Validation loss: 2.430740388404328

Epoch: 6| Step: 7
Training loss: 1.7500914141076043
Validation loss: 2.427910474513878

Epoch: 6| Step: 8
Training loss: 1.8995751006203279
Validation loss: 2.398250732760479

Epoch: 6| Step: 9
Training loss: 2.2270883039722933
Validation loss: 2.3831397364612292

Epoch: 6| Step: 10
Training loss: 2.615139014376513
Validation loss: 2.347489349338627

Epoch: 6| Step: 11
Training loss: 2.197935010884706
Validation loss: 2.363317948912977

Epoch: 6| Step: 12
Training loss: 2.521317007359273
Validation loss: 2.3689312180178126

Epoch: 6| Step: 13
Training loss: 2.5051083825700737
Validation loss: 2.3486285903964688

Epoch: 388| Step: 0
Training loss: 2.357020434796357
Validation loss: 2.391418709181301

Epoch: 6| Step: 1
Training loss: 2.5064895325158107
Validation loss: 2.4329784305874553

Epoch: 6| Step: 2
Training loss: 2.3149947035792757
Validation loss: 2.441413720166663

Epoch: 6| Step: 3
Training loss: 2.3830505252209018
Validation loss: 2.4823537178042283

Epoch: 6| Step: 4
Training loss: 2.1884109780026644
Validation loss: 2.5292289866360056

Epoch: 6| Step: 5
Training loss: 2.00993585190017
Validation loss: 2.553051449291916

Epoch: 6| Step: 6
Training loss: 2.9259357487996067
Validation loss: 2.5770040213598304

Epoch: 6| Step: 7
Training loss: 2.4233527812500966
Validation loss: 2.597281706265929

Epoch: 6| Step: 8
Training loss: 2.161253279798765
Validation loss: 2.516946371046487

Epoch: 6| Step: 9
Training loss: 2.0826460912781397
Validation loss: 2.4497410645351687

Epoch: 6| Step: 10
Training loss: 1.9689738433983675
Validation loss: 2.3830145917108023

Epoch: 6| Step: 11
Training loss: 2.109511533486392
Validation loss: 2.3413981286077887

Epoch: 6| Step: 12
Training loss: 2.057005760188515
Validation loss: 2.322566060350285

Epoch: 6| Step: 13
Training loss: 2.3542577562742135
Validation loss: 2.316001055515236

Epoch: 389| Step: 0
Training loss: 2.1059390871489465
Validation loss: 2.3243363666840255

Epoch: 6| Step: 1
Training loss: 1.9211147634528993
Validation loss: 2.333534746955165

Epoch: 6| Step: 2
Training loss: 2.4614376468141645
Validation loss: 2.3607964262752743

Epoch: 6| Step: 3
Training loss: 2.1622532742383225
Validation loss: 2.4247879637582392

Epoch: 6| Step: 4
Training loss: 2.5032207723100086
Validation loss: 2.4484264669401345

Epoch: 6| Step: 5
Training loss: 2.032565937732217
Validation loss: 2.4369769401540036

Epoch: 6| Step: 6
Training loss: 2.3180372597676033
Validation loss: 2.450230001301966

Epoch: 6| Step: 7
Training loss: 2.918513358282457
Validation loss: 2.4176425519319

Epoch: 6| Step: 8
Training loss: 1.5269438471284154
Validation loss: 2.463369560217872

Epoch: 6| Step: 9
Training loss: 2.1095474737792506
Validation loss: 2.438459019964561

Epoch: 6| Step: 10
Training loss: 2.1758861139802246
Validation loss: 2.4557925366531776

Epoch: 6| Step: 11
Training loss: 2.409105761336646
Validation loss: 2.4843488843941772

Epoch: 6| Step: 12
Training loss: 2.243618073476711
Validation loss: 2.4729873411453873

Epoch: 6| Step: 13
Training loss: 2.6953066618482966
Validation loss: 2.478020779010817

Epoch: 390| Step: 0
Training loss: 2.4610717736806293
Validation loss: 2.5025284747711907

Epoch: 6| Step: 1
Training loss: 2.616078247031668
Validation loss: 2.460394092730049

Epoch: 6| Step: 2
Training loss: 2.526599237839013
Validation loss: 2.442952289744448

Epoch: 6| Step: 3
Training loss: 2.083266702222231
Validation loss: 2.395784456914601

Epoch: 6| Step: 4
Training loss: 2.2717927311794845
Validation loss: 2.3751685568985708

Epoch: 6| Step: 5
Training loss: 2.045150379723602
Validation loss: 2.3498947121277536

Epoch: 6| Step: 6
Training loss: 1.8930852346440827
Validation loss: 2.3566969170154533

Epoch: 6| Step: 7
Training loss: 2.33422339584161
Validation loss: 2.3256393160091404

Epoch: 6| Step: 8
Training loss: 2.0079004884432092
Validation loss: 2.3543958464360486

Epoch: 6| Step: 9
Training loss: 1.918938603280256
Validation loss: 2.360826809089728

Epoch: 6| Step: 10
Training loss: 2.183688084947974
Validation loss: 2.3527958964877067

Epoch: 6| Step: 11
Training loss: 2.2982136465015213
Validation loss: 2.372938054969628

Epoch: 6| Step: 12
Training loss: 2.2300633798667375
Validation loss: 2.3857057615382415

Epoch: 6| Step: 13
Training loss: 2.770976089203672
Validation loss: 2.4050291874818934

Epoch: 391| Step: 0
Training loss: 2.2136627762518146
Validation loss: 2.4286384735485345

Epoch: 6| Step: 1
Training loss: 1.8070978359384875
Validation loss: 2.4309060015105177

Epoch: 6| Step: 2
Training loss: 1.830924214101502
Validation loss: 2.419199543005692

Epoch: 6| Step: 3
Training loss: 2.4020166189871843
Validation loss: 2.439943040609605

Epoch: 6| Step: 4
Training loss: 2.2903858304551776
Validation loss: 2.394799235537059

Epoch: 6| Step: 5
Training loss: 2.577192103054672
Validation loss: 2.4003401097424373

Epoch: 6| Step: 6
Training loss: 2.031738222576453
Validation loss: 2.4038499599202634

Epoch: 6| Step: 7
Training loss: 2.467354488700924
Validation loss: 2.4179671511491643

Epoch: 6| Step: 8
Training loss: 2.0958873031472605
Validation loss: 2.417689456706864

Epoch: 6| Step: 9
Training loss: 2.2544471448708023
Validation loss: 2.4694155440681884

Epoch: 6| Step: 10
Training loss: 2.5848098555088614
Validation loss: 2.473355983251417

Epoch: 6| Step: 11
Training loss: 2.4378261836978057
Validation loss: 2.467065400730404

Epoch: 6| Step: 12
Training loss: 1.761874037705477
Validation loss: 2.4900686534387293

Epoch: 6| Step: 13
Training loss: 2.3125886642366935
Validation loss: 2.4527557065818306

Epoch: 392| Step: 0
Training loss: 2.101554558607788
Validation loss: 2.4378910145478128

Epoch: 6| Step: 1
Training loss: 2.644580294043012
Validation loss: 2.4531161003298836

Epoch: 6| Step: 2
Training loss: 2.404368271685657
Validation loss: 2.400285610642392

Epoch: 6| Step: 3
Training loss: 1.8466848517577181
Validation loss: 2.398999383676416

Epoch: 6| Step: 4
Training loss: 2.394324637580145
Validation loss: 2.402414037311691

Epoch: 6| Step: 5
Training loss: 1.9717263022094584
Validation loss: 2.420195309256091

Epoch: 6| Step: 6
Training loss: 2.4714443135409874
Validation loss: 2.4140599746550184

Epoch: 6| Step: 7
Training loss: 2.551441335049652
Validation loss: 2.408817064597639

Epoch: 6| Step: 8
Training loss: 1.804370802797484
Validation loss: 2.3804285441181996

Epoch: 6| Step: 9
Training loss: 2.5889618581803773
Validation loss: 2.353049255275474

Epoch: 6| Step: 10
Training loss: 1.9250526520105093
Validation loss: 2.3720131114636147

Epoch: 6| Step: 11
Training loss: 1.7409623290033909
Validation loss: 2.38432599514884

Epoch: 6| Step: 12
Training loss: 2.526682748097531
Validation loss: 2.3566932630557487

Epoch: 6| Step: 13
Training loss: 1.7824291542601813
Validation loss: 2.3607284873063206

Epoch: 393| Step: 0
Training loss: 2.6141060523984168
Validation loss: 2.3881265462516263

Epoch: 6| Step: 1
Training loss: 2.4520196064263176
Validation loss: 2.371007716882914

Epoch: 6| Step: 2
Training loss: 2.2989988304158437
Validation loss: 2.4034370021720433

Epoch: 6| Step: 3
Training loss: 2.425411472608803
Validation loss: 2.41267924122444

Epoch: 6| Step: 4
Training loss: 2.3305741299401923
Validation loss: 2.438136417088705

Epoch: 6| Step: 5
Training loss: 2.335462234783011
Validation loss: 2.438734676342607

Epoch: 6| Step: 6
Training loss: 1.8952500700201482
Validation loss: 2.5211679624155185

Epoch: 6| Step: 7
Training loss: 2.526169187073334
Validation loss: 2.543752373977992

Epoch: 6| Step: 8
Training loss: 1.9045297333591364
Validation loss: 2.4795711273925125

Epoch: 6| Step: 9
Training loss: 2.220381660646004
Validation loss: 2.3973401221923227

Epoch: 6| Step: 10
Training loss: 2.130487425288289
Validation loss: 2.362314711735414

Epoch: 6| Step: 11
Training loss: 2.158880867848548
Validation loss: 2.3543698695680075

Epoch: 6| Step: 12
Training loss: 1.8581182255574928
Validation loss: 2.3345837573494084

Epoch: 6| Step: 13
Training loss: 2.2988409853877743
Validation loss: 2.3289686118320496

Epoch: 394| Step: 0
Training loss: 2.134641540774206
Validation loss: 2.3720062992541666

Epoch: 6| Step: 1
Training loss: 2.1241709269913276
Validation loss: 2.381745105385403

Epoch: 6| Step: 2
Training loss: 2.705010170203532
Validation loss: 2.369376147457301

Epoch: 6| Step: 3
Training loss: 1.6392538971696808
Validation loss: 2.411068004322178

Epoch: 6| Step: 4
Training loss: 2.2614229367890575
Validation loss: 2.417393233760359

Epoch: 6| Step: 5
Training loss: 1.9757276136328825
Validation loss: 2.409105318119731

Epoch: 6| Step: 6
Training loss: 2.202359005488523
Validation loss: 2.402236710124699

Epoch: 6| Step: 7
Training loss: 1.6457741722708774
Validation loss: 2.4034922201884856

Epoch: 6| Step: 8
Training loss: 2.276585238309789
Validation loss: 2.4032333539698483

Epoch: 6| Step: 9
Training loss: 1.9377120117353828
Validation loss: 2.41679561965426

Epoch: 6| Step: 10
Training loss: 2.477095200681586
Validation loss: 2.436005683575128

Epoch: 6| Step: 11
Training loss: 2.8494529132101922
Validation loss: 2.4505260058992215

Epoch: 6| Step: 12
Training loss: 2.281022151908025
Validation loss: 2.475051300807367

Epoch: 6| Step: 13
Training loss: 2.5870739609121607
Validation loss: 2.4949177001491147

Epoch: 395| Step: 0
Training loss: 2.3657545530454183
Validation loss: 2.446175517418532

Epoch: 6| Step: 1
Training loss: 2.410612239393424
Validation loss: 2.4590271008541547

Epoch: 6| Step: 2
Training loss: 2.1659788605000974
Validation loss: 2.4561411860456333

Epoch: 6| Step: 3
Training loss: 2.3977986332942214
Validation loss: 2.4484456363739135

Epoch: 6| Step: 4
Training loss: 1.9241021130641176
Validation loss: 2.4362495334332492

Epoch: 6| Step: 5
Training loss: 2.169759474753755
Validation loss: 2.3894609929378734

Epoch: 6| Step: 6
Training loss: 2.4066280712016352
Validation loss: 2.376677619545145

Epoch: 6| Step: 7
Training loss: 2.239179234679424
Validation loss: 2.3492975615994935

Epoch: 6| Step: 8
Training loss: 1.9724487799894848
Validation loss: 2.324963732703507

Epoch: 6| Step: 9
Training loss: 2.27271597512645
Validation loss: 2.3196027154950705

Epoch: 6| Step: 10
Training loss: 2.456157389440689
Validation loss: 2.3624791386118345

Epoch: 6| Step: 11
Training loss: 1.600369935184787
Validation loss: 2.3972395662694845

Epoch: 6| Step: 12
Training loss: 2.3942791306658444
Validation loss: 2.4541821996926174

Epoch: 6| Step: 13
Training loss: 2.4042797196471124
Validation loss: 2.445915760277335

Epoch: 396| Step: 0
Training loss: 2.3509956766638034
Validation loss: 2.485717298340445

Epoch: 6| Step: 1
Training loss: 1.6399474425151668
Validation loss: 2.4954988104812443

Epoch: 6| Step: 2
Training loss: 2.820827954811667
Validation loss: 2.4971604166606673

Epoch: 6| Step: 3
Training loss: 2.0917812599717713
Validation loss: 2.488386145299175

Epoch: 6| Step: 4
Training loss: 2.234537292135136
Validation loss: 2.454911283847383

Epoch: 6| Step: 5
Training loss: 1.9707588361836965
Validation loss: 2.4535935738648114

Epoch: 6| Step: 6
Training loss: 2.6059156317707655
Validation loss: 2.4585118441862277

Epoch: 6| Step: 7
Training loss: 1.9987004349451427
Validation loss: 2.422169405283676

Epoch: 6| Step: 8
Training loss: 2.1609808949866527
Validation loss: 2.3778132177482196

Epoch: 6| Step: 9
Training loss: 2.4475980077803685
Validation loss: 2.377507587706846

Epoch: 6| Step: 10
Training loss: 1.9174196657663023
Validation loss: 2.356476910041865

Epoch: 6| Step: 11
Training loss: 2.179533265922588
Validation loss: 2.3704755115309655

Epoch: 6| Step: 12
Training loss: 2.255505924691478
Validation loss: 2.395330549845749

Epoch: 6| Step: 13
Training loss: 1.9545559943320243
Validation loss: 2.3911927870842438

Epoch: 397| Step: 0
Training loss: 1.8471316344852
Validation loss: 2.411810803709565

Epoch: 6| Step: 1
Training loss: 2.1444236297563553
Validation loss: 2.458152315564065

Epoch: 6| Step: 2
Training loss: 2.0214992356790726
Validation loss: 2.4784418895742655

Epoch: 6| Step: 3
Training loss: 2.2516151565017237
Validation loss: 2.477510668718765

Epoch: 6| Step: 4
Training loss: 2.497880227716902
Validation loss: 2.508130199830654

Epoch: 6| Step: 5
Training loss: 2.108339408694876
Validation loss: 2.5398941654434926

Epoch: 6| Step: 6
Training loss: 2.082567786387733
Validation loss: 2.510700807322827

Epoch: 6| Step: 7
Training loss: 2.36259574090633
Validation loss: 2.4724105896700337

Epoch: 6| Step: 8
Training loss: 2.0596656976193266
Validation loss: 2.4612468045258304

Epoch: 6| Step: 9
Training loss: 2.138202159284408
Validation loss: 2.383757700085771

Epoch: 6| Step: 10
Training loss: 2.217214133362764
Validation loss: 2.3492429292705714

Epoch: 6| Step: 11
Training loss: 2.4352706103966795
Validation loss: 2.309294717796332

Epoch: 6| Step: 12
Training loss: 2.4022649488473267
Validation loss: 2.3229480518538628

Epoch: 6| Step: 13
Training loss: 2.630465313031427
Validation loss: 2.32187042410329

Epoch: 398| Step: 0
Training loss: 2.247753505306504
Validation loss: 2.3600654181341505

Epoch: 6| Step: 1
Training loss: 1.7319845961575133
Validation loss: 2.3991725936571555

Epoch: 6| Step: 2
Training loss: 1.8066523041218783
Validation loss: 2.4348865736321974

Epoch: 6| Step: 3
Training loss: 2.3088059690886045
Validation loss: 2.464640334769042

Epoch: 6| Step: 4
Training loss: 2.6237070441580275
Validation loss: 2.5490922474727338

Epoch: 6| Step: 5
Training loss: 2.2587173918928434
Validation loss: 2.54626993460468

Epoch: 6| Step: 6
Training loss: 2.1465322473548647
Validation loss: 2.4849082130523032

Epoch: 6| Step: 7
Training loss: 2.171601641899608
Validation loss: 2.419060545834453

Epoch: 6| Step: 8
Training loss: 2.1329287542721116
Validation loss: 2.3377724664258195

Epoch: 6| Step: 9
Training loss: 2.1284065990139944
Validation loss: 2.351775323031446

Epoch: 6| Step: 10
Training loss: 1.944345931176445
Validation loss: 2.331853504071331

Epoch: 6| Step: 11
Training loss: 2.2685312507197124
Validation loss: 2.3422520259247626

Epoch: 6| Step: 12
Training loss: 2.751221125588557
Validation loss: 2.3466231960011337

Epoch: 6| Step: 13
Training loss: 2.4425503178765604
Validation loss: 2.3519866771197884

Epoch: 399| Step: 0
Training loss: 2.4839202656626145
Validation loss: 2.4573855939588474

Epoch: 6| Step: 1
Training loss: 2.2416666203419657
Validation loss: 2.51299176963098

Epoch: 6| Step: 2
Training loss: 2.117216440826471
Validation loss: 2.5405162047991587

Epoch: 6| Step: 3
Training loss: 1.9652167207049656
Validation loss: 2.5943408129598993

Epoch: 6| Step: 4
Training loss: 2.3307318717614076
Validation loss: 2.558952548236483

Epoch: 6| Step: 5
Training loss: 2.0704294999369055
Validation loss: 2.552781171655594

Epoch: 6| Step: 6
Training loss: 1.8876076572865135
Validation loss: 2.506711959929027

Epoch: 6| Step: 7
Training loss: 2.2907895808403103
Validation loss: 2.4527608625889816

Epoch: 6| Step: 8
Training loss: 1.6932132222287233
Validation loss: 2.4338629717917613

Epoch: 6| Step: 9
Training loss: 2.524985013105276
Validation loss: 2.3711882001069284

Epoch: 6| Step: 10
Training loss: 2.2002028978592056
Validation loss: 2.332838867096515

Epoch: 6| Step: 11
Training loss: 2.229129208639238
Validation loss: 2.34655738731629

Epoch: 6| Step: 12
Training loss: 2.3847626257275367
Validation loss: 2.3516504905405218

Epoch: 6| Step: 13
Training loss: 2.7617266059990366
Validation loss: 2.3602121268782232

Epoch: 400| Step: 0
Training loss: 2.7059559193169385
Validation loss: 2.3880451031316

Epoch: 6| Step: 1
Training loss: 1.9985853795149247
Validation loss: 2.4154440315690118

Epoch: 6| Step: 2
Training loss: 1.8492005811861592
Validation loss: 2.4931560831281385

Epoch: 6| Step: 3
Training loss: 2.113058984600265
Validation loss: 2.5097399789182884

Epoch: 6| Step: 4
Training loss: 2.5273252601477822
Validation loss: 2.5788976919062745

Epoch: 6| Step: 5
Training loss: 2.495367335491528
Validation loss: 2.5669784159071756

Epoch: 6| Step: 6
Training loss: 2.1776202937467755
Validation loss: 2.5020823287036293

Epoch: 6| Step: 7
Training loss: 2.2289741171510267
Validation loss: 2.45872933890005

Epoch: 6| Step: 8
Training loss: 1.7018088758765502
Validation loss: 2.3658056669949454

Epoch: 6| Step: 9
Training loss: 2.3912068575184198
Validation loss: 2.3101273503770945

Epoch: 6| Step: 10
Training loss: 2.6096295443889646
Validation loss: 2.295979427696897

Epoch: 6| Step: 11
Training loss: 1.784138729667233
Validation loss: 2.32724131790233

Epoch: 6| Step: 12
Training loss: 2.289741701776
Validation loss: 2.320372252186771

Epoch: 6| Step: 13
Training loss: 1.977117829847578
Validation loss: 2.374825551610669

Epoch: 401| Step: 0
Training loss: 2.123738980593055
Validation loss: 2.3960041131513914

Epoch: 6| Step: 1
Training loss: 2.357443315587048
Validation loss: 2.418263666884032

Epoch: 6| Step: 2
Training loss: 2.859790542508574
Validation loss: 2.4676413756531552

Epoch: 6| Step: 3
Training loss: 1.6308380308296384
Validation loss: 2.530237813587604

Epoch: 6| Step: 4
Training loss: 2.0633843577808206
Validation loss: 2.543674177148507

Epoch: 6| Step: 5
Training loss: 2.2837247619737693
Validation loss: 2.6009909093574572

Epoch: 6| Step: 6
Training loss: 2.4662128400444074
Validation loss: 2.5623011938370244

Epoch: 6| Step: 7
Training loss: 1.9527654698386316
Validation loss: 2.5271541830385544

Epoch: 6| Step: 8
Training loss: 2.393637261586929
Validation loss: 2.4304096077512742

Epoch: 6| Step: 9
Training loss: 2.286180159230454
Validation loss: 2.394443215321001

Epoch: 6| Step: 10
Training loss: 1.7356455505055592
Validation loss: 2.356675651303882

Epoch: 6| Step: 11
Training loss: 2.1182774064519534
Validation loss: 2.3293442540681264

Epoch: 6| Step: 12
Training loss: 2.0911174564803563
Validation loss: 2.326870159662521

Epoch: 6| Step: 13
Training loss: 2.3418230400500852
Validation loss: 2.3200760338972

Epoch: 402| Step: 0
Training loss: 2.1796412309227247
Validation loss: 2.347824444735644

Epoch: 6| Step: 1
Training loss: 1.9428699893186105
Validation loss: 2.401805470493259

Epoch: 6| Step: 2
Training loss: 2.4081686718186313
Validation loss: 2.4275138857219307

Epoch: 6| Step: 3
Training loss: 1.9665619331964015
Validation loss: 2.4757869706064337

Epoch: 6| Step: 4
Training loss: 2.3144368489011033
Validation loss: 2.4875738170791575

Epoch: 6| Step: 5
Training loss: 2.241346992568302
Validation loss: 2.495540273229964

Epoch: 6| Step: 6
Training loss: 2.782533842225442
Validation loss: 2.511325705466943

Epoch: 6| Step: 7
Training loss: 1.9110612032285494
Validation loss: 2.5027281631736327

Epoch: 6| Step: 8
Training loss: 2.201123891204203
Validation loss: 2.425074743889327

Epoch: 6| Step: 9
Training loss: 1.8408609158113207
Validation loss: 2.3783239410369235

Epoch: 6| Step: 10
Training loss: 2.269448572645579
Validation loss: 2.3600103952513645

Epoch: 6| Step: 11
Training loss: 2.161952122429008
Validation loss: 2.3133648954191597

Epoch: 6| Step: 12
Training loss: 2.1811724017749374
Validation loss: 2.316492244790745

Epoch: 6| Step: 13
Training loss: 2.7770346940386847
Validation loss: 2.358597917917917

Epoch: 403| Step: 0
Training loss: 2.4352868621232444
Validation loss: 2.3535835014981434

Epoch: 6| Step: 1
Training loss: 1.9295518958750817
Validation loss: 2.3768555733080268

Epoch: 6| Step: 2
Training loss: 2.226893350213498
Validation loss: 2.3592457319254803

Epoch: 6| Step: 3
Training loss: 2.3312213967539837
Validation loss: 2.3843761276951856

Epoch: 6| Step: 4
Training loss: 2.133780570635276
Validation loss: 2.4203527233323143

Epoch: 6| Step: 5
Training loss: 1.9202424845956294
Validation loss: 2.4970142008283136

Epoch: 6| Step: 6
Training loss: 2.4005136854071263
Validation loss: 2.5175757615330436

Epoch: 6| Step: 7
Training loss: 2.4756312018174493
Validation loss: 2.598015491244613

Epoch: 6| Step: 8
Training loss: 2.587808629302424
Validation loss: 2.5580003832056133

Epoch: 6| Step: 9
Training loss: 2.341060264870882
Validation loss: 2.4566488670286115

Epoch: 6| Step: 10
Training loss: 2.1842129670433676
Validation loss: 2.3714572516833794

Epoch: 6| Step: 11
Training loss: 2.2332833564442507
Validation loss: 2.3296313382023333

Epoch: 6| Step: 12
Training loss: 2.0623898332246093
Validation loss: 2.2968630019909715

Epoch: 6| Step: 13
Training loss: 1.4056793326549826
Validation loss: 2.2998659528661465

Epoch: 404| Step: 0
Training loss: 2.972680471474497
Validation loss: 2.3100325511153046

Epoch: 6| Step: 1
Training loss: 2.2547968488310186
Validation loss: 2.2955615242207545

Epoch: 6| Step: 2
Training loss: 2.1717623674565973
Validation loss: 2.319011375493976

Epoch: 6| Step: 3
Training loss: 2.349348578562004
Validation loss: 2.372523245294157

Epoch: 6| Step: 4
Training loss: 2.4224145103778403
Validation loss: 2.3811988588869895

Epoch: 6| Step: 5
Training loss: 2.399211547403508
Validation loss: 2.4434018610128168

Epoch: 6| Step: 6
Training loss: 1.8502935898285955
Validation loss: 2.5110781916275733

Epoch: 6| Step: 7
Training loss: 2.583574119749377
Validation loss: 2.603182713505607

Epoch: 6| Step: 8
Training loss: 1.80118971555003
Validation loss: 2.6242356493767325

Epoch: 6| Step: 9
Training loss: 1.9397602433579353
Validation loss: 2.638178415803869

Epoch: 6| Step: 10
Training loss: 1.8795984464305717
Validation loss: 2.5732460012137377

Epoch: 6| Step: 11
Training loss: 1.6478014256644005
Validation loss: 2.5493877131826577

Epoch: 6| Step: 12
Training loss: 2.4344904978706348
Validation loss: 2.4493100178967278

Epoch: 6| Step: 13
Training loss: 1.9620694848451712
Validation loss: 2.4079205590133945

Epoch: 405| Step: 0
Training loss: 2.420582087791652
Validation loss: 2.36926466364667

Epoch: 6| Step: 1
Training loss: 1.9700528027385467
Validation loss: 2.3410702661853557

Epoch: 6| Step: 2
Training loss: 2.4140494633294836
Validation loss: 2.3335524372282217

Epoch: 6| Step: 3
Training loss: 1.9883744193620794
Validation loss: 2.3567007711263823

Epoch: 6| Step: 4
Training loss: 2.0147589663845533
Validation loss: 2.359044105662234

Epoch: 6| Step: 5
Training loss: 1.9448051557054364
Validation loss: 2.378771692863308

Epoch: 6| Step: 6
Training loss: 1.6763716504631914
Validation loss: 2.382991512519819

Epoch: 6| Step: 7
Training loss: 1.8302238349352151
Validation loss: 2.3979978616416497

Epoch: 6| Step: 8
Training loss: 2.1478730171077687
Validation loss: 2.444159245664907

Epoch: 6| Step: 9
Training loss: 2.687190725584342
Validation loss: 2.4391976295969946

Epoch: 6| Step: 10
Training loss: 1.9428787633951092
Validation loss: 2.3966495601971114

Epoch: 6| Step: 11
Training loss: 2.4305211443205965
Validation loss: 2.3860381060675877

Epoch: 6| Step: 12
Training loss: 2.6462401330157572
Validation loss: 2.36749941308984

Epoch: 6| Step: 13
Training loss: 2.3001716466792237
Validation loss: 2.3703488648306346

Epoch: 406| Step: 0
Training loss: 1.767758860752933
Validation loss: 2.3603509542690215

Epoch: 6| Step: 1
Training loss: 2.1551853813570507
Validation loss: 2.3725131680216203

Epoch: 6| Step: 2
Training loss: 2.1134330991106633
Validation loss: 2.387756302587656

Epoch: 6| Step: 3
Training loss: 1.8755930916227586
Validation loss: 2.3762605254814955

Epoch: 6| Step: 4
Training loss: 2.9384747774899034
Validation loss: 2.3821400393341174

Epoch: 6| Step: 5
Training loss: 2.304007012720827
Validation loss: 2.3966363512556996

Epoch: 6| Step: 6
Training loss: 2.114643553328905
Validation loss: 2.4130567906285556

Epoch: 6| Step: 7
Training loss: 2.1931145685121236
Validation loss: 2.4154419555601403

Epoch: 6| Step: 8
Training loss: 2.233325204787004
Validation loss: 2.398007030015155

Epoch: 6| Step: 9
Training loss: 1.5099230606485778
Validation loss: 2.4176738522803993

Epoch: 6| Step: 10
Training loss: 2.359764521699119
Validation loss: 2.423189600986537

Epoch: 6| Step: 11
Training loss: 2.3188371174119586
Validation loss: 2.424186437122051

Epoch: 6| Step: 12
Training loss: 2.002719936984723
Validation loss: 2.4237337535554877

Epoch: 6| Step: 13
Training loss: 2.346459107305013
Validation loss: 2.4229040060385403

Epoch: 407| Step: 0
Training loss: 1.7635271555856913
Validation loss: 2.389434521254108

Epoch: 6| Step: 1
Training loss: 1.78139615714101
Validation loss: 2.3747333005543814

Epoch: 6| Step: 2
Training loss: 2.370621007206413
Validation loss: 2.363535474085059

Epoch: 6| Step: 3
Training loss: 2.0551300152490684
Validation loss: 2.323622560751677

Epoch: 6| Step: 4
Training loss: 2.3335217899329326
Validation loss: 2.357594895931925

Epoch: 6| Step: 5
Training loss: 2.201811486832459
Validation loss: 2.3300960412076868

Epoch: 6| Step: 6
Training loss: 2.1209513298540394
Validation loss: 2.3456345876598643

Epoch: 6| Step: 7
Training loss: 2.2122324463877177
Validation loss: 2.3702242171961028

Epoch: 6| Step: 8
Training loss: 2.3588545269389236
Validation loss: 2.405503320034078

Epoch: 6| Step: 9
Training loss: 2.3725239746683227
Validation loss: 2.421354994718149

Epoch: 6| Step: 10
Training loss: 2.372003974473785
Validation loss: 2.4411281805689

Epoch: 6| Step: 11
Training loss: 2.185489057197134
Validation loss: 2.4761978377299623

Epoch: 6| Step: 12
Training loss: 2.287745490737421
Validation loss: 2.447450046579445

Epoch: 6| Step: 13
Training loss: 1.715501176989915
Validation loss: 2.4297775485579587

Epoch: 408| Step: 0
Training loss: 2.2932053919892637
Validation loss: 2.426112934845386

Epoch: 6| Step: 1
Training loss: 2.140299528675538
Validation loss: 2.4309829757610033

Epoch: 6| Step: 2
Training loss: 2.1581882113808812
Validation loss: 2.42606220913932

Epoch: 6| Step: 3
Training loss: 2.20940850433456
Validation loss: 2.404988127806983

Epoch: 6| Step: 4
Training loss: 2.352185543825267
Validation loss: 2.433773457815935

Epoch: 6| Step: 5
Training loss: 1.9914004098680118
Validation loss: 2.420746538861496

Epoch: 6| Step: 6
Training loss: 2.018151998377701
Validation loss: 2.4331664748246036

Epoch: 6| Step: 7
Training loss: 1.9964964697405612
Validation loss: 2.434246796173643

Epoch: 6| Step: 8
Training loss: 2.092078381428508
Validation loss: 2.4243696339212244

Epoch: 6| Step: 9
Training loss: 1.6162402931152011
Validation loss: 2.437928251809321

Epoch: 6| Step: 10
Training loss: 2.2761365461905614
Validation loss: 2.454513229112171

Epoch: 6| Step: 11
Training loss: 2.6936527172675166
Validation loss: 2.4288003551775184

Epoch: 6| Step: 12
Training loss: 1.82093833021201
Validation loss: 2.406290926276942

Epoch: 6| Step: 13
Training loss: 2.397043027794789
Validation loss: 2.3995572933535687

Epoch: 409| Step: 0
Training loss: 2.2767532132604527
Validation loss: 2.3830455110000757

Epoch: 6| Step: 1
Training loss: 2.158209974183136
Validation loss: 2.368282983413893

Epoch: 6| Step: 2
Training loss: 2.397945390844659
Validation loss: 2.3852870003339515

Epoch: 6| Step: 3
Training loss: 2.2380912127550405
Validation loss: 2.3873545703685535

Epoch: 6| Step: 4
Training loss: 2.0369101671084144
Validation loss: 2.418725344789874

Epoch: 6| Step: 5
Training loss: 1.7987275897996668
Validation loss: 2.4408019413383335

Epoch: 6| Step: 6
Training loss: 2.153509527011308
Validation loss: 2.489984493824255

Epoch: 6| Step: 7
Training loss: 1.730500645052953
Validation loss: 2.4662674997313196

Epoch: 6| Step: 8
Training loss: 2.288905115543282
Validation loss: 2.435614074795194

Epoch: 6| Step: 9
Training loss: 2.560954209203945
Validation loss: 2.446502605619436

Epoch: 6| Step: 10
Training loss: 2.2419616372793327
Validation loss: 2.4297014836219972

Epoch: 6| Step: 11
Training loss: 1.7890459751215542
Validation loss: 2.4213895683711106

Epoch: 6| Step: 12
Training loss: 1.774718305236779
Validation loss: 2.408658998803862

Epoch: 6| Step: 13
Training loss: 2.532294540581484
Validation loss: 2.440653607525108

Epoch: 410| Step: 0
Training loss: 2.5245467544006845
Validation loss: 2.456150673874957

Epoch: 6| Step: 1
Training loss: 2.3610732680136612
Validation loss: 2.4668770577181647

Epoch: 6| Step: 2
Training loss: 2.1153101181037153
Validation loss: 2.481084472882923

Epoch: 6| Step: 3
Training loss: 1.6822151505240308
Validation loss: 2.463560821854867

Epoch: 6| Step: 4
Training loss: 1.7295465013881146
Validation loss: 2.4632064035161845

Epoch: 6| Step: 5
Training loss: 2.293130430275951
Validation loss: 2.40203273496383

Epoch: 6| Step: 6
Training loss: 2.0154774929749824
Validation loss: 2.3870617276176818

Epoch: 6| Step: 7
Training loss: 2.2376002795375065
Validation loss: 2.3942516425758598

Epoch: 6| Step: 8
Training loss: 2.416682232335265
Validation loss: 2.3697278691768546

Epoch: 6| Step: 9
Training loss: 1.5139975708068951
Validation loss: 2.4066625272637823

Epoch: 6| Step: 10
Training loss: 2.282765760210892
Validation loss: 2.4155967120359154

Epoch: 6| Step: 11
Training loss: 2.05939654742764
Validation loss: 2.435406600254982

Epoch: 6| Step: 12
Training loss: 2.263365361919203
Validation loss: 2.5055037888719105

Epoch: 6| Step: 13
Training loss: 2.5917797648620415
Validation loss: 2.5206847554287335

Epoch: 411| Step: 0
Training loss: 2.4917401238099637
Validation loss: 2.4104664721351785

Epoch: 6| Step: 1
Training loss: 2.041611871827446
Validation loss: 2.3343947581274453

Epoch: 6| Step: 2
Training loss: 2.5696923339679523
Validation loss: 2.2972799054053565

Epoch: 6| Step: 3
Training loss: 2.100682411124353
Validation loss: 2.282153546389452

Epoch: 6| Step: 4
Training loss: 2.170199619375935
Validation loss: 2.2609402253563498

Epoch: 6| Step: 5
Training loss: 2.1115302484049807
Validation loss: 2.2589973604881135

Epoch: 6| Step: 6
Training loss: 2.083329989112713
Validation loss: 2.2790833187128925

Epoch: 6| Step: 7
Training loss: 2.479551995943206
Validation loss: 2.266541376246295

Epoch: 6| Step: 8
Training loss: 2.049610668521485
Validation loss: 2.2902769978305844

Epoch: 6| Step: 9
Training loss: 1.7623981933409598
Validation loss: 2.3650366337034554

Epoch: 6| Step: 10
Training loss: 2.006016740875522
Validation loss: 2.449690221640335

Epoch: 6| Step: 11
Training loss: 1.7957636838123676
Validation loss: 2.581860606454726

Epoch: 6| Step: 12
Training loss: 2.7244394338242612
Validation loss: 2.6590932088369126

Epoch: 6| Step: 13
Training loss: 1.4614906283902604
Validation loss: 2.684553216862544

Epoch: 412| Step: 0
Training loss: 2.1770366560268504
Validation loss: 2.705412014392316

Epoch: 6| Step: 1
Training loss: 2.122110084691143
Validation loss: 2.727689512528556

Epoch: 6| Step: 2
Training loss: 2.44165018312621
Validation loss: 2.713366596702039

Epoch: 6| Step: 3
Training loss: 2.2559279658471065
Validation loss: 2.6684207268268723

Epoch: 6| Step: 4
Training loss: 2.46101035358432
Validation loss: 2.6164323290603715

Epoch: 6| Step: 5
Training loss: 1.9255405608337663
Validation loss: 2.511759915399914

Epoch: 6| Step: 6
Training loss: 2.0180869037981832
Validation loss: 2.4522539165939254

Epoch: 6| Step: 7
Training loss: 2.09053122362871
Validation loss: 2.4092574367626107

Epoch: 6| Step: 8
Training loss: 2.266851264318199
Validation loss: 2.3946820082676075

Epoch: 6| Step: 9
Training loss: 2.278924880607124
Validation loss: 2.347302310486073

Epoch: 6| Step: 10
Training loss: 1.9227981211228353
Validation loss: 2.339436431124914

Epoch: 6| Step: 11
Training loss: 2.1033773421062927
Validation loss: 2.304039163612258

Epoch: 6| Step: 12
Training loss: 2.185093673339221
Validation loss: 2.314668396488139

Epoch: 6| Step: 13
Training loss: 2.556311788022065
Validation loss: 2.3390276340192595

Epoch: 413| Step: 0
Training loss: 2.399906665258698
Validation loss: 2.355784101686055

Epoch: 6| Step: 1
Training loss: 1.9345435689958026
Validation loss: 2.3718959912641466

Epoch: 6| Step: 2
Training loss: 1.9273647893245143
Validation loss: 2.440244908175003

Epoch: 6| Step: 3
Training loss: 2.516639457538708
Validation loss: 2.5151821371611067

Epoch: 6| Step: 4
Training loss: 1.98454109758307
Validation loss: 2.553430177664689

Epoch: 6| Step: 5
Training loss: 1.9001058774861332
Validation loss: 2.5512518136909232

Epoch: 6| Step: 6
Training loss: 2.115423164149819
Validation loss: 2.5176081625267757

Epoch: 6| Step: 7
Training loss: 2.266300284937181
Validation loss: 2.4879970686075263

Epoch: 6| Step: 8
Training loss: 1.980837033431091
Validation loss: 2.496334380856343

Epoch: 6| Step: 9
Training loss: 2.18521107402679
Validation loss: 2.497584569690877

Epoch: 6| Step: 10
Training loss: 1.919669894411412
Validation loss: 2.4690381877893484

Epoch: 6| Step: 11
Training loss: 2.6019051357689373
Validation loss: 2.428577935901285

Epoch: 6| Step: 12
Training loss: 1.9739782756781092
Validation loss: 2.403808247673591

Epoch: 6| Step: 13
Training loss: 2.7342757724741236
Validation loss: 2.4019941845138404

Epoch: 414| Step: 0
Training loss: 2.174801617925539
Validation loss: 2.375946303280727

Epoch: 6| Step: 1
Training loss: 2.1216535584713334
Validation loss: 2.3801076679309423

Epoch: 6| Step: 2
Training loss: 2.2528223773614355
Validation loss: 2.3626520089184355

Epoch: 6| Step: 3
Training loss: 2.4184199144922083
Validation loss: 2.388025182605818

Epoch: 6| Step: 4
Training loss: 2.2901170404167934
Validation loss: 2.47370614614982

Epoch: 6| Step: 5
Training loss: 1.7952713154052087
Validation loss: 2.50519886278988

Epoch: 6| Step: 6
Training loss: 2.3471058535148686
Validation loss: 2.5849841592729033

Epoch: 6| Step: 7
Training loss: 2.2235654771315616
Validation loss: 2.5642460982533524

Epoch: 6| Step: 8
Training loss: 1.8802978691557646
Validation loss: 2.4476945907686836

Epoch: 6| Step: 9
Training loss: 1.9221357463331104
Validation loss: 2.382329895756493

Epoch: 6| Step: 10
Training loss: 2.123315255503848
Validation loss: 2.3279655012646616

Epoch: 6| Step: 11
Training loss: 2.463017725860212
Validation loss: 2.3162127674797905

Epoch: 6| Step: 12
Training loss: 1.985468285427638
Validation loss: 2.2994649935400893

Epoch: 6| Step: 13
Training loss: 2.654731495960243
Validation loss: 2.340994822717942

Epoch: 415| Step: 0
Training loss: 2.1889040119705125
Validation loss: 2.3403688358927903

Epoch: 6| Step: 1
Training loss: 1.8209161371510187
Validation loss: 2.3919035738879444

Epoch: 6| Step: 2
Training loss: 2.167978867515806
Validation loss: 2.4663714722449552

Epoch: 6| Step: 3
Training loss: 1.9962594099784452
Validation loss: 2.449461800446095

Epoch: 6| Step: 4
Training loss: 2.1862426413951503
Validation loss: 2.473952055028819

Epoch: 6| Step: 5
Training loss: 1.9711151448471003
Validation loss: 2.5060304061229663

Epoch: 6| Step: 6
Training loss: 2.079512512961858
Validation loss: 2.509459398345227

Epoch: 6| Step: 7
Training loss: 2.362149558743543
Validation loss: 2.53950095607177

Epoch: 6| Step: 8
Training loss: 2.206608716639819
Validation loss: 2.4793152889114376

Epoch: 6| Step: 9
Training loss: 1.8294485142946981
Validation loss: 2.448235473783295

Epoch: 6| Step: 10
Training loss: 2.642911654539817
Validation loss: 2.402412928583889

Epoch: 6| Step: 11
Training loss: 1.992397761001355
Validation loss: 2.4051205824221276

Epoch: 6| Step: 12
Training loss: 2.134532863425613
Validation loss: 2.4053267673621277

Epoch: 6| Step: 13
Training loss: 1.8335937473994395
Validation loss: 2.3661801070139994

Epoch: 416| Step: 0
Training loss: 1.9085866021527214
Validation loss: 2.381646907138893

Epoch: 6| Step: 1
Training loss: 1.9958763526734649
Validation loss: 2.3730739886174232

Epoch: 6| Step: 2
Training loss: 2.1179334164060366
Validation loss: 2.375129824610619

Epoch: 6| Step: 3
Training loss: 2.5850992832265036
Validation loss: 2.400629363507449

Epoch: 6| Step: 4
Training loss: 2.126582846449609
Validation loss: 2.447046621087366

Epoch: 6| Step: 5
Training loss: 2.029394387921203
Validation loss: 2.42031201576746

Epoch: 6| Step: 6
Training loss: 2.314255949868438
Validation loss: 2.452720686627556

Epoch: 6| Step: 7
Training loss: 2.233367692863376
Validation loss: 2.4475383810983464

Epoch: 6| Step: 8
Training loss: 2.3656166832398493
Validation loss: 2.4943888338998166

Epoch: 6| Step: 9
Training loss: 2.1571931849358763
Validation loss: 2.505453273821412

Epoch: 6| Step: 10
Training loss: 1.9836421424278368
Validation loss: 2.5062866680425295

Epoch: 6| Step: 11
Training loss: 2.0219551459675578
Validation loss: 2.4765123625100625

Epoch: 6| Step: 12
Training loss: 1.7461430416787662
Validation loss: 2.4289687898330325

Epoch: 6| Step: 13
Training loss: 1.7668320572407703
Validation loss: 2.3924515071177193

Epoch: 417| Step: 0
Training loss: 1.8798735541573963
Validation loss: 2.365435287201518

Epoch: 6| Step: 1
Training loss: 2.112097106976982
Validation loss: 2.3038412112566706

Epoch: 6| Step: 2
Training loss: 2.131541561644087
Validation loss: 2.290022722589985

Epoch: 6| Step: 3
Training loss: 1.97551956102964
Validation loss: 2.3350633233952793

Epoch: 6| Step: 4
Training loss: 2.075201171866728
Validation loss: 2.315910555945565

Epoch: 6| Step: 5
Training loss: 2.3701894125918503
Validation loss: 2.3337714213218685

Epoch: 6| Step: 6
Training loss: 2.586122811583827
Validation loss: 2.329494118066288

Epoch: 6| Step: 7
Training loss: 2.161070480171754
Validation loss: 2.4111047658882003

Epoch: 6| Step: 8
Training loss: 1.9202894167525366
Validation loss: 2.429978803382427

Epoch: 6| Step: 9
Training loss: 1.6500171487090476
Validation loss: 2.499941092996927

Epoch: 6| Step: 10
Training loss: 2.3339341162214295
Validation loss: 2.5412244877777157

Epoch: 6| Step: 11
Training loss: 2.416695452113104
Validation loss: 2.5665631858965696

Epoch: 6| Step: 12
Training loss: 1.8072862286078204
Validation loss: 2.5520794119856047

Epoch: 6| Step: 13
Training loss: 2.3266986343388307
Validation loss: 2.4923753837633535

Epoch: 418| Step: 0
Training loss: 2.2841133019959803
Validation loss: 2.4840073213146217

Epoch: 6| Step: 1
Training loss: 1.9552173850721009
Validation loss: 2.4381929921214636

Epoch: 6| Step: 2
Training loss: 1.9883768174862255
Validation loss: 2.3872156670652482

Epoch: 6| Step: 3
Training loss: 2.5129055701721166
Validation loss: 2.388613903267291

Epoch: 6| Step: 4
Training loss: 2.030889860651885
Validation loss: 2.3486356876302734

Epoch: 6| Step: 5
Training loss: 2.3801185262642197
Validation loss: 2.3475333896866615

Epoch: 6| Step: 6
Training loss: 2.1647705682494807
Validation loss: 2.3667448687195045

Epoch: 6| Step: 7
Training loss: 2.265532182568031
Validation loss: 2.3866820059580296

Epoch: 6| Step: 8
Training loss: 2.1291943836336595
Validation loss: 2.4085447132697433

Epoch: 6| Step: 9
Training loss: 2.267292855757348
Validation loss: 2.459801978910095

Epoch: 6| Step: 10
Training loss: 1.7832320044895833
Validation loss: 2.470683276367356

Epoch: 6| Step: 11
Training loss: 1.4928143368031535
Validation loss: 2.4757470782197473

Epoch: 6| Step: 12
Training loss: 2.210114019050458
Validation loss: 2.5225150643671705

Epoch: 6| Step: 13
Training loss: 1.6527146087813296
Validation loss: 2.511688037796119

Epoch: 419| Step: 0
Training loss: 2.0604064025726108
Validation loss: 2.489971651827775

Epoch: 6| Step: 1
Training loss: 1.9122594943943585
Validation loss: 2.4425601817659013

Epoch: 6| Step: 2
Training loss: 2.056594253988158
Validation loss: 2.3828938562258037

Epoch: 6| Step: 3
Training loss: 1.9267562038687531
Validation loss: 2.392801603152024

Epoch: 6| Step: 4
Training loss: 2.012696852445129
Validation loss: 2.3604064557865683

Epoch: 6| Step: 5
Training loss: 1.9179023063012106
Validation loss: 2.3279537642562063

Epoch: 6| Step: 6
Training loss: 1.8614400087495986
Validation loss: 2.332840500114853

Epoch: 6| Step: 7
Training loss: 2.5558694794093784
Validation loss: 2.344301975020424

Epoch: 6| Step: 8
Training loss: 2.0236075193637566
Validation loss: 2.3871540327668583

Epoch: 6| Step: 9
Training loss: 2.4332637654989715
Validation loss: 2.440025588267382

Epoch: 6| Step: 10
Training loss: 2.166044573852705
Validation loss: 2.471382675093778

Epoch: 6| Step: 11
Training loss: 2.190236369227846
Validation loss: 2.412335406786239

Epoch: 6| Step: 12
Training loss: 2.0705060760401524
Validation loss: 2.379985573167266

Epoch: 6| Step: 13
Training loss: 2.4215729555856114
Validation loss: 2.3471084476216215

Epoch: 420| Step: 0
Training loss: 2.0814187471180547
Validation loss: 2.370857182233266

Epoch: 6| Step: 1
Training loss: 1.792385496794499
Validation loss: 2.4211297186853633

Epoch: 6| Step: 2
Training loss: 2.0492224591098367
Validation loss: 2.4345382058411804

Epoch: 6| Step: 3
Training loss: 2.463907248299468
Validation loss: 2.460060808838071

Epoch: 6| Step: 4
Training loss: 2.480104434675478
Validation loss: 2.4369156134042465

Epoch: 6| Step: 5
Training loss: 2.3273045675174946
Validation loss: 2.444042765319663

Epoch: 6| Step: 6
Training loss: 2.1613461630030772
Validation loss: 2.4641286509737768

Epoch: 6| Step: 7
Training loss: 1.5356820252030492
Validation loss: 2.4239103764008307

Epoch: 6| Step: 8
Training loss: 1.8814052530398047
Validation loss: 2.420370110058421

Epoch: 6| Step: 9
Training loss: 2.242595143761085
Validation loss: 2.363744084715819

Epoch: 6| Step: 10
Training loss: 2.5577104048256936
Validation loss: 2.3248583867502806

Epoch: 6| Step: 11
Training loss: 2.1961709512761076
Validation loss: 2.3149285782736633

Epoch: 6| Step: 12
Training loss: 1.5896929545203027
Validation loss: 2.326757067280945

Epoch: 6| Step: 13
Training loss: 1.6084167442368533
Validation loss: 2.349056256498257

Epoch: 421| Step: 0
Training loss: 2.0738118090394613
Validation loss: 2.359184680682067

Epoch: 6| Step: 1
Training loss: 2.2440915413610694
Validation loss: 2.4091683365745284

Epoch: 6| Step: 2
Training loss: 2.1225595485210356
Validation loss: 2.429865335435451

Epoch: 6| Step: 3
Training loss: 1.946927361679707
Validation loss: 2.4842995025706243

Epoch: 6| Step: 4
Training loss: 2.252247535537386
Validation loss: 2.4982188576085385

Epoch: 6| Step: 5
Training loss: 1.7353071852179636
Validation loss: 2.4961249940282655

Epoch: 6| Step: 6
Training loss: 2.2547782387983184
Validation loss: 2.4744027954911254

Epoch: 6| Step: 7
Training loss: 1.5500232756312982
Validation loss: 2.474927586233326

Epoch: 6| Step: 8
Training loss: 1.898169981392414
Validation loss: 2.502812075571034

Epoch: 6| Step: 9
Training loss: 2.053507534952321
Validation loss: 2.5452232135530712

Epoch: 6| Step: 10
Training loss: 2.3045370796383864
Validation loss: 2.542562018057026

Epoch: 6| Step: 11
Training loss: 2.0375978317644603
Validation loss: 2.507254999756996

Epoch: 6| Step: 12
Training loss: 2.658649124075516
Validation loss: 2.487665538955237

Epoch: 6| Step: 13
Training loss: 1.866266765787454
Validation loss: 2.39206171747349

Epoch: 422| Step: 0
Training loss: 2.2015273341124426
Validation loss: 2.3629769951378834

Epoch: 6| Step: 1
Training loss: 2.0192266415284834
Validation loss: 2.3242262195836982

Epoch: 6| Step: 2
Training loss: 1.8615258863331128
Validation loss: 2.3153285105835595

Epoch: 6| Step: 3
Training loss: 1.859431033532337
Validation loss: 2.2909864872401857

Epoch: 6| Step: 4
Training loss: 2.2207781695969433
Validation loss: 2.287473524740497

Epoch: 6| Step: 5
Training loss: 2.2639924580209154
Validation loss: 2.2987007684830205

Epoch: 6| Step: 6
Training loss: 2.2879622487441673
Validation loss: 2.3741046662165264

Epoch: 6| Step: 7
Training loss: 1.8979303129887108
Validation loss: 2.4204821447323126

Epoch: 6| Step: 8
Training loss: 2.455505285376607
Validation loss: 2.44387242449288

Epoch: 6| Step: 9
Training loss: 1.9232264783366253
Validation loss: 2.5176869479798216

Epoch: 6| Step: 10
Training loss: 2.2314742672834242
Validation loss: 2.5518007973804

Epoch: 6| Step: 11
Training loss: 1.7235877876776875
Validation loss: 2.534707503745001

Epoch: 6| Step: 12
Training loss: 2.2556462967549793
Validation loss: 2.5165413591492762

Epoch: 6| Step: 13
Training loss: 2.383487093129311
Validation loss: 2.45494958185999

Epoch: 423| Step: 0
Training loss: 1.700323688320935
Validation loss: 2.4056044779292405

Epoch: 6| Step: 1
Training loss: 1.8290998679833983
Validation loss: 2.364986951896462

Epoch: 6| Step: 2
Training loss: 2.07554248015165
Validation loss: 2.315927833449517

Epoch: 6| Step: 3
Training loss: 2.1326696327064036
Validation loss: 2.321904511024653

Epoch: 6| Step: 4
Training loss: 2.1522766213584608
Validation loss: 2.3071862097613853

Epoch: 6| Step: 5
Training loss: 1.9339409410518622
Validation loss: 2.2974954949669697

Epoch: 6| Step: 6
Training loss: 2.109555046027009
Validation loss: 2.2957922703924103

Epoch: 6| Step: 7
Training loss: 2.3137781889366313
Validation loss: 2.3185583771949183

Epoch: 6| Step: 8
Training loss: 2.0762795880601943
Validation loss: 2.399075528705603

Epoch: 6| Step: 9
Training loss: 2.115808354466058
Validation loss: 2.479424735583893

Epoch: 6| Step: 10
Training loss: 2.318965328120212
Validation loss: 2.5648033900631884

Epoch: 6| Step: 11
Training loss: 1.897665361278109
Validation loss: 2.5756566646108885

Epoch: 6| Step: 12
Training loss: 2.19614250810223
Validation loss: 2.5103203316706604

Epoch: 6| Step: 13
Training loss: 2.4640403925569774
Validation loss: 2.438953063312949

Epoch: 424| Step: 0
Training loss: 2.1665344442468277
Validation loss: 2.4556346497518766

Epoch: 6| Step: 1
Training loss: 2.5047866773096916
Validation loss: 2.372698423182672

Epoch: 6| Step: 2
Training loss: 1.9900834884574274
Validation loss: 2.3362604907654827

Epoch: 6| Step: 3
Training loss: 2.222813820239892
Validation loss: 2.3371291847330955

Epoch: 6| Step: 4
Training loss: 2.3690454223323223
Validation loss: 2.341734246718191

Epoch: 6| Step: 5
Training loss: 1.6118624824194665
Validation loss: 2.3755435861241807

Epoch: 6| Step: 6
Training loss: 1.9487405622350418
Validation loss: 2.4180136976325763

Epoch: 6| Step: 7
Training loss: 1.683293999630999
Validation loss: 2.43969488174641

Epoch: 6| Step: 8
Training loss: 1.77648489186213
Validation loss: 2.4583842423640694

Epoch: 6| Step: 9
Training loss: 2.19270751179901
Validation loss: 2.465594174836653

Epoch: 6| Step: 10
Training loss: 2.3579141502638827
Validation loss: 2.439729836484177

Epoch: 6| Step: 11
Training loss: 2.160653965816266
Validation loss: 2.4436257321459407

Epoch: 6| Step: 12
Training loss: 1.8088950777429615
Validation loss: 2.41556459728724

Epoch: 6| Step: 13
Training loss: 2.2440358694409057
Validation loss: 2.4256421591367694

Epoch: 425| Step: 0
Training loss: 2.205848471437436
Validation loss: 2.4253654507384783

Epoch: 6| Step: 1
Training loss: 2.2137792003564645
Validation loss: 2.384071261574184

Epoch: 6| Step: 2
Training loss: 1.7405233603479358
Validation loss: 2.3922446025525987

Epoch: 6| Step: 3
Training loss: 2.1163728279750162
Validation loss: 2.4151074209924674

Epoch: 6| Step: 4
Training loss: 2.1709791572585906
Validation loss: 2.4537994427443204

Epoch: 6| Step: 5
Training loss: 2.55020653879307
Validation loss: 2.4949240909581225

Epoch: 6| Step: 6
Training loss: 1.973304022762486
Validation loss: 2.445462408853245

Epoch: 6| Step: 7
Training loss: 2.057009005544011
Validation loss: 2.4073714333356513

Epoch: 6| Step: 8
Training loss: 2.447251693551977
Validation loss: 2.3853617202965514

Epoch: 6| Step: 9
Training loss: 1.623523481513475
Validation loss: 2.357196211760383

Epoch: 6| Step: 10
Training loss: 1.9411296071721253
Validation loss: 2.349858774546596

Epoch: 6| Step: 11
Training loss: 1.9910530001504125
Validation loss: 2.3656991011422415

Epoch: 6| Step: 12
Training loss: 1.776910146284485
Validation loss: 2.382327063980611

Epoch: 6| Step: 13
Training loss: 2.370471451621829
Validation loss: 2.4025801998387517

Epoch: 426| Step: 0
Training loss: 2.0306529414731065
Validation loss: 2.4007784019088576

Epoch: 6| Step: 1
Training loss: 1.7927664848381497
Validation loss: 2.393292469085179

Epoch: 6| Step: 2
Training loss: 2.1022851545261796
Validation loss: 2.456948646594019

Epoch: 6| Step: 3
Training loss: 2.3872386409846023
Validation loss: 2.478904824731096

Epoch: 6| Step: 4
Training loss: 2.295233938224328
Validation loss: 2.451808275874143

Epoch: 6| Step: 5
Training loss: 1.9420410592072899
Validation loss: 2.4430185798735446

Epoch: 6| Step: 6
Training loss: 2.0001804747215988
Validation loss: 2.3598684995328876

Epoch: 6| Step: 7
Training loss: 1.5241340805305057
Validation loss: 2.3040119764160294

Epoch: 6| Step: 8
Training loss: 2.0662599450510726
Validation loss: 2.3100127335905802

Epoch: 6| Step: 9
Training loss: 2.2114651862415777
Validation loss: 2.3415828187823156

Epoch: 6| Step: 10
Training loss: 2.3663177403155995
Validation loss: 2.374577382670782

Epoch: 6| Step: 11
Training loss: 1.8758407615108954
Validation loss: 2.395440917405004

Epoch: 6| Step: 12
Training loss: 2.0290601223253555
Validation loss: 2.4210417479466875

Epoch: 6| Step: 13
Training loss: 2.2866787004107842
Validation loss: 2.4936450059139927

Epoch: 427| Step: 0
Training loss: 2.033217900027368
Validation loss: 2.454020842218161

Epoch: 6| Step: 1
Training loss: 2.52200749272588
Validation loss: 2.4940131551372566

Epoch: 6| Step: 2
Training loss: 1.7025360348958898
Validation loss: 2.471278287357913

Epoch: 6| Step: 3
Training loss: 1.8515133750611674
Validation loss: 2.4037639686790735

Epoch: 6| Step: 4
Training loss: 2.194842413804587
Validation loss: 2.38310645711162

Epoch: 6| Step: 5
Training loss: 2.0745368900324404
Validation loss: 2.3583078245253595

Epoch: 6| Step: 6
Training loss: 2.360210346610874
Validation loss: 2.3563814220289765

Epoch: 6| Step: 7
Training loss: 1.8867631042195234
Validation loss: 2.3626978331113264

Epoch: 6| Step: 8
Training loss: 1.5127448805881736
Validation loss: 2.354279258344955

Epoch: 6| Step: 9
Training loss: 1.7993698712587554
Validation loss: 2.355892969206574

Epoch: 6| Step: 10
Training loss: 2.2406609951304275
Validation loss: 2.3630188661634155

Epoch: 6| Step: 11
Training loss: 2.3591152831365445
Validation loss: 2.416563960797094

Epoch: 6| Step: 12
Training loss: 2.2557238781682862
Validation loss: 2.485201957460177

Epoch: 6| Step: 13
Training loss: 1.8614939308569636
Validation loss: 2.4976382225769362

Epoch: 428| Step: 0
Training loss: 2.2043112949546617
Validation loss: 2.5158049419017505

Epoch: 6| Step: 1
Training loss: 2.00356297220418
Validation loss: 2.5307389977504964

Epoch: 6| Step: 2
Training loss: 2.4476019041455164
Validation loss: 2.511483866092833

Epoch: 6| Step: 3
Training loss: 2.2432066830749107
Validation loss: 2.4386933284530974

Epoch: 6| Step: 4
Training loss: 2.0127100011594043
Validation loss: 2.3640324374275754

Epoch: 6| Step: 5
Training loss: 2.415352091110019
Validation loss: 2.341232476874881

Epoch: 6| Step: 6
Training loss: 1.805186347218537
Validation loss: 2.3241952049915153

Epoch: 6| Step: 7
Training loss: 2.1997022080447954
Validation loss: 2.315940049833389

Epoch: 6| Step: 8
Training loss: 1.9162942137472934
Validation loss: 2.341710668719789

Epoch: 6| Step: 9
Training loss: 1.9091512770624297
Validation loss: 2.3205221029064

Epoch: 6| Step: 10
Training loss: 1.7460430231769175
Validation loss: 2.349896608215099

Epoch: 6| Step: 11
Training loss: 2.3163531395418597
Validation loss: 2.4089305901259435

Epoch: 6| Step: 12
Training loss: 1.2543577528120895
Validation loss: 2.426908092112966

Epoch: 6| Step: 13
Training loss: 2.4355879889523004
Validation loss: 2.4766708034100517

Epoch: 429| Step: 0
Training loss: 1.8459683666680575
Validation loss: 2.4576525359894705

Epoch: 6| Step: 1
Training loss: 2.0623213950765713
Validation loss: 2.475801625784346

Epoch: 6| Step: 2
Training loss: 1.8271314741496094
Validation loss: 2.38141975873247

Epoch: 6| Step: 3
Training loss: 2.3313331773252637
Validation loss: 2.343238491450279

Epoch: 6| Step: 4
Training loss: 2.2247399081682744
Validation loss: 2.3283567476354534

Epoch: 6| Step: 5
Training loss: 2.1369109965146293
Validation loss: 2.3276104630669385

Epoch: 6| Step: 6
Training loss: 1.8872107581019153
Validation loss: 2.3511271680378756

Epoch: 6| Step: 7
Training loss: 2.119988422182246
Validation loss: 2.405077103584729

Epoch: 6| Step: 8
Training loss: 2.0205039185181786
Validation loss: 2.446059841582396

Epoch: 6| Step: 9
Training loss: 2.053943920116526
Validation loss: 2.4437949682191307

Epoch: 6| Step: 10
Training loss: 2.207433721253716
Validation loss: 2.5161053130144335

Epoch: 6| Step: 11
Training loss: 2.1612073882862575
Validation loss: 2.5252317110479763

Epoch: 6| Step: 12
Training loss: 1.7008513927232984
Validation loss: 2.4970075130099354

Epoch: 6| Step: 13
Training loss: 2.421149458956675
Validation loss: 2.5252705719748256

Epoch: 430| Step: 0
Training loss: 1.3411101203780653
Validation loss: 2.4939696676656355

Epoch: 6| Step: 1
Training loss: 2.1698588062532336
Validation loss: 2.4790268951073147

Epoch: 6| Step: 2
Training loss: 2.1415276399405623
Validation loss: 2.477716619728633

Epoch: 6| Step: 3
Training loss: 2.110536156824302
Validation loss: 2.4614348878217287

Epoch: 6| Step: 4
Training loss: 1.9067479093066775
Validation loss: 2.438712411453749

Epoch: 6| Step: 5
Training loss: 1.9802819037846686
Validation loss: 2.4680196435384967

Epoch: 6| Step: 6
Training loss: 2.3099898040018023
Validation loss: 2.504156259175197

Epoch: 6| Step: 7
Training loss: 2.317656875782061
Validation loss: 2.4883590065088375

Epoch: 6| Step: 8
Training loss: 1.598719161677954
Validation loss: 2.4046118937168495

Epoch: 6| Step: 9
Training loss: 2.130047469527998
Validation loss: 2.4500142194374215

Epoch: 6| Step: 10
Training loss: 1.9848402784452759
Validation loss: 2.3870890085323504

Epoch: 6| Step: 11
Training loss: 2.437983929450477
Validation loss: 2.402123968564068

Epoch: 6| Step: 12
Training loss: 1.9524690060469525
Validation loss: 2.38679088195328

Epoch: 6| Step: 13
Training loss: 1.6791345440211303
Validation loss: 2.3537909465383735

Epoch: 431| Step: 0
Training loss: 2.2026986866248497
Validation loss: 2.35988004087577

Epoch: 6| Step: 1
Training loss: 1.6850981396810232
Validation loss: 2.3738782378354504

Epoch: 6| Step: 2
Training loss: 2.4623482671938666
Validation loss: 2.4099966274788134

Epoch: 6| Step: 3
Training loss: 1.8897723332284095
Validation loss: 2.421724343484871

Epoch: 6| Step: 4
Training loss: 2.289757945165543
Validation loss: 2.4292218689633702

Epoch: 6| Step: 5
Training loss: 1.9780881519712397
Validation loss: 2.470006606065049

Epoch: 6| Step: 6
Training loss: 2.0756034754849173
Validation loss: 2.426973639251326

Epoch: 6| Step: 7
Training loss: 2.1625512971471843
Validation loss: 2.4418402168069355

Epoch: 6| Step: 8
Training loss: 2.0321649691455934
Validation loss: 2.3905160155103067

Epoch: 6| Step: 9
Training loss: 1.9855391924565184
Validation loss: 2.343398120129064

Epoch: 6| Step: 10
Training loss: 1.6498426622455262
Validation loss: 2.3363747075955072

Epoch: 6| Step: 11
Training loss: 1.9012353946443319
Validation loss: 2.357073320661054

Epoch: 6| Step: 12
Training loss: 2.303504562674811
Validation loss: 2.386166451286538

Epoch: 6| Step: 13
Training loss: 2.155659802145661
Validation loss: 2.4265366174887344

Epoch: 432| Step: 0
Training loss: 1.5582914513384372
Validation loss: 2.429898326241767

Epoch: 6| Step: 1
Training loss: 1.8308164558564548
Validation loss: 2.4313651776149015

Epoch: 6| Step: 2
Training loss: 2.24339033554157
Validation loss: 2.433788095268336

Epoch: 6| Step: 3
Training loss: 1.7204085237484805
Validation loss: 2.467961790012459

Epoch: 6| Step: 4
Training loss: 2.6445291764266705
Validation loss: 2.455735108085595

Epoch: 6| Step: 5
Training loss: 1.9829989490669764
Validation loss: 2.439872659712098

Epoch: 6| Step: 6
Training loss: 2.2063343669548714
Validation loss: 2.4560993827967845

Epoch: 6| Step: 7
Training loss: 2.0544983519312883
Validation loss: 2.4295290615131573

Epoch: 6| Step: 8
Training loss: 1.9347103093274884
Validation loss: 2.4328308231653417

Epoch: 6| Step: 9
Training loss: 2.1892904311346886
Validation loss: 2.347189137655497

Epoch: 6| Step: 10
Training loss: 2.0278105740384453
Validation loss: 2.3132792686666726

Epoch: 6| Step: 11
Training loss: 2.537187183059201
Validation loss: 2.297877666763588

Epoch: 6| Step: 12
Training loss: 1.4465209857408639
Validation loss: 2.334720668466168

Epoch: 6| Step: 13
Training loss: 2.0714648224801464
Validation loss: 2.3730610173753193

Epoch: 433| Step: 0
Training loss: 1.9837752509718454
Validation loss: 2.4296206100515687

Epoch: 6| Step: 1
Training loss: 2.1821710254277296
Validation loss: 2.5036619981477424

Epoch: 6| Step: 2
Training loss: 2.4301796564949263
Validation loss: 2.581912033443749

Epoch: 6| Step: 3
Training loss: 2.212044482565095
Validation loss: 2.5640911801600583

Epoch: 6| Step: 4
Training loss: 1.9886578576053444
Validation loss: 2.5508884796281257

Epoch: 6| Step: 5
Training loss: 2.2401049575739225
Validation loss: 2.492234067494341

Epoch: 6| Step: 6
Training loss: 1.7692332574737555
Validation loss: 2.462444308079946

Epoch: 6| Step: 7
Training loss: 1.4620754277749475
Validation loss: 2.408423914289747

Epoch: 6| Step: 8
Training loss: 2.358473750900209
Validation loss: 2.338406573131606

Epoch: 6| Step: 9
Training loss: 1.8533090329578243
Validation loss: 2.299556738998618

Epoch: 6| Step: 10
Training loss: 2.216920662671278
Validation loss: 2.2944804401463155

Epoch: 6| Step: 11
Training loss: 2.0168195629746277
Validation loss: 2.323420316362557

Epoch: 6| Step: 12
Training loss: 1.9156456453041628
Validation loss: 2.3692291075246823

Epoch: 6| Step: 13
Training loss: 2.428067762174017
Validation loss: 2.4582598094537165

Epoch: 434| Step: 0
Training loss: 2.318567923828678
Validation loss: 2.524505439034846

Epoch: 6| Step: 1
Training loss: 2.180769675636065
Validation loss: 2.606856843210201

Epoch: 6| Step: 2
Training loss: 2.377787309649288
Validation loss: 2.6265163924858412

Epoch: 6| Step: 3
Training loss: 2.1940128918793222
Validation loss: 2.5463373464874017

Epoch: 6| Step: 4
Training loss: 2.003028245990515
Validation loss: 2.43200250647515

Epoch: 6| Step: 5
Training loss: 1.3717579767806225
Validation loss: 2.3382174607925212

Epoch: 6| Step: 6
Training loss: 2.489936026858256
Validation loss: 2.306583308490124

Epoch: 6| Step: 7
Training loss: 2.2478832248277842
Validation loss: 2.268416316697489

Epoch: 6| Step: 8
Training loss: 1.9580232767079473
Validation loss: 2.2442469326475085

Epoch: 6| Step: 9
Training loss: 2.0019674161075276
Validation loss: 2.2595050002169383

Epoch: 6| Step: 10
Training loss: 2.1623692687986424
Validation loss: 2.307500545104483

Epoch: 6| Step: 11
Training loss: 2.3076707056452745
Validation loss: 2.3355641003678076

Epoch: 6| Step: 12
Training loss: 1.8605384072017572
Validation loss: 2.3835365770097696

Epoch: 6| Step: 13
Training loss: 1.0529142378273473
Validation loss: 2.4594580022756403

Epoch: 435| Step: 0
Training loss: 1.7625154102274008
Validation loss: 2.5172136870146224

Epoch: 6| Step: 1
Training loss: 2.5165288024260604
Validation loss: 2.523465045826994

Epoch: 6| Step: 2
Training loss: 2.056329223590779
Validation loss: 2.492446363919487

Epoch: 6| Step: 3
Training loss: 1.680181741080319
Validation loss: 2.4209529374500107

Epoch: 6| Step: 4
Training loss: 2.105250756013882
Validation loss: 2.3758936411345606

Epoch: 6| Step: 5
Training loss: 2.0890673755026783
Validation loss: 2.3595963099729507

Epoch: 6| Step: 6
Training loss: 1.795757244589923
Validation loss: 2.3257867909320806

Epoch: 6| Step: 7
Training loss: 2.2264434247216633
Validation loss: 2.3344489939275572

Epoch: 6| Step: 8
Training loss: 1.6170539247937645
Validation loss: 2.3667577944220466

Epoch: 6| Step: 9
Training loss: 2.4558405333448925
Validation loss: 2.408732369272377

Epoch: 6| Step: 10
Training loss: 1.7851274016405358
Validation loss: 2.4397413236796157

Epoch: 6| Step: 11
Training loss: 2.3649695552939027
Validation loss: 2.438903997955805

Epoch: 6| Step: 12
Training loss: 2.6799931921801288
Validation loss: 2.441026917355258

Epoch: 6| Step: 13
Training loss: 1.56285487913305
Validation loss: 2.4676213631787745

Epoch: 436| Step: 0
Training loss: 1.814833355864418
Validation loss: 2.5090718371418874

Epoch: 6| Step: 1
Training loss: 2.363820618170185
Validation loss: 2.5540966343982463

Epoch: 6| Step: 2
Training loss: 2.0742598994711825
Validation loss: 2.5719253113472393

Epoch: 6| Step: 3
Training loss: 2.312791651299476
Validation loss: 2.553153954643711

Epoch: 6| Step: 4
Training loss: 2.0392897906726737
Validation loss: 2.470095501320919

Epoch: 6| Step: 5
Training loss: 1.730348191033566
Validation loss: 2.435326668815512

Epoch: 6| Step: 6
Training loss: 2.084934636470528
Validation loss: 2.374527488599566

Epoch: 6| Step: 7
Training loss: 2.127748619103345
Validation loss: 2.32657613999097

Epoch: 6| Step: 8
Training loss: 2.126007738704
Validation loss: 2.3006777117570945

Epoch: 6| Step: 9
Training loss: 2.050610693242498
Validation loss: 2.272243088879153

Epoch: 6| Step: 10
Training loss: 1.964056748508478
Validation loss: 2.2830127676817176

Epoch: 6| Step: 11
Training loss: 1.9832454079551145
Validation loss: 2.2973077056873046

Epoch: 6| Step: 12
Training loss: 2.367565364076318
Validation loss: 2.3650727449716284

Epoch: 6| Step: 13
Training loss: 1.9856257664454167
Validation loss: 2.439863419599362

Epoch: 437| Step: 0
Training loss: 2.072802503755236
Validation loss: 2.516281948117955

Epoch: 6| Step: 1
Training loss: 2.1180270736808278
Validation loss: 2.5479193953749513

Epoch: 6| Step: 2
Training loss: 2.1719983841133077
Validation loss: 2.5233135156737423

Epoch: 6| Step: 3
Training loss: 1.928265870325614
Validation loss: 2.475154883629586

Epoch: 6| Step: 4
Training loss: 2.0472476998475906
Validation loss: 2.4044292674704204

Epoch: 6| Step: 5
Training loss: 1.715581574437603
Validation loss: 2.34072537521233

Epoch: 6| Step: 6
Training loss: 2.4812098079472173
Validation loss: 2.327799314336506

Epoch: 6| Step: 7
Training loss: 1.272951185358809
Validation loss: 2.296134816630299

Epoch: 6| Step: 8
Training loss: 2.172393627130569
Validation loss: 2.2952480551968106

Epoch: 6| Step: 9
Training loss: 2.1238985011747236
Validation loss: 2.335928495173476

Epoch: 6| Step: 10
Training loss: 2.3479779573669872
Validation loss: 2.4110236098426125

Epoch: 6| Step: 11
Training loss: 1.8804264382395093
Validation loss: 2.491756238722207

Epoch: 6| Step: 12
Training loss: 2.2023560825745516
Validation loss: 2.525744904437606

Epoch: 6| Step: 13
Training loss: 2.1791885515892573
Validation loss: 2.604535224347628

Epoch: 438| Step: 0
Training loss: 1.8124546176885148
Validation loss: 2.602588435876392

Epoch: 6| Step: 1
Training loss: 1.85025229151367
Validation loss: 2.5565772622051064

Epoch: 6| Step: 2
Training loss: 1.995849893085798
Validation loss: 2.5391780077941557

Epoch: 6| Step: 3
Training loss: 2.611364828007303
Validation loss: 2.5491420616790874

Epoch: 6| Step: 4
Training loss: 1.8565320632306863
Validation loss: 2.4848991631016903

Epoch: 6| Step: 5
Training loss: 2.097704213764377
Validation loss: 2.434378002133883

Epoch: 6| Step: 6
Training loss: 2.113626673984784
Validation loss: 2.402394787632834

Epoch: 6| Step: 7
Training loss: 1.5201479878663255
Validation loss: 2.353292873854787

Epoch: 6| Step: 8
Training loss: 2.058973129030424
Validation loss: 2.332954236590171

Epoch: 6| Step: 9
Training loss: 2.070510336582274
Validation loss: 2.340807023439065

Epoch: 6| Step: 10
Training loss: 1.8146169073223046
Validation loss: 2.356071981424469

Epoch: 6| Step: 11
Training loss: 2.097772179495531
Validation loss: 2.3721180427402637

Epoch: 6| Step: 12
Training loss: 2.3876725459037305
Validation loss: 2.3744604958415496

Epoch: 6| Step: 13
Training loss: 1.844333362426059
Validation loss: 2.420879565655923

Epoch: 439| Step: 0
Training loss: 2.292453376520558
Validation loss: 2.4553283897477476

Epoch: 6| Step: 1
Training loss: 2.1282401346439337
Validation loss: 2.4801376564927566

Epoch: 6| Step: 2
Training loss: 2.199505260498527
Validation loss: 2.4659991267431556

Epoch: 6| Step: 3
Training loss: 2.3932733763443026
Validation loss: 2.507529013878333

Epoch: 6| Step: 4
Training loss: 1.912891886334649
Validation loss: 2.481447089472594

Epoch: 6| Step: 5
Training loss: 2.2523659876037594
Validation loss: 2.5035788289825733

Epoch: 6| Step: 6
Training loss: 1.7980470235104762
Validation loss: 2.4901499131621785

Epoch: 6| Step: 7
Training loss: 2.0464581946067084
Validation loss: 2.5023295838878035

Epoch: 6| Step: 8
Training loss: 1.559509773010961
Validation loss: 2.5116134552844005

Epoch: 6| Step: 9
Training loss: 1.8635823708259835
Validation loss: 2.511679892721916

Epoch: 6| Step: 10
Training loss: 1.897072132305701
Validation loss: 2.475625054783233

Epoch: 6| Step: 11
Training loss: 2.023071491616861
Validation loss: 2.4875887841288535

Epoch: 6| Step: 12
Training loss: 1.9754838374970103
Validation loss: 2.4605385067053196

Epoch: 6| Step: 13
Training loss: 1.3817559208971704
Validation loss: 2.4244258999845223

Epoch: 440| Step: 0
Training loss: 1.973451299309527
Validation loss: 2.3596795536185224

Epoch: 6| Step: 1
Training loss: 1.7335381765857294
Validation loss: 2.3545721682927576

Epoch: 6| Step: 2
Training loss: 2.5941871366623523
Validation loss: 2.3127689964512106

Epoch: 6| Step: 3
Training loss: 1.9575543037764973
Validation loss: 2.3363031039556175

Epoch: 6| Step: 4
Training loss: 1.5160348868872633
Validation loss: 2.3469326535393007

Epoch: 6| Step: 5
Training loss: 2.2862181193369477
Validation loss: 2.353696215469929

Epoch: 6| Step: 6
Training loss: 1.7486539841333921
Validation loss: 2.4144527965248215

Epoch: 6| Step: 7
Training loss: 2.2928207843615773
Validation loss: 2.4436036524044065

Epoch: 6| Step: 8
Training loss: 1.935891498945878
Validation loss: 2.5357605693115013

Epoch: 6| Step: 9
Training loss: 1.717266205224016
Validation loss: 2.543456696111424

Epoch: 6| Step: 10
Training loss: 2.2010908543485157
Validation loss: 2.5155117554889075

Epoch: 6| Step: 11
Training loss: 1.8039002125582435
Validation loss: 2.566507198111283

Epoch: 6| Step: 12
Training loss: 2.2639537040101696
Validation loss: 2.5125508230978255

Epoch: 6| Step: 13
Training loss: 1.8378934789264505
Validation loss: 2.4593092488361816

Epoch: 441| Step: 0
Training loss: 1.822219308344261
Validation loss: 2.426671990701234

Epoch: 6| Step: 1
Training loss: 2.097667956896743
Validation loss: 2.3911880987079868

Epoch: 6| Step: 2
Training loss: 2.0697070118051917
Validation loss: 2.3610112262515797

Epoch: 6| Step: 3
Training loss: 2.07512247114807
Validation loss: 2.2986753917998928

Epoch: 6| Step: 4
Training loss: 1.8315477200809807
Validation loss: 2.2759044498193326

Epoch: 6| Step: 5
Training loss: 2.2364436890173445
Validation loss: 2.2884858311592597

Epoch: 6| Step: 6
Training loss: 1.8719086913068403
Validation loss: 2.332974096044531

Epoch: 6| Step: 7
Training loss: 2.0619558136624407
Validation loss: 2.359248204020401

Epoch: 6| Step: 8
Training loss: 1.9866531391237952
Validation loss: 2.437646667384272

Epoch: 6| Step: 9
Training loss: 2.0200586571061283
Validation loss: 2.495363274334064

Epoch: 6| Step: 10
Training loss: 1.854168373992934
Validation loss: 2.5504541001212364

Epoch: 6| Step: 11
Training loss: 1.8474961709484845
Validation loss: 2.607222057645658

Epoch: 6| Step: 12
Training loss: 2.1533642684359986
Validation loss: 2.6248659372155547

Epoch: 6| Step: 13
Training loss: 2.2801700282695156
Validation loss: 2.593066400575137

Epoch: 442| Step: 0
Training loss: 1.9798218763550715
Validation loss: 2.5952363058297547

Epoch: 6| Step: 1
Training loss: 1.9628120976013248
Validation loss: 2.5371275278000756

Epoch: 6| Step: 2
Training loss: 2.2336817379486527
Validation loss: 2.4137875691467174

Epoch: 6| Step: 3
Training loss: 1.69402816571597
Validation loss: 2.3473327281670007

Epoch: 6| Step: 4
Training loss: 1.6043957468258452
Validation loss: 2.3063439341484697

Epoch: 6| Step: 5
Training loss: 2.1277365174483203
Validation loss: 2.3134156487135273

Epoch: 6| Step: 6
Training loss: 1.6050833357807393
Validation loss: 2.284925580326454

Epoch: 6| Step: 7
Training loss: 2.3183669850996624
Validation loss: 2.3114737450973717

Epoch: 6| Step: 8
Training loss: 1.8562706429203868
Validation loss: 2.3341953526339654

Epoch: 6| Step: 9
Training loss: 2.08080503272123
Validation loss: 2.3799445920164537

Epoch: 6| Step: 10
Training loss: 2.4863616869175305
Validation loss: 2.4726504377136

Epoch: 6| Step: 11
Training loss: 2.3244610315553236
Validation loss: 2.5755351044927934

Epoch: 6| Step: 12
Training loss: 2.2078432462998667
Validation loss: 2.548728977214778

Epoch: 6| Step: 13
Training loss: 1.4519066574054398
Validation loss: 2.542810134095669

Epoch: 443| Step: 0
Training loss: 2.543893953416303
Validation loss: 2.518364334758795

Epoch: 6| Step: 1
Training loss: 1.6363243775041385
Validation loss: 2.4615151931297046

Epoch: 6| Step: 2
Training loss: 2.272678209122008
Validation loss: 2.4046633853484276

Epoch: 6| Step: 3
Training loss: 1.60181644566353
Validation loss: 2.3765857424180004

Epoch: 6| Step: 4
Training loss: 1.9565259086868527
Validation loss: 2.3418372680833532

Epoch: 6| Step: 5
Training loss: 1.6244592500496962
Validation loss: 2.3240322276375087

Epoch: 6| Step: 6
Training loss: 2.2486165349857083
Validation loss: 2.372832337220595

Epoch: 6| Step: 7
Training loss: 1.799933442898583
Validation loss: 2.3922684294229652

Epoch: 6| Step: 8
Training loss: 1.9827329795529167
Validation loss: 2.4437757476179547

Epoch: 6| Step: 9
Training loss: 1.8387263766287663
Validation loss: 2.516227707546355

Epoch: 6| Step: 10
Training loss: 1.6857433359307727
Validation loss: 2.5273318393371653

Epoch: 6| Step: 11
Training loss: 2.347803501582587
Validation loss: 2.5558465257271927

Epoch: 6| Step: 12
Training loss: 2.422649432003265
Validation loss: 2.551571777452274

Epoch: 6| Step: 13
Training loss: 1.742776061400965
Validation loss: 2.4806167471829603

Epoch: 444| Step: 0
Training loss: 1.778322189472513
Validation loss: 2.399120386844842

Epoch: 6| Step: 1
Training loss: 2.239017491976385
Validation loss: 2.3701705544988827

Epoch: 6| Step: 2
Training loss: 1.844451253692028
Validation loss: 2.3544990558266936

Epoch: 6| Step: 3
Training loss: 1.7846367745863052
Validation loss: 2.3334901913716886

Epoch: 6| Step: 4
Training loss: 2.039477660494233
Validation loss: 2.367700093028637

Epoch: 6| Step: 5
Training loss: 1.6490309672967078
Validation loss: 2.3761361404894754

Epoch: 6| Step: 6
Training loss: 1.7315677227333228
Validation loss: 2.3818472233277834

Epoch: 6| Step: 7
Training loss: 2.431248693784544
Validation loss: 2.4258120141530672

Epoch: 6| Step: 8
Training loss: 2.096537542122092
Validation loss: 2.500721909776003

Epoch: 6| Step: 9
Training loss: 1.4332244979583106
Validation loss: 2.5264504649400923

Epoch: 6| Step: 10
Training loss: 2.410167724977748
Validation loss: 2.548400764122343

Epoch: 6| Step: 11
Training loss: 2.1807388450007523
Validation loss: 2.5720543401300535

Epoch: 6| Step: 12
Training loss: 2.327847150569555
Validation loss: 2.5054893739373454

Epoch: 6| Step: 13
Training loss: 1.8892042638500783
Validation loss: 2.4288778764037082

Epoch: 445| Step: 0
Training loss: 2.24347907425686
Validation loss: 2.4089487105919725

Epoch: 6| Step: 1
Training loss: 1.6361040586194704
Validation loss: 2.349587799096769

Epoch: 6| Step: 2
Training loss: 1.83944548813682
Validation loss: 2.3278951388961184

Epoch: 6| Step: 3
Training loss: 1.8015333744020599
Validation loss: 2.340326316997696

Epoch: 6| Step: 4
Training loss: 1.9023771498487685
Validation loss: 2.322321724869298

Epoch: 6| Step: 5
Training loss: 2.450809236122884
Validation loss: 2.327331646745534

Epoch: 6| Step: 6
Training loss: 2.1453307837966427
Validation loss: 2.3381296527504194

Epoch: 6| Step: 7
Training loss: 1.5338514378711756
Validation loss: 2.324878594894729

Epoch: 6| Step: 8
Training loss: 2.292657418373906
Validation loss: 2.36872014527914

Epoch: 6| Step: 9
Training loss: 2.1971398618522864
Validation loss: 2.405725544227622

Epoch: 6| Step: 10
Training loss: 1.8519092347826582
Validation loss: 2.4364852807261457

Epoch: 6| Step: 11
Training loss: 2.2627989934974657
Validation loss: 2.4410920386471147

Epoch: 6| Step: 12
Training loss: 1.9144050135985615
Validation loss: 2.4208814998652146

Epoch: 6| Step: 13
Training loss: 1.6104556409191804
Validation loss: 2.4637837404966754

Epoch: 446| Step: 0
Training loss: 2.1155169325574437
Validation loss: 2.5095388216867427

Epoch: 6| Step: 1
Training loss: 2.0348012545024408
Validation loss: 2.5889771545516247

Epoch: 6| Step: 2
Training loss: 2.011046776992447
Validation loss: 2.5648078620310004

Epoch: 6| Step: 3
Training loss: 2.1144698038928595
Validation loss: 2.485535394824567

Epoch: 6| Step: 4
Training loss: 1.9594564125876366
Validation loss: 2.404377197188534

Epoch: 6| Step: 5
Training loss: 1.6074060042977902
Validation loss: 2.3497186169832904

Epoch: 6| Step: 6
Training loss: 2.1014252231390067
Validation loss: 2.3129094167993682

Epoch: 6| Step: 7
Training loss: 1.8585957408892764
Validation loss: 2.318668803493899

Epoch: 6| Step: 8
Training loss: 2.2083907809672594
Validation loss: 2.330218840098671

Epoch: 6| Step: 9
Training loss: 1.8033379467019648
Validation loss: 2.371380323614591

Epoch: 6| Step: 10
Training loss: 1.401113581554814
Validation loss: 2.3990341021171493

Epoch: 6| Step: 11
Training loss: 2.750289815023114
Validation loss: 2.4558070773133367

Epoch: 6| Step: 12
Training loss: 2.0496521957109133
Validation loss: 2.4868562277660407

Epoch: 6| Step: 13
Training loss: 2.314813024166969
Validation loss: 2.482844784317765

Epoch: 447| Step: 0
Training loss: 1.3611263087239465
Validation loss: 2.4481816958449634

Epoch: 6| Step: 1
Training loss: 1.633680341150547
Validation loss: 2.432129129186362

Epoch: 6| Step: 2
Training loss: 2.1058148894001083
Validation loss: 2.4024505001921037

Epoch: 6| Step: 3
Training loss: 2.078097924077608
Validation loss: 2.3513828272042274

Epoch: 6| Step: 4
Training loss: 1.8038682275253342
Validation loss: 2.348461664957668

Epoch: 6| Step: 5
Training loss: 2.2358591979022826
Validation loss: 2.321843261307499

Epoch: 6| Step: 6
Training loss: 1.7927947448202357
Validation loss: 2.343169310904539

Epoch: 6| Step: 7
Training loss: 1.666167883942212
Validation loss: 2.382541333763997

Epoch: 6| Step: 8
Training loss: 1.9968952279417023
Validation loss: 2.4471342394613735

Epoch: 6| Step: 9
Training loss: 2.4070571932683773
Validation loss: 2.4717071556699426

Epoch: 6| Step: 10
Training loss: 1.8080435589547839
Validation loss: 2.490072264054516

Epoch: 6| Step: 11
Training loss: 2.4281500462795362
Validation loss: 2.537782902902271

Epoch: 6| Step: 12
Training loss: 2.105641656969946
Validation loss: 2.5233366667450663

Epoch: 6| Step: 13
Training loss: 2.402114782819524
Validation loss: 2.4846827313270516

Epoch: 448| Step: 0
Training loss: 2.110150004112494
Validation loss: 2.5044340272029184

Epoch: 6| Step: 1
Training loss: 1.7157425664701518
Validation loss: 2.4923574326883338

Epoch: 6| Step: 2
Training loss: 1.6298983180621052
Validation loss: 2.4303881014923334

Epoch: 6| Step: 3
Training loss: 2.1818510959772417
Validation loss: 2.4094163570645435

Epoch: 6| Step: 4
Training loss: 1.8267373581361803
Validation loss: 2.4218562786689968

Epoch: 6| Step: 5
Training loss: 1.9179230041642297
Validation loss: 2.4199572085712067

Epoch: 6| Step: 6
Training loss: 2.0686038469854346
Validation loss: 2.4447481233458213

Epoch: 6| Step: 7
Training loss: 1.3952349001503637
Validation loss: 2.4393727765109396

Epoch: 6| Step: 8
Training loss: 2.0774147139210606
Validation loss: 2.4179100233454185

Epoch: 6| Step: 9
Training loss: 1.7932578790784874
Validation loss: 2.375910855783322

Epoch: 6| Step: 10
Training loss: 2.503981757252939
Validation loss: 2.3448612589428595

Epoch: 6| Step: 11
Training loss: 1.9618311817517222
Validation loss: 2.3473119062251833

Epoch: 6| Step: 12
Training loss: 2.1540727542006106
Validation loss: 2.382815362937656

Epoch: 6| Step: 13
Training loss: 2.58272378149508
Validation loss: 2.4227748441626633

Epoch: 449| Step: 0
Training loss: 2.08637521558855
Validation loss: 2.445877361689194

Epoch: 6| Step: 1
Training loss: 1.5548783381665698
Validation loss: 2.496755731439978

Epoch: 6| Step: 2
Training loss: 2.3698049244492356
Validation loss: 2.538493238170087

Epoch: 6| Step: 3
Training loss: 2.1732366670668855
Validation loss: 2.483756953001079

Epoch: 6| Step: 4
Training loss: 1.717913406681086
Validation loss: 2.441715853184934

Epoch: 6| Step: 5
Training loss: 1.6428244969577748
Validation loss: 2.4188416336286647

Epoch: 6| Step: 6
Training loss: 2.0104089713731716
Validation loss: 2.3773280414706925

Epoch: 6| Step: 7
Training loss: 1.9540957060444475
Validation loss: 2.3196398954582027

Epoch: 6| Step: 8
Training loss: 2.0541446099119156
Validation loss: 2.33072463751416

Epoch: 6| Step: 9
Training loss: 1.9493864365731743
Validation loss: 2.342045613427256

Epoch: 6| Step: 10
Training loss: 2.1429078118827865
Validation loss: 2.348501842982075

Epoch: 6| Step: 11
Training loss: 1.550399464230991
Validation loss: 2.385962943922761

Epoch: 6| Step: 12
Training loss: 1.9808506945324125
Validation loss: 2.47625478344971

Epoch: 6| Step: 13
Training loss: 2.529747411007861
Validation loss: 2.5445645480273558

Epoch: 450| Step: 0
Training loss: 2.215909079349402
Validation loss: 2.6150101340825787

Epoch: 6| Step: 1
Training loss: 2.2394969361666046
Validation loss: 2.540096121162594

Epoch: 6| Step: 2
Training loss: 2.1535829275800724
Validation loss: 2.490750390447534

Epoch: 6| Step: 3
Training loss: 2.06220960017613
Validation loss: 2.4381026560805634

Epoch: 6| Step: 4
Training loss: 2.60029181530059
Validation loss: 2.4206499286073746

Epoch: 6| Step: 5
Training loss: 1.419184728221158
Validation loss: 2.4241631100972207

Epoch: 6| Step: 6
Training loss: 1.876029876157942
Validation loss: 2.413735004005733

Epoch: 6| Step: 7
Training loss: 2.242055643172149
Validation loss: 2.414242318373554

Epoch: 6| Step: 8
Training loss: 2.334494256544207
Validation loss: 2.395571535920357

Epoch: 6| Step: 9
Training loss: 1.2964425342563033
Validation loss: 2.400775135392451

Epoch: 6| Step: 10
Training loss: 1.3577090172353492
Validation loss: 2.3952569358251568

Epoch: 6| Step: 11
Training loss: 1.8425836268252473
Validation loss: 2.402990382184058

Epoch: 6| Step: 12
Training loss: 1.7328963291264714
Validation loss: 2.4584833151184236

Epoch: 6| Step: 13
Training loss: 1.6810809365961423
Validation loss: 2.4441856291620607

Epoch: 451| Step: 0
Training loss: 2.0359100878634737
Validation loss: 2.4545475268466554

Epoch: 6| Step: 1
Training loss: 1.513708810663271
Validation loss: 2.4277433465954177

Epoch: 6| Step: 2
Training loss: 1.7458599027859136
Validation loss: 2.421428851827101

Epoch: 6| Step: 3
Training loss: 1.8641585677813246
Validation loss: 2.4884140111365527

Epoch: 6| Step: 4
Training loss: 1.8017185113853937
Validation loss: 2.5186038995038165

Epoch: 6| Step: 5
Training loss: 2.118461985409289
Validation loss: 2.5258905898191726

Epoch: 6| Step: 6
Training loss: 1.9628773854886215
Validation loss: 2.510500789092912

Epoch: 6| Step: 7
Training loss: 1.9574242842489475
Validation loss: 2.4703081752975886

Epoch: 6| Step: 8
Training loss: 2.0035176337208442
Validation loss: 2.4756292446266075

Epoch: 6| Step: 9
Training loss: 2.10823650012087
Validation loss: 2.4447208252102874

Epoch: 6| Step: 10
Training loss: 2.3219670520058173
Validation loss: 2.3883809240552303

Epoch: 6| Step: 11
Training loss: 2.329872243759561
Validation loss: 2.3767332802009826

Epoch: 6| Step: 12
Training loss: 1.8342766574577458
Validation loss: 2.3882013225585688

Epoch: 6| Step: 13
Training loss: 1.668283115752848
Validation loss: 2.3570456346934345

Epoch: 452| Step: 0
Training loss: 1.9485018526048397
Validation loss: 2.384572260421603

Epoch: 6| Step: 1
Training loss: 2.0942986751572423
Validation loss: 2.3945072636383813

Epoch: 6| Step: 2
Training loss: 1.692582987521503
Validation loss: 2.416409112432955

Epoch: 6| Step: 3
Training loss: 2.421492417173389
Validation loss: 2.4641397310411155

Epoch: 6| Step: 4
Training loss: 1.9478255741899124
Validation loss: 2.4562235671546286

Epoch: 6| Step: 5
Training loss: 2.067128853748127
Validation loss: 2.4770983427521975

Epoch: 6| Step: 6
Training loss: 1.714156306298374
Validation loss: 2.485879075547621

Epoch: 6| Step: 7
Training loss: 1.645071489119906
Validation loss: 2.486580428376287

Epoch: 6| Step: 8
Training loss: 1.8219422997007124
Validation loss: 2.4810035548255707

Epoch: 6| Step: 9
Training loss: 1.9987520854621776
Validation loss: 2.4579927185198254

Epoch: 6| Step: 10
Training loss: 2.0583338419595725
Validation loss: 2.459218446379344

Epoch: 6| Step: 11
Training loss: 1.5920230260171027
Validation loss: 2.4299552144033343

Epoch: 6| Step: 12
Training loss: 2.251464790802564
Validation loss: 2.4300529490821594

Epoch: 6| Step: 13
Training loss: 1.6815093340335328
Validation loss: 2.43875912018126

Epoch: 453| Step: 0
Training loss: 1.5818668232935928
Validation loss: 2.464947200666368

Epoch: 6| Step: 1
Training loss: 1.915792936397234
Validation loss: 2.475578207999163

Epoch: 6| Step: 2
Training loss: 2.57260873370132
Validation loss: 2.4789383651194896

Epoch: 6| Step: 3
Training loss: 1.6288378950454774
Validation loss: 2.4655890992144074

Epoch: 6| Step: 4
Training loss: 1.815381423448171
Validation loss: 2.4408889173829746

Epoch: 6| Step: 5
Training loss: 1.4759477415422098
Validation loss: 2.427432660454859

Epoch: 6| Step: 6
Training loss: 1.8459308463603608
Validation loss: 2.4484111055273017

Epoch: 6| Step: 7
Training loss: 2.039030579064978
Validation loss: 2.420064009160015

Epoch: 6| Step: 8
Training loss: 2.08171116299053
Validation loss: 2.4409028336826255

Epoch: 6| Step: 9
Training loss: 2.254252124607269
Validation loss: 2.45376179543961

Epoch: 6| Step: 10
Training loss: 2.724325317013804
Validation loss: 2.4954532059013093

Epoch: 6| Step: 11
Training loss: 1.5473836967876546
Validation loss: 2.451117548062507

Epoch: 6| Step: 12
Training loss: 1.781855563911079
Validation loss: 2.4401632315316317

Epoch: 6| Step: 13
Training loss: 1.537166686486162
Validation loss: 2.3949913082529837

Epoch: 454| Step: 0
Training loss: 2.1029792179635356
Validation loss: 2.365624738436845

Epoch: 6| Step: 1
Training loss: 1.5998983529704776
Validation loss: 2.409820913578591

Epoch: 6| Step: 2
Training loss: 2.3909970660923565
Validation loss: 2.4305174547325548

Epoch: 6| Step: 3
Training loss: 1.8484566307851409
Validation loss: 2.416017095687856

Epoch: 6| Step: 4
Training loss: 1.69582081570641
Validation loss: 2.416833192549688

Epoch: 6| Step: 5
Training loss: 2.189895734874234
Validation loss: 2.418356553546985

Epoch: 6| Step: 6
Training loss: 2.07651796085077
Validation loss: 2.3938238018967293

Epoch: 6| Step: 7
Training loss: 2.345767360954353
Validation loss: 2.378492086150079

Epoch: 6| Step: 8
Training loss: 1.74893155860362
Validation loss: 2.392238624900767

Epoch: 6| Step: 9
Training loss: 1.7382401707970854
Validation loss: 2.4128987805166706

Epoch: 6| Step: 10
Training loss: 1.7844254815598528
Validation loss: 2.428196747028497

Epoch: 6| Step: 11
Training loss: 1.8499882439935744
Validation loss: 2.477774590029233

Epoch: 6| Step: 12
Training loss: 1.906266822115356
Validation loss: 2.4657678522479007

Epoch: 6| Step: 13
Training loss: 1.7311875204662452
Validation loss: 2.493626653775947

Epoch: 455| Step: 0
Training loss: 1.8154788038843956
Validation loss: 2.4508639945767063

Epoch: 6| Step: 1
Training loss: 2.2630973659578095
Validation loss: 2.4640824252276325

Epoch: 6| Step: 2
Training loss: 1.9244588834513583
Validation loss: 2.4603796687881907

Epoch: 6| Step: 3
Training loss: 1.756764553076561
Validation loss: 2.47175879911027

Epoch: 6| Step: 4
Training loss: 2.3364585882133744
Validation loss: 2.424220662657911

Epoch: 6| Step: 5
Training loss: 1.9974830406146968
Validation loss: 2.427710765268792

Epoch: 6| Step: 6
Training loss: 1.9332170215784756
Validation loss: 2.3983698806618143

Epoch: 6| Step: 7
Training loss: 1.8181380353337708
Validation loss: 2.3790651115441865

Epoch: 6| Step: 8
Training loss: 2.070245936061416
Validation loss: 2.358538817306636

Epoch: 6| Step: 9
Training loss: 1.8663896587875093
Validation loss: 2.3722471637680584

Epoch: 6| Step: 10
Training loss: 1.9490686637875145
Validation loss: 2.391776053163988

Epoch: 6| Step: 11
Training loss: 1.6648099411637816
Validation loss: 2.4227132383325563

Epoch: 6| Step: 12
Training loss: 1.9006716294042656
Validation loss: 2.44393960778276

Epoch: 6| Step: 13
Training loss: 1.8490904066885274
Validation loss: 2.4602385195475085

Epoch: 456| Step: 0
Training loss: 1.837227810272915
Validation loss: 2.5021021408578172

Epoch: 6| Step: 1
Training loss: 1.925939093073369
Validation loss: 2.482733663829584

Epoch: 6| Step: 2
Training loss: 1.6113153260618578
Validation loss: 2.5374431995343145

Epoch: 6| Step: 3
Training loss: 1.8312064390241773
Validation loss: 2.5477670838167334

Epoch: 6| Step: 4
Training loss: 1.7579789146486842
Validation loss: 2.5465307928548917

Epoch: 6| Step: 5
Training loss: 2.067502053939002
Validation loss: 2.503676153280499

Epoch: 6| Step: 6
Training loss: 1.946149959847388
Validation loss: 2.5439632522605176

Epoch: 6| Step: 7
Training loss: 2.1184368881177433
Validation loss: 2.4985445431190376

Epoch: 6| Step: 8
Training loss: 1.670960363314044
Validation loss: 2.4090992349194305

Epoch: 6| Step: 9
Training loss: 2.261833227551353
Validation loss: 2.3633731046877444

Epoch: 6| Step: 10
Training loss: 1.9966926049642373
Validation loss: 2.341735645823046

Epoch: 6| Step: 11
Training loss: 2.3218824424983766
Validation loss: 2.3465244314792706

Epoch: 6| Step: 12
Training loss: 2.0289063064052266
Validation loss: 2.370673586420329

Epoch: 6| Step: 13
Training loss: 1.5406360618085857
Validation loss: 2.4064087343270866

Epoch: 457| Step: 0
Training loss: 1.3829948606774862
Validation loss: 2.443770501318006

Epoch: 6| Step: 1
Training loss: 1.9550165401061503
Validation loss: 2.4537535542031015

Epoch: 6| Step: 2
Training loss: 1.6163065256853801
Validation loss: 2.449419895762484

Epoch: 6| Step: 3
Training loss: 1.4994696633277496
Validation loss: 2.504599324368645

Epoch: 6| Step: 4
Training loss: 1.9919898439975736
Validation loss: 2.5310881915040864

Epoch: 6| Step: 5
Training loss: 2.040011714826868
Validation loss: 2.5000420710397466

Epoch: 6| Step: 6
Training loss: 2.1851329530818124
Validation loss: 2.472738359786349

Epoch: 6| Step: 7
Training loss: 1.7461805898078469
Validation loss: 2.510618333899145

Epoch: 6| Step: 8
Training loss: 2.223727593225958
Validation loss: 2.4841960028067867

Epoch: 6| Step: 9
Training loss: 1.8702933684145775
Validation loss: 2.5055257538885014

Epoch: 6| Step: 10
Training loss: 1.9036876779976561
Validation loss: 2.5147012502283754

Epoch: 6| Step: 11
Training loss: 1.650383907507594
Validation loss: 2.528126486756489

Epoch: 6| Step: 12
Training loss: 2.6696023477760624
Validation loss: 2.4926540799380565

Epoch: 6| Step: 13
Training loss: 2.1931599010822462
Validation loss: 2.453162176361142

Epoch: 458| Step: 0
Training loss: 1.8715955344135242
Validation loss: 2.4074020504486513

Epoch: 6| Step: 1
Training loss: 1.530203169503879
Validation loss: 2.408464514101253

Epoch: 6| Step: 2
Training loss: 2.244076454832107
Validation loss: 2.381039295580502

Epoch: 6| Step: 3
Training loss: 1.8976734649015565
Validation loss: 2.43091211503612

Epoch: 6| Step: 4
Training loss: 2.010756416140769
Validation loss: 2.4512479367556295

Epoch: 6| Step: 5
Training loss: 1.8280719195101738
Validation loss: 2.4589302571602

Epoch: 6| Step: 6
Training loss: 2.3858455178068145
Validation loss: 2.4794897391341397

Epoch: 6| Step: 7
Training loss: 1.478710408652164
Validation loss: 2.472103598667905

Epoch: 6| Step: 8
Training loss: 2.0033837542586275
Validation loss: 2.49499402760575

Epoch: 6| Step: 9
Training loss: 1.6071649580147358
Validation loss: 2.4997090939500177

Epoch: 6| Step: 10
Training loss: 1.913210060100517
Validation loss: 2.5031521849255585

Epoch: 6| Step: 11
Training loss: 1.7337129721231979
Validation loss: 2.5080957210303447

Epoch: 6| Step: 12
Training loss: 1.8209679205392544
Validation loss: 2.5305301721883944

Epoch: 6| Step: 13
Training loss: 2.493053704287362
Validation loss: 2.491853055637063

Epoch: 459| Step: 0
Training loss: 2.2004675021659326
Validation loss: 2.460837680128891

Epoch: 6| Step: 1
Training loss: 1.708997279527172
Validation loss: 2.434342201775779

Epoch: 6| Step: 2
Training loss: 2.463345950674626
Validation loss: 2.4136387541083644

Epoch: 6| Step: 3
Training loss: 1.1572369667583453
Validation loss: 2.4416607976969824

Epoch: 6| Step: 4
Training loss: 2.313422148077883
Validation loss: 2.483687391503711

Epoch: 6| Step: 5
Training loss: 2.01877507527843
Validation loss: 2.4937421021136084

Epoch: 6| Step: 6
Training loss: 1.946819533634103
Validation loss: 2.4737929778005374

Epoch: 6| Step: 7
Training loss: 1.4226746877934562
Validation loss: 2.467390993501592

Epoch: 6| Step: 8
Training loss: 2.216080254833253
Validation loss: 2.4123481195583554

Epoch: 6| Step: 9
Training loss: 1.8727922793601162
Validation loss: 2.377688484317317

Epoch: 6| Step: 10
Training loss: 1.8718836636096008
Validation loss: 2.3718009327026137

Epoch: 6| Step: 11
Training loss: 1.8379570425034124
Validation loss: 2.3774935337836736

Epoch: 6| Step: 12
Training loss: 1.8525263213270997
Validation loss: 2.4015266181943096

Epoch: 6| Step: 13
Training loss: 1.8242558673619478
Validation loss: 2.391379226482732

Epoch: 460| Step: 0
Training loss: 1.7091624488697927
Validation loss: 2.408476841759751

Epoch: 6| Step: 1
Training loss: 1.9218558954049174
Validation loss: 2.434458272216009

Epoch: 6| Step: 2
Training loss: 2.4286471282957716
Validation loss: 2.4247675436784366

Epoch: 6| Step: 3
Training loss: 1.9352390263902586
Validation loss: 2.443396470168058

Epoch: 6| Step: 4
Training loss: 2.2584479998466813
Validation loss: 2.4758679183344863

Epoch: 6| Step: 5
Training loss: 1.7692071142018688
Validation loss: 2.4938790061944194

Epoch: 6| Step: 6
Training loss: 1.8691856514381433
Validation loss: 2.4880740952212537

Epoch: 6| Step: 7
Training loss: 1.7944563136316785
Validation loss: 2.4925607067580864

Epoch: 6| Step: 8
Training loss: 1.9877911096581518
Validation loss: 2.458674650307603

Epoch: 6| Step: 9
Training loss: 2.0490936601790644
Validation loss: 2.493704255945618

Epoch: 6| Step: 10
Training loss: 1.1806719379777662
Validation loss: 2.4461037835962616

Epoch: 6| Step: 11
Training loss: 2.17426130532094
Validation loss: 2.459993017698474

Epoch: 6| Step: 12
Training loss: 1.782307896260563
Validation loss: 2.4189641082907913

Epoch: 6| Step: 13
Training loss: 1.6475670853242732
Validation loss: 2.436993130006962

Epoch: 461| Step: 0
Training loss: 1.9539926051504561
Validation loss: 2.403549516819217

Epoch: 6| Step: 1
Training loss: 1.866544732584519
Validation loss: 2.3701586873977605

Epoch: 6| Step: 2
Training loss: 1.7142873917298966
Validation loss: 2.375796028674453

Epoch: 6| Step: 3
Training loss: 1.8346371854868788
Validation loss: 2.350651055379254

Epoch: 6| Step: 4
Training loss: 1.91201492091865
Validation loss: 2.393840454949134

Epoch: 6| Step: 5
Training loss: 1.2419973743736537
Validation loss: 2.4051950009332574

Epoch: 6| Step: 6
Training loss: 2.8902551362825424
Validation loss: 2.3963139298521297

Epoch: 6| Step: 7
Training loss: 2.159242074411061
Validation loss: 2.446907245517445

Epoch: 6| Step: 8
Training loss: 1.5037534165442665
Validation loss: 2.474734006219351

Epoch: 6| Step: 9
Training loss: 1.8519163799522838
Validation loss: 2.502095235592192

Epoch: 6| Step: 10
Training loss: 1.7233597406741192
Validation loss: 2.483404680911786

Epoch: 6| Step: 11
Training loss: 1.8968223954122718
Validation loss: 2.494351281211411

Epoch: 6| Step: 12
Training loss: 1.708085561632717
Validation loss: 2.4663418309284264

Epoch: 6| Step: 13
Training loss: 2.2817349898161314
Validation loss: 2.451067196543638

Epoch: 462| Step: 0
Training loss: 2.393104314747058
Validation loss: 2.4353252834769132

Epoch: 6| Step: 1
Training loss: 1.6827781454137467
Validation loss: 2.4387995334991635

Epoch: 6| Step: 2
Training loss: 1.763520936643192
Validation loss: 2.43864756564645

Epoch: 6| Step: 3
Training loss: 2.220300911450999
Validation loss: 2.388053544291553

Epoch: 6| Step: 4
Training loss: 1.9669786386304482
Validation loss: 2.3648953918765385

Epoch: 6| Step: 5
Training loss: 1.416262017221803
Validation loss: 2.3571978627070047

Epoch: 6| Step: 6
Training loss: 1.869289539747011
Validation loss: 2.3854753279540457

Epoch: 6| Step: 7
Training loss: 1.4722518568035328
Validation loss: 2.405099685177568

Epoch: 6| Step: 8
Training loss: 2.170727433485056
Validation loss: 2.4007838724329185

Epoch: 6| Step: 9
Training loss: 2.0723180881082857
Validation loss: 2.4336741860518374

Epoch: 6| Step: 10
Training loss: 1.8474921704076062
Validation loss: 2.479076145663861

Epoch: 6| Step: 11
Training loss: 1.9026309820694773
Validation loss: 2.4997180605413423

Epoch: 6| Step: 12
Training loss: 1.7020806426544899
Validation loss: 2.544313400936363

Epoch: 6| Step: 13
Training loss: 2.0638255859063643
Validation loss: 2.571391261559799

Epoch: 463| Step: 0
Training loss: 2.0344686975890602
Validation loss: 2.6008795671105567

Epoch: 6| Step: 1
Training loss: 1.781749253828573
Validation loss: 2.5319663406132187

Epoch: 6| Step: 2
Training loss: 1.6706704765092701
Validation loss: 2.486151828303732

Epoch: 6| Step: 3
Training loss: 2.1741205037680835
Validation loss: 2.4782824281541362

Epoch: 6| Step: 4
Training loss: 1.6684662481225887
Validation loss: 2.4122302466103522

Epoch: 6| Step: 5
Training loss: 1.868998076644569
Validation loss: 2.377902409314379

Epoch: 6| Step: 6
Training loss: 1.9015678687791726
Validation loss: 2.358913822326445

Epoch: 6| Step: 7
Training loss: 2.110577276004904
Validation loss: 2.348202289148872

Epoch: 6| Step: 8
Training loss: 2.194893467779223
Validation loss: 2.3442380794822353

Epoch: 6| Step: 9
Training loss: 2.0146547096439567
Validation loss: 2.3691925348022105

Epoch: 6| Step: 10
Training loss: 1.4515781988931327
Validation loss: 2.3884426973564477

Epoch: 6| Step: 11
Training loss: 2.328954459289319
Validation loss: 2.425797198583019

Epoch: 6| Step: 12
Training loss: 1.8876658840421445
Validation loss: 2.4776028790261138

Epoch: 6| Step: 13
Training loss: 1.2496604458245442
Validation loss: 2.5080818351351017

Epoch: 464| Step: 0
Training loss: 2.0939424340934885
Validation loss: 2.530674281366764

Epoch: 6| Step: 1
Training loss: 1.5322837454225657
Validation loss: 2.5249603795521334

Epoch: 6| Step: 2
Training loss: 1.6964024147369101
Validation loss: 2.5442515972546906

Epoch: 6| Step: 3
Training loss: 1.6800749575831861
Validation loss: 2.496346170352664

Epoch: 6| Step: 4
Training loss: 2.062875193368597
Validation loss: 2.4645408822756694

Epoch: 6| Step: 5
Training loss: 1.840950537813325
Validation loss: 2.4413206365197175

Epoch: 6| Step: 6
Training loss: 1.6888891789299454
Validation loss: 2.395396147685806

Epoch: 6| Step: 7
Training loss: 2.438630355488849
Validation loss: 2.3656852160188775

Epoch: 6| Step: 8
Training loss: 2.127932824687912
Validation loss: 2.365183393947932

Epoch: 6| Step: 9
Training loss: 1.645761206611771
Validation loss: 2.388721027169909

Epoch: 6| Step: 10
Training loss: 2.1208235145246626
Validation loss: 2.4726218156844144

Epoch: 6| Step: 11
Training loss: 1.8028973043924457
Validation loss: 2.5144789162768046

Epoch: 6| Step: 12
Training loss: 2.080747512781063
Validation loss: 2.567314224700932

Epoch: 6| Step: 13
Training loss: 2.3092546114171912
Validation loss: 2.5751738640812176

Epoch: 465| Step: 0
Training loss: 1.7189143709133596
Validation loss: 2.4593995168455507

Epoch: 6| Step: 1
Training loss: 2.236365225538322
Validation loss: 2.331401579236261

Epoch: 6| Step: 2
Training loss: 1.8658495462771514
Validation loss: 2.2483558538313586

Epoch: 6| Step: 3
Training loss: 1.7829921300931535
Validation loss: 2.255396201219517

Epoch: 6| Step: 4
Training loss: 2.3162361069667643
Validation loss: 2.313967869975673

Epoch: 6| Step: 5
Training loss: 2.1671288315272177
Validation loss: 2.3339249817402563

Epoch: 6| Step: 6
Training loss: 2.1917854837717488
Validation loss: 2.4267186765811606

Epoch: 6| Step: 7
Training loss: 1.900780005715273
Validation loss: 2.479888941785228

Epoch: 6| Step: 8
Training loss: 1.8963951773444783
Validation loss: 2.547287937260343

Epoch: 6| Step: 9
Training loss: 2.3800434970887965
Validation loss: 2.6024410950992563

Epoch: 6| Step: 10
Training loss: 1.7705957440330196
Validation loss: 2.5289387686237523

Epoch: 6| Step: 11
Training loss: 1.6211238996160948
Validation loss: 2.4739364054840944

Epoch: 6| Step: 12
Training loss: 1.557310871869148
Validation loss: 2.4173142746846668

Epoch: 6| Step: 13
Training loss: 1.7856219662916606
Validation loss: 2.3595503994703266

Epoch: 466| Step: 0
Training loss: 2.1838704106237508
Validation loss: 2.308905489307834

Epoch: 6| Step: 1
Training loss: 1.847374989431696
Validation loss: 2.3354390347444296

Epoch: 6| Step: 2
Training loss: 2.002898500107631
Validation loss: 2.346235563837467

Epoch: 6| Step: 3
Training loss: 1.6233453395851218
Validation loss: 2.365602928762309

Epoch: 6| Step: 4
Training loss: 1.9620714290654984
Validation loss: 2.367076618710337

Epoch: 6| Step: 5
Training loss: 1.6351600089214513
Validation loss: 2.43349389359716

Epoch: 6| Step: 6
Training loss: 1.9847980558932468
Validation loss: 2.5128829626644147

Epoch: 6| Step: 7
Training loss: 1.5661497595784033
Validation loss: 2.5474997979019864

Epoch: 6| Step: 8
Training loss: 2.000705594528231
Validation loss: 2.558146306096821

Epoch: 6| Step: 9
Training loss: 1.9436837237181053
Validation loss: 2.5032401325181457

Epoch: 6| Step: 10
Training loss: 1.736685167984089
Validation loss: 2.5079616803443816

Epoch: 6| Step: 11
Training loss: 2.2843437641476583
Validation loss: 2.440770645588853

Epoch: 6| Step: 12
Training loss: 1.8088857855771496
Validation loss: 2.4200431699774456

Epoch: 6| Step: 13
Training loss: 2.330677655608039
Validation loss: 2.3696389027475293

Epoch: 467| Step: 0
Training loss: 2.21382109430402
Validation loss: 2.3588242252298364

Epoch: 6| Step: 1
Training loss: 2.156829203338045
Validation loss: 2.334602697005082

Epoch: 6| Step: 2
Training loss: 1.8345666840463692
Validation loss: 2.310009329846736

Epoch: 6| Step: 3
Training loss: 1.6887036022529849
Validation loss: 2.316711729910855

Epoch: 6| Step: 4
Training loss: 2.1864957411572137
Validation loss: 2.3398246056977037

Epoch: 6| Step: 5
Training loss: 2.1189466537090187
Validation loss: 2.4015094857523835

Epoch: 6| Step: 6
Training loss: 1.7994744116301216
Validation loss: 2.4649938724839946

Epoch: 6| Step: 7
Training loss: 1.6787901144567856
Validation loss: 2.5213401462593272

Epoch: 6| Step: 8
Training loss: 1.6219278786331865
Validation loss: 2.5646915278584568

Epoch: 6| Step: 9
Training loss: 1.8243005640279228
Validation loss: 2.58610193259974

Epoch: 6| Step: 10
Training loss: 2.1259571612501853
Validation loss: 2.5790290468055335

Epoch: 6| Step: 11
Training loss: 2.1850587574196867
Validation loss: 2.559729719636657

Epoch: 6| Step: 12
Training loss: 1.3835961659010263
Validation loss: 2.470704575586483

Epoch: 6| Step: 13
Training loss: 1.6687069405133008
Validation loss: 2.396457832200735

Epoch: 468| Step: 0
Training loss: 2.0153056046907256
Validation loss: 2.30991372776468

Epoch: 6| Step: 1
Training loss: 2.2536753200655824
Validation loss: 2.28507507870002

Epoch: 6| Step: 2
Training loss: 1.9577413705872608
Validation loss: 2.2204828123733042

Epoch: 6| Step: 3
Training loss: 1.8454579346895166
Validation loss: 2.264129884242864

Epoch: 6| Step: 4
Training loss: 1.7809168186114792
Validation loss: 2.2864011055242397

Epoch: 6| Step: 5
Training loss: 2.1411936206599314
Validation loss: 2.3471746744691506

Epoch: 6| Step: 6
Training loss: 1.9678826010740853
Validation loss: 2.386225153410037

Epoch: 6| Step: 7
Training loss: 1.7182408358927437
Validation loss: 2.474457311562981

Epoch: 6| Step: 8
Training loss: 2.1724672676315895
Validation loss: 2.5355845894580127

Epoch: 6| Step: 9
Training loss: 1.9595483973922185
Validation loss: 2.6138839361477126

Epoch: 6| Step: 10
Training loss: 1.7052480082089914
Validation loss: 2.59262569516309

Epoch: 6| Step: 11
Training loss: 2.038360240921913
Validation loss: 2.6769609167539317

Epoch: 6| Step: 12
Training loss: 2.0050702200220414
Validation loss: 2.6636967864921512

Epoch: 6| Step: 13
Training loss: 1.2655728176332557
Validation loss: 2.531883125118487

Epoch: 469| Step: 0
Training loss: 2.07926381966522
Validation loss: 2.4447020402625386

Epoch: 6| Step: 1
Training loss: 1.7688171427892834
Validation loss: 2.377293042695668

Epoch: 6| Step: 2
Training loss: 1.781943136174921
Validation loss: 2.355955402829156

Epoch: 6| Step: 3
Training loss: 2.087281554893396
Validation loss: 2.307522806169489

Epoch: 6| Step: 4
Training loss: 2.1728754826632795
Validation loss: 2.3472457607951682

Epoch: 6| Step: 5
Training loss: 2.100525327098027
Validation loss: 2.3451847997859114

Epoch: 6| Step: 6
Training loss: 1.827157963004633
Validation loss: 2.398192463161769

Epoch: 6| Step: 7
Training loss: 1.8476807026122077
Validation loss: 2.403643797085209

Epoch: 6| Step: 8
Training loss: 1.7769964193158845
Validation loss: 2.443258374242324

Epoch: 6| Step: 9
Training loss: 1.752342223440144
Validation loss: 2.4821637018091915

Epoch: 6| Step: 10
Training loss: 1.5281324764763102
Validation loss: 2.4927818188124897

Epoch: 6| Step: 11
Training loss: 2.025312225384157
Validation loss: 2.4963095713842214

Epoch: 6| Step: 12
Training loss: 1.7596949013778094
Validation loss: 2.5133931072906814

Epoch: 6| Step: 13
Training loss: 1.9330505841223495
Validation loss: 2.4819295152591847

Epoch: 470| Step: 0
Training loss: 1.9756090480567126
Validation loss: 2.484296805085779

Epoch: 6| Step: 1
Training loss: 1.8960868819607084
Validation loss: 2.467789318312922

Epoch: 6| Step: 2
Training loss: 1.9622529013995376
Validation loss: 2.461488243416612

Epoch: 6| Step: 3
Training loss: 1.8327509070516332
Validation loss: 2.462863204228438

Epoch: 6| Step: 4
Training loss: 1.5535026904654679
Validation loss: 2.443398900141594

Epoch: 6| Step: 5
Training loss: 2.274982988901781
Validation loss: 2.452485232522465

Epoch: 6| Step: 6
Training loss: 1.7334420384041087
Validation loss: 2.4624227302320985

Epoch: 6| Step: 7
Training loss: 1.696718397694632
Validation loss: 2.459374386904777

Epoch: 6| Step: 8
Training loss: 1.7271714323403178
Validation loss: 2.476626828202738

Epoch: 6| Step: 9
Training loss: 1.8107738825797681
Validation loss: 2.468695891662109

Epoch: 6| Step: 10
Training loss: 1.677693944939044
Validation loss: 2.455541070559663

Epoch: 6| Step: 11
Training loss: 1.8046321447560894
Validation loss: 2.442315243666434

Epoch: 6| Step: 12
Training loss: 1.9911407712778426
Validation loss: 2.437245314896668

Epoch: 6| Step: 13
Training loss: 2.569181709488854
Validation loss: 2.4181898095765386

Epoch: 471| Step: 0
Training loss: 2.2680039116961943
Validation loss: 2.4142513273642443

Epoch: 6| Step: 1
Training loss: 1.9040122734042892
Validation loss: 2.3392557458560095

Epoch: 6| Step: 2
Training loss: 1.8761320511393589
Validation loss: 2.3238435787994867

Epoch: 6| Step: 3
Training loss: 1.9515284001568238
Validation loss: 2.3406267134121856

Epoch: 6| Step: 4
Training loss: 1.6620620380120243
Validation loss: 2.3210990022739932

Epoch: 6| Step: 5
Training loss: 1.9326179276937694
Validation loss: 2.3808938346570403

Epoch: 6| Step: 6
Training loss: 1.8071335898387362
Validation loss: 2.4362816291142884

Epoch: 6| Step: 7
Training loss: 2.153938270527312
Validation loss: 2.490782437416845

Epoch: 6| Step: 8
Training loss: 2.1923983634957933
Validation loss: 2.5380746509695755

Epoch: 6| Step: 9
Training loss: 1.67266769868513
Validation loss: 2.6037198109505386

Epoch: 6| Step: 10
Training loss: 1.271483062415317
Validation loss: 2.537560906157395

Epoch: 6| Step: 11
Training loss: 1.77007644035669
Validation loss: 2.54243597864476

Epoch: 6| Step: 12
Training loss: 2.0541636448258256
Validation loss: 2.555870831507633

Epoch: 6| Step: 13
Training loss: 1.7389049311267912
Validation loss: 2.4773143060532066

Epoch: 472| Step: 0
Training loss: 1.758241863794376
Validation loss: 2.4286747664899093

Epoch: 6| Step: 1
Training loss: 2.0172638846900655
Validation loss: 2.3645350577933324

Epoch: 6| Step: 2
Training loss: 1.5220584202706533
Validation loss: 2.3472861245499708

Epoch: 6| Step: 3
Training loss: 1.943102949084208
Validation loss: 2.29059445047798

Epoch: 6| Step: 4
Training loss: 1.982954402862965
Validation loss: 2.282285931300884

Epoch: 6| Step: 5
Training loss: 1.8373817120320532
Validation loss: 2.299281693451014

Epoch: 6| Step: 6
Training loss: 2.3195025639159037
Validation loss: 2.337828184863045

Epoch: 6| Step: 7
Training loss: 2.012303891311839
Validation loss: 2.417501722920295

Epoch: 6| Step: 8
Training loss: 1.980612604759097
Validation loss: 2.5155656818154637

Epoch: 6| Step: 9
Training loss: 1.4776654035025154
Validation loss: 2.579236460402116

Epoch: 6| Step: 10
Training loss: 2.1353542287738887
Validation loss: 2.627504361230022

Epoch: 6| Step: 11
Training loss: 1.6061915791496588
Validation loss: 2.583481890713515

Epoch: 6| Step: 12
Training loss: 1.9674135546373321
Validation loss: 2.5705886574274497

Epoch: 6| Step: 13
Training loss: 1.8779068983642266
Validation loss: 2.5547404282978747

Epoch: 473| Step: 0
Training loss: 2.3880275003776266
Validation loss: 2.473974779956253

Epoch: 6| Step: 1
Training loss: 1.9244339197300255
Validation loss: 2.4124365677789164

Epoch: 6| Step: 2
Training loss: 1.564720254825314
Validation loss: 2.377597664119487

Epoch: 6| Step: 3
Training loss: 1.0935577223569246
Validation loss: 2.325114531777386

Epoch: 6| Step: 4
Training loss: 1.6282787989865262
Validation loss: 2.347131430736098

Epoch: 6| Step: 5
Training loss: 2.5886735991251615
Validation loss: 2.3582987616232125

Epoch: 6| Step: 6
Training loss: 2.042541225769033
Validation loss: 2.3629591253555455

Epoch: 6| Step: 7
Training loss: 1.3736321407920165
Validation loss: 2.3454829699591397

Epoch: 6| Step: 8
Training loss: 1.600901323006902
Validation loss: 2.3891297576518853

Epoch: 6| Step: 9
Training loss: 1.7531432805323717
Validation loss: 2.411620339525665

Epoch: 6| Step: 10
Training loss: 1.7297445120715447
Validation loss: 2.4384965008691566

Epoch: 6| Step: 11
Training loss: 2.101600618264899
Validation loss: 2.469904800720367

Epoch: 6| Step: 12
Training loss: 1.8696394267748857
Validation loss: 2.5305895412769237

Epoch: 6| Step: 13
Training loss: 1.8552553716740363
Validation loss: 2.5303719609438255

Epoch: 474| Step: 0
Training loss: 1.5956043600382877
Validation loss: 2.568871382948811

Epoch: 6| Step: 1
Training loss: 2.09719781110534
Validation loss: 2.5495637176627155

Epoch: 6| Step: 2
Training loss: 2.007949052612686
Validation loss: 2.5769058820482043

Epoch: 6| Step: 3
Training loss: 2.0663283681344735
Validation loss: 2.5782020355976036

Epoch: 6| Step: 4
Training loss: 1.3386812644431072
Validation loss: 2.4965614534009264

Epoch: 6| Step: 5
Training loss: 1.8159796100933794
Validation loss: 2.467879200312845

Epoch: 6| Step: 6
Training loss: 1.5556770894091265
Validation loss: 2.378410630017101

Epoch: 6| Step: 7
Training loss: 2.063786769934479
Validation loss: 2.329772623875262

Epoch: 6| Step: 8
Training loss: 1.46286275554436
Validation loss: 2.297381401812221

Epoch: 6| Step: 9
Training loss: 1.7990165885088387
Validation loss: 2.2589941335178296

Epoch: 6| Step: 10
Training loss: 2.01010914824091
Validation loss: 2.327587594492989

Epoch: 6| Step: 11
Training loss: 1.860709344696773
Validation loss: 2.3383038123023985

Epoch: 6| Step: 12
Training loss: 2.0455690833496334
Validation loss: 2.4109647682468376

Epoch: 6| Step: 13
Training loss: 2.5481905669627345
Validation loss: 2.418213781538745

Epoch: 475| Step: 0
Training loss: 1.5467341195119484
Validation loss: 2.523687114311501

Epoch: 6| Step: 1
Training loss: 1.2690672980365545
Validation loss: 2.5412480960971555

Epoch: 6| Step: 2
Training loss: 1.8052898904376093
Validation loss: 2.5586832015372853

Epoch: 6| Step: 3
Training loss: 2.2352338087431782
Validation loss: 2.5563174311482286

Epoch: 6| Step: 4
Training loss: 1.8165161099589726
Validation loss: 2.515546494430101

Epoch: 6| Step: 5
Training loss: 2.057834782114083
Validation loss: 2.5109378564886424

Epoch: 6| Step: 6
Training loss: 1.8311794228347154
Validation loss: 2.4639745267522963

Epoch: 6| Step: 7
Training loss: 2.1449350001305767
Validation loss: 2.426617936136709

Epoch: 6| Step: 8
Training loss: 1.7284286563352547
Validation loss: 2.4375543191272278

Epoch: 6| Step: 9
Training loss: 1.8821126183148604
Validation loss: 2.4332218136463815

Epoch: 6| Step: 10
Training loss: 1.691135587466396
Validation loss: 2.503761565684708

Epoch: 6| Step: 11
Training loss: 2.207830287810399
Validation loss: 2.5166795869476735

Epoch: 6| Step: 12
Training loss: 1.494564858839874
Validation loss: 2.485410374851087

Epoch: 6| Step: 13
Training loss: 2.0013327926103006
Validation loss: 2.488429206993732

Epoch: 476| Step: 0
Training loss: 1.7936586868490498
Validation loss: 2.420602853493665

Epoch: 6| Step: 1
Training loss: 1.666266902027987
Validation loss: 2.3887192863945828

Epoch: 6| Step: 2
Training loss: 1.6632403281335018
Validation loss: 2.404304351705715

Epoch: 6| Step: 3
Training loss: 2.102197033693378
Validation loss: 2.404756902879884

Epoch: 6| Step: 4
Training loss: 1.5764725598029048
Validation loss: 2.411870545690704

Epoch: 6| Step: 5
Training loss: 1.6663378709086625
Validation loss: 2.4249091844856374

Epoch: 6| Step: 6
Training loss: 1.7780050200358217
Validation loss: 2.471518667455876

Epoch: 6| Step: 7
Training loss: 1.6526923206508468
Validation loss: 2.4274408220742716

Epoch: 6| Step: 8
Training loss: 2.064969866996907
Validation loss: 2.429156844738861

Epoch: 6| Step: 9
Training loss: 1.7896485014460317
Validation loss: 2.413810481335699

Epoch: 6| Step: 10
Training loss: 2.0166159862528965
Validation loss: 2.427279505661431

Epoch: 6| Step: 11
Training loss: 2.0749456421499812
Validation loss: 2.4110609196764443

Epoch: 6| Step: 12
Training loss: 2.054114548316671
Validation loss: 2.4453738698708816

Epoch: 6| Step: 13
Training loss: 1.7638120542730942
Validation loss: 2.4172734088358814

Epoch: 477| Step: 0
Training loss: 1.1196634026930594
Validation loss: 2.439670619616993

Epoch: 6| Step: 1
Training loss: 1.6854685105443594
Validation loss: 2.469970534332685

Epoch: 6| Step: 2
Training loss: 2.0693868619117426
Validation loss: 2.410993942535684

Epoch: 6| Step: 3
Training loss: 1.6398708971892397
Validation loss: 2.463640952245594

Epoch: 6| Step: 4
Training loss: 2.0386796496875847
Validation loss: 2.498230975825782

Epoch: 6| Step: 5
Training loss: 2.13813124141992
Validation loss: 2.4584239753905237

Epoch: 6| Step: 6
Training loss: 1.769943357735921
Validation loss: 2.4762963955271946

Epoch: 6| Step: 7
Training loss: 1.8028957174888536
Validation loss: 2.474563275625801

Epoch: 6| Step: 8
Training loss: 1.72028414142459
Validation loss: 2.4433977953223196

Epoch: 6| Step: 9
Training loss: 1.756124406443975
Validation loss: 2.44050288383904

Epoch: 6| Step: 10
Training loss: 2.0546774048067706
Validation loss: 2.4602281023584887

Epoch: 6| Step: 11
Training loss: 1.9118337929441622
Validation loss: 2.4241212217775674

Epoch: 6| Step: 12
Training loss: 2.0298403029742547
Validation loss: 2.3882722257424946

Epoch: 6| Step: 13
Training loss: 1.9140374629660337
Validation loss: 2.385722513165455

Epoch: 478| Step: 0
Training loss: 1.9684203946753727
Validation loss: 2.372670998955388

Epoch: 6| Step: 1
Training loss: 1.2634689427533896
Validation loss: 2.3823563839702127

Epoch: 6| Step: 2
Training loss: 1.397627014912022
Validation loss: 2.3790933709962045

Epoch: 6| Step: 3
Training loss: 1.566955165813209
Validation loss: 2.425332171541112

Epoch: 6| Step: 4
Training loss: 2.0761833585347986
Validation loss: 2.447119354982894

Epoch: 6| Step: 5
Training loss: 2.407682116504025
Validation loss: 2.4860764322684403

Epoch: 6| Step: 6
Training loss: 1.5359803916553767
Validation loss: 2.5563009119067304

Epoch: 6| Step: 7
Training loss: 1.6995160423749447
Validation loss: 2.511218603656753

Epoch: 6| Step: 8
Training loss: 1.4153380147293828
Validation loss: 2.5502282072494467

Epoch: 6| Step: 9
Training loss: 1.9154918082950039
Validation loss: 2.5216724416517566

Epoch: 6| Step: 10
Training loss: 1.818215271251874
Validation loss: 2.480754983251918

Epoch: 6| Step: 11
Training loss: 1.856802113944103
Validation loss: 2.469813114713801

Epoch: 6| Step: 12
Training loss: 2.239988518072401
Validation loss: 2.4263501747118412

Epoch: 6| Step: 13
Training loss: 2.4787139692972553
Validation loss: 2.367383729673446

Epoch: 479| Step: 0
Training loss: 1.9885320898684344
Validation loss: 2.399468433953519

Epoch: 6| Step: 1
Training loss: 1.3686928445387776
Validation loss: 2.3836636254242896

Epoch: 6| Step: 2
Training loss: 1.874541099339949
Validation loss: 2.400889488584852

Epoch: 6| Step: 3
Training loss: 2.407978576438121
Validation loss: 2.4046045693590044

Epoch: 6| Step: 4
Training loss: 1.530490764870458
Validation loss: 2.408706432935161

Epoch: 6| Step: 5
Training loss: 2.509320432608857
Validation loss: 2.433758171401491

Epoch: 6| Step: 6
Training loss: 1.9654829377234633
Validation loss: 2.458146825660413

Epoch: 6| Step: 7
Training loss: 2.0337924011724735
Validation loss: 2.5129788381153655

Epoch: 6| Step: 8
Training loss: 1.7549840253662627
Validation loss: 2.5302401702930917

Epoch: 6| Step: 9
Training loss: 1.821094917810852
Validation loss: 2.539061223764154

Epoch: 6| Step: 10
Training loss: 1.6046336431482249
Validation loss: 2.538989173959942

Epoch: 6| Step: 11
Training loss: 1.539080934365726
Validation loss: 2.552639732624685

Epoch: 6| Step: 12
Training loss: 1.254560971085584
Validation loss: 2.5282122372247766

Epoch: 6| Step: 13
Training loss: 1.1450029774589638
Validation loss: 2.4901321447413487

Epoch: 480| Step: 0
Training loss: 1.7767711345789168
Validation loss: 2.46584144059337

Epoch: 6| Step: 1
Training loss: 1.36062547016968
Validation loss: 2.4299249901287285

Epoch: 6| Step: 2
Training loss: 1.5933657912349362
Validation loss: 2.401364788656785

Epoch: 6| Step: 3
Training loss: 2.341081142415776
Validation loss: 2.3825150660391508

Epoch: 6| Step: 4
Training loss: 1.830674439684394
Validation loss: 2.350923015659799

Epoch: 6| Step: 5
Training loss: 1.7299794351314652
Validation loss: 2.3634103385689618

Epoch: 6| Step: 6
Training loss: 1.7655854347319606
Validation loss: 2.358746028697929

Epoch: 6| Step: 7
Training loss: 1.54257374789674
Validation loss: 2.3935866862740682

Epoch: 6| Step: 8
Training loss: 1.8084306746387502
Validation loss: 2.4224607184784746

Epoch: 6| Step: 9
Training loss: 2.1116726265180628
Validation loss: 2.469905813760524

Epoch: 6| Step: 10
Training loss: 1.953414895478104
Validation loss: 2.4995870187575573

Epoch: 6| Step: 11
Training loss: 1.4585610711431984
Validation loss: 2.5393071044021154

Epoch: 6| Step: 12
Training loss: 1.9786041330346607
Validation loss: 2.545028687681749

Epoch: 6| Step: 13
Training loss: 2.329652323671546
Validation loss: 2.539875217866003

Epoch: 481| Step: 0
Training loss: 1.942458053980417
Validation loss: 2.5427267905446245

Epoch: 6| Step: 1
Training loss: 1.7759235450938755
Validation loss: 2.48421600095107

Epoch: 6| Step: 2
Training loss: 1.5396309979002873
Validation loss: 2.4483955178510564

Epoch: 6| Step: 3
Training loss: 2.1591137652122803
Validation loss: 2.4290055554202383

Epoch: 6| Step: 4
Training loss: 1.8485853508500605
Validation loss: 2.4169202027301804

Epoch: 6| Step: 5
Training loss: 1.7734001928766243
Validation loss: 2.4036173082818726

Epoch: 6| Step: 6
Training loss: 1.5393334939234338
Validation loss: 2.418337296138006

Epoch: 6| Step: 7
Training loss: 2.0818805461112238
Validation loss: 2.437801112152061

Epoch: 6| Step: 8
Training loss: 1.4862947598094765
Validation loss: 2.451361417352587

Epoch: 6| Step: 9
Training loss: 1.6810311554353874
Validation loss: 2.4586516869922392

Epoch: 6| Step: 10
Training loss: 2.2071986852279015
Validation loss: 2.4714684214203713

Epoch: 6| Step: 11
Training loss: 2.045866506686982
Validation loss: 2.485492577986423

Epoch: 6| Step: 12
Training loss: 2.0689066018014297
Validation loss: 2.496150110365178

Epoch: 6| Step: 13
Training loss: 1.4833114025909309
Validation loss: 2.4896466520061757

Epoch: 482| Step: 0
Training loss: 1.9904042958506072
Validation loss: 2.4922784842759187

Epoch: 6| Step: 1
Training loss: 2.2261182910784467
Validation loss: 2.4753050099428835

Epoch: 6| Step: 2
Training loss: 1.4759579990376066
Validation loss: 2.468628735651463

Epoch: 6| Step: 3
Training loss: 1.7955043706795577
Validation loss: 2.481178333738103

Epoch: 6| Step: 4
Training loss: 1.741969552541551
Validation loss: 2.438107419325747

Epoch: 6| Step: 5
Training loss: 1.890465721798253
Validation loss: 2.437181986848097

Epoch: 6| Step: 6
Training loss: 1.8095758461700333
Validation loss: 2.3896218563191414

Epoch: 6| Step: 7
Training loss: 1.8064398906641659
Validation loss: 2.3742670910179395

Epoch: 6| Step: 8
Training loss: 1.4667470545123915
Validation loss: 2.429516469771217

Epoch: 6| Step: 9
Training loss: 1.6762774962034044
Validation loss: 2.3888540499907496

Epoch: 6| Step: 10
Training loss: 1.9333290612513379
Validation loss: 2.369386961378885

Epoch: 6| Step: 11
Training loss: 1.3859455800815452
Validation loss: 2.373058419229271

Epoch: 6| Step: 12
Training loss: 1.9576213502844408
Validation loss: 2.381462247432426

Epoch: 6| Step: 13
Training loss: 2.52683390879993
Validation loss: 2.404881379391936

Epoch: 483| Step: 0
Training loss: 2.0277269769282666
Validation loss: 2.4236625359724067

Epoch: 6| Step: 1
Training loss: 2.6922416553153683
Validation loss: 2.4222090838368326

Epoch: 6| Step: 2
Training loss: 1.6084393494341356
Validation loss: 2.448471838615316

Epoch: 6| Step: 3
Training loss: 1.9568829813392086
Validation loss: 2.4595028473209384

Epoch: 6| Step: 4
Training loss: 1.5972343951143806
Validation loss: 2.456931749318096

Epoch: 6| Step: 5
Training loss: 1.1916328089690373
Validation loss: 2.4499573889503563

Epoch: 6| Step: 6
Training loss: 1.853806821501451
Validation loss: 2.511743504232514

Epoch: 6| Step: 7
Training loss: 1.7930026580995089
Validation loss: 2.4287160168306228

Epoch: 6| Step: 8
Training loss: 1.7344493678189594
Validation loss: 2.434590366047412

Epoch: 6| Step: 9
Training loss: 1.8366416067962703
Validation loss: 2.419390102457624

Epoch: 6| Step: 10
Training loss: 1.6861405017950974
Validation loss: 2.422920144969461

Epoch: 6| Step: 11
Training loss: 1.5213963063206872
Validation loss: 2.4102733277350192

Epoch: 6| Step: 12
Training loss: 1.9848128308855904
Validation loss: 2.383839482184666

Epoch: 6| Step: 13
Training loss: 1.5202293067430868
Validation loss: 2.356674571097646

Epoch: 484| Step: 0
Training loss: 2.154464645977418
Validation loss: 2.3789342818013037

Epoch: 6| Step: 1
Training loss: 1.6412257956400058
Validation loss: 2.418369330603746

Epoch: 6| Step: 2
Training loss: 1.549992050642733
Validation loss: 2.433704436448956

Epoch: 6| Step: 3
Training loss: 1.3469928380128675
Validation loss: 2.4168365328293597

Epoch: 6| Step: 4
Training loss: 1.7045492813760976
Validation loss: 2.397792025849903

Epoch: 6| Step: 5
Training loss: 1.7517845047146217
Validation loss: 2.4676284599741987

Epoch: 6| Step: 6
Training loss: 1.9128915747401984
Validation loss: 2.4740126357193457

Epoch: 6| Step: 7
Training loss: 1.9267442628332807
Validation loss: 2.489967443905117

Epoch: 6| Step: 8
Training loss: 1.8609572658562092
Validation loss: 2.4737604174545673

Epoch: 6| Step: 9
Training loss: 2.170381979657514
Validation loss: 2.505173449328534

Epoch: 6| Step: 10
Training loss: 1.8990055066511475
Validation loss: 2.506996505304758

Epoch: 6| Step: 11
Training loss: 2.0254480690383287
Validation loss: 2.5066178007845723

Epoch: 6| Step: 12
Training loss: 1.5718121555878148
Validation loss: 2.4864342863426416

Epoch: 6| Step: 13
Training loss: 1.5949419089952643
Validation loss: 2.4845927576367006

Epoch: 485| Step: 0
Training loss: 1.4741383185427495
Validation loss: 2.4678870578072045

Epoch: 6| Step: 1
Training loss: 1.405491348771944
Validation loss: 2.4480361403138593

Epoch: 6| Step: 2
Training loss: 2.1040695721977536
Validation loss: 2.4128821814385257

Epoch: 6| Step: 3
Training loss: 2.4216273027315665
Validation loss: 2.3664417806759435

Epoch: 6| Step: 4
Training loss: 1.5451377592427937
Validation loss: 2.35944125413789

Epoch: 6| Step: 5
Training loss: 1.5850913510637301
Validation loss: 2.3873401303769786

Epoch: 6| Step: 6
Training loss: 1.8020304486520928
Validation loss: 2.42593491046296

Epoch: 6| Step: 7
Training loss: 1.587897081350266
Validation loss: 2.3960989267623853

Epoch: 6| Step: 8
Training loss: 2.035658410149227
Validation loss: 2.406256304017359

Epoch: 6| Step: 9
Training loss: 1.549475901196883
Validation loss: 2.4354897211377127

Epoch: 6| Step: 10
Training loss: 1.8144393279800386
Validation loss: 2.433138035261116

Epoch: 6| Step: 11
Training loss: 1.6870725584859816
Validation loss: 2.493300399387011

Epoch: 6| Step: 12
Training loss: 2.201109918299521
Validation loss: 2.4875464426966283

Epoch: 6| Step: 13
Training loss: 1.8168898728230727
Validation loss: 2.5336233336008482

Epoch: 486| Step: 0
Training loss: 2.108477253079034
Validation loss: 2.535583978774726

Epoch: 6| Step: 1
Training loss: 1.5582177035973501
Validation loss: 2.5001687844018066

Epoch: 6| Step: 2
Training loss: 1.8586272972257445
Validation loss: 2.4791411505985703

Epoch: 6| Step: 3
Training loss: 2.037298265077117
Validation loss: 2.453668098847502

Epoch: 6| Step: 4
Training loss: 1.829003147587641
Validation loss: 2.4356241667616283

Epoch: 6| Step: 5
Training loss: 1.3978477385232644
Validation loss: 2.4015344109650134

Epoch: 6| Step: 6
Training loss: 2.0889477671899437
Validation loss: 2.3803506388914704

Epoch: 6| Step: 7
Training loss: 1.8774446445233777
Validation loss: 2.4175614902257

Epoch: 6| Step: 8
Training loss: 1.8628425641538369
Validation loss: 2.446998934881967

Epoch: 6| Step: 9
Training loss: 1.686095889820745
Validation loss: 2.5137717446467724

Epoch: 6| Step: 10
Training loss: 1.604767732183827
Validation loss: 2.516827868904374

Epoch: 6| Step: 11
Training loss: 1.852488869493331
Validation loss: 2.510933086422193

Epoch: 6| Step: 12
Training loss: 1.5869704016441453
Validation loss: 2.550498242796792

Epoch: 6| Step: 13
Training loss: 1.6753020768569808
Validation loss: 2.5678995102003657

Epoch: 487| Step: 0
Training loss: 1.7855979990561701
Validation loss: 2.5219811375868706

Epoch: 6| Step: 1
Training loss: 2.1608892097511263
Validation loss: 2.5039192140371695

Epoch: 6| Step: 2
Training loss: 1.8402309131852919
Validation loss: 2.4605473107636815

Epoch: 6| Step: 3
Training loss: 1.6432427004233146
Validation loss: 2.466555364348657

Epoch: 6| Step: 4
Training loss: 2.128442332265496
Validation loss: 2.4223262021216914

Epoch: 6| Step: 5
Training loss: 1.7391962622022425
Validation loss: 2.3734913099767514

Epoch: 6| Step: 6
Training loss: 1.7995135630196903
Validation loss: 2.3718152727414523

Epoch: 6| Step: 7
Training loss: 1.5694327096115905
Validation loss: 2.3281480631539697

Epoch: 6| Step: 8
Training loss: 2.0979348109602496
Validation loss: 2.3464367338133734

Epoch: 6| Step: 9
Training loss: 1.6336932567499531
Validation loss: 2.3620939652308772

Epoch: 6| Step: 10
Training loss: 1.2843814821845434
Validation loss: 2.4272159857220625

Epoch: 6| Step: 11
Training loss: 2.0377831665979147
Validation loss: 2.470902560199351

Epoch: 6| Step: 12
Training loss: 1.6738492058547059
Validation loss: 2.527823098969488

Epoch: 6| Step: 13
Training loss: 1.7424664466506226
Validation loss: 2.5779657786435046

Epoch: 488| Step: 0
Training loss: 1.5711762439347805
Validation loss: 2.6259622612017823

Epoch: 6| Step: 1
Training loss: 2.1974939117520895
Validation loss: 2.6251428949046356

Epoch: 6| Step: 2
Training loss: 1.5806050972007901
Validation loss: 2.522427643482806

Epoch: 6| Step: 3
Training loss: 1.518215207733142
Validation loss: 2.4537569675076347

Epoch: 6| Step: 4
Training loss: 1.9471543260178004
Validation loss: 2.4043917353127635

Epoch: 6| Step: 5
Training loss: 1.6515589083341091
Validation loss: 2.3289817185708004

Epoch: 6| Step: 6
Training loss: 1.8360943017107756
Validation loss: 2.301975845933056

Epoch: 6| Step: 7
Training loss: 1.7721041738057681
Validation loss: 2.273540010048654

Epoch: 6| Step: 8
Training loss: 1.8778185957861904
Validation loss: 2.30963852812061

Epoch: 6| Step: 9
Training loss: 2.1960078865562807
Validation loss: 2.28568608995687

Epoch: 6| Step: 10
Training loss: 2.0399981577247828
Validation loss: 2.349522881432368

Epoch: 6| Step: 11
Training loss: 1.7736866645715583
Validation loss: 2.3417537629511846

Epoch: 6| Step: 12
Training loss: 1.5365490213128448
Validation loss: 2.406642323028461

Epoch: 6| Step: 13
Training loss: 1.9280876910342089
Validation loss: 2.5104024630787136

Epoch: 489| Step: 0
Training loss: 1.5519885689225956
Validation loss: 2.5489310616933945

Epoch: 6| Step: 1
Training loss: 2.148354490583878
Validation loss: 2.5719684914425476

Epoch: 6| Step: 2
Training loss: 1.468908017363072
Validation loss: 2.5478003465572017

Epoch: 6| Step: 3
Training loss: 1.1577602523979094
Validation loss: 2.5216192838789353

Epoch: 6| Step: 4
Training loss: 1.7822256260699594
Validation loss: 2.5284069506856643

Epoch: 6| Step: 5
Training loss: 1.9560221432717684
Validation loss: 2.4871248523520078

Epoch: 6| Step: 6
Training loss: 1.5016776081467034
Validation loss: 2.432358847132992

Epoch: 6| Step: 7
Training loss: 2.1664005140523708
Validation loss: 2.3739789658086727

Epoch: 6| Step: 8
Training loss: 1.8317069150872145
Validation loss: 2.363522624041764

Epoch: 6| Step: 9
Training loss: 2.1710001329222526
Validation loss: 2.3975620027342335

Epoch: 6| Step: 10
Training loss: 2.0023258513544797
Validation loss: 2.3796299761079087

Epoch: 6| Step: 11
Training loss: 1.5341507819722844
Validation loss: 2.386421071326329

Epoch: 6| Step: 12
Training loss: 1.5745480479337794
Validation loss: 2.4249753227031223

Epoch: 6| Step: 13
Training loss: 2.0627575337854123
Validation loss: 2.4584979629106236

Epoch: 490| Step: 0
Training loss: 2.1735710273055693
Validation loss: 2.479881803059944

Epoch: 6| Step: 1
Training loss: 1.5651256625391374
Validation loss: 2.4619112561406897

Epoch: 6| Step: 2
Training loss: 2.0467730780698608
Validation loss: 2.476908852000739

Epoch: 6| Step: 3
Training loss: 1.4330661228893948
Validation loss: 2.4824612480770476

Epoch: 6| Step: 4
Training loss: 1.923642284111651
Validation loss: 2.49068716811039

Epoch: 6| Step: 5
Training loss: 1.7783751460948285
Validation loss: 2.502926237803569

Epoch: 6| Step: 6
Training loss: 1.4719677841195988
Validation loss: 2.490858749043541

Epoch: 6| Step: 7
Training loss: 1.5666086727257298
Validation loss: 2.4913023721424103

Epoch: 6| Step: 8
Training loss: 2.085482544164923
Validation loss: 2.4968967065788226

Epoch: 6| Step: 9
Training loss: 1.1235551032426416
Validation loss: 2.446714598234341

Epoch: 6| Step: 10
Training loss: 1.7496136511349913
Validation loss: 2.4626959728621842

Epoch: 6| Step: 11
Training loss: 1.6495364896375442
Validation loss: 2.4207304632783595

Epoch: 6| Step: 12
Training loss: 2.2240234889567043
Validation loss: 2.4029358647771892

Epoch: 6| Step: 13
Training loss: 1.870659763919351
Validation loss: 2.3757148896212974

Epoch: 491| Step: 0
Training loss: 1.9431406789437284
Validation loss: 2.3955255743230524

Epoch: 6| Step: 1
Training loss: 1.8930926022255743
Validation loss: 2.3870989775550484

Epoch: 6| Step: 2
Training loss: 2.0107248758512903
Validation loss: 2.362222857674965

Epoch: 6| Step: 3
Training loss: 1.8643335214131997
Validation loss: 2.3852787632640506

Epoch: 6| Step: 4
Training loss: 1.9048078741475611
Validation loss: 2.497378853858638

Epoch: 6| Step: 5
Training loss: 1.8256783047905805
Validation loss: 2.593560860423304

Epoch: 6| Step: 6
Training loss: 1.9793266900939228
Validation loss: 2.6383096838289757

Epoch: 6| Step: 7
Training loss: 1.9831979820270436
Validation loss: 2.5904685225347794

Epoch: 6| Step: 8
Training loss: 2.2189194520528424
Validation loss: 2.479923974015407

Epoch: 6| Step: 9
Training loss: 1.8398144632588116
Validation loss: 2.381968610807921

Epoch: 6| Step: 10
Training loss: 1.2110271789814675
Validation loss: 2.2785306999313026

Epoch: 6| Step: 11
Training loss: 1.4758693945406625
Validation loss: 2.2393899210704316

Epoch: 6| Step: 12
Training loss: 1.4976222743328034
Validation loss: 2.2134130305650306

Epoch: 6| Step: 13
Training loss: 1.6925114991601766
Validation loss: 2.278935708073492

Epoch: 492| Step: 0
Training loss: 1.7959726472823512
Validation loss: 2.324988263414046

Epoch: 6| Step: 1
Training loss: 1.9695126100994993
Validation loss: 2.404500493367121

Epoch: 6| Step: 2
Training loss: 1.6900496824286404
Validation loss: 2.464689775550633

Epoch: 6| Step: 3
Training loss: 1.8285456768419441
Validation loss: 2.5697303958370252

Epoch: 6| Step: 4
Training loss: 1.4385784913288922
Validation loss: 2.5780904310785715

Epoch: 6| Step: 5
Training loss: 2.1254705020398434
Validation loss: 2.5797575931404433

Epoch: 6| Step: 6
Training loss: 1.9852666578700056
Validation loss: 2.5696228290980905

Epoch: 6| Step: 7
Training loss: 1.5994795489230538
Validation loss: 2.537177644617082

Epoch: 6| Step: 8
Training loss: 1.5592066580317574
Validation loss: 2.428896047540477

Epoch: 6| Step: 9
Training loss: 1.386503992778588
Validation loss: 2.416915286355028

Epoch: 6| Step: 10
Training loss: 1.845328027464473
Validation loss: 2.3679114483241825

Epoch: 6| Step: 11
Training loss: 1.6289298149618152
Validation loss: 2.3220761371021594

Epoch: 6| Step: 12
Training loss: 2.2270297446968796
Validation loss: 2.322236228010336

Epoch: 6| Step: 13
Training loss: 1.9648562482129215
Validation loss: 2.3594302637030244

Epoch: 493| Step: 0
Training loss: 1.650081736534179
Validation loss: 2.3818946634742715

Epoch: 6| Step: 1
Training loss: 1.947893261556379
Validation loss: 2.435728646891653

Epoch: 6| Step: 2
Training loss: 1.7427802339152192
Validation loss: 2.4338597475719617

Epoch: 6| Step: 3
Training loss: 1.9048644486708388
Validation loss: 2.495477895472911

Epoch: 6| Step: 4
Training loss: 1.386718062279759
Validation loss: 2.4510662656672415

Epoch: 6| Step: 5
Training loss: 1.7078457423375102
Validation loss: 2.482874927123006

Epoch: 6| Step: 6
Training loss: 2.048083232678427
Validation loss: 2.4500464099944264

Epoch: 6| Step: 7
Training loss: 1.6683572142597516
Validation loss: 2.4282818160369004

Epoch: 6| Step: 8
Training loss: 1.6520672650255332
Validation loss: 2.368688659107502

Epoch: 6| Step: 9
Training loss: 1.692482691666469
Validation loss: 2.3611781317287064

Epoch: 6| Step: 10
Training loss: 1.7343742439337104
Validation loss: 2.404226485985924

Epoch: 6| Step: 11
Training loss: 2.0462663051209606
Validation loss: 2.3866046179844442

Epoch: 6| Step: 12
Training loss: 2.0712264436845302
Validation loss: 2.4158902269985743

Epoch: 6| Step: 13
Training loss: 1.2289924120905447
Validation loss: 2.448518221392059

Epoch: 494| Step: 0
Training loss: 1.4065765425585586
Validation loss: 2.5079680200262238

Epoch: 6| Step: 1
Training loss: 1.6676156521200562
Validation loss: 2.5330573622488033

Epoch: 6| Step: 2
Training loss: 2.190037808374964
Validation loss: 2.560227552759942

Epoch: 6| Step: 3
Training loss: 1.3907515650385023
Validation loss: 2.484247824174859

Epoch: 6| Step: 4
Training loss: 1.8605050251458983
Validation loss: 2.468974474889532

Epoch: 6| Step: 5
Training loss: 1.8623021270302271
Validation loss: 2.416295945697102

Epoch: 6| Step: 6
Training loss: 1.620795532740267
Validation loss: 2.4069224210337254

Epoch: 6| Step: 7
Training loss: 1.6893414940088718
Validation loss: 2.4363509783756396

Epoch: 6| Step: 8
Training loss: 1.5695846161188578
Validation loss: 2.4662267995178566

Epoch: 6| Step: 9
Training loss: 1.3177308795593332
Validation loss: 2.507430553948285

Epoch: 6| Step: 10
Training loss: 2.2496750914905355
Validation loss: 2.489209782481768

Epoch: 6| Step: 11
Training loss: 1.8408753566455374
Validation loss: 2.4514717386991687

Epoch: 6| Step: 12
Training loss: 1.829235098506619
Validation loss: 2.4469171772310925

Epoch: 6| Step: 13
Training loss: 2.3134668751775864
Validation loss: 2.468209806350574

Epoch: 495| Step: 0
Training loss: 2.4517978066596786
Validation loss: 2.452645983385762

Epoch: 6| Step: 1
Training loss: 1.6028663352215073
Validation loss: 2.411134940065359

Epoch: 6| Step: 2
Training loss: 1.9749489934587972
Validation loss: 2.373588931891593

Epoch: 6| Step: 3
Training loss: 1.6328118429228269
Validation loss: 2.3769118661468127

Epoch: 6| Step: 4
Training loss: 1.880394360188602
Validation loss: 2.3236794646896324

Epoch: 6| Step: 5
Training loss: 1.6817346207669863
Validation loss: 2.369822474327541

Epoch: 6| Step: 6
Training loss: 1.6576875889466047
Validation loss: 2.339547155146897

Epoch: 6| Step: 7
Training loss: 1.4292059749317163
Validation loss: 2.383037372685287

Epoch: 6| Step: 8
Training loss: 1.9080671810582668
Validation loss: 2.40228716949308

Epoch: 6| Step: 9
Training loss: 1.9070167875386157
Validation loss: 2.5074641176421584

Epoch: 6| Step: 10
Training loss: 1.78080851119716
Validation loss: 2.570729826940641

Epoch: 6| Step: 11
Training loss: 1.4223700699020538
Validation loss: 2.6074564178527337

Epoch: 6| Step: 12
Training loss: 1.6566872649316229
Validation loss: 2.6116469309178187

Epoch: 6| Step: 13
Training loss: 1.6199887105760333
Validation loss: 2.591301350413104

Epoch: 496| Step: 0
Training loss: 1.8629370157485186
Validation loss: 2.5183445309280583

Epoch: 6| Step: 1
Training loss: 1.855615485563006
Validation loss: 2.412481233801271

Epoch: 6| Step: 2
Training loss: 1.6104477205362626
Validation loss: 2.3495165714049917

Epoch: 6| Step: 3
Training loss: 1.6108596028124686
Validation loss: 2.3173252240280315

Epoch: 6| Step: 4
Training loss: 1.9750818428755095
Validation loss: 2.294409671299942

Epoch: 6| Step: 5
Training loss: 1.905361844137574
Validation loss: 2.331085715305686

Epoch: 6| Step: 6
Training loss: 1.9530992429942262
Validation loss: 2.438695685321614

Epoch: 6| Step: 7
Training loss: 1.6904924492338758
Validation loss: 2.47521238570693

Epoch: 6| Step: 8
Training loss: 1.2972533352070719
Validation loss: 2.4985161869407038

Epoch: 6| Step: 9
Training loss: 2.3852784451303
Validation loss: 2.504078471070901

Epoch: 6| Step: 10
Training loss: 1.5284005725980323
Validation loss: 2.4998892769854044

Epoch: 6| Step: 11
Training loss: 1.692206142953341
Validation loss: 2.539108993319156

Epoch: 6| Step: 12
Training loss: 1.786542158319632
Validation loss: 2.492605204627263

Epoch: 6| Step: 13
Training loss: 1.7561717195814983
Validation loss: 2.5359328885234547

Epoch: 497| Step: 0
Training loss: 1.1523863703717832
Validation loss: 2.5133808041181536

Epoch: 6| Step: 1
Training loss: 1.9214458451631613
Validation loss: 2.448193585283213

Epoch: 6| Step: 2
Training loss: 1.7469346583898304
Validation loss: 2.38667460616716

Epoch: 6| Step: 3
Training loss: 1.4841350160651303
Validation loss: 2.3640684078785714

Epoch: 6| Step: 4
Training loss: 1.6943618288727804
Validation loss: 2.4075857545335406

Epoch: 6| Step: 5
Training loss: 1.5113095855956131
Validation loss: 2.389257769408874

Epoch: 6| Step: 6
Training loss: 1.930199003188477
Validation loss: 2.397182505957444

Epoch: 6| Step: 7
Training loss: 1.9405776160900714
Validation loss: 2.4332667523994647

Epoch: 6| Step: 8
Training loss: 1.5020893962735984
Validation loss: 2.456062305172537

Epoch: 6| Step: 9
Training loss: 1.976024750546804
Validation loss: 2.4797170174152385

Epoch: 6| Step: 10
Training loss: 1.3871239298575477
Validation loss: 2.515720128950032

Epoch: 6| Step: 11
Training loss: 2.0199328379277293
Validation loss: 2.5649275787286827

Epoch: 6| Step: 12
Training loss: 1.7840002144013691
Validation loss: 2.516948702510822

Epoch: 6| Step: 13
Training loss: 2.609545582203799
Validation loss: 2.5642751472281895

Epoch: 498| Step: 0
Training loss: 1.6243183466919735
Validation loss: 2.4868161840926346

Epoch: 6| Step: 1
Training loss: 2.096483638074563
Validation loss: 2.422123245605287

Epoch: 6| Step: 2
Training loss: 1.138010975018829
Validation loss: 2.3734846165023105

Epoch: 6| Step: 3
Training loss: 1.7398467483117828
Validation loss: 2.3206939102045334

Epoch: 6| Step: 4
Training loss: 1.9328922733259615
Validation loss: 2.355051518669595

Epoch: 6| Step: 5
Training loss: 1.8952095626464203
Validation loss: 2.337362920928975

Epoch: 6| Step: 6
Training loss: 1.6442998510375382
Validation loss: 2.386241598426524

Epoch: 6| Step: 7
Training loss: 1.8956006993799797
Validation loss: 2.4127270808402685

Epoch: 6| Step: 8
Training loss: 1.5218490535709703
Validation loss: 2.455830266612175

Epoch: 6| Step: 9
Training loss: 2.036935332517614
Validation loss: 2.52344827495065

Epoch: 6| Step: 10
Training loss: 1.9289124202513706
Validation loss: 2.5598344502673434

Epoch: 6| Step: 11
Training loss: 1.3848186531190165
Validation loss: 2.5767033818630996

Epoch: 6| Step: 12
Training loss: 1.9702940441601302
Validation loss: 2.6678789815807287

Epoch: 6| Step: 13
Training loss: 1.486614826236542
Validation loss: 2.602492646357505

Epoch: 499| Step: 0
Training loss: 1.5960041635310809
Validation loss: 2.5284405056322687

Epoch: 6| Step: 1
Training loss: 1.591491819767568
Validation loss: 2.3798780899936487

Epoch: 6| Step: 2
Training loss: 1.69250241323099
Validation loss: 2.3019312742148017

Epoch: 6| Step: 3
Training loss: 1.475096120773572
Validation loss: 2.266374187341169

Epoch: 6| Step: 4
Training loss: 1.774307575295185
Validation loss: 2.253895223812416

Epoch: 6| Step: 5
Training loss: 2.0983651382342714
Validation loss: 2.2848195328107583

Epoch: 6| Step: 6
Training loss: 1.491285041211926
Validation loss: 2.3327029214542265

Epoch: 6| Step: 7
Training loss: 1.998341230112253
Validation loss: 2.3718356893397017

Epoch: 6| Step: 8
Training loss: 1.9067480968657404
Validation loss: 2.4233806713011488

Epoch: 6| Step: 9
Training loss: 1.8475426927313057
Validation loss: 2.4496934773502392

Epoch: 6| Step: 10
Training loss: 1.9560735799683622
Validation loss: 2.513596711868908

Epoch: 6| Step: 11
Training loss: 1.5862166436237621
Validation loss: 2.5772362334007473

Epoch: 6| Step: 12
Training loss: 2.0143758762321022
Validation loss: 2.5595587911815754

Epoch: 6| Step: 13
Training loss: 1.2739305068455138
Validation loss: 2.5548841462158483

Epoch: 500| Step: 0
Training loss: 1.6484758273184275
Validation loss: 2.572888950137003

Epoch: 6| Step: 1
Training loss: 1.4103347369485855
Validation loss: 2.538299396398909

Epoch: 6| Step: 2
Training loss: 1.475554268356385
Validation loss: 2.5444827409947783

Epoch: 6| Step: 3
Training loss: 1.779924066509831
Validation loss: 2.518571765793738

Epoch: 6| Step: 4
Training loss: 1.6235383869798683
Validation loss: 2.5280922086725606

Epoch: 6| Step: 5
Training loss: 2.0335691857219107
Validation loss: 2.5045485638378753

Epoch: 6| Step: 6
Training loss: 1.476996383295816
Validation loss: 2.4929796193729805

Epoch: 6| Step: 7
Training loss: 1.9903675817173978
Validation loss: 2.434380061994331

Epoch: 6| Step: 8
Training loss: 1.5699754799306957
Validation loss: 2.4246028953475482

Epoch: 6| Step: 9
Training loss: 2.2789696570498488
Validation loss: 2.403110575785027

Epoch: 6| Step: 10
Training loss: 1.7184220434625506
Validation loss: 2.3740864525745238

Epoch: 6| Step: 11
Training loss: 1.5899428728025529
Validation loss: 2.3698451560248226

Epoch: 6| Step: 12
Training loss: 1.4281293372290795
Validation loss: 2.3539996583856295

Epoch: 6| Step: 13
Training loss: 2.09489250326114
Validation loss: 2.379914736569497

Epoch: 501| Step: 0
Training loss: 1.5665622547879228
Validation loss: 2.3583087104854976

Epoch: 6| Step: 1
Training loss: 1.630619748722275
Validation loss: 2.3598128430478393

Epoch: 6| Step: 2
Training loss: 1.6785268632718089
Validation loss: 2.375604166235857

Epoch: 6| Step: 3
Training loss: 1.871600693615375
Validation loss: 2.3583740955991144

Epoch: 6| Step: 4
Training loss: 2.380857372204859
Validation loss: 2.366104468994548

Epoch: 6| Step: 5
Training loss: 1.62639858508276
Validation loss: 2.3629776504293787

Epoch: 6| Step: 6
Training loss: 1.4781053344192598
Validation loss: 2.450646170044053

Epoch: 6| Step: 7
Training loss: 1.6454472471235309
Validation loss: 2.509561151833959

Epoch: 6| Step: 8
Training loss: 1.829892795424358
Validation loss: 2.5348731448113795

Epoch: 6| Step: 9
Training loss: 1.6733206799903886
Validation loss: 2.5291788810814406

Epoch: 6| Step: 10
Training loss: 1.7611885710942143
Validation loss: 2.4915141707150075

Epoch: 6| Step: 11
Training loss: 1.8603598286602772
Validation loss: 2.5219191698541183

Epoch: 6| Step: 12
Training loss: 1.5450427831509934
Validation loss: 2.466631066060709

Epoch: 6| Step: 13
Training loss: 1.7264534065682948
Validation loss: 2.4871288785158763

Epoch: 502| Step: 0
Training loss: 2.333820519222158
Validation loss: 2.472341388120795

Epoch: 6| Step: 1
Training loss: 2.0167324365447126
Validation loss: 2.5080801158750017

Epoch: 6| Step: 2
Training loss: 1.9139820938349006
Validation loss: 2.471109567188365

Epoch: 6| Step: 3
Training loss: 1.540441988894318
Validation loss: 2.5147250341483076

Epoch: 6| Step: 4
Training loss: 0.9334214502416418
Validation loss: 2.531192071439942

Epoch: 6| Step: 5
Training loss: 1.3480293973609374
Validation loss: 2.568487548873898

Epoch: 6| Step: 6
Training loss: 2.358513479013524
Validation loss: 2.5911903565917855

Epoch: 6| Step: 7
Training loss: 1.341349031431079
Validation loss: 2.4912802858378824

Epoch: 6| Step: 8
Training loss: 1.5943355606566534
Validation loss: 2.442970585224296

Epoch: 6| Step: 9
Training loss: 1.7534941803047277
Validation loss: 2.408824256948525

Epoch: 6| Step: 10
Training loss: 1.6381120600766017
Validation loss: 2.3620407473271765

Epoch: 6| Step: 11
Training loss: 1.4691276876320651
Validation loss: 2.3708175225545904

Epoch: 6| Step: 12
Training loss: 1.5855563603070706
Validation loss: 2.3251758590526497

Epoch: 6| Step: 13
Training loss: 1.993818684892618
Validation loss: 2.3552828182935657

Epoch: 503| Step: 0
Training loss: 1.77071719817269
Validation loss: 2.3466857129247085

Epoch: 6| Step: 1
Training loss: 1.1392932590075926
Validation loss: 2.402888692280835

Epoch: 6| Step: 2
Training loss: 2.014861206121067
Validation loss: 2.4625992089056874

Epoch: 6| Step: 3
Training loss: 1.6426917727386927
Validation loss: 2.4792459616040334

Epoch: 6| Step: 4
Training loss: 1.8039650399865776
Validation loss: 2.5318215409955758

Epoch: 6| Step: 5
Training loss: 1.6459125869919564
Validation loss: 2.5466371837041737

Epoch: 6| Step: 6
Training loss: 2.1195420126777056
Validation loss: 2.585281454907668

Epoch: 6| Step: 7
Training loss: 1.9678355924194288
Validation loss: 2.5752345782233403

Epoch: 6| Step: 8
Training loss: 1.602703004735038
Validation loss: 2.530345245110016

Epoch: 6| Step: 9
Training loss: 1.6690245956062257
Validation loss: 2.459979253163371

Epoch: 6| Step: 10
Training loss: 1.732751172066577
Validation loss: 2.422130999629062

Epoch: 6| Step: 11
Training loss: 1.5589680998929274
Validation loss: 2.3720487917527198

Epoch: 6| Step: 12
Training loss: 1.6529679077734778
Validation loss: 2.3191098470111844

Epoch: 6| Step: 13
Training loss: 1.4002811490179985
Validation loss: 2.301658231051732

Epoch: 504| Step: 0
Training loss: 1.316480413775817
Validation loss: 2.2807428535436087

Epoch: 6| Step: 1
Training loss: 1.7964263355877177
Validation loss: 2.297925728714491

Epoch: 6| Step: 2
Training loss: 1.7979944473834326
Validation loss: 2.288114530700614

Epoch: 6| Step: 3
Training loss: 1.7330417491728873
Validation loss: 2.332071928756211

Epoch: 6| Step: 4
Training loss: 1.8916289131105424
Validation loss: 2.3669086082044997

Epoch: 6| Step: 5
Training loss: 1.9693040824961334
Validation loss: 2.434273002756427

Epoch: 6| Step: 6
Training loss: 1.4799433357113725
Validation loss: 2.5104984118149396

Epoch: 6| Step: 7
Training loss: 1.7118181026567199
Validation loss: 2.5598587712608634

Epoch: 6| Step: 8
Training loss: 1.7515223557213173
Validation loss: 2.622092939688504

Epoch: 6| Step: 9
Training loss: 1.5132372422877165
Validation loss: 2.5637199175244154

Epoch: 6| Step: 10
Training loss: 1.4972682555762993
Validation loss: 2.532048755541487

Epoch: 6| Step: 11
Training loss: 1.955769754759855
Validation loss: 2.5051924444672062

Epoch: 6| Step: 12
Training loss: 1.9718292013372294
Validation loss: 2.480876927974382

Epoch: 6| Step: 13
Training loss: 2.0795770605786674
Validation loss: 2.4039199280504913

Epoch: 505| Step: 0
Training loss: 1.5601023779800647
Validation loss: 2.3841289098830503

Epoch: 6| Step: 1
Training loss: 2.029446667015784
Validation loss: 2.321634219374504

Epoch: 6| Step: 2
Training loss: 2.293310188723737
Validation loss: 2.315695035704367

Epoch: 6| Step: 3
Training loss: 1.716122786772848
Validation loss: 2.3365951009202455

Epoch: 6| Step: 4
Training loss: 1.6217245689998514
Validation loss: 2.39759612182141

Epoch: 6| Step: 5
Training loss: 1.5271910764286636
Validation loss: 2.417540957145309

Epoch: 6| Step: 6
Training loss: 1.4832174505908784
Validation loss: 2.479162291842377

Epoch: 6| Step: 7
Training loss: 1.9775784862968426
Validation loss: 2.5272198781886104

Epoch: 6| Step: 8
Training loss: 2.0266439005342685
Validation loss: 2.546868685698104

Epoch: 6| Step: 9
Training loss: 1.5874190152154388
Validation loss: 2.556300210899646

Epoch: 6| Step: 10
Training loss: 1.5381703380860963
Validation loss: 2.5311401355498693

Epoch: 6| Step: 11
Training loss: 1.5223252368714761
Validation loss: 2.49622609973883

Epoch: 6| Step: 12
Training loss: 1.2825850997263928
Validation loss: 2.4975734008854378

Epoch: 6| Step: 13
Training loss: 1.7313399694318263
Validation loss: 2.43714825364272

Epoch: 506| Step: 0
Training loss: 1.2907770025785794
Validation loss: 2.4649805388834425

Epoch: 6| Step: 1
Training loss: 1.7142445553652388
Validation loss: 2.4218607727119816

Epoch: 6| Step: 2
Training loss: 1.7579541636709397
Validation loss: 2.385270301536711

Epoch: 6| Step: 3
Training loss: 1.277302032629403
Validation loss: 2.3972576863453297

Epoch: 6| Step: 4
Training loss: 2.0115112197642717
Validation loss: 2.3661521776445777

Epoch: 6| Step: 5
Training loss: 2.0066299221354145
Validation loss: 2.4238171985861157

Epoch: 6| Step: 6
Training loss: 1.6953050463815842
Validation loss: 2.419955866343512

Epoch: 6| Step: 7
Training loss: 1.5584088744079245
Validation loss: 2.4771905446051985

Epoch: 6| Step: 8
Training loss: 1.134620749176155
Validation loss: 2.52041497890961

Epoch: 6| Step: 9
Training loss: 1.643905484348275
Validation loss: 2.5036282073597116

Epoch: 6| Step: 10
Training loss: 2.406613904510252
Validation loss: 2.5028776609023398

Epoch: 6| Step: 11
Training loss: 2.014054270417511
Validation loss: 2.5087187296968128

Epoch: 6| Step: 12
Training loss: 1.0558064494414925
Validation loss: 2.5114943738495628

Epoch: 6| Step: 13
Training loss: 1.898514169157379
Validation loss: 2.5669985516120373

Epoch: 507| Step: 0
Training loss: 1.874755652718645
Validation loss: 2.4228963507747525

Epoch: 6| Step: 1
Training loss: 1.6442435912311435
Validation loss: 2.4186228584828022

Epoch: 6| Step: 2
Training loss: 1.8458738217817954
Validation loss: 2.429599852837951

Epoch: 6| Step: 3
Training loss: 1.5075626462758651
Validation loss: 2.368413381879549

Epoch: 6| Step: 4
Training loss: 2.048439883675196
Validation loss: 2.3645195861379498

Epoch: 6| Step: 5
Training loss: 1.3660729797382969
Validation loss: 2.3410802805979114

Epoch: 6| Step: 6
Training loss: 1.6900993390202943
Validation loss: 2.3253749856842756

Epoch: 6| Step: 7
Training loss: 1.5743913958136058
Validation loss: 2.2999307233231443

Epoch: 6| Step: 8
Training loss: 1.6271362934293547
Validation loss: 2.3818595412922186

Epoch: 6| Step: 9
Training loss: 2.3072564758877854
Validation loss: 2.448258162542883

Epoch: 6| Step: 10
Training loss: 1.871125732658223
Validation loss: 2.529831173035409

Epoch: 6| Step: 11
Training loss: 1.4797297825154787
Validation loss: 2.603088288200412

Epoch: 6| Step: 12
Training loss: 1.4614757831353766
Validation loss: 2.6587305838819555

Epoch: 6| Step: 13
Training loss: 1.9851267434501594
Validation loss: 2.593130605815927

Epoch: 508| Step: 0
Training loss: 1.6596749359729825
Validation loss: 2.5192330509150627

Epoch: 6| Step: 1
Training loss: 1.675880695940241
Validation loss: 2.3929254491631573

Epoch: 6| Step: 2
Training loss: 1.6547339356330357
Validation loss: 2.289493539666935

Epoch: 6| Step: 3
Training loss: 2.087463278076262
Validation loss: 2.2462270977283394

Epoch: 6| Step: 4
Training loss: 2.0384481973585222
Validation loss: 2.1992358298456183

Epoch: 6| Step: 5
Training loss: 1.8578963611306183
Validation loss: 2.2246073652128717

Epoch: 6| Step: 6
Training loss: 2.3707957952530005
Validation loss: 2.252032291890748

Epoch: 6| Step: 7
Training loss: 1.7974807381692177
Validation loss: 2.351142439961323

Epoch: 6| Step: 8
Training loss: 1.3050675894966521
Validation loss: 2.485952509942666

Epoch: 6| Step: 9
Training loss: 1.286400468068014
Validation loss: 2.6043144397442304

Epoch: 6| Step: 10
Training loss: 1.9009908451620414
Validation loss: 2.6926729507741403

Epoch: 6| Step: 11
Training loss: 1.7385942155939038
Validation loss: 2.744331347571775

Epoch: 6| Step: 12
Training loss: 1.9360989457886473
Validation loss: 2.707930420532332

Epoch: 6| Step: 13
Training loss: 1.5492601597840474
Validation loss: 2.5807584327531794

Epoch: 509| Step: 0
Training loss: 1.6860551653397489
Validation loss: 2.5566461149845026

Epoch: 6| Step: 1
Training loss: 1.2877087970052485
Validation loss: 2.5014886474488853

Epoch: 6| Step: 2
Training loss: 1.7945018189623763
Validation loss: 2.4207802258080973

Epoch: 6| Step: 3
Training loss: 1.6209997678423556
Validation loss: 2.4043327580705998

Epoch: 6| Step: 4
Training loss: 1.7092063192935023
Validation loss: 2.3773186876658197

Epoch: 6| Step: 5
Training loss: 1.945645958689227
Validation loss: 2.349867982915465

Epoch: 6| Step: 6
Training loss: 1.7626989644612445
Validation loss: 2.363164985825438

Epoch: 6| Step: 7
Training loss: 1.6429651917887498
Validation loss: 2.3867938217500386

Epoch: 6| Step: 8
Training loss: 1.518030361902219
Validation loss: 2.458269717723175

Epoch: 6| Step: 9
Training loss: 1.9064919990393674
Validation loss: 2.430107137174282

Epoch: 6| Step: 10
Training loss: 1.5758526749468704
Validation loss: 2.508997142120439

Epoch: 6| Step: 11
Training loss: 1.6446839757755074
Validation loss: 2.5154731963024366

Epoch: 6| Step: 12
Training loss: 1.6302104458373725
Validation loss: 2.509368317786122

Epoch: 6| Step: 13
Training loss: 2.1736548287000526
Validation loss: 2.4863408012502957

Epoch: 510| Step: 0
Training loss: 1.2927459801482475
Validation loss: 2.4614200616995614

Epoch: 6| Step: 1
Training loss: 2.16086813594019
Validation loss: 2.4388806776769894

Epoch: 6| Step: 2
Training loss: 1.8065892887554298
Validation loss: 2.4636649361721155

Epoch: 6| Step: 3
Training loss: 1.435472800491081
Validation loss: 2.4686509020723992

Epoch: 6| Step: 4
Training loss: 1.8051955923902756
Validation loss: 2.468622807956421

Epoch: 6| Step: 5
Training loss: 1.8383123742940937
Validation loss: 2.4592221862072554

Epoch: 6| Step: 6
Training loss: 1.7304538700333727
Validation loss: 2.4507320686533385

Epoch: 6| Step: 7
Training loss: 1.9501784414173848
Validation loss: 2.441242806819026

Epoch: 6| Step: 8
Training loss: 2.0045557586839164
Validation loss: 2.442260096195591

Epoch: 6| Step: 9
Training loss: 1.6786076822974794
Validation loss: 2.43714421749217

Epoch: 6| Step: 10
Training loss: 1.459048431910386
Validation loss: 2.4422189434066617

Epoch: 6| Step: 11
Training loss: 1.647929615045436
Validation loss: 2.440837372818471

Epoch: 6| Step: 12
Training loss: 1.0599771729296616
Validation loss: 2.441913406035314

Epoch: 6| Step: 13
Training loss: 1.3434512671266365
Validation loss: 2.424935961906308

Epoch: 511| Step: 0
Training loss: 1.3987993166550148
Validation loss: 2.425944346290202

Epoch: 6| Step: 1
Training loss: 1.7579381601135249
Validation loss: 2.4259387422861316

Epoch: 6| Step: 2
Training loss: 1.5261281827633646
Validation loss: 2.4224819453566586

Epoch: 6| Step: 3
Training loss: 2.230651206655943
Validation loss: 2.435730988736127

Epoch: 6| Step: 4
Training loss: 1.4528328386517215
Validation loss: 2.435256046071015

Epoch: 6| Step: 5
Training loss: 2.0554977385949957
Validation loss: 2.451913622699314

Epoch: 6| Step: 6
Training loss: 1.4306522303798264
Validation loss: 2.4490631808268617

Epoch: 6| Step: 7
Training loss: 2.064144750280334
Validation loss: 2.4409405259756176

Epoch: 6| Step: 8
Training loss: 1.5708620239120128
Validation loss: 2.439819821219861

Epoch: 6| Step: 9
Training loss: 1.3109419976067487
Validation loss: 2.4389895548910214

Epoch: 6| Step: 10
Training loss: 1.5712776823799361
Validation loss: 2.405228443639292

Epoch: 6| Step: 11
Training loss: 1.848800272744892
Validation loss: 2.4564445769852967

Epoch: 6| Step: 12
Training loss: 1.8617588437493866
Validation loss: 2.4189172886426595

Epoch: 6| Step: 13
Training loss: 1.0824629820910048
Validation loss: 2.422618104933379

Epoch: 512| Step: 0
Training loss: 1.9943212713154908
Validation loss: 2.459222010031518

Epoch: 6| Step: 1
Training loss: 1.495261974537425
Validation loss: 2.50021657723431

Epoch: 6| Step: 2
Training loss: 1.578087985671661
Validation loss: 2.49612988585396

Epoch: 6| Step: 3
Training loss: 1.8026736694562955
Validation loss: 2.5035518200666327

Epoch: 6| Step: 4
Training loss: 1.779346720796039
Validation loss: 2.5241933660983173

Epoch: 6| Step: 5
Training loss: 1.6770961911042277
Validation loss: 2.5000683216275514

Epoch: 6| Step: 6
Training loss: 1.6789450490523585
Validation loss: 2.5070154856079254

Epoch: 6| Step: 7
Training loss: 1.6196782930036286
Validation loss: 2.41903197858543

Epoch: 6| Step: 8
Training loss: 1.4797684515427656
Validation loss: 2.4438075713628375

Epoch: 6| Step: 9
Training loss: 1.2640382215056813
Validation loss: 2.4590877583651585

Epoch: 6| Step: 10
Training loss: 1.9303139970751073
Validation loss: 2.432104456384244

Epoch: 6| Step: 11
Training loss: 1.4603551019960115
Validation loss: 2.4614899046089596

Epoch: 6| Step: 12
Training loss: 2.1189940230468447
Validation loss: 2.4304661638157508

Epoch: 6| Step: 13
Training loss: 1.1314019728106783
Validation loss: 2.4292361465362324

Epoch: 513| Step: 0
Training loss: 1.386266586300798
Validation loss: 2.419152841834715

Epoch: 6| Step: 1
Training loss: 1.7713574550126676
Validation loss: 2.4185140586823186

Epoch: 6| Step: 2
Training loss: 1.3864333597862664
Validation loss: 2.413680187068883

Epoch: 6| Step: 3
Training loss: 1.927453852594618
Validation loss: 2.4063927009244694

Epoch: 6| Step: 4
Training loss: 1.8096969239047684
Validation loss: 2.4166653908573075

Epoch: 6| Step: 5
Training loss: 1.9228529264136225
Validation loss: 2.4810118925732083

Epoch: 6| Step: 6
Training loss: 1.729788687484928
Validation loss: 2.510753723509354

Epoch: 6| Step: 7
Training loss: 1.5831677534291957
Validation loss: 2.480509914153198

Epoch: 6| Step: 8
Training loss: 2.1550156750739546
Validation loss: 2.507357443903609

Epoch: 6| Step: 9
Training loss: 1.6684165192760507
Validation loss: 2.482029703612778

Epoch: 6| Step: 10
Training loss: 1.618296662113868
Validation loss: 2.4410048078050965

Epoch: 6| Step: 11
Training loss: 1.2213323573569461
Validation loss: 2.473731793759439

Epoch: 6| Step: 12
Training loss: 1.4929636589374702
Validation loss: 2.470206390165252

Epoch: 6| Step: 13
Training loss: 1.5690456613299235
Validation loss: 2.456193050832863

Epoch: 514| Step: 0
Training loss: 1.5400111184400012
Validation loss: 2.4792545089677454

Epoch: 6| Step: 1
Training loss: 1.8037405460821039
Validation loss: 2.4553500842347344

Epoch: 6| Step: 2
Training loss: 1.8758447015938395
Validation loss: 2.4986179089788663

Epoch: 6| Step: 3
Training loss: 2.025439711502878
Validation loss: 2.474230012251832

Epoch: 6| Step: 4
Training loss: 1.4949927997734678
Validation loss: 2.458927242006255

Epoch: 6| Step: 5
Training loss: 1.6840512390949443
Validation loss: 2.4729886639198804

Epoch: 6| Step: 6
Training loss: 1.6098943076182548
Validation loss: 2.4797122503558326

Epoch: 6| Step: 7
Training loss: 1.342818624949896
Validation loss: 2.530857992157223

Epoch: 6| Step: 8
Training loss: 1.912792672096744
Validation loss: 2.5194960277321505

Epoch: 6| Step: 9
Training loss: 1.5704593874426718
Validation loss: 2.491236615853497

Epoch: 6| Step: 10
Training loss: 1.5944372453131994
Validation loss: 2.438268091909148

Epoch: 6| Step: 11
Training loss: 1.9469277902858027
Validation loss: 2.4363300354329667

Epoch: 6| Step: 12
Training loss: 1.1606679487935243
Validation loss: 2.3542464149580558

Epoch: 6| Step: 13
Training loss: 1.7284074135222083
Validation loss: 2.35007973271479

Epoch: 515| Step: 0
Training loss: 2.0444773834910586
Validation loss: 2.3337547175184645

Epoch: 6| Step: 1
Training loss: 1.3940562660130917
Validation loss: 2.3535311107171135

Epoch: 6| Step: 2
Training loss: 1.2620609634262356
Validation loss: 2.3391161563632172

Epoch: 6| Step: 3
Training loss: 1.9981340406092212
Validation loss: 2.3843185090181755

Epoch: 6| Step: 4
Training loss: 1.8595809822429497
Validation loss: 2.4209702425635813

Epoch: 6| Step: 5
Training loss: 1.8430710528457694
Validation loss: 2.4699594108807355

Epoch: 6| Step: 6
Training loss: 1.9595456598115677
Validation loss: 2.4916666789035493

Epoch: 6| Step: 7
Training loss: 1.7395668333569292
Validation loss: 2.48250517053465

Epoch: 6| Step: 8
Training loss: 1.695359330475381
Validation loss: 2.5023425043562395

Epoch: 6| Step: 9
Training loss: 1.5137703155993951
Validation loss: 2.5062170506106813

Epoch: 6| Step: 10
Training loss: 1.352192020994968
Validation loss: 2.472133421339066

Epoch: 6| Step: 11
Training loss: 1.5721590183675518
Validation loss: 2.4583292853848886

Epoch: 6| Step: 12
Training loss: 1.4777572077480352
Validation loss: 2.4483992789223468

Epoch: 6| Step: 13
Training loss: 1.4697116382132625
Validation loss: 2.40164436106181

Epoch: 516| Step: 0
Training loss: 2.0557424643600055
Validation loss: 2.437256770676016

Epoch: 6| Step: 1
Training loss: 1.5086201298529427
Validation loss: 2.4339369486090905

Epoch: 6| Step: 2
Training loss: 1.5270355772259432
Validation loss: 2.4360228501847883

Epoch: 6| Step: 3
Training loss: 1.6361011441496944
Validation loss: 2.459915167025021

Epoch: 6| Step: 4
Training loss: 1.5729322453752608
Validation loss: 2.4461019054887942

Epoch: 6| Step: 5
Training loss: 1.9004573045815778
Validation loss: 2.5206248692883704

Epoch: 6| Step: 6
Training loss: 1.2368073461225597
Validation loss: 2.534217160864025

Epoch: 6| Step: 7
Training loss: 1.9052571071626845
Validation loss: 2.5813190004747812

Epoch: 6| Step: 8
Training loss: 1.8213126909702202
Validation loss: 2.5562591750741017

Epoch: 6| Step: 9
Training loss: 1.3265980638245765
Validation loss: 2.4797364825542445

Epoch: 6| Step: 10
Training loss: 1.9374277655149197
Validation loss: 2.4745278774201407

Epoch: 6| Step: 11
Training loss: 1.6569900298938074
Validation loss: 2.4049648309612266

Epoch: 6| Step: 12
Training loss: 1.7175647463525816
Validation loss: 2.3660084745377574

Epoch: 6| Step: 13
Training loss: 1.285565250326836
Validation loss: 2.328885965689329

Epoch: 517| Step: 0
Training loss: 1.4364389567166755
Validation loss: 2.3124471301969667

Epoch: 6| Step: 1
Training loss: 1.3978519172662678
Validation loss: 2.3088924023988535

Epoch: 6| Step: 2
Training loss: 1.8740679649641012
Validation loss: 2.3824127093195244

Epoch: 6| Step: 3
Training loss: 1.5129119343614892
Validation loss: 2.373323915603335

Epoch: 6| Step: 4
Training loss: 1.0889453534864082
Validation loss: 2.414036044278384

Epoch: 6| Step: 5
Training loss: 1.8149232121977823
Validation loss: 2.459113021548302

Epoch: 6| Step: 6
Training loss: 1.535004586452131
Validation loss: 2.4466383483930887

Epoch: 6| Step: 7
Training loss: 1.7689738290380825
Validation loss: 2.4768883151253798

Epoch: 6| Step: 8
Training loss: 1.889480622797117
Validation loss: 2.467246067276998

Epoch: 6| Step: 9
Training loss: 1.7891281315788048
Validation loss: 2.46588530144649

Epoch: 6| Step: 10
Training loss: 1.9030946976577845
Validation loss: 2.422819384138644

Epoch: 6| Step: 11
Training loss: 1.8017216211007783
Validation loss: 2.459474404797855

Epoch: 6| Step: 12
Training loss: 1.832795266463096
Validation loss: 2.4451001436227378

Epoch: 6| Step: 13
Training loss: 1.3039698197289133
Validation loss: 2.529468486242714

Epoch: 518| Step: 0
Training loss: 1.1672256810736565
Validation loss: 2.537789081716401

Epoch: 6| Step: 1
Training loss: 1.512830064557727
Validation loss: 2.544393812899402

Epoch: 6| Step: 2
Training loss: 1.7763129630261516
Validation loss: 2.594014359528452

Epoch: 6| Step: 3
Training loss: 1.7880282681809958
Validation loss: 2.509603961538635

Epoch: 6| Step: 4
Training loss: 1.2739920783492793
Validation loss: 2.4713325450700916

Epoch: 6| Step: 5
Training loss: 1.4414877933087247
Validation loss: 2.391018996886761

Epoch: 6| Step: 6
Training loss: 1.744452676058473
Validation loss: 2.369405944725843

Epoch: 6| Step: 7
Training loss: 1.4077985079087985
Validation loss: 2.3914667221803287

Epoch: 6| Step: 8
Training loss: 1.6186415175684332
Validation loss: 2.4135692716601596

Epoch: 6| Step: 9
Training loss: 1.4006270843449498
Validation loss: 2.46662133428656

Epoch: 6| Step: 10
Training loss: 1.5453113397761695
Validation loss: 2.498414878386491

Epoch: 6| Step: 11
Training loss: 2.4045864150902787
Validation loss: 2.4950511484955133

Epoch: 6| Step: 12
Training loss: 1.9153428135889654
Validation loss: 2.579166054745868

Epoch: 6| Step: 13
Training loss: 2.2179724176960365
Validation loss: 2.512740855640408

Epoch: 519| Step: 0
Training loss: 1.1302614097027757
Validation loss: 2.5315481760012974

Epoch: 6| Step: 1
Training loss: 2.004046875776627
Validation loss: 2.506650778595022

Epoch: 6| Step: 2
Training loss: 0.9389376108204659
Validation loss: 2.469785023438123

Epoch: 6| Step: 3
Training loss: 1.550936981760646
Validation loss: 2.4462590211713504

Epoch: 6| Step: 4
Training loss: 1.635057867583493
Validation loss: 2.4736845162655623

Epoch: 6| Step: 5
Training loss: 1.4104638437845236
Validation loss: 2.488974665486651

Epoch: 6| Step: 6
Training loss: 1.439080903207941
Validation loss: 2.5145834772608295

Epoch: 6| Step: 7
Training loss: 1.5324072065776904
Validation loss: 2.4997002068089214

Epoch: 6| Step: 8
Training loss: 2.0389532885773742
Validation loss: 2.474148858618655

Epoch: 6| Step: 9
Training loss: 1.7192630348926232
Validation loss: 2.530283010074469

Epoch: 6| Step: 10
Training loss: 2.178206730407903
Validation loss: 2.448870734552456

Epoch: 6| Step: 11
Training loss: 1.768105444046562
Validation loss: 2.444680370306105

Epoch: 6| Step: 12
Training loss: 1.8761437424491048
Validation loss: 2.391794973499547

Epoch: 6| Step: 13
Training loss: 1.2723580682589022
Validation loss: 2.3426232301788836

Epoch: 520| Step: 0
Training loss: 1.9198125922611031
Validation loss: 2.290397613350091

Epoch: 6| Step: 1
Training loss: 1.8293967103077158
Validation loss: 2.301941262332786

Epoch: 6| Step: 2
Training loss: 1.5342129437237366
Validation loss: 2.300499738106811

Epoch: 6| Step: 3
Training loss: 1.6262492733014746
Validation loss: 2.3215752213070577

Epoch: 6| Step: 4
Training loss: 1.6044570445358206
Validation loss: 2.37056365440235

Epoch: 6| Step: 5
Training loss: 1.3266482052564854
Validation loss: 2.36338207925062

Epoch: 6| Step: 6
Training loss: 1.7650287262737492
Validation loss: 2.4030698812515796

Epoch: 6| Step: 7
Training loss: 1.6426991022399318
Validation loss: 2.426492920175186

Epoch: 6| Step: 8
Training loss: 1.495392159280378
Validation loss: 2.49050966990295

Epoch: 6| Step: 9
Training loss: 1.807946371464675
Validation loss: 2.490689304916547

Epoch: 6| Step: 10
Training loss: 1.3709703699662212
Validation loss: 2.5139345667523263

Epoch: 6| Step: 11
Training loss: 1.6182957044889412
Validation loss: 2.4894291665296295

Epoch: 6| Step: 12
Training loss: 1.6075340778778833
Validation loss: 2.5049581593177086

Epoch: 6| Step: 13
Training loss: 2.3709022909727517
Validation loss: 2.471065475376128

Epoch: 521| Step: 0
Training loss: 1.3117479258615954
Validation loss: 2.4125406143567254

Epoch: 6| Step: 1
Training loss: 1.5389236929791223
Validation loss: 2.3990928666003515

Epoch: 6| Step: 2
Training loss: 1.4526728264945177
Validation loss: 2.3427376981747776

Epoch: 6| Step: 3
Training loss: 1.4880236305083236
Validation loss: 2.370276100563352

Epoch: 6| Step: 4
Training loss: 1.9560886938116742
Validation loss: 2.3235093709835968

Epoch: 6| Step: 5
Training loss: 1.9903776437331815
Validation loss: 2.386975622400818

Epoch: 6| Step: 6
Training loss: 1.6901210633203763
Validation loss: 2.430219599060176

Epoch: 6| Step: 7
Training loss: 1.5231725217772976
Validation loss: 2.434868972592434

Epoch: 6| Step: 8
Training loss: 2.015760668543133
Validation loss: 2.478696552257406

Epoch: 6| Step: 9
Training loss: 1.4424591767403678
Validation loss: 2.5199132460730316

Epoch: 6| Step: 10
Training loss: 1.9073400038867312
Validation loss: 2.5023229645742804

Epoch: 6| Step: 11
Training loss: 1.8368145085745355
Validation loss: 2.4892870877401214

Epoch: 6| Step: 12
Training loss: 1.3753966712981274
Validation loss: 2.502000115271051

Epoch: 6| Step: 13
Training loss: 0.8390841575399027
Validation loss: 2.522031947755281

Epoch: 522| Step: 0
Training loss: 2.079026335093945
Validation loss: 2.5235017396036916

Epoch: 6| Step: 1
Training loss: 1.5287550237889684
Validation loss: 2.505300940767862

Epoch: 6| Step: 2
Training loss: 1.5576216264141296
Validation loss: 2.506525164612605

Epoch: 6| Step: 3
Training loss: 1.7239503735438253
Validation loss: 2.5066068696203363

Epoch: 6| Step: 4
Training loss: 1.5098623464379262
Validation loss: 2.4665869045858866

Epoch: 6| Step: 5
Training loss: 1.1073416759912384
Validation loss: 2.4333351614261534

Epoch: 6| Step: 6
Training loss: 1.2441396668339129
Validation loss: 2.401930608005743

Epoch: 6| Step: 7
Training loss: 1.795455305430753
Validation loss: 2.440318872219758

Epoch: 6| Step: 8
Training loss: 2.0009627409234696
Validation loss: 2.4038382862804766

Epoch: 6| Step: 9
Training loss: 1.6569647776118284
Validation loss: 2.3800060467821162

Epoch: 6| Step: 10
Training loss: 1.7088074685222847
Validation loss: 2.4385405760190104

Epoch: 6| Step: 11
Training loss: 1.2156188062495348
Validation loss: 2.4312434457598373

Epoch: 6| Step: 12
Training loss: 1.8799581458119974
Validation loss: 2.434622714206766

Epoch: 6| Step: 13
Training loss: 1.4594881753105984
Validation loss: 2.44157994908804

Epoch: 523| Step: 0
Training loss: 1.3765913684255686
Validation loss: 2.4522353268262584

Epoch: 6| Step: 1
Training loss: 1.6024988926066888
Validation loss: 2.4320480211649054

Epoch: 6| Step: 2
Training loss: 1.8254577219488823
Validation loss: 2.4295619740535797

Epoch: 6| Step: 3
Training loss: 1.6515186314815269
Validation loss: 2.441894006846256

Epoch: 6| Step: 4
Training loss: 1.8984923806126757
Validation loss: 2.451357603306806

Epoch: 6| Step: 5
Training loss: 1.1238460450505527
Validation loss: 2.411901048825314

Epoch: 6| Step: 6
Training loss: 1.4765933401933882
Validation loss: 2.43615371108813

Epoch: 6| Step: 7
Training loss: 1.7814309546928533
Validation loss: 2.4833184062654765

Epoch: 6| Step: 8
Training loss: 1.9694071687124903
Validation loss: 2.4948460972052326

Epoch: 6| Step: 9
Training loss: 1.6343411677343471
Validation loss: 2.509720250041885

Epoch: 6| Step: 10
Training loss: 1.544434674359407
Validation loss: 2.4722359344162372

Epoch: 6| Step: 11
Training loss: 1.6491276891624715
Validation loss: 2.498419026933065

Epoch: 6| Step: 12
Training loss: 1.613308885536228
Validation loss: 2.4707018975001867

Epoch: 6| Step: 13
Training loss: 1.0749902902208996
Validation loss: 2.444160081625674

Epoch: 524| Step: 0
Training loss: 1.4948762167523655
Validation loss: 2.4787780699828637

Epoch: 6| Step: 1
Training loss: 1.5631424918067363
Validation loss: 2.4655716107745835

Epoch: 6| Step: 2
Training loss: 1.4739270785447398
Validation loss: 2.4487538742487636

Epoch: 6| Step: 3
Training loss: 1.5525603958643273
Validation loss: 2.4074893722007404

Epoch: 6| Step: 4
Training loss: 1.6094339600660739
Validation loss: 2.4259509219695903

Epoch: 6| Step: 5
Training loss: 1.5292872091209542
Validation loss: 2.4606149603055147

Epoch: 6| Step: 6
Training loss: 1.7776778693073576
Validation loss: 2.4765244875653254

Epoch: 6| Step: 7
Training loss: 1.4302225414588192
Validation loss: 2.5197477478688155

Epoch: 6| Step: 8
Training loss: 1.507877012463814
Validation loss: 2.5257920204738022

Epoch: 6| Step: 9
Training loss: 1.7729602457227314
Validation loss: 2.474109352739813

Epoch: 6| Step: 10
Training loss: 1.980386826365093
Validation loss: 2.4756953305458773

Epoch: 6| Step: 11
Training loss: 1.4965927845504785
Validation loss: 2.4209791947503865

Epoch: 6| Step: 12
Training loss: 1.6920562270541413
Validation loss: 2.452839191174435

Epoch: 6| Step: 13
Training loss: 1.6041241512196758
Validation loss: 2.3578240460138575

Epoch: 525| Step: 0
Training loss: 1.2825137163287617
Validation loss: 2.415465596058703

Epoch: 6| Step: 1
Training loss: 1.3291840313979946
Validation loss: 2.4313824634490353

Epoch: 6| Step: 2
Training loss: 1.3397097506676345
Validation loss: 2.4660408136349514

Epoch: 6| Step: 3
Training loss: 2.0652576852878735
Validation loss: 2.4944717370272635

Epoch: 6| Step: 4
Training loss: 1.5204094945031559
Validation loss: 2.454974059004268

Epoch: 6| Step: 5
Training loss: 1.3211764155804935
Validation loss: 2.4664214817066243

Epoch: 6| Step: 6
Training loss: 1.3747190708663757
Validation loss: 2.462628078070963

Epoch: 6| Step: 7
Training loss: 2.0037668042064296
Validation loss: 2.4284523156534448

Epoch: 6| Step: 8
Training loss: 1.9758271066842925
Validation loss: 2.4465050084066133

Epoch: 6| Step: 9
Training loss: 1.9914757747493625
Validation loss: 2.419235880586548

Epoch: 6| Step: 10
Training loss: 1.548668332413626
Validation loss: 2.4351155192765153

Epoch: 6| Step: 11
Training loss: 1.467952024517835
Validation loss: 2.4129409098731434

Epoch: 6| Step: 12
Training loss: 1.572022223735315
Validation loss: 2.4512890038513206

Epoch: 6| Step: 13
Training loss: 1.255454892626226
Validation loss: 2.4322397031031424

Epoch: 526| Step: 0
Training loss: 1.7217043368024192
Validation loss: 2.4938259282923894

Epoch: 6| Step: 1
Training loss: 1.5754709871672152
Validation loss: 2.5417949221195397

Epoch: 6| Step: 2
Training loss: 1.5070879682800609
Validation loss: 2.55331531762752

Epoch: 6| Step: 3
Training loss: 1.5813946231851466
Validation loss: 2.5546304571516725

Epoch: 6| Step: 4
Training loss: 1.4783018655592444
Validation loss: 2.5579442801597136

Epoch: 6| Step: 5
Training loss: 1.9585707162142467
Validation loss: 2.5265055494471187

Epoch: 6| Step: 6
Training loss: 1.5404116531192802
Validation loss: 2.480488108988239

Epoch: 6| Step: 7
Training loss: 1.9541643962833362
Validation loss: 2.434514637873075

Epoch: 6| Step: 8
Training loss: 1.7263717200742696
Validation loss: 2.3596632912463598

Epoch: 6| Step: 9
Training loss: 1.854346648778337
Validation loss: 2.368236990168249

Epoch: 6| Step: 10
Training loss: 1.342585569243982
Validation loss: 2.3760776314767527

Epoch: 6| Step: 11
Training loss: 1.5637479757391912
Validation loss: 2.379638679820261

Epoch: 6| Step: 12
Training loss: 1.2023748561114664
Validation loss: 2.3922879599067888

Epoch: 6| Step: 13
Training loss: 1.4031315028118514
Validation loss: 2.4505017620830674

Epoch: 527| Step: 0
Training loss: 1.7118603730038167
Validation loss: 2.550601559362828

Epoch: 6| Step: 1
Training loss: 1.9294866542310136
Validation loss: 2.5637679380896063

Epoch: 6| Step: 2
Training loss: 1.760562762757314
Validation loss: 2.56480057933647

Epoch: 6| Step: 3
Training loss: 1.8795527815007658
Validation loss: 2.592891760169573

Epoch: 6| Step: 4
Training loss: 1.2006549001820026
Validation loss: 2.53393141335123

Epoch: 6| Step: 5
Training loss: 1.1009832712577778
Validation loss: 2.539211605164948

Epoch: 6| Step: 6
Training loss: 1.5696101349696874
Validation loss: 2.5518082598339022

Epoch: 6| Step: 7
Training loss: 1.8302675391405332
Validation loss: 2.4919460942342853

Epoch: 6| Step: 8
Training loss: 1.4022723421495615
Validation loss: 2.4294055059829476

Epoch: 6| Step: 9
Training loss: 1.2862826341913653
Validation loss: 2.409539810863487

Epoch: 6| Step: 10
Training loss: 1.5647204071966831
Validation loss: 2.3784452588074707

Epoch: 6| Step: 11
Training loss: 1.4246236203702356
Validation loss: 2.345783061206106

Epoch: 6| Step: 12
Training loss: 1.6388017968925623
Validation loss: 2.344113668577855

Epoch: 6| Step: 13
Training loss: 1.9865242440208273
Validation loss: 2.3614599225611084

Epoch: 528| Step: 0
Training loss: 1.8302711214061684
Validation loss: 2.3913745840335436

Epoch: 6| Step: 1
Training loss: 2.1135480504310076
Validation loss: 2.356163421351939

Epoch: 6| Step: 2
Training loss: 1.4875156305597828
Validation loss: 2.4087872285641243

Epoch: 6| Step: 3
Training loss: 1.7673852298925339
Validation loss: 2.421417104124717

Epoch: 6| Step: 4
Training loss: 1.6236988140023165
Validation loss: 2.43381857282464

Epoch: 6| Step: 5
Training loss: 0.9111131214168773
Validation loss: 2.4676492650717945

Epoch: 6| Step: 6
Training loss: 1.6393655938574185
Validation loss: 2.4934458680766607

Epoch: 6| Step: 7
Training loss: 1.5637087914566317
Validation loss: 2.5591184642754485

Epoch: 6| Step: 8
Training loss: 1.4524734841321316
Validation loss: 2.5441019264119697

Epoch: 6| Step: 9
Training loss: 1.6602544777925683
Validation loss: 2.6027938952269274

Epoch: 6| Step: 10
Training loss: 1.6910913187429106
Validation loss: 2.5189014779396337

Epoch: 6| Step: 11
Training loss: 1.4694033853571067
Validation loss: 2.449578275331751

Epoch: 6| Step: 12
Training loss: 1.333209012116635
Validation loss: 2.4140770615676375

Epoch: 6| Step: 13
Training loss: 1.4112992238058484
Validation loss: 2.415733263934548

Epoch: 529| Step: 0
Training loss: 1.3239038143543
Validation loss: 2.3724950275265084

Epoch: 6| Step: 1
Training loss: 2.1564021402395444
Validation loss: 2.3542993348251335

Epoch: 6| Step: 2
Training loss: 1.5290848352362956
Validation loss: 2.380953341885269

Epoch: 6| Step: 3
Training loss: 1.3443677502467255
Validation loss: 2.431351207779078

Epoch: 6| Step: 4
Training loss: 1.6065622582812926
Validation loss: 2.463473172694579

Epoch: 6| Step: 5
Training loss: 1.4537900817803562
Validation loss: 2.5252755890607474

Epoch: 6| Step: 6
Training loss: 1.6651676430374647
Validation loss: 2.5336256355530438

Epoch: 6| Step: 7
Training loss: 1.8623558961561977
Validation loss: 2.5927628616603355

Epoch: 6| Step: 8
Training loss: 2.002751841430808
Validation loss: 2.551043518138358

Epoch: 6| Step: 9
Training loss: 1.240568485462164
Validation loss: 2.542571447570483

Epoch: 6| Step: 10
Training loss: 1.4180728254139454
Validation loss: 2.491367458868738

Epoch: 6| Step: 11
Training loss: 1.117248746887037
Validation loss: 2.4020501347608003

Epoch: 6| Step: 12
Training loss: 1.773016657028657
Validation loss: 2.3660050798365297

Epoch: 6| Step: 13
Training loss: 1.4736438141570771
Validation loss: 2.315457670669708

Epoch: 530| Step: 0
Training loss: 1.8312444563121013
Validation loss: 2.351267368115798

Epoch: 6| Step: 1
Training loss: 1.5508555050999995
Validation loss: 2.4518356257998093

Epoch: 6| Step: 2
Training loss: 1.53079458198376
Validation loss: 2.4707772791766076

Epoch: 6| Step: 3
Training loss: 1.5681810479545462
Validation loss: 2.5413850476650497

Epoch: 6| Step: 4
Training loss: 1.6831148887129417
Validation loss: 2.616707072688338

Epoch: 6| Step: 5
Training loss: 1.5735565382961227
Validation loss: 2.622287266572092

Epoch: 6| Step: 6
Training loss: 1.1391809807422022
Validation loss: 2.668492285126087

Epoch: 6| Step: 7
Training loss: 2.011179435065837
Validation loss: 2.649722510978705

Epoch: 6| Step: 8
Training loss: 2.195285783381137
Validation loss: 2.5657703891001375

Epoch: 6| Step: 9
Training loss: 1.6334148555315016
Validation loss: 2.481579482749132

Epoch: 6| Step: 10
Training loss: 1.1125153165470114
Validation loss: 2.412767211917952

Epoch: 6| Step: 11
Training loss: 1.2735564755519435
Validation loss: 2.3674632922728454

Epoch: 6| Step: 12
Training loss: 1.3107678472979847
Validation loss: 2.334317557533393

Epoch: 6| Step: 13
Training loss: 1.7602383299414857
Validation loss: 2.3383167680429247

Epoch: 531| Step: 0
Training loss: 1.4988872056123221
Validation loss: 2.3155994004405285

Epoch: 6| Step: 1
Training loss: 1.3135877370759121
Validation loss: 2.354508417537122

Epoch: 6| Step: 2
Training loss: 1.3761627742694884
Validation loss: 2.4284098230406865

Epoch: 6| Step: 3
Training loss: 2.0214164390758316
Validation loss: 2.43009381417883

Epoch: 6| Step: 4
Training loss: 1.1656305901032855
Validation loss: 2.4639936126808113

Epoch: 6| Step: 5
Training loss: 1.8058273877003586
Validation loss: 2.599232863928545

Epoch: 6| Step: 6
Training loss: 1.5090497726816912
Validation loss: 2.565652456360607

Epoch: 6| Step: 7
Training loss: 1.5743447530217731
Validation loss: 2.5371385245041305

Epoch: 6| Step: 8
Training loss: 1.6172822933702622
Validation loss: 2.4529974962891448

Epoch: 6| Step: 9
Training loss: 1.1923448211341179
Validation loss: 2.442654706411469

Epoch: 6| Step: 10
Training loss: 1.734453354173924
Validation loss: 2.3935678218724967

Epoch: 6| Step: 11
Training loss: 2.314403575254145
Validation loss: 2.3901890644023385

Epoch: 6| Step: 12
Training loss: 1.2303237102948343
Validation loss: 2.373816324198963

Epoch: 6| Step: 13
Training loss: 1.2651766230047747
Validation loss: 2.3956068792409813

Epoch: 532| Step: 0
Training loss: 1.5433348402478722
Validation loss: 2.44043731087515

Epoch: 6| Step: 1
Training loss: 1.2147529788925786
Validation loss: 2.4567942931629765

Epoch: 6| Step: 2
Training loss: 1.5704336546662823
Validation loss: 2.4597730625062053

Epoch: 6| Step: 3
Training loss: 1.6008547824188522
Validation loss: 2.518097642857621

Epoch: 6| Step: 4
Training loss: 2.110370203418655
Validation loss: 2.4901491677949665

Epoch: 6| Step: 5
Training loss: 1.995647821053978
Validation loss: 2.459193324491738

Epoch: 6| Step: 6
Training loss: 1.5398305922381066
Validation loss: 2.4149318825688133

Epoch: 6| Step: 7
Training loss: 1.4947088220835292
Validation loss: 2.4416895679442976

Epoch: 6| Step: 8
Training loss: 1.4951065830524892
Validation loss: 2.435175549624775

Epoch: 6| Step: 9
Training loss: 1.3877174756872817
Validation loss: 2.4789886138364903

Epoch: 6| Step: 10
Training loss: 1.502982829581511
Validation loss: 2.474025599931206

Epoch: 6| Step: 11
Training loss: 1.5394147285913578
Validation loss: 2.4872828274948944

Epoch: 6| Step: 12
Training loss: 1.2834758497759153
Validation loss: 2.504691950908633

Epoch: 6| Step: 13
Training loss: 1.4087233514981619
Validation loss: 2.4943951916338416

Epoch: 533| Step: 0
Training loss: 1.7336030909117714
Validation loss: 2.480561436336183

Epoch: 6| Step: 1
Training loss: 1.7555528146116104
Validation loss: 2.46459378367952

Epoch: 6| Step: 2
Training loss: 1.7073599981102323
Validation loss: 2.4416342887452194

Epoch: 6| Step: 3
Training loss: 1.8207335414936128
Validation loss: 2.4929277183110026

Epoch: 6| Step: 4
Training loss: 1.2868942520902513
Validation loss: 2.4471650494575092

Epoch: 6| Step: 5
Training loss: 1.5009779126589975
Validation loss: 2.4414443503411456

Epoch: 6| Step: 6
Training loss: 1.2612194573264714
Validation loss: 2.4069892478613184

Epoch: 6| Step: 7
Training loss: 1.5865540457006813
Validation loss: 2.3746932392376956

Epoch: 6| Step: 8
Training loss: 1.393989778429208
Validation loss: 2.388826437230236

Epoch: 6| Step: 9
Training loss: 1.3913740648063113
Validation loss: 2.4430820493973893

Epoch: 6| Step: 10
Training loss: 1.0606151017922478
Validation loss: 2.4858026347701876

Epoch: 6| Step: 11
Training loss: 1.9930340931527277
Validation loss: 2.5340905040670094

Epoch: 6| Step: 12
Training loss: 1.7078687765023004
Validation loss: 2.563665797626853

Epoch: 6| Step: 13
Training loss: 1.4340417977736357
Validation loss: 2.51251885379449

Epoch: 534| Step: 0
Training loss: 1.6420968855548908
Validation loss: 2.525350544680629

Epoch: 6| Step: 1
Training loss: 1.3732035779455805
Validation loss: 2.492224581250957

Epoch: 6| Step: 2
Training loss: 1.6640724575837271
Validation loss: 2.490062499833691

Epoch: 6| Step: 3
Training loss: 1.1518290259158785
Validation loss: 2.4344684332104083

Epoch: 6| Step: 4
Training loss: 1.424207011648949
Validation loss: 2.419734078152154

Epoch: 6| Step: 5
Training loss: 1.6616778413070976
Validation loss: 2.4427224169832686

Epoch: 6| Step: 6
Training loss: 1.740093118434049
Validation loss: 2.4382632879724353

Epoch: 6| Step: 7
Training loss: 1.3741045984131142
Validation loss: 2.450533040787514

Epoch: 6| Step: 8
Training loss: 1.321185393400465
Validation loss: 2.489087907146111

Epoch: 6| Step: 9
Training loss: 1.4240119721198705
Validation loss: 2.489597466912201

Epoch: 6| Step: 10
Training loss: 1.8015550783638057
Validation loss: 2.5514598400404265

Epoch: 6| Step: 11
Training loss: 1.5698257375089855
Validation loss: 2.596253930116527

Epoch: 6| Step: 12
Training loss: 1.8438884877064652
Validation loss: 2.617036023422228

Epoch: 6| Step: 13
Training loss: 1.7165654951979545
Validation loss: 2.5689903080405037

Epoch: 535| Step: 0
Training loss: 1.489026701457841
Validation loss: 2.545625218070048

Epoch: 6| Step: 1
Training loss: 1.6614641131676218
Validation loss: 2.4916705361936855

Epoch: 6| Step: 2
Training loss: 1.4432551406988179
Validation loss: 2.4868662486346462

Epoch: 6| Step: 3
Training loss: 1.9553917510372223
Validation loss: 2.4639803761514636

Epoch: 6| Step: 4
Training loss: 1.4101075140226758
Validation loss: 2.4430842162978275

Epoch: 6| Step: 5
Training loss: 1.6731760542058687
Validation loss: 2.405366931313424

Epoch: 6| Step: 6
Training loss: 1.7300964368280451
Validation loss: 2.4405802660212634

Epoch: 6| Step: 7
Training loss: 1.491541218233166
Validation loss: 2.4645914937047917

Epoch: 6| Step: 8
Training loss: 1.3060470167813005
Validation loss: 2.489499521168373

Epoch: 6| Step: 9
Training loss: 1.2559903611949221
Validation loss: 2.4982538329077912

Epoch: 6| Step: 10
Training loss: 1.1487422201497133
Validation loss: 2.5160710209374066

Epoch: 6| Step: 11
Training loss: 1.6408858318981168
Validation loss: 2.4918347983271945

Epoch: 6| Step: 12
Training loss: 1.8662815849150727
Validation loss: 2.4793443051736546

Epoch: 6| Step: 13
Training loss: 1.0250003907737917
Validation loss: 2.4481820885303445

Epoch: 536| Step: 0
Training loss: 1.8108653886078774
Validation loss: 2.44832530349481

Epoch: 6| Step: 1
Training loss: 1.542685335422755
Validation loss: 2.450948184790415

Epoch: 6| Step: 2
Training loss: 1.5992235922542104
Validation loss: 2.458779477208633

Epoch: 6| Step: 3
Training loss: 1.3479673164831418
Validation loss: 2.4200989370580936

Epoch: 6| Step: 4
Training loss: 1.6137296409120487
Validation loss: 2.4321036162797274

Epoch: 6| Step: 5
Training loss: 1.1425011242082603
Validation loss: 2.447122703160354

Epoch: 6| Step: 6
Training loss: 1.4001524654882602
Validation loss: 2.46541962108419

Epoch: 6| Step: 7
Training loss: 1.707917217035229
Validation loss: 2.520914789516199

Epoch: 6| Step: 8
Training loss: 1.1755231402905089
Validation loss: 2.4640094668738275

Epoch: 6| Step: 9
Training loss: 1.5445329294692438
Validation loss: 2.4531070078141717

Epoch: 6| Step: 10
Training loss: 1.6027354341522517
Validation loss: 2.43166393089797

Epoch: 6| Step: 11
Training loss: 1.5723494797611397
Validation loss: 2.4253604404959352

Epoch: 6| Step: 12
Training loss: 1.9143390066541142
Validation loss: 2.432143077688866

Epoch: 6| Step: 13
Training loss: 1.2751982516072156
Validation loss: 2.489488684238814

Epoch: 537| Step: 0
Training loss: 1.657727572093071
Validation loss: 2.456369018990155

Epoch: 6| Step: 1
Training loss: 1.5847318228674956
Validation loss: 2.486423423165244

Epoch: 6| Step: 2
Training loss: 1.9662027380247418
Validation loss: 2.510954744615538

Epoch: 6| Step: 3
Training loss: 0.852033222531292
Validation loss: 2.522066300073979

Epoch: 6| Step: 4
Training loss: 1.860412436463038
Validation loss: 2.5598530438053646

Epoch: 6| Step: 5
Training loss: 1.3017418324547814
Validation loss: 2.482837316965366

Epoch: 6| Step: 6
Training loss: 1.1727281643687348
Validation loss: 2.4851859599406128

Epoch: 6| Step: 7
Training loss: 1.6020850840915726
Validation loss: 2.453375061156737

Epoch: 6| Step: 8
Training loss: 1.6457783009788713
Validation loss: 2.4316811734919845

Epoch: 6| Step: 9
Training loss: 1.5092722097585358
Validation loss: 2.389632837707339

Epoch: 6| Step: 10
Training loss: 1.5170668203364421
Validation loss: 2.344519779579805

Epoch: 6| Step: 11
Training loss: 1.5311116525860995
Validation loss: 2.3446199832859684

Epoch: 6| Step: 12
Training loss: 1.598851360839089
Validation loss: 2.3548675631355303

Epoch: 6| Step: 13
Training loss: 1.3887594761426432
Validation loss: 2.463615811978343

Epoch: 538| Step: 0
Training loss: 1.6674365014106451
Validation loss: 2.5322803307965076

Epoch: 6| Step: 1
Training loss: 1.5268953645701147
Validation loss: 2.5412942684816238

Epoch: 6| Step: 2
Training loss: 1.5525620850758712
Validation loss: 2.5633182634815594

Epoch: 6| Step: 3
Training loss: 1.578439209128455
Validation loss: 2.5618826529937615

Epoch: 6| Step: 4
Training loss: 1.2390009476332469
Validation loss: 2.50943694470057

Epoch: 6| Step: 5
Training loss: 1.5848508221915003
Validation loss: 2.4939239354117793

Epoch: 6| Step: 6
Training loss: 1.23893205646373
Validation loss: 2.4624050199311243

Epoch: 6| Step: 7
Training loss: 1.3128241184213572
Validation loss: 2.4435755404691006

Epoch: 6| Step: 8
Training loss: 1.2785754317139524
Validation loss: 2.428497120978644

Epoch: 6| Step: 9
Training loss: 1.3727741431824492
Validation loss: 2.3989247141908336

Epoch: 6| Step: 10
Training loss: 2.003193689558187
Validation loss: 2.4905275787109153

Epoch: 6| Step: 11
Training loss: 1.702095840700748
Validation loss: 2.508834060378254

Epoch: 6| Step: 12
Training loss: 1.7153158385275058
Validation loss: 2.576940431045819

Epoch: 6| Step: 13
Training loss: 1.9070774221241857
Validation loss: 2.6076990878378297

Epoch: 539| Step: 0
Training loss: 1.8450750341897104
Validation loss: 2.551365273978287

Epoch: 6| Step: 1
Training loss: 1.7706897976615912
Validation loss: 2.502315179353999

Epoch: 6| Step: 2
Training loss: 1.1975403014789865
Validation loss: 2.4590803330270705

Epoch: 6| Step: 3
Training loss: 1.4809484182850021
Validation loss: 2.4645558175688826

Epoch: 6| Step: 4
Training loss: 1.3315341950572699
Validation loss: 2.4290598011785356

Epoch: 6| Step: 5
Training loss: 1.518434810506508
Validation loss: 2.4038569943646637

Epoch: 6| Step: 6
Training loss: 1.511929992583974
Validation loss: 2.417209750572199

Epoch: 6| Step: 7
Training loss: 1.4310263946306219
Validation loss: 2.467924207086821

Epoch: 6| Step: 8
Training loss: 1.4506900855259073
Validation loss: 2.5012057257855935

Epoch: 6| Step: 9
Training loss: 1.399644511934553
Validation loss: 2.5480289870914845

Epoch: 6| Step: 10
Training loss: 1.648458616293217
Validation loss: 2.5974079752070858

Epoch: 6| Step: 11
Training loss: 1.8757339948225296
Validation loss: 2.5672379418760887

Epoch: 6| Step: 12
Training loss: 1.3949683863978342
Validation loss: 2.524805551833424

Epoch: 6| Step: 13
Training loss: 1.2807789843926536
Validation loss: 2.516425252403725

Epoch: 540| Step: 0
Training loss: 1.774464045457277
Validation loss: 2.4626633131617206

Epoch: 6| Step: 1
Training loss: 1.4960133503557878
Validation loss: 2.4816254703831744

Epoch: 6| Step: 2
Training loss: 1.3151663988956142
Validation loss: 2.433212749515301

Epoch: 6| Step: 3
Training loss: 1.3096033557247635
Validation loss: 2.4811217004406787

Epoch: 6| Step: 4
Training loss: 1.6206521777173957
Validation loss: 2.527713277258969

Epoch: 6| Step: 5
Training loss: 1.8373154683778656
Validation loss: 2.5583896420597707

Epoch: 6| Step: 6
Training loss: 1.3902465219548497
Validation loss: 2.537289852418204

Epoch: 6| Step: 7
Training loss: 1.3838666357077585
Validation loss: 2.4810103157501127

Epoch: 6| Step: 8
Training loss: 1.207757626331961
Validation loss: 2.4631749365607774

Epoch: 6| Step: 9
Training loss: 1.388692520352972
Validation loss: 2.4691021970339553

Epoch: 6| Step: 10
Training loss: 1.9925660615162113
Validation loss: 2.4334157951315767

Epoch: 6| Step: 11
Training loss: 1.5999650385136366
Validation loss: 2.409564903566863

Epoch: 6| Step: 12
Training loss: 1.5487464604248782
Validation loss: 2.3621853424375363

Epoch: 6| Step: 13
Training loss: 0.6265556049681013
Validation loss: 2.3871492886684025

Epoch: 541| Step: 0
Training loss: 1.8337116790283061
Validation loss: 2.401574856106274

Epoch: 6| Step: 1
Training loss: 1.5449572148000552
Validation loss: 2.406133542107967

Epoch: 6| Step: 2
Training loss: 1.6364325589538582
Validation loss: 2.495451807712045

Epoch: 6| Step: 3
Training loss: 1.4452771981541792
Validation loss: 2.5339209227575874

Epoch: 6| Step: 4
Training loss: 1.4773128157291462
Validation loss: 2.5225613342039903

Epoch: 6| Step: 5
Training loss: 1.6526372121381776
Validation loss: 2.5108661125889267

Epoch: 6| Step: 6
Training loss: 1.0887408401331682
Validation loss: 2.4878640822211513

Epoch: 6| Step: 7
Training loss: 1.3995759900918656
Validation loss: 2.4428343815253335

Epoch: 6| Step: 8
Training loss: 1.2719836683034593
Validation loss: 2.458801291385928

Epoch: 6| Step: 9
Training loss: 1.658252153693977
Validation loss: 2.4676354829869074

Epoch: 6| Step: 10
Training loss: 1.6992125061621994
Validation loss: 2.448809174890299

Epoch: 6| Step: 11
Training loss: 1.4640434011477719
Validation loss: 2.4713991613324864

Epoch: 6| Step: 12
Training loss: 1.5953616053452246
Validation loss: 2.4606131651630414

Epoch: 6| Step: 13
Training loss: 1.3548208221688172
Validation loss: 2.4982635866631346

Epoch: 542| Step: 0
Training loss: 1.3256970821137009
Validation loss: 2.4812215608199772

Epoch: 6| Step: 1
Training loss: 1.703121150301161
Validation loss: 2.455048475250358

Epoch: 6| Step: 2
Training loss: 1.8234439486901957
Validation loss: 2.4306511581143546

Epoch: 6| Step: 3
Training loss: 1.2899055729542248
Validation loss: 2.4663084165212683

Epoch: 6| Step: 4
Training loss: 1.2607202978619894
Validation loss: 2.420821394635076

Epoch: 6| Step: 5
Training loss: 1.2971588191880228
Validation loss: 2.4413290635900022

Epoch: 6| Step: 6
Training loss: 1.5443444408695484
Validation loss: 2.360771574820872

Epoch: 6| Step: 7
Training loss: 1.7539275917844785
Validation loss: 2.3244549865700974

Epoch: 6| Step: 8
Training loss: 1.816746505534469
Validation loss: 2.307239141782805

Epoch: 6| Step: 9
Training loss: 1.2995360775438571
Validation loss: 2.372739867129326

Epoch: 6| Step: 10
Training loss: 1.3006385977023713
Validation loss: 2.455817032015307

Epoch: 6| Step: 11
Training loss: 1.5981311791710413
Validation loss: 2.4937989196329693

Epoch: 6| Step: 12
Training loss: 1.2836078255288532
Validation loss: 2.5952097203455495

Epoch: 6| Step: 13
Training loss: 1.9068146791672929
Validation loss: 2.6232511356115844

Epoch: 543| Step: 0
Training loss: 1.0570155693069636
Validation loss: 2.633634421255856

Epoch: 6| Step: 1
Training loss: 1.5677044975090202
Validation loss: 2.637801236534147

Epoch: 6| Step: 2
Training loss: 1.4796003144791128
Validation loss: 2.592571443964514

Epoch: 6| Step: 3
Training loss: 1.473797019874934
Validation loss: 2.4945637489243055

Epoch: 6| Step: 4
Training loss: 1.4864944585497357
Validation loss: 2.4251072274332075

Epoch: 6| Step: 5
Training loss: 1.5058775825240855
Validation loss: 2.3692611935398196

Epoch: 6| Step: 6
Training loss: 1.8562488722878059
Validation loss: 2.321781099586705

Epoch: 6| Step: 7
Training loss: 1.628593140292463
Validation loss: 2.318106255840649

Epoch: 6| Step: 8
Training loss: 1.4218085975652108
Validation loss: 2.328668393713016

Epoch: 6| Step: 9
Training loss: 1.309956720452597
Validation loss: 2.419835793807324

Epoch: 6| Step: 10
Training loss: 1.6964705067664363
Validation loss: 2.445857303205158

Epoch: 6| Step: 11
Training loss: 1.8740937904085277
Validation loss: 2.4703028499150177

Epoch: 6| Step: 12
Training loss: 1.4937594457351633
Validation loss: 2.5213497517332204

Epoch: 6| Step: 13
Training loss: 1.4230443317265995
Validation loss: 2.5432919215202388

Epoch: 544| Step: 0
Training loss: 1.3679853018952641
Validation loss: 2.5322019993934863

Epoch: 6| Step: 1
Training loss: 1.0258466015558594
Validation loss: 2.489579378415728

Epoch: 6| Step: 2
Training loss: 1.3650871492169558
Validation loss: 2.4670720346282353

Epoch: 6| Step: 3
Training loss: 1.2610826335516756
Validation loss: 2.3868547886881726

Epoch: 6| Step: 4
Training loss: 1.3022711758223813
Validation loss: 2.3680579470426304

Epoch: 6| Step: 5
Training loss: 1.5737619044767928
Validation loss: 2.363189552838072

Epoch: 6| Step: 6
Training loss: 1.5745662182680853
Validation loss: 2.3625731013774565

Epoch: 6| Step: 7
Training loss: 1.5812242498298974
Validation loss: 2.3993779979550394

Epoch: 6| Step: 8
Training loss: 1.650104276656579
Validation loss: 2.390342934365023

Epoch: 6| Step: 9
Training loss: 1.644557635532837
Validation loss: 2.4685581050140057

Epoch: 6| Step: 10
Training loss: 1.811895598563895
Validation loss: 2.48380103936409

Epoch: 6| Step: 11
Training loss: 1.7264964923927963
Validation loss: 2.512874369513713

Epoch: 6| Step: 12
Training loss: 1.554243474840172
Validation loss: 2.5218214984596288

Epoch: 6| Step: 13
Training loss: 1.5176363311563248
Validation loss: 2.5402228423398765

Epoch: 545| Step: 0
Training loss: 1.7183322051914383
Validation loss: 2.5888222710897457

Epoch: 6| Step: 1
Training loss: 1.4695258830498255
Validation loss: 2.5998596680856165

Epoch: 6| Step: 2
Training loss: 1.5873044141297676
Validation loss: 2.6187304598116747

Epoch: 6| Step: 3
Training loss: 2.1100196135996914
Validation loss: 2.577057867114763

Epoch: 6| Step: 4
Training loss: 1.210169000724668
Validation loss: 2.5454317612960744

Epoch: 6| Step: 5
Training loss: 1.490743447642022
Validation loss: 2.4929697544494633

Epoch: 6| Step: 6
Training loss: 1.1427348754823297
Validation loss: 2.465517783095619

Epoch: 6| Step: 7
Training loss: 1.6566719381426342
Validation loss: 2.425146684818438

Epoch: 6| Step: 8
Training loss: 1.4477146291309977
Validation loss: 2.4053194515760477

Epoch: 6| Step: 9
Training loss: 1.3578691582661633
Validation loss: 2.3722479429383836

Epoch: 6| Step: 10
Training loss: 1.4073357523185532
Validation loss: 2.3941788295203628

Epoch: 6| Step: 11
Training loss: 1.3481627466172537
Validation loss: 2.4066758340360948

Epoch: 6| Step: 12
Training loss: 1.2964637288067065
Validation loss: 2.4931310245468263

Epoch: 6| Step: 13
Training loss: 1.7964307816439562
Validation loss: 2.4785356860431507

Epoch: 546| Step: 0
Training loss: 1.5497516125422786
Validation loss: 2.5190459267055507

Epoch: 6| Step: 1
Training loss: 1.2412792220042073
Validation loss: 2.5956912573961897

Epoch: 6| Step: 2
Training loss: 1.4774745163115666
Validation loss: 2.6234049015899803

Epoch: 6| Step: 3
Training loss: 2.0436745585945264
Validation loss: 2.625294768917601

Epoch: 6| Step: 4
Training loss: 1.377897677195074
Validation loss: 2.5827493540116566

Epoch: 6| Step: 5
Training loss: 1.1094319503565435
Validation loss: 2.5174677367089604

Epoch: 6| Step: 6
Training loss: 1.2042131333587045
Validation loss: 2.50549979530486

Epoch: 6| Step: 7
Training loss: 1.133095804502197
Validation loss: 2.5197737377173444

Epoch: 6| Step: 8
Training loss: 1.3179722648533034
Validation loss: 2.464162995899249

Epoch: 6| Step: 9
Training loss: 1.6994775333877963
Validation loss: 2.4567179731952486

Epoch: 6| Step: 10
Training loss: 2.110217794956454
Validation loss: 2.396342574825859

Epoch: 6| Step: 11
Training loss: 0.9914276337177464
Validation loss: 2.406532698220307

Epoch: 6| Step: 12
Training loss: 1.6993551265316311
Validation loss: 2.438768292996209

Epoch: 6| Step: 13
Training loss: 1.351371795783171
Validation loss: 2.4584451023957192

Epoch: 547| Step: 0
Training loss: 1.0433435231057535
Validation loss: 2.4768835338240693

Epoch: 6| Step: 1
Training loss: 1.1257545272122784
Validation loss: 2.508977751745091

Epoch: 6| Step: 2
Training loss: 1.213826234821803
Validation loss: 2.561786411190714

Epoch: 6| Step: 3
Training loss: 1.2328017143676988
Validation loss: 2.61998583383307

Epoch: 6| Step: 4
Training loss: 1.1986429528262306
Validation loss: 2.6130953224342583

Epoch: 6| Step: 5
Training loss: 1.9930641788498444
Validation loss: 2.674685895770052

Epoch: 6| Step: 6
Training loss: 1.4970197476222944
Validation loss: 2.5692457642401556

Epoch: 6| Step: 7
Training loss: 1.3566380714680248
Validation loss: 2.50914033934162

Epoch: 6| Step: 8
Training loss: 1.5782383037721688
Validation loss: 2.453947045657699

Epoch: 6| Step: 9
Training loss: 1.7546624335573224
Validation loss: 2.357318731045161

Epoch: 6| Step: 10
Training loss: 1.8915377848857238
Validation loss: 2.295222730812085

Epoch: 6| Step: 11
Training loss: 1.6928391939100382
Validation loss: 2.2957947426968013

Epoch: 6| Step: 12
Training loss: 1.7880164674090198
Validation loss: 2.343074244496426

Epoch: 6| Step: 13
Training loss: 1.1693789539035846
Validation loss: 2.379868121424155

Epoch: 548| Step: 0
Training loss: 1.441830208309604
Validation loss: 2.4298129466613196

Epoch: 6| Step: 1
Training loss: 1.3770167126413593
Validation loss: 2.5251351693247526

Epoch: 6| Step: 2
Training loss: 1.1159317321542825
Validation loss: 2.55522170597696

Epoch: 6| Step: 3
Training loss: 1.6823621170204839
Validation loss: 2.616246453949684

Epoch: 6| Step: 4
Training loss: 1.0459808402631627
Validation loss: 2.6123468723826067

Epoch: 6| Step: 5
Training loss: 1.3682738429591395
Validation loss: 2.5931585541691833

Epoch: 6| Step: 6
Training loss: 1.540271110203014
Validation loss: 2.5447916004733178

Epoch: 6| Step: 7
Training loss: 1.6193463202895793
Validation loss: 2.5090190060525983

Epoch: 6| Step: 8
Training loss: 1.7258409744503682
Validation loss: 2.3809000098420756

Epoch: 6| Step: 9
Training loss: 1.791974625254541
Validation loss: 2.347669388907287

Epoch: 6| Step: 10
Training loss: 1.4834284926905057
Validation loss: 2.3420941558606

Epoch: 6| Step: 11
Training loss: 1.4694931098332555
Validation loss: 2.358963121258875

Epoch: 6| Step: 12
Training loss: 1.6392739682291726
Validation loss: 2.3726459552909827

Epoch: 6| Step: 13
Training loss: 1.566502746501698
Validation loss: 2.502014019549691

Epoch: 549| Step: 0
Training loss: 1.9138362828692932
Validation loss: 2.5957747418150925

Epoch: 6| Step: 1
Training loss: 1.5457953336146033
Validation loss: 2.6502555037518825

Epoch: 6| Step: 2
Training loss: 1.4792028968922961
Validation loss: 2.6891309278097193

Epoch: 6| Step: 3
Training loss: 1.5495654512204273
Validation loss: 2.6181420427213804

Epoch: 6| Step: 4
Training loss: 1.4336822233002775
Validation loss: 2.5435945346298454

Epoch: 6| Step: 5
Training loss: 1.0562803320507863
Validation loss: 2.4634876565728163

Epoch: 6| Step: 6
Training loss: 1.3567475983820028
Validation loss: 2.4407077419772056

Epoch: 6| Step: 7
Training loss: 1.7784196552513487
Validation loss: 2.3829852158089895

Epoch: 6| Step: 8
Training loss: 1.2914490772860625
Validation loss: 2.383992474767284

Epoch: 6| Step: 9
Training loss: 1.4669130891357813
Validation loss: 2.4106805862299767

Epoch: 6| Step: 10
Training loss: 1.3254506730233464
Validation loss: 2.427504082142963

Epoch: 6| Step: 11
Training loss: 1.335337989540635
Validation loss: 2.4352806437820695

Epoch: 6| Step: 12
Training loss: 1.7284270700303135
Validation loss: 2.4599497969245414

Epoch: 6| Step: 13
Training loss: 1.1481611996396548
Validation loss: 2.5167789308146133

Epoch: 550| Step: 0
Training loss: 1.6929969267707417
Validation loss: 2.4775135950316676

Epoch: 6| Step: 1
Training loss: 1.8707721728527866
Validation loss: 2.5153177825718687

Epoch: 6| Step: 2
Training loss: 2.0589149991721167
Validation loss: 2.463976990535068

Epoch: 6| Step: 3
Training loss: 1.3200296855247249
Validation loss: 2.403382580763889

Epoch: 6| Step: 4
Training loss: 1.2421415788331658
Validation loss: 2.4156087353228886

Epoch: 6| Step: 5
Training loss: 1.5346664151976706
Validation loss: 2.4219335945231357

Epoch: 6| Step: 6
Training loss: 1.0548554463360347
Validation loss: 2.442202067035682

Epoch: 6| Step: 7
Training loss: 1.3914579832728933
Validation loss: 2.481929489436124

Epoch: 6| Step: 8
Training loss: 1.329400964294171
Validation loss: 2.5281834938426053

Epoch: 6| Step: 9
Training loss: 1.008437738977102
Validation loss: 2.5763361069631388

Epoch: 6| Step: 10
Training loss: 1.2192065044229572
Validation loss: 2.5688637340439127

Epoch: 6| Step: 11
Training loss: 1.4392904658139407
Validation loss: 2.582533034276853

Epoch: 6| Step: 12
Training loss: 1.4704673142365863
Validation loss: 2.5000379651786284

Epoch: 6| Step: 13
Training loss: 1.643653834905895
Validation loss: 2.434354927575974

Testing loss: 2.482606752509233
