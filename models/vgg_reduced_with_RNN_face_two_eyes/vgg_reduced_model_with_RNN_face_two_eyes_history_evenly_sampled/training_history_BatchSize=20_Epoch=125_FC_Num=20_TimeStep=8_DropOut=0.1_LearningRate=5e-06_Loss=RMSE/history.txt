Epoch: 1| Step: 0
Training loss: 6.18082260335946
Validation loss: 5.811163711738532

Epoch: 5| Step: 1
Training loss: 6.2533981240717855
Validation loss: 5.8072160530952575

Epoch: 5| Step: 2
Training loss: 6.7722749867451295
Validation loss: 5.803754490477339

Epoch: 5| Step: 3
Training loss: 5.3073802737200815
Validation loss: 5.8010049524280225

Epoch: 5| Step: 4
Training loss: 5.707610407065105
Validation loss: 5.79792797883757

Epoch: 5| Step: 5
Training loss: 5.603779416608045
Validation loss: 5.795550718590361

Epoch: 5| Step: 6
Training loss: 5.7834264009373015
Validation loss: 5.79312490910331

Epoch: 5| Step: 7
Training loss: 5.6998167711221415
Validation loss: 5.790751172020268

Epoch: 5| Step: 8
Training loss: 5.322780938355871
Validation loss: 5.7883201002302505

Epoch: 5| Step: 9
Training loss: 6.321541231766338
Validation loss: 5.785840988363372

Epoch: 5| Step: 10
Training loss: 4.779331196239659
Validation loss: 5.783148220516284

Epoch: 2| Step: 0
Training loss: 6.21699445472238
Validation loss: 5.780092059006698

Epoch: 5| Step: 1
Training loss: 5.242577164518204
Validation loss: 5.777128489312716

Epoch: 5| Step: 2
Training loss: 6.39049695919637
Validation loss: 5.7740806552054815

Epoch: 5| Step: 3
Training loss: 6.073606405026885
Validation loss: 5.770863071340003

Epoch: 5| Step: 4
Training loss: 5.381252112482345
Validation loss: 5.76748427603579

Epoch: 5| Step: 5
Training loss: 5.670191323148918
Validation loss: 5.763490656385218

Epoch: 5| Step: 6
Training loss: 5.642288934751372
Validation loss: 5.7599112047053085

Epoch: 5| Step: 7
Training loss: 5.720147300904319
Validation loss: 5.755845136541438

Epoch: 5| Step: 8
Training loss: 6.179556631831739
Validation loss: 5.751386353164736

Epoch: 5| Step: 9
Training loss: 5.8109555397256285
Validation loss: 5.7467257079393965

Epoch: 5| Step: 10
Training loss: 5.234460995095835
Validation loss: 5.742437971282083

Epoch: 3| Step: 0
Training loss: 5.293014514908239
Validation loss: 5.737670044739814

Epoch: 5| Step: 1
Training loss: 6.56195821796336
Validation loss: 5.7326503450353785

Epoch: 5| Step: 2
Training loss: 4.948082122713328
Validation loss: 5.727408397020435

Epoch: 5| Step: 3
Training loss: 5.899038281696923
Validation loss: 5.72138516913579

Epoch: 5| Step: 4
Training loss: 5.945563051656311
Validation loss: 5.715892543857622

Epoch: 5| Step: 5
Training loss: 5.609318384931477
Validation loss: 5.710115210168928

Epoch: 5| Step: 6
Training loss: 5.372598688311776
Validation loss: 5.703321046335145

Epoch: 5| Step: 7
Training loss: 6.321223208683894
Validation loss: 5.696631193572174

Epoch: 5| Step: 8
Training loss: 6.040314972603806
Validation loss: 5.689417886538811

Epoch: 5| Step: 9
Training loss: 4.8905163835158065
Validation loss: 5.682107685369125

Epoch: 5| Step: 10
Training loss: 6.111533795776152
Validation loss: 5.674322300168165

Epoch: 4| Step: 0
Training loss: 6.1286535460172145
Validation loss: 5.666293453446643

Epoch: 5| Step: 1
Training loss: 5.495147298239211
Validation loss: 5.657567097220217

Epoch: 5| Step: 2
Training loss: 6.4366475253789375
Validation loss: 5.6485301353558155

Epoch: 5| Step: 3
Training loss: 5.303398144172315
Validation loss: 5.639277927981074

Epoch: 5| Step: 4
Training loss: 4.312988695844045
Validation loss: 5.6292614216582795

Epoch: 5| Step: 5
Training loss: 4.648244029915546
Validation loss: 5.6192152606679056

Epoch: 5| Step: 6
Training loss: 6.501395442533496
Validation loss: 5.608240754244497

Epoch: 5| Step: 7
Training loss: 6.407424446937544
Validation loss: 5.598172319952534

Epoch: 5| Step: 8
Training loss: 6.218462913442467
Validation loss: 5.585323371519137

Epoch: 5| Step: 9
Training loss: 5.009218110919475
Validation loss: 5.5732691088618225

Epoch: 5| Step: 10
Training loss: 5.1581953598247114
Validation loss: 5.5606359695563

Epoch: 5| Step: 0
Training loss: 5.803686207065979
Validation loss: 5.547403387877027

Epoch: 5| Step: 1
Training loss: 5.613870248706459
Validation loss: 5.533171394939723

Epoch: 5| Step: 2
Training loss: 6.50707651947649
Validation loss: 5.519069349732587

Epoch: 5| Step: 3
Training loss: 6.045855137973886
Validation loss: 5.503607192572892

Epoch: 5| Step: 4
Training loss: 4.798724783940203
Validation loss: 5.488057629709395

Epoch: 5| Step: 5
Training loss: 4.965442636356921
Validation loss: 5.471457186985526

Epoch: 5| Step: 6
Training loss: 6.596578127109581
Validation loss: 5.454523459800657

Epoch: 5| Step: 7
Training loss: 5.027780983621174
Validation loss: 5.436066993717142

Epoch: 5| Step: 8
Training loss: 4.601118341586764
Validation loss: 5.418421085230608

Epoch: 5| Step: 9
Training loss: 5.328805650657151
Validation loss: 5.398590395825795

Epoch: 5| Step: 10
Training loss: 4.828648017282341
Validation loss: 5.379331575220876

Epoch: 6| Step: 0
Training loss: 4.881552181097457
Validation loss: 5.359024586016575

Epoch: 5| Step: 1
Training loss: 6.278045292258602
Validation loss: 5.337994300359533

Epoch: 5| Step: 2
Training loss: 5.486396264929291
Validation loss: 5.316681196931177

Epoch: 5| Step: 3
Training loss: 5.1935488812265405
Validation loss: 5.294973626675964

Epoch: 5| Step: 4
Training loss: 5.588605678318553
Validation loss: 5.271024784241324

Epoch: 5| Step: 5
Training loss: 5.159865897454305
Validation loss: 5.247406758059606

Epoch: 5| Step: 6
Training loss: 5.509285111756965
Validation loss: 5.224296690959117

Epoch: 5| Step: 7
Training loss: 4.582569035469487
Validation loss: 5.199151215092668

Epoch: 5| Step: 8
Training loss: 5.281685715257107
Validation loss: 5.1750179672305805

Epoch: 5| Step: 9
Training loss: 5.01802894286547
Validation loss: 5.15099407167296

Epoch: 5| Step: 10
Training loss: 5.120528526742965
Validation loss: 5.126066427579902

Epoch: 7| Step: 0
Training loss: 5.336803360442675
Validation loss: 5.100532276833438

Epoch: 5| Step: 1
Training loss: 6.250427536646525
Validation loss: 5.075273733547708

Epoch: 5| Step: 2
Training loss: 4.370487610872168
Validation loss: 5.048728515901667

Epoch: 5| Step: 3
Training loss: 4.938242796060335
Validation loss: 5.025688577327753

Epoch: 5| Step: 4
Training loss: 4.836315331312333
Validation loss: 5.000646594498154

Epoch: 5| Step: 5
Training loss: 4.826847635814211
Validation loss: 4.974005292007089

Epoch: 5| Step: 6
Training loss: 5.240930807418604
Validation loss: 4.950868294785189

Epoch: 5| Step: 7
Training loss: 5.229627591471825
Validation loss: 4.926319340497328

Epoch: 5| Step: 8
Training loss: 5.050265375095324
Validation loss: 4.90433332612215

Epoch: 5| Step: 9
Training loss: 4.492133788741398
Validation loss: 4.8810157249393304

Epoch: 5| Step: 10
Training loss: 4.649433651141522
Validation loss: 4.857229088631099

Epoch: 8| Step: 0
Training loss: 5.296645978179405
Validation loss: 4.8349203842901805

Epoch: 5| Step: 1
Training loss: 4.703904806484374
Validation loss: 4.813850719348857

Epoch: 5| Step: 2
Training loss: 5.427940120414527
Validation loss: 4.791972400529446

Epoch: 5| Step: 3
Training loss: 4.933492845241871
Validation loss: 4.77143161882481

Epoch: 5| Step: 4
Training loss: 5.3023358218087555
Validation loss: 4.7505558705482045

Epoch: 5| Step: 5
Training loss: 4.910949982770784
Validation loss: 4.729499887914288

Epoch: 5| Step: 6
Training loss: 5.033786868615661
Validation loss: 4.7078271292988765

Epoch: 5| Step: 7
Training loss: 4.190445959717008
Validation loss: 4.685549050420089

Epoch: 5| Step: 8
Training loss: 4.334547435188074
Validation loss: 4.666458193712108

Epoch: 5| Step: 9
Training loss: 4.66543349366786
Validation loss: 4.647692920659146

Epoch: 5| Step: 10
Training loss: 3.839635616339103
Validation loss: 4.625829230427062

Epoch: 9| Step: 0
Training loss: 4.80738419939328
Validation loss: 4.606853201138772

Epoch: 5| Step: 1
Training loss: 3.271109761667434
Validation loss: 4.587813588132995

Epoch: 5| Step: 2
Training loss: 5.026638405380605
Validation loss: 4.57509513812992

Epoch: 5| Step: 3
Training loss: 5.5073202143141415
Validation loss: 4.561057044213773

Epoch: 5| Step: 4
Training loss: 4.362907263865555
Validation loss: 4.546286809300719

Epoch: 5| Step: 5
Training loss: 4.944435945901223
Validation loss: 4.531847953451558

Epoch: 5| Step: 6
Training loss: 4.300257679515204
Validation loss: 4.520128519073482

Epoch: 5| Step: 7
Training loss: 4.349219521847425
Validation loss: 4.505747933134676

Epoch: 5| Step: 8
Training loss: 3.6163369944103816
Validation loss: 4.495529449434644

Epoch: 5| Step: 9
Training loss: 5.179867564389957
Validation loss: 4.479012176680644

Epoch: 5| Step: 10
Training loss: 5.142920448276902
Validation loss: 4.469043040834132

Epoch: 10| Step: 0
Training loss: 4.717855406585833
Validation loss: 4.452901516602739

Epoch: 5| Step: 1
Training loss: 4.821797295251444
Validation loss: 4.444988900508551

Epoch: 5| Step: 2
Training loss: 4.875511729451939
Validation loss: 4.4297921929632516

Epoch: 5| Step: 3
Training loss: 5.278189771310131
Validation loss: 4.4149721570807525

Epoch: 5| Step: 4
Training loss: 3.911408337283291
Validation loss: 4.400801802878435

Epoch: 5| Step: 5
Training loss: 4.27242020069865
Validation loss: 4.386386131174185

Epoch: 5| Step: 6
Training loss: 4.463204096964111
Validation loss: 4.374911570790655

Epoch: 5| Step: 7
Training loss: 3.993643717179902
Validation loss: 4.358713318057592

Epoch: 5| Step: 8
Training loss: 4.048107062767236
Validation loss: 4.344046645659687

Epoch: 5| Step: 9
Training loss: 4.2117160509115354
Validation loss: 4.329809532497878

Epoch: 5| Step: 10
Training loss: 4.760543565568207
Validation loss: 4.315418541660257

Epoch: 11| Step: 0
Training loss: 3.756031780283158
Validation loss: 4.30458249676328

Epoch: 5| Step: 1
Training loss: 4.216577945625244
Validation loss: 4.289725019241243

Epoch: 5| Step: 2
Training loss: 4.412371556301044
Validation loss: 4.277838547570654

Epoch: 5| Step: 3
Training loss: 4.854018224102777
Validation loss: 4.262175870460975

Epoch: 5| Step: 4
Training loss: 5.246949717550281
Validation loss: 4.248297073300338

Epoch: 5| Step: 5
Training loss: 4.054807451711978
Validation loss: 4.23460723623944

Epoch: 5| Step: 6
Training loss: 4.62717139331897
Validation loss: 4.222965362540196

Epoch: 5| Step: 7
Training loss: 3.9097555071398458
Validation loss: 4.207860865103911

Epoch: 5| Step: 8
Training loss: 3.860964428488587
Validation loss: 4.193195899777016

Epoch: 5| Step: 9
Training loss: 4.337803564524827
Validation loss: 4.180407440618247

Epoch: 5| Step: 10
Training loss: 4.465381126071348
Validation loss: 4.166471591607829

Epoch: 12| Step: 0
Training loss: 4.3967906518151025
Validation loss: 4.1564075021618265

Epoch: 5| Step: 1
Training loss: 4.799299888415529
Validation loss: 4.14427039015269

Epoch: 5| Step: 2
Training loss: 4.039205345712087
Validation loss: 4.131185182117503

Epoch: 5| Step: 3
Training loss: 4.0896667617058675
Validation loss: 4.119817282717611

Epoch: 5| Step: 4
Training loss: 4.0942049428893865
Validation loss: 4.110945370158358

Epoch: 5| Step: 5
Training loss: 4.346827233475086
Validation loss: 4.100539829562568

Epoch: 5| Step: 6
Training loss: 4.321657271565617
Validation loss: 4.0893987234537335

Epoch: 5| Step: 7
Training loss: 4.6614909534982365
Validation loss: 4.077999940509818

Epoch: 5| Step: 8
Training loss: 3.9590451989114657
Validation loss: 4.0684333327336955

Epoch: 5| Step: 9
Training loss: 3.8160760086534964
Validation loss: 4.059661893645311

Epoch: 5| Step: 10
Training loss: 3.951059638714247
Validation loss: 4.050401035933565

Epoch: 13| Step: 0
Training loss: 4.399519304547257
Validation loss: 4.040506815359868

Epoch: 5| Step: 1
Training loss: 5.195530386349732
Validation loss: 4.0328621095218695

Epoch: 5| Step: 2
Training loss: 4.30000795762856
Validation loss: 4.021870928029873

Epoch: 5| Step: 3
Training loss: 4.020837391800224
Validation loss: 4.013659836255263

Epoch: 5| Step: 4
Training loss: 3.7652134334054264
Validation loss: 4.002576435351268

Epoch: 5| Step: 5
Training loss: 4.696983002152527
Validation loss: 3.99787099641675

Epoch: 5| Step: 6
Training loss: 2.8910977363651718
Validation loss: 3.986493752811209

Epoch: 5| Step: 7
Training loss: 4.860745840729983
Validation loss: 3.9803930161450727

Epoch: 5| Step: 8
Training loss: 3.342907665788468
Validation loss: 3.9740039767607565

Epoch: 5| Step: 9
Training loss: 3.428446412645577
Validation loss: 3.965380669131047

Epoch: 5| Step: 10
Training loss: 4.165959768730098
Validation loss: 3.9580533527173682

Epoch: 14| Step: 0
Training loss: 4.068389379690124
Validation loss: 3.952271576524196

Epoch: 5| Step: 1
Training loss: 4.64015888994394
Validation loss: 3.9473533495802573

Epoch: 5| Step: 2
Training loss: 4.332865958807425
Validation loss: 3.939715755389704

Epoch: 5| Step: 3
Training loss: 3.3206591615906706
Validation loss: 3.933482354749316

Epoch: 5| Step: 4
Training loss: 4.839686701384059
Validation loss: 3.930439241247545

Epoch: 5| Step: 5
Training loss: 4.1780699264788375
Validation loss: 3.9251036043054914

Epoch: 5| Step: 6
Training loss: 3.825341532300759
Validation loss: 3.917363982917901

Epoch: 5| Step: 7
Training loss: 3.7249634708943216
Validation loss: 3.9133762872128157

Epoch: 5| Step: 8
Training loss: 4.096152263240157
Validation loss: 3.9078090793552516

Epoch: 5| Step: 9
Training loss: 3.993411718139482
Validation loss: 3.902347229200097

Epoch: 5| Step: 10
Training loss: 3.5828499726749343
Validation loss: 3.8991773615424328

Epoch: 15| Step: 0
Training loss: 3.9589537820259753
Validation loss: 3.8940472542726994

Epoch: 5| Step: 1
Training loss: 3.466823695978996
Validation loss: 3.889501656004494

Epoch: 5| Step: 2
Training loss: 4.037257722842858
Validation loss: 3.881214250574279

Epoch: 5| Step: 3
Training loss: 4.017581923005011
Validation loss: 3.878961930656394

Epoch: 5| Step: 4
Training loss: 4.5274794050535
Validation loss: 3.875184175505417

Epoch: 5| Step: 5
Training loss: 4.471069160965716
Validation loss: 3.867650345107823

Epoch: 5| Step: 6
Training loss: 3.9908988649557604
Validation loss: 3.862946893575917

Epoch: 5| Step: 7
Training loss: 3.950006513952365
Validation loss: 3.85650128155334

Epoch: 5| Step: 8
Training loss: 4.566114274374919
Validation loss: 3.852569395880863

Epoch: 5| Step: 9
Training loss: 3.3028816357249884
Validation loss: 3.8439984851964057

Epoch: 5| Step: 10
Training loss: 3.832683978159487
Validation loss: 3.8388936728228575

Epoch: 16| Step: 0
Training loss: 4.194601840560088
Validation loss: 3.8345586366420146

Epoch: 5| Step: 1
Training loss: 4.45174774823507
Validation loss: 3.826518321190206

Epoch: 5| Step: 2
Training loss: 3.6432544561039633
Validation loss: 3.8209226149484787

Epoch: 5| Step: 3
Training loss: 4.080424044395396
Validation loss: 3.811805487006977

Epoch: 5| Step: 4
Training loss: 4.324597625537287
Validation loss: 3.8027545726951035

Epoch: 5| Step: 5
Training loss: 4.312149033570121
Validation loss: 3.795267341789003

Epoch: 5| Step: 6
Training loss: 4.027730899114129
Validation loss: 3.7828059814235395

Epoch: 5| Step: 7
Training loss: 3.831528252458756
Validation loss: 3.7742013499757165

Epoch: 5| Step: 8
Training loss: 3.447306845097043
Validation loss: 3.7630188054132074

Epoch: 5| Step: 9
Training loss: 3.334709995820564
Validation loss: 3.756901535419858

Epoch: 5| Step: 10
Training loss: 3.8100979851966166
Validation loss: 3.746479460121699

Epoch: 17| Step: 0
Training loss: 4.178300003346905
Validation loss: 3.7373294862350552

Epoch: 5| Step: 1
Training loss: 4.382380771962741
Validation loss: 3.7338668086839553

Epoch: 5| Step: 2
Training loss: 3.622195112351873
Validation loss: 3.7225781772906976

Epoch: 5| Step: 3
Training loss: 4.179369420577955
Validation loss: 3.7169149642998525

Epoch: 5| Step: 4
Training loss: 3.7076078555366414
Validation loss: 3.7124091440441758

Epoch: 5| Step: 5
Training loss: 4.078153062044255
Validation loss: 3.710452320654687

Epoch: 5| Step: 6
Training loss: 3.483133958893649
Validation loss: 3.703796200585668

Epoch: 5| Step: 7
Training loss: 3.6556549892281347
Validation loss: 3.696021950152933

Epoch: 5| Step: 8
Training loss: 4.029622067130645
Validation loss: 3.693584287160611

Epoch: 5| Step: 9
Training loss: 3.594678277911932
Validation loss: 3.689233643864147

Epoch: 5| Step: 10
Training loss: 3.783618658008621
Validation loss: 3.686119083818023

Epoch: 18| Step: 0
Training loss: 3.9709059498816104
Validation loss: 3.6785609772088423

Epoch: 5| Step: 1
Training loss: 3.792261908343057
Validation loss: 3.6718368329307665

Epoch: 5| Step: 2
Training loss: 3.387917276843023
Validation loss: 3.6696900090364983

Epoch: 5| Step: 3
Training loss: 3.057152887386476
Validation loss: 3.6634415615668674

Epoch: 5| Step: 4
Training loss: 4.633563799352073
Validation loss: 3.659839997448004

Epoch: 5| Step: 5
Training loss: 3.9539285076896493
Validation loss: 3.6541795304911133

Epoch: 5| Step: 6
Training loss: 3.6545680163138647
Validation loss: 3.6486089512031925

Epoch: 5| Step: 7
Training loss: 4.047003666662351
Validation loss: 3.6460707603294464

Epoch: 5| Step: 8
Training loss: 3.8622739460296818
Validation loss: 3.6413714781572963

Epoch: 5| Step: 9
Training loss: 4.062290127541639
Validation loss: 3.6362739950935095

Epoch: 5| Step: 10
Training loss: 3.611746269185596
Validation loss: 3.636749191670491

Epoch: 19| Step: 0
Training loss: 4.161375169873939
Validation loss: 3.630023748162569

Epoch: 5| Step: 1
Training loss: 3.393508599057536
Validation loss: 3.623428269902046

Epoch: 5| Step: 2
Training loss: 3.352793220822274
Validation loss: 3.618620900752987

Epoch: 5| Step: 3
Training loss: 3.4187635794584343
Validation loss: 3.6142528770956526

Epoch: 5| Step: 4
Training loss: 3.900053923796504
Validation loss: 3.613614527379441

Epoch: 5| Step: 5
Training loss: 2.932103495999908
Validation loss: 3.610147658515339

Epoch: 5| Step: 6
Training loss: 3.5091190071526306
Validation loss: 3.6078098090596695

Epoch: 5| Step: 7
Training loss: 4.133459029798819
Validation loss: 3.6049819788524253

Epoch: 5| Step: 8
Training loss: 4.56777648990924
Validation loss: 3.5991778729331774

Epoch: 5| Step: 9
Training loss: 4.153150966267467
Validation loss: 3.599254192043876

Epoch: 5| Step: 10
Training loss: 4.075954517369046
Validation loss: 3.5981895841804294

Epoch: 20| Step: 0
Training loss: 4.2580998594974435
Validation loss: 3.592237931818295

Epoch: 5| Step: 1
Training loss: 2.895959334525283
Validation loss: 3.5912946805110537

Epoch: 5| Step: 2
Training loss: 3.081085794959842
Validation loss: 3.5872709075016886

Epoch: 5| Step: 3
Training loss: 3.454056143900218
Validation loss: 3.580421428384665

Epoch: 5| Step: 4
Training loss: 3.69272385752239
Validation loss: 3.579157497122986

Epoch: 5| Step: 5
Training loss: 3.8808749793266433
Validation loss: 3.5763891508746997

Epoch: 5| Step: 6
Training loss: 4.1346537593364125
Validation loss: 3.5739476531071004

Epoch: 5| Step: 7
Training loss: 3.761090726310399
Validation loss: 3.573637895138448

Epoch: 5| Step: 8
Training loss: 3.768705635379035
Validation loss: 3.5703446251335897

Epoch: 5| Step: 9
Training loss: 4.025226676671015
Validation loss: 3.5650148853872063

Epoch: 5| Step: 10
Training loss: 4.401285824596039
Validation loss: 3.5630364941471755

Epoch: 21| Step: 0
Training loss: 3.9133094169713365
Validation loss: 3.558879360276088

Epoch: 5| Step: 1
Training loss: 3.4831591481975614
Validation loss: 3.5561162980604877

Epoch: 5| Step: 2
Training loss: 3.8312670211040514
Validation loss: 3.5561221100340514

Epoch: 5| Step: 3
Training loss: 2.6169805188676536
Validation loss: 3.550646936471054

Epoch: 5| Step: 4
Training loss: 4.6647507049578
Validation loss: 3.550732678283644

Epoch: 5| Step: 5
Training loss: 3.9343125293671513
Validation loss: 3.547297375370283

Epoch: 5| Step: 6
Training loss: 4.294571026483748
Validation loss: 3.548448066430005

Epoch: 5| Step: 7
Training loss: 3.18747980447991
Validation loss: 3.53798887088925

Epoch: 5| Step: 8
Training loss: 3.4379813117406455
Validation loss: 3.5383553522278364

Epoch: 5| Step: 9
Training loss: 3.6430836508291264
Validation loss: 3.536790655676878

Epoch: 5| Step: 10
Training loss: 3.8707825875352158
Validation loss: 3.531678550097163

Epoch: 22| Step: 0
Training loss: 2.8057831135821325
Validation loss: 3.5323648350933055

Epoch: 5| Step: 1
Training loss: 2.605675730569408
Validation loss: 3.5298755035064264

Epoch: 5| Step: 2
Training loss: 4.050428560917919
Validation loss: 3.5274242178949535

Epoch: 5| Step: 3
Training loss: 4.397120114172674
Validation loss: 3.524397122888043

Epoch: 5| Step: 4
Training loss: 3.4888990651796905
Validation loss: 3.526535284393223

Epoch: 5| Step: 5
Training loss: 3.711599062124225
Validation loss: 3.5204102612159383

Epoch: 5| Step: 6
Training loss: 4.16582470334319
Validation loss: 3.516507935850333

Epoch: 5| Step: 7
Training loss: 4.034183824472885
Validation loss: 3.512779753294688

Epoch: 5| Step: 8
Training loss: 4.02311891942604
Validation loss: 3.513248378796513

Epoch: 5| Step: 9
Training loss: 3.6222568524609344
Validation loss: 3.5057391212303486

Epoch: 5| Step: 10
Training loss: 3.650908391082708
Validation loss: 3.5028181435281986

Epoch: 23| Step: 0
Training loss: 3.800024163018752
Validation loss: 3.4984475837259588

Epoch: 5| Step: 1
Training loss: 3.804322148822826
Validation loss: 3.499865765202185

Epoch: 5| Step: 2
Training loss: 4.120934997682801
Validation loss: 3.4974747057439166

Epoch: 5| Step: 3
Training loss: 4.031239117748151
Validation loss: 3.4929571091718468

Epoch: 5| Step: 4
Training loss: 2.8868935084322596
Validation loss: 3.490956315556075

Epoch: 5| Step: 5
Training loss: 3.9028166063458007
Validation loss: 3.4866908911093266

Epoch: 5| Step: 6
Training loss: 3.789359861680587
Validation loss: 3.4846883447408725

Epoch: 5| Step: 7
Training loss: 2.8849715751424454
Validation loss: 3.488859175636162

Epoch: 5| Step: 8
Training loss: 3.8388833351542857
Validation loss: 3.4891855942843732

Epoch: 5| Step: 9
Training loss: 3.43517932584784
Validation loss: 3.4802994033923627

Epoch: 5| Step: 10
Training loss: 4.044523638577564
Validation loss: 3.47582623938858

Epoch: 24| Step: 0
Training loss: 4.256728287989901
Validation loss: 3.4781517452999133

Epoch: 5| Step: 1
Training loss: 4.277695788523919
Validation loss: 3.477741263117945

Epoch: 5| Step: 2
Training loss: 3.8312494722898034
Validation loss: 3.4718715875161976

Epoch: 5| Step: 3
Training loss: 3.5406178136821653
Validation loss: 3.4700616678922334

Epoch: 5| Step: 4
Training loss: 3.120734240627125
Validation loss: 3.4684502907178762

Epoch: 5| Step: 5
Training loss: 3.6533529427505633
Validation loss: 3.467345979687407

Epoch: 5| Step: 6
Training loss: 3.669127130052102
Validation loss: 3.462845300948184

Epoch: 5| Step: 7
Training loss: 3.1066149245879915
Validation loss: 3.4603436158937906

Epoch: 5| Step: 8
Training loss: 3.64905224344495
Validation loss: 3.458745154777992

Epoch: 5| Step: 9
Training loss: 3.2512675527812327
Validation loss: 3.4591744002229006

Epoch: 5| Step: 10
Training loss: 3.9974572921485065
Validation loss: 3.4610410977717114

Epoch: 25| Step: 0
Training loss: 3.592468165798805
Validation loss: 3.4548074000639097

Epoch: 5| Step: 1
Training loss: 3.712957278259892
Validation loss: 3.454931628912158

Epoch: 5| Step: 2
Training loss: 3.3663875753717347
Validation loss: 3.4517272279168574

Epoch: 5| Step: 3
Training loss: 2.8648419257689515
Validation loss: 3.4518367019895275

Epoch: 5| Step: 4
Training loss: 3.944075044757541
Validation loss: 3.449683528020298

Epoch: 5| Step: 5
Training loss: 3.9672229862917243
Validation loss: 3.4495137447283724

Epoch: 5| Step: 6
Training loss: 4.012100513572144
Validation loss: 3.445987093206846

Epoch: 5| Step: 7
Training loss: 3.755267449212147
Validation loss: 3.44205706326165

Epoch: 5| Step: 8
Training loss: 4.04813179914296
Validation loss: 3.4468520254192936

Epoch: 5| Step: 9
Training loss: 2.9958219044290066
Validation loss: 3.4480642350284847

Epoch: 5| Step: 10
Training loss: 3.914792417282193
Validation loss: 3.4463473527878072

Epoch: 26| Step: 0
Training loss: 2.9893270420356495
Validation loss: 3.446005008953953

Epoch: 5| Step: 1
Training loss: 3.8206412519112107
Validation loss: 3.444092135837451

Epoch: 5| Step: 2
Training loss: 3.9738839652059417
Validation loss: 3.439380910506076

Epoch: 5| Step: 3
Training loss: 3.420808808908281
Validation loss: 3.4364820641853386

Epoch: 5| Step: 4
Training loss: 3.928175041711506
Validation loss: 3.4368778683779606

Epoch: 5| Step: 5
Training loss: 3.8300640566974544
Validation loss: 3.4352204790276315

Epoch: 5| Step: 6
Training loss: 3.6702365547465536
Validation loss: 3.4347994073098334

Epoch: 5| Step: 7
Training loss: 3.7099793170856254
Validation loss: 3.43199503874459

Epoch: 5| Step: 8
Training loss: 3.0963367475570966
Validation loss: 3.430255960230916

Epoch: 5| Step: 9
Training loss: 3.906581406840134
Validation loss: 3.428139289606838

Epoch: 5| Step: 10
Training loss: 3.751815102305769
Validation loss: 3.4326334664904543

Epoch: 27| Step: 0
Training loss: 3.297019340645847
Validation loss: 3.432247878565012

Epoch: 5| Step: 1
Training loss: 3.3394992226812352
Validation loss: 3.4301050885773323

Epoch: 5| Step: 2
Training loss: 4.663071723636714
Validation loss: 3.4211134652007438

Epoch: 5| Step: 3
Training loss: 3.289914562194296
Validation loss: 3.4233568382165185

Epoch: 5| Step: 4
Training loss: 4.102926438023836
Validation loss: 3.41663240274996

Epoch: 5| Step: 5
Training loss: 3.341979797101323
Validation loss: 3.418479430035513

Epoch: 5| Step: 6
Training loss: 3.7291060430333687
Validation loss: 3.417760173287448

Epoch: 5| Step: 7
Training loss: 3.3738361753840507
Validation loss: 3.417451998367392

Epoch: 5| Step: 8
Training loss: 3.605725445603798
Validation loss: 3.415864520649646

Epoch: 5| Step: 9
Training loss: 3.5368366441738304
Validation loss: 3.4133961709388667

Epoch: 5| Step: 10
Training loss: 3.542694855084569
Validation loss: 3.4121619485807746

Epoch: 28| Step: 0
Training loss: 4.038985290379666
Validation loss: 3.4131296674864045

Epoch: 5| Step: 1
Training loss: 3.367541088824948
Validation loss: 3.420483211590806

Epoch: 5| Step: 2
Training loss: 3.1811559037417725
Validation loss: 3.4188965864550758

Epoch: 5| Step: 3
Training loss: 3.9770137028754236
Validation loss: 3.4100405699945107

Epoch: 5| Step: 4
Training loss: 3.5067506810072935
Validation loss: 3.4052683091208906

Epoch: 5| Step: 5
Training loss: 3.7213594914000714
Validation loss: 3.4046426657144995

Epoch: 5| Step: 6
Training loss: 3.600511641701947
Validation loss: 3.405479838561541

Epoch: 5| Step: 7
Training loss: 3.2163389490298417
Validation loss: 3.4044177902299078

Epoch: 5| Step: 8
Training loss: 3.8114318602084714
Validation loss: 3.4019786346406664

Epoch: 5| Step: 9
Training loss: 4.003943645023543
Validation loss: 3.403034020048859

Epoch: 5| Step: 10
Training loss: 3.3217579287177914
Validation loss: 3.4018467612596597

Epoch: 29| Step: 0
Training loss: 2.846911506963117
Validation loss: 3.4005155074225595

Epoch: 5| Step: 1
Training loss: 3.5901451274896936
Validation loss: 3.3980783157907797

Epoch: 5| Step: 2
Training loss: 3.896494409839835
Validation loss: 3.4014829793309103

Epoch: 5| Step: 3
Training loss: 3.0516298410668434
Validation loss: 3.3980079138913752

Epoch: 5| Step: 4
Training loss: 4.168936047841954
Validation loss: 3.3942701052187183

Epoch: 5| Step: 5
Training loss: 3.334803225361263
Validation loss: 3.3935797530404077

Epoch: 5| Step: 6
Training loss: 4.2688392015467285
Validation loss: 3.3928111433534256

Epoch: 5| Step: 7
Training loss: 3.0567151922813536
Validation loss: 3.3960235980768343

Epoch: 5| Step: 8
Training loss: 4.461045673080971
Validation loss: 3.3968875792891438

Epoch: 5| Step: 9
Training loss: 3.1664698355554286
Validation loss: 3.393813467073449

Epoch: 5| Step: 10
Training loss: 3.559991455282179
Validation loss: 3.390620470977279

Epoch: 30| Step: 0
Training loss: 3.324908927874884
Validation loss: 3.388918280803254

Epoch: 5| Step: 1
Training loss: 3.877311755295659
Validation loss: 3.390169306142758

Epoch: 5| Step: 2
Training loss: 4.182487790397157
Validation loss: 3.3932765427611575

Epoch: 5| Step: 3
Training loss: 3.2449583415926737
Validation loss: 3.3887100796793166

Epoch: 5| Step: 4
Training loss: 2.762631450304655
Validation loss: 3.3856955913936546

Epoch: 5| Step: 5
Training loss: 4.3568685565879495
Validation loss: 3.3841907136119036

Epoch: 5| Step: 6
Training loss: 2.9020821824428653
Validation loss: 3.3867566269960707

Epoch: 5| Step: 7
Training loss: 3.706749538574684
Validation loss: 3.38621293137095

Epoch: 5| Step: 8
Training loss: 3.8097126261148757
Validation loss: 3.386064883790685

Epoch: 5| Step: 9
Training loss: 3.591937594952779
Validation loss: 3.382422136819495

Epoch: 5| Step: 10
Training loss: 3.652762551189318
Validation loss: 3.382212082007691

Epoch: 31| Step: 0
Training loss: 3.641361800525883
Validation loss: 3.381744971892929

Epoch: 5| Step: 1
Training loss: 3.783309123652185
Validation loss: 3.379739425679229

Epoch: 5| Step: 2
Training loss: 2.0230526355603202
Validation loss: 3.3811217420970894

Epoch: 5| Step: 3
Training loss: 3.669509060528437
Validation loss: 3.3790139469393905

Epoch: 5| Step: 4
Training loss: 4.270795099350898
Validation loss: 3.378473558188755

Epoch: 5| Step: 5
Training loss: 3.3736063587638085
Validation loss: 3.376380212815352

Epoch: 5| Step: 6
Training loss: 3.512146445294991
Validation loss: 3.378702233385278

Epoch: 5| Step: 7
Training loss: 3.6198770563313474
Validation loss: 3.3763226766151146

Epoch: 5| Step: 8
Training loss: 3.703895456507159
Validation loss: 3.374455171374762

Epoch: 5| Step: 9
Training loss: 3.853733650145615
Validation loss: 3.374346525126374

Epoch: 5| Step: 10
Training loss: 3.7667032178157487
Validation loss: 3.3741971606440315

Epoch: 32| Step: 0
Training loss: 2.6333724425425618
Validation loss: 3.373950118914083

Epoch: 5| Step: 1
Training loss: 3.725508758825425
Validation loss: 3.3738805767074607

Epoch: 5| Step: 2
Training loss: 4.751034071947665
Validation loss: 3.373601250638092

Epoch: 5| Step: 3
Training loss: 3.2378530184660104
Validation loss: 3.37273111042313

Epoch: 5| Step: 4
Training loss: 3.6858540110331846
Validation loss: 3.3735314869402204

Epoch: 5| Step: 5
Training loss: 3.6949478195284553
Validation loss: 3.3697745959308265

Epoch: 5| Step: 6
Training loss: 2.8934095013462007
Validation loss: 3.3698069728423756

Epoch: 5| Step: 7
Training loss: 3.4009988888225853
Validation loss: 3.367680220472028

Epoch: 5| Step: 8
Training loss: 3.836912695461388
Validation loss: 3.366849898498971

Epoch: 5| Step: 9
Training loss: 3.690554889009774
Validation loss: 3.3650919943325794

Epoch: 5| Step: 10
Training loss: 3.6182569731238785
Validation loss: 3.3635949063639328

Epoch: 33| Step: 0
Training loss: 3.5417402970383134
Validation loss: 3.363649420333561

Epoch: 5| Step: 1
Training loss: 3.908533146243696
Validation loss: 3.3616334100917533

Epoch: 5| Step: 2
Training loss: 3.459516177445458
Validation loss: 3.3612222868100528

Epoch: 5| Step: 3
Training loss: 3.338626822795511
Validation loss: 3.3599019008700104

Epoch: 5| Step: 4
Training loss: 3.441483287836654
Validation loss: 3.3608423651765884

Epoch: 5| Step: 5
Training loss: 3.411576332594673
Validation loss: 3.354977642614655

Epoch: 5| Step: 6
Training loss: 3.2389386548566055
Validation loss: 3.3494531639112437

Epoch: 5| Step: 7
Training loss: 3.785934572931119
Validation loss: 3.3493359116423567

Epoch: 5| Step: 8
Training loss: 3.539263250118264
Validation loss: 3.3480079060209005

Epoch: 5| Step: 9
Training loss: 3.90603905680438
Validation loss: 3.350742072826132

Epoch: 5| Step: 10
Training loss: 3.806519366975835
Validation loss: 3.3518887346790796

Epoch: 34| Step: 0
Training loss: 4.382100038877755
Validation loss: 3.3465313388556934

Epoch: 5| Step: 1
Training loss: 3.242614865000117
Validation loss: 3.3412549939340055

Epoch: 5| Step: 2
Training loss: 3.2899487676370827
Validation loss: 3.3467647665281204

Epoch: 5| Step: 3
Training loss: 4.182100829271265
Validation loss: 3.34671129661037

Epoch: 5| Step: 4
Training loss: 3.3419869311457844
Validation loss: 3.34909822573732

Epoch: 5| Step: 5
Training loss: 3.7755861345200015
Validation loss: 3.343880553558089

Epoch: 5| Step: 6
Training loss: 3.4316197819692857
Validation loss: 3.338337961134028

Epoch: 5| Step: 7
Training loss: 3.843141833318278
Validation loss: 3.341138061660696

Epoch: 5| Step: 8
Training loss: 3.1171263112728824
Validation loss: 3.3388714688475996

Epoch: 5| Step: 9
Training loss: 3.073449005741523
Validation loss: 3.3358937433265528

Epoch: 5| Step: 10
Training loss: 3.3073785885579774
Validation loss: 3.33486258257348

Epoch: 35| Step: 0
Training loss: 3.082621741447089
Validation loss: 3.3354933989858777

Epoch: 5| Step: 1
Training loss: 4.193401220971925
Validation loss: 3.3371123754891725

Epoch: 5| Step: 2
Training loss: 3.4519876531687355
Validation loss: 3.3330619891279607

Epoch: 5| Step: 3
Training loss: 3.7219163253373253
Validation loss: 3.3322839151495196

Epoch: 5| Step: 4
Training loss: 3.376556037780142
Validation loss: 3.3350769410034493

Epoch: 5| Step: 5
Training loss: 2.6919017496190403
Validation loss: 3.3335591444828383

Epoch: 5| Step: 6
Training loss: 3.5984571064635613
Validation loss: 3.331736676509193

Epoch: 5| Step: 7
Training loss: 4.449896461911054
Validation loss: 3.32854939667086

Epoch: 5| Step: 8
Training loss: 3.4122714794063387
Validation loss: 3.328604482285183

Epoch: 5| Step: 9
Training loss: 3.233981785852101
Validation loss: 3.330783938633013

Epoch: 5| Step: 10
Training loss: 3.7051289604693243
Validation loss: 3.3255558669101446

Epoch: 36| Step: 0
Training loss: 3.6278885480927903
Validation loss: 3.3263757177513984

Epoch: 5| Step: 1
Training loss: 2.962052027315593
Validation loss: 3.3275150978671193

Epoch: 5| Step: 2
Training loss: 3.2849433095096017
Validation loss: 3.3374130037970775

Epoch: 5| Step: 3
Training loss: 3.8493955756998752
Validation loss: 3.331892050097598

Epoch: 5| Step: 4
Training loss: 3.7150052233077817
Validation loss: 3.327063561892398

Epoch: 5| Step: 5
Training loss: 3.5886165941422914
Validation loss: 3.3229426741928383

Epoch: 5| Step: 6
Training loss: 3.7522385591419845
Validation loss: 3.3255949277208257

Epoch: 5| Step: 7
Training loss: 3.4879118754777383
Validation loss: 3.330455265612166

Epoch: 5| Step: 8
Training loss: 4.129607430705525
Validation loss: 3.331753943163907

Epoch: 5| Step: 9
Training loss: 3.532962080207013
Validation loss: 3.3285402467112286

Epoch: 5| Step: 10
Training loss: 3.0508997231117574
Validation loss: 3.3243259081863097

Epoch: 37| Step: 0
Training loss: 2.5628347410816827
Validation loss: 3.3222995189716396

Epoch: 5| Step: 1
Training loss: 3.913118960624632
Validation loss: 3.318741116439337

Epoch: 5| Step: 2
Training loss: 3.3669461829855694
Validation loss: 3.321588014077606

Epoch: 5| Step: 3
Training loss: 3.43070923482038
Validation loss: 3.322131059650423

Epoch: 5| Step: 4
Training loss: 4.049677405048572
Validation loss: 3.3197904690107687

Epoch: 5| Step: 5
Training loss: 3.7941030422891537
Validation loss: 3.319224496899686

Epoch: 5| Step: 6
Training loss: 3.4763061428920334
Validation loss: 3.3202166336571537

Epoch: 5| Step: 7
Training loss: 2.003632465420751
Validation loss: 3.3175986318477912

Epoch: 5| Step: 8
Training loss: 3.778461910147184
Validation loss: 3.3143091816073613

Epoch: 5| Step: 9
Training loss: 3.879336238204656
Validation loss: 3.3169259708983643

Epoch: 5| Step: 10
Training loss: 4.337911950153008
Validation loss: 3.3188968759506623

Epoch: 38| Step: 0
Training loss: 4.239724696596429
Validation loss: 3.3156972922811505

Epoch: 5| Step: 1
Training loss: 3.7576606069467626
Validation loss: 3.3133634501030347

Epoch: 5| Step: 2
Training loss: 3.1527391301576393
Validation loss: 3.3121282856916245

Epoch: 5| Step: 3
Training loss: 3.2833560542629154
Validation loss: 3.3155216885034147

Epoch: 5| Step: 4
Training loss: 2.7988333212890093
Validation loss: 3.313288292449835

Epoch: 5| Step: 5
Training loss: 3.5912096415773753
Validation loss: 3.311903333492021

Epoch: 5| Step: 6
Training loss: 3.5743520242826743
Validation loss: 3.3142842792364116

Epoch: 5| Step: 7
Training loss: 3.690716262192901
Validation loss: 3.312259949406294

Epoch: 5| Step: 8
Training loss: 2.7505460543789337
Validation loss: 3.310306354409814

Epoch: 5| Step: 9
Training loss: 4.2181762305136
Validation loss: 3.307681372118848

Epoch: 5| Step: 10
Training loss: 3.662043488990647
Validation loss: 3.308616445072999

Epoch: 39| Step: 0
Training loss: 3.9848884999604066
Validation loss: 3.3080644093175873

Epoch: 5| Step: 1
Training loss: 3.321856258766512
Validation loss: 3.30801588518015

Epoch: 5| Step: 2
Training loss: 3.1005836306585906
Validation loss: 3.3074212032520856

Epoch: 5| Step: 3
Training loss: 3.6155451100589375
Validation loss: 3.3068285711441456

Epoch: 5| Step: 4
Training loss: 3.5472058381376286
Validation loss: 3.3082849854608307

Epoch: 5| Step: 5
Training loss: 3.870093161474438
Validation loss: 3.305174957127867

Epoch: 5| Step: 6
Training loss: 3.7841765372970757
Validation loss: 3.3058764468921957

Epoch: 5| Step: 7
Training loss: 3.2994412382615956
Validation loss: 3.3051174301804243

Epoch: 5| Step: 8
Training loss: 3.140237964676002
Validation loss: 3.306792586638563

Epoch: 5| Step: 9
Training loss: 3.2209753843288893
Validation loss: 3.304193326373398

Epoch: 5| Step: 10
Training loss: 3.9920321021843757
Validation loss: 3.3038037102401776

Epoch: 40| Step: 0
Training loss: 3.7220452078359827
Validation loss: 3.3059099032509103

Epoch: 5| Step: 1
Training loss: 3.9634298876098493
Validation loss: 3.3080617930280787

Epoch: 5| Step: 2
Training loss: 4.153850809458762
Validation loss: 3.3112296812536988

Epoch: 5| Step: 3
Training loss: 3.8021824793321186
Validation loss: 3.3073200721027964

Epoch: 5| Step: 4
Training loss: 3.4166925630906144
Validation loss: 3.3038970212086585

Epoch: 5| Step: 5
Training loss: 2.5087947644933255
Validation loss: 3.3025033521351483

Epoch: 5| Step: 6
Training loss: 3.8178186058088657
Validation loss: 3.3017329148499504

Epoch: 5| Step: 7
Training loss: 3.2220288214978
Validation loss: 3.304268613311562

Epoch: 5| Step: 8
Training loss: 3.4823232862516806
Validation loss: 3.3020480046559944

Epoch: 5| Step: 9
Training loss: 3.5033271506630315
Validation loss: 3.3021814723732335

Epoch: 5| Step: 10
Training loss: 2.979961547091431
Validation loss: 3.303908713895243

Epoch: 41| Step: 0
Training loss: 3.1371638266115465
Validation loss: 3.300903209324616

Epoch: 5| Step: 1
Training loss: 4.014451861179499
Validation loss: 3.3009025802394896

Epoch: 5| Step: 2
Training loss: 2.9672349778364855
Validation loss: 3.2996718244428878

Epoch: 5| Step: 3
Training loss: 2.6090850669002768
Validation loss: 3.2993641907995515

Epoch: 5| Step: 4
Training loss: 4.020744177796709
Validation loss: 3.2988462757564774

Epoch: 5| Step: 5
Training loss: 3.5671857836364547
Validation loss: 3.2981138745271656

Epoch: 5| Step: 6
Training loss: 4.355227011228684
Validation loss: 3.29891999216701

Epoch: 5| Step: 7
Training loss: 3.6027372020853865
Validation loss: 3.2985046803622473

Epoch: 5| Step: 8
Training loss: 3.449436202490382
Validation loss: 3.297483631325304

Epoch: 5| Step: 9
Training loss: 3.151231004475377
Validation loss: 3.2990283575376953

Epoch: 5| Step: 10
Training loss: 3.663194240351104
Validation loss: 3.2949262476835894

Epoch: 42| Step: 0
Training loss: 4.029370720057687
Validation loss: 3.2981988764050088

Epoch: 5| Step: 1
Training loss: 3.118488394060751
Validation loss: 3.2951962550994

Epoch: 5| Step: 2
Training loss: 3.4052228866426413
Validation loss: 3.297092738676853

Epoch: 5| Step: 3
Training loss: 3.9046093966887967
Validation loss: 3.294499560017091

Epoch: 5| Step: 4
Training loss: 3.393420214287117
Validation loss: 3.2963860821923867

Epoch: 5| Step: 5
Training loss: 3.3894707609278134
Validation loss: 3.2950865531049063

Epoch: 5| Step: 6
Training loss: 4.120595024991579
Validation loss: 3.294487910973749

Epoch: 5| Step: 7
Training loss: 2.336044462172766
Validation loss: 3.2956473156398234

Epoch: 5| Step: 8
Training loss: 3.031439549133591
Validation loss: 3.294573507525972

Epoch: 5| Step: 9
Training loss: 3.6264525824591596
Validation loss: 3.2971141397781993

Epoch: 5| Step: 10
Training loss: 4.175145385403701
Validation loss: 3.294050129206861

Epoch: 43| Step: 0
Training loss: 3.742092951653323
Validation loss: 3.292783127016841

Epoch: 5| Step: 1
Training loss: 3.7276880895592637
Validation loss: 3.293077779861655

Epoch: 5| Step: 2
Training loss: 3.643588844779252
Validation loss: 3.29214222282914

Epoch: 5| Step: 3
Training loss: 3.5308593263825503
Validation loss: 3.290501291805194

Epoch: 5| Step: 4
Training loss: 4.1955957299354685
Validation loss: 3.2929123831432228

Epoch: 5| Step: 5
Training loss: 3.252431986608582
Validation loss: 3.292891210094335

Epoch: 5| Step: 6
Training loss: 3.7467053245323942
Validation loss: 3.292659082392246

Epoch: 5| Step: 7
Training loss: 3.430977893594689
Validation loss: 3.291476699957114

Epoch: 5| Step: 8
Training loss: 2.970082997661932
Validation loss: 3.2929791323207005

Epoch: 5| Step: 9
Training loss: 2.9899897459741016
Validation loss: 3.2911283292447826

Epoch: 5| Step: 10
Training loss: 3.37344847443683
Validation loss: 3.293170715140152

Epoch: 44| Step: 0
Training loss: 3.2653636188943236
Validation loss: 3.293274021402569

Epoch: 5| Step: 1
Training loss: 3.4789275279444873
Validation loss: 3.2896457469004114

Epoch: 5| Step: 2
Training loss: 3.0542354005275913
Validation loss: 3.28743891455525

Epoch: 5| Step: 3
Training loss: 3.0186821655486624
Validation loss: 3.2904248998333068

Epoch: 5| Step: 4
Training loss: 2.913414440757319
Validation loss: 3.290617603649376

Epoch: 5| Step: 5
Training loss: 2.9189753704750476
Validation loss: 3.2892716727842575

Epoch: 5| Step: 6
Training loss: 3.78965669672443
Validation loss: 3.2901658862935936

Epoch: 5| Step: 7
Training loss: 4.151670069336438
Validation loss: 3.2900459304746796

Epoch: 5| Step: 8
Training loss: 4.329725940303803
Validation loss: 3.2892287590367086

Epoch: 5| Step: 9
Training loss: 3.7317289929951563
Validation loss: 3.2888783028282664

Epoch: 5| Step: 10
Training loss: 3.8651080465080976
Validation loss: 3.287192588497051

Epoch: 45| Step: 0
Training loss: 3.7117807173168007
Validation loss: 3.2868445592838467

Epoch: 5| Step: 1
Training loss: 3.49369448377145
Validation loss: 3.2849744208684126

Epoch: 5| Step: 2
Training loss: 3.9808687228127786
Validation loss: 3.286694135478929

Epoch: 5| Step: 3
Training loss: 3.5235817619614758
Validation loss: 3.2842120527036096

Epoch: 5| Step: 4
Training loss: 3.4335454214815555
Validation loss: 3.2874734997953325

Epoch: 5| Step: 5
Training loss: 2.943757068925214
Validation loss: 3.2900558482598767

Epoch: 5| Step: 6
Training loss: 4.167049288665773
Validation loss: 3.290358888885014

Epoch: 5| Step: 7
Training loss: 2.931451291979127
Validation loss: 3.2900796919643014

Epoch: 5| Step: 8
Training loss: 3.072738349180485
Validation loss: 3.2885689344988767

Epoch: 5| Step: 9
Training loss: 3.351151590122486
Validation loss: 3.2892198784865943

Epoch: 5| Step: 10
Training loss: 3.9844664320085235
Validation loss: 3.2842618433807633

Epoch: 46| Step: 0
Training loss: 4.556285021821313
Validation loss: 3.2815115469407776

Epoch: 5| Step: 1
Training loss: 2.936161791571469
Validation loss: 3.2798864411483173

Epoch: 5| Step: 2
Training loss: 3.9426226520508965
Validation loss: 3.2811164496726337

Epoch: 5| Step: 3
Training loss: 3.9787347103092374
Validation loss: 3.2831974233362704

Epoch: 5| Step: 4
Training loss: 4.002486409837952
Validation loss: 3.281667124403225

Epoch: 5| Step: 5
Training loss: 2.9717544611443834
Validation loss: 3.284000727816859

Epoch: 5| Step: 6
Training loss: 3.0928014977413523
Validation loss: 3.283207350877493

Epoch: 5| Step: 7
Training loss: 2.994748605612069
Validation loss: 3.282032472411975

Epoch: 5| Step: 8
Training loss: 3.7205424116373127
Validation loss: 3.2811495014041454

Epoch: 5| Step: 9
Training loss: 3.276528440051946
Validation loss: 3.2779892337094236

Epoch: 5| Step: 10
Training loss: 2.618153225948527
Validation loss: 3.2768097601527257

Epoch: 47| Step: 0
Training loss: 3.4020089160997458
Validation loss: 3.2777995831055278

Epoch: 5| Step: 1
Training loss: 4.076038045838513
Validation loss: 3.2783383031015907

Epoch: 5| Step: 2
Training loss: 3.4301137463807745
Validation loss: 3.2789107321100963

Epoch: 5| Step: 3
Training loss: 3.945780690428449
Validation loss: 3.2775711257801263

Epoch: 5| Step: 4
Training loss: 3.4551438173870745
Validation loss: 3.279284743543019

Epoch: 5| Step: 5
Training loss: 3.624093567219252
Validation loss: 3.2845099143794148

Epoch: 5| Step: 6
Training loss: 2.6857203424089775
Validation loss: 3.2815942852233433

Epoch: 5| Step: 7
Training loss: 3.305698537717199
Validation loss: 3.2804387665556183

Epoch: 5| Step: 8
Training loss: 3.949572629383203
Validation loss: 3.2835770082184683

Epoch: 5| Step: 9
Training loss: 2.846874993300202
Validation loss: 3.2762958588351814

Epoch: 5| Step: 10
Training loss: 3.7010631374198373
Validation loss: 3.2746464516948124

Epoch: 48| Step: 0
Training loss: 3.586560430005134
Validation loss: 3.2737944062801114

Epoch: 5| Step: 1
Training loss: 3.849114744787752
Validation loss: 3.273710692466351

Epoch: 5| Step: 2
Training loss: 3.8691089519068953
Validation loss: 3.2731644194473892

Epoch: 5| Step: 3
Training loss: 3.836380259022988
Validation loss: 3.2721290104356338

Epoch: 5| Step: 4
Training loss: 3.430671290111231
Validation loss: 3.2730169245125604

Epoch: 5| Step: 5
Training loss: 3.446426177006362
Validation loss: 3.273090932849009

Epoch: 5| Step: 6
Training loss: 3.3935997917416234
Validation loss: 3.2705100731694317

Epoch: 5| Step: 7
Training loss: 3.537847381896966
Validation loss: 3.269646523266682

Epoch: 5| Step: 8
Training loss: 3.0882267826294276
Validation loss: 3.2666821702518516

Epoch: 5| Step: 9
Training loss: 3.0770522053839455
Validation loss: 3.269318535470732

Epoch: 5| Step: 10
Training loss: 3.3896951411180383
Validation loss: 3.268571161623078

Epoch: 49| Step: 0
Training loss: 3.1618002256806577
Validation loss: 3.26750379094528

Epoch: 5| Step: 1
Training loss: 3.730369302912032
Validation loss: 3.263296611501806

Epoch: 5| Step: 2
Training loss: 3.389073029884734
Validation loss: 3.2670002819594144

Epoch: 5| Step: 3
Training loss: 3.8850432652012192
Validation loss: 3.2717826181057834

Epoch: 5| Step: 4
Training loss: 3.143768710920648
Validation loss: 3.2701364943675935

Epoch: 5| Step: 5
Training loss: 2.662406518575593
Validation loss: 3.2647936328400244

Epoch: 5| Step: 6
Training loss: 3.6105500657578133
Validation loss: 3.2654503447229932

Epoch: 5| Step: 7
Training loss: 2.9471557677608087
Validation loss: 3.2599103442013755

Epoch: 5| Step: 8
Training loss: 4.102023086118343
Validation loss: 3.26117296020175

Epoch: 5| Step: 9
Training loss: 4.096167629462596
Validation loss: 3.2579759110364996

Epoch: 5| Step: 10
Training loss: 3.482489516221236
Validation loss: 3.256156400707925

Epoch: 50| Step: 0
Training loss: 3.46555889537841
Validation loss: 3.2552266196773

Epoch: 5| Step: 1
Training loss: 4.082686755831292
Validation loss: 3.2570600726933825

Epoch: 5| Step: 2
Training loss: 2.9888017188702363
Validation loss: 3.2546269379573904

Epoch: 5| Step: 3
Training loss: 3.3430554390525895
Validation loss: 3.2530201698169865

Epoch: 5| Step: 4
Training loss: 3.5897988533475127
Validation loss: 3.2599366134841805

Epoch: 5| Step: 5
Training loss: 3.1167583887267765
Validation loss: 3.2590780101222503

Epoch: 5| Step: 6
Training loss: 3.6729016755754333
Validation loss: 3.2671852386322877

Epoch: 5| Step: 7
Training loss: 3.2985760246329328
Validation loss: 3.269846839085058

Epoch: 5| Step: 8
Training loss: 3.1724609435122053
Validation loss: 3.266395217777162

Epoch: 5| Step: 9
Training loss: 4.003568249834028
Validation loss: 3.2583064576348693

Epoch: 5| Step: 10
Training loss: 3.5926794696701725
Validation loss: 3.2509910296748767

Epoch: 51| Step: 0
Training loss: 3.3845118951981528
Validation loss: 3.2500130871618915

Epoch: 5| Step: 1
Training loss: 3.4764125834512822
Validation loss: 3.249888964066467

Epoch: 5| Step: 2
Training loss: 3.960329750280528
Validation loss: 3.2457965443143686

Epoch: 5| Step: 3
Training loss: 3.3387399377532
Validation loss: 3.249710024320396

Epoch: 5| Step: 4
Training loss: 3.440604593907683
Validation loss: 3.2496490210117064

Epoch: 5| Step: 5
Training loss: 3.276629000576946
Validation loss: 3.248504876908878

Epoch: 5| Step: 6
Training loss: 3.2066163922636255
Validation loss: 3.2470134441519423

Epoch: 5| Step: 7
Training loss: 3.8125872992854672
Validation loss: 3.2463676625629176

Epoch: 5| Step: 8
Training loss: 3.8127728974275925
Validation loss: 3.2447821930830454

Epoch: 5| Step: 9
Training loss: 3.652746233463467
Validation loss: 3.2457656900903253

Epoch: 5| Step: 10
Training loss: 2.8048190030267532
Validation loss: 3.248258209146088

Epoch: 52| Step: 0
Training loss: 2.8944487154541263
Validation loss: 3.2505101370705676

Epoch: 5| Step: 1
Training loss: 3.615869401404749
Validation loss: 3.258036402769174

Epoch: 5| Step: 2
Training loss: 3.683694848203387
Validation loss: 3.2505782743285305

Epoch: 5| Step: 3
Training loss: 3.8772137378952594
Validation loss: 3.246344293821413

Epoch: 5| Step: 4
Training loss: 3.264098618354574
Validation loss: 3.243018294023419

Epoch: 5| Step: 5
Training loss: 3.4708465563708075
Validation loss: 3.2427223386123742

Epoch: 5| Step: 6
Training loss: 3.768480286823878
Validation loss: 3.2463728192678243

Epoch: 5| Step: 7
Training loss: 3.3181169498796472
Validation loss: 3.245201807972585

Epoch: 5| Step: 8
Training loss: 4.102217907084185
Validation loss: 3.245279766094252

Epoch: 5| Step: 9
Training loss: 3.1627042139032087
Validation loss: 3.241502582996753

Epoch: 5| Step: 10
Training loss: 2.953012938618694
Validation loss: 3.2425368926176024

Epoch: 53| Step: 0
Training loss: 3.5876420900071975
Validation loss: 3.242366395520157

Epoch: 5| Step: 1
Training loss: 3.2262278976777052
Validation loss: 3.2442343789683172

Epoch: 5| Step: 2
Training loss: 2.995333220679341
Validation loss: 3.241526701593597

Epoch: 5| Step: 3
Training loss: 3.670014644666344
Validation loss: 3.2419068969325733

Epoch: 5| Step: 4
Training loss: 3.2873626448217323
Validation loss: 3.240562740928786

Epoch: 5| Step: 5
Training loss: 3.63326019481808
Validation loss: 3.239904789677124

Epoch: 5| Step: 6
Training loss: 3.3861034146698574
Validation loss: 3.2401933214796075

Epoch: 5| Step: 7
Training loss: 3.64359120044188
Validation loss: 3.239965705844538

Epoch: 5| Step: 8
Training loss: 3.33491518315978
Validation loss: 3.239398539658764

Epoch: 5| Step: 9
Training loss: 3.715355485873939
Validation loss: 3.2383356133215164

Epoch: 5| Step: 10
Training loss: 3.832367084186553
Validation loss: 3.237007658484429

Epoch: 54| Step: 0
Training loss: 2.501179512246998
Validation loss: 3.238270100141763

Epoch: 5| Step: 1
Training loss: 4.0174603850637585
Validation loss: 3.2378360032458313

Epoch: 5| Step: 2
Training loss: 3.56867004946325
Validation loss: 3.2369913769484273

Epoch: 5| Step: 3
Training loss: 3.997013168988975
Validation loss: 3.2358622445515697

Epoch: 5| Step: 4
Training loss: 3.1303253575103134
Validation loss: 3.236655386264076

Epoch: 5| Step: 5
Training loss: 3.4899482801917117
Validation loss: 3.235054125929203

Epoch: 5| Step: 6
Training loss: 3.6032567869437573
Validation loss: 3.2339556180733817

Epoch: 5| Step: 7
Training loss: 3.2118304790640986
Validation loss: 3.2340174120585723

Epoch: 5| Step: 8
Training loss: 3.5035593462872217
Validation loss: 3.2344708774506943

Epoch: 5| Step: 9
Training loss: 3.751221902774479
Validation loss: 3.233781543446894

Epoch: 5| Step: 10
Training loss: 3.2236388771811324
Validation loss: 3.233519269085574

Epoch: 55| Step: 0
Training loss: 3.8042406763660814
Validation loss: 3.233667075140794

Epoch: 5| Step: 1
Training loss: 3.1042576377561484
Validation loss: 3.2325403575263705

Epoch: 5| Step: 2
Training loss: 3.3934297695084155
Validation loss: 3.232577706292749

Epoch: 5| Step: 3
Training loss: 3.683056238951198
Validation loss: 3.232681194714856

Epoch: 5| Step: 4
Training loss: 3.2312143703835323
Validation loss: 3.232861690789032

Epoch: 5| Step: 5
Training loss: 3.432091081437697
Validation loss: 3.232032132226393

Epoch: 5| Step: 6
Training loss: 3.4027481977427025
Validation loss: 3.2318015525184003

Epoch: 5| Step: 7
Training loss: 3.534475693082044
Validation loss: 3.230018516595903

Epoch: 5| Step: 8
Training loss: 3.2691380345237078
Validation loss: 3.230663838215642

Epoch: 5| Step: 9
Training loss: 3.767848581086118
Validation loss: 3.2322891862922596

Epoch: 5| Step: 10
Training loss: 3.563471611439764
Validation loss: 3.233477412784503

Epoch: 56| Step: 0
Training loss: 3.8480257892815097
Validation loss: 3.231667348547724

Epoch: 5| Step: 1
Training loss: 3.5544153130252325
Validation loss: 3.230168632058084

Epoch: 5| Step: 2
Training loss: 3.5620960207317665
Validation loss: 3.231418784628059

Epoch: 5| Step: 3
Training loss: 3.5414699425009517
Validation loss: 3.2292089220683526

Epoch: 5| Step: 4
Training loss: 3.291792436603303
Validation loss: 3.22995152351385

Epoch: 5| Step: 5
Training loss: 3.5399292817029564
Validation loss: 3.228310458345311

Epoch: 5| Step: 6
Training loss: 3.221566606741565
Validation loss: 3.2289811339388006

Epoch: 5| Step: 7
Training loss: 3.372740660409266
Validation loss: 3.227378587272147

Epoch: 5| Step: 8
Training loss: 4.060921465030025
Validation loss: 3.226854350818954

Epoch: 5| Step: 9
Training loss: 3.1257173859189096
Validation loss: 3.228799125933464

Epoch: 5| Step: 10
Training loss: 2.8717619864359025
Validation loss: 3.229622638330752

Epoch: 57| Step: 0
Training loss: 3.3183267556979024
Validation loss: 3.2282192961570826

Epoch: 5| Step: 1
Training loss: 3.668833540269116
Validation loss: 3.2320073177325264

Epoch: 5| Step: 2
Training loss: 3.619207819043659
Validation loss: 3.2293551551092263

Epoch: 5| Step: 3
Training loss: 3.1877771892822593
Validation loss: 3.2256942661835692

Epoch: 5| Step: 4
Training loss: 3.529347945552601
Validation loss: 3.226155613030129

Epoch: 5| Step: 5
Training loss: 3.60326697672801
Validation loss: 3.2237309689084443

Epoch: 5| Step: 6
Training loss: 3.023935518475462
Validation loss: 3.2271719486116224

Epoch: 5| Step: 7
Training loss: 3.3555605501666874
Validation loss: 3.2259164819102653

Epoch: 5| Step: 8
Training loss: 2.8499373311966085
Validation loss: 3.2221921696131908

Epoch: 5| Step: 9
Training loss: 4.34334864237252
Validation loss: 3.228924731434787

Epoch: 5| Step: 10
Training loss: 3.4313502006978394
Validation loss: 3.2278399793050885

Epoch: 58| Step: 0
Training loss: 3.7976639795214875
Validation loss: 3.2246324783037874

Epoch: 5| Step: 1
Training loss: 2.8356862863295613
Validation loss: 3.223102636064206

Epoch: 5| Step: 2
Training loss: 3.7703100160985006
Validation loss: 3.2208279557672643

Epoch: 5| Step: 3
Training loss: 2.950426109703614
Validation loss: 3.222014647572841

Epoch: 5| Step: 4
Training loss: 2.975982369186105
Validation loss: 3.2217149945828685

Epoch: 5| Step: 5
Training loss: 3.428008970037451
Validation loss: 3.2197883954814497

Epoch: 5| Step: 6
Training loss: 3.6832588504722987
Validation loss: 3.219932865272758

Epoch: 5| Step: 7
Training loss: 3.3528131316845102
Validation loss: 3.2207094069301805

Epoch: 5| Step: 8
Training loss: 3.9136342558655226
Validation loss: 3.2209227830992777

Epoch: 5| Step: 9
Training loss: 3.3329527319741903
Validation loss: 3.2201507766735387

Epoch: 5| Step: 10
Training loss: 3.924451612322223
Validation loss: 3.2191185569484846

Epoch: 59| Step: 0
Training loss: 4.040421808714282
Validation loss: 3.2165097131128912

Epoch: 5| Step: 1
Training loss: 4.002708710012747
Validation loss: 3.2205035057505076

Epoch: 5| Step: 2
Training loss: 2.1265029080440785
Validation loss: 3.220009550659919

Epoch: 5| Step: 3
Training loss: 3.313161244160865
Validation loss: 3.220704906420371

Epoch: 5| Step: 4
Training loss: 3.869333369284204
Validation loss: 3.2198953650570337

Epoch: 5| Step: 5
Training loss: 3.4921604641885517
Validation loss: 3.220561200418845

Epoch: 5| Step: 6
Training loss: 3.3772785830823286
Validation loss: 3.220495400489405

Epoch: 5| Step: 7
Training loss: 3.266429309266325
Validation loss: 3.2187970965713446

Epoch: 5| Step: 8
Training loss: 3.5807938263574854
Validation loss: 3.2204607686170803

Epoch: 5| Step: 9
Training loss: 3.1603247900533087
Validation loss: 3.2179905271895044

Epoch: 5| Step: 10
Training loss: 3.4717388850877695
Validation loss: 3.220005536422092

Epoch: 60| Step: 0
Training loss: 3.88682082152404
Validation loss: 3.2163015695148833

Epoch: 5| Step: 1
Training loss: 3.2169036013716013
Validation loss: 3.215708334738353

Epoch: 5| Step: 2
Training loss: 3.9869750870231755
Validation loss: 3.2175508267063764

Epoch: 5| Step: 3
Training loss: 3.188295452120874
Validation loss: 3.2147920245237795

Epoch: 5| Step: 4
Training loss: 2.907794828940294
Validation loss: 3.213179816132368

Epoch: 5| Step: 5
Training loss: 3.4736115350680214
Validation loss: 3.2152203023974373

Epoch: 5| Step: 6
Training loss: 3.4192494810337846
Validation loss: 3.2155008695706617

Epoch: 5| Step: 7
Training loss: 4.017916133387012
Validation loss: 3.216288769226727

Epoch: 5| Step: 8
Training loss: 2.850433042319633
Validation loss: 3.215979884954845

Epoch: 5| Step: 9
Training loss: 3.315548915151856
Validation loss: 3.2180095696696744

Epoch: 5| Step: 10
Training loss: 3.59207897312714
Validation loss: 3.226549204100483

Epoch: 61| Step: 0
Training loss: 3.0853369792475984
Validation loss: 3.219667650547396

Epoch: 5| Step: 1
Training loss: 3.5029232896076925
Validation loss: 3.217335824502069

Epoch: 5| Step: 2
Training loss: 3.1980300203957652
Validation loss: 3.2176085982215556

Epoch: 5| Step: 3
Training loss: 3.2092764983248476
Validation loss: 3.2182190000406474

Epoch: 5| Step: 4
Training loss: 3.9100368607288476
Validation loss: 3.2119669772780037

Epoch: 5| Step: 5
Training loss: 3.147891316710488
Validation loss: 3.211567973438708

Epoch: 5| Step: 6
Training loss: 4.177563621452018
Validation loss: 3.2137020489421544

Epoch: 5| Step: 7
Training loss: 3.2507847058700237
Validation loss: 3.2138129160205646

Epoch: 5| Step: 8
Training loss: 3.33710253916981
Validation loss: 3.2128713255685777

Epoch: 5| Step: 9
Training loss: 3.3092678783971556
Validation loss: 3.2111690190167352

Epoch: 5| Step: 10
Training loss: 3.7865189342380505
Validation loss: 3.2116487523346495

Epoch: 62| Step: 0
Training loss: 2.9635907768555994
Validation loss: 3.2098905323893394

Epoch: 5| Step: 1
Training loss: 3.5553061146128493
Validation loss: 3.211381392573255

Epoch: 5| Step: 2
Training loss: 4.594774404473296
Validation loss: 3.210347630926388

Epoch: 5| Step: 3
Training loss: 3.2579178827380013
Validation loss: 3.211827794760828

Epoch: 5| Step: 4
Training loss: 3.115703028521569
Validation loss: 3.2122742657974888

Epoch: 5| Step: 5
Training loss: 3.4968810489660176
Validation loss: 3.212880400393187

Epoch: 5| Step: 6
Training loss: 3.2991146055852822
Validation loss: 3.2118401546697

Epoch: 5| Step: 7
Training loss: 3.6441452623342507
Validation loss: 3.2107664060247747

Epoch: 5| Step: 8
Training loss: 3.51299407850766
Validation loss: 3.208891089904619

Epoch: 5| Step: 9
Training loss: 2.8415674910107693
Validation loss: 3.2088197457401297

Epoch: 5| Step: 10
Training loss: 3.4287674002044217
Validation loss: 3.208487264208372

Epoch: 63| Step: 0
Training loss: 4.086147091451617
Validation loss: 3.206536418815207

Epoch: 5| Step: 1
Training loss: 3.502659876875534
Validation loss: 3.2064030762635625

Epoch: 5| Step: 2
Training loss: 2.931703245344284
Validation loss: 3.2080102274938334

Epoch: 5| Step: 3
Training loss: 3.4312224895993446
Validation loss: 3.205467134174452

Epoch: 5| Step: 4
Training loss: 3.1099003486981713
Validation loss: 3.206816567382156

Epoch: 5| Step: 5
Training loss: 3.8959091641530903
Validation loss: 3.2046089262606516

Epoch: 5| Step: 6
Training loss: 3.392489575431173
Validation loss: 3.204693888393104

Epoch: 5| Step: 7
Training loss: 2.7091889912641687
Validation loss: 3.2091917981116413

Epoch: 5| Step: 8
Training loss: 3.6124724601567033
Validation loss: 3.2073413213906363

Epoch: 5| Step: 9
Training loss: 3.7709323315068533
Validation loss: 3.206724188167215

Epoch: 5| Step: 10
Training loss: 3.2759052161267403
Validation loss: 3.206941358319113

Epoch: 64| Step: 0
Training loss: 4.121579225699866
Validation loss: 3.204673633233552

Epoch: 5| Step: 1
Training loss: 3.2458904400079738
Validation loss: 3.205954819211934

Epoch: 5| Step: 2
Training loss: 3.5606278971599505
Validation loss: 3.2035744372505

Epoch: 5| Step: 3
Training loss: 3.7240987826807257
Validation loss: 3.202476873287826

Epoch: 5| Step: 4
Training loss: 3.6476616044616943
Validation loss: 3.2047043631082537

Epoch: 5| Step: 5
Training loss: 2.9390621495588904
Validation loss: 3.2034834322310326

Epoch: 5| Step: 6
Training loss: 3.1151878425208093
Validation loss: 3.204854736373928

Epoch: 5| Step: 7
Training loss: 2.653629042123387
Validation loss: 3.2022689055469633

Epoch: 5| Step: 8
Training loss: 3.122181956920375
Validation loss: 3.2048586528000738

Epoch: 5| Step: 9
Training loss: 3.3883698870301937
Validation loss: 3.205876510165031

Epoch: 5| Step: 10
Training loss: 4.243886028014232
Validation loss: 3.2043046765366747

Epoch: 65| Step: 0
Training loss: 3.876417700551367
Validation loss: 3.200825358093224

Epoch: 5| Step: 1
Training loss: 2.552959826203018
Validation loss: 3.2027381997576856

Epoch: 5| Step: 2
Training loss: 3.2006917503829135
Validation loss: 3.2028215017932196

Epoch: 5| Step: 3
Training loss: 3.5023203379086576
Validation loss: 3.201057556421938

Epoch: 5| Step: 4
Training loss: 3.7182409114343127
Validation loss: 3.200264538641343

Epoch: 5| Step: 5
Training loss: 3.8623430831293164
Validation loss: 3.199959460060653

Epoch: 5| Step: 6
Training loss: 3.4238892640630065
Validation loss: 3.2005952391069905

Epoch: 5| Step: 7
Training loss: 3.3465590041980584
Validation loss: 3.199675680909782

Epoch: 5| Step: 8
Training loss: 3.751656992722021
Validation loss: 3.2003524742533487

Epoch: 5| Step: 9
Training loss: 3.0390943510842963
Validation loss: 3.2010661329596295

Epoch: 5| Step: 10
Training loss: 3.4076350484661875
Validation loss: 3.201397256719623

Epoch: 66| Step: 0
Training loss: 3.4355854598280957
Validation loss: 3.200433203000185

Epoch: 5| Step: 1
Training loss: 3.2079314108101507
Validation loss: 3.2034498208595896

Epoch: 5| Step: 2
Training loss: 3.4659826563661507
Validation loss: 3.2025463863213313

Epoch: 5| Step: 3
Training loss: 3.4571482148292216
Validation loss: 3.2025905056137085

Epoch: 5| Step: 4
Training loss: 3.7767723621775255
Validation loss: 3.2020504977808404

Epoch: 5| Step: 5
Training loss: 2.8239756119407153
Validation loss: 3.1980003951760057

Epoch: 5| Step: 6
Training loss: 3.8224890501814817
Validation loss: 3.198577106132467

Epoch: 5| Step: 7
Training loss: 3.513069410768237
Validation loss: 3.198633887477026

Epoch: 5| Step: 8
Training loss: 3.530057587626645
Validation loss: 3.197137668350973

Epoch: 5| Step: 9
Training loss: 3.7165708167428018
Validation loss: 3.1955390988427905

Epoch: 5| Step: 10
Training loss: 2.949574106798984
Validation loss: 3.197526243688182

Epoch: 67| Step: 0
Training loss: 3.0120192401367727
Validation loss: 3.196526674283585

Epoch: 5| Step: 1
Training loss: 3.0465244189331964
Validation loss: 3.1989973147037234

Epoch: 5| Step: 2
Training loss: 3.687051390175676
Validation loss: 3.1976800603712094

Epoch: 5| Step: 3
Training loss: 3.921596076439179
Validation loss: 3.1990056667669475

Epoch: 5| Step: 4
Training loss: 3.1873518965477845
Validation loss: 3.1969498692100737

Epoch: 5| Step: 5
Training loss: 3.0205761679442116
Validation loss: 3.193720643512814

Epoch: 5| Step: 6
Training loss: 3.3667022992756936
Validation loss: 3.192029289840968

Epoch: 5| Step: 7
Training loss: 3.902408633680752
Validation loss: 3.19300459072889

Epoch: 5| Step: 8
Training loss: 3.460033841270813
Validation loss: 3.1917990306506345

Epoch: 5| Step: 9
Training loss: 3.6703046321987562
Validation loss: 3.190188635418727

Epoch: 5| Step: 10
Training loss: 3.4192083410676317
Validation loss: 3.193219802925703

Epoch: 68| Step: 0
Training loss: 3.6661534961754576
Validation loss: 3.19181421102143

Epoch: 5| Step: 1
Training loss: 2.6805773444819225
Validation loss: 3.1889370006085542

Epoch: 5| Step: 2
Training loss: 4.000132320122825
Validation loss: 3.1906763923279824

Epoch: 5| Step: 3
Training loss: 2.796948224180043
Validation loss: 3.189463656198559

Epoch: 5| Step: 4
Training loss: 3.2051087726101737
Validation loss: 3.1892734880375593

Epoch: 5| Step: 5
Training loss: 3.4680920225999885
Validation loss: 3.1882464495768565

Epoch: 5| Step: 6
Training loss: 3.055224437304842
Validation loss: 3.187495938386366

Epoch: 5| Step: 7
Training loss: 3.3924074893220593
Validation loss: 3.1900489647990256

Epoch: 5| Step: 8
Training loss: 3.893903951525206
Validation loss: 3.1864971261763486

Epoch: 5| Step: 9
Training loss: 4.12012100671635
Validation loss: 3.1897444683684895

Epoch: 5| Step: 10
Training loss: 3.142501498201509
Validation loss: 3.188242376048677

Epoch: 69| Step: 0
Training loss: 2.9699937323301824
Validation loss: 3.1878114846110495

Epoch: 5| Step: 1
Training loss: 4.099551916060533
Validation loss: 3.191780712907086

Epoch: 5| Step: 2
Training loss: 3.892938990501219
Validation loss: 3.189149166538381

Epoch: 5| Step: 3
Training loss: 3.368726338885554
Validation loss: 3.1872425268919606

Epoch: 5| Step: 4
Training loss: 3.1045014032381304
Validation loss: 3.1885205428062307

Epoch: 5| Step: 5
Training loss: 3.555609883118531
Validation loss: 3.1871490993134386

Epoch: 5| Step: 6
Training loss: 2.794749043343784
Validation loss: 3.187607349387256

Epoch: 5| Step: 7
Training loss: 2.904708617627646
Validation loss: 3.1858764799022525

Epoch: 5| Step: 8
Training loss: 3.167822141818
Validation loss: 3.1872768352127787

Epoch: 5| Step: 9
Training loss: 3.987574949128173
Validation loss: 3.185355716472754

Epoch: 5| Step: 10
Training loss: 3.6674251783314773
Validation loss: 3.183358764632756

Epoch: 70| Step: 0
Training loss: 3.794454925755971
Validation loss: 3.18365161107611

Epoch: 5| Step: 1
Training loss: 2.6832473286969334
Validation loss: 3.1858059903536544

Epoch: 5| Step: 2
Training loss: 3.9712575364994414
Validation loss: 3.182556775841859

Epoch: 5| Step: 3
Training loss: 3.4632579868945745
Validation loss: 3.184943655357299

Epoch: 5| Step: 4
Training loss: 3.50660871822888
Validation loss: 3.180486197356545

Epoch: 5| Step: 5
Training loss: 3.8305861677410116
Validation loss: 3.1822962805787025

Epoch: 5| Step: 6
Training loss: 2.684369948074863
Validation loss: 3.184142662351811

Epoch: 5| Step: 7
Training loss: 3.350279235589311
Validation loss: 3.181224412760996

Epoch: 5| Step: 8
Training loss: 3.722204959569981
Validation loss: 3.181542357755161

Epoch: 5| Step: 9
Training loss: 3.037478782045958
Validation loss: 3.179597159396831

Epoch: 5| Step: 10
Training loss: 3.4076672326722175
Validation loss: 3.1794285862948812

Epoch: 71| Step: 0
Training loss: 2.853520805254966
Validation loss: 3.180907716635734

Epoch: 5| Step: 1
Training loss: 3.1788193925910435
Validation loss: 3.1818036084666392

Epoch: 5| Step: 2
Training loss: 3.990392352247825
Validation loss: 3.180571562066444

Epoch: 5| Step: 3
Training loss: 3.034697155493695
Validation loss: 3.177168222493907

Epoch: 5| Step: 4
Training loss: 3.060061515488971
Validation loss: 3.1777375471436593

Epoch: 5| Step: 5
Training loss: 3.486955858665022
Validation loss: 3.1755381398042384

Epoch: 5| Step: 6
Training loss: 3.7158232640017843
Validation loss: 3.1758779599753124

Epoch: 5| Step: 7
Training loss: 3.8846380904232114
Validation loss: 3.176276310673574

Epoch: 5| Step: 8
Training loss: 3.651174560101853
Validation loss: 3.1746973727585726

Epoch: 5| Step: 9
Training loss: 3.761871493240144
Validation loss: 3.1725690207576607

Epoch: 5| Step: 10
Training loss: 2.6710767836365226
Validation loss: 3.1708985571565624

Epoch: 72| Step: 0
Training loss: 2.9221168458776448
Validation loss: 3.171099043469989

Epoch: 5| Step: 1
Training loss: 3.6014763083249997
Validation loss: 3.170168272136538

Epoch: 5| Step: 2
Training loss: 3.288809941034457
Validation loss: 3.169858664917718

Epoch: 5| Step: 3
Training loss: 3.00193120468168
Validation loss: 3.169655848429632

Epoch: 5| Step: 4
Training loss: 3.594356452523914
Validation loss: 3.1684697249981393

Epoch: 5| Step: 5
Training loss: 3.992797804912376
Validation loss: 3.1692015945796292

Epoch: 5| Step: 6
Training loss: 3.0675098158501326
Validation loss: 3.167869252627749

Epoch: 5| Step: 7
Training loss: 3.8547372481557463
Validation loss: 3.1677201164397575

Epoch: 5| Step: 8
Training loss: 3.046319372915742
Validation loss: 3.1668807272026887

Epoch: 5| Step: 9
Training loss: 3.7789370185588402
Validation loss: 3.1703211552149884

Epoch: 5| Step: 10
Training loss: 3.247312608441158
Validation loss: 3.1680213128077654

Epoch: 73| Step: 0
Training loss: 3.453026541432516
Validation loss: 3.166312384635106

Epoch: 5| Step: 1
Training loss: 3.73295559902237
Validation loss: 3.166779982952434

Epoch: 5| Step: 2
Training loss: 3.227497547246236
Validation loss: 3.165405382241606

Epoch: 5| Step: 3
Training loss: 3.722293095522846
Validation loss: 3.1629209650141106

Epoch: 5| Step: 4
Training loss: 2.8970873379379047
Validation loss: 3.1655060333717904

Epoch: 5| Step: 5
Training loss: 3.564489378026257
Validation loss: 3.164461934612163

Epoch: 5| Step: 6
Training loss: 3.4223664510012606
Validation loss: 3.1651327263959237

Epoch: 5| Step: 7
Training loss: 2.802754110339925
Validation loss: 3.1655536248809777

Epoch: 5| Step: 8
Training loss: 3.05813193701872
Validation loss: 3.163915326741654

Epoch: 5| Step: 9
Training loss: 3.653336627661712
Validation loss: 3.1632795277881733

Epoch: 5| Step: 10
Training loss: 3.950016774974887
Validation loss: 3.162342333459595

Epoch: 74| Step: 0
Training loss: 3.749470228285304
Validation loss: 3.1626125013639514

Epoch: 5| Step: 1
Training loss: 2.7543040319708725
Validation loss: 3.1615451932516314

Epoch: 5| Step: 2
Training loss: 3.3472095311629078
Validation loss: 3.163782099375912

Epoch: 5| Step: 3
Training loss: 2.960374280360809
Validation loss: 3.1617555461178686

Epoch: 5| Step: 4
Training loss: 3.374517194334745
Validation loss: 3.162428020939136

Epoch: 5| Step: 5
Training loss: 3.7009103325301886
Validation loss: 3.1622745454791485

Epoch: 5| Step: 6
Training loss: 3.3697052855625005
Validation loss: 3.161254735699894

Epoch: 5| Step: 7
Training loss: 3.665995594228042
Validation loss: 3.1624840254102327

Epoch: 5| Step: 8
Training loss: 3.9436036289819407
Validation loss: 3.1620244961309307

Epoch: 5| Step: 9
Training loss: 3.779352263604131
Validation loss: 3.1626835163577685

Epoch: 5| Step: 10
Training loss: 2.4687306850015776
Validation loss: 3.163430682133362

Epoch: 75| Step: 0
Training loss: 3.065844986203828
Validation loss: 3.1618064900447904

Epoch: 5| Step: 1
Training loss: 3.095104807125252
Validation loss: 3.163904585721608

Epoch: 5| Step: 2
Training loss: 3.2218568492418833
Validation loss: 3.160250469087854

Epoch: 5| Step: 3
Training loss: 3.7760472089354082
Validation loss: 3.159477232021717

Epoch: 5| Step: 4
Training loss: 3.9762893313129863
Validation loss: 3.1598644713335133

Epoch: 5| Step: 5
Training loss: 3.5866663904674474
Validation loss: 3.158857118626678

Epoch: 5| Step: 6
Training loss: 2.5922670836186037
Validation loss: 3.157991081584051

Epoch: 5| Step: 7
Training loss: 3.1422385250977367
Validation loss: 3.1591195799128675

Epoch: 5| Step: 8
Training loss: 3.76277869830391
Validation loss: 3.1572786634946115

Epoch: 5| Step: 9
Training loss: 3.6952505610559583
Validation loss: 3.1575129421063304

Epoch: 5| Step: 10
Training loss: 3.3718325975525487
Validation loss: 3.1560767495889364

Epoch: 76| Step: 0
Training loss: 2.9730777717321115
Validation loss: 3.158964674459859

Epoch: 5| Step: 1
Training loss: 3.435705930531434
Validation loss: 3.156772131320774

Epoch: 5| Step: 2
Training loss: 3.5119205200482173
Validation loss: 3.162890424116444

Epoch: 5| Step: 3
Training loss: 3.505431592764334
Validation loss: 3.1609876828739325

Epoch: 5| Step: 4
Training loss: 3.6096480625452965
Validation loss: 3.159874429379456

Epoch: 5| Step: 5
Training loss: 3.8089395375879853
Validation loss: 3.164526025344912

Epoch: 5| Step: 6
Training loss: 2.945367544454143
Validation loss: 3.156301086395723

Epoch: 5| Step: 7
Training loss: 2.9979441274127954
Validation loss: 3.154919656167667

Epoch: 5| Step: 8
Training loss: 3.549893074037184
Validation loss: 3.1546126043288263

Epoch: 5| Step: 9
Training loss: 3.433620135972991
Validation loss: 3.155043191058522

Epoch: 5| Step: 10
Training loss: 3.6527357900806665
Validation loss: 3.1544708806405946

Epoch: 77| Step: 0
Training loss: 3.7647490056281865
Validation loss: 3.156531103825941

Epoch: 5| Step: 1
Training loss: 3.0795329790140986
Validation loss: 3.153092783768388

Epoch: 5| Step: 2
Training loss: 3.4112261899436573
Validation loss: 3.1550122895066517

Epoch: 5| Step: 3
Training loss: 3.3445532003429572
Validation loss: 3.1548051137209274

Epoch: 5| Step: 4
Training loss: 4.007778710414335
Validation loss: 3.1528032916887025

Epoch: 5| Step: 5
Training loss: 4.001208599606919
Validation loss: 3.1530978247108292

Epoch: 5| Step: 6
Training loss: 2.8892654108367775
Validation loss: 3.15408161200533

Epoch: 5| Step: 7
Training loss: 3.7981848949325454
Validation loss: 3.150831620732725

Epoch: 5| Step: 8
Training loss: 2.636032354234447
Validation loss: 3.153544317796487

Epoch: 5| Step: 9
Training loss: 3.1607255081088366
Validation loss: 3.153180912916094

Epoch: 5| Step: 10
Training loss: 3.032920455780017
Validation loss: 3.155099512685145

Epoch: 78| Step: 0
Training loss: 2.944629215544975
Validation loss: 3.155066135854092

Epoch: 5| Step: 1
Training loss: 4.001099673745102
Validation loss: 3.152508483934114

Epoch: 5| Step: 2
Training loss: 3.3668408137940955
Validation loss: 3.1519402127517058

Epoch: 5| Step: 3
Training loss: 3.446824068746282
Validation loss: 3.1514883463959693

Epoch: 5| Step: 4
Training loss: 3.1171882648514884
Validation loss: 3.1495684609226706

Epoch: 5| Step: 5
Training loss: 3.2380562440677423
Validation loss: 3.151361514138306

Epoch: 5| Step: 6
Training loss: 3.130090610789165
Validation loss: 3.151722015071683

Epoch: 5| Step: 7
Training loss: 3.889642185337368
Validation loss: 3.1489551464402803

Epoch: 5| Step: 8
Training loss: 3.108662432582698
Validation loss: 3.1484550976961825

Epoch: 5| Step: 9
Training loss: 3.209498916209796
Validation loss: 3.1513160325093983

Epoch: 5| Step: 10
Training loss: 3.8830857363069198
Validation loss: 3.1485381846572125

Epoch: 79| Step: 0
Training loss: 3.9331569637477033
Validation loss: 3.1488217412206208

Epoch: 5| Step: 1
Training loss: 3.9047001319854946
Validation loss: 3.151738491451493

Epoch: 5| Step: 2
Training loss: 2.6186660461807034
Validation loss: 3.149105404947512

Epoch: 5| Step: 3
Training loss: 3.612988797286314
Validation loss: 3.15100376747396

Epoch: 5| Step: 4
Training loss: 3.5096889990592026
Validation loss: 3.1523691964608194

Epoch: 5| Step: 5
Training loss: 3.380872068596188
Validation loss: 3.153105095036524

Epoch: 5| Step: 6
Training loss: 3.025279821899696
Validation loss: 3.1495957148176332

Epoch: 5| Step: 7
Training loss: 3.5885581286993524
Validation loss: 3.1514223244943937

Epoch: 5| Step: 8
Training loss: 3.7410799111583226
Validation loss: 3.148011419591945

Epoch: 5| Step: 9
Training loss: 3.4233932958871662
Validation loss: 3.146506503898961

Epoch: 5| Step: 10
Training loss: 2.0983419593995305
Validation loss: 3.1508664003690194

Epoch: 80| Step: 0
Training loss: 3.5155387359208214
Validation loss: 3.1484878891430443

Epoch: 5| Step: 1
Training loss: 3.6244626140184533
Validation loss: 3.152915857844562

Epoch: 5| Step: 2
Training loss: 3.7568790918206405
Validation loss: 3.1512991422803753

Epoch: 5| Step: 3
Training loss: 4.104241126816355
Validation loss: 3.1492686370447487

Epoch: 5| Step: 4
Training loss: 3.5491069207615538
Validation loss: 3.1479158780846004

Epoch: 5| Step: 5
Training loss: 3.2857884582298245
Validation loss: 3.1483366232089462

Epoch: 5| Step: 6
Training loss: 2.5659909543764754
Validation loss: 3.149411115798405

Epoch: 5| Step: 7
Training loss: 2.423027797871711
Validation loss: 3.1482671273604845

Epoch: 5| Step: 8
Training loss: 3.8435257016619437
Validation loss: 3.146997056572734

Epoch: 5| Step: 9
Training loss: 3.0208330000953927
Validation loss: 3.146502153089439

Epoch: 5| Step: 10
Training loss: 3.352716278450448
Validation loss: 3.1475767555336898

Epoch: 81| Step: 0
Training loss: 3.3631749152942163
Validation loss: 3.1457790382837643

Epoch: 5| Step: 1
Training loss: 3.3921201722972114
Validation loss: 3.1474480730915935

Epoch: 5| Step: 2
Training loss: 3.068278252726963
Validation loss: 3.145006744483438

Epoch: 5| Step: 3
Training loss: 3.009074632463906
Validation loss: 3.1475848025930846

Epoch: 5| Step: 4
Training loss: 3.9354236517232146
Validation loss: 3.147324707635964

Epoch: 5| Step: 5
Training loss: 3.1084995283298587
Validation loss: 3.149591602695914

Epoch: 5| Step: 6
Training loss: 3.1884692345340753
Validation loss: 3.1462918730858482

Epoch: 5| Step: 7
Training loss: 3.4813112209011794
Validation loss: 3.1492942158054693

Epoch: 5| Step: 8
Training loss: 3.4920902793374298
Validation loss: 3.1490507622493866

Epoch: 5| Step: 9
Training loss: 4.007423902563699
Validation loss: 3.1486118066565556

Epoch: 5| Step: 10
Training loss: 3.11479764645425
Validation loss: 3.147599412677285

Epoch: 82| Step: 0
Training loss: 2.910977200428333
Validation loss: 3.150827114794706

Epoch: 5| Step: 1
Training loss: 3.8669511202615037
Validation loss: 3.1459333445599555

Epoch: 5| Step: 2
Training loss: 3.0700722326174623
Validation loss: 3.1390927851980917

Epoch: 5| Step: 3
Training loss: 3.6603601291019494
Validation loss: 3.1425571447960636

Epoch: 5| Step: 4
Training loss: 3.866745555555246
Validation loss: 3.1440596855504017

Epoch: 5| Step: 5
Training loss: 2.927868413115426
Validation loss: 3.1412454187285275

Epoch: 5| Step: 6
Training loss: 3.4236285450155957
Validation loss: 3.14081465449956

Epoch: 5| Step: 7
Training loss: 3.073789069698036
Validation loss: 3.140298066305116

Epoch: 5| Step: 8
Training loss: 2.584019805596097
Validation loss: 3.139795819056648

Epoch: 5| Step: 9
Training loss: 3.9393409179685066
Validation loss: 3.139630576508273

Epoch: 5| Step: 10
Training loss: 3.788045782165036
Validation loss: 3.140508463560668

Epoch: 83| Step: 0
Training loss: 4.180519548826451
Validation loss: 3.13973677418152

Epoch: 5| Step: 1
Training loss: 3.206933265146322
Validation loss: 3.139378556996114

Epoch: 5| Step: 2
Training loss: 3.509611420382963
Validation loss: 3.1383507917076714

Epoch: 5| Step: 3
Training loss: 2.6509835487295588
Validation loss: 3.140690528930043

Epoch: 5| Step: 4
Training loss: 3.239048332039835
Validation loss: 3.1375496429332164

Epoch: 5| Step: 5
Training loss: 3.358004836178376
Validation loss: 3.13764130204256

Epoch: 5| Step: 6
Training loss: 3.6430239652588337
Validation loss: 3.1357488015102177

Epoch: 5| Step: 7
Training loss: 3.243577038925743
Validation loss: 3.1363841523660794

Epoch: 5| Step: 8
Training loss: 3.629073123770159
Validation loss: 3.1363342439340305

Epoch: 5| Step: 9
Training loss: 3.8034243513667816
Validation loss: 3.1378330968879298

Epoch: 5| Step: 10
Training loss: 2.345509898337038
Validation loss: 3.139282978145245

Epoch: 84| Step: 0
Training loss: 3.7600106454252145
Validation loss: 3.1378776325973354

Epoch: 5| Step: 1
Training loss: 3.2939880169278184
Validation loss: 3.1357325272592664

Epoch: 5| Step: 2
Training loss: 3.359501326204025
Validation loss: 3.1379574604840723

Epoch: 5| Step: 3
Training loss: 2.9030392867165484
Validation loss: 3.141398284521146

Epoch: 5| Step: 4
Training loss: 3.4681659928561532
Validation loss: 3.1411032078198344

Epoch: 5| Step: 5
Training loss: 2.9911519542013507
Validation loss: 3.1364428631129604

Epoch: 5| Step: 6
Training loss: 2.8661107840253055
Validation loss: 3.1359988499163833

Epoch: 5| Step: 7
Training loss: 3.5867482849912533
Validation loss: 3.135681061612577

Epoch: 5| Step: 8
Training loss: 3.9292630218525026
Validation loss: 3.13381109861782

Epoch: 5| Step: 9
Training loss: 3.699989246662082
Validation loss: 3.135769111094454

Epoch: 5| Step: 10
Training loss: 3.284751114148068
Validation loss: 3.136547494794601

Epoch: 85| Step: 0
Training loss: 3.2642867709292593
Validation loss: 3.135421838505027

Epoch: 5| Step: 1
Training loss: 3.0531381253416217
Validation loss: 3.1358767900803866

Epoch: 5| Step: 2
Training loss: 3.860777688819675
Validation loss: 3.1339038020838643

Epoch: 5| Step: 3
Training loss: 3.3579255991651764
Validation loss: 3.1353563940613376

Epoch: 5| Step: 4
Training loss: 4.09786291483134
Validation loss: 3.1350016113613104

Epoch: 5| Step: 5
Training loss: 3.192961109769196
Validation loss: 3.1379594424708572

Epoch: 5| Step: 6
Training loss: 3.0945438175769637
Validation loss: 3.137972925830003

Epoch: 5| Step: 7
Training loss: 3.383532159033784
Validation loss: 3.139039156498493

Epoch: 5| Step: 8
Training loss: 3.6749190029638377
Validation loss: 3.1373346935351356

Epoch: 5| Step: 9
Training loss: 3.580665719134851
Validation loss: 3.1336834306343637

Epoch: 5| Step: 10
Training loss: 2.287741322112943
Validation loss: 3.1321843925923485

Epoch: 86| Step: 0
Training loss: 3.310573089405798
Validation loss: 3.1303191701904884

Epoch: 5| Step: 1
Training loss: 3.276416088029262
Validation loss: 3.1315524106137858

Epoch: 5| Step: 2
Training loss: 4.0119645471499235
Validation loss: 3.1311312899840593

Epoch: 5| Step: 3
Training loss: 3.5599266261136604
Validation loss: 3.1312588041251894

Epoch: 5| Step: 4
Training loss: 2.9215028903260722
Validation loss: 3.1295562409439497

Epoch: 5| Step: 5
Training loss: 3.152340270918542
Validation loss: 3.129729147528455

Epoch: 5| Step: 6
Training loss: 3.4450665513740075
Validation loss: 3.1315920853426182

Epoch: 5| Step: 7
Training loss: 2.826761665307348
Validation loss: 3.129048091069023

Epoch: 5| Step: 8
Training loss: 3.8019339057438937
Validation loss: 3.1313246322179413

Epoch: 5| Step: 9
Training loss: 3.178965493599619
Validation loss: 3.131082381876561

Epoch: 5| Step: 10
Training loss: 3.657480538160651
Validation loss: 3.1296504998533807

Epoch: 87| Step: 0
Training loss: 3.196747324790799
Validation loss: 3.1304853079724992

Epoch: 5| Step: 1
Training loss: 4.074262287788707
Validation loss: 3.1293984237380776

Epoch: 5| Step: 2
Training loss: 3.329329724828404
Validation loss: 3.12941767679848

Epoch: 5| Step: 3
Training loss: 3.5105615391631386
Validation loss: 3.128393003945891

Epoch: 5| Step: 4
Training loss: 3.534265766428929
Validation loss: 3.1327634577461603

Epoch: 5| Step: 5
Training loss: 3.2957255452338314
Validation loss: 3.130184249180582

Epoch: 5| Step: 6
Training loss: 3.6911896172792926
Validation loss: 3.128762870263493

Epoch: 5| Step: 7
Training loss: 3.0069212546762394
Validation loss: 3.1276062169637417

Epoch: 5| Step: 8
Training loss: 3.3905356962335733
Validation loss: 3.1308882468020167

Epoch: 5| Step: 9
Training loss: 2.3737233394754758
Validation loss: 3.1282067693743705

Epoch: 5| Step: 10
Training loss: 3.621687197485877
Validation loss: 3.126904253204869

Epoch: 88| Step: 0
Training loss: 3.471336431474685
Validation loss: 3.1254140337595833

Epoch: 5| Step: 1
Training loss: 3.2465680415104097
Validation loss: 3.124932412677946

Epoch: 5| Step: 2
Training loss: 3.780792334736961
Validation loss: 3.1243181022001396

Epoch: 5| Step: 3
Training loss: 2.4070366898685385
Validation loss: 3.126202761623624

Epoch: 5| Step: 4
Training loss: 3.298504756529118
Validation loss: 3.1239385906550954

Epoch: 5| Step: 5
Training loss: 2.930259058830033
Validation loss: 3.12472698864928

Epoch: 5| Step: 6
Training loss: 3.601573886149979
Validation loss: 3.125389283247173

Epoch: 5| Step: 7
Training loss: 3.4168787324423437
Validation loss: 3.1238390810933825

Epoch: 5| Step: 8
Training loss: 3.8131019242192914
Validation loss: 3.1231675064461415

Epoch: 5| Step: 9
Training loss: 3.3336569787897923
Validation loss: 3.125514351138922

Epoch: 5| Step: 10
Training loss: 3.7199165373842704
Validation loss: 3.124869293432732

Epoch: 89| Step: 0
Training loss: 3.0623636020725606
Validation loss: 3.121890487007562

Epoch: 5| Step: 1
Training loss: 3.095173517887965
Validation loss: 3.1226152422682554

Epoch: 5| Step: 2
Training loss: 4.190114813349134
Validation loss: 3.122011033393638

Epoch: 5| Step: 3
Training loss: 3.0909398735267906
Validation loss: 3.1214635194800127

Epoch: 5| Step: 4
Training loss: 2.610398326016777
Validation loss: 3.1219939525972653

Epoch: 5| Step: 5
Training loss: 3.9734932496918476
Validation loss: 3.1220011114174855

Epoch: 5| Step: 6
Training loss: 4.215005300570557
Validation loss: 3.1200012474094376

Epoch: 5| Step: 7
Training loss: 3.535651375677414
Validation loss: 3.122681303473153

Epoch: 5| Step: 8
Training loss: 3.0478122932326843
Validation loss: 3.122294300189718

Epoch: 5| Step: 9
Training loss: 2.607731741448431
Validation loss: 3.1235001408183876

Epoch: 5| Step: 10
Training loss: 3.2504451153458933
Validation loss: 3.120582464043951

Epoch: 90| Step: 0
Training loss: 3.040645236254764
Validation loss: 3.122855688291377

Epoch: 5| Step: 1
Training loss: 3.8094127224438403
Validation loss: 3.121863568541753

Epoch: 5| Step: 2
Training loss: 3.6726003376839746
Validation loss: 3.1228698065844998

Epoch: 5| Step: 3
Training loss: 2.4773500556107666
Validation loss: 3.1237386885754432

Epoch: 5| Step: 4
Training loss: 2.9596786842702256
Validation loss: 3.1320533940553315

Epoch: 5| Step: 5
Training loss: 3.15144117780935
Validation loss: 3.1233179270209313

Epoch: 5| Step: 6
Training loss: 3.7128192186387112
Validation loss: 3.128335164848148

Epoch: 5| Step: 7
Training loss: 3.6777211501521383
Validation loss: 3.1241471765574955

Epoch: 5| Step: 8
Training loss: 3.4255872125599858
Validation loss: 3.1191640410162464

Epoch: 5| Step: 9
Training loss: 3.1121885519201173
Validation loss: 3.1205485438592713

Epoch: 5| Step: 10
Training loss: 3.939796262595222
Validation loss: 3.1192118752240563

Epoch: 91| Step: 0
Training loss: 3.5874970811572813
Validation loss: 3.120736279555623

Epoch: 5| Step: 1
Training loss: 3.6747457766670504
Validation loss: 3.1216458193475627

Epoch: 5| Step: 2
Training loss: 3.4987292026284624
Validation loss: 3.121380399269451

Epoch: 5| Step: 3
Training loss: 3.4886653470819846
Validation loss: 3.1210701283268647

Epoch: 5| Step: 4
Training loss: 3.4278147804850136
Validation loss: 3.1216959773945034

Epoch: 5| Step: 5
Training loss: 3.361343445817786
Validation loss: 3.1214179422335766

Epoch: 5| Step: 6
Training loss: 3.508241215188915
Validation loss: 3.1184586198983832

Epoch: 5| Step: 7
Training loss: 3.0920608995764383
Validation loss: 3.1165623290455695

Epoch: 5| Step: 8
Training loss: 2.7862202670400706
Validation loss: 3.116646263771292

Epoch: 5| Step: 9
Training loss: 3.6576912150589256
Validation loss: 3.1163674876955603

Epoch: 5| Step: 10
Training loss: 2.930552606646444
Validation loss: 3.116338246087205

Epoch: 92| Step: 0
Training loss: 3.0882340396483197
Validation loss: 3.11461073066025

Epoch: 5| Step: 1
Training loss: 2.7934893356346366
Validation loss: 3.115814340775975

Epoch: 5| Step: 2
Training loss: 3.256643108281409
Validation loss: 3.1170592227036447

Epoch: 5| Step: 3
Training loss: 3.5547949470797455
Validation loss: 3.119575031288936

Epoch: 5| Step: 4
Training loss: 3.4433898405132695
Validation loss: 3.119201826813705

Epoch: 5| Step: 5
Training loss: 3.675607934609572
Validation loss: 3.1162034149160878

Epoch: 5| Step: 6
Training loss: 3.5723341011838405
Validation loss: 3.1158240553656413

Epoch: 5| Step: 7
Training loss: 3.503328511760768
Validation loss: 3.115098747145023

Epoch: 5| Step: 8
Training loss: 3.3872123455365006
Validation loss: 3.1143268580162182

Epoch: 5| Step: 9
Training loss: 3.3507000718319317
Validation loss: 3.113283023717153

Epoch: 5| Step: 10
Training loss: 3.4317244127061226
Validation loss: 3.113042778773343

Epoch: 93| Step: 0
Training loss: 3.0528463683571605
Validation loss: 3.111802654260718

Epoch: 5| Step: 1
Training loss: 3.2950089945692094
Validation loss: 3.1136156519300933

Epoch: 5| Step: 2
Training loss: 3.168777080472841
Validation loss: 3.109146920270133

Epoch: 5| Step: 3
Training loss: 3.3462369707813617
Validation loss: 3.1110497227875786

Epoch: 5| Step: 4
Training loss: 3.7411080796598606
Validation loss: 3.1119300575138324

Epoch: 5| Step: 5
Training loss: 2.984433158587435
Validation loss: 3.112070555221847

Epoch: 5| Step: 6
Training loss: 3.3767800052321073
Validation loss: 3.1111826975106966

Epoch: 5| Step: 7
Training loss: 3.784789769369976
Validation loss: 3.1103509566919385

Epoch: 5| Step: 8
Training loss: 3.419490732567817
Validation loss: 3.111587784974007

Epoch: 5| Step: 9
Training loss: 3.6557348165519605
Validation loss: 3.111024342140949

Epoch: 5| Step: 10
Training loss: 3.1288221255076816
Validation loss: 3.1120989884512293

Epoch: 94| Step: 0
Training loss: 4.089735086157925
Validation loss: 3.1153115375251472

Epoch: 5| Step: 1
Training loss: 3.573926302926517
Validation loss: 3.11889552790953

Epoch: 5| Step: 2
Training loss: 2.989982250505411
Validation loss: 3.1217507564587734

Epoch: 5| Step: 3
Training loss: 3.289609741208018
Validation loss: 3.125400990016254

Epoch: 5| Step: 4
Training loss: 3.024795109138883
Validation loss: 3.1176514277364356

Epoch: 5| Step: 5
Training loss: 3.693776107670002
Validation loss: 3.115421898520827

Epoch: 5| Step: 6
Training loss: 3.443584536473421
Validation loss: 3.1089369041192607

Epoch: 5| Step: 7
Training loss: 3.041956604677524
Validation loss: 3.111044714246503

Epoch: 5| Step: 8
Training loss: 3.558669188921499
Validation loss: 3.108104198569948

Epoch: 5| Step: 9
Training loss: 2.452711131178185
Validation loss: 3.1090537169232166

Epoch: 5| Step: 10
Training loss: 3.6909632825738194
Validation loss: 3.1095427341476527

Epoch: 95| Step: 0
Training loss: 4.149049645499006
Validation loss: 3.1095893247195274

Epoch: 5| Step: 1
Training loss: 3.459991394649675
Validation loss: 3.1095056405884707

Epoch: 5| Step: 2
Training loss: 3.0568178363166862
Validation loss: 3.109382748523312

Epoch: 5| Step: 3
Training loss: 2.9358728650395087
Validation loss: 3.108999793527711

Epoch: 5| Step: 4
Training loss: 2.8408161161987744
Validation loss: 3.1089725630738423

Epoch: 5| Step: 5
Training loss: 2.9863207800146756
Validation loss: 3.1114210674133105

Epoch: 5| Step: 6
Training loss: 3.8267049841562915
Validation loss: 3.113855140519277

Epoch: 5| Step: 7
Training loss: 3.0438072998167884
Validation loss: 3.119556238501441

Epoch: 5| Step: 8
Training loss: 3.818156689193735
Validation loss: 3.1150251988694833

Epoch: 5| Step: 9
Training loss: 3.167663333719127
Validation loss: 3.114145844478465

Epoch: 5| Step: 10
Training loss: 3.513039956725347
Validation loss: 3.1084022824656605

Epoch: 96| Step: 0
Training loss: 3.201649097855788
Validation loss: 3.113486078830655

Epoch: 5| Step: 1
Training loss: 2.986044850957318
Validation loss: 3.1062053706347523

Epoch: 5| Step: 2
Training loss: 3.46100184120321
Validation loss: 3.1049905066265535

Epoch: 5| Step: 3
Training loss: 3.7462324926242827
Validation loss: 3.1045974963229073

Epoch: 5| Step: 4
Training loss: 3.720378999784642
Validation loss: 3.1036234532658264

Epoch: 5| Step: 5
Training loss: 3.5352745415723446
Validation loss: 3.106275922237487

Epoch: 5| Step: 6
Training loss: 2.8853343488241348
Validation loss: 3.1049478696809367

Epoch: 5| Step: 7
Training loss: 3.3091155702451327
Validation loss: 3.1038789193896466

Epoch: 5| Step: 8
Training loss: 3.1205287226152865
Validation loss: 3.104236332492285

Epoch: 5| Step: 9
Training loss: 3.299702954650346
Validation loss: 3.103512593416833

Epoch: 5| Step: 10
Training loss: 3.6767436763091466
Validation loss: 3.1044291018999157

Epoch: 97| Step: 0
Training loss: 3.509835456403943
Validation loss: 3.105105638316535

Epoch: 5| Step: 1
Training loss: 3.7502569746343326
Validation loss: 3.104786740664369

Epoch: 5| Step: 2
Training loss: 4.042140710041573
Validation loss: 3.107533788302559

Epoch: 5| Step: 3
Training loss: 3.331798120462153
Validation loss: 3.1073506035936913

Epoch: 5| Step: 4
Training loss: 3.0388696604447167
Validation loss: 3.101829334866317

Epoch: 5| Step: 5
Training loss: 3.199384189003061
Validation loss: 3.102585931765087

Epoch: 5| Step: 6
Training loss: 3.0398020494160125
Validation loss: 3.0997584286873954

Epoch: 5| Step: 7
Training loss: 3.1133671728360386
Validation loss: 3.1014402421275213

Epoch: 5| Step: 8
Training loss: 3.4445073231389296
Validation loss: 3.101653476111396

Epoch: 5| Step: 9
Training loss: 3.1128110063815626
Validation loss: 3.1014225892756366

Epoch: 5| Step: 10
Training loss: 3.268228031882688
Validation loss: 3.101505231794825

Epoch: 98| Step: 0
Training loss: 3.403747479244872
Validation loss: 3.101425457581595

Epoch: 5| Step: 1
Training loss: 3.3285944791097433
Validation loss: 3.101556687594852

Epoch: 5| Step: 2
Training loss: 3.060135843590213
Validation loss: 3.100836450263732

Epoch: 5| Step: 3
Training loss: 3.426801227371746
Validation loss: 3.102410926535401

Epoch: 5| Step: 4
Training loss: 3.0487439805613046
Validation loss: 3.0997584319955767

Epoch: 5| Step: 5
Training loss: 2.877792992013639
Validation loss: 3.101156341895878

Epoch: 5| Step: 6
Training loss: 3.7709045122429314
Validation loss: 3.101796104705536

Epoch: 5| Step: 7
Training loss: 3.7650670314865464
Validation loss: 3.0989562282346568

Epoch: 5| Step: 8
Training loss: 3.568277993863665
Validation loss: 3.1019251933643006

Epoch: 5| Step: 9
Training loss: 2.7260949026256105
Validation loss: 3.104868963366126

Epoch: 5| Step: 10
Training loss: 3.880348083573795
Validation loss: 3.106839609828477

Epoch: 99| Step: 0
Training loss: 3.343068846728234
Validation loss: 3.10479967449417

Epoch: 5| Step: 1
Training loss: 3.2623107738354737
Validation loss: 3.1032525188154327

Epoch: 5| Step: 2
Training loss: 3.2841297410155335
Validation loss: 3.1045432833034328

Epoch: 5| Step: 3
Training loss: 3.244263501398107
Validation loss: 3.097758984064435

Epoch: 5| Step: 4
Training loss: 3.2669825310358274
Validation loss: 3.1001568486959625

Epoch: 5| Step: 5
Training loss: 3.965956057414255
Validation loss: 3.099681286731357

Epoch: 5| Step: 6
Training loss: 3.027732302434057
Validation loss: 3.097838275059732

Epoch: 5| Step: 7
Training loss: 4.059355472461933
Validation loss: 3.0981473078448976

Epoch: 5| Step: 8
Training loss: 2.6679324682402163
Validation loss: 3.0966512136924726

Epoch: 5| Step: 9
Training loss: 3.388923042069678
Validation loss: 3.0958496477279662

Epoch: 5| Step: 10
Training loss: 3.1948753748125287
Validation loss: 3.0970342577754173

Epoch: 100| Step: 0
Training loss: 3.3857074006271026
Validation loss: 3.0976715987532497

Epoch: 5| Step: 1
Training loss: 3.785565774374644
Validation loss: 3.0974027842932434

Epoch: 5| Step: 2
Training loss: 3.577950952286486
Validation loss: 3.0994886025123534

Epoch: 5| Step: 3
Training loss: 3.5264168130768065
Validation loss: 3.0999930509052067

Epoch: 5| Step: 4
Training loss: 3.8808979556619034
Validation loss: 3.097260155348859

Epoch: 5| Step: 5
Training loss: 3.502956776318802
Validation loss: 3.1025035923689983

Epoch: 5| Step: 6
Training loss: 2.8862069673828548
Validation loss: 3.103009706949569

Epoch: 5| Step: 7
Training loss: 2.758408349698743
Validation loss: 3.1014975974971914

Epoch: 5| Step: 8
Training loss: 3.1062572701750937
Validation loss: 3.1000821867814485

Epoch: 5| Step: 9
Training loss: 2.947875508986004
Validation loss: 3.0975052122584894

Epoch: 5| Step: 10
Training loss: 3.364415277746315
Validation loss: 3.0967209497996757

Epoch: 101| Step: 0
Training loss: 3.729419181131141
Validation loss: 3.0968774024516392

Epoch: 5| Step: 1
Training loss: 2.459276783398583
Validation loss: 3.093299593455934

Epoch: 5| Step: 2
Training loss: 3.6627227350930456
Validation loss: 3.09254910722424

Epoch: 5| Step: 3
Training loss: 3.423412656846261
Validation loss: 3.093274819698841

Epoch: 5| Step: 4
Training loss: 3.021432768880962
Validation loss: 3.092493501682361

Epoch: 5| Step: 5
Training loss: 3.071332068210433
Validation loss: 3.090324656796255

Epoch: 5| Step: 6
Training loss: 3.3920342817103633
Validation loss: 3.0912470515862047

Epoch: 5| Step: 7
Training loss: 3.614362169401617
Validation loss: 3.09030958430211

Epoch: 5| Step: 8
Training loss: 3.8460123490935234
Validation loss: 3.095152224639048

Epoch: 5| Step: 9
Training loss: 3.0995501468722964
Validation loss: 3.09243277355517

Epoch: 5| Step: 10
Training loss: 3.3217224717672247
Validation loss: 3.092015598650073

Epoch: 102| Step: 0
Training loss: 3.147452302045631
Validation loss: 3.0902198546110995

Epoch: 5| Step: 1
Training loss: 2.5650344038769752
Validation loss: 3.0904438877631626

Epoch: 5| Step: 2
Training loss: 3.740834798004573
Validation loss: 3.0893169789084416

Epoch: 5| Step: 3
Training loss: 3.550031694082702
Validation loss: 3.0904231442663685

Epoch: 5| Step: 4
Training loss: 3.479609219544595
Validation loss: 3.0888976120763525

Epoch: 5| Step: 5
Training loss: 3.4425051230487367
Validation loss: 3.088472720651467

Epoch: 5| Step: 6
Training loss: 3.673565544385853
Validation loss: 3.089745267293665

Epoch: 5| Step: 7
Training loss: 3.428143338316949
Validation loss: 3.0880012852228647

Epoch: 5| Step: 8
Training loss: 3.1701488589886395
Validation loss: 3.0886104116588338

Epoch: 5| Step: 9
Training loss: 3.548744549184431
Validation loss: 3.0896769295107283

Epoch: 5| Step: 10
Training loss: 2.8555280311369535
Validation loss: 3.087409280114493

Epoch: 103| Step: 0
Training loss: 3.354368373579286
Validation loss: 3.087871278231564

Epoch: 5| Step: 1
Training loss: 3.1311479746021234
Validation loss: 3.0880779742863935

Epoch: 5| Step: 2
Training loss: 3.2490040646965266
Validation loss: 3.0891519449313103

Epoch: 5| Step: 3
Training loss: 3.6511442611725924
Validation loss: 3.0907617089047283

Epoch: 5| Step: 4
Training loss: 3.174981911675298
Validation loss: 3.08794613825312

Epoch: 5| Step: 5
Training loss: 3.7504754083007987
Validation loss: 3.0887462414922964

Epoch: 5| Step: 6
Training loss: 3.2939676057279996
Validation loss: 3.0862525921343553

Epoch: 5| Step: 7
Training loss: 3.657439861520242
Validation loss: 3.086451978413453

Epoch: 5| Step: 8
Training loss: 2.768012444142941
Validation loss: 3.0870434595595917

Epoch: 5| Step: 9
Training loss: 3.8958741592199226
Validation loss: 3.0866491799049802

Epoch: 5| Step: 10
Training loss: 2.5573789085739804
Validation loss: 3.0866590643578524

Epoch: 104| Step: 0
Training loss: 3.5832422969402367
Validation loss: 3.084068055043625

Epoch: 5| Step: 1
Training loss: 4.188977792090447
Validation loss: 3.087402801690867

Epoch: 5| Step: 2
Training loss: 3.4146441699588674
Validation loss: 3.088512984470178

Epoch: 5| Step: 3
Training loss: 2.9514895153967715
Validation loss: 3.0862360186706574

Epoch: 5| Step: 4
Training loss: 3.365005671367429
Validation loss: 3.08468410821777

Epoch: 5| Step: 5
Training loss: 3.3038155778488187
Validation loss: 3.0838936598962294

Epoch: 5| Step: 6
Training loss: 3.50970815570124
Validation loss: 3.088686708773867

Epoch: 5| Step: 7
Training loss: 2.8740698926970984
Validation loss: 3.0845609818944286

Epoch: 5| Step: 8
Training loss: 3.196926613966209
Validation loss: 3.0846806259615813

Epoch: 5| Step: 9
Training loss: 2.9938316509285494
Validation loss: 3.087552165673119

Epoch: 5| Step: 10
Training loss: 3.2352769856330834
Validation loss: 3.0892240171067944

Epoch: 105| Step: 0
Training loss: 2.9123454826526247
Validation loss: 3.089511163802812

Epoch: 5| Step: 1
Training loss: 3.3069033577510067
Validation loss: 3.0915974586178487

Epoch: 5| Step: 2
Training loss: 3.264074222001301
Validation loss: 3.087093513802421

Epoch: 5| Step: 3
Training loss: 3.595980540798947
Validation loss: 3.084890059642527

Epoch: 5| Step: 4
Training loss: 3.651170380954145
Validation loss: 3.0824801593000903

Epoch: 5| Step: 5
Training loss: 3.190123282654248
Validation loss: 3.082567554442853

Epoch: 5| Step: 6
Training loss: 3.829859749240504
Validation loss: 3.081639605946147

Epoch: 5| Step: 7
Training loss: 3.4839159744413717
Validation loss: 3.081705322649654

Epoch: 5| Step: 8
Training loss: 3.1595090149057965
Validation loss: 3.0827456570824636

Epoch: 5| Step: 9
Training loss: 3.594072277711531
Validation loss: 3.080055379841119

Epoch: 5| Step: 10
Training loss: 2.477595165130214
Validation loss: 3.082714032473433

Epoch: 106| Step: 0
Training loss: 3.293759577988772
Validation loss: 3.0800344190550817

Epoch: 5| Step: 1
Training loss: 3.176570029561754
Validation loss: 3.0808279844609956

Epoch: 5| Step: 2
Training loss: 3.517240704032776
Validation loss: 3.0831028234915134

Epoch: 5| Step: 3
Training loss: 3.2429407187003716
Validation loss: 3.0805399851043336

Epoch: 5| Step: 4
Training loss: 3.5135198775489576
Validation loss: 3.0823179422773785

Epoch: 5| Step: 5
Training loss: 3.2813072562898866
Validation loss: 3.0850252089875925

Epoch: 5| Step: 6
Training loss: 3.0549166464165163
Validation loss: 3.0908828431206543

Epoch: 5| Step: 7
Training loss: 3.70052404043375
Validation loss: 3.0877077544661087

Epoch: 5| Step: 8
Training loss: 3.72415550439106
Validation loss: 3.0840796360378304

Epoch: 5| Step: 9
Training loss: 2.813568336184346
Validation loss: 3.0770692373863193

Epoch: 5| Step: 10
Training loss: 3.3660434983378686
Validation loss: 3.0771947604111642

Epoch: 107| Step: 0
Training loss: 2.6290948808626373
Validation loss: 3.0768867610234953

Epoch: 5| Step: 1
Training loss: 3.1649197394392616
Validation loss: 3.0765377833239325

Epoch: 5| Step: 2
Training loss: 4.245648568687572
Validation loss: 3.0799292608926523

Epoch: 5| Step: 3
Training loss: 2.7855187564041017
Validation loss: 3.078503590574757

Epoch: 5| Step: 4
Training loss: 3.4305346578835825
Validation loss: 3.0768536364226766

Epoch: 5| Step: 5
Training loss: 2.951157817895459
Validation loss: 3.076280078355461

Epoch: 5| Step: 6
Training loss: 3.3344360117170266
Validation loss: 3.0757737704291555

Epoch: 5| Step: 7
Training loss: 3.274139547516466
Validation loss: 3.0776761343353023

Epoch: 5| Step: 8
Training loss: 3.3967387546704955
Validation loss: 3.079081031502919

Epoch: 5| Step: 9
Training loss: 3.8813392714893236
Validation loss: 3.077853814528372

Epoch: 5| Step: 10
Training loss: 3.348934681731258
Validation loss: 3.0834412997920007

Epoch: 108| Step: 0
Training loss: 3.5310491994294706
Validation loss: 3.082116663265873

Epoch: 5| Step: 1
Training loss: 3.3076225215394692
Validation loss: 3.0854841508599296

Epoch: 5| Step: 2
Training loss: 3.2900460193047554
Validation loss: 3.084342796840045

Epoch: 5| Step: 3
Training loss: 3.755034309972065
Validation loss: 3.0880724976266682

Epoch: 5| Step: 4
Training loss: 3.7141926512744665
Validation loss: 3.0871111472785504

Epoch: 5| Step: 5
Training loss: 3.283489226175881
Validation loss: 3.0763365077979787

Epoch: 5| Step: 6
Training loss: 3.2142453569573184
Validation loss: 3.074863082834895

Epoch: 5| Step: 7
Training loss: 3.0489493327023705
Validation loss: 3.0735997918227094

Epoch: 5| Step: 8
Training loss: 2.929177038862622
Validation loss: 3.0731439953049153

Epoch: 5| Step: 9
Training loss: 3.3250606560014613
Validation loss: 3.0716180030606783

Epoch: 5| Step: 10
Training loss: 3.2208624268896084
Validation loss: 3.076115417535336

Epoch: 109| Step: 0
Training loss: 2.6683736245399334
Validation loss: 3.0748751437142587

Epoch: 5| Step: 1
Training loss: 2.492629152584811
Validation loss: 3.075694148999424

Epoch: 5| Step: 2
Training loss: 3.5935281436275086
Validation loss: 3.07640129112843

Epoch: 5| Step: 3
Training loss: 2.81582377385209
Validation loss: 3.07875138530607

Epoch: 5| Step: 4
Training loss: 3.7933737855798
Validation loss: 3.0747019480834106

Epoch: 5| Step: 5
Training loss: 3.900162859719633
Validation loss: 3.073248148552562

Epoch: 5| Step: 6
Training loss: 2.640384911451612
Validation loss: 3.0724804940800152

Epoch: 5| Step: 7
Training loss: 3.2642128551397604
Validation loss: 3.072515637464198

Epoch: 5| Step: 8
Training loss: 4.501498078954826
Validation loss: 3.070177028656211

Epoch: 5| Step: 9
Training loss: 2.9904973209115897
Validation loss: 3.071169489403771

Epoch: 5| Step: 10
Training loss: 3.5396505713555064
Validation loss: 3.0701021169711757

Epoch: 110| Step: 0
Training loss: 3.4940333597810276
Validation loss: 3.0741094299893987

Epoch: 5| Step: 1
Training loss: 3.4558456543082716
Validation loss: 3.0709300270429125

Epoch: 5| Step: 2
Training loss: 3.6072221420833546
Validation loss: 3.071126259371659

Epoch: 5| Step: 3
Training loss: 2.8365289581020265
Validation loss: 3.0705294970359125

Epoch: 5| Step: 4
Training loss: 3.106581770374073
Validation loss: 3.0687630294403907

Epoch: 5| Step: 5
Training loss: 3.5233376228741893
Validation loss: 3.067705165524968

Epoch: 5| Step: 6
Training loss: 3.1538812794616993
Validation loss: 3.0697345278877886

Epoch: 5| Step: 7
Training loss: 3.3963076176422513
Validation loss: 3.068950679312404

Epoch: 5| Step: 8
Training loss: 3.324697816353895
Validation loss: 3.069443265989272

Epoch: 5| Step: 9
Training loss: 3.3504823308995992
Validation loss: 3.0673642055937007

Epoch: 5| Step: 10
Training loss: 3.3980846002565164
Validation loss: 3.067477378937981

Epoch: 111| Step: 0
Training loss: 2.663657775743133
Validation loss: 3.06820929727561

Epoch: 5| Step: 1
Training loss: 2.5278918749405364
Validation loss: 3.070183536748008

Epoch: 5| Step: 2
Training loss: 3.61291832003319
Validation loss: 3.071011177772907

Epoch: 5| Step: 3
Training loss: 3.5427606725523244
Validation loss: 3.072318286453676

Epoch: 5| Step: 4
Training loss: 3.659030867503479
Validation loss: 3.086429310958933

Epoch: 5| Step: 5
Training loss: 3.326717741834719
Validation loss: 3.091519264701032

Epoch: 5| Step: 6
Training loss: 3.6638150975493784
Validation loss: 3.0713999452579817

Epoch: 5| Step: 7
Training loss: 3.2168404553628065
Validation loss: 3.0680351370867016

Epoch: 5| Step: 8
Training loss: 3.17260192659261
Validation loss: 3.066368430626608

Epoch: 5| Step: 9
Training loss: 3.678216141938427
Validation loss: 3.0683109034214144

Epoch: 5| Step: 10
Training loss: 3.4290936418609044
Validation loss: 3.0668728088586277

Epoch: 112| Step: 0
Training loss: 3.5307804571938277
Validation loss: 3.069431512841563

Epoch: 5| Step: 1
Training loss: 3.3983841815142113
Validation loss: 3.0686168044519238

Epoch: 5| Step: 2
Training loss: 2.93384340648731
Validation loss: 3.066735990158954

Epoch: 5| Step: 3
Training loss: 3.3925726434271346
Validation loss: 3.0674105818210773

Epoch: 5| Step: 4
Training loss: 3.663962942369123
Validation loss: 3.0658015673683834

Epoch: 5| Step: 5
Training loss: 3.63156086679318
Validation loss: 3.065446196157851

Epoch: 5| Step: 6
Training loss: 3.2427072131462054
Validation loss: 3.0652816458588994

Epoch: 5| Step: 7
Training loss: 3.0486484159380307
Validation loss: 3.0655422958563223

Epoch: 5| Step: 8
Training loss: 2.8834247714264345
Validation loss: 3.0656914136897684

Epoch: 5| Step: 9
Training loss: 3.26274295647644
Validation loss: 3.06517212837932

Epoch: 5| Step: 10
Training loss: 3.6216927272691692
Validation loss: 3.0627372855701958

Epoch: 113| Step: 0
Training loss: 3.507687029049514
Validation loss: 3.0658574906207363

Epoch: 5| Step: 1
Training loss: 3.4154375393058944
Validation loss: 3.0655094166375676

Epoch: 5| Step: 2
Training loss: 3.163973734046142
Validation loss: 3.0687203920655026

Epoch: 5| Step: 3
Training loss: 2.9691187579365144
Validation loss: 3.067156675317576

Epoch: 5| Step: 4
Training loss: 3.0301335431876235
Validation loss: 3.075508842782828

Epoch: 5| Step: 5
Training loss: 3.5092388558071868
Validation loss: 3.078380280340509

Epoch: 5| Step: 6
Training loss: 3.23512591062431
Validation loss: 3.0700108213114716

Epoch: 5| Step: 7
Training loss: 3.792654572507212
Validation loss: 3.0643184838842243

Epoch: 5| Step: 8
Training loss: 4.246682611392603
Validation loss: 3.0625342977619425

Epoch: 5| Step: 9
Training loss: 2.776037668269405
Validation loss: 3.0600977590624465

Epoch: 5| Step: 10
Training loss: 2.553913804233006
Validation loss: 3.0618711658456763

Epoch: 114| Step: 0
Training loss: 3.5049290689863453
Validation loss: 3.063215524153135

Epoch: 5| Step: 1
Training loss: 3.3115875138946
Validation loss: 3.0641924241864644

Epoch: 5| Step: 2
Training loss: 3.1694959917333496
Validation loss: 3.068705733921301

Epoch: 5| Step: 3
Training loss: 3.1978023313943886
Validation loss: 3.064493104592374

Epoch: 5| Step: 4
Training loss: 3.3762936408715474
Validation loss: 3.0646852352717797

Epoch: 5| Step: 5
Training loss: 2.9337805067572136
Validation loss: 3.06973847640028

Epoch: 5| Step: 6
Training loss: 3.166204033904632
Validation loss: 3.066588830851792

Epoch: 5| Step: 7
Training loss: 4.011001002689865
Validation loss: 3.0627663190815024

Epoch: 5| Step: 8
Training loss: 3.1744105535304854
Validation loss: 3.061298499649743

Epoch: 5| Step: 9
Training loss: 3.12134307514785
Validation loss: 3.0635334286177303

Epoch: 5| Step: 10
Training loss: 3.62630307684382
Validation loss: 3.0613727675708766

Epoch: 115| Step: 0
Training loss: 3.359997500918231
Validation loss: 3.060314166871326

Epoch: 5| Step: 1
Training loss: 2.794941836111896
Validation loss: 3.060058055479505

Epoch: 5| Step: 2
Training loss: 3.428872535176511
Validation loss: 3.0586670778082956

Epoch: 5| Step: 3
Training loss: 3.120038939257475
Validation loss: 3.0629517316459047

Epoch: 5| Step: 4
Training loss: 3.5496793575279115
Validation loss: 3.062372341010808

Epoch: 5| Step: 5
Training loss: 3.030744372798054
Validation loss: 3.061479988358328

Epoch: 5| Step: 6
Training loss: 2.485507059385396
Validation loss: 3.068531951131545

Epoch: 5| Step: 7
Training loss: 3.510284300590435
Validation loss: 3.074238463714357

Epoch: 5| Step: 8
Training loss: 3.8425890402073164
Validation loss: 3.063436720274389

Epoch: 5| Step: 9
Training loss: 3.7123463094732907
Validation loss: 3.0612821830091854

Epoch: 5| Step: 10
Training loss: 3.5586658390921295
Validation loss: 3.0569864717391804

Epoch: 116| Step: 0
Training loss: 3.3193820502368463
Validation loss: 3.058347209798238

Epoch: 5| Step: 1
Training loss: 3.661879289647025
Validation loss: 3.058233846118282

Epoch: 5| Step: 2
Training loss: 3.4987649100784255
Validation loss: 3.0588381298004466

Epoch: 5| Step: 3
Training loss: 2.840541832506904
Validation loss: 3.060261949756895

Epoch: 5| Step: 4
Training loss: 4.082997885698588
Validation loss: 3.0598910354161224

Epoch: 5| Step: 5
Training loss: 2.995064331026107
Validation loss: 3.0598339323626114

Epoch: 5| Step: 6
Training loss: 3.661137501247331
Validation loss: 3.0610042575022485

Epoch: 5| Step: 7
Training loss: 3.080320553137775
Validation loss: 3.059796815979345

Epoch: 5| Step: 8
Training loss: 2.8726857034201925
Validation loss: 3.058137741421957

Epoch: 5| Step: 9
Training loss: 3.0707928230860664
Validation loss: 3.058525722859154

Epoch: 5| Step: 10
Training loss: 3.3096223243460225
Validation loss: 3.057553096172666

Epoch: 117| Step: 0
Training loss: 3.627107468023897
Validation loss: 3.057151611080709

Epoch: 5| Step: 1
Training loss: 2.942499654116809
Validation loss: 3.0575046478049144

Epoch: 5| Step: 2
Training loss: 3.4652729650212164
Validation loss: 3.05944471578449

Epoch: 5| Step: 3
Training loss: 2.6089483586175772
Validation loss: 3.057336225438412

Epoch: 5| Step: 4
Training loss: 3.5473701030668234
Validation loss: 3.061721730491993

Epoch: 5| Step: 5
Training loss: 2.3804779122667354
Validation loss: 3.0606126659955546

Epoch: 5| Step: 6
Training loss: 3.5912971418601405
Validation loss: 3.0635094216948646

Epoch: 5| Step: 7
Training loss: 3.5374114709566875
Validation loss: 3.0633981562555617

Epoch: 5| Step: 8
Training loss: 3.664986500006112
Validation loss: 3.059916744679997

Epoch: 5| Step: 9
Training loss: 3.791560091190678
Validation loss: 3.056519554550391

Epoch: 5| Step: 10
Training loss: 3.107704518984927
Validation loss: 3.054538624672052

Epoch: 118| Step: 0
Training loss: 2.9417784355334327
Validation loss: 3.054015754076222

Epoch: 5| Step: 1
Training loss: 3.5450171087414417
Validation loss: 3.051820832682636

Epoch: 5| Step: 2
Training loss: 3.955166979133082
Validation loss: 3.052292181038112

Epoch: 5| Step: 3
Training loss: 3.7885054660620243
Validation loss: 3.0545341017403396

Epoch: 5| Step: 4
Training loss: 3.291006207098913
Validation loss: 3.053347472398005

Epoch: 5| Step: 5
Training loss: 3.2483395956679435
Validation loss: 3.0534148978887616

Epoch: 5| Step: 6
Training loss: 3.2106477555650574
Validation loss: 3.052908113181397

Epoch: 5| Step: 7
Training loss: 4.02757225535368
Validation loss: 3.052741083195467

Epoch: 5| Step: 8
Training loss: 2.915420175044775
Validation loss: 3.052767289357113

Epoch: 5| Step: 9
Training loss: 2.667213969889843
Validation loss: 3.0522571029733707

Epoch: 5| Step: 10
Training loss: 2.4880975628518445
Validation loss: 3.0522743094511524

Epoch: 119| Step: 0
Training loss: 2.759942979776472
Validation loss: 3.051542137876205

Epoch: 5| Step: 1
Training loss: 3.053210279353312
Validation loss: 3.0501494173864345

Epoch: 5| Step: 2
Training loss: 3.9731318996454146
Validation loss: 3.051725115752262

Epoch: 5| Step: 3
Training loss: 3.4659446850923095
Validation loss: 3.0510234499494473

Epoch: 5| Step: 4
Training loss: 3.5401290398047975
Validation loss: 3.05082085499053

Epoch: 5| Step: 5
Training loss: 3.329877365191084
Validation loss: 3.0499625238489525

Epoch: 5| Step: 6
Training loss: 2.6036037192639996
Validation loss: 3.0526649878129284

Epoch: 5| Step: 7
Training loss: 3.374424355476792
Validation loss: 3.049450794655901

Epoch: 5| Step: 8
Training loss: 3.79371165927071
Validation loss: 3.049250756165594

Epoch: 5| Step: 9
Training loss: 2.885516462195472
Validation loss: 3.0520370167977386

Epoch: 5| Step: 10
Training loss: 3.5185382894514503
Validation loss: 3.049933796296417

Epoch: 120| Step: 0
Training loss: 2.949804952606672
Validation loss: 3.0503971395379037

Epoch: 5| Step: 1
Training loss: 3.3868539116627563
Validation loss: 3.0488210684864057

Epoch: 5| Step: 2
Training loss: 3.505048652779246
Validation loss: 3.051981401419525

Epoch: 5| Step: 3
Training loss: 3.1888495187695725
Validation loss: 3.051756065187672

Epoch: 5| Step: 4
Training loss: 2.8843156570826958
Validation loss: 3.048961746655231

Epoch: 5| Step: 5
Training loss: 2.8404384237020124
Validation loss: 3.050481364436676

Epoch: 5| Step: 6
Training loss: 3.6324467956889253
Validation loss: 3.0523864792656608

Epoch: 5| Step: 7
Training loss: 3.4815388585345888
Validation loss: 3.0505336792165667

Epoch: 5| Step: 8
Training loss: 3.460337843084292
Validation loss: 3.045824455512133

Epoch: 5| Step: 9
Training loss: 3.8577904788285275
Validation loss: 3.0486490197117506

Epoch: 5| Step: 10
Training loss: 3.1232212344815733
Validation loss: 3.048216101759783

Epoch: 121| Step: 0
Training loss: 3.433359322557569
Validation loss: 3.0471512561188434

Epoch: 5| Step: 1
Training loss: 3.253057069096668
Validation loss: 3.0479442385218753

Epoch: 5| Step: 2
Training loss: 3.356322565128961
Validation loss: 3.047163361060508

Epoch: 5| Step: 3
Training loss: 3.49442965152792
Validation loss: 3.0449272743545626

Epoch: 5| Step: 4
Training loss: 3.214192246788671
Validation loss: 3.0443683251001588

Epoch: 5| Step: 5
Training loss: 2.9305516303720647
Validation loss: 3.0454105716805997

Epoch: 5| Step: 6
Training loss: 3.382589213906865
Validation loss: 3.043077367336603

Epoch: 5| Step: 7
Training loss: 2.9335223924514637
Validation loss: 3.0447087321867627

Epoch: 5| Step: 8
Training loss: 3.8279920905259712
Validation loss: 3.044086754142165

Epoch: 5| Step: 9
Training loss: 3.00612618871457
Validation loss: 3.0430127321985685

Epoch: 5| Step: 10
Training loss: 3.5683561678967526
Validation loss: 3.042124456011141

Epoch: 122| Step: 0
Training loss: 3.428548914971685
Validation loss: 3.043950315222223

Epoch: 5| Step: 1
Training loss: 3.1693058226176016
Validation loss: 3.0428293382533838

Epoch: 5| Step: 2
Training loss: 3.219353924732102
Validation loss: 3.0421175524908484

Epoch: 5| Step: 3
Training loss: 3.473105780188098
Validation loss: 3.041206145194783

Epoch: 5| Step: 4
Training loss: 3.8610398875253185
Validation loss: 3.0430291585939195

Epoch: 5| Step: 5
Training loss: 3.545313823459289
Validation loss: 3.0435371089819183

Epoch: 5| Step: 6
Training loss: 3.5789891161565293
Validation loss: 3.041919683962088

Epoch: 5| Step: 7
Training loss: 3.0739708767803813
Validation loss: 3.042219763777474

Epoch: 5| Step: 8
Training loss: 2.7881443425088857
Validation loss: 3.0417867297723395

Epoch: 5| Step: 9
Training loss: 3.235768778043471
Validation loss: 3.040386559901312

Epoch: 5| Step: 10
Training loss: 2.838305448916677
Validation loss: 3.0415517307962534

Epoch: 123| Step: 0
Training loss: 2.69628773612902
Validation loss: 3.0405889538418087

Epoch: 5| Step: 1
Training loss: 3.6365578653742516
Validation loss: 3.0431799103120962

Epoch: 5| Step: 2
Training loss: 3.402334359963004
Validation loss: 3.0426954818348415

Epoch: 5| Step: 3
Training loss: 3.294111349997392
Validation loss: 3.041996572328031

Epoch: 5| Step: 4
Training loss: 4.001886399821974
Validation loss: 3.043796233500092

Epoch: 5| Step: 5
Training loss: 3.43505383933795
Validation loss: 3.041716653736476

Epoch: 5| Step: 6
Training loss: 3.5180853478519403
Validation loss: 3.0382958188037508

Epoch: 5| Step: 7
Training loss: 2.3256761613655383
Validation loss: 3.039987945082078

Epoch: 5| Step: 8
Training loss: 3.7112749127033333
Validation loss: 3.039171952013529

Epoch: 5| Step: 9
Training loss: 3.436930661303115
Validation loss: 3.0428492502753213

Epoch: 5| Step: 10
Training loss: 2.4282148504141325
Validation loss: 3.037568569114141

Epoch: 124| Step: 0
Training loss: 3.3409564746806337
Validation loss: 3.037575234844004

Epoch: 5| Step: 1
Training loss: 3.2001661078733017
Validation loss: 3.040301716374058

Epoch: 5| Step: 2
Training loss: 2.841427535868081
Validation loss: 3.0392753099932266

Epoch: 5| Step: 3
Training loss: 2.9370837626892317
Validation loss: 3.039695248087011

Epoch: 5| Step: 4
Training loss: 3.3062036521850375
Validation loss: 3.0379434536080367

Epoch: 5| Step: 5
Training loss: 3.822600695504372
Validation loss: 3.0388541834167015

Epoch: 5| Step: 6
Training loss: 3.1301020362480547
Validation loss: 3.0380697037754354

Epoch: 5| Step: 7
Training loss: 3.457703467924155
Validation loss: 3.0365984945953497

Epoch: 5| Step: 8
Training loss: 3.3590794632902394
Validation loss: 3.039979500202215

Epoch: 5| Step: 9
Training loss: 3.5525408288916798
Validation loss: 3.0386918596880466

Epoch: 5| Step: 10
Training loss: 3.401304522059474
Validation loss: 3.0384424550701037

Epoch: 125| Step: 0
Training loss: 3.592395693141427
Validation loss: 3.0359096819075013

Epoch: 5| Step: 1
Training loss: 3.5940062058384066
Validation loss: 3.0362008246146988

Epoch: 5| Step: 2
Training loss: 2.8349964272343695
Validation loss: 3.0375261023830586

Epoch: 5| Step: 3
Training loss: 2.9125805888671144
Validation loss: 3.0367640132458

Epoch: 5| Step: 4
Training loss: 3.6646103439217548
Validation loss: 3.037464222962547

Epoch: 5| Step: 5
Training loss: 3.4060951687681973
Validation loss: 3.03367957670355

Epoch: 5| Step: 6
Training loss: 2.3963265837289853
Validation loss: 3.0413013856435924

Epoch: 5| Step: 7
Training loss: 3.506529983520687
Validation loss: 3.0402398361068443

Epoch: 5| Step: 8
Training loss: 3.596502427625215
Validation loss: 3.0419512514586056

Epoch: 5| Step: 9
Training loss: 2.9708604238023106
Validation loss: 3.0414246667824347

Epoch: 5| Step: 10
Training loss: 3.712087994971249
Validation loss: 3.0399527688909873

Testing loss: 3.238546583765583
