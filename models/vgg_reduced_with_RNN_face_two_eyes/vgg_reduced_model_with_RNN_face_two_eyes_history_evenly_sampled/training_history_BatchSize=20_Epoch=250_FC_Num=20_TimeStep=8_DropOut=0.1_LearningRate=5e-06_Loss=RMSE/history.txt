Epoch: 1| Step: 0
Training loss: 5.700527487992442
Validation loss: 5.768570795796405

Epoch: 5| Step: 1
Training loss: 5.670647438397618
Validation loss: 5.762693464516664

Epoch: 5| Step: 2
Training loss: 6.043553586054298
Validation loss: 5.756775190925326

Epoch: 5| Step: 3
Training loss: 5.543956923896816
Validation loss: 5.750409515193639

Epoch: 5| Step: 4
Training loss: 6.064090480803778
Validation loss: 5.744122194345104

Epoch: 5| Step: 5
Training loss: 6.031203511903901
Validation loss: 5.7382781030142045

Epoch: 5| Step: 6
Training loss: 6.52264976999169
Validation loss: 5.731226705952304

Epoch: 5| Step: 7
Training loss: 5.958744950737484
Validation loss: 5.7253314503946635

Epoch: 5| Step: 8
Training loss: 5.796922051169395
Validation loss: 5.718316873911738

Epoch: 5| Step: 9
Training loss: 4.530925449718656
Validation loss: 5.711375439161731

Epoch: 5| Step: 10
Training loss: 5.379522860331944
Validation loss: 5.704248058566832

Epoch: 2| Step: 0
Training loss: 6.5365949598727315
Validation loss: 5.696995232578159

Epoch: 5| Step: 1
Training loss: 5.601859921442857
Validation loss: 5.689765706964904

Epoch: 5| Step: 2
Training loss: 5.6410762363334515
Validation loss: 5.682118506406293

Epoch: 5| Step: 3
Training loss: 5.999996185301522
Validation loss: 5.673897580827309

Epoch: 5| Step: 4
Training loss: 5.588454654391886
Validation loss: 5.664935368093356

Epoch: 5| Step: 5
Training loss: 5.550332294860734
Validation loss: 5.657281216303511

Epoch: 5| Step: 6
Training loss: 5.650265051102035
Validation loss: 5.647847988304979

Epoch: 5| Step: 7
Training loss: 6.010313706422434
Validation loss: 5.638831350564838

Epoch: 5| Step: 8
Training loss: 4.581642023776324
Validation loss: 5.629476518368303

Epoch: 5| Step: 9
Training loss: 5.492978903129395
Validation loss: 5.619176258554432

Epoch: 5| Step: 10
Training loss: 5.80754255314516
Validation loss: 5.608634783577182

Epoch: 3| Step: 0
Training loss: 5.30909907368879
Validation loss: 5.597267709817944

Epoch: 5| Step: 1
Training loss: 5.570338865755449
Validation loss: 5.586998582083826

Epoch: 5| Step: 2
Training loss: 5.557259995412866
Validation loss: 5.574741875262608

Epoch: 5| Step: 3
Training loss: 6.7179919857648525
Validation loss: 5.5620394851733135

Epoch: 5| Step: 4
Training loss: 4.366366996868538
Validation loss: 5.550403039265042

Epoch: 5| Step: 5
Training loss: 6.031336650324767
Validation loss: 5.53623022301934

Epoch: 5| Step: 6
Training loss: 5.990677584883482
Validation loss: 5.521996139255287

Epoch: 5| Step: 7
Training loss: 5.038186356426781
Validation loss: 5.508054149792513

Epoch: 5| Step: 8
Training loss: 5.206454474748803
Validation loss: 5.493344449883154

Epoch: 5| Step: 9
Training loss: 5.837980798693004
Validation loss: 5.477557619771405

Epoch: 5| Step: 10
Training loss: 5.305452586578972
Validation loss: 5.461714808003334

Epoch: 4| Step: 0
Training loss: 5.59134166169076
Validation loss: 5.445042033183025

Epoch: 5| Step: 1
Training loss: 6.096826021514891
Validation loss: 5.4280696323247986

Epoch: 5| Step: 2
Training loss: 5.233932430858838
Validation loss: 5.410922210326745

Epoch: 5| Step: 3
Training loss: 4.053431086574483
Validation loss: 5.3927504287294346

Epoch: 5| Step: 4
Training loss: 5.335858859687709
Validation loss: 5.3759706903226085

Epoch: 5| Step: 5
Training loss: 4.8677474628978885
Validation loss: 5.355463063090349

Epoch: 5| Step: 6
Training loss: 5.706021845623654
Validation loss: 5.339398545578702

Epoch: 5| Step: 7
Training loss: 5.479163669058363
Validation loss: 5.318308984646853

Epoch: 5| Step: 8
Training loss: 6.1674380807973055
Validation loss: 5.300337247204963

Epoch: 5| Step: 9
Training loss: 5.149582870034384
Validation loss: 5.280359886240389

Epoch: 5| Step: 10
Training loss: 5.407709531071036
Validation loss: 5.259587985956491

Epoch: 5| Step: 0
Training loss: 5.483232428058054
Validation loss: 5.240042885895488

Epoch: 5| Step: 1
Training loss: 5.195318741185161
Validation loss: 5.2191497686952175

Epoch: 5| Step: 2
Training loss: 5.308790280463465
Validation loss: 5.196757163980437

Epoch: 5| Step: 3
Training loss: 4.241140443627544
Validation loss: 5.175413772870941

Epoch: 5| Step: 4
Training loss: 4.571076575419582
Validation loss: 5.1559930970450685

Epoch: 5| Step: 5
Training loss: 5.161805460394833
Validation loss: 5.135163518750791

Epoch: 5| Step: 6
Training loss: 5.665134260130357
Validation loss: 5.114345050344766

Epoch: 5| Step: 7
Training loss: 4.910756368085211
Validation loss: 5.094027255693887

Epoch: 5| Step: 8
Training loss: 4.640711517041263
Validation loss: 5.072308836476362

Epoch: 5| Step: 9
Training loss: 5.468165077536115
Validation loss: 5.052391823104673

Epoch: 5| Step: 10
Training loss: 6.294817945833811
Validation loss: 5.032224686724643

Epoch: 6| Step: 0
Training loss: 5.6818705774839104
Validation loss: 5.010102208334722

Epoch: 5| Step: 1
Training loss: 5.646505318190147
Validation loss: 4.989472481779462

Epoch: 5| Step: 2
Training loss: 4.437237369126279
Validation loss: 4.969183245279388

Epoch: 5| Step: 3
Training loss: 4.029933980774908
Validation loss: 4.948251798082063

Epoch: 5| Step: 4
Training loss: 5.210669926718164
Validation loss: 4.928503372688774

Epoch: 5| Step: 5
Training loss: 4.64358272122847
Validation loss: 4.909186562960081

Epoch: 5| Step: 6
Training loss: 4.679718883581118
Validation loss: 4.886169515520601

Epoch: 5| Step: 7
Training loss: 4.784984252329776
Validation loss: 4.866875330966014

Epoch: 5| Step: 8
Training loss: 4.309094839968569
Validation loss: 4.843479653077155

Epoch: 5| Step: 9
Training loss: 5.854659886698459
Validation loss: 4.822631913997491

Epoch: 5| Step: 10
Training loss: 5.128426871518562
Validation loss: 4.8025655499227184

Epoch: 7| Step: 0
Training loss: 4.868139476962742
Validation loss: 4.784714794241974

Epoch: 5| Step: 1
Training loss: 5.050041598913501
Validation loss: 4.766646347731167

Epoch: 5| Step: 2
Training loss: 4.894166876525892
Validation loss: 4.752429295614118

Epoch: 5| Step: 3
Training loss: 5.32705042230522
Validation loss: 4.735821164393652

Epoch: 5| Step: 4
Training loss: 5.072595584846797
Validation loss: 4.721451545929515

Epoch: 5| Step: 5
Training loss: 4.161244768464274
Validation loss: 4.706392199333097

Epoch: 5| Step: 6
Training loss: 4.839468164780085
Validation loss: 4.692352382306041

Epoch: 5| Step: 7
Training loss: 4.352141035375218
Validation loss: 4.674681298039531

Epoch: 5| Step: 8
Training loss: 4.829695856536971
Validation loss: 4.663702569861204

Epoch: 5| Step: 9
Training loss: 4.101150928011084
Validation loss: 4.647925826593664

Epoch: 5| Step: 10
Training loss: 5.144517161379722
Validation loss: 4.630984796765171

Epoch: 8| Step: 0
Training loss: 3.454708513034664
Validation loss: 4.617571473710886

Epoch: 5| Step: 1
Training loss: 5.277657455054337
Validation loss: 4.604685842322351

Epoch: 5| Step: 2
Training loss: 4.335695552089671
Validation loss: 4.5910393393212745

Epoch: 5| Step: 3
Training loss: 5.057805463133717
Validation loss: 4.580125693469018

Epoch: 5| Step: 4
Training loss: 4.939652372167633
Validation loss: 4.568600444136712

Epoch: 5| Step: 5
Training loss: 4.393777930223838
Validation loss: 4.556888090719395

Epoch: 5| Step: 6
Training loss: 4.93212018089176
Validation loss: 4.54545984128045

Epoch: 5| Step: 7
Training loss: 5.373717753918538
Validation loss: 4.534460565557961

Epoch: 5| Step: 8
Training loss: 4.882170465602384
Validation loss: 4.524484013932393

Epoch: 5| Step: 9
Training loss: 3.897224313945818
Validation loss: 4.510603602189149

Epoch: 5| Step: 10
Training loss: 4.199148346066782
Validation loss: 4.500274228270983

Epoch: 9| Step: 0
Training loss: 4.71578421453491
Validation loss: 4.493382201192087

Epoch: 5| Step: 1
Training loss: 4.983631808082852
Validation loss: 4.478746221698055

Epoch: 5| Step: 2
Training loss: 5.1430578533243825
Validation loss: 4.4686351187387725

Epoch: 5| Step: 3
Training loss: 4.581384741660871
Validation loss: 4.4587895195729015

Epoch: 5| Step: 4
Training loss: 4.935982193220716
Validation loss: 4.445853702649852

Epoch: 5| Step: 5
Training loss: 4.238019550172179
Validation loss: 4.43545121427952

Epoch: 5| Step: 6
Training loss: 4.479696884118833
Validation loss: 4.424324776590719

Epoch: 5| Step: 7
Training loss: 4.771241927106352
Validation loss: 4.414344986916685

Epoch: 5| Step: 8
Training loss: 3.513010095231612
Validation loss: 4.400769809695877

Epoch: 5| Step: 9
Training loss: 4.443363452951425
Validation loss: 4.390639933537114

Epoch: 5| Step: 10
Training loss: 3.8496705645029152
Validation loss: 4.377568681856676

Epoch: 10| Step: 0
Training loss: 5.1749138792676455
Validation loss: 4.369011254054029

Epoch: 5| Step: 1
Training loss: 4.525480188002908
Validation loss: 4.357748819114599

Epoch: 5| Step: 2
Training loss: 4.356958957159239
Validation loss: 4.346291955716603

Epoch: 5| Step: 3
Training loss: 4.1706602921286775
Validation loss: 4.335067640188629

Epoch: 5| Step: 4
Training loss: 4.3411895011379125
Validation loss: 4.326770601800043

Epoch: 5| Step: 5
Training loss: 4.663548222340445
Validation loss: 4.319185555429692

Epoch: 5| Step: 6
Training loss: 3.2673650604847575
Validation loss: 4.307241440592875

Epoch: 5| Step: 7
Training loss: 4.727071939552443
Validation loss: 4.2989744091337405

Epoch: 5| Step: 8
Training loss: 4.886642052942784
Validation loss: 4.291214906112723

Epoch: 5| Step: 9
Training loss: 3.81033476332539
Validation loss: 4.282042304668326

Epoch: 5| Step: 10
Training loss: 4.646451945951357
Validation loss: 4.273870026132713

Epoch: 11| Step: 0
Training loss: 4.32544435191955
Validation loss: 4.262455517556574

Epoch: 5| Step: 1
Training loss: 4.214290267904929
Validation loss: 4.252987103244014

Epoch: 5| Step: 2
Training loss: 4.854568704920244
Validation loss: 4.247187050891696

Epoch: 5| Step: 3
Training loss: 4.175868491108083
Validation loss: 4.238411066804156

Epoch: 5| Step: 4
Training loss: 4.00720662376388
Validation loss: 4.230725477824086

Epoch: 5| Step: 5
Training loss: 4.370873385167994
Validation loss: 4.223054020715363

Epoch: 5| Step: 6
Training loss: 3.894982161670819
Validation loss: 4.213687987226856

Epoch: 5| Step: 7
Training loss: 4.174982749309421
Validation loss: 4.204473610093578

Epoch: 5| Step: 8
Training loss: 4.7731905559589904
Validation loss: 4.198277173717562

Epoch: 5| Step: 9
Training loss: 4.6126775774590785
Validation loss: 4.188749621262113

Epoch: 5| Step: 10
Training loss: 4.350997258018238
Validation loss: 4.1798815346669835

Epoch: 12| Step: 0
Training loss: 4.592193962785729
Validation loss: 4.173707598934177

Epoch: 5| Step: 1
Training loss: 3.519387905914863
Validation loss: 4.16466562930484

Epoch: 5| Step: 2
Training loss: 4.536102853271625
Validation loss: 4.154759374977766

Epoch: 5| Step: 3
Training loss: 3.9169693011516635
Validation loss: 4.145128008427674

Epoch: 5| Step: 4
Training loss: 4.807892414330154
Validation loss: 4.136961042936993

Epoch: 5| Step: 5
Training loss: 4.115372491156395
Validation loss: 4.12970491303147

Epoch: 5| Step: 6
Training loss: 4.192365410406755
Validation loss: 4.118278877294442

Epoch: 5| Step: 7
Training loss: 3.4511289048771583
Validation loss: 4.109384173105358

Epoch: 5| Step: 8
Training loss: 4.838088535515884
Validation loss: 4.102256530702806

Epoch: 5| Step: 9
Training loss: 4.576183128587315
Validation loss: 4.0934779754615604

Epoch: 5| Step: 10
Training loss: 4.0725297801016085
Validation loss: 4.087079804155521

Epoch: 13| Step: 0
Training loss: 4.179368051460688
Validation loss: 4.0790318745981935

Epoch: 5| Step: 1
Training loss: 3.952801114410571
Validation loss: 4.06805387362303

Epoch: 5| Step: 2
Training loss: 4.826201318012678
Validation loss: 4.063121760064483

Epoch: 5| Step: 3
Training loss: 4.852443449230348
Validation loss: 4.049740001628201

Epoch: 5| Step: 4
Training loss: 3.866260887646199
Validation loss: 4.043353043650797

Epoch: 5| Step: 5
Training loss: 3.1848209566727625
Validation loss: 4.038276007888032

Epoch: 5| Step: 6
Training loss: 4.770936701069847
Validation loss: 4.026678382997337

Epoch: 5| Step: 7
Training loss: 4.067019252396678
Validation loss: 4.019999094553657

Epoch: 5| Step: 8
Training loss: 3.244794197550971
Validation loss: 4.00997627992887

Epoch: 5| Step: 9
Training loss: 3.8791538247873474
Validation loss: 4.004160399175575

Epoch: 5| Step: 10
Training loss: 4.810950884501518
Validation loss: 3.9956583050798944

Epoch: 14| Step: 0
Training loss: 3.7683760221803047
Validation loss: 3.985122710236831

Epoch: 5| Step: 1
Training loss: 3.565731390018626
Validation loss: 3.97972988340559

Epoch: 5| Step: 2
Training loss: 4.678154339185512
Validation loss: 3.971584048127812

Epoch: 5| Step: 3
Training loss: 4.942825728678084
Validation loss: 3.96172423831087

Epoch: 5| Step: 4
Training loss: 3.7191161929076184
Validation loss: 3.9548072022713288

Epoch: 5| Step: 5
Training loss: 5.273129331273408
Validation loss: 3.9431907924424774

Epoch: 5| Step: 6
Training loss: 3.0456484159668924
Validation loss: 3.9342422277502926

Epoch: 5| Step: 7
Training loss: 4.212634139373121
Validation loss: 3.925028165955648

Epoch: 5| Step: 8
Training loss: 3.5107367546028896
Validation loss: 3.915153299187256

Epoch: 5| Step: 9
Training loss: 4.06521562630802
Validation loss: 3.907678649197337

Epoch: 5| Step: 10
Training loss: 3.659794971789358
Validation loss: 3.9004518407559328

Epoch: 15| Step: 0
Training loss: 3.7845928453891964
Validation loss: 3.8912354802597187

Epoch: 5| Step: 1
Training loss: 4.562777994126127
Validation loss: 3.8816553177762736

Epoch: 5| Step: 2
Training loss: 2.944230343774024
Validation loss: 3.872275573349125

Epoch: 5| Step: 3
Training loss: 5.026641251240908
Validation loss: 3.86777172546004

Epoch: 5| Step: 4
Training loss: 3.6244257768105674
Validation loss: 3.856042841077075

Epoch: 5| Step: 5
Training loss: 4.123122741781868
Validation loss: 3.846434678678271

Epoch: 5| Step: 6
Training loss: 3.8767145117061994
Validation loss: 3.841293497085534

Epoch: 5| Step: 7
Training loss: 3.979875245175794
Validation loss: 3.8374528743106575

Epoch: 5| Step: 8
Training loss: 4.049566956904423
Validation loss: 3.8298738035671755

Epoch: 5| Step: 9
Training loss: 4.008996145496337
Validation loss: 3.8236704796202057

Epoch: 5| Step: 10
Training loss: 3.841634152509965
Validation loss: 3.8178804968693165

Epoch: 16| Step: 0
Training loss: 4.19161147782161
Validation loss: 3.811350726722842

Epoch: 5| Step: 1
Training loss: 2.924010123969841
Validation loss: 3.8030286574864984

Epoch: 5| Step: 2
Training loss: 4.466608561427297
Validation loss: 3.801297853621867

Epoch: 5| Step: 3
Training loss: 3.371539849991841
Validation loss: 3.797662790070411

Epoch: 5| Step: 4
Training loss: 4.388388936557025
Validation loss: 3.7912144441418443

Epoch: 5| Step: 5
Training loss: 3.614657940859542
Validation loss: 3.790448114790068

Epoch: 5| Step: 6
Training loss: 3.5939158525757815
Validation loss: 3.7787286889510443

Epoch: 5| Step: 7
Training loss: 3.925072570907403
Validation loss: 3.7760088170722765

Epoch: 5| Step: 8
Training loss: 3.7576462675193043
Validation loss: 3.7688721527910323

Epoch: 5| Step: 9
Training loss: 4.690564387347282
Validation loss: 3.7583279253960287

Epoch: 5| Step: 10
Training loss: 4.285897064852666
Validation loss: 3.755870877668636

Epoch: 17| Step: 0
Training loss: 3.899594305407312
Validation loss: 3.7486195994000546

Epoch: 5| Step: 1
Training loss: 3.780415971060011
Validation loss: 3.7450306004490725

Epoch: 5| Step: 2
Training loss: 4.379787985839419
Validation loss: 3.739121538498354

Epoch: 5| Step: 3
Training loss: 3.914312358502985
Validation loss: 3.7333425223073364

Epoch: 5| Step: 4
Training loss: 3.704211626899234
Validation loss: 3.729698743114638

Epoch: 5| Step: 5
Training loss: 3.6340832528386042
Validation loss: 3.727489066366079

Epoch: 5| Step: 6
Training loss: 3.7167454293519873
Validation loss: 3.7188840921019772

Epoch: 5| Step: 7
Training loss: 2.8381273626415546
Validation loss: 3.7149880762283853

Epoch: 5| Step: 8
Training loss: 5.1436072513986355
Validation loss: 3.711163880675888

Epoch: 5| Step: 9
Training loss: 3.923526856784677
Validation loss: 3.7088695293790535

Epoch: 5| Step: 10
Training loss: 3.59607389197211
Validation loss: 3.705400691105585

Epoch: 18| Step: 0
Training loss: 3.815429187595949
Validation loss: 3.699589018763153

Epoch: 5| Step: 1
Training loss: 3.338838910197602
Validation loss: 3.69610823151037

Epoch: 5| Step: 2
Training loss: 3.8185243380686162
Validation loss: 3.6887025146394743

Epoch: 5| Step: 3
Training loss: 4.716526341232397
Validation loss: 3.690086030823971

Epoch: 5| Step: 4
Training loss: 3.134131251524452
Validation loss: 3.682367805498727

Epoch: 5| Step: 5
Training loss: 3.979539757192677
Validation loss: 3.6785685791388714

Epoch: 5| Step: 6
Training loss: 3.7337270517732755
Validation loss: 3.672127082879752

Epoch: 5| Step: 7
Training loss: 3.4166631155848464
Validation loss: 3.672310937728439

Epoch: 5| Step: 8
Training loss: 4.039546738305196
Validation loss: 3.6640769873724333

Epoch: 5| Step: 9
Training loss: 4.766290536903697
Validation loss: 3.6588631697673764

Epoch: 5| Step: 10
Training loss: 3.275734179954871
Validation loss: 3.6586871890919115

Epoch: 19| Step: 0
Training loss: 4.650366016052065
Validation loss: 3.654703722525861

Epoch: 5| Step: 1
Training loss: 4.180966418675448
Validation loss: 3.6492695833745787

Epoch: 5| Step: 2
Training loss: 3.1797936724058475
Validation loss: 3.6447086203799417

Epoch: 5| Step: 3
Training loss: 4.307262612751858
Validation loss: 3.6370299079194015

Epoch: 5| Step: 4
Training loss: 3.2527379460714303
Validation loss: 3.637686792146062

Epoch: 5| Step: 5
Training loss: 3.328101789366687
Validation loss: 3.6329081790571167

Epoch: 5| Step: 6
Training loss: 3.418314435644067
Validation loss: 3.6280389564413316

Epoch: 5| Step: 7
Training loss: 3.5931366770288005
Validation loss: 3.6293313822187883

Epoch: 5| Step: 8
Training loss: 3.5066810601329452
Validation loss: 3.621718365759827

Epoch: 5| Step: 9
Training loss: 3.3674113825385943
Validation loss: 3.6176668271802335

Epoch: 5| Step: 10
Training loss: 4.994269138513189
Validation loss: 3.616389511155046

Epoch: 20| Step: 0
Training loss: 3.0599636551936293
Validation loss: 3.613113326161884

Epoch: 5| Step: 1
Training loss: 2.8327186329055785
Validation loss: 3.609740240692282

Epoch: 5| Step: 2
Training loss: 4.3142024563611585
Validation loss: 3.611974999896148

Epoch: 5| Step: 3
Training loss: 3.555890560924846
Validation loss: 3.6047181219654747

Epoch: 5| Step: 4
Training loss: 3.285628676039635
Validation loss: 3.601528416787022

Epoch: 5| Step: 5
Training loss: 3.7575408139426543
Validation loss: 3.600938373442933

Epoch: 5| Step: 6
Training loss: 3.9096229334334045
Validation loss: 3.599848990879368

Epoch: 5| Step: 7
Training loss: 3.838674900981114
Validation loss: 3.6001448338381983

Epoch: 5| Step: 8
Training loss: 3.3817887023394153
Validation loss: 3.595377656456115

Epoch: 5| Step: 9
Training loss: 4.712563204151749
Validation loss: 3.591603456720464

Epoch: 5| Step: 10
Training loss: 4.75101982010754
Validation loss: 3.5877626068339326

Epoch: 21| Step: 0
Training loss: 3.5754521810891795
Validation loss: 3.5802630277220295

Epoch: 5| Step: 1
Training loss: 4.342269755020548
Validation loss: 3.5772281677584745

Epoch: 5| Step: 2
Training loss: 4.047158956691415
Validation loss: 3.5762890507735823

Epoch: 5| Step: 3
Training loss: 3.0605342550693067
Validation loss: 3.575424035405641

Epoch: 5| Step: 4
Training loss: 3.6735807312204187
Validation loss: 3.566417351596839

Epoch: 5| Step: 5
Training loss: 3.4747013210677378
Validation loss: 3.5645763058237527

Epoch: 5| Step: 6
Training loss: 4.014927191163221
Validation loss: 3.563701586034484

Epoch: 5| Step: 7
Training loss: 3.3540071406052427
Validation loss: 3.557561471241516

Epoch: 5| Step: 8
Training loss: 4.358230714094355
Validation loss: 3.5580886762091404

Epoch: 5| Step: 9
Training loss: 4.028302911894237
Validation loss: 3.5578269958669155

Epoch: 5| Step: 10
Training loss: 3.1737354253289283
Validation loss: 3.552778327169999

Epoch: 22| Step: 0
Training loss: 4.110943049068613
Validation loss: 3.550220827706912

Epoch: 5| Step: 1
Training loss: 3.432292808953164
Validation loss: 3.548240045863968

Epoch: 5| Step: 2
Training loss: 3.56757087535533
Validation loss: 3.5483494423800908

Epoch: 5| Step: 3
Training loss: 3.9902040216203574
Validation loss: 3.545381690724215

Epoch: 5| Step: 4
Training loss: 4.20616680816865
Validation loss: 3.5407733859605433

Epoch: 5| Step: 5
Training loss: 3.891435531080235
Validation loss: 3.5390244710787297

Epoch: 5| Step: 6
Training loss: 4.013022444037977
Validation loss: 3.5373491080613726

Epoch: 5| Step: 7
Training loss: 3.121629499494887
Validation loss: 3.531471328993735

Epoch: 5| Step: 8
Training loss: 3.6064818044965303
Validation loss: 3.5313643599336357

Epoch: 5| Step: 9
Training loss: 3.5601341020850747
Validation loss: 3.5301341948260103

Epoch: 5| Step: 10
Training loss: 3.5321042538265917
Validation loss: 3.529032453872289

Epoch: 23| Step: 0
Training loss: 4.009430021650302
Validation loss: 3.5271964264484095

Epoch: 5| Step: 1
Training loss: 3.866919182610848
Validation loss: 3.525295660995156

Epoch: 5| Step: 2
Training loss: 3.5311128032667733
Validation loss: 3.5229636660587276

Epoch: 5| Step: 3
Training loss: 4.318979233483613
Validation loss: 3.520800215673442

Epoch: 5| Step: 4
Training loss: 3.2508975036853704
Validation loss: 3.5171642919687756

Epoch: 5| Step: 5
Training loss: 3.642073445475636
Validation loss: 3.516087126079962

Epoch: 5| Step: 6
Training loss: 3.1707548221153545
Validation loss: 3.5151566636252607

Epoch: 5| Step: 7
Training loss: 2.902024016603642
Validation loss: 3.508644149941117

Epoch: 5| Step: 8
Training loss: 3.7543627474289463
Validation loss: 3.508764938343209

Epoch: 5| Step: 9
Training loss: 4.539532267805706
Validation loss: 3.505311251183226

Epoch: 5| Step: 10
Training loss: 3.64136206242633
Validation loss: 3.505068017635113

Epoch: 24| Step: 0
Training loss: 3.9822968692065372
Validation loss: 3.5022215084964414

Epoch: 5| Step: 1
Training loss: 4.05646594961257
Validation loss: 3.4990160536118817

Epoch: 5| Step: 2
Training loss: 2.691712825682488
Validation loss: 3.49540304626422

Epoch: 5| Step: 3
Training loss: 3.8391508794787983
Validation loss: 3.4968496448084743

Epoch: 5| Step: 4
Training loss: 3.5045822665180753
Validation loss: 3.494425061895863

Epoch: 5| Step: 5
Training loss: 3.373680845939098
Validation loss: 3.492367855249873

Epoch: 5| Step: 6
Training loss: 3.5691994031683962
Validation loss: 3.491122287938758

Epoch: 5| Step: 7
Training loss: 4.001178806175657
Validation loss: 3.4911244946038473

Epoch: 5| Step: 8
Training loss: 4.405254711533299
Validation loss: 3.4868524823639917

Epoch: 5| Step: 9
Training loss: 3.8076571364360454
Validation loss: 3.4864442275562726

Epoch: 5| Step: 10
Training loss: 3.118327838098389
Validation loss: 3.4837319356264684

Epoch: 25| Step: 0
Training loss: 3.099709983303409
Validation loss: 3.483087390880701

Epoch: 5| Step: 1
Training loss: 3.48607918841643
Validation loss: 3.482882918507254

Epoch: 5| Step: 2
Training loss: 3.4559727314385422
Validation loss: 3.4867013009710175

Epoch: 5| Step: 3
Training loss: 3.957640108675543
Validation loss: 3.4840084798986175

Epoch: 5| Step: 4
Training loss: 3.6287460702420833
Validation loss: 3.4812724359237497

Epoch: 5| Step: 5
Training loss: 3.971299801647187
Validation loss: 3.481608939463767

Epoch: 5| Step: 6
Training loss: 3.475719564022957
Validation loss: 3.4773669442345367

Epoch: 5| Step: 7
Training loss: 3.6072508271068546
Validation loss: 3.473914307373148

Epoch: 5| Step: 8
Training loss: 3.7979807558300336
Validation loss: 3.474433409029756

Epoch: 5| Step: 9
Training loss: 3.8564439523848577
Validation loss: 3.469673018412386

Epoch: 5| Step: 10
Training loss: 4.2437649036982865
Validation loss: 3.469407873303771

Epoch: 26| Step: 0
Training loss: 4.071534191281754
Validation loss: 3.468629411639102

Epoch: 5| Step: 1
Training loss: 3.2077243441635765
Validation loss: 3.465804114679929

Epoch: 5| Step: 2
Training loss: 2.929000570508824
Validation loss: 3.4655681022711304

Epoch: 5| Step: 3
Training loss: 3.930720593537583
Validation loss: 3.467234065837881

Epoch: 5| Step: 4
Training loss: 3.6687910399342925
Validation loss: 3.4644651191170284

Epoch: 5| Step: 5
Training loss: 3.626295976159953
Validation loss: 3.4626789053165377

Epoch: 5| Step: 6
Training loss: 3.639750232301667
Validation loss: 3.4652569214829207

Epoch: 5| Step: 7
Training loss: 4.411849772063287
Validation loss: 3.4589979336475056

Epoch: 5| Step: 8
Training loss: 4.052897210584121
Validation loss: 3.4578875938771136

Epoch: 5| Step: 9
Training loss: 3.4308448871982904
Validation loss: 3.4582286086956575

Epoch: 5| Step: 10
Training loss: 3.1770824661670605
Validation loss: 3.4603646104064776

Epoch: 27| Step: 0
Training loss: 3.91590481646531
Validation loss: 3.4585068149299163

Epoch: 5| Step: 1
Training loss: 3.517529865889112
Validation loss: 3.4563552936239494

Epoch: 5| Step: 2
Training loss: 3.3109737694892862
Validation loss: 3.4537716988789295

Epoch: 5| Step: 3
Training loss: 3.8350883833785625
Validation loss: 3.4522690000415723

Epoch: 5| Step: 4
Training loss: 2.9864050865859646
Validation loss: 3.449453404686541

Epoch: 5| Step: 5
Training loss: 3.5106142405405683
Validation loss: 3.450099978871613

Epoch: 5| Step: 6
Training loss: 4.14109091386668
Validation loss: 3.449570577408631

Epoch: 5| Step: 7
Training loss: 3.9237389257687334
Validation loss: 3.448192974356037

Epoch: 5| Step: 8
Training loss: 3.5648564358731516
Validation loss: 3.4445152347112105

Epoch: 5| Step: 9
Training loss: 3.4676432175546736
Validation loss: 3.445801496596119

Epoch: 5| Step: 10
Training loss: 4.0797910831294315
Validation loss: 3.443570970739466

Epoch: 28| Step: 0
Training loss: 3.216959038395098
Validation loss: 3.4431648420239633

Epoch: 5| Step: 1
Training loss: 3.21031550487941
Validation loss: 3.441644242601541

Epoch: 5| Step: 2
Training loss: 3.748055780588039
Validation loss: 3.43750203748775

Epoch: 5| Step: 3
Training loss: 4.1963762181503474
Validation loss: 3.4367251942771584

Epoch: 5| Step: 4
Training loss: 3.5824022340178923
Validation loss: 3.4367469149117484

Epoch: 5| Step: 5
Training loss: 3.2387206144188663
Validation loss: 3.435539381547495

Epoch: 5| Step: 6
Training loss: 3.762840159301631
Validation loss: 3.4355514089710937

Epoch: 5| Step: 7
Training loss: 3.949621766729028
Validation loss: 3.441429837694389

Epoch: 5| Step: 8
Training loss: 3.9276449002659914
Validation loss: 3.4362114274517466

Epoch: 5| Step: 9
Training loss: 3.833245290215075
Validation loss: 3.4317422355765226

Epoch: 5| Step: 10
Training loss: 3.3748183024911285
Validation loss: 3.433348053557056

Epoch: 29| Step: 0
Training loss: 3.735593844266763
Validation loss: 3.432379668420318

Epoch: 5| Step: 1
Training loss: 3.7103091059235243
Validation loss: 3.4298291634587073

Epoch: 5| Step: 2
Training loss: 2.4875092319336383
Validation loss: 3.4292506582753126

Epoch: 5| Step: 3
Training loss: 3.8004504037257476
Validation loss: 3.4263594184124857

Epoch: 5| Step: 4
Training loss: 2.9382508312578923
Validation loss: 3.4265319628035367

Epoch: 5| Step: 5
Training loss: 4.3649064386746925
Validation loss: 3.4279369975777367

Epoch: 5| Step: 6
Training loss: 3.621638614026854
Validation loss: 3.4260277697002217

Epoch: 5| Step: 7
Training loss: 3.523908697792265
Validation loss: 3.423829647986465

Epoch: 5| Step: 8
Training loss: 4.061102054398564
Validation loss: 3.4242736347976432

Epoch: 5| Step: 9
Training loss: 3.4115657100328685
Validation loss: 3.4264999258617

Epoch: 5| Step: 10
Training loss: 4.191755722849205
Validation loss: 3.421452341326555

Epoch: 30| Step: 0
Training loss: 3.8095715641820553
Validation loss: 3.4211606085212023

Epoch: 5| Step: 1
Training loss: 3.487773520842549
Validation loss: 3.4217323576540193

Epoch: 5| Step: 2
Training loss: 3.8788899001653787
Validation loss: 3.4223798700693138

Epoch: 5| Step: 3
Training loss: 3.4309238299656797
Validation loss: 3.4191963971137747

Epoch: 5| Step: 4
Training loss: 3.10766539227901
Validation loss: 3.4184181147219554

Epoch: 5| Step: 5
Training loss: 4.08988129198684
Validation loss: 3.4188115237921597

Epoch: 5| Step: 6
Training loss: 3.8934314824060943
Validation loss: 3.4169279839453086

Epoch: 5| Step: 7
Training loss: 3.3843528288927813
Validation loss: 3.4167867940038303

Epoch: 5| Step: 8
Training loss: 3.649366240153617
Validation loss: 3.4172522605526674

Epoch: 5| Step: 9
Training loss: 3.5969173902835765
Validation loss: 3.4155538396424725

Epoch: 5| Step: 10
Training loss: 3.6343932947565927
Validation loss: 3.4158322485652577

Epoch: 31| Step: 0
Training loss: 3.3545292881409035
Validation loss: 3.41418386230361

Epoch: 5| Step: 1
Training loss: 3.556044635977446
Validation loss: 3.413639751191496

Epoch: 5| Step: 2
Training loss: 3.8999241992724425
Validation loss: 3.4141909866407727

Epoch: 5| Step: 3
Training loss: 4.167710186303924
Validation loss: 3.412374619359945

Epoch: 5| Step: 4
Training loss: 3.1504446593804576
Validation loss: 3.4118556408986938

Epoch: 5| Step: 5
Training loss: 3.199506995847875
Validation loss: 3.4144839200850834

Epoch: 5| Step: 6
Training loss: 3.6039920977760924
Validation loss: 3.412436922243067

Epoch: 5| Step: 7
Training loss: 3.537550175718719
Validation loss: 3.410321619546763

Epoch: 5| Step: 8
Training loss: 3.8156367671200875
Validation loss: 3.40927317408341

Epoch: 5| Step: 9
Training loss: 3.3890683868343006
Validation loss: 3.410171432638924

Epoch: 5| Step: 10
Training loss: 4.258661308025634
Validation loss: 3.4086592366027375

Epoch: 32| Step: 0
Training loss: 4.0605078874691545
Validation loss: 3.4080766903511153

Epoch: 5| Step: 1
Training loss: 3.8716472765047945
Validation loss: 3.40848771367511

Epoch: 5| Step: 2
Training loss: 3.764827279717618
Validation loss: 3.40575135167288

Epoch: 5| Step: 3
Training loss: 3.3729408481635073
Validation loss: 3.4062656666776503

Epoch: 5| Step: 4
Training loss: 4.204121184441724
Validation loss: 3.4042986793318666

Epoch: 5| Step: 5
Training loss: 4.30690723381109
Validation loss: 3.406227434619264

Epoch: 5| Step: 6
Training loss: 3.4895785355416336
Validation loss: 3.405728472857855

Epoch: 5| Step: 7
Training loss: 3.4939836836784917
Validation loss: 3.40250419190466

Epoch: 5| Step: 8
Training loss: 2.661677571104959
Validation loss: 3.4038339132902005

Epoch: 5| Step: 9
Training loss: 3.267061784424511
Validation loss: 3.4032201719779303

Epoch: 5| Step: 10
Training loss: 3.0443066849676415
Validation loss: 3.404218637166091

Epoch: 33| Step: 0
Training loss: 4.317574652737114
Validation loss: 3.4036763404809474

Epoch: 5| Step: 1
Training loss: 4.032350848207173
Validation loss: 3.3996664991170964

Epoch: 5| Step: 2
Training loss: 3.180442026954179
Validation loss: 3.4053759086048028

Epoch: 5| Step: 3
Training loss: 3.6106755279233185
Validation loss: 3.401551881860138

Epoch: 5| Step: 4
Training loss: 3.295293202531364
Validation loss: 3.404818261516996

Epoch: 5| Step: 5
Training loss: 3.439628081066261
Validation loss: 3.4082528734512154

Epoch: 5| Step: 6
Training loss: 3.427997841993474
Validation loss: 3.411852262639114

Epoch: 5| Step: 7
Training loss: 3.365060794048756
Validation loss: 3.3978579130557005

Epoch: 5| Step: 8
Training loss: 3.4636728056362935
Validation loss: 3.397781358894118

Epoch: 5| Step: 9
Training loss: 4.018989074145461
Validation loss: 3.3995051073260707

Epoch: 5| Step: 10
Training loss: 3.5926278394067577
Validation loss: 3.3970971990766903

Epoch: 34| Step: 0
Training loss: 4.147720878472631
Validation loss: 3.39736135924525

Epoch: 5| Step: 1
Training loss: 3.7335206654641997
Validation loss: 3.3981805542305703

Epoch: 5| Step: 2
Training loss: 2.8671963143278174
Validation loss: 3.398170508416754

Epoch: 5| Step: 3
Training loss: 3.954774776175432
Validation loss: 3.396649024445228

Epoch: 5| Step: 4
Training loss: 3.593554416807629
Validation loss: 3.3948706258724353

Epoch: 5| Step: 5
Training loss: 3.1100900105885043
Validation loss: 3.3952800109440546

Epoch: 5| Step: 6
Training loss: 3.8585357371246376
Validation loss: 3.3930562965614413

Epoch: 5| Step: 7
Training loss: 3.1991290218453345
Validation loss: 3.3941997920067766

Epoch: 5| Step: 8
Training loss: 3.476976280019587
Validation loss: 3.394597774247282

Epoch: 5| Step: 9
Training loss: 3.7599627079027442
Validation loss: 3.3930674137794354

Epoch: 5| Step: 10
Training loss: 4.010919924119069
Validation loss: 3.3901333986273454

Epoch: 35| Step: 0
Training loss: 3.3274620004686737
Validation loss: 3.389296047668062

Epoch: 5| Step: 1
Training loss: 3.1956451168281372
Validation loss: 3.387653601660798

Epoch: 5| Step: 2
Training loss: 3.2255955464112858
Validation loss: 3.3914597929056307

Epoch: 5| Step: 3
Training loss: 4.345120879182985
Validation loss: 3.388357288103674

Epoch: 5| Step: 4
Training loss: 4.146742422346143
Validation loss: 3.386512960248857

Epoch: 5| Step: 5
Training loss: 3.8728910059879937
Validation loss: 3.3853451270534567

Epoch: 5| Step: 6
Training loss: 3.3753174526537446
Validation loss: 3.3836529010463186

Epoch: 5| Step: 7
Training loss: 3.9758192165883455
Validation loss: 3.3821988583064932

Epoch: 5| Step: 8
Training loss: 3.483544220693117
Validation loss: 3.381647309786473

Epoch: 5| Step: 9
Training loss: 3.3448022630575753
Validation loss: 3.3790091003929184

Epoch: 5| Step: 10
Training loss: 3.184017448080361
Validation loss: 3.3784816304663767

Epoch: 36| Step: 0
Training loss: 3.525678847939238
Validation loss: 3.377925973253308

Epoch: 5| Step: 1
Training loss: 3.2705788159002718
Validation loss: 3.37633919134217

Epoch: 5| Step: 2
Training loss: 4.321910817735031
Validation loss: 3.375427733996021

Epoch: 5| Step: 3
Training loss: 3.3887205620601843
Validation loss: 3.3802498412723705

Epoch: 5| Step: 4
Training loss: 3.742885070642508
Validation loss: 3.3772135577393305

Epoch: 5| Step: 5
Training loss: 3.1437922207554867
Validation loss: 3.3764950074221054

Epoch: 5| Step: 6
Training loss: 3.81164778893359
Validation loss: 3.372447464114121

Epoch: 5| Step: 7
Training loss: 3.872180158829659
Validation loss: 3.373427104671277

Epoch: 5| Step: 8
Training loss: 3.7466246355036414
Validation loss: 3.3735386287348894

Epoch: 5| Step: 9
Training loss: 3.1713420251012567
Validation loss: 3.371760166529489

Epoch: 5| Step: 10
Training loss: 3.4815941905842727
Validation loss: 3.3705294308116973

Epoch: 37| Step: 0
Training loss: 3.8821446172474863
Validation loss: 3.3712101664342606

Epoch: 5| Step: 1
Training loss: 2.8209246449269
Validation loss: 3.368530558334096

Epoch: 5| Step: 2
Training loss: 4.23052691052472
Validation loss: 3.3683540084862007

Epoch: 5| Step: 3
Training loss: 2.928784528814495
Validation loss: 3.3664627203080513

Epoch: 5| Step: 4
Training loss: 3.9008202008213275
Validation loss: 3.3691166559894232

Epoch: 5| Step: 5
Training loss: 3.9804512600051223
Validation loss: 3.3666358802173217

Epoch: 5| Step: 6
Training loss: 3.1431001996518133
Validation loss: 3.3660854221227776

Epoch: 5| Step: 7
Training loss: 2.9830143408128493
Validation loss: 3.3656216617450028

Epoch: 5| Step: 8
Training loss: 3.8855425257748104
Validation loss: 3.36870143391996

Epoch: 5| Step: 9
Training loss: 4.2064932901611645
Validation loss: 3.367841447467081

Epoch: 5| Step: 10
Training loss: 3.1656557945869994
Validation loss: 3.3660271082701763

Epoch: 38| Step: 0
Training loss: 3.5912188033154053
Validation loss: 3.36581360968519

Epoch: 5| Step: 1
Training loss: 3.5112699533766754
Validation loss: 3.3649791237230273

Epoch: 5| Step: 2
Training loss: 3.113773474556955
Validation loss: 3.363910054636812

Epoch: 5| Step: 3
Training loss: 3.3671959967627716
Validation loss: 3.3671476882694926

Epoch: 5| Step: 4
Training loss: 3.8307381566519396
Validation loss: 3.3650950614738377

Epoch: 5| Step: 5
Training loss: 3.7933531702882783
Validation loss: 3.3627948132664107

Epoch: 5| Step: 6
Training loss: 3.98485822552254
Validation loss: 3.3631472509499742

Epoch: 5| Step: 7
Training loss: 3.3217951078667483
Validation loss: 3.3625387897442978

Epoch: 5| Step: 8
Training loss: 3.2622651698928906
Validation loss: 3.361601202310469

Epoch: 5| Step: 9
Training loss: 3.615537724476039
Validation loss: 3.3612100727366516

Epoch: 5| Step: 10
Training loss: 4.109336011578353
Validation loss: 3.3598936138020834

Epoch: 39| Step: 0
Training loss: 3.3450403308575334
Validation loss: 3.360927541066842

Epoch: 5| Step: 1
Training loss: 2.814458377152889
Validation loss: 3.3607803934474427

Epoch: 5| Step: 2
Training loss: 3.6404042975199684
Validation loss: 3.361729484803052

Epoch: 5| Step: 3
Training loss: 3.7407107694731025
Validation loss: 3.3579253960849087

Epoch: 5| Step: 4
Training loss: 3.3624724546530906
Validation loss: 3.357925402192586

Epoch: 5| Step: 5
Training loss: 3.684936408189083
Validation loss: 3.3570861375562133

Epoch: 5| Step: 6
Training loss: 3.7901922999490756
Validation loss: 3.357355087556999

Epoch: 5| Step: 7
Training loss: 4.502838299298986
Validation loss: 3.3583399855912384

Epoch: 5| Step: 8
Training loss: 3.5534663188256506
Validation loss: 3.3569606460450787

Epoch: 5| Step: 9
Training loss: 3.3582101621040468
Validation loss: 3.3583802956240314

Epoch: 5| Step: 10
Training loss: 3.482268102720006
Validation loss: 3.3576563741839194

Epoch: 40| Step: 0
Training loss: 3.545554163006813
Validation loss: 3.3577275198296386

Epoch: 5| Step: 1
Training loss: 2.9552423868961437
Validation loss: 3.3548933915879315

Epoch: 5| Step: 2
Training loss: 3.3764405178647396
Validation loss: 3.3567237245766615

Epoch: 5| Step: 3
Training loss: 3.6572465109185592
Validation loss: 3.355955173044572

Epoch: 5| Step: 4
Training loss: 2.987013683879045
Validation loss: 3.3549530039013793

Epoch: 5| Step: 5
Training loss: 3.6961578628052867
Validation loss: 3.3546163896563046

Epoch: 5| Step: 6
Training loss: 3.00926684604134
Validation loss: 3.355469738639961

Epoch: 5| Step: 7
Training loss: 4.308302896319565
Validation loss: 3.3540748217254994

Epoch: 5| Step: 8
Training loss: 4.154080850268961
Validation loss: 3.3570317835254926

Epoch: 5| Step: 9
Training loss: 3.7029214151168213
Validation loss: 3.3521073891837374

Epoch: 5| Step: 10
Training loss: 3.8438656177034716
Validation loss: 3.35307995335569

Epoch: 41| Step: 0
Training loss: 3.9930537230261685
Validation loss: 3.3525854709893252

Epoch: 5| Step: 1
Training loss: 4.099496782636816
Validation loss: 3.352833241229501

Epoch: 5| Step: 2
Training loss: 3.486754558566543
Validation loss: 3.354722760271759

Epoch: 5| Step: 3
Training loss: 3.4309236909835303
Validation loss: 3.35125320544513

Epoch: 5| Step: 4
Training loss: 3.6911946553939403
Validation loss: 3.3515979334615675

Epoch: 5| Step: 5
Training loss: 2.9642404135888207
Validation loss: 3.3511131347368055

Epoch: 5| Step: 6
Training loss: 2.7038719600519143
Validation loss: 3.350308325385247

Epoch: 5| Step: 7
Training loss: 4.468207906641393
Validation loss: 3.354507536482156

Epoch: 5| Step: 8
Training loss: 3.6220151517015045
Validation loss: 3.3512524113961186

Epoch: 5| Step: 9
Training loss: 2.8334080368366377
Validation loss: 3.3483492333503695

Epoch: 5| Step: 10
Training loss: 3.758801748403508
Validation loss: 3.34981340786484

Epoch: 42| Step: 0
Training loss: 3.2886340661893763
Validation loss: 3.351147813301113

Epoch: 5| Step: 1
Training loss: 2.7658310290820562
Validation loss: 3.3537279465152805

Epoch: 5| Step: 2
Training loss: 3.0463880883476846
Validation loss: 3.3568336254817988

Epoch: 5| Step: 3
Training loss: 4.2669753847093865
Validation loss: 3.3523477294733683

Epoch: 5| Step: 4
Training loss: 2.777494316472952
Validation loss: 3.352113608407613

Epoch: 5| Step: 5
Training loss: 3.6747256637214814
Validation loss: 3.348625421598879

Epoch: 5| Step: 6
Training loss: 3.9204149910159036
Validation loss: 3.3482640850936263

Epoch: 5| Step: 7
Training loss: 3.852273562025377
Validation loss: 3.3478640499511325

Epoch: 5| Step: 8
Training loss: 3.670291380579936
Validation loss: 3.3455283574992456

Epoch: 5| Step: 9
Training loss: 3.322153384439257
Validation loss: 3.347050689660099

Epoch: 5| Step: 10
Training loss: 4.534972036794904
Validation loss: 3.3473582602572423

Epoch: 43| Step: 0
Training loss: 2.7657730149138477
Validation loss: 3.345972994566935

Epoch: 5| Step: 1
Training loss: 4.008433273454762
Validation loss: 3.3466891632170475

Epoch: 5| Step: 2
Training loss: 3.7106831995515437
Validation loss: 3.3469591355772215

Epoch: 5| Step: 3
Training loss: 3.741938381623577
Validation loss: 3.3483950077785143

Epoch: 5| Step: 4
Training loss: 3.007145636809339
Validation loss: 3.345098222718748

Epoch: 5| Step: 5
Training loss: 4.258247899183235
Validation loss: 3.3429470790727374

Epoch: 5| Step: 6
Training loss: 4.439627983385474
Validation loss: 3.3434053722033164

Epoch: 5| Step: 7
Training loss: 2.777974117545717
Validation loss: 3.3432545993113125

Epoch: 5| Step: 8
Training loss: 3.1119342029254735
Validation loss: 3.3442832392018316

Epoch: 5| Step: 9
Training loss: 3.5297387864505967
Validation loss: 3.3442299864140566

Epoch: 5| Step: 10
Training loss: 3.5803410360193486
Validation loss: 3.343337292598979

Epoch: 44| Step: 0
Training loss: 4.442786922259121
Validation loss: 3.34204766502762

Epoch: 5| Step: 1
Training loss: 3.7365601343445873
Validation loss: 3.348045424618097

Epoch: 5| Step: 2
Training loss: 3.642247963840812
Validation loss: 3.343372968122385

Epoch: 5| Step: 3
Training loss: 3.253029071958222
Validation loss: 3.3461449653916953

Epoch: 5| Step: 4
Training loss: 3.2587271671058606
Validation loss: 3.3433883129430657

Epoch: 5| Step: 5
Training loss: 3.4224274768487866
Validation loss: 3.3419421260256352

Epoch: 5| Step: 6
Training loss: 3.655543984610949
Validation loss: 3.3440003445599564

Epoch: 5| Step: 7
Training loss: 3.495951081673498
Validation loss: 3.3472474631015916

Epoch: 5| Step: 8
Training loss: 2.69085368780678
Validation loss: 3.3413216014072384

Epoch: 5| Step: 9
Training loss: 3.6146277315929076
Validation loss: 3.3428959200889516

Epoch: 5| Step: 10
Training loss: 3.9395889311773726
Validation loss: 3.34221111495353

Epoch: 45| Step: 0
Training loss: 3.971814992047677
Validation loss: 3.341116112329794

Epoch: 5| Step: 1
Training loss: 4.716473567141652
Validation loss: 3.3440810583923417

Epoch: 5| Step: 2
Training loss: 3.2340558028163304
Validation loss: 3.339775085031213

Epoch: 5| Step: 3
Training loss: 3.706496365932246
Validation loss: 3.3403306969843958

Epoch: 5| Step: 4
Training loss: 3.5270752662045193
Validation loss: 3.336804885377321

Epoch: 5| Step: 5
Training loss: 3.5282405756628075
Validation loss: 3.335882426348573

Epoch: 5| Step: 6
Training loss: 3.893007827982172
Validation loss: 3.335834849433095

Epoch: 5| Step: 7
Training loss: 3.18120791664093
Validation loss: 3.3352788282735264

Epoch: 5| Step: 8
Training loss: 2.8511041142169784
Validation loss: 3.334289289623179

Epoch: 5| Step: 9
Training loss: 2.6015604838228863
Validation loss: 3.3336163667269765

Epoch: 5| Step: 10
Training loss: 3.650811609410936
Validation loss: 3.334782248326844

Epoch: 46| Step: 0
Training loss: 2.8187403642781534
Validation loss: 3.334304487106336

Epoch: 5| Step: 1
Training loss: 3.626378290641496
Validation loss: 3.336899450031493

Epoch: 5| Step: 2
Training loss: 3.193989748083775
Validation loss: 3.337837691116465

Epoch: 5| Step: 3
Training loss: 3.9584947385840934
Validation loss: 3.3378548340447134

Epoch: 5| Step: 4
Training loss: 3.9662645622344357
Validation loss: 3.335407581273289

Epoch: 5| Step: 5
Training loss: 2.791125819257925
Validation loss: 3.341097248956844

Epoch: 5| Step: 6
Training loss: 3.9076335440456518
Validation loss: 3.3429401940133023

Epoch: 5| Step: 7
Training loss: 3.128584370147753
Validation loss: 3.332013901687456

Epoch: 5| Step: 8
Training loss: 3.768754726932022
Validation loss: 3.3294596457293593

Epoch: 5| Step: 9
Training loss: 3.569519622710325
Validation loss: 3.3314125084655792

Epoch: 5| Step: 10
Training loss: 4.2940611347595805
Validation loss: 3.331488023680501

Epoch: 47| Step: 0
Training loss: 4.471895404718472
Validation loss: 3.338379226860675

Epoch: 5| Step: 1
Training loss: 4.005986740341753
Validation loss: 3.3326526767270583

Epoch: 5| Step: 2
Training loss: 3.375747597863682
Validation loss: 3.335403297785263

Epoch: 5| Step: 3
Training loss: 1.7765331390021348
Validation loss: 3.3323313688958915

Epoch: 5| Step: 4
Training loss: 3.0281921379276024
Validation loss: 3.3294469871190584

Epoch: 5| Step: 5
Training loss: 3.805154947943177
Validation loss: 3.325647737330765

Epoch: 5| Step: 6
Training loss: 3.5487368902089904
Validation loss: 3.32543460356636

Epoch: 5| Step: 7
Training loss: 3.2374923352478495
Validation loss: 3.3279855550558204

Epoch: 5| Step: 8
Training loss: 4.269659237631636
Validation loss: 3.3274370378190192

Epoch: 5| Step: 9
Training loss: 3.698090039697712
Validation loss: 3.3306500268656443

Epoch: 5| Step: 10
Training loss: 3.2287398189512646
Validation loss: 3.3251509672957447

Epoch: 48| Step: 0
Training loss: 3.170734369552382
Validation loss: 3.327523808416053

Epoch: 5| Step: 1
Training loss: 2.9263465650970284
Validation loss: 3.3291701765538737

Epoch: 5| Step: 2
Training loss: 3.94891664158816
Validation loss: 3.3246548432405922

Epoch: 5| Step: 3
Training loss: 3.179400606826539
Validation loss: 3.324194515693223

Epoch: 5| Step: 4
Training loss: 3.187192415842738
Validation loss: 3.3308594065254136

Epoch: 5| Step: 5
Training loss: 4.244552936354617
Validation loss: 3.3271196506784073

Epoch: 5| Step: 6
Training loss: 3.953113058320958
Validation loss: 3.327082242848719

Epoch: 5| Step: 7
Training loss: 3.848176345916338
Validation loss: 3.328556092761742

Epoch: 5| Step: 8
Training loss: 2.7469755360472523
Validation loss: 3.3264068523791432

Epoch: 5| Step: 9
Training loss: 3.7740359256330285
Validation loss: 3.3284873582193653

Epoch: 5| Step: 10
Training loss: 3.91077838106129
Validation loss: 3.327061290335202

Epoch: 49| Step: 0
Training loss: 4.271493752133054
Validation loss: 3.32501604839791

Epoch: 5| Step: 1
Training loss: 4.062421123032345
Validation loss: 3.323910724241879

Epoch: 5| Step: 2
Training loss: 4.177420256131515
Validation loss: 3.3234734056124764

Epoch: 5| Step: 3
Training loss: 3.317965910218499
Validation loss: 3.3216954022276126

Epoch: 5| Step: 4
Training loss: 3.3695881156624865
Validation loss: 3.324638602297248

Epoch: 5| Step: 5
Training loss: 2.763250851322403
Validation loss: 3.3218169703147864

Epoch: 5| Step: 6
Training loss: 2.7041897303024327
Validation loss: 3.3261738604464997

Epoch: 5| Step: 7
Training loss: 3.1472341353379987
Validation loss: 3.323722944956745

Epoch: 5| Step: 8
Training loss: 4.260648738195639
Validation loss: 3.325639804302576

Epoch: 5| Step: 9
Training loss: 3.317386405972075
Validation loss: 3.3208305210550346

Epoch: 5| Step: 10
Training loss: 3.2459920965957556
Validation loss: 3.320579916640657

Epoch: 50| Step: 0
Training loss: 3.881866278379854
Validation loss: 3.3201468771078573

Epoch: 5| Step: 1
Training loss: 3.9365225895791074
Validation loss: 3.3217697892927625

Epoch: 5| Step: 2
Training loss: 3.3660427900326897
Validation loss: 3.3203295280314276

Epoch: 5| Step: 3
Training loss: 4.232903594384766
Validation loss: 3.319867270994554

Epoch: 5| Step: 4
Training loss: 3.262045911268215
Validation loss: 3.3183351288040486

Epoch: 5| Step: 5
Training loss: 3.175647014863695
Validation loss: 3.3196882844662388

Epoch: 5| Step: 6
Training loss: 3.3328972213285324
Validation loss: 3.3213079519233673

Epoch: 5| Step: 7
Training loss: 3.704683643791158
Validation loss: 3.319803496499421

Epoch: 5| Step: 8
Training loss: 2.9152279893237045
Validation loss: 3.3191645920146224

Epoch: 5| Step: 9
Training loss: 3.9607519824882584
Validation loss: 3.323240314473339

Epoch: 5| Step: 10
Training loss: 3.012976555703633
Validation loss: 3.3285780494372954

Epoch: 51| Step: 0
Training loss: 3.499047013378222
Validation loss: 3.329279152804886

Epoch: 5| Step: 1
Training loss: 3.9169053890984444
Validation loss: 3.3246783447367814

Epoch: 5| Step: 2
Training loss: 3.2395592757105534
Validation loss: 3.3226535978570673

Epoch: 5| Step: 3
Training loss: 2.55395702686168
Validation loss: 3.3199095176603657

Epoch: 5| Step: 4
Training loss: 2.8743718331774284
Validation loss: 3.3181731265411436

Epoch: 5| Step: 5
Training loss: 3.6996031161684204
Validation loss: 3.3164726824732766

Epoch: 5| Step: 6
Training loss: 3.782416676008833
Validation loss: 3.3177666243266386

Epoch: 5| Step: 7
Training loss: 3.4619292136480864
Validation loss: 3.3164403058916556

Epoch: 5| Step: 8
Training loss: 3.8443605511821275
Validation loss: 3.315354949400197

Epoch: 5| Step: 9
Training loss: 3.699434268075133
Validation loss: 3.3159872835167987

Epoch: 5| Step: 10
Training loss: 4.308302896319565
Validation loss: 3.313708135542074

Epoch: 52| Step: 0
Training loss: 3.629898838914042
Validation loss: 3.3176604249590906

Epoch: 5| Step: 1
Training loss: 3.539826771651859
Validation loss: 3.31599286076617

Epoch: 5| Step: 2
Training loss: 2.9869972412484875
Validation loss: 3.314926261907682

Epoch: 5| Step: 3
Training loss: 3.518208550487609
Validation loss: 3.3155485648842835

Epoch: 5| Step: 4
Training loss: 3.8794372748294226
Validation loss: 3.3158666768767113

Epoch: 5| Step: 5
Training loss: 4.024295456158386
Validation loss: 3.315595453243623

Epoch: 5| Step: 6
Training loss: 3.9020189488047152
Validation loss: 3.3157348440183396

Epoch: 5| Step: 7
Training loss: 3.1125325028894024
Validation loss: 3.311872914001407

Epoch: 5| Step: 8
Training loss: 3.410481755298312
Validation loss: 3.3154920754419575

Epoch: 5| Step: 9
Training loss: 2.8629255086819354
Validation loss: 3.3142137867368833

Epoch: 5| Step: 10
Training loss: 4.03834347255398
Validation loss: 3.314139098571602

Epoch: 53| Step: 0
Training loss: 3.8600774581332025
Validation loss: 3.315097606833435

Epoch: 5| Step: 1
Training loss: 4.65280863939871
Validation loss: 3.3127691368933414

Epoch: 5| Step: 2
Training loss: 3.2000510748125084
Validation loss: 3.3127175830621813

Epoch: 5| Step: 3
Training loss: 3.720883310515614
Validation loss: 3.3108655364746347

Epoch: 5| Step: 4
Training loss: 3.7417413688514753
Validation loss: 3.3130251421181236

Epoch: 5| Step: 5
Training loss: 3.2585426445453805
Validation loss: 3.312641336587678

Epoch: 5| Step: 6
Training loss: 2.8688717087003814
Validation loss: 3.312736040010984

Epoch: 5| Step: 7
Training loss: 4.114041192115111
Validation loss: 3.3101451441638

Epoch: 5| Step: 8
Training loss: 2.9873219265398303
Validation loss: 3.3151935485143147

Epoch: 5| Step: 9
Training loss: 2.853164849728982
Validation loss: 3.3153609298092612

Epoch: 5| Step: 10
Training loss: 3.2706229917759546
Validation loss: 3.313702620981072

Epoch: 54| Step: 0
Training loss: 3.4096587037702597
Validation loss: 3.318479086064431

Epoch: 5| Step: 1
Training loss: 3.3333967838606227
Validation loss: 3.3218182915651546

Epoch: 5| Step: 2
Training loss: 3.379592596477283
Validation loss: 3.326392372555348

Epoch: 5| Step: 3
Training loss: 3.2069933351233955
Validation loss: 3.327033338804833

Epoch: 5| Step: 4
Training loss: 3.9347614271265954
Validation loss: 3.314576117330971

Epoch: 5| Step: 5
Training loss: 3.6477167696006205
Validation loss: 3.3087800913895156

Epoch: 5| Step: 6
Training loss: 4.434432137828898
Validation loss: 3.3092424128493927

Epoch: 5| Step: 7
Training loss: 3.6004993251380877
Validation loss: 3.309831390614547

Epoch: 5| Step: 8
Training loss: 3.1316392180772845
Validation loss: 3.3083324998258536

Epoch: 5| Step: 9
Training loss: 2.997509558426202
Validation loss: 3.312671606626445

Epoch: 5| Step: 10
Training loss: 3.767997785563537
Validation loss: 3.3117273210788594

Epoch: 55| Step: 0
Training loss: 3.7097358765885007
Validation loss: 3.308038956204665

Epoch: 5| Step: 1
Training loss: 3.8020934361711167
Validation loss: 3.3060817286515696

Epoch: 5| Step: 2
Training loss: 3.6583256494764362
Validation loss: 3.311475908534662

Epoch: 5| Step: 3
Training loss: 3.605662761192279
Validation loss: 3.310659992253993

Epoch: 5| Step: 4
Training loss: 3.9844087487081725
Validation loss: 3.3127197948059557

Epoch: 5| Step: 5
Training loss: 3.3014406527463063
Validation loss: 3.3077632790976357

Epoch: 5| Step: 6
Training loss: 3.511757448384176
Validation loss: 3.309089787436731

Epoch: 5| Step: 7
Training loss: 3.3448394711782
Validation loss: 3.3100189898388916

Epoch: 5| Step: 8
Training loss: 2.8031961625506208
Validation loss: 3.308938052933881

Epoch: 5| Step: 9
Training loss: 3.7273380903953837
Validation loss: 3.3086141484533673

Epoch: 5| Step: 10
Training loss: 3.4024188693630384
Validation loss: 3.3043415702391044

Epoch: 56| Step: 0
Training loss: 3.750852996451443
Validation loss: 3.3044172611064586

Epoch: 5| Step: 1
Training loss: 3.9569656954096075
Validation loss: 3.3061379586044377

Epoch: 5| Step: 2
Training loss: 3.3411691277817552
Validation loss: 3.304092381956439

Epoch: 5| Step: 3
Training loss: 2.858624802864098
Validation loss: 3.303729323712759

Epoch: 5| Step: 4
Training loss: 3.290422679336411
Validation loss: 3.304757055359678

Epoch: 5| Step: 5
Training loss: 3.2690022358482653
Validation loss: 3.3051030277320876

Epoch: 5| Step: 6
Training loss: 3.990044363822106
Validation loss: 3.304112611122671

Epoch: 5| Step: 7
Training loss: 3.440089412236922
Validation loss: 3.303736878682989

Epoch: 5| Step: 8
Training loss: 3.8204456766392916
Validation loss: 3.3012839593530834

Epoch: 5| Step: 9
Training loss: 3.9021084001384
Validation loss: 3.3012340231475745

Epoch: 5| Step: 10
Training loss: 3.086839297872682
Validation loss: 3.3009719683828873

Epoch: 57| Step: 0
Training loss: 3.0439898010664526
Validation loss: 3.2993377824378367

Epoch: 5| Step: 1
Training loss: 3.8148526296486867
Validation loss: 3.2996081343305095

Epoch: 5| Step: 2
Training loss: 3.7376938122155634
Validation loss: 3.300873121835056

Epoch: 5| Step: 3
Training loss: 3.548017275883225
Validation loss: 3.3020575152847056

Epoch: 5| Step: 4
Training loss: 3.4473336793919898
Validation loss: 3.3018544477053764

Epoch: 5| Step: 5
Training loss: 3.800168716299168
Validation loss: 3.2989387423475587

Epoch: 5| Step: 6
Training loss: 3.893011012604857
Validation loss: 3.2971294899521593

Epoch: 5| Step: 7
Training loss: 3.634388571506394
Validation loss: 3.3024648837558446

Epoch: 5| Step: 8
Training loss: 3.938428254686071
Validation loss: 3.301268261959085

Epoch: 5| Step: 9
Training loss: 3.0459784337944065
Validation loss: 3.301678335960129

Epoch: 5| Step: 10
Training loss: 2.6951549539270445
Validation loss: 3.2976191216063238

Epoch: 58| Step: 0
Training loss: 3.0624660567913278
Validation loss: 3.2996809891915504

Epoch: 5| Step: 1
Training loss: 2.9458760094327903
Validation loss: 3.298008961547862

Epoch: 5| Step: 2
Training loss: 3.993468674376031
Validation loss: 3.2990402438788444

Epoch: 5| Step: 3
Training loss: 3.1979972174789224
Validation loss: 3.295760586461573

Epoch: 5| Step: 4
Training loss: 4.638051356522714
Validation loss: 3.297294317485685

Epoch: 5| Step: 5
Training loss: 3.7579042419528217
Validation loss: 3.297300722510232

Epoch: 5| Step: 6
Training loss: 3.009866701640707
Validation loss: 3.298560988961661

Epoch: 5| Step: 7
Training loss: 3.438454374129631
Validation loss: 3.297588652754629

Epoch: 5| Step: 8
Training loss: 2.819048230957888
Validation loss: 3.299251792761499

Epoch: 5| Step: 9
Training loss: 3.7785420455016805
Validation loss: 3.297603950964539

Epoch: 5| Step: 10
Training loss: 3.868848039558835
Validation loss: 3.2983066110152817

Epoch: 59| Step: 0
Training loss: 3.330669021759341
Validation loss: 3.2947806295305653

Epoch: 5| Step: 1
Training loss: 3.558497807604849
Validation loss: 3.2989162915426897

Epoch: 5| Step: 2
Training loss: 3.7519420681204205
Validation loss: 3.2986424073981837

Epoch: 5| Step: 3
Training loss: 3.6480179408619398
Validation loss: 3.2964995656012603

Epoch: 5| Step: 4
Training loss: 2.8793416619197685
Validation loss: 3.2942889386419276

Epoch: 5| Step: 5
Training loss: 2.9771913680132256
Validation loss: 3.292038916872184

Epoch: 5| Step: 6
Training loss: 4.034462764857967
Validation loss: 3.292519057286741

Epoch: 5| Step: 7
Training loss: 3.5273974172706533
Validation loss: 3.29302008829474

Epoch: 5| Step: 8
Training loss: 3.768508250515594
Validation loss: 3.2919122181950535

Epoch: 5| Step: 9
Training loss: 3.6853049258983424
Validation loss: 3.2895888492780325

Epoch: 5| Step: 10
Training loss: 3.5398076432979084
Validation loss: 3.290547586580698

Epoch: 60| Step: 0
Training loss: 2.8936316447431563
Validation loss: 3.2895781523216083

Epoch: 5| Step: 1
Training loss: 3.5739950141295593
Validation loss: 3.2918557148721663

Epoch: 5| Step: 2
Training loss: 3.161750909798682
Validation loss: 3.288961719440808

Epoch: 5| Step: 3
Training loss: 3.230333392295355
Validation loss: 3.287220516152249

Epoch: 5| Step: 4
Training loss: 4.2339454799019585
Validation loss: 3.2869289002736375

Epoch: 5| Step: 5
Training loss: 4.207599286309283
Validation loss: 3.2914285948831874

Epoch: 5| Step: 6
Training loss: 3.0623020964535566
Validation loss: 3.289530593073243

Epoch: 5| Step: 7
Training loss: 3.0108871004393034
Validation loss: 3.2901168831229954

Epoch: 5| Step: 8
Training loss: 4.046682228003993
Validation loss: 3.29043345769224

Epoch: 5| Step: 9
Training loss: 3.58866469454252
Validation loss: 3.287520146792661

Epoch: 5| Step: 10
Training loss: 3.4388394607116877
Validation loss: 3.2881748411564162

Epoch: 61| Step: 0
Training loss: 3.824141317485675
Validation loss: 3.286013871903335

Epoch: 5| Step: 1
Training loss: 3.1075148649466278
Validation loss: 3.287218426850539

Epoch: 5| Step: 2
Training loss: 3.2628535871985034
Validation loss: 3.2873410632587916

Epoch: 5| Step: 3
Training loss: 4.0308473371149836
Validation loss: 3.285446354153058

Epoch: 5| Step: 4
Training loss: 3.3343988305109944
Validation loss: 3.286287507318262

Epoch: 5| Step: 5
Training loss: 3.2990596818708657
Validation loss: 3.283928661729899

Epoch: 5| Step: 6
Training loss: 3.7061414062647393
Validation loss: 3.2854528228509623

Epoch: 5| Step: 7
Training loss: 3.4073936572311916
Validation loss: 3.2867696516572495

Epoch: 5| Step: 8
Training loss: 3.4942064017879506
Validation loss: 3.2849913722011888

Epoch: 5| Step: 9
Training loss: 3.456362902157928
Validation loss: 3.301177393594939

Epoch: 5| Step: 10
Training loss: 3.7747538858989054
Validation loss: 3.292232625730793

Epoch: 62| Step: 0
Training loss: 3.5546490006929576
Validation loss: 3.284276483972433

Epoch: 5| Step: 1
Training loss: 3.88600478779355
Validation loss: 3.2832420775147315

Epoch: 5| Step: 2
Training loss: 3.6963027369297916
Validation loss: 3.2818147391100165

Epoch: 5| Step: 3
Training loss: 4.089941451719231
Validation loss: 3.281276182821244

Epoch: 5| Step: 4
Training loss: 3.877820618862507
Validation loss: 3.2884766027576693

Epoch: 5| Step: 5
Training loss: 3.343379205127253
Validation loss: 3.284629893641956

Epoch: 5| Step: 6
Training loss: 3.2923716663326483
Validation loss: 3.2811828106370147

Epoch: 5| Step: 7
Training loss: 2.93533683832557
Validation loss: 3.290136521879925

Epoch: 5| Step: 8
Training loss: 3.128907773973568
Validation loss: 3.2852931296826413

Epoch: 5| Step: 9
Training loss: 2.9664287928964677
Validation loss: 3.2816958466834527

Epoch: 5| Step: 10
Training loss: 3.7898971424890906
Validation loss: 3.2819307229599315

Epoch: 63| Step: 0
Training loss: 3.7269005452185326
Validation loss: 3.2866213804085063

Epoch: 5| Step: 1
Training loss: 3.996133604624693
Validation loss: 3.2886356018941005

Epoch: 5| Step: 2
Training loss: 3.4383263721725355
Validation loss: 3.281272001334329

Epoch: 5| Step: 3
Training loss: 3.526128785687902
Validation loss: 3.2812650728050423

Epoch: 5| Step: 4
Training loss: 3.705549902834593
Validation loss: 3.282398888813453

Epoch: 5| Step: 5
Training loss: 3.3544798205285136
Validation loss: 3.2811115866598803

Epoch: 5| Step: 6
Training loss: 2.883105420786865
Validation loss: 3.279645520680933

Epoch: 5| Step: 7
Training loss: 3.569152376435932
Validation loss: 3.277784740734219

Epoch: 5| Step: 8
Training loss: 3.961942586591613
Validation loss: 3.2794443923651406

Epoch: 5| Step: 9
Training loss: 3.2351701284302954
Validation loss: 3.2806370128898594

Epoch: 5| Step: 10
Training loss: 3.0829572362318896
Validation loss: 3.283246025368394

Epoch: 64| Step: 0
Training loss: 2.648196679253272
Validation loss: 3.2782182366837316

Epoch: 5| Step: 1
Training loss: 3.829933455563928
Validation loss: 3.282284314126024

Epoch: 5| Step: 2
Training loss: 3.780939641148391
Validation loss: 3.278527999955466

Epoch: 5| Step: 3
Training loss: 3.10411954157003
Validation loss: 3.277871524285221

Epoch: 5| Step: 4
Training loss: 3.4908261643299157
Validation loss: 3.277813355470789

Epoch: 5| Step: 5
Training loss: 3.8951427779270187
Validation loss: 3.276445747547307

Epoch: 5| Step: 6
Training loss: 3.424065990204254
Validation loss: 3.2746652688374205

Epoch: 5| Step: 7
Training loss: 4.126514041360446
Validation loss: 3.274522164711445

Epoch: 5| Step: 8
Training loss: 3.608713328826278
Validation loss: 3.2755749075494687

Epoch: 5| Step: 9
Training loss: 2.928629203385996
Validation loss: 3.276429467943222

Epoch: 5| Step: 10
Training loss: 3.585557572593735
Validation loss: 3.273532499629956

Epoch: 65| Step: 0
Training loss: 4.045809690260367
Validation loss: 3.272961534653791

Epoch: 5| Step: 1
Training loss: 2.9927417052643737
Validation loss: 3.2738624363706315

Epoch: 5| Step: 2
Training loss: 3.7685376058420204
Validation loss: 3.2722177145966285

Epoch: 5| Step: 3
Training loss: 4.018832221013251
Validation loss: 3.269996724704882

Epoch: 5| Step: 4
Training loss: 3.3762459044729995
Validation loss: 3.271022485222876

Epoch: 5| Step: 5
Training loss: 3.2251506977210003
Validation loss: 3.270705898904408

Epoch: 5| Step: 6
Training loss: 3.4446212524920816
Validation loss: 3.2712624436049875

Epoch: 5| Step: 7
Training loss: 3.3772360846966776
Validation loss: 3.2730785089519125

Epoch: 5| Step: 8
Training loss: 3.823380126023795
Validation loss: 3.270664721510568

Epoch: 5| Step: 9
Training loss: 2.7731894798597576
Validation loss: 3.2717196113744422

Epoch: 5| Step: 10
Training loss: 3.565032192903451
Validation loss: 3.2713040170679064

Epoch: 66| Step: 0
Training loss: 3.4139078834142533
Validation loss: 3.272777474679609

Epoch: 5| Step: 1
Training loss: 3.3936947756606926
Validation loss: 3.2811045702823773

Epoch: 5| Step: 2
Training loss: 3.6201673719798455
Validation loss: 3.2747046532773356

Epoch: 5| Step: 3
Training loss: 3.4135610530808367
Validation loss: 3.274768170922858

Epoch: 5| Step: 4
Training loss: 3.0701032960394103
Validation loss: 3.2750754707067724

Epoch: 5| Step: 5
Training loss: 3.8569124218564523
Validation loss: 3.2749456233138456

Epoch: 5| Step: 6
Training loss: 2.8615247639343218
Validation loss: 3.270856169184663

Epoch: 5| Step: 7
Training loss: 4.239402573439741
Validation loss: 3.2695059814841025

Epoch: 5| Step: 8
Training loss: 3.7855228211139877
Validation loss: 3.270279384335015

Epoch: 5| Step: 9
Training loss: 3.4433007973693717
Validation loss: 3.2684597251580416

Epoch: 5| Step: 10
Training loss: 3.2965680743351236
Validation loss: 3.269152644037842

Epoch: 67| Step: 0
Training loss: 2.749634891895069
Validation loss: 3.268895012971665

Epoch: 5| Step: 1
Training loss: 3.3326202265579092
Validation loss: 3.2688651406393947

Epoch: 5| Step: 2
Training loss: 3.867781529897041
Validation loss: 3.2671627712882754

Epoch: 5| Step: 3
Training loss: 3.9362810458197326
Validation loss: 3.267526776121948

Epoch: 5| Step: 4
Training loss: 3.2900573240811086
Validation loss: 3.2684396235842827

Epoch: 5| Step: 5
Training loss: 2.9512676877336363
Validation loss: 3.268100193591845

Epoch: 5| Step: 6
Training loss: 3.918209840577373
Validation loss: 3.2659992023836257

Epoch: 5| Step: 7
Training loss: 3.4822188065179485
Validation loss: 3.267874477808924

Epoch: 5| Step: 8
Training loss: 3.4531600743234256
Validation loss: 3.2655142504166563

Epoch: 5| Step: 9
Training loss: 3.5065505172678417
Validation loss: 3.2671824774006617

Epoch: 5| Step: 10
Training loss: 3.9216483609190687
Validation loss: 3.270973866154738

Epoch: 68| Step: 0
Training loss: 4.1502594188819755
Validation loss: 3.26936849415748

Epoch: 5| Step: 1
Training loss: 3.704710673207852
Validation loss: 3.2685696117852907

Epoch: 5| Step: 2
Training loss: 3.1387265668850355
Validation loss: 3.2724306856478744

Epoch: 5| Step: 3
Training loss: 3.6970900923648062
Validation loss: 3.269337501685103

Epoch: 5| Step: 4
Training loss: 3.5592912645680284
Validation loss: 3.272492033568019

Epoch: 5| Step: 5
Training loss: 3.6162284749692892
Validation loss: 3.2708708525377

Epoch: 5| Step: 6
Training loss: 3.2172977171105726
Validation loss: 3.269844732410053

Epoch: 5| Step: 7
Training loss: 2.943999870694199
Validation loss: 3.2651247729770785

Epoch: 5| Step: 8
Training loss: 3.0592029495879443
Validation loss: 3.2641771987883814

Epoch: 5| Step: 9
Training loss: 3.945111381012423
Validation loss: 3.261954072889665

Epoch: 5| Step: 10
Training loss: 3.2709816253155344
Validation loss: 3.265283214128463

Epoch: 69| Step: 0
Training loss: 3.2375213504514386
Validation loss: 3.2636934057055136

Epoch: 5| Step: 1
Training loss: 2.6126660818943086
Validation loss: 3.263311964415454

Epoch: 5| Step: 2
Training loss: 3.647642387973299
Validation loss: 3.262330925746792

Epoch: 5| Step: 3
Training loss: 4.076131399161163
Validation loss: 3.26231766482243

Epoch: 5| Step: 4
Training loss: 3.3505769716708227
Validation loss: 3.261948986400169

Epoch: 5| Step: 5
Training loss: 3.3649436041313345
Validation loss: 3.2626986911939846

Epoch: 5| Step: 6
Training loss: 3.7218924956787305
Validation loss: 3.2642090570500293

Epoch: 5| Step: 7
Training loss: 2.951242644233375
Validation loss: 3.2628050145489795

Epoch: 5| Step: 8
Training loss: 3.970386317984446
Validation loss: 3.2614294216454893

Epoch: 5| Step: 9
Training loss: 4.058918004672224
Validation loss: 3.2627110178971592

Epoch: 5| Step: 10
Training loss: 3.1926250768429765
Validation loss: 3.2617765975006794

Epoch: 70| Step: 0
Training loss: 3.5494184743049537
Validation loss: 3.2628269909731835

Epoch: 5| Step: 1
Training loss: 4.815960915327684
Validation loss: 3.2610125064893487

Epoch: 5| Step: 2
Training loss: 3.594644319131852
Validation loss: 3.261374899316439

Epoch: 5| Step: 3
Training loss: 3.6024449523066155
Validation loss: 3.2636322772973587

Epoch: 5| Step: 4
Training loss: 2.7768616076757575
Validation loss: 3.262245372780305

Epoch: 5| Step: 5
Training loss: 3.747910235181927
Validation loss: 3.261541723986462

Epoch: 5| Step: 6
Training loss: 3.327530928768233
Validation loss: 3.2616145700370875

Epoch: 5| Step: 7
Training loss: 3.397077336466104
Validation loss: 3.2641274598837393

Epoch: 5| Step: 8
Training loss: 3.1380531826435973
Validation loss: 3.2643711253693395

Epoch: 5| Step: 9
Training loss: 3.1331354673961456
Validation loss: 3.270332979005737

Epoch: 5| Step: 10
Training loss: 2.892485973221935
Validation loss: 3.2811377869934963

Epoch: 71| Step: 0
Training loss: 3.4756881471607137
Validation loss: 3.294810363383046

Epoch: 5| Step: 1
Training loss: 3.3347105677888824
Validation loss: 3.26401805518829

Epoch: 5| Step: 2
Training loss: 3.991864872566159
Validation loss: 3.25905548767508

Epoch: 5| Step: 3
Training loss: 3.792902748484391
Validation loss: 3.259561022201368

Epoch: 5| Step: 4
Training loss: 3.7595148810462375
Validation loss: 3.2577034262204414

Epoch: 5| Step: 5
Training loss: 3.7111716106252404
Validation loss: 3.2616727589329484

Epoch: 5| Step: 6
Training loss: 3.497218116378764
Validation loss: 3.2563661339321075

Epoch: 5| Step: 7
Training loss: 3.3662831802517736
Validation loss: 3.253328001426303

Epoch: 5| Step: 8
Training loss: 3.134752847520688
Validation loss: 3.255623687168786

Epoch: 5| Step: 9
Training loss: 3.123043974015616
Validation loss: 3.2561244605089326

Epoch: 5| Step: 10
Training loss: 3.210025258663066
Validation loss: 3.257888588063887

Epoch: 72| Step: 0
Training loss: 4.005731529453711
Validation loss: 3.2590760215581582

Epoch: 5| Step: 1
Training loss: 4.404971755735017
Validation loss: 3.259585054368262

Epoch: 5| Step: 2
Training loss: 3.7983663008563244
Validation loss: 3.259952167813351

Epoch: 5| Step: 3
Training loss: 2.9607746814258533
Validation loss: 3.2554922811725766

Epoch: 5| Step: 4
Training loss: 3.2932411162661204
Validation loss: 3.2559781857001893

Epoch: 5| Step: 5
Training loss: 3.5347243240107042
Validation loss: 3.25959613131602

Epoch: 5| Step: 6
Training loss: 3.3544845114540998
Validation loss: 3.256932084138328

Epoch: 5| Step: 7
Training loss: 2.6825885694801332
Validation loss: 3.260054407428853

Epoch: 5| Step: 8
Training loss: 3.0867694747259793
Validation loss: 3.2549133030574673

Epoch: 5| Step: 9
Training loss: 3.61003998414613
Validation loss: 3.2568000649916202

Epoch: 5| Step: 10
Training loss: 3.4054974765883057
Validation loss: 3.2581082153750356

Epoch: 73| Step: 0
Training loss: 3.780938253871629
Validation loss: 3.256793470112425

Epoch: 5| Step: 1
Training loss: 3.7863001871293385
Validation loss: 3.254413391048294

Epoch: 5| Step: 2
Training loss: 4.174847518968882
Validation loss: 3.256152744386689

Epoch: 5| Step: 3
Training loss: 3.838583226110495
Validation loss: 3.253960134830221

Epoch: 5| Step: 4
Training loss: 3.4012801284885623
Validation loss: 3.252418460679382

Epoch: 5| Step: 5
Training loss: 2.7305947467073635
Validation loss: 3.254279490927775

Epoch: 5| Step: 6
Training loss: 3.9050388747464795
Validation loss: 3.251848018827001

Epoch: 5| Step: 7
Training loss: 3.0793550618669974
Validation loss: 3.250738643704532

Epoch: 5| Step: 8
Training loss: 2.827329239145289
Validation loss: 3.251699227443217

Epoch: 5| Step: 9
Training loss: 3.6198192275207886
Validation loss: 3.2517296816272645

Epoch: 5| Step: 10
Training loss: 2.8337560413163265
Validation loss: 3.2509058249262996

Epoch: 74| Step: 0
Training loss: 2.7876941733022877
Validation loss: 3.2537356080291504

Epoch: 5| Step: 1
Training loss: 3.5773905037704905
Validation loss: 3.2518782619146753

Epoch: 5| Step: 2
Training loss: 3.2483055392531615
Validation loss: 3.2510170966078

Epoch: 5| Step: 3
Training loss: 3.6052588570151833
Validation loss: 3.2501259961564535

Epoch: 5| Step: 4
Training loss: 3.503432225852959
Validation loss: 3.251753240298945

Epoch: 5| Step: 5
Training loss: 2.9979342660040516
Validation loss: 3.249739807668542

Epoch: 5| Step: 6
Training loss: 3.5590908402642563
Validation loss: 3.249258175220745

Epoch: 5| Step: 7
Training loss: 3.231886343949917
Validation loss: 3.248398570065631

Epoch: 5| Step: 8
Training loss: 3.303178158479387
Validation loss: 3.251122448858021

Epoch: 5| Step: 9
Training loss: 4.228703490702591
Validation loss: 3.2489856370700916

Epoch: 5| Step: 10
Training loss: 4.195978037293942
Validation loss: 3.2476163899545423

Epoch: 75| Step: 0
Training loss: 3.597492558071983
Validation loss: 3.248403881386579

Epoch: 5| Step: 1
Training loss: 3.503207508105769
Validation loss: 3.2485537138817544

Epoch: 5| Step: 2
Training loss: 3.0921292153484825
Validation loss: 3.2464086695910703

Epoch: 5| Step: 3
Training loss: 4.298274363753844
Validation loss: 3.244417193073529

Epoch: 5| Step: 4
Training loss: 3.0804623477258795
Validation loss: 3.2477946738579577

Epoch: 5| Step: 5
Training loss: 3.553065338573286
Validation loss: 3.24453516486714

Epoch: 5| Step: 6
Training loss: 3.450603410224554
Validation loss: 3.248485978466918

Epoch: 5| Step: 7
Training loss: 3.9999077309456905
Validation loss: 3.247962307339795

Epoch: 5| Step: 8
Training loss: 3.54040542285294
Validation loss: 3.246028974675639

Epoch: 5| Step: 9
Training loss: 2.769028030110361
Validation loss: 3.2507320554555466

Epoch: 5| Step: 10
Training loss: 3.199627115458693
Validation loss: 3.250215874247581

Epoch: 76| Step: 0
Training loss: 3.51958950726965
Validation loss: 3.247353878267141

Epoch: 5| Step: 1
Training loss: 3.544319744833031
Validation loss: 3.249804382810734

Epoch: 5| Step: 2
Training loss: 3.493599761844432
Validation loss: 3.2477849356555426

Epoch: 5| Step: 3
Training loss: 3.5364295984523104
Validation loss: 3.2471726048039766

Epoch: 5| Step: 4
Training loss: 3.2186987419120983
Validation loss: 3.2485591157027205

Epoch: 5| Step: 5
Training loss: 3.327341193372609
Validation loss: 3.2460626743064607

Epoch: 5| Step: 6
Training loss: 3.5470263747123836
Validation loss: 3.2434806639676137

Epoch: 5| Step: 7
Training loss: 3.7530695749934093
Validation loss: 3.2427541080281714

Epoch: 5| Step: 8
Training loss: 3.875807770244444
Validation loss: 3.241363113786151

Epoch: 5| Step: 9
Training loss: 2.898618790131419
Validation loss: 3.2423423827946016

Epoch: 5| Step: 10
Training loss: 3.5644709171216906
Validation loss: 3.2430384693745413

Epoch: 77| Step: 0
Training loss: 3.175219346527035
Validation loss: 3.2406342944294546

Epoch: 5| Step: 1
Training loss: 3.625551773696981
Validation loss: 3.2443870700788002

Epoch: 5| Step: 2
Training loss: 3.753074657093017
Validation loss: 3.243395891093302

Epoch: 5| Step: 3
Training loss: 3.595006839071886
Validation loss: 3.2439686458589687

Epoch: 5| Step: 4
Training loss: 2.7925764755391427
Validation loss: 3.2420868627805652

Epoch: 5| Step: 5
Training loss: 3.157665124292063
Validation loss: 3.2398608912825897

Epoch: 5| Step: 6
Training loss: 4.275793677823731
Validation loss: 3.2420193805143516

Epoch: 5| Step: 7
Training loss: 3.7850679401059977
Validation loss: 3.240838191248154

Epoch: 5| Step: 8
Training loss: 3.584223052764403
Validation loss: 3.241839406175394

Epoch: 5| Step: 9
Training loss: 3.3050510936948605
Validation loss: 3.2406938670828507

Epoch: 5| Step: 10
Training loss: 2.9304644152152357
Validation loss: 3.242099952627693

Epoch: 78| Step: 0
Training loss: 3.389824979421988
Validation loss: 3.2400707702093463

Epoch: 5| Step: 1
Training loss: 3.2101280510100896
Validation loss: 3.2377924125199633

Epoch: 5| Step: 2
Training loss: 3.8578808320715834
Validation loss: 3.241028295326331

Epoch: 5| Step: 3
Training loss: 3.187635531068548
Validation loss: 3.2413074289822568

Epoch: 5| Step: 4
Training loss: 3.705634831907522
Validation loss: 3.2396982678606485

Epoch: 5| Step: 5
Training loss: 3.379321404679929
Validation loss: 3.238015460622951

Epoch: 5| Step: 6
Training loss: 3.656902026864
Validation loss: 3.2389142304603955

Epoch: 5| Step: 7
Training loss: 4.013432598174881
Validation loss: 3.2402077608456294

Epoch: 5| Step: 8
Training loss: 3.1639227942247485
Validation loss: 3.2378116623784816

Epoch: 5| Step: 9
Training loss: 3.3799990612231876
Validation loss: 3.2386552918810905

Epoch: 5| Step: 10
Training loss: 3.1857351765506663
Validation loss: 3.2377279335282054

Epoch: 79| Step: 0
Training loss: 3.5097093784620754
Validation loss: 3.2363733308061957

Epoch: 5| Step: 1
Training loss: 3.788333531681922
Validation loss: 3.235871015637872

Epoch: 5| Step: 2
Training loss: 3.5238155999493346
Validation loss: 3.237920484636174

Epoch: 5| Step: 3
Training loss: 4.014769466712829
Validation loss: 3.234151502657732

Epoch: 5| Step: 4
Training loss: 3.6732956755473847
Validation loss: 3.238008330276211

Epoch: 5| Step: 5
Training loss: 3.1758648813269437
Validation loss: 3.2352407052944447

Epoch: 5| Step: 6
Training loss: 2.9802273193807056
Validation loss: 3.2355779196575636

Epoch: 5| Step: 7
Training loss: 3.4036412879934903
Validation loss: 3.2359560109941468

Epoch: 5| Step: 8
Training loss: 3.6839693915538
Validation loss: 3.2350379264867697

Epoch: 5| Step: 9
Training loss: 3.451117575045027
Validation loss: 3.2400216154747032

Epoch: 5| Step: 10
Training loss: 2.8076129415728763
Validation loss: 3.2379534721600667

Epoch: 80| Step: 0
Training loss: 3.2875805050815985
Validation loss: 3.235611442903202

Epoch: 5| Step: 1
Training loss: 3.829488955035421
Validation loss: 3.234479305152287

Epoch: 5| Step: 2
Training loss: 3.7101362467628407
Validation loss: 3.2353538730907596

Epoch: 5| Step: 3
Training loss: 3.3976134956496025
Validation loss: 3.236750252844962

Epoch: 5| Step: 4
Training loss: 3.6776065328118865
Validation loss: 3.2336065493019195

Epoch: 5| Step: 5
Training loss: 3.625396969862323
Validation loss: 3.232530491682593

Epoch: 5| Step: 6
Training loss: 3.417867185991027
Validation loss: 3.232936628667303

Epoch: 5| Step: 7
Training loss: 2.4457471174893612
Validation loss: 3.233871478628804

Epoch: 5| Step: 8
Training loss: 3.6628376879939504
Validation loss: 3.2337097764755325

Epoch: 5| Step: 9
Training loss: 3.7988818481098403
Validation loss: 3.233432010298899

Epoch: 5| Step: 10
Training loss: 3.1083827903706083
Validation loss: 3.2327646799715555

Epoch: 81| Step: 0
Training loss: 2.8908481821041896
Validation loss: 3.2302996872957217

Epoch: 5| Step: 1
Training loss: 4.112307354435433
Validation loss: 3.2336972393295293

Epoch: 5| Step: 2
Training loss: 3.7999220187568077
Validation loss: 3.2319951832773075

Epoch: 5| Step: 3
Training loss: 3.255902139603674
Validation loss: 3.232105790903484

Epoch: 5| Step: 4
Training loss: 3.8404807477264127
Validation loss: 3.232462788500038

Epoch: 5| Step: 5
Training loss: 3.336254667619718
Validation loss: 3.2330328326506477

Epoch: 5| Step: 6
Training loss: 3.0674041096343596
Validation loss: 3.2324578641875643

Epoch: 5| Step: 7
Training loss: 3.1973179723780523
Validation loss: 3.231942463148953

Epoch: 5| Step: 8
Training loss: 3.43517405106472
Validation loss: 3.2321308235572315

Epoch: 5| Step: 9
Training loss: 3.0514998328458742
Validation loss: 3.232404433051162

Epoch: 5| Step: 10
Training loss: 4.067352214208136
Validation loss: 3.233695492021396

Epoch: 82| Step: 0
Training loss: 3.3828834015285545
Validation loss: 3.231908132415263

Epoch: 5| Step: 1
Training loss: 2.393566242067174
Validation loss: 3.230402916972037

Epoch: 5| Step: 2
Training loss: 3.2018690670866157
Validation loss: 3.233131966020189

Epoch: 5| Step: 3
Training loss: 3.3998648616637226
Validation loss: 3.231046132198948

Epoch: 5| Step: 4
Training loss: 3.3769255902307895
Validation loss: 3.2332834212224126

Epoch: 5| Step: 5
Training loss: 3.546034524292332
Validation loss: 3.2293096414776805

Epoch: 5| Step: 6
Training loss: 4.549140706507388
Validation loss: 3.230681170532268

Epoch: 5| Step: 7
Training loss: 3.6544209657495217
Validation loss: 3.235650744920766

Epoch: 5| Step: 8
Training loss: 3.085729973490765
Validation loss: 3.2336633688140264

Epoch: 5| Step: 9
Training loss: 3.581922889326766
Validation loss: 3.2280414924652323

Epoch: 5| Step: 10
Training loss: 3.6527515856855794
Validation loss: 3.227408562402474

Epoch: 83| Step: 0
Training loss: 3.1707734699254386
Validation loss: 3.2263000376764985

Epoch: 5| Step: 1
Training loss: 3.9659090461939623
Validation loss: 3.2285266560864194

Epoch: 5| Step: 2
Training loss: 3.550458131698822
Validation loss: 3.2266173340816056

Epoch: 5| Step: 3
Training loss: 3.5333494174039384
Validation loss: 3.2276244567751102

Epoch: 5| Step: 4
Training loss: 4.219015381554673
Validation loss: 3.226696892454988

Epoch: 5| Step: 5
Training loss: 3.45192134817083
Validation loss: 3.2266747986651976

Epoch: 5| Step: 6
Training loss: 2.9202876547648975
Validation loss: 3.22812572589191

Epoch: 5| Step: 7
Training loss: 3.17516453234066
Validation loss: 3.2302104304406263

Epoch: 5| Step: 8
Training loss: 3.1960330514452093
Validation loss: 3.2244676668752854

Epoch: 5| Step: 9
Training loss: 3.0146077866651035
Validation loss: 3.227895139551331

Epoch: 5| Step: 10
Training loss: 3.7565155646312576
Validation loss: 3.227793167171986

Epoch: 84| Step: 0
Training loss: 3.65549206825119
Validation loss: 3.2290304202189617

Epoch: 5| Step: 1
Training loss: 3.491522877235419
Validation loss: 3.230003433233334

Epoch: 5| Step: 2
Training loss: 3.3505411081141934
Validation loss: 3.228209097864456

Epoch: 5| Step: 3
Training loss: 2.580005491679653
Validation loss: 3.2261747829308924

Epoch: 5| Step: 4
Training loss: 3.9651067637131843
Validation loss: 3.2285786903531166

Epoch: 5| Step: 5
Training loss: 3.3381883232882896
Validation loss: 3.226574403811921

Epoch: 5| Step: 6
Training loss: 3.4728381835515028
Validation loss: 3.2270243662080293

Epoch: 5| Step: 7
Training loss: 3.1463514663406014
Validation loss: 3.227185662177235

Epoch: 5| Step: 8
Training loss: 3.1555093330555968
Validation loss: 3.2221109437403928

Epoch: 5| Step: 9
Training loss: 4.048367376099312
Validation loss: 3.2260932901995076

Epoch: 5| Step: 10
Training loss: 3.7290793183111375
Validation loss: 3.2249909240157417

Epoch: 85| Step: 0
Training loss: 3.7859422558523574
Validation loss: 3.2238108593449497

Epoch: 5| Step: 1
Training loss: 3.5856711427918886
Validation loss: 3.222512926958667

Epoch: 5| Step: 2
Training loss: 3.426818760144804
Validation loss: 3.2228157751251603

Epoch: 5| Step: 3
Training loss: 3.0498236057990726
Validation loss: 3.226998769615164

Epoch: 5| Step: 4
Training loss: 3.862011831106419
Validation loss: 3.2246520372755656

Epoch: 5| Step: 5
Training loss: 3.5751243569679705
Validation loss: 3.2227466603135833

Epoch: 5| Step: 6
Training loss: 3.4827737593004344
Validation loss: 3.225533066516765

Epoch: 5| Step: 7
Training loss: 3.4179204795698634
Validation loss: 3.2257258766632395

Epoch: 5| Step: 8
Training loss: 2.918333140630478
Validation loss: 3.2250753682779765

Epoch: 5| Step: 9
Training loss: 3.613287584453907
Validation loss: 3.223115086362535

Epoch: 5| Step: 10
Training loss: 3.240208180179681
Validation loss: 3.224596986918075

Epoch: 86| Step: 0
Training loss: 3.179903440149068
Validation loss: 3.2231626608057544

Epoch: 5| Step: 1
Training loss: 4.084570924223224
Validation loss: 3.225409397074486

Epoch: 5| Step: 2
Training loss: 3.2784071459959017
Validation loss: 3.2263576398138616

Epoch: 5| Step: 3
Training loss: 3.307572064065177
Validation loss: 3.224545328850761

Epoch: 5| Step: 4
Training loss: 3.6689458323628856
Validation loss: 3.2261168548998804

Epoch: 5| Step: 5
Training loss: 3.789857383802587
Validation loss: 3.224918300022739

Epoch: 5| Step: 6
Training loss: 3.1141654832562273
Validation loss: 3.222966339814365

Epoch: 5| Step: 7
Training loss: 3.518321719624048
Validation loss: 3.224382991231269

Epoch: 5| Step: 8
Training loss: 2.726947483985311
Validation loss: 3.2200833187534976

Epoch: 5| Step: 9
Training loss: 3.895939762613269
Validation loss: 3.2232690348253863

Epoch: 5| Step: 10
Training loss: 3.264756958869723
Validation loss: 3.2195573051807687

Epoch: 87| Step: 0
Training loss: 3.3363277019486617
Validation loss: 3.2185286403880715

Epoch: 5| Step: 1
Training loss: 3.545641579618646
Validation loss: 3.218196873539287

Epoch: 5| Step: 2
Training loss: 2.4665759207383244
Validation loss: 3.2194034810281305

Epoch: 5| Step: 3
Training loss: 3.4302453910307915
Validation loss: 3.2188668290068354

Epoch: 5| Step: 4
Training loss: 3.9110729503455706
Validation loss: 3.217166798399051

Epoch: 5| Step: 5
Training loss: 3.1745717277937233
Validation loss: 3.218045966998034

Epoch: 5| Step: 6
Training loss: 3.4373401951490776
Validation loss: 3.2189134714963794

Epoch: 5| Step: 7
Training loss: 4.072989902992386
Validation loss: 3.2175619161003906

Epoch: 5| Step: 8
Training loss: 3.5743749699039795
Validation loss: 3.2208032308593166

Epoch: 5| Step: 9
Training loss: 3.0294637234435
Validation loss: 3.218545241532972

Epoch: 5| Step: 10
Training loss: 3.850750634475514
Validation loss: 3.2173777577288893

Epoch: 88| Step: 0
Training loss: 2.771299241746493
Validation loss: 3.218466823031334

Epoch: 5| Step: 1
Training loss: 3.8424042617694796
Validation loss: 3.21904887774985

Epoch: 5| Step: 2
Training loss: 2.924154443056684
Validation loss: 3.2209544404063326

Epoch: 5| Step: 3
Training loss: 3.0717277856363334
Validation loss: 3.2202081162274987

Epoch: 5| Step: 4
Training loss: 3.334308735869213
Validation loss: 3.22668839278348

Epoch: 5| Step: 5
Training loss: 3.534500921217161
Validation loss: 3.2299755029521817

Epoch: 5| Step: 6
Training loss: 3.556141717264519
Validation loss: 3.2283994564463177

Epoch: 5| Step: 7
Training loss: 3.743017562519262
Validation loss: 3.224904631667017

Epoch: 5| Step: 8
Training loss: 2.726743238519582
Validation loss: 3.2207084979136726

Epoch: 5| Step: 9
Training loss: 3.7949217493486214
Validation loss: 3.2149670372321903

Epoch: 5| Step: 10
Training loss: 4.513801602554831
Validation loss: 3.2158826446887296

Epoch: 89| Step: 0
Training loss: 3.0663244540244974
Validation loss: 3.2132646441897275

Epoch: 5| Step: 1
Training loss: 2.7075962726528475
Validation loss: 3.2151790140006034

Epoch: 5| Step: 2
Training loss: 3.9753359718610404
Validation loss: 3.213607032472604

Epoch: 5| Step: 3
Training loss: 3.273402248001562
Validation loss: 3.2139168730670318

Epoch: 5| Step: 4
Training loss: 3.559383032624757
Validation loss: 3.2168682072124883

Epoch: 5| Step: 5
Training loss: 3.3740647044328753
Validation loss: 3.21532164976017

Epoch: 5| Step: 6
Training loss: 3.6407343639270358
Validation loss: 3.2128866465514268

Epoch: 5| Step: 7
Training loss: 3.3774899375421152
Validation loss: 3.212952793802897

Epoch: 5| Step: 8
Training loss: 3.297000972998733
Validation loss: 3.2135330869934733

Epoch: 5| Step: 9
Training loss: 4.139222335753397
Validation loss: 3.211864505586389

Epoch: 5| Step: 10
Training loss: 3.403772835768728
Validation loss: 3.2080274472581847

Epoch: 90| Step: 0
Training loss: 3.587222598313162
Validation loss: 3.210877660302484

Epoch: 5| Step: 1
Training loss: 3.567750775532601
Validation loss: 3.213227069343372

Epoch: 5| Step: 2
Training loss: 3.327048830646883
Validation loss: 3.212468845322819

Epoch: 5| Step: 3
Training loss: 3.90831036971015
Validation loss: 3.2126569190966654

Epoch: 5| Step: 4
Training loss: 3.042418678720267
Validation loss: 3.208760417824791

Epoch: 5| Step: 5
Training loss: 4.049073789203531
Validation loss: 3.2156499183987455

Epoch: 5| Step: 6
Training loss: 2.7731149405296334
Validation loss: 3.216401241676722

Epoch: 5| Step: 7
Training loss: 3.9733458814060136
Validation loss: 3.2167863344629644

Epoch: 5| Step: 8
Training loss: 3.4479849694316056
Validation loss: 3.218263773557684

Epoch: 5| Step: 9
Training loss: 2.5077883520181814
Validation loss: 3.2209904415194592

Epoch: 5| Step: 10
Training loss: 3.509372695555232
Validation loss: 3.2162375619850097

Epoch: 91| Step: 0
Training loss: 4.277164709794552
Validation loss: 3.21839816365486

Epoch: 5| Step: 1
Training loss: 3.305080814268053
Validation loss: 3.2130390129852797

Epoch: 5| Step: 2
Training loss: 3.37893757888294
Validation loss: 3.2116270595100063

Epoch: 5| Step: 3
Training loss: 3.1029965715060532
Validation loss: 3.214676893595579

Epoch: 5| Step: 4
Training loss: 3.2227130676809503
Validation loss: 3.208617917051009

Epoch: 5| Step: 5
Training loss: 3.182541674560593
Validation loss: 3.207732809369083

Epoch: 5| Step: 6
Training loss: 3.6588597561215463
Validation loss: 3.2049735229057887

Epoch: 5| Step: 7
Training loss: 3.2836190526996205
Validation loss: 3.2065328794063634

Epoch: 5| Step: 8
Training loss: 3.696511459211051
Validation loss: 3.204791879319262

Epoch: 5| Step: 9
Training loss: 3.4956601348153407
Validation loss: 3.204623033173696

Epoch: 5| Step: 10
Training loss: 3.157488287317294
Validation loss: 3.2042348808161

Epoch: 92| Step: 0
Training loss: 4.024054204101732
Validation loss: 3.2055013746004897

Epoch: 5| Step: 1
Training loss: 4.076231301225895
Validation loss: 3.2060826406596874

Epoch: 5| Step: 2
Training loss: 2.740981573138252
Validation loss: 3.2062869093043704

Epoch: 5| Step: 3
Training loss: 3.4347112267172477
Validation loss: 3.2057892202878064

Epoch: 5| Step: 4
Training loss: 3.1590747845314926
Validation loss: 3.2085188204892674

Epoch: 5| Step: 5
Training loss: 3.6464950978183266
Validation loss: 3.2035304811565632

Epoch: 5| Step: 6
Training loss: 3.0038443411411424
Validation loss: 3.203648913476348

Epoch: 5| Step: 7
Training loss: 2.8958346872303675
Validation loss: 3.2055417351739863

Epoch: 5| Step: 8
Training loss: 3.588594536837074
Validation loss: 3.203699768985465

Epoch: 5| Step: 9
Training loss: 3.471734901987088
Validation loss: 3.205339799255944

Epoch: 5| Step: 10
Training loss: 3.6677655538515572
Validation loss: 3.2039250368916146

Epoch: 93| Step: 0
Training loss: 3.453397023805447
Validation loss: 3.2068874236999414

Epoch: 5| Step: 1
Training loss: 2.6672122715055004
Validation loss: 3.2048267293079262

Epoch: 5| Step: 2
Training loss: 2.921934076211772
Validation loss: 3.204258787083675

Epoch: 5| Step: 3
Training loss: 3.471933914083009
Validation loss: 3.201834019965794

Epoch: 5| Step: 4
Training loss: 2.7314663484900104
Validation loss: 3.2001744921342556

Epoch: 5| Step: 5
Training loss: 3.7173755574129275
Validation loss: 3.202438350525119

Epoch: 5| Step: 6
Training loss: 3.798401200102606
Validation loss: 3.2006877599750254

Epoch: 5| Step: 7
Training loss: 3.605216929857082
Validation loss: 3.2009250996951524

Epoch: 5| Step: 8
Training loss: 3.331970428949226
Validation loss: 3.1999612386083816

Epoch: 5| Step: 9
Training loss: 4.046016881978241
Validation loss: 3.2017417147813214

Epoch: 5| Step: 10
Training loss: 3.932978622692681
Validation loss: 3.200606420889778

Epoch: 94| Step: 0
Training loss: 3.099879810095245
Validation loss: 3.201739621745902

Epoch: 5| Step: 1
Training loss: 3.802971235440827
Validation loss: 3.2017543146014367

Epoch: 5| Step: 2
Training loss: 3.820632016290793
Validation loss: 3.202223902785509

Epoch: 5| Step: 3
Training loss: 3.3284919070878507
Validation loss: 3.2009419539200468

Epoch: 5| Step: 4
Training loss: 3.391677341553731
Validation loss: 3.2004007355175923

Epoch: 5| Step: 5
Training loss: 3.902452499814144
Validation loss: 3.1987479256088

Epoch: 5| Step: 6
Training loss: 3.4818882300653304
Validation loss: 3.1987468316276084

Epoch: 5| Step: 7
Training loss: 3.4985798270547455
Validation loss: 3.2020248640780533

Epoch: 5| Step: 8
Training loss: 3.194976714382178
Validation loss: 3.199998906735264

Epoch: 5| Step: 9
Training loss: 3.3500979053367677
Validation loss: 3.199962344191606

Epoch: 5| Step: 10
Training loss: 2.751507345986616
Validation loss: 3.2007473480534796

Epoch: 95| Step: 0
Training loss: 3.997117315109667
Validation loss: 3.197765132842062

Epoch: 5| Step: 1
Training loss: 3.461784999577643
Validation loss: 3.199691633138353

Epoch: 5| Step: 2
Training loss: 3.7360458147723676
Validation loss: 3.1979681915870692

Epoch: 5| Step: 3
Training loss: 3.8468947533256044
Validation loss: 3.1984864029666333

Epoch: 5| Step: 4
Training loss: 2.7176106137220875
Validation loss: 3.2030097442468284

Epoch: 5| Step: 5
Training loss: 3.6257168291283333
Validation loss: 3.1978399792558654

Epoch: 5| Step: 6
Training loss: 3.6861721169518735
Validation loss: 3.1994650158986175

Epoch: 5| Step: 7
Training loss: 2.7822574119691943
Validation loss: 3.1970364269487552

Epoch: 5| Step: 8
Training loss: 2.991562900142709
Validation loss: 3.1976537767097977

Epoch: 5| Step: 9
Training loss: 3.433966467789733
Validation loss: 3.1968179969066766

Epoch: 5| Step: 10
Training loss: 3.300840045473022
Validation loss: 3.197319547131959

Epoch: 96| Step: 0
Training loss: 3.428332502123618
Validation loss: 3.1981531886574524

Epoch: 5| Step: 1
Training loss: 2.9611075561323967
Validation loss: 3.1968069005111133

Epoch: 5| Step: 2
Training loss: 3.275121287655243
Validation loss: 3.197205200662701

Epoch: 5| Step: 3
Training loss: 3.2121748941580344
Validation loss: 3.201827719418082

Epoch: 5| Step: 4
Training loss: 3.657123819901951
Validation loss: 3.2011893894195658

Epoch: 5| Step: 5
Training loss: 3.6285912712721773
Validation loss: 3.204132847532998

Epoch: 5| Step: 6
Training loss: 3.486579915846261
Validation loss: 3.2045459939843246

Epoch: 5| Step: 7
Training loss: 3.5193166381570977
Validation loss: 3.2010968734397003

Epoch: 5| Step: 8
Training loss: 3.54955791890733
Validation loss: 3.1960863815536587

Epoch: 5| Step: 9
Training loss: 3.934008548992974
Validation loss: 3.194047595806929

Epoch: 5| Step: 10
Training loss: 3.021726769931249
Validation loss: 3.196274363771132

Epoch: 97| Step: 0
Training loss: 3.8862254074069473
Validation loss: 3.193708989706234

Epoch: 5| Step: 1
Training loss: 3.470009652379927
Validation loss: 3.1931019905866767

Epoch: 5| Step: 2
Training loss: 3.55342337799017
Validation loss: 3.1918341783198496

Epoch: 5| Step: 3
Training loss: 2.9536600586915163
Validation loss: 3.192796677258432

Epoch: 5| Step: 4
Training loss: 2.894981277220802
Validation loss: 3.1927035936810455

Epoch: 5| Step: 5
Training loss: 3.4791783467780095
Validation loss: 3.1921536027717603

Epoch: 5| Step: 6
Training loss: 4.148374510320983
Validation loss: 3.1918113034639366

Epoch: 5| Step: 7
Training loss: 2.8448427217852195
Validation loss: 3.1922489044406603

Epoch: 5| Step: 8
Training loss: 2.9015883929895265
Validation loss: 3.1911173286673153

Epoch: 5| Step: 9
Training loss: 3.9266986742857792
Validation loss: 3.1909907346852737

Epoch: 5| Step: 10
Training loss: 3.471358134941624
Validation loss: 3.188674787478343

Epoch: 98| Step: 0
Training loss: 3.3132557996380916
Validation loss: 3.191943684602503

Epoch: 5| Step: 1
Training loss: 3.308196385109072
Validation loss: 3.1893620449984796

Epoch: 5| Step: 2
Training loss: 3.6770533631628024
Validation loss: 3.189918716729275

Epoch: 5| Step: 3
Training loss: 3.522463238797072
Validation loss: 3.1884099589200336

Epoch: 5| Step: 4
Training loss: 3.529512771395279
Validation loss: 3.189135315940067

Epoch: 5| Step: 5
Training loss: 3.424777398219621
Validation loss: 3.1905411189943074

Epoch: 5| Step: 6
Training loss: 3.2391438732976012
Validation loss: 3.1906378138667137

Epoch: 5| Step: 7
Training loss: 3.1422556728894855
Validation loss: 3.1896079820396523

Epoch: 5| Step: 8
Training loss: 3.4990456506150203
Validation loss: 3.1995599235162215

Epoch: 5| Step: 9
Training loss: 3.3891843204931136
Validation loss: 3.2044062819294528

Epoch: 5| Step: 10
Training loss: 3.7812259137355926
Validation loss: 3.213061460647259

Epoch: 99| Step: 0
Training loss: 3.342634068313257
Validation loss: 3.201581081946084

Epoch: 5| Step: 1
Training loss: 3.932689089197116
Validation loss: 3.1876252624490533

Epoch: 5| Step: 2
Training loss: 3.3850256747873755
Validation loss: 3.1863543876428304

Epoch: 5| Step: 3
Training loss: 3.5768083707025093
Validation loss: 3.1859505080414317

Epoch: 5| Step: 4
Training loss: 3.3654068134959116
Validation loss: 3.1864857050119033

Epoch: 5| Step: 5
Training loss: 2.991238515778434
Validation loss: 3.1853491394701314

Epoch: 5| Step: 6
Training loss: 2.9041515691101156
Validation loss: 3.1847204176953787

Epoch: 5| Step: 7
Training loss: 3.0403025629659695
Validation loss: 3.1868375781158353

Epoch: 5| Step: 8
Training loss: 3.6899823384262898
Validation loss: 3.187888953139714

Epoch: 5| Step: 9
Training loss: 3.8860623366087155
Validation loss: 3.1891889028717375

Epoch: 5| Step: 10
Training loss: 3.594948742836683
Validation loss: 3.1896611913126076

Epoch: 100| Step: 0
Training loss: 3.294161434643894
Validation loss: 3.18879901974257

Epoch: 5| Step: 1
Training loss: 3.3048737746241885
Validation loss: 3.184281403720655

Epoch: 5| Step: 2
Training loss: 3.5785774044903933
Validation loss: 3.1906404862681836

Epoch: 5| Step: 3
Training loss: 3.152574268407053
Validation loss: 3.192024789051362

Epoch: 5| Step: 4
Training loss: 3.7932742277701768
Validation loss: 3.186847062527066

Epoch: 5| Step: 5
Training loss: 3.2189511726992195
Validation loss: 3.193655123811587

Epoch: 5| Step: 6
Training loss: 3.3103686979614326
Validation loss: 3.1837119673343404

Epoch: 5| Step: 7
Training loss: 3.4949083076640926
Validation loss: 3.1827389659006102

Epoch: 5| Step: 8
Training loss: 3.6706169408147575
Validation loss: 3.182032662195702

Epoch: 5| Step: 9
Training loss: 3.4798727327950076
Validation loss: 3.1803595501961786

Epoch: 5| Step: 10
Training loss: 3.488636917145843
Validation loss: 3.1821781314955326

Epoch: 101| Step: 0
Training loss: 2.971520827375581
Validation loss: 3.182180736884068

Epoch: 5| Step: 1
Training loss: 4.034119050810633
Validation loss: 3.180596284566296

Epoch: 5| Step: 2
Training loss: 3.380020081499927
Validation loss: 3.179723176607123

Epoch: 5| Step: 3
Training loss: 2.4193881156642747
Validation loss: 3.181864786146362

Epoch: 5| Step: 4
Training loss: 3.2940369453882887
Validation loss: 3.1804432094502224

Epoch: 5| Step: 5
Training loss: 2.7528061854281076
Validation loss: 3.1800946329784128

Epoch: 5| Step: 6
Training loss: 3.8305148391705086
Validation loss: 3.1787231221274324

Epoch: 5| Step: 7
Training loss: 3.3148380880961543
Validation loss: 3.1799330340296117

Epoch: 5| Step: 8
Training loss: 3.80919266124316
Validation loss: 3.1803621465954177

Epoch: 5| Step: 9
Training loss: 4.0115982230707905
Validation loss: 3.180852698239388

Epoch: 5| Step: 10
Training loss: 3.58041481811471
Validation loss: 3.181443976273247

Epoch: 102| Step: 0
Training loss: 3.027073765682915
Validation loss: 3.180266208195355

Epoch: 5| Step: 1
Training loss: 3.8220932131688476
Validation loss: 3.1785018301428676

Epoch: 5| Step: 2
Training loss: 3.4519347474085036
Validation loss: 3.177803177214183

Epoch: 5| Step: 3
Training loss: 2.9761552507041604
Validation loss: 3.178281782678951

Epoch: 5| Step: 4
Training loss: 2.884754715513393
Validation loss: 3.178359297159312

Epoch: 5| Step: 5
Training loss: 2.9273594265618073
Validation loss: 3.177124904856172

Epoch: 5| Step: 6
Training loss: 3.175397748888706
Validation loss: 3.1778059184938146

Epoch: 5| Step: 7
Training loss: 3.7104621663089175
Validation loss: 3.1758167832100375

Epoch: 5| Step: 8
Training loss: 3.5377012754946158
Validation loss: 3.1767279663057804

Epoch: 5| Step: 9
Training loss: 3.8476496817440764
Validation loss: 3.1767273045602473

Epoch: 5| Step: 10
Training loss: 4.198510568917798
Validation loss: 3.1763230588020086

Epoch: 103| Step: 0
Training loss: 2.9166361307634694
Validation loss: 3.175951308221983

Epoch: 5| Step: 1
Training loss: 3.9694337030658
Validation loss: 3.1778572827634726

Epoch: 5| Step: 2
Training loss: 4.014385343749446
Validation loss: 3.175752226100258

Epoch: 5| Step: 3
Training loss: 3.423307772067087
Validation loss: 3.1756863211497732

Epoch: 5| Step: 4
Training loss: 2.891073985928803
Validation loss: 3.177402836257125

Epoch: 5| Step: 5
Training loss: 3.009693538488209
Validation loss: 3.175796437513178

Epoch: 5| Step: 6
Training loss: 4.0115490128101055
Validation loss: 3.1788491255985694

Epoch: 5| Step: 7
Training loss: 3.4378039139001584
Validation loss: 3.1739877005091683

Epoch: 5| Step: 8
Training loss: 3.0112147521809933
Validation loss: 3.1733474574955722

Epoch: 5| Step: 9
Training loss: 3.5998549644076645
Validation loss: 3.1744062506571384

Epoch: 5| Step: 10
Training loss: 3.072320257381384
Validation loss: 3.175944296032996

Epoch: 104| Step: 0
Training loss: 3.523267788405173
Validation loss: 3.175326698528277

Epoch: 5| Step: 1
Training loss: 3.4612507904371443
Validation loss: 3.1738306823164844

Epoch: 5| Step: 2
Training loss: 3.2045621299678713
Validation loss: 3.1740006770453557

Epoch: 5| Step: 3
Training loss: 3.12319619571501
Validation loss: 3.1728546813499663

Epoch: 5| Step: 4
Training loss: 4.044590131932672
Validation loss: 3.172582704493654

Epoch: 5| Step: 5
Training loss: 3.9673483468525217
Validation loss: 3.173010528641044

Epoch: 5| Step: 6
Training loss: 3.158135181609138
Validation loss: 3.17326068984736

Epoch: 5| Step: 7
Training loss: 3.6970430157000505
Validation loss: 3.173320528772189

Epoch: 5| Step: 8
Training loss: 3.420111632951203
Validation loss: 3.1734555788705094

Epoch: 5| Step: 9
Training loss: 2.8051618849606847
Validation loss: 3.172651514997539

Epoch: 5| Step: 10
Training loss: 2.9640143921949287
Validation loss: 3.1748435520226104

Epoch: 105| Step: 0
Training loss: 3.264724388231834
Validation loss: 3.1719822631331973

Epoch: 5| Step: 1
Training loss: 3.6648998483085897
Validation loss: 3.1740890721278188

Epoch: 5| Step: 2
Training loss: 3.1196629535359346
Validation loss: 3.1720342955270557

Epoch: 5| Step: 3
Training loss: 3.843702734679862
Validation loss: 3.170164497232311

Epoch: 5| Step: 4
Training loss: 3.883476952665269
Validation loss: 3.1743402240786223

Epoch: 5| Step: 5
Training loss: 3.224276048887364
Validation loss: 3.171440744207074

Epoch: 5| Step: 6
Training loss: 3.6395913158752093
Validation loss: 3.170679503703939

Epoch: 5| Step: 7
Training loss: 2.9963518849644935
Validation loss: 3.1719589266748365

Epoch: 5| Step: 8
Training loss: 3.7989464905643757
Validation loss: 3.172637476017608

Epoch: 5| Step: 9
Training loss: 3.3429297751383213
Validation loss: 3.1700929753718614

Epoch: 5| Step: 10
Training loss: 2.4844874710439604
Validation loss: 3.171263930050426

Epoch: 106| Step: 0
Training loss: 3.354645278302507
Validation loss: 3.1726570969575643

Epoch: 5| Step: 1
Training loss: 3.1355221414832086
Validation loss: 3.1705833256833147

Epoch: 5| Step: 2
Training loss: 3.2381250139010778
Validation loss: 3.169518823813717

Epoch: 5| Step: 3
Training loss: 3.9292059844157765
Validation loss: 3.1683535856431786

Epoch: 5| Step: 4
Training loss: 3.80031815752967
Validation loss: 3.1729541484321113

Epoch: 5| Step: 5
Training loss: 3.8027134342724014
Validation loss: 3.169357036681766

Epoch: 5| Step: 6
Training loss: 3.4799534408699433
Validation loss: 3.1682658283736957

Epoch: 5| Step: 7
Training loss: 2.42884993759354
Validation loss: 3.165958212492304

Epoch: 5| Step: 8
Training loss: 3.2940218905547822
Validation loss: 3.1674665359446625

Epoch: 5| Step: 9
Training loss: 3.1935696127277216
Validation loss: 3.16630983015264

Epoch: 5| Step: 10
Training loss: 3.7564707559467574
Validation loss: 3.1658464145534015

Epoch: 107| Step: 0
Training loss: 3.6741827023534688
Validation loss: 3.1668506389688713

Epoch: 5| Step: 1
Training loss: 3.887268702258954
Validation loss: 3.1683141964782653

Epoch: 5| Step: 2
Training loss: 3.790817263413942
Validation loss: 3.1680177635468816

Epoch: 5| Step: 3
Training loss: 3.5949882696010755
Validation loss: 3.1635542963403154

Epoch: 5| Step: 4
Training loss: 2.930322522323928
Validation loss: 3.1639963677616496

Epoch: 5| Step: 5
Training loss: 3.8021627896859522
Validation loss: 3.1663437960995076

Epoch: 5| Step: 6
Training loss: 3.3056346356703514
Validation loss: 3.1666741692195632

Epoch: 5| Step: 7
Training loss: 2.9379900259805565
Validation loss: 3.166303628945586

Epoch: 5| Step: 8
Training loss: 2.535385427123183
Validation loss: 3.1652011286583974

Epoch: 5| Step: 9
Training loss: 3.9416242525965393
Validation loss: 3.1687954163108585

Epoch: 5| Step: 10
Training loss: 2.718190804336461
Validation loss: 3.1659483132600137

Epoch: 108| Step: 0
Training loss: 3.6328740596682736
Validation loss: 3.166169349875878

Epoch: 5| Step: 1
Training loss: 4.034430616779935
Validation loss: 3.168546289346138

Epoch: 5| Step: 2
Training loss: 2.7631424791102033
Validation loss: 3.164956411962817

Epoch: 5| Step: 3
Training loss: 3.56272539463103
Validation loss: 3.163294159394576

Epoch: 5| Step: 4
Training loss: 3.6977276964214556
Validation loss: 3.1651740034649958

Epoch: 5| Step: 5
Training loss: 3.3193385232778985
Validation loss: 3.161107446316965

Epoch: 5| Step: 6
Training loss: 3.4509941880014976
Validation loss: 3.163371882286819

Epoch: 5| Step: 7
Training loss: 3.4478508212130285
Validation loss: 3.1619484005943383

Epoch: 5| Step: 8
Training loss: 2.2151071435576624
Validation loss: 3.1626916254929083

Epoch: 5| Step: 9
Training loss: 3.5966487969162872
Validation loss: 3.1627391872108

Epoch: 5| Step: 10
Training loss: 3.550124507386232
Validation loss: 3.1600680476668783

Epoch: 109| Step: 0
Training loss: 4.0020517809032965
Validation loss: 3.1617633170860215

Epoch: 5| Step: 1
Training loss: 2.714475845547046
Validation loss: 3.1622230156542104

Epoch: 5| Step: 2
Training loss: 2.982074430021653
Validation loss: 3.1618009067666684

Epoch: 5| Step: 3
Training loss: 3.763113870317581
Validation loss: 3.162894664844707

Epoch: 5| Step: 4
Training loss: 3.1107184033572297
Validation loss: 3.161119925875126

Epoch: 5| Step: 5
Training loss: 3.5626909974413317
Validation loss: 3.1602158511356535

Epoch: 5| Step: 6
Training loss: 3.4787975884546642
Validation loss: 3.16075474947903

Epoch: 5| Step: 7
Training loss: 3.6069811524400315
Validation loss: 3.1613721632895695

Epoch: 5| Step: 8
Training loss: 3.850968197049607
Validation loss: 3.159755086534446

Epoch: 5| Step: 9
Training loss: 2.8216746414381317
Validation loss: 3.161776583796989

Epoch: 5| Step: 10
Training loss: 3.407469784776892
Validation loss: 3.162020099380416

Epoch: 110| Step: 0
Training loss: 4.198700685702676
Validation loss: 3.1623926096739696

Epoch: 5| Step: 1
Training loss: 3.7906148660371803
Validation loss: 3.161482693890405

Epoch: 5| Step: 2
Training loss: 3.230286598836103
Validation loss: 3.161814327374415

Epoch: 5| Step: 3
Training loss: 2.9965619413968283
Validation loss: 3.1587543849001665

Epoch: 5| Step: 4
Training loss: 3.6815089032719457
Validation loss: 3.1567314785451166

Epoch: 5| Step: 5
Training loss: 3.319640183541155
Validation loss: 3.1573647863845085

Epoch: 5| Step: 6
Training loss: 3.4751667778555797
Validation loss: 3.1585760124048394

Epoch: 5| Step: 7
Training loss: 2.65356974294558
Validation loss: 3.1583826476212136

Epoch: 5| Step: 8
Training loss: 3.646461098529754
Validation loss: 3.1581206941357607

Epoch: 5| Step: 9
Training loss: 3.2703054370612485
Validation loss: 3.15645649942224

Epoch: 5| Step: 10
Training loss: 2.938747709168742
Validation loss: 3.1565853798845156

Epoch: 111| Step: 0
Training loss: 3.890985801543421
Validation loss: 3.155119503512846

Epoch: 5| Step: 1
Training loss: 3.1212763154032306
Validation loss: 3.1571511990600394

Epoch: 5| Step: 2
Training loss: 3.9376255802534237
Validation loss: 3.1560978600494654

Epoch: 5| Step: 3
Training loss: 3.3800315085753865
Validation loss: 3.1573488216693035

Epoch: 5| Step: 4
Training loss: 3.4187584188242575
Validation loss: 3.15555538468469

Epoch: 5| Step: 5
Training loss: 3.4568596576411594
Validation loss: 3.1560171637014633

Epoch: 5| Step: 6
Training loss: 3.4078098190416006
Validation loss: 3.1558912819216043

Epoch: 5| Step: 7
Training loss: 3.2254697413221938
Validation loss: 3.1543430288545955

Epoch: 5| Step: 8
Training loss: 3.015692043053328
Validation loss: 3.1551485465804774

Epoch: 5| Step: 9
Training loss: 3.1917050617455045
Validation loss: 3.154245400155598

Epoch: 5| Step: 10
Training loss: 3.3294173762548334
Validation loss: 3.1572457108217757

Epoch: 112| Step: 0
Training loss: 3.535686845108713
Validation loss: 3.154334700762175

Epoch: 5| Step: 1
Training loss: 3.484906211696563
Validation loss: 3.1610134928342024

Epoch: 5| Step: 2
Training loss: 3.633564270333005
Validation loss: 3.159296372643073

Epoch: 5| Step: 3
Training loss: 3.1195940179048702
Validation loss: 3.158863668007579

Epoch: 5| Step: 4
Training loss: 2.5655018970911465
Validation loss: 3.161053993219982

Epoch: 5| Step: 5
Training loss: 3.131768792398789
Validation loss: 3.154858547552801

Epoch: 5| Step: 6
Training loss: 2.58923461562976
Validation loss: 3.15192551705196

Epoch: 5| Step: 7
Training loss: 3.711848161288516
Validation loss: 3.153506484179704

Epoch: 5| Step: 8
Training loss: 3.7864724657021482
Validation loss: 3.151744439065069

Epoch: 5| Step: 9
Training loss: 3.8360542232989037
Validation loss: 3.1515519688547684

Epoch: 5| Step: 10
Training loss: 3.854703230066139
Validation loss: 3.1515724092452877

Epoch: 113| Step: 0
Training loss: 3.5262527890956683
Validation loss: 3.148933972626519

Epoch: 5| Step: 1
Training loss: 3.635637526193005
Validation loss: 3.1479449151328645

Epoch: 5| Step: 2
Training loss: 3.5142272883442054
Validation loss: 3.150839735961289

Epoch: 5| Step: 3
Training loss: 2.8483000185919045
Validation loss: 3.149831437371494

Epoch: 5| Step: 4
Training loss: 3.9850811500854175
Validation loss: 3.150587203751513

Epoch: 5| Step: 5
Training loss: 4.075236382678559
Validation loss: 3.1513537191472074

Epoch: 5| Step: 6
Training loss: 3.0341716725734984
Validation loss: 3.1500742088232183

Epoch: 5| Step: 7
Training loss: 2.682159262540416
Validation loss: 3.148692225446653

Epoch: 5| Step: 8
Training loss: 3.5760532028200327
Validation loss: 3.1492040274033966

Epoch: 5| Step: 9
Training loss: 3.168116404976458
Validation loss: 3.1506676502342983

Epoch: 5| Step: 10
Training loss: 3.079910457597566
Validation loss: 3.1494643684573704

Epoch: 114| Step: 0
Training loss: 3.9102171017602014
Validation loss: 3.150628243382732

Epoch: 5| Step: 1
Training loss: 2.8355208161729646
Validation loss: 3.157202058130168

Epoch: 5| Step: 2
Training loss: 3.6275268166705623
Validation loss: 3.1513836559729933

Epoch: 5| Step: 3
Training loss: 3.2565543766504277
Validation loss: 3.15146461413829

Epoch: 5| Step: 4
Training loss: 3.268475178531387
Validation loss: 3.1505576304096174

Epoch: 5| Step: 5
Training loss: 3.0068145285349392
Validation loss: 3.150171470369904

Epoch: 5| Step: 6
Training loss: 4.377525036891097
Validation loss: 3.149922115667195

Epoch: 5| Step: 7
Training loss: 3.147817848887993
Validation loss: 3.1490529033303307

Epoch: 5| Step: 8
Training loss: 3.516751935265599
Validation loss: 3.1494102220193096

Epoch: 5| Step: 9
Training loss: 2.935445838351895
Validation loss: 3.146432294885796

Epoch: 5| Step: 10
Training loss: 3.2202133259686527
Validation loss: 3.150090745906957

Epoch: 115| Step: 0
Training loss: 3.5040077696587804
Validation loss: 3.147615126301808

Epoch: 5| Step: 1
Training loss: 4.424299566146146
Validation loss: 3.1505460252544757

Epoch: 5| Step: 2
Training loss: 3.001984734452564
Validation loss: 3.1485314884058826

Epoch: 5| Step: 3
Training loss: 3.4983391227026064
Validation loss: 3.1470594314180165

Epoch: 5| Step: 4
Training loss: 2.55859943418381
Validation loss: 3.145641798352045

Epoch: 5| Step: 5
Training loss: 2.4684391067408864
Validation loss: 3.1452812020513576

Epoch: 5| Step: 6
Training loss: 3.026079310031478
Validation loss: 3.146944523039789

Epoch: 5| Step: 7
Training loss: 3.300499970679824
Validation loss: 3.147346651427714

Epoch: 5| Step: 8
Training loss: 3.446563147706412
Validation loss: 3.1447674002686323

Epoch: 5| Step: 9
Training loss: 3.7574707637215448
Validation loss: 3.1453490318762727

Epoch: 5| Step: 10
Training loss: 4.035895221767888
Validation loss: 3.146109023655862

Epoch: 116| Step: 0
Training loss: 2.7763568825652936
Validation loss: 3.1466005776842945

Epoch: 5| Step: 1
Training loss: 3.049595640299864
Validation loss: 3.145875964860238

Epoch: 5| Step: 2
Training loss: 3.8725647195785147
Validation loss: 3.1499440975212796

Epoch: 5| Step: 3
Training loss: 3.594869953291649
Validation loss: 3.1470670496847597

Epoch: 5| Step: 4
Training loss: 3.4499805339319347
Validation loss: 3.1462333901286006

Epoch: 5| Step: 5
Training loss: 3.0293326065248416
Validation loss: 3.1459925534585707

Epoch: 5| Step: 6
Training loss: 3.7918791379539756
Validation loss: 3.1463964379756924

Epoch: 5| Step: 7
Training loss: 2.8266273874876595
Validation loss: 3.143979149896945

Epoch: 5| Step: 8
Training loss: 3.775536247716966
Validation loss: 3.145896305224611

Epoch: 5| Step: 9
Training loss: 3.2208846337763606
Validation loss: 3.145065097005685

Epoch: 5| Step: 10
Training loss: 3.832763104250726
Validation loss: 3.1454724813381274

Epoch: 117| Step: 0
Training loss: 4.111909846018892
Validation loss: 3.1420519803177345

Epoch: 5| Step: 1
Training loss: 2.663317086652045
Validation loss: 3.1423113793148088

Epoch: 5| Step: 2
Training loss: 3.6227020346335803
Validation loss: 3.1438736924301685

Epoch: 5| Step: 3
Training loss: 3.7149172995232833
Validation loss: 3.142551816105428

Epoch: 5| Step: 4
Training loss: 3.4221336232175754
Validation loss: 3.143635946776221

Epoch: 5| Step: 5
Training loss: 3.2688937095429624
Validation loss: 3.142758755514936

Epoch: 5| Step: 6
Training loss: 3.201937869525312
Validation loss: 3.1403573732888153

Epoch: 5| Step: 7
Training loss: 3.7044021400009677
Validation loss: 3.141544430099007

Epoch: 5| Step: 8
Training loss: 2.446448698945528
Validation loss: 3.1411450667197593

Epoch: 5| Step: 9
Training loss: 3.1731074903033982
Validation loss: 3.1418611749324534

Epoch: 5| Step: 10
Training loss: 3.7384441344232515
Validation loss: 3.1404196506204434

Epoch: 118| Step: 0
Training loss: 2.6695513520504024
Validation loss: 3.138901300091469

Epoch: 5| Step: 1
Training loss: 3.972325914240335
Validation loss: 3.1417406827158367

Epoch: 5| Step: 2
Training loss: 3.587237884834935
Validation loss: 3.1390775736419387

Epoch: 5| Step: 3
Training loss: 3.4532988491570427
Validation loss: 3.141050227207395

Epoch: 5| Step: 4
Training loss: 3.3130023503408896
Validation loss: 3.138467150958789

Epoch: 5| Step: 5
Training loss: 3.205171852205877
Validation loss: 3.1421555603805666

Epoch: 5| Step: 6
Training loss: 3.5362139895059572
Validation loss: 3.139198796900971

Epoch: 5| Step: 7
Training loss: 3.5138021532963073
Validation loss: 3.13760583082412

Epoch: 5| Step: 8
Training loss: 3.2767748151325433
Validation loss: 3.1380633651240015

Epoch: 5| Step: 9
Training loss: 3.368674673395426
Validation loss: 3.137583357259239

Epoch: 5| Step: 10
Training loss: 3.2885105276984734
Validation loss: 3.1372742066394137

Epoch: 119| Step: 0
Training loss: 3.8816396373322557
Validation loss: 3.138452694405866

Epoch: 5| Step: 1
Training loss: 3.2433149101097376
Validation loss: 3.1372554528663734

Epoch: 5| Step: 2
Training loss: 3.5970267574533623
Validation loss: 3.137670752008481

Epoch: 5| Step: 3
Training loss: 2.5156048128253974
Validation loss: 3.138906311554041

Epoch: 5| Step: 4
Training loss: 3.0938925662088974
Validation loss: 3.1385952483998536

Epoch: 5| Step: 5
Training loss: 2.657769968812727
Validation loss: 3.140248728683134

Epoch: 5| Step: 6
Training loss: 3.8487262303113
Validation loss: 3.1388685718425395

Epoch: 5| Step: 7
Training loss: 3.8207224994476694
Validation loss: 3.1379961866124786

Epoch: 5| Step: 8
Training loss: 4.05127515145333
Validation loss: 3.1384473946877867

Epoch: 5| Step: 9
Training loss: 3.180905270587935
Validation loss: 3.1369917735715798

Epoch: 5| Step: 10
Training loss: 2.9768436329158345
Validation loss: 3.1393299227324967

Epoch: 120| Step: 0
Training loss: 3.2732321007866396
Validation loss: 3.1414532814816476

Epoch: 5| Step: 1
Training loss: 3.2104080394816266
Validation loss: 3.1367096305519166

Epoch: 5| Step: 2
Training loss: 3.4533152808327547
Validation loss: 3.135920921111124

Epoch: 5| Step: 3
Training loss: 3.415629780060127
Validation loss: 3.1369446697731007

Epoch: 5| Step: 4
Training loss: 3.178210616107264
Validation loss: 3.134622298999408

Epoch: 5| Step: 5
Training loss: 3.428565048030184
Validation loss: 3.133989923546008

Epoch: 5| Step: 6
Training loss: 3.3859337201557267
Validation loss: 3.135814166638742

Epoch: 5| Step: 7
Training loss: 3.394812604089116
Validation loss: 3.134213270428455

Epoch: 5| Step: 8
Training loss: 2.5863817645838036
Validation loss: 3.1343656171041703

Epoch: 5| Step: 9
Training loss: 4.073438033794197
Validation loss: 3.1345430257479796

Epoch: 5| Step: 10
Training loss: 3.7630815582479578
Validation loss: 3.1315812228146576

Epoch: 121| Step: 0
Training loss: 3.4620183286043957
Validation loss: 3.1328567740294377

Epoch: 5| Step: 1
Training loss: 3.846058966126605
Validation loss: 3.1338046334952567

Epoch: 5| Step: 2
Training loss: 3.8877397126012707
Validation loss: 3.1319896611757705

Epoch: 5| Step: 3
Training loss: 2.943329404034121
Validation loss: 3.132305695198735

Epoch: 5| Step: 4
Training loss: 2.865188109395556
Validation loss: 3.130883731813444

Epoch: 5| Step: 5
Training loss: 3.283212274814362
Validation loss: 3.1331292749886663

Epoch: 5| Step: 6
Training loss: 2.9748190432098136
Validation loss: 3.1329472480890233

Epoch: 5| Step: 7
Training loss: 3.8379931254203576
Validation loss: 3.132868732754475

Epoch: 5| Step: 8
Training loss: 3.5128043154914774
Validation loss: 3.1308626388534737

Epoch: 5| Step: 9
Training loss: 3.2048832231454276
Validation loss: 3.1324995852946604

Epoch: 5| Step: 10
Training loss: 3.224498467296982
Validation loss: 3.132397755738188

Epoch: 122| Step: 0
Training loss: 3.634499828658216
Validation loss: 3.1326211678538414

Epoch: 5| Step: 1
Training loss: 2.796840646202469
Validation loss: 3.1304526334120184

Epoch: 5| Step: 2
Training loss: 3.3614021749723997
Validation loss: 3.133706978499499

Epoch: 5| Step: 3
Training loss: 2.821325400261401
Validation loss: 3.130193813521598

Epoch: 5| Step: 4
Training loss: 4.0896373795086065
Validation loss: 3.1299537477493344

Epoch: 5| Step: 5
Training loss: 3.3812239443185805
Validation loss: 3.1299292575615985

Epoch: 5| Step: 6
Training loss: 3.1465792413732743
Validation loss: 3.128181275516791

Epoch: 5| Step: 7
Training loss: 3.505001309512951
Validation loss: 3.1296920605871694

Epoch: 5| Step: 8
Training loss: 3.204953746253602
Validation loss: 3.1291518230279243

Epoch: 5| Step: 9
Training loss: 3.54524253887147
Validation loss: 3.128307954370568

Epoch: 5| Step: 10
Training loss: 3.5934274279908336
Validation loss: 3.1283865251678646

Epoch: 123| Step: 0
Training loss: 2.6831756221635135
Validation loss: 3.1278750576290624

Epoch: 5| Step: 1
Training loss: 3.4883107764007932
Validation loss: 3.1282229516541196

Epoch: 5| Step: 2
Training loss: 3.9565164244315825
Validation loss: 3.1295059991660525

Epoch: 5| Step: 3
Training loss: 3.8120124380062888
Validation loss: 3.128341551949805

Epoch: 5| Step: 4
Training loss: 3.7893554574247643
Validation loss: 3.1330051280554914

Epoch: 5| Step: 5
Training loss: 2.9810244940794695
Validation loss: 3.1309399951152135

Epoch: 5| Step: 6
Training loss: 3.7657651756440234
Validation loss: 3.130751790392895

Epoch: 5| Step: 7
Training loss: 3.3645877582217825
Validation loss: 3.1318439038556556

Epoch: 5| Step: 8
Training loss: 3.451222167325973
Validation loss: 3.131749455560707

Epoch: 5| Step: 9
Training loss: 2.595160227332753
Validation loss: 3.126645080548653

Epoch: 5| Step: 10
Training loss: 2.96678964238544
Validation loss: 3.127029142448352

Epoch: 124| Step: 0
Training loss: 3.536459262194205
Validation loss: 3.125366799762332

Epoch: 5| Step: 1
Training loss: 3.5707815183591767
Validation loss: 3.1258785038428587

Epoch: 5| Step: 2
Training loss: 2.7163459409086537
Validation loss: 3.126553586944972

Epoch: 5| Step: 3
Training loss: 3.0201721695586916
Validation loss: 3.12441598828997

Epoch: 5| Step: 4
Training loss: 3.133475597344398
Validation loss: 3.1247355917364605

Epoch: 5| Step: 5
Training loss: 3.4373915221697646
Validation loss: 3.126305366158329

Epoch: 5| Step: 6
Training loss: 3.7660615913269355
Validation loss: 3.126102361365853

Epoch: 5| Step: 7
Training loss: 3.357050175532454
Validation loss: 3.123121389316246

Epoch: 5| Step: 8
Training loss: 3.2459885709870444
Validation loss: 3.1258793174161235

Epoch: 5| Step: 9
Training loss: 3.3848666326262404
Validation loss: 3.1241402852439353

Epoch: 5| Step: 10
Training loss: 3.9589795572244983
Validation loss: 3.1260004308530456

Epoch: 125| Step: 0
Training loss: 3.5384437407489346
Validation loss: 3.122963515363053

Epoch: 5| Step: 1
Training loss: 3.2182287886747396
Validation loss: 3.124205941661515

Epoch: 5| Step: 2
Training loss: 3.2800171488802072
Validation loss: 3.1229543032100766

Epoch: 5| Step: 3
Training loss: 3.1901404719979185
Validation loss: 3.123984894314084

Epoch: 5| Step: 4
Training loss: 4.013627204739255
Validation loss: 3.123710013316764

Epoch: 5| Step: 5
Training loss: 2.835110966900787
Validation loss: 3.1227918292672507

Epoch: 5| Step: 6
Training loss: 2.9403883349280013
Validation loss: 3.1231620256502803

Epoch: 5| Step: 7
Training loss: 3.8892626234637926
Validation loss: 3.1220269529960203

Epoch: 5| Step: 8
Training loss: 3.1364873703383522
Validation loss: 3.1219151580949753

Epoch: 5| Step: 9
Training loss: 3.5275732833852396
Validation loss: 3.120895783383204

Epoch: 5| Step: 10
Training loss: 3.442953742548342
Validation loss: 3.121375195404965

Epoch: 126| Step: 0
Training loss: 3.7679457734775954
Validation loss: 3.1217375150975957

Epoch: 5| Step: 1
Training loss: 3.3029923656905504
Validation loss: 3.120467369369799

Epoch: 5| Step: 2
Training loss: 3.0664588097605368
Validation loss: 3.1211376317239976

Epoch: 5| Step: 3
Training loss: 3.536700473112083
Validation loss: 3.1223765216488033

Epoch: 5| Step: 4
Training loss: 4.629641085857769
Validation loss: 3.121404146718939

Epoch: 5| Step: 5
Training loss: 2.7115324835079244
Validation loss: 3.1190980655910607

Epoch: 5| Step: 6
Training loss: 2.9388958475582987
Validation loss: 3.1237629170762484

Epoch: 5| Step: 7
Training loss: 3.122760122564821
Validation loss: 3.122863506802793

Epoch: 5| Step: 8
Training loss: 3.3515374598423575
Validation loss: 3.1204581383459247

Epoch: 5| Step: 9
Training loss: 3.4868305944803932
Validation loss: 3.118941220924165

Epoch: 5| Step: 10
Training loss: 2.726212530984905
Validation loss: 3.1187876752735986

Epoch: 127| Step: 0
Training loss: 3.0764815692321634
Validation loss: 3.118704744326662

Epoch: 5| Step: 1
Training loss: 3.036463707493279
Validation loss: 3.120743276964086

Epoch: 5| Step: 2
Training loss: 3.937317495809193
Validation loss: 3.11736620203863

Epoch: 5| Step: 3
Training loss: 3.512407381730424
Validation loss: 3.1188612614081506

Epoch: 5| Step: 4
Training loss: 3.337264857777553
Validation loss: 3.1219459573666817

Epoch: 5| Step: 5
Training loss: 2.9725314501357087
Validation loss: 3.1192088539648677

Epoch: 5| Step: 6
Training loss: 3.7619197867003202
Validation loss: 3.118711971526477

Epoch: 5| Step: 7
Training loss: 3.5251029195708448
Validation loss: 3.119610236643516

Epoch: 5| Step: 8
Training loss: 3.118162380353054
Validation loss: 3.118314802531576

Epoch: 5| Step: 9
Training loss: 3.522154716208484
Validation loss: 3.1164515617551953

Epoch: 5| Step: 10
Training loss: 3.1732787986151223
Validation loss: 3.118451845903806

Epoch: 128| Step: 0
Training loss: 3.321271977637254
Validation loss: 3.115536491677302

Epoch: 5| Step: 1
Training loss: 2.9991746402884276
Validation loss: 3.117522639124889

Epoch: 5| Step: 2
Training loss: 2.828976497710288
Validation loss: 3.115673806184488

Epoch: 5| Step: 3
Training loss: 3.5450215475398696
Validation loss: 3.114205460167581

Epoch: 5| Step: 4
Training loss: 3.355188644495109
Validation loss: 3.1153109285670277

Epoch: 5| Step: 5
Training loss: 3.5339589488781495
Validation loss: 3.11872706540365

Epoch: 5| Step: 6
Training loss: 3.626216026759781
Validation loss: 3.1192303659897918

Epoch: 5| Step: 7
Training loss: 3.4976785317828076
Validation loss: 3.122278650443643

Epoch: 5| Step: 8
Training loss: 3.8502677923430086
Validation loss: 3.116602948901638

Epoch: 5| Step: 9
Training loss: 3.022432697515487
Validation loss: 3.11669925617602

Epoch: 5| Step: 10
Training loss: 3.4247534503046397
Validation loss: 3.1160479342432845

Epoch: 129| Step: 0
Training loss: 3.0911697262507696
Validation loss: 3.114709324307972

Epoch: 5| Step: 1
Training loss: 3.4525154231650266
Validation loss: 3.114607999608413

Epoch: 5| Step: 2
Training loss: 3.8017847788746293
Validation loss: 3.116049591204595

Epoch: 5| Step: 3
Training loss: 3.7798194385980026
Validation loss: 3.1159341810023444

Epoch: 5| Step: 4
Training loss: 4.0444267260916735
Validation loss: 3.114431536317869

Epoch: 5| Step: 5
Training loss: 3.3639585940503713
Validation loss: 3.113845871780711

Epoch: 5| Step: 6
Training loss: 3.3244823884696872
Validation loss: 3.113215980787947

Epoch: 5| Step: 7
Training loss: 2.802730461941955
Validation loss: 3.112471393147836

Epoch: 5| Step: 8
Training loss: 3.6981405844077178
Validation loss: 3.114830398815934

Epoch: 5| Step: 9
Training loss: 2.594434257240453
Validation loss: 3.1123462698176105

Epoch: 5| Step: 10
Training loss: 2.73088277971259
Validation loss: 3.111724272734319

Epoch: 130| Step: 0
Training loss: 2.951751227981391
Validation loss: 3.1121606384712033

Epoch: 5| Step: 1
Training loss: 3.203455168292322
Validation loss: 3.1116274522640914

Epoch: 5| Step: 2
Training loss: 3.6121856183066057
Validation loss: 3.1107998544912028

Epoch: 5| Step: 3
Training loss: 3.433618191750322
Validation loss: 3.113361335533692

Epoch: 5| Step: 4
Training loss: 3.6318371191430585
Validation loss: 3.111482084905068

Epoch: 5| Step: 5
Training loss: 3.725099672353711
Validation loss: 3.1125319592796683

Epoch: 5| Step: 6
Training loss: 2.546882769800984
Validation loss: 3.112940031923577

Epoch: 5| Step: 7
Training loss: 3.684631913330144
Validation loss: 3.109804041908628

Epoch: 5| Step: 8
Training loss: 2.9932338389093642
Validation loss: 3.1124388474151212

Epoch: 5| Step: 9
Training loss: 4.022897035908754
Validation loss: 3.1121770705819873

Epoch: 5| Step: 10
Training loss: 2.915533190689268
Validation loss: 3.110080963081696

Epoch: 131| Step: 0
Training loss: 3.5894722066553286
Validation loss: 3.115397089197471

Epoch: 5| Step: 1
Training loss: 3.7851096387577723
Validation loss: 3.1140125764254356

Epoch: 5| Step: 2
Training loss: 3.4591182292970806
Validation loss: 3.1176179978269056

Epoch: 5| Step: 3
Training loss: 2.5890404101150564
Validation loss: 3.1131128608458094

Epoch: 5| Step: 4
Training loss: 3.22808875684897
Validation loss: 3.1129642019995

Epoch: 5| Step: 5
Training loss: 3.1187868532743988
Validation loss: 3.111928859693145

Epoch: 5| Step: 6
Training loss: 3.2630384505096464
Validation loss: 3.1116719601642364

Epoch: 5| Step: 7
Training loss: 3.074933406449896
Validation loss: 3.1085145249957553

Epoch: 5| Step: 8
Training loss: 3.535524465026066
Validation loss: 3.1070669174916365

Epoch: 5| Step: 9
Training loss: 3.601920881665887
Validation loss: 3.1087280876786387

Epoch: 5| Step: 10
Training loss: 3.6686822524306075
Validation loss: 3.10752761912629

Epoch: 132| Step: 0
Training loss: 3.4179061099170784
Validation loss: 3.1085133786407644

Epoch: 5| Step: 1
Training loss: 2.912297673217276
Validation loss: 3.1076969032160524

Epoch: 5| Step: 2
Training loss: 3.4944779567462643
Validation loss: 3.109390759213003

Epoch: 5| Step: 3
Training loss: 3.6916036240222936
Validation loss: 3.106185016310116

Epoch: 5| Step: 4
Training loss: 2.607062131374729
Validation loss: 3.107713715297943

Epoch: 5| Step: 5
Training loss: 3.3997031474952144
Validation loss: 3.1101351999191675

Epoch: 5| Step: 6
Training loss: 3.823351441207172
Validation loss: 3.10989240362044

Epoch: 5| Step: 7
Training loss: 3.5630512814874384
Validation loss: 3.1093067811608166

Epoch: 5| Step: 8
Training loss: 2.243179580309299
Validation loss: 3.106207055955629

Epoch: 5| Step: 9
Training loss: 3.4292160092431208
Validation loss: 3.107653757289188

Epoch: 5| Step: 10
Training loss: 4.133331208587428
Validation loss: 3.106886179050056

Epoch: 133| Step: 0
Training loss: 2.9293116620905444
Validation loss: 3.1076519605604163

Epoch: 5| Step: 1
Training loss: 3.590203699904996
Validation loss: 3.109270098693404

Epoch: 5| Step: 2
Training loss: 2.699023183094821
Validation loss: 3.107937940838039

Epoch: 5| Step: 3
Training loss: 3.420502687954749
Validation loss: 3.1065343391635274

Epoch: 5| Step: 4
Training loss: 3.7600944712113393
Validation loss: 3.10863546884522

Epoch: 5| Step: 5
Training loss: 2.724088229309174
Validation loss: 3.1110918657402955

Epoch: 5| Step: 6
Training loss: 3.0603412103840006
Validation loss: 3.1101880015780234

Epoch: 5| Step: 7
Training loss: 3.313746667584701
Validation loss: 3.1110152858146414

Epoch: 5| Step: 8
Training loss: 3.5616354980913822
Validation loss: 3.1088716393558578

Epoch: 5| Step: 9
Training loss: 3.817239410759453
Validation loss: 3.11077379355794

Epoch: 5| Step: 10
Training loss: 3.9415578368783986
Validation loss: 3.105825805156601

Epoch: 134| Step: 0
Training loss: 4.051505837888348
Validation loss: 3.1063269903509574

Epoch: 5| Step: 1
Training loss: 3.4012055447612752
Validation loss: 3.107808008108594

Epoch: 5| Step: 2
Training loss: 3.2654100557251993
Validation loss: 3.107090431099913

Epoch: 5| Step: 3
Training loss: 3.2676973475055826
Validation loss: 3.10897141111558

Epoch: 5| Step: 4
Training loss: 3.072677051232269
Validation loss: 3.1072888696910193

Epoch: 5| Step: 5
Training loss: 3.4690414168831687
Validation loss: 3.1066542015087912

Epoch: 5| Step: 6
Training loss: 4.247372881158607
Validation loss: 3.10744474077275

Epoch: 5| Step: 7
Training loss: 3.0344832961835353
Validation loss: 3.1051878013870056

Epoch: 5| Step: 8
Training loss: 2.9772240411720796
Validation loss: 3.1033896028122214

Epoch: 5| Step: 9
Training loss: 3.1472658007497314
Validation loss: 3.1018223861175436

Epoch: 5| Step: 10
Training loss: 2.620786737008589
Validation loss: 3.101514335728047

Epoch: 135| Step: 0
Training loss: 3.3265620757067307
Validation loss: 3.1008870656149594

Epoch: 5| Step: 1
Training loss: 3.469571677824725
Validation loss: 3.1041604646459873

Epoch: 5| Step: 2
Training loss: 3.189330230045829
Validation loss: 3.1038092069967194

Epoch: 5| Step: 3
Training loss: 3.0492511580414123
Validation loss: 3.1053386198416133

Epoch: 5| Step: 4
Training loss: 4.374110976218526
Validation loss: 3.105874566203608

Epoch: 5| Step: 5
Training loss: 3.490907438731164
Validation loss: 3.1002453183305576

Epoch: 5| Step: 6
Training loss: 3.255947393315738
Validation loss: 3.1027859052353453

Epoch: 5| Step: 7
Training loss: 3.280827667668103
Validation loss: 3.099862500666623

Epoch: 5| Step: 8
Training loss: 3.552544587168927
Validation loss: 3.0997681141997564

Epoch: 5| Step: 9
Training loss: 2.505747006900647
Validation loss: 3.101375142811898

Epoch: 5| Step: 10
Training loss: 3.1869705358842335
Validation loss: 3.103265275643014

Epoch: 136| Step: 0
Training loss: 4.188469617948603
Validation loss: 3.1012626195701434

Epoch: 5| Step: 1
Training loss: 3.184350495997553
Validation loss: 3.105974986422853

Epoch: 5| Step: 2
Training loss: 3.4255847069831447
Validation loss: 3.1071055715318017

Epoch: 5| Step: 3
Training loss: 3.789707404243477
Validation loss: 3.104430756804665

Epoch: 5| Step: 4
Training loss: 3.3231345716119414
Validation loss: 3.102742726546173

Epoch: 5| Step: 5
Training loss: 2.810628056099324
Validation loss: 3.106224439797283

Epoch: 5| Step: 6
Training loss: 3.642334892599613
Validation loss: 3.102676987761165

Epoch: 5| Step: 7
Training loss: 3.380029956752591
Validation loss: 3.1048496918416806

Epoch: 5| Step: 8
Training loss: 2.9116859051382353
Validation loss: 3.104634666690043

Epoch: 5| Step: 9
Training loss: 3.0801674509974424
Validation loss: 3.1017479143064883

Epoch: 5| Step: 10
Training loss: 2.924725778881301
Validation loss: 3.101402428398965

Epoch: 137| Step: 0
Training loss: 3.143064699502896
Validation loss: 3.1011942098781056

Epoch: 5| Step: 1
Training loss: 2.8028480214328426
Validation loss: 3.0995996716227756

Epoch: 5| Step: 2
Training loss: 3.3270046873756183
Validation loss: 3.100468106145165

Epoch: 5| Step: 3
Training loss: 3.561800436299381
Validation loss: 3.101503168651713

Epoch: 5| Step: 4
Training loss: 3.374927802549903
Validation loss: 3.09953687352905

Epoch: 5| Step: 5
Training loss: 2.962939227415312
Validation loss: 3.0977180649724656

Epoch: 5| Step: 6
Training loss: 3.547273722684431
Validation loss: 3.098512201346404

Epoch: 5| Step: 7
Training loss: 3.8582260336624983
Validation loss: 3.0986313315507843

Epoch: 5| Step: 8
Training loss: 3.813406664492255
Validation loss: 3.1024186627039083

Epoch: 5| Step: 9
Training loss: 3.4334539009578156
Validation loss: 3.0999559208134015

Epoch: 5| Step: 10
Training loss: 2.860646283147848
Validation loss: 3.099512822893533

Epoch: 138| Step: 0
Training loss: 3.343097801418779
Validation loss: 3.1033530404022587

Epoch: 5| Step: 1
Training loss: 3.0368123096276873
Validation loss: 3.1021382824482644

Epoch: 5| Step: 2
Training loss: 3.0828616494593186
Validation loss: 3.1027586334670327

Epoch: 5| Step: 3
Training loss: 3.4881133821940216
Validation loss: 3.1009928622753073

Epoch: 5| Step: 4
Training loss: 3.409874763538265
Validation loss: 3.104712690478926

Epoch: 5| Step: 5
Training loss: 2.7459230546277213
Validation loss: 3.098653514275777

Epoch: 5| Step: 6
Training loss: 3.4866246372507588
Validation loss: 3.0988030689556543

Epoch: 5| Step: 7
Training loss: 3.362072948011608
Validation loss: 3.097540450780778

Epoch: 5| Step: 8
Training loss: 3.6992581938400004
Validation loss: 3.098481862076267

Epoch: 5| Step: 9
Training loss: 4.045188758699136
Validation loss: 3.0973944868474206

Epoch: 5| Step: 10
Training loss: 2.9833265130446347
Validation loss: 3.0961178704505152

Epoch: 139| Step: 0
Training loss: 3.2273557117455645
Validation loss: 3.0958376250869875

Epoch: 5| Step: 1
Training loss: 2.852580852783577
Validation loss: 3.0951142744517157

Epoch: 5| Step: 2
Training loss: 2.759785840391725
Validation loss: 3.09647689718648

Epoch: 5| Step: 3
Training loss: 3.4761751452043836
Validation loss: 3.095531512099443

Epoch: 5| Step: 4
Training loss: 3.040289859003219
Validation loss: 3.095452986898634

Epoch: 5| Step: 5
Training loss: 4.024336690327878
Validation loss: 3.094918285777296

Epoch: 5| Step: 6
Training loss: 3.479033888302825
Validation loss: 3.0950029971616666

Epoch: 5| Step: 7
Training loss: 3.3826898636293836
Validation loss: 3.0939172471872314

Epoch: 5| Step: 8
Training loss: 3.697596934648974
Validation loss: 3.092439392319887

Epoch: 5| Step: 9
Training loss: 3.1623916547105932
Validation loss: 3.093808311657825

Epoch: 5| Step: 10
Training loss: 3.6227309919572956
Validation loss: 3.091230285957717

Epoch: 140| Step: 0
Training loss: 3.479866703593727
Validation loss: 3.09555003168491

Epoch: 5| Step: 1
Training loss: 3.139827038563157
Validation loss: 3.096567954823566

Epoch: 5| Step: 2
Training loss: 3.828285058237119
Validation loss: 3.0981220796726516

Epoch: 5| Step: 3
Training loss: 3.20059967978529
Validation loss: 3.102202274083527

Epoch: 5| Step: 4
Training loss: 3.4585694075443616
Validation loss: 3.1026500001002084

Epoch: 5| Step: 5
Training loss: 3.003430471454732
Validation loss: 3.1006059961991927

Epoch: 5| Step: 6
Training loss: 3.330521701120673
Validation loss: 3.0985702405377897

Epoch: 5| Step: 7
Training loss: 2.522990278644861
Validation loss: 3.0969318283064187

Epoch: 5| Step: 8
Training loss: 3.393996008848722
Validation loss: 3.0915427439806678

Epoch: 5| Step: 9
Training loss: 3.5149804096571344
Validation loss: 3.0947572276902684

Epoch: 5| Step: 10
Training loss: 3.851393009193828
Validation loss: 3.0945425865164373

Epoch: 141| Step: 0
Training loss: 3.255695927023634
Validation loss: 3.095707159640446

Epoch: 5| Step: 1
Training loss: 2.9549919564642733
Validation loss: 3.0982354956063825

Epoch: 5| Step: 2
Training loss: 3.026800133903483
Validation loss: 3.0992696179534502

Epoch: 5| Step: 3
Training loss: 2.9147153230510714
Validation loss: 3.0976987456501908

Epoch: 5| Step: 4
Training loss: 3.8849450746480607
Validation loss: 3.09310350471652

Epoch: 5| Step: 5
Training loss: 3.6757685370230475
Validation loss: 3.095823978088692

Epoch: 5| Step: 6
Training loss: 3.641051697181441
Validation loss: 3.0919217528646206

Epoch: 5| Step: 7
Training loss: 3.599926757067427
Validation loss: 3.091616520033964

Epoch: 5| Step: 8
Training loss: 3.5778068834177925
Validation loss: 3.089479498913839

Epoch: 5| Step: 9
Training loss: 3.28380463472301
Validation loss: 3.0912338520616154

Epoch: 5| Step: 10
Training loss: 2.7522839685076907
Validation loss: 3.0900081986267005

Epoch: 142| Step: 0
Training loss: 2.9647686412278955
Validation loss: 3.089106597196414

Epoch: 5| Step: 1
Training loss: 3.351223872935558
Validation loss: 3.0901288646070095

Epoch: 5| Step: 2
Training loss: 3.403891210411175
Validation loss: 3.0886574076243734

Epoch: 5| Step: 3
Training loss: 3.4459399562393473
Validation loss: 3.0908891832020853

Epoch: 5| Step: 4
Training loss: 3.4119866736130557
Validation loss: 3.089219017992584

Epoch: 5| Step: 5
Training loss: 3.0751489494659228
Validation loss: 3.0903806912532485

Epoch: 5| Step: 6
Training loss: 3.468002376234391
Validation loss: 3.0913518562658484

Epoch: 5| Step: 7
Training loss: 3.590886442993174
Validation loss: 3.0948666980688655

Epoch: 5| Step: 8
Training loss: 4.05988074742961
Validation loss: 3.0888668231469096

Epoch: 5| Step: 9
Training loss: 2.6898458134590366
Validation loss: 3.0863256266205124

Epoch: 5| Step: 10
Training loss: 3.1850091514276273
Validation loss: 3.0894192998785095

Epoch: 143| Step: 0
Training loss: 3.5594043331930303
Validation loss: 3.0870471791507277

Epoch: 5| Step: 1
Training loss: 3.4407915482155387
Validation loss: 3.088193372894203

Epoch: 5| Step: 2
Training loss: 3.282238620598574
Validation loss: 3.088389443013099

Epoch: 5| Step: 3
Training loss: 3.4531584172767937
Validation loss: 3.085937175176979

Epoch: 5| Step: 4
Training loss: 3.4917598180856118
Validation loss: 3.087963609951825

Epoch: 5| Step: 5
Training loss: 3.2046386119846417
Validation loss: 3.0842154376556774

Epoch: 5| Step: 6
Training loss: 2.960297286337731
Validation loss: 3.0849498567614373

Epoch: 5| Step: 7
Training loss: 3.5466664794931386
Validation loss: 3.0849040508561614

Epoch: 5| Step: 8
Training loss: 3.5347482013726146
Validation loss: 3.0853026607679253

Epoch: 5| Step: 9
Training loss: 3.182589919145227
Validation loss: 3.08420238093083

Epoch: 5| Step: 10
Training loss: 3.058481967096455
Validation loss: 3.0848939787843195

Epoch: 144| Step: 0
Training loss: 3.56742732294125
Validation loss: 3.083954111435867

Epoch: 5| Step: 1
Training loss: 3.5919613574950655
Validation loss: 3.0836865212571447

Epoch: 5| Step: 2
Training loss: 3.363102747558749
Validation loss: 3.087204835368797

Epoch: 5| Step: 3
Training loss: 2.9845969232461673
Validation loss: 3.0865156582019027

Epoch: 5| Step: 4
Training loss: 3.8972771700913365
Validation loss: 3.0894221245610427

Epoch: 5| Step: 5
Training loss: 3.4130113323391256
Validation loss: 3.0879365775516243

Epoch: 5| Step: 6
Training loss: 3.158740128326992
Validation loss: 3.087091113834852

Epoch: 5| Step: 7
Training loss: 3.3965073991097134
Validation loss: 3.094009874089179

Epoch: 5| Step: 8
Training loss: 2.9286182944771233
Validation loss: 3.0909798854183586

Epoch: 5| Step: 9
Training loss: 3.0712963595402187
Validation loss: 3.0922860611514573

Epoch: 5| Step: 10
Training loss: 3.2810349166858495
Validation loss: 3.082808140262116

Epoch: 145| Step: 0
Training loss: 3.015996247995001
Validation loss: 3.0804170460066165

Epoch: 5| Step: 1
Training loss: 3.286730594309907
Validation loss: 3.0817373577450877

Epoch: 5| Step: 2
Training loss: 3.109091434296194
Validation loss: 3.079529522567305

Epoch: 5| Step: 3
Training loss: 3.0758683506010938
Validation loss: 3.0798696026941634

Epoch: 5| Step: 4
Training loss: 3.392466524053154
Validation loss: 3.0800219355711533

Epoch: 5| Step: 5
Training loss: 2.6457178786511433
Validation loss: 3.0788128404290784

Epoch: 5| Step: 6
Training loss: 3.3193413963620895
Validation loss: 3.0795506840858327

Epoch: 5| Step: 7
Training loss: 3.3845793798839097
Validation loss: 3.0781809742028914

Epoch: 5| Step: 8
Training loss: 3.8346810390519637
Validation loss: 3.0790741817010616

Epoch: 5| Step: 9
Training loss: 3.6228960442828972
Validation loss: 3.0783308789121935

Epoch: 5| Step: 10
Training loss: 3.9547622366135404
Validation loss: 3.077064717578805

Epoch: 146| Step: 0
Training loss: 3.4423319754668187
Validation loss: 3.078778970484564

Epoch: 5| Step: 1
Training loss: 3.3802652613818176
Validation loss: 3.0785660899021843

Epoch: 5| Step: 2
Training loss: 3.465880710809664
Validation loss: 3.076175816916424

Epoch: 5| Step: 3
Training loss: 2.918753358892105
Validation loss: 3.0784816890285778

Epoch: 5| Step: 4
Training loss: 3.0124563063622514
Validation loss: 3.07770859620197

Epoch: 5| Step: 5
Training loss: 3.8854880373265863
Validation loss: 3.0767691460791666

Epoch: 5| Step: 6
Training loss: 3.807347803010755
Validation loss: 3.074373493838837

Epoch: 5| Step: 7
Training loss: 3.1498217698795017
Validation loss: 3.0770771789011566

Epoch: 5| Step: 8
Training loss: 3.481264102708615
Validation loss: 3.076915586034903

Epoch: 5| Step: 9
Training loss: 3.228623440898631
Validation loss: 3.0765250956615167

Epoch: 5| Step: 10
Training loss: 2.7150300106125185
Validation loss: 3.0751135152117923

Epoch: 147| Step: 0
Training loss: 4.091974004221032
Validation loss: 3.0793068416308698

Epoch: 5| Step: 1
Training loss: 3.390242172638371
Validation loss: 3.072907414047858

Epoch: 5| Step: 2
Training loss: 3.9745071585443537
Validation loss: 3.0751576479026483

Epoch: 5| Step: 3
Training loss: 3.2378070700402666
Validation loss: 3.076241932019291

Epoch: 5| Step: 4
Training loss: 3.146533475524717
Validation loss: 3.0742339989527285

Epoch: 5| Step: 5
Training loss: 3.511680322761458
Validation loss: 3.075073676198365

Epoch: 5| Step: 6
Training loss: 3.8069501411413613
Validation loss: 3.0744604169039857

Epoch: 5| Step: 7
Training loss: 2.0274108993199667
Validation loss: 3.0758126176972262

Epoch: 5| Step: 8
Training loss: 3.2197569225801703
Validation loss: 3.072744885220036

Epoch: 5| Step: 9
Training loss: 3.0220401501819136
Validation loss: 3.0734189387248954

Epoch: 5| Step: 10
Training loss: 2.6722867771087198
Validation loss: 3.0717943286360483

Epoch: 148| Step: 0
Training loss: 3.214446959916694
Validation loss: 3.0756209245706656

Epoch: 5| Step: 1
Training loss: 3.0979813432815106
Validation loss: 3.073339413109305

Epoch: 5| Step: 2
Training loss: 2.7106588698670775
Validation loss: 3.0773611029180996

Epoch: 5| Step: 3
Training loss: 3.248768940100183
Validation loss: 3.089902213365585

Epoch: 5| Step: 4
Training loss: 3.3038507939932344
Validation loss: 3.0921864200860782

Epoch: 5| Step: 5
Training loss: 3.8348725310904292
Validation loss: 3.079526826169822

Epoch: 5| Step: 6
Training loss: 2.9238804753266816
Validation loss: 3.0745610235009457

Epoch: 5| Step: 7
Training loss: 3.43821306635593
Validation loss: 3.074840724310622

Epoch: 5| Step: 8
Training loss: 2.878440456933464
Validation loss: 3.0725694685828975

Epoch: 5| Step: 9
Training loss: 3.3042407444029642
Validation loss: 3.072624672931239

Epoch: 5| Step: 10
Training loss: 4.544403558084435
Validation loss: 3.072123775870358

Epoch: 149| Step: 0
Training loss: 3.824098423437377
Validation loss: 3.0723729846520147

Epoch: 5| Step: 1
Training loss: 3.4993662941673302
Validation loss: 3.069702593855832

Epoch: 5| Step: 2
Training loss: 3.3549225865627084
Validation loss: 3.0729380850708568

Epoch: 5| Step: 3
Training loss: 3.000446604228961
Validation loss: 3.070222671014243

Epoch: 5| Step: 4
Training loss: 2.9897629598602533
Validation loss: 3.071470478371436

Epoch: 5| Step: 5
Training loss: 3.5761066724582324
Validation loss: 3.0724044002961888

Epoch: 5| Step: 6
Training loss: 3.0544232110234124
Validation loss: 3.069934207853538

Epoch: 5| Step: 7
Training loss: 3.1270157988234257
Validation loss: 3.0714469574975634

Epoch: 5| Step: 8
Training loss: 3.720899073129309
Validation loss: 3.0726790836705695

Epoch: 5| Step: 9
Training loss: 3.388031138766794
Validation loss: 3.0725124910216968

Epoch: 5| Step: 10
Training loss: 2.985685050988106
Validation loss: 3.0707702562674495

Epoch: 150| Step: 0
Training loss: 3.7754976007784573
Validation loss: 3.0740678758574242

Epoch: 5| Step: 1
Training loss: 3.277344913959865
Validation loss: 3.0793491126362946

Epoch: 5| Step: 2
Training loss: 3.267156360538029
Validation loss: 3.0797116500525186

Epoch: 5| Step: 3
Training loss: 3.095526291282232
Validation loss: 3.0825440250971394

Epoch: 5| Step: 4
Training loss: 3.6353307384111173
Validation loss: 3.081286169530946

Epoch: 5| Step: 5
Training loss: 3.808156650598881
Validation loss: 3.0833834838336216

Epoch: 5| Step: 6
Training loss: 2.616139033953816
Validation loss: 3.07571288138353

Epoch: 5| Step: 7
Training loss: 3.111580837832077
Validation loss: 3.079058653650878

Epoch: 5| Step: 8
Training loss: 3.3841399304021813
Validation loss: 3.0733932081117596

Epoch: 5| Step: 9
Training loss: 2.9672952400401518
Validation loss: 3.0673841012641585

Epoch: 5| Step: 10
Training loss: 3.58472643246051
Validation loss: 3.069339813023983

Epoch: 151| Step: 0
Training loss: 2.6363857030692417
Validation loss: 3.0715635117618594

Epoch: 5| Step: 1
Training loss: 3.508406896718494
Validation loss: 3.0693663485384213

Epoch: 5| Step: 2
Training loss: 3.6377536436178954
Validation loss: 3.0748733094898375

Epoch: 5| Step: 3
Training loss: 3.1352386593058053
Validation loss: 3.06741464364616

Epoch: 5| Step: 4
Training loss: 3.4059670707020264
Validation loss: 3.074810965218621

Epoch: 5| Step: 5
Training loss: 3.055227246612334
Validation loss: 3.069827300721586

Epoch: 5| Step: 6
Training loss: 3.1946164144767883
Validation loss: 3.070052498830887

Epoch: 5| Step: 7
Training loss: 3.648355160423244
Validation loss: 3.067561223457888

Epoch: 5| Step: 8
Training loss: 2.8883843062786565
Validation loss: 3.0715237377114897

Epoch: 5| Step: 9
Training loss: 3.869534853204397
Validation loss: 3.0687759555372023

Epoch: 5| Step: 10
Training loss: 3.494065430516013
Validation loss: 3.067792659011212

Epoch: 152| Step: 0
Training loss: 3.3412354899047485
Validation loss: 3.0668106848038255

Epoch: 5| Step: 1
Training loss: 2.733845773980651
Validation loss: 3.0645156247775964

Epoch: 5| Step: 2
Training loss: 2.4778213911489964
Validation loss: 3.064560043935663

Epoch: 5| Step: 3
Training loss: 2.6384323316336196
Validation loss: 3.0657126707278164

Epoch: 5| Step: 4
Training loss: 4.039026138466648
Validation loss: 3.066150854827024

Epoch: 5| Step: 5
Training loss: 3.4612974922556163
Validation loss: 3.068227005859858

Epoch: 5| Step: 6
Training loss: 3.225536414195592
Validation loss: 3.0658409172819923

Epoch: 5| Step: 7
Training loss: 3.233171469448302
Validation loss: 3.0650605494240164

Epoch: 5| Step: 8
Training loss: 3.9137151567826414
Validation loss: 3.0683564223111985

Epoch: 5| Step: 9
Training loss: 3.386893192009395
Validation loss: 3.0662946691329833

Epoch: 5| Step: 10
Training loss: 3.8674794713013667
Validation loss: 3.0661371701774742

Epoch: 153| Step: 0
Training loss: 3.4565207239117695
Validation loss: 3.0688670164375345

Epoch: 5| Step: 1
Training loss: 3.4782868298826446
Validation loss: 3.0696513507238894

Epoch: 5| Step: 2
Training loss: 4.08822188696033
Validation loss: 3.067482530489453

Epoch: 5| Step: 3
Training loss: 3.710120438422793
Validation loss: 3.0681885705655847

Epoch: 5| Step: 4
Training loss: 3.437518310498108
Validation loss: 3.0674903012591965

Epoch: 5| Step: 5
Training loss: 2.914284050831467
Validation loss: 3.0686506679294365

Epoch: 5| Step: 6
Training loss: 2.8717423932464667
Validation loss: 3.067053472047619

Epoch: 5| Step: 7
Training loss: 2.9179133521034
Validation loss: 3.0662652434662303

Epoch: 5| Step: 8
Training loss: 3.308680797814466
Validation loss: 3.064005923693387

Epoch: 5| Step: 9
Training loss: 3.7410504678372454
Validation loss: 3.066111959560356

Epoch: 5| Step: 10
Training loss: 2.0834042600638147
Validation loss: 3.0648984342444483

Epoch: 154| Step: 0
Training loss: 3.323997266049873
Validation loss: 3.064893172956421

Epoch: 5| Step: 1
Training loss: 3.2594085369780346
Validation loss: 3.0646570012475105

Epoch: 5| Step: 2
Training loss: 4.293523417662083
Validation loss: 3.065895160767331

Epoch: 5| Step: 3
Training loss: 2.9707265598393535
Validation loss: 3.066277396689604

Epoch: 5| Step: 4
Training loss: 3.4259851584216032
Validation loss: 3.067684129545351

Epoch: 5| Step: 5
Training loss: 3.6614983865311634
Validation loss: 3.0646757492307777

Epoch: 5| Step: 6
Training loss: 2.7929631159798944
Validation loss: 3.062430939555977

Epoch: 5| Step: 7
Training loss: 3.326095320335251
Validation loss: 3.063692715743993

Epoch: 5| Step: 8
Training loss: 3.064917252685316
Validation loss: 3.063043609315233

Epoch: 5| Step: 9
Training loss: 3.3278645158295994
Validation loss: 3.0635931522189135

Epoch: 5| Step: 10
Training loss: 2.7921387192660236
Validation loss: 3.062671200368323

Epoch: 155| Step: 0
Training loss: 3.348981525979583
Validation loss: 3.0666951904691326

Epoch: 5| Step: 1
Training loss: 3.3692156354874476
Validation loss: 3.0649056109947947

Epoch: 5| Step: 2
Training loss: 3.5227683504008516
Validation loss: 3.066784767504623

Epoch: 5| Step: 3
Training loss: 3.1908977575034165
Validation loss: 3.0726048988016146

Epoch: 5| Step: 4
Training loss: 3.292412218735469
Validation loss: 3.061004187988403

Epoch: 5| Step: 5
Training loss: 4.151924578663391
Validation loss: 3.0648757077574835

Epoch: 5| Step: 6
Training loss: 2.5457344543767575
Validation loss: 3.0627301455911273

Epoch: 5| Step: 7
Training loss: 3.844161593102173
Validation loss: 3.0621520115306606

Epoch: 5| Step: 8
Training loss: 3.0406436680439266
Validation loss: 3.059183366923081

Epoch: 5| Step: 9
Training loss: 2.7091500933619455
Validation loss: 3.059978646768147

Epoch: 5| Step: 10
Training loss: 3.2491069447019365
Validation loss: 3.0577710095886963

Epoch: 156| Step: 0
Training loss: 3.491845167478796
Validation loss: 3.0582529151359887

Epoch: 5| Step: 1
Training loss: 3.232486634311644
Validation loss: 3.0567700287856554

Epoch: 5| Step: 2
Training loss: 3.0517934372920665
Validation loss: 3.0588284336987694

Epoch: 5| Step: 3
Training loss: 3.259985475800345
Validation loss: 3.0580834760251645

Epoch: 5| Step: 4
Training loss: 3.461294874766235
Validation loss: 3.059227897024185

Epoch: 5| Step: 5
Training loss: 3.4109375223674414
Validation loss: 3.059275361117761

Epoch: 5| Step: 6
Training loss: 3.386283943397615
Validation loss: 3.0576935738204516

Epoch: 5| Step: 7
Training loss: 2.6716456621581424
Validation loss: 3.057215434101907

Epoch: 5| Step: 8
Training loss: 3.7736504220223415
Validation loss: 3.0607140259564107

Epoch: 5| Step: 9
Training loss: 3.5051942157130416
Validation loss: 3.0626984147536023

Epoch: 5| Step: 10
Training loss: 3.133639942210105
Validation loss: 3.0570726233205345

Epoch: 157| Step: 0
Training loss: 3.7696247306656914
Validation loss: 3.0570875317959625

Epoch: 5| Step: 1
Training loss: 3.550799110627866
Validation loss: 3.0554086495736517

Epoch: 5| Step: 2
Training loss: 3.2585758623040566
Validation loss: 3.058197156282889

Epoch: 5| Step: 3
Training loss: 4.120762353381577
Validation loss: 3.0584217346331797

Epoch: 5| Step: 4
Training loss: 3.7636290519586373
Validation loss: 3.057549033823873

Epoch: 5| Step: 5
Training loss: 3.3270264724398317
Validation loss: 3.057323025412302

Epoch: 5| Step: 6
Training loss: 3.4476563661784057
Validation loss: 3.058882243364525

Epoch: 5| Step: 7
Training loss: 2.939404620914184
Validation loss: 3.0575769067103753

Epoch: 5| Step: 8
Training loss: 2.41850558285545
Validation loss: 3.057416532894144

Epoch: 5| Step: 9
Training loss: 2.6018259642482016
Validation loss: 3.0568639951521726

Epoch: 5| Step: 10
Training loss: 2.8585283870892244
Validation loss: 3.0570221513272227

Epoch: 158| Step: 0
Training loss: 3.7861937684511475
Validation loss: 3.0539749288342923

Epoch: 5| Step: 1
Training loss: 3.2420239510707516
Validation loss: 3.058222998821991

Epoch: 5| Step: 2
Training loss: 3.80075214370921
Validation loss: 3.0536701971728397

Epoch: 5| Step: 3
Training loss: 3.4200076229166663
Validation loss: 3.0555070215685682

Epoch: 5| Step: 4
Training loss: 3.4693906725084696
Validation loss: 3.0555566879697946

Epoch: 5| Step: 5
Training loss: 3.4473566405300797
Validation loss: 3.0556288335322135

Epoch: 5| Step: 6
Training loss: 2.641682430023751
Validation loss: 3.0547750742823734

Epoch: 5| Step: 7
Training loss: 2.6986248505742627
Validation loss: 3.0546445100535715

Epoch: 5| Step: 8
Training loss: 3.8685051416858682
Validation loss: 3.054490940095914

Epoch: 5| Step: 9
Training loss: 2.99157883949962
Validation loss: 3.0562060466073335

Epoch: 5| Step: 10
Training loss: 2.740660065412478
Validation loss: 3.054833324266628

Epoch: 159| Step: 0
Training loss: 3.2115348761427382
Validation loss: 3.052027140333201

Epoch: 5| Step: 1
Training loss: 3.152949202961037
Validation loss: 3.0549115626287437

Epoch: 5| Step: 2
Training loss: 3.2261420246133112
Validation loss: 3.0535023499898446

Epoch: 5| Step: 3
Training loss: 3.494077030496601
Validation loss: 3.052027694719708

Epoch: 5| Step: 4
Training loss: 3.485430912430299
Validation loss: 3.0531433934516152

Epoch: 5| Step: 5
Training loss: 3.268661474484293
Validation loss: 3.0517017064734975

Epoch: 5| Step: 6
Training loss: 3.3260719521745887
Validation loss: 3.052378456714225

Epoch: 5| Step: 7
Training loss: 3.129227639597727
Validation loss: 3.051462610050204

Epoch: 5| Step: 8
Training loss: 3.464341257293349
Validation loss: 3.0503470361420804

Epoch: 5| Step: 9
Training loss: 3.1157550627746806
Validation loss: 3.0509203437595334

Epoch: 5| Step: 10
Training loss: 3.6117869323460274
Validation loss: 3.05032557957506

Epoch: 160| Step: 0
Training loss: 3.0758627696882224
Validation loss: 3.0493654819943585

Epoch: 5| Step: 1
Training loss: 3.3784086180699653
Validation loss: 3.052663183913144

Epoch: 5| Step: 2
Training loss: 3.63172276057187
Validation loss: 3.051014107129132

Epoch: 5| Step: 3
Training loss: 2.3621938678662184
Validation loss: 3.051007270778055

Epoch: 5| Step: 4
Training loss: 3.3234449263661445
Validation loss: 3.053332654811692

Epoch: 5| Step: 5
Training loss: 3.4734605301931345
Validation loss: 3.0530563727489093

Epoch: 5| Step: 6
Training loss: 3.708417755766162
Validation loss: 3.0488769164093927

Epoch: 5| Step: 7
Training loss: 3.209358216773911
Validation loss: 3.0518591809441404

Epoch: 5| Step: 8
Training loss: 2.800422507152607
Validation loss: 3.050293832319633

Epoch: 5| Step: 9
Training loss: 3.595211627445339
Validation loss: 3.0486005156146163

Epoch: 5| Step: 10
Training loss: 3.6978266028956805
Validation loss: 3.0536099319236656

Epoch: 161| Step: 0
Training loss: 3.6512377691276283
Validation loss: 3.049991466309222

Epoch: 5| Step: 1
Training loss: 3.4832979598979468
Validation loss: 3.049602079667194

Epoch: 5| Step: 2
Training loss: 3.0864149279615574
Validation loss: 3.0504487699842833

Epoch: 5| Step: 3
Training loss: 2.8516768759168127
Validation loss: 3.0529669563617263

Epoch: 5| Step: 4
Training loss: 3.4736933495129065
Validation loss: 3.0547167191215916

Epoch: 5| Step: 5
Training loss: 3.090422719540034
Validation loss: 3.057320475877124

Epoch: 5| Step: 6
Training loss: 3.5272677762962994
Validation loss: 3.051785818083864

Epoch: 5| Step: 7
Training loss: 3.191196168594183
Validation loss: 3.0465111417673096

Epoch: 5| Step: 8
Training loss: 3.722881938741755
Validation loss: 3.047835491820011

Epoch: 5| Step: 9
Training loss: 2.842769747292349
Validation loss: 3.0479341822558794

Epoch: 5| Step: 10
Training loss: 3.378762585005783
Validation loss: 3.0477827707141834

Epoch: 162| Step: 0
Training loss: 3.2275715651729535
Validation loss: 3.0490596170142132

Epoch: 5| Step: 1
Training loss: 3.3983803930636536
Validation loss: 3.048820981877522

Epoch: 5| Step: 2
Training loss: 2.807738788127549
Validation loss: 3.0487933358597776

Epoch: 5| Step: 3
Training loss: 3.223707214994534
Validation loss: 3.0497337071073023

Epoch: 5| Step: 4
Training loss: 3.4029435374743264
Validation loss: 3.0508016899400716

Epoch: 5| Step: 5
Training loss: 2.515005094549582
Validation loss: 3.047711879500959

Epoch: 5| Step: 6
Training loss: 3.7391073336625316
Validation loss: 3.0485355249693185

Epoch: 5| Step: 7
Training loss: 3.43247327000934
Validation loss: 3.045818321267682

Epoch: 5| Step: 8
Training loss: 3.0797926359844525
Validation loss: 3.0466485691625826

Epoch: 5| Step: 9
Training loss: 3.5524327767204373
Validation loss: 3.0452461291298736

Epoch: 5| Step: 10
Training loss: 3.9279431819186055
Validation loss: 3.0447751045327394

Epoch: 163| Step: 0
Training loss: 3.590687118271828
Validation loss: 3.0472998083926353

Epoch: 5| Step: 1
Training loss: 2.984099210608602
Validation loss: 3.0438385436885445

Epoch: 5| Step: 2
Training loss: 3.408222712157183
Validation loss: 3.04576142573004

Epoch: 5| Step: 3
Training loss: 3.8761346447905933
Validation loss: 3.0437385429663126

Epoch: 5| Step: 4
Training loss: 3.214397116653038
Validation loss: 3.044596510222839

Epoch: 5| Step: 5
Training loss: 2.8004036918906765
Validation loss: 3.0433916481544814

Epoch: 5| Step: 6
Training loss: 3.475051242807323
Validation loss: 3.0473097279409025

Epoch: 5| Step: 7
Training loss: 3.2128147846767026
Validation loss: 3.0461275027810877

Epoch: 5| Step: 8
Training loss: 3.5349121009441475
Validation loss: 3.0471547156400236

Epoch: 5| Step: 9
Training loss: 3.2132617863594963
Validation loss: 3.0451480890611515

Epoch: 5| Step: 10
Training loss: 2.873445505252409
Validation loss: 3.0431166505281944

Epoch: 164| Step: 0
Training loss: 2.9150053651737418
Validation loss: 3.044304618429377

Epoch: 5| Step: 1
Training loss: 3.9056242174528393
Validation loss: 3.0464018676022033

Epoch: 5| Step: 2
Training loss: 2.673265508027572
Validation loss: 3.0490518514018485

Epoch: 5| Step: 3
Training loss: 2.979568045371596
Validation loss: 3.0461682530941205

Epoch: 5| Step: 4
Training loss: 2.9786933220558898
Validation loss: 3.0546460391847203

Epoch: 5| Step: 5
Training loss: 3.742651287478967
Validation loss: 3.046362776568246

Epoch: 5| Step: 6
Training loss: 3.4113543700861193
Validation loss: 3.0436864381970596

Epoch: 5| Step: 7
Training loss: 4.144863507240298
Validation loss: 3.040722281625847

Epoch: 5| Step: 8
Training loss: 3.3187437413043472
Validation loss: 3.0403664673264514

Epoch: 5| Step: 9
Training loss: 3.3243462687149257
Validation loss: 3.041657168960296

Epoch: 5| Step: 10
Training loss: 2.4815336089355333
Validation loss: 3.042261043388389

Epoch: 165| Step: 0
Training loss: 2.903441353798332
Validation loss: 3.0415768348103684

Epoch: 5| Step: 1
Training loss: 3.3610218358509507
Validation loss: 3.0406416445448774

Epoch: 5| Step: 2
Training loss: 3.3038581546973025
Validation loss: 3.04025821607324

Epoch: 5| Step: 3
Training loss: 3.2855905071187355
Validation loss: 3.041151629940657

Epoch: 5| Step: 4
Training loss: 3.0076244741351923
Validation loss: 3.040670288734784

Epoch: 5| Step: 5
Training loss: 3.454111087905653
Validation loss: 3.0387030373967043

Epoch: 5| Step: 6
Training loss: 3.998601311283014
Validation loss: 3.0378174665567275

Epoch: 5| Step: 7
Training loss: 3.382725245383431
Validation loss: 3.03727101520785

Epoch: 5| Step: 8
Training loss: 3.2425217789364873
Validation loss: 3.038512842014197

Epoch: 5| Step: 9
Training loss: 2.772709796696946
Validation loss: 3.0384168779757643

Epoch: 5| Step: 10
Training loss: 3.5281446187746854
Validation loss: 3.038025194335992

Epoch: 166| Step: 0
Training loss: 3.107343000157833
Validation loss: 3.038625460770677

Epoch: 5| Step: 1
Training loss: 3.422422321739362
Validation loss: 3.0378853987609356

Epoch: 5| Step: 2
Training loss: 3.4008204031332903
Validation loss: 3.039377447744832

Epoch: 5| Step: 3
Training loss: 3.4509657240707186
Validation loss: 3.039336674283862

Epoch: 5| Step: 4
Training loss: 2.4715089471474867
Validation loss: 3.0381043735323616

Epoch: 5| Step: 5
Training loss: 3.2978955176408906
Validation loss: 3.037190846967172

Epoch: 5| Step: 6
Training loss: 3.551790167530317
Validation loss: 3.0373739626840597

Epoch: 5| Step: 7
Training loss: 2.661075293243052
Validation loss: 3.03857632419898

Epoch: 5| Step: 8
Training loss: 3.334325181898151
Validation loss: 3.0373230359020127

Epoch: 5| Step: 9
Training loss: 3.8934774092139754
Validation loss: 3.0364516865402438

Epoch: 5| Step: 10
Training loss: 3.5530344714170905
Validation loss: 3.0345693339037116

Epoch: 167| Step: 0
Training loss: 3.1006734424167903
Validation loss: 3.0361114108457983

Epoch: 5| Step: 1
Training loss: 3.0609631477438115
Validation loss: 3.0353007642546674

Epoch: 5| Step: 2
Training loss: 2.8260444870759076
Validation loss: 3.0364667114576753

Epoch: 5| Step: 3
Training loss: 3.1246665776717126
Validation loss: 3.0393808355625844

Epoch: 5| Step: 4
Training loss: 3.827485945941779
Validation loss: 3.0412278094051386

Epoch: 5| Step: 5
Training loss: 2.939325942015993
Validation loss: 3.03995440239353

Epoch: 5| Step: 6
Training loss: 3.9992560648532653
Validation loss: 3.0445123347198892

Epoch: 5| Step: 7
Training loss: 2.3353884252586923
Validation loss: 3.0453023919751656

Epoch: 5| Step: 8
Training loss: 4.205577716127904
Validation loss: 3.043965970152383

Epoch: 5| Step: 9
Training loss: 3.7555813262426447
Validation loss: 3.036975260561823

Epoch: 5| Step: 10
Training loss: 2.4832584583165684
Validation loss: 3.0323587581756652

Epoch: 168| Step: 0
Training loss: 2.834761783071067
Validation loss: 3.0321961087072165

Epoch: 5| Step: 1
Training loss: 3.7900393141265054
Validation loss: 3.032310206554704

Epoch: 5| Step: 2
Training loss: 2.733736672144366
Validation loss: 3.030977017596302

Epoch: 5| Step: 3
Training loss: 3.4559249918268335
Validation loss: 3.0300103636032754

Epoch: 5| Step: 4
Training loss: 3.458273385382427
Validation loss: 3.0313021257132813

Epoch: 5| Step: 5
Training loss: 3.6613223112551196
Validation loss: 3.030302240608388

Epoch: 5| Step: 6
Training loss: 3.7754777719669086
Validation loss: 3.032739334089056

Epoch: 5| Step: 7
Training loss: 2.938185591536467
Validation loss: 3.0292454358263132

Epoch: 5| Step: 8
Training loss: 2.9347318227185353
Validation loss: 3.028534368296224

Epoch: 5| Step: 9
Training loss: 3.4875106045688207
Validation loss: 3.0307587856826625

Epoch: 5| Step: 10
Training loss: 2.9389839482292546
Validation loss: 3.0285785228712605

Epoch: 169| Step: 0
Training loss: 2.8253647627847354
Validation loss: 3.030047472581874

Epoch: 5| Step: 1
Training loss: 3.16166373794841
Validation loss: 3.0291345130626812

Epoch: 5| Step: 2
Training loss: 3.9073559225492827
Validation loss: 3.0276435428920827

Epoch: 5| Step: 3
Training loss: 3.514566491038985
Validation loss: 3.0280177486767177

Epoch: 5| Step: 4
Training loss: 3.148507772944044
Validation loss: 3.027912296148016

Epoch: 5| Step: 5
Training loss: 2.723023574547735
Validation loss: 3.0275727068022853

Epoch: 5| Step: 6
Training loss: 3.837644240063617
Validation loss: 3.0304759755988364

Epoch: 5| Step: 7
Training loss: 2.9684631209046373
Validation loss: 3.026693266795567

Epoch: 5| Step: 8
Training loss: 3.6464919594357386
Validation loss: 3.027350214681031

Epoch: 5| Step: 9
Training loss: 3.4886941868285657
Validation loss: 3.027768812768082

Epoch: 5| Step: 10
Training loss: 2.6713286616480723
Validation loss: 3.0268229802687747

Epoch: 170| Step: 0
Training loss: 3.4006957520337497
Validation loss: 3.0278096188110335

Epoch: 5| Step: 1
Training loss: 3.500223697598132
Validation loss: 3.027007194068332

Epoch: 5| Step: 2
Training loss: 3.122679802732042
Validation loss: 3.0269645334322193

Epoch: 5| Step: 3
Training loss: 3.471124884246623
Validation loss: 3.0271886172259883

Epoch: 5| Step: 4
Training loss: 3.679583440714475
Validation loss: 3.0262885737517085

Epoch: 5| Step: 5
Training loss: 3.404450387387889
Validation loss: 3.0263452407108957

Epoch: 5| Step: 6
Training loss: 3.077095750401848
Validation loss: 3.027282393274016

Epoch: 5| Step: 7
Training loss: 3.1256386676467383
Validation loss: 3.025409692574057

Epoch: 5| Step: 8
Training loss: 2.683456572867688
Validation loss: 3.024625143393493

Epoch: 5| Step: 9
Training loss: 3.497694345982084
Validation loss: 3.0234781033434315

Epoch: 5| Step: 10
Training loss: 3.163935906032306
Validation loss: 3.025860669813298

Epoch: 171| Step: 0
Training loss: 3.6627612701028083
Validation loss: 3.0237250388873917

Epoch: 5| Step: 1
Training loss: 2.884804469049158
Validation loss: 3.0224713194067094

Epoch: 5| Step: 2
Training loss: 2.9892220804994416
Validation loss: 3.0263408035570274

Epoch: 5| Step: 3
Training loss: 2.89419154182755
Validation loss: 3.0251933733766303

Epoch: 5| Step: 4
Training loss: 3.2698926281580896
Validation loss: 3.022695737147468

Epoch: 5| Step: 5
Training loss: 4.07444626492026
Validation loss: 3.0230233462931597

Epoch: 5| Step: 6
Training loss: 3.5688906453171723
Validation loss: 3.022874759485838

Epoch: 5| Step: 7
Training loss: 3.5974131614908753
Validation loss: 3.0225489747683003

Epoch: 5| Step: 8
Training loss: 2.9928717167080348
Validation loss: 3.0234648572472573

Epoch: 5| Step: 9
Training loss: 2.6670958849073183
Validation loss: 3.0211269254379824

Epoch: 5| Step: 10
Training loss: 3.3734112991651286
Validation loss: 3.024164343361341

Epoch: 172| Step: 0
Training loss: 3.7308877280260986
Validation loss: 3.023392971870773

Epoch: 5| Step: 1
Training loss: 3.172017512384973
Validation loss: 3.0229018004063395

Epoch: 5| Step: 2
Training loss: 3.095365314524101
Validation loss: 3.0233305445577483

Epoch: 5| Step: 3
Training loss: 3.8284032603747287
Validation loss: 3.0250050320537265

Epoch: 5| Step: 4
Training loss: 3.2925687752899937
Validation loss: 3.02747915991225

Epoch: 5| Step: 5
Training loss: 3.0957513366218223
Validation loss: 3.038530919410514

Epoch: 5| Step: 6
Training loss: 3.0122625550204645
Validation loss: 3.044791954195746

Epoch: 5| Step: 7
Training loss: 3.0989941164830537
Validation loss: 3.0257464677134567

Epoch: 5| Step: 8
Training loss: 2.9561788925425936
Validation loss: 3.0277614463864198

Epoch: 5| Step: 9
Training loss: 3.749723297083066
Validation loss: 3.0211300770289577

Epoch: 5| Step: 10
Training loss: 2.9994802024659792
Validation loss: 3.019272226841206

Epoch: 173| Step: 0
Training loss: 4.023519511451784
Validation loss: 3.0205248501572983

Epoch: 5| Step: 1
Training loss: 3.157703933472821
Validation loss: 3.018125676873592

Epoch: 5| Step: 2
Training loss: 3.61632328131933
Validation loss: 3.018802793474237

Epoch: 5| Step: 3
Training loss: 2.918904309002319
Validation loss: 3.020064796277445

Epoch: 5| Step: 4
Training loss: 3.2838824656893424
Validation loss: 3.019821468243672

Epoch: 5| Step: 5
Training loss: 2.6887918960095045
Validation loss: 3.020210136201378

Epoch: 5| Step: 6
Training loss: 3.6017019116608506
Validation loss: 3.0195729892036733

Epoch: 5| Step: 7
Training loss: 3.5869486262117722
Validation loss: 3.0200910296238956

Epoch: 5| Step: 8
Training loss: 2.933813175777594
Validation loss: 3.0175441029706156

Epoch: 5| Step: 9
Training loss: 2.321584436403105
Validation loss: 3.018322287912376

Epoch: 5| Step: 10
Training loss: 3.7551729762317074
Validation loss: 3.017936421321115

Epoch: 174| Step: 0
Training loss: 3.2758247210663476
Validation loss: 3.0179081916660917

Epoch: 5| Step: 1
Training loss: 3.014078484903666
Validation loss: 3.0175259763089923

Epoch: 5| Step: 2
Training loss: 3.656045761272759
Validation loss: 3.0160021147895857

Epoch: 5| Step: 3
Training loss: 3.079278410319417
Validation loss: 3.015507286801193

Epoch: 5| Step: 4
Training loss: 3.2083043348975275
Validation loss: 3.018456188162342

Epoch: 5| Step: 5
Training loss: 3.356762389100164
Validation loss: 3.0177561231327124

Epoch: 5| Step: 6
Training loss: 3.513927812993141
Validation loss: 3.01783809718787

Epoch: 5| Step: 7
Training loss: 3.4006004027767265
Validation loss: 3.0208480891177447

Epoch: 5| Step: 8
Training loss: 2.756264660162658
Validation loss: 3.0213642851767695

Epoch: 5| Step: 9
Training loss: 3.387504301737063
Validation loss: 3.0214641066665244

Epoch: 5| Step: 10
Training loss: 3.4408932670485037
Validation loss: 3.0283897004574487

Epoch: 175| Step: 0
Training loss: 2.5383126897675856
Validation loss: 3.026014604949261

Epoch: 5| Step: 1
Training loss: 2.720952512069443
Validation loss: 3.021684320660917

Epoch: 5| Step: 2
Training loss: 3.000335674579804
Validation loss: 3.0227273866699695

Epoch: 5| Step: 3
Training loss: 3.838783342818475
Validation loss: 3.036539925205636

Epoch: 5| Step: 4
Training loss: 3.184578098637369
Validation loss: 3.022614372343138

Epoch: 5| Step: 5
Training loss: 3.0783799738742137
Validation loss: 3.0131150293329356

Epoch: 5| Step: 6
Training loss: 3.2775014627949517
Validation loss: 3.0127593046517367

Epoch: 5| Step: 7
Training loss: 3.2347992697086503
Validation loss: 3.014701156399471

Epoch: 5| Step: 8
Training loss: 4.025866558548757
Validation loss: 3.014523624207249

Epoch: 5| Step: 9
Training loss: 3.235393419118771
Validation loss: 3.013839751775036

Epoch: 5| Step: 10
Training loss: 3.787985485423718
Validation loss: 3.0166775851838756

Epoch: 176| Step: 0
Training loss: 2.839748039889052
Validation loss: 3.016232360889172

Epoch: 5| Step: 1
Training loss: 3.182539876611626
Validation loss: 3.0174343541215127

Epoch: 5| Step: 2
Training loss: 3.0349240404455617
Validation loss: 3.0165421153288303

Epoch: 5| Step: 3
Training loss: 3.7276492023861105
Validation loss: 3.016167002580337

Epoch: 5| Step: 4
Training loss: 3.63759975231028
Validation loss: 3.0135691752483953

Epoch: 5| Step: 5
Training loss: 3.242804264096009
Validation loss: 3.0135170099270643

Epoch: 5| Step: 6
Training loss: 3.4299891867064027
Validation loss: 3.0128181984907325

Epoch: 5| Step: 7
Training loss: 3.5227756597602156
Validation loss: 3.01209753690228

Epoch: 5| Step: 8
Training loss: 3.6680744387479107
Validation loss: 3.0120417679432636

Epoch: 5| Step: 9
Training loss: 2.595503432699104
Validation loss: 3.011580583318983

Epoch: 5| Step: 10
Training loss: 3.083685640019884
Validation loss: 3.0107073405984766

Epoch: 177| Step: 0
Training loss: 3.158370410496898
Validation loss: 3.007437785917439

Epoch: 5| Step: 1
Training loss: 3.656118537300051
Validation loss: 3.012534975565302

Epoch: 5| Step: 2
Training loss: 3.27716973334944
Validation loss: 3.0200737484410225

Epoch: 5| Step: 3
Training loss: 3.5955670614363644
Validation loss: 3.0307109587326706

Epoch: 5| Step: 4
Training loss: 3.222801547387424
Validation loss: 3.0237440728770504

Epoch: 5| Step: 5
Training loss: 3.337407165836403
Validation loss: 3.0083392739517816

Epoch: 5| Step: 6
Training loss: 3.4983426666014106
Validation loss: 3.009468991950399

Epoch: 5| Step: 7
Training loss: 2.8589652346311576
Validation loss: 3.007686925705725

Epoch: 5| Step: 8
Training loss: 2.9077826939633056
Validation loss: 3.006477648502031

Epoch: 5| Step: 9
Training loss: 3.6480819888354517
Validation loss: 3.0100863783972662

Epoch: 5| Step: 10
Training loss: 2.7667277233632968
Validation loss: 3.0100191857879337

Epoch: 178| Step: 0
Training loss: 3.3835532982891348
Validation loss: 3.009625663323743

Epoch: 5| Step: 1
Training loss: 3.1900817289017462
Validation loss: 3.008989048327075

Epoch: 5| Step: 2
Training loss: 3.871559584657546
Validation loss: 3.0078417772994492

Epoch: 5| Step: 3
Training loss: 2.7393576428722746
Validation loss: 3.010122254069656

Epoch: 5| Step: 4
Training loss: 2.81820287025397
Validation loss: 3.0084046804610787

Epoch: 5| Step: 5
Training loss: 3.7997961541763603
Validation loss: 3.009113899494596

Epoch: 5| Step: 6
Training loss: 3.400758008047158
Validation loss: 3.0088029474851328

Epoch: 5| Step: 7
Training loss: 2.872219897658069
Validation loss: 3.009915206456708

Epoch: 5| Step: 8
Training loss: 3.1336265514695123
Validation loss: 3.0080197652151255

Epoch: 5| Step: 9
Training loss: 3.2624430508959623
Validation loss: 3.0086197399372385

Epoch: 5| Step: 10
Training loss: 3.488051044860544
Validation loss: 3.0091757169797506

Epoch: 179| Step: 0
Training loss: 3.3580806633972218
Validation loss: 3.0090669749498313

Epoch: 5| Step: 1
Training loss: 2.979219627354233
Validation loss: 3.0079298870404445

Epoch: 5| Step: 2
Training loss: 3.8276772996337916
Validation loss: 3.006096563814741

Epoch: 5| Step: 3
Training loss: 3.5553543974345825
Validation loss: 3.0048467450174856

Epoch: 5| Step: 4
Training loss: 3.3974302004843433
Validation loss: 3.0061449691363418

Epoch: 5| Step: 5
Training loss: 3.321301265919583
Validation loss: 3.006805835309116

Epoch: 5| Step: 6
Training loss: 3.0981537273922815
Validation loss: 3.0040084181629223

Epoch: 5| Step: 7
Training loss: 2.8435395550674007
Validation loss: 3.0045193962884214

Epoch: 5| Step: 8
Training loss: 3.2865933462583157
Validation loss: 3.0053863981633033

Epoch: 5| Step: 9
Training loss: 3.025305671065545
Validation loss: 3.004006608940368

Epoch: 5| Step: 10
Training loss: 3.2798476355915245
Validation loss: 3.0061244950425756

Epoch: 180| Step: 0
Training loss: 2.7688109587079137
Validation loss: 3.00363758498221

Epoch: 5| Step: 1
Training loss: 3.6514482838597275
Validation loss: 3.004764562436423

Epoch: 5| Step: 2
Training loss: 3.5727003530670154
Validation loss: 3.002432454879089

Epoch: 5| Step: 3
Training loss: 2.366249628888165
Validation loss: 3.0041499420743167

Epoch: 5| Step: 4
Training loss: 3.2454452876849498
Validation loss: 3.0047806825999936

Epoch: 5| Step: 5
Training loss: 3.089224848631979
Validation loss: 3.003138459214426

Epoch: 5| Step: 6
Training loss: 3.3217118489634143
Validation loss: 3.0021480950377533

Epoch: 5| Step: 7
Training loss: 3.205327165541636
Validation loss: 3.0023220093222367

Epoch: 5| Step: 8
Training loss: 3.8306319766635384
Validation loss: 3.0039225181460076

Epoch: 5| Step: 9
Training loss: 2.9546343463250064
Validation loss: 3.0072907810246887

Epoch: 5| Step: 10
Training loss: 3.8238976629202326
Validation loss: 3.0088356386354884

Epoch: 181| Step: 0
Training loss: 3.4805746522626326
Validation loss: 3.0092742168039703

Epoch: 5| Step: 1
Training loss: 3.184517156630503
Validation loss: 3.008789360717708

Epoch: 5| Step: 2
Training loss: 3.0387565243022117
Validation loss: 3.0043098894017963

Epoch: 5| Step: 3
Training loss: 2.6468300231210855
Validation loss: 3.0011563858195642

Epoch: 5| Step: 4
Training loss: 3.464312765383831
Validation loss: 3.0033538513991425

Epoch: 5| Step: 5
Training loss: 3.5920206967885395
Validation loss: 3.0046422028486846

Epoch: 5| Step: 6
Training loss: 3.0071478567609335
Validation loss: 3.0022385305616703

Epoch: 5| Step: 7
Training loss: 3.7347580461890995
Validation loss: 3.0024415970859186

Epoch: 5| Step: 8
Training loss: 3.0797455680091295
Validation loss: 3.0028317701247853

Epoch: 5| Step: 9
Training loss: 3.532754223227735
Validation loss: 3.0026866494282864

Epoch: 5| Step: 10
Training loss: 3.092931619928607
Validation loss: 3.0028723379161804

Epoch: 182| Step: 0
Training loss: 2.9857740069014076
Validation loss: 3.002086062819106

Epoch: 5| Step: 1
Training loss: 3.071947589377515
Validation loss: 3.001475644629242

Epoch: 5| Step: 2
Training loss: 3.14066462705294
Validation loss: 3.0013705373676274

Epoch: 5| Step: 3
Training loss: 2.8136964584265933
Validation loss: 2.998832715672275

Epoch: 5| Step: 4
Training loss: 3.108204683670434
Validation loss: 3.0009440437278156

Epoch: 5| Step: 5
Training loss: 3.364175179273639
Validation loss: 3.0007088603069043

Epoch: 5| Step: 6
Training loss: 3.770902236112255
Validation loss: 3.0006874144618756

Epoch: 5| Step: 7
Training loss: 3.0098068165172838
Validation loss: 2.9977455666756097

Epoch: 5| Step: 8
Training loss: 3.862991306699036
Validation loss: 2.9973831624804146

Epoch: 5| Step: 9
Training loss: 3.7373256119580165
Validation loss: 2.9996926139946734

Epoch: 5| Step: 10
Training loss: 2.868828992233962
Validation loss: 2.9993633257801946

Epoch: 183| Step: 0
Training loss: 3.6243902548626656
Validation loss: 2.9985127129245606

Epoch: 5| Step: 1
Training loss: 2.7939948057919652
Validation loss: 2.999085121047889

Epoch: 5| Step: 2
Training loss: 2.385908772933284
Validation loss: 2.9964970352575064

Epoch: 5| Step: 3
Training loss: 3.186490815416834
Validation loss: 2.998618308501432

Epoch: 5| Step: 4
Training loss: 3.502726718881033
Validation loss: 2.9996660056878173

Epoch: 5| Step: 5
Training loss: 3.2683564220846884
Validation loss: 3.0036133246599697

Epoch: 5| Step: 6
Training loss: 3.5959194103796075
Validation loss: 3.0021166478467696

Epoch: 5| Step: 7
Training loss: 3.9942320722263696
Validation loss: 3.0007365939263946

Epoch: 5| Step: 8
Training loss: 3.272553754791956
Validation loss: 2.9974709253692775

Epoch: 5| Step: 9
Training loss: 3.068594648542787
Validation loss: 2.9964264279368336

Epoch: 5| Step: 10
Training loss: 2.9579222129307294
Validation loss: 2.995893363745402

Epoch: 184| Step: 0
Training loss: 3.530091222173336
Validation loss: 2.9968109100396276

Epoch: 5| Step: 1
Training loss: 3.3028703748425694
Validation loss: 2.995539434028268

Epoch: 5| Step: 2
Training loss: 3.518920845505217
Validation loss: 2.9946153086792306

Epoch: 5| Step: 3
Training loss: 3.216549018988011
Validation loss: 2.9959055645514097

Epoch: 5| Step: 4
Training loss: 3.4209380238752938
Validation loss: 2.9962150682972264

Epoch: 5| Step: 5
Training loss: 3.2810613668807393
Validation loss: 2.992929478914618

Epoch: 5| Step: 6
Training loss: 2.4243324855490185
Validation loss: 2.995872592824242

Epoch: 5| Step: 7
Training loss: 3.660618576765816
Validation loss: 2.9935940272861843

Epoch: 5| Step: 8
Training loss: 3.3889397858791255
Validation loss: 2.995797524335253

Epoch: 5| Step: 9
Training loss: 3.0692943020362526
Validation loss: 2.9945688015841205

Epoch: 5| Step: 10
Training loss: 2.9419286904785507
Validation loss: 2.9944559034084817

Epoch: 185| Step: 0
Training loss: 3.277532888053969
Validation loss: 2.99367575693719

Epoch: 5| Step: 1
Training loss: 3.416305398837317
Validation loss: 2.992901806576251

Epoch: 5| Step: 2
Training loss: 3.5071799338730845
Validation loss: 2.9939408075993863

Epoch: 5| Step: 3
Training loss: 2.871528852022568
Validation loss: 2.990116908855689

Epoch: 5| Step: 4
Training loss: 3.2669464795948384
Validation loss: 2.994773167164695

Epoch: 5| Step: 5
Training loss: 3.01907293831407
Validation loss: 2.9928710468606803

Epoch: 5| Step: 6
Training loss: 3.1774773191877603
Validation loss: 2.9949023765156793

Epoch: 5| Step: 7
Training loss: 2.9913083371038423
Validation loss: 2.992523900140314

Epoch: 5| Step: 8
Training loss: 3.2948509620221786
Validation loss: 2.992165215119378

Epoch: 5| Step: 9
Training loss: 3.583755793545168
Validation loss: 2.9934874297584533

Epoch: 5| Step: 10
Training loss: 3.504480219241602
Validation loss: 2.992966121712977

Epoch: 186| Step: 0
Training loss: 2.7151417959710695
Validation loss: 2.9940900494182325

Epoch: 5| Step: 1
Training loss: 3.5208205424119696
Validation loss: 2.992811523215036

Epoch: 5| Step: 2
Training loss: 3.2765501241309254
Validation loss: 2.993994037544009

Epoch: 5| Step: 3
Training loss: 2.9251719758429306
Validation loss: 2.99149497696331

Epoch: 5| Step: 4
Training loss: 3.521412066385327
Validation loss: 2.993199022853045

Epoch: 5| Step: 5
Training loss: 3.7011272981319543
Validation loss: 2.9945658788683707

Epoch: 5| Step: 6
Training loss: 3.1735044907110934
Validation loss: 2.9956942460380964

Epoch: 5| Step: 7
Training loss: 3.3331319907097403
Validation loss: 2.993874959225773

Epoch: 5| Step: 8
Training loss: 3.33225778075758
Validation loss: 2.993052076647589

Epoch: 5| Step: 9
Training loss: 2.983973131534404
Validation loss: 2.99220981898552

Epoch: 5| Step: 10
Training loss: 3.3424309241062673
Validation loss: 2.9918999308979157

Epoch: 187| Step: 0
Training loss: 3.8963856161121684
Validation loss: 2.990319894926458

Epoch: 5| Step: 1
Training loss: 3.3548633175792233
Validation loss: 2.9884325038918003

Epoch: 5| Step: 2
Training loss: 3.497423177097634
Validation loss: 2.9885124960489917

Epoch: 5| Step: 3
Training loss: 3.4697896413225537
Validation loss: 2.9875830367408467

Epoch: 5| Step: 4
Training loss: 3.225251086019675
Validation loss: 2.988622938118834

Epoch: 5| Step: 5
Training loss: 3.4131556513355994
Validation loss: 2.9916082173971956

Epoch: 5| Step: 6
Training loss: 2.5908769988851366
Validation loss: 2.9894389478928414

Epoch: 5| Step: 7
Training loss: 2.572709562998597
Validation loss: 2.992636364921541

Epoch: 5| Step: 8
Training loss: 3.2968826655438876
Validation loss: 2.989950917150754

Epoch: 5| Step: 9
Training loss: 2.8465282576575746
Validation loss: 2.9878227867172824

Epoch: 5| Step: 10
Training loss: 3.5363776863052614
Validation loss: 2.9872939791295687

Epoch: 188| Step: 0
Training loss: 3.3594048077347636
Validation loss: 2.9853279092732614

Epoch: 5| Step: 1
Training loss: 2.5779587200757406
Validation loss: 2.9870030654414768

Epoch: 5| Step: 2
Training loss: 4.245637562100163
Validation loss: 2.9875216949371266

Epoch: 5| Step: 3
Training loss: 2.8018184853410086
Validation loss: 2.987907497928882

Epoch: 5| Step: 4
Training loss: 2.793798619472379
Validation loss: 2.9843984022158745

Epoch: 5| Step: 5
Training loss: 3.6789420439833354
Validation loss: 2.985724129339322

Epoch: 5| Step: 6
Training loss: 3.819574265248553
Validation loss: 2.987731784419409

Epoch: 5| Step: 7
Training loss: 3.4466411770653442
Validation loss: 2.9864113922283213

Epoch: 5| Step: 8
Training loss: 2.910566999903162
Validation loss: 2.98493836492048

Epoch: 5| Step: 9
Training loss: 3.5007619028508152
Validation loss: 2.986563712088746

Epoch: 5| Step: 10
Training loss: 2.00910427233427
Validation loss: 2.9867567280360006

Epoch: 189| Step: 0
Training loss: 3.2266199878069517
Validation loss: 2.9859447245607753

Epoch: 5| Step: 1
Training loss: 3.6527226052672375
Validation loss: 2.9860746232786326

Epoch: 5| Step: 2
Training loss: 3.3966235000168474
Validation loss: 2.985687374477939

Epoch: 5| Step: 3
Training loss: 2.976719809552952
Validation loss: 2.983045528739453

Epoch: 5| Step: 4
Training loss: 3.932899694192268
Validation loss: 2.9839031712180843

Epoch: 5| Step: 5
Training loss: 2.7109424250225436
Validation loss: 2.9839336247338464

Epoch: 5| Step: 6
Training loss: 2.532634780174302
Validation loss: 2.98361895893029

Epoch: 5| Step: 7
Training loss: 3.3786149621553503
Validation loss: 2.984435847269388

Epoch: 5| Step: 8
Training loss: 3.44794859780146
Validation loss: 2.983321501469576

Epoch: 5| Step: 9
Training loss: 2.904203945743425
Validation loss: 2.985029783888556

Epoch: 5| Step: 10
Training loss: 3.5052755650746454
Validation loss: 2.9856847006613223

Epoch: 190| Step: 0
Training loss: 2.7431047867060436
Validation loss: 2.9843059562518257

Epoch: 5| Step: 1
Training loss: 3.788629566117254
Validation loss: 2.986244528797066

Epoch: 5| Step: 2
Training loss: 2.9513037176870163
Validation loss: 2.9847096437721117

Epoch: 5| Step: 3
Training loss: 3.1975966965502485
Validation loss: 2.9835851485582805

Epoch: 5| Step: 4
Training loss: 3.4470799901328113
Validation loss: 2.981927355154422

Epoch: 5| Step: 5
Training loss: 2.765206601665821
Validation loss: 2.9818949347087194

Epoch: 5| Step: 6
Training loss: 3.049050205116392
Validation loss: 2.9840575164598016

Epoch: 5| Step: 7
Training loss: 3.3341590017700824
Validation loss: 2.9819521822200286

Epoch: 5| Step: 8
Training loss: 3.993925011371641
Validation loss: 2.981573374611398

Epoch: 5| Step: 9
Training loss: 2.8057647591408075
Validation loss: 2.9808565941989262

Epoch: 5| Step: 10
Training loss: 3.572213299234049
Validation loss: 2.981480197021169

Epoch: 191| Step: 0
Training loss: 3.4678727148912216
Validation loss: 2.981074046086174

Epoch: 5| Step: 1
Training loss: 3.0799335259534404
Validation loss: 2.980157162740208

Epoch: 5| Step: 2
Training loss: 3.455117457776753
Validation loss: 2.978330099889773

Epoch: 5| Step: 3
Training loss: 3.3708801555485906
Validation loss: 2.981357368504526

Epoch: 5| Step: 4
Training loss: 3.5145430192668496
Validation loss: 2.9807838335002446

Epoch: 5| Step: 5
Training loss: 3.3471055351238683
Validation loss: 2.980577769031672

Epoch: 5| Step: 6
Training loss: 3.2930452059629585
Validation loss: 2.979031727909693

Epoch: 5| Step: 7
Training loss: 3.142156275096595
Validation loss: 2.978128631158827

Epoch: 5| Step: 8
Training loss: 2.840636676558699
Validation loss: 2.9785232698237207

Epoch: 5| Step: 9
Training loss: 3.7494697195871027
Validation loss: 2.979614646360786

Epoch: 5| Step: 10
Training loss: 2.191552359594114
Validation loss: 2.9794881503657322

Epoch: 192| Step: 0
Training loss: 3.1602125316082907
Validation loss: 2.979538870554666

Epoch: 5| Step: 1
Training loss: 3.6798060695715695
Validation loss: 2.978767735466061

Epoch: 5| Step: 2
Training loss: 2.9626178251246955
Validation loss: 2.9781726860155096

Epoch: 5| Step: 3
Training loss: 3.2367191389278367
Validation loss: 2.981727052030345

Epoch: 5| Step: 4
Training loss: 3.677601865061697
Validation loss: 2.9760252911598637

Epoch: 5| Step: 5
Training loss: 3.0622992936364257
Validation loss: 2.9779698895064426

Epoch: 5| Step: 6
Training loss: 3.609593372427152
Validation loss: 2.977402075344068

Epoch: 5| Step: 7
Training loss: 2.8740124872370396
Validation loss: 2.9779047873321027

Epoch: 5| Step: 8
Training loss: 3.5625025431306026
Validation loss: 2.981104231815534

Epoch: 5| Step: 9
Training loss: 2.8265081177936873
Validation loss: 2.9807841164586124

Epoch: 5| Step: 10
Training loss: 2.9773302264620876
Validation loss: 2.9811622658830665

Epoch: 193| Step: 0
Training loss: 3.245948907625178
Validation loss: 2.977083012041869

Epoch: 5| Step: 1
Training loss: 3.2405300085994115
Validation loss: 2.976386026289613

Epoch: 5| Step: 2
Training loss: 3.4670515971562565
Validation loss: 2.9785324277492955

Epoch: 5| Step: 3
Training loss: 3.5770963164626943
Validation loss: 2.9799481669213552

Epoch: 5| Step: 4
Training loss: 3.6120677332985496
Validation loss: 2.989862350461357

Epoch: 5| Step: 5
Training loss: 2.5985660193172864
Validation loss: 2.9913475733886394

Epoch: 5| Step: 6
Training loss: 3.352701629332982
Validation loss: 2.98243785203573

Epoch: 5| Step: 7
Training loss: 3.8818177574259813
Validation loss: 2.979267933268407

Epoch: 5| Step: 8
Training loss: 2.5501038848061115
Validation loss: 2.9761579192998684

Epoch: 5| Step: 9
Training loss: 2.978450306660839
Validation loss: 2.9782108093218933

Epoch: 5| Step: 10
Training loss: 3.0665219424831234
Validation loss: 2.980003796650946

Epoch: 194| Step: 0
Training loss: 3.856351587079605
Validation loss: 2.991663957655669

Epoch: 5| Step: 1
Training loss: 3.1997408225482786
Validation loss: 2.991615806483406

Epoch: 5| Step: 2
Training loss: 3.16192675434864
Validation loss: 2.991048728058579

Epoch: 5| Step: 3
Training loss: 3.6516313643485088
Validation loss: 2.9854629020687806

Epoch: 5| Step: 4
Training loss: 3.077159284731754
Validation loss: 2.9762970878151855

Epoch: 5| Step: 5
Training loss: 2.9206483275357216
Validation loss: 2.974304620991817

Epoch: 5| Step: 6
Training loss: 3.4528124913824922
Validation loss: 2.980746954936429

Epoch: 5| Step: 7
Training loss: 2.6704944814208234
Validation loss: 2.9848766844783374

Epoch: 5| Step: 8
Training loss: 3.4054210249061065
Validation loss: 2.9835896484385303

Epoch: 5| Step: 9
Training loss: 3.228700829817144
Validation loss: 2.989014177374719

Epoch: 5| Step: 10
Training loss: 3.042593270520142
Validation loss: 2.984627244276805

Epoch: 195| Step: 0
Training loss: 3.1681397341342126
Validation loss: 2.978868640117168

Epoch: 5| Step: 1
Training loss: 3.662291141322409
Validation loss: 2.973421129349281

Epoch: 5| Step: 2
Training loss: 3.217381306721253
Validation loss: 2.9758099402463833

Epoch: 5| Step: 3
Training loss: 3.478035398359075
Validation loss: 2.9747161465784524

Epoch: 5| Step: 4
Training loss: 2.8972494564399867
Validation loss: 2.9745771643760848

Epoch: 5| Step: 5
Training loss: 3.4076141985356867
Validation loss: 2.9719660732325948

Epoch: 5| Step: 6
Training loss: 3.716146631737534
Validation loss: 2.9742050863035567

Epoch: 5| Step: 7
Training loss: 3.4801067673539294
Validation loss: 2.970644010668007

Epoch: 5| Step: 8
Training loss: 2.6807273871163484
Validation loss: 2.9737473469349474

Epoch: 5| Step: 9
Training loss: 3.100236046941092
Validation loss: 2.9736544741522803

Epoch: 5| Step: 10
Training loss: 2.7031220011611796
Validation loss: 2.973677313290954

Epoch: 196| Step: 0
Training loss: 3.5851938311796903
Validation loss: 2.973606714163463

Epoch: 5| Step: 1
Training loss: 2.9843286640504667
Validation loss: 2.9730102161014655

Epoch: 5| Step: 2
Training loss: 3.7177657419640604
Validation loss: 2.980450658477605

Epoch: 5| Step: 3
Training loss: 3.1719984209073573
Validation loss: 2.9717047313075025

Epoch: 5| Step: 4
Training loss: 3.0323671464994857
Validation loss: 2.9752485924728576

Epoch: 5| Step: 5
Training loss: 3.251756340235942
Validation loss: 2.982303291379436

Epoch: 5| Step: 6
Training loss: 2.8388174687123695
Validation loss: 2.977130120373898

Epoch: 5| Step: 7
Training loss: 3.796158962470772
Validation loss: 2.9728325639564566

Epoch: 5| Step: 8
Training loss: 3.201294017460825
Validation loss: 2.978488837837306

Epoch: 5| Step: 9
Training loss: 3.0680446645477097
Validation loss: 2.9719864695202136

Epoch: 5| Step: 10
Training loss: 2.916968974840683
Validation loss: 2.9733982002992185

Epoch: 197| Step: 0
Training loss: 3.908497400371521
Validation loss: 2.9704057170657414

Epoch: 5| Step: 1
Training loss: 3.0423144517300584
Validation loss: 2.970979351977084

Epoch: 5| Step: 2
Training loss: 2.5940832820161432
Validation loss: 2.9710817412299164

Epoch: 5| Step: 3
Training loss: 2.852939053980568
Validation loss: 2.9717108235721272

Epoch: 5| Step: 4
Training loss: 3.6178982326857003
Validation loss: 2.973694972725155

Epoch: 5| Step: 5
Training loss: 3.5712133560730766
Validation loss: 2.9710473299987505

Epoch: 5| Step: 6
Training loss: 2.8215491629519907
Validation loss: 2.970767067260209

Epoch: 5| Step: 7
Training loss: 3.633115300510596
Validation loss: 2.97099608603577

Epoch: 5| Step: 8
Training loss: 3.1525443201178978
Validation loss: 2.9708626864004226

Epoch: 5| Step: 9
Training loss: 3.1641916507688674
Validation loss: 2.967281254134115

Epoch: 5| Step: 10
Training loss: 3.1781105423770066
Validation loss: 2.9690861872681236

Epoch: 198| Step: 0
Training loss: 3.209532790126313
Validation loss: 2.9659963015845956

Epoch: 5| Step: 1
Training loss: 3.234472448382911
Validation loss: 2.9679510072248303

Epoch: 5| Step: 2
Training loss: 2.9904560228720043
Validation loss: 2.968913911311054

Epoch: 5| Step: 3
Training loss: 3.3998317620783842
Validation loss: 2.9689613357735505

Epoch: 5| Step: 4
Training loss: 2.9182931089070934
Validation loss: 2.9688408311507324

Epoch: 5| Step: 5
Training loss: 3.6199311959066494
Validation loss: 2.9773462265153783

Epoch: 5| Step: 6
Training loss: 3.5477205184562095
Validation loss: 2.976487247677544

Epoch: 5| Step: 7
Training loss: 3.1640838999083414
Validation loss: 2.971569141974084

Epoch: 5| Step: 8
Training loss: 3.128969341884969
Validation loss: 2.968190228591776

Epoch: 5| Step: 9
Training loss: 3.1407485861683604
Validation loss: 2.9661545621769854

Epoch: 5| Step: 10
Training loss: 3.304205388102431
Validation loss: 2.9676912009642864

Epoch: 199| Step: 0
Training loss: 3.202047324903686
Validation loss: 2.96854899945205

Epoch: 5| Step: 1
Training loss: 2.667781259140009
Validation loss: 2.9684747936448033

Epoch: 5| Step: 2
Training loss: 3.2123773692433395
Validation loss: 2.968010626075111

Epoch: 5| Step: 3
Training loss: 3.605566087526817
Validation loss: 2.9656115312530966

Epoch: 5| Step: 4
Training loss: 3.3246407336267825
Validation loss: 2.965321747991299

Epoch: 5| Step: 5
Training loss: 2.25849962173604
Validation loss: 2.96882481116445

Epoch: 5| Step: 6
Training loss: 3.1059809424312466
Validation loss: 2.968554366724798

Epoch: 5| Step: 7
Training loss: 3.337288861971973
Validation loss: 2.9694706161496134

Epoch: 5| Step: 8
Training loss: 3.8703504170118586
Validation loss: 2.9681638785637636

Epoch: 5| Step: 9
Training loss: 3.70216543907663
Validation loss: 2.9677308643811364

Epoch: 5| Step: 10
Training loss: 3.1621368199665993
Validation loss: 2.966766760592661

Epoch: 200| Step: 0
Training loss: 3.5798716717101864
Validation loss: 2.9645529075860346

Epoch: 5| Step: 1
Training loss: 2.874931002908483
Validation loss: 2.96500003157506

Epoch: 5| Step: 2
Training loss: 3.3367220025391693
Validation loss: 2.9652706532097635

Epoch: 5| Step: 3
Training loss: 3.6045272440976754
Validation loss: 2.9631375293284368

Epoch: 5| Step: 4
Training loss: 3.0047718879327165
Validation loss: 2.9651452277820236

Epoch: 5| Step: 5
Training loss: 3.1708420447999752
Validation loss: 2.964251424912935

Epoch: 5| Step: 6
Training loss: 3.4223441581828586
Validation loss: 2.9612688422538267

Epoch: 5| Step: 7
Training loss: 3.528335989361104
Validation loss: 2.964584026844345

Epoch: 5| Step: 8
Training loss: 2.8132262245989894
Validation loss: 2.9651625143826843

Epoch: 5| Step: 9
Training loss: 3.1786800353720643
Validation loss: 2.9659284238860666

Epoch: 5| Step: 10
Training loss: 3.0443131068905585
Validation loss: 2.963466294204926

Epoch: 201| Step: 0
Training loss: 3.1343390724199636
Validation loss: 2.9655323321960956

Epoch: 5| Step: 1
Training loss: 3.2236848796348
Validation loss: 2.964416102116716

Epoch: 5| Step: 2
Training loss: 3.0743909155055045
Validation loss: 2.9667321731489884

Epoch: 5| Step: 3
Training loss: 3.105249015663605
Validation loss: 2.9697857572473776

Epoch: 5| Step: 4
Training loss: 3.933224854886158
Validation loss: 2.963577619485517

Epoch: 5| Step: 5
Training loss: 3.1774606616138485
Validation loss: 2.959696240133493

Epoch: 5| Step: 6
Training loss: 3.709334820447012
Validation loss: 2.9634634930688657

Epoch: 5| Step: 7
Training loss: 2.5986485013090386
Validation loss: 2.958624045718666

Epoch: 5| Step: 8
Training loss: 3.4091595463634485
Validation loss: 2.959876630384152

Epoch: 5| Step: 9
Training loss: 3.5048515210013016
Validation loss: 2.960388026979685

Epoch: 5| Step: 10
Training loss: 2.360832623033813
Validation loss: 2.9620420637226648

Epoch: 202| Step: 0
Training loss: 3.3361384668498273
Validation loss: 2.960949372108047

Epoch: 5| Step: 1
Training loss: 3.52323584814795
Validation loss: 2.9603917749443256

Epoch: 5| Step: 2
Training loss: 2.6305891208281897
Validation loss: 2.9595738787625208

Epoch: 5| Step: 3
Training loss: 3.4075494090113376
Validation loss: 2.9661560816119943

Epoch: 5| Step: 4
Training loss: 3.3754746845004076
Validation loss: 2.9642230679893258

Epoch: 5| Step: 5
Training loss: 2.9981731574584702
Validation loss: 2.9663030085107436

Epoch: 5| Step: 6
Training loss: 3.002235533337089
Validation loss: 2.9605750210731587

Epoch: 5| Step: 7
Training loss: 3.4955137656138193
Validation loss: 2.959562170916464

Epoch: 5| Step: 8
Training loss: 2.8153845511849753
Validation loss: 2.9610715917924675

Epoch: 5| Step: 9
Training loss: 3.135496896792424
Validation loss: 2.9566717587252

Epoch: 5| Step: 10
Training loss: 3.843352506600225
Validation loss: 2.957285011710322

Epoch: 203| Step: 0
Training loss: 2.9940912549949616
Validation loss: 2.9548414843032567

Epoch: 5| Step: 1
Training loss: 3.2466294343551123
Validation loss: 2.958223425490111

Epoch: 5| Step: 2
Training loss: 3.5350055810002106
Validation loss: 2.9609193281018205

Epoch: 5| Step: 3
Training loss: 3.1347990895799445
Validation loss: 2.957927667955615

Epoch: 5| Step: 4
Training loss: 3.1636709465480486
Validation loss: 2.964105995511187

Epoch: 5| Step: 5
Training loss: 3.6881674469607924
Validation loss: 2.963824146541612

Epoch: 5| Step: 6
Training loss: 3.1639511277177506
Validation loss: 2.9629313641433304

Epoch: 5| Step: 7
Training loss: 2.701130743258329
Validation loss: 2.9637631805838622

Epoch: 5| Step: 8
Training loss: 3.868864678330189
Validation loss: 2.9612036698561006

Epoch: 5| Step: 9
Training loss: 2.995893688062602
Validation loss: 2.962201267748737

Epoch: 5| Step: 10
Training loss: 2.8978032243264042
Validation loss: 2.9572593065780137

Epoch: 204| Step: 0
Training loss: 2.97921562599198
Validation loss: 2.9600904366042737

Epoch: 5| Step: 1
Training loss: 2.874310949930374
Validation loss: 2.957633177560906

Epoch: 5| Step: 2
Training loss: 2.741546121128978
Validation loss: 2.9544747362853117

Epoch: 5| Step: 3
Training loss: 3.7191887604705873
Validation loss: 2.9543555827951975

Epoch: 5| Step: 4
Training loss: 3.2164483590898665
Validation loss: 2.958425014056776

Epoch: 5| Step: 5
Training loss: 3.5098639863443024
Validation loss: 2.9560591859262013

Epoch: 5| Step: 6
Training loss: 3.566188174680215
Validation loss: 2.9542489639589466

Epoch: 5| Step: 7
Training loss: 3.212384939545212
Validation loss: 2.955463463435679

Epoch: 5| Step: 8
Training loss: 3.17384390020118
Validation loss: 2.9541324846477672

Epoch: 5| Step: 9
Training loss: 3.267573747101819
Validation loss: 2.9533336240388244

Epoch: 5| Step: 10
Training loss: 3.201548118428686
Validation loss: 2.9546502020410714

Epoch: 205| Step: 0
Training loss: 3.8625951761414212
Validation loss: 2.9529909067766056

Epoch: 5| Step: 1
Training loss: 3.2707833612273287
Validation loss: 2.953909892114611

Epoch: 5| Step: 2
Training loss: 3.107142274602826
Validation loss: 2.954839162586484

Epoch: 5| Step: 3
Training loss: 3.175061509144827
Validation loss: 2.950703507686902

Epoch: 5| Step: 4
Training loss: 3.176382385641636
Validation loss: 2.9547169037483667

Epoch: 5| Step: 5
Training loss: 2.6384976637994204
Validation loss: 2.9569897108459853

Epoch: 5| Step: 6
Training loss: 3.218878289786367
Validation loss: 2.9557095535897533

Epoch: 5| Step: 7
Training loss: 2.873928036080128
Validation loss: 2.954527230812147

Epoch: 5| Step: 8
Training loss: 3.4930010707710517
Validation loss: 2.9545948923459413

Epoch: 5| Step: 9
Training loss: 3.4009592105670596
Validation loss: 2.9621303639453167

Epoch: 5| Step: 10
Training loss: 3.201813517718684
Validation loss: 2.9640790115273568

Epoch: 206| Step: 0
Training loss: 3.316248230601161
Validation loss: 2.9731604076753384

Epoch: 5| Step: 1
Training loss: 3.3122803237336607
Validation loss: 2.95580205783661

Epoch: 5| Step: 2
Training loss: 2.350499822341078
Validation loss: 2.957369595553112

Epoch: 5| Step: 3
Training loss: 3.6948809704430516
Validation loss: 2.9530821861856937

Epoch: 5| Step: 4
Training loss: 2.946901899358606
Validation loss: 2.9491869400939525

Epoch: 5| Step: 5
Training loss: 2.97869908502617
Validation loss: 2.9481448546806988

Epoch: 5| Step: 6
Training loss: 3.5732456571109146
Validation loss: 2.949966734150596

Epoch: 5| Step: 7
Training loss: 3.6893698913652586
Validation loss: 2.955703801305596

Epoch: 5| Step: 8
Training loss: 2.951092217188922
Validation loss: 2.9506560452134223

Epoch: 5| Step: 9
Training loss: 2.8601996894961625
Validation loss: 2.9493667848982668

Epoch: 5| Step: 10
Training loss: 3.672681095028705
Validation loss: 2.95288661401115

Epoch: 207| Step: 0
Training loss: 3.6350060844108105
Validation loss: 2.949037407902046

Epoch: 5| Step: 1
Training loss: 3.657174278873607
Validation loss: 2.947529787871928

Epoch: 5| Step: 2
Training loss: 3.2893956393972057
Validation loss: 2.9517485963793386

Epoch: 5| Step: 3
Training loss: 2.7540025193723014
Validation loss: 2.9539539644906547

Epoch: 5| Step: 4
Training loss: 3.0914916455956334
Validation loss: 2.9544607209270985

Epoch: 5| Step: 5
Training loss: 2.865887006556711
Validation loss: 2.959788882227237

Epoch: 5| Step: 6
Training loss: 2.7792525244342183
Validation loss: 2.952036712473111

Epoch: 5| Step: 7
Training loss: 3.238957793424522
Validation loss: 2.9485821354192097

Epoch: 5| Step: 8
Training loss: 3.4471545496003753
Validation loss: 2.9457125306824263

Epoch: 5| Step: 9
Training loss: 3.1214142635998963
Validation loss: 2.9456691234995813

Epoch: 5| Step: 10
Training loss: 3.530867969474204
Validation loss: 2.9490706607283586

Epoch: 208| Step: 0
Training loss: 3.163912244455082
Validation loss: 2.951275073049954

Epoch: 5| Step: 1
Training loss: 2.651877270944141
Validation loss: 2.945323005875789

Epoch: 5| Step: 2
Training loss: 3.285752758251067
Validation loss: 2.9506710882276326

Epoch: 5| Step: 3
Training loss: 3.0936732427149494
Validation loss: 2.9514663690622935

Epoch: 5| Step: 4
Training loss: 3.6865829361920457
Validation loss: 2.9506326616625844

Epoch: 5| Step: 5
Training loss: 3.5042343411315855
Validation loss: 2.9523346162212363

Epoch: 5| Step: 6
Training loss: 2.667661054302227
Validation loss: 2.9510803697105663

Epoch: 5| Step: 7
Training loss: 3.235237485726557
Validation loss: 2.9518277101709263

Epoch: 5| Step: 8
Training loss: 3.5863076810562595
Validation loss: 2.9553714647242195

Epoch: 5| Step: 9
Training loss: 3.225501525679857
Validation loss: 2.9505455904405844

Epoch: 5| Step: 10
Training loss: 3.2704366617559084
Validation loss: 2.950815820973504

Epoch: 209| Step: 0
Training loss: 3.2995363314322526
Validation loss: 2.9435773499407287

Epoch: 5| Step: 1
Training loss: 2.704092392883514
Validation loss: 2.9433094145105922

Epoch: 5| Step: 2
Training loss: 3.080540208135253
Validation loss: 2.944408220592138

Epoch: 5| Step: 3
Training loss: 3.2575699603867245
Validation loss: 2.94633489164278

Epoch: 5| Step: 4
Training loss: 3.4094629096315625
Validation loss: 2.942947755758952

Epoch: 5| Step: 5
Training loss: 3.1046637493390423
Validation loss: 2.9459726418482837

Epoch: 5| Step: 6
Training loss: 3.4648452638366902
Validation loss: 2.9469833459022254

Epoch: 5| Step: 7
Training loss: 2.929864577981805
Validation loss: 2.9459025622986585

Epoch: 5| Step: 8
Training loss: 3.6360652020843345
Validation loss: 2.9442642760715008

Epoch: 5| Step: 9
Training loss: 3.3178295231138386
Validation loss: 2.942733579558722

Epoch: 5| Step: 10
Training loss: 3.125754303495448
Validation loss: 2.9446907256480053

Epoch: 210| Step: 0
Training loss: 3.3021406455536653
Validation loss: 2.9407854882728843

Epoch: 5| Step: 1
Training loss: 3.3880545018033494
Validation loss: 2.9442396867319998

Epoch: 5| Step: 2
Training loss: 3.252757443231369
Validation loss: 2.939819071573052

Epoch: 5| Step: 3
Training loss: 3.2508702213476504
Validation loss: 2.9461363132658493

Epoch: 5| Step: 4
Training loss: 2.846687895303347
Validation loss: 2.9430840696221416

Epoch: 5| Step: 5
Training loss: 2.648580541658236
Validation loss: 2.9408990956361403

Epoch: 5| Step: 6
Training loss: 2.9977519831558195
Validation loss: 2.944596166784839

Epoch: 5| Step: 7
Training loss: 2.7527197480033023
Validation loss: 2.946756954367088

Epoch: 5| Step: 8
Training loss: 3.829408889652923
Validation loss: 2.946876864863923

Epoch: 5| Step: 9
Training loss: 3.6306424129972767
Validation loss: 2.943829336621972

Epoch: 5| Step: 10
Training loss: 3.3768963607685785
Validation loss: 2.941532773055771

Epoch: 211| Step: 0
Training loss: 3.534506317586321
Validation loss: 2.941801713866324

Epoch: 5| Step: 1
Training loss: 2.402818983260016
Validation loss: 2.940990598663737

Epoch: 5| Step: 2
Training loss: 3.6226251649787753
Validation loss: 2.940244798715601

Epoch: 5| Step: 3
Training loss: 2.902754291234579
Validation loss: 2.942962961871678

Epoch: 5| Step: 4
Training loss: 3.2813646568974386
Validation loss: 2.9419746433155036

Epoch: 5| Step: 5
Training loss: 3.506705536379134
Validation loss: 2.9447206218173263

Epoch: 5| Step: 6
Training loss: 4.0205041358602935
Validation loss: 2.9406801114126973

Epoch: 5| Step: 7
Training loss: 3.2343568663157876
Validation loss: 2.944392341067124

Epoch: 5| Step: 8
Training loss: 2.8105249887850934
Validation loss: 2.937199360987311

Epoch: 5| Step: 9
Training loss: 2.6624372340581237
Validation loss: 2.9392068233369457

Epoch: 5| Step: 10
Training loss: 3.1388209081469447
Validation loss: 2.939583886855817

Epoch: 212| Step: 0
Training loss: 3.4357955868615444
Validation loss: 2.938043205952828

Epoch: 5| Step: 1
Training loss: 2.938940466091891
Validation loss: 2.936787933745572

Epoch: 5| Step: 2
Training loss: 3.0879026698650285
Validation loss: 2.941080732943887

Epoch: 5| Step: 3
Training loss: 3.523668370433012
Validation loss: 2.941716514201547

Epoch: 5| Step: 4
Training loss: 3.189926570178744
Validation loss: 2.9380300947262596

Epoch: 5| Step: 5
Training loss: 3.298517622487316
Validation loss: 2.9367234445704433

Epoch: 5| Step: 6
Training loss: 3.909943566268732
Validation loss: 2.938206678647072

Epoch: 5| Step: 7
Training loss: 2.659152251797965
Validation loss: 2.9359052025367918

Epoch: 5| Step: 8
Training loss: 3.2841430988706724
Validation loss: 2.937170762964493

Epoch: 5| Step: 9
Training loss: 3.10855797236299
Validation loss: 2.93415998883575

Epoch: 5| Step: 10
Training loss: 2.7267141218027557
Validation loss: 2.9352952777573487

Epoch: 213| Step: 0
Training loss: 3.8092209519617337
Validation loss: 2.9377547943198064

Epoch: 5| Step: 1
Training loss: 2.927869553145983
Validation loss: 2.9371054704484045

Epoch: 5| Step: 2
Training loss: 2.7813784108896416
Validation loss: 2.9414651640371092

Epoch: 5| Step: 3
Training loss: 2.9901914786582693
Validation loss: 2.944333249640183

Epoch: 5| Step: 4
Training loss: 3.6643908257999094
Validation loss: 2.954810957399467

Epoch: 5| Step: 5
Training loss: 3.9596818065926014
Validation loss: 2.949126373932703

Epoch: 5| Step: 6
Training loss: 3.5184934315893224
Validation loss: 2.9583054407917273

Epoch: 5| Step: 7
Training loss: 3.135389832712381
Validation loss: 2.9762521937895836

Epoch: 5| Step: 8
Training loss: 3.0357803626041764
Validation loss: 2.938950098023479

Epoch: 5| Step: 9
Training loss: 2.7472166367557507
Validation loss: 2.9355420001829664

Epoch: 5| Step: 10
Training loss: 2.4432057821054243
Validation loss: 2.934940795979128

Epoch: 214| Step: 0
Training loss: 3.277486768473229
Validation loss: 2.9368747079702957

Epoch: 5| Step: 1
Training loss: 3.0485395530773824
Validation loss: 2.9357811937689537

Epoch: 5| Step: 2
Training loss: 3.0703239926033317
Validation loss: 2.9403979865290912

Epoch: 5| Step: 3
Training loss: 2.4259548155876582
Validation loss: 2.9436886453244795

Epoch: 5| Step: 4
Training loss: 3.716330374199166
Validation loss: 2.9529755734620475

Epoch: 5| Step: 5
Training loss: 3.2546935302561306
Validation loss: 2.946070449331497

Epoch: 5| Step: 6
Training loss: 3.4388884081315494
Validation loss: 2.9384460950382043

Epoch: 5| Step: 7
Training loss: 3.286863774572231
Validation loss: 2.9382528833906116

Epoch: 5| Step: 8
Training loss: 3.1509055032025803
Validation loss: 2.936695865904363

Epoch: 5| Step: 9
Training loss: 3.5559523794806753
Validation loss: 2.935566650151103

Epoch: 5| Step: 10
Training loss: 3.111372263105002
Validation loss: 2.93466591073846

Epoch: 215| Step: 0
Training loss: 2.929256478710324
Validation loss: 2.9329026866309778

Epoch: 5| Step: 1
Training loss: 2.890553736452639
Validation loss: 2.9333520725309836

Epoch: 5| Step: 2
Training loss: 3.3927262646665155
Validation loss: 2.931225288228

Epoch: 5| Step: 3
Training loss: 3.3770594494630264
Validation loss: 2.934141719248277

Epoch: 5| Step: 4
Training loss: 3.1149519550175846
Validation loss: 2.932952233511274

Epoch: 5| Step: 5
Training loss: 2.88747948313108
Validation loss: 2.9330574413734616

Epoch: 5| Step: 6
Training loss: 3.021798411585192
Validation loss: 2.9358424159646876

Epoch: 5| Step: 7
Training loss: 3.056168219285436
Validation loss: 2.9408098257920234

Epoch: 5| Step: 8
Training loss: 3.7269753921142668
Validation loss: 2.936439836014405

Epoch: 5| Step: 9
Training loss: 3.7051077254846843
Validation loss: 2.9436472148658788

Epoch: 5| Step: 10
Training loss: 3.167788574513745
Validation loss: 2.9404598536731164

Epoch: 216| Step: 0
Training loss: 3.358466020965085
Validation loss: 2.9347471709857373

Epoch: 5| Step: 1
Training loss: 3.306909125524549
Validation loss: 2.9344087619405914

Epoch: 5| Step: 2
Training loss: 2.910745241099183
Validation loss: 2.930388799701056

Epoch: 5| Step: 3
Training loss: 3.046719434630385
Validation loss: 2.9287492661027064

Epoch: 5| Step: 4
Training loss: 3.2557425017453236
Validation loss: 2.9284012195751665

Epoch: 5| Step: 5
Training loss: 3.398881554367212
Validation loss: 2.931238697517445

Epoch: 5| Step: 6
Training loss: 3.3331357102621704
Validation loss: 2.9302004041813414

Epoch: 5| Step: 7
Training loss: 3.151372786009514
Validation loss: 2.929454928884795

Epoch: 5| Step: 8
Training loss: 2.9376110299412383
Validation loss: 2.9326273612103946

Epoch: 5| Step: 9
Training loss: 3.320071510096329
Validation loss: 2.927424974983326

Epoch: 5| Step: 10
Training loss: 3.3469563735202104
Validation loss: 2.9298614122188207

Epoch: 217| Step: 0
Training loss: 2.597628072714894
Validation loss: 2.9323375321430225

Epoch: 5| Step: 1
Training loss: 3.027551971165871
Validation loss: 2.930254691399259

Epoch: 5| Step: 2
Training loss: 3.4788247281161833
Validation loss: 2.9267321887509223

Epoch: 5| Step: 3
Training loss: 3.443038778369757
Validation loss: 2.92809223060361

Epoch: 5| Step: 4
Training loss: 3.0135043104440618
Validation loss: 2.9284879919386566

Epoch: 5| Step: 5
Training loss: 3.8895799083452856
Validation loss: 2.928324670069046

Epoch: 5| Step: 6
Training loss: 3.3449365524866286
Validation loss: 2.9270042385683577

Epoch: 5| Step: 7
Training loss: 3.5824056947571714
Validation loss: 2.9291240270042196

Epoch: 5| Step: 8
Training loss: 3.081302300371058
Validation loss: 2.9278784579776844

Epoch: 5| Step: 9
Training loss: 2.844136641491339
Validation loss: 2.9266297414414613

Epoch: 5| Step: 10
Training loss: 2.77492111712537
Validation loss: 2.929379667127174

Epoch: 218| Step: 0
Training loss: 2.859955608850376
Validation loss: 2.9271926961633223

Epoch: 5| Step: 1
Training loss: 2.949264829161962
Validation loss: 2.925271293834839

Epoch: 5| Step: 2
Training loss: 2.968911578148178
Validation loss: 2.9312625921734434

Epoch: 5| Step: 3
Training loss: 3.2519085488686605
Validation loss: 2.9247406589952023

Epoch: 5| Step: 4
Training loss: 3.3553371559069247
Validation loss: 2.930631577943397

Epoch: 5| Step: 5
Training loss: 3.2964717383334046
Validation loss: 2.925796257931364

Epoch: 5| Step: 6
Training loss: 3.578205757395841
Validation loss: 2.9254025721716577

Epoch: 5| Step: 7
Training loss: 3.2658022599730554
Validation loss: 2.923233187721947

Epoch: 5| Step: 8
Training loss: 3.059353516048321
Validation loss: 2.9264513621798844

Epoch: 5| Step: 9
Training loss: 2.8986720892473237
Validation loss: 2.9278894869726

Epoch: 5| Step: 10
Training loss: 3.8161404848050426
Validation loss: 2.9286389497640304

Epoch: 219| Step: 0
Training loss: 3.5565443617704546
Validation loss: 2.9276582178679837

Epoch: 5| Step: 1
Training loss: 3.8547916764746906
Validation loss: 2.926098124616963

Epoch: 5| Step: 2
Training loss: 2.9015044157739722
Validation loss: 2.933223053554917

Epoch: 5| Step: 3
Training loss: 3.1824899831226148
Validation loss: 2.9281125998021307

Epoch: 5| Step: 4
Training loss: 3.3823870596177095
Validation loss: 2.9302312635915766

Epoch: 5| Step: 5
Training loss: 3.0946240972406738
Validation loss: 2.9290931874371204

Epoch: 5| Step: 6
Training loss: 3.0226677597351297
Validation loss: 2.938648714038556

Epoch: 5| Step: 7
Training loss: 2.9840712467616304
Validation loss: 2.929473119186438

Epoch: 5| Step: 8
Training loss: 3.0690199288485296
Validation loss: 2.934852291792031

Epoch: 5| Step: 9
Training loss: 3.464009387719382
Validation loss: 2.9275954076714448

Epoch: 5| Step: 10
Training loss: 2.5747374502606393
Validation loss: 2.9249250570841845

Epoch: 220| Step: 0
Training loss: 2.342221486441159
Validation loss: 2.9221475099140526

Epoch: 5| Step: 1
Training loss: 3.3778516237094953
Validation loss: 2.9213374579323053

Epoch: 5| Step: 2
Training loss: 3.857626824064909
Validation loss: 2.9207915295039477

Epoch: 5| Step: 3
Training loss: 3.0333031062482037
Validation loss: 2.9223906973497207

Epoch: 5| Step: 4
Training loss: 3.308125900824817
Validation loss: 2.9235423815782298

Epoch: 5| Step: 5
Training loss: 3.135384661911424
Validation loss: 2.9216907884701415

Epoch: 5| Step: 6
Training loss: 3.494575247433248
Validation loss: 2.920713060174926

Epoch: 5| Step: 7
Training loss: 3.2130509078560534
Validation loss: 2.923438122126869

Epoch: 5| Step: 8
Training loss: 3.358751531898027
Validation loss: 2.921581835974769

Epoch: 5| Step: 9
Training loss: 2.684743487787026
Validation loss: 2.923494404487754

Epoch: 5| Step: 10
Training loss: 3.2685917423952766
Validation loss: 2.925583459336142

Epoch: 221| Step: 0
Training loss: 3.1890395691200015
Validation loss: 2.9251471129525193

Epoch: 5| Step: 1
Training loss: 3.1652644382307495
Validation loss: 2.933367118636223

Epoch: 5| Step: 2
Training loss: 3.068710569295428
Validation loss: 2.933288524258403

Epoch: 5| Step: 3
Training loss: 3.0052092148345944
Validation loss: 2.936608616724474

Epoch: 5| Step: 4
Training loss: 3.6795448226966725
Validation loss: 2.9325293754954984

Epoch: 5| Step: 5
Training loss: 2.9298513951552
Validation loss: 2.9310347922030293

Epoch: 5| Step: 6
Training loss: 3.4988083854511136
Validation loss: 2.933939255595835

Epoch: 5| Step: 7
Training loss: 3.277401656501991
Validation loss: 2.917465994042944

Epoch: 5| Step: 8
Training loss: 3.7428839240577214
Validation loss: 2.9201779396927408

Epoch: 5| Step: 9
Training loss: 2.8501899655927883
Validation loss: 2.9194270468484946

Epoch: 5| Step: 10
Training loss: 2.677563951941361
Validation loss: 2.9187962195253387

Epoch: 222| Step: 0
Training loss: 3.0818352195757766
Validation loss: 2.9209365465108497

Epoch: 5| Step: 1
Training loss: 3.3616533936626385
Validation loss: 2.922085931479731

Epoch: 5| Step: 2
Training loss: 3.347556256255292
Validation loss: 2.918780824270519

Epoch: 5| Step: 3
Training loss: 3.2681629594680053
Validation loss: 2.9237216362857144

Epoch: 5| Step: 4
Training loss: 2.8906484242083
Validation loss: 2.9232344611083496

Epoch: 5| Step: 5
Training loss: 2.6270470584681207
Validation loss: 2.9259922985358844

Epoch: 5| Step: 6
Training loss: 3.0802858774854216
Validation loss: 2.9197527811885196

Epoch: 5| Step: 7
Training loss: 3.306798382514806
Validation loss: 2.92196113881043

Epoch: 5| Step: 8
Training loss: 3.223225713180495
Validation loss: 2.918205420208235

Epoch: 5| Step: 9
Training loss: 3.179561828079319
Validation loss: 2.9170177764041

Epoch: 5| Step: 10
Training loss: 3.9327791766519424
Validation loss: 2.9214297491621557

Epoch: 223| Step: 0
Training loss: 3.3287963190125764
Validation loss: 2.921995411308278

Epoch: 5| Step: 1
Training loss: 3.0914654243827164
Validation loss: 2.9198729463750377

Epoch: 5| Step: 2
Training loss: 3.472092950745726
Validation loss: 2.9201898510919504

Epoch: 5| Step: 3
Training loss: 3.948204747998348
Validation loss: 2.9251068142709484

Epoch: 5| Step: 4
Training loss: 2.891312800878593
Validation loss: 2.9220838250039023

Epoch: 5| Step: 5
Training loss: 3.2638505559162754
Validation loss: 2.925158196942636

Epoch: 5| Step: 6
Training loss: 3.037342045448587
Validation loss: 2.9255518849171813

Epoch: 5| Step: 7
Training loss: 3.1876006764986955
Validation loss: 2.9219399985071766

Epoch: 5| Step: 8
Training loss: 2.6578775244310053
Validation loss: 2.922141373974177

Epoch: 5| Step: 9
Training loss: 3.0220527730760818
Validation loss: 2.9245857008466345

Epoch: 5| Step: 10
Training loss: 3.2423032441218793
Validation loss: 2.923528957156938

Epoch: 224| Step: 0
Training loss: 3.448282981075962
Validation loss: 2.9251235224148204

Epoch: 5| Step: 1
Training loss: 3.2650629317336524
Validation loss: 2.9252302212595347

Epoch: 5| Step: 2
Training loss: 3.001605716773488
Validation loss: 2.934450555220714

Epoch: 5| Step: 3
Training loss: 3.175462619989747
Validation loss: 2.927902510519484

Epoch: 5| Step: 4
Training loss: 3.416419710367878
Validation loss: 2.9327297624742874

Epoch: 5| Step: 5
Training loss: 2.732315944884203
Validation loss: 2.9188967890848865

Epoch: 5| Step: 6
Training loss: 3.5441966426277434
Validation loss: 2.9210652191148676

Epoch: 5| Step: 7
Training loss: 3.0257357750786538
Validation loss: 2.921732102083051

Epoch: 5| Step: 8
Training loss: 3.317566362075137
Validation loss: 2.9150270544203196

Epoch: 5| Step: 9
Training loss: 3.17122384138374
Validation loss: 2.914288602297988

Epoch: 5| Step: 10
Training loss: 3.0580204490940925
Validation loss: 2.9140526903534942

Epoch: 225| Step: 0
Training loss: 3.6695359592029875
Validation loss: 2.9145210659910226

Epoch: 5| Step: 1
Training loss: 2.916228034324674
Validation loss: 2.9174740431224793

Epoch: 5| Step: 2
Training loss: 3.35283787787706
Validation loss: 2.918244437603384

Epoch: 5| Step: 3
Training loss: 3.422273795522292
Validation loss: 2.918002354241322

Epoch: 5| Step: 4
Training loss: 3.2455285931098876
Validation loss: 2.9219989453104858

Epoch: 5| Step: 5
Training loss: 3.051966086642929
Validation loss: 2.925770425981167

Epoch: 5| Step: 6
Training loss: 3.1038304259887424
Validation loss: 2.923046891102527

Epoch: 5| Step: 7
Training loss: 2.984168879396211
Validation loss: 2.9185691154706452

Epoch: 5| Step: 8
Training loss: 3.0527065712705372
Validation loss: 2.9181845926788705

Epoch: 5| Step: 9
Training loss: 3.477098745072305
Validation loss: 2.913150689457875

Epoch: 5| Step: 10
Training loss: 2.861682231981458
Validation loss: 2.914091325680164

Epoch: 226| Step: 0
Training loss: 3.4441603898948725
Validation loss: 2.9135606098155735

Epoch: 5| Step: 1
Training loss: 3.190314004445401
Validation loss: 2.9171515406009774

Epoch: 5| Step: 2
Training loss: 3.521532850730547
Validation loss: 2.918798371411517

Epoch: 5| Step: 3
Training loss: 3.0996256817663372
Validation loss: 2.915704514565437

Epoch: 5| Step: 4
Training loss: 3.020361466659616
Validation loss: 2.918614348668805

Epoch: 5| Step: 5
Training loss: 3.312422697496817
Validation loss: 2.917387721737556

Epoch: 5| Step: 6
Training loss: 2.8884087391772764
Validation loss: 2.917436454785224

Epoch: 5| Step: 7
Training loss: 3.289918330607967
Validation loss: 2.9153755482842345

Epoch: 5| Step: 8
Training loss: 2.4082203514058453
Validation loss: 2.9154617375528464

Epoch: 5| Step: 9
Training loss: 3.5494920931399037
Validation loss: 2.921912252230242

Epoch: 5| Step: 10
Training loss: 3.3504523014646317
Validation loss: 2.913525214761748

Epoch: 227| Step: 0
Training loss: 2.7054357629671237
Validation loss: 2.9098658329047873

Epoch: 5| Step: 1
Training loss: 3.509327312902989
Validation loss: 2.912263903677453

Epoch: 5| Step: 2
Training loss: 3.258002479191651
Validation loss: 2.9097588138281636

Epoch: 5| Step: 3
Training loss: 3.7416180075785705
Validation loss: 2.9101618738444253

Epoch: 5| Step: 4
Training loss: 2.635218938313141
Validation loss: 2.910183220393083

Epoch: 5| Step: 5
Training loss: 2.9306328227466936
Validation loss: 2.907773703785317

Epoch: 5| Step: 6
Training loss: 3.527843080919114
Validation loss: 2.909001568935999

Epoch: 5| Step: 7
Training loss: 3.8420618583548722
Validation loss: 2.908158983408129

Epoch: 5| Step: 8
Training loss: 2.845350213510529
Validation loss: 2.9090526403412365

Epoch: 5| Step: 9
Training loss: 2.911410764102019
Validation loss: 2.907212698546397

Epoch: 5| Step: 10
Training loss: 3.012792017542332
Validation loss: 2.909270894576287

Epoch: 228| Step: 0
Training loss: 3.124926451771224
Validation loss: 2.906429053701108

Epoch: 5| Step: 1
Training loss: 2.8328539685908343
Validation loss: 2.9063631640616174

Epoch: 5| Step: 2
Training loss: 3.3480371105001407
Validation loss: 2.9100285142734137

Epoch: 5| Step: 3
Training loss: 3.35474818778435
Validation loss: 2.9076951811530765

Epoch: 5| Step: 4
Training loss: 3.947752547396566
Validation loss: 2.905782648996684

Epoch: 5| Step: 5
Training loss: 3.1744161113999265
Validation loss: 2.91139613461962

Epoch: 5| Step: 6
Training loss: 3.1865394491342283
Validation loss: 2.9050533491961605

Epoch: 5| Step: 7
Training loss: 3.130154135811914
Validation loss: 2.904415727182206

Epoch: 5| Step: 8
Training loss: 2.8284433090897148
Validation loss: 2.9056524270375403

Epoch: 5| Step: 9
Training loss: 3.2523739287611675
Validation loss: 2.9056513594612157

Epoch: 5| Step: 10
Training loss: 2.791023483959369
Validation loss: 2.905739247030838

Epoch: 229| Step: 0
Training loss: 3.0099712601110222
Validation loss: 2.9096088069322805

Epoch: 5| Step: 1
Training loss: 3.265825767368807
Validation loss: 2.9058345515819304

Epoch: 5| Step: 2
Training loss: 2.746220679354512
Validation loss: 2.9098387547279674

Epoch: 5| Step: 3
Training loss: 3.4433081369379823
Validation loss: 2.91147407402594

Epoch: 5| Step: 4
Training loss: 2.823482771037129
Validation loss: 2.909465889876651

Epoch: 5| Step: 5
Training loss: 3.3207678628464192
Validation loss: 2.907449684400742

Epoch: 5| Step: 6
Training loss: 3.503579761344674
Validation loss: 2.9103859457788963

Epoch: 5| Step: 7
Training loss: 3.883817055390067
Validation loss: 2.909973902583723

Epoch: 5| Step: 8
Training loss: 1.9681454896026889
Validation loss: 2.907221962059171

Epoch: 5| Step: 9
Training loss: 3.6747956043935046
Validation loss: 2.906103555864608

Epoch: 5| Step: 10
Training loss: 3.0425017442909827
Validation loss: 2.9058629224859303

Epoch: 230| Step: 0
Training loss: 3.403221954281704
Validation loss: 2.90456141350821

Epoch: 5| Step: 1
Training loss: 3.082381814762334
Validation loss: 2.905883886851523

Epoch: 5| Step: 2
Training loss: 3.1491562091633236
Validation loss: 2.902922455288239

Epoch: 5| Step: 3
Training loss: 3.2080162849488576
Validation loss: 2.9054745157639337

Epoch: 5| Step: 4
Training loss: 3.2695534180102728
Validation loss: 2.906354302686892

Epoch: 5| Step: 5
Training loss: 2.4494749479739433
Validation loss: 2.907200118463607

Epoch: 5| Step: 6
Training loss: 3.3676475688542964
Validation loss: 2.90991512890031

Epoch: 5| Step: 7
Training loss: 2.9923033530015433
Validation loss: 2.9039180934598203

Epoch: 5| Step: 8
Training loss: 3.6901868955841275
Validation loss: 2.9055354439254857

Epoch: 5| Step: 9
Training loss: 3.097692424471548
Validation loss: 2.9022924086086617

Epoch: 5| Step: 10
Training loss: 3.27401371438819
Validation loss: 2.9039693037040326

Epoch: 231| Step: 0
Training loss: 3.6824630992358753
Validation loss: 2.9030945163127186

Epoch: 5| Step: 1
Training loss: 3.5215003531078164
Validation loss: 2.902995571740034

Epoch: 5| Step: 2
Training loss: 2.74299926914674
Validation loss: 2.9013231239279844

Epoch: 5| Step: 3
Training loss: 2.832716781253108
Validation loss: 2.903308697896402

Epoch: 5| Step: 4
Training loss: 3.3257622727006577
Validation loss: 2.903817734370219

Epoch: 5| Step: 5
Training loss: 3.583637638625812
Validation loss: 2.904447135941725

Epoch: 5| Step: 6
Training loss: 2.75460611743551
Validation loss: 2.8985421828754467

Epoch: 5| Step: 7
Training loss: 2.598033906258744
Validation loss: 2.899937372447237

Epoch: 5| Step: 8
Training loss: 3.300736755432355
Validation loss: 2.9023843157170064

Epoch: 5| Step: 9
Training loss: 3.90352908166211
Validation loss: 2.900500323128138

Epoch: 5| Step: 10
Training loss: 2.3873650757377463
Validation loss: 2.899889259430486

Epoch: 232| Step: 0
Training loss: 2.846063029531568
Validation loss: 2.903358925965765

Epoch: 5| Step: 1
Training loss: 3.2441454754723673
Validation loss: 2.8969887244637076

Epoch: 5| Step: 2
Training loss: 2.305006412488909
Validation loss: 2.8998068119633347

Epoch: 5| Step: 3
Training loss: 2.7848306816037156
Validation loss: 2.9011849592433268

Epoch: 5| Step: 4
Training loss: 2.7817654078538463
Validation loss: 2.8994839544348894

Epoch: 5| Step: 5
Training loss: 3.7728063715051845
Validation loss: 2.9003177840700336

Epoch: 5| Step: 6
Training loss: 2.803619606499644
Validation loss: 2.8990688389857273

Epoch: 5| Step: 7
Training loss: 2.585583434975315
Validation loss: 2.9011349511248206

Epoch: 5| Step: 8
Training loss: 3.726757372353362
Validation loss: 2.898537944546614

Epoch: 5| Step: 9
Training loss: 3.777818746593952
Validation loss: 2.9056585492713847

Epoch: 5| Step: 10
Training loss: 4.072192557797728
Validation loss: 2.903837916291618

Epoch: 233| Step: 0
Training loss: 2.9123741351915142
Validation loss: 2.9062754065048906

Epoch: 5| Step: 1
Training loss: 3.4931131454651574
Validation loss: 2.9122136298062427

Epoch: 5| Step: 2
Training loss: 2.8582806603682323
Validation loss: 2.91291131151098

Epoch: 5| Step: 3
Training loss: 3.3897108964102936
Validation loss: 2.9079630338662987

Epoch: 5| Step: 4
Training loss: 3.054712163723162
Validation loss: 2.8993443041650226

Epoch: 5| Step: 5
Training loss: 3.0401220362411863
Validation loss: 2.8963414104510687

Epoch: 5| Step: 6
Training loss: 3.599271165396976
Validation loss: 2.89491450801327

Epoch: 5| Step: 7
Training loss: 2.804811777745798
Validation loss: 2.899275661824707

Epoch: 5| Step: 8
Training loss: 3.1836761276727077
Validation loss: 2.8968754950862547

Epoch: 5| Step: 9
Training loss: 3.823093767074418
Validation loss: 2.8955174383951676

Epoch: 5| Step: 10
Training loss: 2.698275234200906
Validation loss: 2.8973827874859954

Epoch: 234| Step: 0
Training loss: 3.9042667084330462
Validation loss: 2.8955222513307515

Epoch: 5| Step: 1
Training loss: 2.5656659177614105
Validation loss: 2.8969964286792975

Epoch: 5| Step: 2
Training loss: 3.1222012002885093
Validation loss: 2.896038269194745

Epoch: 5| Step: 3
Training loss: 3.388133456415412
Validation loss: 2.901337192746068

Epoch: 5| Step: 4
Training loss: 2.320179636840797
Validation loss: 2.899244058214

Epoch: 5| Step: 5
Training loss: 2.8632729232271488
Validation loss: 2.895901104132646

Epoch: 5| Step: 6
Training loss: 2.9796619848270107
Validation loss: 2.896637175042744

Epoch: 5| Step: 7
Training loss: 3.214470249510073
Validation loss: 2.896013339428073

Epoch: 5| Step: 8
Training loss: 3.5886860870548287
Validation loss: 2.8997345522481113

Epoch: 5| Step: 9
Training loss: 3.2699560620916994
Validation loss: 2.8995697098299154

Epoch: 5| Step: 10
Training loss: 3.5835052419426936
Validation loss: 2.8957537709996046

Epoch: 235| Step: 0
Training loss: 3.37691372903025
Validation loss: 2.8959662518406484

Epoch: 5| Step: 1
Training loss: 2.6751159286334523
Validation loss: 2.8958222400886298

Epoch: 5| Step: 2
Training loss: 3.398465562024946
Validation loss: 2.89509055691381

Epoch: 5| Step: 3
Training loss: 3.221151696608447
Validation loss: 2.8928337972656477

Epoch: 5| Step: 4
Training loss: 2.953400614153641
Validation loss: 2.894728938594014

Epoch: 5| Step: 5
Training loss: 3.1764532412884336
Validation loss: 2.891033411815301

Epoch: 5| Step: 6
Training loss: 3.489645354825274
Validation loss: 2.895094047604375

Epoch: 5| Step: 7
Training loss: 3.0845183767215603
Validation loss: 2.895560467667751

Epoch: 5| Step: 8
Training loss: 3.1406817834380063
Validation loss: 2.895629143187006

Epoch: 5| Step: 9
Training loss: 3.245011536000206
Validation loss: 2.896564853956809

Epoch: 5| Step: 10
Training loss: 3.2497357481118603
Validation loss: 2.8931110718650945

Epoch: 236| Step: 0
Training loss: 3.177133044911843
Validation loss: 2.891656120441588

Epoch: 5| Step: 1
Training loss: 3.1359673879251173
Validation loss: 2.894561913996439

Epoch: 5| Step: 2
Training loss: 3.333465303351739
Validation loss: 2.893001538396592

Epoch: 5| Step: 3
Training loss: 3.187969098447513
Validation loss: 2.898901134102931

Epoch: 5| Step: 4
Training loss: 3.5302167072723987
Validation loss: 2.9023455095333417

Epoch: 5| Step: 5
Training loss: 3.1296686012889676
Validation loss: 2.9066085532502544

Epoch: 5| Step: 6
Training loss: 2.7328497420096745
Validation loss: 2.916481686071747

Epoch: 5| Step: 7
Training loss: 3.7264332618935603
Validation loss: 2.9122749970875375

Epoch: 5| Step: 8
Training loss: 3.2313322783570024
Validation loss: 2.9262899503689512

Epoch: 5| Step: 9
Training loss: 3.223783242807501
Validation loss: 2.932812343846555

Epoch: 5| Step: 10
Training loss: 2.3560596945734016
Validation loss: 2.907206966705529

Epoch: 237| Step: 0
Training loss: 3.9684162149715374
Validation loss: 2.902090982658601

Epoch: 5| Step: 1
Training loss: 3.787069838869827
Validation loss: 2.901112140024802

Epoch: 5| Step: 2
Training loss: 2.625090552085152
Validation loss: 2.896681041733074

Epoch: 5| Step: 3
Training loss: 3.328863644008326
Validation loss: 2.890291698854787

Epoch: 5| Step: 4
Training loss: 3.326713298427456
Validation loss: 2.8929359995853363

Epoch: 5| Step: 5
Training loss: 2.6580788094897594
Validation loss: 2.89050456613489

Epoch: 5| Step: 6
Training loss: 2.723427880730332
Validation loss: 2.8929463553798818

Epoch: 5| Step: 7
Training loss: 3.3050026168466617
Validation loss: 2.888313853735198

Epoch: 5| Step: 8
Training loss: 2.6449771206592763
Validation loss: 2.8888405269153847

Epoch: 5| Step: 9
Training loss: 3.0502030414474337
Validation loss: 2.889163733521686

Epoch: 5| Step: 10
Training loss: 3.290035584092106
Validation loss: 2.8936647564065203

Epoch: 238| Step: 0
Training loss: 3.07122090420198
Validation loss: 2.8908783823500395

Epoch: 5| Step: 1
Training loss: 3.779696310852303
Validation loss: 2.889393658991451

Epoch: 5| Step: 2
Training loss: 3.058636622414646
Validation loss: 2.889150577055056

Epoch: 5| Step: 3
Training loss: 2.679412026884714
Validation loss: 2.8896016365590227

Epoch: 5| Step: 4
Training loss: 2.966686776625235
Validation loss: 2.8886944612963763

Epoch: 5| Step: 5
Training loss: 2.9976080259530766
Validation loss: 2.8911138979715525

Epoch: 5| Step: 6
Training loss: 3.2224119521513193
Validation loss: 2.8920285494385243

Epoch: 5| Step: 7
Training loss: 2.923054666086937
Validation loss: 2.890989029347017

Epoch: 5| Step: 8
Training loss: 3.078979683353388
Validation loss: 2.8898981734288953

Epoch: 5| Step: 9
Training loss: 3.6318256965773874
Validation loss: 2.8848110540900618

Epoch: 5| Step: 10
Training loss: 3.466594404298838
Validation loss: 2.886652516144673

Epoch: 239| Step: 0
Training loss: 3.6249515924839
Validation loss: 2.8878947242787874

Epoch: 5| Step: 1
Training loss: 2.8937413917891335
Validation loss: 2.887980771429307

Epoch: 5| Step: 2
Training loss: 3.105918765300849
Validation loss: 2.8949975003878445

Epoch: 5| Step: 3
Training loss: 3.0945079144814103
Validation loss: 2.900194985931839

Epoch: 5| Step: 4
Training loss: 3.3030570406676008
Validation loss: 2.9157427512497027

Epoch: 5| Step: 5
Training loss: 3.535148156931344
Validation loss: 2.926306916329764

Epoch: 5| Step: 6
Training loss: 2.7394488534930783
Validation loss: 2.9388794235802935

Epoch: 5| Step: 7
Training loss: 2.932965939084377
Validation loss: 2.92753968666257

Epoch: 5| Step: 8
Training loss: 3.3186464685070884
Validation loss: 2.9203980451630382

Epoch: 5| Step: 9
Training loss: 3.257718823593244
Validation loss: 2.915145314348751

Epoch: 5| Step: 10
Training loss: 3.2510312718342678
Validation loss: 2.9096842769933713

Epoch: 240| Step: 0
Training loss: 3.116731309135378
Validation loss: 2.91117333720335

Epoch: 5| Step: 1
Training loss: 3.3846713766721823
Validation loss: 2.8939418566025337

Epoch: 5| Step: 2
Training loss: 3.548906324382649
Validation loss: 2.89144692435505

Epoch: 5| Step: 3
Training loss: 2.818227404004793
Validation loss: 2.8863397240340967

Epoch: 5| Step: 4
Training loss: 3.1772328492717072
Validation loss: 2.8885041202956128

Epoch: 5| Step: 5
Training loss: 3.123990620675947
Validation loss: 2.8893105340455962

Epoch: 5| Step: 6
Training loss: 3.1460554705541526
Validation loss: 2.8882934337504125

Epoch: 5| Step: 7
Training loss: 3.3499572751181748
Validation loss: 2.8907509911286864

Epoch: 5| Step: 8
Training loss: 3.2757239902840505
Validation loss: 2.8872941195412394

Epoch: 5| Step: 9
Training loss: 2.817313758360846
Validation loss: 2.8885721461809313

Epoch: 5| Step: 10
Training loss: 3.2150494682338744
Validation loss: 2.8863694483091105

Epoch: 241| Step: 0
Training loss: 3.5754227074894858
Validation loss: 2.8860608839543747

Epoch: 5| Step: 1
Training loss: 3.3635508997414276
Validation loss: 2.887721950241922

Epoch: 5| Step: 2
Training loss: 3.631781844095009
Validation loss: 2.8850751755974584

Epoch: 5| Step: 3
Training loss: 2.900074622410906
Validation loss: 2.8845872200326363

Epoch: 5| Step: 4
Training loss: 3.0944989771654043
Validation loss: 2.8857481041162534

Epoch: 5| Step: 5
Training loss: 2.8595082403105274
Validation loss: 2.8828300313024395

Epoch: 5| Step: 6
Training loss: 3.3585773319429633
Validation loss: 2.8865885055142106

Epoch: 5| Step: 7
Training loss: 3.231144863166927
Validation loss: 2.8835860382119294

Epoch: 5| Step: 8
Training loss: 2.437110771989552
Validation loss: 2.886979372304031

Epoch: 5| Step: 9
Training loss: 3.632154704601215
Validation loss: 2.890788705630713

Epoch: 5| Step: 10
Training loss: 2.5761033888499014
Validation loss: 2.8975966325926645

Epoch: 242| Step: 0
Training loss: 3.5827958051290056
Validation loss: 2.8896470428514336

Epoch: 5| Step: 1
Training loss: 3.170102079655255
Validation loss: 2.8888710685077275

Epoch: 5| Step: 2
Training loss: 3.4067975925237737
Validation loss: 2.889044202421638

Epoch: 5| Step: 3
Training loss: 2.9898749197119368
Validation loss: 2.8939413755780174

Epoch: 5| Step: 4
Training loss: 3.391909870047894
Validation loss: 2.8896414198912876

Epoch: 5| Step: 5
Training loss: 2.7016609063656785
Validation loss: 2.8944644934396075

Epoch: 5| Step: 6
Training loss: 3.11631850747626
Validation loss: 2.889328292991554

Epoch: 5| Step: 7
Training loss: 3.5345524562062773
Validation loss: 2.885386425544116

Epoch: 5| Step: 8
Training loss: 2.908949879728249
Validation loss: 2.8805783989095417

Epoch: 5| Step: 9
Training loss: 2.923155804778252
Validation loss: 2.8857981852106223

Epoch: 5| Step: 10
Training loss: 3.0781302669886728
Validation loss: 2.879690518086991

Epoch: 243| Step: 0
Training loss: 3.795004552705268
Validation loss: 2.8808830761651474

Epoch: 5| Step: 1
Training loss: 3.3652114203185484
Validation loss: 2.8785297657824107

Epoch: 5| Step: 2
Training loss: 3.4909996384921254
Validation loss: 2.882115721815407

Epoch: 5| Step: 3
Training loss: 2.8460040538809905
Validation loss: 2.879086475321974

Epoch: 5| Step: 4
Training loss: 2.739167640004238
Validation loss: 2.876881386444103

Epoch: 5| Step: 5
Training loss: 3.536919422831269
Validation loss: 2.87974889110024

Epoch: 5| Step: 6
Training loss: 2.571855817980515
Validation loss: 2.880912892334829

Epoch: 5| Step: 7
Training loss: 3.457380201756392
Validation loss: 2.8765297610026304

Epoch: 5| Step: 8
Training loss: 2.4577490117530205
Validation loss: 2.879342503306561

Epoch: 5| Step: 9
Training loss: 2.823366070737351
Validation loss: 2.878370113699165

Epoch: 5| Step: 10
Training loss: 3.5731178130684262
Validation loss: 2.8795128474607354

Epoch: 244| Step: 0
Training loss: 3.3847082873912284
Validation loss: 2.878487587185609

Epoch: 5| Step: 1
Training loss: 2.9597333004371857
Validation loss: 2.879298234452781

Epoch: 5| Step: 2
Training loss: 3.5739996837750314
Validation loss: 2.8807013996262656

Epoch: 5| Step: 3
Training loss: 2.90567765701641
Validation loss: 2.878648234646229

Epoch: 5| Step: 4
Training loss: 2.9835488339239866
Validation loss: 2.879522119957732

Epoch: 5| Step: 5
Training loss: 3.029465612241201
Validation loss: 2.8757105515949206

Epoch: 5| Step: 6
Training loss: 3.4771386515653173
Validation loss: 2.877500353653558

Epoch: 5| Step: 7
Training loss: 3.599431597024074
Validation loss: 2.878160890754022

Epoch: 5| Step: 8
Training loss: 2.607425532534888
Validation loss: 2.878153874529889

Epoch: 5| Step: 9
Training loss: 2.78734546455396
Validation loss: 2.8775117396686665

Epoch: 5| Step: 10
Training loss: 3.4550568713132335
Validation loss: 2.8837450717093933

Epoch: 245| Step: 0
Training loss: 3.7624927964252444
Validation loss: 2.8802052904154603

Epoch: 5| Step: 1
Training loss: 2.9089107024123955
Validation loss: 2.8856671609108675

Epoch: 5| Step: 2
Training loss: 2.9828781448422492
Validation loss: 2.88384820151498

Epoch: 5| Step: 3
Training loss: 3.3630456077620616
Validation loss: 2.88193015378244

Epoch: 5| Step: 4
Training loss: 3.320050110266436
Validation loss: 2.8827189172885967

Epoch: 5| Step: 5
Training loss: 2.8731253773371823
Validation loss: 2.877581694071672

Epoch: 5| Step: 6
Training loss: 2.6637971359944395
Validation loss: 2.877559286040492

Epoch: 5| Step: 7
Training loss: 2.751410642697625
Validation loss: 2.8809212749067963

Epoch: 5| Step: 8
Training loss: 3.2897815054370443
Validation loss: 2.8791460421654707

Epoch: 5| Step: 9
Training loss: 3.1327488766723692
Validation loss: 2.8780826825363843

Epoch: 5| Step: 10
Training loss: 3.715691470745913
Validation loss: 2.8781270796468004

Epoch: 246| Step: 0
Training loss: 2.9189299566759015
Validation loss: 2.8764148697602585

Epoch: 5| Step: 1
Training loss: 3.7673859969966195
Validation loss: 2.879308579642687

Epoch: 5| Step: 2
Training loss: 3.4780506163780727
Validation loss: 2.8773684561248722

Epoch: 5| Step: 3
Training loss: 3.042423380605577
Validation loss: 2.8751666327040595

Epoch: 5| Step: 4
Training loss: 3.2856005210610406
Validation loss: 2.8727548061978254

Epoch: 5| Step: 5
Training loss: 3.701239383454252
Validation loss: 2.875707039158571

Epoch: 5| Step: 6
Training loss: 2.7589705415973285
Validation loss: 2.8749127813933564

Epoch: 5| Step: 7
Training loss: 3.456245910752483
Validation loss: 2.8786397368052095

Epoch: 5| Step: 8
Training loss: 2.5847192758685393
Validation loss: 2.8796794255672777

Epoch: 5| Step: 9
Training loss: 2.4321681664512185
Validation loss: 2.879103418477692

Epoch: 5| Step: 10
Training loss: 3.1477719495636847
Validation loss: 2.878784821842284

Epoch: 247| Step: 0
Training loss: 3.153509933521357
Validation loss: 2.87808269233459

Epoch: 5| Step: 1
Training loss: 3.811913617175065
Validation loss: 2.876576042042041

Epoch: 5| Step: 2
Training loss: 2.9648884605283254
Validation loss: 2.877710522611062

Epoch: 5| Step: 3
Training loss: 3.307828524212412
Validation loss: 2.8736988055006005

Epoch: 5| Step: 4
Training loss: 2.9363587780157214
Validation loss: 2.871504136222572

Epoch: 5| Step: 5
Training loss: 3.2102373756746885
Validation loss: 2.870075004071776

Epoch: 5| Step: 6
Training loss: 2.932925294181562
Validation loss: 2.8707124806420286

Epoch: 5| Step: 7
Training loss: 3.775651049524879
Validation loss: 2.8718021963339626

Epoch: 5| Step: 8
Training loss: 3.013620293324769
Validation loss: 2.873428274461029

Epoch: 5| Step: 9
Training loss: 2.7422725305660216
Validation loss: 2.8705471737102815

Epoch: 5| Step: 10
Training loss: 2.710856939432499
Validation loss: 2.883935649471807

Epoch: 248| Step: 0
Training loss: 3.277110658706718
Validation loss: 2.8916665818877347

Epoch: 5| Step: 1
Training loss: 3.2068321547232395
Validation loss: 2.8904393308032956

Epoch: 5| Step: 2
Training loss: 3.0659916494197312
Validation loss: 2.8762978704644273

Epoch: 5| Step: 3
Training loss: 3.0662131084675255
Validation loss: 2.87796208190875

Epoch: 5| Step: 4
Training loss: 2.590517534666019
Validation loss: 2.8678949875869697

Epoch: 5| Step: 5
Training loss: 3.2452698544531944
Validation loss: 2.8705387429820357

Epoch: 5| Step: 6
Training loss: 3.837666729712825
Validation loss: 2.867948692316155

Epoch: 5| Step: 7
Training loss: 2.8697710999976698
Validation loss: 2.8709040829362054

Epoch: 5| Step: 8
Training loss: 2.8936354348756965
Validation loss: 2.8746539019494493

Epoch: 5| Step: 9
Training loss: 2.875092712234315
Validation loss: 2.872019176164114

Epoch: 5| Step: 10
Training loss: 3.8493983009105115
Validation loss: 2.869267729281343

Epoch: 249| Step: 0
Training loss: 2.7251059240350077
Validation loss: 2.8677577172364215

Epoch: 5| Step: 1
Training loss: 3.100625153541369
Validation loss: 2.868535443865401

Epoch: 5| Step: 2
Training loss: 3.021710989602993
Validation loss: 2.8679262912580743

Epoch: 5| Step: 3
Training loss: 3.0612440063866493
Validation loss: 2.871931720636678

Epoch: 5| Step: 4
Training loss: 3.1728425452895874
Validation loss: 2.8701093789767036

Epoch: 5| Step: 5
Training loss: 3.4769654458374837
Validation loss: 2.8728572944948234

Epoch: 5| Step: 6
Training loss: 3.28971309071753
Validation loss: 2.8821186642784142

Epoch: 5| Step: 7
Training loss: 3.714289193623349
Validation loss: 2.8733474401230445

Epoch: 5| Step: 8
Training loss: 3.365150348767795
Validation loss: 2.875268827285142

Epoch: 5| Step: 9
Training loss: 2.7502749045556634
Validation loss: 2.8747568477979617

Epoch: 5| Step: 10
Training loss: 2.998853146368032
Validation loss: 2.8717342409833777

Epoch: 250| Step: 0
Training loss: 3.1215486923005575
Validation loss: 2.8674715924087173

Epoch: 5| Step: 1
Training loss: 3.0208898254023167
Validation loss: 2.8721368915589403

Epoch: 5| Step: 2
Training loss: 3.01305853386814
Validation loss: 2.8682477144888754

Epoch: 5| Step: 3
Training loss: 2.4181307490347765
Validation loss: 2.8681370545156346

Epoch: 5| Step: 4
Training loss: 3.5418474637427426
Validation loss: 2.871143450964993

Epoch: 5| Step: 5
Training loss: 3.094917462408504
Validation loss: 2.870925952215024

Epoch: 5| Step: 6
Training loss: 3.273148480677664
Validation loss: 2.8704899389387433

Epoch: 5| Step: 7
Training loss: 3.439463245522092
Validation loss: 2.86638978949105

Epoch: 5| Step: 8
Training loss: 3.185360208979466
Validation loss: 2.867166405588714

Epoch: 5| Step: 9
Training loss: 3.5400907862600612
Validation loss: 2.867993956936964

Epoch: 5| Step: 10
Training loss: 3.003876724395695
Validation loss: 2.868054714168162

Testing loss: 3.077357050611467
