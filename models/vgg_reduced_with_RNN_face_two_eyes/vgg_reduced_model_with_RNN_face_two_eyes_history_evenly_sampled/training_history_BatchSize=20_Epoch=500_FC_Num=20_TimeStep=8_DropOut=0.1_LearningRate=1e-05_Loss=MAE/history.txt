Epoch: 1| Step: 0
Training loss: 5.0249924659729
Validation loss: 5.222950986636582

Epoch: 5| Step: 1
Training loss: 5.793959617614746
Validation loss: 5.214933139021679

Epoch: 5| Step: 2
Training loss: 5.449056625366211
Validation loss: 5.2079262477095405

Epoch: 5| Step: 3
Training loss: 4.679359436035156
Validation loss: 5.201360174404678

Epoch: 5| Step: 4
Training loss: 4.17361307144165
Validation loss: 5.19529378029608

Epoch: 5| Step: 5
Training loss: 5.217728614807129
Validation loss: 5.18894475506198

Epoch: 5| Step: 6
Training loss: 5.869349479675293
Validation loss: 5.181868578798028

Epoch: 5| Step: 7
Training loss: 5.0519890785217285
Validation loss: 5.174587301028672

Epoch: 5| Step: 8
Training loss: 5.1843671798706055
Validation loss: 5.166964818072575

Epoch: 5| Step: 9
Training loss: 4.7296600341796875
Validation loss: 5.158041487457932

Epoch: 5| Step: 10
Training loss: 3.414064884185791
Validation loss: 5.148741809270716

Epoch: 2| Step: 0
Training loss: 4.437213897705078
Validation loss: 5.13840215949602

Epoch: 5| Step: 1
Training loss: 5.3632636070251465
Validation loss: 5.12725684976065

Epoch: 5| Step: 2
Training loss: 4.701876640319824
Validation loss: 5.114661032153714

Epoch: 5| Step: 3
Training loss: 4.676401615142822
Validation loss: 5.101018336511427

Epoch: 5| Step: 4
Training loss: 5.381983757019043
Validation loss: 5.086139576409453

Epoch: 5| Step: 5
Training loss: 5.675781726837158
Validation loss: 5.06966479106616

Epoch: 5| Step: 6
Training loss: 4.569911479949951
Validation loss: 5.052123064635902

Epoch: 5| Step: 7
Training loss: 5.268099784851074
Validation loss: 5.032628761824741

Epoch: 5| Step: 8
Training loss: 4.012084007263184
Validation loss: 5.012511863503405

Epoch: 5| Step: 9
Training loss: 5.064929962158203
Validation loss: 4.990213307001257

Epoch: 5| Step: 10
Training loss: 4.180974006652832
Validation loss: 4.966056551984561

Epoch: 3| Step: 0
Training loss: 4.240572452545166
Validation loss: 4.940600959203577

Epoch: 5| Step: 1
Training loss: 3.8242411613464355
Validation loss: 4.913457834592429

Epoch: 5| Step: 2
Training loss: 4.684866905212402
Validation loss: 4.884411099136517

Epoch: 5| Step: 3
Training loss: 5.140353679656982
Validation loss: 4.854953991469516

Epoch: 5| Step: 4
Training loss: 4.218594551086426
Validation loss: 4.823436465314639

Epoch: 5| Step: 5
Training loss: 4.30425500869751
Validation loss: 4.791983486503683

Epoch: 5| Step: 6
Training loss: 5.310561656951904
Validation loss: 4.757512318190708

Epoch: 5| Step: 7
Training loss: 4.299384117126465
Validation loss: 4.723692463290307

Epoch: 5| Step: 8
Training loss: 5.667311191558838
Validation loss: 4.687768002992035

Epoch: 5| Step: 9
Training loss: 4.478768348693848
Validation loss: 4.651937310413648

Epoch: 5| Step: 10
Training loss: 4.0464019775390625
Validation loss: 4.615798232375934

Epoch: 4| Step: 0
Training loss: 3.9397196769714355
Validation loss: 4.57753264006748

Epoch: 5| Step: 1
Training loss: 4.744370460510254
Validation loss: 4.541134603561893

Epoch: 5| Step: 2
Training loss: 3.901170253753662
Validation loss: 4.502887469466015

Epoch: 5| Step: 3
Training loss: 5.126981258392334
Validation loss: 4.467141443683255

Epoch: 5| Step: 4
Training loss: 3.540693998336792
Validation loss: 4.43102624083078

Epoch: 5| Step: 5
Training loss: 3.1292781829833984
Validation loss: 4.397946683309412

Epoch: 5| Step: 6
Training loss: 3.6211097240448
Validation loss: 4.364616214588124

Epoch: 5| Step: 7
Training loss: 4.858729839324951
Validation loss: 4.335702214189755

Epoch: 5| Step: 8
Training loss: 4.358109474182129
Validation loss: 4.3059465398070635

Epoch: 5| Step: 9
Training loss: 4.115206718444824
Validation loss: 4.27698625031338

Epoch: 5| Step: 10
Training loss: 5.083078861236572
Validation loss: 4.248629459770777

Epoch: 5| Step: 0
Training loss: 3.773297071456909
Validation loss: 4.219369472995881

Epoch: 5| Step: 1
Training loss: 3.938281297683716
Validation loss: 4.189887946651828

Epoch: 5| Step: 2
Training loss: 3.5283026695251465
Validation loss: 4.157725400822137

Epoch: 5| Step: 3
Training loss: 3.8917489051818848
Validation loss: 4.123990892082133

Epoch: 5| Step: 4
Training loss: 3.3460052013397217
Validation loss: 4.092951515669464

Epoch: 5| Step: 5
Training loss: 3.479616641998291
Validation loss: 4.063487878409765

Epoch: 5| Step: 6
Training loss: 4.90688943862915
Validation loss: 4.039307589172035

Epoch: 5| Step: 7
Training loss: 3.5906879901885986
Validation loss: 4.0153931648500505

Epoch: 5| Step: 8
Training loss: 5.273476600646973
Validation loss: 3.996718175949589

Epoch: 5| Step: 9
Training loss: 3.4971060752868652
Validation loss: 3.9761122734315935

Epoch: 5| Step: 10
Training loss: 3.7967052459716797
Validation loss: 3.9576353667884745

Epoch: 6| Step: 0
Training loss: 4.174798011779785
Validation loss: 3.9365820371976463

Epoch: 5| Step: 1
Training loss: 3.9572136402130127
Validation loss: 3.9181946375036754

Epoch: 5| Step: 2
Training loss: 2.973198890686035
Validation loss: 3.9001589282866447

Epoch: 5| Step: 3
Training loss: 3.6912055015563965
Validation loss: 3.883191652195428

Epoch: 5| Step: 4
Training loss: 4.607011318206787
Validation loss: 3.866904761201592

Epoch: 5| Step: 5
Training loss: 4.255648612976074
Validation loss: 3.8492090112419537

Epoch: 5| Step: 6
Training loss: 4.174284934997559
Validation loss: 3.831746306470645

Epoch: 5| Step: 7
Training loss: 2.608900547027588
Validation loss: 3.8078531783114196

Epoch: 5| Step: 8
Training loss: 4.1184258460998535
Validation loss: 3.7879350211030696

Epoch: 5| Step: 9
Training loss: 3.6574904918670654
Validation loss: 3.7676928991912515

Epoch: 5| Step: 10
Training loss: 2.5807812213897705
Validation loss: 3.749710352190079

Epoch: 7| Step: 0
Training loss: 3.7445571422576904
Validation loss: 3.73531069806827

Epoch: 5| Step: 1
Training loss: 3.5927300453186035
Validation loss: 3.7213923315848074

Epoch: 5| Step: 2
Training loss: 3.0713443756103516
Validation loss: 3.704352012244604

Epoch: 5| Step: 3
Training loss: 3.5530357360839844
Validation loss: 3.687843238153765

Epoch: 5| Step: 4
Training loss: 3.1961278915405273
Validation loss: 3.6663770778204805

Epoch: 5| Step: 5
Training loss: 4.515750408172607
Validation loss: 3.65281617769631

Epoch: 5| Step: 6
Training loss: 3.904519557952881
Validation loss: 3.6325637781491844

Epoch: 5| Step: 7
Training loss: 2.9731616973876953
Validation loss: 3.613857969161003

Epoch: 5| Step: 8
Training loss: 3.7324695587158203
Validation loss: 3.5960627294355825

Epoch: 5| Step: 9
Training loss: 3.4117093086242676
Validation loss: 3.574993054072062

Epoch: 5| Step: 10
Training loss: 3.405698776245117
Validation loss: 3.5596063265236477

Epoch: 8| Step: 0
Training loss: 3.08293080329895
Validation loss: 3.5443518623228996

Epoch: 5| Step: 1
Training loss: 4.509568214416504
Validation loss: 3.529942789385396

Epoch: 5| Step: 2
Training loss: 3.158048152923584
Validation loss: 3.516815572656611

Epoch: 5| Step: 3
Training loss: 4.257425785064697
Validation loss: 3.502629772309334

Epoch: 5| Step: 4
Training loss: 3.6811842918395996
Validation loss: 3.49225257032661

Epoch: 5| Step: 5
Training loss: 3.365872859954834
Validation loss: 3.478166462272726

Epoch: 5| Step: 6
Training loss: 3.5343849658966064
Validation loss: 3.470859061005295

Epoch: 5| Step: 7
Training loss: 2.7511534690856934
Validation loss: 3.4621575673421225

Epoch: 5| Step: 8
Training loss: 3.1564464569091797
Validation loss: 3.4542724445301998

Epoch: 5| Step: 9
Training loss: 3.190340042114258
Validation loss: 3.441181985280847

Epoch: 5| Step: 10
Training loss: 2.90256929397583
Validation loss: 3.4314175395555395

Epoch: 9| Step: 0
Training loss: 3.3112456798553467
Validation loss: 3.4219464896827616

Epoch: 5| Step: 1
Training loss: 3.1107521057128906
Validation loss: 3.4160812157456593

Epoch: 5| Step: 2
Training loss: 3.245882511138916
Validation loss: 3.4161787853446057

Epoch: 5| Step: 3
Training loss: 3.818856716156006
Validation loss: 3.406685131852345

Epoch: 5| Step: 4
Training loss: 4.164215087890625
Validation loss: 3.38785288410802

Epoch: 5| Step: 5
Training loss: 4.241494178771973
Validation loss: 3.3766014473412627

Epoch: 5| Step: 6
Training loss: 3.7608704566955566
Validation loss: 3.367735690968011

Epoch: 5| Step: 7
Training loss: 2.942739248275757
Validation loss: 3.3597750894484983

Epoch: 5| Step: 8
Training loss: 1.9903514385223389
Validation loss: 3.352359212854857

Epoch: 5| Step: 9
Training loss: 2.8787078857421875
Validation loss: 3.349118468581989

Epoch: 5| Step: 10
Training loss: 3.198099136352539
Validation loss: 3.3440734109570904

Epoch: 10| Step: 0
Training loss: 2.9111545085906982
Validation loss: 3.3368511251223985

Epoch: 5| Step: 1
Training loss: 2.8359367847442627
Validation loss: 3.331153146682247

Epoch: 5| Step: 2
Training loss: 3.412832260131836
Validation loss: 3.321739519796064

Epoch: 5| Step: 3
Training loss: 4.081814765930176
Validation loss: 3.3150980267473447

Epoch: 5| Step: 4
Training loss: 2.7159557342529297
Validation loss: 3.308532084188154

Epoch: 5| Step: 5
Training loss: 3.1864311695098877
Validation loss: 3.298125692593154

Epoch: 5| Step: 6
Training loss: 3.641625165939331
Validation loss: 3.2940602635824554

Epoch: 5| Step: 7
Training loss: 2.446538209915161
Validation loss: 3.28877378279163

Epoch: 5| Step: 8
Training loss: 4.062014579772949
Validation loss: 3.2817929406319895

Epoch: 5| Step: 9
Training loss: 2.788033962249756
Validation loss: 3.2738930307408816

Epoch: 5| Step: 10
Training loss: 3.9954493045806885
Validation loss: 3.266573470125916

Epoch: 11| Step: 0
Training loss: 2.791234254837036
Validation loss: 3.2553886803247596

Epoch: 5| Step: 1
Training loss: 3.129051923751831
Validation loss: 3.251945005950107

Epoch: 5| Step: 2
Training loss: 3.8315207958221436
Validation loss: 3.2455667065035914

Epoch: 5| Step: 3
Training loss: 2.976543426513672
Validation loss: 3.2340512737151115

Epoch: 5| Step: 4
Training loss: 2.714261770248413
Validation loss: 3.230243318824358

Epoch: 5| Step: 5
Training loss: 3.4529366493225098
Validation loss: 3.22488131061677

Epoch: 5| Step: 6
Training loss: 3.567824602127075
Validation loss: 3.223131349009852

Epoch: 5| Step: 7
Training loss: 3.4606125354766846
Validation loss: 3.2212574610146145

Epoch: 5| Step: 8
Training loss: 2.799060106277466
Validation loss: 3.207348169819001

Epoch: 5| Step: 9
Training loss: 2.844857931137085
Validation loss: 3.203497358547744

Epoch: 5| Step: 10
Training loss: 3.9385080337524414
Validation loss: 3.2014502709911716

Epoch: 12| Step: 0
Training loss: 3.5877227783203125
Validation loss: 3.1948164457915933

Epoch: 5| Step: 1
Training loss: 3.955021619796753
Validation loss: 3.190629651469569

Epoch: 5| Step: 2
Training loss: 3.482802629470825
Validation loss: 3.1839420410894577

Epoch: 5| Step: 3
Training loss: 2.816631317138672
Validation loss: 3.182915892652286

Epoch: 5| Step: 4
Training loss: 2.5715174674987793
Validation loss: 3.1769254053792646

Epoch: 5| Step: 5
Training loss: 3.187075614929199
Validation loss: 3.173792057139899

Epoch: 5| Step: 6
Training loss: 2.847846508026123
Validation loss: 3.17418352506494

Epoch: 5| Step: 7
Training loss: 2.2432055473327637
Validation loss: 3.177310671857608

Epoch: 5| Step: 8
Training loss: 4.2694244384765625
Validation loss: 3.1666811307271323

Epoch: 5| Step: 9
Training loss: 3.1291816234588623
Validation loss: 3.1582879558686288

Epoch: 5| Step: 10
Training loss: 2.8319554328918457
Validation loss: 3.152276531342537

Epoch: 13| Step: 0
Training loss: 3.0564498901367188
Validation loss: 3.153901146304223

Epoch: 5| Step: 1
Training loss: 3.049272060394287
Validation loss: 3.1560254994259087

Epoch: 5| Step: 2
Training loss: 2.817223072052002
Validation loss: 3.1777732756830033

Epoch: 5| Step: 3
Training loss: 2.8281030654907227
Validation loss: 3.145231790440057

Epoch: 5| Step: 4
Training loss: 3.093773603439331
Validation loss: 3.140310897622057

Epoch: 5| Step: 5
Training loss: 3.480306625366211
Validation loss: 3.142161676960607

Epoch: 5| Step: 6
Training loss: 3.3126025199890137
Validation loss: 3.144295561698175

Epoch: 5| Step: 7
Training loss: 3.5525314807891846
Validation loss: 3.137516877984488

Epoch: 5| Step: 8
Training loss: 3.129798173904419
Validation loss: 3.1336169960678264

Epoch: 5| Step: 9
Training loss: 2.7057044506073
Validation loss: 3.1237976730510755

Epoch: 5| Step: 10
Training loss: 3.796093225479126
Validation loss: 3.1291717560060563

Epoch: 14| Step: 0
Training loss: 2.60072660446167
Validation loss: 3.128891655193862

Epoch: 5| Step: 1
Training loss: 3.1992173194885254
Validation loss: 3.1259008530647523

Epoch: 5| Step: 2
Training loss: 3.8119468688964844
Validation loss: 3.1212325711404123

Epoch: 5| Step: 3
Training loss: 1.935983419418335
Validation loss: 3.115277672326693

Epoch: 5| Step: 4
Training loss: 2.8745388984680176
Validation loss: 3.112190128654562

Epoch: 5| Step: 5
Training loss: 2.851801633834839
Validation loss: 3.1120460238508

Epoch: 5| Step: 6
Training loss: 3.8806846141815186
Validation loss: 3.0982022029097362

Epoch: 5| Step: 7
Training loss: 2.9477429389953613
Validation loss: 3.0934428091972106

Epoch: 5| Step: 8
Training loss: 3.524628162384033
Validation loss: 3.09034788480369

Epoch: 5| Step: 9
Training loss: 3.7628085613250732
Validation loss: 3.089832403326547

Epoch: 5| Step: 10
Training loss: 3.000532388687134
Validation loss: 3.085015053390175

Epoch: 15| Step: 0
Training loss: 2.4478373527526855
Validation loss: 3.0817278918399604

Epoch: 5| Step: 1
Training loss: 3.09157133102417
Validation loss: 3.07789175228406

Epoch: 5| Step: 2
Training loss: 2.9240832328796387
Validation loss: 3.0748641157662995

Epoch: 5| Step: 3
Training loss: 3.3766579627990723
Validation loss: 3.0666991561971684

Epoch: 5| Step: 4
Training loss: 2.7935023307800293
Validation loss: 3.0683946994043167

Epoch: 5| Step: 5
Training loss: 3.6856517791748047
Validation loss: 3.0606887827637377

Epoch: 5| Step: 6
Training loss: 2.6052050590515137
Validation loss: 3.0537483948533253

Epoch: 5| Step: 7
Training loss: 3.186694622039795
Validation loss: 3.0436108317426456

Epoch: 5| Step: 8
Training loss: 3.604708433151245
Validation loss: 3.043351573328818

Epoch: 5| Step: 9
Training loss: 3.229405164718628
Validation loss: 3.037358514724239

Epoch: 5| Step: 10
Training loss: 3.1809823513031006
Validation loss: 3.0331903913969636

Epoch: 16| Step: 0
Training loss: 3.4715874195098877
Validation loss: 3.030856506798857

Epoch: 5| Step: 1
Training loss: 3.7956783771514893
Validation loss: 3.0340960077060166

Epoch: 5| Step: 2
Training loss: 3.1849324703216553
Validation loss: 3.030006598400813

Epoch: 5| Step: 3
Training loss: 2.7873778343200684
Validation loss: 3.027105574966759

Epoch: 5| Step: 4
Training loss: 2.2585272789001465
Validation loss: 3.021588930519678

Epoch: 5| Step: 5
Training loss: 3.024954319000244
Validation loss: 3.015009821102183

Epoch: 5| Step: 6
Training loss: 3.690769910812378
Validation loss: 3.0118793825949393

Epoch: 5| Step: 7
Training loss: 3.0134315490722656
Validation loss: 3.0141351069173505

Epoch: 5| Step: 8
Training loss: 3.052107572555542
Validation loss: 3.001343939893989

Epoch: 5| Step: 9
Training loss: 2.4377846717834473
Validation loss: 2.992924972247052

Epoch: 5| Step: 10
Training loss: 3.0997374057769775
Validation loss: 2.9879053792645855

Epoch: 17| Step: 0
Training loss: 3.443535566329956
Validation loss: 2.9863274302533878

Epoch: 5| Step: 1
Training loss: 3.857862949371338
Validation loss: 2.982225997473604

Epoch: 5| Step: 2
Training loss: 3.2849724292755127
Validation loss: 2.9761612928041847

Epoch: 5| Step: 3
Training loss: 2.885756015777588
Validation loss: 2.975522223339286

Epoch: 5| Step: 4
Training loss: 3.316349744796753
Validation loss: 2.9763530710692048

Epoch: 5| Step: 5
Training loss: 2.690031051635742
Validation loss: 2.967382854030978

Epoch: 5| Step: 6
Training loss: 2.280993700027466
Validation loss: 2.962755064810476

Epoch: 5| Step: 7
Training loss: 3.3167338371276855
Validation loss: 2.971826091889412

Epoch: 5| Step: 8
Training loss: 4.027089595794678
Validation loss: 2.9611102124696136

Epoch: 5| Step: 9
Training loss: 2.5326080322265625
Validation loss: 2.9561116259585143

Epoch: 5| Step: 10
Training loss: 1.6388050317764282
Validation loss: 2.950448871940695

Epoch: 18| Step: 0
Training loss: 2.5292820930480957
Validation loss: 2.9643963075453237

Epoch: 5| Step: 1
Training loss: 3.210752010345459
Validation loss: 2.9795761467308126

Epoch: 5| Step: 2
Training loss: 3.8679442405700684
Validation loss: 2.967792708386657

Epoch: 5| Step: 3
Training loss: 3.273953914642334
Validation loss: 2.9573643233186457

Epoch: 5| Step: 4
Training loss: 2.3372750282287598
Validation loss: 2.939549092323549

Epoch: 5| Step: 5
Training loss: 2.649779796600342
Validation loss: 2.9454887067118

Epoch: 5| Step: 6
Training loss: 2.575924873352051
Validation loss: 2.9541173186353458

Epoch: 5| Step: 7
Training loss: 2.9389288425445557
Validation loss: 2.9573217591931744

Epoch: 5| Step: 8
Training loss: 3.2634825706481934
Validation loss: 2.9607729629803727

Epoch: 5| Step: 9
Training loss: 3.325230836868286
Validation loss: 2.9347438196982107

Epoch: 5| Step: 10
Training loss: 3.358250617980957
Validation loss: 2.9256890409736225

Epoch: 19| Step: 0
Training loss: 2.5201916694641113
Validation loss: 2.9242432143098567

Epoch: 5| Step: 1
Training loss: 3.091820240020752
Validation loss: 2.923752143818845

Epoch: 5| Step: 2
Training loss: 2.4958243370056152
Validation loss: 2.923272068782519

Epoch: 5| Step: 3
Training loss: 2.9206981658935547
Validation loss: 2.923077888386224

Epoch: 5| Step: 4
Training loss: 3.1595704555511475
Validation loss: 2.924078131234774

Epoch: 5| Step: 5
Training loss: 2.5965733528137207
Validation loss: 2.924837689245901

Epoch: 5| Step: 6
Training loss: 3.445183277130127
Validation loss: 2.918613992711549

Epoch: 5| Step: 7
Training loss: 3.2575924396514893
Validation loss: 2.912452018389138

Epoch: 5| Step: 8
Training loss: 3.517650604248047
Validation loss: 2.918222027440225

Epoch: 5| Step: 9
Training loss: 3.1929163932800293
Validation loss: 2.914995813882479

Epoch: 5| Step: 10
Training loss: 2.82651424407959
Validation loss: 2.909825401921426

Epoch: 20| Step: 0
Training loss: 2.410303831100464
Validation loss: 2.9231360009921494

Epoch: 5| Step: 1
Training loss: 3.4252235889434814
Validation loss: 2.928575251692085

Epoch: 5| Step: 2
Training loss: 3.216747760772705
Validation loss: 2.9253583262043614

Epoch: 5| Step: 3
Training loss: 2.632740020751953
Validation loss: 2.915899520279259

Epoch: 5| Step: 4
Training loss: 3.5848472118377686
Validation loss: 2.898634579873854

Epoch: 5| Step: 5
Training loss: 3.648752212524414
Validation loss: 2.8966521293886247

Epoch: 5| Step: 6
Training loss: 3.055999279022217
Validation loss: 2.891212283924062

Epoch: 5| Step: 7
Training loss: 3.361967086791992
Validation loss: 2.8868615858016478

Epoch: 5| Step: 8
Training loss: 2.3737637996673584
Validation loss: 2.8880403093112412

Epoch: 5| Step: 9
Training loss: 2.2967276573181152
Validation loss: 2.891280681856217

Epoch: 5| Step: 10
Training loss: 2.847935914993286
Validation loss: 2.8856864795889905

Epoch: 21| Step: 0
Training loss: 2.905038833618164
Validation loss: 2.8881772231030207

Epoch: 5| Step: 1
Training loss: 3.4539616107940674
Validation loss: 2.888544592806088

Epoch: 5| Step: 2
Training loss: 2.8054256439208984
Validation loss: 2.8847252143326627

Epoch: 5| Step: 3
Training loss: 2.6611287593841553
Validation loss: 2.886574770814629

Epoch: 5| Step: 4
Training loss: 3.246509075164795
Validation loss: 2.8807088585310083

Epoch: 5| Step: 5
Training loss: 2.773952007293701
Validation loss: 2.8776354379551385

Epoch: 5| Step: 6
Training loss: 2.2856249809265137
Validation loss: 2.8823011536752023

Epoch: 5| Step: 7
Training loss: 3.2636361122131348
Validation loss: 2.8823024201136764

Epoch: 5| Step: 8
Training loss: 2.7233896255493164
Validation loss: 2.8763930413030807

Epoch: 5| Step: 9
Training loss: 3.074817180633545
Validation loss: 2.8850721543835056

Epoch: 5| Step: 10
Training loss: 3.6161413192749023
Validation loss: 2.8892584205955587

Epoch: 22| Step: 0
Training loss: 3.087796449661255
Validation loss: 2.883744050097722

Epoch: 5| Step: 1
Training loss: 3.09599232673645
Validation loss: 2.8799913570445073

Epoch: 5| Step: 2
Training loss: 2.920018434524536
Validation loss: 2.8966392163307435

Epoch: 5| Step: 3
Training loss: 3.115593433380127
Validation loss: 2.909673703614102

Epoch: 5| Step: 4
Training loss: 2.650175094604492
Validation loss: 2.873172918955485

Epoch: 5| Step: 5
Training loss: 2.4540367126464844
Validation loss: 2.8660437086577057

Epoch: 5| Step: 6
Training loss: 2.9493038654327393
Validation loss: 2.862972979904503

Epoch: 5| Step: 7
Training loss: 2.5040202140808105
Validation loss: 2.8691337928977063

Epoch: 5| Step: 8
Training loss: 3.5518593788146973
Validation loss: 2.870833884003342

Epoch: 5| Step: 9
Training loss: 4.017547607421875
Validation loss: 2.8734434676426712

Epoch: 5| Step: 10
Training loss: 2.235750675201416
Validation loss: 2.864502878599269

Epoch: 23| Step: 0
Training loss: 1.7901805639266968
Validation loss: 2.8618041648659656

Epoch: 5| Step: 1
Training loss: 3.014578342437744
Validation loss: 2.8625058691988707

Epoch: 5| Step: 2
Training loss: 3.2140285968780518
Validation loss: 2.8649554790989047

Epoch: 5| Step: 3
Training loss: 2.6994340419769287
Validation loss: 2.8679617245992026

Epoch: 5| Step: 4
Training loss: 2.5813956260681152
Validation loss: 2.869494281789308

Epoch: 5| Step: 5
Training loss: 2.985788345336914
Validation loss: 2.8803286680611233

Epoch: 5| Step: 6
Training loss: 3.1401448249816895
Validation loss: 2.873249687174315

Epoch: 5| Step: 7
Training loss: 2.5807082653045654
Validation loss: 2.872038902774934

Epoch: 5| Step: 8
Training loss: 3.2613987922668457
Validation loss: 2.863177607136388

Epoch: 5| Step: 9
Training loss: 3.6264591217041016
Validation loss: 2.8557258498284126

Epoch: 5| Step: 10
Training loss: 3.8718814849853516
Validation loss: 2.85361151285069

Epoch: 24| Step: 0
Training loss: 3.0086188316345215
Validation loss: 2.849315430528374

Epoch: 5| Step: 1
Training loss: 1.8994524478912354
Validation loss: 2.848255398452923

Epoch: 5| Step: 2
Training loss: 2.5376365184783936
Validation loss: 2.848324050185501

Epoch: 5| Step: 3
Training loss: 3.2882163524627686
Validation loss: 2.846595759032875

Epoch: 5| Step: 4
Training loss: 1.824789047241211
Validation loss: 2.8445603514230378

Epoch: 5| Step: 5
Training loss: 3.1253116130828857
Validation loss: 2.845737805930517

Epoch: 5| Step: 6
Training loss: 3.5632083415985107
Validation loss: 2.8488310024302494

Epoch: 5| Step: 7
Training loss: 2.0851216316223145
Validation loss: 2.842711453796715

Epoch: 5| Step: 8
Training loss: 3.164548397064209
Validation loss: 2.851016593235795

Epoch: 5| Step: 9
Training loss: 4.31008243560791
Validation loss: 2.844347087285852

Epoch: 5| Step: 10
Training loss: 3.757223129272461
Validation loss: 2.844240880781604

Epoch: 25| Step: 0
Training loss: 3.097977876663208
Validation loss: 2.8343140156038347

Epoch: 5| Step: 1
Training loss: 2.7768092155456543
Validation loss: 2.834623949502104

Epoch: 5| Step: 2
Training loss: 2.91696834564209
Validation loss: 2.83640258542953

Epoch: 5| Step: 3
Training loss: 3.086077928543091
Validation loss: 2.8296901538807857

Epoch: 5| Step: 4
Training loss: 2.3654818534851074
Validation loss: 2.833137824971189

Epoch: 5| Step: 5
Training loss: 3.7406630516052246
Validation loss: 2.827291032319428

Epoch: 5| Step: 6
Training loss: 2.9541831016540527
Validation loss: 2.8274811519089567

Epoch: 5| Step: 7
Training loss: 3.2914886474609375
Validation loss: 2.830088218053182

Epoch: 5| Step: 8
Training loss: 2.4063901901245117
Validation loss: 2.82520660790064

Epoch: 5| Step: 9
Training loss: 2.9339659214019775
Validation loss: 2.829300190812798

Epoch: 5| Step: 10
Training loss: 2.7511205673217773
Validation loss: 2.837412021493399

Epoch: 26| Step: 0
Training loss: 2.4882633686065674
Validation loss: 2.8388773190077914

Epoch: 5| Step: 1
Training loss: 2.5923962593078613
Validation loss: 2.8496647393831642

Epoch: 5| Step: 2
Training loss: 2.6204280853271484
Validation loss: 2.842881400098083

Epoch: 5| Step: 3
Training loss: 2.681445360183716
Validation loss: 2.815935206669633

Epoch: 5| Step: 4
Training loss: 3.4511961936950684
Validation loss: 2.815408581046648

Epoch: 5| Step: 5
Training loss: 2.7235703468322754
Validation loss: 2.81911571820577

Epoch: 5| Step: 6
Training loss: 3.0991268157958984
Validation loss: 2.8195543673730667

Epoch: 5| Step: 7
Training loss: 3.099287748336792
Validation loss: 2.8238406130062637

Epoch: 5| Step: 8
Training loss: 2.7807095050811768
Validation loss: 2.8155519629037506

Epoch: 5| Step: 9
Training loss: 3.5981030464172363
Validation loss: 2.8121357066656953

Epoch: 5| Step: 10
Training loss: 3.1740660667419434
Validation loss: 2.8114567443888676

Epoch: 27| Step: 0
Training loss: 3.090883493423462
Validation loss: 2.821406800259826

Epoch: 5| Step: 1
Training loss: 2.5037219524383545
Validation loss: 2.8245027731823664

Epoch: 5| Step: 2
Training loss: 3.196824550628662
Validation loss: 2.836072293660974

Epoch: 5| Step: 3
Training loss: 3.8174147605895996
Validation loss: 2.8204121358932985

Epoch: 5| Step: 4
Training loss: 3.4113082885742188
Validation loss: 2.8196302229358303

Epoch: 5| Step: 5
Training loss: 2.432403087615967
Validation loss: 2.8165441431025022

Epoch: 5| Step: 6
Training loss: 2.7999610900878906
Validation loss: 2.8219610696197837

Epoch: 5| Step: 7
Training loss: 2.729372262954712
Validation loss: 2.8165143433437554

Epoch: 5| Step: 8
Training loss: 2.653475522994995
Validation loss: 2.811063689570273

Epoch: 5| Step: 9
Training loss: 3.052959442138672
Validation loss: 2.804971594964304

Epoch: 5| Step: 10
Training loss: 2.5074286460876465
Validation loss: 2.8046975135803223

Epoch: 28| Step: 0
Training loss: 3.516719102859497
Validation loss: 2.801661352957449

Epoch: 5| Step: 1
Training loss: 3.343869686126709
Validation loss: 2.8053765527663694

Epoch: 5| Step: 2
Training loss: 2.1034510135650635
Validation loss: 2.8114870030392884

Epoch: 5| Step: 3
Training loss: 3.5621209144592285
Validation loss: 2.8019220162463445

Epoch: 5| Step: 4
Training loss: 2.7380988597869873
Validation loss: 2.801413256634948

Epoch: 5| Step: 5
Training loss: 3.105201482772827
Validation loss: 2.793545574270269

Epoch: 5| Step: 6
Training loss: 2.6843204498291016
Validation loss: 2.7969269880684475

Epoch: 5| Step: 7
Training loss: 3.266181230545044
Validation loss: 2.801907052275955

Epoch: 5| Step: 8
Training loss: 2.7025110721588135
Validation loss: 2.802232534654679

Epoch: 5| Step: 9
Training loss: 2.5009307861328125
Validation loss: 2.8094281227357927

Epoch: 5| Step: 10
Training loss: 2.559772253036499
Validation loss: 2.820393726389895

Epoch: 29| Step: 0
Training loss: 3.0870916843414307
Validation loss: 2.819961404287687

Epoch: 5| Step: 1
Training loss: 2.740299940109253
Validation loss: 2.8261330332807315

Epoch: 5| Step: 2
Training loss: 2.4943501949310303
Validation loss: 2.810166533275317

Epoch: 5| Step: 3
Training loss: 2.700953245162964
Validation loss: 2.7977009947581957

Epoch: 5| Step: 4
Training loss: 3.1471469402313232
Validation loss: 2.790465957374983

Epoch: 5| Step: 5
Training loss: 3.1466870307922363
Validation loss: 2.789762986603604

Epoch: 5| Step: 6
Training loss: 2.96122407913208
Validation loss: 2.7893072764078775

Epoch: 5| Step: 7
Training loss: 2.8912646770477295
Validation loss: 2.786365468014953

Epoch: 5| Step: 8
Training loss: 3.1923959255218506
Validation loss: 2.789268632088938

Epoch: 5| Step: 9
Training loss: 2.937021255493164
Validation loss: 2.7858958500687794

Epoch: 5| Step: 10
Training loss: 2.7138848304748535
Validation loss: 2.7835212599846626

Epoch: 30| Step: 0
Training loss: 2.880690097808838
Validation loss: 2.7852435393999984

Epoch: 5| Step: 1
Training loss: 3.0075302124023438
Validation loss: 2.789740208656557

Epoch: 5| Step: 2
Training loss: 2.322751522064209
Validation loss: 2.7860715850707023

Epoch: 5| Step: 3
Training loss: 3.399488925933838
Validation loss: 2.7866211629682973

Epoch: 5| Step: 4
Training loss: 2.844165086746216
Validation loss: 2.7849762414091375

Epoch: 5| Step: 5
Training loss: 3.338162660598755
Validation loss: 2.7843287632029545

Epoch: 5| Step: 6
Training loss: 2.6037468910217285
Validation loss: 2.781920494571809

Epoch: 5| Step: 7
Training loss: 3.2327303886413574
Validation loss: 2.7867256979788504

Epoch: 5| Step: 8
Training loss: 2.952357530593872
Validation loss: 2.7822103628548245

Epoch: 5| Step: 9
Training loss: 2.8957133293151855
Validation loss: 2.7869512983547744

Epoch: 5| Step: 10
Training loss: 2.3701345920562744
Validation loss: 2.782080158110588

Epoch: 31| Step: 0
Training loss: 2.029679775238037
Validation loss: 2.7875441428153747

Epoch: 5| Step: 1
Training loss: 2.260894775390625
Validation loss: 2.78468930849465

Epoch: 5| Step: 2
Training loss: 3.611523389816284
Validation loss: 2.789425209004392

Epoch: 5| Step: 3
Training loss: 3.165215015411377
Validation loss: 2.7886780410684566

Epoch: 5| Step: 4
Training loss: 3.3656036853790283
Validation loss: 2.79006391186868

Epoch: 5| Step: 5
Training loss: 2.6060843467712402
Validation loss: 2.7867007640100296

Epoch: 5| Step: 6
Training loss: 2.372819662094116
Validation loss: 2.7809462290938183

Epoch: 5| Step: 7
Training loss: 2.894970655441284
Validation loss: 2.7831494423650924

Epoch: 5| Step: 8
Training loss: 3.1431686878204346
Validation loss: 2.7806665461550475

Epoch: 5| Step: 9
Training loss: 2.7883877754211426
Validation loss: 2.780035126593805

Epoch: 5| Step: 10
Training loss: 3.8062245845794678
Validation loss: 2.776832021692748

Epoch: 32| Step: 0
Training loss: 2.4592061042785645
Validation loss: 2.77836694512316

Epoch: 5| Step: 1
Training loss: 2.9283664226531982
Validation loss: 2.778246533486151

Epoch: 5| Step: 2
Training loss: 2.564976930618286
Validation loss: 2.7773783565849386

Epoch: 5| Step: 3
Training loss: 2.764193058013916
Validation loss: 2.7770275146730485

Epoch: 5| Step: 4
Training loss: 2.5319342613220215
Validation loss: 2.774532174551359

Epoch: 5| Step: 5
Training loss: 3.0383992195129395
Validation loss: 2.7735226564509894

Epoch: 5| Step: 6
Training loss: 3.0052247047424316
Validation loss: 2.771943707619944

Epoch: 5| Step: 7
Training loss: 3.026015043258667
Validation loss: 2.7753363245276996

Epoch: 5| Step: 8
Training loss: 3.679696559906006
Validation loss: 2.777248569714126

Epoch: 5| Step: 9
Training loss: 3.5664405822753906
Validation loss: 2.776306995781519

Epoch: 5| Step: 10
Training loss: 2.1635801792144775
Validation loss: 2.7745611231814147

Epoch: 33| Step: 0
Training loss: 2.575453996658325
Validation loss: 2.774729226225166

Epoch: 5| Step: 1
Training loss: 3.301785945892334
Validation loss: 2.773385609349897

Epoch: 5| Step: 2
Training loss: 2.464120388031006
Validation loss: 2.7753682136535645

Epoch: 5| Step: 3
Training loss: 3.215587615966797
Validation loss: 2.7751178126181326

Epoch: 5| Step: 4
Training loss: 3.145061492919922
Validation loss: 2.773291608338715

Epoch: 5| Step: 5
Training loss: 3.1506309509277344
Validation loss: 2.7713852159438597

Epoch: 5| Step: 6
Training loss: 2.900582790374756
Validation loss: 2.771043577501851

Epoch: 5| Step: 7
Training loss: 2.6209354400634766
Validation loss: 2.7745878747714463

Epoch: 5| Step: 8
Training loss: 2.704416036605835
Validation loss: 2.769445998694307

Epoch: 5| Step: 9
Training loss: 2.7681972980499268
Validation loss: 2.765688096323321

Epoch: 5| Step: 10
Training loss: 2.9380154609680176
Validation loss: 2.767430384953817

Epoch: 34| Step: 0
Training loss: 3.0486364364624023
Validation loss: 2.7616513467604116

Epoch: 5| Step: 1
Training loss: 3.086426258087158
Validation loss: 2.7611019867722706

Epoch: 5| Step: 2
Training loss: 3.362949848175049
Validation loss: 2.766809614755774

Epoch: 5| Step: 3
Training loss: 2.6414787769317627
Validation loss: 2.7637552933026384

Epoch: 5| Step: 4
Training loss: 2.1215670108795166
Validation loss: 2.763185429316695

Epoch: 5| Step: 5
Training loss: 2.9898221492767334
Validation loss: 2.7652474885345786

Epoch: 5| Step: 6
Training loss: 3.2678489685058594
Validation loss: 2.7627410939944688

Epoch: 5| Step: 7
Training loss: 3.182863473892212
Validation loss: 2.7629283525610484

Epoch: 5| Step: 8
Training loss: 3.298457384109497
Validation loss: 2.7574880789684992

Epoch: 5| Step: 9
Training loss: 2.214346408843994
Validation loss: 2.7593797432479037

Epoch: 5| Step: 10
Training loss: 2.495115041732788
Validation loss: 2.7577975027022825

Epoch: 35| Step: 0
Training loss: 3.2903060913085938
Validation loss: 2.7547910162197646

Epoch: 5| Step: 1
Training loss: 3.3435912132263184
Validation loss: 2.7599429110045075

Epoch: 5| Step: 2
Training loss: 3.091351270675659
Validation loss: 2.759345313554169

Epoch: 5| Step: 3
Training loss: 2.7812676429748535
Validation loss: 2.7585730937219437

Epoch: 5| Step: 4
Training loss: 3.8260531425476074
Validation loss: 2.763368178439397

Epoch: 5| Step: 5
Training loss: 2.5364391803741455
Validation loss: 2.7598170131765385

Epoch: 5| Step: 6
Training loss: 2.2441794872283936
Validation loss: 2.761070807774862

Epoch: 5| Step: 7
Training loss: 2.162334680557251
Validation loss: 2.7635056639230378

Epoch: 5| Step: 8
Training loss: 3.064730167388916
Validation loss: 2.760921444944156

Epoch: 5| Step: 9
Training loss: 3.091012477874756
Validation loss: 2.7588112969552316

Epoch: 5| Step: 10
Training loss: 2.164062738418579
Validation loss: 2.7590594496778262

Epoch: 36| Step: 0
Training loss: 2.970844030380249
Validation loss: 2.7567492479919107

Epoch: 5| Step: 1
Training loss: 2.4201407432556152
Validation loss: 2.7558414423337547

Epoch: 5| Step: 2
Training loss: 3.10023832321167
Validation loss: 2.754603744834982

Epoch: 5| Step: 3
Training loss: 3.265824794769287
Validation loss: 2.75314599211498

Epoch: 5| Step: 4
Training loss: 2.5671439170837402
Validation loss: 2.752947258692916

Epoch: 5| Step: 5
Training loss: 2.776092290878296
Validation loss: 2.749496036960233

Epoch: 5| Step: 6
Training loss: 2.9996559619903564
Validation loss: 2.754896415177212

Epoch: 5| Step: 7
Training loss: 2.3531980514526367
Validation loss: 2.7551918978332193

Epoch: 5| Step: 8
Training loss: 2.847973585128784
Validation loss: 2.7527017285746913

Epoch: 5| Step: 9
Training loss: 3.450333833694458
Validation loss: 2.7538034736469226

Epoch: 5| Step: 10
Training loss: 2.8975601196289062
Validation loss: 2.751813896240727

Epoch: 37| Step: 0
Training loss: 3.636322498321533
Validation loss: 2.749495167886057

Epoch: 5| Step: 1
Training loss: 2.6530492305755615
Validation loss: 2.7507486087019726

Epoch: 5| Step: 2
Training loss: 3.7298812866210938
Validation loss: 2.7478972942598405

Epoch: 5| Step: 3
Training loss: 3.0865864753723145
Validation loss: 2.749803444390656

Epoch: 5| Step: 4
Training loss: 2.95917010307312
Validation loss: 2.746759799218947

Epoch: 5| Step: 5
Training loss: 2.9074106216430664
Validation loss: 2.7453071045619186

Epoch: 5| Step: 6
Training loss: 2.4467661380767822
Validation loss: 2.747721451585011

Epoch: 5| Step: 7
Training loss: 2.094569444656372
Validation loss: 2.7480312239739204

Epoch: 5| Step: 8
Training loss: 3.041137456893921
Validation loss: 2.7468139484364498

Epoch: 5| Step: 9
Training loss: 2.508659839630127
Validation loss: 2.7512163013540287

Epoch: 5| Step: 10
Training loss: 2.4481735229492188
Validation loss: 2.7528990109761557

Epoch: 38| Step: 0
Training loss: 2.4214107990264893
Validation loss: 2.750414404817807

Epoch: 5| Step: 1
Training loss: 3.142849922180176
Validation loss: 2.757618740040769

Epoch: 5| Step: 2
Training loss: 3.2062668800354004
Validation loss: 2.7578492164611816

Epoch: 5| Step: 3
Training loss: 2.678068161010742
Validation loss: 2.756865865440779

Epoch: 5| Step: 4
Training loss: 3.176511287689209
Validation loss: 2.752714756996401

Epoch: 5| Step: 5
Training loss: 2.1972129344940186
Validation loss: 2.7500578459872993

Epoch: 5| Step: 6
Training loss: 2.9429221153259277
Validation loss: 2.7458416415799047

Epoch: 5| Step: 7
Training loss: 2.9447898864746094
Validation loss: 2.745856764496014

Epoch: 5| Step: 8
Training loss: 2.772947311401367
Validation loss: 2.74664290489689

Epoch: 5| Step: 9
Training loss: 2.69756817817688
Validation loss: 2.7433216674353487

Epoch: 5| Step: 10
Training loss: 3.496910572052002
Validation loss: 2.741547733224848

Epoch: 39| Step: 0
Training loss: 3.24452543258667
Validation loss: 2.7425197529536423

Epoch: 5| Step: 1
Training loss: 2.7131857872009277
Validation loss: 2.743758596399779

Epoch: 5| Step: 2
Training loss: 2.9326462745666504
Validation loss: 2.74079910145011

Epoch: 5| Step: 3
Training loss: 2.7845406532287598
Validation loss: 2.7423295385094097

Epoch: 5| Step: 4
Training loss: 2.9809937477111816
Validation loss: 2.739492416381836

Epoch: 5| Step: 5
Training loss: 3.13861083984375
Validation loss: 2.7413295520249235

Epoch: 5| Step: 6
Training loss: 2.3730382919311523
Validation loss: 2.742894052177347

Epoch: 5| Step: 7
Training loss: 2.6941730976104736
Validation loss: 2.7386174817239084

Epoch: 5| Step: 8
Training loss: 2.7453529834747314
Validation loss: 2.74267211011661

Epoch: 5| Step: 9
Training loss: 3.126617431640625
Validation loss: 2.7462344707981234

Epoch: 5| Step: 10
Training loss: 2.8507332801818848
Validation loss: 2.743806759516398

Epoch: 40| Step: 0
Training loss: 3.0928878784179688
Validation loss: 2.7433895346938924

Epoch: 5| Step: 1
Training loss: 2.7492308616638184
Validation loss: 2.7361557047854186

Epoch: 5| Step: 2
Training loss: 2.652705669403076
Validation loss: 2.7383715183504167

Epoch: 5| Step: 3
Training loss: 2.9910223484039307
Validation loss: 2.7333560938476236

Epoch: 5| Step: 4
Training loss: 2.3919529914855957
Validation loss: 2.7346843032426733

Epoch: 5| Step: 5
Training loss: 2.294821262359619
Validation loss: 2.7341976986136487

Epoch: 5| Step: 6
Training loss: 3.125854253768921
Validation loss: 2.732868581689814

Epoch: 5| Step: 7
Training loss: 3.425431728363037
Validation loss: 2.734348863683721

Epoch: 5| Step: 8
Training loss: 2.8436779975891113
Validation loss: 2.7430605632002636

Epoch: 5| Step: 9
Training loss: 2.899933338165283
Validation loss: 2.7450301916368547

Epoch: 5| Step: 10
Training loss: 3.0199320316314697
Validation loss: 2.7432763320143505

Epoch: 41| Step: 0
Training loss: 2.700958490371704
Validation loss: 2.740802667474234

Epoch: 5| Step: 1
Training loss: 3.1486191749572754
Validation loss: 2.742011526579498

Epoch: 5| Step: 2
Training loss: 2.6065385341644287
Validation loss: 2.7420461280371553

Epoch: 5| Step: 3
Training loss: 2.9424312114715576
Validation loss: 2.740993533083188

Epoch: 5| Step: 4
Training loss: 3.420259952545166
Validation loss: 2.738943592194588

Epoch: 5| Step: 5
Training loss: 2.5807857513427734
Validation loss: 2.738824121413692

Epoch: 5| Step: 6
Training loss: 2.4534449577331543
Validation loss: 2.737720053683045

Epoch: 5| Step: 7
Training loss: 2.585029125213623
Validation loss: 2.7386039841559624

Epoch: 5| Step: 8
Training loss: 2.7283520698547363
Validation loss: 2.7328263559649066

Epoch: 5| Step: 9
Training loss: 2.597092866897583
Validation loss: 2.737306207738897

Epoch: 5| Step: 10
Training loss: 3.840341567993164
Validation loss: 2.729984760284424

Epoch: 42| Step: 0
Training loss: 2.814342975616455
Validation loss: 2.732026743632491

Epoch: 5| Step: 1
Training loss: 2.5402376651763916
Validation loss: 2.7276588511723343

Epoch: 5| Step: 2
Training loss: 2.8462653160095215
Validation loss: 2.7288143096431607

Epoch: 5| Step: 3
Training loss: 3.685986042022705
Validation loss: 2.7297400095129527

Epoch: 5| Step: 4
Training loss: 2.330848455429077
Validation loss: 2.724772786581388

Epoch: 5| Step: 5
Training loss: 2.1823925971984863
Validation loss: 2.7260483336705033

Epoch: 5| Step: 6
Training loss: 2.575507640838623
Validation loss: 2.724741315328947

Epoch: 5| Step: 7
Training loss: 3.276444911956787
Validation loss: 2.7271909982927385

Epoch: 5| Step: 8
Training loss: 3.353839874267578
Validation loss: 2.7319176017597155

Epoch: 5| Step: 9
Training loss: 2.8258180618286133
Validation loss: 2.7246649919017667

Epoch: 5| Step: 10
Training loss: 3.0189759731292725
Validation loss: 2.727057085242323

Epoch: 43| Step: 0
Training loss: 3.50835919380188
Validation loss: 2.726290149073447

Epoch: 5| Step: 1
Training loss: 2.396869421005249
Validation loss: 2.7276274824655182

Epoch: 5| Step: 2
Training loss: 2.3675692081451416
Validation loss: 2.721861224020681

Epoch: 5| Step: 3
Training loss: 2.585160493850708
Validation loss: 2.7243160663112516

Epoch: 5| Step: 4
Training loss: 2.8678786754608154
Validation loss: 2.7305490791156726

Epoch: 5| Step: 5
Training loss: 3.2470695972442627
Validation loss: 2.721108131511237

Epoch: 5| Step: 6
Training loss: 2.709155321121216
Validation loss: 2.7201674369073685

Epoch: 5| Step: 7
Training loss: 2.766947031021118
Validation loss: 2.7255236692326044

Epoch: 5| Step: 8
Training loss: 3.072345733642578
Validation loss: 2.7205235112097954

Epoch: 5| Step: 9
Training loss: 2.50813889503479
Validation loss: 2.7213923110756824

Epoch: 5| Step: 10
Training loss: 3.4157087802886963
Validation loss: 2.726363492268388

Epoch: 44| Step: 0
Training loss: 2.4017086029052734
Validation loss: 2.7263150215148926

Epoch: 5| Step: 1
Training loss: 2.303353786468506
Validation loss: 2.726292202549596

Epoch: 5| Step: 2
Training loss: 3.5196433067321777
Validation loss: 2.7301093070737776

Epoch: 5| Step: 3
Training loss: 2.786893367767334
Validation loss: 2.7303741747333157

Epoch: 5| Step: 4
Training loss: 2.6925230026245117
Validation loss: 2.7292528049920195

Epoch: 5| Step: 5
Training loss: 3.2033824920654297
Validation loss: 2.7328693661638486

Epoch: 5| Step: 6
Training loss: 3.365900754928589
Validation loss: 2.7249413510804534

Epoch: 5| Step: 7
Training loss: 2.872168779373169
Validation loss: 2.7231767895401164

Epoch: 5| Step: 8
Training loss: 2.7001256942749023
Validation loss: 2.720915502117526

Epoch: 5| Step: 9
Training loss: 2.3449337482452393
Validation loss: 2.7214800978219635

Epoch: 5| Step: 10
Training loss: 3.1926841735839844
Validation loss: 2.7249938954589186

Epoch: 45| Step: 0
Training loss: 3.5870978832244873
Validation loss: 2.723089859049807

Epoch: 5| Step: 1
Training loss: 3.038994789123535
Validation loss: 2.7249469500716015

Epoch: 5| Step: 2
Training loss: 2.574514389038086
Validation loss: 2.719015423969556

Epoch: 5| Step: 3
Training loss: 3.055264711380005
Validation loss: 2.7261525251532115

Epoch: 5| Step: 4
Training loss: 3.2268905639648438
Validation loss: 2.7222593087022022

Epoch: 5| Step: 5
Training loss: 2.6003713607788086
Validation loss: 2.7235662244981333

Epoch: 5| Step: 6
Training loss: 3.2586963176727295
Validation loss: 2.7189477720568256

Epoch: 5| Step: 7
Training loss: 1.5959084033966064
Validation loss: 2.7173573919521865

Epoch: 5| Step: 8
Training loss: 2.8363890647888184
Validation loss: 2.7206162586007068

Epoch: 5| Step: 9
Training loss: 2.8510241508483887
Validation loss: 2.7208309019765546

Epoch: 5| Step: 10
Training loss: 2.6641345024108887
Validation loss: 2.7209193578330417

Epoch: 46| Step: 0
Training loss: 3.0826613903045654
Validation loss: 2.7192496791962655

Epoch: 5| Step: 1
Training loss: 3.5432534217834473
Validation loss: 2.7168160535955943

Epoch: 5| Step: 2
Training loss: 3.3239035606384277
Validation loss: 2.7149679404433056

Epoch: 5| Step: 3
Training loss: 2.2169268131256104
Validation loss: 2.7145319446440666

Epoch: 5| Step: 4
Training loss: 3.4617466926574707
Validation loss: 2.7113995475153767

Epoch: 5| Step: 5
Training loss: 2.2290847301483154
Validation loss: 2.715741216495473

Epoch: 5| Step: 6
Training loss: 3.073998212814331
Validation loss: 2.7135054372972056

Epoch: 5| Step: 7
Training loss: 2.315333604812622
Validation loss: 2.714229299176124

Epoch: 5| Step: 8
Training loss: 3.0355677604675293
Validation loss: 2.710489311525899

Epoch: 5| Step: 9
Training loss: 2.091639995574951
Validation loss: 2.709274043319046

Epoch: 5| Step: 10
Training loss: 2.8898470401763916
Validation loss: 2.7067486598927486

Epoch: 47| Step: 0
Training loss: 3.2910637855529785
Validation loss: 2.706725284617434

Epoch: 5| Step: 1
Training loss: 2.9789319038391113
Validation loss: 2.70690082990995

Epoch: 5| Step: 2
Training loss: 2.5689432621002197
Validation loss: 2.7070091744904876

Epoch: 5| Step: 3
Training loss: 3.0848050117492676
Validation loss: 2.7060353268859205

Epoch: 5| Step: 4
Training loss: 2.480639934539795
Validation loss: 2.7108246331573813

Epoch: 5| Step: 5
Training loss: 2.4609522819519043
Validation loss: 2.7152566038152224

Epoch: 5| Step: 6
Training loss: 2.7200634479522705
Validation loss: 2.7133554309927006

Epoch: 5| Step: 7
Training loss: 3.4871344566345215
Validation loss: 2.7173474898902317

Epoch: 5| Step: 8
Training loss: 3.1521124839782715
Validation loss: 2.7147607572617067

Epoch: 5| Step: 9
Training loss: 2.9519150257110596
Validation loss: 2.7083216149319886

Epoch: 5| Step: 10
Training loss: 1.8906328678131104
Validation loss: 2.7031884654875724

Epoch: 48| Step: 0
Training loss: 1.4933056831359863
Validation loss: 2.7008252759133615

Epoch: 5| Step: 1
Training loss: 3.424544095993042
Validation loss: 2.7003782385139057

Epoch: 5| Step: 2
Training loss: 2.3568968772888184
Validation loss: 2.7062989357979066

Epoch: 5| Step: 3
Training loss: 3.253110408782959
Validation loss: 2.705434504375663

Epoch: 5| Step: 4
Training loss: 3.1275179386138916
Validation loss: 2.715174441696495

Epoch: 5| Step: 5
Training loss: 2.7883822917938232
Validation loss: 2.7135398464818157

Epoch: 5| Step: 6
Training loss: 3.0011677742004395
Validation loss: 2.7146770056857856

Epoch: 5| Step: 7
Training loss: 2.5172464847564697
Validation loss: 2.715888584813764

Epoch: 5| Step: 8
Training loss: 2.4516947269439697
Validation loss: 2.7026793854210966

Epoch: 5| Step: 9
Training loss: 3.3061256408691406
Validation loss: 2.6972525811964467

Epoch: 5| Step: 10
Training loss: 3.525639533996582
Validation loss: 2.7006779896315707

Epoch: 49| Step: 0
Training loss: 2.997706174850464
Validation loss: 2.699170384355771

Epoch: 5| Step: 1
Training loss: 1.967299222946167
Validation loss: 2.7038732536377443

Epoch: 5| Step: 2
Training loss: 2.187349319458008
Validation loss: 2.7056711104608353

Epoch: 5| Step: 3
Training loss: 2.7923197746276855
Validation loss: 2.713969263979184

Epoch: 5| Step: 4
Training loss: 2.8316845893859863
Validation loss: 2.708859999974569

Epoch: 5| Step: 5
Training loss: 2.2677879333496094
Validation loss: 2.7191780510769097

Epoch: 5| Step: 6
Training loss: 3.4389290809631348
Validation loss: 2.706282315715667

Epoch: 5| Step: 7
Training loss: 3.448831558227539
Validation loss: 2.709035617049022

Epoch: 5| Step: 8
Training loss: 3.0128815174102783
Validation loss: 2.7009592415184103

Epoch: 5| Step: 9
Training loss: 3.2287673950195312
Validation loss: 2.699533957307057

Epoch: 5| Step: 10
Training loss: 3.014902114868164
Validation loss: 2.697129370063864

Epoch: 50| Step: 0
Training loss: 2.9912426471710205
Validation loss: 2.695047929722776

Epoch: 5| Step: 1
Training loss: 2.57785964012146
Validation loss: 2.69461868398933

Epoch: 5| Step: 2
Training loss: 1.8235509395599365
Validation loss: 2.6906938552856445

Epoch: 5| Step: 3
Training loss: 2.327576160430908
Validation loss: 2.693314931725943

Epoch: 5| Step: 4
Training loss: 3.1891846656799316
Validation loss: 2.6938880387172905

Epoch: 5| Step: 5
Training loss: 3.279085636138916
Validation loss: 2.6945975236995245

Epoch: 5| Step: 6
Training loss: 3.136843204498291
Validation loss: 2.699597768886115

Epoch: 5| Step: 7
Training loss: 2.7319540977478027
Validation loss: 2.7067335549221245

Epoch: 5| Step: 8
Training loss: 3.047135829925537
Validation loss: 2.706626849789773

Epoch: 5| Step: 9
Training loss: 3.00293231010437
Validation loss: 2.706338861937164

Epoch: 5| Step: 10
Training loss: 3.0981569290161133
Validation loss: 2.7035954408748175

Epoch: 51| Step: 0
Training loss: 3.1289126873016357
Validation loss: 2.7027291610676754

Epoch: 5| Step: 1
Training loss: 2.510899066925049
Validation loss: 2.6968983629698395

Epoch: 5| Step: 2
Training loss: 2.5139477252960205
Validation loss: 2.6977308052842335

Epoch: 5| Step: 3
Training loss: 2.932983875274658
Validation loss: 2.6964350618341917

Epoch: 5| Step: 4
Training loss: 2.6981632709503174
Validation loss: 2.693491607583979

Epoch: 5| Step: 5
Training loss: 2.669325590133667
Validation loss: 2.6988117899945987

Epoch: 5| Step: 6
Training loss: 3.6351571083068848
Validation loss: 2.7011737285121793

Epoch: 5| Step: 7
Training loss: 2.676612615585327
Validation loss: 2.7024344372492966

Epoch: 5| Step: 8
Training loss: 2.3146414756774902
Validation loss: 2.697028934314687

Epoch: 5| Step: 9
Training loss: 3.296905040740967
Validation loss: 2.689946054130472

Epoch: 5| Step: 10
Training loss: 2.713123083114624
Validation loss: 2.6880788162190425

Epoch: 52| Step: 0
Training loss: 2.7339258193969727
Validation loss: 2.6841882736452165

Epoch: 5| Step: 1
Training loss: 2.485513925552368
Validation loss: 2.6864014415330786

Epoch: 5| Step: 2
Training loss: 3.2754530906677246
Validation loss: 2.687880382742933

Epoch: 5| Step: 3
Training loss: 3.150944232940674
Validation loss: 2.687317189349923

Epoch: 5| Step: 4
Training loss: 2.929335117340088
Validation loss: 2.692407590086742

Epoch: 5| Step: 5
Training loss: 3.211036205291748
Validation loss: 2.708216800484606

Epoch: 5| Step: 6
Training loss: 2.6856861114501953
Validation loss: 2.723448289337979

Epoch: 5| Step: 7
Training loss: 3.007167100906372
Validation loss: 2.7138694409401185

Epoch: 5| Step: 8
Training loss: 2.9146811962127686
Validation loss: 2.6978950551761094

Epoch: 5| Step: 9
Training loss: 2.759769916534424
Validation loss: 2.6882795133898334

Epoch: 5| Step: 10
Training loss: 1.831668496131897
Validation loss: 2.6852038624466106

Epoch: 53| Step: 0
Training loss: 3.0068345069885254
Validation loss: 2.684568315423945

Epoch: 5| Step: 1
Training loss: 2.997854471206665
Validation loss: 2.6815879498758624

Epoch: 5| Step: 2
Training loss: 2.2587945461273193
Validation loss: 2.6813518744643017

Epoch: 5| Step: 3
Training loss: 3.143200397491455
Validation loss: 2.686781983221731

Epoch: 5| Step: 4
Training loss: 3.1525614261627197
Validation loss: 2.682373821094472

Epoch: 5| Step: 5
Training loss: 2.766171932220459
Validation loss: 2.689556601226971

Epoch: 5| Step: 6
Training loss: 2.2574429512023926
Validation loss: 2.6963880190285305

Epoch: 5| Step: 7
Training loss: 3.014521837234497
Validation loss: 2.6971554576709704

Epoch: 5| Step: 8
Training loss: 2.9791195392608643
Validation loss: 2.697367742497434

Epoch: 5| Step: 9
Training loss: 2.547097682952881
Validation loss: 2.681551007814305

Epoch: 5| Step: 10
Training loss: 2.9601893424987793
Validation loss: 2.683939528721635

Epoch: 54| Step: 0
Training loss: 2.5909366607666016
Validation loss: 2.6798610071982107

Epoch: 5| Step: 1
Training loss: 2.4780468940734863
Validation loss: 2.6775547689007175

Epoch: 5| Step: 2
Training loss: 2.3957858085632324
Validation loss: 2.6767099057474444

Epoch: 5| Step: 3
Training loss: 2.673882007598877
Validation loss: 2.6762752763686644

Epoch: 5| Step: 4
Training loss: 2.7212276458740234
Validation loss: 2.685592125820857

Epoch: 5| Step: 5
Training loss: 2.689242124557495
Validation loss: 2.6868715568255355

Epoch: 5| Step: 6
Training loss: 3.11409592628479
Validation loss: 2.6895036492296445

Epoch: 5| Step: 7
Training loss: 2.788180112838745
Validation loss: 2.684907833735148

Epoch: 5| Step: 8
Training loss: 2.7519850730895996
Validation loss: 2.681531498509069

Epoch: 5| Step: 9
Training loss: 3.8059475421905518
Validation loss: 2.679637057806856

Epoch: 5| Step: 10
Training loss: 3.0095794200897217
Validation loss: 2.6793855492786696

Epoch: 55| Step: 0
Training loss: 2.431757926940918
Validation loss: 2.6777661282529115

Epoch: 5| Step: 1
Training loss: 2.3659305572509766
Validation loss: 2.6755191767087547

Epoch: 5| Step: 2
Training loss: 3.052649736404419
Validation loss: 2.672869236238541

Epoch: 5| Step: 3
Training loss: 2.6674818992614746
Validation loss: 2.6805457709937968

Epoch: 5| Step: 4
Training loss: 3.721116304397583
Validation loss: 2.682605202480029

Epoch: 5| Step: 5
Training loss: 2.801598310470581
Validation loss: 2.6866911277976087

Epoch: 5| Step: 6
Training loss: 3.504676103591919
Validation loss: 2.69077645322328

Epoch: 5| Step: 7
Training loss: 2.8842592239379883
Validation loss: 2.6810140302104335

Epoch: 5| Step: 8
Training loss: 2.529350996017456
Validation loss: 2.6763859436076176

Epoch: 5| Step: 9
Training loss: 1.6478526592254639
Validation loss: 2.6721162142292147

Epoch: 5| Step: 10
Training loss: 3.5056915283203125
Validation loss: 2.669648026907316

Epoch: 56| Step: 0
Training loss: 2.6632046699523926
Validation loss: 2.6693807571165022

Epoch: 5| Step: 1
Training loss: 3.6306586265563965
Validation loss: 2.6687277388829056

Epoch: 5| Step: 2
Training loss: 2.7130813598632812
Validation loss: 2.672969636096749

Epoch: 5| Step: 3
Training loss: 3.0689330101013184
Validation loss: 2.6731736352366786

Epoch: 5| Step: 4
Training loss: 2.877310276031494
Validation loss: 2.6724625274699223

Epoch: 5| Step: 5
Training loss: 3.881775379180908
Validation loss: 2.6744672508649927

Epoch: 5| Step: 6
Training loss: 2.7303905487060547
Validation loss: 2.6882306991084928

Epoch: 5| Step: 7
Training loss: 2.7007901668548584
Validation loss: 2.6879132742522867

Epoch: 5| Step: 8
Training loss: 2.3934812545776367
Validation loss: 2.67562198638916

Epoch: 5| Step: 9
Training loss: 1.9346649646759033
Validation loss: 2.677884794050647

Epoch: 5| Step: 10
Training loss: 2.289806604385376
Validation loss: 2.67055800396909

Epoch: 57| Step: 0
Training loss: 3.3637473583221436
Validation loss: 2.6682807860835904

Epoch: 5| Step: 1
Training loss: 2.7536206245422363
Validation loss: 2.669634634448636

Epoch: 5| Step: 2
Training loss: 2.431464910507202
Validation loss: 2.6675752644897788

Epoch: 5| Step: 3
Training loss: 3.169246196746826
Validation loss: 2.6626848072134037

Epoch: 5| Step: 4
Training loss: 2.1705081462860107
Validation loss: 2.667432790161461

Epoch: 5| Step: 5
Training loss: 3.298077344894409
Validation loss: 2.6685965035551336

Epoch: 5| Step: 6
Training loss: 2.762127161026001
Validation loss: 2.664571628775648

Epoch: 5| Step: 7
Training loss: 3.287808656692505
Validation loss: 2.6682529321280857

Epoch: 5| Step: 8
Training loss: 2.4658524990081787
Validation loss: 2.6694124616602415

Epoch: 5| Step: 9
Training loss: 2.2617101669311523
Validation loss: 2.6689468763207875

Epoch: 5| Step: 10
Training loss: 2.907167434692383
Validation loss: 2.6671327878070135

Epoch: 58| Step: 0
Training loss: 2.9884438514709473
Validation loss: 2.6614770068917224

Epoch: 5| Step: 1
Training loss: 2.2989726066589355
Validation loss: 2.662824638428227

Epoch: 5| Step: 2
Training loss: 2.5282769203186035
Validation loss: 2.6604964553668933

Epoch: 5| Step: 3
Training loss: 2.9948537349700928
Validation loss: 2.6587279612018215

Epoch: 5| Step: 4
Training loss: 2.069775104522705
Validation loss: 2.6620715664279078

Epoch: 5| Step: 5
Training loss: 2.90319561958313
Validation loss: 2.663166323015767

Epoch: 5| Step: 6
Training loss: 2.9723048210144043
Validation loss: 2.660799441799041

Epoch: 5| Step: 7
Training loss: 2.5274462699890137
Validation loss: 2.6617602738001014

Epoch: 5| Step: 8
Training loss: 3.4611001014709473
Validation loss: 2.665134096658358

Epoch: 5| Step: 9
Training loss: 3.6602070331573486
Validation loss: 2.6606148314732376

Epoch: 5| Step: 10
Training loss: 2.3778743743896484
Validation loss: 2.6606043872012886

Epoch: 59| Step: 0
Training loss: 2.333845615386963
Validation loss: 2.661422388527983

Epoch: 5| Step: 1
Training loss: 3.113612174987793
Validation loss: 2.6615240612337665

Epoch: 5| Step: 2
Training loss: 2.617365598678589
Validation loss: 2.6607147416760846

Epoch: 5| Step: 3
Training loss: 2.991237163543701
Validation loss: 2.6666827330025296

Epoch: 5| Step: 4
Training loss: 2.5000510215759277
Validation loss: 2.658642904732817

Epoch: 5| Step: 5
Training loss: 2.348968267440796
Validation loss: 2.665097826270647

Epoch: 5| Step: 6
Training loss: 2.949003219604492
Validation loss: 2.6543566385904946

Epoch: 5| Step: 7
Training loss: 3.3424770832061768
Validation loss: 2.658478675350066

Epoch: 5| Step: 8
Training loss: 3.1265978813171387
Validation loss: 2.6565562858376452

Epoch: 5| Step: 9
Training loss: 2.7709884643554688
Validation loss: 2.6569725287857877

Epoch: 5| Step: 10
Training loss: 2.6977200508117676
Validation loss: 2.6542416439261487

Epoch: 60| Step: 0
Training loss: 2.6551384925842285
Validation loss: 2.6581085676788003

Epoch: 5| Step: 1
Training loss: 2.5704972743988037
Validation loss: 2.6532045410525416

Epoch: 5| Step: 2
Training loss: 3.0428128242492676
Validation loss: 2.6549031170465613

Epoch: 5| Step: 3
Training loss: 2.682060718536377
Validation loss: 2.649849163588657

Epoch: 5| Step: 4
Training loss: 3.140470027923584
Validation loss: 2.654350967817409

Epoch: 5| Step: 5
Training loss: 3.1077218055725098
Validation loss: 2.656485980556857

Epoch: 5| Step: 6
Training loss: 2.7541308403015137
Validation loss: 2.651176634655204

Epoch: 5| Step: 7
Training loss: 3.5373432636260986
Validation loss: 2.653965501375096

Epoch: 5| Step: 8
Training loss: 2.8203847408294678
Validation loss: 2.657569352016654

Epoch: 5| Step: 9
Training loss: 2.2036843299865723
Validation loss: 2.654812443640924

Epoch: 5| Step: 10
Training loss: 2.087101697921753
Validation loss: 2.6537091091114986

Epoch: 61| Step: 0
Training loss: 2.9508323669433594
Validation loss: 2.650359579311904

Epoch: 5| Step: 1
Training loss: 3.148873805999756
Validation loss: 2.6492127064735658

Epoch: 5| Step: 2
Training loss: 2.8188910484313965
Validation loss: 2.6474804878234863

Epoch: 5| Step: 3
Training loss: 2.6435747146606445
Validation loss: 2.6465269801437215

Epoch: 5| Step: 4
Training loss: 2.960022449493408
Validation loss: 2.6493959862698793

Epoch: 5| Step: 5
Training loss: 1.9838049411773682
Validation loss: 2.64820784138095

Epoch: 5| Step: 6
Training loss: 2.775954246520996
Validation loss: 2.651109556997976

Epoch: 5| Step: 7
Training loss: 3.3151111602783203
Validation loss: 2.6537144901931926

Epoch: 5| Step: 8
Training loss: 2.188265323638916
Validation loss: 2.656246946704003

Epoch: 5| Step: 9
Training loss: 3.520232677459717
Validation loss: 2.6548712843207904

Epoch: 5| Step: 10
Training loss: 2.3557260036468506
Validation loss: 2.648393661745133

Epoch: 62| Step: 0
Training loss: 2.7299113273620605
Validation loss: 2.649436858392531

Epoch: 5| Step: 1
Training loss: 3.120035171508789
Validation loss: 2.6458274395235124

Epoch: 5| Step: 2
Training loss: 2.7112200260162354
Validation loss: 2.648082128135107

Epoch: 5| Step: 3
Training loss: 3.104980945587158
Validation loss: 2.6499215402910785

Epoch: 5| Step: 4
Training loss: 2.960521697998047
Validation loss: 2.6466983236292356

Epoch: 5| Step: 5
Training loss: 2.1190271377563477
Validation loss: 2.646944151129774

Epoch: 5| Step: 6
Training loss: 3.149125099182129
Validation loss: 2.6439998713872765

Epoch: 5| Step: 7
Training loss: 2.248711347579956
Validation loss: 2.6426603665915867

Epoch: 5| Step: 8
Training loss: 2.9374449253082275
Validation loss: 2.643763901084982

Epoch: 5| Step: 9
Training loss: 3.105109691619873
Validation loss: 2.645324645503875

Epoch: 5| Step: 10
Training loss: 2.4216723442077637
Validation loss: 2.6404950054742957

Epoch: 63| Step: 0
Training loss: 3.5345466136932373
Validation loss: 2.6471023021205777

Epoch: 5| Step: 1
Training loss: 3.136814594268799
Validation loss: 2.6453955019673994

Epoch: 5| Step: 2
Training loss: 2.9281163215637207
Validation loss: 2.646622492421058

Epoch: 5| Step: 3
Training loss: 2.639000654220581
Validation loss: 2.64768922457131

Epoch: 5| Step: 4
Training loss: 2.26720929145813
Validation loss: 2.6462605358451925

Epoch: 5| Step: 5
Training loss: 2.5670828819274902
Validation loss: 2.6499071249397854

Epoch: 5| Step: 6
Training loss: 2.7365734577178955
Validation loss: 2.6538811268345004

Epoch: 5| Step: 7
Training loss: 2.5901687145233154
Validation loss: 2.6557861015360844

Epoch: 5| Step: 8
Training loss: 2.7525618076324463
Validation loss: 2.6601777820176977

Epoch: 5| Step: 9
Training loss: 2.9608025550842285
Validation loss: 2.651709189978979

Epoch: 5| Step: 10
Training loss: 2.625009298324585
Validation loss: 2.6488935562872116

Epoch: 64| Step: 0
Training loss: 1.9710462093353271
Validation loss: 2.645478338323614

Epoch: 5| Step: 1
Training loss: 2.836918592453003
Validation loss: 2.638907983738889

Epoch: 5| Step: 2
Training loss: 2.183073043823242
Validation loss: 2.6419156597506617

Epoch: 5| Step: 3
Training loss: 3.0881001949310303
Validation loss: 2.6395622145745063

Epoch: 5| Step: 4
Training loss: 2.682168960571289
Validation loss: 2.6381495639842045

Epoch: 5| Step: 5
Training loss: 2.6426923274993896
Validation loss: 2.640716455316031

Epoch: 5| Step: 6
Training loss: 3.5742897987365723
Validation loss: 2.6402292687405824

Epoch: 5| Step: 7
Training loss: 2.9403181076049805
Validation loss: 2.6372282812672276

Epoch: 5| Step: 8
Training loss: 3.5230510234832764
Validation loss: 2.636435454891574

Epoch: 5| Step: 9
Training loss: 2.400606155395508
Validation loss: 2.636845155428815

Epoch: 5| Step: 10
Training loss: 2.817056655883789
Validation loss: 2.6371763111442648

Epoch: 65| Step: 0
Training loss: 2.6730875968933105
Validation loss: 2.6367304812195482

Epoch: 5| Step: 1
Training loss: 2.3801944255828857
Validation loss: 2.637096881866455

Epoch: 5| Step: 2
Training loss: 2.7825675010681152
Validation loss: 2.6402505264487317

Epoch: 5| Step: 3
Training loss: 2.899427890777588
Validation loss: 2.6399470631794264

Epoch: 5| Step: 4
Training loss: 3.032141923904419
Validation loss: 2.63213094844613

Epoch: 5| Step: 5
Training loss: 2.817474842071533
Validation loss: 2.6302458804140807

Epoch: 5| Step: 6
Training loss: 3.24054217338562
Validation loss: 2.6355817715326944

Epoch: 5| Step: 7
Training loss: 2.5550410747528076
Validation loss: 2.6313908100128174

Epoch: 5| Step: 8
Training loss: 3.1306281089782715
Validation loss: 2.6381980014103714

Epoch: 5| Step: 9
Training loss: 1.8604320287704468
Validation loss: 2.630639574861014

Epoch: 5| Step: 10
Training loss: 3.2660045623779297
Validation loss: 2.63156997260227

Epoch: 66| Step: 0
Training loss: 2.653174877166748
Validation loss: 2.638458533953595

Epoch: 5| Step: 1
Training loss: 2.397028684616089
Validation loss: 2.635678824558053

Epoch: 5| Step: 2
Training loss: 2.829195499420166
Validation loss: 2.63893295872596

Epoch: 5| Step: 3
Training loss: 3.4150230884552
Validation loss: 2.6394430950123775

Epoch: 5| Step: 4
Training loss: 3.1239795684814453
Validation loss: 2.6334532025039836

Epoch: 5| Step: 5
Training loss: 2.842974901199341
Validation loss: 2.631149127919187

Epoch: 5| Step: 6
Training loss: 2.947206974029541
Validation loss: 2.629363465052779

Epoch: 5| Step: 7
Training loss: 2.912910223007202
Validation loss: 2.6286976388705674

Epoch: 5| Step: 8
Training loss: 2.6017837524414062
Validation loss: 2.632252077902517

Epoch: 5| Step: 9
Training loss: 2.3982129096984863
Validation loss: 2.629650236457907

Epoch: 5| Step: 10
Training loss: 2.3912689685821533
Validation loss: 2.630367450816657

Epoch: 67| Step: 0
Training loss: 2.4740447998046875
Validation loss: 2.630563792362008

Epoch: 5| Step: 1
Training loss: 2.1106150150299072
Validation loss: 2.6328639855948825

Epoch: 5| Step: 2
Training loss: 3.605175495147705
Validation loss: 2.6321945703157814

Epoch: 5| Step: 3
Training loss: 2.6594157218933105
Validation loss: 2.6290217061196604

Epoch: 5| Step: 4
Training loss: 2.929358959197998
Validation loss: 2.6287997281679543

Epoch: 5| Step: 5
Training loss: 3.1699209213256836
Validation loss: 2.624382039552094

Epoch: 5| Step: 6
Training loss: 1.9682105779647827
Validation loss: 2.6257426764375422

Epoch: 5| Step: 7
Training loss: 2.5625827312469482
Validation loss: 2.629459978431784

Epoch: 5| Step: 8
Training loss: 3.2246251106262207
Validation loss: 2.629264813597484

Epoch: 5| Step: 9
Training loss: 2.88753080368042
Validation loss: 2.6296790338331655

Epoch: 5| Step: 10
Training loss: 3.051928758621216
Validation loss: 2.6304242405840146

Epoch: 68| Step: 0
Training loss: 2.8416824340820312
Validation loss: 2.628258953812302

Epoch: 5| Step: 1
Training loss: 2.8226044178009033
Validation loss: 2.6271434522444204

Epoch: 5| Step: 2
Training loss: 2.741359233856201
Validation loss: 2.6279003209965204

Epoch: 5| Step: 3
Training loss: 2.7235162258148193
Validation loss: 2.6285139565826743

Epoch: 5| Step: 4
Training loss: 2.7593817710876465
Validation loss: 2.629439412906606

Epoch: 5| Step: 5
Training loss: 2.768092632293701
Validation loss: 2.6307277551261325

Epoch: 5| Step: 6
Training loss: 2.8980660438537598
Validation loss: 2.6268117017643426

Epoch: 5| Step: 7
Training loss: 1.9525047540664673
Validation loss: 2.6385302748731387

Epoch: 5| Step: 8
Training loss: 2.565382719039917
Validation loss: 2.6393395367489068

Epoch: 5| Step: 9
Training loss: 3.2186119556427
Validation loss: 2.648970083523822

Epoch: 5| Step: 10
Training loss: 3.2256295680999756
Validation loss: 2.6431532572674494

Epoch: 69| Step: 0
Training loss: 1.9138050079345703
Validation loss: 2.639276848044447

Epoch: 5| Step: 1
Training loss: 2.8626785278320312
Validation loss: 2.6266828147313928

Epoch: 5| Step: 2
Training loss: 2.708831548690796
Validation loss: 2.6293907370618594

Epoch: 5| Step: 3
Training loss: 2.7264480590820312
Validation loss: 2.625841599638744

Epoch: 5| Step: 4
Training loss: 3.521315813064575
Validation loss: 2.6281664679127354

Epoch: 5| Step: 5
Training loss: 2.633121967315674
Validation loss: 2.620952272927889

Epoch: 5| Step: 6
Training loss: 2.8181750774383545
Validation loss: 2.6222981176068707

Epoch: 5| Step: 7
Training loss: 2.8059027194976807
Validation loss: 2.618011477173016

Epoch: 5| Step: 8
Training loss: 2.701307773590088
Validation loss: 2.616648515065511

Epoch: 5| Step: 9
Training loss: 3.3611538410186768
Validation loss: 2.6216926036342496

Epoch: 5| Step: 10
Training loss: 2.3443827629089355
Validation loss: 2.6176927756237727

Epoch: 70| Step: 0
Training loss: 2.386826992034912
Validation loss: 2.6204729003290974

Epoch: 5| Step: 1
Training loss: 2.1218819618225098
Validation loss: 2.6205296516418457

Epoch: 5| Step: 2
Training loss: 2.6260828971862793
Validation loss: 2.6217754579359487

Epoch: 5| Step: 3
Training loss: 3.219809055328369
Validation loss: 2.6196648638735534

Epoch: 5| Step: 4
Training loss: 2.777198553085327
Validation loss: 2.618088714538082

Epoch: 5| Step: 5
Training loss: 2.5748140811920166
Validation loss: 2.616065363730154

Epoch: 5| Step: 6
Training loss: 2.8362364768981934
Validation loss: 2.6170475970032396

Epoch: 5| Step: 7
Training loss: 2.623420000076294
Validation loss: 2.6159065551655267

Epoch: 5| Step: 8
Training loss: 2.793208599090576
Validation loss: 2.6156025445589455

Epoch: 5| Step: 9
Training loss: 3.5171756744384766
Validation loss: 2.6191832224527993

Epoch: 5| Step: 10
Training loss: 3.0023272037506104
Validation loss: 2.616036661209599

Epoch: 71| Step: 0
Training loss: 2.7960963249206543
Validation loss: 2.6213285025729927

Epoch: 5| Step: 1
Training loss: 2.1529579162597656
Validation loss: 2.6231893390737553

Epoch: 5| Step: 2
Training loss: 3.408261775970459
Validation loss: 2.628303312486218

Epoch: 5| Step: 3
Training loss: 2.8628368377685547
Validation loss: 2.6280149208602084

Epoch: 5| Step: 4
Training loss: 2.3950858116149902
Validation loss: 2.6208648630367812

Epoch: 5| Step: 5
Training loss: 2.7340145111083984
Validation loss: 2.6149171911260134

Epoch: 5| Step: 6
Training loss: 2.67488694190979
Validation loss: 2.6077613548565934

Epoch: 5| Step: 7
Training loss: 2.9330756664276123
Validation loss: 2.61615095087277

Epoch: 5| Step: 8
Training loss: 3.0567269325256348
Validation loss: 2.6242323255026214

Epoch: 5| Step: 9
Training loss: 2.595062494277954
Validation loss: 2.6268348129846717

Epoch: 5| Step: 10
Training loss: 2.93939471244812
Validation loss: 2.6417994499206543

Epoch: 72| Step: 0
Training loss: 3.22538423538208
Validation loss: 2.6351498121856363

Epoch: 5| Step: 1
Training loss: 2.797435760498047
Validation loss: 2.6225324984519713

Epoch: 5| Step: 2
Training loss: 2.7162697315216064
Validation loss: 2.613672443615493

Epoch: 5| Step: 3
Training loss: 2.227836847305298
Validation loss: 2.611566383351562

Epoch: 5| Step: 4
Training loss: 2.592109203338623
Validation loss: 2.6121909618377686

Epoch: 5| Step: 5
Training loss: 2.2974565029144287
Validation loss: 2.6136610533601496

Epoch: 5| Step: 6
Training loss: 3.0945630073547363
Validation loss: 2.634670290895688

Epoch: 5| Step: 7
Training loss: 2.726987838745117
Validation loss: 2.6320244625050533

Epoch: 5| Step: 8
Training loss: 2.619645595550537
Validation loss: 2.631175566745061

Epoch: 5| Step: 9
Training loss: 3.099954128265381
Validation loss: 2.6332608346016175

Epoch: 5| Step: 10
Training loss: 3.192737102508545
Validation loss: 2.6340298242466424

Epoch: 73| Step: 0
Training loss: 2.6405982971191406
Validation loss: 2.6190086539073656

Epoch: 5| Step: 1
Training loss: 2.517688274383545
Validation loss: 2.6078788259977936

Epoch: 5| Step: 2
Training loss: 3.09804105758667
Validation loss: 2.6095309257507324

Epoch: 5| Step: 3
Training loss: 2.903097629547119
Validation loss: 2.6055618486096783

Epoch: 5| Step: 4
Training loss: 2.8113605976104736
Validation loss: 2.6054722621876705

Epoch: 5| Step: 5
Training loss: 2.7444393634796143
Validation loss: 2.608861597635413

Epoch: 5| Step: 6
Training loss: 2.539475202560425
Validation loss: 2.605600354492023

Epoch: 5| Step: 7
Training loss: 3.0156142711639404
Validation loss: 2.609496049983527

Epoch: 5| Step: 8
Training loss: 2.823150634765625
Validation loss: 2.6052904436665196

Epoch: 5| Step: 9
Training loss: 2.6711623668670654
Validation loss: 2.607701911721178

Epoch: 5| Step: 10
Training loss: 2.6684513092041016
Validation loss: 2.6040920083240797

Epoch: 74| Step: 0
Training loss: 2.7999815940856934
Validation loss: 2.6015446262974895

Epoch: 5| Step: 1
Training loss: 2.5410983562469482
Validation loss: 2.5968946641491306

Epoch: 5| Step: 2
Training loss: 2.926514148712158
Validation loss: 2.5943262166874383

Epoch: 5| Step: 3
Training loss: 1.9345896244049072
Validation loss: 2.5939080689543035

Epoch: 5| Step: 4
Training loss: 2.135199546813965
Validation loss: 2.5957342629791587

Epoch: 5| Step: 5
Training loss: 3.241328716278076
Validation loss: 2.597720697361936

Epoch: 5| Step: 6
Training loss: 2.9969229698181152
Validation loss: 2.608818869436941

Epoch: 5| Step: 7
Training loss: 3.1884422302246094
Validation loss: 2.6232162137185373

Epoch: 5| Step: 8
Training loss: 3.049704074859619
Validation loss: 2.599956258650749

Epoch: 5| Step: 9
Training loss: 2.6420819759368896
Validation loss: 2.593709415005099

Epoch: 5| Step: 10
Training loss: 2.8738160133361816
Validation loss: 2.590722369891341

Epoch: 75| Step: 0
Training loss: 1.839505910873413
Validation loss: 2.5896145092543734

Epoch: 5| Step: 1
Training loss: 2.4102299213409424
Validation loss: 2.5914858592453824

Epoch: 5| Step: 2
Training loss: 3.3718273639678955
Validation loss: 2.590674841275779

Epoch: 5| Step: 3
Training loss: 2.5515871047973633
Validation loss: 2.5876288644729124

Epoch: 5| Step: 4
Training loss: 2.331103563308716
Validation loss: 2.5887076905978623

Epoch: 5| Step: 5
Training loss: 3.0674004554748535
Validation loss: 2.5919487630167315

Epoch: 5| Step: 6
Training loss: 2.546971559524536
Validation loss: 2.5905744670539774

Epoch: 5| Step: 7
Training loss: 3.250575542449951
Validation loss: 2.591075881834953

Epoch: 5| Step: 8
Training loss: 2.6922879219055176
Validation loss: 2.5847106185010684

Epoch: 5| Step: 9
Training loss: 3.0259556770324707
Validation loss: 2.5956271130551576

Epoch: 5| Step: 10
Training loss: 3.2574939727783203
Validation loss: 2.5939497998965684

Epoch: 76| Step: 0
Training loss: 2.6909260749816895
Validation loss: 2.584732917047316

Epoch: 5| Step: 1
Training loss: 3.3511688709259033
Validation loss: 2.58322202005694

Epoch: 5| Step: 2
Training loss: 3.509286880493164
Validation loss: 2.5846431665523077

Epoch: 5| Step: 3
Training loss: 2.987266778945923
Validation loss: 2.580173574468141

Epoch: 5| Step: 4
Training loss: 2.2225492000579834
Validation loss: 2.579632815494332

Epoch: 5| Step: 5
Training loss: 2.7518317699432373
Validation loss: 2.576786031005203

Epoch: 5| Step: 6
Training loss: 2.5031239986419678
Validation loss: 2.578855963163478

Epoch: 5| Step: 7
Training loss: 2.6876707077026367
Validation loss: 2.57924827965357

Epoch: 5| Step: 8
Training loss: 2.250178098678589
Validation loss: 2.582714242319907

Epoch: 5| Step: 9
Training loss: 2.860727071762085
Validation loss: 2.5830511431540213

Epoch: 5| Step: 10
Training loss: 2.264695882797241
Validation loss: 2.5769360680733957

Epoch: 77| Step: 0
Training loss: 2.4760165214538574
Validation loss: 2.5792869496089157

Epoch: 5| Step: 1
Training loss: 2.3453903198242188
Validation loss: 2.575275674943001

Epoch: 5| Step: 2
Training loss: 3.1857481002807617
Validation loss: 2.574616983372678

Epoch: 5| Step: 3
Training loss: 3.0026094913482666
Validation loss: 2.582600088529689

Epoch: 5| Step: 4
Training loss: 2.467637300491333
Validation loss: 2.580372169453611

Epoch: 5| Step: 5
Training loss: 1.6663026809692383
Validation loss: 2.579277830739175

Epoch: 5| Step: 6
Training loss: 3.1207311153411865
Validation loss: 2.5805596382387224

Epoch: 5| Step: 7
Training loss: 2.74459171295166
Validation loss: 2.587743874519102

Epoch: 5| Step: 8
Training loss: 3.0187816619873047
Validation loss: 2.588923172284198

Epoch: 5| Step: 9
Training loss: 3.235196352005005
Validation loss: 2.597767242821314

Epoch: 5| Step: 10
Training loss: 2.8714115619659424
Validation loss: 2.580055406016688

Epoch: 78| Step: 0
Training loss: 2.2485311031341553
Validation loss: 2.591332884245021

Epoch: 5| Step: 1
Training loss: 2.5212149620056152
Validation loss: 2.5741168632302234

Epoch: 5| Step: 2
Training loss: 2.8559789657592773
Validation loss: 2.5732055120570685

Epoch: 5| Step: 3
Training loss: 3.404811143875122
Validation loss: 2.570492923900645

Epoch: 5| Step: 4
Training loss: 1.9354610443115234
Validation loss: 2.5697486708241124

Epoch: 5| Step: 5
Training loss: 2.674978733062744
Validation loss: 2.5713585781794723

Epoch: 5| Step: 6
Training loss: 3.2158284187316895
Validation loss: 2.5704331808192755

Epoch: 5| Step: 7
Training loss: 2.6605758666992188
Validation loss: 2.5709646337775776

Epoch: 5| Step: 8
Training loss: 2.3930370807647705
Validation loss: 2.5688115166079615

Epoch: 5| Step: 9
Training loss: 3.7299644947052
Validation loss: 2.5759946300137426

Epoch: 5| Step: 10
Training loss: 2.388146162033081
Validation loss: 2.5734553849825295

Epoch: 79| Step: 0
Training loss: 2.4836976528167725
Validation loss: 2.5716445215286745

Epoch: 5| Step: 1
Training loss: 2.780771255493164
Validation loss: 2.5724177283625447

Epoch: 5| Step: 2
Training loss: 2.5970559120178223
Validation loss: 2.570027284724738

Epoch: 5| Step: 3
Training loss: 3.0631346702575684
Validation loss: 2.5642667329439552

Epoch: 5| Step: 4
Training loss: 2.927921772003174
Validation loss: 2.568429239334599

Epoch: 5| Step: 5
Training loss: 2.7276291847229004
Validation loss: 2.5693606971412577

Epoch: 5| Step: 6
Training loss: 3.1795084476470947
Validation loss: 2.5717402735064105

Epoch: 5| Step: 7
Training loss: 2.012516498565674
Validation loss: 2.576280886127103

Epoch: 5| Step: 8
Training loss: 2.793769121170044
Validation loss: 2.5741438070933023

Epoch: 5| Step: 9
Training loss: 3.155755043029785
Validation loss: 2.576856756723055

Epoch: 5| Step: 10
Training loss: 2.3055245876312256
Validation loss: 2.5810205987704697

Epoch: 80| Step: 0
Training loss: 2.0720553398132324
Validation loss: 2.578477951788133

Epoch: 5| Step: 1
Training loss: 2.7323546409606934
Validation loss: 2.590408448250063

Epoch: 5| Step: 2
Training loss: 3.383152723312378
Validation loss: 2.6033130332987797

Epoch: 5| Step: 3
Training loss: 2.862213373184204
Validation loss: 2.590812378032233

Epoch: 5| Step: 4
Training loss: 2.7533793449401855
Validation loss: 2.5850721789944555

Epoch: 5| Step: 5
Training loss: 3.4570136070251465
Validation loss: 2.5809101289318455

Epoch: 5| Step: 6
Training loss: 2.493485927581787
Validation loss: 2.5690642659382155

Epoch: 5| Step: 7
Training loss: 2.6825497150421143
Validation loss: 2.563047286002867

Epoch: 5| Step: 8
Training loss: 3.2919094562530518
Validation loss: 2.563468599832186

Epoch: 5| Step: 9
Training loss: 2.5092501640319824
Validation loss: 2.5676405096566803

Epoch: 5| Step: 10
Training loss: 1.6572039127349854
Validation loss: 2.5650968961818243

Epoch: 81| Step: 0
Training loss: 3.0117650032043457
Validation loss: 2.573615648413217

Epoch: 5| Step: 1
Training loss: 2.8831915855407715
Validation loss: 2.569709300994873

Epoch: 5| Step: 2
Training loss: 2.6333038806915283
Validation loss: 2.5694751585683515

Epoch: 5| Step: 3
Training loss: 2.8561861515045166
Validation loss: 2.5658323200800086

Epoch: 5| Step: 4
Training loss: 2.8070549964904785
Validation loss: 2.568752650291689

Epoch: 5| Step: 5
Training loss: 2.933116912841797
Validation loss: 2.574474903845018

Epoch: 5| Step: 6
Training loss: 2.6471691131591797
Validation loss: 2.5740311479055755

Epoch: 5| Step: 7
Training loss: 2.6828038692474365
Validation loss: 2.5735577050075737

Epoch: 5| Step: 8
Training loss: 2.396946430206299
Validation loss: 2.5748403174902803

Epoch: 5| Step: 9
Training loss: 2.746269702911377
Validation loss: 2.5833726903443694

Epoch: 5| Step: 10
Training loss: 2.413893699645996
Validation loss: 2.5823928617661998

Epoch: 82| Step: 0
Training loss: 3.4818012714385986
Validation loss: 2.5864761875521753

Epoch: 5| Step: 1
Training loss: 2.306946039199829
Validation loss: 2.571419697935863

Epoch: 5| Step: 2
Training loss: 2.353694438934326
Validation loss: 2.575646472233598

Epoch: 5| Step: 3
Training loss: 2.346531391143799
Validation loss: 2.5785032779939714

Epoch: 5| Step: 4
Training loss: 2.6404030323028564
Validation loss: 2.5850650495098484

Epoch: 5| Step: 5
Training loss: 2.6569347381591797
Validation loss: 2.570809669392083

Epoch: 5| Step: 6
Training loss: 3.430906295776367
Validation loss: 2.564355529764647

Epoch: 5| Step: 7
Training loss: 2.7027478218078613
Validation loss: 2.5573647432429816

Epoch: 5| Step: 8
Training loss: 2.2638919353485107
Validation loss: 2.5595216751098633

Epoch: 5| Step: 9
Training loss: 3.141584873199463
Validation loss: 2.5676759571157475

Epoch: 5| Step: 10
Training loss: 2.5971996784210205
Validation loss: 2.5788913003859983

Epoch: 83| Step: 0
Training loss: 2.851713180541992
Validation loss: 2.604331729232624

Epoch: 5| Step: 1
Training loss: 3.1668248176574707
Validation loss: 2.632401917570381

Epoch: 5| Step: 2
Training loss: 2.9275760650634766
Validation loss: 2.6412846913901706

Epoch: 5| Step: 3
Training loss: 2.6703240871429443
Validation loss: 2.603111959272815

Epoch: 5| Step: 4
Training loss: 3.092576503753662
Validation loss: 2.5803216631694506

Epoch: 5| Step: 5
Training loss: 1.6030257940292358
Validation loss: 2.5570387019905993

Epoch: 5| Step: 6
Training loss: 2.732992172241211
Validation loss: 2.5557598580596266

Epoch: 5| Step: 7
Training loss: 3.4019992351531982
Validation loss: 2.5715465263653825

Epoch: 5| Step: 8
Training loss: 2.0056538581848145
Validation loss: 2.586651297025783

Epoch: 5| Step: 9
Training loss: 2.481215476989746
Validation loss: 2.611999906519408

Epoch: 5| Step: 10
Training loss: 3.6039507389068604
Validation loss: 2.6062290130123014

Epoch: 84| Step: 0
Training loss: 2.9188220500946045
Validation loss: 2.5764795246944634

Epoch: 5| Step: 1
Training loss: 3.160984516143799
Validation loss: 2.5766736999634774

Epoch: 5| Step: 2
Training loss: 2.1629889011383057
Validation loss: 2.5684130089257353

Epoch: 5| Step: 3
Training loss: 1.8485918045043945
Validation loss: 2.5579066045822634

Epoch: 5| Step: 4
Training loss: 3.1807918548583984
Validation loss: 2.5556981486658894

Epoch: 5| Step: 5
Training loss: 2.815884828567505
Validation loss: 2.5466545730508785

Epoch: 5| Step: 6
Training loss: 2.5423169136047363
Validation loss: 2.549607212825488

Epoch: 5| Step: 7
Training loss: 3.1368041038513184
Validation loss: 2.549676643904819

Epoch: 5| Step: 8
Training loss: 2.930115222930908
Validation loss: 2.5536934893618346

Epoch: 5| Step: 9
Training loss: 2.6618638038635254
Validation loss: 2.557639527064498

Epoch: 5| Step: 10
Training loss: 2.539762020111084
Validation loss: 2.5628362804330806

Epoch: 85| Step: 0
Training loss: 2.535477638244629
Validation loss: 2.5637690405691824

Epoch: 5| Step: 1
Training loss: 2.537501096725464
Validation loss: 2.5656604613027265

Epoch: 5| Step: 2
Training loss: 2.88911771774292
Validation loss: 2.5666633831557406

Epoch: 5| Step: 3
Training loss: 2.3721425533294678
Validation loss: 2.554847599357687

Epoch: 5| Step: 4
Training loss: 2.6887917518615723
Validation loss: 2.5484523106646795

Epoch: 5| Step: 5
Training loss: 2.507500171661377
Validation loss: 2.5427041028135564

Epoch: 5| Step: 6
Training loss: 2.212184429168701
Validation loss: 2.5466685961651545

Epoch: 5| Step: 7
Training loss: 3.061920404434204
Validation loss: 2.554265178659911

Epoch: 5| Step: 8
Training loss: 2.502746105194092
Validation loss: 2.568536276458412

Epoch: 5| Step: 9
Training loss: 3.581277370452881
Validation loss: 2.5759888977132817

Epoch: 5| Step: 10
Training loss: 3.2503151893615723
Validation loss: 2.5668765319290983

Epoch: 86| Step: 0
Training loss: 3.272975206375122
Validation loss: 2.5559114615122476

Epoch: 5| Step: 1
Training loss: 3.4376442432403564
Validation loss: 2.546382519506639

Epoch: 5| Step: 2
Training loss: 3.20823335647583
Validation loss: 2.540667987638904

Epoch: 5| Step: 3
Training loss: 2.7144410610198975
Validation loss: 2.5425868444545294

Epoch: 5| Step: 4
Training loss: 2.9480862617492676
Validation loss: 2.5424979348336496

Epoch: 5| Step: 5
Training loss: 2.1953322887420654
Validation loss: 2.541633957175798

Epoch: 5| Step: 6
Training loss: 2.1502864360809326
Validation loss: 2.539415390260758

Epoch: 5| Step: 7
Training loss: 2.4593114852905273
Validation loss: 2.547209726866855

Epoch: 5| Step: 8
Training loss: 2.862372636795044
Validation loss: 2.5463806941945064

Epoch: 5| Step: 9
Training loss: 2.2836410999298096
Validation loss: 2.547396652160152

Epoch: 5| Step: 10
Training loss: 2.3294003009796143
Validation loss: 2.539929384826332

Epoch: 87| Step: 0
Training loss: 1.8490369319915771
Validation loss: 2.536667413609002

Epoch: 5| Step: 1
Training loss: 2.4470999240875244
Validation loss: 2.539336271183465

Epoch: 5| Step: 2
Training loss: 2.8439269065856934
Validation loss: 2.5410946620407926

Epoch: 5| Step: 3
Training loss: 2.6472620964050293
Validation loss: 2.5396567775357153

Epoch: 5| Step: 4
Training loss: 3.0967955589294434
Validation loss: 2.5377594142831783

Epoch: 5| Step: 5
Training loss: 3.015603542327881
Validation loss: 2.5347542352573846

Epoch: 5| Step: 6
Training loss: 3.128429412841797
Validation loss: 2.536083480363251

Epoch: 5| Step: 7
Training loss: 2.9937424659729004
Validation loss: 2.534446270235123

Epoch: 5| Step: 8
Training loss: 2.6500096321105957
Validation loss: 2.533842671302057

Epoch: 5| Step: 9
Training loss: 2.544154167175293
Validation loss: 2.5349988322104178

Epoch: 5| Step: 10
Training loss: 2.665595531463623
Validation loss: 2.535031164846113

Epoch: 88| Step: 0
Training loss: 2.4551615715026855
Validation loss: 2.5332370983657015

Epoch: 5| Step: 1
Training loss: 2.2205095291137695
Validation loss: 2.538838001989549

Epoch: 5| Step: 2
Training loss: 2.7675325870513916
Validation loss: 2.5337487600182973

Epoch: 5| Step: 3
Training loss: 3.1632943153381348
Validation loss: 2.5338203035375124

Epoch: 5| Step: 4
Training loss: 2.9957947731018066
Validation loss: 2.536504158409693

Epoch: 5| Step: 5
Training loss: 2.494452953338623
Validation loss: 2.5408437354590303

Epoch: 5| Step: 6
Training loss: 2.645730972290039
Validation loss: 2.544474576109199

Epoch: 5| Step: 7
Training loss: 3.2655773162841797
Validation loss: 2.5442235880000617

Epoch: 5| Step: 8
Training loss: 3.000800609588623
Validation loss: 2.549594602277202

Epoch: 5| Step: 9
Training loss: 2.5286269187927246
Validation loss: 2.549742447432651

Epoch: 5| Step: 10
Training loss: 2.3131816387176514
Validation loss: 2.54349922877486

Epoch: 89| Step: 0
Training loss: 2.8939836025238037
Validation loss: 2.536056218608733

Epoch: 5| Step: 1
Training loss: 2.3183212280273438
Validation loss: 2.547497582691972

Epoch: 5| Step: 2
Training loss: 2.6984453201293945
Validation loss: 2.5375552754248343

Epoch: 5| Step: 3
Training loss: 2.289416790008545
Validation loss: 2.5339518952113327

Epoch: 5| Step: 4
Training loss: 2.668083667755127
Validation loss: 2.5338879836502897

Epoch: 5| Step: 5
Training loss: 2.946464776992798
Validation loss: 2.526106857484387

Epoch: 5| Step: 6
Training loss: 2.5100417137145996
Validation loss: 2.5305516232726393

Epoch: 5| Step: 7
Training loss: 2.900282382965088
Validation loss: 2.5320664605786725

Epoch: 5| Step: 8
Training loss: 2.59142804145813
Validation loss: 2.5382528587054183

Epoch: 5| Step: 9
Training loss: 2.9624791145324707
Validation loss: 2.542086216711229

Epoch: 5| Step: 10
Training loss: 3.1396894454956055
Validation loss: 2.544263570539413

Epoch: 90| Step: 0
Training loss: 3.11350154876709
Validation loss: 2.540985838059456

Epoch: 5| Step: 1
Training loss: 2.649719476699829
Validation loss: 2.53723927210736

Epoch: 5| Step: 2
Training loss: 2.532695770263672
Validation loss: 2.533163934625605

Epoch: 5| Step: 3
Training loss: 2.8540377616882324
Validation loss: 2.5278190387192594

Epoch: 5| Step: 4
Training loss: 2.8214058876037598
Validation loss: 2.5253320701660646

Epoch: 5| Step: 5
Training loss: 2.7334656715393066
Validation loss: 2.5253616661153813

Epoch: 5| Step: 6
Training loss: 2.1065852642059326
Validation loss: 2.525803883870443

Epoch: 5| Step: 7
Training loss: 2.293882369995117
Validation loss: 2.531752847856091

Epoch: 5| Step: 8
Training loss: 2.1884756088256836
Validation loss: 2.534738189430647

Epoch: 5| Step: 9
Training loss: 3.035576105117798
Validation loss: 2.5373169811823035

Epoch: 5| Step: 10
Training loss: 3.6807432174682617
Validation loss: 2.532975664702795

Epoch: 91| Step: 0
Training loss: 2.688349723815918
Validation loss: 2.5428974577175674

Epoch: 5| Step: 1
Training loss: 2.6027352809906006
Validation loss: 2.5331777244485836

Epoch: 5| Step: 2
Training loss: 3.2791519165039062
Validation loss: 2.526489432140063

Epoch: 5| Step: 3
Training loss: 2.591433048248291
Validation loss: 2.5224488524980444

Epoch: 5| Step: 4
Training loss: 2.8892643451690674
Validation loss: 2.5218626094120804

Epoch: 5| Step: 5
Training loss: 2.644317865371704
Validation loss: 2.521869541496359

Epoch: 5| Step: 6
Training loss: 2.1725144386291504
Validation loss: 2.522723718356061

Epoch: 5| Step: 7
Training loss: 2.3666977882385254
Validation loss: 2.5282226813736783

Epoch: 5| Step: 8
Training loss: 3.0109076499938965
Validation loss: 2.528377593204539

Epoch: 5| Step: 9
Training loss: 2.8799703121185303
Validation loss: 2.532397885476389

Epoch: 5| Step: 10
Training loss: 2.6452789306640625
Validation loss: 2.5337524721699376

Epoch: 92| Step: 0
Training loss: 2.76898455619812
Validation loss: 2.529664324175927

Epoch: 5| Step: 1
Training loss: 2.5165810585021973
Validation loss: 2.530621044097408

Epoch: 5| Step: 2
Training loss: 3.230494260787964
Validation loss: 2.5328091575253393

Epoch: 5| Step: 3
Training loss: 2.4152567386627197
Validation loss: 2.5289627275159283

Epoch: 5| Step: 4
Training loss: 2.3748116493225098
Validation loss: 2.5255364012974564

Epoch: 5| Step: 5
Training loss: 2.3730108737945557
Validation loss: 2.5195703429560505

Epoch: 5| Step: 6
Training loss: 2.7412021160125732
Validation loss: 2.523711819802561

Epoch: 5| Step: 7
Training loss: 2.533113479614258
Validation loss: 2.5201519304706204

Epoch: 5| Step: 8
Training loss: 2.904132843017578
Validation loss: 2.5242106196700886

Epoch: 5| Step: 9
Training loss: 2.908705234527588
Validation loss: 2.525286997518232

Epoch: 5| Step: 10
Training loss: 3.100247621536255
Validation loss: 2.524024789051343

Epoch: 93| Step: 0
Training loss: 2.920708417892456
Validation loss: 2.525773130437379

Epoch: 5| Step: 1
Training loss: 2.924337148666382
Validation loss: 2.5283052434203444

Epoch: 5| Step: 2
Training loss: 2.641550302505493
Validation loss: 2.529667249289892

Epoch: 5| Step: 3
Training loss: 2.921492099761963
Validation loss: 2.529600630524338

Epoch: 5| Step: 4
Training loss: 2.9104042053222656
Validation loss: 2.520647382223478

Epoch: 5| Step: 5
Training loss: 2.9142355918884277
Validation loss: 2.5211592361491215

Epoch: 5| Step: 6
Training loss: 2.5221383571624756
Validation loss: 2.522410895234795

Epoch: 5| Step: 7
Training loss: 1.6547954082489014
Validation loss: 2.5154845483841433

Epoch: 5| Step: 8
Training loss: 2.917783260345459
Validation loss: 2.5186455044695126

Epoch: 5| Step: 9
Training loss: 2.7920424938201904
Validation loss: 2.5183938908320602

Epoch: 5| Step: 10
Training loss: 2.529890298843384
Validation loss: 2.5140259599172943

Epoch: 94| Step: 0
Training loss: 3.1131560802459717
Validation loss: 2.5211465974007883

Epoch: 5| Step: 1
Training loss: 3.0585553646087646
Validation loss: 2.516011652126107

Epoch: 5| Step: 2
Training loss: 2.4819676876068115
Validation loss: 2.5183427872196322

Epoch: 5| Step: 3
Training loss: 2.634072780609131
Validation loss: 2.5314843526450534

Epoch: 5| Step: 4
Training loss: 3.0665383338928223
Validation loss: 2.530100481484526

Epoch: 5| Step: 5
Training loss: 2.686687469482422
Validation loss: 2.5198923157107447

Epoch: 5| Step: 6
Training loss: 2.6694998741149902
Validation loss: 2.521264858143304

Epoch: 5| Step: 7
Training loss: 2.6760306358337402
Validation loss: 2.5196234385172525

Epoch: 5| Step: 8
Training loss: 2.288886547088623
Validation loss: 2.5153328962223505

Epoch: 5| Step: 9
Training loss: 2.4174888134002686
Validation loss: 2.514743140948716

Epoch: 5| Step: 10
Training loss: 2.6001102924346924
Validation loss: 2.514426374948153

Epoch: 95| Step: 0
Training loss: 1.7648351192474365
Validation loss: 2.514918483713622

Epoch: 5| Step: 1
Training loss: 2.5039713382720947
Validation loss: 2.5149622117319415

Epoch: 5| Step: 2
Training loss: 3.032263994216919
Validation loss: 2.5138198047555904

Epoch: 5| Step: 3
Training loss: 3.4003777503967285
Validation loss: 2.5148323992247223

Epoch: 5| Step: 4
Training loss: 2.1518361568450928
Validation loss: 2.5198173420403593

Epoch: 5| Step: 5
Training loss: 3.156831741333008
Validation loss: 2.519231160481771

Epoch: 5| Step: 6
Training loss: 2.6148204803466797
Validation loss: 2.5253196531726467

Epoch: 5| Step: 7
Training loss: 2.85274600982666
Validation loss: 2.5230026398935625

Epoch: 5| Step: 8
Training loss: 3.319702625274658
Validation loss: 2.526562454879925

Epoch: 5| Step: 9
Training loss: 2.775524616241455
Validation loss: 2.524174374918784

Epoch: 5| Step: 10
Training loss: 2.0264089107513428
Validation loss: 2.5268129815337477

Epoch: 96| Step: 0
Training loss: 2.82912278175354
Validation loss: 2.523530057681504

Epoch: 5| Step: 1
Training loss: 2.750220537185669
Validation loss: 2.5170763756639216

Epoch: 5| Step: 2
Training loss: 2.164095878601074
Validation loss: 2.5258201655521186

Epoch: 5| Step: 3
Training loss: 2.7519826889038086
Validation loss: 2.519904085384902

Epoch: 5| Step: 4
Training loss: 2.750826358795166
Validation loss: 2.5150296329170145

Epoch: 5| Step: 5
Training loss: 2.9708597660064697
Validation loss: 2.515260822029524

Epoch: 5| Step: 6
Training loss: 2.7588818073272705
Validation loss: 2.5190258820851645

Epoch: 5| Step: 7
Training loss: 2.6510136127471924
Validation loss: 2.527208141101304

Epoch: 5| Step: 8
Training loss: 2.4641811847686768
Validation loss: 2.525448005686524

Epoch: 5| Step: 9
Training loss: 2.6023316383361816
Validation loss: 2.5175525680665047

Epoch: 5| Step: 10
Training loss: 3.0397307872772217
Validation loss: 2.513472787795528

Epoch: 97| Step: 0
Training loss: 2.4254355430603027
Validation loss: 2.5137512914596067

Epoch: 5| Step: 1
Training loss: 2.2401037216186523
Validation loss: 2.511585094595468

Epoch: 5| Step: 2
Training loss: 3.1055426597595215
Validation loss: 2.510567613827285

Epoch: 5| Step: 3
Training loss: 3.0231404304504395
Validation loss: 2.507293007707083

Epoch: 5| Step: 4
Training loss: 3.1482717990875244
Validation loss: 2.511512076982888

Epoch: 5| Step: 5
Training loss: 2.4464943408966064
Validation loss: 2.514827289888936

Epoch: 5| Step: 6
Training loss: 3.0947265625
Validation loss: 2.5120314475028747

Epoch: 5| Step: 7
Training loss: 3.085625171661377
Validation loss: 2.511653179763466

Epoch: 5| Step: 8
Training loss: 2.306257724761963
Validation loss: 2.5142315767144643

Epoch: 5| Step: 9
Training loss: 2.239994525909424
Validation loss: 2.508663195435719

Epoch: 5| Step: 10
Training loss: 2.495537519454956
Validation loss: 2.506337963124757

Epoch: 98| Step: 0
Training loss: 3.246894121170044
Validation loss: 2.504738535932315

Epoch: 5| Step: 1
Training loss: 2.644817590713501
Validation loss: 2.500933462573636

Epoch: 5| Step: 2
Training loss: 2.768155574798584
Validation loss: 2.5062915484110513

Epoch: 5| Step: 3
Training loss: 2.8177273273468018
Validation loss: 2.506055619127007

Epoch: 5| Step: 4
Training loss: 2.4127821922302246
Validation loss: 2.5047435914316485

Epoch: 5| Step: 5
Training loss: 2.280268907546997
Validation loss: 2.5083624316800024

Epoch: 5| Step: 6
Training loss: 3.0450692176818848
Validation loss: 2.508876724909711

Epoch: 5| Step: 7
Training loss: 2.53887939453125
Validation loss: 2.5098776740412556

Epoch: 5| Step: 8
Training loss: 2.984811782836914
Validation loss: 2.508026617829518

Epoch: 5| Step: 9
Training loss: 2.7380313873291016
Validation loss: 2.499382757371472

Epoch: 5| Step: 10
Training loss: 1.9813647270202637
Validation loss: 2.5017231049076205

Epoch: 99| Step: 0
Training loss: 3.051723003387451
Validation loss: 2.5101416418629308

Epoch: 5| Step: 1
Training loss: 3.125007152557373
Validation loss: 2.512145524383873

Epoch: 5| Step: 2
Training loss: 2.010906934738159
Validation loss: 2.505708304784631

Epoch: 5| Step: 3
Training loss: 2.993525981903076
Validation loss: 2.507279696003083

Epoch: 5| Step: 4
Training loss: 2.1440277099609375
Validation loss: 2.518372958706271

Epoch: 5| Step: 5
Training loss: 2.7055447101593018
Validation loss: 2.536397252031552

Epoch: 5| Step: 6
Training loss: 2.853421688079834
Validation loss: 2.5543974138075307

Epoch: 5| Step: 7
Training loss: 2.893831253051758
Validation loss: 2.5713122429386264

Epoch: 5| Step: 8
Training loss: 2.8292412757873535
Validation loss: 2.5531280758560344

Epoch: 5| Step: 9
Training loss: 2.6755685806274414
Validation loss: 2.5114467964377454

Epoch: 5| Step: 10
Training loss: 2.3107693195343018
Validation loss: 2.502063746093422

Epoch: 100| Step: 0
Training loss: 2.4740543365478516
Validation loss: 2.5055513048684723

Epoch: 5| Step: 1
Training loss: 2.4750711917877197
Validation loss: 2.5079832397481447

Epoch: 5| Step: 2
Training loss: 2.568495035171509
Validation loss: 2.5091568013673187

Epoch: 5| Step: 3
Training loss: 2.4469597339630127
Validation loss: 2.5091361332965154

Epoch: 5| Step: 4
Training loss: 2.906648635864258
Validation loss: 2.504907202977006

Epoch: 5| Step: 5
Training loss: 2.0571699142456055
Validation loss: 2.503513607927548

Epoch: 5| Step: 6
Training loss: 2.8086090087890625
Validation loss: 2.507180057546144

Epoch: 5| Step: 7
Training loss: 3.26666522026062
Validation loss: 2.5040884658854496

Epoch: 5| Step: 8
Training loss: 3.1566193103790283
Validation loss: 2.499656476000304

Epoch: 5| Step: 9
Training loss: 2.411133050918579
Validation loss: 2.5035913669934837

Epoch: 5| Step: 10
Training loss: 3.0730183124542236
Validation loss: 2.502503741172052

Epoch: 101| Step: 0
Training loss: 3.089052677154541
Validation loss: 2.509560933677099

Epoch: 5| Step: 1
Training loss: 2.951853036880493
Validation loss: 2.5079457823948195

Epoch: 5| Step: 2
Training loss: 3.1565842628479004
Validation loss: 2.506758693725832

Epoch: 5| Step: 3
Training loss: 2.625361204147339
Validation loss: 2.5049564248772076

Epoch: 5| Step: 4
Training loss: 2.693732738494873
Validation loss: 2.5015236946844284

Epoch: 5| Step: 5
Training loss: 3.0830135345458984
Validation loss: 2.499191802035096

Epoch: 5| Step: 6
Training loss: 2.275707721710205
Validation loss: 2.4964065115938903

Epoch: 5| Step: 7
Training loss: 2.729515790939331
Validation loss: 2.4998541596115276

Epoch: 5| Step: 8
Training loss: 2.2201850414276123
Validation loss: 2.4985516609684115

Epoch: 5| Step: 9
Training loss: 2.6588099002838135
Validation loss: 2.495874099833991

Epoch: 5| Step: 10
Training loss: 1.8938812017440796
Validation loss: 2.500462670480051

Epoch: 102| Step: 0
Training loss: 2.8168911933898926
Validation loss: 2.503557692291916

Epoch: 5| Step: 1
Training loss: 2.7977964878082275
Validation loss: 2.4995961061087986

Epoch: 5| Step: 2
Training loss: 2.8678226470947266
Validation loss: 2.496263466855531

Epoch: 5| Step: 3
Training loss: 2.676156520843506
Validation loss: 2.5059015802157822

Epoch: 5| Step: 4
Training loss: 2.2084450721740723
Validation loss: 2.5027392987282044

Epoch: 5| Step: 5
Training loss: 2.234130382537842
Validation loss: 2.5029880051971762

Epoch: 5| Step: 6
Training loss: 2.498868942260742
Validation loss: 2.498078435979864

Epoch: 5| Step: 7
Training loss: 3.0871894359588623
Validation loss: 2.500103586463518

Epoch: 5| Step: 8
Training loss: 2.442507266998291
Validation loss: 2.5061234633127847

Epoch: 5| Step: 9
Training loss: 3.1352908611297607
Validation loss: 2.5082271022181355

Epoch: 5| Step: 10
Training loss: 2.7561147212982178
Validation loss: 2.515331050401093

Epoch: 103| Step: 0
Training loss: 2.41780424118042
Validation loss: 2.5102174051346315

Epoch: 5| Step: 1
Training loss: 2.5839312076568604
Validation loss: 2.504949915793634

Epoch: 5| Step: 2
Training loss: 1.9705150127410889
Validation loss: 2.5086476136279363

Epoch: 5| Step: 3
Training loss: 2.9941725730895996
Validation loss: 2.4988340536753335

Epoch: 5| Step: 4
Training loss: 3.561237335205078
Validation loss: 2.495035368909118

Epoch: 5| Step: 5
Training loss: 2.851414203643799
Validation loss: 2.4952341612949165

Epoch: 5| Step: 6
Training loss: 2.8165132999420166
Validation loss: 2.4922188430704098

Epoch: 5| Step: 7
Training loss: 2.406920909881592
Validation loss: 2.497135687899846

Epoch: 5| Step: 8
Training loss: 1.8432884216308594
Validation loss: 2.496956056164157

Epoch: 5| Step: 9
Training loss: 2.8427226543426514
Validation loss: 2.4941571425366145

Epoch: 5| Step: 10
Training loss: 3.2566988468170166
Validation loss: 2.495701274564189

Epoch: 104| Step: 0
Training loss: 2.5009639263153076
Validation loss: 2.495460933254611

Epoch: 5| Step: 1
Training loss: 2.4636549949645996
Validation loss: 2.489090710557917

Epoch: 5| Step: 2
Training loss: 2.384337902069092
Validation loss: 2.496546442790698

Epoch: 5| Step: 3
Training loss: 3.0812809467315674
Validation loss: 2.496074894423126

Epoch: 5| Step: 4
Training loss: 2.3105077743530273
Validation loss: 2.4943494745480117

Epoch: 5| Step: 5
Training loss: 2.805325984954834
Validation loss: 2.492222293730705

Epoch: 5| Step: 6
Training loss: 2.7389631271362305
Validation loss: 2.4895049320754183

Epoch: 5| Step: 7
Training loss: 2.853759765625
Validation loss: 2.5002262438497236

Epoch: 5| Step: 8
Training loss: 2.963107109069824
Validation loss: 2.519202604088732

Epoch: 5| Step: 9
Training loss: 3.062523365020752
Validation loss: 2.532318530544158

Epoch: 5| Step: 10
Training loss: 2.236051559448242
Validation loss: 2.5409435431162515

Epoch: 105| Step: 0
Training loss: 3.0275814533233643
Validation loss: 2.5343516898411576

Epoch: 5| Step: 1
Training loss: 2.7341902256011963
Validation loss: 2.5197884831377255

Epoch: 5| Step: 2
Training loss: 1.9846458435058594
Validation loss: 2.49749614602776

Epoch: 5| Step: 3
Training loss: 2.2268431186676025
Validation loss: 2.488210339700022

Epoch: 5| Step: 4
Training loss: 2.7776730060577393
Validation loss: 2.487418693880881

Epoch: 5| Step: 5
Training loss: 3.4781880378723145
Validation loss: 2.494595491757957

Epoch: 5| Step: 6
Training loss: 3.199270725250244
Validation loss: 2.5025804581180697

Epoch: 5| Step: 7
Training loss: 2.305830240249634
Validation loss: 2.5086451217692387

Epoch: 5| Step: 8
Training loss: 2.836585521697998
Validation loss: 2.505474667395315

Epoch: 5| Step: 9
Training loss: 2.639709711074829
Validation loss: 2.5021588802337646

Epoch: 5| Step: 10
Training loss: 2.227381467819214
Validation loss: 2.508787037223898

Epoch: 106| Step: 0
Training loss: 3.2014098167419434
Validation loss: 2.5008066213259132

Epoch: 5| Step: 1
Training loss: 2.0488953590393066
Validation loss: 2.48873463625549

Epoch: 5| Step: 2
Training loss: 3.2738354206085205
Validation loss: 2.4889111954678773

Epoch: 5| Step: 3
Training loss: 2.66670560836792
Validation loss: 2.490328940012122

Epoch: 5| Step: 4
Training loss: 3.144625425338745
Validation loss: 2.4906592420352403

Epoch: 5| Step: 5
Training loss: 2.7399039268493652
Validation loss: 2.4919527653724916

Epoch: 5| Step: 6
Training loss: 2.3107869625091553
Validation loss: 2.4935634546382452

Epoch: 5| Step: 7
Training loss: 2.4001235961914062
Validation loss: 2.4970474499528126

Epoch: 5| Step: 8
Training loss: 2.545088291168213
Validation loss: 2.493716391183997

Epoch: 5| Step: 9
Training loss: 2.5175821781158447
Validation loss: 2.4979586037256385

Epoch: 5| Step: 10
Training loss: 2.563164472579956
Validation loss: 2.502961145934238

Epoch: 107| Step: 0
Training loss: 2.8850197792053223
Validation loss: 2.499279001707672

Epoch: 5| Step: 1
Training loss: 2.714897632598877
Validation loss: 2.499577013395166

Epoch: 5| Step: 2
Training loss: 2.2556710243225098
Validation loss: 2.5077119360687914

Epoch: 5| Step: 3
Training loss: 2.104816436767578
Validation loss: 2.50036697746605

Epoch: 5| Step: 4
Training loss: 2.256218671798706
Validation loss: 2.5018507819021902

Epoch: 5| Step: 5
Training loss: 3.1774911880493164
Validation loss: 2.488022904242239

Epoch: 5| Step: 6
Training loss: 3.1123430728912354
Validation loss: 2.487999358484822

Epoch: 5| Step: 7
Training loss: 2.0017333030700684
Validation loss: 2.4893586353589128

Epoch: 5| Step: 8
Training loss: 3.299488067626953
Validation loss: 2.4915400935757543

Epoch: 5| Step: 9
Training loss: 3.0301454067230225
Validation loss: 2.4888679109593874

Epoch: 5| Step: 10
Training loss: 2.5456857681274414
Validation loss: 2.4897428199809086

Epoch: 108| Step: 0
Training loss: 3.0716805458068848
Validation loss: 2.4949487665648102

Epoch: 5| Step: 1
Training loss: 2.8804383277893066
Validation loss: 2.4932786110908753

Epoch: 5| Step: 2
Training loss: 2.7883777618408203
Validation loss: 2.506875935421195

Epoch: 5| Step: 3
Training loss: 1.849557876586914
Validation loss: 2.5235955484451784

Epoch: 5| Step: 4
Training loss: 2.521238088607788
Validation loss: 2.539409896378876

Epoch: 5| Step: 5
Training loss: 2.0157058238983154
Validation loss: 2.5269616265450754

Epoch: 5| Step: 6
Training loss: 2.447115421295166
Validation loss: 2.512511540484685

Epoch: 5| Step: 7
Training loss: 2.874887466430664
Validation loss: 2.48228628917407

Epoch: 5| Step: 8
Training loss: 2.6327507495880127
Validation loss: 2.4860666798007105

Epoch: 5| Step: 9
Training loss: 3.3669629096984863
Validation loss: 2.487883908774263

Epoch: 5| Step: 10
Training loss: 3.0333380699157715
Validation loss: 2.50642442446883

Epoch: 109| Step: 0
Training loss: 2.9831020832061768
Validation loss: 2.5129826632879113

Epoch: 5| Step: 1
Training loss: 2.464489698410034
Validation loss: 2.5517614451787805

Epoch: 5| Step: 2
Training loss: 3.1473500728607178
Validation loss: 2.5537787957858016

Epoch: 5| Step: 3
Training loss: 2.7480506896972656
Validation loss: 2.554415101646095

Epoch: 5| Step: 4
Training loss: 2.5333986282348633
Validation loss: 2.5164368896074194

Epoch: 5| Step: 5
Training loss: 2.4418907165527344
Validation loss: 2.4918642813159573

Epoch: 5| Step: 6
Training loss: 2.599414348602295
Validation loss: 2.484527540463273

Epoch: 5| Step: 7
Training loss: 2.987900972366333
Validation loss: 2.486695856176397

Epoch: 5| Step: 8
Training loss: 2.944439172744751
Validation loss: 2.4842440364181355

Epoch: 5| Step: 9
Training loss: 2.3135323524475098
Validation loss: 2.5001102724382953

Epoch: 5| Step: 10
Training loss: 2.3625965118408203
Validation loss: 2.488883969604328

Epoch: 110| Step: 0
Training loss: 2.8865866661071777
Validation loss: 2.49414905681405

Epoch: 5| Step: 1
Training loss: 2.5641379356384277
Validation loss: 2.4995254573001655

Epoch: 5| Step: 2
Training loss: 2.0211257934570312
Validation loss: 2.495741846740887

Epoch: 5| Step: 3
Training loss: 3.8087668418884277
Validation loss: 2.4940653642018638

Epoch: 5| Step: 4
Training loss: 2.593601942062378
Validation loss: 2.5032512603267545

Epoch: 5| Step: 5
Training loss: 2.541527271270752
Validation loss: 2.4875127577012583

Epoch: 5| Step: 6
Training loss: 2.69456148147583
Validation loss: 2.4907302984627346

Epoch: 5| Step: 7
Training loss: 2.913543939590454
Validation loss: 2.4785275741290023

Epoch: 5| Step: 8
Training loss: 2.97753643989563
Validation loss: 2.470188263923891

Epoch: 5| Step: 9
Training loss: 2.23272442817688
Validation loss: 2.4734745461453675

Epoch: 5| Step: 10
Training loss: 2.0747568607330322
Validation loss: 2.4749023427245436

Epoch: 111| Step: 0
Training loss: 2.6492104530334473
Validation loss: 2.476101718923097

Epoch: 5| Step: 1
Training loss: 3.0224735736846924
Validation loss: 2.477711369914393

Epoch: 5| Step: 2
Training loss: 2.678234577178955
Validation loss: 2.4755719605312554

Epoch: 5| Step: 3
Training loss: 3.0715527534484863
Validation loss: 2.4786772035783335

Epoch: 5| Step: 4
Training loss: 2.6487877368927
Validation loss: 2.4862550022781535

Epoch: 5| Step: 5
Training loss: 2.2625038623809814
Validation loss: 2.484924994489198

Epoch: 5| Step: 6
Training loss: 1.5639078617095947
Validation loss: 2.494393297421035

Epoch: 5| Step: 7
Training loss: 2.9950478076934814
Validation loss: 2.49711117693173

Epoch: 5| Step: 8
Training loss: 2.4975478649139404
Validation loss: 2.4987939455175914

Epoch: 5| Step: 9
Training loss: 2.864626884460449
Validation loss: 2.487083496585969

Epoch: 5| Step: 10
Training loss: 3.213548421859741
Validation loss: 2.4661238244784776

Epoch: 112| Step: 0
Training loss: 2.6364173889160156
Validation loss: 2.4709609554659937

Epoch: 5| Step: 1
Training loss: 2.8286890983581543
Validation loss: 2.4832472596117245

Epoch: 5| Step: 2
Training loss: 2.3755040168762207
Validation loss: 2.48941328448634

Epoch: 5| Step: 3
Training loss: 3.029390811920166
Validation loss: 2.4932894681089666

Epoch: 5| Step: 4
Training loss: 2.7803311347961426
Validation loss: 2.495789130528768

Epoch: 5| Step: 5
Training loss: 2.890101909637451
Validation loss: 2.4974936080235306

Epoch: 5| Step: 6
Training loss: 2.3112380504608154
Validation loss: 2.4826542664599676

Epoch: 5| Step: 7
Training loss: 2.7780990600585938
Validation loss: 2.4804628587538198

Epoch: 5| Step: 8
Training loss: 2.34981107711792
Validation loss: 2.471690441972466

Epoch: 5| Step: 9
Training loss: 2.505225658416748
Validation loss: 2.4804697600744103

Epoch: 5| Step: 10
Training loss: 3.0603222846984863
Validation loss: 2.489471407346828

Epoch: 113| Step: 0
Training loss: 3.166538715362549
Validation loss: 2.516166381938483

Epoch: 5| Step: 1
Training loss: 2.3792152404785156
Validation loss: 2.501567138138638

Epoch: 5| Step: 2
Training loss: 2.2316017150878906
Validation loss: 2.498822796729303

Epoch: 5| Step: 3
Training loss: 2.740391254425049
Validation loss: 2.485281462310463

Epoch: 5| Step: 4
Training loss: 2.998769760131836
Validation loss: 2.4798047183662333

Epoch: 5| Step: 5
Training loss: 2.715695858001709
Validation loss: 2.4731855828274965

Epoch: 5| Step: 6
Training loss: 2.4992692470550537
Validation loss: 2.465890927981305

Epoch: 5| Step: 7
Training loss: 2.3781838417053223
Validation loss: 2.4663900841948805

Epoch: 5| Step: 8
Training loss: 2.6907286643981934
Validation loss: 2.4694323078278573

Epoch: 5| Step: 9
Training loss: 2.462042808532715
Validation loss: 2.465489879731209

Epoch: 5| Step: 10
Training loss: 3.1344387531280518
Validation loss: 2.4702621019014748

Epoch: 114| Step: 0
Training loss: 2.5186541080474854
Validation loss: 2.4667937627402683

Epoch: 5| Step: 1
Training loss: 2.694880723953247
Validation loss: 2.4654627230859574

Epoch: 5| Step: 2
Training loss: 2.3774428367614746
Validation loss: 2.46965116582891

Epoch: 5| Step: 3
Training loss: 3.1845638751983643
Validation loss: 2.4742144102691324

Epoch: 5| Step: 4
Training loss: 2.7303104400634766
Validation loss: 2.4699857670773744

Epoch: 5| Step: 5
Training loss: 3.068617343902588
Validation loss: 2.4727038362974763

Epoch: 5| Step: 6
Training loss: 3.348522901535034
Validation loss: 2.473622614337552

Epoch: 5| Step: 7
Training loss: 1.929669737815857
Validation loss: 2.4775977314159436

Epoch: 5| Step: 8
Training loss: 3.0165655612945557
Validation loss: 2.4735111472427205

Epoch: 5| Step: 9
Training loss: 2.6671302318573
Validation loss: 2.478053587739186

Epoch: 5| Step: 10
Training loss: 1.6651273965835571
Validation loss: 2.486631126813991

Epoch: 115| Step: 0
Training loss: 2.944535255432129
Validation loss: 2.4756098408852854

Epoch: 5| Step: 1
Training loss: 1.9845516681671143
Validation loss: 2.4778309509318364

Epoch: 5| Step: 2
Training loss: 2.7233951091766357
Validation loss: 2.487987741347282

Epoch: 5| Step: 3
Training loss: 2.6675143241882324
Validation loss: 2.496309834141885

Epoch: 5| Step: 4
Training loss: 2.4080371856689453
Validation loss: 2.490007454349149

Epoch: 5| Step: 5
Training loss: 2.4848339557647705
Validation loss: 2.495300180168562

Epoch: 5| Step: 6
Training loss: 3.360656261444092
Validation loss: 2.484786225903419

Epoch: 5| Step: 7
Training loss: 2.528035879135132
Validation loss: 2.477571379753851

Epoch: 5| Step: 8
Training loss: 3.1631524562835693
Validation loss: 2.463021022017284

Epoch: 5| Step: 9
Training loss: 2.360060930252075
Validation loss: 2.460389951223968

Epoch: 5| Step: 10
Training loss: 2.7257091999053955
Validation loss: 2.460999127357237

Epoch: 116| Step: 0
Training loss: 2.691521167755127
Validation loss: 2.4720467957117225

Epoch: 5| Step: 1
Training loss: 2.4529192447662354
Validation loss: 2.4698911251560336

Epoch: 5| Step: 2
Training loss: 3.158287525177002
Validation loss: 2.4774371039482856

Epoch: 5| Step: 3
Training loss: 2.5578017234802246
Validation loss: 2.4935445362521755

Epoch: 5| Step: 4
Training loss: 2.056318998336792
Validation loss: 2.4798510459161576

Epoch: 5| Step: 5
Training loss: 2.7004482746124268
Validation loss: 2.467126484840147

Epoch: 5| Step: 6
Training loss: 3.0263848304748535
Validation loss: 2.4611570988931963

Epoch: 5| Step: 7
Training loss: 2.4656968116760254
Validation loss: 2.458483977984357

Epoch: 5| Step: 8
Training loss: 2.23290753364563
Validation loss: 2.4520322020335863

Epoch: 5| Step: 9
Training loss: 3.178051233291626
Validation loss: 2.455005638061031

Epoch: 5| Step: 10
Training loss: 2.7419111728668213
Validation loss: 2.46049181876644

Epoch: 117| Step: 0
Training loss: 2.3269801139831543
Validation loss: 2.468785842259725

Epoch: 5| Step: 1
Training loss: 3.2568535804748535
Validation loss: 2.4853390468064176

Epoch: 5| Step: 2
Training loss: 2.407510280609131
Validation loss: 2.485383105534379

Epoch: 5| Step: 3
Training loss: 2.4040093421936035
Validation loss: 2.4845045997250463

Epoch: 5| Step: 4
Training loss: 3.019857883453369
Validation loss: 2.493704531782417

Epoch: 5| Step: 5
Training loss: 2.8194468021392822
Validation loss: 2.4756340339619625

Epoch: 5| Step: 6
Training loss: 2.566866159439087
Validation loss: 2.4617294470469155

Epoch: 5| Step: 7
Training loss: 2.4741203784942627
Validation loss: 2.4587822319358907

Epoch: 5| Step: 8
Training loss: 2.803915500640869
Validation loss: 2.459357992295296

Epoch: 5| Step: 9
Training loss: 2.520887851715088
Validation loss: 2.465549176739108

Epoch: 5| Step: 10
Training loss: 2.9247355461120605
Validation loss: 2.4689412527186896

Epoch: 118| Step: 0
Training loss: 2.4981868267059326
Validation loss: 2.471029107288648

Epoch: 5| Step: 1
Training loss: 3.1840267181396484
Validation loss: 2.469407932732695

Epoch: 5| Step: 2
Training loss: 3.0248072147369385
Validation loss: 2.463975747426351

Epoch: 5| Step: 3
Training loss: 3.0900113582611084
Validation loss: 2.4658827704768025

Epoch: 5| Step: 4
Training loss: 2.555479049682617
Validation loss: 2.4726776563993065

Epoch: 5| Step: 5
Training loss: 2.003645420074463
Validation loss: 2.47369211207154

Epoch: 5| Step: 6
Training loss: 3.0127875804901123
Validation loss: 2.476899053460808

Epoch: 5| Step: 7
Training loss: 2.212263345718384
Validation loss: 2.4785812618911907

Epoch: 5| Step: 8
Training loss: 2.638453483581543
Validation loss: 2.490467212533438

Epoch: 5| Step: 9
Training loss: 2.9792771339416504
Validation loss: 2.4748891143388647

Epoch: 5| Step: 10
Training loss: 2.066896438598633
Validation loss: 2.4656368455579205

Epoch: 119| Step: 0
Training loss: 2.467737913131714
Validation loss: 2.451837279463327

Epoch: 5| Step: 1
Training loss: 2.7046446800231934
Validation loss: 2.4517799346677718

Epoch: 5| Step: 2
Training loss: 3.01529598236084
Validation loss: 2.449616370662566

Epoch: 5| Step: 3
Training loss: 2.7444968223571777
Validation loss: 2.450407812672277

Epoch: 5| Step: 4
Training loss: 2.8441836833953857
Validation loss: 2.4528896731715046

Epoch: 5| Step: 5
Training loss: 3.0647969245910645
Validation loss: 2.4566824282369306

Epoch: 5| Step: 6
Training loss: 2.5441555976867676
Validation loss: 2.454427037187802

Epoch: 5| Step: 7
Training loss: 1.5180479288101196
Validation loss: 2.453774829064646

Epoch: 5| Step: 8
Training loss: 3.0327377319335938
Validation loss: 2.454556054966424

Epoch: 5| Step: 9
Training loss: 2.595080614089966
Validation loss: 2.458313690718784

Epoch: 5| Step: 10
Training loss: 2.8472278118133545
Validation loss: 2.4620085249664965

Epoch: 120| Step: 0
Training loss: 2.565004825592041
Validation loss: 2.452330555967105

Epoch: 5| Step: 1
Training loss: 2.471865177154541
Validation loss: 2.453917923793998

Epoch: 5| Step: 2
Training loss: 2.8129303455352783
Validation loss: 2.450728702288802

Epoch: 5| Step: 3
Training loss: 2.953368663787842
Validation loss: 2.4485112390210553

Epoch: 5| Step: 4
Training loss: 2.5027079582214355
Validation loss: 2.4474125344266175

Epoch: 5| Step: 5
Training loss: 2.9834280014038086
Validation loss: 2.4493851533500095

Epoch: 5| Step: 6
Training loss: 2.486203193664551
Validation loss: 2.444690763309438

Epoch: 5| Step: 7
Training loss: 2.49932599067688
Validation loss: 2.445147350270261

Epoch: 5| Step: 8
Training loss: 2.886868715286255
Validation loss: 2.444229381058806

Epoch: 5| Step: 9
Training loss: 2.278733730316162
Validation loss: 2.4483720179527038

Epoch: 5| Step: 10
Training loss: 2.872762680053711
Validation loss: 2.451456457056025

Epoch: 121| Step: 0
Training loss: 2.933598041534424
Validation loss: 2.4695746898651123

Epoch: 5| Step: 1
Training loss: 2.4818313121795654
Validation loss: 2.4658615819869505

Epoch: 5| Step: 2
Training loss: 1.9317348003387451
Validation loss: 2.485694936526719

Epoch: 5| Step: 3
Training loss: 2.9300754070281982
Validation loss: 2.478438469671434

Epoch: 5| Step: 4
Training loss: 2.9240684509277344
Validation loss: 2.476001580556234

Epoch: 5| Step: 5
Training loss: 2.6535990238189697
Validation loss: 2.4654034158234954

Epoch: 5| Step: 6
Training loss: 2.320233106613159
Validation loss: 2.4534386383589877

Epoch: 5| Step: 7
Training loss: 2.3173880577087402
Validation loss: 2.458052240392213

Epoch: 5| Step: 8
Training loss: 2.8860723972320557
Validation loss: 2.4627485762360277

Epoch: 5| Step: 9
Training loss: 3.272775173187256
Validation loss: 2.4629858873223744

Epoch: 5| Step: 10
Training loss: 2.6163973808288574
Validation loss: 2.462644494989867

Epoch: 122| Step: 0
Training loss: 1.8844980001449585
Validation loss: 2.461455427190309

Epoch: 5| Step: 1
Training loss: 2.0014102458953857
Validation loss: 2.454441842212472

Epoch: 5| Step: 2
Training loss: 3.3138091564178467
Validation loss: 2.454797655023554

Epoch: 5| Step: 3
Training loss: 2.6823277473449707
Validation loss: 2.453289924129363

Epoch: 5| Step: 4
Training loss: 2.6362438201904297
Validation loss: 2.452811610314154

Epoch: 5| Step: 5
Training loss: 3.333834171295166
Validation loss: 2.447560989728538

Epoch: 5| Step: 6
Training loss: 2.899080753326416
Validation loss: 2.45773979156248

Epoch: 5| Step: 7
Training loss: 2.9955952167510986
Validation loss: 2.462661135581232

Epoch: 5| Step: 8
Training loss: 2.529693365097046
Validation loss: 2.4698375527576735

Epoch: 5| Step: 9
Training loss: 2.263533115386963
Validation loss: 2.4769108987623647

Epoch: 5| Step: 10
Training loss: 2.557835102081299
Validation loss: 2.470037216781288

Epoch: 123| Step: 0
Training loss: 1.9187662601470947
Validation loss: 2.471188291426628

Epoch: 5| Step: 1
Training loss: 2.7070765495300293
Validation loss: 2.473589740773683

Epoch: 5| Step: 2
Training loss: 2.7371115684509277
Validation loss: 2.471841363496678

Epoch: 5| Step: 3
Training loss: 2.308610439300537
Validation loss: 2.4720938436446653

Epoch: 5| Step: 4
Training loss: 3.2284538745880127
Validation loss: 2.4657536527161956

Epoch: 5| Step: 5
Training loss: 2.9541430473327637
Validation loss: 2.461830028923609

Epoch: 5| Step: 6
Training loss: 3.015364170074463
Validation loss: 2.4455933442679783

Epoch: 5| Step: 7
Training loss: 2.2013416290283203
Validation loss: 2.441191857860934

Epoch: 5| Step: 8
Training loss: 2.7134592533111572
Validation loss: 2.4415488755831154

Epoch: 5| Step: 9
Training loss: 2.3442776203155518
Validation loss: 2.449466920668079

Epoch: 5| Step: 10
Training loss: 3.1289546489715576
Validation loss: 2.4410604969147713

Epoch: 124| Step: 0
Training loss: 3.0643889904022217
Validation loss: 2.448299600232032

Epoch: 5| Step: 1
Training loss: 2.748077154159546
Validation loss: 2.44189420823128

Epoch: 5| Step: 2
Training loss: 2.1650145053863525
Validation loss: 2.450155314578805

Epoch: 5| Step: 3
Training loss: 3.4723057746887207
Validation loss: 2.4502390764092885

Epoch: 5| Step: 4
Training loss: 3.07025146484375
Validation loss: 2.457977666649767

Epoch: 5| Step: 5
Training loss: 2.4828574657440186
Validation loss: 2.456942294233589

Epoch: 5| Step: 6
Training loss: 2.8040308952331543
Validation loss: 2.448438393172397

Epoch: 5| Step: 7
Training loss: 2.6700825691223145
Validation loss: 2.4403946681689193

Epoch: 5| Step: 8
Training loss: 1.868389368057251
Validation loss: 2.442016919453939

Epoch: 5| Step: 9
Training loss: 2.418578863143921
Validation loss: 2.4507714779146257

Epoch: 5| Step: 10
Training loss: 2.2318899631500244
Validation loss: 2.450328332121654

Epoch: 125| Step: 0
Training loss: 3.3615455627441406
Validation loss: 2.4423404432112172

Epoch: 5| Step: 1
Training loss: 2.2845802307128906
Validation loss: 2.4413392389974287

Epoch: 5| Step: 2
Training loss: 2.593165159225464
Validation loss: 2.449519213809762

Epoch: 5| Step: 3
Training loss: 3.1277718544006348
Validation loss: 2.4636317786350044

Epoch: 5| Step: 4
Training loss: 2.621466875076294
Validation loss: 2.474717455525552

Epoch: 5| Step: 5
Training loss: 2.373838424682617
Validation loss: 2.479686267914311

Epoch: 5| Step: 6
Training loss: 2.6665382385253906
Validation loss: 2.479615613978396

Epoch: 5| Step: 7
Training loss: 2.3953781127929688
Validation loss: 2.4585228402127504

Epoch: 5| Step: 8
Training loss: 2.5267961025238037
Validation loss: 2.441863239452403

Epoch: 5| Step: 9
Training loss: 1.9041149616241455
Validation loss: 2.441395887764551

Epoch: 5| Step: 10
Training loss: 3.374459981918335
Validation loss: 2.4377383955063356

Epoch: 126| Step: 0
Training loss: 2.7054476737976074
Validation loss: 2.444106435263029

Epoch: 5| Step: 1
Training loss: 3.1462454795837402
Validation loss: 2.4505848987128145

Epoch: 5| Step: 2
Training loss: 3.2015461921691895
Validation loss: 2.4486144563203216

Epoch: 5| Step: 3
Training loss: 2.512094497680664
Validation loss: 2.4489686335286787

Epoch: 5| Step: 4
Training loss: 2.4619944095611572
Validation loss: 2.4465786462189048

Epoch: 5| Step: 5
Training loss: 3.3353333473205566
Validation loss: 2.4476594719835507

Epoch: 5| Step: 6
Training loss: 1.9224348068237305
Validation loss: 2.4428430911033385

Epoch: 5| Step: 7
Training loss: 2.611523389816284
Validation loss: 2.4448231086936048

Epoch: 5| Step: 8
Training loss: 2.697054147720337
Validation loss: 2.4384663105010986

Epoch: 5| Step: 9
Training loss: 2.5362071990966797
Validation loss: 2.4481834621839624

Epoch: 5| Step: 10
Training loss: 1.9245531558990479
Validation loss: 2.4429530020683043

Epoch: 127| Step: 0
Training loss: 2.7699027061462402
Validation loss: 2.4560113594096196

Epoch: 5| Step: 1
Training loss: 2.2508909702301025
Validation loss: 2.4646845530438166

Epoch: 5| Step: 2
Training loss: 3.2913482189178467
Validation loss: 2.4928160021381993

Epoch: 5| Step: 3
Training loss: 2.1683406829833984
Validation loss: 2.4987708137881373

Epoch: 5| Step: 4
Training loss: 2.853285551071167
Validation loss: 2.4785700664725354

Epoch: 5| Step: 5
Training loss: 1.7144721746444702
Validation loss: 2.469311709045082

Epoch: 5| Step: 6
Training loss: 3.3897223472595215
Validation loss: 2.4674445621428953

Epoch: 5| Step: 7
Training loss: 2.933929443359375
Validation loss: 2.450718169571251

Epoch: 5| Step: 8
Training loss: 2.2845230102539062
Validation loss: 2.4314737717310586

Epoch: 5| Step: 9
Training loss: 2.960019111633301
Validation loss: 2.4425897213720504

Epoch: 5| Step: 10
Training loss: 2.5108323097229004
Validation loss: 2.44331580720922

Epoch: 128| Step: 0
Training loss: 2.834078311920166
Validation loss: 2.444425339339882

Epoch: 5| Step: 1
Training loss: 2.8557381629943848
Validation loss: 2.44294899253435

Epoch: 5| Step: 2
Training loss: 3.053071975708008
Validation loss: 2.4400345228051625

Epoch: 5| Step: 3
Training loss: 2.4839515686035156
Validation loss: 2.443358193161667

Epoch: 5| Step: 4
Training loss: 2.625580310821533
Validation loss: 2.4467146165909304

Epoch: 5| Step: 5
Training loss: 2.260070323944092
Validation loss: 2.4438064175267376

Epoch: 5| Step: 6
Training loss: 2.6526238918304443
Validation loss: 2.440507156874544

Epoch: 5| Step: 7
Training loss: 2.840440273284912
Validation loss: 2.443955465029645

Epoch: 5| Step: 8
Training loss: 2.919581174850464
Validation loss: 2.440252322022633

Epoch: 5| Step: 9
Training loss: 2.3127543926239014
Validation loss: 2.43539668667701

Epoch: 5| Step: 10
Training loss: 2.2818353176116943
Validation loss: 2.4398193051738124

Epoch: 129| Step: 0
Training loss: 2.594364881515503
Validation loss: 2.443927618765062

Epoch: 5| Step: 1
Training loss: 2.819838285446167
Validation loss: 2.4443562543520363

Epoch: 5| Step: 2
Training loss: 3.2645645141601562
Validation loss: 2.460175603948614

Epoch: 5| Step: 3
Training loss: 2.274199962615967
Validation loss: 2.467586809589017

Epoch: 5| Step: 4
Training loss: 1.7518682479858398
Validation loss: 2.461841578124672

Epoch: 5| Step: 5
Training loss: 3.127411365509033
Validation loss: 2.4568256716574393

Epoch: 5| Step: 6
Training loss: 3.405216693878174
Validation loss: 2.4483229549982215

Epoch: 5| Step: 7
Training loss: 2.8928418159484863
Validation loss: 2.439373485503658

Epoch: 5| Step: 8
Training loss: 2.8715522289276123
Validation loss: 2.439894591608355

Epoch: 5| Step: 9
Training loss: 1.9391653537750244
Validation loss: 2.4294836392966648

Epoch: 5| Step: 10
Training loss: 2.1023120880126953
Validation loss: 2.432840097335077

Epoch: 130| Step: 0
Training loss: 2.566488742828369
Validation loss: 2.4386055187512468

Epoch: 5| Step: 1
Training loss: 2.230135679244995
Validation loss: 2.4398260244759182

Epoch: 5| Step: 2
Training loss: 2.520786762237549
Validation loss: 2.4381428867258053

Epoch: 5| Step: 3
Training loss: 2.7865424156188965
Validation loss: 2.443746574463383

Epoch: 5| Step: 4
Training loss: 2.7993149757385254
Validation loss: 2.45692414622153

Epoch: 5| Step: 5
Training loss: 2.7797577381134033
Validation loss: 2.455827333593881

Epoch: 5| Step: 6
Training loss: 2.5349273681640625
Validation loss: 2.4582225866215204

Epoch: 5| Step: 7
Training loss: 2.943281888961792
Validation loss: 2.4723076230736187

Epoch: 5| Step: 8
Training loss: 1.9074602127075195
Validation loss: 2.464162493264803

Epoch: 5| Step: 9
Training loss: 3.4085750579833984
Validation loss: 2.460912360939928

Epoch: 5| Step: 10
Training loss: 2.601773977279663
Validation loss: 2.4522745711829073

Epoch: 131| Step: 0
Training loss: 2.818221092224121
Validation loss: 2.44574712937878

Epoch: 5| Step: 1
Training loss: 3.1173062324523926
Validation loss: 2.4333829136304956

Epoch: 5| Step: 2
Training loss: 2.6898903846740723
Validation loss: 2.4355417810460573

Epoch: 5| Step: 3
Training loss: 3.416961669921875
Validation loss: 2.4310668847894155

Epoch: 5| Step: 4
Training loss: 2.383507490158081
Validation loss: 2.434818942059753

Epoch: 5| Step: 5
Training loss: 2.066382646560669
Validation loss: 2.432165766275057

Epoch: 5| Step: 6
Training loss: 1.4357656240463257
Validation loss: 2.4346153864296536

Epoch: 5| Step: 7
Training loss: 3.323113203048706
Validation loss: 2.430745904163648

Epoch: 5| Step: 8
Training loss: 2.6634087562561035
Validation loss: 2.4324137215973227

Epoch: 5| Step: 9
Training loss: 2.2124686241149902
Validation loss: 2.4319771797426286

Epoch: 5| Step: 10
Training loss: 2.8976519107818604
Validation loss: 2.4295547854515815

Epoch: 132| Step: 0
Training loss: 2.28743052482605
Validation loss: 2.4303244685613983

Epoch: 5| Step: 1
Training loss: 3.2068424224853516
Validation loss: 2.4317930770176712

Epoch: 5| Step: 2
Training loss: 3.2229843139648438
Validation loss: 2.436967288294146

Epoch: 5| Step: 3
Training loss: 2.2692668437957764
Validation loss: 2.4290657171639065

Epoch: 5| Step: 4
Training loss: 1.687146544456482
Validation loss: 2.4287442776464645

Epoch: 5| Step: 5
Training loss: 3.2418105602264404
Validation loss: 2.422317848410658

Epoch: 5| Step: 6
Training loss: 2.3319132328033447
Validation loss: 2.425218515498664

Epoch: 5| Step: 7
Training loss: 2.788147449493408
Validation loss: 2.422722888249223

Epoch: 5| Step: 8
Training loss: 2.647198438644409
Validation loss: 2.4249254093375257

Epoch: 5| Step: 9
Training loss: 2.2254154682159424
Validation loss: 2.4313183574266333

Epoch: 5| Step: 10
Training loss: 3.1016290187835693
Validation loss: 2.4320116555818947

Epoch: 133| Step: 0
Training loss: 3.148071527481079
Validation loss: 2.433719068445185

Epoch: 5| Step: 1
Training loss: 2.2861616611480713
Validation loss: 2.4330287646221858

Epoch: 5| Step: 2
Training loss: 2.620466947555542
Validation loss: 2.4313522897740847

Epoch: 5| Step: 3
Training loss: 2.834596872329712
Validation loss: 2.4357378559727825

Epoch: 5| Step: 4
Training loss: 2.9885010719299316
Validation loss: 2.4303376777197725

Epoch: 5| Step: 5
Training loss: 2.9121181964874268
Validation loss: 2.4290849918960244

Epoch: 5| Step: 6
Training loss: 2.5717785358428955
Validation loss: 2.4330699982181674

Epoch: 5| Step: 7
Training loss: 2.1135449409484863
Validation loss: 2.429559400004725

Epoch: 5| Step: 8
Training loss: 2.857680559158325
Validation loss: 2.4334378396311114

Epoch: 5| Step: 9
Training loss: 2.6479806900024414
Validation loss: 2.430721822605338

Epoch: 5| Step: 10
Training loss: 1.9373812675476074
Validation loss: 2.4272905754786667

Epoch: 134| Step: 0
Training loss: 2.5892796516418457
Validation loss: 2.42338207972947

Epoch: 5| Step: 1
Training loss: 1.4488002061843872
Validation loss: 2.4214224917914278

Epoch: 5| Step: 2
Training loss: 2.5197625160217285
Validation loss: 2.424874269834129

Epoch: 5| Step: 3
Training loss: 2.4847493171691895
Validation loss: 2.424690261963875

Epoch: 5| Step: 4
Training loss: 2.521454095840454
Validation loss: 2.4364344202062136

Epoch: 5| Step: 5
Training loss: 2.8690311908721924
Validation loss: 2.4330092937715593

Epoch: 5| Step: 6
Training loss: 2.907566547393799
Validation loss: 2.435519431226997

Epoch: 5| Step: 7
Training loss: 3.6572723388671875
Validation loss: 2.4381503802473827

Epoch: 5| Step: 8
Training loss: 2.4162585735321045
Validation loss: 2.4369846390139673

Epoch: 5| Step: 9
Training loss: 2.9540562629699707
Validation loss: 2.429284208564348

Epoch: 5| Step: 10
Training loss: 2.456404209136963
Validation loss: 2.4356939292723134

Epoch: 135| Step: 0
Training loss: 3.0357825756073
Validation loss: 2.4321296830331125

Epoch: 5| Step: 1
Training loss: 2.4539403915405273
Validation loss: 2.434967766525925

Epoch: 5| Step: 2
Training loss: 2.423696994781494
Validation loss: 2.4494139225252214

Epoch: 5| Step: 3
Training loss: 2.2327053546905518
Validation loss: 2.456732761475348

Epoch: 5| Step: 4
Training loss: 2.7838737964630127
Validation loss: 2.4507858932659192

Epoch: 5| Step: 5
Training loss: 2.5116562843322754
Validation loss: 2.4413249082462762

Epoch: 5| Step: 6
Training loss: 2.593081474304199
Validation loss: 2.4279936129047024

Epoch: 5| Step: 7
Training loss: 2.582383155822754
Validation loss: 2.4217502583739576

Epoch: 5| Step: 8
Training loss: 2.7794487476348877
Validation loss: 2.4235035116954515

Epoch: 5| Step: 9
Training loss: 2.0885980129241943
Validation loss: 2.4317787296028546

Epoch: 5| Step: 10
Training loss: 3.561918020248413
Validation loss: 2.434150436873077

Epoch: 136| Step: 0
Training loss: 2.8603081703186035
Validation loss: 2.428366122707244

Epoch: 5| Step: 1
Training loss: 2.3928146362304688
Validation loss: 2.4205514846309537

Epoch: 5| Step: 2
Training loss: 2.994847536087036
Validation loss: 2.4158569843538347

Epoch: 5| Step: 3
Training loss: 2.6163806915283203
Validation loss: 2.411037721941548

Epoch: 5| Step: 4
Training loss: 2.8380346298217773
Validation loss: 2.4139395759951685

Epoch: 5| Step: 5
Training loss: 1.652620553970337
Validation loss: 2.4247180454192625

Epoch: 5| Step: 6
Training loss: 2.561849594116211
Validation loss: 2.440748264712672

Epoch: 5| Step: 7
Training loss: 3.1344103813171387
Validation loss: 2.4378692873062624

Epoch: 5| Step: 8
Training loss: 2.7132256031036377
Validation loss: 2.430064624355685

Epoch: 5| Step: 9
Training loss: 2.423499345779419
Validation loss: 2.420368348398516

Epoch: 5| Step: 10
Training loss: 2.8116400241851807
Validation loss: 2.420018314033426

Epoch: 137| Step: 0
Training loss: 2.765749454498291
Validation loss: 2.4175221843104207

Epoch: 5| Step: 1
Training loss: 2.7569358348846436
Validation loss: 2.4074446616634244

Epoch: 5| Step: 2
Training loss: 2.6636650562286377
Validation loss: 2.408349984435625

Epoch: 5| Step: 3
Training loss: 2.529423236846924
Validation loss: 2.4079924655216995

Epoch: 5| Step: 4
Training loss: 2.4094784259796143
Validation loss: 2.40489209851911

Epoch: 5| Step: 5
Training loss: 2.768496036529541
Validation loss: 2.4060485657825263

Epoch: 5| Step: 6
Training loss: 2.360602617263794
Validation loss: 2.4065045951515116

Epoch: 5| Step: 7
Training loss: 2.9699110984802246
Validation loss: 2.4022844914467103

Epoch: 5| Step: 8
Training loss: 2.7221221923828125
Validation loss: 2.406819212821222

Epoch: 5| Step: 9
Training loss: 2.3206448554992676
Validation loss: 2.4045775628859

Epoch: 5| Step: 10
Training loss: 2.617750644683838
Validation loss: 2.407988944361287

Epoch: 138| Step: 0
Training loss: 2.9823460578918457
Validation loss: 2.411523490823725

Epoch: 5| Step: 1
Training loss: 3.271130323410034
Validation loss: 2.4115580204994447

Epoch: 5| Step: 2
Training loss: 2.2098464965820312
Validation loss: 2.4133460393515964

Epoch: 5| Step: 3
Training loss: 2.945493221282959
Validation loss: 2.409693520556214

Epoch: 5| Step: 4
Training loss: 2.6971306800842285
Validation loss: 2.4226871498169436

Epoch: 5| Step: 5
Training loss: 3.4158082008361816
Validation loss: 2.4213388325065694

Epoch: 5| Step: 6
Training loss: 1.975325584411621
Validation loss: 2.422870156585529

Epoch: 5| Step: 7
Training loss: 2.63219952583313
Validation loss: 2.4312543869018555

Epoch: 5| Step: 8
Training loss: 2.4901320934295654
Validation loss: 2.427273517013878

Epoch: 5| Step: 9
Training loss: 1.4936867952346802
Validation loss: 2.4297609380496445

Epoch: 5| Step: 10
Training loss: 2.710475206375122
Validation loss: 2.4267082406628515

Epoch: 139| Step: 0
Training loss: 2.7337124347686768
Validation loss: 2.4194543028390534

Epoch: 5| Step: 1
Training loss: 2.9720616340637207
Validation loss: 2.41747038338774

Epoch: 5| Step: 2
Training loss: 2.979743003845215
Validation loss: 2.425423260658018

Epoch: 5| Step: 3
Training loss: 2.2084901332855225
Validation loss: 2.42832637089555

Epoch: 5| Step: 4
Training loss: 2.2369768619537354
Validation loss: 2.4330567929052536

Epoch: 5| Step: 5
Training loss: 2.186964511871338
Validation loss: 2.4352270890307683

Epoch: 5| Step: 6
Training loss: 2.4326884746551514
Validation loss: 2.433361678995112

Epoch: 5| Step: 7
Training loss: 2.9154741764068604
Validation loss: 2.4241807588966946

Epoch: 5| Step: 8
Training loss: 2.2700345516204834
Validation loss: 2.417572788012925

Epoch: 5| Step: 9
Training loss: 3.1519737243652344
Validation loss: 2.4160245669785367

Epoch: 5| Step: 10
Training loss: 2.874886989593506
Validation loss: 2.4249885364245345

Epoch: 140| Step: 0
Training loss: 2.1172947883605957
Validation loss: 2.4424837097044914

Epoch: 5| Step: 1
Training loss: 2.8178391456604004
Validation loss: 2.4596764349168345

Epoch: 5| Step: 2
Training loss: 2.394775867462158
Validation loss: 2.475819164706815

Epoch: 5| Step: 3
Training loss: 3.8720459938049316
Validation loss: 2.488546238150648

Epoch: 5| Step: 4
Training loss: 1.8408756256103516
Validation loss: 2.4796667329726683

Epoch: 5| Step: 5
Training loss: 2.5572855472564697
Validation loss: 2.447617253949565

Epoch: 5| Step: 6
Training loss: 2.6888694763183594
Validation loss: 2.4314509540475826

Epoch: 5| Step: 7
Training loss: 2.731271266937256
Validation loss: 2.405914819368752

Epoch: 5| Step: 8
Training loss: 3.091334104537964
Validation loss: 2.4011643343074347

Epoch: 5| Step: 9
Training loss: 2.8538331985473633
Validation loss: 2.4016703803052186

Epoch: 5| Step: 10
Training loss: 1.924546241760254
Validation loss: 2.4055311474748837

Epoch: 141| Step: 0
Training loss: 2.9950242042541504
Validation loss: 2.412613353421611

Epoch: 5| Step: 1
Training loss: 1.8896143436431885
Validation loss: 2.406283373473793

Epoch: 5| Step: 2
Training loss: 2.208646059036255
Validation loss: 2.4089629650115967

Epoch: 5| Step: 3
Training loss: 3.3086228370666504
Validation loss: 2.40951479634931

Epoch: 5| Step: 4
Training loss: 2.5425896644592285
Validation loss: 2.408010187969413

Epoch: 5| Step: 5
Training loss: 2.512209892272949
Validation loss: 2.419286286959084

Epoch: 5| Step: 6
Training loss: 3.1879560947418213
Validation loss: 2.423600176329254

Epoch: 5| Step: 7
Training loss: 2.717316150665283
Validation loss: 2.425648299596643

Epoch: 5| Step: 8
Training loss: 2.8191707134246826
Validation loss: 2.429346510159072

Epoch: 5| Step: 9
Training loss: 2.492344617843628
Validation loss: 2.4249511457258657

Epoch: 5| Step: 10
Training loss: 1.9765764474868774
Validation loss: 2.429748083955498

Epoch: 142| Step: 0
Training loss: 2.3837244510650635
Validation loss: 2.4218506351594002

Epoch: 5| Step: 1
Training loss: 2.7896742820739746
Validation loss: 2.417173271538109

Epoch: 5| Step: 2
Training loss: 2.1011290550231934
Validation loss: 2.4174131372923493

Epoch: 5| Step: 3
Training loss: 2.6781394481658936
Validation loss: 2.4137849346283944

Epoch: 5| Step: 4
Training loss: 3.3914942741394043
Validation loss: 2.4062259581781205

Epoch: 5| Step: 5
Training loss: 2.6544029712677
Validation loss: 2.4137869111953245

Epoch: 5| Step: 6
Training loss: 2.6939783096313477
Validation loss: 2.4176126872339556

Epoch: 5| Step: 7
Training loss: 2.4176478385925293
Validation loss: 2.40358055022455

Epoch: 5| Step: 8
Training loss: 2.799423933029175
Validation loss: 2.41274550525091

Epoch: 5| Step: 9
Training loss: 2.6196117401123047
Validation loss: 2.398762136377314

Epoch: 5| Step: 10
Training loss: 2.0728847980499268
Validation loss: 2.4092341135906916

Epoch: 143| Step: 0
Training loss: 2.4883992671966553
Validation loss: 2.402590333774526

Epoch: 5| Step: 1
Training loss: 2.4636733531951904
Validation loss: 2.4006646115292787

Epoch: 5| Step: 2
Training loss: 2.562927007675171
Validation loss: 2.404582751694546

Epoch: 5| Step: 3
Training loss: 3.082602024078369
Validation loss: 2.409473293571062

Epoch: 5| Step: 4
Training loss: 2.109065294265747
Validation loss: 2.413474803329796

Epoch: 5| Step: 5
Training loss: 2.595902681350708
Validation loss: 2.412534534290273

Epoch: 5| Step: 6
Training loss: 3.1076416969299316
Validation loss: 2.4104067663992605

Epoch: 5| Step: 7
Training loss: 2.5708696842193604
Validation loss: 2.409521710488104

Epoch: 5| Step: 8
Training loss: 2.949676275253296
Validation loss: 2.407107996684249

Epoch: 5| Step: 9
Training loss: 2.3366007804870605
Validation loss: 2.412668328131399

Epoch: 5| Step: 10
Training loss: 2.4518611431121826
Validation loss: 2.406261351800734

Epoch: 144| Step: 0
Training loss: 2.3732895851135254
Validation loss: 2.410119628393522

Epoch: 5| Step: 1
Training loss: 2.6744279861450195
Validation loss: 2.4178199511702343

Epoch: 5| Step: 2
Training loss: 2.842566967010498
Validation loss: 2.426704857939033

Epoch: 5| Step: 3
Training loss: 2.401136875152588
Validation loss: 2.428052589457522

Epoch: 5| Step: 4
Training loss: 2.610016107559204
Validation loss: 2.4306843921702397

Epoch: 5| Step: 5
Training loss: 2.683650016784668
Validation loss: 2.4274063969171173

Epoch: 5| Step: 6
Training loss: 2.7378487586975098
Validation loss: 2.422170139128162

Epoch: 5| Step: 7
Training loss: 2.5700974464416504
Validation loss: 2.417231382862214

Epoch: 5| Step: 8
Training loss: 2.2130379676818848
Validation loss: 2.4141508199835338

Epoch: 5| Step: 9
Training loss: 2.9898815155029297
Validation loss: 2.413610273791898

Epoch: 5| Step: 10
Training loss: 2.616058826446533
Validation loss: 2.410343175293297

Epoch: 145| Step: 0
Training loss: 2.432237148284912
Validation loss: 2.401079302193016

Epoch: 5| Step: 1
Training loss: 1.9578492641448975
Validation loss: 2.406485229410151

Epoch: 5| Step: 2
Training loss: 2.7568602561950684
Validation loss: 2.4154722664945867

Epoch: 5| Step: 3
Training loss: 3.086392641067505
Validation loss: 2.4132609751916703

Epoch: 5| Step: 4
Training loss: 1.962572455406189
Validation loss: 2.4172609852206324

Epoch: 5| Step: 5
Training loss: 2.907905101776123
Validation loss: 2.4164734399446877

Epoch: 5| Step: 6
Training loss: 3.2554047107696533
Validation loss: 2.435709934080801

Epoch: 5| Step: 7
Training loss: 2.9305813312530518
Validation loss: 2.4310227722250004

Epoch: 5| Step: 8
Training loss: 1.6898982524871826
Validation loss: 2.4209779641961537

Epoch: 5| Step: 9
Training loss: 2.904263734817505
Validation loss: 2.417455727054227

Epoch: 5| Step: 10
Training loss: 2.851522207260132
Validation loss: 2.405305939335977

Epoch: 146| Step: 0
Training loss: 2.396097183227539
Validation loss: 2.40807169483554

Epoch: 5| Step: 1
Training loss: 2.3621726036071777
Validation loss: 2.392738567885532

Epoch: 5| Step: 2
Training loss: 2.7411608695983887
Validation loss: 2.396316343738187

Epoch: 5| Step: 3
Training loss: 2.7926993370056152
Validation loss: 2.4007747096400105

Epoch: 5| Step: 4
Training loss: 3.227679491043091
Validation loss: 2.4003367270192792

Epoch: 5| Step: 5
Training loss: 2.4328930377960205
Validation loss: 2.4017751780889367

Epoch: 5| Step: 6
Training loss: 1.9890632629394531
Validation loss: 2.3996668951485747

Epoch: 5| Step: 7
Training loss: 3.177466869354248
Validation loss: 2.3982965228378132

Epoch: 5| Step: 8
Training loss: 2.056455612182617
Validation loss: 2.3925079709740094

Epoch: 5| Step: 9
Training loss: 3.047257900238037
Validation loss: 2.397676226913288

Epoch: 5| Step: 10
Training loss: 2.395341396331787
Validation loss: 2.3971043709785707

Epoch: 147| Step: 0
Training loss: 2.805220365524292
Validation loss: 2.399593904454221

Epoch: 5| Step: 1
Training loss: 2.8950042724609375
Validation loss: 2.4037836649084605

Epoch: 5| Step: 2
Training loss: 2.5822834968566895
Validation loss: 2.41226517000506

Epoch: 5| Step: 3
Training loss: 2.46610951423645
Validation loss: 2.404522301048361

Epoch: 5| Step: 4
Training loss: 2.418052911758423
Validation loss: 2.4099139269962104

Epoch: 5| Step: 5
Training loss: 2.364943027496338
Validation loss: 2.411689576282296

Epoch: 5| Step: 6
Training loss: 2.6563541889190674
Validation loss: 2.4180866313237015

Epoch: 5| Step: 7
Training loss: 2.695495367050171
Validation loss: 2.4342638061892603

Epoch: 5| Step: 8
Training loss: 2.944031000137329
Validation loss: 2.45341646030385

Epoch: 5| Step: 9
Training loss: 1.8740432262420654
Validation loss: 2.447722073524229

Epoch: 5| Step: 10
Training loss: 3.099412441253662
Validation loss: 2.4588573158428235

Epoch: 148| Step: 0
Training loss: 2.23065185546875
Validation loss: 2.4277687303481565

Epoch: 5| Step: 1
Training loss: 2.370751142501831
Validation loss: 2.415500158904701

Epoch: 5| Step: 2
Training loss: 3.1140379905700684
Validation loss: 2.412827745560677

Epoch: 5| Step: 3
Training loss: 3.1438252925872803
Validation loss: 2.411586164146341

Epoch: 5| Step: 4
Training loss: 2.2273707389831543
Validation loss: 2.4160720917486374

Epoch: 5| Step: 5
Training loss: 1.781334638595581
Validation loss: 2.396664665591332

Epoch: 5| Step: 6
Training loss: 3.3382408618927
Validation loss: 2.400161417581702

Epoch: 5| Step: 7
Training loss: 2.5000290870666504
Validation loss: 2.3939976205107985

Epoch: 5| Step: 8
Training loss: 2.3287746906280518
Validation loss: 2.398180562962768

Epoch: 5| Step: 9
Training loss: 2.870957612991333
Validation loss: 2.3901999124916653

Epoch: 5| Step: 10
Training loss: 2.7072391510009766
Validation loss: 2.392711913713845

Epoch: 149| Step: 0
Training loss: 2.6646082401275635
Validation loss: 2.3998206123228996

Epoch: 5| Step: 1
Training loss: 2.2264795303344727
Validation loss: 2.397035014244818

Epoch: 5| Step: 2
Training loss: 3.0526161193847656
Validation loss: 2.4075930092924382

Epoch: 5| Step: 3
Training loss: 2.1580252647399902
Validation loss: 2.4144363095683437

Epoch: 5| Step: 4
Training loss: 2.532848834991455
Validation loss: 2.419656479230491

Epoch: 5| Step: 5
Training loss: 2.4144158363342285
Validation loss: 2.4271459220558085

Epoch: 5| Step: 6
Training loss: 2.138432502746582
Validation loss: 2.437263076023389

Epoch: 5| Step: 7
Training loss: 2.58176851272583
Validation loss: 2.439290585056428

Epoch: 5| Step: 8
Training loss: 3.2103874683380127
Validation loss: 2.441152580322758

Epoch: 5| Step: 9
Training loss: 2.7353649139404297
Validation loss: 2.4509300493424937

Epoch: 5| Step: 10
Training loss: 3.0365841388702393
Validation loss: 2.4600745272892777

Epoch: 150| Step: 0
Training loss: 3.1592278480529785
Validation loss: 2.458880668045372

Epoch: 5| Step: 1
Training loss: 2.247840166091919
Validation loss: 2.4326085095764487

Epoch: 5| Step: 2
Training loss: 2.8765475749969482
Validation loss: 2.4017064417562177

Epoch: 5| Step: 3
Training loss: 2.7311198711395264
Validation loss: 2.3892062479449856

Epoch: 5| Step: 4
Training loss: 2.709357976913452
Validation loss: 2.3828326040698635

Epoch: 5| Step: 5
Training loss: 2.924680709838867
Validation loss: 2.3985054031495125

Epoch: 5| Step: 6
Training loss: 1.989999771118164
Validation loss: 2.4125755833041285

Epoch: 5| Step: 7
Training loss: 2.824007987976074
Validation loss: 2.4078869640186267

Epoch: 5| Step: 8
Training loss: 2.2983317375183105
Validation loss: 2.3918843858985492

Epoch: 5| Step: 9
Training loss: 2.405547618865967
Validation loss: 2.3721982304767897

Epoch: 5| Step: 10
Training loss: 2.636376142501831
Validation loss: 2.3662768922826296

Epoch: 151| Step: 0
Training loss: 2.805764675140381
Validation loss: 2.390449872580908

Epoch: 5| Step: 1
Training loss: 2.1606879234313965
Validation loss: 2.394632042095225

Epoch: 5| Step: 2
Training loss: 2.0643320083618164
Validation loss: 2.413329703833467

Epoch: 5| Step: 3
Training loss: 2.479012966156006
Validation loss: 2.4511986958083285

Epoch: 5| Step: 4
Training loss: 3.8413665294647217
Validation loss: 2.4610341646338023

Epoch: 5| Step: 5
Training loss: 2.612464189529419
Validation loss: 2.4379157840564685

Epoch: 5| Step: 6
Training loss: 2.725324869155884
Validation loss: 2.405271791642712

Epoch: 5| Step: 7
Training loss: 2.4888482093811035
Validation loss: 2.3901728942830074

Epoch: 5| Step: 8
Training loss: 2.7059080600738525
Validation loss: 2.380759395578856

Epoch: 5| Step: 9
Training loss: 2.4197394847869873
Validation loss: 2.385972302447083

Epoch: 5| Step: 10
Training loss: 2.3452911376953125
Validation loss: 2.3968078782481532

Epoch: 152| Step: 0
Training loss: 2.2029225826263428
Validation loss: 2.4262106136609147

Epoch: 5| Step: 1
Training loss: 2.5197362899780273
Validation loss: 2.4512032257613314

Epoch: 5| Step: 2
Training loss: 2.846567153930664
Validation loss: 2.451795365220757

Epoch: 5| Step: 3
Training loss: 3.1646535396575928
Validation loss: 2.453597414878107

Epoch: 5| Step: 4
Training loss: 2.3680148124694824
Validation loss: 2.4228941637982606

Epoch: 5| Step: 5
Training loss: 2.315765857696533
Validation loss: 2.4183062327805387

Epoch: 5| Step: 6
Training loss: 2.882564067840576
Validation loss: 2.4050317348972445

Epoch: 5| Step: 7
Training loss: 2.3754758834838867
Validation loss: 2.407449588980726

Epoch: 5| Step: 8
Training loss: 2.648080825805664
Validation loss: 2.411290430253552

Epoch: 5| Step: 9
Training loss: 3.3892905712127686
Validation loss: 2.4105620127852245

Epoch: 5| Step: 10
Training loss: 1.9489517211914062
Validation loss: 2.410126616877894

Epoch: 153| Step: 0
Training loss: 2.918673038482666
Validation loss: 2.4034576210924374

Epoch: 5| Step: 1
Training loss: 2.8158485889434814
Validation loss: 2.3943298939735658

Epoch: 5| Step: 2
Training loss: 2.032686710357666
Validation loss: 2.3985627351268644

Epoch: 5| Step: 3
Training loss: 2.658885955810547
Validation loss: 2.3988410657452

Epoch: 5| Step: 4
Training loss: 2.573915958404541
Validation loss: 2.393200361600486

Epoch: 5| Step: 5
Training loss: 2.310969829559326
Validation loss: 2.392615477244059

Epoch: 5| Step: 6
Training loss: 3.379335403442383
Validation loss: 2.388283362952612

Epoch: 5| Step: 7
Training loss: 2.527139902114868
Validation loss: 2.390647378019107

Epoch: 5| Step: 8
Training loss: 2.199583053588867
Validation loss: 2.384327816706832

Epoch: 5| Step: 9
Training loss: 2.775559902191162
Validation loss: 2.3845639408275647

Epoch: 5| Step: 10
Training loss: 2.2492382526397705
Validation loss: 2.396069049835205

Epoch: 154| Step: 0
Training loss: 1.64699387550354
Validation loss: 2.4022401379000757

Epoch: 5| Step: 1
Training loss: 2.9990527629852295
Validation loss: 2.413463895038892

Epoch: 5| Step: 2
Training loss: 3.3908164501190186
Validation loss: 2.4177601209250827

Epoch: 5| Step: 3
Training loss: 2.5903496742248535
Validation loss: 2.41485434193765

Epoch: 5| Step: 4
Training loss: 2.662158966064453
Validation loss: 2.40525968100435

Epoch: 5| Step: 5
Training loss: 2.8858423233032227
Validation loss: 2.411093311925088

Epoch: 5| Step: 6
Training loss: 2.0837154388427734
Validation loss: 2.404378539772444

Epoch: 5| Step: 7
Training loss: 2.890014171600342
Validation loss: 2.4045091700810257

Epoch: 5| Step: 8
Training loss: 2.194133758544922
Validation loss: 2.4035340227106565

Epoch: 5| Step: 9
Training loss: 2.68267560005188
Validation loss: 2.4033206124459543

Epoch: 5| Step: 10
Training loss: 2.394599676132202
Validation loss: 2.402544447170791

Epoch: 155| Step: 0
Training loss: 2.859302282333374
Validation loss: 2.397841081824354

Epoch: 5| Step: 1
Training loss: 1.8859914541244507
Validation loss: 2.3988847001906364

Epoch: 5| Step: 2
Training loss: 2.6089394092559814
Validation loss: 2.3965396881103516

Epoch: 5| Step: 3
Training loss: 2.312363386154175
Validation loss: 2.390713163601455

Epoch: 5| Step: 4
Training loss: 2.6691532135009766
Validation loss: 2.3962107525076917

Epoch: 5| Step: 5
Training loss: 2.403367280960083
Validation loss: 2.403530033685828

Epoch: 5| Step: 6
Training loss: 3.097456216812134
Validation loss: 2.4078847362149145

Epoch: 5| Step: 7
Training loss: 2.7146363258361816
Validation loss: 2.41238736080867

Epoch: 5| Step: 8
Training loss: 2.5402655601501465
Validation loss: 2.435182668829477

Epoch: 5| Step: 9
Training loss: 2.7047035694122314
Validation loss: 2.4354292115857525

Epoch: 5| Step: 10
Training loss: 2.879591941833496
Validation loss: 2.4271877709255425

Epoch: 156| Step: 0
Training loss: 2.744607925415039
Validation loss: 2.3867561509532313

Epoch: 5| Step: 1
Training loss: 3.225506544113159
Validation loss: 2.3875232306859826

Epoch: 5| Step: 2
Training loss: 2.8429603576660156
Validation loss: 2.407410349897159

Epoch: 5| Step: 3
Training loss: 2.319483757019043
Validation loss: 2.416837425642116

Epoch: 5| Step: 4
Training loss: 2.815004825592041
Validation loss: 2.4228973952672814

Epoch: 5| Step: 5
Training loss: 2.830507755279541
Validation loss: 2.4077197787582234

Epoch: 5| Step: 6
Training loss: 2.177833080291748
Validation loss: 2.404114523241597

Epoch: 5| Step: 7
Training loss: 2.4320693016052246
Validation loss: 2.3891447026242494

Epoch: 5| Step: 8
Training loss: 3.208430051803589
Validation loss: 2.3833182678427747

Epoch: 5| Step: 9
Training loss: 1.8898671865463257
Validation loss: 2.382317740430114

Epoch: 5| Step: 10
Training loss: 2.1194376945495605
Validation loss: 2.3700547500323226

Epoch: 157| Step: 0
Training loss: 1.934396743774414
Validation loss: 2.3647555023111324

Epoch: 5| Step: 1
Training loss: 2.522573471069336
Validation loss: 2.364287446903926

Epoch: 5| Step: 2
Training loss: 2.9394240379333496
Validation loss: 2.3696349820783063

Epoch: 5| Step: 3
Training loss: 2.243647336959839
Validation loss: 2.4051903499070035

Epoch: 5| Step: 4
Training loss: 2.9615225791931152
Validation loss: 2.444251819323468

Epoch: 5| Step: 5
Training loss: 2.5816490650177
Validation loss: 2.453367402476649

Epoch: 5| Step: 6
Training loss: 3.0868802070617676
Validation loss: 2.48228725823023

Epoch: 5| Step: 7
Training loss: 2.9075443744659424
Validation loss: 2.4883931888047086

Epoch: 5| Step: 8
Training loss: 2.3219926357269287
Validation loss: 2.4155901452546478

Epoch: 5| Step: 9
Training loss: 3.25849986076355
Validation loss: 2.3910249817755913

Epoch: 5| Step: 10
Training loss: 1.9244494438171387
Validation loss: 2.368523678471965

Epoch: 158| Step: 0
Training loss: 2.5315804481506348
Validation loss: 2.3708223527477634

Epoch: 5| Step: 1
Training loss: 3.0422487258911133
Validation loss: 2.3701521401764243

Epoch: 5| Step: 2
Training loss: 2.656649112701416
Validation loss: 2.381552852610106

Epoch: 5| Step: 3
Training loss: 1.8601009845733643
Validation loss: 2.4022592985501854

Epoch: 5| Step: 4
Training loss: 2.67175030708313
Validation loss: 2.4021241190612956

Epoch: 5| Step: 5
Training loss: 2.7766168117523193
Validation loss: 2.407825873744103

Epoch: 5| Step: 6
Training loss: 2.3289153575897217
Validation loss: 2.394206125249145

Epoch: 5| Step: 7
Training loss: 2.1938624382019043
Validation loss: 2.3823770887108258

Epoch: 5| Step: 8
Training loss: 2.6428658962249756
Validation loss: 2.3796077902599047

Epoch: 5| Step: 9
Training loss: 3.235281467437744
Validation loss: 2.3740107372242916

Epoch: 5| Step: 10
Training loss: 2.640434741973877
Validation loss: 2.3780857260509203

Epoch: 159| Step: 0
Training loss: 3.190382480621338
Validation loss: 2.369890773168174

Epoch: 5| Step: 1
Training loss: 1.9654470682144165
Validation loss: 2.370811821312033

Epoch: 5| Step: 2
Training loss: 2.7999720573425293
Validation loss: 2.3712692286378596

Epoch: 5| Step: 3
Training loss: 2.3357291221618652
Validation loss: 2.372659016680974

Epoch: 5| Step: 4
Training loss: 2.728180170059204
Validation loss: 2.3750586817341466

Epoch: 5| Step: 5
Training loss: 3.4665274620056152
Validation loss: 2.374434624948809

Epoch: 5| Step: 6
Training loss: 2.509672164916992
Validation loss: 2.3788364907746673

Epoch: 5| Step: 7
Training loss: 2.1320176124572754
Validation loss: 2.3907868669879053

Epoch: 5| Step: 8
Training loss: 2.759298801422119
Validation loss: 2.3862628270221014

Epoch: 5| Step: 9
Training loss: 2.086236000061035
Validation loss: 2.3876426014848935

Epoch: 5| Step: 10
Training loss: 2.3612287044525146
Validation loss: 2.383532465145152

Epoch: 160| Step: 0
Training loss: 2.2164762020111084
Validation loss: 2.4014785059036745

Epoch: 5| Step: 1
Training loss: 2.7079474925994873
Validation loss: 2.3942948002969064

Epoch: 5| Step: 2
Training loss: 2.5628342628479004
Validation loss: 2.389302263977707

Epoch: 5| Step: 3
Training loss: 2.6697287559509277
Validation loss: 2.3949818598326815

Epoch: 5| Step: 4
Training loss: 3.009983777999878
Validation loss: 2.3759601167453233

Epoch: 5| Step: 5
Training loss: 2.3626742362976074
Validation loss: 2.373616997913648

Epoch: 5| Step: 6
Training loss: 2.1412227153778076
Validation loss: 2.370099103578957

Epoch: 5| Step: 7
Training loss: 2.296365976333618
Validation loss: 2.37068953821736

Epoch: 5| Step: 8
Training loss: 3.0202114582061768
Validation loss: 2.369011107311454

Epoch: 5| Step: 9
Training loss: 2.5096116065979004
Validation loss: 2.368960844573154

Epoch: 5| Step: 10
Training loss: 2.8932294845581055
Validation loss: 2.370391038156325

Epoch: 161| Step: 0
Training loss: 2.88120698928833
Validation loss: 2.372610881764402

Epoch: 5| Step: 1
Training loss: 2.4844560623168945
Validation loss: 2.3760365824545584

Epoch: 5| Step: 2
Training loss: 3.157146692276001
Validation loss: 2.3704901613214964

Epoch: 5| Step: 3
Training loss: 2.888763189315796
Validation loss: 2.365495374125819

Epoch: 5| Step: 4
Training loss: 2.5227532386779785
Validation loss: 2.3664167773339058

Epoch: 5| Step: 5
Training loss: 2.4159820079803467
Validation loss: 2.369747074701453

Epoch: 5| Step: 6
Training loss: 2.35990571975708
Validation loss: 2.372123836189188

Epoch: 5| Step: 7
Training loss: 3.2838032245635986
Validation loss: 2.372890172466155

Epoch: 5| Step: 8
Training loss: 1.777240514755249
Validation loss: 2.3624927484860985

Epoch: 5| Step: 9
Training loss: 2.5637478828430176
Validation loss: 2.3620184570230465

Epoch: 5| Step: 10
Training loss: 1.8120732307434082
Validation loss: 2.3670524756113687

Epoch: 162| Step: 0
Training loss: 2.8480403423309326
Validation loss: 2.371722934066608

Epoch: 5| Step: 1
Training loss: 2.17596435546875
Validation loss: 2.3720538744362454

Epoch: 5| Step: 2
Training loss: 2.8629767894744873
Validation loss: 2.3688177793256697

Epoch: 5| Step: 3
Training loss: 2.5533878803253174
Validation loss: 2.3654902647900324

Epoch: 5| Step: 4
Training loss: 2.3165526390075684
Validation loss: 2.3587662840402253

Epoch: 5| Step: 5
Training loss: 2.8376877307891846
Validation loss: 2.3639342989972842

Epoch: 5| Step: 6
Training loss: 2.296435594558716
Validation loss: 2.3661307109299528

Epoch: 5| Step: 7
Training loss: 2.2606873512268066
Validation loss: 2.375698417745611

Epoch: 5| Step: 8
Training loss: 2.3750510215759277
Validation loss: 2.3833276097492506

Epoch: 5| Step: 9
Training loss: 3.268718719482422
Validation loss: 2.39072669962401

Epoch: 5| Step: 10
Training loss: 2.5184988975524902
Validation loss: 2.4017283788291355

Epoch: 163| Step: 0
Training loss: 1.906903862953186
Validation loss: 2.4051076237873366

Epoch: 5| Step: 1
Training loss: 3.0097877979278564
Validation loss: 2.4134456598630516

Epoch: 5| Step: 2
Training loss: 2.8841476440429688
Validation loss: 2.420401338608034

Epoch: 5| Step: 3
Training loss: 2.3473868370056152
Validation loss: 2.419064365407472

Epoch: 5| Step: 4
Training loss: 2.660853862762451
Validation loss: 2.4183088092393774

Epoch: 5| Step: 5
Training loss: 2.872666835784912
Validation loss: 2.407019756173575

Epoch: 5| Step: 6
Training loss: 2.1613078117370605
Validation loss: 2.3984937449937225

Epoch: 5| Step: 7
Training loss: 2.988961696624756
Validation loss: 2.39510021158444

Epoch: 5| Step: 8
Training loss: 2.022691011428833
Validation loss: 2.3858916272399244

Epoch: 5| Step: 9
Training loss: 2.943758487701416
Validation loss: 2.38051159920231

Epoch: 5| Step: 10
Training loss: 2.403803825378418
Validation loss: 2.3649440426980295

Epoch: 164| Step: 0
Training loss: 2.388981342315674
Validation loss: 2.3659315827072307

Epoch: 5| Step: 1
Training loss: 3.2755935192108154
Validation loss: 2.366415108403852

Epoch: 5| Step: 2
Training loss: 2.6500163078308105
Validation loss: 2.3567891941275647

Epoch: 5| Step: 3
Training loss: 2.539142608642578
Validation loss: 2.356370054265504

Epoch: 5| Step: 4
Training loss: 2.107058048248291
Validation loss: 2.3587333463853404

Epoch: 5| Step: 5
Training loss: 2.763871669769287
Validation loss: 2.367073315446095

Epoch: 5| Step: 6
Training loss: 2.543375253677368
Validation loss: 2.360790552631501

Epoch: 5| Step: 7
Training loss: 2.5417091846466064
Validation loss: 2.3616066132822344

Epoch: 5| Step: 8
Training loss: 2.993257999420166
Validation loss: 2.365186970721009

Epoch: 5| Step: 9
Training loss: 2.369055986404419
Validation loss: 2.3509405197635775

Epoch: 5| Step: 10
Training loss: 1.9953244924545288
Validation loss: 2.353494054527693

Epoch: 165| Step: 0
Training loss: 2.6518001556396484
Validation loss: 2.357112410247967

Epoch: 5| Step: 1
Training loss: 2.9447484016418457
Validation loss: 2.3663555883592173

Epoch: 5| Step: 2
Training loss: 3.0804309844970703
Validation loss: 2.363490399493966

Epoch: 5| Step: 3
Training loss: 2.813847541809082
Validation loss: 2.3659596981540805

Epoch: 5| Step: 4
Training loss: 3.3306891918182373
Validation loss: 2.3607962900592434

Epoch: 5| Step: 5
Training loss: 1.873130440711975
Validation loss: 2.358022900037868

Epoch: 5| Step: 6
Training loss: 2.822702407836914
Validation loss: 2.3703026553635955

Epoch: 5| Step: 7
Training loss: 2.085714340209961
Validation loss: 2.371459279009091

Epoch: 5| Step: 8
Training loss: 2.073701858520508
Validation loss: 2.3736641945377475

Epoch: 5| Step: 9
Training loss: 2.1762452125549316
Validation loss: 2.382484930817799

Epoch: 5| Step: 10
Training loss: 2.2010250091552734
Validation loss: 2.3867307734745804

Epoch: 166| Step: 0
Training loss: 2.2148244380950928
Validation loss: 2.3877134835848244

Epoch: 5| Step: 1
Training loss: 2.645622730255127
Validation loss: 2.383549718446629

Epoch: 5| Step: 2
Training loss: 2.427755832672119
Validation loss: 2.40242669146548

Epoch: 5| Step: 3
Training loss: 2.1960785388946533
Validation loss: 2.406915480090726

Epoch: 5| Step: 4
Training loss: 2.3750967979431152
Validation loss: 2.4109608639952955

Epoch: 5| Step: 5
Training loss: 2.884822368621826
Validation loss: 2.4098180942637946

Epoch: 5| Step: 6
Training loss: 2.9491171836853027
Validation loss: 2.4227909695717598

Epoch: 5| Step: 7
Training loss: 2.2796335220336914
Validation loss: 2.4066427984545307

Epoch: 5| Step: 8
Training loss: 3.199345111846924
Validation loss: 2.3839593984747447

Epoch: 5| Step: 9
Training loss: 2.689802885055542
Validation loss: 2.35435974982477

Epoch: 5| Step: 10
Training loss: 2.3408217430114746
Validation loss: 2.347101596093947

Epoch: 167| Step: 0
Training loss: 2.690969228744507
Validation loss: 2.34810249651632

Epoch: 5| Step: 1
Training loss: 2.1575429439544678
Validation loss: 2.3525354182848366

Epoch: 5| Step: 2
Training loss: 1.9749786853790283
Validation loss: 2.362757909682489

Epoch: 5| Step: 3
Training loss: 2.7877228260040283
Validation loss: 2.3595350891031246

Epoch: 5| Step: 4
Training loss: 2.2774336338043213
Validation loss: 2.350815337191346

Epoch: 5| Step: 5
Training loss: 2.33853816986084
Validation loss: 2.3433868961949504

Epoch: 5| Step: 6
Training loss: 2.7740626335144043
Validation loss: 2.3531587867326635

Epoch: 5| Step: 7
Training loss: 2.9744319915771484
Validation loss: 2.3457982770858274

Epoch: 5| Step: 8
Training loss: 2.5914549827575684
Validation loss: 2.3506549737786733

Epoch: 5| Step: 9
Training loss: 3.038205623626709
Validation loss: 2.364069482331635

Epoch: 5| Step: 10
Training loss: 2.570699691772461
Validation loss: 2.3668131136125132

Epoch: 168| Step: 0
Training loss: 3.108440399169922
Validation loss: 2.361221005839686

Epoch: 5| Step: 1
Training loss: 1.659407615661621
Validation loss: 2.3682947235722698

Epoch: 5| Step: 2
Training loss: 3.29066801071167
Validation loss: 2.3681914998639013

Epoch: 5| Step: 3
Training loss: 2.013197422027588
Validation loss: 2.3783464713763167

Epoch: 5| Step: 4
Training loss: 2.7454957962036133
Validation loss: 2.377121320334814

Epoch: 5| Step: 5
Training loss: 2.8899993896484375
Validation loss: 2.3727819688858522

Epoch: 5| Step: 6
Training loss: 2.2220706939697266
Validation loss: 2.3697971861849547

Epoch: 5| Step: 7
Training loss: 2.4965591430664062
Validation loss: 2.3637459534470753

Epoch: 5| Step: 8
Training loss: 2.951328992843628
Validation loss: 2.368712568795809

Epoch: 5| Step: 9
Training loss: 2.706238269805908
Validation loss: 2.361891782411965

Epoch: 5| Step: 10
Training loss: 2.014298677444458
Validation loss: 2.3676740738653366

Epoch: 169| Step: 0
Training loss: 2.079376459121704
Validation loss: 2.3580805973340104

Epoch: 5| Step: 1
Training loss: 2.3291866779327393
Validation loss: 2.3756096029794342

Epoch: 5| Step: 2
Training loss: 2.9289543628692627
Validation loss: 2.3977349112110753

Epoch: 5| Step: 3
Training loss: 2.3848044872283936
Validation loss: 2.369778117825908

Epoch: 5| Step: 4
Training loss: 2.8071601390838623
Validation loss: 2.374811896713831

Epoch: 5| Step: 5
Training loss: 2.0183119773864746
Validation loss: 2.3416824481820546

Epoch: 5| Step: 6
Training loss: 2.826366424560547
Validation loss: 2.337685436330816

Epoch: 5| Step: 7
Training loss: 2.397944450378418
Validation loss: 2.332713391191216

Epoch: 5| Step: 8
Training loss: 2.7714784145355225
Validation loss: 2.35051138939396

Epoch: 5| Step: 9
Training loss: 2.8072690963745117
Validation loss: 2.363507083667222

Epoch: 5| Step: 10
Training loss: 2.965754747390747
Validation loss: 2.389885926759371

Epoch: 170| Step: 0
Training loss: 2.5562758445739746
Validation loss: 2.401557166089294

Epoch: 5| Step: 1
Training loss: 2.779878854751587
Validation loss: 2.413451715182233

Epoch: 5| Step: 2
Training loss: 2.949995517730713
Validation loss: 2.395232780005342

Epoch: 5| Step: 3
Training loss: 2.4507601261138916
Validation loss: 2.392506758371989

Epoch: 5| Step: 4
Training loss: 2.387585401535034
Validation loss: 2.3789051425072456

Epoch: 5| Step: 5
Training loss: 2.4399828910827637
Validation loss: 2.372414747873942

Epoch: 5| Step: 6
Training loss: 2.6203248500823975
Validation loss: 2.3668637890969553

Epoch: 5| Step: 7
Training loss: 2.2029366493225098
Validation loss: 2.368486912019791

Epoch: 5| Step: 8
Training loss: 2.6725826263427734
Validation loss: 2.3585114325246503

Epoch: 5| Step: 9
Training loss: 2.665827512741089
Validation loss: 2.3542458870077647

Epoch: 5| Step: 10
Training loss: 2.352081298828125
Validation loss: 2.3585640743214595

Epoch: 171| Step: 0
Training loss: 2.1924870014190674
Validation loss: 2.3714189913965042

Epoch: 5| Step: 1
Training loss: 2.1040122509002686
Validation loss: 2.4090994199117026

Epoch: 5| Step: 2
Training loss: 1.7408660650253296
Validation loss: 2.439413247569915

Epoch: 5| Step: 3
Training loss: 2.8211636543273926
Validation loss: 2.461924822099747

Epoch: 5| Step: 4
Training loss: 2.69504976272583
Validation loss: 2.4081992257025933

Epoch: 5| Step: 5
Training loss: 2.2781054973602295
Validation loss: 2.388915992552234

Epoch: 5| Step: 6
Training loss: 2.897355079650879
Validation loss: 2.3713866049243557

Epoch: 5| Step: 7
Training loss: 3.1036312580108643
Validation loss: 2.3836781132605767

Epoch: 5| Step: 8
Training loss: 3.473458766937256
Validation loss: 2.4020623686493083

Epoch: 5| Step: 9
Training loss: 2.6349849700927734
Validation loss: 2.4105896719040407

Epoch: 5| Step: 10
Training loss: 2.3651022911071777
Validation loss: 2.412002037930232

Epoch: 172| Step: 0
Training loss: 2.5798048973083496
Validation loss: 2.380162767184678

Epoch: 5| Step: 1
Training loss: 2.4143567085266113
Validation loss: 2.3492865152256464

Epoch: 5| Step: 2
Training loss: 2.248687505722046
Validation loss: 2.3209750216494323

Epoch: 5| Step: 3
Training loss: 2.680086612701416
Validation loss: 2.324842345330023

Epoch: 5| Step: 4
Training loss: 2.7389328479766846
Validation loss: 2.3324392598162413

Epoch: 5| Step: 5
Training loss: 2.522667407989502
Validation loss: 2.340002077882008

Epoch: 5| Step: 6
Training loss: 2.614485263824463
Validation loss: 2.3561964214489026

Epoch: 5| Step: 7
Training loss: 2.2082276344299316
Validation loss: 2.3878055772473736

Epoch: 5| Step: 8
Training loss: 2.8683218955993652
Validation loss: 2.428480743080057

Epoch: 5| Step: 9
Training loss: 2.8313965797424316
Validation loss: 2.38067461598304

Epoch: 5| Step: 10
Training loss: 2.6457080841064453
Validation loss: 2.384672734045213

Epoch: 173| Step: 0
Training loss: 2.411004066467285
Validation loss: 2.3516534348969818

Epoch: 5| Step: 1
Training loss: 2.68396258354187
Validation loss: 2.3339001581233036

Epoch: 5| Step: 2
Training loss: 2.4688735008239746
Validation loss: 2.335825084358133

Epoch: 5| Step: 3
Training loss: 2.5916950702667236
Validation loss: 2.3324228332888697

Epoch: 5| Step: 4
Training loss: 2.3720781803131104
Validation loss: 2.3419425872064408

Epoch: 5| Step: 5
Training loss: 2.964571714401245
Validation loss: 2.348040191076135

Epoch: 5| Step: 6
Training loss: 2.6240603923797607
Validation loss: 2.374045761682654

Epoch: 5| Step: 7
Training loss: 2.633753538131714
Validation loss: 2.386146863301595

Epoch: 5| Step: 8
Training loss: 2.2955079078674316
Validation loss: 2.3881672018317768

Epoch: 5| Step: 9
Training loss: 2.6141254901885986
Validation loss: 2.394002724719304

Epoch: 5| Step: 10
Training loss: 2.5023767948150635
Validation loss: 2.3784480607637795

Epoch: 174| Step: 0
Training loss: 2.3732266426086426
Validation loss: 2.375165372766474

Epoch: 5| Step: 1
Training loss: 2.969458818435669
Validation loss: 2.388124035250756

Epoch: 5| Step: 2
Training loss: 2.7144901752471924
Validation loss: 2.3902511160860778

Epoch: 5| Step: 3
Training loss: 1.7770427465438843
Validation loss: 2.380495830248761

Epoch: 5| Step: 4
Training loss: 2.273131847381592
Validation loss: 2.3634465432936147

Epoch: 5| Step: 5
Training loss: 2.730928897857666
Validation loss: 2.3472918618109917

Epoch: 5| Step: 6
Training loss: 2.445021152496338
Validation loss: 2.350271799231088

Epoch: 5| Step: 7
Training loss: 2.4035415649414062
Validation loss: 2.3383141051056566

Epoch: 5| Step: 8
Training loss: 2.737659454345703
Validation loss: 2.342836603041618

Epoch: 5| Step: 9
Training loss: 2.8373661041259766
Validation loss: 2.333538927057738

Epoch: 5| Step: 10
Training loss: 2.785757064819336
Validation loss: 2.3369987472411125

Epoch: 175| Step: 0
Training loss: 2.6016998291015625
Validation loss: 2.334151073168683

Epoch: 5| Step: 1
Training loss: 2.4030001163482666
Validation loss: 2.3345043223391295

Epoch: 5| Step: 2
Training loss: 2.5522830486297607
Validation loss: 2.331774462935745

Epoch: 5| Step: 3
Training loss: 2.1816518306732178
Validation loss: 2.3333385785420737

Epoch: 5| Step: 4
Training loss: 2.7180304527282715
Validation loss: 2.3295924304634013

Epoch: 5| Step: 5
Training loss: 2.525468587875366
Validation loss: 2.337873899808494

Epoch: 5| Step: 6
Training loss: 2.5652852058410645
Validation loss: 2.350472722002255

Epoch: 5| Step: 7
Training loss: 2.114926338195801
Validation loss: 2.351624442685035

Epoch: 5| Step: 8
Training loss: 2.5945229530334473
Validation loss: 2.3629531347623436

Epoch: 5| Step: 9
Training loss: 2.836803674697876
Validation loss: 2.36316668346364

Epoch: 5| Step: 10
Training loss: 2.947230339050293
Validation loss: 2.3648151710469234

Epoch: 176| Step: 0
Training loss: 1.7908108234405518
Validation loss: 2.3576125021903747

Epoch: 5| Step: 1
Training loss: 2.213881731033325
Validation loss: 2.3564758762236564

Epoch: 5| Step: 2
Training loss: 2.9563136100769043
Validation loss: 2.3654298602893786

Epoch: 5| Step: 3
Training loss: 2.1315908432006836
Validation loss: 2.3806662072417555

Epoch: 5| Step: 4
Training loss: 2.5887610912323
Validation loss: 2.3955233737986577

Epoch: 5| Step: 5
Training loss: 2.81585431098938
Validation loss: 2.3794576980734385

Epoch: 5| Step: 6
Training loss: 2.6908047199249268
Validation loss: 2.3971395133644022

Epoch: 5| Step: 7
Training loss: 2.637232542037964
Validation loss: 2.3834035576030774

Epoch: 5| Step: 8
Training loss: 2.512319803237915
Validation loss: 2.37474157733302

Epoch: 5| Step: 9
Training loss: 2.9154858589172363
Validation loss: 2.3815032923093407

Epoch: 5| Step: 10
Training loss: 2.726585865020752
Validation loss: 2.371877206269131

Epoch: 177| Step: 0
Training loss: 2.8766891956329346
Validation loss: 2.356417373944354

Epoch: 5| Step: 1
Training loss: 2.5758488178253174
Validation loss: 2.36241985905555

Epoch: 5| Step: 2
Training loss: 2.709092378616333
Validation loss: 2.3550160828457085

Epoch: 5| Step: 3
Training loss: 2.7592110633850098
Validation loss: 2.339214753079158

Epoch: 5| Step: 4
Training loss: 2.158108949661255
Validation loss: 2.341827223377843

Epoch: 5| Step: 5
Training loss: 2.9417312145233154
Validation loss: 2.3383010946294314

Epoch: 5| Step: 6
Training loss: 2.4257521629333496
Validation loss: 2.3360014653974965

Epoch: 5| Step: 7
Training loss: 2.254849672317505
Validation loss: 2.3538297094324583

Epoch: 5| Step: 8
Training loss: 2.5557332038879395
Validation loss: 2.340815918419951

Epoch: 5| Step: 9
Training loss: 1.8295825719833374
Validation loss: 2.377051258599886

Epoch: 5| Step: 10
Training loss: 2.8242359161376953
Validation loss: 2.418103051441972

Epoch: 178| Step: 0
Training loss: 2.9363698959350586
Validation loss: 2.3985519280997654

Epoch: 5| Step: 1
Training loss: 2.313199281692505
Validation loss: 2.357622113279117

Epoch: 5| Step: 2
Training loss: 2.5247397422790527
Validation loss: 2.34223170434275

Epoch: 5| Step: 3
Training loss: 2.637500286102295
Validation loss: 2.33678448841136

Epoch: 5| Step: 4
Training loss: 2.261777400970459
Validation loss: 2.3517503687130508

Epoch: 5| Step: 5
Training loss: 3.292367458343506
Validation loss: 2.3495000177814114

Epoch: 5| Step: 6
Training loss: 2.2388899326324463
Validation loss: 2.350054610160089

Epoch: 5| Step: 7
Training loss: 2.5776190757751465
Validation loss: 2.345052303806428

Epoch: 5| Step: 8
Training loss: 2.014315128326416
Validation loss: 2.3329620950965473

Epoch: 5| Step: 9
Training loss: 2.616981029510498
Validation loss: 2.3267851401400823

Epoch: 5| Step: 10
Training loss: 2.486769199371338
Validation loss: 2.3287636310823503

Epoch: 179| Step: 0
Training loss: 2.715087652206421
Validation loss: 2.334681495543449

Epoch: 5| Step: 1
Training loss: 2.1672348976135254
Validation loss: 2.334980049440938

Epoch: 5| Step: 2
Training loss: 2.0889923572540283
Validation loss: 2.3498686359774683

Epoch: 5| Step: 3
Training loss: 2.353111505508423
Validation loss: 2.3539824024323495

Epoch: 5| Step: 4
Training loss: 2.56571626663208
Validation loss: 2.3675831697320424

Epoch: 5| Step: 5
Training loss: 2.2559361457824707
Validation loss: 2.3741970216074297

Epoch: 5| Step: 6
Training loss: 2.571932792663574
Validation loss: 2.385763120907609

Epoch: 5| Step: 7
Training loss: 2.8738813400268555
Validation loss: 2.3838231486658894

Epoch: 5| Step: 8
Training loss: 2.938278913497925
Validation loss: 2.3935512445306264

Epoch: 5| Step: 9
Training loss: 2.5126471519470215
Validation loss: 2.3940674899726786

Epoch: 5| Step: 10
Training loss: 2.8237664699554443
Validation loss: 2.3850292518574703

Epoch: 180| Step: 0
Training loss: 2.668148994445801
Validation loss: 2.3798506541918685

Epoch: 5| Step: 1
Training loss: 2.5548930168151855
Validation loss: 2.378072097737302

Epoch: 5| Step: 2
Training loss: 1.7630685567855835
Validation loss: 2.370345525844123

Epoch: 5| Step: 3
Training loss: 3.359095335006714
Validation loss: 2.366902917943975

Epoch: 5| Step: 4
Training loss: 2.738006591796875
Validation loss: 2.3593055996843564

Epoch: 5| Step: 5
Training loss: 2.395508289337158
Validation loss: 2.34150283311003

Epoch: 5| Step: 6
Training loss: 2.6368794441223145
Validation loss: 2.3327616696716635

Epoch: 5| Step: 7
Training loss: 2.3101372718811035
Validation loss: 2.332221500335201

Epoch: 5| Step: 8
Training loss: 1.950214147567749
Validation loss: 2.3220201666637132

Epoch: 5| Step: 9
Training loss: 2.2301082611083984
Validation loss: 2.326833159692826

Epoch: 5| Step: 10
Training loss: 3.174722194671631
Validation loss: 2.324824494700278

Epoch: 181| Step: 0
Training loss: 2.045182943344116
Validation loss: 2.3313449428927515

Epoch: 5| Step: 1
Training loss: 2.288466215133667
Validation loss: 2.3380755532172417

Epoch: 5| Step: 2
Training loss: 2.5118823051452637
Validation loss: 2.3380287693392847

Epoch: 5| Step: 3
Training loss: 2.4822192192077637
Validation loss: 2.343775713315574

Epoch: 5| Step: 4
Training loss: 2.6415817737579346
Validation loss: 2.3640964031219482

Epoch: 5| Step: 5
Training loss: 2.998427152633667
Validation loss: 2.3619752135328067

Epoch: 5| Step: 6
Training loss: 2.6006507873535156
Validation loss: 2.350616778096845

Epoch: 5| Step: 7
Training loss: 2.6482226848602295
Validation loss: 2.362226596442602

Epoch: 5| Step: 8
Training loss: 2.958704948425293
Validation loss: 2.371182708330052

Epoch: 5| Step: 9
Training loss: 2.336195707321167
Validation loss: 2.363396247227987

Epoch: 5| Step: 10
Training loss: 2.1649208068847656
Validation loss: 2.3746382318517214

Epoch: 182| Step: 0
Training loss: 1.9835160970687866
Validation loss: 2.3614043471633748

Epoch: 5| Step: 1
Training loss: 2.2755672931671143
Validation loss: 2.3574581582059144

Epoch: 5| Step: 2
Training loss: 2.2426257133483887
Validation loss: 2.3726458088044198

Epoch: 5| Step: 3
Training loss: 2.7922325134277344
Validation loss: 2.3657878611677434

Epoch: 5| Step: 4
Training loss: 2.6221272945404053
Validation loss: 2.348252450266192

Epoch: 5| Step: 5
Training loss: 2.414389133453369
Validation loss: 2.3343874972353698

Epoch: 5| Step: 6
Training loss: 2.7943625450134277
Validation loss: 2.3253860678724063

Epoch: 5| Step: 7
Training loss: 2.646472692489624
Validation loss: 2.3171879283843504

Epoch: 5| Step: 8
Training loss: 2.3217222690582275
Validation loss: 2.3281397383700133

Epoch: 5| Step: 9
Training loss: 2.599743127822876
Validation loss: 2.322125061865776

Epoch: 5| Step: 10
Training loss: 2.9379024505615234
Validation loss: 2.336296581452893

Epoch: 183| Step: 0
Training loss: 3.0805559158325195
Validation loss: 2.3746048968325377

Epoch: 5| Step: 1
Training loss: 2.5676000118255615
Validation loss: 2.371905196097589

Epoch: 5| Step: 2
Training loss: 2.684558629989624
Validation loss: 2.4137442188878215

Epoch: 5| Step: 3
Training loss: 2.901801109313965
Validation loss: 2.400221037608321

Epoch: 5| Step: 4
Training loss: 2.182251214981079
Validation loss: 2.3587065025042464

Epoch: 5| Step: 5
Training loss: 1.7068017721176147
Validation loss: 2.3463171297504055

Epoch: 5| Step: 6
Training loss: 2.6344809532165527
Validation loss: 2.3532921396276003

Epoch: 5| Step: 7
Training loss: 2.35021710395813
Validation loss: 2.380373216444446

Epoch: 5| Step: 8
Training loss: 2.632317543029785
Validation loss: 2.388456734277869

Epoch: 5| Step: 9
Training loss: 2.6367483139038086
Validation loss: 2.380335377108666

Epoch: 5| Step: 10
Training loss: 2.4834518432617188
Validation loss: 2.3906917008020545

Epoch: 184| Step: 0
Training loss: 2.3973326683044434
Validation loss: 2.3903188295261835

Epoch: 5| Step: 1
Training loss: 2.970125913619995
Validation loss: 2.3807026596479517

Epoch: 5| Step: 2
Training loss: 2.7443597316741943
Validation loss: 2.3673779451718895

Epoch: 5| Step: 3
Training loss: 2.4649899005889893
Validation loss: 2.352148396994478

Epoch: 5| Step: 4
Training loss: 2.458167314529419
Validation loss: 2.3424692359021915

Epoch: 5| Step: 5
Training loss: 2.0541248321533203
Validation loss: 2.331066864793019

Epoch: 5| Step: 6
Training loss: 2.635751247406006
Validation loss: 2.333784790449245

Epoch: 5| Step: 7
Training loss: 1.9388641119003296
Validation loss: 2.337405199645668

Epoch: 5| Step: 8
Training loss: 2.5174801349639893
Validation loss: 2.3284650156574864

Epoch: 5| Step: 9
Training loss: 2.667518377304077
Validation loss: 2.3173193623942714

Epoch: 5| Step: 10
Training loss: 2.934232711791992
Validation loss: 2.3095276535198255

Epoch: 185| Step: 0
Training loss: 2.832775831222534
Validation loss: 2.307022479272658

Epoch: 5| Step: 1
Training loss: 2.66416335105896
Validation loss: 2.305873886231453

Epoch: 5| Step: 2
Training loss: 2.488614559173584
Validation loss: 2.3155518680490474

Epoch: 5| Step: 3
Training loss: 2.3721718788146973
Validation loss: 2.319899700021231

Epoch: 5| Step: 4
Training loss: 3.20745587348938
Validation loss: 2.331056971703806

Epoch: 5| Step: 5
Training loss: 1.9033305644989014
Validation loss: 2.327590721909718

Epoch: 5| Step: 6
Training loss: 2.7735702991485596
Validation loss: 2.3363823980413456

Epoch: 5| Step: 7
Training loss: 2.2356414794921875
Validation loss: 2.3355027603846725

Epoch: 5| Step: 8
Training loss: 2.6389644145965576
Validation loss: 2.345225147021714

Epoch: 5| Step: 9
Training loss: 2.2472622394561768
Validation loss: 2.3508322572195404

Epoch: 5| Step: 10
Training loss: 2.3734028339385986
Validation loss: 2.347679433002267

Epoch: 186| Step: 0
Training loss: 2.412996292114258
Validation loss: 2.352329889933268

Epoch: 5| Step: 1
Training loss: 2.957141876220703
Validation loss: 2.323599433386198

Epoch: 5| Step: 2
Training loss: 2.3946166038513184
Validation loss: 2.331393482864544

Epoch: 5| Step: 3
Training loss: 3.0283143520355225
Validation loss: 2.3210620444308043

Epoch: 5| Step: 4
Training loss: 2.79298996925354
Validation loss: 2.3211949204885833

Epoch: 5| Step: 5
Training loss: 1.6034183502197266
Validation loss: 2.3121379754876576

Epoch: 5| Step: 6
Training loss: 2.4987194538116455
Validation loss: 2.3111617718973467

Epoch: 5| Step: 7
Training loss: 2.092451572418213
Validation loss: 2.3121873306971725

Epoch: 5| Step: 8
Training loss: 2.749490261077881
Validation loss: 2.3132164145028717

Epoch: 5| Step: 9
Training loss: 2.923213481903076
Validation loss: 2.3174654488922446

Epoch: 5| Step: 10
Training loss: 1.9383039474487305
Validation loss: 2.3281592297297653

Epoch: 187| Step: 0
Training loss: 2.7074801921844482
Validation loss: 2.33478961195997

Epoch: 5| Step: 1
Training loss: 2.7614784240722656
Validation loss: 2.3341607252756753

Epoch: 5| Step: 2
Training loss: 2.898367404937744
Validation loss: 2.34623686857121

Epoch: 5| Step: 3
Training loss: 2.749790668487549
Validation loss: 2.347579445890201

Epoch: 5| Step: 4
Training loss: 2.665255069732666
Validation loss: 2.353652410609748

Epoch: 5| Step: 5
Training loss: 2.278806209564209
Validation loss: 2.3574504108839136

Epoch: 5| Step: 6
Training loss: 1.9653618335723877
Validation loss: 2.338385899861654

Epoch: 5| Step: 7
Training loss: 2.4437973499298096
Validation loss: 2.344925016485235

Epoch: 5| Step: 8
Training loss: 2.414890766143799
Validation loss: 2.3452895354199153

Epoch: 5| Step: 9
Training loss: 2.433171510696411
Validation loss: 2.349474750539308

Epoch: 5| Step: 10
Training loss: 2.1254727840423584
Validation loss: 2.3431902136853946

Epoch: 188| Step: 0
Training loss: 2.832108974456787
Validation loss: 2.332476838942497

Epoch: 5| Step: 1
Training loss: 2.645073652267456
Validation loss: 2.3198185966860865

Epoch: 5| Step: 2
Training loss: 2.6097915172576904
Validation loss: 2.3295163851912304

Epoch: 5| Step: 3
Training loss: 2.1624767780303955
Validation loss: 2.3111147547280915

Epoch: 5| Step: 4
Training loss: 2.976637840270996
Validation loss: 2.320823300269342

Epoch: 5| Step: 5
Training loss: 2.089064836502075
Validation loss: 2.3077373145728983

Epoch: 5| Step: 6
Training loss: 2.2482759952545166
Validation loss: 2.299509971372543

Epoch: 5| Step: 7
Training loss: 2.3030283451080322
Validation loss: 2.303814764945738

Epoch: 5| Step: 8
Training loss: 2.65976881980896
Validation loss: 2.307867806444886

Epoch: 5| Step: 9
Training loss: 3.1453640460968018
Validation loss: 2.3018255861856605

Epoch: 5| Step: 10
Training loss: 1.6714205741882324
Validation loss: 2.3060952194275393

Epoch: 189| Step: 0
Training loss: 2.1453347206115723
Validation loss: 2.3139468982655513

Epoch: 5| Step: 1
Training loss: 2.5902886390686035
Validation loss: 2.3202689334910405

Epoch: 5| Step: 2
Training loss: 2.5638039112091064
Validation loss: 2.333597897201456

Epoch: 5| Step: 3
Training loss: 2.161339282989502
Validation loss: 2.3407370223793933

Epoch: 5| Step: 4
Training loss: 3.202509641647339
Validation loss: 2.3580365206605647

Epoch: 5| Step: 5
Training loss: 3.2122249603271484
Validation loss: 2.360617906816544

Epoch: 5| Step: 6
Training loss: 2.6662302017211914
Validation loss: 2.3401651972083637

Epoch: 5| Step: 7
Training loss: 1.7900819778442383
Validation loss: 2.3495592942801853

Epoch: 5| Step: 8
Training loss: 1.8278366327285767
Validation loss: 2.3440153342421337

Epoch: 5| Step: 9
Training loss: 2.5634236335754395
Validation loss: 2.347168432768955

Epoch: 5| Step: 10
Training loss: 2.7104086875915527
Validation loss: 2.3225949297669115

Epoch: 190| Step: 0
Training loss: 2.3795723915100098
Validation loss: 2.333546453906644

Epoch: 5| Step: 1
Training loss: 2.1076607704162598
Validation loss: 2.324237977304766

Epoch: 5| Step: 2
Training loss: 2.913977861404419
Validation loss: 2.3374168206286687

Epoch: 5| Step: 3
Training loss: 2.8299777507781982
Validation loss: 2.3506706145501908

Epoch: 5| Step: 4
Training loss: 2.72880220413208
Validation loss: 2.347122892256706

Epoch: 5| Step: 5
Training loss: 2.5790939331054688
Validation loss: 2.35214138543734

Epoch: 5| Step: 6
Training loss: 2.4937000274658203
Validation loss: 2.3423263347277077

Epoch: 5| Step: 7
Training loss: 2.2035341262817383
Validation loss: 2.343465807617352

Epoch: 5| Step: 8
Training loss: 2.1290671825408936
Validation loss: 2.325950112394107

Epoch: 5| Step: 9
Training loss: 2.9278626441955566
Validation loss: 2.3350427740363666

Epoch: 5| Step: 10
Training loss: 2.149454116821289
Validation loss: 2.355420338210239

Epoch: 191| Step: 0
Training loss: 3.421344041824341
Validation loss: 2.3635450588759555

Epoch: 5| Step: 1
Training loss: 1.8662612438201904
Validation loss: 2.3560858926465436

Epoch: 5| Step: 2
Training loss: 2.1047616004943848
Validation loss: 2.3316997994658766

Epoch: 5| Step: 3
Training loss: 2.6034388542175293
Validation loss: 2.3144185440514677

Epoch: 5| Step: 4
Training loss: 2.3892664909362793
Validation loss: 2.32614484653678

Epoch: 5| Step: 5
Training loss: 2.6004862785339355
Validation loss: 2.3187014620791198

Epoch: 5| Step: 6
Training loss: 2.880990505218506
Validation loss: 2.364272666233842

Epoch: 5| Step: 7
Training loss: 2.418990135192871
Validation loss: 2.369751440581455

Epoch: 5| Step: 8
Training loss: 2.6268856525421143
Validation loss: 2.378883848908127

Epoch: 5| Step: 9
Training loss: 2.842252254486084
Validation loss: 2.3986849272122948

Epoch: 5| Step: 10
Training loss: 1.7733485698699951
Validation loss: 2.3831735939107914

Epoch: 192| Step: 0
Training loss: 2.8556253910064697
Validation loss: 2.3830945978882494

Epoch: 5| Step: 1
Training loss: 1.8331031799316406
Validation loss: 2.3827320670568817

Epoch: 5| Step: 2
Training loss: 2.950758695602417
Validation loss: 2.3673430386409966

Epoch: 5| Step: 3
Training loss: 2.4246764183044434
Validation loss: 2.3661263706863567

Epoch: 5| Step: 4
Training loss: 3.2066948413848877
Validation loss: 2.36463507529228

Epoch: 5| Step: 5
Training loss: 2.591721296310425
Validation loss: 2.362277997437344

Epoch: 5| Step: 6
Training loss: 3.010235071182251
Validation loss: 2.341215473349376

Epoch: 5| Step: 7
Training loss: 2.1077628135681152
Validation loss: 2.332475249485303

Epoch: 5| Step: 8
Training loss: 2.0787320137023926
Validation loss: 2.3177330506745206

Epoch: 5| Step: 9
Training loss: 1.8813831806182861
Validation loss: 2.311765497730624

Epoch: 5| Step: 10
Training loss: 2.5181093215942383
Validation loss: 2.3254615106890277

Epoch: 193| Step: 0
Training loss: 2.7880866527557373
Validation loss: 2.3349661237450055

Epoch: 5| Step: 1
Training loss: 2.612774610519409
Validation loss: 2.3269942498976186

Epoch: 5| Step: 2
Training loss: 2.1714301109313965
Validation loss: 2.3127549873885287

Epoch: 5| Step: 3
Training loss: 3.1087913513183594
Validation loss: 2.3160896608906407

Epoch: 5| Step: 4
Training loss: 2.5003087520599365
Validation loss: 2.3064160603348927

Epoch: 5| Step: 5
Training loss: 2.629074811935425
Validation loss: 2.300061671964584

Epoch: 5| Step: 6
Training loss: 2.762716293334961
Validation loss: 2.306220216135825

Epoch: 5| Step: 7
Training loss: 2.766216516494751
Validation loss: 2.303763638260544

Epoch: 5| Step: 8
Training loss: 2.2410101890563965
Validation loss: 2.3276224879808325

Epoch: 5| Step: 9
Training loss: 1.896898627281189
Validation loss: 2.313652402611189

Epoch: 5| Step: 10
Training loss: 1.8333220481872559
Validation loss: 2.3223246259074055

Epoch: 194| Step: 0
Training loss: 2.8537611961364746
Validation loss: 2.330871085966787

Epoch: 5| Step: 1
Training loss: 2.408812999725342
Validation loss: 2.316086653740175

Epoch: 5| Step: 2
Training loss: 2.499546766281128
Validation loss: 2.3219421320064093

Epoch: 5| Step: 3
Training loss: 2.016350269317627
Validation loss: 2.319503907234438

Epoch: 5| Step: 4
Training loss: 2.660849094390869
Validation loss: 2.3152905664136334

Epoch: 5| Step: 5
Training loss: 2.5464134216308594
Validation loss: 2.314624741513242

Epoch: 5| Step: 6
Training loss: 2.639263391494751
Validation loss: 2.3104427578628703

Epoch: 5| Step: 7
Training loss: 2.143625497817993
Validation loss: 2.3239949518634426

Epoch: 5| Step: 8
Training loss: 2.3740997314453125
Validation loss: 2.3587070536869827

Epoch: 5| Step: 9
Training loss: 2.6507315635681152
Validation loss: 2.3662324208085255

Epoch: 5| Step: 10
Training loss: 2.3518590927124023
Validation loss: 2.372943716664468

Epoch: 195| Step: 0
Training loss: 2.0841989517211914
Validation loss: 2.357766858993038

Epoch: 5| Step: 1
Training loss: 3.133749485015869
Validation loss: 2.3392300759592364

Epoch: 5| Step: 2
Training loss: 2.4482014179229736
Validation loss: 2.310048613497006

Epoch: 5| Step: 3
Training loss: 3.0110177993774414
Validation loss: 2.300726217608298

Epoch: 5| Step: 4
Training loss: 2.0566165447235107
Validation loss: 2.3071356614430747

Epoch: 5| Step: 5
Training loss: 2.3343303203582764
Validation loss: 2.2935591564383557

Epoch: 5| Step: 6
Training loss: 2.9517674446105957
Validation loss: 2.293400269682689

Epoch: 5| Step: 7
Training loss: 2.4136404991149902
Validation loss: 2.29084349191317

Epoch: 5| Step: 8
Training loss: 2.395169973373413
Validation loss: 2.3045538138317805

Epoch: 5| Step: 9
Training loss: 1.8847150802612305
Validation loss: 2.3137806282248548

Epoch: 5| Step: 10
Training loss: 2.3195533752441406
Validation loss: 2.3224626869283695

Epoch: 196| Step: 0
Training loss: 2.1570420265197754
Validation loss: 2.3155144773503786

Epoch: 5| Step: 1
Training loss: 1.9258590936660767
Validation loss: 2.3090787984991588

Epoch: 5| Step: 2
Training loss: 2.411024332046509
Validation loss: 2.323936265002015

Epoch: 5| Step: 3
Training loss: 2.2939274311065674
Validation loss: 2.3211288195784374

Epoch: 5| Step: 4
Training loss: 2.989647150039673
Validation loss: 2.331944916837959

Epoch: 5| Step: 5
Training loss: 2.5620369911193848
Validation loss: 2.3401041748703166

Epoch: 5| Step: 6
Training loss: 2.1352550983428955
Validation loss: 2.3383381315456924

Epoch: 5| Step: 7
Training loss: 2.2631473541259766
Validation loss: 2.34960723692371

Epoch: 5| Step: 8
Training loss: 2.8760547637939453
Validation loss: 2.355776325348885

Epoch: 5| Step: 9
Training loss: 2.9098010063171387
Validation loss: 2.3443615026371454

Epoch: 5| Step: 10
Training loss: 2.4438858032226562
Validation loss: 2.348387941237419

Epoch: 197| Step: 0
Training loss: 2.7292933464050293
Validation loss: 2.336411576117239

Epoch: 5| Step: 1
Training loss: 2.130413293838501
Validation loss: 2.3231232422654347

Epoch: 5| Step: 2
Training loss: 2.075261354446411
Validation loss: 2.318544331417289

Epoch: 5| Step: 3
Training loss: 2.93461012840271
Validation loss: 2.3215056696245746

Epoch: 5| Step: 4
Training loss: 3.048323631286621
Validation loss: 2.30796778714785

Epoch: 5| Step: 5
Training loss: 1.8224798440933228
Validation loss: 2.3035971836377214

Epoch: 5| Step: 6
Training loss: 2.037492275238037
Validation loss: 2.310003613912931

Epoch: 5| Step: 7
Training loss: 2.1517765522003174
Validation loss: 2.298663385452763

Epoch: 5| Step: 8
Training loss: 3.467726230621338
Validation loss: 2.302526763690415

Epoch: 5| Step: 9
Training loss: 2.227980136871338
Validation loss: 2.3054538055132796

Epoch: 5| Step: 10
Training loss: 2.286421775817871
Validation loss: 2.3014724177698933

Epoch: 198| Step: 0
Training loss: 2.7863128185272217
Validation loss: 2.293624431856217

Epoch: 5| Step: 1
Training loss: 2.149412155151367
Validation loss: 2.2926016238427933

Epoch: 5| Step: 2
Training loss: 3.1486849784851074
Validation loss: 2.302833790420204

Epoch: 5| Step: 3
Training loss: 2.9971728324890137
Validation loss: 2.3202197141544794

Epoch: 5| Step: 4
Training loss: 1.8823868036270142
Validation loss: 2.318034787331858

Epoch: 5| Step: 5
Training loss: 2.068448066711426
Validation loss: 2.322764499213106

Epoch: 5| Step: 6
Training loss: 1.829053521156311
Validation loss: 2.338839330980855

Epoch: 5| Step: 7
Training loss: 2.395047187805176
Validation loss: 2.3486795169050976

Epoch: 5| Step: 8
Training loss: 2.4077579975128174
Validation loss: 2.350281584647394

Epoch: 5| Step: 9
Training loss: 2.3732666969299316
Validation loss: 2.3497582891935944

Epoch: 5| Step: 10
Training loss: 2.897033214569092
Validation loss: 2.3489914812067503

Epoch: 199| Step: 0
Training loss: 2.4878666400909424
Validation loss: 2.340304711813568

Epoch: 5| Step: 1
Training loss: 2.3239681720733643
Validation loss: 2.3018538823691745

Epoch: 5| Step: 2
Training loss: 2.548755407333374
Validation loss: 2.316684361427061

Epoch: 5| Step: 3
Training loss: 2.333632230758667
Validation loss: 2.3118068518177157

Epoch: 5| Step: 4
Training loss: 2.6132097244262695
Validation loss: 2.310976210460868

Epoch: 5| Step: 5
Training loss: 2.1630706787109375
Validation loss: 2.305665187938239

Epoch: 5| Step: 6
Training loss: 2.5256314277648926
Validation loss: 2.305637582655876

Epoch: 5| Step: 7
Training loss: 2.5084826946258545
Validation loss: 2.3094574148936937

Epoch: 5| Step: 8
Training loss: 2.605225086212158
Validation loss: 2.3007244807417675

Epoch: 5| Step: 9
Training loss: 1.9406623840332031
Validation loss: 2.2974614251044487

Epoch: 5| Step: 10
Training loss: 2.7935616970062256
Validation loss: 2.3076022068659463

Epoch: 200| Step: 0
Training loss: 2.6397502422332764
Validation loss: 2.3365228611935853

Epoch: 5| Step: 1
Training loss: 2.4476535320281982
Validation loss: 2.3720922444456365

Epoch: 5| Step: 2
Training loss: 2.179844856262207
Validation loss: 2.3629318667996313

Epoch: 5| Step: 3
Training loss: 1.9542906284332275
Validation loss: 2.3458835591552076

Epoch: 5| Step: 4
Training loss: 2.079381227493286
Validation loss: 2.346536692752633

Epoch: 5| Step: 5
Training loss: 1.7737090587615967
Validation loss: 2.341039196137459

Epoch: 5| Step: 6
Training loss: 2.2170820236206055
Validation loss: 2.347657388256442

Epoch: 5| Step: 7
Training loss: 2.0657997131347656
Validation loss: 2.3360944717161116

Epoch: 5| Step: 8
Training loss: 3.1076488494873047
Validation loss: 2.3426058061661257

Epoch: 5| Step: 9
Training loss: 3.6977028846740723
Validation loss: 2.3377756354629353

Epoch: 5| Step: 10
Training loss: 2.6888763904571533
Validation loss: 2.339011223085465

Epoch: 201| Step: 0
Training loss: 2.1608614921569824
Validation loss: 2.331870981442031

Epoch: 5| Step: 1
Training loss: 2.116459369659424
Validation loss: 2.306392503041093

Epoch: 5| Step: 2
Training loss: 2.9529144763946533
Validation loss: 2.314467353205527

Epoch: 5| Step: 3
Training loss: 2.2021327018737793
Validation loss: 2.3035735596892652

Epoch: 5| Step: 4
Training loss: 2.5713648796081543
Validation loss: 2.29750334319248

Epoch: 5| Step: 5
Training loss: 2.4898619651794434
Validation loss: 2.2842627186929025

Epoch: 5| Step: 6
Training loss: 3.257657527923584
Validation loss: 2.2886398761503157

Epoch: 5| Step: 7
Training loss: 2.1241726875305176
Validation loss: 2.2875174732618433

Epoch: 5| Step: 8
Training loss: 2.8179004192352295
Validation loss: 2.2746719570570093

Epoch: 5| Step: 9
Training loss: 2.0765628814697266
Validation loss: 2.295633259639945

Epoch: 5| Step: 10
Training loss: 1.9510024785995483
Validation loss: 2.313719557177636

Epoch: 202| Step: 0
Training loss: 2.4528377056121826
Validation loss: 2.306724730358329

Epoch: 5| Step: 1
Training loss: 2.3377463817596436
Validation loss: 2.3094080058477258

Epoch: 5| Step: 2
Training loss: 2.4318032264709473
Validation loss: 2.3183958735517276

Epoch: 5| Step: 3
Training loss: 2.092341899871826
Validation loss: 2.3219108453360935

Epoch: 5| Step: 4
Training loss: 2.1706719398498535
Validation loss: 2.3682623896547543

Epoch: 5| Step: 5
Training loss: 2.4215564727783203
Validation loss: 2.397211688821034

Epoch: 5| Step: 6
Training loss: 2.402723789215088
Validation loss: 2.4077436180524927

Epoch: 5| Step: 7
Training loss: 2.45365571975708
Validation loss: 2.374424554968393

Epoch: 5| Step: 8
Training loss: 2.4956517219543457
Validation loss: 2.334417527721774

Epoch: 5| Step: 9
Training loss: 2.616917133331299
Validation loss: 2.33517385298206

Epoch: 5| Step: 10
Training loss: 2.966777801513672
Validation loss: 2.338905115281382

Epoch: 203| Step: 0
Training loss: 2.168243169784546
Validation loss: 2.3752050015234176

Epoch: 5| Step: 1
Training loss: 2.9254555702209473
Validation loss: 2.3820226474474837

Epoch: 5| Step: 2
Training loss: 2.486743927001953
Validation loss: 2.3843633846570085

Epoch: 5| Step: 3
Training loss: 1.923208236694336
Validation loss: 2.3627822809321906

Epoch: 5| Step: 4
Training loss: 2.674940347671509
Validation loss: 2.3320339392590266

Epoch: 5| Step: 5
Training loss: 2.094529151916504
Validation loss: 2.285407979001281

Epoch: 5| Step: 6
Training loss: 2.9484283924102783
Validation loss: 2.249175146061887

Epoch: 5| Step: 7
Training loss: 2.8248305320739746
Validation loss: 2.2655004737197713

Epoch: 5| Step: 8
Training loss: 2.55082368850708
Validation loss: 2.281701604525248

Epoch: 5| Step: 9
Training loss: 2.233158826828003
Validation loss: 2.2944980282937326

Epoch: 5| Step: 10
Training loss: 2.240701675415039
Validation loss: 2.299450974310598

Epoch: 204| Step: 0
Training loss: 2.958207368850708
Validation loss: 2.29485027123523

Epoch: 5| Step: 1
Training loss: 2.8018429279327393
Validation loss: 2.300519940673664

Epoch: 5| Step: 2
Training loss: 1.9264720678329468
Validation loss: 2.3143345245751004

Epoch: 5| Step: 3
Training loss: 2.0119471549987793
Validation loss: 2.3144024059336674

Epoch: 5| Step: 4
Training loss: 2.6245625019073486
Validation loss: 2.319410826570244

Epoch: 5| Step: 5
Training loss: 2.2896475791931152
Validation loss: 2.3210120329292874

Epoch: 5| Step: 6
Training loss: 2.2121520042419434
Validation loss: 2.339850546211325

Epoch: 5| Step: 7
Training loss: 2.468231201171875
Validation loss: 2.3348712792960544

Epoch: 5| Step: 8
Training loss: 2.3973922729492188
Validation loss: 2.344762714960242

Epoch: 5| Step: 9
Training loss: 2.7947895526885986
Validation loss: 2.363564137489565

Epoch: 5| Step: 10
Training loss: 2.2906177043914795
Validation loss: 2.355187077676096

Epoch: 205| Step: 0
Training loss: 2.7912871837615967
Validation loss: 2.347890297571818

Epoch: 5| Step: 1
Training loss: 2.6014907360076904
Validation loss: 2.3500125279990574

Epoch: 5| Step: 2
Training loss: 2.302036762237549
Validation loss: 2.3426804952724005

Epoch: 5| Step: 3
Training loss: 2.3010735511779785
Validation loss: 2.303291828401627

Epoch: 5| Step: 4
Training loss: 2.683328151702881
Validation loss: 2.3114244117531726

Epoch: 5| Step: 5
Training loss: 2.1756904125213623
Validation loss: 2.3284042663471674

Epoch: 5| Step: 6
Training loss: 2.7573580741882324
Validation loss: 2.3682530387755363

Epoch: 5| Step: 7
Training loss: 1.930285096168518
Validation loss: 2.3304479096525457

Epoch: 5| Step: 8
Training loss: 2.8714828491210938
Validation loss: 2.3179038493863997

Epoch: 5| Step: 9
Training loss: 2.228423595428467
Validation loss: 2.2875876375423965

Epoch: 5| Step: 10
Training loss: 2.178953170776367
Validation loss: 2.280258378674907

Epoch: 206| Step: 0
Training loss: 2.1173832416534424
Validation loss: 2.2737098688720376

Epoch: 5| Step: 1
Training loss: 2.5083224773406982
Validation loss: 2.305073756043629

Epoch: 5| Step: 2
Training loss: 2.5934739112854004
Validation loss: 2.3284695738105365

Epoch: 5| Step: 3
Training loss: 2.9544081687927246
Validation loss: 2.3460628447994107

Epoch: 5| Step: 4
Training loss: 2.4596571922302246
Validation loss: 2.37656303374998

Epoch: 5| Step: 5
Training loss: 2.542999267578125
Validation loss: 2.3483282930107525

Epoch: 5| Step: 6
Training loss: 2.3446998596191406
Validation loss: 2.3148670529806488

Epoch: 5| Step: 7
Training loss: 2.5158214569091797
Validation loss: 2.2816875057835735

Epoch: 5| Step: 8
Training loss: 2.519300699234009
Validation loss: 2.2717712617689565

Epoch: 5| Step: 9
Training loss: 1.858481764793396
Validation loss: 2.2839010966721403

Epoch: 5| Step: 10
Training loss: 2.2307047843933105
Validation loss: 2.3032335594136226

Epoch: 207| Step: 0
Training loss: 2.659177303314209
Validation loss: 2.3305796551448044

Epoch: 5| Step: 1
Training loss: 2.6571993827819824
Validation loss: 2.3564889610454602

Epoch: 5| Step: 2
Training loss: 2.282785415649414
Validation loss: 2.3215731907916326

Epoch: 5| Step: 3
Training loss: 1.7040150165557861
Validation loss: 2.30076120104841

Epoch: 5| Step: 4
Training loss: 2.5960211753845215
Validation loss: 2.2930738054296023

Epoch: 5| Step: 5
Training loss: 2.4367713928222656
Validation loss: 2.3042337817530476

Epoch: 5| Step: 6
Training loss: 2.269505500793457
Validation loss: 2.3058989381277435

Epoch: 5| Step: 7
Training loss: 2.934957981109619
Validation loss: 2.2958111455363612

Epoch: 5| Step: 8
Training loss: 2.158247470855713
Validation loss: 2.278015935292808

Epoch: 5| Step: 9
Training loss: 2.5734639167785645
Validation loss: 2.2748341906455254

Epoch: 5| Step: 10
Training loss: 2.5262935161590576
Validation loss: 2.269933044269521

Epoch: 208| Step: 0
Training loss: 2.5449271202087402
Validation loss: 2.2638237707076536

Epoch: 5| Step: 1
Training loss: 2.6187644004821777
Validation loss: 2.255914775274133

Epoch: 5| Step: 2
Training loss: 2.184937000274658
Validation loss: 2.2713246448065645

Epoch: 5| Step: 3
Training loss: 2.622694253921509
Validation loss: 2.286946960674819

Epoch: 5| Step: 4
Training loss: 1.9083439111709595
Validation loss: 2.311551179937137

Epoch: 5| Step: 5
Training loss: 2.6597511768341064
Validation loss: 2.372073232486684

Epoch: 5| Step: 6
Training loss: 2.3076534271240234
Validation loss: 2.393014666854694

Epoch: 5| Step: 7
Training loss: 2.7972402572631836
Validation loss: 2.349048137664795

Epoch: 5| Step: 8
Training loss: 2.715625286102295
Validation loss: 2.3380887303301083

Epoch: 5| Step: 9
Training loss: 2.4693360328674316
Validation loss: 2.337469716225901

Epoch: 5| Step: 10
Training loss: 1.8473219871520996
Validation loss: 2.3564572590653614

Epoch: 209| Step: 0
Training loss: 2.5559847354888916
Validation loss: 2.367567659706198

Epoch: 5| Step: 1
Training loss: 2.224259853363037
Validation loss: 2.3696555937490156

Epoch: 5| Step: 2
Training loss: 2.125253915786743
Validation loss: 2.3089444893662647

Epoch: 5| Step: 3
Training loss: 3.0439658164978027
Validation loss: 2.2831180198218233

Epoch: 5| Step: 4
Training loss: 2.768216609954834
Validation loss: 2.248528360038675

Epoch: 5| Step: 5
Training loss: 2.43792724609375
Validation loss: 2.25037803188447

Epoch: 5| Step: 6
Training loss: 2.7241482734680176
Validation loss: 2.251848307988977

Epoch: 5| Step: 7
Training loss: 2.460186719894409
Validation loss: 2.2669656763794603

Epoch: 5| Step: 8
Training loss: 2.3128795623779297
Validation loss: 2.2860504914355535

Epoch: 5| Step: 9
Training loss: 2.289231300354004
Validation loss: 2.2839818205884708

Epoch: 5| Step: 10
Training loss: 1.9793272018432617
Validation loss: 2.2763528529033867

Epoch: 210| Step: 0
Training loss: 2.075526475906372
Validation loss: 2.2614493703329437

Epoch: 5| Step: 1
Training loss: 2.19142484664917
Validation loss: 2.264431071537797

Epoch: 5| Step: 2
Training loss: 2.4290771484375
Validation loss: 2.2679061351283902

Epoch: 5| Step: 3
Training loss: 2.8306524753570557
Validation loss: 2.2857139200292607

Epoch: 5| Step: 4
Training loss: 2.317775011062622
Validation loss: 2.3196672598520913

Epoch: 5| Step: 5
Training loss: 2.1372745037078857
Validation loss: 2.3461844664747997

Epoch: 5| Step: 6
Training loss: 2.9797215461730957
Validation loss: 2.3789074831111456

Epoch: 5| Step: 7
Training loss: 2.4413809776306152
Validation loss: 2.375467372196977

Epoch: 5| Step: 8
Training loss: 2.1237666606903076
Validation loss: 2.387844762494487

Epoch: 5| Step: 9
Training loss: 2.2865102291107178
Validation loss: 2.366780056748339

Epoch: 5| Step: 10
Training loss: 2.8260338306427
Validation loss: 2.341132522911154

Epoch: 211| Step: 0
Training loss: 2.3531394004821777
Validation loss: 2.3251062952062136

Epoch: 5| Step: 1
Training loss: 1.759216547012329
Validation loss: 2.302467679464689

Epoch: 5| Step: 2
Training loss: 2.3539555072784424
Validation loss: 2.2997019778015795

Epoch: 5| Step: 3
Training loss: 2.534252405166626
Validation loss: 2.2848921950145433

Epoch: 5| Step: 4
Training loss: 1.797989845275879
Validation loss: 2.279400505045409

Epoch: 5| Step: 5
Training loss: 2.8131840229034424
Validation loss: 2.2877852224534556

Epoch: 5| Step: 6
Training loss: 3.0811195373535156
Validation loss: 2.267212429354268

Epoch: 5| Step: 7
Training loss: 2.3717522621154785
Validation loss: 2.2512989044189453

Epoch: 5| Step: 8
Training loss: 2.796536684036255
Validation loss: 2.233113658043646

Epoch: 5| Step: 9
Training loss: 2.270200252532959
Validation loss: 2.2426790345099663

Epoch: 5| Step: 10
Training loss: 2.508040428161621
Validation loss: 2.242046102400749

Epoch: 212| Step: 0
Training loss: 2.5698297023773193
Validation loss: 2.257173917626822

Epoch: 5| Step: 1
Training loss: 2.45464825630188
Validation loss: 2.2642235653374785

Epoch: 5| Step: 2
Training loss: 2.657527446746826
Validation loss: 2.2638432646310456

Epoch: 5| Step: 3
Training loss: 1.8145538568496704
Validation loss: 2.2941536775199314

Epoch: 5| Step: 4
Training loss: 2.416783571243286
Validation loss: 2.291953771345077

Epoch: 5| Step: 5
Training loss: 2.5341384410858154
Validation loss: 2.291665515592021

Epoch: 5| Step: 6
Training loss: 2.3453333377838135
Validation loss: 2.298692087973318

Epoch: 5| Step: 7
Training loss: 2.545603036880493
Validation loss: 2.335688083402572

Epoch: 5| Step: 8
Training loss: 2.778046131134033
Validation loss: 2.3580246766408286

Epoch: 5| Step: 9
Training loss: 1.9337844848632812
Validation loss: 2.362214724222819

Epoch: 5| Step: 10
Training loss: 2.3018381595611572
Validation loss: 2.338046066222652

Epoch: 213| Step: 0
Training loss: 2.2585384845733643
Validation loss: 2.3438347078138784

Epoch: 5| Step: 1
Training loss: 2.4975340366363525
Validation loss: 2.3190723183334514

Epoch: 5| Step: 2
Training loss: 2.059539318084717
Validation loss: 2.325059921510758

Epoch: 5| Step: 3
Training loss: 2.1233439445495605
Validation loss: 2.311850174780815

Epoch: 5| Step: 4
Training loss: 2.067425012588501
Validation loss: 2.316554331010388

Epoch: 5| Step: 5
Training loss: 2.9464404582977295
Validation loss: 2.3076515146481094

Epoch: 5| Step: 6
Training loss: 2.5337812900543213
Validation loss: 2.274860296198117

Epoch: 5| Step: 7
Training loss: 2.631757974624634
Validation loss: 2.264543484616023

Epoch: 5| Step: 8
Training loss: 2.618565320968628
Validation loss: 2.2621080131940943

Epoch: 5| Step: 9
Training loss: 2.396073818206787
Validation loss: 2.2387192044206845

Epoch: 5| Step: 10
Training loss: 2.0095443725585938
Validation loss: 2.228672009642406

Epoch: 214| Step: 0
Training loss: 3.4763031005859375
Validation loss: 2.2322889374148462

Epoch: 5| Step: 1
Training loss: 2.229722499847412
Validation loss: 2.2286898218175417

Epoch: 5| Step: 2
Training loss: 2.776313066482544
Validation loss: 2.2475583181586316

Epoch: 5| Step: 3
Training loss: 2.5048460960388184
Validation loss: 2.261201097119239

Epoch: 5| Step: 4
Training loss: 2.3310115337371826
Validation loss: 2.296683344789731

Epoch: 5| Step: 5
Training loss: 2.088381290435791
Validation loss: 2.307386172715054

Epoch: 5| Step: 6
Training loss: 2.3066539764404297
Validation loss: 2.292600711186727

Epoch: 5| Step: 7
Training loss: 2.3333396911621094
Validation loss: 2.305491626903575

Epoch: 5| Step: 8
Training loss: 2.1769373416900635
Validation loss: 2.309991472510881

Epoch: 5| Step: 9
Training loss: 1.5511647462844849
Validation loss: 2.3056677720879994

Epoch: 5| Step: 10
Training loss: 2.362025022506714
Validation loss: 2.3061317961703063

Epoch: 215| Step: 0
Training loss: 1.9234178066253662
Validation loss: 2.3183055347011936

Epoch: 5| Step: 1
Training loss: 2.614696979522705
Validation loss: 2.338632175999303

Epoch: 5| Step: 2
Training loss: 2.606614351272583
Validation loss: 2.340887556793869

Epoch: 5| Step: 3
Training loss: 2.869692325592041
Validation loss: 2.334968961695189

Epoch: 5| Step: 4
Training loss: 2.2480521202087402
Validation loss: 2.3166937956246

Epoch: 5| Step: 5
Training loss: 2.2554545402526855
Validation loss: 2.3000732698748187

Epoch: 5| Step: 6
Training loss: 2.6369919776916504
Validation loss: 2.2921457572649886

Epoch: 5| Step: 7
Training loss: 2.260871410369873
Validation loss: 2.284362999341821

Epoch: 5| Step: 8
Training loss: 2.3877997398376465
Validation loss: 2.279899538204234

Epoch: 5| Step: 9
Training loss: 2.143970012664795
Validation loss: 2.270684088430097

Epoch: 5| Step: 10
Training loss: 2.209774971008301
Validation loss: 2.2862812549837175

Epoch: 216| Step: 0
Training loss: 2.343970537185669
Validation loss: 2.2843103472904494

Epoch: 5| Step: 1
Training loss: 2.362408399581909
Validation loss: 2.29157139537155

Epoch: 5| Step: 2
Training loss: 2.5045158863067627
Validation loss: 2.2809015909830728

Epoch: 5| Step: 3
Training loss: 2.5430283546447754
Validation loss: 2.2692438787029636

Epoch: 5| Step: 4
Training loss: 2.4483227729797363
Validation loss: 2.264765421549479

Epoch: 5| Step: 5
Training loss: 2.5386455059051514
Validation loss: 2.265056851089642

Epoch: 5| Step: 6
Training loss: 1.6910902261734009
Validation loss: 2.262710136751975

Epoch: 5| Step: 7
Training loss: 2.1662161350250244
Validation loss: 2.2786535550189275

Epoch: 5| Step: 8
Training loss: 1.8528242111206055
Validation loss: 2.2953287709143853

Epoch: 5| Step: 9
Training loss: 2.6340644359588623
Validation loss: 2.2726262179754113

Epoch: 5| Step: 10
Training loss: 2.9905972480773926
Validation loss: 2.2940359910329184

Epoch: 217| Step: 0
Training loss: 2.20373272895813
Validation loss: 2.282883136503158

Epoch: 5| Step: 1
Training loss: 2.5219929218292236
Validation loss: 2.294322770128968

Epoch: 5| Step: 2
Training loss: 2.347733736038208
Validation loss: 2.292889307903987

Epoch: 5| Step: 3
Training loss: 2.2374329566955566
Validation loss: 2.2662168805317213

Epoch: 5| Step: 4
Training loss: 2.5834569931030273
Validation loss: 2.2750535267655567

Epoch: 5| Step: 5
Training loss: 2.254230499267578
Validation loss: 2.2981882864429104

Epoch: 5| Step: 6
Training loss: 2.194211483001709
Validation loss: 2.291061944859002

Epoch: 5| Step: 7
Training loss: 2.4715518951416016
Validation loss: 2.29900130661585

Epoch: 5| Step: 8
Training loss: 2.5230796337127686
Validation loss: 2.33709777298794

Epoch: 5| Step: 9
Training loss: 2.8513004779815674
Validation loss: 2.3762294912850983

Epoch: 5| Step: 10
Training loss: 1.9401763677597046
Validation loss: 2.3718974026300574

Epoch: 218| Step: 0
Training loss: 1.4251625537872314
Validation loss: 2.2802371286576792

Epoch: 5| Step: 1
Training loss: 2.9436287879943848
Validation loss: 2.2573934729381273

Epoch: 5| Step: 2
Training loss: 2.5975470542907715
Validation loss: 2.2525151339910363

Epoch: 5| Step: 3
Training loss: 2.451831340789795
Validation loss: 2.2548375309154554

Epoch: 5| Step: 4
Training loss: 2.68986439704895
Validation loss: 2.259378743428056

Epoch: 5| Step: 5
Training loss: 2.4018120765686035
Validation loss: 2.2681572437286377

Epoch: 5| Step: 6
Training loss: 2.3567817211151123
Validation loss: 2.293348122668523

Epoch: 5| Step: 7
Training loss: 2.226818561553955
Validation loss: 2.312861596384356

Epoch: 5| Step: 8
Training loss: 3.0130927562713623
Validation loss: 2.3051076473728305

Epoch: 5| Step: 9
Training loss: 2.093219757080078
Validation loss: 2.3099350006349626

Epoch: 5| Step: 10
Training loss: 2.063413381576538
Validation loss: 2.2850415245179208

Epoch: 219| Step: 0
Training loss: 2.8193016052246094
Validation loss: 2.266949804880286

Epoch: 5| Step: 1
Training loss: 2.623384952545166
Validation loss: 2.25024220507632

Epoch: 5| Step: 2
Training loss: 2.5503578186035156
Validation loss: 2.2543676386597338

Epoch: 5| Step: 3
Training loss: 1.9521957635879517
Validation loss: 2.2631358600431875

Epoch: 5| Step: 4
Training loss: 2.3537545204162598
Validation loss: 2.3028115149467223

Epoch: 5| Step: 5
Training loss: 2.5677342414855957
Validation loss: 2.301255485062958

Epoch: 5| Step: 6
Training loss: 1.8872419595718384
Validation loss: 2.321915964926443

Epoch: 5| Step: 7
Training loss: 3.030885696411133
Validation loss: 2.299052156427855

Epoch: 5| Step: 8
Training loss: 2.6207287311553955
Validation loss: 2.268044435849754

Epoch: 5| Step: 9
Training loss: 1.8713102340698242
Validation loss: 2.257650985512682

Epoch: 5| Step: 10
Training loss: 2.0556790828704834
Validation loss: 2.2520886826258835

Epoch: 220| Step: 0
Training loss: 1.6216821670532227
Validation loss: 2.2585157348263647

Epoch: 5| Step: 1
Training loss: 2.691218614578247
Validation loss: 2.297413408115346

Epoch: 5| Step: 2
Training loss: 2.751354932785034
Validation loss: 2.3166847613550003

Epoch: 5| Step: 3
Training loss: 2.474287509918213
Validation loss: 2.3201497729106615

Epoch: 5| Step: 4
Training loss: 2.245598316192627
Validation loss: 2.3053203962182485

Epoch: 5| Step: 5
Training loss: 1.4510124921798706
Validation loss: 2.292578202421947

Epoch: 5| Step: 6
Training loss: 3.0367960929870605
Validation loss: 2.2994348515746412

Epoch: 5| Step: 7
Training loss: 2.3000617027282715
Validation loss: 2.2985892270200994

Epoch: 5| Step: 8
Training loss: 2.577893018722534
Validation loss: 2.309541613824906

Epoch: 5| Step: 9
Training loss: 2.6221811771392822
Validation loss: 2.307583312834463

Epoch: 5| Step: 10
Training loss: 2.327821969985962
Validation loss: 2.3030311779309343

Epoch: 221| Step: 0
Training loss: 1.8912101984024048
Validation loss: 2.2597540655443744

Epoch: 5| Step: 1
Training loss: 2.391404628753662
Validation loss: 2.249284380225725

Epoch: 5| Step: 2
Training loss: 2.3283135890960693
Validation loss: 2.256085841886459

Epoch: 5| Step: 3
Training loss: 2.1166763305664062
Validation loss: 2.267603449924018

Epoch: 5| Step: 4
Training loss: 2.7447032928466797
Validation loss: 2.2824976854426886

Epoch: 5| Step: 5
Training loss: 2.0125534534454346
Validation loss: 2.27682154152983

Epoch: 5| Step: 6
Training loss: 2.3786239624023438
Validation loss: 2.269596222908266

Epoch: 5| Step: 7
Training loss: 2.3667733669281006
Validation loss: 2.2588812740900184

Epoch: 5| Step: 8
Training loss: 2.5893783569335938
Validation loss: 2.270825678302396

Epoch: 5| Step: 9
Training loss: 2.2935702800750732
Validation loss: 2.2775347027727353

Epoch: 5| Step: 10
Training loss: 2.8824269771575928
Validation loss: 2.296208408571059

Epoch: 222| Step: 0
Training loss: 1.8620548248291016
Validation loss: 2.2934527384337557

Epoch: 5| Step: 1
Training loss: 2.4202256202697754
Validation loss: 2.3133982996786795

Epoch: 5| Step: 2
Training loss: 1.9372999668121338
Validation loss: 2.330615920405234

Epoch: 5| Step: 3
Training loss: 2.425241470336914
Validation loss: 2.334007245238109

Epoch: 5| Step: 4
Training loss: 2.5160226821899414
Validation loss: 2.3224459232822543

Epoch: 5| Step: 5
Training loss: 2.6388192176818848
Validation loss: 2.3132375107016614

Epoch: 5| Step: 6
Training loss: 2.482060194015503
Validation loss: 2.3145929100692912

Epoch: 5| Step: 7
Training loss: 1.9916083812713623
Validation loss: 2.2912131817110124

Epoch: 5| Step: 8
Training loss: 2.5498290061950684
Validation loss: 2.280203555219917

Epoch: 5| Step: 9
Training loss: 2.880122661590576
Validation loss: 2.2538931728691183

Epoch: 5| Step: 10
Training loss: 2.122490167617798
Validation loss: 2.2420082861377346

Epoch: 223| Step: 0
Training loss: 2.4976367950439453
Validation loss: 2.212388002744285

Epoch: 5| Step: 1
Training loss: 2.3973257541656494
Validation loss: 2.2238438001243015

Epoch: 5| Step: 2
Training loss: 2.509542465209961
Validation loss: 2.2218313601709183

Epoch: 5| Step: 3
Training loss: 2.5037589073181152
Validation loss: 2.2337164084116616

Epoch: 5| Step: 4
Training loss: 2.27502703666687
Validation loss: 2.23146939662195

Epoch: 5| Step: 5
Training loss: 2.32533597946167
Validation loss: 2.2525124396047285

Epoch: 5| Step: 6
Training loss: 2.2617878913879395
Validation loss: 2.254947300880186

Epoch: 5| Step: 7
Training loss: 1.92014479637146
Validation loss: 2.260748137709915

Epoch: 5| Step: 8
Training loss: 2.07891583442688
Validation loss: 2.273729257686164

Epoch: 5| Step: 9
Training loss: 2.6816134452819824
Validation loss: 2.280339648646693

Epoch: 5| Step: 10
Training loss: 2.2233517169952393
Validation loss: 2.2827709310798237

Epoch: 224| Step: 0
Training loss: 2.803680419921875
Validation loss: 2.2814155599122405

Epoch: 5| Step: 1
Training loss: 2.4468555450439453
Validation loss: 2.271907309050201

Epoch: 5| Step: 2
Training loss: 2.2939486503601074
Validation loss: 2.29709279921747

Epoch: 5| Step: 3
Training loss: 2.390956401824951
Validation loss: 2.289738990927255

Epoch: 5| Step: 4
Training loss: 2.3019118309020996
Validation loss: 2.2836862943505727

Epoch: 5| Step: 5
Training loss: 2.1465373039245605
Validation loss: 2.283995377120151

Epoch: 5| Step: 6
Training loss: 2.0244390964508057
Validation loss: 2.2825649630638862

Epoch: 5| Step: 7
Training loss: 2.2636187076568604
Validation loss: 2.2714093872295913

Epoch: 5| Step: 8
Training loss: 1.7166671752929688
Validation loss: 2.2809026343848116

Epoch: 5| Step: 9
Training loss: 2.686304807662964
Validation loss: 2.2910455016679663

Epoch: 5| Step: 10
Training loss: 2.478236675262451
Validation loss: 2.290604506769488

Epoch: 225| Step: 0
Training loss: 2.80767560005188
Validation loss: 2.2816616335222797

Epoch: 5| Step: 1
Training loss: 2.735313892364502
Validation loss: 2.2628360589345298

Epoch: 5| Step: 2
Training loss: 1.6140722036361694
Validation loss: 2.2408369177131244

Epoch: 5| Step: 3
Training loss: 2.095797061920166
Validation loss: 2.2444993603614067

Epoch: 5| Step: 4
Training loss: 2.7232041358947754
Validation loss: 2.2272920557247695

Epoch: 5| Step: 5
Training loss: 2.057147264480591
Validation loss: 2.228071633205619

Epoch: 5| Step: 6
Training loss: 2.6693358421325684
Validation loss: 2.253309993333714

Epoch: 5| Step: 7
Training loss: 1.976210355758667
Validation loss: 2.260863211847121

Epoch: 5| Step: 8
Training loss: 2.1299259662628174
Validation loss: 2.280894466625747

Epoch: 5| Step: 9
Training loss: 2.4568302631378174
Validation loss: 2.2852579137330413

Epoch: 5| Step: 10
Training loss: 2.2239303588867188
Validation loss: 2.291131091374223

Epoch: 226| Step: 0
Training loss: 2.198286771774292
Validation loss: 2.3076128652018886

Epoch: 5| Step: 1
Training loss: 2.579868793487549
Validation loss: 2.3265761316463514

Epoch: 5| Step: 2
Training loss: 2.7031643390655518
Validation loss: 2.324140905052103

Epoch: 5| Step: 3
Training loss: 2.8698668479919434
Validation loss: 2.3327004037877566

Epoch: 5| Step: 4
Training loss: 1.7281116247177124
Validation loss: 2.3243938338372017

Epoch: 5| Step: 5
Training loss: 2.0230021476745605
Validation loss: 2.3025566198492564

Epoch: 5| Step: 6
Training loss: 2.6105053424835205
Validation loss: 2.2970713159089446

Epoch: 5| Step: 7
Training loss: 2.3813867568969727
Validation loss: 2.2991359772220736

Epoch: 5| Step: 8
Training loss: 2.1754822731018066
Validation loss: 2.2969129072722567

Epoch: 5| Step: 9
Training loss: 2.1321487426757812
Validation loss: 2.273973306020101

Epoch: 5| Step: 10
Training loss: 2.0353403091430664
Validation loss: 2.2764008737379506

Epoch: 227| Step: 0
Training loss: 2.0986170768737793
Validation loss: 2.2785008107462237

Epoch: 5| Step: 1
Training loss: 2.460277557373047
Validation loss: 2.2442074437295236

Epoch: 5| Step: 2
Training loss: 2.3729333877563477
Validation loss: 2.2293538355058238

Epoch: 5| Step: 3
Training loss: 2.1627001762390137
Validation loss: 2.2159666002437635

Epoch: 5| Step: 4
Training loss: 2.606638193130493
Validation loss: 2.2200258752351165

Epoch: 5| Step: 5
Training loss: 2.3664944171905518
Validation loss: 2.2232117729802288

Epoch: 5| Step: 6
Training loss: 2.3140408992767334
Validation loss: 2.2258847221251457

Epoch: 5| Step: 7
Training loss: 2.090057849884033
Validation loss: 2.249063850730978

Epoch: 5| Step: 8
Training loss: 2.5184032917022705
Validation loss: 2.242794498320549

Epoch: 5| Step: 9
Training loss: 2.501483201980591
Validation loss: 2.2499847091654295

Epoch: 5| Step: 10
Training loss: 1.936554193496704
Validation loss: 2.2565890999250513

Epoch: 228| Step: 0
Training loss: 2.331359386444092
Validation loss: 2.276640256245931

Epoch: 5| Step: 1
Training loss: 2.6050658226013184
Validation loss: 2.2845406891197286

Epoch: 5| Step: 2
Training loss: 2.215134859085083
Validation loss: 2.321770921830208

Epoch: 5| Step: 3
Training loss: 1.9042303562164307
Validation loss: 2.3492267516351517

Epoch: 5| Step: 4
Training loss: 2.740004539489746
Validation loss: 2.344119874379968

Epoch: 5| Step: 5
Training loss: 2.231961250305176
Validation loss: 2.3242125972624748

Epoch: 5| Step: 6
Training loss: 1.8013639450073242
Validation loss: 2.331374752906061

Epoch: 5| Step: 7
Training loss: 2.1945903301239014
Validation loss: 2.3264027052028204

Epoch: 5| Step: 8
Training loss: 2.301217794418335
Validation loss: 2.3179719781362884

Epoch: 5| Step: 9
Training loss: 2.229649066925049
Validation loss: 2.298379800652945

Epoch: 5| Step: 10
Training loss: 3.2608535289764404
Validation loss: 2.268933355167348

Epoch: 229| Step: 0
Training loss: 2.205564022064209
Validation loss: 2.2395479858562513

Epoch: 5| Step: 1
Training loss: 1.751251220703125
Validation loss: 2.2110676380895797

Epoch: 5| Step: 2
Training loss: 1.8127501010894775
Validation loss: 2.2341130805271927

Epoch: 5| Step: 3
Training loss: 2.032022476196289
Validation loss: 2.255739793982557

Epoch: 5| Step: 4
Training loss: 2.7617621421813965
Validation loss: 2.2504990049587783

Epoch: 5| Step: 5
Training loss: 2.3900232315063477
Validation loss: 2.236285371165122

Epoch: 5| Step: 6
Training loss: 2.8721652030944824
Validation loss: 2.239282799023454

Epoch: 5| Step: 7
Training loss: 2.3580222129821777
Validation loss: 2.2157893411574827

Epoch: 5| Step: 8
Training loss: 2.5899479389190674
Validation loss: 2.225405731508809

Epoch: 5| Step: 9
Training loss: 2.3437657356262207
Validation loss: 2.218702886694221

Epoch: 5| Step: 10
Training loss: 2.330106735229492
Validation loss: 2.2285457221410607

Epoch: 230| Step: 0
Training loss: 1.9580647945404053
Validation loss: 2.234439524271155

Epoch: 5| Step: 1
Training loss: 2.359947919845581
Validation loss: 2.2709392834735174

Epoch: 5| Step: 2
Training loss: 2.4727492332458496
Validation loss: 2.283821036738734

Epoch: 5| Step: 3
Training loss: 2.215423345565796
Validation loss: 2.2998630385245047

Epoch: 5| Step: 4
Training loss: 2.7450053691864014
Validation loss: 2.3158817880897113

Epoch: 5| Step: 5
Training loss: 2.5955471992492676
Validation loss: 2.3202673747975338

Epoch: 5| Step: 6
Training loss: 1.8542630672454834
Validation loss: 2.2966633150654454

Epoch: 5| Step: 7
Training loss: 2.4208927154541016
Validation loss: 2.283415896918184

Epoch: 5| Step: 8
Training loss: 2.5949363708496094
Validation loss: 2.2786630674075057

Epoch: 5| Step: 9
Training loss: 2.2259743213653564
Validation loss: 2.2689443993312057

Epoch: 5| Step: 10
Training loss: 1.771964192390442
Validation loss: 2.2751569158287457

Epoch: 231| Step: 0
Training loss: 2.1372408866882324
Validation loss: 2.2539731097477738

Epoch: 5| Step: 1
Training loss: 1.6411006450653076
Validation loss: 2.234924179251476

Epoch: 5| Step: 2
Training loss: 2.238349199295044
Validation loss: 2.2400341623572895

Epoch: 5| Step: 3
Training loss: 3.22697377204895
Validation loss: 2.242356343935895

Epoch: 5| Step: 4
Training loss: 2.420955181121826
Validation loss: 2.244789090207828

Epoch: 5| Step: 5
Training loss: 1.9373199939727783
Validation loss: 2.2489464334262315

Epoch: 5| Step: 6
Training loss: 2.508923292160034
Validation loss: 2.2477295321802937

Epoch: 5| Step: 7
Training loss: 2.1352195739746094
Validation loss: 2.221456518737219

Epoch: 5| Step: 8
Training loss: 2.407583713531494
Validation loss: 2.2292255227283766

Epoch: 5| Step: 9
Training loss: 1.8881571292877197
Validation loss: 2.2282802417714107

Epoch: 5| Step: 10
Training loss: 2.715015411376953
Validation loss: 2.263144270066292

Epoch: 232| Step: 0
Training loss: 2.131713390350342
Validation loss: 2.2585387191464825

Epoch: 5| Step: 1
Training loss: 2.6195151805877686
Validation loss: 2.261044566349317

Epoch: 5| Step: 2
Training loss: 2.0232865810394287
Validation loss: 2.2772997809994604

Epoch: 5| Step: 3
Training loss: 2.1111996173858643
Validation loss: 2.2911262973662345

Epoch: 5| Step: 4
Training loss: 1.3660962581634521
Validation loss: 2.279182464845719

Epoch: 5| Step: 5
Training loss: 2.9699063301086426
Validation loss: 2.273887167694748

Epoch: 5| Step: 6
Training loss: 2.443652629852295
Validation loss: 2.2735350901080715

Epoch: 5| Step: 7
Training loss: 3.0947232246398926
Validation loss: 2.2661448986299577

Epoch: 5| Step: 8
Training loss: 2.5104713439941406
Validation loss: 2.2865706669386996

Epoch: 5| Step: 9
Training loss: 1.570643663406372
Validation loss: 2.29411405645391

Epoch: 5| Step: 10
Training loss: 2.3555636405944824
Validation loss: 2.2720389468695528

Epoch: 233| Step: 0
Training loss: 2.0792465209960938
Validation loss: 2.2740163546736523

Epoch: 5| Step: 1
Training loss: 1.9154624938964844
Validation loss: 2.2707728724325857

Epoch: 5| Step: 2
Training loss: 2.8110687732696533
Validation loss: 2.2736739791849607

Epoch: 5| Step: 3
Training loss: 2.2265267372131348
Validation loss: 2.260312041928691

Epoch: 5| Step: 4
Training loss: 2.6230580806732178
Validation loss: 2.2552103073366228

Epoch: 5| Step: 5
Training loss: 2.529959201812744
Validation loss: 2.2262086150466756

Epoch: 5| Step: 6
Training loss: 2.0171329975128174
Validation loss: 2.2336472747146443

Epoch: 5| Step: 7
Training loss: 1.9025131464004517
Validation loss: 2.225581838238624

Epoch: 5| Step: 8
Training loss: 2.3447365760803223
Validation loss: 2.225647690475628

Epoch: 5| Step: 9
Training loss: 1.9021984338760376
Validation loss: 2.237550840582899

Epoch: 5| Step: 10
Training loss: 2.570051670074463
Validation loss: 2.2577863906019475

Epoch: 234| Step: 0
Training loss: 2.545236110687256
Validation loss: 2.245230064597181

Epoch: 5| Step: 1
Training loss: 1.4575647115707397
Validation loss: 2.2604305000715357

Epoch: 5| Step: 2
Training loss: 2.046475887298584
Validation loss: 2.257300966529436

Epoch: 5| Step: 3
Training loss: 1.6323045492172241
Validation loss: 2.2662300166263374

Epoch: 5| Step: 4
Training loss: 2.199939250946045
Validation loss: 2.287034467984271

Epoch: 5| Step: 5
Training loss: 2.116514205932617
Validation loss: 2.2968210840737946

Epoch: 5| Step: 6
Training loss: 2.30115008354187
Validation loss: 2.274172782897949

Epoch: 5| Step: 7
Training loss: 2.4442410469055176
Validation loss: 2.2711453886442285

Epoch: 5| Step: 8
Training loss: 2.974259853363037
Validation loss: 2.288717878762112

Epoch: 5| Step: 9
Training loss: 2.629232883453369
Validation loss: 2.2808557633430726

Epoch: 5| Step: 10
Training loss: 2.614081621170044
Validation loss: 2.265024185180664

Epoch: 235| Step: 0
Training loss: 2.49322247505188
Validation loss: 2.2295108149128575

Epoch: 5| Step: 1
Training loss: 2.037205457687378
Validation loss: 2.2312631248145975

Epoch: 5| Step: 2
Training loss: 2.2460241317749023
Validation loss: 2.2121293531951083

Epoch: 5| Step: 3
Training loss: 1.7279033660888672
Validation loss: 2.205359241013886

Epoch: 5| Step: 4
Training loss: 2.7293248176574707
Validation loss: 2.2054510783123713

Epoch: 5| Step: 5
Training loss: 2.6327433586120605
Validation loss: 2.212065709534512

Epoch: 5| Step: 6
Training loss: 2.387843370437622
Validation loss: 2.2178494007356706

Epoch: 5| Step: 7
Training loss: 2.4128568172454834
Validation loss: 2.247728757960822

Epoch: 5| Step: 8
Training loss: 1.5579547882080078
Validation loss: 2.2679925490451116

Epoch: 5| Step: 9
Training loss: 2.803109884262085
Validation loss: 2.270887169786679

Epoch: 5| Step: 10
Training loss: 1.7557225227355957
Validation loss: 2.2623249356464674

Epoch: 236| Step: 0
Training loss: 2.661632776260376
Validation loss: 2.269511697112873

Epoch: 5| Step: 1
Training loss: 2.0243782997131348
Validation loss: 2.2812200900047057

Epoch: 5| Step: 2
Training loss: 2.476067066192627
Validation loss: 2.263595355454312

Epoch: 5| Step: 3
Training loss: 2.348057270050049
Validation loss: 2.2460492195621615

Epoch: 5| Step: 4
Training loss: 1.5607486963272095
Validation loss: 2.2262994371434695

Epoch: 5| Step: 5
Training loss: 2.1129837036132812
Validation loss: 2.231686366501675

Epoch: 5| Step: 6
Training loss: 2.489598512649536
Validation loss: 2.2096596763980005

Epoch: 5| Step: 7
Training loss: 2.3438541889190674
Validation loss: 2.227917835276614

Epoch: 5| Step: 8
Training loss: 2.527156114578247
Validation loss: 2.2412688398873932

Epoch: 5| Step: 9
Training loss: 2.0686757564544678
Validation loss: 2.242409716370285

Epoch: 5| Step: 10
Training loss: 2.206376552581787
Validation loss: 2.2688548513638076

Epoch: 237| Step: 0
Training loss: 2.5485317707061768
Validation loss: 2.2973048148616666

Epoch: 5| Step: 1
Training loss: 1.6501436233520508
Validation loss: 2.293351158019035

Epoch: 5| Step: 2
Training loss: 2.5259737968444824
Validation loss: 2.3293973656110865

Epoch: 5| Step: 3
Training loss: 2.3623647689819336
Validation loss: 2.3024581734852125

Epoch: 5| Step: 4
Training loss: 1.8589894771575928
Validation loss: 2.3374247576600764

Epoch: 5| Step: 5
Training loss: 2.039691209793091
Validation loss: 2.341666570273779

Epoch: 5| Step: 6
Training loss: 2.352999448776245
Validation loss: 2.32500797189692

Epoch: 5| Step: 7
Training loss: 2.461594343185425
Validation loss: 2.293337446387096

Epoch: 5| Step: 8
Training loss: 3.094186544418335
Validation loss: 2.3008076554985455

Epoch: 5| Step: 9
Training loss: 1.9870761632919312
Validation loss: 2.2790137349918322

Epoch: 5| Step: 10
Training loss: 1.818010687828064
Validation loss: 2.2532447358613372

Epoch: 238| Step: 0
Training loss: 1.8705337047576904
Validation loss: 2.285597183371103

Epoch: 5| Step: 1
Training loss: 2.572852373123169
Validation loss: 2.303168781342045

Epoch: 5| Step: 2
Training loss: 2.141144275665283
Validation loss: 2.2634082583970923

Epoch: 5| Step: 3
Training loss: 2.2498931884765625
Validation loss: 2.2418059866915465

Epoch: 5| Step: 4
Training loss: 1.9570871591567993
Validation loss: 2.225833013493528

Epoch: 5| Step: 5
Training loss: 2.2899904251098633
Validation loss: 2.182403859271798

Epoch: 5| Step: 6
Training loss: 2.4453649520874023
Validation loss: 2.175819689227689

Epoch: 5| Step: 7
Training loss: 2.035820960998535
Validation loss: 2.1625675591089393

Epoch: 5| Step: 8
Training loss: 2.4606478214263916
Validation loss: 2.1821979861105643

Epoch: 5| Step: 9
Training loss: 2.3992209434509277
Validation loss: 2.175778217213128

Epoch: 5| Step: 10
Training loss: 2.610908031463623
Validation loss: 2.2094846822882213

Epoch: 239| Step: 0
Training loss: 2.6554923057556152
Validation loss: 2.2301153547020367

Epoch: 5| Step: 1
Training loss: 1.919284462928772
Validation loss: 2.235359050894296

Epoch: 5| Step: 2
Training loss: 2.1787781715393066
Validation loss: 2.215095338001046

Epoch: 5| Step: 3
Training loss: 2.1070473194122314
Validation loss: 2.2202159538063952

Epoch: 5| Step: 4
Training loss: 1.8253307342529297
Validation loss: 2.1968085124928463

Epoch: 5| Step: 5
Training loss: 2.7188384532928467
Validation loss: 2.2031997737064155

Epoch: 5| Step: 6
Training loss: 2.008242607116699
Validation loss: 2.227523701165312

Epoch: 5| Step: 7
Training loss: 2.5878543853759766
Validation loss: 2.2571223705045638

Epoch: 5| Step: 8
Training loss: 1.9376659393310547
Validation loss: 2.256890731473123

Epoch: 5| Step: 9
Training loss: 2.2923481464385986
Validation loss: 2.230600518565024

Epoch: 5| Step: 10
Training loss: 2.4408955574035645
Validation loss: 2.2273172396485523

Epoch: 240| Step: 0
Training loss: 1.9261175394058228
Validation loss: 2.23144801457723

Epoch: 5| Step: 1
Training loss: 1.8430416584014893
Validation loss: 2.2440753649639826

Epoch: 5| Step: 2
Training loss: 1.701519250869751
Validation loss: 2.261910296255542

Epoch: 5| Step: 3
Training loss: 2.1814024448394775
Validation loss: 2.260726446746498

Epoch: 5| Step: 4
Training loss: 2.007352113723755
Validation loss: 2.2759814852027485

Epoch: 5| Step: 5
Training loss: 2.2203145027160645
Validation loss: 2.2728479216175694

Epoch: 5| Step: 6
Training loss: 2.4983863830566406
Validation loss: 2.2861089732057307

Epoch: 5| Step: 7
Training loss: 2.2506253719329834
Validation loss: 2.276153959253783

Epoch: 5| Step: 8
Training loss: 1.8769499063491821
Validation loss: 2.2817990497876237

Epoch: 5| Step: 9
Training loss: 3.307131290435791
Validation loss: 2.2807222309932915

Epoch: 5| Step: 10
Training loss: 2.7323310375213623
Validation loss: 2.3001774921212146

Epoch: 241| Step: 0
Training loss: 2.0897579193115234
Validation loss: 2.284194125924059

Epoch: 5| Step: 1
Training loss: 2.2505860328674316
Validation loss: 2.271153699967169

Epoch: 5| Step: 2
Training loss: 2.8422813415527344
Validation loss: 2.230906045565041

Epoch: 5| Step: 3
Training loss: 1.908785104751587
Validation loss: 2.2111991913087907

Epoch: 5| Step: 4
Training loss: 2.0506107807159424
Validation loss: 2.201085816147507

Epoch: 5| Step: 5
Training loss: 2.735125780105591
Validation loss: 2.19717598730518

Epoch: 5| Step: 6
Training loss: 2.06559419631958
Validation loss: 2.2004654740774505

Epoch: 5| Step: 7
Training loss: 1.8982740640640259
Validation loss: 2.184460675844582

Epoch: 5| Step: 8
Training loss: 2.329174518585205
Validation loss: 2.1758407251809233

Epoch: 5| Step: 9
Training loss: 2.1145288944244385
Validation loss: 2.1765133232198735

Epoch: 5| Step: 10
Training loss: 2.2144691944122314
Validation loss: 2.1711660533822994

Epoch: 242| Step: 0
Training loss: 1.8108608722686768
Validation loss: 2.1965377202597995

Epoch: 5| Step: 1
Training loss: 2.7369282245635986
Validation loss: 2.2311031779935284

Epoch: 5| Step: 2
Training loss: 2.427319288253784
Validation loss: 2.2353866523311985

Epoch: 5| Step: 3
Training loss: 2.310637950897217
Validation loss: 2.243843029904109

Epoch: 5| Step: 4
Training loss: 2.1136412620544434
Validation loss: 2.2676532729979484

Epoch: 5| Step: 5
Training loss: 1.8643817901611328
Validation loss: 2.284740786398611

Epoch: 5| Step: 6
Training loss: 2.1799521446228027
Validation loss: 2.2848459982102916

Epoch: 5| Step: 7
Training loss: 2.116895914077759
Validation loss: 2.278590976551015

Epoch: 5| Step: 8
Training loss: 2.296250581741333
Validation loss: 2.2792845938795354

Epoch: 5| Step: 9
Training loss: 1.6700553894042969
Validation loss: 2.2755244970321655

Epoch: 5| Step: 10
Training loss: 2.927013635635376
Validation loss: 2.24068703446337

Epoch: 243| Step: 0
Training loss: 1.7336032390594482
Validation loss: 2.2380321564212924

Epoch: 5| Step: 1
Training loss: 2.959754467010498
Validation loss: 2.206607477639311

Epoch: 5| Step: 2
Training loss: 2.1049375534057617
Validation loss: 2.1846723146336053

Epoch: 5| Step: 3
Training loss: 2.449528932571411
Validation loss: 2.160806825084071

Epoch: 5| Step: 4
Training loss: 2.313582181930542
Validation loss: 2.1962455664911578

Epoch: 5| Step: 5
Training loss: 1.8154232501983643
Validation loss: 2.190930438298051

Epoch: 5| Step: 6
Training loss: 2.2708821296691895
Validation loss: 2.2027780535400554

Epoch: 5| Step: 7
Training loss: 1.5051865577697754
Validation loss: 2.1891363410539526

Epoch: 5| Step: 8
Training loss: 2.2903666496276855
Validation loss: 2.2217222208617837

Epoch: 5| Step: 9
Training loss: 2.6169822216033936
Validation loss: 2.246508067654025

Epoch: 5| Step: 10
Training loss: 2.2768616676330566
Validation loss: 2.2116480053112073

Epoch: 244| Step: 0
Training loss: 2.2908434867858887
Validation loss: 2.2368709169408327

Epoch: 5| Step: 1
Training loss: 2.338667869567871
Validation loss: 2.239933736862675

Epoch: 5| Step: 2
Training loss: 2.055305004119873
Validation loss: 2.2093478325874574

Epoch: 5| Step: 3
Training loss: 2.2833690643310547
Validation loss: 2.2131600687580724

Epoch: 5| Step: 4
Training loss: 1.6567134857177734
Validation loss: 2.221402188783051

Epoch: 5| Step: 5
Training loss: 1.4496411085128784
Validation loss: 2.2209177427394415

Epoch: 5| Step: 6
Training loss: 2.290125608444214
Validation loss: 2.2300496511561896

Epoch: 5| Step: 7
Training loss: 2.552155017852783
Validation loss: 2.2350242753182687

Epoch: 5| Step: 8
Training loss: 2.3679885864257812
Validation loss: 2.25313707833649

Epoch: 5| Step: 9
Training loss: 2.7027721405029297
Validation loss: 2.2495139773173998

Epoch: 5| Step: 10
Training loss: 2.280261993408203
Validation loss: 2.274768953682274

Epoch: 245| Step: 0
Training loss: 2.8905422687530518
Validation loss: 2.2336460954399517

Epoch: 5| Step: 1
Training loss: 2.076381206512451
Validation loss: 2.2199429927333707

Epoch: 5| Step: 2
Training loss: 1.8257421255111694
Validation loss: 2.1881973589620283

Epoch: 5| Step: 3
Training loss: 2.1955225467681885
Validation loss: 2.189745182632118

Epoch: 5| Step: 4
Training loss: 1.9382518529891968
Validation loss: 2.196959872399607

Epoch: 5| Step: 5
Training loss: 1.98196280002594
Validation loss: 2.201106389363607

Epoch: 5| Step: 6
Training loss: 2.1636579036712646
Validation loss: 2.235701311019159

Epoch: 5| Step: 7
Training loss: 2.2645561695098877
Validation loss: 2.2433975768345658

Epoch: 5| Step: 8
Training loss: 2.3841042518615723
Validation loss: 2.2631897926330566

Epoch: 5| Step: 9
Training loss: 2.3917489051818848
Validation loss: 2.265409605477446

Epoch: 5| Step: 10
Training loss: 2.137192964553833
Validation loss: 2.231901245732461

Epoch: 246| Step: 0
Training loss: 2.298025369644165
Validation loss: 2.237164592230192

Epoch: 5| Step: 1
Training loss: 1.9920179843902588
Validation loss: 2.2261610979674966

Epoch: 5| Step: 2
Training loss: 1.7359764575958252
Validation loss: 2.2259153166124896

Epoch: 5| Step: 3
Training loss: 2.1966731548309326
Validation loss: 2.241916666748703

Epoch: 5| Step: 4
Training loss: 2.623892307281494
Validation loss: 2.2311734973743396

Epoch: 5| Step: 5
Training loss: 1.8981682062149048
Validation loss: 2.205093692707759

Epoch: 5| Step: 6
Training loss: 2.3281612396240234
Validation loss: 2.1679300979901384

Epoch: 5| Step: 7
Training loss: 2.4770700931549072
Validation loss: 2.1554861863454184

Epoch: 5| Step: 8
Training loss: 1.743198037147522
Validation loss: 2.1743318547484694

Epoch: 5| Step: 9
Training loss: 2.484785795211792
Validation loss: 2.175703501188627

Epoch: 5| Step: 10
Training loss: 2.3822827339172363
Validation loss: 2.212197901100241

Epoch: 247| Step: 0
Training loss: 2.9513611793518066
Validation loss: 2.2418742102961384

Epoch: 5| Step: 1
Training loss: 2.7142930030822754
Validation loss: 2.247494097678892

Epoch: 5| Step: 2
Training loss: 2.0343899726867676
Validation loss: 2.239493341856105

Epoch: 5| Step: 3
Training loss: 1.894439697265625
Validation loss: 2.269070594541488

Epoch: 5| Step: 4
Training loss: 2.4190549850463867
Validation loss: 2.2706888004015853

Epoch: 5| Step: 5
Training loss: 2.33439302444458
Validation loss: 2.2959518791526876

Epoch: 5| Step: 6
Training loss: 2.0367484092712402
Validation loss: 2.291955965821461

Epoch: 5| Step: 7
Training loss: 2.3591201305389404
Validation loss: 2.2492239244522585

Epoch: 5| Step: 8
Training loss: 2.0580410957336426
Validation loss: 2.194030269499748

Epoch: 5| Step: 9
Training loss: 1.0907371044158936
Validation loss: 2.194696967319776

Epoch: 5| Step: 10
Training loss: 2.2976222038269043
Validation loss: 2.1981319868436424

Epoch: 248| Step: 0
Training loss: 2.694507122039795
Validation loss: 2.183097452245733

Epoch: 5| Step: 1
Training loss: 2.0859851837158203
Validation loss: 2.1959712941159486

Epoch: 5| Step: 2
Training loss: 2.119201183319092
Validation loss: 2.216646207276211

Epoch: 5| Step: 3
Training loss: 2.0890188217163086
Validation loss: 2.222612711691087

Epoch: 5| Step: 4
Training loss: 1.729696273803711
Validation loss: 2.2157534578795075

Epoch: 5| Step: 5
Training loss: 1.6301120519638062
Validation loss: 2.2262430370494886

Epoch: 5| Step: 6
Training loss: 2.326976776123047
Validation loss: 2.233035315749466

Epoch: 5| Step: 7
Training loss: 2.2864527702331543
Validation loss: 2.2442990400457896

Epoch: 5| Step: 8
Training loss: 2.4484333992004395
Validation loss: 2.2553883239787114

Epoch: 5| Step: 9
Training loss: 2.2842094898223877
Validation loss: 2.263493968594459

Epoch: 5| Step: 10
Training loss: 2.2885549068450928
Validation loss: 2.237325276097944

Epoch: 249| Step: 0
Training loss: 1.8158661127090454
Validation loss: 2.220633363211027

Epoch: 5| Step: 1
Training loss: 2.4056501388549805
Validation loss: 2.2023076267652613

Epoch: 5| Step: 2
Training loss: 2.575941562652588
Validation loss: 2.175042301095942

Epoch: 5| Step: 3
Training loss: 1.7019283771514893
Validation loss: 2.1529292329665153

Epoch: 5| Step: 4
Training loss: 2.535886526107788
Validation loss: 2.1437861393856745

Epoch: 5| Step: 5
Training loss: 1.8233258724212646
Validation loss: 2.131749556910607

Epoch: 5| Step: 6
Training loss: 2.0838112831115723
Validation loss: 2.124415483526004

Epoch: 5| Step: 7
Training loss: 2.21931791305542
Validation loss: 2.1481369849174254

Epoch: 5| Step: 8
Training loss: 2.8755016326904297
Validation loss: 2.1497180410610732

Epoch: 5| Step: 9
Training loss: 2.213029146194458
Validation loss: 2.155507867054273

Epoch: 5| Step: 10
Training loss: 1.429612159729004
Validation loss: 2.189329972831152

Epoch: 250| Step: 0
Training loss: 2.5966222286224365
Validation loss: 2.206552461911273

Epoch: 5| Step: 1
Training loss: 2.1453051567077637
Validation loss: 2.218575108435846

Epoch: 5| Step: 2
Training loss: 2.0932798385620117
Validation loss: 2.214310456347722

Epoch: 5| Step: 3
Training loss: 1.855123519897461
Validation loss: 2.22504432483386

Epoch: 5| Step: 4
Training loss: 2.113402843475342
Validation loss: 2.2498437512305474

Epoch: 5| Step: 5
Training loss: 2.185584545135498
Validation loss: 2.250809569512644

Epoch: 5| Step: 6
Training loss: 1.8851959705352783
Validation loss: 2.254962895506172

Epoch: 5| Step: 7
Training loss: 2.518721580505371
Validation loss: 2.237311727257185

Epoch: 5| Step: 8
Training loss: 2.2483572959899902
Validation loss: 2.2245232469292096

Epoch: 5| Step: 9
Training loss: 2.1774497032165527
Validation loss: 2.2140802080913256

Epoch: 5| Step: 10
Training loss: 1.9095395803451538
Validation loss: 2.1927953368874005

Epoch: 251| Step: 0
Training loss: 1.7671566009521484
Validation loss: 2.1823418371139036

Epoch: 5| Step: 1
Training loss: 2.3131725788116455
Validation loss: 2.1739710812927573

Epoch: 5| Step: 2
Training loss: 2.6410913467407227
Validation loss: 2.1903625560063187

Epoch: 5| Step: 3
Training loss: 2.1712334156036377
Validation loss: 2.164831528099634

Epoch: 5| Step: 4
Training loss: 2.5488486289978027
Validation loss: 2.1640542578953568

Epoch: 5| Step: 5
Training loss: 2.5248525142669678
Validation loss: 2.1553121023280646

Epoch: 5| Step: 6
Training loss: 2.369126796722412
Validation loss: 2.1340422297036774

Epoch: 5| Step: 7
Training loss: 2.010608196258545
Validation loss: 2.151886914366035

Epoch: 5| Step: 8
Training loss: 1.771388292312622
Validation loss: 2.1660217008283063

Epoch: 5| Step: 9
Training loss: 1.969614028930664
Validation loss: 2.2014928607530493

Epoch: 5| Step: 10
Training loss: 1.601575493812561
Validation loss: 2.21412488209304

Epoch: 252| Step: 0
Training loss: 2.804542064666748
Validation loss: 2.2383439643408662

Epoch: 5| Step: 1
Training loss: 2.077986240386963
Validation loss: 2.2529359453467914

Epoch: 5| Step: 2
Training loss: 2.4384984970092773
Validation loss: 2.254323510713475

Epoch: 5| Step: 3
Training loss: 2.4002490043640137
Validation loss: 2.232685125002297

Epoch: 5| Step: 4
Training loss: 2.1225805282592773
Validation loss: 2.238742966805735

Epoch: 5| Step: 5
Training loss: 2.86540150642395
Validation loss: 2.2126795784119637

Epoch: 5| Step: 6
Training loss: 1.5320369005203247
Validation loss: 2.2123679602017967

Epoch: 5| Step: 7
Training loss: 1.2173750400543213
Validation loss: 2.20000147691337

Epoch: 5| Step: 8
Training loss: 2.451512575149536
Validation loss: 2.176359071526476

Epoch: 5| Step: 9
Training loss: 1.8615057468414307
Validation loss: 2.1626583094237954

Epoch: 5| Step: 10
Training loss: 2.0102319717407227
Validation loss: 2.1684265675083285

Epoch: 253| Step: 0
Training loss: 2.0881736278533936
Validation loss: 2.1937735055082586

Epoch: 5| Step: 1
Training loss: 1.960123062133789
Validation loss: 2.2190692245319323

Epoch: 5| Step: 2
Training loss: 2.529564380645752
Validation loss: 2.2140605539403935

Epoch: 5| Step: 3
Training loss: 2.7317728996276855
Validation loss: 2.189463569271949

Epoch: 5| Step: 4
Training loss: 1.809064507484436
Validation loss: 2.1875599225362143

Epoch: 5| Step: 5
Training loss: 2.2290713787078857
Validation loss: 2.1701764496423865

Epoch: 5| Step: 6
Training loss: 2.4062814712524414
Validation loss: 2.166446514027093

Epoch: 5| Step: 7
Training loss: 2.0232582092285156
Validation loss: 2.197089038869386

Epoch: 5| Step: 8
Training loss: 1.9617195129394531
Validation loss: 2.2116646151388846

Epoch: 5| Step: 9
Training loss: 2.025113582611084
Validation loss: 2.253548365767284

Epoch: 5| Step: 10
Training loss: 2.185915231704712
Validation loss: 2.2199990210994596

Epoch: 254| Step: 0
Training loss: 2.6180825233459473
Validation loss: 2.1776795899996193

Epoch: 5| Step: 1
Training loss: 1.816626787185669
Validation loss: 2.1884586939247708

Epoch: 5| Step: 2
Training loss: 2.166142702102661
Validation loss: 2.2097723253311647

Epoch: 5| Step: 3
Training loss: 2.6403636932373047
Validation loss: 2.2025524647005144

Epoch: 5| Step: 4
Training loss: 2.196323871612549
Validation loss: 2.207450164261685

Epoch: 5| Step: 5
Training loss: 1.9964039325714111
Validation loss: 2.1824624705058273

Epoch: 5| Step: 6
Training loss: 2.0078296661376953
Validation loss: 2.138344483990823

Epoch: 5| Step: 7
Training loss: 1.979439377784729
Validation loss: 2.14152088088374

Epoch: 5| Step: 8
Training loss: 2.375858783721924
Validation loss: 2.1422291468548518

Epoch: 5| Step: 9
Training loss: 2.036334991455078
Validation loss: 2.133342173791701

Epoch: 5| Step: 10
Training loss: 1.9707484245300293
Validation loss: 2.138206292224187

Epoch: 255| Step: 0
Training loss: 1.723711371421814
Validation loss: 2.1499355659689954

Epoch: 5| Step: 1
Training loss: 2.286038637161255
Validation loss: 2.1708610339831282

Epoch: 5| Step: 2
Training loss: 1.7124254703521729
Validation loss: 2.1541554440734205

Epoch: 5| Step: 3
Training loss: 2.003577709197998
Validation loss: 2.18844489512905

Epoch: 5| Step: 4
Training loss: 2.3922812938690186
Validation loss: 2.2154546040360645

Epoch: 5| Step: 5
Training loss: 1.9479252099990845
Validation loss: 2.1985719973041165

Epoch: 5| Step: 6
Training loss: 2.3802645206451416
Validation loss: 2.184072668834399

Epoch: 5| Step: 7
Training loss: 2.6583313941955566
Validation loss: 2.2033317845354796

Epoch: 5| Step: 8
Training loss: 2.087228536605835
Validation loss: 2.2003284500491236

Epoch: 5| Step: 9
Training loss: 2.143479824066162
Validation loss: 2.2110675919440483

Epoch: 5| Step: 10
Training loss: 2.366278648376465
Validation loss: 2.1999205081693587

Epoch: 256| Step: 0
Training loss: 2.3985836505889893
Validation loss: 2.189061435320044

Epoch: 5| Step: 1
Training loss: 1.8749605417251587
Validation loss: 2.1919667669521865

Epoch: 5| Step: 2
Training loss: 2.015648603439331
Validation loss: 2.195405552464147

Epoch: 5| Step: 3
Training loss: 1.9963449239730835
Validation loss: 2.1903335945580595

Epoch: 5| Step: 4
Training loss: 2.146697759628296
Validation loss: 2.195842722410797

Epoch: 5| Step: 5
Training loss: 2.6438469886779785
Validation loss: 2.174995753072923

Epoch: 5| Step: 6
Training loss: 2.5564417839050293
Validation loss: 2.173817539727816

Epoch: 5| Step: 7
Training loss: 1.9606319665908813
Validation loss: 2.14457619062034

Epoch: 5| Step: 8
Training loss: 2.063390016555786
Validation loss: 2.14485679646974

Epoch: 5| Step: 9
Training loss: 1.6483170986175537
Validation loss: 2.153644661749563

Epoch: 5| Step: 10
Training loss: 2.2169573307037354
Validation loss: 2.1749760002218266

Epoch: 257| Step: 0
Training loss: 1.9567991495132446
Validation loss: 2.152701565014419

Epoch: 5| Step: 1
Training loss: 2.1538586616516113
Validation loss: 2.1829785070111676

Epoch: 5| Step: 2
Training loss: 1.9779040813446045
Validation loss: 2.1867467562357583

Epoch: 5| Step: 3
Training loss: 2.018868923187256
Validation loss: 2.2032392614631244

Epoch: 5| Step: 4
Training loss: 2.1514885425567627
Validation loss: 2.2071603741697086

Epoch: 5| Step: 5
Training loss: 1.8620048761367798
Validation loss: 2.2136947262671685

Epoch: 5| Step: 6
Training loss: 1.856011986732483
Validation loss: 2.20202168726152

Epoch: 5| Step: 7
Training loss: 2.340663433074951
Validation loss: 2.1863239631857923

Epoch: 5| Step: 8
Training loss: 2.7926645278930664
Validation loss: 2.173578126456148

Epoch: 5| Step: 9
Training loss: 1.8665997982025146
Validation loss: 2.1763926193278325

Epoch: 5| Step: 10
Training loss: 2.2796597480773926
Validation loss: 2.171093189588157

Epoch: 258| Step: 0
Training loss: 2.3132054805755615
Validation loss: 2.191891652281566

Epoch: 5| Step: 1
Training loss: 2.1187801361083984
Validation loss: 2.1979368950731013

Epoch: 5| Step: 2
Training loss: 1.5792256593704224
Validation loss: 2.1971317824497016

Epoch: 5| Step: 3
Training loss: 1.9799058437347412
Validation loss: 2.171837878483598

Epoch: 5| Step: 4
Training loss: 1.7875030040740967
Validation loss: 2.1996791465308076

Epoch: 5| Step: 5
Training loss: 2.972834348678589
Validation loss: 2.205524044652139

Epoch: 5| Step: 6
Training loss: 2.529789447784424
Validation loss: 2.2315396826754332

Epoch: 5| Step: 7
Training loss: 1.6106879711151123
Validation loss: 2.23891879153508

Epoch: 5| Step: 8
Training loss: 1.6988950967788696
Validation loss: 2.2194654864649617

Epoch: 5| Step: 9
Training loss: 2.276034355163574
Validation loss: 2.1833244151966547

Epoch: 5| Step: 10
Training loss: 2.4999332427978516
Validation loss: 2.175566016986806

Epoch: 259| Step: 0
Training loss: 1.7016456127166748
Validation loss: 2.1727745302261843

Epoch: 5| Step: 1
Training loss: 2.0537972450256348
Validation loss: 2.1411646924993044

Epoch: 5| Step: 2
Training loss: 2.5192222595214844
Validation loss: 2.1494825706687024

Epoch: 5| Step: 3
Training loss: 1.8609132766723633
Validation loss: 2.157534986413935

Epoch: 5| Step: 4
Training loss: 1.8038753271102905
Validation loss: 2.152702195670015

Epoch: 5| Step: 5
Training loss: 2.1048216819763184
Validation loss: 2.160006138586229

Epoch: 5| Step: 6
Training loss: 2.3383922576904297
Validation loss: 2.1419242453831497

Epoch: 5| Step: 7
Training loss: 1.9151246547698975
Validation loss: 2.1539208030187957

Epoch: 5| Step: 8
Training loss: 1.8733876943588257
Validation loss: 2.169694444184662

Epoch: 5| Step: 9
Training loss: 2.251821756362915
Validation loss: 2.1945564618674656

Epoch: 5| Step: 10
Training loss: 2.823301315307617
Validation loss: 2.1933737493330434

Epoch: 260| Step: 0
Training loss: 2.1794638633728027
Validation loss: 2.222983688436529

Epoch: 5| Step: 1
Training loss: 2.163361072540283
Validation loss: 2.193391215416693

Epoch: 5| Step: 2
Training loss: 1.8372882604599
Validation loss: 2.1907010937249787

Epoch: 5| Step: 3
Training loss: 2.676630973815918
Validation loss: 2.1844263435691915

Epoch: 5| Step: 4
Training loss: 2.0048601627349854
Validation loss: 2.1681495943377094

Epoch: 5| Step: 5
Training loss: 2.0342764854431152
Validation loss: 2.183292988807924

Epoch: 5| Step: 6
Training loss: 2.105346441268921
Validation loss: 2.167736525176674

Epoch: 5| Step: 7
Training loss: 2.0429739952087402
Validation loss: 2.175102799169479

Epoch: 5| Step: 8
Training loss: 1.7767016887664795
Validation loss: 2.1992261666123585

Epoch: 5| Step: 9
Training loss: 1.9667221307754517
Validation loss: 2.211588144302368

Epoch: 5| Step: 10
Training loss: 2.3105297088623047
Validation loss: 2.2128806306469824

Epoch: 261| Step: 0
Training loss: 1.762813925743103
Validation loss: 2.184199297299949

Epoch: 5| Step: 1
Training loss: 1.4958040714263916
Validation loss: 2.177628494078113

Epoch: 5| Step: 2
Training loss: 2.423902988433838
Validation loss: 2.209499743676955

Epoch: 5| Step: 3
Training loss: 1.753662109375
Validation loss: 2.1879457517336776

Epoch: 5| Step: 4
Training loss: 2.2462456226348877
Validation loss: 2.198807926588161

Epoch: 5| Step: 5
Training loss: 1.5240627527236938
Validation loss: 2.1968945764726207

Epoch: 5| Step: 6
Training loss: 2.1806468963623047
Validation loss: 2.188370414959487

Epoch: 5| Step: 7
Training loss: 2.7796754837036133
Validation loss: 2.180345768569618

Epoch: 5| Step: 8
Training loss: 2.0907487869262695
Validation loss: 2.1583749889045634

Epoch: 5| Step: 9
Training loss: 2.489356279373169
Validation loss: 2.1628778442259757

Epoch: 5| Step: 10
Training loss: 2.3713326454162598
Validation loss: 2.131296800028893

Epoch: 262| Step: 0
Training loss: 1.6068006753921509
Validation loss: 2.1321614198787238

Epoch: 5| Step: 1
Training loss: 2.036799430847168
Validation loss: 2.1337880396073863

Epoch: 5| Step: 2
Training loss: 1.733435034751892
Validation loss: 2.1534133367640997

Epoch: 5| Step: 3
Training loss: 2.468977451324463
Validation loss: 2.122579061856834

Epoch: 5| Step: 4
Training loss: 2.2504143714904785
Validation loss: 2.161507527033488

Epoch: 5| Step: 5
Training loss: 2.0243451595306396
Validation loss: 2.1833300103423414

Epoch: 5| Step: 6
Training loss: 1.9163535833358765
Validation loss: 2.2185810842821674

Epoch: 5| Step: 7
Training loss: 2.6892001628875732
Validation loss: 2.181610663731893

Epoch: 5| Step: 8
Training loss: 1.653533697128296
Validation loss: 2.160422331543379

Epoch: 5| Step: 9
Training loss: 2.2092204093933105
Validation loss: 2.164450322428057

Epoch: 5| Step: 10
Training loss: 2.6573054790496826
Validation loss: 2.177606595459805

Epoch: 263| Step: 0
Training loss: 2.8600010871887207
Validation loss: 2.2025652854673323

Epoch: 5| Step: 1
Training loss: 2.4290857315063477
Validation loss: 2.2049927032122048

Epoch: 5| Step: 2
Training loss: 1.4511438608169556
Validation loss: 2.176990862815611

Epoch: 5| Step: 3
Training loss: 2.457449436187744
Validation loss: 2.163075372736941

Epoch: 5| Step: 4
Training loss: 2.0820960998535156
Validation loss: 2.1741563927742744

Epoch: 5| Step: 5
Training loss: 2.044188976287842
Validation loss: 2.1924329701290337

Epoch: 5| Step: 6
Training loss: 2.085392713546753
Validation loss: 2.2002694324780534

Epoch: 5| Step: 7
Training loss: 2.082789897918701
Validation loss: 2.20738386595121

Epoch: 5| Step: 8
Training loss: 1.9237667322158813
Validation loss: 2.1638528890507196

Epoch: 5| Step: 9
Training loss: 1.8644376993179321
Validation loss: 2.1365183194478354

Epoch: 5| Step: 10
Training loss: 1.819069504737854
Validation loss: 2.1313997391731507

Epoch: 264| Step: 0
Training loss: 1.9828754663467407
Validation loss: 2.156247305613692

Epoch: 5| Step: 1
Training loss: 2.2307064533233643
Validation loss: 2.1565807698875346

Epoch: 5| Step: 2
Training loss: 1.6912739276885986
Validation loss: 2.152833043888051

Epoch: 5| Step: 3
Training loss: 1.6665118932724
Validation loss: 2.1660815515825824

Epoch: 5| Step: 4
Training loss: 2.4256880283355713
Validation loss: 2.17488698292804

Epoch: 5| Step: 5
Training loss: 2.220913887023926
Validation loss: 2.146958140916722

Epoch: 5| Step: 6
Training loss: 1.8408615589141846
Validation loss: 2.1493649610909085

Epoch: 5| Step: 7
Training loss: 2.4141833782196045
Validation loss: 2.1819833760620444

Epoch: 5| Step: 8
Training loss: 1.841058373451233
Validation loss: 2.1915188207421252

Epoch: 5| Step: 9
Training loss: 2.453418254852295
Validation loss: 2.1622625986735025

Epoch: 5| Step: 10
Training loss: 2.4624123573303223
Validation loss: 2.1502043559987056

Epoch: 265| Step: 0
Training loss: 2.043407678604126
Validation loss: 2.1213237649650982

Epoch: 5| Step: 1
Training loss: 2.079760789871216
Validation loss: 2.1322897864926245

Epoch: 5| Step: 2
Training loss: 1.5464470386505127
Validation loss: 2.1245164127760034

Epoch: 5| Step: 3
Training loss: 2.2400708198547363
Validation loss: 2.1452066770163913

Epoch: 5| Step: 4
Training loss: 2.3913285732269287
Validation loss: 2.154974211928665

Epoch: 5| Step: 5
Training loss: 2.538349151611328
Validation loss: 2.152782504276563

Epoch: 5| Step: 6
Training loss: 1.9584696292877197
Validation loss: 2.1575189816054476

Epoch: 5| Step: 7
Training loss: 1.9716119766235352
Validation loss: 2.190940744133406

Epoch: 5| Step: 8
Training loss: 1.9021419286727905
Validation loss: 2.2032365209312847

Epoch: 5| Step: 9
Training loss: 1.8773969411849976
Validation loss: 2.2175016249379804

Epoch: 5| Step: 10
Training loss: 2.4700746536254883
Validation loss: 2.2097235277134883

Epoch: 266| Step: 0
Training loss: 2.165328025817871
Validation loss: 2.199016929954611

Epoch: 5| Step: 1
Training loss: 2.5018017292022705
Validation loss: 2.1843033324005785

Epoch: 5| Step: 2
Training loss: 1.9178889989852905
Validation loss: 2.1755255345375306

Epoch: 5| Step: 3
Training loss: 1.2865190505981445
Validation loss: 2.166807573328736

Epoch: 5| Step: 4
Training loss: 1.7861106395721436
Validation loss: 2.169234373236215

Epoch: 5| Step: 5
Training loss: 2.24487566947937
Validation loss: 2.145754852602559

Epoch: 5| Step: 6
Training loss: 1.7798426151275635
Validation loss: 2.152310868745209

Epoch: 5| Step: 7
Training loss: 2.078094959259033
Validation loss: 2.1587359187423543

Epoch: 5| Step: 8
Training loss: 2.6082799434661865
Validation loss: 2.1485695441563926

Epoch: 5| Step: 9
Training loss: 2.2802748680114746
Validation loss: 2.166191562529533

Epoch: 5| Step: 10
Training loss: 2.0018792152404785
Validation loss: 2.157906768142536

Epoch: 267| Step: 0
Training loss: 1.9804885387420654
Validation loss: 2.1603698422831874

Epoch: 5| Step: 1
Training loss: 1.8633553981781006
Validation loss: 2.13022361006788

Epoch: 5| Step: 2
Training loss: 1.953221321105957
Validation loss: 2.120541391834136

Epoch: 5| Step: 3
Training loss: 1.6801416873931885
Validation loss: 2.1067130386188464

Epoch: 5| Step: 4
Training loss: 2.3199257850646973
Validation loss: 2.132768363080999

Epoch: 5| Step: 5
Training loss: 2.013197422027588
Validation loss: 2.123875169343846

Epoch: 5| Step: 6
Training loss: 1.6865453720092773
Validation loss: 2.1561526278013825

Epoch: 5| Step: 7
Training loss: 2.659585952758789
Validation loss: 2.1632714604818695

Epoch: 5| Step: 8
Training loss: 2.814185619354248
Validation loss: 2.163120068529601

Epoch: 5| Step: 9
Training loss: 1.8920997381210327
Validation loss: 2.1709731753154466

Epoch: 5| Step: 10
Training loss: 1.8787986040115356
Validation loss: 2.1850634877399733

Epoch: 268| Step: 0
Training loss: 1.865830421447754
Validation loss: 2.167997455084196

Epoch: 5| Step: 1
Training loss: 2.5476789474487305
Validation loss: 2.1665224131717475

Epoch: 5| Step: 2
Training loss: 2.1285288333892822
Validation loss: 2.177831401107132

Epoch: 5| Step: 3
Training loss: 1.518052339553833
Validation loss: 2.169012079956711

Epoch: 5| Step: 4
Training loss: 2.1937994956970215
Validation loss: 2.1082969263035762

Epoch: 5| Step: 5
Training loss: 2.3379557132720947
Validation loss: 2.1114301976337226

Epoch: 5| Step: 6
Training loss: 1.7530616521835327
Validation loss: 2.1066021021976264

Epoch: 5| Step: 7
Training loss: 1.93328058719635
Validation loss: 2.1432384496094077

Epoch: 5| Step: 8
Training loss: 2.2127866744995117
Validation loss: 2.1334247307110856

Epoch: 5| Step: 9
Training loss: 1.810927391052246
Validation loss: 2.144609820458197

Epoch: 5| Step: 10
Training loss: 2.552262544631958
Validation loss: 2.162351785167571

Epoch: 269| Step: 0
Training loss: 2.033909559249878
Validation loss: 2.133259937327395

Epoch: 5| Step: 1
Training loss: 2.4635791778564453
Validation loss: 2.1354437233299337

Epoch: 5| Step: 2
Training loss: 1.6247930526733398
Validation loss: 2.1547326759625505

Epoch: 5| Step: 3
Training loss: 1.5100436210632324
Validation loss: 2.145465099683372

Epoch: 5| Step: 4
Training loss: 2.125983953475952
Validation loss: 2.15739639600118

Epoch: 5| Step: 5
Training loss: 1.7108707427978516
Validation loss: 2.1455568357180526

Epoch: 5| Step: 6
Training loss: 2.451401710510254
Validation loss: 2.1443989199976765

Epoch: 5| Step: 7
Training loss: 1.821295142173767
Validation loss: 2.1477985740989767

Epoch: 5| Step: 8
Training loss: 2.202306032180786
Validation loss: 2.1531996880808184

Epoch: 5| Step: 9
Training loss: 2.4800572395324707
Validation loss: 2.148336818141322

Epoch: 5| Step: 10
Training loss: 2.1247308254241943
Validation loss: 2.1513050576691986

Epoch: 270| Step: 0
Training loss: 1.9240871667861938
Validation loss: 2.140954158639395

Epoch: 5| Step: 1
Training loss: 2.285698652267456
Validation loss: 2.1348038206818285

Epoch: 5| Step: 2
Training loss: 1.7512118816375732
Validation loss: 2.1343645370134743

Epoch: 5| Step: 3
Training loss: 2.5468873977661133
Validation loss: 2.1297683536365466

Epoch: 5| Step: 4
Training loss: 1.9208523035049438
Validation loss: 2.109509068150674

Epoch: 5| Step: 5
Training loss: 1.8939619064331055
Validation loss: 2.1115489518770607

Epoch: 5| Step: 6
Training loss: 1.3900253772735596
Validation loss: 2.1119133746752174

Epoch: 5| Step: 7
Training loss: 2.9199721813201904
Validation loss: 2.116865078608195

Epoch: 5| Step: 8
Training loss: 2.069445848464966
Validation loss: 2.1215814082853255

Epoch: 5| Step: 9
Training loss: 2.1353631019592285
Validation loss: 2.152875861813945

Epoch: 5| Step: 10
Training loss: 1.5646727085113525
Validation loss: 2.145500667633549

Epoch: 271| Step: 0
Training loss: 1.9306195974349976
Validation loss: 2.1573534832205823

Epoch: 5| Step: 1
Training loss: 2.430859327316284
Validation loss: 2.186934248093636

Epoch: 5| Step: 2
Training loss: 2.1624796390533447
Validation loss: 2.2018706337098153

Epoch: 5| Step: 3
Training loss: 1.9818496704101562
Validation loss: 2.1956641327950264

Epoch: 5| Step: 4
Training loss: 1.8641211986541748
Validation loss: 2.1821521084795714

Epoch: 5| Step: 5
Training loss: 1.8180326223373413
Validation loss: 2.185822138222315

Epoch: 5| Step: 6
Training loss: 1.27410888671875
Validation loss: 2.148852671346357

Epoch: 5| Step: 7
Training loss: 2.2871856689453125
Validation loss: 2.1718279802671043

Epoch: 5| Step: 8
Training loss: 2.439807891845703
Validation loss: 2.162847157447569

Epoch: 5| Step: 9
Training loss: 1.8301894664764404
Validation loss: 2.1310064305541334

Epoch: 5| Step: 10
Training loss: 2.35673189163208
Validation loss: 2.1273538733041413

Epoch: 272| Step: 0
Training loss: 2.1515684127807617
Validation loss: 2.1215768309049707

Epoch: 5| Step: 1
Training loss: 1.754320502281189
Validation loss: 2.1297942951161373

Epoch: 5| Step: 2
Training loss: 1.8529056310653687
Validation loss: 2.1091464296463998

Epoch: 5| Step: 3
Training loss: 1.2070233821868896
Validation loss: 2.1469923321918776

Epoch: 5| Step: 4
Training loss: 2.2933080196380615
Validation loss: 2.1601133859285744

Epoch: 5| Step: 5
Training loss: 1.6902215480804443
Validation loss: 2.1539519820162045

Epoch: 5| Step: 6
Training loss: 2.476757764816284
Validation loss: 2.1557300321517454

Epoch: 5| Step: 7
Training loss: 2.212463855743408
Validation loss: 2.123223179130144

Epoch: 5| Step: 8
Training loss: 1.5466371774673462
Validation loss: 2.1313831626728015

Epoch: 5| Step: 9
Training loss: 2.5062077045440674
Validation loss: 2.121848926749281

Epoch: 5| Step: 10
Training loss: 2.529411554336548
Validation loss: 2.1124340744428736

Epoch: 273| Step: 0
Training loss: 1.792470932006836
Validation loss: 2.1223489007642193

Epoch: 5| Step: 1
Training loss: 2.268674373626709
Validation loss: 2.1340801254395516

Epoch: 5| Step: 2
Training loss: 1.7467756271362305
Validation loss: 2.1087267321925007

Epoch: 5| Step: 3
Training loss: 1.8098491430282593
Validation loss: 2.1248957905718076

Epoch: 5| Step: 4
Training loss: 2.49177885055542
Validation loss: 2.126855832274242

Epoch: 5| Step: 5
Training loss: 2.4896483421325684
Validation loss: 2.114057820330384

Epoch: 5| Step: 6
Training loss: 1.7159192562103271
Validation loss: 2.143399910260272

Epoch: 5| Step: 7
Training loss: 1.8641726970672607
Validation loss: 2.113517577930163

Epoch: 5| Step: 8
Training loss: 2.370117664337158
Validation loss: 2.097417462256647

Epoch: 5| Step: 9
Training loss: 2.236886978149414
Validation loss: 2.0962848022419918

Epoch: 5| Step: 10
Training loss: 1.4789248704910278
Validation loss: 2.0816467679956907

Epoch: 274| Step: 0
Training loss: 2.053436040878296
Validation loss: 2.103157138311735

Epoch: 5| Step: 1
Training loss: 2.0708365440368652
Validation loss: 2.1131943964189097

Epoch: 5| Step: 2
Training loss: 2.9621644020080566
Validation loss: 2.112340191359161

Epoch: 5| Step: 3
Training loss: 1.879589319229126
Validation loss: 2.141101065502372

Epoch: 5| Step: 4
Training loss: 2.050659418106079
Validation loss: 2.146495211508966

Epoch: 5| Step: 5
Training loss: 2.7434282302856445
Validation loss: 2.1796049379533335

Epoch: 5| Step: 6
Training loss: 1.8835337162017822
Validation loss: 2.1301762365525767

Epoch: 5| Step: 7
Training loss: 1.8087193965911865
Validation loss: 2.1019699804244505

Epoch: 5| Step: 8
Training loss: 1.8792383670806885
Validation loss: 2.105575394886796

Epoch: 5| Step: 9
Training loss: 1.1539676189422607
Validation loss: 2.1080788104764876

Epoch: 5| Step: 10
Training loss: 1.6843953132629395
Validation loss: 2.1330905486178655

Epoch: 275| Step: 0
Training loss: 1.872995138168335
Validation loss: 2.145146582716255

Epoch: 5| Step: 1
Training loss: 2.060304641723633
Validation loss: 2.12184134093664

Epoch: 5| Step: 2
Training loss: 2.0468947887420654
Validation loss: 2.1053972474990355

Epoch: 5| Step: 3
Training loss: 1.6777817010879517
Validation loss: 2.10885964926853

Epoch: 5| Step: 4
Training loss: 2.2984232902526855
Validation loss: 2.1077547637365197

Epoch: 5| Step: 5
Training loss: 2.065736770629883
Validation loss: 2.117707065356675

Epoch: 5| Step: 6
Training loss: 2.1140036582946777
Validation loss: 2.137999091097104

Epoch: 5| Step: 7
Training loss: 1.6951853036880493
Validation loss: 2.119276367208009

Epoch: 5| Step: 8
Training loss: 2.076401948928833
Validation loss: 2.1491982065221316

Epoch: 5| Step: 9
Training loss: 2.1336050033569336
Validation loss: 2.166760742023427

Epoch: 5| Step: 10
Training loss: 2.1656768321990967
Validation loss: 2.1602593596263597

Epoch: 276| Step: 0
Training loss: 2.2854182720184326
Validation loss: 2.1649299026817403

Epoch: 5| Step: 1
Training loss: 1.448141098022461
Validation loss: 2.1286130643660024

Epoch: 5| Step: 2
Training loss: 1.8421337604522705
Validation loss: 2.136442756140104

Epoch: 5| Step: 3
Training loss: 2.4424078464508057
Validation loss: 2.128434722141553

Epoch: 5| Step: 4
Training loss: 2.4851596355438232
Validation loss: 2.134105272190545

Epoch: 5| Step: 5
Training loss: 2.247680425643921
Validation loss: 2.117687855997393

Epoch: 5| Step: 6
Training loss: 1.9840339422225952
Validation loss: 2.1220869056640135

Epoch: 5| Step: 7
Training loss: 2.000627279281616
Validation loss: 2.118390155094926

Epoch: 5| Step: 8
Training loss: 1.9735883474349976
Validation loss: 2.091606898974347

Epoch: 5| Step: 9
Training loss: 2.0402796268463135
Validation loss: 2.0929475650992444

Epoch: 5| Step: 10
Training loss: 1.2317761182785034
Validation loss: 2.0986079118585073

Epoch: 277| Step: 0
Training loss: 2.107574462890625
Validation loss: 2.102723842026085

Epoch: 5| Step: 1
Training loss: 2.2671260833740234
Validation loss: 2.074901448783054

Epoch: 5| Step: 2
Training loss: 1.9167286157608032
Validation loss: 2.06052747080403

Epoch: 5| Step: 3
Training loss: 2.770709991455078
Validation loss: 2.0820428389374928

Epoch: 5| Step: 4
Training loss: 2.2567927837371826
Validation loss: 2.0865778794852634

Epoch: 5| Step: 5
Training loss: 2.082667112350464
Validation loss: 2.098636196505639

Epoch: 5| Step: 6
Training loss: 1.889609694480896
Validation loss: 2.1260614446414414

Epoch: 5| Step: 7
Training loss: 1.7714354991912842
Validation loss: 2.122044424856863

Epoch: 5| Step: 8
Training loss: 2.007713794708252
Validation loss: 2.1381998190315823

Epoch: 5| Step: 9
Training loss: 1.6320022344589233
Validation loss: 2.1266077308244604

Epoch: 5| Step: 10
Training loss: 1.2168909311294556
Validation loss: 2.1325383083794707

Epoch: 278| Step: 0
Training loss: 2.3965210914611816
Validation loss: 2.158588433778414

Epoch: 5| Step: 1
Training loss: 2.852193832397461
Validation loss: 2.196353268879716

Epoch: 5| Step: 2
Training loss: 2.334108352661133
Validation loss: 2.211183919701525

Epoch: 5| Step: 3
Training loss: 2.039724349975586
Validation loss: 2.2033362004064743

Epoch: 5| Step: 4
Training loss: 0.8608304858207703
Validation loss: 2.1914808057969615

Epoch: 5| Step: 5
Training loss: 1.7695881128311157
Validation loss: 2.192729127022528

Epoch: 5| Step: 6
Training loss: 1.649715781211853
Validation loss: 2.2182939155127412

Epoch: 5| Step: 7
Training loss: 2.5486464500427246
Validation loss: 2.1834024049902476

Epoch: 5| Step: 8
Training loss: 1.7938798666000366
Validation loss: 2.1571056688985517

Epoch: 5| Step: 9
Training loss: 2.220705986022949
Validation loss: 2.123707009900001

Epoch: 5| Step: 10
Training loss: 1.4670320749282837
Validation loss: 2.084472143521873

Epoch: 279| Step: 0
Training loss: 2.2459044456481934
Validation loss: 2.074096184904857

Epoch: 5| Step: 1
Training loss: 2.074258327484131
Validation loss: 2.0698116671654487

Epoch: 5| Step: 2
Training loss: 2.0203328132629395
Validation loss: 2.0542884770260064

Epoch: 5| Step: 3
Training loss: 2.0988850593566895
Validation loss: 2.0363718386619323

Epoch: 5| Step: 4
Training loss: 1.7177932262420654
Validation loss: 2.0426490934946204

Epoch: 5| Step: 5
Training loss: 2.2737925052642822
Validation loss: 2.045133470207132

Epoch: 5| Step: 6
Training loss: 1.539347529411316
Validation loss: 2.0499951057536627

Epoch: 5| Step: 7
Training loss: 1.7888898849487305
Validation loss: 2.088588747926938

Epoch: 5| Step: 8
Training loss: 1.6341571807861328
Validation loss: 2.1407399690279396

Epoch: 5| Step: 9
Training loss: 2.557913303375244
Validation loss: 2.1724619327052945

Epoch: 5| Step: 10
Training loss: 1.9328453540802002
Validation loss: 2.175684320029392

Epoch: 280| Step: 0
Training loss: 2.3618078231811523
Validation loss: 2.2014440182716615

Epoch: 5| Step: 1
Training loss: 2.210456371307373
Validation loss: 2.1860003279101465

Epoch: 5| Step: 2
Training loss: 2.4005415439605713
Validation loss: 2.173133252769388

Epoch: 5| Step: 3
Training loss: 1.399585247039795
Validation loss: 2.137379960347247

Epoch: 5| Step: 4
Training loss: 1.8569904565811157
Validation loss: 2.1370166783691733

Epoch: 5| Step: 5
Training loss: 2.00160813331604
Validation loss: 2.128740131214101

Epoch: 5| Step: 6
Training loss: 2.1012024879455566
Validation loss: 2.1194753390486523

Epoch: 5| Step: 7
Training loss: 2.2515435218811035
Validation loss: 2.126687599766639

Epoch: 5| Step: 8
Training loss: 2.4039738178253174
Validation loss: 2.1077483956531813

Epoch: 5| Step: 9
Training loss: 1.1301259994506836
Validation loss: 2.0979665633170836

Epoch: 5| Step: 10
Training loss: 1.662253975868225
Validation loss: 2.124958404930689

Epoch: 281| Step: 0
Training loss: 1.8969395160675049
Validation loss: 2.113689799462595

Epoch: 5| Step: 1
Training loss: 1.5564110279083252
Validation loss: 2.164691253374982

Epoch: 5| Step: 2
Training loss: 2.0548863410949707
Validation loss: 2.1472040478901198

Epoch: 5| Step: 3
Training loss: 1.802146553993225
Validation loss: 2.1185913573029223

Epoch: 5| Step: 4
Training loss: 1.9601142406463623
Validation loss: 2.1128555472179125

Epoch: 5| Step: 5
Training loss: 2.0499610900878906
Validation loss: 2.111335041702435

Epoch: 5| Step: 6
Training loss: 2.075329303741455
Validation loss: 2.0969631825723956

Epoch: 5| Step: 7
Training loss: 1.9508998394012451
Validation loss: 2.0968049418541694

Epoch: 5| Step: 8
Training loss: 2.3222172260284424
Validation loss: 2.083460454017885

Epoch: 5| Step: 9
Training loss: 1.7628192901611328
Validation loss: 2.0952381382706347

Epoch: 5| Step: 10
Training loss: 2.5020885467529297
Validation loss: 2.094965273334134

Epoch: 282| Step: 0
Training loss: 2.0833241939544678
Validation loss: 2.119183850544755

Epoch: 5| Step: 1
Training loss: 2.2434284687042236
Validation loss: 2.123736007239229

Epoch: 5| Step: 2
Training loss: 1.92568039894104
Validation loss: 2.156262090129237

Epoch: 5| Step: 3
Training loss: 2.5311179161071777
Validation loss: 2.1357768389486496

Epoch: 5| Step: 4
Training loss: 1.7391960620880127
Validation loss: 2.109305058756182

Epoch: 5| Step: 5
Training loss: 1.5478227138519287
Validation loss: 2.0980913869796263

Epoch: 5| Step: 6
Training loss: 1.9256994724273682
Validation loss: 2.1043273223343717

Epoch: 5| Step: 7
Training loss: 2.6334500312805176
Validation loss: 2.100512609686903

Epoch: 5| Step: 8
Training loss: 1.7967742681503296
Validation loss: 2.083812922559759

Epoch: 5| Step: 9
Training loss: 1.7712278366088867
Validation loss: 2.0825060875185075

Epoch: 5| Step: 10
Training loss: 1.394474744796753
Validation loss: 2.0892885654203353

Epoch: 283| Step: 0
Training loss: 2.1878323554992676
Validation loss: 2.0943939775548954

Epoch: 5| Step: 1
Training loss: 2.5752577781677246
Validation loss: 2.0785773556719542

Epoch: 5| Step: 2
Training loss: 1.8062931299209595
Validation loss: 2.10978691808639

Epoch: 5| Step: 3
Training loss: 1.6826808452606201
Validation loss: 2.09917857826397

Epoch: 5| Step: 4
Training loss: 2.5690836906433105
Validation loss: 2.114339749018351

Epoch: 5| Step: 5
Training loss: 1.9715538024902344
Validation loss: 2.1301823431445706

Epoch: 5| Step: 6
Training loss: 1.8024619817733765
Validation loss: 2.142830261620142

Epoch: 5| Step: 7
Training loss: 1.9903857707977295
Validation loss: 2.164621330076648

Epoch: 5| Step: 8
Training loss: 1.8831380605697632
Validation loss: 2.1714482384343303

Epoch: 5| Step: 9
Training loss: 1.456477403640747
Validation loss: 2.1400297482808432

Epoch: 5| Step: 10
Training loss: 1.6891838312149048
Validation loss: 2.123685275354693

Epoch: 284| Step: 0
Training loss: 2.191631555557251
Validation loss: 2.106764092240282

Epoch: 5| Step: 1
Training loss: 2.3158507347106934
Validation loss: 2.1177913488880282

Epoch: 5| Step: 2
Training loss: 1.7779937982559204
Validation loss: 2.121546063371884

Epoch: 5| Step: 3
Training loss: 2.178497791290283
Validation loss: 2.0990373203831334

Epoch: 5| Step: 4
Training loss: 2.3219456672668457
Validation loss: 2.0844310637443297

Epoch: 5| Step: 5
Training loss: 2.1722025871276855
Validation loss: 2.063462996995577

Epoch: 5| Step: 6
Training loss: 1.6196740865707397
Validation loss: 2.0524956616022254

Epoch: 5| Step: 7
Training loss: 1.8085654973983765
Validation loss: 2.0585062606360323

Epoch: 5| Step: 8
Training loss: 1.794915795326233
Validation loss: 2.075273097202342

Epoch: 5| Step: 9
Training loss: 2.405078411102295
Validation loss: 2.103008570209626

Epoch: 5| Step: 10
Training loss: 1.139958381652832
Validation loss: 2.1198385095083587

Epoch: 285| Step: 0
Training loss: 1.678429365158081
Validation loss: 2.1060201583370084

Epoch: 5| Step: 1
Training loss: 1.6897742748260498
Validation loss: 2.117081193513768

Epoch: 5| Step: 2
Training loss: 1.9054759740829468
Validation loss: 2.109521162125372

Epoch: 5| Step: 3
Training loss: 1.8068287372589111
Validation loss: 2.1300322753126903

Epoch: 5| Step: 4
Training loss: 2.3560585975646973
Validation loss: 2.110810746428787

Epoch: 5| Step: 5
Training loss: 2.1395721435546875
Validation loss: 2.1014316158909954

Epoch: 5| Step: 6
Training loss: 1.6688343286514282
Validation loss: 2.080666039579658

Epoch: 5| Step: 7
Training loss: 1.7687768936157227
Validation loss: 2.092716136286336

Epoch: 5| Step: 8
Training loss: 1.8417094945907593
Validation loss: 2.0957915782928467

Epoch: 5| Step: 9
Training loss: 2.3477871417999268
Validation loss: 2.115390467387374

Epoch: 5| Step: 10
Training loss: 2.475513219833374
Validation loss: 2.1064401185640724

Epoch: 286| Step: 0
Training loss: 2.059418201446533
Validation loss: 2.120030972265428

Epoch: 5| Step: 1
Training loss: 1.8162391185760498
Validation loss: 2.1215785934079077

Epoch: 5| Step: 2
Training loss: 1.8509804010391235
Validation loss: 2.1372790567336546

Epoch: 5| Step: 3
Training loss: 1.5471609830856323
Validation loss: 2.129334483095395

Epoch: 5| Step: 4
Training loss: 1.6817185878753662
Validation loss: 2.1261615266082106

Epoch: 5| Step: 5
Training loss: 2.228982448577881
Validation loss: 2.1630455755418345

Epoch: 5| Step: 6
Training loss: 2.0862174034118652
Validation loss: 2.1439915664734377

Epoch: 5| Step: 7
Training loss: 1.6785328388214111
Validation loss: 2.148619426194058

Epoch: 5| Step: 8
Training loss: 2.3780665397644043
Validation loss: 2.1292545282712547

Epoch: 5| Step: 9
Training loss: 2.0106101036071777
Validation loss: 2.117836550999713

Epoch: 5| Step: 10
Training loss: 2.295447587966919
Validation loss: 2.103975985639839

Epoch: 287| Step: 0
Training loss: 2.447542190551758
Validation loss: 2.111340252302026

Epoch: 5| Step: 1
Training loss: 1.5071401596069336
Validation loss: 2.063352051601615

Epoch: 5| Step: 2
Training loss: 2.6376380920410156
Validation loss: 2.05661831748101

Epoch: 5| Step: 3
Training loss: 2.0822196006774902
Validation loss: 2.0386584843358686

Epoch: 5| Step: 4
Training loss: 1.8210747241973877
Validation loss: 2.050755521302582

Epoch: 5| Step: 5
Training loss: 2.266474962234497
Validation loss: 2.0539819014969694

Epoch: 5| Step: 6
Training loss: 1.9494918584823608
Validation loss: 2.055187225341797

Epoch: 5| Step: 7
Training loss: 1.8363014459609985
Validation loss: 2.0744892140870452

Epoch: 5| Step: 8
Training loss: 1.2532291412353516
Validation loss: 2.1088141856654996

Epoch: 5| Step: 9
Training loss: 1.9964587688446045
Validation loss: 2.1538803295422624

Epoch: 5| Step: 10
Training loss: 1.630442500114441
Validation loss: 2.1530286688958444

Epoch: 288| Step: 0
Training loss: 1.7343257665634155
Validation loss: 2.1299437938197965

Epoch: 5| Step: 1
Training loss: 2.1179213523864746
Validation loss: 2.1333593066020677

Epoch: 5| Step: 2
Training loss: 1.581261396408081
Validation loss: 2.12314115032073

Epoch: 5| Step: 3
Training loss: 1.8799870014190674
Validation loss: 2.0955502115270144

Epoch: 5| Step: 4
Training loss: 1.4916120767593384
Validation loss: 2.0913685931954333

Epoch: 5| Step: 5
Training loss: 2.2629287242889404
Validation loss: 2.100771072090313

Epoch: 5| Step: 6
Training loss: 2.0292088985443115
Validation loss: 2.098417389777399

Epoch: 5| Step: 7
Training loss: 2.342097759246826
Validation loss: 2.0948138724091234

Epoch: 5| Step: 8
Training loss: 2.104879379272461
Validation loss: 2.093747772196288

Epoch: 5| Step: 9
Training loss: 2.3488895893096924
Validation loss: 2.1249469300752044

Epoch: 5| Step: 10
Training loss: 1.4640322923660278
Validation loss: 2.1202586030447357

Epoch: 289| Step: 0
Training loss: 2.1898741722106934
Validation loss: 2.1269850500168337

Epoch: 5| Step: 1
Training loss: 1.4181735515594482
Validation loss: 2.132310039253645

Epoch: 5| Step: 2
Training loss: 1.6611545085906982
Validation loss: 2.0917781117141887

Epoch: 5| Step: 3
Training loss: 2.00862455368042
Validation loss: 2.114289872107967

Epoch: 5| Step: 4
Training loss: 1.7673494815826416
Validation loss: 2.1172430540925715

Epoch: 5| Step: 5
Training loss: 2.0911214351654053
Validation loss: 2.114240300270819

Epoch: 5| Step: 6
Training loss: 1.2302148342132568
Validation loss: 2.101822191669095

Epoch: 5| Step: 7
Training loss: 2.4827802181243896
Validation loss: 2.108865202114146

Epoch: 5| Step: 8
Training loss: 1.938058853149414
Validation loss: 2.0902153650919595

Epoch: 5| Step: 9
Training loss: 2.2694895267486572
Validation loss: 2.068858236394903

Epoch: 5| Step: 10
Training loss: 2.1468100547790527
Validation loss: 2.080124499977276

Epoch: 290| Step: 0
Training loss: 2.2378146648406982
Validation loss: 2.0740948364298832

Epoch: 5| Step: 1
Training loss: 1.4939714670181274
Validation loss: 2.091062602176461

Epoch: 5| Step: 2
Training loss: 1.7079098224639893
Validation loss: 2.0819872297266477

Epoch: 5| Step: 3
Training loss: 1.4955174922943115
Validation loss: 2.094904471469182

Epoch: 5| Step: 4
Training loss: 2.508247137069702
Validation loss: 2.0993176134683753

Epoch: 5| Step: 5
Training loss: 2.200660467147827
Validation loss: 2.098850796299596

Epoch: 5| Step: 6
Training loss: 2.3683762550354004
Validation loss: 2.1138274913193076

Epoch: 5| Step: 7
Training loss: 1.7478506565093994
Validation loss: 2.1035304146428264

Epoch: 5| Step: 8
Training loss: 2.2478411197662354
Validation loss: 2.0773735853933517

Epoch: 5| Step: 9
Training loss: 1.4359352588653564
Validation loss: 2.0532178340419645

Epoch: 5| Step: 10
Training loss: 1.857725977897644
Validation loss: 2.0513733804866834

Epoch: 291| Step: 0
Training loss: 1.4779638051986694
Validation loss: 2.0503827448814147

Epoch: 5| Step: 1
Training loss: 2.508573055267334
Validation loss: 2.0588966877229753

Epoch: 5| Step: 2
Training loss: 2.453375816345215
Validation loss: 2.051515975306111

Epoch: 5| Step: 3
Training loss: 1.5505110025405884
Validation loss: 2.0726023207428637

Epoch: 5| Step: 4
Training loss: 2.4067506790161133
Validation loss: 2.0940668518825243

Epoch: 5| Step: 5
Training loss: 1.9456405639648438
Validation loss: 2.1290664070396015

Epoch: 5| Step: 6
Training loss: 1.5290918350219727
Validation loss: 2.1585765218222015

Epoch: 5| Step: 7
Training loss: 1.9145673513412476
Validation loss: 2.1924614880674627

Epoch: 5| Step: 8
Training loss: 1.4439951181411743
Validation loss: 2.1951329938827024

Epoch: 5| Step: 9
Training loss: 2.4043679237365723
Validation loss: 2.1605915459253455

Epoch: 5| Step: 10
Training loss: 1.7505820989608765
Validation loss: 2.1366047474645797

Epoch: 292| Step: 0
Training loss: 2.0915939807891846
Validation loss: 2.088164355165215

Epoch: 5| Step: 1
Training loss: 1.8936856985092163
Validation loss: 2.0593124128157094

Epoch: 5| Step: 2
Training loss: 2.170945644378662
Validation loss: 2.0632537564923688

Epoch: 5| Step: 3
Training loss: 1.9600070714950562
Validation loss: 2.032593032365204

Epoch: 5| Step: 4
Training loss: 2.368136167526245
Validation loss: 2.062257884651102

Epoch: 5| Step: 5
Training loss: 1.4619675874710083
Validation loss: 2.055544347532334

Epoch: 5| Step: 6
Training loss: 1.9949274063110352
Validation loss: 2.0598264227631273

Epoch: 5| Step: 7
Training loss: 1.7650539875030518
Validation loss: 2.0751333159785115

Epoch: 5| Step: 8
Training loss: 1.2843058109283447
Validation loss: 2.084205114713279

Epoch: 5| Step: 9
Training loss: 2.2248966693878174
Validation loss: 2.0783728579039216

Epoch: 5| Step: 10
Training loss: 2.069559097290039
Validation loss: 2.097979612247918

Epoch: 293| Step: 0
Training loss: 2.0872364044189453
Validation loss: 2.094621176360756

Epoch: 5| Step: 1
Training loss: 1.834619164466858
Validation loss: 2.1195796817861576

Epoch: 5| Step: 2
Training loss: 1.759771704673767
Validation loss: 2.14990242450468

Epoch: 5| Step: 3
Training loss: 2.5756213665008545
Validation loss: 2.1484899367055585

Epoch: 5| Step: 4
Training loss: 2.0799508094787598
Validation loss: 2.141667648028302

Epoch: 5| Step: 5
Training loss: 1.5162699222564697
Validation loss: 2.1131818166343113

Epoch: 5| Step: 6
Training loss: 2.184216022491455
Validation loss: 2.074960026689755

Epoch: 5| Step: 7
Training loss: 2.0755186080932617
Validation loss: 2.080562956871525

Epoch: 5| Step: 8
Training loss: 1.7669492959976196
Validation loss: 2.1072964668273926

Epoch: 5| Step: 9
Training loss: 2.1584813594818115
Validation loss: 2.142863114674886

Epoch: 5| Step: 10
Training loss: 1.3219406604766846
Validation loss: 2.16739902188701

Epoch: 294| Step: 0
Training loss: 1.8343356847763062
Validation loss: 2.1890893161937757

Epoch: 5| Step: 1
Training loss: 1.9348758459091187
Validation loss: 2.1851570221685592

Epoch: 5| Step: 2
Training loss: 1.8479206562042236
Validation loss: 2.1258312220214517

Epoch: 5| Step: 3
Training loss: 2.5101916790008545
Validation loss: 2.10031456844781

Epoch: 5| Step: 4
Training loss: 1.9044554233551025
Validation loss: 2.0852361276585567

Epoch: 5| Step: 5
Training loss: 1.4105323553085327
Validation loss: 2.1074612384201377

Epoch: 5| Step: 6
Training loss: 1.8696829080581665
Validation loss: 2.1510829669173046

Epoch: 5| Step: 7
Training loss: 2.4040238857269287
Validation loss: 2.179740778861507

Epoch: 5| Step: 8
Training loss: 2.024418354034424
Validation loss: 2.1794474227454073

Epoch: 5| Step: 9
Training loss: 2.085606098175049
Validation loss: 2.1549098466032293

Epoch: 5| Step: 10
Training loss: 1.7414788007736206
Validation loss: 2.1097699724217898

Epoch: 295| Step: 0
Training loss: 1.8178884983062744
Validation loss: 2.101882255205544

Epoch: 5| Step: 1
Training loss: 1.7021230459213257
Validation loss: 2.101640207793123

Epoch: 5| Step: 2
Training loss: 2.1790177822113037
Validation loss: 2.080887371493924

Epoch: 5| Step: 3
Training loss: 2.196503162384033
Validation loss: 2.0604165241282475

Epoch: 5| Step: 4
Training loss: 1.9591734409332275
Validation loss: 2.036648065813126

Epoch: 5| Step: 5
Training loss: 1.7531791925430298
Validation loss: 2.025524905932847

Epoch: 5| Step: 6
Training loss: 1.3900022506713867
Validation loss: 2.0296186490725447

Epoch: 5| Step: 7
Training loss: 1.870526671409607
Validation loss: 2.005760690217377

Epoch: 5| Step: 8
Training loss: 2.099606990814209
Validation loss: 2.0248640865407963

Epoch: 5| Step: 9
Training loss: 2.1286189556121826
Validation loss: 2.026627207315096

Epoch: 5| Step: 10
Training loss: 1.924640417098999
Validation loss: 2.052912571096933

Epoch: 296| Step: 0
Training loss: 1.9017398357391357
Validation loss: 2.1081277593489616

Epoch: 5| Step: 1
Training loss: 1.930442452430725
Validation loss: 2.1278674320508073

Epoch: 5| Step: 2
Training loss: 1.5745179653167725
Validation loss: 2.12742474643133

Epoch: 5| Step: 3
Training loss: 1.4407641887664795
Validation loss: 2.1364134152730307

Epoch: 5| Step: 4
Training loss: 2.3687796592712402
Validation loss: 2.1494569893806212

Epoch: 5| Step: 5
Training loss: 2.0751242637634277
Validation loss: 2.111072160864389

Epoch: 5| Step: 6
Training loss: 1.8658788204193115
Validation loss: 2.100676591678332

Epoch: 5| Step: 7
Training loss: 2.3256676197052
Validation loss: 2.118502183627057

Epoch: 5| Step: 8
Training loss: 1.6179125308990479
Validation loss: 2.1232743135062595

Epoch: 5| Step: 9
Training loss: 1.9899585247039795
Validation loss: 2.1271073074751

Epoch: 5| Step: 10
Training loss: 2.070817708969116
Validation loss: 2.143386956184141

Epoch: 297| Step: 0
Training loss: 1.4269111156463623
Validation loss: 2.141867914507466

Epoch: 5| Step: 1
Training loss: 2.494623899459839
Validation loss: 2.1258917239404496

Epoch: 5| Step: 2
Training loss: 1.3174117803573608
Validation loss: 2.1373400893262637

Epoch: 5| Step: 3
Training loss: 2.2628133296966553
Validation loss: 2.134152349605355

Epoch: 5| Step: 4
Training loss: 2.2472984790802
Validation loss: 2.1417370637257895

Epoch: 5| Step: 5
Training loss: 1.5320817232131958
Validation loss: 2.1567582289377847

Epoch: 5| Step: 6
Training loss: 2.142695188522339
Validation loss: 2.1220699458993892

Epoch: 5| Step: 7
Training loss: 1.6896060705184937
Validation loss: 2.101838452841646

Epoch: 5| Step: 8
Training loss: 1.871774435043335
Validation loss: 2.095387861292849

Epoch: 5| Step: 9
Training loss: 2.224534511566162
Validation loss: 2.0559040295180453

Epoch: 5| Step: 10
Training loss: 1.639967918395996
Validation loss: 2.065451696354856

Epoch: 298| Step: 0
Training loss: 2.079653263092041
Validation loss: 2.045517498447049

Epoch: 5| Step: 1
Training loss: 2.230250597000122
Validation loss: 2.0508637556465725

Epoch: 5| Step: 2
Training loss: 1.85503351688385
Validation loss: 2.054568732938459

Epoch: 5| Step: 3
Training loss: 1.7538849115371704
Validation loss: 2.024260276107378

Epoch: 5| Step: 4
Training loss: 1.6907211542129517
Validation loss: 2.037850884981053

Epoch: 5| Step: 5
Training loss: 1.9526216983795166
Validation loss: 2.0602028344267156

Epoch: 5| Step: 6
Training loss: 2.4081883430480957
Validation loss: 2.076950373188142

Epoch: 5| Step: 7
Training loss: 1.632493257522583
Validation loss: 2.0759650225280435

Epoch: 5| Step: 8
Training loss: 1.4330499172210693
Validation loss: 2.117596031517111

Epoch: 5| Step: 9
Training loss: 1.9541094303131104
Validation loss: 2.156868032229844

Epoch: 5| Step: 10
Training loss: 1.8625988960266113
Validation loss: 2.161930843066144

Epoch: 299| Step: 0
Training loss: 1.8830583095550537
Validation loss: 2.184380116001252

Epoch: 5| Step: 1
Training loss: 2.0692315101623535
Validation loss: 2.1947406543198453

Epoch: 5| Step: 2
Training loss: 1.3914457559585571
Validation loss: 2.175787910338371

Epoch: 5| Step: 3
Training loss: 1.6415096521377563
Validation loss: 2.1555469356557375

Epoch: 5| Step: 4
Training loss: 1.6695398092269897
Validation loss: 2.111618031737625

Epoch: 5| Step: 5
Training loss: 2.0287585258483887
Validation loss: 2.1062266160083074

Epoch: 5| Step: 6
Training loss: 1.7170406579971313
Validation loss: 2.0948121586153583

Epoch: 5| Step: 7
Training loss: 2.02451229095459
Validation loss: 2.06855014575425

Epoch: 5| Step: 8
Training loss: 2.446277618408203
Validation loss: 2.070832093556722

Epoch: 5| Step: 9
Training loss: 1.8147798776626587
Validation loss: 2.0364051403537875

Epoch: 5| Step: 10
Training loss: 2.2014424800872803
Validation loss: 2.0702117745594313

Epoch: 300| Step: 0
Training loss: 2.9900875091552734
Validation loss: 2.0591782780103784

Epoch: 5| Step: 1
Training loss: 1.8790502548217773
Validation loss: 2.0425975681633077

Epoch: 5| Step: 2
Training loss: 1.9107208251953125
Validation loss: 2.0425249863696355

Epoch: 5| Step: 3
Training loss: 1.5211751461029053
Validation loss: 2.066549107592593

Epoch: 5| Step: 4
Training loss: 1.9694287776947021
Validation loss: 2.0900643974222164

Epoch: 5| Step: 5
Training loss: 2.0344271659851074
Validation loss: 2.098502348828059

Epoch: 5| Step: 6
Training loss: 1.6006479263305664
Validation loss: 2.126074251308236

Epoch: 5| Step: 7
Training loss: 2.0990700721740723
Validation loss: 2.1449983812147573

Epoch: 5| Step: 8
Training loss: 1.0418410301208496
Validation loss: 2.1053638919707267

Epoch: 5| Step: 9
Training loss: 1.7373161315917969
Validation loss: 2.0783513361407864

Epoch: 5| Step: 10
Training loss: 1.7865921258926392
Validation loss: 2.0677140066700597

Epoch: 301| Step: 0
Training loss: 1.8030685186386108
Validation loss: 2.066285615326256

Epoch: 5| Step: 1
Training loss: 1.7315280437469482
Validation loss: 2.0730393932711695

Epoch: 5| Step: 2
Training loss: 1.5980638265609741
Validation loss: 2.056702490775816

Epoch: 5| Step: 3
Training loss: 1.6813316345214844
Validation loss: 2.0535614721236692

Epoch: 5| Step: 4
Training loss: 2.1166114807128906
Validation loss: 2.071227724834155

Epoch: 5| Step: 5
Training loss: 1.3947193622589111
Validation loss: 2.056048382994949

Epoch: 5| Step: 6
Training loss: 2.182311534881592
Validation loss: 2.0684531965563373

Epoch: 5| Step: 7
Training loss: 1.7784452438354492
Validation loss: 2.093835228232927

Epoch: 5| Step: 8
Training loss: 2.3336868286132812
Validation loss: 2.11547181939566

Epoch: 5| Step: 9
Training loss: 2.4858317375183105
Validation loss: 2.1433708821573565

Epoch: 5| Step: 10
Training loss: 1.7040867805480957
Validation loss: 2.1712141600988244

Epoch: 302| Step: 0
Training loss: 2.3287720680236816
Validation loss: 2.16240438594613

Epoch: 5| Step: 1
Training loss: 1.7511894702911377
Validation loss: 2.1256902064046552

Epoch: 5| Step: 2
Training loss: 1.94576895236969
Validation loss: 2.0501013494306997

Epoch: 5| Step: 3
Training loss: 2.0472021102905273
Validation loss: 2.03375090834915

Epoch: 5| Step: 4
Training loss: 2.2359471321105957
Validation loss: 2.0340035307791924

Epoch: 5| Step: 5
Training loss: 2.204780340194702
Validation loss: 2.0404812994823662

Epoch: 5| Step: 6
Training loss: 1.8334184885025024
Validation loss: 2.039041297410124

Epoch: 5| Step: 7
Training loss: 1.4157236814498901
Validation loss: 2.038881265988914

Epoch: 5| Step: 8
Training loss: 2.1189043521881104
Validation loss: 2.051540756738314

Epoch: 5| Step: 9
Training loss: 1.3959226608276367
Validation loss: 2.053109368970317

Epoch: 5| Step: 10
Training loss: 1.295823335647583
Validation loss: 2.0605723639970184

Epoch: 303| Step: 0
Training loss: 1.5336259603500366
Validation loss: 2.067289647235665

Epoch: 5| Step: 1
Training loss: 2.1346752643585205
Validation loss: 2.093223875568759

Epoch: 5| Step: 2
Training loss: 1.5750783681869507
Validation loss: 2.099388849350714

Epoch: 5| Step: 3
Training loss: 1.8386472463607788
Validation loss: 2.1075036833363194

Epoch: 5| Step: 4
Training loss: 1.7304151058197021
Validation loss: 2.094553524448026

Epoch: 5| Step: 5
Training loss: 2.026794910430908
Validation loss: 2.1117192314517115

Epoch: 5| Step: 6
Training loss: 1.8230335712432861
Validation loss: 2.1361506139078448

Epoch: 5| Step: 7
Training loss: 1.8525787591934204
Validation loss: 2.1199110374655774

Epoch: 5| Step: 8
Training loss: 1.8073351383209229
Validation loss: 2.1137296768926803

Epoch: 5| Step: 9
Training loss: 1.8815110921859741
Validation loss: 2.094119143742387

Epoch: 5| Step: 10
Training loss: 2.1641528606414795
Validation loss: 2.0907924636717765

Epoch: 304| Step: 0
Training loss: 2.2816834449768066
Validation loss: 2.086921158657279

Epoch: 5| Step: 1
Training loss: 1.098431944847107
Validation loss: 2.072610920475375

Epoch: 5| Step: 2
Training loss: 2.171818733215332
Validation loss: 2.046727620145326

Epoch: 5| Step: 3
Training loss: 2.3510003089904785
Validation loss: 2.041829429646974

Epoch: 5| Step: 4
Training loss: 2.068329334259033
Validation loss: 2.028152105628803

Epoch: 5| Step: 5
Training loss: 1.6775468587875366
Validation loss: 2.028699923587102

Epoch: 5| Step: 6
Training loss: 1.973901391029358
Validation loss: 2.049876066946214

Epoch: 5| Step: 7
Training loss: 1.4784681797027588
Validation loss: 2.0712117687348397

Epoch: 5| Step: 8
Training loss: 1.9448573589324951
Validation loss: 2.0688048690877934

Epoch: 5| Step: 9
Training loss: 2.0112674236297607
Validation loss: 2.07175104079708

Epoch: 5| Step: 10
Training loss: 1.2081432342529297
Validation loss: 2.0935658280567457

Epoch: 305| Step: 0
Training loss: 1.840174913406372
Validation loss: 2.116916186066084

Epoch: 5| Step: 1
Training loss: 2.5544657707214355
Validation loss: 2.153253342515679

Epoch: 5| Step: 2
Training loss: 1.5492818355560303
Validation loss: 2.132365426709575

Epoch: 5| Step: 3
Training loss: 1.908416509628296
Validation loss: 2.1364060806971725

Epoch: 5| Step: 4
Training loss: 1.7889007329940796
Validation loss: 2.12086905458922

Epoch: 5| Step: 5
Training loss: 2.070570468902588
Validation loss: 2.1009173764977405

Epoch: 5| Step: 6
Training loss: 1.37538743019104
Validation loss: 2.0681146152557863

Epoch: 5| Step: 7
Training loss: 1.2221198081970215
Validation loss: 2.1003817768507105

Epoch: 5| Step: 8
Training loss: 2.6008384227752686
Validation loss: 2.105011865656863

Epoch: 5| Step: 9
Training loss: 2.0416836738586426
Validation loss: 2.118004245142783

Epoch: 5| Step: 10
Training loss: 1.4571202993392944
Validation loss: 2.0803490377241567

Epoch: 306| Step: 0
Training loss: 1.2505561113357544
Validation loss: 2.088503594039589

Epoch: 5| Step: 1
Training loss: 1.9949209690093994
Validation loss: 2.0545264264588714

Epoch: 5| Step: 2
Training loss: 2.6562819480895996
Validation loss: 2.0590685029183664

Epoch: 5| Step: 3
Training loss: 1.8891851902008057
Validation loss: 2.0818000173056

Epoch: 5| Step: 4
Training loss: 1.7908445596694946
Validation loss: 2.0875794477360223

Epoch: 5| Step: 5
Training loss: 2.3344249725341797
Validation loss: 2.089690569908388

Epoch: 5| Step: 6
Training loss: 1.699908971786499
Validation loss: 2.087312893200946

Epoch: 5| Step: 7
Training loss: 1.8583290576934814
Validation loss: 2.108341222168297

Epoch: 5| Step: 8
Training loss: 1.619249939918518
Validation loss: 2.072257964841781

Epoch: 5| Step: 9
Training loss: 2.113379716873169
Validation loss: 2.059188573591171

Epoch: 5| Step: 10
Training loss: 1.5210322141647339
Validation loss: 2.0621624326193206

Epoch: 307| Step: 0
Training loss: 1.752422571182251
Validation loss: 2.0705708534486833

Epoch: 5| Step: 1
Training loss: 1.9578144550323486
Validation loss: 2.08937729302273

Epoch: 5| Step: 2
Training loss: 1.882154107093811
Validation loss: 2.0983733156675934

Epoch: 5| Step: 3
Training loss: 2.131803274154663
Validation loss: 2.1271021519937823

Epoch: 5| Step: 4
Training loss: 1.8790019750595093
Validation loss: 2.0981145597273305

Epoch: 5| Step: 5
Training loss: 1.8917102813720703
Validation loss: 2.1554488161558747

Epoch: 5| Step: 6
Training loss: 1.8804702758789062
Validation loss: 2.180434174435113

Epoch: 5| Step: 7
Training loss: 1.491645097732544
Validation loss: 2.2179750857814664

Epoch: 5| Step: 8
Training loss: 1.863189697265625
Validation loss: 2.221177952263945

Epoch: 5| Step: 9
Training loss: 2.06988263130188
Validation loss: 2.1826011314187

Epoch: 5| Step: 10
Training loss: 1.5039347410202026
Validation loss: 2.1466076963691303

Epoch: 308| Step: 0
Training loss: 1.700191855430603
Validation loss: 2.1715054947842836

Epoch: 5| Step: 1
Training loss: 2.1774487495422363
Validation loss: 2.1515453784696517

Epoch: 5| Step: 2
Training loss: 1.5675991773605347
Validation loss: 2.1076121868625766

Epoch: 5| Step: 3
Training loss: 2.4083328247070312
Validation loss: 2.0717369484645065

Epoch: 5| Step: 4
Training loss: 1.7226459980010986
Validation loss: 2.0705046435838104

Epoch: 5| Step: 5
Training loss: 1.6636863946914673
Validation loss: 2.063240835743566

Epoch: 5| Step: 6
Training loss: 2.17897629737854
Validation loss: 2.048325377125894

Epoch: 5| Step: 7
Training loss: 1.74593985080719
Validation loss: 2.0329341170608357

Epoch: 5| Step: 8
Training loss: 1.8171627521514893
Validation loss: 2.007592813943022

Epoch: 5| Step: 9
Training loss: 1.627668023109436
Validation loss: 2.0224241210568334

Epoch: 5| Step: 10
Training loss: 1.7825002670288086
Validation loss: 2.0573141395404773

Epoch: 309| Step: 0
Training loss: 2.1000592708587646
Validation loss: 2.0578403844628284

Epoch: 5| Step: 1
Training loss: 1.0544817447662354
Validation loss: 2.058761214697233

Epoch: 5| Step: 2
Training loss: 1.4813910722732544
Validation loss: 2.0722162620995634

Epoch: 5| Step: 3
Training loss: 2.1726996898651123
Validation loss: 2.0652899716490056

Epoch: 5| Step: 4
Training loss: 1.8614848852157593
Validation loss: 2.0678928026589016

Epoch: 5| Step: 5
Training loss: 1.32915461063385
Validation loss: 2.063755940365535

Epoch: 5| Step: 6
Training loss: 1.9234554767608643
Validation loss: 2.067371009498514

Epoch: 5| Step: 7
Training loss: 2.166355848312378
Validation loss: 2.0641554786312963

Epoch: 5| Step: 8
Training loss: 2.5684356689453125
Validation loss: 2.091855308061005

Epoch: 5| Step: 9
Training loss: 1.4516923427581787
Validation loss: 2.0820757304468462

Epoch: 5| Step: 10
Training loss: 1.899712085723877
Validation loss: 2.0986024974494852

Epoch: 310| Step: 0
Training loss: 1.6462444067001343
Validation loss: 2.086451533020184

Epoch: 5| Step: 1
Training loss: 1.881635069847107
Validation loss: 2.0700930177524524

Epoch: 5| Step: 2
Training loss: 2.209033489227295
Validation loss: 2.0846351628662436

Epoch: 5| Step: 3
Training loss: 1.5436270236968994
Validation loss: 2.0761837574743454

Epoch: 5| Step: 4
Training loss: 2.3377928733825684
Validation loss: 2.0915187417819934

Epoch: 5| Step: 5
Training loss: 2.6524343490600586
Validation loss: 2.0745115023787304

Epoch: 5| Step: 6
Training loss: 2.0280373096466064
Validation loss: 2.0791884942721297

Epoch: 5| Step: 7
Training loss: 1.6238460540771484
Validation loss: 2.117548550328901

Epoch: 5| Step: 8
Training loss: 1.2279537916183472
Validation loss: 2.1003112972423597

Epoch: 5| Step: 9
Training loss: 1.3982725143432617
Validation loss: 2.0977622642312

Epoch: 5| Step: 10
Training loss: 1.2489995956420898
Validation loss: 2.0939040389112247

Epoch: 311| Step: 0
Training loss: 1.6306651830673218
Validation loss: 2.0286516912521853

Epoch: 5| Step: 1
Training loss: 1.2437491416931152
Validation loss: 2.0473355375310427

Epoch: 5| Step: 2
Training loss: 1.629259705543518
Validation loss: 2.0574118642396826

Epoch: 5| Step: 3
Training loss: 1.6683847904205322
Validation loss: 2.0536369713403846

Epoch: 5| Step: 4
Training loss: 1.7196018695831299
Validation loss: 2.071525243020827

Epoch: 5| Step: 5
Training loss: 2.270941972732544
Validation loss: 2.0728798630417034

Epoch: 5| Step: 6
Training loss: 2.2676901817321777
Validation loss: 2.0989181739027782

Epoch: 5| Step: 7
Training loss: 1.9823452234268188
Validation loss: 2.0755373611245105

Epoch: 5| Step: 8
Training loss: 1.6788997650146484
Validation loss: 2.0951524639642365

Epoch: 5| Step: 9
Training loss: 1.8035389184951782
Validation loss: 2.1053358713785806

Epoch: 5| Step: 10
Training loss: 2.0918941497802734
Validation loss: 2.1425125047724736

Epoch: 312| Step: 0
Training loss: 1.5694379806518555
Validation loss: 2.1480990045814106

Epoch: 5| Step: 1
Training loss: 1.5604183673858643
Validation loss: 2.1683158207965154

Epoch: 5| Step: 2
Training loss: 1.6241695880889893
Validation loss: 2.1611624943312777

Epoch: 5| Step: 3
Training loss: 2.0110440254211426
Validation loss: 2.104848941167196

Epoch: 5| Step: 4
Training loss: 1.6967039108276367
Validation loss: 2.076505155973537

Epoch: 5| Step: 5
Training loss: 1.850563406944275
Validation loss: 2.071350852648417

Epoch: 5| Step: 6
Training loss: 1.7200956344604492
Validation loss: 2.058187195049819

Epoch: 5| Step: 7
Training loss: 2.1131539344787598
Validation loss: 2.0461810276072514

Epoch: 5| Step: 8
Training loss: 2.0348098278045654
Validation loss: 2.0147010434058403

Epoch: 5| Step: 9
Training loss: 2.19865083694458
Validation loss: 2.030341162476488

Epoch: 5| Step: 10
Training loss: 2.0252459049224854
Validation loss: 2.0350834861878426

Epoch: 313| Step: 0
Training loss: 1.2815370559692383
Validation loss: 2.0651001481599707

Epoch: 5| Step: 1
Training loss: 1.7953180074691772
Validation loss: 2.067051120983657

Epoch: 5| Step: 2
Training loss: 1.8507344722747803
Validation loss: 2.0734061348822808

Epoch: 5| Step: 3
Training loss: 2.0704822540283203
Validation loss: 2.075338917393838

Epoch: 5| Step: 4
Training loss: 2.021422863006592
Validation loss: 2.1215617887435423

Epoch: 5| Step: 5
Training loss: 1.7886734008789062
Validation loss: 2.0938541594372

Epoch: 5| Step: 6
Training loss: 1.8628265857696533
Validation loss: 2.0973261607590543

Epoch: 5| Step: 7
Training loss: 1.8913075923919678
Validation loss: 2.104193739993598

Epoch: 5| Step: 8
Training loss: 2.1113150119781494
Validation loss: 2.11222082056025

Epoch: 5| Step: 9
Training loss: 1.6625114679336548
Validation loss: 2.0818184678272535

Epoch: 5| Step: 10
Training loss: 1.183247447013855
Validation loss: 2.0810602531638196

Epoch: 314| Step: 0
Training loss: 2.172567844390869
Validation loss: 2.0650138034615466

Epoch: 5| Step: 1
Training loss: 1.7239735126495361
Validation loss: 2.036327290278609

Epoch: 5| Step: 2
Training loss: 1.321548342704773
Validation loss: 2.0336912844770696

Epoch: 5| Step: 3
Training loss: 1.9708877801895142
Validation loss: 2.0324659501352618

Epoch: 5| Step: 4
Training loss: 1.9938551187515259
Validation loss: 2.0194403048484557

Epoch: 5| Step: 5
Training loss: 1.8940503597259521
Validation loss: 2.0098513851883593

Epoch: 5| Step: 6
Training loss: 2.189990997314453
Validation loss: 2.017933835265457

Epoch: 5| Step: 7
Training loss: 1.5821430683135986
Validation loss: 2.0125567451600106

Epoch: 5| Step: 8
Training loss: 1.1329549551010132
Validation loss: 2.017509347649031

Epoch: 5| Step: 9
Training loss: 1.5756523609161377
Validation loss: 2.0682849973760624

Epoch: 5| Step: 10
Training loss: 2.3289902210235596
Validation loss: 2.106888530074909

Epoch: 315| Step: 0
Training loss: 1.338189721107483
Validation loss: 2.120812799340935

Epoch: 5| Step: 1
Training loss: 1.6516262292861938
Validation loss: 2.15087241126645

Epoch: 5| Step: 2
Training loss: 1.7789573669433594
Validation loss: 2.162378873876346

Epoch: 5| Step: 3
Training loss: 1.8970258235931396
Validation loss: 2.155546442154915

Epoch: 5| Step: 4
Training loss: 2.041558027267456
Validation loss: 2.1356380216536985

Epoch: 5| Step: 5
Training loss: 2.140838623046875
Validation loss: 2.1333579299270466

Epoch: 5| Step: 6
Training loss: 2.0340933799743652
Validation loss: 2.1324168661589264

Epoch: 5| Step: 7
Training loss: 1.6998023986816406
Validation loss: 2.107964631049864

Epoch: 5| Step: 8
Training loss: 1.8198143243789673
Validation loss: 2.073300846161381

Epoch: 5| Step: 9
Training loss: 1.9631786346435547
Validation loss: 2.067081594979891

Epoch: 5| Step: 10
Training loss: 1.037352442741394
Validation loss: 2.036415906362636

Epoch: 316| Step: 0
Training loss: 1.7772789001464844
Validation loss: 2.0214719310883553

Epoch: 5| Step: 1
Training loss: 1.8344576358795166
Validation loss: 2.006002564584055

Epoch: 5| Step: 2
Training loss: 2.000838279724121
Validation loss: 1.9937029935980355

Epoch: 5| Step: 3
Training loss: 1.7835273742675781
Validation loss: 2.0064224914837907

Epoch: 5| Step: 4
Training loss: 1.6796042919158936
Validation loss: 1.9973670295489732

Epoch: 5| Step: 5
Training loss: 1.4474858045578003
Validation loss: 2.005850512494323

Epoch: 5| Step: 6
Training loss: 1.8284311294555664
Validation loss: 2.0009876015365764

Epoch: 5| Step: 7
Training loss: 2.0056183338165283
Validation loss: 2.04148296899693

Epoch: 5| Step: 8
Training loss: 1.1054656505584717
Validation loss: 2.066770230570147

Epoch: 5| Step: 9
Training loss: 2.5725085735321045
Validation loss: 2.1312420624558643

Epoch: 5| Step: 10
Training loss: 1.7135487794876099
Validation loss: 2.097372680582026

Epoch: 317| Step: 0
Training loss: 1.918997049331665
Validation loss: 2.105908304132441

Epoch: 5| Step: 1
Training loss: 2.2651429176330566
Validation loss: 2.08275100492662

Epoch: 5| Step: 2
Training loss: 1.2792301177978516
Validation loss: 2.053818092551283

Epoch: 5| Step: 3
Training loss: 2.0550267696380615
Validation loss: 2.0634401344483897

Epoch: 5| Step: 4
Training loss: 1.9241058826446533
Validation loss: 2.05210103014464

Epoch: 5| Step: 5
Training loss: 1.9634662866592407
Validation loss: 2.079925642218641

Epoch: 5| Step: 6
Training loss: 1.5179210901260376
Validation loss: 2.076342653202754

Epoch: 5| Step: 7
Training loss: 1.3651479482650757
Validation loss: 2.0880039276615268

Epoch: 5| Step: 8
Training loss: 1.5081685781478882
Validation loss: 2.0962305953425746

Epoch: 5| Step: 9
Training loss: 2.0800347328186035
Validation loss: 2.1117594626642044

Epoch: 5| Step: 10
Training loss: 1.8877711296081543
Validation loss: 2.079113737229378

Epoch: 318| Step: 0
Training loss: 1.6805765628814697
Validation loss: 2.075941588288994

Epoch: 5| Step: 1
Training loss: 1.8959529399871826
Validation loss: 2.056344796252507

Epoch: 5| Step: 2
Training loss: 2.230483055114746
Validation loss: 2.0383996553318475

Epoch: 5| Step: 3
Training loss: 1.6847892999649048
Validation loss: 2.036202524297981

Epoch: 5| Step: 4
Training loss: 1.5297659635543823
Validation loss: 2.0462784433877594

Epoch: 5| Step: 5
Training loss: 1.5904566049575806
Validation loss: 2.0621728243366366

Epoch: 5| Step: 6
Training loss: 1.4582239389419556
Validation loss: 2.0885593480961298

Epoch: 5| Step: 7
Training loss: 1.732193946838379
Validation loss: 2.0609267180965793

Epoch: 5| Step: 8
Training loss: 2.1229097843170166
Validation loss: 2.083952247455556

Epoch: 5| Step: 9
Training loss: 1.8782081604003906
Validation loss: 2.071245485736478

Epoch: 5| Step: 10
Training loss: 1.478383183479309
Validation loss: 2.0665531389174925

Epoch: 319| Step: 0
Training loss: 1.6938368082046509
Validation loss: 2.0675245151724866

Epoch: 5| Step: 1
Training loss: 2.008122682571411
Validation loss: 2.042774174803047

Epoch: 5| Step: 2
Training loss: 1.5746405124664307
Validation loss: 2.051380447162095

Epoch: 5| Step: 3
Training loss: 1.7452919483184814
Validation loss: 2.027210130486437

Epoch: 5| Step: 4
Training loss: 1.371909499168396
Validation loss: 2.011317148003527

Epoch: 5| Step: 5
Training loss: 1.794301986694336
Validation loss: 2.026764508216612

Epoch: 5| Step: 6
Training loss: 1.9683866500854492
Validation loss: 1.9998929654398272

Epoch: 5| Step: 7
Training loss: 2.1749961376190186
Validation loss: 2.02083267447769

Epoch: 5| Step: 8
Training loss: 2.1427721977233887
Validation loss: 2.026036577840005

Epoch: 5| Step: 9
Training loss: 1.5093014240264893
Validation loss: 2.044702963162494

Epoch: 5| Step: 10
Training loss: 1.2760112285614014
Validation loss: 2.072173362137169

Epoch: 320| Step: 0
Training loss: 1.8073704242706299
Validation loss: 2.117736626696843

Epoch: 5| Step: 1
Training loss: 1.4513566493988037
Validation loss: 2.130121141351679

Epoch: 5| Step: 2
Training loss: 1.8673919439315796
Validation loss: 2.1136649654757593

Epoch: 5| Step: 3
Training loss: 1.7213118076324463
Validation loss: 2.1224611818149524

Epoch: 5| Step: 4
Training loss: 1.9534223079681396
Validation loss: 2.048839707528391

Epoch: 5| Step: 5
Training loss: 2.2022206783294678
Validation loss: 2.0024731979575208

Epoch: 5| Step: 6
Training loss: 1.773832082748413
Validation loss: 2.011259062315828

Epoch: 5| Step: 7
Training loss: 1.567049264907837
Validation loss: 2.0139649632156535

Epoch: 5| Step: 8
Training loss: 1.740216851234436
Validation loss: 2.0230250358581543

Epoch: 5| Step: 9
Training loss: 1.5794408321380615
Validation loss: 2.0256547927856445

Epoch: 5| Step: 10
Training loss: 1.7906501293182373
Validation loss: 2.044357758696361

Epoch: 321| Step: 0
Training loss: 2.3950304985046387
Validation loss: 2.064726911565309

Epoch: 5| Step: 1
Training loss: 2.185070037841797
Validation loss: 2.0660306817741803

Epoch: 5| Step: 2
Training loss: 1.8126165866851807
Validation loss: 2.085161675689041

Epoch: 5| Step: 3
Training loss: 1.7888438701629639
Validation loss: 2.0854746757015103

Epoch: 5| Step: 4
Training loss: 1.4220539331436157
Validation loss: 2.1114940386946484

Epoch: 5| Step: 5
Training loss: 1.0980106592178345
Validation loss: 2.1018127574715564

Epoch: 5| Step: 6
Training loss: 1.438413143157959
Validation loss: 2.1092702932255243

Epoch: 5| Step: 7
Training loss: 1.2900559902191162
Validation loss: 2.0632367518640335

Epoch: 5| Step: 8
Training loss: 2.4176204204559326
Validation loss: 2.0774241826867543

Epoch: 5| Step: 9
Training loss: 1.5538862943649292
Validation loss: 2.0462026224341443

Epoch: 5| Step: 10
Training loss: 1.8543927669525146
Validation loss: 2.0414293658348823

Epoch: 322| Step: 0
Training loss: 1.991851806640625
Validation loss: 2.0123481417214997

Epoch: 5| Step: 1
Training loss: 1.2789266109466553
Validation loss: 2.016790486151172

Epoch: 5| Step: 2
Training loss: 1.407776117324829
Validation loss: 2.024074846698392

Epoch: 5| Step: 3
Training loss: 1.5249686241149902
Validation loss: 2.0175521963386127

Epoch: 5| Step: 4
Training loss: 2.469895124435425
Validation loss: 2.0059732185897006

Epoch: 5| Step: 5
Training loss: 2.1536033153533936
Validation loss: 1.9853772617155505

Epoch: 5| Step: 6
Training loss: 1.6328308582305908
Validation loss: 1.9954333664268575

Epoch: 5| Step: 7
Training loss: 1.7354247570037842
Validation loss: 2.0535465645533737

Epoch: 5| Step: 8
Training loss: 1.4344840049743652
Validation loss: 2.0848680683361587

Epoch: 5| Step: 9
Training loss: 2.1668009757995605
Validation loss: 2.1480940157367336

Epoch: 5| Step: 10
Training loss: 1.8526519536972046
Validation loss: 2.1756616459097913

Epoch: 323| Step: 0
Training loss: 0.9225702285766602
Validation loss: 2.1583656546890095

Epoch: 5| Step: 1
Training loss: 2.5131020545959473
Validation loss: 2.1853501412176315

Epoch: 5| Step: 2
Training loss: 1.5483348369598389
Validation loss: 2.212864342556205

Epoch: 5| Step: 3
Training loss: 1.833593726158142
Validation loss: 2.172323675565822

Epoch: 5| Step: 4
Training loss: 2.069652557373047
Validation loss: 2.1247886303932435

Epoch: 5| Step: 5
Training loss: 1.7270361185073853
Validation loss: 2.060801754715622

Epoch: 5| Step: 6
Training loss: 2.343278408050537
Validation loss: 2.0376011838195143

Epoch: 5| Step: 7
Training loss: 1.9715468883514404
Validation loss: 2.027919623159593

Epoch: 5| Step: 8
Training loss: 1.7465827465057373
Validation loss: 2.0274533571735507

Epoch: 5| Step: 9
Training loss: 1.6890430450439453
Validation loss: 2.033949613571167

Epoch: 5| Step: 10
Training loss: 1.471380352973938
Validation loss: 2.0326288835976714

Epoch: 324| Step: 0
Training loss: 2.193922758102417
Validation loss: 2.0175699598045758

Epoch: 5| Step: 1
Training loss: 1.3866684436798096
Validation loss: 1.999970812951365

Epoch: 5| Step: 2
Training loss: 1.426106333732605
Validation loss: 2.016483570939751

Epoch: 5| Step: 3
Training loss: 1.963090181350708
Validation loss: 2.067645942011187

Epoch: 5| Step: 4
Training loss: 1.7035471200942993
Validation loss: 2.0725626586585917

Epoch: 5| Step: 5
Training loss: 1.576751947402954
Validation loss: 2.1035912780351538

Epoch: 5| Step: 6
Training loss: 2.1597068309783936
Validation loss: 2.1014416653622865

Epoch: 5| Step: 7
Training loss: 1.735538125038147
Validation loss: 2.0488599269620833

Epoch: 5| Step: 8
Training loss: 1.8846553564071655
Validation loss: 2.0287055943601873

Epoch: 5| Step: 9
Training loss: 1.8442445993423462
Validation loss: 1.998171329498291

Epoch: 5| Step: 10
Training loss: 1.4285410642623901
Validation loss: 2.0034971185909805

Epoch: 325| Step: 0
Training loss: 1.453446865081787
Validation loss: 2.010257669674453

Epoch: 5| Step: 1
Training loss: 1.4556280374526978
Validation loss: 2.018297956835839

Epoch: 5| Step: 2
Training loss: 1.436963438987732
Validation loss: 2.0404919065454954

Epoch: 5| Step: 3
Training loss: 2.046945095062256
Validation loss: 2.0355147674519527

Epoch: 5| Step: 4
Training loss: 1.8378574848175049
Validation loss: 2.070818881834707

Epoch: 5| Step: 5
Training loss: 1.891278624534607
Validation loss: 2.0969144836548836

Epoch: 5| Step: 6
Training loss: 1.6625080108642578
Validation loss: 2.142072630184953

Epoch: 5| Step: 7
Training loss: 2.0173771381378174
Validation loss: 2.161096998440322

Epoch: 5| Step: 8
Training loss: 1.413117527961731
Validation loss: 2.130221818083076

Epoch: 5| Step: 9
Training loss: 1.7843668460845947
Validation loss: 2.0929641774905625

Epoch: 5| Step: 10
Training loss: 2.4263803958892822
Validation loss: 2.0758579033677296

Epoch: 326| Step: 0
Training loss: 1.8113759756088257
Validation loss: 2.0526384435674196

Epoch: 5| Step: 1
Training loss: 2.116879940032959
Validation loss: 2.0464307121051255

Epoch: 5| Step: 2
Training loss: 1.5174486637115479
Validation loss: 2.0715499462619906

Epoch: 5| Step: 3
Training loss: 1.3460758924484253
Validation loss: 2.034301850103563

Epoch: 5| Step: 4
Training loss: 2.3507673740386963
Validation loss: 2.035529992913687

Epoch: 5| Step: 5
Training loss: 1.749367117881775
Validation loss: 2.0380264687281784

Epoch: 5| Step: 6
Training loss: 1.343924880027771
Validation loss: 2.0083509337517524

Epoch: 5| Step: 7
Training loss: 1.1046534776687622
Validation loss: 2.004225000258415

Epoch: 5| Step: 8
Training loss: 1.996649146080017
Validation loss: 2.0396020681627336

Epoch: 5| Step: 9
Training loss: 1.9166475534439087
Validation loss: 2.0280330386213077

Epoch: 5| Step: 10
Training loss: 1.560144066810608
Validation loss: 2.0490411814822944

Epoch: 327| Step: 0
Training loss: 1.495382308959961
Validation loss: 2.0447607040405273

Epoch: 5| Step: 1
Training loss: 1.623836874961853
Validation loss: 2.0523082645990516

Epoch: 5| Step: 2
Training loss: 1.7850173711776733
Validation loss: 2.0593242927264144

Epoch: 5| Step: 3
Training loss: 1.4652175903320312
Validation loss: 2.0666880428150134

Epoch: 5| Step: 4
Training loss: 1.451079249382019
Validation loss: 2.074234454862533

Epoch: 5| Step: 5
Training loss: 1.543628454208374
Validation loss: 2.066516735220468

Epoch: 5| Step: 6
Training loss: 1.8255609273910522
Validation loss: 2.081584293355224

Epoch: 5| Step: 7
Training loss: 1.808912992477417
Validation loss: 2.07750508862157

Epoch: 5| Step: 8
Training loss: 2.4573867321014404
Validation loss: 2.062174827821793

Epoch: 5| Step: 9
Training loss: 2.0463085174560547
Validation loss: 2.0424138794663134

Epoch: 5| Step: 10
Training loss: 1.3064415454864502
Validation loss: 2.032819760743008

Epoch: 328| Step: 0
Training loss: 1.956404447555542
Validation loss: 2.0280713291578394

Epoch: 5| Step: 1
Training loss: 1.567657470703125
Validation loss: 2.0223508983530025

Epoch: 5| Step: 2
Training loss: 1.155839204788208
Validation loss: 2.002624464291398

Epoch: 5| Step: 3
Training loss: 1.7410686016082764
Validation loss: 2.0181378113326205

Epoch: 5| Step: 4
Training loss: 2.0246994495391846
Validation loss: 2.02539469990679

Epoch: 5| Step: 5
Training loss: 2.3936920166015625
Validation loss: 2.0088187110039497

Epoch: 5| Step: 6
Training loss: 1.4818944931030273
Validation loss: 2.053894253187282

Epoch: 5| Step: 7
Training loss: 2.4801430702209473
Validation loss: 2.035324199225313

Epoch: 5| Step: 8
Training loss: 1.2106029987335205
Validation loss: 2.058810187924293

Epoch: 5| Step: 9
Training loss: 1.5860952138900757
Validation loss: 2.0710334649649997

Epoch: 5| Step: 10
Training loss: 1.2566896677017212
Validation loss: 2.087128493093675

Epoch: 329| Step: 0
Training loss: 1.8708652257919312
Validation loss: 2.05756740672614

Epoch: 5| Step: 1
Training loss: 1.4098175764083862
Validation loss: 2.0475272106867966

Epoch: 5| Step: 2
Training loss: 1.7925350666046143
Validation loss: 2.0704223366193872

Epoch: 5| Step: 3
Training loss: 2.1904726028442383
Validation loss: 2.034365551446074

Epoch: 5| Step: 4
Training loss: 1.7812057733535767
Validation loss: 2.0128087766708864

Epoch: 5| Step: 5
Training loss: 1.608210563659668
Validation loss: 2.040054081588663

Epoch: 5| Step: 6
Training loss: 1.284113883972168
Validation loss: 2.0203679453942085

Epoch: 5| Step: 7
Training loss: 1.6520946025848389
Validation loss: 2.0086703659385763

Epoch: 5| Step: 8
Training loss: 1.6387304067611694
Validation loss: 2.0113933060758855

Epoch: 5| Step: 9
Training loss: 2.0806756019592285
Validation loss: 2.0396589425302323

Epoch: 5| Step: 10
Training loss: 1.360154151916504
Validation loss: 2.0042411435034966

Epoch: 330| Step: 0
Training loss: 2.25825834274292
Validation loss: 2.0093038300032258

Epoch: 5| Step: 1
Training loss: 1.7465171813964844
Validation loss: 2.0347891904974498

Epoch: 5| Step: 2
Training loss: 1.9781386852264404
Validation loss: 2.0168961837727535

Epoch: 5| Step: 3
Training loss: 1.314713954925537
Validation loss: 2.0344348222978654

Epoch: 5| Step: 4
Training loss: 1.1365433931350708
Validation loss: 2.0083722658054803

Epoch: 5| Step: 5
Training loss: 2.1706039905548096
Validation loss: 2.042212358085058

Epoch: 5| Step: 6
Training loss: 1.9350101947784424
Validation loss: 2.0222281743121404

Epoch: 5| Step: 7
Training loss: 1.3392513990402222
Validation loss: 2.0389618130140406

Epoch: 5| Step: 8
Training loss: 1.6993381977081299
Validation loss: 2.027516339414863

Epoch: 5| Step: 9
Training loss: 1.5993667840957642
Validation loss: 2.052861516193677

Epoch: 5| Step: 10
Training loss: 1.4663963317871094
Validation loss: 2.0671967024444253

Epoch: 331| Step: 0
Training loss: 1.5020391941070557
Validation loss: 2.023518767408145

Epoch: 5| Step: 1
Training loss: 1.9728591442108154
Validation loss: 2.0233004246988604

Epoch: 5| Step: 2
Training loss: 1.701162576675415
Validation loss: 2.0115510404750867

Epoch: 5| Step: 3
Training loss: 1.570549726486206
Validation loss: 2.0128038006444133

Epoch: 5| Step: 4
Training loss: 0.8082877397537231
Validation loss: 2.0144891585073164

Epoch: 5| Step: 5
Training loss: 1.8703620433807373
Validation loss: 2.0275513151640534

Epoch: 5| Step: 6
Training loss: 1.532106637954712
Validation loss: 2.032513915851552

Epoch: 5| Step: 7
Training loss: 1.2169597148895264
Validation loss: 2.0899787320885608

Epoch: 5| Step: 8
Training loss: 2.3925983905792236
Validation loss: 2.1051279242320726

Epoch: 5| Step: 9
Training loss: 1.759627103805542
Validation loss: 2.120441899504713

Epoch: 5| Step: 10
Training loss: 2.4117915630340576
Validation loss: 2.1112601039230183

Epoch: 332| Step: 0
Training loss: 1.8475261926651
Validation loss: 2.0860809010844075

Epoch: 5| Step: 1
Training loss: 1.9066565036773682
Validation loss: 2.063214358463082

Epoch: 5| Step: 2
Training loss: 2.0291550159454346
Validation loss: 2.0344290707700994

Epoch: 5| Step: 3
Training loss: 1.6071075201034546
Validation loss: 1.9905919644140428

Epoch: 5| Step: 4
Training loss: 1.4167686700820923
Validation loss: 1.9872206769963747

Epoch: 5| Step: 5
Training loss: 1.4437322616577148
Validation loss: 1.981175527777723

Epoch: 5| Step: 6
Training loss: 1.7141389846801758
Validation loss: 1.9956437951775008

Epoch: 5| Step: 7
Training loss: 1.479745626449585
Validation loss: 1.9999498513437086

Epoch: 5| Step: 8
Training loss: 1.4832080602645874
Validation loss: 2.0512938550723496

Epoch: 5| Step: 9
Training loss: 1.9452435970306396
Validation loss: 2.0541041051187823

Epoch: 5| Step: 10
Training loss: 1.5586906671524048
Validation loss: 2.0910979778535905

Epoch: 333| Step: 0
Training loss: 1.6006265878677368
Validation loss: 2.086230859961561

Epoch: 5| Step: 1
Training loss: 2.3356661796569824
Validation loss: 2.094268932137438

Epoch: 5| Step: 2
Training loss: 1.735517144203186
Validation loss: 2.1295553381725023

Epoch: 5| Step: 3
Training loss: 1.9949524402618408
Validation loss: 2.116702474573607

Epoch: 5| Step: 4
Training loss: 1.6246732473373413
Validation loss: 2.0557541847229004

Epoch: 5| Step: 5
Training loss: 1.6974350214004517
Validation loss: 2.0234263481632357

Epoch: 5| Step: 6
Training loss: 1.086113691329956
Validation loss: 2.029959842722903

Epoch: 5| Step: 7
Training loss: 1.7859615087509155
Validation loss: 2.0330770143898587

Epoch: 5| Step: 8
Training loss: 1.418637990951538
Validation loss: 2.0571506036225187

Epoch: 5| Step: 9
Training loss: 1.82315993309021
Validation loss: 2.0494204182778635

Epoch: 5| Step: 10
Training loss: 1.789452075958252
Validation loss: 2.0167314288436726

Epoch: 334| Step: 0
Training loss: 2.003579616546631
Validation loss: 1.9826370926313504

Epoch: 5| Step: 1
Training loss: 1.346642017364502
Validation loss: 2.0150633832459808

Epoch: 5| Step: 2
Training loss: 1.3932569026947021
Validation loss: 2.0265825666407102

Epoch: 5| Step: 3
Training loss: 1.8383458852767944
Validation loss: 2.0422835311582013

Epoch: 5| Step: 4
Training loss: 1.3883106708526611
Validation loss: 2.0525386333465576

Epoch: 5| Step: 5
Training loss: 1.7766284942626953
Validation loss: 2.09089869453061

Epoch: 5| Step: 6
Training loss: 1.4972118139266968
Validation loss: 2.0952398982099307

Epoch: 5| Step: 7
Training loss: 1.4775089025497437
Validation loss: 2.0932751829906175

Epoch: 5| Step: 8
Training loss: 1.8156150579452515
Validation loss: 2.1064333582437165

Epoch: 5| Step: 9
Training loss: 1.827021598815918
Validation loss: 2.069656623307095

Epoch: 5| Step: 10
Training loss: 1.9571675062179565
Validation loss: 2.0652180025654454

Epoch: 335| Step: 0
Training loss: 1.5607883930206299
Validation loss: 2.0259903182265577

Epoch: 5| Step: 1
Training loss: 1.552364706993103
Validation loss: 2.031094592104676

Epoch: 5| Step: 2
Training loss: 2.027318000793457
Validation loss: 2.031161421088762

Epoch: 5| Step: 3
Training loss: 1.549041748046875
Validation loss: 2.0302484881493355

Epoch: 5| Step: 4
Training loss: 1.540523886680603
Validation loss: 2.0065308360643286

Epoch: 5| Step: 5
Training loss: 1.018480658531189
Validation loss: 2.024209850577898

Epoch: 5| Step: 6
Training loss: 1.724547028541565
Validation loss: 2.034146879308967

Epoch: 5| Step: 7
Training loss: 1.8281304836273193
Validation loss: 2.0520842177893526

Epoch: 5| Step: 8
Training loss: 1.7392635345458984
Validation loss: 2.042734848555698

Epoch: 5| Step: 9
Training loss: 1.6572802066802979
Validation loss: 2.025818914495489

Epoch: 5| Step: 10
Training loss: 1.8272817134857178
Validation loss: 2.0154485164150113

Epoch: 336| Step: 0
Training loss: 1.6516029834747314
Validation loss: 2.018935029224683

Epoch: 5| Step: 1
Training loss: 1.2575182914733887
Validation loss: 2.0128700528093564

Epoch: 5| Step: 2
Training loss: 1.7701514959335327
Validation loss: 2.009189678776649

Epoch: 5| Step: 3
Training loss: 1.6446930170059204
Validation loss: 2.0217406711270733

Epoch: 5| Step: 4
Training loss: 1.743160605430603
Validation loss: 2.0298735967246433

Epoch: 5| Step: 5
Training loss: 1.2989389896392822
Validation loss: 1.9961148590169928

Epoch: 5| Step: 6
Training loss: 1.7586408853530884
Validation loss: 2.0046800592894196

Epoch: 5| Step: 7
Training loss: 1.902575135231018
Validation loss: 2.036242751665013

Epoch: 5| Step: 8
Training loss: 1.6926910877227783
Validation loss: 2.030485377516798

Epoch: 5| Step: 9
Training loss: 1.3136894702911377
Validation loss: 2.035824397558807

Epoch: 5| Step: 10
Training loss: 2.01103138923645
Validation loss: 2.040955769118442

Epoch: 337| Step: 0
Training loss: 0.9487141370773315
Validation loss: 2.045739837872085

Epoch: 5| Step: 1
Training loss: 1.9266468286514282
Validation loss: 2.0955333145715858

Epoch: 5| Step: 2
Training loss: 1.079361915588379
Validation loss: 2.1073358469111945

Epoch: 5| Step: 3
Training loss: 1.3054012060165405
Validation loss: 2.1261685573926536

Epoch: 5| Step: 4
Training loss: 2.0425236225128174
Validation loss: 2.134885544418007

Epoch: 5| Step: 5
Training loss: 2.19631290435791
Validation loss: 2.0960084597269693

Epoch: 5| Step: 6
Training loss: 1.5864107608795166
Validation loss: 2.068251771311606

Epoch: 5| Step: 7
Training loss: 2.0549511909484863
Validation loss: 2.0611123551604567

Epoch: 5| Step: 8
Training loss: 1.6846494674682617
Validation loss: 2.0662948598143873

Epoch: 5| Step: 9
Training loss: 1.6491405963897705
Validation loss: 2.0446237056486067

Epoch: 5| Step: 10
Training loss: 1.6604338884353638
Validation loss: 2.052158227530859

Epoch: 338| Step: 0
Training loss: 1.5574954748153687
Validation loss: 2.0519007380290697

Epoch: 5| Step: 1
Training loss: 1.468585729598999
Validation loss: 2.0178164435971166

Epoch: 5| Step: 2
Training loss: 1.0414326190948486
Validation loss: 2.0119886667497697

Epoch: 5| Step: 3
Training loss: 1.959022879600525
Validation loss: 1.9896118820354503

Epoch: 5| Step: 4
Training loss: 2.211045503616333
Validation loss: 2.0002970054585445

Epoch: 5| Step: 5
Training loss: 1.3373621702194214
Validation loss: 2.0043007225118656

Epoch: 5| Step: 6
Training loss: 1.8842239379882812
Validation loss: 1.9938673396264353

Epoch: 5| Step: 7
Training loss: 1.7663190364837646
Validation loss: 2.0152715713747087

Epoch: 5| Step: 8
Training loss: 2.213183641433716
Validation loss: 2.015136626458937

Epoch: 5| Step: 9
Training loss: 1.092297911643982
Validation loss: 2.0574603747296076

Epoch: 5| Step: 10
Training loss: 1.3832613229751587
Validation loss: 2.049683173497518

Epoch: 339| Step: 0
Training loss: 1.9365240335464478
Validation loss: 2.071514659030463

Epoch: 5| Step: 1
Training loss: 1.470597267150879
Validation loss: 2.0432334215410295

Epoch: 5| Step: 2
Training loss: 1.5483238697052002
Validation loss: 2.0514023380894817

Epoch: 5| Step: 3
Training loss: 1.3476121425628662
Validation loss: 2.078301873258365

Epoch: 5| Step: 4
Training loss: 1.676560401916504
Validation loss: 2.0520520979358303

Epoch: 5| Step: 5
Training loss: 1.9190242290496826
Validation loss: 2.0657191404732327

Epoch: 5| Step: 6
Training loss: 1.9002933502197266
Validation loss: 2.0595914971443916

Epoch: 5| Step: 7
Training loss: 1.3202574253082275
Validation loss: 2.0264856174427974

Epoch: 5| Step: 8
Training loss: 1.5262253284454346
Validation loss: 2.003718482550754

Epoch: 5| Step: 9
Training loss: 1.4782673120498657
Validation loss: 1.9823048345504268

Epoch: 5| Step: 10
Training loss: 1.7555149793624878
Validation loss: 1.9820074676185526

Epoch: 340| Step: 0
Training loss: 2.0175137519836426
Validation loss: 2.0092520726624357

Epoch: 5| Step: 1
Training loss: 2.1068484783172607
Validation loss: 2.01844891425102

Epoch: 5| Step: 2
Training loss: 1.957665205001831
Validation loss: 2.0333455736919115

Epoch: 5| Step: 3
Training loss: 1.2483789920806885
Validation loss: 2.0713558350839922

Epoch: 5| Step: 4
Training loss: 1.2945711612701416
Validation loss: 2.0801000146455664

Epoch: 5| Step: 5
Training loss: 2.1158645153045654
Validation loss: 2.0673212364155757

Epoch: 5| Step: 6
Training loss: 1.556663990020752
Validation loss: 2.0678044544753207

Epoch: 5| Step: 7
Training loss: 1.2536405324935913
Validation loss: 2.067483079048895

Epoch: 5| Step: 8
Training loss: 1.448919415473938
Validation loss: 2.0558156608253397

Epoch: 5| Step: 9
Training loss: 1.6671676635742188
Validation loss: 2.029298274747787

Epoch: 5| Step: 10
Training loss: 1.2154206037521362
Validation loss: 2.056043137786209

Epoch: 341| Step: 0
Training loss: 1.7171993255615234
Validation loss: 2.0361890741573867

Epoch: 5| Step: 1
Training loss: 1.5188908576965332
Validation loss: 2.0331002422558364

Epoch: 5| Step: 2
Training loss: 1.3444468975067139
Validation loss: 2.065095364406545

Epoch: 5| Step: 3
Training loss: 1.6102275848388672
Validation loss: 2.0889070726210073

Epoch: 5| Step: 4
Training loss: 1.4048770666122437
Validation loss: 2.0657458395086308

Epoch: 5| Step: 5
Training loss: 1.7890770435333252
Validation loss: 2.0522729914675475

Epoch: 5| Step: 6
Training loss: 1.3176114559173584
Validation loss: 2.0668102208004204

Epoch: 5| Step: 7
Training loss: 1.5442615747451782
Validation loss: 2.0567123505377

Epoch: 5| Step: 8
Training loss: 1.7060874700546265
Validation loss: 2.04063154292363

Epoch: 5| Step: 9
Training loss: 2.4531288146972656
Validation loss: 2.0378604089060137

Epoch: 5| Step: 10
Training loss: 1.4288139343261719
Validation loss: 2.0378223439698577

Epoch: 342| Step: 0
Training loss: 1.4079656600952148
Validation loss: 2.0177437977124284

Epoch: 5| Step: 1
Training loss: 1.4833223819732666
Validation loss: 2.0017780129627516

Epoch: 5| Step: 2
Training loss: 1.752183198928833
Validation loss: 1.9952243451149232

Epoch: 5| Step: 3
Training loss: 1.2319796085357666
Validation loss: 1.9960319713879657

Epoch: 5| Step: 4
Training loss: 1.8649113178253174
Validation loss: 1.98722574146845

Epoch: 5| Step: 5
Training loss: 2.1819796562194824
Validation loss: 1.9778968390598093

Epoch: 5| Step: 6
Training loss: 1.4610254764556885
Validation loss: 2.001698758012505

Epoch: 5| Step: 7
Training loss: 1.4029096364974976
Validation loss: 2.000437812138629

Epoch: 5| Step: 8
Training loss: 1.583882212638855
Validation loss: 1.9983386237134215

Epoch: 5| Step: 9
Training loss: 1.5706794261932373
Validation loss: 2.0327008437084895

Epoch: 5| Step: 10
Training loss: 1.456494688987732
Validation loss: 2.0375451554534254

Epoch: 343| Step: 0
Training loss: 1.5182174444198608
Validation loss: 2.1071719623381093

Epoch: 5| Step: 1
Training loss: 2.089092254638672
Validation loss: 2.125836322384496

Epoch: 5| Step: 2
Training loss: 1.3434330224990845
Validation loss: 2.102857624330828

Epoch: 5| Step: 3
Training loss: 1.5361700057983398
Validation loss: 2.0745541767407487

Epoch: 5| Step: 4
Training loss: 1.2883329391479492
Validation loss: 2.076052560601183

Epoch: 5| Step: 5
Training loss: 1.4350924491882324
Validation loss: 2.0483230044764857

Epoch: 5| Step: 6
Training loss: 1.3575150966644287
Validation loss: 2.023451728205527

Epoch: 5| Step: 7
Training loss: 1.5885111093521118
Validation loss: 2.046785803251369

Epoch: 5| Step: 8
Training loss: 1.2968590259552002
Validation loss: 2.009416005944693

Epoch: 5| Step: 9
Training loss: 1.6422693729400635
Validation loss: 2.0018249891137563

Epoch: 5| Step: 10
Training loss: 2.543111801147461
Validation loss: 2.0134600157378824

Epoch: 344| Step: 0
Training loss: 1.4099222421646118
Validation loss: 1.9969719686815817

Epoch: 5| Step: 1
Training loss: 1.9221694469451904
Validation loss: 2.0554603043422905

Epoch: 5| Step: 2
Training loss: 1.2313168048858643
Validation loss: 2.0180483915472545

Epoch: 5| Step: 3
Training loss: 1.6563224792480469
Validation loss: 2.0417666127604823

Epoch: 5| Step: 4
Training loss: 1.4158875942230225
Validation loss: 2.052135626475016

Epoch: 5| Step: 5
Training loss: 1.7192013263702393
Validation loss: 2.0596688101368565

Epoch: 5| Step: 6
Training loss: 2.190720319747925
Validation loss: 2.0579582106682563

Epoch: 5| Step: 7
Training loss: 1.5742789506912231
Validation loss: 2.063408677295972

Epoch: 5| Step: 8
Training loss: 1.444056510925293
Validation loss: 2.0626763733484412

Epoch: 5| Step: 9
Training loss: 1.251132845878601
Validation loss: 2.052793604071422

Epoch: 5| Step: 10
Training loss: 1.3878326416015625
Validation loss: 2.0313058002020723

Epoch: 345| Step: 0
Training loss: 1.8957006931304932
Validation loss: 2.0096881697254796

Epoch: 5| Step: 1
Training loss: 2.079512119293213
Validation loss: 1.9922695980277112

Epoch: 5| Step: 2
Training loss: 1.8845634460449219
Validation loss: 2.0120159567043348

Epoch: 5| Step: 3
Training loss: 1.0868828296661377
Validation loss: 1.9876704498003888

Epoch: 5| Step: 4
Training loss: 1.8280737400054932
Validation loss: 2.0318670426645586

Epoch: 5| Step: 5
Training loss: 1.3276985883712769
Validation loss: 2.0259241416890132

Epoch: 5| Step: 6
Training loss: 1.44118332862854
Validation loss: 2.048672740177442

Epoch: 5| Step: 7
Training loss: 1.1341898441314697
Validation loss: 2.0375110949239423

Epoch: 5| Step: 8
Training loss: 1.2894948720932007
Validation loss: 2.04567462910888

Epoch: 5| Step: 9
Training loss: 1.320578694343567
Validation loss: 2.0301732017147924

Epoch: 5| Step: 10
Training loss: 2.0708441734313965
Validation loss: 2.0106117263917

Epoch: 346| Step: 0
Training loss: 2.3002748489379883
Validation loss: 2.0244302621451755

Epoch: 5| Step: 1
Training loss: 2.2540462017059326
Validation loss: 2.001403293301982

Epoch: 5| Step: 2
Training loss: 1.5974904298782349
Validation loss: 1.9913696230098765

Epoch: 5| Step: 3
Training loss: 1.0173472166061401
Validation loss: 1.9652904489988923

Epoch: 5| Step: 4
Training loss: 1.6532649993896484
Validation loss: 1.9990622676828855

Epoch: 5| Step: 5
Training loss: 1.6304982900619507
Validation loss: 2.003636201222738

Epoch: 5| Step: 6
Training loss: 1.9241631031036377
Validation loss: 2.039157868713461

Epoch: 5| Step: 7
Training loss: 1.2493401765823364
Validation loss: 2.039570795592441

Epoch: 5| Step: 8
Training loss: 1.178615927696228
Validation loss: 2.048679273615601

Epoch: 5| Step: 9
Training loss: 1.3322678804397583
Validation loss: 2.0548788373188307

Epoch: 5| Step: 10
Training loss: 1.2616147994995117
Validation loss: 2.068761007760161

Epoch: 347| Step: 0
Training loss: 1.743395447731018
Validation loss: 2.1227589653384302

Epoch: 5| Step: 1
Training loss: 1.6906884908676147
Validation loss: 2.1773634700364966

Epoch: 5| Step: 2
Training loss: 0.9815664291381836
Validation loss: 2.139196190782773

Epoch: 5| Step: 3
Training loss: 1.235884428024292
Validation loss: 2.1045746213646344

Epoch: 5| Step: 4
Training loss: 1.716604232788086
Validation loss: 2.0832575418615855

Epoch: 5| Step: 5
Training loss: 1.4951797723770142
Validation loss: 2.0720095813915296

Epoch: 5| Step: 6
Training loss: 1.604820966720581
Validation loss: 2.0588972888967043

Epoch: 5| Step: 7
Training loss: 1.3537359237670898
Validation loss: 2.05978230250779

Epoch: 5| Step: 8
Training loss: 1.9867992401123047
Validation loss: 2.0532869010843258

Epoch: 5| Step: 9
Training loss: 1.801730751991272
Validation loss: 2.0276636000602477

Epoch: 5| Step: 10
Training loss: 1.846242070198059
Validation loss: 1.968014314610471

Epoch: 348| Step: 0
Training loss: 1.627399206161499
Validation loss: 1.9762220639054493

Epoch: 5| Step: 1
Training loss: 1.8024041652679443
Validation loss: 1.9611484953152236

Epoch: 5| Step: 2
Training loss: 2.047489643096924
Validation loss: 1.9569887371473416

Epoch: 5| Step: 3
Training loss: 1.9380476474761963
Validation loss: 1.9472130678033317

Epoch: 5| Step: 4
Training loss: 0.9353049993515015
Validation loss: 1.946466069067678

Epoch: 5| Step: 5
Training loss: 1.5478723049163818
Validation loss: 1.96464402444901

Epoch: 5| Step: 6
Training loss: 1.403860330581665
Validation loss: 2.0058690629979616

Epoch: 5| Step: 7
Training loss: 1.3899985551834106
Validation loss: 2.038591247732921

Epoch: 5| Step: 8
Training loss: 1.9033401012420654
Validation loss: 2.06823000472079

Epoch: 5| Step: 9
Training loss: 1.4670194387435913
Validation loss: 2.102132902350477

Epoch: 5| Step: 10
Training loss: 1.3807259798049927
Validation loss: 2.1023548854294645

Epoch: 349| Step: 0
Training loss: 2.0496790409088135
Validation loss: 2.0764206147963002

Epoch: 5| Step: 1
Training loss: 1.221622109413147
Validation loss: 2.072270147262081

Epoch: 5| Step: 2
Training loss: 2.0054314136505127
Validation loss: 2.073877852450135

Epoch: 5| Step: 3
Training loss: 1.0761557817459106
Validation loss: 2.071604290316182

Epoch: 5| Step: 4
Training loss: 1.5815575122833252
Validation loss: 2.081938066790181

Epoch: 5| Step: 5
Training loss: 2.149312734603882
Validation loss: 2.065010006709765

Epoch: 5| Step: 6
Training loss: 1.6953856945037842
Validation loss: 2.0906733543642106

Epoch: 5| Step: 7
Training loss: 1.389162302017212
Validation loss: 2.080367857410062

Epoch: 5| Step: 8
Training loss: 1.134549617767334
Validation loss: 2.0651339318162654

Epoch: 5| Step: 9
Training loss: 1.3015650510787964
Validation loss: 2.0554230302892704

Epoch: 5| Step: 10
Training loss: 1.5316495895385742
Validation loss: 2.054641910778579

Epoch: 350| Step: 0
Training loss: 1.2406532764434814
Validation loss: 2.0539718597166

Epoch: 5| Step: 1
Training loss: 1.8078006505966187
Validation loss: 2.076757445130297

Epoch: 5| Step: 2
Training loss: 1.8081896305084229
Validation loss: 2.054310529462753

Epoch: 5| Step: 3
Training loss: 1.413879632949829
Validation loss: 2.0494345324013823

Epoch: 5| Step: 4
Training loss: 1.416033148765564
Validation loss: 2.061627495673395

Epoch: 5| Step: 5
Training loss: 1.8340599536895752
Validation loss: 2.055088609777471

Epoch: 5| Step: 6
Training loss: 1.7637779712677002
Validation loss: 2.0539050704689434

Epoch: 5| Step: 7
Training loss: 1.1774466037750244
Validation loss: 2.0440598072544223

Epoch: 5| Step: 8
Training loss: 1.8527816534042358
Validation loss: 2.0300247964038642

Epoch: 5| Step: 9
Training loss: 1.169168472290039
Validation loss: 2.018329812634376

Epoch: 5| Step: 10
Training loss: 1.4133580923080444
Validation loss: 2.003144802585725

Epoch: 351| Step: 0
Training loss: 1.5696955919265747
Validation loss: 2.0172472717941448

Epoch: 5| Step: 1
Training loss: 1.927635908126831
Validation loss: 2.0407897528781684

Epoch: 5| Step: 2
Training loss: 1.8261024951934814
Validation loss: 2.0703886042359056

Epoch: 5| Step: 3
Training loss: 1.5163955688476562
Validation loss: 2.0787189468260734

Epoch: 5| Step: 4
Training loss: 0.9475944638252258
Validation loss: 2.1342463518983577

Epoch: 5| Step: 5
Training loss: 1.502628207206726
Validation loss: 2.129569997069656

Epoch: 5| Step: 6
Training loss: 1.6151514053344727
Validation loss: 2.118862831464378

Epoch: 5| Step: 7
Training loss: 1.4076287746429443
Validation loss: 2.148447859671808

Epoch: 5| Step: 8
Training loss: 1.766924500465393
Validation loss: 2.0866802315558157

Epoch: 5| Step: 9
Training loss: 1.352832555770874
Validation loss: 2.100732280362037

Epoch: 5| Step: 10
Training loss: 1.4642720222473145
Validation loss: 2.030727358274562

Epoch: 352| Step: 0
Training loss: 1.5220317840576172
Validation loss: 1.990736399927447

Epoch: 5| Step: 1
Training loss: 1.4195445775985718
Validation loss: 1.980101534115371

Epoch: 5| Step: 2
Training loss: 2.0709829330444336
Validation loss: 2.0014019268815235

Epoch: 5| Step: 3
Training loss: 1.5990619659423828
Validation loss: 1.966577656807438

Epoch: 5| Step: 4
Training loss: 1.500948190689087
Validation loss: 1.9859989612333235

Epoch: 5| Step: 5
Training loss: 1.7201690673828125
Validation loss: 1.9850505590438843

Epoch: 5| Step: 6
Training loss: 1.5467015504837036
Validation loss: 1.9996511372186805

Epoch: 5| Step: 7
Training loss: 1.4991651773452759
Validation loss: 2.0066133417109007

Epoch: 5| Step: 8
Training loss: 1.3185911178588867
Validation loss: 1.9997173765654206

Epoch: 5| Step: 9
Training loss: 1.057105302810669
Validation loss: 2.023523367861266

Epoch: 5| Step: 10
Training loss: 1.3473303318023682
Validation loss: 2.021193295396784

Epoch: 353| Step: 0
Training loss: 1.3171756267547607
Validation loss: 2.0154671207551034

Epoch: 5| Step: 1
Training loss: 1.742361068725586
Validation loss: 2.0569904337647142

Epoch: 5| Step: 2
Training loss: 1.7844187021255493
Validation loss: 2.0617404035342637

Epoch: 5| Step: 3
Training loss: 0.597608745098114
Validation loss: 2.0916415388866136

Epoch: 5| Step: 4
Training loss: 1.0553239583969116
Validation loss: 2.0862040468441543

Epoch: 5| Step: 5
Training loss: 1.762642502784729
Validation loss: 2.136571068917551

Epoch: 5| Step: 6
Training loss: 1.3398983478546143
Validation loss: 2.0846571307028494

Epoch: 5| Step: 7
Training loss: 1.4247132539749146
Validation loss: 2.0339081697566535

Epoch: 5| Step: 8
Training loss: 1.799319863319397
Validation loss: 1.9985987601741668

Epoch: 5| Step: 9
Training loss: 1.8572285175323486
Validation loss: 1.977514083667468

Epoch: 5| Step: 10
Training loss: 1.8820991516113281
Validation loss: 1.9800837129674933

Epoch: 354| Step: 0
Training loss: 1.2798024415969849
Validation loss: 1.9830981659632858

Epoch: 5| Step: 1
Training loss: 1.1987295150756836
Validation loss: 2.002153604261337

Epoch: 5| Step: 2
Training loss: 1.3569889068603516
Validation loss: 1.9903255713883268

Epoch: 5| Step: 3
Training loss: 1.644781470298767
Validation loss: 2.024143875286143

Epoch: 5| Step: 4
Training loss: 1.3610188961029053
Validation loss: 2.0495019676864787

Epoch: 5| Step: 5
Training loss: 1.5262678861618042
Validation loss: 2.044768387271512

Epoch: 5| Step: 6
Training loss: 1.8811982870101929
Validation loss: 2.0550504179411035

Epoch: 5| Step: 7
Training loss: 1.9892269372940063
Validation loss: 2.040797136163199

Epoch: 5| Step: 8
Training loss: 1.6467132568359375
Validation loss: 2.019727973527806

Epoch: 5| Step: 9
Training loss: 1.0308201313018799
Validation loss: 1.9995796347177157

Epoch: 5| Step: 10
Training loss: 1.782636284828186
Validation loss: 1.994741783347181

Epoch: 355| Step: 0
Training loss: 1.6460106372833252
Validation loss: 1.9937283556948426

Epoch: 5| Step: 1
Training loss: 1.4218310117721558
Validation loss: 1.9635097031952233

Epoch: 5| Step: 2
Training loss: 1.4527591466903687
Validation loss: 1.9586497558060514

Epoch: 5| Step: 3
Training loss: 2.0389368534088135
Validation loss: 1.971264511026362

Epoch: 5| Step: 4
Training loss: 1.760926604270935
Validation loss: 1.9738211644593107

Epoch: 5| Step: 5
Training loss: 1.6621043682098389
Validation loss: 1.9740908556087042

Epoch: 5| Step: 6
Training loss: 1.3298622369766235
Validation loss: 1.9938335200791717

Epoch: 5| Step: 7
Training loss: 1.7776607275009155
Validation loss: 2.00010565147605

Epoch: 5| Step: 8
Training loss: 1.1706252098083496
Validation loss: 2.003448486328125

Epoch: 5| Step: 9
Training loss: 1.2102692127227783
Validation loss: 1.983271057887744

Epoch: 5| Step: 10
Training loss: 0.998825192451477
Validation loss: 2.0105085898471136

Epoch: 356| Step: 0
Training loss: 2.0194685459136963
Validation loss: 2.0601884075390395

Epoch: 5| Step: 1
Training loss: 1.66701340675354
Validation loss: 2.032565347609981

Epoch: 5| Step: 2
Training loss: 0.9498618245124817
Validation loss: 2.038610330191992

Epoch: 5| Step: 3
Training loss: 1.7523990869522095
Validation loss: 2.047294762826735

Epoch: 5| Step: 4
Training loss: 1.9709465503692627
Validation loss: 2.075786872576642

Epoch: 5| Step: 5
Training loss: 1.56121027469635
Validation loss: 2.0749501951279177

Epoch: 5| Step: 6
Training loss: 0.9434638023376465
Validation loss: 2.070298130794238

Epoch: 5| Step: 7
Training loss: 1.5101274251937866
Validation loss: 2.0621751123859036

Epoch: 5| Step: 8
Training loss: 1.3625783920288086
Validation loss: 2.0000257004973707

Epoch: 5| Step: 9
Training loss: 1.5519741773605347
Validation loss: 1.9599220060533094

Epoch: 5| Step: 10
Training loss: 1.172752022743225
Validation loss: 1.9594514100782332

Epoch: 357| Step: 0
Training loss: 2.225724458694458
Validation loss: 1.9720098959502352

Epoch: 5| Step: 1
Training loss: 1.9567476511001587
Validation loss: 1.9599278075720674

Epoch: 5| Step: 2
Training loss: 1.9692264795303345
Validation loss: 1.9571904161924958

Epoch: 5| Step: 3
Training loss: 0.9770216941833496
Validation loss: 1.9481738395588373

Epoch: 5| Step: 4
Training loss: 1.4207581281661987
Validation loss: 1.9803964937886884

Epoch: 5| Step: 5
Training loss: 0.9800513386726379
Validation loss: 1.9930093057693974

Epoch: 5| Step: 6
Training loss: 1.9328981637954712
Validation loss: 1.9876782407042801

Epoch: 5| Step: 7
Training loss: 1.4582875967025757
Validation loss: 2.004998376292567

Epoch: 5| Step: 8
Training loss: 1.0670169591903687
Validation loss: 2.0397670256194247

Epoch: 5| Step: 9
Training loss: 1.3681540489196777
Validation loss: 2.074838448596257

Epoch: 5| Step: 10
Training loss: 0.9859017729759216
Validation loss: 2.0809049016685894

Epoch: 358| Step: 0
Training loss: 1.2917029857635498
Validation loss: 2.0742081544732534

Epoch: 5| Step: 1
Training loss: 0.8859207034111023
Validation loss: 2.090883901042323

Epoch: 5| Step: 2
Training loss: 1.5433614253997803
Validation loss: 2.0719882096013715

Epoch: 5| Step: 3
Training loss: 1.7367254495620728
Validation loss: 2.060343393715479

Epoch: 5| Step: 4
Training loss: 1.6174936294555664
Validation loss: 2.0266503287899877

Epoch: 5| Step: 5
Training loss: 1.5550296306610107
Validation loss: 2.03220610977501

Epoch: 5| Step: 6
Training loss: 1.6356899738311768
Validation loss: 1.9996942166359193

Epoch: 5| Step: 7
Training loss: 1.6455631256103516
Validation loss: 1.9999687594752158

Epoch: 5| Step: 8
Training loss: 1.3505885601043701
Validation loss: 1.964959830366155

Epoch: 5| Step: 9
Training loss: 1.3816852569580078
Validation loss: 1.9802050411060292

Epoch: 5| Step: 10
Training loss: 1.6464354991912842
Validation loss: 1.9619862930749052

Epoch: 359| Step: 0
Training loss: 1.4245507717132568
Validation loss: 1.9945564013655468

Epoch: 5| Step: 1
Training loss: 1.5688085556030273
Validation loss: 2.0201007704580984

Epoch: 5| Step: 2
Training loss: 1.0931470394134521
Validation loss: 2.0542952552918465

Epoch: 5| Step: 3
Training loss: 1.4941173791885376
Validation loss: 2.061055056510433

Epoch: 5| Step: 4
Training loss: 1.5450503826141357
Validation loss: 2.023763072106146

Epoch: 5| Step: 5
Training loss: 1.5447051525115967
Validation loss: 2.019282084639354

Epoch: 5| Step: 6
Training loss: 1.6292587518692017
Validation loss: 2.018087435794133

Epoch: 5| Step: 7
Training loss: 1.3357998132705688
Validation loss: 1.9965914167383665

Epoch: 5| Step: 8
Training loss: 1.8074805736541748
Validation loss: 1.9826343956814017

Epoch: 5| Step: 9
Training loss: 0.9668265581130981
Validation loss: 1.9978465777571484

Epoch: 5| Step: 10
Training loss: 1.8361501693725586
Validation loss: 1.9870538839729883

Epoch: 360| Step: 0
Training loss: 1.535789132118225
Validation loss: 1.992436690997052

Epoch: 5| Step: 1
Training loss: 1.6793403625488281
Validation loss: 1.9992937939141386

Epoch: 5| Step: 2
Training loss: 1.5595792531967163
Validation loss: 1.9959971392026512

Epoch: 5| Step: 3
Training loss: 1.4733073711395264
Validation loss: 2.03624859035656

Epoch: 5| Step: 4
Training loss: 1.6458085775375366
Validation loss: 2.068153373656734

Epoch: 5| Step: 5
Training loss: 0.9140018224716187
Validation loss: 2.054725008626138

Epoch: 5| Step: 6
Training loss: 1.4434382915496826
Validation loss: 2.060098945453603

Epoch: 5| Step: 7
Training loss: 1.6702616214752197
Validation loss: 2.043976331269869

Epoch: 5| Step: 8
Training loss: 1.565688967704773
Validation loss: 2.0359445771863385

Epoch: 5| Step: 9
Training loss: 1.2470180988311768
Validation loss: 2.0046084875701577

Epoch: 5| Step: 10
Training loss: 1.3270858526229858
Validation loss: 1.9800461133321126

Epoch: 361| Step: 0
Training loss: 1.3119882345199585
Validation loss: 1.9719381960489417

Epoch: 5| Step: 1
Training loss: 1.264049768447876
Validation loss: 1.9425401379985194

Epoch: 5| Step: 2
Training loss: 1.4603781700134277
Validation loss: 1.9385364017178934

Epoch: 5| Step: 3
Training loss: 1.8531763553619385
Validation loss: 1.959196816208542

Epoch: 5| Step: 4
Training loss: 1.3737521171569824
Validation loss: 1.9768679975181498

Epoch: 5| Step: 5
Training loss: 1.5568227767944336
Validation loss: 1.9852150755543863

Epoch: 5| Step: 6
Training loss: 1.049638032913208
Validation loss: 2.01929485541518

Epoch: 5| Step: 7
Training loss: 1.3315098285675049
Validation loss: 2.0432872156943045

Epoch: 5| Step: 8
Training loss: 1.9146146774291992
Validation loss: 2.0344793860630324

Epoch: 5| Step: 9
Training loss: 1.7639198303222656
Validation loss: 2.0388890748382895

Epoch: 5| Step: 10
Training loss: 1.0335514545440674
Validation loss: 2.045950415313885

Epoch: 362| Step: 0
Training loss: 1.6645370721817017
Validation loss: 2.0067952268867084

Epoch: 5| Step: 1
Training loss: 1.4361071586608887
Validation loss: 1.9742889955479612

Epoch: 5| Step: 2
Training loss: 1.6711461544036865
Validation loss: 1.969216562086536

Epoch: 5| Step: 3
Training loss: 1.201663613319397
Validation loss: 1.940343867066086

Epoch: 5| Step: 4
Training loss: 1.323216438293457
Validation loss: 1.9642092002335416

Epoch: 5| Step: 5
Training loss: 1.4295570850372314
Validation loss: 1.9604311322653165

Epoch: 5| Step: 6
Training loss: 1.1562881469726562
Validation loss: 1.9898483625022314

Epoch: 5| Step: 7
Training loss: 1.2596919536590576
Validation loss: 2.0019933626215947

Epoch: 5| Step: 8
Training loss: 1.6848926544189453
Validation loss: 1.993815928377131

Epoch: 5| Step: 9
Training loss: 1.6276743412017822
Validation loss: 2.022970579003775

Epoch: 5| Step: 10
Training loss: 1.5366235971450806
Validation loss: 2.0310342504132177

Epoch: 363| Step: 0
Training loss: 1.2739200592041016
Validation loss: 2.0325987954293527

Epoch: 5| Step: 1
Training loss: 0.7111428380012512
Validation loss: 2.0339625932837047

Epoch: 5| Step: 2
Training loss: 1.2201950550079346
Validation loss: 2.027312763275639

Epoch: 5| Step: 3
Training loss: 1.4069671630859375
Validation loss: 2.0652872336808072

Epoch: 5| Step: 4
Training loss: 1.9352600574493408
Validation loss: 2.029850644450034

Epoch: 5| Step: 5
Training loss: 1.653051733970642
Validation loss: 2.041110682231124

Epoch: 5| Step: 6
Training loss: 2.291012763977051
Validation loss: 2.0207021262056086

Epoch: 5| Step: 7
Training loss: 1.3470247983932495
Validation loss: 2.0376328883632535

Epoch: 5| Step: 8
Training loss: 1.7690341472625732
Validation loss: 2.0092837964334795

Epoch: 5| Step: 9
Training loss: 1.3138500452041626
Validation loss: 1.9757194775407032

Epoch: 5| Step: 10
Training loss: 0.784908652305603
Validation loss: 1.9992746794095604

Epoch: 364| Step: 0
Training loss: 1.2537144422531128
Validation loss: 1.9925116813311012

Epoch: 5| Step: 1
Training loss: 1.6755638122558594
Validation loss: 2.0176048304445002

Epoch: 5| Step: 2
Training loss: 0.665584921836853
Validation loss: 2.0565726423776276

Epoch: 5| Step: 3
Training loss: 1.6219921112060547
Validation loss: 2.08437345873925

Epoch: 5| Step: 4
Training loss: 1.7274982929229736
Validation loss: 2.1168646786802556

Epoch: 5| Step: 5
Training loss: 1.5676469802856445
Validation loss: 2.074895667773421

Epoch: 5| Step: 6
Training loss: 1.4808995723724365
Validation loss: 2.0508058071136475

Epoch: 5| Step: 7
Training loss: 1.481597661972046
Validation loss: 2.037734116277387

Epoch: 5| Step: 8
Training loss: 1.5935838222503662
Validation loss: 2.0489530127535582

Epoch: 5| Step: 9
Training loss: 1.532566785812378
Validation loss: 2.056037420867592

Epoch: 5| Step: 10
Training loss: 1.6416516304016113
Validation loss: 2.0295414822075957

Epoch: 365| Step: 0
Training loss: 1.1759140491485596
Validation loss: 1.9905855245487665

Epoch: 5| Step: 1
Training loss: 1.6302152872085571
Validation loss: 1.9663020077572073

Epoch: 5| Step: 2
Training loss: 1.4160518646240234
Validation loss: 1.9313134660003006

Epoch: 5| Step: 3
Training loss: 1.4691143035888672
Validation loss: 1.9937929927661855

Epoch: 5| Step: 4
Training loss: 1.1672289371490479
Validation loss: 2.0456509064602595

Epoch: 5| Step: 5
Training loss: 1.6393539905548096
Validation loss: 2.0566955907370454

Epoch: 5| Step: 6
Training loss: 1.1983609199523926
Validation loss: 2.0536019558547647

Epoch: 5| Step: 7
Training loss: 1.819675087928772
Validation loss: 2.0807292948486986

Epoch: 5| Step: 8
Training loss: 1.7229923009872437
Validation loss: 2.1001310156237696

Epoch: 5| Step: 9
Training loss: 1.4291770458221436
Validation loss: 2.1252322581506546

Epoch: 5| Step: 10
Training loss: 1.6723346710205078
Validation loss: 2.0952627069206646

Epoch: 366| Step: 0
Training loss: 1.7852528095245361
Validation loss: 2.0445000894608034

Epoch: 5| Step: 1
Training loss: 1.3458195924758911
Validation loss: 2.013078894666446

Epoch: 5| Step: 2
Training loss: 1.0533970594406128
Validation loss: 1.9711765114979078

Epoch: 5| Step: 3
Training loss: 1.3413625955581665
Validation loss: 2.001198257169416

Epoch: 5| Step: 4
Training loss: 1.1034913063049316
Validation loss: 2.0213606178119616

Epoch: 5| Step: 5
Training loss: 1.5229545831680298
Validation loss: 2.028345557951158

Epoch: 5| Step: 6
Training loss: 1.4203732013702393
Validation loss: 2.005255468430058

Epoch: 5| Step: 7
Training loss: 1.412712574005127
Validation loss: 1.9866934373814573

Epoch: 5| Step: 8
Training loss: 1.896582007408142
Validation loss: 1.9835421321212605

Epoch: 5| Step: 9
Training loss: 1.7046552896499634
Validation loss: 1.982238463176194

Epoch: 5| Step: 10
Training loss: 1.1002466678619385
Validation loss: 1.9874951941992647

Epoch: 367| Step: 0
Training loss: 1.2261968851089478
Validation loss: 1.993303991133167

Epoch: 5| Step: 1
Training loss: 0.9410284757614136
Validation loss: 1.9578284294374528

Epoch: 5| Step: 2
Training loss: 1.8388597965240479
Validation loss: 1.952308856030946

Epoch: 5| Step: 3
Training loss: 0.9476426839828491
Validation loss: 1.9754904623954528

Epoch: 5| Step: 4
Training loss: 1.6806538105010986
Validation loss: 2.0043788417693107

Epoch: 5| Step: 5
Training loss: 1.3884899616241455
Validation loss: 2.004853358832739

Epoch: 5| Step: 6
Training loss: 1.7862489223480225
Validation loss: 1.9595257979567333

Epoch: 5| Step: 7
Training loss: 1.6602027416229248
Validation loss: 1.9675453901290894

Epoch: 5| Step: 8
Training loss: 2.0660552978515625
Validation loss: 1.9832427732406124

Epoch: 5| Step: 9
Training loss: 1.5742127895355225
Validation loss: 1.961633365641358

Epoch: 5| Step: 10
Training loss: 0.6613089442253113
Validation loss: 1.9816783243610012

Epoch: 368| Step: 0
Training loss: 1.6546781063079834
Validation loss: 2.0108370140034664

Epoch: 5| Step: 1
Training loss: 0.7726814150810242
Validation loss: 2.011726315303515

Epoch: 5| Step: 2
Training loss: 1.519423246383667
Validation loss: 1.9981368498135639

Epoch: 5| Step: 3
Training loss: 1.4146687984466553
Validation loss: 2.023467292067825

Epoch: 5| Step: 4
Training loss: 1.4042370319366455
Validation loss: 2.0639801615027973

Epoch: 5| Step: 5
Training loss: 1.6712367534637451
Validation loss: 2.0533097328678256

Epoch: 5| Step: 6
Training loss: 0.9363008737564087
Validation loss: 2.059612936871026

Epoch: 5| Step: 7
Training loss: 1.7435146570205688
Validation loss: 2.0466407729733374

Epoch: 5| Step: 8
Training loss: 2.126868963241577
Validation loss: 2.0699421359646704

Epoch: 5| Step: 9
Training loss: 1.1512451171875
Validation loss: 2.0481182067624983

Epoch: 5| Step: 10
Training loss: 1.6773022413253784
Validation loss: 2.035748989351334

Epoch: 369| Step: 0
Training loss: 1.6057662963867188
Validation loss: 1.9935389526428715

Epoch: 5| Step: 1
Training loss: 2.0333468914031982
Validation loss: 1.9781983283258253

Epoch: 5| Step: 2
Training loss: 1.4557583332061768
Validation loss: 1.972894113550904

Epoch: 5| Step: 3
Training loss: 1.3895251750946045
Validation loss: 1.9408418247776646

Epoch: 5| Step: 4
Training loss: 1.4389557838439941
Validation loss: 1.9416168146235968

Epoch: 5| Step: 5
Training loss: 1.6356258392333984
Validation loss: 1.9448723023937595

Epoch: 5| Step: 6
Training loss: 1.4279441833496094
Validation loss: 1.9454071855032316

Epoch: 5| Step: 7
Training loss: 0.9631329774856567
Validation loss: 1.9767249335524857

Epoch: 5| Step: 8
Training loss: 1.1387566328048706
Validation loss: 1.9772042792330506

Epoch: 5| Step: 9
Training loss: 1.306160569190979
Validation loss: 1.9997053236089728

Epoch: 5| Step: 10
Training loss: 1.1965199708938599
Validation loss: 2.0125377896011516

Epoch: 370| Step: 0
Training loss: 1.5134434700012207
Validation loss: 2.0314046439304145

Epoch: 5| Step: 1
Training loss: 1.6186363697052002
Validation loss: 2.047786863901282

Epoch: 5| Step: 2
Training loss: 1.948736548423767
Validation loss: 1.9674349343904884

Epoch: 5| Step: 3
Training loss: 1.1464335918426514
Validation loss: 1.9742231010108866

Epoch: 5| Step: 4
Training loss: 1.3129868507385254
Validation loss: 1.9767400756958993

Epoch: 5| Step: 5
Training loss: 1.134576678276062
Validation loss: 1.9691074830229565

Epoch: 5| Step: 6
Training loss: 1.2848390340805054
Validation loss: 1.971648471329802

Epoch: 5| Step: 7
Training loss: 1.371064305305481
Validation loss: 2.0239501896724907

Epoch: 5| Step: 8
Training loss: 1.4628201723098755
Validation loss: 1.980794672043093

Epoch: 5| Step: 9
Training loss: 1.2354594469070435
Validation loss: 2.0119897678334224

Epoch: 5| Step: 10
Training loss: 1.6432868242263794
Validation loss: 2.0074809469202513

Epoch: 371| Step: 0
Training loss: 0.9336467981338501
Validation loss: 2.0293138886010773

Epoch: 5| Step: 1
Training loss: 1.1996536254882812
Validation loss: 2.0372373083586335

Epoch: 5| Step: 2
Training loss: 0.8336434364318848
Validation loss: 2.0510523678154073

Epoch: 5| Step: 3
Training loss: 1.32233726978302
Validation loss: 2.0439874164519773

Epoch: 5| Step: 4
Training loss: 1.4814345836639404
Validation loss: 2.035920432818833

Epoch: 5| Step: 5
Training loss: 1.6528503894805908
Validation loss: 1.9992757125567364

Epoch: 5| Step: 6
Training loss: 1.595154047012329
Validation loss: 1.9632429525416384

Epoch: 5| Step: 7
Training loss: 1.0004371404647827
Validation loss: 1.9697572108237975

Epoch: 5| Step: 8
Training loss: 1.5394337177276611
Validation loss: 1.9977359925546954

Epoch: 5| Step: 9
Training loss: 2.0766828060150146
Validation loss: 1.9891234751670592

Epoch: 5| Step: 10
Training loss: 1.7149604558944702
Validation loss: 1.982189437394501

Epoch: 372| Step: 0
Training loss: 1.4327582120895386
Validation loss: 1.9776484838096045

Epoch: 5| Step: 1
Training loss: 1.1964393854141235
Validation loss: 1.989742843053674

Epoch: 5| Step: 2
Training loss: 1.9235899448394775
Validation loss: 1.9925040404001872

Epoch: 5| Step: 3
Training loss: 1.465748906135559
Validation loss: 1.9939626634761851

Epoch: 5| Step: 4
Training loss: 1.1018435955047607
Validation loss: 1.9999220653246808

Epoch: 5| Step: 5
Training loss: 1.4070433378219604
Validation loss: 2.009942057312176

Epoch: 5| Step: 6
Training loss: 1.4521143436431885
Validation loss: 2.0391946890020884

Epoch: 5| Step: 7
Training loss: 1.3263752460479736
Validation loss: 1.9929225073065808

Epoch: 5| Step: 8
Training loss: 1.4479150772094727
Validation loss: 2.0189306902629074

Epoch: 5| Step: 9
Training loss: 0.964154064655304
Validation loss: 1.9599332527447773

Epoch: 5| Step: 10
Training loss: 1.6021490097045898
Validation loss: 2.003905434762278

Epoch: 373| Step: 0
Training loss: 1.808890700340271
Validation loss: 1.9891238853495607

Epoch: 5| Step: 1
Training loss: 0.9675916433334351
Validation loss: 1.990493715450328

Epoch: 5| Step: 2
Training loss: 1.4722546339035034
Validation loss: 1.9698930914684007

Epoch: 5| Step: 3
Training loss: 1.1867021322250366
Validation loss: 1.9428896698900449

Epoch: 5| Step: 4
Training loss: 1.5669896602630615
Validation loss: 1.9672576176222933

Epoch: 5| Step: 5
Training loss: 1.4174070358276367
Validation loss: 1.9707575895453011

Epoch: 5| Step: 6
Training loss: 1.8443644046783447
Validation loss: 1.96119551761176

Epoch: 5| Step: 7
Training loss: 1.5393553972244263
Validation loss: 1.9513475100199382

Epoch: 5| Step: 8
Training loss: 1.2476643323898315
Validation loss: 1.9618237864586614

Epoch: 5| Step: 9
Training loss: 0.9194409251213074
Validation loss: 1.9662912173937726

Epoch: 5| Step: 10
Training loss: 1.1683143377304077
Validation loss: 2.0098565573333413

Epoch: 374| Step: 0
Training loss: 0.9957890510559082
Validation loss: 2.006424291159517

Epoch: 5| Step: 1
Training loss: 0.7487017512321472
Validation loss: 2.0608335489867837

Epoch: 5| Step: 2
Training loss: 1.4107872247695923
Validation loss: 2.060786275453465

Epoch: 5| Step: 3
Training loss: 1.4892877340316772
Validation loss: 2.0972581807003228

Epoch: 5| Step: 4
Training loss: 1.4597899913787842
Validation loss: 2.0655135211124214

Epoch: 5| Step: 5
Training loss: 2.226287841796875
Validation loss: 2.038792512750113

Epoch: 5| Step: 6
Training loss: 1.6322101354599
Validation loss: 1.9965949955806936

Epoch: 5| Step: 7
Training loss: 1.1183987855911255
Validation loss: 1.982199791939028

Epoch: 5| Step: 8
Training loss: 0.8381497263908386
Validation loss: 1.9356602340616205

Epoch: 5| Step: 9
Training loss: 1.4412128925323486
Validation loss: 1.969238063340546

Epoch: 5| Step: 10
Training loss: 1.9268702268600464
Validation loss: 1.934488296508789

Epoch: 375| Step: 0
Training loss: 1.239098310470581
Validation loss: 1.9080355808299074

Epoch: 5| Step: 1
Training loss: 1.8209145069122314
Validation loss: 1.9151187481418732

Epoch: 5| Step: 2
Training loss: 1.1977087259292603
Validation loss: 1.9341704101972683

Epoch: 5| Step: 3
Training loss: 0.9001007080078125
Validation loss: 1.9484777809471212

Epoch: 5| Step: 4
Training loss: 0.8256523013114929
Validation loss: 2.0068423081469793

Epoch: 5| Step: 5
Training loss: 2.0808680057525635
Validation loss: 2.0002704358869985

Epoch: 5| Step: 6
Training loss: 1.1959002017974854
Validation loss: 2.0099660350430395

Epoch: 5| Step: 7
Training loss: 1.6247880458831787
Validation loss: 1.9912916601345103

Epoch: 5| Step: 8
Training loss: 1.6145000457763672
Validation loss: 1.9543604722587011

Epoch: 5| Step: 9
Training loss: 1.3042991161346436
Validation loss: 2.0106798756507134

Epoch: 5| Step: 10
Training loss: 1.594015121459961
Validation loss: 2.014517799500496

Epoch: 376| Step: 0
Training loss: 1.2267239093780518
Validation loss: 2.0337026067959365

Epoch: 5| Step: 1
Training loss: 1.6602871417999268
Validation loss: 2.0012472021964287

Epoch: 5| Step: 2
Training loss: 1.51822829246521
Validation loss: 1.9762044709215882

Epoch: 5| Step: 3
Training loss: 1.2946245670318604
Validation loss: 1.953405959631807

Epoch: 5| Step: 4
Training loss: 1.4764587879180908
Validation loss: 1.974183141544301

Epoch: 5| Step: 5
Training loss: 0.8278824090957642
Validation loss: 1.9894305608605827

Epoch: 5| Step: 6
Training loss: 1.4198700189590454
Validation loss: 2.012139078109495

Epoch: 5| Step: 7
Training loss: 1.2573630809783936
Validation loss: 2.0053323968764274

Epoch: 5| Step: 8
Training loss: 1.7822437286376953
Validation loss: 2.017762840435069

Epoch: 5| Step: 9
Training loss: 1.549365758895874
Validation loss: 2.0174379964028635

Epoch: 5| Step: 10
Training loss: 1.1719434261322021
Validation loss: 2.003182444521176

Epoch: 377| Step: 0
Training loss: 1.280671238899231
Validation loss: 2.0270410737683697

Epoch: 5| Step: 1
Training loss: 1.0557665824890137
Validation loss: 2.018931117109073

Epoch: 5| Step: 2
Training loss: 1.2327486276626587
Validation loss: 2.0112589392610776

Epoch: 5| Step: 3
Training loss: 1.5591760873794556
Validation loss: 1.9982663662202897

Epoch: 5| Step: 4
Training loss: 1.1822035312652588
Validation loss: 1.976360256953906

Epoch: 5| Step: 5
Training loss: 1.6261346340179443
Validation loss: 1.9549155722382248

Epoch: 5| Step: 6
Training loss: 1.3369183540344238
Validation loss: 1.9469467286140687

Epoch: 5| Step: 7
Training loss: 1.0209393501281738
Validation loss: 1.9413467709736159

Epoch: 5| Step: 8
Training loss: 1.5929689407348633
Validation loss: 1.9562250106565413

Epoch: 5| Step: 9
Training loss: 1.6743981838226318
Validation loss: 1.92801224031756

Epoch: 5| Step: 10
Training loss: 1.4011844396591187
Validation loss: 1.9450418167216803

Epoch: 378| Step: 0
Training loss: 0.9248561859130859
Validation loss: 1.9395916154307704

Epoch: 5| Step: 1
Training loss: 1.645700216293335
Validation loss: 1.9886672983887375

Epoch: 5| Step: 2
Training loss: 1.3538752794265747
Validation loss: 2.010574456184141

Epoch: 5| Step: 3
Training loss: 1.5556628704071045
Validation loss: 1.9951828577185189

Epoch: 5| Step: 4
Training loss: 1.1651198863983154
Validation loss: 1.972530944373018

Epoch: 5| Step: 5
Training loss: 1.7809356451034546
Validation loss: 1.9657105348443473

Epoch: 5| Step: 6
Training loss: 1.047499179840088
Validation loss: 1.9453029094203826

Epoch: 5| Step: 7
Training loss: 1.511400818824768
Validation loss: 1.9750877477789437

Epoch: 5| Step: 8
Training loss: 1.4924702644348145
Validation loss: 1.968759416252054

Epoch: 5| Step: 9
Training loss: 1.4621086120605469
Validation loss: 1.97883056312479

Epoch: 5| Step: 10
Training loss: 0.8460729122161865
Validation loss: 1.9779424154630272

Epoch: 379| Step: 0
Training loss: 1.7357984781265259
Validation loss: 1.9723810406141384

Epoch: 5| Step: 1
Training loss: 0.8204805254936218
Validation loss: 1.9944940100434005

Epoch: 5| Step: 2
Training loss: 1.2032238245010376
Validation loss: 2.0051348491381575

Epoch: 5| Step: 3
Training loss: 1.3440757989883423
Validation loss: 2.0252571772503596

Epoch: 5| Step: 4
Training loss: 1.554518461227417
Validation loss: 2.000100008903011

Epoch: 5| Step: 5
Training loss: 1.5112775564193726
Validation loss: 1.997910596991098

Epoch: 5| Step: 6
Training loss: 0.9621750116348267
Validation loss: 1.980505899716449

Epoch: 5| Step: 7
Training loss: 1.2158803939819336
Validation loss: 1.9397355984616023

Epoch: 5| Step: 8
Training loss: 1.6619793176651
Validation loss: 1.932697529433876

Epoch: 5| Step: 9
Training loss: 1.6077324151992798
Validation loss: 1.9209835631873018

Epoch: 5| Step: 10
Training loss: 1.0628572702407837
Validation loss: 1.9224619314234743

Epoch: 380| Step: 0
Training loss: 1.3290356397628784
Validation loss: 1.9554815241085586

Epoch: 5| Step: 1
Training loss: 1.6807159185409546
Validation loss: 1.9646992452682988

Epoch: 5| Step: 2
Training loss: 1.243957757949829
Validation loss: 2.011605449902114

Epoch: 5| Step: 3
Training loss: 1.3399770259857178
Validation loss: 2.0092162137390464

Epoch: 5| Step: 4
Training loss: 1.2881786823272705
Validation loss: 2.0520769857591197

Epoch: 5| Step: 5
Training loss: 1.181096076965332
Validation loss: 2.0849187707388275

Epoch: 5| Step: 6
Training loss: 1.711825966835022
Validation loss: 2.0891327947698612

Epoch: 5| Step: 7
Training loss: 0.8715304136276245
Validation loss: 2.0629815952752226

Epoch: 5| Step: 8
Training loss: 1.1547877788543701
Validation loss: 2.0508731347258373

Epoch: 5| Step: 9
Training loss: 1.3111785650253296
Validation loss: 2.0033656435628093

Epoch: 5| Step: 10
Training loss: 1.791321873664856
Validation loss: 1.9846857350359681

Epoch: 381| Step: 0
Training loss: 1.1352312564849854
Validation loss: 1.9534663436233357

Epoch: 5| Step: 1
Training loss: 1.6306499242782593
Validation loss: 1.9336500706211213

Epoch: 5| Step: 2
Training loss: 0.8893114924430847
Validation loss: 1.8944810000799035

Epoch: 5| Step: 3
Training loss: 1.529710054397583
Validation loss: 1.893948954920615

Epoch: 5| Step: 4
Training loss: 1.6734635829925537
Validation loss: 1.8991669506155036

Epoch: 5| Step: 5
Training loss: 1.4240174293518066
Validation loss: 1.948745858284735

Epoch: 5| Step: 6
Training loss: 1.1375830173492432
Validation loss: 1.9672658366541709

Epoch: 5| Step: 7
Training loss: 1.357808232307434
Validation loss: 2.0342037805946926

Epoch: 5| Step: 8
Training loss: 1.3331313133239746
Validation loss: 2.056321679904897

Epoch: 5| Step: 9
Training loss: 1.6004199981689453
Validation loss: 2.07519095687456

Epoch: 5| Step: 10
Training loss: 1.3061940670013428
Validation loss: 2.03087140411459

Epoch: 382| Step: 0
Training loss: 1.6693594455718994
Validation loss: 2.025164024804228

Epoch: 5| Step: 1
Training loss: 1.5428167581558228
Validation loss: 2.0152960156881683

Epoch: 5| Step: 2
Training loss: 1.2819616794586182
Validation loss: 2.0239947278012513

Epoch: 5| Step: 3
Training loss: 1.6329841613769531
Validation loss: 1.9889292960525842

Epoch: 5| Step: 4
Training loss: 1.0910581350326538
Validation loss: 1.956692135462197

Epoch: 5| Step: 5
Training loss: 1.6503738164901733
Validation loss: 1.9486928921873852

Epoch: 5| Step: 6
Training loss: 0.7591560482978821
Validation loss: 1.9354557080935406

Epoch: 5| Step: 7
Training loss: 1.5940401554107666
Validation loss: 1.961411891445037

Epoch: 5| Step: 8
Training loss: 1.2883087396621704
Validation loss: 1.961511258156069

Epoch: 5| Step: 9
Training loss: 1.6172962188720703
Validation loss: 1.9596334888089089

Epoch: 5| Step: 10
Training loss: 0.6025848388671875
Validation loss: 1.9720536073048909

Epoch: 383| Step: 0
Training loss: 1.314165472984314
Validation loss: 1.9637365059186054

Epoch: 5| Step: 1
Training loss: 1.1798558235168457
Validation loss: 2.006564473593107

Epoch: 5| Step: 2
Training loss: 2.1114745140075684
Validation loss: 2.019932593068769

Epoch: 5| Step: 3
Training loss: 0.9333721399307251
Validation loss: 2.0358029539867113

Epoch: 5| Step: 4
Training loss: 0.8941032290458679
Validation loss: 2.0063532244774605

Epoch: 5| Step: 5
Training loss: 1.5741900205612183
Validation loss: 2.013760227029042

Epoch: 5| Step: 6
Training loss: 1.641754388809204
Validation loss: 2.0200667048013337

Epoch: 5| Step: 7
Training loss: 1.5677578449249268
Validation loss: 2.0014998400083153

Epoch: 5| Step: 8
Training loss: 1.5438671112060547
Validation loss: 1.988885236042802

Epoch: 5| Step: 9
Training loss: 0.9523593783378601
Validation loss: 1.943324004450152

Epoch: 5| Step: 10
Training loss: 0.8453989624977112
Validation loss: 1.98256121143218

Epoch: 384| Step: 0
Training loss: 1.0167701244354248
Validation loss: 1.9803606387107604

Epoch: 5| Step: 1
Training loss: 1.9158130884170532
Validation loss: 1.9681495607540171

Epoch: 5| Step: 2
Training loss: 1.3032152652740479
Validation loss: 1.9628753610836562

Epoch: 5| Step: 3
Training loss: 1.424748420715332
Validation loss: 1.9282249686538533

Epoch: 5| Step: 4
Training loss: 0.8433300852775574
Validation loss: 1.9771809052395564

Epoch: 5| Step: 5
Training loss: 0.9254761934280396
Validation loss: 1.9958372192998086

Epoch: 5| Step: 6
Training loss: 1.5905988216400146
Validation loss: 1.9897780700396466

Epoch: 5| Step: 7
Training loss: 1.1467950344085693
Validation loss: 1.9919932055216965

Epoch: 5| Step: 8
Training loss: 1.4010173082351685
Validation loss: 2.0176254856971

Epoch: 5| Step: 9
Training loss: 1.4154049158096313
Validation loss: 2.0229585029745616

Epoch: 5| Step: 10
Training loss: 1.4242217540740967
Validation loss: 2.0309037995594803

Epoch: 385| Step: 0
Training loss: 1.6674600839614868
Validation loss: 1.9999809700955626

Epoch: 5| Step: 1
Training loss: 1.175959825515747
Validation loss: 1.9811513372646865

Epoch: 5| Step: 2
Training loss: 1.341514229774475
Validation loss: 1.9673755656006515

Epoch: 5| Step: 3
Training loss: 1.0449036359786987
Validation loss: 1.9573626966886624

Epoch: 5| Step: 4
Training loss: 1.1785304546356201
Validation loss: 1.9710891644159954

Epoch: 5| Step: 5
Training loss: 1.4297765493392944
Validation loss: 2.005118857147873

Epoch: 5| Step: 6
Training loss: 1.3740692138671875
Validation loss: 2.037014889460738

Epoch: 5| Step: 7
Training loss: 0.9931676983833313
Validation loss: 2.056225779236004

Epoch: 5| Step: 8
Training loss: 1.2121093273162842
Validation loss: 2.0600085976303264

Epoch: 5| Step: 9
Training loss: 1.6184453964233398
Validation loss: 2.039141224276635

Epoch: 5| Step: 10
Training loss: 1.5097557306289673
Validation loss: 1.9944086818284885

Epoch: 386| Step: 0
Training loss: 1.3061765432357788
Validation loss: 1.9556621684822986

Epoch: 5| Step: 1
Training loss: 1.5963881015777588
Validation loss: 1.9334980569859987

Epoch: 5| Step: 2
Training loss: 1.3453649282455444
Validation loss: 1.9454034669424898

Epoch: 5| Step: 3
Training loss: 0.43863654136657715
Validation loss: 1.9402345867567166

Epoch: 5| Step: 4
Training loss: 1.3261598348617554
Validation loss: 1.9199310746244205

Epoch: 5| Step: 5
Training loss: 1.3938305377960205
Validation loss: 1.9330042395540463

Epoch: 5| Step: 6
Training loss: 1.6848621368408203
Validation loss: 1.9620871543884277

Epoch: 5| Step: 7
Training loss: 0.676582396030426
Validation loss: 1.9850192813463108

Epoch: 5| Step: 8
Training loss: 1.5388002395629883
Validation loss: 1.9863168116538756

Epoch: 5| Step: 9
Training loss: 1.5485079288482666
Validation loss: 2.0420018883161646

Epoch: 5| Step: 10
Training loss: 1.7223200798034668
Validation loss: 2.0741789161518054

Epoch: 387| Step: 0
Training loss: 1.1991031169891357
Validation loss: 2.080312216153709

Epoch: 5| Step: 1
Training loss: 1.658241629600525
Validation loss: 2.041992800210112

Epoch: 5| Step: 2
Training loss: 0.8098871111869812
Validation loss: 2.003939818310481

Epoch: 5| Step: 3
Training loss: 1.1567546129226685
Validation loss: 1.9680575786098358

Epoch: 5| Step: 4
Training loss: 0.9418386220932007
Validation loss: 1.9464289078148462

Epoch: 5| Step: 5
Training loss: 1.4191786050796509
Validation loss: 1.9396158546529791

Epoch: 5| Step: 6
Training loss: 1.420525312423706
Validation loss: 1.9165462306750718

Epoch: 5| Step: 7
Training loss: 1.3679592609405518
Validation loss: 1.9577759568409254

Epoch: 5| Step: 8
Training loss: 1.3429609537124634
Validation loss: 1.9262009448902582

Epoch: 5| Step: 9
Training loss: 1.6285617351531982
Validation loss: 1.9379597287024222

Epoch: 5| Step: 10
Training loss: 1.3720495700836182
Validation loss: 1.9576272477385819

Epoch: 388| Step: 0
Training loss: 1.1232670545578003
Validation loss: 1.948821726665702

Epoch: 5| Step: 1
Training loss: 1.3575547933578491
Validation loss: 1.94135872907536

Epoch: 5| Step: 2
Training loss: 1.3640902042388916
Validation loss: 1.9251442609294769

Epoch: 5| Step: 3
Training loss: 1.2757606506347656
Validation loss: 1.9191247135080316

Epoch: 5| Step: 4
Training loss: 1.6071964502334595
Validation loss: 1.9157529210531583

Epoch: 5| Step: 5
Training loss: 1.5466772317886353
Validation loss: 1.91687939500296

Epoch: 5| Step: 6
Training loss: 1.2461880445480347
Validation loss: 1.9447867306329871

Epoch: 5| Step: 7
Training loss: 0.8318516612052917
Validation loss: 1.9566090722237863

Epoch: 5| Step: 8
Training loss: 1.5108976364135742
Validation loss: 1.9557500103468537

Epoch: 5| Step: 9
Training loss: 1.048841953277588
Validation loss: 1.9483488375140774

Epoch: 5| Step: 10
Training loss: 1.383362889289856
Validation loss: 1.9822216841482347

Epoch: 389| Step: 0
Training loss: 1.1800312995910645
Validation loss: 1.972387731716197

Epoch: 5| Step: 1
Training loss: 1.2993055582046509
Validation loss: 1.9632789665652859

Epoch: 5| Step: 2
Training loss: 1.1141963005065918
Validation loss: 1.94916194997808

Epoch: 5| Step: 3
Training loss: 1.5311123132705688
Validation loss: 2.0022983128024685

Epoch: 5| Step: 4
Training loss: 1.1350058317184448
Validation loss: 2.032747359686

Epoch: 5| Step: 5
Training loss: 0.9772695302963257
Validation loss: 2.0229127765983663

Epoch: 5| Step: 6
Training loss: 1.4157822132110596
Validation loss: 2.002027180887038

Epoch: 5| Step: 7
Training loss: 1.3053598403930664
Validation loss: 1.9977583244282713

Epoch: 5| Step: 8
Training loss: 1.2951819896697998
Validation loss: 1.9843857365269815

Epoch: 5| Step: 9
Training loss: 1.5953197479248047
Validation loss: 2.011367331268967

Epoch: 5| Step: 10
Training loss: 1.473990559577942
Validation loss: 1.968292046618718

Epoch: 390| Step: 0
Training loss: 0.9910731315612793
Validation loss: 1.9710267615574661

Epoch: 5| Step: 1
Training loss: 1.7797149419784546
Validation loss: 1.926581157151089

Epoch: 5| Step: 2
Training loss: 1.6127405166625977
Validation loss: 1.904449632090907

Epoch: 5| Step: 3
Training loss: 1.061274766921997
Validation loss: 1.973212198544574

Epoch: 5| Step: 4
Training loss: 1.2709087133407593
Validation loss: 1.9711324220062585

Epoch: 5| Step: 5
Training loss: 1.303269624710083
Validation loss: 1.9998910016911005

Epoch: 5| Step: 6
Training loss: 1.4964429140090942
Validation loss: 2.0265098823014127

Epoch: 5| Step: 7
Training loss: 1.3045629262924194
Validation loss: 2.015311280886332

Epoch: 5| Step: 8
Training loss: 1.2033840417861938
Validation loss: 2.0305835047075824

Epoch: 5| Step: 9
Training loss: 1.5022281408309937
Validation loss: 2.021913764297321

Epoch: 5| Step: 10
Training loss: 0.8211026191711426
Validation loss: 2.017713487789195

Epoch: 391| Step: 0
Training loss: 1.8686821460723877
Validation loss: 2.033763962407266

Epoch: 5| Step: 1
Training loss: 1.307836890220642
Validation loss: 1.9708261438595351

Epoch: 5| Step: 2
Training loss: 1.1785001754760742
Validation loss: 1.9488313941545383

Epoch: 5| Step: 3
Training loss: 0.9108282327651978
Validation loss: 1.919932734581732

Epoch: 5| Step: 4
Training loss: 1.0843812227249146
Validation loss: 1.918194942576911

Epoch: 5| Step: 5
Training loss: 1.4660255908966064
Validation loss: 1.9098870472241474

Epoch: 5| Step: 6
Training loss: 1.2430654764175415
Validation loss: 1.9089458116921045

Epoch: 5| Step: 7
Training loss: 1.1707817316055298
Validation loss: 1.9056753471333494

Epoch: 5| Step: 8
Training loss: 1.0779495239257812
Validation loss: 1.9523627578571279

Epoch: 5| Step: 9
Training loss: 1.5283255577087402
Validation loss: 1.9911273653789232

Epoch: 5| Step: 10
Training loss: 1.5349558591842651
Validation loss: 2.0535207627921976

Epoch: 392| Step: 0
Training loss: 1.1704511642456055
Validation loss: 2.074866120533277

Epoch: 5| Step: 1
Training loss: 1.5861961841583252
Validation loss: 2.0664867560068765

Epoch: 5| Step: 2
Training loss: 1.0820746421813965
Validation loss: 2.0830165493872856

Epoch: 5| Step: 3
Training loss: 1.7524502277374268
Validation loss: 2.015909746129026

Epoch: 5| Step: 4
Training loss: 1.3110026121139526
Validation loss: 1.9891700847174532

Epoch: 5| Step: 5
Training loss: 1.3523147106170654
Validation loss: 1.9669534852427821

Epoch: 5| Step: 6
Training loss: 1.5671472549438477
Validation loss: 1.9240387165418236

Epoch: 5| Step: 7
Training loss: 1.344581961631775
Validation loss: 1.9050793622129707

Epoch: 5| Step: 8
Training loss: 1.364707112312317
Validation loss: 1.9098692376126525

Epoch: 5| Step: 9
Training loss: 0.9436835050582886
Validation loss: 1.9363459951134139

Epoch: 5| Step: 10
Training loss: 1.1056259870529175
Validation loss: 1.9531899857264694

Epoch: 393| Step: 0
Training loss: 1.6146970987319946
Validation loss: 1.9388028793437506

Epoch: 5| Step: 1
Training loss: 0.7387661933898926
Validation loss: 1.9307296045364872

Epoch: 5| Step: 2
Training loss: 1.266841173171997
Validation loss: 1.940015403173303

Epoch: 5| Step: 3
Training loss: 1.1795941591262817
Validation loss: 1.9664800807993899

Epoch: 5| Step: 4
Training loss: 1.6315791606903076
Validation loss: 2.015811993229774

Epoch: 5| Step: 5
Training loss: 1.0152127742767334
Validation loss: 2.053825259208679

Epoch: 5| Step: 6
Training loss: 1.2346975803375244
Validation loss: 1.9824856942699802

Epoch: 5| Step: 7
Training loss: 0.9026943445205688
Validation loss: 1.9901299450987129

Epoch: 5| Step: 8
Training loss: 1.4196211099624634
Validation loss: 1.9960569745750838

Epoch: 5| Step: 9
Training loss: 1.432808518409729
Validation loss: 1.9879407780144804

Epoch: 5| Step: 10
Training loss: 2.0890865325927734
Validation loss: 2.000378695867395

Epoch: 394| Step: 0
Training loss: 1.652956247329712
Validation loss: 1.9743257709728774

Epoch: 5| Step: 1
Training loss: 1.528188705444336
Validation loss: 1.9889435857854865

Epoch: 5| Step: 2
Training loss: 1.2575318813323975
Validation loss: 1.9470950249702699

Epoch: 5| Step: 3
Training loss: 1.135947585105896
Validation loss: 1.9316514358725598

Epoch: 5| Step: 4
Training loss: 1.251695156097412
Validation loss: 1.979131631953742

Epoch: 5| Step: 5
Training loss: 0.9824067950248718
Validation loss: 1.9339993910122943

Epoch: 5| Step: 6
Training loss: 0.746855616569519
Validation loss: 1.9291866146108156

Epoch: 5| Step: 7
Training loss: 1.3383338451385498
Validation loss: 1.8804371869692238

Epoch: 5| Step: 8
Training loss: 1.4044616222381592
Validation loss: 1.9326485305704095

Epoch: 5| Step: 9
Training loss: 1.3859373331069946
Validation loss: 1.9778048428156043

Epoch: 5| Step: 10
Training loss: 1.5843147039413452
Validation loss: 2.0425728623585035

Epoch: 395| Step: 0
Training loss: 1.0558207035064697
Validation loss: 2.038107651536183

Epoch: 5| Step: 1
Training loss: 1.1709192991256714
Validation loss: 2.0497632077945176

Epoch: 5| Step: 2
Training loss: 1.5283534526824951
Validation loss: 2.0419472827706286

Epoch: 5| Step: 3
Training loss: 1.6494907140731812
Validation loss: 2.0247650761758127

Epoch: 5| Step: 4
Training loss: 0.997409462928772
Validation loss: 2.053145985449514

Epoch: 5| Step: 5
Training loss: 1.4868857860565186
Validation loss: 2.053001801172892

Epoch: 5| Step: 6
Training loss: 1.5860788822174072
Validation loss: 2.0427782125370477

Epoch: 5| Step: 7
Training loss: 1.2197761535644531
Validation loss: 2.0131871700286865

Epoch: 5| Step: 8
Training loss: 1.2663414478302002
Validation loss: 1.9486645267855736

Epoch: 5| Step: 9
Training loss: 1.2833075523376465
Validation loss: 1.9207645141950218

Epoch: 5| Step: 10
Training loss: 0.7177098393440247
Validation loss: 1.9183449360632128

Epoch: 396| Step: 0
Training loss: 1.1502281427383423
Validation loss: 1.946658674106803

Epoch: 5| Step: 1
Training loss: 0.8657664060592651
Validation loss: 1.945744849020435

Epoch: 5| Step: 2
Training loss: 0.8778862953186035
Validation loss: 1.9458362787000594

Epoch: 5| Step: 3
Training loss: 1.281122088432312
Validation loss: 1.9403250255892355

Epoch: 5| Step: 4
Training loss: 1.0506818294525146
Validation loss: 1.9697662271479124

Epoch: 5| Step: 5
Training loss: 1.4889671802520752
Validation loss: 1.9565358341381114

Epoch: 5| Step: 6
Training loss: 0.9274173974990845
Validation loss: 1.9241402226109658

Epoch: 5| Step: 7
Training loss: 1.6144250631332397
Validation loss: 1.9126182012660529

Epoch: 5| Step: 8
Training loss: 1.1110005378723145
Validation loss: 1.901906818471929

Epoch: 5| Step: 9
Training loss: 1.917703628540039
Validation loss: 1.930864426397508

Epoch: 5| Step: 10
Training loss: 1.864628553390503
Validation loss: 1.9849976647284724

Epoch: 397| Step: 0
Training loss: 2.109785318374634
Validation loss: 2.001102112954663

Epoch: 5| Step: 1
Training loss: 0.9622685313224792
Validation loss: 2.0214823484420776

Epoch: 5| Step: 2
Training loss: 1.7398658990859985
Validation loss: 1.9982478849349483

Epoch: 5| Step: 3
Training loss: 0.9451961517333984
Validation loss: 1.9573923003289007

Epoch: 5| Step: 4
Training loss: 1.0371263027191162
Validation loss: 1.9869016639647945

Epoch: 5| Step: 5
Training loss: 1.3465467691421509
Validation loss: 1.9487091469508346

Epoch: 5| Step: 6
Training loss: 1.1464380025863647
Validation loss: 1.9912874262820008

Epoch: 5| Step: 7
Training loss: 1.218129277229309
Validation loss: 1.9539338863024147

Epoch: 5| Step: 8
Training loss: 1.0475409030914307
Validation loss: 1.9265255094856344

Epoch: 5| Step: 9
Training loss: 1.2198128700256348
Validation loss: 1.9570185471606512

Epoch: 5| Step: 10
Training loss: 1.1156811714172363
Validation loss: 1.917874546461208

Epoch: 398| Step: 0
Training loss: 1.3826507329940796
Validation loss: 1.9591444077030304

Epoch: 5| Step: 1
Training loss: 1.7504876852035522
Validation loss: 1.9269293700495074

Epoch: 5| Step: 2
Training loss: 1.31119704246521
Validation loss: 1.9623053945520872

Epoch: 5| Step: 3
Training loss: 1.1747639179229736
Validation loss: 1.9347955437116726

Epoch: 5| Step: 4
Training loss: 1.1317368745803833
Validation loss: 1.9292715159795617

Epoch: 5| Step: 5
Training loss: 1.2499078512191772
Validation loss: 1.9407049199586273

Epoch: 5| Step: 6
Training loss: 1.3641481399536133
Validation loss: 1.9432230047000352

Epoch: 5| Step: 7
Training loss: 1.320217490196228
Validation loss: 1.95361053815452

Epoch: 5| Step: 8
Training loss: 0.821174144744873
Validation loss: 1.9287815824631722

Epoch: 5| Step: 9
Training loss: 1.5793848037719727
Validation loss: 1.9344496457807479

Epoch: 5| Step: 10
Training loss: 0.5443564057350159
Validation loss: 1.948485153977589

Epoch: 399| Step: 0
Training loss: 1.339835286140442
Validation loss: 1.9577099456582019

Epoch: 5| Step: 1
Training loss: 1.1683440208435059
Validation loss: 1.9930710997632755

Epoch: 5| Step: 2
Training loss: 1.4963022470474243
Validation loss: 2.004749762114658

Epoch: 5| Step: 3
Training loss: 1.148991584777832
Validation loss: 1.989980569449804

Epoch: 5| Step: 4
Training loss: 0.9747562408447266
Validation loss: 1.9902316344681608

Epoch: 5| Step: 5
Training loss: 1.3607561588287354
Validation loss: 2.0007791544801448

Epoch: 5| Step: 6
Training loss: 1.11112642288208
Validation loss: 1.9730462476771364

Epoch: 5| Step: 7
Training loss: 0.5950631499290466
Validation loss: 1.9726547553975096

Epoch: 5| Step: 8
Training loss: 1.5227453708648682
Validation loss: 1.9630369806802401

Epoch: 5| Step: 9
Training loss: 1.4158968925476074
Validation loss: 1.9480790733009257

Epoch: 5| Step: 10
Training loss: 1.56167733669281
Validation loss: 1.939114527035785

Epoch: 400| Step: 0
Training loss: 1.1827863454818726
Validation loss: 1.9298587678581156

Epoch: 5| Step: 1
Training loss: 1.2753491401672363
Validation loss: 1.930281973654224

Epoch: 5| Step: 2
Training loss: 1.5368584394454956
Validation loss: 1.907320733993284

Epoch: 5| Step: 3
Training loss: 1.150895118713379
Validation loss: 1.9429412439305296

Epoch: 5| Step: 4
Training loss: 0.9475172758102417
Validation loss: 1.934609963047889

Epoch: 5| Step: 5
Training loss: 1.4423246383666992
Validation loss: 1.910730573438829

Epoch: 5| Step: 6
Training loss: 1.0806716680526733
Validation loss: 1.9172717755840671

Epoch: 5| Step: 7
Training loss: 1.263358235359192
Validation loss: 1.9321533505634596

Epoch: 5| Step: 8
Training loss: 1.3228973150253296
Validation loss: 1.9709854049067344

Epoch: 5| Step: 9
Training loss: 0.9064170718193054
Validation loss: 1.9702411236301545

Epoch: 5| Step: 10
Training loss: 1.5846389532089233
Validation loss: 1.958034215434905

Epoch: 401| Step: 0
Training loss: 1.6190532445907593
Validation loss: 1.9383962718389367

Epoch: 5| Step: 1
Training loss: 1.0935401916503906
Validation loss: 1.9164775545879076

Epoch: 5| Step: 2
Training loss: 1.3367923498153687
Validation loss: 1.9063817711286648

Epoch: 5| Step: 3
Training loss: 1.3306362628936768
Validation loss: 1.9297162435388053

Epoch: 5| Step: 4
Training loss: 1.1268430948257446
Validation loss: 1.9760276194541686

Epoch: 5| Step: 5
Training loss: 1.5559378862380981
Validation loss: 1.9944481260033065

Epoch: 5| Step: 6
Training loss: 0.841961681842804
Validation loss: 1.9862498621786795

Epoch: 5| Step: 7
Training loss: 1.212173342704773
Validation loss: 1.978761153836404

Epoch: 5| Step: 8
Training loss: 1.2596490383148193
Validation loss: 2.003458046144055

Epoch: 5| Step: 9
Training loss: 1.0088717937469482
Validation loss: 1.9956295387719267

Epoch: 5| Step: 10
Training loss: 1.3497319221496582
Validation loss: 2.0017529738846647

Epoch: 402| Step: 0
Training loss: 1.1963361501693726
Validation loss: 1.974838000471874

Epoch: 5| Step: 1
Training loss: 1.0910329818725586
Validation loss: 1.9633480887259207

Epoch: 5| Step: 2
Training loss: 1.2920106649398804
Validation loss: 1.9486117901340607

Epoch: 5| Step: 3
Training loss: 0.8549002408981323
Validation loss: 1.952414802325669

Epoch: 5| Step: 4
Training loss: 1.7000160217285156
Validation loss: 1.9408686955769856

Epoch: 5| Step: 5
Training loss: 1.4252512454986572
Validation loss: 1.9319531686844365

Epoch: 5| Step: 6
Training loss: 1.9155585765838623
Validation loss: 1.9395328670419671

Epoch: 5| Step: 7
Training loss: 0.9668792486190796
Validation loss: 1.9242447460851362

Epoch: 5| Step: 8
Training loss: 1.3715366125106812
Validation loss: 1.930480928831203

Epoch: 5| Step: 9
Training loss: 0.8522555232048035
Validation loss: 1.9095264891142487

Epoch: 5| Step: 10
Training loss: 1.1171005964279175
Validation loss: 1.9475716224280737

Epoch: 403| Step: 0
Training loss: 0.9574226140975952
Validation loss: 1.9848568644574893

Epoch: 5| Step: 1
Training loss: 1.3086631298065186
Validation loss: 1.990954593945575

Epoch: 5| Step: 2
Training loss: 1.3243904113769531
Validation loss: 1.9798562295975224

Epoch: 5| Step: 3
Training loss: 1.1735531091690063
Validation loss: 1.9681956870581514

Epoch: 5| Step: 4
Training loss: 1.1664384603500366
Validation loss: 1.9856169890331965

Epoch: 5| Step: 5
Training loss: 1.0105247497558594
Validation loss: 2.0255314816710768

Epoch: 5| Step: 6
Training loss: 1.4436054229736328
Validation loss: 2.021809544614566

Epoch: 5| Step: 7
Training loss: 1.2818355560302734
Validation loss: 2.0006478550613567

Epoch: 5| Step: 8
Training loss: 1.1789424419403076
Validation loss: 1.987685081779316

Epoch: 5| Step: 9
Training loss: 1.7887481451034546
Validation loss: 1.9974233565791961

Epoch: 5| Step: 10
Training loss: 1.0584142208099365
Validation loss: 1.9476189972251974

Epoch: 404| Step: 0
Training loss: 1.2496142387390137
Validation loss: 1.937707858700906

Epoch: 5| Step: 1
Training loss: 0.8592996597290039
Validation loss: 1.9177323438787972

Epoch: 5| Step: 2
Training loss: 1.5881246328353882
Validation loss: 1.9247044312056674

Epoch: 5| Step: 3
Training loss: 1.3472760915756226
Validation loss: 1.9475735925859021

Epoch: 5| Step: 4
Training loss: 1.7761914730072021
Validation loss: 1.952652931213379

Epoch: 5| Step: 5
Training loss: 1.1417715549468994
Validation loss: 1.9470669736144364

Epoch: 5| Step: 6
Training loss: 0.9309636950492859
Validation loss: 1.9133731870241062

Epoch: 5| Step: 7
Training loss: 1.1143406629562378
Validation loss: 1.9100164956943964

Epoch: 5| Step: 8
Training loss: 1.0044552087783813
Validation loss: 1.9060947279776297

Epoch: 5| Step: 9
Training loss: 1.1608123779296875
Validation loss: 1.948560062275138

Epoch: 5| Step: 10
Training loss: 1.4652429819107056
Validation loss: 1.9488056167479484

Epoch: 405| Step: 0
Training loss: 0.9013339281082153
Validation loss: 1.9495658874511719

Epoch: 5| Step: 1
Training loss: 1.7276815176010132
Validation loss: 1.9970074635680004

Epoch: 5| Step: 2
Training loss: 1.403358817100525
Validation loss: 2.038026604601132

Epoch: 5| Step: 3
Training loss: 1.1851129531860352
Validation loss: 2.0007892270242014

Epoch: 5| Step: 4
Training loss: 1.1046360731124878
Validation loss: 1.982829616915795

Epoch: 5| Step: 5
Training loss: 1.415468454360962
Validation loss: 1.9904650654844058

Epoch: 5| Step: 6
Training loss: 1.8248307704925537
Validation loss: 1.9260071631400817

Epoch: 5| Step: 7
Training loss: 1.1996550559997559
Validation loss: 1.9041251110774216

Epoch: 5| Step: 8
Training loss: 1.0295242071151733
Validation loss: 1.9203906507902249

Epoch: 5| Step: 9
Training loss: 0.8713763356208801
Validation loss: 1.884158561306615

Epoch: 5| Step: 10
Training loss: 0.7599192261695862
Validation loss: 1.8586053771357383

Epoch: 406| Step: 0
Training loss: 1.1471359729766846
Validation loss: 1.8935131103761735

Epoch: 5| Step: 1
Training loss: 1.0320608615875244
Validation loss: 1.8907376796968522

Epoch: 5| Step: 2
Training loss: 0.995815634727478
Validation loss: 1.8902809876267628

Epoch: 5| Step: 3
Training loss: 1.058081030845642
Validation loss: 1.9264863511567474

Epoch: 5| Step: 4
Training loss: 1.6935546398162842
Validation loss: 1.9104827757804625

Epoch: 5| Step: 5
Training loss: 1.5559598207473755
Validation loss: 1.9076825982780867

Epoch: 5| Step: 6
Training loss: 1.4379441738128662
Validation loss: 1.9253472897314257

Epoch: 5| Step: 7
Training loss: 1.3957924842834473
Validation loss: 1.9281631105689592

Epoch: 5| Step: 8
Training loss: 1.0523974895477295
Validation loss: 1.9475909535602858

Epoch: 5| Step: 9
Training loss: 1.3123853206634521
Validation loss: 1.9441216581611223

Epoch: 5| Step: 10
Training loss: 0.3491586148738861
Validation loss: 1.9572059339092625

Epoch: 407| Step: 0
Training loss: 1.237778902053833
Validation loss: 1.95884870970121

Epoch: 5| Step: 1
Training loss: 0.8558036684989929
Validation loss: 1.9085561511337117

Epoch: 5| Step: 2
Training loss: 0.8685806393623352
Validation loss: 1.9255547805499005

Epoch: 5| Step: 3
Training loss: 1.5851409435272217
Validation loss: 1.951205127982683

Epoch: 5| Step: 4
Training loss: 1.2843010425567627
Validation loss: 1.9329325793891825

Epoch: 5| Step: 5
Training loss: 1.376954197883606
Validation loss: 1.9345390835115988

Epoch: 5| Step: 6
Training loss: 1.5737559795379639
Validation loss: 1.9476052535477506

Epoch: 5| Step: 7
Training loss: 0.5455619096755981
Validation loss: 1.9452649393389303

Epoch: 5| Step: 8
Training loss: 1.3123352527618408
Validation loss: 1.948480111296459

Epoch: 5| Step: 9
Training loss: 1.1477724313735962
Validation loss: 1.9344500828814764

Epoch: 5| Step: 10
Training loss: 1.422871708869934
Validation loss: 1.9364925199939358

Epoch: 408| Step: 0
Training loss: 1.378025770187378
Validation loss: 1.8915854423276839

Epoch: 5| Step: 1
Training loss: 1.8228651285171509
Validation loss: 1.8903526234370407

Epoch: 5| Step: 2
Training loss: 1.2024338245391846
Validation loss: 1.8851597603931223

Epoch: 5| Step: 3
Training loss: 1.4196650981903076
Validation loss: 1.8934549926429667

Epoch: 5| Step: 4
Training loss: 1.2369309663772583
Validation loss: 1.9424166807564356

Epoch: 5| Step: 5
Training loss: 1.1720306873321533
Validation loss: 2.0001818518484793

Epoch: 5| Step: 6
Training loss: 0.9405725598335266
Validation loss: 1.9768486663859377

Epoch: 5| Step: 7
Training loss: 1.0095975399017334
Validation loss: 1.9779643140813357

Epoch: 5| Step: 8
Training loss: 1.0626847743988037
Validation loss: 1.9928486609971652

Epoch: 5| Step: 9
Training loss: 0.9802618026733398
Validation loss: 1.9537525946094143

Epoch: 5| Step: 10
Training loss: 1.1367919445037842
Validation loss: 1.9625512784527195

Epoch: 409| Step: 0
Training loss: 1.2295701503753662
Validation loss: 1.942403575425507

Epoch: 5| Step: 1
Training loss: 1.1652342081069946
Validation loss: 1.9085150482834026

Epoch: 5| Step: 2
Training loss: 0.942656397819519
Validation loss: 1.892114095790412

Epoch: 5| Step: 3
Training loss: 1.0669190883636475
Validation loss: 1.9128754702947472

Epoch: 5| Step: 4
Training loss: 1.1812903881072998
Validation loss: 1.874754145581235

Epoch: 5| Step: 5
Training loss: 1.6381902694702148
Validation loss: 1.9270500136959938

Epoch: 5| Step: 6
Training loss: 1.2519818544387817
Validation loss: 1.9146791606821039

Epoch: 5| Step: 7
Training loss: 0.9496870040893555
Validation loss: 1.8924412855537989

Epoch: 5| Step: 8
Training loss: 1.2073675394058228
Validation loss: 1.8960144186532626

Epoch: 5| Step: 9
Training loss: 1.3992621898651123
Validation loss: 1.8952503140254686

Epoch: 5| Step: 10
Training loss: 1.0468112230300903
Validation loss: 1.9082427012023104

Epoch: 410| Step: 0
Training loss: 1.590677261352539
Validation loss: 1.9363300505504812

Epoch: 5| Step: 1
Training loss: 0.9699058532714844
Validation loss: 1.9472245618861208

Epoch: 5| Step: 2
Training loss: 1.1157954931259155
Validation loss: 1.9369864681715607

Epoch: 5| Step: 3
Training loss: 1.293830156326294
Validation loss: 1.9429526149585683

Epoch: 5| Step: 4
Training loss: 1.5129859447479248
Validation loss: 1.9315957305251912

Epoch: 5| Step: 5
Training loss: 1.1684309244155884
Validation loss: 1.9248328747287873

Epoch: 5| Step: 6
Training loss: 1.2026340961456299
Validation loss: 1.9185653642941547

Epoch: 5| Step: 7
Training loss: 1.408748984336853
Validation loss: 1.90922325529078

Epoch: 5| Step: 8
Training loss: 0.9508475065231323
Validation loss: 1.9472551294552383

Epoch: 5| Step: 9
Training loss: 0.8758220672607422
Validation loss: 1.9496263521973805

Epoch: 5| Step: 10
Training loss: 1.0636861324310303
Validation loss: 1.9487932010363507

Epoch: 411| Step: 0
Training loss: 1.1637579202651978
Validation loss: 1.9543379320893237

Epoch: 5| Step: 1
Training loss: 1.1170148849487305
Validation loss: 2.0146677750413136

Epoch: 5| Step: 2
Training loss: 1.452901005744934
Validation loss: 2.013201134179228

Epoch: 5| Step: 3
Training loss: 0.9903115034103394
Validation loss: 1.9931862815733878

Epoch: 5| Step: 4
Training loss: 0.9811302423477173
Validation loss: 2.0053287667612874

Epoch: 5| Step: 5
Training loss: 1.006745457649231
Validation loss: 1.952745509404008

Epoch: 5| Step: 6
Training loss: 1.3784611225128174
Validation loss: 1.9044753556610436

Epoch: 5| Step: 7
Training loss: 1.1245462894439697
Validation loss: 1.8508306626350648

Epoch: 5| Step: 8
Training loss: 1.1564552783966064
Validation loss: 1.8839248393171577

Epoch: 5| Step: 9
Training loss: 1.4130446910858154
Validation loss: 1.861275847240161

Epoch: 5| Step: 10
Training loss: 1.3672075271606445
Validation loss: 1.8713160804522935

Epoch: 412| Step: 0
Training loss: 1.3153626918792725
Validation loss: 1.8506041457576137

Epoch: 5| Step: 1
Training loss: 1.4221081733703613
Validation loss: 1.904337344631072

Epoch: 5| Step: 2
Training loss: 1.8739917278289795
Validation loss: 1.9399995662832772

Epoch: 5| Step: 3
Training loss: 1.0461146831512451
Validation loss: 1.9093172345110165

Epoch: 5| Step: 4
Training loss: 1.0678187608718872
Validation loss: 1.9391499796221334

Epoch: 5| Step: 5
Training loss: 0.8478173017501831
Validation loss: 1.9347253255946661

Epoch: 5| Step: 6
Training loss: 0.9134197235107422
Validation loss: 1.9674849766556934

Epoch: 5| Step: 7
Training loss: 0.9881542325019836
Validation loss: 1.9912154930894093

Epoch: 5| Step: 8
Training loss: 1.0881965160369873
Validation loss: 1.9639036988699308

Epoch: 5| Step: 9
Training loss: 1.2630863189697266
Validation loss: 1.9709039208709553

Epoch: 5| Step: 10
Training loss: 1.2112141847610474
Validation loss: 1.9397137408615441

Epoch: 413| Step: 0
Training loss: 1.3434371948242188
Validation loss: 1.924838759565866

Epoch: 5| Step: 1
Training loss: 0.838147759437561
Validation loss: 1.9171960097487255

Epoch: 5| Step: 2
Training loss: 1.0205646753311157
Validation loss: 1.9178861982078963

Epoch: 5| Step: 3
Training loss: 1.320089340209961
Validation loss: 1.8849696010671637

Epoch: 5| Step: 4
Training loss: 1.3966506719589233
Validation loss: 1.8850799914329284

Epoch: 5| Step: 5
Training loss: 1.2978960275650024
Validation loss: 1.9034462180188907

Epoch: 5| Step: 6
Training loss: 1.4157345294952393
Validation loss: 1.8839978633388397

Epoch: 5| Step: 7
Training loss: 0.994261622428894
Validation loss: 1.9455241105889762

Epoch: 5| Step: 8
Training loss: 1.0103466510772705
Validation loss: 1.9136865985008977

Epoch: 5| Step: 9
Training loss: 0.9912294149398804
Validation loss: 1.9144178372557445

Epoch: 5| Step: 10
Training loss: 1.1842178106307983
Validation loss: 1.9166422056895431

Epoch: 414| Step: 0
Training loss: 1.5662133693695068
Validation loss: 1.9027554117223269

Epoch: 5| Step: 1
Training loss: 0.8338824510574341
Validation loss: 1.9501765774142357

Epoch: 5| Step: 2
Training loss: 1.501610279083252
Validation loss: 1.9649705130566832

Epoch: 5| Step: 3
Training loss: 1.2344801425933838
Validation loss: 1.9692732275173228

Epoch: 5| Step: 4
Training loss: 1.1616075038909912
Validation loss: 1.9334014295249857

Epoch: 5| Step: 5
Training loss: 1.4708102941513062
Validation loss: 1.9525513200349705

Epoch: 5| Step: 6
Training loss: 0.7554028630256653
Validation loss: 1.9486751569214689

Epoch: 5| Step: 7
Training loss: 0.8149248361587524
Validation loss: 1.9513633481917843

Epoch: 5| Step: 8
Training loss: 1.2658555507659912
Validation loss: 1.9537771799231087

Epoch: 5| Step: 9
Training loss: 1.1348927021026611
Validation loss: 1.993462658697559

Epoch: 5| Step: 10
Training loss: 0.8881955146789551
Validation loss: 1.9429225511448358

Epoch: 415| Step: 0
Training loss: 1.6113898754119873
Validation loss: 1.9388030934077438

Epoch: 5| Step: 1
Training loss: 0.7032558917999268
Validation loss: 1.940212401010657

Epoch: 5| Step: 2
Training loss: 1.351433515548706
Validation loss: 1.8921982088396627

Epoch: 5| Step: 3
Training loss: 1.1330941915512085
Validation loss: 1.9333907609344811

Epoch: 5| Step: 4
Training loss: 1.1846086978912354
Validation loss: 1.9136328953568653

Epoch: 5| Step: 5
Training loss: 0.9399030804634094
Validation loss: 1.8801228410454207

Epoch: 5| Step: 6
Training loss: 1.1357957124710083
Validation loss: 1.904135650204074

Epoch: 5| Step: 7
Training loss: 1.2477065324783325
Validation loss: 1.8926088579239384

Epoch: 5| Step: 8
Training loss: 0.9191504716873169
Validation loss: 1.9128074504995858

Epoch: 5| Step: 9
Training loss: 1.2375752925872803
Validation loss: 1.9387617841843636

Epoch: 5| Step: 10
Training loss: 1.2784756422042847
Validation loss: 1.9493676475299302

Epoch: 416| Step: 0
Training loss: 1.1212658882141113
Validation loss: 1.9437583518284622

Epoch: 5| Step: 1
Training loss: 1.3202543258666992
Validation loss: 1.971363300918251

Epoch: 5| Step: 2
Training loss: 1.2413450479507446
Validation loss: 1.9700128903952978

Epoch: 5| Step: 3
Training loss: 1.4093716144561768
Validation loss: 1.968587129346786

Epoch: 5| Step: 4
Training loss: 1.099543809890747
Validation loss: 1.9390722013288928

Epoch: 5| Step: 5
Training loss: 0.9474374651908875
Validation loss: 1.890709969305223

Epoch: 5| Step: 6
Training loss: 1.1033976078033447
Validation loss: 1.9195545232424172

Epoch: 5| Step: 7
Training loss: 0.8437560200691223
Validation loss: 1.926355714439064

Epoch: 5| Step: 8
Training loss: 0.9872602224349976
Validation loss: 1.929038061890551

Epoch: 5| Step: 9
Training loss: 1.4709991216659546
Validation loss: 1.9054473676989157

Epoch: 5| Step: 10
Training loss: 0.9752689599990845
Validation loss: 1.9567013197047736

Epoch: 417| Step: 0
Training loss: 1.0231633186340332
Validation loss: 1.920414622111987

Epoch: 5| Step: 1
Training loss: 0.7811999917030334
Validation loss: 1.8937816376327186

Epoch: 5| Step: 2
Training loss: 1.1260379552841187
Validation loss: 1.9243068002885388

Epoch: 5| Step: 3
Training loss: 1.0013947486877441
Validation loss: 1.9146533922482563

Epoch: 5| Step: 4
Training loss: 1.1301565170288086
Validation loss: 1.8796051625282533

Epoch: 5| Step: 5
Training loss: 1.2253566980361938
Validation loss: 1.9108064559198195

Epoch: 5| Step: 6
Training loss: 1.4289095401763916
Validation loss: 1.8898470158218055

Epoch: 5| Step: 7
Training loss: 1.349061369895935
Validation loss: 1.9008274386006017

Epoch: 5| Step: 8
Training loss: 1.0018317699432373
Validation loss: 1.8910944641277354

Epoch: 5| Step: 9
Training loss: 1.253185510635376
Validation loss: 1.907001087742467

Epoch: 5| Step: 10
Training loss: 1.1114583015441895
Validation loss: 1.9296444744192145

Epoch: 418| Step: 0
Training loss: 0.8214513659477234
Validation loss: 1.9488478437546761

Epoch: 5| Step: 1
Training loss: 1.4894111156463623
Validation loss: 1.9219509593902095

Epoch: 5| Step: 2
Training loss: 0.8842989206314087
Validation loss: 1.9310451181986

Epoch: 5| Step: 3
Training loss: 0.9543984532356262
Validation loss: 1.8814984354921567

Epoch: 5| Step: 4
Training loss: 1.1875327825546265
Validation loss: 1.8941208034433343

Epoch: 5| Step: 5
Training loss: 1.4045153856277466
Validation loss: 1.8982801860378635

Epoch: 5| Step: 6
Training loss: 1.3307428359985352
Validation loss: 1.8929420055881623

Epoch: 5| Step: 7
Training loss: 1.2613434791564941
Validation loss: 1.9003046340839838

Epoch: 5| Step: 8
Training loss: 0.7900281548500061
Validation loss: 1.87520855985662

Epoch: 5| Step: 9
Training loss: 1.2525442838668823
Validation loss: 1.93220506944964

Epoch: 5| Step: 10
Training loss: 1.2390553951263428
Validation loss: 1.9591706042648644

Epoch: 419| Step: 0
Training loss: 1.7224996089935303
Validation loss: 2.0169095570041287

Epoch: 5| Step: 1
Training loss: 0.9435269236564636
Validation loss: 2.010357497840799

Epoch: 5| Step: 2
Training loss: 1.015634298324585
Validation loss: 2.023260081968

Epoch: 5| Step: 3
Training loss: 0.9400110244750977
Validation loss: 1.9866169857722458

Epoch: 5| Step: 4
Training loss: 0.918915867805481
Validation loss: 1.9889686902364094

Epoch: 5| Step: 5
Training loss: 1.1782658100128174
Validation loss: 1.9536790411959413

Epoch: 5| Step: 6
Training loss: 1.1874580383300781
Validation loss: 1.94719180240426

Epoch: 5| Step: 7
Training loss: 1.2510632276535034
Validation loss: 1.890674728219227

Epoch: 5| Step: 8
Training loss: 1.472212553024292
Validation loss: 1.8897469582096222

Epoch: 5| Step: 9
Training loss: 0.9343226552009583
Validation loss: 1.8598812882618239

Epoch: 5| Step: 10
Training loss: 1.0640124082565308
Validation loss: 1.8756480037525136

Epoch: 420| Step: 0
Training loss: 1.2055212259292603
Validation loss: 1.9120587225883239

Epoch: 5| Step: 1
Training loss: 1.47447669506073
Validation loss: 1.9142435853199293

Epoch: 5| Step: 2
Training loss: 0.7751808166503906
Validation loss: 1.8876949869176394

Epoch: 5| Step: 3
Training loss: 1.1922868490219116
Validation loss: 1.93476866650325

Epoch: 5| Step: 4
Training loss: 1.6543056964874268
Validation loss: 1.9166111048831735

Epoch: 5| Step: 5
Training loss: 0.9908388257026672
Validation loss: 1.9343645726480792

Epoch: 5| Step: 6
Training loss: 0.7770708203315735
Validation loss: 1.94382599348663

Epoch: 5| Step: 7
Training loss: 0.7061066031455994
Validation loss: 1.9505802200686546

Epoch: 5| Step: 8
Training loss: 1.3160266876220703
Validation loss: 1.948986840504472

Epoch: 5| Step: 9
Training loss: 1.5551962852478027
Validation loss: 1.901703275660033

Epoch: 5| Step: 10
Training loss: 0.8931159973144531
Validation loss: 1.897405783335368

Epoch: 421| Step: 0
Training loss: 1.3678399324417114
Validation loss: 1.9019736013104838

Epoch: 5| Step: 1
Training loss: 1.115382194519043
Validation loss: 1.8927127148515435

Epoch: 5| Step: 2
Training loss: 1.0731383562088013
Validation loss: 1.895467258268787

Epoch: 5| Step: 3
Training loss: 1.3702281713485718
Validation loss: 1.9285472105908137

Epoch: 5| Step: 4
Training loss: 0.879765510559082
Validation loss: 1.9189598303969189

Epoch: 5| Step: 5
Training loss: 1.365483283996582
Validation loss: 1.9437908511007986

Epoch: 5| Step: 6
Training loss: 1.2781226634979248
Validation loss: 1.9388127442329162

Epoch: 5| Step: 7
Training loss: 1.2667144536972046
Validation loss: 1.9286944968726045

Epoch: 5| Step: 8
Training loss: 0.6691473722457886
Validation loss: 1.9337141795824933

Epoch: 5| Step: 9
Training loss: 1.0191866159439087
Validation loss: 1.92270625534878

Epoch: 5| Step: 10
Training loss: 0.8570882081985474
Validation loss: 1.954471593262047

Epoch: 422| Step: 0
Training loss: 0.8927583694458008
Validation loss: 1.9486606531245734

Epoch: 5| Step: 1
Training loss: 1.1945998668670654
Validation loss: 1.930359273828486

Epoch: 5| Step: 2
Training loss: 1.3153024911880493
Validation loss: 1.9367917083924817

Epoch: 5| Step: 3
Training loss: 0.624655544757843
Validation loss: 1.8965616944015666

Epoch: 5| Step: 4
Training loss: 1.1916933059692383
Validation loss: 1.8844997857206611

Epoch: 5| Step: 5
Training loss: 1.2676846981048584
Validation loss: 1.906949206065106

Epoch: 5| Step: 6
Training loss: 1.1139769554138184
Validation loss: 1.8820051236819195

Epoch: 5| Step: 7
Training loss: 1.112015962600708
Validation loss: 1.8609263025304323

Epoch: 5| Step: 8
Training loss: 0.758202075958252
Validation loss: 1.9063327389378701

Epoch: 5| Step: 9
Training loss: 1.1645851135253906
Validation loss: 1.914144036590412

Epoch: 5| Step: 10
Training loss: 1.7573881149291992
Validation loss: 1.881574958883306

Epoch: 423| Step: 0
Training loss: 0.6430689692497253
Validation loss: 1.9122570201914797

Epoch: 5| Step: 1
Training loss: 0.8542030453681946
Validation loss: 1.912024854331888

Epoch: 5| Step: 2
Training loss: 0.7817432284355164
Validation loss: 1.8964989005878408

Epoch: 5| Step: 3
Training loss: 1.2998665571212769
Validation loss: 1.8774704381983767

Epoch: 5| Step: 4
Training loss: 1.3969806432724
Validation loss: 1.912648823953444

Epoch: 5| Step: 5
Training loss: 1.2813589572906494
Validation loss: 1.9276162591031802

Epoch: 5| Step: 6
Training loss: 1.3196253776550293
Validation loss: 1.9508149444416005

Epoch: 5| Step: 7
Training loss: 0.8386139869689941
Validation loss: 1.9068806081689813

Epoch: 5| Step: 8
Training loss: 1.05259370803833
Validation loss: 1.9015012338597288

Epoch: 5| Step: 9
Training loss: 1.1911580562591553
Validation loss: 1.9069630433154363

Epoch: 5| Step: 10
Training loss: 1.6714681386947632
Validation loss: 1.9073169462142452

Epoch: 424| Step: 0
Training loss: 1.4563184976577759
Validation loss: 1.916567737056363

Epoch: 5| Step: 1
Training loss: 0.7807753086090088
Validation loss: 1.9456805695769608

Epoch: 5| Step: 2
Training loss: 1.5774495601654053
Validation loss: 1.9183533742863645

Epoch: 5| Step: 3
Training loss: 1.0347650051116943
Validation loss: 1.899504433396042

Epoch: 5| Step: 4
Training loss: 0.8723357319831848
Validation loss: 1.9305264513979676

Epoch: 5| Step: 5
Training loss: 0.9240538477897644
Validation loss: 1.8822550363438104

Epoch: 5| Step: 6
Training loss: 0.7805498242378235
Validation loss: 1.9200588951828659

Epoch: 5| Step: 7
Training loss: 0.8492963910102844
Validation loss: 1.9120948173666512

Epoch: 5| Step: 8
Training loss: 1.2839677333831787
Validation loss: 1.880633161913964

Epoch: 5| Step: 9
Training loss: 1.2277380228042603
Validation loss: 1.9124044179916382

Epoch: 5| Step: 10
Training loss: 1.5058728456497192
Validation loss: 1.9543541246844875

Epoch: 425| Step: 0
Training loss: 0.9768440127372742
Validation loss: 1.9715199406429003

Epoch: 5| Step: 1
Training loss: 1.0756100416183472
Validation loss: 1.9469468901234288

Epoch: 5| Step: 2
Training loss: 0.8714815974235535
Validation loss: 1.949842910612783

Epoch: 5| Step: 3
Training loss: 1.0061339139938354
Validation loss: 1.9165467344304568

Epoch: 5| Step: 4
Training loss: 0.7928284406661987
Validation loss: 1.9274737104292838

Epoch: 5| Step: 5
Training loss: 1.0322809219360352
Validation loss: 1.8919962401031165

Epoch: 5| Step: 6
Training loss: 1.4785913228988647
Validation loss: 1.8982952051265265

Epoch: 5| Step: 7
Training loss: 1.4283326864242554
Validation loss: 1.8904334165716683

Epoch: 5| Step: 8
Training loss: 1.2726951837539673
Validation loss: 1.8464004237164733

Epoch: 5| Step: 9
Training loss: 1.1072880029678345
Validation loss: 1.8888733566448253

Epoch: 5| Step: 10
Training loss: 1.1046767234802246
Validation loss: 1.9123403615848993

Epoch: 426| Step: 0
Training loss: 1.0310195684432983
Validation loss: 1.930449096105432

Epoch: 5| Step: 1
Training loss: 1.0541818141937256
Validation loss: 1.970345216412698

Epoch: 5| Step: 2
Training loss: 1.3404439687728882
Validation loss: 1.963907455885282

Epoch: 5| Step: 3
Training loss: 1.4772106409072876
Validation loss: 1.9497037241535802

Epoch: 5| Step: 4
Training loss: 0.8968023061752319
Validation loss: 1.9498107151318622

Epoch: 5| Step: 5
Training loss: 1.123766303062439
Validation loss: 1.9783682297634821

Epoch: 5| Step: 6
Training loss: 0.8068062663078308
Validation loss: 1.9422614830796436

Epoch: 5| Step: 7
Training loss: 1.2195364236831665
Validation loss: 1.9439218185281242

Epoch: 5| Step: 8
Training loss: 0.8505399823188782
Validation loss: 1.905977609337017

Epoch: 5| Step: 9
Training loss: 1.2338449954986572
Validation loss: 1.9201579850207093

Epoch: 5| Step: 10
Training loss: 1.076283574104309
Validation loss: 1.8559372630170596

Epoch: 427| Step: 0
Training loss: 1.071150302886963
Validation loss: 1.8751072037604548

Epoch: 5| Step: 1
Training loss: 0.7512938976287842
Validation loss: 1.8739601130126624

Epoch: 5| Step: 2
Training loss: 1.1028127670288086
Validation loss: 1.8939338550772717

Epoch: 5| Step: 3
Training loss: 1.4645932912826538
Validation loss: 1.9519817367676766

Epoch: 5| Step: 4
Training loss: 1.332126498222351
Validation loss: 1.953251543865409

Epoch: 5| Step: 5
Training loss: 1.0291657447814941
Validation loss: 1.9813749662009619

Epoch: 5| Step: 6
Training loss: 0.997004508972168
Validation loss: 1.9982664892750401

Epoch: 5| Step: 7
Training loss: 0.5676182508468628
Validation loss: 1.966958495878404

Epoch: 5| Step: 8
Training loss: 0.9333459734916687
Validation loss: 1.9617584136224562

Epoch: 5| Step: 9
Training loss: 1.1500495672225952
Validation loss: 1.943563622813071

Epoch: 5| Step: 10
Training loss: 1.6933420896530151
Validation loss: 1.928718304121366

Epoch: 428| Step: 0
Training loss: 1.2615323066711426
Validation loss: 1.9444143746488838

Epoch: 5| Step: 1
Training loss: 1.5356874465942383
Validation loss: 1.920180122057597

Epoch: 5| Step: 2
Training loss: 0.8600685000419617
Validation loss: 1.864097684942266

Epoch: 5| Step: 3
Training loss: 0.9852437973022461
Validation loss: 1.8960067738768875

Epoch: 5| Step: 4
Training loss: 1.0466811656951904
Validation loss: 1.9031904641018118

Epoch: 5| Step: 5
Training loss: 0.8678146600723267
Validation loss: 1.9195410461835964

Epoch: 5| Step: 6
Training loss: 1.5384011268615723
Validation loss: 1.8814849815061014

Epoch: 5| Step: 7
Training loss: 1.1194565296173096
Validation loss: 1.8885597477677047

Epoch: 5| Step: 8
Training loss: 1.1124536991119385
Validation loss: 1.8730594829846454

Epoch: 5| Step: 9
Training loss: 0.9231227040290833
Validation loss: 1.9085124948973298

Epoch: 5| Step: 10
Training loss: 0.7032940983772278
Validation loss: 1.9135809585612307

Epoch: 429| Step: 0
Training loss: 1.3004989624023438
Validation loss: 1.9256415367126465

Epoch: 5| Step: 1
Training loss: 1.1387851238250732
Validation loss: 1.9421525770618069

Epoch: 5| Step: 2
Training loss: 1.434800148010254
Validation loss: 1.9530462590597009

Epoch: 5| Step: 3
Training loss: 1.3039252758026123
Validation loss: 1.9526782266555294

Epoch: 5| Step: 4
Training loss: 1.0392992496490479
Validation loss: 1.904643266431747

Epoch: 5| Step: 5
Training loss: 1.2353366613388062
Validation loss: 1.9231028761914981

Epoch: 5| Step: 6
Training loss: 1.0043668746948242
Validation loss: 1.9048186604694655

Epoch: 5| Step: 7
Training loss: 0.7304328680038452
Validation loss: 1.8907998326004192

Epoch: 5| Step: 8
Training loss: 1.0748804807662964
Validation loss: 1.872687191091558

Epoch: 5| Step: 9
Training loss: 1.0566364526748657
Validation loss: 1.8781234090046217

Epoch: 5| Step: 10
Training loss: 0.6352064609527588
Validation loss: 1.873710992515728

Epoch: 430| Step: 0
Training loss: 1.4007842540740967
Validation loss: 1.9195549616249659

Epoch: 5| Step: 1
Training loss: 0.8576461672782898
Validation loss: 1.9426849811307845

Epoch: 5| Step: 2
Training loss: 0.9542392492294312
Validation loss: 1.9364107578031478

Epoch: 5| Step: 3
Training loss: 1.2970211505889893
Validation loss: 1.9508252143859863

Epoch: 5| Step: 4
Training loss: 0.8033180236816406
Validation loss: 1.9966938764818254

Epoch: 5| Step: 5
Training loss: 1.078112244606018
Validation loss: 1.9559844565647904

Epoch: 5| Step: 6
Training loss: 1.4642932415008545
Validation loss: 1.9853606300969278

Epoch: 5| Step: 7
Training loss: 0.8989993929862976
Validation loss: 1.9651109300633913

Epoch: 5| Step: 8
Training loss: 1.0398863554000854
Validation loss: 1.9652153138191468

Epoch: 5| Step: 9
Training loss: 1.3810523748397827
Validation loss: 1.910457198337842

Epoch: 5| Step: 10
Training loss: 0.8142037391662598
Validation loss: 1.899170393584877

Epoch: 431| Step: 0
Training loss: 1.2795040607452393
Validation loss: 1.9280377100872736

Epoch: 5| Step: 1
Training loss: 1.057050347328186
Validation loss: 1.9438217134885891

Epoch: 5| Step: 2
Training loss: 0.9344407320022583
Validation loss: 1.8883959426674792

Epoch: 5| Step: 3
Training loss: 1.2595794200897217
Validation loss: 1.8828504226541007

Epoch: 5| Step: 4
Training loss: 1.3306878805160522
Validation loss: 1.8877544967077111

Epoch: 5| Step: 5
Training loss: 1.3028438091278076
Validation loss: 1.872565520706997

Epoch: 5| Step: 6
Training loss: 1.3762153387069702
Validation loss: 1.8705836829318796

Epoch: 5| Step: 7
Training loss: 0.6159383058547974
Validation loss: 1.8638864050629318

Epoch: 5| Step: 8
Training loss: 1.0140354633331299
Validation loss: 1.8379836428549983

Epoch: 5| Step: 9
Training loss: 0.7652562856674194
Validation loss: 1.8544032240426669

Epoch: 5| Step: 10
Training loss: 1.0140856504440308
Validation loss: 1.8828730865191388

Epoch: 432| Step: 0
Training loss: 0.9347987174987793
Validation loss: 1.8954760105379167

Epoch: 5| Step: 1
Training loss: 0.8748211860656738
Validation loss: 1.9175992358115412

Epoch: 5| Step: 2
Training loss: 1.2864679098129272
Validation loss: 1.9280681135833904

Epoch: 5| Step: 3
Training loss: 1.4723960161209106
Validation loss: 1.9196355676138273

Epoch: 5| Step: 4
Training loss: 0.8576165437698364
Validation loss: 1.9182286083057363

Epoch: 5| Step: 5
Training loss: 1.3302419185638428
Validation loss: 1.9376332311220066

Epoch: 5| Step: 6
Training loss: 0.7776170969009399
Validation loss: 1.8823457020585255

Epoch: 5| Step: 7
Training loss: 0.9734336137771606
Validation loss: 1.8866185821512693

Epoch: 5| Step: 8
Training loss: 0.6609621047973633
Validation loss: 1.894506505740586

Epoch: 5| Step: 9
Training loss: 1.6111319065093994
Validation loss: 1.912004178570163

Epoch: 5| Step: 10
Training loss: 0.8479130268096924
Validation loss: 1.8976779419888732

Epoch: 433| Step: 0
Training loss: 1.4659178256988525
Validation loss: 1.892210119514055

Epoch: 5| Step: 1
Training loss: 1.4462594985961914
Validation loss: 1.9249999215525966

Epoch: 5| Step: 2
Training loss: 0.7888538837432861
Validation loss: 1.8795759729159776

Epoch: 5| Step: 3
Training loss: 0.9752950668334961
Validation loss: 1.8800666345063077

Epoch: 5| Step: 4
Training loss: 0.7921757102012634
Validation loss: 1.874247798355677

Epoch: 5| Step: 5
Training loss: 0.884557843208313
Validation loss: 1.8598547276630197

Epoch: 5| Step: 6
Training loss: 1.14072585105896
Validation loss: 1.901769304788241

Epoch: 5| Step: 7
Training loss: 1.211405873298645
Validation loss: 1.8983824573537356

Epoch: 5| Step: 8
Training loss: 0.6965221166610718
Validation loss: 1.9238525385497718

Epoch: 5| Step: 9
Training loss: 1.5056803226470947
Validation loss: 1.9417546192804973

Epoch: 5| Step: 10
Training loss: 0.6791102290153503
Validation loss: 1.9667715052122712

Epoch: 434| Step: 0
Training loss: 1.1462851762771606
Validation loss: 1.9439745820978636

Epoch: 5| Step: 1
Training loss: 1.3386650085449219
Validation loss: 1.960376786929305

Epoch: 5| Step: 2
Training loss: 1.4713575839996338
Validation loss: 1.910521335499261

Epoch: 5| Step: 3
Training loss: 1.0238631963729858
Validation loss: 1.9546708778668476

Epoch: 5| Step: 4
Training loss: 1.3250095844268799
Validation loss: 1.904165344853555

Epoch: 5| Step: 5
Training loss: 1.4180406332015991
Validation loss: 1.9278187098041657

Epoch: 5| Step: 6
Training loss: 0.9303766489028931
Validation loss: 1.9191529994369836

Epoch: 5| Step: 7
Training loss: 1.043990135192871
Validation loss: 1.9192386340069514

Epoch: 5| Step: 8
Training loss: 0.58049476146698
Validation loss: 1.8841583254516765

Epoch: 5| Step: 9
Training loss: 0.7807015180587769
Validation loss: 1.8647070046394103

Epoch: 5| Step: 10
Training loss: 0.9843049049377441
Validation loss: 1.882487053512245

Epoch: 435| Step: 0
Training loss: 1.2784254550933838
Validation loss: 1.9186575412750244

Epoch: 5| Step: 1
Training loss: 1.026289939880371
Validation loss: 1.9215129434421498

Epoch: 5| Step: 2
Training loss: 0.9853719472885132
Validation loss: 1.8969007153664865

Epoch: 5| Step: 3
Training loss: 1.217505693435669
Validation loss: 1.9366172282926497

Epoch: 5| Step: 4
Training loss: 1.2813602685928345
Validation loss: 1.9548026797592

Epoch: 5| Step: 5
Training loss: 0.5813472867012024
Validation loss: 1.945509179945915

Epoch: 5| Step: 6
Training loss: 1.529473066329956
Validation loss: 1.9659128471087384

Epoch: 5| Step: 7
Training loss: 1.3513689041137695
Validation loss: 1.8923869825178576

Epoch: 5| Step: 8
Training loss: 0.8320837020874023
Validation loss: 1.9137889851805985

Epoch: 5| Step: 9
Training loss: 1.1218085289001465
Validation loss: 1.9030245016979914

Epoch: 5| Step: 10
Training loss: 1.012499213218689
Validation loss: 1.93166813670948

Epoch: 436| Step: 0
Training loss: 1.3002254962921143
Validation loss: 1.9584500924233468

Epoch: 5| Step: 1
Training loss: 1.2901021242141724
Validation loss: 1.92713729540507

Epoch: 5| Step: 2
Training loss: 0.7951406240463257
Validation loss: 1.9212018315510084

Epoch: 5| Step: 3
Training loss: 0.8980934023857117
Validation loss: 1.9227371203002108

Epoch: 5| Step: 4
Training loss: 1.0594996213912964
Validation loss: 1.9259951371018604

Epoch: 5| Step: 5
Training loss: 1.21308171749115
Validation loss: 1.9374264465865267

Epoch: 5| Step: 6
Training loss: 1.2921814918518066
Validation loss: 1.9099880674833893

Epoch: 5| Step: 7
Training loss: 1.2367955446243286
Validation loss: 1.8948232255956179

Epoch: 5| Step: 8
Training loss: 1.0256084203720093
Validation loss: 1.898973362420195

Epoch: 5| Step: 9
Training loss: 0.6174436807632446
Validation loss: 1.8378569836257606

Epoch: 5| Step: 10
Training loss: 0.9228531122207642
Validation loss: 1.8564235779546923

Epoch: 437| Step: 0
Training loss: 0.9865685701370239
Validation loss: 1.8387540937751852

Epoch: 5| Step: 1
Training loss: 0.9004679918289185
Validation loss: 1.8423540105101883

Epoch: 5| Step: 2
Training loss: 1.2609220743179321
Validation loss: 1.8794591978032102

Epoch: 5| Step: 3
Training loss: 0.7751306295394897
Validation loss: 1.8734094686405633

Epoch: 5| Step: 4
Training loss: 1.4266188144683838
Validation loss: 1.9066809915727185

Epoch: 5| Step: 5
Training loss: 1.1583874225616455
Validation loss: 1.93517985779752

Epoch: 5| Step: 6
Training loss: 0.903874397277832
Validation loss: 1.9646016115783362

Epoch: 5| Step: 7
Training loss: 1.4227831363677979
Validation loss: 2.0049183189228015

Epoch: 5| Step: 8
Training loss: 1.68408203125
Validation loss: 1.980807755583076

Epoch: 5| Step: 9
Training loss: 0.761753261089325
Validation loss: 1.9290037949879963

Epoch: 5| Step: 10
Training loss: 0.814849853515625
Validation loss: 1.896265293962212

Epoch: 438| Step: 0
Training loss: 1.1046451330184937
Validation loss: 1.824411949162842

Epoch: 5| Step: 1
Training loss: 1.4060008525848389
Validation loss: 1.8436638334746003

Epoch: 5| Step: 2
Training loss: 0.7839305996894836
Validation loss: 1.8428294107478151

Epoch: 5| Step: 3
Training loss: 0.9141338467597961
Validation loss: 1.8145281525068386

Epoch: 5| Step: 4
Training loss: 1.0252410173416138
Validation loss: 1.801372621649055

Epoch: 5| Step: 5
Training loss: 1.1799814701080322
Validation loss: 1.798965650220071

Epoch: 5| Step: 6
Training loss: 0.888124942779541
Validation loss: 1.8818459831258303

Epoch: 5| Step: 7
Training loss: 1.0706886053085327
Validation loss: 1.8950313137423607

Epoch: 5| Step: 8
Training loss: 1.0417721271514893
Validation loss: 1.959663575695407

Epoch: 5| Step: 9
Training loss: 1.1976444721221924
Validation loss: 1.9618570612322899

Epoch: 5| Step: 10
Training loss: 1.1843255758285522
Validation loss: 1.97202826956267

Epoch: 439| Step: 0
Training loss: 0.6248367428779602
Validation loss: 1.9588665859673613

Epoch: 5| Step: 1
Training loss: 0.5229789018630981
Validation loss: 1.949831606239401

Epoch: 5| Step: 2
Training loss: 1.3745858669281006
Validation loss: 1.9516229155243083

Epoch: 5| Step: 3
Training loss: 1.2677946090698242
Validation loss: 1.899780164482773

Epoch: 5| Step: 4
Training loss: 1.3762308359146118
Validation loss: 1.8451063120236961

Epoch: 5| Step: 5
Training loss: 0.629274845123291
Validation loss: 1.8601513178117814

Epoch: 5| Step: 6
Training loss: 1.2479888200759888
Validation loss: 1.866996818973172

Epoch: 5| Step: 7
Training loss: 1.1057296991348267
Validation loss: 1.8618944062981555

Epoch: 5| Step: 8
Training loss: 1.3729393482208252
Validation loss: 1.8512099558307278

Epoch: 5| Step: 9
Training loss: 0.8279913663864136
Validation loss: 1.9168527357039913

Epoch: 5| Step: 10
Training loss: 1.381867527961731
Validation loss: 1.8506457286496316

Epoch: 440| Step: 0
Training loss: 1.2899706363677979
Validation loss: 1.8857650449199062

Epoch: 5| Step: 1
Training loss: 0.4919090270996094
Validation loss: 1.8708840582960395

Epoch: 5| Step: 2
Training loss: 0.7746332287788391
Validation loss: 1.8831912881584578

Epoch: 5| Step: 3
Training loss: 1.233058214187622
Validation loss: 1.8616466804217267

Epoch: 5| Step: 4
Training loss: 1.4369150400161743
Validation loss: 1.8783188942940003

Epoch: 5| Step: 5
Training loss: 1.2203816175460815
Validation loss: 1.912265782715172

Epoch: 5| Step: 6
Training loss: 0.7980486154556274
Validation loss: 1.9022748547215615

Epoch: 5| Step: 7
Training loss: 1.1482040882110596
Validation loss: 1.8699260168178107

Epoch: 5| Step: 8
Training loss: 1.0364633798599243
Validation loss: 1.9077510500466952

Epoch: 5| Step: 9
Training loss: 1.1758830547332764
Validation loss: 1.9329763407348304

Epoch: 5| Step: 10
Training loss: 0.9881443977355957
Validation loss: 1.9411893519022132

Epoch: 441| Step: 0
Training loss: 1.3738971948623657
Validation loss: 1.9418972051271828

Epoch: 5| Step: 1
Training loss: 1.2793916463851929
Validation loss: 1.9051027708156134

Epoch: 5| Step: 2
Training loss: 1.1877353191375732
Validation loss: 1.9110705878144951

Epoch: 5| Step: 3
Training loss: 0.6897329092025757
Validation loss: 1.8784420541537705

Epoch: 5| Step: 4
Training loss: 1.084187626838684
Validation loss: 1.870673970509601

Epoch: 5| Step: 5
Training loss: 1.149611473083496
Validation loss: 1.8735121014297649

Epoch: 5| Step: 6
Training loss: 0.8658120036125183
Validation loss: 1.8468429157810826

Epoch: 5| Step: 7
Training loss: 0.9777754545211792
Validation loss: 1.88046230295653

Epoch: 5| Step: 8
Training loss: 1.0341142416000366
Validation loss: 1.8724603742681525

Epoch: 5| Step: 9
Training loss: 0.896030604839325
Validation loss: 1.9638626908743253

Epoch: 5| Step: 10
Training loss: 0.9281267523765564
Validation loss: 1.9996356682110858

Epoch: 442| Step: 0
Training loss: 1.002001404762268
Validation loss: 1.9988931058555521

Epoch: 5| Step: 1
Training loss: 0.6155017018318176
Validation loss: 2.015226080853452

Epoch: 5| Step: 2
Training loss: 1.1642471551895142
Validation loss: 1.9606074492136638

Epoch: 5| Step: 3
Training loss: 1.563129186630249
Validation loss: 1.9377125309359642

Epoch: 5| Step: 4
Training loss: 1.0056098699569702
Validation loss: 1.9050718712550339

Epoch: 5| Step: 5
Training loss: 0.6503636240959167
Validation loss: 1.8807561756462179

Epoch: 5| Step: 6
Training loss: 0.9914289712905884
Validation loss: 1.8877827570002566

Epoch: 5| Step: 7
Training loss: 1.1579862833023071
Validation loss: 1.9100789652075818

Epoch: 5| Step: 8
Training loss: 0.9074975848197937
Validation loss: 1.8677381725721462

Epoch: 5| Step: 9
Training loss: 1.2840182781219482
Validation loss: 1.894959290822347

Epoch: 5| Step: 10
Training loss: 1.1498361825942993
Validation loss: 1.90892578453146

Epoch: 443| Step: 0
Training loss: 1.2310810089111328
Validation loss: 1.9161290225162302

Epoch: 5| Step: 1
Training loss: 1.0036522150039673
Validation loss: 1.9722646385110834

Epoch: 5| Step: 2
Training loss: 0.8799351453781128
Validation loss: 1.9989360968271892

Epoch: 5| Step: 3
Training loss: 0.6743911504745483
Validation loss: 2.0057289959282003

Epoch: 5| Step: 4
Training loss: 1.1793063879013062
Validation loss: 2.0041156071488575

Epoch: 5| Step: 5
Training loss: 1.2452011108398438
Validation loss: 1.9416558255431473

Epoch: 5| Step: 6
Training loss: 1.1641972064971924
Validation loss: 1.920359291056151

Epoch: 5| Step: 7
Training loss: 1.2997568845748901
Validation loss: 1.9066096749356998

Epoch: 5| Step: 8
Training loss: 0.9541481733322144
Validation loss: 1.904535178215273

Epoch: 5| Step: 9
Training loss: 1.2164818048477173
Validation loss: 1.8766293333422752

Epoch: 5| Step: 10
Training loss: 0.6030969619750977
Validation loss: 1.9115119236771778

Epoch: 444| Step: 0
Training loss: 1.0494046211242676
Validation loss: 1.9121022301335489

Epoch: 5| Step: 1
Training loss: 0.6618016958236694
Validation loss: 1.9460472265879314

Epoch: 5| Step: 2
Training loss: 1.0749717950820923
Validation loss: 1.9984629333660167

Epoch: 5| Step: 3
Training loss: 0.7335492372512817
Validation loss: 1.9401760203863985

Epoch: 5| Step: 4
Training loss: 1.3679475784301758
Validation loss: 1.93350007969846

Epoch: 5| Step: 5
Training loss: 1.1937412023544312
Validation loss: 1.9596605941813479

Epoch: 5| Step: 6
Training loss: 1.033829927444458
Validation loss: 1.9518942743219354

Epoch: 5| Step: 7
Training loss: 0.7685891389846802
Validation loss: 1.9133940922316683

Epoch: 5| Step: 8
Training loss: 1.0130960941314697
Validation loss: 1.9331752241298716

Epoch: 5| Step: 9
Training loss: 1.5796326398849487
Validation loss: 1.9186172523806173

Epoch: 5| Step: 10
Training loss: 0.6700524687767029
Validation loss: 1.8864476193663895

Epoch: 445| Step: 0
Training loss: 0.9292448163032532
Validation loss: 1.8795337395001483

Epoch: 5| Step: 1
Training loss: 0.973638653755188
Validation loss: 1.8570850997842767

Epoch: 5| Step: 2
Training loss: 0.8531726598739624
Validation loss: 1.869339330222017

Epoch: 5| Step: 3
Training loss: 1.5186625719070435
Validation loss: 1.9385894216516966

Epoch: 5| Step: 4
Training loss: 1.041982889175415
Validation loss: 1.8996963962431876

Epoch: 5| Step: 5
Training loss: 0.8404701352119446
Validation loss: 1.9296456460029847

Epoch: 5| Step: 6
Training loss: 0.971095085144043
Validation loss: 1.9007631437752837

Epoch: 5| Step: 7
Training loss: 0.9477237462997437
Validation loss: 1.8790096390631892

Epoch: 5| Step: 8
Training loss: 0.9077544212341309
Validation loss: 1.8590199498720066

Epoch: 5| Step: 9
Training loss: 1.0489261150360107
Validation loss: 1.8619656152622674

Epoch: 5| Step: 10
Training loss: 1.084611177444458
Validation loss: 1.8743388780983545

Epoch: 446| Step: 0
Training loss: 0.9290574789047241
Validation loss: 1.8816052841883835

Epoch: 5| Step: 1
Training loss: 0.8464824557304382
Validation loss: 1.8879141935738184

Epoch: 5| Step: 2
Training loss: 1.2087972164154053
Validation loss: 1.873758351931008

Epoch: 5| Step: 3
Training loss: 1.3446590900421143
Validation loss: 1.8886552190267911

Epoch: 5| Step: 4
Training loss: 1.392038106918335
Validation loss: 1.8515832129345144

Epoch: 5| Step: 5
Training loss: 1.1961005926132202
Validation loss: 1.8618100881576538

Epoch: 5| Step: 6
Training loss: 0.6990010738372803
Validation loss: 1.8701874466352566

Epoch: 5| Step: 7
Training loss: 0.8705447316169739
Validation loss: 1.8683168426636727

Epoch: 5| Step: 8
Training loss: 0.784229576587677
Validation loss: 1.8388825385801253

Epoch: 5| Step: 9
Training loss: 0.9288313984870911
Validation loss: 1.8373325460700578

Epoch: 5| Step: 10
Training loss: 0.9060618281364441
Validation loss: 1.8333386041784798

Epoch: 447| Step: 0
Training loss: 0.9624438285827637
Validation loss: 1.8647210982538038

Epoch: 5| Step: 1
Training loss: 1.0313174724578857
Validation loss: 1.8981273687014015

Epoch: 5| Step: 2
Training loss: 1.276085376739502
Validation loss: 1.9558594457564815

Epoch: 5| Step: 3
Training loss: 1.0944511890411377
Validation loss: 1.9344632817852883

Epoch: 5| Step: 4
Training loss: 0.46998047828674316
Validation loss: 1.9117131412670176

Epoch: 5| Step: 5
Training loss: 1.3682913780212402
Validation loss: 1.8851304874625257

Epoch: 5| Step: 6
Training loss: 0.8690418004989624
Validation loss: 1.9202533844978578

Epoch: 5| Step: 7
Training loss: 0.6477246880531311
Validation loss: 1.8927843519436416

Epoch: 5| Step: 8
Training loss: 1.2846899032592773
Validation loss: 1.8226669296141593

Epoch: 5| Step: 9
Training loss: 1.415518879890442
Validation loss: 1.8048504860170427

Epoch: 5| Step: 10
Training loss: 1.11276113986969
Validation loss: 1.806096775557405

Epoch: 448| Step: 0
Training loss: 1.4131048917770386
Validation loss: 1.8271731189502183

Epoch: 5| Step: 1
Training loss: 1.182015299797058
Validation loss: 1.8128919473258398

Epoch: 5| Step: 2
Training loss: 0.9101086854934692
Validation loss: 1.8191136519114177

Epoch: 5| Step: 3
Training loss: 0.7408016920089722
Validation loss: 1.8662416370966102

Epoch: 5| Step: 4
Training loss: 1.1202348470687866
Validation loss: 1.9314075439207015

Epoch: 5| Step: 5
Training loss: 1.0285767316818237
Validation loss: 1.9514486264157038

Epoch: 5| Step: 6
Training loss: 1.0954152345657349
Validation loss: 1.9578394530921854

Epoch: 5| Step: 7
Training loss: 0.4945599436759949
Validation loss: 1.9451487589907903

Epoch: 5| Step: 8
Training loss: 1.2990829944610596
Validation loss: 1.9369264007896505

Epoch: 5| Step: 9
Training loss: 0.9286794662475586
Validation loss: 1.8933609249771282

Epoch: 5| Step: 10
Training loss: 1.124504566192627
Validation loss: 1.8634015667823054

Epoch: 449| Step: 0
Training loss: 0.8235973119735718
Validation loss: 1.841629365439056

Epoch: 5| Step: 1
Training loss: 1.5235891342163086
Validation loss: 1.858529527982076

Epoch: 5| Step: 2
Training loss: 1.049712061882019
Validation loss: 1.8617562042769564

Epoch: 5| Step: 3
Training loss: 0.8188371658325195
Validation loss: 1.8570831129627843

Epoch: 5| Step: 4
Training loss: 0.9593076705932617
Validation loss: 1.859796198465491

Epoch: 5| Step: 5
Training loss: 1.1010299921035767
Validation loss: 1.899483775579801

Epoch: 5| Step: 6
Training loss: 0.6607660055160522
Validation loss: 1.9115751558734524

Epoch: 5| Step: 7
Training loss: 1.279090404510498
Validation loss: 1.9196457824399393

Epoch: 5| Step: 8
Training loss: 0.8151251673698425
Validation loss: 1.9272448683297763

Epoch: 5| Step: 9
Training loss: 1.2524908781051636
Validation loss: 1.9017536063348093

Epoch: 5| Step: 10
Training loss: 0.751538872718811
Validation loss: 1.9175950904046335

Epoch: 450| Step: 0
Training loss: 0.8736955523490906
Validation loss: 1.8681464009387518

Epoch: 5| Step: 1
Training loss: 1.1002180576324463
Validation loss: 1.8605361471893966

Epoch: 5| Step: 2
Training loss: 0.9216215014457703
Validation loss: 1.8961438222598004

Epoch: 5| Step: 3
Training loss: 0.8865368962287903
Validation loss: 1.9125559253077353

Epoch: 5| Step: 4
Training loss: 1.1481332778930664
Validation loss: 1.8844273141635361

Epoch: 5| Step: 5
Training loss: 1.1396249532699585
Validation loss: 1.8916272655610116

Epoch: 5| Step: 6
Training loss: 0.953482985496521
Validation loss: 1.8869020554327196

Epoch: 5| Step: 7
Training loss: 0.7216398119926453
Validation loss: 1.9002258546890751

Epoch: 5| Step: 8
Training loss: 1.0801409482955933
Validation loss: 1.8916535595411896

Epoch: 5| Step: 9
Training loss: 1.1564650535583496
Validation loss: 1.8521768277691257

Epoch: 5| Step: 10
Training loss: 1.062780499458313
Validation loss: 1.8496562242507935

Epoch: 451| Step: 0
Training loss: 0.9845563173294067
Validation loss: 1.8252088651862195

Epoch: 5| Step: 1
Training loss: 1.3948050737380981
Validation loss: 1.8641925845094907

Epoch: 5| Step: 2
Training loss: 0.9764344096183777
Validation loss: 1.8668461615039456

Epoch: 5| Step: 3
Training loss: 1.0719668865203857
Validation loss: 1.8542999400887439

Epoch: 5| Step: 4
Training loss: 1.0773591995239258
Validation loss: 1.8852660758520967

Epoch: 5| Step: 5
Training loss: 0.9169315099716187
Validation loss: 1.9097724422331779

Epoch: 5| Step: 6
Training loss: 0.8822553753852844
Validation loss: 1.9229938368643484

Epoch: 5| Step: 7
Training loss: 1.0577332973480225
Validation loss: 1.9343850945913663

Epoch: 5| Step: 8
Training loss: 1.093494176864624
Validation loss: 1.9667155588826826

Epoch: 5| Step: 9
Training loss: 0.7003210783004761
Validation loss: 1.9557826852285733

Epoch: 5| Step: 10
Training loss: 0.812663733959198
Validation loss: 1.9183241705740652

Epoch: 452| Step: 0
Training loss: 1.0870100259780884
Validation loss: 1.8962112152448265

Epoch: 5| Step: 1
Training loss: 0.7374817132949829
Validation loss: 1.8943435966327626

Epoch: 5| Step: 2
Training loss: 1.1812044382095337
Validation loss: 1.8965247933582594

Epoch: 5| Step: 3
Training loss: 0.8263322710990906
Validation loss: 1.8778645274459675

Epoch: 5| Step: 4
Training loss: 0.9821531176567078
Validation loss: 1.9016020118549306

Epoch: 5| Step: 5
Training loss: 0.6998389363288879
Validation loss: 1.8799167448474514

Epoch: 5| Step: 6
Training loss: 0.8765605688095093
Validation loss: 1.8820393072661532

Epoch: 5| Step: 7
Training loss: 1.1889904737472534
Validation loss: 1.8801791462846982

Epoch: 5| Step: 8
Training loss: 1.1348644495010376
Validation loss: 1.8157193583826865

Epoch: 5| Step: 9
Training loss: 1.0761326551437378
Validation loss: 1.8549532159682243

Epoch: 5| Step: 10
Training loss: 1.1967583894729614
Validation loss: 1.836661502879153

Epoch: 453| Step: 0
Training loss: 1.0418307781219482
Validation loss: 1.8225213840443601

Epoch: 5| Step: 1
Training loss: 0.7433270215988159
Validation loss: 1.8491962007296983

Epoch: 5| Step: 2
Training loss: 1.0208895206451416
Validation loss: 1.870727353198554

Epoch: 5| Step: 3
Training loss: 0.8493296504020691
Validation loss: 1.9072342406037033

Epoch: 5| Step: 4
Training loss: 0.5890483260154724
Validation loss: 1.9299729101119503

Epoch: 5| Step: 5
Training loss: 0.9714805483818054
Validation loss: 1.9554125160299323

Epoch: 5| Step: 6
Training loss: 1.203193187713623
Validation loss: 1.9437092734921364

Epoch: 5| Step: 7
Training loss: 1.0360634326934814
Validation loss: 1.9195951607919508

Epoch: 5| Step: 8
Training loss: 1.4161689281463623
Validation loss: 1.93085386419809

Epoch: 5| Step: 9
Training loss: 1.1089633703231812
Validation loss: 1.8867040462391351

Epoch: 5| Step: 10
Training loss: 0.803866982460022
Validation loss: 1.8816039780134797

Epoch: 454| Step: 0
Training loss: 1.0846960544586182
Validation loss: 1.8844247043773692

Epoch: 5| Step: 1
Training loss: 0.9022289514541626
Validation loss: 1.867775410734197

Epoch: 5| Step: 2
Training loss: 0.7372076511383057
Validation loss: 1.8737097965773715

Epoch: 5| Step: 3
Training loss: 0.8029779195785522
Validation loss: 1.8224501763620684

Epoch: 5| Step: 4
Training loss: 1.012197732925415
Validation loss: 1.822039419604886

Epoch: 5| Step: 5
Training loss: 1.2376207113265991
Validation loss: 1.8115148621220742

Epoch: 5| Step: 6
Training loss: 1.3881504535675049
Validation loss: 1.8073215740983204

Epoch: 5| Step: 7
Training loss: 0.8327072262763977
Validation loss: 1.8602138937160533

Epoch: 5| Step: 8
Training loss: 1.0167574882507324
Validation loss: 1.8792281407181934

Epoch: 5| Step: 9
Training loss: 1.143373966217041
Validation loss: 1.8796604833295267

Epoch: 5| Step: 10
Training loss: 0.7830157279968262
Validation loss: 1.9407160038589149

Epoch: 455| Step: 0
Training loss: 1.1993004083633423
Validation loss: 1.9773942937133133

Epoch: 5| Step: 1
Training loss: 1.3948185443878174
Validation loss: 1.9409111443386282

Epoch: 5| Step: 2
Training loss: 1.0937947034835815
Validation loss: 1.966675353306596

Epoch: 5| Step: 3
Training loss: 1.0110089778900146
Validation loss: 1.968110736980233

Epoch: 5| Step: 4
Training loss: 0.7559912204742432
Validation loss: 1.9276544855486961

Epoch: 5| Step: 5
Training loss: 0.9863861203193665
Validation loss: 1.8914154883353942

Epoch: 5| Step: 6
Training loss: 0.9213111996650696
Validation loss: 1.8767555734162689

Epoch: 5| Step: 7
Training loss: 0.7931753993034363
Validation loss: 1.865109553901098

Epoch: 5| Step: 8
Training loss: 0.8926317095756531
Validation loss: 1.8475091457366943

Epoch: 5| Step: 9
Training loss: 0.7481748461723328
Validation loss: 1.8337775635462936

Epoch: 5| Step: 10
Training loss: 1.0898733139038086
Validation loss: 1.8087701848758164

Epoch: 456| Step: 0
Training loss: 0.43650150299072266
Validation loss: 1.826014655892567

Epoch: 5| Step: 1
Training loss: 1.0762202739715576
Validation loss: 1.8980759920612458

Epoch: 5| Step: 2
Training loss: 0.8466671705245972
Validation loss: 1.898779284569525

Epoch: 5| Step: 3
Training loss: 0.542730450630188
Validation loss: 1.8881743954073997

Epoch: 5| Step: 4
Training loss: 1.4088733196258545
Validation loss: 1.8885735388725036

Epoch: 5| Step: 5
Training loss: 1.089536190032959
Validation loss: 1.9029763565268567

Epoch: 5| Step: 6
Training loss: 1.2947301864624023
Validation loss: 1.8978264459999659

Epoch: 5| Step: 7
Training loss: 0.8901596069335938
Validation loss: 1.9000853428276636

Epoch: 5| Step: 8
Training loss: 0.7626935839653015
Validation loss: 1.8837318010227655

Epoch: 5| Step: 9
Training loss: 1.2413995265960693
Validation loss: 1.8924684370717695

Epoch: 5| Step: 10
Training loss: 0.9907984733581543
Validation loss: 1.8852577363291094

Epoch: 457| Step: 0
Training loss: 1.002187728881836
Validation loss: 1.8783767774540892

Epoch: 5| Step: 1
Training loss: 1.112470030784607
Validation loss: 1.8650750831891132

Epoch: 5| Step: 2
Training loss: 1.366816520690918
Validation loss: 1.8702402435323244

Epoch: 5| Step: 3
Training loss: 0.8409219980239868
Validation loss: 1.8674013268563054

Epoch: 5| Step: 4
Training loss: 1.0279569625854492
Validation loss: 1.8591737042191208

Epoch: 5| Step: 5
Training loss: 0.8682808876037598
Validation loss: 1.8721362313916605

Epoch: 5| Step: 6
Training loss: 0.8243950605392456
Validation loss: 1.890873791069113

Epoch: 5| Step: 7
Training loss: 1.0174431800842285
Validation loss: 1.877514777644988

Epoch: 5| Step: 8
Training loss: 0.9798086285591125
Validation loss: 1.8570643060950822

Epoch: 5| Step: 9
Training loss: 0.6930112242698669
Validation loss: 1.8699340205038748

Epoch: 5| Step: 10
Training loss: 0.9280240535736084
Validation loss: 1.849876598645282

Epoch: 458| Step: 0
Training loss: 1.005467176437378
Validation loss: 1.8066719244885188

Epoch: 5| Step: 1
Training loss: 1.4832417964935303
Validation loss: 1.8944120202013242

Epoch: 5| Step: 2
Training loss: 0.8342863917350769
Validation loss: 1.8884246656971593

Epoch: 5| Step: 3
Training loss: 0.7672591209411621
Validation loss: 1.9286203794581915

Epoch: 5| Step: 4
Training loss: 1.3193843364715576
Validation loss: 1.9710872532219015

Epoch: 5| Step: 5
Training loss: 0.9064055681228638
Validation loss: 2.01690960186784

Epoch: 5| Step: 6
Training loss: 0.9654449224472046
Validation loss: 2.007093665420368

Epoch: 5| Step: 7
Training loss: 0.9795454144477844
Validation loss: 1.988275025480537

Epoch: 5| Step: 8
Training loss: 0.8771361112594604
Validation loss: 1.9231296636724984

Epoch: 5| Step: 9
Training loss: 1.233662724494934
Validation loss: 1.9113615648720854

Epoch: 5| Step: 10
Training loss: 0.8051584959030151
Validation loss: 1.8751107364572503

Epoch: 459| Step: 0
Training loss: 1.1867109537124634
Validation loss: 1.8771910462328183

Epoch: 5| Step: 1
Training loss: 0.8256920576095581
Validation loss: 1.8668676653215963

Epoch: 5| Step: 2
Training loss: 0.9119895696640015
Validation loss: 1.845627784729004

Epoch: 5| Step: 3
Training loss: 0.8274326324462891
Validation loss: 1.8499125665233982

Epoch: 5| Step: 4
Training loss: 0.9558877944946289
Validation loss: 1.869348572146508

Epoch: 5| Step: 5
Training loss: 0.9719024896621704
Validation loss: 1.9018368567189863

Epoch: 5| Step: 6
Training loss: 1.3844799995422363
Validation loss: 1.9429886520549815

Epoch: 5| Step: 7
Training loss: 0.7312959432601929
Validation loss: 1.997977537493552

Epoch: 5| Step: 8
Training loss: 1.0816227197647095
Validation loss: 2.02739114915171

Epoch: 5| Step: 9
Training loss: 1.3103123903274536
Validation loss: 2.045237304061972

Epoch: 5| Step: 10
Training loss: 1.088262915611267
Validation loss: 1.9819408103983889

Epoch: 460| Step: 0
Training loss: 0.8166939616203308
Validation loss: 1.8768403837757726

Epoch: 5| Step: 1
Training loss: 0.9838680028915405
Validation loss: 1.8554288725699148

Epoch: 5| Step: 2
Training loss: 0.735785186290741
Validation loss: 1.853831132253011

Epoch: 5| Step: 3
Training loss: 0.7585679292678833
Validation loss: 1.8411230566681072

Epoch: 5| Step: 4
Training loss: 1.2000844478607178
Validation loss: 1.8332455401779504

Epoch: 5| Step: 5
Training loss: 1.388895034790039
Validation loss: 1.902541729711717

Epoch: 5| Step: 6
Training loss: 0.8181164860725403
Validation loss: 1.934923202760758

Epoch: 5| Step: 7
Training loss: 1.445998191833496
Validation loss: 1.9345418714707898

Epoch: 5| Step: 8
Training loss: 1.3323113918304443
Validation loss: 1.9191432742662327

Epoch: 5| Step: 9
Training loss: 1.1477062702178955
Validation loss: 1.932115993192119

Epoch: 5| Step: 10
Training loss: 0.4817204773426056
Validation loss: 1.9582152930639123

Epoch: 461| Step: 0
Training loss: 0.9902507662773132
Validation loss: 1.9854961864409908

Epoch: 5| Step: 1
Training loss: 1.4760644435882568
Validation loss: 1.9810588218832528

Epoch: 5| Step: 2
Training loss: 0.7126598954200745
Validation loss: 1.9547502725355086

Epoch: 5| Step: 3
Training loss: 1.271241545677185
Validation loss: 1.9388034933356828

Epoch: 5| Step: 4
Training loss: 0.8582332730293274
Validation loss: 1.8933359243536507

Epoch: 5| Step: 5
Training loss: 0.5328794717788696
Validation loss: 1.8462744887157152

Epoch: 5| Step: 6
Training loss: 1.0689401626586914
Validation loss: 1.8313324207900672

Epoch: 5| Step: 7
Training loss: 0.9524347186088562
Validation loss: 1.805653126009049

Epoch: 5| Step: 8
Training loss: 1.0334038734436035
Validation loss: 1.7961871521447295

Epoch: 5| Step: 9
Training loss: 1.166122317314148
Validation loss: 1.8171566301776516

Epoch: 5| Step: 10
Training loss: 1.0426527261734009
Validation loss: 1.8263752460479736

Epoch: 462| Step: 0
Training loss: 1.1264092922210693
Validation loss: 1.850257017279184

Epoch: 5| Step: 1
Training loss: 0.7733243703842163
Validation loss: 1.8339323664224276

Epoch: 5| Step: 2
Training loss: 0.8575025796890259
Validation loss: 1.8593715608760875

Epoch: 5| Step: 3
Training loss: 1.0694857835769653
Validation loss: 1.893223685602988

Epoch: 5| Step: 4
Training loss: 0.9811372756958008
Validation loss: 1.9129414750683693

Epoch: 5| Step: 5
Training loss: 1.4085801839828491
Validation loss: 1.9651740597140404

Epoch: 5| Step: 6
Training loss: 0.8209846615791321
Validation loss: 1.9800038709435412

Epoch: 5| Step: 7
Training loss: 1.0133472681045532
Validation loss: 1.9429223511808662

Epoch: 5| Step: 8
Training loss: 0.9238940477371216
Validation loss: 1.9327665131579164

Epoch: 5| Step: 9
Training loss: 0.8759859800338745
Validation loss: 1.8737249323116836

Epoch: 5| Step: 10
Training loss: 0.6352025270462036
Validation loss: 1.8757333050491989

Epoch: 463| Step: 0
Training loss: 1.0181964635849
Validation loss: 1.8638663304749357

Epoch: 5| Step: 1
Training loss: 1.2135684490203857
Validation loss: 1.854687984271716

Epoch: 5| Step: 2
Training loss: 1.0845088958740234
Validation loss: 1.8878486156463623

Epoch: 5| Step: 3
Training loss: 1.2172726392745972
Validation loss: 1.823519588798605

Epoch: 5| Step: 4
Training loss: 0.5575235486030579
Validation loss: 1.8497418229297926

Epoch: 5| Step: 5
Training loss: 0.8403087854385376
Validation loss: 1.8691576552647415

Epoch: 5| Step: 6
Training loss: 0.8887413144111633
Validation loss: 1.8912804831740677

Epoch: 5| Step: 7
Training loss: 1.0337401628494263
Validation loss: 1.9052795376828922

Epoch: 5| Step: 8
Training loss: 0.842846691608429
Validation loss: 1.9443935578869236

Epoch: 5| Step: 9
Training loss: 1.0088222026824951
Validation loss: 1.9405517847307268

Epoch: 5| Step: 10
Training loss: 0.7945144176483154
Validation loss: 1.9761745134989421

Epoch: 464| Step: 0
Training loss: 1.0851056575775146
Validation loss: 2.0032924605954077

Epoch: 5| Step: 1
Training loss: 0.5890119075775146
Validation loss: 1.9364856404642905

Epoch: 5| Step: 2
Training loss: 1.1992191076278687
Validation loss: 1.918215226101619

Epoch: 5| Step: 3
Training loss: 0.9594433903694153
Validation loss: 1.8923887283571306

Epoch: 5| Step: 4
Training loss: 0.9047232866287231
Validation loss: 1.8532592763182938

Epoch: 5| Step: 5
Training loss: 1.017134189605713
Validation loss: 1.881160105428388

Epoch: 5| Step: 6
Training loss: 1.1067410707473755
Validation loss: 1.8437005524994226

Epoch: 5| Step: 7
Training loss: 0.8459161520004272
Validation loss: 1.8841487361538796

Epoch: 5| Step: 8
Training loss: 0.8176641464233398
Validation loss: 1.8658048363142117

Epoch: 5| Step: 9
Training loss: 0.9086261987686157
Validation loss: 1.917223548376432

Epoch: 5| Step: 10
Training loss: 1.2268648147583008
Validation loss: 1.8995642559502715

Epoch: 465| Step: 0
Training loss: 0.9304621815681458
Validation loss: 1.8964489621500815

Epoch: 5| Step: 1
Training loss: 0.5880131125450134
Validation loss: 1.9111099320073281

Epoch: 5| Step: 2
Training loss: 1.1975761651992798
Validation loss: 1.8804117620632212

Epoch: 5| Step: 3
Training loss: 0.609061062335968
Validation loss: 1.8821788846805532

Epoch: 5| Step: 4
Training loss: 0.9662613868713379
Validation loss: 1.902982916883243

Epoch: 5| Step: 5
Training loss: 1.2598556280136108
Validation loss: 1.888047872051116

Epoch: 5| Step: 6
Training loss: 1.0553383827209473
Validation loss: 1.9156726752558062

Epoch: 5| Step: 7
Training loss: 0.9259673357009888
Validation loss: 1.9107913150582263

Epoch: 5| Step: 8
Training loss: 1.0303865671157837
Validation loss: 1.931098141977864

Epoch: 5| Step: 9
Training loss: 0.8254785537719727
Validation loss: 1.932779772307283

Epoch: 5| Step: 10
Training loss: 1.124271273612976
Validation loss: 1.9326934122270154

Epoch: 466| Step: 0
Training loss: 0.9989482760429382
Validation loss: 1.893774450466197

Epoch: 5| Step: 1
Training loss: 0.7329484820365906
Validation loss: 1.8884303672339326

Epoch: 5| Step: 2
Training loss: 1.219628930091858
Validation loss: 1.8830581070274435

Epoch: 5| Step: 3
Training loss: 1.0378921031951904
Validation loss: 1.8435911773353495

Epoch: 5| Step: 4
Training loss: 0.5671858787536621
Validation loss: 1.861570305721734

Epoch: 5| Step: 5
Training loss: 0.9168556928634644
Validation loss: 1.8845753285192675

Epoch: 5| Step: 6
Training loss: 1.207428216934204
Validation loss: 1.8829105451542845

Epoch: 5| Step: 7
Training loss: 0.5542462468147278
Validation loss: 1.8513131987664007

Epoch: 5| Step: 8
Training loss: 0.9303228259086609
Validation loss: 1.8380862833351217

Epoch: 5| Step: 9
Training loss: 0.6727180480957031
Validation loss: 1.8702507454861876

Epoch: 5| Step: 10
Training loss: 1.3924190998077393
Validation loss: 1.8544226179840744

Epoch: 467| Step: 0
Training loss: 1.0722728967666626
Validation loss: 1.8472761261847712

Epoch: 5| Step: 1
Training loss: 1.2268178462982178
Validation loss: 1.8488467713837982

Epoch: 5| Step: 2
Training loss: 1.2808923721313477
Validation loss: 1.8237579009866203

Epoch: 5| Step: 3
Training loss: 0.5910773873329163
Validation loss: 1.8329257170359294

Epoch: 5| Step: 4
Training loss: 1.0168912410736084
Validation loss: 1.8325181750841038

Epoch: 5| Step: 5
Training loss: 0.5284699201583862
Validation loss: 1.874275626674775

Epoch: 5| Step: 6
Training loss: 0.7709996104240417
Validation loss: 1.908485556161532

Epoch: 5| Step: 7
Training loss: 0.7231019735336304
Validation loss: 1.9014911831066172

Epoch: 5| Step: 8
Training loss: 0.917678713798523
Validation loss: 1.945972332390406

Epoch: 5| Step: 9
Training loss: 1.190842866897583
Validation loss: 1.9109151055735927

Epoch: 5| Step: 10
Training loss: 0.8374696969985962
Validation loss: 1.9295012361259871

Epoch: 468| Step: 0
Training loss: 0.8389261364936829
Validation loss: 1.8743217888698782

Epoch: 5| Step: 1
Training loss: 0.9311067461967468
Validation loss: 1.8456460660503757

Epoch: 5| Step: 2
Training loss: 1.1584676504135132
Validation loss: 1.875887147841915

Epoch: 5| Step: 3
Training loss: 1.1540238857269287
Validation loss: 1.8167866404338548

Epoch: 5| Step: 4
Training loss: 0.8176895380020142
Validation loss: 1.823072821863236

Epoch: 5| Step: 5
Training loss: 0.6434087157249451
Validation loss: 1.8280892602859005

Epoch: 5| Step: 6
Training loss: 1.1525875329971313
Validation loss: 1.8685704277407738

Epoch: 5| Step: 7
Training loss: 1.1032435894012451
Validation loss: 1.8769047721739738

Epoch: 5| Step: 8
Training loss: 1.005257248878479
Validation loss: 1.8815410111540107

Epoch: 5| Step: 9
Training loss: 0.48960477113723755
Validation loss: 1.8704384014170656

Epoch: 5| Step: 10
Training loss: 0.8462763428688049
Validation loss: 1.892256083027009

Epoch: 469| Step: 0
Training loss: 0.6896752715110779
Validation loss: 1.8451422299108198

Epoch: 5| Step: 1
Training loss: 0.7866278290748596
Validation loss: 1.8641763348733225

Epoch: 5| Step: 2
Training loss: 1.4681100845336914
Validation loss: 1.8898351833384524

Epoch: 5| Step: 3
Training loss: 0.9681574106216431
Validation loss: 1.8754555666318504

Epoch: 5| Step: 4
Training loss: 0.9550663232803345
Validation loss: 1.8817525961065804

Epoch: 5| Step: 5
Training loss: 0.7519380450248718
Validation loss: 1.8564503321083643

Epoch: 5| Step: 6
Training loss: 1.1419551372528076
Validation loss: 1.9014028785049275

Epoch: 5| Step: 7
Training loss: 0.9074767827987671
Validation loss: 1.887750082118537

Epoch: 5| Step: 8
Training loss: 0.517905056476593
Validation loss: 1.8611985944932508

Epoch: 5| Step: 9
Training loss: 0.8491970300674438
Validation loss: 1.891366954772703

Epoch: 5| Step: 10
Training loss: 1.4236410856246948
Validation loss: 1.8407989189188967

Epoch: 470| Step: 0
Training loss: 1.2285622358322144
Validation loss: 1.8573590222225393

Epoch: 5| Step: 1
Training loss: 1.0888863801956177
Validation loss: 1.8142530495120632

Epoch: 5| Step: 2
Training loss: 0.8953266143798828
Validation loss: 1.839057937745125

Epoch: 5| Step: 3
Training loss: 1.2438968420028687
Validation loss: 1.8257266116398636

Epoch: 5| Step: 4
Training loss: 0.6866552233695984
Validation loss: 1.8583598380447717

Epoch: 5| Step: 5
Training loss: 0.9149689674377441
Validation loss: 1.8500337741708244

Epoch: 5| Step: 6
Training loss: 0.8698476552963257
Validation loss: 1.9250900309572938

Epoch: 5| Step: 7
Training loss: 0.964145839214325
Validation loss: 1.8803258211381975

Epoch: 5| Step: 8
Training loss: 0.7519508004188538
Validation loss: 1.8548484797118812

Epoch: 5| Step: 9
Training loss: 0.910997211933136
Validation loss: 1.8525325700800905

Epoch: 5| Step: 10
Training loss: 0.5422597527503967
Validation loss: 1.8535140970701813

Epoch: 471| Step: 0
Training loss: 1.0840932130813599
Validation loss: 1.8270125453190138

Epoch: 5| Step: 1
Training loss: 0.7330277562141418
Validation loss: 1.82972704210589

Epoch: 5| Step: 2
Training loss: 0.7999476194381714
Validation loss: 1.813306591844046

Epoch: 5| Step: 3
Training loss: 1.0457571744918823
Validation loss: 1.8663278907857916

Epoch: 5| Step: 4
Training loss: 0.7684191465377808
Validation loss: 1.8502267124832317

Epoch: 5| Step: 5
Training loss: 1.2400007247924805
Validation loss: 1.8124224421798543

Epoch: 5| Step: 6
Training loss: 0.8212947845458984
Validation loss: 1.8250892931415188

Epoch: 5| Step: 7
Training loss: 0.7777811288833618
Validation loss: 1.846112432018403

Epoch: 5| Step: 8
Training loss: 0.9655343890190125
Validation loss: 1.8714276359927269

Epoch: 5| Step: 9
Training loss: 1.0875277519226074
Validation loss: 1.8616329892989127

Epoch: 5| Step: 10
Training loss: 0.7209301590919495
Validation loss: 1.8556579133515716

Epoch: 472| Step: 0
Training loss: 1.6892592906951904
Validation loss: 1.8580543905176141

Epoch: 5| Step: 1
Training loss: 1.156645655632019
Validation loss: 1.8359375346091487

Epoch: 5| Step: 2
Training loss: 0.49295035004615784
Validation loss: 1.8573626318285543

Epoch: 5| Step: 3
Training loss: 1.0610036849975586
Validation loss: 1.8552483025417532

Epoch: 5| Step: 4
Training loss: 0.874333381652832
Validation loss: 1.8940196344929356

Epoch: 5| Step: 5
Training loss: 0.5167830586433411
Validation loss: 1.8940336640163133

Epoch: 5| Step: 6
Training loss: 0.5289445519447327
Validation loss: 1.871748674300409

Epoch: 5| Step: 7
Training loss: 0.8494080305099487
Validation loss: 1.861605139188869

Epoch: 5| Step: 8
Training loss: 0.9433778524398804
Validation loss: 1.91360850872532

Epoch: 5| Step: 9
Training loss: 1.0649497509002686
Validation loss: 1.929319691914384

Epoch: 5| Step: 10
Training loss: 1.0356817245483398
Validation loss: 1.9080002141255203

Epoch: 473| Step: 0
Training loss: 0.9254620671272278
Validation loss: 1.8842132988796438

Epoch: 5| Step: 1
Training loss: 0.7529771327972412
Validation loss: 1.8660192284532773

Epoch: 5| Step: 2
Training loss: 1.1773674488067627
Validation loss: 1.8807419910225818

Epoch: 5| Step: 3
Training loss: 1.0683561563491821
Validation loss: 1.8951104046196066

Epoch: 5| Step: 4
Training loss: 0.7812567949295044
Validation loss: 1.8881879532209007

Epoch: 5| Step: 5
Training loss: 1.2356258630752563
Validation loss: 1.8716127513557352

Epoch: 5| Step: 6
Training loss: 0.9002159833908081
Validation loss: 1.8211353722439017

Epoch: 5| Step: 7
Training loss: 1.0104992389678955
Validation loss: 1.8160037763657109

Epoch: 5| Step: 8
Training loss: 0.4612051546573639
Validation loss: 1.7816337782849547

Epoch: 5| Step: 9
Training loss: 0.9005735516548157
Validation loss: 1.7911371005478727

Epoch: 5| Step: 10
Training loss: 0.6418805122375488
Validation loss: 1.8163359588192356

Epoch: 474| Step: 0
Training loss: 0.7736670970916748
Validation loss: 1.8705861786360383

Epoch: 5| Step: 1
Training loss: 0.8978228569030762
Validation loss: 1.8214666202504148

Epoch: 5| Step: 2
Training loss: 1.12469482421875
Validation loss: 1.8897570615173669

Epoch: 5| Step: 3
Training loss: 1.2658164501190186
Validation loss: 1.86255128922001

Epoch: 5| Step: 4
Training loss: 0.4621981084346771
Validation loss: 1.897135220548158

Epoch: 5| Step: 5
Training loss: 0.930404782295227
Validation loss: 1.9184598153637302

Epoch: 5| Step: 6
Training loss: 1.0718799829483032
Validation loss: 1.8618380459406043

Epoch: 5| Step: 7
Training loss: 0.7775320410728455
Validation loss: 1.888669393395865

Epoch: 5| Step: 8
Training loss: 0.9001106023788452
Validation loss: 1.8338341405314784

Epoch: 5| Step: 9
Training loss: 0.8716467022895813
Validation loss: 1.866118751546388

Epoch: 5| Step: 10
Training loss: 0.8063715696334839
Validation loss: 1.8253099597910398

Epoch: 475| Step: 0
Training loss: 0.6793067455291748
Validation loss: 1.825137645967545

Epoch: 5| Step: 1
Training loss: 1.3440202474594116
Validation loss: 1.8424568227542344

Epoch: 5| Step: 2
Training loss: 1.0754600763320923
Validation loss: 1.8259373006000315

Epoch: 5| Step: 3
Training loss: 0.5802629590034485
Validation loss: 1.8258492010895924

Epoch: 5| Step: 4
Training loss: 1.0984567403793335
Validation loss: 1.8267991709452804

Epoch: 5| Step: 5
Training loss: 0.7284947037696838
Validation loss: 1.8133176065260364

Epoch: 5| Step: 6
Training loss: 1.1206449270248413
Validation loss: 1.8305180329148487

Epoch: 5| Step: 7
Training loss: 0.8694154620170593
Validation loss: 1.8596831675498717

Epoch: 5| Step: 8
Training loss: 0.6349002122879028
Validation loss: 1.8707045662787654

Epoch: 5| Step: 9
Training loss: 1.2084624767303467
Validation loss: 1.8697684529007121

Epoch: 5| Step: 10
Training loss: 0.5125296115875244
Validation loss: 1.8751861177464968

Epoch: 476| Step: 0
Training loss: 0.46490421891212463
Validation loss: 1.8593919290009366

Epoch: 5| Step: 1
Training loss: 0.47196322679519653
Validation loss: 1.880165656407674

Epoch: 5| Step: 2
Training loss: 0.788167417049408
Validation loss: 1.9348201187708045

Epoch: 5| Step: 3
Training loss: 0.9659020304679871
Validation loss: 1.8780167935996928

Epoch: 5| Step: 4
Training loss: 1.5512306690216064
Validation loss: 1.862282947827411

Epoch: 5| Step: 5
Training loss: 0.7906181216239929
Validation loss: 1.8802073694044543

Epoch: 5| Step: 6
Training loss: 0.9727279543876648
Validation loss: 1.8286993785571026

Epoch: 5| Step: 7
Training loss: 0.9961286783218384
Validation loss: 1.8434693787687568

Epoch: 5| Step: 8
Training loss: 1.0788037776947021
Validation loss: 1.8368428842995757

Epoch: 5| Step: 9
Training loss: 0.7617722153663635
Validation loss: 1.8281747295010475

Epoch: 5| Step: 10
Training loss: 0.8260152339935303
Validation loss: 1.8378495772679646

Epoch: 477| Step: 0
Training loss: 0.6371933221817017
Validation loss: 1.8509497386153027

Epoch: 5| Step: 1
Training loss: 0.5121933221817017
Validation loss: 1.8911919363083378

Epoch: 5| Step: 2
Training loss: 0.8357208371162415
Validation loss: 1.9226622632754746

Epoch: 5| Step: 3
Training loss: 0.5610675811767578
Validation loss: 1.9165897689839846

Epoch: 5| Step: 4
Training loss: 1.0799362659454346
Validation loss: 1.8663949633157382

Epoch: 5| Step: 5
Training loss: 1.095533013343811
Validation loss: 1.869860577326949

Epoch: 5| Step: 6
Training loss: 1.2030750513076782
Validation loss: 1.8277891425676243

Epoch: 5| Step: 7
Training loss: 1.2133146524429321
Validation loss: 1.82163740229863

Epoch: 5| Step: 8
Training loss: 0.5466083288192749
Validation loss: 1.8420167123117754

Epoch: 5| Step: 9
Training loss: 0.911143958568573
Validation loss: 1.8210201801792267

Epoch: 5| Step: 10
Training loss: 1.432586669921875
Validation loss: 1.8350294777142104

Epoch: 478| Step: 0
Training loss: 0.9008744955062866
Validation loss: 1.8604690669685282

Epoch: 5| Step: 1
Training loss: 0.8808937072753906
Validation loss: 1.9053493135718889

Epoch: 5| Step: 2
Training loss: 0.8757381439208984
Validation loss: 1.8902389516112625

Epoch: 5| Step: 3
Training loss: 0.7827522158622742
Validation loss: 1.8695135372941212

Epoch: 5| Step: 4
Training loss: 0.8037201166152954
Validation loss: 1.8611126561318674

Epoch: 5| Step: 5
Training loss: 0.5112558007240295
Validation loss: 1.8597655091234433

Epoch: 5| Step: 6
Training loss: 1.1128208637237549
Validation loss: 1.881395374574969

Epoch: 5| Step: 7
Training loss: 0.9802244305610657
Validation loss: 1.8903835306885421

Epoch: 5| Step: 8
Training loss: 1.0698186159133911
Validation loss: 1.8560533472286758

Epoch: 5| Step: 9
Training loss: 0.7895103693008423
Validation loss: 1.8007823741564186

Epoch: 5| Step: 10
Training loss: 1.1236774921417236
Validation loss: 1.8346674262836415

Epoch: 479| Step: 0
Training loss: 1.2109429836273193
Validation loss: 1.8455302484573857

Epoch: 5| Step: 1
Training loss: 1.1783512830734253
Validation loss: 1.8269430104122366

Epoch: 5| Step: 2
Training loss: 0.9503742456436157
Validation loss: 1.8442861021205943

Epoch: 5| Step: 3
Training loss: 0.5977739095687866
Validation loss: 1.84496731399208

Epoch: 5| Step: 4
Training loss: 0.8078042268753052
Validation loss: 1.828710763685165

Epoch: 5| Step: 5
Training loss: 0.9064508676528931
Validation loss: 1.8337207917244203

Epoch: 5| Step: 6
Training loss: 0.9532066583633423
Validation loss: 1.8174888344221218

Epoch: 5| Step: 7
Training loss: 0.6256438493728638
Validation loss: 1.8290385225767731

Epoch: 5| Step: 8
Training loss: 0.8319446444511414
Validation loss: 1.864777103547127

Epoch: 5| Step: 9
Training loss: 0.6192522048950195
Validation loss: 1.8512327953051495

Epoch: 5| Step: 10
Training loss: 0.8207915425300598
Validation loss: 1.87700871370172

Epoch: 480| Step: 0
Training loss: 0.8591662645339966
Validation loss: 1.9222957139374108

Epoch: 5| Step: 1
Training loss: 0.9728294610977173
Validation loss: 1.903881501126033

Epoch: 5| Step: 2
Training loss: 0.721680760383606
Validation loss: 1.9451856305522304

Epoch: 5| Step: 3
Training loss: 0.535905122756958
Validation loss: 1.915860322213942

Epoch: 5| Step: 4
Training loss: 1.065712332725525
Validation loss: 1.8906077082439134

Epoch: 5| Step: 5
Training loss: 1.2049968242645264
Validation loss: 1.8814735694598126

Epoch: 5| Step: 6
Training loss: 0.9471594095230103
Validation loss: 1.8442736261634416

Epoch: 5| Step: 7
Training loss: 1.1952369213104248
Validation loss: 1.8220076791701778

Epoch: 5| Step: 8
Training loss: 0.5917676091194153
Validation loss: 1.8133693510486233

Epoch: 5| Step: 9
Training loss: 0.8594264984130859
Validation loss: 1.8387341217328144

Epoch: 5| Step: 10
Training loss: 0.7465825080871582
Validation loss: 1.8235756710011473

Epoch: 481| Step: 0
Training loss: 0.6161479949951172
Validation loss: 1.802256562376535

Epoch: 5| Step: 1
Training loss: 0.6578687429428101
Validation loss: 1.8348111824322773

Epoch: 5| Step: 2
Training loss: 0.6239627599716187
Validation loss: 1.8651841866072787

Epoch: 5| Step: 3
Training loss: 1.1303527355194092
Validation loss: 1.867434819539388

Epoch: 5| Step: 4
Training loss: 0.8594647645950317
Validation loss: 1.9072401010861961

Epoch: 5| Step: 5
Training loss: 1.1480482816696167
Validation loss: 1.9160563112587057

Epoch: 5| Step: 6
Training loss: 0.9091314077377319
Validation loss: 1.9084159110182075

Epoch: 5| Step: 7
Training loss: 0.9598695039749146
Validation loss: 1.8628810580058763

Epoch: 5| Step: 8
Training loss: 0.9129962921142578
Validation loss: 1.8629344330039075

Epoch: 5| Step: 9
Training loss: 1.3264083862304688
Validation loss: 1.8705531012627385

Epoch: 5| Step: 10
Training loss: 0.25396814942359924
Validation loss: 1.837911190525178

Epoch: 482| Step: 0
Training loss: 1.0083787441253662
Validation loss: 1.7971400919780935

Epoch: 5| Step: 1
Training loss: 0.9159269332885742
Validation loss: 1.8350554486756683

Epoch: 5| Step: 2
Training loss: 0.6861406564712524
Validation loss: 1.841993406254758

Epoch: 5| Step: 3
Training loss: 0.556139349937439
Validation loss: 1.8549364305311633

Epoch: 5| Step: 4
Training loss: 0.8012177348136902
Validation loss: 1.8762126776479906

Epoch: 5| Step: 5
Training loss: 0.7786659598350525
Validation loss: 1.9003458112798712

Epoch: 5| Step: 6
Training loss: 1.0466411113739014
Validation loss: 1.9428093779471614

Epoch: 5| Step: 7
Training loss: 1.2739970684051514
Validation loss: 1.9259065620360836

Epoch: 5| Step: 8
Training loss: 0.8205817341804504
Validation loss: 1.9145040717176212

Epoch: 5| Step: 9
Training loss: 0.9274500608444214
Validation loss: 1.890266062110983

Epoch: 5| Step: 10
Training loss: 0.8610966205596924
Validation loss: 1.9059512487021826

Epoch: 483| Step: 0
Training loss: 0.7046517729759216
Validation loss: 1.9184236039397538

Epoch: 5| Step: 1
Training loss: 0.8394119143486023
Validation loss: 1.890842935090424

Epoch: 5| Step: 2
Training loss: 1.0217640399932861
Validation loss: 1.8851118446678243

Epoch: 5| Step: 3
Training loss: 0.8168967962265015
Validation loss: 1.8779933683333858

Epoch: 5| Step: 4
Training loss: 1.1048846244812012
Validation loss: 1.8446965345772364

Epoch: 5| Step: 5
Training loss: 0.831137478351593
Validation loss: 1.825190019863908

Epoch: 5| Step: 6
Training loss: 1.00518798828125
Validation loss: 1.7957730665001819

Epoch: 5| Step: 7
Training loss: 0.8025957345962524
Validation loss: 1.827223244533744

Epoch: 5| Step: 8
Training loss: 1.1949694156646729
Validation loss: 1.8395474841517787

Epoch: 5| Step: 9
Training loss: 0.5012460947036743
Validation loss: 1.8145007843612342

Epoch: 5| Step: 10
Training loss: 0.6937663555145264
Validation loss: 1.8473267978237522

Epoch: 484| Step: 0
Training loss: 0.7846394777297974
Validation loss: 1.8721805323836624

Epoch: 5| Step: 1
Training loss: 1.191396713256836
Validation loss: 1.8740080056651947

Epoch: 5| Step: 2
Training loss: 0.8301542401313782
Validation loss: 1.8676614556261288

Epoch: 5| Step: 3
Training loss: 0.6807525753974915
Validation loss: 1.9195137459744689

Epoch: 5| Step: 4
Training loss: 1.0581433773040771
Validation loss: 1.8868571763397546

Epoch: 5| Step: 5
Training loss: 0.9224811792373657
Validation loss: 1.9028266565774077

Epoch: 5| Step: 6
Training loss: 0.5125161409378052
Validation loss: 1.8999638301070019

Epoch: 5| Step: 7
Training loss: 0.8011816143989563
Validation loss: 1.8950476146513415

Epoch: 5| Step: 8
Training loss: 1.2396416664123535
Validation loss: 1.853007520398786

Epoch: 5| Step: 9
Training loss: 0.6840097308158875
Validation loss: 1.8446680948298464

Epoch: 5| Step: 10
Training loss: 0.7090941071510315
Validation loss: 1.8541816075642903

Epoch: 485| Step: 0
Training loss: 0.5599247217178345
Validation loss: 1.8302769250767206

Epoch: 5| Step: 1
Training loss: 0.6717808842658997
Validation loss: 1.848537330986351

Epoch: 5| Step: 2
Training loss: 0.7649646997451782
Validation loss: 1.8597064607886857

Epoch: 5| Step: 3
Training loss: 0.7042566537857056
Validation loss: 1.8644154969082083

Epoch: 5| Step: 4
Training loss: 0.7254843711853027
Validation loss: 1.8559580220971057

Epoch: 5| Step: 5
Training loss: 0.9704684019088745
Validation loss: 1.8303555685986754

Epoch: 5| Step: 6
Training loss: 0.9077439308166504
Validation loss: 1.8862738609313965

Epoch: 5| Step: 7
Training loss: 1.2965666055679321
Validation loss: 1.8464105539424445

Epoch: 5| Step: 8
Training loss: 0.7689271569252014
Validation loss: 1.843901656007254

Epoch: 5| Step: 9
Training loss: 0.9892621040344238
Validation loss: 1.8259526478346957

Epoch: 5| Step: 10
Training loss: 1.0726423263549805
Validation loss: 1.7885027175308557

Epoch: 486| Step: 0
Training loss: 0.9478970766067505
Validation loss: 1.805878100856658

Epoch: 5| Step: 1
Training loss: 1.326676607131958
Validation loss: 1.8100185125104842

Epoch: 5| Step: 2
Training loss: 1.169865369796753
Validation loss: 1.8461243375655143

Epoch: 5| Step: 3
Training loss: 0.5622738599777222
Validation loss: 1.847570643630079

Epoch: 5| Step: 4
Training loss: 0.5422515869140625
Validation loss: 1.8513856549416818

Epoch: 5| Step: 5
Training loss: 0.8246709704399109
Validation loss: 1.8752492627789896

Epoch: 5| Step: 6
Training loss: 0.7062854170799255
Validation loss: 1.9303799393356487

Epoch: 5| Step: 7
Training loss: 0.9305269122123718
Validation loss: 1.9264075294617684

Epoch: 5| Step: 8
Training loss: 0.7425333261489868
Validation loss: 1.9412503857766428

Epoch: 5| Step: 9
Training loss: 0.6949163675308228
Validation loss: 1.9273468217542093

Epoch: 5| Step: 10
Training loss: 1.0050885677337646
Validation loss: 1.9239293157413442

Epoch: 487| Step: 0
Training loss: 0.9014021158218384
Validation loss: 1.8935603544276247

Epoch: 5| Step: 1
Training loss: 0.6635621190071106
Validation loss: 1.8806032890914588

Epoch: 5| Step: 2
Training loss: 1.0422083139419556
Validation loss: 1.8636829981239893

Epoch: 5| Step: 3
Training loss: 1.0332273244857788
Validation loss: 1.8529912784535398

Epoch: 5| Step: 4
Training loss: 0.7377868294715881
Validation loss: 1.8258211933156496

Epoch: 5| Step: 5
Training loss: 0.9963260889053345
Validation loss: 1.848605558436404

Epoch: 5| Step: 6
Training loss: 0.8874098062515259
Validation loss: 1.8498382965723674

Epoch: 5| Step: 7
Training loss: 0.6959034204483032
Validation loss: 1.8896129772227297

Epoch: 5| Step: 8
Training loss: 0.8682158589363098
Validation loss: 1.8604647959432294

Epoch: 5| Step: 9
Training loss: 0.588642954826355
Validation loss: 1.894944162778957

Epoch: 5| Step: 10
Training loss: 0.9261375665664673
Validation loss: 1.8741567647585304

Epoch: 488| Step: 0
Training loss: 0.8826889991760254
Validation loss: 1.8447140621882614

Epoch: 5| Step: 1
Training loss: 0.9846839904785156
Validation loss: 1.8464757601420085

Epoch: 5| Step: 2
Training loss: 0.5639531016349792
Validation loss: 1.8342496092601488

Epoch: 5| Step: 3
Training loss: 1.1113277673721313
Validation loss: 1.85275109224422

Epoch: 5| Step: 4
Training loss: 0.42817243933677673
Validation loss: 1.8530783255894978

Epoch: 5| Step: 5
Training loss: 1.0292199850082397
Validation loss: 1.8635806486170778

Epoch: 5| Step: 6
Training loss: 0.9004303216934204
Validation loss: 1.8769157522468156

Epoch: 5| Step: 7
Training loss: 0.7222586870193481
Validation loss: 1.8825106825879825

Epoch: 5| Step: 8
Training loss: 1.0623376369476318
Validation loss: 1.8784478441361459

Epoch: 5| Step: 9
Training loss: 0.8670986294746399
Validation loss: 1.9041707810535227

Epoch: 5| Step: 10
Training loss: 0.6471165418624878
Validation loss: 1.887486538579387

Epoch: 489| Step: 0
Training loss: 0.9490382075309753
Validation loss: 1.8887378541372155

Epoch: 5| Step: 1
Training loss: 0.8801323771476746
Validation loss: 1.8613705647889005

Epoch: 5| Step: 2
Training loss: 0.8560665249824524
Validation loss: 1.8363550670685307

Epoch: 5| Step: 3
Training loss: 0.875721275806427
Validation loss: 1.8439866919671335

Epoch: 5| Step: 4
Training loss: 0.537551999092102
Validation loss: 1.8094310286224529

Epoch: 5| Step: 5
Training loss: 1.024425983428955
Validation loss: 1.779118960903537

Epoch: 5| Step: 6
Training loss: 0.9789937734603882
Validation loss: 1.7808138965278544

Epoch: 5| Step: 7
Training loss: 0.98650723695755
Validation loss: 1.7486850497543172

Epoch: 5| Step: 8
Training loss: 0.4729131758213043
Validation loss: 1.706349390809254

Epoch: 5| Step: 9
Training loss: 0.8922012448310852
Validation loss: 1.7629072255985712

Epoch: 5| Step: 10
Training loss: 1.1223372220993042
Validation loss: 1.7687517866011588

Epoch: 490| Step: 0
Training loss: 0.5606591701507568
Validation loss: 1.8053616426324333

Epoch: 5| Step: 1
Training loss: 1.073729157447815
Validation loss: 1.8214968417280464

Epoch: 5| Step: 2
Training loss: 0.9512723684310913
Validation loss: 1.88112396834999

Epoch: 5| Step: 3
Training loss: 0.8017604947090149
Validation loss: 1.8871504606739167

Epoch: 5| Step: 4
Training loss: 0.6613486409187317
Validation loss: 1.8634631608122139

Epoch: 5| Step: 5
Training loss: 0.5892581939697266
Validation loss: 1.8366792432723507

Epoch: 5| Step: 6
Training loss: 1.16109037399292
Validation loss: 1.8037087378963348

Epoch: 5| Step: 7
Training loss: 0.6237963438034058
Validation loss: 1.8008646881708534

Epoch: 5| Step: 8
Training loss: 0.7577806711196899
Validation loss: 1.7972694789209673

Epoch: 5| Step: 9
Training loss: 1.2846581935882568
Validation loss: 1.8167224173904748

Epoch: 5| Step: 10
Training loss: 0.8814806938171387
Validation loss: 1.831423387732557

Epoch: 491| Step: 0
Training loss: 0.8495467305183411
Validation loss: 1.8464218724158503

Epoch: 5| Step: 1
Training loss: 0.7085782289505005
Validation loss: 1.866305378175551

Epoch: 5| Step: 2
Training loss: 0.7209600210189819
Validation loss: 1.8851937350406442

Epoch: 5| Step: 3
Training loss: 0.6269166469573975
Validation loss: 1.8630556957696074

Epoch: 5| Step: 4
Training loss: 0.6899464726448059
Validation loss: 1.837845674125097

Epoch: 5| Step: 5
Training loss: 1.0877363681793213
Validation loss: 1.83320144684084

Epoch: 5| Step: 6
Training loss: 1.0189049243927002
Validation loss: 1.8079708263438234

Epoch: 5| Step: 7
Training loss: 0.9519003629684448
Validation loss: 1.824367054047123

Epoch: 5| Step: 8
Training loss: 0.7229007482528687
Validation loss: 1.818329184286056

Epoch: 5| Step: 9
Training loss: 0.641480565071106
Validation loss: 1.8280314168622416

Epoch: 5| Step: 10
Training loss: 1.3346930742263794
Validation loss: 1.8363390622600433

Epoch: 492| Step: 0
Training loss: 0.681677520275116
Validation loss: 1.8527580204830374

Epoch: 5| Step: 1
Training loss: 0.769051730632782
Validation loss: 1.8233305062017133

Epoch: 5| Step: 2
Training loss: 1.0222954750061035
Validation loss: 1.8342852566831855

Epoch: 5| Step: 3
Training loss: 0.6982661485671997
Validation loss: 1.8023822358859483

Epoch: 5| Step: 4
Training loss: 0.8632229566574097
Validation loss: 1.81370258972209

Epoch: 5| Step: 5
Training loss: 0.975176990032196
Validation loss: 1.8161821878084572

Epoch: 5| Step: 6
Training loss: 0.8420401811599731
Validation loss: 1.786565080765755

Epoch: 5| Step: 7
Training loss: 0.5536938309669495
Validation loss: 1.8256797521345076

Epoch: 5| Step: 8
Training loss: 0.7465589642524719
Validation loss: 1.8324156153586604

Epoch: 5| Step: 9
Training loss: 1.0538018941879272
Validation loss: 1.8355412444760721

Epoch: 5| Step: 10
Training loss: 1.0014066696166992
Validation loss: 1.896857984604374

Epoch: 493| Step: 0
Training loss: 0.992414653301239
Validation loss: 1.9189390584986696

Epoch: 5| Step: 1
Training loss: 1.14509117603302
Validation loss: 1.9298798730296474

Epoch: 5| Step: 2
Training loss: 0.8494508862495422
Validation loss: 1.901726520189675

Epoch: 5| Step: 3
Training loss: 0.5382044315338135
Validation loss: 1.888595490045445

Epoch: 5| Step: 4
Training loss: 0.6467121839523315
Validation loss: 1.8593537346009286

Epoch: 5| Step: 5
Training loss: 0.9908292889595032
Validation loss: 1.8541790298236314

Epoch: 5| Step: 6
Training loss: 1.0816867351531982
Validation loss: 1.8376109010429793

Epoch: 5| Step: 7
Training loss: 0.8330721855163574
Validation loss: 1.7862739050260155

Epoch: 5| Step: 8
Training loss: 0.6004399061203003
Validation loss: 1.790643169033912

Epoch: 5| Step: 9
Training loss: 1.0095679759979248
Validation loss: 1.792906415077948

Epoch: 5| Step: 10
Training loss: 0.8463659882545471
Validation loss: 1.779397823477304

Epoch: 494| Step: 0
Training loss: 1.07241952419281
Validation loss: 1.8257883389790852

Epoch: 5| Step: 1
Training loss: 1.0553264617919922
Validation loss: 1.8754111079759495

Epoch: 5| Step: 2
Training loss: 1.2197052240371704
Validation loss: 1.9086556050085253

Epoch: 5| Step: 3
Training loss: 0.7890290021896362
Validation loss: 1.9445307613700948

Epoch: 5| Step: 4
Training loss: 0.379396915435791
Validation loss: 1.9455776368418047

Epoch: 5| Step: 5
Training loss: 0.7149079442024231
Validation loss: 1.9246534262934039

Epoch: 5| Step: 6
Training loss: 0.5719244480133057
Validation loss: 1.9040305294016355

Epoch: 5| Step: 7
Training loss: 0.8120654225349426
Validation loss: 1.8588142664201799

Epoch: 5| Step: 8
Training loss: 0.9168903231620789
Validation loss: 1.773256601825837

Epoch: 5| Step: 9
Training loss: 1.1110942363739014
Validation loss: 1.7607741676351076

Epoch: 5| Step: 10
Training loss: 0.6380888223648071
Validation loss: 1.7327019168484596

Epoch: 495| Step: 0
Training loss: 1.0379011631011963
Validation loss: 1.7532907275743381

Epoch: 5| Step: 1
Training loss: 1.2631337642669678
Validation loss: 1.7604568081517373

Epoch: 5| Step: 2
Training loss: 1.0986272096633911
Validation loss: 1.7751065620812037

Epoch: 5| Step: 3
Training loss: 0.7728362083435059
Validation loss: 1.7702526610384706

Epoch: 5| Step: 4
Training loss: 0.26567766070365906
Validation loss: 1.8298034309059061

Epoch: 5| Step: 5
Training loss: 1.0766804218292236
Validation loss: 1.9028535478858537

Epoch: 5| Step: 6
Training loss: 0.7333821058273315
Validation loss: 1.9292671577904814

Epoch: 5| Step: 7
Training loss: 0.8279428482055664
Validation loss: 1.953504882833009

Epoch: 5| Step: 8
Training loss: 0.9061163067817688
Validation loss: 1.9492387489605976

Epoch: 5| Step: 9
Training loss: 1.0114047527313232
Validation loss: 1.950072201349402

Epoch: 5| Step: 10
Training loss: 0.5503743290901184
Validation loss: 1.898597013565802

Epoch: 496| Step: 0
Training loss: 0.3351011872291565
Validation loss: 1.88161027303306

Epoch: 5| Step: 1
Training loss: 1.1297680139541626
Validation loss: 1.8495726752024826

Epoch: 5| Step: 2
Training loss: 1.0858359336853027
Validation loss: 1.7806847121125908

Epoch: 5| Step: 3
Training loss: 0.8037561178207397
Validation loss: 1.80976406733195

Epoch: 5| Step: 4
Training loss: 0.8057463765144348
Validation loss: 1.7955501028286514

Epoch: 5| Step: 5
Training loss: 0.7158576250076294
Validation loss: 1.8399383150121218

Epoch: 5| Step: 6
Training loss: 0.9625577926635742
Validation loss: 1.8755540309413787

Epoch: 5| Step: 7
Training loss: 0.8239738345146179
Validation loss: 1.9036673909874373

Epoch: 5| Step: 8
Training loss: 0.4596368670463562
Validation loss: 1.890950043996175

Epoch: 5| Step: 9
Training loss: 1.262096881866455
Validation loss: 1.9076652808855938

Epoch: 5| Step: 10
Training loss: 0.899229884147644
Validation loss: 1.8963969253724622

Epoch: 497| Step: 0
Training loss: 1.0837507247924805
Validation loss: 1.8580303653593986

Epoch: 5| Step: 1
Training loss: 1.0583772659301758
Validation loss: 1.817644142335461

Epoch: 5| Step: 2
Training loss: 0.6027282476425171
Validation loss: 1.8281837086523733

Epoch: 5| Step: 3
Training loss: 0.7838397026062012
Validation loss: 1.8283134301503499

Epoch: 5| Step: 4
Training loss: 0.727373480796814
Validation loss: 1.8174753560814807

Epoch: 5| Step: 5
Training loss: 0.7542117834091187
Validation loss: 1.836018612307887

Epoch: 5| Step: 6
Training loss: 0.7154610753059387
Validation loss: 1.8696471439894808

Epoch: 5| Step: 7
Training loss: 0.4651253819465637
Validation loss: 1.8450755098814606

Epoch: 5| Step: 8
Training loss: 1.1383559703826904
Validation loss: 1.9025448060804797

Epoch: 5| Step: 9
Training loss: 0.8895857930183411
Validation loss: 1.9365295312737907

Epoch: 5| Step: 10
Training loss: 0.9803640842437744
Validation loss: 1.9322845935821533

Epoch: 498| Step: 0
Training loss: 1.2413948774337769
Validation loss: 1.9211810070981261

Epoch: 5| Step: 1
Training loss: 0.7239485383033752
Validation loss: 1.8432561223224928

Epoch: 5| Step: 2
Training loss: 0.5094038844108582
Validation loss: 1.811752898718721

Epoch: 5| Step: 3
Training loss: 0.5675454139709473
Validation loss: 1.8154840597542383

Epoch: 5| Step: 4
Training loss: 0.9391075372695923
Validation loss: 1.8226215095930203

Epoch: 5| Step: 5
Training loss: 0.6416476964950562
Validation loss: 1.7884452958260812

Epoch: 5| Step: 6
Training loss: 0.6031185388565063
Validation loss: 1.8157437142505441

Epoch: 5| Step: 7
Training loss: 1.087717056274414
Validation loss: 1.846727886507588

Epoch: 5| Step: 8
Training loss: 0.9650731086730957
Validation loss: 1.8575124779055197

Epoch: 5| Step: 9
Training loss: 0.8078150749206543
Validation loss: 1.8678911975634995

Epoch: 5| Step: 10
Training loss: 1.076598882675171
Validation loss: 1.9065165596623574

Epoch: 499| Step: 0
Training loss: 0.8052569627761841
Validation loss: 1.8686926916081419

Epoch: 5| Step: 1
Training loss: 0.7521805763244629
Validation loss: 1.8845346179059757

Epoch: 5| Step: 2
Training loss: 0.7130845785140991
Validation loss: 1.8420058399118402

Epoch: 5| Step: 3
Training loss: 0.7683829665184021
Validation loss: 1.779823346804547

Epoch: 5| Step: 4
Training loss: 0.46910232305526733
Validation loss: 1.7834621244861233

Epoch: 5| Step: 5
Training loss: 1.0458062887191772
Validation loss: 1.746621597197748

Epoch: 5| Step: 6
Training loss: 0.6623729467391968
Validation loss: 1.7683205617371427

Epoch: 5| Step: 7
Training loss: 0.9327667355537415
Validation loss: 1.78456865074814

Epoch: 5| Step: 8
Training loss: 1.0972915887832642
Validation loss: 1.8031074846944501

Epoch: 5| Step: 9
Training loss: 1.0393701791763306
Validation loss: 1.84772067428917

Epoch: 5| Step: 10
Training loss: 0.7900344729423523
Validation loss: 1.889855118208034

Epoch: 500| Step: 0
Training loss: 0.9298480153083801
Validation loss: 1.9238035037953367

Epoch: 5| Step: 1
Training loss: 0.6570233702659607
Validation loss: 1.969911580444664

Epoch: 5| Step: 2
Training loss: 0.6513901948928833
Validation loss: 1.9432337207178916

Epoch: 5| Step: 3
Training loss: 0.7027251124382019
Validation loss: 1.874008555566111

Epoch: 5| Step: 4
Training loss: 0.984214186668396
Validation loss: 1.8568085393598002

Epoch: 5| Step: 5
Training loss: 1.299423098564148
Validation loss: 1.8207275521370672

Epoch: 5| Step: 6
Training loss: 0.931541919708252
Validation loss: 1.8110277037466727

Epoch: 5| Step: 7
Training loss: 1.0014203786849976
Validation loss: 1.7861866976625176

Epoch: 5| Step: 8
Training loss: 0.7014726400375366
Validation loss: 1.7547618894166843

Epoch: 5| Step: 9
Training loss: 0.7846862077713013
Validation loss: 1.75354520223474

Epoch: 5| Step: 10
Training loss: 0.6582751274108887
Validation loss: 1.8020503572238389

Testing loss: 1.9249413940641615
