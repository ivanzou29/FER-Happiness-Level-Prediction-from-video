Epoch: 1| Step: 0
Training loss: 4.108028411865234
Validation loss: 5.183232979107928

Epoch: 6| Step: 1
Training loss: 4.567895889282227
Validation loss: 5.174262451869185

Epoch: 6| Step: 2
Training loss: 4.990695953369141
Validation loss: 5.165350488437119

Epoch: 6| Step: 3
Training loss: 5.098814010620117
Validation loss: 5.156366735376338

Epoch: 6| Step: 4
Training loss: 3.870861053466797
Validation loss: 5.147562857597105

Epoch: 6| Step: 5
Training loss: 6.384389877319336
Validation loss: 5.138297583467217

Epoch: 6| Step: 6
Training loss: 5.014368534088135
Validation loss: 5.128236534774945

Epoch: 6| Step: 7
Training loss: 4.983539581298828
Validation loss: 5.118540420327135

Epoch: 6| Step: 8
Training loss: 4.9439849853515625
Validation loss: 5.107344524834746

Epoch: 6| Step: 9
Training loss: 4.692488670349121
Validation loss: 5.095915527753933

Epoch: 6| Step: 10
Training loss: 6.384937286376953
Validation loss: 5.0840742767498055

Epoch: 6| Step: 11
Training loss: 5.067778587341309
Validation loss: 5.071519354338287

Epoch: 6| Step: 12
Training loss: 5.009782791137695
Validation loss: 5.057710027181974

Epoch: 6| Step: 13
Training loss: 2.7881593704223633
Validation loss: 5.04299598099083

Epoch: 2| Step: 0
Training loss: 4.507593154907227
Validation loss: 5.027482709577007

Epoch: 6| Step: 1
Training loss: 5.965270042419434
Validation loss: 5.011291160378405

Epoch: 6| Step: 2
Training loss: 3.994675874710083
Validation loss: 4.993248175549251

Epoch: 6| Step: 3
Training loss: 4.337174415588379
Validation loss: 4.9738271518420145

Epoch: 6| Step: 4
Training loss: 4.9126973152160645
Validation loss: 4.953920897617135

Epoch: 6| Step: 5
Training loss: 4.724733352661133
Validation loss: 4.932733869039884

Epoch: 6| Step: 6
Training loss: 4.840694427490234
Validation loss: 4.9096997220029115

Epoch: 6| Step: 7
Training loss: 5.026042938232422
Validation loss: 4.8850855365876225

Epoch: 6| Step: 8
Training loss: 4.402390480041504
Validation loss: 4.859550860620314

Epoch: 6| Step: 9
Training loss: 3.656362295150757
Validation loss: 4.831925064004878

Epoch: 6| Step: 10
Training loss: 4.368134021759033
Validation loss: 4.803488828802622

Epoch: 6| Step: 11
Training loss: 5.0853142738342285
Validation loss: 4.772427287153018

Epoch: 6| Step: 12
Training loss: 5.05599308013916
Validation loss: 4.740517636781098

Epoch: 6| Step: 13
Training loss: 4.586263656616211
Validation loss: 4.707557698731781

Epoch: 3| Step: 0
Training loss: 3.4616341590881348
Validation loss: 4.674268025223927

Epoch: 6| Step: 1
Training loss: 4.883604526519775
Validation loss: 4.638465122510028

Epoch: 6| Step: 2
Training loss: 3.3072495460510254
Validation loss: 4.601817243842668

Epoch: 6| Step: 3
Training loss: 4.841513633728027
Validation loss: 4.564029990985829

Epoch: 6| Step: 4
Training loss: 5.5015435218811035
Validation loss: 4.525074671673519

Epoch: 6| Step: 5
Training loss: 5.03037166595459
Validation loss: 4.485427789790656

Epoch: 6| Step: 6
Training loss: 3.832447052001953
Validation loss: 4.445179964906426

Epoch: 6| Step: 7
Training loss: 4.5275983810424805
Validation loss: 4.403703099937849

Epoch: 6| Step: 8
Training loss: 3.6583995819091797
Validation loss: 4.36641723878922

Epoch: 6| Step: 9
Training loss: 4.708038806915283
Validation loss: 4.328885221994051

Epoch: 6| Step: 10
Training loss: 3.671159267425537
Validation loss: 4.2945354830834175

Epoch: 6| Step: 11
Training loss: 4.221807956695557
Validation loss: 4.262057586382794

Epoch: 6| Step: 12
Training loss: 3.963022232055664
Validation loss: 4.231226654462917

Epoch: 6| Step: 13
Training loss: 3.469438076019287
Validation loss: 4.2013435056132655

Epoch: 4| Step: 0
Training loss: 4.870153427124023
Validation loss: 4.174875208126601

Epoch: 6| Step: 1
Training loss: 3.040229320526123
Validation loss: 4.14737779350691

Epoch: 6| Step: 2
Training loss: 3.5831048488616943
Validation loss: 4.122381707673432

Epoch: 6| Step: 3
Training loss: 3.6375844478607178
Validation loss: 4.09741275541244

Epoch: 6| Step: 4
Training loss: 4.421720504760742
Validation loss: 4.074336915887812

Epoch: 6| Step: 5
Training loss: 3.0772738456726074
Validation loss: 4.049920592256772

Epoch: 6| Step: 6
Training loss: 4.107168197631836
Validation loss: 4.027209015302761

Epoch: 6| Step: 7
Training loss: 3.3878731727600098
Validation loss: 4.004339395030852

Epoch: 6| Step: 8
Training loss: 4.166081428527832
Validation loss: 3.9840407115156933

Epoch: 6| Step: 9
Training loss: 4.083019256591797
Validation loss: 3.965605389687323

Epoch: 6| Step: 10
Training loss: 4.930113792419434
Validation loss: 3.9498094948389197

Epoch: 6| Step: 11
Training loss: 3.6553378105163574
Validation loss: 3.930556656211935

Epoch: 6| Step: 12
Training loss: 2.787649154663086
Validation loss: 3.9141881747912337

Epoch: 6| Step: 13
Training loss: 4.6494269371032715
Validation loss: 3.9001169204711914

Epoch: 5| Step: 0
Training loss: 4.074916839599609
Validation loss: 3.887739376355243

Epoch: 6| Step: 1
Training loss: 4.290816307067871
Validation loss: 3.874307337627616

Epoch: 6| Step: 2
Training loss: 5.623071193695068
Validation loss: 3.863092945468041

Epoch: 6| Step: 3
Training loss: 3.393467426300049
Validation loss: 3.8499072187690326

Epoch: 6| Step: 4
Training loss: 3.669882297515869
Validation loss: 3.835782717632991

Epoch: 6| Step: 5
Training loss: 3.6583046913146973
Validation loss: 3.822902951189267

Epoch: 6| Step: 6
Training loss: 2.5497145652770996
Validation loss: 3.811016856983144

Epoch: 6| Step: 7
Training loss: 3.210439682006836
Validation loss: 3.8005337099875174

Epoch: 6| Step: 8
Training loss: 2.884705066680908
Validation loss: 3.7929244169624905

Epoch: 6| Step: 9
Training loss: 2.7991342544555664
Validation loss: 3.7823975393849034

Epoch: 6| Step: 10
Training loss: 3.1730785369873047
Validation loss: 3.774552368348645

Epoch: 6| Step: 11
Training loss: 5.108150482177734
Validation loss: 3.766953432431785

Epoch: 6| Step: 12
Training loss: 3.8460400104522705
Validation loss: 3.7585239666764454

Epoch: 6| Step: 13
Training loss: 3.268040895462036
Validation loss: 3.745955954315842

Epoch: 6| Step: 0
Training loss: 3.2203636169433594
Validation loss: 3.736600716908773

Epoch: 6| Step: 1
Training loss: 2.8679637908935547
Validation loss: 3.7282490781558457

Epoch: 6| Step: 2
Training loss: 4.06019401550293
Validation loss: 3.7183776747795845

Epoch: 6| Step: 3
Training loss: 4.308446407318115
Validation loss: 3.707829244675175

Epoch: 6| Step: 4
Training loss: 4.441569805145264
Validation loss: 3.699010105543239

Epoch: 6| Step: 5
Training loss: 3.9110352993011475
Validation loss: 3.688311822952763

Epoch: 6| Step: 6
Training loss: 3.595996856689453
Validation loss: 3.681278177486953

Epoch: 6| Step: 7
Training loss: 2.92997407913208
Validation loss: 3.669691942071402

Epoch: 6| Step: 8
Training loss: 4.022011756896973
Validation loss: 3.6598052260696248

Epoch: 6| Step: 9
Training loss: 3.6581549644470215
Validation loss: 3.650704035194971

Epoch: 6| Step: 10
Training loss: 3.114523410797119
Validation loss: 3.6422811169778146

Epoch: 6| Step: 11
Training loss: 3.5316357612609863
Validation loss: 3.632736041981687

Epoch: 6| Step: 12
Training loss: 3.256176471710205
Validation loss: 3.6243531755221787

Epoch: 6| Step: 13
Training loss: 2.9312546253204346
Validation loss: 3.615508364092919

Epoch: 7| Step: 0
Training loss: 3.3187947273254395
Validation loss: 3.6078191008619083

Epoch: 6| Step: 1
Training loss: 3.2809648513793945
Validation loss: 3.598390310041366

Epoch: 6| Step: 2
Training loss: 3.406158447265625
Validation loss: 3.592040384969404

Epoch: 6| Step: 3
Training loss: 3.6071338653564453
Validation loss: 3.5872922558938303

Epoch: 6| Step: 4
Training loss: 4.419612407684326
Validation loss: 3.580068447256601

Epoch: 6| Step: 5
Training loss: 3.865006685256958
Validation loss: 3.5684384633136053

Epoch: 6| Step: 6
Training loss: 2.899946451187134
Validation loss: 3.564066912538262

Epoch: 6| Step: 7
Training loss: 4.211095809936523
Validation loss: 3.557356188374181

Epoch: 6| Step: 8
Training loss: 2.530910015106201
Validation loss: 3.5495730266776135

Epoch: 6| Step: 9
Training loss: 2.6370372772216797
Validation loss: 3.540888945261637

Epoch: 6| Step: 10
Training loss: 4.314813137054443
Validation loss: 3.533542989402689

Epoch: 6| Step: 11
Training loss: 3.8734169006347656
Validation loss: 3.5270306858965146

Epoch: 6| Step: 12
Training loss: 3.3038766384124756
Validation loss: 3.518011618685979

Epoch: 6| Step: 13
Training loss: 2.76619029045105
Validation loss: 3.5099067380351405

Epoch: 8| Step: 0
Training loss: 3.7294421195983887
Validation loss: 3.50268159374114

Epoch: 6| Step: 1
Training loss: 2.559471368789673
Validation loss: 3.4950129344899166

Epoch: 6| Step: 2
Training loss: 3.7282464504241943
Validation loss: 3.4875511610379784

Epoch: 6| Step: 3
Training loss: 3.7375545501708984
Validation loss: 3.479670222087573

Epoch: 6| Step: 4
Training loss: 3.786933422088623
Validation loss: 3.469917292236

Epoch: 6| Step: 5
Training loss: 2.696711540222168
Validation loss: 3.459660860799974

Epoch: 6| Step: 6
Training loss: 3.097598075866699
Validation loss: 3.4475239476849957

Epoch: 6| Step: 7
Training loss: 2.9708001613616943
Validation loss: 3.432978694156934

Epoch: 6| Step: 8
Training loss: 4.475088119506836
Validation loss: 3.4223393650465113

Epoch: 6| Step: 9
Training loss: 3.5221009254455566
Validation loss: 3.411185654260779

Epoch: 6| Step: 10
Training loss: 3.697092294692993
Validation loss: 3.4024834658509944

Epoch: 6| Step: 11
Training loss: 3.0358920097351074
Validation loss: 3.394137336361793

Epoch: 6| Step: 12
Training loss: 2.2927422523498535
Validation loss: 3.388518600053685

Epoch: 6| Step: 13
Training loss: 4.62516975402832
Validation loss: 3.3854083937983357

Epoch: 9| Step: 0
Training loss: 3.2261569499969482
Validation loss: 3.3742333791589223

Epoch: 6| Step: 1
Training loss: 2.540196657180786
Validation loss: 3.367591029854231

Epoch: 6| Step: 2
Training loss: 3.537379741668701
Validation loss: 3.362544000789683

Epoch: 6| Step: 3
Training loss: 2.2339799404144287
Validation loss: 3.356128490099343

Epoch: 6| Step: 4
Training loss: 3.4417641162872314
Validation loss: 3.3494998049992386

Epoch: 6| Step: 5
Training loss: 3.100520133972168
Validation loss: 3.3479665146079114

Epoch: 6| Step: 6
Training loss: 3.6382312774658203
Validation loss: 3.337400551765196

Epoch: 6| Step: 7
Training loss: 2.6213529109954834
Validation loss: 3.3304184431670816

Epoch: 6| Step: 8
Training loss: 4.624586582183838
Validation loss: 3.327747168079499

Epoch: 6| Step: 9
Training loss: 4.573977470397949
Validation loss: 3.3244963922808246

Epoch: 6| Step: 10
Training loss: 3.933877944946289
Validation loss: 3.317277149487567

Epoch: 6| Step: 11
Training loss: 2.240891456604004
Validation loss: 3.3154615099712084

Epoch: 6| Step: 12
Training loss: 2.730674982070923
Validation loss: 3.3082750663962415

Epoch: 6| Step: 13
Training loss: 3.9965221881866455
Validation loss: 3.3023653261123167

Epoch: 10| Step: 0
Training loss: 2.8712449073791504
Validation loss: 3.2951392999259372

Epoch: 6| Step: 1
Training loss: 3.2509593963623047
Validation loss: 3.292596673452726

Epoch: 6| Step: 2
Training loss: 3.025662422180176
Validation loss: 3.282555913412443

Epoch: 6| Step: 3
Training loss: 2.945089340209961
Validation loss: 3.2764713379644577

Epoch: 6| Step: 4
Training loss: 4.146580696105957
Validation loss: 3.269859916420393

Epoch: 6| Step: 5
Training loss: 3.0215463638305664
Validation loss: 3.265136529040593

Epoch: 6| Step: 6
Training loss: 2.471031427383423
Validation loss: 3.2605172152160318

Epoch: 6| Step: 7
Training loss: 3.961765766143799
Validation loss: 3.249882439131378

Epoch: 6| Step: 8
Training loss: 3.687818765640259
Validation loss: 3.255382563478203

Epoch: 6| Step: 9
Training loss: 3.3978240489959717
Validation loss: 3.251385563163347

Epoch: 6| Step: 10
Training loss: 2.6863255500793457
Validation loss: 3.2358832948951313

Epoch: 6| Step: 11
Training loss: 3.150946855545044
Validation loss: 3.240114978564683

Epoch: 6| Step: 12
Training loss: 3.090569019317627
Validation loss: 3.2554073897741174

Epoch: 6| Step: 13
Training loss: 4.030822277069092
Validation loss: 3.2400456525946177

Epoch: 11| Step: 0
Training loss: 3.6772308349609375
Validation loss: 3.2264379378288024

Epoch: 6| Step: 1
Training loss: 2.305703639984131
Validation loss: 3.220417812306394

Epoch: 6| Step: 2
Training loss: 3.2657899856567383
Validation loss: 3.224219301695465

Epoch: 6| Step: 3
Training loss: 2.634204149246216
Validation loss: 3.222646321019819

Epoch: 6| Step: 4
Training loss: 2.867966890335083
Validation loss: 3.221904267546951

Epoch: 6| Step: 5
Training loss: 3.9012980461120605
Validation loss: 3.2105458603110364

Epoch: 6| Step: 6
Training loss: 3.689791202545166
Validation loss: 3.2003825223574074

Epoch: 6| Step: 7
Training loss: 3.0516605377197266
Validation loss: 3.1955799543729393

Epoch: 6| Step: 8
Training loss: 3.464125633239746
Validation loss: 3.1930222998383226

Epoch: 6| Step: 9
Training loss: 3.2551870346069336
Validation loss: 3.1946738894267748

Epoch: 6| Step: 10
Training loss: 2.58333683013916
Validation loss: 3.1896294983484412

Epoch: 6| Step: 11
Training loss: 3.0668630599975586
Validation loss: 3.179417779368739

Epoch: 6| Step: 12
Training loss: 3.48972749710083
Validation loss: 3.1753513915564424

Epoch: 6| Step: 13
Training loss: 3.77786922454834
Validation loss: 3.1698522260112147

Epoch: 12| Step: 0
Training loss: 3.1496644020080566
Validation loss: 3.1689079192376908

Epoch: 6| Step: 1
Training loss: 3.298344850540161
Validation loss: 3.1647809500335367

Epoch: 6| Step: 2
Training loss: 3.6528468132019043
Validation loss: 3.159564143867903

Epoch: 6| Step: 3
Training loss: 2.399847984313965
Validation loss: 3.1511854433244273

Epoch: 6| Step: 4
Training loss: 3.381962537765503
Validation loss: 3.1489266913424254

Epoch: 6| Step: 5
Training loss: 2.3604238033294678
Validation loss: 3.145309204696327

Epoch: 6| Step: 6
Training loss: 2.551131248474121
Validation loss: 3.144073050509217

Epoch: 6| Step: 7
Training loss: 3.430619239807129
Validation loss: 3.1400915166383148

Epoch: 6| Step: 8
Training loss: 3.371875524520874
Validation loss: 3.1350418085693033

Epoch: 6| Step: 9
Training loss: 3.5962727069854736
Validation loss: 3.1291290457530687

Epoch: 6| Step: 10
Training loss: 4.0886993408203125
Validation loss: 3.1199085763705674

Epoch: 6| Step: 11
Training loss: 2.9052603244781494
Validation loss: 3.1122325081979074

Epoch: 6| Step: 12
Training loss: 2.963836193084717
Validation loss: 3.1142804545740925

Epoch: 6| Step: 13
Training loss: 2.8792312145233154
Validation loss: 3.1157973248471498

Epoch: 13| Step: 0
Training loss: 2.7955827713012695
Validation loss: 3.114023203490883

Epoch: 6| Step: 1
Training loss: 2.9182443618774414
Validation loss: 3.1131974086966565

Epoch: 6| Step: 2
Training loss: 3.862143039703369
Validation loss: 3.100855222312353

Epoch: 6| Step: 3
Training loss: 1.8858402967453003
Validation loss: 3.097034090308733

Epoch: 6| Step: 4
Training loss: 3.241013288497925
Validation loss: 3.092558712087652

Epoch: 6| Step: 5
Training loss: 2.797131061553955
Validation loss: 3.0900419373666086

Epoch: 6| Step: 6
Training loss: 3.640608787536621
Validation loss: 3.0879329276341263

Epoch: 6| Step: 7
Training loss: 3.771451950073242
Validation loss: 3.099960219475531

Epoch: 6| Step: 8
Training loss: 4.069513320922852
Validation loss: 3.0760299544180594

Epoch: 6| Step: 9
Training loss: 3.1463160514831543
Validation loss: 3.072291453679403

Epoch: 6| Step: 10
Training loss: 2.66741943359375
Validation loss: 3.0706316758227605

Epoch: 6| Step: 11
Training loss: 2.956732988357544
Validation loss: 3.069867577604068

Epoch: 6| Step: 12
Training loss: 2.4310340881347656
Validation loss: 3.0593561485249507

Epoch: 6| Step: 13
Training loss: 3.595747947692871
Validation loss: 3.052533913684148

Epoch: 14| Step: 0
Training loss: 4.2284135818481445
Validation loss: 3.0505898614083566

Epoch: 6| Step: 1
Training loss: 1.9776744842529297
Validation loss: 3.0463731776001635

Epoch: 6| Step: 2
Training loss: 2.9749093055725098
Validation loss: 3.044063127169045

Epoch: 6| Step: 3
Training loss: 2.3461194038391113
Validation loss: 3.0409759936794156

Epoch: 6| Step: 4
Training loss: 2.504636764526367
Validation loss: 3.0341327651854484

Epoch: 6| Step: 5
Training loss: 2.4092888832092285
Validation loss: 3.03107855396886

Epoch: 6| Step: 6
Training loss: 2.702332019805908
Validation loss: 3.0287203276029198

Epoch: 6| Step: 7
Training loss: 3.3622093200683594
Validation loss: 3.0282724288202103

Epoch: 6| Step: 8
Training loss: 3.9172120094299316
Validation loss: 3.028616384793353

Epoch: 6| Step: 9
Training loss: 3.7320556640625
Validation loss: 3.020784698506837

Epoch: 6| Step: 10
Training loss: 3.420246124267578
Validation loss: 3.0152286739759546

Epoch: 6| Step: 11
Training loss: 2.9000210762023926
Validation loss: 3.0076606478742374

Epoch: 6| Step: 12
Training loss: 4.014241695404053
Validation loss: 2.999040570310367

Epoch: 6| Step: 13
Training loss: 2.2102901935577393
Validation loss: 2.995897934000979

Epoch: 15| Step: 0
Training loss: 2.268969774246216
Validation loss: 2.9988171900472333

Epoch: 6| Step: 1
Training loss: 3.202897071838379
Validation loss: 2.997804036704443

Epoch: 6| Step: 2
Training loss: 1.9783567190170288
Validation loss: 2.996888219669301

Epoch: 6| Step: 3
Training loss: 2.890705108642578
Validation loss: 2.9824908779513453

Epoch: 6| Step: 4
Training loss: 3.198319435119629
Validation loss: 2.9781054168619137

Epoch: 6| Step: 5
Training loss: 2.350926399230957
Validation loss: 2.9732739412656395

Epoch: 6| Step: 6
Training loss: 4.022409439086914
Validation loss: 2.9713126510702152

Epoch: 6| Step: 7
Training loss: 2.9701952934265137
Validation loss: 2.9681437656443608

Epoch: 6| Step: 8
Training loss: 2.7571115493774414
Validation loss: 2.9682136838154127

Epoch: 6| Step: 9
Training loss: 3.0954980850219727
Validation loss: 2.9681481853608163

Epoch: 6| Step: 10
Training loss: 3.4217774868011475
Validation loss: 2.9642028090774373

Epoch: 6| Step: 11
Training loss: 3.511241912841797
Validation loss: 2.9584287264013804

Epoch: 6| Step: 12
Training loss: 3.0803282260894775
Validation loss: 2.954309432737289

Epoch: 6| Step: 13
Training loss: 4.36125373840332
Validation loss: 2.949421828792941

Epoch: 16| Step: 0
Training loss: 3.083225727081299
Validation loss: 2.9417983178169496

Epoch: 6| Step: 1
Training loss: 2.8422532081604004
Validation loss: 2.9346011966787358

Epoch: 6| Step: 2
Training loss: 2.7833988666534424
Validation loss: 2.928690254047353

Epoch: 6| Step: 3
Training loss: 3.0118772983551025
Validation loss: 2.919633598737819

Epoch: 6| Step: 4
Training loss: 2.809811592102051
Validation loss: 2.915558612474831

Epoch: 6| Step: 5
Training loss: 2.830937623977661
Validation loss: 2.9149888843618412

Epoch: 6| Step: 6
Training loss: 2.922725200653076
Validation loss: 2.9194071831241732

Epoch: 6| Step: 7
Training loss: 3.0381197929382324
Validation loss: 2.925741869916198

Epoch: 6| Step: 8
Training loss: 2.594780921936035
Validation loss: 2.909695271522768

Epoch: 6| Step: 9
Training loss: 3.0766260623931885
Validation loss: 2.894236910727716

Epoch: 6| Step: 10
Training loss: 3.538994789123535
Validation loss: 2.889669474735055

Epoch: 6| Step: 11
Training loss: 3.654744863510132
Validation loss: 2.8900987255957817

Epoch: 6| Step: 12
Training loss: 2.1992557048797607
Validation loss: 2.8846401963182675

Epoch: 6| Step: 13
Training loss: 4.001764297485352
Validation loss: 2.8827090596639984

Epoch: 17| Step: 0
Training loss: 2.9708938598632812
Validation loss: 2.8770380866143013

Epoch: 6| Step: 1
Training loss: 2.6173617839813232
Validation loss: 2.8753335450285222

Epoch: 6| Step: 2
Training loss: 2.8155064582824707
Validation loss: 2.876866771328834

Epoch: 6| Step: 3
Training loss: 3.633411169052124
Validation loss: 2.87418395216747

Epoch: 6| Step: 4
Training loss: 1.793704867362976
Validation loss: 2.8641791061688493

Epoch: 6| Step: 5
Training loss: 2.8971810340881348
Validation loss: 2.861811143095775

Epoch: 6| Step: 6
Training loss: 2.4328484535217285
Validation loss: 2.8523246062699186

Epoch: 6| Step: 7
Training loss: 3.536095380783081
Validation loss: 2.8519087042859805

Epoch: 6| Step: 8
Training loss: 3.8086256980895996
Validation loss: 2.8447959269246748

Epoch: 6| Step: 9
Training loss: 2.395373582839966
Validation loss: 2.8388146303033315

Epoch: 6| Step: 10
Training loss: 3.5312676429748535
Validation loss: 2.8394824356161137

Epoch: 6| Step: 11
Training loss: 2.923605442047119
Validation loss: 2.8385665749990814

Epoch: 6| Step: 12
Training loss: 3.35709547996521
Validation loss: 2.8351210958214215

Epoch: 6| Step: 13
Training loss: 2.490065813064575
Validation loss: 2.8298056792187434

Epoch: 18| Step: 0
Training loss: 2.8288071155548096
Validation loss: 2.823217684222806

Epoch: 6| Step: 1
Training loss: 3.911017656326294
Validation loss: 2.8207208366804224

Epoch: 6| Step: 2
Training loss: 2.219666004180908
Validation loss: 2.8184334385779595

Epoch: 6| Step: 3
Training loss: 3.380545139312744
Validation loss: 2.8143922949350006

Epoch: 6| Step: 4
Training loss: 3.0710153579711914
Validation loss: 2.8128429510260142

Epoch: 6| Step: 5
Training loss: 2.2505269050598145
Validation loss: 2.813866846023067

Epoch: 6| Step: 6
Training loss: 3.0820186138153076
Validation loss: 2.8063844250094507

Epoch: 6| Step: 7
Training loss: 2.762516498565674
Validation loss: 2.809697215275098

Epoch: 6| Step: 8
Training loss: 3.6990771293640137
Validation loss: 2.8122911145610194

Epoch: 6| Step: 9
Training loss: 3.22567081451416
Validation loss: 2.8008026563993065

Epoch: 6| Step: 10
Training loss: 2.413154363632202
Validation loss: 2.7957247611015075

Epoch: 6| Step: 11
Training loss: 2.6233177185058594
Validation loss: 2.7905883071243123

Epoch: 6| Step: 12
Training loss: 3.1381702423095703
Validation loss: 2.7871057218120945

Epoch: 6| Step: 13
Training loss: 2.0004212856292725
Validation loss: 2.7895861005270355

Epoch: 19| Step: 0
Training loss: 2.7649526596069336
Validation loss: 2.7817680938269502

Epoch: 6| Step: 1
Training loss: 2.90303111076355
Validation loss: 2.7834575201875422

Epoch: 6| Step: 2
Training loss: 2.9891159534454346
Validation loss: 2.788418457072268

Epoch: 6| Step: 3
Training loss: 2.7758548259735107
Validation loss: 2.78849684551198

Epoch: 6| Step: 4
Training loss: 2.5403709411621094
Validation loss: 2.782281803828414

Epoch: 6| Step: 5
Training loss: 3.4781384468078613
Validation loss: 2.776457402013963

Epoch: 6| Step: 6
Training loss: 3.4172098636627197
Validation loss: 2.77551204927506

Epoch: 6| Step: 7
Training loss: 3.1927428245544434
Validation loss: 2.7771637080818095

Epoch: 6| Step: 8
Training loss: 3.1333160400390625
Validation loss: 2.770916856745238

Epoch: 6| Step: 9
Training loss: 2.976639747619629
Validation loss: 2.7680710310577066

Epoch: 6| Step: 10
Training loss: 3.0946264266967773
Validation loss: 2.7640913327534995

Epoch: 6| Step: 11
Training loss: 2.4631190299987793
Validation loss: 2.764340446841332

Epoch: 6| Step: 12
Training loss: 2.271933078765869
Validation loss: 2.757503083957139

Epoch: 6| Step: 13
Training loss: 2.4642179012298584
Validation loss: 2.756108522415161

Epoch: 20| Step: 0
Training loss: 2.5670175552368164
Validation loss: 2.7629447803702405

Epoch: 6| Step: 1
Training loss: 3.643585205078125
Validation loss: 2.758945877834033

Epoch: 6| Step: 2
Training loss: 2.3002545833587646
Validation loss: 2.756191263916672

Epoch: 6| Step: 3
Training loss: 2.5519533157348633
Validation loss: 2.750875452513336

Epoch: 6| Step: 4
Training loss: 2.8139708042144775
Validation loss: 2.7446252120438444

Epoch: 6| Step: 5
Training loss: 3.8393075466156006
Validation loss: 2.74513183101531

Epoch: 6| Step: 6
Training loss: 2.782959222793579
Validation loss: 2.7488682628959737

Epoch: 6| Step: 7
Training loss: 3.1759238243103027
Validation loss: 2.750958670852005

Epoch: 6| Step: 8
Training loss: 2.634639263153076
Validation loss: 2.747180269610497

Epoch: 6| Step: 9
Training loss: 3.032304286956787
Validation loss: 2.7353097725940008

Epoch: 6| Step: 10
Training loss: 2.426659107208252
Validation loss: 2.7259667124799503

Epoch: 6| Step: 11
Training loss: 3.3525631427764893
Validation loss: 2.7587669613540813

Epoch: 6| Step: 12
Training loss: 2.477151393890381
Validation loss: 2.7526362839565484

Epoch: 6| Step: 13
Training loss: 2.8658580780029297
Validation loss: 2.7809212105248564

Epoch: 21| Step: 0
Training loss: 2.6096439361572266
Validation loss: 2.7521312134240263

Epoch: 6| Step: 1
Training loss: 3.1809451580047607
Validation loss: 2.7315242162314792

Epoch: 6| Step: 2
Training loss: 1.9953453540802002
Validation loss: 2.7375450390641407

Epoch: 6| Step: 3
Training loss: 2.517089605331421
Validation loss: 2.750118596579439

Epoch: 6| Step: 4
Training loss: 3.037954330444336
Validation loss: 2.7709468718497985

Epoch: 6| Step: 5
Training loss: 3.928257465362549
Validation loss: 2.759017890499484

Epoch: 6| Step: 6
Training loss: 3.049208402633667
Validation loss: 2.7437082106067288

Epoch: 6| Step: 7
Training loss: 4.016069412231445
Validation loss: 2.7328402073152605

Epoch: 6| Step: 8
Training loss: 2.163696527481079
Validation loss: 2.7161579490989767

Epoch: 6| Step: 9
Training loss: 3.5221335887908936
Validation loss: 2.7139259538342877

Epoch: 6| Step: 10
Training loss: 2.6392760276794434
Validation loss: 2.7140102053201325

Epoch: 6| Step: 11
Training loss: 2.478452444076538
Validation loss: 2.717742512303014

Epoch: 6| Step: 12
Training loss: 2.673030376434326
Validation loss: 2.717326783364819

Epoch: 6| Step: 13
Training loss: 2.237684965133667
Validation loss: 2.710841017384683

Epoch: 22| Step: 0
Training loss: 2.632517099380493
Validation loss: 2.7088366298265356

Epoch: 6| Step: 1
Training loss: 2.0263564586639404
Validation loss: 2.7039288705395115

Epoch: 6| Step: 2
Training loss: 2.7250657081604004
Validation loss: 2.709140149495935

Epoch: 6| Step: 3
Training loss: 2.392582654953003
Validation loss: 2.70805113802674

Epoch: 6| Step: 4
Training loss: 2.88331937789917
Validation loss: 2.7040797074635825

Epoch: 6| Step: 5
Training loss: 2.9654436111450195
Validation loss: 2.70390942019801

Epoch: 6| Step: 6
Training loss: 3.437757968902588
Validation loss: 2.6931006293142996

Epoch: 6| Step: 7
Training loss: 2.8960952758789062
Validation loss: 2.6851318625993628

Epoch: 6| Step: 8
Training loss: 2.9432930946350098
Validation loss: 2.683277545436736

Epoch: 6| Step: 9
Training loss: 2.755560874938965
Validation loss: 2.688077731799054

Epoch: 6| Step: 10
Training loss: 2.8028366565704346
Validation loss: 2.7046901308080202

Epoch: 6| Step: 11
Training loss: 3.3829102516174316
Validation loss: 2.7004013087159846

Epoch: 6| Step: 12
Training loss: 2.9741902351379395
Validation loss: 2.677506657056911

Epoch: 6| Step: 13
Training loss: 3.2916786670684814
Validation loss: 2.6723901507675007

Epoch: 23| Step: 0
Training loss: 2.7113351821899414
Validation loss: 2.669335106367706

Epoch: 6| Step: 1
Training loss: 3.1916332244873047
Validation loss: 2.6728314584301365

Epoch: 6| Step: 2
Training loss: 3.190260648727417
Validation loss: 2.670297540644164

Epoch: 6| Step: 3
Training loss: 3.0428147315979004
Validation loss: 2.6771578173483572

Epoch: 6| Step: 4
Training loss: 3.1648550033569336
Validation loss: 2.6704694635124615

Epoch: 6| Step: 5
Training loss: 2.5949878692626953
Validation loss: 2.6664523322095155

Epoch: 6| Step: 6
Training loss: 2.600886344909668
Validation loss: 2.661962927028697

Epoch: 6| Step: 7
Training loss: 2.7266740798950195
Validation loss: 2.660518016866458

Epoch: 6| Step: 8
Training loss: 2.434861183166504
Validation loss: 2.6565906540040047

Epoch: 6| Step: 9
Training loss: 1.7661454677581787
Validation loss: 2.6643893693083074

Epoch: 6| Step: 10
Training loss: 3.0625476837158203
Validation loss: 2.671611903816141

Epoch: 6| Step: 11
Training loss: 4.007748603820801
Validation loss: 2.656923432503977

Epoch: 6| Step: 12
Training loss: 2.841548204421997
Validation loss: 2.6451684172435472

Epoch: 6| Step: 13
Training loss: 2.002140522003174
Validation loss: 2.6431151513130433

Epoch: 24| Step: 0
Training loss: 2.6995673179626465
Validation loss: 2.6429977442628596

Epoch: 6| Step: 1
Training loss: 2.7967047691345215
Validation loss: 2.6413028829841205

Epoch: 6| Step: 2
Training loss: 3.4613895416259766
Validation loss: 2.6375184136052288

Epoch: 6| Step: 3
Training loss: 2.1318159103393555
Validation loss: 2.6381495050204697

Epoch: 6| Step: 4
Training loss: 2.8053770065307617
Validation loss: 2.6336498183588826

Epoch: 6| Step: 5
Training loss: 3.3368115425109863
Validation loss: 2.631227231794788

Epoch: 6| Step: 6
Training loss: 2.9730477333068848
Validation loss: 2.6271270782716813

Epoch: 6| Step: 7
Training loss: 3.2877838611602783
Validation loss: 2.6285078346088366

Epoch: 6| Step: 8
Training loss: 2.80619478225708
Validation loss: 2.6241948271310456

Epoch: 6| Step: 9
Training loss: 2.5190725326538086
Validation loss: 2.626921666565762

Epoch: 6| Step: 10
Training loss: 3.0462307929992676
Validation loss: 2.625494964661137

Epoch: 6| Step: 11
Training loss: 1.7824184894561768
Validation loss: 2.6281419287445726

Epoch: 6| Step: 12
Training loss: 2.6233506202697754
Validation loss: 2.619796786257016

Epoch: 6| Step: 13
Training loss: 3.202582836151123
Validation loss: 2.6189990607641076

Epoch: 25| Step: 0
Training loss: 2.3400561809539795
Validation loss: 2.633255873956988

Epoch: 6| Step: 1
Training loss: 2.8740615844726562
Validation loss: 2.665333019789829

Epoch: 6| Step: 2
Training loss: 3.1206536293029785
Validation loss: 2.675597885603546

Epoch: 6| Step: 3
Training loss: 2.5520379543304443
Validation loss: 2.622801101335915

Epoch: 6| Step: 4
Training loss: 2.7983906269073486
Validation loss: 2.612355673184959

Epoch: 6| Step: 5
Training loss: 3.3722517490386963
Validation loss: 2.6342401043061288

Epoch: 6| Step: 6
Training loss: 2.746112108230591
Validation loss: 2.6219698639326197

Epoch: 6| Step: 7
Training loss: 3.4829354286193848
Validation loss: 2.6097854824476343

Epoch: 6| Step: 8
Training loss: 2.71744704246521
Validation loss: 2.603806798176099

Epoch: 6| Step: 9
Training loss: 2.5475013256073
Validation loss: 2.604317295935846

Epoch: 6| Step: 10
Training loss: 2.441401243209839
Validation loss: 2.6056446606113064

Epoch: 6| Step: 11
Training loss: 2.4883244037628174
Validation loss: 2.608773890361991

Epoch: 6| Step: 12
Training loss: 2.649320602416992
Validation loss: 2.617163286414198

Epoch: 6| Step: 13
Training loss: 3.358537197113037
Validation loss: 2.6287371804637294

Epoch: 26| Step: 0
Training loss: 3.37606143951416
Validation loss: 2.621332173706383

Epoch: 6| Step: 1
Training loss: 3.7742185592651367
Validation loss: 2.6033326707860476

Epoch: 6| Step: 2
Training loss: 1.6952173709869385
Validation loss: 2.598643574663388

Epoch: 6| Step: 3
Training loss: 3.2131409645080566
Validation loss: 2.591782815994755

Epoch: 6| Step: 4
Training loss: 2.64436411857605
Validation loss: 2.5926923521103395

Epoch: 6| Step: 5
Training loss: 2.9987287521362305
Validation loss: 2.594430810661726

Epoch: 6| Step: 6
Training loss: 2.755225896835327
Validation loss: 2.592656215031942

Epoch: 6| Step: 7
Training loss: 2.723792791366577
Validation loss: 2.5931663154273905

Epoch: 6| Step: 8
Training loss: 1.644860029220581
Validation loss: 2.598040001366728

Epoch: 6| Step: 9
Training loss: 3.1419456005096436
Validation loss: 2.6005640747726604

Epoch: 6| Step: 10
Training loss: 2.445436954498291
Validation loss: 2.5989563683027863

Epoch: 6| Step: 11
Training loss: 3.3327744007110596
Validation loss: 2.5959037785889

Epoch: 6| Step: 12
Training loss: 2.5956039428710938
Validation loss: 2.595360199610392

Epoch: 6| Step: 13
Training loss: 2.465402841567993
Validation loss: 2.587255875269572

Epoch: 27| Step: 0
Training loss: 2.4604101181030273
Validation loss: 2.5848286946614585

Epoch: 6| Step: 1
Training loss: 2.641911745071411
Validation loss: 2.577895167053387

Epoch: 6| Step: 2
Training loss: 2.0111050605773926
Validation loss: 2.5770305536126576

Epoch: 6| Step: 3
Training loss: 2.6978888511657715
Validation loss: 2.5748099665487967

Epoch: 6| Step: 4
Training loss: 2.3786263465881348
Validation loss: 2.5752435653440413

Epoch: 6| Step: 5
Training loss: 2.2409214973449707
Validation loss: 2.572840590630808

Epoch: 6| Step: 6
Training loss: 3.158405303955078
Validation loss: 2.5751050723496305

Epoch: 6| Step: 7
Training loss: 3.413086414337158
Validation loss: 2.587556864625664

Epoch: 6| Step: 8
Training loss: 3.8140978813171387
Validation loss: 2.5941786560960995

Epoch: 6| Step: 9
Training loss: 2.5578534603118896
Validation loss: 2.5847499857666674

Epoch: 6| Step: 10
Training loss: 2.7721686363220215
Validation loss: 2.5707290377668155

Epoch: 6| Step: 11
Training loss: 1.8008917570114136
Validation loss: 2.562508157504502

Epoch: 6| Step: 12
Training loss: 3.7451376914978027
Validation loss: 2.569739774991107

Epoch: 6| Step: 13
Training loss: 3.2157955169677734
Validation loss: 2.5755369099237586

Epoch: 28| Step: 0
Training loss: 2.9002633094787598
Validation loss: 2.582079184952603

Epoch: 6| Step: 1
Training loss: 2.704559326171875
Validation loss: 2.576188366900208

Epoch: 6| Step: 2
Training loss: 2.875880002975464
Validation loss: 2.575061152058263

Epoch: 6| Step: 3
Training loss: 2.8709139823913574
Validation loss: 2.571707638361121

Epoch: 6| Step: 4
Training loss: 2.3482553958892822
Validation loss: 2.57286661671054

Epoch: 6| Step: 5
Training loss: 3.3203887939453125
Validation loss: 2.5677526586799213

Epoch: 6| Step: 6
Training loss: 2.747870922088623
Validation loss: 2.567832692976921

Epoch: 6| Step: 7
Training loss: 3.0767016410827637
Validation loss: 2.5659871691016742

Epoch: 6| Step: 8
Training loss: 2.578247547149658
Validation loss: 2.5635172679860103

Epoch: 6| Step: 9
Training loss: 2.439258098602295
Validation loss: 2.5559258691726194

Epoch: 6| Step: 10
Training loss: 2.775132894515991
Validation loss: 2.5544976713836833

Epoch: 6| Step: 11
Training loss: 2.608485460281372
Validation loss: 2.5526906674908054

Epoch: 6| Step: 12
Training loss: 2.6188931465148926
Validation loss: 2.550322307053433

Epoch: 6| Step: 13
Training loss: 2.8062496185302734
Validation loss: 2.5591975155697075

Epoch: 29| Step: 0
Training loss: 2.703270435333252
Validation loss: 2.567848415784938

Epoch: 6| Step: 1
Training loss: 2.9764230251312256
Validation loss: 2.5766238884259294

Epoch: 6| Step: 2
Training loss: 2.6598408222198486
Validation loss: 2.562357259053056

Epoch: 6| Step: 3
Training loss: 2.5662922859191895
Validation loss: 2.5536019776457097

Epoch: 6| Step: 4
Training loss: 2.25107479095459
Validation loss: 2.554729128396639

Epoch: 6| Step: 5
Training loss: 2.647062301635742
Validation loss: 2.5601978122547107

Epoch: 6| Step: 6
Training loss: 2.8904247283935547
Validation loss: 2.5588495987717823

Epoch: 6| Step: 7
Training loss: 3.399766206741333
Validation loss: 2.555819588322793

Epoch: 6| Step: 8
Training loss: 3.1741185188293457
Validation loss: 2.549647415837934

Epoch: 6| Step: 9
Training loss: 3.092484474182129
Validation loss: 2.547767713505735

Epoch: 6| Step: 10
Training loss: 2.441188335418701
Validation loss: 2.5399493914778515

Epoch: 6| Step: 11
Training loss: 2.444007158279419
Validation loss: 2.537197264291907

Epoch: 6| Step: 12
Training loss: 2.6264984607696533
Validation loss: 2.5344136735444427

Epoch: 6| Step: 13
Training loss: 2.5594587326049805
Validation loss: 2.533992567370015

Epoch: 30| Step: 0
Training loss: 2.7096614837646484
Validation loss: 2.53504692610874

Epoch: 6| Step: 1
Training loss: 3.189987897872925
Validation loss: 2.5406901605667604

Epoch: 6| Step: 2
Training loss: 2.295158863067627
Validation loss: 2.5387717677700903

Epoch: 6| Step: 3
Training loss: 2.5021913051605225
Validation loss: 2.5386609979855117

Epoch: 6| Step: 4
Training loss: 2.505136013031006
Validation loss: 2.5369056706787436

Epoch: 6| Step: 5
Training loss: 2.277256727218628
Validation loss: 2.5395346995322936

Epoch: 6| Step: 6
Training loss: 3.1196303367614746
Validation loss: 2.538436443574967

Epoch: 6| Step: 7
Training loss: 2.9006667137145996
Validation loss: 2.532447825195969

Epoch: 6| Step: 8
Training loss: 3.025320053100586
Validation loss: 2.531059008772655

Epoch: 6| Step: 9
Training loss: 1.986728549003601
Validation loss: 2.5304003992388324

Epoch: 6| Step: 10
Training loss: 2.963766574859619
Validation loss: 2.5384901185189523

Epoch: 6| Step: 11
Training loss: 3.02274751663208
Validation loss: 2.5623086267902004

Epoch: 6| Step: 12
Training loss: 2.658177375793457
Validation loss: 2.5735411285072245

Epoch: 6| Step: 13
Training loss: 3.6253843307495117
Validation loss: 2.541086373790618

Epoch: 31| Step: 0
Training loss: 2.6989641189575195
Validation loss: 2.5295364190173406

Epoch: 6| Step: 1
Training loss: 2.1638176441192627
Validation loss: 2.5296857305752334

Epoch: 6| Step: 2
Training loss: 2.7477028369903564
Validation loss: 2.5296751529939714

Epoch: 6| Step: 3
Training loss: 2.5335617065429688
Validation loss: 2.5272638746487197

Epoch: 6| Step: 4
Training loss: 2.616633176803589
Validation loss: 2.5293460584455922

Epoch: 6| Step: 5
Training loss: 2.6631734371185303
Validation loss: 2.5410188244235132

Epoch: 6| Step: 6
Training loss: 3.084585666656494
Validation loss: 2.5483923983830277

Epoch: 6| Step: 7
Training loss: 3.4526798725128174
Validation loss: 2.5376470909323743

Epoch: 6| Step: 8
Training loss: 3.6665842533111572
Validation loss: 2.526644822089903

Epoch: 6| Step: 9
Training loss: 2.0952019691467285
Validation loss: 2.5183910964637675

Epoch: 6| Step: 10
Training loss: 2.8381152153015137
Validation loss: 2.5231442951386973

Epoch: 6| Step: 11
Training loss: 2.7206063270568848
Validation loss: 2.526965287423903

Epoch: 6| Step: 12
Training loss: 2.1807308197021484
Validation loss: 2.530447188244071

Epoch: 6| Step: 13
Training loss: 2.8390045166015625
Validation loss: 2.5376270227534796

Epoch: 32| Step: 0
Training loss: 3.435760498046875
Validation loss: 2.5672087002825994

Epoch: 6| Step: 1
Training loss: 3.121891498565674
Validation loss: 2.5812961106659262

Epoch: 6| Step: 2
Training loss: 2.3942959308624268
Validation loss: 2.5459903106894544

Epoch: 6| Step: 3
Training loss: 2.8653526306152344
Validation loss: 2.54575155755525

Epoch: 6| Step: 4
Training loss: 2.3629777431488037
Validation loss: 2.565928259203511

Epoch: 6| Step: 5
Training loss: 2.691511392593384
Validation loss: 2.5556652187019266

Epoch: 6| Step: 6
Training loss: 2.394041061401367
Validation loss: 2.546367804209391

Epoch: 6| Step: 7
Training loss: 2.181824207305908
Validation loss: 2.5188827758194297

Epoch: 6| Step: 8
Training loss: 2.754210948944092
Validation loss: 2.5100713417094243

Epoch: 6| Step: 9
Training loss: 1.9942456483840942
Validation loss: 2.515413994430214

Epoch: 6| Step: 10
Training loss: 2.5194878578186035
Validation loss: 2.527271642479845

Epoch: 6| Step: 11
Training loss: 3.4486448764801025
Validation loss: 2.531207264110606

Epoch: 6| Step: 12
Training loss: 3.305948257446289
Validation loss: 2.5357118575803694

Epoch: 6| Step: 13
Training loss: 3.0925862789154053
Validation loss: 2.5284719544072307

Epoch: 33| Step: 0
Training loss: 3.3694305419921875
Validation loss: 2.5276683812500327

Epoch: 6| Step: 1
Training loss: 2.5924243927001953
Validation loss: 2.5228945516770884

Epoch: 6| Step: 2
Training loss: 2.386021614074707
Validation loss: 2.5187325400690876

Epoch: 6| Step: 3
Training loss: 2.3062119483947754
Validation loss: 2.5167298393864788

Epoch: 6| Step: 4
Training loss: 2.937525749206543
Validation loss: 2.5138587900387344

Epoch: 6| Step: 5
Training loss: 2.0645148754119873
Validation loss: 2.5365262634010723

Epoch: 6| Step: 6
Training loss: 3.2316694259643555
Validation loss: 2.553735861214258

Epoch: 6| Step: 7
Training loss: 2.9416728019714355
Validation loss: 2.5571335720759567

Epoch: 6| Step: 8
Training loss: 2.914188861846924
Validation loss: 2.5457458752457813

Epoch: 6| Step: 9
Training loss: 2.960831880569458
Validation loss: 2.5224822234081965

Epoch: 6| Step: 10
Training loss: 2.885348320007324
Validation loss: 2.5153621883802515

Epoch: 6| Step: 11
Training loss: 2.5260090827941895
Validation loss: 2.5012451756385063

Epoch: 6| Step: 12
Training loss: 2.1630024909973145
Validation loss: 2.499898854122367

Epoch: 6| Step: 13
Training loss: 3.071200370788574
Validation loss: 2.5051969943508023

Epoch: 34| Step: 0
Training loss: 2.83701753616333
Validation loss: 2.505277256811819

Epoch: 6| Step: 1
Training loss: 2.637619972229004
Validation loss: 2.512233139366232

Epoch: 6| Step: 2
Training loss: 2.526008367538452
Validation loss: 2.5224612041186263

Epoch: 6| Step: 3
Training loss: 3.051999092102051
Validation loss: 2.5113763347748788

Epoch: 6| Step: 4
Training loss: 2.4897637367248535
Validation loss: 2.506014798277168

Epoch: 6| Step: 5
Training loss: 2.2706990242004395
Validation loss: 2.4951013185644664

Epoch: 6| Step: 6
Training loss: 2.6742329597473145
Validation loss: 2.4929197372928744

Epoch: 6| Step: 7
Training loss: 2.8740217685699463
Validation loss: 2.4953752640754945

Epoch: 6| Step: 8
Training loss: 2.5708212852478027
Validation loss: 2.5005396771174606

Epoch: 6| Step: 9
Training loss: 2.1842803955078125
Validation loss: 2.513311845000072

Epoch: 6| Step: 10
Training loss: 2.956686496734619
Validation loss: 2.5146955725967244

Epoch: 6| Step: 11
Training loss: 3.0611186027526855
Validation loss: 2.509172244738507

Epoch: 6| Step: 12
Training loss: 2.8832311630249023
Validation loss: 2.5058711523650796

Epoch: 6| Step: 13
Training loss: 3.3672749996185303
Validation loss: 2.498395178907661

Epoch: 35| Step: 0
Training loss: 2.8407537937164307
Validation loss: 2.506950616836548

Epoch: 6| Step: 1
Training loss: 3.0378785133361816
Validation loss: 2.4946996294042116

Epoch: 6| Step: 2
Training loss: 1.8977279663085938
Validation loss: 2.4883804064925

Epoch: 6| Step: 3
Training loss: 3.022409200668335
Validation loss: 2.4859744348833637

Epoch: 6| Step: 4
Training loss: 2.9669079780578613
Validation loss: 2.4807310873462307

Epoch: 6| Step: 5
Training loss: 2.9853146076202393
Validation loss: 2.4787591862422165

Epoch: 6| Step: 6
Training loss: 3.072420120239258
Validation loss: 2.4760943305107856

Epoch: 6| Step: 7
Training loss: 3.2296838760375977
Validation loss: 2.4766004136813584

Epoch: 6| Step: 8
Training loss: 2.871833324432373
Validation loss: 2.475574572881063

Epoch: 6| Step: 9
Training loss: 1.609100580215454
Validation loss: 2.4764025339516262

Epoch: 6| Step: 10
Training loss: 2.546461582183838
Validation loss: 2.4748050935806765

Epoch: 6| Step: 11
Training loss: 2.422354221343994
Validation loss: 2.4742559976475214

Epoch: 6| Step: 12
Training loss: 2.686523675918579
Validation loss: 2.4732306324025637

Epoch: 6| Step: 13
Training loss: 2.656214714050293
Validation loss: 2.474623554496355

Epoch: 36| Step: 0
Training loss: 2.4685399532318115
Validation loss: 2.4782721560488463

Epoch: 6| Step: 1
Training loss: 2.471604347229004
Validation loss: 2.476010068770378

Epoch: 6| Step: 2
Training loss: 3.0045862197875977
Validation loss: 2.479433241710868

Epoch: 6| Step: 3
Training loss: 2.596395492553711
Validation loss: 2.478884830269762

Epoch: 6| Step: 4
Training loss: 2.5761594772338867
Validation loss: 2.4847039791845504

Epoch: 6| Step: 5
Training loss: 2.8515095710754395
Validation loss: 2.4781859305597123

Epoch: 6| Step: 6
Training loss: 2.653090476989746
Validation loss: 2.4803201831797117

Epoch: 6| Step: 7
Training loss: 2.7407798767089844
Validation loss: 2.475044091542562

Epoch: 6| Step: 8
Training loss: 2.5735459327697754
Validation loss: 2.47418882513559

Epoch: 6| Step: 9
Training loss: 2.5738449096679688
Validation loss: 2.4817186581191195

Epoch: 6| Step: 10
Training loss: 2.7306935787200928
Validation loss: 2.4829820971335135

Epoch: 6| Step: 11
Training loss: 2.751464366912842
Validation loss: 2.4783390773239957

Epoch: 6| Step: 12
Training loss: 2.7738521099090576
Validation loss: 2.4758812201920377

Epoch: 6| Step: 13
Training loss: 3.201572895050049
Validation loss: 2.471364721175163

Epoch: 37| Step: 0
Training loss: 2.9799041748046875
Validation loss: 2.467551169856902

Epoch: 6| Step: 1
Training loss: 2.696727752685547
Validation loss: 2.4618657404376614

Epoch: 6| Step: 2
Training loss: 1.8707820177078247
Validation loss: 2.458514844217608

Epoch: 6| Step: 3
Training loss: 3.0868282318115234
Validation loss: 2.4562447404348724

Epoch: 6| Step: 4
Training loss: 2.0537467002868652
Validation loss: 2.458878049286463

Epoch: 6| Step: 5
Training loss: 2.5480756759643555
Validation loss: 2.4596573691214285

Epoch: 6| Step: 6
Training loss: 2.840179920196533
Validation loss: 2.461068025199316

Epoch: 6| Step: 7
Training loss: 2.2983322143554688
Validation loss: 2.4651949046760477

Epoch: 6| Step: 8
Training loss: 3.3276703357696533
Validation loss: 2.464247816352434

Epoch: 6| Step: 9
Training loss: 2.172736644744873
Validation loss: 2.459445781605218

Epoch: 6| Step: 10
Training loss: 2.8946304321289062
Validation loss: 2.4564805928096978

Epoch: 6| Step: 11
Training loss: 3.1160314083099365
Validation loss: 2.460605113737045

Epoch: 6| Step: 12
Training loss: 2.921172618865967
Validation loss: 2.459516043304115

Epoch: 6| Step: 13
Training loss: 2.904989004135132
Validation loss: 2.4525982564495457

Epoch: 38| Step: 0
Training loss: 2.6893420219421387
Validation loss: 2.45351529377763

Epoch: 6| Step: 1
Training loss: 2.664684295654297
Validation loss: 2.4696145954952446

Epoch: 6| Step: 2
Training loss: 2.742316246032715
Validation loss: 2.4893027723476453

Epoch: 6| Step: 3
Training loss: 2.374549627304077
Validation loss: 2.52043745851004

Epoch: 6| Step: 4
Training loss: 2.934894323348999
Validation loss: 2.5236295474472867

Epoch: 6| Step: 5
Training loss: 2.9750328063964844
Validation loss: 2.5148314532413276

Epoch: 6| Step: 6
Training loss: 2.427551031112671
Validation loss: 2.483282148197133

Epoch: 6| Step: 7
Training loss: 2.666924238204956
Validation loss: 2.4487579073957217

Epoch: 6| Step: 8
Training loss: 2.596604347229004
Validation loss: 2.4497154374276437

Epoch: 6| Step: 9
Training loss: 1.9944401979446411
Validation loss: 2.457727160505069

Epoch: 6| Step: 10
Training loss: 2.9134771823883057
Validation loss: 2.462948558151081

Epoch: 6| Step: 11
Training loss: 2.89237642288208
Validation loss: 2.4661193919438187

Epoch: 6| Step: 12
Training loss: 3.456395149230957
Validation loss: 2.463905134508687

Epoch: 6| Step: 13
Training loss: 2.379032611846924
Validation loss: 2.4657833217292704

Epoch: 39| Step: 0
Training loss: 2.6788036823272705
Validation loss: 2.4607778697885494

Epoch: 6| Step: 1
Training loss: 2.004361152648926
Validation loss: 2.458019082264234

Epoch: 6| Step: 2
Training loss: 2.504279375076294
Validation loss: 2.449671091571931

Epoch: 6| Step: 3
Training loss: 2.4930052757263184
Validation loss: 2.446373780568441

Epoch: 6| Step: 4
Training loss: 2.6046862602233887
Validation loss: 2.4374139385838665

Epoch: 6| Step: 5
Training loss: 2.710531234741211
Validation loss: 2.440046141224523

Epoch: 6| Step: 6
Training loss: 2.7221779823303223
Validation loss: 2.4483672162537933

Epoch: 6| Step: 7
Training loss: 3.0487444400787354
Validation loss: 2.4526685463484896

Epoch: 6| Step: 8
Training loss: 3.118528366088867
Validation loss: 2.4577805662667878

Epoch: 6| Step: 9
Training loss: 2.848255157470703
Validation loss: 2.4567136995254026

Epoch: 6| Step: 10
Training loss: 2.4792916774749756
Validation loss: 2.4489372314945346

Epoch: 6| Step: 11
Training loss: 2.77205228805542
Validation loss: 2.448938459478399

Epoch: 6| Step: 12
Training loss: 2.8793444633483887
Validation loss: 2.4584498302910918

Epoch: 6| Step: 13
Training loss: 2.5834059715270996
Validation loss: 2.464068664017544

Epoch: 40| Step: 0
Training loss: 1.8835728168487549
Validation loss: 2.4824842560675835

Epoch: 6| Step: 1
Training loss: 2.788681983947754
Validation loss: 2.49044111979905

Epoch: 6| Step: 2
Training loss: 3.153704881668091
Validation loss: 2.493422265975706

Epoch: 6| Step: 3
Training loss: 2.317274570465088
Validation loss: 2.4638387644162743

Epoch: 6| Step: 4
Training loss: 2.7593507766723633
Validation loss: 2.442621377206618

Epoch: 6| Step: 5
Training loss: 2.7536754608154297
Validation loss: 2.4316020691266624

Epoch: 6| Step: 6
Training loss: 3.573127508163452
Validation loss: 2.4285073049606813

Epoch: 6| Step: 7
Training loss: 2.124628782272339
Validation loss: 2.434209339080318

Epoch: 6| Step: 8
Training loss: 2.7613134384155273
Validation loss: 2.4396816402353267

Epoch: 6| Step: 9
Training loss: 2.2443161010742188
Validation loss: 2.4407666370432866

Epoch: 6| Step: 10
Training loss: 2.2898783683776855
Validation loss: 2.4380175990443074

Epoch: 6| Step: 11
Training loss: 2.980827808380127
Validation loss: 2.440141272801225

Epoch: 6| Step: 12
Training loss: 2.9592926502227783
Validation loss: 2.4400089210079563

Epoch: 6| Step: 13
Training loss: 3.2544946670532227
Validation loss: 2.4343931508320633

Epoch: 41| Step: 0
Training loss: 2.7339730262756348
Validation loss: 2.436510250132571

Epoch: 6| Step: 1
Training loss: 3.2529542446136475
Validation loss: 2.4328050472403087

Epoch: 6| Step: 2
Training loss: 2.4691481590270996
Validation loss: 2.424085288919428

Epoch: 6| Step: 3
Training loss: 2.7864928245544434
Validation loss: 2.4217448029466855

Epoch: 6| Step: 4
Training loss: 2.8761396408081055
Validation loss: 2.4218136084977018

Epoch: 6| Step: 5
Training loss: 2.5019311904907227
Validation loss: 2.4285154368287776

Epoch: 6| Step: 6
Training loss: 3.2408695220947266
Validation loss: 2.4287044258527857

Epoch: 6| Step: 7
Training loss: 2.4658408164978027
Validation loss: 2.438233806240943

Epoch: 6| Step: 8
Training loss: 2.082695960998535
Validation loss: 2.4361265372204524

Epoch: 6| Step: 9
Training loss: 2.293222188949585
Validation loss: 2.436079802051667

Epoch: 6| Step: 10
Training loss: 2.4578990936279297
Validation loss: 2.438701275856264

Epoch: 6| Step: 11
Training loss: 2.7037980556488037
Validation loss: 2.4377003177519767

Epoch: 6| Step: 12
Training loss: 3.280719757080078
Validation loss: 2.4349851121184645

Epoch: 6| Step: 13
Training loss: 1.7650303840637207
Validation loss: 2.4280119788262153

Epoch: 42| Step: 0
Training loss: 3.574542760848999
Validation loss: 2.4253032694580736

Epoch: 6| Step: 1
Training loss: 2.412248134613037
Validation loss: 2.4311162733262583

Epoch: 6| Step: 2
Training loss: 2.7609314918518066
Validation loss: 2.4399894052936184

Epoch: 6| Step: 3
Training loss: 2.5972437858581543
Validation loss: 2.438286401892221

Epoch: 6| Step: 4
Training loss: 2.0064547061920166
Validation loss: 2.4350890087824997

Epoch: 6| Step: 5
Training loss: 1.860630750656128
Validation loss: 2.4356788102016655

Epoch: 6| Step: 6
Training loss: 3.3626492023468018
Validation loss: 2.423019814234908

Epoch: 6| Step: 7
Training loss: 2.8195672035217285
Validation loss: 2.4203519513530116

Epoch: 6| Step: 8
Training loss: 3.4424619674682617
Validation loss: 2.4181811963358233

Epoch: 6| Step: 9
Training loss: 2.8243932723999023
Validation loss: 2.4380006431251444

Epoch: 6| Step: 10
Training loss: 2.650179386138916
Validation loss: 2.4816817955304216

Epoch: 6| Step: 11
Training loss: 2.7180285453796387
Validation loss: 2.503081557571247

Epoch: 6| Step: 12
Training loss: 1.730499029159546
Validation loss: 2.5234537483543478

Epoch: 6| Step: 13
Training loss: 2.5975356101989746
Validation loss: 2.5336863917689167

Epoch: 43| Step: 0
Training loss: 2.8357105255126953
Validation loss: 2.5205938649433914

Epoch: 6| Step: 1
Training loss: 2.4376721382141113
Validation loss: 2.477297349642682

Epoch: 6| Step: 2
Training loss: 2.974390983581543
Validation loss: 2.4260493068284887

Epoch: 6| Step: 3
Training loss: 2.1959729194641113
Validation loss: 2.411374415120771

Epoch: 6| Step: 4
Training loss: 2.5555410385131836
Validation loss: 2.4161788981447936

Epoch: 6| Step: 5
Training loss: 2.5328855514526367
Validation loss: 2.426685530652282

Epoch: 6| Step: 6
Training loss: 2.9729793071746826
Validation loss: 2.4275410816233647

Epoch: 6| Step: 7
Training loss: 3.4071578979492188
Validation loss: 2.428091485013244

Epoch: 6| Step: 8
Training loss: 3.0964908599853516
Validation loss: 2.427936189918108

Epoch: 6| Step: 9
Training loss: 2.290482521057129
Validation loss: 2.4202681792679654

Epoch: 6| Step: 10
Training loss: 1.839030385017395
Validation loss: 2.4325795481281896

Epoch: 6| Step: 11
Training loss: 2.684180736541748
Validation loss: 2.4407569592998875

Epoch: 6| Step: 12
Training loss: 2.8934450149536133
Validation loss: 2.45407800264256

Epoch: 6| Step: 13
Training loss: 2.98020076751709
Validation loss: 2.4567876708122993

Epoch: 44| Step: 0
Training loss: 2.903001308441162
Validation loss: 2.461940339816514

Epoch: 6| Step: 1
Training loss: 2.942638397216797
Validation loss: 2.4528517517992245

Epoch: 6| Step: 2
Training loss: 3.0951976776123047
Validation loss: 2.4358099083746634

Epoch: 6| Step: 3
Training loss: 2.526431083679199
Validation loss: 2.4256917738145396

Epoch: 6| Step: 4
Training loss: 2.6955714225769043
Validation loss: 2.4196739991505942

Epoch: 6| Step: 5
Training loss: 3.1613636016845703
Validation loss: 2.415314515431722

Epoch: 6| Step: 6
Training loss: 1.4454008340835571
Validation loss: 2.4219392961071384

Epoch: 6| Step: 7
Training loss: 2.5246682167053223
Validation loss: 2.443923565649217

Epoch: 6| Step: 8
Training loss: 2.581911563873291
Validation loss: 2.4317106790440057

Epoch: 6| Step: 9
Training loss: 2.6924266815185547
Validation loss: 2.4273291069974183

Epoch: 6| Step: 10
Training loss: 3.4576756954193115
Validation loss: 2.4250883748454433

Epoch: 6| Step: 11
Training loss: 2.76865816116333
Validation loss: 2.4175816966641333

Epoch: 6| Step: 12
Training loss: 2.2197911739349365
Validation loss: 2.4162118140087334

Epoch: 6| Step: 13
Training loss: 2.087466239929199
Validation loss: 2.4193506266481135

Epoch: 45| Step: 0
Training loss: 2.547847270965576
Validation loss: 2.4256622611835437

Epoch: 6| Step: 1
Training loss: 1.9328522682189941
Validation loss: 2.42380795427548

Epoch: 6| Step: 2
Training loss: 2.339209794998169
Validation loss: 2.417253901881556

Epoch: 6| Step: 3
Training loss: 2.9802656173706055
Validation loss: 2.412642225142448

Epoch: 6| Step: 4
Training loss: 2.768360137939453
Validation loss: 2.4081678441775742

Epoch: 6| Step: 5
Training loss: 3.0055930614471436
Validation loss: 2.3998739898845716

Epoch: 6| Step: 6
Training loss: 3.0205795764923096
Validation loss: 2.393864513725363

Epoch: 6| Step: 7
Training loss: 3.1293325424194336
Validation loss: 2.3965866745159192

Epoch: 6| Step: 8
Training loss: 2.359889030456543
Validation loss: 2.3962619971203547

Epoch: 6| Step: 9
Training loss: 2.3806533813476562
Validation loss: 2.3911989940110074

Epoch: 6| Step: 10
Training loss: 3.2273881435394287
Validation loss: 2.3919121219265844

Epoch: 6| Step: 11
Training loss: 2.885636329650879
Validation loss: 2.395719451289023

Epoch: 6| Step: 12
Training loss: 2.8182101249694824
Validation loss: 2.400674522563975

Epoch: 6| Step: 13
Training loss: 1.2087737321853638
Validation loss: 2.3988359128275225

Epoch: 46| Step: 0
Training loss: 2.89565372467041
Validation loss: 2.3935446457196305

Epoch: 6| Step: 1
Training loss: 3.0801515579223633
Validation loss: 2.3964472637381604

Epoch: 6| Step: 2
Training loss: 2.454364776611328
Validation loss: 2.3991540990849978

Epoch: 6| Step: 3
Training loss: 2.650129795074463
Validation loss: 2.3975229622215353

Epoch: 6| Step: 4
Training loss: 3.4373257160186768
Validation loss: 2.407031536102295

Epoch: 6| Step: 5
Training loss: 2.29764986038208
Validation loss: 2.405807092625608

Epoch: 6| Step: 6
Training loss: 2.4572906494140625
Validation loss: 2.413272721793062

Epoch: 6| Step: 7
Training loss: 2.196091651916504
Validation loss: 2.4011368572071032

Epoch: 6| Step: 8
Training loss: 2.309445858001709
Validation loss: 2.4030160955203477

Epoch: 6| Step: 9
Training loss: 2.7685599327087402
Validation loss: 2.403861181710356

Epoch: 6| Step: 10
Training loss: 1.9960285425186157
Validation loss: 2.4101370778135074

Epoch: 6| Step: 11
Training loss: 2.520693778991699
Validation loss: 2.402933041254679

Epoch: 6| Step: 12
Training loss: 2.9806108474731445
Validation loss: 2.3927779325874905

Epoch: 6| Step: 13
Training loss: 3.2135822772979736
Validation loss: 2.3907537332145115

Epoch: 47| Step: 0
Training loss: 3.357966423034668
Validation loss: 2.3925918225319154

Epoch: 6| Step: 1
Training loss: 2.5399227142333984
Validation loss: 2.393592675526937

Epoch: 6| Step: 2
Training loss: 2.448334217071533
Validation loss: 2.3930890765241397

Epoch: 6| Step: 3
Training loss: 2.49685001373291
Validation loss: 2.3918317876836306

Epoch: 6| Step: 4
Training loss: 2.953237295150757
Validation loss: 2.3929068914023777

Epoch: 6| Step: 5
Training loss: 2.6351969242095947
Validation loss: 2.389160689487252

Epoch: 6| Step: 6
Training loss: 2.2285995483398438
Validation loss: 2.3906852763186217

Epoch: 6| Step: 7
Training loss: 2.297393798828125
Validation loss: 2.384415506034769

Epoch: 6| Step: 8
Training loss: 3.093963146209717
Validation loss: 2.3855394906895135

Epoch: 6| Step: 9
Training loss: 2.385075569152832
Validation loss: 2.3835577887873494

Epoch: 6| Step: 10
Training loss: 3.13385009765625
Validation loss: 2.3812787917352494

Epoch: 6| Step: 11
Training loss: 2.5615017414093018
Validation loss: 2.3818193148541194

Epoch: 6| Step: 12
Training loss: 2.3835601806640625
Validation loss: 2.380416308679888

Epoch: 6| Step: 13
Training loss: 2.4405572414398193
Validation loss: 2.3796638904079312

Epoch: 48| Step: 0
Training loss: 1.96431303024292
Validation loss: 2.382388835312218

Epoch: 6| Step: 1
Training loss: 2.2825820446014404
Validation loss: 2.3842684786806823

Epoch: 6| Step: 2
Training loss: 2.8401012420654297
Validation loss: 2.38813078788019

Epoch: 6| Step: 3
Training loss: 2.3423571586608887
Validation loss: 2.3914801471976825

Epoch: 6| Step: 4
Training loss: 2.7920444011688232
Validation loss: 2.419836549348729

Epoch: 6| Step: 5
Training loss: 3.1090383529663086
Validation loss: 2.4538409581748386

Epoch: 6| Step: 6
Training loss: 1.9894332885742188
Validation loss: 2.4669056195084766

Epoch: 6| Step: 7
Training loss: 3.021613597869873
Validation loss: 2.486629932157455

Epoch: 6| Step: 8
Training loss: 2.473017692565918
Validation loss: 2.465285570390763

Epoch: 6| Step: 9
Training loss: 2.8641326427459717
Validation loss: 2.4414905553222983

Epoch: 6| Step: 10
Training loss: 2.7306315898895264
Validation loss: 2.4057320599914878

Epoch: 6| Step: 11
Training loss: 2.766007900238037
Validation loss: 2.3854895689154185

Epoch: 6| Step: 12
Training loss: 2.848538398742676
Validation loss: 2.3817557032390306

Epoch: 6| Step: 13
Training loss: 3.203579902648926
Validation loss: 2.3793533412359094

Epoch: 49| Step: 0
Training loss: 3.5164427757263184
Validation loss: 2.388813054689797

Epoch: 6| Step: 1
Training loss: 2.6256024837493896
Validation loss: 2.421690853693152

Epoch: 6| Step: 2
Training loss: 2.9820635318756104
Validation loss: 2.4399536078976047

Epoch: 6| Step: 3
Training loss: 2.8534817695617676
Validation loss: 2.4437770587141796

Epoch: 6| Step: 4
Training loss: 2.8793201446533203
Validation loss: 2.436563379021101

Epoch: 6| Step: 5
Training loss: 2.6190741062164307
Validation loss: 2.430795141445693

Epoch: 6| Step: 6
Training loss: 2.6288790702819824
Validation loss: 2.4180023747105754

Epoch: 6| Step: 7
Training loss: 2.1449997425079346
Validation loss: 2.401233021930982

Epoch: 6| Step: 8
Training loss: 2.9075114727020264
Validation loss: 2.3916166520887807

Epoch: 6| Step: 9
Training loss: 2.599825382232666
Validation loss: 2.3863297893155004

Epoch: 6| Step: 10
Training loss: 2.6506543159484863
Validation loss: 2.379004592536598

Epoch: 6| Step: 11
Training loss: 2.0581278800964355
Validation loss: 2.3755967258125223

Epoch: 6| Step: 12
Training loss: 2.238466262817383
Validation loss: 2.376500896228257

Epoch: 6| Step: 13
Training loss: 2.9552924633026123
Validation loss: 2.3747820469640915

Epoch: 50| Step: 0
Training loss: 2.1021947860717773
Validation loss: 2.381993011761737

Epoch: 6| Step: 1
Training loss: 2.7737908363342285
Validation loss: 2.388882165314049

Epoch: 6| Step: 2
Training loss: 2.84024715423584
Validation loss: 2.398932832543568

Epoch: 6| Step: 3
Training loss: 3.0780134201049805
Validation loss: 2.3968076654659805

Epoch: 6| Step: 4
Training loss: 3.377328395843506
Validation loss: 2.405972037264096

Epoch: 6| Step: 5
Training loss: 3.0355429649353027
Validation loss: 2.402532490350867

Epoch: 6| Step: 6
Training loss: 1.979732871055603
Validation loss: 2.4037177844714095

Epoch: 6| Step: 7
Training loss: 2.225489616394043
Validation loss: 2.42529139467465

Epoch: 6| Step: 8
Training loss: 2.1813666820526123
Validation loss: 2.4343299583722184

Epoch: 6| Step: 9
Training loss: 2.717165946960449
Validation loss: 2.4346126407705326

Epoch: 6| Step: 10
Training loss: 2.325171709060669
Validation loss: 2.420391131472844

Epoch: 6| Step: 11
Training loss: 2.5976171493530273
Validation loss: 2.4082836104977514

Epoch: 6| Step: 12
Training loss: 2.766350507736206
Validation loss: 2.3920719392838015

Epoch: 6| Step: 13
Training loss: 3.1163575649261475
Validation loss: 2.382456466715823

Epoch: 51| Step: 0
Training loss: 2.451378583908081
Validation loss: 2.3737182360823437

Epoch: 6| Step: 1
Training loss: 2.35841703414917
Validation loss: 2.3703659119144564

Epoch: 6| Step: 2
Training loss: 2.3095574378967285
Validation loss: 2.3665946350302747

Epoch: 6| Step: 3
Training loss: 3.1665759086608887
Validation loss: 2.3701479486239854

Epoch: 6| Step: 4
Training loss: 2.1085102558135986
Validation loss: 2.3798776031822286

Epoch: 6| Step: 5
Training loss: 2.7122225761413574
Validation loss: 2.4106105707025014

Epoch: 6| Step: 6
Training loss: 2.712378978729248
Validation loss: 2.4424720630850842

Epoch: 6| Step: 7
Training loss: 2.073730945587158
Validation loss: 2.4381262768981276

Epoch: 6| Step: 8
Training loss: 2.0888659954071045
Validation loss: 2.422481575319844

Epoch: 6| Step: 9
Training loss: 3.027958631515503
Validation loss: 2.3860830876135055

Epoch: 6| Step: 10
Training loss: 3.362414836883545
Validation loss: 2.373780245422035

Epoch: 6| Step: 11
Training loss: 3.012678623199463
Validation loss: 2.365631784162214

Epoch: 6| Step: 12
Training loss: 3.278268814086914
Validation loss: 2.365703762218516

Epoch: 6| Step: 13
Training loss: 1.8855531215667725
Validation loss: 2.375610407962594

Epoch: 52| Step: 0
Training loss: 2.3427178859710693
Validation loss: 2.402854101632231

Epoch: 6| Step: 1
Training loss: 2.8501689434051514
Validation loss: 2.451685026127805

Epoch: 6| Step: 2
Training loss: 2.1356918811798096
Validation loss: 2.466247620121125

Epoch: 6| Step: 3
Training loss: 2.8002703189849854
Validation loss: 2.4718046880537465

Epoch: 6| Step: 4
Training loss: 2.2073328495025635
Validation loss: 2.408071187234694

Epoch: 6| Step: 5
Training loss: 2.662165880203247
Validation loss: 2.3872266187462756

Epoch: 6| Step: 6
Training loss: 2.96498703956604
Validation loss: 2.376615542237477

Epoch: 6| Step: 7
Training loss: 2.859262466430664
Validation loss: 2.3758241027914067

Epoch: 6| Step: 8
Training loss: 2.954346179962158
Validation loss: 2.387854996547904

Epoch: 6| Step: 9
Training loss: 2.4421801567077637
Validation loss: 2.407332338312621

Epoch: 6| Step: 10
Training loss: 2.1529579162597656
Validation loss: 2.431819882444156

Epoch: 6| Step: 11
Training loss: 3.0486624240875244
Validation loss: 2.4555026587619575

Epoch: 6| Step: 12
Training loss: 2.741126537322998
Validation loss: 2.4962352296357513

Epoch: 6| Step: 13
Training loss: 3.2383151054382324
Validation loss: 2.517989094539355

Epoch: 53| Step: 0
Training loss: 2.994549512863159
Validation loss: 2.4529963001128166

Epoch: 6| Step: 1
Training loss: 2.80365252494812
Validation loss: 2.4027536146102415

Epoch: 6| Step: 2
Training loss: 2.035644769668579
Validation loss: 2.3706395908068587

Epoch: 6| Step: 3
Training loss: 3.287827968597412
Validation loss: 2.3637565207737747

Epoch: 6| Step: 4
Training loss: 2.8840830326080322
Validation loss: 2.3610967948872554

Epoch: 6| Step: 5
Training loss: 2.517735004425049
Validation loss: 2.3747281515470116

Epoch: 6| Step: 6
Training loss: 2.4727835655212402
Validation loss: 2.3851080043341524

Epoch: 6| Step: 7
Training loss: 2.8073534965515137
Validation loss: 2.4010766193430912

Epoch: 6| Step: 8
Training loss: 3.0711851119995117
Validation loss: 2.4265463531658216

Epoch: 6| Step: 9
Training loss: 3.184657573699951
Validation loss: 2.4313696610030306

Epoch: 6| Step: 10
Training loss: 2.4663519859313965
Validation loss: 2.4237709224865003

Epoch: 6| Step: 11
Training loss: 2.5386769771575928
Validation loss: 2.4230040786086873

Epoch: 6| Step: 12
Training loss: 2.375872850418091
Validation loss: 2.40427912435224

Epoch: 6| Step: 13
Training loss: 1.4436206817626953
Validation loss: 2.3846591031679543

Epoch: 54| Step: 0
Training loss: 2.1604371070861816
Validation loss: 2.3756113667641916

Epoch: 6| Step: 1
Training loss: 2.8037662506103516
Validation loss: 2.3683448658194592

Epoch: 6| Step: 2
Training loss: 2.625145196914673
Validation loss: 2.3682509058265278

Epoch: 6| Step: 3
Training loss: 3.0390753746032715
Validation loss: 2.3811920073724564

Epoch: 6| Step: 4
Training loss: 1.5307223796844482
Validation loss: 2.3899416795340915

Epoch: 6| Step: 5
Training loss: 2.762873888015747
Validation loss: 2.401669225385112

Epoch: 6| Step: 6
Training loss: 2.93509578704834
Validation loss: 2.4079358705910305

Epoch: 6| Step: 7
Training loss: 3.476984977722168
Validation loss: 2.416357565951604

Epoch: 6| Step: 8
Training loss: 2.88490629196167
Validation loss: 2.401053031285604

Epoch: 6| Step: 9
Training loss: 2.2927286624908447
Validation loss: 2.3816827420265443

Epoch: 6| Step: 10
Training loss: 3.255465507507324
Validation loss: 2.3624640498110043

Epoch: 6| Step: 11
Training loss: 2.093186855316162
Validation loss: 2.3585543888871388

Epoch: 6| Step: 12
Training loss: 2.5748777389526367
Validation loss: 2.3645347831069783

Epoch: 6| Step: 13
Training loss: 2.3215432167053223
Validation loss: 2.362149912823913

Epoch: 55| Step: 0
Training loss: 2.593418598175049
Validation loss: 2.3609178348254134

Epoch: 6| Step: 1
Training loss: 2.297020435333252
Validation loss: 2.3624257554290113

Epoch: 6| Step: 2
Training loss: 3.2373664379119873
Validation loss: 2.352307718287232

Epoch: 6| Step: 3
Training loss: 2.3894906044006348
Validation loss: 2.352949893602761

Epoch: 6| Step: 4
Training loss: 3.242363214492798
Validation loss: 2.3492768092822005

Epoch: 6| Step: 5
Training loss: 2.6037368774414062
Validation loss: 2.349997000027728

Epoch: 6| Step: 6
Training loss: 1.8940125703811646
Validation loss: 2.348443833730554

Epoch: 6| Step: 7
Training loss: 2.8706560134887695
Validation loss: 2.35211932018239

Epoch: 6| Step: 8
Training loss: 2.7661828994750977
Validation loss: 2.35532804202008

Epoch: 6| Step: 9
Training loss: 2.6909053325653076
Validation loss: 2.3605364932808826

Epoch: 6| Step: 10
Training loss: 2.6177878379821777
Validation loss: 2.3665736926499235

Epoch: 6| Step: 11
Training loss: 2.3575358390808105
Validation loss: 2.379377680440103

Epoch: 6| Step: 12
Training loss: 2.50030517578125
Validation loss: 2.3981560699401365

Epoch: 6| Step: 13
Training loss: 2.8408453464508057
Validation loss: 2.397829358295728

Epoch: 56| Step: 0
Training loss: 2.978156566619873
Validation loss: 2.379568443503431

Epoch: 6| Step: 1
Training loss: 2.7458996772766113
Validation loss: 2.36689325814606

Epoch: 6| Step: 2
Training loss: 3.0930356979370117
Validation loss: 2.346763017357037

Epoch: 6| Step: 3
Training loss: 1.8364195823669434
Validation loss: 2.3482512069004837

Epoch: 6| Step: 4
Training loss: 2.589477062225342
Validation loss: 2.3450222963927896

Epoch: 6| Step: 5
Training loss: 2.2592012882232666
Validation loss: 2.3409155184222805

Epoch: 6| Step: 6
Training loss: 2.9527385234832764
Validation loss: 2.3378650347391763

Epoch: 6| Step: 7
Training loss: 2.6091527938842773
Validation loss: 2.337205071603098

Epoch: 6| Step: 8
Training loss: 3.25797438621521
Validation loss: 2.3434069195101337

Epoch: 6| Step: 9
Training loss: 2.5468063354492188
Validation loss: 2.338186974166542

Epoch: 6| Step: 10
Training loss: 2.5825538635253906
Validation loss: 2.3358583424680974

Epoch: 6| Step: 11
Training loss: 2.234637498855591
Validation loss: 2.3347227522121963

Epoch: 6| Step: 12
Training loss: 2.5114383697509766
Validation loss: 2.335960893220799

Epoch: 6| Step: 13
Training loss: 2.320747137069702
Validation loss: 2.336224356005269

Epoch: 57| Step: 0
Training loss: 2.504664897918701
Validation loss: 2.3380496168649323

Epoch: 6| Step: 1
Training loss: 2.6212027072906494
Validation loss: 2.3349848408852854

Epoch: 6| Step: 2
Training loss: 2.7095489501953125
Validation loss: 2.337954059723885

Epoch: 6| Step: 3
Training loss: 2.40612530708313
Validation loss: 2.3340252983954644

Epoch: 6| Step: 4
Training loss: 2.3377885818481445
Validation loss: 2.3380739663236882

Epoch: 6| Step: 5
Training loss: 2.849639415740967
Validation loss: 2.339093885114116

Epoch: 6| Step: 6
Training loss: 2.563720941543579
Validation loss: 2.335595720557756

Epoch: 6| Step: 7
Training loss: 2.3787500858306885
Validation loss: 2.3398315214341685

Epoch: 6| Step: 8
Training loss: 2.568350315093994
Validation loss: 2.3403886313079507

Epoch: 6| Step: 9
Training loss: 2.753145694732666
Validation loss: 2.3580369359703472

Epoch: 6| Step: 10
Training loss: 2.365485906600952
Validation loss: 2.3815166616952546

Epoch: 6| Step: 11
Training loss: 2.871947765350342
Validation loss: 2.395270150194886

Epoch: 6| Step: 12
Training loss: 3.1797232627868652
Validation loss: 2.398517367660358

Epoch: 6| Step: 13
Training loss: 2.5007693767547607
Validation loss: 2.396049153420233

Epoch: 58| Step: 0
Training loss: 2.8382227420806885
Validation loss: 2.3881554988122757

Epoch: 6| Step: 1
Training loss: 2.530872344970703
Validation loss: 2.374642202931066

Epoch: 6| Step: 2
Training loss: 2.2650609016418457
Validation loss: 2.368755994304534

Epoch: 6| Step: 3
Training loss: 2.7522759437561035
Validation loss: 2.360971407223773

Epoch: 6| Step: 4
Training loss: 2.5931951999664307
Validation loss: 2.358139322650048

Epoch: 6| Step: 5
Training loss: 2.653909206390381
Validation loss: 2.354231637011292

Epoch: 6| Step: 6
Training loss: 3.015169620513916
Validation loss: 2.356863673015307

Epoch: 6| Step: 7
Training loss: 1.9095029830932617
Validation loss: 2.3584688735264603

Epoch: 6| Step: 8
Training loss: 3.1674585342407227
Validation loss: 2.3611366902628252

Epoch: 6| Step: 9
Training loss: 2.6577858924865723
Validation loss: 2.3553809222354682

Epoch: 6| Step: 10
Training loss: 2.4089818000793457
Validation loss: 2.366099008949854

Epoch: 6| Step: 11
Training loss: 2.927089214324951
Validation loss: 2.3578741986264466

Epoch: 6| Step: 12
Training loss: 2.570080280303955
Validation loss: 2.356442920623287

Epoch: 6| Step: 13
Training loss: 1.938896656036377
Validation loss: 2.3487034536177114

Epoch: 59| Step: 0
Training loss: 2.287290573120117
Validation loss: 2.3401808969436155

Epoch: 6| Step: 1
Training loss: 3.025524854660034
Validation loss: 2.338478513943252

Epoch: 6| Step: 2
Training loss: 2.7675209045410156
Validation loss: 2.333111281036049

Epoch: 6| Step: 3
Training loss: 2.3889713287353516
Validation loss: 2.3319213697987218

Epoch: 6| Step: 4
Training loss: 2.065603494644165
Validation loss: 2.327600638071696

Epoch: 6| Step: 5
Training loss: 2.9762401580810547
Validation loss: 2.330700400055096

Epoch: 6| Step: 6
Training loss: 2.5201804637908936
Validation loss: 2.327660950281287

Epoch: 6| Step: 7
Training loss: 2.7941677570343018
Validation loss: 2.3287339569419943

Epoch: 6| Step: 8
Training loss: 2.90922212600708
Validation loss: 2.3264392704092045

Epoch: 6| Step: 9
Training loss: 2.1635828018188477
Validation loss: 2.332399329831523

Epoch: 6| Step: 10
Training loss: 2.303814172744751
Validation loss: 2.3314104157109417

Epoch: 6| Step: 11
Training loss: 2.6669235229492188
Validation loss: 2.333181227407148

Epoch: 6| Step: 12
Training loss: 2.71378493309021
Validation loss: 2.3332090172716367

Epoch: 6| Step: 13
Training loss: 3.3033010959625244
Validation loss: 2.331269012984409

Epoch: 60| Step: 0
Training loss: 3.1362924575805664
Validation loss: 2.3362864345632572

Epoch: 6| Step: 1
Training loss: 3.059157371520996
Validation loss: 2.3372706674760386

Epoch: 6| Step: 2
Training loss: 1.946378231048584
Validation loss: 2.339066909205529

Epoch: 6| Step: 3
Training loss: 2.5405800342559814
Validation loss: 2.3384879481407905

Epoch: 6| Step: 4
Training loss: 2.9785268306732178
Validation loss: 2.340368891275057

Epoch: 6| Step: 5
Training loss: 2.8338279724121094
Validation loss: 2.3491808881041822

Epoch: 6| Step: 6
Training loss: 2.197506904602051
Validation loss: 2.360578816424134

Epoch: 6| Step: 7
Training loss: 2.728142499923706
Validation loss: 2.3719854867586525

Epoch: 6| Step: 8
Training loss: 2.9829821586608887
Validation loss: 2.3837756751686014

Epoch: 6| Step: 9
Training loss: 2.539182424545288
Validation loss: 2.383855668447351

Epoch: 6| Step: 10
Training loss: 2.277815341949463
Validation loss: 2.4013703433416222

Epoch: 6| Step: 11
Training loss: 2.1044716835021973
Validation loss: 2.405481407719274

Epoch: 6| Step: 12
Training loss: 2.477760076522827
Validation loss: 2.406535927967359

Epoch: 6| Step: 13
Training loss: 2.9743854999542236
Validation loss: 2.3766542762838383

Epoch: 61| Step: 0
Training loss: 3.0193347930908203
Validation loss: 2.3598374038614254

Epoch: 6| Step: 1
Training loss: 2.467482089996338
Validation loss: 2.34650356026106

Epoch: 6| Step: 2
Training loss: 3.0062367916107178
Validation loss: 2.34792983916498

Epoch: 6| Step: 3
Training loss: 2.08432936668396
Validation loss: 2.342207283102056

Epoch: 6| Step: 4
Training loss: 2.727567672729492
Validation loss: 2.339257809423631

Epoch: 6| Step: 5
Training loss: 3.180337905883789
Validation loss: 2.335916660165274

Epoch: 6| Step: 6
Training loss: 2.8290340900421143
Validation loss: 2.337536099136517

Epoch: 6| Step: 7
Training loss: 2.935133934020996
Validation loss: 2.33544167395561

Epoch: 6| Step: 8
Training loss: 2.045384645462036
Validation loss: 2.329210014753444

Epoch: 6| Step: 9
Training loss: 2.6776390075683594
Validation loss: 2.3221322157049693

Epoch: 6| Step: 10
Training loss: 2.41848087310791
Validation loss: 2.3197426693413847

Epoch: 6| Step: 11
Training loss: 1.9325878620147705
Validation loss: 2.3201619271309144

Epoch: 6| Step: 12
Training loss: 2.659606456756592
Validation loss: 2.318614322652099

Epoch: 6| Step: 13
Training loss: 2.4511754512786865
Validation loss: 2.3212551788617204

Epoch: 62| Step: 0
Training loss: 1.8279253244400024
Validation loss: 2.322369290936378

Epoch: 6| Step: 1
Training loss: 2.349700927734375
Validation loss: 2.3255724496738885

Epoch: 6| Step: 2
Training loss: 2.405029058456421
Validation loss: 2.3259573213515745

Epoch: 6| Step: 3
Training loss: 2.61202335357666
Validation loss: 2.3267518038390786

Epoch: 6| Step: 4
Training loss: 3.149092674255371
Validation loss: 2.3418192273827008

Epoch: 6| Step: 5
Training loss: 2.022998094558716
Validation loss: 2.367075430449619

Epoch: 6| Step: 6
Training loss: 3.060471534729004
Validation loss: 2.3675298408795427

Epoch: 6| Step: 7
Training loss: 1.956442952156067
Validation loss: 2.3504722349105345

Epoch: 6| Step: 8
Training loss: 3.1035594940185547
Validation loss: 2.356582841565532

Epoch: 6| Step: 9
Training loss: 3.054447650909424
Validation loss: 2.3582497053248908

Epoch: 6| Step: 10
Training loss: 2.7526192665100098
Validation loss: 2.3600597304682576

Epoch: 6| Step: 11
Training loss: 2.415466785430908
Validation loss: 2.356119727575651

Epoch: 6| Step: 12
Training loss: 2.7516403198242188
Validation loss: 2.362007059076781

Epoch: 6| Step: 13
Training loss: 3.1641814708709717
Validation loss: 2.344697203687442

Epoch: 63| Step: 0
Training loss: 2.278348207473755
Validation loss: 2.3251220641597623

Epoch: 6| Step: 1
Training loss: 1.9582847356796265
Validation loss: 2.3167721597097253

Epoch: 6| Step: 2
Training loss: 2.2314836978912354
Validation loss: 2.318341311588082

Epoch: 6| Step: 3
Training loss: 2.8727307319641113
Validation loss: 2.333275079727173

Epoch: 6| Step: 4
Training loss: 2.7569921016693115
Validation loss: 2.341637216588502

Epoch: 6| Step: 5
Training loss: 2.884417772293091
Validation loss: 2.3481076199521302

Epoch: 6| Step: 6
Training loss: 2.718444585800171
Validation loss: 2.364841999546174

Epoch: 6| Step: 7
Training loss: 2.087324857711792
Validation loss: 2.373123130490703

Epoch: 6| Step: 8
Training loss: 3.2624893188476562
Validation loss: 2.3830944389425297

Epoch: 6| Step: 9
Training loss: 3.018768548965454
Validation loss: 2.3897792959725983

Epoch: 6| Step: 10
Training loss: 2.902949810028076
Validation loss: 2.382486989421229

Epoch: 6| Step: 11
Training loss: 2.7833518981933594
Validation loss: 2.3503220106965754

Epoch: 6| Step: 12
Training loss: 2.6167044639587402
Validation loss: 2.3303253996756768

Epoch: 6| Step: 13
Training loss: 2.0420351028442383
Validation loss: 2.3165900937972532

Epoch: 64| Step: 0
Training loss: 2.4287540912628174
Validation loss: 2.308644438302645

Epoch: 6| Step: 1
Training loss: 2.5942201614379883
Validation loss: 2.3068242765242055

Epoch: 6| Step: 2
Training loss: 3.139604330062866
Validation loss: 2.3064246844219904

Epoch: 6| Step: 3
Training loss: 3.0780045986175537
Validation loss: 2.303255599032166

Epoch: 6| Step: 4
Training loss: 1.9227262735366821
Validation loss: 2.309202658232822

Epoch: 6| Step: 5
Training loss: 3.1282167434692383
Validation loss: 2.3088559284005115

Epoch: 6| Step: 6
Training loss: 2.1530656814575195
Validation loss: 2.305270343698481

Epoch: 6| Step: 7
Training loss: 2.6837291717529297
Validation loss: 2.3090579176461823

Epoch: 6| Step: 8
Training loss: 1.2665574550628662
Validation loss: 2.3135212185562297

Epoch: 6| Step: 9
Training loss: 3.336397409439087
Validation loss: 2.3160282411882953

Epoch: 6| Step: 10
Training loss: 3.274155378341675
Validation loss: 2.3150468257165726

Epoch: 6| Step: 11
Training loss: 1.4428446292877197
Validation loss: 2.3163424845664733

Epoch: 6| Step: 12
Training loss: 3.172696113586426
Validation loss: 2.323963704929557

Epoch: 6| Step: 13
Training loss: 2.77817440032959
Validation loss: 2.320645547682239

Epoch: 65| Step: 0
Training loss: 2.6741790771484375
Validation loss: 2.330840513270388

Epoch: 6| Step: 1
Training loss: 3.127837896347046
Validation loss: 2.336868198969031

Epoch: 6| Step: 2
Training loss: 2.056457281112671
Validation loss: 2.3387466451173187

Epoch: 6| Step: 3
Training loss: 3.3333873748779297
Validation loss: 2.355210775970131

Epoch: 6| Step: 4
Training loss: 2.034233331680298
Validation loss: 2.341735650134343

Epoch: 6| Step: 5
Training loss: 2.793189525604248
Validation loss: 2.3443205484779934

Epoch: 6| Step: 6
Training loss: 1.777808666229248
Validation loss: 2.338945009375131

Epoch: 6| Step: 7
Training loss: 2.657831907272339
Validation loss: 2.3375275250404113

Epoch: 6| Step: 8
Training loss: 2.7940425872802734
Validation loss: 2.339595015330981

Epoch: 6| Step: 9
Training loss: 1.9916112422943115
Validation loss: 2.3375166180313274

Epoch: 6| Step: 10
Training loss: 2.60398006439209
Validation loss: 2.3365604698017077

Epoch: 6| Step: 11
Training loss: 2.608731985092163
Validation loss: 2.3516484806614537

Epoch: 6| Step: 12
Training loss: 3.102989912033081
Validation loss: 2.3665201228152037

Epoch: 6| Step: 13
Training loss: 2.886385917663574
Validation loss: 2.365022341410319

Epoch: 66| Step: 0
Training loss: 2.595160961151123
Validation loss: 2.3422422357784805

Epoch: 6| Step: 1
Training loss: 2.600126266479492
Validation loss: 2.3294612822994107

Epoch: 6| Step: 2
Training loss: 2.4803109169006348
Validation loss: 2.3152021368344626

Epoch: 6| Step: 3
Training loss: 3.038416862487793
Validation loss: 2.317501069397055

Epoch: 6| Step: 4
Training loss: 2.223280906677246
Validation loss: 2.3195755994448097

Epoch: 6| Step: 5
Training loss: 2.9518609046936035
Validation loss: 2.317333052235265

Epoch: 6| Step: 6
Training loss: 1.6670293807983398
Validation loss: 2.3180351923870783

Epoch: 6| Step: 7
Training loss: 2.3827362060546875
Validation loss: 2.3174556134849467

Epoch: 6| Step: 8
Training loss: 3.026979923248291
Validation loss: 2.3188870055701143

Epoch: 6| Step: 9
Training loss: 2.7114882469177246
Validation loss: 2.3178446446695635

Epoch: 6| Step: 10
Training loss: 2.1444506645202637
Validation loss: 2.326537529627482

Epoch: 6| Step: 11
Training loss: 2.9771888256073
Validation loss: 2.3439496460781304

Epoch: 6| Step: 12
Training loss: 3.006117820739746
Validation loss: 2.359605781493648

Epoch: 6| Step: 13
Training loss: 2.243340492248535
Validation loss: 2.3781817446472826

Epoch: 67| Step: 0
Training loss: 2.779587984085083
Validation loss: 2.3867018786809777

Epoch: 6| Step: 1
Training loss: 2.9857022762298584
Validation loss: 2.3912779413243777

Epoch: 6| Step: 2
Training loss: 2.249946117401123
Validation loss: 2.3862946494933097

Epoch: 6| Step: 3
Training loss: 3.1451711654663086
Validation loss: 2.3784445178124214

Epoch: 6| Step: 4
Training loss: 2.3388826847076416
Validation loss: 2.3774041052787536

Epoch: 6| Step: 5
Training loss: 2.6861777305603027
Validation loss: 2.3585450239078973

Epoch: 6| Step: 6
Training loss: 1.8330295085906982
Validation loss: 2.3640139615663918

Epoch: 6| Step: 7
Training loss: 2.4792470932006836
Validation loss: 2.363448009696058

Epoch: 6| Step: 8
Training loss: 2.9601244926452637
Validation loss: 2.351651317329817

Epoch: 6| Step: 9
Training loss: 2.2037312984466553
Validation loss: 2.3483744693058792

Epoch: 6| Step: 10
Training loss: 2.6305670738220215
Validation loss: 2.3452207349961802

Epoch: 6| Step: 11
Training loss: 2.811283826828003
Validation loss: 2.3364718191085325

Epoch: 6| Step: 12
Training loss: 2.782924175262451
Validation loss: 2.323653321112356

Epoch: 6| Step: 13
Training loss: 2.0487518310546875
Validation loss: 2.3102309293644403

Epoch: 68| Step: 0
Training loss: 2.6330556869506836
Validation loss: 2.3022902768145324

Epoch: 6| Step: 1
Training loss: 3.095761299133301
Validation loss: 2.3069919360581266

Epoch: 6| Step: 2
Training loss: 2.886385440826416
Validation loss: 2.305820554815313

Epoch: 6| Step: 3
Training loss: 3.162707805633545
Validation loss: 2.3113655339005175

Epoch: 6| Step: 4
Training loss: 2.746095657348633
Validation loss: 2.31197783254808

Epoch: 6| Step: 5
Training loss: 2.877072334289551
Validation loss: 2.3111024620712444

Epoch: 6| Step: 6
Training loss: 2.557130813598633
Validation loss: 2.312560450646185

Epoch: 6| Step: 7
Training loss: 2.1739799976348877
Validation loss: 2.3076486843888477

Epoch: 6| Step: 8
Training loss: 2.536606788635254
Validation loss: 2.308297275215067

Epoch: 6| Step: 9
Training loss: 1.9559953212738037
Validation loss: 2.3028790976411555

Epoch: 6| Step: 10
Training loss: 2.6597883701324463
Validation loss: 2.302793243879913

Epoch: 6| Step: 11
Training loss: 2.036799430847168
Validation loss: 2.309028358869655

Epoch: 6| Step: 12
Training loss: 2.639927625656128
Validation loss: 2.3114805170284805

Epoch: 6| Step: 13
Training loss: 2.0192689895629883
Validation loss: 2.3078951425449823

Epoch: 69| Step: 0
Training loss: 2.892549514770508
Validation loss: 2.31881804620066

Epoch: 6| Step: 1
Training loss: 2.776815176010132
Validation loss: 2.3181198232917377

Epoch: 6| Step: 2
Training loss: 2.080479621887207
Validation loss: 2.328100017322007

Epoch: 6| Step: 3
Training loss: 2.990199565887451
Validation loss: 2.3404445827648206

Epoch: 6| Step: 4
Training loss: 2.3724355697631836
Validation loss: 2.3549011061268468

Epoch: 6| Step: 5
Training loss: 2.400533676147461
Validation loss: 2.3894350938899542

Epoch: 6| Step: 6
Training loss: 2.5293354988098145
Validation loss: 2.4063211269276117

Epoch: 6| Step: 7
Training loss: 2.71671724319458
Validation loss: 2.4274565737734557

Epoch: 6| Step: 8
Training loss: 2.4679737091064453
Validation loss: 2.422180588527392

Epoch: 6| Step: 9
Training loss: 2.437926769256592
Validation loss: 2.4075463228328253

Epoch: 6| Step: 10
Training loss: 2.9422521591186523
Validation loss: 2.4000213094936904

Epoch: 6| Step: 11
Training loss: 2.2402429580688477
Validation loss: 2.391382496844056

Epoch: 6| Step: 12
Training loss: 3.516726016998291
Validation loss: 2.3660122374052643

Epoch: 6| Step: 13
Training loss: 1.2766270637512207
Validation loss: 2.360434565492856

Epoch: 70| Step: 0
Training loss: 2.4487876892089844
Validation loss: 2.3538528898710847

Epoch: 6| Step: 1
Training loss: 2.95143985748291
Validation loss: 2.3559739692236787

Epoch: 6| Step: 2
Training loss: 1.8657606840133667
Validation loss: 2.3657123606692076

Epoch: 6| Step: 3
Training loss: 2.670583963394165
Validation loss: 2.373453314586352

Epoch: 6| Step: 4
Training loss: 2.774801254272461
Validation loss: 2.3684272227748746

Epoch: 6| Step: 5
Training loss: 2.9151105880737305
Validation loss: 2.374931094466999

Epoch: 6| Step: 6
Training loss: 2.631756067276001
Validation loss: 2.3750499115195325

Epoch: 6| Step: 7
Training loss: 2.860415458679199
Validation loss: 2.3813131188833587

Epoch: 6| Step: 8
Training loss: 2.4056997299194336
Validation loss: 2.3721012966607207

Epoch: 6| Step: 9
Training loss: 2.489180088043213
Validation loss: 2.350865010292299

Epoch: 6| Step: 10
Training loss: 2.301276206970215
Validation loss: 2.3415789860551075

Epoch: 6| Step: 11
Training loss: 2.7616584300994873
Validation loss: 2.333471716091197

Epoch: 6| Step: 12
Training loss: 2.725564956665039
Validation loss: 2.335057440624442

Epoch: 6| Step: 13
Training loss: 2.4353740215301514
Validation loss: 2.342825605023292

Epoch: 71| Step: 0
Training loss: 2.5761163234710693
Validation loss: 2.3591928123145975

Epoch: 6| Step: 1
Training loss: 1.8356409072875977
Validation loss: 2.3631281160539195

Epoch: 6| Step: 2
Training loss: 2.416496992111206
Validation loss: 2.3732505408666467

Epoch: 6| Step: 3
Training loss: 2.5142273902893066
Validation loss: 2.3713204655596005

Epoch: 6| Step: 4
Training loss: 2.444481134414673
Validation loss: 2.387276646911457

Epoch: 6| Step: 5
Training loss: 2.8493313789367676
Validation loss: 2.3624026929178545

Epoch: 6| Step: 6
Training loss: 2.391500473022461
Validation loss: 2.333716736044935

Epoch: 6| Step: 7
Training loss: 2.410944700241089
Validation loss: 2.3079881360453944

Epoch: 6| Step: 8
Training loss: 2.80181884765625
Validation loss: 2.3038233890328357

Epoch: 6| Step: 9
Training loss: 3.038292646408081
Validation loss: 2.2934589052713044

Epoch: 6| Step: 10
Training loss: 2.5764687061309814
Validation loss: 2.2929554318868988

Epoch: 6| Step: 11
Training loss: 3.0507476329803467
Validation loss: 2.290409998227191

Epoch: 6| Step: 12
Training loss: 2.524176597595215
Validation loss: 2.293250153141637

Epoch: 6| Step: 13
Training loss: 2.6274523735046387
Validation loss: 2.302103850149339

Epoch: 72| Step: 0
Training loss: 2.9625515937805176
Validation loss: 2.3146359587228424

Epoch: 6| Step: 1
Training loss: 1.951517105102539
Validation loss: 2.317311233089816

Epoch: 6| Step: 2
Training loss: 4.128599643707275
Validation loss: 2.3132861045099076

Epoch: 6| Step: 3
Training loss: 3.5982422828674316
Validation loss: 2.31747192464849

Epoch: 6| Step: 4
Training loss: 2.7050065994262695
Validation loss: 2.3029564093518

Epoch: 6| Step: 5
Training loss: 2.400806427001953
Validation loss: 2.3020148687465216

Epoch: 6| Step: 6
Training loss: 2.1914148330688477
Validation loss: 2.2967282802827897

Epoch: 6| Step: 7
Training loss: 2.3021111488342285
Validation loss: 2.292063174709197

Epoch: 6| Step: 8
Training loss: 2.516788959503174
Validation loss: 2.2952737962045977

Epoch: 6| Step: 9
Training loss: 2.0162830352783203
Validation loss: 2.301390089014525

Epoch: 6| Step: 10
Training loss: 2.9323768615722656
Validation loss: 2.3076823911359234

Epoch: 6| Step: 11
Training loss: 1.8920440673828125
Validation loss: 2.3123626144983436

Epoch: 6| Step: 12
Training loss: 1.6765873432159424
Validation loss: 2.3318569583277546

Epoch: 6| Step: 13
Training loss: 3.1060359477996826
Validation loss: 2.363445512710079

Epoch: 73| Step: 0
Training loss: 2.7778244018554688
Validation loss: 2.4028002985062136

Epoch: 6| Step: 1
Training loss: 2.765932083129883
Validation loss: 2.438575506210327

Epoch: 6| Step: 2
Training loss: 3.090559482574463
Validation loss: 2.4456948170097927

Epoch: 6| Step: 3
Training loss: 2.6752824783325195
Validation loss: 2.4432348461561304

Epoch: 6| Step: 4
Training loss: 2.000300645828247
Validation loss: 2.4327576314249346

Epoch: 6| Step: 5
Training loss: 1.989008903503418
Validation loss: 2.4035307181778776

Epoch: 6| Step: 6
Training loss: 2.3255250453948975
Validation loss: 2.39347243309021

Epoch: 6| Step: 7
Training loss: 2.2658791542053223
Validation loss: 2.381958535922471

Epoch: 6| Step: 8
Training loss: 3.2745161056518555
Validation loss: 2.3720382311010875

Epoch: 6| Step: 9
Training loss: 2.617934465408325
Validation loss: 2.374204369001491

Epoch: 6| Step: 10
Training loss: 2.9764528274536133
Validation loss: 2.3743460819285405

Epoch: 6| Step: 11
Training loss: 1.9759373664855957
Validation loss: 2.3761323139231694

Epoch: 6| Step: 12
Training loss: 2.9562883377075195
Validation loss: 2.367071056878695

Epoch: 6| Step: 13
Training loss: 2.7113349437713623
Validation loss: 2.3667698085948987

Epoch: 74| Step: 0
Training loss: 1.7402604818344116
Validation loss: 2.3519516939757974

Epoch: 6| Step: 1
Training loss: 2.4141287803649902
Validation loss: 2.3468398740214687

Epoch: 6| Step: 2
Training loss: 2.3236894607543945
Validation loss: 2.3276282202812935

Epoch: 6| Step: 3
Training loss: 2.8485565185546875
Validation loss: 2.327163721925469

Epoch: 6| Step: 4
Training loss: 2.0194969177246094
Validation loss: 2.3156969701090167

Epoch: 6| Step: 5
Training loss: 2.389586925506592
Validation loss: 2.314869024420297

Epoch: 6| Step: 6
Training loss: 2.5999319553375244
Validation loss: 2.317117552603445

Epoch: 6| Step: 7
Training loss: 3.068241596221924
Validation loss: 2.312944704486478

Epoch: 6| Step: 8
Training loss: 2.20560359954834
Validation loss: 2.3084138824093725

Epoch: 6| Step: 9
Training loss: 2.636336326599121
Validation loss: 2.3062511926056235

Epoch: 6| Step: 10
Training loss: 3.149260997772217
Validation loss: 2.297257015782018

Epoch: 6| Step: 11
Training loss: 3.0073227882385254
Validation loss: 2.288609577763465

Epoch: 6| Step: 12
Training loss: 2.6976752281188965
Validation loss: 2.288056678669427

Epoch: 6| Step: 13
Training loss: 2.879350423812866
Validation loss: 2.2875515491731706

Epoch: 75| Step: 0
Training loss: 2.8710365295410156
Validation loss: 2.2838683692357873

Epoch: 6| Step: 1
Training loss: 3.220712661743164
Validation loss: 2.2809847708671325

Epoch: 6| Step: 2
Training loss: 2.6335816383361816
Validation loss: 2.284328096656389

Epoch: 6| Step: 3
Training loss: 2.4338831901550293
Validation loss: 2.288443201331682

Epoch: 6| Step: 4
Training loss: 2.372687816619873
Validation loss: 2.292075517357037

Epoch: 6| Step: 5
Training loss: 2.371835947036743
Validation loss: 2.312274166332778

Epoch: 6| Step: 6
Training loss: 2.518415689468384
Validation loss: 2.336787546834638

Epoch: 6| Step: 7
Training loss: 2.08278226852417
Validation loss: 2.3460948928709953

Epoch: 6| Step: 8
Training loss: 2.472480535507202
Validation loss: 2.3876166394961778

Epoch: 6| Step: 9
Training loss: 2.786076545715332
Validation loss: 2.3794555125697965

Epoch: 6| Step: 10
Training loss: 2.973970890045166
Validation loss: 2.3478443289315827

Epoch: 6| Step: 11
Training loss: 3.220959424972534
Validation loss: 2.3091243774660173

Epoch: 6| Step: 12
Training loss: 2.1053619384765625
Validation loss: 2.2951981380421627

Epoch: 6| Step: 13
Training loss: 1.4286757707595825
Validation loss: 2.2863393496441584

Epoch: 76| Step: 0
Training loss: 2.4588112831115723
Validation loss: 2.2713447206763813

Epoch: 6| Step: 1
Training loss: 2.8766226768493652
Validation loss: 2.264871379380585

Epoch: 6| Step: 2
Training loss: 2.0822951793670654
Validation loss: 2.265858204134049

Epoch: 6| Step: 3
Training loss: 2.832998752593994
Validation loss: 2.266779148450462

Epoch: 6| Step: 4
Training loss: 3.450749158859253
Validation loss: 2.269923943345265

Epoch: 6| Step: 5
Training loss: 2.2054636478424072
Validation loss: 2.2742704473515993

Epoch: 6| Step: 6
Training loss: 2.058671712875366
Validation loss: 2.2770624532494494

Epoch: 6| Step: 7
Training loss: 3.024491786956787
Validation loss: 2.2774960123082644

Epoch: 6| Step: 8
Training loss: 2.7152695655822754
Validation loss: 2.281787141676872

Epoch: 6| Step: 9
Training loss: 2.494964599609375
Validation loss: 2.282717468918011

Epoch: 6| Step: 10
Training loss: 2.9929752349853516
Validation loss: 2.287102594170519

Epoch: 6| Step: 11
Training loss: 1.8530064821243286
Validation loss: 2.2939619710368495

Epoch: 6| Step: 12
Training loss: 2.13252329826355
Validation loss: 2.302365060775511

Epoch: 6| Step: 13
Training loss: 2.8304872512817383
Validation loss: 2.3084654013315835

Epoch: 77| Step: 0
Training loss: 2.7685632705688477
Validation loss: 2.316671017677553

Epoch: 6| Step: 1
Training loss: 2.3915505409240723
Validation loss: 2.318670072863179

Epoch: 6| Step: 2
Training loss: 2.7128114700317383
Validation loss: 2.324136972427368

Epoch: 6| Step: 3
Training loss: 3.2891907691955566
Validation loss: 2.3183460440686954

Epoch: 6| Step: 4
Training loss: 3.0593466758728027
Validation loss: 2.3171547766654723

Epoch: 6| Step: 5
Training loss: 2.0452792644500732
Validation loss: 2.3137910878786476

Epoch: 6| Step: 6
Training loss: 2.123722553253174
Validation loss: 2.312977102495009

Epoch: 6| Step: 7
Training loss: 2.1644322872161865
Validation loss: 2.3014330787043416

Epoch: 6| Step: 8
Training loss: 2.765674591064453
Validation loss: 2.3114015133150163

Epoch: 6| Step: 9
Training loss: 2.2231760025024414
Validation loss: 2.308041218788393

Epoch: 6| Step: 10
Training loss: 3.0207982063293457
Validation loss: 2.304983713293588

Epoch: 6| Step: 11
Training loss: 2.4152166843414307
Validation loss: 2.3195663523930374

Epoch: 6| Step: 12
Training loss: 2.135287046432495
Validation loss: 2.3209506978270826

Epoch: 6| Step: 13
Training loss: 2.643183708190918
Validation loss: 2.318320784517514

Epoch: 78| Step: 0
Training loss: 3.062830924987793
Validation loss: 2.309679139044977

Epoch: 6| Step: 1
Training loss: 2.4205515384674072
Validation loss: 2.300507955653693

Epoch: 6| Step: 2
Training loss: 2.4479265213012695
Validation loss: 2.295288714029456

Epoch: 6| Step: 3
Training loss: 2.7368617057800293
Validation loss: 2.28605063756307

Epoch: 6| Step: 4
Training loss: 2.753276824951172
Validation loss: 2.286340562246179

Epoch: 6| Step: 5
Training loss: 2.250917434692383
Validation loss: 2.2825134697780816

Epoch: 6| Step: 6
Training loss: 2.2998414039611816
Validation loss: 2.279089102181055

Epoch: 6| Step: 7
Training loss: 2.3039140701293945
Validation loss: 2.277305926046064

Epoch: 6| Step: 8
Training loss: 2.4992661476135254
Validation loss: 2.2878607575611403

Epoch: 6| Step: 9
Training loss: 2.033048152923584
Validation loss: 2.2896793196278233

Epoch: 6| Step: 10
Training loss: 2.3561203479766846
Validation loss: 2.293880872828986

Epoch: 6| Step: 11
Training loss: 2.6158859729766846
Validation loss: 2.29142044052001

Epoch: 6| Step: 12
Training loss: 2.7905168533325195
Validation loss: 2.286252780627179

Epoch: 6| Step: 13
Training loss: 3.368614673614502
Validation loss: 2.30105730025999

Epoch: 79| Step: 0
Training loss: 2.054379940032959
Validation loss: 2.3089262798268306

Epoch: 6| Step: 1
Training loss: 2.5157012939453125
Validation loss: 2.334438116319718

Epoch: 6| Step: 2
Training loss: 2.8524296283721924
Validation loss: 2.3516095992057555

Epoch: 6| Step: 3
Training loss: 2.337775468826294
Validation loss: 2.3836332726222214

Epoch: 6| Step: 4
Training loss: 2.905667781829834
Validation loss: 2.3877196235041462

Epoch: 6| Step: 5
Training loss: 2.162994384765625
Validation loss: 2.38758026143556

Epoch: 6| Step: 6
Training loss: 2.9604883193969727
Validation loss: 2.38376199430035

Epoch: 6| Step: 7
Training loss: 2.205488681793213
Validation loss: 2.3535046628726426

Epoch: 6| Step: 8
Training loss: 2.4961533546447754
Validation loss: 2.35102322793776

Epoch: 6| Step: 9
Training loss: 2.3608198165893555
Validation loss: 2.351381098070452

Epoch: 6| Step: 10
Training loss: 2.1114745140075684
Validation loss: 2.346354792194982

Epoch: 6| Step: 11
Training loss: 2.9773449897766113
Validation loss: 2.3330783536357265

Epoch: 6| Step: 12
Training loss: 3.7877988815307617
Validation loss: 2.315350624822801

Epoch: 6| Step: 13
Training loss: 1.6962718963623047
Validation loss: 2.2962720855589835

Epoch: 80| Step: 0
Training loss: 2.6044557094573975
Validation loss: 2.2814501741881013

Epoch: 6| Step: 1
Training loss: 2.7084290981292725
Validation loss: 2.2827979441612

Epoch: 6| Step: 2
Training loss: 2.518782615661621
Validation loss: 2.2932114037134315

Epoch: 6| Step: 3
Training loss: 3.001821517944336
Validation loss: 2.2984080571000294

Epoch: 6| Step: 4
Training loss: 2.2889585494995117
Validation loss: 2.2963698089763684

Epoch: 6| Step: 5
Training loss: 2.3461759090423584
Validation loss: 2.2943666096656554

Epoch: 6| Step: 6
Training loss: 2.8243589401245117
Validation loss: 2.290964013786726

Epoch: 6| Step: 7
Training loss: 3.158212661743164
Validation loss: 2.27591343720754

Epoch: 6| Step: 8
Training loss: 2.3902335166931152
Validation loss: 2.273280442401927

Epoch: 6| Step: 9
Training loss: 2.9476983547210693
Validation loss: 2.2698868936108005

Epoch: 6| Step: 10
Training loss: 2.560492992401123
Validation loss: 2.2690491881421817

Epoch: 6| Step: 11
Training loss: 2.111724376678467
Validation loss: 2.26878434611905

Epoch: 6| Step: 12
Training loss: 1.7123191356658936
Validation loss: 2.2900623941934235

Epoch: 6| Step: 13
Training loss: 2.5780253410339355
Validation loss: 2.3069136040185088

Epoch: 81| Step: 0
Training loss: 2.392608165740967
Validation loss: 2.301532801761422

Epoch: 6| Step: 1
Training loss: 2.827436923980713
Validation loss: 2.3041016850420224

Epoch: 6| Step: 2
Training loss: 1.9453892707824707
Validation loss: 2.304329300439486

Epoch: 6| Step: 3
Training loss: 2.3524205684661865
Validation loss: 2.2936662191985757

Epoch: 6| Step: 4
Training loss: 2.4323806762695312
Validation loss: 2.2862612790958856

Epoch: 6| Step: 5
Training loss: 2.8734617233276367
Validation loss: 2.2839826550534976

Epoch: 6| Step: 6
Training loss: 2.919053316116333
Validation loss: 2.272502173659622

Epoch: 6| Step: 7
Training loss: 2.595050096511841
Validation loss: 2.267641628942182

Epoch: 6| Step: 8
Training loss: 2.629760980606079
Validation loss: 2.256011486053467

Epoch: 6| Step: 9
Training loss: 2.9521124362945557
Validation loss: 2.2491234887030815

Epoch: 6| Step: 10
Training loss: 1.9775304794311523
Validation loss: 2.242610449432045

Epoch: 6| Step: 11
Training loss: 2.5655510425567627
Validation loss: 2.2403469239511797

Epoch: 6| Step: 12
Training loss: 2.727004051208496
Validation loss: 2.240668732632873

Epoch: 6| Step: 13
Training loss: 2.2046890258789062
Validation loss: 2.2417505941083355

Epoch: 82| Step: 0
Training loss: 2.6529245376586914
Validation loss: 2.241656223932902

Epoch: 6| Step: 1
Training loss: 1.8932613134384155
Validation loss: 2.242865252238448

Epoch: 6| Step: 2
Training loss: 2.290828227996826
Validation loss: 2.242862411724624

Epoch: 6| Step: 3
Training loss: 2.6779117584228516
Validation loss: 2.247215541460181

Epoch: 6| Step: 4
Training loss: 2.4628117084503174
Validation loss: 2.254120535747979

Epoch: 6| Step: 5
Training loss: 2.681936025619507
Validation loss: 2.254058660999421

Epoch: 6| Step: 6
Training loss: 2.5845470428466797
Validation loss: 2.259305606606186

Epoch: 6| Step: 7
Training loss: 2.196437358856201
Validation loss: 2.2750169333591255

Epoch: 6| Step: 8
Training loss: 3.2682976722717285
Validation loss: 2.2832395748425554

Epoch: 6| Step: 9
Training loss: 2.5047831535339355
Validation loss: 2.2950106436206448

Epoch: 6| Step: 10
Training loss: 2.547163486480713
Validation loss: 2.291841753067509

Epoch: 6| Step: 11
Training loss: 2.24318528175354
Validation loss: 2.284140812453403

Epoch: 6| Step: 12
Training loss: 2.7813148498535156
Validation loss: 2.279926453867266

Epoch: 6| Step: 13
Training loss: 3.279003143310547
Validation loss: 2.270321297389205

Epoch: 83| Step: 0
Training loss: 3.1436309814453125
Validation loss: 2.2695603421939317

Epoch: 6| Step: 1
Training loss: 2.2799980640411377
Validation loss: 2.272017305897128

Epoch: 6| Step: 2
Training loss: 1.4762988090515137
Validation loss: 2.270171152648105

Epoch: 6| Step: 3
Training loss: 1.756034016609192
Validation loss: 2.2650404899351058

Epoch: 6| Step: 4
Training loss: 2.5432469844818115
Validation loss: 2.2636768869174424

Epoch: 6| Step: 5
Training loss: 2.8156704902648926
Validation loss: 2.264817812109506

Epoch: 6| Step: 6
Training loss: 3.01488995552063
Validation loss: 2.264913502559867

Epoch: 6| Step: 7
Training loss: 2.909311294555664
Validation loss: 2.267273520910612

Epoch: 6| Step: 8
Training loss: 1.7970716953277588
Validation loss: 2.2794919526705177

Epoch: 6| Step: 9
Training loss: 2.7146153450012207
Validation loss: 2.2853299545985397

Epoch: 6| Step: 10
Training loss: 3.0436899662017822
Validation loss: 2.284953284007247

Epoch: 6| Step: 11
Training loss: 2.847928524017334
Validation loss: 2.3139831686532624

Epoch: 6| Step: 12
Training loss: 2.9800610542297363
Validation loss: 2.3175152322297454

Epoch: 6| Step: 13
Training loss: 1.847779631614685
Validation loss: 2.3143323595805834

Epoch: 84| Step: 0
Training loss: 2.3905751705169678
Validation loss: 2.29392550581245

Epoch: 6| Step: 1
Training loss: 2.3213930130004883
Validation loss: 2.304380404051914

Epoch: 6| Step: 2
Training loss: 2.4225597381591797
Validation loss: 2.310654363324565

Epoch: 6| Step: 3
Training loss: 2.573321580886841
Validation loss: 2.300237286475397

Epoch: 6| Step: 4
Training loss: 2.9245924949645996
Validation loss: 2.3051098674856205

Epoch: 6| Step: 5
Training loss: 1.9374847412109375
Validation loss: 2.295381720348071

Epoch: 6| Step: 6
Training loss: 2.819544792175293
Validation loss: 2.2716799474531606

Epoch: 6| Step: 7
Training loss: 2.790045738220215
Validation loss: 2.269918813500353

Epoch: 6| Step: 8
Training loss: 2.765718936920166
Validation loss: 2.26621869174383

Epoch: 6| Step: 9
Training loss: 1.7272011041641235
Validation loss: 2.262116498844598

Epoch: 6| Step: 10
Training loss: 2.8950271606445312
Validation loss: 2.259236693382263

Epoch: 6| Step: 11
Training loss: 2.0998599529266357
Validation loss: 2.26183569687669

Epoch: 6| Step: 12
Training loss: 3.189483642578125
Validation loss: 2.2618762293169574

Epoch: 6| Step: 13
Training loss: 2.566835641860962
Validation loss: 2.2622542842741935

Epoch: 85| Step: 0
Training loss: 2.9173150062561035
Validation loss: 2.2587110586063837

Epoch: 6| Step: 1
Training loss: 2.484079122543335
Validation loss: 2.2628426474909626

Epoch: 6| Step: 2
Training loss: 2.266901969909668
Validation loss: 2.259266890505309

Epoch: 6| Step: 3
Training loss: 2.8913755416870117
Validation loss: 2.273789111004081

Epoch: 6| Step: 4
Training loss: 2.4711337089538574
Validation loss: 2.263399167727399

Epoch: 6| Step: 5
Training loss: 2.5330488681793213
Validation loss: 2.2722911347625074

Epoch: 6| Step: 6
Training loss: 2.7017874717712402
Validation loss: 2.274807835137972

Epoch: 6| Step: 7
Training loss: 1.9837275743484497
Validation loss: 2.2781992753346763

Epoch: 6| Step: 8
Training loss: 2.424278736114502
Validation loss: 2.2655781674128708

Epoch: 6| Step: 9
Training loss: 3.0096349716186523
Validation loss: 2.2904927371650614

Epoch: 6| Step: 10
Training loss: 2.3149890899658203
Validation loss: 2.2866687210657264

Epoch: 6| Step: 11
Training loss: 2.826326847076416
Validation loss: 2.288868813104527

Epoch: 6| Step: 12
Training loss: 2.561999797821045
Validation loss: 2.285640529406968

Epoch: 6| Step: 13
Training loss: 1.3878424167633057
Validation loss: 2.283186766409105

Epoch: 86| Step: 0
Training loss: 2.425635814666748
Validation loss: 2.289325370583483

Epoch: 6| Step: 1
Training loss: 2.9500393867492676
Validation loss: 2.2968672321688746

Epoch: 6| Step: 2
Training loss: 2.357403516769409
Validation loss: 2.312819929533107

Epoch: 6| Step: 3
Training loss: 3.1007306575775146
Validation loss: 2.307886549221572

Epoch: 6| Step: 4
Training loss: 2.7848095893859863
Validation loss: 2.2961699629342682

Epoch: 6| Step: 5
Training loss: 2.7327890396118164
Validation loss: 2.271862118474899

Epoch: 6| Step: 6
Training loss: 3.00321102142334
Validation loss: 2.265329853180916

Epoch: 6| Step: 7
Training loss: 2.7387332916259766
Validation loss: 2.262440264865916

Epoch: 6| Step: 8
Training loss: 2.3990039825439453
Validation loss: 2.2629064770155054

Epoch: 6| Step: 9
Training loss: 2.232510566711426
Validation loss: 2.2525237555144937

Epoch: 6| Step: 10
Training loss: 2.3234643936157227
Validation loss: 2.25853999968498

Epoch: 6| Step: 11
Training loss: 2.1501753330230713
Validation loss: 2.2459691929560837

Epoch: 6| Step: 12
Training loss: 1.8811109066009521
Validation loss: 2.2449370045815744

Epoch: 6| Step: 13
Training loss: 1.883735179901123
Validation loss: 2.249079386393229

Epoch: 87| Step: 0
Training loss: 2.44465970993042
Validation loss: 2.254810648579751

Epoch: 6| Step: 1
Training loss: 2.3891587257385254
Validation loss: 2.23951320750739

Epoch: 6| Step: 2
Training loss: 2.5824575424194336
Validation loss: 2.2379925302279893

Epoch: 6| Step: 3
Training loss: 2.881291389465332
Validation loss: 2.240037651472194

Epoch: 6| Step: 4
Training loss: 2.530695915222168
Validation loss: 2.2371765362319125

Epoch: 6| Step: 5
Training loss: 2.4098215103149414
Validation loss: 2.2299453379005514

Epoch: 6| Step: 6
Training loss: 2.1341159343719482
Validation loss: 2.241250635475241

Epoch: 6| Step: 7
Training loss: 1.92693293094635
Validation loss: 2.242362453091529

Epoch: 6| Step: 8
Training loss: 3.397714614868164
Validation loss: 2.249795684250452

Epoch: 6| Step: 9
Training loss: 2.337493419647217
Validation loss: 2.271884056829637

Epoch: 6| Step: 10
Training loss: 2.7308189868927
Validation loss: 2.271312129112982

Epoch: 6| Step: 11
Training loss: 2.5153698921203613
Validation loss: 2.2811561848527644

Epoch: 6| Step: 12
Training loss: 2.657813549041748
Validation loss: 2.280990792858985

Epoch: 6| Step: 13
Training loss: 2.20094895362854
Validation loss: 2.2744996573335383

Epoch: 88| Step: 0
Training loss: 2.5097603797912598
Validation loss: 2.2648018521647297

Epoch: 6| Step: 1
Training loss: 2.670536994934082
Validation loss: 2.2548562019102034

Epoch: 6| Step: 2
Training loss: 2.9724981784820557
Validation loss: 2.2495254188455562

Epoch: 6| Step: 3
Training loss: 2.0731253623962402
Validation loss: 2.242272279595816

Epoch: 6| Step: 4
Training loss: 2.8549914360046387
Validation loss: 2.2405396456359536

Epoch: 6| Step: 5
Training loss: 2.073312759399414
Validation loss: 2.2389387135864585

Epoch: 6| Step: 6
Training loss: 2.426882743835449
Validation loss: 2.238794429327852

Epoch: 6| Step: 7
Training loss: 2.3515748977661133
Validation loss: 2.2362926365226827

Epoch: 6| Step: 8
Training loss: 2.6989212036132812
Validation loss: 2.2402444142167286

Epoch: 6| Step: 9
Training loss: 2.4811325073242188
Validation loss: 2.2426108339781403

Epoch: 6| Step: 10
Training loss: 2.848982810974121
Validation loss: 2.2367891752591698

Epoch: 6| Step: 11
Training loss: 2.300588846206665
Validation loss: 2.242697059467275

Epoch: 6| Step: 12
Training loss: 2.839341402053833
Validation loss: 2.2460449357186594

Epoch: 6| Step: 13
Training loss: 2.0928897857666016
Validation loss: 2.2448302238218245

Epoch: 89| Step: 0
Training loss: 2.2476272583007812
Validation loss: 2.255980278856011

Epoch: 6| Step: 1
Training loss: 2.50620698928833
Validation loss: 2.2629371227756625

Epoch: 6| Step: 2
Training loss: 2.707435369491577
Validation loss: 2.2814806058842647

Epoch: 6| Step: 3
Training loss: 2.4627089500427246
Validation loss: 2.281526868061353

Epoch: 6| Step: 4
Training loss: 2.1990365982055664
Validation loss: 2.2907231469308176

Epoch: 6| Step: 5
Training loss: 3.370527982711792
Validation loss: 2.2972013488892586

Epoch: 6| Step: 6
Training loss: 1.782319188117981
Validation loss: 2.297806368079237

Epoch: 6| Step: 7
Training loss: 2.4087395668029785
Validation loss: 2.2916671537583873

Epoch: 6| Step: 8
Training loss: 2.459027051925659
Validation loss: 2.2765876131673015

Epoch: 6| Step: 9
Training loss: 2.7854204177856445
Validation loss: 2.266466548365931

Epoch: 6| Step: 10
Training loss: 2.8531222343444824
Validation loss: 2.2489734439439673

Epoch: 6| Step: 11
Training loss: 3.1765880584716797
Validation loss: 2.2328094487549155

Epoch: 6| Step: 12
Training loss: 2.0457112789154053
Validation loss: 2.222044196180118

Epoch: 6| Step: 13
Training loss: 1.88819420337677
Validation loss: 2.2264817965927945

Epoch: 90| Step: 0
Training loss: 2.6419997215270996
Validation loss: 2.2258095792544785

Epoch: 6| Step: 1
Training loss: 2.8822059631347656
Validation loss: 2.2311508732457317

Epoch: 6| Step: 2
Training loss: 2.882052183151245
Validation loss: 2.224910789920438

Epoch: 6| Step: 3
Training loss: 3.1739344596862793
Validation loss: 2.2359051037860174

Epoch: 6| Step: 4
Training loss: 2.5642013549804688
Validation loss: 2.2399812206145255

Epoch: 6| Step: 5
Training loss: 2.151810646057129
Validation loss: 2.2535266645493044

Epoch: 6| Step: 6
Training loss: 1.6922078132629395
Validation loss: 2.253994236710251

Epoch: 6| Step: 7
Training loss: 2.4734292030334473
Validation loss: 2.267128908506004

Epoch: 6| Step: 8
Training loss: 2.1804189682006836
Validation loss: 2.2671148648826023

Epoch: 6| Step: 9
Training loss: 2.4147145748138428
Validation loss: 2.2679571900316464

Epoch: 6| Step: 10
Training loss: 2.624903917312622
Validation loss: 2.2640298976693103

Epoch: 6| Step: 11
Training loss: 2.695979118347168
Validation loss: 2.265458163394723

Epoch: 6| Step: 12
Training loss: 2.2859749794006348
Validation loss: 2.2605400508449924

Epoch: 6| Step: 13
Training loss: 2.451516628265381
Validation loss: 2.2456608536422893

Epoch: 91| Step: 0
Training loss: 2.1980886459350586
Validation loss: 2.2466805442687003

Epoch: 6| Step: 1
Training loss: 2.9077401161193848
Validation loss: 2.2442540481526363

Epoch: 6| Step: 2
Training loss: 2.3132874965667725
Validation loss: 2.243214948202974

Epoch: 6| Step: 3
Training loss: 2.621605634689331
Validation loss: 2.2449744209166496

Epoch: 6| Step: 4
Training loss: 2.917949914932251
Validation loss: 2.2568771159777077

Epoch: 6| Step: 5
Training loss: 2.773995876312256
Validation loss: 2.2656155991297897

Epoch: 6| Step: 6
Training loss: 2.8408594131469727
Validation loss: 2.274696465461485

Epoch: 6| Step: 7
Training loss: 2.0156631469726562
Validation loss: 2.2816723341582925

Epoch: 6| Step: 8
Training loss: 2.6225244998931885
Validation loss: 2.2713757304735083

Epoch: 6| Step: 9
Training loss: 2.187859058380127
Validation loss: 2.2866293358546432

Epoch: 6| Step: 10
Training loss: 2.181370496749878
Validation loss: 2.2759551950680312

Epoch: 6| Step: 11
Training loss: 2.7615675926208496
Validation loss: 2.2853128628064225

Epoch: 6| Step: 12
Training loss: 2.2579312324523926
Validation loss: 2.279335114263719

Epoch: 6| Step: 13
Training loss: 2.48409366607666
Validation loss: 2.2673516760590258

Epoch: 92| Step: 0
Training loss: 3.0040688514709473
Validation loss: 2.2520148984847532

Epoch: 6| Step: 1
Training loss: 3.0311951637268066
Validation loss: 2.237319051578481

Epoch: 6| Step: 2
Training loss: 2.8205273151397705
Validation loss: 2.2361941645222325

Epoch: 6| Step: 3
Training loss: 2.2338528633117676
Validation loss: 2.2276761326738583

Epoch: 6| Step: 4
Training loss: 2.5145673751831055
Validation loss: 2.2207135795265116

Epoch: 6| Step: 5
Training loss: 2.8373961448669434
Validation loss: 2.22096908989773

Epoch: 6| Step: 6
Training loss: 2.5638914108276367
Validation loss: 2.217113798664462

Epoch: 6| Step: 7
Training loss: 2.9796814918518066
Validation loss: 2.2193102785336074

Epoch: 6| Step: 8
Training loss: 2.130162239074707
Validation loss: 2.214936610191099

Epoch: 6| Step: 9
Training loss: 1.6355339288711548
Validation loss: 2.217926820119222

Epoch: 6| Step: 10
Training loss: 2.6514477729797363
Validation loss: 2.2184349516386628

Epoch: 6| Step: 11
Training loss: 2.3746466636657715
Validation loss: 2.2160078428124868

Epoch: 6| Step: 12
Training loss: 1.8845059871673584
Validation loss: 2.2182675202687583

Epoch: 6| Step: 13
Training loss: 2.3695104122161865
Validation loss: 2.2280082164272184

Epoch: 93| Step: 0
Training loss: 2.0940780639648438
Validation loss: 2.236465436156078

Epoch: 6| Step: 1
Training loss: 2.8631043434143066
Validation loss: 2.2454974702609483

Epoch: 6| Step: 2
Training loss: 2.5068602561950684
Validation loss: 2.244815839234219

Epoch: 6| Step: 3
Training loss: 2.7290985584259033
Validation loss: 2.25970523588119

Epoch: 6| Step: 4
Training loss: 2.146730899810791
Validation loss: 2.256714483743073

Epoch: 6| Step: 5
Training loss: 1.9448366165161133
Validation loss: 2.26600508920608

Epoch: 6| Step: 6
Training loss: 2.9297308921813965
Validation loss: 2.2610814981563117

Epoch: 6| Step: 7
Training loss: 1.7997949123382568
Validation loss: 2.242502527852212

Epoch: 6| Step: 8
Training loss: 2.9956767559051514
Validation loss: 2.2252965601541663

Epoch: 6| Step: 9
Training loss: 2.5868630409240723
Validation loss: 2.2307782275702364

Epoch: 6| Step: 10
Training loss: 2.0523834228515625
Validation loss: 2.2169632860409316

Epoch: 6| Step: 11
Training loss: 3.0160274505615234
Validation loss: 2.213276445224721

Epoch: 6| Step: 12
Training loss: 2.7262930870056152
Validation loss: 2.217123403344103

Epoch: 6| Step: 13
Training loss: 2.4020097255706787
Validation loss: 2.223690343159501

Epoch: 94| Step: 0
Training loss: 2.3272695541381836
Validation loss: 2.219319353821457

Epoch: 6| Step: 1
Training loss: 2.4577372074127197
Validation loss: 2.228040151698615

Epoch: 6| Step: 2
Training loss: 3.0140771865844727
Validation loss: 2.2254278980275637

Epoch: 6| Step: 3
Training loss: 1.9574391841888428
Validation loss: 2.2326171705799718

Epoch: 6| Step: 4
Training loss: 2.186617374420166
Validation loss: 2.228343886713828

Epoch: 6| Step: 5
Training loss: 2.9378457069396973
Validation loss: 2.2331784027878956

Epoch: 6| Step: 6
Training loss: 2.5586094856262207
Validation loss: 2.233347192887337

Epoch: 6| Step: 7
Training loss: 2.2430429458618164
Validation loss: 2.223422086367043

Epoch: 6| Step: 8
Training loss: 2.3417980670928955
Validation loss: 2.226397257979198

Epoch: 6| Step: 9
Training loss: 1.917590856552124
Validation loss: 2.222357501265823

Epoch: 6| Step: 10
Training loss: 3.1395745277404785
Validation loss: 2.2049276777493056

Epoch: 6| Step: 11
Training loss: 2.9326729774475098
Validation loss: 2.203227348225091

Epoch: 6| Step: 12
Training loss: 2.1433489322662354
Validation loss: 2.2038828429355415

Epoch: 6| Step: 13
Training loss: 2.804751396179199
Validation loss: 2.195220498628514

Epoch: 95| Step: 0
Training loss: 2.6074819564819336
Validation loss: 2.2067525027900614

Epoch: 6| Step: 1
Training loss: 2.3677005767822266
Validation loss: 2.2111687737126506

Epoch: 6| Step: 2
Training loss: 2.3378701210021973
Validation loss: 2.2076737214160222

Epoch: 6| Step: 3
Training loss: 2.105273723602295
Validation loss: 2.2331102471197806

Epoch: 6| Step: 4
Training loss: 2.4221103191375732
Validation loss: 2.2328973534286662

Epoch: 6| Step: 5
Training loss: 1.8338711261749268
Validation loss: 2.236969727341847

Epoch: 6| Step: 6
Training loss: 2.5100555419921875
Validation loss: 2.2323131766370548

Epoch: 6| Step: 7
Training loss: 3.069514751434326
Validation loss: 2.2227698397892777

Epoch: 6| Step: 8
Training loss: 2.7157366275787354
Validation loss: 2.23476069460633

Epoch: 6| Step: 9
Training loss: 2.82474946975708
Validation loss: 2.2281095725233837

Epoch: 6| Step: 10
Training loss: 2.505716323852539
Validation loss: 2.222853850292903

Epoch: 6| Step: 11
Training loss: 2.4541068077087402
Validation loss: 2.2230815938723985

Epoch: 6| Step: 12
Training loss: 2.0907559394836426
Validation loss: 2.210605880265595

Epoch: 6| Step: 13
Training loss: 3.186208963394165
Validation loss: 2.2158029105073664

Epoch: 96| Step: 0
Training loss: 1.9329826831817627
Validation loss: 2.2215018554400374

Epoch: 6| Step: 1
Training loss: 3.1593358516693115
Validation loss: 2.2328144093995452

Epoch: 6| Step: 2
Training loss: 2.918731689453125
Validation loss: 2.2279546645379837

Epoch: 6| Step: 3
Training loss: 2.181558132171631
Validation loss: 2.2337201103087394

Epoch: 6| Step: 4
Training loss: 2.691331386566162
Validation loss: 2.230152517236689

Epoch: 6| Step: 5
Training loss: 2.6676554679870605
Validation loss: 2.223435853117256

Epoch: 6| Step: 6
Training loss: 2.7261545658111572
Validation loss: 2.209106683731079

Epoch: 6| Step: 7
Training loss: 2.6879193782806396
Validation loss: 2.215115593325707

Epoch: 6| Step: 8
Training loss: 2.224902629852295
Validation loss: 2.213857623838609

Epoch: 6| Step: 9
Training loss: 2.677903175354004
Validation loss: 2.2113418950829455

Epoch: 6| Step: 10
Training loss: 2.7136573791503906
Validation loss: 2.2000805383087485

Epoch: 6| Step: 11
Training loss: 2.1539597511291504
Validation loss: 2.1983271696234263

Epoch: 6| Step: 12
Training loss: 1.3415628671646118
Validation loss: 2.2085644070820143

Epoch: 6| Step: 13
Training loss: 2.5734148025512695
Validation loss: 2.210405292049531

Epoch: 97| Step: 0
Training loss: 2.7946360111236572
Validation loss: 2.203610034399135

Epoch: 6| Step: 1
Training loss: 2.1299855709075928
Validation loss: 2.212396098721412

Epoch: 6| Step: 2
Training loss: 3.278529405593872
Validation loss: 2.2115800047433503

Epoch: 6| Step: 3
Training loss: 2.1530587673187256
Validation loss: 2.2156484998682493

Epoch: 6| Step: 4
Training loss: 3.1238136291503906
Validation loss: 2.2194450209217687

Epoch: 6| Step: 5
Training loss: 2.6161584854125977
Validation loss: 2.215807942933934

Epoch: 6| Step: 6
Training loss: 2.4550061225891113
Validation loss: 2.22433074315389

Epoch: 6| Step: 7
Training loss: 2.5048162937164307
Validation loss: 2.2480108173944617

Epoch: 6| Step: 8
Training loss: 2.1102240085601807
Validation loss: 2.2512113919822117

Epoch: 6| Step: 9
Training loss: 2.891162395477295
Validation loss: 2.2848208463320168

Epoch: 6| Step: 10
Training loss: 2.087048053741455
Validation loss: 2.277337581880631

Epoch: 6| Step: 11
Training loss: 1.6976516246795654
Validation loss: 2.2501084625080066

Epoch: 6| Step: 12
Training loss: 2.2526397705078125
Validation loss: 2.2154308801056235

Epoch: 6| Step: 13
Training loss: 2.9184730052948
Validation loss: 2.2065537975680445

Epoch: 98| Step: 0
Training loss: 2.871936798095703
Validation loss: 2.199507797918012

Epoch: 6| Step: 1
Training loss: 3.2825088500976562
Validation loss: 2.194201277148339

Epoch: 6| Step: 2
Training loss: 2.5022659301757812
Validation loss: 2.2013849917278496

Epoch: 6| Step: 3
Training loss: 2.6032938957214355
Validation loss: 2.195301663491034

Epoch: 6| Step: 4
Training loss: 1.8375920057296753
Validation loss: 2.1916916524210284

Epoch: 6| Step: 5
Training loss: 3.024359703063965
Validation loss: 2.189599790880757

Epoch: 6| Step: 6
Training loss: 2.533050537109375
Validation loss: 2.1848011362937187

Epoch: 6| Step: 7
Training loss: 2.5688979625701904
Validation loss: 2.1801739841379146

Epoch: 6| Step: 8
Training loss: 1.947824239730835
Validation loss: 2.177277949548537

Epoch: 6| Step: 9
Training loss: 2.0983328819274902
Validation loss: 2.184793608162993

Epoch: 6| Step: 10
Training loss: 1.4361224174499512
Validation loss: 2.1847281071447555

Epoch: 6| Step: 11
Training loss: 2.0317025184631348
Validation loss: 2.1984310637238207

Epoch: 6| Step: 12
Training loss: 3.3082094192504883
Validation loss: 2.2259151756122546

Epoch: 6| Step: 13
Training loss: 2.8460981845855713
Validation loss: 2.257819019338136

Epoch: 99| Step: 0
Training loss: 1.5419235229492188
Validation loss: 2.2772557299624205

Epoch: 6| Step: 1
Training loss: 2.4281997680664062
Validation loss: 2.2782714213094404

Epoch: 6| Step: 2
Training loss: 2.76637864112854
Validation loss: 2.2446184747962543

Epoch: 6| Step: 3
Training loss: 2.210893154144287
Validation loss: 2.210856654310739

Epoch: 6| Step: 4
Training loss: 2.6863489151000977
Validation loss: 2.20229112204685

Epoch: 6| Step: 5
Training loss: 2.193791627883911
Validation loss: 2.1933026236872517

Epoch: 6| Step: 6
Training loss: 3.1933579444885254
Validation loss: 2.2074961764838106

Epoch: 6| Step: 7
Training loss: 3.0019590854644775
Validation loss: 2.2090362605228218

Epoch: 6| Step: 8
Training loss: 2.702962875366211
Validation loss: 2.2165265032040176

Epoch: 6| Step: 9
Training loss: 1.9759795665740967
Validation loss: 2.203578333700857

Epoch: 6| Step: 10
Training loss: 2.6836671829223633
Validation loss: 2.2134347628521662

Epoch: 6| Step: 11
Training loss: 2.6816787719726562
Validation loss: 2.205931814767981

Epoch: 6| Step: 12
Training loss: 2.463955879211426
Validation loss: 2.205201433550927

Epoch: 6| Step: 13
Training loss: 2.508666515350342
Validation loss: 2.204662540907501

Epoch: 100| Step: 0
Training loss: 2.413421630859375
Validation loss: 2.2142533409980034

Epoch: 6| Step: 1
Training loss: 2.8723177909851074
Validation loss: 2.235547396444505

Epoch: 6| Step: 2
Training loss: 2.0575032234191895
Validation loss: 2.2593150754128732

Epoch: 6| Step: 3
Training loss: 3.018035888671875
Validation loss: 2.291776221285584

Epoch: 6| Step: 4
Training loss: 2.401071310043335
Validation loss: 2.3278661774050806

Epoch: 6| Step: 5
Training loss: 2.4397025108337402
Validation loss: 2.310407110439834

Epoch: 6| Step: 6
Training loss: 2.382835865020752
Validation loss: 2.271993701175977

Epoch: 6| Step: 7
Training loss: 1.9189345836639404
Validation loss: 2.2497494297642864

Epoch: 6| Step: 8
Training loss: 2.393519878387451
Validation loss: 2.2060789215949272

Epoch: 6| Step: 9
Training loss: 2.987440586090088
Validation loss: 2.196920020605928

Epoch: 6| Step: 10
Training loss: 2.7102572917938232
Validation loss: 2.203113035489154

Epoch: 6| Step: 11
Training loss: 2.383410930633545
Validation loss: 2.2295393072148806

Epoch: 6| Step: 12
Training loss: 2.0083096027374268
Validation loss: 2.267848035340668

Epoch: 6| Step: 13
Training loss: 3.339052677154541
Validation loss: 2.2978512420449206

Epoch: 101| Step: 0
Training loss: 2.8178510665893555
Validation loss: 2.2615365892328243

Epoch: 6| Step: 1
Training loss: 2.5812387466430664
Validation loss: 2.235015215412263

Epoch: 6| Step: 2
Training loss: 2.374871253967285
Validation loss: 2.204780255594561

Epoch: 6| Step: 3
Training loss: 2.369720458984375
Validation loss: 2.188655427707139

Epoch: 6| Step: 4
Training loss: 2.630110502243042
Validation loss: 2.188201073677309

Epoch: 6| Step: 5
Training loss: 3.180006742477417
Validation loss: 2.190344220848494

Epoch: 6| Step: 6
Training loss: 2.09289288520813
Validation loss: 2.1896034594505065

Epoch: 6| Step: 7
Training loss: 2.1200642585754395
Validation loss: 2.1906241268239994

Epoch: 6| Step: 8
Training loss: 1.8974720239639282
Validation loss: 2.1944392188902824

Epoch: 6| Step: 9
Training loss: 1.9892432689666748
Validation loss: 2.2012689600708666

Epoch: 6| Step: 10
Training loss: 2.709763526916504
Validation loss: 2.212713223631664

Epoch: 6| Step: 11
Training loss: 2.770052909851074
Validation loss: 2.2166013076741207

Epoch: 6| Step: 12
Training loss: 3.126094341278076
Validation loss: 2.232551864398423

Epoch: 6| Step: 13
Training loss: 1.787087082862854
Validation loss: 2.240197520102224

Epoch: 102| Step: 0
Training loss: 2.226851463317871
Validation loss: 2.225609556321175

Epoch: 6| Step: 1
Training loss: 2.7955994606018066
Validation loss: 2.2280925063676733

Epoch: 6| Step: 2
Training loss: 1.9105573892593384
Validation loss: 2.2228393016322965

Epoch: 6| Step: 3
Training loss: 2.1868677139282227
Validation loss: 2.2252047984830794

Epoch: 6| Step: 4
Training loss: 2.4313127994537354
Validation loss: 2.2251201803966234

Epoch: 6| Step: 5
Training loss: 2.648348808288574
Validation loss: 2.2224395634025655

Epoch: 6| Step: 6
Training loss: 2.3615736961364746
Validation loss: 2.2151351385219122

Epoch: 6| Step: 7
Training loss: 2.3214805126190186
Validation loss: 2.213903022068803

Epoch: 6| Step: 8
Training loss: 2.7653911113739014
Validation loss: 2.2180892857172156

Epoch: 6| Step: 9
Training loss: 2.1380724906921387
Validation loss: 2.2227717343197075

Epoch: 6| Step: 10
Training loss: 2.240957736968994
Validation loss: 2.225126035751835

Epoch: 6| Step: 11
Training loss: 2.837022066116333
Validation loss: 2.2316103673750356

Epoch: 6| Step: 12
Training loss: 3.114471912384033
Validation loss: 2.2503794854687107

Epoch: 6| Step: 13
Training loss: 2.5855772495269775
Validation loss: 2.2568352260897235

Epoch: 103| Step: 0
Training loss: 2.3859243392944336
Validation loss: 2.2377106835765224

Epoch: 6| Step: 1
Training loss: 2.4884285926818848
Validation loss: 2.2151554374284643

Epoch: 6| Step: 2
Training loss: 1.99454665184021
Validation loss: 2.219442308589976

Epoch: 6| Step: 3
Training loss: 2.555617570877075
Validation loss: 2.219883224015595

Epoch: 6| Step: 4
Training loss: 3.0902748107910156
Validation loss: 2.224812589665895

Epoch: 6| Step: 5
Training loss: 2.010237455368042
Validation loss: 2.2160762817628923

Epoch: 6| Step: 6
Training loss: 2.8411130905151367
Validation loss: 2.2247630985834266

Epoch: 6| Step: 7
Training loss: 2.1562113761901855
Validation loss: 2.2264737775248866

Epoch: 6| Step: 8
Training loss: 2.682145595550537
Validation loss: 2.234059064619003

Epoch: 6| Step: 9
Training loss: 2.3603081703186035
Validation loss: 2.2233506018115627

Epoch: 6| Step: 10
Training loss: 2.200265407562256
Validation loss: 2.2274979775951755

Epoch: 6| Step: 11
Training loss: 2.1523733139038086
Validation loss: 2.2140205367918937

Epoch: 6| Step: 12
Training loss: 2.879422664642334
Validation loss: 2.216347163723361

Epoch: 6| Step: 13
Training loss: 2.8822011947631836
Validation loss: 2.1923764187802552

Epoch: 104| Step: 0
Training loss: 2.8372344970703125
Validation loss: 2.1891488618748163

Epoch: 6| Step: 1
Training loss: 2.5560808181762695
Validation loss: 2.1793306745508665

Epoch: 6| Step: 2
Training loss: 2.345322608947754
Validation loss: 2.18009554442539

Epoch: 6| Step: 3
Training loss: 2.7436771392822266
Validation loss: 2.1782608519318285

Epoch: 6| Step: 4
Training loss: 2.517192840576172
Validation loss: 2.180974004089191

Epoch: 6| Step: 5
Training loss: 2.3050668239593506
Validation loss: 2.1919509146803167

Epoch: 6| Step: 6
Training loss: 2.7446556091308594
Validation loss: 2.201282813984861

Epoch: 6| Step: 7
Training loss: 2.2390074729919434
Validation loss: 2.2133306457150366

Epoch: 6| Step: 8
Training loss: 3.1360199451446533
Validation loss: 2.2157095222062964

Epoch: 6| Step: 9
Training loss: 1.1676232814788818
Validation loss: 2.2253427479856756

Epoch: 6| Step: 10
Training loss: 2.2981767654418945
Validation loss: 2.234431420603106

Epoch: 6| Step: 11
Training loss: 2.3250389099121094
Validation loss: 2.2292403328803276

Epoch: 6| Step: 12
Training loss: 2.883056640625
Validation loss: 2.216956120665355

Epoch: 6| Step: 13
Training loss: 2.262744903564453
Validation loss: 2.1977512016091296

Epoch: 105| Step: 0
Training loss: 2.2273738384246826
Validation loss: 2.1790338293198617

Epoch: 6| Step: 1
Training loss: 3.8400321006774902
Validation loss: 2.17268410933915

Epoch: 6| Step: 2
Training loss: 2.10447096824646
Validation loss: 2.1820503293827014

Epoch: 6| Step: 3
Training loss: 1.9995089769363403
Validation loss: 2.1809715686305875

Epoch: 6| Step: 4
Training loss: 2.794619083404541
Validation loss: 2.19203007605768

Epoch: 6| Step: 5
Training loss: 2.5005836486816406
Validation loss: 2.205738934137488

Epoch: 6| Step: 6
Training loss: 2.031708240509033
Validation loss: 2.1933679349960817

Epoch: 6| Step: 7
Training loss: 2.364630937576294
Validation loss: 2.196589039218041

Epoch: 6| Step: 8
Training loss: 2.4883675575256348
Validation loss: 2.186682306310182

Epoch: 6| Step: 9
Training loss: 2.550957202911377
Validation loss: 2.1874581049847346

Epoch: 6| Step: 10
Training loss: 2.7052483558654785
Validation loss: 2.188161911502961

Epoch: 6| Step: 11
Training loss: 2.894685745239258
Validation loss: 2.1871817522151495

Epoch: 6| Step: 12
Training loss: 2.302877902984619
Validation loss: 2.1950106210606073

Epoch: 6| Step: 13
Training loss: 2.2517967224121094
Validation loss: 2.184749751962641

Epoch: 106| Step: 0
Training loss: 2.354510545730591
Validation loss: 2.1757332150654127

Epoch: 6| Step: 1
Training loss: 2.6884963512420654
Validation loss: 2.1735768010539394

Epoch: 6| Step: 2
Training loss: 1.8930141925811768
Validation loss: 2.183616521537945

Epoch: 6| Step: 3
Training loss: 2.578080177307129
Validation loss: 2.193583699964708

Epoch: 6| Step: 4
Training loss: 2.7570881843566895
Validation loss: 2.1991145559536514

Epoch: 6| Step: 5
Training loss: 2.545729637145996
Validation loss: 2.214787507569918

Epoch: 6| Step: 6
Training loss: 1.873066782951355
Validation loss: 2.226205092604442

Epoch: 6| Step: 7
Training loss: 2.0087156295776367
Validation loss: 2.2367733242691203

Epoch: 6| Step: 8
Training loss: 1.8597058057785034
Validation loss: 2.2527999339565152

Epoch: 6| Step: 9
Training loss: 2.7990798950195312
Validation loss: 2.270676077053111

Epoch: 6| Step: 10
Training loss: 3.0090131759643555
Validation loss: 2.270028466819435

Epoch: 6| Step: 11
Training loss: 2.598404884338379
Validation loss: 2.2543738503609934

Epoch: 6| Step: 12
Training loss: 2.8587746620178223
Validation loss: 2.224777780553346

Epoch: 6| Step: 13
Training loss: 3.013777494430542
Validation loss: 2.210399732794813

Epoch: 107| Step: 0
Training loss: 2.6083202362060547
Validation loss: 2.2168724152349655

Epoch: 6| Step: 1
Training loss: 2.0895209312438965
Validation loss: 2.2255354158339964

Epoch: 6| Step: 2
Training loss: 2.6072354316711426
Validation loss: 2.2152898811524913

Epoch: 6| Step: 3
Training loss: 2.64609694480896
Validation loss: 2.212465545182587

Epoch: 6| Step: 4
Training loss: 2.859035015106201
Validation loss: 2.203821474506009

Epoch: 6| Step: 5
Training loss: 2.0885097980499268
Validation loss: 2.2123232092908633

Epoch: 6| Step: 6
Training loss: 2.50032377243042
Validation loss: 2.2034199878733647

Epoch: 6| Step: 7
Training loss: 2.833038091659546
Validation loss: 2.2029814438153337

Epoch: 6| Step: 8
Training loss: 1.9573047161102295
Validation loss: 2.202886055874568

Epoch: 6| Step: 9
Training loss: 2.3272106647491455
Validation loss: 2.206530555602043

Epoch: 6| Step: 10
Training loss: 2.4594783782958984
Validation loss: 2.2129880689805552

Epoch: 6| Step: 11
Training loss: 2.9840283393859863
Validation loss: 2.209651134347403

Epoch: 6| Step: 12
Training loss: 1.944844365119934
Validation loss: 2.21077630084048

Epoch: 6| Step: 13
Training loss: 2.122290849685669
Validation loss: 2.2077438664692703

Epoch: 108| Step: 0
Training loss: 2.910989761352539
Validation loss: 2.1900428520735873

Epoch: 6| Step: 1
Training loss: 1.8960561752319336
Validation loss: 2.186430859309371

Epoch: 6| Step: 2
Training loss: 1.6612226963043213
Validation loss: 2.1881223263279086

Epoch: 6| Step: 3
Training loss: 3.116347312927246
Validation loss: 2.188786345143472

Epoch: 6| Step: 4
Training loss: 1.815653681755066
Validation loss: 2.176474678900934

Epoch: 6| Step: 5
Training loss: 2.890495538711548
Validation loss: 2.182535545800322

Epoch: 6| Step: 6
Training loss: 2.764673948287964
Validation loss: 2.1756827690268077

Epoch: 6| Step: 7
Training loss: 2.8539786338806152
Validation loss: 2.1790622280490015

Epoch: 6| Step: 8
Training loss: 2.9935667514801025
Validation loss: 2.180500445827361

Epoch: 6| Step: 9
Training loss: 2.0760579109191895
Validation loss: 2.1944259802500405

Epoch: 6| Step: 10
Training loss: 2.48944354057312
Validation loss: 2.218384696591285

Epoch: 6| Step: 11
Training loss: 2.6978514194488525
Validation loss: 2.220276850526051

Epoch: 6| Step: 12
Training loss: 1.8814737796783447
Validation loss: 2.220520034913094

Epoch: 6| Step: 13
Training loss: 1.9282574653625488
Validation loss: 2.215054089023221

Epoch: 109| Step: 0
Training loss: 2.005250930786133
Validation loss: 2.2089310871657504

Epoch: 6| Step: 1
Training loss: 2.486823320388794
Validation loss: 2.199896950875559

Epoch: 6| Step: 2
Training loss: 2.7806856632232666
Validation loss: 2.1996991198549987

Epoch: 6| Step: 3
Training loss: 2.1708602905273438
Validation loss: 2.1963478237070064

Epoch: 6| Step: 4
Training loss: 2.415748357772827
Validation loss: 2.1924811153001684

Epoch: 6| Step: 5
Training loss: 2.846592426300049
Validation loss: 2.195096331257974

Epoch: 6| Step: 6
Training loss: 2.3767127990722656
Validation loss: 2.179011498728106

Epoch: 6| Step: 7
Training loss: 1.7808550596237183
Validation loss: 2.1790638944154144

Epoch: 6| Step: 8
Training loss: 1.8745169639587402
Validation loss: 2.176641474487961

Epoch: 6| Step: 9
Training loss: 2.2985377311706543
Validation loss: 2.1767839462526384

Epoch: 6| Step: 10
Training loss: 2.5206520557403564
Validation loss: 2.175051878857356

Epoch: 6| Step: 11
Training loss: 2.4558331966400146
Validation loss: 2.1633588267910864

Epoch: 6| Step: 12
Training loss: 2.854626417160034
Validation loss: 2.159725161008937

Epoch: 6| Step: 13
Training loss: 3.811211109161377
Validation loss: 2.1683205481498473

Epoch: 110| Step: 0
Training loss: 2.552159309387207
Validation loss: 2.192401865477203

Epoch: 6| Step: 1
Training loss: 2.6866157054901123
Validation loss: 2.186930710269559

Epoch: 6| Step: 2
Training loss: 2.1991288661956787
Validation loss: 2.1977155977679836

Epoch: 6| Step: 3
Training loss: 2.3064322471618652
Validation loss: 2.2052312948370494

Epoch: 6| Step: 4
Training loss: 3.1775145530700684
Validation loss: 2.192877813052106

Epoch: 6| Step: 5
Training loss: 2.285742998123169
Validation loss: 2.1804322478591756

Epoch: 6| Step: 6
Training loss: 1.5761725902557373
Validation loss: 2.164427080462056

Epoch: 6| Step: 7
Training loss: 2.8664369583129883
Validation loss: 2.1471756504428003

Epoch: 6| Step: 8
Training loss: 2.471095085144043
Validation loss: 2.145155427276447

Epoch: 6| Step: 9
Training loss: 1.9664703607559204
Validation loss: 2.151113376822523

Epoch: 6| Step: 10
Training loss: 2.6872520446777344
Validation loss: 2.146658412871822

Epoch: 6| Step: 11
Training loss: 1.7073107957839966
Validation loss: 2.142242867459533

Epoch: 6| Step: 12
Training loss: 2.837972640991211
Validation loss: 2.1416598673789733

Epoch: 6| Step: 13
Training loss: 3.162058115005493
Validation loss: 2.1461451092073993

Epoch: 111| Step: 0
Training loss: 2.384737491607666
Validation loss: 2.1530885465683474

Epoch: 6| Step: 1
Training loss: 2.5806660652160645
Validation loss: 2.158797656336138

Epoch: 6| Step: 2
Training loss: 3.2682342529296875
Validation loss: 2.143759733887129

Epoch: 6| Step: 3
Training loss: 2.445890426635742
Validation loss: 2.1389841341203257

Epoch: 6| Step: 4
Training loss: 2.6572024822235107
Validation loss: 2.1355856310936714

Epoch: 6| Step: 5
Training loss: 2.826040267944336
Validation loss: 2.1429357656868557

Epoch: 6| Step: 6
Training loss: 2.120939254760742
Validation loss: 2.1399066076483777

Epoch: 6| Step: 7
Training loss: 1.4444465637207031
Validation loss: 2.1490399388856787

Epoch: 6| Step: 8
Training loss: 1.9727833271026611
Validation loss: 2.1474676286020586

Epoch: 6| Step: 9
Training loss: 2.5704479217529297
Validation loss: 2.147481974735055

Epoch: 6| Step: 10
Training loss: 2.765630006790161
Validation loss: 2.152195402370986

Epoch: 6| Step: 11
Training loss: 2.407589912414551
Validation loss: 2.1576507129976825

Epoch: 6| Step: 12
Training loss: 2.0738742351531982
Validation loss: 2.172045350074768

Epoch: 6| Step: 13
Training loss: 2.5421643257141113
Validation loss: 2.1740739730096634

Epoch: 112| Step: 0
Training loss: 2.315267562866211
Validation loss: 2.168118635813395

Epoch: 6| Step: 1
Training loss: 2.2847137451171875
Validation loss: 2.173154273340779

Epoch: 6| Step: 2
Training loss: 2.2887511253356934
Validation loss: 2.1757535870357225

Epoch: 6| Step: 3
Training loss: 2.85695743560791
Validation loss: 2.181694325580392

Epoch: 6| Step: 4
Training loss: 2.881815195083618
Validation loss: 2.179256619945649

Epoch: 6| Step: 5
Training loss: 2.0858592987060547
Validation loss: 2.2094035943349204

Epoch: 6| Step: 6
Training loss: 2.00276780128479
Validation loss: 2.2162024641549714

Epoch: 6| Step: 7
Training loss: 2.443514347076416
Validation loss: 2.2094799523712485

Epoch: 6| Step: 8
Training loss: 2.3924407958984375
Validation loss: 2.193165825259301

Epoch: 6| Step: 9
Training loss: 2.48172664642334
Validation loss: 2.192181484673613

Epoch: 6| Step: 10
Training loss: 2.426508903503418
Validation loss: 2.1848491725101264

Epoch: 6| Step: 11
Training loss: 2.0034587383270264
Validation loss: 2.1849101102480324

Epoch: 6| Step: 12
Training loss: 3.064307689666748
Validation loss: 2.1851863630356325

Epoch: 6| Step: 13
Training loss: 2.491929769515991
Validation loss: 2.1740396202251477

Epoch: 113| Step: 0
Training loss: 2.6678109169006348
Validation loss: 2.168933637680546

Epoch: 6| Step: 1
Training loss: 2.5043535232543945
Validation loss: 2.1690619966035247

Epoch: 6| Step: 2
Training loss: 2.305325984954834
Validation loss: 2.1640327592049875

Epoch: 6| Step: 3
Training loss: 2.693974018096924
Validation loss: 2.1579388315959642

Epoch: 6| Step: 4
Training loss: 2.4787042140960693
Validation loss: 2.1667644157204577

Epoch: 6| Step: 5
Training loss: 2.5565316677093506
Validation loss: 2.167991861220329

Epoch: 6| Step: 6
Training loss: 2.3267574310302734
Validation loss: 2.1655619580258607

Epoch: 6| Step: 7
Training loss: 3.0681395530700684
Validation loss: 2.1598183954915693

Epoch: 6| Step: 8
Training loss: 1.5037193298339844
Validation loss: 2.156960912930068

Epoch: 6| Step: 9
Training loss: 2.4448282718658447
Validation loss: 2.15677168292384

Epoch: 6| Step: 10
Training loss: 2.3413138389587402
Validation loss: 2.1625420483209754

Epoch: 6| Step: 11
Training loss: 1.9636309146881104
Validation loss: 2.1679633048272904

Epoch: 6| Step: 12
Training loss: 2.6008458137512207
Validation loss: 2.1885583990363666

Epoch: 6| Step: 13
Training loss: 2.666598320007324
Validation loss: 2.214046045016217

Epoch: 114| Step: 0
Training loss: 2.1618878841400146
Validation loss: 2.230539365481305

Epoch: 6| Step: 1
Training loss: 2.6630678176879883
Validation loss: 2.2457079477207635

Epoch: 6| Step: 2
Training loss: 2.2631618976593018
Validation loss: 2.2510179140234507

Epoch: 6| Step: 3
Training loss: 2.7566983699798584
Validation loss: 2.2721770322451027

Epoch: 6| Step: 4
Training loss: 2.5785129070281982
Validation loss: 2.262598036437906

Epoch: 6| Step: 5
Training loss: 2.4096314907073975
Validation loss: 2.2430091416963966

Epoch: 6| Step: 6
Training loss: 2.5203747749328613
Validation loss: 2.2025484115846696

Epoch: 6| Step: 7
Training loss: 2.2733969688415527
Validation loss: 2.2041687991029475

Epoch: 6| Step: 8
Training loss: 1.5987968444824219
Validation loss: 2.197134053835305

Epoch: 6| Step: 9
Training loss: 2.5361545085906982
Validation loss: 2.20235732037534

Epoch: 6| Step: 10
Training loss: 2.366204261779785
Validation loss: 2.2136722533933577

Epoch: 6| Step: 11
Training loss: 2.7292275428771973
Validation loss: 2.206612035792361

Epoch: 6| Step: 12
Training loss: 2.6399245262145996
Validation loss: 2.1982054402751308

Epoch: 6| Step: 13
Training loss: 2.1766817569732666
Validation loss: 2.188416650218348

Epoch: 115| Step: 0
Training loss: 1.6306946277618408
Validation loss: 2.178392643569618

Epoch: 6| Step: 1
Training loss: 2.722588539123535
Validation loss: 2.170558311605966

Epoch: 6| Step: 2
Training loss: 2.135058879852295
Validation loss: 2.1674256760586976

Epoch: 6| Step: 3
Training loss: 2.118212938308716
Validation loss: 2.1672381534371326

Epoch: 6| Step: 4
Training loss: 1.9032416343688965
Validation loss: 2.1758664320873957

Epoch: 6| Step: 5
Training loss: 2.710871696472168
Validation loss: 2.1854171406838203

Epoch: 6| Step: 6
Training loss: 2.560487747192383
Validation loss: 2.2031198265731975

Epoch: 6| Step: 7
Training loss: 2.696038007736206
Validation loss: 2.2083796249922885

Epoch: 6| Step: 8
Training loss: 2.5981597900390625
Validation loss: 2.208652409174109

Epoch: 6| Step: 9
Training loss: 2.36445689201355
Validation loss: 2.2026970822324037

Epoch: 6| Step: 10
Training loss: 2.546225070953369
Validation loss: 2.1873930833672963

Epoch: 6| Step: 11
Training loss: 3.078915596008301
Validation loss: 2.1793885756564397

Epoch: 6| Step: 12
Training loss: 2.5373237133026123
Validation loss: 2.1719473613205778

Epoch: 6| Step: 13
Training loss: 2.189873218536377
Validation loss: 2.1780752751135055

Epoch: 116| Step: 0
Training loss: 2.3586208820343018
Validation loss: 2.1699391295832973

Epoch: 6| Step: 1
Training loss: 2.7425427436828613
Validation loss: 2.172264145266625

Epoch: 6| Step: 2
Training loss: 2.2190258502960205
Validation loss: 2.172365052725679

Epoch: 6| Step: 3
Training loss: 2.5408430099487305
Validation loss: 2.1903938426766345

Epoch: 6| Step: 4
Training loss: 2.973987579345703
Validation loss: 2.194580906180925

Epoch: 6| Step: 5
Training loss: 2.1573567390441895
Validation loss: 2.2040521278176257

Epoch: 6| Step: 6
Training loss: 2.80629301071167
Validation loss: 2.1982868230471047

Epoch: 6| Step: 7
Training loss: 2.706296443939209
Validation loss: 2.193226193868986

Epoch: 6| Step: 8
Training loss: 2.239539384841919
Validation loss: 2.1645974600186912

Epoch: 6| Step: 9
Training loss: 2.1478238105773926
Validation loss: 2.1494775164511895

Epoch: 6| Step: 10
Training loss: 2.6092567443847656
Validation loss: 2.1391679676630164

Epoch: 6| Step: 11
Training loss: 2.118011951446533
Validation loss: 2.149017195547781

Epoch: 6| Step: 12
Training loss: 2.5143144130706787
Validation loss: 2.152755232267482

Epoch: 6| Step: 13
Training loss: 1.6212249994277954
Validation loss: 2.1490681607236146

Epoch: 117| Step: 0
Training loss: 2.5061850547790527
Validation loss: 2.1657224983297367

Epoch: 6| Step: 1
Training loss: 2.9149258136749268
Validation loss: 2.2019113981595604

Epoch: 6| Step: 2
Training loss: 2.2697041034698486
Validation loss: 2.213312277229883

Epoch: 6| Step: 3
Training loss: 2.3224124908447266
Validation loss: 2.195870427675145

Epoch: 6| Step: 4
Training loss: 2.432877540588379
Validation loss: 2.189741047479773

Epoch: 6| Step: 5
Training loss: 2.043318271636963
Validation loss: 2.196094064302342

Epoch: 6| Step: 6
Training loss: 3.0856077671051025
Validation loss: 2.1850019449828775

Epoch: 6| Step: 7
Training loss: 2.7865028381347656
Validation loss: 2.1707448984986994

Epoch: 6| Step: 8
Training loss: 2.18393611907959
Validation loss: 2.1569983831015964

Epoch: 6| Step: 9
Training loss: 2.1042394638061523
Validation loss: 2.166068184760309

Epoch: 6| Step: 10
Training loss: 2.707252264022827
Validation loss: 2.1757310282799507

Epoch: 6| Step: 11
Training loss: 2.1678357124328613
Validation loss: 2.1815980929200367

Epoch: 6| Step: 12
Training loss: 2.364711046218872
Validation loss: 2.200891210186866

Epoch: 6| Step: 13
Training loss: 1.605303406715393
Validation loss: 2.20179993619201

Epoch: 118| Step: 0
Training loss: 2.268787384033203
Validation loss: 2.201236165979857

Epoch: 6| Step: 1
Training loss: 2.634289026260376
Validation loss: 2.1936069791034987

Epoch: 6| Step: 2
Training loss: 3.0865395069122314
Validation loss: 2.1797699774465253

Epoch: 6| Step: 3
Training loss: 2.664144992828369
Validation loss: 2.16948769041287

Epoch: 6| Step: 4
Training loss: 2.2429752349853516
Validation loss: 2.172107204314201

Epoch: 6| Step: 5
Training loss: 2.041194200515747
Validation loss: 2.172506324706539

Epoch: 6| Step: 6
Training loss: 2.5551772117614746
Validation loss: 2.1709796062079807

Epoch: 6| Step: 7
Training loss: 2.421628475189209
Validation loss: 2.1692986719069944

Epoch: 6| Step: 8
Training loss: 2.229595184326172
Validation loss: 2.1592971740230436

Epoch: 6| Step: 9
Training loss: 2.2640628814697266
Validation loss: 2.1563670942860265

Epoch: 6| Step: 10
Training loss: 2.652334213256836
Validation loss: 2.148863233545775

Epoch: 6| Step: 11
Training loss: 2.2913661003112793
Validation loss: 2.158677911245695

Epoch: 6| Step: 12
Training loss: 2.3362033367156982
Validation loss: 2.1540599253869828

Epoch: 6| Step: 13
Training loss: 1.6032098531723022
Validation loss: 2.1595779054908344

Epoch: 119| Step: 0
Training loss: 3.0131936073303223
Validation loss: 2.1698836639363277

Epoch: 6| Step: 1
Training loss: 2.074169158935547
Validation loss: 2.181399204397714

Epoch: 6| Step: 2
Training loss: 2.9183199405670166
Validation loss: 2.186841949339836

Epoch: 6| Step: 3
Training loss: 2.7819604873657227
Validation loss: 2.1782849360537786

Epoch: 6| Step: 4
Training loss: 2.4639275074005127
Validation loss: 2.1708969121338217

Epoch: 6| Step: 5
Training loss: 1.794830322265625
Validation loss: 2.158180862344721

Epoch: 6| Step: 6
Training loss: 1.9160634279251099
Validation loss: 2.1635399710747505

Epoch: 6| Step: 7
Training loss: 2.232947826385498
Validation loss: 2.173254346334806

Epoch: 6| Step: 8
Training loss: 2.01741361618042
Validation loss: 2.183849826935799

Epoch: 6| Step: 9
Training loss: 2.0118370056152344
Validation loss: 2.2065584659576416

Epoch: 6| Step: 10
Training loss: 2.522963762283325
Validation loss: 2.217721744250226

Epoch: 6| Step: 11
Training loss: 2.15895676612854
Validation loss: 2.2220041162224224

Epoch: 6| Step: 12
Training loss: 2.3975977897644043
Validation loss: 2.211731928651051

Epoch: 6| Step: 13
Training loss: 3.880039691925049
Validation loss: 2.1966364870789232

Epoch: 120| Step: 0
Training loss: 2.154230833053589
Validation loss: 2.181550533540787

Epoch: 6| Step: 1
Training loss: 2.2893195152282715
Validation loss: 2.151737154171031

Epoch: 6| Step: 2
Training loss: 2.2034430503845215
Validation loss: 2.137126802116312

Epoch: 6| Step: 3
Training loss: 2.7741856575012207
Validation loss: 2.1313919559601815

Epoch: 6| Step: 4
Training loss: 2.8207814693450928
Validation loss: 2.1354981827479538

Epoch: 6| Step: 5
Training loss: 1.6727243661880493
Validation loss: 2.151356251009049

Epoch: 6| Step: 6
Training loss: 2.4086031913757324
Validation loss: 2.153915274527765

Epoch: 6| Step: 7
Training loss: 1.9869414567947388
Validation loss: 2.174382104668566

Epoch: 6| Step: 8
Training loss: 2.7867250442504883
Validation loss: 2.171221717711418

Epoch: 6| Step: 9
Training loss: 2.643005847930908
Validation loss: 2.173200531672406

Epoch: 6| Step: 10
Training loss: 2.4683480262756348
Validation loss: 2.1684729796583935

Epoch: 6| Step: 11
Training loss: 2.4561524391174316
Validation loss: 2.1715916267005344

Epoch: 6| Step: 12
Training loss: 2.943337917327881
Validation loss: 2.1720497608184814

Epoch: 6| Step: 13
Training loss: 2.3744630813598633
Validation loss: 2.149894586173437

Epoch: 121| Step: 0
Training loss: 2.3509981632232666
Validation loss: 2.1552646698490268

Epoch: 6| Step: 1
Training loss: 2.325091600418091
Validation loss: 2.147960388532249

Epoch: 6| Step: 2
Training loss: 2.7546534538269043
Validation loss: 2.156599283218384

Epoch: 6| Step: 3
Training loss: 2.1710140705108643
Validation loss: 2.175970140323844

Epoch: 6| Step: 4
Training loss: 2.320518970489502
Validation loss: 2.2039222691648748

Epoch: 6| Step: 5
Training loss: 2.6815524101257324
Validation loss: 2.2030475677982455

Epoch: 6| Step: 6
Training loss: 2.2237470149993896
Validation loss: 2.190698577511695

Epoch: 6| Step: 7
Training loss: 1.7741029262542725
Validation loss: 2.1847929467437086

Epoch: 6| Step: 8
Training loss: 2.926325559616089
Validation loss: 2.150777586044804

Epoch: 6| Step: 9
Training loss: 1.836725115776062
Validation loss: 2.1481069685310445

Epoch: 6| Step: 10
Training loss: 2.270750045776367
Validation loss: 2.1481771328115977

Epoch: 6| Step: 11
Training loss: 2.32820463180542
Validation loss: 2.1409578387455275

Epoch: 6| Step: 12
Training loss: 2.9404377937316895
Validation loss: 2.1367574712281585

Epoch: 6| Step: 13
Training loss: 2.957157611846924
Validation loss: 2.1342172648317073

Epoch: 122| Step: 0
Training loss: 1.7814971208572388
Validation loss: 2.1326391799475557

Epoch: 6| Step: 1
Training loss: 2.8257784843444824
Validation loss: 2.13753423383159

Epoch: 6| Step: 2
Training loss: 2.0998635292053223
Validation loss: 2.1404602450709187

Epoch: 6| Step: 3
Training loss: 3.1590912342071533
Validation loss: 2.148816059994441

Epoch: 6| Step: 4
Training loss: 2.62310791015625
Validation loss: 2.177070968894548

Epoch: 6| Step: 5
Training loss: 2.6836814880371094
Validation loss: 2.187669102863599

Epoch: 6| Step: 6
Training loss: 1.9680564403533936
Validation loss: 2.1838687581400715

Epoch: 6| Step: 7
Training loss: 2.493499279022217
Validation loss: 2.187927182002734

Epoch: 6| Step: 8
Training loss: 1.7722899913787842
Validation loss: 2.1940767149771414

Epoch: 6| Step: 9
Training loss: 2.5369081497192383
Validation loss: 2.2075127837478474

Epoch: 6| Step: 10
Training loss: 2.433769464492798
Validation loss: 2.2096909566592147

Epoch: 6| Step: 11
Training loss: 2.1626498699188232
Validation loss: 2.2126514373287076

Epoch: 6| Step: 12
Training loss: 2.0901732444763184
Validation loss: 2.202102809823969

Epoch: 6| Step: 13
Training loss: 2.585873603820801
Validation loss: 2.211020167155932

Epoch: 123| Step: 0
Training loss: 2.8258185386657715
Validation loss: 2.2099230161277195

Epoch: 6| Step: 1
Training loss: 2.0609681606292725
Validation loss: 2.217503668159567

Epoch: 6| Step: 2
Training loss: 2.3221616744995117
Validation loss: 2.209142851573165

Epoch: 6| Step: 3
Training loss: 2.8293731212615967
Validation loss: 2.2063062601192023

Epoch: 6| Step: 4
Training loss: 2.5024991035461426
Validation loss: 2.1874096419221614

Epoch: 6| Step: 5
Training loss: 2.190896987915039
Validation loss: 2.1777011245809574

Epoch: 6| Step: 6
Training loss: 2.210111141204834
Validation loss: 2.1593872411276704

Epoch: 6| Step: 7
Training loss: 2.735835075378418
Validation loss: 2.158660131116067

Epoch: 6| Step: 8
Training loss: 2.3617820739746094
Validation loss: 2.151261270687144

Epoch: 6| Step: 9
Training loss: 1.619952917098999
Validation loss: 2.153489828109741

Epoch: 6| Step: 10
Training loss: 2.9322495460510254
Validation loss: 2.1532284136741393

Epoch: 6| Step: 11
Training loss: 1.9234333038330078
Validation loss: 2.147219950152982

Epoch: 6| Step: 12
Training loss: 2.9010510444641113
Validation loss: 2.152178669488558

Epoch: 6| Step: 13
Training loss: 1.4727956056594849
Validation loss: 2.154183563365731

Epoch: 124| Step: 0
Training loss: 2.2540154457092285
Validation loss: 2.171679748001919

Epoch: 6| Step: 1
Training loss: 3.063117265701294
Validation loss: 2.1756431453971454

Epoch: 6| Step: 2
Training loss: 2.812692165374756
Validation loss: 2.201354403649607

Epoch: 6| Step: 3
Training loss: 1.7448581457138062
Validation loss: 2.213374275033192

Epoch: 6| Step: 4
Training loss: 2.116763114929199
Validation loss: 2.219534512489073

Epoch: 6| Step: 5
Training loss: 2.4596800804138184
Validation loss: 2.2058247725168862

Epoch: 6| Step: 6
Training loss: 3.3754971027374268
Validation loss: 2.212210944903794

Epoch: 6| Step: 7
Training loss: 2.2339203357696533
Validation loss: 2.209154631501885

Epoch: 6| Step: 8
Training loss: 2.140502691268921
Validation loss: 2.18933867895475

Epoch: 6| Step: 9
Training loss: 1.8996376991271973
Validation loss: 2.1680063175898727

Epoch: 6| Step: 10
Training loss: 2.653930187225342
Validation loss: 2.163441235019315

Epoch: 6| Step: 11
Training loss: 2.4962406158447266
Validation loss: 2.15243342614943

Epoch: 6| Step: 12
Training loss: 1.8053162097930908
Validation loss: 2.1474742927858905

Epoch: 6| Step: 13
Training loss: 2.0838871002197266
Validation loss: 2.1434796317931144

Epoch: 125| Step: 0
Training loss: 1.7970983982086182
Validation loss: 2.1333733233072425

Epoch: 6| Step: 1
Training loss: 2.3442654609680176
Validation loss: 2.139492916804488

Epoch: 6| Step: 2
Training loss: 3.0053296089172363
Validation loss: 2.131799385111819

Epoch: 6| Step: 3
Training loss: 2.4183926582336426
Validation loss: 2.1336099486197195

Epoch: 6| Step: 4
Training loss: 2.2130298614501953
Validation loss: 2.135189688333901

Epoch: 6| Step: 5
Training loss: 2.678074359893799
Validation loss: 2.1287707269832654

Epoch: 6| Step: 6
Training loss: 1.972217321395874
Validation loss: 2.1439985690578336

Epoch: 6| Step: 7
Training loss: 1.5987910032272339
Validation loss: 2.15956175199119

Epoch: 6| Step: 8
Training loss: 2.673203468322754
Validation loss: 2.1686695057858705

Epoch: 6| Step: 9
Training loss: 2.4735493659973145
Validation loss: 2.1910203836297475

Epoch: 6| Step: 10
Training loss: 2.0444207191467285
Validation loss: 2.2060303893140567

Epoch: 6| Step: 11
Training loss: 2.5877819061279297
Validation loss: 2.2131275823039394

Epoch: 6| Step: 12
Training loss: 3.2631759643554688
Validation loss: 2.2274267724765244

Epoch: 6| Step: 13
Training loss: 2.0201330184936523
Validation loss: 2.208913487772788

Epoch: 126| Step: 0
Training loss: 2.3031184673309326
Validation loss: 2.191832547546715

Epoch: 6| Step: 1
Training loss: 1.8461440801620483
Validation loss: 2.1885365260544645

Epoch: 6| Step: 2
Training loss: 2.2530996799468994
Validation loss: 2.174817624912467

Epoch: 6| Step: 3
Training loss: 2.938770294189453
Validation loss: 2.150597228798815

Epoch: 6| Step: 4
Training loss: 2.046337604522705
Validation loss: 2.1343788216190953

Epoch: 6| Step: 5
Training loss: 2.5740303993225098
Validation loss: 2.129795984555316

Epoch: 6| Step: 6
Training loss: 2.087353467941284
Validation loss: 2.1321778733243226

Epoch: 6| Step: 7
Training loss: 2.8695881366729736
Validation loss: 2.145333848973756

Epoch: 6| Step: 8
Training loss: 1.9946011304855347
Validation loss: 2.14516205428749

Epoch: 6| Step: 9
Training loss: 2.8685431480407715
Validation loss: 2.1543808906309065

Epoch: 6| Step: 10
Training loss: 1.830336332321167
Validation loss: 2.1624284213589084

Epoch: 6| Step: 11
Training loss: 2.821237802505493
Validation loss: 2.162874653775205

Epoch: 6| Step: 12
Training loss: 2.72936749458313
Validation loss: 2.1783295113553285

Epoch: 6| Step: 13
Training loss: 2.468130111694336
Validation loss: 2.190381770492882

Epoch: 127| Step: 0
Training loss: 2.0767972469329834
Validation loss: 2.1849498261687574

Epoch: 6| Step: 1
Training loss: 2.7710394859313965
Validation loss: 2.179383753448404

Epoch: 6| Step: 2
Training loss: 2.933821201324463
Validation loss: 2.158452808216054

Epoch: 6| Step: 3
Training loss: 2.4600276947021484
Validation loss: 2.159014053242181

Epoch: 6| Step: 4
Training loss: 2.018500804901123
Validation loss: 2.1529658379093295

Epoch: 6| Step: 5
Training loss: 2.5889534950256348
Validation loss: 2.148271414541429

Epoch: 6| Step: 6
Training loss: 2.7976231575012207
Validation loss: 2.166986616708899

Epoch: 6| Step: 7
Training loss: 2.118546485900879
Validation loss: 2.1656663187088503

Epoch: 6| Step: 8
Training loss: 1.672682762145996
Validation loss: 2.2064503418501986

Epoch: 6| Step: 9
Training loss: 2.312622547149658
Validation loss: 2.2397744835063977

Epoch: 6| Step: 10
Training loss: 2.066683530807495
Validation loss: 2.2591125862572783

Epoch: 6| Step: 11
Training loss: 3.1629419326782227
Validation loss: 2.2865082217801

Epoch: 6| Step: 12
Training loss: 1.6948931217193604
Validation loss: 2.2339251861777356

Epoch: 6| Step: 13
Training loss: 2.9717323780059814
Validation loss: 2.18787569128057

Epoch: 128| Step: 0
Training loss: 2.087324619293213
Validation loss: 2.1550651211892404

Epoch: 6| Step: 1
Training loss: 1.7507487535476685
Validation loss: 2.135986863925893

Epoch: 6| Step: 2
Training loss: 2.006397247314453
Validation loss: 2.13394017757908

Epoch: 6| Step: 3
Training loss: 2.8223037719726562
Validation loss: 2.1311972243811494

Epoch: 6| Step: 4
Training loss: 2.8240177631378174
Validation loss: 2.1309706575127056

Epoch: 6| Step: 5
Training loss: 2.4501922130584717
Validation loss: 2.121942666269118

Epoch: 6| Step: 6
Training loss: 2.2785940170288086
Validation loss: 2.1229675123768468

Epoch: 6| Step: 7
Training loss: 1.7446558475494385
Validation loss: 2.122357791469943

Epoch: 6| Step: 8
Training loss: 2.972095012664795
Validation loss: 2.1237393002356253

Epoch: 6| Step: 9
Training loss: 1.5884346961975098
Validation loss: 2.1232801252795803

Epoch: 6| Step: 10
Training loss: 2.5129241943359375
Validation loss: 2.1341062899558776

Epoch: 6| Step: 11
Training loss: 2.9801628589630127
Validation loss: 2.141896181209113

Epoch: 6| Step: 12
Training loss: 2.2138071060180664
Validation loss: 2.146928702631304

Epoch: 6| Step: 13
Training loss: 2.9487736225128174
Validation loss: 2.1555772084061817

Epoch: 129| Step: 0
Training loss: 2.210433006286621
Validation loss: 2.1806873531751734

Epoch: 6| Step: 1
Training loss: 2.405505657196045
Validation loss: 2.192087309334868

Epoch: 6| Step: 2
Training loss: 2.5194156169891357
Validation loss: 2.20636837456816

Epoch: 6| Step: 3
Training loss: 2.098773956298828
Validation loss: 2.1947606763532086

Epoch: 6| Step: 4
Training loss: 2.9238779544830322
Validation loss: 2.177416414342901

Epoch: 6| Step: 5
Training loss: 2.420743465423584
Validation loss: 2.158379318893597

Epoch: 6| Step: 6
Training loss: 1.925220251083374
Validation loss: 2.143712000180316

Epoch: 6| Step: 7
Training loss: 2.405292510986328
Validation loss: 2.143942356109619

Epoch: 6| Step: 8
Training loss: 2.3534092903137207
Validation loss: 2.132671320310203

Epoch: 6| Step: 9
Training loss: 1.9873802661895752
Validation loss: 2.128590945274599

Epoch: 6| Step: 10
Training loss: 2.7377562522888184
Validation loss: 2.1273637125569005

Epoch: 6| Step: 11
Training loss: 2.3046252727508545
Validation loss: 2.130233198083857

Epoch: 6| Step: 12
Training loss: 2.4773383140563965
Validation loss: 2.1294091811744114

Epoch: 6| Step: 13
Training loss: 2.0793375968933105
Validation loss: 2.13034773642017

Epoch: 130| Step: 0
Training loss: 2.434277057647705
Validation loss: 2.132651716150263

Epoch: 6| Step: 1
Training loss: 2.6639811992645264
Validation loss: 2.14325931379872

Epoch: 6| Step: 2
Training loss: 2.3784098625183105
Validation loss: 2.139965511137439

Epoch: 6| Step: 3
Training loss: 1.7803376913070679
Validation loss: 2.1490873803374586

Epoch: 6| Step: 4
Training loss: 2.8926568031311035
Validation loss: 2.1426315666526876

Epoch: 6| Step: 5
Training loss: 2.6350860595703125
Validation loss: 2.154361342871061

Epoch: 6| Step: 6
Training loss: 2.304710865020752
Validation loss: 2.1594733653529996

Epoch: 6| Step: 7
Training loss: 2.428100824356079
Validation loss: 2.1633821431026665

Epoch: 6| Step: 8
Training loss: 2.0047903060913086
Validation loss: 2.1858104377664547

Epoch: 6| Step: 9
Training loss: 3.0997166633605957
Validation loss: 2.180483950081692

Epoch: 6| Step: 10
Training loss: 2.287144184112549
Validation loss: 2.2022601789043796

Epoch: 6| Step: 11
Training loss: 2.298150062561035
Validation loss: 2.210889821411461

Epoch: 6| Step: 12
Training loss: 1.377309799194336
Validation loss: 2.2026722508092083

Epoch: 6| Step: 13
Training loss: 2.137669801712036
Validation loss: 2.2049559880328435

Epoch: 131| Step: 0
Training loss: 2.235909938812256
Validation loss: 2.2084881208276235

Epoch: 6| Step: 1
Training loss: 2.042818546295166
Validation loss: 2.1932075190287765

Epoch: 6| Step: 2
Training loss: 2.1733741760253906
Validation loss: 2.191185639750573

Epoch: 6| Step: 3
Training loss: 2.1379871368408203
Validation loss: 2.1752294776260213

Epoch: 6| Step: 4
Training loss: 2.504103660583496
Validation loss: 2.1738287120737056

Epoch: 6| Step: 5
Training loss: 2.7586722373962402
Validation loss: 2.163498363187236

Epoch: 6| Step: 6
Training loss: 2.9502241611480713
Validation loss: 2.1661639546835296

Epoch: 6| Step: 7
Training loss: 2.939263343811035
Validation loss: 2.1426226426196355

Epoch: 6| Step: 8
Training loss: 1.5613878965377808
Validation loss: 2.135382695864606

Epoch: 6| Step: 9
Training loss: 2.0579171180725098
Validation loss: 2.1351354045252644

Epoch: 6| Step: 10
Training loss: 1.8535094261169434
Validation loss: 2.1397700348208026

Epoch: 6| Step: 11
Training loss: 2.8163089752197266
Validation loss: 2.1453219998267388

Epoch: 6| Step: 12
Training loss: 2.0431935787200928
Validation loss: 2.1358283091616888

Epoch: 6| Step: 13
Training loss: 3.0995800495147705
Validation loss: 2.119118703308926

Epoch: 132| Step: 0
Training loss: 2.2424657344818115
Validation loss: 2.1303014319430114

Epoch: 6| Step: 1
Training loss: 2.10683536529541
Validation loss: 2.126209265442305

Epoch: 6| Step: 2
Training loss: 1.3780615329742432
Validation loss: 2.122747980138307

Epoch: 6| Step: 3
Training loss: 2.8560800552368164
Validation loss: 2.1250773745198406

Epoch: 6| Step: 4
Training loss: 2.5785248279571533
Validation loss: 2.1282012462615967

Epoch: 6| Step: 5
Training loss: 2.0954713821411133
Validation loss: 2.125179562517392

Epoch: 6| Step: 6
Training loss: 2.3292064666748047
Validation loss: 2.128541822074562

Epoch: 6| Step: 7
Training loss: 2.3270411491394043
Validation loss: 2.128343000206896

Epoch: 6| Step: 8
Training loss: 2.38871169090271
Validation loss: 2.1286246763762606

Epoch: 6| Step: 9
Training loss: 2.8829870223999023
Validation loss: 2.1233944380155174

Epoch: 6| Step: 10
Training loss: 2.3655335903167725
Validation loss: 2.1210010256818546

Epoch: 6| Step: 11
Training loss: 2.063108444213867
Validation loss: 2.1142310724463513

Epoch: 6| Step: 12
Training loss: 2.4680285453796387
Validation loss: 2.1081200543270318

Epoch: 6| Step: 13
Training loss: 2.7459752559661865
Validation loss: 2.1070767397521646

Epoch: 133| Step: 0
Training loss: 2.6779561042785645
Validation loss: 2.107306771380927

Epoch: 6| Step: 1
Training loss: 2.8058371543884277
Validation loss: 2.119005649320541

Epoch: 6| Step: 2
Training loss: 2.206888437271118
Validation loss: 2.11946185686255

Epoch: 6| Step: 3
Training loss: 2.4374027252197266
Validation loss: 2.118336969806302

Epoch: 6| Step: 4
Training loss: 1.9745725393295288
Validation loss: 2.116972666914745

Epoch: 6| Step: 5
Training loss: 2.540148973464966
Validation loss: 2.1137694440862185

Epoch: 6| Step: 6
Training loss: 2.7709689140319824
Validation loss: 2.103808492742559

Epoch: 6| Step: 7
Training loss: 1.5733938217163086
Validation loss: 2.1058981598064466

Epoch: 6| Step: 8
Training loss: 2.4958462715148926
Validation loss: 2.11650941705191

Epoch: 6| Step: 9
Training loss: 1.880831003189087
Validation loss: 2.1157468980358494

Epoch: 6| Step: 10
Training loss: 2.1120047569274902
Validation loss: 2.1224654361765873

Epoch: 6| Step: 11
Training loss: 2.775982141494751
Validation loss: 2.110390906692833

Epoch: 6| Step: 12
Training loss: 2.23844051361084
Validation loss: 2.1051801353372555

Epoch: 6| Step: 13
Training loss: 1.7219641208648682
Validation loss: 2.107819234171221

Epoch: 134| Step: 0
Training loss: 2.319416046142578
Validation loss: 2.0983261908254316

Epoch: 6| Step: 1
Training loss: 2.1862969398498535
Validation loss: 2.1161124078176354

Epoch: 6| Step: 2
Training loss: 1.8657965660095215
Validation loss: 2.1277765125356694

Epoch: 6| Step: 3
Training loss: 2.1302788257598877
Validation loss: 2.1260911803091727

Epoch: 6| Step: 4
Training loss: 2.5322184562683105
Validation loss: 2.1192091408596245

Epoch: 6| Step: 5
Training loss: 1.8558824062347412
Validation loss: 2.123818284721785

Epoch: 6| Step: 6
Training loss: 2.364776134490967
Validation loss: 2.124176656046221

Epoch: 6| Step: 7
Training loss: 2.5443296432495117
Validation loss: 2.119846687521986

Epoch: 6| Step: 8
Training loss: 2.579801321029663
Validation loss: 2.1282778632256294

Epoch: 6| Step: 9
Training loss: 1.987215280532837
Validation loss: 2.1415006934955554

Epoch: 6| Step: 10
Training loss: 3.0342116355895996
Validation loss: 2.1430793654534126

Epoch: 6| Step: 11
Training loss: 2.209028720855713
Validation loss: 2.1368664413370113

Epoch: 6| Step: 12
Training loss: 2.5758819580078125
Validation loss: 2.1334632583843764

Epoch: 6| Step: 13
Training loss: 1.8361331224441528
Validation loss: 2.11846790646994

Epoch: 135| Step: 0
Training loss: 1.876094102859497
Validation loss: 2.113663158109111

Epoch: 6| Step: 1
Training loss: 2.284696102142334
Validation loss: 2.1117672856136034

Epoch: 6| Step: 2
Training loss: 3.052044153213501
Validation loss: 2.0943021210291053

Epoch: 6| Step: 3
Training loss: 2.1713967323303223
Validation loss: 2.116170364041482

Epoch: 6| Step: 4
Training loss: 1.844231367111206
Validation loss: 2.110569538608674

Epoch: 6| Step: 5
Training loss: 2.7268600463867188
Validation loss: 2.1070539771869616

Epoch: 6| Step: 6
Training loss: 2.2899322509765625
Validation loss: 2.1003563378446843

Epoch: 6| Step: 7
Training loss: 2.4697961807250977
Validation loss: 2.1082871357599893

Epoch: 6| Step: 8
Training loss: 2.7083399295806885
Validation loss: 2.1059557468660417

Epoch: 6| Step: 9
Training loss: 1.8764965534210205
Validation loss: 2.115545421518305

Epoch: 6| Step: 10
Training loss: 2.7712717056274414
Validation loss: 2.114081303278605

Epoch: 6| Step: 11
Training loss: 2.5514073371887207
Validation loss: 2.1164378786599762

Epoch: 6| Step: 12
Training loss: 2.062690258026123
Validation loss: 2.1388103590216687

Epoch: 6| Step: 13
Training loss: 1.2910438776016235
Validation loss: 2.135105045892859

Epoch: 136| Step: 0
Training loss: 2.1765716075897217
Validation loss: 2.142619043268183

Epoch: 6| Step: 1
Training loss: 1.8952767848968506
Validation loss: 2.1520105920812136

Epoch: 6| Step: 2
Training loss: 2.6729302406311035
Validation loss: 2.1335787683404903

Epoch: 6| Step: 3
Training loss: 2.1974031925201416
Validation loss: 2.152993820046866

Epoch: 6| Step: 4
Training loss: 2.468014717102051
Validation loss: 2.158316784007575

Epoch: 6| Step: 5
Training loss: 2.2382640838623047
Validation loss: 2.1828646890578733

Epoch: 6| Step: 6
Training loss: 2.4207866191864014
Validation loss: 2.210560343598807

Epoch: 6| Step: 7
Training loss: 2.067333698272705
Validation loss: 2.164616069486064

Epoch: 6| Step: 8
Training loss: 1.74981689453125
Validation loss: 2.13409694035848

Epoch: 6| Step: 9
Training loss: 2.398069143295288
Validation loss: 2.118762049623715

Epoch: 6| Step: 10
Training loss: 3.172909736633301
Validation loss: 2.10655963805414

Epoch: 6| Step: 11
Training loss: 2.125602960586548
Validation loss: 2.112800854508595

Epoch: 6| Step: 12
Training loss: 3.0535824298858643
Validation loss: 2.1149681742473314

Epoch: 6| Step: 13
Training loss: 1.5742247104644775
Validation loss: 2.1257155582469

Epoch: 137| Step: 0
Training loss: 2.4550514221191406
Validation loss: 2.150111271489051

Epoch: 6| Step: 1
Training loss: 3.356173038482666
Validation loss: 2.1482770673690306

Epoch: 6| Step: 2
Training loss: 3.157224655151367
Validation loss: 2.13748594509658

Epoch: 6| Step: 3
Training loss: 1.6685514450073242
Validation loss: 2.134873925998647

Epoch: 6| Step: 4
Training loss: 2.3940541744232178
Validation loss: 2.126702680382677

Epoch: 6| Step: 5
Training loss: 2.5155835151672363
Validation loss: 2.1173469033292545

Epoch: 6| Step: 6
Training loss: 2.415043830871582
Validation loss: 2.095339552048714

Epoch: 6| Step: 7
Training loss: 1.8377190828323364
Validation loss: 2.0914307358444377

Epoch: 6| Step: 8
Training loss: 1.6854287385940552
Validation loss: 2.095685871698523

Epoch: 6| Step: 9
Training loss: 2.5850698947906494
Validation loss: 2.091614447614198

Epoch: 6| Step: 10
Training loss: 2.5211243629455566
Validation loss: 2.0908781918146278

Epoch: 6| Step: 11
Training loss: 1.8345860242843628
Validation loss: 2.0953897096777476

Epoch: 6| Step: 12
Training loss: 1.8907084465026855
Validation loss: 2.1065535199257637

Epoch: 6| Step: 13
Training loss: 1.938955545425415
Validation loss: 2.121561651588768

Epoch: 138| Step: 0
Training loss: 2.179309606552124
Validation loss: 2.1428200250030844

Epoch: 6| Step: 1
Training loss: 2.1069235801696777
Validation loss: 2.1599224664831675

Epoch: 6| Step: 2
Training loss: 2.082063674926758
Validation loss: 2.167513432041291

Epoch: 6| Step: 3
Training loss: 2.4499077796936035
Validation loss: 2.161642446312853

Epoch: 6| Step: 4
Training loss: 2.0045790672302246
Validation loss: 2.143138183060513

Epoch: 6| Step: 5
Training loss: 2.19997239112854
Validation loss: 2.1335892549125095

Epoch: 6| Step: 6
Training loss: 2.043405294418335
Validation loss: 2.1165051947357836

Epoch: 6| Step: 7
Training loss: 2.7595176696777344
Validation loss: 2.1123345000769502

Epoch: 6| Step: 8
Training loss: 2.3425087928771973
Validation loss: 2.101217640343533

Epoch: 6| Step: 9
Training loss: 2.3040874004364014
Validation loss: 2.095973892878461

Epoch: 6| Step: 10
Training loss: 2.616823673248291
Validation loss: 2.1014519532521567

Epoch: 6| Step: 11
Training loss: 2.109804153442383
Validation loss: 2.1080272864269953

Epoch: 6| Step: 12
Training loss: 2.8445539474487305
Validation loss: 2.110196227668434

Epoch: 6| Step: 13
Training loss: 1.8098727464675903
Validation loss: 2.1127582134739047

Epoch: 139| Step: 0
Training loss: 1.7964541912078857
Validation loss: 2.115436779555454

Epoch: 6| Step: 1
Training loss: 2.5821285247802734
Validation loss: 2.1233991461415447

Epoch: 6| Step: 2
Training loss: 2.4025776386260986
Validation loss: 2.1153341877845024

Epoch: 6| Step: 3
Training loss: 1.7020413875579834
Validation loss: 2.1219864865785003

Epoch: 6| Step: 4
Training loss: 1.6894398927688599
Validation loss: 2.1201823526813137

Epoch: 6| Step: 5
Training loss: 1.6022891998291016
Validation loss: 2.119862521848371

Epoch: 6| Step: 6
Training loss: 2.1501166820526123
Validation loss: 2.1238093209523026

Epoch: 6| Step: 7
Training loss: 2.219850540161133
Validation loss: 2.111951361420334

Epoch: 6| Step: 8
Training loss: 1.8320813179016113
Validation loss: 2.125554887197351

Epoch: 6| Step: 9
Training loss: 3.0608363151550293
Validation loss: 2.1141121105481218

Epoch: 6| Step: 10
Training loss: 3.003938674926758
Validation loss: 2.137284771088631

Epoch: 6| Step: 11
Training loss: 3.0826423168182373
Validation loss: 2.1365754860703663

Epoch: 6| Step: 12
Training loss: 2.288567543029785
Validation loss: 2.115187842358825

Epoch: 6| Step: 13
Training loss: 2.6563947200775146
Validation loss: 2.1165618819575154

Epoch: 140| Step: 0
Training loss: 2.426565647125244
Validation loss: 2.1084339311045985

Epoch: 6| Step: 1
Training loss: 1.992010235786438
Validation loss: 2.1018563214168755

Epoch: 6| Step: 2
Training loss: 1.7652899026870728
Validation loss: 2.1237903384752173

Epoch: 6| Step: 3
Training loss: 2.036926746368408
Validation loss: 2.117199247883212

Epoch: 6| Step: 4
Training loss: 2.088449478149414
Validation loss: 2.1168801746060772

Epoch: 6| Step: 5
Training loss: 2.4281153678894043
Validation loss: 2.115903828733711

Epoch: 6| Step: 6
Training loss: 2.6385130882263184
Validation loss: 2.124453890708185

Epoch: 6| Step: 7
Training loss: 2.670287609100342
Validation loss: 2.1202069085131408

Epoch: 6| Step: 8
Training loss: 2.4473233222961426
Validation loss: 2.1249364704214115

Epoch: 6| Step: 9
Training loss: 2.051229953765869
Validation loss: 2.127301819862858

Epoch: 6| Step: 10
Training loss: 2.238680839538574
Validation loss: 2.1347372275526806

Epoch: 6| Step: 11
Training loss: 2.1294970512390137
Validation loss: 2.124261227987146

Epoch: 6| Step: 12
Training loss: 2.174356460571289
Validation loss: 2.1173058735427035

Epoch: 6| Step: 13
Training loss: 2.8920769691467285
Validation loss: 2.104905902698476

Epoch: 141| Step: 0
Training loss: 2.6109869480133057
Validation loss: 2.1034405128930205

Epoch: 6| Step: 1
Training loss: 2.568917989730835
Validation loss: 2.0836892063899706

Epoch: 6| Step: 2
Training loss: 2.5422916412353516
Validation loss: 2.091620873379451

Epoch: 6| Step: 3
Training loss: 1.7628839015960693
Validation loss: 2.0821412353105444

Epoch: 6| Step: 4
Training loss: 2.7641897201538086
Validation loss: 2.090757011085428

Epoch: 6| Step: 5
Training loss: 2.135615587234497
Validation loss: 2.095661570948939

Epoch: 6| Step: 6
Training loss: 1.3997453451156616
Validation loss: 2.08547536019356

Epoch: 6| Step: 7
Training loss: 1.995182991027832
Validation loss: 2.082509950924945

Epoch: 6| Step: 8
Training loss: 2.350353479385376
Validation loss: 2.0979269601965465

Epoch: 6| Step: 9
Training loss: 2.2160589694976807
Validation loss: 2.1137278541441886

Epoch: 6| Step: 10
Training loss: 2.5883092880249023
Validation loss: 2.124066391298848

Epoch: 6| Step: 11
Training loss: 2.151801109313965
Validation loss: 2.1269897235337125

Epoch: 6| Step: 12
Training loss: 2.2762508392333984
Validation loss: 2.156787598004905

Epoch: 6| Step: 13
Training loss: 2.7007060050964355
Validation loss: 2.1702462421950472

Epoch: 142| Step: 0
Training loss: 2.1784420013427734
Validation loss: 2.2081059589180896

Epoch: 6| Step: 1
Training loss: 1.6955866813659668
Validation loss: 2.20923125872048

Epoch: 6| Step: 2
Training loss: 2.2754616737365723
Validation loss: 2.250039423665693

Epoch: 6| Step: 3
Training loss: 2.002291679382324
Validation loss: 2.213259325232557

Epoch: 6| Step: 4
Training loss: 2.2151641845703125
Validation loss: 2.2029689294035717

Epoch: 6| Step: 5
Training loss: 2.014591932296753
Validation loss: 2.1339956432260494

Epoch: 6| Step: 6
Training loss: 2.233111619949341
Validation loss: 2.0783586937894105

Epoch: 6| Step: 7
Training loss: 2.8311262130737305
Validation loss: 2.086338540559174

Epoch: 6| Step: 8
Training loss: 2.4877049922943115
Validation loss: 2.0826577063529723

Epoch: 6| Step: 9
Training loss: 2.598850727081299
Validation loss: 2.0836642916484545

Epoch: 6| Step: 10
Training loss: 2.222899913787842
Validation loss: 2.0922409898491314

Epoch: 6| Step: 11
Training loss: 2.3188228607177734
Validation loss: 2.0747979071832474

Epoch: 6| Step: 12
Training loss: 2.3194048404693604
Validation loss: 2.054925041814004

Epoch: 6| Step: 13
Training loss: 3.2443666458129883
Validation loss: 2.0450788056978615

Epoch: 143| Step: 0
Training loss: 2.0429227352142334
Validation loss: 2.0500526671768515

Epoch: 6| Step: 1
Training loss: 2.9944849014282227
Validation loss: 2.0522973127262567

Epoch: 6| Step: 2
Training loss: 2.6077818870544434
Validation loss: 2.0547661140400875

Epoch: 6| Step: 3
Training loss: 1.9994823932647705
Validation loss: 2.063591557164346

Epoch: 6| Step: 4
Training loss: 1.8121148347854614
Validation loss: 2.0821872936782015

Epoch: 6| Step: 5
Training loss: 2.043496608734131
Validation loss: 2.087045900283321

Epoch: 6| Step: 6
Training loss: 2.9755682945251465
Validation loss: 2.0963763344672417

Epoch: 6| Step: 7
Training loss: 2.0956568717956543
Validation loss: 2.124593081012849

Epoch: 6| Step: 8
Training loss: 1.5879652500152588
Validation loss: 2.1437493293516097

Epoch: 6| Step: 9
Training loss: 2.1941781044006348
Validation loss: 2.1636742520075973

Epoch: 6| Step: 10
Training loss: 2.6371192932128906
Validation loss: 2.1795475482940674

Epoch: 6| Step: 11
Training loss: 2.5206243991851807
Validation loss: 2.19988799864246

Epoch: 6| Step: 12
Training loss: 2.422607898712158
Validation loss: 2.183972383058199

Epoch: 6| Step: 13
Training loss: 1.8668668270111084
Validation loss: 2.161766053527914

Epoch: 144| Step: 0
Training loss: 2.2300360202789307
Validation loss: 2.173935236469392

Epoch: 6| Step: 1
Training loss: 1.3051304817199707
Validation loss: 2.1772358930239113

Epoch: 6| Step: 2
Training loss: 2.0442724227905273
Validation loss: 2.1789141470386135

Epoch: 6| Step: 3
Training loss: 2.0714311599731445
Validation loss: 2.153823765375281

Epoch: 6| Step: 4
Training loss: 2.082991123199463
Validation loss: 2.1697717623044084

Epoch: 6| Step: 5
Training loss: 2.7455151081085205
Validation loss: 2.135969397842243

Epoch: 6| Step: 6
Training loss: 1.9969489574432373
Validation loss: 2.0967469407666113

Epoch: 6| Step: 7
Training loss: 2.295498847961426
Validation loss: 2.088691493516327

Epoch: 6| Step: 8
Training loss: 2.284156084060669
Validation loss: 2.07983688897984

Epoch: 6| Step: 9
Training loss: 2.2562756538391113
Validation loss: 2.0711184035065355

Epoch: 6| Step: 10
Training loss: 2.439301013946533
Validation loss: 2.0750972276092856

Epoch: 6| Step: 11
Training loss: 3.224709987640381
Validation loss: 2.067957329493697

Epoch: 6| Step: 12
Training loss: 2.1496710777282715
Validation loss: 2.0784969355470393

Epoch: 6| Step: 13
Training loss: 3.2807106971740723
Validation loss: 2.0727273956421883

Epoch: 145| Step: 0
Training loss: 2.27763032913208
Validation loss: 2.0769677623625724

Epoch: 6| Step: 1
Training loss: 2.576885223388672
Validation loss: 2.0939993268700055

Epoch: 6| Step: 2
Training loss: 2.5834357738494873
Validation loss: 2.0986537561621716

Epoch: 6| Step: 3
Training loss: 2.2724976539611816
Validation loss: 2.071233146934099

Epoch: 6| Step: 4
Training loss: 2.882688522338867
Validation loss: 2.07272671627742

Epoch: 6| Step: 5
Training loss: 2.4474997520446777
Validation loss: 2.0910765329996743

Epoch: 6| Step: 6
Training loss: 2.216477870941162
Validation loss: 2.089793312934137

Epoch: 6| Step: 7
Training loss: 1.5413175821304321
Validation loss: 2.0910727131751274

Epoch: 6| Step: 8
Training loss: 1.924362301826477
Validation loss: 2.110854120664699

Epoch: 6| Step: 9
Training loss: 2.7823431491851807
Validation loss: 2.110656274262295

Epoch: 6| Step: 10
Training loss: 1.6826205253601074
Validation loss: 2.113165497779846

Epoch: 6| Step: 11
Training loss: 1.9447669982910156
Validation loss: 2.1092897871489167

Epoch: 6| Step: 12
Training loss: 1.947182059288025
Validation loss: 2.1091621204089095

Epoch: 6| Step: 13
Training loss: 2.6770477294921875
Validation loss: 2.11670248610999

Epoch: 146| Step: 0
Training loss: 1.9920105934143066
Validation loss: 2.122788800988146

Epoch: 6| Step: 1
Training loss: 2.4544315338134766
Validation loss: 2.131005847325889

Epoch: 6| Step: 2
Training loss: 2.4307827949523926
Validation loss: 2.131476871428951

Epoch: 6| Step: 3
Training loss: 2.3047406673431396
Validation loss: 2.1479294620534426

Epoch: 6| Step: 4
Training loss: 2.2376742362976074
Validation loss: 2.152820961449736

Epoch: 6| Step: 5
Training loss: 1.9076430797576904
Validation loss: 2.1669711464194843

Epoch: 6| Step: 6
Training loss: 1.9727237224578857
Validation loss: 2.18544666869666

Epoch: 6| Step: 7
Training loss: 2.5031261444091797
Validation loss: 2.1910282898974676

Epoch: 6| Step: 8
Training loss: 2.113924980163574
Validation loss: 2.193522140543948

Epoch: 6| Step: 9
Training loss: 2.7353923320770264
Validation loss: 2.173662749669885

Epoch: 6| Step: 10
Training loss: 1.7751951217651367
Validation loss: 2.158592882976737

Epoch: 6| Step: 11
Training loss: 2.4582982063293457
Validation loss: 2.1760050532638386

Epoch: 6| Step: 12
Training loss: 2.29362154006958
Validation loss: 2.15640071130568

Epoch: 6| Step: 13
Training loss: 2.7954578399658203
Validation loss: 2.123215260044221

Epoch: 147| Step: 0
Training loss: 1.5245484113693237
Validation loss: 2.127875335754887

Epoch: 6| Step: 1
Training loss: 1.6895835399627686
Validation loss: 2.1239584261371243

Epoch: 6| Step: 2
Training loss: 2.3305253982543945
Validation loss: 2.111456633895956

Epoch: 6| Step: 3
Training loss: 2.7164363861083984
Validation loss: 2.1073979229055424

Epoch: 6| Step: 4
Training loss: 2.6421899795532227
Validation loss: 2.0918408516914613

Epoch: 6| Step: 5
Training loss: 2.3669097423553467
Validation loss: 2.089267380775944

Epoch: 6| Step: 6
Training loss: 2.168184757232666
Validation loss: 2.088033445419804

Epoch: 6| Step: 7
Training loss: 2.72725510597229
Validation loss: 2.0886920728991107

Epoch: 6| Step: 8
Training loss: 2.3306827545166016
Validation loss: 2.0939851512191114

Epoch: 6| Step: 9
Training loss: 1.9434455633163452
Validation loss: 2.087707657967844

Epoch: 6| Step: 10
Training loss: 2.0632822513580322
Validation loss: 2.085510539752181

Epoch: 6| Step: 11
Training loss: 1.7730127573013306
Validation loss: 2.06123044413905

Epoch: 6| Step: 12
Training loss: 2.8498289585113525
Validation loss: 2.0795423087253364

Epoch: 6| Step: 13
Training loss: 2.0280582904815674
Validation loss: 2.077313297538347

Epoch: 148| Step: 0
Training loss: 2.3984150886535645
Validation loss: 2.0863781782888595

Epoch: 6| Step: 1
Training loss: 2.11261248588562
Validation loss: 2.0844260313177623

Epoch: 6| Step: 2
Training loss: 1.7215054035186768
Validation loss: 2.0974665431566137

Epoch: 6| Step: 3
Training loss: 1.4275535345077515
Validation loss: 2.0842396033707487

Epoch: 6| Step: 4
Training loss: 2.249107837677002
Validation loss: 2.081713468797745

Epoch: 6| Step: 5
Training loss: 1.5236406326293945
Validation loss: 2.082858080505043

Epoch: 6| Step: 6
Training loss: 2.45563006401062
Validation loss: 2.0977773461290585

Epoch: 6| Step: 7
Training loss: 2.593550205230713
Validation loss: 2.0863224947324364

Epoch: 6| Step: 8
Training loss: 2.852663040161133
Validation loss: 2.0728981930722474

Epoch: 6| Step: 9
Training loss: 2.2422103881835938
Validation loss: 2.0630085775929112

Epoch: 6| Step: 10
Training loss: 2.4031271934509277
Validation loss: 2.0585995963824693

Epoch: 6| Step: 11
Training loss: 2.269749402999878
Validation loss: 2.0704076520858274

Epoch: 6| Step: 12
Training loss: 2.6879842281341553
Validation loss: 2.060237284629576

Epoch: 6| Step: 13
Training loss: 2.5175962448120117
Validation loss: 2.074612420092347

Epoch: 149| Step: 0
Training loss: 1.7239389419555664
Validation loss: 2.0740900731855825

Epoch: 6| Step: 1
Training loss: 2.156039237976074
Validation loss: 2.1107378621255197

Epoch: 6| Step: 2
Training loss: 1.7866461277008057
Validation loss: 2.1227015833700857

Epoch: 6| Step: 3
Training loss: 1.7531516551971436
Validation loss: 2.1396476248259186

Epoch: 6| Step: 4
Training loss: 2.002695083618164
Validation loss: 2.1375439141386297

Epoch: 6| Step: 5
Training loss: 2.667226552963257
Validation loss: 2.142358796570891

Epoch: 6| Step: 6
Training loss: 2.166057586669922
Validation loss: 2.1335547098549466

Epoch: 6| Step: 7
Training loss: 2.536524534225464
Validation loss: 2.1362854511507097

Epoch: 6| Step: 8
Training loss: 2.081768274307251
Validation loss: 2.1501449692633843

Epoch: 6| Step: 9
Training loss: 2.024655818939209
Validation loss: 2.1460659068117858

Epoch: 6| Step: 10
Training loss: 2.80288028717041
Validation loss: 2.1411272966733543

Epoch: 6| Step: 11
Training loss: 2.937871217727661
Validation loss: 2.147387663523356

Epoch: 6| Step: 12
Training loss: 1.9260480403900146
Validation loss: 2.1085650382503385

Epoch: 6| Step: 13
Training loss: 2.6290009021759033
Validation loss: 2.1211921745730984

Epoch: 150| Step: 0
Training loss: 2.6478281021118164
Validation loss: 2.1262325522720174

Epoch: 6| Step: 1
Training loss: 2.101059913635254
Validation loss: 2.1277703572345037

Epoch: 6| Step: 2
Training loss: 1.9677233695983887
Validation loss: 2.1449693992573726

Epoch: 6| Step: 3
Training loss: 2.6867499351501465
Validation loss: 2.1465034895045783

Epoch: 6| Step: 4
Training loss: 2.752556800842285
Validation loss: 2.165697331069618

Epoch: 6| Step: 5
Training loss: 2.946328639984131
Validation loss: 2.149779286435855

Epoch: 6| Step: 6
Training loss: 1.52573823928833
Validation loss: 2.1286456456748386

Epoch: 6| Step: 7
Training loss: 1.2014883756637573
Validation loss: 2.108719866762879

Epoch: 6| Step: 8
Training loss: 3.173184394836426
Validation loss: 2.113157879921698

Epoch: 6| Step: 9
Training loss: 1.8482946157455444
Validation loss: 2.1178635474174254

Epoch: 6| Step: 10
Training loss: 2.2644715309143066
Validation loss: 2.1406597475851736

Epoch: 6| Step: 11
Training loss: 1.7540807723999023
Validation loss: 2.1078943437145603

Epoch: 6| Step: 12
Training loss: 2.5543906688690186
Validation loss: 2.1158436395788707

Epoch: 6| Step: 13
Training loss: 1.6461519002914429
Validation loss: 2.1044867782182592

Epoch: 151| Step: 0
Training loss: 2.3705906867980957
Validation loss: 2.0887037784822526

Epoch: 6| Step: 1
Training loss: 2.208756685256958
Validation loss: 2.0805547493760304

Epoch: 6| Step: 2
Training loss: 2.1290698051452637
Validation loss: 2.0719081740225516

Epoch: 6| Step: 3
Training loss: 2.5870282649993896
Validation loss: 2.0760141418826197

Epoch: 6| Step: 4
Training loss: 1.8734740018844604
Validation loss: 2.0946432903248775

Epoch: 6| Step: 5
Training loss: 2.703524112701416
Validation loss: 2.097503569818312

Epoch: 6| Step: 6
Training loss: 2.3268721103668213
Validation loss: 2.115042874889989

Epoch: 6| Step: 7
Training loss: 1.675846815109253
Validation loss: 2.112166896943123

Epoch: 6| Step: 8
Training loss: 2.218208074569702
Validation loss: 2.0924678951181392

Epoch: 6| Step: 9
Training loss: 1.7332301139831543
Validation loss: 2.079090905445878

Epoch: 6| Step: 10
Training loss: 2.3413145542144775
Validation loss: 2.0874175410116873

Epoch: 6| Step: 11
Training loss: 2.6303462982177734
Validation loss: 2.078504488032351

Epoch: 6| Step: 12
Training loss: 2.400174140930176
Validation loss: 2.079749184270059

Epoch: 6| Step: 13
Training loss: 1.770810604095459
Validation loss: 2.088638977337909

Epoch: 152| Step: 0
Training loss: 2.4561314582824707
Validation loss: 2.1041973636996363

Epoch: 6| Step: 1
Training loss: 2.324047327041626
Validation loss: 2.1138988412836546

Epoch: 6| Step: 2
Training loss: 2.07653546333313
Validation loss: 2.1159994230475476

Epoch: 6| Step: 3
Training loss: 2.9536519050598145
Validation loss: 2.108889343918011

Epoch: 6| Step: 4
Training loss: 2.821671485900879
Validation loss: 2.136344973758985

Epoch: 6| Step: 5
Training loss: 1.7971305847167969
Validation loss: 2.1191506360166814

Epoch: 6| Step: 6
Training loss: 1.567996859550476
Validation loss: 2.122227022724767

Epoch: 6| Step: 7
Training loss: 2.3640575408935547
Validation loss: 2.1085186132820706

Epoch: 6| Step: 8
Training loss: 2.7615294456481934
Validation loss: 2.1443242539641676

Epoch: 6| Step: 9
Training loss: 2.517287254333496
Validation loss: 2.181503903481268

Epoch: 6| Step: 10
Training loss: 2.108511447906494
Validation loss: 2.1538927888357513

Epoch: 6| Step: 11
Training loss: 2.1517441272735596
Validation loss: 2.120820399253599

Epoch: 6| Step: 12
Training loss: 1.5854527950286865
Validation loss: 2.0802273135031424

Epoch: 6| Step: 13
Training loss: 1.1800318956375122
Validation loss: 2.0739290239990398

Epoch: 153| Step: 0
Training loss: 2.0650601387023926
Validation loss: 2.085851779548071

Epoch: 6| Step: 1
Training loss: 2.4249491691589355
Validation loss: 2.0768538162272465

Epoch: 6| Step: 2
Training loss: 2.423861503601074
Validation loss: 2.0921210576129217

Epoch: 6| Step: 3
Training loss: 2.4158895015716553
Validation loss: 2.094027981963209

Epoch: 6| Step: 4
Training loss: 2.275303363800049
Validation loss: 2.1013326696170274

Epoch: 6| Step: 5
Training loss: 1.8915832042694092
Validation loss: 2.103074494228568

Epoch: 6| Step: 6
Training loss: 2.8237223625183105
Validation loss: 2.1016357842312066

Epoch: 6| Step: 7
Training loss: 2.3380699157714844
Validation loss: 2.110409462323753

Epoch: 6| Step: 8
Training loss: 2.7616987228393555
Validation loss: 2.114191457789431

Epoch: 6| Step: 9
Training loss: 1.9787852764129639
Validation loss: 2.1303956072817565

Epoch: 6| Step: 10
Training loss: 1.887235164642334
Validation loss: 2.141429639631702

Epoch: 6| Step: 11
Training loss: 2.0642645359039307
Validation loss: 2.1446788528914094

Epoch: 6| Step: 12
Training loss: 1.854557991027832
Validation loss: 2.1454943610775854

Epoch: 6| Step: 13
Training loss: 1.4594165086746216
Validation loss: 2.138856500707647

Epoch: 154| Step: 0
Training loss: 2.567448854446411
Validation loss: 2.125227084723852

Epoch: 6| Step: 1
Training loss: 1.4544224739074707
Validation loss: 2.1028303792399745

Epoch: 6| Step: 2
Training loss: 2.2998266220092773
Validation loss: 2.0841393727128223

Epoch: 6| Step: 3
Training loss: 2.035808563232422
Validation loss: 2.07910313657535

Epoch: 6| Step: 4
Training loss: 2.6364974975585938
Validation loss: 2.071397755735664

Epoch: 6| Step: 5
Training loss: 2.3871216773986816
Validation loss: 2.0772849026546685

Epoch: 6| Step: 6
Training loss: 1.9790083169937134
Validation loss: 2.0754994910250426

Epoch: 6| Step: 7
Training loss: 2.236179828643799
Validation loss: 2.0747576080342776

Epoch: 6| Step: 8
Training loss: 2.414180040359497
Validation loss: 2.080401151410995

Epoch: 6| Step: 9
Training loss: 2.1525168418884277
Validation loss: 2.0667875620626632

Epoch: 6| Step: 10
Training loss: 1.7872498035430908
Validation loss: 2.0917803933543544

Epoch: 6| Step: 11
Training loss: 2.195646286010742
Validation loss: 2.1143113541346725

Epoch: 6| Step: 12
Training loss: 2.5687429904937744
Validation loss: 2.137360836869927

Epoch: 6| Step: 13
Training loss: 2.295952796936035
Validation loss: 2.1748342257674023

Epoch: 155| Step: 0
Training loss: 1.9971468448638916
Validation loss: 2.153103898930293

Epoch: 6| Step: 1
Training loss: 2.137157917022705
Validation loss: 2.1540546199326873

Epoch: 6| Step: 2
Training loss: 2.3305251598358154
Validation loss: 2.151379781384622

Epoch: 6| Step: 3
Training loss: 2.102701425552368
Validation loss: 2.1402286919214393

Epoch: 6| Step: 4
Training loss: 1.7229304313659668
Validation loss: 2.1152272416699316

Epoch: 6| Step: 5
Training loss: 1.8774549961090088
Validation loss: 2.110123412583464

Epoch: 6| Step: 6
Training loss: 1.6940780878067017
Validation loss: 2.1277321987254645

Epoch: 6| Step: 7
Training loss: 2.7090489864349365
Validation loss: 2.137290903317031

Epoch: 6| Step: 8
Training loss: 2.181354522705078
Validation loss: 2.1387606795116136

Epoch: 6| Step: 9
Training loss: 2.0098488330841064
Validation loss: 2.127061431125928

Epoch: 6| Step: 10
Training loss: 3.1262123584747314
Validation loss: 2.127272705877981

Epoch: 6| Step: 11
Training loss: 2.249389171600342
Validation loss: 2.1216925767160233

Epoch: 6| Step: 12
Training loss: 2.052267074584961
Validation loss: 2.0939288677707797

Epoch: 6| Step: 13
Training loss: 2.570157766342163
Validation loss: 2.097659134095715

Epoch: 156| Step: 0
Training loss: 2.1795830726623535
Validation loss: 2.0897136093467794

Epoch: 6| Step: 1
Training loss: 2.230625629425049
Validation loss: 2.0921258336754254

Epoch: 6| Step: 2
Training loss: 2.254023551940918
Validation loss: 2.081943478635562

Epoch: 6| Step: 3
Training loss: 2.343430519104004
Validation loss: 2.062804563071138

Epoch: 6| Step: 4
Training loss: 1.8750022649765015
Validation loss: 2.0643379226807625

Epoch: 6| Step: 5
Training loss: 2.1780447959899902
Validation loss: 2.0451613497990433

Epoch: 6| Step: 6
Training loss: 2.4188952445983887
Validation loss: 2.0620176638326337

Epoch: 6| Step: 7
Training loss: 2.0394558906555176
Validation loss: 2.0654377463043376

Epoch: 6| Step: 8
Training loss: 2.669161796569824
Validation loss: 2.0620943013057915

Epoch: 6| Step: 9
Training loss: 2.5316662788391113
Validation loss: 2.062437408713884

Epoch: 6| Step: 10
Training loss: 2.29061222076416
Validation loss: 2.0667961592315347

Epoch: 6| Step: 11
Training loss: 2.092655658721924
Validation loss: 2.08285593217419

Epoch: 6| Step: 12
Training loss: 1.515939712524414
Validation loss: 2.093408166721303

Epoch: 6| Step: 13
Training loss: 1.7685343027114868
Validation loss: 2.107756963340185

Epoch: 157| Step: 0
Training loss: 2.377758502960205
Validation loss: 2.122461877843385

Epoch: 6| Step: 1
Training loss: 1.6764421463012695
Validation loss: 2.156321379446214

Epoch: 6| Step: 2
Training loss: 2.1764700412750244
Validation loss: 2.103700130216537

Epoch: 6| Step: 3
Training loss: 1.5925822257995605
Validation loss: 2.074017242718768

Epoch: 6| Step: 4
Training loss: 2.208378314971924
Validation loss: 2.0647631204256447

Epoch: 6| Step: 5
Training loss: 1.9645469188690186
Validation loss: 2.0631228390560357

Epoch: 6| Step: 6
Training loss: 2.3271737098693848
Validation loss: 2.048433748624658

Epoch: 6| Step: 7
Training loss: 2.3917388916015625
Validation loss: 2.056704064851166

Epoch: 6| Step: 8
Training loss: 2.6740856170654297
Validation loss: 2.068043867746989

Epoch: 6| Step: 9
Training loss: 2.2268500328063965
Validation loss: 2.0924834564167965

Epoch: 6| Step: 10
Training loss: 1.8373780250549316
Validation loss: 2.100772332119685

Epoch: 6| Step: 11
Training loss: 2.1671605110168457
Validation loss: 2.0903262720313123

Epoch: 6| Step: 12
Training loss: 2.3783814907073975
Validation loss: 2.116085380636236

Epoch: 6| Step: 13
Training loss: 3.1553773880004883
Validation loss: 2.1312751936656174

Epoch: 158| Step: 0
Training loss: 2.481640338897705
Validation loss: 2.1343456622092956

Epoch: 6| Step: 1
Training loss: 2.2695510387420654
Validation loss: 2.1558456984899377

Epoch: 6| Step: 2
Training loss: 2.0000507831573486
Validation loss: 2.1664014964975338

Epoch: 6| Step: 3
Training loss: 1.8590772151947021
Validation loss: 2.160356988189041

Epoch: 6| Step: 4
Training loss: 2.0937860012054443
Validation loss: 2.15889722301114

Epoch: 6| Step: 5
Training loss: 2.763972282409668
Validation loss: 2.131094886410621

Epoch: 6| Step: 6
Training loss: 2.0502071380615234
Validation loss: 2.1090057203846593

Epoch: 6| Step: 7
Training loss: 2.8300976753234863
Validation loss: 2.0913988364640104

Epoch: 6| Step: 8
Training loss: 2.1153745651245117
Validation loss: 2.08312516186827

Epoch: 6| Step: 9
Training loss: 2.4099621772766113
Validation loss: 2.0768911248894146

Epoch: 6| Step: 10
Training loss: 1.6248795986175537
Validation loss: 2.0659755455550326

Epoch: 6| Step: 11
Training loss: 1.8277868032455444
Validation loss: 2.058799442424569

Epoch: 6| Step: 12
Training loss: 1.9108169078826904
Validation loss: 2.0623599213938557

Epoch: 6| Step: 13
Training loss: 2.5300509929656982
Validation loss: 2.051749890850436

Epoch: 159| Step: 0
Training loss: 1.9394557476043701
Validation loss: 2.0537399476574314

Epoch: 6| Step: 1
Training loss: 2.6554338932037354
Validation loss: 2.0686861699627292

Epoch: 6| Step: 2
Training loss: 1.9510127305984497
Validation loss: 2.0872009492689565

Epoch: 6| Step: 3
Training loss: 2.1116693019866943
Validation loss: 2.1032471208162207

Epoch: 6| Step: 4
Training loss: 2.889604091644287
Validation loss: 2.1256959515233196

Epoch: 6| Step: 5
Training loss: 1.8005467653274536
Validation loss: 2.1431125056359077

Epoch: 6| Step: 6
Training loss: 2.477832317352295
Validation loss: 2.1560513588689987

Epoch: 6| Step: 7
Training loss: 2.924584150314331
Validation loss: 2.1393979980099584

Epoch: 6| Step: 8
Training loss: 2.7734856605529785
Validation loss: 2.13712852872828

Epoch: 6| Step: 9
Training loss: 1.6955119371414185
Validation loss: 2.1177660496004167

Epoch: 6| Step: 10
Training loss: 1.882898211479187
Validation loss: 2.1032889453313683

Epoch: 6| Step: 11
Training loss: 2.2819323539733887
Validation loss: 2.1004105280804377

Epoch: 6| Step: 12
Training loss: 1.4338397979736328
Validation loss: 2.089317152577062

Epoch: 6| Step: 13
Training loss: 1.0388128757476807
Validation loss: 2.0876381115246843

Epoch: 160| Step: 0
Training loss: 1.8394644260406494
Validation loss: 2.0802227271500455

Epoch: 6| Step: 1
Training loss: 2.2064876556396484
Validation loss: 2.0900254685391664

Epoch: 6| Step: 2
Training loss: 2.352334499359131
Validation loss: 2.072846330622191

Epoch: 6| Step: 3
Training loss: 2.514312267303467
Validation loss: 2.0809482297589703

Epoch: 6| Step: 4
Training loss: 2.100306987762451
Validation loss: 2.083910398585822

Epoch: 6| Step: 5
Training loss: 2.591383934020996
Validation loss: 2.0759557934217554

Epoch: 6| Step: 6
Training loss: 2.1665210723876953
Validation loss: 2.0696755301567817

Epoch: 6| Step: 7
Training loss: 2.013336658477783
Validation loss: 2.072075684865316

Epoch: 6| Step: 8
Training loss: 2.508979320526123
Validation loss: 2.0722509058572913

Epoch: 6| Step: 9
Training loss: 1.8498855829238892
Validation loss: 2.075133426215059

Epoch: 6| Step: 10
Training loss: 2.1788525581359863
Validation loss: 2.057299929280435

Epoch: 6| Step: 11
Training loss: 1.5008141994476318
Validation loss: 2.082103794620883

Epoch: 6| Step: 12
Training loss: 2.0371222496032715
Validation loss: 2.081292759987616

Epoch: 6| Step: 13
Training loss: 2.2204525470733643
Validation loss: 2.1017380760562037

Epoch: 161| Step: 0
Training loss: 2.490352153778076
Validation loss: 2.1131397985642955

Epoch: 6| Step: 1
Training loss: 1.934729814529419
Validation loss: 2.1436563320057367

Epoch: 6| Step: 2
Training loss: 2.3982176780700684
Validation loss: 2.136971912076396

Epoch: 6| Step: 3
Training loss: 2.53041934967041
Validation loss: 2.1315960345729703

Epoch: 6| Step: 4
Training loss: 2.607003927230835
Validation loss: 2.1112066212520806

Epoch: 6| Step: 5
Training loss: 1.8599436283111572
Validation loss: 2.093446949476837

Epoch: 6| Step: 6
Training loss: 2.1768243312835693
Validation loss: 2.1141139922603482

Epoch: 6| Step: 7
Training loss: 1.666654348373413
Validation loss: 2.0932304077250983

Epoch: 6| Step: 8
Training loss: 1.7594621181488037
Validation loss: 2.1214754824997275

Epoch: 6| Step: 9
Training loss: 2.2486283779144287
Validation loss: 2.1225086540304203

Epoch: 6| Step: 10
Training loss: 1.5761001110076904
Validation loss: 2.1080841069580405

Epoch: 6| Step: 11
Training loss: 2.3645598888397217
Validation loss: 2.1186740218952136

Epoch: 6| Step: 12
Training loss: 2.126361846923828
Validation loss: 2.108288861090137

Epoch: 6| Step: 13
Training loss: 2.154956340789795
Validation loss: 2.106962006579163

Epoch: 162| Step: 0
Training loss: 1.6627283096313477
Validation loss: 2.110254374883508

Epoch: 6| Step: 1
Training loss: 2.066969394683838
Validation loss: 2.113382566359735

Epoch: 6| Step: 2
Training loss: 1.5263961553573608
Validation loss: 2.097173785650602

Epoch: 6| Step: 3
Training loss: 2.691375494003296
Validation loss: 2.0942243773450135

Epoch: 6| Step: 4
Training loss: 2.1782782077789307
Validation loss: 2.080758276806083

Epoch: 6| Step: 5
Training loss: 2.412014961242676
Validation loss: 2.098006838111467

Epoch: 6| Step: 6
Training loss: 2.365811824798584
Validation loss: 2.0933314113206762

Epoch: 6| Step: 7
Training loss: 2.146787643432617
Validation loss: 2.109811446999991

Epoch: 6| Step: 8
Training loss: 2.382023811340332
Validation loss: 2.1083508486388833

Epoch: 6| Step: 9
Training loss: 2.4688148498535156
Validation loss: 2.1409426030292305

Epoch: 6| Step: 10
Training loss: 2.292248249053955
Validation loss: 2.147118894002771

Epoch: 6| Step: 11
Training loss: 1.5287253856658936
Validation loss: 2.129577326518233

Epoch: 6| Step: 12
Training loss: 2.295884132385254
Validation loss: 2.1456778459651495

Epoch: 6| Step: 13
Training loss: 1.9525765180587769
Validation loss: 2.134194356138988

Epoch: 163| Step: 0
Training loss: 1.9744728803634644
Validation loss: 2.1251297432889222

Epoch: 6| Step: 1
Training loss: 1.65751051902771
Validation loss: 2.098300382655154

Epoch: 6| Step: 2
Training loss: 2.663482904434204
Validation loss: 2.1079286862445135

Epoch: 6| Step: 3
Training loss: 1.6576409339904785
Validation loss: 2.118168404025416

Epoch: 6| Step: 4
Training loss: 2.7354483604431152
Validation loss: 2.1206690367831977

Epoch: 6| Step: 5
Training loss: 1.8095924854278564
Validation loss: 2.1228139195390927

Epoch: 6| Step: 6
Training loss: 2.2649974822998047
Validation loss: 2.13492008947557

Epoch: 6| Step: 7
Training loss: 2.061939001083374
Validation loss: 2.1196006305756105

Epoch: 6| Step: 8
Training loss: 2.3328330516815186
Validation loss: 2.148749395083356

Epoch: 6| Step: 9
Training loss: 2.1493780612945557
Validation loss: 2.124634099263017

Epoch: 6| Step: 10
Training loss: 2.3574273586273193
Validation loss: 2.133252095150691

Epoch: 6| Step: 11
Training loss: 1.8924181461334229
Validation loss: 2.112255101562828

Epoch: 6| Step: 12
Training loss: 2.004518985748291
Validation loss: 2.1002585452090026

Epoch: 6| Step: 13
Training loss: 2.0707943439483643
Validation loss: 2.0785889497367283

Epoch: 164| Step: 0
Training loss: 2.295339345932007
Validation loss: 2.0929983046747025

Epoch: 6| Step: 1
Training loss: 1.8030725717544556
Validation loss: 2.073837164909609

Epoch: 6| Step: 2
Training loss: 1.7042357921600342
Validation loss: 2.0811276743488927

Epoch: 6| Step: 3
Training loss: 2.2870543003082275
Validation loss: 2.0823248253073743

Epoch: 6| Step: 4
Training loss: 2.62848162651062
Validation loss: 2.0726999121327556

Epoch: 6| Step: 5
Training loss: 2.4351747035980225
Validation loss: 2.076937953631083

Epoch: 6| Step: 6
Training loss: 1.8973723649978638
Validation loss: 2.0816515991764684

Epoch: 6| Step: 7
Training loss: 1.8991001844406128
Validation loss: 2.0964784109464256

Epoch: 6| Step: 8
Training loss: 1.845461368560791
Validation loss: 2.1030518418999127

Epoch: 6| Step: 9
Training loss: 2.8124077320098877
Validation loss: 2.090963259820015

Epoch: 6| Step: 10
Training loss: 2.3828306198120117
Validation loss: 2.085274839913973

Epoch: 6| Step: 11
Training loss: 1.4365819692611694
Validation loss: 2.0632677949884886

Epoch: 6| Step: 12
Training loss: 2.4121975898742676
Validation loss: 2.06271336155553

Epoch: 6| Step: 13
Training loss: 1.5441974401474
Validation loss: 2.079891517598142

Epoch: 165| Step: 0
Training loss: 1.823467493057251
Validation loss: 2.073324231691258

Epoch: 6| Step: 1
Training loss: 1.6183987855911255
Validation loss: 2.085952812625516

Epoch: 6| Step: 2
Training loss: 1.928027868270874
Validation loss: 2.0978158558568647

Epoch: 6| Step: 3
Training loss: 2.4846973419189453
Validation loss: 2.1069095314189954

Epoch: 6| Step: 4
Training loss: 2.2284278869628906
Validation loss: 2.1097604792605162

Epoch: 6| Step: 5
Training loss: 2.5218114852905273
Validation loss: 2.125908056894938

Epoch: 6| Step: 6
Training loss: 2.284329414367676
Validation loss: 2.102110183367165

Epoch: 6| Step: 7
Training loss: 1.9793078899383545
Validation loss: 2.094539306497061

Epoch: 6| Step: 8
Training loss: 1.8490887880325317
Validation loss: 2.091801228061799

Epoch: 6| Step: 9
Training loss: 1.4578189849853516
Validation loss: 2.10254249265117

Epoch: 6| Step: 10
Training loss: 2.1327381134033203
Validation loss: 2.120256454713883

Epoch: 6| Step: 11
Training loss: 2.041475296020508
Validation loss: 2.1363069190773913

Epoch: 6| Step: 12
Training loss: 3.1480400562286377
Validation loss: 2.14742116261554

Epoch: 6| Step: 13
Training loss: 2.268261194229126
Validation loss: 2.148558524347121

Epoch: 166| Step: 0
Training loss: 2.657355308532715
Validation loss: 2.1387546472651984

Epoch: 6| Step: 1
Training loss: 1.8746168613433838
Validation loss: 2.1242759830208233

Epoch: 6| Step: 2
Training loss: 2.796161651611328
Validation loss: 2.128560834033515

Epoch: 6| Step: 3
Training loss: 2.2736034393310547
Validation loss: 2.117118263757357

Epoch: 6| Step: 4
Training loss: 2.0232059955596924
Validation loss: 2.139153403620566

Epoch: 6| Step: 5
Training loss: 2.0861592292785645
Validation loss: 2.1580606686171664

Epoch: 6| Step: 6
Training loss: 2.3079187870025635
Validation loss: 2.166267128400905

Epoch: 6| Step: 7
Training loss: 1.886444330215454
Validation loss: 2.147425510550058

Epoch: 6| Step: 8
Training loss: 2.3299381732940674
Validation loss: 2.1801843950825353

Epoch: 6| Step: 9
Training loss: 1.902370810508728
Validation loss: 2.1507220114431074

Epoch: 6| Step: 10
Training loss: 2.03818416595459
Validation loss: 2.134447959161574

Epoch: 6| Step: 11
Training loss: 1.34019935131073
Validation loss: 2.11496163183643

Epoch: 6| Step: 12
Training loss: 1.758840560913086
Validation loss: 2.092212518056234

Epoch: 6| Step: 13
Training loss: 1.8882863521575928
Validation loss: 2.0721645227042575

Epoch: 167| Step: 0
Training loss: 2.0494132041931152
Validation loss: 2.063824003742587

Epoch: 6| Step: 1
Training loss: 2.2307565212249756
Validation loss: 2.0828173673281105

Epoch: 6| Step: 2
Training loss: 1.6361839771270752
Validation loss: 2.084684866730885

Epoch: 6| Step: 3
Training loss: 1.729562759399414
Validation loss: 2.073783149001419

Epoch: 6| Step: 4
Training loss: 2.557373523712158
Validation loss: 2.068278674156435

Epoch: 6| Step: 5
Training loss: 2.2959647178649902
Validation loss: 2.0666844921727336

Epoch: 6| Step: 6
Training loss: 1.9554224014282227
Validation loss: 2.059123526337326

Epoch: 6| Step: 7
Training loss: 1.9955610036849976
Validation loss: 2.064026185261306

Epoch: 6| Step: 8
Training loss: 2.2512290477752686
Validation loss: 2.070328381753737

Epoch: 6| Step: 9
Training loss: 2.6485934257507324
Validation loss: 2.1100192275098575

Epoch: 6| Step: 10
Training loss: 2.249420166015625
Validation loss: 2.130301288379136

Epoch: 6| Step: 11
Training loss: 1.8618645668029785
Validation loss: 2.154944876188873

Epoch: 6| Step: 12
Training loss: 1.9358556270599365
Validation loss: 2.1838888070916616

Epoch: 6| Step: 13
Training loss: 2.143918991088867
Validation loss: 2.1937736875267437

Epoch: 168| Step: 0
Training loss: 1.8035571575164795
Validation loss: 2.1623574303042505

Epoch: 6| Step: 1
Training loss: 2.718703031539917
Validation loss: 2.188593787531699

Epoch: 6| Step: 2
Training loss: 2.835416078567505
Validation loss: 2.1331127817912767

Epoch: 6| Step: 3
Training loss: 2.071519613265991
Validation loss: 2.128931050659508

Epoch: 6| Step: 4
Training loss: 2.533745050430298
Validation loss: 2.144817800932033

Epoch: 6| Step: 5
Training loss: 2.2057342529296875
Validation loss: 2.116799657062818

Epoch: 6| Step: 6
Training loss: 1.8977508544921875
Validation loss: 2.1176700617677424

Epoch: 6| Step: 7
Training loss: 2.0489301681518555
Validation loss: 2.105686690217705

Epoch: 6| Step: 8
Training loss: 1.970548152923584
Validation loss: 2.104107169694798

Epoch: 6| Step: 9
Training loss: 1.367030143737793
Validation loss: 2.1178611632316344

Epoch: 6| Step: 10
Training loss: 2.19482159614563
Validation loss: 2.1209073784530803

Epoch: 6| Step: 11
Training loss: 2.150681257247925
Validation loss: 2.118959178206741

Epoch: 6| Step: 12
Training loss: 1.46770441532135
Validation loss: 2.116839878020748

Epoch: 6| Step: 13
Training loss: 1.6914421319961548
Validation loss: 2.114061076153991

Epoch: 169| Step: 0
Training loss: 2.3313536643981934
Validation loss: 2.1214635090161393

Epoch: 6| Step: 1
Training loss: 2.76499342918396
Validation loss: 2.131351742693173

Epoch: 6| Step: 2
Training loss: 1.89448881149292
Validation loss: 2.136760131005318

Epoch: 6| Step: 3
Training loss: 1.544041633605957
Validation loss: 2.126665348647743

Epoch: 6| Step: 4
Training loss: 1.76699697971344
Validation loss: 2.120790507203789

Epoch: 6| Step: 5
Training loss: 2.4345180988311768
Validation loss: 2.1086389531371412

Epoch: 6| Step: 6
Training loss: 1.8677114248275757
Validation loss: 2.096858180979247

Epoch: 6| Step: 7
Training loss: 2.3434271812438965
Validation loss: 2.106092442748367

Epoch: 6| Step: 8
Training loss: 1.9058738946914673
Validation loss: 2.123818779504427

Epoch: 6| Step: 9
Training loss: 1.8514320850372314
Validation loss: 2.131817788206121

Epoch: 6| Step: 10
Training loss: 2.7301888465881348
Validation loss: 2.1140897197108113

Epoch: 6| Step: 11
Training loss: 1.7648190259933472
Validation loss: 2.1103532237391316

Epoch: 6| Step: 12
Training loss: 2.046280860900879
Validation loss: 2.096667751189201

Epoch: 6| Step: 13
Training loss: 1.9003829956054688
Validation loss: 2.0925167939996205

Epoch: 170| Step: 0
Training loss: 2.401869297027588
Validation loss: 2.0962451247758764

Epoch: 6| Step: 1
Training loss: 1.9660696983337402
Validation loss: 2.0838639479811474

Epoch: 6| Step: 2
Training loss: 1.8990129232406616
Validation loss: 2.0778815541216122

Epoch: 6| Step: 3
Training loss: 1.905989408493042
Validation loss: 2.1018492021868305

Epoch: 6| Step: 4
Training loss: 1.8212730884552002
Validation loss: 2.0897167536520187

Epoch: 6| Step: 5
Training loss: 2.0955588817596436
Validation loss: 2.1155303344931653

Epoch: 6| Step: 6
Training loss: 2.2877559661865234
Validation loss: 2.095783761752549

Epoch: 6| Step: 7
Training loss: 2.4165773391723633
Validation loss: 2.1176983823058424

Epoch: 6| Step: 8
Training loss: 1.8005110025405884
Validation loss: 2.1161432766145274

Epoch: 6| Step: 9
Training loss: 1.5794398784637451
Validation loss: 2.1229111763738815

Epoch: 6| Step: 10
Training loss: 2.448108196258545
Validation loss: 2.1331192780566472

Epoch: 6| Step: 11
Training loss: 2.0853590965270996
Validation loss: 2.126270963299659

Epoch: 6| Step: 12
Training loss: 2.023698329925537
Validation loss: 2.1024005105418544

Epoch: 6| Step: 13
Training loss: 2.338341236114502
Validation loss: 2.100401804011355

Epoch: 171| Step: 0
Training loss: 3.1598618030548096
Validation loss: 2.103089201834894

Epoch: 6| Step: 1
Training loss: 1.9770108461380005
Validation loss: 2.1025424324056154

Epoch: 6| Step: 2
Training loss: 2.1201722621917725
Validation loss: 2.099382633803993

Epoch: 6| Step: 3
Training loss: 2.8279309272766113
Validation loss: 2.1031942905918246

Epoch: 6| Step: 4
Training loss: 1.2239115238189697
Validation loss: 2.114509677374235

Epoch: 6| Step: 5
Training loss: 1.1711101531982422
Validation loss: 2.1111295428327335

Epoch: 6| Step: 6
Training loss: 1.8574641942977905
Validation loss: 2.1245805012282504

Epoch: 6| Step: 7
Training loss: 1.8671642541885376
Validation loss: 2.1378429448732765

Epoch: 6| Step: 8
Training loss: 2.03269362449646
Validation loss: 2.1610039998126287

Epoch: 6| Step: 9
Training loss: 2.2726497650146484
Validation loss: 2.1567992625697965

Epoch: 6| Step: 10
Training loss: 1.9063060283660889
Validation loss: 2.1430428656198646

Epoch: 6| Step: 11
Training loss: 2.2344563007354736
Validation loss: 2.1167384398880826

Epoch: 6| Step: 12
Training loss: 2.375511884689331
Validation loss: 2.1010078845485562

Epoch: 6| Step: 13
Training loss: 1.7930325269699097
Validation loss: 2.1023927504016506

Epoch: 172| Step: 0
Training loss: 1.8018581867218018
Validation loss: 2.093703172540152

Epoch: 6| Step: 1
Training loss: 1.7859070301055908
Validation loss: 2.0854893192168205

Epoch: 6| Step: 2
Training loss: 2.391321897506714
Validation loss: 2.084815127875215

Epoch: 6| Step: 3
Training loss: 1.7748059034347534
Validation loss: 2.080729676831153

Epoch: 6| Step: 4
Training loss: 1.8892043828964233
Validation loss: 2.086369582401809

Epoch: 6| Step: 5
Training loss: 1.7531869411468506
Validation loss: 2.096212148666382

Epoch: 6| Step: 6
Training loss: 1.7328052520751953
Validation loss: 2.093327965787662

Epoch: 6| Step: 7
Training loss: 2.497838020324707
Validation loss: 2.091599787435224

Epoch: 6| Step: 8
Training loss: 1.9699763059616089
Validation loss: 2.0787275991132184

Epoch: 6| Step: 9
Training loss: 2.0534920692443848
Validation loss: 2.0833115167515253

Epoch: 6| Step: 10
Training loss: 2.326052665710449
Validation loss: 2.0851557382973294

Epoch: 6| Step: 11
Training loss: 2.324007034301758
Validation loss: 2.090418974558512

Epoch: 6| Step: 12
Training loss: 2.036438226699829
Validation loss: 2.0821034626294206

Epoch: 6| Step: 13
Training loss: 2.484139919281006
Validation loss: 2.088906252256004

Epoch: 173| Step: 0
Training loss: 2.337327003479004
Validation loss: 2.085291080577399

Epoch: 6| Step: 1
Training loss: 2.557201385498047
Validation loss: 2.0883848231325866

Epoch: 6| Step: 2
Training loss: 1.3184633255004883
Validation loss: 2.11409931541771

Epoch: 6| Step: 3
Training loss: 1.582737922668457
Validation loss: 2.0990039020456295

Epoch: 6| Step: 4
Training loss: 2.9228763580322266
Validation loss: 2.124584267216344

Epoch: 6| Step: 5
Training loss: 1.8730412721633911
Validation loss: 2.1000730940090713

Epoch: 6| Step: 6
Training loss: 1.8472256660461426
Validation loss: 2.1174460841763403

Epoch: 6| Step: 7
Training loss: 1.9219508171081543
Validation loss: 2.1008388791033017

Epoch: 6| Step: 8
Training loss: 2.8668932914733887
Validation loss: 2.1130781148069646

Epoch: 6| Step: 9
Training loss: 1.5519933700561523
Validation loss: 2.1106504265980055

Epoch: 6| Step: 10
Training loss: 2.4188320636749268
Validation loss: 2.1069226636681506

Epoch: 6| Step: 11
Training loss: 1.352851390838623
Validation loss: 2.0983065635927263

Epoch: 6| Step: 12
Training loss: 1.939494252204895
Validation loss: 2.089947276217963

Epoch: 6| Step: 13
Training loss: 2.3201632499694824
Validation loss: 2.0898921361533542

Epoch: 174| Step: 0
Training loss: 2.0103471279144287
Validation loss: 2.114805260012227

Epoch: 6| Step: 1
Training loss: 1.8995206356048584
Validation loss: 2.1625150942033335

Epoch: 6| Step: 2
Training loss: 1.9195351600646973
Validation loss: 2.222729721376973

Epoch: 6| Step: 3
Training loss: 1.816619634628296
Validation loss: 2.2578186860648533

Epoch: 6| Step: 4
Training loss: 2.1962575912475586
Validation loss: 2.2301905360273135

Epoch: 6| Step: 5
Training loss: 2.3615164756774902
Validation loss: 2.1617664239739858

Epoch: 6| Step: 6
Training loss: 1.6652148962020874
Validation loss: 2.11514118922654

Epoch: 6| Step: 7
Training loss: 3.1407346725463867
Validation loss: 2.0750664177761284

Epoch: 6| Step: 8
Training loss: 2.6718087196350098
Validation loss: 2.0622384522550847

Epoch: 6| Step: 9
Training loss: 1.6696579456329346
Validation loss: 2.071045865294754

Epoch: 6| Step: 10
Training loss: 2.116623878479004
Validation loss: 2.085723700061921

Epoch: 6| Step: 11
Training loss: 2.008312225341797
Validation loss: 2.0736083240919214

Epoch: 6| Step: 12
Training loss: 2.1656694412231445
Validation loss: 2.0778442967322563

Epoch: 6| Step: 13
Training loss: 1.2710421085357666
Validation loss: 2.0822870859535794

Epoch: 175| Step: 0
Training loss: 1.8936463594436646
Validation loss: 2.085209144059048

Epoch: 6| Step: 1
Training loss: 2.807023525238037
Validation loss: 2.078288189826473

Epoch: 6| Step: 2
Training loss: 1.4557442665100098
Validation loss: 2.06577528292133

Epoch: 6| Step: 3
Training loss: 2.475459575653076
Validation loss: 2.069976234948763

Epoch: 6| Step: 4
Training loss: 1.691778540611267
Validation loss: 2.0744422866452124

Epoch: 6| Step: 5
Training loss: 2.2046315670013428
Validation loss: 2.1140196887395715

Epoch: 6| Step: 6
Training loss: 2.1936593055725098
Validation loss: 2.1059762072819534

Epoch: 6| Step: 7
Training loss: 2.8827719688415527
Validation loss: 2.141428993594262

Epoch: 6| Step: 8
Training loss: 2.264071464538574
Validation loss: 2.157205104827881

Epoch: 6| Step: 9
Training loss: 1.554596185684204
Validation loss: 2.1629010823465165

Epoch: 6| Step: 10
Training loss: 1.842329978942871
Validation loss: 2.128353467551611

Epoch: 6| Step: 11
Training loss: 1.2581124305725098
Validation loss: 2.128045147465121

Epoch: 6| Step: 12
Training loss: 1.9341609477996826
Validation loss: 2.081905439335813

Epoch: 6| Step: 13
Training loss: 1.7117953300476074
Validation loss: 2.0759842934147006

Epoch: 176| Step: 0
Training loss: 1.5157320499420166
Validation loss: 2.081905984109448

Epoch: 6| Step: 1
Training loss: 2.4373507499694824
Validation loss: 2.078374849852695

Epoch: 6| Step: 2
Training loss: 1.2955856323242188
Validation loss: 2.085744627060429

Epoch: 6| Step: 3
Training loss: 3.1963913440704346
Validation loss: 2.0912854453568817

Epoch: 6| Step: 4
Training loss: 1.5118612051010132
Validation loss: 2.1100152051577004

Epoch: 6| Step: 5
Training loss: 1.3674299716949463
Validation loss: 2.129448195939423

Epoch: 6| Step: 6
Training loss: 2.1850271224975586
Validation loss: 2.1430792244531776

Epoch: 6| Step: 7
Training loss: 1.8752241134643555
Validation loss: 2.1478581556709866

Epoch: 6| Step: 8
Training loss: 2.6403942108154297
Validation loss: 2.164010847768476

Epoch: 6| Step: 9
Training loss: 2.300415515899658
Validation loss: 2.146052513071286

Epoch: 6| Step: 10
Training loss: 1.5990755558013916
Validation loss: 2.1369873862112723

Epoch: 6| Step: 11
Training loss: 2.1812117099761963
Validation loss: 2.125817826999131

Epoch: 6| Step: 12
Training loss: 2.3516454696655273
Validation loss: 2.132166039559149

Epoch: 6| Step: 13
Training loss: 1.8636349439620972
Validation loss: 2.124839751951156

Epoch: 177| Step: 0
Training loss: 2.240901231765747
Validation loss: 2.1104938214825046

Epoch: 6| Step: 1
Training loss: 2.0049805641174316
Validation loss: 2.1070397028359036

Epoch: 6| Step: 2
Training loss: 2.7907118797302246
Validation loss: 2.090897129428002

Epoch: 6| Step: 3
Training loss: 1.978162407875061
Validation loss: 2.1255637855939966

Epoch: 6| Step: 4
Training loss: 2.1423985958099365
Validation loss: 2.132902188967633

Epoch: 6| Step: 5
Training loss: 1.894670009613037
Validation loss: 2.138247174601401

Epoch: 6| Step: 6
Training loss: 1.9327948093414307
Validation loss: 2.1351827036949897

Epoch: 6| Step: 7
Training loss: 1.540292501449585
Validation loss: 2.128922857264037

Epoch: 6| Step: 8
Training loss: 1.7505842447280884
Validation loss: 2.100764379706434

Epoch: 6| Step: 9
Training loss: 2.687899589538574
Validation loss: 2.099972337804815

Epoch: 6| Step: 10
Training loss: 2.280186176300049
Validation loss: 2.0663477707934637

Epoch: 6| Step: 11
Training loss: 1.3228495121002197
Validation loss: 2.0534346103668213

Epoch: 6| Step: 12
Training loss: 1.702937364578247
Validation loss: 2.0527355824747393

Epoch: 6| Step: 13
Training loss: 2.1796786785125732
Validation loss: 2.0611201640098327

Epoch: 178| Step: 0
Training loss: 1.787513256072998
Validation loss: 2.062873057139817

Epoch: 6| Step: 1
Training loss: 1.8064541816711426
Validation loss: 2.0525317217714045

Epoch: 6| Step: 2
Training loss: 2.0891802310943604
Validation loss: 2.067623971610941

Epoch: 6| Step: 3
Training loss: 2.62502384185791
Validation loss: 2.0847920346003708

Epoch: 6| Step: 4
Training loss: 2.3295817375183105
Validation loss: 2.0817123202867407

Epoch: 6| Step: 5
Training loss: 2.751707077026367
Validation loss: 2.09164180550524

Epoch: 6| Step: 6
Training loss: 1.9903764724731445
Validation loss: 2.0829705602379254

Epoch: 6| Step: 7
Training loss: 1.838399052619934
Validation loss: 2.0883614170935845

Epoch: 6| Step: 8
Training loss: 1.71644926071167
Validation loss: 2.1077477624339442

Epoch: 6| Step: 9
Training loss: 2.2062835693359375
Validation loss: 2.1197973835852837

Epoch: 6| Step: 10
Training loss: 1.5062388181686401
Validation loss: 2.1362331900545346

Epoch: 6| Step: 11
Training loss: 1.89618718624115
Validation loss: 2.1551301530612412

Epoch: 6| Step: 12
Training loss: 2.102214813232422
Validation loss: 2.1906741972892516

Epoch: 6| Step: 13
Training loss: 1.5159707069396973
Validation loss: 2.1947034405123804

Epoch: 179| Step: 0
Training loss: 1.6044130325317383
Validation loss: 2.1957747602975495

Epoch: 6| Step: 1
Training loss: 2.493533134460449
Validation loss: 2.1707393238621373

Epoch: 6| Step: 2
Training loss: 1.9205111265182495
Validation loss: 2.14899464320111

Epoch: 6| Step: 3
Training loss: 1.5850012302398682
Validation loss: 2.1137328032524354

Epoch: 6| Step: 4
Training loss: 2.1497511863708496
Validation loss: 2.0884767911767446

Epoch: 6| Step: 5
Training loss: 2.5128698348999023
Validation loss: 2.0774540516637985

Epoch: 6| Step: 6
Training loss: 1.9985984563827515
Validation loss: 2.067773380587178

Epoch: 6| Step: 7
Training loss: 2.0544188022613525
Validation loss: 2.0528386331373647

Epoch: 6| Step: 8
Training loss: 1.8219481706619263
Validation loss: 2.045110889660415

Epoch: 6| Step: 9
Training loss: 2.7000560760498047
Validation loss: 2.0534503998294955

Epoch: 6| Step: 10
Training loss: 2.452787160873413
Validation loss: 2.038312114695067

Epoch: 6| Step: 11
Training loss: 1.3725031614303589
Validation loss: 2.0422651383184616

Epoch: 6| Step: 12
Training loss: 1.8365325927734375
Validation loss: 2.0452296374946513

Epoch: 6| Step: 13
Training loss: 1.8875880241394043
Validation loss: 2.068239963182839

Epoch: 180| Step: 0
Training loss: 2.156412124633789
Validation loss: 2.0965992289204753

Epoch: 6| Step: 1
Training loss: 1.3649158477783203
Validation loss: 2.122272845237486

Epoch: 6| Step: 2
Training loss: 1.5110784769058228
Validation loss: 2.155628702973807

Epoch: 6| Step: 3
Training loss: 2.158677816390991
Validation loss: 2.1538280492187827

Epoch: 6| Step: 4
Training loss: 2.6190621852874756
Validation loss: 2.123440097096146

Epoch: 6| Step: 5
Training loss: 2.1359572410583496
Validation loss: 2.0814683206619753

Epoch: 6| Step: 6
Training loss: 2.301112651824951
Validation loss: 2.082857567776916

Epoch: 6| Step: 7
Training loss: 2.7078070640563965
Validation loss: 2.072598457336426

Epoch: 6| Step: 8
Training loss: 1.34813392162323
Validation loss: 2.0816155069617817

Epoch: 6| Step: 9
Training loss: 2.325009346008301
Validation loss: 2.08210995376751

Epoch: 6| Step: 10
Training loss: 1.7830497026443481
Validation loss: 2.086838150537142

Epoch: 6| Step: 11
Training loss: 2.0114221572875977
Validation loss: 2.076463992877673

Epoch: 6| Step: 12
Training loss: 1.8338154554367065
Validation loss: 2.078464561893094

Epoch: 6| Step: 13
Training loss: 1.738389015197754
Validation loss: 2.085978026031166

Epoch: 181| Step: 0
Training loss: 2.2783455848693848
Validation loss: 2.0760718032877934

Epoch: 6| Step: 1
Training loss: 1.9591184854507446
Validation loss: 2.0813548718729327

Epoch: 6| Step: 2
Training loss: 1.706310749053955
Validation loss: 2.081585491857221

Epoch: 6| Step: 3
Training loss: 2.739762306213379
Validation loss: 2.1005144478172384

Epoch: 6| Step: 4
Training loss: 1.9218318462371826
Validation loss: 2.1218806774385515

Epoch: 6| Step: 5
Training loss: 2.232698917388916
Validation loss: 2.1436326965208976

Epoch: 6| Step: 6
Training loss: 2.112628221511841
Validation loss: 2.155365918272285

Epoch: 6| Step: 7
Training loss: 2.4377198219299316
Validation loss: 2.1400261258566253

Epoch: 6| Step: 8
Training loss: 1.1745433807373047
Validation loss: 2.1483205954233804

Epoch: 6| Step: 9
Training loss: 1.4442062377929688
Validation loss: 2.1419377608965804

Epoch: 6| Step: 10
Training loss: 2.372467041015625
Validation loss: 2.127053842749647

Epoch: 6| Step: 11
Training loss: 2.1430246829986572
Validation loss: 2.1036600899952713

Epoch: 6| Step: 12
Training loss: 1.4598829746246338
Validation loss: 2.0786746419886106

Epoch: 6| Step: 13
Training loss: 1.8031243085861206
Validation loss: 2.0601845300325783

Epoch: 182| Step: 0
Training loss: 1.7420469522476196
Validation loss: 2.0515992615812566

Epoch: 6| Step: 1
Training loss: 2.0512001514434814
Validation loss: 2.0498990499845116

Epoch: 6| Step: 2
Training loss: 2.5084359645843506
Validation loss: 2.0533172443348873

Epoch: 6| Step: 3
Training loss: 1.6651208400726318
Validation loss: 2.0491401162198795

Epoch: 6| Step: 4
Training loss: 1.644302487373352
Validation loss: 2.050966658899861

Epoch: 6| Step: 5
Training loss: 2.1381337642669678
Validation loss: 2.069297618763421

Epoch: 6| Step: 6
Training loss: 2.419888496398926
Validation loss: 2.075732026048886

Epoch: 6| Step: 7
Training loss: 2.2970969676971436
Validation loss: 2.0736973644584737

Epoch: 6| Step: 8
Training loss: 1.6351490020751953
Validation loss: 2.080057613311275

Epoch: 6| Step: 9
Training loss: 1.5906327962875366
Validation loss: 2.0875757894208355

Epoch: 6| Step: 10
Training loss: 1.7430388927459717
Validation loss: 2.0978672196788173

Epoch: 6| Step: 11
Training loss: 1.7165124416351318
Validation loss: 2.1017361430711645

Epoch: 6| Step: 12
Training loss: 2.1828765869140625
Validation loss: 2.123917955224232

Epoch: 6| Step: 13
Training loss: 2.8588104248046875
Validation loss: 2.106450811509163

Epoch: 183| Step: 0
Training loss: 2.018864631652832
Validation loss: 2.09761328722841

Epoch: 6| Step: 1
Training loss: 2.358311653137207
Validation loss: 2.0678493925320205

Epoch: 6| Step: 2
Training loss: 2.4110326766967773
Validation loss: 2.0585403442382812

Epoch: 6| Step: 3
Training loss: 1.1487094163894653
Validation loss: 2.052760283152262

Epoch: 6| Step: 4
Training loss: 1.8304643630981445
Validation loss: 2.0482133485937632

Epoch: 6| Step: 5
Training loss: 1.725142002105713
Validation loss: 2.05067930939377

Epoch: 6| Step: 6
Training loss: 2.4512341022491455
Validation loss: 2.0560036308021954

Epoch: 6| Step: 7
Training loss: 1.5395574569702148
Validation loss: 2.0558738400859218

Epoch: 6| Step: 8
Training loss: 2.554313898086548
Validation loss: 2.0458058182911207

Epoch: 6| Step: 9
Training loss: 2.1853842735290527
Validation loss: 2.0585268107793664

Epoch: 6| Step: 10
Training loss: 1.1724035739898682
Validation loss: 2.0521438942160657

Epoch: 6| Step: 11
Training loss: 1.9633867740631104
Validation loss: 2.0815945261268207

Epoch: 6| Step: 12
Training loss: 2.384988784790039
Validation loss: 2.11437439662154

Epoch: 6| Step: 13
Training loss: 2.1113576889038086
Validation loss: 2.142357136613579

Epoch: 184| Step: 0
Training loss: 1.1175246238708496
Validation loss: 2.151857882417658

Epoch: 6| Step: 1
Training loss: 1.9699240922927856
Validation loss: 2.1556162449621383

Epoch: 6| Step: 2
Training loss: 2.3772411346435547
Validation loss: 2.1503246407355032

Epoch: 6| Step: 3
Training loss: 2.5224995613098145
Validation loss: 2.120458218359178

Epoch: 6| Step: 4
Training loss: 1.572197675704956
Validation loss: 2.091008045340097

Epoch: 6| Step: 5
Training loss: 2.388948678970337
Validation loss: 2.0805269031114477

Epoch: 6| Step: 6
Training loss: 1.7465200424194336
Validation loss: 2.069155195707916

Epoch: 6| Step: 7
Training loss: 2.2964870929718018
Validation loss: 2.055784199827461

Epoch: 6| Step: 8
Training loss: 2.1748013496398926
Validation loss: 2.069401523118378

Epoch: 6| Step: 9
Training loss: 2.240403652191162
Validation loss: 2.0894005644705986

Epoch: 6| Step: 10
Training loss: 1.8420348167419434
Validation loss: 2.084085900296447

Epoch: 6| Step: 11
Training loss: 1.621462345123291
Validation loss: 2.0972948253795667

Epoch: 6| Step: 12
Training loss: 2.2284605503082275
Validation loss: 2.0971153013167845

Epoch: 6| Step: 13
Training loss: 1.4919251203536987
Validation loss: 2.086806147329269

Epoch: 185| Step: 0
Training loss: 2.1023430824279785
Validation loss: 2.0572217549047163

Epoch: 6| Step: 1
Training loss: 1.670788288116455
Validation loss: 2.064731051844935

Epoch: 6| Step: 2
Training loss: 2.2260096073150635
Validation loss: 2.0474090781263126

Epoch: 6| Step: 3
Training loss: 1.8559739589691162
Validation loss: 2.0530946613639913

Epoch: 6| Step: 4
Training loss: 2.077396869659424
Validation loss: 2.048548816352762

Epoch: 6| Step: 5
Training loss: 2.5282981395721436
Validation loss: 2.061073628805017

Epoch: 6| Step: 6
Training loss: 2.4248099327087402
Validation loss: 2.055547542469476

Epoch: 6| Step: 7
Training loss: 2.2631406784057617
Validation loss: 2.0652874605630034

Epoch: 6| Step: 8
Training loss: 2.0746538639068604
Validation loss: 2.0704582916793

Epoch: 6| Step: 9
Training loss: 1.7791796922683716
Validation loss: 2.0784905546454975

Epoch: 6| Step: 10
Training loss: 1.806473970413208
Validation loss: 2.0913764276812152

Epoch: 6| Step: 11
Training loss: 1.2332570552825928
Validation loss: 2.112989966587354

Epoch: 6| Step: 12
Training loss: 1.6637996435165405
Validation loss: 2.1140129361101376

Epoch: 6| Step: 13
Training loss: 1.7535357475280762
Validation loss: 2.096224659232683

Epoch: 186| Step: 0
Training loss: 2.359391450881958
Validation loss: 2.0948567672442366

Epoch: 6| Step: 1
Training loss: 1.771829605102539
Validation loss: 2.1050916615352837

Epoch: 6| Step: 2
Training loss: 1.4369845390319824
Validation loss: 2.085449751987252

Epoch: 6| Step: 3
Training loss: 2.2570273876190186
Validation loss: 2.0884356267990603

Epoch: 6| Step: 4
Training loss: 1.4899044036865234
Validation loss: 2.0726278943400227

Epoch: 6| Step: 5
Training loss: 1.8895173072814941
Validation loss: 2.073569684900263

Epoch: 6| Step: 6
Training loss: 2.703444719314575
Validation loss: 2.0661341221101823

Epoch: 6| Step: 7
Training loss: 2.5717411041259766
Validation loss: 2.0515665854177167

Epoch: 6| Step: 8
Training loss: 1.9576932191848755
Validation loss: 2.0536135383831557

Epoch: 6| Step: 9
Training loss: 1.7335283756256104
Validation loss: 2.040967341392271

Epoch: 6| Step: 10
Training loss: 1.5812435150146484
Validation loss: 2.035356242169616

Epoch: 6| Step: 11
Training loss: 1.8990137577056885
Validation loss: 2.0509883152541293

Epoch: 6| Step: 12
Training loss: 2.202188730239868
Validation loss: 2.0825498975733274

Epoch: 6| Step: 13
Training loss: 1.1760480403900146
Validation loss: 2.1399531043985838

Epoch: 187| Step: 0
Training loss: 2.641892671585083
Validation loss: 2.177009453055679

Epoch: 6| Step: 1
Training loss: 2.292067289352417
Validation loss: 2.2118075739952827

Epoch: 6| Step: 2
Training loss: 2.226597309112549
Validation loss: 2.2078857229601954

Epoch: 6| Step: 3
Training loss: 2.0519418716430664
Validation loss: 2.190533653382332

Epoch: 6| Step: 4
Training loss: 1.606984257698059
Validation loss: 2.134444293155465

Epoch: 6| Step: 5
Training loss: 1.9268593788146973
Validation loss: 2.1264067311440744

Epoch: 6| Step: 6
Training loss: 2.078110694885254
Validation loss: 2.08931121518535

Epoch: 6| Step: 7
Training loss: 1.8952374458312988
Validation loss: 2.065811764809393

Epoch: 6| Step: 8
Training loss: 1.6609737873077393
Validation loss: 2.074626224015349

Epoch: 6| Step: 9
Training loss: 1.3602452278137207
Validation loss: 2.060248536448325

Epoch: 6| Step: 10
Training loss: 2.268585681915283
Validation loss: 2.062750195944181

Epoch: 6| Step: 11
Training loss: 2.3003990650177
Validation loss: 2.0572496588512132

Epoch: 6| Step: 12
Training loss: 2.0330240726470947
Validation loss: 2.057127874384644

Epoch: 6| Step: 13
Training loss: 1.377241611480713
Validation loss: 2.04187128748945

Epoch: 188| Step: 0
Training loss: 2.0247583389282227
Validation loss: 2.0646786497485254

Epoch: 6| Step: 1
Training loss: 2.22269606590271
Validation loss: 2.0655384832812893

Epoch: 6| Step: 2
Training loss: 2.0030994415283203
Validation loss: 2.075353573727351

Epoch: 6| Step: 3
Training loss: 1.9840023517608643
Validation loss: 2.0714974557199786

Epoch: 6| Step: 4
Training loss: 1.1412379741668701
Validation loss: 2.070275816866147

Epoch: 6| Step: 5
Training loss: 1.7275835275650024
Validation loss: 2.074662503375802

Epoch: 6| Step: 6
Training loss: 2.832519292831421
Validation loss: 2.0756685169794227

Epoch: 6| Step: 7
Training loss: 1.800540804862976
Validation loss: 2.0584499759058796

Epoch: 6| Step: 8
Training loss: 1.471121072769165
Validation loss: 2.0867606978262625

Epoch: 6| Step: 9
Training loss: 2.1168909072875977
Validation loss: 2.0793478796558995

Epoch: 6| Step: 10
Training loss: 1.8642208576202393
Validation loss: 2.0747283120309152

Epoch: 6| Step: 11
Training loss: 2.3767056465148926
Validation loss: 2.0758918421242827

Epoch: 6| Step: 12
Training loss: 1.6995502710342407
Validation loss: 2.056234900669385

Epoch: 6| Step: 13
Training loss: 2.0071656703948975
Validation loss: 2.045089266633475

Epoch: 189| Step: 0
Training loss: 1.8714673519134521
Validation loss: 2.037027273126828

Epoch: 6| Step: 1
Training loss: 1.8769687414169312
Validation loss: 2.0296126257988716

Epoch: 6| Step: 2
Training loss: 1.119683861732483
Validation loss: 2.0344896803620043

Epoch: 6| Step: 3
Training loss: 1.3958311080932617
Validation loss: 2.0597219851709183

Epoch: 6| Step: 4
Training loss: 2.1280035972595215
Validation loss: 2.058117123060329

Epoch: 6| Step: 5
Training loss: 2.212704658508301
Validation loss: 2.0658179995834187

Epoch: 6| Step: 6
Training loss: 2.5421855449676514
Validation loss: 2.067132073064004

Epoch: 6| Step: 7
Training loss: 2.039155960083008
Validation loss: 2.077732497645963

Epoch: 6| Step: 8
Training loss: 1.8683446645736694
Validation loss: 2.0700646446597193

Epoch: 6| Step: 9
Training loss: 2.3038926124572754
Validation loss: 2.07879194905681

Epoch: 6| Step: 10
Training loss: 2.1972579956054688
Validation loss: 2.0736678531092982

Epoch: 6| Step: 11
Training loss: 1.7847001552581787
Validation loss: 2.0784421300375335

Epoch: 6| Step: 12
Training loss: 1.8908542394638062
Validation loss: 2.0705725864697526

Epoch: 6| Step: 13
Training loss: 1.6231540441513062
Validation loss: 2.045743898678851

Epoch: 190| Step: 0
Training loss: 1.9110960960388184
Validation loss: 2.0541162644663165

Epoch: 6| Step: 1
Training loss: 1.3839538097381592
Validation loss: 2.053537799466041

Epoch: 6| Step: 2
Training loss: 2.2806031703948975
Validation loss: 2.060954104187668

Epoch: 6| Step: 3
Training loss: 1.7754813432693481
Validation loss: 2.0645823017243417

Epoch: 6| Step: 4
Training loss: 2.3672659397125244
Validation loss: 2.066119988759359

Epoch: 6| Step: 5
Training loss: 1.314164638519287
Validation loss: 2.078902816259733

Epoch: 6| Step: 6
Training loss: 0.9901838898658752
Validation loss: 2.100151858022136

Epoch: 6| Step: 7
Training loss: 2.5072879791259766
Validation loss: 2.105059782663981

Epoch: 6| Step: 8
Training loss: 2.1564650535583496
Validation loss: 2.1130539242939284

Epoch: 6| Step: 9
Training loss: 2.2874088287353516
Validation loss: 2.1228458253286218

Epoch: 6| Step: 10
Training loss: 2.2407069206237793
Validation loss: 2.0906333884885235

Epoch: 6| Step: 11
Training loss: 1.7545597553253174
Validation loss: 2.0670180961649907

Epoch: 6| Step: 12
Training loss: 2.246957778930664
Validation loss: 2.049829613777899

Epoch: 6| Step: 13
Training loss: 1.7184062004089355
Validation loss: 2.032509985790458

Epoch: 191| Step: 0
Training loss: 1.7895259857177734
Validation loss: 2.019086654468249

Epoch: 6| Step: 1
Training loss: 2.091294765472412
Validation loss: 2.023649292607461

Epoch: 6| Step: 2
Training loss: 2.5562291145324707
Validation loss: 2.0260231751267628

Epoch: 6| Step: 3
Training loss: 1.662106990814209
Validation loss: 2.0364753841072

Epoch: 6| Step: 4
Training loss: 1.5509536266326904
Validation loss: 2.0504379516006797

Epoch: 6| Step: 5
Training loss: 1.8635622262954712
Validation loss: 2.043035304674538

Epoch: 6| Step: 6
Training loss: 1.8256877660751343
Validation loss: 2.0446321759172665

Epoch: 6| Step: 7
Training loss: 2.3186731338500977
Validation loss: 2.0589599417101954

Epoch: 6| Step: 8
Training loss: 1.7463350296020508
Validation loss: 2.0736269579138806

Epoch: 6| Step: 9
Training loss: 1.4406489133834839
Validation loss: 2.0706944773274083

Epoch: 6| Step: 10
Training loss: 2.142854928970337
Validation loss: 2.0953254161342496

Epoch: 6| Step: 11
Training loss: 1.7349956035614014
Validation loss: 2.0903506407173733

Epoch: 6| Step: 12
Training loss: 2.07351016998291
Validation loss: 2.07625340389949

Epoch: 6| Step: 13
Training loss: 2.5829851627349854
Validation loss: 2.063585042953491

Epoch: 192| Step: 0
Training loss: 1.743687391281128
Validation loss: 2.0482325810258106

Epoch: 6| Step: 1
Training loss: 1.8064268827438354
Validation loss: 2.0296212755223757

Epoch: 6| Step: 2
Training loss: 2.063319206237793
Validation loss: 2.0512524099760157

Epoch: 6| Step: 3
Training loss: 1.7733917236328125
Validation loss: 2.0330596123972247

Epoch: 6| Step: 4
Training loss: 1.98834228515625
Validation loss: 2.023429637314171

Epoch: 6| Step: 5
Training loss: 2.0420827865600586
Validation loss: 2.04865595345856

Epoch: 6| Step: 6
Training loss: 1.622807502746582
Validation loss: 2.044031232915899

Epoch: 6| Step: 7
Training loss: 2.0003867149353027
Validation loss: 2.050192376618744

Epoch: 6| Step: 8
Training loss: 1.9790256023406982
Validation loss: 2.061833917453725

Epoch: 6| Step: 9
Training loss: 1.682576060295105
Validation loss: 2.0808435024753695

Epoch: 6| Step: 10
Training loss: 2.699305534362793
Validation loss: 2.0898200440150436

Epoch: 6| Step: 11
Training loss: 1.8872047662734985
Validation loss: 2.114019657975884

Epoch: 6| Step: 12
Training loss: 2.0716147422790527
Validation loss: 2.1180356215405207

Epoch: 6| Step: 13
Training loss: 1.8902612924575806
Validation loss: 2.1144064908386557

Epoch: 193| Step: 0
Training loss: 2.4470200538635254
Validation loss: 2.1198221483538227

Epoch: 6| Step: 1
Training loss: 2.2518081665039062
Validation loss: 2.101013914231331

Epoch: 6| Step: 2
Training loss: 1.5556715726852417
Validation loss: 2.0816831742563555

Epoch: 6| Step: 3
Training loss: 1.8660087585449219
Validation loss: 2.0816453156932706

Epoch: 6| Step: 4
Training loss: 1.8406399488449097
Validation loss: 2.0814917138827744

Epoch: 6| Step: 5
Training loss: 1.8129487037658691
Validation loss: 2.078394095102946

Epoch: 6| Step: 6
Training loss: 1.27069091796875
Validation loss: 2.0850428150546167

Epoch: 6| Step: 7
Training loss: 2.176621198654175
Validation loss: 2.0748487621225338

Epoch: 6| Step: 8
Training loss: 1.7113293409347534
Validation loss: 2.085597784288468

Epoch: 6| Step: 9
Training loss: 2.390876293182373
Validation loss: 2.0511861129473616

Epoch: 6| Step: 10
Training loss: 2.417405128479004
Validation loss: 2.046118959303825

Epoch: 6| Step: 11
Training loss: 1.6428008079528809
Validation loss: 2.0463923074865855

Epoch: 6| Step: 12
Training loss: 1.4275439977645874
Validation loss: 2.045784132454985

Epoch: 6| Step: 13
Training loss: 2.1655802726745605
Validation loss: 2.051967155548834

Epoch: 194| Step: 0
Training loss: 2.7240686416625977
Validation loss: 2.040859986377019

Epoch: 6| Step: 1
Training loss: 1.692078709602356
Validation loss: 2.039766191154398

Epoch: 6| Step: 2
Training loss: 2.2232518196105957
Validation loss: 2.027811696452479

Epoch: 6| Step: 3
Training loss: 1.6525181531906128
Validation loss: 2.035110050632108

Epoch: 6| Step: 4
Training loss: 2.271801710128784
Validation loss: 2.0385011960101385

Epoch: 6| Step: 5
Training loss: 2.364870309829712
Validation loss: 2.054359224534804

Epoch: 6| Step: 6
Training loss: 1.5122334957122803
Validation loss: 2.08831775060264

Epoch: 6| Step: 7
Training loss: 1.4391183853149414
Validation loss: 2.09313383922782

Epoch: 6| Step: 8
Training loss: 1.9066505432128906
Validation loss: 2.091730220343477

Epoch: 6| Step: 9
Training loss: 1.8409465551376343
Validation loss: 2.0864117632630053

Epoch: 6| Step: 10
Training loss: 1.586334466934204
Validation loss: 2.0931401534747054

Epoch: 6| Step: 11
Training loss: 1.7962634563446045
Validation loss: 2.075924401642174

Epoch: 6| Step: 12
Training loss: 1.8997111320495605
Validation loss: 2.0719859702612764

Epoch: 6| Step: 13
Training loss: 1.4076638221740723
Validation loss: 2.068764732730004

Epoch: 195| Step: 0
Training loss: 1.7767361402511597
Validation loss: 2.058069863627034

Epoch: 6| Step: 1
Training loss: 2.054931879043579
Validation loss: 2.0824872037415862

Epoch: 6| Step: 2
Training loss: 1.5104246139526367
Validation loss: 2.077764529053883

Epoch: 6| Step: 3
Training loss: 2.0702900886535645
Validation loss: 2.102617343266805

Epoch: 6| Step: 4
Training loss: 0.8683570623397827
Validation loss: 2.069680577965193

Epoch: 6| Step: 5
Training loss: 1.8179471492767334
Validation loss: 2.0649683513948993

Epoch: 6| Step: 6
Training loss: 2.1337831020355225
Validation loss: 2.0333166378800587

Epoch: 6| Step: 7
Training loss: 1.8342443704605103
Validation loss: 2.0503738695575344

Epoch: 6| Step: 8
Training loss: 2.07361102104187
Validation loss: 2.0565726064866587

Epoch: 6| Step: 9
Training loss: 2.129110097885132
Validation loss: 2.0434169436013825

Epoch: 6| Step: 10
Training loss: 1.6416230201721191
Validation loss: 2.0695044507262526

Epoch: 6| Step: 11
Training loss: 2.1259310245513916
Validation loss: 2.078263498121692

Epoch: 6| Step: 12
Training loss: 2.423936367034912
Validation loss: 2.0902548118304183

Epoch: 6| Step: 13
Training loss: 2.2628164291381836
Validation loss: 2.0834195178042174

Epoch: 196| Step: 0
Training loss: 1.2960147857666016
Validation loss: 2.0800790222742225

Epoch: 6| Step: 1
Training loss: 1.0108006000518799
Validation loss: 2.0625404952674784

Epoch: 6| Step: 2
Training loss: 0.9724295735359192
Validation loss: 2.075303453271107

Epoch: 6| Step: 3
Training loss: 1.819954514503479
Validation loss: 2.055833003854239

Epoch: 6| Step: 4
Training loss: 2.2219271659851074
Validation loss: 2.0596436864586285

Epoch: 6| Step: 5
Training loss: 2.4109315872192383
Validation loss: 2.0795331796010337

Epoch: 6| Step: 6
Training loss: 1.5079337358474731
Validation loss: 2.0538479717828895

Epoch: 6| Step: 7
Training loss: 2.310136318206787
Validation loss: 2.0387159726952993

Epoch: 6| Step: 8
Training loss: 2.3940961360931396
Validation loss: 2.0294954751127507

Epoch: 6| Step: 9
Training loss: 2.810384750366211
Validation loss: 2.030742536308945

Epoch: 6| Step: 10
Training loss: 1.5576558113098145
Validation loss: 2.044026319698621

Epoch: 6| Step: 11
Training loss: 2.2079858779907227
Validation loss: 2.0499278524870514

Epoch: 6| Step: 12
Training loss: 2.157677173614502
Validation loss: 2.057057155075894

Epoch: 6| Step: 13
Training loss: 1.466105580329895
Validation loss: 2.0997686950109338

Epoch: 197| Step: 0
Training loss: 1.666834831237793
Validation loss: 2.1386850316037416

Epoch: 6| Step: 1
Training loss: 2.163640022277832
Validation loss: 2.1493716137383574

Epoch: 6| Step: 2
Training loss: 1.8361365795135498
Validation loss: 2.130203334234094

Epoch: 6| Step: 3
Training loss: 2.1786835193634033
Validation loss: 2.069536514179681

Epoch: 6| Step: 4
Training loss: 1.7351832389831543
Validation loss: 2.0533464185653196

Epoch: 6| Step: 5
Training loss: 1.8944915533065796
Validation loss: 2.040301335755215

Epoch: 6| Step: 6
Training loss: 1.606174111366272
Validation loss: 2.0299900013913392

Epoch: 6| Step: 7
Training loss: 1.9812607765197754
Validation loss: 2.0457249508109143

Epoch: 6| Step: 8
Training loss: 1.5986180305480957
Validation loss: 2.042666300650566

Epoch: 6| Step: 9
Training loss: 2.444796085357666
Validation loss: 2.05046167168566

Epoch: 6| Step: 10
Training loss: 1.5559966564178467
Validation loss: 2.0342752523319696

Epoch: 6| Step: 11
Training loss: 1.7155365943908691
Validation loss: 2.043964993569159

Epoch: 6| Step: 12
Training loss: 2.650869369506836
Validation loss: 2.061157852090815

Epoch: 6| Step: 13
Training loss: 1.2382349967956543
Validation loss: 2.0660077397541334

Epoch: 198| Step: 0
Training loss: 2.392228364944458
Validation loss: 2.093857125569415

Epoch: 6| Step: 1
Training loss: 2.021533250808716
Validation loss: 2.0958453083551056

Epoch: 6| Step: 2
Training loss: 1.8319573402404785
Validation loss: 2.082702482900312

Epoch: 6| Step: 3
Training loss: 1.7929449081420898
Validation loss: 2.0539933455887662

Epoch: 6| Step: 4
Training loss: 1.9934682846069336
Validation loss: 2.0483514878057663

Epoch: 6| Step: 5
Training loss: 1.7994544506072998
Validation loss: 2.017866301280196

Epoch: 6| Step: 6
Training loss: 1.106497049331665
Validation loss: 1.9981790332384006

Epoch: 6| Step: 7
Training loss: 1.5576242208480835
Validation loss: 2.016575715875113

Epoch: 6| Step: 8
Training loss: 2.158634901046753
Validation loss: 2.0081595143964215

Epoch: 6| Step: 9
Training loss: 1.5255393981933594
Validation loss: 2.018586923999171

Epoch: 6| Step: 10
Training loss: 2.008941173553467
Validation loss: 2.01468345298562

Epoch: 6| Step: 11
Training loss: 2.104290008544922
Validation loss: 2.04339446303665

Epoch: 6| Step: 12
Training loss: 2.2289838790893555
Validation loss: 2.056295153915241

Epoch: 6| Step: 13
Training loss: 2.015986919403076
Validation loss: 2.081101220141175

Epoch: 199| Step: 0
Training loss: 2.602797031402588
Validation loss: 2.099235483395156

Epoch: 6| Step: 1
Training loss: 1.453353762626648
Validation loss: 2.121967029827897

Epoch: 6| Step: 2
Training loss: 2.3287394046783447
Validation loss: 2.1324196489908362

Epoch: 6| Step: 3
Training loss: 2.1102142333984375
Validation loss: 2.0922257464419127

Epoch: 6| Step: 4
Training loss: 1.4251461029052734
Validation loss: 2.0592409308238695

Epoch: 6| Step: 5
Training loss: 1.286120057106018
Validation loss: 2.019542658200828

Epoch: 6| Step: 6
Training loss: 2.388178825378418
Validation loss: 2.0057251197035595

Epoch: 6| Step: 7
Training loss: 1.7550292015075684
Validation loss: 1.9913708702210458

Epoch: 6| Step: 8
Training loss: 1.988769769668579
Validation loss: 2.001689394315084

Epoch: 6| Step: 9
Training loss: 1.870639443397522
Validation loss: 2.022752816959094

Epoch: 6| Step: 10
Training loss: 1.52974534034729
Validation loss: 2.021057827498323

Epoch: 6| Step: 11
Training loss: 2.0005338191986084
Validation loss: 2.029907968736464

Epoch: 6| Step: 12
Training loss: 1.7736587524414062
Validation loss: 2.068769908720447

Epoch: 6| Step: 13
Training loss: 1.9272905588150024
Validation loss: 2.0862668252760366

Epoch: 200| Step: 0
Training loss: 1.427086353302002
Validation loss: 2.0910996275563396

Epoch: 6| Step: 1
Training loss: 1.6957284212112427
Validation loss: 2.0679292704469416

Epoch: 6| Step: 2
Training loss: 1.9530303478240967
Validation loss: 2.0612432251694384

Epoch: 6| Step: 3
Training loss: 2.221590518951416
Validation loss: 2.0640802921787387

Epoch: 6| Step: 4
Training loss: 1.5635616779327393
Validation loss: 2.0655435926170758

Epoch: 6| Step: 5
Training loss: 1.5386210680007935
Validation loss: 2.07016158616671

Epoch: 6| Step: 6
Training loss: 1.9936859607696533
Validation loss: 2.069278750368344

Epoch: 6| Step: 7
Training loss: 1.9952465295791626
Validation loss: 2.056954763268912

Epoch: 6| Step: 8
Training loss: 2.1401724815368652
Validation loss: 2.070084471856394

Epoch: 6| Step: 9
Training loss: 1.2391624450683594
Validation loss: 2.042625352900515

Epoch: 6| Step: 10
Training loss: 2.306786060333252
Validation loss: 2.034010018071821

Epoch: 6| Step: 11
Training loss: 2.336946487426758
Validation loss: 2.0606091791583645

Epoch: 6| Step: 12
Training loss: 1.4524883031845093
Validation loss: 2.03812760947853

Epoch: 6| Step: 13
Training loss: 2.7605581283569336
Validation loss: 2.0202013113165416

Epoch: 201| Step: 0
Training loss: 1.993454933166504
Validation loss: 2.026213925371888

Epoch: 6| Step: 1
Training loss: 1.7134296894073486
Validation loss: 2.016735576814221

Epoch: 6| Step: 2
Training loss: 1.2154057025909424
Validation loss: 2.0335403693619596

Epoch: 6| Step: 3
Training loss: 1.6480677127838135
Validation loss: 2.0485131932843115

Epoch: 6| Step: 4
Training loss: 1.910251498222351
Validation loss: 2.046877186785462

Epoch: 6| Step: 5
Training loss: 1.7933483123779297
Validation loss: 2.0296165789327314

Epoch: 6| Step: 6
Training loss: 1.9706065654754639
Validation loss: 2.056886916519493

Epoch: 6| Step: 7
Training loss: 2.122267961502075
Validation loss: 2.0534602313913326

Epoch: 6| Step: 8
Training loss: 2.3545827865600586
Validation loss: 2.0550657344120804

Epoch: 6| Step: 9
Training loss: 1.9177663326263428
Validation loss: 2.0786781234125935

Epoch: 6| Step: 10
Training loss: 1.1842820644378662
Validation loss: 2.0510615148851947

Epoch: 6| Step: 11
Training loss: 2.1289169788360596
Validation loss: 2.060879466354206

Epoch: 6| Step: 12
Training loss: 2.548100709915161
Validation loss: 2.037194219968652

Epoch: 6| Step: 13
Training loss: 1.6035428047180176
Validation loss: 2.033211028704079

Epoch: 202| Step: 0
Training loss: 1.446822166442871
Validation loss: 2.045853425097722

Epoch: 6| Step: 1
Training loss: 2.1464152336120605
Validation loss: 2.0542517387738792

Epoch: 6| Step: 2
Training loss: 1.6853358745574951
Validation loss: 2.0748070670712377

Epoch: 6| Step: 3
Training loss: 1.249869704246521
Validation loss: 2.080663614375617

Epoch: 6| Step: 4
Training loss: 2.1956329345703125
Validation loss: 2.101507120234992

Epoch: 6| Step: 5
Training loss: 1.899551510810852
Validation loss: 2.1136540700030584

Epoch: 6| Step: 6
Training loss: 2.0942561626434326
Validation loss: 2.136064839619462

Epoch: 6| Step: 7
Training loss: 2.0224838256835938
Validation loss: 2.098095981023645

Epoch: 6| Step: 8
Training loss: 1.9967327117919922
Validation loss: 2.1006928618236254

Epoch: 6| Step: 9
Training loss: 1.2550926208496094
Validation loss: 2.0974038262521066

Epoch: 6| Step: 10
Training loss: 2.0172982215881348
Validation loss: 2.0663725394074635

Epoch: 6| Step: 11
Training loss: 2.1637349128723145
Validation loss: 2.0504205688353507

Epoch: 6| Step: 12
Training loss: 1.5192222595214844
Validation loss: 2.029339469889159

Epoch: 6| Step: 13
Training loss: 2.1385231018066406
Validation loss: 2.0264406870770197

Epoch: 203| Step: 0
Training loss: 2.2076125144958496
Validation loss: 2.0074321595571374

Epoch: 6| Step: 1
Training loss: 1.651153802871704
Validation loss: 2.0061623921958347

Epoch: 6| Step: 2
Training loss: 1.4976940155029297
Validation loss: 1.9980622145437426

Epoch: 6| Step: 3
Training loss: 1.7442302703857422
Validation loss: 2.010216361732893

Epoch: 6| Step: 4
Training loss: 2.1489803791046143
Validation loss: 2.044303797906445

Epoch: 6| Step: 5
Training loss: 1.347623586654663
Validation loss: 2.048209869733421

Epoch: 6| Step: 6
Training loss: 2.032166004180908
Validation loss: 2.041288311763476

Epoch: 6| Step: 7
Training loss: 1.507343053817749
Validation loss: 2.0591285215911044

Epoch: 6| Step: 8
Training loss: 2.3221938610076904
Validation loss: 2.0528343928757535

Epoch: 6| Step: 9
Training loss: 1.8490254878997803
Validation loss: 2.050025780995687

Epoch: 6| Step: 10
Training loss: 1.5620567798614502
Validation loss: 2.042905790831453

Epoch: 6| Step: 11
Training loss: 2.4480743408203125
Validation loss: 2.059285476643552

Epoch: 6| Step: 12
Training loss: 1.9317209720611572
Validation loss: 2.0324891972285446

Epoch: 6| Step: 13
Training loss: 1.6304768323898315
Validation loss: 2.052059740148565

Epoch: 204| Step: 0
Training loss: 2.0706143379211426
Validation loss: 2.054371428746049

Epoch: 6| Step: 1
Training loss: 2.0307977199554443
Validation loss: 2.0791452520637104

Epoch: 6| Step: 2
Training loss: 2.222095012664795
Validation loss: 2.1049969657774894

Epoch: 6| Step: 3
Training loss: 2.1760663986206055
Validation loss: 2.142188302932247

Epoch: 6| Step: 4
Training loss: 1.5702745914459229
Validation loss: 2.1748282601756435

Epoch: 6| Step: 5
Training loss: 1.2933382987976074
Validation loss: 2.187143046368835

Epoch: 6| Step: 6
Training loss: 1.7387070655822754
Validation loss: 2.111502743536426

Epoch: 6| Step: 7
Training loss: 1.9808356761932373
Validation loss: 2.057208855946859

Epoch: 6| Step: 8
Training loss: 2.021479606628418
Validation loss: 2.011957235233758

Epoch: 6| Step: 9
Training loss: 1.4879295825958252
Validation loss: 1.9955409111515168

Epoch: 6| Step: 10
Training loss: 2.0577008724212646
Validation loss: 1.9910040337552306

Epoch: 6| Step: 11
Training loss: 1.5060992240905762
Validation loss: 1.9827060827644922

Epoch: 6| Step: 12
Training loss: 1.6346254348754883
Validation loss: 1.9781853255405222

Epoch: 6| Step: 13
Training loss: 2.2625153064727783
Validation loss: 1.9865714029599262

Epoch: 205| Step: 0
Training loss: 1.7217118740081787
Validation loss: 1.993102035214824

Epoch: 6| Step: 1
Training loss: 1.8984558582305908
Validation loss: 2.0189652135295253

Epoch: 6| Step: 2
Training loss: 2.135735034942627
Validation loss: 2.036051275909588

Epoch: 6| Step: 3
Training loss: 2.3654913902282715
Validation loss: 2.0609718638081707

Epoch: 6| Step: 4
Training loss: 1.587186574935913
Validation loss: 2.090846830798734

Epoch: 6| Step: 5
Training loss: 2.140557289123535
Validation loss: 2.098634171229537

Epoch: 6| Step: 6
Training loss: 1.811375379562378
Validation loss: 2.079496145248413

Epoch: 6| Step: 7
Training loss: 1.3136777877807617
Validation loss: 2.072992068465038

Epoch: 6| Step: 8
Training loss: 1.6916884183883667
Validation loss: 2.0501212330274683

Epoch: 6| Step: 9
Training loss: 2.1260182857513428
Validation loss: 2.0536052462875203

Epoch: 6| Step: 10
Training loss: 0.9806112051010132
Validation loss: 2.0326279670961442

Epoch: 6| Step: 11
Training loss: 1.9476951360702515
Validation loss: 2.014169627620328

Epoch: 6| Step: 12
Training loss: 1.9535505771636963
Validation loss: 2.020920245878158

Epoch: 6| Step: 13
Training loss: 2.1112053394317627
Validation loss: 2.029587976394161

Epoch: 206| Step: 0
Training loss: 1.6286485195159912
Validation loss: 2.0297150509331816

Epoch: 6| Step: 1
Training loss: 1.9011198282241821
Validation loss: 2.0319556754122496

Epoch: 6| Step: 2
Training loss: 2.1726388931274414
Validation loss: 2.047245499908283

Epoch: 6| Step: 3
Training loss: 1.2167894840240479
Validation loss: 2.071560887880223

Epoch: 6| Step: 4
Training loss: 1.578589677810669
Validation loss: 2.064952442722936

Epoch: 6| Step: 5
Training loss: 1.6361989974975586
Validation loss: 2.084853900376187

Epoch: 6| Step: 6
Training loss: 1.7610342502593994
Validation loss: 2.0978592852110505

Epoch: 6| Step: 7
Training loss: 1.4265496730804443
Validation loss: 2.081567669427523

Epoch: 6| Step: 8
Training loss: 2.412104606628418
Validation loss: 2.030328619864679

Epoch: 6| Step: 9
Training loss: 1.6949217319488525
Validation loss: 2.0313050029098347

Epoch: 6| Step: 10
Training loss: 1.9997596740722656
Validation loss: 2.037921796562851

Epoch: 6| Step: 11
Training loss: 2.2641265392303467
Validation loss: 2.0272068310809392

Epoch: 6| Step: 12
Training loss: 1.8911447525024414
Validation loss: 2.0382219796539633

Epoch: 6| Step: 13
Training loss: 2.2984132766723633
Validation loss: 2.0351608376349173

Epoch: 207| Step: 0
Training loss: 1.8102352619171143
Validation loss: 2.0289311960179317

Epoch: 6| Step: 1
Training loss: 1.9324297904968262
Validation loss: 2.0161867039178007

Epoch: 6| Step: 2
Training loss: 2.6214659214019775
Validation loss: 2.0174524835360947

Epoch: 6| Step: 3
Training loss: 1.2305628061294556
Validation loss: 2.004466938716109

Epoch: 6| Step: 4
Training loss: 1.4937299489974976
Validation loss: 2.0067580951157438

Epoch: 6| Step: 5
Training loss: 1.892385482788086
Validation loss: 2.0169806454771306

Epoch: 6| Step: 6
Training loss: 1.9913105964660645
Validation loss: 2.031034020967381

Epoch: 6| Step: 7
Training loss: 1.791942834854126
Validation loss: 2.0417953768084125

Epoch: 6| Step: 8
Training loss: 2.0791149139404297
Validation loss: 2.0541131957884757

Epoch: 6| Step: 9
Training loss: 1.9804614782333374
Validation loss: 2.0517250132817093

Epoch: 6| Step: 10
Training loss: 1.5575859546661377
Validation loss: 2.0543432876627934

Epoch: 6| Step: 11
Training loss: 1.6224137544631958
Validation loss: 2.0310036187530844

Epoch: 6| Step: 12
Training loss: 1.9437255859375
Validation loss: 2.033089030173517

Epoch: 6| Step: 13
Training loss: 1.2446202039718628
Validation loss: 2.023631212531879

Epoch: 208| Step: 0
Training loss: 2.3102235794067383
Validation loss: 2.0233199416950183

Epoch: 6| Step: 1
Training loss: 1.806643009185791
Validation loss: 2.0610501381658737

Epoch: 6| Step: 2
Training loss: 1.8710627555847168
Validation loss: 2.060056076254896

Epoch: 6| Step: 3
Training loss: 2.0803656578063965
Validation loss: 2.0639138273013535

Epoch: 6| Step: 4
Training loss: 1.3156681060791016
Validation loss: 2.0388045490428968

Epoch: 6| Step: 5
Training loss: 2.4444901943206787
Validation loss: 2.0629552654040757

Epoch: 6| Step: 6
Training loss: 1.2575600147247314
Validation loss: 2.0756376610007337

Epoch: 6| Step: 7
Training loss: 1.797135591506958
Validation loss: 2.0515145306946128

Epoch: 6| Step: 8
Training loss: 1.832031488418579
Validation loss: 2.0609470875032487

Epoch: 6| Step: 9
Training loss: 1.381056308746338
Validation loss: 2.0478506652257775

Epoch: 6| Step: 10
Training loss: 1.513044834136963
Validation loss: 2.0585277208717923

Epoch: 6| Step: 11
Training loss: 2.1495251655578613
Validation loss: 2.0472126391626175

Epoch: 6| Step: 12
Training loss: 1.6471234560012817
Validation loss: 2.064791279454385

Epoch: 6| Step: 13
Training loss: 1.9894757270812988
Validation loss: 2.048726133120957

Epoch: 209| Step: 0
Training loss: 1.996835470199585
Validation loss: 2.0592195987701416

Epoch: 6| Step: 1
Training loss: 1.4264049530029297
Validation loss: 2.0500658430078977

Epoch: 6| Step: 2
Training loss: 1.3827096223831177
Validation loss: 2.0485608513637255

Epoch: 6| Step: 3
Training loss: 1.7891690731048584
Validation loss: 2.0459735290978545

Epoch: 6| Step: 4
Training loss: 1.5109789371490479
Validation loss: 2.03803240611989

Epoch: 6| Step: 5
Training loss: 1.4732661247253418
Validation loss: 2.030363070067539

Epoch: 6| Step: 6
Training loss: 2.147906541824341
Validation loss: 2.0273740189049834

Epoch: 6| Step: 7
Training loss: 1.4016153812408447
Validation loss: 2.0021117912825717

Epoch: 6| Step: 8
Training loss: 1.392720341682434
Validation loss: 2.0271780567784465

Epoch: 6| Step: 9
Training loss: 1.9075431823730469
Validation loss: 2.0229419149378294

Epoch: 6| Step: 10
Training loss: 2.1866674423217773
Validation loss: 2.0441958468447448

Epoch: 6| Step: 11
Training loss: 2.223510980606079
Validation loss: 2.053839063131681

Epoch: 6| Step: 12
Training loss: 2.338221549987793
Validation loss: 2.0544483623197003

Epoch: 6| Step: 13
Training loss: 2.150163173675537
Validation loss: 2.055076012047388

Epoch: 210| Step: 0
Training loss: 1.5805273056030273
Validation loss: 2.036119240586476

Epoch: 6| Step: 1
Training loss: 2.1089303493499756
Validation loss: 2.012408028366745

Epoch: 6| Step: 2
Training loss: 2.3677337169647217
Validation loss: 2.0387228765795307

Epoch: 6| Step: 3
Training loss: 2.3858776092529297
Validation loss: 2.028511369100181

Epoch: 6| Step: 4
Training loss: 1.9560513496398926
Validation loss: 2.0236605495534916

Epoch: 6| Step: 5
Training loss: 1.072738766670227
Validation loss: 2.04290275163548

Epoch: 6| Step: 6
Training loss: 2.356259822845459
Validation loss: 2.0246483459267566

Epoch: 6| Step: 7
Training loss: 2.1335604190826416
Validation loss: 2.019790118740451

Epoch: 6| Step: 8
Training loss: 0.9822276830673218
Validation loss: 2.016891582037813

Epoch: 6| Step: 9
Training loss: 1.7828404903411865
Validation loss: 2.0360918891045356

Epoch: 6| Step: 10
Training loss: 1.3531458377838135
Validation loss: 2.0580484815823135

Epoch: 6| Step: 11
Training loss: 1.449324131011963
Validation loss: 2.0859485621093423

Epoch: 6| Step: 12
Training loss: 1.8177516460418701
Validation loss: 2.0801686420235583

Epoch: 6| Step: 13
Training loss: 1.5345101356506348
Validation loss: 2.0857842122354815

Epoch: 211| Step: 0
Training loss: 2.3182854652404785
Validation loss: 2.091691800343093

Epoch: 6| Step: 1
Training loss: 1.7812139987945557
Validation loss: 2.07360755243609

Epoch: 6| Step: 2
Training loss: 1.56465482711792
Validation loss: 2.0626875738943777

Epoch: 6| Step: 3
Training loss: 1.6039400100708008
Validation loss: 2.058717662288297

Epoch: 6| Step: 4
Training loss: 1.8119161128997803
Validation loss: 2.037126992338447

Epoch: 6| Step: 5
Training loss: 1.292539119720459
Validation loss: 2.037633393400459

Epoch: 6| Step: 6
Training loss: 1.4385648965835571
Validation loss: 2.0366623760551534

Epoch: 6| Step: 7
Training loss: 2.1366336345672607
Validation loss: 2.033947599831448

Epoch: 6| Step: 8
Training loss: 1.8319330215454102
Validation loss: 2.0333756836511756

Epoch: 6| Step: 9
Training loss: 1.9796738624572754
Validation loss: 2.0425037389160483

Epoch: 6| Step: 10
Training loss: 1.6383540630340576
Validation loss: 2.025351929408248

Epoch: 6| Step: 11
Training loss: 1.855193853378296
Validation loss: 2.029428833274431

Epoch: 6| Step: 12
Training loss: 2.1564173698425293
Validation loss: 2.041474906347131

Epoch: 6| Step: 13
Training loss: 1.6201752424240112
Validation loss: 2.0715661715435725

Epoch: 212| Step: 0
Training loss: 1.75764000415802
Validation loss: 2.0469887051531064

Epoch: 6| Step: 1
Training loss: 1.5863943099975586
Validation loss: 2.0377150402274182

Epoch: 6| Step: 2
Training loss: 1.8830400705337524
Validation loss: 2.0470803194148566

Epoch: 6| Step: 3
Training loss: 1.5300929546356201
Validation loss: 2.0402307395012147

Epoch: 6| Step: 4
Training loss: 1.7026677131652832
Validation loss: 2.019973131918138

Epoch: 6| Step: 5
Training loss: 0.9586664438247681
Validation loss: 2.0087565222094135

Epoch: 6| Step: 6
Training loss: 1.6572705507278442
Validation loss: 2.016533786250699

Epoch: 6| Step: 7
Training loss: 2.284438371658325
Validation loss: 2.012941865510838

Epoch: 6| Step: 8
Training loss: 1.8138939142227173
Validation loss: 2.0162765608038953

Epoch: 6| Step: 9
Training loss: 1.5960965156555176
Validation loss: 2.0177157809657436

Epoch: 6| Step: 10
Training loss: 1.8507966995239258
Validation loss: 2.0182052735359437

Epoch: 6| Step: 11
Training loss: 2.2242798805236816
Validation loss: 2.05679226434359

Epoch: 6| Step: 12
Training loss: 2.016024589538574
Validation loss: 2.0554643190035256

Epoch: 6| Step: 13
Training loss: 2.2887868881225586
Validation loss: 2.0484015710892214

Epoch: 213| Step: 0
Training loss: 2.0020384788513184
Validation loss: 2.0501510648317236

Epoch: 6| Step: 1
Training loss: 2.1108860969543457
Validation loss: 2.056378504281403

Epoch: 6| Step: 2
Training loss: 2.007349967956543
Validation loss: 2.066169326023389

Epoch: 6| Step: 3
Training loss: 1.8640999794006348
Validation loss: 2.036336196366177

Epoch: 6| Step: 4
Training loss: 2.120577335357666
Validation loss: 2.026492130371832

Epoch: 6| Step: 5
Training loss: 1.2914232015609741
Validation loss: 2.020170315619438

Epoch: 6| Step: 6
Training loss: 1.3876700401306152
Validation loss: 2.0015035611326977

Epoch: 6| Step: 7
Training loss: 1.6192940473556519
Validation loss: 2.014330699879636

Epoch: 6| Step: 8
Training loss: 1.5788049697875977
Validation loss: 2.0460782204904864

Epoch: 6| Step: 9
Training loss: 1.9587385654449463
Validation loss: 2.0393404524813414

Epoch: 6| Step: 10
Training loss: 1.6037378311157227
Validation loss: 2.075083094258462

Epoch: 6| Step: 11
Training loss: 1.8799293041229248
Validation loss: 2.069820716816892

Epoch: 6| Step: 12
Training loss: 1.6596567630767822
Validation loss: 2.078755409486832

Epoch: 6| Step: 13
Training loss: 2.0036418437957764
Validation loss: 2.0921978847954863

Epoch: 214| Step: 0
Training loss: 1.5457024574279785
Validation loss: 2.0597644621326077

Epoch: 6| Step: 1
Training loss: 2.4811596870422363
Validation loss: 2.0490149990204842

Epoch: 6| Step: 2
Training loss: 1.966810941696167
Validation loss: 2.0436186816102717

Epoch: 6| Step: 3
Training loss: 1.9465693235397339
Validation loss: 2.0202170802700903

Epoch: 6| Step: 4
Training loss: 1.6735951900482178
Validation loss: 2.0211242578362905

Epoch: 6| Step: 5
Training loss: 1.9067823886871338
Validation loss: 2.0236455368739303

Epoch: 6| Step: 6
Training loss: 2.0225629806518555
Validation loss: 2.019222318485219

Epoch: 6| Step: 7
Training loss: 1.8462574481964111
Validation loss: 2.033866115795669

Epoch: 6| Step: 8
Training loss: 2.1986632347106934
Validation loss: 2.0393813169130715

Epoch: 6| Step: 9
Training loss: 0.9541919231414795
Validation loss: 2.0424013394181446

Epoch: 6| Step: 10
Training loss: 1.3960769176483154
Validation loss: 2.0613873953460367

Epoch: 6| Step: 11
Training loss: 1.7165099382400513
Validation loss: 2.053142809098767

Epoch: 6| Step: 12
Training loss: 1.2930747270584106
Validation loss: 2.0143369449082242

Epoch: 6| Step: 13
Training loss: 1.69874906539917
Validation loss: 2.0302980792137886

Epoch: 215| Step: 0
Training loss: 1.6924993991851807
Validation loss: 2.020242808967508

Epoch: 6| Step: 1
Training loss: 1.8736791610717773
Validation loss: 2.0275448906806206

Epoch: 6| Step: 2
Training loss: 1.26166832447052
Validation loss: 2.0284453092082853

Epoch: 6| Step: 3
Training loss: 1.9595911502838135
Validation loss: 2.0499966977744974

Epoch: 6| Step: 4
Training loss: 1.719624400138855
Validation loss: 2.072578607066985

Epoch: 6| Step: 5
Training loss: 2.302140951156616
Validation loss: 2.0701937290929977

Epoch: 6| Step: 6
Training loss: 1.7535635232925415
Validation loss: 2.0839451410437144

Epoch: 6| Step: 7
Training loss: 1.7818055152893066
Validation loss: 2.096085448418894

Epoch: 6| Step: 8
Training loss: 1.4982069730758667
Validation loss: 2.0658852592591317

Epoch: 6| Step: 9
Training loss: 2.11643123626709
Validation loss: 2.0645995140075684

Epoch: 6| Step: 10
Training loss: 1.6306828260421753
Validation loss: 2.0454331392882974

Epoch: 6| Step: 11
Training loss: 1.2978711128234863
Validation loss: 2.013287804460013

Epoch: 6| Step: 12
Training loss: 1.890891194343567
Validation loss: 2.022392495985954

Epoch: 6| Step: 13
Training loss: 1.777135968208313
Validation loss: 2.000218049172432

Epoch: 216| Step: 0
Training loss: 1.6689071655273438
Validation loss: 1.9918488225629252

Epoch: 6| Step: 1
Training loss: 1.4595235586166382
Validation loss: 2.0011187394460044

Epoch: 6| Step: 2
Training loss: 1.3279988765716553
Validation loss: 1.9992945399335635

Epoch: 6| Step: 3
Training loss: 1.8701390027999878
Validation loss: 2.0044047268488074

Epoch: 6| Step: 4
Training loss: 2.3696365356445312
Validation loss: 2.028973005151236

Epoch: 6| Step: 5
Training loss: 1.5071825981140137
Validation loss: 2.046265794384864

Epoch: 6| Step: 6
Training loss: 1.2492351531982422
Validation loss: 2.0669881630969305

Epoch: 6| Step: 7
Training loss: 2.0843701362609863
Validation loss: 2.1068457903400546

Epoch: 6| Step: 8
Training loss: 2.1887481212615967
Validation loss: 2.1307453673372985

Epoch: 6| Step: 9
Training loss: 2.363462448120117
Validation loss: 2.088151833062531

Epoch: 6| Step: 10
Training loss: 1.4961085319519043
Validation loss: 2.0370769628914456

Epoch: 6| Step: 11
Training loss: 1.7436041831970215
Validation loss: 2.005794696910407

Epoch: 6| Step: 12
Training loss: 1.5595039129257202
Validation loss: 1.9810402265159033

Epoch: 6| Step: 13
Training loss: 1.6793274879455566
Validation loss: 1.989261870743126

Epoch: 217| Step: 0
Training loss: 1.5183875560760498
Validation loss: 1.9934413920166671

Epoch: 6| Step: 1
Training loss: 1.596088171005249
Validation loss: 1.995456467392624

Epoch: 6| Step: 2
Training loss: 1.8646281957626343
Validation loss: 2.012254922620712

Epoch: 6| Step: 3
Training loss: 1.4223095178604126
Validation loss: 2.02487019313279

Epoch: 6| Step: 4
Training loss: 2.6387877464294434
Validation loss: 2.059830011860017

Epoch: 6| Step: 5
Training loss: 2.3951683044433594
Validation loss: 2.069847554288885

Epoch: 6| Step: 6
Training loss: 1.620093584060669
Validation loss: 2.112878312346756

Epoch: 6| Step: 7
Training loss: 1.6468687057495117
Validation loss: 2.1274248835861043

Epoch: 6| Step: 8
Training loss: 1.4385066032409668
Validation loss: 2.115279407911403

Epoch: 6| Step: 9
Training loss: 1.999122142791748
Validation loss: 2.0735352757156535

Epoch: 6| Step: 10
Training loss: 1.696685791015625
Validation loss: 2.0824451087623514

Epoch: 6| Step: 11
Training loss: 1.48744797706604
Validation loss: 2.056188257791663

Epoch: 6| Step: 12
Training loss: 1.6752984523773193
Validation loss: 2.047900592127154

Epoch: 6| Step: 13
Training loss: 1.7362979650497437
Validation loss: 2.0498521533063663

Epoch: 218| Step: 0
Training loss: 1.8110363483428955
Validation loss: 2.065751741009374

Epoch: 6| Step: 1
Training loss: 2.326470375061035
Validation loss: 2.0683298367325977

Epoch: 6| Step: 2
Training loss: 2.1099064350128174
Validation loss: 2.0854053099950156

Epoch: 6| Step: 3
Training loss: 1.756378173828125
Validation loss: 2.072612936778735

Epoch: 6| Step: 4
Training loss: 1.5685231685638428
Validation loss: 2.0513289590035715

Epoch: 6| Step: 5
Training loss: 1.4978148937225342
Validation loss: 2.0363878973068728

Epoch: 6| Step: 6
Training loss: 2.152108669281006
Validation loss: 1.99747605733974

Epoch: 6| Step: 7
Training loss: 1.6230899095535278
Validation loss: 1.9704429065027544

Epoch: 6| Step: 8
Training loss: 1.1197947263717651
Validation loss: 1.9734760125478108

Epoch: 6| Step: 9
Training loss: 1.7616535425186157
Validation loss: 1.9649963122542187

Epoch: 6| Step: 10
Training loss: 1.2666516304016113
Validation loss: 1.979463017115029

Epoch: 6| Step: 11
Training loss: 2.113010883331299
Validation loss: 1.9847463125823646

Epoch: 6| Step: 12
Training loss: 1.5990266799926758
Validation loss: 2.012701993347496

Epoch: 6| Step: 13
Training loss: 1.9608930349349976
Validation loss: 2.0492098921088764

Epoch: 219| Step: 0
Training loss: 1.5334076881408691
Validation loss: 2.067574986847498

Epoch: 6| Step: 1
Training loss: 1.621690273284912
Validation loss: 2.082844497055136

Epoch: 6| Step: 2
Training loss: 1.7106870412826538
Validation loss: 2.1273979012684157

Epoch: 6| Step: 3
Training loss: 1.7778654098510742
Validation loss: 2.141887072593935

Epoch: 6| Step: 4
Training loss: 2.336733818054199
Validation loss: 2.1567106182857225

Epoch: 6| Step: 5
Training loss: 1.5662753582000732
Validation loss: 2.1405681871598765

Epoch: 6| Step: 6
Training loss: 1.757108449935913
Validation loss: 2.100866679222353

Epoch: 6| Step: 7
Training loss: 2.4815561771392822
Validation loss: 2.0667379953527965

Epoch: 6| Step: 8
Training loss: 1.542541742324829
Validation loss: 2.033915264632112

Epoch: 6| Step: 9
Training loss: 1.375457763671875
Validation loss: 2.006097819215508

Epoch: 6| Step: 10
Training loss: 1.1753780841827393
Validation loss: 2.0047219594319663

Epoch: 6| Step: 11
Training loss: 1.9074240922927856
Validation loss: 2.0009046985257055

Epoch: 6| Step: 12
Training loss: 2.180501937866211
Validation loss: 2.013216854423605

Epoch: 6| Step: 13
Training loss: 1.959503412246704
Validation loss: 2.0316511302865963

Epoch: 220| Step: 0
Training loss: 1.7612590789794922
Validation loss: 2.0567188224484845

Epoch: 6| Step: 1
Training loss: 1.8694119453430176
Validation loss: 2.089291695625551

Epoch: 6| Step: 2
Training loss: 1.4753165245056152
Validation loss: 2.109884064684632

Epoch: 6| Step: 3
Training loss: 2.1025235652923584
Validation loss: 2.090567957970404

Epoch: 6| Step: 4
Training loss: 1.7834991216659546
Validation loss: 2.0479985898540867

Epoch: 6| Step: 5
Training loss: 1.6769566535949707
Validation loss: 2.022575375854328

Epoch: 6| Step: 6
Training loss: 1.9070746898651123
Validation loss: 1.996312898974265

Epoch: 6| Step: 7
Training loss: 1.360555648803711
Validation loss: 1.9789615831067484

Epoch: 6| Step: 8
Training loss: 1.7508540153503418
Validation loss: 1.9822710560214134

Epoch: 6| Step: 9
Training loss: 1.4453908205032349
Validation loss: 1.998810120808181

Epoch: 6| Step: 10
Training loss: 2.093364715576172
Validation loss: 1.9992110677944717

Epoch: 6| Step: 11
Training loss: 2.288982629776001
Validation loss: 1.9894234249668736

Epoch: 6| Step: 12
Training loss: 1.6267616748809814
Validation loss: 2.014992678037254

Epoch: 6| Step: 13
Training loss: 1.5899202823638916
Validation loss: 2.021337793719384

Epoch: 221| Step: 0
Training loss: 1.502133846282959
Validation loss: 2.1016757949706046

Epoch: 6| Step: 1
Training loss: 1.5235095024108887
Validation loss: 2.167810022190053

Epoch: 6| Step: 2
Training loss: 2.2262306213378906
Validation loss: 2.2953171204495173

Epoch: 6| Step: 3
Training loss: 2.6054892539978027
Validation loss: 2.3099682971995366

Epoch: 6| Step: 4
Training loss: 1.7888407707214355
Validation loss: 2.226932156470514

Epoch: 6| Step: 5
Training loss: 1.9518177509307861
Validation loss: 2.0724869748597503

Epoch: 6| Step: 6
Training loss: 1.4641962051391602
Validation loss: 2.007845719655355

Epoch: 6| Step: 7
Training loss: 1.137428879737854
Validation loss: 1.9936579376138666

Epoch: 6| Step: 8
Training loss: 2.2285513877868652
Validation loss: 1.9554652014086324

Epoch: 6| Step: 9
Training loss: 2.1291940212249756
Validation loss: 1.961436221676488

Epoch: 6| Step: 10
Training loss: 1.071413278579712
Validation loss: 1.958771405681487

Epoch: 6| Step: 11
Training loss: 2.027456283569336
Validation loss: 1.9683723270252187

Epoch: 6| Step: 12
Training loss: 2.0245115756988525
Validation loss: 1.9759885059889926

Epoch: 6| Step: 13
Training loss: 1.7295724153518677
Validation loss: 1.964623478792047

Epoch: 222| Step: 0
Training loss: 1.8456175327301025
Validation loss: 1.9812774401839062

Epoch: 6| Step: 1
Training loss: 1.6654372215270996
Validation loss: 2.009234377132949

Epoch: 6| Step: 2
Training loss: 1.3024171590805054
Validation loss: 2.085484527772473

Epoch: 6| Step: 3
Training loss: 1.8886961936950684
Validation loss: 2.200318523632583

Epoch: 6| Step: 4
Training loss: 1.3443658351898193
Validation loss: 2.306313068636002

Epoch: 6| Step: 5
Training loss: 2.204834461212158
Validation loss: 2.2940727690214753

Epoch: 6| Step: 6
Training loss: 2.4040398597717285
Validation loss: 2.248208486905662

Epoch: 6| Step: 7
Training loss: 1.6505002975463867
Validation loss: 2.156552084030644

Epoch: 6| Step: 8
Training loss: 1.676066279411316
Validation loss: 2.0493845760181384

Epoch: 6| Step: 9
Training loss: 1.3784629106521606
Validation loss: 2.000137911047987

Epoch: 6| Step: 10
Training loss: 2.1658682823181152
Validation loss: 2.0078012943267822

Epoch: 6| Step: 11
Training loss: 2.3876125812530518
Validation loss: 2.0084493570430304

Epoch: 6| Step: 12
Training loss: 2.356494665145874
Validation loss: 2.000987918146195

Epoch: 6| Step: 13
Training loss: 0.8270865082740784
Validation loss: 2.0199623671911096

Epoch: 223| Step: 0
Training loss: 2.0214431285858154
Validation loss: 2.0216384933840845

Epoch: 6| Step: 1
Training loss: 1.6981291770935059
Validation loss: 2.0314753478573215

Epoch: 6| Step: 2
Training loss: 2.197814464569092
Validation loss: 2.024061390148696

Epoch: 6| Step: 3
Training loss: 1.8850858211517334
Validation loss: 2.01121126708164

Epoch: 6| Step: 4
Training loss: 1.901331901550293
Validation loss: 2.018831476088493

Epoch: 6| Step: 5
Training loss: 1.0565764904022217
Validation loss: 2.042283724713069

Epoch: 6| Step: 6
Training loss: 2.615342140197754
Validation loss: 2.0879758955329977

Epoch: 6| Step: 7
Training loss: 1.4041329622268677
Validation loss: 2.131169137134347

Epoch: 6| Step: 8
Training loss: 1.72954523563385
Validation loss: 2.1607929737337175

Epoch: 6| Step: 9
Training loss: 2.0340943336486816
Validation loss: 2.1253329592366375

Epoch: 6| Step: 10
Training loss: 1.4819470643997192
Validation loss: 2.1042908109644407

Epoch: 6| Step: 11
Training loss: 1.6739909648895264
Validation loss: 2.1136341864062893

Epoch: 6| Step: 12
Training loss: 1.8949600458145142
Validation loss: 2.087646775348212

Epoch: 6| Step: 13
Training loss: 1.196631669998169
Validation loss: 2.0371439879940403

Epoch: 224| Step: 0
Training loss: 1.087741494178772
Validation loss: 2.0201799869537354

Epoch: 6| Step: 1
Training loss: 1.8190525770187378
Validation loss: 2.0293090625475814

Epoch: 6| Step: 2
Training loss: 1.8276478052139282
Validation loss: 2.0317553909876014

Epoch: 6| Step: 3
Training loss: 1.951007604598999
Validation loss: 2.034175516456686

Epoch: 6| Step: 4
Training loss: 1.955583930015564
Validation loss: 2.035182176097747

Epoch: 6| Step: 5
Training loss: 1.2823848724365234
Validation loss: 2.0461379610082155

Epoch: 6| Step: 6
Training loss: 1.4409931898117065
Validation loss: 2.0296493089327248

Epoch: 6| Step: 7
Training loss: 2.199373722076416
Validation loss: 2.047675560879451

Epoch: 6| Step: 8
Training loss: 1.4310212135314941
Validation loss: 2.0482718047275337

Epoch: 6| Step: 9
Training loss: 1.8141833543777466
Validation loss: 2.0311900005545667

Epoch: 6| Step: 10
Training loss: 1.7074222564697266
Validation loss: 2.047475175190997

Epoch: 6| Step: 11
Training loss: 1.9305002689361572
Validation loss: 2.0488193009489324

Epoch: 6| Step: 12
Training loss: 1.7836576700210571
Validation loss: 2.0316451685402983

Epoch: 6| Step: 13
Training loss: 1.5648176670074463
Validation loss: 2.01629320011344

Epoch: 225| Step: 0
Training loss: 1.8936904668807983
Validation loss: 2.006166958039807

Epoch: 6| Step: 1
Training loss: 1.6520860195159912
Validation loss: 2.007407972889562

Epoch: 6| Step: 2
Training loss: 1.3169547319412231
Validation loss: 1.995888211393869

Epoch: 6| Step: 3
Training loss: 2.2117395401000977
Validation loss: 2.0052880189752065

Epoch: 6| Step: 4
Training loss: 2.245415210723877
Validation loss: 2.01231623208651

Epoch: 6| Step: 5
Training loss: 1.3425475358963013
Validation loss: 2.036176496936429

Epoch: 6| Step: 6
Training loss: 1.2070002555847168
Validation loss: 2.065125614084223

Epoch: 6| Step: 7
Training loss: 1.9349229335784912
Validation loss: 2.105645195130379

Epoch: 6| Step: 8
Training loss: 1.545198917388916
Validation loss: 2.1573366490743493

Epoch: 6| Step: 9
Training loss: 1.785973072052002
Validation loss: 2.1039325703856764

Epoch: 6| Step: 10
Training loss: 1.6943981647491455
Validation loss: 2.0636371835585563

Epoch: 6| Step: 11
Training loss: 1.9529154300689697
Validation loss: 2.0123469137376353

Epoch: 6| Step: 12
Training loss: 1.164360761642456
Validation loss: 1.9890853115307388

Epoch: 6| Step: 13
Training loss: 1.9879275560379028
Validation loss: 1.9945575973039031

Epoch: 226| Step: 0
Training loss: 1.3118596076965332
Validation loss: 1.9777696901752102

Epoch: 6| Step: 1
Training loss: 1.3480730056762695
Validation loss: 1.9709767013467767

Epoch: 6| Step: 2
Training loss: 1.7209594249725342
Validation loss: 1.9681999824380363

Epoch: 6| Step: 3
Training loss: 1.9892829656600952
Validation loss: 1.9625864644204416

Epoch: 6| Step: 4
Training loss: 1.7688438892364502
Validation loss: 1.9655612489228607

Epoch: 6| Step: 5
Training loss: 1.7810766696929932
Validation loss: 1.9787600655709543

Epoch: 6| Step: 6
Training loss: 1.9019818305969238
Validation loss: 1.9958862361087595

Epoch: 6| Step: 7
Training loss: 1.7943764925003052
Validation loss: 2.0295056719933786

Epoch: 6| Step: 8
Training loss: 1.9746220111846924
Validation loss: 2.062550857502927

Epoch: 6| Step: 9
Training loss: 1.6185437440872192
Validation loss: 2.097343147441905

Epoch: 6| Step: 10
Training loss: 1.5208936929702759
Validation loss: 2.0897041982220066

Epoch: 6| Step: 11
Training loss: 1.7450740337371826
Validation loss: 2.0845282167516728

Epoch: 6| Step: 12
Training loss: 1.7647939920425415
Validation loss: 2.090990662574768

Epoch: 6| Step: 13
Training loss: 1.4349342584609985
Validation loss: 2.0663965338019916

Epoch: 227| Step: 0
Training loss: 1.465232253074646
Validation loss: 2.044687040390507

Epoch: 6| Step: 1
Training loss: 1.6782371997833252
Validation loss: 2.0215185303841867

Epoch: 6| Step: 2
Training loss: 1.5300276279449463
Validation loss: 2.0098891783786077

Epoch: 6| Step: 3
Training loss: 1.7231454849243164
Validation loss: 1.9945186504753687

Epoch: 6| Step: 4
Training loss: 1.6018500328063965
Validation loss: 1.9796394160998765

Epoch: 6| Step: 5
Training loss: 1.2978365421295166
Validation loss: 1.9852050696649859

Epoch: 6| Step: 6
Training loss: 1.068467617034912
Validation loss: 1.9997143335239862

Epoch: 6| Step: 7
Training loss: 2.212578296661377
Validation loss: 1.992221906620969

Epoch: 6| Step: 8
Training loss: 1.909624457359314
Validation loss: 2.0057452340279855

Epoch: 6| Step: 9
Training loss: 2.36781644821167
Validation loss: 2.0035864960762764

Epoch: 6| Step: 10
Training loss: 1.8683290481567383
Validation loss: 2.0118807849063667

Epoch: 6| Step: 11
Training loss: 1.9549909830093384
Validation loss: 2.013902046347177

Epoch: 6| Step: 12
Training loss: 1.2834994792938232
Validation loss: 2.012227310929247

Epoch: 6| Step: 13
Training loss: 1.5131545066833496
Validation loss: 2.0230778135279173

Epoch: 228| Step: 0
Training loss: 2.3903427124023438
Validation loss: 2.033342722923525

Epoch: 6| Step: 1
Training loss: 1.9225332736968994
Validation loss: 2.024831565477515

Epoch: 6| Step: 2
Training loss: 1.8321404457092285
Validation loss: 2.0478073986627723

Epoch: 6| Step: 3
Training loss: 1.644129991531372
Validation loss: 2.044963308559951

Epoch: 6| Step: 4
Training loss: 1.229234218597412
Validation loss: 2.026021489533045

Epoch: 6| Step: 5
Training loss: 1.2938470840454102
Validation loss: 2.04958785733869

Epoch: 6| Step: 6
Training loss: 1.3347201347351074
Validation loss: 2.027128424695743

Epoch: 6| Step: 7
Training loss: 1.5518815517425537
Validation loss: 2.024648876600368

Epoch: 6| Step: 8
Training loss: 1.326714277267456
Validation loss: 2.014297790424798

Epoch: 6| Step: 9
Training loss: 1.7464687824249268
Validation loss: 2.022325074800881

Epoch: 6| Step: 10
Training loss: 1.9936907291412354
Validation loss: 2.0183220627487346

Epoch: 6| Step: 11
Training loss: 2.485457420349121
Validation loss: 2.007565507324793

Epoch: 6| Step: 12
Training loss: 1.2770029306411743
Validation loss: 1.9945559270920292

Epoch: 6| Step: 13
Training loss: 0.8884429931640625
Validation loss: 1.9911865239502282

Epoch: 229| Step: 0
Training loss: 1.4185956716537476
Validation loss: 1.986831970112298

Epoch: 6| Step: 1
Training loss: 1.3949670791625977
Validation loss: 1.9699986032260361

Epoch: 6| Step: 2
Training loss: 2.158719778060913
Validation loss: 1.9688562680316228

Epoch: 6| Step: 3
Training loss: 2.1953916549682617
Validation loss: 1.962035035574308

Epoch: 6| Step: 4
Training loss: 1.4341826438903809
Validation loss: 1.9960664561999741

Epoch: 6| Step: 5
Training loss: 1.4400001764297485
Validation loss: 2.011134527062857

Epoch: 6| Step: 6
Training loss: 1.5181405544281006
Validation loss: 2.0028633584258375

Epoch: 6| Step: 7
Training loss: 1.7269282341003418
Validation loss: 2.0183410747076875

Epoch: 6| Step: 8
Training loss: 1.3363571166992188
Validation loss: 2.03213583782155

Epoch: 6| Step: 9
Training loss: 1.5980439186096191
Validation loss: 2.0110033404442573

Epoch: 6| Step: 10
Training loss: 1.375046730041504
Validation loss: 1.9970489394280218

Epoch: 6| Step: 11
Training loss: 1.8082175254821777
Validation loss: 2.0048203019685644

Epoch: 6| Step: 12
Training loss: 2.3480937480926514
Validation loss: 2.0042863199787755

Epoch: 6| Step: 13
Training loss: 1.8088622093200684
Validation loss: 1.9917039730215584

Epoch: 230| Step: 0
Training loss: 1.1865744590759277
Validation loss: 2.0213904444889357

Epoch: 6| Step: 1
Training loss: 1.6309309005737305
Validation loss: 2.030671937491304

Epoch: 6| Step: 2
Training loss: 1.8507434129714966
Validation loss: 2.0311401864533782

Epoch: 6| Step: 3
Training loss: 2.0824599266052246
Validation loss: 2.000807346836213

Epoch: 6| Step: 4
Training loss: 1.558455467224121
Validation loss: 1.966365627063218

Epoch: 6| Step: 5
Training loss: 1.4482948780059814
Validation loss: 1.9530704021453857

Epoch: 6| Step: 6
Training loss: 1.9027642011642456
Validation loss: 1.961305881059298

Epoch: 6| Step: 7
Training loss: 2.0080676078796387
Validation loss: 1.939408758635162

Epoch: 6| Step: 8
Training loss: 1.7697912454605103
Validation loss: 1.952971104652651

Epoch: 6| Step: 9
Training loss: 1.7123627662658691
Validation loss: 1.9705284116088704

Epoch: 6| Step: 10
Training loss: 1.6561610698699951
Validation loss: 1.9745731123032109

Epoch: 6| Step: 11
Training loss: 0.9693721532821655
Validation loss: 1.97484601184886

Epoch: 6| Step: 12
Training loss: 2.1903843879699707
Validation loss: 1.9959228269515499

Epoch: 6| Step: 13
Training loss: 1.404360294342041
Validation loss: 2.028737291213005

Epoch: 231| Step: 0
Training loss: 1.3486247062683105
Validation loss: 2.0670061085813787

Epoch: 6| Step: 1
Training loss: 1.260313868522644
Validation loss: 2.0975274296217066

Epoch: 6| Step: 2
Training loss: 1.5937708616256714
Validation loss: 2.105815513159639

Epoch: 6| Step: 3
Training loss: 2.1659317016601562
Validation loss: 2.1124109580952632

Epoch: 6| Step: 4
Training loss: 1.4289073944091797
Validation loss: 2.0983362402967227

Epoch: 6| Step: 5
Training loss: 1.2386808395385742
Validation loss: 2.040590581073556

Epoch: 6| Step: 6
Training loss: 1.3701924085617065
Validation loss: 2.0208596285953315

Epoch: 6| Step: 7
Training loss: 1.972399115562439
Validation loss: 1.9933516594671434

Epoch: 6| Step: 8
Training loss: 1.854488492012024
Validation loss: 1.9967686296791158

Epoch: 6| Step: 9
Training loss: 2.3135805130004883
Validation loss: 1.9678438286627493

Epoch: 6| Step: 10
Training loss: 1.3245271444320679
Validation loss: 1.959889796472365

Epoch: 6| Step: 11
Training loss: 1.4314956665039062
Validation loss: 1.9857717560183616

Epoch: 6| Step: 12
Training loss: 1.9353899955749512
Validation loss: 1.9879293211044804

Epoch: 6| Step: 13
Training loss: 2.9898171424865723
Validation loss: 2.008788384417052

Epoch: 232| Step: 0
Training loss: 1.2480844259262085
Validation loss: 2.0219504628130185

Epoch: 6| Step: 1
Training loss: 1.609368085861206
Validation loss: 2.0534787357494397

Epoch: 6| Step: 2
Training loss: 1.7497358322143555
Validation loss: 2.056126220251924

Epoch: 6| Step: 3
Training loss: 1.5739481449127197
Validation loss: 2.0684453953978834

Epoch: 6| Step: 4
Training loss: 1.755327582359314
Validation loss: 2.076167465538107

Epoch: 6| Step: 5
Training loss: 2.158529281616211
Validation loss: 2.061485393072969

Epoch: 6| Step: 6
Training loss: 2.148756504058838
Validation loss: 2.0699123336422827

Epoch: 6| Step: 7
Training loss: 0.9537643790245056
Validation loss: 2.0651556240615023

Epoch: 6| Step: 8
Training loss: 2.058202028274536
Validation loss: 2.057703456571025

Epoch: 6| Step: 9
Training loss: 1.9830689430236816
Validation loss: 2.0483407256423787

Epoch: 6| Step: 10
Training loss: 1.76023268699646
Validation loss: 2.030963854123187

Epoch: 6| Step: 11
Training loss: 1.7277653217315674
Validation loss: 2.009624218428007

Epoch: 6| Step: 12
Training loss: 1.2168018817901611
Validation loss: 2.007548689842224

Epoch: 6| Step: 13
Training loss: 0.940460741519928
Validation loss: 2.016138235727946

Epoch: 233| Step: 0
Training loss: 1.6263961791992188
Validation loss: 2.0043212136914654

Epoch: 6| Step: 1
Training loss: 1.124831199645996
Validation loss: 2.011398355166117

Epoch: 6| Step: 2
Training loss: 2.058750629425049
Validation loss: 1.9983375162206671

Epoch: 6| Step: 3
Training loss: 1.5614745616912842
Validation loss: 2.011786742876935

Epoch: 6| Step: 4
Training loss: 1.7717639207839966
Validation loss: 2.0451016502995647

Epoch: 6| Step: 5
Training loss: 2.095613956451416
Validation loss: 2.0697720409721456

Epoch: 6| Step: 6
Training loss: 2.344135046005249
Validation loss: 2.097385865385814

Epoch: 6| Step: 7
Training loss: 1.8767979145050049
Validation loss: 2.1051896284985285

Epoch: 6| Step: 8
Training loss: 2.14374041557312
Validation loss: 2.110787296807894

Epoch: 6| Step: 9
Training loss: 1.145430326461792
Validation loss: 2.0987891868878434

Epoch: 6| Step: 10
Training loss: 1.5465034246444702
Validation loss: 2.0887889400605233

Epoch: 6| Step: 11
Training loss: 1.0742762088775635
Validation loss: 2.047822904843156

Epoch: 6| Step: 12
Training loss: 1.2857565879821777
Validation loss: 2.027461587741811

Epoch: 6| Step: 13
Training loss: 1.1905345916748047
Validation loss: 2.016748857754533

Epoch: 234| Step: 0
Training loss: 1.1243667602539062
Validation loss: 1.9986829347507928

Epoch: 6| Step: 1
Training loss: 1.5515916347503662
Validation loss: 2.0048302694033553

Epoch: 6| Step: 2
Training loss: 1.7580318450927734
Validation loss: 2.012525457207875

Epoch: 6| Step: 3
Training loss: 1.3955857753753662
Validation loss: 2.0113504599499445

Epoch: 6| Step: 4
Training loss: 2.2684943675994873
Validation loss: 2.0193975279408116

Epoch: 6| Step: 5
Training loss: 1.3245022296905518
Validation loss: 2.0486338625672045

Epoch: 6| Step: 6
Training loss: 2.472900867462158
Validation loss: 2.08168137714427

Epoch: 6| Step: 7
Training loss: 2.073112964630127
Validation loss: 2.0529049442660425

Epoch: 6| Step: 8
Training loss: 1.5843076705932617
Validation loss: 2.0563459665544572

Epoch: 6| Step: 9
Training loss: 1.6792738437652588
Validation loss: 2.028284110048766

Epoch: 6| Step: 10
Training loss: 2.038668394088745
Validation loss: 2.0090521522747573

Epoch: 6| Step: 11
Training loss: 1.1899229288101196
Validation loss: 1.9865125584345993

Epoch: 6| Step: 12
Training loss: 1.11175537109375
Validation loss: 1.9881722722002255

Epoch: 6| Step: 13
Training loss: 1.043164610862732
Validation loss: 1.993659359152599

Epoch: 235| Step: 0
Training loss: 1.7963910102844238
Validation loss: 2.048938489729358

Epoch: 6| Step: 1
Training loss: 1.3747541904449463
Validation loss: 2.0745516989820745

Epoch: 6| Step: 2
Training loss: 2.033255100250244
Validation loss: 2.086429742074782

Epoch: 6| Step: 3
Training loss: 1.6763238906860352
Validation loss: 2.1008320572555705

Epoch: 6| Step: 4
Training loss: 0.9697012901306152
Validation loss: 2.097626063131517

Epoch: 6| Step: 5
Training loss: 1.5521782636642456
Validation loss: 2.107343045614099

Epoch: 6| Step: 6
Training loss: 2.0287137031555176
Validation loss: 2.0402177431250132

Epoch: 6| Step: 7
Training loss: 1.9696862697601318
Validation loss: 2.006938353661568

Epoch: 6| Step: 8
Training loss: 1.3953454494476318
Validation loss: 1.9933527541416947

Epoch: 6| Step: 9
Training loss: 1.7236357927322388
Validation loss: 1.9916468230626916

Epoch: 6| Step: 10
Training loss: 1.7238428592681885
Validation loss: 1.9934633342168664

Epoch: 6| Step: 11
Training loss: 1.624544382095337
Validation loss: 1.9817251287480837

Epoch: 6| Step: 12
Training loss: 1.6800066232681274
Validation loss: 2.0007449170594573

Epoch: 6| Step: 13
Training loss: 1.5768197774887085
Validation loss: 1.9932773805433703

Epoch: 236| Step: 0
Training loss: 1.5586048364639282
Validation loss: 2.0034240945692985

Epoch: 6| Step: 1
Training loss: 1.611799955368042
Validation loss: 2.026635903184132

Epoch: 6| Step: 2
Training loss: 1.8946107625961304
Validation loss: 2.068289126119306

Epoch: 6| Step: 3
Training loss: 1.7986578941345215
Validation loss: 2.072004691247017

Epoch: 6| Step: 4
Training loss: 1.3126498460769653
Validation loss: 2.0387541222315964

Epoch: 6| Step: 5
Training loss: 0.9084771871566772
Validation loss: 2.0387528070839505

Epoch: 6| Step: 6
Training loss: 1.7365005016326904
Validation loss: 2.0314194079368346

Epoch: 6| Step: 7
Training loss: 1.3099673986434937
Validation loss: 2.0484560023071947

Epoch: 6| Step: 8
Training loss: 1.4882278442382812
Validation loss: 2.045089089742271

Epoch: 6| Step: 9
Training loss: 1.849421501159668
Validation loss: 2.022888204102875

Epoch: 6| Step: 10
Training loss: 1.3115841150283813
Validation loss: 2.0228578249613443

Epoch: 6| Step: 11
Training loss: 1.547914743423462
Validation loss: 2.032209127180038

Epoch: 6| Step: 12
Training loss: 2.498842716217041
Validation loss: 2.0235937564603743

Epoch: 6| Step: 13
Training loss: 2.1941628456115723
Validation loss: 2.0145773913270686

Epoch: 237| Step: 0
Training loss: 1.1723873615264893
Validation loss: 2.0116282355400825

Epoch: 6| Step: 1
Training loss: 1.5390465259552002
Validation loss: 1.9937724477501326

Epoch: 6| Step: 2
Training loss: 1.145554780960083
Validation loss: 1.9807414726544452

Epoch: 6| Step: 3
Training loss: 0.9444270133972168
Validation loss: 1.9920172781072638

Epoch: 6| Step: 4
Training loss: 1.4162602424621582
Validation loss: 1.9815472223425423

Epoch: 6| Step: 5
Training loss: 1.7620282173156738
Validation loss: 1.9986152572016562

Epoch: 6| Step: 6
Training loss: 1.3424551486968994
Validation loss: 2.000447548845763

Epoch: 6| Step: 7
Training loss: 2.329411506652832
Validation loss: 2.012261685504708

Epoch: 6| Step: 8
Training loss: 1.4743919372558594
Validation loss: 2.021407104307605

Epoch: 6| Step: 9
Training loss: 1.9044768810272217
Validation loss: 2.0119968280997327

Epoch: 6| Step: 10
Training loss: 1.779604196548462
Validation loss: 2.035457750802399

Epoch: 6| Step: 11
Training loss: 2.189718008041382
Validation loss: 2.0484257308385705

Epoch: 6| Step: 12
Training loss: 1.3836417198181152
Validation loss: 2.0267401664487776

Epoch: 6| Step: 13
Training loss: 2.1533737182617188
Validation loss: 2.0286256138996412

Epoch: 238| Step: 0
Training loss: 1.2324955463409424
Validation loss: 2.0590581406829176

Epoch: 6| Step: 1
Training loss: 2.116596221923828
Validation loss: 2.0749152860333844

Epoch: 6| Step: 2
Training loss: 1.8208105564117432
Validation loss: 2.131931484386485

Epoch: 6| Step: 3
Training loss: 0.8192973136901855
Validation loss: 2.2058650575658327

Epoch: 6| Step: 4
Training loss: 1.6073081493377686
Validation loss: 2.199015486624933

Epoch: 6| Step: 5
Training loss: 1.3802927732467651
Validation loss: 2.1435151997432915

Epoch: 6| Step: 6
Training loss: 2.268434524536133
Validation loss: 2.0636678100914083

Epoch: 6| Step: 7
Training loss: 1.724560022354126
Validation loss: 2.024835837784634

Epoch: 6| Step: 8
Training loss: 1.869673728942871
Validation loss: 1.994927878020912

Epoch: 6| Step: 9
Training loss: 1.0580189228057861
Validation loss: 1.954736235321209

Epoch: 6| Step: 10
Training loss: 2.665170192718506
Validation loss: 1.9660966524513819

Epoch: 6| Step: 11
Training loss: 0.9326859712600708
Validation loss: 1.9592525254013717

Epoch: 6| Step: 12
Training loss: 1.6112312078475952
Validation loss: 1.9572439552635275

Epoch: 6| Step: 13
Training loss: 1.3387188911437988
Validation loss: 1.9812554877291444

Epoch: 239| Step: 0
Training loss: 1.6481425762176514
Validation loss: 2.0044568918084584

Epoch: 6| Step: 1
Training loss: 1.4396255016326904
Validation loss: 2.0288097063700357

Epoch: 6| Step: 2
Training loss: 1.0347399711608887
Validation loss: 2.061924911314441

Epoch: 6| Step: 3
Training loss: 1.2360020875930786
Validation loss: 2.089417403744113

Epoch: 6| Step: 4
Training loss: 1.5601332187652588
Validation loss: 2.0955283795633624

Epoch: 6| Step: 5
Training loss: 1.8034409284591675
Validation loss: 2.057086456206537

Epoch: 6| Step: 6
Training loss: 2.012146472930908
Validation loss: 2.0193982470420098

Epoch: 6| Step: 7
Training loss: 1.6446242332458496
Validation loss: 2.012697970995339

Epoch: 6| Step: 8
Training loss: 2.078580856323242
Validation loss: 1.9965928331498177

Epoch: 6| Step: 9
Training loss: 1.1716619729995728
Validation loss: 1.989669374240342

Epoch: 6| Step: 10
Training loss: 1.4203991889953613
Validation loss: 1.9723090048759215

Epoch: 6| Step: 11
Training loss: 1.8231332302093506
Validation loss: 1.9842765741450812

Epoch: 6| Step: 12
Training loss: 1.8878611326217651
Validation loss: 1.9692779740979593

Epoch: 6| Step: 13
Training loss: 1.6209619045257568
Validation loss: 1.9884196391669653

Epoch: 240| Step: 0
Training loss: 1.2540531158447266
Validation loss: 2.013691771414972

Epoch: 6| Step: 1
Training loss: 2.1198272705078125
Validation loss: 2.0532927500304354

Epoch: 6| Step: 2
Training loss: 2.272264003753662
Validation loss: 2.103391199983576

Epoch: 6| Step: 3
Training loss: 1.4364550113677979
Validation loss: 2.0722187847219486

Epoch: 6| Step: 4
Training loss: 1.441577672958374
Validation loss: 2.041239566700433

Epoch: 6| Step: 5
Training loss: 1.733120083808899
Validation loss: 2.0122783594234015

Epoch: 6| Step: 6
Training loss: 1.4102813005447388
Validation loss: 1.9823403076459003

Epoch: 6| Step: 7
Training loss: 1.4662394523620605
Validation loss: 1.965548123082807

Epoch: 6| Step: 8
Training loss: 1.5604610443115234
Validation loss: 1.970547406904159

Epoch: 6| Step: 9
Training loss: 1.215052604675293
Validation loss: 1.9651606698190012

Epoch: 6| Step: 10
Training loss: 1.821917176246643
Validation loss: 1.9858385260387132

Epoch: 6| Step: 11
Training loss: 1.770932912826538
Validation loss: 2.0062171566870903

Epoch: 6| Step: 12
Training loss: 1.6367192268371582
Validation loss: 2.050891871093422

Epoch: 6| Step: 13
Training loss: 1.2317204475402832
Validation loss: 2.0733910427298596

Epoch: 241| Step: 0
Training loss: 1.2984559535980225
Validation loss: 2.072876318808525

Epoch: 6| Step: 1
Training loss: 1.4972779750823975
Validation loss: 2.0482138100490777

Epoch: 6| Step: 2
Training loss: 1.6493226289749146
Validation loss: 2.039220740718226

Epoch: 6| Step: 3
Training loss: 1.8770525455474854
Validation loss: 2.0439836209820164

Epoch: 6| Step: 4
Training loss: 2.0600287914276123
Validation loss: 2.020553009484404

Epoch: 6| Step: 5
Training loss: 1.180342435836792
Validation loss: 2.029696692702591

Epoch: 6| Step: 6
Training loss: 1.2339798212051392
Validation loss: 2.031853929642708

Epoch: 6| Step: 7
Training loss: 2.0442895889282227
Validation loss: 2.0237653114462413

Epoch: 6| Step: 8
Training loss: 1.2458809614181519
Validation loss: 2.058867305837652

Epoch: 6| Step: 9
Training loss: 1.7570867538452148
Validation loss: 2.0510564965586506

Epoch: 6| Step: 10
Training loss: 1.4324452877044678
Validation loss: 2.081302031393974

Epoch: 6| Step: 11
Training loss: 1.4451899528503418
Validation loss: 2.0979211048413346

Epoch: 6| Step: 12
Training loss: 1.8208508491516113
Validation loss: 2.0834374299613376

Epoch: 6| Step: 13
Training loss: 1.886313557624817
Validation loss: 2.0810109979362896

Epoch: 242| Step: 0
Training loss: 2.0205492973327637
Validation loss: 2.0489269020736858

Epoch: 6| Step: 1
Training loss: 1.3879810571670532
Validation loss: 2.0389099223639375

Epoch: 6| Step: 2
Training loss: 1.4726473093032837
Validation loss: 2.0183904952900384

Epoch: 6| Step: 3
Training loss: 1.4400405883789062
Validation loss: 2.023004880515478

Epoch: 6| Step: 4
Training loss: 1.2457207441329956
Validation loss: 2.02564480996901

Epoch: 6| Step: 5
Training loss: 1.9863343238830566
Validation loss: 1.9981746340310702

Epoch: 6| Step: 6
Training loss: 1.4555933475494385
Validation loss: 1.9996113930979083

Epoch: 6| Step: 7
Training loss: 1.1420037746429443
Validation loss: 2.0046583683260026

Epoch: 6| Step: 8
Training loss: 1.461360216140747
Validation loss: 2.004885822214106

Epoch: 6| Step: 9
Training loss: 0.9508571624755859
Validation loss: 2.00381863117218

Epoch: 6| Step: 10
Training loss: 1.922868251800537
Validation loss: 2.004947513662359

Epoch: 6| Step: 11
Training loss: 1.642223596572876
Validation loss: 2.007100389849755

Epoch: 6| Step: 12
Training loss: 2.1373021602630615
Validation loss: 2.014651193413683

Epoch: 6| Step: 13
Training loss: 2.005734920501709
Validation loss: 2.017139373287078

Epoch: 243| Step: 0
Training loss: 0.7355271577835083
Validation loss: 2.0290452677716493

Epoch: 6| Step: 1
Training loss: 2.012181282043457
Validation loss: 2.029608557301183

Epoch: 6| Step: 2
Training loss: 1.6486417055130005
Validation loss: 2.046841618835285

Epoch: 6| Step: 3
Training loss: 1.4701539278030396
Validation loss: 2.0222692374260194

Epoch: 6| Step: 4
Training loss: 1.7716219425201416
Validation loss: 2.0118561611380628

Epoch: 6| Step: 5
Training loss: 1.622405767440796
Validation loss: 2.024391802408362

Epoch: 6| Step: 6
Training loss: 1.5609416961669922
Validation loss: 2.026736013350948

Epoch: 6| Step: 7
Training loss: 1.4957393407821655
Validation loss: 2.0196361464838826

Epoch: 6| Step: 8
Training loss: 1.9404206275939941
Validation loss: 2.034984528377492

Epoch: 6| Step: 9
Training loss: 1.0684523582458496
Validation loss: 2.0698602314918273

Epoch: 6| Step: 10
Training loss: 1.323310375213623
Validation loss: 2.0974302445688555

Epoch: 6| Step: 11
Training loss: 1.7540440559387207
Validation loss: 2.101872182661487

Epoch: 6| Step: 12
Training loss: 1.784260869026184
Validation loss: 2.169592966315567

Epoch: 6| Step: 13
Training loss: 1.7658908367156982
Validation loss: 2.1294029041003157

Epoch: 244| Step: 0
Training loss: 2.052191972732544
Validation loss: 2.0497675608563166

Epoch: 6| Step: 1
Training loss: 1.2060868740081787
Validation loss: 1.9977578411820114

Epoch: 6| Step: 2
Training loss: 1.2517366409301758
Validation loss: 1.9758129747965003

Epoch: 6| Step: 3
Training loss: 2.149833917617798
Validation loss: 1.9597270463102607

Epoch: 6| Step: 4
Training loss: 1.9018909931182861
Validation loss: 1.9582198486533215

Epoch: 6| Step: 5
Training loss: 0.9794381856918335
Validation loss: 1.957275616225376

Epoch: 6| Step: 6
Training loss: 0.9925056099891663
Validation loss: 1.960002517187467

Epoch: 6| Step: 7
Training loss: 1.625054121017456
Validation loss: 1.9455268152298466

Epoch: 6| Step: 8
Training loss: 1.9464001655578613
Validation loss: 1.981661327423588

Epoch: 6| Step: 9
Training loss: 1.2855647802352905
Validation loss: 2.030559588504094

Epoch: 6| Step: 10
Training loss: 1.3528132438659668
Validation loss: 2.0622107239179712

Epoch: 6| Step: 11
Training loss: 1.8436365127563477
Validation loss: 2.093007510708224

Epoch: 6| Step: 12
Training loss: 2.0103864669799805
Validation loss: 2.032304071610974

Epoch: 6| Step: 13
Training loss: 1.8523529767990112
Validation loss: 1.9971788801172727

Epoch: 245| Step: 0
Training loss: 1.9416368007659912
Validation loss: 1.9598914166932464

Epoch: 6| Step: 1
Training loss: 1.0919771194458008
Validation loss: 1.9495458923360354

Epoch: 6| Step: 2
Training loss: 1.435563564300537
Validation loss: 1.939649066617412

Epoch: 6| Step: 3
Training loss: 2.055213689804077
Validation loss: 1.959302871457992

Epoch: 6| Step: 4
Training loss: 1.8094300031661987
Validation loss: 1.9739146053150136

Epoch: 6| Step: 5
Training loss: 1.5942109823226929
Validation loss: 1.9844157952134327

Epoch: 6| Step: 6
Training loss: 1.3485792875289917
Validation loss: 2.036370808078397

Epoch: 6| Step: 7
Training loss: 1.5303475856781006
Validation loss: 2.058668223760461

Epoch: 6| Step: 8
Training loss: 1.037446141242981
Validation loss: 2.0576884592733076

Epoch: 6| Step: 9
Training loss: 1.4710975885391235
Validation loss: 2.069286031107749

Epoch: 6| Step: 10
Training loss: 2.429684638977051
Validation loss: 2.046894733623792

Epoch: 6| Step: 11
Training loss: 1.074493408203125
Validation loss: 2.0295653266291462

Epoch: 6| Step: 12
Training loss: 1.4607551097869873
Validation loss: 2.0240949341045913

Epoch: 6| Step: 13
Training loss: 1.8223406076431274
Validation loss: 2.0311742264737367

Epoch: 246| Step: 0
Training loss: 1.4590239524841309
Validation loss: 2.038407548781364

Epoch: 6| Step: 1
Training loss: 1.7764325141906738
Validation loss: 2.0765813935187554

Epoch: 6| Step: 2
Training loss: 1.7144708633422852
Validation loss: 2.0641830685318157

Epoch: 6| Step: 3
Training loss: 1.7968388795852661
Validation loss: 2.053654759160934

Epoch: 6| Step: 4
Training loss: 1.4844566583633423
Validation loss: 2.0476830018463956

Epoch: 6| Step: 5
Training loss: 1.5022997856140137
Validation loss: 2.0348808688502156

Epoch: 6| Step: 6
Training loss: 1.8693597316741943
Validation loss: 2.018063450372347

Epoch: 6| Step: 7
Training loss: 1.7392449378967285
Validation loss: 2.0336508404824043

Epoch: 6| Step: 8
Training loss: 0.9056494235992432
Validation loss: 2.0708587208101825

Epoch: 6| Step: 9
Training loss: 1.876124382019043
Validation loss: 2.130044908933742

Epoch: 6| Step: 10
Training loss: 1.7961938381195068
Validation loss: 2.184923559106806

Epoch: 6| Step: 11
Training loss: 1.5725493431091309
Validation loss: 2.185981863288469

Epoch: 6| Step: 12
Training loss: 1.6724354028701782
Validation loss: 2.112165222885788

Epoch: 6| Step: 13
Training loss: 0.7276898622512817
Validation loss: 2.029121950108518

Epoch: 247| Step: 0
Training loss: 1.799347996711731
Validation loss: 1.9558060502493253

Epoch: 6| Step: 1
Training loss: 1.5370203256607056
Validation loss: 1.933103399892007

Epoch: 6| Step: 2
Training loss: 1.4012126922607422
Validation loss: 1.9239703365551528

Epoch: 6| Step: 3
Training loss: 1.6988811492919922
Validation loss: 1.917866785039184

Epoch: 6| Step: 4
Training loss: 1.2787396907806396
Validation loss: 1.933080232271584

Epoch: 6| Step: 5
Training loss: 1.3787524700164795
Validation loss: 1.9470509598332066

Epoch: 6| Step: 6
Training loss: 1.6863083839416504
Validation loss: 1.9510601053955734

Epoch: 6| Step: 7
Training loss: 1.5991131067276
Validation loss: 1.9527014032486947

Epoch: 6| Step: 8
Training loss: 1.6934617757797241
Validation loss: 1.9938727424990745

Epoch: 6| Step: 9
Training loss: 1.647695779800415
Validation loss: 2.0080188987075642

Epoch: 6| Step: 10
Training loss: 1.5643813610076904
Validation loss: 2.0647204870818765

Epoch: 6| Step: 11
Training loss: 2.2590489387512207
Validation loss: 2.097927346024462

Epoch: 6| Step: 12
Training loss: 1.5656993389129639
Validation loss: 2.154618345281129

Epoch: 6| Step: 13
Training loss: 1.0618404150009155
Validation loss: 2.1657835001586587

Epoch: 248| Step: 0
Training loss: 1.411569356918335
Validation loss: 2.144903987966558

Epoch: 6| Step: 1
Training loss: 1.674055814743042
Validation loss: 2.110565846966159

Epoch: 6| Step: 2
Training loss: 1.408820629119873
Validation loss: 2.086544616248018

Epoch: 6| Step: 3
Training loss: 1.9142646789550781
Validation loss: 2.0681273155314948

Epoch: 6| Step: 4
Training loss: 2.029564619064331
Validation loss: 2.063912719808599

Epoch: 6| Step: 5
Training loss: 1.2907400131225586
Validation loss: 2.0664454993381294

Epoch: 6| Step: 6
Training loss: 0.8726586103439331
Validation loss: 2.0652330408814135

Epoch: 6| Step: 7
Training loss: 1.5020233392715454
Validation loss: 2.062229384658157

Epoch: 6| Step: 8
Training loss: 1.2314319610595703
Validation loss: 2.0532068565327632

Epoch: 6| Step: 9
Training loss: 1.3339475393295288
Validation loss: 2.026804233110079

Epoch: 6| Step: 10
Training loss: 1.3119176626205444
Validation loss: 2.0206632511590117

Epoch: 6| Step: 11
Training loss: 1.6279230117797852
Validation loss: 1.9746668543866885

Epoch: 6| Step: 12
Training loss: 2.1784913539886475
Validation loss: 1.9548102732627624

Epoch: 6| Step: 13
Training loss: 1.7131227254867554
Validation loss: 1.9588031666253203

Epoch: 249| Step: 0
Training loss: 1.3326516151428223
Validation loss: 1.9480001875149306

Epoch: 6| Step: 1
Training loss: 1.046325445175171
Validation loss: 1.9688377457280313

Epoch: 6| Step: 2
Training loss: 1.8999310731887817
Validation loss: 1.9620475730588358

Epoch: 6| Step: 3
Training loss: 1.4811689853668213
Validation loss: 1.9979333313562537

Epoch: 6| Step: 4
Training loss: 1.7482638359069824
Validation loss: 2.0255152397258307

Epoch: 6| Step: 5
Training loss: 1.775017499923706
Validation loss: 2.0692620226131972

Epoch: 6| Step: 6
Training loss: 1.5391993522644043
Validation loss: 2.0473466586041194

Epoch: 6| Step: 7
Training loss: 1.8503828048706055
Validation loss: 2.036044074643043

Epoch: 6| Step: 8
Training loss: 1.9690630435943604
Validation loss: 2.02792517856885

Epoch: 6| Step: 9
Training loss: 1.4745793342590332
Validation loss: 2.029251285778579

Epoch: 6| Step: 10
Training loss: 1.4657841920852661
Validation loss: 2.0140180062222224

Epoch: 6| Step: 11
Training loss: 0.8930416107177734
Validation loss: 2.0104072978419643

Epoch: 6| Step: 12
Training loss: 1.2476556301116943
Validation loss: 2.016607344791453

Epoch: 6| Step: 13
Training loss: 1.7668737173080444
Validation loss: 2.037186397019253

Epoch: 250| Step: 0
Training loss: 2.0496058464050293
Validation loss: 2.0704112565645607

Epoch: 6| Step: 1
Training loss: 1.2376551628112793
Validation loss: 2.1018946222079697

Epoch: 6| Step: 2
Training loss: 1.5898197889328003
Validation loss: 2.130540173540833

Epoch: 6| Step: 3
Training loss: 1.9637422561645508
Validation loss: 2.1369485521829255

Epoch: 6| Step: 4
Training loss: 1.0485576391220093
Validation loss: 2.0989764377635014

Epoch: 6| Step: 5
Training loss: 1.3726164102554321
Validation loss: 2.058870771879791

Epoch: 6| Step: 6
Training loss: 1.3930375576019287
Validation loss: 2.0550097265551166

Epoch: 6| Step: 7
Training loss: 1.6912897825241089
Validation loss: 2.0235125762160107

Epoch: 6| Step: 8
Training loss: 1.5147409439086914
Validation loss: 1.9982600314642793

Epoch: 6| Step: 9
Training loss: 1.4890027046203613
Validation loss: 1.9827108049905429

Epoch: 6| Step: 10
Training loss: 1.4760091304779053
Validation loss: 1.9793016167097195

Epoch: 6| Step: 11
Training loss: 1.488731861114502
Validation loss: 1.9769791787670505

Epoch: 6| Step: 12
Training loss: 1.4454376697540283
Validation loss: 1.9869752494237756

Epoch: 6| Step: 13
Training loss: 2.384056806564331
Validation loss: 1.980494221051534

Epoch: 251| Step: 0
Training loss: 1.5402312278747559
Validation loss: 1.9851522996861448

Epoch: 6| Step: 1
Training loss: 0.923478364944458
Validation loss: 1.9929083265284055

Epoch: 6| Step: 2
Training loss: 1.9944570064544678
Validation loss: 2.0066220862891084

Epoch: 6| Step: 3
Training loss: 1.086629033088684
Validation loss: 1.989846444899036

Epoch: 6| Step: 4
Training loss: 1.4716517925262451
Validation loss: 2.0208700369763117

Epoch: 6| Step: 5
Training loss: 1.6036911010742188
Validation loss: 2.0256296370619085

Epoch: 6| Step: 6
Training loss: 1.3476088047027588
Validation loss: 2.0165240008343934

Epoch: 6| Step: 7
Training loss: 1.4100441932678223
Validation loss: 2.0698830773753505

Epoch: 6| Step: 8
Training loss: 2.247556686401367
Validation loss: 2.0917724704229705

Epoch: 6| Step: 9
Training loss: 1.323674201965332
Validation loss: 2.0954577897184636

Epoch: 6| Step: 10
Training loss: 1.781268835067749
Validation loss: 2.058656447677202

Epoch: 6| Step: 11
Training loss: 1.6343340873718262
Validation loss: 2.047723374059123

Epoch: 6| Step: 12
Training loss: 1.0978881120681763
Validation loss: 2.028049994540471

Epoch: 6| Step: 13
Training loss: 1.8855109214782715
Validation loss: 2.0077445904413858

Epoch: 252| Step: 0
Training loss: 1.389359712600708
Validation loss: 2.0157297606109292

Epoch: 6| Step: 1
Training loss: 1.402477502822876
Validation loss: 2.0267220440731255

Epoch: 6| Step: 2
Training loss: 2.137787103652954
Validation loss: 2.055421967660227

Epoch: 6| Step: 3
Training loss: 1.1456079483032227
Validation loss: 2.0744548895025767

Epoch: 6| Step: 4
Training loss: 1.453766107559204
Validation loss: 2.0746117689276256

Epoch: 6| Step: 5
Training loss: 1.5549578666687012
Validation loss: 2.048165346986504

Epoch: 6| Step: 6
Training loss: 1.592943549156189
Validation loss: 2.018598735973399

Epoch: 6| Step: 7
Training loss: 1.6572582721710205
Validation loss: 1.9844971715763051

Epoch: 6| Step: 8
Training loss: 1.4322831630706787
Validation loss: 1.956492257374589

Epoch: 6| Step: 9
Training loss: 1.4594991207122803
Validation loss: 1.944753873732782

Epoch: 6| Step: 10
Training loss: 1.2989002466201782
Validation loss: 1.9616274910588418

Epoch: 6| Step: 11
Training loss: 1.3508838415145874
Validation loss: 1.969209050619474

Epoch: 6| Step: 12
Training loss: 1.6504806280136108
Validation loss: 1.9801331848226569

Epoch: 6| Step: 13
Training loss: 2.0270233154296875
Validation loss: 2.012372583471319

Epoch: 253| Step: 0
Training loss: 1.3182463645935059
Validation loss: 2.0680167546836277

Epoch: 6| Step: 1
Training loss: 1.4233092069625854
Validation loss: 2.1035968129352858

Epoch: 6| Step: 2
Training loss: 1.500008225440979
Validation loss: 2.115059816709129

Epoch: 6| Step: 3
Training loss: 1.9594894647598267
Validation loss: 2.115159526948006

Epoch: 6| Step: 4
Training loss: 1.3571122884750366
Validation loss: 2.084590296591482

Epoch: 6| Step: 5
Training loss: 1.7980729341506958
Validation loss: 2.048192972777992

Epoch: 6| Step: 6
Training loss: 2.2295100688934326
Validation loss: 2.022033101768904

Epoch: 6| Step: 7
Training loss: 1.2414501905441284
Validation loss: 1.9905218642245057

Epoch: 6| Step: 8
Training loss: 1.4407134056091309
Validation loss: 1.995865212973728

Epoch: 6| Step: 9
Training loss: 1.1793245077133179
Validation loss: 1.977706406706123

Epoch: 6| Step: 10
Training loss: 1.3974316120147705
Validation loss: 1.9875025800479356

Epoch: 6| Step: 11
Training loss: 1.1229159832000732
Validation loss: 1.9844712416330974

Epoch: 6| Step: 12
Training loss: 1.7612898349761963
Validation loss: 2.004682993376127

Epoch: 6| Step: 13
Training loss: 1.4018149375915527
Validation loss: 2.0295530621723463

Epoch: 254| Step: 0
Training loss: 1.6717679500579834
Validation loss: 2.041881448479109

Epoch: 6| Step: 1
Training loss: 1.2442922592163086
Validation loss: 2.0171198203999507

Epoch: 6| Step: 2
Training loss: 1.4378283023834229
Validation loss: 2.029044007742277

Epoch: 6| Step: 3
Training loss: 1.4281866550445557
Validation loss: 2.028985805408929

Epoch: 6| Step: 4
Training loss: 1.012563943862915
Validation loss: 2.0155818705917685

Epoch: 6| Step: 5
Training loss: 2.0214366912841797
Validation loss: 2.0063364275040163

Epoch: 6| Step: 6
Training loss: 1.1323716640472412
Validation loss: 2.0292097471093618

Epoch: 6| Step: 7
Training loss: 1.0912930965423584
Validation loss: 2.0311105610221944

Epoch: 6| Step: 8
Training loss: 1.6221736669540405
Validation loss: 2.047853041720647

Epoch: 6| Step: 9
Training loss: 1.7342216968536377
Validation loss: 2.0586023561416136

Epoch: 6| Step: 10
Training loss: 1.8074147701263428
Validation loss: 2.079412821800478

Epoch: 6| Step: 11
Training loss: 1.6976032257080078
Validation loss: 2.0887109618033133

Epoch: 6| Step: 12
Training loss: 1.418681263923645
Validation loss: 2.091294742399646

Epoch: 6| Step: 13
Training loss: 1.7088526487350464
Validation loss: 2.0887863225834344

Epoch: 255| Step: 0
Training loss: 1.4318259954452515
Validation loss: 2.092703675711027

Epoch: 6| Step: 1
Training loss: 1.2847940921783447
Validation loss: 2.0814299211707166

Epoch: 6| Step: 2
Training loss: 1.8270719051361084
Validation loss: 2.0586453150677424

Epoch: 6| Step: 3
Training loss: 1.3907465934753418
Validation loss: 2.011210553107723

Epoch: 6| Step: 4
Training loss: 1.3992621898651123
Validation loss: 1.9954956231578704

Epoch: 6| Step: 5
Training loss: 1.4446362257003784
Validation loss: 1.9819348178884035

Epoch: 6| Step: 6
Training loss: 1.309313416481018
Validation loss: 1.9567257268454439

Epoch: 6| Step: 7
Training loss: 2.0916810035705566
Validation loss: 1.9576746558630338

Epoch: 6| Step: 8
Training loss: 1.6399879455566406
Validation loss: 1.9441513733197284

Epoch: 6| Step: 9
Training loss: 1.6885162591934204
Validation loss: 1.9593655716988347

Epoch: 6| Step: 10
Training loss: 1.298331379890442
Validation loss: 1.989672528800144

Epoch: 6| Step: 11
Training loss: 1.401604175567627
Validation loss: 1.9706144153430898

Epoch: 6| Step: 12
Training loss: 1.636798620223999
Validation loss: 1.9963523457127232

Epoch: 6| Step: 13
Training loss: 0.7937673926353455
Validation loss: 2.0092727240695747

Epoch: 256| Step: 0
Training loss: 1.431451678276062
Validation loss: 1.994160326578284

Epoch: 6| Step: 1
Training loss: 2.0467782020568848
Validation loss: 2.0098425201190415

Epoch: 6| Step: 2
Training loss: 1.2268884181976318
Validation loss: 1.9965778537975845

Epoch: 6| Step: 3
Training loss: 1.6034895181655884
Validation loss: 1.9950961489831247

Epoch: 6| Step: 4
Training loss: 1.2691882848739624
Validation loss: 2.005688965961497

Epoch: 6| Step: 5
Training loss: 0.7384964227676392
Validation loss: 1.999075331995564

Epoch: 6| Step: 6
Training loss: 0.8168788552284241
Validation loss: 2.0383281964127735

Epoch: 6| Step: 7
Training loss: 0.9685436487197876
Validation loss: 2.0656972444185646

Epoch: 6| Step: 8
Training loss: 2.05818772315979
Validation loss: 2.0757344089528567

Epoch: 6| Step: 9
Training loss: 1.5613535642623901
Validation loss: 2.090974807739258

Epoch: 6| Step: 10
Training loss: 2.007598400115967
Validation loss: 2.088791239646173

Epoch: 6| Step: 11
Training loss: 1.2705600261688232
Validation loss: 2.0919362909050396

Epoch: 6| Step: 12
Training loss: 2.318446397781372
Validation loss: 2.103428843200848

Epoch: 6| Step: 13
Training loss: 1.2093054056167603
Validation loss: 2.0882812879418813

Epoch: 257| Step: 0
Training loss: 1.6071444749832153
Validation loss: 2.088471116558198

Epoch: 6| Step: 1
Training loss: 1.3680270910263062
Validation loss: 2.086204828754548

Epoch: 6| Step: 2
Training loss: 1.4161380529403687
Validation loss: 2.086531815990325

Epoch: 6| Step: 3
Training loss: 1.1287144422531128
Validation loss: 2.0724051613961496

Epoch: 6| Step: 4
Training loss: 1.5067777633666992
Validation loss: 2.0655761764895533

Epoch: 6| Step: 5
Training loss: 1.7541214227676392
Validation loss: 2.044343499727147

Epoch: 6| Step: 6
Training loss: 1.7355762720108032
Validation loss: 2.024111601614183

Epoch: 6| Step: 7
Training loss: 1.3194408416748047
Validation loss: 1.989594095496721

Epoch: 6| Step: 8
Training loss: 1.1129775047302246
Validation loss: 1.9783783292257657

Epoch: 6| Step: 9
Training loss: 2.540501117706299
Validation loss: 1.98544236921495

Epoch: 6| Step: 10
Training loss: 1.311631202697754
Validation loss: 1.9733817628634873

Epoch: 6| Step: 11
Training loss: 1.1551885604858398
Validation loss: 2.003794688050465

Epoch: 6| Step: 12
Training loss: 1.4274623394012451
Validation loss: 2.0188743273417153

Epoch: 6| Step: 13
Training loss: 0.8938490748405457
Validation loss: 2.061647388242906

Epoch: 258| Step: 0
Training loss: 1.5813498497009277
Validation loss: 2.088298818116547

Epoch: 6| Step: 1
Training loss: 1.465749979019165
Validation loss: 2.1060468765997116

Epoch: 6| Step: 2
Training loss: 1.2421045303344727
Validation loss: 2.1145081596989788

Epoch: 6| Step: 3
Training loss: 1.1915464401245117
Validation loss: 2.121543040839575

Epoch: 6| Step: 4
Training loss: 2.022904396057129
Validation loss: 2.089048895784604

Epoch: 6| Step: 5
Training loss: 1.7123758792877197
Validation loss: 2.03571940237476

Epoch: 6| Step: 6
Training loss: 0.695346474647522
Validation loss: 2.0248576402664185

Epoch: 6| Step: 7
Training loss: 1.5876843929290771
Validation loss: 1.999264335119596

Epoch: 6| Step: 8
Training loss: 0.9313562512397766
Validation loss: 1.9928939534771828

Epoch: 6| Step: 9
Training loss: 1.9861589670181274
Validation loss: 1.986363278281304

Epoch: 6| Step: 10
Training loss: 1.6578147411346436
Validation loss: 1.9989173630232453

Epoch: 6| Step: 11
Training loss: 0.9509490728378296
Validation loss: 2.0157895831651587

Epoch: 6| Step: 12
Training loss: 1.3753691911697388
Validation loss: 2.022453925942862

Epoch: 6| Step: 13
Training loss: 2.3064146041870117
Validation loss: 2.0164523355422483

Epoch: 259| Step: 0
Training loss: 1.022679328918457
Validation loss: 2.0154830396816297

Epoch: 6| Step: 1
Training loss: 1.443297266960144
Validation loss: 1.9937535088549379

Epoch: 6| Step: 2
Training loss: 1.175840973854065
Validation loss: 1.987360587684057

Epoch: 6| Step: 3
Training loss: 1.3475759029388428
Validation loss: 1.987292315370293

Epoch: 6| Step: 4
Training loss: 1.19857919216156
Validation loss: 2.005401481864273

Epoch: 6| Step: 5
Training loss: 1.501395344734192
Validation loss: 1.9850742637470205

Epoch: 6| Step: 6
Training loss: 1.3715907335281372
Validation loss: 2.016197250735375

Epoch: 6| Step: 7
Training loss: 1.4110748767852783
Validation loss: 2.005481996843892

Epoch: 6| Step: 8
Training loss: 1.6234911680221558
Validation loss: 2.0167291241307415

Epoch: 6| Step: 9
Training loss: 1.5631228685379028
Validation loss: 2.0293623862727994

Epoch: 6| Step: 10
Training loss: 1.448948621749878
Validation loss: 2.0361646349712084

Epoch: 6| Step: 11
Training loss: 1.7329505681991577
Validation loss: 2.021837167842414

Epoch: 6| Step: 12
Training loss: 1.7171992063522339
Validation loss: 2.0360782954000656

Epoch: 6| Step: 13
Training loss: 1.3897217512130737
Validation loss: 2.028967962470106

Epoch: 260| Step: 0
Training loss: 1.0862693786621094
Validation loss: 2.0454117072525846

Epoch: 6| Step: 1
Training loss: 1.1050416231155396
Validation loss: 2.0404787845509027

Epoch: 6| Step: 2
Training loss: 1.5427827835083008
Validation loss: 2.039422232617614

Epoch: 6| Step: 3
Training loss: 1.3302257061004639
Validation loss: 2.0488176666280276

Epoch: 6| Step: 4
Training loss: 1.1173008680343628
Validation loss: 2.051286194914131

Epoch: 6| Step: 5
Training loss: 1.6353280544281006
Validation loss: 2.0267680229679232

Epoch: 6| Step: 6
Training loss: 1.094249963760376
Validation loss: 2.0016162600568546

Epoch: 6| Step: 7
Training loss: 1.5470426082611084
Validation loss: 2.0012833636294127

Epoch: 6| Step: 8
Training loss: 1.6368160247802734
Validation loss: 2.008748459559615

Epoch: 6| Step: 9
Training loss: 1.467786192893982
Validation loss: 2.0097559857112106

Epoch: 6| Step: 10
Training loss: 1.6444921493530273
Validation loss: 2.0165640205465336

Epoch: 6| Step: 11
Training loss: 2.077441930770874
Validation loss: 1.9987554985989806

Epoch: 6| Step: 12
Training loss: 0.9529209733009338
Validation loss: 2.0312700476697696

Epoch: 6| Step: 13
Training loss: 1.8952059745788574
Validation loss: 2.0405513445536294

Epoch: 261| Step: 0
Training loss: 1.2745295763015747
Validation loss: 2.055906985395698

Epoch: 6| Step: 1
Training loss: 1.0391936302185059
Validation loss: 2.076032784677321

Epoch: 6| Step: 2
Training loss: 1.1392638683319092
Validation loss: 2.0730097127217118

Epoch: 6| Step: 3
Training loss: 1.7834360599517822
Validation loss: 2.0697359038937475

Epoch: 6| Step: 4
Training loss: 1.8705081939697266
Validation loss: 2.0555917498885945

Epoch: 6| Step: 5
Training loss: 1.5571534633636475
Validation loss: 2.0517081547808904

Epoch: 6| Step: 6
Training loss: 0.9873638153076172
Validation loss: 2.028159147949629

Epoch: 6| Step: 7
Training loss: 1.340444803237915
Validation loss: 2.0317284522518033

Epoch: 6| Step: 8
Training loss: 1.5217313766479492
Validation loss: 2.0055174622484433

Epoch: 6| Step: 9
Training loss: 1.7123810052871704
Validation loss: 2.0147436306040776

Epoch: 6| Step: 10
Training loss: 1.7932510375976562
Validation loss: 2.0228718429483394

Epoch: 6| Step: 11
Training loss: 1.0635818243026733
Validation loss: 2.0215533958968295

Epoch: 6| Step: 12
Training loss: 1.6598303318023682
Validation loss: 2.0224534439784225

Epoch: 6| Step: 13
Training loss: 0.9180834889411926
Validation loss: 1.9932631164468744

Epoch: 262| Step: 0
Training loss: 1.543156623840332
Validation loss: 2.0041489626771662

Epoch: 6| Step: 1
Training loss: 0.8740965723991394
Validation loss: 2.0203109197719122

Epoch: 6| Step: 2
Training loss: 0.9071899056434631
Validation loss: 2.0131511303686325

Epoch: 6| Step: 3
Training loss: 1.5058776140213013
Validation loss: 1.9905664664442821

Epoch: 6| Step: 4
Training loss: 1.2687950134277344
Validation loss: 1.998445228863788

Epoch: 6| Step: 5
Training loss: 1.8512327671051025
Validation loss: 1.9927213653441398

Epoch: 6| Step: 6
Training loss: 1.6519978046417236
Validation loss: 2.008459988460746

Epoch: 6| Step: 7
Training loss: 1.1821773052215576
Validation loss: 2.029371629479111

Epoch: 6| Step: 8
Training loss: 1.3620961904525757
Validation loss: 2.0391404769753896

Epoch: 6| Step: 9
Training loss: 1.6234543323516846
Validation loss: 2.0658764416171658

Epoch: 6| Step: 10
Training loss: 1.5169439315795898
Validation loss: 2.1011045902006087

Epoch: 6| Step: 11
Training loss: 1.233162522315979
Validation loss: 2.1019488534619732

Epoch: 6| Step: 12
Training loss: 1.6527538299560547
Validation loss: 2.1271838629117577

Epoch: 6| Step: 13
Training loss: 1.9508018493652344
Validation loss: 2.098477089276878

Epoch: 263| Step: 0
Training loss: 0.9582293033599854
Validation loss: 2.0746236488383305

Epoch: 6| Step: 1
Training loss: 1.597792148590088
Validation loss: 2.0476658164813952

Epoch: 6| Step: 2
Training loss: 1.497424602508545
Validation loss: 2.038758324038598

Epoch: 6| Step: 3
Training loss: 1.8195279836654663
Validation loss: 2.030058055795649

Epoch: 6| Step: 4
Training loss: 1.2929167747497559
Validation loss: 2.0217580000559487

Epoch: 6| Step: 5
Training loss: 1.616114854812622
Validation loss: 2.022546798952164

Epoch: 6| Step: 6
Training loss: 1.445622205734253
Validation loss: 2.0177816088481615

Epoch: 6| Step: 7
Training loss: 1.7034671306610107
Validation loss: 2.0274274990122807

Epoch: 6| Step: 8
Training loss: 0.9685417413711548
Validation loss: 2.033581651667113

Epoch: 6| Step: 9
Training loss: 0.8163431286811829
Validation loss: 2.022924807763869

Epoch: 6| Step: 10
Training loss: 1.4887512922286987
Validation loss: 2.0358923327538276

Epoch: 6| Step: 11
Training loss: 1.531083345413208
Validation loss: 2.0114742068834204

Epoch: 6| Step: 12
Training loss: 1.7174508571624756
Validation loss: 2.014588467536434

Epoch: 6| Step: 13
Training loss: 0.983877420425415
Validation loss: 2.0051683277212162

Epoch: 264| Step: 0
Training loss: 1.6039133071899414
Validation loss: 1.9900711608189408

Epoch: 6| Step: 1
Training loss: 1.528676986694336
Validation loss: 1.9760094381147815

Epoch: 6| Step: 2
Training loss: 1.251634120941162
Validation loss: 1.983913621594829

Epoch: 6| Step: 3
Training loss: 0.9350720643997192
Validation loss: 1.9918291004755164

Epoch: 6| Step: 4
Training loss: 1.1338207721710205
Validation loss: 2.0064359275243615

Epoch: 6| Step: 5
Training loss: 1.5449528694152832
Validation loss: 2.021879252567086

Epoch: 6| Step: 6
Training loss: 2.0295228958129883
Validation loss: 2.0163437012703187

Epoch: 6| Step: 7
Training loss: 1.6513400077819824
Validation loss: 2.0298971309456775

Epoch: 6| Step: 8
Training loss: 1.5549521446228027
Validation loss: 2.0208036181747273

Epoch: 6| Step: 9
Training loss: 0.8481596112251282
Validation loss: 2.038129860355008

Epoch: 6| Step: 10
Training loss: 1.0591654777526855
Validation loss: 2.0289765378480316

Epoch: 6| Step: 11
Training loss: 1.4432233572006226
Validation loss: 2.025673245870939

Epoch: 6| Step: 12
Training loss: 1.344568133354187
Validation loss: 2.0336703228694137

Epoch: 6| Step: 13
Training loss: 1.7530618906021118
Validation loss: 2.0547329405302643

Epoch: 265| Step: 0
Training loss: 1.5147690773010254
Validation loss: 2.068974571843301

Epoch: 6| Step: 1
Training loss: 1.1554672718048096
Validation loss: 2.0625158843173774

Epoch: 6| Step: 2
Training loss: 1.342414140701294
Validation loss: 2.066701243000646

Epoch: 6| Step: 3
Training loss: 1.009492039680481
Validation loss: 2.063227040793306

Epoch: 6| Step: 4
Training loss: 1.082758903503418
Validation loss: 2.0439702618506645

Epoch: 6| Step: 5
Training loss: 2.5545504093170166
Validation loss: 2.056006508488809

Epoch: 6| Step: 6
Training loss: 1.4435760974884033
Validation loss: 2.039940736627066

Epoch: 6| Step: 7
Training loss: 1.3601562976837158
Validation loss: 2.0096523921976805

Epoch: 6| Step: 8
Training loss: 1.6621354818344116
Validation loss: 2.03008028768724

Epoch: 6| Step: 9
Training loss: 1.465926170349121
Validation loss: 2.023544675560408

Epoch: 6| Step: 10
Training loss: 1.733580470085144
Validation loss: 2.0188735095403527

Epoch: 6| Step: 11
Training loss: 0.5937835574150085
Validation loss: 2.0441464711261053

Epoch: 6| Step: 12
Training loss: 1.3745903968811035
Validation loss: 2.026361693618118

Epoch: 6| Step: 13
Training loss: 1.5246756076812744
Validation loss: 2.0451603653610393

Epoch: 266| Step: 0
Training loss: 1.4362390041351318
Validation loss: 2.006184870196927

Epoch: 6| Step: 1
Training loss: 1.2873212099075317
Validation loss: 2.0050350337900142

Epoch: 6| Step: 2
Training loss: 1.2776886224746704
Validation loss: 1.9908118094167402

Epoch: 6| Step: 3
Training loss: 1.5973427295684814
Validation loss: 2.0057518853936145

Epoch: 6| Step: 4
Training loss: 1.758865475654602
Validation loss: 2.0155961987792805

Epoch: 6| Step: 5
Training loss: 1.135753870010376
Validation loss: 2.023855532369306

Epoch: 6| Step: 6
Training loss: 1.5436420440673828
Validation loss: 2.041661949567897

Epoch: 6| Step: 7
Training loss: 1.1794397830963135
Validation loss: 2.0495005858841764

Epoch: 6| Step: 8
Training loss: 1.5500400066375732
Validation loss: 2.0184252287751887

Epoch: 6| Step: 9
Training loss: 1.481980323791504
Validation loss: 1.9995426003650953

Epoch: 6| Step: 10
Training loss: 1.1760358810424805
Validation loss: 1.9815941062024844

Epoch: 6| Step: 11
Training loss: 1.1062785387039185
Validation loss: 1.9965526365464734

Epoch: 6| Step: 12
Training loss: 1.693359136581421
Validation loss: 2.0370447904832902

Epoch: 6| Step: 13
Training loss: 1.413271188735962
Validation loss: 2.050488846276396

Epoch: 267| Step: 0
Training loss: 0.8503109812736511
Validation loss: 2.091041882832845

Epoch: 6| Step: 1
Training loss: 1.6040749549865723
Validation loss: 2.1026365590351883

Epoch: 6| Step: 2
Training loss: 1.9289352893829346
Validation loss: 2.1040090309676303

Epoch: 6| Step: 3
Training loss: 1.2565292119979858
Validation loss: 2.0902328414301716

Epoch: 6| Step: 4
Training loss: 1.3025732040405273
Validation loss: 2.05159959741818

Epoch: 6| Step: 5
Training loss: 1.5916895866394043
Validation loss: 2.0376102155254734

Epoch: 6| Step: 6
Training loss: 0.6156202554702759
Validation loss: 2.0227310067863873

Epoch: 6| Step: 7
Training loss: 1.359581470489502
Validation loss: 1.9912085020413963

Epoch: 6| Step: 8
Training loss: 1.6871252059936523
Validation loss: 1.9889604635136102

Epoch: 6| Step: 9
Training loss: 1.5317273139953613
Validation loss: 1.9660449156197168

Epoch: 6| Step: 10
Training loss: 1.1690175533294678
Validation loss: 1.9810235884881788

Epoch: 6| Step: 11
Training loss: 1.2586421966552734
Validation loss: 2.003306245291105

Epoch: 6| Step: 12
Training loss: 1.8548647165298462
Validation loss: 1.9899803694858347

Epoch: 6| Step: 13
Training loss: 1.2506592273712158
Validation loss: 2.0069243779746433

Epoch: 268| Step: 0
Training loss: 1.1260263919830322
Validation loss: 1.99414098775515

Epoch: 6| Step: 1
Training loss: 1.6517208814620972
Validation loss: 2.029890651343971

Epoch: 6| Step: 2
Training loss: 1.041789174079895
Validation loss: 2.0287631711652203

Epoch: 6| Step: 3
Training loss: 1.4130398035049438
Validation loss: 2.071693387082828

Epoch: 6| Step: 4
Training loss: 1.3323664665222168
Validation loss: 2.0601108356188704

Epoch: 6| Step: 5
Training loss: 1.283118486404419
Validation loss: 2.061481406611781

Epoch: 6| Step: 6
Training loss: 1.5899858474731445
Validation loss: 2.0392968526450534

Epoch: 6| Step: 7
Training loss: 1.8225317001342773
Validation loss: 2.0265985791401198

Epoch: 6| Step: 8
Training loss: 1.6715000867843628
Validation loss: 2.006034606246538

Epoch: 6| Step: 9
Training loss: 1.1630990505218506
Validation loss: 1.9839593287437194

Epoch: 6| Step: 10
Training loss: 1.2398793697357178
Validation loss: 2.001615772965134

Epoch: 6| Step: 11
Training loss: 1.2116272449493408
Validation loss: 2.0008103488593973

Epoch: 6| Step: 12
Training loss: 1.3608770370483398
Validation loss: 2.017150144423208

Epoch: 6| Step: 13
Training loss: 1.1101175546646118
Validation loss: 2.029238029192853

Epoch: 269| Step: 0
Training loss: 1.8691396713256836
Validation loss: 2.0215854542229765

Epoch: 6| Step: 1
Training loss: 1.0799064636230469
Validation loss: 1.9963565308560607

Epoch: 6| Step: 2
Training loss: 1.3156847953796387
Validation loss: 1.9861285237855808

Epoch: 6| Step: 3
Training loss: 1.137243628501892
Validation loss: 1.9809745204064153

Epoch: 6| Step: 4
Training loss: 1.3140966892242432
Validation loss: 1.9829535202313495

Epoch: 6| Step: 5
Training loss: 1.518671989440918
Validation loss: 1.9813734972348778

Epoch: 6| Step: 6
Training loss: 1.3940097093582153
Validation loss: 1.9815104071811964

Epoch: 6| Step: 7
Training loss: 0.7341824769973755
Validation loss: 2.0202841822819044

Epoch: 6| Step: 8
Training loss: 2.6633920669555664
Validation loss: 2.037654362699037

Epoch: 6| Step: 9
Training loss: 0.9867538213729858
Validation loss: 2.036927596215279

Epoch: 6| Step: 10
Training loss: 1.4296292066574097
Validation loss: 2.051108580763622

Epoch: 6| Step: 11
Training loss: 1.2760823965072632
Validation loss: 2.069882565929044

Epoch: 6| Step: 12
Training loss: 1.5429344177246094
Validation loss: 2.0690611921330935

Epoch: 6| Step: 13
Training loss: 0.6594502925872803
Validation loss: 2.0747826060941144

Epoch: 270| Step: 0
Training loss: 1.1411597728729248
Validation loss: 2.049164006786962

Epoch: 6| Step: 1
Training loss: 1.096510887145996
Validation loss: 2.041350938940561

Epoch: 6| Step: 2
Training loss: 1.2228238582611084
Validation loss: 2.0315905283856135

Epoch: 6| Step: 3
Training loss: 2.024669647216797
Validation loss: 2.0403496091083815

Epoch: 6| Step: 4
Training loss: 1.25276517868042
Validation loss: 2.0483359495798745

Epoch: 6| Step: 5
Training loss: 1.4154322147369385
Validation loss: 2.044391021933607

Epoch: 6| Step: 6
Training loss: 1.6496797800064087
Validation loss: 2.0431059586104525

Epoch: 6| Step: 7
Training loss: 1.7732863426208496
Validation loss: 2.053292384711645

Epoch: 6| Step: 8
Training loss: 1.0214322805404663
Validation loss: 2.0393070251710954

Epoch: 6| Step: 9
Training loss: 1.8961613178253174
Validation loss: 2.0380117175399617

Epoch: 6| Step: 10
Training loss: 1.3021425008773804
Validation loss: 1.9998592740745955

Epoch: 6| Step: 11
Training loss: 1.0995882749557495
Validation loss: 1.98070328979082

Epoch: 6| Step: 12
Training loss: 0.9953030347824097
Validation loss: 1.961760518371418

Epoch: 6| Step: 13
Training loss: 1.1634852886199951
Validation loss: 1.963958353124639

Epoch: 271| Step: 0
Training loss: 1.3674122095108032
Validation loss: 1.962016934989601

Epoch: 6| Step: 1
Training loss: 1.1829032897949219
Validation loss: 1.979818817107908

Epoch: 6| Step: 2
Training loss: 1.3919894695281982
Validation loss: 2.0051846299120175

Epoch: 6| Step: 3
Training loss: 1.5035743713378906
Validation loss: 1.9881480765599076

Epoch: 6| Step: 4
Training loss: 1.2650911808013916
Validation loss: 1.9798228407418856

Epoch: 6| Step: 5
Training loss: 1.20743727684021
Validation loss: 1.9925777130229498

Epoch: 6| Step: 6
Training loss: 1.5080479383468628
Validation loss: 1.9856119514793478

Epoch: 6| Step: 7
Training loss: 1.578882098197937
Validation loss: 1.9721127133215628

Epoch: 6| Step: 8
Training loss: 0.9390154480934143
Validation loss: 1.9986107451941377

Epoch: 6| Step: 9
Training loss: 0.7797672748565674
Validation loss: 2.0115954465763544

Epoch: 6| Step: 10
Training loss: 1.4943830966949463
Validation loss: 2.036267219051238

Epoch: 6| Step: 11
Training loss: 2.0273101329803467
Validation loss: 2.078626558344851

Epoch: 6| Step: 12
Training loss: 1.4610387086868286
Validation loss: 2.1096056353661323

Epoch: 6| Step: 13
Training loss: 1.1243784427642822
Validation loss: 2.110365543314206

Epoch: 272| Step: 0
Training loss: 1.402275562286377
Validation loss: 2.107242830338017

Epoch: 6| Step: 1
Training loss: 1.8366873264312744
Validation loss: 2.080169208588139

Epoch: 6| Step: 2
Training loss: 1.1778485774993896
Validation loss: 2.084339234136766

Epoch: 6| Step: 3
Training loss: 1.3188602924346924
Validation loss: 2.06760258700258

Epoch: 6| Step: 4
Training loss: 1.6090105772018433
Validation loss: 2.05417211081392

Epoch: 6| Step: 5
Training loss: 1.140857458114624
Validation loss: 2.041576664934876

Epoch: 6| Step: 6
Training loss: 0.9522727727890015
Validation loss: 2.0184480772223523

Epoch: 6| Step: 7
Training loss: 1.5418176651000977
Validation loss: 1.9906917451530375

Epoch: 6| Step: 8
Training loss: 0.8410331010818481
Validation loss: 1.982994516690572

Epoch: 6| Step: 9
Training loss: 1.6168534755706787
Validation loss: 1.9914145879848029

Epoch: 6| Step: 10
Training loss: 0.8665671944618225
Validation loss: 1.9706395415849582

Epoch: 6| Step: 11
Training loss: 1.3142441511154175
Validation loss: 1.9984694424495901

Epoch: 6| Step: 12
Training loss: 1.4004207849502563
Validation loss: 2.00694885048815

Epoch: 6| Step: 13
Training loss: 1.9535045623779297
Validation loss: 2.0240559629214707

Epoch: 273| Step: 0
Training loss: 1.7372398376464844
Validation loss: 2.0095488127841743

Epoch: 6| Step: 1
Training loss: 1.4074915647506714
Validation loss: 2.016288665033156

Epoch: 6| Step: 2
Training loss: 1.1382827758789062
Validation loss: 2.0408295533990346

Epoch: 6| Step: 3
Training loss: 1.2325325012207031
Validation loss: 2.03527404415992

Epoch: 6| Step: 4
Training loss: 1.4581570625305176
Validation loss: 2.0475665292432232

Epoch: 6| Step: 5
Training loss: 0.7512271404266357
Validation loss: 2.0521067470632572

Epoch: 6| Step: 6
Training loss: 1.498844861984253
Validation loss: 2.0449662746921664

Epoch: 6| Step: 7
Training loss: 1.352760672569275
Validation loss: 2.0722537194528887

Epoch: 6| Step: 8
Training loss: 1.3155863285064697
Validation loss: 2.068694314649028

Epoch: 6| Step: 9
Training loss: 1.7515676021575928
Validation loss: 2.0752743982499644

Epoch: 6| Step: 10
Training loss: 0.9310540556907654
Validation loss: 2.0571562064591276

Epoch: 6| Step: 11
Training loss: 0.9885213375091553
Validation loss: 2.049580253580565

Epoch: 6| Step: 12
Training loss: 1.9435282945632935
Validation loss: 2.0194083183042464

Epoch: 6| Step: 13
Training loss: 1.1935203075408936
Validation loss: 2.004881506325096

Epoch: 274| Step: 0
Training loss: 1.2094590663909912
Validation loss: 1.9989330512221142

Epoch: 6| Step: 1
Training loss: 0.9416159987449646
Validation loss: 1.9761904311436478

Epoch: 6| Step: 2
Training loss: 1.263979196548462
Validation loss: 1.9669523059680898

Epoch: 6| Step: 3
Training loss: 1.367475986480713
Validation loss: 1.9879556855847758

Epoch: 6| Step: 4
Training loss: 1.0835037231445312
Validation loss: 1.9739876536912815

Epoch: 6| Step: 5
Training loss: 1.5503079891204834
Validation loss: 1.9707296304805304

Epoch: 6| Step: 6
Training loss: 1.7426071166992188
Validation loss: 1.964655424958916

Epoch: 6| Step: 7
Training loss: 0.6992433071136475
Validation loss: 1.9887937448358024

Epoch: 6| Step: 8
Training loss: 1.2046115398406982
Validation loss: 2.0100312335516817

Epoch: 6| Step: 9
Training loss: 1.6067607402801514
Validation loss: 2.0176453744211504

Epoch: 6| Step: 10
Training loss: 1.4029486179351807
Validation loss: 2.0473437898902485

Epoch: 6| Step: 11
Training loss: 1.4805412292480469
Validation loss: 2.051541712976271

Epoch: 6| Step: 12
Training loss: 1.3394438028335571
Validation loss: 2.0451538485865437

Epoch: 6| Step: 13
Training loss: 1.998077630996704
Validation loss: 2.0329092433375697

Epoch: 275| Step: 0
Training loss: 1.0267266035079956
Validation loss: 2.044928527647449

Epoch: 6| Step: 1
Training loss: 1.6301058530807495
Validation loss: 2.050276828068559

Epoch: 6| Step: 2
Training loss: 1.0961953401565552
Validation loss: 2.057519324364201

Epoch: 6| Step: 3
Training loss: 1.63765549659729
Validation loss: 2.0472541419408654

Epoch: 6| Step: 4
Training loss: 1.43846595287323
Validation loss: 2.0463199448841873

Epoch: 6| Step: 5
Training loss: 0.9182612895965576
Validation loss: 2.058087815520584

Epoch: 6| Step: 6
Training loss: 1.244612693786621
Validation loss: 2.0592249554972493

Epoch: 6| Step: 7
Training loss: 1.1266118288040161
Validation loss: 2.057990315139935

Epoch: 6| Step: 8
Training loss: 1.0335160493850708
Validation loss: 2.053782791219732

Epoch: 6| Step: 9
Training loss: 1.303945541381836
Validation loss: 2.033512528224658

Epoch: 6| Step: 10
Training loss: 1.8679614067077637
Validation loss: 2.0170803326432423

Epoch: 6| Step: 11
Training loss: 1.27596116065979
Validation loss: 1.9946470978439494

Epoch: 6| Step: 12
Training loss: 1.4651036262512207
Validation loss: 1.9936688933321225

Epoch: 6| Step: 13
Training loss: 1.0676599740982056
Validation loss: 1.9861170053482056

Epoch: 276| Step: 0
Training loss: 1.2610846757888794
Validation loss: 1.97494541188722

Epoch: 6| Step: 1
Training loss: 1.2397820949554443
Validation loss: 1.9898497827591435

Epoch: 6| Step: 2
Training loss: 1.1187559366226196
Validation loss: 2.030128240585327

Epoch: 6| Step: 3
Training loss: 1.0328646898269653
Validation loss: 2.0413644916267804

Epoch: 6| Step: 4
Training loss: 1.8872262239456177
Validation loss: 2.0640548018999

Epoch: 6| Step: 5
Training loss: 1.0099565982818604
Validation loss: 2.0625434716542563

Epoch: 6| Step: 6
Training loss: 1.26829993724823
Validation loss: 2.0572944687258814

Epoch: 6| Step: 7
Training loss: 0.9841283559799194
Validation loss: 2.0463352305914766

Epoch: 6| Step: 8
Training loss: 1.536015272140503
Validation loss: 2.0184770617433774

Epoch: 6| Step: 9
Training loss: 1.4440289735794067
Validation loss: 2.0138726644618536

Epoch: 6| Step: 10
Training loss: 1.396677017211914
Validation loss: 1.9886648488301102

Epoch: 6| Step: 11
Training loss: 0.8053368330001831
Validation loss: 2.019574180726082

Epoch: 6| Step: 12
Training loss: 1.6427667140960693
Validation loss: 2.036896300572221

Epoch: 6| Step: 13
Training loss: 2.007322311401367
Validation loss: 2.0394988803453344

Epoch: 277| Step: 0
Training loss: 1.1620768308639526
Validation loss: 2.0479625296849076

Epoch: 6| Step: 1
Training loss: 0.7578500509262085
Validation loss: 2.0379593269799345

Epoch: 6| Step: 2
Training loss: 1.5261908769607544
Validation loss: 2.054356659612348

Epoch: 6| Step: 3
Training loss: 0.7678307294845581
Validation loss: 2.0567694069236837

Epoch: 6| Step: 4
Training loss: 1.219062089920044
Validation loss: 2.0409876018442135

Epoch: 6| Step: 5
Training loss: 1.422559142112732
Validation loss: 2.0347380330485683

Epoch: 6| Step: 6
Training loss: 1.5865927934646606
Validation loss: 2.020926276842753

Epoch: 6| Step: 7
Training loss: 1.511592984199524
Validation loss: 2.0035169586058585

Epoch: 6| Step: 8
Training loss: 1.309758186340332
Validation loss: 2.0106660435276646

Epoch: 6| Step: 9
Training loss: 1.5302951335906982
Validation loss: 2.0165338054780038

Epoch: 6| Step: 10
Training loss: 2.0181007385253906
Validation loss: 2.02963775204074

Epoch: 6| Step: 11
Training loss: 1.0136399269104004
Validation loss: 2.0460448700894593

Epoch: 6| Step: 12
Training loss: 1.1453728675842285
Validation loss: 2.0629381159300446

Epoch: 6| Step: 13
Training loss: 1.1020879745483398
Validation loss: 2.070220975465672

Epoch: 278| Step: 0
Training loss: 0.6112226247787476
Validation loss: 2.077046891694428

Epoch: 6| Step: 1
Training loss: 1.5354759693145752
Validation loss: 2.0866917589659333

Epoch: 6| Step: 2
Training loss: 1.5719352960586548
Validation loss: 2.0445601773518387

Epoch: 6| Step: 3
Training loss: 1.7074000835418701
Validation loss: 2.0338276855407225

Epoch: 6| Step: 4
Training loss: 1.0419690608978271
Validation loss: 2.0146806393900225

Epoch: 6| Step: 5
Training loss: 1.3770180940628052
Validation loss: 2.0019342950595322

Epoch: 6| Step: 6
Training loss: 1.3560489416122437
Validation loss: 1.998610911830779

Epoch: 6| Step: 7
Training loss: 1.1235902309417725
Validation loss: 2.0171703523205173

Epoch: 6| Step: 8
Training loss: 0.799367368221283
Validation loss: 2.0201390212582004

Epoch: 6| Step: 9
Training loss: 1.2433350086212158
Validation loss: 2.0395021938508555

Epoch: 6| Step: 10
Training loss: 1.519291877746582
Validation loss: 2.0627110465880363

Epoch: 6| Step: 11
Training loss: 1.2691230773925781
Validation loss: 2.0568980119561635

Epoch: 6| Step: 12
Training loss: 1.6685454845428467
Validation loss: 2.0659875164749804

Epoch: 6| Step: 13
Training loss: 1.326821208000183
Validation loss: 2.0404486861280215

Epoch: 279| Step: 0
Training loss: 1.6418952941894531
Validation loss: 2.0423902619269585

Epoch: 6| Step: 1
Training loss: 0.8694627285003662
Validation loss: 2.0470424108607794

Epoch: 6| Step: 2
Training loss: 1.7080950736999512
Validation loss: 2.023283061160836

Epoch: 6| Step: 3
Training loss: 1.715242624282837
Validation loss: 2.021469264902094

Epoch: 6| Step: 4
Training loss: 1.4407975673675537
Validation loss: 1.9896845791929512

Epoch: 6| Step: 5
Training loss: 1.508378267288208
Validation loss: 1.9882912738348848

Epoch: 6| Step: 6
Training loss: 1.0997284650802612
Validation loss: 1.990988487838417

Epoch: 6| Step: 7
Training loss: 0.8511450886726379
Validation loss: 1.9629332993620185

Epoch: 6| Step: 8
Training loss: 1.1930512189865112
Validation loss: 1.9938506887805076

Epoch: 6| Step: 9
Training loss: 0.9297598004341125
Validation loss: 2.0283991470131824

Epoch: 6| Step: 10
Training loss: 0.41813957691192627
Validation loss: 2.0450999403512604

Epoch: 6| Step: 11
Training loss: 1.404065489768982
Validation loss: 2.0797509865094255

Epoch: 6| Step: 12
Training loss: 1.7789485454559326
Validation loss: 2.0920433536652596

Epoch: 6| Step: 13
Training loss: 1.6692965030670166
Validation loss: 2.079778616146375

Epoch: 280| Step: 0
Training loss: 1.3786170482635498
Validation loss: 2.089230952724334

Epoch: 6| Step: 1
Training loss: 1.3233733177185059
Validation loss: 2.0791735418381228

Epoch: 6| Step: 2
Training loss: 1.4760878086090088
Validation loss: 2.024356016548731

Epoch: 6| Step: 3
Training loss: 0.9987727403640747
Validation loss: 1.9941282451793712

Epoch: 6| Step: 4
Training loss: 1.1375601291656494
Validation loss: 1.9899971946593253

Epoch: 6| Step: 5
Training loss: 1.670192003250122
Validation loss: 1.9687559514917352

Epoch: 6| Step: 6
Training loss: 1.2488590478897095
Validation loss: 1.964833797947053

Epoch: 6| Step: 7
Training loss: 1.3196418285369873
Validation loss: 1.9690866560064337

Epoch: 6| Step: 8
Training loss: 0.8580340147018433
Validation loss: 1.9633986949920654

Epoch: 6| Step: 9
Training loss: 1.5152146816253662
Validation loss: 1.975143619762954

Epoch: 6| Step: 10
Training loss: 1.119861364364624
Validation loss: 1.9881381398888045

Epoch: 6| Step: 11
Training loss: 1.4220645427703857
Validation loss: 1.9891875008101105

Epoch: 6| Step: 12
Training loss: 0.8516199588775635
Validation loss: 2.013143947047572

Epoch: 6| Step: 13
Training loss: 1.6402087211608887
Validation loss: 2.0361666525563886

Epoch: 281| Step: 0
Training loss: 1.6785073280334473
Validation loss: 2.0506264368693032

Epoch: 6| Step: 1
Training loss: 1.1580290794372559
Validation loss: 2.0669989585876465

Epoch: 6| Step: 2
Training loss: 0.7351047992706299
Validation loss: 2.058196883047781

Epoch: 6| Step: 3
Training loss: 1.313291072845459
Validation loss: 2.0567263710883354

Epoch: 6| Step: 4
Training loss: 1.8085477352142334
Validation loss: 2.067266518069852

Epoch: 6| Step: 5
Training loss: 1.4352712631225586
Validation loss: 2.088869845995339

Epoch: 6| Step: 6
Training loss: 0.97196364402771
Validation loss: 2.109570303270894

Epoch: 6| Step: 7
Training loss: 1.2322065830230713
Validation loss: 2.095861020908561

Epoch: 6| Step: 8
Training loss: 1.381352186203003
Validation loss: 2.0918617966354534

Epoch: 6| Step: 9
Training loss: 1.203178882598877
Validation loss: 2.067873865045527

Epoch: 6| Step: 10
Training loss: 0.9387859106063843
Validation loss: 2.036771156454599

Epoch: 6| Step: 11
Training loss: 1.5714573860168457
Validation loss: 2.011130858493108

Epoch: 6| Step: 12
Training loss: 1.119020938873291
Validation loss: 1.9687237214016657

Epoch: 6| Step: 13
Training loss: 1.4464788436889648
Validation loss: 1.9733296709675943

Epoch: 282| Step: 0
Training loss: 1.0966143608093262
Validation loss: 1.963176268403248

Epoch: 6| Step: 1
Training loss: 1.523399829864502
Validation loss: 1.9613507947614115

Epoch: 6| Step: 2
Training loss: 1.0937902927398682
Validation loss: 1.9901015040695027

Epoch: 6| Step: 3
Training loss: 0.6318143606185913
Validation loss: 2.033712007666147

Epoch: 6| Step: 4
Training loss: 1.6288524866104126
Validation loss: 2.085255999718943

Epoch: 6| Step: 5
Training loss: 1.0347402095794678
Validation loss: 2.1173639425667385

Epoch: 6| Step: 6
Training loss: 1.4669222831726074
Validation loss: 2.1295106769889913

Epoch: 6| Step: 7
Training loss: 1.1873360872268677
Validation loss: 2.155919505703834

Epoch: 6| Step: 8
Training loss: 1.6437058448791504
Validation loss: 2.10106473840693

Epoch: 6| Step: 9
Training loss: 1.4271190166473389
Validation loss: 2.0783497633472567

Epoch: 6| Step: 10
Training loss: 1.0107795000076294
Validation loss: 2.0389050693922144

Epoch: 6| Step: 11
Training loss: 1.131753921508789
Validation loss: 2.0048505337007585

Epoch: 6| Step: 12
Training loss: 1.767880916595459
Validation loss: 2.0049843429237284

Epoch: 6| Step: 13
Training loss: 1.4166722297668457
Validation loss: 2.012612153125066

Epoch: 283| Step: 0
Training loss: 1.0327520370483398
Validation loss: 2.0284221672242686

Epoch: 6| Step: 1
Training loss: 1.273558497428894
Validation loss: 2.0040313454084497

Epoch: 6| Step: 2
Training loss: 1.8559075593948364
Validation loss: 2.0358830626292894

Epoch: 6| Step: 3
Training loss: 1.3377573490142822
Validation loss: 2.0678060029142644

Epoch: 6| Step: 4
Training loss: 1.2265841960906982
Validation loss: 2.029601699562483

Epoch: 6| Step: 5
Training loss: 0.8398455381393433
Validation loss: 2.035003872327907

Epoch: 6| Step: 6
Training loss: 0.8064311742782593
Validation loss: 2.0110722767409457

Epoch: 6| Step: 7
Training loss: 1.5954837799072266
Validation loss: 2.022890975398402

Epoch: 6| Step: 8
Training loss: 1.2184326648712158
Validation loss: 2.0102573851103425

Epoch: 6| Step: 9
Training loss: 0.7496851086616516
Validation loss: 2.03633616816613

Epoch: 6| Step: 10
Training loss: 1.551888346672058
Validation loss: 2.0610244774049327

Epoch: 6| Step: 11
Training loss: 1.3134410381317139
Validation loss: 2.0910149517879693

Epoch: 6| Step: 12
Training loss: 1.379823923110962
Validation loss: 2.1214402080864034

Epoch: 6| Step: 13
Training loss: 1.325927734375
Validation loss: 2.10162054979673

Epoch: 284| Step: 0
Training loss: 1.2066760063171387
Validation loss: 2.1161423613948207

Epoch: 6| Step: 1
Training loss: 0.7454968690872192
Validation loss: 2.1005563787234727

Epoch: 6| Step: 2
Training loss: 1.561111569404602
Validation loss: 2.054490189398489

Epoch: 6| Step: 3
Training loss: 1.2180739641189575
Validation loss: 2.0593468040548344

Epoch: 6| Step: 4
Training loss: 0.9265927076339722
Validation loss: 2.049655798942812

Epoch: 6| Step: 5
Training loss: 1.1120929718017578
Validation loss: 2.027754960521575

Epoch: 6| Step: 6
Training loss: 1.6319756507873535
Validation loss: 2.0181429680957588

Epoch: 6| Step: 7
Training loss: 1.4764951467514038
Validation loss: 2.008149711034631

Epoch: 6| Step: 8
Training loss: 0.771346926689148
Validation loss: 1.9979655742645264

Epoch: 6| Step: 9
Training loss: 1.0890893936157227
Validation loss: 1.9948504355645948

Epoch: 6| Step: 10
Training loss: 1.517958402633667
Validation loss: 1.9716366260282454

Epoch: 6| Step: 11
Training loss: 1.2889320850372314
Validation loss: 1.995349173904747

Epoch: 6| Step: 12
Training loss: 1.6808958053588867
Validation loss: 2.0312217550892986

Epoch: 6| Step: 13
Training loss: 1.3622291088104248
Validation loss: 2.0422813507818405

Epoch: 285| Step: 0
Training loss: 0.9246875643730164
Validation loss: 2.0772531878563667

Epoch: 6| Step: 1
Training loss: 1.0538628101348877
Validation loss: 2.099739033688781

Epoch: 6| Step: 2
Training loss: 1.1409499645233154
Validation loss: 2.108493576767624

Epoch: 6| Step: 3
Training loss: 1.3688132762908936
Validation loss: 2.0614257179280764

Epoch: 6| Step: 4
Training loss: 0.7824435234069824
Validation loss: 2.0103535882888304

Epoch: 6| Step: 5
Training loss: 1.020626187324524
Validation loss: 1.9814746405488701

Epoch: 6| Step: 6
Training loss: 1.3166662454605103
Validation loss: 1.9854466786948584

Epoch: 6| Step: 7
Training loss: 1.005587100982666
Validation loss: 2.0264969525798673

Epoch: 6| Step: 8
Training loss: 1.4898334741592407
Validation loss: 2.030579005518267

Epoch: 6| Step: 9
Training loss: 2.1403510570526123
Validation loss: 2.070891723837904

Epoch: 6| Step: 10
Training loss: 1.9072563648223877
Validation loss: 2.1106754656760924

Epoch: 6| Step: 11
Training loss: 1.3061789274215698
Validation loss: 2.097642711413804

Epoch: 6| Step: 12
Training loss: 0.6528381109237671
Validation loss: 2.14733878771464

Epoch: 6| Step: 13
Training loss: 1.996284008026123
Validation loss: 2.1051813492210965

Epoch: 286| Step: 0
Training loss: 1.3992986679077148
Validation loss: 2.0673155374424432

Epoch: 6| Step: 1
Training loss: 1.487889051437378
Validation loss: 2.0287515450549383

Epoch: 6| Step: 2
Training loss: 1.3645195960998535
Validation loss: 1.997372829785911

Epoch: 6| Step: 3
Training loss: 0.9441031217575073
Validation loss: 1.954567583658362

Epoch: 6| Step: 4
Training loss: 1.3410489559173584
Validation loss: 1.9418098054906374

Epoch: 6| Step: 5
Training loss: 0.7408413290977478
Validation loss: 1.928344831671766

Epoch: 6| Step: 6
Training loss: 1.2029386758804321
Validation loss: 1.9052484727674914

Epoch: 6| Step: 7
Training loss: 1.562158465385437
Validation loss: 1.914747489395962

Epoch: 6| Step: 8
Training loss: 1.1550805568695068
Validation loss: 1.9403220043387464

Epoch: 6| Step: 9
Training loss: 0.804498553276062
Validation loss: 2.004071839394108

Epoch: 6| Step: 10
Training loss: 1.4030598402023315
Validation loss: 2.0480637806718067

Epoch: 6| Step: 11
Training loss: 1.1728827953338623
Validation loss: 2.1126548705562467

Epoch: 6| Step: 12
Training loss: 1.1582223176956177
Validation loss: 2.1597330749675794

Epoch: 6| Step: 13
Training loss: 2.296881675720215
Validation loss: 2.17479286655303

Epoch: 287| Step: 0
Training loss: 1.1924421787261963
Validation loss: 2.219798759747577

Epoch: 6| Step: 1
Training loss: 0.9189598560333252
Validation loss: 2.2084079070757796

Epoch: 6| Step: 2
Training loss: 1.6271770000457764
Validation loss: 2.1810677102817

Epoch: 6| Step: 3
Training loss: 0.8284047842025757
Validation loss: 2.108998930582436

Epoch: 6| Step: 4
Training loss: 0.8018813133239746
Validation loss: 2.049738196916478

Epoch: 6| Step: 5
Training loss: 1.6012879610061646
Validation loss: 1.9989633188452771

Epoch: 6| Step: 6
Training loss: 1.1928386688232422
Validation loss: 1.9758666176949777

Epoch: 6| Step: 7
Training loss: 1.0402953624725342
Validation loss: 1.9478157079348

Epoch: 6| Step: 8
Training loss: 0.9013652801513672
Validation loss: 1.9403284313858196

Epoch: 6| Step: 9
Training loss: 1.2503300905227661
Validation loss: 1.9557055388727496

Epoch: 6| Step: 10
Training loss: 1.6731455326080322
Validation loss: 1.9593805946329588

Epoch: 6| Step: 11
Training loss: 1.3313413858413696
Validation loss: 1.9702290001735892

Epoch: 6| Step: 12
Training loss: 1.4498971700668335
Validation loss: 1.9663858157332226

Epoch: 6| Step: 13
Training loss: 1.8460612297058105
Validation loss: 2.008246612805192

Epoch: 288| Step: 0
Training loss: 0.6163734197616577
Validation loss: 2.017304233325425

Epoch: 6| Step: 1
Training loss: 1.1040194034576416
Validation loss: 2.029226823519635

Epoch: 6| Step: 2
Training loss: 1.6815683841705322
Validation loss: 2.0290286976804017

Epoch: 6| Step: 3
Training loss: 1.5947582721710205
Validation loss: 2.0170972219077488

Epoch: 6| Step: 4
Training loss: 1.287245750427246
Validation loss: 2.0381463855825444

Epoch: 6| Step: 5
Training loss: 1.1859185695648193
Validation loss: 2.012104288224251

Epoch: 6| Step: 6
Training loss: 1.3061045408248901
Validation loss: 2.0041408641363985

Epoch: 6| Step: 7
Training loss: 1.3852643966674805
Validation loss: 2.0013895906427854

Epoch: 6| Step: 8
Training loss: 0.8030011057853699
Validation loss: 2.018724879910869

Epoch: 6| Step: 9
Training loss: 1.2309794425964355
Validation loss: 2.0037753992183234

Epoch: 6| Step: 10
Training loss: 1.2798265218734741
Validation loss: 2.020397388806907

Epoch: 6| Step: 11
Training loss: 1.3768126964569092
Validation loss: 2.047700943485383

Epoch: 6| Step: 12
Training loss: 1.3555651903152466
Validation loss: 2.0882950495648127

Epoch: 6| Step: 13
Training loss: 0.7860918641090393
Validation loss: 2.0906875107877996

Epoch: 289| Step: 0
Training loss: 1.3490626811981201
Validation loss: 2.071663366850986

Epoch: 6| Step: 1
Training loss: 1.6326937675476074
Validation loss: 2.048526733152328

Epoch: 6| Step: 2
Training loss: 1.0840857028961182
Validation loss: 2.036262495543367

Epoch: 6| Step: 3
Training loss: 0.9802154302597046
Validation loss: 2.004095185187555

Epoch: 6| Step: 4
Training loss: 1.523991346359253
Validation loss: 1.9663806371791388

Epoch: 6| Step: 5
Training loss: 0.41519808769226074
Validation loss: 1.951067025943469

Epoch: 6| Step: 6
Training loss: 1.8742138147354126
Validation loss: 1.9468677120824014

Epoch: 6| Step: 7
Training loss: 1.2885233163833618
Validation loss: 1.9776006373026038

Epoch: 6| Step: 8
Training loss: 0.9251058101654053
Validation loss: 1.9940402917964484

Epoch: 6| Step: 9
Training loss: 0.9387094378471375
Validation loss: 2.019123628575315

Epoch: 6| Step: 10
Training loss: 1.312934160232544
Validation loss: 2.0284856827028337

Epoch: 6| Step: 11
Training loss: 1.86142098903656
Validation loss: 2.0683051565642

Epoch: 6| Step: 12
Training loss: 1.1514496803283691
Validation loss: 2.105440564053033

Epoch: 6| Step: 13
Training loss: 0.34838995337486267
Validation loss: 2.0994403951911518

Epoch: 290| Step: 0
Training loss: 1.0114574432373047
Validation loss: 2.1006685944013697

Epoch: 6| Step: 1
Training loss: 1.3611857891082764
Validation loss: 2.106902309643325

Epoch: 6| Step: 2
Training loss: 1.0923974514007568
Validation loss: 2.0761165541987263

Epoch: 6| Step: 3
Training loss: 1.1929829120635986
Validation loss: 2.032674817628758

Epoch: 6| Step: 4
Training loss: 1.6247620582580566
Validation loss: 2.002261282295309

Epoch: 6| Step: 5
Training loss: 0.8053073883056641
Validation loss: 1.9939384460449219

Epoch: 6| Step: 6
Training loss: 1.6570112705230713
Validation loss: 1.9666835659293718

Epoch: 6| Step: 7
Training loss: 1.4434908628463745
Validation loss: 1.978622328850531

Epoch: 6| Step: 8
Training loss: 1.3542540073394775
Validation loss: 1.9641125817452707

Epoch: 6| Step: 9
Training loss: 1.3410025835037231
Validation loss: 1.9875496484900033

Epoch: 6| Step: 10
Training loss: 1.3033766746520996
Validation loss: 1.9953437056592715

Epoch: 6| Step: 11
Training loss: 0.9148837924003601
Validation loss: 2.0429929943494898

Epoch: 6| Step: 12
Training loss: 0.7041435241699219
Validation loss: 2.0518904706483245

Epoch: 6| Step: 13
Training loss: 0.9871363043785095
Validation loss: 2.057330095639793

Epoch: 291| Step: 0
Training loss: 1.1284785270690918
Validation loss: 2.0729561159687657

Epoch: 6| Step: 1
Training loss: 1.2063560485839844
Validation loss: 2.1275412113435808

Epoch: 6| Step: 2
Training loss: 1.5777912139892578
Validation loss: 2.1379852141103437

Epoch: 6| Step: 3
Training loss: 1.2741442918777466
Validation loss: 2.0935928103744343

Epoch: 6| Step: 4
Training loss: 0.8662017583847046
Validation loss: 2.048734490589429

Epoch: 6| Step: 5
Training loss: 1.1115074157714844
Validation loss: 1.9900828253838323

Epoch: 6| Step: 6
Training loss: 1.595985770225525
Validation loss: 1.9562947429636472

Epoch: 6| Step: 7
Training loss: 1.1101722717285156
Validation loss: 1.9660534269066268

Epoch: 6| Step: 8
Training loss: 1.6976362466812134
Validation loss: 1.9616145113463044

Epoch: 6| Step: 9
Training loss: 0.9231372475624084
Validation loss: 1.9481813625622821

Epoch: 6| Step: 10
Training loss: 1.1618285179138184
Validation loss: 1.947723546335774

Epoch: 6| Step: 11
Training loss: 1.0791947841644287
Validation loss: 1.9663180176929762

Epoch: 6| Step: 12
Training loss: 1.3590645790100098
Validation loss: 1.982853376737205

Epoch: 6| Step: 13
Training loss: 1.517591953277588
Validation loss: 1.9929500497797483

Epoch: 292| Step: 0
Training loss: 0.975324273109436
Validation loss: 2.056298389229723

Epoch: 6| Step: 1
Training loss: 1.3518059253692627
Validation loss: 2.073664137112197

Epoch: 6| Step: 2
Training loss: 1.5307270288467407
Validation loss: 2.131769029043054

Epoch: 6| Step: 3
Training loss: 1.0540257692337036
Validation loss: 2.190682042029596

Epoch: 6| Step: 4
Training loss: 1.7422268390655518
Validation loss: 2.204045885352678

Epoch: 6| Step: 5
Training loss: 1.880868911743164
Validation loss: 2.195452315832979

Epoch: 6| Step: 6
Training loss: 1.5873377323150635
Validation loss: 2.119092320883146

Epoch: 6| Step: 7
Training loss: 0.8738068342208862
Validation loss: 2.0455960996689333

Epoch: 6| Step: 8
Training loss: 0.9122532606124878
Validation loss: 1.953418198452201

Epoch: 6| Step: 9
Training loss: 1.2234251499176025
Validation loss: 1.943383192503324

Epoch: 6| Step: 10
Training loss: 1.0772196054458618
Validation loss: 1.926336867834932

Epoch: 6| Step: 11
Training loss: 0.847101092338562
Validation loss: 1.9391239279059953

Epoch: 6| Step: 12
Training loss: 1.147761583328247
Validation loss: 1.935447125024693

Epoch: 6| Step: 13
Training loss: 1.4256924390792847
Validation loss: 1.9333976212368216

Epoch: 293| Step: 0
Training loss: 0.8841636180877686
Validation loss: 1.9112398701329385

Epoch: 6| Step: 1
Training loss: 1.133472204208374
Validation loss: 1.9323713138539305

Epoch: 6| Step: 2
Training loss: 0.6197643280029297
Validation loss: 1.9517088218401837

Epoch: 6| Step: 3
Training loss: 1.397891640663147
Validation loss: 2.000804694749976

Epoch: 6| Step: 4
Training loss: 1.4848016500473022
Validation loss: 2.0421171265263713

Epoch: 6| Step: 5
Training loss: 1.1944931745529175
Validation loss: 2.073031484439809

Epoch: 6| Step: 6
Training loss: 0.9972361922264099
Validation loss: 2.0884055642671484

Epoch: 6| Step: 7
Training loss: 1.8563618659973145
Validation loss: 2.1371325318531325

Epoch: 6| Step: 8
Training loss: 1.9614795446395874
Validation loss: 2.1465291259109334

Epoch: 6| Step: 9
Training loss: 0.8174052238464355
Validation loss: 2.1221085466364378

Epoch: 6| Step: 10
Training loss: 1.2693274021148682
Validation loss: 2.0776496266806

Epoch: 6| Step: 11
Training loss: 0.984144926071167
Validation loss: 2.0136454028467976

Epoch: 6| Step: 12
Training loss: 1.4310662746429443
Validation loss: 1.987092056582051

Epoch: 6| Step: 13
Training loss: 1.0117107629776
Validation loss: 1.9977534086473527

Epoch: 294| Step: 0
Training loss: 1.4579548835754395
Validation loss: 1.9563065357105707

Epoch: 6| Step: 1
Training loss: 1.3140535354614258
Validation loss: 1.9713940171785251

Epoch: 6| Step: 2
Training loss: 0.9526647329330444
Validation loss: 1.9811056249885148

Epoch: 6| Step: 3
Training loss: 1.8976373672485352
Validation loss: 1.9671466299282607

Epoch: 6| Step: 4
Training loss: 1.2789113521575928
Validation loss: 2.0054325249887284

Epoch: 6| Step: 5
Training loss: 0.9504773616790771
Validation loss: 2.0072145308217695

Epoch: 6| Step: 6
Training loss: 1.6777424812316895
Validation loss: 2.0132683720639957

Epoch: 6| Step: 7
Training loss: 0.985853374004364
Validation loss: 2.036431025433284

Epoch: 6| Step: 8
Training loss: 0.8029321432113647
Validation loss: 2.031401152251869

Epoch: 6| Step: 9
Training loss: 0.8485643863677979
Validation loss: 2.0660984208506923

Epoch: 6| Step: 10
Training loss: 0.9669148921966553
Validation loss: 2.078020054166035

Epoch: 6| Step: 11
Training loss: 1.3960868120193481
Validation loss: 2.0740606054182975

Epoch: 6| Step: 12
Training loss: 1.049403190612793
Validation loss: 2.094657292930029

Epoch: 6| Step: 13
Training loss: 0.8814942240715027
Validation loss: 2.113474428012807

Epoch: 295| Step: 0
Training loss: 1.1317994594573975
Validation loss: 2.118867471653928

Epoch: 6| Step: 1
Training loss: 1.3769755363464355
Validation loss: 2.141032471451708

Epoch: 6| Step: 2
Training loss: 1.353988766670227
Validation loss: 2.121463708980109

Epoch: 6| Step: 3
Training loss: 0.969182014465332
Validation loss: 2.1225335162173034

Epoch: 6| Step: 4
Training loss: 0.8513675928115845
Validation loss: 2.1012529198841383

Epoch: 6| Step: 5
Training loss: 1.0423403978347778
Validation loss: 2.1014837167596303

Epoch: 6| Step: 6
Training loss: 1.4701143503189087
Validation loss: 2.062084374889251

Epoch: 6| Step: 7
Training loss: 1.2758774757385254
Validation loss: 2.0243420729073147

Epoch: 6| Step: 8
Training loss: 1.4173294305801392
Validation loss: 1.9979522446150422

Epoch: 6| Step: 9
Training loss: 0.9657838344573975
Validation loss: 1.9764895900603263

Epoch: 6| Step: 10
Training loss: 1.6951203346252441
Validation loss: 1.9666399237930134

Epoch: 6| Step: 11
Training loss: 0.9765254259109497
Validation loss: 1.932382692572891

Epoch: 6| Step: 12
Training loss: 1.1508960723876953
Validation loss: 1.9261577347273469

Epoch: 6| Step: 13
Training loss: 1.0382450819015503
Validation loss: 1.9237207776756697

Epoch: 296| Step: 0
Training loss: 1.1113015413284302
Validation loss: 1.971433021688974

Epoch: 6| Step: 1
Training loss: 1.0292093753814697
Validation loss: 2.0017539916499967

Epoch: 6| Step: 2
Training loss: 1.3105225563049316
Validation loss: 2.0608626616898404

Epoch: 6| Step: 3
Training loss: 1.5280954837799072
Validation loss: 2.115205266142404

Epoch: 6| Step: 4
Training loss: 0.8124433159828186
Validation loss: 2.140824315368488

Epoch: 6| Step: 5
Training loss: 1.5482488870620728
Validation loss: 2.163363666944606

Epoch: 6| Step: 6
Training loss: 1.3275563716888428
Validation loss: 2.1475625679057133

Epoch: 6| Step: 7
Training loss: 1.0048248767852783
Validation loss: 2.1110768625813146

Epoch: 6| Step: 8
Training loss: 1.1236680746078491
Validation loss: 2.058103361437398

Epoch: 6| Step: 9
Training loss: 0.9527279734611511
Validation loss: 2.031032459710234

Epoch: 6| Step: 10
Training loss: 1.0725160837173462
Validation loss: 2.0126903416008077

Epoch: 6| Step: 11
Training loss: 1.3668873310089111
Validation loss: 1.963092573227421

Epoch: 6| Step: 12
Training loss: 1.2398924827575684
Validation loss: 1.979889654344128

Epoch: 6| Step: 13
Training loss: 1.4185935258865356
Validation loss: 1.9739668164201962

Epoch: 297| Step: 0
Training loss: 1.2922325134277344
Validation loss: 1.9763322043162521

Epoch: 6| Step: 1
Training loss: 1.1046006679534912
Validation loss: 1.964523917885237

Epoch: 6| Step: 2
Training loss: 0.8333306312561035
Validation loss: 1.9577174314888575

Epoch: 6| Step: 3
Training loss: 1.5613168478012085
Validation loss: 2.008492431332988

Epoch: 6| Step: 4
Training loss: 1.0932756662368774
Validation loss: 2.0328369307261642

Epoch: 6| Step: 5
Training loss: 1.3216190338134766
Validation loss: 2.049644693251579

Epoch: 6| Step: 6
Training loss: 1.4518693685531616
Validation loss: 2.0245602387253956

Epoch: 6| Step: 7
Training loss: 0.7595869898796082
Validation loss: 2.0420195236000964

Epoch: 6| Step: 8
Training loss: 1.251262903213501
Validation loss: 2.0368368446186023

Epoch: 6| Step: 9
Training loss: 0.7688038945198059
Validation loss: 2.0514406645169823

Epoch: 6| Step: 10
Training loss: 1.2291345596313477
Validation loss: 2.0588129130742883

Epoch: 6| Step: 11
Training loss: 1.5421366691589355
Validation loss: 2.0529189289257093

Epoch: 6| Step: 12
Training loss: 1.10593581199646
Validation loss: 2.076156266273991

Epoch: 6| Step: 13
Training loss: 0.9837068915367126
Validation loss: 2.0937257735959944

Epoch: 298| Step: 0
Training loss: 0.6350719332695007
Validation loss: 2.0876792989751345

Epoch: 6| Step: 1
Training loss: 1.2424148321151733
Validation loss: 2.0694199121126564

Epoch: 6| Step: 2
Training loss: 0.8359498977661133
Validation loss: 2.0442376700780724

Epoch: 6| Step: 3
Training loss: 0.9930395483970642
Validation loss: 2.032838449683241

Epoch: 6| Step: 4
Training loss: 1.238175868988037
Validation loss: 2.0526031986359627

Epoch: 6| Step: 5
Training loss: 1.1441158056259155
Validation loss: 2.0562123073044645

Epoch: 6| Step: 6
Training loss: 1.0890082120895386
Validation loss: 2.0367122029745452

Epoch: 6| Step: 7
Training loss: 1.2148326635360718
Validation loss: 2.016823410987854

Epoch: 6| Step: 8
Training loss: 2.0356242656707764
Validation loss: 2.0130864932972896

Epoch: 6| Step: 9
Training loss: 1.6473908424377441
Validation loss: 1.9956702160578903

Epoch: 6| Step: 10
Training loss: 1.6202740669250488
Validation loss: 1.9947691476473244

Epoch: 6| Step: 11
Training loss: 0.6945486664772034
Validation loss: 1.9877592773847683

Epoch: 6| Step: 12
Training loss: 0.920327365398407
Validation loss: 1.9872001063439153

Epoch: 6| Step: 13
Training loss: 0.915955662727356
Validation loss: 1.9971463552085302

Epoch: 299| Step: 0
Training loss: 0.6176941394805908
Validation loss: 2.0196366258846816

Epoch: 6| Step: 1
Training loss: 1.0094631910324097
Validation loss: 2.0489305988434823

Epoch: 6| Step: 2
Training loss: 1.1239722967147827
Validation loss: 2.117322926880211

Epoch: 6| Step: 3
Training loss: 1.2431703805923462
Validation loss: 2.1382360099464335

Epoch: 6| Step: 4
Training loss: 0.9099196791648865
Validation loss: 2.1312896756715674

Epoch: 6| Step: 5
Training loss: 1.5667213201522827
Validation loss: 2.1073457899913994

Epoch: 6| Step: 6
Training loss: 1.341082215309143
Validation loss: 2.104196781753212

Epoch: 6| Step: 7
Training loss: 0.8999711275100708
Validation loss: 2.0745931671511744

Epoch: 6| Step: 8
Training loss: 1.340078353881836
Validation loss: 2.0383291539325508

Epoch: 6| Step: 9
Training loss: 1.6243757009506226
Validation loss: 2.008107111018191

Epoch: 6| Step: 10
Training loss: 1.1802945137023926
Validation loss: 2.0132094890840593

Epoch: 6| Step: 11
Training loss: 1.1571648120880127
Validation loss: 2.019937994659588

Epoch: 6| Step: 12
Training loss: 1.076347827911377
Validation loss: 2.0512805702865764

Epoch: 6| Step: 13
Training loss: 1.1789063215255737
Validation loss: 2.04573142656716

Epoch: 300| Step: 0
Training loss: 1.1951661109924316
Validation loss: 2.061452873291508

Epoch: 6| Step: 1
Training loss: 1.5477056503295898
Validation loss: 2.046724793731525

Epoch: 6| Step: 2
Training loss: 0.9268659353256226
Validation loss: 2.0663376931221253

Epoch: 6| Step: 3
Training loss: 1.5672199726104736
Validation loss: 2.042231677680887

Epoch: 6| Step: 4
Training loss: 1.1447402238845825
Validation loss: 2.0420061516505417

Epoch: 6| Step: 5
Training loss: 1.2109277248382568
Validation loss: 2.0201775514951317

Epoch: 6| Step: 6
Training loss: 1.4310957193374634
Validation loss: 2.036234305750939

Epoch: 6| Step: 7
Training loss: 0.6075344085693359
Validation loss: 2.046344719907289

Epoch: 6| Step: 8
Training loss: 0.8624228835105896
Validation loss: 2.057850019906157

Epoch: 6| Step: 9
Training loss: 0.9553235173225403
Validation loss: 2.0480395517041607

Epoch: 6| Step: 10
Training loss: 1.4314547777175903
Validation loss: 2.0497707551525486

Epoch: 6| Step: 11
Training loss: 0.8655709028244019
Validation loss: 2.0064037974162767

Epoch: 6| Step: 12
Training loss: 1.2407944202423096
Validation loss: 2.0279031774049163

Epoch: 6| Step: 13
Training loss: 0.9431260228157043
Validation loss: 1.99178143214154

Epoch: 301| Step: 0
Training loss: 1.2321213483810425
Validation loss: 2.0052122223761772

Epoch: 6| Step: 1
Training loss: 0.9332417845726013
Validation loss: 1.99251558960125

Epoch: 6| Step: 2
Training loss: 1.3932616710662842
Validation loss: 2.012795886685771

Epoch: 6| Step: 3
Training loss: 1.0759042501449585
Validation loss: 2.0126690403107674

Epoch: 6| Step: 4
Training loss: 1.060225486755371
Validation loss: 2.0136662580633677

Epoch: 6| Step: 5
Training loss: 1.1283349990844727
Validation loss: 2.0195769174124605

Epoch: 6| Step: 6
Training loss: 1.3116971254348755
Validation loss: 2.0122371027546544

Epoch: 6| Step: 7
Training loss: 0.9378786683082581
Validation loss: 2.0076920652902253

Epoch: 6| Step: 8
Training loss: 0.6773068308830261
Validation loss: 2.022556274167953

Epoch: 6| Step: 9
Training loss: 1.6875771284103394
Validation loss: 2.0441314174282934

Epoch: 6| Step: 10
Training loss: 1.2024450302124023
Validation loss: 2.0460977579957698

Epoch: 6| Step: 11
Training loss: 1.0332719087600708
Validation loss: 2.0848418538288405

Epoch: 6| Step: 12
Training loss: 0.9164047241210938
Validation loss: 2.0889888168663107

Epoch: 6| Step: 13
Training loss: 1.310130000114441
Validation loss: 2.1019107205893404

Epoch: 302| Step: 0
Training loss: 0.7405672073364258
Validation loss: 2.0898350502855036

Epoch: 6| Step: 1
Training loss: 1.308027982711792
Validation loss: 2.098291984168432

Epoch: 6| Step: 2
Training loss: 1.4583873748779297
Validation loss: 2.0682234949963068

Epoch: 6| Step: 3
Training loss: 1.2212574481964111
Validation loss: 2.037209704358091

Epoch: 6| Step: 4
Training loss: 1.3882865905761719
Validation loss: 2.0465959400259037

Epoch: 6| Step: 5
Training loss: 1.091900110244751
Validation loss: 2.0239720985453618

Epoch: 6| Step: 6
Training loss: 0.7665187120437622
Validation loss: 2.010767371423783

Epoch: 6| Step: 7
Training loss: 0.7686144113540649
Validation loss: 1.9996842363829255

Epoch: 6| Step: 8
Training loss: 0.8503481149673462
Validation loss: 2.0077109016397947

Epoch: 6| Step: 9
Training loss: 1.4834232330322266
Validation loss: 2.0062826256598196

Epoch: 6| Step: 10
Training loss: 1.653425693511963
Validation loss: 2.01383384325171

Epoch: 6| Step: 11
Training loss: 1.472123622894287
Validation loss: 2.0229473960015083

Epoch: 6| Step: 12
Training loss: 1.2311123609542847
Validation loss: 2.007365684355459

Epoch: 6| Step: 13
Training loss: 0.4184180200099945
Validation loss: 1.963255661790089

Epoch: 303| Step: 0
Training loss: 1.4057759046554565
Validation loss: 1.9539095919619325

Epoch: 6| Step: 1
Training loss: 0.9870588779449463
Validation loss: 1.9626498171078262

Epoch: 6| Step: 2
Training loss: 0.5441806316375732
Validation loss: 1.9911599056695097

Epoch: 6| Step: 3
Training loss: 1.7699038982391357
Validation loss: 1.9950168722419328

Epoch: 6| Step: 4
Training loss: 0.762578010559082
Validation loss: 2.0142719066271217

Epoch: 6| Step: 5
Training loss: 1.1157348155975342
Validation loss: 2.0428258090890865

Epoch: 6| Step: 6
Training loss: 0.9115833044052124
Validation loss: 2.0572903028098484

Epoch: 6| Step: 7
Training loss: 1.5351909399032593
Validation loss: 2.080010055213846

Epoch: 6| Step: 8
Training loss: 0.7908015251159668
Validation loss: 2.0770938498999483

Epoch: 6| Step: 9
Training loss: 1.315809965133667
Validation loss: 2.0883428358262583

Epoch: 6| Step: 10
Training loss: 1.1705284118652344
Validation loss: 2.058738990496564

Epoch: 6| Step: 11
Training loss: 0.9412235021591187
Validation loss: 2.051335573196411

Epoch: 6| Step: 12
Training loss: 1.2075296640396118
Validation loss: 2.0634207417888026

Epoch: 6| Step: 13
Training loss: 1.6117976903915405
Validation loss: 2.0713043059072187

Epoch: 304| Step: 0
Training loss: 1.2326949834823608
Validation loss: 2.0475028894280873

Epoch: 6| Step: 1
Training loss: 1.0384197235107422
Validation loss: 2.060739295456999

Epoch: 6| Step: 2
Training loss: 1.2489279508590698
Validation loss: 2.0223457954263173

Epoch: 6| Step: 3
Training loss: 0.8661119341850281
Validation loss: 2.020771780321675

Epoch: 6| Step: 4
Training loss: 1.7431495189666748
Validation loss: 2.025702125282698

Epoch: 6| Step: 5
Training loss: 1.4784278869628906
Validation loss: 2.011022888204103

Epoch: 6| Step: 6
Training loss: 0.9181891679763794
Validation loss: 1.99161192165908

Epoch: 6| Step: 7
Training loss: 1.0624191761016846
Validation loss: 1.9800496742289553

Epoch: 6| Step: 8
Training loss: 1.3004014492034912
Validation loss: 1.9719210440112698

Epoch: 6| Step: 9
Training loss: 0.9516547918319702
Validation loss: 1.9763656675174672

Epoch: 6| Step: 10
Training loss: 0.5790449380874634
Validation loss: 1.9802669812274236

Epoch: 6| Step: 11
Training loss: 1.0002188682556152
Validation loss: 2.0302920059491227

Epoch: 6| Step: 12
Training loss: 1.2777079343795776
Validation loss: 2.0457173188527427

Epoch: 6| Step: 13
Training loss: 0.9605477452278137
Validation loss: 2.0653682293430453

Epoch: 305| Step: 0
Training loss: 0.9769590497016907
Validation loss: 2.1362813916257632

Epoch: 6| Step: 1
Training loss: 1.059890866279602
Validation loss: 2.159376158509203

Epoch: 6| Step: 2
Training loss: 1.4469901323318481
Validation loss: 2.150470192714404

Epoch: 6| Step: 3
Training loss: 0.886550784111023
Validation loss: 2.1003017169173046

Epoch: 6| Step: 4
Training loss: 1.2213530540466309
Validation loss: 2.080269064954532

Epoch: 6| Step: 5
Training loss: 0.8501140475273132
Validation loss: 2.0501027363602833

Epoch: 6| Step: 6
Training loss: 1.587144136428833
Validation loss: 2.0196827791070424

Epoch: 6| Step: 7
Training loss: 1.3641993999481201
Validation loss: 2.015073968518165

Epoch: 6| Step: 8
Training loss: 0.8087972402572632
Validation loss: 1.9908963685394616

Epoch: 6| Step: 9
Training loss: 1.4488149881362915
Validation loss: 1.9650659843157696

Epoch: 6| Step: 10
Training loss: 1.1399883031845093
Validation loss: 1.936523388790828

Epoch: 6| Step: 11
Training loss: 0.9864387512207031
Validation loss: 1.9598388864148049

Epoch: 6| Step: 12
Training loss: 0.6432804465293884
Validation loss: 1.9655786227154475

Epoch: 6| Step: 13
Training loss: 1.6275569200515747
Validation loss: 2.0146130618228706

Epoch: 306| Step: 0
Training loss: 1.0060855150222778
Validation loss: 2.043882741723009

Epoch: 6| Step: 1
Training loss: 1.4662739038467407
Validation loss: 2.0650486971742366

Epoch: 6| Step: 2
Training loss: 1.3126153945922852
Validation loss: 2.073725459396198

Epoch: 6| Step: 3
Training loss: 1.1232788562774658
Validation loss: 2.0468042909458117

Epoch: 6| Step: 4
Training loss: 0.687920331954956
Validation loss: 2.0526528050822597

Epoch: 6| Step: 5
Training loss: 1.1296260356903076
Validation loss: 2.0467988650004068

Epoch: 6| Step: 6
Training loss: 1.2773693799972534
Validation loss: 2.058169577711372

Epoch: 6| Step: 7
Training loss: 1.28037691116333
Validation loss: 2.0331599738008235

Epoch: 6| Step: 8
Training loss: 0.8945972919464111
Validation loss: 2.048333698703397

Epoch: 6| Step: 9
Training loss: 1.1393460035324097
Validation loss: 2.0221620785292758

Epoch: 6| Step: 10
Training loss: 1.1137363910675049
Validation loss: 1.9966351729567333

Epoch: 6| Step: 11
Training loss: 0.5801540017127991
Validation loss: 1.9969264230420511

Epoch: 6| Step: 12
Training loss: 1.04838228225708
Validation loss: 2.0015332557821788

Epoch: 6| Step: 13
Training loss: 1.3897000551223755
Validation loss: 2.004411901197126

Epoch: 307| Step: 0
Training loss: 0.9740327596664429
Validation loss: 1.986216111849713

Epoch: 6| Step: 1
Training loss: 1.6206111907958984
Validation loss: 1.9912833744479763

Epoch: 6| Step: 2
Training loss: 1.2230559587478638
Validation loss: 2.005800090810304

Epoch: 6| Step: 3
Training loss: 0.8036084175109863
Validation loss: 1.9841926661870812

Epoch: 6| Step: 4
Training loss: 0.9266176223754883
Validation loss: 1.9972515131837578

Epoch: 6| Step: 5
Training loss: 1.124592900276184
Validation loss: 2.016620712895547

Epoch: 6| Step: 6
Training loss: 1.3159854412078857
Validation loss: 2.025863891006798

Epoch: 6| Step: 7
Training loss: 0.9898462295532227
Validation loss: 2.0117627702733523

Epoch: 6| Step: 8
Training loss: 1.1968392133712769
Validation loss: 2.0051099472148444

Epoch: 6| Step: 9
Training loss: 1.2999024391174316
Validation loss: 2.0078725853273944

Epoch: 6| Step: 10
Training loss: 1.055480718612671
Validation loss: 2.011852784823346

Epoch: 6| Step: 11
Training loss: 0.921795129776001
Validation loss: 2.0207636164080713

Epoch: 6| Step: 12
Training loss: 0.7550036311149597
Validation loss: 2.0164553426927134

Epoch: 6| Step: 13
Training loss: 1.0262198448181152
Validation loss: 2.0024416908141105

Epoch: 308| Step: 0
Training loss: 1.2280181646347046
Validation loss: 2.0071738125175558

Epoch: 6| Step: 1
Training loss: 1.100437879562378
Validation loss: 1.9896696818772184

Epoch: 6| Step: 2
Training loss: 1.187875747680664
Validation loss: 2.003480670272663

Epoch: 6| Step: 3
Training loss: 1.0324935913085938
Validation loss: 2.006237099247594

Epoch: 6| Step: 4
Training loss: 0.7765296697616577
Validation loss: 2.006106675312083

Epoch: 6| Step: 5
Training loss: 1.0550874471664429
Validation loss: 1.9879079890507523

Epoch: 6| Step: 6
Training loss: 0.8883166313171387
Validation loss: 2.010581759996312

Epoch: 6| Step: 7
Training loss: 1.057955026626587
Validation loss: 1.9757683687312628

Epoch: 6| Step: 8
Training loss: 1.5807900428771973
Validation loss: 1.9773915531814739

Epoch: 6| Step: 9
Training loss: 0.9625121355056763
Validation loss: 1.969534707325761

Epoch: 6| Step: 10
Training loss: 1.8381258249282837
Validation loss: 1.9627533728076565

Epoch: 6| Step: 11
Training loss: 0.7160230278968811
Validation loss: 1.9466912515701786

Epoch: 6| Step: 12
Training loss: 0.7520632743835449
Validation loss: 1.9515416263252177

Epoch: 6| Step: 13
Training loss: 0.5786117911338806
Validation loss: 1.962597764948363

Epoch: 309| Step: 0
Training loss: 1.073647141456604
Validation loss: 2.0246099989901305

Epoch: 6| Step: 1
Training loss: 0.6581814885139465
Validation loss: 2.024991766099007

Epoch: 6| Step: 2
Training loss: 1.0016496181488037
Validation loss: 2.028620481491089

Epoch: 6| Step: 3
Training loss: 1.104872226715088
Validation loss: 2.0349282167291127

Epoch: 6| Step: 4
Training loss: 1.2226054668426514
Validation loss: 2.0597456706467496

Epoch: 6| Step: 5
Training loss: 1.5533004999160767
Validation loss: 2.0352977757812827

Epoch: 6| Step: 6
Training loss: 0.7533548474311829
Validation loss: 2.0419189596688874

Epoch: 6| Step: 7
Training loss: 1.4157435894012451
Validation loss: 2.056490126476493

Epoch: 6| Step: 8
Training loss: 0.5372706651687622
Validation loss: 2.0314201462653374

Epoch: 6| Step: 9
Training loss: 1.117046594619751
Validation loss: 2.021075721709959

Epoch: 6| Step: 10
Training loss: 1.422713279724121
Validation loss: 2.026561680660453

Epoch: 6| Step: 11
Training loss: 1.1336796283721924
Validation loss: 1.9887731075286865

Epoch: 6| Step: 12
Training loss: 0.7240599989891052
Validation loss: 1.9657665529558737

Epoch: 6| Step: 13
Training loss: 1.3918590545654297
Validation loss: 1.9789192035634031

Epoch: 310| Step: 0
Training loss: 1.1717525720596313
Validation loss: 1.9398404154726254

Epoch: 6| Step: 1
Training loss: 0.9934382438659668
Validation loss: 1.9531263971841464

Epoch: 6| Step: 2
Training loss: 1.5045857429504395
Validation loss: 1.932112201567619

Epoch: 6| Step: 3
Training loss: 0.6136858463287354
Validation loss: 1.9406765199476672

Epoch: 6| Step: 4
Training loss: 1.0558634996414185
Validation loss: 1.9585343996683757

Epoch: 6| Step: 5
Training loss: 1.1204781532287598
Validation loss: 1.979455860712195

Epoch: 6| Step: 6
Training loss: 1.4230597019195557
Validation loss: 2.042850071384061

Epoch: 6| Step: 7
Training loss: 0.9791838526725769
Validation loss: 2.069239477957449

Epoch: 6| Step: 8
Training loss: 0.8025417923927307
Validation loss: 2.101352342995264

Epoch: 6| Step: 9
Training loss: 1.3584377765655518
Validation loss: 2.1507708000880417

Epoch: 6| Step: 10
Training loss: 1.1563127040863037
Validation loss: 2.1590785877678984

Epoch: 6| Step: 11
Training loss: 0.8794847726821899
Validation loss: 2.128343520625945

Epoch: 6| Step: 12
Training loss: 0.7584936022758484
Validation loss: 2.0997570073732765

Epoch: 6| Step: 13
Training loss: 1.384440302848816
Validation loss: 2.032254868938077

Epoch: 311| Step: 0
Training loss: 0.873043417930603
Validation loss: 1.9804878183590469

Epoch: 6| Step: 1
Training loss: 1.3522833585739136
Validation loss: 1.944473381965391

Epoch: 6| Step: 2
Training loss: 1.0069198608398438
Validation loss: 1.9240333726329188

Epoch: 6| Step: 3
Training loss: 1.5091161727905273
Validation loss: 1.886150115279741

Epoch: 6| Step: 4
Training loss: 1.3675847053527832
Validation loss: 1.8985073643345987

Epoch: 6| Step: 5
Training loss: 1.2444336414337158
Validation loss: 1.8980285429185437

Epoch: 6| Step: 6
Training loss: 0.9706982374191284
Validation loss: 1.9157312172715382

Epoch: 6| Step: 7
Training loss: 1.0718787908554077
Validation loss: 1.9550234194724792

Epoch: 6| Step: 8
Training loss: 1.316751480102539
Validation loss: 1.9613976286303612

Epoch: 6| Step: 9
Training loss: 0.9178364276885986
Validation loss: 1.9736193764594294

Epoch: 6| Step: 10
Training loss: 0.7104330062866211
Validation loss: 1.9959125595708047

Epoch: 6| Step: 11
Training loss: 0.8327456712722778
Validation loss: 2.011282810600855

Epoch: 6| Step: 12
Training loss: 1.256083607673645
Validation loss: 2.0412552689993255

Epoch: 6| Step: 13
Training loss: 0.46322834491729736
Validation loss: 2.0330842002745597

Epoch: 312| Step: 0
Training loss: 1.3895398378372192
Validation loss: 2.0634586862338486

Epoch: 6| Step: 1
Training loss: 1.3064959049224854
Validation loss: 2.028465432505454

Epoch: 6| Step: 2
Training loss: 0.932949960231781
Validation loss: 2.035892355826593

Epoch: 6| Step: 3
Training loss: 1.0499547719955444
Validation loss: 2.047560650815246

Epoch: 6| Step: 4
Training loss: 0.9352928400039673
Validation loss: 2.0088109739365114

Epoch: 6| Step: 5
Training loss: 0.9365785121917725
Validation loss: 2.007860158079414

Epoch: 6| Step: 6
Training loss: 1.4148082733154297
Validation loss: 2.0155160696275773

Epoch: 6| Step: 7
Training loss: 0.8883575797080994
Validation loss: 2.001620986128366

Epoch: 6| Step: 8
Training loss: 1.3019769191741943
Validation loss: 2.0229762484950404

Epoch: 6| Step: 9
Training loss: 1.0829627513885498
Validation loss: 1.9994534702711209

Epoch: 6| Step: 10
Training loss: 0.6863552331924438
Validation loss: 2.027051853877242

Epoch: 6| Step: 11
Training loss: 1.1052378416061401
Validation loss: 2.0268771981680267

Epoch: 6| Step: 12
Training loss: 0.8544030785560608
Validation loss: 2.058870234797078

Epoch: 6| Step: 13
Training loss: 0.9140641689300537
Validation loss: 2.0023365879571564

Epoch: 313| Step: 0
Training loss: 1.4084794521331787
Validation loss: 2.0190227800799954

Epoch: 6| Step: 1
Training loss: 1.3302502632141113
Validation loss: 1.9947018854079708

Epoch: 6| Step: 2
Training loss: 1.5201184749603271
Validation loss: 2.004061160549041

Epoch: 6| Step: 3
Training loss: 0.5498262643814087
Validation loss: 1.978759217005904

Epoch: 6| Step: 4
Training loss: 0.6313207149505615
Validation loss: 1.9420791928486159

Epoch: 6| Step: 5
Training loss: 0.9468040466308594
Validation loss: 1.9605367875868274

Epoch: 6| Step: 6
Training loss: 0.9227324724197388
Validation loss: 1.9445729870950021

Epoch: 6| Step: 7
Training loss: 0.634388267993927
Validation loss: 1.945978892746792

Epoch: 6| Step: 8
Training loss: 0.8824440240859985
Validation loss: 1.974434882081965

Epoch: 6| Step: 9
Training loss: 1.3079686164855957
Validation loss: 2.0241368970563336

Epoch: 6| Step: 10
Training loss: 1.202778697013855
Validation loss: 2.050529622262524

Epoch: 6| Step: 11
Training loss: 1.6218218803405762
Validation loss: 2.085402145180651

Epoch: 6| Step: 12
Training loss: 1.104742407798767
Validation loss: 2.0970137644839544

Epoch: 6| Step: 13
Training loss: 0.7001264095306396
Validation loss: 2.1323966441615934

Epoch: 314| Step: 0
Training loss: 0.9595749378204346
Validation loss: 2.1653789615118377

Epoch: 6| Step: 1
Training loss: 0.8637317419052124
Validation loss: 2.141322696080772

Epoch: 6| Step: 2
Training loss: 1.366654634475708
Validation loss: 2.1266433974748016

Epoch: 6| Step: 3
Training loss: 1.5517737865447998
Validation loss: 2.1004226848643315

Epoch: 6| Step: 4
Training loss: 1.091549277305603
Validation loss: 2.032758520495507

Epoch: 6| Step: 5
Training loss: 1.2126331329345703
Validation loss: 2.0098680552615913

Epoch: 6| Step: 6
Training loss: 1.3227195739746094
Validation loss: 1.9762097968850085

Epoch: 6| Step: 7
Training loss: 0.7733352184295654
Validation loss: 1.9546013096327424

Epoch: 6| Step: 8
Training loss: 0.9027460217475891
Validation loss: 1.9476141609171385

Epoch: 6| Step: 9
Training loss: 1.2591772079467773
Validation loss: 1.97278328223895

Epoch: 6| Step: 10
Training loss: 1.184152603149414
Validation loss: 2.0076533620075514

Epoch: 6| Step: 11
Training loss: 0.9880325794219971
Validation loss: 2.0505495571321055

Epoch: 6| Step: 12
Training loss: 0.41069215536117554
Validation loss: 2.052819114859386

Epoch: 6| Step: 13
Training loss: 0.9362761974334717
Validation loss: 2.0571022623328754

Epoch: 315| Step: 0
Training loss: 1.0500390529632568
Validation loss: 2.046562866498065

Epoch: 6| Step: 1
Training loss: 0.8514114022254944
Validation loss: 2.034130124635594

Epoch: 6| Step: 2
Training loss: 0.7691212892532349
Validation loss: 2.0260674594551005

Epoch: 6| Step: 3
Training loss: 1.1235229969024658
Validation loss: 1.9906832748843777

Epoch: 6| Step: 4
Training loss: 1.7842161655426025
Validation loss: 2.0131171839211577

Epoch: 6| Step: 5
Training loss: 0.5266593098640442
Validation loss: 1.9718690892701507

Epoch: 6| Step: 6
Training loss: 1.003625512123108
Validation loss: 1.9706502986210648

Epoch: 6| Step: 7
Training loss: 1.4198272228240967
Validation loss: 1.9554026139679777

Epoch: 6| Step: 8
Training loss: 0.5298075675964355
Validation loss: 1.9870738778063046

Epoch: 6| Step: 9
Training loss: 0.9370830059051514
Validation loss: 1.9741179814902685

Epoch: 6| Step: 10
Training loss: 0.9939364790916443
Validation loss: 1.9969170452446066

Epoch: 6| Step: 11
Training loss: 1.4089277982711792
Validation loss: 2.0206522300679195

Epoch: 6| Step: 12
Training loss: 0.692229688167572
Validation loss: 2.0289020108920273

Epoch: 6| Step: 13
Training loss: 1.6243504285812378
Validation loss: 2.044291880822951

Epoch: 316| Step: 0
Training loss: 1.0853451490402222
Validation loss: 2.0135782252075853

Epoch: 6| Step: 1
Training loss: 0.6788439750671387
Validation loss: 2.0190640098305157

Epoch: 6| Step: 2
Training loss: 0.5648919939994812
Validation loss: 1.9982295638771468

Epoch: 6| Step: 3
Training loss: 1.0707440376281738
Validation loss: 2.0156550433046077

Epoch: 6| Step: 4
Training loss: 1.2051748037338257
Validation loss: 2.004652718062042

Epoch: 6| Step: 5
Training loss: 0.9864538908004761
Validation loss: 1.9757595216074297

Epoch: 6| Step: 6
Training loss: 0.9437301158905029
Validation loss: 1.9876979935553767

Epoch: 6| Step: 7
Training loss: 1.1487228870391846
Validation loss: 2.0024375402799217

Epoch: 6| Step: 8
Training loss: 1.2076466083526611
Validation loss: 2.001807571739279

Epoch: 6| Step: 9
Training loss: 1.2463123798370361
Validation loss: 1.9870511870230398

Epoch: 6| Step: 10
Training loss: 1.3176429271697998
Validation loss: 2.0325090821071337

Epoch: 6| Step: 11
Training loss: 0.9443539381027222
Validation loss: 2.0171502021051224

Epoch: 6| Step: 12
Training loss: 1.1465070247650146
Validation loss: 2.0257385892252766

Epoch: 6| Step: 13
Training loss: 0.4621826708316803
Validation loss: 2.0167358408692064

Epoch: 317| Step: 0
Training loss: 0.6720665693283081
Validation loss: 2.032509555098831

Epoch: 6| Step: 1
Training loss: 0.919622540473938
Validation loss: 2.028904937928723

Epoch: 6| Step: 2
Training loss: 0.7953624725341797
Validation loss: 2.003153730464238

Epoch: 6| Step: 3
Training loss: 0.5339528322219849
Validation loss: 2.007636975216609

Epoch: 6| Step: 4
Training loss: 0.8399003744125366
Validation loss: 2.011681059355377

Epoch: 6| Step: 5
Training loss: 0.9601287841796875
Validation loss: 2.008281394999514

Epoch: 6| Step: 6
Training loss: 0.9979473352432251
Validation loss: 2.0189612014319307

Epoch: 6| Step: 7
Training loss: 1.3057234287261963
Validation loss: 2.0211425314667406

Epoch: 6| Step: 8
Training loss: 1.2488205432891846
Validation loss: 2.0129508843985935

Epoch: 6| Step: 9
Training loss: 1.6291180849075317
Validation loss: 2.027076430218194

Epoch: 6| Step: 10
Training loss: 1.271198034286499
Validation loss: 1.9971161375763595

Epoch: 6| Step: 11
Training loss: 1.100886344909668
Validation loss: 1.9836198181234381

Epoch: 6| Step: 12
Training loss: 1.052240014076233
Validation loss: 1.9685644180543962

Epoch: 6| Step: 13
Training loss: 0.8885901570320129
Validation loss: 1.9508661852088025

Epoch: 318| Step: 0
Training loss: 1.4719878435134888
Validation loss: 1.925836742565196

Epoch: 6| Step: 1
Training loss: 0.6484785079956055
Validation loss: 1.9280292616095593

Epoch: 6| Step: 2
Training loss: 1.1220896244049072
Validation loss: 1.9519782668800765

Epoch: 6| Step: 3
Training loss: 1.6205865144729614
Validation loss: 1.957027723712306

Epoch: 6| Step: 4
Training loss: 0.5491859912872314
Validation loss: 2.0066679139291086

Epoch: 6| Step: 5
Training loss: 0.9935865998268127
Validation loss: 2.015994555206709

Epoch: 6| Step: 6
Training loss: 0.5690975189208984
Validation loss: 2.047406332467192

Epoch: 6| Step: 7
Training loss: 1.2346998453140259
Validation loss: 2.0683445315207205

Epoch: 6| Step: 8
Training loss: 1.0070950984954834
Validation loss: 2.079512160311463

Epoch: 6| Step: 9
Training loss: 0.9073203802108765
Validation loss: 2.062407592291473

Epoch: 6| Step: 10
Training loss: 1.0190898180007935
Validation loss: 2.0508401900209408

Epoch: 6| Step: 11
Training loss: 0.8074764013290405
Validation loss: 1.9967805441989694

Epoch: 6| Step: 12
Training loss: 1.0279672145843506
Validation loss: 1.9462904635296072

Epoch: 6| Step: 13
Training loss: 1.5538185834884644
Validation loss: 1.9190352321952902

Epoch: 319| Step: 0
Training loss: 0.9978748559951782
Validation loss: 1.9152428860305457

Epoch: 6| Step: 1
Training loss: 1.0148355960845947
Validation loss: 1.9075442674339458

Epoch: 6| Step: 2
Training loss: 1.1722278594970703
Validation loss: 1.931193568373239

Epoch: 6| Step: 3
Training loss: 0.6584295034408569
Validation loss: 1.9832362680024997

Epoch: 6| Step: 4
Training loss: 1.266096591949463
Validation loss: 2.003153949655512

Epoch: 6| Step: 5
Training loss: 0.8982843160629272
Validation loss: 2.0586730523775985

Epoch: 6| Step: 6
Training loss: 1.2507295608520508
Validation loss: 2.080126295807541

Epoch: 6| Step: 7
Training loss: 1.0730351209640503
Validation loss: 2.062205952982749

Epoch: 6| Step: 8
Training loss: 0.953490674495697
Validation loss: 2.036801261286582

Epoch: 6| Step: 9
Training loss: 1.1915043592453003
Validation loss: 1.9936356313766972

Epoch: 6| Step: 10
Training loss: 0.9167795777320862
Validation loss: 1.9454762166546238

Epoch: 6| Step: 11
Training loss: 0.7859140634536743
Validation loss: 1.9313079541729343

Epoch: 6| Step: 12
Training loss: 0.9625470638275146
Validation loss: 1.9292472229208997

Epoch: 6| Step: 13
Training loss: 1.3969895839691162
Validation loss: 1.9328892897534113

Epoch: 320| Step: 0
Training loss: 1.675264596939087
Validation loss: 1.9466166060457948

Epoch: 6| Step: 1
Training loss: 1.1574229001998901
Validation loss: 1.9678029719219412

Epoch: 6| Step: 2
Training loss: 1.3739635944366455
Validation loss: 2.0282095350244993

Epoch: 6| Step: 3
Training loss: 0.40449777245521545
Validation loss: 2.0293865896040395

Epoch: 6| Step: 4
Training loss: 0.47573405504226685
Validation loss: 2.059084984564012

Epoch: 6| Step: 5
Training loss: 1.05256187915802
Validation loss: 2.0436285849540465

Epoch: 6| Step: 6
Training loss: 1.0383013486862183
Validation loss: 2.0423520252268803

Epoch: 6| Step: 7
Training loss: 0.8689860105514526
Validation loss: 2.059150117699818

Epoch: 6| Step: 8
Training loss: 0.8586627244949341
Validation loss: 2.0336358316483034

Epoch: 6| Step: 9
Training loss: 1.2176098823547363
Validation loss: 2.006262970227067

Epoch: 6| Step: 10
Training loss: 0.6398051977157593
Validation loss: 2.0146296613959858

Epoch: 6| Step: 11
Training loss: 0.9307626485824585
Validation loss: 1.9911530440853489

Epoch: 6| Step: 12
Training loss: 0.945282518863678
Validation loss: 1.9835804316305345

Epoch: 6| Step: 13
Training loss: 1.4724223613739014
Validation loss: 1.9838821272696219

Epoch: 321| Step: 0
Training loss: 1.2027188539505005
Validation loss: 1.9656767383698495

Epoch: 6| Step: 1
Training loss: 0.6985865831375122
Validation loss: 1.9511409036574825

Epoch: 6| Step: 2
Training loss: 0.53462153673172
Validation loss: 1.9761011062129852

Epoch: 6| Step: 3
Training loss: 1.205146074295044
Validation loss: 1.9695022798353625

Epoch: 6| Step: 4
Training loss: 1.0872993469238281
Validation loss: 1.9659732362275482

Epoch: 6| Step: 5
Training loss: 1.155766248703003
Validation loss: 1.9561486269838066

Epoch: 6| Step: 6
Training loss: 1.0330548286437988
Validation loss: 1.950785913775044

Epoch: 6| Step: 7
Training loss: 0.7639728784561157
Validation loss: 1.9823196126568703

Epoch: 6| Step: 8
Training loss: 1.291795253753662
Validation loss: 1.963660922101749

Epoch: 6| Step: 9
Training loss: 1.2182047367095947
Validation loss: 1.9773110010290658

Epoch: 6| Step: 10
Training loss: 0.5933123230934143
Validation loss: 1.9765400604535175

Epoch: 6| Step: 11
Training loss: 0.6162554025650024
Validation loss: 2.023780648426343

Epoch: 6| Step: 12
Training loss: 0.9378623962402344
Validation loss: 2.034121988922037

Epoch: 6| Step: 13
Training loss: 2.025731086730957
Validation loss: 2.048629104450185

Epoch: 322| Step: 0
Training loss: 1.0416584014892578
Validation loss: 2.0258731226767264

Epoch: 6| Step: 1
Training loss: 0.7451450824737549
Validation loss: 2.0091186210673344

Epoch: 6| Step: 2
Training loss: 0.9428943395614624
Validation loss: 1.9734523514265656

Epoch: 6| Step: 3
Training loss: 1.4382898807525635
Validation loss: 1.9555070759147726

Epoch: 6| Step: 4
Training loss: 0.841407060623169
Validation loss: 1.940312421450051

Epoch: 6| Step: 5
Training loss: 0.7796033620834351
Validation loss: 1.9377573959289058

Epoch: 6| Step: 6
Training loss: 1.0101274251937866
Validation loss: 1.9476892614877352

Epoch: 6| Step: 7
Training loss: 0.9546202421188354
Validation loss: 1.9887459329379502

Epoch: 6| Step: 8
Training loss: 0.6774836182594299
Validation loss: 2.0235771850873063

Epoch: 6| Step: 9
Training loss: 1.0571014881134033
Validation loss: 2.035638857913274

Epoch: 6| Step: 10
Training loss: 1.213374376296997
Validation loss: 2.0182752147797616

Epoch: 6| Step: 11
Training loss: 1.248057246208191
Validation loss: 2.008129365982548

Epoch: 6| Step: 12
Training loss: 1.0973771810531616
Validation loss: 1.9557975979261502

Epoch: 6| Step: 13
Training loss: 0.5002719163894653
Validation loss: 1.9423280531360256

Epoch: 323| Step: 0
Training loss: 0.7019453048706055
Validation loss: 1.9441144056217645

Epoch: 6| Step: 1
Training loss: 1.2599782943725586
Validation loss: 1.9317333185544578

Epoch: 6| Step: 2
Training loss: 1.4355930089950562
Validation loss: 1.9486032224470569

Epoch: 6| Step: 3
Training loss: 1.1872155666351318
Validation loss: 1.9560437766454553

Epoch: 6| Step: 4
Training loss: 0.6472272872924805
Validation loss: 1.97675246320745

Epoch: 6| Step: 5
Training loss: 0.8736273050308228
Validation loss: 1.9708500549357424

Epoch: 6| Step: 6
Training loss: 1.3488783836364746
Validation loss: 2.019708110440162

Epoch: 6| Step: 7
Training loss: 0.9286293983459473
Validation loss: 2.052095659317509

Epoch: 6| Step: 8
Training loss: 0.7978723049163818
Validation loss: 2.0043676104596866

Epoch: 6| Step: 9
Training loss: 1.0759695768356323
Validation loss: 2.021706214515112

Epoch: 6| Step: 10
Training loss: 0.7386380434036255
Validation loss: 2.00067473483342

Epoch: 6| Step: 11
Training loss: 1.1577037572860718
Validation loss: 1.9750326423234836

Epoch: 6| Step: 12
Training loss: 0.9730377197265625
Validation loss: 1.9412080831425165

Epoch: 6| Step: 13
Training loss: 0.3936287462711334
Validation loss: 1.9264406722079042

Epoch: 324| Step: 0
Training loss: 1.2793102264404297
Validation loss: 1.9346338702786354

Epoch: 6| Step: 1
Training loss: 0.4267379641532898
Validation loss: 1.9890714588985647

Epoch: 6| Step: 2
Training loss: 1.2029054164886475
Validation loss: 1.9798432806486725

Epoch: 6| Step: 3
Training loss: 0.8169974088668823
Validation loss: 1.9732937761532363

Epoch: 6| Step: 4
Training loss: 0.8464649319648743
Validation loss: 2.0191067316198863

Epoch: 6| Step: 5
Training loss: 0.9655344486236572
Validation loss: 1.9986969988833192

Epoch: 6| Step: 6
Training loss: 0.6649754047393799
Validation loss: 1.979883619534072

Epoch: 6| Step: 7
Training loss: 1.0859295129776
Validation loss: 1.9759966045297601

Epoch: 6| Step: 8
Training loss: 0.7503461837768555
Validation loss: 1.9328148980294504

Epoch: 6| Step: 9
Training loss: 1.2719610929489136
Validation loss: 1.9497270994288947

Epoch: 6| Step: 10
Training loss: 1.4737908840179443
Validation loss: 1.9388916748826222

Epoch: 6| Step: 11
Training loss: 1.089377760887146
Validation loss: 1.9551178614298503

Epoch: 6| Step: 12
Training loss: 0.862514317035675
Validation loss: 1.9806957449964298

Epoch: 6| Step: 13
Training loss: 0.8897322416305542
Validation loss: 2.0273773362559657

Epoch: 325| Step: 0
Training loss: 0.8009819984436035
Validation loss: 2.0292677802424275

Epoch: 6| Step: 1
Training loss: 0.8538494110107422
Validation loss: 2.0625611171927503

Epoch: 6| Step: 2
Training loss: 0.6836246252059937
Validation loss: 2.046971747952123

Epoch: 6| Step: 3
Training loss: 1.2101471424102783
Validation loss: 2.008438846116425

Epoch: 6| Step: 4
Training loss: 1.410954236984253
Validation loss: 1.9768235196349442

Epoch: 6| Step: 5
Training loss: 1.0946093797683716
Validation loss: 1.9754182830933602

Epoch: 6| Step: 6
Training loss: 0.781110942363739
Validation loss: 1.9278456190580964

Epoch: 6| Step: 7
Training loss: 0.9916623830795288
Validation loss: 1.9213024326550063

Epoch: 6| Step: 8
Training loss: 1.4223785400390625
Validation loss: 1.9109836445059827

Epoch: 6| Step: 9
Training loss: 0.39573904871940613
Validation loss: 1.9024888443690475

Epoch: 6| Step: 10
Training loss: 0.9132051467895508
Validation loss: 1.9178862264079433

Epoch: 6| Step: 11
Training loss: 1.3193254470825195
Validation loss: 1.9559232650264617

Epoch: 6| Step: 12
Training loss: 0.9161137342453003
Validation loss: 2.0013879012036067

Epoch: 6| Step: 13
Training loss: 0.5499093532562256
Validation loss: 2.0229242540174917

Epoch: 326| Step: 0
Training loss: 0.9606003761291504
Validation loss: 2.0264353739318026

Epoch: 6| Step: 1
Training loss: 0.934170126914978
Validation loss: 2.0171636278911302

Epoch: 6| Step: 2
Training loss: 0.7088488936424255
Validation loss: 2.007264203922723

Epoch: 6| Step: 3
Training loss: 1.4079681634902954
Validation loss: 1.9980468301362888

Epoch: 6| Step: 4
Training loss: 0.5856536030769348
Validation loss: 1.9721206259983841

Epoch: 6| Step: 5
Training loss: 0.7867027521133423
Validation loss: 1.9671750222482989

Epoch: 6| Step: 6
Training loss: 1.4061522483825684
Validation loss: 1.9690676068746915

Epoch: 6| Step: 7
Training loss: 0.8854122757911682
Validation loss: 1.9848515628486552

Epoch: 6| Step: 8
Training loss: 0.8754928708076477
Validation loss: 1.9927036672510126

Epoch: 6| Step: 9
Training loss: 0.9549089670181274
Validation loss: 1.9884308653493081

Epoch: 6| Step: 10
Training loss: 1.0534160137176514
Validation loss: 1.9784276370079286

Epoch: 6| Step: 11
Training loss: 0.8267629146575928
Validation loss: 1.9891287613940496

Epoch: 6| Step: 12
Training loss: 1.2788039445877075
Validation loss: 1.992668697910924

Epoch: 6| Step: 13
Training loss: 0.5771377086639404
Validation loss: 1.986314856877891

Epoch: 327| Step: 0
Training loss: 0.6037520170211792
Validation loss: 1.9557057170457737

Epoch: 6| Step: 1
Training loss: 1.3097755908966064
Validation loss: 1.9438991597903672

Epoch: 6| Step: 2
Training loss: 1.4328336715698242
Validation loss: 1.927410658969674

Epoch: 6| Step: 3
Training loss: 0.7480384111404419
Validation loss: 1.9377376392323484

Epoch: 6| Step: 4
Training loss: 0.8249990940093994
Validation loss: 1.9353526715309388

Epoch: 6| Step: 5
Training loss: 0.6284433007240295
Validation loss: 1.9501934269423127

Epoch: 6| Step: 6
Training loss: 1.2611409425735474
Validation loss: 1.9859444531061317

Epoch: 6| Step: 7
Training loss: 0.8588290810585022
Validation loss: 2.056776500517322

Epoch: 6| Step: 8
Training loss: 1.1854679584503174
Validation loss: 2.075660341529436

Epoch: 6| Step: 9
Training loss: 1.1971338987350464
Validation loss: 2.04639853969697

Epoch: 6| Step: 10
Training loss: 0.8532115817070007
Validation loss: 2.0154092299040927

Epoch: 6| Step: 11
Training loss: 0.6712591648101807
Validation loss: 1.9450116465168614

Epoch: 6| Step: 12
Training loss: 1.498215675354004
Validation loss: 1.912559728468618

Epoch: 6| Step: 13
Training loss: 0.7547671794891357
Validation loss: 1.8757408434344875

Epoch: 328| Step: 0
Training loss: 1.290185570716858
Validation loss: 1.8558035550578948

Epoch: 6| Step: 1
Training loss: 1.0567609071731567
Validation loss: 1.8675208681373185

Epoch: 6| Step: 2
Training loss: 0.7676169276237488
Validation loss: 1.8651313179282731

Epoch: 6| Step: 3
Training loss: 1.158217191696167
Validation loss: 1.870757290112075

Epoch: 6| Step: 4
Training loss: 1.2237893342971802
Validation loss: 1.8916770373621294

Epoch: 6| Step: 5
Training loss: 0.5741998553276062
Validation loss: 1.9361620359523322

Epoch: 6| Step: 6
Training loss: 0.8766789436340332
Validation loss: 1.9514127380104476

Epoch: 6| Step: 7
Training loss: 0.7703754901885986
Validation loss: 2.02640785196776

Epoch: 6| Step: 8
Training loss: 1.172633409500122
Validation loss: 2.044765915921939

Epoch: 6| Step: 9
Training loss: 0.7596604824066162
Validation loss: 2.083545487414124

Epoch: 6| Step: 10
Training loss: 0.6003268957138062
Validation loss: 2.02874727659328

Epoch: 6| Step: 11
Training loss: 1.048096776008606
Validation loss: 2.027140866043747

Epoch: 6| Step: 12
Training loss: 1.018561840057373
Validation loss: 1.9540738264719646

Epoch: 6| Step: 13
Training loss: 1.0187931060791016
Validation loss: 1.9389097818764307

Epoch: 329| Step: 0
Training loss: 0.6894956827163696
Validation loss: 1.9020622366218156

Epoch: 6| Step: 1
Training loss: 0.717362642288208
Validation loss: 1.874289338306714

Epoch: 6| Step: 2
Training loss: 0.7655462026596069
Validation loss: 1.8427933672423005

Epoch: 6| Step: 3
Training loss: 1.4719998836517334
Validation loss: 1.8500215930323447

Epoch: 6| Step: 4
Training loss: 1.3196988105773926
Validation loss: 1.861147108898368

Epoch: 6| Step: 5
Training loss: 1.114808201789856
Validation loss: 1.8646563112094838

Epoch: 6| Step: 6
Training loss: 0.9474179744720459
Validation loss: 1.8850356276317308

Epoch: 6| Step: 7
Training loss: 0.4325961768627167
Validation loss: 1.905994503728805

Epoch: 6| Step: 8
Training loss: 1.006150484085083
Validation loss: 1.9154412028610066

Epoch: 6| Step: 9
Training loss: 1.2626558542251587
Validation loss: 1.9716981303307317

Epoch: 6| Step: 10
Training loss: 0.9562103748321533
Validation loss: 2.0391612245190527

Epoch: 6| Step: 11
Training loss: 1.2652273178100586
Validation loss: 2.053988084998182

Epoch: 6| Step: 12
Training loss: 0.7710515260696411
Validation loss: 2.0672172577150407

Epoch: 6| Step: 13
Training loss: 0.518545925617218
Validation loss: 2.065263581532304

Epoch: 330| Step: 0
Training loss: 0.7147289514541626
Validation loss: 2.0482981333168606

Epoch: 6| Step: 1
Training loss: 1.0461862087249756
Validation loss: 2.01744294294747

Epoch: 6| Step: 2
Training loss: 0.499073326587677
Validation loss: 1.9705044095234205

Epoch: 6| Step: 3
Training loss: 1.0527827739715576
Validation loss: 1.948923986445191

Epoch: 6| Step: 4
Training loss: 1.0059541463851929
Validation loss: 1.9076939616152035

Epoch: 6| Step: 5
Training loss: 1.08512544631958
Validation loss: 1.8820369666622532

Epoch: 6| Step: 6
Training loss: 1.3431370258331299
Validation loss: 1.9003112931405344

Epoch: 6| Step: 7
Training loss: 0.8971084356307983
Validation loss: 1.8984815984643915

Epoch: 6| Step: 8
Training loss: 1.2008674144744873
Validation loss: 1.8918760104845929

Epoch: 6| Step: 9
Training loss: 1.0713882446289062
Validation loss: 1.9105574700140184

Epoch: 6| Step: 10
Training loss: 0.9139520525932312
Validation loss: 1.9589965548566592

Epoch: 6| Step: 11
Training loss: 0.738944411277771
Validation loss: 2.009904266685568

Epoch: 6| Step: 12
Training loss: 0.8544938564300537
Validation loss: 2.00652317846975

Epoch: 6| Step: 13
Training loss: 1.0119086503982544
Validation loss: 2.041745795998522

Epoch: 331| Step: 0
Training loss: 1.0366168022155762
Validation loss: 2.0695188301865772

Epoch: 6| Step: 1
Training loss: 0.31905677914619446
Validation loss: 2.05907727056934

Epoch: 6| Step: 2
Training loss: 1.0290277004241943
Validation loss: 2.0675610752515894

Epoch: 6| Step: 3
Training loss: 0.7474324107170105
Validation loss: 2.0504277649746148

Epoch: 6| Step: 4
Training loss: 0.9431016445159912
Validation loss: 2.061679244041443

Epoch: 6| Step: 5
Training loss: 1.2388056516647339
Validation loss: 2.014630094651253

Epoch: 6| Step: 6
Training loss: 1.3507521152496338
Validation loss: 1.9927644191249725

Epoch: 6| Step: 7
Training loss: 0.9571731090545654
Validation loss: 1.9331469433282011

Epoch: 6| Step: 8
Training loss: 0.8628250360488892
Validation loss: 1.9071787916203982

Epoch: 6| Step: 9
Training loss: 1.3760203123092651
Validation loss: 1.8870085606011011

Epoch: 6| Step: 10
Training loss: 1.0430322885513306
Validation loss: 1.8689016654927244

Epoch: 6| Step: 11
Training loss: 1.016251564025879
Validation loss: 1.8674766414908952

Epoch: 6| Step: 12
Training loss: 0.4957641363143921
Validation loss: 1.8683603655907415

Epoch: 6| Step: 13
Training loss: 0.9014630913734436
Validation loss: 1.8942576915987077

Epoch: 332| Step: 0
Training loss: 1.3142832517623901
Validation loss: 1.922719799062257

Epoch: 6| Step: 1
Training loss: 0.9060750603675842
Validation loss: 1.9317540840436054

Epoch: 6| Step: 2
Training loss: 0.8540676832199097
Validation loss: 1.9558306156948049

Epoch: 6| Step: 3
Training loss: 0.8751121163368225
Validation loss: 1.9915602002092587

Epoch: 6| Step: 4
Training loss: 1.075480341911316
Validation loss: 1.9919708403207923

Epoch: 6| Step: 5
Training loss: 0.678650975227356
Validation loss: 2.0270064851289153

Epoch: 6| Step: 6
Training loss: 1.177025556564331
Validation loss: 2.0117252385744484

Epoch: 6| Step: 7
Training loss: 1.0313977003097534
Validation loss: 2.001397668674428

Epoch: 6| Step: 8
Training loss: 1.192146897315979
Validation loss: 1.9756763135233233

Epoch: 6| Step: 9
Training loss: 0.7893610596656799
Validation loss: 1.9920115163249354

Epoch: 6| Step: 10
Training loss: 1.0032081604003906
Validation loss: 1.957688000894362

Epoch: 6| Step: 11
Training loss: 0.7632596492767334
Validation loss: 1.941350317770435

Epoch: 6| Step: 12
Training loss: 0.5556193590164185
Validation loss: 1.9375397236116472

Epoch: 6| Step: 13
Training loss: 1.2103197574615479
Validation loss: 1.9233375877462409

Epoch: 333| Step: 0
Training loss: 0.7382696866989136
Validation loss: 1.9217131048120477

Epoch: 6| Step: 1
Training loss: 1.1706088781356812
Validation loss: 1.9072116010932512

Epoch: 6| Step: 2
Training loss: 0.6628849506378174
Validation loss: 1.898135095514277

Epoch: 6| Step: 3
Training loss: 0.5255126953125
Validation loss: 1.886057903689723

Epoch: 6| Step: 4
Training loss: 1.563185214996338
Validation loss: 1.9305716317187074

Epoch: 6| Step: 5
Training loss: 0.8075894117355347
Validation loss: 1.9125903819196968

Epoch: 6| Step: 6
Training loss: 0.6602715253829956
Validation loss: 1.918695843347939

Epoch: 6| Step: 7
Training loss: 0.7347793579101562
Validation loss: 1.9304259848851029

Epoch: 6| Step: 8
Training loss: 1.1524856090545654
Validation loss: 1.9534117226959558

Epoch: 6| Step: 9
Training loss: 0.9260112643241882
Validation loss: 1.9516774121151175

Epoch: 6| Step: 10
Training loss: 1.255387783050537
Validation loss: 1.9544373660959222

Epoch: 6| Step: 11
Training loss: 0.7879356145858765
Validation loss: 1.9750872273598947

Epoch: 6| Step: 12
Training loss: 0.964184582233429
Validation loss: 1.980256119082051

Epoch: 6| Step: 13
Training loss: 1.008862853050232
Validation loss: 1.965448820462791

Epoch: 334| Step: 0
Training loss: 0.7859063148498535
Validation loss: 1.9502441703632314

Epoch: 6| Step: 1
Training loss: 1.083818793296814
Validation loss: 1.9477310231936875

Epoch: 6| Step: 2
Training loss: 1.2225651741027832
Validation loss: 1.9368416827212098

Epoch: 6| Step: 3
Training loss: 0.5370672345161438
Validation loss: 1.9124482626556067

Epoch: 6| Step: 4
Training loss: 1.0801259279251099
Validation loss: 1.8798805641871628

Epoch: 6| Step: 5
Training loss: 1.3316665887832642
Validation loss: 1.8814232272486533

Epoch: 6| Step: 6
Training loss: 1.0714421272277832
Validation loss: 1.8752013483355123

Epoch: 6| Step: 7
Training loss: 0.5071461200714111
Validation loss: 1.892961948148666

Epoch: 6| Step: 8
Training loss: 0.8679585456848145
Validation loss: 1.9124732966064124

Epoch: 6| Step: 9
Training loss: 0.8177388906478882
Validation loss: 1.951492888953096

Epoch: 6| Step: 10
Training loss: 0.6150656938552856
Validation loss: 1.9579619707599762

Epoch: 6| Step: 11
Training loss: 1.069071650505066
Validation loss: 1.9988476230252175

Epoch: 6| Step: 12
Training loss: 1.0150128602981567
Validation loss: 2.0173799491697744

Epoch: 6| Step: 13
Training loss: 0.776481568813324
Validation loss: 2.0476687364680792

Epoch: 335| Step: 0
Training loss: 0.8220075964927673
Validation loss: 2.032373648817821

Epoch: 6| Step: 1
Training loss: 1.2026667594909668
Validation loss: 2.0219793473520586

Epoch: 6| Step: 2
Training loss: 0.5502709746360779
Validation loss: 1.9969651340156473

Epoch: 6| Step: 3
Training loss: 0.7280228137969971
Validation loss: 1.976062269620998

Epoch: 6| Step: 4
Training loss: 1.2419650554656982
Validation loss: 1.942708751206757

Epoch: 6| Step: 5
Training loss: 1.3315098285675049
Validation loss: 1.9134055260689027

Epoch: 6| Step: 6
Training loss: 0.5009879469871521
Validation loss: 1.9040733716821159

Epoch: 6| Step: 7
Training loss: 0.9675973057746887
Validation loss: 1.9073757266485563

Epoch: 6| Step: 8
Training loss: 1.4870892763137817
Validation loss: 1.861382540836129

Epoch: 6| Step: 9
Training loss: 0.8555432558059692
Validation loss: 1.8904510544192406

Epoch: 6| Step: 10
Training loss: 0.7578874826431274
Validation loss: 1.8920098632894538

Epoch: 6| Step: 11
Training loss: 0.7181307077407837
Validation loss: 1.9149353734908565

Epoch: 6| Step: 12
Training loss: 0.8246275186538696
Validation loss: 1.9572245561948387

Epoch: 6| Step: 13
Training loss: 1.037261962890625
Validation loss: 2.0057191130935506

Epoch: 336| Step: 0
Training loss: 0.7823625206947327
Validation loss: 1.9716774955872567

Epoch: 6| Step: 1
Training loss: 1.0244250297546387
Validation loss: 1.9670694899815384

Epoch: 6| Step: 2
Training loss: 1.0156396627426147
Validation loss: 1.9427865615455053

Epoch: 6| Step: 3
Training loss: 0.8702514171600342
Validation loss: 1.949208749237881

Epoch: 6| Step: 4
Training loss: 0.9684768915176392
Validation loss: 1.8991652534854027

Epoch: 6| Step: 5
Training loss: 1.073581337928772
Validation loss: 1.8914494091464626

Epoch: 6| Step: 6
Training loss: 1.0057209730148315
Validation loss: 1.8816949449559695

Epoch: 6| Step: 7
Training loss: 0.6428702473640442
Validation loss: 1.8785541083223076

Epoch: 6| Step: 8
Training loss: 1.27804696559906
Validation loss: 1.8509809483763993

Epoch: 6| Step: 9
Training loss: 0.7894459962844849
Validation loss: 1.8560423786922167

Epoch: 6| Step: 10
Training loss: 0.6496304273605347
Validation loss: 1.8552889195821618

Epoch: 6| Step: 11
Training loss: 0.8687937259674072
Validation loss: 1.8797607242420156

Epoch: 6| Step: 12
Training loss: 0.8113477230072021
Validation loss: 1.9476749538093485

Epoch: 6| Step: 13
Training loss: 1.101281762123108
Validation loss: 1.9806402857585619

Epoch: 337| Step: 0
Training loss: 0.6195738911628723
Validation loss: 2.0443364958609305

Epoch: 6| Step: 1
Training loss: 1.3035407066345215
Validation loss: 2.09548613332933

Epoch: 6| Step: 2
Training loss: 1.2380611896514893
Validation loss: 2.1282411262553227

Epoch: 6| Step: 3
Training loss: 1.1792727708816528
Validation loss: 2.167006864342638

Epoch: 6| Step: 4
Training loss: 0.9916989803314209
Validation loss: 2.1478987355386057

Epoch: 6| Step: 5
Training loss: 1.1189193725585938
Validation loss: 2.068191566774922

Epoch: 6| Step: 6
Training loss: 0.779442548751831
Validation loss: 1.9661418891722156

Epoch: 6| Step: 7
Training loss: 0.5075494050979614
Validation loss: 1.9376991538591282

Epoch: 6| Step: 8
Training loss: 0.8950274586677551
Validation loss: 1.8918364073640557

Epoch: 6| Step: 9
Training loss: 0.8993715047836304
Validation loss: 1.8787903785705566

Epoch: 6| Step: 10
Training loss: 0.7433954477310181
Validation loss: 1.8768410016131658

Epoch: 6| Step: 11
Training loss: 1.0818830728530884
Validation loss: 1.862755214014361

Epoch: 6| Step: 12
Training loss: 0.9672556519508362
Validation loss: 1.8850139687138219

Epoch: 6| Step: 13
Training loss: 0.8454625010490417
Validation loss: 1.9143821475326375

Epoch: 338| Step: 0
Training loss: 0.5491747856140137
Validation loss: 1.9245250994159329

Epoch: 6| Step: 1
Training loss: 0.8132107853889465
Validation loss: 1.9462366809127152

Epoch: 6| Step: 2
Training loss: 0.6959855556488037
Validation loss: 1.9813454343426613

Epoch: 6| Step: 3
Training loss: 1.188815712928772
Validation loss: 1.9470874981213642

Epoch: 6| Step: 4
Training loss: 0.9397569894790649
Validation loss: 1.9382755551286923

Epoch: 6| Step: 5
Training loss: 1.0166302919387817
Validation loss: 1.932886827376581

Epoch: 6| Step: 6
Training loss: 1.1504137516021729
Validation loss: 1.925593178759339

Epoch: 6| Step: 7
Training loss: 0.6369131803512573
Validation loss: 1.9278637593792332

Epoch: 6| Step: 8
Training loss: 1.1448227167129517
Validation loss: 1.947673322052084

Epoch: 6| Step: 9
Training loss: 0.8118252158164978
Validation loss: 1.935581725130799

Epoch: 6| Step: 10
Training loss: 1.1709954738616943
Validation loss: 1.98407958656229

Epoch: 6| Step: 11
Training loss: 0.8384711742401123
Validation loss: 1.9591444641031244

Epoch: 6| Step: 12
Training loss: 0.9372677803039551
Validation loss: 1.9320124323650072

Epoch: 6| Step: 13
Training loss: 0.5451505184173584
Validation loss: 1.9324026979425901

Epoch: 339| Step: 0
Training loss: 0.5226244926452637
Validation loss: 1.9422096706205798

Epoch: 6| Step: 1
Training loss: 0.8078820109367371
Validation loss: 1.9561198911359232

Epoch: 6| Step: 2
Training loss: 1.043982744216919
Validation loss: 1.984310055291781

Epoch: 6| Step: 3
Training loss: 1.1401698589324951
Validation loss: 1.9750949875000985

Epoch: 6| Step: 4
Training loss: 1.1348880529403687
Validation loss: 1.985329762581856

Epoch: 6| Step: 5
Training loss: 0.8631531000137329
Validation loss: 1.9616440790955738

Epoch: 6| Step: 6
Training loss: 1.1702436208724976
Validation loss: 1.9486478938851306

Epoch: 6| Step: 7
Training loss: 0.7606279850006104
Validation loss: 1.9182446900234427

Epoch: 6| Step: 8
Training loss: 0.4195418357849121
Validation loss: 1.9112454204149143

Epoch: 6| Step: 9
Training loss: 0.9096203446388245
Validation loss: 1.906792450976628

Epoch: 6| Step: 10
Training loss: 0.7671605348587036
Validation loss: 1.9151156922822357

Epoch: 6| Step: 11
Training loss: 1.0723800659179688
Validation loss: 1.915306786055206

Epoch: 6| Step: 12
Training loss: 0.9168845415115356
Validation loss: 1.9414493524900047

Epoch: 6| Step: 13
Training loss: 0.8397178053855896
Validation loss: 1.9587253268047045

Epoch: 340| Step: 0
Training loss: 0.6142575144767761
Validation loss: 1.977580907524273

Epoch: 6| Step: 1
Training loss: 0.8847544193267822
Validation loss: 1.9970862762902373

Epoch: 6| Step: 2
Training loss: 1.3438293933868408
Validation loss: 2.014435706600066

Epoch: 6| Step: 3
Training loss: 1.2046489715576172
Validation loss: 1.9726240070917274

Epoch: 6| Step: 4
Training loss: 0.9522941708564758
Validation loss: 1.980256979183484

Epoch: 6| Step: 5
Training loss: 0.45264875888824463
Validation loss: 1.9539939408661218

Epoch: 6| Step: 6
Training loss: 0.7630620002746582
Validation loss: 1.953488285823535

Epoch: 6| Step: 7
Training loss: 0.5738821029663086
Validation loss: 1.934938802514025

Epoch: 6| Step: 8
Training loss: 0.807166337966919
Validation loss: 1.946565051232615

Epoch: 6| Step: 9
Training loss: 0.979233980178833
Validation loss: 1.917629244507

Epoch: 6| Step: 10
Training loss: 0.9706991910934448
Validation loss: 1.9321210794551398

Epoch: 6| Step: 11
Training loss: 0.9606698751449585
Validation loss: 1.9284538286988453

Epoch: 6| Step: 12
Training loss: 0.905282735824585
Validation loss: 1.9289908011754353

Epoch: 6| Step: 13
Training loss: 1.1501933336257935
Validation loss: 1.9291391526499102

Epoch: 341| Step: 0
Training loss: 1.1026334762573242
Validation loss: 1.9058185892720376

Epoch: 6| Step: 1
Training loss: 0.7938686609268188
Validation loss: 1.8997821346406014

Epoch: 6| Step: 2
Training loss: 0.6430829763412476
Validation loss: 1.916347260116249

Epoch: 6| Step: 3
Training loss: 0.8517074584960938
Validation loss: 1.9219327395962131

Epoch: 6| Step: 4
Training loss: 0.9012647867202759
Validation loss: 1.9301343130809006

Epoch: 6| Step: 5
Training loss: 0.960424542427063
Validation loss: 1.9442909686796126

Epoch: 6| Step: 6
Training loss: 0.6528599262237549
Validation loss: 1.9584082070217337

Epoch: 6| Step: 7
Training loss: 0.9044755697250366
Validation loss: 1.9928979796748008

Epoch: 6| Step: 8
Training loss: 0.6688421964645386
Validation loss: 2.021394475813835

Epoch: 6| Step: 9
Training loss: 0.729591965675354
Validation loss: 2.0054913349049066

Epoch: 6| Step: 10
Training loss: 1.1835660934448242
Validation loss: 2.0112308866234234

Epoch: 6| Step: 11
Training loss: 1.151484489440918
Validation loss: 1.9889961827185847

Epoch: 6| Step: 12
Training loss: 0.6891425251960754
Validation loss: 2.0022950762061664

Epoch: 6| Step: 13
Training loss: 0.9452037811279297
Validation loss: 1.9832150705399052

Epoch: 342| Step: 0
Training loss: 0.6382551789283752
Validation loss: 1.946304093125046

Epoch: 6| Step: 1
Training loss: 0.5819510221481323
Validation loss: 1.9435184546696243

Epoch: 6| Step: 2
Training loss: 0.8694478869438171
Validation loss: 1.9561830528320805

Epoch: 6| Step: 3
Training loss: 1.2943763732910156
Validation loss: 1.9371509039273827

Epoch: 6| Step: 4
Training loss: 0.9489540457725525
Validation loss: 1.9657536270797893

Epoch: 6| Step: 5
Training loss: 0.7319767475128174
Validation loss: 1.9529097669868059

Epoch: 6| Step: 6
Training loss: 0.594164252281189
Validation loss: 1.949120448481652

Epoch: 6| Step: 7
Training loss: 0.7565717101097107
Validation loss: 1.9581669620288316

Epoch: 6| Step: 8
Training loss: 0.38317862153053284
Validation loss: 1.9722489951759257

Epoch: 6| Step: 9
Training loss: 0.9911208152770996
Validation loss: 1.9619617821067892

Epoch: 6| Step: 10
Training loss: 1.0414068698883057
Validation loss: 1.9948982243896813

Epoch: 6| Step: 11
Training loss: 0.7237520217895508
Validation loss: 1.9877060741506598

Epoch: 6| Step: 12
Training loss: 1.8003205060958862
Validation loss: 1.9983755721840808

Epoch: 6| Step: 13
Training loss: 0.8615440726280212
Validation loss: 1.9610261212113083

Epoch: 343| Step: 0
Training loss: 0.9507540464401245
Validation loss: 1.9352336750235608

Epoch: 6| Step: 1
Training loss: 0.7536516189575195
Validation loss: 1.9400086005528767

Epoch: 6| Step: 2
Training loss: 0.5934193134307861
Validation loss: 1.894911168723978

Epoch: 6| Step: 3
Training loss: 0.7078884840011597
Validation loss: 1.887294456522952

Epoch: 6| Step: 4
Training loss: 0.7282650470733643
Validation loss: 1.8992233904459144

Epoch: 6| Step: 5
Training loss: 0.9801039695739746
Validation loss: 1.890737651496805

Epoch: 6| Step: 6
Training loss: 0.9360517859458923
Validation loss: 1.9057495696570284

Epoch: 6| Step: 7
Training loss: 0.77919602394104
Validation loss: 1.9464012320323656

Epoch: 6| Step: 8
Training loss: 0.9147366285324097
Validation loss: 1.9281556862656788

Epoch: 6| Step: 9
Training loss: 1.068892002105713
Validation loss: 1.9674560805802703

Epoch: 6| Step: 10
Training loss: 1.0264356136322021
Validation loss: 2.023623821555927

Epoch: 6| Step: 11
Training loss: 0.6836772561073303
Validation loss: 2.0103023462398077

Epoch: 6| Step: 12
Training loss: 0.9506931304931641
Validation loss: 2.019674712611783

Epoch: 6| Step: 13
Training loss: 1.1744173765182495
Validation loss: 1.9927991808101695

Epoch: 344| Step: 0
Training loss: 1.1786389350891113
Validation loss: 1.966291889067619

Epoch: 6| Step: 1
Training loss: 0.8474328517913818
Validation loss: 1.9298902891015495

Epoch: 6| Step: 2
Training loss: 0.9843841791152954
Validation loss: 1.9044530327602098

Epoch: 6| Step: 3
Training loss: 0.8205376863479614
Validation loss: 1.8994928765040573

Epoch: 6| Step: 4
Training loss: 0.2981109619140625
Validation loss: 1.8961514901089411

Epoch: 6| Step: 5
Training loss: 0.6006932854652405
Validation loss: 1.8945588937369726

Epoch: 6| Step: 6
Training loss: 0.9803714752197266
Validation loss: 1.9148412135339552

Epoch: 6| Step: 7
Training loss: 0.7582091689109802
Validation loss: 1.9177539194783857

Epoch: 6| Step: 8
Training loss: 0.5078524351119995
Validation loss: 1.918707052866618

Epoch: 6| Step: 9
Training loss: 0.8134547472000122
Validation loss: 1.9247198002312773

Epoch: 6| Step: 10
Training loss: 0.8786965012550354
Validation loss: 1.9468403131731096

Epoch: 6| Step: 11
Training loss: 1.0569207668304443
Validation loss: 1.9582971719003492

Epoch: 6| Step: 12
Training loss: 1.2425382137298584
Validation loss: 1.9736043099434144

Epoch: 6| Step: 13
Training loss: 1.1067556142807007
Validation loss: 1.9386430530137913

Epoch: 345| Step: 0
Training loss: 0.9423725008964539
Validation loss: 1.9111412494413313

Epoch: 6| Step: 1
Training loss: 0.9149072170257568
Validation loss: 1.9269482063990768

Epoch: 6| Step: 2
Training loss: 0.37781038880348206
Validation loss: 1.9070475486017042

Epoch: 6| Step: 3
Training loss: 0.8045647144317627
Validation loss: 1.8922713392524309

Epoch: 6| Step: 4
Training loss: 0.9645587205886841
Validation loss: 1.909540509664884

Epoch: 6| Step: 5
Training loss: 0.7608386874198914
Validation loss: 1.9188103470751035

Epoch: 6| Step: 6
Training loss: 1.1468539237976074
Validation loss: 1.9353775465360252

Epoch: 6| Step: 7
Training loss: 1.2107300758361816
Validation loss: 1.9728368533554899

Epoch: 6| Step: 8
Training loss: 1.1336896419525146
Validation loss: 1.9910904386992097

Epoch: 6| Step: 9
Training loss: 0.6339982748031616
Validation loss: 2.00707588144528

Epoch: 6| Step: 10
Training loss: 0.7064285278320312
Validation loss: 2.0091701810077955

Epoch: 6| Step: 11
Training loss: 0.6963465213775635
Validation loss: 1.9604931851868987

Epoch: 6| Step: 12
Training loss: 0.9590626955032349
Validation loss: 1.9543445341048702

Epoch: 6| Step: 13
Training loss: 0.36423051357269287
Validation loss: 1.8995078122743996

Epoch: 346| Step: 0
Training loss: 0.6901519298553467
Validation loss: 1.8760376514927033

Epoch: 6| Step: 1
Training loss: 0.7251880168914795
Validation loss: 1.8519767702266734

Epoch: 6| Step: 2
Training loss: 0.9751858115196228
Validation loss: 1.8575181050967144

Epoch: 6| Step: 3
Training loss: 0.5793606638908386
Validation loss: 1.8686838278206446

Epoch: 6| Step: 4
Training loss: 0.6701853275299072
Validation loss: 1.8766513075879825

Epoch: 6| Step: 5
Training loss: 1.259066104888916
Validation loss: 1.8972927678015925

Epoch: 6| Step: 6
Training loss: 0.5529983639717102
Validation loss: 1.8994154237931775

Epoch: 6| Step: 7
Training loss: 0.9600189328193665
Validation loss: 1.9295002081060921

Epoch: 6| Step: 8
Training loss: 0.8465230464935303
Validation loss: 1.9096892110763057

Epoch: 6| Step: 9
Training loss: 0.7006818652153015
Validation loss: 1.9537957201721847

Epoch: 6| Step: 10
Training loss: 1.1479201316833496
Validation loss: 1.9591178996588594

Epoch: 6| Step: 11
Training loss: 0.9332661628723145
Validation loss: 1.953329901541433

Epoch: 6| Step: 12
Training loss: 1.1337302923202515
Validation loss: 1.921770079161531

Epoch: 6| Step: 13
Training loss: 0.7726374864578247
Validation loss: 1.934976577758789

Epoch: 347| Step: 0
Training loss: 0.9152932167053223
Validation loss: 1.9257987032654464

Epoch: 6| Step: 1
Training loss: 0.9513481855392456
Validation loss: 1.9497261111454298

Epoch: 6| Step: 2
Training loss: 0.6138163208961487
Validation loss: 1.9500981338562504

Epoch: 6| Step: 3
Training loss: 0.8592261672019958
Validation loss: 1.9497375821554532

Epoch: 6| Step: 4
Training loss: 0.7449219226837158
Validation loss: 1.9619513839803717

Epoch: 6| Step: 5
Training loss: 0.7253566980361938
Validation loss: 1.9743740263805594

Epoch: 6| Step: 6
Training loss: 0.5527605414390564
Validation loss: 1.9814845208198792

Epoch: 6| Step: 7
Training loss: 1.0449241399765015
Validation loss: 1.9823404871007448

Epoch: 6| Step: 8
Training loss: 1.1127057075500488
Validation loss: 2.000796648763841

Epoch: 6| Step: 9
Training loss: 0.6965007781982422
Validation loss: 1.9625663693233202

Epoch: 6| Step: 10
Training loss: 0.9314677119255066
Validation loss: 1.9657177476472751

Epoch: 6| Step: 11
Training loss: 1.2214624881744385
Validation loss: 1.9616813736577188

Epoch: 6| Step: 12
Training loss: 0.8469351530075073
Validation loss: 1.9132053762353876

Epoch: 6| Step: 13
Training loss: 0.7495391368865967
Validation loss: 1.8966074733323948

Epoch: 348| Step: 0
Training loss: 1.4392766952514648
Validation loss: 1.8978783199864049

Epoch: 6| Step: 1
Training loss: 0.9101596474647522
Validation loss: 1.8805872650556668

Epoch: 6| Step: 2
Training loss: 0.7958098649978638
Validation loss: 1.864390685994138

Epoch: 6| Step: 3
Training loss: 0.9996556043624878
Validation loss: 1.8470127287731375

Epoch: 6| Step: 4
Training loss: 0.8970365524291992
Validation loss: 1.8600011781979633

Epoch: 6| Step: 5
Training loss: 0.7282382249832153
Validation loss: 1.8690663230034612

Epoch: 6| Step: 6
Training loss: 0.8365851044654846
Validation loss: 1.9180552908169326

Epoch: 6| Step: 7
Training loss: 0.855631411075592
Validation loss: 1.926325677543558

Epoch: 6| Step: 8
Training loss: 0.41012418270111084
Validation loss: 1.9829679945463776

Epoch: 6| Step: 9
Training loss: 0.9385679960250854
Validation loss: 2.0173552779741186

Epoch: 6| Step: 10
Training loss: 0.9284458756446838
Validation loss: 2.0152025889324885

Epoch: 6| Step: 11
Training loss: 0.6256781816482544
Validation loss: 2.0305517450455697

Epoch: 6| Step: 12
Training loss: 1.018970251083374
Validation loss: 2.037807141580889

Epoch: 6| Step: 13
Training loss: 0.4611872434616089
Validation loss: 1.9572033651413456

Epoch: 349| Step: 0
Training loss: 0.8762345314025879
Validation loss: 1.9533220824374948

Epoch: 6| Step: 1
Training loss: 0.4068261384963989
Validation loss: 1.9287439007912912

Epoch: 6| Step: 2
Training loss: 0.7809067964553833
Validation loss: 1.9145388423755605

Epoch: 6| Step: 3
Training loss: 0.5156807899475098
Validation loss: 1.9212916871552825

Epoch: 6| Step: 4
Training loss: 0.585533857345581
Validation loss: 1.9142082532246907

Epoch: 6| Step: 5
Training loss: 0.904738187789917
Validation loss: 1.9206334775493992

Epoch: 6| Step: 6
Training loss: 1.076648235321045
Validation loss: 1.9391959738987747

Epoch: 6| Step: 7
Training loss: 0.9426121115684509
Validation loss: 1.9721146796339302

Epoch: 6| Step: 8
Training loss: 0.7747195959091187
Validation loss: 1.9871895877263879

Epoch: 6| Step: 9
Training loss: 0.831780731678009
Validation loss: 1.9804054562763502

Epoch: 6| Step: 10
Training loss: 1.2094722986221313
Validation loss: 2.0186546233392533

Epoch: 6| Step: 11
Training loss: 1.0692577362060547
Validation loss: 2.0030776992920907

Epoch: 6| Step: 12
Training loss: 0.5113043785095215
Validation loss: 2.010426744338005

Epoch: 6| Step: 13
Training loss: 1.7747128009796143
Validation loss: 1.9924118262465282

Epoch: 350| Step: 0
Training loss: 0.8866870403289795
Validation loss: 2.02205063450721

Epoch: 6| Step: 1
Training loss: 1.0232985019683838
Validation loss: 2.0289327611205397

Epoch: 6| Step: 2
Training loss: 1.1186020374298096
Validation loss: 2.0364332250369492

Epoch: 6| Step: 3
Training loss: 0.777947187423706
Validation loss: 2.0127598880439677

Epoch: 6| Step: 4
Training loss: 0.6281989812850952
Validation loss: 1.975738715100032

Epoch: 6| Step: 5
Training loss: 1.0418832302093506
Validation loss: 1.9205806844977922

Epoch: 6| Step: 6
Training loss: 0.8526370525360107
Validation loss: 1.9047047181796002

Epoch: 6| Step: 7
Training loss: 0.8805752396583557
Validation loss: 1.8580492234999133

Epoch: 6| Step: 8
Training loss: 0.6945873498916626
Validation loss: 1.85335244799173

Epoch: 6| Step: 9
Training loss: 0.7631164193153381
Validation loss: 1.822584149658039

Epoch: 6| Step: 10
Training loss: 0.5794212222099304
Validation loss: 1.8244611806766962

Epoch: 6| Step: 11
Training loss: 1.0225989818572998
Validation loss: 1.8267535394237888

Epoch: 6| Step: 12
Training loss: 0.7978274822235107
Validation loss: 1.8428816974803965

Epoch: 6| Step: 13
Training loss: 0.8505669832229614
Validation loss: 1.8497141779109996

Testing loss: 2.101147895389133
