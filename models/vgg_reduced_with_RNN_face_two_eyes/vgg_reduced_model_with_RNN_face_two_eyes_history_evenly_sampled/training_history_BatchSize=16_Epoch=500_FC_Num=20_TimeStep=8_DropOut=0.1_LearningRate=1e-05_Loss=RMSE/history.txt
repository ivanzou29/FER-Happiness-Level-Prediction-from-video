Epoch: 1| Step: 0
Training loss: 4.983236439931359
Validation loss: 5.738998907114642

Epoch: 6| Step: 1
Training loss: 5.957670623986862
Validation loss: 5.729529328115244

Epoch: 6| Step: 2
Training loss: 4.620736502529187
Validation loss: 5.721392417279977

Epoch: 6| Step: 3
Training loss: 4.661844668726322
Validation loss: 5.714933735313814

Epoch: 6| Step: 4
Training loss: 5.726304031513531
Validation loss: 5.709098720892554

Epoch: 6| Step: 5
Training loss: 4.735468672021933
Validation loss: 5.703165089411131

Epoch: 6| Step: 6
Training loss: 5.963178500871154
Validation loss: 5.697808041506089

Epoch: 6| Step: 7
Training loss: 6.697616768189649
Validation loss: 5.692064824569729

Epoch: 6| Step: 8
Training loss: 5.536028505891384
Validation loss: 5.685692405381791

Epoch: 6| Step: 9
Training loss: 7.534280887302353
Validation loss: 5.678643887198175

Epoch: 6| Step: 10
Training loss: 4.814365372235257
Validation loss: 5.671126629492105

Epoch: 6| Step: 11
Training loss: 5.8269408303944505
Validation loss: 5.663601078054676

Epoch: 6| Step: 12
Training loss: 6.045999626258084
Validation loss: 5.654703557387855

Epoch: 6| Step: 13
Training loss: 6.710352560181439
Validation loss: 5.645584830526044

Epoch: 2| Step: 0
Training loss: 5.796290941453726
Validation loss: 5.635396705528249

Epoch: 6| Step: 1
Training loss: 5.733395360271062
Validation loss: 5.623773544580208

Epoch: 6| Step: 2
Training loss: 4.505872920710025
Validation loss: 5.611721939379046

Epoch: 6| Step: 3
Training loss: 6.050668398923417
Validation loss: 5.598428128076416

Epoch: 6| Step: 4
Training loss: 5.106417952241915
Validation loss: 5.584213488058725

Epoch: 6| Step: 5
Training loss: 6.3494961275851445
Validation loss: 5.569064258436571

Epoch: 6| Step: 6
Training loss: 5.263482900422685
Validation loss: 5.55307399837987

Epoch: 6| Step: 7
Training loss: 5.159411022076703
Validation loss: 5.5352039696797055

Epoch: 6| Step: 8
Training loss: 5.03690432678084
Validation loss: 5.517073225870121

Epoch: 6| Step: 9
Training loss: 6.3496958862531665
Validation loss: 5.497760271923182

Epoch: 6| Step: 10
Training loss: 5.0219268663216905
Validation loss: 5.477796057096433

Epoch: 6| Step: 11
Training loss: 4.656342575893878
Validation loss: 5.456235777389517

Epoch: 6| Step: 12
Training loss: 5.73668954481535
Validation loss: 5.434458027738786

Epoch: 6| Step: 13
Training loss: 7.634615479225198
Validation loss: 5.4119098964498935

Epoch: 3| Step: 0
Training loss: 5.0488844139753875
Validation loss: 5.388907552653742

Epoch: 6| Step: 1
Training loss: 4.774635077307999
Validation loss: 5.365247647037947

Epoch: 6| Step: 2
Training loss: 5.170981707456298
Validation loss: 5.341801727959208

Epoch: 6| Step: 3
Training loss: 4.837854945051614
Validation loss: 5.316736942410192

Epoch: 6| Step: 4
Training loss: 5.405612444907701
Validation loss: 5.29335217919475

Epoch: 6| Step: 5
Training loss: 6.4251207748520605
Validation loss: 5.269101598149147

Epoch: 6| Step: 6
Training loss: 4.630122466805515
Validation loss: 5.245160512612968

Epoch: 6| Step: 7
Training loss: 5.405554930706626
Validation loss: 5.217513611623035

Epoch: 6| Step: 8
Training loss: 5.876144622331771
Validation loss: 5.190186950343789

Epoch: 6| Step: 9
Training loss: 5.867144588308455
Validation loss: 5.160559045543536

Epoch: 6| Step: 10
Training loss: 4.683846232247996
Validation loss: 5.130901203639013

Epoch: 6| Step: 11
Training loss: 5.312243287110924
Validation loss: 5.10242233087105

Epoch: 6| Step: 12
Training loss: 5.356153938206559
Validation loss: 5.0728805603708595

Epoch: 6| Step: 13
Training loss: 4.406207145320191
Validation loss: 5.046422170712982

Epoch: 4| Step: 0
Training loss: 5.24007221871033
Validation loss: 5.020620925788575

Epoch: 6| Step: 1
Training loss: 5.426766862873729
Validation loss: 4.995520188678474

Epoch: 6| Step: 2
Training loss: 4.50527306071036
Validation loss: 4.971666875673554

Epoch: 6| Step: 3
Training loss: 5.432104832285138
Validation loss: 4.949502840139258

Epoch: 6| Step: 4
Training loss: 5.643225580228104
Validation loss: 4.92715100587039

Epoch: 6| Step: 5
Training loss: 5.444368606264093
Validation loss: 4.905028041129621

Epoch: 6| Step: 6
Training loss: 4.654153031636855
Validation loss: 4.8827000638096365

Epoch: 6| Step: 7
Training loss: 5.190217926212928
Validation loss: 4.859961206441771

Epoch: 6| Step: 8
Training loss: 5.471784523608613
Validation loss: 4.837578197662391

Epoch: 6| Step: 9
Training loss: 3.970008350238618
Validation loss: 4.8168212088047175

Epoch: 6| Step: 10
Training loss: 4.631556837699903
Validation loss: 4.793859972656787

Epoch: 6| Step: 11
Training loss: 3.715989314282578
Validation loss: 4.771218339096393

Epoch: 6| Step: 12
Training loss: 4.8085116418913945
Validation loss: 4.751938442163387

Epoch: 6| Step: 13
Training loss: 4.797056511541922
Validation loss: 4.736515273589583

Epoch: 5| Step: 0
Training loss: 4.722706531796533
Validation loss: 4.71665823474181

Epoch: 6| Step: 1
Training loss: 4.048011178434717
Validation loss: 4.700987514135425

Epoch: 6| Step: 2
Training loss: 3.8114638874895834
Validation loss: 4.683789554101847

Epoch: 6| Step: 3
Training loss: 4.617289120867741
Validation loss: 4.670385548219775

Epoch: 6| Step: 4
Training loss: 4.734199747297789
Validation loss: 4.653665696866351

Epoch: 6| Step: 5
Training loss: 4.470583879539564
Validation loss: 4.6383858853548015

Epoch: 6| Step: 6
Training loss: 5.526101340050489
Validation loss: 4.618334840149684

Epoch: 6| Step: 7
Training loss: 5.520821778867135
Validation loss: 4.600524648250988

Epoch: 6| Step: 8
Training loss: 4.722664327433125
Validation loss: 4.582273137293462

Epoch: 6| Step: 9
Training loss: 3.9887204876426274
Validation loss: 4.563274062220506

Epoch: 6| Step: 10
Training loss: 5.01364676659081
Validation loss: 4.548599568456496

Epoch: 6| Step: 11
Training loss: 5.223397201670195
Validation loss: 4.529389403586075

Epoch: 6| Step: 12
Training loss: 4.424233390653199
Validation loss: 4.511233338277363

Epoch: 6| Step: 13
Training loss: 4.6413968147627545
Validation loss: 4.495259907001594

Epoch: 6| Step: 0
Training loss: 5.703443377243424
Validation loss: 4.47941200784456

Epoch: 6| Step: 1
Training loss: 4.500139870059336
Validation loss: 4.4651078506274455

Epoch: 6| Step: 2
Training loss: 4.284042450111281
Validation loss: 4.45242411709587

Epoch: 6| Step: 3
Training loss: 4.970067263480005
Validation loss: 4.4401169818561765

Epoch: 6| Step: 4
Training loss: 4.9173237420800175
Validation loss: 4.42661748048054

Epoch: 6| Step: 5
Training loss: 3.670124561992019
Validation loss: 4.41348496242554

Epoch: 6| Step: 6
Training loss: 3.4304051093824968
Validation loss: 4.402482932949906

Epoch: 6| Step: 7
Training loss: 3.7160557836445625
Validation loss: 4.390391711189815

Epoch: 6| Step: 8
Training loss: 4.821271556739791
Validation loss: 4.380932306780167

Epoch: 6| Step: 9
Training loss: 4.219701589004149
Validation loss: 4.370902718519464

Epoch: 6| Step: 10
Training loss: 5.214108716047143
Validation loss: 4.359875580919484

Epoch: 6| Step: 11
Training loss: 4.0357983383897436
Validation loss: 4.349788566432543

Epoch: 6| Step: 12
Training loss: 3.860322781838388
Validation loss: 4.342460668194928

Epoch: 6| Step: 13
Training loss: 5.713964909676439
Validation loss: 4.330045931344969

Epoch: 7| Step: 0
Training loss: 4.505877577038441
Validation loss: 4.322275824352881

Epoch: 6| Step: 1
Training loss: 3.307633622080517
Validation loss: 4.313100335802704

Epoch: 6| Step: 2
Training loss: 3.48750937402484
Validation loss: 4.307395019116616

Epoch: 6| Step: 3
Training loss: 4.809143877827579
Validation loss: 4.298351148090899

Epoch: 6| Step: 4
Training loss: 4.84174014816507
Validation loss: 4.291339730795257

Epoch: 6| Step: 5
Training loss: 4.344551945489393
Validation loss: 4.2846676848429315

Epoch: 6| Step: 6
Training loss: 3.891717351437723
Validation loss: 4.275319255572203

Epoch: 6| Step: 7
Training loss: 5.180555360104873
Validation loss: 4.268251840113681

Epoch: 6| Step: 8
Training loss: 4.2681899411267015
Validation loss: 4.259598948245335

Epoch: 6| Step: 9
Training loss: 3.8805487498359708
Validation loss: 4.25160658870114

Epoch: 6| Step: 10
Training loss: 4.498558025328892
Validation loss: 4.2446464923931515

Epoch: 6| Step: 11
Training loss: 4.68487597453001
Validation loss: 4.236644062900314

Epoch: 6| Step: 12
Training loss: 4.773018127100082
Validation loss: 4.234453768838135

Epoch: 6| Step: 13
Training loss: 4.856989136835885
Validation loss: 4.2186105453673735

Epoch: 8| Step: 0
Training loss: 4.5127579718315385
Validation loss: 4.213752867335085

Epoch: 6| Step: 1
Training loss: 3.534961336779634
Validation loss: 4.207523660777088

Epoch: 6| Step: 2
Training loss: 5.326786354130305
Validation loss: 4.199122846022877

Epoch: 6| Step: 3
Training loss: 3.65357221047508
Validation loss: 4.188238278114985

Epoch: 6| Step: 4
Training loss: 4.625087427910992
Validation loss: 4.179599338813476

Epoch: 6| Step: 5
Training loss: 3.5871307448845515
Validation loss: 4.170028796046023

Epoch: 6| Step: 6
Training loss: 4.660187355826614
Validation loss: 4.161765052295145

Epoch: 6| Step: 7
Training loss: 3.7320503437207817
Validation loss: 4.1519174210796495

Epoch: 6| Step: 8
Training loss: 4.793293861859773
Validation loss: 4.142098628444718

Epoch: 6| Step: 9
Training loss: 4.618471641566621
Validation loss: 4.131899498216827

Epoch: 6| Step: 10
Training loss: 4.006511395239088
Validation loss: 4.122317643048827

Epoch: 6| Step: 11
Training loss: 3.8063528814333027
Validation loss: 4.120155278704646

Epoch: 6| Step: 12
Training loss: 4.6146474909861155
Validation loss: 4.110221524501325

Epoch: 6| Step: 13
Training loss: 4.181036444486232
Validation loss: 4.097483892458375

Epoch: 9| Step: 0
Training loss: 3.88752040551034
Validation loss: 4.091278403423229

Epoch: 6| Step: 1
Training loss: 4.3663082431913285
Validation loss: 4.085262577810885

Epoch: 6| Step: 2
Training loss: 3.9849166202796584
Validation loss: 4.0801350740347795

Epoch: 6| Step: 3
Training loss: 4.638692434164966
Validation loss: 4.074656920589811

Epoch: 6| Step: 4
Training loss: 5.260119539940408
Validation loss: 4.064563135837901

Epoch: 6| Step: 5
Training loss: 4.252019963157492
Validation loss: 4.056623680813264

Epoch: 6| Step: 6
Training loss: 4.486586606887636
Validation loss: 4.052028567167094

Epoch: 6| Step: 7
Training loss: 3.3756035159182556
Validation loss: 4.0467531305681606

Epoch: 6| Step: 8
Training loss: 4.183722315076369
Validation loss: 4.042278136131268

Epoch: 6| Step: 9
Training loss: 4.244017260848025
Validation loss: 4.033084933500686

Epoch: 6| Step: 10
Training loss: 4.234259009092276
Validation loss: 4.024507446943072

Epoch: 6| Step: 11
Training loss: 4.093102556820366
Validation loss: 4.017972460249354

Epoch: 6| Step: 12
Training loss: 3.5952076485077566
Validation loss: 4.018385189298863

Epoch: 6| Step: 13
Training loss: 3.576275343260156
Validation loss: 4.01221761529239

Epoch: 10| Step: 0
Training loss: 4.0883053980631185
Validation loss: 4.000384076455233

Epoch: 6| Step: 1
Training loss: 5.232525581337428
Validation loss: 3.9936822687558053

Epoch: 6| Step: 2
Training loss: 3.490736418801115
Validation loss: 3.990499565979874

Epoch: 6| Step: 3
Training loss: 3.6204693861922075
Validation loss: 3.9832387263875657

Epoch: 6| Step: 4
Training loss: 3.652098817823319
Validation loss: 3.9776021163057673

Epoch: 6| Step: 5
Training loss: 3.922802697604545
Validation loss: 3.973305035561452

Epoch: 6| Step: 6
Training loss: 4.516385235528865
Validation loss: 3.964251889499861

Epoch: 6| Step: 7
Training loss: 3.827599314192875
Validation loss: 3.957832099167725

Epoch: 6| Step: 8
Training loss: 4.61540505331356
Validation loss: 3.9556713762556464

Epoch: 6| Step: 9
Training loss: 4.002710377813057
Validation loss: 3.9509126327763817

Epoch: 6| Step: 10
Training loss: 4.986010244347506
Validation loss: 3.945061450574631

Epoch: 6| Step: 11
Training loss: 3.1333043956096693
Validation loss: 3.934404447122914

Epoch: 6| Step: 12
Training loss: 3.0115051589610022
Validation loss: 3.9291852101082076

Epoch: 6| Step: 13
Training loss: 5.342164635421054
Validation loss: 3.9278990678783683

Epoch: 11| Step: 0
Training loss: 4.614479264692533
Validation loss: 3.9184548234912593

Epoch: 6| Step: 1
Training loss: 4.360081550465425
Validation loss: 3.910162932240136

Epoch: 6| Step: 2
Training loss: 3.2977831706059804
Validation loss: 3.909392757720866

Epoch: 6| Step: 3
Training loss: 4.600219115967955
Validation loss: 3.907405438574103

Epoch: 6| Step: 4
Training loss: 4.169092972357201
Validation loss: 3.9037851175521734

Epoch: 6| Step: 5
Training loss: 3.1305328217878525
Validation loss: 3.8942127622318483

Epoch: 6| Step: 6
Training loss: 3.86948740992289
Validation loss: 3.887532506471245

Epoch: 6| Step: 7
Training loss: 4.163641072717709
Validation loss: 3.882927683480297

Epoch: 6| Step: 8
Training loss: 4.715579957538362
Validation loss: 3.8797991947448294

Epoch: 6| Step: 9
Training loss: 3.5333855847028
Validation loss: 3.871301808178957

Epoch: 6| Step: 10
Training loss: 4.360685636873267
Validation loss: 3.8672207758501362

Epoch: 6| Step: 11
Training loss: 3.7044060016517144
Validation loss: 3.8685395062668793

Epoch: 6| Step: 12
Training loss: 3.4941624597557017
Validation loss: 3.859081076272525

Epoch: 6| Step: 13
Training loss: 4.492684245632786
Validation loss: 3.8545407092384405

Epoch: 12| Step: 0
Training loss: 4.319428117127683
Validation loss: 3.8513783424576147

Epoch: 6| Step: 1
Training loss: 4.06490407382444
Validation loss: 3.8477683576991377

Epoch: 6| Step: 2
Training loss: 4.383305540588998
Validation loss: 3.8438026243873193

Epoch: 6| Step: 3
Training loss: 3.849554997277346
Validation loss: 3.8356165277025513

Epoch: 6| Step: 4
Training loss: 3.7594148070906543
Validation loss: 3.833459950121991

Epoch: 6| Step: 5
Training loss: 4.675238683798751
Validation loss: 3.8300465318227563

Epoch: 6| Step: 6
Training loss: 4.003812641817342
Validation loss: 3.8241709174771876

Epoch: 6| Step: 7
Training loss: 3.07313140291265
Validation loss: 3.819704768214339

Epoch: 6| Step: 8
Training loss: 4.128682429112691
Validation loss: 3.8161276603343084

Epoch: 6| Step: 9
Training loss: 4.625967800847993
Validation loss: 3.809345711012813

Epoch: 6| Step: 10
Training loss: 3.423840380753878
Validation loss: 3.8054256504362964

Epoch: 6| Step: 11
Training loss: 4.040105983741427
Validation loss: 3.7998910330243154

Epoch: 6| Step: 12
Training loss: 3.848674565833839
Validation loss: 3.7971650942901993

Epoch: 6| Step: 13
Training loss: 2.846459910576991
Validation loss: 3.794047986600835

Epoch: 13| Step: 0
Training loss: 4.0389021762336075
Validation loss: 3.7933694170720953

Epoch: 6| Step: 1
Training loss: 3.648134794890322
Validation loss: 3.7881819190317136

Epoch: 6| Step: 2
Training loss: 4.032316081706404
Validation loss: 3.7864938252940603

Epoch: 6| Step: 3
Training loss: 4.680113809620028
Validation loss: 3.79220886347489

Epoch: 6| Step: 4
Training loss: 4.008313599430183
Validation loss: 3.7796853622618154

Epoch: 6| Step: 5
Training loss: 3.379586670562359
Validation loss: 3.7851951450913193

Epoch: 6| Step: 6
Training loss: 3.651929470780906
Validation loss: 3.79955800815468

Epoch: 6| Step: 7
Training loss: 3.5080163977140786
Validation loss: 3.77059834809318

Epoch: 6| Step: 8
Training loss: 3.754312324591364
Validation loss: 3.7758244657866693

Epoch: 6| Step: 9
Training loss: 3.7454202024580576
Validation loss: 3.7844945441659936

Epoch: 6| Step: 10
Training loss: 4.050955935089533
Validation loss: 3.7879748829410644

Epoch: 6| Step: 11
Training loss: 4.322769983706194
Validation loss: 3.779879432891402

Epoch: 6| Step: 12
Training loss: 4.74220921921509
Validation loss: 3.761095242732333

Epoch: 6| Step: 13
Training loss: 3.290460647289723
Validation loss: 3.750719486795697

Epoch: 14| Step: 0
Training loss: 4.607815339613719
Validation loss: 3.7501709683729922

Epoch: 6| Step: 1
Training loss: 4.236406015161078
Validation loss: 3.756534327912918

Epoch: 6| Step: 2
Training loss: 4.400482081966809
Validation loss: 3.758206969459857

Epoch: 6| Step: 3
Training loss: 3.7053510839836235
Validation loss: 3.749752758448486

Epoch: 6| Step: 4
Training loss: 3.613983778832178
Validation loss: 3.7445257174803466

Epoch: 6| Step: 5
Training loss: 4.590375218565122
Validation loss: 3.747785131548396

Epoch: 6| Step: 6
Training loss: 4.145840106492125
Validation loss: 3.7371473593169924

Epoch: 6| Step: 7
Training loss: 3.8723470158461795
Validation loss: 3.7262146269876895

Epoch: 6| Step: 8
Training loss: 3.9321174768262583
Validation loss: 3.7275832781275713

Epoch: 6| Step: 9
Training loss: 3.1161841591904125
Validation loss: 3.7286027179538954

Epoch: 6| Step: 10
Training loss: 3.716902073360182
Validation loss: 3.732193172037927

Epoch: 6| Step: 11
Training loss: 3.423803334818268
Validation loss: 3.7200053574383127

Epoch: 6| Step: 12
Training loss: 3.8348374663803795
Validation loss: 3.7178784330839245

Epoch: 6| Step: 13
Training loss: 2.8675127806374534
Validation loss: 3.716432245694633

Epoch: 15| Step: 0
Training loss: 3.936723178347008
Validation loss: 3.717147679110819

Epoch: 6| Step: 1
Training loss: 3.6176246065877886
Validation loss: 3.715841094389538

Epoch: 6| Step: 2
Training loss: 4.000722343072239
Validation loss: 3.7137015932078046

Epoch: 6| Step: 3
Training loss: 3.636576878190699
Validation loss: 3.7070827516211957

Epoch: 6| Step: 4
Training loss: 3.5170896742785085
Validation loss: 3.70123571798127

Epoch: 6| Step: 5
Training loss: 2.992669049350501
Validation loss: 3.6955537411806847

Epoch: 6| Step: 6
Training loss: 4.762299324673753
Validation loss: 3.6966167452357688

Epoch: 6| Step: 7
Training loss: 4.117894844806125
Validation loss: 3.6955298830475014

Epoch: 6| Step: 8
Training loss: 3.98849728827679
Validation loss: 3.6924241692527144

Epoch: 6| Step: 9
Training loss: 2.65937890165695
Validation loss: 3.6897524320422486

Epoch: 6| Step: 10
Training loss: 3.7976728943171825
Validation loss: 3.6838623564171806

Epoch: 6| Step: 11
Training loss: 3.8753858804841936
Validation loss: 3.6784708623375293

Epoch: 6| Step: 12
Training loss: 4.5622880442258715
Validation loss: 3.6743795852154313

Epoch: 6| Step: 13
Training loss: 4.727060036442817
Validation loss: 3.672236787579533

Epoch: 16| Step: 0
Training loss: 3.6687446399240153
Validation loss: 3.6712600196501852

Epoch: 6| Step: 1
Training loss: 3.0985320153299067
Validation loss: 3.6681698563995924

Epoch: 6| Step: 2
Training loss: 3.673829422929728
Validation loss: 3.6690498887033995

Epoch: 6| Step: 3
Training loss: 5.008813338463544
Validation loss: 3.6641914276250116

Epoch: 6| Step: 4
Training loss: 3.7364531923330837
Validation loss: 3.6618719345068262

Epoch: 6| Step: 5
Training loss: 3.916738482418841
Validation loss: 3.6588486505399036

Epoch: 6| Step: 6
Training loss: 3.848162591604063
Validation loss: 3.6561461361083327

Epoch: 6| Step: 7
Training loss: 3.555509836843394
Validation loss: 3.652672844204386

Epoch: 6| Step: 8
Training loss: 3.6370327626499814
Validation loss: 3.6507624578103

Epoch: 6| Step: 9
Training loss: 3.5193850606518122
Validation loss: 3.6492872162797454

Epoch: 6| Step: 10
Training loss: 3.4370494200433477
Validation loss: 3.6468922740482426

Epoch: 6| Step: 11
Training loss: 4.186471385734556
Validation loss: 3.646125312516568

Epoch: 6| Step: 12
Training loss: 4.068259045210316
Validation loss: 3.6429852425821023

Epoch: 6| Step: 13
Training loss: 4.428113869792381
Validation loss: 3.6412746457698026

Epoch: 17| Step: 0
Training loss: 3.510617772047885
Validation loss: 3.6374804962349123

Epoch: 6| Step: 1
Training loss: 3.9010017233392253
Validation loss: 3.6353201067779817

Epoch: 6| Step: 2
Training loss: 3.035678263859245
Validation loss: 3.6333583132865512

Epoch: 6| Step: 3
Training loss: 4.050118225632625
Validation loss: 3.6332556944770023

Epoch: 6| Step: 4
Training loss: 4.588401951071812
Validation loss: 3.6291039319178626

Epoch: 6| Step: 5
Training loss: 4.411834856859357
Validation loss: 3.6278313289296866

Epoch: 6| Step: 6
Training loss: 4.042511107854733
Validation loss: 3.6257762198103256

Epoch: 6| Step: 7
Training loss: 2.9607094548560853
Validation loss: 3.623272674868187

Epoch: 6| Step: 8
Training loss: 3.786856034428597
Validation loss: 3.620013980880405

Epoch: 6| Step: 9
Training loss: 3.7754840868863466
Validation loss: 3.619879532239909

Epoch: 6| Step: 10
Training loss: 3.229428549371106
Validation loss: 3.617079441254304

Epoch: 6| Step: 11
Training loss: 4.511247988494568
Validation loss: 3.616565202272947

Epoch: 6| Step: 12
Training loss: 3.620789944147701
Validation loss: 3.613446098276591

Epoch: 6| Step: 13
Training loss: 3.4915831040706786
Validation loss: 3.6109082341426455

Epoch: 18| Step: 0
Training loss: 3.9959765703280032
Validation loss: 3.6100202762344638

Epoch: 6| Step: 1
Training loss: 3.708152352249389
Validation loss: 3.6087297675133625

Epoch: 6| Step: 2
Training loss: 2.442330684357245
Validation loss: 3.6058026542029515

Epoch: 6| Step: 3
Training loss: 4.141908612210595
Validation loss: 3.604099989817311

Epoch: 6| Step: 4
Training loss: 4.567981927812572
Validation loss: 3.601699440339359

Epoch: 6| Step: 5
Training loss: 3.467335455523854
Validation loss: 3.5997063524993256

Epoch: 6| Step: 6
Training loss: 4.2024637716117175
Validation loss: 3.5971863969047346

Epoch: 6| Step: 7
Training loss: 3.720429498017566
Validation loss: 3.5953974360738377

Epoch: 6| Step: 8
Training loss: 2.9037982073890465
Validation loss: 3.5918391971982837

Epoch: 6| Step: 9
Training loss: 3.0154553301422817
Validation loss: 3.5922089156662738

Epoch: 6| Step: 10
Training loss: 4.301994686121653
Validation loss: 3.5898456238952834

Epoch: 6| Step: 11
Training loss: 4.238602108390448
Validation loss: 3.5894492104149784

Epoch: 6| Step: 12
Training loss: 3.810132151236712
Validation loss: 3.5878167179709592

Epoch: 6| Step: 13
Training loss: 4.214354987879781
Validation loss: 3.5857644463504452

Epoch: 19| Step: 0
Training loss: 4.620636815030588
Validation loss: 3.5862490464389327

Epoch: 6| Step: 1
Training loss: 3.660654919505151
Validation loss: 3.5853716086770735

Epoch: 6| Step: 2
Training loss: 2.850315437930182
Validation loss: 3.583243077499126

Epoch: 6| Step: 3
Training loss: 3.527041873286384
Validation loss: 3.5788134413998596

Epoch: 6| Step: 4
Training loss: 4.2530035737339045
Validation loss: 3.578092875938512

Epoch: 6| Step: 5
Training loss: 3.1238434749568156
Validation loss: 3.5757111347859207

Epoch: 6| Step: 6
Training loss: 3.722710816182591
Validation loss: 3.5759061898123523

Epoch: 6| Step: 7
Training loss: 4.0950273457453665
Validation loss: 3.5729978885756615

Epoch: 6| Step: 8
Training loss: 4.325883966858862
Validation loss: 3.5726177863456106

Epoch: 6| Step: 9
Training loss: 3.6217376235304912
Validation loss: 3.570918461719448

Epoch: 6| Step: 10
Training loss: 3.76029698964289
Validation loss: 3.568145656646498

Epoch: 6| Step: 11
Training loss: 4.162995106804396
Validation loss: 3.5678252074437746

Epoch: 6| Step: 12
Training loss: 3.061163474402601
Validation loss: 3.5659475205496802

Epoch: 6| Step: 13
Training loss: 3.588236551735197
Validation loss: 3.5642501671233253

Epoch: 20| Step: 0
Training loss: 3.172127248571206
Validation loss: 3.5632957141226154

Epoch: 6| Step: 1
Training loss: 4.230022826076812
Validation loss: 3.5608198013713395

Epoch: 6| Step: 2
Training loss: 3.113535488952518
Validation loss: 3.559754347504644

Epoch: 6| Step: 3
Training loss: 3.967711064878635
Validation loss: 3.5583074496474483

Epoch: 6| Step: 4
Training loss: 4.002963875380049
Validation loss: 3.559122185037305

Epoch: 6| Step: 5
Training loss: 3.6699477312071465
Validation loss: 3.556187090740902

Epoch: 6| Step: 6
Training loss: 3.9047111226588855
Validation loss: 3.553787047079544

Epoch: 6| Step: 7
Training loss: 4.222004179315925
Validation loss: 3.553660170904011

Epoch: 6| Step: 8
Training loss: 2.7879332064668807
Validation loss: 3.550666825197933

Epoch: 6| Step: 9
Training loss: 3.9646192064264296
Validation loss: 3.5495827061741996

Epoch: 6| Step: 10
Training loss: 2.8483681541116526
Validation loss: 3.5485100290905662

Epoch: 6| Step: 11
Training loss: 4.462546143707289
Validation loss: 3.5465418597860325

Epoch: 6| Step: 12
Training loss: 3.7122657727678354
Validation loss: 3.5459938055131173

Epoch: 6| Step: 13
Training loss: 4.323764408437163
Validation loss: 3.542702577053445

Epoch: 21| Step: 0
Training loss: 4.052941212718842
Validation loss: 3.5425422445117003

Epoch: 6| Step: 1
Training loss: 2.7198501641011648
Validation loss: 3.5382075727826905

Epoch: 6| Step: 2
Training loss: 4.416462635629793
Validation loss: 3.538259049436878

Epoch: 6| Step: 3
Training loss: 3.6594049910204887
Validation loss: 3.535855487170383

Epoch: 6| Step: 4
Training loss: 4.132607121403273
Validation loss: 3.5346900996557413

Epoch: 6| Step: 5
Training loss: 3.0216551265787253
Validation loss: 3.534223195094072

Epoch: 6| Step: 6
Training loss: 3.432614825968249
Validation loss: 3.532922120717584

Epoch: 6| Step: 7
Training loss: 3.424154837253611
Validation loss: 3.5310237201104413

Epoch: 6| Step: 8
Training loss: 3.365308055635646
Validation loss: 3.5298442011556213

Epoch: 6| Step: 9
Training loss: 3.376397302797449
Validation loss: 3.5280753633972775

Epoch: 6| Step: 10
Training loss: 4.170355016292265
Validation loss: 3.526665450968489

Epoch: 6| Step: 11
Training loss: 4.431676347503666
Validation loss: 3.5258442233964944

Epoch: 6| Step: 12
Training loss: 3.9058389676325187
Validation loss: 3.5228158988073193

Epoch: 6| Step: 13
Training loss: 3.878107855034246
Validation loss: 3.5207585220461484

Epoch: 22| Step: 0
Training loss: 3.595946594316952
Validation loss: 3.5198677230570508

Epoch: 6| Step: 1
Training loss: 3.2027674033430826
Validation loss: 3.5194080135403465

Epoch: 6| Step: 2
Training loss: 3.540149243974991
Validation loss: 3.5179617167813517

Epoch: 6| Step: 3
Training loss: 3.6325588999184792
Validation loss: 3.5170646186486385

Epoch: 6| Step: 4
Training loss: 3.1324115601253353
Validation loss: 3.515393220651196

Epoch: 6| Step: 5
Training loss: 3.6436869960984724
Validation loss: 3.5136457385024356

Epoch: 6| Step: 6
Training loss: 2.4970667797626067
Validation loss: 3.5125785464141472

Epoch: 6| Step: 7
Training loss: 3.828883255580311
Validation loss: 3.5115775312261723

Epoch: 6| Step: 8
Training loss: 4.0254948661296694
Validation loss: 3.50924952606354

Epoch: 6| Step: 9
Training loss: 4.061697543192138
Validation loss: 3.507491215003648

Epoch: 6| Step: 10
Training loss: 4.360279932747317
Validation loss: 3.5053427301923246

Epoch: 6| Step: 11
Training loss: 4.357964619101202
Validation loss: 3.5038819985730187

Epoch: 6| Step: 12
Training loss: 4.088222120233943
Validation loss: 3.5018897294737537

Epoch: 6| Step: 13
Training loss: 3.7331715963161276
Validation loss: 3.5003945411004653

Epoch: 23| Step: 0
Training loss: 3.133641920382842
Validation loss: 3.4970438642538006

Epoch: 6| Step: 1
Training loss: 4.2956701080560284
Validation loss: 3.4948845953028442

Epoch: 6| Step: 2
Training loss: 4.378164836040663
Validation loss: 3.4926887066828383

Epoch: 6| Step: 3
Training loss: 3.7917161595953517
Validation loss: 3.4927753413371465

Epoch: 6| Step: 4
Training loss: 3.240571209747117
Validation loss: 3.49153973404023

Epoch: 6| Step: 5
Training loss: 3.758543328101826
Validation loss: 3.4916295147224563

Epoch: 6| Step: 6
Training loss: 3.628600338626516
Validation loss: 3.491027621794514

Epoch: 6| Step: 7
Training loss: 3.8266900311951884
Validation loss: 3.491948206562755

Epoch: 6| Step: 8
Training loss: 3.6403297664793803
Validation loss: 3.4888778617462894

Epoch: 6| Step: 9
Training loss: 3.4011444185322226
Validation loss: 3.4904988723232875

Epoch: 6| Step: 10
Training loss: 3.7273956583054995
Validation loss: 3.4864789990386003

Epoch: 6| Step: 11
Training loss: 3.6025180169739706
Validation loss: 3.482651236164581

Epoch: 6| Step: 12
Training loss: 3.3740552356949505
Validation loss: 3.481662015768129

Epoch: 6| Step: 13
Training loss: 4.007974543279335
Validation loss: 3.5025625941031913

Epoch: 24| Step: 0
Training loss: 3.214762022664465
Validation loss: 3.4774079225275263

Epoch: 6| Step: 1
Training loss: 4.639373507791737
Validation loss: 3.481919496742269

Epoch: 6| Step: 2
Training loss: 4.252522112897088
Validation loss: 3.494702136923058

Epoch: 6| Step: 3
Training loss: 4.0094578509195955
Validation loss: 3.492994314146007

Epoch: 6| Step: 4
Training loss: 3.395136069266298
Validation loss: 3.4841548526952115

Epoch: 6| Step: 5
Training loss: 3.912887305446518
Validation loss: 3.476749362696094

Epoch: 6| Step: 6
Training loss: 3.16149345935662
Validation loss: 3.476078333686437

Epoch: 6| Step: 7
Training loss: 3.046259891335853
Validation loss: 3.475082566572985

Epoch: 6| Step: 8
Training loss: 3.3374217392107406
Validation loss: 3.4744202382284506

Epoch: 6| Step: 9
Training loss: 3.674559435743823
Validation loss: 3.4753966325783487

Epoch: 6| Step: 10
Training loss: 4.010687378833262
Validation loss: 3.4767544977168674

Epoch: 6| Step: 11
Training loss: 3.492295368073298
Validation loss: 3.47402734760637

Epoch: 6| Step: 12
Training loss: 3.3024575936932314
Validation loss: 3.472201413546869

Epoch: 6| Step: 13
Training loss: 4.086307662038909
Validation loss: 3.4705504800157274

Epoch: 25| Step: 0
Training loss: 3.373790100243779
Validation loss: 3.468992024360931

Epoch: 6| Step: 1
Training loss: 3.0693510069129752
Validation loss: 3.4671362031396087

Epoch: 6| Step: 2
Training loss: 2.091658957215143
Validation loss: 3.4650388948183326

Epoch: 6| Step: 3
Training loss: 3.5771264427814797
Validation loss: 3.4657088642264253

Epoch: 6| Step: 4
Training loss: 3.7982926096678264
Validation loss: 3.464082210728417

Epoch: 6| Step: 5
Training loss: 3.407730340819917
Validation loss: 3.462574770901863

Epoch: 6| Step: 6
Training loss: 4.72721901109494
Validation loss: 3.460844019349097

Epoch: 6| Step: 7
Training loss: 4.596135149556449
Validation loss: 3.460156111717835

Epoch: 6| Step: 8
Training loss: 3.0459364790526786
Validation loss: 3.459364912267354

Epoch: 6| Step: 9
Training loss: 3.6912592459981717
Validation loss: 3.4589503158343593

Epoch: 6| Step: 10
Training loss: 3.9560648123019044
Validation loss: 3.4581668490977147

Epoch: 6| Step: 11
Training loss: 3.6617249798258826
Validation loss: 3.4574181914581446

Epoch: 6| Step: 12
Training loss: 3.851025402697531
Validation loss: 3.4565557682281938

Epoch: 6| Step: 13
Training loss: 4.1266559398144
Validation loss: 3.4554291287880874

Epoch: 26| Step: 0
Training loss: 4.11347391486994
Validation loss: 3.45542865767094

Epoch: 6| Step: 1
Training loss: 4.255591809079886
Validation loss: 3.4541514574024785

Epoch: 6| Step: 2
Training loss: 3.4094209522818386
Validation loss: 3.4542006257317057

Epoch: 6| Step: 3
Training loss: 4.223272767348996
Validation loss: 3.452834416716635

Epoch: 6| Step: 4
Training loss: 3.5852615284461407
Validation loss: 3.450359147923976

Epoch: 6| Step: 5
Training loss: 3.6477792542242504
Validation loss: 3.4498915107888553

Epoch: 6| Step: 6
Training loss: 3.8765336970066855
Validation loss: 3.4495829379021195

Epoch: 6| Step: 7
Training loss: 3.9408754685111513
Validation loss: 3.4484449239124273

Epoch: 6| Step: 8
Training loss: 2.077211910797061
Validation loss: 3.4482700196702183

Epoch: 6| Step: 9
Training loss: 3.9478734533248145
Validation loss: 3.4482769799080386

Epoch: 6| Step: 10
Training loss: 3.208005731544226
Validation loss: 3.446502885434521

Epoch: 6| Step: 11
Training loss: 2.923888466415586
Validation loss: 3.4459971930514834

Epoch: 6| Step: 12
Training loss: 3.8971729253392846
Validation loss: 3.4454787849035045

Epoch: 6| Step: 13
Training loss: 3.733200463133076
Validation loss: 3.445529213899594

Epoch: 27| Step: 0
Training loss: 3.2423669236874266
Validation loss: 3.44442844607682

Epoch: 6| Step: 1
Training loss: 3.6541695177566615
Validation loss: 3.444252360574342

Epoch: 6| Step: 2
Training loss: 2.9012685763492865
Validation loss: 3.4435818474517075

Epoch: 6| Step: 3
Training loss: 3.167311067433728
Validation loss: 3.442211736662149

Epoch: 6| Step: 4
Training loss: 4.1753260593666655
Validation loss: 3.44171293849738

Epoch: 6| Step: 5
Training loss: 2.057260968586896
Validation loss: 3.4411088884546346

Epoch: 6| Step: 6
Training loss: 3.9341930247332013
Validation loss: 3.4404307441243733

Epoch: 6| Step: 7
Training loss: 3.866318853673541
Validation loss: 3.440478865643658

Epoch: 6| Step: 8
Training loss: 4.009203336732083
Validation loss: 3.4397493403172907

Epoch: 6| Step: 9
Training loss: 4.668314620097055
Validation loss: 3.4387776645123096

Epoch: 6| Step: 10
Training loss: 3.045142517512987
Validation loss: 3.438413920246367

Epoch: 6| Step: 11
Training loss: 3.6549214614800416
Validation loss: 3.4368058996391757

Epoch: 6| Step: 12
Training loss: 3.96859584719231
Validation loss: 3.4368832240891978

Epoch: 6| Step: 13
Training loss: 4.507302187590034
Validation loss: 3.436898512435694

Epoch: 28| Step: 0
Training loss: 2.732744788175622
Validation loss: 3.4357174246042943

Epoch: 6| Step: 1
Training loss: 2.977753968958147
Validation loss: 3.434799619279684

Epoch: 6| Step: 2
Training loss: 3.8913421582693815
Validation loss: 3.4344099339052443

Epoch: 6| Step: 3
Training loss: 3.711030015294145
Validation loss: 3.4333977841274432

Epoch: 6| Step: 4
Training loss: 3.892284973712659
Validation loss: 3.433180271595355

Epoch: 6| Step: 5
Training loss: 3.230954633011143
Validation loss: 3.4321960324355665

Epoch: 6| Step: 6
Training loss: 4.048642748183271
Validation loss: 3.431744127075316

Epoch: 6| Step: 7
Training loss: 4.1178462100554425
Validation loss: 3.4313011188488374

Epoch: 6| Step: 8
Training loss: 4.782320987204665
Validation loss: 3.4304321580955164

Epoch: 6| Step: 9
Training loss: 3.2153236893043835
Validation loss: 3.4298712837460883

Epoch: 6| Step: 10
Training loss: 3.4726738258835312
Validation loss: 3.428159191356571

Epoch: 6| Step: 11
Training loss: 3.8766879435442174
Validation loss: 3.4275486277378397

Epoch: 6| Step: 12
Training loss: 2.89926061741361
Validation loss: 3.4271104010325835

Epoch: 6| Step: 13
Training loss: 3.878658659409954
Validation loss: 3.426733263462763

Epoch: 29| Step: 0
Training loss: 3.5089869243022718
Validation loss: 3.4261068780848514

Epoch: 6| Step: 1
Training loss: 3.186057568467626
Validation loss: 3.425686895313083

Epoch: 6| Step: 2
Training loss: 4.582663099817156
Validation loss: 3.4248381475618355

Epoch: 6| Step: 3
Training loss: 3.8502390601510057
Validation loss: 3.4239565806119487

Epoch: 6| Step: 4
Training loss: 3.000355699433005
Validation loss: 3.4238702681965143

Epoch: 6| Step: 5
Training loss: 3.5872933145457955
Validation loss: 3.4227619835549006

Epoch: 6| Step: 6
Training loss: 3.6691254405809377
Validation loss: 3.4220791606577206

Epoch: 6| Step: 7
Training loss: 3.677313879348421
Validation loss: 3.4218715866805303

Epoch: 6| Step: 8
Training loss: 3.0945399653334418
Validation loss: 3.4207522687994056

Epoch: 6| Step: 9
Training loss: 3.717031129720536
Validation loss: 3.420732467099779

Epoch: 6| Step: 10
Training loss: 3.631323330741185
Validation loss: 3.420296700265712

Epoch: 6| Step: 11
Training loss: 3.222625325372457
Validation loss: 3.419142689293779

Epoch: 6| Step: 12
Training loss: 3.6919375082742723
Validation loss: 3.418833249506962

Epoch: 6| Step: 13
Training loss: 4.7805322843925175
Validation loss: 3.418539391388847

Epoch: 30| Step: 0
Training loss: 3.3479173306977033
Validation loss: 3.4174264162669807

Epoch: 6| Step: 1
Training loss: 3.3509227791281146
Validation loss: 3.417668504597876

Epoch: 6| Step: 2
Training loss: 4.056397064787519
Validation loss: 3.416114892882595

Epoch: 6| Step: 3
Training loss: 3.147172621713696
Validation loss: 3.4159468100828616

Epoch: 6| Step: 4
Training loss: 4.592485526305572
Validation loss: 3.4148717487945115

Epoch: 6| Step: 5
Training loss: 3.975308023670196
Validation loss: 3.415346107024628

Epoch: 6| Step: 6
Training loss: 2.952908947019811
Validation loss: 3.414373748439028

Epoch: 6| Step: 7
Training loss: 3.135606390365783
Validation loss: 3.4135106805312536

Epoch: 6| Step: 8
Training loss: 2.8427055033642548
Validation loss: 3.4138597793486376

Epoch: 6| Step: 9
Training loss: 3.886440861414837
Validation loss: 3.412438432283151

Epoch: 6| Step: 10
Training loss: 4.207357438245434
Validation loss: 3.412885473933928

Epoch: 6| Step: 11
Training loss: 3.665098649762076
Validation loss: 3.4120750057125693

Epoch: 6| Step: 12
Training loss: 4.01755628640151
Validation loss: 3.4116959799128073

Epoch: 6| Step: 13
Training loss: 3.0509650532819377
Validation loss: 3.4097319898426526

Epoch: 31| Step: 0
Training loss: 3.517694703266704
Validation loss: 3.4102817295195265

Epoch: 6| Step: 1
Training loss: 2.5755250710252255
Validation loss: 3.4091933976022437

Epoch: 6| Step: 2
Training loss: 3.062345851210597
Validation loss: 3.4094795871587076

Epoch: 6| Step: 3
Training loss: 3.705419931848196
Validation loss: 3.408468351425963

Epoch: 6| Step: 4
Training loss: 3.7922400296050185
Validation loss: 3.40824239247317

Epoch: 6| Step: 5
Training loss: 3.2599136565774014
Validation loss: 3.407238847872887

Epoch: 6| Step: 6
Training loss: 3.7566525261067594
Validation loss: 3.4073191140279406

Epoch: 6| Step: 7
Training loss: 3.5427614801210225
Validation loss: 3.4065949302142235

Epoch: 6| Step: 8
Training loss: 3.3844875214840213
Validation loss: 3.404790188602627

Epoch: 6| Step: 9
Training loss: 4.167603095048919
Validation loss: 3.405149018675344

Epoch: 6| Step: 10
Training loss: 4.149985963728734
Validation loss: 3.4049917536785914

Epoch: 6| Step: 11
Training loss: 4.42131810000763
Validation loss: 3.4049632650809136

Epoch: 6| Step: 12
Training loss: 4.043091879918498
Validation loss: 3.4031550908854222

Epoch: 6| Step: 13
Training loss: 2.514534091757039
Validation loss: 3.4026978994345467

Epoch: 32| Step: 0
Training loss: 3.3387056608979933
Validation loss: 3.4050324555640756

Epoch: 6| Step: 1
Training loss: 4.043274916698338
Validation loss: 3.411407666212498

Epoch: 6| Step: 2
Training loss: 3.3370059444201927
Validation loss: 3.4022731545514953

Epoch: 6| Step: 3
Training loss: 3.5122751510168158
Validation loss: 3.4013621210651706

Epoch: 6| Step: 4
Training loss: 3.944491884605946
Validation loss: 3.4004629000379074

Epoch: 6| Step: 5
Training loss: 3.6272401136373618
Validation loss: 3.3999768817943257

Epoch: 6| Step: 6
Training loss: 4.0425519203149864
Validation loss: 3.4025972079149795

Epoch: 6| Step: 7
Training loss: 3.508093603888382
Validation loss: 3.40328039464661

Epoch: 6| Step: 8
Training loss: 3.3877264193494727
Validation loss: 3.4035759264701486

Epoch: 6| Step: 9
Training loss: 2.8136021467871526
Validation loss: 3.4000101865655648

Epoch: 6| Step: 10
Training loss: 3.5457449974116755
Validation loss: 3.3983799811768987

Epoch: 6| Step: 11
Training loss: 4.494480775032171
Validation loss: 3.3973517773517585

Epoch: 6| Step: 12
Training loss: 2.9364154517994225
Validation loss: 3.397485951584276

Epoch: 6| Step: 13
Training loss: 4.174682815289848
Validation loss: 3.39696820021588

Epoch: 33| Step: 0
Training loss: 3.8051396596695164
Validation loss: 3.396634318750907

Epoch: 6| Step: 1
Training loss: 3.87055073922334
Validation loss: 3.3973894588334588

Epoch: 6| Step: 2
Training loss: 4.078745827609894
Validation loss: 3.404719735741952

Epoch: 6| Step: 3
Training loss: 4.249258313255215
Validation loss: 3.40273216076906

Epoch: 6| Step: 4
Training loss: 3.6461349507863394
Validation loss: 3.395875624144146

Epoch: 6| Step: 5
Training loss: 3.2780935455064153
Validation loss: 3.3964387308865325

Epoch: 6| Step: 6
Training loss: 3.853747137107615
Validation loss: 3.393422115059089

Epoch: 6| Step: 7
Training loss: 3.8492323072878767
Validation loss: 3.3927654248871786

Epoch: 6| Step: 8
Training loss: 3.5447534610476614
Validation loss: 3.3923269413791544

Epoch: 6| Step: 9
Training loss: 3.196267729028637
Validation loss: 3.390421957740767

Epoch: 6| Step: 10
Training loss: 3.356376978001284
Validation loss: 3.3900405745310986

Epoch: 6| Step: 11
Training loss: 3.8704011761421095
Validation loss: 3.389449294013341

Epoch: 6| Step: 12
Training loss: 2.7706458427459277
Validation loss: 3.3902131517553764

Epoch: 6| Step: 13
Training loss: 2.5244986839056787
Validation loss: 3.390722117727977

Epoch: 34| Step: 0
Training loss: 3.996395394284822
Validation loss: 3.393323929274804

Epoch: 6| Step: 1
Training loss: 2.8736124422088616
Validation loss: 3.389348028126036

Epoch: 6| Step: 2
Training loss: 2.8825830714620166
Validation loss: 3.386856193075086

Epoch: 6| Step: 3
Training loss: 4.566448854324348
Validation loss: 3.387362789781846

Epoch: 6| Step: 4
Training loss: 3.5279301254203763
Validation loss: 3.387789584157506

Epoch: 6| Step: 5
Training loss: 2.9920796108466168
Validation loss: 3.3879843501621

Epoch: 6| Step: 6
Training loss: 4.065427224394221
Validation loss: 3.3854707219783347

Epoch: 6| Step: 7
Training loss: 2.724217496739836
Validation loss: 3.3848672976084986

Epoch: 6| Step: 8
Training loss: 4.335331065065918
Validation loss: 3.384185601008867

Epoch: 6| Step: 9
Training loss: 3.581319657159267
Validation loss: 3.3845257324937053

Epoch: 6| Step: 10
Training loss: 3.3012013184996265
Validation loss: 3.3862087704460837

Epoch: 6| Step: 11
Training loss: 3.235364974362859
Validation loss: 3.387631897715353

Epoch: 6| Step: 12
Training loss: 3.966823921505838
Validation loss: 3.388704858146379

Epoch: 6| Step: 13
Training loss: 4.283174625133181
Validation loss: 3.385876912651787

Epoch: 35| Step: 0
Training loss: 4.042784519881605
Validation loss: 3.382310493341778

Epoch: 6| Step: 1
Training loss: 3.610403071379924
Validation loss: 3.3809405995433544

Epoch: 6| Step: 2
Training loss: 3.3041045123328
Validation loss: 3.384225697123852

Epoch: 6| Step: 3
Training loss: 3.745061037918391
Validation loss: 3.380135686134712

Epoch: 6| Step: 4
Training loss: 3.5616786076784823
Validation loss: 3.382455575028543

Epoch: 6| Step: 5
Training loss: 3.0493848586817345
Validation loss: 3.383761325762693

Epoch: 6| Step: 6
Training loss: 3.5789049123159065
Validation loss: 3.3867684718916244

Epoch: 6| Step: 7
Training loss: 3.138278065291202
Validation loss: 3.3866316475009257

Epoch: 6| Step: 8
Training loss: 3.16153961194471
Validation loss: 3.389040803746007

Epoch: 6| Step: 9
Training loss: 3.7526108871636272
Validation loss: 3.3813534953009685

Epoch: 6| Step: 10
Training loss: 3.5098472759787995
Validation loss: 3.3785802430337752

Epoch: 6| Step: 11
Training loss: 4.197578258773193
Validation loss: 3.378714115622594

Epoch: 6| Step: 12
Training loss: 3.9045838731903713
Validation loss: 3.3758277622374915

Epoch: 6| Step: 13
Training loss: 3.9421664243082586
Validation loss: 3.3754038081116926

Epoch: 36| Step: 0
Training loss: 3.080110480816499
Validation loss: 3.3747193171537044

Epoch: 6| Step: 1
Training loss: 3.8382762608417096
Validation loss: 3.373999977306282

Epoch: 6| Step: 2
Training loss: 4.311673734816656
Validation loss: 3.373813680435737

Epoch: 6| Step: 3
Training loss: 3.8792505639684216
Validation loss: 3.3746960410786957

Epoch: 6| Step: 4
Training loss: 3.945716036564052
Validation loss: 3.3728924790577652

Epoch: 6| Step: 5
Training loss: 2.966326557623075
Validation loss: 3.371578779537788

Epoch: 6| Step: 6
Training loss: 3.3978630194218957
Validation loss: 3.371382767696075

Epoch: 6| Step: 7
Training loss: 3.7274690880827306
Validation loss: 3.3707778610223627

Epoch: 6| Step: 8
Training loss: 3.620574354268278
Validation loss: 3.3711577557338543

Epoch: 6| Step: 9
Training loss: 3.4651605403199475
Validation loss: 3.3706946323928144

Epoch: 6| Step: 10
Training loss: 2.8733475953682657
Validation loss: 3.3690509708954357

Epoch: 6| Step: 11
Training loss: 3.5064421358010733
Validation loss: 3.369136762576678

Epoch: 6| Step: 12
Training loss: 3.840774749245063
Validation loss: 3.3686806565569754

Epoch: 6| Step: 13
Training loss: 3.830426828091586
Validation loss: 3.3678057357875644

Epoch: 37| Step: 0
Training loss: 2.9706803320336967
Validation loss: 3.367831641522455

Epoch: 6| Step: 1
Training loss: 3.440263642920451
Validation loss: 3.3681810160648333

Epoch: 6| Step: 2
Training loss: 3.490545582358783
Validation loss: 3.365174496868437

Epoch: 6| Step: 3
Training loss: 4.130454416468416
Validation loss: 3.3662854618972355

Epoch: 6| Step: 4
Training loss: 3.5329138962688726
Validation loss: 3.365887480241043

Epoch: 6| Step: 5
Training loss: 3.3421732669935658
Validation loss: 3.3664976283665116

Epoch: 6| Step: 6
Training loss: 4.315617857864293
Validation loss: 3.365864450801144

Epoch: 6| Step: 7
Training loss: 3.870656686508693
Validation loss: 3.3698055532493627

Epoch: 6| Step: 8
Training loss: 3.8622534515801994
Validation loss: 3.3650952214587746

Epoch: 6| Step: 9
Training loss: 3.8982612401834116
Validation loss: 3.364228314474106

Epoch: 6| Step: 10
Training loss: 3.293619727321769
Validation loss: 3.3639959751401274

Epoch: 6| Step: 11
Training loss: 2.924653389763708
Validation loss: 3.3644859010062937

Epoch: 6| Step: 12
Training loss: 3.4806312326165525
Validation loss: 3.3637045355166695

Epoch: 6| Step: 13
Training loss: 3.5464435600674165
Validation loss: 3.3639670486709248

Epoch: 38| Step: 0
Training loss: 3.3843786125128603
Validation loss: 3.365913728248328

Epoch: 6| Step: 1
Training loss: 3.7817299278171945
Validation loss: 3.3613932410440124

Epoch: 6| Step: 2
Training loss: 3.8751533231858377
Validation loss: 3.3632418631022847

Epoch: 6| Step: 3
Training loss: 4.214112848611209
Validation loss: 3.3616214842573506

Epoch: 6| Step: 4
Training loss: 3.7082615248910513
Validation loss: 3.3590237143120203

Epoch: 6| Step: 5
Training loss: 2.534785685913257
Validation loss: 3.3597597711235663

Epoch: 6| Step: 6
Training loss: 3.284707708956212
Validation loss: 3.3582668772885866

Epoch: 6| Step: 7
Training loss: 3.649501473857824
Validation loss: 3.3585771441683336

Epoch: 6| Step: 8
Training loss: 4.344298842630653
Validation loss: 3.3567733500518386

Epoch: 6| Step: 9
Training loss: 2.2711436441699617
Validation loss: 3.3589075028876687

Epoch: 6| Step: 10
Training loss: 4.203726913293471
Validation loss: 3.3577407482854595

Epoch: 6| Step: 11
Training loss: 3.511295348241587
Validation loss: 3.3576804952478456

Epoch: 6| Step: 12
Training loss: 3.844180695509326
Validation loss: 3.3564607029609084

Epoch: 6| Step: 13
Training loss: 2.5628245078443848
Validation loss: 3.35714610115189

Epoch: 39| Step: 0
Training loss: 2.799879963890385
Validation loss: 3.356569740254935

Epoch: 6| Step: 1
Training loss: 3.184612986288369
Validation loss: 3.3570744735376308

Epoch: 6| Step: 2
Training loss: 3.485911761727034
Validation loss: 3.3557986110539795

Epoch: 6| Step: 3
Training loss: 3.9454476210617715
Validation loss: 3.355830323727935

Epoch: 6| Step: 4
Training loss: 3.2349413684561013
Validation loss: 3.3540012107604937

Epoch: 6| Step: 5
Training loss: 4.107764795257778
Validation loss: 3.353696880537468

Epoch: 6| Step: 6
Training loss: 4.2771134266613
Validation loss: 3.354013049037702

Epoch: 6| Step: 7
Training loss: 3.9880476237737312
Validation loss: 3.353548313304326

Epoch: 6| Step: 8
Training loss: 2.773683005199058
Validation loss: 3.3531525784019625

Epoch: 6| Step: 9
Training loss: 3.4386583630670007
Validation loss: 3.351673920925846

Epoch: 6| Step: 10
Training loss: 4.310178712472055
Validation loss: 3.3514772803944006

Epoch: 6| Step: 11
Training loss: 3.120208270873194
Validation loss: 3.350583470713412

Epoch: 6| Step: 12
Training loss: 2.798339119549832
Validation loss: 3.3489009608769345

Epoch: 6| Step: 13
Training loss: 4.5522251179813455
Validation loss: 3.350894351089306

Epoch: 40| Step: 0
Training loss: 3.220844365175476
Validation loss: 3.3503474144008027

Epoch: 6| Step: 1
Training loss: 3.4361380913621846
Validation loss: 3.349816410934002

Epoch: 6| Step: 2
Training loss: 4.3746797716928265
Validation loss: 3.351056344379734

Epoch: 6| Step: 3
Training loss: 3.0962696026461436
Validation loss: 3.3478204522231048

Epoch: 6| Step: 4
Training loss: 3.362571721216109
Validation loss: 3.3491774082781376

Epoch: 6| Step: 5
Training loss: 3.6020870199160724
Validation loss: 3.3514363228101876

Epoch: 6| Step: 6
Training loss: 3.7730854257173587
Validation loss: 3.3456619273855557

Epoch: 6| Step: 7
Training loss: 2.658011716163825
Validation loss: 3.3450512566454456

Epoch: 6| Step: 8
Training loss: 4.066124341062681
Validation loss: 3.344462835005837

Epoch: 6| Step: 9
Training loss: 3.7402221360765813
Validation loss: 3.3447507292878407

Epoch: 6| Step: 10
Training loss: 3.885408880449254
Validation loss: 3.343674465764235

Epoch: 6| Step: 11
Training loss: 3.40835296388925
Validation loss: 3.344724061499585

Epoch: 6| Step: 12
Training loss: 4.05867152648949
Validation loss: 3.3436353554755502

Epoch: 6| Step: 13
Training loss: 2.5894584541766608
Validation loss: 3.343364613247373

Epoch: 41| Step: 0
Training loss: 3.4454680600156333
Validation loss: 3.343891753001098

Epoch: 6| Step: 1
Training loss: 3.9013613207872035
Validation loss: 3.3450058625831427

Epoch: 6| Step: 2
Training loss: 3.8131868337842696
Validation loss: 3.343315678227021

Epoch: 6| Step: 3
Training loss: 3.7721286185899796
Validation loss: 3.3410690994869117

Epoch: 6| Step: 4
Training loss: 3.0403968215747104
Validation loss: 3.3404434518677357

Epoch: 6| Step: 5
Training loss: 3.911515616019918
Validation loss: 3.339566175306593

Epoch: 6| Step: 6
Training loss: 3.305865715784345
Validation loss: 3.3379216906236344

Epoch: 6| Step: 7
Training loss: 2.8905164543598096
Validation loss: 3.339502568194903

Epoch: 6| Step: 8
Training loss: 2.7556745763252724
Validation loss: 3.3391047985962077

Epoch: 6| Step: 9
Training loss: 4.061855793273755
Validation loss: 3.339233239780614

Epoch: 6| Step: 10
Training loss: 3.6335221448595934
Validation loss: 3.3377846365750767

Epoch: 6| Step: 11
Training loss: 3.654428403231578
Validation loss: 3.337719456277504

Epoch: 6| Step: 12
Training loss: 3.665539019032375
Validation loss: 3.337155455522278

Epoch: 6| Step: 13
Training loss: 4.17180824940747
Validation loss: 3.337159011570636

Epoch: 42| Step: 0
Training loss: 3.6470437501961404
Validation loss: 3.336558378990173

Epoch: 6| Step: 1
Training loss: 3.504103843195359
Validation loss: 3.3367237573613173

Epoch: 6| Step: 2
Training loss: 4.410162088611614
Validation loss: 3.3356056717891387

Epoch: 6| Step: 3
Training loss: 3.3425349229287846
Validation loss: 3.3377180015307872

Epoch: 6| Step: 4
Training loss: 3.322101568783379
Validation loss: 3.350090595722912

Epoch: 6| Step: 5
Training loss: 2.7303681580183126
Validation loss: 3.347519306550327

Epoch: 6| Step: 6
Training loss: 3.948770288196115
Validation loss: 3.3335501651586155

Epoch: 6| Step: 7
Training loss: 3.2503116164835713
Validation loss: 3.3333647623939004

Epoch: 6| Step: 8
Training loss: 3.12376226708979
Validation loss: 3.3320750466241953

Epoch: 6| Step: 9
Training loss: 3.7247857870682846
Validation loss: 3.333273563054228

Epoch: 6| Step: 10
Training loss: 3.3055000478605727
Validation loss: 3.331579444265247

Epoch: 6| Step: 11
Training loss: 4.0899498460301436
Validation loss: 3.335775244378959

Epoch: 6| Step: 12
Training loss: 3.34066002223442
Validation loss: 3.3349136410922844

Epoch: 6| Step: 13
Training loss: 4.202189628581812
Validation loss: 3.3319750746241192

Epoch: 43| Step: 0
Training loss: 4.103885595827761
Validation loss: 3.329686759507899

Epoch: 6| Step: 1
Training loss: 3.3712960157128777
Validation loss: 3.3291227439730395

Epoch: 6| Step: 2
Training loss: 3.838266570724907
Validation loss: 3.3285318807917825

Epoch: 6| Step: 3
Training loss: 3.251920866018676
Validation loss: 3.329465432946602

Epoch: 6| Step: 4
Training loss: 3.8900815285423076
Validation loss: 3.327206710017677

Epoch: 6| Step: 5
Training loss: 3.658801109861458
Validation loss: 3.3282863838367653

Epoch: 6| Step: 6
Training loss: 3.5659583187523523
Validation loss: 3.3281326243788754

Epoch: 6| Step: 7
Training loss: 2.518820019072952
Validation loss: 3.326962889118854

Epoch: 6| Step: 8
Training loss: 3.7289605252423788
Validation loss: 3.32926780718208

Epoch: 6| Step: 9
Training loss: 3.8997658585908788
Validation loss: 3.328142368583877

Epoch: 6| Step: 10
Training loss: 3.6988896482352347
Validation loss: 3.3256603178983233

Epoch: 6| Step: 11
Training loss: 3.105735604198863
Validation loss: 3.3287108423390057

Epoch: 6| Step: 12
Training loss: 4.113020639595464
Validation loss: 3.3269525727807445

Epoch: 6| Step: 13
Training loss: 1.8812382871953885
Validation loss: 3.324225914449042

Epoch: 44| Step: 0
Training loss: 2.7324675091960846
Validation loss: 3.322693768333851

Epoch: 6| Step: 1
Training loss: 3.8086380706555816
Validation loss: 3.3228926136834485

Epoch: 6| Step: 2
Training loss: 3.4142471368301006
Validation loss: 3.3224252934192213

Epoch: 6| Step: 3
Training loss: 3.6608564262839844
Validation loss: 3.3231165195732664

Epoch: 6| Step: 4
Training loss: 3.0836094053927865
Validation loss: 3.3240879224399755

Epoch: 6| Step: 5
Training loss: 3.4629713157723825
Validation loss: 3.3230932045258927

Epoch: 6| Step: 6
Training loss: 3.8521500268956186
Validation loss: 3.323958101625845

Epoch: 6| Step: 7
Training loss: 2.5998305779056983
Validation loss: 3.3205433260881745

Epoch: 6| Step: 8
Training loss: 4.356876217726057
Validation loss: 3.3200267443424183

Epoch: 6| Step: 9
Training loss: 3.821075675264895
Validation loss: 3.321658651080887

Epoch: 6| Step: 10
Training loss: 4.049114535516193
Validation loss: 3.3171805578886437

Epoch: 6| Step: 11
Training loss: 3.2432536015474023
Validation loss: 3.3183910931820937

Epoch: 6| Step: 12
Training loss: 3.239542642973624
Validation loss: 3.3189962516459257

Epoch: 6| Step: 13
Training loss: 4.398467638037844
Validation loss: 3.317945371458265

Epoch: 45| Step: 0
Training loss: 3.81751309355743
Validation loss: 3.316758934473535

Epoch: 6| Step: 1
Training loss: 3.3485271518398783
Validation loss: 3.3165578739500945

Epoch: 6| Step: 2
Training loss: 2.656709160107927
Validation loss: 3.317192342089803

Epoch: 6| Step: 3
Training loss: 3.8906131116080287
Validation loss: 3.3163754945763326

Epoch: 6| Step: 4
Training loss: 3.4721617545054957
Validation loss: 3.3153440602956312

Epoch: 6| Step: 5
Training loss: 4.522210094634553
Validation loss: 3.315354060147863

Epoch: 6| Step: 6
Training loss: 2.823287282640976
Validation loss: 3.3147854125366245

Epoch: 6| Step: 7
Training loss: 3.9053567093835175
Validation loss: 3.316005609392174

Epoch: 6| Step: 8
Training loss: 3.313330492239744
Validation loss: 3.3151024733503798

Epoch: 6| Step: 9
Training loss: 3.5075251200314113
Validation loss: 3.3143247383392866

Epoch: 6| Step: 10
Training loss: 3.0247739849304622
Validation loss: 3.3128831811653914

Epoch: 6| Step: 11
Training loss: 4.263269242040309
Validation loss: 3.3128414353441484

Epoch: 6| Step: 12
Training loss: 3.644480615981667
Validation loss: 3.3117129264755008

Epoch: 6| Step: 13
Training loss: 2.5341540972937233
Validation loss: 3.313155781306366

Epoch: 46| Step: 0
Training loss: 3.6243168417337497
Validation loss: 3.3111930493146144

Epoch: 6| Step: 1
Training loss: 4.235890697866561
Validation loss: 3.336529167777523

Epoch: 6| Step: 2
Training loss: 3.3111640107397378
Validation loss: 3.315339955027426

Epoch: 6| Step: 3
Training loss: 3.3929753046325994
Validation loss: 3.3102227167031906

Epoch: 6| Step: 4
Training loss: 3.441906133884632
Validation loss: 3.3077393365520384

Epoch: 6| Step: 5
Training loss: 3.2392656143917953
Validation loss: 3.309912112794569

Epoch: 6| Step: 6
Training loss: 3.444684652614377
Validation loss: 3.316407515429686

Epoch: 6| Step: 7
Training loss: 3.75313564175154
Validation loss: 3.321653061734403

Epoch: 6| Step: 8
Training loss: 3.043441637778434
Validation loss: 3.3139248718738403

Epoch: 6| Step: 9
Training loss: 2.8667504083984596
Validation loss: 3.308100507081869

Epoch: 6| Step: 10
Training loss: 3.604925145656444
Validation loss: 3.3068037628402687

Epoch: 6| Step: 11
Training loss: 3.6587863829862606
Validation loss: 3.320827507213311

Epoch: 6| Step: 12
Training loss: 4.375061034730509
Validation loss: 3.306259992495876

Epoch: 6| Step: 13
Training loss: 3.3688642040137875
Validation loss: 3.3061088965656236

Epoch: 47| Step: 0
Training loss: 3.328404517815752
Validation loss: 3.3054786048821536

Epoch: 6| Step: 1
Training loss: 3.5347121829173664
Validation loss: 3.3053815823526023

Epoch: 6| Step: 2
Training loss: 3.4058773291869637
Validation loss: 3.3060733059015175

Epoch: 6| Step: 3
Training loss: 3.928865077450989
Validation loss: 3.307347755386083

Epoch: 6| Step: 4
Training loss: 3.5745551946329686
Validation loss: 3.305591655152738

Epoch: 6| Step: 5
Training loss: 3.2587678455351416
Validation loss: 3.3062825996867793

Epoch: 6| Step: 6
Training loss: 3.001201071318514
Validation loss: 3.3074672867773254

Epoch: 6| Step: 7
Training loss: 3.524758778428101
Validation loss: 3.3057110871839894

Epoch: 6| Step: 8
Training loss: 4.246991158329127
Validation loss: 3.30522155751834

Epoch: 6| Step: 9
Training loss: 3.6258380841874533
Validation loss: 3.3048409399904695

Epoch: 6| Step: 10
Training loss: 3.6956174051254167
Validation loss: 3.304615912196236

Epoch: 6| Step: 11
Training loss: 3.4781890835817797
Validation loss: 3.3035198060826096

Epoch: 6| Step: 12
Training loss: 2.7980199420319187
Validation loss: 3.303824235263381

Epoch: 6| Step: 13
Training loss: 4.265549208418357
Validation loss: 3.3077158108093294

Epoch: 48| Step: 0
Training loss: 3.5130956070136428
Validation loss: 3.3040986000019257

Epoch: 6| Step: 1
Training loss: 3.260252699623953
Validation loss: 3.304120931797779

Epoch: 6| Step: 2
Training loss: 3.5746146894767072
Validation loss: 3.302116075309878

Epoch: 6| Step: 3
Training loss: 3.714529126439117
Validation loss: 3.3018737417974298

Epoch: 6| Step: 4
Training loss: 3.1654075495153555
Validation loss: 3.300195538584178

Epoch: 6| Step: 5
Training loss: 4.278337587880267
Validation loss: 3.2999894338682876

Epoch: 6| Step: 6
Training loss: 3.2299791031861247
Validation loss: 3.2987953778482257

Epoch: 6| Step: 7
Training loss: 3.559518068032237
Validation loss: 3.2976242681339056

Epoch: 6| Step: 8
Training loss: 3.9526869942081335
Validation loss: 3.302437481700285

Epoch: 6| Step: 9
Training loss: 3.3457706798674565
Validation loss: 3.295348848729701

Epoch: 6| Step: 10
Training loss: 3.6190261287457477
Validation loss: 3.2952683136077088

Epoch: 6| Step: 11
Training loss: 3.671955253860338
Validation loss: 3.293001323097964

Epoch: 6| Step: 12
Training loss: 2.7962554586439947
Validation loss: 3.295843323289686

Epoch: 6| Step: 13
Training loss: 3.698281126016293
Validation loss: 3.29473461599331

Epoch: 49| Step: 0
Training loss: 3.7412665075976053
Validation loss: 3.2955745232981393

Epoch: 6| Step: 1
Training loss: 3.541072586198987
Validation loss: 3.3054734426628705

Epoch: 6| Step: 2
Training loss: 3.4797905155138795
Validation loss: 3.292577612548727

Epoch: 6| Step: 3
Training loss: 3.9580579293798444
Validation loss: 3.2919893544043806

Epoch: 6| Step: 4
Training loss: 3.555777782873153
Validation loss: 3.29058968768588

Epoch: 6| Step: 5
Training loss: 3.624615484430472
Validation loss: 3.2961461367122467

Epoch: 6| Step: 6
Training loss: 3.1489090862118485
Validation loss: 3.296307661398127

Epoch: 6| Step: 7
Training loss: 3.689067959811716
Validation loss: 3.291874818359003

Epoch: 6| Step: 8
Training loss: 3.5770928505867374
Validation loss: 3.290115270190202

Epoch: 6| Step: 9
Training loss: 3.367704913751856
Validation loss: 3.2884428138953203

Epoch: 6| Step: 10
Training loss: 3.6060034127116123
Validation loss: 3.287988462561162

Epoch: 6| Step: 11
Training loss: 3.47357405901605
Validation loss: 3.2902217937421585

Epoch: 6| Step: 12
Training loss: 3.559875056613809
Validation loss: 3.29458811318827

Epoch: 6| Step: 13
Training loss: 2.6663049114741035
Validation loss: 3.2863100662408393

Epoch: 50| Step: 0
Training loss: 3.6553904509306365
Validation loss: 3.2854318982448554

Epoch: 6| Step: 1
Training loss: 4.069791149057681
Validation loss: 3.2849366509459648

Epoch: 6| Step: 2
Training loss: 3.4677785251916355
Validation loss: 3.2843762046796376

Epoch: 6| Step: 3
Training loss: 3.075561385354389
Validation loss: 3.285142571628809

Epoch: 6| Step: 4
Training loss: 3.705091766991886
Validation loss: 3.28351939175822

Epoch: 6| Step: 5
Training loss: 3.9446845735220095
Validation loss: 3.283694445978452

Epoch: 6| Step: 6
Training loss: 2.6111395802760766
Validation loss: 3.283194495197803

Epoch: 6| Step: 7
Training loss: 2.741282169624681
Validation loss: 3.2830994237600066

Epoch: 6| Step: 8
Training loss: 3.924027418408276
Validation loss: 3.282983804486275

Epoch: 6| Step: 9
Training loss: 3.6244003852314415
Validation loss: 3.281775413437976

Epoch: 6| Step: 10
Training loss: 3.7882665683039383
Validation loss: 3.2824924802321087

Epoch: 6| Step: 11
Training loss: 3.0725921631935402
Validation loss: 3.2824293338676798

Epoch: 6| Step: 12
Training loss: 3.7602323168144833
Validation loss: 3.279371023040662

Epoch: 6| Step: 13
Training loss: 3.5673203900147024
Validation loss: 3.2810939784929958

Epoch: 51| Step: 0
Training loss: 3.3381071874232204
Validation loss: 3.280005002892113

Epoch: 6| Step: 1
Training loss: 3.213561533532128
Validation loss: 3.2781763231343723

Epoch: 6| Step: 2
Training loss: 3.6183779510413268
Validation loss: 3.2787509634755505

Epoch: 6| Step: 3
Training loss: 3.6484713501758788
Validation loss: 3.2792770181002524

Epoch: 6| Step: 4
Training loss: 3.633788275161162
Validation loss: 3.278545706353518

Epoch: 6| Step: 5
Training loss: 3.745170153227158
Validation loss: 3.277630525324947

Epoch: 6| Step: 6
Training loss: 3.6243385500718763
Validation loss: 3.2762833312836985

Epoch: 6| Step: 7
Training loss: 4.129115508090127
Validation loss: 3.2770160991995185

Epoch: 6| Step: 8
Training loss: 3.279562089111577
Validation loss: 3.276864645285559

Epoch: 6| Step: 9
Training loss: 3.2116261878347148
Validation loss: 3.277841222258082

Epoch: 6| Step: 10
Training loss: 3.304603954368367
Validation loss: 3.2751511123188695

Epoch: 6| Step: 11
Training loss: 3.894365465926657
Validation loss: 3.2752609169033824

Epoch: 6| Step: 12
Training loss: 3.064147506071606
Validation loss: 3.27416949857128

Epoch: 6| Step: 13
Training loss: 3.326341464545894
Validation loss: 3.2739819695428904

Epoch: 52| Step: 0
Training loss: 3.6209689121887125
Validation loss: 3.273686723274445

Epoch: 6| Step: 1
Training loss: 3.4340904666401624
Validation loss: 3.2738287018415444

Epoch: 6| Step: 2
Training loss: 3.836803330794313
Validation loss: 3.273590592584575

Epoch: 6| Step: 3
Training loss: 3.3472053998750417
Validation loss: 3.2724420904472185

Epoch: 6| Step: 4
Training loss: 3.228839061895478
Validation loss: 3.2731605690863437

Epoch: 6| Step: 5
Training loss: 3.7439378694449075
Validation loss: 3.2725902975196357

Epoch: 6| Step: 6
Training loss: 3.3914318618914545
Validation loss: 3.271662608865528

Epoch: 6| Step: 7
Training loss: 3.2378854176049936
Validation loss: 3.2705822679703904

Epoch: 6| Step: 8
Training loss: 3.6055184771083244
Validation loss: 3.268284404022944

Epoch: 6| Step: 9
Training loss: 4.09901334474415
Validation loss: 3.2678960294639157

Epoch: 6| Step: 10
Training loss: 3.603389648881997
Validation loss: 3.2690686733373577

Epoch: 6| Step: 11
Training loss: 2.969896275927917
Validation loss: 3.2666162492813795

Epoch: 6| Step: 12
Training loss: 3.858110969897377
Validation loss: 3.2675799059712376

Epoch: 6| Step: 13
Training loss: 2.611732468724486
Validation loss: 3.2674533180808587

Epoch: 53| Step: 0
Training loss: 4.26098738425374
Validation loss: 3.266292192401267

Epoch: 6| Step: 1
Training loss: 3.3748184437838162
Validation loss: 3.267107459517561

Epoch: 6| Step: 2
Training loss: 3.032849862970602
Validation loss: 3.2659125798313067

Epoch: 6| Step: 3
Training loss: 3.4056605957769674
Validation loss: 3.2678599002366013

Epoch: 6| Step: 4
Training loss: 3.591828736604197
Validation loss: 3.2667910038847867

Epoch: 6| Step: 5
Training loss: 3.305833261687157
Validation loss: 3.266833981663081

Epoch: 6| Step: 6
Training loss: 3.855763834721404
Validation loss: 3.2659447696877457

Epoch: 6| Step: 7
Training loss: 2.456446737316465
Validation loss: 3.2628403621838116

Epoch: 6| Step: 8
Training loss: 3.7756124037614747
Validation loss: 3.262825457264007

Epoch: 6| Step: 9
Training loss: 4.5663933015481515
Validation loss: 3.26705619269714

Epoch: 6| Step: 10
Training loss: 2.6870581685092247
Validation loss: 3.264859482250369

Epoch: 6| Step: 11
Training loss: 3.5157332340110066
Validation loss: 3.2617725937950235

Epoch: 6| Step: 12
Training loss: 2.345529923091408
Validation loss: 3.262031640871738

Epoch: 6| Step: 13
Training loss: 4.573718349016784
Validation loss: 3.261610193566377

Epoch: 54| Step: 0
Training loss: 3.0565800962457415
Validation loss: 3.2604097153108156

Epoch: 6| Step: 1
Training loss: 2.986704770793126
Validation loss: 3.2614142666015193

Epoch: 6| Step: 2
Training loss: 3.335072890004149
Validation loss: 3.2608623423473326

Epoch: 6| Step: 3
Training loss: 3.1819373566738984
Validation loss: 3.2595880320291757

Epoch: 6| Step: 4
Training loss: 3.968757449165622
Validation loss: 3.2597008948551323

Epoch: 6| Step: 5
Training loss: 3.15275712830386
Validation loss: 3.2587687297747747

Epoch: 6| Step: 6
Training loss: 3.005844145916587
Validation loss: 3.259006106397468

Epoch: 6| Step: 7
Training loss: 3.2921009662482494
Validation loss: 3.261122714808709

Epoch: 6| Step: 8
Training loss: 4.064947711378369
Validation loss: 3.259796153248853

Epoch: 6| Step: 9
Training loss: 4.352943406764006
Validation loss: 3.258222189310251

Epoch: 6| Step: 10
Training loss: 3.3284825952254504
Validation loss: 3.2562842339508076

Epoch: 6| Step: 11
Training loss: 3.8170928805940827
Validation loss: 3.2573532882929177

Epoch: 6| Step: 12
Training loss: 3.7595384722371117
Validation loss: 3.257527255453602

Epoch: 6| Step: 13
Training loss: 3.338626108673756
Validation loss: 3.256720889349381

Epoch: 55| Step: 0
Training loss: 3.152149823166791
Validation loss: 3.258335876012756

Epoch: 6| Step: 1
Training loss: 3.6334665017411267
Validation loss: 3.256522956779357

Epoch: 6| Step: 2
Training loss: 3.509515361747377
Validation loss: 3.2555569501034323

Epoch: 6| Step: 3
Training loss: 4.014564700727605
Validation loss: 3.254111912650782

Epoch: 6| Step: 4
Training loss: 3.812787654843597
Validation loss: 3.2532629666753294

Epoch: 6| Step: 5
Training loss: 3.100453368228913
Validation loss: 3.253242099803381

Epoch: 6| Step: 6
Training loss: 3.2265755050434035
Validation loss: 3.252140780469797

Epoch: 6| Step: 7
Training loss: 3.5056629689065235
Validation loss: 3.2532344212651516

Epoch: 6| Step: 8
Training loss: 3.033705198808277
Validation loss: 3.252842087198672

Epoch: 6| Step: 9
Training loss: 3.5460787648222425
Validation loss: 3.255762889590943

Epoch: 6| Step: 10
Training loss: 3.9222264835261273
Validation loss: 3.254634543893654

Epoch: 6| Step: 11
Training loss: 2.998964766857317
Validation loss: 3.252111238257663

Epoch: 6| Step: 12
Training loss: 3.4647609008379763
Validation loss: 3.252136749135602

Epoch: 6| Step: 13
Training loss: 4.085987681560274
Validation loss: 3.2522957977966533

Epoch: 56| Step: 0
Training loss: 3.1655268541883204
Validation loss: 3.2528106740285567

Epoch: 6| Step: 1
Training loss: 4.061076457694346
Validation loss: 3.2603074514530332

Epoch: 6| Step: 2
Training loss: 3.163563027224474
Validation loss: 3.2918149609155782

Epoch: 6| Step: 3
Training loss: 3.8434596998797335
Validation loss: 3.3179245026434034

Epoch: 6| Step: 4
Training loss: 3.1310462443744935
Validation loss: 3.248319036533676

Epoch: 6| Step: 5
Training loss: 3.833343063563285
Validation loss: 3.2486449052011657

Epoch: 6| Step: 6
Training loss: 3.5619094091394317
Validation loss: 3.257045298743013

Epoch: 6| Step: 7
Training loss: 3.272593387119303
Validation loss: 3.298230853756412

Epoch: 6| Step: 8
Training loss: 3.9108064246225664
Validation loss: 3.308338714551425

Epoch: 6| Step: 9
Training loss: 3.256667706721389
Validation loss: 3.2885879339087487

Epoch: 6| Step: 10
Training loss: 4.0476247910317245
Validation loss: 3.2859153415349684

Epoch: 6| Step: 11
Training loss: 3.491946901230135
Validation loss: 3.25606710782313

Epoch: 6| Step: 12
Training loss: 3.3060905778664953
Validation loss: 3.2471421789357824

Epoch: 6| Step: 13
Training loss: 2.285619861491652
Validation loss: 3.2518451050315287

Epoch: 57| Step: 0
Training loss: 3.4133224558160236
Validation loss: 3.2539540336947215

Epoch: 6| Step: 1
Training loss: 3.284638027181152
Validation loss: 3.2578006489501945

Epoch: 6| Step: 2
Training loss: 3.44355670365703
Validation loss: 3.260891902764445

Epoch: 6| Step: 3
Training loss: 3.3457706798674565
Validation loss: 3.259198454431798

Epoch: 6| Step: 4
Training loss: 3.6338986321578686
Validation loss: 3.259505493344371

Epoch: 6| Step: 5
Training loss: 3.7872103539432094
Validation loss: 3.2510360899462345

Epoch: 6| Step: 6
Training loss: 3.7765152978373866
Validation loss: 3.2535623458471576

Epoch: 6| Step: 7
Training loss: 3.628723862646191
Validation loss: 3.250594467305281

Epoch: 6| Step: 8
Training loss: 2.8828297022691363
Validation loss: 3.2493157214639683

Epoch: 6| Step: 9
Training loss: 3.3673764062982827
Validation loss: 3.2493607481618665

Epoch: 6| Step: 10
Training loss: 3.997794258399889
Validation loss: 3.2474987637608588

Epoch: 6| Step: 11
Training loss: 2.204070409200527
Validation loss: 3.24868676020955

Epoch: 6| Step: 12
Training loss: 3.913782532324343
Validation loss: 3.2501307682835883

Epoch: 6| Step: 13
Training loss: 4.0299581187606455
Validation loss: 3.2496732811031928

Epoch: 58| Step: 0
Training loss: 3.3732792741668214
Validation loss: 3.2511499333093323

Epoch: 6| Step: 1
Training loss: 4.3181842438905464
Validation loss: 3.249279914260959

Epoch: 6| Step: 2
Training loss: 3.1523936668329475
Validation loss: 3.246086953303384

Epoch: 6| Step: 3
Training loss: 3.403437862254365
Validation loss: 3.246881879183582

Epoch: 6| Step: 4
Training loss: 3.870542485068875
Validation loss: 3.2438375343254555

Epoch: 6| Step: 5
Training loss: 2.9572403908145413
Validation loss: 3.2419641853971712

Epoch: 6| Step: 6
Training loss: 2.1523116259938253
Validation loss: 3.2433098607853332

Epoch: 6| Step: 7
Training loss: 2.7762026474721804
Validation loss: 3.2430627085625066

Epoch: 6| Step: 8
Training loss: 3.885282962465577
Validation loss: 3.240439308850685

Epoch: 6| Step: 9
Training loss: 3.401141053753769
Validation loss: 3.240764797497079

Epoch: 6| Step: 10
Training loss: 3.7660997020308966
Validation loss: 3.239361013119721

Epoch: 6| Step: 11
Training loss: 4.218346244423494
Validation loss: 3.2404451229321514

Epoch: 6| Step: 12
Training loss: 3.3466650119589962
Validation loss: 3.23761599607645

Epoch: 6| Step: 13
Training loss: 3.525122804058237
Validation loss: 3.2368382561754965

Epoch: 59| Step: 0
Training loss: 3.4526761829190815
Validation loss: 3.2377723089958588

Epoch: 6| Step: 1
Training loss: 3.2856140180654223
Validation loss: 3.235675011721214

Epoch: 6| Step: 2
Training loss: 2.384053491837152
Validation loss: 3.2350305185550408

Epoch: 6| Step: 3
Training loss: 3.432600656743624
Validation loss: 3.233942712468682

Epoch: 6| Step: 4
Training loss: 3.210234999091133
Validation loss: 3.236116683544159

Epoch: 6| Step: 5
Training loss: 3.8766378817442204
Validation loss: 3.2339965954051113

Epoch: 6| Step: 6
Training loss: 3.4197453530078734
Validation loss: 3.2355727520868878

Epoch: 6| Step: 7
Training loss: 3.858631386721057
Validation loss: 3.2328107048235903

Epoch: 6| Step: 8
Training loss: 2.8415807477951835
Validation loss: 3.236711757021362

Epoch: 6| Step: 9
Training loss: 4.063489822699766
Validation loss: 3.2360795562453037

Epoch: 6| Step: 10
Training loss: 3.0723277071763038
Validation loss: 3.2373274072001332

Epoch: 6| Step: 11
Training loss: 4.47926831980248
Validation loss: 3.2341373469836325

Epoch: 6| Step: 12
Training loss: 3.8878380778703696
Validation loss: 3.237096023077156

Epoch: 6| Step: 13
Training loss: 2.1324713018348955
Validation loss: 3.235664325097289

Epoch: 60| Step: 0
Training loss: 3.459970171143832
Validation loss: 3.2354311073616486

Epoch: 6| Step: 1
Training loss: 3.1038436380211984
Validation loss: 3.23372691488319

Epoch: 6| Step: 2
Training loss: 3.8187296265903057
Validation loss: 3.233647453362559

Epoch: 6| Step: 3
Training loss: 3.521777927309885
Validation loss: 3.234665026845409

Epoch: 6| Step: 4
Training loss: 2.4244813738087987
Validation loss: 3.233691956177185

Epoch: 6| Step: 5
Training loss: 2.81781351641759
Validation loss: 3.234097967915528

Epoch: 6| Step: 6
Training loss: 3.765598661085271
Validation loss: 3.2331865919496345

Epoch: 6| Step: 7
Training loss: 3.678768877505294
Validation loss: 3.232696319509686

Epoch: 6| Step: 8
Training loss: 3.044887266029662
Validation loss: 3.2325516016964952

Epoch: 6| Step: 9
Training loss: 3.5791858949392705
Validation loss: 3.232656918129235

Epoch: 6| Step: 10
Training loss: 4.463069052437043
Validation loss: 3.2335306176765695

Epoch: 6| Step: 11
Training loss: 3.0909023858573934
Validation loss: 3.232673602155371

Epoch: 6| Step: 12
Training loss: 3.937992125744016
Validation loss: 3.230784088074911

Epoch: 6| Step: 13
Training loss: 3.3210312009389287
Validation loss: 3.2304986980444936

Epoch: 61| Step: 0
Training loss: 4.258996081552631
Validation loss: 3.229111564131693

Epoch: 6| Step: 1
Training loss: 3.709552578744862
Validation loss: 3.2290449571381807

Epoch: 6| Step: 2
Training loss: 3.5901994497845657
Validation loss: 3.2291623099962923

Epoch: 6| Step: 3
Training loss: 3.8524800227177627
Validation loss: 3.2276633318280505

Epoch: 6| Step: 4
Training loss: 3.1660050822040686
Validation loss: 3.2267747327686083

Epoch: 6| Step: 5
Training loss: 3.698994453502332
Validation loss: 3.2262042145938166

Epoch: 6| Step: 6
Training loss: 3.2556202050633454
Validation loss: 3.2234420117737206

Epoch: 6| Step: 7
Training loss: 3.666710520973356
Validation loss: 3.2261775379391873

Epoch: 6| Step: 8
Training loss: 3.5248235780111767
Validation loss: 3.2260577926342098

Epoch: 6| Step: 9
Training loss: 3.052271675487201
Validation loss: 3.2236938945946036

Epoch: 6| Step: 10
Training loss: 3.060799574263803
Validation loss: 3.224745656660061

Epoch: 6| Step: 11
Training loss: 2.479039346540421
Validation loss: 3.2242436910987524

Epoch: 6| Step: 12
Training loss: 3.7629417895118817
Validation loss: 3.2246745026776904

Epoch: 6| Step: 13
Training loss: 2.7151753394621565
Validation loss: 3.224736506311872

Epoch: 62| Step: 0
Training loss: 3.287397747117605
Validation loss: 3.2233585888760086

Epoch: 6| Step: 1
Training loss: 3.367216672129287
Validation loss: 3.2233999633782666

Epoch: 6| Step: 2
Training loss: 3.940823560124362
Validation loss: 3.222603679388539

Epoch: 6| Step: 3
Training loss: 3.1226153621330153
Validation loss: 3.2245843443790325

Epoch: 6| Step: 4
Training loss: 4.103686670935403
Validation loss: 3.223121736629952

Epoch: 6| Step: 5
Training loss: 3.532921319607487
Validation loss: 3.2223421866428863

Epoch: 6| Step: 6
Training loss: 3.396712643727405
Validation loss: 3.225144499161379

Epoch: 6| Step: 7
Training loss: 3.00524919945992
Validation loss: 3.2238046327620524

Epoch: 6| Step: 8
Training loss: 4.002357979994345
Validation loss: 3.2250688039148234

Epoch: 6| Step: 9
Training loss: 3.6833609935245506
Validation loss: 3.228610039144837

Epoch: 6| Step: 10
Training loss: 2.974542528128981
Validation loss: 3.2261811018849915

Epoch: 6| Step: 11
Training loss: 3.210709092678379
Validation loss: 3.230247783924279

Epoch: 6| Step: 12
Training loss: 2.7741674188040113
Validation loss: 3.2216413768482344

Epoch: 6| Step: 13
Training loss: 3.9449029993235913
Validation loss: 3.2188660867228345

Epoch: 63| Step: 0
Training loss: 3.839787495415434
Validation loss: 3.2185134490149157

Epoch: 6| Step: 1
Training loss: 3.8325191268891525
Validation loss: 3.215682793166694

Epoch: 6| Step: 2
Training loss: 3.442943355292664
Validation loss: 3.2160412351609167

Epoch: 6| Step: 3
Training loss: 3.2267433836252817
Validation loss: 3.213998979239931

Epoch: 6| Step: 4
Training loss: 2.965089488745581
Validation loss: 3.213147617872149

Epoch: 6| Step: 5
Training loss: 3.178206115107612
Validation loss: 3.2124717357795527

Epoch: 6| Step: 6
Training loss: 3.7245995171851063
Validation loss: 3.2106803174475615

Epoch: 6| Step: 7
Training loss: 3.4707384338471954
Validation loss: 3.210194977031998

Epoch: 6| Step: 8
Training loss: 3.313199671141486
Validation loss: 3.2100243178701224

Epoch: 6| Step: 9
Training loss: 2.896324683203219
Validation loss: 3.208900534698518

Epoch: 6| Step: 10
Training loss: 3.723287426817236
Validation loss: 3.2081522334466515

Epoch: 6| Step: 11
Training loss: 3.1866329734276624
Validation loss: 3.207268115502249

Epoch: 6| Step: 12
Training loss: 3.4484677215344273
Validation loss: 3.208620042352933

Epoch: 6| Step: 13
Training loss: 4.265899984697644
Validation loss: 3.206954153548451

Epoch: 64| Step: 0
Training loss: 3.127756657669315
Validation loss: 3.206351882245605

Epoch: 6| Step: 1
Training loss: 3.2217818119991333
Validation loss: 3.2066557186731957

Epoch: 6| Step: 2
Training loss: 2.908411186364006
Validation loss: 3.2058242673519213

Epoch: 6| Step: 3
Training loss: 3.4125115474743097
Validation loss: 3.2106951051282198

Epoch: 6| Step: 4
Training loss: 3.213661838718451
Validation loss: 3.209822839670643

Epoch: 6| Step: 5
Training loss: 3.106191260782177
Validation loss: 3.207366887825365

Epoch: 6| Step: 6
Training loss: 4.537650172583285
Validation loss: 3.2074937242540167

Epoch: 6| Step: 7
Training loss: 2.8214097358668138
Validation loss: 3.2073996812393926

Epoch: 6| Step: 8
Training loss: 2.5455650283938414
Validation loss: 3.2081611969604573

Epoch: 6| Step: 9
Training loss: 4.070149892535295
Validation loss: 3.209688269436626

Epoch: 6| Step: 10
Training loss: 3.8000816336446355
Validation loss: 3.2082667467047186

Epoch: 6| Step: 11
Training loss: 3.2017573716677545
Validation loss: 3.20750761226973

Epoch: 6| Step: 12
Training loss: 4.146760820830613
Validation loss: 3.205900867995677

Epoch: 6| Step: 13
Training loss: 3.721585130653952
Validation loss: 3.2084584970168653

Epoch: 65| Step: 0
Training loss: 3.5745546610424457
Validation loss: 3.2098917655343144

Epoch: 6| Step: 1
Training loss: 3.8679546173336794
Validation loss: 3.2168009394652084

Epoch: 6| Step: 2
Training loss: 3.4393333401202755
Validation loss: 3.20920328066142

Epoch: 6| Step: 3
Training loss: 3.821339475053997
Validation loss: 3.205416907343173

Epoch: 6| Step: 4
Training loss: 3.7992167217697137
Validation loss: 3.205510970139756

Epoch: 6| Step: 5
Training loss: 2.8178649595567653
Validation loss: 3.2034506883575147

Epoch: 6| Step: 6
Training loss: 3.1288230399164965
Validation loss: 3.202624192443565

Epoch: 6| Step: 7
Training loss: 4.0641621637205345
Validation loss: 3.2027356751286815

Epoch: 6| Step: 8
Training loss: 3.9477652300104293
Validation loss: 3.2028267702319306

Epoch: 6| Step: 9
Training loss: 3.4701441806884086
Validation loss: 3.2002714630956848

Epoch: 6| Step: 10
Training loss: 2.8874393539335235
Validation loss: 3.2014247636706354

Epoch: 6| Step: 11
Training loss: 2.9191529349148317
Validation loss: 3.197625061979661

Epoch: 6| Step: 12
Training loss: 3.162368132363758
Validation loss: 3.198316557043894

Epoch: 6| Step: 13
Training loss: 2.638239307651923
Validation loss: 3.2003416712820383

Epoch: 66| Step: 0
Training loss: 2.355489803492146
Validation loss: 3.196841123028123

Epoch: 6| Step: 1
Training loss: 3.9006116534143658
Validation loss: 3.1972044982525323

Epoch: 6| Step: 2
Training loss: 3.363863621000911
Validation loss: 3.1964141874449084

Epoch: 6| Step: 3
Training loss: 3.1017840327940616
Validation loss: 3.199087386331822

Epoch: 6| Step: 4
Training loss: 2.7426562655778213
Validation loss: 3.197390312436461

Epoch: 6| Step: 5
Training loss: 2.9233161513701895
Validation loss: 3.1980553582542863

Epoch: 6| Step: 6
Training loss: 3.5992821613519506
Validation loss: 3.1972566590043203

Epoch: 6| Step: 7
Training loss: 2.7706764769553325
Validation loss: 3.1958665822437844

Epoch: 6| Step: 8
Training loss: 3.6492039530933282
Validation loss: 3.1955942326132494

Epoch: 6| Step: 9
Training loss: 3.4115349603254046
Validation loss: 3.1964955129047143

Epoch: 6| Step: 10
Training loss: 3.787033072416605
Validation loss: 3.1961764261298597

Epoch: 6| Step: 11
Training loss: 4.141506806530691
Validation loss: 3.2011143978799317

Epoch: 6| Step: 12
Training loss: 4.332245225497704
Validation loss: 3.210349810982059

Epoch: 6| Step: 13
Training loss: 3.580202524008249
Validation loss: 3.222669114888585

Epoch: 67| Step: 0
Training loss: 3.451025415150637
Validation loss: 3.209265308406918

Epoch: 6| Step: 1
Training loss: 2.9663993765043326
Validation loss: 3.2071173342109947

Epoch: 6| Step: 2
Training loss: 4.093377948190638
Validation loss: 3.195432939347357

Epoch: 6| Step: 3
Training loss: 2.786112274832296
Validation loss: 3.193782511204635

Epoch: 6| Step: 4
Training loss: 3.2948978515906973
Validation loss: 3.1932720897805567

Epoch: 6| Step: 5
Training loss: 4.427193290990469
Validation loss: 3.1927705027448514

Epoch: 6| Step: 6
Training loss: 3.8309863548981764
Validation loss: 3.191769260850368

Epoch: 6| Step: 7
Training loss: 4.016388698050542
Validation loss: 3.1924223688550764

Epoch: 6| Step: 8
Training loss: 2.3761041985600193
Validation loss: 3.1916292609948185

Epoch: 6| Step: 9
Training loss: 2.6954573882592516
Validation loss: 3.1902510200068

Epoch: 6| Step: 10
Training loss: 3.4167919291042574
Validation loss: 3.191250189264274

Epoch: 6| Step: 11
Training loss: 3.8562401769874635
Validation loss: 3.189922497992408

Epoch: 6| Step: 12
Training loss: 2.5851815493081527
Validation loss: 3.190567527136779

Epoch: 6| Step: 13
Training loss: 3.6343233637860344
Validation loss: 3.1896562419119237

Epoch: 68| Step: 0
Training loss: 2.5059451938125243
Validation loss: 3.187707915533382

Epoch: 6| Step: 1
Training loss: 3.6495580484038657
Validation loss: 3.1885110657849376

Epoch: 6| Step: 2
Training loss: 3.6632836658927843
Validation loss: 3.187656040864139

Epoch: 6| Step: 3
Training loss: 4.104057091090912
Validation loss: 3.186705535125256

Epoch: 6| Step: 4
Training loss: 2.859052796267621
Validation loss: 3.187154633360234

Epoch: 6| Step: 5
Training loss: 3.445411594202759
Validation loss: 3.1858946851403993

Epoch: 6| Step: 6
Training loss: 2.993969259813958
Validation loss: 3.185113768484293

Epoch: 6| Step: 7
Training loss: 3.5226941730812436
Validation loss: 3.1872873108640927

Epoch: 6| Step: 8
Training loss: 3.5017236824846876
Validation loss: 3.1851751063386318

Epoch: 6| Step: 9
Training loss: 4.392506043761627
Validation loss: 3.18511764640325

Epoch: 6| Step: 10
Training loss: 3.4696570232969663
Validation loss: 3.1841954219159616

Epoch: 6| Step: 11
Training loss: 3.093604036220919
Validation loss: 3.185861366192436

Epoch: 6| Step: 12
Training loss: 3.248326677759541
Validation loss: 3.185592576094922

Epoch: 6| Step: 13
Training loss: 2.8940722555909093
Validation loss: 3.183337379942207

Epoch: 69| Step: 0
Training loss: 3.333933458347287
Validation loss: 3.1833146840198716

Epoch: 6| Step: 1
Training loss: 2.9532346351900047
Validation loss: 3.185216060900659

Epoch: 6| Step: 2
Training loss: 3.9065643184087917
Validation loss: 3.183886215714208

Epoch: 6| Step: 3
Training loss: 3.76565463105886
Validation loss: 3.1863600019174583

Epoch: 6| Step: 4
Training loss: 2.9806549694036812
Validation loss: 3.1853143548520566

Epoch: 6| Step: 5
Training loss: 3.208031000201587
Validation loss: 3.1850229217708494

Epoch: 6| Step: 6
Training loss: 4.358388700309815
Validation loss: 3.181725115933881

Epoch: 6| Step: 7
Training loss: 4.1402926329606045
Validation loss: 3.1816943236557806

Epoch: 6| Step: 8
Training loss: 2.972363170557728
Validation loss: 3.1819746435781187

Epoch: 6| Step: 9
Training loss: 3.436518858559396
Validation loss: 3.1813197920207923

Epoch: 6| Step: 10
Training loss: 2.483965954005155
Validation loss: 3.180211906629539

Epoch: 6| Step: 11
Training loss: 3.350966322722523
Validation loss: 3.1789958768369355

Epoch: 6| Step: 12
Training loss: 3.3186533653429002
Validation loss: 3.179797951864434

Epoch: 6| Step: 13
Training loss: 3.2111823738078167
Validation loss: 3.1791057188977154

Epoch: 70| Step: 0
Training loss: 3.2173039419436567
Validation loss: 3.1772159903091786

Epoch: 6| Step: 1
Training loss: 3.7484342485217375
Validation loss: 3.17635973122637

Epoch: 6| Step: 2
Training loss: 4.210719624900414
Validation loss: 3.1766606757635163

Epoch: 6| Step: 3
Training loss: 3.557952119536196
Validation loss: 3.177272108505775

Epoch: 6| Step: 4
Training loss: 3.4079889180983773
Validation loss: 3.1750299513849995

Epoch: 6| Step: 5
Training loss: 3.161353790884167
Validation loss: 3.174784832737501

Epoch: 6| Step: 6
Training loss: 3.121888557228993
Validation loss: 3.174266849911249

Epoch: 6| Step: 7
Training loss: 3.4387285291361294
Validation loss: 3.174257794724284

Epoch: 6| Step: 8
Training loss: 2.6086024437022886
Validation loss: 3.1743208735955264

Epoch: 6| Step: 9
Training loss: 3.697307540083658
Validation loss: 3.173916129104557

Epoch: 6| Step: 10
Training loss: 2.7548083836542707
Validation loss: 3.173089140602152

Epoch: 6| Step: 11
Training loss: 3.547383141773808
Validation loss: 3.1726374582405708

Epoch: 6| Step: 12
Training loss: 4.427289794894673
Validation loss: 3.17286476911183

Epoch: 6| Step: 13
Training loss: 1.0722290477524457
Validation loss: 3.170966767130151

Epoch: 71| Step: 0
Training loss: 3.859110464072462
Validation loss: 3.1722179328285987

Epoch: 6| Step: 1
Training loss: 2.7384351831287272
Validation loss: 3.1730015336971595

Epoch: 6| Step: 2
Training loss: 3.909585368033158
Validation loss: 3.169758482790589

Epoch: 6| Step: 3
Training loss: 3.0407446591707417
Validation loss: 3.1708651517795605

Epoch: 6| Step: 4
Training loss: 3.838683347878004
Validation loss: 3.170857713581977

Epoch: 6| Step: 5
Training loss: 3.3179492393873913
Validation loss: 3.1703546762975128

Epoch: 6| Step: 6
Training loss: 2.260093091549705
Validation loss: 3.169082501053386

Epoch: 6| Step: 7
Training loss: 4.011471986842324
Validation loss: 3.1689364459725273

Epoch: 6| Step: 8
Training loss: 3.7796042147319513
Validation loss: 3.1703651120415057

Epoch: 6| Step: 9
Training loss: 2.986222419339952
Validation loss: 3.1696220093712046

Epoch: 6| Step: 10
Training loss: 3.720539848369543
Validation loss: 3.1696613499317836

Epoch: 6| Step: 11
Training loss: 3.5479967133292853
Validation loss: 3.167700942410637

Epoch: 6| Step: 12
Training loss: 3.0380514076107477
Validation loss: 3.170506853382844

Epoch: 6| Step: 13
Training loss: 3.1548035583762357
Validation loss: 3.1677250062356346

Epoch: 72| Step: 0
Training loss: 4.247056502729618
Validation loss: 3.1697651584624547

Epoch: 6| Step: 1
Training loss: 2.866763049730616
Validation loss: 3.1692809279187344

Epoch: 6| Step: 2
Training loss: 3.423841216371863
Validation loss: 3.1672082679637032

Epoch: 6| Step: 3
Training loss: 2.9739013951468936
Validation loss: 3.1711834078243717

Epoch: 6| Step: 4
Training loss: 3.2106605280387637
Validation loss: 3.175458386357655

Epoch: 6| Step: 5
Training loss: 3.2208609464250477
Validation loss: 3.1730906659776275

Epoch: 6| Step: 6
Training loss: 3.373972418436626
Validation loss: 3.170819358077471

Epoch: 6| Step: 7
Training loss: 2.8540282575549027
Validation loss: 3.168246547600476

Epoch: 6| Step: 8
Training loss: 3.149948628324593
Validation loss: 3.1667573124638877

Epoch: 6| Step: 9
Training loss: 3.236133337058244
Validation loss: 3.1666135748431827

Epoch: 6| Step: 10
Training loss: 3.7751241196191514
Validation loss: 3.1644665750607124

Epoch: 6| Step: 11
Training loss: 4.135699642822788
Validation loss: 3.1619706174761464

Epoch: 6| Step: 12
Training loss: 3.825735537548208
Validation loss: 3.161501483967728

Epoch: 6| Step: 13
Training loss: 2.82563587897927
Validation loss: 3.1592883505455838

Epoch: 73| Step: 0
Training loss: 3.4004834560669974
Validation loss: 3.161024237189927

Epoch: 6| Step: 1
Training loss: 2.6949586497798883
Validation loss: 3.1620349192347774

Epoch: 6| Step: 2
Training loss: 3.2602222778742345
Validation loss: 3.160852842193974

Epoch: 6| Step: 3
Training loss: 3.2507646101397607
Validation loss: 3.159380549070594

Epoch: 6| Step: 4
Training loss: 2.8076036854294903
Validation loss: 3.158360509398096

Epoch: 6| Step: 5
Training loss: 3.188358266134397
Validation loss: 3.158282620970416

Epoch: 6| Step: 6
Training loss: 3.5143302737433797
Validation loss: 3.158777575433425

Epoch: 6| Step: 7
Training loss: 3.6404792199806386
Validation loss: 3.1583540807290325

Epoch: 6| Step: 8
Training loss: 3.568053350913607
Validation loss: 3.158253530421136

Epoch: 6| Step: 9
Training loss: 3.853353768616798
Validation loss: 3.1596783278220553

Epoch: 6| Step: 10
Training loss: 4.1922634986588685
Validation loss: 3.1581986766602257

Epoch: 6| Step: 11
Training loss: 3.719078241816109
Validation loss: 3.157336689341159

Epoch: 6| Step: 12
Training loss: 3.2604352241613617
Validation loss: 3.1560274425605734

Epoch: 6| Step: 13
Training loss: 2.7382529525274224
Validation loss: 3.1549962243178666

Epoch: 74| Step: 0
Training loss: 3.1252851737557266
Validation loss: 3.1547346007404906

Epoch: 6| Step: 1
Training loss: 3.4080654520904408
Validation loss: 3.153185756963929

Epoch: 6| Step: 2
Training loss: 2.902706488099458
Validation loss: 3.1541610021550213

Epoch: 6| Step: 3
Training loss: 3.15741942241724
Validation loss: 3.1533456608383177

Epoch: 6| Step: 4
Training loss: 3.340054618023393
Validation loss: 3.153203765569288

Epoch: 6| Step: 5
Training loss: 3.6922638719354826
Validation loss: 3.154621368087068

Epoch: 6| Step: 6
Training loss: 3.9060758017798998
Validation loss: 3.153139052813062

Epoch: 6| Step: 7
Training loss: 3.2587413607162015
Validation loss: 3.152206828412323

Epoch: 6| Step: 8
Training loss: 3.2471597438342235
Validation loss: 3.1512731437439965

Epoch: 6| Step: 9
Training loss: 3.857516810540625
Validation loss: 3.1497301543104306

Epoch: 6| Step: 10
Training loss: 3.149837816695389
Validation loss: 3.150199706190619

Epoch: 6| Step: 11
Training loss: 3.506632787035562
Validation loss: 3.1505013325580817

Epoch: 6| Step: 12
Training loss: 3.311731501269241
Validation loss: 3.149058149379541

Epoch: 6| Step: 13
Training loss: 3.7328559627054543
Validation loss: 3.1499328482092155

Epoch: 75| Step: 0
Training loss: 2.909005284403922
Validation loss: 3.1491613850303444

Epoch: 6| Step: 1
Training loss: 3.405004151015475
Validation loss: 3.1486655523973575

Epoch: 6| Step: 2
Training loss: 3.531642520660577
Validation loss: 3.148199177185741

Epoch: 6| Step: 3
Training loss: 3.5509242667928778
Validation loss: 3.1485641373819537

Epoch: 6| Step: 4
Training loss: 4.1686661055557535
Validation loss: 3.1476529997810005

Epoch: 6| Step: 5
Training loss: 2.9230357429754283
Validation loss: 3.14750290895692

Epoch: 6| Step: 6
Training loss: 3.9504168133587596
Validation loss: 3.1466844256713165

Epoch: 6| Step: 7
Training loss: 3.363961712522946
Validation loss: 3.146067630089162

Epoch: 6| Step: 8
Training loss: 4.023631622668323
Validation loss: 3.145366943531107

Epoch: 6| Step: 9
Training loss: 3.468055449362584
Validation loss: 3.1452517613981437

Epoch: 6| Step: 10
Training loss: 2.4695316477615052
Validation loss: 3.1445646872883075

Epoch: 6| Step: 11
Training loss: 3.515491805202551
Validation loss: 3.1449019018783972

Epoch: 6| Step: 12
Training loss: 2.7586860461960963
Validation loss: 3.1442415045212275

Epoch: 6| Step: 13
Training loss: 2.713328601479993
Validation loss: 3.145117357892196

Epoch: 76| Step: 0
Training loss: 4.19547707574078
Validation loss: 3.1498447771269307

Epoch: 6| Step: 1
Training loss: 3.1575751213989878
Validation loss: 3.1474928368357054

Epoch: 6| Step: 2
Training loss: 3.6982420585638347
Validation loss: 3.1455097554986353

Epoch: 6| Step: 3
Training loss: 3.9568522978646423
Validation loss: 3.1428471597583005

Epoch: 6| Step: 4
Training loss: 3.560993612264953
Validation loss: 3.1427054993557273

Epoch: 6| Step: 5
Training loss: 3.5045414479640624
Validation loss: 3.1421658666352306

Epoch: 6| Step: 6
Training loss: 2.7930670874296615
Validation loss: 3.1400813105205345

Epoch: 6| Step: 7
Training loss: 2.1440595931553452
Validation loss: 3.139515263944283

Epoch: 6| Step: 8
Training loss: 3.6475899669697895
Validation loss: 3.1392929296136174

Epoch: 6| Step: 9
Training loss: 3.67025188527534
Validation loss: 3.13962760266043

Epoch: 6| Step: 10
Training loss: 3.1400886950752604
Validation loss: 3.1385094959086017

Epoch: 6| Step: 11
Training loss: 2.9471620777867207
Validation loss: 3.139075373489145

Epoch: 6| Step: 12
Training loss: 3.4905358831629205
Validation loss: 3.1397998672568526

Epoch: 6| Step: 13
Training loss: 2.8178270541768486
Validation loss: 3.137637084376938

Epoch: 77| Step: 0
Training loss: 3.5742681114248596
Validation loss: 3.1385744449592794

Epoch: 6| Step: 1
Training loss: 3.451534681782279
Validation loss: 3.138376309148492

Epoch: 6| Step: 2
Training loss: 3.1628382445373964
Validation loss: 3.138620078553869

Epoch: 6| Step: 3
Training loss: 3.841568490606093
Validation loss: 3.1374368000124346

Epoch: 6| Step: 4
Training loss: 2.7256156785819132
Validation loss: 3.136633007506295

Epoch: 6| Step: 5
Training loss: 3.2138713418197096
Validation loss: 3.136746296162557

Epoch: 6| Step: 6
Training loss: 3.8490982684076016
Validation loss: 3.1338284438630355

Epoch: 6| Step: 7
Training loss: 3.144891981201468
Validation loss: 3.1361097597877596

Epoch: 6| Step: 8
Training loss: 3.3249619904833767
Validation loss: 3.133669825738637

Epoch: 6| Step: 9
Training loss: 3.0878934045884074
Validation loss: 3.133563269465149

Epoch: 6| Step: 10
Training loss: 3.5191001162302498
Validation loss: 3.135772958471286

Epoch: 6| Step: 11
Training loss: 3.790253316420516
Validation loss: 3.1396723668563125

Epoch: 6| Step: 12
Training loss: 3.0764474702935503
Validation loss: 3.140940947892885

Epoch: 6| Step: 13
Training loss: 3.478995237105427
Validation loss: 3.151335566554069

Epoch: 78| Step: 0
Training loss: 3.942408091284759
Validation loss: 3.1524870835171774

Epoch: 6| Step: 1
Training loss: 2.7601527153832537
Validation loss: 3.1535824980803473

Epoch: 6| Step: 2
Training loss: 3.6426473738809655
Validation loss: 3.1582169813758934

Epoch: 6| Step: 3
Training loss: 2.210206790587574
Validation loss: 3.14107023644287

Epoch: 6| Step: 4
Training loss: 3.799762899129314
Validation loss: 3.1313384822711336

Epoch: 6| Step: 5
Training loss: 3.610552178840906
Validation loss: 3.130023906571516

Epoch: 6| Step: 6
Training loss: 3.325930592806546
Validation loss: 3.1312859570302525

Epoch: 6| Step: 7
Training loss: 3.432788741490098
Validation loss: 3.131010158857912

Epoch: 6| Step: 8
Training loss: 2.581240903824488
Validation loss: 3.1308163533921007

Epoch: 6| Step: 9
Training loss: 3.687906275205777
Validation loss: 3.131948833242555

Epoch: 6| Step: 10
Training loss: 3.3406982756411976
Validation loss: 3.1308024379780806

Epoch: 6| Step: 11
Training loss: 3.8944093002158136
Validation loss: 3.1306866315591253

Epoch: 6| Step: 12
Training loss: 3.0862338539464433
Validation loss: 3.1294287852246825

Epoch: 6| Step: 13
Training loss: 3.8021354497533992
Validation loss: 3.1293764614074115

Epoch: 79| Step: 0
Training loss: 3.5403048122233978
Validation loss: 3.1291003343517487

Epoch: 6| Step: 1
Training loss: 3.135414774103111
Validation loss: 3.1274412009089825

Epoch: 6| Step: 2
Training loss: 2.764460000394384
Validation loss: 3.1297442857483353

Epoch: 6| Step: 3
Training loss: 3.7397336938465435
Validation loss: 3.130777847978506

Epoch: 6| Step: 4
Training loss: 3.5333019135235775
Validation loss: 3.1312901369929604

Epoch: 6| Step: 5
Training loss: 2.9802853989106413
Validation loss: 3.1310989947037426

Epoch: 6| Step: 6
Training loss: 3.1462384062088513
Validation loss: 3.132533543839599

Epoch: 6| Step: 7
Training loss: 3.532169458646446
Validation loss: 3.1315295366729368

Epoch: 6| Step: 8
Training loss: 2.867606566360454
Validation loss: 3.1282994414186636

Epoch: 6| Step: 9
Training loss: 3.5746653793695
Validation loss: 3.1269132110415008

Epoch: 6| Step: 10
Training loss: 2.7865057159863516
Validation loss: 3.1268145701210988

Epoch: 6| Step: 11
Training loss: 3.881531901419
Validation loss: 3.126409866434818

Epoch: 6| Step: 12
Training loss: 4.148091734648897
Validation loss: 3.1258423209419495

Epoch: 6| Step: 13
Training loss: 3.315972289684
Validation loss: 3.1249776006736716

Epoch: 80| Step: 0
Training loss: 4.033255144942975
Validation loss: 3.1230226466903104

Epoch: 6| Step: 1
Training loss: 2.714076882051389
Validation loss: 3.12410585306611

Epoch: 6| Step: 2
Training loss: 2.8542365926451216
Validation loss: 3.125426939645985

Epoch: 6| Step: 3
Training loss: 3.202222594635367
Validation loss: 3.1230504852195864

Epoch: 6| Step: 4
Training loss: 3.7765016613227687
Validation loss: 3.1231052364215635

Epoch: 6| Step: 5
Training loss: 3.588140471703656
Validation loss: 3.122409696992167

Epoch: 6| Step: 6
Training loss: 3.2763385163145653
Validation loss: 3.1219892325953253

Epoch: 6| Step: 7
Training loss: 3.227337981869694
Validation loss: 3.1214525050808355

Epoch: 6| Step: 8
Training loss: 3.497720112067408
Validation loss: 3.12173284562379

Epoch: 6| Step: 9
Training loss: 3.011143967221263
Validation loss: 3.1208999168859

Epoch: 6| Step: 10
Training loss: 3.4607007912315484
Validation loss: 3.120322776983443

Epoch: 6| Step: 11
Training loss: 3.1603335412161546
Validation loss: 3.1186654966894647

Epoch: 6| Step: 12
Training loss: 4.044091876758738
Validation loss: 3.118786133202922

Epoch: 6| Step: 13
Training loss: 2.84429574278061
Validation loss: 3.1181609037462867

Epoch: 81| Step: 0
Training loss: 3.533877585138337
Validation loss: 3.1185516671167193

Epoch: 6| Step: 1
Training loss: 4.338974337700404
Validation loss: 3.1186968648348956

Epoch: 6| Step: 2
Training loss: 3.3212600612523877
Validation loss: 3.117430552132991

Epoch: 6| Step: 3
Training loss: 3.5926095230938757
Validation loss: 3.1172323709698633

Epoch: 6| Step: 4
Training loss: 3.58675971816888
Validation loss: 3.117729255689912

Epoch: 6| Step: 5
Training loss: 3.5238047744591325
Validation loss: 3.1157262317588685

Epoch: 6| Step: 6
Training loss: 3.318302758033047
Validation loss: 3.115202183196603

Epoch: 6| Step: 7
Training loss: 3.6307737474774013
Validation loss: 3.1150185507334878

Epoch: 6| Step: 8
Training loss: 2.469624907549824
Validation loss: 3.1138755122172266

Epoch: 6| Step: 9
Training loss: 2.643006734775214
Validation loss: 3.1140013998335396

Epoch: 6| Step: 10
Training loss: 3.2470452007957546
Validation loss: 3.1140327215218018

Epoch: 6| Step: 11
Training loss: 3.180536330237626
Validation loss: 3.1161076961833922

Epoch: 6| Step: 12
Training loss: 2.899629496880118
Validation loss: 3.1177012783727065

Epoch: 6| Step: 13
Training loss: 3.574633898362771
Validation loss: 3.117067330453518

Epoch: 82| Step: 0
Training loss: 3.4113093608137888
Validation loss: 3.116933785937816

Epoch: 6| Step: 1
Training loss: 3.5332812653309906
Validation loss: 3.1124894042266527

Epoch: 6| Step: 2
Training loss: 3.426576076329338
Validation loss: 3.1143563983874523

Epoch: 6| Step: 3
Training loss: 3.758324602092968
Validation loss: 3.110407950762579

Epoch: 6| Step: 4
Training loss: 3.385772185609463
Validation loss: 3.109432584967568

Epoch: 6| Step: 5
Training loss: 3.8707245651638393
Validation loss: 3.109424274276973

Epoch: 6| Step: 6
Training loss: 3.1131636191704675
Validation loss: 3.1098388484198125

Epoch: 6| Step: 7
Training loss: 3.7222009882787837
Validation loss: 3.1095417217315253

Epoch: 6| Step: 8
Training loss: 2.3164850900237295
Validation loss: 3.108088675333221

Epoch: 6| Step: 9
Training loss: 2.8822201169288233
Validation loss: 3.108712313561024

Epoch: 6| Step: 10
Training loss: 2.6381562560036715
Validation loss: 3.1088185564038957

Epoch: 6| Step: 11
Training loss: 3.9233660656112677
Validation loss: 3.1080985402684096

Epoch: 6| Step: 12
Training loss: 3.1615688717332873
Validation loss: 3.1075779934993872

Epoch: 6| Step: 13
Training loss: 3.727739000442483
Validation loss: 3.107822950368449

Epoch: 83| Step: 0
Training loss: 3.535481306274522
Validation loss: 3.106154558028536

Epoch: 6| Step: 1
Training loss: 3.0379269397983775
Validation loss: 3.10521469268845

Epoch: 6| Step: 2
Training loss: 2.6620810738820295
Validation loss: 3.106501856668376

Epoch: 6| Step: 3
Training loss: 3.009211702758961
Validation loss: 3.1079289530560157

Epoch: 6| Step: 4
Training loss: 3.631539858150122
Validation loss: 3.1057069368884784

Epoch: 6| Step: 5
Training loss: 3.3675677091479246
Validation loss: 3.1054934545488706

Epoch: 6| Step: 6
Training loss: 2.757446956452901
Validation loss: 3.1061902786363325

Epoch: 6| Step: 7
Training loss: 1.909784885495853
Validation loss: 3.108012798418066

Epoch: 6| Step: 8
Training loss: 3.8164673471392083
Validation loss: 3.1108994259638254

Epoch: 6| Step: 9
Training loss: 3.4258927399991674
Validation loss: 3.114327239970084

Epoch: 6| Step: 10
Training loss: 3.576781441256318
Validation loss: 3.1069764126145096

Epoch: 6| Step: 11
Training loss: 4.090623433321893
Validation loss: 3.102568822524431

Epoch: 6| Step: 12
Training loss: 4.238760953555499
Validation loss: 3.1033177960121647

Epoch: 6| Step: 13
Training loss: 3.194384451777343
Validation loss: 3.1148110243137883

Epoch: 84| Step: 0
Training loss: 3.4622309831577245
Validation loss: 3.1399533292239745

Epoch: 6| Step: 1
Training loss: 3.0761898560982415
Validation loss: 3.151932944619195

Epoch: 6| Step: 2
Training loss: 3.3924564038864977
Validation loss: 3.158892278985186

Epoch: 6| Step: 3
Training loss: 2.9430706690068718
Validation loss: 3.1352250202743126

Epoch: 6| Step: 4
Training loss: 3.912139481092033
Validation loss: 3.1052830030763943

Epoch: 6| Step: 5
Training loss: 3.5710379032632753
Validation loss: 3.100360530314181

Epoch: 6| Step: 6
Training loss: 3.1067739371033496
Validation loss: 3.100496888868691

Epoch: 6| Step: 7
Training loss: 3.271793362273957
Validation loss: 3.100056977663053

Epoch: 6| Step: 8
Training loss: 2.8994517235576125
Validation loss: 3.101863230817359

Epoch: 6| Step: 9
Training loss: 3.432538700427373
Validation loss: 3.1025445169283303

Epoch: 6| Step: 10
Training loss: 3.0773511194555865
Validation loss: 3.100235474713863

Epoch: 6| Step: 11
Training loss: 3.796693899600117
Validation loss: 3.101891503883026

Epoch: 6| Step: 12
Training loss: 3.096372937444199
Validation loss: 3.1043409100559596

Epoch: 6| Step: 13
Training loss: 4.36902602910456
Validation loss: 3.1047881608781402

Epoch: 85| Step: 0
Training loss: 2.983703857371923
Validation loss: 3.105256175110673

Epoch: 6| Step: 1
Training loss: 3.289145425580212
Validation loss: 3.1048865520369464

Epoch: 6| Step: 2
Training loss: 3.1687275722093693
Validation loss: 3.11042296954713

Epoch: 6| Step: 3
Training loss: 3.019012761971337
Validation loss: 3.118282433707592

Epoch: 6| Step: 4
Training loss: 3.4771031334375926
Validation loss: 3.110154653005898

Epoch: 6| Step: 5
Training loss: 3.806225976727221
Validation loss: 3.1002915805950457

Epoch: 6| Step: 6
Training loss: 3.1884494938073815
Validation loss: 3.095348180280201

Epoch: 6| Step: 7
Training loss: 3.1196962744256895
Validation loss: 3.096499215393221

Epoch: 6| Step: 8
Training loss: 3.157114646997652
Validation loss: 3.095160139635407

Epoch: 6| Step: 9
Training loss: 3.5382445613334395
Validation loss: 3.0949435119017124

Epoch: 6| Step: 10
Training loss: 3.626902114106817
Validation loss: 3.094996968671635

Epoch: 6| Step: 11
Training loss: 3.661036040623893
Validation loss: 3.094112222149199

Epoch: 6| Step: 12
Training loss: 3.435511204467677
Validation loss: 3.093885657223201

Epoch: 6| Step: 13
Training loss: 3.426948861650289
Validation loss: 3.093990020374145

Epoch: 86| Step: 0
Training loss: 3.6131490157391135
Validation loss: 3.0937946010178394

Epoch: 6| Step: 1
Training loss: 3.0200409650234747
Validation loss: 3.0931539101097756

Epoch: 6| Step: 2
Training loss: 3.3966202711456313
Validation loss: 3.0916374056121603

Epoch: 6| Step: 3
Training loss: 3.9600644927119544
Validation loss: 3.091489706792501

Epoch: 6| Step: 4
Training loss: 4.071094518356529
Validation loss: 3.0913643255105825

Epoch: 6| Step: 5
Training loss: 2.816434016203283
Validation loss: 3.091737884441096

Epoch: 6| Step: 6
Training loss: 3.0143803216838587
Validation loss: 3.0897769933471833

Epoch: 6| Step: 7
Training loss: 3.583374836407808
Validation loss: 3.0899458203887433

Epoch: 6| Step: 8
Training loss: 3.862384564795068
Validation loss: 3.0896985143935685

Epoch: 6| Step: 9
Training loss: 3.1477149910557327
Validation loss: 3.0885987414089064

Epoch: 6| Step: 10
Training loss: 2.4908250295228997
Validation loss: 3.088233847057784

Epoch: 6| Step: 11
Training loss: 2.2651210882227737
Validation loss: 3.0872750804717355

Epoch: 6| Step: 12
Training loss: 3.120013722120578
Validation loss: 3.086450499925709

Epoch: 6| Step: 13
Training loss: 4.329869769034269
Validation loss: 3.0872199952661887

Epoch: 87| Step: 0
Training loss: 3.4537725747606696
Validation loss: 3.0857444975938133

Epoch: 6| Step: 1
Training loss: 2.205554028928769
Validation loss: 3.0858611232807154

Epoch: 6| Step: 2
Training loss: 3.1248406941816524
Validation loss: 3.085894201039045

Epoch: 6| Step: 3
Training loss: 2.103952743180875
Validation loss: 3.084140576853632

Epoch: 6| Step: 4
Training loss: 4.2270430822259355
Validation loss: 3.085350903623806

Epoch: 6| Step: 5
Training loss: 2.9544881268254803
Validation loss: 3.0851967182716487

Epoch: 6| Step: 6
Training loss: 3.1966048707315955
Validation loss: 3.0850905677168488

Epoch: 6| Step: 7
Training loss: 3.4600437637824815
Validation loss: 3.0861221534455128

Epoch: 6| Step: 8
Training loss: 3.992503532546648
Validation loss: 3.0862612925026394

Epoch: 6| Step: 9
Training loss: 4.012455858599807
Validation loss: 3.08623618148178

Epoch: 6| Step: 10
Training loss: 2.5768662587678413
Validation loss: 3.084593465221425

Epoch: 6| Step: 11
Training loss: 3.99633478088463
Validation loss: 3.0846655965320173

Epoch: 6| Step: 12
Training loss: 3.5728924067408587
Validation loss: 3.0848087762173266

Epoch: 6| Step: 13
Training loss: 2.8239987447265773
Validation loss: 3.08638107499195

Epoch: 88| Step: 0
Training loss: 2.5173828428068505
Validation loss: 3.083339977312676

Epoch: 6| Step: 1
Training loss: 3.2288578172877562
Validation loss: 3.0866178104070094

Epoch: 6| Step: 2
Training loss: 4.115708492651584
Validation loss: 3.0889453589182363

Epoch: 6| Step: 3
Training loss: 3.1207606743035097
Validation loss: 3.085487683723237

Epoch: 6| Step: 4
Training loss: 3.738495536569908
Validation loss: 3.082887211236574

Epoch: 6| Step: 5
Training loss: 4.002036529908086
Validation loss: 3.0861738457912735

Epoch: 6| Step: 6
Training loss: 3.5629157108226344
Validation loss: 3.080448279746672

Epoch: 6| Step: 7
Training loss: 3.3067456052443367
Validation loss: 3.0807469183988254

Epoch: 6| Step: 8
Training loss: 3.1236267124131487
Validation loss: 3.08126774060005

Epoch: 6| Step: 9
Training loss: 2.5684767083464783
Validation loss: 3.079181761878576

Epoch: 6| Step: 10
Training loss: 2.833556633919964
Validation loss: 3.0789358002840563

Epoch: 6| Step: 11
Training loss: 3.19847342317699
Validation loss: 3.0786898406895924

Epoch: 6| Step: 12
Training loss: 3.7862964090026248
Validation loss: 3.077012473954071

Epoch: 6| Step: 13
Training loss: 3.0479371395888015
Validation loss: 3.076533779374644

Epoch: 89| Step: 0
Training loss: 3.3275757815518214
Validation loss: 3.076595661266241

Epoch: 6| Step: 1
Training loss: 3.0289017538293623
Validation loss: 3.077365449846179

Epoch: 6| Step: 2
Training loss: 3.7018762728450456
Validation loss: 3.077169280480281

Epoch: 6| Step: 3
Training loss: 2.963148273086154
Validation loss: 3.075321264631493

Epoch: 6| Step: 4
Training loss: 3.397607320475748
Validation loss: 3.0744534150526004

Epoch: 6| Step: 5
Training loss: 2.852656575217706
Validation loss: 3.0756619250976454

Epoch: 6| Step: 6
Training loss: 3.1982869152406743
Validation loss: 3.0781881033283756

Epoch: 6| Step: 7
Training loss: 3.662314968187266
Validation loss: 3.085917134942734

Epoch: 6| Step: 8
Training loss: 2.9560651725429343
Validation loss: 3.091409077046583

Epoch: 6| Step: 9
Training loss: 4.0126448085240485
Validation loss: 3.1209875323835155

Epoch: 6| Step: 10
Training loss: 3.356460229409317
Validation loss: 3.1483819035967713

Epoch: 6| Step: 11
Training loss: 3.3850383527603056
Validation loss: 3.0978029464101806

Epoch: 6| Step: 12
Training loss: 3.3900536965587666
Validation loss: 3.0730811863249694

Epoch: 6| Step: 13
Training loss: 3.4521285470608025
Validation loss: 3.0753085219329033

Epoch: 90| Step: 0
Training loss: 3.7607025009672395
Validation loss: 3.0750906591342795

Epoch: 6| Step: 1
Training loss: 2.151975735254585
Validation loss: 3.0968256718790275

Epoch: 6| Step: 2
Training loss: 3.692595501221943
Validation loss: 3.1629017602706786

Epoch: 6| Step: 3
Training loss: 3.102923423773734
Validation loss: 3.177612511299339

Epoch: 6| Step: 4
Training loss: 3.729895295010728
Validation loss: 3.1738494849105474

Epoch: 6| Step: 5
Training loss: 3.4304010782884213
Validation loss: 3.149961391367976

Epoch: 6| Step: 6
Training loss: 3.55869612143504
Validation loss: 3.1310489627256617

Epoch: 6| Step: 7
Training loss: 3.51649728761848
Validation loss: 3.1004942214548716

Epoch: 6| Step: 8
Training loss: 2.6251232481587756
Validation loss: 3.0727563336847084

Epoch: 6| Step: 9
Training loss: 3.5573076924549034
Validation loss: 3.0748866609511416

Epoch: 6| Step: 10
Training loss: 3.2001695349606454
Validation loss: 3.077424393518155

Epoch: 6| Step: 11
Training loss: 3.5356086230762718
Validation loss: 3.079257799743979

Epoch: 6| Step: 12
Training loss: 3.1748610098145438
Validation loss: 3.091056696315025

Epoch: 6| Step: 13
Training loss: 4.074595125831906
Validation loss: 3.100943624328644

Epoch: 91| Step: 0
Training loss: 3.494446026253018
Validation loss: 3.0775093090414765

Epoch: 6| Step: 1
Training loss: 2.9109809679767493
Validation loss: 3.072691041322213

Epoch: 6| Step: 2
Training loss: 3.5406143120977256
Validation loss: 3.072492364894145

Epoch: 6| Step: 3
Training loss: 3.150374883717648
Validation loss: 3.069506547797908

Epoch: 6| Step: 4
Training loss: 3.7707440416642686
Validation loss: 3.068592118815686

Epoch: 6| Step: 5
Training loss: 2.6611884491030326
Validation loss: 3.068719088825152

Epoch: 6| Step: 6
Training loss: 2.885506051305237
Validation loss: 3.0669667641060716

Epoch: 6| Step: 7
Training loss: 3.741449908553219
Validation loss: 3.065896701846936

Epoch: 6| Step: 8
Training loss: 2.8744707034959234
Validation loss: 3.066464641875421

Epoch: 6| Step: 9
Training loss: 3.605337287266762
Validation loss: 3.066958893374807

Epoch: 6| Step: 10
Training loss: 2.998933284575853
Validation loss: 3.064690817299645

Epoch: 6| Step: 11
Training loss: 3.941941314763644
Validation loss: 3.0648177841477757

Epoch: 6| Step: 12
Training loss: 3.4936562677410703
Validation loss: 3.0641980949596217

Epoch: 6| Step: 13
Training loss: 3.2508935433602297
Validation loss: 3.0636941282304258

Epoch: 92| Step: 0
Training loss: 1.9777475656864025
Validation loss: 3.0622593406559764

Epoch: 6| Step: 1
Training loss: 3.771969337832278
Validation loss: 3.0615764930674434

Epoch: 6| Step: 2
Training loss: 3.108618256001829
Validation loss: 3.0611045810855697

Epoch: 6| Step: 3
Training loss: 3.5723318320135906
Validation loss: 3.0621257818709946

Epoch: 6| Step: 4
Training loss: 3.6286300373386067
Validation loss: 3.0643410070259622

Epoch: 6| Step: 5
Training loss: 3.2265400366197468
Validation loss: 3.0595619853518374

Epoch: 6| Step: 6
Training loss: 3.4825215563411605
Validation loss: 3.061100566161891

Epoch: 6| Step: 7
Training loss: 3.363666578808541
Validation loss: 3.0581211228931844

Epoch: 6| Step: 8
Training loss: 3.5427262161163964
Validation loss: 3.060008730231484

Epoch: 6| Step: 9
Training loss: 3.210757805095769
Validation loss: 3.0589747343729172

Epoch: 6| Step: 10
Training loss: 3.670332694292439
Validation loss: 3.0596733869424986

Epoch: 6| Step: 11
Training loss: 3.3257118036834865
Validation loss: 3.0598116533704105

Epoch: 6| Step: 12
Training loss: 3.6448779498311104
Validation loss: 3.058621099568715

Epoch: 6| Step: 13
Training loss: 1.8580192944907625
Validation loss: 3.05885474191946

Epoch: 93| Step: 0
Training loss: 3.3916597677124742
Validation loss: 3.0569898228506296

Epoch: 6| Step: 1
Training loss: 3.558856372375713
Validation loss: 3.057528869569347

Epoch: 6| Step: 2
Training loss: 2.332447519642139
Validation loss: 3.057934475120213

Epoch: 6| Step: 3
Training loss: 4.103147945063891
Validation loss: 3.0567918124867433

Epoch: 6| Step: 4
Training loss: 2.7542069074852567
Validation loss: 3.0554470174112733

Epoch: 6| Step: 5
Training loss: 3.0751021205413345
Validation loss: 3.0561017319874635

Epoch: 6| Step: 6
Training loss: 4.15140038268162
Validation loss: 3.0555992699147065

Epoch: 6| Step: 7
Training loss: 3.4735810600674593
Validation loss: 3.054501798127777

Epoch: 6| Step: 8
Training loss: 2.969122933504555
Validation loss: 3.0547173049110956

Epoch: 6| Step: 9
Training loss: 2.9196587791692004
Validation loss: 3.054450676830596

Epoch: 6| Step: 10
Training loss: 3.4055722463536546
Validation loss: 3.0535026849797813

Epoch: 6| Step: 11
Training loss: 3.248607924239946
Validation loss: 3.0531137663023435

Epoch: 6| Step: 12
Training loss: 3.2086901445679756
Validation loss: 3.05235580666668

Epoch: 6| Step: 13
Training loss: 3.6145646738822155
Validation loss: 3.051636820518203

Epoch: 94| Step: 0
Training loss: 3.8136263574933333
Validation loss: 3.0507233125632767

Epoch: 6| Step: 1
Training loss: 2.73181485897307
Validation loss: 3.050550908861411

Epoch: 6| Step: 2
Training loss: 3.3337302130622217
Validation loss: 3.0526581030909843

Epoch: 6| Step: 3
Training loss: 3.0626208223137144
Validation loss: 3.0527632147613497

Epoch: 6| Step: 4
Training loss: 3.149470838877764
Validation loss: 3.052492065567189

Epoch: 6| Step: 5
Training loss: 3.686364855860703
Validation loss: 3.05159707910049

Epoch: 6| Step: 6
Training loss: 2.6997629768037803
Validation loss: 3.0532936088511353

Epoch: 6| Step: 7
Training loss: 2.690412141220007
Validation loss: 3.0551843078945633

Epoch: 6| Step: 8
Training loss: 3.4702480621057665
Validation loss: 3.0531180050074602

Epoch: 6| Step: 9
Training loss: 3.7536560038695264
Validation loss: 3.053374024311827

Epoch: 6| Step: 10
Training loss: 3.3221617093169264
Validation loss: 3.0565274639059448

Epoch: 6| Step: 11
Training loss: 3.3291449618119384
Validation loss: 3.0504267191153174

Epoch: 6| Step: 12
Training loss: 3.7449876984214683
Validation loss: 3.052431808972737

Epoch: 6| Step: 13
Training loss: 3.409109612615892
Validation loss: 3.0502807766335103

Epoch: 95| Step: 0
Training loss: 3.223674673359302
Validation loss: 3.046789409906689

Epoch: 6| Step: 1
Training loss: 3.2625013680290773
Validation loss: 3.0492781239559603

Epoch: 6| Step: 2
Training loss: 4.199379084875088
Validation loss: 3.049816470892278

Epoch: 6| Step: 3
Training loss: 3.4839781120304734
Validation loss: 3.0501203738833795

Epoch: 6| Step: 4
Training loss: 2.9471811695777164
Validation loss: 3.048806482843026

Epoch: 6| Step: 5
Training loss: 3.025219138538833
Validation loss: 3.047963802557546

Epoch: 6| Step: 6
Training loss: 3.3644655913703647
Validation loss: 3.0487328960056628

Epoch: 6| Step: 7
Training loss: 2.8511527825304372
Validation loss: 3.0466571125197457

Epoch: 6| Step: 8
Training loss: 3.102093629497574
Validation loss: 3.04754499542171

Epoch: 6| Step: 9
Training loss: 3.6477745483066024
Validation loss: 3.046904347890779

Epoch: 6| Step: 10
Training loss: 2.9532942143153624
Validation loss: 3.0463408543338484

Epoch: 6| Step: 11
Training loss: 3.7908923577653932
Validation loss: 3.045383103472547

Epoch: 6| Step: 12
Training loss: 2.984879535947173
Validation loss: 3.0438172888617743

Epoch: 6| Step: 13
Training loss: 3.2299622734866382
Validation loss: 3.0429246677516253

Epoch: 96| Step: 0
Training loss: 3.3261832003532232
Validation loss: 3.0445956395640215

Epoch: 6| Step: 1
Training loss: 3.6605676442193054
Validation loss: 3.0442838485471695

Epoch: 6| Step: 2
Training loss: 3.2317289134013634
Validation loss: 3.04459079957217

Epoch: 6| Step: 3
Training loss: 2.850422168717643
Validation loss: 3.043405847835092

Epoch: 6| Step: 4
Training loss: 3.2265820075454483
Validation loss: 3.0425879083103653

Epoch: 6| Step: 5
Training loss: 2.751517830637202
Validation loss: 3.0430078627300405

Epoch: 6| Step: 6
Training loss: 3.4292164263971827
Validation loss: 3.0421925886688768

Epoch: 6| Step: 7
Training loss: 3.083962419273492
Validation loss: 3.04194397841466

Epoch: 6| Step: 8
Training loss: 3.7382968117002378
Validation loss: 3.043476675091817

Epoch: 6| Step: 9
Training loss: 3.388381145219398
Validation loss: 3.040405383342101

Epoch: 6| Step: 10
Training loss: 3.699687666211115
Validation loss: 3.041282010560287

Epoch: 6| Step: 11
Training loss: 2.8012514451247457
Validation loss: 3.041966913305554

Epoch: 6| Step: 12
Training loss: 3.0888735167793993
Validation loss: 3.0397368082466003

Epoch: 6| Step: 13
Training loss: 4.141926341420019
Validation loss: 3.039667900284546

Epoch: 97| Step: 0
Training loss: 3.3156183787431677
Validation loss: 3.0408892855328205

Epoch: 6| Step: 1
Training loss: 3.88695355956862
Validation loss: 3.0386376705455294

Epoch: 6| Step: 2
Training loss: 3.5650521221871543
Validation loss: 3.039924478882734

Epoch: 6| Step: 3
Training loss: 2.622767270908464
Validation loss: 3.0393070778718054

Epoch: 6| Step: 4
Training loss: 2.9387986579348855
Validation loss: 3.0384155128005275

Epoch: 6| Step: 5
Training loss: 3.7339023945438075
Validation loss: 3.0390516618834367

Epoch: 6| Step: 6
Training loss: 3.391163304222933
Validation loss: 3.037921073150739

Epoch: 6| Step: 7
Training loss: 3.074878045121563
Validation loss: 3.03771861116918

Epoch: 6| Step: 8
Training loss: 3.970023604161887
Validation loss: 3.0360825260572786

Epoch: 6| Step: 9
Training loss: 3.411312715562643
Validation loss: 3.0353651354041475

Epoch: 6| Step: 10
Training loss: 2.8738377751256694
Validation loss: 3.0356597674892822

Epoch: 6| Step: 11
Training loss: 2.8018636700113713
Validation loss: 3.036006421835098

Epoch: 6| Step: 12
Training loss: 3.417342018432932
Validation loss: 3.0366288822872005

Epoch: 6| Step: 13
Training loss: 2.52429014746645
Validation loss: 3.0329076701792888

Epoch: 98| Step: 0
Training loss: 3.50711344866705
Validation loss: 3.0337510425684764

Epoch: 6| Step: 1
Training loss: 3.425436874705586
Validation loss: 3.038995478181774

Epoch: 6| Step: 2
Training loss: 3.875924277055067
Validation loss: 3.034065590669372

Epoch: 6| Step: 3
Training loss: 3.0853552160297575
Validation loss: 3.0315064614688314

Epoch: 6| Step: 4
Training loss: 2.868162067478877
Validation loss: 3.0341139519725875

Epoch: 6| Step: 5
Training loss: 3.262945070272592
Validation loss: 3.0319547105729243

Epoch: 6| Step: 6
Training loss: 2.9498909493673118
Validation loss: 3.034347762880985

Epoch: 6| Step: 7
Training loss: 2.8919842797534048
Validation loss: 3.045854643423722

Epoch: 6| Step: 8
Training loss: 3.501813554934493
Validation loss: 3.0422754261498652

Epoch: 6| Step: 9
Training loss: 3.4113659717588094
Validation loss: 3.0297029837808207

Epoch: 6| Step: 10
Training loss: 3.6539953077815452
Validation loss: 3.0299425298216325

Epoch: 6| Step: 11
Training loss: 3.3779116186456606
Validation loss: 3.030934033060235

Epoch: 6| Step: 12
Training loss: 2.811626213821382
Validation loss: 3.0304655644357874

Epoch: 6| Step: 13
Training loss: 3.444743483561803
Validation loss: 3.029234747079219

Epoch: 99| Step: 0
Training loss: 3.124737232604871
Validation loss: 3.029140581226662

Epoch: 6| Step: 1
Training loss: 3.606651963387896
Validation loss: 3.0298244895152524

Epoch: 6| Step: 2
Training loss: 3.4691790066298833
Validation loss: 3.0303730907246558

Epoch: 6| Step: 3
Training loss: 3.7425526737438273
Validation loss: 3.029424989291172

Epoch: 6| Step: 4
Training loss: 3.3550290406927332
Validation loss: 3.0296351862725013

Epoch: 6| Step: 5
Training loss: 2.309760765304111
Validation loss: 3.03100064106936

Epoch: 6| Step: 6
Training loss: 2.995847530269453
Validation loss: 3.026803014482731

Epoch: 6| Step: 7
Training loss: 3.144639519195877
Validation loss: 3.0307536114658205

Epoch: 6| Step: 8
Training loss: 3.5412227277584183
Validation loss: 3.02827745279456

Epoch: 6| Step: 9
Training loss: 3.8905340590055535
Validation loss: 3.028399794534835

Epoch: 6| Step: 10
Training loss: 2.4997918042276326
Validation loss: 3.0262528071325447

Epoch: 6| Step: 11
Training loss: 3.0236377896150337
Validation loss: 3.028492327653211

Epoch: 6| Step: 12
Training loss: 3.694852449519231
Validation loss: 3.0276717097181463

Epoch: 6| Step: 13
Training loss: 3.3558097905849698
Validation loss: 3.024742750936468

Epoch: 100| Step: 0
Training loss: 2.985487485916572
Validation loss: 3.024132097665898

Epoch: 6| Step: 1
Training loss: 2.7443452263304917
Validation loss: 3.0259544717652607

Epoch: 6| Step: 2
Training loss: 2.8629694791040388
Validation loss: 3.023592077404894

Epoch: 6| Step: 3
Training loss: 3.2816997401513257
Validation loss: 3.0226334811786786

Epoch: 6| Step: 4
Training loss: 3.9426707875300435
Validation loss: 3.0232229663043584

Epoch: 6| Step: 5
Training loss: 3.006013565124239
Validation loss: 3.0220151824848855

Epoch: 6| Step: 6
Training loss: 3.062006696557933
Validation loss: 3.023439865702805

Epoch: 6| Step: 7
Training loss: 3.788983216390238
Validation loss: 3.0226707477252805

Epoch: 6| Step: 8
Training loss: 4.2995916483179135
Validation loss: 3.0235161081757647

Epoch: 6| Step: 9
Training loss: 3.4157435558017912
Validation loss: 3.0222452300528224

Epoch: 6| Step: 10
Training loss: 2.8596963337097026
Validation loss: 3.0244336024346135

Epoch: 6| Step: 11
Training loss: 3.3559947906017222
Validation loss: 3.0207650764966028

Epoch: 6| Step: 12
Training loss: 2.6739935256035086
Validation loss: 3.0194815123353784

Epoch: 6| Step: 13
Training loss: 3.3582898183674366
Validation loss: 3.0215022539194116

Epoch: 101| Step: 0
Training loss: 3.5804185471333168
Validation loss: 3.0188449503717

Epoch: 6| Step: 1
Training loss: 3.8432582137438756
Validation loss: 3.019066727637058

Epoch: 6| Step: 2
Training loss: 2.8581301788409954
Validation loss: 3.0187717066100994

Epoch: 6| Step: 3
Training loss: 3.558673342705538
Validation loss: 3.0189781939556672

Epoch: 6| Step: 4
Training loss: 3.4824489864164794
Validation loss: 3.016606961553884

Epoch: 6| Step: 5
Training loss: 3.7646794695138004
Validation loss: 3.017517937538094

Epoch: 6| Step: 6
Training loss: 2.6274756610298406
Validation loss: 3.0162138489651205

Epoch: 6| Step: 7
Training loss: 2.3877891724905664
Validation loss: 3.015912183786415

Epoch: 6| Step: 8
Training loss: 2.8390645423424132
Validation loss: 3.0169256857737774

Epoch: 6| Step: 9
Training loss: 3.0200441228409645
Validation loss: 3.0159950392740957

Epoch: 6| Step: 10
Training loss: 4.312373947291595
Validation loss: 3.0150657082882173

Epoch: 6| Step: 11
Training loss: 2.5090998972667693
Validation loss: 3.015300068646201

Epoch: 6| Step: 12
Training loss: 3.493142631023507
Validation loss: 3.012973400689222

Epoch: 6| Step: 13
Training loss: 2.941655567641748
Validation loss: 3.012873381276075

Epoch: 102| Step: 0
Training loss: 3.547466615246929
Validation loss: 3.014206181179397

Epoch: 6| Step: 1
Training loss: 3.080004897423356
Validation loss: 3.01452660751341

Epoch: 6| Step: 2
Training loss: 3.2190798988534963
Validation loss: 3.0126470405068715

Epoch: 6| Step: 3
Training loss: 3.768390826923141
Validation loss: 3.01259081283284

Epoch: 6| Step: 4
Training loss: 3.386622162423867
Validation loss: 3.011606744153679

Epoch: 6| Step: 5
Training loss: 2.9371022705933827
Validation loss: 3.013649614581914

Epoch: 6| Step: 6
Training loss: 3.321087914970762
Validation loss: 3.012376500674049

Epoch: 6| Step: 7
Training loss: 2.878285231049358
Validation loss: 3.0125068084771933

Epoch: 6| Step: 8
Training loss: 2.8108782012944293
Validation loss: 3.010773857946139

Epoch: 6| Step: 9
Training loss: 3.123714182489217
Validation loss: 3.011370306036299

Epoch: 6| Step: 10
Training loss: 3.1819361578137206
Validation loss: 3.011713466461694

Epoch: 6| Step: 11
Training loss: 3.333403936274175
Validation loss: 3.011809276077211

Epoch: 6| Step: 12
Training loss: 3.7563136039845624
Validation loss: 3.012225443115325

Epoch: 6| Step: 13
Training loss: 3.532777708979784
Validation loss: 3.0111749659633005

Epoch: 103| Step: 0
Training loss: 3.339389988820791
Validation loss: 3.0109734471496177

Epoch: 6| Step: 1
Training loss: 3.319805223197696
Validation loss: 3.0109623853183187

Epoch: 6| Step: 2
Training loss: 3.4640472425538626
Validation loss: 3.0084236400981035

Epoch: 6| Step: 3
Training loss: 3.7754343250348517
Validation loss: 3.0071692744355523

Epoch: 6| Step: 4
Training loss: 3.883419242749051
Validation loss: 3.0080060675238456

Epoch: 6| Step: 5
Training loss: 3.7708290198426138
Validation loss: 3.0075712646603954

Epoch: 6| Step: 6
Training loss: 2.898507089113651
Validation loss: 3.008087140550575

Epoch: 6| Step: 7
Training loss: 2.704847371419197
Validation loss: 3.007723142385675

Epoch: 6| Step: 8
Training loss: 2.810612023654237
Validation loss: 3.0057990211162706

Epoch: 6| Step: 9
Training loss: 3.198075645711552
Validation loss: 3.0082814343685174

Epoch: 6| Step: 10
Training loss: 2.795510326739638
Validation loss: 3.0045116964470533

Epoch: 6| Step: 11
Training loss: 2.7308963118892455
Validation loss: 3.0036813553177013

Epoch: 6| Step: 12
Training loss: 3.7772749506968144
Validation loss: 3.0028352371650353

Epoch: 6| Step: 13
Training loss: 2.90187399593667
Validation loss: 3.004444255437277

Epoch: 104| Step: 0
Training loss: 3.119311839774883
Validation loss: 3.007607065064237

Epoch: 6| Step: 1
Training loss: 3.4326078802772115
Validation loss: 3.0081363498840283

Epoch: 6| Step: 2
Training loss: 3.9955376529917235
Validation loss: 3.010289010055967

Epoch: 6| Step: 3
Training loss: 2.2212021937080046
Validation loss: 3.004616855086085

Epoch: 6| Step: 4
Training loss: 3.414610236114101
Validation loss: 3.0028865507709055

Epoch: 6| Step: 5
Training loss: 3.3042219839640805
Validation loss: 3.0036150760801696

Epoch: 6| Step: 6
Training loss: 2.671338211480981
Validation loss: 3.00392866454987

Epoch: 6| Step: 7
Training loss: 2.7563382712002538
Validation loss: 3.0029491811233484

Epoch: 6| Step: 8
Training loss: 3.3511575663196975
Validation loss: 2.9999232060164243

Epoch: 6| Step: 9
Training loss: 3.4590089130446686
Validation loss: 3.0004045323088215

Epoch: 6| Step: 10
Training loss: 4.021025236356521
Validation loss: 3.000470200644553

Epoch: 6| Step: 11
Training loss: 2.8381678530497383
Validation loss: 3.0004457481003164

Epoch: 6| Step: 12
Training loss: 3.461713785638437
Validation loss: 2.9989964813228305

Epoch: 6| Step: 13
Training loss: 3.3332508712741094
Validation loss: 2.9985681504248625

Epoch: 105| Step: 0
Training loss: 3.1041043337168306
Validation loss: 2.9967439475977544

Epoch: 6| Step: 1
Training loss: 3.5805944724903185
Validation loss: 2.9989085784299765

Epoch: 6| Step: 2
Training loss: 3.341990355481717
Validation loss: 2.9964204680580053

Epoch: 6| Step: 3
Training loss: 3.378671132986744
Validation loss: 3.0003662757416287

Epoch: 6| Step: 4
Training loss: 3.2478897873355725
Validation loss: 2.9972648902402566

Epoch: 6| Step: 5
Training loss: 2.9580850273121957
Validation loss: 2.9981332734214616

Epoch: 6| Step: 6
Training loss: 3.3601682214406163
Validation loss: 2.9998048373630937

Epoch: 6| Step: 7
Training loss: 3.14179249788914
Validation loss: 3.0000259165857863

Epoch: 6| Step: 8
Training loss: 3.616287547924316
Validation loss: 2.996885180686736

Epoch: 6| Step: 9
Training loss: 3.2256697558081107
Validation loss: 2.9965558055485393

Epoch: 6| Step: 10
Training loss: 3.63219172598501
Validation loss: 2.99684435648161

Epoch: 6| Step: 11
Training loss: 2.041340458040036
Validation loss: 2.9958571606545275

Epoch: 6| Step: 12
Training loss: 3.459012772945963
Validation loss: 2.9950030645561303

Epoch: 6| Step: 13
Training loss: 3.4846802992562895
Validation loss: 2.9944154690174103

Epoch: 106| Step: 0
Training loss: 3.0749498440753635
Validation loss: 2.9957418917953866

Epoch: 6| Step: 1
Training loss: 3.561072749623741
Validation loss: 2.992655200872864

Epoch: 6| Step: 2
Training loss: 3.007348755595327
Validation loss: 2.9934358205743976

Epoch: 6| Step: 3
Training loss: 3.1890214766948186
Validation loss: 2.9929144187391694

Epoch: 6| Step: 4
Training loss: 3.5068366173680072
Validation loss: 2.9958608077675746

Epoch: 6| Step: 5
Training loss: 3.11537243767339
Validation loss: 2.991058223044607

Epoch: 6| Step: 6
Training loss: 2.605750759253107
Validation loss: 2.9945767898122924

Epoch: 6| Step: 7
Training loss: 3.401037304784403
Validation loss: 2.9951864596358164

Epoch: 6| Step: 8
Training loss: 3.666130344585584
Validation loss: 2.9942548047880906

Epoch: 6| Step: 9
Training loss: 3.536783389778885
Validation loss: 2.992491525961563

Epoch: 6| Step: 10
Training loss: 2.6045121434251413
Validation loss: 2.99481803179777

Epoch: 6| Step: 11
Training loss: 3.085808937195399
Validation loss: 2.9967825558079473

Epoch: 6| Step: 12
Training loss: 3.643934979986155
Validation loss: 2.991744030507922

Epoch: 6| Step: 13
Training loss: 3.598831564643762
Validation loss: 2.9906916302462703

Epoch: 107| Step: 0
Training loss: 2.9319706272980257
Validation loss: 2.989309313719002

Epoch: 6| Step: 1
Training loss: 3.19964842653154
Validation loss: 2.988098404027786

Epoch: 6| Step: 2
Training loss: 2.8812752943935296
Validation loss: 2.988562073160728

Epoch: 6| Step: 3
Training loss: 2.895310023019043
Validation loss: 2.9889702257041

Epoch: 6| Step: 4
Training loss: 2.794822749759935
Validation loss: 2.9893716659524388

Epoch: 6| Step: 5
Training loss: 3.4272016757989485
Validation loss: 2.988364567896394

Epoch: 6| Step: 6
Training loss: 3.41618675645171
Validation loss: 2.9887468704873763

Epoch: 6| Step: 7
Training loss: 3.4717824242006827
Validation loss: 2.988831709901265

Epoch: 6| Step: 8
Training loss: 3.4498613910197227
Validation loss: 2.987074976038036

Epoch: 6| Step: 9
Training loss: 2.413566859452289
Validation loss: 2.9861699780474846

Epoch: 6| Step: 10
Training loss: 3.0793820055941343
Validation loss: 2.9863501701490156

Epoch: 6| Step: 11
Training loss: 3.5965122387965645
Validation loss: 2.9846424502006426

Epoch: 6| Step: 12
Training loss: 4.177457239376174
Validation loss: 2.986139465779933

Epoch: 6| Step: 13
Training loss: 3.7760312976914028
Validation loss: 2.9859645265387127

Epoch: 108| Step: 0
Training loss: 3.357821793008604
Validation loss: 2.983836030797124

Epoch: 6| Step: 1
Training loss: 3.441705801112456
Validation loss: 2.9831531430598326

Epoch: 6| Step: 2
Training loss: 2.931721624568056
Validation loss: 2.984444390046293

Epoch: 6| Step: 3
Training loss: 2.989492452660103
Validation loss: 2.986753214006606

Epoch: 6| Step: 4
Training loss: 3.666383443355446
Validation loss: 2.9888848712985276

Epoch: 6| Step: 5
Training loss: 2.8967095748597207
Validation loss: 2.9909645198071293

Epoch: 6| Step: 6
Training loss: 4.031224923462461
Validation loss: 2.9970832954631037

Epoch: 6| Step: 7
Training loss: 2.79248580491873
Validation loss: 3.0157451381489087

Epoch: 6| Step: 8
Training loss: 3.650399638206168
Validation loss: 2.9970218572720966

Epoch: 6| Step: 9
Training loss: 2.9567213009413704
Validation loss: 2.996671270661945

Epoch: 6| Step: 10
Training loss: 2.4872523505609747
Validation loss: 3.0025972912458716

Epoch: 6| Step: 11
Training loss: 3.800444883103724
Validation loss: 2.9992559682783044

Epoch: 6| Step: 12
Training loss: 2.951706803097597
Validation loss: 2.9802819753138294

Epoch: 6| Step: 13
Training loss: 3.4017320821086523
Validation loss: 2.980898582525986

Epoch: 109| Step: 0
Training loss: 3.844553297507143
Validation loss: 2.981885804304789

Epoch: 6| Step: 1
Training loss: 3.3096407660231146
Validation loss: 2.9841177739909304

Epoch: 6| Step: 2
Training loss: 3.623075303122971
Validation loss: 2.9889118294669657

Epoch: 6| Step: 3
Training loss: 3.020931023081431
Validation loss: 2.987720797852536

Epoch: 6| Step: 4
Training loss: 2.7872020168719787
Validation loss: 2.9912417897072148

Epoch: 6| Step: 5
Training loss: 2.842782159789951
Validation loss: 2.995212825286044

Epoch: 6| Step: 6
Training loss: 3.401424244290682
Validation loss: 2.9961436209318575

Epoch: 6| Step: 7
Training loss: 3.31869848179028
Validation loss: 3.007729090096226

Epoch: 6| Step: 8
Training loss: 3.0981409528274253
Validation loss: 3.017456053067944

Epoch: 6| Step: 9
Training loss: 3.335293638465009
Validation loss: 2.9981443808763775

Epoch: 6| Step: 10
Training loss: 3.3055138963768744
Validation loss: 2.9830121475906384

Epoch: 6| Step: 11
Training loss: 3.0565061496976655
Validation loss: 2.9808720782266427

Epoch: 6| Step: 12
Training loss: 3.4668893033453476
Validation loss: 2.980361601308337

Epoch: 6| Step: 13
Training loss: 3.2046618240644693
Validation loss: 2.979838441754412

Epoch: 110| Step: 0
Training loss: 3.0923737826914524
Validation loss: 2.9787284496652977

Epoch: 6| Step: 1
Training loss: 3.756687305148912
Validation loss: 2.9784675762914508

Epoch: 6| Step: 2
Training loss: 3.48114877002308
Validation loss: 2.9781011664849464

Epoch: 6| Step: 3
Training loss: 3.3664932420335
Validation loss: 2.977084104809305

Epoch: 6| Step: 4
Training loss: 3.450167809427247
Validation loss: 2.9758282719080666

Epoch: 6| Step: 5
Training loss: 2.967209586994875
Validation loss: 2.9753645260214303

Epoch: 6| Step: 6
Training loss: 2.9149005083801542
Validation loss: 2.9762869893025323

Epoch: 6| Step: 7
Training loss: 3.3034177825428785
Validation loss: 2.9771967154001016

Epoch: 6| Step: 8
Training loss: 3.105233199105213
Validation loss: 2.975914595209316

Epoch: 6| Step: 9
Training loss: 2.8455384049036727
Validation loss: 2.9760870930284713

Epoch: 6| Step: 10
Training loss: 3.033738206385451
Validation loss: 2.9734217354656383

Epoch: 6| Step: 11
Training loss: 3.309123351531619
Validation loss: 2.974841797571499

Epoch: 6| Step: 12
Training loss: 2.7304010778508263
Validation loss: 2.9732560774568895

Epoch: 6| Step: 13
Training loss: 4.451745820212372
Validation loss: 2.973760229993997

Epoch: 111| Step: 0
Training loss: 3.6844741562045535
Validation loss: 2.974204118324275

Epoch: 6| Step: 1
Training loss: 3.3562584903545716
Validation loss: 2.9730598189023234

Epoch: 6| Step: 2
Training loss: 2.797512301502334
Validation loss: 2.972338049498019

Epoch: 6| Step: 3
Training loss: 2.8877090180284326
Validation loss: 2.97406376919964

Epoch: 6| Step: 4
Training loss: 3.7541144369869244
Validation loss: 2.971116532581299

Epoch: 6| Step: 5
Training loss: 3.409586820656963
Validation loss: 2.9728922401322313

Epoch: 6| Step: 6
Training loss: 3.2957188897853955
Validation loss: 2.971002258276287

Epoch: 6| Step: 7
Training loss: 2.639294441469764
Validation loss: 2.9702866071134877

Epoch: 6| Step: 8
Training loss: 3.123940402635939
Validation loss: 2.9699837668947437

Epoch: 6| Step: 9
Training loss: 3.236293942185198
Validation loss: 2.9700310681042823

Epoch: 6| Step: 10
Training loss: 3.647843175671009
Validation loss: 2.969883124912552

Epoch: 6| Step: 11
Training loss: 3.662160937137005
Validation loss: 2.970192719840862

Epoch: 6| Step: 12
Training loss: 2.871016354717893
Validation loss: 2.9675143785184757

Epoch: 6| Step: 13
Training loss: 2.427749695119602
Validation loss: 2.9691603786587306

Epoch: 112| Step: 0
Training loss: 2.8879013839432517
Validation loss: 2.967821065042622

Epoch: 6| Step: 1
Training loss: 3.538271245017871
Validation loss: 2.969401747313586

Epoch: 6| Step: 2
Training loss: 3.1021340561804625
Validation loss: 2.968813470530053

Epoch: 6| Step: 3
Training loss: 3.420621180644622
Validation loss: 2.9679531593184167

Epoch: 6| Step: 4
Training loss: 2.375435939733605
Validation loss: 2.967988464573136

Epoch: 6| Step: 5
Training loss: 4.464631857395446
Validation loss: 2.966740171520378

Epoch: 6| Step: 6
Training loss: 3.009387587286273
Validation loss: 2.9672157921675306

Epoch: 6| Step: 7
Training loss: 2.642823787979498
Validation loss: 2.9666130038481464

Epoch: 6| Step: 8
Training loss: 3.1282972107395266
Validation loss: 2.9643873178211786

Epoch: 6| Step: 9
Training loss: 3.7901003330608503
Validation loss: 2.964983833472415

Epoch: 6| Step: 10
Training loss: 2.5991156357817715
Validation loss: 2.9641647169796856

Epoch: 6| Step: 11
Training loss: 3.295260354900594
Validation loss: 2.965046596952608

Epoch: 6| Step: 12
Training loss: 3.035078482202304
Validation loss: 2.9629054345792283

Epoch: 6| Step: 13
Training loss: 3.7590422650330995
Validation loss: 2.962112690090635

Epoch: 113| Step: 0
Training loss: 2.147483142080519
Validation loss: 2.96256749367145

Epoch: 6| Step: 1
Training loss: 3.3824334405749115
Validation loss: 2.960573680618492

Epoch: 6| Step: 2
Training loss: 3.4947911057374657
Validation loss: 2.963480998828189

Epoch: 6| Step: 3
Training loss: 2.214239990184185
Validation loss: 2.962827119307504

Epoch: 6| Step: 4
Training loss: 3.791427157596124
Validation loss: 2.9628941569477365

Epoch: 6| Step: 5
Training loss: 3.8009715645199913
Validation loss: 2.9677631354901166

Epoch: 6| Step: 6
Training loss: 2.9059814000857
Validation loss: 2.9699488586904006

Epoch: 6| Step: 7
Training loss: 3.4232676559234743
Validation loss: 2.992718083034281

Epoch: 6| Step: 8
Training loss: 3.0307456314645744
Validation loss: 2.9777142057345283

Epoch: 6| Step: 9
Training loss: 3.0218700515406742
Validation loss: 2.965688556738841

Epoch: 6| Step: 10
Training loss: 3.5021855478765502
Validation loss: 2.9618546385904208

Epoch: 6| Step: 11
Training loss: 3.8939653021741387
Validation loss: 2.9611929025938295

Epoch: 6| Step: 12
Training loss: 3.3880081977970247
Validation loss: 2.9583474224909945

Epoch: 6| Step: 13
Training loss: 2.3055652046257036
Validation loss: 2.9578328302130443

Epoch: 114| Step: 0
Training loss: 2.675963547337154
Validation loss: 2.95737129720891

Epoch: 6| Step: 1
Training loss: 3.3170882782940967
Validation loss: 2.95840374176619

Epoch: 6| Step: 2
Training loss: 2.974685677985575
Validation loss: 2.9571316392982268

Epoch: 6| Step: 3
Training loss: 3.922989766632899
Validation loss: 2.9603486141769633

Epoch: 6| Step: 4
Training loss: 3.325824067528139
Validation loss: 2.9588862527369377

Epoch: 6| Step: 5
Training loss: 2.926176607237363
Validation loss: 2.958340909712185

Epoch: 6| Step: 6
Training loss: 3.527493259307239
Validation loss: 2.959337019749995

Epoch: 6| Step: 7
Training loss: 3.3260769698916404
Validation loss: 2.9581585837825646

Epoch: 6| Step: 8
Training loss: 3.8005598107625023
Validation loss: 2.959221642554215

Epoch: 6| Step: 9
Training loss: 2.5883081178568883
Validation loss: 2.9578531679481883

Epoch: 6| Step: 10
Training loss: 3.685247994389437
Validation loss: 2.95836469941855

Epoch: 6| Step: 11
Training loss: 2.7751109058109336
Validation loss: 2.9576224285046897

Epoch: 6| Step: 12
Training loss: 3.0722274438385586
Validation loss: 2.956015893385032

Epoch: 6| Step: 13
Training loss: 2.9751256643730253
Validation loss: 2.9558861385829247

Epoch: 115| Step: 0
Training loss: 3.1730359588326325
Validation loss: 2.9551182370520546

Epoch: 6| Step: 1
Training loss: 3.380863042043794
Validation loss: 2.9563547219524082

Epoch: 6| Step: 2
Training loss: 3.3580918811362683
Validation loss: 2.955108879038905

Epoch: 6| Step: 3
Training loss: 3.3911437591435463
Validation loss: 2.9546052133724134

Epoch: 6| Step: 4
Training loss: 3.1305230734071845
Validation loss: 2.9534375468674843

Epoch: 6| Step: 5
Training loss: 3.9378967085311603
Validation loss: 2.951574940198889

Epoch: 6| Step: 6
Training loss: 3.7183692801353914
Validation loss: 2.9529821089259785

Epoch: 6| Step: 7
Training loss: 2.897877106898181
Validation loss: 2.9523776996390105

Epoch: 6| Step: 8
Training loss: 3.19862399319287
Validation loss: 2.953493774883028

Epoch: 6| Step: 9
Training loss: 2.884256967627895
Validation loss: 2.9509845569762634

Epoch: 6| Step: 10
Training loss: 2.845340493581403
Validation loss: 2.9529923322794396

Epoch: 6| Step: 11
Training loss: 3.688305912206058
Validation loss: 2.9502679803571303

Epoch: 6| Step: 12
Training loss: 2.6490925116738553
Validation loss: 2.9504401807211247

Epoch: 6| Step: 13
Training loss: 2.2180110076823776
Validation loss: 2.9527164056546606

Epoch: 116| Step: 0
Training loss: 3.543202923455995
Validation loss: 2.953710623514405

Epoch: 6| Step: 1
Training loss: 3.2309664397083244
Validation loss: 2.9579234193813324

Epoch: 6| Step: 2
Training loss: 3.7117189247165028
Validation loss: 2.9585565083918652

Epoch: 6| Step: 3
Training loss: 3.3511581354807807
Validation loss: 2.9556855373822546

Epoch: 6| Step: 4
Training loss: 3.6394234831625356
Validation loss: 2.9528157088014875

Epoch: 6| Step: 5
Training loss: 3.3871802485268985
Validation loss: 2.9517496299130976

Epoch: 6| Step: 6
Training loss: 2.7551154329517957
Validation loss: 2.95140463013928

Epoch: 6| Step: 7
Training loss: 1.9240114076319812
Validation loss: 2.951124253268869

Epoch: 6| Step: 8
Training loss: 3.3188180230419926
Validation loss: 2.94846365501579

Epoch: 6| Step: 9
Training loss: 2.8931441593586475
Validation loss: 2.947524795450894

Epoch: 6| Step: 10
Training loss: 2.861183970078178
Validation loss: 2.9451391458978913

Epoch: 6| Step: 11
Training loss: 3.613369007591388
Validation loss: 2.94646829241748

Epoch: 6| Step: 12
Training loss: 3.305193923131718
Validation loss: 2.946191740859052

Epoch: 6| Step: 13
Training loss: 3.276395421823203
Validation loss: 2.9439740269224353

Epoch: 117| Step: 0
Training loss: 3.1291288946710605
Validation loss: 2.945904911074007

Epoch: 6| Step: 1
Training loss: 2.860096157831666
Validation loss: 2.944664823514724

Epoch: 6| Step: 2
Training loss: 3.891963743732942
Validation loss: 2.9452360566571207

Epoch: 6| Step: 3
Training loss: 3.193432840324666
Validation loss: 2.9450031804740107

Epoch: 6| Step: 4
Training loss: 2.1664396925173564
Validation loss: 2.94412238126228

Epoch: 6| Step: 5
Training loss: 3.9402677708369005
Validation loss: 2.946076132535999

Epoch: 6| Step: 6
Training loss: 3.5078040719727537
Validation loss: 2.9460980411824096

Epoch: 6| Step: 7
Training loss: 2.5597611654153414
Validation loss: 2.945495921810481

Epoch: 6| Step: 8
Training loss: 3.8183372711556514
Validation loss: 2.945248861618991

Epoch: 6| Step: 9
Training loss: 2.962196263705684
Validation loss: 2.9433532658601407

Epoch: 6| Step: 10
Training loss: 3.459656626911875
Validation loss: 2.9425542458758476

Epoch: 6| Step: 11
Training loss: 3.324660382816834
Validation loss: 2.9423322777996526

Epoch: 6| Step: 12
Training loss: 2.5772524195108466
Validation loss: 2.948222791279308

Epoch: 6| Step: 13
Training loss: 3.21226351568891
Validation loss: 2.973333092007139

Epoch: 118| Step: 0
Training loss: 4.069932447617998
Validation loss: 3.0079179276270733

Epoch: 6| Step: 1
Training loss: 2.6908883314831566
Validation loss: 3.0040119717459373

Epoch: 6| Step: 2
Training loss: 2.2285751080744625
Validation loss: 2.9686332761726772

Epoch: 6| Step: 3
Training loss: 3.6463690373263193
Validation loss: 2.94314940197415

Epoch: 6| Step: 4
Training loss: 3.226144832890812
Validation loss: 2.9400225586172555

Epoch: 6| Step: 5
Training loss: 2.923772022674848
Validation loss: 2.938832644224268

Epoch: 6| Step: 6
Training loss: 3.4297931628797556
Validation loss: 2.939703032987665

Epoch: 6| Step: 7
Training loss: 3.2167414351817945
Validation loss: 2.939023841181093

Epoch: 6| Step: 8
Training loss: 3.0308936784673493
Validation loss: 2.9408115518495617

Epoch: 6| Step: 9
Training loss: 3.0970972622313933
Validation loss: 2.9419128010554876

Epoch: 6| Step: 10
Training loss: 3.277574060506785
Validation loss: 2.94131719863007

Epoch: 6| Step: 11
Training loss: 3.0802914503844474
Validation loss: 2.9403457436992975

Epoch: 6| Step: 12
Training loss: 3.4282790922239235
Validation loss: 2.9412471284407746

Epoch: 6| Step: 13
Training loss: 3.6976748248612394
Validation loss: 2.9388178755898235

Epoch: 119| Step: 0
Training loss: 3.5164585057943785
Validation loss: 2.9391492543816162

Epoch: 6| Step: 1
Training loss: 3.022238954641111
Validation loss: 2.940299067886635

Epoch: 6| Step: 2
Training loss: 3.454101148351332
Validation loss: 2.939294112266668

Epoch: 6| Step: 3
Training loss: 2.960576903596969
Validation loss: 2.938536908464369

Epoch: 6| Step: 4
Training loss: 3.4425746566666686
Validation loss: 2.937314795889369

Epoch: 6| Step: 5
Training loss: 2.569520126694484
Validation loss: 2.9365094080518097

Epoch: 6| Step: 6
Training loss: 3.335856452332571
Validation loss: 2.937133453756484

Epoch: 6| Step: 7
Training loss: 2.0537511047991837
Validation loss: 2.935879304100798

Epoch: 6| Step: 8
Training loss: 3.0592453458625446
Validation loss: 2.935514516962335

Epoch: 6| Step: 9
Training loss: 3.5026327857605577
Validation loss: 2.935431891087845

Epoch: 6| Step: 10
Training loss: 3.6069872335615734
Validation loss: 2.9341175588328983

Epoch: 6| Step: 11
Training loss: 2.9503066727886065
Validation loss: 2.9347085669270228

Epoch: 6| Step: 12
Training loss: 3.433815663601743
Validation loss: 2.9336947796514354

Epoch: 6| Step: 13
Training loss: 4.153214342750811
Validation loss: 2.932503184981121

Epoch: 120| Step: 0
Training loss: 3.2845130317930034
Validation loss: 2.933280960810594

Epoch: 6| Step: 1
Training loss: 3.470152975002957
Validation loss: 2.933811482303372

Epoch: 6| Step: 2
Training loss: 3.283194991810271
Validation loss: 2.9324629812690444

Epoch: 6| Step: 3
Training loss: 3.009013939229031
Validation loss: 2.9325255997887227

Epoch: 6| Step: 4
Training loss: 3.0267000953856042
Validation loss: 2.931100563679396

Epoch: 6| Step: 5
Training loss: 3.701925606588591
Validation loss: 2.932461257291333

Epoch: 6| Step: 6
Training loss: 2.962745617692111
Validation loss: 2.931884944330536

Epoch: 6| Step: 7
Training loss: 3.0928380373443645
Validation loss: 2.931230821797547

Epoch: 6| Step: 8
Training loss: 2.795012295991059
Validation loss: 2.9312951125913873

Epoch: 6| Step: 9
Training loss: 3.346790250672221
Validation loss: 2.9298446435929986

Epoch: 6| Step: 10
Training loss: 2.7723059696585253
Validation loss: 2.92967727932805

Epoch: 6| Step: 11
Training loss: 3.37893757888294
Validation loss: 2.9279417235317404

Epoch: 6| Step: 12
Training loss: 3.5498705074709433
Validation loss: 2.9299042871041263

Epoch: 6| Step: 13
Training loss: 3.1537166286158937
Validation loss: 2.928160118625854

Epoch: 121| Step: 0
Training loss: 2.1317502684773655
Validation loss: 2.9319975998815258

Epoch: 6| Step: 1
Training loss: 3.5055435420933936
Validation loss: 2.927786210663839

Epoch: 6| Step: 2
Training loss: 3.0689616641139037
Validation loss: 2.9272541522821776

Epoch: 6| Step: 3
Training loss: 3.802961580750977
Validation loss: 2.9263109620039227

Epoch: 6| Step: 4
Training loss: 3.2515486915364833
Validation loss: 2.9266807102035832

Epoch: 6| Step: 5
Training loss: 2.3354414090953735
Validation loss: 2.9271499777429626

Epoch: 6| Step: 6
Training loss: 3.463828504726562
Validation loss: 2.924823160911107

Epoch: 6| Step: 7
Training loss: 2.6036699253612605
Validation loss: 2.928027914137148

Epoch: 6| Step: 8
Training loss: 3.169451910826076
Validation loss: 2.924301580522382

Epoch: 6| Step: 9
Training loss: 3.413317985450492
Validation loss: 2.9263315845176265

Epoch: 6| Step: 10
Training loss: 3.527929855099163
Validation loss: 2.9250266482087035

Epoch: 6| Step: 11
Training loss: 3.9427958402745045
Validation loss: 2.923430107883741

Epoch: 6| Step: 12
Training loss: 3.4260351245725267
Validation loss: 2.926015146975882

Epoch: 6| Step: 13
Training loss: 2.394032760931353
Validation loss: 2.925233093186051

Epoch: 122| Step: 0
Training loss: 3.5553083946497375
Validation loss: 2.9239936742453665

Epoch: 6| Step: 1
Training loss: 3.1553539854988872
Validation loss: 2.931000376124371

Epoch: 6| Step: 2
Training loss: 2.696947304119966
Validation loss: 2.9322764640834684

Epoch: 6| Step: 3
Training loss: 3.1910760304793437
Validation loss: 2.942655141256952

Epoch: 6| Step: 4
Training loss: 3.042624301048209
Validation loss: 2.9278773538500724

Epoch: 6| Step: 5
Training loss: 2.7093590090234647
Validation loss: 2.9216779390487835

Epoch: 6| Step: 6
Training loss: 3.5538759751454903
Validation loss: 2.923260807453787

Epoch: 6| Step: 7
Training loss: 3.034885389498684
Validation loss: 2.9253078017222975

Epoch: 6| Step: 8
Training loss: 3.2280181483026835
Validation loss: 2.926912165155518

Epoch: 6| Step: 9
Training loss: 3.106033446594274
Validation loss: 2.926268106308632

Epoch: 6| Step: 10
Training loss: 3.5925073216628483
Validation loss: 2.927593316543686

Epoch: 6| Step: 11
Training loss: 3.4892651920576876
Validation loss: 2.9281925334193373

Epoch: 6| Step: 12
Training loss: 3.150747053176917
Validation loss: 2.9274038443621575

Epoch: 6| Step: 13
Training loss: 3.4465599656205974
Validation loss: 2.926149011523113

Epoch: 123| Step: 0
Training loss: 3.028473516511241
Validation loss: 2.9268242511832154

Epoch: 6| Step: 1
Training loss: 3.239122086016913
Validation loss: 2.9247071137680516

Epoch: 6| Step: 2
Training loss: 3.055755974718264
Validation loss: 2.9251034873547006

Epoch: 6| Step: 3
Training loss: 2.9888546860954492
Validation loss: 2.9242099243583897

Epoch: 6| Step: 4
Training loss: 3.972113198041647
Validation loss: 2.9252038207873823

Epoch: 6| Step: 5
Training loss: 2.5529141585325936
Validation loss: 2.924580875256009

Epoch: 6| Step: 6
Training loss: 3.465209115944393
Validation loss: 2.9226207561235458

Epoch: 6| Step: 7
Training loss: 2.798046527347546
Validation loss: 2.9219732578951745

Epoch: 6| Step: 8
Training loss: 2.878012364406681
Validation loss: 2.92074902291255

Epoch: 6| Step: 9
Training loss: 2.6004409892892464
Validation loss: 2.920021894822104

Epoch: 6| Step: 10
Training loss: 3.808703423901661
Validation loss: 2.920116038789042

Epoch: 6| Step: 11
Training loss: 3.4224278948302915
Validation loss: 2.9187265168782606

Epoch: 6| Step: 12
Training loss: 3.2739837117940542
Validation loss: 2.917390509994938

Epoch: 6| Step: 13
Training loss: 3.738593236964874
Validation loss: 2.9191249294179626

Epoch: 124| Step: 0
Training loss: 3.309523774892265
Validation loss: 2.9186646378935084

Epoch: 6| Step: 1
Training loss: 3.408294344230566
Validation loss: 2.9168441179382874

Epoch: 6| Step: 2
Training loss: 3.476234677749769
Validation loss: 2.9180792764414165

Epoch: 6| Step: 3
Training loss: 3.208588197831969
Validation loss: 2.916575690284781

Epoch: 6| Step: 4
Training loss: 3.536230035902824
Validation loss: 2.916792152857882

Epoch: 6| Step: 5
Training loss: 3.1914761744558175
Validation loss: 2.9162178139516763

Epoch: 6| Step: 6
Training loss: 3.029792041755371
Validation loss: 2.916741723238983

Epoch: 6| Step: 7
Training loss: 2.8687889345805617
Validation loss: 2.9156773270705196

Epoch: 6| Step: 8
Training loss: 3.211107978100625
Validation loss: 2.914680575304062

Epoch: 6| Step: 9
Training loss: 3.7295591833305624
Validation loss: 2.915840665402801

Epoch: 6| Step: 10
Training loss: 3.2129718062977095
Validation loss: 2.9156225969714216

Epoch: 6| Step: 11
Training loss: 3.0488367269957926
Validation loss: 2.915285059824554

Epoch: 6| Step: 12
Training loss: 2.596900038248447
Validation loss: 2.9159028830197813

Epoch: 6| Step: 13
Training loss: 2.5676543337783992
Validation loss: 2.914612747574409

Epoch: 125| Step: 0
Training loss: 3.329379422897572
Validation loss: 2.9164023184337826

Epoch: 6| Step: 1
Training loss: 2.9735011580564232
Validation loss: 2.91449573752326

Epoch: 6| Step: 2
Training loss: 2.349481212897239
Validation loss: 2.9143941153335065

Epoch: 6| Step: 3
Training loss: 3.640125682463568
Validation loss: 2.9173617248219204

Epoch: 6| Step: 4
Training loss: 2.8540127195249934
Validation loss: 2.913705362012417

Epoch: 6| Step: 5
Training loss: 2.626554482996391
Validation loss: 2.9188940663816703

Epoch: 6| Step: 6
Training loss: 3.4944651300019873
Validation loss: 2.9151579093921898

Epoch: 6| Step: 7
Training loss: 3.421227102039271
Validation loss: 2.914936032728674

Epoch: 6| Step: 8
Training loss: 3.345689585358257
Validation loss: 2.9138667389391846

Epoch: 6| Step: 9
Training loss: 3.474902770514071
Validation loss: 2.915290309712815

Epoch: 6| Step: 10
Training loss: 3.3450999164341466
Validation loss: 2.9124400692904984

Epoch: 6| Step: 11
Training loss: 3.613087911846047
Validation loss: 2.913955997521264

Epoch: 6| Step: 12
Training loss: 3.007875912480901
Validation loss: 2.909403475567021

Epoch: 6| Step: 13
Training loss: 2.881248153057044
Validation loss: 2.909378338698603

Epoch: 126| Step: 0
Training loss: 3.394435868059039
Validation loss: 2.910584620344703

Epoch: 6| Step: 1
Training loss: 2.7427276340205866
Validation loss: 2.9078081117624563

Epoch: 6| Step: 2
Training loss: 3.1689444096685926
Validation loss: 2.908595951600585

Epoch: 6| Step: 3
Training loss: 2.662421652487364
Validation loss: 2.906358979477915

Epoch: 6| Step: 4
Training loss: 3.8415977841461033
Validation loss: 2.907948833127257

Epoch: 6| Step: 5
Training loss: 3.4029326077137645
Validation loss: 2.905803632468639

Epoch: 6| Step: 6
Training loss: 2.479751891830681
Validation loss: 2.9075002513801413

Epoch: 6| Step: 7
Training loss: 2.7172875691392027
Validation loss: 2.908254203374549

Epoch: 6| Step: 8
Training loss: 3.998336446065726
Validation loss: 2.9074377675395904

Epoch: 6| Step: 9
Training loss: 3.105021587302927
Validation loss: 2.9078073747111244

Epoch: 6| Step: 10
Training loss: 2.558817007792882
Validation loss: 2.9071622138671

Epoch: 6| Step: 11
Training loss: 3.8535480449567565
Validation loss: 2.907833148474148

Epoch: 6| Step: 12
Training loss: 3.1523569099690456
Validation loss: 2.9077176858070772

Epoch: 6| Step: 13
Training loss: 3.335248031657949
Validation loss: 2.9066801111253397

Epoch: 127| Step: 0
Training loss: 3.071607476787208
Validation loss: 2.906529589879393

Epoch: 6| Step: 1
Training loss: 4.144426781347122
Validation loss: 2.905306245296823

Epoch: 6| Step: 2
Training loss: 3.2511594611456505
Validation loss: 2.9037671491715735

Epoch: 6| Step: 3
Training loss: 3.1602033274460015
Validation loss: 2.903324639211627

Epoch: 6| Step: 4
Training loss: 2.3669263236114952
Validation loss: 2.9019525046984227

Epoch: 6| Step: 5
Training loss: 3.3366626960763797
Validation loss: 2.9017914882432536

Epoch: 6| Step: 6
Training loss: 3.1809057203062543
Validation loss: 2.9006919220687544

Epoch: 6| Step: 7
Training loss: 2.5519459797753177
Validation loss: 2.900360524685076

Epoch: 6| Step: 8
Training loss: 2.711615485904297
Validation loss: 2.9027254086119405

Epoch: 6| Step: 9
Training loss: 3.579504288605957
Validation loss: 2.900962628945021

Epoch: 6| Step: 10
Training loss: 3.546638380047806
Validation loss: 2.901280211932586

Epoch: 6| Step: 11
Training loss: 3.2627884075969473
Validation loss: 2.903387344018277

Epoch: 6| Step: 12
Training loss: 3.099333069954829
Validation loss: 2.905909210982373

Epoch: 6| Step: 13
Training loss: 2.975221987864972
Validation loss: 2.9073311740480943

Epoch: 128| Step: 0
Training loss: 2.9196930760588913
Validation loss: 2.9003583803328725

Epoch: 6| Step: 1
Training loss: 3.199355573138757
Validation loss: 2.902514557554578

Epoch: 6| Step: 2
Training loss: 3.5299053501483377
Validation loss: 2.899766078902172

Epoch: 6| Step: 3
Training loss: 3.80467885229863
Validation loss: 2.9002640838380795

Epoch: 6| Step: 4
Training loss: 2.948495131891122
Validation loss: 2.900218454830933

Epoch: 6| Step: 5
Training loss: 3.2125590515646616
Validation loss: 2.9035908255362175

Epoch: 6| Step: 6
Training loss: 3.2081256815770085
Validation loss: 2.9015626856843335

Epoch: 6| Step: 7
Training loss: 2.7171433184707707
Validation loss: 2.901270500005669

Epoch: 6| Step: 8
Training loss: 3.06547993074666
Validation loss: 2.9007987418524963

Epoch: 6| Step: 9
Training loss: 2.96545259157451
Validation loss: 2.9013102921026253

Epoch: 6| Step: 10
Training loss: 2.878741607720039
Validation loss: 2.9070651970479835

Epoch: 6| Step: 11
Training loss: 3.192035365575615
Validation loss: 2.908172274263876

Epoch: 6| Step: 12
Training loss: 3.502470506956427
Validation loss: 2.9118428307788182

Epoch: 6| Step: 13
Training loss: 3.538870092555309
Validation loss: 2.9111025308841967

Epoch: 129| Step: 0
Training loss: 3.286366569741253
Validation loss: 2.9196330237489683

Epoch: 6| Step: 1
Training loss: 3.305832973204865
Validation loss: 2.9228732829874935

Epoch: 6| Step: 2
Training loss: 3.5228612052090544
Validation loss: 2.9120930482050946

Epoch: 6| Step: 3
Training loss: 2.742955809334239
Validation loss: 2.9114900952275162

Epoch: 6| Step: 4
Training loss: 3.078698119432255
Validation loss: 2.913229373923237

Epoch: 6| Step: 5
Training loss: 3.297062728382294
Validation loss: 2.901088887788032

Epoch: 6| Step: 6
Training loss: 3.0078762295399466
Validation loss: 2.8968242196160943

Epoch: 6| Step: 7
Training loss: 3.084981649582259
Validation loss: 2.8956644825381836

Epoch: 6| Step: 8
Training loss: 3.1966706539708616
Validation loss: 2.8953598944491925

Epoch: 6| Step: 9
Training loss: 2.9388502548296844
Validation loss: 2.8968470512065188

Epoch: 6| Step: 10
Training loss: 3.2399830137207846
Validation loss: 2.8940211253385995

Epoch: 6| Step: 11
Training loss: 3.175468626506142
Validation loss: 2.894294906146706

Epoch: 6| Step: 12
Training loss: 3.5731235514690085
Validation loss: 2.8949885776572213

Epoch: 6| Step: 13
Training loss: 3.162494487531479
Validation loss: 2.8951770649388617

Epoch: 130| Step: 0
Training loss: 3.219684798409751
Validation loss: 2.8949936376529335

Epoch: 6| Step: 1
Training loss: 2.389708997974695
Validation loss: 2.8946883785143394

Epoch: 6| Step: 2
Training loss: 3.157713446934611
Validation loss: 2.894561867941347

Epoch: 6| Step: 3
Training loss: 3.732496738930649
Validation loss: 2.8946350521000204

Epoch: 6| Step: 4
Training loss: 3.0729171149474426
Validation loss: 2.8938859712948504

Epoch: 6| Step: 5
Training loss: 3.686422675568326
Validation loss: 2.8925249546668574

Epoch: 6| Step: 6
Training loss: 3.321510296356721
Validation loss: 2.8931220278194334

Epoch: 6| Step: 7
Training loss: 2.746098351508636
Validation loss: 2.8921854097216255

Epoch: 6| Step: 8
Training loss: 3.225939083141473
Validation loss: 2.890109206024484

Epoch: 6| Step: 9
Training loss: 3.4637616004047502
Validation loss: 2.8902196004002976

Epoch: 6| Step: 10
Training loss: 3.1056827879266153
Validation loss: 2.890890186565339

Epoch: 6| Step: 11
Training loss: 2.8522600548782884
Validation loss: 2.8899432308711503

Epoch: 6| Step: 12
Training loss: 2.736777073409933
Validation loss: 2.891146760926441

Epoch: 6| Step: 13
Training loss: 3.8514648177505926
Validation loss: 2.8910443250982896

Epoch: 131| Step: 0
Training loss: 3.472967384912366
Validation loss: 2.9048695782906533

Epoch: 6| Step: 1
Training loss: 3.037161813755495
Validation loss: 2.9059023861486275

Epoch: 6| Step: 2
Training loss: 3.4585456936144903
Validation loss: 2.9160554963347907

Epoch: 6| Step: 3
Training loss: 2.920352967759005
Validation loss: 2.9014140389926726

Epoch: 6| Step: 4
Training loss: 3.4424336487824325
Validation loss: 2.8931954300483533

Epoch: 6| Step: 5
Training loss: 3.028105058004027
Validation loss: 2.888272158859162

Epoch: 6| Step: 6
Training loss: 2.7943290332280415
Validation loss: 2.8861137114748714

Epoch: 6| Step: 7
Training loss: 3.4460655998233887
Validation loss: 2.888621604103885

Epoch: 6| Step: 8
Training loss: 2.842134456967927
Validation loss: 2.8881739482941007

Epoch: 6| Step: 9
Training loss: 3.3325778740886514
Validation loss: 2.8865206069568106

Epoch: 6| Step: 10
Training loss: 3.360784758249802
Validation loss: 2.88455531418241

Epoch: 6| Step: 11
Training loss: 2.8444174517734933
Validation loss: 2.88404491835513

Epoch: 6| Step: 12
Training loss: 3.653254398504888
Validation loss: 2.8858730733655054

Epoch: 6| Step: 13
Training loss: 2.366407914411401
Validation loss: 2.88285188525468

Epoch: 132| Step: 0
Training loss: 2.87028647770764
Validation loss: 2.883071790376656

Epoch: 6| Step: 1
Training loss: 3.4168956183660457
Validation loss: 2.885005226948751

Epoch: 6| Step: 2
Training loss: 3.5986920417870008
Validation loss: 2.884170012956566

Epoch: 6| Step: 3
Training loss: 3.5803594150950495
Validation loss: 2.8782908521462796

Epoch: 6| Step: 4
Training loss: 3.389555872403639
Validation loss: 2.882500767565555

Epoch: 6| Step: 5
Training loss: 2.9612871029076473
Validation loss: 2.881379872989424

Epoch: 6| Step: 6
Training loss: 3.717966461982512
Validation loss: 2.8821390746419637

Epoch: 6| Step: 7
Training loss: 3.0472950181251295
Validation loss: 2.8821939718075047

Epoch: 6| Step: 8
Training loss: 3.233156131201459
Validation loss: 2.8807995454649356

Epoch: 6| Step: 9
Training loss: 2.711365327963185
Validation loss: 2.8793158022887417

Epoch: 6| Step: 10
Training loss: 2.3587959033601225
Validation loss: 2.881344025677278

Epoch: 6| Step: 11
Training loss: 3.152117601718095
Validation loss: 2.882300715773573

Epoch: 6| Step: 12
Training loss: 2.6793380820896764
Validation loss: 2.8855115917017464

Epoch: 6| Step: 13
Training loss: 3.6358471080919244
Validation loss: 2.887232053481205

Epoch: 133| Step: 0
Training loss: 3.174627753836227
Validation loss: 2.881335492189598

Epoch: 6| Step: 1
Training loss: 2.8048046374498625
Validation loss: 2.8802516298849197

Epoch: 6| Step: 2
Training loss: 3.1223826319288444
Validation loss: 2.877804394687568

Epoch: 6| Step: 3
Training loss: 3.0505363180427394
Validation loss: 2.8773206223764554

Epoch: 6| Step: 4
Training loss: 2.8699113344326306
Validation loss: 2.8774812387671065

Epoch: 6| Step: 5
Training loss: 3.5647230741100735
Validation loss: 2.8771615180100882

Epoch: 6| Step: 6
Training loss: 3.7865550760383866
Validation loss: 2.8781409269371885

Epoch: 6| Step: 7
Training loss: 3.3957281427922017
Validation loss: 2.877376385721156

Epoch: 6| Step: 8
Training loss: 2.826911623825276
Validation loss: 2.8767389492986726

Epoch: 6| Step: 9
Training loss: 2.8161582043922047
Validation loss: 2.876725690558848

Epoch: 6| Step: 10
Training loss: 2.9320898353584437
Validation loss: 2.876840422351542

Epoch: 6| Step: 11
Training loss: 3.477139337239889
Validation loss: 2.8764793438563663

Epoch: 6| Step: 12
Training loss: 2.963789640665925
Validation loss: 2.874356710149688

Epoch: 6| Step: 13
Training loss: 3.5993301192206455
Validation loss: 2.8756344359600794

Epoch: 134| Step: 0
Training loss: 2.7465962239216637
Validation loss: 2.874711846619375

Epoch: 6| Step: 1
Training loss: 2.7408977203213802
Validation loss: 2.8731224970465465

Epoch: 6| Step: 2
Training loss: 3.4491604101273747
Validation loss: 2.8761716954489134

Epoch: 6| Step: 3
Training loss: 3.110396174375905
Validation loss: 2.8724091882197853

Epoch: 6| Step: 4
Training loss: 3.177134245584428
Validation loss: 2.8743472488519575

Epoch: 6| Step: 5
Training loss: 3.5234392593277897
Validation loss: 2.873081519513481

Epoch: 6| Step: 6
Training loss: 2.7454805517027125
Validation loss: 2.873118290817674

Epoch: 6| Step: 7
Training loss: 3.063892437204716
Validation loss: 2.874844283371768

Epoch: 6| Step: 8
Training loss: 3.340688855066749
Validation loss: 2.872025631632236

Epoch: 6| Step: 9
Training loss: 3.529705283638177
Validation loss: 2.875577569900748

Epoch: 6| Step: 10
Training loss: 3.3718794065204496
Validation loss: 2.874948767749063

Epoch: 6| Step: 11
Training loss: 3.37566849481184
Validation loss: 2.873236594678592

Epoch: 6| Step: 12
Training loss: 2.9014662883298254
Validation loss: 2.8731276731801594

Epoch: 6| Step: 13
Training loss: 3.044654545723605
Validation loss: 2.876231721077318

Epoch: 135| Step: 0
Training loss: 3.293992649239246
Validation loss: 2.8790799564367298

Epoch: 6| Step: 1
Training loss: 2.6934314300436846
Validation loss: 2.8762601843246896

Epoch: 6| Step: 2
Training loss: 2.5911824950623
Validation loss: 2.877105792380153

Epoch: 6| Step: 3
Training loss: 3.6569956483760286
Validation loss: 2.87429645716935

Epoch: 6| Step: 4
Training loss: 3.0075431405871265
Validation loss: 2.8736137697004636

Epoch: 6| Step: 5
Training loss: 2.4981220821605037
Validation loss: 2.869199657612625

Epoch: 6| Step: 6
Training loss: 2.64463835235945
Validation loss: 2.869990235175895

Epoch: 6| Step: 7
Training loss: 3.8080519696784565
Validation loss: 2.8712046942427403

Epoch: 6| Step: 8
Training loss: 3.8690228047116633
Validation loss: 2.870570778724565

Epoch: 6| Step: 9
Training loss: 3.298014800844125
Validation loss: 2.8704477806369226

Epoch: 6| Step: 10
Training loss: 2.8441148461010677
Validation loss: 2.868536446608559

Epoch: 6| Step: 11
Training loss: 3.2379004389139787
Validation loss: 2.8691415006515517

Epoch: 6| Step: 12
Training loss: 2.9057012880862234
Validation loss: 2.871068955448951

Epoch: 6| Step: 13
Training loss: 3.800795552147423
Validation loss: 2.8737773337410855

Epoch: 136| Step: 0
Training loss: 3.966743983522323
Validation loss: 2.8737305187608464

Epoch: 6| Step: 1
Training loss: 2.9893806379944188
Validation loss: 2.8761114876223877

Epoch: 6| Step: 2
Training loss: 3.511197298604361
Validation loss: 2.874494427906486

Epoch: 6| Step: 3
Training loss: 2.6730847213454036
Validation loss: 2.8759859738679143

Epoch: 6| Step: 4
Training loss: 3.1112631427614508
Validation loss: 2.871003294571733

Epoch: 6| Step: 5
Training loss: 2.999823088198009
Validation loss: 2.8667463841935885

Epoch: 6| Step: 6
Training loss: 3.309093234969321
Validation loss: 2.865135925034516

Epoch: 6| Step: 7
Training loss: 3.3205483027481755
Validation loss: 2.8662545945612483

Epoch: 6| Step: 8
Training loss: 3.2096125707013154
Validation loss: 2.866612995596329

Epoch: 6| Step: 9
Training loss: 2.1409011996767493
Validation loss: 2.866774650089091

Epoch: 6| Step: 10
Training loss: 2.081385184814944
Validation loss: 2.8693038900790757

Epoch: 6| Step: 11
Training loss: 3.534330121876052
Validation loss: 2.869759300925917

Epoch: 6| Step: 12
Training loss: 3.806943878417491
Validation loss: 2.8690576942257655

Epoch: 6| Step: 13
Training loss: 3.033934986964446
Validation loss: 2.8712943245811524

Epoch: 137| Step: 0
Training loss: 3.3687317177129574
Validation loss: 2.8699304568604185

Epoch: 6| Step: 1
Training loss: 3.0216857409063693
Validation loss: 2.867767086742585

Epoch: 6| Step: 2
Training loss: 3.7859522058419377
Validation loss: 2.866649167524224

Epoch: 6| Step: 3
Training loss: 2.669545368249907
Validation loss: 2.865530295069662

Epoch: 6| Step: 4
Training loss: 3.556393526261577
Validation loss: 2.8643625326816706

Epoch: 6| Step: 5
Training loss: 3.2847155480634016
Validation loss: 2.8646050216137176

Epoch: 6| Step: 6
Training loss: 2.8868015055479797
Validation loss: 2.8633252158545273

Epoch: 6| Step: 7
Training loss: 3.207756601655791
Validation loss: 2.863203423275916

Epoch: 6| Step: 8
Training loss: 2.654473192928555
Validation loss: 2.8603528692579667

Epoch: 6| Step: 9
Training loss: 3.3852190791448273
Validation loss: 2.86376701887583

Epoch: 6| Step: 10
Training loss: 2.504505579690321
Validation loss: 2.8615052923729203

Epoch: 6| Step: 11
Training loss: 3.1431801493735634
Validation loss: 2.8628262145658203

Epoch: 6| Step: 12
Training loss: 3.2073497172684964
Validation loss: 2.8641067069582298

Epoch: 6| Step: 13
Training loss: 3.4743766170634505
Validation loss: 2.8619469902625005

Epoch: 138| Step: 0
Training loss: 3.4115643123249058
Validation loss: 2.8651173199999898

Epoch: 6| Step: 1
Training loss: 3.0637497200998824
Validation loss: 2.874660451383232

Epoch: 6| Step: 2
Training loss: 2.9482839151154385
Validation loss: 2.8882587036455334

Epoch: 6| Step: 3
Training loss: 3.3543565747696955
Validation loss: 2.896295415155319

Epoch: 6| Step: 4
Training loss: 3.0661530797160066
Validation loss: 2.8969253749644284

Epoch: 6| Step: 5
Training loss: 3.398947631432515
Validation loss: 2.884689197295323

Epoch: 6| Step: 6
Training loss: 3.470037273019911
Validation loss: 2.868238389455304

Epoch: 6| Step: 7
Training loss: 3.3007301100883053
Validation loss: 2.8596496777349993

Epoch: 6| Step: 8
Training loss: 3.349790589349232
Validation loss: 2.8633364048575256

Epoch: 6| Step: 9
Training loss: 2.932967727447164
Validation loss: 2.861857507011364

Epoch: 6| Step: 10
Training loss: 3.0201233829784315
Validation loss: 2.881809815581046

Epoch: 6| Step: 11
Training loss: 2.3852830430186898
Validation loss: 2.9239120169411774

Epoch: 6| Step: 12
Training loss: 3.4563081319104003
Validation loss: 2.949091440511857

Epoch: 6| Step: 13
Training loss: 3.216179274824029
Validation loss: 2.9285065611705954

Epoch: 139| Step: 0
Training loss: 3.6816170527262617
Validation loss: 2.871070702003853

Epoch: 6| Step: 1
Training loss: 3.290587880214128
Validation loss: 2.860439680387649

Epoch: 6| Step: 2
Training loss: 3.382928648049345
Validation loss: 2.854928792386554

Epoch: 6| Step: 3
Training loss: 3.1421881434337045
Validation loss: 2.856851115801709

Epoch: 6| Step: 4
Training loss: 3.343142730614525
Validation loss: 2.8780510323755046

Epoch: 6| Step: 5
Training loss: 3.3227355014759383
Validation loss: 2.898051004921704

Epoch: 6| Step: 6
Training loss: 3.3544525277404444
Validation loss: 2.930287460969427

Epoch: 6| Step: 7
Training loss: 3.0859008786889546
Validation loss: 2.923208115402453

Epoch: 6| Step: 8
Training loss: 2.9074865192287773
Validation loss: 2.895815508340465

Epoch: 6| Step: 9
Training loss: 2.3353034852705226
Validation loss: 2.8635224455068284

Epoch: 6| Step: 10
Training loss: 3.4652814964897947
Validation loss: 2.854054799023465

Epoch: 6| Step: 11
Training loss: 3.0821598156704164
Validation loss: 2.8527366891944794

Epoch: 6| Step: 12
Training loss: 2.8775553749516423
Validation loss: 2.853899377735928

Epoch: 6| Step: 13
Training loss: 2.485157969191483
Validation loss: 2.8536246311778424

Epoch: 140| Step: 0
Training loss: 2.8125220403867295
Validation loss: 2.8533459300643025

Epoch: 6| Step: 1
Training loss: 3.315545175869637
Validation loss: 2.8539327725176094

Epoch: 6| Step: 2
Training loss: 2.4797248746174216
Validation loss: 2.8522689333123363

Epoch: 6| Step: 3
Training loss: 2.5565176191821406
Validation loss: 2.8571951357337

Epoch: 6| Step: 4
Training loss: 3.3790119485364434
Validation loss: 2.8743439461310594

Epoch: 6| Step: 5
Training loss: 3.8595608191602415
Validation loss: 2.858159287874059

Epoch: 6| Step: 6
Training loss: 3.285850424345185
Validation loss: 2.852119002892236

Epoch: 6| Step: 7
Training loss: 3.1274805523628304
Validation loss: 2.8529560149363555

Epoch: 6| Step: 8
Training loss: 2.785042737704807
Validation loss: 2.851648664443975

Epoch: 6| Step: 9
Training loss: 3.503108143149117
Validation loss: 2.8519482378541765

Epoch: 6| Step: 10
Training loss: 3.74903195920007
Validation loss: 2.8505208228767898

Epoch: 6| Step: 11
Training loss: 3.065311309288432
Validation loss: 2.8525382716242147

Epoch: 6| Step: 12
Training loss: 3.066100203676386
Validation loss: 2.8529634318969355

Epoch: 6| Step: 13
Training loss: 2.5561578001822136
Validation loss: 2.8524304678102856

Epoch: 141| Step: 0
Training loss: 2.8723849137560653
Validation loss: 2.856596692279876

Epoch: 6| Step: 1
Training loss: 3.360488210359157
Validation loss: 2.8587980629183876

Epoch: 6| Step: 2
Training loss: 2.7562685526874358
Validation loss: 2.85061361089937

Epoch: 6| Step: 3
Training loss: 3.4652205373096217
Validation loss: 2.851821208461108

Epoch: 6| Step: 4
Training loss: 3.191490965971307
Validation loss: 2.8513830371483206

Epoch: 6| Step: 5
Training loss: 3.697728599100066
Validation loss: 2.849562886295983

Epoch: 6| Step: 6
Training loss: 2.6838188687759743
Validation loss: 2.849478514837039

Epoch: 6| Step: 7
Training loss: 2.460213303351122
Validation loss: 2.851314744400148

Epoch: 6| Step: 8
Training loss: 2.3647218459195862
Validation loss: 2.8518592418231075

Epoch: 6| Step: 9
Training loss: 3.1371270433017897
Validation loss: 2.8571432454977637

Epoch: 6| Step: 10
Training loss: 3.1166089125669267
Validation loss: 2.8587455969057274

Epoch: 6| Step: 11
Training loss: 3.6178220517758235
Validation loss: 2.8590106504473543

Epoch: 6| Step: 12
Training loss: 3.431789996348921
Validation loss: 2.8638895671712614

Epoch: 6| Step: 13
Training loss: 3.949176731508664
Validation loss: 2.8576919333505337

Epoch: 142| Step: 0
Training loss: 3.1176466830694753
Validation loss: 2.850010605212868

Epoch: 6| Step: 1
Training loss: 3.288024303559933
Validation loss: 2.845791227121418

Epoch: 6| Step: 2
Training loss: 3.1681288973855244
Validation loss: 2.8483132107393376

Epoch: 6| Step: 3
Training loss: 2.770543181254455
Validation loss: 2.849515464769352

Epoch: 6| Step: 4
Training loss: 3.36098594187254
Validation loss: 2.8494623564009878

Epoch: 6| Step: 5
Training loss: 3.295438770029223
Validation loss: 2.849211894322663

Epoch: 6| Step: 6
Training loss: 3.495696964870187
Validation loss: 2.847112335444289

Epoch: 6| Step: 7
Training loss: 3.4292568901000022
Validation loss: 2.847344091771702

Epoch: 6| Step: 8
Training loss: 3.2666491495039054
Validation loss: 2.848072548170499

Epoch: 6| Step: 9
Training loss: 2.459007838760671
Validation loss: 2.847401589213658

Epoch: 6| Step: 10
Training loss: 2.7791515534851223
Validation loss: 2.84662679280002

Epoch: 6| Step: 11
Training loss: 3.033824338752691
Validation loss: 2.847571966995523

Epoch: 6| Step: 12
Training loss: 3.3939457115098026
Validation loss: 2.8462604474664115

Epoch: 6| Step: 13
Training loss: 3.023127734656415
Validation loss: 2.846063200677358

Epoch: 143| Step: 0
Training loss: 3.3444498345833984
Validation loss: 2.8454233912212863

Epoch: 6| Step: 1
Training loss: 2.9819042903346693
Validation loss: 2.8448739285677935

Epoch: 6| Step: 2
Training loss: 2.7513141959784737
Validation loss: 2.843817685617766

Epoch: 6| Step: 3
Training loss: 2.95825943832162
Validation loss: 2.8431377966683367

Epoch: 6| Step: 4
Training loss: 2.391054401603657
Validation loss: 2.8430827882863605

Epoch: 6| Step: 5
Training loss: 3.4996490302544534
Validation loss: 2.8430511443462465

Epoch: 6| Step: 6
Training loss: 3.484592858590042
Validation loss: 2.8423450681671065

Epoch: 6| Step: 7
Training loss: 3.425533759856556
Validation loss: 2.8439938092394916

Epoch: 6| Step: 8
Training loss: 3.209245296186278
Validation loss: 2.8406171890675385

Epoch: 6| Step: 9
Training loss: 2.9027132232967245
Validation loss: 2.8425158879234913

Epoch: 6| Step: 10
Training loss: 3.7736449885533467
Validation loss: 2.8405369570995296

Epoch: 6| Step: 11
Training loss: 3.13646243747699
Validation loss: 2.839674761065595

Epoch: 6| Step: 12
Training loss: 2.940353306412058
Validation loss: 2.8414731291393736

Epoch: 6| Step: 13
Training loss: 2.901317717991675
Validation loss: 2.83947884625728

Epoch: 144| Step: 0
Training loss: 3.1212249842853135
Validation loss: 2.8409604347190816

Epoch: 6| Step: 1
Training loss: 2.895391380194884
Validation loss: 2.839118696713049

Epoch: 6| Step: 2
Training loss: 2.9879129419679042
Validation loss: 2.840670873429791

Epoch: 6| Step: 3
Training loss: 3.008555134832768
Validation loss: 2.839907477314729

Epoch: 6| Step: 4
Training loss: 2.8727062861089716
Validation loss: 2.8417529441427014

Epoch: 6| Step: 5
Training loss: 3.5144062557658877
Validation loss: 2.8386742550261004

Epoch: 6| Step: 6
Training loss: 2.4104711985265
Validation loss: 2.841308445325821

Epoch: 6| Step: 7
Training loss: 4.068087681833439
Validation loss: 2.839564284044968

Epoch: 6| Step: 8
Training loss: 2.4925987358777517
Validation loss: 2.841995074136959

Epoch: 6| Step: 9
Training loss: 3.3987954137587337
Validation loss: 2.8430001443183888

Epoch: 6| Step: 10
Training loss: 3.3468949688654988
Validation loss: 2.8450168481942057

Epoch: 6| Step: 11
Training loss: 2.7345047402256237
Validation loss: 2.853318680291574

Epoch: 6| Step: 12
Training loss: 3.5667078699126558
Validation loss: 2.8527217417418926

Epoch: 6| Step: 13
Training loss: 3.1702431676360976
Validation loss: 2.8525468921584465

Epoch: 145| Step: 0
Training loss: 3.0331990376461513
Validation loss: 2.8598550677835703

Epoch: 6| Step: 1
Training loss: 1.885427534658677
Validation loss: 2.873075962285393

Epoch: 6| Step: 2
Training loss: 2.7014174167027827
Validation loss: 2.9031840425082933

Epoch: 6| Step: 3
Training loss: 2.9777387562689137
Validation loss: 2.9127725303190775

Epoch: 6| Step: 4
Training loss: 3.3572468958911412
Validation loss: 2.926613196944268

Epoch: 6| Step: 5
Training loss: 3.4218000290552886
Validation loss: 2.883804722789235

Epoch: 6| Step: 6
Training loss: 3.6375989657962453
Validation loss: 2.862488990573012

Epoch: 6| Step: 7
Training loss: 2.8742502312933444
Validation loss: 2.8428119950136677

Epoch: 6| Step: 8
Training loss: 3.3923043166349562
Validation loss: 2.8368612785103213

Epoch: 6| Step: 9
Training loss: 3.890074051296807
Validation loss: 2.8312653242681334

Epoch: 6| Step: 10
Training loss: 3.272196750797197
Validation loss: 2.8301507147655878

Epoch: 6| Step: 11
Training loss: 3.2367530226130214
Validation loss: 2.8296035412500893

Epoch: 6| Step: 12
Training loss: 3.2021249093752884
Validation loss: 2.830752228263141

Epoch: 6| Step: 13
Training loss: 2.4114928164121032
Validation loss: 2.832141834401263

Epoch: 146| Step: 0
Training loss: 3.1618119889884246
Validation loss: 2.8336934458592444

Epoch: 6| Step: 1
Training loss: 3.1938885264952086
Validation loss: 2.8349244634360358

Epoch: 6| Step: 2
Training loss: 2.4784126951760603
Validation loss: 2.840413356138989

Epoch: 6| Step: 3
Training loss: 3.088866106890026
Validation loss: 2.8392139630249953

Epoch: 6| Step: 4
Training loss: 2.8843216086226886
Validation loss: 2.8387672595833564

Epoch: 6| Step: 5
Training loss: 3.2464135261509552
Validation loss: 2.8354266310038128

Epoch: 6| Step: 6
Training loss: 2.866680381061957
Validation loss: 2.830799428887413

Epoch: 6| Step: 7
Training loss: 2.480653290379434
Validation loss: 2.8295864973949416

Epoch: 6| Step: 8
Training loss: 3.1778055006061363
Validation loss: 2.8304190148747104

Epoch: 6| Step: 9
Training loss: 2.9454180549304962
Validation loss: 2.8264449935716556

Epoch: 6| Step: 10
Training loss: 3.659181381563192
Validation loss: 2.828795427061281

Epoch: 6| Step: 11
Training loss: 3.098162346346041
Validation loss: 2.8286179139222933

Epoch: 6| Step: 12
Training loss: 3.9284674568784985
Validation loss: 2.8267557349652517

Epoch: 6| Step: 13
Training loss: 3.6739681689732175
Validation loss: 2.830363819082443

Epoch: 147| Step: 0
Training loss: 3.1410505471472256
Validation loss: 2.8312055088477166

Epoch: 6| Step: 1
Training loss: 3.7348606958927677
Validation loss: 2.8274453896152787

Epoch: 6| Step: 2
Training loss: 3.4704423504839013
Validation loss: 2.828629382506537

Epoch: 6| Step: 3
Training loss: 2.3089873983601845
Validation loss: 2.8282055795444405

Epoch: 6| Step: 4
Training loss: 2.6349946439279632
Validation loss: 2.8286754829546004

Epoch: 6| Step: 5
Training loss: 2.9627848878524765
Validation loss: 2.8266316502008686

Epoch: 6| Step: 6
Training loss: 3.0051797020317945
Validation loss: 2.8271063274965496

Epoch: 6| Step: 7
Training loss: 3.418994963132055
Validation loss: 2.827653177340499

Epoch: 6| Step: 8
Training loss: 3.4821132281373814
Validation loss: 2.829601036139606

Epoch: 6| Step: 9
Training loss: 3.125830120456895
Validation loss: 2.832403407384268

Epoch: 6| Step: 10
Training loss: 3.41822306531557
Validation loss: 2.846490167475776

Epoch: 6| Step: 11
Training loss: 2.771290466536222
Validation loss: 2.845679975860818

Epoch: 6| Step: 12
Training loss: 3.125094450476954
Validation loss: 2.8643015082806724

Epoch: 6| Step: 13
Training loss: 2.9450583107944555
Validation loss: 2.8824618595641907

Epoch: 148| Step: 0
Training loss: 2.5972104256464608
Validation loss: 2.8322955413936555

Epoch: 6| Step: 1
Training loss: 2.8054774454991773
Validation loss: 2.8268493356971893

Epoch: 6| Step: 2
Training loss: 3.5286014042646165
Validation loss: 2.8238934464428116

Epoch: 6| Step: 3
Training loss: 3.0467033142234086
Validation loss: 2.821336516851406

Epoch: 6| Step: 4
Training loss: 3.3614665772618992
Validation loss: 2.8245966018641924

Epoch: 6| Step: 5
Training loss: 3.8119890464713406
Validation loss: 2.826273533573907

Epoch: 6| Step: 6
Training loss: 3.426108054359419
Validation loss: 2.82731609869956

Epoch: 6| Step: 7
Training loss: 3.2554393147217375
Validation loss: 2.8302345654712338

Epoch: 6| Step: 8
Training loss: 2.7806563869015894
Validation loss: 2.832501264529015

Epoch: 6| Step: 9
Training loss: 2.81334554889552
Validation loss: 2.839041646091517

Epoch: 6| Step: 10
Training loss: 3.331821734693701
Validation loss: 2.8317801361153583

Epoch: 6| Step: 11
Training loss: 3.5728440940018564
Validation loss: 2.8302731941678747

Epoch: 6| Step: 12
Training loss: 2.8444293541640437
Validation loss: 2.8271431418193296

Epoch: 6| Step: 13
Training loss: 1.81557690134863
Validation loss: 2.825015791764381

Epoch: 149| Step: 0
Training loss: 3.3409494811608487
Validation loss: 2.8249556652397643

Epoch: 6| Step: 1
Training loss: 3.4688562600296056
Validation loss: 2.8233498545654325

Epoch: 6| Step: 2
Training loss: 2.7038920642708817
Validation loss: 2.821686001960534

Epoch: 6| Step: 3
Training loss: 2.938326455589838
Validation loss: 2.821807853043295

Epoch: 6| Step: 4
Training loss: 2.3258223443185733
Validation loss: 2.8211955062852896

Epoch: 6| Step: 5
Training loss: 4.1183517518217645
Validation loss: 2.820238883437933

Epoch: 6| Step: 6
Training loss: 3.1017691209513805
Validation loss: 2.8206087630099077

Epoch: 6| Step: 7
Training loss: 2.9834537382354225
Validation loss: 2.818393605673129

Epoch: 6| Step: 8
Training loss: 2.8099698023683755
Validation loss: 2.8163192867811624

Epoch: 6| Step: 9
Training loss: 3.5561256266266907
Validation loss: 2.8177519479059

Epoch: 6| Step: 10
Training loss: 3.390525429665583
Validation loss: 2.8161355443018237

Epoch: 6| Step: 11
Training loss: 2.793895135646952
Validation loss: 2.816348076986862

Epoch: 6| Step: 12
Training loss: 2.8104170821641783
Validation loss: 2.814370575827633

Epoch: 6| Step: 13
Training loss: 3.0489143002615466
Validation loss: 2.8116857464333216

Epoch: 150| Step: 0
Training loss: 2.877873187486195
Validation loss: 2.8149850510943604

Epoch: 6| Step: 1
Training loss: 3.796490810721279
Validation loss: 2.81377776914326

Epoch: 6| Step: 2
Training loss: 3.150953324185601
Validation loss: 2.8147428349986314

Epoch: 6| Step: 3
Training loss: 2.6412446688784637
Validation loss: 2.816516958186286

Epoch: 6| Step: 4
Training loss: 3.227741607912748
Validation loss: 2.8213632413761767

Epoch: 6| Step: 5
Training loss: 2.9778422010231393
Validation loss: 2.8223853501058014

Epoch: 6| Step: 6
Training loss: 3.2535439755563327
Validation loss: 2.838710502095816

Epoch: 6| Step: 7
Training loss: 2.9651723084067947
Validation loss: 2.843077991176778

Epoch: 6| Step: 8
Training loss: 2.838977371980221
Validation loss: 2.8491759464112425

Epoch: 6| Step: 9
Training loss: 3.1896772241674483
Validation loss: 2.853486313168576

Epoch: 6| Step: 10
Training loss: 2.982064676034989
Validation loss: 2.8233206200017116

Epoch: 6| Step: 11
Training loss: 3.135735496625531
Validation loss: 2.8124151602178125

Epoch: 6| Step: 12
Training loss: 3.1195093365746738
Validation loss: 2.8119409417981056

Epoch: 6| Step: 13
Training loss: 3.64417810558795
Validation loss: 2.813073386259953

Epoch: 151| Step: 0
Training loss: 3.2308457141947624
Validation loss: 2.811101498756877

Epoch: 6| Step: 1
Training loss: 2.590460104117682
Validation loss: 2.811116347415527

Epoch: 6| Step: 2
Training loss: 2.717854319392493
Validation loss: 2.8126110898117758

Epoch: 6| Step: 3
Training loss: 3.0466983059242634
Validation loss: 2.8139337191887197

Epoch: 6| Step: 4
Training loss: 3.627763944102601
Validation loss: 2.813485624372205

Epoch: 6| Step: 5
Training loss: 3.210001936819853
Validation loss: 2.815819714193975

Epoch: 6| Step: 6
Training loss: 3.430908541895508
Validation loss: 2.814212799827629

Epoch: 6| Step: 7
Training loss: 3.3850138419698004
Validation loss: 2.8143776481304266

Epoch: 6| Step: 8
Training loss: 3.1351747810278097
Validation loss: 2.8145231784034492

Epoch: 6| Step: 9
Training loss: 2.8031785566472176
Validation loss: 2.8150743777732528

Epoch: 6| Step: 10
Training loss: 2.504503390184432
Validation loss: 2.815657098177523

Epoch: 6| Step: 11
Training loss: 3.0127496006555208
Validation loss: 2.8142324583167415

Epoch: 6| Step: 12
Training loss: 3.2924294533554193
Validation loss: 2.8131768035538744

Epoch: 6| Step: 13
Training loss: 3.844654504063432
Validation loss: 2.813322550857885

Epoch: 152| Step: 0
Training loss: 2.5626218813311583
Validation loss: 2.813150023130456

Epoch: 6| Step: 1
Training loss: 3.1025651901244826
Validation loss: 2.813868324009656

Epoch: 6| Step: 2
Training loss: 3.1184773847730276
Validation loss: 2.818082139620233

Epoch: 6| Step: 3
Training loss: 3.013863953596136
Validation loss: 2.828937662813654

Epoch: 6| Step: 4
Training loss: 2.7948259061255563
Validation loss: 2.830517781127298

Epoch: 6| Step: 5
Training loss: 3.212716827793632
Validation loss: 2.846650951896685

Epoch: 6| Step: 6
Training loss: 3.8170005624524355
Validation loss: 2.880042108345577

Epoch: 6| Step: 7
Training loss: 3.138600926051328
Validation loss: 2.883603390559565

Epoch: 6| Step: 8
Training loss: 2.863329877869812
Validation loss: 2.8641415419590595

Epoch: 6| Step: 9
Training loss: 3.223973304496026
Validation loss: 2.8295979883276945

Epoch: 6| Step: 10
Training loss: 2.911450235336224
Validation loss: 2.8188787938537962

Epoch: 6| Step: 11
Training loss: 3.562710136774638
Validation loss: 2.817324615063405

Epoch: 6| Step: 12
Training loss: 3.176912263527491
Validation loss: 2.8043776746716587

Epoch: 6| Step: 13
Training loss: 3.1143302346843287
Validation loss: 2.8023637481175054

Epoch: 153| Step: 0
Training loss: 3.6824889968738765
Validation loss: 2.8041200717658787

Epoch: 6| Step: 1
Training loss: 3.4999927793155847
Validation loss: 2.805328503381519

Epoch: 6| Step: 2
Training loss: 2.53344894781146
Validation loss: 2.8056210799559187

Epoch: 6| Step: 3
Training loss: 3.3652994124138305
Validation loss: 2.8085591114429818

Epoch: 6| Step: 4
Training loss: 2.6672217466885466
Validation loss: 2.8086491244341376

Epoch: 6| Step: 5
Training loss: 3.909690135570434
Validation loss: 2.8073986499654704

Epoch: 6| Step: 6
Training loss: 2.9172525816463115
Validation loss: 2.80954071920931

Epoch: 6| Step: 7
Training loss: 3.2442426303763066
Validation loss: 2.8108986236779203

Epoch: 6| Step: 8
Training loss: 3.168565047244283
Validation loss: 2.809429511639704

Epoch: 6| Step: 9
Training loss: 3.5954890811665785
Validation loss: 2.8098488420680674

Epoch: 6| Step: 10
Training loss: 2.7258668903029553
Validation loss: 2.808198241869213

Epoch: 6| Step: 11
Training loss: 2.2943507226435265
Validation loss: 2.807551527399591

Epoch: 6| Step: 12
Training loss: 3.1373684069024925
Validation loss: 2.806166348417688

Epoch: 6| Step: 13
Training loss: 1.7715627701308791
Validation loss: 2.804336672615692

Epoch: 154| Step: 0
Training loss: 2.288083019897841
Validation loss: 2.806322101154876

Epoch: 6| Step: 1
Training loss: 3.15022639717443
Validation loss: 2.807114221435445

Epoch: 6| Step: 2
Training loss: 3.281629849200407
Validation loss: 2.8030652482930662

Epoch: 6| Step: 3
Training loss: 2.8192780940983444
Validation loss: 2.8037025234170034

Epoch: 6| Step: 4
Training loss: 2.9351587908289343
Validation loss: 2.8014493735090147

Epoch: 6| Step: 5
Training loss: 3.6505808119931515
Validation loss: 2.801860324853697

Epoch: 6| Step: 6
Training loss: 2.9526991764236055
Validation loss: 2.8083462010819074

Epoch: 6| Step: 7
Training loss: 3.002055735376288
Validation loss: 2.8138793024229423

Epoch: 6| Step: 8
Training loss: 3.450706221680531
Validation loss: 2.8097391311890196

Epoch: 6| Step: 9
Training loss: 3.6609580221345808
Validation loss: 2.812702210881097

Epoch: 6| Step: 10
Training loss: 3.2808105174433937
Validation loss: 2.8030781429933254

Epoch: 6| Step: 11
Training loss: 2.582076864373467
Validation loss: 2.8049597848942796

Epoch: 6| Step: 12
Training loss: 3.0241114927255195
Validation loss: 2.7990576684850392

Epoch: 6| Step: 13
Training loss: 3.3867045295531177
Validation loss: 2.8006559237987556

Epoch: 155| Step: 0
Training loss: 3.4472242660851116
Validation loss: 2.7993783449684426

Epoch: 6| Step: 1
Training loss: 2.9008823170663547
Validation loss: 2.802617223743103

Epoch: 6| Step: 2
Training loss: 2.545526627349805
Validation loss: 2.8063610169777626

Epoch: 6| Step: 3
Training loss: 2.294397380224033
Validation loss: 2.814126291734187

Epoch: 6| Step: 4
Training loss: 2.574097417770803
Validation loss: 2.8163020860675902

Epoch: 6| Step: 5
Training loss: 3.0119429330473038
Validation loss: 2.8186835691515086

Epoch: 6| Step: 6
Training loss: 3.434000349219187
Validation loss: 2.814853990213143

Epoch: 6| Step: 7
Training loss: 3.6600285755146755
Validation loss: 2.802546884168849

Epoch: 6| Step: 8
Training loss: 2.8300146039174834
Validation loss: 2.7999053641336813

Epoch: 6| Step: 9
Training loss: 4.012731793800155
Validation loss: 2.7989200199432442

Epoch: 6| Step: 10
Training loss: 3.5931995799615066
Validation loss: 2.79927486619533

Epoch: 6| Step: 11
Training loss: 2.9442531795479683
Validation loss: 2.797543287568309

Epoch: 6| Step: 12
Training loss: 3.276810321886227
Validation loss: 2.795898021214158

Epoch: 6| Step: 13
Training loss: 2.2211040849475414
Validation loss: 2.7948079934052497

Epoch: 156| Step: 0
Training loss: 2.833838492594773
Validation loss: 2.7951949396723355

Epoch: 6| Step: 1
Training loss: 3.7821697030889383
Validation loss: 2.794608512169353

Epoch: 6| Step: 2
Training loss: 2.76478900235426
Validation loss: 2.794304246531337

Epoch: 6| Step: 3
Training loss: 2.5538645127399326
Validation loss: 2.7952378715962842

Epoch: 6| Step: 4
Training loss: 2.497429479876861
Validation loss: 2.7958210118517424

Epoch: 6| Step: 5
Training loss: 3.527432158620062
Validation loss: 2.7939868221446824

Epoch: 6| Step: 6
Training loss: 3.040709375384994
Validation loss: 2.79823476314049

Epoch: 6| Step: 7
Training loss: 3.138656530716615
Validation loss: 2.7953892992696643

Epoch: 6| Step: 8
Training loss: 3.361376073252584
Validation loss: 2.795131179825096

Epoch: 6| Step: 9
Training loss: 3.672150556897744
Validation loss: 2.7964742280233437

Epoch: 6| Step: 10
Training loss: 2.756414648142383
Validation loss: 2.79657401159178

Epoch: 6| Step: 11
Training loss: 3.821440173387423
Validation loss: 2.8001093936827313

Epoch: 6| Step: 12
Training loss: 2.6254009667198392
Validation loss: 2.7949039904124247

Epoch: 6| Step: 13
Training loss: 2.3514909194748252
Validation loss: 2.792653084162794

Epoch: 157| Step: 0
Training loss: 3.5212046109579385
Validation loss: 2.7929794406550017

Epoch: 6| Step: 1
Training loss: 2.841852582142996
Validation loss: 2.790427157915108

Epoch: 6| Step: 2
Training loss: 2.8084852598243915
Validation loss: 2.7911005760912757

Epoch: 6| Step: 3
Training loss: 2.61879469075455
Validation loss: 2.7902765965553704

Epoch: 6| Step: 4
Training loss: 3.070226925344104
Validation loss: 2.790015736355896

Epoch: 6| Step: 5
Training loss: 2.7649527557089453
Validation loss: 2.789256376074459

Epoch: 6| Step: 6
Training loss: 3.0119155443466297
Validation loss: 2.788221403912342

Epoch: 6| Step: 7
Training loss: 3.670599273482364
Validation loss: 2.786256140218813

Epoch: 6| Step: 8
Training loss: 2.7722056917331788
Validation loss: 2.788542019230533

Epoch: 6| Step: 9
Training loss: 3.190650579665689
Validation loss: 2.788975676915544

Epoch: 6| Step: 10
Training loss: 3.322119510583949
Validation loss: 2.7905458126530482

Epoch: 6| Step: 11
Training loss: 2.872004731644582
Validation loss: 2.7874649531245583

Epoch: 6| Step: 12
Training loss: 3.1784982167686464
Validation loss: 2.7911018702649253

Epoch: 6| Step: 13
Training loss: 3.8969252716957703
Validation loss: 2.785620583448765

Epoch: 158| Step: 0
Training loss: 3.0630564281460497
Validation loss: 2.7862290651574857

Epoch: 6| Step: 1
Training loss: 2.7927038533963207
Validation loss: 2.785710747737712

Epoch: 6| Step: 2
Training loss: 3.2685726314584382
Validation loss: 2.7848629373830716

Epoch: 6| Step: 3
Training loss: 3.1099351541314864
Validation loss: 2.7852441898991

Epoch: 6| Step: 4
Training loss: 2.84569876833486
Validation loss: 2.785431156508392

Epoch: 6| Step: 5
Training loss: 3.005285216901104
Validation loss: 2.783919550754651

Epoch: 6| Step: 6
Training loss: 2.835473224898915
Validation loss: 2.7838242478172437

Epoch: 6| Step: 7
Training loss: 3.9318421904832674
Validation loss: 2.78719454356794

Epoch: 6| Step: 8
Training loss: 3.0233010746736024
Validation loss: 2.7857861408549525

Epoch: 6| Step: 9
Training loss: 3.149535032802709
Validation loss: 2.7870295223895982

Epoch: 6| Step: 10
Training loss: 2.9248840830730476
Validation loss: 2.792785883621642

Epoch: 6| Step: 11
Training loss: 3.4734156392962974
Validation loss: 2.8031865026840617

Epoch: 6| Step: 12
Training loss: 2.771898557268265
Validation loss: 2.7968191284604744

Epoch: 6| Step: 13
Training loss: 2.9912192269514586
Validation loss: 2.799138521539837

Epoch: 159| Step: 0
Training loss: 3.474056412181168
Validation loss: 2.78951068752857

Epoch: 6| Step: 1
Training loss: 3.574551192702106
Validation loss: 2.784473560976678

Epoch: 6| Step: 2
Training loss: 3.1949329850357784
Validation loss: 2.781911736456484

Epoch: 6| Step: 3
Training loss: 2.8012012289177184
Validation loss: 2.7844143994860957

Epoch: 6| Step: 4
Training loss: 3.408737534212401
Validation loss: 2.7827488177953934

Epoch: 6| Step: 5
Training loss: 3.269903127652775
Validation loss: 2.783051526169206

Epoch: 6| Step: 6
Training loss: 2.6777967895089687
Validation loss: 2.7836011834594316

Epoch: 6| Step: 7
Training loss: 2.8462654139487107
Validation loss: 2.781644526105312

Epoch: 6| Step: 8
Training loss: 3.409784985025303
Validation loss: 2.784124566713234

Epoch: 6| Step: 9
Training loss: 2.593975103330878
Validation loss: 2.784022266889414

Epoch: 6| Step: 10
Training loss: 3.507185780160158
Validation loss: 2.7846700507472777

Epoch: 6| Step: 11
Training loss: 3.0091787430732113
Validation loss: 2.784574023159714

Epoch: 6| Step: 12
Training loss: 2.811172765584258
Validation loss: 2.78318158011669

Epoch: 6| Step: 13
Training loss: 2.123025537855635
Validation loss: 2.781627751509039

Epoch: 160| Step: 0
Training loss: 2.2952214731301583
Validation loss: 2.784313966531877

Epoch: 6| Step: 1
Training loss: 3.309192661813157
Validation loss: 2.7858713342323895

Epoch: 6| Step: 2
Training loss: 2.8488237998947357
Validation loss: 2.785687174603718

Epoch: 6| Step: 3
Training loss: 3.295017966885706
Validation loss: 2.7851433837015387

Epoch: 6| Step: 4
Training loss: 3.2742640651223986
Validation loss: 2.7833474281263144

Epoch: 6| Step: 5
Training loss: 3.5576884921999197
Validation loss: 2.7810849044779697

Epoch: 6| Step: 6
Training loss: 3.1074771168879782
Validation loss: 2.781749804409641

Epoch: 6| Step: 7
Training loss: 2.7541508126391676
Validation loss: 2.7793085397241737

Epoch: 6| Step: 8
Training loss: 3.335341675054517
Validation loss: 2.779968325889747

Epoch: 6| Step: 9
Training loss: 3.602662553581113
Validation loss: 2.779656622414952

Epoch: 6| Step: 10
Training loss: 3.011044041995958
Validation loss: 2.78045407398864

Epoch: 6| Step: 11
Training loss: 3.2625773687433273
Validation loss: 2.778000881779077

Epoch: 6| Step: 12
Training loss: 2.551290043652587
Validation loss: 2.779500555115899

Epoch: 6| Step: 13
Training loss: 2.643804498205464
Validation loss: 2.7809054419472736

Epoch: 161| Step: 0
Training loss: 3.9039793205026214
Validation loss: 2.7789262846757046

Epoch: 6| Step: 1
Training loss: 2.973091404428137
Validation loss: 2.7783661727455127

Epoch: 6| Step: 2
Training loss: 2.4098605526353998
Validation loss: 2.7807363367858415

Epoch: 6| Step: 3
Training loss: 3.748241012022053
Validation loss: 2.777861568732182

Epoch: 6| Step: 4
Training loss: 3.4120990335955192
Validation loss: 2.7777156192907406

Epoch: 6| Step: 5
Training loss: 3.120608792208467
Validation loss: 2.784263398807137

Epoch: 6| Step: 6
Training loss: 2.7053308912817378
Validation loss: 2.7947337472209766

Epoch: 6| Step: 7
Training loss: 3.2587794051400207
Validation loss: 2.7861066674338093

Epoch: 6| Step: 8
Training loss: 2.6018121273115002
Validation loss: 2.787305724028201

Epoch: 6| Step: 9
Training loss: 3.6430184678544943
Validation loss: 2.788048330680182

Epoch: 6| Step: 10
Training loss: 3.1404602614890225
Validation loss: 2.777962886494497

Epoch: 6| Step: 11
Training loss: 2.870110375810648
Validation loss: 2.7756501784287315

Epoch: 6| Step: 12
Training loss: 2.072009272992803
Validation loss: 2.7738377999897375

Epoch: 6| Step: 13
Training loss: 2.774666527308922
Validation loss: 2.775028597924472

Epoch: 162| Step: 0
Training loss: 2.675922740898696
Validation loss: 2.775183763842918

Epoch: 6| Step: 1
Training loss: 2.95304539487408
Validation loss: 2.775130006183195

Epoch: 6| Step: 2
Training loss: 3.5804683557951726
Validation loss: 2.7715870525024733

Epoch: 6| Step: 3
Training loss: 2.8278407170007895
Validation loss: 2.772411968760976

Epoch: 6| Step: 4
Training loss: 2.512522804574291
Validation loss: 2.7725385319051052

Epoch: 6| Step: 5
Training loss: 2.591258955487805
Validation loss: 2.7722300268348006

Epoch: 6| Step: 6
Training loss: 3.251179261103514
Validation loss: 2.771807851192033

Epoch: 6| Step: 7
Training loss: 2.3421467701816874
Validation loss: 2.7733743381081832

Epoch: 6| Step: 8
Training loss: 3.556946290407236
Validation loss: 2.7799250908293223

Epoch: 6| Step: 9
Training loss: 3.3066419228530384
Validation loss: 2.7714280729918466

Epoch: 6| Step: 10
Training loss: 3.2282305601425803
Validation loss: 2.7741056125993158

Epoch: 6| Step: 11
Training loss: 3.742042108630157
Validation loss: 2.775091459804528

Epoch: 6| Step: 12
Training loss: 3.081326905813189
Validation loss: 2.7714458620931826

Epoch: 6| Step: 13
Training loss: 3.32037497068989
Validation loss: 2.7711968810663836

Epoch: 163| Step: 0
Training loss: 3.1144110760636603
Validation loss: 2.7709605295496473

Epoch: 6| Step: 1
Training loss: 2.4403862126917426
Validation loss: 2.770856365139284

Epoch: 6| Step: 2
Training loss: 3.1521077688160455
Validation loss: 2.7699496938667827

Epoch: 6| Step: 3
Training loss: 3.034415882593412
Validation loss: 2.769286195090601

Epoch: 6| Step: 4
Training loss: 3.2563883277960337
Validation loss: 2.767775815136858

Epoch: 6| Step: 5
Training loss: 2.9767464007740876
Validation loss: 2.770440506705208

Epoch: 6| Step: 6
Training loss: 3.2129278766362477
Validation loss: 2.7699509655293806

Epoch: 6| Step: 7
Training loss: 3.2002352449255618
Validation loss: 2.769916776668028

Epoch: 6| Step: 8
Training loss: 3.4557084995888845
Validation loss: 2.771988037740448

Epoch: 6| Step: 9
Training loss: 2.5911951926177075
Validation loss: 2.7717084635281433

Epoch: 6| Step: 10
Training loss: 2.6638204962479115
Validation loss: 2.7739784407609593

Epoch: 6| Step: 11
Training loss: 2.9964850815468957
Validation loss: 2.7725228497179533

Epoch: 6| Step: 12
Training loss: 3.583836823214367
Validation loss: 2.7688966123442413

Epoch: 6| Step: 13
Training loss: 3.4545293515573845
Validation loss: 2.768133621126638

Epoch: 164| Step: 0
Training loss: 2.2207340449694395
Validation loss: 2.7691733635289193

Epoch: 6| Step: 1
Training loss: 3.039804245518816
Validation loss: 2.76773764335929

Epoch: 6| Step: 2
Training loss: 2.8500718492519512
Validation loss: 2.7674312775053744

Epoch: 6| Step: 3
Training loss: 3.926686409370086
Validation loss: 2.7677764301639796

Epoch: 6| Step: 4
Training loss: 2.79337914926227
Validation loss: 2.766627376686114

Epoch: 6| Step: 5
Training loss: 3.0376423555147323
Validation loss: 2.767601256764857

Epoch: 6| Step: 6
Training loss: 2.925272226299875
Validation loss: 2.76872730520361

Epoch: 6| Step: 7
Training loss: 2.2817170174585653
Validation loss: 2.7670491809097024

Epoch: 6| Step: 8
Training loss: 2.7411679711964894
Validation loss: 2.7650140006638027

Epoch: 6| Step: 9
Training loss: 3.158817870751046
Validation loss: 2.766996390915752

Epoch: 6| Step: 10
Training loss: 3.726802794188668
Validation loss: 2.76513624915872

Epoch: 6| Step: 11
Training loss: 3.2541623970684284
Validation loss: 2.7653863575749993

Epoch: 6| Step: 12
Training loss: 3.1256224965934285
Validation loss: 2.7679563391810613

Epoch: 6| Step: 13
Training loss: 3.863651022653769
Validation loss: 2.7716601705807693

Epoch: 165| Step: 0
Training loss: 3.020781067143932
Validation loss: 2.7696171442394024

Epoch: 6| Step: 1
Training loss: 2.256794947702188
Validation loss: 2.7750619755189216

Epoch: 6| Step: 2
Training loss: 3.5225525821093977
Validation loss: 2.777013374555632

Epoch: 6| Step: 3
Training loss: 3.2166495274958473
Validation loss: 2.7671198942792605

Epoch: 6| Step: 4
Training loss: 2.6012791201470646
Validation loss: 2.765587746835251

Epoch: 6| Step: 5
Training loss: 3.403850024907888
Validation loss: 2.766338312249342

Epoch: 6| Step: 6
Training loss: 2.896657227331423
Validation loss: 2.7683690601379722

Epoch: 6| Step: 7
Training loss: 3.076560615318112
Validation loss: 2.770254803040577

Epoch: 6| Step: 8
Training loss: 3.0738624453522276
Validation loss: 2.768666818331707

Epoch: 6| Step: 9
Training loss: 3.2408637228342245
Validation loss: 2.767734411641349

Epoch: 6| Step: 10
Training loss: 2.925071395915596
Validation loss: 2.770546330118614

Epoch: 6| Step: 11
Training loss: 3.581867243382807
Validation loss: 2.7698608213452163

Epoch: 6| Step: 12
Training loss: 3.1542055665963904
Validation loss: 2.768205873759138

Epoch: 6| Step: 13
Training loss: 2.798418098863818
Validation loss: 2.769201782925637

Epoch: 166| Step: 0
Training loss: 3.6839864770266244
Validation loss: 2.7677498912488976

Epoch: 6| Step: 1
Training loss: 2.210390919767016
Validation loss: 2.7672843490317947

Epoch: 6| Step: 2
Training loss: 2.988021460316919
Validation loss: 2.767971842554367

Epoch: 6| Step: 3
Training loss: 2.893298588059229
Validation loss: 2.7692966540880333

Epoch: 6| Step: 4
Training loss: 2.698602498393555
Validation loss: 2.766765443002538

Epoch: 6| Step: 5
Training loss: 3.005159391977638
Validation loss: 2.7665264351575742

Epoch: 6| Step: 6
Training loss: 3.1438497053530776
Validation loss: 2.764827174970332

Epoch: 6| Step: 7
Training loss: 3.9031401194882047
Validation loss: 2.7631901156078382

Epoch: 6| Step: 8
Training loss: 2.834495661311144
Validation loss: 2.7626533725940265

Epoch: 6| Step: 9
Training loss: 3.182122575145708
Validation loss: 2.7609584419866753

Epoch: 6| Step: 10
Training loss: 2.9855892247769122
Validation loss: 2.761777390506703

Epoch: 6| Step: 11
Training loss: 3.36062527833029
Validation loss: 2.7623520947726923

Epoch: 6| Step: 12
Training loss: 3.4372579315957466
Validation loss: 2.7627775368463703

Epoch: 6| Step: 13
Training loss: 1.7296740082556612
Validation loss: 2.767089809933648

Epoch: 167| Step: 0
Training loss: 3.1966875097757446
Validation loss: 2.7676817051143727

Epoch: 6| Step: 1
Training loss: 3.578196162553132
Validation loss: 2.765976846536721

Epoch: 6| Step: 2
Training loss: 2.9747528422292624
Validation loss: 2.771298949424945

Epoch: 6| Step: 3
Training loss: 3.183183926842647
Validation loss: 2.7650313294344064

Epoch: 6| Step: 4
Training loss: 3.1761072045496954
Validation loss: 2.76536809238891

Epoch: 6| Step: 5
Training loss: 3.0097919242645603
Validation loss: 2.7597075214128584

Epoch: 6| Step: 6
Training loss: 2.520036513654389
Validation loss: 2.760425150775622

Epoch: 6| Step: 7
Training loss: 3.1097349025673564
Validation loss: 2.7581372134228723

Epoch: 6| Step: 8
Training loss: 2.8069954304754763
Validation loss: 2.7617696079846774

Epoch: 6| Step: 9
Training loss: 3.2340123069967808
Validation loss: 2.759258421199082

Epoch: 6| Step: 10
Training loss: 2.559561649731382
Validation loss: 2.7594662875926748

Epoch: 6| Step: 11
Training loss: 3.338488137485053
Validation loss: 2.7590001513857945

Epoch: 6| Step: 12
Training loss: 3.1445379221590706
Validation loss: 2.757398276129877

Epoch: 6| Step: 13
Training loss: 3.130521854857467
Validation loss: 2.7571698966703924

Epoch: 168| Step: 0
Training loss: 3.277292826351243
Validation loss: 2.758022103891752

Epoch: 6| Step: 1
Training loss: 2.428489463288491
Validation loss: 2.756478290722419

Epoch: 6| Step: 2
Training loss: 3.101614464005028
Validation loss: 2.7567238903927396

Epoch: 6| Step: 3
Training loss: 3.168191509199664
Validation loss: 2.7559969379984857

Epoch: 6| Step: 4
Training loss: 3.48825773805766
Validation loss: 2.757971876744215

Epoch: 6| Step: 5
Training loss: 2.5704230658685017
Validation loss: 2.760513820010421

Epoch: 6| Step: 6
Training loss: 2.516779190562627
Validation loss: 2.764312055213621

Epoch: 6| Step: 7
Training loss: 4.121398740935789
Validation loss: 2.765902005313354

Epoch: 6| Step: 8
Training loss: 2.307976913019338
Validation loss: 2.762689998130379

Epoch: 6| Step: 9
Training loss: 2.7076823895029336
Validation loss: 2.766124614630849

Epoch: 6| Step: 10
Training loss: 3.237810015471733
Validation loss: 2.7632418965438323

Epoch: 6| Step: 11
Training loss: 3.3937779546608513
Validation loss: 2.7610163753295325

Epoch: 6| Step: 12
Training loss: 3.2093405360495115
Validation loss: 2.75962322128882

Epoch: 6| Step: 13
Training loss: 2.9044269052936
Validation loss: 2.7588438308598007

Epoch: 169| Step: 0
Training loss: 3.4446715020299066
Validation loss: 2.756293846058612

Epoch: 6| Step: 1
Training loss: 3.7801696242768874
Validation loss: 2.755342347940554

Epoch: 6| Step: 2
Training loss: 3.5963345728991194
Validation loss: 2.753035519128065

Epoch: 6| Step: 3
Training loss: 2.9608510188454837
Validation loss: 2.7555608413198804

Epoch: 6| Step: 4
Training loss: 2.6606673367272533
Validation loss: 2.752584138201057

Epoch: 6| Step: 5
Training loss: 2.7735222602034835
Validation loss: 2.7509028825433273

Epoch: 6| Step: 6
Training loss: 2.6181188036639735
Validation loss: 2.753471954319069

Epoch: 6| Step: 7
Training loss: 3.7439272983453367
Validation loss: 2.750316171006128

Epoch: 6| Step: 8
Training loss: 2.8482117915537635
Validation loss: 2.750609462729842

Epoch: 6| Step: 9
Training loss: 2.9593719127924927
Validation loss: 2.750705555769253

Epoch: 6| Step: 10
Training loss: 2.0717282618692616
Validation loss: 2.7509938100886524

Epoch: 6| Step: 11
Training loss: 2.7562725317070824
Validation loss: 2.7486986929626873

Epoch: 6| Step: 12
Training loss: 3.1588362871226443
Validation loss: 2.7512529023029977

Epoch: 6| Step: 13
Training loss: 3.227504047890628
Validation loss: 2.7505305217570557

Epoch: 170| Step: 0
Training loss: 2.5724132730083746
Validation loss: 2.751514413090862

Epoch: 6| Step: 1
Training loss: 2.863825934879864
Validation loss: 2.7520089590928887

Epoch: 6| Step: 2
Training loss: 3.5227225988810122
Validation loss: 2.7502735799847216

Epoch: 6| Step: 3
Training loss: 1.9789618001280285
Validation loss: 2.751259567520593

Epoch: 6| Step: 4
Training loss: 4.013846987131971
Validation loss: 2.7505869709767983

Epoch: 6| Step: 5
Training loss: 3.770958506717782
Validation loss: 2.750556787821447

Epoch: 6| Step: 6
Training loss: 2.972520381514325
Validation loss: 2.751207109128625

Epoch: 6| Step: 7
Training loss: 3.6424270557647938
Validation loss: 2.747705382300751

Epoch: 6| Step: 8
Training loss: 2.8902772436508606
Validation loss: 2.747385738237422

Epoch: 6| Step: 9
Training loss: 3.1566068239860585
Validation loss: 2.749464432219039

Epoch: 6| Step: 10
Training loss: 2.5550175724806308
Validation loss: 2.747605025754431

Epoch: 6| Step: 11
Training loss: 3.1598782977075626
Validation loss: 2.7531707342334464

Epoch: 6| Step: 12
Training loss: 1.92669773539844
Validation loss: 2.7501302289284917

Epoch: 6| Step: 13
Training loss: 3.0688934541257504
Validation loss: 2.7453437364080897

Epoch: 171| Step: 0
Training loss: 3.534474748709853
Validation loss: 2.7508225893380915

Epoch: 6| Step: 1
Training loss: 2.8598047152451476
Validation loss: 2.749681594180125

Epoch: 6| Step: 2
Training loss: 3.30254278185594
Validation loss: 2.746621298349084

Epoch: 6| Step: 3
Training loss: 3.5761709416386687
Validation loss: 2.7466274203798853

Epoch: 6| Step: 4
Training loss: 2.3098297167020587
Validation loss: 2.745938007397995

Epoch: 6| Step: 5
Training loss: 2.7233606464443536
Validation loss: 2.7456343706565756

Epoch: 6| Step: 6
Training loss: 3.0066153385605188
Validation loss: 2.740870093374737

Epoch: 6| Step: 7
Training loss: 2.398879914376168
Validation loss: 2.7420424275832906

Epoch: 6| Step: 8
Training loss: 3.3754940377794287
Validation loss: 2.742832711519361

Epoch: 6| Step: 9
Training loss: 3.1518033875078344
Validation loss: 2.7426888332159236

Epoch: 6| Step: 10
Training loss: 3.4388889627725416
Validation loss: 2.7450626663934847

Epoch: 6| Step: 11
Training loss: 3.1555005685137543
Validation loss: 2.7431416498846835

Epoch: 6| Step: 12
Training loss: 3.138856760121284
Validation loss: 2.742236190451035

Epoch: 6| Step: 13
Training loss: 2.242460121302023
Validation loss: 2.743431222249944

Epoch: 172| Step: 0
Training loss: 2.558591979513939
Validation loss: 2.743321573665874

Epoch: 6| Step: 1
Training loss: 3.1631289011341965
Validation loss: 2.7440020836328007

Epoch: 6| Step: 2
Training loss: 3.309474787229776
Validation loss: 2.743990268820609

Epoch: 6| Step: 3
Training loss: 3.204365113408473
Validation loss: 2.7456605098900906

Epoch: 6| Step: 4
Training loss: 3.665255419481576
Validation loss: 2.74520871571143

Epoch: 6| Step: 5
Training loss: 3.0631513875973946
Validation loss: 2.748303918609142

Epoch: 6| Step: 6
Training loss: 2.8871191260743867
Validation loss: 2.7498224859286147

Epoch: 6| Step: 7
Training loss: 2.928656394071543
Validation loss: 2.7537407756619254

Epoch: 6| Step: 8
Training loss: 2.78457425792752
Validation loss: 2.7509216002331867

Epoch: 6| Step: 9
Training loss: 3.5185564492692647
Validation loss: 2.7477279004402875

Epoch: 6| Step: 10
Training loss: 2.992695180189309
Validation loss: 2.745227751447852

Epoch: 6| Step: 11
Training loss: 2.8186139092929037
Validation loss: 2.7473801474431325

Epoch: 6| Step: 12
Training loss: 2.4988130612833923
Validation loss: 2.7461902615043665

Epoch: 6| Step: 13
Training loss: 3.4167949993564077
Validation loss: 2.747668191278884

Epoch: 173| Step: 0
Training loss: 3.562744132260009
Validation loss: 2.7523604300121556

Epoch: 6| Step: 1
Training loss: 2.487968389224435
Validation loss: 2.7473995278504737

Epoch: 6| Step: 2
Training loss: 3.2509283060495533
Validation loss: 2.7501800679518116

Epoch: 6| Step: 3
Training loss: 3.33555568680949
Validation loss: 2.752964538037701

Epoch: 6| Step: 4
Training loss: 3.332714802257468
Validation loss: 2.7516948645403767

Epoch: 6| Step: 5
Training loss: 2.901361106576007
Validation loss: 2.7419723063101022

Epoch: 6| Step: 6
Training loss: 2.760922933733284
Validation loss: 2.739492968793849

Epoch: 6| Step: 7
Training loss: 3.305318857760147
Validation loss: 2.737981048765407

Epoch: 6| Step: 8
Training loss: 2.473575848911078
Validation loss: 2.7408321969482303

Epoch: 6| Step: 9
Training loss: 3.4027033549017993
Validation loss: 2.739516490237955

Epoch: 6| Step: 10
Training loss: 2.62029917195524
Validation loss: 2.739259512073486

Epoch: 6| Step: 11
Training loss: 3.1286956297127704
Validation loss: 2.741456410112809

Epoch: 6| Step: 12
Training loss: 3.1911399851631748
Validation loss: 2.74461005644215

Epoch: 6| Step: 13
Training loss: 2.805792715626285
Validation loss: 2.746470826881828

Epoch: 174| Step: 0
Training loss: 2.977460590553356
Validation loss: 2.744791028120626

Epoch: 6| Step: 1
Training loss: 2.884684464043214
Validation loss: 2.7426719437442824

Epoch: 6| Step: 2
Training loss: 2.417045848520482
Validation loss: 2.7422028368093962

Epoch: 6| Step: 3
Training loss: 2.267660555133979
Validation loss: 2.744529350283397

Epoch: 6| Step: 4
Training loss: 3.5275139413797385
Validation loss: 2.7526170009639377

Epoch: 6| Step: 5
Training loss: 3.133091331497361
Validation loss: 2.7572137944506205

Epoch: 6| Step: 6
Training loss: 2.8112227188625285
Validation loss: 2.750805461830684

Epoch: 6| Step: 7
Training loss: 3.2524624812244123
Validation loss: 2.7486880968295155

Epoch: 6| Step: 8
Training loss: 3.2583578188497313
Validation loss: 2.7527848552476852

Epoch: 6| Step: 9
Training loss: 3.3154194760059976
Validation loss: 2.7500276461616475

Epoch: 6| Step: 10
Training loss: 2.870819369329662
Validation loss: 2.75067449783117

Epoch: 6| Step: 11
Training loss: 3.579069720825276
Validation loss: 2.754675391292873

Epoch: 6| Step: 12
Training loss: 2.3541037176937785
Validation loss: 2.7575595157171366

Epoch: 6| Step: 13
Training loss: 4.252949308400492
Validation loss: 2.7534646641294165

Epoch: 175| Step: 0
Training loss: 2.907963401490669
Validation loss: 2.735841652739887

Epoch: 6| Step: 1
Training loss: 3.4900060748727824
Validation loss: 2.734391281618553

Epoch: 6| Step: 2
Training loss: 3.186928641778106
Validation loss: 2.7360474490398565

Epoch: 6| Step: 3
Training loss: 2.6546419549529805
Validation loss: 2.736763525347635

Epoch: 6| Step: 4
Training loss: 2.5644163084038474
Validation loss: 2.735231687822688

Epoch: 6| Step: 5
Training loss: 3.365645690684355
Validation loss: 2.735591736553003

Epoch: 6| Step: 6
Training loss: 3.1865390002110003
Validation loss: 2.7397129479377145

Epoch: 6| Step: 7
Training loss: 3.821717173701073
Validation loss: 2.7389358572003606

Epoch: 6| Step: 8
Training loss: 2.8497238293070284
Validation loss: 2.7399249254373923

Epoch: 6| Step: 9
Training loss: 3.3234156569752633
Validation loss: 2.743061259405574

Epoch: 6| Step: 10
Training loss: 1.6763284141183645
Validation loss: 2.749886089960102

Epoch: 6| Step: 11
Training loss: 3.118187153698168
Validation loss: 2.757215990622996

Epoch: 6| Step: 12
Training loss: 3.2190009454475144
Validation loss: 2.7488233196736935

Epoch: 6| Step: 13
Training loss: 2.872569508056033
Validation loss: 2.745329465824229

Epoch: 176| Step: 0
Training loss: 3.2292705560195185
Validation loss: 2.7394568968843194

Epoch: 6| Step: 1
Training loss: 3.510467000689117
Validation loss: 2.737524478196256

Epoch: 6| Step: 2
Training loss: 2.7562308382159713
Validation loss: 2.7369300916955885

Epoch: 6| Step: 3
Training loss: 3.6688504362899215
Validation loss: 2.737430805045956

Epoch: 6| Step: 4
Training loss: 3.7040458210362273
Validation loss: 2.73670110859678

Epoch: 6| Step: 5
Training loss: 2.916842609730001
Validation loss: 2.7346602771272184

Epoch: 6| Step: 6
Training loss: 2.7282873780472454
Validation loss: 2.733307287595817

Epoch: 6| Step: 7
Training loss: 2.7427311980476055
Validation loss: 2.733481439944293

Epoch: 6| Step: 8
Training loss: 3.232294712849955
Validation loss: 2.7363766705028665

Epoch: 6| Step: 9
Training loss: 2.72907357870055
Validation loss: 2.7345820072881706

Epoch: 6| Step: 10
Training loss: 3.2250840168736
Validation loss: 2.731620558664579

Epoch: 6| Step: 11
Training loss: 2.8100086622002833
Validation loss: 2.7306358956031973

Epoch: 6| Step: 12
Training loss: 2.186661913951888
Validation loss: 2.730819699076773

Epoch: 6| Step: 13
Training loss: 2.851664000494502
Validation loss: 2.732877483805553

Epoch: 177| Step: 0
Training loss: 3.1177066380251577
Validation loss: 2.7327117370945966

Epoch: 6| Step: 1
Training loss: 3.216686587362586
Validation loss: 2.734962421376612

Epoch: 6| Step: 2
Training loss: 3.487290193543109
Validation loss: 2.7317801646760422

Epoch: 6| Step: 3
Training loss: 2.855645587836074
Validation loss: 2.733959348996405

Epoch: 6| Step: 4
Training loss: 3.0546174102313017
Validation loss: 2.734282566272011

Epoch: 6| Step: 5
Training loss: 3.1548407401682255
Validation loss: 2.7365884099273714

Epoch: 6| Step: 6
Training loss: 3.7377269816289123
Validation loss: 2.734105835776451

Epoch: 6| Step: 7
Training loss: 2.4652741505293214
Validation loss: 2.7317688469387993

Epoch: 6| Step: 8
Training loss: 3.074940849913824
Validation loss: 2.736142379158431

Epoch: 6| Step: 9
Training loss: 2.66222589004121
Validation loss: 2.7324439317640015

Epoch: 6| Step: 10
Training loss: 2.822520398318811
Validation loss: 2.731676856207665

Epoch: 6| Step: 11
Training loss: 3.2827252659198862
Validation loss: 2.729497016114242

Epoch: 6| Step: 12
Training loss: 2.8585193792209695
Validation loss: 2.7344212738200038

Epoch: 6| Step: 13
Training loss: 2.3590799109235463
Validation loss: 2.7301029492706474

Epoch: 178| Step: 0
Training loss: 3.0192458793938624
Validation loss: 2.7290298445151846

Epoch: 6| Step: 1
Training loss: 3.244379465404679
Validation loss: 2.7261349909706674

Epoch: 6| Step: 2
Training loss: 2.64668274308454
Validation loss: 2.728437125333987

Epoch: 6| Step: 3
Training loss: 3.0158118946093095
Validation loss: 2.7325506637582895

Epoch: 6| Step: 4
Training loss: 3.188465645320131
Validation loss: 2.7304719610405286

Epoch: 6| Step: 5
Training loss: 2.9267724755638698
Validation loss: 2.728976897745303

Epoch: 6| Step: 6
Training loss: 3.436525380079019
Validation loss: 2.7306529515256104

Epoch: 6| Step: 7
Training loss: 2.9520048408778745
Validation loss: 2.7308235612175507

Epoch: 6| Step: 8
Training loss: 3.129196553567995
Validation loss: 2.737987082438306

Epoch: 6| Step: 9
Training loss: 2.6385718495394217
Validation loss: 2.7416296371226916

Epoch: 6| Step: 10
Training loss: 3.359155692105704
Validation loss: 2.746917290712985

Epoch: 6| Step: 11
Training loss: 3.184503680353588
Validation loss: 2.7520327731961944

Epoch: 6| Step: 12
Training loss: 3.065035957262414
Validation loss: 2.756073149526123

Epoch: 6| Step: 13
Training loss: 2.5857063489790626
Validation loss: 2.752580109144378

Epoch: 179| Step: 0
Training loss: 2.216410518369172
Validation loss: 2.755813027650444

Epoch: 6| Step: 1
Training loss: 2.2869233952458172
Validation loss: 2.7504976135596455

Epoch: 6| Step: 2
Training loss: 3.004861706996485
Validation loss: 2.747172612823289

Epoch: 6| Step: 3
Training loss: 2.583604203656656
Validation loss: 2.7472199793953687

Epoch: 6| Step: 4
Training loss: 3.633395765508949
Validation loss: 2.748426891703952

Epoch: 6| Step: 5
Training loss: 2.7949828668386556
Validation loss: 2.742134844682242

Epoch: 6| Step: 6
Training loss: 3.259203277775011
Validation loss: 2.7270418208811544

Epoch: 6| Step: 7
Training loss: 3.3224590947121015
Validation loss: 2.724996261541431

Epoch: 6| Step: 8
Training loss: 2.971166811537996
Validation loss: 2.735393366176975

Epoch: 6| Step: 9
Training loss: 3.7137964418961924
Validation loss: 2.7478817736533308

Epoch: 6| Step: 10
Training loss: 2.838569365666651
Validation loss: 2.732141457389924

Epoch: 6| Step: 11
Training loss: 3.813016012322725
Validation loss: 2.724735553272181

Epoch: 6| Step: 12
Training loss: 2.6900592417380067
Validation loss: 2.7238624170154107

Epoch: 6| Step: 13
Training loss: 3.323030683102009
Validation loss: 2.7231194002222696

Epoch: 180| Step: 0
Training loss: 2.531781364523126
Validation loss: 2.7240723143131165

Epoch: 6| Step: 1
Training loss: 3.4832348519112712
Validation loss: 2.726439135938342

Epoch: 6| Step: 2
Training loss: 2.887750299347545
Validation loss: 2.73211583532733

Epoch: 6| Step: 3
Training loss: 3.284149051810352
Validation loss: 2.736110678059686

Epoch: 6| Step: 4
Training loss: 2.829262689038688
Validation loss: 2.739681140306769

Epoch: 6| Step: 5
Training loss: 2.6642552638861425
Validation loss: 2.7420890862198437

Epoch: 6| Step: 6
Training loss: 3.240940966601987
Validation loss: 2.7462249361836606

Epoch: 6| Step: 7
Training loss: 2.777151795955403
Validation loss: 2.755420884963662

Epoch: 6| Step: 8
Training loss: 3.1685972519274004
Validation loss: 2.7558598298926476

Epoch: 6| Step: 9
Training loss: 2.7614582807631303
Validation loss: 2.7527317246481737

Epoch: 6| Step: 10
Training loss: 3.66907072728655
Validation loss: 2.7331527983362975

Epoch: 6| Step: 11
Training loss: 3.075478592511749
Validation loss: 2.724114279785937

Epoch: 6| Step: 12
Training loss: 3.289151224493622
Validation loss: 2.722322962261878

Epoch: 6| Step: 13
Training loss: 2.670813366304013
Validation loss: 2.7200473739864512

Epoch: 181| Step: 0
Training loss: 2.807641134408745
Validation loss: 2.7194150800258963

Epoch: 6| Step: 1
Training loss: 3.51898873367956
Validation loss: 2.718623551466934

Epoch: 6| Step: 2
Training loss: 3.128617291198327
Validation loss: 2.7190851880217046

Epoch: 6| Step: 3
Training loss: 2.136783020057181
Validation loss: 2.7164299910187912

Epoch: 6| Step: 4
Training loss: 2.908174267402158
Validation loss: 2.718322686379067

Epoch: 6| Step: 5
Training loss: 2.68550861123309
Validation loss: 2.7180130369554707

Epoch: 6| Step: 6
Training loss: 4.077154869942531
Validation loss: 2.7184442148509897

Epoch: 6| Step: 7
Training loss: 3.028542321957253
Validation loss: 2.7153147152825765

Epoch: 6| Step: 8
Training loss: 3.3754679037632602
Validation loss: 2.7164933472916726

Epoch: 6| Step: 9
Training loss: 2.6273430857457623
Validation loss: 2.7178620842897554

Epoch: 6| Step: 10
Training loss: 2.117278375118142
Validation loss: 2.7177664722590977

Epoch: 6| Step: 11
Training loss: 3.0463754097627285
Validation loss: 2.7161528002132322

Epoch: 6| Step: 12
Training loss: 3.2734417243875638
Validation loss: 2.7184017808463756

Epoch: 6| Step: 13
Training loss: 3.554469242312199
Validation loss: 2.7175647743822817

Epoch: 182| Step: 0
Training loss: 3.3979246256766475
Validation loss: 2.7181624193786074

Epoch: 6| Step: 1
Training loss: 2.6647070499319034
Validation loss: 2.7176789411282494

Epoch: 6| Step: 2
Training loss: 2.8933847810709534
Validation loss: 2.7225101782684034

Epoch: 6| Step: 3
Training loss: 3.07330843911946
Validation loss: 2.7324450960979934

Epoch: 6| Step: 4
Training loss: 2.3680134455969273
Validation loss: 2.7498755002668944

Epoch: 6| Step: 5
Training loss: 3.3939083392613325
Validation loss: 2.78357247176414

Epoch: 6| Step: 6
Training loss: 3.2325484421029165
Validation loss: 2.7742607876331253

Epoch: 6| Step: 7
Training loss: 3.028817528110815
Validation loss: 2.7455676969771283

Epoch: 6| Step: 8
Training loss: 2.7357348739037137
Validation loss: 2.7171792205184544

Epoch: 6| Step: 9
Training loss: 3.4711498859544685
Validation loss: 2.7160215027950314

Epoch: 6| Step: 10
Training loss: 2.7896387696307303
Validation loss: 2.7097652102029874

Epoch: 6| Step: 11
Training loss: 2.7554322255728487
Validation loss: 2.7111862421706596

Epoch: 6| Step: 12
Training loss: 3.0680650245708803
Validation loss: 2.711813047897115

Epoch: 6| Step: 13
Training loss: 3.8368735482399083
Validation loss: 2.711787236599601

Epoch: 183| Step: 0
Training loss: 3.341115323544611
Validation loss: 2.7128628744319325

Epoch: 6| Step: 1
Training loss: 2.6324411917092503
Validation loss: 2.7130811102556556

Epoch: 6| Step: 2
Training loss: 3.3585999060408227
Validation loss: 2.7147801304797325

Epoch: 6| Step: 3
Training loss: 2.737639826857112
Validation loss: 2.710250990271624

Epoch: 6| Step: 4
Training loss: 3.085160787834565
Validation loss: 2.7102192341545894

Epoch: 6| Step: 5
Training loss: 2.5893465833603204
Validation loss: 2.708857782920256

Epoch: 6| Step: 6
Training loss: 3.3736546978770385
Validation loss: 2.7061985980173957

Epoch: 6| Step: 7
Training loss: 2.4310763887920284
Validation loss: 2.7100337373976306

Epoch: 6| Step: 8
Training loss: 2.735495986040253
Validation loss: 2.7104225266517723

Epoch: 6| Step: 9
Training loss: 3.46461694226658
Validation loss: 2.7105310006507035

Epoch: 6| Step: 10
Training loss: 3.011669984811103
Validation loss: 2.710580272046249

Epoch: 6| Step: 11
Training loss: 3.7050920243874765
Validation loss: 2.720397679073099

Epoch: 6| Step: 12
Training loss: 2.3482530187658277
Validation loss: 2.723459841473764

Epoch: 6| Step: 13
Training loss: 3.7202171188489728
Validation loss: 2.7193931806063514

Epoch: 184| Step: 0
Training loss: 3.023332934086895
Validation loss: 2.7244718974106723

Epoch: 6| Step: 1
Training loss: 3.280967191588522
Validation loss: 2.7244766897560386

Epoch: 6| Step: 2
Training loss: 3.362169673534525
Validation loss: 2.721936354096291

Epoch: 6| Step: 3
Training loss: 2.8841673605792306
Validation loss: 2.7130292932629763

Epoch: 6| Step: 4
Training loss: 3.579269292838176
Validation loss: 2.71404357340967

Epoch: 6| Step: 5
Training loss: 2.94641918164363
Validation loss: 2.708789665518193

Epoch: 6| Step: 6
Training loss: 2.698653916967126
Validation loss: 2.7050916924407926

Epoch: 6| Step: 7
Training loss: 2.5082897076873776
Validation loss: 2.7044357829011503

Epoch: 6| Step: 8
Training loss: 3.215559479960686
Validation loss: 2.705506483437917

Epoch: 6| Step: 9
Training loss: 3.173069019796848
Validation loss: 2.7071765257595564

Epoch: 6| Step: 10
Training loss: 2.927773626164922
Validation loss: 2.706164559587604

Epoch: 6| Step: 11
Training loss: 2.7316327976860366
Validation loss: 2.703066424355706

Epoch: 6| Step: 12
Training loss: 2.9349168823534413
Validation loss: 2.7040253547612707

Epoch: 6| Step: 13
Training loss: 3.1030079430574675
Validation loss: 2.700289549165306

Epoch: 185| Step: 0
Training loss: 3.4077257231902025
Validation loss: 2.7008144365291833

Epoch: 6| Step: 1
Training loss: 2.529078175873125
Validation loss: 2.699428282322043

Epoch: 6| Step: 2
Training loss: 2.9976412719320553
Validation loss: 2.7009124611123974

Epoch: 6| Step: 3
Training loss: 2.7359745251880594
Validation loss: 2.702971562731228

Epoch: 6| Step: 4
Training loss: 3.882073990342237
Validation loss: 2.702461211914149

Epoch: 6| Step: 5
Training loss: 3.1519605741697667
Validation loss: 2.701163433828355

Epoch: 6| Step: 6
Training loss: 2.64419494924759
Validation loss: 2.6996042935420927

Epoch: 6| Step: 7
Training loss: 2.4999868392597926
Validation loss: 2.7004632923031515

Epoch: 6| Step: 8
Training loss: 3.061039167490692
Validation loss: 2.700459264277531

Epoch: 6| Step: 9
Training loss: 3.122497013967169
Validation loss: 2.6976579725901475

Epoch: 6| Step: 10
Training loss: 2.846314332525664
Validation loss: 2.6993258250981955

Epoch: 6| Step: 11
Training loss: 2.6279687896280337
Validation loss: 2.6985908562625722

Epoch: 6| Step: 12
Training loss: 3.299921878699188
Validation loss: 2.7011677293952747

Epoch: 6| Step: 13
Training loss: 3.5971656821057105
Validation loss: 2.6994036090649196

Epoch: 186| Step: 0
Training loss: 3.4578255123508974
Validation loss: 2.7017902372390075

Epoch: 6| Step: 1
Training loss: 2.568895407317903
Validation loss: 2.7043510576140073

Epoch: 6| Step: 2
Training loss: 3.281466231714538
Validation loss: 2.7009943333995468

Epoch: 6| Step: 3
Training loss: 2.9756011611954674
Validation loss: 2.702708112416927

Epoch: 6| Step: 4
Training loss: 2.7717575788087228
Validation loss: 2.706598943497247

Epoch: 6| Step: 5
Training loss: 3.4389653637143756
Validation loss: 2.7007443241054734

Epoch: 6| Step: 6
Training loss: 2.21120373096869
Validation loss: 2.703215670151184

Epoch: 6| Step: 7
Training loss: 2.8855521563911157
Validation loss: 2.6971920527601623

Epoch: 6| Step: 8
Training loss: 2.965992500197947
Validation loss: 2.7013153044498415

Epoch: 6| Step: 9
Training loss: 3.1545003441535155
Validation loss: 2.700354361666109

Epoch: 6| Step: 10
Training loss: 3.1335157713297637
Validation loss: 2.6996900480830752

Epoch: 6| Step: 11
Training loss: 3.43800045185186
Validation loss: 2.6961783467848286

Epoch: 6| Step: 12
Training loss: 3.129497953132366
Validation loss: 2.699910413098197

Epoch: 6| Step: 13
Training loss: 2.5041647552973796
Validation loss: 2.701474635002537

Epoch: 187| Step: 0
Training loss: 2.662491768837684
Validation loss: 2.7114299239349817

Epoch: 6| Step: 1
Training loss: 2.908068836357666
Validation loss: 2.722982604359355

Epoch: 6| Step: 2
Training loss: 3.2260196404613053
Validation loss: 2.735385837550994

Epoch: 6| Step: 3
Training loss: 3.027233175904021
Validation loss: 2.7529930763361836

Epoch: 6| Step: 4
Training loss: 3.7920419835611434
Validation loss: 2.7253283766905394

Epoch: 6| Step: 5
Training loss: 2.6679969886636967
Validation loss: 2.7261869133833683

Epoch: 6| Step: 6
Training loss: 2.857789981309072
Validation loss: 2.708773164712986

Epoch: 6| Step: 7
Training loss: 3.0766371795905454
Validation loss: 2.7057900716476824

Epoch: 6| Step: 8
Training loss: 2.904319532212396
Validation loss: 2.7121910116189447

Epoch: 6| Step: 9
Training loss: 3.2458863266686184
Validation loss: 2.7137976248517366

Epoch: 6| Step: 10
Training loss: 2.479869571916935
Validation loss: 2.72891934484473

Epoch: 6| Step: 11
Training loss: 3.6341739195468685
Validation loss: 2.7074374538558494

Epoch: 6| Step: 12
Training loss: 2.705792648750496
Validation loss: 2.7048593647897006

Epoch: 6| Step: 13
Training loss: 3.028120175132411
Validation loss: 2.7007343381363818

Epoch: 188| Step: 0
Training loss: 3.4948272627464076
Validation loss: 2.6968477327926133

Epoch: 6| Step: 1
Training loss: 2.8666862028772178
Validation loss: 2.696686213754464

Epoch: 6| Step: 2
Training loss: 2.5727301361381754
Validation loss: 2.697859824592175

Epoch: 6| Step: 3
Training loss: 2.8893581604265735
Validation loss: 2.693955124211729

Epoch: 6| Step: 4
Training loss: 3.0406351996914296
Validation loss: 2.696485973336283

Epoch: 6| Step: 5
Training loss: 2.8098339584274163
Validation loss: 2.6966281546952753

Epoch: 6| Step: 6
Training loss: 3.3880115756182767
Validation loss: 2.693762429015045

Epoch: 6| Step: 7
Training loss: 2.71312218838827
Validation loss: 2.6998617189622762

Epoch: 6| Step: 8
Training loss: 3.188746190025838
Validation loss: 2.697414538819753

Epoch: 6| Step: 9
Training loss: 2.5701993320213985
Validation loss: 2.6975240139368153

Epoch: 6| Step: 10
Training loss: 3.2077629936549106
Validation loss: 2.7062806528310643

Epoch: 6| Step: 11
Training loss: 2.947191686189421
Validation loss: 2.7039332260646063

Epoch: 6| Step: 12
Training loss: 3.5562788869961715
Validation loss: 2.7020780323660403

Epoch: 6| Step: 13
Training loss: 2.9570678547416502
Validation loss: 2.6946060203542332

Epoch: 189| Step: 0
Training loss: 3.348092370129728
Validation loss: 2.6918856138542506

Epoch: 6| Step: 1
Training loss: 2.166540166634382
Validation loss: 2.6958302342284086

Epoch: 6| Step: 2
Training loss: 2.851919658711671
Validation loss: 2.6947467492566806

Epoch: 6| Step: 3
Training loss: 3.581803076412527
Validation loss: 2.6954247635427016

Epoch: 6| Step: 4
Training loss: 3.9105428072068293
Validation loss: 2.696984013982166

Epoch: 6| Step: 5
Training loss: 2.8333126142155662
Validation loss: 2.697567271492483

Epoch: 6| Step: 6
Training loss: 2.8271630268675807
Validation loss: 2.6995053396877107

Epoch: 6| Step: 7
Training loss: 2.675843799166278
Validation loss: 2.6970317372917303

Epoch: 6| Step: 8
Training loss: 3.4236934480874672
Validation loss: 2.69752342470856

Epoch: 6| Step: 9
Training loss: 2.51556993507159
Validation loss: 2.6946155875875393

Epoch: 6| Step: 10
Training loss: 3.3286040771679444
Validation loss: 2.6948109225908343

Epoch: 6| Step: 11
Training loss: 2.5719897702311783
Validation loss: 2.692663240490543

Epoch: 6| Step: 12
Training loss: 3.37502882203405
Validation loss: 2.6942311076208396

Epoch: 6| Step: 13
Training loss: 2.0329709318965983
Validation loss: 2.6971265825575617

Epoch: 190| Step: 0
Training loss: 2.670802207761443
Validation loss: 2.7084336696872504

Epoch: 6| Step: 1
Training loss: 3.5350446989047244
Validation loss: 2.71374023937864

Epoch: 6| Step: 2
Training loss: 3.25627967396283
Validation loss: 2.7414635321161525

Epoch: 6| Step: 3
Training loss: 3.427246058967178
Validation loss: 2.794014169780895

Epoch: 6| Step: 4
Training loss: 2.4505932615132244
Validation loss: 2.831965069646411

Epoch: 6| Step: 5
Training loss: 3.097111888644201
Validation loss: 2.9056523370435183

Epoch: 6| Step: 6
Training loss: 2.848125570840048
Validation loss: 2.866587409273367

Epoch: 6| Step: 7
Training loss: 3.29976090229718
Validation loss: 2.779339580233594

Epoch: 6| Step: 8
Training loss: 2.763880465019164
Validation loss: 2.7379528708500347

Epoch: 6| Step: 9
Training loss: 3.5971674053740057
Validation loss: 2.69113469334098

Epoch: 6| Step: 10
Training loss: 3.2354489814698573
Validation loss: 2.691255944456556

Epoch: 6| Step: 11
Training loss: 2.8197670195091513
Validation loss: 2.6935237294891503

Epoch: 6| Step: 12
Training loss: 3.0127537157527873
Validation loss: 2.7205476297634026

Epoch: 6| Step: 13
Training loss: 2.305840879298598
Validation loss: 2.7397744604827885

Epoch: 191| Step: 0
Training loss: 3.2674914415243035
Validation loss: 2.7555312522564472

Epoch: 6| Step: 1
Training loss: 3.059533063879148
Validation loss: 2.7628732549290795

Epoch: 6| Step: 2
Training loss: 3.470990806081647
Validation loss: 2.7686297968437814

Epoch: 6| Step: 3
Training loss: 3.419870843512034
Validation loss: 2.7613199035958402

Epoch: 6| Step: 4
Training loss: 2.881789111096605
Validation loss: 2.755835374422536

Epoch: 6| Step: 5
Training loss: 2.546837180389254
Validation loss: 2.7475007176796953

Epoch: 6| Step: 6
Training loss: 3.058293158521111
Validation loss: 2.7466385779536004

Epoch: 6| Step: 7
Training loss: 3.0407137662784143
Validation loss: 2.744384373636314

Epoch: 6| Step: 8
Training loss: 3.084014370599061
Validation loss: 2.738045372614295

Epoch: 6| Step: 9
Training loss: 2.9452296075868603
Validation loss: 2.739253846200505

Epoch: 6| Step: 10
Training loss: 2.9220518986807855
Validation loss: 2.7362423194479857

Epoch: 6| Step: 11
Training loss: 2.711707805500458
Validation loss: 2.7377137626287724

Epoch: 6| Step: 12
Training loss: 3.3193464242534407
Validation loss: 2.737081410804713

Epoch: 6| Step: 13
Training loss: 3.2398930899324276
Validation loss: 2.7380365179806447

Epoch: 192| Step: 0
Training loss: 2.866860352855695
Validation loss: 2.7396987228831713

Epoch: 6| Step: 1
Training loss: 2.980757993009601
Validation loss: 2.7430857979196976

Epoch: 6| Step: 2
Training loss: 2.972992766452667
Validation loss: 2.7475127068109244

Epoch: 6| Step: 3
Training loss: 3.834533931855127
Validation loss: 2.7458658998631353

Epoch: 6| Step: 4
Training loss: 2.2086427459841547
Validation loss: 2.7455765917500243

Epoch: 6| Step: 5
Training loss: 2.3896779696530284
Validation loss: 2.7383374227764232

Epoch: 6| Step: 6
Training loss: 2.179134941477963
Validation loss: 2.7418254310242367

Epoch: 6| Step: 7
Training loss: 2.8046635278723966
Validation loss: 2.739953032546814

Epoch: 6| Step: 8
Training loss: 3.303640357517205
Validation loss: 2.7398972783894844

Epoch: 6| Step: 9
Training loss: 3.4331912693396673
Validation loss: 2.741173582610394

Epoch: 6| Step: 10
Training loss: 3.580831778240924
Validation loss: 2.7349895484009084

Epoch: 6| Step: 11
Training loss: 3.153243644304493
Validation loss: 2.7346159704298674

Epoch: 6| Step: 12
Training loss: 3.518431090408289
Validation loss: 2.731732742480545

Epoch: 6| Step: 13
Training loss: 2.955011159033449
Validation loss: 2.7313127237496544

Epoch: 193| Step: 0
Training loss: 2.9413498344938422
Validation loss: 2.733664589754811

Epoch: 6| Step: 1
Training loss: 2.9473364880273216
Validation loss: 2.7164104675175103

Epoch: 6| Step: 2
Training loss: 3.229622560539377
Validation loss: 2.684719306942761

Epoch: 6| Step: 3
Training loss: 3.0480075394144204
Validation loss: 2.688954454128186

Epoch: 6| Step: 4
Training loss: 3.2598655324245733
Validation loss: 2.7019510721155586

Epoch: 6| Step: 5
Training loss: 2.63401753273055
Validation loss: 2.7112196313033037

Epoch: 6| Step: 6
Training loss: 3.4272992067070716
Validation loss: 2.737806361428309

Epoch: 6| Step: 7
Training loss: 2.996048550221308
Validation loss: 2.7320256025798977

Epoch: 6| Step: 8
Training loss: 3.3125739899055286
Validation loss: 2.756075325213325

Epoch: 6| Step: 9
Training loss: 3.0022221918088037
Validation loss: 2.745467877646566

Epoch: 6| Step: 10
Training loss: 2.6621215551353785
Validation loss: 2.7256522835578365

Epoch: 6| Step: 11
Training loss: 2.8009049349705593
Validation loss: 2.729160952912372

Epoch: 6| Step: 12
Training loss: 3.1066431667874363
Validation loss: 2.7305195647428553

Epoch: 6| Step: 13
Training loss: 2.84981318079015
Validation loss: 2.716751552256908

Epoch: 194| Step: 0
Training loss: 2.7832415019283974
Validation loss: 2.709846710484948

Epoch: 6| Step: 1
Training loss: 2.8548648472210445
Validation loss: 2.705090765580909

Epoch: 6| Step: 2
Training loss: 2.88058211721961
Validation loss: 2.696974918074114

Epoch: 6| Step: 3
Training loss: 2.7929215433893013
Validation loss: 2.687411341882495

Epoch: 6| Step: 4
Training loss: 2.756002810372967
Validation loss: 2.682411053719863

Epoch: 6| Step: 5
Training loss: 2.6619135000217233
Validation loss: 2.68326425303578

Epoch: 6| Step: 6
Training loss: 3.436667879130917
Validation loss: 2.6797380474011794

Epoch: 6| Step: 7
Training loss: 3.2409228696558183
Validation loss: 2.6801048099046842

Epoch: 6| Step: 8
Training loss: 3.2026962365472236
Validation loss: 2.680432687707385

Epoch: 6| Step: 9
Training loss: 3.6912201042269372
Validation loss: 2.6784690531881283

Epoch: 6| Step: 10
Training loss: 3.389591182487855
Validation loss: 2.68244507531416

Epoch: 6| Step: 11
Training loss: 2.4797537186067182
Validation loss: 2.679308765962804

Epoch: 6| Step: 12
Training loss: 3.0809432552155047
Validation loss: 2.682723368045254

Epoch: 6| Step: 13
Training loss: 2.7028536798218226
Validation loss: 2.6794113073768533

Epoch: 195| Step: 0
Training loss: 2.7734906258666205
Validation loss: 2.682549865956134

Epoch: 6| Step: 1
Training loss: 3.0377417197417187
Validation loss: 2.7122011331083917

Epoch: 6| Step: 2
Training loss: 3.6158450047349375
Validation loss: 2.742625052925952

Epoch: 6| Step: 3
Training loss: 3.1821643826782786
Validation loss: 2.7265435558492737

Epoch: 6| Step: 4
Training loss: 3.654756159339295
Validation loss: 2.70771743043918

Epoch: 6| Step: 5
Training loss: 2.8377592262465576
Validation loss: 2.67491592560316

Epoch: 6| Step: 6
Training loss: 2.7350051589721898
Validation loss: 2.6771435263801333

Epoch: 6| Step: 7
Training loss: 2.3424073506112273
Validation loss: 2.6840591133446874

Epoch: 6| Step: 8
Training loss: 3.2627714548414697
Validation loss: 2.7143201201296328

Epoch: 6| Step: 9
Training loss: 3.5470551432433335
Validation loss: 2.7492060088417443

Epoch: 6| Step: 10
Training loss: 3.140307965574769
Validation loss: 2.7729467183907515

Epoch: 6| Step: 11
Training loss: 2.8603360588197964
Validation loss: 2.7694923813193624

Epoch: 6| Step: 12
Training loss: 2.6315010947707744
Validation loss: 2.771376630016436

Epoch: 6| Step: 13
Training loss: 2.8839193560770657
Validation loss: 2.7650549590639737

Epoch: 196| Step: 0
Training loss: 2.847658929182553
Validation loss: 2.7373502515335133

Epoch: 6| Step: 1
Training loss: 3.187349054090993
Validation loss: 2.692338653707811

Epoch: 6| Step: 2
Training loss: 2.8966858704358023
Validation loss: 2.682469557635559

Epoch: 6| Step: 3
Training loss: 2.5373371541804164
Validation loss: 2.679508066055013

Epoch: 6| Step: 4
Training loss: 2.815643164843901
Validation loss: 2.677541041916928

Epoch: 6| Step: 5
Training loss: 2.722406405967285
Validation loss: 2.673170970827863

Epoch: 6| Step: 6
Training loss: 3.3491848423573707
Validation loss: 2.6760494765109426

Epoch: 6| Step: 7
Training loss: 3.005574134147167
Validation loss: 2.674390243053817

Epoch: 6| Step: 8
Training loss: 3.7285885211738625
Validation loss: 2.680820722593679

Epoch: 6| Step: 9
Training loss: 2.396177140045078
Validation loss: 2.686000066768181

Epoch: 6| Step: 10
Training loss: 3.127636826996068
Validation loss: 2.6906531252810786

Epoch: 6| Step: 11
Training loss: 2.6935437577104495
Validation loss: 2.6928675232335353

Epoch: 6| Step: 12
Training loss: 3.382903558153062
Validation loss: 2.7082818735564658

Epoch: 6| Step: 13
Training loss: 3.565024301411327
Validation loss: 2.66827294754314

Epoch: 197| Step: 0
Training loss: 2.3644611030165463
Validation loss: 2.673491418811554

Epoch: 6| Step: 1
Training loss: 2.8243939146221857
Validation loss: 2.6682766494509695

Epoch: 6| Step: 2
Training loss: 3.0906050909961325
Validation loss: 2.6746354397969565

Epoch: 6| Step: 3
Training loss: 2.7372902289017893
Validation loss: 2.6752645775917814

Epoch: 6| Step: 4
Training loss: 3.2629642141696347
Validation loss: 2.67927314489172

Epoch: 6| Step: 5
Training loss: 2.994809906392599
Validation loss: 2.679451224462495

Epoch: 6| Step: 6
Training loss: 2.931638835827652
Validation loss: 2.683257126558814

Epoch: 6| Step: 7
Training loss: 2.8262947862493957
Validation loss: 2.679416328619173

Epoch: 6| Step: 8
Training loss: 3.359891488048744
Validation loss: 2.679763898570915

Epoch: 6| Step: 9
Training loss: 3.0908193868482026
Validation loss: 2.6787412526116943

Epoch: 6| Step: 10
Training loss: 3.5507625835335124
Validation loss: 2.6736497284315863

Epoch: 6| Step: 11
Training loss: 2.5611941103704137
Validation loss: 2.6772467300527305

Epoch: 6| Step: 12
Training loss: 3.338803349007654
Validation loss: 2.679148032986834

Epoch: 6| Step: 13
Training loss: 3.2020135207167737
Validation loss: 2.6696466675454795

Epoch: 198| Step: 0
Training loss: 2.47511456156993
Validation loss: 2.6688253858296984

Epoch: 6| Step: 1
Training loss: 2.9230226924823217
Validation loss: 2.669441100461873

Epoch: 6| Step: 2
Training loss: 3.507575420022845
Validation loss: 2.6670207364097838

Epoch: 6| Step: 3
Training loss: 3.2022438884351874
Validation loss: 2.668291435413383

Epoch: 6| Step: 4
Training loss: 3.3157545691798584
Validation loss: 2.6676496769174736

Epoch: 6| Step: 5
Training loss: 3.1346807450541254
Validation loss: 2.666031999074584

Epoch: 6| Step: 6
Training loss: 2.9783942726303554
Validation loss: 2.6652243059630467

Epoch: 6| Step: 7
Training loss: 3.0434165693629343
Validation loss: 2.663768206067707

Epoch: 6| Step: 8
Training loss: 2.3427938927110863
Validation loss: 2.665653523390368

Epoch: 6| Step: 9
Training loss: 2.7956270811711526
Validation loss: 2.6636998970870724

Epoch: 6| Step: 10
Training loss: 2.546740756563207
Validation loss: 2.6636024515484356

Epoch: 6| Step: 11
Training loss: 3.365768381392305
Validation loss: 2.667165761113491

Epoch: 6| Step: 12
Training loss: 3.120223553057878
Validation loss: 2.6650080951494695

Epoch: 6| Step: 13
Training loss: 3.186140032098116
Validation loss: 2.6638960535670937

Epoch: 199| Step: 0
Training loss: 3.4142340086711687
Validation loss: 2.6637176279862205

Epoch: 6| Step: 1
Training loss: 2.954327858067981
Validation loss: 2.670233833124222

Epoch: 6| Step: 2
Training loss: 2.8321814345953893
Validation loss: 2.6659357994654096

Epoch: 6| Step: 3
Training loss: 2.9952128680816776
Validation loss: 2.66666924440608

Epoch: 6| Step: 4
Training loss: 3.1937902877267224
Validation loss: 2.6725429162317362

Epoch: 6| Step: 5
Training loss: 2.9205697964251796
Validation loss: 2.6901975973912298

Epoch: 6| Step: 6
Training loss: 2.589267027839168
Validation loss: 2.7477791601251913

Epoch: 6| Step: 7
Training loss: 2.985083371121139
Validation loss: 2.788793273084958

Epoch: 6| Step: 8
Training loss: 3.7031324684293097
Validation loss: 2.7740654430492477

Epoch: 6| Step: 9
Training loss: 3.2159958695057775
Validation loss: 2.748876901658706

Epoch: 6| Step: 10
Training loss: 3.2990355440545134
Validation loss: 2.696170045918075

Epoch: 6| Step: 11
Training loss: 2.5544164671307668
Validation loss: 2.6615462833566412

Epoch: 6| Step: 12
Training loss: 2.266345100406322
Validation loss: 2.659840077716971

Epoch: 6| Step: 13
Training loss: 3.39216838815472
Validation loss: 2.664261328848743

Epoch: 200| Step: 0
Training loss: 2.602024713186296
Validation loss: 2.6808011166752146

Epoch: 6| Step: 1
Training loss: 2.9730777717321115
Validation loss: 2.6988849797116092

Epoch: 6| Step: 2
Training loss: 3.2028868051679176
Validation loss: 2.722160227907258

Epoch: 6| Step: 3
Training loss: 2.988466025230998
Validation loss: 2.724881240395835

Epoch: 6| Step: 4
Training loss: 2.791116252176986
Validation loss: 2.7359913201374613

Epoch: 6| Step: 5
Training loss: 3.7210973175371307
Validation loss: 2.703561090775253

Epoch: 6| Step: 6
Training loss: 2.852518501455768
Validation loss: 2.6776308559800572

Epoch: 6| Step: 7
Training loss: 2.974556314417187
Validation loss: 2.6686796424565244

Epoch: 6| Step: 8
Training loss: 2.933165253534314
Validation loss: 2.664918342439336

Epoch: 6| Step: 9
Training loss: 2.7655117205680257
Validation loss: 2.6623686319037265

Epoch: 6| Step: 10
Training loss: 3.0538703625537513
Validation loss: 2.6611556104210514

Epoch: 6| Step: 11
Training loss: 3.5189578386248863
Validation loss: 2.662369845179163

Epoch: 6| Step: 12
Training loss: 3.1280136835525814
Validation loss: 2.661746759324278

Epoch: 6| Step: 13
Training loss: 2.9232546563111006
Validation loss: 2.6722362480150523

Epoch: 201| Step: 0
Training loss: 2.822832244699261
Validation loss: 2.6813658936910856

Epoch: 6| Step: 1
Training loss: 3.021492739211516
Validation loss: 2.699244388006057

Epoch: 6| Step: 2
Training loss: 2.8259650143498063
Validation loss: 2.709973080412105

Epoch: 6| Step: 3
Training loss: 3.134824187780466
Validation loss: 2.7128374652994367

Epoch: 6| Step: 4
Training loss: 3.071943243128275
Validation loss: 2.691248097078684

Epoch: 6| Step: 5
Training loss: 2.705529086535948
Validation loss: 2.680599209067662

Epoch: 6| Step: 6
Training loss: 2.9178934151398845
Validation loss: 2.6662645668104274

Epoch: 6| Step: 7
Training loss: 2.608975682570394
Validation loss: 2.6640549545558936

Epoch: 6| Step: 8
Training loss: 3.1131741877470325
Validation loss: 2.6657957076247

Epoch: 6| Step: 9
Training loss: 3.297847658561133
Validation loss: 2.6637576435826933

Epoch: 6| Step: 10
Training loss: 3.56238970669455
Validation loss: 2.661106620419589

Epoch: 6| Step: 11
Training loss: 3.0601296106950975
Validation loss: 2.6588710797913016

Epoch: 6| Step: 12
Training loss: 2.8537318508725678
Validation loss: 2.659468010374303

Epoch: 6| Step: 13
Training loss: 2.980727918163471
Validation loss: 2.6600550711709983

Epoch: 202| Step: 0
Training loss: 2.997100859753905
Validation loss: 2.6619261173274196

Epoch: 6| Step: 1
Training loss: 2.872234673127718
Validation loss: 2.6621428875721755

Epoch: 6| Step: 2
Training loss: 2.605573614889793
Validation loss: 2.66233904321858

Epoch: 6| Step: 3
Training loss: 3.1489171119555226
Validation loss: 2.6602191434249116

Epoch: 6| Step: 4
Training loss: 2.9188219735463203
Validation loss: 2.6620297087222276

Epoch: 6| Step: 5
Training loss: 3.3229197598784745
Validation loss: 2.6594966771662514

Epoch: 6| Step: 6
Training loss: 3.282085493983869
Validation loss: 2.658728843437516

Epoch: 6| Step: 7
Training loss: 2.650777407642551
Validation loss: 2.6554697588243026

Epoch: 6| Step: 8
Training loss: 2.8537976845539057
Validation loss: 2.656885388388903

Epoch: 6| Step: 9
Training loss: 2.736572951719096
Validation loss: 2.657038345469997

Epoch: 6| Step: 10
Training loss: 3.1834547515668317
Validation loss: 2.654953965554139

Epoch: 6| Step: 11
Training loss: 3.409585422137784
Validation loss: 2.654480887297214

Epoch: 6| Step: 12
Training loss: 2.6759654183598056
Validation loss: 2.657466795516735

Epoch: 6| Step: 13
Training loss: 3.487450580862054
Validation loss: 2.6546796689453998

Epoch: 203| Step: 0
Training loss: 2.8021545873797695
Validation loss: 2.6552453937218816

Epoch: 6| Step: 1
Training loss: 2.8654916513880835
Validation loss: 2.651796039520021

Epoch: 6| Step: 2
Training loss: 3.427186788526016
Validation loss: 2.654385865544758

Epoch: 6| Step: 3
Training loss: 2.550920608242139
Validation loss: 2.654257244132462

Epoch: 6| Step: 4
Training loss: 2.9035052392333256
Validation loss: 2.6530301165297194

Epoch: 6| Step: 5
Training loss: 2.5167340979058093
Validation loss: 2.655802264954381

Epoch: 6| Step: 6
Training loss: 3.199088032232948
Validation loss: 2.652706187867366

Epoch: 6| Step: 7
Training loss: 2.837929774603067
Validation loss: 2.6512838412150335

Epoch: 6| Step: 8
Training loss: 2.749269388420309
Validation loss: 2.6563822858710027

Epoch: 6| Step: 9
Training loss: 3.5091259372883727
Validation loss: 2.6494244209108437

Epoch: 6| Step: 10
Training loss: 2.9792929313596557
Validation loss: 2.6539450559899955

Epoch: 6| Step: 11
Training loss: 2.822258697818056
Validation loss: 2.6497371987509

Epoch: 6| Step: 12
Training loss: 3.2049168482808614
Validation loss: 2.6561453463877354

Epoch: 6| Step: 13
Training loss: 3.6305919792944494
Validation loss: 2.653893712069047

Epoch: 204| Step: 0
Training loss: 3.1628703567705383
Validation loss: 2.658437668881586

Epoch: 6| Step: 1
Training loss: 3.1506200755329994
Validation loss: 2.6551061417328006

Epoch: 6| Step: 2
Training loss: 2.871582986059291
Validation loss: 2.653027939439951

Epoch: 6| Step: 3
Training loss: 3.3838066772178608
Validation loss: 2.650746700188558

Epoch: 6| Step: 4
Training loss: 2.546903457950673
Validation loss: 2.652258414235402

Epoch: 6| Step: 5
Training loss: 3.353120170653777
Validation loss: 2.650090500231814

Epoch: 6| Step: 6
Training loss: 3.025676519234641
Validation loss: 2.6519768689950776

Epoch: 6| Step: 7
Training loss: 3.061781818492744
Validation loss: 2.648420028829753

Epoch: 6| Step: 8
Training loss: 3.0239503410742716
Validation loss: 2.6484334494749477

Epoch: 6| Step: 9
Training loss: 2.4981921334941495
Validation loss: 2.647153150372576

Epoch: 6| Step: 10
Training loss: 2.8428614978524154
Validation loss: 2.6500087612902705

Epoch: 6| Step: 11
Training loss: 2.780234933847144
Validation loss: 2.6500747406214265

Epoch: 6| Step: 12
Training loss: 3.1226988903319155
Validation loss: 2.6561269037918156

Epoch: 6| Step: 13
Training loss: 2.980611295278618
Validation loss: 2.6600676192278825

Epoch: 205| Step: 0
Training loss: 2.507466610261183
Validation loss: 2.662384030831579

Epoch: 6| Step: 1
Training loss: 3.21731579873526
Validation loss: 2.6746605188569843

Epoch: 6| Step: 2
Training loss: 2.705650869392553
Validation loss: 2.671118370971819

Epoch: 6| Step: 3
Training loss: 3.318914859793426
Validation loss: 2.667093627984051

Epoch: 6| Step: 4
Training loss: 3.04293960341866
Validation loss: 2.6697085336479276

Epoch: 6| Step: 5
Training loss: 2.91355879370236
Validation loss: 2.6705175123754654

Epoch: 6| Step: 6
Training loss: 3.274087700192939
Validation loss: 2.6668497978927284

Epoch: 6| Step: 7
Training loss: 3.6782154937475897
Validation loss: 2.6686555043439735

Epoch: 6| Step: 8
Training loss: 2.8383093129289794
Validation loss: 2.668647682730202

Epoch: 6| Step: 9
Training loss: 2.5488635765913354
Validation loss: 2.6832621921970206

Epoch: 6| Step: 10
Training loss: 3.216196324908354
Validation loss: 2.6771992946819845

Epoch: 6| Step: 11
Training loss: 2.3475640353405516
Validation loss: 2.671061330206831

Epoch: 6| Step: 12
Training loss: 3.046154543477166
Validation loss: 2.665238669279692

Epoch: 6| Step: 13
Training loss: 3.0564351655688173
Validation loss: 2.6540554572217228

Epoch: 206| Step: 0
Training loss: 2.9597300782724205
Validation loss: 2.6546759886364915

Epoch: 6| Step: 1
Training loss: 3.250345945286145
Validation loss: 2.6506317706298876

Epoch: 6| Step: 2
Training loss: 3.2814493754531866
Validation loss: 2.6471123046279255

Epoch: 6| Step: 3
Training loss: 2.9058005693005438
Validation loss: 2.6475660612390777

Epoch: 6| Step: 4
Training loss: 2.945250978510323
Validation loss: 2.6482951379201616

Epoch: 6| Step: 5
Training loss: 2.558320521551436
Validation loss: 2.6465110682711765

Epoch: 6| Step: 6
Training loss: 2.994417081985853
Validation loss: 2.648140334056381

Epoch: 6| Step: 7
Training loss: 2.639408260120539
Validation loss: 2.6465836732653947

Epoch: 6| Step: 8
Training loss: 3.042464913610232
Validation loss: 2.6448287652311744

Epoch: 6| Step: 9
Training loss: 3.0335708071076635
Validation loss: 2.646425126910271

Epoch: 6| Step: 10
Training loss: 3.355828262627137
Validation loss: 2.6484216753780037

Epoch: 6| Step: 11
Training loss: 3.202144863618774
Validation loss: 2.651513496694593

Epoch: 6| Step: 12
Training loss: 2.4089787851351963
Validation loss: 2.650078446667998

Epoch: 6| Step: 13
Training loss: 3.231551259973668
Validation loss: 2.6497456624930678

Epoch: 207| Step: 0
Training loss: 3.172025629986309
Validation loss: 2.6467735161335235

Epoch: 6| Step: 1
Training loss: 3.201066411662682
Validation loss: 2.6449977025753397

Epoch: 6| Step: 2
Training loss: 3.106900251090635
Validation loss: 2.6461535817040973

Epoch: 6| Step: 3
Training loss: 2.5068715074049313
Validation loss: 2.64421054320915

Epoch: 6| Step: 4
Training loss: 2.4262633896487222
Validation loss: 2.64261124110263

Epoch: 6| Step: 5
Training loss: 3.1904845383351206
Validation loss: 2.6431202461370766

Epoch: 6| Step: 6
Training loss: 2.4044265774062836
Validation loss: 2.6431231219768576

Epoch: 6| Step: 7
Training loss: 3.0199209655120867
Validation loss: 2.644629029884253

Epoch: 6| Step: 8
Training loss: 3.1921230524384834
Validation loss: 2.6422718502618

Epoch: 6| Step: 9
Training loss: 3.429893539600488
Validation loss: 2.6417489365827813

Epoch: 6| Step: 10
Training loss: 2.956508736447671
Validation loss: 2.6442121991653464

Epoch: 6| Step: 11
Training loss: 3.219781802822683
Validation loss: 2.6445163127712217

Epoch: 6| Step: 12
Training loss: 2.852051408216097
Validation loss: 2.6445911938882416

Epoch: 6| Step: 13
Training loss: 2.7870816588276766
Validation loss: 2.642646753916889

Epoch: 208| Step: 0
Training loss: 2.4887290563617013
Validation loss: 2.6412193103807984

Epoch: 6| Step: 1
Training loss: 3.513952238762461
Validation loss: 2.6389825708944596

Epoch: 6| Step: 2
Training loss: 2.4700705943656556
Validation loss: 2.644766554628647

Epoch: 6| Step: 3
Training loss: 2.5299536128559996
Validation loss: 2.640318893881169

Epoch: 6| Step: 4
Training loss: 2.803269221615616
Validation loss: 2.6410582880425744

Epoch: 6| Step: 5
Training loss: 3.4612473463252877
Validation loss: 2.6429620070809134

Epoch: 6| Step: 6
Training loss: 3.1809162137156646
Validation loss: 2.6442510634226597

Epoch: 6| Step: 7
Training loss: 2.5635007439335666
Validation loss: 2.653175088521311

Epoch: 6| Step: 8
Training loss: 2.862964482499173
Validation loss: 2.6544038769321103

Epoch: 6| Step: 9
Training loss: 3.1025367571108053
Validation loss: 2.6556090458070405

Epoch: 6| Step: 10
Training loss: 3.7684171463223506
Validation loss: 2.6704064424194964

Epoch: 6| Step: 11
Training loss: 2.7185523301097976
Validation loss: 2.6543372286831883

Epoch: 6| Step: 12
Training loss: 3.1321486533149097
Validation loss: 2.6489449645050454

Epoch: 6| Step: 13
Training loss: 2.754539557610033
Validation loss: 2.63896256476939

Epoch: 209| Step: 0
Training loss: 3.219269349503598
Validation loss: 2.6402893066614856

Epoch: 6| Step: 1
Training loss: 2.8940659945752847
Validation loss: 2.6396491435661815

Epoch: 6| Step: 2
Training loss: 3.234450187362045
Validation loss: 2.640460084980219

Epoch: 6| Step: 3
Training loss: 2.6701315383798936
Validation loss: 2.64102129296501

Epoch: 6| Step: 4
Training loss: 2.8362066808479978
Validation loss: 2.640858976179146

Epoch: 6| Step: 5
Training loss: 3.055813086860218
Validation loss: 2.6436461730706413

Epoch: 6| Step: 6
Training loss: 2.965862275129137
Validation loss: 2.6424287418300096

Epoch: 6| Step: 7
Training loss: 2.481924227723696
Validation loss: 2.642332234464542

Epoch: 6| Step: 8
Training loss: 3.2824854386900792
Validation loss: 2.6402430822783725

Epoch: 6| Step: 9
Training loss: 2.6045767702800995
Validation loss: 2.6392683872065117

Epoch: 6| Step: 10
Training loss: 3.135050670938284
Validation loss: 2.6413219454719754

Epoch: 6| Step: 11
Training loss: 3.1606559594093757
Validation loss: 2.6364197332145842

Epoch: 6| Step: 12
Training loss: 3.1836704361929584
Validation loss: 2.63944164813057

Epoch: 6| Step: 13
Training loss: 3.076438170517425
Validation loss: 2.637856982322487

Epoch: 210| Step: 0
Training loss: 3.1075024357584384
Validation loss: 2.6369215733747846

Epoch: 6| Step: 1
Training loss: 2.726076973693866
Validation loss: 2.636914391652221

Epoch: 6| Step: 2
Training loss: 2.5798936730291313
Validation loss: 2.638983967839744

Epoch: 6| Step: 3
Training loss: 3.2268326394557003
Validation loss: 2.6448352653695584

Epoch: 6| Step: 4
Training loss: 2.799678484304674
Validation loss: 2.648063233204324

Epoch: 6| Step: 5
Training loss: 3.041069564389967
Validation loss: 2.670756638189324

Epoch: 6| Step: 6
Training loss: 2.686182098169513
Validation loss: 2.6834923294748223

Epoch: 6| Step: 7
Training loss: 2.9329495186114514
Validation loss: 2.6894949624556896

Epoch: 6| Step: 8
Training loss: 3.178838593106827
Validation loss: 2.6617960043295357

Epoch: 6| Step: 9
Training loss: 2.8496358136838964
Validation loss: 2.6458235406117065

Epoch: 6| Step: 10
Training loss: 2.5596161408526052
Validation loss: 2.6368563460495147

Epoch: 6| Step: 11
Training loss: 3.5666116110096797
Validation loss: 2.6397029798279146

Epoch: 6| Step: 12
Training loss: 3.181327827865599
Validation loss: 2.6380927957740963

Epoch: 6| Step: 13
Training loss: 3.395144074743963
Validation loss: 2.641222960909071

Epoch: 211| Step: 0
Training loss: 3.250143488137323
Validation loss: 2.642669421256024

Epoch: 6| Step: 1
Training loss: 3.653515045515096
Validation loss: 2.64142371666571

Epoch: 6| Step: 2
Training loss: 3.0628079629317035
Validation loss: 2.6464089667010806

Epoch: 6| Step: 3
Training loss: 2.6366809531434465
Validation loss: 2.646514406364172

Epoch: 6| Step: 4
Training loss: 3.1417729191979586
Validation loss: 2.6407721237532966

Epoch: 6| Step: 5
Training loss: 2.464338489622878
Validation loss: 2.646781138932613

Epoch: 6| Step: 6
Training loss: 2.6302805874912103
Validation loss: 2.6504311377843126

Epoch: 6| Step: 7
Training loss: 2.9064716541713365
Validation loss: 2.644780598184534

Epoch: 6| Step: 8
Training loss: 3.2330297353777038
Validation loss: 2.647740831848891

Epoch: 6| Step: 9
Training loss: 2.6563957623149683
Validation loss: 2.6470130881774576

Epoch: 6| Step: 10
Training loss: 3.2634766735460663
Validation loss: 2.6459021029272947

Epoch: 6| Step: 11
Training loss: 3.3093840140561257
Validation loss: 2.6422420122700703

Epoch: 6| Step: 12
Training loss: 2.486055489550715
Validation loss: 2.644504818846566

Epoch: 6| Step: 13
Training loss: 2.971713223551732
Validation loss: 2.641982217431927

Epoch: 212| Step: 0
Training loss: 2.368366212377253
Validation loss: 2.6387850375232573

Epoch: 6| Step: 1
Training loss: 2.765787410816503
Validation loss: 2.639346087849347

Epoch: 6| Step: 2
Training loss: 2.3958304584872923
Validation loss: 2.6356333336673377

Epoch: 6| Step: 3
Training loss: 3.2564056066429417
Validation loss: 2.633397681900098

Epoch: 6| Step: 4
Training loss: 2.741631519436319
Validation loss: 2.6342767321028133

Epoch: 6| Step: 5
Training loss: 3.349099132055946
Validation loss: 2.635417711740138

Epoch: 6| Step: 6
Training loss: 3.669194838217674
Validation loss: 2.630870799425736

Epoch: 6| Step: 7
Training loss: 3.3058736489596425
Validation loss: 2.6328173238391734

Epoch: 6| Step: 8
Training loss: 2.8012744251226427
Validation loss: 2.634074190732646

Epoch: 6| Step: 9
Training loss: 3.064365675038873
Validation loss: 2.6312957617833668

Epoch: 6| Step: 10
Training loss: 2.7073640605019142
Validation loss: 2.634075163993069

Epoch: 6| Step: 11
Training loss: 2.9480282028898874
Validation loss: 2.634378977395123

Epoch: 6| Step: 12
Training loss: 2.884171824464886
Validation loss: 2.6334393945531973

Epoch: 6| Step: 13
Training loss: 3.2389591183981152
Validation loss: 2.6384742027432124

Epoch: 213| Step: 0
Training loss: 2.943905279190667
Validation loss: 2.6335343047318576

Epoch: 6| Step: 1
Training loss: 2.9515822483127057
Validation loss: 2.6462864057100624

Epoch: 6| Step: 2
Training loss: 2.3273973800047822
Validation loss: 2.642949727978109

Epoch: 6| Step: 3
Training loss: 3.051213545216189
Validation loss: 2.637903896740041

Epoch: 6| Step: 4
Training loss: 2.832046066771585
Validation loss: 2.6427446229276597

Epoch: 6| Step: 5
Training loss: 2.579522788544399
Validation loss: 2.6391547160026003

Epoch: 6| Step: 6
Training loss: 3.030296569008152
Validation loss: 2.637555253492529

Epoch: 6| Step: 7
Training loss: 2.3896288822248497
Validation loss: 2.6316057990733017

Epoch: 6| Step: 8
Training loss: 3.23034003484504
Validation loss: 2.630059834303449

Epoch: 6| Step: 9
Training loss: 3.0959775977494735
Validation loss: 2.633330396853339

Epoch: 6| Step: 10
Training loss: 3.253381290655569
Validation loss: 2.630018978476979

Epoch: 6| Step: 11
Training loss: 3.60908910106197
Validation loss: 2.630915863253835

Epoch: 6| Step: 12
Training loss: 3.3027358187644684
Validation loss: 2.62897874927555

Epoch: 6| Step: 13
Training loss: 2.648284817685956
Validation loss: 2.6290607910097648

Epoch: 214| Step: 0
Training loss: 2.6279219758747407
Validation loss: 2.6306532649273424

Epoch: 6| Step: 1
Training loss: 2.8064297760809427
Validation loss: 2.6306557748184765

Epoch: 6| Step: 2
Training loss: 2.5115568070242147
Validation loss: 2.632861694176248

Epoch: 6| Step: 3
Training loss: 3.7485542053398526
Validation loss: 2.631660506140153

Epoch: 6| Step: 4
Training loss: 3.1853609574616955
Validation loss: 2.629151256864483

Epoch: 6| Step: 5
Training loss: 3.1069234260034198
Validation loss: 2.6314603061356503

Epoch: 6| Step: 6
Training loss: 2.8780912283408155
Validation loss: 2.632791208399173

Epoch: 6| Step: 7
Training loss: 2.9902179500794004
Validation loss: 2.633294246311325

Epoch: 6| Step: 8
Training loss: 2.439558480448626
Validation loss: 2.6437582101924475

Epoch: 6| Step: 9
Training loss: 3.4784845075548803
Validation loss: 2.6479010014827282

Epoch: 6| Step: 10
Training loss: 2.830577650931283
Validation loss: 2.654100818512329

Epoch: 6| Step: 11
Training loss: 2.891108456984343
Validation loss: 2.666216809131498

Epoch: 6| Step: 12
Training loss: 2.969329777371019
Validation loss: 2.6559183240591486

Epoch: 6| Step: 13
Training loss: 2.8855417456296633
Validation loss: 2.6454078604165523

Epoch: 215| Step: 0
Training loss: 3.2166255124742142
Validation loss: 2.640078115726887

Epoch: 6| Step: 1
Training loss: 3.0025509479148256
Validation loss: 2.6416053367222183

Epoch: 6| Step: 2
Training loss: 3.077100244336588
Validation loss: 2.6274786935186345

Epoch: 6| Step: 3
Training loss: 3.0541379780655786
Validation loss: 2.6306090400675597

Epoch: 6| Step: 4
Training loss: 2.946211538537172
Validation loss: 2.625155062961601

Epoch: 6| Step: 5
Training loss: 3.095023461470168
Validation loss: 2.6272731866751533

Epoch: 6| Step: 6
Training loss: 2.8142381171668376
Validation loss: 2.6295771308164766

Epoch: 6| Step: 7
Training loss: 3.74735713653343
Validation loss: 2.631256024161311

Epoch: 6| Step: 8
Training loss: 2.759146651327231
Validation loss: 2.6347661027455063

Epoch: 6| Step: 9
Training loss: 2.8380687261301976
Validation loss: 2.6244216903046236

Epoch: 6| Step: 10
Training loss: 2.613121951598
Validation loss: 2.6304878836003938

Epoch: 6| Step: 11
Training loss: 2.394596764817964
Validation loss: 2.6311869217880215

Epoch: 6| Step: 12
Training loss: 2.4776427022136915
Validation loss: 2.630020867563639

Epoch: 6| Step: 13
Training loss: 3.4899232765224486
Validation loss: 2.6313019348667006

Epoch: 216| Step: 0
Training loss: 2.5081014021127674
Validation loss: 2.6290946916924764

Epoch: 6| Step: 1
Training loss: 2.8216522500634422
Validation loss: 2.6311985786294145

Epoch: 6| Step: 2
Training loss: 2.9828098846631903
Validation loss: 2.6367469519318893

Epoch: 6| Step: 3
Training loss: 3.0187052279167235
Validation loss: 2.627424790215806

Epoch: 6| Step: 4
Training loss: 2.4220914682430736
Validation loss: 2.6236439462725762

Epoch: 6| Step: 5
Training loss: 3.117193312866604
Validation loss: 2.622430204690933

Epoch: 6| Step: 6
Training loss: 2.953765476749666
Validation loss: 2.6247864737441566

Epoch: 6| Step: 7
Training loss: 3.350711741207897
Validation loss: 2.6229138481281833

Epoch: 6| Step: 8
Training loss: 3.1071488735848543
Validation loss: 2.621221615254755

Epoch: 6| Step: 9
Training loss: 2.5675178338520723
Validation loss: 2.621499774532206

Epoch: 6| Step: 10
Training loss: 3.5503528365899393
Validation loss: 2.6230881599867577

Epoch: 6| Step: 11
Training loss: 2.727366768776169
Validation loss: 2.6248113903331776

Epoch: 6| Step: 12
Training loss: 2.7654943920265547
Validation loss: 2.62253080181755

Epoch: 6| Step: 13
Training loss: 3.771152349364085
Validation loss: 2.6222660478893873

Epoch: 217| Step: 0
Training loss: 2.7777925067087263
Validation loss: 2.622032254620521

Epoch: 6| Step: 1
Training loss: 2.3488614103926895
Validation loss: 2.6246071993798767

Epoch: 6| Step: 2
Training loss: 2.714977233678863
Validation loss: 2.6236113602577027

Epoch: 6| Step: 3
Training loss: 2.8799935801752383
Validation loss: 2.622268516437368

Epoch: 6| Step: 4
Training loss: 3.3103426259817277
Validation loss: 2.6269993451165576

Epoch: 6| Step: 5
Training loss: 3.202130419141514
Validation loss: 2.627735975934438

Epoch: 6| Step: 6
Training loss: 3.5619796908365617
Validation loss: 2.626060942381462

Epoch: 6| Step: 7
Training loss: 2.9677078827286003
Validation loss: 2.627371279031783

Epoch: 6| Step: 8
Training loss: 2.850214558606129
Validation loss: 2.6284797221393794

Epoch: 6| Step: 9
Training loss: 3.024688383083173
Validation loss: 2.6278268883585

Epoch: 6| Step: 10
Training loss: 3.15185981827014
Validation loss: 2.629431490528359

Epoch: 6| Step: 11
Training loss: 3.0181744328896287
Validation loss: 2.626436374749162

Epoch: 6| Step: 12
Training loss: 2.8230518341548736
Validation loss: 2.624462047170774

Epoch: 6| Step: 13
Training loss: 2.905617922066355
Validation loss: 2.624385672005232

Epoch: 218| Step: 0
Training loss: 3.298866429849027
Validation loss: 2.6202981192212973

Epoch: 6| Step: 1
Training loss: 3.2381605026869975
Validation loss: 2.6206021294480757

Epoch: 6| Step: 2
Training loss: 2.7434051505507457
Validation loss: 2.6188069959906928

Epoch: 6| Step: 3
Training loss: 2.564379305332706
Validation loss: 2.6202047940463267

Epoch: 6| Step: 4
Training loss: 2.974768871657547
Validation loss: 2.621303271894846

Epoch: 6| Step: 5
Training loss: 3.015466557426887
Validation loss: 2.61879783314732

Epoch: 6| Step: 6
Training loss: 3.3406630197186784
Validation loss: 2.620061100963017

Epoch: 6| Step: 7
Training loss: 2.3682466158291517
Validation loss: 2.617670288517213

Epoch: 6| Step: 8
Training loss: 3.7785653917025916
Validation loss: 2.6269514249835857

Epoch: 6| Step: 9
Training loss: 2.861132805833589
Validation loss: 2.6223667696035458

Epoch: 6| Step: 10
Training loss: 3.003208193385837
Validation loss: 2.6218046457267303

Epoch: 6| Step: 11
Training loss: 2.076036594178593
Validation loss: 2.623130824301243

Epoch: 6| Step: 12
Training loss: 2.779682446325639
Validation loss: 2.627216175134181

Epoch: 6| Step: 13
Training loss: 3.151528178507106
Validation loss: 2.6301453220483615

Epoch: 219| Step: 0
Training loss: 2.755927200618228
Validation loss: 2.6441523513966705

Epoch: 6| Step: 1
Training loss: 3.404529662060331
Validation loss: 2.642424112595619

Epoch: 6| Step: 2
Training loss: 2.211611911102581
Validation loss: 2.6259936714325094

Epoch: 6| Step: 3
Training loss: 3.0054856056194876
Validation loss: 2.6186130148841213

Epoch: 6| Step: 4
Training loss: 3.0067885204019418
Validation loss: 2.6187264264803662

Epoch: 6| Step: 5
Training loss: 3.633245626901709
Validation loss: 2.618995972486243

Epoch: 6| Step: 6
Training loss: 3.239312572551156
Validation loss: 2.621537887081814

Epoch: 6| Step: 7
Training loss: 3.067631684378191
Validation loss: 2.622184029183642

Epoch: 6| Step: 8
Training loss: 2.7827036626952286
Validation loss: 2.6284352017535095

Epoch: 6| Step: 9
Training loss: 2.524657624704538
Validation loss: 2.6280721538767744

Epoch: 6| Step: 10
Training loss: 2.753102546453114
Validation loss: 2.6311066534260177

Epoch: 6| Step: 11
Training loss: 2.6090925600616384
Validation loss: 2.6322167015347055

Epoch: 6| Step: 12
Training loss: 3.359781781785213
Validation loss: 2.6289442932070672

Epoch: 6| Step: 13
Training loss: 3.0759066415913283
Validation loss: 2.627595498264341

Epoch: 220| Step: 0
Training loss: 2.8121447868676905
Validation loss: 2.628223192403421

Epoch: 6| Step: 1
Training loss: 3.0665138565912295
Validation loss: 2.624901634439841

Epoch: 6| Step: 2
Training loss: 2.9337382477832525
Validation loss: 2.625456391880408

Epoch: 6| Step: 3
Training loss: 3.5258339727285897
Validation loss: 2.621653500462677

Epoch: 6| Step: 4
Training loss: 2.974126504840854
Validation loss: 2.621286367070537

Epoch: 6| Step: 5
Training loss: 3.0808678813713875
Validation loss: 2.624086110561704

Epoch: 6| Step: 6
Training loss: 2.7162340295552974
Validation loss: 2.620772466082026

Epoch: 6| Step: 7
Training loss: 3.0131966889325112
Validation loss: 2.619066896089318

Epoch: 6| Step: 8
Training loss: 3.1325820495625027
Validation loss: 2.6278934958319704

Epoch: 6| Step: 9
Training loss: 2.9899731602309356
Validation loss: 2.624278211999905

Epoch: 6| Step: 10
Training loss: 3.393772896536626
Validation loss: 2.625225772319005

Epoch: 6| Step: 11
Training loss: 2.8307023080758245
Validation loss: 2.63271410109971

Epoch: 6| Step: 12
Training loss: 2.207713873969271
Validation loss: 2.6314251850048316

Epoch: 6| Step: 13
Training loss: 2.654499329739858
Validation loss: 2.634914379672713

Epoch: 221| Step: 0
Training loss: 3.1978518368655595
Validation loss: 2.63683331081554

Epoch: 6| Step: 1
Training loss: 3.4528725648327376
Validation loss: 2.635040999296309

Epoch: 6| Step: 2
Training loss: 3.3652542122529074
Validation loss: 2.6288611380705267

Epoch: 6| Step: 3
Training loss: 2.961717809758984
Validation loss: 2.6227920317169238

Epoch: 6| Step: 4
Training loss: 3.2034033677632108
Validation loss: 2.6174328026184734

Epoch: 6| Step: 5
Training loss: 2.481390257745962
Validation loss: 2.617500853815698

Epoch: 6| Step: 6
Training loss: 3.0113824441364994
Validation loss: 2.617842052769401

Epoch: 6| Step: 7
Training loss: 3.0251686994943587
Validation loss: 2.6146846415459555

Epoch: 6| Step: 8
Training loss: 2.872792599004413
Validation loss: 2.612766852833886

Epoch: 6| Step: 9
Training loss: 1.8914129963769863
Validation loss: 2.6172256606528994

Epoch: 6| Step: 10
Training loss: 2.6665825433177854
Validation loss: 2.612203371714748

Epoch: 6| Step: 11
Training loss: 2.960570622162808
Validation loss: 2.6135064867720597

Epoch: 6| Step: 12
Training loss: 2.6589149121933975
Validation loss: 2.6150997645265144

Epoch: 6| Step: 13
Training loss: 3.7111816325945868
Validation loss: 2.6090099631288024

Epoch: 222| Step: 0
Training loss: 2.8295680626992796
Validation loss: 2.614500936665828

Epoch: 6| Step: 1
Training loss: 3.029720746507646
Validation loss: 2.6123368360419432

Epoch: 6| Step: 2
Training loss: 3.344164385921164
Validation loss: 2.615100848762762

Epoch: 6| Step: 3
Training loss: 3.368083790314472
Validation loss: 2.616211894867927

Epoch: 6| Step: 4
Training loss: 2.92195300645788
Validation loss: 2.6182324021437693

Epoch: 6| Step: 5
Training loss: 2.836447929917075
Validation loss: 2.6237588498216526

Epoch: 6| Step: 6
Training loss: 2.7103491592698954
Validation loss: 2.6421741451808067

Epoch: 6| Step: 7
Training loss: 2.9217036395898837
Validation loss: 2.6541710300776407

Epoch: 6| Step: 8
Training loss: 3.280501507356841
Validation loss: 2.659631445072131

Epoch: 6| Step: 9
Training loss: 2.4959779811034633
Validation loss: 2.637357217593864

Epoch: 6| Step: 10
Training loss: 2.686094404412113
Validation loss: 2.6187211023756305

Epoch: 6| Step: 11
Training loss: 2.8585442341959624
Validation loss: 2.6161602621534827

Epoch: 6| Step: 12
Training loss: 3.164419799222355
Validation loss: 2.6122573476861968

Epoch: 6| Step: 13
Training loss: 2.6473238693884045
Validation loss: 2.6101392079209456

Epoch: 223| Step: 0
Training loss: 3.041801414814578
Validation loss: 2.613579817356434

Epoch: 6| Step: 1
Training loss: 3.25147815248487
Validation loss: 2.6113917084654488

Epoch: 6| Step: 2
Training loss: 2.6663817213725842
Validation loss: 2.611353856232075

Epoch: 6| Step: 3
Training loss: 2.8491722644960302
Validation loss: 2.611853690829443

Epoch: 6| Step: 4
Training loss: 3.096145473128077
Validation loss: 2.6104711586042875

Epoch: 6| Step: 5
Training loss: 2.960262493402602
Validation loss: 2.6122915223719234

Epoch: 6| Step: 6
Training loss: 3.037488672054816
Validation loss: 2.6118061759762377

Epoch: 6| Step: 7
Training loss: 2.777721610031227
Validation loss: 2.6121935674176218

Epoch: 6| Step: 8
Training loss: 2.9860597019550927
Validation loss: 2.6117954013860096

Epoch: 6| Step: 9
Training loss: 3.4466371649605367
Validation loss: 2.6107191544213304

Epoch: 6| Step: 10
Training loss: 2.88164482142249
Validation loss: 2.6107472267493463

Epoch: 6| Step: 11
Training loss: 3.058074244474257
Validation loss: 2.61117963287166

Epoch: 6| Step: 12
Training loss: 2.4048430057286794
Validation loss: 2.610598473752314

Epoch: 6| Step: 13
Training loss: 2.9359579705808274
Validation loss: 2.606668369451694

Epoch: 224| Step: 0
Training loss: 3.3338031596639377
Validation loss: 2.610910635917415

Epoch: 6| Step: 1
Training loss: 2.6718791939328836
Validation loss: 2.6169148385900365

Epoch: 6| Step: 2
Training loss: 3.54566390413095
Validation loss: 2.615323680161703

Epoch: 6| Step: 3
Training loss: 2.7835942364996593
Validation loss: 2.6158485520049024

Epoch: 6| Step: 4
Training loss: 2.547850626736605
Validation loss: 2.621713103017994

Epoch: 6| Step: 5
Training loss: 2.8811069808847316
Validation loss: 2.6197789191746863

Epoch: 6| Step: 6
Training loss: 2.840437080705757
Validation loss: 2.6181844341553453

Epoch: 6| Step: 7
Training loss: 2.7284856533842867
Validation loss: 2.62754198421495

Epoch: 6| Step: 8
Training loss: 3.284445233233811
Validation loss: 2.633902113610605

Epoch: 6| Step: 9
Training loss: 3.0969160429451073
Validation loss: 2.6182784217602353

Epoch: 6| Step: 10
Training loss: 3.489130717668518
Validation loss: 2.6248421580044368

Epoch: 6| Step: 11
Training loss: 2.5743928656498767
Validation loss: 2.620609615113261

Epoch: 6| Step: 12
Training loss: 2.5398018567453446
Validation loss: 2.612424192228079

Epoch: 6| Step: 13
Training loss: 2.7299803377498404
Validation loss: 2.61370055163503

Epoch: 225| Step: 0
Training loss: 2.703794539777399
Validation loss: 2.611146377822623

Epoch: 6| Step: 1
Training loss: 3.1258470531688984
Validation loss: 2.6149405126907737

Epoch: 6| Step: 2
Training loss: 2.8449402718065073
Validation loss: 2.6112219439253783

Epoch: 6| Step: 3
Training loss: 3.269324438556978
Validation loss: 2.6098948081240843

Epoch: 6| Step: 4
Training loss: 3.414727257578904
Validation loss: 2.613489487374152

Epoch: 6| Step: 5
Training loss: 3.095794310565558
Validation loss: 2.6209692823911923

Epoch: 6| Step: 6
Training loss: 3.272691008819651
Validation loss: 2.6115552363350343

Epoch: 6| Step: 7
Training loss: 3.2287807274987084
Validation loss: 2.6134388553905605

Epoch: 6| Step: 8
Training loss: 2.8176092575809304
Validation loss: 2.6140567582820826

Epoch: 6| Step: 9
Training loss: 2.6633392873736477
Validation loss: 2.617548404372231

Epoch: 6| Step: 10
Training loss: 2.501813993374865
Validation loss: 2.619287375806808

Epoch: 6| Step: 11
Training loss: 2.508253587572499
Validation loss: 2.611758051681178

Epoch: 6| Step: 12
Training loss: 2.454067170782197
Validation loss: 2.6259440215396808

Epoch: 6| Step: 13
Training loss: 3.4286288841292594
Validation loss: 2.6268920535135445

Epoch: 226| Step: 0
Training loss: 3.0666382525689495
Validation loss: 2.621546847699592

Epoch: 6| Step: 1
Training loss: 3.5739464494549686
Validation loss: 2.614074673403736

Epoch: 6| Step: 2
Training loss: 3.0828502035953056
Validation loss: 2.6101854350498708

Epoch: 6| Step: 3
Training loss: 2.91010217808407
Validation loss: 2.6061033425074283

Epoch: 6| Step: 4
Training loss: 3.0689111671157816
Validation loss: 2.60761872174125

Epoch: 6| Step: 5
Training loss: 2.8591148383182174
Validation loss: 2.6041219780481817

Epoch: 6| Step: 6
Training loss: 2.941238297205323
Validation loss: 2.6110352570465527

Epoch: 6| Step: 7
Training loss: 2.926824773226752
Validation loss: 2.6114149308144348

Epoch: 6| Step: 8
Training loss: 2.7006353478475127
Validation loss: 2.6095112801914664

Epoch: 6| Step: 9
Training loss: 2.830606794241899
Validation loss: 2.6180472893677478

Epoch: 6| Step: 10
Training loss: 2.841329697423882
Validation loss: 2.6069421271300826

Epoch: 6| Step: 11
Training loss: 3.2446030040938454
Validation loss: 2.6102100215458792

Epoch: 6| Step: 12
Training loss: 2.63818119888437
Validation loss: 2.608330158649887

Epoch: 6| Step: 13
Training loss: 2.06276805176197
Validation loss: 2.6091281164205693

Epoch: 227| Step: 0
Training loss: 2.831667709694667
Validation loss: 2.622725582061994

Epoch: 6| Step: 1
Training loss: 2.786553630209403
Validation loss: 2.620518711062787

Epoch: 6| Step: 2
Training loss: 2.7783103580665256
Validation loss: 2.6241686266703295

Epoch: 6| Step: 3
Training loss: 3.0317967501835983
Validation loss: 2.628255006747474

Epoch: 6| Step: 4
Training loss: 2.8364346491431567
Validation loss: 2.631568202526801

Epoch: 6| Step: 5
Training loss: 3.1151345742242573
Validation loss: 2.6301359326073617

Epoch: 6| Step: 6
Training loss: 2.753186893525158
Validation loss: 2.6203807066752494

Epoch: 6| Step: 7
Training loss: 2.38787623931081
Validation loss: 2.6176163938013235

Epoch: 6| Step: 8
Training loss: 2.73666477787202
Validation loss: 2.628343792442468

Epoch: 6| Step: 9
Training loss: 2.9012278160946527
Validation loss: 2.6164305624388637

Epoch: 6| Step: 10
Training loss: 3.474424240386464
Validation loss: 2.610598183076563

Epoch: 6| Step: 11
Training loss: 3.038929129765501
Validation loss: 2.604211179947606

Epoch: 6| Step: 12
Training loss: 3.6391677231929416
Validation loss: 2.6041097107268074

Epoch: 6| Step: 13
Training loss: 2.6635260167642403
Validation loss: 2.6045856278277495

Epoch: 228| Step: 0
Training loss: 3.3291101564680803
Validation loss: 2.608102210126824

Epoch: 6| Step: 1
Training loss: 2.8675127806374534
Validation loss: 2.6097526146883476

Epoch: 6| Step: 2
Training loss: 3.0992552200991006
Validation loss: 2.610238814353254

Epoch: 6| Step: 3
Training loss: 3.0976345451142957
Validation loss: 2.6061650300080568

Epoch: 6| Step: 4
Training loss: 2.8294253231534063
Validation loss: 2.6099234010797265

Epoch: 6| Step: 5
Training loss: 3.3286529265576723
Validation loss: 2.60672051865737

Epoch: 6| Step: 6
Training loss: 2.780585048780378
Validation loss: 2.6120001424076973

Epoch: 6| Step: 7
Training loss: 2.593853867990402
Validation loss: 2.61450013752003

Epoch: 6| Step: 8
Training loss: 2.6072053397916113
Validation loss: 2.607755293281

Epoch: 6| Step: 9
Training loss: 2.8904161532451393
Validation loss: 2.601477748263056

Epoch: 6| Step: 10
Training loss: 3.3572640817431965
Validation loss: 2.6057247090194795

Epoch: 6| Step: 11
Training loss: 3.0459103353206225
Validation loss: 2.6125926059489997

Epoch: 6| Step: 12
Training loss: 2.5251227736132096
Validation loss: 2.6047073104944296

Epoch: 6| Step: 13
Training loss: 2.615629820095712
Validation loss: 2.6053139775799776

Epoch: 229| Step: 0
Training loss: 3.2253533931180387
Validation loss: 2.6025860274647634

Epoch: 6| Step: 1
Training loss: 2.754521640711274
Validation loss: 2.6016963899774446

Epoch: 6| Step: 2
Training loss: 2.997712534797855
Validation loss: 2.602026045241766

Epoch: 6| Step: 3
Training loss: 3.0444254100356125
Validation loss: 2.600145976147038

Epoch: 6| Step: 4
Training loss: 2.393030290500403
Validation loss: 2.5992585847058716

Epoch: 6| Step: 5
Training loss: 2.96050941774777
Validation loss: 2.5966381642961736

Epoch: 6| Step: 6
Training loss: 2.85885365220256
Validation loss: 2.5982000696600602

Epoch: 6| Step: 7
Training loss: 2.5638163837262002
Validation loss: 2.602799948766953

Epoch: 6| Step: 8
Training loss: 3.5046795488217177
Validation loss: 2.597526966140426

Epoch: 6| Step: 9
Training loss: 3.0078904971624087
Validation loss: 2.6039925534688617

Epoch: 6| Step: 10
Training loss: 3.115419426566859
Validation loss: 2.6050898176193

Epoch: 6| Step: 11
Training loss: 2.592478428955977
Validation loss: 2.6092947316990545

Epoch: 6| Step: 12
Training loss: 2.8053773334495
Validation loss: 2.6100981718921377

Epoch: 6| Step: 13
Training loss: 3.451776025262453
Validation loss: 2.608559768790993

Epoch: 230| Step: 0
Training loss: 3.230129976049015
Validation loss: 2.6114002444575104

Epoch: 6| Step: 1
Training loss: 2.523747191897564
Validation loss: 2.6120843260190294

Epoch: 6| Step: 2
Training loss: 2.947260609515696
Validation loss: 2.6093958332580267

Epoch: 6| Step: 3
Training loss: 3.183603934991377
Validation loss: 2.614181951202464

Epoch: 6| Step: 4
Training loss: 2.280702708188783
Validation loss: 2.621438668904819

Epoch: 6| Step: 5
Training loss: 3.5235216760836106
Validation loss: 2.6333393212381835

Epoch: 6| Step: 6
Training loss: 2.193555678757233
Validation loss: 2.6045012500721128

Epoch: 6| Step: 7
Training loss: 3.323257396931108
Validation loss: 2.611645564504673

Epoch: 6| Step: 8
Training loss: 2.1342658935183874
Validation loss: 2.6097862956505855

Epoch: 6| Step: 9
Training loss: 2.781365552923466
Validation loss: 2.6043420269077417

Epoch: 6| Step: 10
Training loss: 3.335479490477566
Validation loss: 2.59785929288889

Epoch: 6| Step: 11
Training loss: 2.784138240659581
Validation loss: 2.5948599061476374

Epoch: 6| Step: 12
Training loss: 3.283971910939681
Validation loss: 2.5992928523788255

Epoch: 6| Step: 13
Training loss: 3.382738354863678
Validation loss: 2.597899281817544

Epoch: 231| Step: 0
Training loss: 2.7391081036407043
Validation loss: 2.5921009928619387

Epoch: 6| Step: 1
Training loss: 3.1682306409551546
Validation loss: 2.5970401378376975

Epoch: 6| Step: 2
Training loss: 2.8861554206561046
Validation loss: 2.5952434645913747

Epoch: 6| Step: 3
Training loss: 3.044391891817937
Validation loss: 2.5994669591859685

Epoch: 6| Step: 4
Training loss: 2.029415299720645
Validation loss: 2.601531971403095

Epoch: 6| Step: 5
Training loss: 3.4080762254760066
Validation loss: 2.604534162289114

Epoch: 6| Step: 6
Training loss: 3.1645970022589833
Validation loss: 2.609359133011873

Epoch: 6| Step: 7
Training loss: 3.3090014426077508
Validation loss: 2.6121780168828965

Epoch: 6| Step: 8
Training loss: 3.0311412988422965
Validation loss: 2.6124780331234834

Epoch: 6| Step: 9
Training loss: 2.5329889046613876
Validation loss: 2.610714164059139

Epoch: 6| Step: 10
Training loss: 2.6407488731808737
Validation loss: 2.607019824593979

Epoch: 6| Step: 11
Training loss: 3.1934289580530573
Validation loss: 2.6129894437330425

Epoch: 6| Step: 12
Training loss: 3.0520727962446537
Validation loss: 2.6043201117479757

Epoch: 6| Step: 13
Training loss: 2.480026854554261
Validation loss: 2.6140319990729384

Epoch: 232| Step: 0
Training loss: 2.21939367709174
Validation loss: 2.6136405407581464

Epoch: 6| Step: 1
Training loss: 2.3119709337578747
Validation loss: 2.6290816174661216

Epoch: 6| Step: 2
Training loss: 3.2226942765275424
Validation loss: 2.625780349975716

Epoch: 6| Step: 3
Training loss: 2.656361027809416
Validation loss: 2.6333642844326586

Epoch: 6| Step: 4
Training loss: 2.1740193929781126
Validation loss: 2.6327810873793607

Epoch: 6| Step: 5
Training loss: 3.038859147277509
Validation loss: 2.649741413210256

Epoch: 6| Step: 6
Training loss: 3.4364589155014915
Validation loss: 2.6529420400820993

Epoch: 6| Step: 7
Training loss: 3.2880651996208967
Validation loss: 2.6808559530226534

Epoch: 6| Step: 8
Training loss: 3.7009656058534843
Validation loss: 2.637397219053913

Epoch: 6| Step: 9
Training loss: 3.1425559717017486
Validation loss: 2.623583515473859

Epoch: 6| Step: 10
Training loss: 2.809519990398099
Validation loss: 2.609102695348595

Epoch: 6| Step: 11
Training loss: 2.766826131736817
Validation loss: 2.595499398831778

Epoch: 6| Step: 12
Training loss: 3.387586506657489
Validation loss: 2.5959684272370724

Epoch: 6| Step: 13
Training loss: 2.201245635860694
Validation loss: 2.5879091576291677

Epoch: 233| Step: 0
Training loss: 3.1081641825314326
Validation loss: 2.593260844352901

Epoch: 6| Step: 1
Training loss: 2.787898999041648
Validation loss: 2.5935485401831033

Epoch: 6| Step: 2
Training loss: 3.0685585972283507
Validation loss: 2.591179949409646

Epoch: 6| Step: 3
Training loss: 3.075715336906067
Validation loss: 2.5882418318077174

Epoch: 6| Step: 4
Training loss: 2.1965330810139805
Validation loss: 2.58548162834064

Epoch: 6| Step: 5
Training loss: 2.6219481029481155
Validation loss: 2.588049164441554

Epoch: 6| Step: 6
Training loss: 3.4851639884994507
Validation loss: 2.5935879026708695

Epoch: 6| Step: 7
Training loss: 3.547237696987709
Validation loss: 2.597069530734049

Epoch: 6| Step: 8
Training loss: 2.728857435417254
Validation loss: 2.616227032405541

Epoch: 6| Step: 9
Training loss: 2.2659410979653116
Validation loss: 2.63885447428063

Epoch: 6| Step: 10
Training loss: 2.6146929795171423
Validation loss: 2.6534562303051423

Epoch: 6| Step: 11
Training loss: 3.3675951788350664
Validation loss: 2.6677051804903384

Epoch: 6| Step: 12
Training loss: 3.3152664436523387
Validation loss: 2.634883229513002

Epoch: 6| Step: 13
Training loss: 2.6550122238136407
Validation loss: 2.623921829709188

Epoch: 234| Step: 0
Training loss: 3.0236374742087473
Validation loss: 2.618030039395832

Epoch: 6| Step: 1
Training loss: 2.99703053696317
Validation loss: 2.5979566367262836

Epoch: 6| Step: 2
Training loss: 2.9514077658454734
Validation loss: 2.6071256703992525

Epoch: 6| Step: 3
Training loss: 2.5936539413864907
Validation loss: 2.609426337642152

Epoch: 6| Step: 4
Training loss: 3.0803318536008595
Validation loss: 2.5954584987769023

Epoch: 6| Step: 5
Training loss: 3.352958761824561
Validation loss: 2.596285282081525

Epoch: 6| Step: 6
Training loss: 2.468771246323726
Validation loss: 2.5882358779353263

Epoch: 6| Step: 7
Training loss: 2.6362977998758272
Validation loss: 2.5838304319908714

Epoch: 6| Step: 8
Training loss: 2.9170064092493115
Validation loss: 2.5839581053280734

Epoch: 6| Step: 9
Training loss: 3.4449952686648273
Validation loss: 2.58497601903135

Epoch: 6| Step: 10
Training loss: 3.5361542531195482
Validation loss: 2.5888632126103412

Epoch: 6| Step: 11
Training loss: 2.8336607986902194
Validation loss: 2.581264339821246

Epoch: 6| Step: 12
Training loss: 2.645638125770283
Validation loss: 2.587507258674483

Epoch: 6| Step: 13
Training loss: 1.9078964877250377
Validation loss: 2.5851581418814944

Epoch: 235| Step: 0
Training loss: 2.679566227696121
Validation loss: 2.5907810989416125

Epoch: 6| Step: 1
Training loss: 2.534197280616918
Validation loss: 2.6077753854597394

Epoch: 6| Step: 2
Training loss: 3.1984738704251563
Validation loss: 2.62112844521927

Epoch: 6| Step: 3
Training loss: 3.3008965285897793
Validation loss: 2.6399240239933093

Epoch: 6| Step: 4
Training loss: 3.3917787056927984
Validation loss: 2.674397384531125

Epoch: 6| Step: 5
Training loss: 2.44252337722758
Validation loss: 2.6762483875719085

Epoch: 6| Step: 6
Training loss: 3.438339408342767
Validation loss: 2.7077862271365576

Epoch: 6| Step: 7
Training loss: 2.6031974718279716
Validation loss: 2.671459191309468

Epoch: 6| Step: 8
Training loss: 3.283603514448737
Validation loss: 2.652753710407175

Epoch: 6| Step: 9
Training loss: 2.4549480880252195
Validation loss: 2.6298439298967637

Epoch: 6| Step: 10
Training loss: 2.8470024540967316
Validation loss: 2.5998938450073505

Epoch: 6| Step: 11
Training loss: 3.081079913971609
Validation loss: 2.584532994732318

Epoch: 6| Step: 12
Training loss: 2.8214099048735117
Validation loss: 2.591689566315974

Epoch: 6| Step: 13
Training loss: 2.7807577319028707
Validation loss: 2.5889987406250885

Epoch: 236| Step: 0
Training loss: 2.8076665247023773
Validation loss: 2.5852067236578287

Epoch: 6| Step: 1
Training loss: 2.410569215880258
Validation loss: 2.5866539625634584

Epoch: 6| Step: 2
Training loss: 3.517896537200569
Validation loss: 2.596108793855762

Epoch: 6| Step: 3
Training loss: 2.8484675922153944
Validation loss: 2.5943961971237366

Epoch: 6| Step: 4
Training loss: 3.180594050263762
Validation loss: 2.5961830162646535

Epoch: 6| Step: 5
Training loss: 3.0084080490457055
Validation loss: 2.5936816330424532

Epoch: 6| Step: 6
Training loss: 2.967840597504324
Validation loss: 2.5939168815829015

Epoch: 6| Step: 7
Training loss: 3.234832878689679
Validation loss: 2.5923833744397684

Epoch: 6| Step: 8
Training loss: 2.654808999930285
Validation loss: 2.5891557804646115

Epoch: 6| Step: 9
Training loss: 2.870935469435969
Validation loss: 2.5879878019420826

Epoch: 6| Step: 10
Training loss: 3.1001562202222512
Validation loss: 2.587622386290432

Epoch: 6| Step: 11
Training loss: 2.543493729412852
Validation loss: 2.589540232304146

Epoch: 6| Step: 12
Training loss: 3.2627924996281763
Validation loss: 2.582630788030231

Epoch: 6| Step: 13
Training loss: 2.2721818425519027
Validation loss: 2.5968528519853784

Epoch: 237| Step: 0
Training loss: 2.9033782881341503
Validation loss: 2.593212504415003

Epoch: 6| Step: 1
Training loss: 3.5391135643649765
Validation loss: 2.5970825607939285

Epoch: 6| Step: 2
Training loss: 2.7400278134570217
Validation loss: 2.5918090739905364

Epoch: 6| Step: 3
Training loss: 2.805532684065082
Validation loss: 2.5997148667449235

Epoch: 6| Step: 4
Training loss: 2.909256723132441
Validation loss: 2.6047338374252256

Epoch: 6| Step: 5
Training loss: 2.574356376430554
Validation loss: 2.6213368455208834

Epoch: 6| Step: 6
Training loss: 3.2929690396092695
Validation loss: 2.62203937688792

Epoch: 6| Step: 7
Training loss: 2.777953948686286
Validation loss: 2.6256028785373866

Epoch: 6| Step: 8
Training loss: 3.3714078931428335
Validation loss: 2.619865477274914

Epoch: 6| Step: 9
Training loss: 2.0456112753421967
Validation loss: 2.6091034617574476

Epoch: 6| Step: 10
Training loss: 2.356310338226733
Validation loss: 2.604621486857186

Epoch: 6| Step: 11
Training loss: 3.508818280432553
Validation loss: 2.6083571106789725

Epoch: 6| Step: 12
Training loss: 3.1603258462294206
Validation loss: 2.591934199103501

Epoch: 6| Step: 13
Training loss: 2.7066303963728737
Validation loss: 2.5940376534390093

Epoch: 238| Step: 0
Training loss: 2.903911675342154
Validation loss: 2.585387858499961

Epoch: 6| Step: 1
Training loss: 3.0442487304163572
Validation loss: 2.5901513703390595

Epoch: 6| Step: 2
Training loss: 3.4346790182630014
Validation loss: 2.5889786651221764

Epoch: 6| Step: 3
Training loss: 2.9714949917443767
Validation loss: 2.592602674338015

Epoch: 6| Step: 4
Training loss: 2.7743127435796118
Validation loss: 2.5917175885698285

Epoch: 6| Step: 5
Training loss: 3.77970917889866
Validation loss: 2.5903932120349995

Epoch: 6| Step: 6
Training loss: 2.7884447284464997
Validation loss: 2.5917949382702012

Epoch: 6| Step: 7
Training loss: 3.004201807529949
Validation loss: 2.5914324277867595

Epoch: 6| Step: 8
Training loss: 2.69436097971667
Validation loss: 2.588676519606126

Epoch: 6| Step: 9
Training loss: 2.970100657751399
Validation loss: 2.5924524144550185

Epoch: 6| Step: 10
Training loss: 3.011152043441703
Validation loss: 2.6019376906531115

Epoch: 6| Step: 11
Training loss: 2.5531155944426853
Validation loss: 2.601812499273127

Epoch: 6| Step: 12
Training loss: 2.384447381157127
Validation loss: 2.601939430659363

Epoch: 6| Step: 13
Training loss: 1.9489268235296857
Validation loss: 2.6156858061194366

Epoch: 239| Step: 0
Training loss: 2.529899142520445
Validation loss: 2.6020287753621996

Epoch: 6| Step: 1
Training loss: 2.8994341265304433
Validation loss: 2.606567910569201

Epoch: 6| Step: 2
Training loss: 2.6322337796471142
Validation loss: 2.6079852754738524

Epoch: 6| Step: 3
Training loss: 3.2301400143064893
Validation loss: 2.6107184788277946

Epoch: 6| Step: 4
Training loss: 2.874371667284774
Validation loss: 2.6097769557522117

Epoch: 6| Step: 5
Training loss: 2.6772515705448496
Validation loss: 2.6052379483481887

Epoch: 6| Step: 6
Training loss: 3.039841735886235
Validation loss: 2.6174453591181406

Epoch: 6| Step: 7
Training loss: 2.8347431116260133
Validation loss: 2.6201303240700176

Epoch: 6| Step: 8
Training loss: 3.401789132779109
Validation loss: 2.6152519933665905

Epoch: 6| Step: 9
Training loss: 3.3289167868199674
Validation loss: 2.61404520152918

Epoch: 6| Step: 10
Training loss: 2.4591580209178265
Validation loss: 2.605150251801452

Epoch: 6| Step: 11
Training loss: 3.404813691138225
Validation loss: 2.5957772874059684

Epoch: 6| Step: 12
Training loss: 2.494117969717731
Validation loss: 2.590913781835671

Epoch: 6| Step: 13
Training loss: 3.000840387255736
Validation loss: 2.587644529058773

Epoch: 240| Step: 0
Training loss: 3.2263848576817256
Validation loss: 2.583102624483947

Epoch: 6| Step: 1
Training loss: 3.113181692946285
Validation loss: 2.582143756451423

Epoch: 6| Step: 2
Training loss: 3.077157270248748
Validation loss: 2.5862074469658993

Epoch: 6| Step: 3
Training loss: 2.97738275715108
Validation loss: 2.585154816787977

Epoch: 6| Step: 4
Training loss: 2.54291793374006
Validation loss: 2.5804847873185186

Epoch: 6| Step: 5
Training loss: 3.2742240161166194
Validation loss: 2.5828651175264623

Epoch: 6| Step: 6
Training loss: 2.7982072267939757
Validation loss: 2.580053453072156

Epoch: 6| Step: 7
Training loss: 2.8114873970586425
Validation loss: 2.5789043403307246

Epoch: 6| Step: 8
Training loss: 2.7440060402661897
Validation loss: 2.5823827841218656

Epoch: 6| Step: 9
Training loss: 2.2708773010850347
Validation loss: 2.5833412557977296

Epoch: 6| Step: 10
Training loss: 3.1342957141466825
Validation loss: 2.583277982250465

Epoch: 6| Step: 11
Training loss: 3.448242878920562
Validation loss: 2.5828767373641397

Epoch: 6| Step: 12
Training loss: 2.937822689431923
Validation loss: 2.5844988110836584

Epoch: 6| Step: 13
Training loss: 2.187977765906583
Validation loss: 2.5892661902120304

Epoch: 241| Step: 0
Training loss: 2.4301298174306307
Validation loss: 2.586908988557608

Epoch: 6| Step: 1
Training loss: 3.1794334516332086
Validation loss: 2.5908672044237213

Epoch: 6| Step: 2
Training loss: 3.3298455747247004
Validation loss: 2.603503481846434

Epoch: 6| Step: 3
Training loss: 2.919069299652181
Validation loss: 2.612126111089279

Epoch: 6| Step: 4
Training loss: 2.4770734482534005
Validation loss: 2.6187918900081586

Epoch: 6| Step: 5
Training loss: 3.3929842989620407
Validation loss: 2.6433375344196945

Epoch: 6| Step: 6
Training loss: 2.4551024029850703
Validation loss: 2.650323606921432

Epoch: 6| Step: 7
Training loss: 3.3415327474977854
Validation loss: 2.6502744795669444

Epoch: 6| Step: 8
Training loss: 2.8830033732754083
Validation loss: 2.6283997207697647

Epoch: 6| Step: 9
Training loss: 3.495758756646112
Validation loss: 2.6100666735031117

Epoch: 6| Step: 10
Training loss: 2.7766739994088105
Validation loss: 2.5883236998785186

Epoch: 6| Step: 11
Training loss: 2.316380106632087
Validation loss: 2.578889601044846

Epoch: 6| Step: 12
Training loss: 2.596714118537007
Validation loss: 2.5765898329244568

Epoch: 6| Step: 13
Training loss: 3.339646718420591
Validation loss: 2.5777955999219166

Epoch: 242| Step: 0
Training loss: 3.019999281523158
Validation loss: 2.5791218520564794

Epoch: 6| Step: 1
Training loss: 2.7684603881923233
Validation loss: 2.5850908537704007

Epoch: 6| Step: 2
Training loss: 3.3099672243276137
Validation loss: 2.585359262915257

Epoch: 6| Step: 3
Training loss: 3.0171169879246054
Validation loss: 2.585138052420449

Epoch: 6| Step: 4
Training loss: 3.124443615020502
Validation loss: 2.582348168951205

Epoch: 6| Step: 5
Training loss: 3.2370769622015954
Validation loss: 2.5844455280489256

Epoch: 6| Step: 6
Training loss: 2.677633048490888
Validation loss: 2.5823332924655165

Epoch: 6| Step: 7
Training loss: 3.1331394243773913
Validation loss: 2.5840097941605378

Epoch: 6| Step: 8
Training loss: 2.704097506711928
Validation loss: 2.580397844096222

Epoch: 6| Step: 9
Training loss: 2.857441399508227
Validation loss: 2.579735158085767

Epoch: 6| Step: 10
Training loss: 3.092911423597312
Validation loss: 2.578455052980915

Epoch: 6| Step: 11
Training loss: 2.527474212816791
Validation loss: 2.578706021434265

Epoch: 6| Step: 12
Training loss: 3.1147380947758436
Validation loss: 2.5741797087948575

Epoch: 6| Step: 13
Training loss: 2.2678113188260194
Validation loss: 2.5739128728650336

Epoch: 243| Step: 0
Training loss: 1.882675102570701
Validation loss: 2.5740353083552865

Epoch: 6| Step: 1
Training loss: 3.3534638673568513
Validation loss: 2.5747219503059187

Epoch: 6| Step: 2
Training loss: 3.0721765348851657
Validation loss: 2.576899817421703

Epoch: 6| Step: 3
Training loss: 2.811128917917472
Validation loss: 2.582221144732104

Epoch: 6| Step: 4
Training loss: 2.8647137606434474
Validation loss: 2.582857146289569

Epoch: 6| Step: 5
Training loss: 3.0021410295676607
Validation loss: 2.588796612000498

Epoch: 6| Step: 6
Training loss: 3.064803522231533
Validation loss: 2.6025170518753606

Epoch: 6| Step: 7
Training loss: 2.763098128109815
Validation loss: 2.61658272071349

Epoch: 6| Step: 8
Training loss: 3.577226417685046
Validation loss: 2.622768445810785

Epoch: 6| Step: 9
Training loss: 3.63633508020806
Validation loss: 2.638027028903967

Epoch: 6| Step: 10
Training loss: 2.266963694782767
Validation loss: 2.612343569138338

Epoch: 6| Step: 11
Training loss: 2.5110240111910183
Validation loss: 2.6304853175102294

Epoch: 6| Step: 12
Training loss: 3.0401552878421088
Validation loss: 2.6019484843877234

Epoch: 6| Step: 13
Training loss: 2.6082202846253426
Validation loss: 2.6076283112201764

Epoch: 244| Step: 0
Training loss: 3.3465675533355195
Validation loss: 2.5943484702506714

Epoch: 6| Step: 1
Training loss: 2.8374308707937193
Validation loss: 2.5838970286479306

Epoch: 6| Step: 2
Training loss: 2.90800751078815
Validation loss: 2.581559242555629

Epoch: 6| Step: 3
Training loss: 2.3171675719152143
Validation loss: 2.587646549143509

Epoch: 6| Step: 4
Training loss: 2.9035456390656593
Validation loss: 2.583952184247228

Epoch: 6| Step: 5
Training loss: 2.8953238571940636
Validation loss: 2.5785411510036136

Epoch: 6| Step: 6
Training loss: 3.059865947604498
Validation loss: 2.579598778647644

Epoch: 6| Step: 7
Training loss: 3.124089680643409
Validation loss: 2.577961387178427

Epoch: 6| Step: 8
Training loss: 2.90975265264468
Validation loss: 2.5741015170470702

Epoch: 6| Step: 9
Training loss: 3.177861019487745
Validation loss: 2.574963975728653

Epoch: 6| Step: 10
Training loss: 3.1995218992704415
Validation loss: 2.5754547201898896

Epoch: 6| Step: 11
Training loss: 2.9949356884810077
Validation loss: 2.5736710693427205

Epoch: 6| Step: 12
Training loss: 2.397038452463859
Validation loss: 2.5671527579910776

Epoch: 6| Step: 13
Training loss: 2.3655057163979807
Validation loss: 2.576653367219293

Epoch: 245| Step: 0
Training loss: 2.8789835988061525
Validation loss: 2.5758007412612787

Epoch: 6| Step: 1
Training loss: 2.6123277780813607
Validation loss: 2.5752986008844734

Epoch: 6| Step: 2
Training loss: 3.132118966445991
Validation loss: 2.578172146194257

Epoch: 6| Step: 3
Training loss: 3.3602632989352763
Validation loss: 2.5751613085349816

Epoch: 6| Step: 4
Training loss: 3.1005696357839176
Validation loss: 2.5800770200842345

Epoch: 6| Step: 5
Training loss: 3.1712142180881435
Validation loss: 2.59614341465431

Epoch: 6| Step: 6
Training loss: 2.313190460227096
Validation loss: 2.6025608990779823

Epoch: 6| Step: 7
Training loss: 2.6760558495616538
Validation loss: 2.6010567078791693

Epoch: 6| Step: 8
Training loss: 2.605388131102578
Validation loss: 2.6225233294565307

Epoch: 6| Step: 9
Training loss: 3.1444799952150464
Validation loss: 2.645488105739016

Epoch: 6| Step: 10
Training loss: 2.6389373261763565
Validation loss: 2.643986256271226

Epoch: 6| Step: 11
Training loss: 3.148145941399027
Validation loss: 2.6265653034311955

Epoch: 6| Step: 12
Training loss: 2.9938461447549964
Validation loss: 2.608434629381761

Epoch: 6| Step: 13
Training loss: 2.908249362145033
Validation loss: 2.589762655587917

Epoch: 246| Step: 0
Training loss: 3.156716793780794
Validation loss: 2.5864805622814178

Epoch: 6| Step: 1
Training loss: 3.006962960890763
Validation loss: 2.5713697166058846

Epoch: 6| Step: 2
Training loss: 2.955448588807456
Validation loss: 2.5693288442483277

Epoch: 6| Step: 3
Training loss: 2.550374628111207
Validation loss: 2.5704838832471704

Epoch: 6| Step: 4
Training loss: 2.79197041201831
Validation loss: 2.5715630544243226

Epoch: 6| Step: 5
Training loss: 2.4199857172268664
Validation loss: 2.5710713428051335

Epoch: 6| Step: 6
Training loss: 3.3157955546470723
Validation loss: 2.5738925153546006

Epoch: 6| Step: 7
Training loss: 3.0567744704122135
Validation loss: 2.5811162098586204

Epoch: 6| Step: 8
Training loss: 2.8288242887619326
Validation loss: 2.5841646381860195

Epoch: 6| Step: 9
Training loss: 2.861891342819547
Validation loss: 2.5748743241430216

Epoch: 6| Step: 10
Training loss: 2.8851378451890626
Validation loss: 2.6055339316734374

Epoch: 6| Step: 11
Training loss: 3.215009423178335
Validation loss: 2.61229582962836

Epoch: 6| Step: 12
Training loss: 2.780134341609675
Validation loss: 2.6291526424570284

Epoch: 6| Step: 13
Training loss: 2.968284008195325
Validation loss: 2.623141740953225

Epoch: 247| Step: 0
Training loss: 3.1370814435587273
Validation loss: 2.606495801004756

Epoch: 6| Step: 1
Training loss: 3.1910905249943156
Validation loss: 2.595858564267215

Epoch: 6| Step: 2
Training loss: 2.9937379968199482
Validation loss: 2.5784885879741264

Epoch: 6| Step: 3
Training loss: 2.458464236465021
Validation loss: 2.568752112029831

Epoch: 6| Step: 4
Training loss: 2.4758075321496174
Validation loss: 2.567625652522035

Epoch: 6| Step: 5
Training loss: 3.334850268112495
Validation loss: 2.5670465203327164

Epoch: 6| Step: 6
Training loss: 3.0174529707055786
Validation loss: 2.5663896059013576

Epoch: 6| Step: 7
Training loss: 2.60979928775906
Validation loss: 2.5699603846971995

Epoch: 6| Step: 8
Training loss: 3.181485654125636
Validation loss: 2.573230905728569

Epoch: 6| Step: 9
Training loss: 3.0957952347298385
Validation loss: 2.5747379690151386

Epoch: 6| Step: 10
Training loss: 2.9051659315718648
Validation loss: 2.574379830288675

Epoch: 6| Step: 11
Training loss: 2.670793637969098
Validation loss: 2.5779407961194383

Epoch: 6| Step: 12
Training loss: 3.1178976602844624
Validation loss: 2.5762967217013797

Epoch: 6| Step: 13
Training loss: 2.298954651493592
Validation loss: 2.58283520466547

Epoch: 248| Step: 0
Training loss: 2.821362582602556
Validation loss: 2.5803992340106845

Epoch: 6| Step: 1
Training loss: 3.297745576148919
Validation loss: 2.584232982126883

Epoch: 6| Step: 2
Training loss: 3.265235695152413
Validation loss: 2.5884986930491016

Epoch: 6| Step: 3
Training loss: 2.463765581102035
Validation loss: 2.5835073292064994

Epoch: 6| Step: 4
Training loss: 3.0917797558058115
Validation loss: 2.5744729973152913

Epoch: 6| Step: 5
Training loss: 2.7973413345027325
Validation loss: 2.567379935697689

Epoch: 6| Step: 6
Training loss: 3.086960557770295
Validation loss: 2.5699235736774653

Epoch: 6| Step: 7
Training loss: 2.970210469042171
Validation loss: 2.5673132131502423

Epoch: 6| Step: 8
Training loss: 3.263462062189119
Validation loss: 2.5644333152017422

Epoch: 6| Step: 9
Training loss: 2.789623642151366
Validation loss: 2.5724458822140703

Epoch: 6| Step: 10
Training loss: 2.4270419225038755
Validation loss: 2.5745034156059234

Epoch: 6| Step: 11
Training loss: 2.3222922154372854
Validation loss: 2.5759088073939727

Epoch: 6| Step: 12
Training loss: 2.861808033559775
Validation loss: 2.5767615299166935

Epoch: 6| Step: 13
Training loss: 3.3555457713620975
Validation loss: 2.597875258732191

Epoch: 249| Step: 0
Training loss: 2.833098532727476
Validation loss: 2.598121207556191

Epoch: 6| Step: 1
Training loss: 2.9938286247361505
Validation loss: 2.5932693579727166

Epoch: 6| Step: 2
Training loss: 3.101177047492616
Validation loss: 2.5974027046238684

Epoch: 6| Step: 3
Training loss: 3.3071461723143885
Validation loss: 2.5844147496423275

Epoch: 6| Step: 4
Training loss: 3.075328970579036
Validation loss: 2.593968625966588

Epoch: 6| Step: 5
Training loss: 3.0831570617877007
Validation loss: 2.5784209716986495

Epoch: 6| Step: 6
Training loss: 2.4168933455168258
Validation loss: 2.576847990945037

Epoch: 6| Step: 7
Training loss: 2.4485641164363665
Validation loss: 2.585150817348325

Epoch: 6| Step: 8
Training loss: 3.2716624834911974
Validation loss: 2.584048868402152

Epoch: 6| Step: 9
Training loss: 2.25497775995152
Validation loss: 2.5802853419964444

Epoch: 6| Step: 10
Training loss: 2.9325927977257513
Validation loss: 2.59910182584296

Epoch: 6| Step: 11
Training loss: 2.7043869512693712
Validation loss: 2.610399835485458

Epoch: 6| Step: 12
Training loss: 3.0750028780791916
Validation loss: 2.6378639185132218

Epoch: 6| Step: 13
Training loss: 3.2654948961541925
Validation loss: 2.6188944349223937

Epoch: 250| Step: 0
Training loss: 2.777004988515108
Validation loss: 2.6182899980143026

Epoch: 6| Step: 1
Training loss: 2.6092562163036686
Validation loss: 2.6080288572465715

Epoch: 6| Step: 2
Training loss: 3.015710700996449
Validation loss: 2.5942139885736313

Epoch: 6| Step: 3
Training loss: 2.5931366344603726
Validation loss: 2.611328581017365

Epoch: 6| Step: 4
Training loss: 2.9566153431609177
Validation loss: 2.6093133923171474

Epoch: 6| Step: 5
Training loss: 3.102894225667964
Validation loss: 2.6276359595614873

Epoch: 6| Step: 6
Training loss: 2.675861797373433
Validation loss: 2.6037014400891576

Epoch: 6| Step: 7
Training loss: 3.200809144002586
Validation loss: 2.5791863467769276

Epoch: 6| Step: 8
Training loss: 2.6331287046995433
Validation loss: 2.5685982162534278

Epoch: 6| Step: 9
Training loss: 2.8387806829678146
Validation loss: 2.560345299817519

Epoch: 6| Step: 10
Training loss: 3.1812650249253798
Validation loss: 2.5610787827172468

Epoch: 6| Step: 11
Training loss: 3.4383141680534814
Validation loss: 2.5581002349443267

Epoch: 6| Step: 12
Training loss: 3.179838359731286
Validation loss: 2.561539565768895

Epoch: 6| Step: 13
Training loss: 2.1735370232004665
Validation loss: 2.5627897615475335

Epoch: 251| Step: 0
Training loss: 2.756261978642391
Validation loss: 2.5562432993140556

Epoch: 6| Step: 1
Training loss: 2.85974769039546
Validation loss: 2.556194905217041

Epoch: 6| Step: 2
Training loss: 2.7725262931491943
Validation loss: 2.561474972016371

Epoch: 6| Step: 3
Training loss: 3.4876618214462716
Validation loss: 2.5609731169475505

Epoch: 6| Step: 4
Training loss: 2.8786100858941155
Validation loss: 2.5622145250896504

Epoch: 6| Step: 5
Training loss: 2.74682373068466
Validation loss: 2.5585062863235097

Epoch: 6| Step: 6
Training loss: 2.8731841282115793
Validation loss: 2.559217908763258

Epoch: 6| Step: 7
Training loss: 2.9517189190413045
Validation loss: 2.562099706646869

Epoch: 6| Step: 8
Training loss: 2.564955488566068
Validation loss: 2.5706852493227954

Epoch: 6| Step: 9
Training loss: 3.2362167348437607
Validation loss: 2.575022399013231

Epoch: 6| Step: 10
Training loss: 3.102355855564159
Validation loss: 2.595139812251941

Epoch: 6| Step: 11
Training loss: 3.0003666653674097
Validation loss: 2.6099974354293005

Epoch: 6| Step: 12
Training loss: 2.4970193260218005
Validation loss: 2.6353449508738693

Epoch: 6| Step: 13
Training loss: 2.7530866986142426
Validation loss: 2.653779817695291

Epoch: 252| Step: 0
Training loss: 3.2820048599253675
Validation loss: 2.692229916164614

Epoch: 6| Step: 1
Training loss: 3.572050710713277
Validation loss: 2.6676091315560226

Epoch: 6| Step: 2
Training loss: 2.576168635831218
Validation loss: 2.6164917889449244

Epoch: 6| Step: 3
Training loss: 2.5130763441421387
Validation loss: 2.606868256782127

Epoch: 6| Step: 4
Training loss: 2.1213922729616157
Validation loss: 2.5970390115114013

Epoch: 6| Step: 5
Training loss: 3.1826826605627336
Validation loss: 2.585898485029741

Epoch: 6| Step: 6
Training loss: 1.9428590676855122
Validation loss: 2.576177773660185

Epoch: 6| Step: 7
Training loss: 2.920964226576466
Validation loss: 2.5713013538003744

Epoch: 6| Step: 8
Training loss: 3.0397360087261824
Validation loss: 2.5705280739060776

Epoch: 6| Step: 9
Training loss: 3.211902037308365
Validation loss: 2.562530160241724

Epoch: 6| Step: 10
Training loss: 3.726155832681815
Validation loss: 2.562432417039634

Epoch: 6| Step: 11
Training loss: 2.7620322819728513
Validation loss: 2.5674215606460367

Epoch: 6| Step: 12
Training loss: 2.670952353203534
Validation loss: 2.5630950556967

Epoch: 6| Step: 13
Training loss: 2.8294812738689057
Validation loss: 2.5657168959816405

Epoch: 253| Step: 0
Training loss: 3.057782334698872
Validation loss: 2.569887623531564

Epoch: 6| Step: 1
Training loss: 2.319553546534962
Validation loss: 2.571452222532375

Epoch: 6| Step: 2
Training loss: 2.924810230587402
Validation loss: 2.5736447561599576

Epoch: 6| Step: 3
Training loss: 2.4419274834215594
Validation loss: 2.57013676931547

Epoch: 6| Step: 4
Training loss: 3.2947816394931118
Validation loss: 2.5763587746098824

Epoch: 6| Step: 5
Training loss: 3.01006535962897
Validation loss: 2.576155801517821

Epoch: 6| Step: 6
Training loss: 2.4723442085640337
Validation loss: 2.5839538054024143

Epoch: 6| Step: 7
Training loss: 2.565700486219183
Validation loss: 2.594954842285118

Epoch: 6| Step: 8
Training loss: 2.280581128029577
Validation loss: 2.604632155295606

Epoch: 6| Step: 9
Training loss: 3.3089608053017114
Validation loss: 2.6076078158044265

Epoch: 6| Step: 10
Training loss: 3.3241592204661696
Validation loss: 2.5961001794416663

Epoch: 6| Step: 11
Training loss: 3.2150760163476004
Validation loss: 2.5819592385721006

Epoch: 6| Step: 12
Training loss: 2.9465962250806723
Validation loss: 2.578963948734217

Epoch: 6| Step: 13
Training loss: 3.4887388811306717
Validation loss: 2.5774952626208916

Epoch: 254| Step: 0
Training loss: 3.4564154642241904
Validation loss: 2.576311928583505

Epoch: 6| Step: 1
Training loss: 2.750496992804751
Validation loss: 2.576201780644865

Epoch: 6| Step: 2
Training loss: 2.9204868548305916
Validation loss: 2.5818108347028557

Epoch: 6| Step: 3
Training loss: 3.042826461893163
Validation loss: 2.5883003218585325

Epoch: 6| Step: 4
Training loss: 2.8349971000212517
Validation loss: 2.613971644698512

Epoch: 6| Step: 5
Training loss: 3.1174096049867543
Validation loss: 2.6276934156598157

Epoch: 6| Step: 6
Training loss: 2.752934017766637
Validation loss: 2.6165377441362594

Epoch: 6| Step: 7
Training loss: 2.4699383543406834
Validation loss: 2.6278157541043035

Epoch: 6| Step: 8
Training loss: 2.599531234151477
Validation loss: 2.630999434801566

Epoch: 6| Step: 9
Training loss: 3.006867178456979
Validation loss: 2.626992107967764

Epoch: 6| Step: 10
Training loss: 2.5112870054428376
Validation loss: 2.6310044626905364

Epoch: 6| Step: 11
Training loss: 2.9873152224806065
Validation loss: 2.581146598528006

Epoch: 6| Step: 12
Training loss: 2.465668118756169
Validation loss: 2.586050695005095

Epoch: 6| Step: 13
Training loss: 4.014418365039986
Validation loss: 2.579268993282964

Epoch: 255| Step: 0
Training loss: 2.889454867682319
Validation loss: 2.5637107367918963

Epoch: 6| Step: 1
Training loss: 3.144245395343712
Validation loss: 2.5555034055942656

Epoch: 6| Step: 2
Training loss: 2.4577259240056235
Validation loss: 2.5591524550085594

Epoch: 6| Step: 3
Training loss: 3.1440081996568137
Validation loss: 2.5594526549938377

Epoch: 6| Step: 4
Training loss: 3.126254630956686
Validation loss: 2.5551148508405412

Epoch: 6| Step: 5
Training loss: 2.9122059816931856
Validation loss: 2.5539659284701632

Epoch: 6| Step: 6
Training loss: 2.5842989890787815
Validation loss: 2.5557707843355177

Epoch: 6| Step: 7
Training loss: 2.71128055919346
Validation loss: 2.5541117616698927

Epoch: 6| Step: 8
Training loss: 2.834576913524578
Validation loss: 2.5541781776732386

Epoch: 6| Step: 9
Training loss: 2.5299249642444006
Validation loss: 2.566491631470031

Epoch: 6| Step: 10
Training loss: 3.652818944688579
Validation loss: 2.5617716925027616

Epoch: 6| Step: 11
Training loss: 2.253663365650209
Validation loss: 2.567704926070665

Epoch: 6| Step: 12
Training loss: 2.8358646940443486
Validation loss: 2.5807788423938307

Epoch: 6| Step: 13
Training loss: 3.5313699077401917
Validation loss: 2.5883373622985615

Epoch: 256| Step: 0
Training loss: 3.0477741186392193
Validation loss: 2.5702754401801657

Epoch: 6| Step: 1
Training loss: 2.375015057967787
Validation loss: 2.5769174382261215

Epoch: 6| Step: 2
Training loss: 2.901557661883419
Validation loss: 2.5685213687097934

Epoch: 6| Step: 3
Training loss: 3.3068358740531414
Validation loss: 2.575709969212946

Epoch: 6| Step: 4
Training loss: 3.0623366643205787
Validation loss: 2.5604086064109577

Epoch: 6| Step: 5
Training loss: 2.5510714542575603
Validation loss: 2.554956502337669

Epoch: 6| Step: 6
Training loss: 2.6942754989653435
Validation loss: 2.5542242663734265

Epoch: 6| Step: 7
Training loss: 2.7592258883977485
Validation loss: 2.5657062895497162

Epoch: 6| Step: 8
Training loss: 3.353648996783642
Validation loss: 2.572279898937712

Epoch: 6| Step: 9
Training loss: 2.522696560478247
Validation loss: 2.5721770793695296

Epoch: 6| Step: 10
Training loss: 3.213521915088628
Validation loss: 2.564797492731176

Epoch: 6| Step: 11
Training loss: 3.0295436815158965
Validation loss: 2.564449264220682

Epoch: 6| Step: 12
Training loss: 3.146172780971288
Validation loss: 2.560284667162536

Epoch: 6| Step: 13
Training loss: 2.7378913286153503
Validation loss: 2.5642332582536596

Epoch: 257| Step: 0
Training loss: 2.1979737357253004
Validation loss: 2.564015380360828

Epoch: 6| Step: 1
Training loss: 2.902531038918407
Validation loss: 2.5663321748409134

Epoch: 6| Step: 2
Training loss: 2.3803492086333686
Validation loss: 2.5943799104603396

Epoch: 6| Step: 3
Training loss: 3.0576513404851613
Validation loss: 2.635897034794151

Epoch: 6| Step: 4
Training loss: 3.204060041210318
Validation loss: 2.6663781418249086

Epoch: 6| Step: 5
Training loss: 3.4378309610739946
Validation loss: 2.677589875803151

Epoch: 6| Step: 6
Training loss: 3.4532071617328812
Validation loss: 2.668399370601013

Epoch: 6| Step: 7
Training loss: 3.078949174095376
Validation loss: 2.6277317632550674

Epoch: 6| Step: 8
Training loss: 2.892887529082389
Validation loss: 2.590934359835195

Epoch: 6| Step: 9
Training loss: 2.168089937139348
Validation loss: 2.5620307852938278

Epoch: 6| Step: 10
Training loss: 3.138351756437023
Validation loss: 2.5644579054804746

Epoch: 6| Step: 11
Training loss: 2.769019506008978
Validation loss: 2.561649458477772

Epoch: 6| Step: 12
Training loss: 3.1597017355081234
Validation loss: 2.5570151843704627

Epoch: 6| Step: 13
Training loss: 2.697681480574752
Validation loss: 2.559982696078639

Epoch: 258| Step: 0
Training loss: 2.9885473992997547
Validation loss: 2.5577141775500087

Epoch: 6| Step: 1
Training loss: 3.255003671951684
Validation loss: 2.553734135246412

Epoch: 6| Step: 2
Training loss: 2.8669791080923126
Validation loss: 2.5562334227965273

Epoch: 6| Step: 3
Training loss: 2.8392083088073656
Validation loss: 2.5617647064002407

Epoch: 6| Step: 4
Training loss: 2.890957539993778
Validation loss: 2.559270606133788

Epoch: 6| Step: 5
Training loss: 2.208109094523056
Validation loss: 2.5697691574682766

Epoch: 6| Step: 6
Training loss: 2.8146847186874755
Validation loss: 2.5709060485813287

Epoch: 6| Step: 7
Training loss: 2.8584563233483617
Validation loss: 2.5599916548458332

Epoch: 6| Step: 8
Training loss: 2.9399013038210136
Validation loss: 2.5571152309778973

Epoch: 6| Step: 9
Training loss: 2.513980114465939
Validation loss: 2.551176566453496

Epoch: 6| Step: 10
Training loss: 3.2166012007882028
Validation loss: 2.5569816003562433

Epoch: 6| Step: 11
Training loss: 3.2708042086784697
Validation loss: 2.565553911799608

Epoch: 6| Step: 12
Training loss: 2.8974619249239977
Validation loss: 2.565896642106177

Epoch: 6| Step: 13
Training loss: 2.9738539339481664
Validation loss: 2.5706320165481635

Epoch: 259| Step: 0
Training loss: 2.5760923753666365
Validation loss: 2.57179871433309

Epoch: 6| Step: 1
Training loss: 2.5833626919790658
Validation loss: 2.57053333476693

Epoch: 6| Step: 2
Training loss: 2.792391545333489
Validation loss: 2.572340538868821

Epoch: 6| Step: 3
Training loss: 3.248556109781833
Validation loss: 2.565355247367738

Epoch: 6| Step: 4
Training loss: 3.015555109192526
Validation loss: 2.579581814191812

Epoch: 6| Step: 5
Training loss: 2.4790057816647675
Validation loss: 2.581017909061233

Epoch: 6| Step: 6
Training loss: 3.133319309554946
Validation loss: 2.5780552431714567

Epoch: 6| Step: 7
Training loss: 2.649567219644751
Validation loss: 2.570429590598214

Epoch: 6| Step: 8
Training loss: 2.4371136090106873
Validation loss: 2.5609590933173307

Epoch: 6| Step: 9
Training loss: 3.1354479275958385
Validation loss: 2.57463725998025

Epoch: 6| Step: 10
Training loss: 3.278072017099684
Validation loss: 2.57531333185416

Epoch: 6| Step: 11
Training loss: 3.2108745336739792
Validation loss: 2.584536968346318

Epoch: 6| Step: 12
Training loss: 2.4509119633116767
Validation loss: 2.579699765038818

Epoch: 6| Step: 13
Training loss: 3.6208077228256443
Validation loss: 2.605678732840489

Epoch: 260| Step: 0
Training loss: 2.934771630209815
Validation loss: 2.590764978552459

Epoch: 6| Step: 1
Training loss: 2.6415941615538654
Validation loss: 2.582106300516661

Epoch: 6| Step: 2
Training loss: 2.6676312033394027
Validation loss: 2.564161470843261

Epoch: 6| Step: 3
Training loss: 2.8119408793467993
Validation loss: 2.5650020582581874

Epoch: 6| Step: 4
Training loss: 3.0003312245942766
Validation loss: 2.5673716527657087

Epoch: 6| Step: 5
Training loss: 3.0953118591461983
Validation loss: 2.566377878449782

Epoch: 6| Step: 6
Training loss: 2.4975784017573512
Validation loss: 2.5622454501061966

Epoch: 6| Step: 7
Training loss: 2.656122630936401
Validation loss: 2.5576466575725543

Epoch: 6| Step: 8
Training loss: 3.143726999490678
Validation loss: 2.554980422252929

Epoch: 6| Step: 9
Training loss: 2.8892332283438305
Validation loss: 2.55874464862404

Epoch: 6| Step: 10
Training loss: 3.0768733699158095
Validation loss: 2.560391715060073

Epoch: 6| Step: 11
Training loss: 2.7938555396709925
Validation loss: 2.5710537607065205

Epoch: 6| Step: 12
Training loss: 3.2276231255599552
Validation loss: 2.5637152886633867

Epoch: 6| Step: 13
Training loss: 3.0833729578169864
Validation loss: 2.5579135907848793

Epoch: 261| Step: 0
Training loss: 2.4525684284148177
Validation loss: 2.572416524878591

Epoch: 6| Step: 1
Training loss: 3.2254199205592484
Validation loss: 2.578941762250574

Epoch: 6| Step: 2
Training loss: 2.62550648843824
Validation loss: 2.578085993089172

Epoch: 6| Step: 3
Training loss: 2.0673551345868084
Validation loss: 2.5929090270958954

Epoch: 6| Step: 4
Training loss: 2.8748636628041884
Validation loss: 2.579304099032413

Epoch: 6| Step: 5
Training loss: 3.132158853353642
Validation loss: 2.5804614743878647

Epoch: 6| Step: 6
Training loss: 2.9781403452106625
Validation loss: 2.5702710515344003

Epoch: 6| Step: 7
Training loss: 3.056540471102789
Validation loss: 2.5678281916869756

Epoch: 6| Step: 8
Training loss: 3.0105757269807616
Validation loss: 2.5651241804963827

Epoch: 6| Step: 9
Training loss: 3.1144413910399176
Validation loss: 2.5562430355529644

Epoch: 6| Step: 10
Training loss: 2.5687339132506
Validation loss: 2.5550846582526137

Epoch: 6| Step: 11
Training loss: 3.0136259895040487
Validation loss: 2.5470179035744698

Epoch: 6| Step: 12
Training loss: 3.43710102887099
Validation loss: 2.5462458754720587

Epoch: 6| Step: 13
Training loss: 2.5817893141428234
Validation loss: 2.5457708412689257

Epoch: 262| Step: 0
Training loss: 2.897472621995736
Validation loss: 2.5400123640679504

Epoch: 6| Step: 1
Training loss: 3.1646176451647188
Validation loss: 2.543371836594845

Epoch: 6| Step: 2
Training loss: 2.318004963498401
Validation loss: 2.5418807888834216

Epoch: 6| Step: 3
Training loss: 2.721423533649166
Validation loss: 2.541072505357712

Epoch: 6| Step: 4
Training loss: 2.6912583087628104
Validation loss: 2.5386147401342356

Epoch: 6| Step: 5
Training loss: 2.9873631082878553
Validation loss: 2.546330994607528

Epoch: 6| Step: 6
Training loss: 3.308253030899402
Validation loss: 2.550134024776543

Epoch: 6| Step: 7
Training loss: 2.9137669635869683
Validation loss: 2.5502563875278494

Epoch: 6| Step: 8
Training loss: 2.6471373480949105
Validation loss: 2.5547268210212954

Epoch: 6| Step: 9
Training loss: 3.147251710438398
Validation loss: 2.5478870991183302

Epoch: 6| Step: 10
Training loss: 2.628765674930698
Validation loss: 2.5521684128067803

Epoch: 6| Step: 11
Training loss: 3.019140220678586
Validation loss: 2.5580063222652276

Epoch: 6| Step: 12
Training loss: 3.1497824094188744
Validation loss: 2.5666906204538846

Epoch: 6| Step: 13
Training loss: 2.6197344329426806
Validation loss: 2.5602557110936757

Epoch: 263| Step: 0
Training loss: 2.7598529647969623
Validation loss: 2.5547095509147217

Epoch: 6| Step: 1
Training loss: 2.697812366801532
Validation loss: 2.5501883252851862

Epoch: 6| Step: 2
Training loss: 2.526493642950374
Validation loss: 2.550862497253976

Epoch: 6| Step: 3
Training loss: 3.1913310944428677
Validation loss: 2.5605441577193893

Epoch: 6| Step: 4
Training loss: 2.965944108586881
Validation loss: 2.564379731209961

Epoch: 6| Step: 5
Training loss: 2.878100506308642
Validation loss: 2.5568643611476136

Epoch: 6| Step: 6
Training loss: 3.0324040998247233
Validation loss: 2.567138464532906

Epoch: 6| Step: 7
Training loss: 2.7391464020347263
Validation loss: 2.5775140808528643

Epoch: 6| Step: 8
Training loss: 2.9428618174448333
Validation loss: 2.5692717263453027

Epoch: 6| Step: 9
Training loss: 2.862583715555661
Validation loss: 2.5589475220402336

Epoch: 6| Step: 10
Training loss: 2.7820702532653634
Validation loss: 2.567672645044439

Epoch: 6| Step: 11
Training loss: 2.8714989616263304
Validation loss: 2.552470804165839

Epoch: 6| Step: 12
Training loss: 3.1971956780203876
Validation loss: 2.5550200909505203

Epoch: 6| Step: 13
Training loss: 2.9238483476672057
Validation loss: 2.558367827284703

Epoch: 264| Step: 0
Training loss: 2.856869793513496
Validation loss: 2.5529173408456707

Epoch: 6| Step: 1
Training loss: 2.619717323254508
Validation loss: 2.5544243775809465

Epoch: 6| Step: 2
Training loss: 2.8285447962994774
Validation loss: 2.550716573764026

Epoch: 6| Step: 3
Training loss: 2.6664108709993286
Validation loss: 2.5661551925437323

Epoch: 6| Step: 4
Training loss: 3.017224455912818
Validation loss: 2.5784549992911696

Epoch: 6| Step: 5
Training loss: 3.3573889250855506
Validation loss: 2.5720634860972593

Epoch: 6| Step: 6
Training loss: 2.229708620544787
Validation loss: 2.59388338989638

Epoch: 6| Step: 7
Training loss: 2.8885888428841624
Validation loss: 2.6006277298783536

Epoch: 6| Step: 8
Training loss: 2.5486571272860186
Validation loss: 2.588827915639337

Epoch: 6| Step: 9
Training loss: 2.9297890607396444
Validation loss: 2.584170414932019

Epoch: 6| Step: 10
Training loss: 3.4303353290852927
Validation loss: 2.5726812460140795

Epoch: 6| Step: 11
Training loss: 3.128763602787674
Validation loss: 2.563288631584165

Epoch: 6| Step: 12
Training loss: 3.042755785481406
Validation loss: 2.5709370046642213

Epoch: 6| Step: 13
Training loss: 2.271087270648061
Validation loss: 2.5638213483810453

Epoch: 265| Step: 0
Training loss: 2.524155836345535
Validation loss: 2.5605127515933184

Epoch: 6| Step: 1
Training loss: 3.3567427857704226
Validation loss: 2.56074948550072

Epoch: 6| Step: 2
Training loss: 2.9042279171790004
Validation loss: 2.5519241802388692

Epoch: 6| Step: 3
Training loss: 2.4780627017951584
Validation loss: 2.5447950699803408

Epoch: 6| Step: 4
Training loss: 3.5918544911943586
Validation loss: 2.5463135849991505

Epoch: 6| Step: 5
Training loss: 2.398517818535038
Validation loss: 2.5490024623796277

Epoch: 6| Step: 6
Training loss: 2.581845090679459
Validation loss: 2.5497285494529502

Epoch: 6| Step: 7
Training loss: 2.8291241477351856
Validation loss: 2.5485012635836464

Epoch: 6| Step: 8
Training loss: 3.4220332975657084
Validation loss: 2.556795230487769

Epoch: 6| Step: 9
Training loss: 2.601541788287956
Validation loss: 2.561546346317027

Epoch: 6| Step: 10
Training loss: 3.25862239586351
Validation loss: 2.5570629543818097

Epoch: 6| Step: 11
Training loss: 2.6309437444422255
Validation loss: 2.5813481095788258

Epoch: 6| Step: 12
Training loss: 2.8393846479181026
Validation loss: 2.610034024548751

Epoch: 6| Step: 13
Training loss: 2.222338930350206
Validation loss: 2.6266352418360954

Epoch: 266| Step: 0
Training loss: 2.47840932824046
Validation loss: 2.6764501703357193

Epoch: 6| Step: 1
Training loss: 3.0681166234138106
Validation loss: 2.672601525851935

Epoch: 6| Step: 2
Training loss: 2.979327662103695
Validation loss: 2.6580235177059275

Epoch: 6| Step: 3
Training loss: 3.1128039598457917
Validation loss: 2.6054132528849077

Epoch: 6| Step: 4
Training loss: 3.0530733102192684
Validation loss: 2.5703212691632897

Epoch: 6| Step: 5
Training loss: 2.8349715340074955
Validation loss: 2.5671940261226305

Epoch: 6| Step: 6
Training loss: 3.104839601904138
Validation loss: 2.5572950513801573

Epoch: 6| Step: 7
Training loss: 2.796603397416045
Validation loss: 2.556228350134898

Epoch: 6| Step: 8
Training loss: 3.5764092075466167
Validation loss: 2.5545829186318993

Epoch: 6| Step: 9
Training loss: 2.6806066955097987
Validation loss: 2.5546005016951323

Epoch: 6| Step: 10
Training loss: 2.895427940772327
Validation loss: 2.5518047496303016

Epoch: 6| Step: 11
Training loss: 2.336383177429619
Validation loss: 2.5532738653391744

Epoch: 6| Step: 12
Training loss: 2.9131401177181617
Validation loss: 2.5534553548165193

Epoch: 6| Step: 13
Training loss: 2.9158952692007416
Validation loss: 2.5511696910168467

Epoch: 267| Step: 0
Training loss: 3.3590522078749374
Validation loss: 2.5516106873331483

Epoch: 6| Step: 1
Training loss: 2.937820417095059
Validation loss: 2.5524815429323584

Epoch: 6| Step: 2
Training loss: 2.9982603115189788
Validation loss: 2.553681563558217

Epoch: 6| Step: 3
Training loss: 3.1695620367234763
Validation loss: 2.5544386889903485

Epoch: 6| Step: 4
Training loss: 2.7879639072736393
Validation loss: 2.562800087954077

Epoch: 6| Step: 5
Training loss: 1.8213337010699264
Validation loss: 2.5811730716183474

Epoch: 6| Step: 6
Training loss: 2.3124947418977913
Validation loss: 2.6195631646612894

Epoch: 6| Step: 7
Training loss: 2.7551619892994084
Validation loss: 2.696203543039318

Epoch: 6| Step: 8
Training loss: 3.4213126778706298
Validation loss: 2.7380601071780575

Epoch: 6| Step: 9
Training loss: 3.1285764446579147
Validation loss: 2.6816034613115827

Epoch: 6| Step: 10
Training loss: 2.615773653206556
Validation loss: 2.668807801254727

Epoch: 6| Step: 11
Training loss: 3.0886916606091335
Validation loss: 2.61858515611096

Epoch: 6| Step: 12
Training loss: 3.1370951235512425
Validation loss: 2.5963665884606595

Epoch: 6| Step: 13
Training loss: 3.1884895733367773
Validation loss: 2.548516486435769

Epoch: 268| Step: 0
Training loss: 3.020838051277072
Validation loss: 2.534323218922167

Epoch: 6| Step: 1
Training loss: 2.8891937836712325
Validation loss: 2.5323454353760915

Epoch: 6| Step: 2
Training loss: 2.9133555191324274
Validation loss: 2.541971451311132

Epoch: 6| Step: 3
Training loss: 2.9568343506419548
Validation loss: 2.54795871217938

Epoch: 6| Step: 4
Training loss: 2.7206586079676365
Validation loss: 2.5708554335258347

Epoch: 6| Step: 5
Training loss: 3.1994692898787824
Validation loss: 2.575145647864199

Epoch: 6| Step: 6
Training loss: 3.371512695306701
Validation loss: 2.558793111719766

Epoch: 6| Step: 7
Training loss: 3.13737205457266
Validation loss: 2.5446168809028995

Epoch: 6| Step: 8
Training loss: 3.410494618271632
Validation loss: 2.5395643451706995

Epoch: 6| Step: 9
Training loss: 2.5454931898713453
Validation loss: 2.534584799979385

Epoch: 6| Step: 10
Training loss: 2.7631366979890233
Validation loss: 2.5371492230803243

Epoch: 6| Step: 11
Training loss: 2.399782282172917
Validation loss: 2.539122760016606

Epoch: 6| Step: 12
Training loss: 2.5985873052432145
Validation loss: 2.5511624960062997

Epoch: 6| Step: 13
Training loss: 2.794809868338953
Validation loss: 2.5749952474140674

Epoch: 269| Step: 0
Training loss: 3.0084861892654544
Validation loss: 2.5956374574384653

Epoch: 6| Step: 1
Training loss: 2.861689063732353
Validation loss: 2.577038382019142

Epoch: 6| Step: 2
Training loss: 2.992226702480627
Validation loss: 2.573651322527546

Epoch: 6| Step: 3
Training loss: 2.8029921144013223
Validation loss: 2.564903275813511

Epoch: 6| Step: 4
Training loss: 3.1942765251659218
Validation loss: 2.539998000139892

Epoch: 6| Step: 5
Training loss: 3.0166374443985253
Validation loss: 2.5537657020334317

Epoch: 6| Step: 6
Training loss: 2.847689069812587
Validation loss: 2.552922934235816

Epoch: 6| Step: 7
Training loss: 2.580625488990743
Validation loss: 2.556105261291677

Epoch: 6| Step: 8
Training loss: 2.960354790431291
Validation loss: 2.5519589770324465

Epoch: 6| Step: 9
Training loss: 2.5387236853268322
Validation loss: 2.539062649432636

Epoch: 6| Step: 10
Training loss: 3.0574180321299473
Validation loss: 2.5493261059281753

Epoch: 6| Step: 11
Training loss: 3.256031894518252
Validation loss: 2.550121302215815

Epoch: 6| Step: 12
Training loss: 2.415415560586266
Validation loss: 2.553796830749705

Epoch: 6| Step: 13
Training loss: 2.7182923732020616
Validation loss: 2.565341897261784

Epoch: 270| Step: 0
Training loss: 2.1344187071585234
Validation loss: 2.5724729212016153

Epoch: 6| Step: 1
Training loss: 3.226777372063698
Validation loss: 2.6048875223664174

Epoch: 6| Step: 2
Training loss: 2.309280319234535
Validation loss: 2.6292582778437406

Epoch: 6| Step: 3
Training loss: 3.3335924683616005
Validation loss: 2.6313544015932644

Epoch: 6| Step: 4
Training loss: 3.010757233430212
Validation loss: 2.6621933838658545

Epoch: 6| Step: 5
Training loss: 2.786346908670739
Validation loss: 2.6546219509550384

Epoch: 6| Step: 6
Training loss: 2.8697509947362247
Validation loss: 2.621155086176415

Epoch: 6| Step: 7
Training loss: 2.917614773647684
Validation loss: 2.643372074913181

Epoch: 6| Step: 8
Training loss: 2.7298523039217355
Validation loss: 2.6555156196866734

Epoch: 6| Step: 9
Training loss: 2.954757804175403
Validation loss: 2.66652514257767

Epoch: 6| Step: 10
Training loss: 2.9003623472948115
Validation loss: 2.626346628490539

Epoch: 6| Step: 11
Training loss: 2.7980920285516238
Validation loss: 2.590674151925553

Epoch: 6| Step: 12
Training loss: 3.1541653537789505
Validation loss: 2.5654215571609136

Epoch: 6| Step: 13
Training loss: 2.7361235341297285
Validation loss: 2.5388385794497585

Epoch: 271| Step: 0
Training loss: 3.0043373542650667
Validation loss: 2.540021970085604

Epoch: 6| Step: 1
Training loss: 3.1947137322925867
Validation loss: 2.549202699899132

Epoch: 6| Step: 2
Training loss: 1.715106222794597
Validation loss: 2.548720822770714

Epoch: 6| Step: 3
Training loss: 2.4236472259813473
Validation loss: 2.5474726946147688

Epoch: 6| Step: 4
Training loss: 3.3359370711815446
Validation loss: 2.5504301086043997

Epoch: 6| Step: 5
Training loss: 3.0790173161841454
Validation loss: 2.5588544078903674

Epoch: 6| Step: 6
Training loss: 2.631140746976796
Validation loss: 2.555276122100581

Epoch: 6| Step: 7
Training loss: 3.204610489431914
Validation loss: 2.564996621139806

Epoch: 6| Step: 8
Training loss: 3.2410923590466543
Validation loss: 2.5629489884502776

Epoch: 6| Step: 9
Training loss: 2.732217951507492
Validation loss: 2.5668869648424817

Epoch: 6| Step: 10
Training loss: 3.1323523433192753
Validation loss: 2.5734003064241664

Epoch: 6| Step: 11
Training loss: 2.4709715686059375
Validation loss: 2.572474179864944

Epoch: 6| Step: 12
Training loss: 3.2842588162765187
Validation loss: 2.5763301464733064

Epoch: 6| Step: 13
Training loss: 2.774717567436464
Validation loss: 2.5749109264928656

Epoch: 272| Step: 0
Training loss: 2.637884670608423
Validation loss: 2.5769838235644964

Epoch: 6| Step: 1
Training loss: 3.1062388490902717
Validation loss: 2.576839793165225

Epoch: 6| Step: 2
Training loss: 2.902730800445249
Validation loss: 2.5799306374148396

Epoch: 6| Step: 3
Training loss: 2.2766542519621407
Validation loss: 2.594138778408491

Epoch: 6| Step: 4
Training loss: 3.1487658308175632
Validation loss: 2.5820939752646765

Epoch: 6| Step: 5
Training loss: 2.7612135882413944
Validation loss: 2.5932584994448096

Epoch: 6| Step: 6
Training loss: 2.9932806742170226
Validation loss: 2.5815394796128563

Epoch: 6| Step: 7
Training loss: 3.05102006707708
Validation loss: 2.583090538208937

Epoch: 6| Step: 8
Training loss: 2.8143191070733233
Validation loss: 2.585335803550752

Epoch: 6| Step: 9
Training loss: 3.0836698674930445
Validation loss: 2.5858156667308783

Epoch: 6| Step: 10
Training loss: 2.910075961035901
Validation loss: 2.5915232604828766

Epoch: 6| Step: 11
Training loss: 3.2438010739107432
Validation loss: 2.5870433990847657

Epoch: 6| Step: 12
Training loss: 2.7576451237274835
Validation loss: 2.5886262698405105

Epoch: 6| Step: 13
Training loss: 2.3691505878487447
Validation loss: 2.5921825244394476

Epoch: 273| Step: 0
Training loss: 3.1085914122866773
Validation loss: 2.610892599422085

Epoch: 6| Step: 1
Training loss: 2.8705761916589396
Validation loss: 2.595527931098064

Epoch: 6| Step: 2
Training loss: 2.9201947445138363
Validation loss: 2.6078455053411793

Epoch: 6| Step: 3
Training loss: 3.2380558022867896
Validation loss: 2.609862452688889

Epoch: 6| Step: 4
Training loss: 3.2391248830408763
Validation loss: 2.58858635851176

Epoch: 6| Step: 5
Training loss: 3.469596415858829
Validation loss: 2.579272161964225

Epoch: 6| Step: 6
Training loss: 2.1857314453733663
Validation loss: 2.5753898383652793

Epoch: 6| Step: 7
Training loss: 3.0669073970957843
Validation loss: 2.5567987869818136

Epoch: 6| Step: 8
Training loss: 2.498900457816876
Validation loss: 2.5511590833936437

Epoch: 6| Step: 9
Training loss: 2.9199868695734654
Validation loss: 2.548635195006337

Epoch: 6| Step: 10
Training loss: 3.0318613910546555
Validation loss: 2.5293600160907945

Epoch: 6| Step: 11
Training loss: 2.673936907141607
Validation loss: 2.5397896502101682

Epoch: 6| Step: 12
Training loss: 2.413479336419564
Validation loss: 2.536642818122411

Epoch: 6| Step: 13
Training loss: 2.081636831631231
Validation loss: 2.5375615325293546

Epoch: 274| Step: 0
Training loss: 2.5529282604975547
Validation loss: 2.5513076132355823

Epoch: 6| Step: 1
Training loss: 2.6727803798865417
Validation loss: 2.5597816843838825

Epoch: 6| Step: 2
Training loss: 2.319111625666131
Validation loss: 2.564621528097224

Epoch: 6| Step: 3
Training loss: 2.808260116603753
Validation loss: 2.618927576414093

Epoch: 6| Step: 4
Training loss: 3.0703011626599683
Validation loss: 2.695377430275674

Epoch: 6| Step: 5
Training loss: 3.3328900678275653
Validation loss: 2.70779679681444

Epoch: 6| Step: 6
Training loss: 3.103172364886664
Validation loss: 2.682236414594273

Epoch: 6| Step: 7
Training loss: 2.6666501362606136
Validation loss: 2.6463201235055664

Epoch: 6| Step: 8
Training loss: 2.2575062474769503
Validation loss: 2.5910228858174773

Epoch: 6| Step: 9
Training loss: 2.9014722046902057
Validation loss: 2.5443950199612715

Epoch: 6| Step: 10
Training loss: 2.8134208019574176
Validation loss: 2.5247590073356903

Epoch: 6| Step: 11
Training loss: 3.156406512015174
Validation loss: 2.5315736224212944

Epoch: 6| Step: 12
Training loss: 3.060882296801935
Validation loss: 2.5287141786994125

Epoch: 6| Step: 13
Training loss: 3.476620791514473
Validation loss: 2.531423054639406

Epoch: 275| Step: 0
Training loss: 2.8317106499566873
Validation loss: 2.526260040928633

Epoch: 6| Step: 1
Training loss: 3.0572654987278933
Validation loss: 2.537916355475844

Epoch: 6| Step: 2
Training loss: 3.1683019799118086
Validation loss: 2.5349066293340146

Epoch: 6| Step: 3
Training loss: 2.7633588741703554
Validation loss: 2.5354911764602166

Epoch: 6| Step: 4
Training loss: 3.387179122310512
Validation loss: 2.536351978277034

Epoch: 6| Step: 5
Training loss: 2.828298068151727
Validation loss: 2.5414799981953355

Epoch: 6| Step: 6
Training loss: 2.382731351877703
Validation loss: 2.53954970160463

Epoch: 6| Step: 7
Training loss: 2.5631883208483814
Validation loss: 2.5360002527083805

Epoch: 6| Step: 8
Training loss: 2.943252450156385
Validation loss: 2.544552757265006

Epoch: 6| Step: 9
Training loss: 2.5566363352833568
Validation loss: 2.545505448619002

Epoch: 6| Step: 10
Training loss: 2.7992512076367513
Validation loss: 2.547890444674544

Epoch: 6| Step: 11
Training loss: 3.1378278279868033
Validation loss: 2.5550964535916245

Epoch: 6| Step: 12
Training loss: 2.9049702769874712
Validation loss: 2.5554513518424296

Epoch: 6| Step: 13
Training loss: 2.89941587155762
Validation loss: 2.567317127539643

Epoch: 276| Step: 0
Training loss: 3.1297685480312447
Validation loss: 2.577025027774479

Epoch: 6| Step: 1
Training loss: 3.371210301794562
Validation loss: 2.5785854078896007

Epoch: 6| Step: 2
Training loss: 2.097072754586976
Validation loss: 2.5665305878510916

Epoch: 6| Step: 3
Training loss: 2.888999358127268
Validation loss: 2.564650579816931

Epoch: 6| Step: 4
Training loss: 2.9319198851523316
Validation loss: 2.580879371375987

Epoch: 6| Step: 5
Training loss: 3.550925475360949
Validation loss: 2.589230805168481

Epoch: 6| Step: 6
Training loss: 2.8185888713788314
Validation loss: 2.597954734192236

Epoch: 6| Step: 7
Training loss: 2.369100068728764
Validation loss: 2.6102275638245263

Epoch: 6| Step: 8
Training loss: 2.4111508090281193
Validation loss: 2.6107917492667836

Epoch: 6| Step: 9
Training loss: 3.0966518163855343
Validation loss: 2.605522794643128

Epoch: 6| Step: 10
Training loss: 2.9472172494890896
Validation loss: 2.5974174079451458

Epoch: 6| Step: 11
Training loss: 2.2721495240801897
Validation loss: 2.57508750911789

Epoch: 6| Step: 12
Training loss: 3.077486388287164
Validation loss: 2.581404058023505

Epoch: 6| Step: 13
Training loss: 2.9078700974636305
Validation loss: 2.5703692377124794

Epoch: 277| Step: 0
Training loss: 2.9272541978229145
Validation loss: 2.5821934552676202

Epoch: 6| Step: 1
Training loss: 2.5935423434676403
Validation loss: 2.5515734191805173

Epoch: 6| Step: 2
Training loss: 2.7882754286525984
Validation loss: 2.5487836456158157

Epoch: 6| Step: 3
Training loss: 2.8494927406626878
Validation loss: 2.542370741215952

Epoch: 6| Step: 4
Training loss: 3.323508772917512
Validation loss: 2.5325231496325027

Epoch: 6| Step: 5
Training loss: 2.7179787956067503
Validation loss: 2.541077496288802

Epoch: 6| Step: 6
Training loss: 2.436063294163135
Validation loss: 2.5450695349058554

Epoch: 6| Step: 7
Training loss: 2.640162139595228
Validation loss: 2.543710282091179

Epoch: 6| Step: 8
Training loss: 2.927425559096718
Validation loss: 2.553790372945051

Epoch: 6| Step: 9
Training loss: 3.1495471447172965
Validation loss: 2.552800389991546

Epoch: 6| Step: 10
Training loss: 2.6398253725557512
Validation loss: 2.5458012047369243

Epoch: 6| Step: 11
Training loss: 2.086696072494124
Validation loss: 2.5401344942948314

Epoch: 6| Step: 12
Training loss: 4.107817728264907
Validation loss: 2.551540917989363

Epoch: 6| Step: 13
Training loss: 2.049393596745116
Validation loss: 2.5475960742559685

Epoch: 278| Step: 0
Training loss: 2.75384469470767
Validation loss: 2.5533552069755077

Epoch: 6| Step: 1
Training loss: 3.1138822006651345
Validation loss: 2.5529394351674415

Epoch: 6| Step: 2
Training loss: 3.1071342944197906
Validation loss: 2.5796936185343156

Epoch: 6| Step: 3
Training loss: 2.7792257593402905
Validation loss: 2.578699290977358

Epoch: 6| Step: 4
Training loss: 3.021888355750282
Validation loss: 2.590147202436162

Epoch: 6| Step: 5
Training loss: 2.9079650412534783
Validation loss: 2.5835698856678113

Epoch: 6| Step: 6
Training loss: 2.221856105632897
Validation loss: 2.5659695618996183

Epoch: 6| Step: 7
Training loss: 2.7893727875259926
Validation loss: 2.549794940879037

Epoch: 6| Step: 8
Training loss: 2.5886631917282594
Validation loss: 2.556719520209066

Epoch: 6| Step: 9
Training loss: 3.3219590356771103
Validation loss: 2.538001203459918

Epoch: 6| Step: 10
Training loss: 2.8371387806329267
Validation loss: 2.543650781831498

Epoch: 6| Step: 11
Training loss: 3.476984371348758
Validation loss: 2.547440535094763

Epoch: 6| Step: 12
Training loss: 2.081157909108596
Validation loss: 2.5290328605409216

Epoch: 6| Step: 13
Training loss: 2.7382301401981715
Validation loss: 2.5688345084208932

Epoch: 279| Step: 0
Training loss: 2.706247631891285
Validation loss: 2.569593054403717

Epoch: 6| Step: 1
Training loss: 3.1272375107348918
Validation loss: 2.5952964809928165

Epoch: 6| Step: 2
Training loss: 2.360303077310254
Validation loss: 2.6013770820328963

Epoch: 6| Step: 3
Training loss: 2.3963795136109796
Validation loss: 2.637411059814403

Epoch: 6| Step: 4
Training loss: 3.3693727275123924
Validation loss: 2.645352695312028

Epoch: 6| Step: 5
Training loss: 3.06975117373978
Validation loss: 2.6607751105220943

Epoch: 6| Step: 6
Training loss: 3.155218276802348
Validation loss: 2.6762045507277126

Epoch: 6| Step: 7
Training loss: 2.757811635479238
Validation loss: 2.609203210895872

Epoch: 6| Step: 8
Training loss: 2.7876020609556416
Validation loss: 2.5876804900959804

Epoch: 6| Step: 9
Training loss: 2.665690531489744
Validation loss: 2.5727436651348246

Epoch: 6| Step: 10
Training loss: 2.8773200583848486
Validation loss: 2.552543730871636

Epoch: 6| Step: 11
Training loss: 2.359752599550471
Validation loss: 2.5369572683271056

Epoch: 6| Step: 12
Training loss: 3.3062578803330887
Validation loss: 2.539389467855411

Epoch: 6| Step: 13
Training loss: 2.949253026497835
Validation loss: 2.5246877496102815

Epoch: 280| Step: 0
Training loss: 2.5636610796688184
Validation loss: 2.536610147862229

Epoch: 6| Step: 1
Training loss: 2.7543061960246833
Validation loss: 2.529449532528364

Epoch: 6| Step: 2
Training loss: 3.039666829172738
Validation loss: 2.537727521710958

Epoch: 6| Step: 3
Training loss: 2.791199963023349
Validation loss: 2.538263020570723

Epoch: 6| Step: 4
Training loss: 2.5743515605558667
Validation loss: 2.5376113669952027

Epoch: 6| Step: 5
Training loss: 2.988349863897736
Validation loss: 2.536278313595421

Epoch: 6| Step: 6
Training loss: 2.9949641877391193
Validation loss: 2.5484868635047047

Epoch: 6| Step: 7
Training loss: 2.8458581174010487
Validation loss: 2.5743659762862205

Epoch: 6| Step: 8
Training loss: 2.797142229153885
Validation loss: 2.577477406060523

Epoch: 6| Step: 9
Training loss: 2.71401705882278
Validation loss: 2.609953460229707

Epoch: 6| Step: 10
Training loss: 3.3915856753964935
Validation loss: 2.62607941064403

Epoch: 6| Step: 11
Training loss: 2.9804511513446683
Validation loss: 2.5991053491055163

Epoch: 6| Step: 12
Training loss: 2.5232846240335784
Validation loss: 2.5875159165579107

Epoch: 6| Step: 13
Training loss: 3.3020271432871175
Validation loss: 2.5670058490433063

Epoch: 281| Step: 0
Training loss: 2.35115955233573
Validation loss: 2.5489349922429607

Epoch: 6| Step: 1
Training loss: 2.4164212749025187
Validation loss: 2.534423211472175

Epoch: 6| Step: 2
Training loss: 3.176191728065643
Validation loss: 2.5326609444840478

Epoch: 6| Step: 3
Training loss: 3.377455771585125
Validation loss: 2.530005755495977

Epoch: 6| Step: 4
Training loss: 3.459650700307713
Validation loss: 2.5264236152976363

Epoch: 6| Step: 5
Training loss: 2.8067609088264724
Validation loss: 2.529442203774795

Epoch: 6| Step: 6
Training loss: 3.3346360680895906
Validation loss: 2.5293401802724578

Epoch: 6| Step: 7
Training loss: 2.80406594362412
Validation loss: 2.529486073107196

Epoch: 6| Step: 8
Training loss: 2.59867042878402
Validation loss: 2.5343778581864758

Epoch: 6| Step: 9
Training loss: 2.1603990525275902
Validation loss: 2.5330800336094037

Epoch: 6| Step: 10
Training loss: 3.0028056694411203
Validation loss: 2.535604354689139

Epoch: 6| Step: 11
Training loss: 2.8843077216769357
Validation loss: 2.5315835475494404

Epoch: 6| Step: 12
Training loss: 2.8043514464791808
Validation loss: 2.532502051455888

Epoch: 6| Step: 13
Training loss: 2.517396291435809
Validation loss: 2.5429891857015843

Epoch: 282| Step: 0
Training loss: 3.0317652942733786
Validation loss: 2.5447095801107813

Epoch: 6| Step: 1
Training loss: 3.2631287593706646
Validation loss: 2.5407470920402813

Epoch: 6| Step: 2
Training loss: 2.4973183554576814
Validation loss: 2.5569455173770743

Epoch: 6| Step: 3
Training loss: 2.4905376653543763
Validation loss: 2.554502862532028

Epoch: 6| Step: 4
Training loss: 2.740166857017447
Validation loss: 2.569562310602227

Epoch: 6| Step: 5
Training loss: 2.42939467060751
Validation loss: 2.5776006598583394

Epoch: 6| Step: 6
Training loss: 3.276258759616056
Validation loss: 2.586695210952473

Epoch: 6| Step: 7
Training loss: 3.2532613969364457
Validation loss: 2.5822963247472406

Epoch: 6| Step: 8
Training loss: 3.395807901923001
Validation loss: 2.6004849518419895

Epoch: 6| Step: 9
Training loss: 2.580920743840525
Validation loss: 2.5825870436929326

Epoch: 6| Step: 10
Training loss: 3.0831787139339917
Validation loss: 2.612902934532549

Epoch: 6| Step: 11
Training loss: 2.6420820380966057
Validation loss: 2.60639184370195

Epoch: 6| Step: 12
Training loss: 2.514914370798726
Validation loss: 2.5743469956241483

Epoch: 6| Step: 13
Training loss: 2.4456046907910904
Validation loss: 2.5767681161991725

Epoch: 283| Step: 0
Training loss: 2.6299844375846133
Validation loss: 2.561753056849281

Epoch: 6| Step: 1
Training loss: 3.221265236015836
Validation loss: 2.555838499312316

Epoch: 6| Step: 2
Training loss: 3.0925999825550683
Validation loss: 2.556742751822686

Epoch: 6| Step: 3
Training loss: 2.9306144366945475
Validation loss: 2.5562959276318664

Epoch: 6| Step: 4
Training loss: 2.795498130779975
Validation loss: 2.544212164719716

Epoch: 6| Step: 5
Training loss: 2.259561778430055
Validation loss: 2.5424497162357755

Epoch: 6| Step: 6
Training loss: 2.0719040996642595
Validation loss: 2.539651570862103

Epoch: 6| Step: 7
Training loss: 2.9110301094660245
Validation loss: 2.5290461357142777

Epoch: 6| Step: 8
Training loss: 3.205872190349218
Validation loss: 2.5315318900772503

Epoch: 6| Step: 9
Training loss: 2.2879126463200388
Validation loss: 2.537079628984245

Epoch: 6| Step: 10
Training loss: 3.306957574425147
Validation loss: 2.5352091633697302

Epoch: 6| Step: 11
Training loss: 3.5974203191844096
Validation loss: 2.534878866004465

Epoch: 6| Step: 12
Training loss: 2.4192916381948764
Validation loss: 2.5349600090734334

Epoch: 6| Step: 13
Training loss: 2.7617029516046094
Validation loss: 2.5447282876875383

Epoch: 284| Step: 0
Training loss: 2.7241434553465824
Validation loss: 2.5599995220315908

Epoch: 6| Step: 1
Training loss: 3.051127122329348
Validation loss: 2.5799987974034493

Epoch: 6| Step: 2
Training loss: 3.1253207232879454
Validation loss: 2.6014751791792183

Epoch: 6| Step: 3
Training loss: 3.5520390631787335
Validation loss: 2.631286567408756

Epoch: 6| Step: 4
Training loss: 2.544660295699175
Validation loss: 2.6067476461583863

Epoch: 6| Step: 5
Training loss: 2.238665110109086
Validation loss: 2.5682208003208493

Epoch: 6| Step: 6
Training loss: 3.276542411018605
Validation loss: 2.5558133020034663

Epoch: 6| Step: 7
Training loss: 2.8172670443069445
Validation loss: 2.533727994928971

Epoch: 6| Step: 8
Training loss: 2.4248353646619667
Validation loss: 2.5363418266985187

Epoch: 6| Step: 9
Training loss: 2.5420776305931647
Validation loss: 2.5306133693638238

Epoch: 6| Step: 10
Training loss: 2.856510082064824
Validation loss: 2.5229074245300636

Epoch: 6| Step: 11
Training loss: 2.8780355599057548
Validation loss: 2.529835828426792

Epoch: 6| Step: 12
Training loss: 2.759087200427966
Validation loss: 2.525198850514967

Epoch: 6| Step: 13
Training loss: 2.928781761033035
Validation loss: 2.5365758964942025

Epoch: 285| Step: 0
Training loss: 2.908637921871142
Validation loss: 2.5336032827498878

Epoch: 6| Step: 1
Training loss: 3.0372472210478185
Validation loss: 2.539029833612691

Epoch: 6| Step: 2
Training loss: 2.92222258596414
Validation loss: 2.535289410071551

Epoch: 6| Step: 3
Training loss: 3.2137691143213782
Validation loss: 2.552513652498765

Epoch: 6| Step: 4
Training loss: 3.0939982921494527
Validation loss: 2.5434740758861683

Epoch: 6| Step: 5
Training loss: 2.7669490080320087
Validation loss: 2.5609504042138913

Epoch: 6| Step: 6
Training loss: 2.953128390840067
Validation loss: 2.5826814318859492

Epoch: 6| Step: 7
Training loss: 2.652477232954883
Validation loss: 2.576043463467752

Epoch: 6| Step: 8
Training loss: 2.3363663397774372
Validation loss: 2.5715766075054094

Epoch: 6| Step: 9
Training loss: 2.6381154070085335
Validation loss: 2.5710171154096098

Epoch: 6| Step: 10
Training loss: 2.1287308646936363
Validation loss: 2.56785942148472

Epoch: 6| Step: 11
Training loss: 3.753857472367799
Validation loss: 2.584389776884055

Epoch: 6| Step: 12
Training loss: 2.307415501792557
Validation loss: 2.5806819940061203

Epoch: 6| Step: 13
Training loss: 2.399057314430984
Validation loss: 2.560836387031185

Epoch: 286| Step: 0
Training loss: 2.567041420103473
Validation loss: 2.557922314257839

Epoch: 6| Step: 1
Training loss: 3.053737326746785
Validation loss: 2.560084909384403

Epoch: 6| Step: 2
Training loss: 3.293711948355939
Validation loss: 2.564828315636873

Epoch: 6| Step: 3
Training loss: 2.294303648443729
Validation loss: 2.5660271779112036

Epoch: 6| Step: 4
Training loss: 2.322617641298739
Validation loss: 2.584244866637454

Epoch: 6| Step: 5
Training loss: 2.998243771527088
Validation loss: 2.5773485453236584

Epoch: 6| Step: 6
Training loss: 2.895767997901154
Validation loss: 2.56675162215388

Epoch: 6| Step: 7
Training loss: 2.628414113656494
Validation loss: 2.5334593604183335

Epoch: 6| Step: 8
Training loss: 3.0631717801447724
Validation loss: 2.523985540823949

Epoch: 6| Step: 9
Training loss: 2.596952368803664
Validation loss: 2.5289235566670394

Epoch: 6| Step: 10
Training loss: 2.171766978260174
Validation loss: 2.5303035259411017

Epoch: 6| Step: 11
Training loss: 3.44838475548698
Validation loss: 2.528338814340643

Epoch: 6| Step: 12
Training loss: 2.816134329908095
Validation loss: 2.5257185060812373

Epoch: 6| Step: 13
Training loss: 3.474100471269168
Validation loss: 2.536785657389991

Epoch: 287| Step: 0
Training loss: 2.5960904328298944
Validation loss: 2.537162558850991

Epoch: 6| Step: 1
Training loss: 3.0344361539702844
Validation loss: 2.53196661297833

Epoch: 6| Step: 2
Training loss: 2.945022366346519
Validation loss: 2.5296353419221558

Epoch: 6| Step: 3
Training loss: 2.5108729431930903
Validation loss: 2.558508268292145

Epoch: 6| Step: 4
Training loss: 3.5200632520974806
Validation loss: 2.6026750436355433

Epoch: 6| Step: 5
Training loss: 3.2011316563405487
Validation loss: 2.66334923259006

Epoch: 6| Step: 6
Training loss: 2.658644191858664
Validation loss: 2.6917488211963536

Epoch: 6| Step: 7
Training loss: 3.4138895859565435
Validation loss: 2.7134512133828825

Epoch: 6| Step: 8
Training loss: 3.0411341649584194
Validation loss: 2.676544216247693

Epoch: 6| Step: 9
Training loss: 2.3649766121609144
Validation loss: 2.607078799013503

Epoch: 6| Step: 10
Training loss: 2.1642346916137636
Validation loss: 2.5955801164703334

Epoch: 6| Step: 11
Training loss: 2.3634869446576467
Validation loss: 2.5360009896537923

Epoch: 6| Step: 12
Training loss: 3.2526577572751045
Validation loss: 2.5246866285766445

Epoch: 6| Step: 13
Training loss: 1.5249851288617577
Validation loss: 2.513628317639164

Epoch: 288| Step: 0
Training loss: 3.2877665886647924
Validation loss: 2.517322323087413

Epoch: 6| Step: 1
Training loss: 2.8499707939926906
Validation loss: 2.5144039077770994

Epoch: 6| Step: 2
Training loss: 2.821546205479283
Validation loss: 2.513320313493909

Epoch: 6| Step: 3
Training loss: 2.417439983770906
Validation loss: 2.5186899802819958

Epoch: 6| Step: 4
Training loss: 3.3688762350971495
Validation loss: 2.5239327496927455

Epoch: 6| Step: 5
Training loss: 2.8113500151392197
Validation loss: 2.533314664860426

Epoch: 6| Step: 6
Training loss: 2.681873730934997
Validation loss: 2.538562469341305

Epoch: 6| Step: 7
Training loss: 2.50688986280016
Validation loss: 2.5305284114470985

Epoch: 6| Step: 8
Training loss: 2.7633836360014254
Validation loss: 2.5476974990171595

Epoch: 6| Step: 9
Training loss: 2.2276176228063695
Validation loss: 2.5313546885631064

Epoch: 6| Step: 10
Training loss: 3.0723550229364593
Validation loss: 2.5382808025336496

Epoch: 6| Step: 11
Training loss: 2.659151175882313
Validation loss: 2.545459445782315

Epoch: 6| Step: 12
Training loss: 2.6953328449752987
Validation loss: 2.52626007695392

Epoch: 6| Step: 13
Training loss: 3.6158870724033316
Validation loss: 2.5523593702241683

Epoch: 289| Step: 0
Training loss: 3.12172237172063
Validation loss: 2.5564451427836548

Epoch: 6| Step: 1
Training loss: 2.3352347755438165
Validation loss: 2.5585273975171763

Epoch: 6| Step: 2
Training loss: 2.8019385507231966
Validation loss: 2.57645360042829

Epoch: 6| Step: 3
Training loss: 2.2478553299288526
Validation loss: 2.5745489074421233

Epoch: 6| Step: 4
Training loss: 2.668377287878134
Validation loss: 2.5589713094762025

Epoch: 6| Step: 5
Training loss: 2.9781222524560222
Validation loss: 2.5358659916311366

Epoch: 6| Step: 6
Training loss: 3.144354735923138
Validation loss: 2.5417840847474475

Epoch: 6| Step: 7
Training loss: 3.3445869895604905
Validation loss: 2.5293601843406

Epoch: 6| Step: 8
Training loss: 2.837727299799497
Validation loss: 2.5246707005032727

Epoch: 6| Step: 9
Training loss: 3.2400857386606408
Validation loss: 2.516792101533057

Epoch: 6| Step: 10
Training loss: 2.8051221080455915
Validation loss: 2.52504907729081

Epoch: 6| Step: 11
Training loss: 2.857313069314285
Validation loss: 2.525443204963953

Epoch: 6| Step: 12
Training loss: 2.4774512011113234
Validation loss: 2.5260179419376523

Epoch: 6| Step: 13
Training loss: 2.6069565947225852
Validation loss: 2.5462511542843083

Epoch: 290| Step: 0
Training loss: 3.0809926264054646
Validation loss: 2.5939882279986772

Epoch: 6| Step: 1
Training loss: 3.5000245229679394
Validation loss: 2.620492333648183

Epoch: 6| Step: 2
Training loss: 3.005154314442651
Validation loss: 2.60613553803656

Epoch: 6| Step: 3
Training loss: 2.862241215231505
Validation loss: 2.5758440693770663

Epoch: 6| Step: 4
Training loss: 2.9627959928444016
Validation loss: 2.57145012990789

Epoch: 6| Step: 5
Training loss: 2.8989532094168378
Validation loss: 2.544669069643517

Epoch: 6| Step: 6
Training loss: 2.5702872695380217
Validation loss: 2.5247144186912562

Epoch: 6| Step: 7
Training loss: 2.7612158332254704
Validation loss: 2.5191851751604406

Epoch: 6| Step: 8
Training loss: 2.4122607967401155
Validation loss: 2.5109683001624528

Epoch: 6| Step: 9
Training loss: 2.4488624423091916
Validation loss: 2.517813588911766

Epoch: 6| Step: 10
Training loss: 2.7527596758484556
Validation loss: 2.52878343935524

Epoch: 6| Step: 11
Training loss: 2.8612184679286234
Validation loss: 2.5353874059318926

Epoch: 6| Step: 12
Training loss: 2.8244098688359194
Validation loss: 2.5690368365250396

Epoch: 6| Step: 13
Training loss: 2.4112295175397307
Validation loss: 2.596902193289112

Epoch: 291| Step: 0
Training loss: 2.69936961126441
Validation loss: 2.664840569704414

Epoch: 6| Step: 1
Training loss: 2.5220311264246975
Validation loss: 2.7060328173273476

Epoch: 6| Step: 2
Training loss: 3.0759985690268574
Validation loss: 2.705395778214528

Epoch: 6| Step: 3
Training loss: 2.875969433087513
Validation loss: 2.692209900070834

Epoch: 6| Step: 4
Training loss: 2.5822985535273726
Validation loss: 2.6371639603533956

Epoch: 6| Step: 5
Training loss: 2.6693227077498762
Validation loss: 2.61200974917149

Epoch: 6| Step: 6
Training loss: 3.0240903637418266
Validation loss: 2.570802533854447

Epoch: 6| Step: 7
Training loss: 3.1153485603093722
Validation loss: 2.553275059166458

Epoch: 6| Step: 8
Training loss: 2.925148502068788
Validation loss: 2.51653211224828

Epoch: 6| Step: 9
Training loss: 2.7389810187694255
Validation loss: 2.5170731643294886

Epoch: 6| Step: 10
Training loss: 2.9570628558829415
Validation loss: 2.521384300430119

Epoch: 6| Step: 11
Training loss: 3.1482236425119936
Validation loss: 2.5179110696006783

Epoch: 6| Step: 12
Training loss: 2.794043956883214
Validation loss: 2.5149878758306414

Epoch: 6| Step: 13
Training loss: 2.752294363574403
Validation loss: 2.5180248445647044

Epoch: 292| Step: 0
Training loss: 2.9496384479927285
Validation loss: 2.5105964522400175

Epoch: 6| Step: 1
Training loss: 2.147557525752457
Validation loss: 2.5177236679280637

Epoch: 6| Step: 2
Training loss: 3.056640625
Validation loss: 2.5217756064397863

Epoch: 6| Step: 3
Training loss: 2.81095428376968
Validation loss: 2.5305567097950443

Epoch: 6| Step: 4
Training loss: 2.3765723394407177
Validation loss: 2.5296762258998005

Epoch: 6| Step: 5
Training loss: 2.7755345972289804
Validation loss: 2.5328969738581653

Epoch: 6| Step: 6
Training loss: 2.897915446109547
Validation loss: 2.548813778064409

Epoch: 6| Step: 7
Training loss: 2.5312085560361064
Validation loss: 2.547548420572185

Epoch: 6| Step: 8
Training loss: 3.356129342579564
Validation loss: 2.5817718020556297

Epoch: 6| Step: 9
Training loss: 2.6987268907865958
Validation loss: 2.575242591969032

Epoch: 6| Step: 10
Training loss: 3.056579160224666
Validation loss: 2.5980436741955226

Epoch: 6| Step: 11
Training loss: 2.6173184945645698
Validation loss: 2.5976987546752075

Epoch: 6| Step: 12
Training loss: 3.0968824769515884
Validation loss: 2.5840061600325743

Epoch: 6| Step: 13
Training loss: 3.2532033538909886
Validation loss: 2.5445513387025454

Epoch: 293| Step: 0
Training loss: 3.10087827731084
Validation loss: 2.5530920546920335

Epoch: 6| Step: 1
Training loss: 2.2429731634050754
Validation loss: 2.5511531173398803

Epoch: 6| Step: 2
Training loss: 3.0329141669549786
Validation loss: 2.544020497007009

Epoch: 6| Step: 3
Training loss: 2.294269978887173
Validation loss: 2.5547535167035638

Epoch: 6| Step: 4
Training loss: 2.5811481668183687
Validation loss: 2.5632416587041584

Epoch: 6| Step: 5
Training loss: 2.6220368509270857
Validation loss: 2.5644270721245053

Epoch: 6| Step: 6
Training loss: 3.1282523968618134
Validation loss: 2.572949033681976

Epoch: 6| Step: 7
Training loss: 3.1153239174533263
Validation loss: 2.5923217357722748

Epoch: 6| Step: 8
Training loss: 2.6234136056635475
Validation loss: 2.6001670026507946

Epoch: 6| Step: 9
Training loss: 3.2708756429928405
Validation loss: 2.59272440522602

Epoch: 6| Step: 10
Training loss: 3.1348470041520238
Validation loss: 2.5879262259958664

Epoch: 6| Step: 11
Training loss: 2.771700978971847
Validation loss: 2.558074897060257

Epoch: 6| Step: 12
Training loss: 2.8655768503784373
Validation loss: 2.544444439484341

Epoch: 6| Step: 13
Training loss: 2.1743067020085767
Validation loss: 2.5281725565479927

Epoch: 294| Step: 0
Training loss: 3.1287532392752535
Validation loss: 2.5351034275502196

Epoch: 6| Step: 1
Training loss: 2.5905879405722043
Validation loss: 2.5323385472816144

Epoch: 6| Step: 2
Training loss: 2.100203744904547
Validation loss: 2.5260948646626216

Epoch: 6| Step: 3
Training loss: 3.293824434253672
Validation loss: 2.535773109659434

Epoch: 6| Step: 4
Training loss: 2.675235709385071
Validation loss: 2.54552797889914

Epoch: 6| Step: 5
Training loss: 2.9503771395370677
Validation loss: 2.55158535031334

Epoch: 6| Step: 6
Training loss: 2.7189325731734098
Validation loss: 2.5908506932240347

Epoch: 6| Step: 7
Training loss: 2.8925794437876804
Validation loss: 2.557739946992617

Epoch: 6| Step: 8
Training loss: 2.2055698113523916
Validation loss: 2.548212479930044

Epoch: 6| Step: 9
Training loss: 3.437465875629628
Validation loss: 2.535664864719964

Epoch: 6| Step: 10
Training loss: 3.0033463252637214
Validation loss: 2.530864243083539

Epoch: 6| Step: 11
Training loss: 2.6205151710995476
Validation loss: 2.539315325421096

Epoch: 6| Step: 12
Training loss: 2.6855038171264134
Validation loss: 2.547558637685613

Epoch: 6| Step: 13
Training loss: 3.4850794332419253
Validation loss: 2.5480711977919497

Epoch: 295| Step: 0
Training loss: 3.019343006341182
Validation loss: 2.5373422777441164

Epoch: 6| Step: 1
Training loss: 3.0287545540807272
Validation loss: 2.5247700721267097

Epoch: 6| Step: 2
Training loss: 2.662901146985318
Validation loss: 2.5192885547561197

Epoch: 6| Step: 3
Training loss: 2.7090886652205777
Validation loss: 2.5211484317705386

Epoch: 6| Step: 4
Training loss: 3.0305310212690486
Validation loss: 2.521394633732498

Epoch: 6| Step: 5
Training loss: 2.7546538075568234
Validation loss: 2.5193913857133707

Epoch: 6| Step: 6
Training loss: 2.847174960935613
Validation loss: 2.5219253738117

Epoch: 6| Step: 7
Training loss: 2.928100481612597
Validation loss: 2.527091046686842

Epoch: 6| Step: 8
Training loss: 2.162344681117813
Validation loss: 2.517968642932565

Epoch: 6| Step: 9
Training loss: 2.8942436044448847
Validation loss: 2.533129154700642

Epoch: 6| Step: 10
Training loss: 2.8698707934281082
Validation loss: 2.5705349524171455

Epoch: 6| Step: 11
Training loss: 3.0470814170363645
Validation loss: 2.599723417410105

Epoch: 6| Step: 12
Training loss: 2.3922199588419817
Validation loss: 2.626317113255715

Epoch: 6| Step: 13
Training loss: 2.9522884738226405
Validation loss: 2.647766430943141

Epoch: 296| Step: 0
Training loss: 2.9317292689900327
Validation loss: 2.6295408146073087

Epoch: 6| Step: 1
Training loss: 2.840098961193958
Validation loss: 2.6156074908235007

Epoch: 6| Step: 2
Training loss: 2.887438032798195
Validation loss: 2.5763636066338127

Epoch: 6| Step: 3
Training loss: 3.0626024501557816
Validation loss: 2.5500408330998288

Epoch: 6| Step: 4
Training loss: 2.583765506485618
Validation loss: 2.5758478842148493

Epoch: 6| Step: 5
Training loss: 2.512896082389049
Validation loss: 2.550010951406925

Epoch: 6| Step: 6
Training loss: 2.8617308870225324
Validation loss: 2.544894108105986

Epoch: 6| Step: 7
Training loss: 2.753309166211832
Validation loss: 2.538920723843331

Epoch: 6| Step: 8
Training loss: 3.2151940712264033
Validation loss: 2.535051360435538

Epoch: 6| Step: 9
Training loss: 2.8392015909103963
Validation loss: 2.5157751304684783

Epoch: 6| Step: 10
Training loss: 2.48676573684697
Validation loss: 2.511959768053451

Epoch: 6| Step: 11
Training loss: 2.649678437498323
Validation loss: 2.510293747109427

Epoch: 6| Step: 12
Training loss: 2.8126269841667573
Validation loss: 2.505893934699553

Epoch: 6| Step: 13
Training loss: 2.6588235393158786
Validation loss: 2.499269017645991

Epoch: 297| Step: 0
Training loss: 2.3971200114011935
Validation loss: 2.524863788362885

Epoch: 6| Step: 1
Training loss: 2.6445493711586026
Validation loss: 2.5193737736633084

Epoch: 6| Step: 2
Training loss: 2.357961269005573
Validation loss: 2.539503211306454

Epoch: 6| Step: 3
Training loss: 2.6853662936445897
Validation loss: 2.550555376051312

Epoch: 6| Step: 4
Training loss: 2.8454581360097673
Validation loss: 2.5567166514626445

Epoch: 6| Step: 5
Training loss: 3.114930982973222
Validation loss: 2.587542866926463

Epoch: 6| Step: 6
Training loss: 2.815228812639763
Validation loss: 2.572681454279628

Epoch: 6| Step: 7
Training loss: 2.4816311252867918
Validation loss: 2.5738434710115237

Epoch: 6| Step: 8
Training loss: 2.682785867637721
Validation loss: 2.5638015896977064

Epoch: 6| Step: 9
Training loss: 3.3422090776700166
Validation loss: 2.560419484101586

Epoch: 6| Step: 10
Training loss: 3.007185912819128
Validation loss: 2.533891588524555

Epoch: 6| Step: 11
Training loss: 2.8739867705463418
Validation loss: 2.552802676659605

Epoch: 6| Step: 12
Training loss: 3.136235600146141
Validation loss: 2.5651279403178666

Epoch: 6| Step: 13
Training loss: 2.9374003291975246
Validation loss: 2.566486053666975

Epoch: 298| Step: 0
Training loss: 3.186144372230072
Validation loss: 2.552280641570948

Epoch: 6| Step: 1
Training loss: 2.3525437243753102
Validation loss: 2.5325470465824513

Epoch: 6| Step: 2
Training loss: 3.1278889844272553
Validation loss: 2.521853877434006

Epoch: 6| Step: 3
Training loss: 2.7889800927732957
Validation loss: 2.5201189402969915

Epoch: 6| Step: 4
Training loss: 2.8785683421943613
Validation loss: 2.5114284041300694

Epoch: 6| Step: 5
Training loss: 2.724965324531206
Validation loss: 2.5092454333758343

Epoch: 6| Step: 6
Training loss: 2.7726895895442465
Validation loss: 2.5151465349531423

Epoch: 6| Step: 7
Training loss: 3.058020916884086
Validation loss: 2.5075955237487424

Epoch: 6| Step: 8
Training loss: 2.581754776411753
Validation loss: 2.515022884995358

Epoch: 6| Step: 9
Training loss: 2.5640116629015393
Validation loss: 2.518524466840568

Epoch: 6| Step: 10
Training loss: 2.668238881679414
Validation loss: 2.5200859581629875

Epoch: 6| Step: 11
Training loss: 3.315022929300724
Validation loss: 2.5303022148921275

Epoch: 6| Step: 12
Training loss: 2.250513018296055
Validation loss: 2.536929769966008

Epoch: 6| Step: 13
Training loss: 2.4649279983559067
Validation loss: 2.5520906405985735

Epoch: 299| Step: 0
Training loss: 2.7350182348895267
Validation loss: 2.586386164549523

Epoch: 6| Step: 1
Training loss: 2.8271101505935117
Validation loss: 2.6327093861331026

Epoch: 6| Step: 2
Training loss: 2.7633266058066472
Validation loss: 2.593599866882551

Epoch: 6| Step: 3
Training loss: 2.3272334702388586
Validation loss: 2.5342171568175833

Epoch: 6| Step: 4
Training loss: 3.071580464862352
Validation loss: 2.539544110053851

Epoch: 6| Step: 5
Training loss: 3.2821396847695796
Validation loss: 2.5117090985083967

Epoch: 6| Step: 6
Training loss: 3.002976847952848
Validation loss: 2.514266381794028

Epoch: 6| Step: 7
Training loss: 2.3425715217541794
Validation loss: 2.5074078428876567

Epoch: 6| Step: 8
Training loss: 2.6048208000064963
Validation loss: 2.4997144023236486

Epoch: 6| Step: 9
Training loss: 2.5325394160224386
Validation loss: 2.4988822602039913

Epoch: 6| Step: 10
Training loss: 3.713378232094367
Validation loss: 2.504434009801026

Epoch: 6| Step: 11
Training loss: 2.7568678494267513
Validation loss: 2.50291472614856

Epoch: 6| Step: 12
Training loss: 2.7193997363098874
Validation loss: 2.514031307622191

Epoch: 6| Step: 13
Training loss: 2.6762193307272946
Validation loss: 2.5342278181580102

Epoch: 300| Step: 0
Training loss: 2.7333571801269607
Validation loss: 2.556816558348471

Epoch: 6| Step: 1
Training loss: 2.8580509309495112
Validation loss: 2.5764530342579226

Epoch: 6| Step: 2
Training loss: 2.845893638794767
Validation loss: 2.5909652458223915

Epoch: 6| Step: 3
Training loss: 3.233137253259299
Validation loss: 2.6383048729470553

Epoch: 6| Step: 4
Training loss: 2.751101706640589
Validation loss: 2.6274319725081385

Epoch: 6| Step: 5
Training loss: 3.040930637159396
Validation loss: 2.605215391257488

Epoch: 6| Step: 6
Training loss: 2.842833151103351
Validation loss: 2.56307621061693

Epoch: 6| Step: 7
Training loss: 3.359712237796681
Validation loss: 2.5576392813157187

Epoch: 6| Step: 8
Training loss: 2.5890209795535375
Validation loss: 2.538595643645907

Epoch: 6| Step: 9
Training loss: 2.804458991387644
Validation loss: 2.5316663445488965

Epoch: 6| Step: 10
Training loss: 2.753476632878888
Validation loss: 2.5347192462434114

Epoch: 6| Step: 11
Training loss: 2.703257298401746
Validation loss: 2.5130075370942224

Epoch: 6| Step: 12
Training loss: 2.2762729227586656
Validation loss: 2.515816603471751

Epoch: 6| Step: 13
Training loss: 2.4007978225865925
Validation loss: 2.5120832789554743

Epoch: 301| Step: 0
Training loss: 3.1086362028135217
Validation loss: 2.5264979097728135

Epoch: 6| Step: 1
Training loss: 2.620287070381273
Validation loss: 2.537737187392824

Epoch: 6| Step: 2
Training loss: 2.440354754032906
Validation loss: 2.5714263208257844

Epoch: 6| Step: 3
Training loss: 2.766515211379638
Validation loss: 2.6268274301195893

Epoch: 6| Step: 4
Training loss: 3.3070926796632603
Validation loss: 2.669146095240583

Epoch: 6| Step: 5
Training loss: 2.2891781097485304
Validation loss: 2.679217122173347

Epoch: 6| Step: 6
Training loss: 3.076235583417671
Validation loss: 2.665958234170844

Epoch: 6| Step: 7
Training loss: 2.8060539126121293
Validation loss: 2.6484182535379

Epoch: 6| Step: 8
Training loss: 2.90115566246564
Validation loss: 2.6100764366790936

Epoch: 6| Step: 9
Training loss: 2.9372912393613784
Validation loss: 2.6046425146332868

Epoch: 6| Step: 10
Training loss: 2.765205911898601
Validation loss: 2.5607871947500516

Epoch: 6| Step: 11
Training loss: 2.3538655001217834
Validation loss: 2.525811192449875

Epoch: 6| Step: 12
Training loss: 2.952178803495001
Validation loss: 2.5048047665231934

Epoch: 6| Step: 13
Training loss: 3.183825899798777
Validation loss: 2.5080324749337044

Epoch: 302| Step: 0
Training loss: 2.861541927539061
Validation loss: 2.4982564824850773

Epoch: 6| Step: 1
Training loss: 2.539373478552184
Validation loss: 2.4988519996337994

Epoch: 6| Step: 2
Training loss: 3.113404236856762
Validation loss: 2.500953059909229

Epoch: 6| Step: 3
Training loss: 3.4041139397025972
Validation loss: 2.4941307430832995

Epoch: 6| Step: 4
Training loss: 2.4948003101132783
Validation loss: 2.4892059872922223

Epoch: 6| Step: 5
Training loss: 2.6333483594956624
Validation loss: 2.489564207084822

Epoch: 6| Step: 6
Training loss: 2.7820468575420896
Validation loss: 2.4910861704617155

Epoch: 6| Step: 7
Training loss: 2.8680302267569977
Validation loss: 2.505120729440277

Epoch: 6| Step: 8
Training loss: 3.1613660083510298
Validation loss: 2.504025371843836

Epoch: 6| Step: 9
Training loss: 2.6024611928430184
Validation loss: 2.521292269843597

Epoch: 6| Step: 10
Training loss: 2.259480002510397
Validation loss: 2.525348047380167

Epoch: 6| Step: 11
Training loss: 2.7261590085243195
Validation loss: 2.5794377171633585

Epoch: 6| Step: 12
Training loss: 2.6082635214078604
Validation loss: 2.6019319306920647

Epoch: 6| Step: 13
Training loss: 3.09854955888985
Validation loss: 2.632092032340107

Epoch: 303| Step: 0
Training loss: 2.89826870244248
Validation loss: 2.5635779919849773

Epoch: 6| Step: 1
Training loss: 3.0443402041234457
Validation loss: 2.5467010454745718

Epoch: 6| Step: 2
Training loss: 2.3007563798528503
Validation loss: 2.5252254878026434

Epoch: 6| Step: 3
Training loss: 2.212564577356369
Validation loss: 2.5166042386011633

Epoch: 6| Step: 4
Training loss: 2.683316812010267
Validation loss: 2.511587292190361

Epoch: 6| Step: 5
Training loss: 3.206646132955283
Validation loss: 2.5242688504808553

Epoch: 6| Step: 6
Training loss: 2.173377196780081
Validation loss: 2.5133769842268503

Epoch: 6| Step: 7
Training loss: 2.6150664431589936
Validation loss: 2.5177769807513872

Epoch: 6| Step: 8
Training loss: 2.9503309161259246
Validation loss: 2.5257406261930333

Epoch: 6| Step: 9
Training loss: 2.947882302738829
Validation loss: 2.5258509071783934

Epoch: 6| Step: 10
Training loss: 2.9365888765260157
Validation loss: 2.5358556940457673

Epoch: 6| Step: 11
Training loss: 3.2521765829756952
Validation loss: 2.5273913657171274

Epoch: 6| Step: 12
Training loss: 2.9402783829076697
Validation loss: 2.532493342662031

Epoch: 6| Step: 13
Training loss: 2.73477135101752
Validation loss: 2.5569626360264115

Epoch: 304| Step: 0
Training loss: 2.827274595091068
Validation loss: 2.545335862357134

Epoch: 6| Step: 1
Training loss: 3.1650191756356096
Validation loss: 2.5633993638969534

Epoch: 6| Step: 2
Training loss: 3.1498617353824225
Validation loss: 2.601693974827799

Epoch: 6| Step: 3
Training loss: 2.3992031999964167
Validation loss: 2.635703901981764

Epoch: 6| Step: 4
Training loss: 3.088559815909382
Validation loss: 2.708746040142556

Epoch: 6| Step: 5
Training loss: 2.88890164527359
Validation loss: 2.7511663364042955

Epoch: 6| Step: 6
Training loss: 2.5344844921463174
Validation loss: 2.7211254361511474

Epoch: 6| Step: 7
Training loss: 2.469573450979978
Validation loss: 2.6822740846737263

Epoch: 6| Step: 8
Training loss: 3.3963059328574903
Validation loss: 2.632616608050432

Epoch: 6| Step: 9
Training loss: 2.442988452154873
Validation loss: 2.552206549182377

Epoch: 6| Step: 10
Training loss: 2.4450671770661456
Validation loss: 2.532450522049689

Epoch: 6| Step: 11
Training loss: 2.592724241088112
Validation loss: 2.501427275842994

Epoch: 6| Step: 12
Training loss: 3.0569998728084817
Validation loss: 2.5056164512934234

Epoch: 6| Step: 13
Training loss: 2.4405241570538347
Validation loss: 2.5056645939793163

Epoch: 305| Step: 0
Training loss: 3.465564536692889
Validation loss: 2.500415152257921

Epoch: 6| Step: 1
Training loss: 2.7018722541931024
Validation loss: 2.4958482795856853

Epoch: 6| Step: 2
Training loss: 2.8047971571203383
Validation loss: 2.508763401836848

Epoch: 6| Step: 3
Training loss: 1.8730024505534029
Validation loss: 2.512298142061682

Epoch: 6| Step: 4
Training loss: 3.163057445504974
Validation loss: 2.5213077708554454

Epoch: 6| Step: 5
Training loss: 2.6230672351220248
Validation loss: 2.521095701222279

Epoch: 6| Step: 6
Training loss: 2.9718865138652157
Validation loss: 2.561682710088619

Epoch: 6| Step: 7
Training loss: 2.1100065063086983
Validation loss: 2.5602335237023555

Epoch: 6| Step: 8
Training loss: 2.306951723107049
Validation loss: 2.603096467332148

Epoch: 6| Step: 9
Training loss: 2.891880402008611
Validation loss: 2.5921411240300904

Epoch: 6| Step: 10
Training loss: 3.1079828414148776
Validation loss: 2.609867191249416

Epoch: 6| Step: 11
Training loss: 2.8691495995222134
Validation loss: 2.6058987815787504

Epoch: 6| Step: 12
Training loss: 2.919437472884298
Validation loss: 2.5669561098519242

Epoch: 6| Step: 13
Training loss: 3.335987242566788
Validation loss: 2.5725014283300154

Epoch: 306| Step: 0
Training loss: 2.924712898966638
Validation loss: 2.5413610229884176

Epoch: 6| Step: 1
Training loss: 2.3134633712424684
Validation loss: 2.5205065187322484

Epoch: 6| Step: 2
Training loss: 2.6921476054542817
Validation loss: 2.511169791058558

Epoch: 6| Step: 3
Training loss: 2.6392399693788358
Validation loss: 2.5088817530279184

Epoch: 6| Step: 4
Training loss: 2.954080417021428
Validation loss: 2.510869670835716

Epoch: 6| Step: 5
Training loss: 2.7940260373146817
Validation loss: 2.5082203891100456

Epoch: 6| Step: 6
Training loss: 3.2649827535503837
Validation loss: 2.502774427503348

Epoch: 6| Step: 7
Training loss: 2.9381988992589396
Validation loss: 2.504615457876771

Epoch: 6| Step: 8
Training loss: 3.213125703785969
Validation loss: 2.506074618278971

Epoch: 6| Step: 9
Training loss: 2.197666087638786
Validation loss: 2.513586897262658

Epoch: 6| Step: 10
Training loss: 2.4968545199092613
Validation loss: 2.5135202164883377

Epoch: 6| Step: 11
Training loss: 2.87849479229807
Validation loss: 2.5057736125877383

Epoch: 6| Step: 12
Training loss: 2.684281129272647
Validation loss: 2.524246385368557

Epoch: 6| Step: 13
Training loss: 3.2234794166491194
Validation loss: 2.5587131943603882

Epoch: 307| Step: 0
Training loss: 2.8676062337923875
Validation loss: 2.621593116192847

Epoch: 6| Step: 1
Training loss: 3.437643152203924
Validation loss: 2.676334147153317

Epoch: 6| Step: 2
Training loss: 2.229444599353869
Validation loss: 2.704222253067308

Epoch: 6| Step: 3
Training loss: 2.9204455464254475
Validation loss: 2.7092340563395796

Epoch: 6| Step: 4
Training loss: 2.6222843473514192
Validation loss: 2.6943165831200444

Epoch: 6| Step: 5
Training loss: 2.8593933438405785
Validation loss: 2.6482732786465197

Epoch: 6| Step: 6
Training loss: 2.3356240358827893
Validation loss: 2.5835819439010623

Epoch: 6| Step: 7
Training loss: 2.8437196499389192
Validation loss: 2.537607390619002

Epoch: 6| Step: 8
Training loss: 2.8738371114316816
Validation loss: 2.5142259202076964

Epoch: 6| Step: 9
Training loss: 3.0796709390211428
Validation loss: 2.5092922676759324

Epoch: 6| Step: 10
Training loss: 2.312537631166841
Validation loss: 2.512517754880719

Epoch: 6| Step: 11
Training loss: 2.9961973567789295
Validation loss: 2.506065786958291

Epoch: 6| Step: 12
Training loss: 2.7983311107354787
Validation loss: 2.5003357815587997

Epoch: 6| Step: 13
Training loss: 2.937504058185777
Validation loss: 2.5020818389434285

Epoch: 308| Step: 0
Training loss: 2.861242632841839
Validation loss: 2.512124994558233

Epoch: 6| Step: 1
Training loss: 2.803247448682496
Validation loss: 2.5087792234654507

Epoch: 6| Step: 2
Training loss: 3.328310965773435
Validation loss: 2.506203565008051

Epoch: 6| Step: 3
Training loss: 2.74863677481639
Validation loss: 2.526887257178722

Epoch: 6| Step: 4
Training loss: 3.193879419380831
Validation loss: 2.553279212958132

Epoch: 6| Step: 5
Training loss: 3.3490231014809275
Validation loss: 2.5646583857299134

Epoch: 6| Step: 6
Training loss: 2.1628627274436285
Validation loss: 2.5948913944982737

Epoch: 6| Step: 7
Training loss: 2.7675596894785595
Validation loss: 2.575010142399468

Epoch: 6| Step: 8
Training loss: 2.083588266669411
Validation loss: 2.5647940912638503

Epoch: 6| Step: 9
Training loss: 3.2241636507702647
Validation loss: 2.583699615887559

Epoch: 6| Step: 10
Training loss: 2.479748911298468
Validation loss: 2.581934341355324

Epoch: 6| Step: 11
Training loss: 2.6173722386991662
Validation loss: 2.5895477295510263

Epoch: 6| Step: 12
Training loss: 2.684625374571736
Validation loss: 2.5901631999808545

Epoch: 6| Step: 13
Training loss: 2.4221333027577416
Validation loss: 2.5813337914365304

Epoch: 309| Step: 0
Training loss: 2.3860207893508294
Validation loss: 2.5535219967169587

Epoch: 6| Step: 1
Training loss: 2.3260466240025566
Validation loss: 2.5602621746196985

Epoch: 6| Step: 2
Training loss: 3.500858201669036
Validation loss: 2.5840397063218488

Epoch: 6| Step: 3
Training loss: 2.8549508644057933
Validation loss: 2.542924808804115

Epoch: 6| Step: 4
Training loss: 2.398311251321507
Validation loss: 2.54392844183459

Epoch: 6| Step: 5
Training loss: 3.0764713395902636
Validation loss: 2.534930485610885

Epoch: 6| Step: 6
Training loss: 3.128784634516184
Validation loss: 2.5314589089744315

Epoch: 6| Step: 7
Training loss: 2.8799752019768268
Validation loss: 2.5449351146367682

Epoch: 6| Step: 8
Training loss: 2.9689501243197474
Validation loss: 2.5290815746930417

Epoch: 6| Step: 9
Training loss: 2.345465172379972
Validation loss: 2.54139733732512

Epoch: 6| Step: 10
Training loss: 2.7432685307960036
Validation loss: 2.534861281663481

Epoch: 6| Step: 11
Training loss: 2.336225715131356
Validation loss: 2.554629532903139

Epoch: 6| Step: 12
Training loss: 2.6375298954864874
Validation loss: 2.540489905440019

Epoch: 6| Step: 13
Training loss: 3.0456183556402614
Validation loss: 2.5392519997684366

Epoch: 310| Step: 0
Training loss: 2.9978054284901416
Validation loss: 2.5284435088664896

Epoch: 6| Step: 1
Training loss: 2.514520058919591
Validation loss: 2.5292236023573884

Epoch: 6| Step: 2
Training loss: 2.5187140033885305
Validation loss: 2.522147721179951

Epoch: 6| Step: 3
Training loss: 2.997566030505211
Validation loss: 2.510230375626759

Epoch: 6| Step: 4
Training loss: 2.9851686710517558
Validation loss: 2.5187048703193935

Epoch: 6| Step: 5
Training loss: 3.0482063710292486
Validation loss: 2.5100217915518748

Epoch: 6| Step: 6
Training loss: 2.7517233563811807
Validation loss: 2.510338893157622

Epoch: 6| Step: 7
Training loss: 2.885235189705434
Validation loss: 2.5253923324752905

Epoch: 6| Step: 8
Training loss: 2.7449389616636792
Validation loss: 2.5534298754610556

Epoch: 6| Step: 9
Training loss: 2.822759607504297
Validation loss: 2.5664580775653687

Epoch: 6| Step: 10
Training loss: 2.7186335396213126
Validation loss: 2.613397880002039

Epoch: 6| Step: 11
Training loss: 2.674553315132424
Validation loss: 2.6070581743927983

Epoch: 6| Step: 12
Training loss: 2.251395852184516
Validation loss: 2.620991564027926

Epoch: 6| Step: 13
Training loss: 2.84422147426633
Validation loss: 2.6442696373226497

Epoch: 311| Step: 0
Training loss: 3.367025774194031
Validation loss: 2.6364654159228738

Epoch: 6| Step: 1
Training loss: 3.3004548944154353
Validation loss: 2.6595242534252796

Epoch: 6| Step: 2
Training loss: 2.184701055332714
Validation loss: 2.667000361939601

Epoch: 6| Step: 3
Training loss: 2.6615123905034648
Validation loss: 2.6650250121866836

Epoch: 6| Step: 4
Training loss: 2.821456212327431
Validation loss: 2.697616005144353

Epoch: 6| Step: 5
Training loss: 2.585632306209179
Validation loss: 2.6898355906940097

Epoch: 6| Step: 6
Training loss: 2.3145276021442576
Validation loss: 2.67857964429948

Epoch: 6| Step: 7
Training loss: 2.697487835083295
Validation loss: 2.6500412205442543

Epoch: 6| Step: 8
Training loss: 3.022277767319217
Validation loss: 2.6201189115195724

Epoch: 6| Step: 9
Training loss: 2.751440537894529
Validation loss: 2.5705805364242664

Epoch: 6| Step: 10
Training loss: 2.6015208931193357
Validation loss: 2.5144131706613164

Epoch: 6| Step: 11
Training loss: 2.547005866497399
Validation loss: 2.5183790404326247

Epoch: 6| Step: 12
Training loss: 3.2067374351554485
Validation loss: 2.520401874929337

Epoch: 6| Step: 13
Training loss: 2.6542246558193923
Validation loss: 2.5169948067998953

Epoch: 312| Step: 0
Training loss: 2.5921716138871447
Validation loss: 2.5151721891013956

Epoch: 6| Step: 1
Training loss: 2.5655529165421878
Validation loss: 2.5082308870303955

Epoch: 6| Step: 2
Training loss: 2.22247442430299
Validation loss: 2.5100715017648447

Epoch: 6| Step: 3
Training loss: 2.7145099242544193
Validation loss: 2.50767248713092

Epoch: 6| Step: 4
Training loss: 3.168053039106787
Validation loss: 2.5145258967689204

Epoch: 6| Step: 5
Training loss: 2.233605312278792
Validation loss: 2.5163361386180294

Epoch: 6| Step: 6
Training loss: 2.4783749852360613
Validation loss: 2.532265342403843

Epoch: 6| Step: 7
Training loss: 3.331711819756076
Validation loss: 2.5465543076859936

Epoch: 6| Step: 8
Training loss: 2.2424980772556666
Validation loss: 2.551923504148886

Epoch: 6| Step: 9
Training loss: 3.5626375941424726
Validation loss: 2.560685216215326

Epoch: 6| Step: 10
Training loss: 3.3122970230964897
Validation loss: 2.5861585796615527

Epoch: 6| Step: 11
Training loss: 2.411897843078006
Validation loss: 2.608861430442459

Epoch: 6| Step: 12
Training loss: 2.88405129712709
Validation loss: 2.6164786595818397

Epoch: 6| Step: 13
Training loss: 3.192829389076633
Validation loss: 2.611193914008905

Epoch: 313| Step: 0
Training loss: 2.927921016920238
Validation loss: 2.640350910079664

Epoch: 6| Step: 1
Training loss: 3.1265035445466074
Validation loss: 2.620099405179714

Epoch: 6| Step: 2
Training loss: 2.511913713212401
Validation loss: 2.5914543530071272

Epoch: 6| Step: 3
Training loss: 2.7193359094439056
Validation loss: 2.5844711519732395

Epoch: 6| Step: 4
Training loss: 2.7015900415767344
Validation loss: 2.5461227823077746

Epoch: 6| Step: 5
Training loss: 2.9039701317756554
Validation loss: 2.5208324794077988

Epoch: 6| Step: 6
Training loss: 2.8298808174513295
Validation loss: 2.5221166419698116

Epoch: 6| Step: 7
Training loss: 2.786960525654717
Validation loss: 2.5254475253324298

Epoch: 6| Step: 8
Training loss: 2.8181785900902927
Validation loss: 2.5332651405461

Epoch: 6| Step: 9
Training loss: 2.5834200034420594
Validation loss: 2.539005404982868

Epoch: 6| Step: 10
Training loss: 2.308694750130425
Validation loss: 2.5702530021524868

Epoch: 6| Step: 11
Training loss: 2.8753766352206034
Validation loss: 2.5634622425435287

Epoch: 6| Step: 12
Training loss: 2.7566179925141663
Validation loss: 2.561984411753921

Epoch: 6| Step: 13
Training loss: 2.677173380444375
Validation loss: 2.6106549624348565

Epoch: 314| Step: 0
Training loss: 3.218606593816914
Validation loss: 2.611004640872085

Epoch: 6| Step: 1
Training loss: 3.019143537376086
Validation loss: 2.5933880860493512

Epoch: 6| Step: 2
Training loss: 2.7004077462208573
Validation loss: 2.588743095577097

Epoch: 6| Step: 3
Training loss: 2.519375960421539
Validation loss: 2.5535451228912014

Epoch: 6| Step: 4
Training loss: 2.987060616714982
Validation loss: 2.5473388122720513

Epoch: 6| Step: 5
Training loss: 2.794287822253418
Validation loss: 2.5220814837615446

Epoch: 6| Step: 6
Training loss: 2.99727650042216
Validation loss: 2.5159528117830257

Epoch: 6| Step: 7
Training loss: 2.579805970547515
Validation loss: 2.504327017611095

Epoch: 6| Step: 8
Training loss: 2.8869967397757956
Validation loss: 2.512547320289303

Epoch: 6| Step: 9
Training loss: 2.8377051191090272
Validation loss: 2.502900692694504

Epoch: 6| Step: 10
Training loss: 2.6374858729268893
Validation loss: 2.504778107558041

Epoch: 6| Step: 11
Training loss: 2.8828641064994667
Validation loss: 2.504660743122817

Epoch: 6| Step: 12
Training loss: 2.2665741083470334
Validation loss: 2.5115492596785653

Epoch: 6| Step: 13
Training loss: 2.712938521136097
Validation loss: 2.520085133146329

Epoch: 315| Step: 0
Training loss: 2.9634728359459697
Validation loss: 2.533062505601922

Epoch: 6| Step: 1
Training loss: 2.630847684498664
Validation loss: 2.5439305208193534

Epoch: 6| Step: 2
Training loss: 2.187837629148039
Validation loss: 2.56546713509347

Epoch: 6| Step: 3
Training loss: 3.4748374516733525
Validation loss: 2.5806891961211873

Epoch: 6| Step: 4
Training loss: 2.632917362468
Validation loss: 2.562454874525261

Epoch: 6| Step: 5
Training loss: 2.3639970184152457
Validation loss: 2.5556400476671937

Epoch: 6| Step: 6
Training loss: 2.513462250571189
Validation loss: 2.5570837035351452

Epoch: 6| Step: 7
Training loss: 3.0256049694083007
Validation loss: 2.5582815503815413

Epoch: 6| Step: 8
Training loss: 2.83504621303239
Validation loss: 2.5624789445453735

Epoch: 6| Step: 9
Training loss: 2.6951815808331188
Validation loss: 2.5546145692628235

Epoch: 6| Step: 10
Training loss: 3.0210041041720412
Validation loss: 2.5661839092160355

Epoch: 6| Step: 11
Training loss: 2.8883344493173366
Validation loss: 2.539975253260678

Epoch: 6| Step: 12
Training loss: 2.368881173641165
Validation loss: 2.5496939595106625

Epoch: 6| Step: 13
Training loss: 3.148644528078198
Validation loss: 2.564881431479183

Epoch: 316| Step: 0
Training loss: 3.664640271277809
Validation loss: 2.562798024276623

Epoch: 6| Step: 1
Training loss: 1.8335401750692946
Validation loss: 2.5817773349188764

Epoch: 6| Step: 2
Training loss: 3.0958419046672665
Validation loss: 2.568007217008754

Epoch: 6| Step: 3
Training loss: 2.3034221731774966
Validation loss: 2.561834897801484

Epoch: 6| Step: 4
Training loss: 2.7131020646882282
Validation loss: 2.562876807960497

Epoch: 6| Step: 5
Training loss: 2.364926104691615
Validation loss: 2.575264177192541

Epoch: 6| Step: 6
Training loss: 2.8630895615511887
Validation loss: 2.5762417654184793

Epoch: 6| Step: 7
Training loss: 2.9270360723370334
Validation loss: 2.546258483992115

Epoch: 6| Step: 8
Training loss: 3.0332512295968144
Validation loss: 2.5569985433094353

Epoch: 6| Step: 9
Training loss: 2.864496699092413
Validation loss: 2.54496203290371

Epoch: 6| Step: 10
Training loss: 2.5892036763240998
Validation loss: 2.5363174277715665

Epoch: 6| Step: 11
Training loss: 2.6357856060012206
Validation loss: 2.526001485376666

Epoch: 6| Step: 12
Training loss: 2.9622324826780737
Validation loss: 2.5155835686784345

Epoch: 6| Step: 13
Training loss: 2.0568359514098256
Validation loss: 2.5193221996056483

Epoch: 317| Step: 0
Training loss: 2.4664340201630917
Validation loss: 2.511001552138993

Epoch: 6| Step: 1
Training loss: 2.9484899567757594
Validation loss: 2.515580186270831

Epoch: 6| Step: 2
Training loss: 2.71523452251699
Validation loss: 2.5175547509168936

Epoch: 6| Step: 3
Training loss: 2.7957799035626962
Validation loss: 2.51353020474413

Epoch: 6| Step: 4
Training loss: 2.9056021675891603
Validation loss: 2.5346516699998856

Epoch: 6| Step: 5
Training loss: 2.5177428056290085
Validation loss: 2.524641615212393

Epoch: 6| Step: 6
Training loss: 2.9946931949956612
Validation loss: 2.5469923417029996

Epoch: 6| Step: 7
Training loss: 2.393707183375283
Validation loss: 2.525472288128899

Epoch: 6| Step: 8
Training loss: 2.591771209750704
Validation loss: 2.5380745671335165

Epoch: 6| Step: 9
Training loss: 3.099352301337358
Validation loss: 2.5313974618844237

Epoch: 6| Step: 10
Training loss: 2.6473060374041135
Validation loss: 2.5198035232090072

Epoch: 6| Step: 11
Training loss: 2.8584810120567643
Validation loss: 2.5108876978472727

Epoch: 6| Step: 12
Training loss: 2.947850274909859
Validation loss: 2.5201007392418124

Epoch: 6| Step: 13
Training loss: 2.5287218066089685
Validation loss: 2.5182216691810964

Epoch: 318| Step: 0
Training loss: 2.1705376329092396
Validation loss: 2.52648194948614

Epoch: 6| Step: 1
Training loss: 2.4039673319864514
Validation loss: 2.542453488413625

Epoch: 6| Step: 2
Training loss: 3.202478855369977
Validation loss: 2.5557532765303628

Epoch: 6| Step: 3
Training loss: 2.9588072670284578
Validation loss: 2.5752411733885365

Epoch: 6| Step: 4
Training loss: 2.7849380386281135
Validation loss: 2.589300277259229

Epoch: 6| Step: 5
Training loss: 2.5982094541344645
Validation loss: 2.579598682247712

Epoch: 6| Step: 6
Training loss: 2.9186636673046515
Validation loss: 2.603903194430239

Epoch: 6| Step: 7
Training loss: 2.4135609324847995
Validation loss: 2.6036127701589526

Epoch: 6| Step: 8
Training loss: 2.843943159648677
Validation loss: 2.557908650744317

Epoch: 6| Step: 9
Training loss: 2.6655281040339407
Validation loss: 2.5384369251631176

Epoch: 6| Step: 10
Training loss: 2.891971748667814
Validation loss: 2.530915759204501

Epoch: 6| Step: 11
Training loss: 2.9402521105774047
Validation loss: 2.537200635839177

Epoch: 6| Step: 12
Training loss: 2.8133166505068865
Validation loss: 2.522329213232137

Epoch: 6| Step: 13
Training loss: 2.7481994803431835
Validation loss: 2.516623927772631

Epoch: 319| Step: 0
Training loss: 2.7314765609246696
Validation loss: 2.513704716922317

Epoch: 6| Step: 1
Training loss: 2.879288998630439
Validation loss: 2.512105789567383

Epoch: 6| Step: 2
Training loss: 2.711853400305056
Validation loss: 2.507107486043208

Epoch: 6| Step: 3
Training loss: 1.716151614220414
Validation loss: 2.5053489109565237

Epoch: 6| Step: 4
Training loss: 2.7263625981630906
Validation loss: 2.500546059397476

Epoch: 6| Step: 5
Training loss: 2.612032513566535
Validation loss: 2.4918672624188547

Epoch: 6| Step: 6
Training loss: 2.6487653411233745
Validation loss: 2.500386403073366

Epoch: 6| Step: 7
Training loss: 2.7603886057069213
Validation loss: 2.514456648154892

Epoch: 6| Step: 8
Training loss: 2.9899301006605383
Validation loss: 2.53953795418537

Epoch: 6| Step: 9
Training loss: 3.0095526875518215
Validation loss: 2.579903263211101

Epoch: 6| Step: 10
Training loss: 3.218806886633229
Validation loss: 2.643032658100612

Epoch: 6| Step: 11
Training loss: 2.8921412434889895
Validation loss: 2.6056275894697283

Epoch: 6| Step: 12
Training loss: 3.011282368474525
Validation loss: 2.5549617992751608

Epoch: 6| Step: 13
Training loss: 2.397543078722686
Validation loss: 2.5447605237952944

Epoch: 320| Step: 0
Training loss: 2.7024335031859423
Validation loss: 2.5429428580901456

Epoch: 6| Step: 1
Training loss: 2.379907557030522
Validation loss: 2.521133092476689

Epoch: 6| Step: 2
Training loss: 2.8457838896612078
Validation loss: 2.5201685805348606

Epoch: 6| Step: 3
Training loss: 2.5840657539268763
Validation loss: 2.529905562002767

Epoch: 6| Step: 4
Training loss: 2.621853804928903
Validation loss: 2.512926471733849

Epoch: 6| Step: 5
Training loss: 2.8900317433867753
Validation loss: 2.521016356223363

Epoch: 6| Step: 6
Training loss: 2.748187941974949
Validation loss: 2.5251539102417833

Epoch: 6| Step: 7
Training loss: 3.3023107472438604
Validation loss: 2.5409541113831726

Epoch: 6| Step: 8
Training loss: 2.7887571365354042
Validation loss: 2.5455907627110954

Epoch: 6| Step: 9
Training loss: 2.9893945153628425
Validation loss: 2.5353160343706302

Epoch: 6| Step: 10
Training loss: 2.5189147668148735
Validation loss: 2.5308890551886205

Epoch: 6| Step: 11
Training loss: 2.8446013465297226
Validation loss: 2.5210616743022305

Epoch: 6| Step: 12
Training loss: 2.5039390050022154
Validation loss: 2.535867892221548

Epoch: 6| Step: 13
Training loss: 2.5825301018850357
Validation loss: 2.528907474834812

Epoch: 321| Step: 0
Training loss: 2.5708981110641362
Validation loss: 2.5495332290689423

Epoch: 6| Step: 1
Training loss: 2.4920569119575307
Validation loss: 2.540472802940361

Epoch: 6| Step: 2
Training loss: 3.0053420188606803
Validation loss: 2.5374599915745084

Epoch: 6| Step: 3
Training loss: 2.728371967965705
Validation loss: 2.558268710508663

Epoch: 6| Step: 4
Training loss: 2.0141623461162337
Validation loss: 2.5746704842509027

Epoch: 6| Step: 5
Training loss: 2.344703683737557
Validation loss: 2.546988014599116

Epoch: 6| Step: 6
Training loss: 2.8824290612417194
Validation loss: 2.5589875339756025

Epoch: 6| Step: 7
Training loss: 3.1260060026241763
Validation loss: 2.5622349363628447

Epoch: 6| Step: 8
Training loss: 2.7404494469679093
Validation loss: 2.542497850660529

Epoch: 6| Step: 9
Training loss: 2.652843220443341
Validation loss: 2.5376497928543422

Epoch: 6| Step: 10
Training loss: 2.6933878785769667
Validation loss: 2.532657262993326

Epoch: 6| Step: 11
Training loss: 3.1992575022454552
Validation loss: 2.5162043260129128

Epoch: 6| Step: 12
Training loss: 3.1430645477919974
Validation loss: 2.512621317994388

Epoch: 6| Step: 13
Training loss: 2.1453100016913487
Validation loss: 2.502228818029634

Epoch: 322| Step: 0
Training loss: 2.614856558780624
Validation loss: 2.5049997950331875

Epoch: 6| Step: 1
Training loss: 2.82403074195382
Validation loss: 2.5140674283443003

Epoch: 6| Step: 2
Training loss: 2.403813007419648
Validation loss: 2.519420969162385

Epoch: 6| Step: 3
Training loss: 2.6718862432946007
Validation loss: 2.5203387769322267

Epoch: 6| Step: 4
Training loss: 2.8582287768341175
Validation loss: 2.512917630827011

Epoch: 6| Step: 5
Training loss: 3.0488199921816577
Validation loss: 2.5560123314563308

Epoch: 6| Step: 6
Training loss: 2.588136596506315
Validation loss: 2.5629436510047268

Epoch: 6| Step: 7
Training loss: 2.5059830597154993
Validation loss: 2.5645963116214605

Epoch: 6| Step: 8
Training loss: 2.6072049740074634
Validation loss: 2.597547108814419

Epoch: 6| Step: 9
Training loss: 2.5117997175725435
Validation loss: 2.6383402202382795

Epoch: 6| Step: 10
Training loss: 2.3366953153209913
Validation loss: 2.664926206744571

Epoch: 6| Step: 11
Training loss: 2.8926902198064126
Validation loss: 2.701059431759508

Epoch: 6| Step: 12
Training loss: 3.3380389060649547
Validation loss: 2.752537711487212

Epoch: 6| Step: 13
Training loss: 3.079497675123543
Validation loss: 2.752407899178353

Epoch: 323| Step: 0
Training loss: 2.040704526417738
Validation loss: 2.7000190264761814

Epoch: 6| Step: 1
Training loss: 2.2768114360991247
Validation loss: 2.674557569086917

Epoch: 6| Step: 2
Training loss: 3.1102784344327223
Validation loss: 2.6250824473413137

Epoch: 6| Step: 3
Training loss: 2.2053987930450916
Validation loss: 2.603146574663228

Epoch: 6| Step: 4
Training loss: 2.9106602174783864
Validation loss: 2.5686925750454246

Epoch: 6| Step: 5
Training loss: 3.103975908874148
Validation loss: 2.5432697000425435

Epoch: 6| Step: 6
Training loss: 2.4218385755199425
Validation loss: 2.5284203842765427

Epoch: 6| Step: 7
Training loss: 2.913151903009825
Validation loss: 2.5176596892170164

Epoch: 6| Step: 8
Training loss: 3.502477586389963
Validation loss: 2.501365144307966

Epoch: 6| Step: 9
Training loss: 2.9024429817743487
Validation loss: 2.4917251508302747

Epoch: 6| Step: 10
Training loss: 2.3262564309844547
Validation loss: 2.4922574841243597

Epoch: 6| Step: 11
Training loss: 2.634130312234202
Validation loss: 2.503272351406904

Epoch: 6| Step: 12
Training loss: 3.363764392562576
Validation loss: 2.5089976090734067

Epoch: 6| Step: 13
Training loss: 2.763965604559814
Validation loss: 2.498666055692686

Epoch: 324| Step: 0
Training loss: 2.5880791131239738
Validation loss: 2.5207125866117295

Epoch: 6| Step: 1
Training loss: 2.6935666829549443
Validation loss: 2.5028934070668987

Epoch: 6| Step: 2
Training loss: 1.8492127006248091
Validation loss: 2.515941777504008

Epoch: 6| Step: 3
Training loss: 2.7626030570437283
Validation loss: 2.5401817531781568

Epoch: 6| Step: 4
Training loss: 2.4960484746847516
Validation loss: 2.575445259769111

Epoch: 6| Step: 5
Training loss: 2.936950469864782
Validation loss: 2.5957815420678996

Epoch: 6| Step: 6
Training loss: 3.1932463366365695
Validation loss: 2.5772890975047438

Epoch: 6| Step: 7
Training loss: 2.5478905835276096
Validation loss: 2.5845090487678393

Epoch: 6| Step: 8
Training loss: 2.2864562941928077
Validation loss: 2.560724168824792

Epoch: 6| Step: 9
Training loss: 3.28667763987393
Validation loss: 2.541738894071945

Epoch: 6| Step: 10
Training loss: 2.8060105797261627
Validation loss: 2.5254403179466878

Epoch: 6| Step: 11
Training loss: 2.8891729883550803
Validation loss: 2.500915461250059

Epoch: 6| Step: 12
Training loss: 2.89815632980685
Validation loss: 2.4916314094752368

Epoch: 6| Step: 13
Training loss: 3.309900379352864
Validation loss: 2.477467149236673

Epoch: 325| Step: 0
Training loss: 2.716843210424425
Validation loss: 2.490910696302528

Epoch: 6| Step: 1
Training loss: 2.8769750030990937
Validation loss: 2.4923174259710636

Epoch: 6| Step: 2
Training loss: 2.5750647675600136
Validation loss: 2.5201666782772754

Epoch: 6| Step: 3
Training loss: 2.58536857500824
Validation loss: 2.5370442542344627

Epoch: 6| Step: 4
Training loss: 2.5214384209237104
Validation loss: 2.583887126866907

Epoch: 6| Step: 5
Training loss: 2.7984577154795724
Validation loss: 2.6310680188609683

Epoch: 6| Step: 6
Training loss: 3.5813461530469706
Validation loss: 2.6731990039717606

Epoch: 6| Step: 7
Training loss: 2.59852060264243
Validation loss: 2.6056364896877318

Epoch: 6| Step: 8
Training loss: 2.4432090999701104
Validation loss: 2.560540447235018

Epoch: 6| Step: 9
Training loss: 2.004975567143228
Validation loss: 2.526298836312864

Epoch: 6| Step: 10
Training loss: 2.8365077766837694
Validation loss: 2.5163103058190552

Epoch: 6| Step: 11
Training loss: 2.9638992031322733
Validation loss: 2.5063786451106895

Epoch: 6| Step: 12
Training loss: 2.7104941233641786
Validation loss: 2.5099873887831055

Epoch: 6| Step: 13
Training loss: 2.6076339121123557
Validation loss: 2.508035535314882

Epoch: 326| Step: 0
Training loss: 2.6210217075140307
Validation loss: 2.5068137083541244

Epoch: 6| Step: 1
Training loss: 2.510462991331911
Validation loss: 2.5090764666805203

Epoch: 6| Step: 2
Training loss: 3.1492497837484175
Validation loss: 2.5081981758113705

Epoch: 6| Step: 3
Training loss: 2.5066965062144195
Validation loss: 2.518852180149432

Epoch: 6| Step: 4
Training loss: 3.131008627719743
Validation loss: 2.5540282709812834

Epoch: 6| Step: 5
Training loss: 2.751057161525628
Validation loss: 2.550737432835844

Epoch: 6| Step: 6
Training loss: 2.2317761866632546
Validation loss: 2.5850506657125996

Epoch: 6| Step: 7
Training loss: 2.6015284080677263
Validation loss: 2.597176038698384

Epoch: 6| Step: 8
Training loss: 2.862556896727035
Validation loss: 2.5908167779705877

Epoch: 6| Step: 9
Training loss: 2.9923705998665673
Validation loss: 2.6027170792498366

Epoch: 6| Step: 10
Training loss: 2.5481335859268675
Validation loss: 2.588337465306239

Epoch: 6| Step: 11
Training loss: 2.6406675256318266
Validation loss: 2.59371395903938

Epoch: 6| Step: 12
Training loss: 2.6368145960589
Validation loss: 2.5653312283196184

Epoch: 6| Step: 13
Training loss: 3.3809243939173284
Validation loss: 2.5449362262473576

Epoch: 327| Step: 0
Training loss: 2.2605228194055513
Validation loss: 2.5207270609429027

Epoch: 6| Step: 1
Training loss: 2.681137448951866
Validation loss: 2.513040687618199

Epoch: 6| Step: 2
Training loss: 2.850429529314295
Validation loss: 2.502852718602862

Epoch: 6| Step: 3
Training loss: 2.9455449748687608
Validation loss: 2.5108103204577077

Epoch: 6| Step: 4
Training loss: 2.1830968956895243
Validation loss: 2.5238118695465253

Epoch: 6| Step: 5
Training loss: 2.732830636000829
Validation loss: 2.522970768203387

Epoch: 6| Step: 6
Training loss: 2.8010624913275795
Validation loss: 2.5294237829790385

Epoch: 6| Step: 7
Training loss: 2.6894103069678406
Validation loss: 2.548470004796844

Epoch: 6| Step: 8
Training loss: 2.810175549735427
Validation loss: 2.530549722615581

Epoch: 6| Step: 9
Training loss: 3.007492563645959
Validation loss: 2.5292762546773315

Epoch: 6| Step: 10
Training loss: 2.560200101065367
Validation loss: 2.523962633383041

Epoch: 6| Step: 11
Training loss: 2.490691019712455
Validation loss: 2.5318980752723284

Epoch: 6| Step: 12
Training loss: 2.894517906250872
Validation loss: 2.562782866249707

Epoch: 6| Step: 13
Training loss: 3.380860503321591
Validation loss: 2.553713628923223

Epoch: 328| Step: 0
Training loss: 3.0805719399444076
Validation loss: 2.5416006997227423

Epoch: 6| Step: 1
Training loss: 2.6225799122172764
Validation loss: 2.5369350600788416

Epoch: 6| Step: 2
Training loss: 2.838554414959666
Validation loss: 2.5412840619948986

Epoch: 6| Step: 3
Training loss: 2.558397684520177
Validation loss: 2.53230256771816

Epoch: 6| Step: 4
Training loss: 2.43693594641833
Validation loss: 2.5556670407649147

Epoch: 6| Step: 5
Training loss: 2.560900584449986
Validation loss: 2.522004364929016

Epoch: 6| Step: 6
Training loss: 2.9320573097654528
Validation loss: 2.537263027554283

Epoch: 6| Step: 7
Training loss: 2.7342711510692532
Validation loss: 2.5284896119169877

Epoch: 6| Step: 8
Training loss: 2.6960462373113527
Validation loss: 2.5357463880484183

Epoch: 6| Step: 9
Training loss: 2.546905798228519
Validation loss: 2.527005332230807

Epoch: 6| Step: 10
Training loss: 2.7633728512590703
Validation loss: 2.530106093969845

Epoch: 6| Step: 11
Training loss: 2.2509131168187175
Validation loss: 2.5364221295419416

Epoch: 6| Step: 12
Training loss: 2.8862756949198323
Validation loss: 2.5515534099175827

Epoch: 6| Step: 13
Training loss: 3.111737604488761
Validation loss: 2.540005280269011

Epoch: 329| Step: 0
Training loss: 3.1168543128441404
Validation loss: 2.536251879320079

Epoch: 6| Step: 1
Training loss: 3.085358306999101
Validation loss: 2.548386943929285

Epoch: 6| Step: 2
Training loss: 2.744204656865261
Validation loss: 2.558067767572017

Epoch: 6| Step: 3
Training loss: 2.6973122959394544
Validation loss: 2.582718754906908

Epoch: 6| Step: 4
Training loss: 3.197539432571796
Validation loss: 2.573924387700444

Epoch: 6| Step: 5
Training loss: 2.7745115967269474
Validation loss: 2.5544210134848533

Epoch: 6| Step: 6
Training loss: 2.520248618501766
Validation loss: 2.560846128668605

Epoch: 6| Step: 7
Training loss: 2.606236654928973
Validation loss: 2.57481152654843

Epoch: 6| Step: 8
Training loss: 2.3497558953951656
Validation loss: 2.5613200714827427

Epoch: 6| Step: 9
Training loss: 2.48376361353637
Validation loss: 2.5530731593740654

Epoch: 6| Step: 10
Training loss: 3.0003897095917105
Validation loss: 2.576131565717452

Epoch: 6| Step: 11
Training loss: 2.6370292424246706
Validation loss: 2.537180473819756

Epoch: 6| Step: 12
Training loss: 2.2499296389280605
Validation loss: 2.5367497378695743

Epoch: 6| Step: 13
Training loss: 2.0456584780593756
Validation loss: 2.5207632281010453

Epoch: 330| Step: 0
Training loss: 3.0782255359632678
Validation loss: 2.509742147512152

Epoch: 6| Step: 1
Training loss: 3.171675952998679
Validation loss: 2.5112213110161563

Epoch: 6| Step: 2
Training loss: 2.3249092166363368
Validation loss: 2.494938296693284

Epoch: 6| Step: 3
Training loss: 2.423274860052669
Validation loss: 2.5055779567375245

Epoch: 6| Step: 4
Training loss: 2.94513521748659
Validation loss: 2.512009568505528

Epoch: 6| Step: 5
Training loss: 3.008973370744515
Validation loss: 2.5064039041778328

Epoch: 6| Step: 6
Training loss: 2.7189642284659596
Validation loss: 2.5192804627481458

Epoch: 6| Step: 7
Training loss: 3.2347459073635254
Validation loss: 2.5202259425904585

Epoch: 6| Step: 8
Training loss: 2.648689910653539
Validation loss: 2.5296499263349452

Epoch: 6| Step: 9
Training loss: 1.858823678481067
Validation loss: 2.560025488780401

Epoch: 6| Step: 10
Training loss: 2.7208913503851244
Validation loss: 2.596557393651429

Epoch: 6| Step: 11
Training loss: 2.3448071956473355
Validation loss: 2.6139760247037462

Epoch: 6| Step: 12
Training loss: 2.1334577429774786
Validation loss: 2.6396920063828073

Epoch: 6| Step: 13
Training loss: 2.782557747953674
Validation loss: 2.6187531383739455

Epoch: 331| Step: 0
Training loss: 2.6928482068525375
Validation loss: 2.64347741022978

Epoch: 6| Step: 1
Training loss: 2.628683503054051
Validation loss: 2.6334862679303854

Epoch: 6| Step: 2
Training loss: 2.7198164152852717
Validation loss: 2.6189320381885106

Epoch: 6| Step: 3
Training loss: 2.77011502546979
Validation loss: 2.5475351577861143

Epoch: 6| Step: 4
Training loss: 2.467841355385873
Validation loss: 2.5368096061492533

Epoch: 6| Step: 5
Training loss: 2.8703712021292116
Validation loss: 2.5181740633257332

Epoch: 6| Step: 6
Training loss: 2.9764447526846003
Validation loss: 2.5044091505627386

Epoch: 6| Step: 7
Training loss: 2.3137727276527165
Validation loss: 2.490061932552287

Epoch: 6| Step: 8
Training loss: 2.5448235985377377
Validation loss: 2.5075079804228055

Epoch: 6| Step: 9
Training loss: 2.681521041437603
Validation loss: 2.513520424556156

Epoch: 6| Step: 10
Training loss: 3.2704519709606426
Validation loss: 2.5188142054252523

Epoch: 6| Step: 11
Training loss: 2.753685042783552
Validation loss: 2.5586510100850286

Epoch: 6| Step: 12
Training loss: 2.3873191365545416
Validation loss: 2.591270797881334

Epoch: 6| Step: 13
Training loss: 3.1198925241885807
Validation loss: 2.61387856441946

Epoch: 332| Step: 0
Training loss: 2.324489340538025
Validation loss: 2.641059175250236

Epoch: 6| Step: 1
Training loss: 2.705611480023501
Validation loss: 2.6288243711779202

Epoch: 6| Step: 2
Training loss: 2.4000419692502457
Validation loss: 2.6651156405038603

Epoch: 6| Step: 3
Training loss: 2.516244942233161
Validation loss: 2.7011829280166677

Epoch: 6| Step: 4
Training loss: 3.251676567162934
Validation loss: 2.7277143462817537

Epoch: 6| Step: 5
Training loss: 2.1994700313676194
Validation loss: 2.793773602333675

Epoch: 6| Step: 6
Training loss: 2.4530805838870644
Validation loss: 2.8900949397351625

Epoch: 6| Step: 7
Training loss: 2.601843649762148
Validation loss: 2.8615649609025904

Epoch: 6| Step: 8
Training loss: 3.0215460802421754
Validation loss: 2.777422718066402

Epoch: 6| Step: 9
Training loss: 3.149199211421496
Validation loss: 2.659431083416264

Epoch: 6| Step: 10
Training loss: 2.5965004551014976
Validation loss: 2.5561318292458743

Epoch: 6| Step: 11
Training loss: 2.801547276912419
Validation loss: 2.504822129957349

Epoch: 6| Step: 12
Training loss: 3.4907168848414485
Validation loss: 2.4924819838653134

Epoch: 6| Step: 13
Training loss: 2.6842797969682417
Validation loss: 2.5063569320310455

Epoch: 333| Step: 0
Training loss: 2.8404035055929926
Validation loss: 2.511604409694931

Epoch: 6| Step: 1
Training loss: 3.026728453096541
Validation loss: 2.5231265244047556

Epoch: 6| Step: 2
Training loss: 3.128236391749904
Validation loss: 2.521280972194665

Epoch: 6| Step: 3
Training loss: 2.8054422622148354
Validation loss: 2.5002204797796863

Epoch: 6| Step: 4
Training loss: 2.4804725947312725
Validation loss: 2.482635350225671

Epoch: 6| Step: 5
Training loss: 2.8390857046855427
Validation loss: 2.4805776362718723

Epoch: 6| Step: 6
Training loss: 2.1960011552623495
Validation loss: 2.4793525161496506

Epoch: 6| Step: 7
Training loss: 3.363434082528547
Validation loss: 2.4955683221664176

Epoch: 6| Step: 8
Training loss: 2.850270770411233
Validation loss: 2.5216195105950936

Epoch: 6| Step: 9
Training loss: 3.2816167717261884
Validation loss: 2.541373850434717

Epoch: 6| Step: 10
Training loss: 2.7615024854271386
Validation loss: 2.5509510752292868

Epoch: 6| Step: 11
Training loss: 2.397127172541217
Validation loss: 2.578656425408505

Epoch: 6| Step: 12
Training loss: 2.3921436148815878
Validation loss: 2.586171792570849

Epoch: 6| Step: 13
Training loss: 2.5137539178105444
Validation loss: 2.6225157857130617

Epoch: 334| Step: 0
Training loss: 2.505054894795709
Validation loss: 2.6096905817194047

Epoch: 6| Step: 1
Training loss: 2.6722527844784505
Validation loss: 2.635388954720857

Epoch: 6| Step: 2
Training loss: 2.2542282218308403
Validation loss: 2.648653611623903

Epoch: 6| Step: 3
Training loss: 2.932655560334197
Validation loss: 2.6415645672669807

Epoch: 6| Step: 4
Training loss: 2.977910575072301
Validation loss: 2.6147153950364554

Epoch: 6| Step: 5
Training loss: 2.7346601936930814
Validation loss: 2.614299675602387

Epoch: 6| Step: 6
Training loss: 2.7724852740599273
Validation loss: 2.5840684077816274

Epoch: 6| Step: 7
Training loss: 3.123622743381273
Validation loss: 2.5736977717285945

Epoch: 6| Step: 8
Training loss: 2.973681399695423
Validation loss: 2.5571776160116046

Epoch: 6| Step: 9
Training loss: 1.9697998517406174
Validation loss: 2.5210699446493234

Epoch: 6| Step: 10
Training loss: 2.8841465290214883
Validation loss: 2.509350207834152

Epoch: 6| Step: 11
Training loss: 2.578245587852192
Validation loss: 2.5043359840471755

Epoch: 6| Step: 12
Training loss: 2.368499593659411
Validation loss: 2.51164100932509

Epoch: 6| Step: 13
Training loss: 3.340984591336928
Validation loss: 2.5144649188159307

Epoch: 335| Step: 0
Training loss: 1.8278634952104063
Validation loss: 2.5031824570089585

Epoch: 6| Step: 1
Training loss: 2.891913874133826
Validation loss: 2.51554418612504

Epoch: 6| Step: 2
Training loss: 2.3660095103919976
Validation loss: 2.5356760487413874

Epoch: 6| Step: 3
Training loss: 2.698954545821655
Validation loss: 2.5179638872034777

Epoch: 6| Step: 4
Training loss: 2.353930728758486
Validation loss: 2.533508105825726

Epoch: 6| Step: 5
Training loss: 2.6609111504585727
Validation loss: 2.522820718406266

Epoch: 6| Step: 6
Training loss: 2.9558803077179374
Validation loss: 2.5393566098190035

Epoch: 6| Step: 7
Training loss: 2.9151929856242136
Validation loss: 2.5407626014941975

Epoch: 6| Step: 8
Training loss: 2.9139116263515135
Validation loss: 2.5295225351196047

Epoch: 6| Step: 9
Training loss: 3.2891813786785464
Validation loss: 2.5342661091875454

Epoch: 6| Step: 10
Training loss: 2.399146158603981
Validation loss: 2.5262515800460457

Epoch: 6| Step: 11
Training loss: 2.7669907985157893
Validation loss: 2.533315904524434

Epoch: 6| Step: 12
Training loss: 2.801117816957205
Validation loss: 2.5402104294229817

Epoch: 6| Step: 13
Training loss: 2.8766038816045905
Validation loss: 2.5860555892176738

Epoch: 336| Step: 0
Training loss: 3.1750030878006945
Validation loss: 2.595098558302848

Epoch: 6| Step: 1
Training loss: 2.774560491450012
Validation loss: 2.6137560169698038

Epoch: 6| Step: 2
Training loss: 2.83699894316865
Validation loss: 2.593606928351053

Epoch: 6| Step: 3
Training loss: 2.1173904152789897
Validation loss: 2.5649636983422504

Epoch: 6| Step: 4
Training loss: 2.2825096519575325
Validation loss: 2.5419614900945504

Epoch: 6| Step: 5
Training loss: 2.300507870868566
Validation loss: 2.532933313391137

Epoch: 6| Step: 6
Training loss: 3.379502295694081
Validation loss: 2.5316820989933917

Epoch: 6| Step: 7
Training loss: 2.87482916282935
Validation loss: 2.547186947084999

Epoch: 6| Step: 8
Training loss: 2.1297549734531063
Validation loss: 2.54591185633265

Epoch: 6| Step: 9
Training loss: 2.4290179835816343
Validation loss: 2.5785394369654555

Epoch: 6| Step: 10
Training loss: 3.230096465757731
Validation loss: 2.5897417871404294

Epoch: 6| Step: 11
Training loss: 2.091057027702264
Validation loss: 2.6233329274595407

Epoch: 6| Step: 12
Training loss: 2.5518988925432904
Validation loss: 2.6585631479094314

Epoch: 6| Step: 13
Training loss: 3.6582312799236885
Validation loss: 2.6506291118480383

Epoch: 337| Step: 0
Training loss: 2.581649775177885
Validation loss: 2.645354321479938

Epoch: 6| Step: 1
Training loss: 2.5945425086737712
Validation loss: 2.6256311949830176

Epoch: 6| Step: 2
Training loss: 2.921603103471426
Validation loss: 2.5801733725248295

Epoch: 6| Step: 3
Training loss: 2.295741417828179
Validation loss: 2.5608515055240293

Epoch: 6| Step: 4
Training loss: 2.0915157866551324
Validation loss: 2.5361988057571945

Epoch: 6| Step: 5
Training loss: 2.918308958267325
Validation loss: 2.5245086023219803

Epoch: 6| Step: 6
Training loss: 2.647141491153851
Validation loss: 2.518687909980674

Epoch: 6| Step: 7
Training loss: 2.605294880934973
Validation loss: 2.512811752786836

Epoch: 6| Step: 8
Training loss: 2.720740280390586
Validation loss: 2.4952118787498603

Epoch: 6| Step: 9
Training loss: 3.3743214808213837
Validation loss: 2.5036106963843614

Epoch: 6| Step: 10
Training loss: 2.625054222636829
Validation loss: 2.4968801864263575

Epoch: 6| Step: 11
Training loss: 2.71976013710762
Validation loss: 2.5202155505830253

Epoch: 6| Step: 12
Training loss: 2.6322076029022883
Validation loss: 2.505240640838496

Epoch: 6| Step: 13
Training loss: 2.572274708424072
Validation loss: 2.521561845751047

Epoch: 338| Step: 0
Training loss: 2.894254478164455
Validation loss: 2.505513007919885

Epoch: 6| Step: 1
Training loss: 2.565333869576481
Validation loss: 2.5420104889799844

Epoch: 6| Step: 2
Training loss: 2.904456456821192
Validation loss: 2.566606070649261

Epoch: 6| Step: 3
Training loss: 3.173330189305305
Validation loss: 2.5947408482357086

Epoch: 6| Step: 4
Training loss: 2.6860328040488017
Validation loss: 2.616763460853503

Epoch: 6| Step: 5
Training loss: 2.525384110798588
Validation loss: 2.5933607995259345

Epoch: 6| Step: 6
Training loss: 1.9624250021046659
Validation loss: 2.5833602061016854

Epoch: 6| Step: 7
Training loss: 2.4541398397208893
Validation loss: 2.5628333796533487

Epoch: 6| Step: 8
Training loss: 2.855060261158884
Validation loss: 2.522410730535095

Epoch: 6| Step: 9
Training loss: 3.0783791993804503
Validation loss: 2.543469546754316

Epoch: 6| Step: 10
Training loss: 2.70507741990063
Validation loss: 2.516597254449934

Epoch: 6| Step: 11
Training loss: 2.2510648962467203
Validation loss: 2.5203675131479177

Epoch: 6| Step: 12
Training loss: 2.466640295282933
Validation loss: 2.505917718833289

Epoch: 6| Step: 13
Training loss: 2.7822879183301357
Validation loss: 2.5070956060390053

Epoch: 339| Step: 0
Training loss: 2.7493196859690103
Validation loss: 2.5083714717306345

Epoch: 6| Step: 1
Training loss: 2.6808740418955757
Validation loss: 2.521238272298194

Epoch: 6| Step: 2
Training loss: 2.6199215401119886
Validation loss: 2.5270982108151507

Epoch: 6| Step: 3
Training loss: 2.3901729779712646
Validation loss: 2.548734116100442

Epoch: 6| Step: 4
Training loss: 2.745375993892158
Validation loss: 2.565084470668391

Epoch: 6| Step: 5
Training loss: 2.7426568740864012
Validation loss: 2.5884087911961235

Epoch: 6| Step: 6
Training loss: 2.7388783890800403
Validation loss: 2.6052579349698517

Epoch: 6| Step: 7
Training loss: 2.863943317470441
Validation loss: 2.6059659751038557

Epoch: 6| Step: 8
Training loss: 2.5909414137264455
Validation loss: 2.5903963225734468

Epoch: 6| Step: 9
Training loss: 2.559226201055496
Validation loss: 2.5828794291649837

Epoch: 6| Step: 10
Training loss: 2.683517965832
Validation loss: 2.572811167557097

Epoch: 6| Step: 11
Training loss: 2.7887810744089334
Validation loss: 2.578090335616635

Epoch: 6| Step: 12
Training loss: 2.680091582768919
Validation loss: 2.596403360782746

Epoch: 6| Step: 13
Training loss: 2.5876097098417934
Validation loss: 2.5679878309552095

Epoch: 340| Step: 0
Training loss: 2.1198319814786517
Validation loss: 2.609315481103349

Epoch: 6| Step: 1
Training loss: 2.5819760315223603
Validation loss: 2.6153091059369284

Epoch: 6| Step: 2
Training loss: 2.6871959603011533
Validation loss: 2.6013018572282784

Epoch: 6| Step: 3
Training loss: 3.0425804194006947
Validation loss: 2.6136474607842395

Epoch: 6| Step: 4
Training loss: 2.664771558979841
Validation loss: 2.6272354061533894

Epoch: 6| Step: 5
Training loss: 2.655612285580884
Validation loss: 2.6232486953520313

Epoch: 6| Step: 6
Training loss: 3.045907673970045
Validation loss: 2.539472026502763

Epoch: 6| Step: 7
Training loss: 3.1771822721157474
Validation loss: 2.5313891412210765

Epoch: 6| Step: 8
Training loss: 2.091686655483508
Validation loss: 2.495148234156856

Epoch: 6| Step: 9
Training loss: 2.2735056653897043
Validation loss: 2.4828413996439487

Epoch: 6| Step: 10
Training loss: 2.7818520569396243
Validation loss: 2.4845653081046373

Epoch: 6| Step: 11
Training loss: 3.324217889339636
Validation loss: 2.4806241674796476

Epoch: 6| Step: 12
Training loss: 2.3998633504748033
Validation loss: 2.4773076478403286

Epoch: 6| Step: 13
Training loss: 2.6267823117676743
Validation loss: 2.4814159220152163

Epoch: 341| Step: 0
Training loss: 2.9321963541498293
Validation loss: 2.4894516883863806

Epoch: 6| Step: 1
Training loss: 2.965581548310168
Validation loss: 2.493728509469512

Epoch: 6| Step: 2
Training loss: 2.1756188487837442
Validation loss: 2.5159374856465164

Epoch: 6| Step: 3
Training loss: 2.2898993410867585
Validation loss: 2.5215357746964044

Epoch: 6| Step: 4
Training loss: 2.7909201197904734
Validation loss: 2.532667312428007

Epoch: 6| Step: 5
Training loss: 2.632626309022795
Validation loss: 2.5563652573206537

Epoch: 6| Step: 6
Training loss: 2.9436367134600827
Validation loss: 2.541610768263461

Epoch: 6| Step: 7
Training loss: 2.8645130125720035
Validation loss: 2.5995139461230865

Epoch: 6| Step: 8
Training loss: 2.6860260581018656
Validation loss: 2.6274560024558262

Epoch: 6| Step: 9
Training loss: 2.08176877083166
Validation loss: 2.6578567384199054

Epoch: 6| Step: 10
Training loss: 2.5976557910890103
Validation loss: 2.669982454817534

Epoch: 6| Step: 11
Training loss: 2.4189863143729307
Validation loss: 2.6472357948351632

Epoch: 6| Step: 12
Training loss: 2.8109056828274164
Validation loss: 2.6148174144987677

Epoch: 6| Step: 13
Training loss: 3.215894006092684
Validation loss: 2.6049314266070485

Epoch: 342| Step: 0
Training loss: 3.08622149355807
Validation loss: 2.5763031678700683

Epoch: 6| Step: 1
Training loss: 2.525232957725622
Validation loss: 2.5199447314174845

Epoch: 6| Step: 2
Training loss: 2.6642222426504967
Validation loss: 2.500244226626743

Epoch: 6| Step: 3
Training loss: 2.5882873000820665
Validation loss: 2.5113688617728083

Epoch: 6| Step: 4
Training loss: 2.2692733329202928
Validation loss: 2.487621182026111

Epoch: 6| Step: 5
Training loss: 1.7163039401386058
Validation loss: 2.508079249089439

Epoch: 6| Step: 6
Training loss: 2.5654177917739047
Validation loss: 2.5009887196327356

Epoch: 6| Step: 7
Training loss: 2.7624015341769104
Validation loss: 2.503296165057112

Epoch: 6| Step: 8
Training loss: 2.177008072375084
Validation loss: 2.4919822501113003

Epoch: 6| Step: 9
Training loss: 3.4302683275438084
Validation loss: 2.513333130540783

Epoch: 6| Step: 10
Training loss: 2.6110843382019686
Validation loss: 2.5272648557750985

Epoch: 6| Step: 11
Training loss: 2.728257753478451
Validation loss: 2.5295695980222193

Epoch: 6| Step: 12
Training loss: 2.8226402588451247
Validation loss: 2.5600763229608

Epoch: 6| Step: 13
Training loss: 3.3098271940824193
Validation loss: 2.574804604700571

Epoch: 343| Step: 0
Training loss: 2.5046919662616625
Validation loss: 2.5798965925184127

Epoch: 6| Step: 1
Training loss: 2.1376724485914678
Validation loss: 2.614059527815413

Epoch: 6| Step: 2
Training loss: 2.3216027163068365
Validation loss: 2.621528554824496

Epoch: 6| Step: 3
Training loss: 2.9689003354205337
Validation loss: 2.6114222651265986

Epoch: 6| Step: 4
Training loss: 2.688085181822307
Validation loss: 2.636950889222019

Epoch: 6| Step: 5
Training loss: 2.2896008167750557
Validation loss: 2.617545410328686

Epoch: 6| Step: 6
Training loss: 2.0805755163824546
Validation loss: 2.6061665193039256

Epoch: 6| Step: 7
Training loss: 2.7321170748679333
Validation loss: 2.5937805816432906

Epoch: 6| Step: 8
Training loss: 3.0968827848981366
Validation loss: 2.545490082875727

Epoch: 6| Step: 9
Training loss: 2.7355316331638426
Validation loss: 2.5333494966581775

Epoch: 6| Step: 10
Training loss: 2.8100784049176757
Validation loss: 2.5255382868912153

Epoch: 6| Step: 11
Training loss: 3.0831731462537544
Validation loss: 2.5190216177340337

Epoch: 6| Step: 12
Training loss: 2.948171184502332
Validation loss: 2.513329742044515

Epoch: 6| Step: 13
Training loss: 2.2345971483890286
Validation loss: 2.4847140615801835

Epoch: 344| Step: 0
Training loss: 2.805020198375309
Validation loss: 2.499781663651135

Epoch: 6| Step: 1
Training loss: 2.717593769326197
Validation loss: 2.4960093025859655

Epoch: 6| Step: 2
Training loss: 2.579364270686394
Validation loss: 2.5017449431796845

Epoch: 6| Step: 3
Training loss: 2.7335297068169093
Validation loss: 2.516883025485006

Epoch: 6| Step: 4
Training loss: 2.568200260933954
Validation loss: 2.5440812099382923

Epoch: 6| Step: 5
Training loss: 2.3697767543672867
Validation loss: 2.5637261593237857

Epoch: 6| Step: 6
Training loss: 2.736573387334306
Validation loss: 2.595067092717666

Epoch: 6| Step: 7
Training loss: 2.777832589138523
Validation loss: 2.621872163002237

Epoch: 6| Step: 8
Training loss: 2.627939939390306
Validation loss: 2.6437343759374947

Epoch: 6| Step: 9
Training loss: 2.7291060773418607
Validation loss: 2.6804421467627324

Epoch: 6| Step: 10
Training loss: 2.0813480709213152
Validation loss: 2.7249453927219265

Epoch: 6| Step: 11
Training loss: 3.2924413292595225
Validation loss: 2.7778694307595466

Epoch: 6| Step: 12
Training loss: 2.7661980504028874
Validation loss: 2.718448542523946

Epoch: 6| Step: 13
Training loss: 2.806116786590129
Validation loss: 2.618393463346463

Epoch: 345| Step: 0
Training loss: 2.214713710082401
Validation loss: 2.521646619803998

Epoch: 6| Step: 1
Training loss: 2.5590173268776932
Validation loss: 2.4762179216918523

Epoch: 6| Step: 2
Training loss: 2.6629616708722392
Validation loss: 2.4618112320737153

Epoch: 6| Step: 3
Training loss: 2.0305667608427105
Validation loss: 2.4754821350414864

Epoch: 6| Step: 4
Training loss: 2.9458094817566898
Validation loss: 2.4875276951622163

Epoch: 6| Step: 5
Training loss: 2.497953244647519
Validation loss: 2.493037542232608

Epoch: 6| Step: 6
Training loss: 3.1991230597525364
Validation loss: 2.509552879313455

Epoch: 6| Step: 7
Training loss: 2.964074398131513
Validation loss: 2.503192359520142

Epoch: 6| Step: 8
Training loss: 2.611967706068815
Validation loss: 2.495692905190559

Epoch: 6| Step: 9
Training loss: 3.5642979418274274
Validation loss: 2.48920219209689

Epoch: 6| Step: 10
Training loss: 2.6909058746581107
Validation loss: 2.49034060968021

Epoch: 6| Step: 11
Training loss: 2.4371703487398775
Validation loss: 2.4778525215674296

Epoch: 6| Step: 12
Training loss: 2.859596785818906
Validation loss: 2.480470005739498

Epoch: 6| Step: 13
Training loss: 2.936924979561325
Validation loss: 2.4903682168810954

Epoch: 346| Step: 0
Training loss: 3.1327650109399414
Validation loss: 2.5046356681170145

Epoch: 6| Step: 1
Training loss: 2.556864612812809
Validation loss: 2.541943103544778

Epoch: 6| Step: 2
Training loss: 2.7045615904627582
Validation loss: 2.6216144141525017

Epoch: 6| Step: 3
Training loss: 3.330258540750581
Validation loss: 2.745951834156691

Epoch: 6| Step: 4
Training loss: 2.4503619919205764
Validation loss: 2.787908815328254

Epoch: 6| Step: 5
Training loss: 2.905442320459081
Validation loss: 2.8256375148031783

Epoch: 6| Step: 6
Training loss: 3.1197306648790564
Validation loss: 2.754919880069614

Epoch: 6| Step: 7
Training loss: 2.065330066487877
Validation loss: 2.6860911365035607

Epoch: 6| Step: 8
Training loss: 2.4041711323485613
Validation loss: 2.5953008228755534

Epoch: 6| Step: 9
Training loss: 2.4783948984646487
Validation loss: 2.5661497398861943

Epoch: 6| Step: 10
Training loss: 2.604007705923184
Validation loss: 2.547015134618974

Epoch: 6| Step: 11
Training loss: 2.857338435427332
Validation loss: 2.5157793033770854

Epoch: 6| Step: 12
Training loss: 2.4388401553306385
Validation loss: 2.501701070558205

Epoch: 6| Step: 13
Training loss: 2.860008461412838
Validation loss: 2.476266528781502

Epoch: 347| Step: 0
Training loss: 3.311559291635377
Validation loss: 2.4834552583689606

Epoch: 6| Step: 1
Training loss: 2.086310535464609
Validation loss: 2.4757342017209787

Epoch: 6| Step: 2
Training loss: 2.597065289040603
Validation loss: 2.470800496062173

Epoch: 6| Step: 3
Training loss: 2.6378066693682043
Validation loss: 2.475483963932766

Epoch: 6| Step: 4
Training loss: 2.577653969014901
Validation loss: 2.473115088247654

Epoch: 6| Step: 5
Training loss: 2.0585050328517243
Validation loss: 2.4803856217318176

Epoch: 6| Step: 6
Training loss: 2.407805101307784
Validation loss: 2.4868896289580693

Epoch: 6| Step: 7
Training loss: 2.7497858484287896
Validation loss: 2.508075213626295

Epoch: 6| Step: 8
Training loss: 2.7972853375557865
Validation loss: 2.5061300411898166

Epoch: 6| Step: 9
Training loss: 2.929958646306699
Validation loss: 2.5321240583966267

Epoch: 6| Step: 10
Training loss: 2.528252981975724
Validation loss: 2.552040601669355

Epoch: 6| Step: 11
Training loss: 3.0285043768130793
Validation loss: 2.561676245143004

Epoch: 6| Step: 12
Training loss: 2.356096022859235
Validation loss: 2.58363847753023

Epoch: 6| Step: 13
Training loss: 3.1230587842760733
Validation loss: 2.6208502220771592

Epoch: 348| Step: 0
Training loss: 3.225375273405697
Validation loss: 2.6332856342839466

Epoch: 6| Step: 1
Training loss: 2.9666633098740465
Validation loss: 2.616346400109637

Epoch: 6| Step: 2
Training loss: 2.3061492939286152
Validation loss: 2.5939413781645775

Epoch: 6| Step: 3
Training loss: 2.4635778401617703
Validation loss: 2.587018658812465

Epoch: 6| Step: 4
Training loss: 3.0496750705425444
Validation loss: 2.5752547837651134

Epoch: 6| Step: 5
Training loss: 2.32324588193275
Validation loss: 2.5679472604301026

Epoch: 6| Step: 6
Training loss: 2.3549206856818024
Validation loss: 2.54301299337414

Epoch: 6| Step: 7
Training loss: 2.8475330048775884
Validation loss: 2.534711733478087

Epoch: 6| Step: 8
Training loss: 3.018469857116402
Validation loss: 2.5302482181319585

Epoch: 6| Step: 9
Training loss: 2.2938453259525873
Validation loss: 2.548850236664068

Epoch: 6| Step: 10
Training loss: 2.5964134053952788
Validation loss: 2.567589310256191

Epoch: 6| Step: 11
Training loss: 2.5156403535172966
Validation loss: 2.5641087970034726

Epoch: 6| Step: 12
Training loss: 2.2837817631158472
Validation loss: 2.5790742411254715

Epoch: 6| Step: 13
Training loss: 1.9590041519946682
Validation loss: 2.562518266062009

Epoch: 349| Step: 0
Training loss: 2.0899922826159054
Validation loss: 2.5557933093838416

Epoch: 6| Step: 1
Training loss: 2.742462231385543
Validation loss: 2.5864824227058927

Epoch: 6| Step: 2
Training loss: 2.9913408560689803
Validation loss: 2.5823320723615533

Epoch: 6| Step: 3
Training loss: 2.2628119532881215
Validation loss: 2.5492161646949367

Epoch: 6| Step: 4
Training loss: 3.0416346160732903
Validation loss: 2.5577412219267943

Epoch: 6| Step: 5
Training loss: 2.209073848244619
Validation loss: 2.53731207473749

Epoch: 6| Step: 6
Training loss: 2.5306103687047123
Validation loss: 2.5428959015523858

Epoch: 6| Step: 7
Training loss: 2.2785994926463458
Validation loss: 2.510725021231827

Epoch: 6| Step: 8
Training loss: 2.404108754413089
Validation loss: 2.5012051210579846

Epoch: 6| Step: 9
Training loss: 2.85383427673026
Validation loss: 2.5443223090791935

Epoch: 6| Step: 10
Training loss: 2.839725539149041
Validation loss: 2.522615423347781

Epoch: 6| Step: 11
Training loss: 3.2177531356055296
Validation loss: 2.537169611685151

Epoch: 6| Step: 12
Training loss: 2.0200598373615066
Validation loss: 2.5819208754106606

Epoch: 6| Step: 13
Training loss: 3.179089089209956
Validation loss: 2.6245897483282015

Epoch: 350| Step: 0
Training loss: 3.4667242509998837
Validation loss: 2.6395072447488035

Epoch: 6| Step: 1
Training loss: 3.0920366879812047
Validation loss: 2.6473579235544955

Epoch: 6| Step: 2
Training loss: 2.706840563466761
Validation loss: 2.6466653339467046

Epoch: 6| Step: 3
Training loss: 2.466637588879454
Validation loss: 2.6387963819741795

Epoch: 6| Step: 4
Training loss: 2.839864066994466
Validation loss: 2.605700094959474

Epoch: 6| Step: 5
Training loss: 2.7423789454739134
Validation loss: 2.573009547247294

Epoch: 6| Step: 6
Training loss: 2.8198214708455227
Validation loss: 2.58215010661117

Epoch: 6| Step: 7
Training loss: 2.3923300851976403
Validation loss: 2.5685649463749995

Epoch: 6| Step: 8
Training loss: 1.869808958464194
Validation loss: 2.5698214688812966

Epoch: 6| Step: 9
Training loss: 2.2583272274633917
Validation loss: 2.5526704753612854

Epoch: 6| Step: 10
Training loss: 2.220519528813975
Validation loss: 2.5565258179491153

Epoch: 6| Step: 11
Training loss: 2.5824874498001424
Validation loss: 2.525689387180485

Epoch: 6| Step: 12
Training loss: 2.4057317398584983
Validation loss: 2.531393867677188

Epoch: 6| Step: 13
Training loss: 2.5227118709572065
Validation loss: 2.522489106828485

Epoch: 351| Step: 0
Training loss: 3.1229227409956892
Validation loss: 2.5578019830293317

Epoch: 6| Step: 1
Training loss: 2.527836605640419
Validation loss: 2.612739178989461

Epoch: 6| Step: 2
Training loss: 2.8325859841934404
Validation loss: 2.608842551386054

Epoch: 6| Step: 3
Training loss: 2.606251108731919
Validation loss: 2.563453316906893

Epoch: 6| Step: 4
Training loss: 2.904693514862317
Validation loss: 2.535815738695134

Epoch: 6| Step: 5
Training loss: 2.905864566962948
Validation loss: 2.509789213606998

Epoch: 6| Step: 6
Training loss: 2.3322451188311066
Validation loss: 2.5177951227483972

Epoch: 6| Step: 7
Training loss: 2.9150712872486
Validation loss: 2.506307227927429

Epoch: 6| Step: 8
Training loss: 2.080905746077909
Validation loss: 2.506499873015153

Epoch: 6| Step: 9
Training loss: 2.714729141999733
Validation loss: 2.5609164914021845

Epoch: 6| Step: 10
Training loss: 2.4035812044116946
Validation loss: 2.5694897831053427

Epoch: 6| Step: 11
Training loss: 2.586691017658932
Validation loss: 2.6033995202694187

Epoch: 6| Step: 12
Training loss: 2.25307466448087
Validation loss: 2.6151443276382755

Epoch: 6| Step: 13
Training loss: 2.3604933759632347
Validation loss: 2.627334623993084

Epoch: 352| Step: 0
Training loss: 2.865383484957841
Validation loss: 2.578740644734588

Epoch: 6| Step: 1
Training loss: 2.6199714088335906
Validation loss: 2.5382827659552945

Epoch: 6| Step: 2
Training loss: 2.0592794995313146
Validation loss: 2.514448832192079

Epoch: 6| Step: 3
Training loss: 2.2241703501166206
Validation loss: 2.4869814368861864

Epoch: 6| Step: 4
Training loss: 2.210085215932211
Validation loss: 2.4902143845227305

Epoch: 6| Step: 5
Training loss: 2.238681298101133
Validation loss: 2.4704624803159527

Epoch: 6| Step: 6
Training loss: 3.1456111972687157
Validation loss: 2.4754204801096655

Epoch: 6| Step: 7
Training loss: 2.468891574325192
Validation loss: 2.4928200774938225

Epoch: 6| Step: 8
Training loss: 2.5787440626008564
Validation loss: 2.493532768001287

Epoch: 6| Step: 9
Training loss: 2.9705180474789157
Validation loss: 2.5483327076490774

Epoch: 6| Step: 10
Training loss: 2.9751210164051916
Validation loss: 2.583688763775981

Epoch: 6| Step: 11
Training loss: 2.9704978214828035
Validation loss: 2.6022268398786963

Epoch: 6| Step: 12
Training loss: 1.9011370769927027
Validation loss: 2.6304245999484017

Epoch: 6| Step: 13
Training loss: 3.58977839729006
Validation loss: 2.63384777236063

Epoch: 353| Step: 0
Training loss: 2.6443255075409198
Validation loss: 2.6312122785673155

Epoch: 6| Step: 1
Training loss: 2.626595874871614
Validation loss: 2.6225415528302354

Epoch: 6| Step: 2
Training loss: 2.2092998356962705
Validation loss: 2.628142138022602

Epoch: 6| Step: 3
Training loss: 2.7950419807352205
Validation loss: 2.59087181594396

Epoch: 6| Step: 4
Training loss: 2.6856751567372905
Validation loss: 2.6050174693323185

Epoch: 6| Step: 5
Training loss: 2.5651257715751528
Validation loss: 2.6074939776345647

Epoch: 6| Step: 6
Training loss: 2.8343279345725403
Validation loss: 2.5961383192506484

Epoch: 6| Step: 7
Training loss: 3.05743238048374
Validation loss: 2.61425160505389

Epoch: 6| Step: 8
Training loss: 2.7716634744919015
Validation loss: 2.5950588477752543

Epoch: 6| Step: 9
Training loss: 2.160427745568743
Validation loss: 2.55766155937073

Epoch: 6| Step: 10
Training loss: 2.200875940205355
Validation loss: 2.564083033578828

Epoch: 6| Step: 11
Training loss: 3.0429831664854263
Validation loss: 2.552280940897304

Epoch: 6| Step: 12
Training loss: 2.5104449469739643
Validation loss: 2.565557085429125

Epoch: 6| Step: 13
Training loss: 1.762065980106736
Validation loss: 2.558466914168314

Epoch: 354| Step: 0
Training loss: 3.001728513575781
Validation loss: 2.573860757157447

Epoch: 6| Step: 1
Training loss: 2.372951025263341
Validation loss: 2.576537770368829

Epoch: 6| Step: 2
Training loss: 2.5192014493148864
Validation loss: 2.555484733258564

Epoch: 6| Step: 3
Training loss: 2.3893394254829587
Validation loss: 2.537287904394395

Epoch: 6| Step: 4
Training loss: 2.8845067615109086
Validation loss: 2.537909745137355

Epoch: 6| Step: 5
Training loss: 3.139301381722246
Validation loss: 2.557071811090682

Epoch: 6| Step: 6
Training loss: 2.9538224622803373
Validation loss: 2.569374657189178

Epoch: 6| Step: 7
Training loss: 2.782605130385105
Validation loss: 2.614392985054865

Epoch: 6| Step: 8
Training loss: 2.817905741114863
Validation loss: 2.6569734074481355

Epoch: 6| Step: 9
Training loss: 1.922779459688811
Validation loss: 2.6749775040402928

Epoch: 6| Step: 10
Training loss: 2.5794825823129828
Validation loss: 2.6183643822789784

Epoch: 6| Step: 11
Training loss: 2.230869130343865
Validation loss: 2.5786712018173428

Epoch: 6| Step: 12
Training loss: 2.52110120963124
Validation loss: 2.556619645630073

Epoch: 6| Step: 13
Training loss: 1.7986130642808729
Validation loss: 2.5363319323195883

Epoch: 355| Step: 0
Training loss: 2.607193634673428
Validation loss: 2.5315397839330123

Epoch: 6| Step: 1
Training loss: 2.429727633718223
Validation loss: 2.4888002043748694

Epoch: 6| Step: 2
Training loss: 2.991560190443588
Validation loss: 2.497026028182026

Epoch: 6| Step: 3
Training loss: 2.243886589631955
Validation loss: 2.483122345940838

Epoch: 6| Step: 4
Training loss: 2.6526398303884346
Validation loss: 2.4731650779633565

Epoch: 6| Step: 5
Training loss: 2.6386637429903375
Validation loss: 2.4873788084833555

Epoch: 6| Step: 6
Training loss: 2.5463153247571797
Validation loss: 2.4820729117359837

Epoch: 6| Step: 7
Training loss: 2.5381667214923667
Validation loss: 2.4912020586329047

Epoch: 6| Step: 8
Training loss: 2.5163921821246014
Validation loss: 2.5394418685122524

Epoch: 6| Step: 9
Training loss: 2.747384821913409
Validation loss: 2.5250838515261194

Epoch: 6| Step: 10
Training loss: 2.4135959013826027
Validation loss: 2.579193496412143

Epoch: 6| Step: 11
Training loss: 2.686856836052153
Validation loss: 2.6201605479110848

Epoch: 6| Step: 12
Training loss: 2.650581324891444
Validation loss: 2.6740438172855576

Epoch: 6| Step: 13
Training loss: 3.6322918918800267
Validation loss: 2.66715800337531

Epoch: 356| Step: 0
Training loss: 3.034502781417761
Validation loss: 2.647763275487391

Epoch: 6| Step: 1
Training loss: 2.181633630807947
Validation loss: 2.596144202663518

Epoch: 6| Step: 2
Training loss: 2.0362901805194134
Validation loss: 2.554498418688658

Epoch: 6| Step: 3
Training loss: 2.991750341607125
Validation loss: 2.535886242955269

Epoch: 6| Step: 4
Training loss: 2.9125326195719765
Validation loss: 2.518772564476008

Epoch: 6| Step: 5
Training loss: 2.0955165413795505
Validation loss: 2.5028630690061693

Epoch: 6| Step: 6
Training loss: 2.4349477072237224
Validation loss: 2.5073158606305563

Epoch: 6| Step: 7
Training loss: 2.749633417838661
Validation loss: 2.5055128298830978

Epoch: 6| Step: 8
Training loss: 3.08965269093637
Validation loss: 2.4987310060131933

Epoch: 6| Step: 9
Training loss: 2.2218578225288663
Validation loss: 2.512378514944006

Epoch: 6| Step: 10
Training loss: 2.670313507133459
Validation loss: 2.5278718435337493

Epoch: 6| Step: 11
Training loss: 2.52935428038741
Validation loss: 2.5381328133357717

Epoch: 6| Step: 12
Training loss: 2.6727650370197593
Validation loss: 2.521929541626509

Epoch: 6| Step: 13
Training loss: 2.9161246931524007
Validation loss: 2.5509607872838145

Epoch: 357| Step: 0
Training loss: 2.933408119230893
Validation loss: 2.559781925747186

Epoch: 6| Step: 1
Training loss: 2.415422371364102
Validation loss: 2.578940559429348

Epoch: 6| Step: 2
Training loss: 2.3764497448057686
Validation loss: 2.5861604571696213

Epoch: 6| Step: 3
Training loss: 2.3782046932547245
Validation loss: 2.5868566753339954

Epoch: 6| Step: 4
Training loss: 2.5634949776124274
Validation loss: 2.5885730747362503

Epoch: 6| Step: 5
Training loss: 2.6960447339554685
Validation loss: 2.5705676432941806

Epoch: 6| Step: 6
Training loss: 2.8011753544528486
Validation loss: 2.5891249580455997

Epoch: 6| Step: 7
Training loss: 2.7220910250476598
Validation loss: 2.542547214295655

Epoch: 6| Step: 8
Training loss: 2.5458104067538554
Validation loss: 2.5631435135512577

Epoch: 6| Step: 9
Training loss: 2.023475676069645
Validation loss: 2.548425742487566

Epoch: 6| Step: 10
Training loss: 2.4915997520656097
Validation loss: 2.54602093433776

Epoch: 6| Step: 11
Training loss: 2.60226238562152
Validation loss: 2.543725729133632

Epoch: 6| Step: 12
Training loss: 2.7645791010379854
Validation loss: 2.54335217708636

Epoch: 6| Step: 13
Training loss: 2.796074864679997
Validation loss: 2.5404501410427547

Epoch: 358| Step: 0
Training loss: 2.81464846460603
Validation loss: 2.537923354698427

Epoch: 6| Step: 1
Training loss: 3.071217954264271
Validation loss: 2.550018915737191

Epoch: 6| Step: 2
Training loss: 2.6567057499070827
Validation loss: 2.540319663432045

Epoch: 6| Step: 3
Training loss: 1.940103258649029
Validation loss: 2.5754298128499675

Epoch: 6| Step: 4
Training loss: 2.7462435989409464
Validation loss: 2.589018756560467

Epoch: 6| Step: 5
Training loss: 2.3200984560694216
Validation loss: 2.620906656088222

Epoch: 6| Step: 6
Training loss: 2.0819615107266554
Validation loss: 2.6363769873684357

Epoch: 6| Step: 7
Training loss: 2.631468659147805
Validation loss: 2.655858956301307

Epoch: 6| Step: 8
Training loss: 2.5754317579046866
Validation loss: 2.6500465799155157

Epoch: 6| Step: 9
Training loss: 2.653334869243746
Validation loss: 2.6370359017805463

Epoch: 6| Step: 10
Training loss: 1.749490868212342
Validation loss: 2.58954901753487

Epoch: 6| Step: 11
Training loss: 2.780200888970476
Validation loss: 2.5484351774656426

Epoch: 6| Step: 12
Training loss: 3.220469487716578
Validation loss: 2.536615826732756

Epoch: 6| Step: 13
Training loss: 2.640382654028083
Validation loss: 2.5201479404547076

Epoch: 359| Step: 0
Training loss: 2.9934551053953653
Validation loss: 2.497513813063253

Epoch: 6| Step: 1
Training loss: 2.8193677339521512
Validation loss: 2.5125026118612306

Epoch: 6| Step: 2
Training loss: 1.884574856764005
Validation loss: 2.483563377842564

Epoch: 6| Step: 3
Training loss: 3.1774298973964243
Validation loss: 2.4958026505760036

Epoch: 6| Step: 4
Training loss: 2.9245188781995086
Validation loss: 2.5006893130564634

Epoch: 6| Step: 5
Training loss: 3.0932086509481995
Validation loss: 2.508013699607659

Epoch: 6| Step: 6
Training loss: 2.15844603677522
Validation loss: 2.5501436705775626

Epoch: 6| Step: 7
Training loss: 2.4404836147253017
Validation loss: 2.5642267847419324

Epoch: 6| Step: 8
Training loss: 2.297009107346638
Validation loss: 2.6119951780486046

Epoch: 6| Step: 9
Training loss: 2.836701261381904
Validation loss: 2.6929098245767364

Epoch: 6| Step: 10
Training loss: 2.93691718630337
Validation loss: 2.670911830142567

Epoch: 6| Step: 11
Training loss: 2.4579995677689994
Validation loss: 2.6121082517953025

Epoch: 6| Step: 12
Training loss: 2.179062839268962
Validation loss: 2.550726402293676

Epoch: 6| Step: 13
Training loss: 1.4667889916097656
Validation loss: 2.5186471876016547

Epoch: 360| Step: 0
Training loss: 2.2813742616855093
Validation loss: 2.48928707229208

Epoch: 6| Step: 1
Training loss: 2.4766526070457133
Validation loss: 2.4880393096362745

Epoch: 6| Step: 2
Training loss: 2.668542758301028
Validation loss: 2.473215299895073

Epoch: 6| Step: 3
Training loss: 2.1811599406803284
Validation loss: 2.4558852419340123

Epoch: 6| Step: 4
Training loss: 2.886950988099803
Validation loss: 2.455219635646865

Epoch: 6| Step: 5
Training loss: 2.543558031941286
Validation loss: 2.4687289777976744

Epoch: 6| Step: 6
Training loss: 2.4507003756243244
Validation loss: 2.483055533643547

Epoch: 6| Step: 7
Training loss: 2.5345743272621264
Validation loss: 2.4709737836740397

Epoch: 6| Step: 8
Training loss: 2.041550561626802
Validation loss: 2.4813445354089634

Epoch: 6| Step: 9
Training loss: 3.002805034252219
Validation loss: 2.5314886947056987

Epoch: 6| Step: 10
Training loss: 2.7299211250341044
Validation loss: 2.5764761546042823

Epoch: 6| Step: 11
Training loss: 2.4092812209426517
Validation loss: 2.6837750724825944

Epoch: 6| Step: 12
Training loss: 3.493761770266119
Validation loss: 2.755859437326809

Epoch: 6| Step: 13
Training loss: 2.6115284331481274
Validation loss: 2.7725108642507292

Epoch: 361| Step: 0
Training loss: 2.458609894104626
Validation loss: 2.776170171022757

Epoch: 6| Step: 1
Training loss: 2.4978662922170085
Validation loss: 2.7640152850077393

Epoch: 6| Step: 2
Training loss: 2.2636181592122226
Validation loss: 2.7198746038075376

Epoch: 6| Step: 3
Training loss: 2.6638602350590226
Validation loss: 2.674680052852045

Epoch: 6| Step: 4
Training loss: 2.4603340498974853
Validation loss: 2.574288535102339

Epoch: 6| Step: 5
Training loss: 2.674663315735097
Validation loss: 2.505383917696168

Epoch: 6| Step: 6
Training loss: 2.689925585146453
Validation loss: 2.4694908352451455

Epoch: 6| Step: 7
Training loss: 2.860516263075741
Validation loss: 2.4663822382022444

Epoch: 6| Step: 8
Training loss: 2.485455356071874
Validation loss: 2.452777126987306

Epoch: 6| Step: 9
Training loss: 2.4069933052873242
Validation loss: 2.4527699893117383

Epoch: 6| Step: 10
Training loss: 2.7260180260334446
Validation loss: 2.4458918459988324

Epoch: 6| Step: 11
Training loss: 2.797438410267637
Validation loss: 2.460494065004895

Epoch: 6| Step: 12
Training loss: 3.1052365774060045
Validation loss: 2.4752869526782906

Epoch: 6| Step: 13
Training loss: 2.6389613582185887
Validation loss: 2.5028195775629163

Epoch: 362| Step: 0
Training loss: 2.807892649530359
Validation loss: 2.5345853744907276

Epoch: 6| Step: 1
Training loss: 2.689072614580956
Validation loss: 2.5716005413045364

Epoch: 6| Step: 2
Training loss: 2.4499941728483696
Validation loss: 2.5910579935908937

Epoch: 6| Step: 3
Training loss: 2.2142464506825683
Validation loss: 2.648606275888847

Epoch: 6| Step: 4
Training loss: 2.656476717978462
Validation loss: 2.645389812975504

Epoch: 6| Step: 5
Training loss: 2.315483025073666
Validation loss: 2.6049241557041545

Epoch: 6| Step: 6
Training loss: 2.980990902819952
Validation loss: 2.5792888282889064

Epoch: 6| Step: 7
Training loss: 2.7036871353156577
Validation loss: 2.5713598493355785

Epoch: 6| Step: 8
Training loss: 2.2594727216721315
Validation loss: 2.52721139008703

Epoch: 6| Step: 9
Training loss: 2.4299006230633933
Validation loss: 2.4875378506524664

Epoch: 6| Step: 10
Training loss: 3.1709659570402216
Validation loss: 2.479555333411594

Epoch: 6| Step: 11
Training loss: 2.130084070686732
Validation loss: 2.470385481041811

Epoch: 6| Step: 12
Training loss: 2.3457186759541244
Validation loss: 2.4667891356267444

Epoch: 6| Step: 13
Training loss: 2.738172586110694
Validation loss: 2.4715999676098255

Epoch: 363| Step: 0
Training loss: 2.9431414710211987
Validation loss: 2.4721370177061477

Epoch: 6| Step: 1
Training loss: 2.122997686944565
Validation loss: 2.4826036121782056

Epoch: 6| Step: 2
Training loss: 2.444749468740056
Validation loss: 2.492044807952672

Epoch: 6| Step: 3
Training loss: 2.6579228238683643
Validation loss: 2.5215953423345834

Epoch: 6| Step: 4
Training loss: 2.543933316310487
Validation loss: 2.5406462959404363

Epoch: 6| Step: 5
Training loss: 2.7044883332948544
Validation loss: 2.6041876679260705

Epoch: 6| Step: 6
Training loss: 3.043326321357373
Validation loss: 2.6435146124112836

Epoch: 6| Step: 7
Training loss: 2.8965818320590313
Validation loss: 2.675611640567279

Epoch: 6| Step: 8
Training loss: 3.140844233058668
Validation loss: 2.6499610492477412

Epoch: 6| Step: 9
Training loss: 2.2385296375868005
Validation loss: 2.632018001946034

Epoch: 6| Step: 10
Training loss: 1.8969386584992374
Validation loss: 2.62857696192596

Epoch: 6| Step: 11
Training loss: 1.925931170278457
Validation loss: 2.595934192709665

Epoch: 6| Step: 12
Training loss: 2.9521471453230714
Validation loss: 2.5818237163696875

Epoch: 6| Step: 13
Training loss: 1.9972351752320823
Validation loss: 2.541108157965291

Epoch: 364| Step: 0
Training loss: 2.3376426979611957
Validation loss: 2.532054594488492

Epoch: 6| Step: 1
Training loss: 2.159835708869228
Validation loss: 2.5185580384295627

Epoch: 6| Step: 2
Training loss: 2.5031536238768455
Validation loss: 2.5340847719890722

Epoch: 6| Step: 3
Training loss: 2.524585285688637
Validation loss: 2.543544442450269

Epoch: 6| Step: 4
Training loss: 2.4572908055162612
Validation loss: 2.517220259023789

Epoch: 6| Step: 5
Training loss: 2.5932907249395734
Validation loss: 2.530360021982683

Epoch: 6| Step: 6
Training loss: 2.663541860410116
Validation loss: 2.5689835690941307

Epoch: 6| Step: 7
Training loss: 2.903954696764289
Validation loss: 2.5909547566004956

Epoch: 6| Step: 8
Training loss: 2.651780081225087
Validation loss: 2.6215424989238407

Epoch: 6| Step: 9
Training loss: 2.6784220117947437
Validation loss: 2.650071807510677

Epoch: 6| Step: 10
Training loss: 2.4458812503139247
Validation loss: 2.6343879921362054

Epoch: 6| Step: 11
Training loss: 2.7062869239032556
Validation loss: 2.623920369054464

Epoch: 6| Step: 12
Training loss: 2.5419805572630603
Validation loss: 2.6064121086835206

Epoch: 6| Step: 13
Training loss: 2.4439317016173776
Validation loss: 2.573767088861069

Epoch: 365| Step: 0
Training loss: 2.4992109961000377
Validation loss: 2.542543386800487

Epoch: 6| Step: 1
Training loss: 2.5732551588857127
Validation loss: 2.5089282773566866

Epoch: 6| Step: 2
Training loss: 2.3115261192290104
Validation loss: 2.4995557677477342

Epoch: 6| Step: 3
Training loss: 2.2991299102968035
Validation loss: 2.4645039940644655

Epoch: 6| Step: 4
Training loss: 2.6114050911607682
Validation loss: 2.4653650320271088

Epoch: 6| Step: 5
Training loss: 2.7260715512620166
Validation loss: 2.4544762465975123

Epoch: 6| Step: 6
Training loss: 2.540075669250343
Validation loss: 2.4643368927685225

Epoch: 6| Step: 7
Training loss: 2.4304126503728805
Validation loss: 2.4868090719537683

Epoch: 6| Step: 8
Training loss: 2.4948450346928057
Validation loss: 2.5207408588736064

Epoch: 6| Step: 9
Training loss: 2.4835889040457797
Validation loss: 2.554505210901418

Epoch: 6| Step: 10
Training loss: 2.1675235325504905
Validation loss: 2.6296682320853066

Epoch: 6| Step: 11
Training loss: 3.1891340667305057
Validation loss: 2.674810994029809

Epoch: 6| Step: 12
Training loss: 2.8252295746820653
Validation loss: 2.687587611646477

Epoch: 6| Step: 13
Training loss: 2.8205542632483978
Validation loss: 2.656567746966388

Epoch: 366| Step: 0
Training loss: 1.743318404516093
Validation loss: 2.6459748815904796

Epoch: 6| Step: 1
Training loss: 1.8688914931197638
Validation loss: 2.5709178072300967

Epoch: 6| Step: 2
Training loss: 2.640639446151313
Validation loss: 2.5407648798251032

Epoch: 6| Step: 3
Training loss: 2.771945691846899
Validation loss: 2.515303246536444

Epoch: 6| Step: 4
Training loss: 2.4709327802110055
Validation loss: 2.4997946911257376

Epoch: 6| Step: 5
Training loss: 2.676950018466387
Validation loss: 2.4952729994566165

Epoch: 6| Step: 6
Training loss: 2.431938183820785
Validation loss: 2.4820688701407807

Epoch: 6| Step: 7
Training loss: 2.5971587428893526
Validation loss: 2.4900999833610142

Epoch: 6| Step: 8
Training loss: 2.4592942337288064
Validation loss: 2.4975009343356174

Epoch: 6| Step: 9
Training loss: 2.78397184764944
Validation loss: 2.520658358999233

Epoch: 6| Step: 10
Training loss: 3.3693223456427637
Validation loss: 2.5136077472631917

Epoch: 6| Step: 11
Training loss: 2.5943700210203704
Validation loss: 2.561974557368618

Epoch: 6| Step: 12
Training loss: 2.555529067920395
Validation loss: 2.5496109023188325

Epoch: 6| Step: 13
Training loss: 2.058783100837173
Validation loss: 2.564007487502431

Epoch: 367| Step: 0
Training loss: 2.4754952137592037
Validation loss: 2.5421453573542476

Epoch: 6| Step: 1
Training loss: 2.1744921168019755
Validation loss: 2.578342654032674

Epoch: 6| Step: 2
Training loss: 2.4985387346228283
Validation loss: 2.551587549654597

Epoch: 6| Step: 3
Training loss: 2.6317950809966484
Validation loss: 2.542198322905723

Epoch: 6| Step: 4
Training loss: 1.927604879650392
Validation loss: 2.5347491726800695

Epoch: 6| Step: 5
Training loss: 2.634437851704729
Validation loss: 2.5673803071558567

Epoch: 6| Step: 6
Training loss: 2.880171230047285
Validation loss: 2.5774832694075

Epoch: 6| Step: 7
Training loss: 2.433170287883959
Validation loss: 2.6022559111524934

Epoch: 6| Step: 8
Training loss: 2.2662163324480082
Validation loss: 2.6190603750664296

Epoch: 6| Step: 9
Training loss: 2.6022561554723715
Validation loss: 2.5997816146340536

Epoch: 6| Step: 10
Training loss: 2.463547451880815
Validation loss: 2.5631300709093177

Epoch: 6| Step: 11
Training loss: 2.4764867343805306
Validation loss: 2.5515165458433167

Epoch: 6| Step: 12
Training loss: 2.9663345951149513
Validation loss: 2.532339155710467

Epoch: 6| Step: 13
Training loss: 2.8298053280897704
Validation loss: 2.505310866627266

Epoch: 368| Step: 0
Training loss: 2.416876674165188
Validation loss: 2.5126508750423318

Epoch: 6| Step: 1
Training loss: 2.5761357811748424
Validation loss: 2.5101830206065223

Epoch: 6| Step: 2
Training loss: 2.8870167249374155
Validation loss: 2.5062263928527186

Epoch: 6| Step: 3
Training loss: 2.4716070519441335
Validation loss: 2.5040645925885925

Epoch: 6| Step: 4
Training loss: 2.5332323953530134
Validation loss: 2.514958740739465

Epoch: 6| Step: 5
Training loss: 2.3613341830722536
Validation loss: 2.5214298833656708

Epoch: 6| Step: 6
Training loss: 2.0428375727185806
Validation loss: 2.5398215094162517

Epoch: 6| Step: 7
Training loss: 2.7173498648096017
Validation loss: 2.592904662916833

Epoch: 6| Step: 8
Training loss: 2.6713818546753605
Validation loss: 2.6244790048012714

Epoch: 6| Step: 9
Training loss: 2.5383646314081125
Validation loss: 2.695530797658652

Epoch: 6| Step: 10
Training loss: 3.4956957372079436
Validation loss: 2.785354412759845

Epoch: 6| Step: 11
Training loss: 2.04100955067876
Validation loss: 2.735464306503291

Epoch: 6| Step: 12
Training loss: 1.9997817158788431
Validation loss: 2.6747675610984705

Epoch: 6| Step: 13
Training loss: 2.7763126567861915
Validation loss: 2.6225724409737134

Epoch: 369| Step: 0
Training loss: 3.0110343818538596
Validation loss: 2.537095735810987

Epoch: 6| Step: 1
Training loss: 1.8936297287219357
Validation loss: 2.5233362105733774

Epoch: 6| Step: 2
Training loss: 2.798174678658857
Validation loss: 2.4907702001054863

Epoch: 6| Step: 3
Training loss: 2.3639858235936213
Validation loss: 2.465929149043973

Epoch: 6| Step: 4
Training loss: 2.5043052795773706
Validation loss: 2.466088950802989

Epoch: 6| Step: 5
Training loss: 2.4226410669406424
Validation loss: 2.449304834738301

Epoch: 6| Step: 6
Training loss: 2.446713177432048
Validation loss: 2.453028617236762

Epoch: 6| Step: 7
Training loss: 2.7538433094813235
Validation loss: 2.454366226379693

Epoch: 6| Step: 8
Training loss: 2.4456731268312297
Validation loss: 2.4529512394933084

Epoch: 6| Step: 9
Training loss: 1.9179496686495134
Validation loss: 2.4807209548458955

Epoch: 6| Step: 10
Training loss: 2.257102775562762
Validation loss: 2.512780470364516

Epoch: 6| Step: 11
Training loss: 2.8243591358121676
Validation loss: 2.542458683845887

Epoch: 6| Step: 12
Training loss: 2.8923892024521725
Validation loss: 2.604275988509394

Epoch: 6| Step: 13
Training loss: 2.928222452697696
Validation loss: 2.5817456548465705

Epoch: 370| Step: 0
Training loss: 2.659616917007627
Validation loss: 2.6371623689919748

Epoch: 6| Step: 1
Training loss: 2.6420336696030047
Validation loss: 2.6268173954279077

Epoch: 6| Step: 2
Training loss: 2.639053057421634
Validation loss: 2.627957133093142

Epoch: 6| Step: 3
Training loss: 2.7246944291159814
Validation loss: 2.6295535911456005

Epoch: 6| Step: 4
Training loss: 2.7781176984281246
Validation loss: 2.614890311257886

Epoch: 6| Step: 5
Training loss: 2.6067078259170637
Validation loss: 2.5937806696091017

Epoch: 6| Step: 6
Training loss: 1.9954418454108724
Validation loss: 2.584287443092757

Epoch: 6| Step: 7
Training loss: 2.765396281122163
Validation loss: 2.533588300159919

Epoch: 6| Step: 8
Training loss: 2.3539052047246063
Validation loss: 2.5274006367911483

Epoch: 6| Step: 9
Training loss: 2.5162254232996246
Validation loss: 2.5142265860417012

Epoch: 6| Step: 10
Training loss: 2.8012377421473897
Validation loss: 2.4920678143586326

Epoch: 6| Step: 11
Training loss: 1.9080627452242036
Validation loss: 2.4832219482959297

Epoch: 6| Step: 12
Training loss: 2.3673149049421744
Validation loss: 2.4933599953670584

Epoch: 6| Step: 13
Training loss: 2.946538937966315
Validation loss: 2.495497407180999

Epoch: 371| Step: 0
Training loss: 2.5065692422412558
Validation loss: 2.4824903215428407

Epoch: 6| Step: 1
Training loss: 3.097825573674559
Validation loss: 2.518028458872857

Epoch: 6| Step: 2
Training loss: 3.2074928834260885
Validation loss: 2.559700254517346

Epoch: 6| Step: 3
Training loss: 2.271343407229667
Validation loss: 2.590981845837089

Epoch: 6| Step: 4
Training loss: 2.40866878861581
Validation loss: 2.634973413741482

Epoch: 6| Step: 5
Training loss: 2.313183863791964
Validation loss: 2.639092672784339

Epoch: 6| Step: 6
Training loss: 1.833628594579807
Validation loss: 2.6626014406679475

Epoch: 6| Step: 7
Training loss: 2.1845213092053632
Validation loss: 2.708949240674264

Epoch: 6| Step: 8
Training loss: 2.9670249344022617
Validation loss: 2.7460260652021558

Epoch: 6| Step: 9
Training loss: 2.218832954682739
Validation loss: 2.763160749266331

Epoch: 6| Step: 10
Training loss: 2.5813710440640976
Validation loss: 2.7329031156125567

Epoch: 6| Step: 11
Training loss: 2.456057211417689
Validation loss: 2.6566629898242033

Epoch: 6| Step: 12
Training loss: 2.8009316631453376
Validation loss: 2.528591841080532

Epoch: 6| Step: 13
Training loss: 2.3360384405774903
Validation loss: 2.4552871834768957

Epoch: 372| Step: 0
Training loss: 2.4027617300253503
Validation loss: 2.416754750339225

Epoch: 6| Step: 1
Training loss: 2.846876165764546
Validation loss: 2.426021929189114

Epoch: 6| Step: 2
Training loss: 2.238186979056163
Validation loss: 2.427170685142405

Epoch: 6| Step: 3
Training loss: 2.5535438147394194
Validation loss: 2.429179395616523

Epoch: 6| Step: 4
Training loss: 2.7585093020485765
Validation loss: 2.433692531002716

Epoch: 6| Step: 5
Training loss: 2.669700406871747
Validation loss: 2.4299255123678853

Epoch: 6| Step: 6
Training loss: 2.511461307033918
Validation loss: 2.4452448852630773

Epoch: 6| Step: 7
Training loss: 2.2306110183051033
Validation loss: 2.4357051999048998

Epoch: 6| Step: 8
Training loss: 2.3248183558889965
Validation loss: 2.4624926082087253

Epoch: 6| Step: 9
Training loss: 3.330399143709489
Validation loss: 2.457917545530394

Epoch: 6| Step: 10
Training loss: 2.7823530431500014
Validation loss: 2.4703445715906103

Epoch: 6| Step: 11
Training loss: 2.465066020151106
Validation loss: 2.5015738609175733

Epoch: 6| Step: 12
Training loss: 2.985673711713553
Validation loss: 2.5169828756836696

Epoch: 6| Step: 13
Training loss: 2.743790638824717
Validation loss: 2.5478274800668412

Epoch: 373| Step: 0
Training loss: 2.973367573351355
Validation loss: 2.544812519191766

Epoch: 6| Step: 1
Training loss: 2.705933187146268
Validation loss: 2.570114695155225

Epoch: 6| Step: 2
Training loss: 2.432065333768755
Validation loss: 2.580834113306169

Epoch: 6| Step: 3
Training loss: 2.350862012181358
Validation loss: 2.5754445689499863

Epoch: 6| Step: 4
Training loss: 2.8580395858084002
Validation loss: 2.597597194891342

Epoch: 6| Step: 5
Training loss: 2.1687872364024616
Validation loss: 2.617823101376553

Epoch: 6| Step: 6
Training loss: 2.124850997188722
Validation loss: 2.5972823853545783

Epoch: 6| Step: 7
Training loss: 2.2997111761110944
Validation loss: 2.576439377474543

Epoch: 6| Step: 8
Training loss: 2.56973028110955
Validation loss: 2.5575673078190535

Epoch: 6| Step: 9
Training loss: 2.556177014192672
Validation loss: 2.5484017278511644

Epoch: 6| Step: 10
Training loss: 2.316408411446346
Validation loss: 2.519381608944601

Epoch: 6| Step: 11
Training loss: 2.467297283530086
Validation loss: 2.5211740187455662

Epoch: 6| Step: 12
Training loss: 2.5556560395245675
Validation loss: 2.5076286016693645

Epoch: 6| Step: 13
Training loss: 2.8508408560863154
Validation loss: 2.5146845330462173

Epoch: 374| Step: 0
Training loss: 1.8729964041647378
Validation loss: 2.5435438235990646

Epoch: 6| Step: 1
Training loss: 2.5388992961370667
Validation loss: 2.553725654460667

Epoch: 6| Step: 2
Training loss: 2.6271640395116043
Validation loss: 2.5805245944605035

Epoch: 6| Step: 3
Training loss: 2.6030191461809347
Validation loss: 2.548633322042867

Epoch: 6| Step: 4
Training loss: 2.4478712253546324
Validation loss: 2.5437400029761434

Epoch: 6| Step: 5
Training loss: 2.668753602072364
Validation loss: 2.5813352503671974

Epoch: 6| Step: 6
Training loss: 2.5556151779333103
Validation loss: 2.6117438374314923

Epoch: 6| Step: 7
Training loss: 2.0470136056810326
Validation loss: 2.615795485149243

Epoch: 6| Step: 8
Training loss: 2.173533622760697
Validation loss: 2.645015078104503

Epoch: 6| Step: 9
Training loss: 3.0287455801748537
Validation loss: 2.6003641619729856

Epoch: 6| Step: 10
Training loss: 2.4691736364850967
Validation loss: 2.5699478670245335

Epoch: 6| Step: 11
Training loss: 2.506445110840939
Validation loss: 2.5163456450131476

Epoch: 6| Step: 12
Training loss: 2.629931676434044
Validation loss: 2.5034337017876434

Epoch: 6| Step: 13
Training loss: 2.8225065451884848
Validation loss: 2.488350596535109

Epoch: 375| Step: 0
Training loss: 3.069078037108827
Validation loss: 2.4876675763334064

Epoch: 6| Step: 1
Training loss: 1.9987841128837256
Validation loss: 2.482179998700796

Epoch: 6| Step: 2
Training loss: 2.159687784730619
Validation loss: 2.488029808429704

Epoch: 6| Step: 3
Training loss: 2.515282838665244
Validation loss: 2.4841332746573968

Epoch: 6| Step: 4
Training loss: 3.056150120388331
Validation loss: 2.5083148166865765

Epoch: 6| Step: 5
Training loss: 2.3829179584117024
Validation loss: 2.5309226927012203

Epoch: 6| Step: 6
Training loss: 2.3198198508332117
Validation loss: 2.5355934615371827

Epoch: 6| Step: 7
Training loss: 2.5855164891065567
Validation loss: 2.5296397189776716

Epoch: 6| Step: 8
Training loss: 2.3183822052240464
Validation loss: 2.5482036185865895

Epoch: 6| Step: 9
Training loss: 2.150504155154761
Validation loss: 2.5276075037463404

Epoch: 6| Step: 10
Training loss: 2.637153555729238
Validation loss: 2.5535468988843752

Epoch: 6| Step: 11
Training loss: 2.135338262343675
Validation loss: 2.5914581982856464

Epoch: 6| Step: 12
Training loss: 2.925258696763957
Validation loss: 2.5880884709017855

Epoch: 6| Step: 13
Training loss: 2.3571277551869056
Validation loss: 2.57274680647855

Epoch: 376| Step: 0
Training loss: 2.8824121874413704
Validation loss: 2.5620843313591304

Epoch: 6| Step: 1
Training loss: 2.61677534359611
Validation loss: 2.5628149217747644

Epoch: 6| Step: 2
Training loss: 2.477895287814448
Validation loss: 2.5383142582633402

Epoch: 6| Step: 3
Training loss: 1.5767593517978753
Validation loss: 2.500945689677606

Epoch: 6| Step: 4
Training loss: 2.6099043440554732
Validation loss: 2.5078422210601534

Epoch: 6| Step: 5
Training loss: 2.4222319309183926
Validation loss: 2.4907239001295327

Epoch: 6| Step: 6
Training loss: 2.4990590231993974
Validation loss: 2.4856008924741455

Epoch: 6| Step: 7
Training loss: 2.0907913483952467
Validation loss: 2.4857333873238994

Epoch: 6| Step: 8
Training loss: 2.673337837113973
Validation loss: 2.507081482483402

Epoch: 6| Step: 9
Training loss: 2.420909270662026
Validation loss: 2.545602672537167

Epoch: 6| Step: 10
Training loss: 2.7311996769579188
Validation loss: 2.6292612800003092

Epoch: 6| Step: 11
Training loss: 2.605861468365034
Validation loss: 2.6191324940139764

Epoch: 6| Step: 12
Training loss: 2.639141320541596
Validation loss: 2.5882204677325373

Epoch: 6| Step: 13
Training loss: 2.3777790875693703
Validation loss: 2.5880779937939926

Epoch: 377| Step: 0
Training loss: 2.5492009500436823
Validation loss: 2.6360611917622565

Epoch: 6| Step: 1
Training loss: 2.152738393060973
Validation loss: 2.6764000574936864

Epoch: 6| Step: 2
Training loss: 2.736867063327457
Validation loss: 2.687039565994875

Epoch: 6| Step: 3
Training loss: 2.062538377809374
Validation loss: 2.6331865574350672

Epoch: 6| Step: 4
Training loss: 2.729695179169132
Validation loss: 2.590150958596873

Epoch: 6| Step: 5
Training loss: 2.05154178141165
Validation loss: 2.5520813979408774

Epoch: 6| Step: 6
Training loss: 2.645191375068368
Validation loss: 2.5178730908643794

Epoch: 6| Step: 7
Training loss: 2.3245949833353445
Validation loss: 2.493050919613006

Epoch: 6| Step: 8
Training loss: 3.199467948551539
Validation loss: 2.488088635781361

Epoch: 6| Step: 9
Training loss: 2.756099179524919
Validation loss: 2.4875687074646256

Epoch: 6| Step: 10
Training loss: 2.477117337912383
Validation loss: 2.4888497647120977

Epoch: 6| Step: 11
Training loss: 2.6420742775397343
Validation loss: 2.493468401975888

Epoch: 6| Step: 12
Training loss: 2.163773720543486
Validation loss: 2.5083879478847524

Epoch: 6| Step: 13
Training loss: 1.7942742143293693
Validation loss: 2.534421258210403

Epoch: 378| Step: 0
Training loss: 2.8521955231659986
Validation loss: 2.5339244405359924

Epoch: 6| Step: 1
Training loss: 2.8922554984978954
Validation loss: 2.520181494486226

Epoch: 6| Step: 2
Training loss: 1.9909546871039216
Validation loss: 2.5329455823191647

Epoch: 6| Step: 3
Training loss: 2.7735961868664827
Validation loss: 2.50842479475968

Epoch: 6| Step: 4
Training loss: 2.172389346905462
Validation loss: 2.506710262740382

Epoch: 6| Step: 5
Training loss: 2.642662210529367
Validation loss: 2.4927770674816934

Epoch: 6| Step: 6
Training loss: 2.1468259003423205
Validation loss: 2.5021764766618055

Epoch: 6| Step: 7
Training loss: 2.7208104711470744
Validation loss: 2.4994345445935457

Epoch: 6| Step: 8
Training loss: 1.9310089405313133
Validation loss: 2.531588102502887

Epoch: 6| Step: 9
Training loss: 2.139930445351812
Validation loss: 2.601438864853585

Epoch: 6| Step: 10
Training loss: 2.8605090951306544
Validation loss: 2.663477167576421

Epoch: 6| Step: 11
Training loss: 1.9286664972134904
Validation loss: 2.6674941731201596

Epoch: 6| Step: 12
Training loss: 2.5363404692433607
Validation loss: 2.601052357370703

Epoch: 6| Step: 13
Training loss: 3.202983425082012
Validation loss: 2.6073573166983195

Epoch: 379| Step: 0
Training loss: 1.7629808189400245
Validation loss: 2.5131328438996796

Epoch: 6| Step: 1
Training loss: 2.412852060986497
Validation loss: 2.4629124235825497

Epoch: 6| Step: 2
Training loss: 2.840896180557046
Validation loss: 2.4522623719539407

Epoch: 6| Step: 3
Training loss: 2.5852728505265983
Validation loss: 2.4279351461158805

Epoch: 6| Step: 4
Training loss: 2.9404973098646576
Validation loss: 2.4254116686808196

Epoch: 6| Step: 5
Training loss: 1.8849739552527514
Validation loss: 2.4508684213084204

Epoch: 6| Step: 6
Training loss: 2.416569565324014
Validation loss: 2.4537526295697427

Epoch: 6| Step: 7
Training loss: 2.2403882613204353
Validation loss: 2.4535105381204483

Epoch: 6| Step: 8
Training loss: 2.290671034034204
Validation loss: 2.4669078757469483

Epoch: 6| Step: 9
Training loss: 2.9852427873644913
Validation loss: 2.488975579095318

Epoch: 6| Step: 10
Training loss: 2.8230960878078686
Validation loss: 2.500106238086998

Epoch: 6| Step: 11
Training loss: 2.757466064825337
Validation loss: 2.5237237774323766

Epoch: 6| Step: 12
Training loss: 2.50553966929758
Validation loss: 2.580455761863141

Epoch: 6| Step: 13
Training loss: 2.092136501519729
Validation loss: 2.6403470078410303

Epoch: 380| Step: 0
Training loss: 2.8325280746859822
Validation loss: 2.7138895112550467

Epoch: 6| Step: 1
Training loss: 2.0761475296961622
Validation loss: 2.719677478484852

Epoch: 6| Step: 2
Training loss: 2.7905877054249166
Validation loss: 2.7033491571027333

Epoch: 6| Step: 3
Training loss: 2.689298249926342
Validation loss: 2.6612705257322067

Epoch: 6| Step: 4
Training loss: 2.5158129319783926
Validation loss: 2.595534373951909

Epoch: 6| Step: 5
Training loss: 2.6463902305383495
Validation loss: 2.524557310350439

Epoch: 6| Step: 6
Training loss: 2.893345228191249
Validation loss: 2.46878672092595

Epoch: 6| Step: 7
Training loss: 2.1904636470561907
Validation loss: 2.4394475814543672

Epoch: 6| Step: 8
Training loss: 2.3991099853109388
Validation loss: 2.4260168864870346

Epoch: 6| Step: 9
Training loss: 3.05449158803706
Validation loss: 2.41925035220294

Epoch: 6| Step: 10
Training loss: 2.493427028153534
Validation loss: 2.4249971386159244

Epoch: 6| Step: 11
Training loss: 1.9663350871034595
Validation loss: 2.4372322328798686

Epoch: 6| Step: 12
Training loss: 2.709431870511529
Validation loss: 2.440639763332183

Epoch: 6| Step: 13
Training loss: 2.223340617982444
Validation loss: 2.4800966375958713

Epoch: 381| Step: 0
Training loss: 2.2409796568437867
Validation loss: 2.5209942638094422

Epoch: 6| Step: 1
Training loss: 2.3376258693811964
Validation loss: 2.541370019154848

Epoch: 6| Step: 2
Training loss: 2.5316837080515264
Validation loss: 2.569169909965287

Epoch: 6| Step: 3
Training loss: 2.4682843698731927
Validation loss: 2.5661830510672234

Epoch: 6| Step: 4
Training loss: 2.1982362222611753
Validation loss: 2.576485942579608

Epoch: 6| Step: 5
Training loss: 2.3365075682034444
Validation loss: 2.606178548730574

Epoch: 6| Step: 6
Training loss: 2.5516506425124748
Validation loss: 2.5911840869596374

Epoch: 6| Step: 7
Training loss: 2.721500540025956
Validation loss: 2.5752124432322248

Epoch: 6| Step: 8
Training loss: 2.503074567384375
Validation loss: 2.5543624547211436

Epoch: 6| Step: 9
Training loss: 2.7077755475920995
Validation loss: 2.526011691197328

Epoch: 6| Step: 10
Training loss: 2.271068689124716
Validation loss: 2.4962009780044077

Epoch: 6| Step: 11
Training loss: 2.414787899520455
Validation loss: 2.494399999492426

Epoch: 6| Step: 12
Training loss: 2.8770180958379976
Validation loss: 2.4753278021965635

Epoch: 6| Step: 13
Training loss: 2.3163057919827117
Validation loss: 2.4739266915664517

Epoch: 382| Step: 0
Training loss: 1.8278327773546588
Validation loss: 2.486798879467665

Epoch: 6| Step: 1
Training loss: 2.08170314586838
Validation loss: 2.5104232067713466

Epoch: 6| Step: 2
Training loss: 2.2090923036741454
Validation loss: 2.522594685908564

Epoch: 6| Step: 3
Training loss: 2.9022670237692294
Validation loss: 2.5273165609034565

Epoch: 6| Step: 4
Training loss: 2.7869242531153477
Validation loss: 2.575262232011251

Epoch: 6| Step: 5
Training loss: 2.5244304958967043
Validation loss: 2.5911503581164563

Epoch: 6| Step: 6
Training loss: 2.816476680811451
Validation loss: 2.5988179073825037

Epoch: 6| Step: 7
Training loss: 1.7933529377802881
Validation loss: 2.624400715507814

Epoch: 6| Step: 8
Training loss: 2.9391445669654397
Validation loss: 2.6499210584665143

Epoch: 6| Step: 9
Training loss: 2.4394157901591584
Validation loss: 2.669062305211666

Epoch: 6| Step: 10
Training loss: 2.1872974846965967
Validation loss: 2.619499981149863

Epoch: 6| Step: 11
Training loss: 2.161832466071005
Validation loss: 2.564597642125129

Epoch: 6| Step: 12
Training loss: 2.8551123692834492
Validation loss: 2.5283903210808756

Epoch: 6| Step: 13
Training loss: 2.5654792214538924
Validation loss: 2.485829774655605

Epoch: 383| Step: 0
Training loss: 2.513930324496309
Validation loss: 2.484179507067422

Epoch: 6| Step: 1
Training loss: 2.3856776287698818
Validation loss: 2.4458370558869404

Epoch: 6| Step: 2
Training loss: 1.9564053263561907
Validation loss: 2.4388193977475896

Epoch: 6| Step: 3
Training loss: 3.0318816795110406
Validation loss: 2.4435324641798384

Epoch: 6| Step: 4
Training loss: 2.259831459715162
Validation loss: 2.4448547847003015

Epoch: 6| Step: 5
Training loss: 2.653281763700235
Validation loss: 2.439115227342216

Epoch: 6| Step: 6
Training loss: 2.506044328959673
Validation loss: 2.4574015001733063

Epoch: 6| Step: 7
Training loss: 1.863217334730718
Validation loss: 2.488188264976518

Epoch: 6| Step: 8
Training loss: 2.990553606510521
Validation loss: 2.4909017309414665

Epoch: 6| Step: 9
Training loss: 2.047772509241022
Validation loss: 2.519172161460039

Epoch: 6| Step: 10
Training loss: 2.1818821294400896
Validation loss: 2.523338136856831

Epoch: 6| Step: 11
Training loss: 2.929065038040349
Validation loss: 2.5379219233392813

Epoch: 6| Step: 12
Training loss: 2.5653400035177953
Validation loss: 2.557268336114701

Epoch: 6| Step: 13
Training loss: 1.634668636749184
Validation loss: 2.582875903619947

Epoch: 384| Step: 0
Training loss: 2.2332475925707165
Validation loss: 2.6100099049205276

Epoch: 6| Step: 1
Training loss: 2.418492274390518
Validation loss: 2.589388981874472

Epoch: 6| Step: 2
Training loss: 2.0996488913432514
Validation loss: 2.57633328593169

Epoch: 6| Step: 3
Training loss: 1.8063050654376351
Validation loss: 2.5459457525165976

Epoch: 6| Step: 4
Training loss: 2.9957287900578624
Validation loss: 2.52689990953677

Epoch: 6| Step: 5
Training loss: 2.27169638748859
Validation loss: 2.5211735693004846

Epoch: 6| Step: 6
Training loss: 2.3535251474781425
Validation loss: 2.4957621012561977

Epoch: 6| Step: 7
Training loss: 2.6112824737735507
Validation loss: 2.4640111045173003

Epoch: 6| Step: 8
Training loss: 3.01982954163149
Validation loss: 2.46708165811279

Epoch: 6| Step: 9
Training loss: 2.211982399261702
Validation loss: 2.524398333784791

Epoch: 6| Step: 10
Training loss: 2.866939190914564
Validation loss: 2.5657931361020685

Epoch: 6| Step: 11
Training loss: 2.6204068098116884
Validation loss: 2.610002966409878

Epoch: 6| Step: 12
Training loss: 1.8530232908181963
Validation loss: 2.6364340244610904

Epoch: 6| Step: 13
Training loss: 2.8043056217433935
Validation loss: 2.676346244351437

Epoch: 385| Step: 0
Training loss: 2.639387213073267
Validation loss: 2.6001769548342604

Epoch: 6| Step: 1
Training loss: 2.6243806744173703
Validation loss: 2.5325003224544456

Epoch: 6| Step: 2
Training loss: 2.736239772897762
Validation loss: 2.475316116622822

Epoch: 6| Step: 3
Training loss: 2.191134022822255
Validation loss: 2.437039981089169

Epoch: 6| Step: 4
Training loss: 2.0527019697801974
Validation loss: 2.419407482326472

Epoch: 6| Step: 5
Training loss: 2.4826770474243847
Validation loss: 2.412624818961805

Epoch: 6| Step: 6
Training loss: 2.1480574948023534
Validation loss: 2.4331509159211353

Epoch: 6| Step: 7
Training loss: 2.404567179603853
Validation loss: 2.4341452951337708

Epoch: 6| Step: 8
Training loss: 2.601272154406198
Validation loss: 2.448501749138917

Epoch: 6| Step: 9
Training loss: 2.145659269908707
Validation loss: 2.440344268773699

Epoch: 6| Step: 10
Training loss: 3.3575130536811986
Validation loss: 2.481334090079422

Epoch: 6| Step: 11
Training loss: 2.414197010626043
Validation loss: 2.52819898606527

Epoch: 6| Step: 12
Training loss: 2.0481451621764215
Validation loss: 2.5441067395909487

Epoch: 6| Step: 13
Training loss: 1.5535936964722346
Validation loss: 2.589801713314672

Epoch: 386| Step: 0
Training loss: 2.3528862455912276
Validation loss: 2.6273117745877363

Epoch: 6| Step: 1
Training loss: 2.056659289037166
Validation loss: 2.6652686918002195

Epoch: 6| Step: 2
Training loss: 2.5833424803869267
Validation loss: 2.709348860830768

Epoch: 6| Step: 3
Training loss: 3.234892283183672
Validation loss: 2.6875606686459146

Epoch: 6| Step: 4
Training loss: 2.8132901247451834
Validation loss: 2.6296786146569695

Epoch: 6| Step: 5
Training loss: 2.638301752816765
Validation loss: 2.5140113534080615

Epoch: 6| Step: 6
Training loss: 2.5845617224551196
Validation loss: 2.4742678350985403

Epoch: 6| Step: 7
Training loss: 2.206651611084685
Validation loss: 2.471652955449025

Epoch: 6| Step: 8
Training loss: 2.2320987871451727
Validation loss: 2.4606326683833637

Epoch: 6| Step: 9
Training loss: 2.836030144137151
Validation loss: 2.44688770571313

Epoch: 6| Step: 10
Training loss: 1.7483804565615089
Validation loss: 2.452807725002372

Epoch: 6| Step: 11
Training loss: 1.586480334357505
Validation loss: 2.4730082405886553

Epoch: 6| Step: 12
Training loss: 2.466515700987235
Validation loss: 2.4730481496843946

Epoch: 6| Step: 13
Training loss: 2.5760685897841427
Validation loss: 2.4808913825812744

Epoch: 387| Step: 0
Training loss: 2.4606927659187012
Validation loss: 2.484806826342243

Epoch: 6| Step: 1
Training loss: 2.496893764993483
Validation loss: 2.495468955766088

Epoch: 6| Step: 2
Training loss: 2.4739230076459555
Validation loss: 2.4888718035723616

Epoch: 6| Step: 3
Training loss: 2.360691031940629
Validation loss: 2.4599509036892995

Epoch: 6| Step: 4
Training loss: 2.0383594221606582
Validation loss: 2.4735662931853764

Epoch: 6| Step: 5
Training loss: 2.4425933637316004
Validation loss: 2.4845553169073424

Epoch: 6| Step: 6
Training loss: 2.895551782180905
Validation loss: 2.503522055240226

Epoch: 6| Step: 7
Training loss: 2.1360576380978973
Validation loss: 2.5346772652969163

Epoch: 6| Step: 8
Training loss: 2.778573280443127
Validation loss: 2.5363348968974866

Epoch: 6| Step: 9
Training loss: 2.3782202321858925
Validation loss: 2.5660947770905844

Epoch: 6| Step: 10
Training loss: 1.818589209301738
Validation loss: 2.5993926367486235

Epoch: 6| Step: 11
Training loss: 2.607747375516217
Validation loss: 2.559083912093781

Epoch: 6| Step: 12
Training loss: 2.188881138348399
Validation loss: 2.5983455296443774

Epoch: 6| Step: 13
Training loss: 2.7055615155021444
Validation loss: 2.578517451640648

Epoch: 388| Step: 0
Training loss: 1.8120420469327678
Validation loss: 2.598908230414124

Epoch: 6| Step: 1
Training loss: 1.9754484150455516
Validation loss: 2.5690186178088354

Epoch: 6| Step: 2
Training loss: 2.669663612806301
Validation loss: 2.5301279680070388

Epoch: 6| Step: 3
Training loss: 2.8124888949704805
Validation loss: 2.4978090879098476

Epoch: 6| Step: 4
Training loss: 2.3794002928214923
Validation loss: 2.4970135416980996

Epoch: 6| Step: 5
Training loss: 2.3968299672498126
Validation loss: 2.4814972832571387

Epoch: 6| Step: 6
Training loss: 2.6729569949177425
Validation loss: 2.4682560430834966

Epoch: 6| Step: 7
Training loss: 2.618899022052496
Validation loss: 2.488258025190947

Epoch: 6| Step: 8
Training loss: 2.468473684565096
Validation loss: 2.464721284534089

Epoch: 6| Step: 9
Training loss: 2.0738005423063277
Validation loss: 2.5063503356281136

Epoch: 6| Step: 10
Training loss: 2.250671498444118
Validation loss: 2.5292023205596106

Epoch: 6| Step: 11
Training loss: 2.7659391235581254
Validation loss: 2.4945231239695183

Epoch: 6| Step: 12
Training loss: 2.380751021362842
Validation loss: 2.512751528012713

Epoch: 6| Step: 13
Training loss: 2.5342371704403
Validation loss: 2.4982317998501062

Epoch: 389| Step: 0
Training loss: 2.688715637640086
Validation loss: 2.489649931664371

Epoch: 6| Step: 1
Training loss: 2.5062990940070593
Validation loss: 2.4883480023466156

Epoch: 6| Step: 2
Training loss: 2.189906295443873
Validation loss: 2.491018270914366

Epoch: 6| Step: 3
Training loss: 2.415228306026814
Validation loss: 2.5012095919389865

Epoch: 6| Step: 4
Training loss: 1.897250082774254
Validation loss: 2.5213368341061186

Epoch: 6| Step: 5
Training loss: 2.5922238559484296
Validation loss: 2.5418498737937782

Epoch: 6| Step: 6
Training loss: 2.5871229883014646
Validation loss: 2.5371512853904017

Epoch: 6| Step: 7
Training loss: 2.21221886696788
Validation loss: 2.558190384184929

Epoch: 6| Step: 8
Training loss: 2.1653329583521614
Validation loss: 2.5381495548566138

Epoch: 6| Step: 9
Training loss: 2.550212054691779
Validation loss: 2.5528185376639754

Epoch: 6| Step: 10
Training loss: 2.2857414865578263
Validation loss: 2.5546028810844392

Epoch: 6| Step: 11
Training loss: 2.602682153371689
Validation loss: 2.54020142713139

Epoch: 6| Step: 12
Training loss: 2.406812230601466
Validation loss: 2.5277519813737936

Epoch: 6| Step: 13
Training loss: 2.2882988082196483
Validation loss: 2.4769782121186203

Epoch: 390| Step: 0
Training loss: 2.6576306513539674
Validation loss: 2.4554643117665083

Epoch: 6| Step: 1
Training loss: 2.718063618626301
Validation loss: 2.451211644403915

Epoch: 6| Step: 2
Training loss: 2.5280717275922124
Validation loss: 2.430982852376362

Epoch: 6| Step: 3
Training loss: 2.789396121803914
Validation loss: 2.434317527182181

Epoch: 6| Step: 4
Training loss: 2.4250924672853267
Validation loss: 2.4388441739581217

Epoch: 6| Step: 5
Training loss: 1.8169217598445135
Validation loss: 2.437939328972516

Epoch: 6| Step: 6
Training loss: 2.55355557904579
Validation loss: 2.4660045726561304

Epoch: 6| Step: 7
Training loss: 2.5092539224832464
Validation loss: 2.4938591132928396

Epoch: 6| Step: 8
Training loss: 2.1672586463740786
Validation loss: 2.533686357767117

Epoch: 6| Step: 9
Training loss: 2.567008727263538
Validation loss: 2.531502434992913

Epoch: 6| Step: 10
Training loss: 1.725849332282476
Validation loss: 2.5719184664580848

Epoch: 6| Step: 11
Training loss: 2.332063556492094
Validation loss: 2.6018277191090164

Epoch: 6| Step: 12
Training loss: 2.3058425336607575
Validation loss: 2.586717673847393

Epoch: 6| Step: 13
Training loss: 2.322046729985284
Validation loss: 2.5872751430837244

Epoch: 391| Step: 0
Training loss: 2.5358919507423505
Validation loss: 2.589212688940019

Epoch: 6| Step: 1
Training loss: 2.781445957095635
Validation loss: 2.568574787952139

Epoch: 6| Step: 2
Training loss: 1.5366685712696335
Validation loss: 2.541718858828196

Epoch: 6| Step: 3
Training loss: 2.1514055315324443
Validation loss: 2.4933675741228103

Epoch: 6| Step: 4
Training loss: 2.4954288653792496
Validation loss: 2.472489180198057

Epoch: 6| Step: 5
Training loss: 2.0764329948829965
Validation loss: 2.4252434103356966

Epoch: 6| Step: 6
Training loss: 2.360666085982267
Validation loss: 2.4333213240590794

Epoch: 6| Step: 7
Training loss: 2.760936491382633
Validation loss: 2.448837738146222

Epoch: 6| Step: 8
Training loss: 2.7177622085871156
Validation loss: 2.4600373142176015

Epoch: 6| Step: 9
Training loss: 2.3328783295548425
Validation loss: 2.5347607744017493

Epoch: 6| Step: 10
Training loss: 2.8041534340382337
Validation loss: 2.604862409292295

Epoch: 6| Step: 11
Training loss: 2.574981900494121
Validation loss: 2.58701672841517

Epoch: 6| Step: 12
Training loss: 2.3414618958055406
Validation loss: 2.572276062862109

Epoch: 6| Step: 13
Training loss: 2.067261834224551
Validation loss: 2.556797911645565

Epoch: 392| Step: 0
Training loss: 1.9155205603252627
Validation loss: 2.525475469492135

Epoch: 6| Step: 1
Training loss: 1.9701969944784714
Validation loss: 2.5239853061946276

Epoch: 6| Step: 2
Training loss: 2.6300468974410434
Validation loss: 2.5103473132086553

Epoch: 6| Step: 3
Training loss: 2.266213807512942
Validation loss: 2.49737851510288

Epoch: 6| Step: 4
Training loss: 2.635322347971129
Validation loss: 2.519285964950058

Epoch: 6| Step: 5
Training loss: 2.5072720619727376
Validation loss: 2.523925324676919

Epoch: 6| Step: 6
Training loss: 3.043643431002227
Validation loss: 2.5217222576833263

Epoch: 6| Step: 7
Training loss: 2.098757776060802
Validation loss: 2.505774834161051

Epoch: 6| Step: 8
Training loss: 2.499789419842137
Validation loss: 2.482617528022124

Epoch: 6| Step: 9
Training loss: 2.3351695351655066
Validation loss: 2.469612300171718

Epoch: 6| Step: 10
Training loss: 2.346056909109937
Validation loss: 2.454226600047053

Epoch: 6| Step: 11
Training loss: 2.4488544588655254
Validation loss: 2.4331292194768297

Epoch: 6| Step: 12
Training loss: 2.322459040384285
Validation loss: 2.4321251300316904

Epoch: 6| Step: 13
Training loss: 2.252290195935902
Validation loss: 2.4461780337130317

Epoch: 393| Step: 0
Training loss: 2.230687867206185
Validation loss: 2.4602805327683432

Epoch: 6| Step: 1
Training loss: 2.57451585088441
Validation loss: 2.447780169833665

Epoch: 6| Step: 2
Training loss: 2.3649359844810514
Validation loss: 2.480509326083912

Epoch: 6| Step: 3
Training loss: 2.006969230290541
Validation loss: 2.4853317669008135

Epoch: 6| Step: 4
Training loss: 2.3421363870796195
Validation loss: 2.5025085906967734

Epoch: 6| Step: 5
Training loss: 2.301686754776648
Validation loss: 2.518744067573365

Epoch: 6| Step: 6
Training loss: 1.982859596071889
Validation loss: 2.5304402775869037

Epoch: 6| Step: 7
Training loss: 2.7291964075540367
Validation loss: 2.511400396562658

Epoch: 6| Step: 8
Training loss: 2.352871451326503
Validation loss: 2.5025139976235296

Epoch: 6| Step: 9
Training loss: 2.896782003842057
Validation loss: 2.4847338853150838

Epoch: 6| Step: 10
Training loss: 2.783542930873594
Validation loss: 2.4763425889386323

Epoch: 6| Step: 11
Training loss: 2.4046510610614313
Validation loss: 2.480824559803179

Epoch: 6| Step: 12
Training loss: 2.0122192945247823
Validation loss: 2.451266166920387

Epoch: 6| Step: 13
Training loss: 2.3102447234812695
Validation loss: 2.457846705133742

Epoch: 394| Step: 0
Training loss: 2.4916253008858793
Validation loss: 2.477014668755413

Epoch: 6| Step: 1
Training loss: 1.8911942815042264
Validation loss: 2.4971968697001543

Epoch: 6| Step: 2
Training loss: 1.9560515184229197
Validation loss: 2.4994536212964436

Epoch: 6| Step: 3
Training loss: 2.218737105211209
Validation loss: 2.511535239765449

Epoch: 6| Step: 4
Training loss: 2.7443308917023574
Validation loss: 2.521746053663652

Epoch: 6| Step: 5
Training loss: 2.412659468840443
Validation loss: 2.482070447840688

Epoch: 6| Step: 6
Training loss: 2.33631745887545
Validation loss: 2.4878513055336753

Epoch: 6| Step: 7
Training loss: 3.1599685367997656
Validation loss: 2.500083546626847

Epoch: 6| Step: 8
Training loss: 2.3139532523218063
Validation loss: 2.476622003438464

Epoch: 6| Step: 9
Training loss: 2.2256481769557985
Validation loss: 2.4821724828715017

Epoch: 6| Step: 10
Training loss: 2.495862015785981
Validation loss: 2.489270503697697

Epoch: 6| Step: 11
Training loss: 1.977725203430862
Validation loss: 2.5046692733577927

Epoch: 6| Step: 12
Training loss: 2.4592308302699633
Validation loss: 2.508395473059517

Epoch: 6| Step: 13
Training loss: 2.499011225668678
Validation loss: 2.5074499399297254

Epoch: 395| Step: 0
Training loss: 2.3008105757031223
Validation loss: 2.526204009823491

Epoch: 6| Step: 1
Training loss: 2.0356156604940274
Validation loss: 2.5094522073572794

Epoch: 6| Step: 2
Training loss: 2.6697815842177013
Validation loss: 2.5263153208727402

Epoch: 6| Step: 3
Training loss: 1.796600586213262
Validation loss: 2.5347071194073547

Epoch: 6| Step: 4
Training loss: 2.0267749495607528
Validation loss: 2.546768154024722

Epoch: 6| Step: 5
Training loss: 2.5259025509205273
Validation loss: 2.560738310874162

Epoch: 6| Step: 6
Training loss: 2.854924307920453
Validation loss: 2.5729074264173786

Epoch: 6| Step: 7
Training loss: 2.2123598302201164
Validation loss: 2.553127414944571

Epoch: 6| Step: 8
Training loss: 2.4073794798032635
Validation loss: 2.518619191093081

Epoch: 6| Step: 9
Training loss: 2.4778051297379724
Validation loss: 2.4865101983781166

Epoch: 6| Step: 10
Training loss: 2.2527931677996462
Validation loss: 2.4728412738768353

Epoch: 6| Step: 11
Training loss: 2.214359075675811
Validation loss: 2.496403160691106

Epoch: 6| Step: 12
Training loss: 2.3850762292287806
Validation loss: 2.5104580283805165

Epoch: 6| Step: 13
Training loss: 3.108314371605139
Validation loss: 2.4794589172270625

Epoch: 396| Step: 0
Training loss: 2.578100215908335
Validation loss: 2.4761512637216985

Epoch: 6| Step: 1
Training loss: 2.0691101037399933
Validation loss: 2.4745205983889518

Epoch: 6| Step: 2
Training loss: 2.0531515320060785
Validation loss: 2.4744755447913773

Epoch: 6| Step: 3
Training loss: 2.797861106550039
Validation loss: 2.460985685945516

Epoch: 6| Step: 4
Training loss: 2.1335135065924704
Validation loss: 2.4795551741892266

Epoch: 6| Step: 5
Training loss: 2.005654685804355
Validation loss: 2.4746485709136112

Epoch: 6| Step: 6
Training loss: 2.5999580453275355
Validation loss: 2.5378114042175905

Epoch: 6| Step: 7
Training loss: 2.294247532241623
Validation loss: 2.558499713150615

Epoch: 6| Step: 8
Training loss: 2.4666857237552238
Validation loss: 2.606289007532827

Epoch: 6| Step: 9
Training loss: 2.8440058666442365
Validation loss: 2.613035908880953

Epoch: 6| Step: 10
Training loss: 2.539236772865397
Validation loss: 2.5498888483339046

Epoch: 6| Step: 11
Training loss: 2.4874782733831022
Validation loss: 2.51424747050363

Epoch: 6| Step: 12
Training loss: 1.845107274025316
Validation loss: 2.466767037696198

Epoch: 6| Step: 13
Training loss: 2.571070133310566
Validation loss: 2.4162027665526065

Epoch: 397| Step: 0
Training loss: 2.5815288845635522
Validation loss: 2.407123566382467

Epoch: 6| Step: 1
Training loss: 2.3991579843699467
Validation loss: 2.4199396673868674

Epoch: 6| Step: 2
Training loss: 2.5445954588488786
Validation loss: 2.393620960025373

Epoch: 6| Step: 3
Training loss: 2.7532848333408295
Validation loss: 2.403461583135172

Epoch: 6| Step: 4
Training loss: 2.475127276606274
Validation loss: 2.409875365120074

Epoch: 6| Step: 5
Training loss: 2.407182983251576
Validation loss: 2.404686256541686

Epoch: 6| Step: 6
Training loss: 2.4818076057284952
Validation loss: 2.4518769355604366

Epoch: 6| Step: 7
Training loss: 2.4852456540548533
Validation loss: 2.457075216475556

Epoch: 6| Step: 8
Training loss: 1.8944725420792619
Validation loss: 2.4816054901026163

Epoch: 6| Step: 9
Training loss: 2.306563205695629
Validation loss: 2.4831216820906854

Epoch: 6| Step: 10
Training loss: 1.4695481100134296
Validation loss: 2.510813175287116

Epoch: 6| Step: 11
Training loss: 2.0557581211780014
Validation loss: 2.5745013553349736

Epoch: 6| Step: 12
Training loss: 2.5955646096177603
Validation loss: 2.562785849246053

Epoch: 6| Step: 13
Training loss: 2.7635566175171182
Validation loss: 2.537708244788598

Epoch: 398| Step: 0
Training loss: 2.7093935920755006
Validation loss: 2.5152865863549465

Epoch: 6| Step: 1
Training loss: 2.775887881677992
Validation loss: 2.4829387779020795

Epoch: 6| Step: 2
Training loss: 2.4622434995644644
Validation loss: 2.479245841655337

Epoch: 6| Step: 3
Training loss: 1.8518214306275311
Validation loss: 2.463720491075181

Epoch: 6| Step: 4
Training loss: 2.216189344063416
Validation loss: 2.4651737470995085

Epoch: 6| Step: 5
Training loss: 2.2783182195661196
Validation loss: 2.4760330414230407

Epoch: 6| Step: 6
Training loss: 2.670348149436095
Validation loss: 2.497866941885214

Epoch: 6| Step: 7
Training loss: 2.6073044654043347
Validation loss: 2.5222417452496324

Epoch: 6| Step: 8
Training loss: 2.1839017429047383
Validation loss: 2.5250208766191586

Epoch: 6| Step: 9
Training loss: 1.8171627971252613
Validation loss: 2.5312035355176654

Epoch: 6| Step: 10
Training loss: 2.2947398531538044
Validation loss: 2.5131148401336816

Epoch: 6| Step: 11
Training loss: 2.7650169091975174
Validation loss: 2.5213852195802504

Epoch: 6| Step: 12
Training loss: 1.9954680117091315
Validation loss: 2.480654658671923

Epoch: 6| Step: 13
Training loss: 1.64821185696483
Validation loss: 2.4626788891243376

Epoch: 399| Step: 0
Training loss: 2.554845309268405
Validation loss: 2.4138445263460655

Epoch: 6| Step: 1
Training loss: 2.72776544917321
Validation loss: 2.4356666761324237

Epoch: 6| Step: 2
Training loss: 2.1801478402289893
Validation loss: 2.4193193737288254

Epoch: 6| Step: 3
Training loss: 2.433266313056659
Validation loss: 2.418199985921912

Epoch: 6| Step: 4
Training loss: 1.9244880590031224
Validation loss: 2.4173619075076247

Epoch: 6| Step: 5
Training loss: 2.392133050120745
Validation loss: 2.423741923399583

Epoch: 6| Step: 6
Training loss: 2.376111122018174
Validation loss: 2.430684392964826

Epoch: 6| Step: 7
Training loss: 2.613000692181326
Validation loss: 2.4612031214157573

Epoch: 6| Step: 8
Training loss: 2.8106646165182805
Validation loss: 2.469060243588817

Epoch: 6| Step: 9
Training loss: 2.285356561733379
Validation loss: 2.5155100871678977

Epoch: 6| Step: 10
Training loss: 2.048081137286721
Validation loss: 2.523417733951682

Epoch: 6| Step: 11
Training loss: 2.114428760410036
Validation loss: 2.540141333999278

Epoch: 6| Step: 12
Training loss: 2.12361110850533
Validation loss: 2.5465602150509987

Epoch: 6| Step: 13
Training loss: 2.6038640469513963
Validation loss: 2.539153934974828

Epoch: 400| Step: 0
Training loss: 1.875226515756787
Validation loss: 2.5515179464668285

Epoch: 6| Step: 1
Training loss: 2.4682800231918955
Validation loss: 2.5996845087472917

Epoch: 6| Step: 2
Training loss: 2.433420827241937
Validation loss: 2.5712012519721807

Epoch: 6| Step: 3
Training loss: 2.322036051651847
Validation loss: 2.5346116167758086

Epoch: 6| Step: 4
Training loss: 2.4565674748920516
Validation loss: 2.5070544448350307

Epoch: 6| Step: 5
Training loss: 2.4868507764872785
Validation loss: 2.453897627674428

Epoch: 6| Step: 6
Training loss: 2.2774480203670144
Validation loss: 2.4380911096412006

Epoch: 6| Step: 7
Training loss: 2.727804606043109
Validation loss: 2.419912507856951

Epoch: 6| Step: 8
Training loss: 2.672226285986433
Validation loss: 2.4392623546312913

Epoch: 6| Step: 9
Training loss: 1.7008356228479242
Validation loss: 2.444858784004247

Epoch: 6| Step: 10
Training loss: 2.3585166127548014
Validation loss: 2.4727339214051645

Epoch: 6| Step: 11
Training loss: 2.4681854568306454
Validation loss: 2.477447566927727

Epoch: 6| Step: 12
Training loss: 2.3491648874302036
Validation loss: 2.501648222154674

Epoch: 6| Step: 13
Training loss: 1.7762898097452893
Validation loss: 2.534898365699554

Epoch: 401| Step: 0
Training loss: 1.6266318710441168
Validation loss: 2.549722861580312

Epoch: 6| Step: 1
Training loss: 3.0615298233087307
Validation loss: 2.5691454635748405

Epoch: 6| Step: 2
Training loss: 2.370583091182359
Validation loss: 2.6338947348296013

Epoch: 6| Step: 3
Training loss: 1.901293956441578
Validation loss: 2.61326674090334

Epoch: 6| Step: 4
Training loss: 2.475477685009892
Validation loss: 2.6297014561703347

Epoch: 6| Step: 5
Training loss: 2.3509856368793987
Validation loss: 2.639055966836225

Epoch: 6| Step: 6
Training loss: 2.4007175803314924
Validation loss: 2.509854625810695

Epoch: 6| Step: 7
Training loss: 2.161634274104977
Validation loss: 2.4150799321879792

Epoch: 6| Step: 8
Training loss: 2.5569272736674984
Validation loss: 2.38088739026639

Epoch: 6| Step: 9
Training loss: 2.2544606814429837
Validation loss: 2.3716306047383915

Epoch: 6| Step: 10
Training loss: 2.4857160679414623
Validation loss: 2.3627834798254543

Epoch: 6| Step: 11
Training loss: 3.0252629567760887
Validation loss: 2.3666479816533976

Epoch: 6| Step: 12
Training loss: 2.7591928804289694
Validation loss: 2.3709844462102265

Epoch: 6| Step: 13
Training loss: 2.3658806243215316
Validation loss: 2.3698870355148665

Epoch: 402| Step: 0
Training loss: 2.3075609817795386
Validation loss: 2.3845618540212223

Epoch: 6| Step: 1
Training loss: 2.4218631867151403
Validation loss: 2.41131465886689

Epoch: 6| Step: 2
Training loss: 2.2672553148912966
Validation loss: 2.5025638334078457

Epoch: 6| Step: 3
Training loss: 2.5056766910221357
Validation loss: 2.6354002855803396

Epoch: 6| Step: 4
Training loss: 2.457214348646469
Validation loss: 2.790452645121792

Epoch: 6| Step: 5
Training loss: 2.794085598103395
Validation loss: 2.8161769180373977

Epoch: 6| Step: 6
Training loss: 2.2259544211465725
Validation loss: 2.8488455376613633

Epoch: 6| Step: 7
Training loss: 2.0863512178966763
Validation loss: 2.7872850460013665

Epoch: 6| Step: 8
Training loss: 2.3793100098977145
Validation loss: 2.6965661142597748

Epoch: 6| Step: 9
Training loss: 2.0858101680910495
Validation loss: 2.5239917696658116

Epoch: 6| Step: 10
Training loss: 2.0990241508166765
Validation loss: 2.4224480540140125

Epoch: 6| Step: 11
Training loss: 3.302134003034859
Validation loss: 2.3913132225619997

Epoch: 6| Step: 12
Training loss: 2.2815286126550705
Validation loss: 2.3704293488510095

Epoch: 6| Step: 13
Training loss: 2.9171571228374535
Validation loss: 2.3805136891437737

Epoch: 403| Step: 0
Training loss: 2.1995195687844142
Validation loss: 2.392958510537264

Epoch: 6| Step: 1
Training loss: 2.09795401677886
Validation loss: 2.378983631926729

Epoch: 6| Step: 2
Training loss: 2.825793322009265
Validation loss: 2.395026679938438

Epoch: 6| Step: 3
Training loss: 2.8857330993405963
Validation loss: 2.394518700122324

Epoch: 6| Step: 4
Training loss: 2.8607334599635594
Validation loss: 2.392737464177984

Epoch: 6| Step: 5
Training loss: 2.5516847467892796
Validation loss: 2.3776981450334205

Epoch: 6| Step: 6
Training loss: 2.4249700642733862
Validation loss: 2.3834240700636684

Epoch: 6| Step: 7
Training loss: 2.2663411028183136
Validation loss: 2.3852252259155335

Epoch: 6| Step: 8
Training loss: 2.8040283618695265
Validation loss: 2.3960013392654207

Epoch: 6| Step: 9
Training loss: 2.071708812924272
Validation loss: 2.411254908960518

Epoch: 6| Step: 10
Training loss: 2.7441368021548107
Validation loss: 2.4947130145163667

Epoch: 6| Step: 11
Training loss: 2.1501696453144326
Validation loss: 2.54136230008687

Epoch: 6| Step: 12
Training loss: 2.7015847464991896
Validation loss: 2.6039326526135254

Epoch: 6| Step: 13
Training loss: 1.7117452587197406
Validation loss: 2.658026877991594

Epoch: 404| Step: 0
Training loss: 1.972987262412097
Validation loss: 2.6725960380891722

Epoch: 6| Step: 1
Training loss: 2.6375626181450613
Validation loss: 2.679263719983057

Epoch: 6| Step: 2
Training loss: 2.138044932543617
Validation loss: 2.6414706628479623

Epoch: 6| Step: 3
Training loss: 2.354692271024633
Validation loss: 2.5774094295497982

Epoch: 6| Step: 4
Training loss: 2.5210507091610874
Validation loss: 2.510118806290852

Epoch: 6| Step: 5
Training loss: 2.2133080811764385
Validation loss: 2.4539995956386464

Epoch: 6| Step: 6
Training loss: 1.9900536572109033
Validation loss: 2.440634971416458

Epoch: 6| Step: 7
Training loss: 2.738644650625543
Validation loss: 2.4341530698401477

Epoch: 6| Step: 8
Training loss: 2.794522708136451
Validation loss: 2.3976655122317854

Epoch: 6| Step: 9
Training loss: 2.1566340892204217
Validation loss: 2.399136580513616

Epoch: 6| Step: 10
Training loss: 2.4812753402223144
Validation loss: 2.412213849110213

Epoch: 6| Step: 11
Training loss: 2.462964195223537
Validation loss: 2.4177080130763873

Epoch: 6| Step: 12
Training loss: 2.409634476480136
Validation loss: 2.4148875299275305

Epoch: 6| Step: 13
Training loss: 2.4569609954930143
Validation loss: 2.441370556904744

Epoch: 405| Step: 0
Training loss: 2.324296299257727
Validation loss: 2.4686850200059443

Epoch: 6| Step: 1
Training loss: 2.384550267648571
Validation loss: 2.522341347743272

Epoch: 6| Step: 2
Training loss: 2.449613645802618
Validation loss: 2.5822203395675722

Epoch: 6| Step: 3
Training loss: 2.7686159157416013
Validation loss: 2.575047803101148

Epoch: 6| Step: 4
Training loss: 2.1951717453764794
Validation loss: 2.5242444892308056

Epoch: 6| Step: 5
Training loss: 2.287969438922291
Validation loss: 2.496717884747497

Epoch: 6| Step: 6
Training loss: 2.606929889797074
Validation loss: 2.4845123768986244

Epoch: 6| Step: 7
Training loss: 2.0925770221057154
Validation loss: 2.4537954841313896

Epoch: 6| Step: 8
Training loss: 2.530040310625242
Validation loss: 2.452677663816906

Epoch: 6| Step: 9
Training loss: 1.9247517958311975
Validation loss: 2.451475720933782

Epoch: 6| Step: 10
Training loss: 1.951996378011939
Validation loss: 2.46021972230906

Epoch: 6| Step: 11
Training loss: 2.758940123076644
Validation loss: 2.4794347360819384

Epoch: 6| Step: 12
Training loss: 1.7963236087166103
Validation loss: 2.4939959174093325

Epoch: 6| Step: 13
Training loss: 2.7126257309142496
Validation loss: 2.524557907453348

Epoch: 406| Step: 0
Training loss: 2.2997779407282253
Validation loss: 2.5482681614201694

Epoch: 6| Step: 1
Training loss: 2.383417871838788
Validation loss: 2.567530372857669

Epoch: 6| Step: 2
Training loss: 2.877498039026197
Validation loss: 2.5813266417705107

Epoch: 6| Step: 3
Training loss: 2.125362140988373
Validation loss: 2.5730388958239327

Epoch: 6| Step: 4
Training loss: 1.9269872143117852
Validation loss: 2.549341023177811

Epoch: 6| Step: 5
Training loss: 2.1846984361874933
Validation loss: 2.533637469072091

Epoch: 6| Step: 6
Training loss: 2.644273032537576
Validation loss: 2.524345517772551

Epoch: 6| Step: 7
Training loss: 2.470273091281167
Validation loss: 2.4849795756896813

Epoch: 6| Step: 8
Training loss: 2.490823785179252
Validation loss: 2.4359177880489185

Epoch: 6| Step: 9
Training loss: 2.497066684283148
Validation loss: 2.4366869257952843

Epoch: 6| Step: 10
Training loss: 2.547863353089334
Validation loss: 2.417891567132232

Epoch: 6| Step: 11
Training loss: 2.0840202979126228
Validation loss: 2.3972022434437084

Epoch: 6| Step: 12
Training loss: 2.0883096643777463
Validation loss: 2.408843347757395

Epoch: 6| Step: 13
Training loss: 1.3862943617771506
Validation loss: 2.381171851780971

Epoch: 407| Step: 0
Training loss: 1.6311156294278222
Validation loss: 2.3946513355778722

Epoch: 6| Step: 1
Training loss: 1.822531661293665
Validation loss: 2.436326897080195

Epoch: 6| Step: 2
Training loss: 2.9000984635573386
Validation loss: 2.4261861452039644

Epoch: 6| Step: 3
Training loss: 2.45116000837516
Validation loss: 2.4461795009389506

Epoch: 6| Step: 4
Training loss: 2.413610422216716
Validation loss: 2.4624160827676516

Epoch: 6| Step: 5
Training loss: 2.021536033080893
Validation loss: 2.4739167123260817

Epoch: 6| Step: 6
Training loss: 2.432203554004638
Validation loss: 2.5112838448975134

Epoch: 6| Step: 7
Training loss: 2.9205345302082413
Validation loss: 2.5605680384523613

Epoch: 6| Step: 8
Training loss: 2.416460642308837
Validation loss: 2.575636794666219

Epoch: 6| Step: 9
Training loss: 1.9685771805736356
Validation loss: 2.576957335293305

Epoch: 6| Step: 10
Training loss: 2.104384558950251
Validation loss: 2.5222031466504924

Epoch: 6| Step: 11
Training loss: 2.369893658018727
Validation loss: 2.4691506732140036

Epoch: 6| Step: 12
Training loss: 2.5215252223647266
Validation loss: 2.4253323063120007

Epoch: 6| Step: 13
Training loss: 2.2188140430072747
Validation loss: 2.4001148340822738

Epoch: 408| Step: 0
Training loss: 2.390844197913936
Validation loss: 2.4105180843795

Epoch: 6| Step: 1
Training loss: 1.8677493730395152
Validation loss: 2.400723784615148

Epoch: 6| Step: 2
Training loss: 2.1131693304467167
Validation loss: 2.4122656003849583

Epoch: 6| Step: 3
Training loss: 1.9796225641766387
Validation loss: 2.438016569071966

Epoch: 6| Step: 4
Training loss: 2.3871869066669373
Validation loss: 2.482931654656725

Epoch: 6| Step: 5
Training loss: 2.8064437085692053
Validation loss: 2.4943272249116752

Epoch: 6| Step: 6
Training loss: 2.212225764461389
Validation loss: 2.520008570221422

Epoch: 6| Step: 7
Training loss: 2.6566781091702905
Validation loss: 2.507525953901335

Epoch: 6| Step: 8
Training loss: 2.0345915085863115
Validation loss: 2.5197128684501804

Epoch: 6| Step: 9
Training loss: 2.295109076473839
Validation loss: 2.551272287046892

Epoch: 6| Step: 10
Training loss: 2.15260936392775
Validation loss: 2.580842317271797

Epoch: 6| Step: 11
Training loss: 2.4815108385558418
Validation loss: 2.6001583548487943

Epoch: 6| Step: 12
Training loss: 2.151783283460654
Validation loss: 2.555484324959579

Epoch: 6| Step: 13
Training loss: 2.588989577247736
Validation loss: 2.5514261115622014

Epoch: 409| Step: 0
Training loss: 2.554043096526763
Validation loss: 2.4980419838494963

Epoch: 6| Step: 1
Training loss: 2.3938029988051697
Validation loss: 2.465620371598203

Epoch: 6| Step: 2
Training loss: 2.2987314623634423
Validation loss: 2.4202198820801617

Epoch: 6| Step: 3
Training loss: 2.5663610074077687
Validation loss: 2.4169685736006374

Epoch: 6| Step: 4
Training loss: 2.5707716140469103
Validation loss: 2.390292049103809

Epoch: 6| Step: 5
Training loss: 2.1686841179682745
Validation loss: 2.404044831798514

Epoch: 6| Step: 6
Training loss: 2.274524756457229
Validation loss: 2.4306187708105655

Epoch: 6| Step: 7
Training loss: 2.590605978901682
Validation loss: 2.4419879704304974

Epoch: 6| Step: 8
Training loss: 1.7283677549744865
Validation loss: 2.474068352023776

Epoch: 6| Step: 9
Training loss: 2.0380379744745656
Validation loss: 2.4546998032927827

Epoch: 6| Step: 10
Training loss: 2.1909927821282045
Validation loss: 2.5036221690002565

Epoch: 6| Step: 11
Training loss: 2.425415502916127
Validation loss: 2.5262371180868493

Epoch: 6| Step: 12
Training loss: 2.2521718457449276
Validation loss: 2.5430876389025006

Epoch: 6| Step: 13
Training loss: 2.077644694186367
Validation loss: 2.5616599335923818

Epoch: 410| Step: 0
Training loss: 2.099050048136952
Validation loss: 2.565436473755189

Epoch: 6| Step: 1
Training loss: 1.985742833450796
Validation loss: 2.5682783578432518

Epoch: 6| Step: 2
Training loss: 2.4963015856352997
Validation loss: 2.5362093425236387

Epoch: 6| Step: 3
Training loss: 2.1573963158934353
Validation loss: 2.5306818618342644

Epoch: 6| Step: 4
Training loss: 1.9447914252939127
Validation loss: 2.517369116088074

Epoch: 6| Step: 5
Training loss: 2.399187399467764
Validation loss: 2.5083367591316406

Epoch: 6| Step: 6
Training loss: 2.26972642804513
Validation loss: 2.4996372616034104

Epoch: 6| Step: 7
Training loss: 2.3982614458809683
Validation loss: 2.4805650458046986

Epoch: 6| Step: 8
Training loss: 2.598806576830853
Validation loss: 2.4643505882317047

Epoch: 6| Step: 9
Training loss: 2.494834809272033
Validation loss: 2.4510631362464728

Epoch: 6| Step: 10
Training loss: 2.709620438912733
Validation loss: 2.4330449584807687

Epoch: 6| Step: 11
Training loss: 2.0049983983972863
Validation loss: 2.4170487398517313

Epoch: 6| Step: 12
Training loss: 2.3614101095930957
Validation loss: 2.412133041783192

Epoch: 6| Step: 13
Training loss: 2.1080259176901315
Validation loss: 2.4348583836900235

Epoch: 411| Step: 0
Training loss: 1.8379721547446852
Validation loss: 2.474698347326916

Epoch: 6| Step: 1
Training loss: 2.319652733298798
Validation loss: 2.489586521770838

Epoch: 6| Step: 2
Training loss: 2.411252654980374
Validation loss: 2.5063218928527227

Epoch: 6| Step: 3
Training loss: 1.9533885320257105
Validation loss: 2.5058751996183073

Epoch: 6| Step: 4
Training loss: 2.4292914260923375
Validation loss: 2.4992925258155205

Epoch: 6| Step: 5
Training loss: 2.293493571486777
Validation loss: 2.5006476127479114

Epoch: 6| Step: 6
Training loss: 1.9369195868600002
Validation loss: 2.499538463115013

Epoch: 6| Step: 7
Training loss: 1.8358934762424586
Validation loss: 2.5187315040193647

Epoch: 6| Step: 8
Training loss: 3.0209761662532713
Validation loss: 2.480570998186616

Epoch: 6| Step: 9
Training loss: 1.6850501043414807
Validation loss: 2.484217408560084

Epoch: 6| Step: 10
Training loss: 2.674431096839465
Validation loss: 2.4527172102126333

Epoch: 6| Step: 11
Training loss: 2.1541939483430075
Validation loss: 2.472594787956635

Epoch: 6| Step: 12
Training loss: 2.4763840090573477
Validation loss: 2.495378650809132

Epoch: 6| Step: 13
Training loss: 2.4343660209989655
Validation loss: 2.4765983297646157

Epoch: 412| Step: 0
Training loss: 2.266984834032185
Validation loss: 2.477528641482011

Epoch: 6| Step: 1
Training loss: 2.360491961910926
Validation loss: 2.487986006172044

Epoch: 6| Step: 2
Training loss: 2.569308099193544
Validation loss: 2.470501017188572

Epoch: 6| Step: 3
Training loss: 2.8998990139971834
Validation loss: 2.4892121800910685

Epoch: 6| Step: 4
Training loss: 2.5464864797242606
Validation loss: 2.513781844084905

Epoch: 6| Step: 5
Training loss: 1.6216589987803216
Validation loss: 2.5010414845941473

Epoch: 6| Step: 6
Training loss: 1.8240560258910907
Validation loss: 2.526090197302603

Epoch: 6| Step: 7
Training loss: 2.258655747018305
Validation loss: 2.552596217526641

Epoch: 6| Step: 8
Training loss: 2.3595300080367028
Validation loss: 2.5868544192637204

Epoch: 6| Step: 9
Training loss: 2.137598836298015
Validation loss: 2.564450224917477

Epoch: 6| Step: 10
Training loss: 2.0597902472659526
Validation loss: 2.5620725241641704

Epoch: 6| Step: 11
Training loss: 2.168457306121211
Validation loss: 2.5197315952641683

Epoch: 6| Step: 12
Training loss: 2.335031186861478
Validation loss: 2.4768497259981306

Epoch: 6| Step: 13
Training loss: 1.9709307989923197
Validation loss: 2.439838786657966

Epoch: 413| Step: 0
Training loss: 2.188594871090953
Validation loss: 2.413478522760616

Epoch: 6| Step: 1
Training loss: 2.410875506787631
Validation loss: 2.4100332117870757

Epoch: 6| Step: 2
Training loss: 2.0068062364742523
Validation loss: 2.432171291724259

Epoch: 6| Step: 3
Training loss: 2.2017671986723886
Validation loss: 2.4378876189893868

Epoch: 6| Step: 4
Training loss: 2.4555278114354873
Validation loss: 2.448355447214759

Epoch: 6| Step: 5
Training loss: 2.224219980564454
Validation loss: 2.470067976827062

Epoch: 6| Step: 6
Training loss: 2.2021579649184146
Validation loss: 2.4690101889338156

Epoch: 6| Step: 7
Training loss: 2.4180448701921757
Validation loss: 2.4670948270855133

Epoch: 6| Step: 8
Training loss: 1.9447205650219486
Validation loss: 2.478900766594621

Epoch: 6| Step: 9
Training loss: 2.5764448760176717
Validation loss: 2.5057706031564715

Epoch: 6| Step: 10
Training loss: 2.1666856422571508
Validation loss: 2.5271723170629388

Epoch: 6| Step: 11
Training loss: 2.384310492246658
Validation loss: 2.5118917132212197

Epoch: 6| Step: 12
Training loss: 2.2840317787925857
Validation loss: 2.5429773654561507

Epoch: 6| Step: 13
Training loss: 1.5489241773494706
Validation loss: 2.483453697549274

Epoch: 414| Step: 0
Training loss: 2.3109389526280086
Validation loss: 2.4720553224693576

Epoch: 6| Step: 1
Training loss: 2.6230143348339956
Validation loss: 2.456597740801072

Epoch: 6| Step: 2
Training loss: 2.6270156569288403
Validation loss: 2.412385547058309

Epoch: 6| Step: 3
Training loss: 2.0931861459817034
Validation loss: 2.400121187325919

Epoch: 6| Step: 4
Training loss: 1.629729796872914
Validation loss: 2.413203028201336

Epoch: 6| Step: 5
Training loss: 2.1332258445760695
Validation loss: 2.398549288293351

Epoch: 6| Step: 6
Training loss: 2.3015527128074957
Validation loss: 2.418646432912068

Epoch: 6| Step: 7
Training loss: 2.157952562519612
Validation loss: 2.386333719364414

Epoch: 6| Step: 8
Training loss: 1.9058722450054795
Validation loss: 2.4037209441750966

Epoch: 6| Step: 9
Training loss: 2.471285712872147
Validation loss: 2.4041311233010725

Epoch: 6| Step: 10
Training loss: 2.0788615362784078
Validation loss: 2.4158577298850976

Epoch: 6| Step: 11
Training loss: 1.7112321991757429
Validation loss: 2.468605638537957

Epoch: 6| Step: 12
Training loss: 2.222645308697257
Validation loss: 2.486465338312658

Epoch: 6| Step: 13
Training loss: 3.081528539235449
Validation loss: 2.5001519085251696

Epoch: 415| Step: 0
Training loss: 2.1771045543847123
Validation loss: 2.637228271160191

Epoch: 6| Step: 1
Training loss: 1.6075962940758983
Validation loss: 2.7297431720780456

Epoch: 6| Step: 2
Training loss: 2.1353907389733764
Validation loss: 2.7612770134453486

Epoch: 6| Step: 3
Training loss: 2.831539895414029
Validation loss: 2.6776316764963295

Epoch: 6| Step: 4
Training loss: 2.3535394311231155
Validation loss: 2.6646165731998854

Epoch: 6| Step: 5
Training loss: 2.3017783214641043
Validation loss: 2.603723873435667

Epoch: 6| Step: 6
Training loss: 2.650522497237444
Validation loss: 2.522502138987419

Epoch: 6| Step: 7
Training loss: 2.402824936724311
Validation loss: 2.4352344325985653

Epoch: 6| Step: 8
Training loss: 2.0914785105462843
Validation loss: 2.406965761093632

Epoch: 6| Step: 9
Training loss: 1.98024036663165
Validation loss: 2.3874771494610267

Epoch: 6| Step: 10
Training loss: 2.3956963099120414
Validation loss: 2.3766529988729457

Epoch: 6| Step: 11
Training loss: 2.5583679565505695
Validation loss: 2.383981909371074

Epoch: 6| Step: 12
Training loss: 2.376887625400696
Validation loss: 2.4269984603365806

Epoch: 6| Step: 13
Training loss: 1.5135461767365308
Validation loss: 2.460463902246647

Epoch: 416| Step: 0
Training loss: 2.298669127327265
Validation loss: 2.5054220448215982

Epoch: 6| Step: 1
Training loss: 1.8165331068143145
Validation loss: 2.563868969581896

Epoch: 6| Step: 2
Training loss: 2.431597483302033
Validation loss: 2.5857797927830877

Epoch: 6| Step: 3
Training loss: 2.2111246953107124
Validation loss: 2.5347503054457494

Epoch: 6| Step: 4
Training loss: 1.928900616167508
Validation loss: 2.553950467075085

Epoch: 6| Step: 5
Training loss: 2.273107655511217
Validation loss: 2.5179086708105514

Epoch: 6| Step: 6
Training loss: 2.455741507430772
Validation loss: 2.501577130062815

Epoch: 6| Step: 7
Training loss: 2.045217294130969
Validation loss: 2.4656899447698257

Epoch: 6| Step: 8
Training loss: 2.482513594114763
Validation loss: 2.42915413245615

Epoch: 6| Step: 9
Training loss: 1.9974731934315872
Validation loss: 2.4309552826067464

Epoch: 6| Step: 10
Training loss: 2.3579054544275184
Validation loss: 2.4169156438134936

Epoch: 6| Step: 11
Training loss: 2.3099685422398495
Validation loss: 2.4209203378041804

Epoch: 6| Step: 12
Training loss: 2.404242334436725
Validation loss: 2.403547586261356

Epoch: 6| Step: 13
Training loss: 2.3310466074234175
Validation loss: 2.4062379501929616

Epoch: 417| Step: 0
Training loss: 1.988965349604228
Validation loss: 2.443471741568269

Epoch: 6| Step: 1
Training loss: 2.0497837510841226
Validation loss: 2.49020603331898

Epoch: 6| Step: 2
Training loss: 1.7938207791815453
Validation loss: 2.515802651157076

Epoch: 6| Step: 3
Training loss: 1.9847559525678875
Validation loss: 2.5411348463976675

Epoch: 6| Step: 4
Training loss: 3.17647305656786
Validation loss: 2.565899882252797

Epoch: 6| Step: 5
Training loss: 2.4986207972332855
Validation loss: 2.537035513539593

Epoch: 6| Step: 6
Training loss: 2.1565977175547943
Validation loss: 2.486152265518998

Epoch: 6| Step: 7
Training loss: 2.1421833909188
Validation loss: 2.4652404575121847

Epoch: 6| Step: 8
Training loss: 1.4753867014215931
Validation loss: 2.4271444515169924

Epoch: 6| Step: 9
Training loss: 2.721173050738267
Validation loss: 2.4163108471092256

Epoch: 6| Step: 10
Training loss: 1.8708705569885025
Validation loss: 2.391127071785498

Epoch: 6| Step: 11
Training loss: 2.0108100097838126
Validation loss: 2.3925642276416386

Epoch: 6| Step: 12
Training loss: 2.443965845746577
Validation loss: 2.4170233838407063

Epoch: 6| Step: 13
Training loss: 2.4507905579895763
Validation loss: 2.452718343235958

Epoch: 418| Step: 0
Training loss: 2.0699783919307717
Validation loss: 2.44459351867036

Epoch: 6| Step: 1
Training loss: 2.0884330765675765
Validation loss: 2.4717186902811195

Epoch: 6| Step: 2
Training loss: 1.678481409737526
Validation loss: 2.5135963110445254

Epoch: 6| Step: 3
Training loss: 2.761910395467741
Validation loss: 2.583946274066373

Epoch: 6| Step: 4
Training loss: 2.2684565246599857
Validation loss: 2.625924337831348

Epoch: 6| Step: 5
Training loss: 2.4988307125763334
Validation loss: 2.615378373950437

Epoch: 6| Step: 6
Training loss: 2.47733100014458
Validation loss: 2.5105860101621467

Epoch: 6| Step: 7
Training loss: 1.978401504644677
Validation loss: 2.4759895508455054

Epoch: 6| Step: 8
Training loss: 2.7393529430061037
Validation loss: 2.439278748971084

Epoch: 6| Step: 9
Training loss: 2.4468512522981047
Validation loss: 2.415027690283617

Epoch: 6| Step: 10
Training loss: 2.060401773993577
Validation loss: 2.3940006888759515

Epoch: 6| Step: 11
Training loss: 1.7286152094371272
Validation loss: 2.3945842843373133

Epoch: 6| Step: 12
Training loss: 2.099955685465865
Validation loss: 2.3941214970902545

Epoch: 6| Step: 13
Training loss: 2.3620678016886325
Validation loss: 2.398377682620434

Epoch: 419| Step: 0
Training loss: 2.437324126329847
Validation loss: 2.4202112607526325

Epoch: 6| Step: 1
Training loss: 2.167241264836983
Validation loss: 2.4665461628714844

Epoch: 6| Step: 2
Training loss: 1.966024176936931
Validation loss: 2.5291492227272827

Epoch: 6| Step: 3
Training loss: 1.7541980797982093
Validation loss: 2.5534647350668607

Epoch: 6| Step: 4
Training loss: 1.7060894845209953
Validation loss: 2.57975216028964

Epoch: 6| Step: 5
Training loss: 1.986978460055951
Validation loss: 2.5696693221860016

Epoch: 6| Step: 6
Training loss: 1.0618069014961045
Validation loss: 2.5488796999773036

Epoch: 6| Step: 7
Training loss: 2.6280907192103657
Validation loss: 2.5440288610049886

Epoch: 6| Step: 8
Training loss: 2.576414986130071
Validation loss: 2.486708569453078

Epoch: 6| Step: 9
Training loss: 2.834873977362891
Validation loss: 2.468911911896595

Epoch: 6| Step: 10
Training loss: 2.341001399375892
Validation loss: 2.420606677341592

Epoch: 6| Step: 11
Training loss: 2.1755476163555403
Validation loss: 2.410348473134107

Epoch: 6| Step: 12
Training loss: 2.5798646548352235
Validation loss: 2.3970524254842944

Epoch: 6| Step: 13
Training loss: 2.2147099422557384
Validation loss: 2.3852436516822086

Epoch: 420| Step: 0
Training loss: 2.307836831286768
Validation loss: 2.39837035205091

Epoch: 6| Step: 1
Training loss: 2.4033238838352173
Validation loss: 2.392493109834424

Epoch: 6| Step: 2
Training loss: 1.1830492435308932
Validation loss: 2.445726872403591

Epoch: 6| Step: 3
Training loss: 2.833069078426646
Validation loss: 2.48259545119546

Epoch: 6| Step: 4
Training loss: 2.632973323630382
Validation loss: 2.561530809577675

Epoch: 6| Step: 5
Training loss: 2.3137306856393085
Validation loss: 2.6483125595768717

Epoch: 6| Step: 6
Training loss: 2.0039671652534787
Validation loss: 2.6106896618512003

Epoch: 6| Step: 7
Training loss: 2.1743417905863005
Validation loss: 2.5297118835625962

Epoch: 6| Step: 8
Training loss: 1.9363531594719547
Validation loss: 2.4580835448751466

Epoch: 6| Step: 9
Training loss: 2.110594898265643
Validation loss: 2.410460325366445

Epoch: 6| Step: 10
Training loss: 2.1006134045594966
Validation loss: 2.379365707021559

Epoch: 6| Step: 11
Training loss: 2.368869196728624
Validation loss: 2.3494886294442625

Epoch: 6| Step: 12
Training loss: 2.5230639863308806
Validation loss: 2.3656126410009657

Epoch: 6| Step: 13
Training loss: 1.849523008559746
Validation loss: 2.3433079303319166

Epoch: 421| Step: 0
Training loss: 1.9333905970654048
Validation loss: 2.3554995182483256

Epoch: 6| Step: 1
Training loss: 1.999119803337995
Validation loss: 2.3544714119963834

Epoch: 6| Step: 2
Training loss: 2.4551414414816644
Validation loss: 2.3550838832939847

Epoch: 6| Step: 3
Training loss: 2.606741575724115
Validation loss: 2.4037046507401945

Epoch: 6| Step: 4
Training loss: 2.1959305840032246
Validation loss: 2.408820811902401

Epoch: 6| Step: 5
Training loss: 2.1947238988300892
Validation loss: 2.4569060212863207

Epoch: 6| Step: 6
Training loss: 1.6697510392102548
Validation loss: 2.4869897556235205

Epoch: 6| Step: 7
Training loss: 2.4608281186939163
Validation loss: 2.5166725642963628

Epoch: 6| Step: 8
Training loss: 2.345291037972774
Validation loss: 2.552906038545059

Epoch: 6| Step: 9
Training loss: 2.2642723518035743
Validation loss: 2.590268695390201

Epoch: 6| Step: 10
Training loss: 1.9733846698131896
Validation loss: 2.5739544210491667

Epoch: 6| Step: 11
Training loss: 2.162051812622979
Validation loss: 2.5735290894181135

Epoch: 6| Step: 12
Training loss: 2.4173996460528766
Validation loss: 2.516885849999066

Epoch: 6| Step: 13
Training loss: 2.1471631518890404
Validation loss: 2.4868841519809104

Epoch: 422| Step: 0
Training loss: 1.9124962451374368
Validation loss: 2.4793103504673746

Epoch: 6| Step: 1
Training loss: 1.9630930326495064
Validation loss: 2.4642579215681653

Epoch: 6| Step: 2
Training loss: 1.9712447451447068
Validation loss: 2.4468833461676707

Epoch: 6| Step: 3
Training loss: 2.4907141847808543
Validation loss: 2.400329606690364

Epoch: 6| Step: 4
Training loss: 1.7209843764008776
Validation loss: 2.4040700431728177

Epoch: 6| Step: 5
Training loss: 1.5081849898142392
Validation loss: 2.392487269424568

Epoch: 6| Step: 6
Training loss: 2.415929769657327
Validation loss: 2.399317157973885

Epoch: 6| Step: 7
Training loss: 1.9048550614215227
Validation loss: 2.4545519699129534

Epoch: 6| Step: 8
Training loss: 2.644590120773136
Validation loss: 2.4696552200116666

Epoch: 6| Step: 9
Training loss: 2.3911068499281747
Validation loss: 2.543441863287395

Epoch: 6| Step: 10
Training loss: 2.602826152375949
Validation loss: 2.5099098988613204

Epoch: 6| Step: 11
Training loss: 2.2591569850727784
Validation loss: 2.454094169606249

Epoch: 6| Step: 12
Training loss: 2.487127830229598
Validation loss: 2.410782789146964

Epoch: 6| Step: 13
Training loss: 2.3729945298689255
Validation loss: 2.4068141958212617

Epoch: 423| Step: 0
Training loss: 2.261062131450676
Validation loss: 2.391230031098595

Epoch: 6| Step: 1
Training loss: 2.7531900110265557
Validation loss: 2.356184502366379

Epoch: 6| Step: 2
Training loss: 1.9735344773096524
Validation loss: 2.3765811093651865

Epoch: 6| Step: 3
Training loss: 2.312519795101087
Validation loss: 2.399691703095764

Epoch: 6| Step: 4
Training loss: 1.841552265060468
Validation loss: 2.4098321741965782

Epoch: 6| Step: 5
Training loss: 1.421909625292047
Validation loss: 2.450521759534837

Epoch: 6| Step: 6
Training loss: 2.401032972561424
Validation loss: 2.481708748228561

Epoch: 6| Step: 7
Training loss: 2.108730754662719
Validation loss: 2.5194609189358563

Epoch: 6| Step: 8
Training loss: 2.1544675232021286
Validation loss: 2.606706368401785

Epoch: 6| Step: 9
Training loss: 2.2263741396820462
Validation loss: 2.651878611793773

Epoch: 6| Step: 10
Training loss: 2.2277693840538864
Validation loss: 2.692236351373808

Epoch: 6| Step: 11
Training loss: 2.1603485077051
Validation loss: 2.630436509667329

Epoch: 6| Step: 12
Training loss: 2.267556044991015
Validation loss: 2.5518364266820712

Epoch: 6| Step: 13
Training loss: 2.694269216111619
Validation loss: 2.522366751868315

Epoch: 424| Step: 0
Training loss: 2.2242647863674567
Validation loss: 2.4982486543203692

Epoch: 6| Step: 1
Training loss: 2.210222971270807
Validation loss: 2.471632610352471

Epoch: 6| Step: 2
Training loss: 2.6028452050825255
Validation loss: 2.4588952219275417

Epoch: 6| Step: 3
Training loss: 1.785079386786346
Validation loss: 2.417066247923458

Epoch: 6| Step: 4
Training loss: 1.9521801914000727
Validation loss: 2.399909051672476

Epoch: 6| Step: 5
Training loss: 2.533581166525807
Validation loss: 2.4059601811512

Epoch: 6| Step: 6
Training loss: 2.5149969418698594
Validation loss: 2.429048479828123

Epoch: 6| Step: 7
Training loss: 2.2620777642385335
Validation loss: 2.4393114348506435

Epoch: 6| Step: 8
Training loss: 2.1646033757603327
Validation loss: 2.4724269943983206

Epoch: 6| Step: 9
Training loss: 1.645949234885323
Validation loss: 2.4672955119523836

Epoch: 6| Step: 10
Training loss: 2.135130576221194
Validation loss: 2.480497554850483

Epoch: 6| Step: 11
Training loss: 2.107304779278445
Validation loss: 2.4783721597603248

Epoch: 6| Step: 12
Training loss: 2.2283892716904967
Validation loss: 2.4337080917105367

Epoch: 6| Step: 13
Training loss: 1.9218077609077486
Validation loss: 2.398610048352636

Epoch: 425| Step: 0
Training loss: 2.627447349826603
Validation loss: 2.371524319550407

Epoch: 6| Step: 1
Training loss: 2.010669382712421
Validation loss: 2.388832277468383

Epoch: 6| Step: 2
Training loss: 2.585084342244669
Validation loss: 2.363829343219239

Epoch: 6| Step: 3
Training loss: 2.1296094380525687
Validation loss: 2.3658064710428244

Epoch: 6| Step: 4
Training loss: 2.127608213261305
Validation loss: 2.388836749394114

Epoch: 6| Step: 5
Training loss: 2.0412973601902604
Validation loss: 2.418876037595297

Epoch: 6| Step: 6
Training loss: 2.387596555824499
Validation loss: 2.4416406672993665

Epoch: 6| Step: 7
Training loss: 2.133650730284311
Validation loss: 2.4983605998225302

Epoch: 6| Step: 8
Training loss: 2.330138391960807
Validation loss: 2.5716156314065257

Epoch: 6| Step: 9
Training loss: 1.1379063226394268
Validation loss: 2.6346654171815946

Epoch: 6| Step: 10
Training loss: 2.173261021813327
Validation loss: 2.6731117915514475

Epoch: 6| Step: 11
Training loss: 2.696140062746288
Validation loss: 2.629617177508122

Epoch: 6| Step: 12
Training loss: 1.735403288766405
Validation loss: 2.521568555880212

Epoch: 6| Step: 13
Training loss: 2.1978817495552567
Validation loss: 2.457029850814267

Epoch: 426| Step: 0
Training loss: 1.6134469822322912
Validation loss: 2.417863944575353

Epoch: 6| Step: 1
Training loss: 1.773760929947688
Validation loss: 2.3903827119530145

Epoch: 6| Step: 2
Training loss: 2.553964308355638
Validation loss: 2.362466315920076

Epoch: 6| Step: 3
Training loss: 2.126059436365604
Validation loss: 2.3655492398019042

Epoch: 6| Step: 4
Training loss: 1.7348425982310922
Validation loss: 2.350642571518391

Epoch: 6| Step: 5
Training loss: 2.68796233702568
Validation loss: 2.366181263056129

Epoch: 6| Step: 6
Training loss: 2.2941488059619157
Validation loss: 2.4063434601324514

Epoch: 6| Step: 7
Training loss: 1.9613453718231324
Validation loss: 2.406208913212871

Epoch: 6| Step: 8
Training loss: 1.8333750922331198
Validation loss: 2.4472012080184014

Epoch: 6| Step: 9
Training loss: 2.8355310742581357
Validation loss: 2.463524610993736

Epoch: 6| Step: 10
Training loss: 2.4935771452002324
Validation loss: 2.532379941369827

Epoch: 6| Step: 11
Training loss: 1.6898032117858481
Validation loss: 2.5325365674630995

Epoch: 6| Step: 12
Training loss: 2.195014037345891
Validation loss: 2.553830774862762

Epoch: 6| Step: 13
Training loss: 2.4612967092751874
Validation loss: 2.5501961342496333

Epoch: 427| Step: 0
Training loss: 2.250143470428543
Validation loss: 2.4728680065591178

Epoch: 6| Step: 1
Training loss: 2.134564249744055
Validation loss: 2.4432914659331924

Epoch: 6| Step: 2
Training loss: 1.9403092107439293
Validation loss: 2.4316606689712925

Epoch: 6| Step: 3
Training loss: 2.413891832559379
Validation loss: 2.399419598104304

Epoch: 6| Step: 4
Training loss: 1.7279420062505952
Validation loss: 2.3664668824141737

Epoch: 6| Step: 5
Training loss: 2.399987331992731
Validation loss: 2.3920474136067496

Epoch: 6| Step: 6
Training loss: 2.0001058550477984
Validation loss: 2.4025014597951166

Epoch: 6| Step: 7
Training loss: 2.074943573885408
Validation loss: 2.4047330840795316

Epoch: 6| Step: 8
Training loss: 2.43808308987557
Validation loss: 2.45287169374067

Epoch: 6| Step: 9
Training loss: 2.674671070874291
Validation loss: 2.4564813764540068

Epoch: 6| Step: 10
Training loss: 1.6264139772704904
Validation loss: 2.494708332632067

Epoch: 6| Step: 11
Training loss: 2.1018276118285653
Validation loss: 2.47722728529723

Epoch: 6| Step: 12
Training loss: 2.2051092640626853
Validation loss: 2.4843315749663035

Epoch: 6| Step: 13
Training loss: 1.8978663083656133
Validation loss: 2.4872503334569376

Epoch: 428| Step: 0
Training loss: 2.0313857986832637
Validation loss: 2.5245880858456258

Epoch: 6| Step: 1
Training loss: 2.40442072706616
Validation loss: 2.531971514532813

Epoch: 6| Step: 2
Training loss: 2.0861009398019266
Validation loss: 2.550307811486154

Epoch: 6| Step: 3
Training loss: 1.8502123453086523
Validation loss: 2.5157384197837223

Epoch: 6| Step: 4
Training loss: 2.0034519446492953
Validation loss: 2.4666031214697384

Epoch: 6| Step: 5
Training loss: 2.4049776354600447
Validation loss: 2.4326938473104063

Epoch: 6| Step: 6
Training loss: 2.010834197597368
Validation loss: 2.4304385396639936

Epoch: 6| Step: 7
Training loss: 2.7485273059184614
Validation loss: 2.3948140694562188

Epoch: 6| Step: 8
Training loss: 1.662897983039203
Validation loss: 2.406261521306374

Epoch: 6| Step: 9
Training loss: 2.492559327516636
Validation loss: 2.395904838133422

Epoch: 6| Step: 10
Training loss: 2.3964944231464673
Validation loss: 2.403985976148055

Epoch: 6| Step: 11
Training loss: 1.860427366299278
Validation loss: 2.409745024045342

Epoch: 6| Step: 12
Training loss: 1.8228215292673127
Validation loss: 2.444326970169731

Epoch: 6| Step: 13
Training loss: 2.024471534248125
Validation loss: 2.4656329390825356

Epoch: 429| Step: 0
Training loss: 2.2788462058478687
Validation loss: 2.482407486104682

Epoch: 6| Step: 1
Training loss: 1.8708451330864904
Validation loss: 2.505419258545591

Epoch: 6| Step: 2
Training loss: 2.633305625125922
Validation loss: 2.50822280432042

Epoch: 6| Step: 3
Training loss: 2.122618968132178
Validation loss: 2.490900082159579

Epoch: 6| Step: 4
Training loss: 1.996712784603386
Validation loss: 2.462853884864701

Epoch: 6| Step: 5
Training loss: 2.34132931633491
Validation loss: 2.4465180387442986

Epoch: 6| Step: 6
Training loss: 2.464398569085774
Validation loss: 2.4266127383158045

Epoch: 6| Step: 7
Training loss: 1.8597441875758198
Validation loss: 2.409979541420939

Epoch: 6| Step: 8
Training loss: 2.6457388753375053
Validation loss: 2.4067111948388002

Epoch: 6| Step: 9
Training loss: 2.0170503057013676
Validation loss: 2.3927467148504005

Epoch: 6| Step: 10
Training loss: 1.7500662109928546
Validation loss: 2.3916190124608585

Epoch: 6| Step: 11
Training loss: 1.4876730970437029
Validation loss: 2.4097757556846164

Epoch: 6| Step: 12
Training loss: 2.036679333128721
Validation loss: 2.413711116078204

Epoch: 6| Step: 13
Training loss: 1.9242362427003492
Validation loss: 2.4293943730244485

Epoch: 430| Step: 0
Training loss: 2.421584081097022
Validation loss: 2.4078020508802105

Epoch: 6| Step: 1
Training loss: 1.963493839022085
Validation loss: 2.442527414985198

Epoch: 6| Step: 2
Training loss: 2.04552269446391
Validation loss: 2.4773029263348847

Epoch: 6| Step: 3
Training loss: 1.6013067273849995
Validation loss: 2.486582810994039

Epoch: 6| Step: 4
Training loss: 1.9840953960326255
Validation loss: 2.515256425295391

Epoch: 6| Step: 5
Training loss: 2.125610263933778
Validation loss: 2.5494557304318644

Epoch: 6| Step: 6
Training loss: 1.9071966853538613
Validation loss: 2.553028848840527

Epoch: 6| Step: 7
Training loss: 1.9445017155281439
Validation loss: 2.5678498282536126

Epoch: 6| Step: 8
Training loss: 2.39433987274332
Validation loss: 2.547300978412791

Epoch: 6| Step: 9
Training loss: 1.657253824885327
Validation loss: 2.4592380659483934

Epoch: 6| Step: 10
Training loss: 2.7201827209471343
Validation loss: 2.4251868011859323

Epoch: 6| Step: 11
Training loss: 1.7028412188766522
Validation loss: 2.3935344379543637

Epoch: 6| Step: 12
Training loss: 2.6871905481361362
Validation loss: 2.3614205197695273

Epoch: 6| Step: 13
Training loss: 2.8017123708300793
Validation loss: 2.3412052671565102

Epoch: 431| Step: 0
Training loss: 2.1389549033256157
Validation loss: 2.368647242227533

Epoch: 6| Step: 1
Training loss: 1.9702013509257619
Validation loss: 2.399391849437088

Epoch: 6| Step: 2
Training loss: 2.024300645226495
Validation loss: 2.402059658009176

Epoch: 6| Step: 3
Training loss: 1.7883844548313628
Validation loss: 2.4252228926115738

Epoch: 6| Step: 4
Training loss: 2.709438470187221
Validation loss: 2.4749270807410584

Epoch: 6| Step: 5
Training loss: 2.329720174661352
Validation loss: 2.49372580984767

Epoch: 6| Step: 6
Training loss: 2.1766729257015576
Validation loss: 2.4613987550464294

Epoch: 6| Step: 7
Training loss: 1.7890154570012535
Validation loss: 2.4303497054615915

Epoch: 6| Step: 8
Training loss: 2.0498333002558744
Validation loss: 2.4289389754667785

Epoch: 6| Step: 9
Training loss: 2.015829859532547
Validation loss: 2.405162080048868

Epoch: 6| Step: 10
Training loss: 2.0311684225280406
Validation loss: 2.39776597224153

Epoch: 6| Step: 11
Training loss: 2.230925130835208
Validation loss: 2.413086341208523

Epoch: 6| Step: 12
Training loss: 2.1170573176939183
Validation loss: 2.43255720204022

Epoch: 6| Step: 13
Training loss: 2.4135030450037114
Validation loss: 2.4476215461305353

Epoch: 432| Step: 0
Training loss: 1.4309816600336076
Validation loss: 2.5095036828940906

Epoch: 6| Step: 1
Training loss: 2.3457533348992428
Validation loss: 2.5627956054804777

Epoch: 6| Step: 2
Training loss: 0.9202353556866048
Validation loss: 2.573740767695301

Epoch: 6| Step: 3
Training loss: 2.467761071026593
Validation loss: 2.5738361461526997

Epoch: 6| Step: 4
Training loss: 2.349818701548114
Validation loss: 2.5084958992257276

Epoch: 6| Step: 5
Training loss: 2.505462210646381
Validation loss: 2.464645779003674

Epoch: 6| Step: 6
Training loss: 1.6543009103773096
Validation loss: 2.413815657869298

Epoch: 6| Step: 7
Training loss: 2.141576625054309
Validation loss: 2.4191437933421494

Epoch: 6| Step: 8
Training loss: 1.929610772093949
Validation loss: 2.442192241589646

Epoch: 6| Step: 9
Training loss: 2.24154813469645
Validation loss: 2.5076524669826648

Epoch: 6| Step: 10
Training loss: 2.4716269232379227
Validation loss: 2.483448665137849

Epoch: 6| Step: 11
Training loss: 2.749265572706649
Validation loss: 2.4641813729219555

Epoch: 6| Step: 12
Training loss: 2.016651454058981
Validation loss: 2.4224148162264445

Epoch: 6| Step: 13
Training loss: 1.869153125366377
Validation loss: 2.408950546363067

Epoch: 433| Step: 0
Training loss: 2.2710581910217176
Validation loss: 2.3566057991237317

Epoch: 6| Step: 1
Training loss: 2.3899830473613832
Validation loss: 2.392144410076752

Epoch: 6| Step: 2
Training loss: 1.923998706051873
Validation loss: 2.3854929135389478

Epoch: 6| Step: 3
Training loss: 2.459530964308457
Validation loss: 2.41907138086841

Epoch: 6| Step: 4
Training loss: 1.9549615998655454
Validation loss: 2.4235310386773

Epoch: 6| Step: 5
Training loss: 2.3145359459073997
Validation loss: 2.4447570356512807

Epoch: 6| Step: 6
Training loss: 2.110865765530895
Validation loss: 2.4494970156090314

Epoch: 6| Step: 7
Training loss: 2.097287619822329
Validation loss: 2.4845590345908395

Epoch: 6| Step: 8
Training loss: 1.804488266024936
Validation loss: 2.495199420175012

Epoch: 6| Step: 9
Training loss: 2.2474961654409724
Validation loss: 2.490317513197826

Epoch: 6| Step: 10
Training loss: 2.230378531587192
Validation loss: 2.507481716215591

Epoch: 6| Step: 11
Training loss: 1.5393156821267473
Validation loss: 2.5373893840374677

Epoch: 6| Step: 12
Training loss: 2.1780369569779836
Validation loss: 2.4979318534582835

Epoch: 6| Step: 13
Training loss: 1.790145346425291
Validation loss: 2.488989577762958

Epoch: 434| Step: 0
Training loss: 1.366698869853028
Validation loss: 2.4578055108348735

Epoch: 6| Step: 1
Training loss: 2.250085193292733
Validation loss: 2.4468849046458208

Epoch: 6| Step: 2
Training loss: 2.54114397855111
Validation loss: 2.454252098158285

Epoch: 6| Step: 3
Training loss: 2.4018004260471058
Validation loss: 2.4704679516721826

Epoch: 6| Step: 4
Training loss: 2.12886873264677
Validation loss: 2.4163254863707166

Epoch: 6| Step: 5
Training loss: 2.3180865261395396
Validation loss: 2.4231733162636817

Epoch: 6| Step: 6
Training loss: 2.339622831025351
Validation loss: 2.4053819888919836

Epoch: 6| Step: 7
Training loss: 2.217283597104302
Validation loss: 2.439359668069348

Epoch: 6| Step: 8
Training loss: 1.9250875775120748
Validation loss: 2.4610161839863007

Epoch: 6| Step: 9
Training loss: 1.9576768248143102
Validation loss: 2.529574714009086

Epoch: 6| Step: 10
Training loss: 1.8952538439549789
Validation loss: 2.5517239176687796

Epoch: 6| Step: 11
Training loss: 2.3921267710426664
Validation loss: 2.5068327181645094

Epoch: 6| Step: 12
Training loss: 1.8244603913916795
Validation loss: 2.462517306559181

Epoch: 6| Step: 13
Training loss: 1.1760126437493612
Validation loss: 2.399865661086374

Epoch: 435| Step: 0
Training loss: 2.0900071124818234
Validation loss: 2.406048995786357

Epoch: 6| Step: 1
Training loss: 2.2207525108569706
Validation loss: 2.3769150716231873

Epoch: 6| Step: 2
Training loss: 2.320875722428394
Validation loss: 2.3911869493950477

Epoch: 6| Step: 3
Training loss: 2.1138750465442238
Validation loss: 2.407276085545493

Epoch: 6| Step: 4
Training loss: 2.3854656519850663
Validation loss: 2.469232681542774

Epoch: 6| Step: 5
Training loss: 2.7556262117047066
Validation loss: 2.53142471956215

Epoch: 6| Step: 6
Training loss: 1.9614375111478672
Validation loss: 2.586281533736045

Epoch: 6| Step: 7
Training loss: 1.7827248072809423
Validation loss: 2.6273546513329658

Epoch: 6| Step: 8
Training loss: 2.257892330038758
Validation loss: 2.5913732486500565

Epoch: 6| Step: 9
Training loss: 1.688917553634713
Validation loss: 2.5588520965741792

Epoch: 6| Step: 10
Training loss: 1.9473350458961451
Validation loss: 2.488667894432847

Epoch: 6| Step: 11
Training loss: 2.0089305332719216
Validation loss: 2.4694033244128804

Epoch: 6| Step: 12
Training loss: 1.86655942177371
Validation loss: 2.4365552018258785

Epoch: 6| Step: 13
Training loss: 2.3249907421625053
Validation loss: 2.407494813099951

Epoch: 436| Step: 0
Training loss: 2.0640322455615303
Validation loss: 2.4082511908569075

Epoch: 6| Step: 1
Training loss: 1.9241675992324352
Validation loss: 2.3784048493410213

Epoch: 6| Step: 2
Training loss: 2.171655877126306
Validation loss: 2.4054712549068986

Epoch: 6| Step: 3
Training loss: 2.091789466424497
Validation loss: 2.45204395024155

Epoch: 6| Step: 4
Training loss: 1.8923272910483886
Validation loss: 2.4523947256918177

Epoch: 6| Step: 5
Training loss: 1.8084476815677508
Validation loss: 2.4283937295671727

Epoch: 6| Step: 6
Training loss: 1.5940515569488138
Validation loss: 2.4396581317085673

Epoch: 6| Step: 7
Training loss: 2.0358702712182986
Validation loss: 2.4496620042600497

Epoch: 6| Step: 8
Training loss: 2.061076742447218
Validation loss: 2.456994788482985

Epoch: 6| Step: 9
Training loss: 2.2462657033363955
Validation loss: 2.485522958915373

Epoch: 6| Step: 10
Training loss: 2.4187516283921866
Validation loss: 2.4951005856973247

Epoch: 6| Step: 11
Training loss: 2.750945795582522
Validation loss: 2.4425799230693963

Epoch: 6| Step: 12
Training loss: 2.5237723208116303
Validation loss: 2.4036718006340325

Epoch: 6| Step: 13
Training loss: 1.901575830392496
Validation loss: 2.4180462781535477

Epoch: 437| Step: 0
Training loss: 1.7391955767746365
Validation loss: 2.4085457191219

Epoch: 6| Step: 1
Training loss: 2.584685515231299
Validation loss: 2.4050110620013965

Epoch: 6| Step: 2
Training loss: 2.1689246467385583
Validation loss: 2.4434097132846815

Epoch: 6| Step: 3
Training loss: 2.321612575071575
Validation loss: 2.445465260296979

Epoch: 6| Step: 4
Training loss: 2.372127803955415
Validation loss: 2.433923729787887

Epoch: 6| Step: 5
Training loss: 2.1260848922359945
Validation loss: 2.457439124058428

Epoch: 6| Step: 6
Training loss: 1.8853630423603867
Validation loss: 2.505167722719306

Epoch: 6| Step: 7
Training loss: 1.9243484955139725
Validation loss: 2.5808867149847057

Epoch: 6| Step: 8
Training loss: 2.2734601521100872
Validation loss: 2.5868827406568706

Epoch: 6| Step: 9
Training loss: 1.8718864020253478
Validation loss: 2.586419204197146

Epoch: 6| Step: 10
Training loss: 2.2185896694657083
Validation loss: 2.4823659914425873

Epoch: 6| Step: 11
Training loss: 1.9459818106072717
Validation loss: 2.4287505511416665

Epoch: 6| Step: 12
Training loss: 1.9639475543755975
Validation loss: 2.3766860169428083

Epoch: 6| Step: 13
Training loss: 2.050518607623735
Validation loss: 2.370367815598733

Epoch: 438| Step: 0
Training loss: 2.4237002478102263
Validation loss: 2.383160069489131

Epoch: 6| Step: 1
Training loss: 1.8093463164116488
Validation loss: 2.381008770153352

Epoch: 6| Step: 2
Training loss: 1.8899660459627226
Validation loss: 2.4191699245673224

Epoch: 6| Step: 3
Training loss: 2.2172543494783725
Validation loss: 2.4227711194987744

Epoch: 6| Step: 4
Training loss: 2.27382790271081
Validation loss: 2.483304279620199

Epoch: 6| Step: 5
Training loss: 2.332853699388683
Validation loss: 2.471362455364883

Epoch: 6| Step: 6
Training loss: 1.838397127544991
Validation loss: 2.4590473396513746

Epoch: 6| Step: 7
Training loss: 2.424452855629476
Validation loss: 2.42184376241629

Epoch: 6| Step: 8
Training loss: 1.907254001558731
Validation loss: 2.3956712629617494

Epoch: 6| Step: 9
Training loss: 1.7196290975805943
Validation loss: 2.4095570277130975

Epoch: 6| Step: 10
Training loss: 1.7761626290960968
Validation loss: 2.4212055933816905

Epoch: 6| Step: 11
Training loss: 2.2503434025121
Validation loss: 2.4230996054307994

Epoch: 6| Step: 12
Training loss: 2.0288938502129996
Validation loss: 2.408564872276282

Epoch: 6| Step: 13
Training loss: 2.1661094046707174
Validation loss: 2.406256480874799

Epoch: 439| Step: 0
Training loss: 2.1016309081788473
Validation loss: 2.4481117811358746

Epoch: 6| Step: 1
Training loss: 2.0444256053738425
Validation loss: 2.44463869826542

Epoch: 6| Step: 2
Training loss: 2.1955532607149357
Validation loss: 2.4919337746770656

Epoch: 6| Step: 3
Training loss: 2.232486593755131
Validation loss: 2.4661806869049374

Epoch: 6| Step: 4
Training loss: 1.7576550900657828
Validation loss: 2.492764292321816

Epoch: 6| Step: 5
Training loss: 2.084500507196377
Validation loss: 2.4435204335070453

Epoch: 6| Step: 6
Training loss: 2.1365414394196005
Validation loss: 2.4249796254306726

Epoch: 6| Step: 7
Training loss: 1.888752538147893
Validation loss: 2.4083562421583777

Epoch: 6| Step: 8
Training loss: 1.8821703817041007
Validation loss: 2.3811393987069858

Epoch: 6| Step: 9
Training loss: 1.9639058538468812
Validation loss: 2.383154850571476

Epoch: 6| Step: 10
Training loss: 2.162349091484727
Validation loss: 2.385494933935792

Epoch: 6| Step: 11
Training loss: 2.2683106388448815
Validation loss: 2.4503783998805466

Epoch: 6| Step: 12
Training loss: 1.798194864909329
Validation loss: 2.516263521146301

Epoch: 6| Step: 13
Training loss: 2.739853607499376
Validation loss: 2.5263457720456075

Epoch: 440| Step: 0
Training loss: 2.247501681691051
Validation loss: 2.536164418436364

Epoch: 6| Step: 1
Training loss: 2.0471549971004444
Validation loss: 2.511700337012247

Epoch: 6| Step: 2
Training loss: 2.0281341129327477
Validation loss: 2.5128610374724842

Epoch: 6| Step: 3
Training loss: 2.2518838837062183
Validation loss: 2.4964676369203

Epoch: 6| Step: 4
Training loss: 2.2341057675219527
Validation loss: 2.480358934414106

Epoch: 6| Step: 5
Training loss: 2.0841058697451413
Validation loss: 2.4461877079557013

Epoch: 6| Step: 6
Training loss: 1.2510144885327263
Validation loss: 2.3840048015413577

Epoch: 6| Step: 7
Training loss: 2.7370781316507915
Validation loss: 2.3885068813558874

Epoch: 6| Step: 8
Training loss: 1.681312591068326
Validation loss: 2.382115902372176

Epoch: 6| Step: 9
Training loss: 2.3141680706909593
Validation loss: 2.386624842541543

Epoch: 6| Step: 10
Training loss: 1.532325756005857
Validation loss: 2.3952240849186675

Epoch: 6| Step: 11
Training loss: 2.061402924962262
Validation loss: 2.4143953933783213

Epoch: 6| Step: 12
Training loss: 1.9045878183193417
Validation loss: 2.424375076591086

Epoch: 6| Step: 13
Training loss: 2.2527358058913656
Validation loss: 2.468610230769364

Epoch: 441| Step: 0
Training loss: 2.2575297987144576
Validation loss: 2.5213355799097465

Epoch: 6| Step: 1
Training loss: 2.289638511911492
Validation loss: 2.5920006206827386

Epoch: 6| Step: 2
Training loss: 1.5905933159631027
Validation loss: 2.5540031687375837

Epoch: 6| Step: 3
Training loss: 1.4790017300196519
Validation loss: 2.506046403568249

Epoch: 6| Step: 4
Training loss: 2.040631855928316
Validation loss: 2.4665908894405204

Epoch: 6| Step: 5
Training loss: 2.081905511491061
Validation loss: 2.413969250574598

Epoch: 6| Step: 6
Training loss: 2.190188036993659
Validation loss: 2.3557510083057

Epoch: 6| Step: 7
Training loss: 2.2743742281290555
Validation loss: 2.34660004840514

Epoch: 6| Step: 8
Training loss: 2.2905612244516464
Validation loss: 2.339875011860798

Epoch: 6| Step: 9
Training loss: 2.557974098241452
Validation loss: 2.353630418292228

Epoch: 6| Step: 10
Training loss: 2.411774473840972
Validation loss: 2.379646599212021

Epoch: 6| Step: 11
Training loss: 1.75737339893238
Validation loss: 2.4092803962893004

Epoch: 6| Step: 12
Training loss: 1.6715712939915564
Validation loss: 2.4825604256835803

Epoch: 6| Step: 13
Training loss: 1.70489605852484
Validation loss: 2.5296364597492786

Epoch: 442| Step: 0
Training loss: 1.9028629792838676
Validation loss: 2.4933742357180204

Epoch: 6| Step: 1
Training loss: 2.0315393095126097
Validation loss: 2.4687395449970344

Epoch: 6| Step: 2
Training loss: 1.841541713543559
Validation loss: 2.4418541654805495

Epoch: 6| Step: 3
Training loss: 2.164572425009515
Validation loss: 2.424533875142904

Epoch: 6| Step: 4
Training loss: 1.8562144497636452
Validation loss: 2.4194644062977577

Epoch: 6| Step: 5
Training loss: 1.9173502186910198
Validation loss: 2.4135278984029513

Epoch: 6| Step: 6
Training loss: 2.233984853121124
Validation loss: 2.353537868019696

Epoch: 6| Step: 7
Training loss: 2.5429549678305956
Validation loss: 2.3646939416078143

Epoch: 6| Step: 8
Training loss: 2.3767745766701696
Validation loss: 2.38422398122345

Epoch: 6| Step: 9
Training loss: 1.7139521824989232
Validation loss: 2.3926153495928157

Epoch: 6| Step: 10
Training loss: 2.0627484027512852
Validation loss: 2.4203351860736455

Epoch: 6| Step: 11
Training loss: 1.7361706210639427
Validation loss: 2.4240102865169124

Epoch: 6| Step: 12
Training loss: 2.01762314752676
Validation loss: 2.446732299517629

Epoch: 6| Step: 13
Training loss: 2.174372931224763
Validation loss: 2.4627333284868724

Epoch: 443| Step: 0
Training loss: 2.1182626619513196
Validation loss: 2.493215179231036

Epoch: 6| Step: 1
Training loss: 2.706871391299266
Validation loss: 2.4907699278672104

Epoch: 6| Step: 2
Training loss: 1.9949002813212924
Validation loss: 2.519282157065347

Epoch: 6| Step: 3
Training loss: 1.7495376112286463
Validation loss: 2.490896293662231

Epoch: 6| Step: 4
Training loss: 2.407458212579941
Validation loss: 2.475000972670961

Epoch: 6| Step: 5
Training loss: 2.041651109389634
Validation loss: 2.4315386820015292

Epoch: 6| Step: 6
Training loss: 2.0264234273069093
Validation loss: 2.411727884538401

Epoch: 6| Step: 7
Training loss: 2.120247181931341
Validation loss: 2.369587904481773

Epoch: 6| Step: 8
Training loss: 2.0597613098226657
Validation loss: 2.360431908977494

Epoch: 6| Step: 9
Training loss: 1.5767059744813583
Validation loss: 2.3774568547393464

Epoch: 6| Step: 10
Training loss: 1.625465179765061
Validation loss: 2.4004356540055056

Epoch: 6| Step: 11
Training loss: 2.031284625418523
Validation loss: 2.436311032684523

Epoch: 6| Step: 12
Training loss: 1.5693294047876631
Validation loss: 2.4505801273081578

Epoch: 6| Step: 13
Training loss: 2.368102044935364
Validation loss: 2.4970113456228122

Epoch: 444| Step: 0
Training loss: 2.3994206206030646
Validation loss: 2.5228284362836013

Epoch: 6| Step: 1
Training loss: 1.4299097774293785
Validation loss: 2.505352946717961

Epoch: 6| Step: 2
Training loss: 1.8340644534567463
Validation loss: 2.478145479701807

Epoch: 6| Step: 3
Training loss: 2.249230783158047
Validation loss: 2.4182089960704922

Epoch: 6| Step: 4
Training loss: 1.6620575194108658
Validation loss: 2.420614511948134

Epoch: 6| Step: 5
Training loss: 1.8990611868949996
Validation loss: 2.4063146502862187

Epoch: 6| Step: 6
Training loss: 2.122246922298756
Validation loss: 2.3862773426063324

Epoch: 6| Step: 7
Training loss: 2.1639312814530016
Validation loss: 2.3898468917464895

Epoch: 6| Step: 8
Training loss: 2.311491256509195
Validation loss: 2.3719634325747263

Epoch: 6| Step: 9
Training loss: 2.5278013307454574
Validation loss: 2.397033914556884

Epoch: 6| Step: 10
Training loss: 1.4193518752545382
Validation loss: 2.3989160890011214

Epoch: 6| Step: 11
Training loss: 2.254566750362925
Validation loss: 2.401045815111881

Epoch: 6| Step: 12
Training loss: 2.0053111128455248
Validation loss: 2.4237730603649275

Epoch: 6| Step: 13
Training loss: 1.6240334937724201
Validation loss: 2.475794136153282

Epoch: 445| Step: 0
Training loss: 2.5197432081386664
Validation loss: 2.4919139799273475

Epoch: 6| Step: 1
Training loss: 2.442888612472787
Validation loss: 2.4715984636123736

Epoch: 6| Step: 2
Training loss: 2.131197475110526
Validation loss: 2.4388305612643557

Epoch: 6| Step: 3
Training loss: 2.5393900029168543
Validation loss: 2.4514011951851757

Epoch: 6| Step: 4
Training loss: 1.7971814764960297
Validation loss: 2.4088849706878

Epoch: 6| Step: 5
Training loss: 2.305661890981347
Validation loss: 2.448758591649601

Epoch: 6| Step: 6
Training loss: 1.8277381422440604
Validation loss: 2.446906968922912

Epoch: 6| Step: 7
Training loss: 1.4926642010969273
Validation loss: 2.4502489002878525

Epoch: 6| Step: 8
Training loss: 1.9701199079706357
Validation loss: 2.438566205556296

Epoch: 6| Step: 9
Training loss: 1.8992320466292052
Validation loss: 2.450991469116322

Epoch: 6| Step: 10
Training loss: 1.0241016824424445
Validation loss: 2.461949297917254

Epoch: 6| Step: 11
Training loss: 2.0819339121096254
Validation loss: 2.472869113762405

Epoch: 6| Step: 12
Training loss: 2.021069647221713
Validation loss: 2.4672400656031

Epoch: 6| Step: 13
Training loss: 1.5210022070503149
Validation loss: 2.5032722039342317

Epoch: 446| Step: 0
Training loss: 1.679753288932359
Validation loss: 2.5030228162400783

Epoch: 6| Step: 1
Training loss: 2.22205514942061
Validation loss: 2.4983798714797443

Epoch: 6| Step: 2
Training loss: 2.360456610327909
Validation loss: 2.458792067146733

Epoch: 6| Step: 3
Training loss: 2.014779675083516
Validation loss: 2.403104051221584

Epoch: 6| Step: 4
Training loss: 1.8134645329139583
Validation loss: 2.3731009517645574

Epoch: 6| Step: 5
Training loss: 2.2159917100207336
Validation loss: 2.3666312891833265

Epoch: 6| Step: 6
Training loss: 2.3587202970072902
Validation loss: 2.3596486937475345

Epoch: 6| Step: 7
Training loss: 2.205701363188262
Validation loss: 2.375775778836246

Epoch: 6| Step: 8
Training loss: 1.8726783366008877
Validation loss: 2.3683317869344056

Epoch: 6| Step: 9
Training loss: 1.6320875100627814
Validation loss: 2.426498787028998

Epoch: 6| Step: 10
Training loss: 1.9749222534908493
Validation loss: 2.434652669566876

Epoch: 6| Step: 11
Training loss: 1.6442254658835302
Validation loss: 2.462491081991622

Epoch: 6| Step: 12
Training loss: 1.8400075398166256
Validation loss: 2.480722934888628

Epoch: 6| Step: 13
Training loss: 2.3758172084868168
Validation loss: 2.500481995910138

Epoch: 447| Step: 0
Training loss: 2.179472772556404
Validation loss: 2.4720172251714403

Epoch: 6| Step: 1
Training loss: 1.7842979454599524
Validation loss: 2.4640031909644957

Epoch: 6| Step: 2
Training loss: 2.0709275969370275
Validation loss: 2.426283324833571

Epoch: 6| Step: 3
Training loss: 2.006773208417427
Validation loss: 2.4181177417184583

Epoch: 6| Step: 4
Training loss: 1.8186171335669907
Validation loss: 2.3615376981268823

Epoch: 6| Step: 5
Training loss: 2.4803826264576223
Validation loss: 2.3639206988934136

Epoch: 6| Step: 6
Training loss: 1.8728444106351023
Validation loss: 2.3968374233945196

Epoch: 6| Step: 7
Training loss: 1.8758884867973047
Validation loss: 2.434221035324877

Epoch: 6| Step: 8
Training loss: 2.0581547596596015
Validation loss: 2.468774061499823

Epoch: 6| Step: 9
Training loss: 1.8636164653587
Validation loss: 2.5007886791078215

Epoch: 6| Step: 10
Training loss: 1.9280598065253194
Validation loss: 2.5913348398559153

Epoch: 6| Step: 11
Training loss: 2.5293852919512205
Validation loss: 2.5840462542114633

Epoch: 6| Step: 12
Training loss: 2.0139103183117752
Validation loss: 2.474824191234329

Epoch: 6| Step: 13
Training loss: 1.9798115198418538
Validation loss: 2.4085954492060253

Epoch: 448| Step: 0
Training loss: 2.3260552339432916
Validation loss: 2.3970207777864685

Epoch: 6| Step: 1
Training loss: 1.8909846192394573
Validation loss: 2.365539946712054

Epoch: 6| Step: 2
Training loss: 1.7354386650727511
Validation loss: 2.377064486030537

Epoch: 6| Step: 3
Training loss: 1.858798474601348
Validation loss: 2.3909971164860226

Epoch: 6| Step: 4
Training loss: 2.194925728933872
Validation loss: 2.3669609124640014

Epoch: 6| Step: 5
Training loss: 1.8753549875545439
Validation loss: 2.409234833487011

Epoch: 6| Step: 6
Training loss: 2.318659749292574
Validation loss: 2.4359481395057143

Epoch: 6| Step: 7
Training loss: 2.3446779575735865
Validation loss: 2.4731869767168084

Epoch: 6| Step: 8
Training loss: 1.317335440403943
Validation loss: 2.488734786803269

Epoch: 6| Step: 9
Training loss: 2.5285631212770765
Validation loss: 2.5050972227481694

Epoch: 6| Step: 10
Training loss: 1.6453752322794881
Validation loss: 2.4591478639445534

Epoch: 6| Step: 11
Training loss: 1.9650489897117485
Validation loss: 2.4724532825903056

Epoch: 6| Step: 12
Training loss: 2.001615348791221
Validation loss: 2.4498029058258894

Epoch: 6| Step: 13
Training loss: 1.755228610350833
Validation loss: 2.45954638968807

Epoch: 449| Step: 0
Training loss: 1.8803707767665598
Validation loss: 2.4778484756749473

Epoch: 6| Step: 1
Training loss: 1.3295014373381306
Validation loss: 2.4850398772333055

Epoch: 6| Step: 2
Training loss: 2.2257094505889943
Validation loss: 2.456427823396045

Epoch: 6| Step: 3
Training loss: 1.9381661039174407
Validation loss: 2.454943029552459

Epoch: 6| Step: 4
Training loss: 2.114027529678891
Validation loss: 2.4965108251835884

Epoch: 6| Step: 5
Training loss: 2.032194416867938
Validation loss: 2.5157889443489885

Epoch: 6| Step: 6
Training loss: 2.272422747584127
Validation loss: 2.4454849220641806

Epoch: 6| Step: 7
Training loss: 1.3159808368563055
Validation loss: 2.4486812894107985

Epoch: 6| Step: 8
Training loss: 2.077920889331583
Validation loss: 2.422794978411389

Epoch: 6| Step: 9
Training loss: 2.4063185644908858
Validation loss: 2.398262225151186

Epoch: 6| Step: 10
Training loss: 1.4040854856000766
Validation loss: 2.402047416417707

Epoch: 6| Step: 11
Training loss: 2.256981719923718
Validation loss: 2.4051255079844185

Epoch: 6| Step: 12
Training loss: 2.212809063720621
Validation loss: 2.4431458541039723

Epoch: 6| Step: 13
Training loss: 2.0548609671235094
Validation loss: 2.425715959163793

Epoch: 450| Step: 0
Training loss: 2.148170704315169
Validation loss: 2.4692385236770122

Epoch: 6| Step: 1
Training loss: 1.9360370034669625
Validation loss: 2.4706314449409335

Epoch: 6| Step: 2
Training loss: 1.8424508641806885
Validation loss: 2.503214046794283

Epoch: 6| Step: 3
Training loss: 2.0185700421978896
Validation loss: 2.464005934595923

Epoch: 6| Step: 4
Training loss: 2.1903809241395598
Validation loss: 2.4168486698117744

Epoch: 6| Step: 5
Training loss: 1.2696562720140583
Validation loss: 2.4047438871886992

Epoch: 6| Step: 6
Training loss: 1.800820836358205
Validation loss: 2.3702741439863004

Epoch: 6| Step: 7
Training loss: 1.9122328752450866
Validation loss: 2.3474695433349417

Epoch: 6| Step: 8
Training loss: 2.229281508675357
Validation loss: 2.379542923227649

Epoch: 6| Step: 9
Training loss: 2.2685797004782255
Validation loss: 2.4178814499249692

Epoch: 6| Step: 10
Training loss: 2.4241535911937406
Validation loss: 2.4536450353902333

Epoch: 6| Step: 11
Training loss: 1.7581638917442124
Validation loss: 2.4931534517807097

Epoch: 6| Step: 12
Training loss: 2.206309512797279
Validation loss: 2.4981654065283565

Epoch: 6| Step: 13
Training loss: 1.263974043081648
Validation loss: 2.5206472934491404

Epoch: 451| Step: 0
Training loss: 1.8626543505927513
Validation loss: 2.54037334015751

Epoch: 6| Step: 1
Training loss: 1.4664441127695473
Validation loss: 2.5309181912483907

Epoch: 6| Step: 2
Training loss: 2.022331495208852
Validation loss: 2.517834144272225

Epoch: 6| Step: 3
Training loss: 2.095664444394898
Validation loss: 2.47367082480655

Epoch: 6| Step: 4
Training loss: 1.8187076550565122
Validation loss: 2.4265399211680414

Epoch: 6| Step: 5
Training loss: 2.412513705199848
Validation loss: 2.3878264287947246

Epoch: 6| Step: 6
Training loss: 2.503400397420414
Validation loss: 2.3849117419761434

Epoch: 6| Step: 7
Training loss: 2.2397873423312284
Validation loss: 2.3525202372784006

Epoch: 6| Step: 8
Training loss: 2.162095039685426
Validation loss: 2.3657160627073703

Epoch: 6| Step: 9
Training loss: 2.362045696517433
Validation loss: 2.4024943104059897

Epoch: 6| Step: 10
Training loss: 1.4885960844151145
Validation loss: 2.4588951958625773

Epoch: 6| Step: 11
Training loss: 1.5581309460810724
Validation loss: 2.513785028005186

Epoch: 6| Step: 12
Training loss: 1.8604167936808453
Validation loss: 2.564517118919823

Epoch: 6| Step: 13
Training loss: 1.523285687047178
Validation loss: 2.533883312474096

Epoch: 452| Step: 0
Training loss: 1.68665278324751
Validation loss: 2.479536674341556

Epoch: 6| Step: 1
Training loss: 1.868293083748759
Validation loss: 2.4958690605281877

Epoch: 6| Step: 2
Training loss: 1.5238645297436995
Validation loss: 2.452715913088425

Epoch: 6| Step: 3
Training loss: 1.6561267015159193
Validation loss: 2.385774702611557

Epoch: 6| Step: 4
Training loss: 2.220631191460835
Validation loss: 2.362226543236121

Epoch: 6| Step: 5
Training loss: 2.1888027126864302
Validation loss: 2.3325768352655114

Epoch: 6| Step: 6
Training loss: 2.2935936773183085
Validation loss: 2.348829772616511

Epoch: 6| Step: 7
Training loss: 1.7733177110992522
Validation loss: 2.3616911888749823

Epoch: 6| Step: 8
Training loss: 1.7730878577713916
Validation loss: 2.3515423947029004

Epoch: 6| Step: 9
Training loss: 2.0012810895650524
Validation loss: 2.3588722810968585

Epoch: 6| Step: 10
Training loss: 1.6740203355353873
Validation loss: 2.37966068997593

Epoch: 6| Step: 11
Training loss: 2.874407831656884
Validation loss: 2.4047207047132386

Epoch: 6| Step: 12
Training loss: 1.675162674705013
Validation loss: 2.4749897734247512

Epoch: 6| Step: 13
Training loss: 2.4030555228916066
Validation loss: 2.5794097284760804

Epoch: 453| Step: 0
Training loss: 1.321274987799205
Validation loss: 2.5541106354836898

Epoch: 6| Step: 1
Training loss: 1.7909479326041822
Validation loss: 2.5846893437997904

Epoch: 6| Step: 2
Training loss: 2.213551623752115
Validation loss: 2.552906278550007

Epoch: 6| Step: 3
Training loss: 2.220131672227755
Validation loss: 2.508729648593481

Epoch: 6| Step: 4
Training loss: 2.0948469789835356
Validation loss: 2.425154397462152

Epoch: 6| Step: 5
Training loss: 1.9621565475732174
Validation loss: 2.380576715490867

Epoch: 6| Step: 6
Training loss: 2.0385124078391237
Validation loss: 2.388223805016908

Epoch: 6| Step: 7
Training loss: 2.0504001226948296
Validation loss: 2.3417184525399115

Epoch: 6| Step: 8
Training loss: 2.420845846733629
Validation loss: 2.3678906860815587

Epoch: 6| Step: 9
Training loss: 1.664084206023156
Validation loss: 2.375745271027363

Epoch: 6| Step: 10
Training loss: 2.1107062765868085
Validation loss: 2.3761488397834887

Epoch: 6| Step: 11
Training loss: 1.8012772743759773
Validation loss: 2.397581308322689

Epoch: 6| Step: 12
Training loss: 1.4774290902409033
Validation loss: 2.4427825369320515

Epoch: 6| Step: 13
Training loss: 2.109138532029141
Validation loss: 2.4637204276012272

Epoch: 454| Step: 0
Training loss: 1.870753693390019
Validation loss: 2.5184259710730323

Epoch: 6| Step: 1
Training loss: 1.7361077253520587
Validation loss: 2.5286799765083927

Epoch: 6| Step: 2
Training loss: 2.360594377508451
Validation loss: 2.486172963036747

Epoch: 6| Step: 3
Training loss: 1.6155000442792957
Validation loss: 2.456668142400458

Epoch: 6| Step: 4
Training loss: 2.241495271485868
Validation loss: 2.4320321704952135

Epoch: 6| Step: 5
Training loss: 1.8496180758729812
Validation loss: 2.415215673694328

Epoch: 6| Step: 6
Training loss: 1.7535521015903528
Validation loss: 2.4191246471141414

Epoch: 6| Step: 7
Training loss: 2.1931628362523288
Validation loss: 2.4652341025831683

Epoch: 6| Step: 8
Training loss: 1.760894311817017
Validation loss: 2.4460928293464463

Epoch: 6| Step: 9
Training loss: 2.0284819302110204
Validation loss: 2.411848068414961

Epoch: 6| Step: 10
Training loss: 2.4392590166843853
Validation loss: 2.395008510871025

Epoch: 6| Step: 11
Training loss: 1.8774556927081596
Validation loss: 2.3579737101184897

Epoch: 6| Step: 12
Training loss: 1.9045699173243305
Validation loss: 2.3371097450595895

Epoch: 6| Step: 13
Training loss: 1.6774231307813112
Validation loss: 2.38277012037397

Epoch: 455| Step: 0
Training loss: 1.4238817076680355
Validation loss: 2.375641042769878

Epoch: 6| Step: 1
Training loss: 1.763087922645872
Validation loss: 2.396365446803338

Epoch: 6| Step: 2
Training loss: 2.556304326680982
Validation loss: 2.408081101629661

Epoch: 6| Step: 3
Training loss: 1.720298347103099
Validation loss: 2.439721928235319

Epoch: 6| Step: 4
Training loss: 2.0111583336519225
Validation loss: 2.4654324022379224

Epoch: 6| Step: 5
Training loss: 1.6667274305075204
Validation loss: 2.4693546979843894

Epoch: 6| Step: 6
Training loss: 1.9186377203580125
Validation loss: 2.475726446795278

Epoch: 6| Step: 7
Training loss: 2.0968700334970523
Validation loss: 2.448326787234603

Epoch: 6| Step: 8
Training loss: 2.2898014685515555
Validation loss: 2.448022740007052

Epoch: 6| Step: 9
Training loss: 1.08369686678442
Validation loss: 2.413283619108861

Epoch: 6| Step: 10
Training loss: 2.451722345435234
Validation loss: 2.3971129165469254

Epoch: 6| Step: 11
Training loss: 2.143140220109678
Validation loss: 2.3921101671474667

Epoch: 6| Step: 12
Training loss: 2.012871213997409
Validation loss: 2.3865494797378566

Epoch: 6| Step: 13
Training loss: 1.3932067393936969
Validation loss: 2.4240106424003076

Epoch: 456| Step: 0
Training loss: 2.1421258495983793
Validation loss: 2.4815742665244764

Epoch: 6| Step: 1
Training loss: 1.9945493572532336
Validation loss: 2.4636225727525978

Epoch: 6| Step: 2
Training loss: 1.8534944008515475
Validation loss: 2.4752213519665176

Epoch: 6| Step: 3
Training loss: 1.8488578518352148
Validation loss: 2.4830247828429877

Epoch: 6| Step: 4
Training loss: 2.167276247788573
Validation loss: 2.4810484475155294

Epoch: 6| Step: 5
Training loss: 1.563328408936402
Validation loss: 2.4615942715873453

Epoch: 6| Step: 6
Training loss: 1.9789234882000006
Validation loss: 2.4378904929634255

Epoch: 6| Step: 7
Training loss: 2.2031299780390348
Validation loss: 2.4054626060311217

Epoch: 6| Step: 8
Training loss: 1.8673158226449655
Validation loss: 2.3947216570427834

Epoch: 6| Step: 9
Training loss: 2.0220103293738947
Validation loss: 2.371643962678651

Epoch: 6| Step: 10
Training loss: 2.3267569394711596
Validation loss: 2.36196221227515

Epoch: 6| Step: 11
Training loss: 1.7679801020171408
Validation loss: 2.394901072497725

Epoch: 6| Step: 12
Training loss: 1.8637647341395889
Validation loss: 2.3939939542251603

Epoch: 6| Step: 13
Training loss: 1.3646108270258392
Validation loss: 2.4289811917965776

Epoch: 457| Step: 0
Training loss: 1.5234140247590342
Validation loss: 2.4894616805285383

Epoch: 6| Step: 1
Training loss: 1.801656315950532
Validation loss: 2.5254670135944233

Epoch: 6| Step: 2
Training loss: 1.5149512612336986
Validation loss: 2.5200379795875456

Epoch: 6| Step: 3
Training loss: 1.9048291523733685
Validation loss: 2.5368051009944033

Epoch: 6| Step: 4
Training loss: 1.8366602996651196
Validation loss: 2.5058817573730483

Epoch: 6| Step: 5
Training loss: 2.064982798322287
Validation loss: 2.441142944050539

Epoch: 6| Step: 6
Training loss: 1.6458119097252892
Validation loss: 2.4081359778869627

Epoch: 6| Step: 7
Training loss: 2.327857290147628
Validation loss: 2.346719799899171

Epoch: 6| Step: 8
Training loss: 2.37027239831586
Validation loss: 2.3565593941223772

Epoch: 6| Step: 9
Training loss: 2.2018049898476186
Validation loss: 2.343197123628749

Epoch: 6| Step: 10
Training loss: 1.7315854845791685
Validation loss: 2.370968477089842

Epoch: 6| Step: 11
Training loss: 1.9683370005643157
Validation loss: 2.3981093882060427

Epoch: 6| Step: 12
Training loss: 1.9712918539206061
Validation loss: 2.4392508110539906

Epoch: 6| Step: 13
Training loss: 2.456793890375747
Validation loss: 2.446562926075897

Epoch: 458| Step: 0
Training loss: 1.6255882372250343
Validation loss: 2.4701660215770205

Epoch: 6| Step: 1
Training loss: 1.9225279776493138
Validation loss: 2.5309632975913154

Epoch: 6| Step: 2
Training loss: 1.4985163026520483
Validation loss: 2.520459187938796

Epoch: 6| Step: 3
Training loss: 2.4152299841764227
Validation loss: 2.512500739512005

Epoch: 6| Step: 4
Training loss: 1.853486682919126
Validation loss: 2.435670583163915

Epoch: 6| Step: 5
Training loss: 1.8112075406844266
Validation loss: 2.410256445995805

Epoch: 6| Step: 6
Training loss: 2.2415674927433984
Validation loss: 2.389340676541794

Epoch: 6| Step: 7
Training loss: 2.0524379469009304
Validation loss: 2.3782561238721787

Epoch: 6| Step: 8
Training loss: 1.9843701340022462
Validation loss: 2.3796126332278167

Epoch: 6| Step: 9
Training loss: 2.0962688041667055
Validation loss: 2.3941520437897212

Epoch: 6| Step: 10
Training loss: 1.943409306637122
Validation loss: 2.401898707583692

Epoch: 6| Step: 11
Training loss: 1.2126829304295699
Validation loss: 2.4509377281148055

Epoch: 6| Step: 12
Training loss: 2.2845996667933326
Validation loss: 2.4649602000765793

Epoch: 6| Step: 13
Training loss: 1.9536429366969377
Validation loss: 2.503629629653893

Epoch: 459| Step: 0
Training loss: 2.0522210580014377
Validation loss: 2.559482262189386

Epoch: 6| Step: 1
Training loss: 2.2166928708050158
Validation loss: 2.6310607324924367

Epoch: 6| Step: 2
Training loss: 2.049829345671125
Validation loss: 2.6076104673286458

Epoch: 6| Step: 3
Training loss: 1.4857421201021659
Validation loss: 2.5433667322333755

Epoch: 6| Step: 4
Training loss: 1.603298381628013
Validation loss: 2.4518827866354522

Epoch: 6| Step: 5
Training loss: 1.824091316689577
Validation loss: 2.408284005643058

Epoch: 6| Step: 6
Training loss: 1.8500799368007022
Validation loss: 2.4042740219614993

Epoch: 6| Step: 7
Training loss: 2.0688153305571384
Validation loss: 2.3755539537899164

Epoch: 6| Step: 8
Training loss: 1.4867428014416446
Validation loss: 2.3660523690053976

Epoch: 6| Step: 9
Training loss: 2.507249905711667
Validation loss: 2.3926394652823726

Epoch: 6| Step: 10
Training loss: 1.592391463552983
Validation loss: 2.4047897930651287

Epoch: 6| Step: 11
Training loss: 2.0415221831391563
Validation loss: 2.435259896388203

Epoch: 6| Step: 12
Training loss: 2.3661361726606613
Validation loss: 2.457308949119614

Epoch: 6| Step: 13
Training loss: 1.9878131787653224
Validation loss: 2.4506366378891515

Epoch: 460| Step: 0
Training loss: 1.6057532585119296
Validation loss: 2.454907270113403

Epoch: 6| Step: 1
Training loss: 1.7942747458390838
Validation loss: 2.4281133706805793

Epoch: 6| Step: 2
Training loss: 2.161916612200931
Validation loss: 2.40623610489446

Epoch: 6| Step: 3
Training loss: 1.9838554122599081
Validation loss: 2.3993348296252486

Epoch: 6| Step: 4
Training loss: 2.0762157417608242
Validation loss: 2.393789246711126

Epoch: 6| Step: 5
Training loss: 1.8612576738536242
Validation loss: 2.398183912038692

Epoch: 6| Step: 6
Training loss: 2.018467045373007
Validation loss: 2.4102219357440244

Epoch: 6| Step: 7
Training loss: 2.299521653562992
Validation loss: 2.4083553511906834

Epoch: 6| Step: 8
Training loss: 1.7435896495528505
Validation loss: 2.4186286432011546

Epoch: 6| Step: 9
Training loss: 1.7318849989658507
Validation loss: 2.483974154864281

Epoch: 6| Step: 10
Training loss: 1.8859533807043225
Validation loss: 2.4979456918636913

Epoch: 6| Step: 11
Training loss: 2.09004749481408
Validation loss: 2.485747035031885

Epoch: 6| Step: 12
Training loss: 1.8246302007925237
Validation loss: 2.4113526743848053

Epoch: 6| Step: 13
Training loss: 1.57772089250456
Validation loss: 2.3878429980596345

Epoch: 461| Step: 0
Training loss: 2.0321119387049036
Validation loss: 2.3495898214539985

Epoch: 6| Step: 1
Training loss: 1.905361155920569
Validation loss: 2.331580730730097

Epoch: 6| Step: 2
Training loss: 1.4633692937413687
Validation loss: 2.33359914868209

Epoch: 6| Step: 3
Training loss: 1.6416315533260228
Validation loss: 2.3116447022197315

Epoch: 6| Step: 4
Training loss: 1.8795503079520592
Validation loss: 2.336606561923648

Epoch: 6| Step: 5
Training loss: 1.9127278559964396
Validation loss: 2.33756879332724

Epoch: 6| Step: 6
Training loss: 1.8259437785774333
Validation loss: 2.3396637421202757

Epoch: 6| Step: 7
Training loss: 1.4644224654616007
Validation loss: 2.3644694554359322

Epoch: 6| Step: 8
Training loss: 2.395172979045217
Validation loss: 2.433041359121514

Epoch: 6| Step: 9
Training loss: 1.866988231288798
Validation loss: 2.5584158936954444

Epoch: 6| Step: 10
Training loss: 1.9333378786274764
Validation loss: 2.617834541563038

Epoch: 6| Step: 11
Training loss: 2.2124083246753465
Validation loss: 2.5956299234590596

Epoch: 6| Step: 12
Training loss: 2.5019278722318
Validation loss: 2.5373545748610007

Epoch: 6| Step: 13
Training loss: 1.7480157774817695
Validation loss: 2.4927323263676384

Epoch: 462| Step: 0
Training loss: 2.4031864828075
Validation loss: 2.4219942537891277

Epoch: 6| Step: 1
Training loss: 1.9809517356119135
Validation loss: 2.359501503411587

Epoch: 6| Step: 2
Training loss: 2.032544823747012
Validation loss: 2.3542975206858348

Epoch: 6| Step: 3
Training loss: 2.085330603389628
Validation loss: 2.344374305406406

Epoch: 6| Step: 4
Training loss: 2.0531338811998743
Validation loss: 2.3785536086230015

Epoch: 6| Step: 5
Training loss: 1.9230176428681316
Validation loss: 2.3827881428351025

Epoch: 6| Step: 6
Training loss: 1.8698795336919487
Validation loss: 2.4146359227865033

Epoch: 6| Step: 7
Training loss: 1.9726481522497779
Validation loss: 2.4227428245639606

Epoch: 6| Step: 8
Training loss: 1.8216147287590037
Validation loss: 2.4193090325466304

Epoch: 6| Step: 9
Training loss: 1.7564793935816339
Validation loss: 2.449305940033102

Epoch: 6| Step: 10
Training loss: 1.5592600992257044
Validation loss: 2.4684494311188265

Epoch: 6| Step: 11
Training loss: 1.5492572358353167
Validation loss: 2.4610038179341625

Epoch: 6| Step: 12
Training loss: 1.6234546062019835
Validation loss: 2.4380378629297

Epoch: 6| Step: 13
Training loss: 2.104584063938487
Validation loss: 2.3932668592405664

Epoch: 463| Step: 0
Training loss: 1.6657124966941523
Validation loss: 2.403957004745765

Epoch: 6| Step: 1
Training loss: 1.6240618271685923
Validation loss: 2.410309517230986

Epoch: 6| Step: 2
Training loss: 1.9002833556650511
Validation loss: 2.421536553029322

Epoch: 6| Step: 3
Training loss: 1.8036018177477622
Validation loss: 2.4245057678472786

Epoch: 6| Step: 4
Training loss: 1.7928654925630136
Validation loss: 2.4243313318571813

Epoch: 6| Step: 5
Training loss: 1.658657842863067
Validation loss: 2.4410206033620265

Epoch: 6| Step: 6
Training loss: 1.9259165625398933
Validation loss: 2.4523136324726105

Epoch: 6| Step: 7
Training loss: 1.7708712255874297
Validation loss: 2.4294606170695423

Epoch: 6| Step: 8
Training loss: 2.2667967824428077
Validation loss: 2.4435970534122355

Epoch: 6| Step: 9
Training loss: 1.909413261467254
Validation loss: 2.4422830273111886

Epoch: 6| Step: 10
Training loss: 2.2801911496461345
Validation loss: 2.4158668368462375

Epoch: 6| Step: 11
Training loss: 2.1394878624921483
Validation loss: 2.4508006136129716

Epoch: 6| Step: 12
Training loss: 2.067909083642327
Validation loss: 2.464523251689436

Epoch: 6| Step: 13
Training loss: 1.7644299539189354
Validation loss: 2.4562087607191896

Epoch: 464| Step: 0
Training loss: 2.0352254844794375
Validation loss: 2.474661545261375

Epoch: 6| Step: 1
Training loss: 1.8333251548353475
Validation loss: 2.482487356690734

Epoch: 6| Step: 2
Training loss: 1.9338741831244854
Validation loss: 2.503961122986693

Epoch: 6| Step: 3
Training loss: 2.0284453763501804
Validation loss: 2.420072928682098

Epoch: 6| Step: 4
Training loss: 2.209439582366407
Validation loss: 2.347667881955231

Epoch: 6| Step: 5
Training loss: 1.9661517482104394
Validation loss: 2.316331308652188

Epoch: 6| Step: 6
Training loss: 1.610873367409387
Validation loss: 2.3265040210030534

Epoch: 6| Step: 7
Training loss: 1.499020256511283
Validation loss: 2.342393291303214

Epoch: 6| Step: 8
Training loss: 2.408943155380486
Validation loss: 2.3411074523469813

Epoch: 6| Step: 9
Training loss: 1.8951945923109346
Validation loss: 2.3312739474531283

Epoch: 6| Step: 10
Training loss: 1.925677995060862
Validation loss: 2.3570463394905157

Epoch: 6| Step: 11
Training loss: 2.033757701219117
Validation loss: 2.4074339833706437

Epoch: 6| Step: 12
Training loss: 1.513258984765782
Validation loss: 2.4440102691145977

Epoch: 6| Step: 13
Training loss: 1.4402604343093943
Validation loss: 2.5130899157883

Epoch: 465| Step: 0
Training loss: 2.0561265438782987
Validation loss: 2.596762070461604

Epoch: 6| Step: 1
Training loss: 2.0211786453589595
Validation loss: 2.643726015133659

Epoch: 6| Step: 2
Training loss: 1.9862289779059563
Validation loss: 2.6259242343455362

Epoch: 6| Step: 3
Training loss: 1.9599536388130172
Validation loss: 2.506984252548484

Epoch: 6| Step: 4
Training loss: 1.4338955678434888
Validation loss: 2.4190311710332737

Epoch: 6| Step: 5
Training loss: 2.3560606053172175
Validation loss: 2.33108996038504

Epoch: 6| Step: 6
Training loss: 2.216699969488479
Validation loss: 2.294327153818963

Epoch: 6| Step: 7
Training loss: 2.083109907249532
Validation loss: 2.313397480316816

Epoch: 6| Step: 8
Training loss: 1.5672487956237304
Validation loss: 2.3292009810492407

Epoch: 6| Step: 9
Training loss: 1.9580360011024207
Validation loss: 2.3581168831098713

Epoch: 6| Step: 10
Training loss: 1.8211568421342363
Validation loss: 2.3791209318551156

Epoch: 6| Step: 11
Training loss: 2.0329511121659536
Validation loss: 2.4147375453079216

Epoch: 6| Step: 12
Training loss: 1.3744827945030629
Validation loss: 2.471165254541657

Epoch: 6| Step: 13
Training loss: 1.943119452153553
Validation loss: 2.4411537115271145

Epoch: 466| Step: 0
Training loss: 1.7403163697933848
Validation loss: 2.521747949646787

Epoch: 6| Step: 1
Training loss: 1.779535103854951
Validation loss: 2.601488148247213

Epoch: 6| Step: 2
Training loss: 2.2020393023123415
Validation loss: 2.6248080021754086

Epoch: 6| Step: 3
Training loss: 2.265437993191355
Validation loss: 2.596078194707185

Epoch: 6| Step: 4
Training loss: 1.3845974883324956
Validation loss: 2.5023024103723586

Epoch: 6| Step: 5
Training loss: 1.9722536790455398
Validation loss: 2.4146830022195602

Epoch: 6| Step: 6
Training loss: 1.7423225658388852
Validation loss: 2.3454559144812435

Epoch: 6| Step: 7
Training loss: 1.6512723294292557
Validation loss: 2.3196563063525026

Epoch: 6| Step: 8
Training loss: 1.7981420942176163
Validation loss: 2.2912356563299707

Epoch: 6| Step: 9
Training loss: 1.8251710158394876
Validation loss: 2.3019279799138332

Epoch: 6| Step: 10
Training loss: 2.332727478481163
Validation loss: 2.3244853745660463

Epoch: 6| Step: 11
Training loss: 1.9090215827277366
Validation loss: 2.319806290070649

Epoch: 6| Step: 12
Training loss: 2.2072323867833075
Validation loss: 2.354955785074274

Epoch: 6| Step: 13
Training loss: 2.0548993715768975
Validation loss: 2.4610840414742134

Epoch: 467| Step: 0
Training loss: 1.925135134623037
Validation loss: 2.5618194128476643

Epoch: 6| Step: 1
Training loss: 2.180574188908729
Validation loss: 2.5798023292555206

Epoch: 6| Step: 2
Training loss: 2.1069154316460827
Validation loss: 2.5369142987226674

Epoch: 6| Step: 3
Training loss: 1.816187035243029
Validation loss: 2.4694589697869356

Epoch: 6| Step: 4
Training loss: 1.7784867520400613
Validation loss: 2.4419869437091957

Epoch: 6| Step: 5
Training loss: 1.8413416116769166
Validation loss: 2.397429227827084

Epoch: 6| Step: 6
Training loss: 2.269646489013016
Validation loss: 2.366432006840066

Epoch: 6| Step: 7
Training loss: 2.236718715890237
Validation loss: 2.371097425016126

Epoch: 6| Step: 8
Training loss: 1.969037837225341
Validation loss: 2.3376738176290304

Epoch: 6| Step: 9
Training loss: 1.6831240961445657
Validation loss: 2.341672815557044

Epoch: 6| Step: 10
Training loss: 1.7733487010352071
Validation loss: 2.3592564102703304

Epoch: 6| Step: 11
Training loss: 1.5835763426898088
Validation loss: 2.398383181067325

Epoch: 6| Step: 12
Training loss: 1.585287176885318
Validation loss: 2.4078006805821683

Epoch: 6| Step: 13
Training loss: 1.568574313474529
Validation loss: 2.435448221840691

Epoch: 468| Step: 0
Training loss: 1.658322027861175
Validation loss: 2.4351004723735254

Epoch: 6| Step: 1
Training loss: 2.2293254641244955
Validation loss: 2.4780443227095232

Epoch: 6| Step: 2
Training loss: 2.026794123887224
Validation loss: 2.457851684617601

Epoch: 6| Step: 3
Training loss: 1.7129723280382423
Validation loss: 2.437926352681737

Epoch: 6| Step: 4
Training loss: 1.8236286262561394
Validation loss: 2.4350754559348267

Epoch: 6| Step: 5
Training loss: 1.9553073744838527
Validation loss: 2.4249413890329135

Epoch: 6| Step: 6
Training loss: 2.0164478603652953
Validation loss: 2.4295922883131564

Epoch: 6| Step: 7
Training loss: 2.146094025513611
Validation loss: 2.4398693120928545

Epoch: 6| Step: 8
Training loss: 1.4557278200346895
Validation loss: 2.410189112241803

Epoch: 6| Step: 9
Training loss: 1.785868629869811
Validation loss: 2.3987677054480208

Epoch: 6| Step: 10
Training loss: 1.9615430162989695
Validation loss: 2.395381017168048

Epoch: 6| Step: 11
Training loss: 1.7520515133587387
Validation loss: 2.4182885551054083

Epoch: 6| Step: 12
Training loss: 1.5908363486664885
Validation loss: 2.4339887340979005

Epoch: 6| Step: 13
Training loss: 2.0083365739767225
Validation loss: 2.4271636612297485

Epoch: 469| Step: 0
Training loss: 1.57643361618664
Validation loss: 2.396050665273079

Epoch: 6| Step: 1
Training loss: 1.8248719183512143
Validation loss: 2.371159750216541

Epoch: 6| Step: 2
Training loss: 1.448368614887897
Validation loss: 2.349997787020725

Epoch: 6| Step: 3
Training loss: 1.2777958341142803
Validation loss: 2.3646866291254174

Epoch: 6| Step: 4
Training loss: 2.0228150341879063
Validation loss: 2.359913559770239

Epoch: 6| Step: 5
Training loss: 1.7642503636681288
Validation loss: 2.3729832975485663

Epoch: 6| Step: 6
Training loss: 1.9220170379502735
Validation loss: 2.363276067999448

Epoch: 6| Step: 7
Training loss: 2.23164702657766
Validation loss: 2.396480426547225

Epoch: 6| Step: 8
Training loss: 2.128545832091469
Validation loss: 2.413806445989589

Epoch: 6| Step: 9
Training loss: 1.3264711741720676
Validation loss: 2.461636522549411

Epoch: 6| Step: 10
Training loss: 1.8367198819149266
Validation loss: 2.5226898990799578

Epoch: 6| Step: 11
Training loss: 2.106554986170435
Validation loss: 2.552468838601082

Epoch: 6| Step: 12
Training loss: 2.124273737048055
Validation loss: 2.5502213061349797

Epoch: 6| Step: 13
Training loss: 2.4931308790449824
Validation loss: 2.435959435630009

Epoch: 470| Step: 0
Training loss: 1.6463743197945315
Validation loss: 2.38505124595544

Epoch: 6| Step: 1
Training loss: 1.822125232190666
Validation loss: 2.3696199905070467

Epoch: 6| Step: 2
Training loss: 1.8029071563876586
Validation loss: 2.315915818469069

Epoch: 6| Step: 3
Training loss: 1.9168276373674635
Validation loss: 2.3189204406409107

Epoch: 6| Step: 4
Training loss: 1.9165430305520832
Validation loss: 2.3457229109455566

Epoch: 6| Step: 5
Training loss: 1.770440278656328
Validation loss: 2.3278274318436143

Epoch: 6| Step: 6
Training loss: 2.0871753234553787
Validation loss: 2.347001207588439

Epoch: 6| Step: 7
Training loss: 2.425611013928976
Validation loss: 2.356326226082157

Epoch: 6| Step: 8
Training loss: 1.5421321097555842
Validation loss: 2.4746924569613213

Epoch: 6| Step: 9
Training loss: 2.040410557180051
Validation loss: 2.577101474517425

Epoch: 6| Step: 10
Training loss: 1.8214121759034716
Validation loss: 2.6529167982281106

Epoch: 6| Step: 11
Training loss: 1.6407152423562854
Validation loss: 2.691963303297376

Epoch: 6| Step: 12
Training loss: 1.6333401206258285
Validation loss: 2.6271116881695957

Epoch: 6| Step: 13
Training loss: 2.140750185236666
Validation loss: 2.46515991685631

Epoch: 471| Step: 0
Training loss: 1.815643872476477
Validation loss: 2.3539354488665327

Epoch: 6| Step: 1
Training loss: 1.8684619719872089
Validation loss: 2.2994055537557183

Epoch: 6| Step: 2
Training loss: 1.3018979614547754
Validation loss: 2.308517867627464

Epoch: 6| Step: 3
Training loss: 2.117445363462428
Validation loss: 2.29554363610343

Epoch: 6| Step: 4
Training loss: 2.1240027836639497
Validation loss: 2.306445091709332

Epoch: 6| Step: 5
Training loss: 1.8663454591184925
Validation loss: 2.3247475442806436

Epoch: 6| Step: 6
Training loss: 1.9797274012710704
Validation loss: 2.3381377231516094

Epoch: 6| Step: 7
Training loss: 2.2434652588791857
Validation loss: 2.396271746213864

Epoch: 6| Step: 8
Training loss: 1.5415514653783557
Validation loss: 2.4473924751523106

Epoch: 6| Step: 9
Training loss: 2.2526515595553365
Validation loss: 2.488480045991049

Epoch: 6| Step: 10
Training loss: 1.7412869302594651
Validation loss: 2.525348765100512

Epoch: 6| Step: 11
Training loss: 1.8789870786034792
Validation loss: 2.5674855454810213

Epoch: 6| Step: 12
Training loss: 1.969700175284954
Validation loss: 2.537035339735875

Epoch: 6| Step: 13
Training loss: 1.3980841163520434
Validation loss: 2.410750367278243

Epoch: 472| Step: 0
Training loss: 1.9138761468594507
Validation loss: 2.378286864644971

Epoch: 6| Step: 1
Training loss: 1.808189000758322
Validation loss: 2.360040653487627

Epoch: 6| Step: 2
Training loss: 2.0965905350456646
Validation loss: 2.325867358722627

Epoch: 6| Step: 3
Training loss: 1.9859863107176827
Validation loss: 2.340418461927806

Epoch: 6| Step: 4
Training loss: 1.5223527225111335
Validation loss: 2.351486315474481

Epoch: 6| Step: 5
Training loss: 1.8281308035473118
Validation loss: 2.346897103172625

Epoch: 6| Step: 6
Training loss: 1.7181527920858828
Validation loss: 2.364939648469714

Epoch: 6| Step: 7
Training loss: 1.8229036675852557
Validation loss: 2.416580228529148

Epoch: 6| Step: 8
Training loss: 1.9470212241624043
Validation loss: 2.4511148151063824

Epoch: 6| Step: 9
Training loss: 1.5865290248030002
Validation loss: 2.4671236483211443

Epoch: 6| Step: 10
Training loss: 1.859380385447164
Validation loss: 2.5122934766218314

Epoch: 6| Step: 11
Training loss: 1.88351288111216
Validation loss: 2.5530705742165924

Epoch: 6| Step: 12
Training loss: 2.0002279151752895
Validation loss: 2.553616335333841

Epoch: 6| Step: 13
Training loss: 1.9039909234391577
Validation loss: 2.4904143654562603

Epoch: 473| Step: 0
Training loss: 1.666939339585001
Validation loss: 2.4354424918095248

Epoch: 6| Step: 1
Training loss: 1.7007581030234722
Validation loss: 2.4067214559360393

Epoch: 6| Step: 2
Training loss: 1.7315240057862715
Validation loss: 2.366611348461356

Epoch: 6| Step: 3
Training loss: 1.335978903324058
Validation loss: 2.3449325968823294

Epoch: 6| Step: 4
Training loss: 1.9614280299923317
Validation loss: 2.3485245035387874

Epoch: 6| Step: 5
Training loss: 1.2424556034990786
Validation loss: 2.351092832562309

Epoch: 6| Step: 6
Training loss: 1.8260524771922189
Validation loss: 2.371818147872596

Epoch: 6| Step: 7
Training loss: 1.9248939930845639
Validation loss: 2.3817363943014347

Epoch: 6| Step: 8
Training loss: 1.773313946558212
Validation loss: 2.435396233169447

Epoch: 6| Step: 9
Training loss: 1.915614779322181
Validation loss: 2.4896606674948574

Epoch: 6| Step: 10
Training loss: 2.832210224678758
Validation loss: 2.566836615605125

Epoch: 6| Step: 11
Training loss: 1.9089858012762921
Validation loss: 2.5345249711927007

Epoch: 6| Step: 12
Training loss: 1.7753320061099374
Validation loss: 2.471051260008152

Epoch: 6| Step: 13
Training loss: 1.9490923945691079
Validation loss: 2.4444683019562055

Epoch: 474| Step: 0
Training loss: 2.2554205133177563
Validation loss: 2.3682955748942223

Epoch: 6| Step: 1
Training loss: 1.7473255565930657
Validation loss: 2.3213667648473373

Epoch: 6| Step: 2
Training loss: 1.9879532639058386
Validation loss: 2.325243257430354

Epoch: 6| Step: 3
Training loss: 1.8085349549197283
Validation loss: 2.297280119667005

Epoch: 6| Step: 4
Training loss: 1.7336395353895722
Validation loss: 2.326436856952337

Epoch: 6| Step: 5
Training loss: 2.0263115344390727
Validation loss: 2.354100971210942

Epoch: 6| Step: 6
Training loss: 1.8140097282678747
Validation loss: 2.3896140515210598

Epoch: 6| Step: 7
Training loss: 0.9482994808720558
Validation loss: 2.4298809570513895

Epoch: 6| Step: 8
Training loss: 1.9611182262530524
Validation loss: 2.46337364810311

Epoch: 6| Step: 9
Training loss: 1.767418279849466
Validation loss: 2.519284579987845

Epoch: 6| Step: 10
Training loss: 1.7442919418805791
Validation loss: 2.56578173165218

Epoch: 6| Step: 11
Training loss: 1.8613848682572607
Validation loss: 2.583984359125968

Epoch: 6| Step: 12
Training loss: 1.8718134186920854
Validation loss: 2.589407455267353

Epoch: 6| Step: 13
Training loss: 1.7210303005275247
Validation loss: 2.6274894418484105

Epoch: 475| Step: 0
Training loss: 2.067197478739556
Validation loss: 2.579331934808834

Epoch: 6| Step: 1
Training loss: 1.8315133540119417
Validation loss: 2.5035461542603277

Epoch: 6| Step: 2
Training loss: 1.637814903555935
Validation loss: 2.4165161345476425

Epoch: 6| Step: 3
Training loss: 1.775153048727075
Validation loss: 2.3623523719639117

Epoch: 6| Step: 4
Training loss: 1.7593596706772792
Validation loss: 2.314555118837368

Epoch: 6| Step: 5
Training loss: 2.3778859723907853
Validation loss: 2.308854440893963

Epoch: 6| Step: 6
Training loss: 1.5208335336484733
Validation loss: 2.284437852965594

Epoch: 6| Step: 7
Training loss: 2.0318806769562485
Validation loss: 2.2927477601314785

Epoch: 6| Step: 8
Training loss: 1.6868687614673248
Validation loss: 2.330607435620338

Epoch: 6| Step: 9
Training loss: 1.8647489705029852
Validation loss: 2.367123729434769

Epoch: 6| Step: 10
Training loss: 1.5912824489883926
Validation loss: 2.445510774969171

Epoch: 6| Step: 11
Training loss: 1.4305664862469258
Validation loss: 2.5058588880241253

Epoch: 6| Step: 12
Training loss: 2.3040896917342764
Validation loss: 2.5690626191256576

Epoch: 6| Step: 13
Training loss: 1.5003164275518623
Validation loss: 2.5973935738559817

Epoch: 476| Step: 0
Training loss: 1.7716515240361546
Validation loss: 2.6136247967722634

Epoch: 6| Step: 1
Training loss: 1.5596214481920818
Validation loss: 2.521879137035308

Epoch: 6| Step: 2
Training loss: 2.0184254671840494
Validation loss: 2.441321867241329

Epoch: 6| Step: 3
Training loss: 1.6571824669801987
Validation loss: 2.40813140766344

Epoch: 6| Step: 4
Training loss: 1.414379695491776
Validation loss: 2.339521292286818

Epoch: 6| Step: 5
Training loss: 1.799523897254538
Validation loss: 2.330014793336359

Epoch: 6| Step: 6
Training loss: 2.0341045569043863
Validation loss: 2.3093428007932757

Epoch: 6| Step: 7
Training loss: 2.0582117526122787
Validation loss: 2.3683058747013335

Epoch: 6| Step: 8
Training loss: 1.1967905418138283
Validation loss: 2.372475075307005

Epoch: 6| Step: 9
Training loss: 2.008378835877554
Validation loss: 2.3746658688158964

Epoch: 6| Step: 10
Training loss: 2.1011284021779737
Validation loss: 2.418221858187598

Epoch: 6| Step: 11
Training loss: 1.9196323863406097
Validation loss: 2.4406046588126675

Epoch: 6| Step: 12
Training loss: 2.0560316903310385
Validation loss: 2.4258949676259127

Epoch: 6| Step: 13
Training loss: 1.2813186627109499
Validation loss: 2.4305289675366324

Epoch: 477| Step: 0
Training loss: 1.4336492959053488
Validation loss: 2.424977716162338

Epoch: 6| Step: 1
Training loss: 1.7967938612157932
Validation loss: 2.402174143219359

Epoch: 6| Step: 2
Training loss: 1.9580590752718976
Validation loss: 2.3784080905310736

Epoch: 6| Step: 3
Training loss: 1.005501633516158
Validation loss: 2.388414261936131

Epoch: 6| Step: 4
Training loss: 2.204274628368268
Validation loss: 2.380651840932082

Epoch: 6| Step: 5
Training loss: 2.115038467309917
Validation loss: 2.368224641942506

Epoch: 6| Step: 6
Training loss: 1.966089600691532
Validation loss: 2.3738509033746187

Epoch: 6| Step: 7
Training loss: 1.703341828988843
Validation loss: 2.3554259284622465

Epoch: 6| Step: 8
Training loss: 1.5452835682011066
Validation loss: 2.3467827998239854

Epoch: 6| Step: 9
Training loss: 2.1290330201648233
Validation loss: 2.3416675047233775

Epoch: 6| Step: 10
Training loss: 1.5249630063682287
Validation loss: 2.3640788703296733

Epoch: 6| Step: 11
Training loss: 1.4228019627164785
Validation loss: 2.3939932528094947

Epoch: 6| Step: 12
Training loss: 1.87509778085695
Validation loss: 2.440781805432786

Epoch: 6| Step: 13
Training loss: 2.229080650119858
Validation loss: 2.488605808500466

Epoch: 478| Step: 0
Training loss: 1.690953570747604
Validation loss: 2.6187493047846204

Epoch: 6| Step: 1
Training loss: 2.069612089474068
Validation loss: 2.7415199969032646

Epoch: 6| Step: 2
Training loss: 2.0719236618472365
Validation loss: 2.7219505721429025

Epoch: 6| Step: 3
Training loss: 1.362944728119662
Validation loss: 2.578730314559177

Epoch: 6| Step: 4
Training loss: 1.7514635505597052
Validation loss: 2.4437534384389488

Epoch: 6| Step: 5
Training loss: 1.7284463125006642
Validation loss: 2.372998418008983

Epoch: 6| Step: 6
Training loss: 2.175331932258369
Validation loss: 2.3323857306716733

Epoch: 6| Step: 7
Training loss: 1.9052458447795346
Validation loss: 2.329984820193799

Epoch: 6| Step: 8
Training loss: 1.8013614539053417
Validation loss: 2.324920279840489

Epoch: 6| Step: 9
Training loss: 1.707593812054958
Validation loss: 2.325751076068478

Epoch: 6| Step: 10
Training loss: 1.5716507556442956
Validation loss: 2.332240792313787

Epoch: 6| Step: 11
Training loss: 2.1341173142110605
Validation loss: 2.3743174154380933

Epoch: 6| Step: 12
Training loss: 2.1658513907246966
Validation loss: 2.3977590877891104

Epoch: 6| Step: 13
Training loss: 1.5678812820830603
Validation loss: 2.400688720057031

Epoch: 479| Step: 0
Training loss: 1.842672259328243
Validation loss: 2.47576989332649

Epoch: 6| Step: 1
Training loss: 1.475132648516395
Validation loss: 2.524413412555032

Epoch: 6| Step: 2
Training loss: 2.0283774384859896
Validation loss: 2.5540288230512087

Epoch: 6| Step: 3
Training loss: 1.8518771777363905
Validation loss: 2.5463028101518215

Epoch: 6| Step: 4
Training loss: 1.6191073461409644
Validation loss: 2.470494058876727

Epoch: 6| Step: 5
Training loss: 1.7839133445409558
Validation loss: 2.4160956350610583

Epoch: 6| Step: 6
Training loss: 2.101497833504968
Validation loss: 2.3802908365683337

Epoch: 6| Step: 7
Training loss: 1.7528958203117648
Validation loss: 2.379698185038959

Epoch: 6| Step: 8
Training loss: 1.9365226372406
Validation loss: 2.343845192128041

Epoch: 6| Step: 9
Training loss: 2.276394523544843
Validation loss: 2.3426758380890615

Epoch: 6| Step: 10
Training loss: 1.2779222397526746
Validation loss: 2.348043416160632

Epoch: 6| Step: 11
Training loss: 1.787493154872779
Validation loss: 2.3744820179434827

Epoch: 6| Step: 12
Training loss: 1.4231025511085558
Validation loss: 2.3677280961722205

Epoch: 6| Step: 13
Training loss: 1.9557489698061838
Validation loss: 2.3749706005269418

Epoch: 480| Step: 0
Training loss: 1.8426679895389813
Validation loss: 2.422031244324922

Epoch: 6| Step: 1
Training loss: 1.5346437331545622
Validation loss: 2.473940342231621

Epoch: 6| Step: 2
Training loss: 1.8754353335771639
Validation loss: 2.4716797881089656

Epoch: 6| Step: 3
Training loss: 1.1764879605819807
Validation loss: 2.4397159859985087

Epoch: 6| Step: 4
Training loss: 1.9905525230256618
Validation loss: 2.4209977915578342

Epoch: 6| Step: 5
Training loss: 1.8633329436290973
Validation loss: 2.3951422056079505

Epoch: 6| Step: 6
Training loss: 1.95338230726975
Validation loss: 2.401766678365764

Epoch: 6| Step: 7
Training loss: 2.0684243859294487
Validation loss: 2.3801879652167015

Epoch: 6| Step: 8
Training loss: 1.859993262842754
Validation loss: 2.375844923887402

Epoch: 6| Step: 9
Training loss: 1.3665859970072087
Validation loss: 2.400396907025238

Epoch: 6| Step: 10
Training loss: 1.7488811185815782
Validation loss: 2.4612471034657077

Epoch: 6| Step: 11
Training loss: 1.8697333437466797
Validation loss: 2.47884712441788

Epoch: 6| Step: 12
Training loss: 2.115151640594007
Validation loss: 2.497060748122986

Epoch: 6| Step: 13
Training loss: 1.0261592636233756
Validation loss: 2.5356393916177615

Epoch: 481| Step: 0
Training loss: 1.4811455379945178
Validation loss: 2.571301987406941

Epoch: 6| Step: 1
Training loss: 1.19368188873431
Validation loss: 2.546169966290861

Epoch: 6| Step: 2
Training loss: 2.3319737924114095
Validation loss: 2.484411072064442

Epoch: 6| Step: 3
Training loss: 1.6593304184494277
Validation loss: 2.4189636250177067

Epoch: 6| Step: 4
Training loss: 1.7258648735982103
Validation loss: 2.3566399966218086

Epoch: 6| Step: 5
Training loss: 1.9596482860527031
Validation loss: 2.3517390855220337

Epoch: 6| Step: 6
Training loss: 1.662403623038925
Validation loss: 2.326778877477313

Epoch: 6| Step: 7
Training loss: 1.4895697995440238
Validation loss: 2.324734197527463

Epoch: 6| Step: 8
Training loss: 1.8741278845388862
Validation loss: 2.3252789189044987

Epoch: 6| Step: 9
Training loss: 1.9684686611123619
Validation loss: 2.3647692572344474

Epoch: 6| Step: 10
Training loss: 1.6215159406463644
Validation loss: 2.375818672765827

Epoch: 6| Step: 11
Training loss: 1.8737916867719446
Validation loss: 2.443241285751873

Epoch: 6| Step: 12
Training loss: 2.118665678883909
Validation loss: 2.5085473412440016

Epoch: 6| Step: 13
Training loss: 1.8412647631558996
Validation loss: 2.5178099753133707

Epoch: 482| Step: 0
Training loss: 1.5129078370367806
Validation loss: 2.544903480625053

Epoch: 6| Step: 1
Training loss: 1.262097989653484
Validation loss: 2.5292995812528334

Epoch: 6| Step: 2
Training loss: 1.790372676946668
Validation loss: 2.5172512754572

Epoch: 6| Step: 3
Training loss: 1.9929611199927137
Validation loss: 2.4335749365743484

Epoch: 6| Step: 4
Training loss: 2.0992584644986056
Validation loss: 2.390359061479522

Epoch: 6| Step: 5
Training loss: 2.1654972319460866
Validation loss: 2.3619504889922465

Epoch: 6| Step: 6
Training loss: 2.0655622002408847
Validation loss: 2.359539757223965

Epoch: 6| Step: 7
Training loss: 2.0449264220266423
Validation loss: 2.3940480140145524

Epoch: 6| Step: 8
Training loss: 1.558108452603105
Validation loss: 2.449900187756442

Epoch: 6| Step: 9
Training loss: 1.6481453153004075
Validation loss: 2.493442374414699

Epoch: 6| Step: 10
Training loss: 1.536974502327164
Validation loss: 2.509564529073933

Epoch: 6| Step: 11
Training loss: 1.6184380897274884
Validation loss: 2.5187845130688586

Epoch: 6| Step: 12
Training loss: 1.503727255734048
Validation loss: 2.4670901728026253

Epoch: 6| Step: 13
Training loss: 1.9416997369179325
Validation loss: 2.398680503853504

Epoch: 483| Step: 0
Training loss: 1.9586724197419194
Validation loss: 2.381276873627828

Epoch: 6| Step: 1
Training loss: 1.4781656594359915
Validation loss: 2.335130324411726

Epoch: 6| Step: 2
Training loss: 2.0261342110046456
Validation loss: 2.3349319627556895

Epoch: 6| Step: 3
Training loss: 2.3439040069843986
Validation loss: 2.303991974695305

Epoch: 6| Step: 4
Training loss: 2.526551112029598
Validation loss: 2.3421909498429994

Epoch: 6| Step: 5
Training loss: 1.8401739063178686
Validation loss: 2.3708176847543707

Epoch: 6| Step: 6
Training loss: 1.461279028480998
Validation loss: 2.448094783072476

Epoch: 6| Step: 7
Training loss: 1.4774790346365418
Validation loss: 2.5083630930828673

Epoch: 6| Step: 8
Training loss: 1.4165803191105448
Validation loss: 2.5707431809781696

Epoch: 6| Step: 9
Training loss: 1.3836611713544442
Validation loss: 2.5603758669266323

Epoch: 6| Step: 10
Training loss: 1.358141723333235
Validation loss: 2.5585758587160723

Epoch: 6| Step: 11
Training loss: 1.389468322790904
Validation loss: 2.5182579659795903

Epoch: 6| Step: 12
Training loss: 1.8518707405116017
Validation loss: 2.4808843991607503

Epoch: 6| Step: 13
Training loss: 1.8975008942170983
Validation loss: 2.423197403966979

Epoch: 484| Step: 0
Training loss: 1.7625918371203946
Validation loss: 2.376173544438824

Epoch: 6| Step: 1
Training loss: 2.0527623661938486
Validation loss: 2.3657158037117303

Epoch: 6| Step: 2
Training loss: 1.6544484110744029
Validation loss: 2.3749939217352036

Epoch: 6| Step: 3
Training loss: 1.2697736303327902
Validation loss: 2.363242417805229

Epoch: 6| Step: 4
Training loss: 1.0461934276494695
Validation loss: 2.378479202659868

Epoch: 6| Step: 5
Training loss: 1.797703626556312
Validation loss: 2.380176213762358

Epoch: 6| Step: 6
Training loss: 1.5581732543622167
Validation loss: 2.383151551830965

Epoch: 6| Step: 7
Training loss: 1.8634994027249643
Validation loss: 2.393276990522715

Epoch: 6| Step: 8
Training loss: 2.0627848110643563
Validation loss: 2.384197508382245

Epoch: 6| Step: 9
Training loss: 2.4283922674305733
Validation loss: 2.393439072351387

Epoch: 6| Step: 10
Training loss: 1.7520216436181435
Validation loss: 2.4220862268381436

Epoch: 6| Step: 11
Training loss: 1.5214613397345609
Validation loss: 2.450800735999895

Epoch: 6| Step: 12
Training loss: 1.688837722092475
Validation loss: 2.507376492278481

Epoch: 6| Step: 13
Training loss: 1.7227894565003679
Validation loss: 2.510927324962128

Epoch: 485| Step: 0
Training loss: 1.4384234406295708
Validation loss: 2.4999232188093528

Epoch: 6| Step: 1
Training loss: 1.6565347102910115
Validation loss: 2.485672816915972

Epoch: 6| Step: 2
Training loss: 1.8282623891474568
Validation loss: 2.4704896097184372

Epoch: 6| Step: 3
Training loss: 1.4974447579614956
Validation loss: 2.43072229960951

Epoch: 6| Step: 4
Training loss: 2.1408573219476845
Validation loss: 2.388483337351573

Epoch: 6| Step: 5
Training loss: 2.0899382097519186
Validation loss: 2.332870677780297

Epoch: 6| Step: 6
Training loss: 2.1353379273823223
Validation loss: 2.3286512151417194

Epoch: 6| Step: 7
Training loss: 1.7204248764102121
Validation loss: 2.3594551732899065

Epoch: 6| Step: 8
Training loss: 1.4719979107313257
Validation loss: 2.380408388613959

Epoch: 6| Step: 9
Training loss: 1.228967095461465
Validation loss: 2.371691186974869

Epoch: 6| Step: 10
Training loss: 1.8269921729886374
Validation loss: 2.3794873250624375

Epoch: 6| Step: 11
Training loss: 2.1832970705976376
Validation loss: 2.3992714187891524

Epoch: 6| Step: 12
Training loss: 1.4322370299119744
Validation loss: 2.4567109982805375

Epoch: 6| Step: 13
Training loss: 1.1548088474545217
Validation loss: 2.4533816249664717

Epoch: 486| Step: 0
Training loss: 1.4587602353819715
Validation loss: 2.459361444488993

Epoch: 6| Step: 1
Training loss: 1.910553249300921
Validation loss: 2.4093464868379213

Epoch: 6| Step: 2
Training loss: 1.5621148206878697
Validation loss: 2.369860964499641

Epoch: 6| Step: 3
Training loss: 1.385963556674779
Validation loss: 2.359910563675178

Epoch: 6| Step: 4
Training loss: 1.4010729118559633
Validation loss: 2.3528105185246875

Epoch: 6| Step: 5
Training loss: 1.5997619928720306
Validation loss: 2.3340197892363466

Epoch: 6| Step: 6
Training loss: 2.2649926717273314
Validation loss: 2.350911610274651

Epoch: 6| Step: 7
Training loss: 2.1281607066112422
Validation loss: 2.3696667461246417

Epoch: 6| Step: 8
Training loss: 1.2353443733579104
Validation loss: 2.4078488811722325

Epoch: 6| Step: 9
Training loss: 1.4673200098553898
Validation loss: 2.427456560150586

Epoch: 6| Step: 10
Training loss: 1.6822881393474374
Validation loss: 2.4864336383269836

Epoch: 6| Step: 11
Training loss: 2.1734391761625234
Validation loss: 2.4815360155110247

Epoch: 6| Step: 12
Training loss: 1.7756625429915596
Validation loss: 2.487308998873487

Epoch: 6| Step: 13
Training loss: 2.010614125201906
Validation loss: 2.461964894016667

Epoch: 487| Step: 0
Training loss: 1.5269646137436736
Validation loss: 2.4685097314363613

Epoch: 6| Step: 1
Training loss: 1.2711102804036378
Validation loss: 2.4973506497180895

Epoch: 6| Step: 2
Training loss: 2.0800939425014793
Validation loss: 2.4876263456371

Epoch: 6| Step: 3
Training loss: 2.104657358294978
Validation loss: 2.4727977447882963

Epoch: 6| Step: 4
Training loss: 1.9550677593615697
Validation loss: 2.47645808836641

Epoch: 6| Step: 5
Training loss: 2.198286004394492
Validation loss: 2.444018034467188

Epoch: 6| Step: 6
Training loss: 1.2958550176410961
Validation loss: 2.37364167217169

Epoch: 6| Step: 7
Training loss: 1.3060461040321447
Validation loss: 2.3836127484161858

Epoch: 6| Step: 8
Training loss: 2.2150611837991367
Validation loss: 2.328072720689665

Epoch: 6| Step: 9
Training loss: 1.7423080607896604
Validation loss: 2.3321541492567293

Epoch: 6| Step: 10
Training loss: 1.5276559183862277
Validation loss: 2.330799939901726

Epoch: 6| Step: 11
Training loss: 1.5050927176066362
Validation loss: 2.3321761409217117

Epoch: 6| Step: 12
Training loss: 1.4958833790574164
Validation loss: 2.341076111672706

Epoch: 6| Step: 13
Training loss: 1.446583369548088
Validation loss: 2.353486151041155

Epoch: 488| Step: 0
Training loss: 1.8740189846954003
Validation loss: 2.359888184093524

Epoch: 6| Step: 1
Training loss: 1.8015499170795264
Validation loss: 2.368808122948279

Epoch: 6| Step: 2
Training loss: 1.7055369805157372
Validation loss: 2.3821904928446207

Epoch: 6| Step: 3
Training loss: 1.72263057629058
Validation loss: 2.410334876065181

Epoch: 6| Step: 4
Training loss: 1.589445996965769
Validation loss: 2.3973406579460117

Epoch: 6| Step: 5
Training loss: 1.0243085110436743
Validation loss: 2.434585826530113

Epoch: 6| Step: 6
Training loss: 1.3349225388245811
Validation loss: 2.4322010991434717

Epoch: 6| Step: 7
Training loss: 1.9551448905893476
Validation loss: 2.432240613780282

Epoch: 6| Step: 8
Training loss: 1.8432032534188127
Validation loss: 2.4373104741173814

Epoch: 6| Step: 9
Training loss: 1.7173553357008149
Validation loss: 2.4043767557655653

Epoch: 6| Step: 10
Training loss: 1.7529460088028472
Validation loss: 2.410871799894388

Epoch: 6| Step: 11
Training loss: 1.7162912989215748
Validation loss: 2.4010186265783093

Epoch: 6| Step: 12
Training loss: 1.8541424638975892
Validation loss: 2.409385646377692

Epoch: 6| Step: 13
Training loss: 1.8703237075916028
Validation loss: 2.3796489714692575

Epoch: 489| Step: 0
Training loss: 1.6503110245689208
Validation loss: 2.3838791376149264

Epoch: 6| Step: 1
Training loss: 1.1956867305375678
Validation loss: 2.3754520946656497

Epoch: 6| Step: 2
Training loss: 1.8292425929179315
Validation loss: 2.402286444886848

Epoch: 6| Step: 3
Training loss: 1.7298384437758751
Validation loss: 2.390973189024844

Epoch: 6| Step: 4
Training loss: 1.851127605629336
Validation loss: 2.4076777743461184

Epoch: 6| Step: 5
Training loss: 1.986207791474728
Validation loss: 2.415121815974135

Epoch: 6| Step: 6
Training loss: 1.8212521464924936
Validation loss: 2.4529996690620597

Epoch: 6| Step: 7
Training loss: 1.9408023132797882
Validation loss: 2.4945389639780884

Epoch: 6| Step: 8
Training loss: 1.1649040917796811
Validation loss: 2.4310732041122605

Epoch: 6| Step: 9
Training loss: 1.4555263571362627
Validation loss: 2.4518713260016765

Epoch: 6| Step: 10
Training loss: 1.0335648882260988
Validation loss: 2.44323367532281

Epoch: 6| Step: 11
Training loss: 2.076730360561649
Validation loss: 2.490942974319807

Epoch: 6| Step: 12
Training loss: 1.9650606373174215
Validation loss: 2.4380442440581778

Epoch: 6| Step: 13
Training loss: 1.8859571100335846
Validation loss: 2.4085709068002186

Epoch: 490| Step: 0
Training loss: 1.697169117878049
Validation loss: 2.370636965690459

Epoch: 6| Step: 1
Training loss: 1.9985558541142052
Validation loss: 2.347469722437179

Epoch: 6| Step: 2
Training loss: 1.677144596410422
Validation loss: 2.360731220105946

Epoch: 6| Step: 3
Training loss: 1.5486804174966893
Validation loss: 2.344438345947729

Epoch: 6| Step: 4
Training loss: 1.9688522675610027
Validation loss: 2.3590214081400585

Epoch: 6| Step: 5
Training loss: 1.940814413511055
Validation loss: 2.360045803486621

Epoch: 6| Step: 6
Training loss: 1.4937952776953873
Validation loss: 2.4222041694648504

Epoch: 6| Step: 7
Training loss: 1.6205545654761733
Validation loss: 2.426625640934895

Epoch: 6| Step: 8
Training loss: 1.3208806547879772
Validation loss: 2.4546566846202897

Epoch: 6| Step: 9
Training loss: 1.6624707413013269
Validation loss: 2.4938164429642993

Epoch: 6| Step: 10
Training loss: 2.0864643474561375
Validation loss: 2.4823373921032856

Epoch: 6| Step: 11
Training loss: 1.6565591775471893
Validation loss: 2.385621379431832

Epoch: 6| Step: 12
Training loss: 0.9108261459104232
Validation loss: 2.3099567326548978

Epoch: 6| Step: 13
Training loss: 2.34604197015318
Validation loss: 2.297143695119518

Epoch: 491| Step: 0
Training loss: 2.2149033849582938
Validation loss: 2.298275091482165

Epoch: 6| Step: 1
Training loss: 2.13807760543503
Validation loss: 2.293259680211056

Epoch: 6| Step: 2
Training loss: 1.7806742892233682
Validation loss: 2.315289923256358

Epoch: 6| Step: 3
Training loss: 1.9830296078163014
Validation loss: 2.3646364125216666

Epoch: 6| Step: 4
Training loss: 1.569264152133653
Validation loss: 2.4613102831253095

Epoch: 6| Step: 5
Training loss: 1.533805272133163
Validation loss: 2.5365176195938397

Epoch: 6| Step: 6
Training loss: 1.4281544621807123
Validation loss: 2.6126371750280124

Epoch: 6| Step: 7
Training loss: 1.9140044534406202
Validation loss: 2.6200661102147786

Epoch: 6| Step: 8
Training loss: 1.6094930661050044
Validation loss: 2.521899005615886

Epoch: 6| Step: 9
Training loss: 1.2796946132960592
Validation loss: 2.4098359794969686

Epoch: 6| Step: 10
Training loss: 1.8597329700714302
Validation loss: 2.3430610502796654

Epoch: 6| Step: 11
Training loss: 1.8529220933136317
Validation loss: 2.331632987459403

Epoch: 6| Step: 12
Training loss: 1.6001051808594435
Validation loss: 2.314704669439762

Epoch: 6| Step: 13
Training loss: 1.9595788755318173
Validation loss: 2.320344712223101

Epoch: 492| Step: 0
Training loss: 1.647813290111657
Validation loss: 2.344907144909938

Epoch: 6| Step: 1
Training loss: 1.6247008121603264
Validation loss: 2.414690606549869

Epoch: 6| Step: 2
Training loss: 1.3563583049511334
Validation loss: 2.4780269832096575

Epoch: 6| Step: 3
Training loss: 1.8040282791780107
Validation loss: 2.5526572868921438

Epoch: 6| Step: 4
Training loss: 1.7474967218676642
Validation loss: 2.595063212283139

Epoch: 6| Step: 5
Training loss: 2.2598668028816116
Validation loss: 2.582018903539236

Epoch: 6| Step: 6
Training loss: 1.7554688830984666
Validation loss: 2.5882209600125767

Epoch: 6| Step: 7
Training loss: 1.952812230816287
Validation loss: 2.522371438314479

Epoch: 6| Step: 8
Training loss: 2.142324065704425
Validation loss: 2.4209612866374

Epoch: 6| Step: 9
Training loss: 1.569750784999981
Validation loss: 2.3554432458975825

Epoch: 6| Step: 10
Training loss: 1.4335622342254914
Validation loss: 2.31585835181745

Epoch: 6| Step: 11
Training loss: 1.153797641981456
Validation loss: 2.3120738487395136

Epoch: 6| Step: 12
Training loss: 1.5918821721538823
Validation loss: 2.298245933096571

Epoch: 6| Step: 13
Training loss: 1.8532621413331956
Validation loss: 2.3072039003864013

Epoch: 493| Step: 0
Training loss: 1.6272846447434144
Validation loss: 2.320282220875947

Epoch: 6| Step: 1
Training loss: 1.5994604691166474
Validation loss: 2.3191887742025203

Epoch: 6| Step: 2
Training loss: 1.5526678107047107
Validation loss: 2.377588920048833

Epoch: 6| Step: 3
Training loss: 2.0150185789098947
Validation loss: 2.3964850778260516

Epoch: 6| Step: 4
Training loss: 1.583859289383269
Validation loss: 2.446737534227988

Epoch: 6| Step: 5
Training loss: 1.9661673908862325
Validation loss: 2.5279950779810085

Epoch: 6| Step: 6
Training loss: 1.866300555781707
Validation loss: 2.5689406332180846

Epoch: 6| Step: 7
Training loss: 1.3938493530716394
Validation loss: 2.5314801697759797

Epoch: 6| Step: 8
Training loss: 1.866330001761766
Validation loss: 2.523063802419979

Epoch: 6| Step: 9
Training loss: 1.6027369961030313
Validation loss: 2.48986969701883

Epoch: 6| Step: 10
Training loss: 2.021839586092242
Validation loss: 2.4408527073246207

Epoch: 6| Step: 11
Training loss: 1.2991659313115813
Validation loss: 2.4207872094671696

Epoch: 6| Step: 12
Training loss: 1.7259280044374576
Validation loss: 2.421820254042861

Epoch: 6| Step: 13
Training loss: 1.4035339405235407
Validation loss: 2.368206791189391

Epoch: 494| Step: 0
Training loss: 1.9764928993967994
Validation loss: 2.389833080950976

Epoch: 6| Step: 1
Training loss: 1.4399501817085938
Validation loss: 2.3797460833159465

Epoch: 6| Step: 2
Training loss: 1.8231960918073291
Validation loss: 2.359970049246561

Epoch: 6| Step: 3
Training loss: 1.1868321397865813
Validation loss: 2.4057938295567087

Epoch: 6| Step: 4
Training loss: 1.4354895755465051
Validation loss: 2.420842657067219

Epoch: 6| Step: 5
Training loss: 2.0262389360769424
Validation loss: 2.4383150562267564

Epoch: 6| Step: 6
Training loss: 1.7822456923202787
Validation loss: 2.447017827392486

Epoch: 6| Step: 7
Training loss: 1.5908490875620391
Validation loss: 2.4550444121395607

Epoch: 6| Step: 8
Training loss: 1.5676374282094832
Validation loss: 2.457658926169484

Epoch: 6| Step: 9
Training loss: 1.6110167786324128
Validation loss: 2.445416747560889

Epoch: 6| Step: 10
Training loss: 1.8384798668118745
Validation loss: 2.408749589764674

Epoch: 6| Step: 11
Training loss: 1.4753246467347245
Validation loss: 2.3734664866723914

Epoch: 6| Step: 12
Training loss: 1.6670490382578496
Validation loss: 2.383652610620879

Epoch: 6| Step: 13
Training loss: 2.2380967521855606
Validation loss: 2.359470409237235

Epoch: 495| Step: 0
Training loss: 1.647290305191789
Validation loss: 2.3692590305364396

Epoch: 6| Step: 1
Training loss: 1.659224448405754
Validation loss: 2.3323917759861494

Epoch: 6| Step: 2
Training loss: 1.899455609884611
Validation loss: 2.347769192843692

Epoch: 6| Step: 3
Training loss: 1.9470095298663175
Validation loss: 2.3801618454693285

Epoch: 6| Step: 4
Training loss: 1.597372538178342
Validation loss: 2.3551027957895756

Epoch: 6| Step: 5
Training loss: 1.3624703692792741
Validation loss: 2.352670856626932

Epoch: 6| Step: 6
Training loss: 1.6886301141817182
Validation loss: 2.3651096231191984

Epoch: 6| Step: 7
Training loss: 1.9094416680067783
Validation loss: 2.4042042310146647

Epoch: 6| Step: 8
Training loss: 1.479952840569198
Validation loss: 2.433879457273551

Epoch: 6| Step: 9
Training loss: 1.6122716372341275
Validation loss: 2.44523872998873

Epoch: 6| Step: 10
Training loss: 1.4101345240221705
Validation loss: 2.439083595681546

Epoch: 6| Step: 11
Training loss: 1.5173695542454386
Validation loss: 2.4747567902650056

Epoch: 6| Step: 12
Training loss: 1.9574412755817412
Validation loss: 2.4812626907868425

Epoch: 6| Step: 13
Training loss: 1.4653208858341964
Validation loss: 2.4735138883903476

Epoch: 496| Step: 0
Training loss: 1.4980056538188669
Validation loss: 2.454857724211939

Epoch: 6| Step: 1
Training loss: 1.4708406705736352
Validation loss: 2.42083669284571

Epoch: 6| Step: 2
Training loss: 1.8632594973016152
Validation loss: 2.4197584321137167

Epoch: 6| Step: 3
Training loss: 1.6560839443814472
Validation loss: 2.4044586442036304

Epoch: 6| Step: 4
Training loss: 2.3046604995439046
Validation loss: 2.4306257763010057

Epoch: 6| Step: 5
Training loss: 1.0397343578735037
Validation loss: 2.409786464377837

Epoch: 6| Step: 6
Training loss: 1.5223096536245688
Validation loss: 2.4206721594689453

Epoch: 6| Step: 7
Training loss: 1.6825393951021048
Validation loss: 2.4049979458861674

Epoch: 6| Step: 8
Training loss: 2.1483273009735164
Validation loss: 2.419641341845623

Epoch: 6| Step: 9
Training loss: 1.7507427546683383
Validation loss: 2.448231693088276

Epoch: 6| Step: 10
Training loss: 1.5427061992306816
Validation loss: 2.412356262073625

Epoch: 6| Step: 11
Training loss: 1.4916426377874012
Validation loss: 2.383360255810954

Epoch: 6| Step: 12
Training loss: 1.405701424305038
Validation loss: 2.359541993240507

Epoch: 6| Step: 13
Training loss: 0.6432418873464744
Validation loss: 2.3667008614427614

Epoch: 497| Step: 0
Training loss: 1.6126191117407085
Validation loss: 2.35302991662025

Epoch: 6| Step: 1
Training loss: 1.460119742747913
Validation loss: 2.3973450926131696

Epoch: 6| Step: 2
Training loss: 1.6990893786059929
Validation loss: 2.409442812438531

Epoch: 6| Step: 3
Training loss: 0.8607248282451138
Validation loss: 2.4424529594247564

Epoch: 6| Step: 4
Training loss: 1.3641542628863679
Validation loss: 2.4734619768757713

Epoch: 6| Step: 5
Training loss: 2.0825314949649028
Validation loss: 2.517473539718513

Epoch: 6| Step: 6
Training loss: 1.8190159580271008
Validation loss: 2.5076617752520405

Epoch: 6| Step: 7
Training loss: 1.4602957555299456
Validation loss: 2.5140657835380984

Epoch: 6| Step: 8
Training loss: 1.6938808038744566
Validation loss: 2.4998384013297246

Epoch: 6| Step: 9
Training loss: 1.621517558023657
Validation loss: 2.4767977974545374

Epoch: 6| Step: 10
Training loss: 1.5274530942367375
Validation loss: 2.4647121136547376

Epoch: 6| Step: 11
Training loss: 2.1773660527932472
Validation loss: 2.446380959469793

Epoch: 6| Step: 12
Training loss: 1.5413137324042754
Validation loss: 2.413607106150673

Epoch: 6| Step: 13
Training loss: 1.7097706756970394
Validation loss: 2.3796155301806134

Epoch: 498| Step: 0
Training loss: 1.1584822783088133
Validation loss: 2.329619807668461

Epoch: 6| Step: 1
Training loss: 1.7705840963856128
Validation loss: 2.3252364041200075

Epoch: 6| Step: 2
Training loss: 1.4614530255562759
Validation loss: 2.352616394167093

Epoch: 6| Step: 3
Training loss: 1.4718574765857004
Validation loss: 2.382954657752294

Epoch: 6| Step: 4
Training loss: 1.4538213230523112
Validation loss: 2.382032863242255

Epoch: 6| Step: 5
Training loss: 1.508288846843971
Validation loss: 2.3746069349182513

Epoch: 6| Step: 6
Training loss: 1.6983893814921127
Validation loss: 2.3859904791531963

Epoch: 6| Step: 7
Training loss: 1.681707400813799
Validation loss: 2.4286198729683655

Epoch: 6| Step: 8
Training loss: 1.2960752296159257
Validation loss: 2.4344701770766726

Epoch: 6| Step: 9
Training loss: 1.6699592809224315
Validation loss: 2.4713624916717474

Epoch: 6| Step: 10
Training loss: 2.2710648048322626
Validation loss: 2.4894594644040056

Epoch: 6| Step: 11
Training loss: 2.051710982516794
Validation loss: 2.484377923387028

Epoch: 6| Step: 12
Training loss: 1.7899668710722365
Validation loss: 2.472603163390443

Epoch: 6| Step: 13
Training loss: 1.0919496159859798
Validation loss: 2.4521556020759046

Epoch: 499| Step: 0
Training loss: 1.190212064007486
Validation loss: 2.440334879170611

Epoch: 6| Step: 1
Training loss: 1.4498034837345972
Validation loss: 2.379399047310445

Epoch: 6| Step: 2
Training loss: 1.9798118811164827
Validation loss: 2.389184495130076

Epoch: 6| Step: 3
Training loss: 1.2866025630188314
Validation loss: 2.3829056184844624

Epoch: 6| Step: 4
Training loss: 1.280318037546709
Validation loss: 2.409477422957966

Epoch: 6| Step: 5
Training loss: 1.8740994516037144
Validation loss: 2.4786549184169364

Epoch: 6| Step: 6
Training loss: 1.697269136800524
Validation loss: 2.4527269579589115

Epoch: 6| Step: 7
Training loss: 1.7279506988644957
Validation loss: 2.437842282731101

Epoch: 6| Step: 8
Training loss: 2.180745404746897
Validation loss: 2.4227765509456516

Epoch: 6| Step: 9
Training loss: 1.5260488186648034
Validation loss: 2.4022713609686077

Epoch: 6| Step: 10
Training loss: 1.6460575804065654
Validation loss: 2.387746829658542

Epoch: 6| Step: 11
Training loss: 1.617345682415173
Validation loss: 2.351069715887412

Epoch: 6| Step: 12
Training loss: 1.2356251530509703
Validation loss: 2.3299086601715002

Epoch: 6| Step: 13
Training loss: 2.0269042257106915
Validation loss: 2.3435757190072986

Epoch: 500| Step: 0
Training loss: 1.8487261845806693
Validation loss: 2.3739801223726062

Epoch: 6| Step: 1
Training loss: 1.5766936505665317
Validation loss: 2.357063746171304

Epoch: 6| Step: 2
Training loss: 1.8477603810426102
Validation loss: 2.3845682046239727

Epoch: 6| Step: 3
Training loss: 1.5071316303462632
Validation loss: 2.445804573039945

Epoch: 6| Step: 4
Training loss: 1.8874994088481458
Validation loss: 2.453340840555001

Epoch: 6| Step: 5
Training loss: 1.545046255166177
Validation loss: 2.457972910137657

Epoch: 6| Step: 6
Training loss: 1.284496010233265
Validation loss: 2.451002637858719

Epoch: 6| Step: 7
Training loss: 1.1685830736546048
Validation loss: 2.4408278002566814

Epoch: 6| Step: 8
Training loss: 1.7706050351650302
Validation loss: 2.4272677429720204

Epoch: 6| Step: 9
Training loss: 2.0011984095693487
Validation loss: 2.44141964199536

Epoch: 6| Step: 10
Training loss: 1.581914902164598
Validation loss: 2.434576988083549

Epoch: 6| Step: 11
Training loss: 1.0512474188846648
Validation loss: 2.4027110170795827

Epoch: 6| Step: 12
Training loss: 1.594978307977096
Validation loss: 2.391441435825955

Epoch: 6| Step: 13
Training loss: 1.6533274506777018
Validation loss: 2.3816510287286508

Testing loss: 2.4850853161117468
